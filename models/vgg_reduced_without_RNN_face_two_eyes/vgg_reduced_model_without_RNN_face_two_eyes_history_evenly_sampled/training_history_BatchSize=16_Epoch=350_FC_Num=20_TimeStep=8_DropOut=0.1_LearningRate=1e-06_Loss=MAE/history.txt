Epoch: 1| Step: 0
Training loss: 5.807065486907959
Validation loss: 4.596022677677934

Epoch: 6| Step: 1
Training loss: 4.70643424987793
Validation loss: 4.591231482003325

Epoch: 6| Step: 2
Training loss: 3.571732521057129
Validation loss: 4.586581883891936

Epoch: 6| Step: 3
Training loss: 3.9895777702331543
Validation loss: 4.582813027084515

Epoch: 6| Step: 4
Training loss: 4.964773178100586
Validation loss: 4.577341254039477

Epoch: 6| Step: 5
Training loss: 3.695463180541992
Validation loss: 4.5712788335738646

Epoch: 6| Step: 6
Training loss: 3.7367167472839355
Validation loss: 4.569153308868408

Epoch: 6| Step: 7
Training loss: 4.893913269042969
Validation loss: 4.562595675068517

Epoch: 6| Step: 8
Training loss: 3.995561122894287
Validation loss: 4.558757766600578

Epoch: 6| Step: 9
Training loss: 4.567564964294434
Validation loss: 4.553594753306399

Epoch: 6| Step: 10
Training loss: 3.1051013469696045
Validation loss: 4.55164707860639

Epoch: 6| Step: 11
Training loss: 5.188851356506348
Validation loss: 4.546256342241841

Epoch: 6| Step: 12
Training loss: 5.032418251037598
Validation loss: 4.5444465760261785

Epoch: 6| Step: 13
Training loss: 3.626204490661621
Validation loss: 4.537995041057628

Epoch: 2| Step: 0
Training loss: 3.851949453353882
Validation loss: 4.532972202506117

Epoch: 6| Step: 1
Training loss: 4.979637145996094
Validation loss: 4.529442892279676

Epoch: 6| Step: 2
Training loss: 3.3712282180786133
Validation loss: 4.5233632826036025

Epoch: 6| Step: 3
Training loss: 4.324599266052246
Validation loss: 4.521583526365219

Epoch: 6| Step: 4
Training loss: 5.075695037841797
Validation loss: 4.517975725153441

Epoch: 6| Step: 5
Training loss: 3.8068959712982178
Validation loss: 4.511028115467359

Epoch: 6| Step: 6
Training loss: 4.875370025634766
Validation loss: 4.508132749988187

Epoch: 6| Step: 7
Training loss: 3.876270055770874
Validation loss: 4.5033880100455335

Epoch: 6| Step: 8
Training loss: 4.61306095123291
Validation loss: 4.499996123775359

Epoch: 6| Step: 9
Training loss: 3.5346951484680176
Validation loss: 4.496241379809636

Epoch: 6| Step: 10
Training loss: 4.546298027038574
Validation loss: 4.491525496205976

Epoch: 6| Step: 11
Training loss: 4.173778533935547
Validation loss: 4.487584503748083

Epoch: 6| Step: 12
Training loss: 4.8511199951171875
Validation loss: 4.483450115367931

Epoch: 6| Step: 13
Training loss: 4.635435104370117
Validation loss: 4.476661584710562

Epoch: 3| Step: 0
Training loss: 3.306898593902588
Validation loss: 4.474134824609243

Epoch: 6| Step: 1
Training loss: 4.832152843475342
Validation loss: 4.471257602014849

Epoch: 6| Step: 2
Training loss: 4.998247146606445
Validation loss: 4.466917355855306

Epoch: 6| Step: 3
Training loss: 4.580387115478516
Validation loss: 4.460648972501037

Epoch: 6| Step: 4
Training loss: 4.230162620544434
Validation loss: 4.45488130405385

Epoch: 6| Step: 5
Training loss: 2.817830801010132
Validation loss: 4.453302839750885

Epoch: 6| Step: 6
Training loss: 2.2997963428497314
Validation loss: 4.447825806115263

Epoch: 6| Step: 7
Training loss: 5.420375823974609
Validation loss: 4.4433523403700965

Epoch: 6| Step: 8
Training loss: 4.134458541870117
Validation loss: 4.439218449336226

Epoch: 6| Step: 9
Training loss: 4.644672870635986
Validation loss: 4.436233176979967

Epoch: 6| Step: 10
Training loss: 5.509428024291992
Validation loss: 4.430961716559626

Epoch: 6| Step: 11
Training loss: 3.678586483001709
Validation loss: 4.425983628919048

Epoch: 6| Step: 12
Training loss: 4.062111854553223
Validation loss: 4.422510905932355

Epoch: 6| Step: 13
Training loss: 5.663559436798096
Validation loss: 4.41772456835675

Epoch: 4| Step: 0
Training loss: 4.348440647125244
Validation loss: 4.411771353854928

Epoch: 6| Step: 1
Training loss: 4.242177963256836
Validation loss: 4.405510292258314

Epoch: 6| Step: 2
Training loss: 4.453883647918701
Validation loss: 4.401658617040162

Epoch: 6| Step: 3
Training loss: 4.373234272003174
Validation loss: 4.398439581676196

Epoch: 6| Step: 4
Training loss: 4.732561111450195
Validation loss: 4.3940886579534055

Epoch: 6| Step: 5
Training loss: 4.563229084014893
Validation loss: 4.388262169335478

Epoch: 6| Step: 6
Training loss: 3.760115623474121
Validation loss: 4.382738982477496

Epoch: 6| Step: 7
Training loss: 4.452695369720459
Validation loss: 4.375173866107899

Epoch: 6| Step: 8
Training loss: 3.856490135192871
Validation loss: 4.371234565652827

Epoch: 6| Step: 9
Training loss: 3.523919105529785
Validation loss: 4.369229027020034

Epoch: 6| Step: 10
Training loss: 3.923285484313965
Validation loss: 4.3607498548364125

Epoch: 6| Step: 11
Training loss: 4.590717315673828
Validation loss: 4.355620379089027

Epoch: 6| Step: 12
Training loss: 3.872953414916992
Validation loss: 4.350427373763053

Epoch: 6| Step: 13
Training loss: 3.7716445922851562
Validation loss: 4.3446168643172065

Epoch: 5| Step: 0
Training loss: 3.6405787467956543
Validation loss: 4.3380757762539774

Epoch: 6| Step: 1
Training loss: 3.316922664642334
Validation loss: 4.337533422695693

Epoch: 6| Step: 2
Training loss: 5.625675201416016
Validation loss: 4.329132377460438

Epoch: 6| Step: 3
Training loss: 4.17356014251709
Validation loss: 4.32365664359062

Epoch: 6| Step: 4
Training loss: 4.816000461578369
Validation loss: 4.316567810632849

Epoch: 6| Step: 5
Training loss: 3.668423891067505
Validation loss: 4.313516334820819

Epoch: 6| Step: 6
Training loss: 4.720999717712402
Validation loss: 4.309381059421006

Epoch: 6| Step: 7
Training loss: 3.8417255878448486
Validation loss: 4.3021884169629825

Epoch: 6| Step: 8
Training loss: 4.14992618560791
Validation loss: 4.296579796780822

Epoch: 6| Step: 9
Training loss: 3.263702392578125
Validation loss: 4.290773504523821

Epoch: 6| Step: 10
Training loss: 4.023508548736572
Validation loss: 4.285363910018757

Epoch: 6| Step: 11
Training loss: 3.344106912612915
Validation loss: 4.279228292485719

Epoch: 6| Step: 12
Training loss: 4.208127498626709
Validation loss: 4.272512784568212

Epoch: 6| Step: 13
Training loss: 5.397176742553711
Validation loss: 4.269008031455419

Epoch: 6| Step: 0
Training loss: 3.826352596282959
Validation loss: 4.262872870250415

Epoch: 6| Step: 1
Training loss: 4.29298210144043
Validation loss: 4.256537040074666

Epoch: 6| Step: 2
Training loss: 4.593946933746338
Validation loss: 4.248672536624375

Epoch: 6| Step: 3
Training loss: 4.810148239135742
Validation loss: 4.242667480181622

Epoch: 6| Step: 4
Training loss: 4.390516757965088
Validation loss: 4.23746516114922

Epoch: 6| Step: 5
Training loss: 3.740023612976074
Validation loss: 4.230499334232782

Epoch: 6| Step: 6
Training loss: 4.866852283477783
Validation loss: 4.2236816242177

Epoch: 6| Step: 7
Training loss: 2.893812656402588
Validation loss: 4.218993935533749

Epoch: 6| Step: 8
Training loss: 4.169510841369629
Validation loss: 4.2136429202172065

Epoch: 6| Step: 9
Training loss: 3.387877941131592
Validation loss: 4.204877761102492

Epoch: 6| Step: 10
Training loss: 3.3547234535217285
Validation loss: 4.201802002486362

Epoch: 6| Step: 11
Training loss: 4.1531476974487305
Validation loss: 4.19582333359667

Epoch: 6| Step: 12
Training loss: 4.365909576416016
Validation loss: 4.1895831682348765

Epoch: 6| Step: 13
Training loss: 3.4835832118988037
Validation loss: 4.184143022824359

Epoch: 7| Step: 0
Training loss: 3.8108253479003906
Validation loss: 4.176076053291239

Epoch: 6| Step: 1
Training loss: 4.048912525177002
Validation loss: 4.169473550652945

Epoch: 6| Step: 2
Training loss: 4.470937728881836
Validation loss: 4.165367895557035

Epoch: 6| Step: 3
Training loss: 4.35457181930542
Validation loss: 4.154912407680224

Epoch: 6| Step: 4
Training loss: 4.5420684814453125
Validation loss: 4.150772638218378

Epoch: 6| Step: 5
Training loss: 4.7223687171936035
Validation loss: 4.143390806772375

Epoch: 6| Step: 6
Training loss: 4.641077995300293
Validation loss: 4.136963867372082

Epoch: 6| Step: 7
Training loss: 3.3710999488830566
Validation loss: 4.129799104505969

Epoch: 6| Step: 8
Training loss: 3.522246837615967
Validation loss: 4.123110207178259

Epoch: 6| Step: 9
Training loss: 4.242690086364746
Validation loss: 4.1155634490392545

Epoch: 6| Step: 10
Training loss: 3.8454437255859375
Validation loss: 4.109145666963311

Epoch: 6| Step: 11
Training loss: 3.1015772819519043
Validation loss: 4.102637362736528

Epoch: 6| Step: 12
Training loss: 2.9004573822021484
Validation loss: 4.094752204033636

Epoch: 6| Step: 13
Training loss: 3.7179040908813477
Validation loss: 4.087125219324584

Epoch: 8| Step: 0
Training loss: 3.8075873851776123
Validation loss: 4.08096250923731

Epoch: 6| Step: 1
Training loss: 3.138253688812256
Validation loss: 4.074394308110719

Epoch: 6| Step: 2
Training loss: 4.3042707443237305
Validation loss: 4.066093050023561

Epoch: 6| Step: 3
Training loss: 3.7620601654052734
Validation loss: 4.060886485602266

Epoch: 6| Step: 4
Training loss: 3.891817092895508
Validation loss: 4.0548801114482265

Epoch: 6| Step: 5
Training loss: 4.746484279632568
Validation loss: 4.048786573512579

Epoch: 6| Step: 6
Training loss: 3.979052782058716
Validation loss: 4.038994076431439

Epoch: 6| Step: 7
Training loss: 3.896453857421875
Validation loss: 4.031348397654872

Epoch: 6| Step: 8
Training loss: 3.527012825012207
Validation loss: 4.02438497543335

Epoch: 6| Step: 9
Training loss: 4.06852388381958
Validation loss: 4.013579842864826

Epoch: 6| Step: 10
Training loss: 3.995265007019043
Validation loss: 4.007466372623239

Epoch: 6| Step: 11
Training loss: 3.6092028617858887
Validation loss: 4.000301361083984

Epoch: 6| Step: 12
Training loss: 4.363065719604492
Validation loss: 3.9928134436248452

Epoch: 6| Step: 13
Training loss: 2.445939779281616
Validation loss: 3.9837572087523756

Epoch: 9| Step: 0
Training loss: 3.537003993988037
Validation loss: 3.9752380412112

Epoch: 6| Step: 1
Training loss: 3.018808364868164
Validation loss: 3.965549922758533

Epoch: 6| Step: 2
Training loss: 3.944143295288086
Validation loss: 3.958881716574392

Epoch: 6| Step: 3
Training loss: 4.347496032714844
Validation loss: 3.9497890190411638

Epoch: 6| Step: 4
Training loss: 1.9735968112945557
Validation loss: 3.9385028141801075

Epoch: 6| Step: 5
Training loss: 3.957979440689087
Validation loss: 3.932193838140016

Epoch: 6| Step: 6
Training loss: 4.322474479675293
Validation loss: 3.925540465180592

Epoch: 6| Step: 7
Training loss: 4.592217922210693
Validation loss: 3.9151813086643013

Epoch: 6| Step: 8
Training loss: 4.449448585510254
Validation loss: 3.9054218569109516

Epoch: 6| Step: 9
Training loss: 3.997781753540039
Validation loss: 3.8955162776413785

Epoch: 6| Step: 10
Training loss: 3.346708297729492
Validation loss: 3.889810577515633

Epoch: 6| Step: 11
Training loss: 2.9132962226867676
Validation loss: 3.8794957719823366

Epoch: 6| Step: 12
Training loss: 4.412637710571289
Validation loss: 3.8751965697093675

Epoch: 6| Step: 13
Training loss: 4.1639885902404785
Validation loss: 3.8632754587358042

Epoch: 10| Step: 0
Training loss: 3.503155469894409
Validation loss: 3.8576813872142504

Epoch: 6| Step: 1
Training loss: 4.22067928314209
Validation loss: 3.8446764869074666

Epoch: 6| Step: 2
Training loss: 2.8389058113098145
Validation loss: 3.8322218130993586

Epoch: 6| Step: 3
Training loss: 4.049783229827881
Validation loss: 3.826659894758655

Epoch: 6| Step: 4
Training loss: 3.6417086124420166
Validation loss: 3.813856186405305

Epoch: 6| Step: 5
Training loss: 3.6982650756835938
Validation loss: 3.8068480184001308

Epoch: 6| Step: 6
Training loss: 3.97597074508667
Validation loss: 3.792141314475767

Epoch: 6| Step: 7
Training loss: 3.3474464416503906
Validation loss: 3.7865800447361444

Epoch: 6| Step: 8
Training loss: 2.857880115509033
Validation loss: 3.77635052639951

Epoch: 6| Step: 9
Training loss: 3.7521252632141113
Validation loss: 3.76755956936908

Epoch: 6| Step: 10
Training loss: 3.8201565742492676
Validation loss: 3.7564803143983245

Epoch: 6| Step: 11
Training loss: 3.874420166015625
Validation loss: 3.744436776766213

Epoch: 6| Step: 12
Training loss: 4.158550262451172
Validation loss: 3.735608903310632

Epoch: 6| Step: 13
Training loss: 3.3198177814483643
Validation loss: 3.7274303743916173

Epoch: 11| Step: 0
Training loss: 4.999510765075684
Validation loss: 3.714241986633629

Epoch: 6| Step: 1
Training loss: 4.200496673583984
Validation loss: 3.704073106088946

Epoch: 6| Step: 2
Training loss: 3.6772799491882324
Validation loss: 3.692124941015756

Epoch: 6| Step: 3
Training loss: 3.314149856567383
Validation loss: 3.6845897090050483

Epoch: 6| Step: 4
Training loss: 4.452373504638672
Validation loss: 3.669664552134852

Epoch: 6| Step: 5
Training loss: 3.6300551891326904
Validation loss: 3.6607088529935448

Epoch: 6| Step: 6
Training loss: 3.195664405822754
Validation loss: 3.6487530175075737

Epoch: 6| Step: 7
Training loss: 3.6674933433532715
Validation loss: 3.6361420385299192

Epoch: 6| Step: 8
Training loss: 2.3934617042541504
Validation loss: 3.6231761722154516

Epoch: 6| Step: 9
Training loss: 2.793395519256592
Validation loss: 3.6133786221986175

Epoch: 6| Step: 10
Training loss: 2.5458335876464844
Validation loss: 3.5995224111823627

Epoch: 6| Step: 11
Training loss: 2.9409449100494385
Validation loss: 3.589304595865229

Epoch: 6| Step: 12
Training loss: 3.9564449787139893
Validation loss: 3.580443174608292

Epoch: 6| Step: 13
Training loss: 3.820963144302368
Validation loss: 3.56699610781926

Epoch: 12| Step: 0
Training loss: 3.42270827293396
Validation loss: 3.555823900366342

Epoch: 6| Step: 1
Training loss: 3.44443678855896
Validation loss: 3.5426469182455413

Epoch: 6| Step: 2
Training loss: 2.92927622795105
Validation loss: 3.5288821727998796

Epoch: 6| Step: 3
Training loss: 4.255705833435059
Validation loss: 3.5174085606810865

Epoch: 6| Step: 4
Training loss: 3.929630756378174
Validation loss: 3.514930199551326

Epoch: 6| Step: 5
Training loss: 2.8888471126556396
Validation loss: 3.496655325735769

Epoch: 6| Step: 6
Training loss: 2.4986143112182617
Validation loss: 3.484072013567853

Epoch: 6| Step: 7
Training loss: 2.8311686515808105
Validation loss: 3.4704452406975532

Epoch: 6| Step: 8
Training loss: 3.4708805084228516
Validation loss: 3.4579755337007585

Epoch: 6| Step: 9
Training loss: 3.9799089431762695
Validation loss: 3.4429966352319203

Epoch: 6| Step: 10
Training loss: 3.4495396614074707
Validation loss: 3.433872699737549

Epoch: 6| Step: 11
Training loss: 3.76041841506958
Validation loss: 3.4160161710554555

Epoch: 6| Step: 12
Training loss: 2.6292667388916016
Validation loss: 3.4024197875812487

Epoch: 6| Step: 13
Training loss: 4.294994354248047
Validation loss: 3.3856042097973567

Epoch: 13| Step: 0
Training loss: 2.925967216491699
Validation loss: 3.379626433054606

Epoch: 6| Step: 1
Training loss: 3.228879451751709
Validation loss: 3.364034216891053

Epoch: 6| Step: 2
Training loss: 3.4613771438598633
Validation loss: 3.347972613508983

Epoch: 6| Step: 3
Training loss: 3.9413232803344727
Validation loss: 3.3352691922136533

Epoch: 6| Step: 4
Training loss: 3.1402602195739746
Validation loss: 3.32092200556109

Epoch: 6| Step: 5
Training loss: 3.1849746704101562
Validation loss: 3.3014935037141204

Epoch: 6| Step: 6
Training loss: 2.7312450408935547
Validation loss: 3.2938234216423443

Epoch: 6| Step: 7
Training loss: 4.191329479217529
Validation loss: 3.275468780148414

Epoch: 6| Step: 8
Training loss: 3.7036123275756836
Validation loss: 3.2609887174380723

Epoch: 6| Step: 9
Training loss: 3.243492603302002
Validation loss: 3.241533443491946

Epoch: 6| Step: 10
Training loss: 2.88822340965271
Validation loss: 3.2291440758653867

Epoch: 6| Step: 11
Training loss: 2.219747304916382
Validation loss: 3.2201501887331725

Epoch: 6| Step: 12
Training loss: 3.0694737434387207
Validation loss: 3.204116331633701

Epoch: 6| Step: 13
Training loss: 2.8693602085113525
Validation loss: 3.185412319757605

Epoch: 14| Step: 0
Training loss: 2.6968443393707275
Validation loss: 3.166242563596336

Epoch: 6| Step: 1
Training loss: 3.215022563934326
Validation loss: 3.1543825287972727

Epoch: 6| Step: 2
Training loss: 2.6855523586273193
Validation loss: 3.139610400763891

Epoch: 6| Step: 3
Training loss: 2.334591865539551
Validation loss: 3.1207725335192937

Epoch: 6| Step: 4
Training loss: 2.8855080604553223
Validation loss: 3.107145368411977

Epoch: 6| Step: 5
Training loss: 3.3134231567382812
Validation loss: 3.0916256238055486

Epoch: 6| Step: 6
Training loss: 3.1265058517456055
Validation loss: 3.0698461301865114

Epoch: 6| Step: 7
Training loss: 3.8040037155151367
Validation loss: 3.065963032425091

Epoch: 6| Step: 8
Training loss: 3.0934271812438965
Validation loss: 3.04132112379997

Epoch: 6| Step: 9
Training loss: 3.3602664470672607
Validation loss: 3.030345106637606

Epoch: 6| Step: 10
Training loss: 3.1156718730926514
Validation loss: 3.011674934817899

Epoch: 6| Step: 11
Training loss: 3.210444211959839
Validation loss: 2.9987640227040937

Epoch: 6| Step: 12
Training loss: 3.2528700828552246
Validation loss: 2.9773292900413595

Epoch: 6| Step: 13
Training loss: 2.1866769790649414
Validation loss: 2.959916296825614

Epoch: 15| Step: 0
Training loss: 3.17350435256958
Validation loss: 2.941656635653588

Epoch: 6| Step: 1
Training loss: 2.6298563480377197
Validation loss: 2.930919275488905

Epoch: 6| Step: 2
Training loss: 2.6368706226348877
Validation loss: 2.914833104738625

Epoch: 6| Step: 3
Training loss: 2.303891897201538
Validation loss: 2.8898141537943194

Epoch: 6| Step: 4
Training loss: 3.111426830291748
Validation loss: 2.875955320173694

Epoch: 6| Step: 5
Training loss: 2.957432746887207
Validation loss: 2.8556267061541156

Epoch: 6| Step: 6
Training loss: 2.2865147590637207
Validation loss: 2.838428117895639

Epoch: 6| Step: 7
Training loss: 2.972719669342041
Validation loss: 2.818302477559736

Epoch: 6| Step: 8
Training loss: 3.042027473449707
Validation loss: 2.8057323578865296

Epoch: 6| Step: 9
Training loss: 2.580375909805298
Validation loss: 2.7865390034132105

Epoch: 6| Step: 10
Training loss: 3.4557530879974365
Validation loss: 2.7672722570357786

Epoch: 6| Step: 11
Training loss: 3.0716235637664795
Validation loss: 2.749729064203078

Epoch: 6| Step: 12
Training loss: 3.0727639198303223
Validation loss: 2.7250237849450882

Epoch: 6| Step: 13
Training loss: 2.8701658248901367
Validation loss: 2.712828577205699

Epoch: 16| Step: 0
Training loss: 2.7537765502929688
Validation loss: 2.6888888241142355

Epoch: 6| Step: 1
Training loss: 2.0495963096618652
Validation loss: 2.668635291437949

Epoch: 6| Step: 2
Training loss: 3.0855295658111572
Validation loss: 2.657910716149115

Epoch: 6| Step: 3
Training loss: 2.5283803939819336
Validation loss: 2.6434648395866476

Epoch: 6| Step: 4
Training loss: 3.039142608642578
Validation loss: 2.630067438207647

Epoch: 6| Step: 5
Training loss: 2.894495964050293
Validation loss: 2.621496744053338

Epoch: 6| Step: 6
Training loss: 2.1495931148529053
Validation loss: 2.59048887478408

Epoch: 6| Step: 7
Training loss: 3.9119749069213867
Validation loss: 2.577789383549844

Epoch: 6| Step: 8
Training loss: 2.6049017906188965
Validation loss: 2.5676885343367055

Epoch: 6| Step: 9
Training loss: 2.101614475250244
Validation loss: 2.55063981650978

Epoch: 6| Step: 10
Training loss: 3.007766008377075
Validation loss: 2.530148990692631

Epoch: 6| Step: 11
Training loss: 3.2993850708007812
Validation loss: 2.514037932119062

Epoch: 6| Step: 12
Training loss: 1.7496263980865479
Validation loss: 2.4994649220538396

Epoch: 6| Step: 13
Training loss: 2.168309211730957
Validation loss: 2.473491040609216

Epoch: 17| Step: 0
Training loss: 3.101846694946289
Validation loss: 2.46365535900157

Epoch: 6| Step: 1
Training loss: 3.1456785202026367
Validation loss: 2.43909014168606

Epoch: 6| Step: 2
Training loss: 2.395921230316162
Validation loss: 2.4137929665145053

Epoch: 6| Step: 3
Training loss: 2.7402400970458984
Validation loss: 2.4057306628073416

Epoch: 6| Step: 4
Training loss: 2.7872281074523926
Validation loss: 2.3925294991462462

Epoch: 6| Step: 5
Training loss: 1.5273441076278687
Validation loss: 2.3769242968610538

Epoch: 6| Step: 6
Training loss: 1.950905442237854
Validation loss: 2.3592246732404156

Epoch: 6| Step: 7
Training loss: 3.058767318725586
Validation loss: 2.3509596983591714

Epoch: 6| Step: 8
Training loss: 3.0285849571228027
Validation loss: 2.3370813810697166

Epoch: 6| Step: 9
Training loss: 2.7716808319091797
Validation loss: 2.3205812823387886

Epoch: 6| Step: 10
Training loss: 2.0381217002868652
Validation loss: 2.3151820680146575

Epoch: 6| Step: 11
Training loss: 2.46412992477417
Validation loss: 2.2996389430056334

Epoch: 6| Step: 12
Training loss: 2.0585947036743164
Validation loss: 2.2806583168686076

Epoch: 6| Step: 13
Training loss: 2.39921236038208
Validation loss: 2.2678082655834895

Epoch: 18| Step: 0
Training loss: 2.959512710571289
Validation loss: 2.263693710809113

Epoch: 6| Step: 1
Training loss: 1.7625926733016968
Validation loss: 2.257145635543331

Epoch: 6| Step: 2
Training loss: 2.2515244483947754
Validation loss: 2.2536423616511847

Epoch: 6| Step: 3
Training loss: 2.0423312187194824
Validation loss: 2.2386401930162982

Epoch: 6| Step: 4
Training loss: 2.3152780532836914
Validation loss: 2.2340645508099626

Epoch: 6| Step: 5
Training loss: 2.8542113304138184
Validation loss: 2.2302615822002454

Epoch: 6| Step: 6
Training loss: 2.6699628829956055
Validation loss: 2.2267437647747736

Epoch: 6| Step: 7
Training loss: 2.357175350189209
Validation loss: 2.221533465129073

Epoch: 6| Step: 8
Training loss: 2.6547515392303467
Validation loss: 2.2159476280212402

Epoch: 6| Step: 9
Training loss: 1.9798377752304077
Validation loss: 2.203135874963576

Epoch: 6| Step: 10
Training loss: 2.1168789863586426
Validation loss: 2.20437289309758

Epoch: 6| Step: 11
Training loss: 2.882695198059082
Validation loss: 2.2029769958988314

Epoch: 6| Step: 12
Training loss: 2.9792652130126953
Validation loss: 2.1763689774338917

Epoch: 6| Step: 13
Training loss: 2.319373607635498
Validation loss: 2.1819333543059645

Epoch: 19| Step: 0
Training loss: 3.1541624069213867
Validation loss: 2.1770027452899563

Epoch: 6| Step: 1
Training loss: 1.9872543811798096
Validation loss: 2.1724162537564515

Epoch: 6| Step: 2
Training loss: 2.2434940338134766
Validation loss: 2.1733082789246754

Epoch: 6| Step: 3
Training loss: 1.986994981765747
Validation loss: 2.165511142823004

Epoch: 6| Step: 4
Training loss: 2.0402400493621826
Validation loss: 2.1555436208683956

Epoch: 6| Step: 5
Training loss: 2.134406566619873
Validation loss: 2.1626202291057957

Epoch: 6| Step: 6
Training loss: 2.0876777172088623
Validation loss: 2.1584375289178666

Epoch: 6| Step: 7
Training loss: 2.274442195892334
Validation loss: 2.1422858392038653

Epoch: 6| Step: 8
Training loss: 2.2634127140045166
Validation loss: 2.149434220406317

Epoch: 6| Step: 9
Training loss: 2.4193530082702637
Validation loss: 2.1447103138892882

Epoch: 6| Step: 10
Training loss: 3.494586706161499
Validation loss: 2.13898878969172

Epoch: 6| Step: 11
Training loss: 3.256539821624756
Validation loss: 2.1463367580085673

Epoch: 6| Step: 12
Training loss: 2.3997294902801514
Validation loss: 2.1345007188858522

Epoch: 6| Step: 13
Training loss: 1.6556456089019775
Validation loss: 2.1364310915752123

Epoch: 20| Step: 0
Training loss: 1.7179094552993774
Validation loss: 2.14178708804551

Epoch: 6| Step: 1
Training loss: 2.1523635387420654
Validation loss: 2.141160385583037

Epoch: 6| Step: 2
Training loss: 2.254157543182373
Validation loss: 2.122305393218994

Epoch: 6| Step: 3
Training loss: 2.517508029937744
Validation loss: 2.1296030603429323

Epoch: 6| Step: 4
Training loss: 2.829495429992676
Validation loss: 2.1179515520731607

Epoch: 6| Step: 5
Training loss: 2.0857925415039062
Validation loss: 2.1209164345136253

Epoch: 6| Step: 6
Training loss: 2.5133438110351562
Validation loss: 2.122343078736336

Epoch: 6| Step: 7
Training loss: 2.8245301246643066
Validation loss: 2.1212074474621843

Epoch: 6| Step: 8
Training loss: 2.5974042415618896
Validation loss: 2.110952949011198

Epoch: 6| Step: 9
Training loss: 1.5996266603469849
Validation loss: 2.112157480691069

Epoch: 6| Step: 10
Training loss: 2.891483783721924
Validation loss: 2.125158720119025

Epoch: 6| Step: 11
Training loss: 2.254873514175415
Validation loss: 2.1089879338459303

Epoch: 6| Step: 12
Training loss: 2.4138290882110596
Validation loss: 2.1070369879404702

Epoch: 6| Step: 13
Training loss: 3.1278836727142334
Validation loss: 2.104379456530335

Epoch: 21| Step: 0
Training loss: 2.939152240753174
Validation loss: 2.108934878021158

Epoch: 6| Step: 1
Training loss: 1.666008710861206
Validation loss: 2.1037516299114434

Epoch: 6| Step: 2
Training loss: 2.1181182861328125
Validation loss: 2.0977124475663707

Epoch: 6| Step: 3
Training loss: 1.9786031246185303
Validation loss: 2.1014432676376833

Epoch: 6| Step: 4
Training loss: 2.8115053176879883
Validation loss: 2.107634113680932

Epoch: 6| Step: 5
Training loss: 2.374163866043091
Validation loss: 2.1037865454150784

Epoch: 6| Step: 6
Training loss: 2.5646581649780273
Validation loss: 2.091611211017896

Epoch: 6| Step: 7
Training loss: 1.9028433561325073
Validation loss: 2.1097064351522796

Epoch: 6| Step: 8
Training loss: 2.549863815307617
Validation loss: 2.093814722953304

Epoch: 6| Step: 9
Training loss: 2.1887240409851074
Validation loss: 2.095675658154231

Epoch: 6| Step: 10
Training loss: 2.339235305786133
Validation loss: 2.0888220238429245

Epoch: 6| Step: 11
Training loss: 2.9253485202789307
Validation loss: 2.09632513600011

Epoch: 6| Step: 12
Training loss: 2.330859899520874
Validation loss: 2.1069604876220867

Epoch: 6| Step: 13
Training loss: 2.530297040939331
Validation loss: 2.103275893836893

Epoch: 22| Step: 0
Training loss: 2.267040729522705
Validation loss: 2.101053668606666

Epoch: 6| Step: 1
Training loss: 2.638474941253662
Validation loss: 2.1100955752916235

Epoch: 6| Step: 2
Training loss: 2.57132625579834
Validation loss: 2.0863850475639425

Epoch: 6| Step: 3
Training loss: 2.383970260620117
Validation loss: 2.104893648496238

Epoch: 6| Step: 4
Training loss: 1.9223417043685913
Validation loss: 2.083411289799598

Epoch: 6| Step: 5
Training loss: 1.8535346984863281
Validation loss: 2.1057354263080064

Epoch: 6| Step: 6
Training loss: 2.2710392475128174
Validation loss: 2.0808478529735277

Epoch: 6| Step: 7
Training loss: 2.6773085594177246
Validation loss: 2.0930094078022945

Epoch: 6| Step: 8
Training loss: 2.2902321815490723
Validation loss: 2.0998898936856176

Epoch: 6| Step: 9
Training loss: 2.865218162536621
Validation loss: 2.0880116032015894

Epoch: 6| Step: 10
Training loss: 3.283250331878662
Validation loss: 2.094828805615825

Epoch: 6| Step: 11
Training loss: 2.433614730834961
Validation loss: 2.0859565017043904

Epoch: 6| Step: 12
Training loss: 1.7867690324783325
Validation loss: 2.0872543242669876

Epoch: 6| Step: 13
Training loss: 1.4655801057815552
Validation loss: 2.092208713613531

Epoch: 23| Step: 0
Training loss: 2.82391095161438
Validation loss: 2.0906033541566584

Epoch: 6| Step: 1
Training loss: 1.8765027523040771
Validation loss: 2.0775216933219665

Epoch: 6| Step: 2
Training loss: 1.414893627166748
Validation loss: 2.083050593253105

Epoch: 6| Step: 3
Training loss: 2.429050922393799
Validation loss: 2.0801972163620817

Epoch: 6| Step: 4
Training loss: 2.4240169525146484
Validation loss: 2.084240241717267

Epoch: 6| Step: 5
Training loss: 2.458148717880249
Validation loss: 2.0828468389408563

Epoch: 6| Step: 6
Training loss: 2.7248458862304688
Validation loss: 2.079677184422811

Epoch: 6| Step: 7
Training loss: 2.168532371520996
Validation loss: 2.078016973310901

Epoch: 6| Step: 8
Training loss: 2.613217353820801
Validation loss: 2.082779653610722

Epoch: 6| Step: 9
Training loss: 2.011045455932617
Validation loss: 2.0862413708881666

Epoch: 6| Step: 10
Training loss: 2.3990626335144043
Validation loss: 2.085704485575358

Epoch: 6| Step: 11
Training loss: 2.6146721839904785
Validation loss: 2.082515239715576

Epoch: 6| Step: 12
Training loss: 2.6792492866516113
Validation loss: 2.0856245576694445

Epoch: 6| Step: 13
Training loss: 2.309154748916626
Validation loss: 2.0747748087811213

Epoch: 24| Step: 0
Training loss: 2.4833083152770996
Validation loss: 2.0749386331086517

Epoch: 6| Step: 1
Training loss: 2.2998194694519043
Validation loss: 2.0765959434611823

Epoch: 6| Step: 2
Training loss: 1.8801822662353516
Validation loss: 2.0685231147273893

Epoch: 6| Step: 3
Training loss: 2.262251853942871
Validation loss: 2.0745207007213304

Epoch: 6| Step: 4
Training loss: 2.394458770751953
Validation loss: 2.0780927955463366

Epoch: 6| Step: 5
Training loss: 2.2094967365264893
Validation loss: 2.0998051422898487

Epoch: 6| Step: 6
Training loss: 2.724353313446045
Validation loss: 2.0831477642059326

Epoch: 6| Step: 7
Training loss: 2.1380228996276855
Validation loss: 2.0705505622330533

Epoch: 6| Step: 8
Training loss: 2.2829997539520264
Validation loss: 2.0689307438429965

Epoch: 6| Step: 9
Training loss: 2.1286513805389404
Validation loss: 2.0819080721947456

Epoch: 6| Step: 10
Training loss: 2.628793954849243
Validation loss: 2.0778958553908975

Epoch: 6| Step: 11
Training loss: 2.4712557792663574
Validation loss: 2.0800151286586637

Epoch: 6| Step: 12
Training loss: 2.064969301223755
Validation loss: 2.0843079333664267

Epoch: 6| Step: 13
Training loss: 3.2722065448760986
Validation loss: 2.093589528914421

Epoch: 25| Step: 0
Training loss: 2.859165668487549
Validation loss: 2.083263742026462

Epoch: 6| Step: 1
Training loss: 2.165447235107422
Validation loss: 2.066240559342087

Epoch: 6| Step: 2
Training loss: 2.647773504257202
Validation loss: 2.078280507877309

Epoch: 6| Step: 3
Training loss: 1.9099924564361572
Validation loss: 2.0931912827235397

Epoch: 6| Step: 4
Training loss: 2.9144461154937744
Validation loss: 2.079931859047182

Epoch: 6| Step: 5
Training loss: 2.2290773391723633
Validation loss: 2.0744993891767276

Epoch: 6| Step: 6
Training loss: 1.9806592464447021
Validation loss: 2.08429983610748

Epoch: 6| Step: 7
Training loss: 3.096677780151367
Validation loss: 2.064662471894295

Epoch: 6| Step: 8
Training loss: 1.9950023889541626
Validation loss: 2.069360597159273

Epoch: 6| Step: 9
Training loss: 1.7816321849822998
Validation loss: 2.0836929967326503

Epoch: 6| Step: 10
Training loss: 1.9868241548538208
Validation loss: 2.0751733933725665

Epoch: 6| Step: 11
Training loss: 2.196922540664673
Validation loss: 2.074744780858358

Epoch: 6| Step: 12
Training loss: 2.3087425231933594
Validation loss: 2.087944940854144

Epoch: 6| Step: 13
Training loss: 2.9737637042999268
Validation loss: 2.0833699985217025

Epoch: 26| Step: 0
Training loss: 2.2696056365966797
Validation loss: 2.092778592981318

Epoch: 6| Step: 1
Training loss: 1.9965033531188965
Validation loss: 2.070222859741539

Epoch: 6| Step: 2
Training loss: 2.882812261581421
Validation loss: 2.0823893905967794

Epoch: 6| Step: 3
Training loss: 2.545215606689453
Validation loss: 2.0726516836433

Epoch: 6| Step: 4
Training loss: 1.8804434537887573
Validation loss: 2.0860821559864986

Epoch: 6| Step: 5
Training loss: 3.430311441421509
Validation loss: 2.0935861346542195

Epoch: 6| Step: 6
Training loss: 2.03904390335083
Validation loss: 2.0889697279981387

Epoch: 6| Step: 7
Training loss: 2.4404006004333496
Validation loss: 2.077232499276438

Epoch: 6| Step: 8
Training loss: 2.035628318786621
Validation loss: 2.0906277215608986

Epoch: 6| Step: 9
Training loss: 1.6297448873519897
Validation loss: 2.09362611462993

Epoch: 6| Step: 10
Training loss: 2.321554660797119
Validation loss: 2.09155664777243

Epoch: 6| Step: 11
Training loss: 2.46620512008667
Validation loss: 2.0873470511487735

Epoch: 6| Step: 12
Training loss: 2.9112801551818848
Validation loss: 2.086372326779109

Epoch: 6| Step: 13
Training loss: 1.2640843391418457
Validation loss: 2.0871671117762083

Epoch: 27| Step: 0
Training loss: 2.1193103790283203
Validation loss: 2.0854657529502787

Epoch: 6| Step: 1
Training loss: 2.171534538269043
Validation loss: 2.085769009846513

Epoch: 6| Step: 2
Training loss: 2.5034689903259277
Validation loss: 2.1003928697237404

Epoch: 6| Step: 3
Training loss: 1.891087293624878
Validation loss: 2.086161639100762

Epoch: 6| Step: 4
Training loss: 2.584531545639038
Validation loss: 2.085880180840851

Epoch: 6| Step: 5
Training loss: 2.3753480911254883
Validation loss: 2.074666056581723

Epoch: 6| Step: 6
Training loss: 2.5137786865234375
Validation loss: 2.07804597321377

Epoch: 6| Step: 7
Training loss: 2.7776780128479004
Validation loss: 2.07595722393323

Epoch: 6| Step: 8
Training loss: 2.419464349746704
Validation loss: 2.105162655153582

Epoch: 6| Step: 9
Training loss: 1.7877815961837769
Validation loss: 2.081636198105351

Epoch: 6| Step: 10
Training loss: 2.5514676570892334
Validation loss: 2.0821071901629047

Epoch: 6| Step: 11
Training loss: 2.6984376907348633
Validation loss: 2.0816485702350573

Epoch: 6| Step: 12
Training loss: 1.8055191040039062
Validation loss: 2.0824249867470033

Epoch: 6| Step: 13
Training loss: 2.273080825805664
Validation loss: 2.0919355218128493

Epoch: 28| Step: 0
Training loss: 2.8345067501068115
Validation loss: 2.0926285482222036

Epoch: 6| Step: 1
Training loss: 1.9726265668869019
Validation loss: 2.0696786808711227

Epoch: 6| Step: 2
Training loss: 2.3506627082824707
Validation loss: 2.0825270119533745

Epoch: 6| Step: 3
Training loss: 2.8706650733947754
Validation loss: 2.0631076623034734

Epoch: 6| Step: 4
Training loss: 2.266214609146118
Validation loss: 2.0863675186710973

Epoch: 6| Step: 5
Training loss: 2.3751049041748047
Validation loss: 2.0768210041907524

Epoch: 6| Step: 6
Training loss: 2.3974785804748535
Validation loss: 2.0800144800575833

Epoch: 6| Step: 7
Training loss: 1.5589632987976074
Validation loss: 2.0709412700386456

Epoch: 6| Step: 8
Training loss: 2.306713581085205
Validation loss: 2.0697953444655224

Epoch: 6| Step: 9
Training loss: 2.0861411094665527
Validation loss: 2.0788240150738786

Epoch: 6| Step: 10
Training loss: 2.488898992538452
Validation loss: 2.0784614368151595

Epoch: 6| Step: 11
Training loss: 2.759767770767212
Validation loss: 2.077131176507601

Epoch: 6| Step: 12
Training loss: 2.278568744659424
Validation loss: 2.0841014308314167

Epoch: 6| Step: 13
Training loss: 1.6351567506790161
Validation loss: 2.076656177479734

Epoch: 29| Step: 0
Training loss: 3.232239246368408
Validation loss: 2.071715147264542

Epoch: 6| Step: 1
Training loss: 1.833008050918579
Validation loss: 2.0904858727608957

Epoch: 6| Step: 2
Training loss: 2.3395209312438965
Validation loss: 2.09843506351594

Epoch: 6| Step: 3
Training loss: 3.4578707218170166
Validation loss: 2.0808833927236576

Epoch: 6| Step: 4
Training loss: 2.1947031021118164
Validation loss: 2.076268644743068

Epoch: 6| Step: 5
Training loss: 2.5461621284484863
Validation loss: 2.069868540251127

Epoch: 6| Step: 6
Training loss: 2.480848789215088
Validation loss: 2.07101656160047

Epoch: 6| Step: 7
Training loss: 2.1687264442443848
Validation loss: 2.084211673787845

Epoch: 6| Step: 8
Training loss: 2.6498429775238037
Validation loss: 2.084892967695831

Epoch: 6| Step: 9
Training loss: 1.931369662284851
Validation loss: 2.0840295027661067

Epoch: 6| Step: 10
Training loss: 1.9244037866592407
Validation loss: 2.0864129681741037

Epoch: 6| Step: 11
Training loss: 2.5248961448669434
Validation loss: 2.084373926603666

Epoch: 6| Step: 12
Training loss: 1.5095343589782715
Validation loss: 2.0707834330938195

Epoch: 6| Step: 13
Training loss: 1.3638746738433838
Validation loss: 2.075049505438856

Epoch: 30| Step: 0
Training loss: 2.19252872467041
Validation loss: 2.089102925792817

Epoch: 6| Step: 1
Training loss: 2.2008769512176514
Validation loss: 2.103622478823508

Epoch: 6| Step: 2
Training loss: 2.675835609436035
Validation loss: 2.0797441608162335

Epoch: 6| Step: 3
Training loss: 1.864241361618042
Validation loss: 2.0801910200426654

Epoch: 6| Step: 4
Training loss: 2.3496851921081543
Validation loss: 2.0815475410030735

Epoch: 6| Step: 5
Training loss: 2.8719770908355713
Validation loss: 2.0932235230681715

Epoch: 6| Step: 6
Training loss: 2.2679805755615234
Validation loss: 2.0770039032864314

Epoch: 6| Step: 7
Training loss: 2.5839016437530518
Validation loss: 2.0902924665840725

Epoch: 6| Step: 8
Training loss: 2.6380414962768555
Validation loss: 2.0717421744459417

Epoch: 6| Step: 9
Training loss: 1.5724718570709229
Validation loss: 2.085658939935828

Epoch: 6| Step: 10
Training loss: 2.345581531524658
Validation loss: 2.085830634640109

Epoch: 6| Step: 11
Training loss: 2.634535312652588
Validation loss: 2.077962777947867

Epoch: 6| Step: 12
Training loss: 1.8262739181518555
Validation loss: 2.0845445176606536

Epoch: 6| Step: 13
Training loss: 2.399399757385254
Validation loss: 2.076949345168247

Epoch: 31| Step: 0
Training loss: 2.2668917179107666
Validation loss: 2.0715036828030824

Epoch: 6| Step: 1
Training loss: 2.863485813140869
Validation loss: 2.067517865088678

Epoch: 6| Step: 2
Training loss: 2.0192158222198486
Validation loss: 2.0742460476454867

Epoch: 6| Step: 3
Training loss: 2.6159491539001465
Validation loss: 2.0655141056224866

Epoch: 6| Step: 4
Training loss: 1.7020773887634277
Validation loss: 2.0787410056719215

Epoch: 6| Step: 5
Training loss: 2.4387717247009277
Validation loss: 2.076768298302927

Epoch: 6| Step: 6
Training loss: 2.096425771713257
Validation loss: 2.071476908140285

Epoch: 6| Step: 7
Training loss: 2.7509212493896484
Validation loss: 2.0791008062260126

Epoch: 6| Step: 8
Training loss: 2.0460987091064453
Validation loss: 2.0792445149472965

Epoch: 6| Step: 9
Training loss: 2.633223295211792
Validation loss: 2.0802705954479914

Epoch: 6| Step: 10
Training loss: 2.0844311714172363
Validation loss: 2.07649819056193

Epoch: 6| Step: 11
Training loss: 2.3673596382141113
Validation loss: 2.0684110169769614

Epoch: 6| Step: 12
Training loss: 2.471452474594116
Validation loss: 2.083619499719271

Epoch: 6| Step: 13
Training loss: 1.6516450643539429
Validation loss: 2.078691869653681

Epoch: 32| Step: 0
Training loss: 2.870305061340332
Validation loss: 2.088534487191067

Epoch: 6| Step: 1
Training loss: 1.9146250486373901
Validation loss: 2.082820459078717

Epoch: 6| Step: 2
Training loss: 2.2094595432281494
Validation loss: 2.0732306536807807

Epoch: 6| Step: 3
Training loss: 3.1824612617492676
Validation loss: 2.0729537138374905

Epoch: 6| Step: 4
Training loss: 2.1350021362304688
Validation loss: 2.086904192483553

Epoch: 6| Step: 5
Training loss: 2.590078353881836
Validation loss: 2.0860145502193

Epoch: 6| Step: 6
Training loss: 2.5118298530578613
Validation loss: 2.0662734354695966

Epoch: 6| Step: 7
Training loss: 2.3482871055603027
Validation loss: 2.0786969738621868

Epoch: 6| Step: 8
Training loss: 2.7040722370147705
Validation loss: 2.0903593109500025

Epoch: 6| Step: 9
Training loss: 2.039135456085205
Validation loss: 2.082668262143289

Epoch: 6| Step: 10
Training loss: 1.4331268072128296
Validation loss: 2.0728362990963842

Epoch: 6| Step: 11
Training loss: 2.350930690765381
Validation loss: 2.0706990175349738

Epoch: 6| Step: 12
Training loss: 1.7367548942565918
Validation loss: 2.0825616352019773

Epoch: 6| Step: 13
Training loss: 2.3968827724456787
Validation loss: 2.091407632315031

Epoch: 33| Step: 0
Training loss: 2.8769102096557617
Validation loss: 2.078259160441737

Epoch: 6| Step: 1
Training loss: 1.3151257038116455
Validation loss: 2.081246127364456

Epoch: 6| Step: 2
Training loss: 1.950648307800293
Validation loss: 2.0809356371561685

Epoch: 6| Step: 3
Training loss: 2.1009652614593506
Validation loss: 2.090703272050427

Epoch: 6| Step: 4
Training loss: 1.7541272640228271
Validation loss: 2.098451074733529

Epoch: 6| Step: 5
Training loss: 2.038513422012329
Validation loss: 2.0884296535163798

Epoch: 6| Step: 6
Training loss: 1.5141645669937134
Validation loss: 2.080336273357432

Epoch: 6| Step: 7
Training loss: 2.633859395980835
Validation loss: 2.093017492243039

Epoch: 6| Step: 8
Training loss: 2.081096649169922
Validation loss: 2.0829102634101786

Epoch: 6| Step: 9
Training loss: 3.0057501792907715
Validation loss: 2.090820457345696

Epoch: 6| Step: 10
Training loss: 2.6324405670166016
Validation loss: 2.0785859887317946

Epoch: 6| Step: 11
Training loss: 2.273618459701538
Validation loss: 2.091319195685848

Epoch: 6| Step: 12
Training loss: 3.317758083343506
Validation loss: 2.0708871644030333

Epoch: 6| Step: 13
Training loss: 2.6199426651000977
Validation loss: 2.098148339538164

Epoch: 34| Step: 0
Training loss: 2.48331618309021
Validation loss: 2.0961420792405323

Epoch: 6| Step: 1
Training loss: 2.3901777267456055
Validation loss: 2.0753242687512468

Epoch: 6| Step: 2
Training loss: 2.762248992919922
Validation loss: 2.0761765562078005

Epoch: 6| Step: 3
Training loss: 3.033745765686035
Validation loss: 2.078118112779433

Epoch: 6| Step: 4
Training loss: 1.9467872381210327
Validation loss: 2.063112869057604

Epoch: 6| Step: 5
Training loss: 2.150557518005371
Validation loss: 2.0780163888008363

Epoch: 6| Step: 6
Training loss: 2.4750397205352783
Validation loss: 2.08017651496395

Epoch: 6| Step: 7
Training loss: 2.5329065322875977
Validation loss: 2.0737204474787556

Epoch: 6| Step: 8
Training loss: 1.655595064163208
Validation loss: 2.083698791842307

Epoch: 6| Step: 9
Training loss: 2.1127688884735107
Validation loss: 2.0681860088020243

Epoch: 6| Step: 10
Training loss: 2.1539840698242188
Validation loss: 2.073536129407985

Epoch: 6| Step: 11
Training loss: 1.9929190874099731
Validation loss: 2.0788214796332904

Epoch: 6| Step: 12
Training loss: 2.278756856918335
Validation loss: 2.074336049377277

Epoch: 6| Step: 13
Training loss: 2.1638331413269043
Validation loss: 2.0733353745552803

Epoch: 35| Step: 0
Training loss: 2.1613659858703613
Validation loss: 2.0818210135224047

Epoch: 6| Step: 1
Training loss: 1.9536385536193848
Validation loss: 2.0754791049547094

Epoch: 6| Step: 2
Training loss: 2.417386054992676
Validation loss: 2.0707573121593845

Epoch: 6| Step: 3
Training loss: 2.2258336544036865
Validation loss: 2.0772744788918445

Epoch: 6| Step: 4
Training loss: 2.417875289916992
Validation loss: 2.0817563456873738

Epoch: 6| Step: 5
Training loss: 2.75235652923584
Validation loss: 2.0789973120535574

Epoch: 6| Step: 6
Training loss: 1.8075425624847412
Validation loss: 2.0819847224861063

Epoch: 6| Step: 7
Training loss: 2.313544750213623
Validation loss: 2.066151269020573

Epoch: 6| Step: 8
Training loss: 1.8966774940490723
Validation loss: 2.0801219299275386

Epoch: 6| Step: 9
Training loss: 2.4034318923950195
Validation loss: 2.0811766616759764

Epoch: 6| Step: 10
Training loss: 2.69472336769104
Validation loss: 2.0625629322503203

Epoch: 6| Step: 11
Training loss: 2.1253669261932373
Validation loss: 2.0569537096126105

Epoch: 6| Step: 12
Training loss: 2.7629566192626953
Validation loss: 2.0739006919245564

Epoch: 6| Step: 13
Training loss: 1.9981850385665894
Validation loss: 2.0737536825159544

Epoch: 36| Step: 0
Training loss: 1.4241992235183716
Validation loss: 2.081890716347643

Epoch: 6| Step: 1
Training loss: 2.4006831645965576
Validation loss: 2.0820969394458237

Epoch: 6| Step: 2
Training loss: 2.3638651371002197
Validation loss: 2.0804710157455935

Epoch: 6| Step: 3
Training loss: 2.9441559314727783
Validation loss: 2.071991378261197

Epoch: 6| Step: 4
Training loss: 2.4365859031677246
Validation loss: 2.070656881537489

Epoch: 6| Step: 5
Training loss: 2.2837934494018555
Validation loss: 2.0714091921365387

Epoch: 6| Step: 6
Training loss: 1.9407172203063965
Validation loss: 2.0845686569008777

Epoch: 6| Step: 7
Training loss: 1.8044465780258179
Validation loss: 2.0943652276069886

Epoch: 6| Step: 8
Training loss: 2.3229312896728516
Validation loss: 2.083055801289056

Epoch: 6| Step: 9
Training loss: 1.6435688734054565
Validation loss: 2.063799258201353

Epoch: 6| Step: 10
Training loss: 2.0848920345306396
Validation loss: 2.0723829615500664

Epoch: 6| Step: 11
Training loss: 2.7733967304229736
Validation loss: 2.0785495324801375

Epoch: 6| Step: 12
Training loss: 3.1312952041625977
Validation loss: 2.0779819385979765

Epoch: 6| Step: 13
Training loss: 2.7119510173797607
Validation loss: 2.0860733575718378

Epoch: 37| Step: 0
Training loss: 2.0459065437316895
Validation loss: 2.068502800438994

Epoch: 6| Step: 1
Training loss: 2.7772507667541504
Validation loss: 2.077080642023394

Epoch: 6| Step: 2
Training loss: 2.432344913482666
Validation loss: 2.0855469267855407

Epoch: 6| Step: 3
Training loss: 2.1523051261901855
Validation loss: 2.0816203599335044

Epoch: 6| Step: 4
Training loss: 2.441118001937866
Validation loss: 2.0923427356186735

Epoch: 6| Step: 5
Training loss: 2.512049913406372
Validation loss: 2.0900159574324086

Epoch: 6| Step: 6
Training loss: 2.7437868118286133
Validation loss: 2.0850088801435245

Epoch: 6| Step: 7
Training loss: 1.2969722747802734
Validation loss: 2.093876382356049

Epoch: 6| Step: 8
Training loss: 2.233764171600342
Validation loss: 2.091991529669813

Epoch: 6| Step: 9
Training loss: 2.5297443866729736
Validation loss: 2.090800472485122

Epoch: 6| Step: 10
Training loss: 2.4490368366241455
Validation loss: 2.0842784425263763

Epoch: 6| Step: 11
Training loss: 2.3153064250946045
Validation loss: 2.0910819717632827

Epoch: 6| Step: 12
Training loss: 1.6374938488006592
Validation loss: 2.094230080163607

Epoch: 6| Step: 13
Training loss: 2.4330012798309326
Validation loss: 2.084002105138635

Epoch: 38| Step: 0
Training loss: 2.236672878265381
Validation loss: 2.0809051682872157

Epoch: 6| Step: 1
Training loss: 2.9448916912078857
Validation loss: 2.0771964032162904

Epoch: 6| Step: 2
Training loss: 2.5132861137390137
Validation loss: 2.082593902464836

Epoch: 6| Step: 3
Training loss: 1.6515486240386963
Validation loss: 2.0822323855533393

Epoch: 6| Step: 4
Training loss: 2.6539626121520996
Validation loss: 2.076593570811774

Epoch: 6| Step: 5
Training loss: 2.121227264404297
Validation loss: 2.086555092565475

Epoch: 6| Step: 6
Training loss: 1.734539270401001
Validation loss: 2.092881361643473

Epoch: 6| Step: 7
Training loss: 2.4558265209198
Validation loss: 2.0943268383702924

Epoch: 6| Step: 8
Training loss: 1.992443561553955
Validation loss: 2.0760068393522695

Epoch: 6| Step: 9
Training loss: 2.644474744796753
Validation loss: 2.0970270774697743

Epoch: 6| Step: 10
Training loss: 2.582153797149658
Validation loss: 2.0695346734857045

Epoch: 6| Step: 11
Training loss: 3.0126943588256836
Validation loss: 2.092627320238339

Epoch: 6| Step: 12
Training loss: 1.7598235607147217
Validation loss: 2.0957381558674637

Epoch: 6| Step: 13
Training loss: 1.0890834331512451
Validation loss: 2.0867900950934297

Epoch: 39| Step: 0
Training loss: 1.4007384777069092
Validation loss: 2.0759372544545

Epoch: 6| Step: 1
Training loss: 2.1116888523101807
Validation loss: 2.093988385251773

Epoch: 6| Step: 2
Training loss: 2.2715888023376465
Validation loss: 2.0716753941710278

Epoch: 6| Step: 3
Training loss: 2.1030871868133545
Validation loss: 2.089762887647075

Epoch: 6| Step: 4
Training loss: 2.7156777381896973
Validation loss: 2.069500743701894

Epoch: 6| Step: 5
Training loss: 2.7257471084594727
Validation loss: 2.078783958188949

Epoch: 6| Step: 6
Training loss: 2.9395151138305664
Validation loss: 2.0730331854153703

Epoch: 6| Step: 7
Training loss: 2.4503417015075684
Validation loss: 2.0729527896450413

Epoch: 6| Step: 8
Training loss: 1.7958766222000122
Validation loss: 2.083521294337447

Epoch: 6| Step: 9
Training loss: 2.7473702430725098
Validation loss: 2.0734327095811085

Epoch: 6| Step: 10
Training loss: 2.4353549480438232
Validation loss: 2.0617441874678417

Epoch: 6| Step: 11
Training loss: 1.7571319341659546
Validation loss: 2.087233579286965

Epoch: 6| Step: 12
Training loss: 1.9441308975219727
Validation loss: 2.0635111716485794

Epoch: 6| Step: 13
Training loss: 2.7148749828338623
Validation loss: 2.073900353523993

Epoch: 40| Step: 0
Training loss: 2.521303415298462
Validation loss: 2.0678670611432803

Epoch: 6| Step: 1
Training loss: 2.207926034927368
Validation loss: 2.0709054854608353

Epoch: 6| Step: 2
Training loss: 2.907909870147705
Validation loss: 2.085925663671186

Epoch: 6| Step: 3
Training loss: 1.9319974184036255
Validation loss: 2.0704287918665076

Epoch: 6| Step: 4
Training loss: 2.073560953140259
Validation loss: 2.063226002518849

Epoch: 6| Step: 5
Training loss: 2.280543804168701
Validation loss: 2.0783811576904787

Epoch: 6| Step: 6
Training loss: 2.43772554397583
Validation loss: 2.075443349858766

Epoch: 6| Step: 7
Training loss: 2.5195858478546143
Validation loss: 2.0935837222683813

Epoch: 6| Step: 8
Training loss: 1.4946478605270386
Validation loss: 2.0768764890650266

Epoch: 6| Step: 9
Training loss: 2.769670248031616
Validation loss: 2.0880247803144556

Epoch: 6| Step: 10
Training loss: 1.979784369468689
Validation loss: 2.0734739008770195

Epoch: 6| Step: 11
Training loss: 2.3719382286071777
Validation loss: 2.0734346835843978

Epoch: 6| Step: 12
Training loss: 2.4952521324157715
Validation loss: 2.081123403323594

Epoch: 6| Step: 13
Training loss: 1.5989117622375488
Validation loss: 2.081932403708017

Epoch: 41| Step: 0
Training loss: 1.8069987297058105
Validation loss: 2.1018931699055496

Epoch: 6| Step: 1
Training loss: 2.2718629837036133
Validation loss: 2.07199905508308

Epoch: 6| Step: 2
Training loss: 2.7781105041503906
Validation loss: 2.073422223009089

Epoch: 6| Step: 3
Training loss: 2.651024580001831
Validation loss: 2.0900432678960983

Epoch: 6| Step: 4
Training loss: 1.861746072769165
Validation loss: 2.0891589964589765

Epoch: 6| Step: 5
Training loss: 2.2772741317749023
Validation loss: 2.081706690531905

Epoch: 6| Step: 6
Training loss: 2.6580686569213867
Validation loss: 2.0780982971191406

Epoch: 6| Step: 7
Training loss: 1.9805796146392822
Validation loss: 2.085594184937016

Epoch: 6| Step: 8
Training loss: 2.197948694229126
Validation loss: 2.0872812091663318

Epoch: 6| Step: 9
Training loss: 2.3625648021698
Validation loss: 2.0930825202695784

Epoch: 6| Step: 10
Training loss: 2.2492055892944336
Validation loss: 2.102266134754304

Epoch: 6| Step: 11
Training loss: 2.502556562423706
Validation loss: 2.092695577170259

Epoch: 6| Step: 12
Training loss: 1.929793357849121
Validation loss: 2.0973559823087466

Epoch: 6| Step: 13
Training loss: 2.4470818042755127
Validation loss: 2.078054961337838

Epoch: 42| Step: 0
Training loss: 2.1029977798461914
Validation loss: 2.089515721926125

Epoch: 6| Step: 1
Training loss: 1.6850001811981201
Validation loss: 2.090039150689238

Epoch: 6| Step: 2
Training loss: 3.3161282539367676
Validation loss: 2.0848664775971444

Epoch: 6| Step: 3
Training loss: 2.0906729698181152
Validation loss: 2.084360691808885

Epoch: 6| Step: 4
Training loss: 2.0089662075042725
Validation loss: 2.0844150563722015

Epoch: 6| Step: 5
Training loss: 2.1550064086914062
Validation loss: 2.079901547842128

Epoch: 6| Step: 6
Training loss: 2.1156680583953857
Validation loss: 2.0867629563936623

Epoch: 6| Step: 7
Training loss: 1.9043047428131104
Validation loss: 2.0724308849662862

Epoch: 6| Step: 8
Training loss: 2.7192540168762207
Validation loss: 2.0732193531528598

Epoch: 6| Step: 9
Training loss: 2.3631396293640137
Validation loss: 2.0853395077490036

Epoch: 6| Step: 10
Training loss: 2.077707290649414
Validation loss: 2.0721385376427763

Epoch: 6| Step: 11
Training loss: 3.032196044921875
Validation loss: 2.069028967170305

Epoch: 6| Step: 12
Training loss: 2.0502395629882812
Validation loss: 2.0826383970117055

Epoch: 6| Step: 13
Training loss: 2.1862170696258545
Validation loss: 2.0719454557664934

Epoch: 43| Step: 0
Training loss: 2.544562339782715
Validation loss: 2.086030831900976

Epoch: 6| Step: 1
Training loss: 2.226970672607422
Validation loss: 2.0751051466952086

Epoch: 6| Step: 2
Training loss: 2.465207099914551
Validation loss: 2.0767720591637397

Epoch: 6| Step: 3
Training loss: 2.013554096221924
Validation loss: 2.0825997860200944

Epoch: 6| Step: 4
Training loss: 1.2671372890472412
Validation loss: 2.094525155200753

Epoch: 6| Step: 5
Training loss: 2.5817973613739014
Validation loss: 2.0785815792699016

Epoch: 6| Step: 6
Training loss: 2.7686760425567627
Validation loss: 2.0685838807013726

Epoch: 6| Step: 7
Training loss: 2.7938919067382812
Validation loss: 2.0940376943157566

Epoch: 6| Step: 8
Training loss: 2.4291458129882812
Validation loss: 2.0818677948367212

Epoch: 6| Step: 9
Training loss: 2.1825122833251953
Validation loss: 2.0731443948643182

Epoch: 6| Step: 10
Training loss: 1.9674289226531982
Validation loss: 2.0687183949255172

Epoch: 6| Step: 11
Training loss: 2.1314196586608887
Validation loss: 2.072331054236299

Epoch: 6| Step: 12
Training loss: 1.7002841234207153
Validation loss: 2.088182380122523

Epoch: 6| Step: 13
Training loss: 3.0354185104370117
Validation loss: 2.0837363555867183

Epoch: 44| Step: 0
Training loss: 1.5598896741867065
Validation loss: 2.068560577207996

Epoch: 6| Step: 1
Training loss: 1.6928260326385498
Validation loss: 2.0909004672881095

Epoch: 6| Step: 2
Training loss: 1.9797950983047485
Validation loss: 2.065926577455254

Epoch: 6| Step: 3
Training loss: 1.9928162097930908
Validation loss: 2.0817316757735385

Epoch: 6| Step: 4
Training loss: 2.986845016479492
Validation loss: 2.07927672068278

Epoch: 6| Step: 5
Training loss: 1.8001974821090698
Validation loss: 2.0868202768346316

Epoch: 6| Step: 6
Training loss: 2.694443941116333
Validation loss: 2.0717053580027756

Epoch: 6| Step: 7
Training loss: 2.6680145263671875
Validation loss: 2.0721507687722482

Epoch: 6| Step: 8
Training loss: 3.0831189155578613
Validation loss: 2.0742630292010564

Epoch: 6| Step: 9
Training loss: 2.4576148986816406
Validation loss: 2.064509327693652

Epoch: 6| Step: 10
Training loss: 2.3277385234832764
Validation loss: 2.0940984141442085

Epoch: 6| Step: 11
Training loss: 2.2241716384887695
Validation loss: 2.0733578102563017

Epoch: 6| Step: 12
Training loss: 2.0995919704437256
Validation loss: 2.071919712969052

Epoch: 6| Step: 13
Training loss: 2.1534321308135986
Validation loss: 2.076672887289396

Epoch: 45| Step: 0
Training loss: 1.8526138067245483
Validation loss: 2.084193680876045

Epoch: 6| Step: 1
Training loss: 2.441000461578369
Validation loss: 2.0783762342186383

Epoch: 6| Step: 2
Training loss: 2.8525869846343994
Validation loss: 2.0807323109719063

Epoch: 6| Step: 3
Training loss: 2.79347562789917
Validation loss: 2.088765928822179

Epoch: 6| Step: 4
Training loss: 1.6295417547225952
Validation loss: 2.077650039426742

Epoch: 6| Step: 5
Training loss: 1.654846429824829
Validation loss: 2.0782140813848025

Epoch: 6| Step: 6
Training loss: 2.6677207946777344
Validation loss: 2.0761324000614945

Epoch: 6| Step: 7
Training loss: 2.281714916229248
Validation loss: 2.081965124735268

Epoch: 6| Step: 8
Training loss: 2.102827787399292
Validation loss: 2.091704060954432

Epoch: 6| Step: 9
Training loss: 1.7257851362228394
Validation loss: 2.071046019113192

Epoch: 6| Step: 10
Training loss: 1.8883392810821533
Validation loss: 2.088008319177935

Epoch: 6| Step: 11
Training loss: 3.0633583068847656
Validation loss: 2.1022046612155054

Epoch: 6| Step: 12
Training loss: 2.512166738510132
Validation loss: 2.075551256056755

Epoch: 6| Step: 13
Training loss: 2.265288829803467
Validation loss: 2.0749614161829792

Epoch: 46| Step: 0
Training loss: 2.9753870964050293
Validation loss: 2.097567932580107

Epoch: 6| Step: 1
Training loss: 2.197599411010742
Validation loss: 2.0911244820523005

Epoch: 6| Step: 2
Training loss: 2.5666017532348633
Validation loss: 2.0757600261319067

Epoch: 6| Step: 3
Training loss: 1.6378309726715088
Validation loss: 2.1062106393998667

Epoch: 6| Step: 4
Training loss: 1.6545466184616089
Validation loss: 2.092244748146303

Epoch: 6| Step: 5
Training loss: 2.299705982208252
Validation loss: 2.0876817011064097

Epoch: 6| Step: 6
Training loss: 2.6150693893432617
Validation loss: 2.082657103897423

Epoch: 6| Step: 7
Training loss: 2.2733778953552246
Validation loss: 2.083099954871721

Epoch: 6| Step: 8
Training loss: 2.2343690395355225
Validation loss: 2.070329189300537

Epoch: 6| Step: 9
Training loss: 2.2026968002319336
Validation loss: 2.085731819111814

Epoch: 6| Step: 10
Training loss: 2.15911865234375
Validation loss: 2.0844295255599485

Epoch: 6| Step: 11
Training loss: 1.9781980514526367
Validation loss: 2.069649568168066

Epoch: 6| Step: 12
Training loss: 2.379913806915283
Validation loss: 2.10407914141173

Epoch: 6| Step: 13
Training loss: 2.5239226818084717
Validation loss: 2.0871430058633127

Epoch: 47| Step: 0
Training loss: 2.5137782096862793
Validation loss: 2.080006367416792

Epoch: 6| Step: 1
Training loss: 1.6584197282791138
Validation loss: 2.0864677095925934

Epoch: 6| Step: 2
Training loss: 1.6442707777023315
Validation loss: 2.070331750377532

Epoch: 6| Step: 3
Training loss: 1.74072265625
Validation loss: 2.065804801961427

Epoch: 6| Step: 4
Training loss: 2.2147068977355957
Validation loss: 2.074249759797127

Epoch: 6| Step: 5
Training loss: 2.5264899730682373
Validation loss: 2.0786842018045406

Epoch: 6| Step: 6
Training loss: 2.499333143234253
Validation loss: 2.0813543027447117

Epoch: 6| Step: 7
Training loss: 2.2566981315612793
Validation loss: 2.0862834222855104

Epoch: 6| Step: 8
Training loss: 2.4826712608337402
Validation loss: 2.072515603034727

Epoch: 6| Step: 9
Training loss: 2.9101955890655518
Validation loss: 2.076525716371434

Epoch: 6| Step: 10
Training loss: 2.3705620765686035
Validation loss: 2.081535941811018

Epoch: 6| Step: 11
Training loss: 2.205796718597412
Validation loss: 2.0719405758765435

Epoch: 6| Step: 12
Training loss: 2.265815258026123
Validation loss: 2.0876173691083024

Epoch: 6| Step: 13
Training loss: 2.272077798843384
Validation loss: 2.0845501756155365

Epoch: 48| Step: 0
Training loss: 1.1143856048583984
Validation loss: 2.0893446745411044

Epoch: 6| Step: 1
Training loss: 2.4063804149627686
Validation loss: 2.0834567111025573

Epoch: 6| Step: 2
Training loss: 1.8913501501083374
Validation loss: 2.084590176100372

Epoch: 6| Step: 3
Training loss: 1.6616365909576416
Validation loss: 2.0906925598780313

Epoch: 6| Step: 4
Training loss: 3.4394214153289795
Validation loss: 2.0751052466771935

Epoch: 6| Step: 5
Training loss: 1.7926726341247559
Validation loss: 2.0858462549025014

Epoch: 6| Step: 6
Training loss: 2.303889751434326
Validation loss: 2.087959276732578

Epoch: 6| Step: 7
Training loss: 2.4655909538269043
Validation loss: 2.0941840705051216

Epoch: 6| Step: 8
Training loss: 2.049229621887207
Validation loss: 2.0646757092527164

Epoch: 6| Step: 9
Training loss: 2.400416851043701
Validation loss: 2.086630149554181

Epoch: 6| Step: 10
Training loss: 2.040327548980713
Validation loss: 2.083894850105368

Epoch: 6| Step: 11
Training loss: 3.165027618408203
Validation loss: 2.065408368264475

Epoch: 6| Step: 12
Training loss: 2.1382884979248047
Validation loss: 2.0818060726247807

Epoch: 6| Step: 13
Training loss: 3.04910945892334
Validation loss: 2.073773081584643

Epoch: 49| Step: 0
Training loss: 2.308701992034912
Validation loss: 2.071031270488616

Epoch: 6| Step: 1
Training loss: 1.8536978960037231
Validation loss: 2.0810535594981205

Epoch: 6| Step: 2
Training loss: 1.6338595151901245
Validation loss: 2.0915648155314948

Epoch: 6| Step: 3
Training loss: 2.377943277359009
Validation loss: 2.0867872109977146

Epoch: 6| Step: 4
Training loss: 2.6179513931274414
Validation loss: 2.0767769403355096

Epoch: 6| Step: 5
Training loss: 1.620369553565979
Validation loss: 2.092303063279839

Epoch: 6| Step: 6
Training loss: 3.0161097049713135
Validation loss: 2.094892919704478

Epoch: 6| Step: 7
Training loss: 2.0919318199157715
Validation loss: 2.087938177970148

Epoch: 6| Step: 8
Training loss: 2.3337695598602295
Validation loss: 2.0928484932068856

Epoch: 6| Step: 9
Training loss: 2.631073474884033
Validation loss: 2.0877273057096746

Epoch: 6| Step: 10
Training loss: 2.70668363571167
Validation loss: 2.0967464241930234

Epoch: 6| Step: 11
Training loss: 2.2180495262145996
Validation loss: 2.0760368262567828

Epoch: 6| Step: 12
Training loss: 1.8436150550842285
Validation loss: 2.096708031110866

Epoch: 6| Step: 13
Training loss: 2.384233236312866
Validation loss: 2.083127857536398

Epoch: 50| Step: 0
Training loss: 1.6636415719985962
Validation loss: 2.086992577839923

Epoch: 6| Step: 1
Training loss: 2.283700466156006
Validation loss: 2.076570269882038

Epoch: 6| Step: 2
Training loss: 2.995051383972168
Validation loss: 2.099017193240504

Epoch: 6| Step: 3
Training loss: 2.4125289916992188
Validation loss: 2.067540082880246

Epoch: 6| Step: 4
Training loss: 2.2084038257598877
Validation loss: 2.08230023999368

Epoch: 6| Step: 5
Training loss: 1.837977647781372
Validation loss: 2.095624631451022

Epoch: 6| Step: 6
Training loss: 2.620441198348999
Validation loss: 2.084079010512239

Epoch: 6| Step: 7
Training loss: 1.8935551643371582
Validation loss: 2.085347362743911

Epoch: 6| Step: 8
Training loss: 2.2856154441833496
Validation loss: 2.071200388734059

Epoch: 6| Step: 9
Training loss: 1.9984862804412842
Validation loss: 2.093396471392724

Epoch: 6| Step: 10
Training loss: 2.046556234359741
Validation loss: 2.082511514745733

Epoch: 6| Step: 11
Training loss: 2.5195279121398926
Validation loss: 2.0844181212045814

Epoch: 6| Step: 12
Training loss: 2.34427547454834
Validation loss: 2.07792111942845

Epoch: 6| Step: 13
Training loss: 2.3896617889404297
Validation loss: 2.077552274991107

Epoch: 51| Step: 0
Training loss: 1.8980348110198975
Validation loss: 2.076796180458479

Epoch: 6| Step: 1
Training loss: 2.626535415649414
Validation loss: 2.066037001148347

Epoch: 6| Step: 2
Training loss: 1.5679707527160645
Validation loss: 2.1015182028534594

Epoch: 6| Step: 3
Training loss: 2.386305332183838
Validation loss: 2.0897960893569456

Epoch: 6| Step: 4
Training loss: 2.8930881023406982
Validation loss: 2.0812738505742883

Epoch: 6| Step: 5
Training loss: 2.772653818130493
Validation loss: 2.0950717182569605

Epoch: 6| Step: 6
Training loss: 2.2613017559051514
Validation loss: 2.080098062433222

Epoch: 6| Step: 7
Training loss: 2.291280508041382
Validation loss: 2.094784072650376

Epoch: 6| Step: 8
Training loss: 2.0090644359588623
Validation loss: 2.0736164328872517

Epoch: 6| Step: 9
Training loss: 2.535468339920044
Validation loss: 2.080493824456328

Epoch: 6| Step: 10
Training loss: 1.9730134010314941
Validation loss: 2.101630659513576

Epoch: 6| Step: 11
Training loss: 2.0901453495025635
Validation loss: 2.083341593383461

Epoch: 6| Step: 12
Training loss: 1.9667901992797852
Validation loss: 2.0789779258030716

Epoch: 6| Step: 13
Training loss: 2.238025665283203
Validation loss: 2.074067061947238

Epoch: 52| Step: 0
Training loss: 2.2172553539276123
Validation loss: 2.0957375341846096

Epoch: 6| Step: 1
Training loss: 2.0610599517822266
Validation loss: 2.079022381895332

Epoch: 6| Step: 2
Training loss: 2.6563172340393066
Validation loss: 2.0733741560289936

Epoch: 6| Step: 3
Training loss: 2.3051443099975586
Validation loss: 2.0801737693048294

Epoch: 6| Step: 4
Training loss: 2.3146514892578125
Validation loss: 2.08121988081163

Epoch: 6| Step: 5
Training loss: 2.6148900985717773
Validation loss: 2.0843046070427023

Epoch: 6| Step: 6
Training loss: 1.569563627243042
Validation loss: 2.107765149044734

Epoch: 6| Step: 7
Training loss: 1.8001973628997803
Validation loss: 2.0855117638905845

Epoch: 6| Step: 8
Training loss: 1.3730530738830566
Validation loss: 2.0816965538968324

Epoch: 6| Step: 9
Training loss: 2.270232677459717
Validation loss: 2.094292640686035

Epoch: 6| Step: 10
Training loss: 2.6326346397399902
Validation loss: 2.0961147700586626

Epoch: 6| Step: 11
Training loss: 1.9558264017105103
Validation loss: 2.0789831889572965

Epoch: 6| Step: 12
Training loss: 3.1086573600769043
Validation loss: 2.092224423603345

Epoch: 6| Step: 13
Training loss: 3.0039587020874023
Validation loss: 2.0820847839437504

Epoch: 53| Step: 0
Training loss: 2.056671142578125
Validation loss: 2.0984701700108026

Epoch: 6| Step: 1
Training loss: 1.8435777425765991
Validation loss: 2.1135699197810185

Epoch: 6| Step: 2
Training loss: 1.937329649925232
Validation loss: 2.0905999778419413

Epoch: 6| Step: 3
Training loss: 1.834061622619629
Validation loss: 2.0987063633498324

Epoch: 6| Step: 4
Training loss: 1.8392062187194824
Validation loss: 2.0972934563954673

Epoch: 6| Step: 5
Training loss: 1.9866610765457153
Validation loss: 2.09660945400115

Epoch: 6| Step: 6
Training loss: 2.0359368324279785
Validation loss: 2.09459856248671

Epoch: 6| Step: 7
Training loss: 2.6610281467437744
Validation loss: 2.0826323250288605

Epoch: 6| Step: 8
Training loss: 2.548130989074707
Validation loss: 2.1124222560595443

Epoch: 6| Step: 9
Training loss: 2.979998826980591
Validation loss: 2.0841601407656105

Epoch: 6| Step: 10
Training loss: 2.7907800674438477
Validation loss: 2.0914724680685226

Epoch: 6| Step: 11
Training loss: 2.2661945819854736
Validation loss: 2.0720457620518182

Epoch: 6| Step: 12
Training loss: 2.0311522483825684
Validation loss: 2.098634276338803

Epoch: 6| Step: 13
Training loss: 3.014158010482788
Validation loss: 2.0993048426925496

Epoch: 54| Step: 0
Training loss: 2.208963394165039
Validation loss: 2.0880578051331224

Epoch: 6| Step: 1
Training loss: 2.32997989654541
Validation loss: 2.0852353290844987

Epoch: 6| Step: 2
Training loss: 2.0436666011810303
Validation loss: 2.0889768600463867

Epoch: 6| Step: 3
Training loss: 2.086336374282837
Validation loss: 2.0860428707574004

Epoch: 6| Step: 4
Training loss: 1.382188320159912
Validation loss: 2.0850297122873287

Epoch: 6| Step: 5
Training loss: 2.3024649620056152
Validation loss: 2.0878958471359743

Epoch: 6| Step: 6
Training loss: 2.371382474899292
Validation loss: 2.0910573928586897

Epoch: 6| Step: 7
Training loss: 2.2760050296783447
Validation loss: 2.083268052788191

Epoch: 6| Step: 8
Training loss: 2.5225133895874023
Validation loss: 2.093363238919166

Epoch: 6| Step: 9
Training loss: 2.3860089778900146
Validation loss: 2.0777035887523363

Epoch: 6| Step: 10
Training loss: 1.7921574115753174
Validation loss: 2.0944557830851567

Epoch: 6| Step: 11
Training loss: 2.4526147842407227
Validation loss: 2.08329015649775

Epoch: 6| Step: 12
Training loss: 2.3008933067321777
Validation loss: 2.075663092315838

Epoch: 6| Step: 13
Training loss: 3.4692373275756836
Validation loss: 2.0628331874006536

Epoch: 55| Step: 0
Training loss: 1.9102429151535034
Validation loss: 2.084468128860638

Epoch: 6| Step: 1
Training loss: 1.924469232559204
Validation loss: 2.0924250823195263

Epoch: 6| Step: 2
Training loss: 1.9782065153121948
Validation loss: 2.0820890088235178

Epoch: 6| Step: 3
Training loss: 2.2789061069488525
Validation loss: 2.0864111351710495

Epoch: 6| Step: 4
Training loss: 2.4837353229522705
Validation loss: 2.073695954456124

Epoch: 6| Step: 5
Training loss: 2.5422544479370117
Validation loss: 2.087747358506726

Epoch: 6| Step: 6
Training loss: 1.691417932510376
Validation loss: 2.1170815139688473

Epoch: 6| Step: 7
Training loss: 2.1408605575561523
Validation loss: 2.086743562452255

Epoch: 6| Step: 8
Training loss: 2.5078444480895996
Validation loss: 2.097921020241194

Epoch: 6| Step: 9
Training loss: 1.811694860458374
Validation loss: 2.076610876667884

Epoch: 6| Step: 10
Training loss: 2.5324840545654297
Validation loss: 2.082133421333887

Epoch: 6| Step: 11
Training loss: 2.061521530151367
Validation loss: 2.097848261556318

Epoch: 6| Step: 12
Training loss: 3.045431137084961
Validation loss: 2.101205207968271

Epoch: 6| Step: 13
Training loss: 2.59879994392395
Validation loss: 2.089588454974595

Epoch: 56| Step: 0
Training loss: 2.068183183670044
Validation loss: 2.080172606693801

Epoch: 6| Step: 1
Training loss: 2.34222412109375
Validation loss: 2.0841517461243497

Epoch: 6| Step: 2
Training loss: 2.4014534950256348
Validation loss: 2.093687972714824

Epoch: 6| Step: 3
Training loss: 2.4498069286346436
Validation loss: 2.0774435509917555

Epoch: 6| Step: 4
Training loss: 2.7226791381835938
Validation loss: 2.1024293027898318

Epoch: 6| Step: 5
Training loss: 1.9612188339233398
Validation loss: 2.0958008791810725

Epoch: 6| Step: 6
Training loss: 2.637354612350464
Validation loss: 2.098052801624421

Epoch: 6| Step: 7
Training loss: 1.9442222118377686
Validation loss: 2.094990675167371

Epoch: 6| Step: 8
Training loss: 2.3747260570526123
Validation loss: 2.091312421265469

Epoch: 6| Step: 9
Training loss: 1.830641508102417
Validation loss: 2.0831965220871793

Epoch: 6| Step: 10
Training loss: 2.930440902709961
Validation loss: 2.0846512830385597

Epoch: 6| Step: 11
Training loss: 1.5732274055480957
Validation loss: 2.0794104952966013

Epoch: 6| Step: 12
Training loss: 1.6935815811157227
Validation loss: 2.0944446286847516

Epoch: 6| Step: 13
Training loss: 2.5756077766418457
Validation loss: 2.073588473822481

Epoch: 57| Step: 0
Training loss: 2.0760293006896973
Validation loss: 2.0890469063994703

Epoch: 6| Step: 1
Training loss: 1.858830213546753
Validation loss: 2.0839686291192168

Epoch: 6| Step: 2
Training loss: 1.9568181037902832
Validation loss: 2.0859551711749007

Epoch: 6| Step: 3
Training loss: 2.2885806560516357
Validation loss: 2.075947993545122

Epoch: 6| Step: 4
Training loss: 2.241450786590576
Validation loss: 2.0899831812868834

Epoch: 6| Step: 5
Training loss: 1.8693822622299194
Validation loss: 2.0845725946528937

Epoch: 6| Step: 6
Training loss: 1.7421221733093262
Validation loss: 2.0925740606041363

Epoch: 6| Step: 7
Training loss: 2.94767689704895
Validation loss: 2.1006367283482708

Epoch: 6| Step: 8
Training loss: 2.531752586364746
Validation loss: 2.1119083230213453

Epoch: 6| Step: 9
Training loss: 2.5103445053100586
Validation loss: 2.0990657216759137

Epoch: 6| Step: 10
Training loss: 1.4448292255401611
Validation loss: 2.0825980478717434

Epoch: 6| Step: 11
Training loss: 2.733774423599243
Validation loss: 2.0874961114698842

Epoch: 6| Step: 12
Training loss: 2.534271478652954
Validation loss: 2.089202360440326

Epoch: 6| Step: 13
Training loss: 2.673858642578125
Validation loss: 2.0953074629588793

Epoch: 58| Step: 0
Training loss: 2.0401105880737305
Validation loss: 2.086975848802956

Epoch: 6| Step: 1
Training loss: 1.9453552961349487
Validation loss: 2.1003027987736527

Epoch: 6| Step: 2
Training loss: 1.797994613647461
Validation loss: 2.0851948645807084

Epoch: 6| Step: 3
Training loss: 2.0573697090148926
Validation loss: 2.087485603106919

Epoch: 6| Step: 4
Training loss: 2.724055051803589
Validation loss: 2.0995109388905187

Epoch: 6| Step: 5
Training loss: 2.5585007667541504
Validation loss: 2.093785032149284

Epoch: 6| Step: 6
Training loss: 2.3226194381713867
Validation loss: 2.09549295004978

Epoch: 6| Step: 7
Training loss: 2.4331703186035156
Validation loss: 2.110118583966327

Epoch: 6| Step: 8
Training loss: 2.5916810035705566
Validation loss: 2.0992614171838246

Epoch: 6| Step: 9
Training loss: 1.8684002161026
Validation loss: 2.103040927199907

Epoch: 6| Step: 10
Training loss: 2.296481132507324
Validation loss: 2.100662713409752

Epoch: 6| Step: 11
Training loss: 2.115520715713501
Validation loss: 2.0916665574555755

Epoch: 6| Step: 12
Training loss: 2.161165237426758
Validation loss: 2.096726873869537

Epoch: 6| Step: 13
Training loss: 2.623152494430542
Validation loss: 2.095204658405755

Epoch: 59| Step: 0
Training loss: 2.4937987327575684
Validation loss: 2.079650660996796

Epoch: 6| Step: 1
Training loss: 2.384877920150757
Validation loss: 2.0911980982749694

Epoch: 6| Step: 2
Training loss: 2.215336799621582
Validation loss: 2.0848140319188437

Epoch: 6| Step: 3
Training loss: 2.225959062576294
Validation loss: 2.088283592654813

Epoch: 6| Step: 4
Training loss: 2.384331703186035
Validation loss: 2.095196718810707

Epoch: 6| Step: 5
Training loss: 2.2844605445861816
Validation loss: 2.0943184386017504

Epoch: 6| Step: 6
Training loss: 1.7577711343765259
Validation loss: 2.099539892647856

Epoch: 6| Step: 7
Training loss: 2.2424216270446777
Validation loss: 2.104315109150384

Epoch: 6| Step: 8
Training loss: 2.140481472015381
Validation loss: 2.1121523508461575

Epoch: 6| Step: 9
Training loss: 1.8106706142425537
Validation loss: 2.0766232141884426

Epoch: 6| Step: 10
Training loss: 2.7942910194396973
Validation loss: 2.1033754515391525

Epoch: 6| Step: 11
Training loss: 1.4195849895477295
Validation loss: 2.0972339645508797

Epoch: 6| Step: 12
Training loss: 2.503791570663452
Validation loss: 2.092985233952922

Epoch: 6| Step: 13
Training loss: 2.7097911834716797
Validation loss: 2.103327535813855

Epoch: 60| Step: 0
Training loss: 2.1847214698791504
Validation loss: 2.0960917870203652

Epoch: 6| Step: 1
Training loss: 1.4317045211791992
Validation loss: 2.1201397808649207

Epoch: 6| Step: 2
Training loss: 2.3762893676757812
Validation loss: 2.0918160856411023

Epoch: 6| Step: 3
Training loss: 2.209836721420288
Validation loss: 2.096133908917827

Epoch: 6| Step: 4
Training loss: 1.4439547061920166
Validation loss: 2.0983059188371063

Epoch: 6| Step: 5
Training loss: 3.1490721702575684
Validation loss: 2.090951044072387

Epoch: 6| Step: 6
Training loss: 2.3690147399902344
Validation loss: 2.095888924855058

Epoch: 6| Step: 7
Training loss: 2.3221311569213867
Validation loss: 2.086853160653063

Epoch: 6| Step: 8
Training loss: 1.9103083610534668
Validation loss: 2.095382764775266

Epoch: 6| Step: 9
Training loss: 2.3642942905426025
Validation loss: 2.0948671346069663

Epoch: 6| Step: 10
Training loss: 2.3330953121185303
Validation loss: 2.1006410198826946

Epoch: 6| Step: 11
Training loss: 2.555727005004883
Validation loss: 2.088468687508696

Epoch: 6| Step: 12
Training loss: 1.9033513069152832
Validation loss: 2.0896160589751376

Epoch: 6| Step: 13
Training loss: 2.961148262023926
Validation loss: 2.098978486112369

Epoch: 61| Step: 0
Training loss: 2.2497880458831787
Validation loss: 2.090600998170914

Epoch: 6| Step: 1
Training loss: 2.1261191368103027
Validation loss: 2.1016800506140596

Epoch: 6| Step: 2
Training loss: 2.0034353733062744
Validation loss: 2.082669655481974

Epoch: 6| Step: 3
Training loss: 2.0888242721557617
Validation loss: 2.0974405927042805

Epoch: 6| Step: 4
Training loss: 2.7973196506500244
Validation loss: 2.100482661236999

Epoch: 6| Step: 5
Training loss: 2.2342801094055176
Validation loss: 2.0944330846109698

Epoch: 6| Step: 6
Training loss: 2.8288376331329346
Validation loss: 2.0954847387088242

Epoch: 6| Step: 7
Training loss: 1.7966301441192627
Validation loss: 2.0914506117502847

Epoch: 6| Step: 8
Training loss: 3.2065939903259277
Validation loss: 2.0978012341325

Epoch: 6| Step: 9
Training loss: 1.864521861076355
Validation loss: 2.0749170754545476

Epoch: 6| Step: 10
Training loss: 2.0463762283325195
Validation loss: 2.098217718062862

Epoch: 6| Step: 11
Training loss: 2.2288715839385986
Validation loss: 2.0878162435306016

Epoch: 6| Step: 12
Training loss: 1.4575352668762207
Validation loss: 2.0952157012877928

Epoch: 6| Step: 13
Training loss: 2.131646156311035
Validation loss: 2.1026618557591594

Epoch: 62| Step: 0
Training loss: 2.1835994720458984
Validation loss: 2.1088089276385564

Epoch: 6| Step: 1
Training loss: 2.4384636878967285
Validation loss: 2.1093132688153173

Epoch: 6| Step: 2
Training loss: 1.6878994703292847
Validation loss: 2.108272824236142

Epoch: 6| Step: 3
Training loss: 2.2130308151245117
Validation loss: 2.1160732546160297

Epoch: 6| Step: 4
Training loss: 1.905146598815918
Validation loss: 2.1017463489245345

Epoch: 6| Step: 5
Training loss: 2.393205404281616
Validation loss: 2.096109902986916

Epoch: 6| Step: 6
Training loss: 2.1170473098754883
Validation loss: 2.103298987111738

Epoch: 6| Step: 7
Training loss: 2.0084524154663086
Validation loss: 2.098795149915962

Epoch: 6| Step: 8
Training loss: 1.7224831581115723
Validation loss: 2.107874519081526

Epoch: 6| Step: 9
Training loss: 2.4312357902526855
Validation loss: 2.0890240207795174

Epoch: 6| Step: 10
Training loss: 2.0873355865478516
Validation loss: 2.095831955632856

Epoch: 6| Step: 11
Training loss: 2.02583384513855
Validation loss: 2.0940487525796376

Epoch: 6| Step: 12
Training loss: 3.0451855659484863
Validation loss: 2.0997304506199335

Epoch: 6| Step: 13
Training loss: 3.372596263885498
Validation loss: 2.0954716167142315

Epoch: 63| Step: 0
Training loss: 2.0136618614196777
Validation loss: 2.0855579145493044

Epoch: 6| Step: 1
Training loss: 2.2302567958831787
Validation loss: 2.0918133720274894

Epoch: 6| Step: 2
Training loss: 1.9112744331359863
Validation loss: 2.108730331543953

Epoch: 6| Step: 3
Training loss: 1.6465312242507935
Validation loss: 2.0858545418708556

Epoch: 6| Step: 4
Training loss: 2.638659954071045
Validation loss: 2.085308982479957

Epoch: 6| Step: 5
Training loss: 2.1739675998687744
Validation loss: 2.096906808114821

Epoch: 6| Step: 6
Training loss: 2.1406335830688477
Validation loss: 2.0817604577669533

Epoch: 6| Step: 7
Training loss: 1.9493331909179688
Validation loss: 2.0768166588198755

Epoch: 6| Step: 8
Training loss: 1.7508529424667358
Validation loss: 2.0922232520195747

Epoch: 6| Step: 9
Training loss: 2.1720223426818848
Validation loss: 2.0810986218913907

Epoch: 6| Step: 10
Training loss: 2.383615016937256
Validation loss: 2.0870063202355498

Epoch: 6| Step: 11
Training loss: 2.7790393829345703
Validation loss: 2.0873341380908923

Epoch: 6| Step: 12
Training loss: 3.10941743850708
Validation loss: 2.082143654105484

Epoch: 6| Step: 13
Training loss: 2.412682056427002
Validation loss: 2.098789366342688

Epoch: 64| Step: 0
Training loss: 2.419264316558838
Validation loss: 2.1183644930521646

Epoch: 6| Step: 1
Training loss: 1.9841101169586182
Validation loss: 2.109974738090269

Epoch: 6| Step: 2
Training loss: 2.3308613300323486
Validation loss: 2.094534993171692

Epoch: 6| Step: 3
Training loss: 2.8661279678344727
Validation loss: 2.0737650984077045

Epoch: 6| Step: 4
Training loss: 3.0496654510498047
Validation loss: 2.090245549396802

Epoch: 6| Step: 5
Training loss: 2.1340177059173584
Validation loss: 2.0938746377985966

Epoch: 6| Step: 6
Training loss: 1.8085823059082031
Validation loss: 2.08362937870846

Epoch: 6| Step: 7
Training loss: 2.1211190223693848
Validation loss: 2.091127639175743

Epoch: 6| Step: 8
Training loss: 1.7638938426971436
Validation loss: 2.1060296386800785

Epoch: 6| Step: 9
Training loss: 2.4952683448791504
Validation loss: 2.092946570406678

Epoch: 6| Step: 10
Training loss: 2.172429323196411
Validation loss: 2.0833767332056516

Epoch: 6| Step: 11
Training loss: 2.1030807495117188
Validation loss: 2.098756126178208

Epoch: 6| Step: 12
Training loss: 2.016500473022461
Validation loss: 2.092793539006223

Epoch: 6| Step: 13
Training loss: 1.7309672832489014
Validation loss: 2.106104076549571

Epoch: 65| Step: 0
Training loss: 1.7510199546813965
Validation loss: 2.0919206296243975

Epoch: 6| Step: 1
Training loss: 2.866790533065796
Validation loss: 2.0928261844060754

Epoch: 6| Step: 2
Training loss: 2.9248671531677246
Validation loss: 2.072411734570739

Epoch: 6| Step: 3
Training loss: 2.256704568862915
Validation loss: 2.0923485935375257

Epoch: 6| Step: 4
Training loss: 2.012272357940674
Validation loss: 2.08982587886113

Epoch: 6| Step: 5
Training loss: 2.2777507305145264
Validation loss: 2.0931443206725584

Epoch: 6| Step: 6
Training loss: 2.385847568511963
Validation loss: 2.083888569185811

Epoch: 6| Step: 7
Training loss: 2.052504777908325
Validation loss: 2.102011575493761

Epoch: 6| Step: 8
Training loss: 2.06176495552063
Validation loss: 2.0918959853469685

Epoch: 6| Step: 9
Training loss: 2.3974666595458984
Validation loss: 2.114391152576734

Epoch: 6| Step: 10
Training loss: 2.1058459281921387
Validation loss: 2.0879870076333322

Epoch: 6| Step: 11
Training loss: 1.542517066001892
Validation loss: 2.093513681042579

Epoch: 6| Step: 12
Training loss: 2.410893201828003
Validation loss: 2.078531034531132

Epoch: 6| Step: 13
Training loss: 2.155280113220215
Validation loss: 2.093689904418043

Epoch: 66| Step: 0
Training loss: 2.3105711936950684
Validation loss: 2.0923184015417613

Epoch: 6| Step: 1
Training loss: 1.7750732898712158
Validation loss: 2.076341700810258

Epoch: 6| Step: 2
Training loss: 2.5534684658050537
Validation loss: 2.0867861406777495

Epoch: 6| Step: 3
Training loss: 2.282174587249756
Validation loss: 2.062192737415273

Epoch: 6| Step: 4
Training loss: 2.176356554031372
Validation loss: 2.0850233006220993

Epoch: 6| Step: 5
Training loss: 2.6575117111206055
Validation loss: 2.084603432686098

Epoch: 6| Step: 6
Training loss: 1.836923599243164
Validation loss: 2.0856990788572576

Epoch: 6| Step: 7
Training loss: 2.176490545272827
Validation loss: 2.0820502811862576

Epoch: 6| Step: 8
Training loss: 2.312084913253784
Validation loss: 2.067099778882919

Epoch: 6| Step: 9
Training loss: 2.543029308319092
Validation loss: 2.071739914596722

Epoch: 6| Step: 10
Training loss: 1.8871119022369385
Validation loss: 2.0828968299332487

Epoch: 6| Step: 11
Training loss: 1.9614590406417847
Validation loss: 2.0908477870366906

Epoch: 6| Step: 12
Training loss: 2.4717156887054443
Validation loss: 2.093013346836131

Epoch: 6| Step: 13
Training loss: 1.7645567655563354
Validation loss: 2.0928355032397854

Epoch: 67| Step: 0
Training loss: 1.6243088245391846
Validation loss: 2.0865823017653597

Epoch: 6| Step: 1
Training loss: 2.141317844390869
Validation loss: 2.093171901600335

Epoch: 6| Step: 2
Training loss: 2.490607738494873
Validation loss: 2.0928501672642206

Epoch: 6| Step: 3
Training loss: 2.402008056640625
Validation loss: 2.0877479378895094

Epoch: 6| Step: 4
Training loss: 2.5490469932556152
Validation loss: 2.0903964863028577

Epoch: 6| Step: 5
Training loss: 2.355595111846924
Validation loss: 2.0943964527499292

Epoch: 6| Step: 6
Training loss: 1.911808967590332
Validation loss: 2.0856678267960906

Epoch: 6| Step: 7
Training loss: 2.696913242340088
Validation loss: 2.086492576906758

Epoch: 6| Step: 8
Training loss: 2.045189619064331
Validation loss: 2.0880165253916094

Epoch: 6| Step: 9
Training loss: 2.1772332191467285
Validation loss: 2.0869385337316864

Epoch: 6| Step: 10
Training loss: 2.0510852336883545
Validation loss: 2.100137859262446

Epoch: 6| Step: 11
Training loss: 1.8567174673080444
Validation loss: 2.0933602317687003

Epoch: 6| Step: 12
Training loss: 1.974250316619873
Validation loss: 2.0900191209649526

Epoch: 6| Step: 13
Training loss: 3.1924796104431152
Validation loss: 2.0909929916422856

Epoch: 68| Step: 0
Training loss: 2.2037644386291504
Validation loss: 2.102238126980361

Epoch: 6| Step: 1
Training loss: 1.6740113496780396
Validation loss: 2.091578680981872

Epoch: 6| Step: 2
Training loss: 2.5229244232177734
Validation loss: 2.086598184800917

Epoch: 6| Step: 3
Training loss: 1.5906504392623901
Validation loss: 2.089625476509012

Epoch: 6| Step: 4
Training loss: 2.536705493927002
Validation loss: 2.0949256291953464

Epoch: 6| Step: 5
Training loss: 2.230137825012207
Validation loss: 2.092768117945681

Epoch: 6| Step: 6
Training loss: 2.467910051345825
Validation loss: 2.0945420585652834

Epoch: 6| Step: 7
Training loss: 2.4309349060058594
Validation loss: 2.1087214510927916

Epoch: 6| Step: 8
Training loss: 2.0596022605895996
Validation loss: 2.095316983038379

Epoch: 6| Step: 9
Training loss: 2.086569309234619
Validation loss: 2.0805841671523226

Epoch: 6| Step: 10
Training loss: 2.4123916625976562
Validation loss: 2.0920033826622912

Epoch: 6| Step: 11
Training loss: 2.0795035362243652
Validation loss: 2.0955277360895628

Epoch: 6| Step: 12
Training loss: 2.7031450271606445
Validation loss: 2.0920404977695917

Epoch: 6| Step: 13
Training loss: 2.141221046447754
Validation loss: 2.110648392349161

Epoch: 69| Step: 0
Training loss: 2.387634754180908
Validation loss: 2.083079563674106

Epoch: 6| Step: 1
Training loss: 1.916286826133728
Validation loss: 2.0966437696128764

Epoch: 6| Step: 2
Training loss: 2.8904004096984863
Validation loss: 2.088595128828479

Epoch: 6| Step: 3
Training loss: 2.373483657836914
Validation loss: 2.1076965819122973

Epoch: 6| Step: 4
Training loss: 3.0201051235198975
Validation loss: 2.0970255200580885

Epoch: 6| Step: 5
Training loss: 1.8649579286575317
Validation loss: 2.087155916357553

Epoch: 6| Step: 6
Training loss: 2.042306900024414
Validation loss: 2.101879405718978

Epoch: 6| Step: 7
Training loss: 2.8682031631469727
Validation loss: 2.1055535731777066

Epoch: 6| Step: 8
Training loss: 2.055762767791748
Validation loss: 2.0934485696977183

Epoch: 6| Step: 9
Training loss: 1.8740689754486084
Validation loss: 2.099818624475951

Epoch: 6| Step: 10
Training loss: 1.5830734968185425
Validation loss: 2.097143914109917

Epoch: 6| Step: 11
Training loss: 2.2859697341918945
Validation loss: 2.1038287980582124

Epoch: 6| Step: 12
Training loss: 1.4858434200286865
Validation loss: 2.1039032269549627

Epoch: 6| Step: 13
Training loss: 2.4695749282836914
Validation loss: 2.109259178561549

Epoch: 70| Step: 0
Training loss: 1.7046403884887695
Validation loss: 2.0838103832737094

Epoch: 6| Step: 1
Training loss: 2.7415263652801514
Validation loss: 2.102395107669215

Epoch: 6| Step: 2
Training loss: 2.1060638427734375
Validation loss: 2.0994107095144128

Epoch: 6| Step: 3
Training loss: 2.0081517696380615
Validation loss: 2.0975819890217116

Epoch: 6| Step: 4
Training loss: 2.080611228942871
Validation loss: 2.1067615888452016

Epoch: 6| Step: 5
Training loss: 2.2833056449890137
Validation loss: 2.0923514827605216

Epoch: 6| Step: 6
Training loss: 1.5602004528045654
Validation loss: 2.10064624714595

Epoch: 6| Step: 7
Training loss: 2.9361228942871094
Validation loss: 2.0978399758697837

Epoch: 6| Step: 8
Training loss: 1.9236191511154175
Validation loss: 2.0880564592217885

Epoch: 6| Step: 9
Training loss: 1.8249534368515015
Validation loss: 2.092514238049907

Epoch: 6| Step: 10
Training loss: 2.575249195098877
Validation loss: 2.0972780899334977

Epoch: 6| Step: 11
Training loss: 2.543219804763794
Validation loss: 2.1094335843158025

Epoch: 6| Step: 12
Training loss: 2.2998993396759033
Validation loss: 2.114590496145269

Epoch: 6| Step: 13
Training loss: 2.3464162349700928
Validation loss: 2.1066000269305323

Epoch: 71| Step: 0
Training loss: 2.144728660583496
Validation loss: 2.094371582872124

Epoch: 6| Step: 1
Training loss: 1.7404816150665283
Validation loss: 2.0892957384868334

Epoch: 6| Step: 2
Training loss: 2.1444923877716064
Validation loss: 2.099339680005145

Epoch: 6| Step: 3
Training loss: 2.729444980621338
Validation loss: 2.0815018402632846

Epoch: 6| Step: 4
Training loss: 1.8632783889770508
Validation loss: 2.091389500966636

Epoch: 6| Step: 5
Training loss: 2.208162307739258
Validation loss: 2.1019727363381335

Epoch: 6| Step: 6
Training loss: 2.46504807472229
Validation loss: 2.1009374459584556

Epoch: 6| Step: 7
Training loss: 2.525655746459961
Validation loss: 2.1022109472623436

Epoch: 6| Step: 8
Training loss: 3.021979808807373
Validation loss: 2.105392017672139

Epoch: 6| Step: 9
Training loss: 2.3957815170288086
Validation loss: 2.0831124333925146

Epoch: 6| Step: 10
Training loss: 2.0077531337738037
Validation loss: 2.083333456388084

Epoch: 6| Step: 11
Training loss: 1.9310837984085083
Validation loss: 2.101557316318635

Epoch: 6| Step: 12
Training loss: 1.8529107570648193
Validation loss: 2.105205355152007

Epoch: 6| Step: 13
Training loss: 1.9056816101074219
Validation loss: 2.106006424914124

Epoch: 72| Step: 0
Training loss: 2.516897201538086
Validation loss: 2.07804395562859

Epoch: 6| Step: 1
Training loss: 2.892483711242676
Validation loss: 2.107683632963447

Epoch: 6| Step: 2
Training loss: 2.1865034103393555
Validation loss: 2.099270925726942

Epoch: 6| Step: 3
Training loss: 2.0061728954315186
Validation loss: 2.084601051063948

Epoch: 6| Step: 4
Training loss: 2.0908288955688477
Validation loss: 2.0887268820116596

Epoch: 6| Step: 5
Training loss: 2.069735288619995
Validation loss: 2.093477295291039

Epoch: 6| Step: 6
Training loss: 2.0718350410461426
Validation loss: 2.091266926898751

Epoch: 6| Step: 7
Training loss: 2.074984073638916
Validation loss: 2.0913628737131753

Epoch: 6| Step: 8
Training loss: 2.1740670204162598
Validation loss: 2.0841764147563646

Epoch: 6| Step: 9
Training loss: 2.3460533618927
Validation loss: 2.0931538574157225

Epoch: 6| Step: 10
Training loss: 1.6449575424194336
Validation loss: 2.0864848308665778

Epoch: 6| Step: 11
Training loss: 2.073148250579834
Validation loss: 2.0971786745132937

Epoch: 6| Step: 12
Training loss: 2.5256900787353516
Validation loss: 2.089740632682718

Epoch: 6| Step: 13
Training loss: 2.5373191833496094
Validation loss: 2.0832225481669107

Epoch: 73| Step: 0
Training loss: 2.557530164718628
Validation loss: 2.0874003825649137

Epoch: 6| Step: 1
Training loss: 2.4062819480895996
Validation loss: 2.073271289948494

Epoch: 6| Step: 2
Training loss: 2.113673210144043
Validation loss: 2.100412038064772

Epoch: 6| Step: 3
Training loss: 2.7020158767700195
Validation loss: 2.083390356391989

Epoch: 6| Step: 4
Training loss: 2.0421371459960938
Validation loss: 2.0995833091838385

Epoch: 6| Step: 5
Training loss: 1.7987141609191895
Validation loss: 2.092491816448909

Epoch: 6| Step: 6
Training loss: 2.508321523666382
Validation loss: 2.08431980686803

Epoch: 6| Step: 7
Training loss: 2.067058801651001
Validation loss: 2.1028284283094507

Epoch: 6| Step: 8
Training loss: 1.7479835748672485
Validation loss: 2.0933826020968858

Epoch: 6| Step: 9
Training loss: 2.085041046142578
Validation loss: 2.0956459442774453

Epoch: 6| Step: 10
Training loss: 2.629884719848633
Validation loss: 2.1018328243686306

Epoch: 6| Step: 11
Training loss: 1.9614511728286743
Validation loss: 2.097517095586305

Epoch: 6| Step: 12
Training loss: 2.0500574111938477
Validation loss: 2.080285500454646

Epoch: 6| Step: 13
Training loss: 2.3069331645965576
Validation loss: 2.0989018845301803

Epoch: 74| Step: 0
Training loss: 2.142913579940796
Validation loss: 2.0848928010591896

Epoch: 6| Step: 1
Training loss: 2.362496852874756
Validation loss: 2.099430248301516

Epoch: 6| Step: 2
Training loss: 2.7525877952575684
Validation loss: 2.097681990233801

Epoch: 6| Step: 3
Training loss: 0.9950637817382812
Validation loss: 2.1150119843021518

Epoch: 6| Step: 4
Training loss: 2.0519444942474365
Validation loss: 2.108994041719744

Epoch: 6| Step: 5
Training loss: 1.8385567665100098
Validation loss: 2.1021939041793987

Epoch: 6| Step: 6
Training loss: 3.172311782836914
Validation loss: 2.102119538091844

Epoch: 6| Step: 7
Training loss: 2.0774502754211426
Validation loss: 2.0969037971188946

Epoch: 6| Step: 8
Training loss: 1.784442663192749
Validation loss: 2.1110704470706243

Epoch: 6| Step: 9
Training loss: 1.8676557540893555
Validation loss: 2.1188083105189826

Epoch: 6| Step: 10
Training loss: 2.2950689792633057
Validation loss: 2.1005221900119575

Epoch: 6| Step: 11
Training loss: 2.4088940620422363
Validation loss: 2.1058122137541413

Epoch: 6| Step: 12
Training loss: 2.17582368850708
Validation loss: 2.0981041334008657

Epoch: 6| Step: 13
Training loss: 3.6661195755004883
Validation loss: 2.086925562991891

Epoch: 75| Step: 0
Training loss: 2.9277210235595703
Validation loss: 2.1021047510126585

Epoch: 6| Step: 1
Training loss: 2.826801300048828
Validation loss: 2.099711272024339

Epoch: 6| Step: 2
Training loss: 2.1551055908203125
Validation loss: 2.094832281912527

Epoch: 6| Step: 3
Training loss: 2.0665903091430664
Validation loss: 2.0978931483402046

Epoch: 6| Step: 4
Training loss: 2.1178693771362305
Validation loss: 2.0954182993981147

Epoch: 6| Step: 5
Training loss: 1.8863110542297363
Validation loss: 2.092349624121061

Epoch: 6| Step: 6
Training loss: 2.7692067623138428
Validation loss: 2.1018263088759555

Epoch: 6| Step: 7
Training loss: 1.763452410697937
Validation loss: 2.114905200978761

Epoch: 6| Step: 8
Training loss: 1.8950629234313965
Validation loss: 2.083054316941128

Epoch: 6| Step: 9
Training loss: 2.586374044418335
Validation loss: 2.105622669701935

Epoch: 6| Step: 10
Training loss: 2.165748357772827
Validation loss: 2.1162028543410765

Epoch: 6| Step: 11
Training loss: 2.0543744564056396
Validation loss: 2.097653429995301

Epoch: 6| Step: 12
Training loss: 1.615804672241211
Validation loss: 2.0990494502488004

Epoch: 6| Step: 13
Training loss: 1.9572855234146118
Validation loss: 2.1215391338512464

Epoch: 76| Step: 0
Training loss: 2.726250171661377
Validation loss: 2.0920323479560112

Epoch: 6| Step: 1
Training loss: 1.4926998615264893
Validation loss: 2.0941571394602456

Epoch: 6| Step: 2
Training loss: 2.021115303039551
Validation loss: 2.0936106661314606

Epoch: 6| Step: 3
Training loss: 2.4853076934814453
Validation loss: 2.1099071887231644

Epoch: 6| Step: 4
Training loss: 2.322643756866455
Validation loss: 2.097506523132324

Epoch: 6| Step: 5
Training loss: 2.0448124408721924
Validation loss: 2.083420204859908

Epoch: 6| Step: 6
Training loss: 2.5569612979888916
Validation loss: 2.0946374657333537

Epoch: 6| Step: 7
Training loss: 1.833503246307373
Validation loss: 2.1026676239505893

Epoch: 6| Step: 8
Training loss: 2.309508800506592
Validation loss: 2.083982913724838

Epoch: 6| Step: 9
Training loss: 1.9437687397003174
Validation loss: 2.0874997761941727

Epoch: 6| Step: 10
Training loss: 2.0890116691589355
Validation loss: 2.08401350180308

Epoch: 6| Step: 11
Training loss: 1.789994478225708
Validation loss: 2.0995158072440856

Epoch: 6| Step: 12
Training loss: 2.4867095947265625
Validation loss: 2.0913310730329124

Epoch: 6| Step: 13
Training loss: 3.1995108127593994
Validation loss: 2.0948247807000273

Epoch: 77| Step: 0
Training loss: 3.3852901458740234
Validation loss: 2.113796982713925

Epoch: 6| Step: 1
Training loss: 1.6412696838378906
Validation loss: 2.098973834386436

Epoch: 6| Step: 2
Training loss: 2.0855154991149902
Validation loss: 2.093977789725027

Epoch: 6| Step: 3
Training loss: 2.1530938148498535
Validation loss: 2.0939472426650343

Epoch: 6| Step: 4
Training loss: 1.790090560913086
Validation loss: 2.0892016246754634

Epoch: 6| Step: 5
Training loss: 2.8724591732025146
Validation loss: 2.09226881816823

Epoch: 6| Step: 6
Training loss: 2.508805513381958
Validation loss: 2.1023349018507105

Epoch: 6| Step: 7
Training loss: 1.4937281608581543
Validation loss: 2.1093485893741732

Epoch: 6| Step: 8
Training loss: 1.9482982158660889
Validation loss: 2.1073949695915304

Epoch: 6| Step: 9
Training loss: 2.807790994644165
Validation loss: 2.1054851496091453

Epoch: 6| Step: 10
Training loss: 1.8536924123764038
Validation loss: 2.1185712340057536

Epoch: 6| Step: 11
Training loss: 1.5704727172851562
Validation loss: 2.117094647499823

Epoch: 6| Step: 12
Training loss: 2.9726200103759766
Validation loss: 2.101606571546165

Epoch: 6| Step: 13
Training loss: 1.5519883632659912
Validation loss: 2.0936038327473465

Epoch: 78| Step: 0
Training loss: 2.348740577697754
Validation loss: 2.094513198380829

Epoch: 6| Step: 1
Training loss: 2.137212038040161
Validation loss: 2.082875064624253

Epoch: 6| Step: 2
Training loss: 1.7677545547485352
Validation loss: 2.1084033981446297

Epoch: 6| Step: 3
Training loss: 2.016244649887085
Validation loss: 2.1013126116926952

Epoch: 6| Step: 4
Training loss: 1.8181915283203125
Validation loss: 2.0849382992713683

Epoch: 6| Step: 5
Training loss: 2.159827947616577
Validation loss: 2.0742552434244463

Epoch: 6| Step: 6
Training loss: 1.8792393207550049
Validation loss: 2.091742161781557

Epoch: 6| Step: 7
Training loss: 2.1737136840820312
Validation loss: 2.1058152734592395

Epoch: 6| Step: 8
Training loss: 2.4373843669891357
Validation loss: 2.0919210782615085

Epoch: 6| Step: 9
Training loss: 1.5951157808303833
Validation loss: 2.095009849917504

Epoch: 6| Step: 10
Training loss: 2.8170416355133057
Validation loss: 2.0736076985636065

Epoch: 6| Step: 11
Training loss: 3.183326005935669
Validation loss: 2.089220631507135

Epoch: 6| Step: 12
Training loss: 2.5284361839294434
Validation loss: 2.1000827922615954

Epoch: 6| Step: 13
Training loss: 1.8061591386795044
Validation loss: 2.0836534166848786

Epoch: 79| Step: 0
Training loss: 2.1616005897521973
Validation loss: 2.079751181346114

Epoch: 6| Step: 1
Training loss: 1.836388349533081
Validation loss: 2.0901769309915523

Epoch: 6| Step: 2
Training loss: 2.5601539611816406
Validation loss: 2.0903551027338994

Epoch: 6| Step: 3
Training loss: 2.5613925457000732
Validation loss: 2.0838993390401206

Epoch: 6| Step: 4
Training loss: 1.7999804019927979
Validation loss: 2.0962246566690426

Epoch: 6| Step: 5
Training loss: 2.667409896850586
Validation loss: 2.0846197758951495

Epoch: 6| Step: 6
Training loss: 1.9228136539459229
Validation loss: 2.0862604443744948

Epoch: 6| Step: 7
Training loss: 1.543470859527588
Validation loss: 2.0851418946378972

Epoch: 6| Step: 8
Training loss: 2.2908847332000732
Validation loss: 2.0772556617695797

Epoch: 6| Step: 9
Training loss: 2.2068867683410645
Validation loss: 2.0959424459806053

Epoch: 6| Step: 10
Training loss: 2.6955387592315674
Validation loss: 2.0955006819899364

Epoch: 6| Step: 11
Training loss: 2.28957462310791
Validation loss: 2.0872923725394794

Epoch: 6| Step: 12
Training loss: 2.042693614959717
Validation loss: 2.1021059379782727

Epoch: 6| Step: 13
Training loss: 2.5398142337799072
Validation loss: 2.085902670378326

Epoch: 80| Step: 0
Training loss: 2.445939064025879
Validation loss: 2.0921676748542377

Epoch: 6| Step: 1
Training loss: 2.5521626472473145
Validation loss: 2.0954036917737735

Epoch: 6| Step: 2
Training loss: 2.195427656173706
Validation loss: 2.099253358379487

Epoch: 6| Step: 3
Training loss: 2.0400733947753906
Validation loss: 2.114573312062089

Epoch: 6| Step: 4
Training loss: 2.420485496520996
Validation loss: 2.0962337229841497

Epoch: 6| Step: 5
Training loss: 2.752545118331909
Validation loss: 2.0958048130876277

Epoch: 6| Step: 6
Training loss: 1.9103974103927612
Validation loss: 2.0920597237925374

Epoch: 6| Step: 7
Training loss: 1.3166799545288086
Validation loss: 2.0921638114478

Epoch: 6| Step: 8
Training loss: 2.206275701522827
Validation loss: 2.101769439635738

Epoch: 6| Step: 9
Training loss: 2.779125213623047
Validation loss: 2.095928199829594

Epoch: 6| Step: 10
Training loss: 2.107142925262451
Validation loss: 2.087046291238518

Epoch: 6| Step: 11
Training loss: 1.75896418094635
Validation loss: 2.0881211962751163

Epoch: 6| Step: 12
Training loss: 1.9901342391967773
Validation loss: 2.097461520984609

Epoch: 6| Step: 13
Training loss: 2.307676076889038
Validation loss: 2.0834675501751643

Epoch: 81| Step: 0
Training loss: 2.4852235317230225
Validation loss: 2.098791524928103

Epoch: 6| Step: 1
Training loss: 2.2060232162475586
Validation loss: 2.092744750361289

Epoch: 6| Step: 2
Training loss: 1.762195348739624
Validation loss: 2.098975012379308

Epoch: 6| Step: 3
Training loss: 1.8420549631118774
Validation loss: 2.0842577231827604

Epoch: 6| Step: 4
Training loss: 2.731654167175293
Validation loss: 2.089933072367022

Epoch: 6| Step: 5
Training loss: 1.9188687801361084
Validation loss: 2.096474551385449

Epoch: 6| Step: 6
Training loss: 2.329441785812378
Validation loss: 2.1035526567889797

Epoch: 6| Step: 7
Training loss: 2.6860179901123047
Validation loss: 2.0881367678283365

Epoch: 6| Step: 8
Training loss: 2.2921206951141357
Validation loss: 2.089955892614139

Epoch: 6| Step: 9
Training loss: 1.2980101108551025
Validation loss: 2.0805396597872496

Epoch: 6| Step: 10
Training loss: 2.173647880554199
Validation loss: 2.0917612455224477

Epoch: 6| Step: 11
Training loss: 2.785296678543091
Validation loss: 2.1013666968191824

Epoch: 6| Step: 12
Training loss: 1.762357473373413
Validation loss: 2.092047070944181

Epoch: 6| Step: 13
Training loss: 2.7247111797332764
Validation loss: 2.071207948910293

Epoch: 82| Step: 0
Training loss: 2.7779524326324463
Validation loss: 2.0934944434832503

Epoch: 6| Step: 1
Training loss: 2.757732629776001
Validation loss: 2.0842991208517425

Epoch: 6| Step: 2
Training loss: 2.1410539150238037
Validation loss: 2.081485407326811

Epoch: 6| Step: 3
Training loss: 2.479753017425537
Validation loss: 2.0679534225053686

Epoch: 6| Step: 4
Training loss: 2.375556468963623
Validation loss: 2.0795113681465067

Epoch: 6| Step: 5
Training loss: 2.0479941368103027
Validation loss: 2.078871544971261

Epoch: 6| Step: 6
Training loss: 1.6627998352050781
Validation loss: 2.105916210400161

Epoch: 6| Step: 7
Training loss: 2.390454053878784
Validation loss: 2.0733385906424573

Epoch: 6| Step: 8
Training loss: 1.8305953741073608
Validation loss: 2.08490692159181

Epoch: 6| Step: 9
Training loss: 2.389923572540283
Validation loss: 2.0963338421237085

Epoch: 6| Step: 10
Training loss: 2.0948855876922607
Validation loss: 2.088057397514261

Epoch: 6| Step: 11
Training loss: 1.8587275743484497
Validation loss: 2.095523281763959

Epoch: 6| Step: 12
Training loss: 2.1338374614715576
Validation loss: 2.0853716135025024

Epoch: 6| Step: 13
Training loss: 1.5164551734924316
Validation loss: 2.1021126201075893

Epoch: 83| Step: 0
Training loss: 2.0459511280059814
Validation loss: 2.0900989091524513

Epoch: 6| Step: 1
Training loss: 2.8659820556640625
Validation loss: 2.0961105349243327

Epoch: 6| Step: 2
Training loss: 2.400470733642578
Validation loss: 2.0816904767867057

Epoch: 6| Step: 3
Training loss: 2.0101253986358643
Validation loss: 2.0795780099848264

Epoch: 6| Step: 4
Training loss: 2.343132734298706
Validation loss: 2.093129042656191

Epoch: 6| Step: 5
Training loss: 1.4733920097351074
Validation loss: 2.0968345570307907

Epoch: 6| Step: 6
Training loss: 2.698063373565674
Validation loss: 2.102840427429445

Epoch: 6| Step: 7
Training loss: 2.336801052093506
Validation loss: 2.1010375253615843

Epoch: 6| Step: 8
Training loss: 1.8920236825942993
Validation loss: 2.109100693015642

Epoch: 6| Step: 9
Training loss: 2.7274975776672363
Validation loss: 2.100733289154627

Epoch: 6| Step: 10
Training loss: 1.6223151683807373
Validation loss: 2.096314940401303

Epoch: 6| Step: 11
Training loss: 1.98177170753479
Validation loss: 2.088277560408397

Epoch: 6| Step: 12
Training loss: 2.0372538566589355
Validation loss: 2.100232490929224

Epoch: 6| Step: 13
Training loss: 2.6037113666534424
Validation loss: 2.092384348633469

Epoch: 84| Step: 0
Training loss: 2.057514190673828
Validation loss: 2.0922674568750526

Epoch: 6| Step: 1
Training loss: 2.4163403511047363
Validation loss: 2.0884288203331733

Epoch: 6| Step: 2
Training loss: 3.221808433532715
Validation loss: 2.097463310405772

Epoch: 6| Step: 3
Training loss: 1.7524267435073853
Validation loss: 2.1131290825464393

Epoch: 6| Step: 4
Training loss: 2.248166799545288
Validation loss: 2.092989256305079

Epoch: 6| Step: 5
Training loss: 2.234388589859009
Validation loss: 2.086629104870622

Epoch: 6| Step: 6
Training loss: 1.5142539739608765
Validation loss: 2.107588691096152

Epoch: 6| Step: 7
Training loss: 2.2110095024108887
Validation loss: 2.103861176839439

Epoch: 6| Step: 8
Training loss: 2.095066547393799
Validation loss: 2.0966683613356722

Epoch: 6| Step: 9
Training loss: 2.0919952392578125
Validation loss: 2.096437008150162

Epoch: 6| Step: 10
Training loss: 2.4262142181396484
Validation loss: 2.1016107413076583

Epoch: 6| Step: 11
Training loss: 2.2614481449127197
Validation loss: 2.0893969856282717

Epoch: 6| Step: 12
Training loss: 1.874382495880127
Validation loss: 2.1042464112722747

Epoch: 6| Step: 13
Training loss: 2.486086845397949
Validation loss: 2.1161761694057013

Epoch: 85| Step: 0
Training loss: 2.222046375274658
Validation loss: 2.1025053198619554

Epoch: 6| Step: 1
Training loss: 1.9316327571868896
Validation loss: 2.1069595736842

Epoch: 6| Step: 2
Training loss: 2.2097482681274414
Validation loss: 2.1001796466048046

Epoch: 6| Step: 3
Training loss: 2.538156509399414
Validation loss: 2.1099702747919227

Epoch: 6| Step: 4
Training loss: 2.094980478286743
Validation loss: 2.0889413587508665

Epoch: 6| Step: 5
Training loss: 2.4398016929626465
Validation loss: 2.088844455698485

Epoch: 6| Step: 6
Training loss: 2.2164719104766846
Validation loss: 2.0918888712442048

Epoch: 6| Step: 7
Training loss: 1.7590948343276978
Validation loss: 2.1023443437391713

Epoch: 6| Step: 8
Training loss: 2.420788288116455
Validation loss: 2.103305466713444

Epoch: 6| Step: 9
Training loss: 2.4855387210845947
Validation loss: 2.097378921765153

Epoch: 6| Step: 10
Training loss: 1.9354345798492432
Validation loss: 2.0968670716849704

Epoch: 6| Step: 11
Training loss: 2.144676446914673
Validation loss: 2.1019102245248775

Epoch: 6| Step: 12
Training loss: 1.623100996017456
Validation loss: 2.113569180170695

Epoch: 6| Step: 13
Training loss: 3.0334103107452393
Validation loss: 2.0846713242992276

Epoch: 86| Step: 0
Training loss: 2.030183792114258
Validation loss: 2.089612873651648

Epoch: 6| Step: 1
Training loss: 2.151742696762085
Validation loss: 2.089032252629598

Epoch: 6| Step: 2
Training loss: 3.0000855922698975
Validation loss: 2.0916871998899724

Epoch: 6| Step: 3
Training loss: 2.0269758701324463
Validation loss: 2.1012918615853913

Epoch: 6| Step: 4
Training loss: 2.7083566188812256
Validation loss: 2.1105612759949057

Epoch: 6| Step: 5
Training loss: 2.512385845184326
Validation loss: 2.080218962443772

Epoch: 6| Step: 6
Training loss: 1.7980704307556152
Validation loss: 2.0935654806834396

Epoch: 6| Step: 7
Training loss: 2.352550506591797
Validation loss: 2.094297978185838

Epoch: 6| Step: 8
Training loss: 2.0505902767181396
Validation loss: 2.0905098248553533

Epoch: 6| Step: 9
Training loss: 1.6869584321975708
Validation loss: 2.1078769109582387

Epoch: 6| Step: 10
Training loss: 2.6321194171905518
Validation loss: 2.0738011226859143

Epoch: 6| Step: 11
Training loss: 1.4033738374710083
Validation loss: 2.0997169812520347

Epoch: 6| Step: 12
Training loss: 2.1967225074768066
Validation loss: 2.1130608243326985

Epoch: 6| Step: 13
Training loss: 2.031881332397461
Validation loss: 2.095277201744818

Epoch: 87| Step: 0
Training loss: 2.450169563293457
Validation loss: 2.0940318210150606

Epoch: 6| Step: 1
Training loss: 1.3576345443725586
Validation loss: 2.0998044847160258

Epoch: 6| Step: 2
Training loss: 1.86691415309906
Validation loss: 2.0940078061114074

Epoch: 6| Step: 3
Training loss: 2.1710164546966553
Validation loss: 2.0974771335560787

Epoch: 6| Step: 4
Training loss: 2.4110212326049805
Validation loss: 2.0950598050189275

Epoch: 6| Step: 5
Training loss: 1.481448769569397
Validation loss: 2.1087045490100818

Epoch: 6| Step: 6
Training loss: 1.961960792541504
Validation loss: 2.09235639725962

Epoch: 6| Step: 7
Training loss: 2.403724193572998
Validation loss: 2.093667919917773

Epoch: 6| Step: 8
Training loss: 2.824101209640503
Validation loss: 2.092820821269866

Epoch: 6| Step: 9
Training loss: 3.1686434745788574
Validation loss: 2.083250320085915

Epoch: 6| Step: 10
Training loss: 2.5499191284179688
Validation loss: 2.0925103797707507

Epoch: 6| Step: 11
Training loss: 1.795988917350769
Validation loss: 2.1057778353332193

Epoch: 6| Step: 12
Training loss: 2.1317410469055176
Validation loss: 2.1041095359351045

Epoch: 6| Step: 13
Training loss: 1.4804131984710693
Validation loss: 2.097077618363083

Epoch: 88| Step: 0
Training loss: 2.461932420730591
Validation loss: 2.0911762470840127

Epoch: 6| Step: 1
Training loss: 2.46394944190979
Validation loss: 2.0995625167764644

Epoch: 6| Step: 2
Training loss: 1.8852157592773438
Validation loss: 2.0967433619242843

Epoch: 6| Step: 3
Training loss: 1.9520031213760376
Validation loss: 2.0924806325666365

Epoch: 6| Step: 4
Training loss: 1.6769325733184814
Validation loss: 2.0719633743327153

Epoch: 6| Step: 5
Training loss: 1.8947649002075195
Validation loss: 2.1024613329159316

Epoch: 6| Step: 6
Training loss: 1.696882963180542
Validation loss: 2.080414507978706

Epoch: 6| Step: 7
Training loss: 2.0511741638183594
Validation loss: 2.1145591940931094

Epoch: 6| Step: 8
Training loss: 2.2173542976379395
Validation loss: 2.1101439383722123

Epoch: 6| Step: 9
Training loss: 2.518852949142456
Validation loss: 2.0741393643040813

Epoch: 6| Step: 10
Training loss: 1.6771469116210938
Validation loss: 2.093803245534179

Epoch: 6| Step: 11
Training loss: 3.2675888538360596
Validation loss: 2.0969691571368965

Epoch: 6| Step: 12
Training loss: 2.143138885498047
Validation loss: 2.0909921764045634

Epoch: 6| Step: 13
Training loss: 3.1987948417663574
Validation loss: 2.110998979178808

Epoch: 89| Step: 0
Training loss: 2.262348175048828
Validation loss: 2.092219970559561

Epoch: 6| Step: 1
Training loss: 2.0001771450042725
Validation loss: 2.1019562418742845

Epoch: 6| Step: 2
Training loss: 2.3289239406585693
Validation loss: 2.1005324074017104

Epoch: 6| Step: 3
Training loss: 2.0245583057403564
Validation loss: 2.090426701371388

Epoch: 6| Step: 4
Training loss: 1.9399421215057373
Validation loss: 2.101284355245611

Epoch: 6| Step: 5
Training loss: 1.8877339363098145
Validation loss: 2.0970386920436734

Epoch: 6| Step: 6
Training loss: 2.353057384490967
Validation loss: 2.0930339008249264

Epoch: 6| Step: 7
Training loss: 2.2067408561706543
Validation loss: 2.0641991015403502

Epoch: 6| Step: 8
Training loss: 1.6760523319244385
Validation loss: 2.09270078392439

Epoch: 6| Step: 9
Training loss: 1.8874895572662354
Validation loss: 2.085039795085948

Epoch: 6| Step: 10
Training loss: 1.8376471996307373
Validation loss: 2.076532930456182

Epoch: 6| Step: 11
Training loss: 3.0882675647735596
Validation loss: 2.106951387979651

Epoch: 6| Step: 12
Training loss: 3.0957393646240234
Validation loss: 2.0987454383603987

Epoch: 6| Step: 13
Training loss: 1.7877955436706543
Validation loss: 2.0845226164787047

Epoch: 90| Step: 0
Training loss: 2.3128654956817627
Validation loss: 2.0772842950718378

Epoch: 6| Step: 1
Training loss: 1.8698008060455322
Validation loss: 2.0938790767423567

Epoch: 6| Step: 2
Training loss: 2.127061367034912
Validation loss: 2.111340022856189

Epoch: 6| Step: 3
Training loss: 2.226036548614502
Validation loss: 2.0997186758184947

Epoch: 6| Step: 4
Training loss: 2.6335108280181885
Validation loss: 2.09136341720499

Epoch: 6| Step: 5
Training loss: 1.9845534563064575
Validation loss: 2.1044744189067552

Epoch: 6| Step: 6
Training loss: 2.61021089553833
Validation loss: 2.0804313408431185

Epoch: 6| Step: 7
Training loss: 2.3724565505981445
Validation loss: 2.11288175787977

Epoch: 6| Step: 8
Training loss: 1.962747573852539
Validation loss: 2.102022168456867

Epoch: 6| Step: 9
Training loss: 2.104980707168579
Validation loss: 2.0734725075383342

Epoch: 6| Step: 10
Training loss: 2.384248971939087
Validation loss: 2.085263195858207

Epoch: 6| Step: 11
Training loss: 2.203922748565674
Validation loss: 2.0934689096225205

Epoch: 6| Step: 12
Training loss: 1.9886078834533691
Validation loss: 2.0873837406917284

Epoch: 6| Step: 13
Training loss: 1.2892347574234009
Validation loss: 2.0941930970837994

Epoch: 91| Step: 0
Training loss: 2.47100830078125
Validation loss: 2.1162327771545737

Epoch: 6| Step: 1
Training loss: 2.3496031761169434
Validation loss: 2.0805718257863033

Epoch: 6| Step: 2
Training loss: 2.1434807777404785
Validation loss: 2.1106968541299143

Epoch: 6| Step: 3
Training loss: 1.5783147811889648
Validation loss: 2.1013399349745883

Epoch: 6| Step: 4
Training loss: 1.9370439052581787
Validation loss: 2.0958444533809537

Epoch: 6| Step: 5
Training loss: 2.1354079246520996
Validation loss: 2.0851910601380053

Epoch: 6| Step: 6
Training loss: 1.8390846252441406
Validation loss: 2.095907470231415

Epoch: 6| Step: 7
Training loss: 2.44647216796875
Validation loss: 2.086749384480138

Epoch: 6| Step: 8
Training loss: 2.2010796070098877
Validation loss: 2.1003465703738633

Epoch: 6| Step: 9
Training loss: 1.716759204864502
Validation loss: 2.0935458752416793

Epoch: 6| Step: 10
Training loss: 3.046173095703125
Validation loss: 2.083288238894555

Epoch: 6| Step: 11
Training loss: 2.5280280113220215
Validation loss: 2.090127307881591

Epoch: 6| Step: 12
Training loss: 2.0992133617401123
Validation loss: 2.0653039909178212

Epoch: 6| Step: 13
Training loss: 2.0426628589630127
Validation loss: 2.0951125416704404

Epoch: 92| Step: 0
Training loss: 1.8094043731689453
Validation loss: 2.0866051181670158

Epoch: 6| Step: 1
Training loss: 2.1168999671936035
Validation loss: 2.093946505618352

Epoch: 6| Step: 2
Training loss: 2.199899673461914
Validation loss: 2.0994545823784283

Epoch: 6| Step: 3
Training loss: 2.2939703464508057
Validation loss: 2.097924360664942

Epoch: 6| Step: 4
Training loss: 2.182981014251709
Validation loss: 2.0954790756266606

Epoch: 6| Step: 5
Training loss: 2.1600213050842285
Validation loss: 2.105336686616303

Epoch: 6| Step: 6
Training loss: 2.804471254348755
Validation loss: 2.1091017351355603

Epoch: 6| Step: 7
Training loss: 1.5103784799575806
Validation loss: 2.1110234247740878

Epoch: 6| Step: 8
Training loss: 2.596573829650879
Validation loss: 2.104054794516615

Epoch: 6| Step: 9
Training loss: 2.6287567615509033
Validation loss: 2.0982492175153507

Epoch: 6| Step: 10
Training loss: 1.9181926250457764
Validation loss: 2.089658271881842

Epoch: 6| Step: 11
Training loss: 2.0752816200256348
Validation loss: 2.0886690847335325

Epoch: 6| Step: 12
Training loss: 1.9761216640472412
Validation loss: 2.0874171257019043

Epoch: 6| Step: 13
Training loss: 2.296027183532715
Validation loss: 2.084260691878616

Epoch: 93| Step: 0
Training loss: 2.403413772583008
Validation loss: 2.0855794029851116

Epoch: 6| Step: 1
Training loss: 2.5467920303344727
Validation loss: 2.0917323814925326

Epoch: 6| Step: 2
Training loss: 2.421111583709717
Validation loss: 2.102300379865913

Epoch: 6| Step: 3
Training loss: 2.373154640197754
Validation loss: 2.085297164096627

Epoch: 6| Step: 4
Training loss: 1.6664725542068481
Validation loss: 2.0949088001763947

Epoch: 6| Step: 5
Training loss: 1.7236452102661133
Validation loss: 2.0823419170994915

Epoch: 6| Step: 6
Training loss: 2.735684871673584
Validation loss: 2.093126073960335

Epoch: 6| Step: 7
Training loss: 1.788435935974121
Validation loss: 2.1027864025485132

Epoch: 6| Step: 8
Training loss: 2.0205888748168945
Validation loss: 2.096374447627734

Epoch: 6| Step: 9
Training loss: 2.5136265754699707
Validation loss: 2.104685280912666

Epoch: 6| Step: 10
Training loss: 2.0826191902160645
Validation loss: 2.107307877591861

Epoch: 6| Step: 11
Training loss: 2.0082597732543945
Validation loss: 2.1092061406822613

Epoch: 6| Step: 12
Training loss: 1.9325275421142578
Validation loss: 2.085601209312357

Epoch: 6| Step: 13
Training loss: 2.5100064277648926
Validation loss: 2.1176349027182466

Epoch: 94| Step: 0
Training loss: 1.9137001037597656
Validation loss: 2.087998631179974

Epoch: 6| Step: 1
Training loss: 2.4928152561187744
Validation loss: 2.0879406326560566

Epoch: 6| Step: 2
Training loss: 2.406156063079834
Validation loss: 2.0916588203881377

Epoch: 6| Step: 3
Training loss: 2.0313682556152344
Validation loss: 2.1003391870888333

Epoch: 6| Step: 4
Training loss: 2.299180269241333
Validation loss: 2.0831445929824666

Epoch: 6| Step: 5
Training loss: 2.601773500442505
Validation loss: 2.097199729693833

Epoch: 6| Step: 6
Training loss: 1.7820899486541748
Validation loss: 2.0820043087005615

Epoch: 6| Step: 7
Training loss: 1.5919227600097656
Validation loss: 2.0814232441686813

Epoch: 6| Step: 8
Training loss: 2.676206111907959
Validation loss: 2.0776170915172947

Epoch: 6| Step: 9
Training loss: 1.585823893547058
Validation loss: 2.099571312627485

Epoch: 6| Step: 10
Training loss: 1.833168387413025
Validation loss: 2.0919199630778325

Epoch: 6| Step: 11
Training loss: 2.3181962966918945
Validation loss: 2.1025454664743073

Epoch: 6| Step: 12
Training loss: 2.546443462371826
Validation loss: 2.0763179743161766

Epoch: 6| Step: 13
Training loss: 2.8367104530334473
Validation loss: 2.0768040815989175

Epoch: 95| Step: 0
Training loss: 1.9357835054397583
Validation loss: 2.1042024832899853

Epoch: 6| Step: 1
Training loss: 2.3103740215301514
Validation loss: 2.075848769116145

Epoch: 6| Step: 2
Training loss: 2.2884998321533203
Validation loss: 2.099872189183389

Epoch: 6| Step: 3
Training loss: 2.5131821632385254
Validation loss: 2.104528101541663

Epoch: 6| Step: 4
Training loss: 2.727613687515259
Validation loss: 2.0838920813734814

Epoch: 6| Step: 5
Training loss: 2.2804617881774902
Validation loss: 2.085936697580481

Epoch: 6| Step: 6
Training loss: 2.141610622406006
Validation loss: 2.0865612773485083

Epoch: 6| Step: 7
Training loss: 1.5325807332992554
Validation loss: 2.0833148943480624

Epoch: 6| Step: 8
Training loss: 1.8294697999954224
Validation loss: 2.0854155684030182

Epoch: 6| Step: 9
Training loss: 2.658453941345215
Validation loss: 2.1080677816944737

Epoch: 6| Step: 10
Training loss: 1.9806349277496338
Validation loss: 2.0908101643285444

Epoch: 6| Step: 11
Training loss: 2.1015095710754395
Validation loss: 2.0850315581085863

Epoch: 6| Step: 12
Training loss: 2.3555068969726562
Validation loss: 2.094874184618714

Epoch: 6| Step: 13
Training loss: 1.6483020782470703
Validation loss: 2.1006548661057667

Epoch: 96| Step: 0
Training loss: 2.219423770904541
Validation loss: 2.110214328253141

Epoch: 6| Step: 1
Training loss: 2.167163372039795
Validation loss: 2.127764312169885

Epoch: 6| Step: 2
Training loss: 2.993250846862793
Validation loss: 2.0979315516769246

Epoch: 6| Step: 3
Training loss: 2.5110249519348145
Validation loss: 2.0878158512935845

Epoch: 6| Step: 4
Training loss: 1.925621747970581
Validation loss: 2.103935275026547

Epoch: 6| Step: 5
Training loss: 2.325282335281372
Validation loss: 2.0798413740691317

Epoch: 6| Step: 6
Training loss: 2.109478235244751
Validation loss: 2.0698030584601947

Epoch: 6| Step: 7
Training loss: 1.9623429775238037
Validation loss: 2.0869666286694106

Epoch: 6| Step: 8
Training loss: 2.3653550148010254
Validation loss: 2.0866583342193277

Epoch: 6| Step: 9
Training loss: 1.7742009162902832
Validation loss: 2.0816809592708463

Epoch: 6| Step: 10
Training loss: 2.883575677871704
Validation loss: 2.1010653408624793

Epoch: 6| Step: 11
Training loss: 1.6104774475097656
Validation loss: 2.086872899404136

Epoch: 6| Step: 12
Training loss: 1.6898101568222046
Validation loss: 2.087889894362419

Epoch: 6| Step: 13
Training loss: 1.6406455039978027
Validation loss: 2.0623860923192834

Epoch: 97| Step: 0
Training loss: 2.342129707336426
Validation loss: 2.0898606033735376

Epoch: 6| Step: 1
Training loss: 2.2403621673583984
Validation loss: 2.0867847781027518

Epoch: 6| Step: 2
Training loss: 2.343926191329956
Validation loss: 2.1016019262293333

Epoch: 6| Step: 3
Training loss: 2.355318784713745
Validation loss: 2.0782061417897544

Epoch: 6| Step: 4
Training loss: 2.092301368713379
Validation loss: 2.09673120257675

Epoch: 6| Step: 5
Training loss: 2.413062810897827
Validation loss: 2.0850660672751804

Epoch: 6| Step: 6
Training loss: 2.0880126953125
Validation loss: 2.087904360986525

Epoch: 6| Step: 7
Training loss: 1.4994219541549683
Validation loss: 2.0695990029201714

Epoch: 6| Step: 8
Training loss: 2.424560070037842
Validation loss: 2.101084381021479

Epoch: 6| Step: 9
Training loss: 1.9190458059310913
Validation loss: 2.0937682518395047

Epoch: 6| Step: 10
Training loss: 2.2055535316467285
Validation loss: 2.087217051495788

Epoch: 6| Step: 11
Training loss: 2.1570866107940674
Validation loss: 2.0795044283713064

Epoch: 6| Step: 12
Training loss: 1.9004172086715698
Validation loss: 2.083172330292322

Epoch: 6| Step: 13
Training loss: 2.664093494415283
Validation loss: 2.0795434662090835

Epoch: 98| Step: 0
Training loss: 1.4158923625946045
Validation loss: 2.0730488018323014

Epoch: 6| Step: 1
Training loss: 2.063430070877075
Validation loss: 2.078736766692131

Epoch: 6| Step: 2
Training loss: 2.324983596801758
Validation loss: 2.0879278644438712

Epoch: 6| Step: 3
Training loss: 2.472479820251465
Validation loss: 2.0786688071425243

Epoch: 6| Step: 4
Training loss: 1.6762298345565796
Validation loss: 2.084120822209184

Epoch: 6| Step: 5
Training loss: 2.841679334640503
Validation loss: 2.1138400275220155

Epoch: 6| Step: 6
Training loss: 2.367295026779175
Validation loss: 2.108002024312173

Epoch: 6| Step: 7
Training loss: 2.6275076866149902
Validation loss: 2.1072105643569783

Epoch: 6| Step: 8
Training loss: 1.611183762550354
Validation loss: 2.1075946374606063

Epoch: 6| Step: 9
Training loss: 2.1827199459075928
Validation loss: 2.1013607440456266

Epoch: 6| Step: 10
Training loss: 2.1431188583374023
Validation loss: 2.1124731917535104

Epoch: 6| Step: 11
Training loss: 2.5543551445007324
Validation loss: 2.103343347067474

Epoch: 6| Step: 12
Training loss: 1.5164240598678589
Validation loss: 2.086203075224353

Epoch: 6| Step: 13
Training loss: 3.069221258163452
Validation loss: 2.0931655770988873

Epoch: 99| Step: 0
Training loss: 2.9508559703826904
Validation loss: 2.0892226465286745

Epoch: 6| Step: 1
Training loss: 2.2946619987487793
Validation loss: 2.091988745556083

Epoch: 6| Step: 2
Training loss: 2.4660496711730957
Validation loss: 2.0987078041158695

Epoch: 6| Step: 3
Training loss: 2.4530320167541504
Validation loss: 2.102219003503041

Epoch: 6| Step: 4
Training loss: 1.957192301750183
Validation loss: 2.0795077175222416

Epoch: 6| Step: 5
Training loss: 1.9144673347473145
Validation loss: 2.078122382522911

Epoch: 6| Step: 6
Training loss: 2.3293228149414062
Validation loss: 2.070237728857225

Epoch: 6| Step: 7
Training loss: 1.6986548900604248
Validation loss: 2.0940774820184194

Epoch: 6| Step: 8
Training loss: 2.1822574138641357
Validation loss: 2.094864317165908

Epoch: 6| Step: 9
Training loss: 2.06466007232666
Validation loss: 2.0735966736270535

Epoch: 6| Step: 10
Training loss: 1.836889386177063
Validation loss: 2.0743662234275573

Epoch: 6| Step: 11
Training loss: 2.022399425506592
Validation loss: 2.0868638407799507

Epoch: 6| Step: 12
Training loss: 1.7550504207611084
Validation loss: 2.0898737061408257

Epoch: 6| Step: 13
Training loss: 2.5559515953063965
Validation loss: 2.0655205275422786

Epoch: 100| Step: 0
Training loss: 2.001305341720581
Validation loss: 2.0890789903620237

Epoch: 6| Step: 1
Training loss: 2.053164482116699
Validation loss: 2.08678908758266

Epoch: 6| Step: 2
Training loss: 2.3362832069396973
Validation loss: 2.086366750860727

Epoch: 6| Step: 3
Training loss: 1.9008324146270752
Validation loss: 2.071638427754884

Epoch: 6| Step: 4
Training loss: 1.7610872983932495
Validation loss: 2.1009744982565604

Epoch: 6| Step: 5
Training loss: 2.2342936992645264
Validation loss: 2.0986234962299304

Epoch: 6| Step: 6
Training loss: 2.2820119857788086
Validation loss: 2.0931542765709663

Epoch: 6| Step: 7
Training loss: 1.4118056297302246
Validation loss: 2.1020348764234975

Epoch: 6| Step: 8
Training loss: 2.530534267425537
Validation loss: 2.080039216626075

Epoch: 6| Step: 9
Training loss: 2.2919797897338867
Validation loss: 2.078375335662596

Epoch: 6| Step: 10
Training loss: 2.4798285961151123
Validation loss: 2.0936152653027604

Epoch: 6| Step: 11
Training loss: 2.7221455574035645
Validation loss: 2.104566659978641

Epoch: 6| Step: 12
Training loss: 2.010772943496704
Validation loss: 2.0955064142903974

Epoch: 6| Step: 13
Training loss: 2.3030903339385986
Validation loss: 2.075248446515811

Epoch: 101| Step: 0
Training loss: 1.699244737625122
Validation loss: 2.0886719983111144

Epoch: 6| Step: 1
Training loss: 2.4679527282714844
Validation loss: 2.085154782059372

Epoch: 6| Step: 2
Training loss: 1.9411964416503906
Validation loss: 2.086269747826361

Epoch: 6| Step: 3
Training loss: 1.913142204284668
Validation loss: 2.097012883873396

Epoch: 6| Step: 4
Training loss: 2.2644762992858887
Validation loss: 2.0873599718975764

Epoch: 6| Step: 5
Training loss: 2.482999801635742
Validation loss: 2.0945617947527158

Epoch: 6| Step: 6
Training loss: 1.9743950366973877
Validation loss: 2.103065149758452

Epoch: 6| Step: 7
Training loss: 2.3692164421081543
Validation loss: 2.075875231014785

Epoch: 6| Step: 8
Training loss: 2.297382354736328
Validation loss: 2.0966376668663433

Epoch: 6| Step: 9
Training loss: 2.832244873046875
Validation loss: 2.0972435141122467

Epoch: 6| Step: 10
Training loss: 2.0973217487335205
Validation loss: 2.0880189172683226

Epoch: 6| Step: 11
Training loss: 1.6398990154266357
Validation loss: 2.0936182865532498

Epoch: 6| Step: 12
Training loss: 2.2219204902648926
Validation loss: 2.105774966619348

Epoch: 6| Step: 13
Training loss: 2.0924673080444336
Validation loss: 2.097734998631221

Epoch: 102| Step: 0
Training loss: 2.388289451599121
Validation loss: 2.0910536063614713

Epoch: 6| Step: 1
Training loss: 2.0059714317321777
Validation loss: 2.0906029773014847

Epoch: 6| Step: 2
Training loss: 2.1539230346679688
Validation loss: 2.081360811828285

Epoch: 6| Step: 3
Training loss: 2.3229007720947266
Validation loss: 2.0812689488933933

Epoch: 6| Step: 4
Training loss: 2.295759439468384
Validation loss: 2.0912226579522573

Epoch: 6| Step: 5
Training loss: 1.6771488189697266
Validation loss: 2.1060922350934757

Epoch: 6| Step: 6
Training loss: 2.254157781600952
Validation loss: 2.0952170074626966

Epoch: 6| Step: 7
Training loss: 2.473719358444214
Validation loss: 2.1098985415633007

Epoch: 6| Step: 8
Training loss: 2.040494441986084
Validation loss: 2.0979100991320867

Epoch: 6| Step: 9
Training loss: 1.9451769590377808
Validation loss: 2.0885375071597356

Epoch: 6| Step: 10
Training loss: 1.6132395267486572
Validation loss: 2.0915133440366356

Epoch: 6| Step: 11
Training loss: 2.235534191131592
Validation loss: 2.0883068653845016

Epoch: 6| Step: 12
Training loss: 2.294170618057251
Validation loss: 2.09058629825551

Epoch: 6| Step: 13
Training loss: 2.9793756008148193
Validation loss: 2.1015244043001564

Epoch: 103| Step: 0
Training loss: 2.5856471061706543
Validation loss: 2.0951573053995767

Epoch: 6| Step: 1
Training loss: 2.146925449371338
Validation loss: 2.0870469898305912

Epoch: 6| Step: 2
Training loss: 2.368159055709839
Validation loss: 2.103590080814977

Epoch: 6| Step: 3
Training loss: 1.5927222967147827
Validation loss: 2.124424592141182

Epoch: 6| Step: 4
Training loss: 1.439192533493042
Validation loss: 2.086768565639373

Epoch: 6| Step: 5
Training loss: 2.1484622955322266
Validation loss: 2.085617434593939

Epoch: 6| Step: 6
Training loss: 2.1007049083709717
Validation loss: 2.097367461009692

Epoch: 6| Step: 7
Training loss: 2.2831978797912598
Validation loss: 2.095972821276675

Epoch: 6| Step: 8
Training loss: 1.9965100288391113
Validation loss: 2.0860631030092955

Epoch: 6| Step: 9
Training loss: 2.1211557388305664
Validation loss: 2.091584221009285

Epoch: 6| Step: 10
Training loss: 2.041019916534424
Validation loss: 2.1083390815283662

Epoch: 6| Step: 11
Training loss: 2.4775137901306152
Validation loss: 2.07217493877616

Epoch: 6| Step: 12
Training loss: 2.313922882080078
Validation loss: 2.097966171080066

Epoch: 6| Step: 13
Training loss: 2.8389551639556885
Validation loss: 2.103205511646886

Epoch: 104| Step: 0
Training loss: 2.6632421016693115
Validation loss: 2.097200696186353

Epoch: 6| Step: 1
Training loss: 1.8587734699249268
Validation loss: 2.0949661347173874

Epoch: 6| Step: 2
Training loss: 2.3207831382751465
Validation loss: 2.1117931283930296

Epoch: 6| Step: 3
Training loss: 2.109893560409546
Validation loss: 2.1090603349029378

Epoch: 6| Step: 4
Training loss: 1.8756452798843384
Validation loss: 2.1022264906155166

Epoch: 6| Step: 5
Training loss: 1.2916021347045898
Validation loss: 2.09383790211011

Epoch: 6| Step: 6
Training loss: 2.4582066535949707
Validation loss: 2.0849965285229426

Epoch: 6| Step: 7
Training loss: 2.646972894668579
Validation loss: 2.1188408687550533

Epoch: 6| Step: 8
Training loss: 2.731313943862915
Validation loss: 2.0958903374210482

Epoch: 6| Step: 9
Training loss: 1.5148909091949463
Validation loss: 2.113620937511485

Epoch: 6| Step: 10
Training loss: 2.101321220397949
Validation loss: 2.0971578116058023

Epoch: 6| Step: 11
Training loss: 2.123626947402954
Validation loss: 2.1016897642484276

Epoch: 6| Step: 12
Training loss: 2.2651453018188477
Validation loss: 2.1019882643094627

Epoch: 6| Step: 13
Training loss: 2.2221052646636963
Validation loss: 2.080108465686921

Epoch: 105| Step: 0
Training loss: 1.8990769386291504
Validation loss: 2.090821942975444

Epoch: 6| Step: 1
Training loss: 1.731858730316162
Validation loss: 2.099934377977925

Epoch: 6| Step: 2
Training loss: 2.5349183082580566
Validation loss: 2.1068787933677755

Epoch: 6| Step: 3
Training loss: 1.8653894662857056
Validation loss: 2.1182191935918664

Epoch: 6| Step: 4
Training loss: 2.389451026916504
Validation loss: 2.103551010931692

Epoch: 6| Step: 5
Training loss: 2.110368013381958
Validation loss: 2.084588881461851

Epoch: 6| Step: 6
Training loss: 3.0086441040039062
Validation loss: 2.0939423614932644

Epoch: 6| Step: 7
Training loss: 2.1663334369659424
Validation loss: 2.0955953136567147

Epoch: 6| Step: 8
Training loss: 2.153050422668457
Validation loss: 2.0968764097459855

Epoch: 6| Step: 9
Training loss: 1.6604654788970947
Validation loss: 2.1148174808871363

Epoch: 6| Step: 10
Training loss: 2.428746223449707
Validation loss: 2.0836189075182845

Epoch: 6| Step: 11
Training loss: 2.078559398651123
Validation loss: 2.0651958834740425

Epoch: 6| Step: 12
Training loss: 1.7439051866531372
Validation loss: 2.081829221017899

Epoch: 6| Step: 13
Training loss: 2.373894691467285
Validation loss: 2.0744703482556086

Epoch: 106| Step: 0
Training loss: 2.5009925365448
Validation loss: 2.0865242942687003

Epoch: 6| Step: 1
Training loss: 2.0442662239074707
Validation loss: 2.0913983288631646

Epoch: 6| Step: 2
Training loss: 2.464552402496338
Validation loss: 2.0784883396599882

Epoch: 6| Step: 3
Training loss: 1.8498868942260742
Validation loss: 2.088900794265091

Epoch: 6| Step: 4
Training loss: 1.694547176361084
Validation loss: 2.0729924735202583

Epoch: 6| Step: 5
Training loss: 2.2298967838287354
Validation loss: 2.083550988986928

Epoch: 6| Step: 6
Training loss: 2.432534694671631
Validation loss: 2.0936595342492543

Epoch: 6| Step: 7
Training loss: 1.5176384449005127
Validation loss: 2.0860005706869145

Epoch: 6| Step: 8
Training loss: 2.2795143127441406
Validation loss: 2.08056612424953

Epoch: 6| Step: 9
Training loss: 1.7734129428863525
Validation loss: 2.0920971683276597

Epoch: 6| Step: 10
Training loss: 2.7427783012390137
Validation loss: 2.086363407873338

Epoch: 6| Step: 11
Training loss: 2.343322992324829
Validation loss: 2.087207360934186

Epoch: 6| Step: 12
Training loss: 1.754899501800537
Validation loss: 2.097755014255483

Epoch: 6| Step: 13
Training loss: 2.550973892211914
Validation loss: 2.1061407801925496

Epoch: 107| Step: 0
Training loss: 1.9520128965377808
Validation loss: 2.063119734487226

Epoch: 6| Step: 1
Training loss: 2.0589511394500732
Validation loss: 2.1013446187460296

Epoch: 6| Step: 2
Training loss: 1.7829259634017944
Validation loss: 2.0795892643672165

Epoch: 6| Step: 3
Training loss: 1.8999195098876953
Validation loss: 2.0877944910398094

Epoch: 6| Step: 4
Training loss: 2.0988173484802246
Validation loss: 2.0872677526166363

Epoch: 6| Step: 5
Training loss: 2.0856375694274902
Validation loss: 2.1023807679453204

Epoch: 6| Step: 6
Training loss: 2.167710781097412
Validation loss: 2.076242789145439

Epoch: 6| Step: 7
Training loss: 2.0615410804748535
Validation loss: 2.085415719657816

Epoch: 6| Step: 8
Training loss: 2.221566915512085
Validation loss: 2.081451786461697

Epoch: 6| Step: 9
Training loss: 2.10870623588562
Validation loss: 2.1010862537609634

Epoch: 6| Step: 10
Training loss: 3.099867820739746
Validation loss: 2.0742217161322154

Epoch: 6| Step: 11
Training loss: 2.0128114223480225
Validation loss: 2.0884012535054195

Epoch: 6| Step: 12
Training loss: 2.6482582092285156
Validation loss: 2.0729695250911098

Epoch: 6| Step: 13
Training loss: 1.917733073234558
Validation loss: 2.0625140179869947

Epoch: 108| Step: 0
Training loss: 2.692201614379883
Validation loss: 2.0720960119719147

Epoch: 6| Step: 1
Training loss: 2.5118751525878906
Validation loss: 2.0788387585711736

Epoch: 6| Step: 2
Training loss: 2.088571786880493
Validation loss: 2.0707154427805254

Epoch: 6| Step: 3
Training loss: 2.0292282104492188
Validation loss: 2.093761110818514

Epoch: 6| Step: 4
Training loss: 1.837203025817871
Validation loss: 2.0777610912117908

Epoch: 6| Step: 5
Training loss: 2.1941943168640137
Validation loss: 2.0916662908369497

Epoch: 6| Step: 6
Training loss: 1.7852592468261719
Validation loss: 2.0729601562664075

Epoch: 6| Step: 7
Training loss: 1.827130675315857
Validation loss: 2.101184719352312

Epoch: 6| Step: 8
Training loss: 2.0925240516662598
Validation loss: 2.0691403291558705

Epoch: 6| Step: 9
Training loss: 2.2710280418395996
Validation loss: 2.084499796231588

Epoch: 6| Step: 10
Training loss: 2.303703784942627
Validation loss: 2.0906591415405273

Epoch: 6| Step: 11
Training loss: 2.2586512565612793
Validation loss: 2.0821583809391147

Epoch: 6| Step: 12
Training loss: 2.1811881065368652
Validation loss: 2.0718174108894925

Epoch: 6| Step: 13
Training loss: 1.8916882276535034
Validation loss: 2.090848881711242

Epoch: 109| Step: 0
Training loss: 1.6034674644470215
Validation loss: 2.0813003534911783

Epoch: 6| Step: 1
Training loss: 2.250694751739502
Validation loss: 2.062184541456161

Epoch: 6| Step: 2
Training loss: 2.794501543045044
Validation loss: 2.076985979592928

Epoch: 6| Step: 3
Training loss: 2.8913097381591797
Validation loss: 2.0689785070316766

Epoch: 6| Step: 4
Training loss: 2.568751335144043
Validation loss: 2.091639280319214

Epoch: 6| Step: 5
Training loss: 1.931692361831665
Validation loss: 2.0678294320260324

Epoch: 6| Step: 6
Training loss: 1.7839082479476929
Validation loss: 2.0777002342285646

Epoch: 6| Step: 7
Training loss: 2.313518524169922
Validation loss: 2.0781331152044316

Epoch: 6| Step: 8
Training loss: 1.5212061405181885
Validation loss: 2.075473141926591

Epoch: 6| Step: 9
Training loss: 1.7760562896728516
Validation loss: 2.0996389683856758

Epoch: 6| Step: 10
Training loss: 2.472439765930176
Validation loss: 2.0809220216607534

Epoch: 6| Step: 11
Training loss: 2.0738747119903564
Validation loss: 2.0787153359382384

Epoch: 6| Step: 12
Training loss: 2.109084129333496
Validation loss: 2.0854818308225243

Epoch: 6| Step: 13
Training loss: 1.886107087135315
Validation loss: 2.08874076156206

Epoch: 110| Step: 0
Training loss: 1.8448461294174194
Validation loss: 2.0767216169705955

Epoch: 6| Step: 1
Training loss: 1.6807628870010376
Validation loss: 2.0831882261460826

Epoch: 6| Step: 2
Training loss: 2.3434598445892334
Validation loss: 2.082690743989842

Epoch: 6| Step: 3
Training loss: 2.055976390838623
Validation loss: 2.063570980102785

Epoch: 6| Step: 4
Training loss: 1.9562432765960693
Validation loss: 2.0753614082131335

Epoch: 6| Step: 5
Training loss: 2.1755361557006836
Validation loss: 2.094036025385703

Epoch: 6| Step: 6
Training loss: 2.26766037940979
Validation loss: 2.0900878444794686

Epoch: 6| Step: 7
Training loss: 1.98385751247406
Validation loss: 2.108444898359237

Epoch: 6| Step: 8
Training loss: 1.6773639917373657
Validation loss: 2.082781755796043

Epoch: 6| Step: 9
Training loss: 2.08484148979187
Validation loss: 2.0837186780027164

Epoch: 6| Step: 10
Training loss: 1.9582409858703613
Validation loss: 2.0738876788846907

Epoch: 6| Step: 11
Training loss: 2.8990259170532227
Validation loss: 2.068701192896853

Epoch: 6| Step: 12
Training loss: 2.499403953552246
Validation loss: 2.074833899415949

Epoch: 6| Step: 13
Training loss: 2.806746482849121
Validation loss: 2.0873882180900982

Epoch: 111| Step: 0
Training loss: 2.7528152465820312
Validation loss: 2.0867099659417265

Epoch: 6| Step: 1
Training loss: 2.212012767791748
Validation loss: 2.0821917262128604

Epoch: 6| Step: 2
Training loss: 2.129422903060913
Validation loss: 2.093596660962669

Epoch: 6| Step: 3
Training loss: 2.204726219177246
Validation loss: 2.0790052798486527

Epoch: 6| Step: 4
Training loss: 2.788785457611084
Validation loss: 2.0867554295447563

Epoch: 6| Step: 5
Training loss: 1.7883288860321045
Validation loss: 2.100573629461309

Epoch: 6| Step: 6
Training loss: 2.2976484298706055
Validation loss: 2.0774646112995763

Epoch: 6| Step: 7
Training loss: 1.754513144493103
Validation loss: 2.0861906723309587

Epoch: 6| Step: 8
Training loss: 1.6867735385894775
Validation loss: 2.0963261409472396

Epoch: 6| Step: 9
Training loss: 2.0552353858947754
Validation loss: 2.0810533467159478

Epoch: 6| Step: 10
Training loss: 1.8779815435409546
Validation loss: 2.0974413015509166

Epoch: 6| Step: 11
Training loss: 2.7201180458068848
Validation loss: 2.083849710802878

Epoch: 6| Step: 12
Training loss: 1.5152335166931152
Validation loss: 2.0963226364504908

Epoch: 6| Step: 13
Training loss: 2.339902877807617
Validation loss: 2.08910442936805

Epoch: 112| Step: 0
Training loss: 2.3265109062194824
Validation loss: 2.0899320264016428

Epoch: 6| Step: 1
Training loss: 2.369410514831543
Validation loss: 2.0773083625301236

Epoch: 6| Step: 2
Training loss: 1.3491322994232178
Validation loss: 2.073481358507628

Epoch: 6| Step: 3
Training loss: 1.6841846704483032
Validation loss: 2.0811236545603764

Epoch: 6| Step: 4
Training loss: 2.4982337951660156
Validation loss: 2.068603241315452

Epoch: 6| Step: 5
Training loss: 1.9702825546264648
Validation loss: 2.07746547268283

Epoch: 6| Step: 6
Training loss: 1.8929054737091064
Validation loss: 2.073071350333511

Epoch: 6| Step: 7
Training loss: 2.6389424800872803
Validation loss: 2.0709870117966847

Epoch: 6| Step: 8
Training loss: 2.3615617752075195
Validation loss: 2.077344391935615

Epoch: 6| Step: 9
Training loss: 2.203209638595581
Validation loss: 2.062979949417935

Epoch: 6| Step: 10
Training loss: 2.145609140396118
Validation loss: 2.080195765341482

Epoch: 6| Step: 11
Training loss: 1.7499703168869019
Validation loss: 2.063995579237579

Epoch: 6| Step: 12
Training loss: 2.6886959075927734
Validation loss: 2.077747001442858

Epoch: 6| Step: 13
Training loss: 2.2078137397766113
Validation loss: 2.0611644124472015

Epoch: 113| Step: 0
Training loss: 1.439150333404541
Validation loss: 2.0751727806624545

Epoch: 6| Step: 1
Training loss: 2.3822834491729736
Validation loss: 2.0795798404242403

Epoch: 6| Step: 2
Training loss: 1.8183274269104004
Validation loss: 2.079840124294322

Epoch: 6| Step: 3
Training loss: 2.7257440090179443
Validation loss: 2.085029617432625

Epoch: 6| Step: 4
Training loss: 1.4964091777801514
Validation loss: 2.0885946584004227

Epoch: 6| Step: 5
Training loss: 2.4894564151763916
Validation loss: 2.1044672945494294

Epoch: 6| Step: 6
Training loss: 2.099699020385742
Validation loss: 2.077966772099977

Epoch: 6| Step: 7
Training loss: 2.372788667678833
Validation loss: 2.0863494719228437

Epoch: 6| Step: 8
Training loss: 1.769856333732605
Validation loss: 2.087212442069925

Epoch: 6| Step: 9
Training loss: 2.1487340927124023
Validation loss: 2.1018182769898446

Epoch: 6| Step: 10
Training loss: 2.627129077911377
Validation loss: 2.082285242695962

Epoch: 6| Step: 11
Training loss: 2.0162510871887207
Validation loss: 2.08301293593581

Epoch: 6| Step: 12
Training loss: 2.1972696781158447
Validation loss: 2.0753031904979418

Epoch: 6| Step: 13
Training loss: 2.3276824951171875
Validation loss: 2.082652712381014

Epoch: 114| Step: 0
Training loss: 2.891036033630371
Validation loss: 2.0881381483488184

Epoch: 6| Step: 1
Training loss: 2.4967546463012695
Validation loss: 2.071620754016343

Epoch: 6| Step: 2
Training loss: 2.309774160385132
Validation loss: 2.0631486767081806

Epoch: 6| Step: 3
Training loss: 2.021162986755371
Validation loss: 2.0903652086052844

Epoch: 6| Step: 4
Training loss: 1.6799148321151733
Validation loss: 2.0681553720146097

Epoch: 6| Step: 5
Training loss: 2.3974289894104004
Validation loss: 2.069706186171501

Epoch: 6| Step: 6
Training loss: 2.9124348163604736
Validation loss: 2.0795234787848687

Epoch: 6| Step: 7
Training loss: 2.1295247077941895
Validation loss: 2.085407862099268

Epoch: 6| Step: 8
Training loss: 1.3229520320892334
Validation loss: 2.075032252137379

Epoch: 6| Step: 9
Training loss: 2.1421639919281006
Validation loss: 2.072236627660772

Epoch: 6| Step: 10
Training loss: 2.1362338066101074
Validation loss: 2.070489937259305

Epoch: 6| Step: 11
Training loss: 1.9850170612335205
Validation loss: 2.076080964457604

Epoch: 6| Step: 12
Training loss: 1.7521785497665405
Validation loss: 2.098293448007235

Epoch: 6| Step: 13
Training loss: 1.5554431676864624
Validation loss: 2.062681790321104

Epoch: 115| Step: 0
Training loss: 2.4201173782348633
Validation loss: 2.075464174311648

Epoch: 6| Step: 1
Training loss: 2.2387309074401855
Validation loss: 2.067928837191674

Epoch: 6| Step: 2
Training loss: 1.5877937078475952
Validation loss: 2.0889212739083076

Epoch: 6| Step: 3
Training loss: 2.901247501373291
Validation loss: 2.054829728218817

Epoch: 6| Step: 4
Training loss: 2.365607261657715
Validation loss: 2.0805092832093597

Epoch: 6| Step: 5
Training loss: 2.003690242767334
Validation loss: 2.093611071186681

Epoch: 6| Step: 6
Training loss: 1.6954277753829956
Validation loss: 2.068101521461241

Epoch: 6| Step: 7
Training loss: 1.6455928087234497
Validation loss: 2.0762200637530257

Epoch: 6| Step: 8
Training loss: 2.456822395324707
Validation loss: 2.0914913377454205

Epoch: 6| Step: 9
Training loss: 2.439408779144287
Validation loss: 2.0667773549274733

Epoch: 6| Step: 10
Training loss: 1.6846730709075928
Validation loss: 2.0929970818181194

Epoch: 6| Step: 11
Training loss: 1.8217706680297852
Validation loss: 2.0873120548904582

Epoch: 6| Step: 12
Training loss: 2.0780978202819824
Validation loss: 2.088120234909878

Epoch: 6| Step: 13
Training loss: 2.6236424446105957
Validation loss: 2.08580510334302

Epoch: 116| Step: 0
Training loss: 2.1949291229248047
Validation loss: 2.0937790755302674

Epoch: 6| Step: 1
Training loss: 2.186459541320801
Validation loss: 2.0959453864764144

Epoch: 6| Step: 2
Training loss: 1.6875150203704834
Validation loss: 2.0795525171423472

Epoch: 6| Step: 3
Training loss: 2.402510643005371
Validation loss: 2.0745335253336097

Epoch: 6| Step: 4
Training loss: 2.4429373741149902
Validation loss: 2.071805157969075

Epoch: 6| Step: 5
Training loss: 1.7708983421325684
Validation loss: 2.063702534603816

Epoch: 6| Step: 6
Training loss: 2.591114044189453
Validation loss: 2.0820666846408638

Epoch: 6| Step: 7
Training loss: 1.7488622665405273
Validation loss: 2.0740143022229596

Epoch: 6| Step: 8
Training loss: 1.9022071361541748
Validation loss: 2.0649225775913527

Epoch: 6| Step: 9
Training loss: 2.108513593673706
Validation loss: 2.0875727681703466

Epoch: 6| Step: 10
Training loss: 2.2321877479553223
Validation loss: 2.0597728388283842

Epoch: 6| Step: 11
Training loss: 2.4782276153564453
Validation loss: 2.0692878897472093

Epoch: 6| Step: 12
Training loss: 1.9908627271652222
Validation loss: 2.0874381680642404

Epoch: 6| Step: 13
Training loss: 2.173495054244995
Validation loss: 2.08548552502868

Epoch: 117| Step: 0
Training loss: 2.68935227394104
Validation loss: 2.0759178541039907

Epoch: 6| Step: 1
Training loss: 1.5535438060760498
Validation loss: 2.0754634949468795

Epoch: 6| Step: 2
Training loss: 1.8920906782150269
Validation loss: 2.0856372592269734

Epoch: 6| Step: 3
Training loss: 2.171849489212036
Validation loss: 2.0822788259034515

Epoch: 6| Step: 4
Training loss: 1.9298067092895508
Validation loss: 2.0783622777590187

Epoch: 6| Step: 5
Training loss: 2.616878032684326
Validation loss: 2.0735348245149017

Epoch: 6| Step: 6
Training loss: 3.0199482440948486
Validation loss: 2.0806373216772593

Epoch: 6| Step: 7
Training loss: 2.10164737701416
Validation loss: 2.0781013273423716

Epoch: 6| Step: 8
Training loss: 1.6644649505615234
Validation loss: 2.0678515588083575

Epoch: 6| Step: 9
Training loss: 2.5080325603485107
Validation loss: 2.0756470772527877

Epoch: 6| Step: 10
Training loss: 1.86966073513031
Validation loss: 2.0833795275739444

Epoch: 6| Step: 11
Training loss: 1.8459351062774658
Validation loss: 2.0785975533147014

Epoch: 6| Step: 12
Training loss: 2.177401542663574
Validation loss: 2.07793523675652

Epoch: 6| Step: 13
Training loss: 1.626758337020874
Validation loss: 2.0796381094122447

Epoch: 118| Step: 0
Training loss: 1.8264999389648438
Validation loss: 2.0719208332800094

Epoch: 6| Step: 1
Training loss: 1.442389726638794
Validation loss: 2.089912058204733

Epoch: 6| Step: 2
Training loss: 2.6971611976623535
Validation loss: 2.0725389219099477

Epoch: 6| Step: 3
Training loss: 2.206181526184082
Validation loss: 2.067785706571353

Epoch: 6| Step: 4
Training loss: 2.6079025268554688
Validation loss: 2.0844357680248957

Epoch: 6| Step: 5
Training loss: 1.9078348875045776
Validation loss: 2.0722354073678293

Epoch: 6| Step: 6
Training loss: 2.0778403282165527
Validation loss: 2.094497561454773

Epoch: 6| Step: 7
Training loss: 2.1175694465637207
Validation loss: 2.062250952566824

Epoch: 6| Step: 8
Training loss: 2.0656447410583496
Validation loss: 2.0853328679197576

Epoch: 6| Step: 9
Training loss: 2.4045095443725586
Validation loss: 2.0700348192645657

Epoch: 6| Step: 10
Training loss: 1.969829797744751
Validation loss: 2.0786254021429245

Epoch: 6| Step: 11
Training loss: 2.0491652488708496
Validation loss: 2.087857918072772

Epoch: 6| Step: 12
Training loss: 1.9272704124450684
Validation loss: 2.0763085875459897

Epoch: 6| Step: 13
Training loss: 2.503980875015259
Validation loss: 2.078383286794027

Epoch: 119| Step: 0
Training loss: 1.9351568222045898
Validation loss: 2.0893073876698813

Epoch: 6| Step: 1
Training loss: 1.5272891521453857
Validation loss: 2.0833071534351637

Epoch: 6| Step: 2
Training loss: 2.5977275371551514
Validation loss: 2.0699515240166777

Epoch: 6| Step: 3
Training loss: 1.819596529006958
Validation loss: 2.0607366267070977

Epoch: 6| Step: 4
Training loss: 1.6317189931869507
Validation loss: 2.065391114962998

Epoch: 6| Step: 5
Training loss: 2.1998391151428223
Validation loss: 2.0724591567952144

Epoch: 6| Step: 6
Training loss: 3.444639205932617
Validation loss: 2.0762490534013316

Epoch: 6| Step: 7
Training loss: 1.4629054069519043
Validation loss: 2.0543355903317853

Epoch: 6| Step: 8
Training loss: 2.071545124053955
Validation loss: 2.0687974986209663

Epoch: 6| Step: 9
Training loss: 2.0342354774475098
Validation loss: 2.064889092599192

Epoch: 6| Step: 10
Training loss: 2.0522193908691406
Validation loss: 2.087038669534909

Epoch: 6| Step: 11
Training loss: 2.37953519821167
Validation loss: 2.067986403742144

Epoch: 6| Step: 12
Training loss: 2.240316867828369
Validation loss: 2.0775115797596593

Epoch: 6| Step: 13
Training loss: 2.6917202472686768
Validation loss: 2.0616212403902443

Epoch: 120| Step: 0
Training loss: 1.7729036808013916
Validation loss: 2.0592396156762236

Epoch: 6| Step: 1
Training loss: 1.9243913888931274
Validation loss: 2.0748024704635784

Epoch: 6| Step: 2
Training loss: 2.281799077987671
Validation loss: 2.063399182852878

Epoch: 6| Step: 3
Training loss: 2.4180281162261963
Validation loss: 2.0720325849389516

Epoch: 6| Step: 4
Training loss: 2.183802604675293
Validation loss: 2.0612827603534987

Epoch: 6| Step: 5
Training loss: 1.8154065608978271
Validation loss: 2.0558732991577475

Epoch: 6| Step: 6
Training loss: 2.043567180633545
Validation loss: 2.0847294087051065

Epoch: 6| Step: 7
Training loss: 1.6741337776184082
Validation loss: 2.06057563904793

Epoch: 6| Step: 8
Training loss: 2.005581855773926
Validation loss: 2.0631431789808374

Epoch: 6| Step: 9
Training loss: 2.233983039855957
Validation loss: 2.0775492345133135

Epoch: 6| Step: 10
Training loss: 2.3274030685424805
Validation loss: 2.071274229275283

Epoch: 6| Step: 11
Training loss: 2.258178472518921
Validation loss: 2.063262075506231

Epoch: 6| Step: 12
Training loss: 2.4543652534484863
Validation loss: 2.061883412381654

Epoch: 6| Step: 13
Training loss: 2.6370701789855957
Validation loss: 2.0522050857543945

Epoch: 121| Step: 0
Training loss: 2.594119071960449
Validation loss: 2.0881828210687123

Epoch: 6| Step: 1
Training loss: 2.0183186531066895
Validation loss: 2.0800248986931256

Epoch: 6| Step: 2
Training loss: 1.749910593032837
Validation loss: 2.0800999300454253

Epoch: 6| Step: 3
Training loss: 2.3230533599853516
Validation loss: 2.055502471103463

Epoch: 6| Step: 4
Training loss: 1.9574670791625977
Validation loss: 2.079235488368619

Epoch: 6| Step: 5
Training loss: 2.051290512084961
Validation loss: 2.088893111034106

Epoch: 6| Step: 6
Training loss: 1.9745229482650757
Validation loss: 2.05542685908656

Epoch: 6| Step: 7
Training loss: 1.9468693733215332
Validation loss: 2.062656661515595

Epoch: 6| Step: 8
Training loss: 2.456329584121704
Validation loss: 2.0870336704356696

Epoch: 6| Step: 9
Training loss: 2.232314109802246
Validation loss: 2.074976823663199

Epoch: 6| Step: 10
Training loss: 2.258396863937378
Validation loss: 2.0719165289273827

Epoch: 6| Step: 11
Training loss: 2.470568895339966
Validation loss: 2.090488362055953

Epoch: 6| Step: 12
Training loss: 1.9492300748825073
Validation loss: 2.0684762026674006

Epoch: 6| Step: 13
Training loss: 1.611816167831421
Validation loss: 2.075447831102597

Epoch: 122| Step: 0
Training loss: 1.8215175867080688
Validation loss: 2.066706730473426

Epoch: 6| Step: 1
Training loss: 2.1308865547180176
Validation loss: 2.083849714648339

Epoch: 6| Step: 2
Training loss: 2.1065237522125244
Validation loss: 2.09396985525726

Epoch: 6| Step: 3
Training loss: 2.7414939403533936
Validation loss: 2.080968012091934

Epoch: 6| Step: 4
Training loss: 2.3690686225891113
Validation loss: 2.0815966270303212

Epoch: 6| Step: 5
Training loss: 2.36159086227417
Validation loss: 2.0648183707268006

Epoch: 6| Step: 6
Training loss: 1.6073203086853027
Validation loss: 2.0767244010843258

Epoch: 6| Step: 7
Training loss: 2.1914541721343994
Validation loss: 2.0767496849900935

Epoch: 6| Step: 8
Training loss: 2.419888973236084
Validation loss: 2.1071767319915113

Epoch: 6| Step: 9
Training loss: 1.905683159828186
Validation loss: 2.0999571328522055

Epoch: 6| Step: 10
Training loss: 1.9700043201446533
Validation loss: 2.074556703208595

Epoch: 6| Step: 11
Training loss: 1.946090817451477
Validation loss: 2.089520342888371

Epoch: 6| Step: 12
Training loss: 1.8507537841796875
Validation loss: 2.0744518400520406

Epoch: 6| Step: 13
Training loss: 2.354482650756836
Validation loss: 2.0658529125234133

Epoch: 123| Step: 0
Training loss: 2.2467174530029297
Validation loss: 2.075581499325332

Epoch: 6| Step: 1
Training loss: 1.954718828201294
Validation loss: 2.0809799419936312

Epoch: 6| Step: 2
Training loss: 2.4821362495422363
Validation loss: 2.0686610591027046

Epoch: 6| Step: 3
Training loss: 2.308770179748535
Validation loss: 2.0809695079762447

Epoch: 6| Step: 4
Training loss: 1.6239657402038574
Validation loss: 2.070255192377234

Epoch: 6| Step: 5
Training loss: 2.019529104232788
Validation loss: 2.07259802920844

Epoch: 6| Step: 6
Training loss: 2.5597498416900635
Validation loss: 2.0718676800368936

Epoch: 6| Step: 7
Training loss: 2.094618558883667
Validation loss: 2.0694892086008543

Epoch: 6| Step: 8
Training loss: 2.5864243507385254
Validation loss: 2.067656978484123

Epoch: 6| Step: 9
Training loss: 1.7859065532684326
Validation loss: 2.0677331480928647

Epoch: 6| Step: 10
Training loss: 2.1396596431732178
Validation loss: 2.0770805061504407

Epoch: 6| Step: 11
Training loss: 2.6256816387176514
Validation loss: 2.068834417609758

Epoch: 6| Step: 12
Training loss: 1.4741816520690918
Validation loss: 2.0838424723635436

Epoch: 6| Step: 13
Training loss: 1.6346631050109863
Validation loss: 2.0640347029573176

Epoch: 124| Step: 0
Training loss: 2.1111204624176025
Validation loss: 2.0659164228746967

Epoch: 6| Step: 1
Training loss: 2.5034756660461426
Validation loss: 2.0607388378471456

Epoch: 6| Step: 2
Training loss: 2.144618511199951
Validation loss: 2.065403155101243

Epoch: 6| Step: 3
Training loss: 2.261404275894165
Validation loss: 2.0820783338239117

Epoch: 6| Step: 4
Training loss: 1.816035509109497
Validation loss: 2.06867782274882

Epoch: 6| Step: 5
Training loss: 2.2699921131134033
Validation loss: 2.0761300748394382

Epoch: 6| Step: 6
Training loss: 0.9475711584091187
Validation loss: 2.0712494465612594

Epoch: 6| Step: 7
Training loss: 2.4699783325195312
Validation loss: 2.0605419579372612

Epoch: 6| Step: 8
Training loss: 2.512840986251831
Validation loss: 2.064535771646807

Epoch: 6| Step: 9
Training loss: 1.9839816093444824
Validation loss: 2.0518702178873043

Epoch: 6| Step: 10
Training loss: 2.036841869354248
Validation loss: 2.0571120733855874

Epoch: 6| Step: 11
Training loss: 2.0229716300964355
Validation loss: 2.082668742825908

Epoch: 6| Step: 12
Training loss: 2.4520721435546875
Validation loss: 2.0615283366172545

Epoch: 6| Step: 13
Training loss: 1.976513385772705
Validation loss: 2.0862688992613103

Epoch: 125| Step: 0
Training loss: 1.7402691841125488
Validation loss: 2.061158731419553

Epoch: 6| Step: 1
Training loss: 1.8923872709274292
Validation loss: 2.0546954447223293

Epoch: 6| Step: 2
Training loss: 2.2907323837280273
Validation loss: 2.0630057178517824

Epoch: 6| Step: 3
Training loss: 2.11983323097229
Validation loss: 2.0530277221433577

Epoch: 6| Step: 4
Training loss: 1.8110737800598145
Validation loss: 2.066448667997955

Epoch: 6| Step: 5
Training loss: 2.203148603439331
Validation loss: 2.0595005135382376

Epoch: 6| Step: 6
Training loss: 2.4088220596313477
Validation loss: 2.0788706066787883

Epoch: 6| Step: 7
Training loss: 2.5843663215637207
Validation loss: 2.0655050777619883

Epoch: 6| Step: 8
Training loss: 2.4284558296203613
Validation loss: 2.05024984575087

Epoch: 6| Step: 9
Training loss: 1.242983102798462
Validation loss: 2.0560447746707546

Epoch: 6| Step: 10
Training loss: 2.1165225505828857
Validation loss: 2.072382534703901

Epoch: 6| Step: 11
Training loss: 2.515617847442627
Validation loss: 2.0493335211148827

Epoch: 6| Step: 12
Training loss: 2.319265127182007
Validation loss: 2.0435525678819224

Epoch: 6| Step: 13
Training loss: 1.8119629621505737
Validation loss: 2.0677487670734362

Epoch: 126| Step: 0
Training loss: 1.989665150642395
Validation loss: 2.0827983143509075

Epoch: 6| Step: 1
Training loss: 1.690568447113037
Validation loss: 2.081153162064091

Epoch: 6| Step: 2
Training loss: 2.248377799987793
Validation loss: 2.0601060595563663

Epoch: 6| Step: 3
Training loss: 2.189588785171509
Validation loss: 2.0639897572096957

Epoch: 6| Step: 4
Training loss: 2.146587371826172
Validation loss: 2.056465912890691

Epoch: 6| Step: 5
Training loss: 2.452208995819092
Validation loss: 2.0513617479672996

Epoch: 6| Step: 6
Training loss: 1.9501137733459473
Validation loss: 2.065330200297858

Epoch: 6| Step: 7
Training loss: 2.324469804763794
Validation loss: 2.0828458686028757

Epoch: 6| Step: 8
Training loss: 2.284595012664795
Validation loss: 2.066659164685075

Epoch: 6| Step: 9
Training loss: 1.5281025171279907
Validation loss: 2.0714877536219936

Epoch: 6| Step: 10
Training loss: 2.17818021774292
Validation loss: 2.071598478542861

Epoch: 6| Step: 11
Training loss: 1.8442574739456177
Validation loss: 2.0585690339406333

Epoch: 6| Step: 12
Training loss: 2.28222918510437
Validation loss: 2.0516022405316754

Epoch: 6| Step: 13
Training loss: 2.8389999866485596
Validation loss: 2.0500147188863447

Epoch: 127| Step: 0
Training loss: 1.7880446910858154
Validation loss: 2.0686873851283902

Epoch: 6| Step: 1
Training loss: 1.3655545711517334
Validation loss: 2.054195938571807

Epoch: 6| Step: 2
Training loss: 1.7538807392120361
Validation loss: 2.050545113061064

Epoch: 6| Step: 3
Training loss: 1.69744873046875
Validation loss: 2.0521037347855104

Epoch: 6| Step: 4
Training loss: 2.53294038772583
Validation loss: 2.0703902859841623

Epoch: 6| Step: 5
Training loss: 2.561100482940674
Validation loss: 2.0762293774594545

Epoch: 6| Step: 6
Training loss: 2.8176732063293457
Validation loss: 2.063683784136208

Epoch: 6| Step: 7
Training loss: 2.6191635131835938
Validation loss: 2.0639824457066034

Epoch: 6| Step: 8
Training loss: 1.6706680059432983
Validation loss: 2.0689295440591793

Epoch: 6| Step: 9
Training loss: 2.20609974861145
Validation loss: 2.081357753405007

Epoch: 6| Step: 10
Training loss: 2.511011838912964
Validation loss: 2.058684654133294

Epoch: 6| Step: 11
Training loss: 2.201390504837036
Validation loss: 2.062753906814001

Epoch: 6| Step: 12
Training loss: 2.0485472679138184
Validation loss: 2.0676966226229103

Epoch: 6| Step: 13
Training loss: 1.3505662679672241
Validation loss: 2.0451786107914423

Epoch: 128| Step: 0
Training loss: 2.2211313247680664
Validation loss: 2.0611094992647887

Epoch: 6| Step: 1
Training loss: 2.365370273590088
Validation loss: 2.042479210002448

Epoch: 6| Step: 2
Training loss: 1.744559407234192
Validation loss: 2.0723288084871028

Epoch: 6| Step: 3
Training loss: 1.9056639671325684
Validation loss: 2.0516909988977576

Epoch: 6| Step: 4
Training loss: 2.2734484672546387
Validation loss: 2.0574850484889042

Epoch: 6| Step: 5
Training loss: 2.1767115592956543
Validation loss: 2.045907720442741

Epoch: 6| Step: 6
Training loss: 1.8317807912826538
Validation loss: 2.0567571219577583

Epoch: 6| Step: 7
Training loss: 1.7490085363388062
Validation loss: 2.080299944005987

Epoch: 6| Step: 8
Training loss: 1.6736533641815186
Validation loss: 2.0588230522730018

Epoch: 6| Step: 9
Training loss: 2.5121912956237793
Validation loss: 2.0482236851928053

Epoch: 6| Step: 10
Training loss: 2.219529151916504
Validation loss: 2.0401617839772213

Epoch: 6| Step: 11
Training loss: 2.1814656257629395
Validation loss: 2.061565242787843

Epoch: 6| Step: 12
Training loss: 2.32146954536438
Validation loss: 2.0673421787959274

Epoch: 6| Step: 13
Training loss: 2.2211499214172363
Validation loss: 2.0756480847635577

Epoch: 129| Step: 0
Training loss: 1.9493496417999268
Validation loss: 2.0354641099129953

Epoch: 6| Step: 1
Training loss: 1.5255167484283447
Validation loss: 2.0503439903259277

Epoch: 6| Step: 2
Training loss: 2.407383680343628
Validation loss: 2.0561786031210296

Epoch: 6| Step: 3
Training loss: 2.0455732345581055
Validation loss: 2.0299247131552747

Epoch: 6| Step: 4
Training loss: 1.8055129051208496
Validation loss: 2.060387365279659

Epoch: 6| Step: 5
Training loss: 2.4417476654052734
Validation loss: 2.058833933645679

Epoch: 6| Step: 6
Training loss: 2.2925243377685547
Validation loss: 2.0492149001808575

Epoch: 6| Step: 7
Training loss: 2.4696009159088135
Validation loss: 2.068658196797935

Epoch: 6| Step: 8
Training loss: 1.9713919162750244
Validation loss: 2.068432992504489

Epoch: 6| Step: 9
Training loss: 2.2061991691589355
Validation loss: 2.074489449941984

Epoch: 6| Step: 10
Training loss: 1.9199483394622803
Validation loss: 2.0706631906570925

Epoch: 6| Step: 11
Training loss: 1.7871410846710205
Validation loss: 2.0420140566364413

Epoch: 6| Step: 12
Training loss: 2.4550607204437256
Validation loss: 2.0555858201878046

Epoch: 6| Step: 13
Training loss: 2.4641048908233643
Validation loss: 2.068805069051763

Epoch: 130| Step: 0
Training loss: 1.5878627300262451
Validation loss: 2.047696831405804

Epoch: 6| Step: 1
Training loss: 1.6048827171325684
Validation loss: 2.0549944972479217

Epoch: 6| Step: 2
Training loss: 2.2555861473083496
Validation loss: 2.074013025529923

Epoch: 6| Step: 3
Training loss: 2.1968252658843994
Validation loss: 2.0591358471942205

Epoch: 6| Step: 4
Training loss: 1.7679511308670044
Validation loss: 2.06003003222968

Epoch: 6| Step: 5
Training loss: 2.5268754959106445
Validation loss: 2.065916017819476

Epoch: 6| Step: 6
Training loss: 1.8321123123168945
Validation loss: 2.073944527615783

Epoch: 6| Step: 7
Training loss: 2.730013847351074
Validation loss: 2.076009063310521

Epoch: 6| Step: 8
Training loss: 2.2946934700012207
Validation loss: 2.0592595351639615

Epoch: 6| Step: 9
Training loss: 1.912784457206726
Validation loss: 2.07438559942348

Epoch: 6| Step: 10
Training loss: 2.447847843170166
Validation loss: 2.0657787553725706

Epoch: 6| Step: 11
Training loss: 1.8627744913101196
Validation loss: 2.0591059192534416

Epoch: 6| Step: 12
Training loss: 2.2015295028686523
Validation loss: 2.0675780824435654

Epoch: 6| Step: 13
Training loss: 2.4236059188842773
Validation loss: 2.0607704116452124

Epoch: 131| Step: 0
Training loss: 2.2415032386779785
Validation loss: 2.0695869256091375

Epoch: 6| Step: 1
Training loss: 1.5501558780670166
Validation loss: 2.0423874880677912

Epoch: 6| Step: 2
Training loss: 2.0698652267456055
Validation loss: 2.065592345371041

Epoch: 6| Step: 3
Training loss: 1.9316521883010864
Validation loss: 2.0623134361800326

Epoch: 6| Step: 4
Training loss: 2.5981621742248535
Validation loss: 2.043536182372801

Epoch: 6| Step: 5
Training loss: 2.392191171646118
Validation loss: 2.033761594885139

Epoch: 6| Step: 6
Training loss: 1.9798047542572021
Validation loss: 2.06462251499135

Epoch: 6| Step: 7
Training loss: 1.5368447303771973
Validation loss: 2.0526706390483405

Epoch: 6| Step: 8
Training loss: 2.1240856647491455
Validation loss: 2.0553181350872083

Epoch: 6| Step: 9
Training loss: 2.8335134983062744
Validation loss: 2.06606976960295

Epoch: 6| Step: 10
Training loss: 2.001270294189453
Validation loss: 2.050816494931457

Epoch: 6| Step: 11
Training loss: 1.564316749572754
Validation loss: 2.064639535001529

Epoch: 6| Step: 12
Training loss: 2.3150479793548584
Validation loss: 2.0496485938308058

Epoch: 6| Step: 13
Training loss: 2.3219542503356934
Validation loss: 2.051061950704103

Epoch: 132| Step: 0
Training loss: 1.993788480758667
Validation loss: 2.0474497810486825

Epoch: 6| Step: 1
Training loss: 2.515618324279785
Validation loss: 2.0548479172491256

Epoch: 6| Step: 2
Training loss: 2.0227363109588623
Validation loss: 2.0487706635587957

Epoch: 6| Step: 3
Training loss: 1.9813799858093262
Validation loss: 2.0547352042249454

Epoch: 6| Step: 4
Training loss: 2.154364585876465
Validation loss: 2.044527807543355

Epoch: 6| Step: 5
Training loss: 2.075667381286621
Validation loss: 2.0324606818537556

Epoch: 6| Step: 6
Training loss: 2.4074079990386963
Validation loss: 2.0443134051497265

Epoch: 6| Step: 7
Training loss: 1.7119547128677368
Validation loss: 2.047764075699673

Epoch: 6| Step: 8
Training loss: 2.3140575885772705
Validation loss: 2.0360757074048443

Epoch: 6| Step: 9
Training loss: 2.128024101257324
Validation loss: 2.0478973337399062

Epoch: 6| Step: 10
Training loss: 2.054701805114746
Validation loss: 2.0473302846313803

Epoch: 6| Step: 11
Training loss: 2.183112859725952
Validation loss: 2.04843424084366

Epoch: 6| Step: 12
Training loss: 2.071709156036377
Validation loss: 2.056470250570646

Epoch: 6| Step: 13
Training loss: 1.205766201019287
Validation loss: 2.057291382102556

Epoch: 133| Step: 0
Training loss: 1.6103930473327637
Validation loss: 2.045044437531502

Epoch: 6| Step: 1
Training loss: 1.3134558200836182
Validation loss: 2.0556281356401342

Epoch: 6| Step: 2
Training loss: 2.366645097732544
Validation loss: 2.0736282999797533

Epoch: 6| Step: 3
Training loss: 2.0968594551086426
Validation loss: 2.0510725231580835

Epoch: 6| Step: 4
Training loss: 2.1335997581481934
Validation loss: 2.058288385791163

Epoch: 6| Step: 5
Training loss: 1.9114314317703247
Validation loss: 2.057449162647288

Epoch: 6| Step: 6
Training loss: 3.4059383869171143
Validation loss: 2.0410599606011504

Epoch: 6| Step: 7
Training loss: 1.9209835529327393
Validation loss: 2.0568575769342403

Epoch: 6| Step: 8
Training loss: 1.3402917385101318
Validation loss: 2.0530785899008475

Epoch: 6| Step: 9
Training loss: 2.1416878700256348
Validation loss: 2.049347657029347

Epoch: 6| Step: 10
Training loss: 2.291257381439209
Validation loss: 2.07318526698697

Epoch: 6| Step: 11
Training loss: 2.499544620513916
Validation loss: 2.070350403426796

Epoch: 6| Step: 12
Training loss: 2.3604979515075684
Validation loss: 2.0566131632815123

Epoch: 6| Step: 13
Training loss: 1.9683314561843872
Validation loss: 2.05027384783632

Epoch: 134| Step: 0
Training loss: 2.26560378074646
Validation loss: 2.0494292320743686

Epoch: 6| Step: 1
Training loss: 1.4999338388442993
Validation loss: 2.0579849827674126

Epoch: 6| Step: 2
Training loss: 1.8573577404022217
Validation loss: 2.061397280744327

Epoch: 6| Step: 3
Training loss: 1.6901007890701294
Validation loss: 2.0447158005929764

Epoch: 6| Step: 4
Training loss: 2.492687463760376
Validation loss: 2.046156483311807

Epoch: 6| Step: 5
Training loss: 1.3737187385559082
Validation loss: 2.050360010516259

Epoch: 6| Step: 6
Training loss: 1.8510699272155762
Validation loss: 2.0629146688727924

Epoch: 6| Step: 7
Training loss: 3.0618412494659424
Validation loss: 2.0411486305216306

Epoch: 6| Step: 8
Training loss: 2.443662643432617
Validation loss: 2.061502448974117

Epoch: 6| Step: 9
Training loss: 1.9418741464614868
Validation loss: 2.0548517575827976

Epoch: 6| Step: 10
Training loss: 2.018641471862793
Validation loss: 2.0608420295100056

Epoch: 6| Step: 11
Training loss: 1.8556947708129883
Validation loss: 2.054923201120028

Epoch: 6| Step: 12
Training loss: 2.9673547744750977
Validation loss: 2.0653227990673435

Epoch: 6| Step: 13
Training loss: 1.6841336488723755
Validation loss: 2.0556161378019597

Epoch: 135| Step: 0
Training loss: 1.5176243782043457
Validation loss: 2.0675339519336657

Epoch: 6| Step: 1
Training loss: 1.763598918914795
Validation loss: 2.0471907431079495

Epoch: 6| Step: 2
Training loss: 2.138672113418579
Validation loss: 2.06151851530998

Epoch: 6| Step: 3
Training loss: 1.7420752048492432
Validation loss: 2.053295373916626

Epoch: 6| Step: 4
Training loss: 2.545807123184204
Validation loss: 2.039374274592246

Epoch: 6| Step: 5
Training loss: 2.4292726516723633
Validation loss: 2.050397522987858

Epoch: 6| Step: 6
Training loss: 2.206793785095215
Validation loss: 2.0599314423017603

Epoch: 6| Step: 7
Training loss: 2.6683597564697266
Validation loss: 2.0619773839109685

Epoch: 6| Step: 8
Training loss: 1.5455396175384521
Validation loss: 2.0622619736579155

Epoch: 6| Step: 9
Training loss: 2.7381672859191895
Validation loss: 2.075847669314313

Epoch: 6| Step: 10
Training loss: 1.9250316619873047
Validation loss: 2.0431798991336616

Epoch: 6| Step: 11
Training loss: 2.569957971572876
Validation loss: 2.06938761280429

Epoch: 6| Step: 12
Training loss: 1.6926429271697998
Validation loss: 2.0592268513094996

Epoch: 6| Step: 13
Training loss: 1.6883034706115723
Validation loss: 2.0695806190531743

Epoch: 136| Step: 0
Training loss: 2.2379631996154785
Validation loss: 2.056241358480146

Epoch: 6| Step: 1
Training loss: 2.3415064811706543
Validation loss: 2.0814376069653417

Epoch: 6| Step: 2
Training loss: 1.808079481124878
Validation loss: 2.066789375838413

Epoch: 6| Step: 3
Training loss: 1.904163122177124
Validation loss: 2.0595414997428976

Epoch: 6| Step: 4
Training loss: 2.7746856212615967
Validation loss: 2.0459119658316336

Epoch: 6| Step: 5
Training loss: 2.4136552810668945
Validation loss: 2.034954071044922

Epoch: 6| Step: 6
Training loss: 1.6081147193908691
Validation loss: 2.060000063270651

Epoch: 6| Step: 7
Training loss: 2.063732624053955
Validation loss: 2.0642790576463104

Epoch: 6| Step: 8
Training loss: 2.23313045501709
Validation loss: 2.043325113993819

Epoch: 6| Step: 9
Training loss: 2.0189812183380127
Validation loss: 2.0438843119528984

Epoch: 6| Step: 10
Training loss: 1.7913806438446045
Validation loss: 2.0600106895610852

Epoch: 6| Step: 11
Training loss: 2.172077178955078
Validation loss: 2.038894344401616

Epoch: 6| Step: 12
Training loss: 1.9881943464279175
Validation loss: 2.040252016436669

Epoch: 6| Step: 13
Training loss: 1.8124433755874634
Validation loss: 2.0514798241276897

Epoch: 137| Step: 0
Training loss: 1.99394690990448
Validation loss: 2.047174706253954

Epoch: 6| Step: 1
Training loss: 1.9701757431030273
Validation loss: 2.057822027514058

Epoch: 6| Step: 2
Training loss: 2.3166887760162354
Validation loss: 2.0655633711045787

Epoch: 6| Step: 3
Training loss: 1.975527286529541
Validation loss: 2.0209158594890306

Epoch: 6| Step: 4
Training loss: 2.8379783630371094
Validation loss: 2.0543429825895574

Epoch: 6| Step: 5
Training loss: 2.1475119590759277
Validation loss: 2.0231549919292493

Epoch: 6| Step: 6
Training loss: 2.150423049926758
Validation loss: 2.0364761993449223

Epoch: 6| Step: 7
Training loss: 1.258622169494629
Validation loss: 2.042301716343049

Epoch: 6| Step: 8
Training loss: 1.6831337213516235
Validation loss: 2.0408298866723174

Epoch: 6| Step: 9
Training loss: 2.0406267642974854
Validation loss: 2.0498044824087494

Epoch: 6| Step: 10
Training loss: 2.134016513824463
Validation loss: 2.036952280229138

Epoch: 6| Step: 11
Training loss: 2.1245110034942627
Validation loss: 2.04095075848282

Epoch: 6| Step: 12
Training loss: 1.9775207042694092
Validation loss: 2.0388243121485554

Epoch: 6| Step: 13
Training loss: 3.350029945373535
Validation loss: 2.042794298100215

Epoch: 138| Step: 0
Training loss: 2.484196662902832
Validation loss: 2.05173614845481

Epoch: 6| Step: 1
Training loss: 1.717888355255127
Validation loss: 2.0407323914189495

Epoch: 6| Step: 2
Training loss: 1.3838776350021362
Validation loss: 2.0690432287031606

Epoch: 6| Step: 3
Training loss: 2.4158077239990234
Validation loss: 2.041359423309244

Epoch: 6| Step: 4
Training loss: 2.81587553024292
Validation loss: 2.050487567019719

Epoch: 6| Step: 5
Training loss: 2.8787431716918945
Validation loss: 2.0576496547268284

Epoch: 6| Step: 6
Training loss: 2.187386989593506
Validation loss: 2.0401579872254403

Epoch: 6| Step: 7
Training loss: 1.8403947353363037
Validation loss: 2.057419220606486

Epoch: 6| Step: 8
Training loss: 1.6383676528930664
Validation loss: 2.05495027829242

Epoch: 6| Step: 9
Training loss: 2.053067445755005
Validation loss: 2.0470618714568434

Epoch: 6| Step: 10
Training loss: 1.7340518236160278
Validation loss: 2.0657005233149373

Epoch: 6| Step: 11
Training loss: 1.6758980751037598
Validation loss: 2.0599759432577316

Epoch: 6| Step: 12
Training loss: 2.188749313354492
Validation loss: 2.054996612251446

Epoch: 6| Step: 13
Training loss: 2.359429359436035
Validation loss: 2.057656821384225

Epoch: 139| Step: 0
Training loss: 1.8602080345153809
Validation loss: 2.0537607362193446

Epoch: 6| Step: 1
Training loss: 2.17313814163208
Validation loss: 2.0509454460554224

Epoch: 6| Step: 2
Training loss: 2.2386510372161865
Validation loss: 2.046012052925684

Epoch: 6| Step: 3
Training loss: 2.145953893661499
Validation loss: 2.0542915354492846

Epoch: 6| Step: 4
Training loss: 2.56223464012146
Validation loss: 2.060656214273104

Epoch: 6| Step: 5
Training loss: 2.12261962890625
Validation loss: 2.0404357192336873

Epoch: 6| Step: 6
Training loss: 1.361769199371338
Validation loss: 2.057918756238876

Epoch: 6| Step: 7
Training loss: 2.028533697128296
Validation loss: 2.0635967357184297

Epoch: 6| Step: 8
Training loss: 2.3891384601593018
Validation loss: 2.0581352813269502

Epoch: 6| Step: 9
Training loss: 2.2144651412963867
Validation loss: 2.0607995525483163

Epoch: 6| Step: 10
Training loss: 2.647650718688965
Validation loss: 2.0544302053348993

Epoch: 6| Step: 11
Training loss: 1.5947322845458984
Validation loss: 2.043794652467133

Epoch: 6| Step: 12
Training loss: 1.9094221591949463
Validation loss: 2.0514314482288976

Epoch: 6| Step: 13
Training loss: 1.880606770515442
Validation loss: 2.062470664260208

Epoch: 140| Step: 0
Training loss: 2.39837384223938
Validation loss: 2.043790494242022

Epoch: 6| Step: 1
Training loss: 2.204019546508789
Validation loss: 2.0506805296867125

Epoch: 6| Step: 2
Training loss: 2.869442939758301
Validation loss: 2.0420887072881064

Epoch: 6| Step: 3
Training loss: 2.2613251209259033
Validation loss: 2.0438621403068624

Epoch: 6| Step: 4
Training loss: 1.503427505493164
Validation loss: 2.0463637228934997

Epoch: 6| Step: 5
Training loss: 2.2992677688598633
Validation loss: 2.04127328113843

Epoch: 6| Step: 6
Training loss: 1.420192003250122
Validation loss: 2.0563230232525895

Epoch: 6| Step: 7
Training loss: 1.2421618700027466
Validation loss: 2.0419059209926154

Epoch: 6| Step: 8
Training loss: 1.4780141115188599
Validation loss: 2.053933999871695

Epoch: 6| Step: 9
Training loss: 2.655445098876953
Validation loss: 2.0356158107839604

Epoch: 6| Step: 10
Training loss: 2.026723861694336
Validation loss: 2.034606783620773

Epoch: 6| Step: 11
Training loss: 1.948172688484192
Validation loss: 2.0355192768958306

Epoch: 6| Step: 12
Training loss: 2.0297937393188477
Validation loss: 2.0467188358306885

Epoch: 6| Step: 13
Training loss: 3.081170082092285
Validation loss: 2.0405035916195122

Epoch: 141| Step: 0
Training loss: 1.6876318454742432
Validation loss: 2.0313958455157537

Epoch: 6| Step: 1
Training loss: 2.0124292373657227
Validation loss: 2.0515230727452103

Epoch: 6| Step: 2
Training loss: 2.3086962699890137
Validation loss: 2.047493173230079

Epoch: 6| Step: 3
Training loss: 2.8531742095947266
Validation loss: 2.058399969531644

Epoch: 6| Step: 4
Training loss: 1.907034158706665
Validation loss: 2.0435411314810477

Epoch: 6| Step: 5
Training loss: 1.7604303359985352
Validation loss: 2.040071633554274

Epoch: 6| Step: 6
Training loss: 2.0175623893737793
Validation loss: 2.048735963400974

Epoch: 6| Step: 7
Training loss: 1.527181625366211
Validation loss: 2.040639954228555

Epoch: 6| Step: 8
Training loss: 2.2069878578186035
Validation loss: 2.0114852766836844

Epoch: 6| Step: 9
Training loss: 2.3383355140686035
Validation loss: 2.0290007745065997

Epoch: 6| Step: 10
Training loss: 1.9146662950515747
Validation loss: 2.036840469606461

Epoch: 6| Step: 11
Training loss: 2.4459805488586426
Validation loss: 2.0373050487169655

Epoch: 6| Step: 12
Training loss: 2.1453781127929688
Validation loss: 2.0280530734728743

Epoch: 6| Step: 13
Training loss: 2.032222270965576
Validation loss: 2.0609797226485385

Epoch: 142| Step: 0
Training loss: 1.9395829439163208
Validation loss: 2.0323876847503004

Epoch: 6| Step: 1
Training loss: 2.6127266883850098
Validation loss: 2.020867725854279

Epoch: 6| Step: 2
Training loss: 1.811582326889038
Validation loss: 2.0347861859106247

Epoch: 6| Step: 3
Training loss: 2.072047710418701
Validation loss: 2.0432663707322973

Epoch: 6| Step: 4
Training loss: 1.801095962524414
Validation loss: 2.0387253761291504

Epoch: 6| Step: 5
Training loss: 2.1065680980682373
Validation loss: 2.03558821575616

Epoch: 6| Step: 6
Training loss: 1.723552942276001
Validation loss: 2.0422914310168196

Epoch: 6| Step: 7
Training loss: 2.4130215644836426
Validation loss: 2.0502200639376076

Epoch: 6| Step: 8
Training loss: 1.747116208076477
Validation loss: 2.055475970750214

Epoch: 6| Step: 9
Training loss: 2.0458970069885254
Validation loss: 2.085773261644507

Epoch: 6| Step: 10
Training loss: 2.4085402488708496
Validation loss: 2.0491841480296147

Epoch: 6| Step: 11
Training loss: 2.991302967071533
Validation loss: 2.0501060101293747

Epoch: 6| Step: 12
Training loss: 1.626420497894287
Validation loss: 2.0594712585531254

Epoch: 6| Step: 13
Training loss: 1.9727473258972168
Validation loss: 2.0433331715163363

Epoch: 143| Step: 0
Training loss: 2.1046013832092285
Validation loss: 2.06775503261115

Epoch: 6| Step: 1
Training loss: 2.0098860263824463
Validation loss: 2.0375816437505905

Epoch: 6| Step: 2
Training loss: 1.609006404876709
Validation loss: 2.056427376244658

Epoch: 6| Step: 3
Training loss: 1.4920086860656738
Validation loss: 2.0465609283857447

Epoch: 6| Step: 4
Training loss: 2.4355382919311523
Validation loss: 2.0543995031746487

Epoch: 6| Step: 5
Training loss: 1.9958312511444092
Validation loss: 2.0673203840050647

Epoch: 6| Step: 6
Training loss: 2.635239601135254
Validation loss: 2.054899759190057

Epoch: 6| Step: 7
Training loss: 2.206988573074341
Validation loss: 2.054808662783715

Epoch: 6| Step: 8
Training loss: 1.9191534519195557
Validation loss: 2.042083896616454

Epoch: 6| Step: 9
Training loss: 2.0756468772888184
Validation loss: 2.0517166019767843

Epoch: 6| Step: 10
Training loss: 1.9824798107147217
Validation loss: 2.0364130773851947

Epoch: 6| Step: 11
Training loss: 2.5115933418273926
Validation loss: 2.065480539875646

Epoch: 6| Step: 12
Training loss: 1.9856574535369873
Validation loss: 2.038598015744199

Epoch: 6| Step: 13
Training loss: 2.0647926330566406
Validation loss: 2.0296581983566284

Epoch: 144| Step: 0
Training loss: 1.8373439311981201
Validation loss: 2.0315834604283816

Epoch: 6| Step: 1
Training loss: 2.0958847999572754
Validation loss: 2.018570779472269

Epoch: 6| Step: 2
Training loss: 1.424405574798584
Validation loss: 2.043376168897075

Epoch: 6| Step: 3
Training loss: 2.4084014892578125
Validation loss: 2.0307942481451136

Epoch: 6| Step: 4
Training loss: 2.018738031387329
Validation loss: 2.0399447282155356

Epoch: 6| Step: 5
Training loss: 2.3166356086730957
Validation loss: 2.034407715643606

Epoch: 6| Step: 6
Training loss: 2.643319845199585
Validation loss: 2.05661682416034

Epoch: 6| Step: 7
Training loss: 2.2742204666137695
Validation loss: 2.015096805428946

Epoch: 6| Step: 8
Training loss: 2.4418222904205322
Validation loss: 2.0422910695434897

Epoch: 6| Step: 9
Training loss: 2.764359474182129
Validation loss: 2.051023501221852

Epoch: 6| Step: 10
Training loss: 1.3993769884109497
Validation loss: 2.0308677701539892

Epoch: 6| Step: 11
Training loss: 2.2669224739074707
Validation loss: 2.0171694268462477

Epoch: 6| Step: 12
Training loss: 1.3996820449829102
Validation loss: 2.031923169730812

Epoch: 6| Step: 13
Training loss: 1.437941312789917
Validation loss: 2.061932727854739

Epoch: 145| Step: 0
Training loss: 2.0687689781188965
Validation loss: 2.024877985318502

Epoch: 6| Step: 1
Training loss: 1.5153024196624756
Validation loss: 2.0335941237788044

Epoch: 6| Step: 2
Training loss: 2.075289487838745
Validation loss: 2.0485355905307236

Epoch: 6| Step: 3
Training loss: 2.225372552871704
Validation loss: 2.0341412175086235

Epoch: 6| Step: 4
Training loss: 2.422424554824829
Validation loss: 2.033698340897919

Epoch: 6| Step: 5
Training loss: 1.7401751279830933
Validation loss: 2.0381338596343994

Epoch: 6| Step: 6
Training loss: 2.6937479972839355
Validation loss: 2.044079637014738

Epoch: 6| Step: 7
Training loss: 2.177415370941162
Validation loss: 2.0383281553945234

Epoch: 6| Step: 8
Training loss: 2.2970058917999268
Validation loss: 2.038574359750235

Epoch: 6| Step: 9
Training loss: 1.6407471895217896
Validation loss: 2.0236670804280106

Epoch: 6| Step: 10
Training loss: 2.130866050720215
Validation loss: 2.0320165388045774

Epoch: 6| Step: 11
Training loss: 1.6679813861846924
Validation loss: 2.0423767874317784

Epoch: 6| Step: 12
Training loss: 2.387951612472534
Validation loss: 2.0324854902041856

Epoch: 6| Step: 13
Training loss: 1.7098249197006226
Validation loss: 2.0605079358623875

Epoch: 146| Step: 0
Training loss: 2.192843437194824
Validation loss: 2.041111412868705

Epoch: 6| Step: 1
Training loss: 1.9789433479309082
Validation loss: 2.034431278064687

Epoch: 6| Step: 2
Training loss: 2.293522357940674
Validation loss: 2.036410170216714

Epoch: 6| Step: 3
Training loss: 1.4465372562408447
Validation loss: 2.044935941696167

Epoch: 6| Step: 4
Training loss: 2.2291407585144043
Validation loss: 2.0438923117935017

Epoch: 6| Step: 5
Training loss: 2.3051598072052
Validation loss: 2.041043596882974

Epoch: 6| Step: 6
Training loss: 2.6646947860717773
Validation loss: 2.0230946361377673

Epoch: 6| Step: 7
Training loss: 1.9353822469711304
Validation loss: 2.02620054060413

Epoch: 6| Step: 8
Training loss: 1.4430323839187622
Validation loss: 2.026325520648751

Epoch: 6| Step: 9
Training loss: 2.4312052726745605
Validation loss: 2.0236624722839682

Epoch: 6| Step: 10
Training loss: 1.887708306312561
Validation loss: 2.02784909484207

Epoch: 6| Step: 11
Training loss: 2.1578993797302246
Validation loss: 2.0400646809608705

Epoch: 6| Step: 12
Training loss: 1.9046063423156738
Validation loss: 2.0282433494444816

Epoch: 6| Step: 13
Training loss: 2.10183048248291
Validation loss: 2.0321057252986456

Epoch: 147| Step: 0
Training loss: 2.3012852668762207
Validation loss: 2.0412064982998754

Epoch: 6| Step: 1
Training loss: 1.790818452835083
Validation loss: 2.034927634782689

Epoch: 6| Step: 2
Training loss: 1.822575569152832
Validation loss: 2.043569121309506

Epoch: 6| Step: 3
Training loss: 2.2965505123138428
Validation loss: 2.0328388598657425

Epoch: 6| Step: 4
Training loss: 1.6582443714141846
Validation loss: 2.041720128828479

Epoch: 6| Step: 5
Training loss: 1.4889323711395264
Validation loss: 2.0336257539769655

Epoch: 6| Step: 6
Training loss: 1.9174091815948486
Validation loss: 2.0170455671125844

Epoch: 6| Step: 7
Training loss: 2.174921989440918
Validation loss: 2.034796504564183

Epoch: 6| Step: 8
Training loss: 2.5409274101257324
Validation loss: 2.0248529218858287

Epoch: 6| Step: 9
Training loss: 1.6691315174102783
Validation loss: 2.051170966958487

Epoch: 6| Step: 10
Training loss: 2.689154624938965
Validation loss: 2.049694220225016

Epoch: 6| Step: 11
Training loss: 1.6565816402435303
Validation loss: 2.0212378988983812

Epoch: 6| Step: 12
Training loss: 2.7086830139160156
Validation loss: 2.016074452348935

Epoch: 6| Step: 13
Training loss: 2.174790143966675
Validation loss: 2.027905994845975

Epoch: 148| Step: 0
Training loss: 2.1394858360290527
Validation loss: 2.038371923149273

Epoch: 6| Step: 1
Training loss: 2.015805959701538
Validation loss: 2.054156066269003

Epoch: 6| Step: 2
Training loss: 1.5182511806488037
Validation loss: 2.051684484686903

Epoch: 6| Step: 3
Training loss: 1.6059587001800537
Validation loss: 2.0516108902551795

Epoch: 6| Step: 4
Training loss: 1.7757415771484375
Validation loss: 2.04610183418438

Epoch: 6| Step: 5
Training loss: 2.5889041423797607
Validation loss: 2.0657123519528295

Epoch: 6| Step: 6
Training loss: 2.9468863010406494
Validation loss: 2.041054500046597

Epoch: 6| Step: 7
Training loss: 1.8012700080871582
Validation loss: 2.048446565546015

Epoch: 6| Step: 8
Training loss: 1.7279739379882812
Validation loss: 2.0604345260127896

Epoch: 6| Step: 9
Training loss: 2.7242918014526367
Validation loss: 2.0302009915792816

Epoch: 6| Step: 10
Training loss: 1.1839404106140137
Validation loss: 2.0416767994562783

Epoch: 6| Step: 11
Training loss: 2.330453395843506
Validation loss: 2.069930544463537

Epoch: 6| Step: 12
Training loss: 2.6423795223236084
Validation loss: 2.0616241949860767

Epoch: 6| Step: 13
Training loss: 1.9728453159332275
Validation loss: 2.0514657856315694

Epoch: 149| Step: 0
Training loss: 1.9601140022277832
Validation loss: 2.0409492305530015

Epoch: 6| Step: 1
Training loss: 1.9805316925048828
Validation loss: 2.0583411237244964

Epoch: 6| Step: 2
Training loss: 2.115673542022705
Validation loss: 2.045223892375987

Epoch: 6| Step: 3
Training loss: 2.182098388671875
Validation loss: 2.0250288004516275

Epoch: 6| Step: 4
Training loss: 1.7962656021118164
Validation loss: 2.0375707354596866

Epoch: 6| Step: 5
Training loss: 1.8294322490692139
Validation loss: 2.0449827819742183

Epoch: 6| Step: 6
Training loss: 2.476634979248047
Validation loss: 2.047061276692216

Epoch: 6| Step: 7
Training loss: 2.234212875366211
Validation loss: 2.041189714144635

Epoch: 6| Step: 8
Training loss: 2.9320883750915527
Validation loss: 2.0331423949169856

Epoch: 6| Step: 9
Training loss: 1.5297389030456543
Validation loss: 2.0253470597728604

Epoch: 6| Step: 10
Training loss: 1.985473871231079
Validation loss: 2.044918821704003

Epoch: 6| Step: 11
Training loss: 1.4844454526901245
Validation loss: 2.029456136047199

Epoch: 6| Step: 12
Training loss: 1.9041649103164673
Validation loss: 2.0101498378220426

Epoch: 6| Step: 13
Training loss: 2.644090175628662
Validation loss: 2.0267342341843473

Epoch: 150| Step: 0
Training loss: 2.024751663208008
Validation loss: 2.0201625964974843

Epoch: 6| Step: 1
Training loss: 2.2617757320404053
Validation loss: 2.0067473098795903

Epoch: 6| Step: 2
Training loss: 2.168914794921875
Validation loss: 2.026500545522218

Epoch: 6| Step: 3
Training loss: 2.264141082763672
Validation loss: 2.022745402910376

Epoch: 6| Step: 4
Training loss: 2.130305767059326
Validation loss: 2.025720191258256

Epoch: 6| Step: 5
Training loss: 2.0812828540802
Validation loss: 2.0244833833427838

Epoch: 6| Step: 6
Training loss: 2.4591946601867676
Validation loss: 2.0279033068687684

Epoch: 6| Step: 7
Training loss: 2.024411678314209
Validation loss: 2.0225897168600433

Epoch: 6| Step: 8
Training loss: 2.1926538944244385
Validation loss: 2.030370186733943

Epoch: 6| Step: 9
Training loss: 2.324542999267578
Validation loss: 2.027829267645395

Epoch: 6| Step: 10
Training loss: 1.9734904766082764
Validation loss: 2.0288404239121305

Epoch: 6| Step: 11
Training loss: 1.504410982131958
Validation loss: 2.031207888357101

Epoch: 6| Step: 12
Training loss: 1.356956958770752
Validation loss: 2.0285984200816

Epoch: 6| Step: 13
Training loss: 1.7316659688949585
Validation loss: 2.0258207462167226

Epoch: 151| Step: 0
Training loss: 1.9545142650604248
Validation loss: 2.0334836782947665

Epoch: 6| Step: 1
Training loss: 2.177607536315918
Validation loss: 2.035581798963649

Epoch: 6| Step: 2
Training loss: 2.806133270263672
Validation loss: 2.029402462385034

Epoch: 6| Step: 3
Training loss: 1.448237419128418
Validation loss: 2.0461166597181752

Epoch: 6| Step: 4
Training loss: 1.7316734790802002
Validation loss: 2.027002174367187

Epoch: 6| Step: 5
Training loss: 1.59690260887146
Validation loss: 2.037020875561622

Epoch: 6| Step: 6
Training loss: 1.996935486793518
Validation loss: 2.0272236344634846

Epoch: 6| Step: 7
Training loss: 2.415773391723633
Validation loss: 2.0300092056233394

Epoch: 6| Step: 8
Training loss: 1.7117443084716797
Validation loss: 2.045259234725788

Epoch: 6| Step: 9
Training loss: 2.300477981567383
Validation loss: 2.003903733786716

Epoch: 6| Step: 10
Training loss: 2.1598007678985596
Validation loss: 2.0382208593430056

Epoch: 6| Step: 11
Training loss: 2.177604913711548
Validation loss: 2.042895345277684

Epoch: 6| Step: 12
Training loss: 1.6911708116531372
Validation loss: 2.0285905689321537

Epoch: 6| Step: 13
Training loss: 2.861176013946533
Validation loss: 2.0337699459445093

Epoch: 152| Step: 0
Training loss: 2.0540719032287598
Validation loss: 2.0298035478079193

Epoch: 6| Step: 1
Training loss: 2.131995677947998
Validation loss: 2.036378155472458

Epoch: 6| Step: 2
Training loss: 2.0505595207214355
Validation loss: 2.0157769469804663

Epoch: 6| Step: 3
Training loss: 1.7082946300506592
Validation loss: 2.019937256331085

Epoch: 6| Step: 4
Training loss: 1.563683271408081
Validation loss: 2.039222648066859

Epoch: 6| Step: 5
Training loss: 2.545086622238159
Validation loss: 2.026512542078572

Epoch: 6| Step: 6
Training loss: 1.8587183952331543
Validation loss: 2.0235830635152836

Epoch: 6| Step: 7
Training loss: 1.592899203300476
Validation loss: 2.022691075519849

Epoch: 6| Step: 8
Training loss: 2.1588804721832275
Validation loss: 2.0054222845262095

Epoch: 6| Step: 9
Training loss: 2.307258367538452
Validation loss: 2.0352365816793134

Epoch: 6| Step: 10
Training loss: 2.3773446083068848
Validation loss: 2.037421639247607

Epoch: 6| Step: 11
Training loss: 2.2809598445892334
Validation loss: 2.0218372344970703

Epoch: 6| Step: 12
Training loss: 2.0023910999298096
Validation loss: 2.0394049280433246

Epoch: 6| Step: 13
Training loss: 1.8628883361816406
Validation loss: 2.020684875467772

Epoch: 153| Step: 0
Training loss: 2.2420005798339844
Validation loss: 2.0219415310890443

Epoch: 6| Step: 1
Training loss: 1.9436064958572388
Validation loss: 2.02702820685602

Epoch: 6| Step: 2
Training loss: 2.932591676712036
Validation loss: 2.0492338224123885

Epoch: 6| Step: 3
Training loss: 2.172898054122925
Validation loss: 2.0329853847462642

Epoch: 6| Step: 4
Training loss: 1.9019579887390137
Validation loss: 2.031970308672997

Epoch: 6| Step: 5
Training loss: 1.8722972869873047
Validation loss: 2.0341192317265335

Epoch: 6| Step: 6
Training loss: 1.4301457405090332
Validation loss: 2.0242337731904883

Epoch: 6| Step: 7
Training loss: 2.161928653717041
Validation loss: 2.0350572075895084

Epoch: 6| Step: 8
Training loss: 1.7460565567016602
Validation loss: 2.0068430503209433

Epoch: 6| Step: 9
Training loss: 1.8223941326141357
Validation loss: 2.0139186869385424

Epoch: 6| Step: 10
Training loss: 2.064828634262085
Validation loss: 2.03027017014001

Epoch: 6| Step: 11
Training loss: 2.0857348442077637
Validation loss: 2.0261693974976898

Epoch: 6| Step: 12
Training loss: 2.173705577850342
Validation loss: 2.0286882808131557

Epoch: 6| Step: 13
Training loss: 2.184191942214966
Validation loss: 2.0185704154352986

Epoch: 154| Step: 0
Training loss: 1.5733563899993896
Validation loss: 2.019377423870948

Epoch: 6| Step: 1
Training loss: 2.06966495513916
Validation loss: 2.0260921652599047

Epoch: 6| Step: 2
Training loss: 1.9699469804763794
Validation loss: 2.025422309034614

Epoch: 6| Step: 3
Training loss: 2.838667631149292
Validation loss: 2.0355553934651036

Epoch: 6| Step: 4
Training loss: 1.677020788192749
Validation loss: 2.03965844902941

Epoch: 6| Step: 5
Training loss: 3.125732183456421
Validation loss: 2.0551062271159184

Epoch: 6| Step: 6
Training loss: 1.9716761112213135
Validation loss: 2.046037666259273

Epoch: 6| Step: 7
Training loss: 1.4568780660629272
Validation loss: 2.0290336326886247

Epoch: 6| Step: 8
Training loss: 2.4775447845458984
Validation loss: 2.0578854622379428

Epoch: 6| Step: 9
Training loss: 1.8899261951446533
Validation loss: 2.0429062048594155

Epoch: 6| Step: 10
Training loss: 1.833411693572998
Validation loss: 2.0420510871436006

Epoch: 6| Step: 11
Training loss: 1.8691461086273193
Validation loss: 2.0365546505938292

Epoch: 6| Step: 12
Training loss: 2.4543304443359375
Validation loss: 2.0421925847248366

Epoch: 6| Step: 13
Training loss: 1.3241199254989624
Validation loss: 2.0264694639431533

Epoch: 155| Step: 0
Training loss: 1.3285020589828491
Validation loss: 2.0392027465246056

Epoch: 6| Step: 1
Training loss: 1.9046454429626465
Validation loss: 2.0359079940344698

Epoch: 6| Step: 2
Training loss: 2.2334203720092773
Validation loss: 2.014807847238356

Epoch: 6| Step: 3
Training loss: 1.659240961074829
Validation loss: 2.0060752181596655

Epoch: 6| Step: 4
Training loss: 1.6638267040252686
Validation loss: 2.0437314856436943

Epoch: 6| Step: 5
Training loss: 3.170747756958008
Validation loss: 2.017375220534622

Epoch: 6| Step: 6
Training loss: 1.5150256156921387
Validation loss: 2.023517362533077

Epoch: 6| Step: 7
Training loss: 2.199118137359619
Validation loss: 2.0397287773829635

Epoch: 6| Step: 8
Training loss: 2.236337423324585
Validation loss: 2.000246669656487

Epoch: 6| Step: 9
Training loss: 2.3407514095306396
Validation loss: 2.0281908691570325

Epoch: 6| Step: 10
Training loss: 1.9886478185653687
Validation loss: 2.024821103260081

Epoch: 6| Step: 11
Training loss: 1.7374027967453003
Validation loss: 2.0177943578330417

Epoch: 6| Step: 12
Training loss: 2.4563775062561035
Validation loss: 2.0088346414668585

Epoch: 6| Step: 13
Training loss: 2.6293351650238037
Validation loss: 2.026852530817832

Epoch: 156| Step: 0
Training loss: 2.113355875015259
Validation loss: 2.0238655305677846

Epoch: 6| Step: 1
Training loss: 1.551666021347046
Validation loss: 2.032764974460807

Epoch: 6| Step: 2
Training loss: 2.217395305633545
Validation loss: 2.01387543319374

Epoch: 6| Step: 3
Training loss: 1.4888026714324951
Validation loss: 2.0256261082105738

Epoch: 6| Step: 4
Training loss: 2.951178789138794
Validation loss: 2.0168444097682996

Epoch: 6| Step: 5
Training loss: 1.8774117231369019
Validation loss: 2.050573184926023

Epoch: 6| Step: 6
Training loss: 1.2328169345855713
Validation loss: 2.0090358885385657

Epoch: 6| Step: 7
Training loss: 2.4869384765625
Validation loss: 2.0179265545260523

Epoch: 6| Step: 8
Training loss: 1.7307686805725098
Validation loss: 2.037580902858447

Epoch: 6| Step: 9
Training loss: 1.811431646347046
Validation loss: 2.0281570239733626

Epoch: 6| Step: 10
Training loss: 1.9090489149093628
Validation loss: 2.0295441842848256

Epoch: 6| Step: 11
Training loss: 1.8773760795593262
Validation loss: 2.0318032080127346

Epoch: 6| Step: 12
Training loss: 2.8579511642456055
Validation loss: 2.0284500993708128

Epoch: 6| Step: 13
Training loss: 2.4149258136749268
Validation loss: 2.024695791223998

Epoch: 157| Step: 0
Training loss: 1.9996620416641235
Validation loss: 2.034203703685473

Epoch: 6| Step: 1
Training loss: 2.157081127166748
Validation loss: 2.027452309926351

Epoch: 6| Step: 2
Training loss: 2.482586622238159
Validation loss: 2.027276405724146

Epoch: 6| Step: 3
Training loss: 2.3596978187561035
Validation loss: 2.01587523183515

Epoch: 6| Step: 4
Training loss: 1.898630142211914
Validation loss: 2.0072999180004163

Epoch: 6| Step: 5
Training loss: 1.9800971746444702
Validation loss: 2.035114934367518

Epoch: 6| Step: 6
Training loss: 1.7259126901626587
Validation loss: 2.034111240858673

Epoch: 6| Step: 7
Training loss: 2.0856680870056152
Validation loss: 2.0323314820566485

Epoch: 6| Step: 8
Training loss: 1.5519163608551025
Validation loss: 2.02169067628922

Epoch: 6| Step: 9
Training loss: 1.4355354309082031
Validation loss: 2.0272708849240373

Epoch: 6| Step: 10
Training loss: 1.7089240550994873
Validation loss: 2.045159875705678

Epoch: 6| Step: 11
Training loss: 2.3633170127868652
Validation loss: 2.0335864866933515

Epoch: 6| Step: 12
Training loss: 3.1163294315338135
Validation loss: 2.025999140995805

Epoch: 6| Step: 13
Training loss: 1.4343689680099487
Validation loss: 2.020353910743549

Epoch: 158| Step: 0
Training loss: 2.189519166946411
Validation loss: 2.038362128760225

Epoch: 6| Step: 1
Training loss: 1.6254591941833496
Validation loss: 2.015139433645433

Epoch: 6| Step: 2
Training loss: 1.8697528839111328
Validation loss: 2.020433336175898

Epoch: 6| Step: 3
Training loss: 1.6765397787094116
Validation loss: 2.0294391455188876

Epoch: 6| Step: 4
Training loss: 2.011636734008789
Validation loss: 2.026790820142274

Epoch: 6| Step: 5
Training loss: 2.0659492015838623
Validation loss: 1.991728436562323

Epoch: 6| Step: 6
Training loss: 2.6238811016082764
Validation loss: 2.0450532820916947

Epoch: 6| Step: 7
Training loss: 1.8332511186599731
Validation loss: 2.0204737686341807

Epoch: 6| Step: 8
Training loss: 2.2449231147766113
Validation loss: 2.0106954190038864

Epoch: 6| Step: 9
Training loss: 1.642193078994751
Validation loss: 2.048703388501239

Epoch: 6| Step: 10
Training loss: 2.0999298095703125
Validation loss: 2.0190785264456146

Epoch: 6| Step: 11
Training loss: 2.2736728191375732
Validation loss: 2.0090115057524813

Epoch: 6| Step: 12
Training loss: 2.1813249588012695
Validation loss: 2.026614628812318

Epoch: 6| Step: 13
Training loss: 2.2516753673553467
Validation loss: 2.018728094716226

Epoch: 159| Step: 0
Training loss: 1.871848464012146
Validation loss: 2.008940089133478

Epoch: 6| Step: 1
Training loss: 2.4264278411865234
Validation loss: 2.0172829602354314

Epoch: 6| Step: 2
Training loss: 1.7227184772491455
Validation loss: 2.001294953848726

Epoch: 6| Step: 3
Training loss: 1.764115810394287
Validation loss: 2.010823652308474

Epoch: 6| Step: 4
Training loss: 2.5679852962493896
Validation loss: 2.03152121010647

Epoch: 6| Step: 5
Training loss: 2.030186176300049
Validation loss: 2.0168317530744817

Epoch: 6| Step: 6
Training loss: 1.994372010231018
Validation loss: 2.0376999416658954

Epoch: 6| Step: 7
Training loss: 2.7214043140411377
Validation loss: 2.0093357986019504

Epoch: 6| Step: 8
Training loss: 1.8721288442611694
Validation loss: 2.0002632923023675

Epoch: 6| Step: 9
Training loss: 1.916419506072998
Validation loss: 2.0274793973533054

Epoch: 6| Step: 10
Training loss: 1.8870786428451538
Validation loss: 2.018335450080133

Epoch: 6| Step: 11
Training loss: 1.9566371440887451
Validation loss: 2.002569320381329

Epoch: 6| Step: 12
Training loss: 1.8473385572433472
Validation loss: 2.0172041641768588

Epoch: 6| Step: 13
Training loss: 1.352114200592041
Validation loss: 2.033909902777723

Epoch: 160| Step: 0
Training loss: 1.8141731023788452
Validation loss: 2.0344343954516995

Epoch: 6| Step: 1
Training loss: 1.630784034729004
Validation loss: 1.9948488448255806

Epoch: 6| Step: 2
Training loss: 1.8098604679107666
Validation loss: 2.017060466991958

Epoch: 6| Step: 3
Training loss: 1.9142392873764038
Validation loss: 2.0316653431102796

Epoch: 6| Step: 4
Training loss: 1.5563180446624756
Validation loss: 2.04909146729336

Epoch: 6| Step: 5
Training loss: 2.2695493698120117
Validation loss: 2.0725993546106483

Epoch: 6| Step: 6
Training loss: 2.887281894683838
Validation loss: 2.0394631790858444

Epoch: 6| Step: 7
Training loss: 1.8371950387954712
Validation loss: 2.0331570102322485

Epoch: 6| Step: 8
Training loss: 2.977334499359131
Validation loss: 2.044500001015202

Epoch: 6| Step: 9
Training loss: 1.8395285606384277
Validation loss: 2.0559587837547384

Epoch: 6| Step: 10
Training loss: 2.204470634460449
Validation loss: 2.048296158031751

Epoch: 6| Step: 11
Training loss: 1.899519443511963
Validation loss: 2.0398940283765077

Epoch: 6| Step: 12
Training loss: 2.124699831008911
Validation loss: 2.0473792860584874

Epoch: 6| Step: 13
Training loss: 1.6874136924743652
Validation loss: 2.0360509349453833

Epoch: 161| Step: 0
Training loss: 1.6744630336761475
Validation loss: 2.044769661400908

Epoch: 6| Step: 1
Training loss: 2.0657243728637695
Validation loss: 2.0428823706924275

Epoch: 6| Step: 2
Training loss: 1.9327924251556396
Validation loss: 2.017990712196596

Epoch: 6| Step: 3
Training loss: 2.0104455947875977
Validation loss: 2.0150714253866546

Epoch: 6| Step: 4
Training loss: 1.892319917678833
Validation loss: 2.036595283016082

Epoch: 6| Step: 5
Training loss: 2.038619041442871
Validation loss: 2.0055638051802114

Epoch: 6| Step: 6
Training loss: 3.100602626800537
Validation loss: 2.0203295497484106

Epoch: 6| Step: 7
Training loss: 2.400830030441284
Validation loss: 2.0059879261960267

Epoch: 6| Step: 8
Training loss: 1.7070863246917725
Validation loss: 2.0127245200577604

Epoch: 6| Step: 9
Training loss: 2.039721965789795
Validation loss: 2.029673860919091

Epoch: 6| Step: 10
Training loss: 2.0900840759277344
Validation loss: 2.0008758908958844

Epoch: 6| Step: 11
Training loss: 1.1684871912002563
Validation loss: 2.001400404078986

Epoch: 6| Step: 12
Training loss: 2.047281265258789
Validation loss: 2.0306870424619285

Epoch: 6| Step: 13
Training loss: 2.212029457092285
Validation loss: 2.0137443055388746

Epoch: 162| Step: 0
Training loss: 1.6037718057632446
Validation loss: 2.014064568345265

Epoch: 6| Step: 1
Training loss: 1.618967890739441
Validation loss: 1.9998903838537072

Epoch: 6| Step: 2
Training loss: 1.4971904754638672
Validation loss: 2.003155562185472

Epoch: 6| Step: 3
Training loss: 2.5898640155792236
Validation loss: 2.005400241062205

Epoch: 6| Step: 4
Training loss: 2.111374616622925
Validation loss: 2.0008060957795832

Epoch: 6| Step: 5
Training loss: 2.3916940689086914
Validation loss: 1.994462272172333

Epoch: 6| Step: 6
Training loss: 1.725703477859497
Validation loss: 2.0082984560279438

Epoch: 6| Step: 7
Training loss: 2.1848506927490234
Validation loss: 2.0076629807872157

Epoch: 6| Step: 8
Training loss: 1.6642390489578247
Validation loss: 2.0152422804986276

Epoch: 6| Step: 9
Training loss: 2.567431926727295
Validation loss: 1.9955408086058914

Epoch: 6| Step: 10
Training loss: 2.6598708629608154
Validation loss: 2.01943080271444

Epoch: 6| Step: 11
Training loss: 1.688407301902771
Validation loss: 2.0351393094626804

Epoch: 6| Step: 12
Training loss: 2.1701931953430176
Validation loss: 2.0059785560895036

Epoch: 6| Step: 13
Training loss: 1.5554512739181519
Validation loss: 2.026506285513601

Epoch: 163| Step: 0
Training loss: 2.7209439277648926
Validation loss: 2.0275631425201253

Epoch: 6| Step: 1
Training loss: 2.280377149581909
Validation loss: 2.015815834845266

Epoch: 6| Step: 2
Training loss: 2.2977678775787354
Validation loss: 2.0145094779229935

Epoch: 6| Step: 3
Training loss: 2.1586568355560303
Validation loss: 1.998618798871194

Epoch: 6| Step: 4
Training loss: 1.6970863342285156
Validation loss: 2.0214300488912933

Epoch: 6| Step: 5
Training loss: 2.466529130935669
Validation loss: 2.0270368091521727

Epoch: 6| Step: 6
Training loss: 1.8954260349273682
Validation loss: 2.0048150554780038

Epoch: 6| Step: 7
Training loss: 1.5240209102630615
Validation loss: 1.9858499906396354

Epoch: 6| Step: 8
Training loss: 1.6580557823181152
Validation loss: 2.0176274520094677

Epoch: 6| Step: 9
Training loss: 2.4169888496398926
Validation loss: 2.0008123382445304

Epoch: 6| Step: 10
Training loss: 1.3558549880981445
Validation loss: 2.00678950484081

Epoch: 6| Step: 11
Training loss: 2.010812282562256
Validation loss: 2.000920336733582

Epoch: 6| Step: 12
Training loss: 1.8568748235702515
Validation loss: 2.0208082583642777

Epoch: 6| Step: 13
Training loss: 1.5488168001174927
Validation loss: 1.9849000771840413

Epoch: 164| Step: 0
Training loss: 1.8230814933776855
Validation loss: 1.9881695239774642

Epoch: 6| Step: 1
Training loss: 2.1845152378082275
Validation loss: 2.0189556383317515

Epoch: 6| Step: 2
Training loss: 1.9222121238708496
Validation loss: 1.9891301303781488

Epoch: 6| Step: 3
Training loss: 1.8949673175811768
Validation loss: 1.9908883443442724

Epoch: 6| Step: 4
Training loss: 1.5031321048736572
Validation loss: 1.9910211101655038

Epoch: 6| Step: 5
Training loss: 2.1520376205444336
Validation loss: 2.032394434816094

Epoch: 6| Step: 6
Training loss: 1.5710482597351074
Validation loss: 2.02042975476993

Epoch: 6| Step: 7
Training loss: 2.2790350914001465
Validation loss: 2.0207485665557203

Epoch: 6| Step: 8
Training loss: 1.8759658336639404
Validation loss: 2.0272741317749023

Epoch: 6| Step: 9
Training loss: 2.803330898284912
Validation loss: 2.0097944377571024

Epoch: 6| Step: 10
Training loss: 2.69083833694458
Validation loss: 2.013344439127112

Epoch: 6| Step: 11
Training loss: 1.812227725982666
Validation loss: 2.0210249231707667

Epoch: 6| Step: 12
Training loss: 2.2085983753204346
Validation loss: 2.0201759902379846

Epoch: 6| Step: 13
Training loss: 0.9114617109298706
Validation loss: 2.0217419144927815

Epoch: 165| Step: 0
Training loss: 2.3339290618896484
Validation loss: 2.006722814293318

Epoch: 6| Step: 1
Training loss: 1.9236485958099365
Validation loss: 2.035913589180157

Epoch: 6| Step: 2
Training loss: 1.7940714359283447
Validation loss: 2.0129491488138833

Epoch: 6| Step: 3
Training loss: 1.959201455116272
Validation loss: 2.037534693235992

Epoch: 6| Step: 4
Training loss: 2.083897352218628
Validation loss: 1.9957479725601852

Epoch: 6| Step: 5
Training loss: 2.0437707901000977
Validation loss: 2.024915611872109

Epoch: 6| Step: 6
Training loss: 2.224525213241577
Validation loss: 2.0288363041416293

Epoch: 6| Step: 7
Training loss: 2.1522717475891113
Validation loss: 2.0116929187569568

Epoch: 6| Step: 8
Training loss: 2.2451300621032715
Validation loss: 2.0110972132734073

Epoch: 6| Step: 9
Training loss: 1.6691027879714966
Validation loss: 2.012225099789199

Epoch: 6| Step: 10
Training loss: 2.3447494506835938
Validation loss: 2.010403225498815

Epoch: 6| Step: 11
Training loss: 2.253005266189575
Validation loss: 1.9955268918827016

Epoch: 6| Step: 12
Training loss: 1.1597394943237305
Validation loss: 2.009994054353365

Epoch: 6| Step: 13
Training loss: 1.5326995849609375
Validation loss: 2.027856258935826

Epoch: 166| Step: 0
Training loss: 2.661741018295288
Validation loss: 2.0392591312367427

Epoch: 6| Step: 1
Training loss: 1.4459233283996582
Validation loss: 2.016430731742613

Epoch: 6| Step: 2
Training loss: 2.188966989517212
Validation loss: 2.0076651457817323

Epoch: 6| Step: 3
Training loss: 1.9814512729644775
Validation loss: 2.0274275349032496

Epoch: 6| Step: 4
Training loss: 1.9073355197906494
Validation loss: 2.005968947564402

Epoch: 6| Step: 5
Training loss: 1.9338732957839966
Validation loss: 2.0215688905408307

Epoch: 6| Step: 6
Training loss: 2.651250123977661
Validation loss: 2.0427702088509836

Epoch: 6| Step: 7
Training loss: 1.339217185974121
Validation loss: 1.9842887873290687

Epoch: 6| Step: 8
Training loss: 2.3350512981414795
Validation loss: 2.004722028650263

Epoch: 6| Step: 9
Training loss: 1.5302512645721436
Validation loss: 2.0308459266539542

Epoch: 6| Step: 10
Training loss: 1.6686872243881226
Validation loss: 2.038430698456303

Epoch: 6| Step: 11
Training loss: 1.9554120302200317
Validation loss: 2.0144072835163405

Epoch: 6| Step: 12
Training loss: 2.433309316635132
Validation loss: 2.0171534989469793

Epoch: 6| Step: 13
Training loss: 1.5214670896530151
Validation loss: 1.9992314282283987

Epoch: 167| Step: 0
Training loss: 1.370934247970581
Validation loss: 2.0323636788193897

Epoch: 6| Step: 1
Training loss: 1.8320664167404175
Validation loss: 2.001297576453096

Epoch: 6| Step: 2
Training loss: 2.682875633239746
Validation loss: 2.013500072622812

Epoch: 6| Step: 3
Training loss: 1.6419672966003418
Validation loss: 2.012717345709442

Epoch: 6| Step: 4
Training loss: 1.951919674873352
Validation loss: 2.0250862824019564

Epoch: 6| Step: 5
Training loss: 2.0223944187164307
Validation loss: 2.021289461402483

Epoch: 6| Step: 6
Training loss: 1.950203537940979
Validation loss: 2.0216694237083517

Epoch: 6| Step: 7
Training loss: 2.858638286590576
Validation loss: 1.9874256144287765

Epoch: 6| Step: 8
Training loss: 1.7542459964752197
Validation loss: 2.026842527492072

Epoch: 6| Step: 9
Training loss: 2.4985570907592773
Validation loss: 2.0060386939715316

Epoch: 6| Step: 10
Training loss: 1.633304476737976
Validation loss: 1.9927148447241834

Epoch: 6| Step: 11
Training loss: 2.3240129947662354
Validation loss: 2.0059454799980245

Epoch: 6| Step: 12
Training loss: 1.9833393096923828
Validation loss: 2.006059700442899

Epoch: 6| Step: 13
Training loss: 1.1242917776107788
Validation loss: 2.027403409763049

Epoch: 168| Step: 0
Training loss: 1.1448850631713867
Validation loss: 1.9846215260926114

Epoch: 6| Step: 1
Training loss: 2.394197463989258
Validation loss: 1.9969793955485027

Epoch: 6| Step: 2
Training loss: 2.494061231613159
Validation loss: 1.9885589448354577

Epoch: 6| Step: 3
Training loss: 1.8176140785217285
Validation loss: 2.00868478128987

Epoch: 6| Step: 4
Training loss: 1.906519889831543
Validation loss: 1.9912674247577626

Epoch: 6| Step: 5
Training loss: 2.0932106971740723
Validation loss: 1.9997381266727243

Epoch: 6| Step: 6
Training loss: 2.50545597076416
Validation loss: 1.9952972332636516

Epoch: 6| Step: 7
Training loss: 1.8292677402496338
Validation loss: 1.9758308677263157

Epoch: 6| Step: 8
Training loss: 1.9296709299087524
Validation loss: 1.9793986479441326

Epoch: 6| Step: 9
Training loss: 1.7270811796188354
Validation loss: 1.9950943762256252

Epoch: 6| Step: 10
Training loss: 2.0188333988189697
Validation loss: 2.0012015758022184

Epoch: 6| Step: 11
Training loss: 1.384117841720581
Validation loss: 1.9882466869969522

Epoch: 6| Step: 12
Training loss: 2.1567416191101074
Validation loss: 2.0076740890420894

Epoch: 6| Step: 13
Training loss: 2.4131128787994385
Validation loss: 2.0384494796875985

Epoch: 169| Step: 0
Training loss: 2.367544651031494
Validation loss: 2.01380733777118

Epoch: 6| Step: 1
Training loss: 1.5895740985870361
Validation loss: 2.0012315857794976

Epoch: 6| Step: 2
Training loss: 2.4605698585510254
Validation loss: 1.9858360521255

Epoch: 6| Step: 3
Training loss: 2.5173897743225098
Validation loss: 1.9860408049757763

Epoch: 6| Step: 4
Training loss: 2.5207104682922363
Validation loss: 2.006672937382934

Epoch: 6| Step: 5
Training loss: 1.9193886518478394
Validation loss: 2.011034970642418

Epoch: 6| Step: 6
Training loss: 1.7882065773010254
Validation loss: 2.0081558304448284

Epoch: 6| Step: 7
Training loss: 1.4340734481811523
Validation loss: 2.0395776994766726

Epoch: 6| Step: 8
Training loss: 1.7168831825256348
Validation loss: 2.0096116322343067

Epoch: 6| Step: 9
Training loss: 2.062623977661133
Validation loss: 2.011002779006958

Epoch: 6| Step: 10
Training loss: 1.566943645477295
Validation loss: 2.0416496953656598

Epoch: 6| Step: 11
Training loss: 2.226788282394409
Validation loss: 2.00566081846914

Epoch: 6| Step: 12
Training loss: 2.0024185180664062
Validation loss: 2.012492820780764

Epoch: 6| Step: 13
Training loss: 1.4347360134124756
Validation loss: 1.9944995269980481

Epoch: 170| Step: 0
Training loss: 2.4936819076538086
Validation loss: 1.9769752628059798

Epoch: 6| Step: 1
Training loss: 2.2620351314544678
Validation loss: 2.0107965110450663

Epoch: 6| Step: 2
Training loss: 2.0690226554870605
Validation loss: 2.0173124600482244

Epoch: 6| Step: 3
Training loss: 1.5135829448699951
Validation loss: 1.975253669164514

Epoch: 6| Step: 4
Training loss: 2.5627081394195557
Validation loss: 1.9823265037228983

Epoch: 6| Step: 5
Training loss: 1.7331823110580444
Validation loss: 1.9915291224756548

Epoch: 6| Step: 6
Training loss: 1.7781968116760254
Validation loss: 2.006880819156606

Epoch: 6| Step: 7
Training loss: 2.090689182281494
Validation loss: 2.002631031056886

Epoch: 6| Step: 8
Training loss: 1.7735402584075928
Validation loss: 2.0138708173587756

Epoch: 6| Step: 9
Training loss: 2.261852741241455
Validation loss: 1.9909098071436728

Epoch: 6| Step: 10
Training loss: 1.8781373500823975
Validation loss: 1.9837980296022149

Epoch: 6| Step: 11
Training loss: 2.150411605834961
Validation loss: 1.987757634091121

Epoch: 6| Step: 12
Training loss: 1.3965654373168945
Validation loss: 1.9828567043427499

Epoch: 6| Step: 13
Training loss: 1.5666013956069946
Validation loss: 2.0113366637178647

Epoch: 171| Step: 0
Training loss: 1.9445748329162598
Validation loss: 1.9902581091850036

Epoch: 6| Step: 1
Training loss: 1.7491896152496338
Validation loss: 2.0100945682935816

Epoch: 6| Step: 2
Training loss: 2.255720853805542
Validation loss: 1.9893559178998392

Epoch: 6| Step: 3
Training loss: 1.5452549457550049
Validation loss: 2.0209627100216445

Epoch: 6| Step: 4
Training loss: 2.1236772537231445
Validation loss: 2.0505905600004297

Epoch: 6| Step: 5
Training loss: 2.316716432571411
Validation loss: 1.994365821602524

Epoch: 6| Step: 6
Training loss: 2.290919780731201
Validation loss: 1.9888576487059235

Epoch: 6| Step: 7
Training loss: 2.061368227005005
Validation loss: 2.0148470632491575

Epoch: 6| Step: 8
Training loss: 2.1082420349121094
Validation loss: 2.016579726690887

Epoch: 6| Step: 9
Training loss: 2.0053491592407227
Validation loss: 2.013403464389104

Epoch: 6| Step: 10
Training loss: 1.5955171585083008
Validation loss: 2.015508855542829

Epoch: 6| Step: 11
Training loss: 1.5517864227294922
Validation loss: 2.0049396586674515

Epoch: 6| Step: 12
Training loss: 2.166929244995117
Validation loss: 2.002961345898208

Epoch: 6| Step: 13
Training loss: 1.8745503425598145
Validation loss: 2.0027554265914427

Epoch: 172| Step: 0
Training loss: 1.8725898265838623
Validation loss: 1.991300795667915

Epoch: 6| Step: 1
Training loss: 2.219026803970337
Validation loss: 1.9987660056801253

Epoch: 6| Step: 2
Training loss: 1.6319738626480103
Validation loss: 2.0112335002550514

Epoch: 6| Step: 3
Training loss: 2.398678779602051
Validation loss: 2.0513428359903316

Epoch: 6| Step: 4
Training loss: 1.9037823677062988
Validation loss: 1.9855690976624847

Epoch: 6| Step: 5
Training loss: 1.3105885982513428
Validation loss: 1.9814331710979503

Epoch: 6| Step: 6
Training loss: 2.832750082015991
Validation loss: 1.9925299536797307

Epoch: 6| Step: 7
Training loss: 1.5268561840057373
Validation loss: 2.0178314357675533

Epoch: 6| Step: 8
Training loss: 2.097926139831543
Validation loss: 2.0245872415522093

Epoch: 6| Step: 9
Training loss: 1.2674858570098877
Validation loss: 2.002967985727454

Epoch: 6| Step: 10
Training loss: 2.1245615482330322
Validation loss: 2.006961784055156

Epoch: 6| Step: 11
Training loss: 2.644436836242676
Validation loss: 2.004400343023321

Epoch: 6| Step: 12
Training loss: 2.111396551132202
Validation loss: 2.0017506819899364

Epoch: 6| Step: 13
Training loss: 1.6490073204040527
Validation loss: 2.0236292244285665

Epoch: 173| Step: 0
Training loss: 2.0130810737609863
Validation loss: 2.0061891002039753

Epoch: 6| Step: 1
Training loss: 2.7778873443603516
Validation loss: 1.995523875759494

Epoch: 6| Step: 2
Training loss: 2.459094524383545
Validation loss: 2.0039081240213044

Epoch: 6| Step: 3
Training loss: 1.896926760673523
Validation loss: 2.0091895159854682

Epoch: 6| Step: 4
Training loss: 2.04934024810791
Validation loss: 1.9905564272275535

Epoch: 6| Step: 5
Training loss: 1.4674283266067505
Validation loss: 1.9845603947998376

Epoch: 6| Step: 6
Training loss: 1.9437217712402344
Validation loss: 2.0053936948058424

Epoch: 6| Step: 7
Training loss: 2.221223831176758
Validation loss: 2.0100440209911716

Epoch: 6| Step: 8
Training loss: 1.6315741539001465
Validation loss: 1.989784158686156

Epoch: 6| Step: 9
Training loss: 1.6431102752685547
Validation loss: 1.9953238630807528

Epoch: 6| Step: 10
Training loss: 2.1879782676696777
Validation loss: 1.9952445645486154

Epoch: 6| Step: 11
Training loss: 1.9910279512405396
Validation loss: 1.9872383481712752

Epoch: 6| Step: 12
Training loss: 1.5218167304992676
Validation loss: 2.002682860179614

Epoch: 6| Step: 13
Training loss: 1.5833104848861694
Validation loss: 1.9885298552051667

Epoch: 174| Step: 0
Training loss: 1.735456943511963
Validation loss: 1.9958600972288398

Epoch: 6| Step: 1
Training loss: 2.5595927238464355
Validation loss: 2.0056450033700592

Epoch: 6| Step: 2
Training loss: 1.8077714443206787
Validation loss: 1.9962134027993808

Epoch: 6| Step: 3
Training loss: 2.184645652770996
Validation loss: 1.9949338615581553

Epoch: 6| Step: 4
Training loss: 2.1655731201171875
Validation loss: 1.9978363475491923

Epoch: 6| Step: 5
Training loss: 2.161034345626831
Validation loss: 1.9881485431425032

Epoch: 6| Step: 6
Training loss: 1.7475452423095703
Validation loss: 1.996539286387864

Epoch: 6| Step: 7
Training loss: 1.780534267425537
Validation loss: 2.016185918161946

Epoch: 6| Step: 8
Training loss: 1.804473638534546
Validation loss: 2.0321884552637735

Epoch: 6| Step: 9
Training loss: 1.8406568765640259
Validation loss: 1.9953176039521412

Epoch: 6| Step: 10
Training loss: 1.815961480140686
Validation loss: 1.9947707832500499

Epoch: 6| Step: 11
Training loss: 1.5954740047454834
Validation loss: 1.9830363745330482

Epoch: 6| Step: 12
Training loss: 2.1011252403259277
Validation loss: 1.984036176435409

Epoch: 6| Step: 13
Training loss: 2.23163104057312
Validation loss: 1.9928204897911317

Epoch: 175| Step: 0
Training loss: 2.153212308883667
Validation loss: 2.019019906238843

Epoch: 6| Step: 1
Training loss: 2.0966997146606445
Validation loss: 1.9864791541971185

Epoch: 6| Step: 2
Training loss: 2.3033106327056885
Validation loss: 1.9717286376542942

Epoch: 6| Step: 3
Training loss: 1.3037083148956299
Validation loss: 1.9788235054221204

Epoch: 6| Step: 4
Training loss: 2.7110111713409424
Validation loss: 1.9563521800502655

Epoch: 6| Step: 5
Training loss: 1.4296398162841797
Validation loss: 1.9726474708126438

Epoch: 6| Step: 6
Training loss: 2.05940580368042
Validation loss: 2.0135928251410045

Epoch: 6| Step: 7
Training loss: 2.5890450477600098
Validation loss: 1.99785961386978

Epoch: 6| Step: 8
Training loss: 1.6242082118988037
Validation loss: 1.9742890429753128

Epoch: 6| Step: 9
Training loss: 1.9856033325195312
Validation loss: 2.0327652628703783

Epoch: 6| Step: 10
Training loss: 1.625244379043579
Validation loss: 1.9987568175920876

Epoch: 6| Step: 11
Training loss: 1.8307451009750366
Validation loss: 2.037878078799094

Epoch: 6| Step: 12
Training loss: 1.9424383640289307
Validation loss: 2.0055475004257692

Epoch: 6| Step: 13
Training loss: 1.3207660913467407
Validation loss: 2.031111337805307

Epoch: 176| Step: 0
Training loss: 1.5306501388549805
Validation loss: 2.0134822322476293

Epoch: 6| Step: 1
Training loss: 2.0911593437194824
Validation loss: 1.9923334711341447

Epoch: 6| Step: 2
Training loss: 2.3449273109436035
Validation loss: 1.9967054141465055

Epoch: 6| Step: 3
Training loss: 1.1222898960113525
Validation loss: 1.9945808982336393

Epoch: 6| Step: 4
Training loss: 1.7739074230194092
Validation loss: 1.9966686028306202

Epoch: 6| Step: 5
Training loss: 2.1964383125305176
Validation loss: 1.989818488397906

Epoch: 6| Step: 6
Training loss: 1.876481533050537
Validation loss: 1.9846473073446622

Epoch: 6| Step: 7
Training loss: 1.7886219024658203
Validation loss: 2.0000305662872973

Epoch: 6| Step: 8
Training loss: 1.9707598686218262
Validation loss: 1.9778582716500888

Epoch: 6| Step: 9
Training loss: 3.0411148071289062
Validation loss: 1.995767060146537

Epoch: 6| Step: 10
Training loss: 2.136138916015625
Validation loss: 2.0015623659215946

Epoch: 6| Step: 11
Training loss: 1.9540588855743408
Validation loss: 1.992111764928346

Epoch: 6| Step: 12
Training loss: 1.707018494606018
Validation loss: 1.9887158011877408

Epoch: 6| Step: 13
Training loss: 1.4395670890808105
Validation loss: 1.9942601996083413

Epoch: 177| Step: 0
Training loss: 1.4784281253814697
Validation loss: 1.9906712591007192

Epoch: 6| Step: 1
Training loss: 1.5373871326446533
Validation loss: 1.9988386925830637

Epoch: 6| Step: 2
Training loss: 1.636668086051941
Validation loss: 2.0059234467885827

Epoch: 6| Step: 3
Training loss: 1.8504031896591187
Validation loss: 1.9937255267174012

Epoch: 6| Step: 4
Training loss: 2.3262810707092285
Validation loss: 1.9861066828491867

Epoch: 6| Step: 5
Training loss: 2.409437656402588
Validation loss: 2.0159977969302925

Epoch: 6| Step: 6
Training loss: 2.2679481506347656
Validation loss: 1.9689042273388113

Epoch: 6| Step: 7
Training loss: 2.019094467163086
Validation loss: 1.9525481462478638

Epoch: 6| Step: 8
Training loss: 1.8047162294387817
Validation loss: 1.9858857239446333

Epoch: 6| Step: 9
Training loss: 2.0886974334716797
Validation loss: 1.9622446747236355

Epoch: 6| Step: 10
Training loss: 2.1075026988983154
Validation loss: 1.9700032869974773

Epoch: 6| Step: 11
Training loss: 1.7367773056030273
Validation loss: 1.9855163751109954

Epoch: 6| Step: 12
Training loss: 1.8968946933746338
Validation loss: 1.9723755992868894

Epoch: 6| Step: 13
Training loss: 2.094517946243286
Validation loss: 1.9824994482019895

Epoch: 178| Step: 0
Training loss: 1.6879377365112305
Validation loss: 1.9500483928188201

Epoch: 6| Step: 1
Training loss: 2.541276454925537
Validation loss: 1.964661080350158

Epoch: 6| Step: 2
Training loss: 2.510190486907959
Validation loss: 1.9781859715779622

Epoch: 6| Step: 3
Training loss: 2.3425326347351074
Validation loss: 1.9965509676164197

Epoch: 6| Step: 4
Training loss: 1.6586029529571533
Validation loss: 1.9826076517822921

Epoch: 6| Step: 5
Training loss: 2.0193722248077393
Validation loss: 1.9627310922068935

Epoch: 6| Step: 6
Training loss: 1.813276767730713
Validation loss: 1.9995550981131933

Epoch: 6| Step: 7
Training loss: 1.720076560974121
Validation loss: 1.9497226335669076

Epoch: 6| Step: 8
Training loss: 1.6437489986419678
Validation loss: 1.9945650280162852

Epoch: 6| Step: 9
Training loss: 2.341449499130249
Validation loss: 1.9610939577061643

Epoch: 6| Step: 10
Training loss: 1.6250336170196533
Validation loss: 1.9686210078577842

Epoch: 6| Step: 11
Training loss: 1.6559650897979736
Validation loss: 1.9927252595142653

Epoch: 6| Step: 12
Training loss: 2.080641746520996
Validation loss: 2.0148825863356232

Epoch: 6| Step: 13
Training loss: 1.000497579574585
Validation loss: 1.9973769111018027

Epoch: 179| Step: 0
Training loss: 1.5644958019256592
Validation loss: 2.00261192424323

Epoch: 6| Step: 1
Training loss: 1.7763147354125977
Validation loss: 1.9751146044782413

Epoch: 6| Step: 2
Training loss: 1.84092116355896
Validation loss: 1.9719930797494867

Epoch: 6| Step: 3
Training loss: 1.8659465312957764
Validation loss: 1.9962011139879945

Epoch: 6| Step: 4
Training loss: 2.580524444580078
Validation loss: 1.9731780393149263

Epoch: 6| Step: 5
Training loss: 1.350804090499878
Validation loss: 1.9883021718712264

Epoch: 6| Step: 6
Training loss: 2.0050997734069824
Validation loss: 2.0033177803921443

Epoch: 6| Step: 7
Training loss: 2.0799779891967773
Validation loss: 1.9655458388790008

Epoch: 6| Step: 8
Training loss: 1.9265856742858887
Validation loss: 2.019277557249992

Epoch: 6| Step: 9
Training loss: 1.9862366914749146
Validation loss: 1.989487737737676

Epoch: 6| Step: 10
Training loss: 2.0547080039978027
Validation loss: 1.969668657548966

Epoch: 6| Step: 11
Training loss: 2.0216941833496094
Validation loss: 1.9753009068068637

Epoch: 6| Step: 12
Training loss: 2.0390303134918213
Validation loss: 2.001178824773399

Epoch: 6| Step: 13
Training loss: 2.032963752746582
Validation loss: 1.9922249509442238

Epoch: 180| Step: 0
Training loss: 2.5042834281921387
Validation loss: 1.9767547858658658

Epoch: 6| Step: 1
Training loss: 2.167335033416748
Validation loss: 1.979766950812391

Epoch: 6| Step: 2
Training loss: 1.6008577346801758
Validation loss: 1.9871639526018532

Epoch: 6| Step: 3
Training loss: 1.542245864868164
Validation loss: 1.988807742313672

Epoch: 6| Step: 4
Training loss: 1.994786024093628
Validation loss: 1.9796829877361175

Epoch: 6| Step: 5
Training loss: 2.1701579093933105
Validation loss: 1.9794091845071444

Epoch: 6| Step: 6
Training loss: 1.9016695022583008
Validation loss: 1.9551024206223027

Epoch: 6| Step: 7
Training loss: 1.9299712181091309
Validation loss: 1.9650196388203611

Epoch: 6| Step: 8
Training loss: 2.2860517501831055
Validation loss: 1.9890397838366929

Epoch: 6| Step: 9
Training loss: 1.444178581237793
Validation loss: 1.9733867542718047

Epoch: 6| Step: 10
Training loss: 1.9011375904083252
Validation loss: 1.9641925429785123

Epoch: 6| Step: 11
Training loss: 1.9814940690994263
Validation loss: 1.976393074117681

Epoch: 6| Step: 12
Training loss: 1.6388587951660156
Validation loss: 1.9769020208748438

Epoch: 6| Step: 13
Training loss: 1.6201589107513428
Validation loss: 1.9757433796441684

Epoch: 181| Step: 0
Training loss: 1.7352080345153809
Validation loss: 1.9715620548494401

Epoch: 6| Step: 1
Training loss: 2.481628894805908
Validation loss: 1.9891707140912291

Epoch: 6| Step: 2
Training loss: 1.8228538036346436
Validation loss: 1.9837306404626498

Epoch: 6| Step: 3
Training loss: 1.5057499408721924
Validation loss: 2.0196346813632595

Epoch: 6| Step: 4
Training loss: 2.3297336101531982
Validation loss: 1.999128467293196

Epoch: 6| Step: 5
Training loss: 1.572311282157898
Validation loss: 1.9681259560328659

Epoch: 6| Step: 6
Training loss: 1.7958590984344482
Validation loss: 1.9888614608395485

Epoch: 6| Step: 7
Training loss: 2.1802215576171875
Validation loss: 1.9537570937987296

Epoch: 6| Step: 8
Training loss: 1.9026224613189697
Validation loss: 1.9696834510372532

Epoch: 6| Step: 9
Training loss: 1.6028780937194824
Validation loss: 1.9862276559234948

Epoch: 6| Step: 10
Training loss: 2.0044660568237305
Validation loss: 1.9651347808940436

Epoch: 6| Step: 11
Training loss: 1.9696403741836548
Validation loss: 1.9776849362158007

Epoch: 6| Step: 12
Training loss: 2.559408187866211
Validation loss: 1.9777175867429344

Epoch: 6| Step: 13
Training loss: 1.6243313550949097
Validation loss: 1.9720570695015691

Epoch: 182| Step: 0
Training loss: 1.5624194145202637
Validation loss: 1.9528745887100056

Epoch: 6| Step: 1
Training loss: 1.876507043838501
Validation loss: 1.9308219289266935

Epoch: 6| Step: 2
Training loss: 2.053877115249634
Validation loss: 1.9708333105169318

Epoch: 6| Step: 3
Training loss: 2.102330207824707
Validation loss: 1.9917874772061583

Epoch: 6| Step: 4
Training loss: 2.3149867057800293
Validation loss: 1.9595387751056301

Epoch: 6| Step: 5
Training loss: 1.9681012630462646
Validation loss: 1.96392539880609

Epoch: 6| Step: 6
Training loss: 1.9025168418884277
Validation loss: 2.0147557181696736

Epoch: 6| Step: 7
Training loss: 1.8359051942825317
Validation loss: 1.9844428454675982

Epoch: 6| Step: 8
Training loss: 1.385049819946289
Validation loss: 2.0021892452752716

Epoch: 6| Step: 9
Training loss: 1.9829254150390625
Validation loss: 1.996737318654214

Epoch: 6| Step: 10
Training loss: 1.9243512153625488
Validation loss: 2.0001277359583045

Epoch: 6| Step: 11
Training loss: 1.7809395790100098
Validation loss: 1.9812267672631048

Epoch: 6| Step: 12
Training loss: 1.8249657154083252
Validation loss: 1.984803484332177

Epoch: 6| Step: 13
Training loss: 2.2757089138031006
Validation loss: 1.999479547623665

Epoch: 183| Step: 0
Training loss: 2.6733193397521973
Validation loss: 1.9971324961672547

Epoch: 6| Step: 1
Training loss: 1.0874462127685547
Validation loss: 1.963070284935736

Epoch: 6| Step: 2
Training loss: 2.24177885055542
Validation loss: 1.9996942243268412

Epoch: 6| Step: 3
Training loss: 2.17755126953125
Validation loss: 1.973037927381454

Epoch: 6| Step: 4
Training loss: 1.666433572769165
Validation loss: 1.9836677966579315

Epoch: 6| Step: 5
Training loss: 1.9001868963241577
Validation loss: 2.007091822162751

Epoch: 6| Step: 6
Training loss: 1.6033257246017456
Validation loss: 2.0289960702260337

Epoch: 6| Step: 7
Training loss: 2.250663995742798
Validation loss: 1.9941365795750772

Epoch: 6| Step: 8
Training loss: 2.0559329986572266
Validation loss: 1.9892711383040234

Epoch: 6| Step: 9
Training loss: 2.096348762512207
Validation loss: 1.9562830937805997

Epoch: 6| Step: 10
Training loss: 1.9505752325057983
Validation loss: 1.9866373885062434

Epoch: 6| Step: 11
Training loss: 1.7016360759735107
Validation loss: 1.9942821046357513

Epoch: 6| Step: 12
Training loss: 1.3823517560958862
Validation loss: 1.9965055681044055

Epoch: 6| Step: 13
Training loss: 1.5338879823684692
Validation loss: 1.9991466255598171

Epoch: 184| Step: 0
Training loss: 2.186521053314209
Validation loss: 1.9403169821667414

Epoch: 6| Step: 1
Training loss: 1.6298898458480835
Validation loss: 1.9819588353556972

Epoch: 6| Step: 2
Training loss: 1.7113850116729736
Validation loss: 1.977467062652752

Epoch: 6| Step: 3
Training loss: 1.5252182483673096
Validation loss: 1.9828363913361744

Epoch: 6| Step: 4
Training loss: 2.035565137863159
Validation loss: 1.9496324203347648

Epoch: 6| Step: 5
Training loss: 1.736685037612915
Validation loss: 1.9817082523017802

Epoch: 6| Step: 6
Training loss: 1.5975730419158936
Validation loss: 1.9630370498985372

Epoch: 6| Step: 7
Training loss: 2.561771869659424
Validation loss: 1.9784268897066835

Epoch: 6| Step: 8
Training loss: 1.6171374320983887
Validation loss: 1.9236752038360925

Epoch: 6| Step: 9
Training loss: 2.2424657344818115
Validation loss: 1.9651742558325491

Epoch: 6| Step: 10
Training loss: 1.8939121961593628
Validation loss: 1.9616456467618224

Epoch: 6| Step: 11
Training loss: 1.808323860168457
Validation loss: 1.9819642741193053

Epoch: 6| Step: 12
Training loss: 1.9537492990493774
Validation loss: 1.9620577827576668

Epoch: 6| Step: 13
Training loss: 2.2073416709899902
Validation loss: 1.964335149334323

Epoch: 185| Step: 0
Training loss: 2.032947063446045
Validation loss: 1.9394450008228261

Epoch: 6| Step: 1
Training loss: 1.6490787267684937
Validation loss: 1.9490935584550262

Epoch: 6| Step: 2
Training loss: 1.1991370916366577
Validation loss: 1.9416852779285882

Epoch: 6| Step: 3
Training loss: 1.564523458480835
Validation loss: 1.9661318115008775

Epoch: 6| Step: 4
Training loss: 1.8041152954101562
Validation loss: 1.9727078317314066

Epoch: 6| Step: 5
Training loss: 1.7129473686218262
Validation loss: 1.9732664554349837

Epoch: 6| Step: 6
Training loss: 1.8849574327468872
Validation loss: 1.9504055733321815

Epoch: 6| Step: 7
Training loss: 2.543281078338623
Validation loss: 1.9702915453141736

Epoch: 6| Step: 8
Training loss: 1.758135199546814
Validation loss: 1.9249078919810634

Epoch: 6| Step: 9
Training loss: 2.5513272285461426
Validation loss: 1.985229717787876

Epoch: 6| Step: 10
Training loss: 1.4972954988479614
Validation loss: 1.9378144882058586

Epoch: 6| Step: 11
Training loss: 2.269324779510498
Validation loss: 1.9764512867055914

Epoch: 6| Step: 12
Training loss: 2.4004335403442383
Validation loss: 1.9421111499109576

Epoch: 6| Step: 13
Training loss: 1.8816204071044922
Validation loss: 1.9597487500918809

Epoch: 186| Step: 0
Training loss: 2.0713648796081543
Validation loss: 1.9608169306990921

Epoch: 6| Step: 1
Training loss: 2.0311107635498047
Validation loss: 1.9456682230836602

Epoch: 6| Step: 2
Training loss: 1.7071759700775146
Validation loss: 1.9855602300295265

Epoch: 6| Step: 3
Training loss: 1.488647699356079
Validation loss: 1.9862483252761185

Epoch: 6| Step: 4
Training loss: 1.70663583278656
Validation loss: 1.9352804332651117

Epoch: 6| Step: 5
Training loss: 2.0732927322387695
Validation loss: 1.9733900357318181

Epoch: 6| Step: 6
Training loss: 1.7475535869598389
Validation loss: 1.942162134314096

Epoch: 6| Step: 7
Training loss: 1.8386330604553223
Validation loss: 1.9881484136786511

Epoch: 6| Step: 8
Training loss: 2.075169324874878
Validation loss: 1.955997258104304

Epoch: 6| Step: 9
Training loss: 1.846672534942627
Validation loss: 1.946500842289258

Epoch: 6| Step: 10
Training loss: 1.8995944261550903
Validation loss: 1.973311798546904

Epoch: 6| Step: 11
Training loss: 1.6826399564743042
Validation loss: 1.9854603916086175

Epoch: 6| Step: 12
Training loss: 2.336592674255371
Validation loss: 1.964162298428115

Epoch: 6| Step: 13
Training loss: 2.223937511444092
Validation loss: 1.9662290285992365

Epoch: 187| Step: 0
Training loss: 2.004862070083618
Validation loss: 1.9600404667597946

Epoch: 6| Step: 1
Training loss: 1.4924499988555908
Validation loss: 1.9817600173334922

Epoch: 6| Step: 2
Training loss: 1.5765197277069092
Validation loss: 1.9741582344937068

Epoch: 6| Step: 3
Training loss: 1.4015345573425293
Validation loss: 1.974122255079208

Epoch: 6| Step: 4
Training loss: 2.0581233501434326
Validation loss: 1.96191680559548

Epoch: 6| Step: 5
Training loss: 1.3950626850128174
Validation loss: 2.0161665665206088

Epoch: 6| Step: 6
Training loss: 2.3446812629699707
Validation loss: 2.0195204083637526

Epoch: 6| Step: 7
Training loss: 3.171945095062256
Validation loss: 1.98242461809548

Epoch: 6| Step: 8
Training loss: 2.0698986053466797
Validation loss: 1.9832317957314112

Epoch: 6| Step: 9
Training loss: 1.8701013326644897
Validation loss: 2.0007907152175903

Epoch: 6| Step: 10
Training loss: 1.5545830726623535
Validation loss: 1.9723199170122865

Epoch: 6| Step: 11
Training loss: 1.9584615230560303
Validation loss: 1.962695493493029

Epoch: 6| Step: 12
Training loss: 1.6189460754394531
Validation loss: 1.9628475430191203

Epoch: 6| Step: 13
Training loss: 2.3206369876861572
Validation loss: 1.9675655826445548

Epoch: 188| Step: 0
Training loss: 2.646392345428467
Validation loss: 1.9688893697595085

Epoch: 6| Step: 1
Training loss: 1.6360514163970947
Validation loss: 1.9504203527204451

Epoch: 6| Step: 2
Training loss: 2.0694918632507324
Validation loss: 1.9321469388982302

Epoch: 6| Step: 3
Training loss: 1.9173784255981445
Validation loss: 1.9404092911751039

Epoch: 6| Step: 4
Training loss: 1.9813265800476074
Validation loss: 1.924339686670611

Epoch: 6| Step: 5
Training loss: 0.9132157564163208
Validation loss: 1.9663410609768284

Epoch: 6| Step: 6
Training loss: 1.3654634952545166
Validation loss: 1.9705054170341902

Epoch: 6| Step: 7
Training loss: 2.0261666774749756
Validation loss: 1.919755151194911

Epoch: 6| Step: 8
Training loss: 1.5976821184158325
Validation loss: 1.946943280517414

Epoch: 6| Step: 9
Training loss: 1.819035291671753
Validation loss: 1.9799471260398946

Epoch: 6| Step: 10
Training loss: 2.430361032485962
Validation loss: 1.9387081361586047

Epoch: 6| Step: 11
Training loss: 2.5189967155456543
Validation loss: 1.9184544060819892

Epoch: 6| Step: 12
Training loss: 1.847923994064331
Validation loss: 1.9503844130423762

Epoch: 6| Step: 13
Training loss: 1.8577027320861816
Validation loss: 1.9459052316604122

Epoch: 189| Step: 0
Training loss: 1.2839540243148804
Validation loss: 1.919425674664077

Epoch: 6| Step: 1
Training loss: 1.595847725868225
Validation loss: 1.952562858981471

Epoch: 6| Step: 2
Training loss: 1.7369791269302368
Validation loss: 1.9916760601023191

Epoch: 6| Step: 3
Training loss: 2.620479106903076
Validation loss: 1.95356289545695

Epoch: 6| Step: 4
Training loss: 1.737037181854248
Validation loss: 1.9301677314184045

Epoch: 6| Step: 5
Training loss: 2.786264181137085
Validation loss: 1.971876218754758

Epoch: 6| Step: 6
Training loss: 1.9585742950439453
Validation loss: 1.9470770269311883

Epoch: 6| Step: 7
Training loss: 1.2414591312408447
Validation loss: 1.938791073137714

Epoch: 6| Step: 8
Training loss: 1.4997820854187012
Validation loss: 1.9818992063563357

Epoch: 6| Step: 9
Training loss: 2.3665788173675537
Validation loss: 1.9894349933952413

Epoch: 6| Step: 10
Training loss: 2.477318048477173
Validation loss: 2.0018197362140944

Epoch: 6| Step: 11
Training loss: 1.6972519159317017
Validation loss: 1.975717572755711

Epoch: 6| Step: 12
Training loss: 1.6863408088684082
Validation loss: 1.9900122560480589

Epoch: 6| Step: 13
Training loss: 2.2468886375427246
Validation loss: 1.971946652217578

Epoch: 190| Step: 0
Training loss: 1.5862129926681519
Validation loss: 1.961443446015799

Epoch: 6| Step: 1
Training loss: 2.157658815383911
Validation loss: 1.9802518736931585

Epoch: 6| Step: 2
Training loss: 2.3709328174591064
Validation loss: 1.9866542675161873

Epoch: 6| Step: 3
Training loss: 1.712052345275879
Validation loss: 1.935476908119776

Epoch: 6| Step: 4
Training loss: 1.8614556789398193
Validation loss: 1.9602585249049689

Epoch: 6| Step: 5
Training loss: 2.0316169261932373
Validation loss: 1.9394183774148264

Epoch: 6| Step: 6
Training loss: 1.6007000207901
Validation loss: 1.9781964607136224

Epoch: 6| Step: 7
Training loss: 2.4071714878082275
Validation loss: 1.9531199137369792

Epoch: 6| Step: 8
Training loss: 1.3174717426300049
Validation loss: 1.9753583656844271

Epoch: 6| Step: 9
Training loss: 1.6300947666168213
Validation loss: 1.9728977436660438

Epoch: 6| Step: 10
Training loss: 1.559640645980835
Validation loss: 1.9656600618875155

Epoch: 6| Step: 11
Training loss: 1.77675199508667
Validation loss: 1.9950376300401584

Epoch: 6| Step: 12
Training loss: 2.1907787322998047
Validation loss: 1.9360580508426954

Epoch: 6| Step: 13
Training loss: 1.9714118242263794
Validation loss: 1.9409916529091455

Epoch: 191| Step: 0
Training loss: 1.9002550840377808
Validation loss: 1.9664602100208242

Epoch: 6| Step: 1
Training loss: 1.7122585773468018
Validation loss: 1.9615601019192768

Epoch: 6| Step: 2
Training loss: 1.683138132095337
Validation loss: 1.9666033073138165

Epoch: 6| Step: 3
Training loss: 1.641334056854248
Validation loss: 1.9487091674599597

Epoch: 6| Step: 4
Training loss: 1.7666535377502441
Validation loss: 1.951150043036348

Epoch: 6| Step: 5
Training loss: 1.8949172496795654
Validation loss: 1.9333606355933732

Epoch: 6| Step: 6
Training loss: 1.9532675743103027
Validation loss: 1.9456906831392677

Epoch: 6| Step: 7
Training loss: 1.5964611768722534
Validation loss: 1.9353570912473945

Epoch: 6| Step: 8
Training loss: 2.156409740447998
Validation loss: 1.9147707621256511

Epoch: 6| Step: 9
Training loss: 2.517320156097412
Validation loss: 1.8863506970867034

Epoch: 6| Step: 10
Training loss: 1.9022936820983887
Validation loss: 1.9185724168695428

Epoch: 6| Step: 11
Training loss: 2.203050136566162
Validation loss: 1.9181877592558503

Epoch: 6| Step: 12
Training loss: 1.7348989248275757
Validation loss: 1.926157912900371

Epoch: 6| Step: 13
Training loss: 1.5237364768981934
Validation loss: 1.9476654016843407

Epoch: 192| Step: 0
Training loss: 2.558701276779175
Validation loss: 1.9116050915051532

Epoch: 6| Step: 1
Training loss: 2.2478089332580566
Validation loss: 1.926862084737388

Epoch: 6| Step: 2
Training loss: 1.356208086013794
Validation loss: 1.9582741580983645

Epoch: 6| Step: 3
Training loss: 1.6949536800384521
Validation loss: 1.9288616782875472

Epoch: 6| Step: 4
Training loss: 1.5927293300628662
Validation loss: 1.9574302396466654

Epoch: 6| Step: 5
Training loss: 1.7141752243041992
Validation loss: 1.9471608695163523

Epoch: 6| Step: 6
Training loss: 1.593941569328308
Validation loss: 1.9408323636618994

Epoch: 6| Step: 7
Training loss: 1.9472180604934692
Validation loss: 1.9515135416420557

Epoch: 6| Step: 8
Training loss: 2.2041587829589844
Validation loss: 1.942953936515316

Epoch: 6| Step: 9
Training loss: 2.0067455768585205
Validation loss: 1.9535129454828077

Epoch: 6| Step: 10
Training loss: 1.9114621877670288
Validation loss: 2.0147875252590386

Epoch: 6| Step: 11
Training loss: 1.971476435661316
Validation loss: 1.9679259305359216

Epoch: 6| Step: 12
Training loss: 2.0171337127685547
Validation loss: 1.972266645841701

Epoch: 6| Step: 13
Training loss: 0.5267784595489502
Validation loss: 1.9890249698392806

Epoch: 193| Step: 0
Training loss: 1.5137243270874023
Validation loss: 1.9864029474155878

Epoch: 6| Step: 1
Training loss: 1.7136882543563843
Validation loss: 1.9818024545587518

Epoch: 6| Step: 2
Training loss: 1.5193884372711182
Validation loss: 1.9711576225937053

Epoch: 6| Step: 3
Training loss: 1.9352084398269653
Validation loss: 1.951086539094166

Epoch: 6| Step: 4
Training loss: 1.9397008419036865
Validation loss: 1.9653115003339705

Epoch: 6| Step: 5
Training loss: 2.048326253890991
Validation loss: 1.9778945625469249

Epoch: 6| Step: 6
Training loss: 1.9418246746063232
Validation loss: 1.949769712263538

Epoch: 6| Step: 7
Training loss: 2.5756936073303223
Validation loss: 1.9722652563484766

Epoch: 6| Step: 8
Training loss: 1.375505805015564
Validation loss: 1.9765792226278653

Epoch: 6| Step: 9
Training loss: 2.363149642944336
Validation loss: 1.9333905071340582

Epoch: 6| Step: 10
Training loss: 1.161428451538086
Validation loss: 1.944384018580119

Epoch: 6| Step: 11
Training loss: 2.016629695892334
Validation loss: 1.9661187766700663

Epoch: 6| Step: 12
Training loss: 1.8108417987823486
Validation loss: 1.9396789291853547

Epoch: 6| Step: 13
Training loss: 2.6442513465881348
Validation loss: 1.9557855257423975

Epoch: 194| Step: 0
Training loss: 1.7479667663574219
Validation loss: 1.9222891856265325

Epoch: 6| Step: 1
Training loss: 2.309737205505371
Validation loss: 1.9593412337764617

Epoch: 6| Step: 2
Training loss: 1.7933523654937744
Validation loss: 1.943592474024783

Epoch: 6| Step: 3
Training loss: 1.4377293586730957
Validation loss: 1.960640617596206

Epoch: 6| Step: 4
Training loss: 2.2794694900512695
Validation loss: 1.9662346570722518

Epoch: 6| Step: 5
Training loss: 1.9825832843780518
Validation loss: 1.9443362105277278

Epoch: 6| Step: 6
Training loss: 1.8392009735107422
Validation loss: 1.9478713158638246

Epoch: 6| Step: 7
Training loss: 2.1908555030822754
Validation loss: 1.9428384022046161

Epoch: 6| Step: 8
Training loss: 1.7993922233581543
Validation loss: 1.9224314946000294

Epoch: 6| Step: 9
Training loss: 2.144510507583618
Validation loss: 1.916558724577709

Epoch: 6| Step: 10
Training loss: 1.6791176795959473
Validation loss: 1.9596152485057872

Epoch: 6| Step: 11
Training loss: 1.5430595874786377
Validation loss: 1.9643751934010496

Epoch: 6| Step: 12
Training loss: 1.539729118347168
Validation loss: 1.9544737287746963

Epoch: 6| Step: 13
Training loss: 1.7696775197982788
Validation loss: 1.9831636541633195

Epoch: 195| Step: 0
Training loss: 1.774362325668335
Validation loss: 1.908162747659991

Epoch: 6| Step: 1
Training loss: 1.2799749374389648
Validation loss: 1.9151258237900273

Epoch: 6| Step: 2
Training loss: 2.3193225860595703
Validation loss: 1.9166483186906385

Epoch: 6| Step: 3
Training loss: 1.854519009590149
Validation loss: 1.95150540977396

Epoch: 6| Step: 4
Training loss: 1.7278083562850952
Validation loss: 1.953468870091182

Epoch: 6| Step: 5
Training loss: 2.0315282344818115
Validation loss: 1.9501037546383437

Epoch: 6| Step: 6
Training loss: 1.8413010835647583
Validation loss: 1.918543836121918

Epoch: 6| Step: 7
Training loss: 1.4805666208267212
Validation loss: 1.9240353248452629

Epoch: 6| Step: 8
Training loss: 2.344529151916504
Validation loss: 1.9418778316949004

Epoch: 6| Step: 9
Training loss: 1.7096948623657227
Validation loss: 1.9152544147224837

Epoch: 6| Step: 10
Training loss: 2.137073278427124
Validation loss: 1.9554035817423174

Epoch: 6| Step: 11
Training loss: 1.7161873579025269
Validation loss: 1.9077436026706491

Epoch: 6| Step: 12
Training loss: 1.6554640531539917
Validation loss: 1.928587882749496

Epoch: 6| Step: 13
Training loss: 2.061469793319702
Validation loss: 1.9060720038670365

Epoch: 196| Step: 0
Training loss: 1.2965672016143799
Validation loss: 1.9244950561113254

Epoch: 6| Step: 1
Training loss: 1.767854928970337
Validation loss: 1.92055764121394

Epoch: 6| Step: 2
Training loss: 1.4976799488067627
Validation loss: 1.9172332876472062

Epoch: 6| Step: 3
Training loss: 1.757720947265625
Validation loss: 1.936353975726712

Epoch: 6| Step: 4
Training loss: 2.3028781414031982
Validation loss: 1.9574354887008667

Epoch: 6| Step: 5
Training loss: 1.7068467140197754
Validation loss: 1.9245696144719278

Epoch: 6| Step: 6
Training loss: 2.3587427139282227
Validation loss: 1.9140374814310381

Epoch: 6| Step: 7
Training loss: 2.1161952018737793
Validation loss: 1.924059696094964

Epoch: 6| Step: 8
Training loss: 2.0927093029022217
Validation loss: 1.9361475539463822

Epoch: 6| Step: 9
Training loss: 1.972522258758545
Validation loss: 1.8916088893849363

Epoch: 6| Step: 10
Training loss: 1.5114959478378296
Validation loss: 1.9435244375659573

Epoch: 6| Step: 11
Training loss: 2.112109899520874
Validation loss: 1.9364263537109538

Epoch: 6| Step: 12
Training loss: 1.8584388494491577
Validation loss: 1.9329836471106416

Epoch: 6| Step: 13
Training loss: 1.3505425453186035
Validation loss: 1.9590795296494679

Epoch: 197| Step: 0
Training loss: 1.7287461757659912
Validation loss: 1.9459069082813878

Epoch: 6| Step: 1
Training loss: 1.445501685142517
Validation loss: 1.9412533698543426

Epoch: 6| Step: 2
Training loss: 1.6964789628982544
Validation loss: 1.9443864566023632

Epoch: 6| Step: 3
Training loss: 2.2523415088653564
Validation loss: 1.9667550556121334

Epoch: 6| Step: 4
Training loss: 2.3665363788604736
Validation loss: 1.94601470680647

Epoch: 6| Step: 5
Training loss: 2.345212697982788
Validation loss: 1.9620261192321777

Epoch: 6| Step: 6
Training loss: 1.5851163864135742
Validation loss: 1.9713955284446798

Epoch: 6| Step: 7
Training loss: 1.9283061027526855
Validation loss: 1.9718662205562796

Epoch: 6| Step: 8
Training loss: 1.8429961204528809
Validation loss: 1.9693041078505977

Epoch: 6| Step: 9
Training loss: 2.007936954498291
Validation loss: 1.9980339555330173

Epoch: 6| Step: 10
Training loss: 1.2127541303634644
Validation loss: 1.9953148621384815

Epoch: 6| Step: 11
Training loss: 2.4063057899475098
Validation loss: 1.9711636151036909

Epoch: 6| Step: 12
Training loss: 1.1322184801101685
Validation loss: 1.9455823988042853

Epoch: 6| Step: 13
Training loss: 2.101353645324707
Validation loss: 1.9784361854676278

Epoch: 198| Step: 0
Training loss: 1.8779106140136719
Validation loss: 1.947597401116484

Epoch: 6| Step: 1
Training loss: 1.8245477676391602
Validation loss: 1.9820845652652044

Epoch: 6| Step: 2
Training loss: 1.9793856143951416
Validation loss: 1.9500615301952566

Epoch: 6| Step: 3
Training loss: 2.318450450897217
Validation loss: 1.9588698828092186

Epoch: 6| Step: 4
Training loss: 1.2800073623657227
Validation loss: 1.927781549833154

Epoch: 6| Step: 5
Training loss: 1.782912254333496
Validation loss: 1.9227109673202678

Epoch: 6| Step: 6
Training loss: 1.8588000535964966
Validation loss: 1.9671678414908789

Epoch: 6| Step: 7
Training loss: 2.249631881713867
Validation loss: 1.927470132227867

Epoch: 6| Step: 8
Training loss: 1.9090216159820557
Validation loss: 1.959335365603047

Epoch: 6| Step: 9
Training loss: 1.857559084892273
Validation loss: 1.912663318777597

Epoch: 6| Step: 10
Training loss: 1.5607502460479736
Validation loss: 1.973242623831636

Epoch: 6| Step: 11
Training loss: 1.8640458583831787
Validation loss: 1.9387857247424383

Epoch: 6| Step: 12
Training loss: 1.8132243156433105
Validation loss: 1.9425396880795878

Epoch: 6| Step: 13
Training loss: 1.6610710620880127
Validation loss: 1.9273898601531982

Epoch: 199| Step: 0
Training loss: 1.6001529693603516
Validation loss: 1.9336941819037161

Epoch: 6| Step: 1
Training loss: 1.1938445568084717
Validation loss: 1.927783739182257

Epoch: 6| Step: 2
Training loss: 1.8256652355194092
Validation loss: 1.9226977978983233

Epoch: 6| Step: 3
Training loss: 1.7665656805038452
Validation loss: 1.8982725015250586

Epoch: 6| Step: 4
Training loss: 2.1484718322753906
Validation loss: 1.913435177136493

Epoch: 6| Step: 5
Training loss: 2.379307746887207
Validation loss: 1.946976484790925

Epoch: 6| Step: 6
Training loss: 2.008127212524414
Validation loss: 1.9497722079676967

Epoch: 6| Step: 7
Training loss: 1.8497135639190674
Validation loss: 1.92996290422255

Epoch: 6| Step: 8
Training loss: 1.8435431718826294
Validation loss: 1.9254907843887166

Epoch: 6| Step: 9
Training loss: 1.842374563217163
Validation loss: 1.9402320179887997

Epoch: 6| Step: 10
Training loss: 2.278311014175415
Validation loss: 1.9154878124114005

Epoch: 6| Step: 11
Training loss: 1.4021062850952148
Validation loss: 1.9669941266377766

Epoch: 6| Step: 12
Training loss: 2.276823043823242
Validation loss: 1.937796320966495

Epoch: 6| Step: 13
Training loss: 1.5460379123687744
Validation loss: 1.9493926596897904

Epoch: 200| Step: 0
Training loss: 1.7584928274154663
Validation loss: 1.948588284113074

Epoch: 6| Step: 1
Training loss: 2.051839828491211
Validation loss: 1.9627800577430314

Epoch: 6| Step: 2
Training loss: 1.6191179752349854
Validation loss: 1.913487926606209

Epoch: 6| Step: 3
Training loss: 1.9025764465332031
Validation loss: 1.9504145524835075

Epoch: 6| Step: 4
Training loss: 2.0204055309295654
Validation loss: 1.9104493907702866

Epoch: 6| Step: 5
Training loss: 1.848120927810669
Validation loss: 1.916973472923361

Epoch: 6| Step: 6
Training loss: 1.831063151359558
Validation loss: 1.9219429390404814

Epoch: 6| Step: 7
Training loss: 2.006145715713501
Validation loss: 1.9191680774893811

Epoch: 6| Step: 8
Training loss: 1.9480669498443604
Validation loss: 1.9187949357494232

Epoch: 6| Step: 9
Training loss: 1.9876264333724976
Validation loss: 1.945571276449388

Epoch: 6| Step: 10
Training loss: 1.4264147281646729
Validation loss: 1.9227689466168802

Epoch: 6| Step: 11
Training loss: 1.9925872087478638
Validation loss: 1.9488985871755948

Epoch: 6| Step: 12
Training loss: 1.3584965467453003
Validation loss: 1.960232396279612

Epoch: 6| Step: 13
Training loss: 1.7052353620529175
Validation loss: 1.9381099042072092

Epoch: 201| Step: 0
Training loss: 1.6248786449432373
Validation loss: 1.9409246816430041

Epoch: 6| Step: 1
Training loss: 1.340638518333435
Validation loss: 1.9321802149536789

Epoch: 6| Step: 2
Training loss: 1.1293587684631348
Validation loss: 1.9533293862496652

Epoch: 6| Step: 3
Training loss: 2.034644603729248
Validation loss: 1.9439263702720724

Epoch: 6| Step: 4
Training loss: 1.2529563903808594
Validation loss: 1.9304173748980287

Epoch: 6| Step: 5
Training loss: 1.2504853010177612
Validation loss: 1.9153345092650382

Epoch: 6| Step: 6
Training loss: 2.2272801399230957
Validation loss: 1.9526304993578183

Epoch: 6| Step: 7
Training loss: 2.373115062713623
Validation loss: 1.9677277047147033

Epoch: 6| Step: 8
Training loss: 2.4998834133148193
Validation loss: 1.9567105283019364

Epoch: 6| Step: 9
Training loss: 1.8795957565307617
Validation loss: 1.9692881761058685

Epoch: 6| Step: 10
Training loss: 2.306168794631958
Validation loss: 1.9699030717213948

Epoch: 6| Step: 11
Training loss: 1.2958488464355469
Validation loss: 1.9690300444121003

Epoch: 6| Step: 12
Training loss: 2.5211784839630127
Validation loss: 1.9704292974164408

Epoch: 6| Step: 13
Training loss: 2.083582878112793
Validation loss: 1.9943758313373854

Epoch: 202| Step: 0
Training loss: 1.5702557563781738
Validation loss: 1.974880810706846

Epoch: 6| Step: 1
Training loss: 1.728752851486206
Validation loss: 1.9610944512069866

Epoch: 6| Step: 2
Training loss: 2.651090145111084
Validation loss: 1.9577539928497807

Epoch: 6| Step: 3
Training loss: 1.688873291015625
Validation loss: 1.948456548875378

Epoch: 6| Step: 4
Training loss: 2.272920608520508
Validation loss: 1.9518732922051543

Epoch: 6| Step: 5
Training loss: 1.5367740392684937
Validation loss: 1.9976635902158675

Epoch: 6| Step: 6
Training loss: 1.9283689260482788
Validation loss: 1.9806212135540542

Epoch: 6| Step: 7
Training loss: 1.6305686235427856
Validation loss: 1.9852888404682119

Epoch: 6| Step: 8
Training loss: 2.007053852081299
Validation loss: 1.975845395877797

Epoch: 6| Step: 9
Training loss: 1.1738429069519043
Validation loss: 1.9299604046729304

Epoch: 6| Step: 10
Training loss: 1.7851300239562988
Validation loss: 1.9009595007024787

Epoch: 6| Step: 11
Training loss: 1.1807754039764404
Validation loss: 1.932639321973247

Epoch: 6| Step: 12
Training loss: 2.1983208656311035
Validation loss: 1.9233737722519906

Epoch: 6| Step: 13
Training loss: 2.4658641815185547
Validation loss: 1.9343422330835813

Epoch: 203| Step: 0
Training loss: 1.6394433975219727
Validation loss: 1.9231033427740938

Epoch: 6| Step: 1
Training loss: 1.2749078273773193
Validation loss: 1.8888047779760053

Epoch: 6| Step: 2
Training loss: 1.713427186012268
Validation loss: 1.9084766321284796

Epoch: 6| Step: 3
Training loss: 1.7292673587799072
Validation loss: 1.9261972955478135

Epoch: 6| Step: 4
Training loss: 2.7117042541503906
Validation loss: 1.9131801307842295

Epoch: 6| Step: 5
Training loss: 1.803814172744751
Validation loss: 1.9253611974818732

Epoch: 6| Step: 6
Training loss: 1.831994652748108
Validation loss: 1.9255413316911267

Epoch: 6| Step: 7
Training loss: 1.478691816329956
Validation loss: 1.9327078301419494

Epoch: 6| Step: 8
Training loss: 1.9789140224456787
Validation loss: 1.9108558944476548

Epoch: 6| Step: 9
Training loss: 1.4577045440673828
Validation loss: 1.932783454977056

Epoch: 6| Step: 10
Training loss: 2.289738178253174
Validation loss: 1.9253361545583254

Epoch: 6| Step: 11
Training loss: 1.9326328039169312
Validation loss: 1.9360136844778573

Epoch: 6| Step: 12
Training loss: 1.8578156232833862
Validation loss: 1.899638727147092

Epoch: 6| Step: 13
Training loss: 1.295464277267456
Validation loss: 1.9021851375538816

Epoch: 204| Step: 0
Training loss: 1.9575334787368774
Validation loss: 1.9335867640792683

Epoch: 6| Step: 1
Training loss: 1.0596425533294678
Validation loss: 1.926547843922851

Epoch: 6| Step: 2
Training loss: 2.3919742107391357
Validation loss: 1.9404169462060417

Epoch: 6| Step: 3
Training loss: 1.7028822898864746
Validation loss: 1.955270274992912

Epoch: 6| Step: 4
Training loss: 1.7916450500488281
Validation loss: 1.8966070157225414

Epoch: 6| Step: 5
Training loss: 1.7682793140411377
Validation loss: 1.9494861659183298

Epoch: 6| Step: 6
Training loss: 2.2767879962921143
Validation loss: 1.949528359597729

Epoch: 6| Step: 7
Training loss: 2.4122438430786133
Validation loss: 1.9443997811245661

Epoch: 6| Step: 8
Training loss: 2.0794477462768555
Validation loss: 1.942585156809899

Epoch: 6| Step: 9
Training loss: 1.3476758003234863
Validation loss: 1.9473349304609402

Epoch: 6| Step: 10
Training loss: 1.9626374244689941
Validation loss: 1.9322076253993536

Epoch: 6| Step: 11
Training loss: 1.3395333290100098
Validation loss: 1.9288313593915714

Epoch: 6| Step: 12
Training loss: 1.5441563129425049
Validation loss: 1.9565580647478822

Epoch: 6| Step: 13
Training loss: 1.8980770111083984
Validation loss: 1.9641942413904334

Epoch: 205| Step: 0
Training loss: 1.9550957679748535
Validation loss: 1.9580210485766012

Epoch: 6| Step: 1
Training loss: 1.5975773334503174
Validation loss: 1.9419658401960969

Epoch: 6| Step: 2
Training loss: 1.3147304058074951
Validation loss: 1.9377702743776384

Epoch: 6| Step: 3
Training loss: 1.6083767414093018
Validation loss: 1.965858208235874

Epoch: 6| Step: 4
Training loss: 1.761669635772705
Validation loss: 1.9604352763904038

Epoch: 6| Step: 5
Training loss: 1.9089471101760864
Validation loss: 1.9573414658987394

Epoch: 6| Step: 6
Training loss: 1.7546699047088623
Validation loss: 1.9263631682242117

Epoch: 6| Step: 7
Training loss: 2.391540765762329
Validation loss: 1.911928182007164

Epoch: 6| Step: 8
Training loss: 1.6583404541015625
Validation loss: 1.975063431647516

Epoch: 6| Step: 9
Training loss: 1.9743633270263672
Validation loss: 1.9370424478284773

Epoch: 6| Step: 10
Training loss: 1.5798888206481934
Validation loss: 1.9082000640130812

Epoch: 6| Step: 11
Training loss: 2.268867015838623
Validation loss: 1.9624100090355001

Epoch: 6| Step: 12
Training loss: 1.740166187286377
Validation loss: 1.900092130066246

Epoch: 6| Step: 13
Training loss: 1.6844278573989868
Validation loss: 1.9258650143941243

Epoch: 206| Step: 0
Training loss: 1.7184871435165405
Validation loss: 1.9488006919942877

Epoch: 6| Step: 1
Training loss: 1.5978749990463257
Validation loss: 1.9000746152734245

Epoch: 6| Step: 2
Training loss: 1.5264675617218018
Validation loss: 1.9445856219978743

Epoch: 6| Step: 3
Training loss: 1.2391678094863892
Validation loss: 1.9349807000929309

Epoch: 6| Step: 4
Training loss: 2.519680976867676
Validation loss: 1.948192088834701

Epoch: 6| Step: 5
Training loss: 0.9994773268699646
Validation loss: 1.9274109460974251

Epoch: 6| Step: 6
Training loss: 1.3628755807876587
Validation loss: 1.9431236918254564

Epoch: 6| Step: 7
Training loss: 2.089569568634033
Validation loss: 1.923447843520872

Epoch: 6| Step: 8
Training loss: 1.9341418743133545
Validation loss: 1.927549110945835

Epoch: 6| Step: 9
Training loss: 2.4361560344696045
Validation loss: 1.9401758742588822

Epoch: 6| Step: 10
Training loss: 1.9686115980148315
Validation loss: 1.936733639368447

Epoch: 6| Step: 11
Training loss: 1.475529670715332
Validation loss: 1.9322396991073445

Epoch: 6| Step: 12
Training loss: 1.8251526355743408
Validation loss: 1.9306713855394753

Epoch: 6| Step: 13
Training loss: 3.3044397830963135
Validation loss: 1.9417094504961403

Epoch: 207| Step: 0
Training loss: 1.6274536848068237
Validation loss: 1.913306466994747

Epoch: 6| Step: 1
Training loss: 1.4265488386154175
Validation loss: 1.9501366538386191

Epoch: 6| Step: 2
Training loss: 1.131527304649353
Validation loss: 1.9327818744926042

Epoch: 6| Step: 3
Training loss: 1.8182382583618164
Validation loss: 1.9256014311185448

Epoch: 6| Step: 4
Training loss: 2.4360687732696533
Validation loss: 1.9617805109229138

Epoch: 6| Step: 5
Training loss: 2.2783780097961426
Validation loss: 1.933420329965571

Epoch: 6| Step: 6
Training loss: 1.8045363426208496
Validation loss: 1.9430058810018724

Epoch: 6| Step: 7
Training loss: 2.1352996826171875
Validation loss: 1.9677958129554667

Epoch: 6| Step: 8
Training loss: 2.0106115341186523
Validation loss: 1.9193579253330026

Epoch: 6| Step: 9
Training loss: 1.0304468870162964
Validation loss: 1.9573479762641333

Epoch: 6| Step: 10
Training loss: 1.8065248727798462
Validation loss: 1.9787120639636953

Epoch: 6| Step: 11
Training loss: 2.0598599910736084
Validation loss: 1.9689545810863536

Epoch: 6| Step: 12
Training loss: 2.4324254989624023
Validation loss: 1.9500184930780882

Epoch: 6| Step: 13
Training loss: 1.1577186584472656
Validation loss: 1.9532138762935516

Epoch: 208| Step: 0
Training loss: 1.1492373943328857
Validation loss: 1.9489454941083026

Epoch: 6| Step: 1
Training loss: 2.163520336151123
Validation loss: 2.000302759549951

Epoch: 6| Step: 2
Training loss: 1.6729583740234375
Validation loss: 1.9665665703435098

Epoch: 6| Step: 3
Training loss: 1.3380565643310547
Validation loss: 1.9257929331512862

Epoch: 6| Step: 4
Training loss: 1.830695390701294
Validation loss: 1.9841574251010854

Epoch: 6| Step: 5
Training loss: 2.0550127029418945
Validation loss: 1.9323265796066613

Epoch: 6| Step: 6
Training loss: 2.4518344402313232
Validation loss: 1.9292271009055517

Epoch: 6| Step: 7
Training loss: 1.4888023138046265
Validation loss: 1.9221437874660696

Epoch: 6| Step: 8
Training loss: 1.558056116104126
Validation loss: 1.8838238511034238

Epoch: 6| Step: 9
Training loss: 1.5766363143920898
Validation loss: 1.9703125902401504

Epoch: 6| Step: 10
Training loss: 1.7831796407699585
Validation loss: 1.900064181256038

Epoch: 6| Step: 11
Training loss: 2.142174005508423
Validation loss: 1.9092362465397004

Epoch: 6| Step: 12
Training loss: 2.0811986923217773
Validation loss: 1.8923204855252338

Epoch: 6| Step: 13
Training loss: 2.203428268432617
Validation loss: 1.9390279669915476

Epoch: 209| Step: 0
Training loss: 1.7748149633407593
Validation loss: 1.9667233036410423

Epoch: 6| Step: 1
Training loss: 1.6358442306518555
Validation loss: 1.9152134951724802

Epoch: 6| Step: 2
Training loss: 2.5832436084747314
Validation loss: 1.955741479832639

Epoch: 6| Step: 3
Training loss: 1.5096282958984375
Validation loss: 1.9375789960225422

Epoch: 6| Step: 4
Training loss: 2.4024879932403564
Validation loss: 1.945638145169904

Epoch: 6| Step: 5
Training loss: 1.5993051528930664
Validation loss: 1.9176912769194572

Epoch: 6| Step: 6
Training loss: 1.5228971242904663
Validation loss: 1.9430211026181456

Epoch: 6| Step: 7
Training loss: 2.223741054534912
Validation loss: 1.958525025716392

Epoch: 6| Step: 8
Training loss: 1.6671805381774902
Validation loss: 1.9280502821809502

Epoch: 6| Step: 9
Training loss: 1.6396889686584473
Validation loss: 1.9627843864502446

Epoch: 6| Step: 10
Training loss: 1.752392292022705
Validation loss: 1.9404125290532266

Epoch: 6| Step: 11
Training loss: 1.5486705303192139
Validation loss: 1.902396334114895

Epoch: 6| Step: 12
Training loss: 1.491097092628479
Validation loss: 1.9441637877495057

Epoch: 6| Step: 13
Training loss: 1.5214877128601074
Validation loss: 1.9794755699814006

Epoch: 210| Step: 0
Training loss: 1.948720932006836
Validation loss: 1.9596829401549472

Epoch: 6| Step: 1
Training loss: 1.4696935415267944
Validation loss: 1.9752126765507523

Epoch: 6| Step: 2
Training loss: 1.252737045288086
Validation loss: 1.9215977755925988

Epoch: 6| Step: 3
Training loss: 1.7428640127182007
Validation loss: 1.9167595178850236

Epoch: 6| Step: 4
Training loss: 1.8672552108764648
Validation loss: 1.926530752130734

Epoch: 6| Step: 5
Training loss: 1.7199676036834717
Validation loss: 1.9482046840011433

Epoch: 6| Step: 6
Training loss: 1.700034260749817
Validation loss: 1.909826071031632

Epoch: 6| Step: 7
Training loss: 1.6349947452545166
Validation loss: 1.9191418591366018

Epoch: 6| Step: 8
Training loss: 1.850482702255249
Validation loss: 1.9711842319016815

Epoch: 6| Step: 9
Training loss: 2.065485954284668
Validation loss: 1.9127285506135674

Epoch: 6| Step: 10
Training loss: 1.8683598041534424
Validation loss: 1.9262597022518035

Epoch: 6| Step: 11
Training loss: 2.418896436691284
Validation loss: 1.9582908409897999

Epoch: 6| Step: 12
Training loss: 1.8953113555908203
Validation loss: 1.9171658318529847

Epoch: 6| Step: 13
Training loss: 1.8486862182617188
Validation loss: 1.941795285030078

Epoch: 211| Step: 0
Training loss: 1.376760721206665
Validation loss: 1.9229527622140863

Epoch: 6| Step: 1
Training loss: 1.250638484954834
Validation loss: 1.9201388230887793

Epoch: 6| Step: 2
Training loss: 2.0189480781555176
Validation loss: 1.9467952046343076

Epoch: 6| Step: 3
Training loss: 1.4402153491973877
Validation loss: 1.9596857627232869

Epoch: 6| Step: 4
Training loss: 2.4923529624938965
Validation loss: 1.931451484721194

Epoch: 6| Step: 5
Training loss: 1.6737185716629028
Validation loss: 1.956226057903741

Epoch: 6| Step: 6
Training loss: 1.8114019632339478
Validation loss: 1.971338882241198

Epoch: 6| Step: 7
Training loss: 2.5983076095581055
Validation loss: 1.9641194856295021

Epoch: 6| Step: 8
Training loss: 1.3526065349578857
Validation loss: 1.9764267526647097

Epoch: 6| Step: 9
Training loss: 1.5729457139968872
Validation loss: 1.9735920813775831

Epoch: 6| Step: 10
Training loss: 1.891197681427002
Validation loss: 1.981501096038408

Epoch: 6| Step: 11
Training loss: 1.8522672653198242
Validation loss: 1.9551563480848908

Epoch: 6| Step: 12
Training loss: 2.785006523132324
Validation loss: 1.9479334764583136

Epoch: 6| Step: 13
Training loss: 0.8632028102874756
Validation loss: 1.9318292628052414

Epoch: 212| Step: 0
Training loss: 1.9694371223449707
Validation loss: 1.9328154146030385

Epoch: 6| Step: 1
Training loss: 1.9876933097839355
Validation loss: 1.9196869468176236

Epoch: 6| Step: 2
Training loss: 1.6049418449401855
Validation loss: 1.9040474423798182

Epoch: 6| Step: 3
Training loss: 1.9560600519180298
Validation loss: 1.8958900974642845

Epoch: 6| Step: 4
Training loss: 0.9928946495056152
Validation loss: 1.9232694359235867

Epoch: 6| Step: 5
Training loss: 1.7648652791976929
Validation loss: 1.9143064406610304

Epoch: 6| Step: 6
Training loss: 1.609429121017456
Validation loss: 1.9222820933147142

Epoch: 6| Step: 7
Training loss: 1.491880178451538
Validation loss: 1.938172491647864

Epoch: 6| Step: 8
Training loss: 1.4801530838012695
Validation loss: 1.9122941045350925

Epoch: 6| Step: 9
Training loss: 1.6615432500839233
Validation loss: 1.8725223361804921

Epoch: 6| Step: 10
Training loss: 2.1079459190368652
Validation loss: 1.9157627692786596

Epoch: 6| Step: 11
Training loss: 2.1796371936798096
Validation loss: 1.9347240796653173

Epoch: 6| Step: 12
Training loss: 2.1208627223968506
Validation loss: 1.9056158065795898

Epoch: 6| Step: 13
Training loss: 2.359018087387085
Validation loss: 1.8995123165909962

Epoch: 213| Step: 0
Training loss: 1.9140974283218384
Validation loss: 1.9172103199907529

Epoch: 6| Step: 1
Training loss: 1.4588948488235474
Validation loss: 1.9205219899454424

Epoch: 6| Step: 2
Training loss: 1.9597100019454956
Validation loss: 1.9052395359162362

Epoch: 6| Step: 3
Training loss: 1.9767124652862549
Validation loss: 1.8741711878007459

Epoch: 6| Step: 4
Training loss: 2.399909734725952
Validation loss: 1.9219264035583825

Epoch: 6| Step: 5
Training loss: 2.7899205684661865
Validation loss: 1.9338630681396813

Epoch: 6| Step: 6
Training loss: 1.9835882186889648
Validation loss: 1.915409493189986

Epoch: 6| Step: 7
Training loss: 1.383565902709961
Validation loss: 1.9149405123085104

Epoch: 6| Step: 8
Training loss: 1.134878158569336
Validation loss: 1.9345453349492883

Epoch: 6| Step: 9
Training loss: 1.8610634803771973
Validation loss: 1.9355492284221034

Epoch: 6| Step: 10
Training loss: 1.7143558263778687
Validation loss: 1.9015837330971994

Epoch: 6| Step: 11
Training loss: 1.694138526916504
Validation loss: 1.9250166390531807

Epoch: 6| Step: 12
Training loss: 1.5046108961105347
Validation loss: 1.937088902278613

Epoch: 6| Step: 13
Training loss: 1.3235753774642944
Validation loss: 1.9022605854977843

Epoch: 214| Step: 0
Training loss: 1.1966361999511719
Validation loss: 1.9711940314180108

Epoch: 6| Step: 1
Training loss: 1.2208914756774902
Validation loss: 1.93569698128649

Epoch: 6| Step: 2
Training loss: 1.2380049228668213
Validation loss: 1.945806239240913

Epoch: 6| Step: 3
Training loss: 2.271451234817505
Validation loss: 1.9659452617809337

Epoch: 6| Step: 4
Training loss: 1.7782526016235352
Validation loss: 1.9485873906843123

Epoch: 6| Step: 5
Training loss: 2.5079827308654785
Validation loss: 1.9242633158160793

Epoch: 6| Step: 6
Training loss: 1.602919101715088
Validation loss: 1.9636246478685768

Epoch: 6| Step: 7
Training loss: 1.7546031475067139
Validation loss: 1.9237143993377686

Epoch: 6| Step: 8
Training loss: 1.4061074256896973
Validation loss: 1.9738635542572185

Epoch: 6| Step: 9
Training loss: 2.1086020469665527
Validation loss: 1.9328177628978607

Epoch: 6| Step: 10
Training loss: 1.7290091514587402
Validation loss: 1.9280259327221942

Epoch: 6| Step: 11
Training loss: 2.1530604362487793
Validation loss: 1.9535752534866333

Epoch: 6| Step: 12
Training loss: 2.0022242069244385
Validation loss: 1.9389114943883752

Epoch: 6| Step: 13
Training loss: 2.417839527130127
Validation loss: 1.9113457100365752

Epoch: 215| Step: 0
Training loss: 1.4542109966278076
Validation loss: 1.9054403766509025

Epoch: 6| Step: 1
Training loss: 1.5947604179382324
Validation loss: 1.9186575502477667

Epoch: 6| Step: 2
Training loss: 2.4285483360290527
Validation loss: 1.9103834257330945

Epoch: 6| Step: 3
Training loss: 2.0040624141693115
Validation loss: 1.9368827009713778

Epoch: 6| Step: 4
Training loss: 1.9484317302703857
Validation loss: 1.9383060047703404

Epoch: 6| Step: 5
Training loss: 2.079014301300049
Validation loss: 1.9339790190419843

Epoch: 6| Step: 6
Training loss: 1.7462095022201538
Validation loss: 1.9303965722360918

Epoch: 6| Step: 7
Training loss: 2.244399309158325
Validation loss: 1.9290702996715423

Epoch: 6| Step: 8
Training loss: 0.838752269744873
Validation loss: 1.9280800229759627

Epoch: 6| Step: 9
Training loss: 1.81178879737854
Validation loss: 1.9598956428548342

Epoch: 6| Step: 10
Training loss: 1.8122715950012207
Validation loss: 1.9482082115706576

Epoch: 6| Step: 11
Training loss: 1.1233792304992676
Validation loss: 1.9303532749093988

Epoch: 6| Step: 12
Training loss: 1.76499342918396
Validation loss: 1.949718495850922

Epoch: 6| Step: 13
Training loss: 2.3050031661987305
Validation loss: 1.9071994238002326

Epoch: 216| Step: 0
Training loss: 1.6329185962677002
Validation loss: 1.9395989461611676

Epoch: 6| Step: 1
Training loss: 2.316488027572632
Validation loss: 1.8975930008836972

Epoch: 6| Step: 2
Training loss: 1.5209169387817383
Validation loss: 1.8907382577978156

Epoch: 6| Step: 3
Training loss: 2.3674325942993164
Validation loss: 1.9783487986492854

Epoch: 6| Step: 4
Training loss: 2.0541152954101562
Validation loss: 1.9296127711572955

Epoch: 6| Step: 5
Training loss: 1.4495679140090942
Validation loss: 1.9522052426492014

Epoch: 6| Step: 6
Training loss: 1.597522258758545
Validation loss: 1.9415856151170627

Epoch: 6| Step: 7
Training loss: 1.249725103378296
Validation loss: 1.9516959190368652

Epoch: 6| Step: 8
Training loss: 2.0580177307128906
Validation loss: 1.9556313253218127

Epoch: 6| Step: 9
Training loss: 1.599542260169983
Validation loss: 1.945899385277943

Epoch: 6| Step: 10
Training loss: 1.6379046440124512
Validation loss: 1.9700435733282438

Epoch: 6| Step: 11
Training loss: 1.573127031326294
Validation loss: 1.9195538220867034

Epoch: 6| Step: 12
Training loss: 2.229832649230957
Validation loss: 1.9297280516675723

Epoch: 6| Step: 13
Training loss: 1.307183027267456
Validation loss: 1.9404912981935727

Epoch: 217| Step: 0
Training loss: 1.3210995197296143
Validation loss: 1.9193619515306206

Epoch: 6| Step: 1
Training loss: 2.128509521484375
Validation loss: 1.890839280620698

Epoch: 6| Step: 2
Training loss: 2.06827449798584
Validation loss: 1.9407712836419382

Epoch: 6| Step: 3
Training loss: 2.1475167274475098
Validation loss: 1.9275335868199666

Epoch: 6| Step: 4
Training loss: 1.895667552947998
Validation loss: 1.887087042613696

Epoch: 6| Step: 5
Training loss: 1.359635591506958
Validation loss: 1.932349858745452

Epoch: 6| Step: 6
Training loss: 1.8566447496414185
Validation loss: 1.909607664231331

Epoch: 6| Step: 7
Training loss: 1.128563404083252
Validation loss: 1.9379392221409788

Epoch: 6| Step: 8
Training loss: 1.5745600461959839
Validation loss: 1.878872549662026

Epoch: 6| Step: 9
Training loss: 1.9702359437942505
Validation loss: 1.8984170652204944

Epoch: 6| Step: 10
Training loss: 1.0895229578018188
Validation loss: 1.9273184319978118

Epoch: 6| Step: 11
Training loss: 2.648388385772705
Validation loss: 1.9079222345864901

Epoch: 6| Step: 12
Training loss: 2.2735695838928223
Validation loss: 1.9289713072520431

Epoch: 6| Step: 13
Training loss: 1.6570744514465332
Validation loss: 1.9062123324281426

Epoch: 218| Step: 0
Training loss: 1.9982357025146484
Validation loss: 1.9341061294719737

Epoch: 6| Step: 1
Training loss: 1.8223774433135986
Validation loss: 1.9358545605854323

Epoch: 6| Step: 2
Training loss: 1.475949764251709
Validation loss: 1.9550142185662382

Epoch: 6| Step: 3
Training loss: 2.01644229888916
Validation loss: 1.9492269280136272

Epoch: 6| Step: 4
Training loss: 1.440504550933838
Validation loss: 1.9398372865492297

Epoch: 6| Step: 5
Training loss: 1.41739821434021
Validation loss: 1.946005654591386

Epoch: 6| Step: 6
Training loss: 1.6684983968734741
Validation loss: 1.9449794984632922

Epoch: 6| Step: 7
Training loss: 1.3620619773864746
Validation loss: 1.913302602306489

Epoch: 6| Step: 8
Training loss: 1.9289075136184692
Validation loss: 1.9611654345707228

Epoch: 6| Step: 9
Training loss: 2.0302624702453613
Validation loss: 1.9085659237318142

Epoch: 6| Step: 10
Training loss: 1.8228200674057007
Validation loss: 1.9278478468618085

Epoch: 6| Step: 11
Training loss: 1.9046566486358643
Validation loss: 1.9360983217916181

Epoch: 6| Step: 12
Training loss: 2.573050022125244
Validation loss: 1.9467266887746832

Epoch: 6| Step: 13
Training loss: 1.3433881998062134
Validation loss: 1.8986155986785889

Epoch: 219| Step: 0
Training loss: 1.5465424060821533
Validation loss: 1.9260287541215138

Epoch: 6| Step: 1
Training loss: 1.089919090270996
Validation loss: 1.92667434805183

Epoch: 6| Step: 2
Training loss: 1.8618032932281494
Validation loss: 1.8971233342283516

Epoch: 6| Step: 3
Training loss: 1.7672488689422607
Validation loss: 1.9453735659199376

Epoch: 6| Step: 4
Training loss: 2.305055618286133
Validation loss: 1.9084423126712922

Epoch: 6| Step: 5
Training loss: 1.706674337387085
Validation loss: 1.9172874727556783

Epoch: 6| Step: 6
Training loss: 1.9911572933197021
Validation loss: 1.8884441685932938

Epoch: 6| Step: 7
Training loss: 1.7919341325759888
Validation loss: 1.9058859630297589

Epoch: 6| Step: 8
Training loss: 1.929627776145935
Validation loss: 1.9105513070219307

Epoch: 6| Step: 9
Training loss: 2.087318181991577
Validation loss: 1.9073607921600342

Epoch: 6| Step: 10
Training loss: 1.6841888427734375
Validation loss: 1.8921474564460017

Epoch: 6| Step: 11
Training loss: 1.596989393234253
Validation loss: 1.9350265354238532

Epoch: 6| Step: 12
Training loss: 1.3938592672348022
Validation loss: 1.9428804433473976

Epoch: 6| Step: 13
Training loss: 2.1101601123809814
Validation loss: 1.9280248675295102

Epoch: 220| Step: 0
Training loss: 2.128730297088623
Validation loss: 1.9267795983181204

Epoch: 6| Step: 1
Training loss: 2.234689235687256
Validation loss: 1.8903129139254171

Epoch: 6| Step: 2
Training loss: 2.1484620571136475
Validation loss: 1.9219089900293658

Epoch: 6| Step: 3
Training loss: 1.723905324935913
Validation loss: 1.9574561567716702

Epoch: 6| Step: 4
Training loss: 1.860460877418518
Validation loss: 1.9260416787157777

Epoch: 6| Step: 5
Training loss: 1.3516279458999634
Validation loss: 1.901654604942568

Epoch: 6| Step: 6
Training loss: 1.8751106262207031
Validation loss: 1.8965600613624818

Epoch: 6| Step: 7
Training loss: 1.944022297859192
Validation loss: 1.9218048934013612

Epoch: 6| Step: 8
Training loss: 1.471011996269226
Validation loss: 1.8951439524209628

Epoch: 6| Step: 9
Training loss: 1.4949333667755127
Validation loss: 1.9157754785271102

Epoch: 6| Step: 10
Training loss: 1.4638209342956543
Validation loss: 1.9104458721735145

Epoch: 6| Step: 11
Training loss: 1.4568631649017334
Validation loss: 1.9339459762778333

Epoch: 6| Step: 12
Training loss: 1.6320486068725586
Validation loss: 1.8900844730356687

Epoch: 6| Step: 13
Training loss: 2.1739420890808105
Validation loss: 1.9041203247603549

Epoch: 221| Step: 0
Training loss: 2.451702117919922
Validation loss: 1.899838246325011

Epoch: 6| Step: 1
Training loss: 1.6270267963409424
Validation loss: 1.9494565802235757

Epoch: 6| Step: 2
Training loss: 2.35982084274292
Validation loss: 1.9236831703493673

Epoch: 6| Step: 3
Training loss: 1.7297914028167725
Validation loss: 1.9455436480942594

Epoch: 6| Step: 4
Training loss: 1.562774658203125
Validation loss: 1.9192005254889046

Epoch: 6| Step: 5
Training loss: 1.8948512077331543
Validation loss: 1.9570311871908044

Epoch: 6| Step: 6
Training loss: 2.1990180015563965
Validation loss: 1.963942712353122

Epoch: 6| Step: 7
Training loss: 1.1583306789398193
Validation loss: 1.9249227534058273

Epoch: 6| Step: 8
Training loss: 1.5470976829528809
Validation loss: 1.9806479561713435

Epoch: 6| Step: 9
Training loss: 1.3103500604629517
Validation loss: 1.9215820335572766

Epoch: 6| Step: 10
Training loss: 2.0295028686523438
Validation loss: 1.9261719667783348

Epoch: 6| Step: 11
Training loss: 1.493843913078308
Validation loss: 1.9310371978308565

Epoch: 6| Step: 12
Training loss: 1.4683763980865479
Validation loss: 1.8880550681903798

Epoch: 6| Step: 13
Training loss: 2.067409038543701
Validation loss: 1.9202564044665265

Epoch: 222| Step: 0
Training loss: 0.9226626753807068
Validation loss: 1.9190399082758094

Epoch: 6| Step: 1
Training loss: 1.8398329019546509
Validation loss: 1.922110511410621

Epoch: 6| Step: 2
Training loss: 1.355372667312622
Validation loss: 1.9042575154253232

Epoch: 6| Step: 3
Training loss: 1.6725785732269287
Validation loss: 1.8842762875300583

Epoch: 6| Step: 4
Training loss: 1.565798044204712
Validation loss: 1.9195166159701604

Epoch: 6| Step: 5
Training loss: 1.8040771484375
Validation loss: 1.9289622281187324

Epoch: 6| Step: 6
Training loss: 1.4674675464630127
Validation loss: 1.891974054357057

Epoch: 6| Step: 7
Training loss: 1.5664548873901367
Validation loss: 1.9219644056853427

Epoch: 6| Step: 8
Training loss: 2.253821849822998
Validation loss: 1.8933846950531006

Epoch: 6| Step: 9
Training loss: 1.935639500617981
Validation loss: 1.913350861559632

Epoch: 6| Step: 10
Training loss: 1.9631149768829346
Validation loss: 1.9017058393006683

Epoch: 6| Step: 11
Training loss: 2.539875030517578
Validation loss: 1.9032766947182276

Epoch: 6| Step: 12
Training loss: 2.071800947189331
Validation loss: 1.9145039037991596

Epoch: 6| Step: 13
Training loss: 1.9362989664077759
Validation loss: 1.898054079342914

Epoch: 223| Step: 0
Training loss: 1.6861982345581055
Validation loss: 1.894677044242941

Epoch: 6| Step: 1
Training loss: 1.0779430866241455
Validation loss: 1.9169563503675564

Epoch: 6| Step: 2
Training loss: 1.8023977279663086
Validation loss: 1.941028441152265

Epoch: 6| Step: 3
Training loss: 2.006962776184082
Validation loss: 1.904679713710662

Epoch: 6| Step: 4
Training loss: 2.1173267364501953
Validation loss: 1.9506728136411278

Epoch: 6| Step: 5
Training loss: 2.4185714721679688
Validation loss: 1.9544212946327784

Epoch: 6| Step: 6
Training loss: 1.7605383396148682
Validation loss: 1.8865792315493348

Epoch: 6| Step: 7
Training loss: 1.768241047859192
Validation loss: 1.9651203117062968

Epoch: 6| Step: 8
Training loss: 1.5519287586212158
Validation loss: 1.9555305934721423

Epoch: 6| Step: 9
Training loss: 2.5390000343322754
Validation loss: 1.9603820449562483

Epoch: 6| Step: 10
Training loss: 1.1619036197662354
Validation loss: 1.9830831943019744

Epoch: 6| Step: 11
Training loss: 1.7265079021453857
Validation loss: 1.9507000625774424

Epoch: 6| Step: 12
Training loss: 1.69236421585083
Validation loss: 1.9224160294378958

Epoch: 6| Step: 13
Training loss: 1.1822750568389893
Validation loss: 1.920788167625345

Epoch: 224| Step: 0
Training loss: 1.8211091756820679
Validation loss: 1.949037859516759

Epoch: 6| Step: 1
Training loss: 2.0812950134277344
Validation loss: 1.9379435149572228

Epoch: 6| Step: 2
Training loss: 1.5044164657592773
Validation loss: 1.916160370713921

Epoch: 6| Step: 3
Training loss: 1.7123973369598389
Validation loss: 1.9172146704889113

Epoch: 6| Step: 4
Training loss: 2.0080060958862305
Validation loss: 1.911638452160743

Epoch: 6| Step: 5
Training loss: 2.3635599613189697
Validation loss: 1.8601841747119863

Epoch: 6| Step: 6
Training loss: 1.3676984310150146
Validation loss: 1.9363995931481803

Epoch: 6| Step: 7
Training loss: 1.9620777368545532
Validation loss: 1.8956592839251283

Epoch: 6| Step: 8
Training loss: 1.4743657112121582
Validation loss: 1.901380012112279

Epoch: 6| Step: 9
Training loss: 2.166830539703369
Validation loss: 1.9106644520195581

Epoch: 6| Step: 10
Training loss: 1.9085246324539185
Validation loss: 1.9075862284629577

Epoch: 6| Step: 11
Training loss: 1.280885100364685
Validation loss: 1.9330719209486438

Epoch: 6| Step: 12
Training loss: 1.4141530990600586
Validation loss: 1.900645798252475

Epoch: 6| Step: 13
Training loss: 1.4335275888442993
Validation loss: 1.9026893684940953

Epoch: 225| Step: 0
Training loss: 1.9039922952651978
Validation loss: 1.9178889733488842

Epoch: 6| Step: 1
Training loss: 1.4368088245391846
Validation loss: 1.9477134853281

Epoch: 6| Step: 2
Training loss: 1.5184388160705566
Validation loss: 1.9629257545676282

Epoch: 6| Step: 3
Training loss: 1.3593928813934326
Validation loss: 1.9532924967427407

Epoch: 6| Step: 4
Training loss: 2.765158176422119
Validation loss: 1.9539265145537674

Epoch: 6| Step: 5
Training loss: 1.4328700304031372
Validation loss: 1.9677226556244718

Epoch: 6| Step: 6
Training loss: 1.9432522058486938
Validation loss: 1.9688975605913388

Epoch: 6| Step: 7
Training loss: 1.528040885925293
Validation loss: 1.9588305219527213

Epoch: 6| Step: 8
Training loss: 1.3609596490859985
Validation loss: 1.948118067556812

Epoch: 6| Step: 9
Training loss: 2.626429557800293
Validation loss: 1.953334339203373

Epoch: 6| Step: 10
Training loss: 1.6305723190307617
Validation loss: 1.9378957876595118

Epoch: 6| Step: 11
Training loss: 1.9005959033966064
Validation loss: 1.9258952281808341

Epoch: 6| Step: 12
Training loss: 1.2129489183425903
Validation loss: 1.937003138244793

Epoch: 6| Step: 13
Training loss: 2.401949644088745
Validation loss: 1.934057779209588

Epoch: 226| Step: 0
Training loss: 1.830281376838684
Validation loss: 1.9188031586267615

Epoch: 6| Step: 1
Training loss: 1.395305871963501
Validation loss: 1.9453658211615779

Epoch: 6| Step: 2
Training loss: 1.8846702575683594
Validation loss: 1.9244751930236816

Epoch: 6| Step: 3
Training loss: 1.282576560974121
Validation loss: 1.9338677493474816

Epoch: 6| Step: 4
Training loss: 1.9517468214035034
Validation loss: 1.8907039729497765

Epoch: 6| Step: 5
Training loss: 1.7693886756896973
Validation loss: 1.9119426460676296

Epoch: 6| Step: 6
Training loss: 2.6298892498016357
Validation loss: 1.9382528284544587

Epoch: 6| Step: 7
Training loss: 1.6583751440048218
Validation loss: 1.8991050374123357

Epoch: 6| Step: 8
Training loss: 1.938690423965454
Validation loss: 1.8705527141530027

Epoch: 6| Step: 9
Training loss: 1.6883126497268677
Validation loss: 1.905867672735645

Epoch: 6| Step: 10
Training loss: 1.6396160125732422
Validation loss: 1.9001468407210482

Epoch: 6| Step: 11
Training loss: 1.6219446659088135
Validation loss: 1.9041995310014295

Epoch: 6| Step: 12
Training loss: 1.380965232849121
Validation loss: 1.8857764518389137

Epoch: 6| Step: 13
Training loss: 1.4675201177597046
Validation loss: 1.9477638608665877

Epoch: 227| Step: 0
Training loss: 1.9296754598617554
Validation loss: 1.8868639187146259

Epoch: 6| Step: 1
Training loss: 1.4412169456481934
Validation loss: 1.8997062201141028

Epoch: 6| Step: 2
Training loss: 1.0775423049926758
Validation loss: 1.895695629940238

Epoch: 6| Step: 3
Training loss: 1.2863889932632446
Validation loss: 1.8868831152557044

Epoch: 6| Step: 4
Training loss: 1.9336459636688232
Validation loss: 1.9306842152790358

Epoch: 6| Step: 5
Training loss: 1.7580957412719727
Validation loss: 1.9494258037177465

Epoch: 6| Step: 6
Training loss: 1.9293551445007324
Validation loss: 1.9876580161433066

Epoch: 6| Step: 7
Training loss: 1.7788623571395874
Validation loss: 1.934425271967406

Epoch: 6| Step: 8
Training loss: 1.994685411453247
Validation loss: 1.9771009132426272

Epoch: 6| Step: 9
Training loss: 2.2828755378723145
Validation loss: 1.986096630814255

Epoch: 6| Step: 10
Training loss: 2.191279411315918
Validation loss: 1.9626254702127108

Epoch: 6| Step: 11
Training loss: 1.2196029424667358
Validation loss: 1.95456644668374

Epoch: 6| Step: 12
Training loss: 1.803823471069336
Validation loss: 1.9379548257397068

Epoch: 6| Step: 13
Training loss: 2.3937253952026367
Validation loss: 1.9518331109836538

Epoch: 228| Step: 0
Training loss: 1.2175428867340088
Validation loss: 1.9330817320013558

Epoch: 6| Step: 1
Training loss: 1.4224495887756348
Validation loss: 1.9163625727417648

Epoch: 6| Step: 2
Training loss: 2.064499855041504
Validation loss: 1.9347677692290275

Epoch: 6| Step: 3
Training loss: 1.8258973360061646
Validation loss: 1.9367256215823594

Epoch: 6| Step: 4
Training loss: 1.3034250736236572
Validation loss: 1.9211429319074076

Epoch: 6| Step: 5
Training loss: 2.00561785697937
Validation loss: 1.8864711452555913

Epoch: 6| Step: 6
Training loss: 1.4289226531982422
Validation loss: 1.925810040966157

Epoch: 6| Step: 7
Training loss: 1.945081114768982
Validation loss: 1.9013687000479749

Epoch: 6| Step: 8
Training loss: 1.6946717500686646
Validation loss: 1.8981835957496398

Epoch: 6| Step: 9
Training loss: 2.461869239807129
Validation loss: 1.923771700551433

Epoch: 6| Step: 10
Training loss: 2.347360849380493
Validation loss: 1.8755004893067062

Epoch: 6| Step: 11
Training loss: 1.3990105390548706
Validation loss: 1.9224727307596514

Epoch: 6| Step: 12
Training loss: 1.6525723934173584
Validation loss: 1.9107397730632494

Epoch: 6| Step: 13
Training loss: 1.6744133234024048
Validation loss: 1.9459811205505042

Epoch: 229| Step: 0
Training loss: 1.058124303817749
Validation loss: 1.909382556074409

Epoch: 6| Step: 1
Training loss: 1.305562973022461
Validation loss: 1.9132510615933327

Epoch: 6| Step: 2
Training loss: 2.731281042098999
Validation loss: 1.9586105013406405

Epoch: 6| Step: 3
Training loss: 1.4762659072875977
Validation loss: 1.9801407347443283

Epoch: 6| Step: 4
Training loss: 1.8904191255569458
Validation loss: 1.972443316572456

Epoch: 6| Step: 5
Training loss: 2.027432680130005
Validation loss: 1.9891851973789993

Epoch: 6| Step: 6
Training loss: 1.4242262840270996
Validation loss: 1.9687563757742605

Epoch: 6| Step: 7
Training loss: 1.236743688583374
Validation loss: 1.9956129571442962

Epoch: 6| Step: 8
Training loss: 2.6728439331054688
Validation loss: 2.012940133771589

Epoch: 6| Step: 9
Training loss: 1.7697055339813232
Validation loss: 2.015360342558994

Epoch: 6| Step: 10
Training loss: 1.8229280710220337
Validation loss: 1.9629338915630052

Epoch: 6| Step: 11
Training loss: 1.8977973461151123
Validation loss: 2.016759853209219

Epoch: 6| Step: 12
Training loss: 1.6950476169586182
Validation loss: 1.950299556537341

Epoch: 6| Step: 13
Training loss: 0.9960162043571472
Validation loss: 1.9758117224580498

Epoch: 230| Step: 0
Training loss: 0.9742307066917419
Validation loss: 1.975623974877019

Epoch: 6| Step: 1
Training loss: 1.9833530187606812
Validation loss: 1.9758879984578779

Epoch: 6| Step: 2
Training loss: 2.1689841747283936
Validation loss: 1.95328478915717

Epoch: 6| Step: 3
Training loss: 1.8858153820037842
Validation loss: 1.9608330777896348

Epoch: 6| Step: 4
Training loss: 1.7069332599639893
Validation loss: 1.929171134066838

Epoch: 6| Step: 5
Training loss: 1.8250219821929932
Validation loss: 1.940997269845778

Epoch: 6| Step: 6
Training loss: 2.2207367420196533
Validation loss: 1.9018171115588116

Epoch: 6| Step: 7
Training loss: 1.5944359302520752
Validation loss: 1.879195326118059

Epoch: 6| Step: 8
Training loss: 1.968320608139038
Validation loss: 1.8919416102029945

Epoch: 6| Step: 9
Training loss: 1.7053896188735962
Validation loss: 1.9046098493760633

Epoch: 6| Step: 10
Training loss: 1.5299980640411377
Validation loss: 1.9089684896571661

Epoch: 6| Step: 11
Training loss: 1.7624421119689941
Validation loss: 1.9175590020354076

Epoch: 6| Step: 12
Training loss: 1.0163339376449585
Validation loss: 1.897958440165366

Epoch: 6| Step: 13
Training loss: 2.2954492568969727
Validation loss: 1.924749602553665

Epoch: 231| Step: 0
Training loss: 1.8466243743896484
Validation loss: 1.9252198870464037

Epoch: 6| Step: 1
Training loss: 1.870919942855835
Validation loss: 1.9346626497084094

Epoch: 6| Step: 2
Training loss: 2.8647208213806152
Validation loss: 1.9153501346547117

Epoch: 6| Step: 3
Training loss: 1.4477341175079346
Validation loss: 1.9453343781091834

Epoch: 6| Step: 4
Training loss: 1.2706990242004395
Validation loss: 1.8991456647073068

Epoch: 6| Step: 5
Training loss: 1.8642207384109497
Validation loss: 1.9010051168421263

Epoch: 6| Step: 6
Training loss: 2.050536632537842
Validation loss: 1.9167570349990681

Epoch: 6| Step: 7
Training loss: 1.0448116064071655
Validation loss: 1.8997190793355305

Epoch: 6| Step: 8
Training loss: 1.6852554082870483
Validation loss: 1.9160482985998994

Epoch: 6| Step: 9
Training loss: 1.0383487939834595
Validation loss: 1.8928685701021584

Epoch: 6| Step: 10
Training loss: 1.1787607669830322
Validation loss: 1.9180043564047864

Epoch: 6| Step: 11
Training loss: 2.624544620513916
Validation loss: 1.9121040695457048

Epoch: 6| Step: 12
Training loss: 1.7980873584747314
Validation loss: 1.9274938901265461

Epoch: 6| Step: 13
Training loss: 1.5957280397415161
Validation loss: 1.942471411920363

Epoch: 232| Step: 0
Training loss: 0.9917784929275513
Validation loss: 1.8951194901620187

Epoch: 6| Step: 1
Training loss: 1.7876195907592773
Validation loss: 1.9307511955179193

Epoch: 6| Step: 2
Training loss: 1.1205804347991943
Validation loss: 1.969853538338856

Epoch: 6| Step: 3
Training loss: 1.2413203716278076
Validation loss: 1.9641191113379695

Epoch: 6| Step: 4
Training loss: 1.959402084350586
Validation loss: 1.9312203314996534

Epoch: 6| Step: 5
Training loss: 1.902688980102539
Validation loss: 1.9512722569127237

Epoch: 6| Step: 6
Training loss: 2.0991454124450684
Validation loss: 1.899998805856192

Epoch: 6| Step: 7
Training loss: 1.9533298015594482
Validation loss: 1.9254843573416434

Epoch: 6| Step: 8
Training loss: 1.3672137260437012
Validation loss: 1.9404153336760819

Epoch: 6| Step: 9
Training loss: 1.8233418464660645
Validation loss: 1.9211315519066268

Epoch: 6| Step: 10
Training loss: 2.1501853466033936
Validation loss: 1.9201572402831046

Epoch: 6| Step: 11
Training loss: 2.9202804565429688
Validation loss: 1.9028169788340086

Epoch: 6| Step: 12
Training loss: 1.8472274541854858
Validation loss: 1.895984600949031

Epoch: 6| Step: 13
Training loss: 0.9657355546951294
Validation loss: 1.8982452871978923

Epoch: 233| Step: 0
Training loss: 1.7506946325302124
Validation loss: 1.9328858519113192

Epoch: 6| Step: 1
Training loss: 1.4253323078155518
Validation loss: 1.8788408976729198

Epoch: 6| Step: 2
Training loss: 2.233485221862793
Validation loss: 1.8792023645934237

Epoch: 6| Step: 3
Training loss: 1.727578043937683
Validation loss: 1.9098318828049528

Epoch: 6| Step: 4
Training loss: 1.7975878715515137
Validation loss: 1.9235097567240398

Epoch: 6| Step: 5
Training loss: 1.5546174049377441
Validation loss: 1.8818216157215897

Epoch: 6| Step: 6
Training loss: 1.3147262334823608
Validation loss: 1.8740156901779996

Epoch: 6| Step: 7
Training loss: 2.10430908203125
Validation loss: 1.9320886071010301

Epoch: 6| Step: 8
Training loss: 1.3069723844528198
Validation loss: 1.902346739204981

Epoch: 6| Step: 9
Training loss: 1.5470001697540283
Validation loss: 1.9130555224675003

Epoch: 6| Step: 10
Training loss: 1.952636957168579
Validation loss: 1.892111268094791

Epoch: 6| Step: 11
Training loss: 2.525097608566284
Validation loss: 1.905550842644066

Epoch: 6| Step: 12
Training loss: 1.3459471464157104
Validation loss: 1.9222372654945619

Epoch: 6| Step: 13
Training loss: 1.5593743324279785
Validation loss: 1.8736730980616745

Epoch: 234| Step: 0
Training loss: 1.513427734375
Validation loss: 1.8908851582516906

Epoch: 6| Step: 1
Training loss: 1.54241144657135
Validation loss: 1.8512932562058972

Epoch: 6| Step: 2
Training loss: 2.1425840854644775
Validation loss: 1.8982131493988859

Epoch: 6| Step: 3
Training loss: 1.577758550643921
Validation loss: 1.9047055449537051

Epoch: 6| Step: 4
Training loss: 1.7571334838867188
Validation loss: 1.925904558550927

Epoch: 6| Step: 5
Training loss: 2.3169283866882324
Validation loss: 1.9384474882515528

Epoch: 6| Step: 6
Training loss: 1.7547111511230469
Validation loss: 1.9306122436318347

Epoch: 6| Step: 7
Training loss: 1.5798484086990356
Validation loss: 1.9109491763576385

Epoch: 6| Step: 8
Training loss: 1.595590353012085
Validation loss: 1.8906695829924716

Epoch: 6| Step: 9
Training loss: 1.6764496564865112
Validation loss: 1.9285116221315117

Epoch: 6| Step: 10
Training loss: 1.592005729675293
Validation loss: 1.9167266174029278

Epoch: 6| Step: 11
Training loss: 1.8762587308883667
Validation loss: 1.9231249722101356

Epoch: 6| Step: 12
Training loss: 1.8552100658416748
Validation loss: 1.9244768222173054

Epoch: 6| Step: 13
Training loss: 0.8428540825843811
Validation loss: 1.9098903850842548

Epoch: 235| Step: 0
Training loss: 1.6345980167388916
Validation loss: 1.9327291775775213

Epoch: 6| Step: 1
Training loss: 1.766966700553894
Validation loss: 1.9092404227102957

Epoch: 6| Step: 2
Training loss: 2.2122981548309326
Validation loss: 1.9013418715487245

Epoch: 6| Step: 3
Training loss: 1.8491475582122803
Validation loss: 1.882955551147461

Epoch: 6| Step: 4
Training loss: 1.4116007089614868
Validation loss: 1.9028962325024348

Epoch: 6| Step: 5
Training loss: 2.1498656272888184
Validation loss: 1.8587218881935201

Epoch: 6| Step: 6
Training loss: 1.2465555667877197
Validation loss: 1.8737645790141115

Epoch: 6| Step: 7
Training loss: 1.9500939846038818
Validation loss: 1.9046245409596352

Epoch: 6| Step: 8
Training loss: 1.6855480670928955
Validation loss: 1.9110691483302782

Epoch: 6| Step: 9
Training loss: 1.5639102458953857
Validation loss: 1.9379113130672003

Epoch: 6| Step: 10
Training loss: 1.7143760919570923
Validation loss: 1.8971691413592267

Epoch: 6| Step: 11
Training loss: 1.8732056617736816
Validation loss: 1.904164876989139

Epoch: 6| Step: 12
Training loss: 1.7973313331604004
Validation loss: 1.9163705149004537

Epoch: 6| Step: 13
Training loss: 0.8553735613822937
Validation loss: 1.8986642950324601

Epoch: 236| Step: 0
Training loss: 1.656226634979248
Validation loss: 1.9158288894161102

Epoch: 6| Step: 1
Training loss: 1.9772467613220215
Validation loss: 1.9544192014201995

Epoch: 6| Step: 2
Training loss: 1.8378288745880127
Validation loss: 1.8858665266344625

Epoch: 6| Step: 3
Training loss: 1.1114221811294556
Validation loss: 1.911995167373329

Epoch: 6| Step: 4
Training loss: 1.63818359375
Validation loss: 1.9052361942106677

Epoch: 6| Step: 5
Training loss: 1.4008865356445312
Validation loss: 1.901669051057549

Epoch: 6| Step: 6
Training loss: 1.8834762573242188
Validation loss: 1.919368197841029

Epoch: 6| Step: 7
Training loss: 1.9358978271484375
Validation loss: 1.9257247076239636

Epoch: 6| Step: 8
Training loss: 1.8800745010375977
Validation loss: 1.9044578793228313

Epoch: 6| Step: 9
Training loss: 1.2699930667877197
Validation loss: 1.8932850104506298

Epoch: 6| Step: 10
Training loss: 1.231980562210083
Validation loss: 1.8810789008294382

Epoch: 6| Step: 11
Training loss: 2.0011394023895264
Validation loss: 1.902188697168904

Epoch: 6| Step: 12
Training loss: 2.4301769733428955
Validation loss: 1.8673917772949382

Epoch: 6| Step: 13
Training loss: 1.9477288722991943
Validation loss: 1.9153118518091017

Epoch: 237| Step: 0
Training loss: 1.8617055416107178
Validation loss: 1.8831571622561383

Epoch: 6| Step: 1
Training loss: 1.1767915487289429
Validation loss: 1.8980571967299267

Epoch: 6| Step: 2
Training loss: 2.050027370452881
Validation loss: 1.9230114029299827

Epoch: 6| Step: 3
Training loss: 1.5242470502853394
Validation loss: 1.9025683518378966

Epoch: 6| Step: 4
Training loss: 1.924452781677246
Validation loss: 1.8776111410510155

Epoch: 6| Step: 5
Training loss: 1.1579806804656982
Validation loss: 1.854408976852253

Epoch: 6| Step: 6
Training loss: 1.678572416305542
Validation loss: 1.8869362185078282

Epoch: 6| Step: 7
Training loss: 1.7305071353912354
Validation loss: 1.878642015559699

Epoch: 6| Step: 8
Training loss: 2.1701912879943848
Validation loss: 1.8890701417000062

Epoch: 6| Step: 9
Training loss: 1.2196276187896729
Validation loss: 1.9171685621302614

Epoch: 6| Step: 10
Training loss: 1.8927396535873413
Validation loss: 1.8749050081417125

Epoch: 6| Step: 11
Training loss: 1.5235487222671509
Validation loss: 1.9195915729768815

Epoch: 6| Step: 12
Training loss: 1.6414991617202759
Validation loss: 1.916796422773792

Epoch: 6| Step: 13
Training loss: 2.702267646789551
Validation loss: 1.9256656041709326

Epoch: 238| Step: 0
Training loss: 1.6883409023284912
Validation loss: 1.8643676004102152

Epoch: 6| Step: 1
Training loss: 2.027200222015381
Validation loss: 1.9222312358117872

Epoch: 6| Step: 2
Training loss: 1.7096667289733887
Validation loss: 1.9275967241615377

Epoch: 6| Step: 3
Training loss: 1.8090159893035889
Validation loss: 1.9228280462244505

Epoch: 6| Step: 4
Training loss: 1.3326189517974854
Validation loss: 1.9464054299939064

Epoch: 6| Step: 5
Training loss: 1.4719946384429932
Validation loss: 1.9296349504942536

Epoch: 6| Step: 6
Training loss: 0.8542979955673218
Validation loss: 1.9458639442279775

Epoch: 6| Step: 7
Training loss: 1.5299793481826782
Validation loss: 1.924457811540173

Epoch: 6| Step: 8
Training loss: 1.5163936614990234
Validation loss: 1.9152398058163222

Epoch: 6| Step: 9
Training loss: 1.6715848445892334
Validation loss: 1.931549543975502

Epoch: 6| Step: 10
Training loss: 1.6789588928222656
Validation loss: 1.8841071423663889

Epoch: 6| Step: 11
Training loss: 1.985691785812378
Validation loss: 1.9402511837661907

Epoch: 6| Step: 12
Training loss: 2.112070083618164
Validation loss: 1.909582661044213

Epoch: 6| Step: 13
Training loss: 2.9443111419677734
Validation loss: 1.9194163225030387

Epoch: 239| Step: 0
Training loss: 2.15311861038208
Validation loss: 1.9267506214880175

Epoch: 6| Step: 1
Training loss: 2.1995460987091064
Validation loss: 1.9383771086251864

Epoch: 6| Step: 2
Training loss: 1.812647819519043
Validation loss: 1.9289068662992088

Epoch: 6| Step: 3
Training loss: 1.512813925743103
Validation loss: 1.9149476174385316

Epoch: 6| Step: 4
Training loss: 1.6367571353912354
Validation loss: 1.9607071363797752

Epoch: 6| Step: 5
Training loss: 1.434355616569519
Validation loss: 1.9205906814144504

Epoch: 6| Step: 6
Training loss: 1.2583849430084229
Validation loss: 1.9104815298511135

Epoch: 6| Step: 7
Training loss: 1.6283643245697021
Validation loss: 1.9485198579808718

Epoch: 6| Step: 8
Training loss: 1.870825171470642
Validation loss: 1.9049330616510043

Epoch: 6| Step: 9
Training loss: 1.6828832626342773
Validation loss: 1.9272723377391856

Epoch: 6| Step: 10
Training loss: 1.3239514827728271
Validation loss: 1.9450409989203177

Epoch: 6| Step: 11
Training loss: 1.8053171634674072
Validation loss: 1.8925077889555244

Epoch: 6| Step: 12
Training loss: 1.480151653289795
Validation loss: 1.8925662643166

Epoch: 6| Step: 13
Training loss: 2.7623002529144287
Validation loss: 1.903151019926994

Epoch: 240| Step: 0
Training loss: 2.6102983951568604
Validation loss: 1.8989566039013606

Epoch: 6| Step: 1
Training loss: 1.4888837337493896
Validation loss: 1.9108524322509766

Epoch: 6| Step: 2
Training loss: 1.5322513580322266
Validation loss: 1.8870471344199231

Epoch: 6| Step: 3
Training loss: 2.364938259124756
Validation loss: 1.8896110775650188

Epoch: 6| Step: 4
Training loss: 1.0986950397491455
Validation loss: 1.8831150890678487

Epoch: 6| Step: 5
Training loss: 1.6632061004638672
Validation loss: 1.8944689484052761

Epoch: 6| Step: 6
Training loss: 1.7390083074569702
Validation loss: 1.9151590780545307

Epoch: 6| Step: 7
Training loss: 1.831089973449707
Validation loss: 1.9153399467468262

Epoch: 6| Step: 8
Training loss: 1.5538575649261475
Validation loss: 1.8608693115172847

Epoch: 6| Step: 9
Training loss: 1.3305473327636719
Validation loss: 1.890082839996584

Epoch: 6| Step: 10
Training loss: 1.7120201587677002
Validation loss: 1.8929925592996741

Epoch: 6| Step: 11
Training loss: 1.7462234497070312
Validation loss: 1.9053843931485248

Epoch: 6| Step: 12
Training loss: 1.6367114782333374
Validation loss: 1.8582231383169852

Epoch: 6| Step: 13
Training loss: 1.4735491275787354
Validation loss: 1.9266435946187666

Epoch: 241| Step: 0
Training loss: 1.1504319906234741
Validation loss: 1.8944187433488908

Epoch: 6| Step: 1
Training loss: 1.858473300933838
Validation loss: 1.9061765209321053

Epoch: 6| Step: 2
Training loss: 1.7602808475494385
Validation loss: 1.9119634295022616

Epoch: 6| Step: 3
Training loss: 1.9977608919143677
Validation loss: 1.887018072989679

Epoch: 6| Step: 4
Training loss: 1.6736366748809814
Validation loss: 1.9206351080248434

Epoch: 6| Step: 5
Training loss: 1.6026721000671387
Validation loss: 1.952037726679156

Epoch: 6| Step: 6
Training loss: 1.2893695831298828
Validation loss: 1.9241455229379798

Epoch: 6| Step: 7
Training loss: 1.6701480150222778
Validation loss: 1.9495005056422243

Epoch: 6| Step: 8
Training loss: 1.6174287796020508
Validation loss: 1.98637060324351

Epoch: 6| Step: 9
Training loss: 1.6674455404281616
Validation loss: 1.8969428552094327

Epoch: 6| Step: 10
Training loss: 1.587867259979248
Validation loss: 1.9023058363186416

Epoch: 6| Step: 11
Training loss: 1.6128485202789307
Validation loss: 1.9563093621243712

Epoch: 6| Step: 12
Training loss: 1.9669092893600464
Validation loss: 1.9406656808750604

Epoch: 6| Step: 13
Training loss: 2.614135503768921
Validation loss: 1.9335995502369379

Epoch: 242| Step: 0
Training loss: 1.5201884508132935
Validation loss: 1.8753702499533211

Epoch: 6| Step: 1
Training loss: 2.2406444549560547
Validation loss: 1.9232943763015091

Epoch: 6| Step: 2
Training loss: 1.111090898513794
Validation loss: 1.949881822832169

Epoch: 6| Step: 3
Training loss: 1.4051308631896973
Validation loss: 1.9338733611568328

Epoch: 6| Step: 4
Training loss: 1.9013899564743042
Validation loss: 1.8907130405467043

Epoch: 6| Step: 5
Training loss: 1.7050952911376953
Validation loss: 1.9221942476046983

Epoch: 6| Step: 6
Training loss: 1.8891388177871704
Validation loss: 1.8878339766174235

Epoch: 6| Step: 7
Training loss: 2.071643829345703
Validation loss: 1.8594358557014055

Epoch: 6| Step: 8
Training loss: 1.761236310005188
Validation loss: 1.883808938405847

Epoch: 6| Step: 9
Training loss: 1.8572429418563843
Validation loss: 1.9087138163146151

Epoch: 6| Step: 10
Training loss: 2.3492109775543213
Validation loss: 1.9397714458486086

Epoch: 6| Step: 11
Training loss: 0.9033899903297424
Validation loss: 1.9482229678861556

Epoch: 6| Step: 12
Training loss: 2.059157371520996
Validation loss: 1.8792659467266453

Epoch: 6| Step: 13
Training loss: 0.4851333796977997
Validation loss: 1.8956389939913185

Epoch: 243| Step: 0
Training loss: 1.6520785093307495
Validation loss: 1.8883523287311677

Epoch: 6| Step: 1
Training loss: 1.3641608953475952
Validation loss: 1.9169679046959005

Epoch: 6| Step: 2
Training loss: 1.2881338596343994
Validation loss: 1.9256509991102322

Epoch: 6| Step: 3
Training loss: 1.1355509757995605
Validation loss: 1.905676608444542

Epoch: 6| Step: 4
Training loss: 1.8685011863708496
Validation loss: 1.881999095280965

Epoch: 6| Step: 5
Training loss: 2.0364480018615723
Validation loss: 1.8744575541506532

Epoch: 6| Step: 6
Training loss: 1.9875926971435547
Validation loss: 1.915456892341696

Epoch: 6| Step: 7
Training loss: 1.7463575601577759
Validation loss: 1.9140153085031817

Epoch: 6| Step: 8
Training loss: 1.7142938375473022
Validation loss: 1.8926092937428465

Epoch: 6| Step: 9
Training loss: 1.916534185409546
Validation loss: 1.8640961390669628

Epoch: 6| Step: 10
Training loss: 1.7958447933197021
Validation loss: 1.8583135681767617

Epoch: 6| Step: 11
Training loss: 1.5038145780563354
Validation loss: 1.8774040258058937

Epoch: 6| Step: 12
Training loss: 2.008610725402832
Validation loss: 1.9055566851810744

Epoch: 6| Step: 13
Training loss: 1.34330153465271
Validation loss: 1.8939123897142307

Epoch: 244| Step: 0
Training loss: 2.003885269165039
Validation loss: 1.8973524365373837

Epoch: 6| Step: 1
Training loss: 1.9836527109146118
Validation loss: 1.8944190279130013

Epoch: 6| Step: 2
Training loss: 1.4173153638839722
Validation loss: 1.908787824774301

Epoch: 6| Step: 3
Training loss: 1.1111762523651123
Validation loss: 1.8877088856953446

Epoch: 6| Step: 4
Training loss: 1.9083380699157715
Validation loss: 1.9067609310150146

Epoch: 6| Step: 5
Training loss: 2.249635934829712
Validation loss: 1.9236525335619528

Epoch: 6| Step: 6
Training loss: 1.8084356784820557
Validation loss: 1.918245397588258

Epoch: 6| Step: 7
Training loss: 1.2915878295898438
Validation loss: 1.9429454803466797

Epoch: 6| Step: 8
Training loss: 1.950444221496582
Validation loss: 1.9073327536224036

Epoch: 6| Step: 9
Training loss: 1.459934949874878
Validation loss: 1.9089921879512008

Epoch: 6| Step: 10
Training loss: 1.4725890159606934
Validation loss: 1.9469174082561205

Epoch: 6| Step: 11
Training loss: 1.608104944229126
Validation loss: 1.9551463665500763

Epoch: 6| Step: 12
Training loss: 2.2246408462524414
Validation loss: 1.927349191839977

Epoch: 6| Step: 13
Training loss: 0.7703141570091248
Validation loss: 1.9392010191435456

Epoch: 245| Step: 0
Training loss: 1.9596033096313477
Validation loss: 1.920842219424504

Epoch: 6| Step: 1
Training loss: 1.7831203937530518
Validation loss: 1.889963847334667

Epoch: 6| Step: 2
Training loss: 1.8614999055862427
Validation loss: 1.8790664160123436

Epoch: 6| Step: 3
Training loss: 1.0207159519195557
Validation loss: 1.846198945917109

Epoch: 6| Step: 4
Training loss: 1.2449076175689697
Validation loss: 1.9141184758114558

Epoch: 6| Step: 5
Training loss: 1.7771997451782227
Validation loss: 1.8830666336961972

Epoch: 6| Step: 6
Training loss: 1.545586347579956
Validation loss: 1.8830409511443107

Epoch: 6| Step: 7
Training loss: 1.5508787631988525
Validation loss: 1.8966127672503073

Epoch: 6| Step: 8
Training loss: 1.6949743032455444
Validation loss: 1.8673307139386413

Epoch: 6| Step: 9
Training loss: 2.6506435871124268
Validation loss: 1.8925393973627398

Epoch: 6| Step: 10
Training loss: 1.5306700468063354
Validation loss: 1.841842592403453

Epoch: 6| Step: 11
Training loss: 1.809178352355957
Validation loss: 1.8750624759222871

Epoch: 6| Step: 12
Training loss: 1.5611844062805176
Validation loss: 1.9071558752367574

Epoch: 6| Step: 13
Training loss: 1.656058430671692
Validation loss: 1.8636508936523108

Epoch: 246| Step: 0
Training loss: 1.507189393043518
Validation loss: 1.8649645146503244

Epoch: 6| Step: 1
Training loss: 1.9123609066009521
Validation loss: 1.9282904799266527

Epoch: 6| Step: 2
Training loss: 2.5044736862182617
Validation loss: 1.896400918242752

Epoch: 6| Step: 3
Training loss: 1.6189467906951904
Validation loss: 1.925084437093427

Epoch: 6| Step: 4
Training loss: 1.577845573425293
Validation loss: 1.9121155969558223

Epoch: 6| Step: 5
Training loss: 1.7585753202438354
Validation loss: 1.936957351623043

Epoch: 6| Step: 6
Training loss: 1.9590604305267334
Validation loss: 1.9319998653986121

Epoch: 6| Step: 7
Training loss: 2.0570878982543945
Validation loss: 1.944976237512404

Epoch: 6| Step: 8
Training loss: 1.3452448844909668
Validation loss: 1.9471583968849593

Epoch: 6| Step: 9
Training loss: 1.8742034435272217
Validation loss: 1.9271029810751639

Epoch: 6| Step: 10
Training loss: 1.1736599206924438
Validation loss: 1.8846894682094615

Epoch: 6| Step: 11
Training loss: 1.7385598421096802
Validation loss: 1.9344817143614574

Epoch: 6| Step: 12
Training loss: 1.5536998510360718
Validation loss: 1.936290858894266

Epoch: 6| Step: 13
Training loss: 1.1043561697006226
Validation loss: 1.9496826561548377

Epoch: 247| Step: 0
Training loss: 1.2246425151824951
Validation loss: 1.8678667032590477

Epoch: 6| Step: 1
Training loss: 2.2120091915130615
Validation loss: 1.94383268971597

Epoch: 6| Step: 2
Training loss: 1.6410086154937744
Validation loss: 1.9112470355085147

Epoch: 6| Step: 3
Training loss: 1.8121953010559082
Validation loss: 1.936432985849278

Epoch: 6| Step: 4
Training loss: 1.6410377025604248
Validation loss: 1.9062205847873483

Epoch: 6| Step: 5
Training loss: 1.8686476945877075
Validation loss: 1.8915249942451395

Epoch: 6| Step: 6
Training loss: 2.1447415351867676
Validation loss: 1.9095107470789263

Epoch: 6| Step: 7
Training loss: 1.874237298965454
Validation loss: 1.91592832790908

Epoch: 6| Step: 8
Training loss: 2.086878538131714
Validation loss: 1.907898263264728

Epoch: 6| Step: 9
Training loss: 1.298898458480835
Validation loss: 1.8967919759852911

Epoch: 6| Step: 10
Training loss: 1.1787288188934326
Validation loss: 1.9305342551200622

Epoch: 6| Step: 11
Training loss: 1.9688189029693604
Validation loss: 1.905326327969951

Epoch: 6| Step: 12
Training loss: 1.1676902770996094
Validation loss: 1.8940963155479842

Epoch: 6| Step: 13
Training loss: 0.8958296179771423
Validation loss: 1.9538457829465148

Epoch: 248| Step: 0
Training loss: 2.5978784561157227
Validation loss: 1.9292207148767286

Epoch: 6| Step: 1
Training loss: 1.6771272420883179
Validation loss: 1.9303862997280654

Epoch: 6| Step: 2
Training loss: 2.2538022994995117
Validation loss: 1.9680089617288241

Epoch: 6| Step: 3
Training loss: 1.3060517311096191
Validation loss: 1.9365747526127806

Epoch: 6| Step: 4
Training loss: 1.2410821914672852
Validation loss: 1.9175421755800965

Epoch: 6| Step: 5
Training loss: 1.3495566844940186
Validation loss: 1.932618095028785

Epoch: 6| Step: 6
Training loss: 1.9770286083221436
Validation loss: 1.9869177367097588

Epoch: 6| Step: 7
Training loss: 1.5228773355484009
Validation loss: 1.9565710188240133

Epoch: 6| Step: 8
Training loss: 1.449223279953003
Validation loss: 1.876838534109054

Epoch: 6| Step: 9
Training loss: 2.0099124908447266
Validation loss: 1.9184679421045447

Epoch: 6| Step: 10
Training loss: 0.9346469640731812
Validation loss: 1.923223045564467

Epoch: 6| Step: 11
Training loss: 2.1328859329223633
Validation loss: 1.952348675779117

Epoch: 6| Step: 12
Training loss: 1.594904899597168
Validation loss: 1.9518636708618493

Epoch: 6| Step: 13
Training loss: 1.4734525680541992
Validation loss: 1.9034912073484032

Epoch: 249| Step: 0
Training loss: 1.9632800817489624
Validation loss: 1.9126877451455722

Epoch: 6| Step: 1
Training loss: 1.4863791465759277
Validation loss: 1.8979020221259004

Epoch: 6| Step: 2
Training loss: 1.5203853845596313
Validation loss: 1.9202835739299815

Epoch: 6| Step: 3
Training loss: 0.9586169719696045
Validation loss: 1.8645051576757943

Epoch: 6| Step: 4
Training loss: 1.340615153312683
Validation loss: 1.8710866538427209

Epoch: 6| Step: 5
Training loss: 1.7148951292037964
Validation loss: 1.896721988595942

Epoch: 6| Step: 6
Training loss: 2.784738540649414
Validation loss: 1.8581167933761433

Epoch: 6| Step: 7
Training loss: 1.6069737672805786
Validation loss: 1.8812951067442536

Epoch: 6| Step: 8
Training loss: 1.5949852466583252
Validation loss: 1.8830405153254026

Epoch: 6| Step: 9
Training loss: 1.006890058517456
Validation loss: 1.9058298962090605

Epoch: 6| Step: 10
Training loss: 1.9560706615447998
Validation loss: 1.8844545348998039

Epoch: 6| Step: 11
Training loss: 1.6360536813735962
Validation loss: 1.8897006204051356

Epoch: 6| Step: 12
Training loss: 2.019622325897217
Validation loss: 1.9025896390279133

Epoch: 6| Step: 13
Training loss: 1.3656011819839478
Validation loss: 1.8671778273838822

Epoch: 250| Step: 0
Training loss: 1.341477394104004
Validation loss: 1.9263129670132872

Epoch: 6| Step: 1
Training loss: 2.1698639392852783
Validation loss: 1.8750203309520599

Epoch: 6| Step: 2
Training loss: 1.7964597940444946
Validation loss: 1.9214280574552474

Epoch: 6| Step: 3
Training loss: 2.285205364227295
Validation loss: 1.90372508828358

Epoch: 6| Step: 4
Training loss: 1.673086166381836
Validation loss: 1.913025475317432

Epoch: 6| Step: 5
Training loss: 1.7427889108657837
Validation loss: 1.892820760767947

Epoch: 6| Step: 6
Training loss: 1.1555039882659912
Validation loss: 1.8949463200825516

Epoch: 6| Step: 7
Training loss: 1.5657920837402344
Validation loss: 1.8775311887905162

Epoch: 6| Step: 8
Training loss: 1.1588214635849
Validation loss: 1.9274120817902267

Epoch: 6| Step: 9
Training loss: 1.4129937887191772
Validation loss: 1.9008164482731973

Epoch: 6| Step: 10
Training loss: 2.276801109313965
Validation loss: 1.9076812228848856

Epoch: 6| Step: 11
Training loss: 1.4380700588226318
Validation loss: 1.9279302294536302

Epoch: 6| Step: 12
Training loss: 1.698150634765625
Validation loss: 1.9408396059466946

Epoch: 6| Step: 13
Training loss: 2.553870916366577
Validation loss: 1.9368157617507442

Epoch: 251| Step: 0
Training loss: 1.1265380382537842
Validation loss: 1.8929220425185336

Epoch: 6| Step: 1
Training loss: 2.0618605613708496
Validation loss: 1.9336617326223722

Epoch: 6| Step: 2
Training loss: 1.600386381149292
Validation loss: 1.9144815385982554

Epoch: 6| Step: 3
Training loss: 1.4575871229171753
Validation loss: 1.9038401342207385

Epoch: 6| Step: 4
Training loss: 1.5140585899353027
Validation loss: 1.8548139333724976

Epoch: 6| Step: 5
Training loss: 1.4034836292266846
Validation loss: 1.9064581701832433

Epoch: 6| Step: 6
Training loss: 1.6394684314727783
Validation loss: 1.9266205628712971

Epoch: 6| Step: 7
Training loss: 1.7207443714141846
Validation loss: 1.9001157463237803

Epoch: 6| Step: 8
Training loss: 2.37544846534729
Validation loss: 1.906660520902244

Epoch: 6| Step: 9
Training loss: 1.5994722843170166
Validation loss: 1.8954006254032094

Epoch: 6| Step: 10
Training loss: 1.830483078956604
Validation loss: 1.8913823032891879

Epoch: 6| Step: 11
Training loss: 1.5785517692565918
Validation loss: 1.9081873188736618

Epoch: 6| Step: 12
Training loss: 1.6838841438293457
Validation loss: 1.904617844089385

Epoch: 6| Step: 13
Training loss: 2.015928030014038
Validation loss: 1.9492104694407473

Epoch: 252| Step: 0
Training loss: 1.3714896440505981
Validation loss: 1.9091618830157864

Epoch: 6| Step: 1
Training loss: 1.3102973699569702
Validation loss: 1.9126898832218622

Epoch: 6| Step: 2
Training loss: 2.1400794982910156
Validation loss: 1.9551337598472514

Epoch: 6| Step: 3
Training loss: 1.8559613227844238
Validation loss: 1.8966318138184086

Epoch: 6| Step: 4
Training loss: 1.673154592514038
Validation loss: 1.8470203568858485

Epoch: 6| Step: 5
Training loss: 1.385683536529541
Validation loss: 1.9019917736771286

Epoch: 6| Step: 6
Training loss: 1.4104933738708496
Validation loss: 1.854264328556676

Epoch: 6| Step: 7
Training loss: 1.679474949836731
Validation loss: 1.8883614924646193

Epoch: 6| Step: 8
Training loss: 2.353273630142212
Validation loss: 1.8950857475239744

Epoch: 6| Step: 9
Training loss: 1.3007622957229614
Validation loss: 1.9231982897686701

Epoch: 6| Step: 10
Training loss: 1.8125625848770142
Validation loss: 1.9341652726614347

Epoch: 6| Step: 11
Training loss: 1.5366531610488892
Validation loss: 1.939571354978828

Epoch: 6| Step: 12
Training loss: 1.535222053527832
Validation loss: 1.9144110679626465

Epoch: 6| Step: 13
Training loss: 2.0115363597869873
Validation loss: 1.9141805902604134

Epoch: 253| Step: 0
Training loss: 1.1439249515533447
Validation loss: 1.926738526231499

Epoch: 6| Step: 1
Training loss: 2.0456559658050537
Validation loss: 1.914166993992303

Epoch: 6| Step: 2
Training loss: 1.21206533908844
Validation loss: 1.970586537032999

Epoch: 6| Step: 3
Training loss: 1.293663740158081
Validation loss: 1.938512714960242

Epoch: 6| Step: 4
Training loss: 1.6092114448547363
Validation loss: 1.9291785878519858

Epoch: 6| Step: 5
Training loss: 1.6888728141784668
Validation loss: 1.9226643603335145

Epoch: 6| Step: 6
Training loss: 1.2604396343231201
Validation loss: 1.929364888898788

Epoch: 6| Step: 7
Training loss: 2.2544167041778564
Validation loss: 1.9063733277782318

Epoch: 6| Step: 8
Training loss: 1.9815497398376465
Validation loss: 1.9457781237940635

Epoch: 6| Step: 9
Training loss: 1.3779308795928955
Validation loss: 1.9198706919147122

Epoch: 6| Step: 10
Training loss: 2.4484758377075195
Validation loss: 1.8959409677854149

Epoch: 6| Step: 11
Training loss: 1.56052827835083
Validation loss: 1.9290916150616062

Epoch: 6| Step: 12
Training loss: 2.0384809970855713
Validation loss: 1.8888308553285496

Epoch: 6| Step: 13
Training loss: 1.5362507104873657
Validation loss: 1.869586540806678

Epoch: 254| Step: 0
Training loss: 2.3397409915924072
Validation loss: 1.8619052697253484

Epoch: 6| Step: 1
Training loss: 1.3029167652130127
Validation loss: 1.8704315436783658

Epoch: 6| Step: 2
Training loss: 1.7144814729690552
Validation loss: 1.8910964304401028

Epoch: 6| Step: 3
Training loss: 2.400930404663086
Validation loss: 1.874305041887427

Epoch: 6| Step: 4
Training loss: 1.4652982950210571
Validation loss: 1.8483369901616087

Epoch: 6| Step: 5
Training loss: 2.148336410522461
Validation loss: 1.870080917112289

Epoch: 6| Step: 6
Training loss: 1.3540327548980713
Validation loss: 1.9019282569167435

Epoch: 6| Step: 7
Training loss: 1.2501767873764038
Validation loss: 1.8971291767653597

Epoch: 6| Step: 8
Training loss: 1.2194162607192993
Validation loss: 1.8895291795012772

Epoch: 6| Step: 9
Training loss: 1.5692311525344849
Validation loss: 1.9205449960565055

Epoch: 6| Step: 10
Training loss: 1.752084493637085
Validation loss: 1.9256715069534958

Epoch: 6| Step: 11
Training loss: 1.514620065689087
Validation loss: 1.9323406616846721

Epoch: 6| Step: 12
Training loss: 1.853772759437561
Validation loss: 1.9572704966350267

Epoch: 6| Step: 13
Training loss: 1.8377939462661743
Validation loss: 1.9365982137700564

Epoch: 255| Step: 0
Training loss: 1.1321887969970703
Validation loss: 1.9061879227238316

Epoch: 6| Step: 1
Training loss: 2.4320068359375
Validation loss: 1.9269921189995223

Epoch: 6| Step: 2
Training loss: 1.5966002941131592
Validation loss: 1.9728052744301416

Epoch: 6| Step: 3
Training loss: 1.6473543643951416
Validation loss: 1.93029333314588

Epoch: 6| Step: 4
Training loss: 1.7295806407928467
Validation loss: 1.9299897634854881

Epoch: 6| Step: 5
Training loss: 1.4200910329818726
Validation loss: 1.9132945793931202

Epoch: 6| Step: 6
Training loss: 1.2873448133468628
Validation loss: 1.9647896482098488

Epoch: 6| Step: 7
Training loss: 1.9579411745071411
Validation loss: 1.9492393898707565

Epoch: 6| Step: 8
Training loss: 1.9959666728973389
Validation loss: 1.9304408796371952

Epoch: 6| Step: 9
Training loss: 1.122996211051941
Validation loss: 1.9149994593794628

Epoch: 6| Step: 10
Training loss: 0.9432026743888855
Validation loss: 1.8910899623747794

Epoch: 6| Step: 11
Training loss: 1.919388771057129
Validation loss: 1.8930610738774782

Epoch: 6| Step: 12
Training loss: 2.4381155967712402
Validation loss: 1.9001009515536729

Epoch: 6| Step: 13
Training loss: 1.7545922994613647
Validation loss: 1.8712885072154384

Epoch: 256| Step: 0
Training loss: 2.1949379444122314
Validation loss: 1.8646640328950779

Epoch: 6| Step: 1
Training loss: 1.896335482597351
Validation loss: 1.869342330963381

Epoch: 6| Step: 2
Training loss: 1.6653285026550293
Validation loss: 1.8671841121489001

Epoch: 6| Step: 3
Training loss: 1.3122689723968506
Validation loss: 1.871865769868256

Epoch: 6| Step: 4
Training loss: 1.7577412128448486
Validation loss: 1.8831198574394308

Epoch: 6| Step: 5
Training loss: 2.0089550018310547
Validation loss: 1.9027234405599616

Epoch: 6| Step: 6
Training loss: 1.834185004234314
Validation loss: 1.8848791776164886

Epoch: 6| Step: 7
Training loss: 1.43581223487854
Validation loss: 1.8580541482535742

Epoch: 6| Step: 8
Training loss: 1.600775957107544
Validation loss: 1.8896057503197783

Epoch: 6| Step: 9
Training loss: 1.8051607608795166
Validation loss: 1.9039093909725067

Epoch: 6| Step: 10
Training loss: 1.8786593675613403
Validation loss: 1.906001357622044

Epoch: 6| Step: 11
Training loss: 1.5665130615234375
Validation loss: 1.9183820011795207

Epoch: 6| Step: 12
Training loss: 1.3808984756469727
Validation loss: 1.913214534841558

Epoch: 6| Step: 13
Training loss: 1.2608262300491333
Validation loss: 1.9241014629281976

Epoch: 257| Step: 0
Training loss: 1.7295933961868286
Validation loss: 1.9413978194677701

Epoch: 6| Step: 1
Training loss: 1.2472761869430542
Validation loss: 1.9162857750410676

Epoch: 6| Step: 2
Training loss: 1.7131799459457397
Validation loss: 1.9227568923786122

Epoch: 6| Step: 3
Training loss: 2.0525870323181152
Validation loss: 1.929303212832379

Epoch: 6| Step: 4
Training loss: 2.2394237518310547
Validation loss: 1.9253519286391556

Epoch: 6| Step: 5
Training loss: 1.5605015754699707
Validation loss: 1.8939917831010715

Epoch: 6| Step: 6
Training loss: 1.4399189949035645
Validation loss: 1.8899917769175705

Epoch: 6| Step: 7
Training loss: 1.690211534500122
Validation loss: 1.8839148142004525

Epoch: 6| Step: 8
Training loss: 1.5941262245178223
Validation loss: 1.920725477639065

Epoch: 6| Step: 9
Training loss: 1.3558685779571533
Validation loss: 1.8730374638752272

Epoch: 6| Step: 10
Training loss: 1.2118419408798218
Validation loss: 1.8926830471202891

Epoch: 6| Step: 11
Training loss: 1.6372919082641602
Validation loss: 1.8886431647885231

Epoch: 6| Step: 12
Training loss: 1.7626640796661377
Validation loss: 1.9050620678932435

Epoch: 6| Step: 13
Training loss: 2.1032886505126953
Validation loss: 1.941235439751738

Epoch: 258| Step: 0
Training loss: 1.192589282989502
Validation loss: 1.91826158185159

Epoch: 6| Step: 1
Training loss: 1.7623779773712158
Validation loss: 1.8827481910746584

Epoch: 6| Step: 2
Training loss: 2.119760036468506
Validation loss: 1.9126018875388688

Epoch: 6| Step: 3
Training loss: 1.332045078277588
Validation loss: 1.8928212478596678

Epoch: 6| Step: 4
Training loss: 1.8067576885223389
Validation loss: 1.8882246530184181

Epoch: 6| Step: 5
Training loss: 1.5690432786941528
Validation loss: 1.9003084244266633

Epoch: 6| Step: 6
Training loss: 1.3276753425598145
Validation loss: 1.9187612636114961

Epoch: 6| Step: 7
Training loss: 1.265854001045227
Validation loss: 1.9219919981495026

Epoch: 6| Step: 8
Training loss: 2.2078280448913574
Validation loss: 1.9061588215571579

Epoch: 6| Step: 9
Training loss: 1.6974432468414307
Validation loss: 1.873892923837067

Epoch: 6| Step: 10
Training loss: 1.164107322692871
Validation loss: 1.878751338169139

Epoch: 6| Step: 11
Training loss: 1.8529454469680786
Validation loss: 1.912187018702107

Epoch: 6| Step: 12
Training loss: 1.7291760444641113
Validation loss: 1.9395087611290716

Epoch: 6| Step: 13
Training loss: 2.11916446685791
Validation loss: 1.9222851850653206

Epoch: 259| Step: 0
Training loss: 1.254340410232544
Validation loss: 1.915359547061305

Epoch: 6| Step: 1
Training loss: 1.4786386489868164
Validation loss: 1.8862958441498459

Epoch: 6| Step: 2
Training loss: 1.7164009809494019
Validation loss: 1.9030974911105247

Epoch: 6| Step: 3
Training loss: 1.7391794919967651
Validation loss: 1.9534475034283054

Epoch: 6| Step: 4
Training loss: 1.7470980882644653
Validation loss: 1.9446608674141668

Epoch: 6| Step: 5
Training loss: 1.8672945499420166
Validation loss: 1.9153203272050427

Epoch: 6| Step: 6
Training loss: 0.8650317192077637
Validation loss: 1.9090138648145942

Epoch: 6| Step: 7
Training loss: 1.1014350652694702
Validation loss: 1.8792534899967972

Epoch: 6| Step: 8
Training loss: 1.996081829071045
Validation loss: 1.9160556575303436

Epoch: 6| Step: 9
Training loss: 1.6448001861572266
Validation loss: 1.921289328605898

Epoch: 6| Step: 10
Training loss: 2.0471608638763428
Validation loss: 1.9346613986517793

Epoch: 6| Step: 11
Training loss: 1.9068832397460938
Validation loss: 1.921510108055607

Epoch: 6| Step: 12
Training loss: 1.740466833114624
Validation loss: 1.8626950274231613

Epoch: 6| Step: 13
Training loss: 1.7799432277679443
Validation loss: 1.8985549942139657

Epoch: 260| Step: 0
Training loss: 1.8644963502883911
Validation loss: 1.9345759896821872

Epoch: 6| Step: 1
Training loss: 1.402074933052063
Validation loss: 1.9344719635543002

Epoch: 6| Step: 2
Training loss: 1.8792057037353516
Validation loss: 1.9046795957831926

Epoch: 6| Step: 3
Training loss: 1.773118019104004
Validation loss: 1.9234379991408317

Epoch: 6| Step: 4
Training loss: 1.162781834602356
Validation loss: 1.8820952407775386

Epoch: 6| Step: 5
Training loss: 1.531538486480713
Validation loss: 1.856397622375078

Epoch: 6| Step: 6
Training loss: 1.5686498880386353
Validation loss: 1.879221257343087

Epoch: 6| Step: 7
Training loss: 1.8888986110687256
Validation loss: 1.8421028147461593

Epoch: 6| Step: 8
Training loss: 0.735862135887146
Validation loss: 1.8498956644406883

Epoch: 6| Step: 9
Training loss: 1.9896087646484375
Validation loss: 1.8928195738023328

Epoch: 6| Step: 10
Training loss: 1.6022295951843262
Validation loss: 1.8679632653472245

Epoch: 6| Step: 11
Training loss: 1.8028295040130615
Validation loss: 1.8721641763564079

Epoch: 6| Step: 12
Training loss: 2.216125011444092
Validation loss: 1.8469879037590438

Epoch: 6| Step: 13
Training loss: 1.3638824224472046
Validation loss: 1.8833938516596311

Epoch: 261| Step: 0
Training loss: 1.543899655342102
Validation loss: 1.8527312368474982

Epoch: 6| Step: 1
Training loss: 1.456350564956665
Validation loss: 1.8661813915416758

Epoch: 6| Step: 2
Training loss: 1.8479788303375244
Validation loss: 1.9233811696370442

Epoch: 6| Step: 3
Training loss: 1.7379436492919922
Validation loss: 1.8952963018930087

Epoch: 6| Step: 4
Training loss: 1.721520185470581
Validation loss: 1.8948747316996257

Epoch: 6| Step: 5
Training loss: 1.685470700263977
Validation loss: 1.9467182146605624

Epoch: 6| Step: 6
Training loss: 2.312398672103882
Validation loss: 1.9015819513669578

Epoch: 6| Step: 7
Training loss: 1.118894100189209
Validation loss: 1.8886191319393855

Epoch: 6| Step: 8
Training loss: 1.5250126123428345
Validation loss: 1.9216305863472722

Epoch: 6| Step: 9
Training loss: 1.5976593494415283
Validation loss: 1.9575117839279996

Epoch: 6| Step: 10
Training loss: 1.039808988571167
Validation loss: 1.8948152526732414

Epoch: 6| Step: 11
Training loss: 1.844918966293335
Validation loss: 1.932779586443337

Epoch: 6| Step: 12
Training loss: 1.7243951559066772
Validation loss: 1.8879626438181887

Epoch: 6| Step: 13
Training loss: 1.708854079246521
Validation loss: 1.9201648645503546

Epoch: 262| Step: 0
Training loss: 1.62310791015625
Validation loss: 1.8952818583416682

Epoch: 6| Step: 1
Training loss: 1.8931443691253662
Validation loss: 1.9626141248210784

Epoch: 6| Step: 2
Training loss: 2.1742773056030273
Validation loss: 1.903945968997094

Epoch: 6| Step: 3
Training loss: 1.6259350776672363
Validation loss: 1.9041018562932168

Epoch: 6| Step: 4
Training loss: 1.749455451965332
Validation loss: 1.8884506097403906

Epoch: 6| Step: 5
Training loss: 1.0540798902511597
Validation loss: 1.8480848138050368

Epoch: 6| Step: 6
Training loss: 1.7452037334442139
Validation loss: 1.8831967166675034

Epoch: 6| Step: 7
Training loss: 1.8986845016479492
Validation loss: 1.8791606182693152

Epoch: 6| Step: 8
Training loss: 1.300865650177002
Validation loss: 1.8476316569953837

Epoch: 6| Step: 9
Training loss: 1.6811268329620361
Validation loss: 1.875199302550285

Epoch: 6| Step: 10
Training loss: 1.5486358404159546
Validation loss: 1.8129825899677892

Epoch: 6| Step: 11
Training loss: 1.548680067062378
Validation loss: 1.874385097975372

Epoch: 6| Step: 12
Training loss: 1.7853500843048096
Validation loss: 1.860040556999945

Epoch: 6| Step: 13
Training loss: 1.2542272806167603
Validation loss: 1.8581695505367812

Epoch: 263| Step: 0
Training loss: 1.661440372467041
Validation loss: 1.8797300579727336

Epoch: 6| Step: 1
Training loss: 1.441917896270752
Validation loss: 1.9040804627121135

Epoch: 6| Step: 2
Training loss: 1.5305466651916504
Validation loss: 1.8870634660925916

Epoch: 6| Step: 3
Training loss: 2.3400959968566895
Validation loss: 1.8725328676162227

Epoch: 6| Step: 4
Training loss: 1.754502534866333
Validation loss: 1.888613106102072

Epoch: 6| Step: 5
Training loss: 1.4577760696411133
Validation loss: 1.889217375427164

Epoch: 6| Step: 6
Training loss: 1.984142780303955
Validation loss: 1.8879586355660551

Epoch: 6| Step: 7
Training loss: 1.341758131980896
Validation loss: 1.902361657029839

Epoch: 6| Step: 8
Training loss: 1.1883130073547363
Validation loss: 1.8482348162640807

Epoch: 6| Step: 9
Training loss: 1.5523306131362915
Validation loss: 1.9330309590985697

Epoch: 6| Step: 10
Training loss: 1.2503211498260498
Validation loss: 1.8824738251265658

Epoch: 6| Step: 11
Training loss: 1.708911657333374
Validation loss: 1.8935576010775823

Epoch: 6| Step: 12
Training loss: 1.7536683082580566
Validation loss: 1.9144043422514392

Epoch: 6| Step: 13
Training loss: 2.1457600593566895
Validation loss: 1.8936888620417605

Epoch: 264| Step: 0
Training loss: 1.102264642715454
Validation loss: 1.8337112190902873

Epoch: 6| Step: 1
Training loss: 1.364558458328247
Validation loss: 1.8766046852193854

Epoch: 6| Step: 2
Training loss: 1.5396696329116821
Validation loss: 1.9041553722914828

Epoch: 6| Step: 3
Training loss: 1.7347385883331299
Validation loss: 1.895981042615829

Epoch: 6| Step: 4
Training loss: 1.6702879667282104
Validation loss: 1.8876798204196397

Epoch: 6| Step: 5
Training loss: 2.1743648052215576
Validation loss: 1.919803419420796

Epoch: 6| Step: 6
Training loss: 1.4091836214065552
Validation loss: 1.9216822744697653

Epoch: 6| Step: 7
Training loss: 1.623974323272705
Validation loss: 1.9302033429504724

Epoch: 6| Step: 8
Training loss: 2.0932395458221436
Validation loss: 1.869943509819687

Epoch: 6| Step: 9
Training loss: 1.7318902015686035
Validation loss: 1.913315834537629

Epoch: 6| Step: 10
Training loss: 1.5031616687774658
Validation loss: 1.9236778084949782

Epoch: 6| Step: 11
Training loss: 1.5344386100769043
Validation loss: 1.8892423670778993

Epoch: 6| Step: 12
Training loss: 1.3639812469482422
Validation loss: 1.9016562008088636

Epoch: 6| Step: 13
Training loss: 1.944092869758606
Validation loss: 1.9419086338371359

Epoch: 265| Step: 0
Training loss: 1.574018955230713
Validation loss: 1.885943369198871

Epoch: 6| Step: 1
Training loss: 1.6803134679794312
Validation loss: 1.9139023660331644

Epoch: 6| Step: 2
Training loss: 1.922849416732788
Validation loss: 1.9149831982069119

Epoch: 6| Step: 3
Training loss: 1.9017235040664673
Validation loss: 1.9575827301189463

Epoch: 6| Step: 4
Training loss: 1.5702306032180786
Validation loss: 1.893018582815765

Epoch: 6| Step: 5
Training loss: 1.8581167459487915
Validation loss: 1.9026097584796209

Epoch: 6| Step: 6
Training loss: 1.2028135061264038
Validation loss: 1.890253133671258

Epoch: 6| Step: 7
Training loss: 1.9806404113769531
Validation loss: 1.8859374946163547

Epoch: 6| Step: 8
Training loss: 2.01952862739563
Validation loss: 1.8786990475910965

Epoch: 6| Step: 9
Training loss: 1.6020081043243408
Validation loss: 1.866032031274611

Epoch: 6| Step: 10
Training loss: 1.528134822845459
Validation loss: 1.8681974180283085

Epoch: 6| Step: 11
Training loss: 1.425879955291748
Validation loss: 1.8820198005245579

Epoch: 6| Step: 12
Training loss: 1.2733039855957031
Validation loss: 1.875721498202252

Epoch: 6| Step: 13
Training loss: 1.2611262798309326
Validation loss: 1.8779130404995334

Epoch: 266| Step: 0
Training loss: 1.28602933883667
Validation loss: 1.9398303262649044

Epoch: 6| Step: 1
Training loss: 1.4300696849822998
Validation loss: 1.881723221912179

Epoch: 6| Step: 2
Training loss: 1.9171983003616333
Validation loss: 1.9052427250851867

Epoch: 6| Step: 3
Training loss: 2.146233558654785
Validation loss: 1.9100504485509728

Epoch: 6| Step: 4
Training loss: 1.5794591903686523
Validation loss: 1.8804977273428312

Epoch: 6| Step: 5
Training loss: 1.7475537061691284
Validation loss: 1.8964410648551038

Epoch: 6| Step: 6
Training loss: 1.7276684045791626
Validation loss: 1.9214975398073915

Epoch: 6| Step: 7
Training loss: 1.7212388515472412
Validation loss: 1.915572581752654

Epoch: 6| Step: 8
Training loss: 1.9625272750854492
Validation loss: 1.912134244877805

Epoch: 6| Step: 9
Training loss: 1.4389941692352295
Validation loss: 1.8933557746230916

Epoch: 6| Step: 10
Training loss: 1.5034782886505127
Validation loss: 1.915795503124114

Epoch: 6| Step: 11
Training loss: 1.7954480648040771
Validation loss: 1.9003167562587286

Epoch: 6| Step: 12
Training loss: 1.2791121006011963
Validation loss: 1.8809958664319848

Epoch: 6| Step: 13
Training loss: 1.0695196390151978
Validation loss: 1.8984113495836976

Epoch: 267| Step: 0
Training loss: 1.311997890472412
Validation loss: 1.9074765661711335

Epoch: 6| Step: 1
Training loss: 1.743009090423584
Validation loss: 1.872797353293306

Epoch: 6| Step: 2
Training loss: 1.1963962316513062
Validation loss: 1.9174208359051776

Epoch: 6| Step: 3
Training loss: 1.9341752529144287
Validation loss: 1.8820533816532423

Epoch: 6| Step: 4
Training loss: 1.8206617832183838
Validation loss: 1.877001295807541

Epoch: 6| Step: 5
Training loss: 1.0306487083435059
Validation loss: 1.9128772815068562

Epoch: 6| Step: 6
Training loss: 1.3625208139419556
Validation loss: 1.8596849697892384

Epoch: 6| Step: 7
Training loss: 1.6193830966949463
Validation loss: 1.9445308280247513

Epoch: 6| Step: 8
Training loss: 1.187304139137268
Validation loss: 1.8930546532395065

Epoch: 6| Step: 9
Training loss: 1.5001094341278076
Validation loss: 1.8812043654021395

Epoch: 6| Step: 10
Training loss: 1.8411122560501099
Validation loss: 1.8866593068645847

Epoch: 6| Step: 11
Training loss: 2.327298879623413
Validation loss: 1.8900667569970573

Epoch: 6| Step: 12
Training loss: 2.1442699432373047
Validation loss: 1.924405187688848

Epoch: 6| Step: 13
Training loss: 2.1263954639434814
Validation loss: 1.9065243339025846

Epoch: 268| Step: 0
Training loss: 1.5582630634307861
Validation loss: 1.9105752680891304

Epoch: 6| Step: 1
Training loss: 2.048898696899414
Validation loss: 1.8703913791205293

Epoch: 6| Step: 2
Training loss: 1.8459657430648804
Validation loss: 1.9446803844103249

Epoch: 6| Step: 3
Training loss: 1.317478895187378
Validation loss: 1.8979004301050657

Epoch: 6| Step: 4
Training loss: 1.8385778665542603
Validation loss: 1.8939365097271499

Epoch: 6| Step: 5
Training loss: 1.6531339883804321
Validation loss: 1.8943461090005853

Epoch: 6| Step: 6
Training loss: 1.2282437086105347
Validation loss: 1.864859604066418

Epoch: 6| Step: 7
Training loss: 1.501422643661499
Validation loss: 1.9048900245338358

Epoch: 6| Step: 8
Training loss: 0.8414123058319092
Validation loss: 1.9344945159009708

Epoch: 6| Step: 9
Training loss: 2.4129228591918945
Validation loss: 1.9111134031767487

Epoch: 6| Step: 10
Training loss: 1.1411983966827393
Validation loss: 1.9201133071735341

Epoch: 6| Step: 11
Training loss: 1.6299028396606445
Validation loss: 1.8822725549820931

Epoch: 6| Step: 12
Training loss: 2.473803997039795
Validation loss: 1.9395385403786936

Epoch: 6| Step: 13
Training loss: 0.9315648674964905
Validation loss: 1.8955358792376775

Epoch: 269| Step: 0
Training loss: 1.874152660369873
Validation loss: 1.9542544631547825

Epoch: 6| Step: 1
Training loss: 2.0402512550354004
Validation loss: 1.9068456042197444

Epoch: 6| Step: 2
Training loss: 1.0024452209472656
Validation loss: 1.9070010697969826

Epoch: 6| Step: 3
Training loss: 1.126047134399414
Validation loss: 1.9169750405896095

Epoch: 6| Step: 4
Training loss: 2.844252586364746
Validation loss: 1.9131951870456818

Epoch: 6| Step: 5
Training loss: 1.3589293956756592
Validation loss: 1.8894055940771615

Epoch: 6| Step: 6
Training loss: 0.8185330629348755
Validation loss: 1.9135679852577947

Epoch: 6| Step: 7
Training loss: 2.207037925720215
Validation loss: 1.9138969093240716

Epoch: 6| Step: 8
Training loss: 1.9965232610702515
Validation loss: 1.906751307108069

Epoch: 6| Step: 9
Training loss: 1.048938274383545
Validation loss: 1.8982830034789218

Epoch: 6| Step: 10
Training loss: 2.157958984375
Validation loss: 1.8677722843744422

Epoch: 6| Step: 11
Training loss: 1.0070842504501343
Validation loss: 1.9239743012253956

Epoch: 6| Step: 12
Training loss: 1.3222696781158447
Validation loss: 1.84662877744244

Epoch: 6| Step: 13
Training loss: 1.9535585641860962
Validation loss: 1.908807272552162

Epoch: 270| Step: 0
Training loss: 1.3797744512557983
Validation loss: 1.954550095783767

Epoch: 6| Step: 1
Training loss: 1.2733385562896729
Validation loss: 1.8729063708295104

Epoch: 6| Step: 2
Training loss: 1.8321462869644165
Validation loss: 1.8742177037782566

Epoch: 6| Step: 3
Training loss: 2.2231926918029785
Validation loss: 1.898774472616052

Epoch: 6| Step: 4
Training loss: 1.712273120880127
Validation loss: 1.887698511923513

Epoch: 6| Step: 5
Training loss: 1.7902673482894897
Validation loss: 1.9080108519523375

Epoch: 6| Step: 6
Training loss: 1.4006072282791138
Validation loss: 1.890103668294927

Epoch: 6| Step: 7
Training loss: 1.7708905935287476
Validation loss: 1.8651138287718578

Epoch: 6| Step: 8
Training loss: 1.9115116596221924
Validation loss: 1.8841206104524675

Epoch: 6| Step: 9
Training loss: 0.9784848093986511
Validation loss: 1.864213805044851

Epoch: 6| Step: 10
Training loss: 1.6654331684112549
Validation loss: 1.895078516775562

Epoch: 6| Step: 11
Training loss: 1.0807068347930908
Validation loss: 1.927551596395431

Epoch: 6| Step: 12
Training loss: 1.649048924446106
Validation loss: 1.9005780220031738

Epoch: 6| Step: 13
Training loss: 2.1827645301818848
Validation loss: 1.931290477834722

Epoch: 271| Step: 0
Training loss: 1.9803324937820435
Validation loss: 1.9654633755324988

Epoch: 6| Step: 1
Training loss: 1.4498764276504517
Validation loss: 1.9016423353584864

Epoch: 6| Step: 2
Training loss: 1.2742671966552734
Validation loss: 1.8745874025488412

Epoch: 6| Step: 3
Training loss: 1.870204210281372
Validation loss: 1.921185435787324

Epoch: 6| Step: 4
Training loss: 1.5163946151733398
Validation loss: 1.9108243398768927

Epoch: 6| Step: 5
Training loss: 1.799462914466858
Validation loss: 1.8956101094522784

Epoch: 6| Step: 6
Training loss: 2.2679548263549805
Validation loss: 1.9138075331205964

Epoch: 6| Step: 7
Training loss: 1.687041997909546
Validation loss: 1.9270507648427

Epoch: 6| Step: 8
Training loss: 1.5342501401901245
Validation loss: 1.8610629215035388

Epoch: 6| Step: 9
Training loss: 1.809847354888916
Validation loss: 1.9485163868114512

Epoch: 6| Step: 10
Training loss: 0.9989995360374451
Validation loss: 1.9116784270091722

Epoch: 6| Step: 11
Training loss: 1.3730977773666382
Validation loss: 1.910782620471011

Epoch: 6| Step: 12
Training loss: 1.6042537689208984
Validation loss: 1.8697054834776028

Epoch: 6| Step: 13
Training loss: 0.8538037538528442
Validation loss: 1.9102261899619974

Epoch: 272| Step: 0
Training loss: 2.1225972175598145
Validation loss: 1.8982553033418552

Epoch: 6| Step: 1
Training loss: 1.10182785987854
Validation loss: 1.8750280834013415

Epoch: 6| Step: 2
Training loss: 1.443349838256836
Validation loss: 1.864748647136073

Epoch: 6| Step: 3
Training loss: 2.3629202842712402
Validation loss: 1.8915953969442716

Epoch: 6| Step: 4
Training loss: 1.2932629585266113
Validation loss: 1.9062528943502774

Epoch: 6| Step: 5
Training loss: 1.8761481046676636
Validation loss: 1.899593968545237

Epoch: 6| Step: 6
Training loss: 1.544649600982666
Validation loss: 1.9165491698890604

Epoch: 6| Step: 7
Training loss: 1.3387503623962402
Validation loss: 1.9148522628250944

Epoch: 6| Step: 8
Training loss: 1.143990159034729
Validation loss: 1.8880896183752245

Epoch: 6| Step: 9
Training loss: 1.2257189750671387
Validation loss: 1.8710991336453346

Epoch: 6| Step: 10
Training loss: 1.7794691324234009
Validation loss: 1.8339662885153165

Epoch: 6| Step: 11
Training loss: 1.994875431060791
Validation loss: 1.8994144303824312

Epoch: 6| Step: 12
Training loss: 1.2519824504852295
Validation loss: 1.8367467003483926

Epoch: 6| Step: 13
Training loss: 1.9031355381011963
Validation loss: 1.9167903315636419

Epoch: 273| Step: 0
Training loss: 1.5400584936141968
Validation loss: 1.8819775158359158

Epoch: 6| Step: 1
Training loss: 1.4464430809020996
Validation loss: 1.8663633805449291

Epoch: 6| Step: 2
Training loss: 1.6276679039001465
Validation loss: 1.8855350197002452

Epoch: 6| Step: 3
Training loss: 2.0667881965637207
Validation loss: 1.90379362721597

Epoch: 6| Step: 4
Training loss: 1.0258868932724
Validation loss: 1.8657837042244532

Epoch: 6| Step: 5
Training loss: 0.9791896343231201
Validation loss: 1.8618443319874425

Epoch: 6| Step: 6
Training loss: 1.3471431732177734
Validation loss: 1.8626749028441727

Epoch: 6| Step: 7
Training loss: 1.646549105644226
Validation loss: 1.891327118360868

Epoch: 6| Step: 8
Training loss: 1.8956904411315918
Validation loss: 1.881485596779854

Epoch: 6| Step: 9
Training loss: 1.9056850671768188
Validation loss: 1.9310157017041278

Epoch: 6| Step: 10
Training loss: 1.57155179977417
Validation loss: 1.8847275254546956

Epoch: 6| Step: 11
Training loss: 1.981295108795166
Validation loss: 1.8961882821975216

Epoch: 6| Step: 12
Training loss: 1.7650361061096191
Validation loss: 1.9089338074448288

Epoch: 6| Step: 13
Training loss: 1.5253825187683105
Validation loss: 1.9128150914305

Epoch: 274| Step: 0
Training loss: 1.016337513923645
Validation loss: 1.8464369850773965

Epoch: 6| Step: 1
Training loss: 1.954309105873108
Validation loss: 1.911710589162765

Epoch: 6| Step: 2
Training loss: 1.5471879243850708
Validation loss: 1.897045805890073

Epoch: 6| Step: 3
Training loss: 1.3928196430206299
Validation loss: 1.8934907336388864

Epoch: 6| Step: 4
Training loss: 1.0402984619140625
Validation loss: 1.8692468814952399

Epoch: 6| Step: 5
Training loss: 1.5377197265625
Validation loss: 1.8885362635376632

Epoch: 6| Step: 6
Training loss: 1.2289823293685913
Validation loss: 1.931283845696398

Epoch: 6| Step: 7
Training loss: 1.7762507200241089
Validation loss: 1.8860627464068833

Epoch: 6| Step: 8
Training loss: 2.068359851837158
Validation loss: 1.87479692633434

Epoch: 6| Step: 9
Training loss: 1.8872041702270508
Validation loss: 1.9105375069443897

Epoch: 6| Step: 10
Training loss: 1.3423142433166504
Validation loss: 1.9108030872960244

Epoch: 6| Step: 11
Training loss: 1.7400768995285034
Validation loss: 1.9306491600569857

Epoch: 6| Step: 12
Training loss: 2.4858298301696777
Validation loss: 1.9126568891668831

Epoch: 6| Step: 13
Training loss: 1.3913869857788086
Validation loss: 1.9266563871855378

Epoch: 275| Step: 0
Training loss: 1.7622911930084229
Validation loss: 1.9396914025788665

Epoch: 6| Step: 1
Training loss: 1.4954179525375366
Validation loss: 1.9124073033691735

Epoch: 6| Step: 2
Training loss: 1.1613681316375732
Validation loss: 1.9597165764019053

Epoch: 6| Step: 3
Training loss: 1.7433487176895142
Validation loss: 1.9243790282998035

Epoch: 6| Step: 4
Training loss: 1.4509544372558594
Validation loss: 1.9538427732324088

Epoch: 6| Step: 5
Training loss: 1.4121532440185547
Validation loss: 1.8964048777857134

Epoch: 6| Step: 6
Training loss: 1.397500991821289
Validation loss: 1.9222676600179365

Epoch: 6| Step: 7
Training loss: 2.0260820388793945
Validation loss: 1.9330691188894293

Epoch: 6| Step: 8
Training loss: 2.161945343017578
Validation loss: 1.9561530287547777

Epoch: 6| Step: 9
Training loss: 1.279700756072998
Validation loss: 1.9218141930077666

Epoch: 6| Step: 10
Training loss: 1.2606490850448608
Validation loss: 1.9373942562328872

Epoch: 6| Step: 11
Training loss: 1.3930962085723877
Validation loss: 1.9395261323580177

Epoch: 6| Step: 12
Training loss: 2.329796314239502
Validation loss: 1.9393383943906395

Epoch: 6| Step: 13
Training loss: 0.9508359432220459
Validation loss: 1.9112759226111955

Epoch: 276| Step: 0
Training loss: 1.6253540515899658
Validation loss: 1.8701842625935872

Epoch: 6| Step: 1
Training loss: 1.038251280784607
Validation loss: 1.9161450042519519

Epoch: 6| Step: 2
Training loss: 1.845461130142212
Validation loss: 1.8775029977162678

Epoch: 6| Step: 3
Training loss: 1.7890164852142334
Validation loss: 1.8813402473285634

Epoch: 6| Step: 4
Training loss: 1.183166742324829
Validation loss: 1.8384708204577047

Epoch: 6| Step: 5
Training loss: 1.648766279220581
Validation loss: 1.8889933657902542

Epoch: 6| Step: 6
Training loss: 1.8196983337402344
Validation loss: 1.8762988839098202

Epoch: 6| Step: 7
Training loss: 1.6048107147216797
Validation loss: 1.8974568690023115

Epoch: 6| Step: 8
Training loss: 1.920362114906311
Validation loss: 1.89520308022858

Epoch: 6| Step: 9
Training loss: 1.4850873947143555
Validation loss: 1.8780850723225584

Epoch: 6| Step: 10
Training loss: 1.1495044231414795
Validation loss: 1.8747108931182532

Epoch: 6| Step: 11
Training loss: 1.9623337984085083
Validation loss: 1.904379524210448

Epoch: 6| Step: 12
Training loss: 1.7896273136138916
Validation loss: 1.9126788326489028

Epoch: 6| Step: 13
Training loss: 2.1867685317993164
Validation loss: 1.8739636867277083

Epoch: 277| Step: 0
Training loss: 1.464116096496582
Validation loss: 1.9340770834235734

Epoch: 6| Step: 1
Training loss: 1.3764081001281738
Validation loss: 1.907026267820789

Epoch: 6| Step: 2
Training loss: 1.829399824142456
Validation loss: 1.9007014689906951

Epoch: 6| Step: 3
Training loss: 1.5017213821411133
Validation loss: 1.9731298646619242

Epoch: 6| Step: 4
Training loss: 2.0570273399353027
Validation loss: 1.9028405963733632

Epoch: 6| Step: 5
Training loss: 1.263150691986084
Validation loss: 1.9533891152310114

Epoch: 6| Step: 6
Training loss: 1.1749114990234375
Validation loss: 1.9051704304192656

Epoch: 6| Step: 7
Training loss: 1.812697172164917
Validation loss: 1.8989456597194876

Epoch: 6| Step: 8
Training loss: 1.9865059852600098
Validation loss: 1.9398418805932487

Epoch: 6| Step: 9
Training loss: 1.3257986307144165
Validation loss: 1.9350613342818392

Epoch: 6| Step: 10
Training loss: 1.4856905937194824
Validation loss: 1.906790115500009

Epoch: 6| Step: 11
Training loss: 1.5610377788543701
Validation loss: 1.881050173954297

Epoch: 6| Step: 12
Training loss: 1.8744829893112183
Validation loss: 1.9109652491026028

Epoch: 6| Step: 13
Training loss: 1.5422409772872925
Validation loss: 1.8943311181119693

Epoch: 278| Step: 0
Training loss: 1.5232806205749512
Validation loss: 1.8965881742456907

Epoch: 6| Step: 1
Training loss: 1.2513025999069214
Validation loss: 1.9204235845996487

Epoch: 6| Step: 2
Training loss: 2.0579354763031006
Validation loss: 1.8706424223479403

Epoch: 6| Step: 3
Training loss: 1.8948941230773926
Validation loss: 1.8871338367462158

Epoch: 6| Step: 4
Training loss: 1.6496334075927734
Validation loss: 1.8729009859023555

Epoch: 6| Step: 5
Training loss: 1.2459053993225098
Validation loss: 1.8443934340630808

Epoch: 6| Step: 6
Training loss: 1.2532223463058472
Validation loss: 1.9091958871451757

Epoch: 6| Step: 7
Training loss: 2.0711512565612793
Validation loss: 1.8790613835857761

Epoch: 6| Step: 8
Training loss: 1.7019751071929932
Validation loss: 1.8872277416208738

Epoch: 6| Step: 9
Training loss: 1.5893170833587646
Validation loss: 1.8635076463863414

Epoch: 6| Step: 10
Training loss: 1.1617240905761719
Validation loss: 1.8871630443039762

Epoch: 6| Step: 11
Training loss: 1.8177597522735596
Validation loss: 1.9276757009567753

Epoch: 6| Step: 12
Training loss: 0.9572203159332275
Validation loss: 1.8818908801642797

Epoch: 6| Step: 13
Training loss: 2.134514570236206
Validation loss: 1.8760061289674492

Epoch: 279| Step: 0
Training loss: 1.2346482276916504
Validation loss: 1.9282400415789696

Epoch: 6| Step: 1
Training loss: 1.5965322256088257
Validation loss: 1.952868297535886

Epoch: 6| Step: 2
Training loss: 1.323825716972351
Validation loss: 1.9342215266278995

Epoch: 6| Step: 3
Training loss: 1.4375168085098267
Validation loss: 1.9431692400286276

Epoch: 6| Step: 4
Training loss: 2.0257763862609863
Validation loss: 1.8845892708788636

Epoch: 6| Step: 5
Training loss: 1.8371635675430298
Validation loss: 1.8963709928656136

Epoch: 6| Step: 6
Training loss: 0.9975540041923523
Validation loss: 1.9034423802488594

Epoch: 6| Step: 7
Training loss: 1.341723918914795
Validation loss: 1.8844911475335397

Epoch: 6| Step: 8
Training loss: 1.5633485317230225
Validation loss: 1.8800665050424554

Epoch: 6| Step: 9
Training loss: 1.473466157913208
Validation loss: 1.9187202222885624

Epoch: 6| Step: 10
Training loss: 1.8717082738876343
Validation loss: 1.8916063821443947

Epoch: 6| Step: 11
Training loss: 2.4237351417541504
Validation loss: 1.9487292317933933

Epoch: 6| Step: 12
Training loss: 1.5111786127090454
Validation loss: 1.9129193188041769

Epoch: 6| Step: 13
Training loss: 1.4736368656158447
Validation loss: 1.9269919062173495

Epoch: 280| Step: 0
Training loss: 1.3496052026748657
Validation loss: 1.9029570279582855

Epoch: 6| Step: 1
Training loss: 1.263404369354248
Validation loss: 1.8938770422371485

Epoch: 6| Step: 2
Training loss: 1.4080954790115356
Validation loss: 1.9305990319098196

Epoch: 6| Step: 3
Training loss: 1.4380147457122803
Validation loss: 1.8756382208998486

Epoch: 6| Step: 4
Training loss: 1.1502654552459717
Validation loss: 1.9019072389089933

Epoch: 6| Step: 5
Training loss: 1.0924601554870605
Validation loss: 1.8996527400068057

Epoch: 6| Step: 6
Training loss: 1.716309666633606
Validation loss: 1.8714912117168467

Epoch: 6| Step: 7
Training loss: 1.8379029035568237
Validation loss: 1.860857335470056

Epoch: 6| Step: 8
Training loss: 2.5697269439697266
Validation loss: 1.8882769359055387

Epoch: 6| Step: 9
Training loss: 1.7613288164138794
Validation loss: 1.8800096563113633

Epoch: 6| Step: 10
Training loss: 2.133176803588867
Validation loss: 1.8885539462489467

Epoch: 6| Step: 11
Training loss: 1.3823437690734863
Validation loss: 1.9160568547505203

Epoch: 6| Step: 12
Training loss: 1.2924818992614746
Validation loss: 1.903175921850307

Epoch: 6| Step: 13
Training loss: 1.9568239450454712
Validation loss: 1.9233877979299074

Epoch: 281| Step: 0
Training loss: 1.9145328998565674
Validation loss: 1.8761801309483026

Epoch: 6| Step: 1
Training loss: 1.6164079904556274
Validation loss: 1.8976112027322092

Epoch: 6| Step: 2
Training loss: 1.2531460523605347
Validation loss: 1.863910887831001

Epoch: 6| Step: 3
Training loss: 1.3365402221679688
Validation loss: 1.8732296830864363

Epoch: 6| Step: 4
Training loss: 1.4927278757095337
Validation loss: 1.8850616614023845

Epoch: 6| Step: 5
Training loss: 1.5557668209075928
Validation loss: 1.8999026065231652

Epoch: 6| Step: 6
Training loss: 1.9749103784561157
Validation loss: 1.881109465834915

Epoch: 6| Step: 7
Training loss: 1.7354933023452759
Validation loss: 1.8823126541670931

Epoch: 6| Step: 8
Training loss: 1.6158411502838135
Validation loss: 1.8593593553830219

Epoch: 6| Step: 9
Training loss: 1.5812528133392334
Validation loss: 1.876433221242761

Epoch: 6| Step: 10
Training loss: 2.0193071365356445
Validation loss: 1.9250262668055873

Epoch: 6| Step: 11
Training loss: 0.8447200059890747
Validation loss: 1.881652929449594

Epoch: 6| Step: 12
Training loss: 1.4812487363815308
Validation loss: 1.8870162092229372

Epoch: 6| Step: 13
Training loss: 1.8208105564117432
Validation loss: 1.8862221087178876

Epoch: 282| Step: 0
Training loss: 1.6349656581878662
Validation loss: 1.8674384163271995

Epoch: 6| Step: 1
Training loss: 1.4375823736190796
Validation loss: 1.8652546046882548

Epoch: 6| Step: 2
Training loss: 2.1042675971984863
Validation loss: 1.8503776698984125

Epoch: 6| Step: 3
Training loss: 1.647099494934082
Validation loss: 1.8958843049182688

Epoch: 6| Step: 4
Training loss: 1.4048205614089966
Validation loss: 1.8740551599892237

Epoch: 6| Step: 5
Training loss: 1.2032253742218018
Validation loss: 1.9424507797405284

Epoch: 6| Step: 6
Training loss: 2.275447368621826
Validation loss: 1.9096017550396662

Epoch: 6| Step: 7
Training loss: 1.8289387226104736
Validation loss: 1.9400212790376397

Epoch: 6| Step: 8
Training loss: 1.2748034000396729
Validation loss: 1.9232083828218522

Epoch: 6| Step: 9
Training loss: 1.2577908039093018
Validation loss: 1.9092156746054207

Epoch: 6| Step: 10
Training loss: 1.3109195232391357
Validation loss: 1.927840063648839

Epoch: 6| Step: 11
Training loss: 1.4443986415863037
Validation loss: 1.8793140380613265

Epoch: 6| Step: 12
Training loss: 1.3678703308105469
Validation loss: 1.8964878961604128

Epoch: 6| Step: 13
Training loss: 2.594419002532959
Validation loss: 1.8454567232439596

Epoch: 283| Step: 0
Training loss: 1.268364429473877
Validation loss: 1.8907914174500333

Epoch: 6| Step: 1
Training loss: 1.4298865795135498
Validation loss: 1.8709461817177393

Epoch: 6| Step: 2
Training loss: 1.9090220928192139
Validation loss: 1.8930755892107565

Epoch: 6| Step: 3
Training loss: 0.814323902130127
Validation loss: 1.9152186147628292

Epoch: 6| Step: 4
Training loss: 1.1757307052612305
Validation loss: 1.8781920363826137

Epoch: 6| Step: 5
Training loss: 1.8269957304000854
Validation loss: 1.875871830089118

Epoch: 6| Step: 6
Training loss: 2.2101354598999023
Validation loss: 1.8602826467124365

Epoch: 6| Step: 7
Training loss: 1.2716403007507324
Validation loss: 1.9498180984168925

Epoch: 6| Step: 8
Training loss: 2.438601493835449
Validation loss: 1.8725758585878598

Epoch: 6| Step: 9
Training loss: 1.1730263233184814
Validation loss: 1.84733288006116

Epoch: 6| Step: 10
Training loss: 2.3226094245910645
Validation loss: 1.9036800566539969

Epoch: 6| Step: 11
Training loss: 1.2956082820892334
Validation loss: 1.9082726329885504

Epoch: 6| Step: 12
Training loss: 1.6107257604599
Validation loss: 1.868987415426521

Epoch: 6| Step: 13
Training loss: 1.3871458768844604
Validation loss: 1.8774604976818126

Epoch: 284| Step: 0
Training loss: 1.5371525287628174
Validation loss: 1.9082751940655451

Epoch: 6| Step: 1
Training loss: 2.253289222717285
Validation loss: 1.9042582716993106

Epoch: 6| Step: 2
Training loss: 1.8473410606384277
Validation loss: 1.9022759532415738

Epoch: 6| Step: 3
Training loss: 1.4912452697753906
Validation loss: 1.8812551011321366

Epoch: 6| Step: 4
Training loss: 1.7587425708770752
Validation loss: 1.9107200125212311

Epoch: 6| Step: 5
Training loss: 1.7580634355545044
Validation loss: 1.8913019472552883

Epoch: 6| Step: 6
Training loss: 1.5211504697799683
Validation loss: 1.8909220900586856

Epoch: 6| Step: 7
Training loss: 1.527413249015808
Validation loss: 1.89615672890858

Epoch: 6| Step: 8
Training loss: 1.2635537385940552
Validation loss: 1.8967483940944876

Epoch: 6| Step: 9
Training loss: 1.0480573177337646
Validation loss: 1.9255194638365059

Epoch: 6| Step: 10
Training loss: 1.3957980871200562
Validation loss: 1.8964228207065212

Epoch: 6| Step: 11
Training loss: 2.0168371200561523
Validation loss: 1.9155231868067095

Epoch: 6| Step: 12
Training loss: 1.1714088916778564
Validation loss: 1.8541351723414596

Epoch: 6| Step: 13
Training loss: 1.2227016687393188
Validation loss: 1.9330023475872573

Epoch: 285| Step: 0
Training loss: 1.564599633216858
Validation loss: 1.8732100789264967

Epoch: 6| Step: 1
Training loss: 1.542325735092163
Validation loss: 1.8477032812692786

Epoch: 6| Step: 2
Training loss: 1.7524126768112183
Validation loss: 1.8660279268859534

Epoch: 6| Step: 3
Training loss: 1.50700044631958
Validation loss: 1.8464031424573673

Epoch: 6| Step: 4
Training loss: 1.0189400911331177
Validation loss: 1.8919019429914412

Epoch: 6| Step: 5
Training loss: 2.149116039276123
Validation loss: 1.879324197769165

Epoch: 6| Step: 6
Training loss: 1.2611247301101685
Validation loss: 1.8977566406291018

Epoch: 6| Step: 7
Training loss: 1.3035521507263184
Validation loss: 1.8576952783010339

Epoch: 6| Step: 8
Training loss: 1.162805199623108
Validation loss: 1.865237477005169

Epoch: 6| Step: 9
Training loss: 2.3797359466552734
Validation loss: 1.903737627049928

Epoch: 6| Step: 10
Training loss: 1.1571869850158691
Validation loss: 1.9017819255910895

Epoch: 6| Step: 11
Training loss: 2.1673693656921387
Validation loss: 1.9347014657912716

Epoch: 6| Step: 12
Training loss: 1.732234239578247
Validation loss: 1.9417644675059984

Epoch: 6| Step: 13
Training loss: 1.3458120822906494
Validation loss: 1.9298178124171432

Epoch: 286| Step: 0
Training loss: 1.6103535890579224
Validation loss: 1.9033088709718438

Epoch: 6| Step: 1
Training loss: 1.4214293956756592
Validation loss: 1.8309329991699548

Epoch: 6| Step: 2
Training loss: 0.8543184995651245
Validation loss: 1.8908099820536952

Epoch: 6| Step: 3
Training loss: 1.607503890991211
Validation loss: 1.8863903271254672

Epoch: 6| Step: 4
Training loss: 1.7386021614074707
Validation loss: 1.8822724870456162

Epoch: 6| Step: 5
Training loss: 1.9028632640838623
Validation loss: 1.8712275681957122

Epoch: 6| Step: 6
Training loss: 2.133507251739502
Validation loss: 1.8668156439258206

Epoch: 6| Step: 7
Training loss: 1.2846125364303589
Validation loss: 1.8943709173510153

Epoch: 6| Step: 8
Training loss: 1.5559320449829102
Validation loss: 1.901408274968465

Epoch: 6| Step: 9
Training loss: 1.629106879234314
Validation loss: 1.877895744897986

Epoch: 6| Step: 10
Training loss: 1.8112983703613281
Validation loss: 1.8518370620666011

Epoch: 6| Step: 11
Training loss: 2.305844783782959
Validation loss: 1.9162048601335095

Epoch: 6| Step: 12
Training loss: 0.8295583724975586
Validation loss: 1.9104606823254657

Epoch: 6| Step: 13
Training loss: 1.5260653495788574
Validation loss: 1.9103262783378683

Epoch: 287| Step: 0
Training loss: 1.2460474967956543
Validation loss: 1.8664896154916415

Epoch: 6| Step: 1
Training loss: 1.5688564777374268
Validation loss: 1.9443447538601455

Epoch: 6| Step: 2
Training loss: 1.403521180152893
Validation loss: 1.8920999444941038

Epoch: 6| Step: 3
Training loss: 1.670785903930664
Validation loss: 1.9610018178980837

Epoch: 6| Step: 4
Training loss: 1.724783182144165
Validation loss: 1.9355720794329079

Epoch: 6| Step: 5
Training loss: 1.7525885105133057
Validation loss: 1.896161574189381

Epoch: 6| Step: 6
Training loss: 1.208751916885376
Validation loss: 1.9187981467093191

Epoch: 6| Step: 7
Training loss: 1.770805835723877
Validation loss: 1.9080138052663496

Epoch: 6| Step: 8
Training loss: 1.7965036630630493
Validation loss: 1.965413337112755

Epoch: 6| Step: 9
Training loss: 1.573046088218689
Validation loss: 1.8769806418367612

Epoch: 6| Step: 10
Training loss: 1.6771740913391113
Validation loss: 1.8933299984983218

Epoch: 6| Step: 11
Training loss: 1.5501484870910645
Validation loss: 1.9015123036599928

Epoch: 6| Step: 12
Training loss: 1.8358640670776367
Validation loss: 1.8579074631455124

Epoch: 6| Step: 13
Training loss: 0.9979340434074402
Validation loss: 1.8699562190681376

Epoch: 288| Step: 0
Training loss: 1.3385274410247803
Validation loss: 1.8861214813365732

Epoch: 6| Step: 1
Training loss: 1.533621072769165
Validation loss: 1.922654341625911

Epoch: 6| Step: 2
Training loss: 1.6153674125671387
Validation loss: 1.8653381127183155

Epoch: 6| Step: 3
Training loss: 1.5888339281082153
Validation loss: 1.9118467889806277

Epoch: 6| Step: 4
Training loss: 1.5546844005584717
Validation loss: 1.8646456195462136

Epoch: 6| Step: 5
Training loss: 1.4886186122894287
Validation loss: 1.870971106713818

Epoch: 6| Step: 6
Training loss: 1.4135973453521729
Validation loss: 1.874359699987596

Epoch: 6| Step: 7
Training loss: 1.4792205095291138
Validation loss: 1.8900323439669866

Epoch: 6| Step: 8
Training loss: 1.8441128730773926
Validation loss: 1.8658097033859582

Epoch: 6| Step: 9
Training loss: 1.9965884685516357
Validation loss: 1.8836555609139063

Epoch: 6| Step: 10
Training loss: 1.8456556797027588
Validation loss: 1.894679231028403

Epoch: 6| Step: 11
Training loss: 0.8689956665039062
Validation loss: 1.8581445511951242

Epoch: 6| Step: 12
Training loss: 2.212066173553467
Validation loss: 1.911362281409643

Epoch: 6| Step: 13
Training loss: 0.9721076488494873
Validation loss: 1.93509728036901

Epoch: 289| Step: 0
Training loss: 1.9832568168640137
Validation loss: 1.9044869740804036

Epoch: 6| Step: 1
Training loss: 2.056497573852539
Validation loss: 1.9035645531069847

Epoch: 6| Step: 2
Training loss: 1.8252151012420654
Validation loss: 1.8545790026264806

Epoch: 6| Step: 3
Training loss: 1.3257522583007812
Validation loss: 1.8763501567225302

Epoch: 6| Step: 4
Training loss: 1.62794828414917
Validation loss: 1.9176054885310512

Epoch: 6| Step: 5
Training loss: 1.5452462434768677
Validation loss: 1.9177530504042102

Epoch: 6| Step: 6
Training loss: 1.896748661994934
Validation loss: 1.9072679781144666

Epoch: 6| Step: 7
Training loss: 1.246510624885559
Validation loss: 1.9181329537463445

Epoch: 6| Step: 8
Training loss: 1.3882176876068115
Validation loss: 1.9164404202533025

Epoch: 6| Step: 9
Training loss: 1.2439136505126953
Validation loss: 1.9033188666066816

Epoch: 6| Step: 10
Training loss: 1.4922188520431519
Validation loss: 1.9208035635691818

Epoch: 6| Step: 11
Training loss: 1.25958251953125
Validation loss: 1.940687757666393

Epoch: 6| Step: 12
Training loss: 1.2830970287322998
Validation loss: 1.9019871629694456

Epoch: 6| Step: 13
Training loss: 1.526556134223938
Validation loss: 1.8987553734933176

Epoch: 290| Step: 0
Training loss: 1.7112230062484741
Validation loss: 1.932974494913573

Epoch: 6| Step: 1
Training loss: 1.9452006816864014
Validation loss: 1.8797414969372492

Epoch: 6| Step: 2
Training loss: 1.6881217956542969
Validation loss: 1.8964691790201331

Epoch: 6| Step: 3
Training loss: 1.4388208389282227
Validation loss: 1.9425346184802312

Epoch: 6| Step: 4
Training loss: 0.8228769302368164
Validation loss: 1.8777508325474237

Epoch: 6| Step: 5
Training loss: 1.747150182723999
Validation loss: 1.8770383993784587

Epoch: 6| Step: 6
Training loss: 1.0171364545822144
Validation loss: 1.9028385877609253

Epoch: 6| Step: 7
Training loss: 1.8747973442077637
Validation loss: 1.9176309800917102

Epoch: 6| Step: 8
Training loss: 1.6868393421173096
Validation loss: 1.8493922807837044

Epoch: 6| Step: 9
Training loss: 1.4784777164459229
Validation loss: 1.916828922046128

Epoch: 6| Step: 10
Training loss: 2.003676414489746
Validation loss: 1.8685514747455556

Epoch: 6| Step: 11
Training loss: 1.017520785331726
Validation loss: 1.9042814034287647

Epoch: 6| Step: 12
Training loss: 1.606330156326294
Validation loss: 1.9054602756295154

Epoch: 6| Step: 13
Training loss: 1.5109789371490479
Validation loss: 1.9333159064733854

Epoch: 291| Step: 0
Training loss: 1.72637939453125
Validation loss: 1.9138857946600965

Epoch: 6| Step: 1
Training loss: 1.458998441696167
Validation loss: 1.913751550900039

Epoch: 6| Step: 2
Training loss: 1.6363685131072998
Validation loss: 1.887874682744344

Epoch: 6| Step: 3
Training loss: 1.3172118663787842
Validation loss: 1.8899301764785603

Epoch: 6| Step: 4
Training loss: 1.2684271335601807
Validation loss: 1.906325524853122

Epoch: 6| Step: 5
Training loss: 2.0860049724578857
Validation loss: 1.895362405366795

Epoch: 6| Step: 6
Training loss: 1.9984593391418457
Validation loss: 1.861302896212506

Epoch: 6| Step: 7
Training loss: 2.1080191135406494
Validation loss: 1.8827500035685878

Epoch: 6| Step: 8
Training loss: 1.3902473449707031
Validation loss: 1.8988706091398835

Epoch: 6| Step: 9
Training loss: 0.8035446405410767
Validation loss: 1.8940419009936753

Epoch: 6| Step: 10
Training loss: 2.165999412536621
Validation loss: 1.8648467153631232

Epoch: 6| Step: 11
Training loss: 1.1302855014801025
Validation loss: 1.8744136876957391

Epoch: 6| Step: 12
Training loss: 1.2898313999176025
Validation loss: 1.8895176661911832

Epoch: 6| Step: 13
Training loss: 1.3353407382965088
Validation loss: 1.8941798056325605

Epoch: 292| Step: 0
Training loss: 2.015699863433838
Validation loss: 1.918799590038997

Epoch: 6| Step: 1
Training loss: 1.7485084533691406
Validation loss: 1.8432266840370752

Epoch: 6| Step: 2
Training loss: 1.972875952720642
Validation loss: 1.9044808905611756

Epoch: 6| Step: 3
Training loss: 1.7935041189193726
Validation loss: 1.8903674207707888

Epoch: 6| Step: 4
Training loss: 1.7030982971191406
Validation loss: 1.8474974414353729

Epoch: 6| Step: 5
Training loss: 1.4324626922607422
Validation loss: 1.947885597905805

Epoch: 6| Step: 6
Training loss: 1.8763757944107056
Validation loss: 1.9576625606065154

Epoch: 6| Step: 7
Training loss: 1.4200257062911987
Validation loss: 1.9464974429017754

Epoch: 6| Step: 8
Training loss: 1.4219951629638672
Validation loss: 1.9405640440602456

Epoch: 6| Step: 9
Training loss: 1.7649322748184204
Validation loss: 2.0037034326984036

Epoch: 6| Step: 10
Training loss: 1.5249509811401367
Validation loss: 1.9760676545481528

Epoch: 6| Step: 11
Training loss: 0.9858647584915161
Validation loss: 1.9501261352210917

Epoch: 6| Step: 12
Training loss: 1.090261697769165
Validation loss: 1.876478425918087

Epoch: 6| Step: 13
Training loss: 1.3829550743103027
Validation loss: 1.9087472679794475

Epoch: 293| Step: 0
Training loss: 1.0847523212432861
Validation loss: 1.9314984967631679

Epoch: 6| Step: 1
Training loss: 1.4300305843353271
Validation loss: 1.884502681352759

Epoch: 6| Step: 2
Training loss: 1.338738203048706
Validation loss: 1.8736779433424755

Epoch: 6| Step: 3
Training loss: 1.2089061737060547
Validation loss: 1.9273909445731872

Epoch: 6| Step: 4
Training loss: 1.5718638896942139
Validation loss: 1.8721148506287606

Epoch: 6| Step: 5
Training loss: 1.3377575874328613
Validation loss: 1.890108444357431

Epoch: 6| Step: 6
Training loss: 1.8221461772918701
Validation loss: 1.897984771318333

Epoch: 6| Step: 7
Training loss: 1.96803617477417
Validation loss: 1.8549372137233775

Epoch: 6| Step: 8
Training loss: 1.731149435043335
Validation loss: 1.8581403314426381

Epoch: 6| Step: 9
Training loss: 1.2287981510162354
Validation loss: 1.8774395783742268

Epoch: 6| Step: 10
Training loss: 1.7113885879516602
Validation loss: 1.9094913839012064

Epoch: 6| Step: 11
Training loss: 1.7957777976989746
Validation loss: 1.855188064677741

Epoch: 6| Step: 12
Training loss: 2.318312406539917
Validation loss: 1.8742295593343756

Epoch: 6| Step: 13
Training loss: 1.9152861833572388
Validation loss: 1.8157273979597195

Epoch: 294| Step: 0
Training loss: 1.9303845167160034
Validation loss: 1.885097457516578

Epoch: 6| Step: 1
Training loss: 1.9287220239639282
Validation loss: 1.861415861755289

Epoch: 6| Step: 2
Training loss: 1.6571344137191772
Validation loss: 1.9297273235936319

Epoch: 6| Step: 3
Training loss: 1.4551568031311035
Validation loss: 1.948899648522818

Epoch: 6| Step: 4
Training loss: 1.1747924089431763
Validation loss: 1.9091022552982453

Epoch: 6| Step: 5
Training loss: 1.5451030731201172
Validation loss: 1.9279583551550423

Epoch: 6| Step: 6
Training loss: 1.5305092334747314
Validation loss: 1.953369878953503

Epoch: 6| Step: 7
Training loss: 1.1464377641677856
Validation loss: 1.9266282730205084

Epoch: 6| Step: 8
Training loss: 1.318507432937622
Validation loss: 1.947455834316951

Epoch: 6| Step: 9
Training loss: 1.7937407493591309
Validation loss: 1.9501986298509824

Epoch: 6| Step: 10
Training loss: 1.3672518730163574
Validation loss: 1.9150014218463693

Epoch: 6| Step: 11
Training loss: 1.9497425556182861
Validation loss: 1.9717781159185594

Epoch: 6| Step: 12
Training loss: 1.4411087036132812
Validation loss: 1.9213996023260138

Epoch: 6| Step: 13
Training loss: 1.032820224761963
Validation loss: 1.9436313208713327

Epoch: 295| Step: 0
Training loss: 0.8384373188018799
Validation loss: 1.903546089767128

Epoch: 6| Step: 1
Training loss: 1.465557336807251
Validation loss: 1.8869608999580465

Epoch: 6| Step: 2
Training loss: 2.034574270248413
Validation loss: 1.891283332660634

Epoch: 6| Step: 3
Training loss: 1.586087703704834
Validation loss: 1.8732884878753333

Epoch: 6| Step: 4
Training loss: 1.2592182159423828
Validation loss: 1.8925439567976101

Epoch: 6| Step: 5
Training loss: 1.954372763633728
Validation loss: 1.8686525629412742

Epoch: 6| Step: 6
Training loss: 1.4712350368499756
Validation loss: 1.8887124151311896

Epoch: 6| Step: 7
Training loss: 2.6304965019226074
Validation loss: 1.8857886663047216

Epoch: 6| Step: 8
Training loss: 1.168428897857666
Validation loss: 1.8695355153852893

Epoch: 6| Step: 9
Training loss: 1.1298481225967407
Validation loss: 1.9169696466897124

Epoch: 6| Step: 10
Training loss: 1.6194669008255005
Validation loss: 1.8753644138254144

Epoch: 6| Step: 11
Training loss: 1.8948079347610474
Validation loss: 1.901878951698221

Epoch: 6| Step: 12
Training loss: 1.3093843460083008
Validation loss: 1.8670177895535705

Epoch: 6| Step: 13
Training loss: 0.9307323098182678
Validation loss: 1.9326525554862073

Epoch: 296| Step: 0
Training loss: 1.0561902523040771
Validation loss: 1.8929702171715357

Epoch: 6| Step: 1
Training loss: 1.7034797668457031
Validation loss: 1.888121690801395

Epoch: 6| Step: 2
Training loss: 1.388479471206665
Validation loss: 1.8657253685817923

Epoch: 6| Step: 3
Training loss: 1.4043817520141602
Validation loss: 1.9034046126950173

Epoch: 6| Step: 4
Training loss: 1.7806901931762695
Validation loss: 1.9132523023954002

Epoch: 6| Step: 5
Training loss: 1.284790277481079
Validation loss: 1.924366997134301

Epoch: 6| Step: 6
Training loss: 1.8969095945358276
Validation loss: 1.9447108930157078

Epoch: 6| Step: 7
Training loss: 1.2921221256256104
Validation loss: 1.9059138580035138

Epoch: 6| Step: 8
Training loss: 1.721709966659546
Validation loss: 1.9272898345865228

Epoch: 6| Step: 9
Training loss: 1.4279794692993164
Validation loss: 1.9163756139816777

Epoch: 6| Step: 10
Training loss: 1.751176118850708
Validation loss: 1.9453858214039956

Epoch: 6| Step: 11
Training loss: 1.6598854064941406
Validation loss: 1.9160725147493425

Epoch: 6| Step: 12
Training loss: 2.053011417388916
Validation loss: 1.9051113154298516

Epoch: 6| Step: 13
Training loss: 1.47849702835083
Validation loss: 1.9229144883412186

Epoch: 297| Step: 0
Training loss: 1.6894848346710205
Validation loss: 1.872809535713606

Epoch: 6| Step: 1
Training loss: 1.3242497444152832
Validation loss: 1.8918680016712477

Epoch: 6| Step: 2
Training loss: 1.3155262470245361
Validation loss: 1.9082900170356996

Epoch: 6| Step: 3
Training loss: 1.7630016803741455
Validation loss: 1.8884758949279785

Epoch: 6| Step: 4
Training loss: 1.7982022762298584
Validation loss: 1.8790041067266976

Epoch: 6| Step: 5
Training loss: 1.2578606605529785
Validation loss: 1.8516421600054669

Epoch: 6| Step: 6
Training loss: 1.548443078994751
Validation loss: 1.8684499289399834

Epoch: 6| Step: 7
Training loss: 2.048068046569824
Validation loss: 1.896362648215345

Epoch: 6| Step: 8
Training loss: 1.547602891921997
Validation loss: 1.8630566725166895

Epoch: 6| Step: 9
Training loss: 1.4147101640701294
Validation loss: 1.896848132533412

Epoch: 6| Step: 10
Training loss: 1.1976155042648315
Validation loss: 1.924070494149321

Epoch: 6| Step: 11
Training loss: 1.724287986755371
Validation loss: 1.8676397031353367

Epoch: 6| Step: 12
Training loss: 1.7881675958633423
Validation loss: 1.881703939489139

Epoch: 6| Step: 13
Training loss: 1.354962944984436
Validation loss: 1.9106432032841507

Epoch: 298| Step: 0
Training loss: 2.160315990447998
Validation loss: 1.8940262781676425

Epoch: 6| Step: 1
Training loss: 1.3898825645446777
Validation loss: 1.9076262507387387

Epoch: 6| Step: 2
Training loss: 1.601158618927002
Validation loss: 1.9129258176331878

Epoch: 6| Step: 3
Training loss: 1.189727544784546
Validation loss: 1.8663586929280271

Epoch: 6| Step: 4
Training loss: 1.4282927513122559
Validation loss: 1.8938137664589831

Epoch: 6| Step: 5
Training loss: 1.500112771987915
Validation loss: 1.9040344568990892

Epoch: 6| Step: 6
Training loss: 1.0508923530578613
Validation loss: 1.862383484840393

Epoch: 6| Step: 7
Training loss: 0.9692289233207703
Validation loss: 1.9037158296954246

Epoch: 6| Step: 8
Training loss: 1.7051174640655518
Validation loss: 1.8827709459489392

Epoch: 6| Step: 9
Training loss: 1.9320718050003052
Validation loss: 1.8786773656004219

Epoch: 6| Step: 10
Training loss: 1.9812554121017456
Validation loss: 1.8641381571369786

Epoch: 6| Step: 11
Training loss: 1.5835371017456055
Validation loss: 1.8660850576175156

Epoch: 6| Step: 12
Training loss: 1.4577202796936035
Validation loss: 1.9225544314230643

Epoch: 6| Step: 13
Training loss: 1.8766160011291504
Validation loss: 1.8924606871861283

Epoch: 299| Step: 0
Training loss: 1.1272603273391724
Validation loss: 1.9014341895298292

Epoch: 6| Step: 1
Training loss: 1.639617919921875
Validation loss: 1.8490505115960234

Epoch: 6| Step: 2
Training loss: 1.1362963914871216
Validation loss: 1.8288830146994641

Epoch: 6| Step: 3
Training loss: 1.6181182861328125
Validation loss: 1.899535373974872

Epoch: 6| Step: 4
Training loss: 2.014986038208008
Validation loss: 1.8898485232424993

Epoch: 6| Step: 5
Training loss: 2.1248836517333984
Validation loss: 1.8604855716869395

Epoch: 6| Step: 6
Training loss: 1.9496033191680908
Validation loss: 1.8233797601474229

Epoch: 6| Step: 7
Training loss: 1.180145025253296
Validation loss: 1.8671229013832666

Epoch: 6| Step: 8
Training loss: 1.4395097494125366
Validation loss: 1.8808756207907071

Epoch: 6| Step: 9
Training loss: 0.8719601631164551
Validation loss: 1.8829799313699045

Epoch: 6| Step: 10
Training loss: 1.606374740600586
Validation loss: 1.784066915512085

Epoch: 6| Step: 11
Training loss: 1.5286237001419067
Validation loss: 1.8712001513409358

Epoch: 6| Step: 12
Training loss: 1.6866306066513062
Validation loss: 1.862102247053577

Epoch: 6| Step: 13
Training loss: 1.4087486267089844
Validation loss: 1.887353882994703

Epoch: 300| Step: 0
Training loss: 1.761400818824768
Validation loss: 1.894814714308708

Epoch: 6| Step: 1
Training loss: 1.4820654392242432
Validation loss: 1.8799340058398504

Epoch: 6| Step: 2
Training loss: 1.0468140840530396
Validation loss: 1.8768207642339891

Epoch: 6| Step: 3
Training loss: 2.09627103805542
Validation loss: 1.832618462142124

Epoch: 6| Step: 4
Training loss: 1.7113984823226929
Validation loss: 1.8817421954165223

Epoch: 6| Step: 5
Training loss: 1.8082916736602783
Validation loss: 1.9086231672635643

Epoch: 6| Step: 6
Training loss: 0.5465453863143921
Validation loss: 1.8799368104627054

Epoch: 6| Step: 7
Training loss: 1.1803474426269531
Validation loss: 1.8481878888222478

Epoch: 6| Step: 8
Training loss: 1.6515882015228271
Validation loss: 1.8763235768964213

Epoch: 6| Step: 9
Training loss: 1.6743693351745605
Validation loss: 1.8872766007659256

Epoch: 6| Step: 10
Training loss: 1.6943553686141968
Validation loss: 1.9001821676890056

Epoch: 6| Step: 11
Training loss: 1.8256964683532715
Validation loss: 1.9029074330483713

Epoch: 6| Step: 12
Training loss: 1.830811858177185
Validation loss: 1.8755476859308058

Epoch: 6| Step: 13
Training loss: 1.0888234376907349
Validation loss: 1.9153310137410318

Epoch: 301| Step: 0
Training loss: 1.6000339984893799
Validation loss: 1.876767175171965

Epoch: 6| Step: 1
Training loss: 1.5319178104400635
Validation loss: 1.896774645774595

Epoch: 6| Step: 2
Training loss: 1.4836580753326416
Validation loss: 1.9157326657284972

Epoch: 6| Step: 3
Training loss: 1.1964178085327148
Validation loss: 1.9385983764484365

Epoch: 6| Step: 4
Training loss: 1.714626669883728
Validation loss: 1.8746343222997521

Epoch: 6| Step: 5
Training loss: 1.4806199073791504
Validation loss: 1.9016529372943345

Epoch: 6| Step: 6
Training loss: 1.0861842632293701
Validation loss: 1.8670933964431926

Epoch: 6| Step: 7
Training loss: 1.2052054405212402
Validation loss: 1.931951565127219

Epoch: 6| Step: 8
Training loss: 2.365927219390869
Validation loss: 1.8636365757193616

Epoch: 6| Step: 9
Training loss: 1.9190747737884521
Validation loss: 1.9016245219015306

Epoch: 6| Step: 10
Training loss: 1.336388111114502
Validation loss: 1.890858962971677

Epoch: 6| Step: 11
Training loss: 1.4485838413238525
Validation loss: 1.9273279507954915

Epoch: 6| Step: 12
Training loss: 1.1735212802886963
Validation loss: 1.9107658875885831

Epoch: 6| Step: 13
Training loss: 1.8569722175598145
Validation loss: 1.9218894627786451

Epoch: 302| Step: 0
Training loss: 2.2816896438598633
Validation loss: 1.8537653248797181

Epoch: 6| Step: 1
Training loss: 2.1132709980010986
Validation loss: 1.8875625697515344

Epoch: 6| Step: 2
Training loss: 1.504958987236023
Validation loss: 1.8612888756618704

Epoch: 6| Step: 3
Training loss: 1.5477993488311768
Validation loss: 1.868673422003305

Epoch: 6| Step: 4
Training loss: 1.380109429359436
Validation loss: 1.870482385799449

Epoch: 6| Step: 5
Training loss: 1.2148057222366333
Validation loss: 1.8714886326943674

Epoch: 6| Step: 6
Training loss: 1.5974675416946411
Validation loss: 1.8563554312593193

Epoch: 6| Step: 7
Training loss: 1.1868226528167725
Validation loss: 1.902818024799388

Epoch: 6| Step: 8
Training loss: 1.0750850439071655
Validation loss: 1.8916294728555987

Epoch: 6| Step: 9
Training loss: 1.871936321258545
Validation loss: 1.9410340452706942

Epoch: 6| Step: 10
Training loss: 1.1800998449325562
Validation loss: 1.9392136412282144

Epoch: 6| Step: 11
Training loss: 1.2681580781936646
Validation loss: 1.8965982378170054

Epoch: 6| Step: 12
Training loss: 1.6685516834259033
Validation loss: 1.8802544186192174

Epoch: 6| Step: 13
Training loss: 1.4610083103179932
Validation loss: 1.8546015293367448

Epoch: 303| Step: 0
Training loss: 1.390254020690918
Validation loss: 1.8887611999306628

Epoch: 6| Step: 1
Training loss: 0.6272792220115662
Validation loss: 1.8861871816778695

Epoch: 6| Step: 2
Training loss: 1.884124755859375
Validation loss: 1.8983055750528972

Epoch: 6| Step: 3
Training loss: 2.0090126991271973
Validation loss: 1.944849088627805

Epoch: 6| Step: 4
Training loss: 1.126491904258728
Validation loss: 1.913701085634129

Epoch: 6| Step: 5
Training loss: 1.6358411312103271
Validation loss: 1.8614932593478952

Epoch: 6| Step: 6
Training loss: 1.759382963180542
Validation loss: 1.9011306967786563

Epoch: 6| Step: 7
Training loss: 0.6656501293182373
Validation loss: 1.9082750658835135

Epoch: 6| Step: 8
Training loss: 1.7940330505371094
Validation loss: 1.9174016944823726

Epoch: 6| Step: 9
Training loss: 1.541527271270752
Validation loss: 1.8802393854305308

Epoch: 6| Step: 10
Training loss: 1.5766488313674927
Validation loss: 1.9390064580466158

Epoch: 6| Step: 11
Training loss: 1.4753856658935547
Validation loss: 1.911679853675186

Epoch: 6| Step: 12
Training loss: 1.7300727367401123
Validation loss: 1.8791984870869627

Epoch: 6| Step: 13
Training loss: 2.496523857116699
Validation loss: 1.897473762112279

Epoch: 304| Step: 0
Training loss: 0.8041516542434692
Validation loss: 1.8463557035692277

Epoch: 6| Step: 1
Training loss: 1.846980333328247
Validation loss: 1.9087263102172523

Epoch: 6| Step: 2
Training loss: 0.8342703580856323
Validation loss: 1.8798537177424277

Epoch: 6| Step: 3
Training loss: 1.706627368927002
Validation loss: 1.9367636390911636

Epoch: 6| Step: 4
Training loss: 1.4392192363739014
Validation loss: 1.8784810086732269

Epoch: 6| Step: 5
Training loss: 1.1099238395690918
Validation loss: 1.8884148623353691

Epoch: 6| Step: 6
Training loss: 2.03589129447937
Validation loss: 1.9019305449660107

Epoch: 6| Step: 7
Training loss: 1.722035527229309
Validation loss: 1.9247776923641082

Epoch: 6| Step: 8
Training loss: 1.956985592842102
Validation loss: 1.9171571449566913

Epoch: 6| Step: 9
Training loss: 2.4444644451141357
Validation loss: 1.8986666766546105

Epoch: 6| Step: 10
Training loss: 0.7247544527053833
Validation loss: 1.9223183995933943

Epoch: 6| Step: 11
Training loss: 1.7514257431030273
Validation loss: 1.8928958946658718

Epoch: 6| Step: 12
Training loss: 1.581777572631836
Validation loss: 1.88675788012884

Epoch: 6| Step: 13
Training loss: 1.2141914367675781
Validation loss: 1.8982969227657522

Epoch: 305| Step: 0
Training loss: 1.3862383365631104
Validation loss: 1.8780902495948217

Epoch: 6| Step: 1
Training loss: 1.4415290355682373
Validation loss: 1.8818655449856994

Epoch: 6| Step: 2
Training loss: 0.8851768970489502
Validation loss: 1.909370118571866

Epoch: 6| Step: 3
Training loss: 1.6647911071777344
Validation loss: 1.8838415120237617

Epoch: 6| Step: 4
Training loss: 1.4769892692565918
Validation loss: 1.9030889362417243

Epoch: 6| Step: 5
Training loss: 1.495025873184204
Validation loss: 1.8271669674945135

Epoch: 6| Step: 6
Training loss: 1.7342190742492676
Validation loss: 1.813620105866463

Epoch: 6| Step: 7
Training loss: 2.0611112117767334
Validation loss: 1.8839726242967831

Epoch: 6| Step: 8
Training loss: 1.1368331909179688
Validation loss: 1.8287971801655267

Epoch: 6| Step: 9
Training loss: 1.2488627433776855
Validation loss: 1.8675396134776454

Epoch: 6| Step: 10
Training loss: 1.6259307861328125
Validation loss: 1.865249240270225

Epoch: 6| Step: 11
Training loss: 1.7503221035003662
Validation loss: 1.876732005867907

Epoch: 6| Step: 12
Training loss: 1.763088345527649
Validation loss: 1.8977759102339387

Epoch: 6| Step: 13
Training loss: 1.334608554840088
Validation loss: 1.9061073244258921

Epoch: 306| Step: 0
Training loss: 1.9781818389892578
Validation loss: 1.8607641279056508

Epoch: 6| Step: 1
Training loss: 1.7077916860580444
Validation loss: 1.8594986969424832

Epoch: 6| Step: 2
Training loss: 1.2427937984466553
Validation loss: 1.8646009352899366

Epoch: 6| Step: 3
Training loss: 1.7305903434753418
Validation loss: 1.9024351694250619

Epoch: 6| Step: 4
Training loss: 1.692570686340332
Validation loss: 1.861438118001466

Epoch: 6| Step: 5
Training loss: 1.398437738418579
Validation loss: 1.9106481357287335

Epoch: 6| Step: 6
Training loss: 1.431680679321289
Validation loss: 1.9054842687422229

Epoch: 6| Step: 7
Training loss: 1.6640301942825317
Validation loss: 1.9124907165445306

Epoch: 6| Step: 8
Training loss: 1.1866161823272705
Validation loss: 1.9321298855607227

Epoch: 6| Step: 9
Training loss: 1.3887909650802612
Validation loss: 1.9783131653262722

Epoch: 6| Step: 10
Training loss: 1.8527783155441284
Validation loss: 1.8911166857647639

Epoch: 6| Step: 11
Training loss: 0.848682165145874
Validation loss: 1.9648040891975485

Epoch: 6| Step: 12
Training loss: 1.6256303787231445
Validation loss: 1.9223717310095345

Epoch: 6| Step: 13
Training loss: 1.2735720872879028
Validation loss: 1.910439411799113

Epoch: 307| Step: 0
Training loss: 1.4138643741607666
Validation loss: 1.9103333629587644

Epoch: 6| Step: 1
Training loss: 1.2698898315429688
Validation loss: 1.877814882545061

Epoch: 6| Step: 2
Training loss: 1.5112526416778564
Validation loss: 1.8878055503291469

Epoch: 6| Step: 3
Training loss: 1.5039570331573486
Validation loss: 1.9162786135109522

Epoch: 6| Step: 4
Training loss: 1.5055967569351196
Validation loss: 1.866783998345816

Epoch: 6| Step: 5
Training loss: 1.3609843254089355
Validation loss: 1.9272295710861043

Epoch: 6| Step: 6
Training loss: 1.6149671077728271
Validation loss: 1.8926076395537264

Epoch: 6| Step: 7
Training loss: 0.6831512451171875
Validation loss: 1.8890026448875346

Epoch: 6| Step: 8
Training loss: 1.7758022546768188
Validation loss: 1.910031667319677

Epoch: 6| Step: 9
Training loss: 1.6598169803619385
Validation loss: 1.8941209687981555

Epoch: 6| Step: 10
Training loss: 1.8400449752807617
Validation loss: 1.9079499219053535

Epoch: 6| Step: 11
Training loss: 1.590686559677124
Validation loss: 1.9024286654687697

Epoch: 6| Step: 12
Training loss: 1.9430913925170898
Validation loss: 1.901891194364076

Epoch: 6| Step: 13
Training loss: 1.6184250116348267
Validation loss: 1.8866938083402571

Epoch: 308| Step: 0
Training loss: 1.7858550548553467
Validation loss: 1.9036495326667704

Epoch: 6| Step: 1
Training loss: 1.4736967086791992
Validation loss: 1.8748959905357772

Epoch: 6| Step: 2
Training loss: 1.6454110145568848
Validation loss: 1.89584429289705

Epoch: 6| Step: 3
Training loss: 1.3197574615478516
Validation loss: 1.952434003994029

Epoch: 6| Step: 4
Training loss: 1.726374864578247
Validation loss: 1.8826355485505955

Epoch: 6| Step: 5
Training loss: 1.3826910257339478
Validation loss: 1.8973003125959826

Epoch: 6| Step: 6
Training loss: 2.3115196228027344
Validation loss: 1.8952523969834851

Epoch: 6| Step: 7
Training loss: 1.3754940032958984
Validation loss: 1.951917617551742

Epoch: 6| Step: 8
Training loss: 1.5184643268585205
Validation loss: 1.911646241782814

Epoch: 6| Step: 9
Training loss: 1.6670830249786377
Validation loss: 1.9265629347934519

Epoch: 6| Step: 10
Training loss: 1.2965631484985352
Validation loss: 1.8786904106857956

Epoch: 6| Step: 11
Training loss: 1.2593727111816406
Validation loss: 1.8809975424120504

Epoch: 6| Step: 12
Training loss: 1.241807460784912
Validation loss: 1.8929501784745084

Epoch: 6| Step: 13
Training loss: 1.077693223953247
Validation loss: 1.881685100575929

Epoch: 309| Step: 0
Training loss: 1.2794439792633057
Validation loss: 1.8744660680012037

Epoch: 6| Step: 1
Training loss: 1.9217438697814941
Validation loss: 1.8765238126118977

Epoch: 6| Step: 2
Training loss: 1.1223770380020142
Validation loss: 1.864589686034828

Epoch: 6| Step: 3
Training loss: 0.839097261428833
Validation loss: 1.910009499519102

Epoch: 6| Step: 4
Training loss: 1.8316030502319336
Validation loss: 1.9221745075718049

Epoch: 6| Step: 5
Training loss: 1.886132001876831
Validation loss: 1.9104330232066493

Epoch: 6| Step: 6
Training loss: 1.696009874343872
Validation loss: 1.8838548301368632

Epoch: 6| Step: 7
Training loss: 1.4998396635055542
Validation loss: 1.8860559630137619

Epoch: 6| Step: 8
Training loss: 1.7604936361312866
Validation loss: 1.8690382152475336

Epoch: 6| Step: 9
Training loss: 1.4313275814056396
Validation loss: 1.8467394485268542

Epoch: 6| Step: 10
Training loss: 1.4747393131256104
Validation loss: 1.853466820973222

Epoch: 6| Step: 11
Training loss: 1.8910940885543823
Validation loss: 1.8996851572426416

Epoch: 6| Step: 12
Training loss: 1.1250264644622803
Validation loss: 1.928975626986514

Epoch: 6| Step: 13
Training loss: 1.6544755697250366
Validation loss: 1.892793934832337

Epoch: 310| Step: 0
Training loss: 1.4359922409057617
Validation loss: 1.8601085139859108

Epoch: 6| Step: 1
Training loss: 1.5518462657928467
Validation loss: 1.90657082808915

Epoch: 6| Step: 2
Training loss: 2.1652731895446777
Validation loss: 1.876051181106157

Epoch: 6| Step: 3
Training loss: 1.358565330505371
Validation loss: 1.8807225227355957

Epoch: 6| Step: 4
Training loss: 0.9840252995491028
Validation loss: 1.883261715212176

Epoch: 6| Step: 5
Training loss: 1.304678201675415
Validation loss: 1.9009429485567155

Epoch: 6| Step: 6
Training loss: 1.7252564430236816
Validation loss: 1.9277311371218773

Epoch: 6| Step: 7
Training loss: 0.8747291564941406
Validation loss: 1.9036313731183288

Epoch: 6| Step: 8
Training loss: 1.7248647212982178
Validation loss: 1.887578095159223

Epoch: 6| Step: 9
Training loss: 2.178053379058838
Validation loss: 1.9018504683689406

Epoch: 6| Step: 10
Training loss: 1.7771064043045044
Validation loss: 1.8630380515129334

Epoch: 6| Step: 11
Training loss: 1.581653356552124
Validation loss: 1.9008793600143925

Epoch: 6| Step: 12
Training loss: 1.3169608116149902
Validation loss: 1.857802314143027

Epoch: 6| Step: 13
Training loss: 0.5239644646644592
Validation loss: 1.8436981170408187

Epoch: 311| Step: 0
Training loss: 1.2525559663772583
Validation loss: 1.8897148896289129

Epoch: 6| Step: 1
Training loss: 1.6068124771118164
Validation loss: 1.9283013574538692

Epoch: 6| Step: 2
Training loss: 1.8581111431121826
Validation loss: 1.8733643895836287

Epoch: 6| Step: 3
Training loss: 1.5511900186538696
Validation loss: 1.9134788154273905

Epoch: 6| Step: 4
Training loss: 1.4226793050765991
Validation loss: 1.8993420498345488

Epoch: 6| Step: 5
Training loss: 2.1111276149749756
Validation loss: 1.834812270697727

Epoch: 6| Step: 6
Training loss: 1.1834251880645752
Validation loss: 1.8823268644271358

Epoch: 6| Step: 7
Training loss: 0.9332637786865234
Validation loss: 1.859881240834472

Epoch: 6| Step: 8
Training loss: 1.2832188606262207
Validation loss: 1.8415279516609766

Epoch: 6| Step: 9
Training loss: 1.796074390411377
Validation loss: 1.8901963836403304

Epoch: 6| Step: 10
Training loss: 1.3646880388259888
Validation loss: 1.888322171344552

Epoch: 6| Step: 11
Training loss: 1.5965040922164917
Validation loss: 1.9055252408468595

Epoch: 6| Step: 12
Training loss: 2.028320550918579
Validation loss: 2.0039147676960116

Epoch: 6| Step: 13
Training loss: 1.1029224395751953
Validation loss: 1.913891548751503

Epoch: 312| Step: 0
Training loss: 1.1020164489746094
Validation loss: 1.9647574117106776

Epoch: 6| Step: 1
Training loss: 2.085315227508545
Validation loss: 1.926526625951131

Epoch: 6| Step: 2
Training loss: 1.313568115234375
Validation loss: 1.9131435783960486

Epoch: 6| Step: 3
Training loss: 1.009792447090149
Validation loss: 1.9170636784645818

Epoch: 6| Step: 4
Training loss: 1.6109997034072876
Validation loss: 1.8996903845058974

Epoch: 6| Step: 5
Training loss: 1.2713865041732788
Validation loss: 1.9312761637472338

Epoch: 6| Step: 6
Training loss: 1.9418690204620361
Validation loss: 1.9120861740522488

Epoch: 6| Step: 7
Training loss: 1.3198671340942383
Validation loss: 1.9101419525761758

Epoch: 6| Step: 8
Training loss: 0.798423707485199
Validation loss: 1.9212917820099862

Epoch: 6| Step: 9
Training loss: 1.322110891342163
Validation loss: 1.8944410239496539

Epoch: 6| Step: 10
Training loss: 2.0587611198425293
Validation loss: 1.8516474513597385

Epoch: 6| Step: 11
Training loss: 1.583470106124878
Validation loss: 1.8669817319480322

Epoch: 6| Step: 12
Training loss: 1.5428078174591064
Validation loss: 1.9124546525298909

Epoch: 6| Step: 13
Training loss: 2.5436317920684814
Validation loss: 1.8877051748255247

Epoch: 313| Step: 0
Training loss: 1.288170337677002
Validation loss: 1.875326430925759

Epoch: 6| Step: 1
Training loss: 1.7659671306610107
Validation loss: 1.8692612596737441

Epoch: 6| Step: 2
Training loss: 2.023298740386963
Validation loss: 1.8884041847721222

Epoch: 6| Step: 3
Training loss: 1.2691974639892578
Validation loss: 1.896252893632458

Epoch: 6| Step: 4
Training loss: 1.4435553550720215
Validation loss: 1.907215097899078

Epoch: 6| Step: 5
Training loss: 1.9267401695251465
Validation loss: 1.8907243731201335

Epoch: 6| Step: 6
Training loss: 1.549316167831421
Validation loss: 1.8734403784557054

Epoch: 6| Step: 7
Training loss: 0.690554141998291
Validation loss: 1.870286342918232

Epoch: 6| Step: 8
Training loss: 2.116065740585327
Validation loss: 1.8837418171667284

Epoch: 6| Step: 9
Training loss: 1.5504759550094604
Validation loss: 1.8841911708154986

Epoch: 6| Step: 10
Training loss: 1.2209275960922241
Validation loss: 1.9016274547064176

Epoch: 6| Step: 11
Training loss: 1.165801763534546
Validation loss: 1.9113608137253792

Epoch: 6| Step: 12
Training loss: 1.2974787950515747
Validation loss: 1.9045094033723236

Epoch: 6| Step: 13
Training loss: 2.2096738815307617
Validation loss: 1.8800380358131983

Epoch: 314| Step: 0
Training loss: 1.2658718824386597
Validation loss: 1.9136185428147674

Epoch: 6| Step: 1
Training loss: 1.452385663986206
Validation loss: 1.8707809832788282

Epoch: 6| Step: 2
Training loss: 1.5774905681610107
Validation loss: 1.8901023531472811

Epoch: 6| Step: 3
Training loss: 1.9887018203735352
Validation loss: 1.8754964361908615

Epoch: 6| Step: 4
Training loss: 1.6672487258911133
Validation loss: 1.8573441998932951

Epoch: 6| Step: 5
Training loss: 1.9106924533843994
Validation loss: 1.869151867846007

Epoch: 6| Step: 6
Training loss: 0.8521357178688049
Validation loss: 1.8913454791550994

Epoch: 6| Step: 7
Training loss: 1.3834644556045532
Validation loss: 1.8619029573214951

Epoch: 6| Step: 8
Training loss: 1.0247397422790527
Validation loss: 1.937165843543186

Epoch: 6| Step: 9
Training loss: 1.296334981918335
Validation loss: 1.9141103734252274

Epoch: 6| Step: 10
Training loss: 2.311371088027954
Validation loss: 1.8795339792005477

Epoch: 6| Step: 11
Training loss: 1.34861159324646
Validation loss: 1.865144165613318

Epoch: 6| Step: 12
Training loss: 1.5607529878616333
Validation loss: 1.87851188067467

Epoch: 6| Step: 13
Training loss: 0.7746661901473999
Validation loss: 1.8435157499005717

Epoch: 315| Step: 0
Training loss: 1.6106390953063965
Validation loss: 1.8299651171571465

Epoch: 6| Step: 1
Training loss: 1.5496776103973389
Validation loss: 1.860938415732435

Epoch: 6| Step: 2
Training loss: 1.352732539176941
Validation loss: 1.8828372006775231

Epoch: 6| Step: 3
Training loss: 1.8834282159805298
Validation loss: 1.907053170665618

Epoch: 6| Step: 4
Training loss: 1.5192813873291016
Validation loss: 1.8470412364570044

Epoch: 6| Step: 5
Training loss: 1.0995573997497559
Validation loss: 1.9169497361747168

Epoch: 6| Step: 6
Training loss: 1.3891099691390991
Validation loss: 1.8769124489958569

Epoch: 6| Step: 7
Training loss: 1.9859238862991333
Validation loss: 1.8875835198228077

Epoch: 6| Step: 8
Training loss: 1.672288179397583
Validation loss: 1.8526668779311641

Epoch: 6| Step: 9
Training loss: 1.404820203781128
Validation loss: 1.9318719064035723

Epoch: 6| Step: 10
Training loss: 1.357715129852295
Validation loss: 1.866473952929179

Epoch: 6| Step: 11
Training loss: 1.3711165189743042
Validation loss: 1.8944216338537072

Epoch: 6| Step: 12
Training loss: 1.1639349460601807
Validation loss: 1.909626437771705

Epoch: 6| Step: 13
Training loss: 1.6634116172790527
Validation loss: 1.899863491776169

Epoch: 316| Step: 0
Training loss: 1.2513422966003418
Validation loss: 1.9125493418785833

Epoch: 6| Step: 1
Training loss: 1.2854454517364502
Validation loss: 1.9127236245780863

Epoch: 6| Step: 2
Training loss: 1.5211750268936157
Validation loss: 1.9508803198414464

Epoch: 6| Step: 3
Training loss: 1.1261686086654663
Validation loss: 1.9022031971203384

Epoch: 6| Step: 4
Training loss: 1.510662317276001
Validation loss: 1.884283547760338

Epoch: 6| Step: 5
Training loss: 2.166304111480713
Validation loss: 1.91780549223705

Epoch: 6| Step: 6
Training loss: 0.9336223602294922
Validation loss: 1.9416426099756712

Epoch: 6| Step: 7
Training loss: 1.8665239810943604
Validation loss: 1.899953705008312

Epoch: 6| Step: 8
Training loss: 1.3770053386688232
Validation loss: 1.8987244329144877

Epoch: 6| Step: 9
Training loss: 1.3730182647705078
Validation loss: 1.9330388602390085

Epoch: 6| Step: 10
Training loss: 1.485669493675232
Validation loss: 1.877443830172221

Epoch: 6| Step: 11
Training loss: 1.5647284984588623
Validation loss: 1.8700575085096462

Epoch: 6| Step: 12
Training loss: 1.706443190574646
Validation loss: 1.8823597123545985

Epoch: 6| Step: 13
Training loss: 1.757779836654663
Validation loss: 1.8494979527688795

Epoch: 317| Step: 0
Training loss: 1.4389386177062988
Validation loss: 1.906519720631261

Epoch: 6| Step: 1
Training loss: 1.6866209506988525
Validation loss: 1.8901603273166123

Epoch: 6| Step: 2
Training loss: 1.1506719589233398
Validation loss: 1.8867196280469176

Epoch: 6| Step: 3
Training loss: 1.0878597497940063
Validation loss: 1.9054075184688772

Epoch: 6| Step: 4
Training loss: 1.4526234865188599
Validation loss: 1.8732247301327285

Epoch: 6| Step: 5
Training loss: 0.822595477104187
Validation loss: 1.8430069133799563

Epoch: 6| Step: 6
Training loss: 1.7105931043624878
Validation loss: 1.9328114781328427

Epoch: 6| Step: 7
Training loss: 1.9400274753570557
Validation loss: 1.9070189716995403

Epoch: 6| Step: 8
Training loss: 1.4364323616027832
Validation loss: 1.921608635174331

Epoch: 6| Step: 9
Training loss: 1.8529298305511475
Validation loss: 1.8979242719629759

Epoch: 6| Step: 10
Training loss: 1.9968065023422241
Validation loss: 1.894601857790383

Epoch: 6| Step: 11
Training loss: 1.763277292251587
Validation loss: 1.9136136347247708

Epoch: 6| Step: 12
Training loss: 1.3079957962036133
Validation loss: 1.9034370145490092

Epoch: 6| Step: 13
Training loss: 1.2661828994750977
Validation loss: 1.8854031767896426

Epoch: 318| Step: 0
Training loss: 1.3900302648544312
Validation loss: 1.8356450129580755

Epoch: 6| Step: 1
Training loss: 1.6338207721710205
Validation loss: 1.8850879669189453

Epoch: 6| Step: 2
Training loss: 1.1457446813583374
Validation loss: 1.8717001535559212

Epoch: 6| Step: 3
Training loss: 1.269352912902832
Validation loss: 1.90045331370446

Epoch: 6| Step: 4
Training loss: 1.7859740257263184
Validation loss: 1.8735312441343903

Epoch: 6| Step: 5
Training loss: 1.2122318744659424
Validation loss: 1.8959907998320877

Epoch: 6| Step: 6
Training loss: 1.5133413076400757
Validation loss: 1.921449347208905

Epoch: 6| Step: 7
Training loss: 1.9326175451278687
Validation loss: 1.9342572483965146

Epoch: 6| Step: 8
Training loss: 1.5134313106536865
Validation loss: 1.898517785533782

Epoch: 6| Step: 9
Training loss: 1.170733094215393
Validation loss: 1.8955380455140145

Epoch: 6| Step: 10
Training loss: 1.4165802001953125
Validation loss: 1.8641574921146515

Epoch: 6| Step: 11
Training loss: 1.3609033823013306
Validation loss: 1.8629620203407862

Epoch: 6| Step: 12
Training loss: 1.4534039497375488
Validation loss: 1.8713555669271817

Epoch: 6| Step: 13
Training loss: 2.533884286880493
Validation loss: 1.9099197413331719

Epoch: 319| Step: 0
Training loss: 1.563920259475708
Validation loss: 1.906140955545569

Epoch: 6| Step: 1
Training loss: 1.3802659511566162
Validation loss: 1.9029348127303585

Epoch: 6| Step: 2
Training loss: 1.8589389324188232
Validation loss: 1.8571709458545973

Epoch: 6| Step: 3
Training loss: 0.889411449432373
Validation loss: 1.9341719573543918

Epoch: 6| Step: 4
Training loss: 1.2163279056549072
Validation loss: 1.8919403142826532

Epoch: 6| Step: 5
Training loss: 2.1741886138916016
Validation loss: 1.9007075448190012

Epoch: 6| Step: 6
Training loss: 1.3576459884643555
Validation loss: 1.892067591349284

Epoch: 6| Step: 7
Training loss: 1.1645395755767822
Validation loss: 1.884550602205338

Epoch: 6| Step: 8
Training loss: 2.109062671661377
Validation loss: 1.9106045076923985

Epoch: 6| Step: 9
Training loss: 1.8817927837371826
Validation loss: 1.9046831002799414

Epoch: 6| Step: 10
Training loss: 1.0291495323181152
Validation loss: 1.895144045993846

Epoch: 6| Step: 11
Training loss: 1.6402790546417236
Validation loss: 1.852463840156473

Epoch: 6| Step: 12
Training loss: 1.180647373199463
Validation loss: 1.876898915536942

Epoch: 6| Step: 13
Training loss: 1.4636584520339966
Validation loss: 1.932554773105088

Epoch: 320| Step: 0
Training loss: 1.6797113418579102
Validation loss: 1.8601995693740023

Epoch: 6| Step: 1
Training loss: 1.2561314105987549
Validation loss: 1.841633096818001

Epoch: 6| Step: 2
Training loss: 1.4028466939926147
Validation loss: 1.8666131650247881

Epoch: 6| Step: 3
Training loss: 1.9084229469299316
Validation loss: 1.8525897315753403

Epoch: 6| Step: 4
Training loss: 1.390625
Validation loss: 1.8427286019889257

Epoch: 6| Step: 5
Training loss: 1.3461873531341553
Validation loss: 1.8440037004409298

Epoch: 6| Step: 6
Training loss: 1.236710786819458
Validation loss: 1.8680697794883483

Epoch: 6| Step: 7
Training loss: 1.2868696451187134
Validation loss: 1.8596175024586339

Epoch: 6| Step: 8
Training loss: 1.1147973537445068
Validation loss: 1.8854696686549852

Epoch: 6| Step: 9
Training loss: 2.4340014457702637
Validation loss: 1.8791919792852094

Epoch: 6| Step: 10
Training loss: 1.4083077907562256
Validation loss: 1.8759275354364866

Epoch: 6| Step: 11
Training loss: 1.5904953479766846
Validation loss: 1.8964651374406711

Epoch: 6| Step: 12
Training loss: 1.467123031616211
Validation loss: 1.9198565342093026

Epoch: 6| Step: 13
Training loss: 1.1916130781173706
Validation loss: 1.9018016156329904

Epoch: 321| Step: 0
Training loss: 1.0453522205352783
Validation loss: 1.9086594350876347

Epoch: 6| Step: 1
Training loss: 1.4600684642791748
Validation loss: 1.9245537186181674

Epoch: 6| Step: 2
Training loss: 2.097683906555176
Validation loss: 1.8887541768371419

Epoch: 6| Step: 3
Training loss: 1.4422320127487183
Validation loss: 1.904072159080095

Epoch: 6| Step: 4
Training loss: 0.8957403898239136
Validation loss: 1.9156049246429114

Epoch: 6| Step: 5
Training loss: 1.6840797662734985
Validation loss: 1.9272212289994763

Epoch: 6| Step: 6
Training loss: 1.4435107707977295
Validation loss: 1.9514498428631855

Epoch: 6| Step: 7
Training loss: 1.7030489444732666
Validation loss: 1.9047825849184425

Epoch: 6| Step: 8
Training loss: 1.856682538986206
Validation loss: 1.856930842963598

Epoch: 6| Step: 9
Training loss: 1.4198838472366333
Validation loss: 1.8605813313555974

Epoch: 6| Step: 10
Training loss: 1.1820414066314697
Validation loss: 1.91388613177884

Epoch: 6| Step: 11
Training loss: 1.3813276290893555
Validation loss: 1.899027423192096

Epoch: 6| Step: 12
Training loss: 1.5344254970550537
Validation loss: 1.8698165250080887

Epoch: 6| Step: 13
Training loss: 1.6190829277038574
Validation loss: 1.8696014112041843

Epoch: 322| Step: 0
Training loss: 1.9118634462356567
Validation loss: 1.8864646278401858

Epoch: 6| Step: 1
Training loss: 1.7136355638504028
Validation loss: 1.8685811258131457

Epoch: 6| Step: 2
Training loss: 1.3413313627243042
Validation loss: 1.8852369464853758

Epoch: 6| Step: 3
Training loss: 2.0359644889831543
Validation loss: 1.8800421120018087

Epoch: 6| Step: 4
Training loss: 0.9094930291175842
Validation loss: 1.9254211200180875

Epoch: 6| Step: 5
Training loss: 1.144737720489502
Validation loss: 1.9109922045020646

Epoch: 6| Step: 6
Training loss: 1.2526416778564453
Validation loss: 1.9269977513179983

Epoch: 6| Step: 7
Training loss: 1.8527050018310547
Validation loss: 1.9274035141032229

Epoch: 6| Step: 8
Training loss: 1.216698169708252
Validation loss: 1.9059171612544725

Epoch: 6| Step: 9
Training loss: 1.2670001983642578
Validation loss: 1.8738213533996253

Epoch: 6| Step: 10
Training loss: 1.0394471883773804
Validation loss: 1.8672888407143213

Epoch: 6| Step: 11
Training loss: 1.1360015869140625
Validation loss: 1.9335678931205504

Epoch: 6| Step: 12
Training loss: 2.146838903427124
Validation loss: 1.937553636489376

Epoch: 6| Step: 13
Training loss: 1.6608061790466309
Validation loss: 1.874221199302263

Epoch: 323| Step: 0
Training loss: 1.149928331375122
Validation loss: 1.8940266204136673

Epoch: 6| Step: 1
Training loss: 1.6924521923065186
Validation loss: 1.850382037060235

Epoch: 6| Step: 2
Training loss: 1.358245849609375
Validation loss: 1.9259966624680387

Epoch: 6| Step: 3
Training loss: 1.9431066513061523
Validation loss: 1.8864799289293186

Epoch: 6| Step: 4
Training loss: 1.2399433851242065
Validation loss: 1.8698552052179973

Epoch: 6| Step: 5
Training loss: 1.2634930610656738
Validation loss: 1.864285630564536

Epoch: 6| Step: 6
Training loss: 1.1933525800704956
Validation loss: 1.8901703767879035

Epoch: 6| Step: 7
Training loss: 1.9620821475982666
Validation loss: 1.8655064157260361

Epoch: 6| Step: 8
Training loss: 1.3172991275787354
Validation loss: 1.8677578126230547

Epoch: 6| Step: 9
Training loss: 1.8578028678894043
Validation loss: 1.843999126906036

Epoch: 6| Step: 10
Training loss: 0.9678146839141846
Validation loss: 1.8776309669658702

Epoch: 6| Step: 11
Training loss: 1.742005467414856
Validation loss: 1.9074742460763583

Epoch: 6| Step: 12
Training loss: 1.961035966873169
Validation loss: 1.8287721846693306

Epoch: 6| Step: 13
Training loss: 1.0398999452590942
Validation loss: 1.89872863728513

Epoch: 324| Step: 0
Training loss: 1.2603784799575806
Validation loss: 1.9070208123935166

Epoch: 6| Step: 1
Training loss: 1.8555419445037842
Validation loss: 1.8814763446008005

Epoch: 6| Step: 2
Training loss: 1.7855844497680664
Validation loss: 1.9612525739977438

Epoch: 6| Step: 3
Training loss: 1.256080150604248
Validation loss: 1.9127233541139992

Epoch: 6| Step: 4
Training loss: 2.027442693710327
Validation loss: 1.893400885725534

Epoch: 6| Step: 5
Training loss: 1.342421293258667
Validation loss: 1.9074544342615272

Epoch: 6| Step: 6
Training loss: 1.4778751134872437
Validation loss: 1.8580130992397186

Epoch: 6| Step: 7
Training loss: 0.803716778755188
Validation loss: 1.9119630564925492

Epoch: 6| Step: 8
Training loss: 1.241121768951416
Validation loss: 1.8998249807665426

Epoch: 6| Step: 9
Training loss: 1.4642380475997925
Validation loss: 1.8689643439426218

Epoch: 6| Step: 10
Training loss: 2.174145221710205
Validation loss: 1.8883103196338942

Epoch: 6| Step: 11
Training loss: 0.8259099125862122
Validation loss: 1.8993269935730965

Epoch: 6| Step: 12
Training loss: 1.4668669700622559
Validation loss: 1.8558135417199904

Epoch: 6| Step: 13
Training loss: 1.4986799955368042
Validation loss: 1.8568084688596829

Epoch: 325| Step: 0
Training loss: 1.4105168581008911
Validation loss: 1.877421832853748

Epoch: 6| Step: 1
Training loss: 2.1838483810424805
Validation loss: 1.9286175581716722

Epoch: 6| Step: 2
Training loss: 1.7196178436279297
Validation loss: 1.8689006605455953

Epoch: 6| Step: 3
Training loss: 0.7658854722976685
Validation loss: 1.872064313580913

Epoch: 6| Step: 4
Training loss: 1.5312135219573975
Validation loss: 1.8808150881080217

Epoch: 6| Step: 5
Training loss: 1.1848169565200806
Validation loss: 1.8926428774351716

Epoch: 6| Step: 6
Training loss: 1.2190204858779907
Validation loss: 1.8703490175226682

Epoch: 6| Step: 7
Training loss: 1.509352684020996
Validation loss: 1.8814913713803856

Epoch: 6| Step: 8
Training loss: 1.8325324058532715
Validation loss: 1.8833756844202678

Epoch: 6| Step: 9
Training loss: 1.3418326377868652
Validation loss: 1.8978810361636582

Epoch: 6| Step: 10
Training loss: 1.3225722312927246
Validation loss: 1.8475684581264373

Epoch: 6| Step: 11
Training loss: 1.0061876773834229
Validation loss: 1.9366577299692298

Epoch: 6| Step: 12
Training loss: 1.436184048652649
Validation loss: 1.9568155529678508

Epoch: 6| Step: 13
Training loss: 2.03580641746521
Validation loss: 1.9622656119767057

Epoch: 326| Step: 0
Training loss: 1.1927326917648315
Validation loss: 1.900012408533404

Epoch: 6| Step: 1
Training loss: 1.2151817083358765
Validation loss: 1.8984669049580891

Epoch: 6| Step: 2
Training loss: 1.0829647779464722
Validation loss: 1.9044167316088112

Epoch: 6| Step: 3
Training loss: 1.5849063396453857
Validation loss: 1.8837440039521904

Epoch: 6| Step: 4
Training loss: 1.4945392608642578
Validation loss: 1.949750461886006

Epoch: 6| Step: 5
Training loss: 1.384598970413208
Validation loss: 1.878073843576575

Epoch: 6| Step: 6
Training loss: 2.134166955947876
Validation loss: 1.8726202646891277

Epoch: 6| Step: 7
Training loss: 1.3892724514007568
Validation loss: 1.852126721412905

Epoch: 6| Step: 8
Training loss: 2.317605495452881
Validation loss: 1.8573315476858487

Epoch: 6| Step: 9
Training loss: 1.9411054849624634
Validation loss: 1.8833278571405718

Epoch: 6| Step: 10
Training loss: 1.3158729076385498
Validation loss: 1.8706369438479025

Epoch: 6| Step: 11
Training loss: 1.093275547027588
Validation loss: 1.9150101856518817

Epoch: 6| Step: 12
Training loss: 1.0518553256988525
Validation loss: 1.9509208151089248

Epoch: 6| Step: 13
Training loss: 1.1243329048156738
Validation loss: 1.8960986163026543

Epoch: 327| Step: 0
Training loss: 1.0543195009231567
Validation loss: 1.9049767794147614

Epoch: 6| Step: 1
Training loss: 2.1186556816101074
Validation loss: 1.8614530383899648

Epoch: 6| Step: 2
Training loss: 1.521545171737671
Validation loss: 1.8915456148885912

Epoch: 6| Step: 3
Training loss: 1.0122698545455933
Validation loss: 1.8761591283223962

Epoch: 6| Step: 4
Training loss: 1.7980930805206299
Validation loss: 1.9198368364764797

Epoch: 6| Step: 5
Training loss: 1.6889593601226807
Validation loss: 1.9360038952160907

Epoch: 6| Step: 6
Training loss: 1.53513503074646
Validation loss: 1.949428904441095

Epoch: 6| Step: 7
Training loss: 1.690804123878479
Validation loss: 1.915492296218872

Epoch: 6| Step: 8
Training loss: 1.435520887374878
Validation loss: 1.9179137752902122

Epoch: 6| Step: 9
Training loss: 0.8359338641166687
Validation loss: 1.8801835378011067

Epoch: 6| Step: 10
Training loss: 1.4550156593322754
Validation loss: 1.9002061813108382

Epoch: 6| Step: 11
Training loss: 1.4006143808364868
Validation loss: 1.8891745946740592

Epoch: 6| Step: 12
Training loss: 1.3111172914505005
Validation loss: 1.8447322576276717

Epoch: 6| Step: 13
Training loss: 1.8124885559082031
Validation loss: 1.8694336606610207

Epoch: 328| Step: 0
Training loss: 1.210066318511963
Validation loss: 1.8815145736099572

Epoch: 6| Step: 1
Training loss: 2.175264835357666
Validation loss: 1.9333636786348076

Epoch: 6| Step: 2
Training loss: 1.384556531906128
Validation loss: 1.8095477588715092

Epoch: 6| Step: 3
Training loss: 1.3079012632369995
Validation loss: 1.907337324593657

Epoch: 6| Step: 4
Training loss: 1.354042410850525
Validation loss: 1.914546574315717

Epoch: 6| Step: 5
Training loss: 1.406733751296997
Validation loss: 1.8426631958253923

Epoch: 6| Step: 6
Training loss: 1.6478970050811768
Validation loss: 1.8888961063918246

Epoch: 6| Step: 7
Training loss: 1.4553725719451904
Validation loss: 1.8913124671546362

Epoch: 6| Step: 8
Training loss: 1.6176178455352783
Validation loss: 1.8360822341775382

Epoch: 6| Step: 9
Training loss: 0.9674577713012695
Validation loss: 1.8454747507649083

Epoch: 6| Step: 10
Training loss: 1.4988300800323486
Validation loss: 1.8960663041760843

Epoch: 6| Step: 11
Training loss: 1.7711708545684814
Validation loss: 1.8809159789034116

Epoch: 6| Step: 12
Training loss: 1.0164811611175537
Validation loss: 1.8880733315662672

Epoch: 6| Step: 13
Training loss: 2.1280324459075928
Validation loss: 1.8638772708113476

Epoch: 329| Step: 0
Training loss: 2.374810218811035
Validation loss: 1.8970152126845492

Epoch: 6| Step: 1
Training loss: 1.2210016250610352
Validation loss: 1.9478880397735103

Epoch: 6| Step: 2
Training loss: 1.010810375213623
Validation loss: 1.996791793454078

Epoch: 6| Step: 3
Training loss: 1.7529690265655518
Validation loss: 1.9437452695702995

Epoch: 6| Step: 4
Training loss: 1.5814707279205322
Validation loss: 1.9189025368741763

Epoch: 6| Step: 5
Training loss: 2.0092501640319824
Validation loss: 1.959064600288227

Epoch: 6| Step: 6
Training loss: 0.7895492911338806
Validation loss: 1.9696569109475741

Epoch: 6| Step: 7
Training loss: 1.5277315378189087
Validation loss: 1.9535596665515695

Epoch: 6| Step: 8
Training loss: 1.2765530347824097
Validation loss: 1.881083168009276

Epoch: 6| Step: 9
Training loss: 1.510522484779358
Validation loss: 1.8738948093947543

Epoch: 6| Step: 10
Training loss: 1.3521976470947266
Validation loss: 1.8814632097880046

Epoch: 6| Step: 11
Training loss: 1.5712940692901611
Validation loss: 1.8961034795289398

Epoch: 6| Step: 12
Training loss: 1.3283531665802002
Validation loss: 1.878890291337044

Epoch: 6| Step: 13
Training loss: 1.074095606803894
Validation loss: 1.9115441922218568

Epoch: 330| Step: 0
Training loss: 1.0566442012786865
Validation loss: 1.8800814459400792

Epoch: 6| Step: 1
Training loss: 1.3510336875915527
Validation loss: 1.911136620788164

Epoch: 6| Step: 2
Training loss: 1.6239566802978516
Validation loss: 1.8668108050541212

Epoch: 6| Step: 3
Training loss: 1.5639616250991821
Validation loss: 1.8622919231332757

Epoch: 6| Step: 4
Training loss: 1.1055845022201538
Validation loss: 1.8856630094589726

Epoch: 6| Step: 5
Training loss: 1.5589749813079834
Validation loss: 1.8409955091373895

Epoch: 6| Step: 6
Training loss: 1.7074804306030273
Validation loss: 1.8882566613535727

Epoch: 6| Step: 7
Training loss: 0.8325803279876709
Validation loss: 1.8756684359683786

Epoch: 6| Step: 8
Training loss: 2.3376951217651367
Validation loss: 1.8772798725353774

Epoch: 6| Step: 9
Training loss: 0.7973437309265137
Validation loss: 1.9160007405024704

Epoch: 6| Step: 10
Training loss: 1.4766860008239746
Validation loss: 1.919684394713371

Epoch: 6| Step: 11
Training loss: 1.3722138404846191
Validation loss: 1.9080950085834791

Epoch: 6| Step: 12
Training loss: 2.2012932300567627
Validation loss: 1.9387667294471496

Epoch: 6| Step: 13
Training loss: 0.8767310976982117
Validation loss: 1.909460461267861

Epoch: 331| Step: 0
Training loss: 2.139705181121826
Validation loss: 1.851224390409326

Epoch: 6| Step: 1
Training loss: 1.1204829216003418
Validation loss: 1.848806676044259

Epoch: 6| Step: 2
Training loss: 1.6604669094085693
Validation loss: 1.8842280449405793

Epoch: 6| Step: 3
Training loss: 1.9254095554351807
Validation loss: 1.9241474187502297

Epoch: 6| Step: 4
Training loss: 1.890820026397705
Validation loss: 1.8922830807265414

Epoch: 6| Step: 5
Training loss: 1.0716276168823242
Validation loss: 1.8805916206811064

Epoch: 6| Step: 6
Training loss: 1.551645278930664
Validation loss: 1.8708323022370696

Epoch: 6| Step: 7
Training loss: 0.9577929973602295
Validation loss: 1.94250827194542

Epoch: 6| Step: 8
Training loss: 1.3826611042022705
Validation loss: 1.8797174499880882

Epoch: 6| Step: 9
Training loss: 1.4405241012573242
Validation loss: 1.8819653308519753

Epoch: 6| Step: 10
Training loss: 1.6794171333312988
Validation loss: 1.8481584108004006

Epoch: 6| Step: 11
Training loss: 1.2521584033966064
Validation loss: 1.9164983585316648

Epoch: 6| Step: 12
Training loss: 1.1292201280593872
Validation loss: 1.8948172305219917

Epoch: 6| Step: 13
Training loss: 1.1196119785308838
Validation loss: 1.9105820463549705

Epoch: 332| Step: 0
Training loss: 1.5759921073913574
Validation loss: 1.9366005851376442

Epoch: 6| Step: 1
Training loss: 1.410622000694275
Validation loss: 1.9083615785003991

Epoch: 6| Step: 2
Training loss: 1.7200592756271362
Validation loss: 1.876288701129216

Epoch: 6| Step: 3
Training loss: 1.5212972164154053
Validation loss: 1.9211982193813528

Epoch: 6| Step: 4
Training loss: 1.6684157848358154
Validation loss: 1.9863490199529996

Epoch: 6| Step: 5
Training loss: 1.4876208305358887
Validation loss: 1.9344631215577484

Epoch: 6| Step: 6
Training loss: 1.0502872467041016
Validation loss: 1.9454866199083225

Epoch: 6| Step: 7
Training loss: 1.1292964220046997
Validation loss: 1.9401036065111879

Epoch: 6| Step: 8
Training loss: 1.4099220037460327
Validation loss: 1.8795138366760746

Epoch: 6| Step: 9
Training loss: 1.2533295154571533
Validation loss: 1.9299143206688665

Epoch: 6| Step: 10
Training loss: 2.1667330265045166
Validation loss: 1.9414058244356545

Epoch: 6| Step: 11
Training loss: 1.510237216949463
Validation loss: 1.9198320809231009

Epoch: 6| Step: 12
Training loss: 1.2092968225479126
Validation loss: 1.89300883969953

Epoch: 6| Step: 13
Training loss: 1.375211238861084
Validation loss: 1.9141599849988056

Epoch: 333| Step: 0
Training loss: 1.8466538190841675
Validation loss: 1.8510930845814366

Epoch: 6| Step: 1
Training loss: 1.5154402256011963
Validation loss: 1.8943728759724607

Epoch: 6| Step: 2
Training loss: 1.3856043815612793
Validation loss: 1.8519319975247948

Epoch: 6| Step: 3
Training loss: 1.6064610481262207
Validation loss: 1.9333910301167478

Epoch: 6| Step: 4
Training loss: 1.6237142086029053
Validation loss: 1.850940465927124

Epoch: 6| Step: 5
Training loss: 1.7487084865570068
Validation loss: 1.8716102594970374

Epoch: 6| Step: 6
Training loss: 1.8768589496612549
Validation loss: 1.847391205449258

Epoch: 6| Step: 7
Training loss: 1.4650273323059082
Validation loss: 1.877603559083836

Epoch: 6| Step: 8
Training loss: 1.62440025806427
Validation loss: 1.848024349058828

Epoch: 6| Step: 9
Training loss: 1.0476902723312378
Validation loss: 1.8675112673031387

Epoch: 6| Step: 10
Training loss: 1.3636600971221924
Validation loss: 1.9022668792355446

Epoch: 6| Step: 11
Training loss: 0.7642037868499756
Validation loss: 1.8678279064034904

Epoch: 6| Step: 12
Training loss: 1.2890245914459229
Validation loss: 1.9202713645914549

Epoch: 6| Step: 13
Training loss: 1.6191993951797485
Validation loss: 1.86848485085272

Epoch: 334| Step: 0
Training loss: 1.453964352607727
Validation loss: 1.904874247889365

Epoch: 6| Step: 1
Training loss: 1.2903367280960083
Validation loss: 1.8874530766599922

Epoch: 6| Step: 2
Training loss: 2.009685516357422
Validation loss: 1.958982313832929

Epoch: 6| Step: 3
Training loss: 1.3053559064865112
Validation loss: 1.9163781058403753

Epoch: 6| Step: 4
Training loss: 1.2382829189300537
Validation loss: 1.9327295223871868

Epoch: 6| Step: 5
Training loss: 0.984155535697937
Validation loss: 1.9318089869714552

Epoch: 6| Step: 6
Training loss: 0.9274787306785583
Validation loss: 1.9186567439827868

Epoch: 6| Step: 7
Training loss: 1.5808473825454712
Validation loss: 1.8732994967891323

Epoch: 6| Step: 8
Training loss: 1.4216748476028442
Validation loss: 1.9101984577794229

Epoch: 6| Step: 9
Training loss: 1.8218963146209717
Validation loss: 1.8633749664470713

Epoch: 6| Step: 10
Training loss: 2.080869674682617
Validation loss: 1.8891681522451422

Epoch: 6| Step: 11
Training loss: 1.239663004875183
Validation loss: 1.851416621156918

Epoch: 6| Step: 12
Training loss: 1.5906964540481567
Validation loss: 1.928691726858898

Epoch: 6| Step: 13
Training loss: 1.5538283586502075
Validation loss: 1.873071990987306

Epoch: 335| Step: 0
Training loss: 1.4391793012619019
Validation loss: 1.8441566126320952

Epoch: 6| Step: 1
Training loss: 1.0452170372009277
Validation loss: 1.9077872140433199

Epoch: 6| Step: 2
Training loss: 1.3858897686004639
Validation loss: 1.904375482630986

Epoch: 6| Step: 3
Training loss: 1.20543372631073
Validation loss: 1.9017743218329646

Epoch: 6| Step: 4
Training loss: 0.959513247013092
Validation loss: 1.8505192815616567

Epoch: 6| Step: 5
Training loss: 1.5283573865890503
Validation loss: 1.8624685784821868

Epoch: 6| Step: 6
Training loss: 1.0543560981750488
Validation loss: 1.8712563604436896

Epoch: 6| Step: 7
Training loss: 2.125579357147217
Validation loss: 1.8829834256120908

Epoch: 6| Step: 8
Training loss: 1.8537087440490723
Validation loss: 1.9031980550417336

Epoch: 6| Step: 9
Training loss: 1.8044986724853516
Validation loss: 1.876485788693992

Epoch: 6| Step: 10
Training loss: 1.1692005395889282
Validation loss: 1.8582519382558844

Epoch: 6| Step: 11
Training loss: 1.5127042531967163
Validation loss: 1.879221244524884

Epoch: 6| Step: 12
Training loss: 1.3888845443725586
Validation loss: 1.8609249604645597

Epoch: 6| Step: 13
Training loss: 1.4336847066879272
Validation loss: 1.8289093945616035

Epoch: 336| Step: 0
Training loss: 1.7906157970428467
Validation loss: 1.8742963908821024

Epoch: 6| Step: 1
Training loss: 1.419933557510376
Validation loss: 1.8728567810468777

Epoch: 6| Step: 2
Training loss: 1.476776123046875
Validation loss: 1.8591430776862687

Epoch: 6| Step: 3
Training loss: 2.188478469848633
Validation loss: 1.853295478769528

Epoch: 6| Step: 4
Training loss: 1.0629762411117554
Validation loss: 1.8776351303182623

Epoch: 6| Step: 5
Training loss: 1.0705316066741943
Validation loss: 1.898621456597441

Epoch: 6| Step: 6
Training loss: 1.7404581308364868
Validation loss: 1.8710830339821436

Epoch: 6| Step: 7
Training loss: 0.728567898273468
Validation loss: 1.8726734474141111

Epoch: 6| Step: 8
Training loss: 1.744828462600708
Validation loss: 1.8841485656717771

Epoch: 6| Step: 9
Training loss: 1.4706395864486694
Validation loss: 1.9061997731526692

Epoch: 6| Step: 10
Training loss: 1.0236248970031738
Validation loss: 1.8856494093454013

Epoch: 6| Step: 11
Training loss: 1.2390049695968628
Validation loss: 1.9081024585231658

Epoch: 6| Step: 12
Training loss: 1.8420498371124268
Validation loss: 1.9121615732869794

Epoch: 6| Step: 13
Training loss: 1.1230518817901611
Validation loss: 1.9417027991305116

Epoch: 337| Step: 0
Training loss: 1.4108490943908691
Validation loss: 1.9124777150410477

Epoch: 6| Step: 1
Training loss: 0.9354162216186523
Validation loss: 1.86054564035067

Epoch: 6| Step: 2
Training loss: 1.536444902420044
Validation loss: 1.8676934447339786

Epoch: 6| Step: 3
Training loss: 2.5319020748138428
Validation loss: 1.8848861225189701

Epoch: 6| Step: 4
Training loss: 1.6068817377090454
Validation loss: 1.8997878246409918

Epoch: 6| Step: 5
Training loss: 1.6084333658218384
Validation loss: 1.8726868911456036

Epoch: 6| Step: 6
Training loss: 1.4103748798370361
Validation loss: 1.903186636586343

Epoch: 6| Step: 7
Training loss: 1.8267791271209717
Validation loss: 1.844690872776893

Epoch: 6| Step: 8
Training loss: 1.124695062637329
Validation loss: 1.8486071889118483

Epoch: 6| Step: 9
Training loss: 1.0056997537612915
Validation loss: 1.8803923719672746

Epoch: 6| Step: 10
Training loss: 1.0402469635009766
Validation loss: 1.9236451989860945

Epoch: 6| Step: 11
Training loss: 1.446293830871582
Validation loss: 1.9051203099630212

Epoch: 6| Step: 12
Training loss: 0.805350661277771
Validation loss: 1.9056526653228267

Epoch: 6| Step: 13
Training loss: 1.9881941080093384
Validation loss: 1.9121854074539677

Epoch: 338| Step: 0
Training loss: 1.352089524269104
Validation loss: 1.8941009557375343

Epoch: 6| Step: 1
Training loss: 2.6463425159454346
Validation loss: 1.9200625329889276

Epoch: 6| Step: 2
Training loss: 0.8625811338424683
Validation loss: 1.890554037145389

Epoch: 6| Step: 3
Training loss: 1.483825445175171
Validation loss: 1.8781931682299542

Epoch: 6| Step: 4
Training loss: 1.0946946144104004
Validation loss: 1.9485865434010823

Epoch: 6| Step: 5
Training loss: 2.258650779724121
Validation loss: 1.9836407566583285

Epoch: 6| Step: 6
Training loss: 0.9899641275405884
Validation loss: 1.9750251423928045

Epoch: 6| Step: 7
Training loss: 1.4187239408493042
Validation loss: 1.9335112546079902

Epoch: 6| Step: 8
Training loss: 2.0269112586975098
Validation loss: 1.916713709472328

Epoch: 6| Step: 9
Training loss: 0.9447900652885437
Validation loss: 1.938359752778084

Epoch: 6| Step: 10
Training loss: 1.2162827253341675
Validation loss: 2.0358719210470877

Epoch: 6| Step: 11
Training loss: 1.0827261209487915
Validation loss: 1.9148116239937403

Epoch: 6| Step: 12
Training loss: 1.5805373191833496
Validation loss: 1.905358083786503

Epoch: 6| Step: 13
Training loss: 1.097040057182312
Validation loss: 1.9446130055253223

Epoch: 339| Step: 0
Training loss: 1.4777389764785767
Validation loss: 1.8852912367031138

Epoch: 6| Step: 1
Training loss: 1.3990864753723145
Validation loss: 1.8946604164697791

Epoch: 6| Step: 2
Training loss: 1.2586209774017334
Validation loss: 1.878277515852323

Epoch: 6| Step: 3
Training loss: 0.8673559427261353
Validation loss: 1.91266385457849

Epoch: 6| Step: 4
Training loss: 1.6567760705947876
Validation loss: 1.8764395072895994

Epoch: 6| Step: 5
Training loss: 1.512831211090088
Validation loss: 1.9086888118456768

Epoch: 6| Step: 6
Training loss: 1.7923943996429443
Validation loss: 1.8839042802010812

Epoch: 6| Step: 7
Training loss: 1.6035988330841064
Validation loss: 1.9073555828422628

Epoch: 6| Step: 8
Training loss: 2.0045392513275146
Validation loss: 1.8509831479800645

Epoch: 6| Step: 9
Training loss: 1.3130038976669312
Validation loss: 1.846070558794083

Epoch: 6| Step: 10
Training loss: 1.3603146076202393
Validation loss: 1.8632435055189236

Epoch: 6| Step: 11
Training loss: 1.2092112302780151
Validation loss: 1.8562147078975555

Epoch: 6| Step: 12
Training loss: 1.5137251615524292
Validation loss: 1.8480864827350905

Epoch: 6| Step: 13
Training loss: 1.251731038093567
Validation loss: 1.8990537517814225

Epoch: 340| Step: 0
Training loss: 1.050992727279663
Validation loss: 1.8996713571651007

Epoch: 6| Step: 1
Training loss: 1.1785657405853271
Validation loss: 1.9174665891995994

Epoch: 6| Step: 2
Training loss: 1.5091526508331299
Validation loss: 1.9066939559034122

Epoch: 6| Step: 3
Training loss: 1.0540883541107178
Validation loss: 1.8739096195467058

Epoch: 6| Step: 4
Training loss: 1.4496781826019287
Validation loss: 1.9384418533694359

Epoch: 6| Step: 5
Training loss: 1.2327064275741577
Validation loss: 1.9109278161038634

Epoch: 6| Step: 6
Training loss: 1.9160563945770264
Validation loss: 1.9145153825001051

Epoch: 6| Step: 7
Training loss: 1.8503105640411377
Validation loss: 1.9318780258137693

Epoch: 6| Step: 8
Training loss: 0.6570087671279907
Validation loss: 1.9076686584821312

Epoch: 6| Step: 9
Training loss: 1.6375032663345337
Validation loss: 1.9124274138481385

Epoch: 6| Step: 10
Training loss: 1.4959319829940796
Validation loss: 1.9251783560681086

Epoch: 6| Step: 11
Training loss: 1.461475133895874
Validation loss: 1.9007508959821475

Epoch: 6| Step: 12
Training loss: 1.4726886749267578
Validation loss: 1.9110252267570906

Epoch: 6| Step: 13
Training loss: 1.7288328409194946
Validation loss: 1.8893226346661967

Epoch: 341| Step: 0
Training loss: 1.1682143211364746
Validation loss: 1.9128050163228025

Epoch: 6| Step: 1
Training loss: 1.4014979600906372
Validation loss: 1.967541540822675

Epoch: 6| Step: 2
Training loss: 1.2988920211791992
Validation loss: 1.9455644405016335

Epoch: 6| Step: 3
Training loss: 1.7154359817504883
Validation loss: 1.9773124110314153

Epoch: 6| Step: 4
Training loss: 1.5797988176345825
Validation loss: 1.926848775597029

Epoch: 6| Step: 5
Training loss: 1.644976258277893
Validation loss: 1.9182004249224098

Epoch: 6| Step: 6
Training loss: 1.2038354873657227
Validation loss: 1.9605249153670443

Epoch: 6| Step: 7
Training loss: 0.5978925824165344
Validation loss: 1.9543619745521135

Epoch: 6| Step: 8
Training loss: 1.2874755859375
Validation loss: 1.9157293176138273

Epoch: 6| Step: 9
Training loss: 1.7739160060882568
Validation loss: 1.909271054370429

Epoch: 6| Step: 10
Training loss: 1.8087471723556519
Validation loss: 1.921782075717885

Epoch: 6| Step: 11
Training loss: 1.3293449878692627
Validation loss: 1.903278625139626

Epoch: 6| Step: 12
Training loss: 2.0162839889526367
Validation loss: 1.9127544280021422

Epoch: 6| Step: 13
Training loss: 0.6186967492103577
Validation loss: 1.8893585179441719

Epoch: 342| Step: 0
Training loss: 0.9828678369522095
Validation loss: 1.9353539046420847

Epoch: 6| Step: 1
Training loss: 1.1125903129577637
Validation loss: 1.8987888674582205

Epoch: 6| Step: 2
Training loss: 1.80966317653656
Validation loss: 1.9199814309356034

Epoch: 6| Step: 3
Training loss: 1.7498536109924316
Validation loss: 1.924787498289539

Epoch: 6| Step: 4
Training loss: 1.703385591506958
Validation loss: 1.8968385034991848

Epoch: 6| Step: 5
Training loss: 0.9957461953163147
Validation loss: 1.8943846635921027

Epoch: 6| Step: 6
Training loss: 1.6941804885864258
Validation loss: 1.92355606889212

Epoch: 6| Step: 7
Training loss: 1.3713874816894531
Validation loss: 1.901080927541179

Epoch: 6| Step: 8
Training loss: 1.8211897611618042
Validation loss: 1.9407109022140503

Epoch: 6| Step: 9
Training loss: 1.1187814474105835
Validation loss: 1.8595918365704116

Epoch: 6| Step: 10
Training loss: 1.4419920444488525
Validation loss: 1.9318397532227218

Epoch: 6| Step: 11
Training loss: 0.9651817679405212
Validation loss: 1.8863487371834375

Epoch: 6| Step: 12
Training loss: 1.1861720085144043
Validation loss: 1.874407914377028

Epoch: 6| Step: 13
Training loss: 2.4078969955444336
Validation loss: 1.9568998377810243

Epoch: 343| Step: 0
Training loss: 1.4485962390899658
Validation loss: 1.9144783917293753

Epoch: 6| Step: 1
Training loss: 1.584625005722046
Validation loss: 1.9264592150206208

Epoch: 6| Step: 2
Training loss: 1.7071510553359985
Validation loss: 1.8688276660057805

Epoch: 6| Step: 3
Training loss: 0.7562533617019653
Validation loss: 1.9014950439494143

Epoch: 6| Step: 4
Training loss: 2.0509133338928223
Validation loss: 1.8863573125613633

Epoch: 6| Step: 5
Training loss: 1.139931082725525
Validation loss: 1.8425153839972712

Epoch: 6| Step: 6
Training loss: 1.531185507774353
Validation loss: 1.8768372074250252

Epoch: 6| Step: 7
Training loss: 1.283717393875122
Validation loss: 1.9259430541787097

Epoch: 6| Step: 8
Training loss: 1.0759564638137817
Validation loss: 1.8814932377107683

Epoch: 6| Step: 9
Training loss: 1.6663061380386353
Validation loss: 1.9056407828484812

Epoch: 6| Step: 10
Training loss: 1.2995514869689941
Validation loss: 1.8823405260680823

Epoch: 6| Step: 11
Training loss: 1.360465168952942
Validation loss: 1.955866906591641

Epoch: 6| Step: 12
Training loss: 1.8286263942718506
Validation loss: 1.907192176388156

Epoch: 6| Step: 13
Training loss: 1.0549015998840332
Validation loss: 1.9163990097661172

Epoch: 344| Step: 0
Training loss: 0.8805077075958252
Validation loss: 1.9202345648119528

Epoch: 6| Step: 1
Training loss: 1.4550362825393677
Validation loss: 1.8980766278441235

Epoch: 6| Step: 2
Training loss: 2.017286539077759
Validation loss: 1.913958280317245

Epoch: 6| Step: 3
Training loss: 1.6739120483398438
Validation loss: 1.9068424855509112

Epoch: 6| Step: 4
Training loss: 1.217984676361084
Validation loss: 1.8846865110499884

Epoch: 6| Step: 5
Training loss: 1.3490276336669922
Validation loss: 1.8960340074313584

Epoch: 6| Step: 6
Training loss: 1.093668818473816
Validation loss: 1.9039997054684548

Epoch: 6| Step: 7
Training loss: 1.2028534412384033
Validation loss: 1.8871897471848356

Epoch: 6| Step: 8
Training loss: 1.7704946994781494
Validation loss: 1.8585346770542923

Epoch: 6| Step: 9
Training loss: 1.5022168159484863
Validation loss: 1.8820798935428742

Epoch: 6| Step: 10
Training loss: 1.4053688049316406
Validation loss: 1.8892344479919763

Epoch: 6| Step: 11
Training loss: 1.4636781215667725
Validation loss: 1.9069414202884962

Epoch: 6| Step: 12
Training loss: 1.7626105546951294
Validation loss: 1.900566897084636

Epoch: 6| Step: 13
Training loss: 0.6647529006004333
Validation loss: 1.8635961445428992

Epoch: 345| Step: 0
Training loss: 1.8417294025421143
Validation loss: 1.8835636313243578

Epoch: 6| Step: 1
Training loss: 1.5267226696014404
Validation loss: 1.86199826066212

Epoch: 6| Step: 2
Training loss: 1.4487197399139404
Validation loss: 1.8781294027964275

Epoch: 6| Step: 3
Training loss: 1.8326685428619385
Validation loss: 1.8553708971187632

Epoch: 6| Step: 4
Training loss: 1.1948189735412598
Validation loss: 1.903258144214589

Epoch: 6| Step: 5
Training loss: 1.5810859203338623
Validation loss: 1.8362332428655317

Epoch: 6| Step: 6
Training loss: 1.1634968519210815
Validation loss: 1.849385694790912

Epoch: 6| Step: 7
Training loss: 1.2090661525726318
Validation loss: 1.893129450018688

Epoch: 6| Step: 8
Training loss: 1.805262804031372
Validation loss: 1.8621097328842326

Epoch: 6| Step: 9
Training loss: 0.9740737676620483
Validation loss: 1.836489959429669

Epoch: 6| Step: 10
Training loss: 1.304352045059204
Validation loss: 1.8929571208133493

Epoch: 6| Step: 11
Training loss: 1.6220219135284424
Validation loss: 1.8779049406769455

Epoch: 6| Step: 12
Training loss: 1.1307563781738281
Validation loss: 1.8708101011091662

Epoch: 6| Step: 13
Training loss: 1.3414334058761597
Validation loss: 1.9002763635368758

Epoch: 346| Step: 0
Training loss: 0.9903935790061951
Validation loss: 1.9009041401647753

Epoch: 6| Step: 1
Training loss: 1.4872231483459473
Validation loss: 1.927892364481444

Epoch: 6| Step: 2
Training loss: 2.0456559658050537
Validation loss: 1.9022168664522068

Epoch: 6| Step: 3
Training loss: 1.2204545736312866
Validation loss: 1.9216020876361477

Epoch: 6| Step: 4
Training loss: 1.4488754272460938
Validation loss: 1.858284286273423

Epoch: 6| Step: 5
Training loss: 0.8811660408973694
Validation loss: 1.9435135497841785

Epoch: 6| Step: 6
Training loss: 1.2733092308044434
Validation loss: 1.8959747719508346

Epoch: 6| Step: 7
Training loss: 1.7055290937423706
Validation loss: 1.920451271918512

Epoch: 6| Step: 8
Training loss: 1.0665314197540283
Validation loss: 1.863180047722273

Epoch: 6| Step: 9
Training loss: 1.4323878288269043
Validation loss: 1.9027387916400869

Epoch: 6| Step: 10
Training loss: 1.8471746444702148
Validation loss: 1.875084364286033

Epoch: 6| Step: 11
Training loss: 1.3809468746185303
Validation loss: 1.8970244725545247

Epoch: 6| Step: 12
Training loss: 1.2733774185180664
Validation loss: 1.9173091970464236

Epoch: 6| Step: 13
Training loss: 1.1609265804290771
Validation loss: 1.892190025698754

Epoch: 347| Step: 0
Training loss: 1.8708927631378174
Validation loss: 1.8784108238835489

Epoch: 6| Step: 1
Training loss: 1.1158185005187988
Validation loss: 1.913651676588161

Epoch: 6| Step: 2
Training loss: 1.0661497116088867
Validation loss: 1.8954653355383104

Epoch: 6| Step: 3
Training loss: 1.3550945520401
Validation loss: 1.9335671189010784

Epoch: 6| Step: 4
Training loss: 2.065431833267212
Validation loss: 1.9153346887198828

Epoch: 6| Step: 5
Training loss: 1.2747719287872314
Validation loss: 1.897001597189134

Epoch: 6| Step: 6
Training loss: 1.2821784019470215
Validation loss: 1.837903340657552

Epoch: 6| Step: 7
Training loss: 1.3132517337799072
Validation loss: 1.9321319134004655

Epoch: 6| Step: 8
Training loss: 1.27942955493927
Validation loss: 1.9045408156610304

Epoch: 6| Step: 9
Training loss: 0.9275156259536743
Validation loss: 1.9306226109945646

Epoch: 6| Step: 10
Training loss: 1.7311286926269531
Validation loss: 1.8911379934639059

Epoch: 6| Step: 11
Training loss: 1.709069013595581
Validation loss: 1.8929430951354325

Epoch: 6| Step: 12
Training loss: 1.4542319774627686
Validation loss: 1.884637305813451

Epoch: 6| Step: 13
Training loss: 1.4660135507583618
Validation loss: 1.8738857776887956

Epoch: 348| Step: 0
Training loss: 1.5353236198425293
Validation loss: 1.8493602698849094

Epoch: 6| Step: 1
Training loss: 1.2961807250976562
Validation loss: 1.8831096695315452

Epoch: 6| Step: 2
Training loss: 2.339071273803711
Validation loss: 1.9371084192747712

Epoch: 6| Step: 3
Training loss: 0.9004382491111755
Validation loss: 1.851744810740153

Epoch: 6| Step: 4
Training loss: 1.4901444911956787
Validation loss: 1.949663758277893

Epoch: 6| Step: 5
Training loss: 1.0207079648971558
Validation loss: 1.9477027077828684

Epoch: 6| Step: 6
Training loss: 1.0957963466644287
Validation loss: 1.9486211717769664

Epoch: 6| Step: 7
Training loss: 1.6774523258209229
Validation loss: 1.8868258512148293

Epoch: 6| Step: 8
Training loss: 1.5499337911605835
Validation loss: 1.8838540892447195

Epoch: 6| Step: 9
Training loss: 1.2372040748596191
Validation loss: 1.9355770951958113

Epoch: 6| Step: 10
Training loss: 1.2752032279968262
Validation loss: 1.8558014208270657

Epoch: 6| Step: 11
Training loss: 1.4109747409820557
Validation loss: 1.8941309195692821

Epoch: 6| Step: 12
Training loss: 1.878746747970581
Validation loss: 1.9099089996789091

Epoch: 6| Step: 13
Training loss: 0.8580371737480164
Validation loss: 1.9229773526550622

Epoch: 349| Step: 0
Training loss: 1.4517512321472168
Validation loss: 1.8939001329483525

Epoch: 6| Step: 1
Training loss: 1.7200956344604492
Validation loss: 1.8707769506721086

Epoch: 6| Step: 2
Training loss: 1.2641102075576782
Validation loss: 1.9343290303343086

Epoch: 6| Step: 3
Training loss: 1.922810673713684
Validation loss: 1.9003387240953342

Epoch: 6| Step: 4
Training loss: 1.0248442888259888
Validation loss: 1.8713196528855192

Epoch: 6| Step: 5
Training loss: 0.7487587332725525
Validation loss: 1.9029942917567428

Epoch: 6| Step: 6
Training loss: 1.156650424003601
Validation loss: 1.889702832827004

Epoch: 6| Step: 7
Training loss: 1.8588097095489502
Validation loss: 1.8397089217298774

Epoch: 6| Step: 8
Training loss: 1.4168593883514404
Validation loss: 1.9078725166218256

Epoch: 6| Step: 9
Training loss: 1.6469210386276245
Validation loss: 1.904188948292886

Epoch: 6| Step: 10
Training loss: 1.3351058959960938
Validation loss: 1.8888635379011913

Epoch: 6| Step: 11
Training loss: 1.2124089002609253
Validation loss: 1.8867095247391732

Epoch: 6| Step: 12
Training loss: 1.3776648044586182
Validation loss: 1.8966121519765546

Epoch: 6| Step: 13
Training loss: 1.4567192792892456
Validation loss: 1.8820569130682177

Epoch: 350| Step: 0
Training loss: 0.9986569285392761
Validation loss: 1.8900814133305703

Epoch: 6| Step: 1
Training loss: 1.2683700323104858
Validation loss: 1.8587281498857724

Epoch: 6| Step: 2
Training loss: 1.32768714427948
Validation loss: 1.8753799725604314

Epoch: 6| Step: 3
Training loss: 1.3665337562561035
Validation loss: 1.893263683524183

Epoch: 6| Step: 4
Training loss: 0.9852796196937561
Validation loss: 1.8943483726952666

Epoch: 6| Step: 5
Training loss: 1.0536818504333496
Validation loss: 1.8681440648212229

Epoch: 6| Step: 6
Training loss: 1.7245218753814697
Validation loss: 1.9218509633054015

Epoch: 6| Step: 7
Training loss: 1.7681050300598145
Validation loss: 1.9250676683200303

Epoch: 6| Step: 8
Training loss: 1.877608299255371
Validation loss: 1.975527383947885

Epoch: 6| Step: 9
Training loss: 1.9386109113693237
Validation loss: 1.9688134859966975

Epoch: 6| Step: 10
Training loss: 0.9974687099456787
Validation loss: 1.9186519871475876

Epoch: 6| Step: 11
Training loss: 1.4204425811767578
Validation loss: 1.9264522303817093

Epoch: 6| Step: 12
Training loss: 1.5384187698364258
Validation loss: 1.9703116058021464

Epoch: 6| Step: 13
Training loss: 1.3792204856872559
Validation loss: 1.9156882762908936

Testing loss: 2.152169402440389
