Epoch: 1| Step: 0
Training loss: 6.884940147399902
Validation loss: 6.3152237553750314

Epoch: 5| Step: 1
Training loss: 6.7054643630981445
Validation loss: 6.308207737502231

Epoch: 5| Step: 2
Training loss: 5.258896827697754
Validation loss: 6.302410433369298

Epoch: 5| Step: 3
Training loss: 6.437867164611816
Validation loss: 6.2951258177398355

Epoch: 5| Step: 4
Training loss: 6.38583517074585
Validation loss: 6.291382430702128

Epoch: 5| Step: 5
Training loss: 7.245509147644043
Validation loss: 6.283493247083438

Epoch: 5| Step: 6
Training loss: 5.710599422454834
Validation loss: 6.278451155590755

Epoch: 5| Step: 7
Training loss: 5.509246349334717
Validation loss: 6.2722027635061615

Epoch: 5| Step: 8
Training loss: 6.095202445983887
Validation loss: 6.265882850975118

Epoch: 5| Step: 9
Training loss: 5.385066032409668
Validation loss: 6.259414888197376

Epoch: 5| Step: 10
Training loss: 5.106339454650879
Validation loss: 6.255464061614005

Epoch: 2| Step: 0
Training loss: 5.5803093910217285
Validation loss: 6.250176265675535

Epoch: 5| Step: 1
Training loss: 6.26831579208374
Validation loss: 6.243828378697877

Epoch: 5| Step: 2
Training loss: 5.565117835998535
Validation loss: 6.237866442690613

Epoch: 5| Step: 3
Training loss: 6.0225830078125
Validation loss: 6.232675096040131

Epoch: 5| Step: 4
Training loss: 6.390778541564941
Validation loss: 6.225793746209914

Epoch: 5| Step: 5
Training loss: 6.540781497955322
Validation loss: 6.21885992891045

Epoch: 5| Step: 6
Training loss: 5.32197904586792
Validation loss: 6.2147185828096125

Epoch: 5| Step: 7
Training loss: 5.815443515777588
Validation loss: 6.207505287662629

Epoch: 5| Step: 8
Training loss: 6.530220031738281
Validation loss: 6.201909408774427

Epoch: 5| Step: 9
Training loss: 6.472308158874512
Validation loss: 6.196982496528215

Epoch: 5| Step: 10
Training loss: 5.573010444641113
Validation loss: 6.192341558394894

Epoch: 3| Step: 0
Training loss: 6.248771667480469
Validation loss: 6.18528111262988

Epoch: 5| Step: 1
Training loss: 6.750340938568115
Validation loss: 6.178117957166446

Epoch: 5| Step: 2
Training loss: 5.8619184494018555
Validation loss: 6.173304696236888

Epoch: 5| Step: 3
Training loss: 5.231016159057617
Validation loss: 6.167564443362656

Epoch: 5| Step: 4
Training loss: 4.740413665771484
Validation loss: 6.161035296737507

Epoch: 5| Step: 5
Training loss: 7.2150678634643555
Validation loss: 6.153685333908245

Epoch: 5| Step: 6
Training loss: 6.104844093322754
Validation loss: 6.149341808852329

Epoch: 5| Step: 7
Training loss: 5.392307758331299
Validation loss: 6.143769038620816

Epoch: 5| Step: 8
Training loss: 6.348028659820557
Validation loss: 6.1381713959478565

Epoch: 5| Step: 9
Training loss: 6.220091342926025
Validation loss: 6.1314633277154735

Epoch: 5| Step: 10
Training loss: 5.190989971160889
Validation loss: 6.126221533744566

Epoch: 4| Step: 0
Training loss: 5.880155563354492
Validation loss: 6.116265061081097

Epoch: 5| Step: 1
Training loss: 5.637796878814697
Validation loss: 6.113070539248887

Epoch: 5| Step: 2
Training loss: 6.237905025482178
Validation loss: 6.104112901995259

Epoch: 5| Step: 3
Training loss: 7.073729515075684
Validation loss: 6.100372863072221

Epoch: 5| Step: 4
Training loss: 5.1011962890625
Validation loss: 6.09183047920145

Epoch: 5| Step: 5
Training loss: 5.193177700042725
Validation loss: 6.08700252861105

Epoch: 5| Step: 6
Training loss: 5.239992618560791
Validation loss: 6.078759116511191

Epoch: 5| Step: 7
Training loss: 6.448542594909668
Validation loss: 6.072511267918412

Epoch: 5| Step: 8
Training loss: 5.560079574584961
Validation loss: 6.066933672915223

Epoch: 5| Step: 9
Training loss: 5.720180511474609
Validation loss: 6.061190523127074

Epoch: 5| Step: 10
Training loss: 6.653517246246338
Validation loss: 6.051328033529302

Epoch: 5| Step: 0
Training loss: 5.583629608154297
Validation loss: 6.047237093730639

Epoch: 5| Step: 1
Training loss: 6.195347785949707
Validation loss: 6.037001081692275

Epoch: 5| Step: 2
Training loss: 5.458050727844238
Validation loss: 6.032683469915903

Epoch: 5| Step: 3
Training loss: 6.304238319396973
Validation loss: 6.023136672153268

Epoch: 5| Step: 4
Training loss: 4.595120906829834
Validation loss: 6.017452998827863

Epoch: 5| Step: 5
Training loss: 5.457675933837891
Validation loss: 6.006184552305488

Epoch: 5| Step: 6
Training loss: 5.620242118835449
Validation loss: 6.000530714629798

Epoch: 5| Step: 7
Training loss: 5.92282772064209
Validation loss: 5.997546513875325

Epoch: 5| Step: 8
Training loss: 5.980144500732422
Validation loss: 5.9895478166559695

Epoch: 5| Step: 9
Training loss: 5.2323102951049805
Validation loss: 5.978558540344238

Epoch: 5| Step: 10
Training loss: 7.711817264556885
Validation loss: 5.974817076037007

Epoch: 6| Step: 0
Training loss: 5.562129020690918
Validation loss: 5.965345244253835

Epoch: 5| Step: 1
Training loss: 4.299197673797607
Validation loss: 5.95693051943215

Epoch: 5| Step: 2
Training loss: 6.804666996002197
Validation loss: 5.949251328745196

Epoch: 5| Step: 3
Training loss: 5.525359153747559
Validation loss: 5.938695266682615

Epoch: 5| Step: 4
Training loss: 5.068274021148682
Validation loss: 5.93163267771403

Epoch: 5| Step: 5
Training loss: 5.738005638122559
Validation loss: 5.924439204636441

Epoch: 5| Step: 6
Training loss: 5.530768871307373
Validation loss: 5.9177829629631455

Epoch: 5| Step: 7
Training loss: 5.913261413574219
Validation loss: 5.9065786382203465

Epoch: 5| Step: 8
Training loss: 5.67977237701416
Validation loss: 5.900028444105579

Epoch: 5| Step: 9
Training loss: 6.679388523101807
Validation loss: 5.891328180989912

Epoch: 5| Step: 10
Training loss: 6.067760467529297
Validation loss: 5.881096055430751

Epoch: 7| Step: 0
Training loss: 6.21141242980957
Validation loss: 5.8747484760899695

Epoch: 5| Step: 1
Training loss: 5.849170684814453
Validation loss: 5.8675713539123535

Epoch: 5| Step: 2
Training loss: 6.5992631912231445
Validation loss: 5.853935323735719

Epoch: 5| Step: 3
Training loss: 5.826709747314453
Validation loss: 5.846474493703535

Epoch: 5| Step: 4
Training loss: 5.230769157409668
Validation loss: 5.8361897468566895

Epoch: 5| Step: 5
Training loss: 4.9639692306518555
Validation loss: 5.827624028728854

Epoch: 5| Step: 6
Training loss: 5.736563205718994
Validation loss: 5.819730081865864

Epoch: 5| Step: 7
Training loss: 6.2212653160095215
Validation loss: 5.808490030227169

Epoch: 5| Step: 8
Training loss: 5.350308895111084
Validation loss: 5.800721204409036

Epoch: 5| Step: 9
Training loss: 4.067401885986328
Validation loss: 5.790591270692887

Epoch: 5| Step: 10
Training loss: 5.677693843841553
Validation loss: 5.780699893992434

Epoch: 8| Step: 0
Training loss: 5.09643030166626
Validation loss: 5.767685782524847

Epoch: 5| Step: 1
Training loss: 5.71085262298584
Validation loss: 5.760526923723118

Epoch: 5| Step: 2
Training loss: 6.057878494262695
Validation loss: 5.748420874277751

Epoch: 5| Step: 3
Training loss: 5.6435089111328125
Validation loss: 5.737424763300085

Epoch: 5| Step: 4
Training loss: 5.969565391540527
Validation loss: 5.732413291931152

Epoch: 5| Step: 5
Training loss: 5.62131404876709
Validation loss: 5.720406506651191

Epoch: 5| Step: 6
Training loss: 5.1507415771484375
Validation loss: 5.709357979477093

Epoch: 5| Step: 7
Training loss: 5.624669075012207
Validation loss: 5.7012109141195975

Epoch: 5| Step: 8
Training loss: 5.792471885681152
Validation loss: 5.686135086961972

Epoch: 5| Step: 9
Training loss: 4.932189464569092
Validation loss: 5.677410530787642

Epoch: 5| Step: 10
Training loss: 4.806564807891846
Validation loss: 5.667598929456485

Epoch: 9| Step: 0
Training loss: 4.691974639892578
Validation loss: 5.655509087347215

Epoch: 5| Step: 1
Training loss: 5.742565155029297
Validation loss: 5.64064048951672

Epoch: 5| Step: 2
Training loss: 4.9678215980529785
Validation loss: 5.632038998347457

Epoch: 5| Step: 3
Training loss: 4.738556861877441
Validation loss: 5.619732641404675

Epoch: 5| Step: 4
Training loss: 5.391558647155762
Validation loss: 5.609449094341647

Epoch: 5| Step: 5
Training loss: 3.7840213775634766
Validation loss: 5.596883435403147

Epoch: 5| Step: 6
Training loss: 5.25662899017334
Validation loss: 5.58561582462762

Epoch: 5| Step: 7
Training loss: 6.766332149505615
Validation loss: 5.57539867072977

Epoch: 5| Step: 8
Training loss: 5.5210466384887695
Validation loss: 5.561892412042105

Epoch: 5| Step: 9
Training loss: 6.966279029846191
Validation loss: 5.547051593821536

Epoch: 5| Step: 10
Training loss: 5.239928245544434
Validation loss: 5.537352664496309

Epoch: 10| Step: 0
Training loss: 5.025914669036865
Validation loss: 5.522652882401661

Epoch: 5| Step: 1
Training loss: 5.7922163009643555
Validation loss: 5.5096886542535595

Epoch: 5| Step: 2
Training loss: 5.7673845291137695
Validation loss: 5.492659748241466

Epoch: 5| Step: 3
Training loss: 5.970738410949707
Validation loss: 5.48053975259104

Epoch: 5| Step: 4
Training loss: 4.1486334800720215
Validation loss: 5.468494112773608

Epoch: 5| Step: 5
Training loss: 5.0854811668396
Validation loss: 5.458003700420421

Epoch: 5| Step: 6
Training loss: 5.276405334472656
Validation loss: 5.438705264881093

Epoch: 5| Step: 7
Training loss: 5.469688415527344
Validation loss: 5.427297156344178

Epoch: 5| Step: 8
Training loss: 5.052377223968506
Validation loss: 5.410245008366083

Epoch: 5| Step: 9
Training loss: 5.8054046630859375
Validation loss: 5.396507550311345

Epoch: 5| Step: 10
Training loss: 3.900075674057007
Validation loss: 5.382972466048374

Epoch: 11| Step: 0
Training loss: 5.270028114318848
Validation loss: 5.366113585810507

Epoch: 5| Step: 1
Training loss: 5.464613914489746
Validation loss: 5.352509908778693

Epoch: 5| Step: 2
Training loss: 6.159803867340088
Validation loss: 5.3396940385141685

Epoch: 5| Step: 3
Training loss: 4.479206085205078
Validation loss: 5.320565167293753

Epoch: 5| Step: 4
Training loss: 3.6731326580047607
Validation loss: 5.2997429191425285

Epoch: 5| Step: 5
Training loss: 6.782086372375488
Validation loss: 5.291351420905

Epoch: 5| Step: 6
Training loss: 4.9084858894348145
Validation loss: 5.27079721676406

Epoch: 5| Step: 7
Training loss: 5.172911167144775
Validation loss: 5.2575849307480675

Epoch: 5| Step: 8
Training loss: 4.449301719665527
Validation loss: 5.237905199809741

Epoch: 5| Step: 9
Training loss: 4.826155662536621
Validation loss: 5.221653000000985

Epoch: 5| Step: 10
Training loss: 4.3155517578125
Validation loss: 5.20033287232922

Epoch: 12| Step: 0
Training loss: 5.0636773109436035
Validation loss: 5.1835987490992395

Epoch: 5| Step: 1
Training loss: 5.00762414932251
Validation loss: 5.165797310490762

Epoch: 5| Step: 2
Training loss: 4.361697673797607
Validation loss: 5.146359264209706

Epoch: 5| Step: 3
Training loss: 4.856869697570801
Validation loss: 5.126981894175212

Epoch: 5| Step: 4
Training loss: 4.962800025939941
Validation loss: 5.11671947151102

Epoch: 5| Step: 5
Training loss: 5.862763404846191
Validation loss: 5.093782927400323

Epoch: 5| Step: 6
Training loss: 4.3124213218688965
Validation loss: 5.073087989643056

Epoch: 5| Step: 7
Training loss: 4.481147289276123
Validation loss: 5.050302228619976

Epoch: 5| Step: 8
Training loss: 4.151418685913086
Validation loss: 5.031766135205505

Epoch: 5| Step: 9
Training loss: 4.779630184173584
Validation loss: 5.009663981776083

Epoch: 5| Step: 10
Training loss: 5.768657207489014
Validation loss: 4.989254736131238

Epoch: 13| Step: 0
Training loss: 5.260622501373291
Validation loss: 4.9732803734399935

Epoch: 5| Step: 1
Training loss: 5.275068759918213
Validation loss: 4.948578491005846

Epoch: 5| Step: 2
Training loss: 3.8927512168884277
Validation loss: 4.929263735330233

Epoch: 5| Step: 3
Training loss: 5.529795169830322
Validation loss: 4.9114234729479715

Epoch: 5| Step: 4
Training loss: 4.000248908996582
Validation loss: 4.889019176524172

Epoch: 5| Step: 5
Training loss: 3.6369566917419434
Validation loss: 4.868239248952558

Epoch: 5| Step: 6
Training loss: 4.698474884033203
Validation loss: 4.847799578020649

Epoch: 5| Step: 7
Training loss: 4.739136219024658
Validation loss: 4.818330052078411

Epoch: 5| Step: 8
Training loss: 4.9113054275512695
Validation loss: 4.808347681517242

Epoch: 5| Step: 9
Training loss: 4.1050519943237305
Validation loss: 4.779643556123139

Epoch: 5| Step: 10
Training loss: 4.917890548706055
Validation loss: 4.757729940516974

Epoch: 14| Step: 0
Training loss: 5.681674003601074
Validation loss: 4.737740675608317

Epoch: 5| Step: 1
Training loss: 3.990682601928711
Validation loss: 4.7155991754224225

Epoch: 5| Step: 2
Training loss: 4.381133079528809
Validation loss: 4.69287799250695

Epoch: 5| Step: 3
Training loss: 4.482169151306152
Validation loss: 4.664972274534164

Epoch: 5| Step: 4
Training loss: 4.583807945251465
Validation loss: 4.63946848018195

Epoch: 5| Step: 5
Training loss: 4.077854633331299
Validation loss: 4.623423643009637

Epoch: 5| Step: 6
Training loss: 2.72428297996521
Validation loss: 4.59575988400367

Epoch: 5| Step: 7
Training loss: 4.587680339813232
Validation loss: 4.570862918771724

Epoch: 5| Step: 8
Training loss: 4.748710632324219
Validation loss: 4.545602362643006

Epoch: 5| Step: 9
Training loss: 4.695810794830322
Validation loss: 4.518070825966456

Epoch: 5| Step: 10
Training loss: 4.25945520401001
Validation loss: 4.497777595314928

Epoch: 15| Step: 0
Training loss: 3.873478651046753
Validation loss: 4.469928946546329

Epoch: 5| Step: 1
Training loss: 4.237721920013428
Validation loss: 4.4461018757153585

Epoch: 5| Step: 2
Training loss: 3.512892961502075
Validation loss: 4.413597491479689

Epoch: 5| Step: 3
Training loss: 4.11069393157959
Validation loss: 4.394746421485819

Epoch: 5| Step: 4
Training loss: 5.107668876647949
Validation loss: 4.361927719526394

Epoch: 5| Step: 5
Training loss: 3.149561882019043
Validation loss: 4.338489106906358

Epoch: 5| Step: 6
Training loss: 4.506608486175537
Validation loss: 4.305284987213791

Epoch: 5| Step: 7
Training loss: 3.0372228622436523
Validation loss: 4.273624989294237

Epoch: 5| Step: 8
Training loss: 3.296260118484497
Validation loss: 4.25469502582345

Epoch: 5| Step: 9
Training loss: 5.562474250793457
Validation loss: 4.232183082129366

Epoch: 5| Step: 10
Training loss: 4.937905788421631
Validation loss: 4.203802203619352

Epoch: 16| Step: 0
Training loss: 4.225491523742676
Validation loss: 4.175046167066021

Epoch: 5| Step: 1
Training loss: 4.375796318054199
Validation loss: 4.147598171746859

Epoch: 5| Step: 2
Training loss: 4.321341514587402
Validation loss: 4.122639081811392

Epoch: 5| Step: 3
Training loss: 4.5042924880981445
Validation loss: 4.0903402656637216

Epoch: 5| Step: 4
Training loss: 3.828345775604248
Validation loss: 4.054808629456387

Epoch: 5| Step: 5
Training loss: 3.5900986194610596
Validation loss: 4.038264228451636

Epoch: 5| Step: 6
Training loss: 2.627260684967041
Validation loss: 4.00891036628395

Epoch: 5| Step: 7
Training loss: 4.165899276733398
Validation loss: 3.97870740326502

Epoch: 5| Step: 8
Training loss: 3.0546035766601562
Validation loss: 3.9541069743453816

Epoch: 5| Step: 9
Training loss: 4.194858074188232
Validation loss: 3.9233918933458227

Epoch: 5| Step: 10
Training loss: 3.303499698638916
Validation loss: 3.900996110772574

Epoch: 17| Step: 0
Training loss: 4.111153602600098
Validation loss: 3.884384257819063

Epoch: 5| Step: 1
Training loss: 4.597007751464844
Validation loss: 3.8389100259350193

Epoch: 5| Step: 2
Training loss: 3.7487735748291016
Validation loss: 3.812504470989268

Epoch: 5| Step: 3
Training loss: 3.3248443603515625
Validation loss: 3.79478818626814

Epoch: 5| Step: 4
Training loss: 5.220603942871094
Validation loss: 3.7649124258308

Epoch: 5| Step: 5
Training loss: 2.8307032585144043
Validation loss: 3.734962647961032

Epoch: 5| Step: 6
Training loss: 3.7548489570617676
Validation loss: 3.708491345887543

Epoch: 5| Step: 7
Training loss: 3.0129268169403076
Validation loss: 3.682045659711284

Epoch: 5| Step: 8
Training loss: 2.7109508514404297
Validation loss: 3.6534981061053533

Epoch: 5| Step: 9
Training loss: 3.325481414794922
Validation loss: 3.6321908632914224

Epoch: 5| Step: 10
Training loss: 2.7898547649383545
Validation loss: 3.604675862096971

Epoch: 18| Step: 0
Training loss: 3.593651294708252
Validation loss: 3.5848773371788765

Epoch: 5| Step: 1
Training loss: 2.598180055618286
Validation loss: 3.545060275703348

Epoch: 5| Step: 2
Training loss: 4.026541709899902
Validation loss: 3.5331781115583194

Epoch: 5| Step: 3
Training loss: 3.7708897590637207
Validation loss: 3.4994864873988654

Epoch: 5| Step: 4
Training loss: 3.1118407249450684
Validation loss: 3.4777890456620084

Epoch: 5| Step: 5
Training loss: 3.511226177215576
Validation loss: 3.456931109069496

Epoch: 5| Step: 6
Training loss: 2.521282911300659
Validation loss: 3.4196603580187728

Epoch: 5| Step: 7
Training loss: 3.9666686058044434
Validation loss: 3.401777426401774

Epoch: 5| Step: 8
Training loss: 3.2716660499572754
Validation loss: 3.3682049653863393

Epoch: 5| Step: 9
Training loss: 3.27020525932312
Validation loss: 3.3414377268924507

Epoch: 5| Step: 10
Training loss: 3.08735990524292
Validation loss: 3.3054780626809723

Epoch: 19| Step: 0
Training loss: 2.893070697784424
Validation loss: 3.292116544579947

Epoch: 5| Step: 1
Training loss: 3.6800551414489746
Validation loss: 3.252938832006147

Epoch: 5| Step: 2
Training loss: 2.6429598331451416
Validation loss: 3.245461861292521

Epoch: 5| Step: 3
Training loss: 2.6001386642456055
Validation loss: 3.223769772437311

Epoch: 5| Step: 4
Training loss: 2.944152593612671
Validation loss: 3.1873192120623846

Epoch: 5| Step: 5
Training loss: 3.169586181640625
Validation loss: 3.168815110319404

Epoch: 5| Step: 6
Training loss: 3.529811143875122
Validation loss: 3.1553163784806446

Epoch: 5| Step: 7
Training loss: 2.944570779800415
Validation loss: 3.1209245856090257

Epoch: 5| Step: 8
Training loss: 3.1954429149627686
Validation loss: 3.107204137309905

Epoch: 5| Step: 9
Training loss: 3.11838436126709
Validation loss: 3.0762286263127483

Epoch: 5| Step: 10
Training loss: 3.6064720153808594
Validation loss: 3.0619603023734143

Epoch: 20| Step: 0
Training loss: 3.5281033515930176
Validation loss: 3.031649287028979

Epoch: 5| Step: 1
Training loss: 2.6059069633483887
Validation loss: 3.0104469330080095

Epoch: 5| Step: 2
Training loss: 2.4747469425201416
Validation loss: 2.9930605016728884

Epoch: 5| Step: 3
Training loss: 3.713390350341797
Validation loss: 2.9814551773891655

Epoch: 5| Step: 4
Training loss: 3.6886696815490723
Validation loss: 2.9506247915247434

Epoch: 5| Step: 5
Training loss: 3.233952283859253
Validation loss: 2.9146695854843303

Epoch: 5| Step: 6
Training loss: 2.8707146644592285
Validation loss: 2.8900067831880305

Epoch: 5| Step: 7
Training loss: 3.0172905921936035
Validation loss: 2.8792702638974754

Epoch: 5| Step: 8
Training loss: 2.250325918197632
Validation loss: 2.851048905362365

Epoch: 5| Step: 9
Training loss: 2.442565679550171
Validation loss: 2.8414737793707077

Epoch: 5| Step: 10
Training loss: 2.8721256256103516
Validation loss: 2.819880784198802

Epoch: 21| Step: 0
Training loss: 3.4391274452209473
Validation loss: 2.7998213306550057

Epoch: 5| Step: 1
Training loss: 2.9980921745300293
Validation loss: 2.7857064816259567

Epoch: 5| Step: 2
Training loss: 2.3923325538635254
Validation loss: 2.760940992704002

Epoch: 5| Step: 3
Training loss: 2.753721237182617
Validation loss: 2.7310553340501684

Epoch: 5| Step: 4
Training loss: 2.9193012714385986
Validation loss: 2.7186904594462407

Epoch: 5| Step: 5
Training loss: 3.230738878250122
Validation loss: 2.72047931660888

Epoch: 5| Step: 6
Training loss: 2.588130235671997
Validation loss: 2.6948118799476215

Epoch: 5| Step: 7
Training loss: 2.9885528087615967
Validation loss: 2.6730346192595777

Epoch: 5| Step: 8
Training loss: 3.0367136001586914
Validation loss: 2.649512488354919

Epoch: 5| Step: 9
Training loss: 2.2825779914855957
Validation loss: 2.6475749092717327

Epoch: 5| Step: 10
Training loss: 2.266782522201538
Validation loss: 2.622620290325534

Epoch: 22| Step: 0
Training loss: 3.242293119430542
Validation loss: 2.6227867218755905

Epoch: 5| Step: 1
Training loss: 2.2899036407470703
Validation loss: 2.594793906775854

Epoch: 5| Step: 2
Training loss: 2.9993929862976074
Validation loss: 2.550774147433619

Epoch: 5| Step: 3
Training loss: 2.531057596206665
Validation loss: 2.5558586428242345

Epoch: 5| Step: 4
Training loss: 2.3158047199249268
Validation loss: 2.5374487625655306

Epoch: 5| Step: 5
Training loss: 2.479188919067383
Validation loss: 2.525224224213631

Epoch: 5| Step: 6
Training loss: 2.6267898082733154
Validation loss: 2.509782047681911

Epoch: 5| Step: 7
Training loss: 2.2029385566711426
Validation loss: 2.500059643099385

Epoch: 5| Step: 8
Training loss: 2.8237833976745605
Validation loss: 2.4738710413696947

Epoch: 5| Step: 9
Training loss: 2.7664074897766113
Validation loss: 2.4786304197003766

Epoch: 5| Step: 10
Training loss: 3.449066162109375
Validation loss: 2.4660782506389003

Epoch: 23| Step: 0
Training loss: 2.182795286178589
Validation loss: 2.449973862658265

Epoch: 5| Step: 1
Training loss: 2.0487217903137207
Validation loss: 2.4436828782481532

Epoch: 5| Step: 2
Training loss: 3.259821653366089
Validation loss: 2.4382015479508268

Epoch: 5| Step: 3
Training loss: 2.261549472808838
Validation loss: 2.411723388138638

Epoch: 5| Step: 4
Training loss: 2.726602554321289
Validation loss: 2.4028119028255506

Epoch: 5| Step: 5
Training loss: 2.655367374420166
Validation loss: 2.4165894421198035

Epoch: 5| Step: 6
Training loss: 2.669572353363037
Validation loss: 2.401181859354819

Epoch: 5| Step: 7
Training loss: 3.4833807945251465
Validation loss: 2.388085457586473

Epoch: 5| Step: 8
Training loss: 2.5756027698516846
Validation loss: 2.3670758021775113

Epoch: 5| Step: 9
Training loss: 2.1964805126190186
Validation loss: 2.3642343449336227

Epoch: 5| Step: 10
Training loss: 2.5110926628112793
Validation loss: 2.355989630504321

Epoch: 24| Step: 0
Training loss: 2.642254590988159
Validation loss: 2.3622380020797893

Epoch: 5| Step: 1
Training loss: 2.7748396396636963
Validation loss: 2.3355034269312376

Epoch: 5| Step: 2
Training loss: 2.019545316696167
Validation loss: 2.353631624611475

Epoch: 5| Step: 3
Training loss: 2.4368882179260254
Validation loss: 2.3190488353852303

Epoch: 5| Step: 4
Training loss: 2.9156641960144043
Validation loss: 2.32516158780744

Epoch: 5| Step: 5
Training loss: 2.5699028968811035
Validation loss: 2.321840483655212

Epoch: 5| Step: 6
Training loss: 2.3463547229766846
Validation loss: 2.2984870441498293

Epoch: 5| Step: 7
Training loss: 1.9600826501846313
Validation loss: 2.3140851477141022

Epoch: 5| Step: 8
Training loss: 2.164155960083008
Validation loss: 2.314419433634768

Epoch: 5| Step: 9
Training loss: 2.976539373397827
Validation loss: 2.308022047883721

Epoch: 5| Step: 10
Training loss: 3.439690113067627
Validation loss: 2.305652477407968

Epoch: 25| Step: 0
Training loss: 2.9110379219055176
Validation loss: 2.299572860040972

Epoch: 5| Step: 1
Training loss: 2.5043282508850098
Validation loss: 2.289119435894874

Epoch: 5| Step: 2
Training loss: 2.5777034759521484
Validation loss: 2.2835224828412457

Epoch: 5| Step: 3
Training loss: 1.6979379653930664
Validation loss: 2.2902735766544136

Epoch: 5| Step: 4
Training loss: 2.1685187816619873
Validation loss: 2.2787953192187893

Epoch: 5| Step: 5
Training loss: 2.462819814682007
Validation loss: 2.2867239675214215

Epoch: 5| Step: 6
Training loss: 2.703090190887451
Validation loss: 2.284246003755959

Epoch: 5| Step: 7
Training loss: 2.232736587524414
Validation loss: 2.2898785939780613

Epoch: 5| Step: 8
Training loss: 3.1207079887390137
Validation loss: 2.264496067518829

Epoch: 5| Step: 9
Training loss: 2.330968141555786
Validation loss: 2.270250948526526

Epoch: 5| Step: 10
Training loss: 3.1998684406280518
Validation loss: 2.257494103523993

Epoch: 26| Step: 0
Training loss: 1.9543918371200562
Validation loss: 2.268220240069974

Epoch: 5| Step: 1
Training loss: 3.216960906982422
Validation loss: 2.243537192703575

Epoch: 5| Step: 2
Training loss: 2.355259656906128
Validation loss: 2.250040235057954

Epoch: 5| Step: 3
Training loss: 2.9711170196533203
Validation loss: 2.248277066856302

Epoch: 5| Step: 4
Training loss: 2.9888453483581543
Validation loss: 2.2557765053164576

Epoch: 5| Step: 5
Training loss: 2.69684100151062
Validation loss: 2.248133441453339

Epoch: 5| Step: 6
Training loss: 1.9654394388198853
Validation loss: 2.2213331858317056

Epoch: 5| Step: 7
Training loss: 2.53546142578125
Validation loss: 2.225530929462884

Epoch: 5| Step: 8
Training loss: 2.2641096115112305
Validation loss: 2.2225914360374532

Epoch: 5| Step: 9
Training loss: 2.2954859733581543
Validation loss: 2.237375932355081

Epoch: 5| Step: 10
Training loss: 2.369450330734253
Validation loss: 2.27012615050039

Epoch: 27| Step: 0
Training loss: 2.9272208213806152
Validation loss: 2.2148737830500447

Epoch: 5| Step: 1
Training loss: 2.4585211277008057
Validation loss: 2.2402274300975185

Epoch: 5| Step: 2
Training loss: 2.3470120429992676
Validation loss: 2.239434244812176

Epoch: 5| Step: 3
Training loss: 2.5222339630126953
Validation loss: 2.243749919758048

Epoch: 5| Step: 4
Training loss: 2.565417766571045
Validation loss: 2.220404919757638

Epoch: 5| Step: 5
Training loss: 3.2268989086151123
Validation loss: 2.227607445050311

Epoch: 5| Step: 6
Training loss: 2.372884750366211
Validation loss: 2.2241585587942474

Epoch: 5| Step: 7
Training loss: 2.596792459487915
Validation loss: 2.2187802919777493

Epoch: 5| Step: 8
Training loss: 2.425020694732666
Validation loss: 2.2087168155177945

Epoch: 5| Step: 9
Training loss: 2.1827359199523926
Validation loss: 2.217927461029381

Epoch: 5| Step: 10
Training loss: 2.0538623332977295
Validation loss: 2.2350168394786056

Epoch: 28| Step: 0
Training loss: 2.7525458335876465
Validation loss: 2.2322028452350247

Epoch: 5| Step: 1
Training loss: 2.5580058097839355
Validation loss: 2.2226090174849316

Epoch: 5| Step: 2
Training loss: 2.490116834640503
Validation loss: 2.2278439460262174

Epoch: 5| Step: 3
Training loss: 1.9508168697357178
Validation loss: 2.2257427912886425

Epoch: 5| Step: 4
Training loss: 2.398742198944092
Validation loss: 2.2147431501778225

Epoch: 5| Step: 5
Training loss: 2.15556001663208
Validation loss: 2.2203706015822706

Epoch: 5| Step: 6
Training loss: 3.075421094894409
Validation loss: 2.2242473453603764

Epoch: 5| Step: 7
Training loss: 3.1236777305603027
Validation loss: 2.2126374783054477

Epoch: 5| Step: 8
Training loss: 2.2933247089385986
Validation loss: 2.2225090444728894

Epoch: 5| Step: 9
Training loss: 2.3503894805908203
Validation loss: 2.231761975954938

Epoch: 5| Step: 10
Training loss: 2.430525541305542
Validation loss: 2.223349319991245

Epoch: 29| Step: 0
Training loss: 2.304624080657959
Validation loss: 2.186655053528406

Epoch: 5| Step: 1
Training loss: 3.185783863067627
Validation loss: 2.2028833666155414

Epoch: 5| Step: 2
Training loss: 2.2924137115478516
Validation loss: 2.218889546650712

Epoch: 5| Step: 3
Training loss: 2.039179563522339
Validation loss: 2.219330938913489

Epoch: 5| Step: 4
Training loss: 2.4997522830963135
Validation loss: 2.214468671429542

Epoch: 5| Step: 5
Training loss: 2.697659730911255
Validation loss: 2.2286390822420836

Epoch: 5| Step: 6
Training loss: 2.6348297595977783
Validation loss: 2.213393037037183

Epoch: 5| Step: 7
Training loss: 3.15014386177063
Validation loss: 2.2164953344611713

Epoch: 5| Step: 8
Training loss: 2.9679839611053467
Validation loss: 2.2042893696856756

Epoch: 5| Step: 9
Training loss: 2.1388025283813477
Validation loss: 2.2269635828592445

Epoch: 5| Step: 10
Training loss: 1.5122780799865723
Validation loss: 2.2431416716626895

Epoch: 30| Step: 0
Training loss: 2.7764792442321777
Validation loss: 2.2245066217196885

Epoch: 5| Step: 1
Training loss: 2.614361047744751
Validation loss: 2.1978410725952475

Epoch: 5| Step: 2
Training loss: 1.8215631246566772
Validation loss: 2.237559897925264

Epoch: 5| Step: 3
Training loss: 2.2802348136901855
Validation loss: 2.208882483102942

Epoch: 5| Step: 4
Training loss: 2.791971445083618
Validation loss: 2.221582123028335

Epoch: 5| Step: 5
Training loss: 2.545611619949341
Validation loss: 2.217846542276362

Epoch: 5| Step: 6
Training loss: 2.529207706451416
Validation loss: 2.2194639713533464

Epoch: 5| Step: 7
Training loss: 2.8705894947052
Validation loss: 2.2173850946528937

Epoch: 5| Step: 8
Training loss: 2.209841251373291
Validation loss: 2.219718115304106

Epoch: 5| Step: 9
Training loss: 2.3879730701446533
Validation loss: 2.1950066333175986

Epoch: 5| Step: 10
Training loss: 2.547506332397461
Validation loss: 2.224715886577483

Epoch: 31| Step: 0
Training loss: 2.623081922531128
Validation loss: 2.220749662768456

Epoch: 5| Step: 1
Training loss: 2.651747465133667
Validation loss: 2.218681311094633

Epoch: 5| Step: 2
Training loss: 1.9695533514022827
Validation loss: 2.212823483251756

Epoch: 5| Step: 3
Training loss: 1.712620496749878
Validation loss: 2.215101544575025

Epoch: 5| Step: 4
Training loss: 2.664870262145996
Validation loss: 2.1776808820744997

Epoch: 5| Step: 5
Training loss: 2.991499423980713
Validation loss: 2.1954600195730887

Epoch: 5| Step: 6
Training loss: 2.8338637351989746
Validation loss: 2.2095958981462704

Epoch: 5| Step: 7
Training loss: 2.416231393814087
Validation loss: 2.205406171019359

Epoch: 5| Step: 8
Training loss: 2.545069932937622
Validation loss: 2.20505371914115

Epoch: 5| Step: 9
Training loss: 2.121932029724121
Validation loss: 2.192615879479275

Epoch: 5| Step: 10
Training loss: 2.7733118534088135
Validation loss: 2.193312329630698

Epoch: 32| Step: 0
Training loss: 2.1738598346710205
Validation loss: 2.1986339040981826

Epoch: 5| Step: 1
Training loss: 2.4869143962860107
Validation loss: 2.1997538740916918

Epoch: 5| Step: 2
Training loss: 2.0136146545410156
Validation loss: 2.1782643307921705

Epoch: 5| Step: 3
Training loss: 2.703108310699463
Validation loss: 2.197304576955816

Epoch: 5| Step: 4
Training loss: 2.4060873985290527
Validation loss: 2.182295383945588

Epoch: 5| Step: 5
Training loss: 2.459355592727661
Validation loss: 2.1903564058324343

Epoch: 5| Step: 6
Training loss: 2.770270586013794
Validation loss: 2.1872678085040023

Epoch: 5| Step: 7
Training loss: 2.7092742919921875
Validation loss: 2.183088981977073

Epoch: 5| Step: 8
Training loss: 2.1314892768859863
Validation loss: 2.2099395131552093

Epoch: 5| Step: 9
Training loss: 2.860522985458374
Validation loss: 2.1854751033167683

Epoch: 5| Step: 10
Training loss: 2.533491849899292
Validation loss: 2.2096971004239974

Epoch: 33| Step: 0
Training loss: 2.438354969024658
Validation loss: 2.1950664930446173

Epoch: 5| Step: 1
Training loss: 2.3696506023406982
Validation loss: 2.1834331404778267

Epoch: 5| Step: 2
Training loss: 2.7466306686401367
Validation loss: 2.198649219287339

Epoch: 5| Step: 3
Training loss: 2.4578042030334473
Validation loss: 2.200358900972592

Epoch: 5| Step: 4
Training loss: 2.9388651847839355
Validation loss: 2.2032260907593595

Epoch: 5| Step: 5
Training loss: 2.1305675506591797
Validation loss: 2.1784302547413814

Epoch: 5| Step: 6
Training loss: 1.8886134624481201
Validation loss: 2.2041611491992907

Epoch: 5| Step: 7
Training loss: 3.1306424140930176
Validation loss: 2.1796015539476947

Epoch: 5| Step: 8
Training loss: 2.117885112762451
Validation loss: 2.195464769999186

Epoch: 5| Step: 9
Training loss: 2.7380504608154297
Validation loss: 2.1833367911718224

Epoch: 5| Step: 10
Training loss: 2.1300458908081055
Validation loss: 2.2014720311728855

Epoch: 34| Step: 0
Training loss: 2.8641514778137207
Validation loss: 2.191876665238411

Epoch: 5| Step: 1
Training loss: 2.0754122734069824
Validation loss: 2.18439499280786

Epoch: 5| Step: 2
Training loss: 2.3050425052642822
Validation loss: 2.1900199228717434

Epoch: 5| Step: 3
Training loss: 1.9299652576446533
Validation loss: 2.1765942778638614

Epoch: 5| Step: 4
Training loss: 2.4478771686553955
Validation loss: 2.1769854278974634

Epoch: 5| Step: 5
Training loss: 3.143768072128296
Validation loss: 2.187659825048139

Epoch: 5| Step: 6
Training loss: 2.167842149734497
Validation loss: 2.176766341732394

Epoch: 5| Step: 7
Training loss: 2.3020825386047363
Validation loss: 2.1837519958455074

Epoch: 5| Step: 8
Training loss: 2.4174017906188965
Validation loss: 2.176705789822404

Epoch: 5| Step: 9
Training loss: 3.036905288696289
Validation loss: 2.1789368634582846

Epoch: 5| Step: 10
Training loss: 2.5154621601104736
Validation loss: 2.1775171397834696

Epoch: 35| Step: 0
Training loss: 2.6122934818267822
Validation loss: 2.1600415962998585

Epoch: 5| Step: 1
Training loss: 1.9140517711639404
Validation loss: 2.140612353560745

Epoch: 5| Step: 2
Training loss: 2.0112669467926025
Validation loss: 2.183579250048566

Epoch: 5| Step: 3
Training loss: 2.9480159282684326
Validation loss: 2.1629393895467124

Epoch: 5| Step: 4
Training loss: 2.6207380294799805
Validation loss: 2.169722239176432

Epoch: 5| Step: 5
Training loss: 2.803950309753418
Validation loss: 2.1849187266442085

Epoch: 5| Step: 6
Training loss: 2.22672963142395
Validation loss: 2.1931619900529102

Epoch: 5| Step: 7
Training loss: 3.052131175994873
Validation loss: 2.191939192433511

Epoch: 5| Step: 8
Training loss: 2.5159459114074707
Validation loss: 2.1710158086592153

Epoch: 5| Step: 9
Training loss: 2.122730255126953
Validation loss: 2.1768597838699177

Epoch: 5| Step: 10
Training loss: 2.177574396133423
Validation loss: 2.1631975763587543

Epoch: 36| Step: 0
Training loss: 2.618401527404785
Validation loss: 2.1752081224995274

Epoch: 5| Step: 1
Training loss: 2.493868589401245
Validation loss: 2.1754341471579766

Epoch: 5| Step: 2
Training loss: 2.7411909103393555
Validation loss: 2.1731718765792025

Epoch: 5| Step: 3
Training loss: 2.1265320777893066
Validation loss: 2.1719659912970757

Epoch: 5| Step: 4
Training loss: 2.00854229927063
Validation loss: 2.1835091062771377

Epoch: 5| Step: 5
Training loss: 2.984891176223755
Validation loss: 2.1626630393407678

Epoch: 5| Step: 6
Training loss: 2.762108564376831
Validation loss: 2.1569447671213458

Epoch: 5| Step: 7
Training loss: 1.9322316646575928
Validation loss: 2.144774998387983

Epoch: 5| Step: 8
Training loss: 2.2693963050842285
Validation loss: 2.1751246657422794

Epoch: 5| Step: 9
Training loss: 2.6067943572998047
Validation loss: 2.168254711294687

Epoch: 5| Step: 10
Training loss: 2.2720069885253906
Validation loss: 2.175034846028974

Epoch: 37| Step: 0
Training loss: 2.7400949001312256
Validation loss: 2.1674834143730903

Epoch: 5| Step: 1
Training loss: 2.5195045471191406
Validation loss: 2.164310746295478

Epoch: 5| Step: 2
Training loss: 2.179107666015625
Validation loss: 2.1577429438150055

Epoch: 5| Step: 3
Training loss: 1.9340368509292603
Validation loss: 2.177539801084867

Epoch: 5| Step: 4
Training loss: 2.5181949138641357
Validation loss: 2.167787040433576

Epoch: 5| Step: 5
Training loss: 2.9379079341888428
Validation loss: 2.162212194934968

Epoch: 5| Step: 6
Training loss: 2.0147628784179688
Validation loss: 2.146234784075009

Epoch: 5| Step: 7
Training loss: 2.2993969917297363
Validation loss: 2.1561254198833177

Epoch: 5| Step: 8
Training loss: 1.8772128820419312
Validation loss: 2.1553714634269796

Epoch: 5| Step: 9
Training loss: 3.2026374340057373
Validation loss: 2.175818177961534

Epoch: 5| Step: 10
Training loss: 2.7124104499816895
Validation loss: 2.1537513604728122

Epoch: 38| Step: 0
Training loss: 1.8716360330581665
Validation loss: 2.1266478620549685

Epoch: 5| Step: 1
Training loss: 1.9407832622528076
Validation loss: 2.1494912024467223

Epoch: 5| Step: 2
Training loss: 2.494542121887207
Validation loss: 2.1375123557224067

Epoch: 5| Step: 3
Training loss: 2.4317736625671387
Validation loss: 2.153654288220149

Epoch: 5| Step: 4
Training loss: 2.7001452445983887
Validation loss: 2.1417331746829453

Epoch: 5| Step: 5
Training loss: 2.6769721508026123
Validation loss: 2.155547939321046

Epoch: 5| Step: 6
Training loss: 2.7981839179992676
Validation loss: 2.159358086124543

Epoch: 5| Step: 7
Training loss: 2.501084089279175
Validation loss: 2.135385436396445

Epoch: 5| Step: 8
Training loss: 1.9393278360366821
Validation loss: 2.1473647625215593

Epoch: 5| Step: 9
Training loss: 2.7780354022979736
Validation loss: 2.148090121566608

Epoch: 5| Step: 10
Training loss: 2.6449592113494873
Validation loss: 2.135290886766167

Epoch: 39| Step: 0
Training loss: 2.5359301567077637
Validation loss: 2.141070632524388

Epoch: 5| Step: 1
Training loss: 2.597771644592285
Validation loss: 2.1422901230473674

Epoch: 5| Step: 2
Training loss: 3.6345221996307373
Validation loss: 2.153867554920976

Epoch: 5| Step: 3
Training loss: 2.8145527839660645
Validation loss: 2.1460074634962183

Epoch: 5| Step: 4
Training loss: 2.5451266765594482
Validation loss: 2.168638995898667

Epoch: 5| Step: 5
Training loss: 2.0800867080688477
Validation loss: 2.1660969667537238

Epoch: 5| Step: 6
Training loss: 2.0272629261016846
Validation loss: 2.15784461780261

Epoch: 5| Step: 7
Training loss: 2.1466002464294434
Validation loss: 2.1714060793640795

Epoch: 5| Step: 8
Training loss: 2.0380356311798096
Validation loss: 2.1564013983613703

Epoch: 5| Step: 9
Training loss: 2.115978240966797
Validation loss: 2.138402223587036

Epoch: 5| Step: 10
Training loss: 2.3137049674987793
Validation loss: 2.159850489708685

Epoch: 40| Step: 0
Training loss: 2.670562267303467
Validation loss: 2.147474355595086

Epoch: 5| Step: 1
Training loss: 2.613109588623047
Validation loss: 2.1418152316924064

Epoch: 5| Step: 2
Training loss: 2.8950886726379395
Validation loss: 2.168657572038712

Epoch: 5| Step: 3
Training loss: 2.3634259700775146
Validation loss: 2.144463159704721

Epoch: 5| Step: 4
Training loss: 2.16041898727417
Validation loss: 2.162733639440229

Epoch: 5| Step: 5
Training loss: 2.1689279079437256
Validation loss: 2.17617751449667

Epoch: 5| Step: 6
Training loss: 2.3717808723449707
Validation loss: 2.135034981594291

Epoch: 5| Step: 7
Training loss: 2.1118156909942627
Validation loss: 2.1261426787222586

Epoch: 5| Step: 8
Training loss: 2.5331344604492188
Validation loss: 2.1466470943984164

Epoch: 5| Step: 9
Training loss: 2.5302340984344482
Validation loss: 2.118170310092229

Epoch: 5| Step: 10
Training loss: 2.1203982830047607
Validation loss: 2.176278098937004

Epoch: 41| Step: 0
Training loss: 2.966280460357666
Validation loss: 2.140837207917244

Epoch: 5| Step: 1
Training loss: 2.421269655227661
Validation loss: 2.146883938902168

Epoch: 5| Step: 2
Training loss: 2.140225648880005
Validation loss: 2.155648082815191

Epoch: 5| Step: 3
Training loss: 2.555609941482544
Validation loss: 2.1392918184239376

Epoch: 5| Step: 4
Training loss: 1.7885265350341797
Validation loss: 2.142882422734332

Epoch: 5| Step: 5
Training loss: 2.749987840652466
Validation loss: 2.139009227034866

Epoch: 5| Step: 6
Training loss: 2.1183369159698486
Validation loss: 2.1197493153233684

Epoch: 5| Step: 7
Training loss: 2.250816822052002
Validation loss: 2.1443369644944386

Epoch: 5| Step: 8
Training loss: 2.961397409439087
Validation loss: 2.1294000469228274

Epoch: 5| Step: 9
Training loss: 2.3681037425994873
Validation loss: 2.131894803816272

Epoch: 5| Step: 10
Training loss: 2.2158737182617188
Validation loss: 2.1356442384822394

Epoch: 42| Step: 0
Training loss: 2.189222812652588
Validation loss: 2.137961382506996

Epoch: 5| Step: 1
Training loss: 2.4594099521636963
Validation loss: 2.1277793697131577

Epoch: 5| Step: 2
Training loss: 2.822509765625
Validation loss: 2.1250278462645826

Epoch: 5| Step: 3
Training loss: 2.653355598449707
Validation loss: 2.1139782192886516

Epoch: 5| Step: 4
Training loss: 3.2837307453155518
Validation loss: 2.1306574652271886

Epoch: 5| Step: 5
Training loss: 1.812544822692871
Validation loss: 2.13604078754302

Epoch: 5| Step: 6
Training loss: 2.9778785705566406
Validation loss: 2.1431299422376897

Epoch: 5| Step: 7
Training loss: 1.8300977945327759
Validation loss: 2.120458443959554

Epoch: 5| Step: 8
Training loss: 2.1654675006866455
Validation loss: 2.1219135317751157

Epoch: 5| Step: 9
Training loss: 2.4948620796203613
Validation loss: 2.1238676809495494

Epoch: 5| Step: 10
Training loss: 1.7166926860809326
Validation loss: 2.1275448619678454

Epoch: 43| Step: 0
Training loss: 2.5641746520996094
Validation loss: 2.1147177168118056

Epoch: 5| Step: 1
Training loss: 2.1022984981536865
Validation loss: 2.105105118084979

Epoch: 5| Step: 2
Training loss: 2.6193161010742188
Validation loss: 2.1430443743223786

Epoch: 5| Step: 3
Training loss: 2.097550630569458
Validation loss: 2.1244039227885585

Epoch: 5| Step: 4
Training loss: 2.504856824874878
Validation loss: 2.1192748777328

Epoch: 5| Step: 5
Training loss: 1.87178635597229
Validation loss: 2.128289138117144

Epoch: 5| Step: 6
Training loss: 2.347914218902588
Validation loss: 2.1201553626727034

Epoch: 5| Step: 7
Training loss: 2.535645008087158
Validation loss: 2.1347024902220695

Epoch: 5| Step: 8
Training loss: 2.5015575885772705
Validation loss: 2.112140231235053

Epoch: 5| Step: 9
Training loss: 2.3843889236450195
Validation loss: 2.112433106668534

Epoch: 5| Step: 10
Training loss: 2.9657461643218994
Validation loss: 2.13548179082973

Epoch: 44| Step: 0
Training loss: 2.057474136352539
Validation loss: 2.125291391085553

Epoch: 5| Step: 1
Training loss: 2.6977341175079346
Validation loss: 2.1284935756396224

Epoch: 5| Step: 2
Training loss: 2.3721201419830322
Validation loss: 2.1310284265907864

Epoch: 5| Step: 3
Training loss: 2.6732165813446045
Validation loss: 2.1133547111224105

Epoch: 5| Step: 4
Training loss: 3.0352132320404053
Validation loss: 2.1314616280217327

Epoch: 5| Step: 5
Training loss: 2.935734272003174
Validation loss: 2.141103898325274

Epoch: 5| Step: 6
Training loss: 2.2246763706207275
Validation loss: 2.1355251291746735

Epoch: 5| Step: 7
Training loss: 1.903322458267212
Validation loss: 2.140885650470693

Epoch: 5| Step: 8
Training loss: 1.851400375366211
Validation loss: 2.1310983588618617

Epoch: 5| Step: 9
Training loss: 2.281639575958252
Validation loss: 2.1101858846602903

Epoch: 5| Step: 10
Training loss: 2.575681209564209
Validation loss: 2.1571687524036696

Epoch: 45| Step: 0
Training loss: 1.94390869140625
Validation loss: 2.135484060933513

Epoch: 5| Step: 1
Training loss: 2.2846271991729736
Validation loss: 2.1373549430601058

Epoch: 5| Step: 2
Training loss: 1.9658613204956055
Validation loss: 2.1168965754970426

Epoch: 5| Step: 3
Training loss: 2.5204129219055176
Validation loss: 2.118849374914682

Epoch: 5| Step: 4
Training loss: 2.336991786956787
Validation loss: 2.1347120551652807

Epoch: 5| Step: 5
Training loss: 2.904090166091919
Validation loss: 2.123698419140231

Epoch: 5| Step: 6
Training loss: 3.03747820854187
Validation loss: 2.131590010017477

Epoch: 5| Step: 7
Training loss: 2.738409996032715
Validation loss: 2.142524083455404

Epoch: 5| Step: 8
Training loss: 2.4945034980773926
Validation loss: 2.1454398170594247

Epoch: 5| Step: 9
Training loss: 2.3594346046447754
Validation loss: 2.1536028795344855

Epoch: 5| Step: 10
Training loss: 1.8093671798706055
Validation loss: 2.1476274459592757

Epoch: 46| Step: 0
Training loss: 2.1919491291046143
Validation loss: 2.115834988573546

Epoch: 5| Step: 1
Training loss: 2.1048309803009033
Validation loss: 2.149836896568216

Epoch: 5| Step: 2
Training loss: 2.7491402626037598
Validation loss: 2.1302351054324897

Epoch: 5| Step: 3
Training loss: 2.03261399269104
Validation loss: 2.113718819874589

Epoch: 5| Step: 4
Training loss: 1.943120002746582
Validation loss: 2.1286542133618425

Epoch: 5| Step: 5
Training loss: 2.679748058319092
Validation loss: 2.1257591709013908

Epoch: 5| Step: 6
Training loss: 3.2833008766174316
Validation loss: 2.1364432329772622

Epoch: 5| Step: 7
Training loss: 2.736680030822754
Validation loss: 2.138058393232284

Epoch: 5| Step: 8
Training loss: 2.3188939094543457
Validation loss: 2.1313166413255917

Epoch: 5| Step: 9
Training loss: 1.6021919250488281
Validation loss: 2.137000855579171

Epoch: 5| Step: 10
Training loss: 2.693960189819336
Validation loss: 2.14171685454666

Epoch: 47| Step: 0
Training loss: 2.557180166244507
Validation loss: 2.123002229198333

Epoch: 5| Step: 1
Training loss: 2.310553789138794
Validation loss: 2.1281616610865437

Epoch: 5| Step: 2
Training loss: 2.3917040824890137
Validation loss: 2.134556144796392

Epoch: 5| Step: 3
Training loss: 2.623122453689575
Validation loss: 2.1291162736954226

Epoch: 5| Step: 4
Training loss: 2.135709762573242
Validation loss: 2.1249611864807787

Epoch: 5| Step: 5
Training loss: 2.3855111598968506
Validation loss: 2.1341278758100284

Epoch: 5| Step: 6
Training loss: 2.478199005126953
Validation loss: 2.142171780268351

Epoch: 5| Step: 7
Training loss: 2.809981107711792
Validation loss: 2.112796950083907

Epoch: 5| Step: 8
Training loss: 2.341071605682373
Validation loss: 2.1238562394213933

Epoch: 5| Step: 9
Training loss: 1.9737199544906616
Validation loss: 2.1207610843002156

Epoch: 5| Step: 10
Training loss: 2.264303684234619
Validation loss: 2.1148922007570983

Epoch: 48| Step: 0
Training loss: 2.5293843746185303
Validation loss: 2.1263783824059272

Epoch: 5| Step: 1
Training loss: 2.2088234424591064
Validation loss: 2.137824135441934

Epoch: 5| Step: 2
Training loss: 1.6029822826385498
Validation loss: 2.120192563661965

Epoch: 5| Step: 3
Training loss: 2.6118478775024414
Validation loss: 2.109696436953801

Epoch: 5| Step: 4
Training loss: 2.6147983074188232
Validation loss: 2.086567877441324

Epoch: 5| Step: 5
Training loss: 2.769819498062134
Validation loss: 2.110029505145165

Epoch: 5| Step: 6
Training loss: 1.9138002395629883
Validation loss: 2.1273292187721498

Epoch: 5| Step: 7
Training loss: 2.050095319747925
Validation loss: 2.1104839412114953

Epoch: 5| Step: 8
Training loss: 2.5068886280059814
Validation loss: 2.0906627562738236

Epoch: 5| Step: 9
Training loss: 3.0126824378967285
Validation loss: 2.0995571280038483

Epoch: 5| Step: 10
Training loss: 2.4505503177642822
Validation loss: 2.120116262025731

Epoch: 49| Step: 0
Training loss: 2.3041298389434814
Validation loss: 2.103128215318085

Epoch: 5| Step: 1
Training loss: 2.0066027641296387
Validation loss: 2.1058552213894424

Epoch: 5| Step: 2
Training loss: 2.0903451442718506
Validation loss: 2.100386268349104

Epoch: 5| Step: 3
Training loss: 2.7353873252868652
Validation loss: 2.0895179984390095

Epoch: 5| Step: 4
Training loss: 2.7850303649902344
Validation loss: 2.111951417820428

Epoch: 5| Step: 5
Training loss: 2.536764621734619
Validation loss: 2.104625040485013

Epoch: 5| Step: 6
Training loss: 1.873613715171814
Validation loss: 2.085326960009913

Epoch: 5| Step: 7
Training loss: 2.14579176902771
Validation loss: 2.090417677356351

Epoch: 5| Step: 8
Training loss: 2.7181785106658936
Validation loss: 2.103796269304009

Epoch: 5| Step: 9
Training loss: 2.8721628189086914
Validation loss: 2.115755404195478

Epoch: 5| Step: 10
Training loss: 2.107142448425293
Validation loss: 2.0909965704846125

Epoch: 50| Step: 0
Training loss: 2.4595654010772705
Validation loss: 2.087731363952801

Epoch: 5| Step: 1
Training loss: 2.5178492069244385
Validation loss: 2.0920866176646244

Epoch: 5| Step: 2
Training loss: 2.4293506145477295
Validation loss: 2.107027716534112

Epoch: 5| Step: 3
Training loss: 2.2923696041107178
Validation loss: 2.089022300576651

Epoch: 5| Step: 4
Training loss: 2.445361375808716
Validation loss: 2.1098510731932936

Epoch: 5| Step: 5
Training loss: 2.492377519607544
Validation loss: 2.0844123824950187

Epoch: 5| Step: 6
Training loss: 2.2204766273498535
Validation loss: 2.0964196574303413

Epoch: 5| Step: 7
Training loss: 1.978036642074585
Validation loss: 2.0858791220572686

Epoch: 5| Step: 8
Training loss: 2.8155009746551514
Validation loss: 2.0750905288163053

Epoch: 5| Step: 9
Training loss: 2.2525668144226074
Validation loss: 2.100006180424844

Epoch: 5| Step: 10
Training loss: 2.1721885204315186
Validation loss: 2.106837646935576

Epoch: 51| Step: 0
Training loss: 2.0756990909576416
Validation loss: 2.077586195802176

Epoch: 5| Step: 1
Training loss: 2.6120762825012207
Validation loss: 2.0886420255066245

Epoch: 5| Step: 2
Training loss: 2.094788074493408
Validation loss: 2.0809261029766453

Epoch: 5| Step: 3
Training loss: 2.1306095123291016
Validation loss: 2.094286887876449

Epoch: 5| Step: 4
Training loss: 2.599522352218628
Validation loss: 2.0938854525166173

Epoch: 5| Step: 5
Training loss: 2.826101064682007
Validation loss: 2.1061307358485397

Epoch: 5| Step: 6
Training loss: 2.54870343208313
Validation loss: 2.076868262342227

Epoch: 5| Step: 7
Training loss: 2.048161506652832
Validation loss: 2.087804220056021

Epoch: 5| Step: 8
Training loss: 2.609046459197998
Validation loss: 2.091499302976875

Epoch: 5| Step: 9
Training loss: 2.1393561363220215
Validation loss: 2.0885315402861564

Epoch: 5| Step: 10
Training loss: 2.3376305103302
Validation loss: 2.082758967594434

Epoch: 52| Step: 0
Training loss: 2.4159371852874756
Validation loss: 2.1025845235393894

Epoch: 5| Step: 1
Training loss: 1.8032996654510498
Validation loss: 2.0900259992127777

Epoch: 5| Step: 2
Training loss: 2.3379123210906982
Validation loss: 2.088324039213119

Epoch: 5| Step: 3
Training loss: 2.533294200897217
Validation loss: 2.112926975373299

Epoch: 5| Step: 4
Training loss: 1.8071033954620361
Validation loss: 2.1121984335684005

Epoch: 5| Step: 5
Training loss: 2.278045177459717
Validation loss: 2.1071892092304845

Epoch: 5| Step: 6
Training loss: 2.349015712738037
Validation loss: 2.099077119622179

Epoch: 5| Step: 7
Training loss: 2.4813461303710938
Validation loss: 2.1100077705998577

Epoch: 5| Step: 8
Training loss: 3.273190975189209
Validation loss: 2.0985713594703266

Epoch: 5| Step: 9
Training loss: 2.1266274452209473
Validation loss: 2.110219359397888

Epoch: 5| Step: 10
Training loss: 2.402151107788086
Validation loss: 2.119191059502222

Epoch: 53| Step: 0
Training loss: 2.6120972633361816
Validation loss: 2.099479465074437

Epoch: 5| Step: 1
Training loss: 2.2606289386749268
Validation loss: 2.0893731937613538

Epoch: 5| Step: 2
Training loss: 2.189222574234009
Validation loss: 2.105717230868596

Epoch: 5| Step: 3
Training loss: 2.3734703063964844
Validation loss: 2.112778917435677

Epoch: 5| Step: 4
Training loss: 2.0280404090881348
Validation loss: 2.104378843820223

Epoch: 5| Step: 5
Training loss: 2.283188581466675
Validation loss: 2.1169025769797702

Epoch: 5| Step: 6
Training loss: 2.700579881668091
Validation loss: 2.091092945427023

Epoch: 5| Step: 7
Training loss: 2.1277060508728027
Validation loss: 2.1000279521429412

Epoch: 5| Step: 8
Training loss: 3.1127219200134277
Validation loss: 2.115304749499085

Epoch: 5| Step: 9
Training loss: 2.2743968963623047
Validation loss: 2.0972602457128544

Epoch: 5| Step: 10
Training loss: 1.9800547361373901
Validation loss: 2.0993382853846394

Epoch: 54| Step: 0
Training loss: 2.3767666816711426
Validation loss: 2.0955589484143

Epoch: 5| Step: 1
Training loss: 2.6379854679107666
Validation loss: 2.1075150120642876

Epoch: 5| Step: 2
Training loss: 2.5932602882385254
Validation loss: 2.098370828936177

Epoch: 5| Step: 3
Training loss: 2.0866522789001465
Validation loss: 2.101051340820969

Epoch: 5| Step: 4
Training loss: 2.332674503326416
Validation loss: 2.096622695205032

Epoch: 5| Step: 5
Training loss: 2.3962738513946533
Validation loss: 2.1098742715774046

Epoch: 5| Step: 6
Training loss: 2.7735543251037598
Validation loss: 2.1045207464566795

Epoch: 5| Step: 7
Training loss: 2.7199196815490723
Validation loss: 2.1010816225441555

Epoch: 5| Step: 8
Training loss: 1.6160593032836914
Validation loss: 2.092316113492494

Epoch: 5| Step: 9
Training loss: 2.4449477195739746
Validation loss: 2.1169523910809587

Epoch: 5| Step: 10
Training loss: 1.872399091720581
Validation loss: 2.1072220674125095

Epoch: 55| Step: 0
Training loss: 1.8634846210479736
Validation loss: 2.0856910418438654

Epoch: 5| Step: 1
Training loss: 2.867032527923584
Validation loss: 2.081618470530356

Epoch: 5| Step: 2
Training loss: 2.2348008155822754
Validation loss: 2.1041557583757626

Epoch: 5| Step: 3
Training loss: 2.5457749366760254
Validation loss: 2.0818882334616875

Epoch: 5| Step: 4
Training loss: 2.7663683891296387
Validation loss: 2.0706021721645067

Epoch: 5| Step: 5
Training loss: 2.600545883178711
Validation loss: 2.0998026811948387

Epoch: 5| Step: 6
Training loss: 2.2455244064331055
Validation loss: 2.080769213297034

Epoch: 5| Step: 7
Training loss: 2.3513693809509277
Validation loss: 2.094684531611781

Epoch: 5| Step: 8
Training loss: 2.16455078125
Validation loss: 2.086270340027348

Epoch: 5| Step: 9
Training loss: 2.1665050983428955
Validation loss: 2.0819643043702647

Epoch: 5| Step: 10
Training loss: 1.9443718194961548
Validation loss: 2.0867792867845103

Epoch: 56| Step: 0
Training loss: 2.1812074184417725
Validation loss: 2.0937626618210987

Epoch: 5| Step: 1
Training loss: 2.793505907058716
Validation loss: 2.0932362541075675

Epoch: 5| Step: 2
Training loss: 2.115159034729004
Validation loss: 2.0973184621462257

Epoch: 5| Step: 3
Training loss: 2.404555082321167
Validation loss: 2.0745901830734743

Epoch: 5| Step: 4
Training loss: 1.8605873584747314
Validation loss: 2.0740948838572346

Epoch: 5| Step: 5
Training loss: 2.3846797943115234
Validation loss: 2.0785472662218156

Epoch: 5| Step: 6
Training loss: 2.3335559368133545
Validation loss: 2.0779414971669516

Epoch: 5| Step: 7
Training loss: 2.2809526920318604
Validation loss: 2.095281449697351

Epoch: 5| Step: 8
Training loss: 2.703922986984253
Validation loss: 2.0669084133640414

Epoch: 5| Step: 9
Training loss: 2.5574193000793457
Validation loss: 2.076721050406015

Epoch: 5| Step: 10
Training loss: 2.102351427078247
Validation loss: 2.0657599177411807

Epoch: 57| Step: 0
Training loss: 2.5235962867736816
Validation loss: 2.072514977506412

Epoch: 5| Step: 1
Training loss: 2.401798725128174
Validation loss: 2.082250609192797

Epoch: 5| Step: 2
Training loss: 2.6165783405303955
Validation loss: 2.076124470721009

Epoch: 5| Step: 3
Training loss: 2.5309386253356934
Validation loss: 2.059862723914526

Epoch: 5| Step: 4
Training loss: 2.087571859359741
Validation loss: 2.0917205451637186

Epoch: 5| Step: 5
Training loss: 2.2459285259246826
Validation loss: 2.0817254948359665

Epoch: 5| Step: 6
Training loss: 2.323061466217041
Validation loss: 2.0864423782594743

Epoch: 5| Step: 7
Training loss: 1.964855432510376
Validation loss: 2.07524126063111

Epoch: 5| Step: 8
Training loss: 1.954994797706604
Validation loss: 2.0878946294066725

Epoch: 5| Step: 9
Training loss: 2.5728416442871094
Validation loss: 2.0815981434237574

Epoch: 5| Step: 10
Training loss: 2.5616321563720703
Validation loss: 2.07038987323802

Epoch: 58| Step: 0
Training loss: 2.2732651233673096
Validation loss: 2.0905570112248903

Epoch: 5| Step: 1
Training loss: 2.4479727745056152
Validation loss: 2.0898276272640435

Epoch: 5| Step: 2
Training loss: 2.299614429473877
Validation loss: 2.08277057063195

Epoch: 5| Step: 3
Training loss: 2.152157783508301
Validation loss: 2.0673580861860708

Epoch: 5| Step: 4
Training loss: 2.125120162963867
Validation loss: 2.0907321976077173

Epoch: 5| Step: 5
Training loss: 2.2493717670440674
Validation loss: 2.0734087600502917

Epoch: 5| Step: 6
Training loss: 2.6680006980895996
Validation loss: 2.0812167993155857

Epoch: 5| Step: 7
Training loss: 2.528329849243164
Validation loss: 2.082674668681237

Epoch: 5| Step: 8
Training loss: 2.422734022140503
Validation loss: 2.0977781575213195

Epoch: 5| Step: 9
Training loss: 2.2615084648132324
Validation loss: 2.0921630474828903

Epoch: 5| Step: 10
Training loss: 2.153019666671753
Validation loss: 2.0766837725075344

Epoch: 59| Step: 0
Training loss: 2.247375249862671
Validation loss: 2.0998499995918682

Epoch: 5| Step: 1
Training loss: 2.803953170776367
Validation loss: 2.080160717810354

Epoch: 5| Step: 2
Training loss: 1.8370792865753174
Validation loss: 2.0833791199550835

Epoch: 5| Step: 3
Training loss: 1.7793896198272705
Validation loss: 2.0749005233087847

Epoch: 5| Step: 4
Training loss: 2.5304386615753174
Validation loss: 2.0822882972737795

Epoch: 5| Step: 5
Training loss: 2.7853646278381348
Validation loss: 2.065268953641256

Epoch: 5| Step: 6
Training loss: 2.062535047531128
Validation loss: 2.1000734144641506

Epoch: 5| Step: 7
Training loss: 2.6904923915863037
Validation loss: 2.087937852387787

Epoch: 5| Step: 8
Training loss: 2.562730550765991
Validation loss: 2.0794254426033265

Epoch: 5| Step: 9
Training loss: 2.160104274749756
Validation loss: 2.0821471342476467

Epoch: 5| Step: 10
Training loss: 2.1458547115325928
Validation loss: 2.064205538841986

Epoch: 60| Step: 0
Training loss: 2.5503010749816895
Validation loss: 2.072994642360236

Epoch: 5| Step: 1
Training loss: 2.1482114791870117
Validation loss: 2.064512783481229

Epoch: 5| Step: 2
Training loss: 2.37916898727417
Validation loss: 2.08923162439818

Epoch: 5| Step: 3
Training loss: 2.520691156387329
Validation loss: 2.050139004184354

Epoch: 5| Step: 4
Training loss: 3.0154216289520264
Validation loss: 2.0859977686277

Epoch: 5| Step: 5
Training loss: 1.7833951711654663
Validation loss: 2.078604239289479

Epoch: 5| Step: 6
Training loss: 2.807015895843506
Validation loss: 2.0770467250577864

Epoch: 5| Step: 7
Training loss: 1.8468215465545654
Validation loss: 2.0629343807056384

Epoch: 5| Step: 8
Training loss: 2.377957582473755
Validation loss: 2.066344074023667

Epoch: 5| Step: 9
Training loss: 2.102748394012451
Validation loss: 2.070209326282624

Epoch: 5| Step: 10
Training loss: 1.954957127571106
Validation loss: 2.0792802841432634

Epoch: 61| Step: 0
Training loss: 2.27847957611084
Validation loss: 2.0986027973954395

Epoch: 5| Step: 1
Training loss: 2.514479160308838
Validation loss: 2.076472543901013

Epoch: 5| Step: 2
Training loss: 2.0979952812194824
Validation loss: 2.086604872057515

Epoch: 5| Step: 3
Training loss: 1.7655248641967773
Validation loss: 2.063099399689705

Epoch: 5| Step: 4
Training loss: 1.9476535320281982
Validation loss: 2.076812310885358

Epoch: 5| Step: 5
Training loss: 2.3945086002349854
Validation loss: 2.0680481182631625

Epoch: 5| Step: 6
Training loss: 2.572610378265381
Validation loss: 2.0852323783341276

Epoch: 5| Step: 7
Training loss: 2.396014451980591
Validation loss: 2.06866616331121

Epoch: 5| Step: 8
Training loss: 2.9574222564697266
Validation loss: 2.0731671394840365

Epoch: 5| Step: 9
Training loss: 2.22007417678833
Validation loss: 2.0675979865494596

Epoch: 5| Step: 10
Training loss: 2.4000346660614014
Validation loss: 2.090700231572633

Epoch: 62| Step: 0
Training loss: 2.550138235092163
Validation loss: 2.0644646998374694

Epoch: 5| Step: 1
Training loss: 2.6129841804504395
Validation loss: 2.053729659767561

Epoch: 5| Step: 2
Training loss: 1.8667852878570557
Validation loss: 2.0725900178314536

Epoch: 5| Step: 3
Training loss: 2.147049903869629
Validation loss: 2.084646878703948

Epoch: 5| Step: 4
Training loss: 2.384385347366333
Validation loss: 2.0816925161628315

Epoch: 5| Step: 5
Training loss: 3.167816162109375
Validation loss: 2.0700449276995916

Epoch: 5| Step: 6
Training loss: 1.6670440435409546
Validation loss: 2.079398683322373

Epoch: 5| Step: 7
Training loss: 2.637789249420166
Validation loss: 2.0900042518492667

Epoch: 5| Step: 8
Training loss: 1.7890167236328125
Validation loss: 2.0747082592338644

Epoch: 5| Step: 9
Training loss: 2.5290610790252686
Validation loss: 2.0595295788139425

Epoch: 5| Step: 10
Training loss: 2.1736204624176025
Validation loss: 2.0691098115777455

Epoch: 63| Step: 0
Training loss: 2.15852689743042
Validation loss: 2.07721419231866

Epoch: 5| Step: 1
Training loss: 2.2582409381866455
Validation loss: 2.0807421745792514

Epoch: 5| Step: 2
Training loss: 2.150620698928833
Validation loss: 2.069701438309044

Epoch: 5| Step: 3
Training loss: 1.6462604999542236
Validation loss: 2.0789114352195495

Epoch: 5| Step: 4
Training loss: 2.458705425262451
Validation loss: 2.0644091790722263

Epoch: 5| Step: 5
Training loss: 2.4223110675811768
Validation loss: 2.069177375044874

Epoch: 5| Step: 6
Training loss: 2.3191349506378174
Validation loss: 2.0845609390607445

Epoch: 5| Step: 7
Training loss: 2.0851495265960693
Validation loss: 2.0701455531581754

Epoch: 5| Step: 8
Training loss: 2.8216021060943604
Validation loss: 2.067642065786546

Epoch: 5| Step: 9
Training loss: 2.6412503719329834
Validation loss: 2.0477588202363703

Epoch: 5| Step: 10
Training loss: 2.563922166824341
Validation loss: 2.061756049433062

Epoch: 64| Step: 0
Training loss: 1.7797777652740479
Validation loss: 2.0671848520155875

Epoch: 5| Step: 1
Training loss: 2.559325695037842
Validation loss: 2.0495927718377884

Epoch: 5| Step: 2
Training loss: 2.6150994300842285
Validation loss: 2.06580440972441

Epoch: 5| Step: 3
Training loss: 2.24826979637146
Validation loss: 2.0771142180247972

Epoch: 5| Step: 4
Training loss: 2.089470148086548
Validation loss: 2.0782961794125137

Epoch: 5| Step: 5
Training loss: 2.5273795127868652
Validation loss: 2.0682928869801183

Epoch: 5| Step: 6
Training loss: 2.040649175643921
Validation loss: 2.0763097168296896

Epoch: 5| Step: 7
Training loss: 2.082495927810669
Validation loss: 2.0834532732604654

Epoch: 5| Step: 8
Training loss: 2.6639208793640137
Validation loss: 2.07550266609397

Epoch: 5| Step: 9
Training loss: 2.3762433528900146
Validation loss: 2.072470259922807

Epoch: 5| Step: 10
Training loss: 2.525618076324463
Validation loss: 2.0682112875805108

Epoch: 65| Step: 0
Training loss: 1.874281644821167
Validation loss: 2.0703357906751734

Epoch: 5| Step: 1
Training loss: 1.7086513042449951
Validation loss: 2.069983748979466

Epoch: 5| Step: 2
Training loss: 2.4928455352783203
Validation loss: 2.0565995311224334

Epoch: 5| Step: 3
Training loss: 2.949392318725586
Validation loss: 2.058705819550381

Epoch: 5| Step: 4
Training loss: 2.1149120330810547
Validation loss: 2.053970208732031

Epoch: 5| Step: 5
Training loss: 2.9722740650177
Validation loss: 2.065673074414653

Epoch: 5| Step: 6
Training loss: 2.077075481414795
Validation loss: 2.075512359219213

Epoch: 5| Step: 7
Training loss: 2.465731620788574
Validation loss: 2.0517925729033766

Epoch: 5| Step: 8
Training loss: 2.1231536865234375
Validation loss: 2.041266418272449

Epoch: 5| Step: 9
Training loss: 2.253782033920288
Validation loss: 2.0844339504036853

Epoch: 5| Step: 10
Training loss: 2.2873544692993164
Validation loss: 2.0685127448010188

Epoch: 66| Step: 0
Training loss: 2.509735345840454
Validation loss: 2.0669843150723364

Epoch: 5| Step: 1
Training loss: 2.451166868209839
Validation loss: 2.047684980976966

Epoch: 5| Step: 2
Training loss: 2.856459140777588
Validation loss: 2.056118908748832

Epoch: 5| Step: 3
Training loss: 2.4324378967285156
Validation loss: 2.0599198495188067

Epoch: 5| Step: 4
Training loss: 1.9997409582138062
Validation loss: 2.064756037086569

Epoch: 5| Step: 5
Training loss: 2.3843438625335693
Validation loss: 2.062178897601302

Epoch: 5| Step: 6
Training loss: 2.179047107696533
Validation loss: 2.088917552783925

Epoch: 5| Step: 7
Training loss: 1.7980877161026
Validation loss: 2.053131789289495

Epoch: 5| Step: 8
Training loss: 2.3136754035949707
Validation loss: 2.0570185440842823

Epoch: 5| Step: 9
Training loss: 2.203547239303589
Validation loss: 2.068669899817436

Epoch: 5| Step: 10
Training loss: 2.1041932106018066
Validation loss: 2.0611167261677403

Epoch: 67| Step: 0
Training loss: 2.5976970195770264
Validation loss: 2.0526756368657595

Epoch: 5| Step: 1
Training loss: 2.128176212310791
Validation loss: 2.053672868718383

Epoch: 5| Step: 2
Training loss: 2.187103748321533
Validation loss: 2.0588734995934272

Epoch: 5| Step: 3
Training loss: 1.9681564569473267
Validation loss: 2.0889567329037573

Epoch: 5| Step: 4
Training loss: 2.7775750160217285
Validation loss: 2.0690188625807404

Epoch: 5| Step: 5
Training loss: 2.132749319076538
Validation loss: 2.064295115009431

Epoch: 5| Step: 6
Training loss: 2.7660117149353027
Validation loss: 2.069801679221533

Epoch: 5| Step: 7
Training loss: 2.3490378856658936
Validation loss: 2.067774139424806

Epoch: 5| Step: 8
Training loss: 2.242605209350586
Validation loss: 2.0655249139314056

Epoch: 5| Step: 9
Training loss: 1.9522655010223389
Validation loss: 2.0736745070385676

Epoch: 5| Step: 10
Training loss: 2.2192888259887695
Validation loss: 2.0884709781216038

Epoch: 68| Step: 0
Training loss: 2.4466910362243652
Validation loss: 2.070918124209168

Epoch: 5| Step: 1
Training loss: 2.055285692214966
Validation loss: 2.0617503299508044

Epoch: 5| Step: 2
Training loss: 2.459963321685791
Validation loss: 2.0805345581423853

Epoch: 5| Step: 3
Training loss: 2.4694783687591553
Validation loss: 2.0694706516881145

Epoch: 5| Step: 4
Training loss: 2.27410626411438
Validation loss: 2.040679793204031

Epoch: 5| Step: 5
Training loss: 1.8210865259170532
Validation loss: 2.05096132909098

Epoch: 5| Step: 6
Training loss: 2.5040650367736816
Validation loss: 2.0584957368912233

Epoch: 5| Step: 7
Training loss: 1.886380910873413
Validation loss: 2.0735891044780774

Epoch: 5| Step: 8
Training loss: 2.2320804595947266
Validation loss: 2.0784836558885473

Epoch: 5| Step: 9
Training loss: 2.530039072036743
Validation loss: 2.0779015043730378

Epoch: 5| Step: 10
Training loss: 2.460930824279785
Validation loss: 2.0711813280659337

Epoch: 69| Step: 0
Training loss: 2.211552143096924
Validation loss: 2.0811799392905286

Epoch: 5| Step: 1
Training loss: 1.9547115564346313
Validation loss: 2.0613911536432084

Epoch: 5| Step: 2
Training loss: 2.7546308040618896
Validation loss: 2.0833374402856313

Epoch: 5| Step: 3
Training loss: 2.571120500564575
Validation loss: 2.063835774698565

Epoch: 5| Step: 4
Training loss: 2.479355573654175
Validation loss: 2.076000746860299

Epoch: 5| Step: 5
Training loss: 1.7390849590301514
Validation loss: 2.094703023151685

Epoch: 5| Step: 6
Training loss: 2.2883002758026123
Validation loss: 2.0833663940429688

Epoch: 5| Step: 7
Training loss: 2.497865676879883
Validation loss: 2.0674747997714626

Epoch: 5| Step: 8
Training loss: 2.0378670692443848
Validation loss: 2.0718953212102256

Epoch: 5| Step: 9
Training loss: 2.2671289443969727
Validation loss: 2.0652515977941532

Epoch: 5| Step: 10
Training loss: 2.4522783756256104
Validation loss: 2.069640680025983

Epoch: 70| Step: 0
Training loss: 1.9990695714950562
Validation loss: 2.0726895947610178

Epoch: 5| Step: 1
Training loss: 2.3752846717834473
Validation loss: 2.064494740578436

Epoch: 5| Step: 2
Training loss: 2.8292698860168457
Validation loss: 2.0817872939571256

Epoch: 5| Step: 3
Training loss: 1.8275718688964844
Validation loss: 2.052521562063566

Epoch: 5| Step: 4
Training loss: 2.451773166656494
Validation loss: 2.0586157050184024

Epoch: 5| Step: 5
Training loss: 2.078169822692871
Validation loss: 2.0630876697519773

Epoch: 5| Step: 6
Training loss: 2.345524549484253
Validation loss: 2.0740771152639903

Epoch: 5| Step: 7
Training loss: 1.9621055126190186
Validation loss: 2.0744203418813725

Epoch: 5| Step: 8
Training loss: 2.1241507530212402
Validation loss: 2.0740333116182716

Epoch: 5| Step: 9
Training loss: 3.2000954151153564
Validation loss: 2.0683659430473083

Epoch: 5| Step: 10
Training loss: 1.854620099067688
Validation loss: 2.063546088434035

Epoch: 71| Step: 0
Training loss: 2.257362127304077
Validation loss: 2.0554875917332147

Epoch: 5| Step: 1
Training loss: 2.3983418941497803
Validation loss: 2.076214813417004

Epoch: 5| Step: 2
Training loss: 2.3368618488311768
Validation loss: 2.0663215985862156

Epoch: 5| Step: 3
Training loss: 2.530806303024292
Validation loss: 2.0712478391585813

Epoch: 5| Step: 4
Training loss: 2.4256198406219482
Validation loss: 2.0568323455831057

Epoch: 5| Step: 5
Training loss: 1.603916883468628
Validation loss: 2.0835260614272086

Epoch: 5| Step: 6
Training loss: 2.730733633041382
Validation loss: 2.0627518546196724

Epoch: 5| Step: 7
Training loss: 1.877805471420288
Validation loss: 2.06124028851909

Epoch: 5| Step: 8
Training loss: 2.4004788398742676
Validation loss: 2.0695353502868326

Epoch: 5| Step: 9
Training loss: 2.1505560874938965
Validation loss: 2.0794661121983684

Epoch: 5| Step: 10
Training loss: 2.6855671405792236
Validation loss: 2.051120033828161

Epoch: 72| Step: 0
Training loss: 2.473449230194092
Validation loss: 2.060799926839849

Epoch: 5| Step: 1
Training loss: 1.7756439447402954
Validation loss: 2.0724908844117196

Epoch: 5| Step: 2
Training loss: 1.9160064458847046
Validation loss: 2.0773236187555457

Epoch: 5| Step: 3
Training loss: 2.2525174617767334
Validation loss: 2.0726537025103005

Epoch: 5| Step: 4
Training loss: 2.162804126739502
Validation loss: 2.0848085341915006

Epoch: 5| Step: 5
Training loss: 2.167048692703247
Validation loss: 2.062059494756883

Epoch: 5| Step: 6
Training loss: 2.815345287322998
Validation loss: 2.074657379939992

Epoch: 5| Step: 7
Training loss: 1.9110000133514404
Validation loss: 2.082489644327471

Epoch: 5| Step: 8
Training loss: 2.490631580352783
Validation loss: 2.0689310335343882

Epoch: 5| Step: 9
Training loss: 2.653233766555786
Validation loss: 2.0670872106347034

Epoch: 5| Step: 10
Training loss: 2.3463892936706543
Validation loss: 2.0838065160218107

Epoch: 73| Step: 0
Training loss: 2.490222454071045
Validation loss: 2.079940329315842

Epoch: 5| Step: 1
Training loss: 2.48161244392395
Validation loss: 2.058689364822962

Epoch: 5| Step: 2
Training loss: 1.9359676837921143
Validation loss: 2.078638187018774

Epoch: 5| Step: 3
Training loss: 1.7481920719146729
Validation loss: 2.077869205064671

Epoch: 5| Step: 4
Training loss: 2.8889694213867188
Validation loss: 2.05392264550732

Epoch: 5| Step: 5
Training loss: 1.696327805519104
Validation loss: 2.067131547517674

Epoch: 5| Step: 6
Training loss: 2.544344425201416
Validation loss: 2.0802793169534333

Epoch: 5| Step: 7
Training loss: 2.310985565185547
Validation loss: 2.0824574578192925

Epoch: 5| Step: 8
Training loss: 2.259530782699585
Validation loss: 2.07734420991713

Epoch: 5| Step: 9
Training loss: 2.076366901397705
Validation loss: 2.068740993417719

Epoch: 5| Step: 10
Training loss: 2.8279569149017334
Validation loss: 2.086497176078058

Epoch: 74| Step: 0
Training loss: 2.676422119140625
Validation loss: 2.071539448153588

Epoch: 5| Step: 1
Training loss: 2.242121458053589
Validation loss: 2.063500424867035

Epoch: 5| Step: 2
Training loss: 2.5458061695098877
Validation loss: 2.074203880884314

Epoch: 5| Step: 3
Training loss: 2.1498780250549316
Validation loss: 2.0685997496369066

Epoch: 5| Step: 4
Training loss: 1.9803760051727295
Validation loss: 2.0820216260930544

Epoch: 5| Step: 5
Training loss: 2.1994781494140625
Validation loss: 2.0659585909176896

Epoch: 5| Step: 6
Training loss: 2.492887496948242
Validation loss: 2.0782967190588675

Epoch: 5| Step: 7
Training loss: 2.030996322631836
Validation loss: 2.0835643147909515

Epoch: 5| Step: 8
Training loss: 2.337876796722412
Validation loss: 2.0705275984220606

Epoch: 5| Step: 9
Training loss: 2.0259182453155518
Validation loss: 2.0785564876371816

Epoch: 5| Step: 10
Training loss: 2.2471377849578857
Validation loss: 2.0820420224179506

Epoch: 75| Step: 0
Training loss: 2.5354599952697754
Validation loss: 2.0858947256559968

Epoch: 5| Step: 1
Training loss: 2.5470046997070312
Validation loss: 2.0697683775296776

Epoch: 5| Step: 2
Training loss: 2.4762721061706543
Validation loss: 2.067426949419001

Epoch: 5| Step: 3
Training loss: 2.147279739379883
Validation loss: 2.0774036812525924

Epoch: 5| Step: 4
Training loss: 1.598520040512085
Validation loss: 2.06225243178747

Epoch: 5| Step: 5
Training loss: 2.797612428665161
Validation loss: 2.0825338581556916

Epoch: 5| Step: 6
Training loss: 2.1751301288604736
Validation loss: 2.0850076252414333

Epoch: 5| Step: 7
Training loss: 2.259946584701538
Validation loss: 2.0761968743416572

Epoch: 5| Step: 8
Training loss: 2.3125457763671875
Validation loss: 2.056154671535697

Epoch: 5| Step: 9
Training loss: 1.842904806137085
Validation loss: 2.0862537468633344

Epoch: 5| Step: 10
Training loss: 2.3929853439331055
Validation loss: 2.0737879481366885

Testing loss: 2.058778405189514
