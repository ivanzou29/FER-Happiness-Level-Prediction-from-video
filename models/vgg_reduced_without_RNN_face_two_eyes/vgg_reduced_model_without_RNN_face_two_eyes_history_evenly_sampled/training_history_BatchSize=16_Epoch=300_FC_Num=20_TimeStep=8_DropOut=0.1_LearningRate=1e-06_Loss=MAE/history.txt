Epoch: 1| Step: 0
Training loss: 4.028953552246094
Validation loss: 4.713782838595811

Epoch: 6| Step: 1
Training loss: 4.813027381896973
Validation loss: 4.707642396291097

Epoch: 6| Step: 2
Training loss: 3.7325196266174316
Validation loss: 4.699621574853056

Epoch: 6| Step: 3
Training loss: 4.12410831451416
Validation loss: 4.6946253520186225

Epoch: 6| Step: 4
Training loss: 5.265358924865723
Validation loss: 4.6869265853717765

Epoch: 6| Step: 5
Training loss: 5.0048675537109375
Validation loss: 4.6816647232219735

Epoch: 6| Step: 6
Training loss: 4.99910831451416
Validation loss: 4.6739747960080384

Epoch: 6| Step: 7
Training loss: 4.994842529296875
Validation loss: 4.670847149305446

Epoch: 6| Step: 8
Training loss: 4.015749454498291
Validation loss: 4.6649350299630115

Epoch: 6| Step: 9
Training loss: 4.408045291900635
Validation loss: 4.659605585118776

Epoch: 6| Step: 10
Training loss: 4.064236164093018
Validation loss: 4.652942349833827

Epoch: 6| Step: 11
Training loss: 4.588639736175537
Validation loss: 4.648873472726473

Epoch: 6| Step: 12
Training loss: 3.908811569213867
Validation loss: 4.6419220842340945

Epoch: 6| Step: 13
Training loss: 4.799279689788818
Validation loss: 4.631084375484015

Epoch: 2| Step: 0
Training loss: 3.6668930053710938
Validation loss: 4.6291634395558345

Epoch: 6| Step: 1
Training loss: 4.244022369384766
Validation loss: 4.623085555209909

Epoch: 6| Step: 2
Training loss: 3.533895492553711
Validation loss: 4.617372917872603

Epoch: 6| Step: 3
Training loss: 5.221723556518555
Validation loss: 4.609329110832625

Epoch: 6| Step: 4
Training loss: 4.272686004638672
Validation loss: 4.605777366186983

Epoch: 6| Step: 5
Training loss: 4.921821594238281
Validation loss: 4.600338335960142

Epoch: 6| Step: 6
Training loss: 4.419569969177246
Validation loss: 4.59292640993672

Epoch: 6| Step: 7
Training loss: 5.128693580627441
Validation loss: 4.58831968615132

Epoch: 6| Step: 8
Training loss: 4.101648330688477
Validation loss: 4.582917413403911

Epoch: 6| Step: 9
Training loss: 3.980592727661133
Validation loss: 4.573866792904433

Epoch: 6| Step: 10
Training loss: 4.791300296783447
Validation loss: 4.57011305644948

Epoch: 6| Step: 11
Training loss: 3.726656913757324
Validation loss: 4.56414597265182

Epoch: 6| Step: 12
Training loss: 4.776753902435303
Validation loss: 4.557817843652541

Epoch: 6| Step: 13
Training loss: 4.918308258056641
Validation loss: 4.551871868871873

Epoch: 3| Step: 0
Training loss: 5.569317817687988
Validation loss: 4.544100592213292

Epoch: 6| Step: 1
Training loss: 3.987637758255005
Validation loss: 4.539634161098029

Epoch: 6| Step: 2
Training loss: 3.909419059753418
Validation loss: 4.530996450813868

Epoch: 6| Step: 3
Training loss: 4.424561977386475
Validation loss: 4.52781956426559

Epoch: 6| Step: 4
Training loss: 4.651922225952148
Validation loss: 4.519101373610958

Epoch: 6| Step: 5
Training loss: 4.628166675567627
Validation loss: 4.515607495461741

Epoch: 6| Step: 6
Training loss: 4.418886184692383
Validation loss: 4.505446551948466

Epoch: 6| Step: 7
Training loss: 3.590550184249878
Validation loss: 4.501404054703251

Epoch: 6| Step: 8
Training loss: 4.2349853515625
Validation loss: 4.4947775666431715

Epoch: 6| Step: 9
Training loss: 3.7540807723999023
Validation loss: 4.4868724653797765

Epoch: 6| Step: 10
Training loss: 3.377202033996582
Validation loss: 4.47919963764888

Epoch: 6| Step: 11
Training loss: 4.8011274337768555
Validation loss: 4.471914481091243

Epoch: 6| Step: 12
Training loss: 5.0539093017578125
Validation loss: 4.467123859672136

Epoch: 6| Step: 13
Training loss: 3.5441079139709473
Validation loss: 4.46075790159164

Epoch: 4| Step: 0
Training loss: 4.535913467407227
Validation loss: 4.454669444791732

Epoch: 6| Step: 1
Training loss: 4.175475120544434
Validation loss: 4.4479386627033195

Epoch: 6| Step: 2
Training loss: 3.335066318511963
Validation loss: 4.441037039602956

Epoch: 6| Step: 3
Training loss: 4.752479553222656
Validation loss: 4.435407023276052

Epoch: 6| Step: 4
Training loss: 3.9307398796081543
Validation loss: 4.425023489100958

Epoch: 6| Step: 5
Training loss: 4.560412406921387
Validation loss: 4.4209039185636785

Epoch: 6| Step: 6
Training loss: 4.650547504425049
Validation loss: 4.412852764129639

Epoch: 6| Step: 7
Training loss: 4.870197296142578
Validation loss: 4.406161928689608

Epoch: 6| Step: 8
Training loss: 4.025038719177246
Validation loss: 4.396112606089602

Epoch: 6| Step: 9
Training loss: 5.622557640075684
Validation loss: 4.3900877275774555

Epoch: 6| Step: 10
Training loss: 2.458672523498535
Validation loss: 4.384503262017363

Epoch: 6| Step: 11
Training loss: 3.7294812202453613
Validation loss: 4.377900390214817

Epoch: 6| Step: 12
Training loss: 3.5915422439575195
Validation loss: 4.3702326179832545

Epoch: 6| Step: 13
Training loss: 5.152800559997559
Validation loss: 4.362334512895154

Epoch: 5| Step: 0
Training loss: 3.838554620742798
Validation loss: 4.354481743228051

Epoch: 6| Step: 1
Training loss: 3.635657787322998
Validation loss: 4.346606531450825

Epoch: 6| Step: 2
Training loss: 3.4135985374450684
Validation loss: 4.3394447347169285

Epoch: 6| Step: 3
Training loss: 4.28562593460083
Validation loss: 4.332937330328008

Epoch: 6| Step: 4
Training loss: 4.39024543762207
Validation loss: 4.325486539512553

Epoch: 6| Step: 5
Training loss: 4.438549518585205
Validation loss: 4.316236654917399

Epoch: 6| Step: 6
Training loss: 4.361339569091797
Validation loss: 4.3106777488544425

Epoch: 6| Step: 7
Training loss: 4.575206756591797
Validation loss: 4.297784487406413

Epoch: 6| Step: 8
Training loss: 4.266890048980713
Validation loss: 4.293384352037983

Epoch: 6| Step: 9
Training loss: 3.5166358947753906
Validation loss: 4.2842147657948155

Epoch: 6| Step: 10
Training loss: 3.94031023979187
Validation loss: 4.274647197415752

Epoch: 6| Step: 11
Training loss: 3.483919620513916
Validation loss: 4.266747930998443

Epoch: 6| Step: 12
Training loss: 4.449523448944092
Validation loss: 4.255283901768346

Epoch: 6| Step: 13
Training loss: 5.61625862121582
Validation loss: 4.250549670188658

Epoch: 6| Step: 0
Training loss: 5.194027900695801
Validation loss: 4.240795971244894

Epoch: 6| Step: 1
Training loss: 3.837934970855713
Validation loss: 4.231674291754282

Epoch: 6| Step: 2
Training loss: 4.685499668121338
Validation loss: 4.222268886463617

Epoch: 6| Step: 3
Training loss: 2.6317222118377686
Validation loss: 4.210976210973596

Epoch: 6| Step: 4
Training loss: 3.0773391723632812
Validation loss: 4.2058290255967

Epoch: 6| Step: 5
Training loss: 3.8213725090026855
Validation loss: 4.196447551891368

Epoch: 6| Step: 6
Training loss: 4.381871700286865
Validation loss: 4.187755141206967

Epoch: 6| Step: 7
Training loss: 3.349123239517212
Validation loss: 4.175342231668452

Epoch: 6| Step: 8
Training loss: 4.271211624145508
Validation loss: 4.171261264431861

Epoch: 6| Step: 9
Training loss: 4.415977954864502
Validation loss: 4.160193958590107

Epoch: 6| Step: 10
Training loss: 4.6027326583862305
Validation loss: 4.149117813315443

Epoch: 6| Step: 11
Training loss: 3.5283966064453125
Validation loss: 4.141705584782426

Epoch: 6| Step: 12
Training loss: 3.584510326385498
Validation loss: 4.1323020253130185

Epoch: 6| Step: 13
Training loss: 5.097352504730225
Validation loss: 4.120070970186624

Epoch: 7| Step: 0
Training loss: 4.583982467651367
Validation loss: 4.114704091061828

Epoch: 6| Step: 1
Training loss: 4.548956871032715
Validation loss: 4.098696160060103

Epoch: 6| Step: 2
Training loss: 2.6968612670898438
Validation loss: 4.090952698902417

Epoch: 6| Step: 3
Training loss: 3.9337997436523438
Validation loss: 4.081078021757064

Epoch: 6| Step: 4
Training loss: 4.216034889221191
Validation loss: 4.072773707810269

Epoch: 6| Step: 5
Training loss: 3.7088887691497803
Validation loss: 4.0600716221717095

Epoch: 6| Step: 6
Training loss: 3.3951661586761475
Validation loss: 4.050325042457991

Epoch: 6| Step: 7
Training loss: 3.0723888874053955
Validation loss: 4.0381789874005065

Epoch: 6| Step: 8
Training loss: 5.580056190490723
Validation loss: 4.0279583572059545

Epoch: 6| Step: 9
Training loss: 3.3964390754699707
Validation loss: 4.018644343140305

Epoch: 6| Step: 10
Training loss: 3.348390579223633
Validation loss: 4.004964120926395

Epoch: 6| Step: 11
Training loss: 3.3301596641540527
Validation loss: 3.9974294939348773

Epoch: 6| Step: 12
Training loss: 4.247138023376465
Validation loss: 3.9843838958330053

Epoch: 6| Step: 13
Training loss: 4.632620334625244
Validation loss: 3.9739160537719727

Epoch: 8| Step: 0
Training loss: 3.9248218536376953
Validation loss: 3.9615222484834733

Epoch: 6| Step: 1
Training loss: 4.009429454803467
Validation loss: 3.9527944005945677

Epoch: 6| Step: 2
Training loss: 3.852743625640869
Validation loss: 3.937574566051524

Epoch: 6| Step: 3
Training loss: 2.602217197418213
Validation loss: 3.9304395619259087

Epoch: 6| Step: 4
Training loss: 3.4165778160095215
Validation loss: 3.9182168822134695

Epoch: 6| Step: 5
Training loss: 3.5353968143463135
Validation loss: 3.9084510751949844

Epoch: 6| Step: 6
Training loss: 3.315577745437622
Validation loss: 3.900803094269127

Epoch: 6| Step: 7
Training loss: 3.358527183532715
Validation loss: 3.888488943858813

Epoch: 6| Step: 8
Training loss: 4.761727809906006
Validation loss: 3.8771623616577475

Epoch: 6| Step: 9
Training loss: 3.276766300201416
Validation loss: 3.8666902895896667

Epoch: 6| Step: 10
Training loss: 4.246288299560547
Validation loss: 3.8530723100067465

Epoch: 6| Step: 11
Training loss: 3.4929521083831787
Validation loss: 3.8445152851843063

Epoch: 6| Step: 12
Training loss: 3.809717893600464
Validation loss: 3.83294839243735

Epoch: 6| Step: 13
Training loss: 5.686319351196289
Validation loss: 3.8215885675081642

Epoch: 9| Step: 0
Training loss: 4.200873851776123
Validation loss: 3.8072520276551605

Epoch: 6| Step: 1
Training loss: 3.3567163944244385
Validation loss: 3.8002626716449694

Epoch: 6| Step: 2
Training loss: 3.4335241317749023
Validation loss: 3.7897038921233146

Epoch: 6| Step: 3
Training loss: 4.565493106842041
Validation loss: 3.771120168829477

Epoch: 6| Step: 4
Training loss: 2.2711799144744873
Validation loss: 3.763919461158014

Epoch: 6| Step: 5
Training loss: 4.461205959320068
Validation loss: 3.7474351954716507

Epoch: 6| Step: 6
Training loss: 4.655402660369873
Validation loss: 3.7385935193748883

Epoch: 6| Step: 7
Training loss: 4.161306858062744
Validation loss: 3.721724884484404

Epoch: 6| Step: 8
Training loss: 3.443706512451172
Validation loss: 3.7129844337381344

Epoch: 6| Step: 9
Training loss: 3.245687484741211
Validation loss: 3.699002053148003

Epoch: 6| Step: 10
Training loss: 3.6588220596313477
Validation loss: 3.682769816408875

Epoch: 6| Step: 11
Training loss: 3.6594581604003906
Validation loss: 3.6708927769814768

Epoch: 6| Step: 12
Training loss: 2.4380035400390625
Validation loss: 3.6581522572425103

Epoch: 6| Step: 13
Training loss: 2.4580163955688477
Validation loss: 3.6447849812046176

Epoch: 10| Step: 0
Training loss: 2.931159734725952
Validation loss: 3.6356307332233717

Epoch: 6| Step: 1
Training loss: 3.6204447746276855
Validation loss: 3.619097437909854

Epoch: 6| Step: 2
Training loss: 1.7838330268859863
Validation loss: 3.609268514058923

Epoch: 6| Step: 3
Training loss: 4.245299339294434
Validation loss: 3.5969394458237516

Epoch: 6| Step: 4
Training loss: 3.6426355838775635
Validation loss: 3.5876539778965775

Epoch: 6| Step: 5
Training loss: 3.2010014057159424
Validation loss: 3.571755450258973

Epoch: 6| Step: 6
Training loss: 3.3286001682281494
Validation loss: 3.5577053408468924

Epoch: 6| Step: 7
Training loss: 4.0077009201049805
Validation loss: 3.544824784801852

Epoch: 6| Step: 8
Training loss: 4.914971351623535
Validation loss: 3.5347786026616252

Epoch: 6| Step: 9
Training loss: 3.182086944580078
Validation loss: 3.514660986520911

Epoch: 6| Step: 10
Training loss: 3.097750663757324
Validation loss: 3.5022081764795447

Epoch: 6| Step: 11
Training loss: 3.9420900344848633
Validation loss: 3.4909130193853892

Epoch: 6| Step: 12
Training loss: 3.2673678398132324
Validation loss: 3.4815413080235964

Epoch: 6| Step: 13
Training loss: 2.8971493244171143
Validation loss: 3.459529910036313

Epoch: 11| Step: 0
Training loss: 4.285821437835693
Validation loss: 3.4463162370907363

Epoch: 6| Step: 1
Training loss: 2.78706693649292
Validation loss: 3.4348971920628704

Epoch: 6| Step: 2
Training loss: 3.478449583053589
Validation loss: 3.4183765252431235

Epoch: 6| Step: 3
Training loss: 3.014098644256592
Validation loss: 3.402915623880202

Epoch: 6| Step: 4
Training loss: 3.100058078765869
Validation loss: 3.388296029900992

Epoch: 6| Step: 5
Training loss: 2.7526705265045166
Validation loss: 3.3748510242790304

Epoch: 6| Step: 6
Training loss: 3.106513023376465
Validation loss: 3.3540342597551245

Epoch: 6| Step: 7
Training loss: 3.918208599090576
Validation loss: 3.3391390641530356

Epoch: 6| Step: 8
Training loss: 3.463395595550537
Validation loss: 3.3271110826923

Epoch: 6| Step: 9
Training loss: 4.170313835144043
Validation loss: 3.3083766557837047

Epoch: 6| Step: 10
Training loss: 2.7821221351623535
Validation loss: 3.295764528295045

Epoch: 6| Step: 11
Training loss: 2.4051268100738525
Validation loss: 3.280182002693094

Epoch: 6| Step: 12
Training loss: 3.5664467811584473
Validation loss: 3.2635066227246354

Epoch: 6| Step: 13
Training loss: 2.910802125930786
Validation loss: 3.248094371570054

Epoch: 12| Step: 0
Training loss: 2.310251474380493
Validation loss: 3.230451747935305

Epoch: 6| Step: 1
Training loss: 2.52602481842041
Validation loss: 3.2100817721377135

Epoch: 6| Step: 2
Training loss: 3.5029659271240234
Validation loss: 3.1947517677020003

Epoch: 6| Step: 3
Training loss: 2.3219172954559326
Validation loss: 3.17885334004638

Epoch: 6| Step: 4
Training loss: 2.884673595428467
Validation loss: 3.1695870635330037

Epoch: 6| Step: 5
Training loss: 3.9839327335357666
Validation loss: 3.153272864639118

Epoch: 6| Step: 6
Training loss: 3.0562939643859863
Validation loss: 3.1382309852107877

Epoch: 6| Step: 7
Training loss: 4.236748695373535
Validation loss: 3.128377406827865

Epoch: 6| Step: 8
Training loss: 3.1146700382232666
Validation loss: 3.112079833143501

Epoch: 6| Step: 9
Training loss: 4.552481174468994
Validation loss: 3.0943595722157466

Epoch: 6| Step: 10
Training loss: 2.712897539138794
Validation loss: 3.0784542688759426

Epoch: 6| Step: 11
Training loss: 2.7849693298339844
Validation loss: 3.068006007902084

Epoch: 6| Step: 12
Training loss: 2.7038655281066895
Validation loss: 3.0442929960066274

Epoch: 6| Step: 13
Training loss: 2.468322277069092
Validation loss: 3.037115655919557

Epoch: 13| Step: 0
Training loss: 2.98567533493042
Validation loss: 3.015090778309812

Epoch: 6| Step: 1
Training loss: 4.04341983795166
Validation loss: 3.0029949039541264

Epoch: 6| Step: 2
Training loss: 3.3589565753936768
Validation loss: 2.9901205801194712

Epoch: 6| Step: 3
Training loss: 3.091486930847168
Validation loss: 2.9698521168001237

Epoch: 6| Step: 4
Training loss: 2.6301889419555664
Validation loss: 2.9531598244943926

Epoch: 6| Step: 5
Training loss: 2.399888038635254
Validation loss: 2.9385430069379908

Epoch: 6| Step: 6
Training loss: 3.5923705101013184
Validation loss: 2.932428288203414

Epoch: 6| Step: 7
Training loss: 3.0269112586975098
Validation loss: 2.919686048261581

Epoch: 6| Step: 8
Training loss: 2.441875457763672
Validation loss: 2.9043208809309107

Epoch: 6| Step: 9
Training loss: 2.875432252883911
Validation loss: 2.8904445709720736

Epoch: 6| Step: 10
Training loss: 3.581083297729492
Validation loss: 2.8808239044681674

Epoch: 6| Step: 11
Training loss: 2.172314405441284
Validation loss: 2.8659154445894304

Epoch: 6| Step: 12
Training loss: 2.3230834007263184
Validation loss: 2.847127247882146

Epoch: 6| Step: 13
Training loss: 3.0605039596557617
Validation loss: 2.8266013360792592

Epoch: 14| Step: 0
Training loss: 3.363229751586914
Validation loss: 2.820428732902773

Epoch: 6| Step: 1
Training loss: 2.9897632598876953
Validation loss: 2.8013566027405443

Epoch: 6| Step: 2
Training loss: 2.570444107055664
Validation loss: 2.7811967326748754

Epoch: 6| Step: 3
Training loss: 2.376953363418579
Validation loss: 2.7650611785150345

Epoch: 6| Step: 4
Training loss: 2.3765993118286133
Validation loss: 2.7609844489764144

Epoch: 6| Step: 5
Training loss: 2.586423397064209
Validation loss: 2.750066864875055

Epoch: 6| Step: 6
Training loss: 3.4617273807525635
Validation loss: 2.730758700319516

Epoch: 6| Step: 7
Training loss: 2.809516429901123
Validation loss: 2.7164816036019275

Epoch: 6| Step: 8
Training loss: 3.1374893188476562
Validation loss: 2.712223101687688

Epoch: 6| Step: 9
Training loss: 2.84487247467041
Validation loss: 2.700511558081514

Epoch: 6| Step: 10
Training loss: 3.410829544067383
Validation loss: 2.6800894429606776

Epoch: 6| Step: 11
Training loss: 2.7315194606781006
Validation loss: 2.651513655980428

Epoch: 6| Step: 12
Training loss: 2.3313512802124023
Validation loss: 2.629906205720799

Epoch: 6| Step: 13
Training loss: 2.7500576972961426
Validation loss: 2.6201608975728354

Epoch: 15| Step: 0
Training loss: 2.225177764892578
Validation loss: 2.6223610524208314

Epoch: 6| Step: 1
Training loss: 2.34454607963562
Validation loss: 2.5979314465676584

Epoch: 6| Step: 2
Training loss: 2.5945115089416504
Validation loss: 2.5894425222950597

Epoch: 6| Step: 3
Training loss: 2.7233667373657227
Validation loss: 2.5653811757282545

Epoch: 6| Step: 4
Training loss: 2.813610553741455
Validation loss: 2.55425327567644

Epoch: 6| Step: 5
Training loss: 3.3251595497131348
Validation loss: 2.5591465452665925

Epoch: 6| Step: 6
Training loss: 2.4958510398864746
Validation loss: 2.534991389961653

Epoch: 6| Step: 7
Training loss: 2.7466988563537598
Validation loss: 2.523301811628444

Epoch: 6| Step: 8
Training loss: 3.1497902870178223
Validation loss: 2.5021641767153175

Epoch: 6| Step: 9
Training loss: 3.1516876220703125
Validation loss: 2.4957303898308867

Epoch: 6| Step: 10
Training loss: 2.8051059246063232
Validation loss: 2.4745313711063837

Epoch: 6| Step: 11
Training loss: 2.752532958984375
Validation loss: 2.468825319761871

Epoch: 6| Step: 12
Training loss: 2.2716360092163086
Validation loss: 2.461332126330304

Epoch: 6| Step: 13
Training loss: 2.664236545562744
Validation loss: 2.448580582936605

Epoch: 16| Step: 0
Training loss: 2.1617517471313477
Validation loss: 2.4322894439902356

Epoch: 6| Step: 1
Training loss: 2.7337727546691895
Validation loss: 2.4251082917695403

Epoch: 6| Step: 2
Training loss: 2.508958578109741
Validation loss: 2.4125705124229513

Epoch: 6| Step: 3
Training loss: 2.279195785522461
Validation loss: 2.3961301465188303

Epoch: 6| Step: 4
Training loss: 3.1992738246917725
Validation loss: 2.388725762726158

Epoch: 6| Step: 5
Training loss: 2.4539694786071777
Validation loss: 2.384642611267746

Epoch: 6| Step: 6
Training loss: 2.344712257385254
Validation loss: 2.3716796008489465

Epoch: 6| Step: 7
Training loss: 2.954969882965088
Validation loss: 2.3624383941773446

Epoch: 6| Step: 8
Training loss: 2.357454776763916
Validation loss: 2.3567725817362466

Epoch: 6| Step: 9
Training loss: 2.840813636779785
Validation loss: 2.341609795888265

Epoch: 6| Step: 10
Training loss: 2.431666612625122
Validation loss: 2.335767984390259

Epoch: 6| Step: 11
Training loss: 2.4910013675689697
Validation loss: 2.3319017553842194

Epoch: 6| Step: 12
Training loss: 3.1365790367126465
Validation loss: 2.318778981444656

Epoch: 6| Step: 13
Training loss: 2.728419780731201
Validation loss: 2.2993930796141266

Epoch: 17| Step: 0
Training loss: 2.792541980743408
Validation loss: 2.3038236107877506

Epoch: 6| Step: 1
Training loss: 2.877532720565796
Validation loss: 2.2827899943115892

Epoch: 6| Step: 2
Training loss: 2.7411599159240723
Validation loss: 2.284810591769475

Epoch: 6| Step: 3
Training loss: 2.7275352478027344
Validation loss: 2.272374322337489

Epoch: 6| Step: 4
Training loss: 2.502023696899414
Validation loss: 2.26068357242051

Epoch: 6| Step: 5
Training loss: 2.691084623336792
Validation loss: 2.26357166869666

Epoch: 6| Step: 6
Training loss: 2.6795384883880615
Validation loss: 2.267549737807243

Epoch: 6| Step: 7
Training loss: 2.394862651824951
Validation loss: 2.2501392185047107

Epoch: 6| Step: 8
Training loss: 2.326406717300415
Validation loss: 2.2365147913655927

Epoch: 6| Step: 9
Training loss: 1.9916269779205322
Validation loss: 2.247394278485288

Epoch: 6| Step: 10
Training loss: 3.078219413757324
Validation loss: 2.23822921065874

Epoch: 6| Step: 11
Training loss: 1.5973527431488037
Validation loss: 2.2289460141171693

Epoch: 6| Step: 12
Training loss: 2.584402322769165
Validation loss: 2.2215776417845037

Epoch: 6| Step: 13
Training loss: 2.5178020000457764
Validation loss: 2.2064408768889723

Epoch: 18| Step: 0
Training loss: 2.3181490898132324
Validation loss: 2.2171082445370254

Epoch: 6| Step: 1
Training loss: 2.6356935501098633
Validation loss: 2.2046682424442743

Epoch: 6| Step: 2
Training loss: 2.522000312805176
Validation loss: 2.2072615700383342

Epoch: 6| Step: 3
Training loss: 2.6438817977905273
Validation loss: 2.194438601052889

Epoch: 6| Step: 4
Training loss: 2.4783520698547363
Validation loss: 2.184160537617181

Epoch: 6| Step: 5
Training loss: 2.687462329864502
Validation loss: 2.1781578627965783

Epoch: 6| Step: 6
Training loss: 1.6141281127929688
Validation loss: 2.1676280562595656

Epoch: 6| Step: 7
Training loss: 2.1314690113067627
Validation loss: 2.180757281600788

Epoch: 6| Step: 8
Training loss: 2.7275500297546387
Validation loss: 2.181782317417924

Epoch: 6| Step: 9
Training loss: 2.757099151611328
Validation loss: 2.1692049528962825

Epoch: 6| Step: 10
Training loss: 2.2939536571502686
Validation loss: 2.1574405290747203

Epoch: 6| Step: 11
Training loss: 2.5699071884155273
Validation loss: 2.150269023833736

Epoch: 6| Step: 12
Training loss: 2.5265774726867676
Validation loss: 2.149349949693167

Epoch: 6| Step: 13
Training loss: 3.63464617729187
Validation loss: 2.1485280054871754

Epoch: 19| Step: 0
Training loss: 2.220895290374756
Validation loss: 2.141514180808939

Epoch: 6| Step: 1
Training loss: 2.33962345123291
Validation loss: 2.1476162184951124

Epoch: 6| Step: 2
Training loss: 1.894935131072998
Validation loss: 2.135093694092125

Epoch: 6| Step: 3
Training loss: 2.7512030601501465
Validation loss: 2.1402298904234365

Epoch: 6| Step: 4
Training loss: 2.777998447418213
Validation loss: 2.1465393907280377

Epoch: 6| Step: 5
Training loss: 2.369919776916504
Validation loss: 2.1392930707623883

Epoch: 6| Step: 6
Training loss: 2.185523748397827
Validation loss: 2.147844329957039

Epoch: 6| Step: 7
Training loss: 2.57194185256958
Validation loss: 2.1336730705794467

Epoch: 6| Step: 8
Training loss: 3.1425423622131348
Validation loss: 2.135749214438982

Epoch: 6| Step: 9
Training loss: 2.843050718307495
Validation loss: 2.137162744358022

Epoch: 6| Step: 10
Training loss: 2.4512288570404053
Validation loss: 2.137996458238171

Epoch: 6| Step: 11
Training loss: 2.8932251930236816
Validation loss: 2.1323313700255526

Epoch: 6| Step: 12
Training loss: 1.997576355934143
Validation loss: 2.132003040723903

Epoch: 6| Step: 13
Training loss: 1.898795485496521
Validation loss: 2.1241280622379755

Epoch: 20| Step: 0
Training loss: 2.845000743865967
Validation loss: 2.118505402277875

Epoch: 6| Step: 1
Training loss: 2.378453254699707
Validation loss: 2.12464322838732

Epoch: 6| Step: 2
Training loss: 2.2613444328308105
Validation loss: 2.134006425898562

Epoch: 6| Step: 3
Training loss: 2.5570101737976074
Validation loss: 2.105580617022771

Epoch: 6| Step: 4
Training loss: 2.776573657989502
Validation loss: 2.0938803213898853

Epoch: 6| Step: 5
Training loss: 2.4905710220336914
Validation loss: 2.0946435313070975

Epoch: 6| Step: 6
Training loss: 2.2107386589050293
Validation loss: 2.0867056923527874

Epoch: 6| Step: 7
Training loss: 2.499781847000122
Validation loss: 2.0912013310258106

Epoch: 6| Step: 8
Training loss: 2.332855701446533
Validation loss: 2.086059122957209

Epoch: 6| Step: 9
Training loss: 1.8746585845947266
Validation loss: 2.0864196028760684

Epoch: 6| Step: 10
Training loss: 2.822902202606201
Validation loss: 2.0672213287763697

Epoch: 6| Step: 11
Training loss: 3.0101399421691895
Validation loss: 2.063246238616205

Epoch: 6| Step: 12
Training loss: 2.2501015663146973
Validation loss: 2.0822540777985767

Epoch: 6| Step: 13
Training loss: 2.113772392272949
Validation loss: 2.08369953145263

Epoch: 21| Step: 0
Training loss: 2.72658634185791
Validation loss: 2.0728071120477494

Epoch: 6| Step: 1
Training loss: 2.5975279808044434
Validation loss: 2.0907150365973033

Epoch: 6| Step: 2
Training loss: 2.565408706665039
Validation loss: 2.0865466569059636

Epoch: 6| Step: 3
Training loss: 2.5971055030822754
Validation loss: 2.0741683872797156

Epoch: 6| Step: 4
Training loss: 2.532292366027832
Validation loss: 2.081959239898189

Epoch: 6| Step: 5
Training loss: 2.3946051597595215
Validation loss: 2.083293507176061

Epoch: 6| Step: 6
Training loss: 1.911466360092163
Validation loss: 2.0738192040433168

Epoch: 6| Step: 7
Training loss: 2.549030303955078
Validation loss: 2.091462419879052

Epoch: 6| Step: 8
Training loss: 2.4779999256134033
Validation loss: 2.0790818096489034

Epoch: 6| Step: 9
Training loss: 2.6283764839172363
Validation loss: 2.0892380091451828

Epoch: 6| Step: 10
Training loss: 2.270064115524292
Validation loss: 2.0718082099832515

Epoch: 6| Step: 11
Training loss: 2.5754823684692383
Validation loss: 2.0967634108758744

Epoch: 6| Step: 12
Training loss: 2.2931711673736572
Validation loss: 2.0811767091033277

Epoch: 6| Step: 13
Training loss: 1.9993313550949097
Validation loss: 2.0863121619788547

Epoch: 22| Step: 0
Training loss: 2.782630205154419
Validation loss: 2.078263169975691

Epoch: 6| Step: 1
Training loss: 2.1024374961853027
Validation loss: 2.088069910644203

Epoch: 6| Step: 2
Training loss: 2.1918411254882812
Validation loss: 2.0666270730316

Epoch: 6| Step: 3
Training loss: 2.5203096866607666
Validation loss: 2.092852597595543

Epoch: 6| Step: 4
Training loss: 2.244143009185791
Validation loss: 2.068904438326436

Epoch: 6| Step: 5
Training loss: 2.088649034500122
Validation loss: 2.064789689997191

Epoch: 6| Step: 6
Training loss: 1.8385913372039795
Validation loss: 2.0713105740085727

Epoch: 6| Step: 7
Training loss: 2.996845245361328
Validation loss: 2.0656638940175376

Epoch: 6| Step: 8
Training loss: 1.726961612701416
Validation loss: 2.077016733025992

Epoch: 6| Step: 9
Training loss: 2.930969715118408
Validation loss: 2.0622605111009333

Epoch: 6| Step: 10
Training loss: 2.458296775817871
Validation loss: 2.0755613311644523

Epoch: 6| Step: 11
Training loss: 2.292834758758545
Validation loss: 2.0595930391742336

Epoch: 6| Step: 12
Training loss: 3.2978546619415283
Validation loss: 2.0548615737627913

Epoch: 6| Step: 13
Training loss: 2.595705270767212
Validation loss: 2.0422228690116637

Epoch: 23| Step: 0
Training loss: 3.15226149559021
Validation loss: 2.068410829831195

Epoch: 6| Step: 1
Training loss: 1.942603349685669
Validation loss: 2.0589045709179294

Epoch: 6| Step: 2
Training loss: 2.857990264892578
Validation loss: 2.0585461611388833

Epoch: 6| Step: 3
Training loss: 2.665694236755371
Validation loss: 2.0539431764233496

Epoch: 6| Step: 4
Training loss: 2.3530328273773193
Validation loss: 2.0492131812598116

Epoch: 6| Step: 5
Training loss: 2.6179494857788086
Validation loss: 2.0411928699862574

Epoch: 6| Step: 6
Training loss: 2.320021152496338
Validation loss: 2.0458586677428214

Epoch: 6| Step: 7
Training loss: 1.681358814239502
Validation loss: 2.039684892982565

Epoch: 6| Step: 8
Training loss: 2.6376566886901855
Validation loss: 2.0414233412793887

Epoch: 6| Step: 9
Training loss: 1.968703269958496
Validation loss: 2.0386424321000294

Epoch: 6| Step: 10
Training loss: 2.0549960136413574
Validation loss: 2.05297928215355

Epoch: 6| Step: 11
Training loss: 2.6420702934265137
Validation loss: 2.032617815079228

Epoch: 6| Step: 12
Training loss: 2.6874983310699463
Validation loss: 2.038249541354436

Epoch: 6| Step: 13
Training loss: 1.9991236925125122
Validation loss: 2.0538449543778614

Epoch: 24| Step: 0
Training loss: 2.1605026721954346
Validation loss: 2.0290430579134213

Epoch: 6| Step: 1
Training loss: 2.848574161529541
Validation loss: 2.0578852366375666

Epoch: 6| Step: 2
Training loss: 2.1410746574401855
Validation loss: 2.0441028161715438

Epoch: 6| Step: 3
Training loss: 2.076212167739868
Validation loss: 2.0366752429675032

Epoch: 6| Step: 4
Training loss: 2.071178436279297
Validation loss: 2.0415453449372323

Epoch: 6| Step: 5
Training loss: 2.518247127532959
Validation loss: 2.0383951663970947

Epoch: 6| Step: 6
Training loss: 2.5687761306762695
Validation loss: 2.035757641638479

Epoch: 6| Step: 7
Training loss: 2.891835927963257
Validation loss: 2.0505228298966602

Epoch: 6| Step: 8
Training loss: 2.0117292404174805
Validation loss: 2.0455616020387217

Epoch: 6| Step: 9
Training loss: 2.532505750656128
Validation loss: 2.0289524255260343

Epoch: 6| Step: 10
Training loss: 2.4262688159942627
Validation loss: 2.0328885560394614

Epoch: 6| Step: 11
Training loss: 1.9978888034820557
Validation loss: 2.028868859814059

Epoch: 6| Step: 12
Training loss: 2.5306198596954346
Validation loss: 2.0154214892336118

Epoch: 6| Step: 13
Training loss: 3.2608373165130615
Validation loss: 2.0471296579607072

Epoch: 25| Step: 0
Training loss: 2.157482385635376
Validation loss: 2.04047272282262

Epoch: 6| Step: 1
Training loss: 2.697720766067505
Validation loss: 2.0377646800010436

Epoch: 6| Step: 2
Training loss: 1.8811709880828857
Validation loss: 2.0330054657433623

Epoch: 6| Step: 3
Training loss: 2.5135679244995117
Validation loss: 2.0427645355142574

Epoch: 6| Step: 4
Training loss: 2.5213284492492676
Validation loss: 2.026995143582744

Epoch: 6| Step: 5
Training loss: 2.2739458084106445
Validation loss: 2.0310235408044632

Epoch: 6| Step: 6
Training loss: 2.073902130126953
Validation loss: 2.040788150602771

Epoch: 6| Step: 7
Training loss: 2.451633930206299
Validation loss: 2.028251681276547

Epoch: 6| Step: 8
Training loss: 2.7415294647216797
Validation loss: 2.044604209161574

Epoch: 6| Step: 9
Training loss: 2.4106698036193848
Validation loss: 2.034499957997312

Epoch: 6| Step: 10
Training loss: 2.3335511684417725
Validation loss: 2.0331479939081336

Epoch: 6| Step: 11
Training loss: 2.1926729679107666
Validation loss: 2.037905793036184

Epoch: 6| Step: 12
Training loss: 2.8408849239349365
Validation loss: 2.023720507980675

Epoch: 6| Step: 13
Training loss: 2.3774967193603516
Validation loss: 2.037138198011665

Epoch: 26| Step: 0
Training loss: 2.3175625801086426
Validation loss: 2.038492218140633

Epoch: 6| Step: 1
Training loss: 2.0278639793395996
Validation loss: 2.0225396156311035

Epoch: 6| Step: 2
Training loss: 3.1393399238586426
Validation loss: 2.023724182959526

Epoch: 6| Step: 3
Training loss: 3.141235113143921
Validation loss: 2.0168822093676497

Epoch: 6| Step: 4
Training loss: 2.312528133392334
Validation loss: 2.0283861775552072

Epoch: 6| Step: 5
Training loss: 1.5953904390335083
Validation loss: 2.0330640013499925

Epoch: 6| Step: 6
Training loss: 3.0107808113098145
Validation loss: 2.022966759179228

Epoch: 6| Step: 7
Training loss: 1.838655710220337
Validation loss: 2.039404244833095

Epoch: 6| Step: 8
Training loss: 2.9664642810821533
Validation loss: 2.0447896693342473

Epoch: 6| Step: 9
Training loss: 2.3790502548217773
Validation loss: 2.037872829744893

Epoch: 6| Step: 10
Training loss: 2.1700291633605957
Validation loss: 2.043594538524587

Epoch: 6| Step: 11
Training loss: 1.5628411769866943
Validation loss: 2.035287744255476

Epoch: 6| Step: 12
Training loss: 2.3059024810791016
Validation loss: 2.0370691899330384

Epoch: 6| Step: 13
Training loss: 2.5714454650878906
Validation loss: 2.044943545454292

Epoch: 27| Step: 0
Training loss: 1.5893042087554932
Validation loss: 2.053369322130757

Epoch: 6| Step: 1
Training loss: 2.7198808193206787
Validation loss: 2.0340846148870324

Epoch: 6| Step: 2
Training loss: 2.890758514404297
Validation loss: 2.0356526169725644

Epoch: 6| Step: 3
Training loss: 1.5885730981826782
Validation loss: 2.0288955268039497

Epoch: 6| Step: 4
Training loss: 2.799607276916504
Validation loss: 2.040161491722189

Epoch: 6| Step: 5
Training loss: 2.055328845977783
Validation loss: 2.0433361094485045

Epoch: 6| Step: 6
Training loss: 2.5291991233825684
Validation loss: 2.0553240109515447

Epoch: 6| Step: 7
Training loss: 2.7668848037719727
Validation loss: 2.0421087652124386

Epoch: 6| Step: 8
Training loss: 2.5249671936035156
Validation loss: 2.0358870119176884

Epoch: 6| Step: 9
Training loss: 1.9973506927490234
Validation loss: 2.0322273033921436

Epoch: 6| Step: 10
Training loss: 2.420619010925293
Validation loss: 2.0418655923617783

Epoch: 6| Step: 11
Training loss: 1.98398756980896
Validation loss: 2.042367455779865

Epoch: 6| Step: 12
Training loss: 2.648556709289551
Validation loss: 2.0298822900300384

Epoch: 6| Step: 13
Training loss: 2.635871410369873
Validation loss: 2.0488116202815885

Epoch: 28| Step: 0
Training loss: 2.3186962604522705
Validation loss: 2.037287837715559

Epoch: 6| Step: 1
Training loss: 2.253955841064453
Validation loss: 2.0289082501524236

Epoch: 6| Step: 2
Training loss: 2.9029879570007324
Validation loss: 2.036355031433926

Epoch: 6| Step: 3
Training loss: 2.5408661365509033
Validation loss: 2.057119684834634

Epoch: 6| Step: 4
Training loss: 1.8247126340866089
Validation loss: 2.031281784016599

Epoch: 6| Step: 5
Training loss: 2.3759846687316895
Validation loss: 2.0222456224503054

Epoch: 6| Step: 6
Training loss: 2.3263614177703857
Validation loss: 2.041128317515055

Epoch: 6| Step: 7
Training loss: 2.4063525199890137
Validation loss: 2.0380614239682435

Epoch: 6| Step: 8
Training loss: 2.451781988143921
Validation loss: 2.0307906084163214

Epoch: 6| Step: 9
Training loss: 1.2768075466156006
Validation loss: 2.0368158099471882

Epoch: 6| Step: 10
Training loss: 2.8078129291534424
Validation loss: 2.0325278377020233

Epoch: 6| Step: 11
Training loss: 2.148127555847168
Validation loss: 2.029484959058864

Epoch: 6| Step: 12
Training loss: 2.7863335609436035
Validation loss: 2.024772626097484

Epoch: 6| Step: 13
Training loss: 2.2545933723449707
Validation loss: 2.030599424915929

Epoch: 29| Step: 0
Training loss: 2.562507152557373
Validation loss: 2.0116143790624474

Epoch: 6| Step: 1
Training loss: 2.044180393218994
Validation loss: 2.0163618441550963

Epoch: 6| Step: 2
Training loss: 2.2467880249023438
Validation loss: 2.015526258817283

Epoch: 6| Step: 3
Training loss: 2.0468506813049316
Validation loss: 2.0339264074961343

Epoch: 6| Step: 4
Training loss: 2.391071319580078
Validation loss: 2.030187019737818

Epoch: 6| Step: 5
Training loss: 2.7517616748809814
Validation loss: 2.021447104792441

Epoch: 6| Step: 6
Training loss: 2.7553458213806152
Validation loss: 2.010747291708505

Epoch: 6| Step: 7
Training loss: 2.4233741760253906
Validation loss: 2.0163868947695662

Epoch: 6| Step: 8
Training loss: 2.9233546257019043
Validation loss: 2.0305699917577926

Epoch: 6| Step: 9
Training loss: 2.4070990085601807
Validation loss: 2.011152890420729

Epoch: 6| Step: 10
Training loss: 1.3841958045959473
Validation loss: 2.029091614548878

Epoch: 6| Step: 11
Training loss: 2.123713493347168
Validation loss: 2.026839989487843

Epoch: 6| Step: 12
Training loss: 2.4135818481445312
Validation loss: 2.020021850062955

Epoch: 6| Step: 13
Training loss: 2.3923604488372803
Validation loss: 2.0151857573498964

Epoch: 30| Step: 0
Training loss: 1.4228721857070923
Validation loss: 2.0208173797976587

Epoch: 6| Step: 1
Training loss: 2.9796574115753174
Validation loss: 2.0259563211471803

Epoch: 6| Step: 2
Training loss: 1.8212659358978271
Validation loss: 2.019884040278773

Epoch: 6| Step: 3
Training loss: 2.300919532775879
Validation loss: 2.0199890508446643

Epoch: 6| Step: 4
Training loss: 2.2349133491516113
Validation loss: 2.0116202369812997

Epoch: 6| Step: 5
Training loss: 2.1583614349365234
Validation loss: 2.0344980083486086

Epoch: 6| Step: 6
Training loss: 2.354158639907837
Validation loss: 2.0069102177055935

Epoch: 6| Step: 7
Training loss: 2.7235898971557617
Validation loss: 2.0066948680467505

Epoch: 6| Step: 8
Training loss: 2.5091171264648438
Validation loss: 2.0185442970645044

Epoch: 6| Step: 9
Training loss: 2.5201542377471924
Validation loss: 2.005131665096488

Epoch: 6| Step: 10
Training loss: 1.853588581085205
Validation loss: 2.011433929525396

Epoch: 6| Step: 11
Training loss: 2.9186534881591797
Validation loss: 2.020160105920607

Epoch: 6| Step: 12
Training loss: 2.066718578338623
Validation loss: 2.0099418317118

Epoch: 6| Step: 13
Training loss: 3.1201839447021484
Validation loss: 2.0306720182459843

Epoch: 31| Step: 0
Training loss: 2.6596784591674805
Validation loss: 1.992236655245545

Epoch: 6| Step: 1
Training loss: 2.344479560852051
Validation loss: 2.015444269744299

Epoch: 6| Step: 2
Training loss: 2.27787709236145
Validation loss: 2.0202090458203386

Epoch: 6| Step: 3
Training loss: 2.4156267642974854
Validation loss: 2.018517098119182

Epoch: 6| Step: 4
Training loss: 1.7616138458251953
Validation loss: 2.0111436972054104

Epoch: 6| Step: 5
Training loss: 3.035477876663208
Validation loss: 2.018152024156304

Epoch: 6| Step: 6
Training loss: 2.119739294052124
Validation loss: 2.0273438166546565

Epoch: 6| Step: 7
Training loss: 1.811570405960083
Validation loss: 2.001634147859389

Epoch: 6| Step: 8
Training loss: 2.8999290466308594
Validation loss: 2.010559399922689

Epoch: 6| Step: 9
Training loss: 2.5625290870666504
Validation loss: 2.0219365858262583

Epoch: 6| Step: 10
Training loss: 2.277475357055664
Validation loss: 2.032280604044596

Epoch: 6| Step: 11
Training loss: 2.363201141357422
Validation loss: 2.000030718823915

Epoch: 6| Step: 12
Training loss: 1.8730981349945068
Validation loss: 2.037063393541562

Epoch: 6| Step: 13
Training loss: 1.8172136545181274
Validation loss: 2.028586426088887

Epoch: 32| Step: 0
Training loss: 2.0844199657440186
Validation loss: 2.0187618014633015

Epoch: 6| Step: 1
Training loss: 2.7149415016174316
Validation loss: 2.008047088499992

Epoch: 6| Step: 2
Training loss: 2.3275396823883057
Validation loss: 2.0354040309947026

Epoch: 6| Step: 3
Training loss: 2.431718111038208
Validation loss: 2.0119500878036662

Epoch: 6| Step: 4
Training loss: 2.199944496154785
Validation loss: 2.0127763453350274

Epoch: 6| Step: 5
Training loss: 2.090885639190674
Validation loss: 2.013396886087233

Epoch: 6| Step: 6
Training loss: 2.667189598083496
Validation loss: 2.023568117490379

Epoch: 6| Step: 7
Training loss: 2.463589668273926
Validation loss: 1.9995926528848627

Epoch: 6| Step: 8
Training loss: 1.6239187717437744
Validation loss: 2.019437664298601

Epoch: 6| Step: 9
Training loss: 2.420614719390869
Validation loss: 2.010990268440657

Epoch: 6| Step: 10
Training loss: 2.038421392440796
Validation loss: 2.0189470168082946

Epoch: 6| Step: 11
Training loss: 1.7196593284606934
Validation loss: 2.0053619543711343

Epoch: 6| Step: 12
Training loss: 3.004875659942627
Validation loss: 1.9965207679297334

Epoch: 6| Step: 13
Training loss: 2.6833386421203613
Validation loss: 1.9961489259555776

Epoch: 33| Step: 0
Training loss: 2.0590829849243164
Validation loss: 2.0045635110588482

Epoch: 6| Step: 1
Training loss: 2.751038074493408
Validation loss: 2.012503282998198

Epoch: 6| Step: 2
Training loss: 2.311983585357666
Validation loss: 2.0168962209455428

Epoch: 6| Step: 3
Training loss: 2.6034841537475586
Validation loss: 2.0071863820475917

Epoch: 6| Step: 4
Training loss: 2.585186719894409
Validation loss: 2.01104724279014

Epoch: 6| Step: 5
Training loss: 2.295492649078369
Validation loss: 2.0299232685437767

Epoch: 6| Step: 6
Training loss: 2.8793482780456543
Validation loss: 2.0265984509580877

Epoch: 6| Step: 7
Training loss: 1.6958494186401367
Validation loss: 2.0270227219468806

Epoch: 6| Step: 8
Training loss: 2.344386577606201
Validation loss: 2.020827095995667

Epoch: 6| Step: 9
Training loss: 2.041773796081543
Validation loss: 2.013876312522478

Epoch: 6| Step: 10
Training loss: 2.092489719390869
Validation loss: 2.0131503843492076

Epoch: 6| Step: 11
Training loss: 2.2736501693725586
Validation loss: 2.0272358053474018

Epoch: 6| Step: 12
Training loss: 2.0049524307250977
Validation loss: 2.0241848627726235

Epoch: 6| Step: 13
Training loss: 2.619352102279663
Validation loss: 2.0142501425999466

Epoch: 34| Step: 0
Training loss: 3.139911651611328
Validation loss: 2.0150576753001057

Epoch: 6| Step: 1
Training loss: 1.9829661846160889
Validation loss: 2.0168025262894167

Epoch: 6| Step: 2
Training loss: 2.4741902351379395
Validation loss: 2.026097869360319

Epoch: 6| Step: 3
Training loss: 1.8726366758346558
Validation loss: 2.034396093378785

Epoch: 6| Step: 4
Training loss: 2.3549365997314453
Validation loss: 2.0072634040668444

Epoch: 6| Step: 5
Training loss: 3.1363070011138916
Validation loss: 2.0272148155396983

Epoch: 6| Step: 6
Training loss: 1.650712490081787
Validation loss: 2.025951272697859

Epoch: 6| Step: 7
Training loss: 1.8819202184677124
Validation loss: 2.01266687275261

Epoch: 6| Step: 8
Training loss: 1.6759231090545654
Validation loss: 2.0264293224580827

Epoch: 6| Step: 9
Training loss: 2.4375975131988525
Validation loss: 2.0079682104049192

Epoch: 6| Step: 10
Training loss: 3.171483039855957
Validation loss: 2.0124433784074682

Epoch: 6| Step: 11
Training loss: 1.5796228647232056
Validation loss: 2.0114347345085553

Epoch: 6| Step: 12
Training loss: 2.529163360595703
Validation loss: 2.0109441024000927

Epoch: 6| Step: 13
Training loss: 1.9790997505187988
Validation loss: 2.016507669161725

Epoch: 35| Step: 0
Training loss: 3.0022153854370117
Validation loss: 2.015642055901148

Epoch: 6| Step: 1
Training loss: 1.9189006090164185
Validation loss: 2.01539118571948

Epoch: 6| Step: 2
Training loss: 2.3348865509033203
Validation loss: 2.0170272627184467

Epoch: 6| Step: 3
Training loss: 2.169440746307373
Validation loss: 2.010808442228584

Epoch: 6| Step: 4
Training loss: 2.296424388885498
Validation loss: 2.0121881705458446

Epoch: 6| Step: 5
Training loss: 2.240771532058716
Validation loss: 2.0280742606809063

Epoch: 6| Step: 6
Training loss: 2.0484864711761475
Validation loss: 2.0273415093780844

Epoch: 6| Step: 7
Training loss: 2.0949978828430176
Validation loss: 2.0120679922001337

Epoch: 6| Step: 8
Training loss: 2.6733765602111816
Validation loss: 2.0196842224367204

Epoch: 6| Step: 9
Training loss: 2.5411815643310547
Validation loss: 2.040172646122594

Epoch: 6| Step: 10
Training loss: 2.730238914489746
Validation loss: 2.010762527424802

Epoch: 6| Step: 11
Training loss: 2.12233567237854
Validation loss: 2.0010693509091615

Epoch: 6| Step: 12
Training loss: 1.9593216180801392
Validation loss: 2.0268178498873146

Epoch: 6| Step: 13
Training loss: 1.5673826932907104
Validation loss: 2.020713584397429

Epoch: 36| Step: 0
Training loss: 2.8634145259857178
Validation loss: 2.0115077572484172

Epoch: 6| Step: 1
Training loss: 2.9556288719177246
Validation loss: 2.011717953989583

Epoch: 6| Step: 2
Training loss: 2.4051156044006348
Validation loss: 2.010434018668308

Epoch: 6| Step: 3
Training loss: 1.419176697731018
Validation loss: 1.9996226808076263

Epoch: 6| Step: 4
Training loss: 2.8543269634246826
Validation loss: 2.0337195780969437

Epoch: 6| Step: 5
Training loss: 3.0985093116760254
Validation loss: 2.0066367580044653

Epoch: 6| Step: 6
Training loss: 2.2608418464660645
Validation loss: 2.0030509528293403

Epoch: 6| Step: 7
Training loss: 2.569946765899658
Validation loss: 2.0020346205721617

Epoch: 6| Step: 8
Training loss: 1.4111930131912231
Validation loss: 2.008995468898486

Epoch: 6| Step: 9
Training loss: 1.3997528553009033
Validation loss: 2.0153145815736506

Epoch: 6| Step: 10
Training loss: 2.562774181365967
Validation loss: 2.030501495125473

Epoch: 6| Step: 11
Training loss: 1.9775811433792114
Validation loss: 2.0079655493459394

Epoch: 6| Step: 12
Training loss: 2.1703453063964844
Validation loss: 2.0198006501761814

Epoch: 6| Step: 13
Training loss: 1.9123075008392334
Validation loss: 2.0078896655831286

Epoch: 37| Step: 0
Training loss: 2.114915609359741
Validation loss: 2.0166417001396097

Epoch: 6| Step: 1
Training loss: 2.4723806381225586
Validation loss: 2.028195991311022

Epoch: 6| Step: 2
Training loss: 2.4770894050598145
Validation loss: 2.0047486841037707

Epoch: 6| Step: 3
Training loss: 2.707608699798584
Validation loss: 2.0137120805760866

Epoch: 6| Step: 4
Training loss: 1.652783989906311
Validation loss: 2.015246623305864

Epoch: 6| Step: 5
Training loss: 1.8627244234085083
Validation loss: 2.0047256767108874

Epoch: 6| Step: 6
Training loss: 2.4555327892303467
Validation loss: 2.0008166387516964

Epoch: 6| Step: 7
Training loss: 2.393184185028076
Validation loss: 2.0010787581884735

Epoch: 6| Step: 8
Training loss: 1.8367701768875122
Validation loss: 1.996318878666047

Epoch: 6| Step: 9
Training loss: 2.61116623878479
Validation loss: 2.0254106367788007

Epoch: 6| Step: 10
Training loss: 2.792022228240967
Validation loss: 2.0109499628825853

Epoch: 6| Step: 11
Training loss: 1.7549293041229248
Validation loss: 2.0273258173337547

Epoch: 6| Step: 12
Training loss: 2.5110859870910645
Validation loss: 2.025630884273078

Epoch: 6| Step: 13
Training loss: 2.197266101837158
Validation loss: 2.0150740838819936

Epoch: 38| Step: 0
Training loss: 2.7002813816070557
Validation loss: 2.0317028402000346

Epoch: 6| Step: 1
Training loss: 2.4475862979888916
Validation loss: 2.016617627554042

Epoch: 6| Step: 2
Training loss: 2.3036141395568848
Validation loss: 2.0243795969152965

Epoch: 6| Step: 3
Training loss: 2.5895581245422363
Validation loss: 2.0225404641961537

Epoch: 6| Step: 4
Training loss: 2.305992603302002
Validation loss: 2.0256148384463404

Epoch: 6| Step: 5
Training loss: 2.120983123779297
Validation loss: 2.0420447241875435

Epoch: 6| Step: 6
Training loss: 2.1290807723999023
Validation loss: 2.0263870005966513

Epoch: 6| Step: 7
Training loss: 1.8077728748321533
Validation loss: 2.0253407698805614

Epoch: 6| Step: 8
Training loss: 2.2575056552886963
Validation loss: 2.0320252731282222

Epoch: 6| Step: 9
Training loss: 1.727824330329895
Validation loss: 2.019922928143573

Epoch: 6| Step: 10
Training loss: 2.56296968460083
Validation loss: 2.013016013688939

Epoch: 6| Step: 11
Training loss: 2.3484747409820557
Validation loss: 2.0262523748541392

Epoch: 6| Step: 12
Training loss: 2.158876419067383
Validation loss: 2.0164987733287196

Epoch: 6| Step: 13
Training loss: 2.179708242416382
Validation loss: 2.017649599300918

Epoch: 39| Step: 0
Training loss: 2.361776828765869
Validation loss: 2.0174435159211517

Epoch: 6| Step: 1
Training loss: 1.8854563236236572
Validation loss: 2.021916740684099

Epoch: 6| Step: 2
Training loss: 1.4856761693954468
Validation loss: 2.021059436182822

Epoch: 6| Step: 3
Training loss: 2.660679578781128
Validation loss: 2.0252281876020533

Epoch: 6| Step: 4
Training loss: 2.182931423187256
Validation loss: 2.0156402318708357

Epoch: 6| Step: 5
Training loss: 2.2830824851989746
Validation loss: 2.007846322110904

Epoch: 6| Step: 6
Training loss: 2.3507168292999268
Validation loss: 2.016566894387686

Epoch: 6| Step: 7
Training loss: 2.1889896392822266
Validation loss: 2.005217158666221

Epoch: 6| Step: 8
Training loss: 2.0092098712921143
Validation loss: 2.0303663951094433

Epoch: 6| Step: 9
Training loss: 2.9064173698425293
Validation loss: 2.0300078994484356

Epoch: 6| Step: 10
Training loss: 1.844852089881897
Validation loss: 2.0275259376854025

Epoch: 6| Step: 11
Training loss: 2.281975030899048
Validation loss: 2.031067831541902

Epoch: 6| Step: 12
Training loss: 2.9567432403564453
Validation loss: 2.0178269058145504

Epoch: 6| Step: 13
Training loss: 2.4546961784362793
Validation loss: 2.0194901830406597

Epoch: 40| Step: 0
Training loss: 1.6361093521118164
Validation loss: 2.034486183556177

Epoch: 6| Step: 1
Training loss: 2.442079544067383
Validation loss: 2.022255707812566

Epoch: 6| Step: 2
Training loss: 2.5146241188049316
Validation loss: 2.031758513501895

Epoch: 6| Step: 3
Training loss: 2.1339774131774902
Validation loss: 2.0277026289252826

Epoch: 6| Step: 4
Training loss: 2.0887858867645264
Validation loss: 2.0271453690785233

Epoch: 6| Step: 5
Training loss: 2.2031354904174805
Validation loss: 2.021259352725039

Epoch: 6| Step: 6
Training loss: 2.5494027137756348
Validation loss: 2.040766713439777

Epoch: 6| Step: 7
Training loss: 2.2222533226013184
Validation loss: 2.0296440278330157

Epoch: 6| Step: 8
Training loss: 1.9850504398345947
Validation loss: 2.014659323999959

Epoch: 6| Step: 9
Training loss: 3.0015058517456055
Validation loss: 2.044302543004354

Epoch: 6| Step: 10
Training loss: 2.0171494483947754
Validation loss: 2.027314968006585

Epoch: 6| Step: 11
Training loss: 2.4034433364868164
Validation loss: 2.0338525310639413

Epoch: 6| Step: 12
Training loss: 1.9356592893600464
Validation loss: 2.0469156208858696

Epoch: 6| Step: 13
Training loss: 2.864337921142578
Validation loss: 2.039050876453359

Epoch: 41| Step: 0
Training loss: 1.8180263042449951
Validation loss: 2.0259114093677972

Epoch: 6| Step: 1
Training loss: 2.2879889011383057
Validation loss: 2.0482717162819317

Epoch: 6| Step: 2
Training loss: 2.1087698936462402
Validation loss: 2.0379254702598817

Epoch: 6| Step: 3
Training loss: 2.0824623107910156
Validation loss: 2.0384530457117225

Epoch: 6| Step: 4
Training loss: 2.5579564571380615
Validation loss: 2.037236511066396

Epoch: 6| Step: 5
Training loss: 2.265251398086548
Validation loss: 2.0189897296249226

Epoch: 6| Step: 6
Training loss: 2.8239316940307617
Validation loss: 2.034222670780715

Epoch: 6| Step: 7
Training loss: 2.0541086196899414
Validation loss: 2.03519090273047

Epoch: 6| Step: 8
Training loss: 2.606057643890381
Validation loss: 2.0268262022285053

Epoch: 6| Step: 9
Training loss: 1.8663581609725952
Validation loss: 2.0282228518557806

Epoch: 6| Step: 10
Training loss: 2.4347469806671143
Validation loss: 2.047674622586978

Epoch: 6| Step: 11
Training loss: 2.3215770721435547
Validation loss: 2.0351136089653097

Epoch: 6| Step: 12
Training loss: 2.4208502769470215
Validation loss: 2.0323840777079263

Epoch: 6| Step: 13
Training loss: 1.7468507289886475
Validation loss: 2.0253553646866993

Epoch: 42| Step: 0
Training loss: 1.831871509552002
Validation loss: 2.0093899080830235

Epoch: 6| Step: 1
Training loss: 1.7803562879562378
Validation loss: 2.0150665493421656

Epoch: 6| Step: 2
Training loss: 1.8110527992248535
Validation loss: 2.013044447027227

Epoch: 6| Step: 3
Training loss: 1.896097183227539
Validation loss: 2.015494877292264

Epoch: 6| Step: 4
Training loss: 2.3192014694213867
Validation loss: 2.021240277956891

Epoch: 6| Step: 5
Training loss: 2.281642436981201
Validation loss: 2.017625753597547

Epoch: 6| Step: 6
Training loss: 1.7756834030151367
Validation loss: 2.0052897366144324

Epoch: 6| Step: 7
Training loss: 2.0197572708129883
Validation loss: 2.018661199077483

Epoch: 6| Step: 8
Training loss: 3.0876708030700684
Validation loss: 2.00800641634131

Epoch: 6| Step: 9
Training loss: 2.1976523399353027
Validation loss: 2.004553497478526

Epoch: 6| Step: 10
Training loss: 1.849704623222351
Validation loss: 1.9918789786677207

Epoch: 6| Step: 11
Training loss: 2.897879123687744
Validation loss: 2.020368350449429

Epoch: 6| Step: 12
Training loss: 3.1607775688171387
Validation loss: 2.036659409922938

Epoch: 6| Step: 13
Training loss: 3.0926005840301514
Validation loss: 2.0230194907034598

Epoch: 43| Step: 0
Training loss: 2.1914191246032715
Validation loss: 2.0172840933645926

Epoch: 6| Step: 1
Training loss: 1.9054919481277466
Validation loss: 2.030798017337758

Epoch: 6| Step: 2
Training loss: 2.3967108726501465
Validation loss: 2.0167192310415287

Epoch: 6| Step: 3
Training loss: 2.146092653274536
Validation loss: 2.0212746115141016

Epoch: 6| Step: 4
Training loss: 1.7780864238739014
Validation loss: 2.020761946196197

Epoch: 6| Step: 5
Training loss: 1.686854600906372
Validation loss: 2.0106722026742916

Epoch: 6| Step: 6
Training loss: 2.2965195178985596
Validation loss: 2.010427628794024

Epoch: 6| Step: 7
Training loss: 2.4471330642700195
Validation loss: 2.0385530097510225

Epoch: 6| Step: 8
Training loss: 1.912326693534851
Validation loss: 2.032581098618046

Epoch: 6| Step: 9
Training loss: 2.8390936851501465
Validation loss: 2.023369550704956

Epoch: 6| Step: 10
Training loss: 2.7852749824523926
Validation loss: 2.033789462940667

Epoch: 6| Step: 11
Training loss: 2.7991504669189453
Validation loss: 2.0191352059764247

Epoch: 6| Step: 12
Training loss: 1.825189232826233
Validation loss: 2.0288991107735583

Epoch: 6| Step: 13
Training loss: 2.8191981315612793
Validation loss: 2.0568486413648053

Epoch: 44| Step: 0
Training loss: 2.4590182304382324
Validation loss: 2.049882432465912

Epoch: 6| Step: 1
Training loss: 1.6621371507644653
Validation loss: 2.0321699675693305

Epoch: 6| Step: 2
Training loss: 2.193568706512451
Validation loss: 2.0352000126274685

Epoch: 6| Step: 3
Training loss: 2.432798385620117
Validation loss: 2.0290988260699856

Epoch: 6| Step: 4
Training loss: 2.4668374061584473
Validation loss: 2.0387149036571546

Epoch: 6| Step: 5
Training loss: 2.4813995361328125
Validation loss: 2.0443586713524273

Epoch: 6| Step: 6
Training loss: 1.7357795238494873
Validation loss: 2.0325256534802016

Epoch: 6| Step: 7
Training loss: 1.8476145267486572
Validation loss: 2.0429496777954923

Epoch: 6| Step: 8
Training loss: 1.9070477485656738
Validation loss: 2.0275453175267866

Epoch: 6| Step: 9
Training loss: 2.184340000152588
Validation loss: 2.0112983872813563

Epoch: 6| Step: 10
Training loss: 2.400240421295166
Validation loss: 2.037406697068163

Epoch: 6| Step: 11
Training loss: 2.4757823944091797
Validation loss: 2.0253030407813286

Epoch: 6| Step: 12
Training loss: 2.7940196990966797
Validation loss: 2.027321748836066

Epoch: 6| Step: 13
Training loss: 2.4043803215026855
Validation loss: 2.0290971904672603

Epoch: 45| Step: 0
Training loss: 1.665081262588501
Validation loss: 2.0353591057562057

Epoch: 6| Step: 1
Training loss: 2.650442600250244
Validation loss: 2.0270451422660583

Epoch: 6| Step: 2
Training loss: 2.5265650749206543
Validation loss: 2.0124698479970298

Epoch: 6| Step: 3
Training loss: 2.7326016426086426
Validation loss: 2.0309822738811536

Epoch: 6| Step: 4
Training loss: 3.0083842277526855
Validation loss: 2.036695406001101

Epoch: 6| Step: 5
Training loss: 1.715944528579712
Validation loss: 2.0300228006096295

Epoch: 6| Step: 6
Training loss: 1.4750347137451172
Validation loss: 2.037693367209486

Epoch: 6| Step: 7
Training loss: 2.3076393604278564
Validation loss: 2.028509695042846

Epoch: 6| Step: 8
Training loss: 1.8058658838272095
Validation loss: 2.0339383514978553

Epoch: 6| Step: 9
Training loss: 2.0727686882019043
Validation loss: 2.0259064641050113

Epoch: 6| Step: 10
Training loss: 1.7367862462997437
Validation loss: 2.02523632203379

Epoch: 6| Step: 11
Training loss: 2.5235719680786133
Validation loss: 2.0371739620803506

Epoch: 6| Step: 12
Training loss: 2.242238998413086
Validation loss: 2.0326436091494817

Epoch: 6| Step: 13
Training loss: 3.460634708404541
Validation loss: 2.041485289091705

Epoch: 46| Step: 0
Training loss: 2.273465633392334
Validation loss: 2.044655656301847

Epoch: 6| Step: 1
Training loss: 1.8789912462234497
Validation loss: 2.039882585566531

Epoch: 6| Step: 2
Training loss: 1.7245101928710938
Validation loss: 2.0229926391314437

Epoch: 6| Step: 3
Training loss: 2.3478822708129883
Validation loss: 2.026050670813489

Epoch: 6| Step: 4
Training loss: 2.86505389213562
Validation loss: 2.0289597870201193

Epoch: 6| Step: 5
Training loss: 2.5336365699768066
Validation loss: 2.017585221157279

Epoch: 6| Step: 6
Training loss: 2.3330562114715576
Validation loss: 2.0367138770318802

Epoch: 6| Step: 7
Training loss: 2.232970714569092
Validation loss: 2.0269766289700746

Epoch: 6| Step: 8
Training loss: 2.2747185230255127
Validation loss: 2.0372251285019742

Epoch: 6| Step: 9
Training loss: 2.4045279026031494
Validation loss: 2.0373169311913113

Epoch: 6| Step: 10
Training loss: 1.7470424175262451
Validation loss: 2.027840998864943

Epoch: 6| Step: 11
Training loss: 1.8791682720184326
Validation loss: 2.0350421090279855

Epoch: 6| Step: 12
Training loss: 2.1961066722869873
Validation loss: 2.020819333291823

Epoch: 6| Step: 13
Training loss: 3.107356071472168
Validation loss: 2.040925852714046

Epoch: 47| Step: 0
Training loss: 2.403115749359131
Validation loss: 2.0334927523007957

Epoch: 6| Step: 1
Training loss: 2.5813069343566895
Validation loss: 2.0321754614512124

Epoch: 6| Step: 2
Training loss: 2.7274041175842285
Validation loss: 2.037120073072372

Epoch: 6| Step: 3
Training loss: 2.6525659561157227
Validation loss: 2.032143609498137

Epoch: 6| Step: 4
Training loss: 2.311054229736328
Validation loss: 2.0408685207366943

Epoch: 6| Step: 5
Training loss: 2.645944833755493
Validation loss: 2.0335956734995686

Epoch: 6| Step: 6
Training loss: 1.797795295715332
Validation loss: 2.049233503239129

Epoch: 6| Step: 7
Training loss: 1.6701406240463257
Validation loss: 2.0193023117639686

Epoch: 6| Step: 8
Training loss: 1.8445031642913818
Validation loss: 2.0178293220458494

Epoch: 6| Step: 9
Training loss: 2.2290334701538086
Validation loss: 2.03004369940809

Epoch: 6| Step: 10
Training loss: 1.7993334531784058
Validation loss: 2.0447924290933917

Epoch: 6| Step: 11
Training loss: 2.344965934753418
Validation loss: 2.0209900358671784

Epoch: 6| Step: 12
Training loss: 2.015896797180176
Validation loss: 2.0154360673760854

Epoch: 6| Step: 13
Training loss: 2.4714698791503906
Validation loss: 2.0364795448959514

Epoch: 48| Step: 0
Training loss: 2.1563827991485596
Validation loss: 2.036387023105416

Epoch: 6| Step: 1
Training loss: 1.9627331495285034
Validation loss: 2.019563101953076

Epoch: 6| Step: 2
Training loss: 1.7706224918365479
Validation loss: 2.019169342133307

Epoch: 6| Step: 3
Training loss: 2.520203113555908
Validation loss: 2.0247746231735393

Epoch: 6| Step: 4
Training loss: 1.5211633443832397
Validation loss: 2.02223805714679

Epoch: 6| Step: 5
Training loss: 2.9808201789855957
Validation loss: 2.0423503396331624

Epoch: 6| Step: 6
Training loss: 2.3143224716186523
Validation loss: 2.032404226641501

Epoch: 6| Step: 7
Training loss: 1.5839327573776245
Validation loss: 2.033394113663704

Epoch: 6| Step: 8
Training loss: 2.2859039306640625
Validation loss: 2.025645004805698

Epoch: 6| Step: 9
Training loss: 2.5168631076812744
Validation loss: 2.021332621574402

Epoch: 6| Step: 10
Training loss: 2.5245537757873535
Validation loss: 2.0090346720910843

Epoch: 6| Step: 11
Training loss: 2.5599563121795654
Validation loss: 2.0234137094149025

Epoch: 6| Step: 12
Training loss: 2.549075126647949
Validation loss: 2.028298903537053

Epoch: 6| Step: 13
Training loss: 2.00376558303833
Validation loss: 2.051689604277252

Epoch: 49| Step: 0
Training loss: 1.797611951828003
Validation loss: 2.03092388696568

Epoch: 6| Step: 1
Training loss: 2.5749313831329346
Validation loss: 2.0558774368737334

Epoch: 6| Step: 2
Training loss: 2.26556396484375
Validation loss: 2.034534090308733

Epoch: 6| Step: 3
Training loss: 2.56441068649292
Validation loss: 2.0260034312484083

Epoch: 6| Step: 4
Training loss: 1.934208631515503
Validation loss: 2.028972871841923

Epoch: 6| Step: 5
Training loss: 2.9375832080841064
Validation loss: 2.0288384063269502

Epoch: 6| Step: 6
Training loss: 2.681391954421997
Validation loss: 2.0302494700236986

Epoch: 6| Step: 7
Training loss: 1.7729315757751465
Validation loss: 2.0500438726076515

Epoch: 6| Step: 8
Training loss: 2.5839874744415283
Validation loss: 2.041823411500582

Epoch: 6| Step: 9
Training loss: 1.9165600538253784
Validation loss: 2.0383909863810383

Epoch: 6| Step: 10
Training loss: 1.7769191265106201
Validation loss: 2.052541963515743

Epoch: 6| Step: 11
Training loss: 2.078691005706787
Validation loss: 2.0487860761662966

Epoch: 6| Step: 12
Training loss: 1.9525476694107056
Validation loss: 2.0430883079446773

Epoch: 6| Step: 13
Training loss: 2.572826862335205
Validation loss: 2.0542478151218866

Epoch: 50| Step: 0
Training loss: 2.3632595539093018
Validation loss: 2.0510779042397775

Epoch: 6| Step: 1
Training loss: 2.0512032508850098
Validation loss: 2.037392580381004

Epoch: 6| Step: 2
Training loss: 1.959266185760498
Validation loss: 2.046330844202349

Epoch: 6| Step: 3
Training loss: 2.5077176094055176
Validation loss: 2.0484783546898955

Epoch: 6| Step: 4
Training loss: 2.274634838104248
Validation loss: 2.0431240066405265

Epoch: 6| Step: 5
Training loss: 1.726137399673462
Validation loss: 2.0476947035840762

Epoch: 6| Step: 6
Training loss: 2.0551838874816895
Validation loss: 2.0261366598067747

Epoch: 6| Step: 7
Training loss: 2.5458180904388428
Validation loss: 2.0164016036577124

Epoch: 6| Step: 8
Training loss: 2.163984775543213
Validation loss: 2.04986979628122

Epoch: 6| Step: 9
Training loss: 2.3439013957977295
Validation loss: 2.058611167374478

Epoch: 6| Step: 10
Training loss: 1.9341152906417847
Validation loss: 2.0507380680371354

Epoch: 6| Step: 11
Training loss: 1.8760312795639038
Validation loss: 2.0467871927445933

Epoch: 6| Step: 12
Training loss: 3.2322397232055664
Validation loss: 2.075025943017775

Epoch: 6| Step: 13
Training loss: 2.219109058380127
Validation loss: 2.0524668796088106

Epoch: 51| Step: 0
Training loss: 2.2727108001708984
Validation loss: 2.0591191463573004

Epoch: 6| Step: 1
Training loss: 2.4881365299224854
Validation loss: 2.0388392658643824

Epoch: 6| Step: 2
Training loss: 2.1279029846191406
Validation loss: 2.0510827085023284

Epoch: 6| Step: 3
Training loss: 1.8577407598495483
Validation loss: 2.065487002813688

Epoch: 6| Step: 4
Training loss: 1.4791163206100464
Validation loss: 2.062785074275027

Epoch: 6| Step: 5
Training loss: 2.1796226501464844
Validation loss: 2.0604453394489903

Epoch: 6| Step: 6
Training loss: 2.1614646911621094
Validation loss: 2.0532454598334526

Epoch: 6| Step: 7
Training loss: 2.3520710468292236
Validation loss: 2.0507782543859174

Epoch: 6| Step: 8
Training loss: 2.2824487686157227
Validation loss: 2.0568851001801027

Epoch: 6| Step: 9
Training loss: 2.8313002586364746
Validation loss: 2.045191180321478

Epoch: 6| Step: 10
Training loss: 2.212324857711792
Validation loss: 2.046686827495534

Epoch: 6| Step: 11
Training loss: 2.6662659645080566
Validation loss: 2.0374745027993315

Epoch: 6| Step: 12
Training loss: 2.3391218185424805
Validation loss: 2.051282500707975

Epoch: 6| Step: 13
Training loss: 1.7582552433013916
Validation loss: 2.0457675008363623

Epoch: 52| Step: 0
Training loss: 2.1933839321136475
Validation loss: 2.034539140680785

Epoch: 6| Step: 1
Training loss: 2.5011744499206543
Validation loss: 2.044449537031112

Epoch: 6| Step: 2
Training loss: 1.6351814270019531
Validation loss: 2.038908984071465

Epoch: 6| Step: 3
Training loss: 1.7207380533218384
Validation loss: 2.0461918384798112

Epoch: 6| Step: 4
Training loss: 2.401914358139038
Validation loss: 2.034960421182776

Epoch: 6| Step: 5
Training loss: 2.242969036102295
Validation loss: 2.0241230354514173

Epoch: 6| Step: 6
Training loss: 1.928131103515625
Validation loss: 2.0399341160251248

Epoch: 6| Step: 7
Training loss: 2.534040689468384
Validation loss: 2.0499591571028515

Epoch: 6| Step: 8
Training loss: 2.2055044174194336
Validation loss: 2.0380451602320515

Epoch: 6| Step: 9
Training loss: 2.0780019760131836
Validation loss: 2.031439683770621

Epoch: 6| Step: 10
Training loss: 2.7597339153289795
Validation loss: 2.0383390918854745

Epoch: 6| Step: 11
Training loss: 2.3482351303100586
Validation loss: 2.0543707134903118

Epoch: 6| Step: 12
Training loss: 2.188255548477173
Validation loss: 2.0526273891489994

Epoch: 6| Step: 13
Training loss: 2.4089159965515137
Validation loss: 2.0309251521223333

Epoch: 53| Step: 0
Training loss: 2.279843807220459
Validation loss: 2.032093176277735

Epoch: 6| Step: 1
Training loss: 2.1988821029663086
Validation loss: 2.0363874640516055

Epoch: 6| Step: 2
Training loss: 2.9078688621520996
Validation loss: 2.0416595987094346

Epoch: 6| Step: 3
Training loss: 2.473574161529541
Validation loss: 2.033618397610162

Epoch: 6| Step: 4
Training loss: 2.0806615352630615
Validation loss: 2.030482324220801

Epoch: 6| Step: 5
Training loss: 1.8797377347946167
Validation loss: 2.0342573453021306

Epoch: 6| Step: 6
Training loss: 2.375620126724243
Validation loss: 2.0322959461519794

Epoch: 6| Step: 7
Training loss: 1.522221326828003
Validation loss: 2.047067371747827

Epoch: 6| Step: 8
Training loss: 2.569145441055298
Validation loss: 2.0384772823702906

Epoch: 6| Step: 9
Training loss: 1.9299240112304688
Validation loss: 2.0358242142585015

Epoch: 6| Step: 10
Training loss: 2.5633435249328613
Validation loss: 2.0521337832173994

Epoch: 6| Step: 11
Training loss: 1.2753053903579712
Validation loss: 2.0548495579791326

Epoch: 6| Step: 12
Training loss: 2.370326519012451
Validation loss: 2.0382158038436726

Epoch: 6| Step: 13
Training loss: 3.389943838119507
Validation loss: 2.0116796185893397

Epoch: 54| Step: 0
Training loss: 1.9051363468170166
Validation loss: 2.027832059450047

Epoch: 6| Step: 1
Training loss: 2.27028226852417
Validation loss: 2.051647614407283

Epoch: 6| Step: 2
Training loss: 2.131805419921875
Validation loss: 2.045478424718303

Epoch: 6| Step: 3
Training loss: 1.8156046867370605
Validation loss: 2.025987366194366

Epoch: 6| Step: 4
Training loss: 2.3951735496520996
Validation loss: 2.0388251786590903

Epoch: 6| Step: 5
Training loss: 2.8222084045410156
Validation loss: 2.038156836263595

Epoch: 6| Step: 6
Training loss: 1.973710536956787
Validation loss: 2.0565901776795745

Epoch: 6| Step: 7
Training loss: 1.8176720142364502
Validation loss: 2.0550757454287623

Epoch: 6| Step: 8
Training loss: 1.8412803411483765
Validation loss: 2.039448158715361

Epoch: 6| Step: 9
Training loss: 2.0051002502441406
Validation loss: 2.0502335256145847

Epoch: 6| Step: 10
Training loss: 2.4992804527282715
Validation loss: 2.046235889516851

Epoch: 6| Step: 11
Training loss: 2.625281810760498
Validation loss: 2.0241991858328543

Epoch: 6| Step: 12
Training loss: 2.8567779064178467
Validation loss: 2.027260036878688

Epoch: 6| Step: 13
Training loss: 2.046105146408081
Validation loss: 2.044894544027185

Epoch: 55| Step: 0
Training loss: 2.1795475482940674
Validation loss: 2.0309991477638163

Epoch: 6| Step: 1
Training loss: 1.4931964874267578
Validation loss: 2.03200440765709

Epoch: 6| Step: 2
Training loss: 2.0606675148010254
Validation loss: 2.0398586603903

Epoch: 6| Step: 3
Training loss: 2.1006062030792236
Validation loss: 2.027174057499055

Epoch: 6| Step: 4
Training loss: 2.7270612716674805
Validation loss: 2.0415055982528196

Epoch: 6| Step: 5
Training loss: 2.6637353897094727
Validation loss: 2.025144551389961

Epoch: 6| Step: 6
Training loss: 1.9786901473999023
Validation loss: 2.035131932586752

Epoch: 6| Step: 7
Training loss: 2.2967629432678223
Validation loss: 2.028083642323812

Epoch: 6| Step: 8
Training loss: 1.7877764701843262
Validation loss: 2.041560629362701

Epoch: 6| Step: 9
Training loss: 1.9013279676437378
Validation loss: 2.0234636299071775

Epoch: 6| Step: 10
Training loss: 2.105600357055664
Validation loss: 2.039768165157687

Epoch: 6| Step: 11
Training loss: 2.836024761199951
Validation loss: 2.0388914974786903

Epoch: 6| Step: 12
Training loss: 2.6804354190826416
Validation loss: 2.0436910807445483

Epoch: 6| Step: 13
Training loss: 2.1865007877349854
Validation loss: 2.047842597448698

Epoch: 56| Step: 0
Training loss: 2.1696481704711914
Validation loss: 2.0571135551698747

Epoch: 6| Step: 1
Training loss: 2.489915370941162
Validation loss: 2.041786014392812

Epoch: 6| Step: 2
Training loss: 2.0606601238250732
Validation loss: 2.056971380787511

Epoch: 6| Step: 3
Training loss: 1.9255561828613281
Validation loss: 2.0472223015241724

Epoch: 6| Step: 4
Training loss: 2.6151509284973145
Validation loss: 2.036882160812296

Epoch: 6| Step: 5
Training loss: 1.873583436012268
Validation loss: 2.0331433626913253

Epoch: 6| Step: 6
Training loss: 2.7543163299560547
Validation loss: 2.0559512235785045

Epoch: 6| Step: 7
Training loss: 1.9853312969207764
Validation loss: 2.0164355257506013

Epoch: 6| Step: 8
Training loss: 1.9811370372772217
Validation loss: 2.046264039572849

Epoch: 6| Step: 9
Training loss: 1.6857750415802002
Validation loss: 2.030429309414279

Epoch: 6| Step: 10
Training loss: 2.1143956184387207
Validation loss: 2.0285464115040277

Epoch: 6| Step: 11
Training loss: 2.218005418777466
Validation loss: 2.0252020589766966

Epoch: 6| Step: 12
Training loss: 3.234910488128662
Validation loss: 2.0324890305919032

Epoch: 6| Step: 13
Training loss: 1.745152235031128
Validation loss: 2.057778522532473

Epoch: 57| Step: 0
Training loss: 2.4228572845458984
Validation loss: 2.058880049695251

Epoch: 6| Step: 1
Training loss: 2.094144821166992
Validation loss: 2.04293684164683

Epoch: 6| Step: 2
Training loss: 2.637742042541504
Validation loss: 2.0440293024945

Epoch: 6| Step: 3
Training loss: 2.070913314819336
Validation loss: 2.04555280106042

Epoch: 6| Step: 4
Training loss: 2.2484514713287354
Validation loss: 2.037126539855875

Epoch: 6| Step: 5
Training loss: 2.002664566040039
Validation loss: 2.027427823312821

Epoch: 6| Step: 6
Training loss: 2.0659303665161133
Validation loss: 2.034701439642137

Epoch: 6| Step: 7
Training loss: 2.204517364501953
Validation loss: 2.0557655083235873

Epoch: 6| Step: 8
Training loss: 2.4554100036621094
Validation loss: 2.0681267707578597

Epoch: 6| Step: 9
Training loss: 2.071258068084717
Validation loss: 2.050867667762182

Epoch: 6| Step: 10
Training loss: 2.2034075260162354
Validation loss: 2.045876233808456

Epoch: 6| Step: 11
Training loss: 2.572540760040283
Validation loss: 2.0427459247650637

Epoch: 6| Step: 12
Training loss: 2.21531343460083
Validation loss: 2.051499210378175

Epoch: 6| Step: 13
Training loss: 1.5296226739883423
Validation loss: 2.055562068057317

Epoch: 58| Step: 0
Training loss: 1.7995927333831787
Validation loss: 2.0467729081389723

Epoch: 6| Step: 1
Training loss: 2.0793046951293945
Validation loss: 2.0528760853634087

Epoch: 6| Step: 2
Training loss: 1.8215681314468384
Validation loss: 2.050203029827405

Epoch: 6| Step: 3
Training loss: 2.3107519149780273
Validation loss: 2.0432508812155774

Epoch: 6| Step: 4
Training loss: 1.9986753463745117
Validation loss: 2.0267026821772256

Epoch: 6| Step: 5
Training loss: 2.5946645736694336
Validation loss: 2.059267661904776

Epoch: 6| Step: 6
Training loss: 2.766369342803955
Validation loss: 2.04624968190347

Epoch: 6| Step: 7
Training loss: 2.1559958457946777
Validation loss: 2.0410197498977825

Epoch: 6| Step: 8
Training loss: 1.866039752960205
Validation loss: 2.037205501269269

Epoch: 6| Step: 9
Training loss: 2.4251983165740967
Validation loss: 2.0384566886450655

Epoch: 6| Step: 10
Training loss: 2.0937600135803223
Validation loss: 2.044367528730823

Epoch: 6| Step: 11
Training loss: 2.091141939163208
Validation loss: 2.041281166897025

Epoch: 6| Step: 12
Training loss: 2.896819829940796
Validation loss: 2.0327018486556185

Epoch: 6| Step: 13
Training loss: 1.5078845024108887
Validation loss: 2.044066100992182

Epoch: 59| Step: 0
Training loss: 2.144101619720459
Validation loss: 2.0371222790851387

Epoch: 6| Step: 1
Training loss: 2.4557254314422607
Validation loss: 2.0300930494903238

Epoch: 6| Step: 2
Training loss: 2.2355010509490967
Validation loss: 2.044581949069936

Epoch: 6| Step: 3
Training loss: 1.945627212524414
Validation loss: 2.0519285227662776

Epoch: 6| Step: 4
Training loss: 2.3204185962677
Validation loss: 2.0351640985858057

Epoch: 6| Step: 5
Training loss: 2.0423221588134766
Validation loss: 2.0426443058957338

Epoch: 6| Step: 6
Training loss: 1.992295265197754
Validation loss: 2.026280700519521

Epoch: 6| Step: 7
Training loss: 2.476774215698242
Validation loss: 2.043954086560075

Epoch: 6| Step: 8
Training loss: 2.612762451171875
Validation loss: 2.0218344196196525

Epoch: 6| Step: 9
Training loss: 1.7360389232635498
Validation loss: 2.044129479315973

Epoch: 6| Step: 10
Training loss: 2.2351016998291016
Validation loss: 2.0511356348632486

Epoch: 6| Step: 11
Training loss: 1.604461908340454
Validation loss: 2.0277736648436515

Epoch: 6| Step: 12
Training loss: 2.6874966621398926
Validation loss: 2.030547224065309

Epoch: 6| Step: 13
Training loss: 2.6948323249816895
Validation loss: 2.0343777159208893

Epoch: 60| Step: 0
Training loss: 2.585817575454712
Validation loss: 2.0363302333380586

Epoch: 6| Step: 1
Training loss: 2.421660900115967
Validation loss: 2.0453990326132825

Epoch: 6| Step: 2
Training loss: 1.881886601448059
Validation loss: 2.0212050227708716

Epoch: 6| Step: 3
Training loss: 2.107835054397583
Validation loss: 2.0375374260769097

Epoch: 6| Step: 4
Training loss: 2.209223985671997
Validation loss: 2.0460390621615994

Epoch: 6| Step: 5
Training loss: 1.8481018543243408
Validation loss: 2.045104467740623

Epoch: 6| Step: 6
Training loss: 2.1008946895599365
Validation loss: 2.0504880771842053

Epoch: 6| Step: 7
Training loss: 1.9848289489746094
Validation loss: 2.057144175293625

Epoch: 6| Step: 8
Training loss: 1.6113005876541138
Validation loss: 2.0417370398839316

Epoch: 6| Step: 9
Training loss: 3.092860221862793
Validation loss: 2.0408356035909345

Epoch: 6| Step: 10
Training loss: 2.3043856620788574
Validation loss: 2.047183718732608

Epoch: 6| Step: 11
Training loss: 1.99979829788208
Validation loss: 2.0531413401326826

Epoch: 6| Step: 12
Training loss: 3.1058177947998047
Validation loss: 2.047622093590357

Epoch: 6| Step: 13
Training loss: 1.327872395515442
Validation loss: 2.043441205896357

Epoch: 61| Step: 0
Training loss: 2.2340219020843506
Validation loss: 2.063356666154759

Epoch: 6| Step: 1
Training loss: 1.9111504554748535
Validation loss: 2.051927520382789

Epoch: 6| Step: 2
Training loss: 1.8792178630828857
Validation loss: 2.062056541442871

Epoch: 6| Step: 3
Training loss: 2.1769843101501465
Validation loss: 2.0351899195742864

Epoch: 6| Step: 4
Training loss: 2.5088601112365723
Validation loss: 2.033460191501084

Epoch: 6| Step: 5
Training loss: 2.3852109909057617
Validation loss: 2.0411268216307445

Epoch: 6| Step: 6
Training loss: 2.2424142360687256
Validation loss: 2.0286421878363496

Epoch: 6| Step: 7
Training loss: 2.6124401092529297
Validation loss: 2.0545210287135136

Epoch: 6| Step: 8
Training loss: 2.4297657012939453
Validation loss: 2.021463212146554

Epoch: 6| Step: 9
Training loss: 2.1087417602539062
Validation loss: 2.055532306753179

Epoch: 6| Step: 10
Training loss: 1.8717265129089355
Validation loss: 2.04574171445703

Epoch: 6| Step: 11
Training loss: 2.27811861038208
Validation loss: 2.0274449548413678

Epoch: 6| Step: 12
Training loss: 2.433546781539917
Validation loss: 2.039837552655128

Epoch: 6| Step: 13
Training loss: 1.230634331703186
Validation loss: 2.0357564008364113

Epoch: 62| Step: 0
Training loss: 2.660490036010742
Validation loss: 2.020596096592565

Epoch: 6| Step: 1
Training loss: 2.558173656463623
Validation loss: 2.0256772733503774

Epoch: 6| Step: 2
Training loss: 2.3163795471191406
Validation loss: 2.057272188125118

Epoch: 6| Step: 3
Training loss: 2.6506423950195312
Validation loss: 2.032499244136195

Epoch: 6| Step: 4
Training loss: 2.4403934478759766
Validation loss: 2.046023832854404

Epoch: 6| Step: 5
Training loss: 2.180722236633301
Validation loss: 2.045106021306848

Epoch: 6| Step: 6
Training loss: 1.9210240840911865
Validation loss: 2.0496145127921976

Epoch: 6| Step: 7
Training loss: 2.119647741317749
Validation loss: 2.043116546446277

Epoch: 6| Step: 8
Training loss: 1.6000258922576904
Validation loss: 2.064015378234207

Epoch: 6| Step: 9
Training loss: 2.0845234394073486
Validation loss: 2.0384600098415087

Epoch: 6| Step: 10
Training loss: 1.7954130172729492
Validation loss: 2.029555379703481

Epoch: 6| Step: 11
Training loss: 2.429572582244873
Validation loss: 2.0118750064603743

Epoch: 6| Step: 12
Training loss: 1.693963885307312
Validation loss: 2.0485777008918022

Epoch: 6| Step: 13
Training loss: 2.2106809616088867
Validation loss: 2.0395874156746814

Epoch: 63| Step: 0
Training loss: 1.7950130701065063
Validation loss: 2.0522401922492572

Epoch: 6| Step: 1
Training loss: 2.1604719161987305
Validation loss: 2.0445243825194654

Epoch: 6| Step: 2
Training loss: 1.3694130182266235
Validation loss: 2.036266888341596

Epoch: 6| Step: 3
Training loss: 2.7808756828308105
Validation loss: 2.0511416004550074

Epoch: 6| Step: 4
Training loss: 2.60404109954834
Validation loss: 2.0420005321502686

Epoch: 6| Step: 5
Training loss: 2.2153677940368652
Validation loss: 2.054954085298764

Epoch: 6| Step: 6
Training loss: 1.4453277587890625
Validation loss: 2.029313718118975

Epoch: 6| Step: 7
Training loss: 3.6297855377197266
Validation loss: 2.0637366438424714

Epoch: 6| Step: 8
Training loss: 2.976107597351074
Validation loss: 2.0397625841120237

Epoch: 6| Step: 9
Training loss: 1.610131025314331
Validation loss: 2.0357130035277335

Epoch: 6| Step: 10
Training loss: 2.1598381996154785
Validation loss: 2.034913524504631

Epoch: 6| Step: 11
Training loss: 1.9308981895446777
Validation loss: 2.040668072239045

Epoch: 6| Step: 12
Training loss: 2.025151252746582
Validation loss: 2.057292196058458

Epoch: 6| Step: 13
Training loss: 1.9415812492370605
Validation loss: 2.0598535255719255

Epoch: 64| Step: 0
Training loss: 2.083704710006714
Validation loss: 2.046373116072788

Epoch: 6| Step: 1
Training loss: 2.244892120361328
Validation loss: 2.0555974027161956

Epoch: 6| Step: 2
Training loss: 1.8914494514465332
Validation loss: 2.057062059320429

Epoch: 6| Step: 3
Training loss: 2.4801530838012695
Validation loss: 2.0404267157277753

Epoch: 6| Step: 4
Training loss: 1.8485603332519531
Validation loss: 2.0389874237839893

Epoch: 6| Step: 5
Training loss: 2.7289414405822754
Validation loss: 2.0426690693824523

Epoch: 6| Step: 6
Training loss: 2.0370171070098877
Validation loss: 2.037721303201491

Epoch: 6| Step: 7
Training loss: 2.3113646507263184
Validation loss: 2.037428835386871

Epoch: 6| Step: 8
Training loss: 2.060734748840332
Validation loss: 2.0465376454014934

Epoch: 6| Step: 9
Training loss: 1.9646008014678955
Validation loss: 2.0502085288365683

Epoch: 6| Step: 10
Training loss: 2.197906970977783
Validation loss: 2.0521462604563725

Epoch: 6| Step: 11
Training loss: 2.662212371826172
Validation loss: 2.0576876235264603

Epoch: 6| Step: 12
Training loss: 1.9568254947662354
Validation loss: 2.0310222410386607

Epoch: 6| Step: 13
Training loss: 2.222384452819824
Validation loss: 2.0423317186294065

Epoch: 65| Step: 0
Training loss: 1.9025800228118896
Validation loss: 2.051973767178033

Epoch: 6| Step: 1
Training loss: 2.3880467414855957
Validation loss: 2.0494655537348923

Epoch: 6| Step: 2
Training loss: 1.8429920673370361
Validation loss: 2.0411292916984967

Epoch: 6| Step: 3
Training loss: 2.256606101989746
Validation loss: 2.0340777699665358

Epoch: 6| Step: 4
Training loss: 2.653228998184204
Validation loss: 2.0553621322877946

Epoch: 6| Step: 5
Training loss: 2.0893733501434326
Validation loss: 2.0630809786499187

Epoch: 6| Step: 6
Training loss: 2.8591270446777344
Validation loss: 2.055131604594569

Epoch: 6| Step: 7
Training loss: 1.8435513973236084
Validation loss: 2.0356647942655828

Epoch: 6| Step: 8
Training loss: 1.9827320575714111
Validation loss: 2.0577749283083024

Epoch: 6| Step: 9
Training loss: 2.204555034637451
Validation loss: 2.0771348886592413

Epoch: 6| Step: 10
Training loss: 1.8405029773712158
Validation loss: 2.0609616169365506

Epoch: 6| Step: 11
Training loss: 2.2055442333221436
Validation loss: 2.040121232309649

Epoch: 6| Step: 12
Training loss: 2.559673309326172
Validation loss: 2.0501738902061217

Epoch: 6| Step: 13
Training loss: 1.533172845840454
Validation loss: 2.051793670141569

Epoch: 66| Step: 0
Training loss: 1.9530799388885498
Validation loss: 2.0517817722853793

Epoch: 6| Step: 1
Training loss: 1.7862364053726196
Validation loss: 2.0517456275160595

Epoch: 6| Step: 2
Training loss: 2.6026196479797363
Validation loss: 2.045265002917218

Epoch: 6| Step: 3
Training loss: 2.7040107250213623
Validation loss: 2.0506026437205653

Epoch: 6| Step: 4
Training loss: 1.8508673906326294
Validation loss: 2.036100019690811

Epoch: 6| Step: 5
Training loss: 1.4991471767425537
Validation loss: 2.052432842152093

Epoch: 6| Step: 6
Training loss: 2.421963691711426
Validation loss: 2.0501024646143757

Epoch: 6| Step: 7
Training loss: 2.051089286804199
Validation loss: 2.0485331294357136

Epoch: 6| Step: 8
Training loss: 1.4545700550079346
Validation loss: 2.0420385560681744

Epoch: 6| Step: 9
Training loss: 3.4010636806488037
Validation loss: 2.0450098553011493

Epoch: 6| Step: 10
Training loss: 2.4786148071289062
Validation loss: 2.0476523560862385

Epoch: 6| Step: 11
Training loss: 1.6354784965515137
Validation loss: 2.0572299829093357

Epoch: 6| Step: 12
Training loss: 2.01623797416687
Validation loss: 2.067346285748225

Epoch: 6| Step: 13
Training loss: 2.9647607803344727
Validation loss: 2.0455732935218403

Epoch: 67| Step: 0
Training loss: 2.186736822128296
Validation loss: 2.0631639675427507

Epoch: 6| Step: 1
Training loss: 2.2313666343688965
Validation loss: 2.0786616110032603

Epoch: 6| Step: 2
Training loss: 2.0622923374176025
Validation loss: 2.0608320313115276

Epoch: 6| Step: 3
Training loss: 2.4061336517333984
Validation loss: 2.0720315261553695

Epoch: 6| Step: 4
Training loss: 2.0168707370758057
Validation loss: 2.0807631759233374

Epoch: 6| Step: 5
Training loss: 2.143918037414551
Validation loss: 2.0495256711077947

Epoch: 6| Step: 6
Training loss: 2.465147018432617
Validation loss: 2.067301345127885

Epoch: 6| Step: 7
Training loss: 2.2372775077819824
Validation loss: 2.075962746015159

Epoch: 6| Step: 8
Training loss: 1.8407949209213257
Validation loss: 2.0672658310141614

Epoch: 6| Step: 9
Training loss: 1.7862169742584229
Validation loss: 2.0659419131535355

Epoch: 6| Step: 10
Training loss: 2.7678580284118652
Validation loss: 2.0566644719851914

Epoch: 6| Step: 11
Training loss: 2.0743956565856934
Validation loss: 2.0469902715375348

Epoch: 6| Step: 12
Training loss: 2.609031915664673
Validation loss: 2.0496827530604538

Epoch: 6| Step: 13
Training loss: 1.368499517440796
Validation loss: 2.0665563460319274

Epoch: 68| Step: 0
Training loss: 1.8455779552459717
Validation loss: 2.0474358963710007

Epoch: 6| Step: 1
Training loss: 2.4509992599487305
Validation loss: 2.0745774469067975

Epoch: 6| Step: 2
Training loss: 1.7362112998962402
Validation loss: 2.060261482833534

Epoch: 6| Step: 3
Training loss: 2.079625368118286
Validation loss: 2.056539771377399

Epoch: 6| Step: 4
Training loss: 2.3474884033203125
Validation loss: 2.0405000102135444

Epoch: 6| Step: 5
Training loss: 2.0829484462738037
Validation loss: 2.053272766451682

Epoch: 6| Step: 6
Training loss: 2.004074811935425
Validation loss: 2.066632939923194

Epoch: 6| Step: 7
Training loss: 2.1609630584716797
Validation loss: 2.059818269104086

Epoch: 6| Step: 8
Training loss: 2.0626368522644043
Validation loss: 2.0544337675135624

Epoch: 6| Step: 9
Training loss: 2.2010045051574707
Validation loss: 2.0638838673150666

Epoch: 6| Step: 10
Training loss: 1.8666436672210693
Validation loss: 2.0472770326881

Epoch: 6| Step: 11
Training loss: 2.781001329421997
Validation loss: 2.064819359010266

Epoch: 6| Step: 12
Training loss: 2.7814860343933105
Validation loss: 2.066971307159752

Epoch: 6| Step: 13
Training loss: 2.193798303604126
Validation loss: 2.044173740571545

Epoch: 69| Step: 0
Training loss: 2.864737033843994
Validation loss: 2.034668485323588

Epoch: 6| Step: 1
Training loss: 1.6297237873077393
Validation loss: 2.068155519423946

Epoch: 6| Step: 2
Training loss: 1.938895583152771
Validation loss: 2.058579896086006

Epoch: 6| Step: 3
Training loss: 2.0306243896484375
Validation loss: 2.054479996363322

Epoch: 6| Step: 4
Training loss: 2.0947937965393066
Validation loss: 2.0633116563161216

Epoch: 6| Step: 5
Training loss: 2.3561244010925293
Validation loss: 2.0444841307978474

Epoch: 6| Step: 6
Training loss: 1.927389144897461
Validation loss: 2.0634362351509834

Epoch: 6| Step: 7
Training loss: 2.6332318782806396
Validation loss: 2.065451818127786

Epoch: 6| Step: 8
Training loss: 2.0571775436401367
Validation loss: 2.0435226271229405

Epoch: 6| Step: 9
Training loss: 2.528782367706299
Validation loss: 2.051852423657653

Epoch: 6| Step: 10
Training loss: 2.073240041732788
Validation loss: 2.042591360307509

Epoch: 6| Step: 11
Training loss: 2.1172661781311035
Validation loss: 2.071370529872115

Epoch: 6| Step: 12
Training loss: 2.065640687942505
Validation loss: 2.050557774882163

Epoch: 6| Step: 13
Training loss: 2.11391544342041
Validation loss: 2.0492998720497213

Epoch: 70| Step: 0
Training loss: 1.867798089981079
Validation loss: 2.0518686258664696

Epoch: 6| Step: 1
Training loss: 2.5205507278442383
Validation loss: 2.062906383186258

Epoch: 6| Step: 2
Training loss: 2.437025785446167
Validation loss: 2.0489908700348227

Epoch: 6| Step: 3
Training loss: 2.8398008346557617
Validation loss: 2.05871089812248

Epoch: 6| Step: 4
Training loss: 1.8993123769760132
Validation loss: 2.0429546820220126

Epoch: 6| Step: 5
Training loss: 2.0147197246551514
Validation loss: 2.0559962077807357

Epoch: 6| Step: 6
Training loss: 2.3553874492645264
Validation loss: 2.0387214229952906

Epoch: 6| Step: 7
Training loss: 2.567815065383911
Validation loss: 2.0427261039774907

Epoch: 6| Step: 8
Training loss: 1.6356028318405151
Validation loss: 2.0503496200807634

Epoch: 6| Step: 9
Training loss: 2.688241958618164
Validation loss: 2.057785198252688

Epoch: 6| Step: 10
Training loss: 2.1651031970977783
Validation loss: 2.062369341491371

Epoch: 6| Step: 11
Training loss: 1.6922602653503418
Validation loss: 2.054041841978668

Epoch: 6| Step: 12
Training loss: 1.6718392372131348
Validation loss: 2.0465561959051315

Epoch: 6| Step: 13
Training loss: 1.997892141342163
Validation loss: 2.061531127140086

Epoch: 71| Step: 0
Training loss: 1.9073216915130615
Validation loss: 2.045771880816388

Epoch: 6| Step: 1
Training loss: 3.27215313911438
Validation loss: 2.046287287947952

Epoch: 6| Step: 2
Training loss: 2.371528148651123
Validation loss: 2.064255156824666

Epoch: 6| Step: 3
Training loss: 1.8291993141174316
Validation loss: 2.0576886976918867

Epoch: 6| Step: 4
Training loss: 2.2831852436065674
Validation loss: 2.0617974163383566

Epoch: 6| Step: 5
Training loss: 2.372431755065918
Validation loss: 2.0541498276495163

Epoch: 6| Step: 6
Training loss: 2.2726683616638184
Validation loss: 2.048484416418178

Epoch: 6| Step: 7
Training loss: 2.435370922088623
Validation loss: 2.069887989310808

Epoch: 6| Step: 8
Training loss: 1.5297120809555054
Validation loss: 2.040986439233185

Epoch: 6| Step: 9
Training loss: 1.6512930393218994
Validation loss: 2.059167808102023

Epoch: 6| Step: 10
Training loss: 1.8585851192474365
Validation loss: 2.0417406584626887

Epoch: 6| Step: 11
Training loss: 2.206909656524658
Validation loss: 2.064411344066743

Epoch: 6| Step: 12
Training loss: 1.9501911401748657
Validation loss: 2.0369666353348763

Epoch: 6| Step: 13
Training loss: 2.717817783355713
Validation loss: 2.058862029865224

Epoch: 72| Step: 0
Training loss: 2.0994760990142822
Validation loss: 2.0510949524500037

Epoch: 6| Step: 1
Training loss: 1.8177558183670044
Validation loss: 2.0692102063086724

Epoch: 6| Step: 2
Training loss: 2.0707454681396484
Validation loss: 2.054649588882282

Epoch: 6| Step: 3
Training loss: 1.8423233032226562
Validation loss: 2.053472013883693

Epoch: 6| Step: 4
Training loss: 2.3319568634033203
Validation loss: 2.0813176042290142

Epoch: 6| Step: 5
Training loss: 1.6015958786010742
Validation loss: 2.050680483541181

Epoch: 6| Step: 6
Training loss: 2.7164180278778076
Validation loss: 2.0568137168884277

Epoch: 6| Step: 7
Training loss: 2.2579538822174072
Validation loss: 2.0608663905051445

Epoch: 6| Step: 8
Training loss: 2.0568602085113525
Validation loss: 2.060886808620986

Epoch: 6| Step: 9
Training loss: 2.7666759490966797
Validation loss: 2.0589652856191

Epoch: 6| Step: 10
Training loss: 2.8628697395324707
Validation loss: 2.0598362517613236

Epoch: 6| Step: 11
Training loss: 2.5158727169036865
Validation loss: 2.0496874355500743

Epoch: 6| Step: 12
Training loss: 1.8050984144210815
Validation loss: 2.042977830415131

Epoch: 6| Step: 13
Training loss: 1.4067472219467163
Validation loss: 2.038719631010486

Epoch: 73| Step: 0
Training loss: 2.5278940200805664
Validation loss: 2.060243853958704

Epoch: 6| Step: 1
Training loss: 1.4741079807281494
Validation loss: 2.041772752679804

Epoch: 6| Step: 2
Training loss: 2.6717605590820312
Validation loss: 2.0615877156616538

Epoch: 6| Step: 3
Training loss: 2.002718925476074
Validation loss: 2.030552687183503

Epoch: 6| Step: 4
Training loss: 2.167102336883545
Validation loss: 2.066780303114204

Epoch: 6| Step: 5
Training loss: 2.363142490386963
Validation loss: 2.031524468493718

Epoch: 6| Step: 6
Training loss: 1.9641690254211426
Validation loss: 2.04269818593097

Epoch: 6| Step: 7
Training loss: 2.5725300312042236
Validation loss: 2.033736636561732

Epoch: 6| Step: 8
Training loss: 2.698232889175415
Validation loss: 2.044611538610151

Epoch: 6| Step: 9
Training loss: 2.483975887298584
Validation loss: 2.0484619012442966

Epoch: 6| Step: 10
Training loss: 1.9264942407608032
Validation loss: 2.0463644086673694

Epoch: 6| Step: 11
Training loss: 1.9798851013183594
Validation loss: 2.0409028145574752

Epoch: 6| Step: 12
Training loss: 1.5114665031433105
Validation loss: 2.0437720796113372

Epoch: 6| Step: 13
Training loss: 1.964537501335144
Validation loss: 2.0540860468341458

Epoch: 74| Step: 0
Training loss: 2.042917251586914
Validation loss: 2.0478923090042604

Epoch: 6| Step: 1
Training loss: 2.346853256225586
Validation loss: 2.0457989887524675

Epoch: 6| Step: 2
Training loss: 2.2646236419677734
Validation loss: 2.0637388344733947

Epoch: 6| Step: 3
Training loss: 1.8781183958053589
Validation loss: 2.0538144893543695

Epoch: 6| Step: 4
Training loss: 1.907211422920227
Validation loss: 2.0579105654070453

Epoch: 6| Step: 5
Training loss: 1.9145512580871582
Validation loss: 2.0502351791627946

Epoch: 6| Step: 6
Training loss: 2.334167957305908
Validation loss: 2.047101587377569

Epoch: 6| Step: 7
Training loss: 2.236180543899536
Validation loss: 2.052955832532657

Epoch: 6| Step: 8
Training loss: 2.448089361190796
Validation loss: 2.0559342163865284

Epoch: 6| Step: 9
Training loss: 1.5773814916610718
Validation loss: 2.043354832997886

Epoch: 6| Step: 10
Training loss: 2.198259115219116
Validation loss: 2.0531321943447156

Epoch: 6| Step: 11
Training loss: 2.148653984069824
Validation loss: 2.053573049524779

Epoch: 6| Step: 12
Training loss: 2.50762939453125
Validation loss: 2.053357747293288

Epoch: 6| Step: 13
Training loss: 2.68084716796875
Validation loss: 2.061850578554215

Epoch: 75| Step: 0
Training loss: 1.8468060493469238
Validation loss: 2.064763563935475

Epoch: 6| Step: 1
Training loss: 1.9487252235412598
Validation loss: 2.05338426046474

Epoch: 6| Step: 2
Training loss: 3.2343313694000244
Validation loss: 2.06430806139464

Epoch: 6| Step: 3
Training loss: 2.055776596069336
Validation loss: 2.066299828149939

Epoch: 6| Step: 4
Training loss: 2.0561704635620117
Validation loss: 2.0514895582711823

Epoch: 6| Step: 5
Training loss: 2.3733410835266113
Validation loss: 2.065746312500328

Epoch: 6| Step: 6
Training loss: 2.301170587539673
Validation loss: 2.036499492583736

Epoch: 6| Step: 7
Training loss: 2.15999698638916
Validation loss: 2.0496220409229235

Epoch: 6| Step: 8
Training loss: 2.103727102279663
Validation loss: 2.0434755253535446

Epoch: 6| Step: 9
Training loss: 2.203188896179199
Validation loss: 2.0556677028697026

Epoch: 6| Step: 10
Training loss: 2.0314369201660156
Validation loss: 2.054527900552237

Epoch: 6| Step: 11
Training loss: 1.6477856636047363
Validation loss: 2.0543939528926725

Epoch: 6| Step: 12
Training loss: 2.2326197624206543
Validation loss: 2.0537272076452933

Epoch: 6| Step: 13
Training loss: 2.063523530960083
Validation loss: 2.0689813193454536

Epoch: 76| Step: 0
Training loss: 1.6541435718536377
Validation loss: 2.034973172731297

Epoch: 6| Step: 1
Training loss: 2.3383164405822754
Validation loss: 2.057128772940687

Epoch: 6| Step: 2
Training loss: 1.6254522800445557
Validation loss: 2.06554845071608

Epoch: 6| Step: 3
Training loss: 2.455744981765747
Validation loss: 2.0567365051597677

Epoch: 6| Step: 4
Training loss: 2.175774574279785
Validation loss: 2.05086919312836

Epoch: 6| Step: 5
Training loss: 2.1628217697143555
Validation loss: 2.051491952711536

Epoch: 6| Step: 6
Training loss: 2.2392468452453613
Validation loss: 2.049425845505089

Epoch: 6| Step: 7
Training loss: 2.6819913387298584
Validation loss: 2.035703900039837

Epoch: 6| Step: 8
Training loss: 2.0074522495269775
Validation loss: 2.0500392567726875

Epoch: 6| Step: 9
Training loss: 1.5718767642974854
Validation loss: 2.0702558576419787

Epoch: 6| Step: 10
Training loss: 1.981560468673706
Validation loss: 2.0538492587304886

Epoch: 6| Step: 11
Training loss: 2.00593900680542
Validation loss: 2.0420596702124483

Epoch: 6| Step: 12
Training loss: 2.3214826583862305
Validation loss: 2.035487118587699

Epoch: 6| Step: 13
Training loss: 3.2837703227996826
Validation loss: 2.0458667278289795

Epoch: 77| Step: 0
Training loss: 2.610856533050537
Validation loss: 2.0821189072824295

Epoch: 6| Step: 1
Training loss: 1.6223244667053223
Validation loss: 2.0507484123271

Epoch: 6| Step: 2
Training loss: 1.7429031133651733
Validation loss: 2.049019367464127

Epoch: 6| Step: 3
Training loss: 2.889686346054077
Validation loss: 2.0498352999328286

Epoch: 6| Step: 4
Training loss: 1.9860737323760986
Validation loss: 2.051160552168405

Epoch: 6| Step: 5
Training loss: 1.7776198387145996
Validation loss: 2.0610254592792963

Epoch: 6| Step: 6
Training loss: 2.2629892826080322
Validation loss: 2.0487173372699368

Epoch: 6| Step: 7
Training loss: 2.2443013191223145
Validation loss: 2.050258385237827

Epoch: 6| Step: 8
Training loss: 1.7724087238311768
Validation loss: 2.0484109001774944

Epoch: 6| Step: 9
Training loss: 2.2656123638153076
Validation loss: 2.058228756791802

Epoch: 6| Step: 10
Training loss: 2.2606048583984375
Validation loss: 2.0671924839737597

Epoch: 6| Step: 11
Training loss: 2.4610495567321777
Validation loss: 2.0442644267953853

Epoch: 6| Step: 12
Training loss: 2.4502320289611816
Validation loss: 2.0619924786270305

Epoch: 6| Step: 13
Training loss: 1.6516518592834473
Validation loss: 2.04115734177251

Epoch: 78| Step: 0
Training loss: 2.5517525672912598
Validation loss: 2.0653122573770504

Epoch: 6| Step: 1
Training loss: 1.7015875577926636
Validation loss: 2.049660041768064

Epoch: 6| Step: 2
Training loss: 2.893256902694702
Validation loss: 2.0632270510478685

Epoch: 6| Step: 3
Training loss: 2.1851625442504883
Validation loss: 2.0483715098391295

Epoch: 6| Step: 4
Training loss: 1.9629504680633545
Validation loss: 2.062863178150628

Epoch: 6| Step: 5
Training loss: 1.63405442237854
Validation loss: 2.0518977411331667

Epoch: 6| Step: 6
Training loss: 2.466198444366455
Validation loss: 2.0530092408580165

Epoch: 6| Step: 7
Training loss: 2.390768051147461
Validation loss: 2.0731043431066696

Epoch: 6| Step: 8
Training loss: 1.8659355640411377
Validation loss: 2.0299499611700735

Epoch: 6| Step: 9
Training loss: 2.4398727416992188
Validation loss: 2.056776891472519

Epoch: 6| Step: 10
Training loss: 2.392120361328125
Validation loss: 2.0583831289763093

Epoch: 6| Step: 11
Training loss: 2.263420820236206
Validation loss: 2.0629545437392367

Epoch: 6| Step: 12
Training loss: 1.7131061553955078
Validation loss: 2.075856380565192

Epoch: 6| Step: 13
Training loss: 1.1157244443893433
Validation loss: 2.052861587975615

Epoch: 79| Step: 0
Training loss: 2.683454751968384
Validation loss: 2.059797566424134

Epoch: 6| Step: 1
Training loss: 2.6599369049072266
Validation loss: 2.06211325558283

Epoch: 6| Step: 2
Training loss: 1.5276192426681519
Validation loss: 2.0282517966403755

Epoch: 6| Step: 3
Training loss: 3.361361026763916
Validation loss: 2.056626501903739

Epoch: 6| Step: 4
Training loss: 2.0338873863220215
Validation loss: 2.0558232184379333

Epoch: 6| Step: 5
Training loss: 2.1270618438720703
Validation loss: 2.0588949547019055

Epoch: 6| Step: 6
Training loss: 1.9571465253829956
Validation loss: 2.0354719956715903

Epoch: 6| Step: 7
Training loss: 1.670777440071106
Validation loss: 2.052616009148218

Epoch: 6| Step: 8
Training loss: 1.869450330734253
Validation loss: 2.0562168218756236

Epoch: 6| Step: 9
Training loss: 1.5950210094451904
Validation loss: 2.0669047268488074

Epoch: 6| Step: 10
Training loss: 2.9124746322631836
Validation loss: 2.04562113618338

Epoch: 6| Step: 11
Training loss: 1.7591557502746582
Validation loss: 2.0688433775337796

Epoch: 6| Step: 12
Training loss: 1.8957427740097046
Validation loss: 2.0452376591261996

Epoch: 6| Step: 13
Training loss: 2.0576512813568115
Validation loss: 2.059294835213692

Epoch: 80| Step: 0
Training loss: 2.11824107170105
Validation loss: 2.0568980888653825

Epoch: 6| Step: 1
Training loss: 1.6681642532348633
Validation loss: 2.049629339607813

Epoch: 6| Step: 2
Training loss: 2.3528289794921875
Validation loss: 2.058547609595842

Epoch: 6| Step: 3
Training loss: 1.8064013719558716
Validation loss: 2.055188307198145

Epoch: 6| Step: 4
Training loss: 1.767910361289978
Validation loss: 2.0623886790326846

Epoch: 6| Step: 5
Training loss: 1.9049968719482422
Validation loss: 2.0698842233227146

Epoch: 6| Step: 6
Training loss: 2.469097137451172
Validation loss: 2.049571970457672

Epoch: 6| Step: 7
Training loss: 2.182098388671875
Validation loss: 2.0715456060183945

Epoch: 6| Step: 8
Training loss: 2.396623373031616
Validation loss: 2.058689635287049

Epoch: 6| Step: 9
Training loss: 2.225804090499878
Validation loss: 2.06181687437078

Epoch: 6| Step: 10
Training loss: 2.536414623260498
Validation loss: 2.052214632752121

Epoch: 6| Step: 11
Training loss: 2.3549726009368896
Validation loss: 2.0613514505406862

Epoch: 6| Step: 12
Training loss: 2.5034689903259277
Validation loss: 2.062665262529927

Epoch: 6| Step: 13
Training loss: 1.7376947402954102
Validation loss: 2.060028237681235

Epoch: 81| Step: 0
Training loss: 1.423440933227539
Validation loss: 2.047066286046018

Epoch: 6| Step: 1
Training loss: 2.762118339538574
Validation loss: 2.0345236639822684

Epoch: 6| Step: 2
Training loss: 2.020387649536133
Validation loss: 2.0697551901622484

Epoch: 6| Step: 3
Training loss: 2.528480052947998
Validation loss: 2.048556653402185

Epoch: 6| Step: 4
Training loss: 2.561363697052002
Validation loss: 2.0488410918943343

Epoch: 6| Step: 5
Training loss: 1.9890477657318115
Validation loss: 2.0458579371052403

Epoch: 6| Step: 6
Training loss: 1.8591419458389282
Validation loss: 2.047898413032614

Epoch: 6| Step: 7
Training loss: 1.9683187007904053
Validation loss: 2.0857500222421463

Epoch: 6| Step: 8
Training loss: 2.3541946411132812
Validation loss: 2.072913028860605

Epoch: 6| Step: 9
Training loss: 1.8704216480255127
Validation loss: 2.0531279399830806

Epoch: 6| Step: 10
Training loss: 2.351900577545166
Validation loss: 2.0598311552437405

Epoch: 6| Step: 11
Training loss: 1.8832166194915771
Validation loss: 2.0723699587647633

Epoch: 6| Step: 12
Training loss: 2.6091880798339844
Validation loss: 2.060678688428735

Epoch: 6| Step: 13
Training loss: 1.4597781896591187
Validation loss: 2.0960880223140923

Epoch: 82| Step: 0
Training loss: 2.493940591812134
Validation loss: 2.0504866697454966

Epoch: 6| Step: 1
Training loss: 1.6937503814697266
Validation loss: 2.0611642240196146

Epoch: 6| Step: 2
Training loss: 2.0647873878479004
Validation loss: 2.0614912997009935

Epoch: 6| Step: 3
Training loss: 1.8767260313034058
Validation loss: 2.0473544571989324

Epoch: 6| Step: 4
Training loss: 2.1567330360412598
Validation loss: 2.0722488434084

Epoch: 6| Step: 5
Training loss: 2.24809193611145
Validation loss: 2.080985285902536

Epoch: 6| Step: 6
Training loss: 2.191897392272949
Validation loss: 2.0392239683417865

Epoch: 6| Step: 7
Training loss: 2.431938648223877
Validation loss: 2.054028513611004

Epoch: 6| Step: 8
Training loss: 1.4795863628387451
Validation loss: 2.0358875848913707

Epoch: 6| Step: 9
Training loss: 2.723529815673828
Validation loss: 2.068490751328007

Epoch: 6| Step: 10
Training loss: 1.784508228302002
Validation loss: 2.044704329582953

Epoch: 6| Step: 11
Training loss: 1.8183040618896484
Validation loss: 2.048394847941655

Epoch: 6| Step: 12
Training loss: 2.4640722274780273
Validation loss: 2.0588788832387617

Epoch: 6| Step: 13
Training loss: 2.8228724002838135
Validation loss: 2.068517279881303

Epoch: 83| Step: 0
Training loss: 2.2248036861419678
Validation loss: 2.0566347619538665

Epoch: 6| Step: 1
Training loss: 2.0878536701202393
Validation loss: 2.0594623140109483

Epoch: 6| Step: 2
Training loss: 1.8438920974731445
Validation loss: 2.0523403152342765

Epoch: 6| Step: 3
Training loss: 1.3636970520019531
Validation loss: 2.0653485405829644

Epoch: 6| Step: 4
Training loss: 2.0210180282592773
Validation loss: 2.0599806052382275

Epoch: 6| Step: 5
Training loss: 2.605584144592285
Validation loss: 2.0544580016084897

Epoch: 6| Step: 6
Training loss: 2.6129581928253174
Validation loss: 2.041433095932007

Epoch: 6| Step: 7
Training loss: 1.6292850971221924
Validation loss: 2.0439198760576147

Epoch: 6| Step: 8
Training loss: 2.580601453781128
Validation loss: 2.0746144607502925

Epoch: 6| Step: 9
Training loss: 2.138077735900879
Validation loss: 2.051334855377033

Epoch: 6| Step: 10
Training loss: 2.2136473655700684
Validation loss: 2.0424514175743185

Epoch: 6| Step: 11
Training loss: 2.288679599761963
Validation loss: 2.0553616682688394

Epoch: 6| Step: 12
Training loss: 2.4575905799865723
Validation loss: 2.0544140774716615

Epoch: 6| Step: 13
Training loss: 1.9423699378967285
Validation loss: 2.0726697496188584

Epoch: 84| Step: 0
Training loss: 2.1697428226470947
Validation loss: 2.0447406230434293

Epoch: 6| Step: 1
Training loss: 2.213212013244629
Validation loss: 2.05624662035255

Epoch: 6| Step: 2
Training loss: 1.7829935550689697
Validation loss: 2.0359828292682605

Epoch: 6| Step: 3
Training loss: 2.134766101837158
Validation loss: 2.0690808052657754

Epoch: 6| Step: 4
Training loss: 2.201831340789795
Validation loss: 2.0656738140249766

Epoch: 6| Step: 5
Training loss: 1.8410911560058594
Validation loss: 2.056257055651757

Epoch: 6| Step: 6
Training loss: 1.969472885131836
Validation loss: 2.0476090818323116

Epoch: 6| Step: 7
Training loss: 1.4974156618118286
Validation loss: 2.0487123458616194

Epoch: 6| Step: 8
Training loss: 1.8685309886932373
Validation loss: 2.0647746439903014

Epoch: 6| Step: 9
Training loss: 2.4613704681396484
Validation loss: 2.0574555538033925

Epoch: 6| Step: 10
Training loss: 2.1926963329315186
Validation loss: 2.0500922408155215

Epoch: 6| Step: 11
Training loss: 2.8488292694091797
Validation loss: 2.0971052467182116

Epoch: 6| Step: 12
Training loss: 2.486570119857788
Validation loss: 2.0904374148256037

Epoch: 6| Step: 13
Training loss: 2.6163506507873535
Validation loss: 2.0646485923438944

Epoch: 85| Step: 0
Training loss: 1.955881118774414
Validation loss: 2.0753969659087477

Epoch: 6| Step: 1
Training loss: 1.5563349723815918
Validation loss: 2.077654988534989

Epoch: 6| Step: 2
Training loss: 1.6829012632369995
Validation loss: 2.058073338641915

Epoch: 6| Step: 3
Training loss: 1.9615448713302612
Validation loss: 2.0700097096863614

Epoch: 6| Step: 4
Training loss: 1.4600707292556763
Validation loss: 2.056135973622722

Epoch: 6| Step: 5
Training loss: 2.4727206230163574
Validation loss: 2.051100195095103

Epoch: 6| Step: 6
Training loss: 2.4578750133514404
Validation loss: 2.073558763791156

Epoch: 6| Step: 7
Training loss: 1.8101850748062134
Validation loss: 2.0610516084137784

Epoch: 6| Step: 8
Training loss: 2.5773839950561523
Validation loss: 2.0628504355748496

Epoch: 6| Step: 9
Training loss: 2.845579147338867
Validation loss: 2.0778862712203816

Epoch: 6| Step: 10
Training loss: 1.8554911613464355
Validation loss: 2.0720301597349104

Epoch: 6| Step: 11
Training loss: 3.0183677673339844
Validation loss: 2.0852801107591197

Epoch: 6| Step: 12
Training loss: 2.314391851425171
Validation loss: 2.0686839088316886

Epoch: 6| Step: 13
Training loss: 1.9135080575942993
Validation loss: 2.0545322818140828

Epoch: 86| Step: 0
Training loss: 2.0068132877349854
Validation loss: 2.057436655926448

Epoch: 6| Step: 1
Training loss: 2.214336395263672
Validation loss: 2.034477831214987

Epoch: 6| Step: 2
Training loss: 1.934476613998413
Validation loss: 2.0641615749687277

Epoch: 6| Step: 3
Training loss: 2.086874485015869
Validation loss: 2.06327244030532

Epoch: 6| Step: 4
Training loss: 2.7441678047180176
Validation loss: 2.052366287477555

Epoch: 6| Step: 5
Training loss: 2.5156984329223633
Validation loss: 2.060276665995198

Epoch: 6| Step: 6
Training loss: 1.828497290611267
Validation loss: 2.0677886470671623

Epoch: 6| Step: 7
Training loss: 2.709613800048828
Validation loss: 2.0459611159498974

Epoch: 6| Step: 8
Training loss: 1.7798551321029663
Validation loss: 2.054535197955306

Epoch: 6| Step: 9
Training loss: 2.2678565979003906
Validation loss: 2.043545553761144

Epoch: 6| Step: 10
Training loss: 2.239197254180908
Validation loss: 2.0547407391250774

Epoch: 6| Step: 11
Training loss: 1.6118136644363403
Validation loss: 2.0576823501176733

Epoch: 6| Step: 12
Training loss: 1.768537998199463
Validation loss: 2.0479079190120903

Epoch: 6| Step: 13
Training loss: 2.317031145095825
Validation loss: 2.0528662666197746

Epoch: 87| Step: 0
Training loss: 1.8237378597259521
Validation loss: 2.053911973071355

Epoch: 6| Step: 1
Training loss: 2.171957015991211
Validation loss: 2.0743934108364965

Epoch: 6| Step: 2
Training loss: 1.4548702239990234
Validation loss: 2.059255602539227

Epoch: 6| Step: 3
Training loss: 1.6567319631576538
Validation loss: 2.0738140075437483

Epoch: 6| Step: 4
Training loss: 2.2180986404418945
Validation loss: 2.0710176216658724

Epoch: 6| Step: 5
Training loss: 2.0191664695739746
Validation loss: 2.0467145801872335

Epoch: 6| Step: 6
Training loss: 2.2012436389923096
Validation loss: 2.0592485063819477

Epoch: 6| Step: 7
Training loss: 1.488757610321045
Validation loss: 2.038890646349999

Epoch: 6| Step: 8
Training loss: 2.5127947330474854
Validation loss: 2.074539863935081

Epoch: 6| Step: 9
Training loss: 2.461893320083618
Validation loss: 2.051449542404503

Epoch: 6| Step: 10
Training loss: 2.045466661453247
Validation loss: 2.059038177613289

Epoch: 6| Step: 11
Training loss: 2.9882097244262695
Validation loss: 2.040070209451901

Epoch: 6| Step: 12
Training loss: 2.58652925491333
Validation loss: 2.0482237544111026

Epoch: 6| Step: 13
Training loss: 2.253909111022949
Validation loss: 2.0604339773936937

Epoch: 88| Step: 0
Training loss: 1.883113145828247
Validation loss: 2.063269781809981

Epoch: 6| Step: 1
Training loss: 1.6106829643249512
Validation loss: 2.066509437817399

Epoch: 6| Step: 2
Training loss: 2.4551808834075928
Validation loss: 2.056899586031514

Epoch: 6| Step: 3
Training loss: 1.538719892501831
Validation loss: 2.068909445116597

Epoch: 6| Step: 4
Training loss: 2.4687047004699707
Validation loss: 2.0391682027488627

Epoch: 6| Step: 5
Training loss: 1.5621541738510132
Validation loss: 2.06642182155322

Epoch: 6| Step: 6
Training loss: 1.959646224975586
Validation loss: 2.0508275134589082

Epoch: 6| Step: 7
Training loss: 2.001128911972046
Validation loss: 2.044440645043568

Epoch: 6| Step: 8
Training loss: 2.4073433876037598
Validation loss: 2.0571241763330277

Epoch: 6| Step: 9
Training loss: 2.818859815597534
Validation loss: 2.043879629463278

Epoch: 6| Step: 10
Training loss: 1.9292670488357544
Validation loss: 2.0696948843617595

Epoch: 6| Step: 11
Training loss: 2.0133063793182373
Validation loss: 2.0530900339926443

Epoch: 6| Step: 12
Training loss: 2.75392746925354
Validation loss: 2.0681343488795783

Epoch: 6| Step: 13
Training loss: 2.472130060195923
Validation loss: 2.042382755587178

Epoch: 89| Step: 0
Training loss: 1.6916465759277344
Validation loss: 2.05339749269588

Epoch: 6| Step: 1
Training loss: 2.136068344116211
Validation loss: 2.065858010322817

Epoch: 6| Step: 2
Training loss: 2.310001850128174
Validation loss: 2.0603118045355684

Epoch: 6| Step: 3
Training loss: 2.4524083137512207
Validation loss: 2.0579665860822125

Epoch: 6| Step: 4
Training loss: 1.9464713335037231
Validation loss: 2.0467848931589434

Epoch: 6| Step: 5
Training loss: 2.407607078552246
Validation loss: 2.053848651147658

Epoch: 6| Step: 6
Training loss: 2.5857410430908203
Validation loss: 2.049405385089177

Epoch: 6| Step: 7
Training loss: 1.850134253501892
Validation loss: 2.0697483375508297

Epoch: 6| Step: 8
Training loss: 1.3102545738220215
Validation loss: 2.0440943266755793

Epoch: 6| Step: 9
Training loss: 2.3472890853881836
Validation loss: 2.0609506637819353

Epoch: 6| Step: 10
Training loss: 2.351956367492676
Validation loss: 2.06473772756515

Epoch: 6| Step: 11
Training loss: 2.058173894882202
Validation loss: 2.0575512762992614

Epoch: 6| Step: 12
Training loss: 2.417173385620117
Validation loss: 2.0803364681941208

Epoch: 6| Step: 13
Training loss: 1.9874526262283325
Validation loss: 2.0708485111113517

Epoch: 90| Step: 0
Training loss: 2.0669095516204834
Validation loss: 2.056710167597699

Epoch: 6| Step: 1
Training loss: 1.887237548828125
Validation loss: 2.0704466348053305

Epoch: 6| Step: 2
Training loss: 2.536041259765625
Validation loss: 2.0618242704740135

Epoch: 6| Step: 3
Training loss: 2.5824360847473145
Validation loss: 2.0855911342046594

Epoch: 6| Step: 4
Training loss: 1.4629093408584595
Validation loss: 2.067299658252347

Epoch: 6| Step: 5
Training loss: 2.2500481605529785
Validation loss: 2.047880382948024

Epoch: 6| Step: 6
Training loss: 1.8372175693511963
Validation loss: 2.070456379203386

Epoch: 6| Step: 7
Training loss: 1.4941306114196777
Validation loss: 2.0585155666515393

Epoch: 6| Step: 8
Training loss: 3.00891375541687
Validation loss: 2.075750958534979

Epoch: 6| Step: 9
Training loss: 2.0609583854675293
Validation loss: 2.0661112851994012

Epoch: 6| Step: 10
Training loss: 2.0141992568969727
Validation loss: 2.056357655473935

Epoch: 6| Step: 11
Training loss: 1.9280667304992676
Validation loss: 2.091477491522348

Epoch: 6| Step: 12
Training loss: 2.5289039611816406
Validation loss: 2.0391224635544645

Epoch: 6| Step: 13
Training loss: 2.2793397903442383
Validation loss: 2.0613532835437405

Epoch: 91| Step: 0
Training loss: 2.414052963256836
Validation loss: 2.076633499514672

Epoch: 6| Step: 1
Training loss: 1.700993299484253
Validation loss: 2.0430540525785057

Epoch: 6| Step: 2
Training loss: 2.580723285675049
Validation loss: 2.056603662429317

Epoch: 6| Step: 3
Training loss: 2.2954819202423096
Validation loss: 2.072005461621028

Epoch: 6| Step: 4
Training loss: 2.189323902130127
Validation loss: 2.065096462926557

Epoch: 6| Step: 5
Training loss: 2.7978062629699707
Validation loss: 2.0611327463580715

Epoch: 6| Step: 6
Training loss: 1.5727627277374268
Validation loss: 2.0567855065868748

Epoch: 6| Step: 7
Training loss: 2.145968437194824
Validation loss: 2.0480784959690546

Epoch: 6| Step: 8
Training loss: 2.0896573066711426
Validation loss: 2.0514927782038206

Epoch: 6| Step: 9
Training loss: 1.6096386909484863
Validation loss: 2.0702304942633516

Epoch: 6| Step: 10
Training loss: 2.4238991737365723
Validation loss: 2.0538694166368052

Epoch: 6| Step: 11
Training loss: 1.9437514543533325
Validation loss: 2.0459159766474078

Epoch: 6| Step: 12
Training loss: 1.9584863185882568
Validation loss: 2.058989212077151

Epoch: 6| Step: 13
Training loss: 2.126013994216919
Validation loss: 2.054050084083311

Epoch: 92| Step: 0
Training loss: 2.641606330871582
Validation loss: 2.052549849274338

Epoch: 6| Step: 1
Training loss: 1.972935676574707
Validation loss: 2.0689414701154156

Epoch: 6| Step: 2
Training loss: 2.2626028060913086
Validation loss: 2.0682720932909238

Epoch: 6| Step: 3
Training loss: 1.5987615585327148
Validation loss: 2.0537617180937078

Epoch: 6| Step: 4
Training loss: 1.694476842880249
Validation loss: 2.0736508036172516

Epoch: 6| Step: 5
Training loss: 2.294589042663574
Validation loss: 2.0750394046947522

Epoch: 6| Step: 6
Training loss: 2.3141894340515137
Validation loss: 2.0452086207687215

Epoch: 6| Step: 7
Training loss: 2.4592642784118652
Validation loss: 2.0574862598091044

Epoch: 6| Step: 8
Training loss: 1.604823350906372
Validation loss: 2.045653053509292

Epoch: 6| Step: 9
Training loss: 1.9878871440887451
Validation loss: 2.048931957573019

Epoch: 6| Step: 10
Training loss: 2.245619773864746
Validation loss: 2.0667425586331274

Epoch: 6| Step: 11
Training loss: 2.1612815856933594
Validation loss: 2.0569211180492113

Epoch: 6| Step: 12
Training loss: 2.083761692047119
Validation loss: 2.0624148845672607

Epoch: 6| Step: 13
Training loss: 2.6162805557250977
Validation loss: 2.071166649941475

Epoch: 93| Step: 0
Training loss: 2.404090404510498
Validation loss: 2.061854757288451

Epoch: 6| Step: 1
Training loss: 2.211411952972412
Validation loss: 2.062353623810635

Epoch: 6| Step: 2
Training loss: 1.3810153007507324
Validation loss: 2.0661181813927105

Epoch: 6| Step: 3
Training loss: 3.076446533203125
Validation loss: 2.058475548221219

Epoch: 6| Step: 4
Training loss: 1.8969264030456543
Validation loss: 2.065903963581208

Epoch: 6| Step: 5
Training loss: 1.5147658586502075
Validation loss: 2.0539940941718315

Epoch: 6| Step: 6
Training loss: 2.414499044418335
Validation loss: 2.0779733632200506

Epoch: 6| Step: 7
Training loss: 2.5825064182281494
Validation loss: 2.062485711548918

Epoch: 6| Step: 8
Training loss: 1.5329067707061768
Validation loss: 2.0509725309187368

Epoch: 6| Step: 9
Training loss: 1.9501482248306274
Validation loss: 2.0575640663023917

Epoch: 6| Step: 10
Training loss: 2.122602939605713
Validation loss: 2.0703919036414034

Epoch: 6| Step: 11
Training loss: 2.264530897140503
Validation loss: 2.0673043279237646

Epoch: 6| Step: 12
Training loss: 1.7678513526916504
Validation loss: 2.0860091511921217

Epoch: 6| Step: 13
Training loss: 3.005345582962036
Validation loss: 2.075274699477739

Epoch: 94| Step: 0
Training loss: 2.2234225273132324
Validation loss: 2.065839631583101

Epoch: 6| Step: 1
Training loss: 1.8984253406524658
Validation loss: 2.0707991738473215

Epoch: 6| Step: 2
Training loss: 2.028494358062744
Validation loss: 2.0688594977060952

Epoch: 6| Step: 3
Training loss: 1.8146731853485107
Validation loss: 2.0824835736264466

Epoch: 6| Step: 4
Training loss: 2.0303354263305664
Validation loss: 2.061968012522626

Epoch: 6| Step: 5
Training loss: 2.2835683822631836
Validation loss: 2.0548403801456576

Epoch: 6| Step: 6
Training loss: 2.2812390327453613
Validation loss: 2.038079633507677

Epoch: 6| Step: 7
Training loss: 3.231710910797119
Validation loss: 2.0639169857066166

Epoch: 6| Step: 8
Training loss: 1.8159583806991577
Validation loss: 2.056720374732889

Epoch: 6| Step: 9
Training loss: 2.2268967628479004
Validation loss: 2.0769994463971866

Epoch: 6| Step: 10
Training loss: 1.7176542282104492
Validation loss: 2.0375407293278682

Epoch: 6| Step: 11
Training loss: 1.852590560913086
Validation loss: 2.0524160656877743

Epoch: 6| Step: 12
Training loss: 2.2037513256073
Validation loss: 2.076996995556739

Epoch: 6| Step: 13
Training loss: 2.4699337482452393
Validation loss: 2.0649513198483374

Epoch: 95| Step: 0
Training loss: 2.8039183616638184
Validation loss: 2.0554240493364233

Epoch: 6| Step: 1
Training loss: 1.8459808826446533
Validation loss: 2.0608041235195693

Epoch: 6| Step: 2
Training loss: 1.991058588027954
Validation loss: 2.034472716751919

Epoch: 6| Step: 3
Training loss: 2.502387046813965
Validation loss: 2.069216561573808

Epoch: 6| Step: 4
Training loss: 2.0477633476257324
Validation loss: 2.061428500759986

Epoch: 6| Step: 5
Training loss: 1.9473508596420288
Validation loss: 2.048575294915066

Epoch: 6| Step: 6
Training loss: 1.6862318515777588
Validation loss: 2.0564701377704577

Epoch: 6| Step: 7
Training loss: 2.582200050354004
Validation loss: 2.0592945801314486

Epoch: 6| Step: 8
Training loss: 2.6561200618743896
Validation loss: 2.0490263636394213

Epoch: 6| Step: 9
Training loss: 1.425490140914917
Validation loss: 2.0586780758314234

Epoch: 6| Step: 10
Training loss: 3.0920848846435547
Validation loss: 2.0552418539600987

Epoch: 6| Step: 11
Training loss: 1.5847049951553345
Validation loss: 2.0620018500153736

Epoch: 6| Step: 12
Training loss: 1.672804355621338
Validation loss: 2.037315002051733

Epoch: 6| Step: 13
Training loss: 1.9334509372711182
Validation loss: 2.043091594531972

Epoch: 96| Step: 0
Training loss: 1.590604543685913
Validation loss: 2.0707973613533923

Epoch: 6| Step: 1
Training loss: 1.823338270187378
Validation loss: 2.0629479910737727

Epoch: 6| Step: 2
Training loss: 2.150665283203125
Validation loss: 2.0542836061087986

Epoch: 6| Step: 3
Training loss: 2.883551597595215
Validation loss: 2.052922784641225

Epoch: 6| Step: 4
Training loss: 2.8429746627807617
Validation loss: 2.052519291959783

Epoch: 6| Step: 5
Training loss: 1.766341209411621
Validation loss: 2.0704420099976244

Epoch: 6| Step: 6
Training loss: 1.977853775024414
Validation loss: 2.0638574630983415

Epoch: 6| Step: 7
Training loss: 2.468992233276367
Validation loss: 2.0584933757781982

Epoch: 6| Step: 8
Training loss: 2.394284725189209
Validation loss: 2.0538309107544603

Epoch: 6| Step: 9
Training loss: 1.5689224004745483
Validation loss: 2.0795542142724477

Epoch: 6| Step: 10
Training loss: 1.635399580001831
Validation loss: 2.076927661895752

Epoch: 6| Step: 11
Training loss: 2.120455265045166
Validation loss: 2.0594057139529975

Epoch: 6| Step: 12
Training loss: 1.7145771980285645
Validation loss: 2.084259017821281

Epoch: 6| Step: 13
Training loss: 2.893458366394043
Validation loss: 2.059233698793637

Epoch: 97| Step: 0
Training loss: 1.5349732637405396
Validation loss: 2.0609158136511363

Epoch: 6| Step: 1
Training loss: 2.0152244567871094
Validation loss: 2.050459723318777

Epoch: 6| Step: 2
Training loss: 1.55112886428833
Validation loss: 2.0728656758544264

Epoch: 6| Step: 3
Training loss: 2.174342632293701
Validation loss: 2.0499092763470066

Epoch: 6| Step: 4
Training loss: 2.322150230407715
Validation loss: 2.067495555006048

Epoch: 6| Step: 5
Training loss: 2.573390007019043
Validation loss: 2.031527357716714

Epoch: 6| Step: 6
Training loss: 1.9886120557785034
Validation loss: 2.064493469012681

Epoch: 6| Step: 7
Training loss: 2.336210250854492
Validation loss: 2.0539062715345815

Epoch: 6| Step: 8
Training loss: 1.8916866779327393
Validation loss: 2.056993456297023

Epoch: 6| Step: 9
Training loss: 2.6500563621520996
Validation loss: 2.0632540192655338

Epoch: 6| Step: 10
Training loss: 2.3818862438201904
Validation loss: 2.058525267467704

Epoch: 6| Step: 11
Training loss: 1.8138253688812256
Validation loss: 2.04301836798268

Epoch: 6| Step: 12
Training loss: 2.489706039428711
Validation loss: 2.0723677322428715

Epoch: 6| Step: 13
Training loss: 1.9143608808517456
Validation loss: 2.05670658234627

Epoch: 98| Step: 0
Training loss: 1.76345956325531
Validation loss: 2.061646528141473

Epoch: 6| Step: 1
Training loss: 2.9018001556396484
Validation loss: 2.0354836038363877

Epoch: 6| Step: 2
Training loss: 1.8578014373779297
Validation loss: 2.0398676703053136

Epoch: 6| Step: 3
Training loss: 1.8918497562408447
Validation loss: 2.0637113266093756

Epoch: 6| Step: 4
Training loss: 2.2753870487213135
Validation loss: 2.0607720869843678

Epoch: 6| Step: 5
Training loss: 2.794135332107544
Validation loss: 2.0444992126957064

Epoch: 6| Step: 6
Training loss: 2.570005416870117
Validation loss: 2.0549123159018894

Epoch: 6| Step: 7
Training loss: 1.5819015502929688
Validation loss: 2.042807235512682

Epoch: 6| Step: 8
Training loss: 2.1105990409851074
Validation loss: 2.0607194054511284

Epoch: 6| Step: 9
Training loss: 1.4585881233215332
Validation loss: 2.0447899115982877

Epoch: 6| Step: 10
Training loss: 2.1257236003875732
Validation loss: 2.0623990335772113

Epoch: 6| Step: 11
Training loss: 2.1699767112731934
Validation loss: 2.0686541731639574

Epoch: 6| Step: 12
Training loss: 2.1333231925964355
Validation loss: 2.0665181644501223

Epoch: 6| Step: 13
Training loss: 1.5462807416915894
Validation loss: 2.0620502630869546

Epoch: 99| Step: 0
Training loss: 1.7607526779174805
Validation loss: 2.0534509125576226

Epoch: 6| Step: 1
Training loss: 1.897870421409607
Validation loss: 2.054132330802179

Epoch: 6| Step: 2
Training loss: 2.292365074157715
Validation loss: 2.054828582271453

Epoch: 6| Step: 3
Training loss: 1.9574717283248901
Validation loss: 2.0555070728384037

Epoch: 6| Step: 4
Training loss: 1.569040060043335
Validation loss: 2.039723063027987

Epoch: 6| Step: 5
Training loss: 2.9592299461364746
Validation loss: 2.0728584348514514

Epoch: 6| Step: 6
Training loss: 2.3649253845214844
Validation loss: 2.03689585193511

Epoch: 6| Step: 7
Training loss: 2.246638774871826
Validation loss: 2.056553071545016

Epoch: 6| Step: 8
Training loss: 2.0402448177337646
Validation loss: 2.053243993431009

Epoch: 6| Step: 9
Training loss: 1.2831218242645264
Validation loss: 2.0694441000620523

Epoch: 6| Step: 10
Training loss: 1.925050973892212
Validation loss: 2.0382411095403854

Epoch: 6| Step: 11
Training loss: 2.517219066619873
Validation loss: 2.072891330206266

Epoch: 6| Step: 12
Training loss: 2.658884048461914
Validation loss: 2.071644280546455

Epoch: 6| Step: 13
Training loss: 1.985687255859375
Validation loss: 2.067446474106081

Epoch: 100| Step: 0
Training loss: 1.7536721229553223
Validation loss: 2.055574014622678

Epoch: 6| Step: 1
Training loss: 1.610105037689209
Validation loss: 2.041219970231415

Epoch: 6| Step: 2
Training loss: 2.0657827854156494
Validation loss: 2.048868589503791

Epoch: 6| Step: 3
Training loss: 2.3843817710876465
Validation loss: 2.0541439851125083

Epoch: 6| Step: 4
Training loss: 2.460383176803589
Validation loss: 2.0522150890801543

Epoch: 6| Step: 5
Training loss: 1.525950312614441
Validation loss: 2.0706714237889936

Epoch: 6| Step: 6
Training loss: 2.488668441772461
Validation loss: 2.0532979170481362

Epoch: 6| Step: 7
Training loss: 2.160644054412842
Validation loss: 2.079017423814343

Epoch: 6| Step: 8
Training loss: 2.0824429988861084
Validation loss: 2.0712153116861978

Epoch: 6| Step: 9
Training loss: 1.3388354778289795
Validation loss: 2.0748670716439523

Epoch: 6| Step: 10
Training loss: 2.2787861824035645
Validation loss: 2.0765494544018983

Epoch: 6| Step: 11
Training loss: 2.2869534492492676
Validation loss: 2.053742083170081

Epoch: 6| Step: 12
Training loss: 1.820309042930603
Validation loss: 2.0475977954044136

Epoch: 6| Step: 13
Training loss: 3.8651444911956787
Validation loss: 2.054907311675369

Epoch: 101| Step: 0
Training loss: 3.0184192657470703
Validation loss: 2.060359944579422

Epoch: 6| Step: 1
Training loss: 2.3162965774536133
Validation loss: 2.0792597480999526

Epoch: 6| Step: 2
Training loss: 2.0717105865478516
Validation loss: 2.057906158508793

Epoch: 6| Step: 3
Training loss: 1.2654147148132324
Validation loss: 2.0573676106750325

Epoch: 6| Step: 4
Training loss: 2.412088632583618
Validation loss: 2.0623168278765935

Epoch: 6| Step: 5
Training loss: 1.2389217615127563
Validation loss: 2.0768207503903295

Epoch: 6| Step: 6
Training loss: 2.3701720237731934
Validation loss: 2.061790753436345

Epoch: 6| Step: 7
Training loss: 1.8828225135803223
Validation loss: 2.060621694851947

Epoch: 6| Step: 8
Training loss: 1.7484843730926514
Validation loss: 2.0632120358046664

Epoch: 6| Step: 9
Training loss: 2.2997870445251465
Validation loss: 2.071194644897215

Epoch: 6| Step: 10
Training loss: 1.9418108463287354
Validation loss: 2.0619189662318074

Epoch: 6| Step: 11
Training loss: 2.184269905090332
Validation loss: 2.0493953586906515

Epoch: 6| Step: 12
Training loss: 2.6083831787109375
Validation loss: 2.042860701519956

Epoch: 6| Step: 13
Training loss: 1.8923356533050537
Validation loss: 2.048665115910192

Epoch: 102| Step: 0
Training loss: 1.913000226020813
Validation loss: 2.0570580420955533

Epoch: 6| Step: 1
Training loss: 1.8585803508758545
Validation loss: 2.0516582253158733

Epoch: 6| Step: 2
Training loss: 2.177494525909424
Validation loss: 2.0756260528359363

Epoch: 6| Step: 3
Training loss: 2.819929599761963
Validation loss: 2.0609266219600553

Epoch: 6| Step: 4
Training loss: 1.7101844549179077
Validation loss: 2.061126060383294

Epoch: 6| Step: 5
Training loss: 2.208388566970825
Validation loss: 2.0757053103498233

Epoch: 6| Step: 6
Training loss: 2.355767250061035
Validation loss: 2.0510563465856735

Epoch: 6| Step: 7
Training loss: 1.8019871711730957
Validation loss: 2.0546173664831344

Epoch: 6| Step: 8
Training loss: 2.4639575481414795
Validation loss: 2.0652088606229393

Epoch: 6| Step: 9
Training loss: 1.6672561168670654
Validation loss: 2.0493764877319336

Epoch: 6| Step: 10
Training loss: 2.0954980850219727
Validation loss: 2.057284543591161

Epoch: 6| Step: 11
Training loss: 2.309260845184326
Validation loss: 2.049144992264368

Epoch: 6| Step: 12
Training loss: 1.6632343530654907
Validation loss: 2.065262048475204

Epoch: 6| Step: 13
Training loss: 2.463569402694702
Validation loss: 2.0775319171208206

Epoch: 103| Step: 0
Training loss: 1.6196568012237549
Validation loss: 2.0570544247986167

Epoch: 6| Step: 1
Training loss: 2.4909541606903076
Validation loss: 2.0710123662025697

Epoch: 6| Step: 2
Training loss: 2.4949560165405273
Validation loss: 2.072536619760657

Epoch: 6| Step: 3
Training loss: 2.2337632179260254
Validation loss: 2.0677762595556115

Epoch: 6| Step: 4
Training loss: 2.044252634048462
Validation loss: 2.0536638459851666

Epoch: 6| Step: 5
Training loss: 1.9121506214141846
Validation loss: 2.058778593617101

Epoch: 6| Step: 6
Training loss: 2.4247019290924072
Validation loss: 2.0612294699556086

Epoch: 6| Step: 7
Training loss: 1.7660084962844849
Validation loss: 2.054460330676007

Epoch: 6| Step: 8
Training loss: 2.374232053756714
Validation loss: 2.0402176482703096

Epoch: 6| Step: 9
Training loss: 1.6074213981628418
Validation loss: 2.0697331838710333

Epoch: 6| Step: 10
Training loss: 2.072549343109131
Validation loss: 2.0456458394245436

Epoch: 6| Step: 11
Training loss: 1.8365319967269897
Validation loss: 2.055373545615904

Epoch: 6| Step: 12
Training loss: 2.236361026763916
Validation loss: 2.056458168132331

Epoch: 6| Step: 13
Training loss: 2.128818988800049
Validation loss: 2.0697194171208206

Epoch: 104| Step: 0
Training loss: 1.5467431545257568
Validation loss: 2.0796949760888213

Epoch: 6| Step: 1
Training loss: 2.4647369384765625
Validation loss: 2.0528983646823513

Epoch: 6| Step: 2
Training loss: 1.3066048622131348
Validation loss: 2.070296346500356

Epoch: 6| Step: 3
Training loss: 1.979920744895935
Validation loss: 2.0566267377586773

Epoch: 6| Step: 4
Training loss: 1.9293118715286255
Validation loss: 2.0648658134604014

Epoch: 6| Step: 5
Training loss: 2.574397563934326
Validation loss: 2.0765052713373655

Epoch: 6| Step: 6
Training loss: 2.714505195617676
Validation loss: 2.0668367185900287

Epoch: 6| Step: 7
Training loss: 1.3932392597198486
Validation loss: 2.031054876183951

Epoch: 6| Step: 8
Training loss: 2.2937726974487305
Validation loss: 2.052238240036913

Epoch: 6| Step: 9
Training loss: 2.071363687515259
Validation loss: 2.0555912256240845

Epoch: 6| Step: 10
Training loss: 2.375965118408203
Validation loss: 2.0501557370667816

Epoch: 6| Step: 11
Training loss: 2.622408628463745
Validation loss: 2.067400655438823

Epoch: 6| Step: 12
Training loss: 1.9565589427947998
Validation loss: 2.0433904663208993

Epoch: 6| Step: 13
Training loss: 1.8083468675613403
Validation loss: 2.0477198246986634

Epoch: 105| Step: 0
Training loss: 1.4937514066696167
Validation loss: 2.054071814783158

Epoch: 6| Step: 1
Training loss: 1.8936092853546143
Validation loss: 2.04668987822789

Epoch: 6| Step: 2
Training loss: 2.5675673484802246
Validation loss: 2.0457072104177167

Epoch: 6| Step: 3
Training loss: 1.9884064197540283
Validation loss: 2.0732538841103993

Epoch: 6| Step: 4
Training loss: 2.718994140625
Validation loss: 2.0628740633687666

Epoch: 6| Step: 5
Training loss: 1.864758014678955
Validation loss: 2.07343755614373

Epoch: 6| Step: 6
Training loss: 2.3449738025665283
Validation loss: 2.0636400074087162

Epoch: 6| Step: 7
Training loss: 1.6277248859405518
Validation loss: 2.0615604167343466

Epoch: 6| Step: 8
Training loss: 2.4476356506347656
Validation loss: 2.050254137285294

Epoch: 6| Step: 9
Training loss: 1.9666314125061035
Validation loss: 2.0594771959448375

Epoch: 6| Step: 10
Training loss: 1.8190066814422607
Validation loss: 2.0356673322698122

Epoch: 6| Step: 11
Training loss: 2.197263479232788
Validation loss: 2.057985267331523

Epoch: 6| Step: 12
Training loss: 2.223820209503174
Validation loss: 2.0628660878827496

Epoch: 6| Step: 13
Training loss: 2.02417254447937
Validation loss: 2.0319599823285173

Epoch: 106| Step: 0
Training loss: 1.7480703592300415
Validation loss: 2.051933850011518

Epoch: 6| Step: 1
Training loss: 2.3512542247772217
Validation loss: 2.061919950669812

Epoch: 6| Step: 2
Training loss: 2.177872657775879
Validation loss: 2.0463444366249988

Epoch: 6| Step: 3
Training loss: 2.24442720413208
Validation loss: 2.039093650797362

Epoch: 6| Step: 4
Training loss: 2.3095169067382812
Validation loss: 2.067228668479509

Epoch: 6| Step: 5
Training loss: 2.1684906482696533
Validation loss: 2.0572382019412134

Epoch: 6| Step: 6
Training loss: 2.3721115589141846
Validation loss: 2.0557887041440575

Epoch: 6| Step: 7
Training loss: 1.6199216842651367
Validation loss: 2.0702150688376477

Epoch: 6| Step: 8
Training loss: 1.487237572669983
Validation loss: 2.029552777608236

Epoch: 6| Step: 9
Training loss: 2.365933895111084
Validation loss: 2.050998923599079

Epoch: 6| Step: 10
Training loss: 3.099032402038574
Validation loss: 2.0541657491396834

Epoch: 6| Step: 11
Training loss: 2.0642449855804443
Validation loss: 2.0483497804211033

Epoch: 6| Step: 12
Training loss: 1.4567177295684814
Validation loss: 2.0514965775192424

Epoch: 6| Step: 13
Training loss: 1.3095524311065674
Validation loss: 2.049320508075017

Epoch: 107| Step: 0
Training loss: 1.8093433380126953
Validation loss: 2.0749974173884236

Epoch: 6| Step: 1
Training loss: 2.0857651233673096
Validation loss: 2.059727204743252

Epoch: 6| Step: 2
Training loss: 1.7559726238250732
Validation loss: 2.0821060288336968

Epoch: 6| Step: 3
Training loss: 2.5944149494171143
Validation loss: 2.0623909222182406

Epoch: 6| Step: 4
Training loss: 1.703287959098816
Validation loss: 2.041241030539236

Epoch: 6| Step: 5
Training loss: 1.8339526653289795
Validation loss: 2.0663027417275215

Epoch: 6| Step: 6
Training loss: 2.6108412742614746
Validation loss: 2.0490925696588334

Epoch: 6| Step: 7
Training loss: 1.9652754068374634
Validation loss: 2.0616456949582664

Epoch: 6| Step: 8
Training loss: 2.1469836235046387
Validation loss: 2.042413883311774

Epoch: 6| Step: 9
Training loss: 1.9006381034851074
Validation loss: 2.0749477929966424

Epoch: 6| Step: 10
Training loss: 2.3546836376190186
Validation loss: 2.0567448267372708

Epoch: 6| Step: 11
Training loss: 1.983414888381958
Validation loss: 2.0304545792200233

Epoch: 6| Step: 12
Training loss: 2.484416961669922
Validation loss: 2.069458400049517

Epoch: 6| Step: 13
Training loss: 1.9262090921401978
Validation loss: 2.0571075088234356

Epoch: 108| Step: 0
Training loss: 2.7248313426971436
Validation loss: 2.0519091672794794

Epoch: 6| Step: 1
Training loss: 2.650818347930908
Validation loss: 2.0804033510146605

Epoch: 6| Step: 2
Training loss: 1.586966872215271
Validation loss: 2.0627312660217285

Epoch: 6| Step: 3
Training loss: 1.7897100448608398
Validation loss: 2.0744097668637513

Epoch: 6| Step: 4
Training loss: 2.6302289962768555
Validation loss: 2.0714754648106073

Epoch: 6| Step: 5
Training loss: 2.1124138832092285
Validation loss: 2.069346703508849

Epoch: 6| Step: 6
Training loss: 2.1181702613830566
Validation loss: 2.04885220784013

Epoch: 6| Step: 7
Training loss: 1.1890501976013184
Validation loss: 2.0720435445026686

Epoch: 6| Step: 8
Training loss: 2.035207509994507
Validation loss: 2.1053731851680304

Epoch: 6| Step: 9
Training loss: 2.2159106731414795
Validation loss: 2.056953690385306

Epoch: 6| Step: 10
Training loss: 1.7661139965057373
Validation loss: 2.0598489456279303

Epoch: 6| Step: 11
Training loss: 1.5871808528900146
Validation loss: 2.0531853296423472

Epoch: 6| Step: 12
Training loss: 2.4389092922210693
Validation loss: 2.0402666855883855

Epoch: 6| Step: 13
Training loss: 2.7114639282226562
Validation loss: 2.0519381159095356

Epoch: 109| Step: 0
Training loss: 2.545734405517578
Validation loss: 2.062020654319435

Epoch: 6| Step: 1
Training loss: 2.325803756713867
Validation loss: 2.063853668910201

Epoch: 6| Step: 2
Training loss: 2.3192689418792725
Validation loss: 2.0747768058571765

Epoch: 6| Step: 3
Training loss: 2.1257448196411133
Validation loss: 2.064088161273669

Epoch: 6| Step: 4
Training loss: 2.0895602703094482
Validation loss: 2.0758889285467004

Epoch: 6| Step: 5
Training loss: 2.1256866455078125
Validation loss: 2.0747288503954486

Epoch: 6| Step: 6
Training loss: 2.3396129608154297
Validation loss: 2.070300937980734

Epoch: 6| Step: 7
Training loss: 2.2457528114318848
Validation loss: 2.0574279280119043

Epoch: 6| Step: 8
Training loss: 1.825146198272705
Validation loss: 2.056860493075463

Epoch: 6| Step: 9
Training loss: 1.954110860824585
Validation loss: 2.0385661984002716

Epoch: 6| Step: 10
Training loss: 1.6839301586151123
Validation loss: 2.0566403455631708

Epoch: 6| Step: 11
Training loss: 1.8678362369537354
Validation loss: 2.037611965210207

Epoch: 6| Step: 12
Training loss: 2.0653185844421387
Validation loss: 2.0383886470589587

Epoch: 6| Step: 13
Training loss: 1.4447565078735352
Validation loss: 2.0314350756265784

Epoch: 110| Step: 0
Training loss: 2.2847304344177246
Validation loss: 2.0417810768209477

Epoch: 6| Step: 1
Training loss: 1.7586743831634521
Validation loss: 2.0579127278379215

Epoch: 6| Step: 2
Training loss: 1.8055870532989502
Validation loss: 2.055183805445189

Epoch: 6| Step: 3
Training loss: 2.3023123741149902
Validation loss: 2.048956573650401

Epoch: 6| Step: 4
Training loss: 2.6798157691955566
Validation loss: 2.081776197238635

Epoch: 6| Step: 5
Training loss: 2.2940409183502197
Validation loss: 2.026590285762664

Epoch: 6| Step: 6
Training loss: 1.5450197458267212
Validation loss: 2.064886026484992

Epoch: 6| Step: 7
Training loss: 1.7449334859848022
Validation loss: 2.03428247410764

Epoch: 6| Step: 8
Training loss: 1.8378134965896606
Validation loss: 2.033820597074365

Epoch: 6| Step: 9
Training loss: 1.8099162578582764
Validation loss: 2.035746741038497

Epoch: 6| Step: 10
Training loss: 2.4010939598083496
Validation loss: 2.048819847004388

Epoch: 6| Step: 11
Training loss: 2.251368999481201
Validation loss: 2.038430816383772

Epoch: 6| Step: 12
Training loss: 1.9248229265213013
Validation loss: 2.0402467225187566

Epoch: 6| Step: 13
Training loss: 2.6630637645721436
Validation loss: 2.0391028478581417

Epoch: 111| Step: 0
Training loss: 2.128901958465576
Validation loss: 2.0489124110949937

Epoch: 6| Step: 1
Training loss: 2.4726758003234863
Validation loss: 2.039949288932226

Epoch: 6| Step: 2
Training loss: 1.993089199066162
Validation loss: 2.0398336379758772

Epoch: 6| Step: 3
Training loss: 1.4529271125793457
Validation loss: 2.03788350858996

Epoch: 6| Step: 4
Training loss: 2.0433690547943115
Validation loss: 2.010106186712942

Epoch: 6| Step: 5
Training loss: 1.6965234279632568
Validation loss: 2.0498231790399037

Epoch: 6| Step: 6
Training loss: 2.170747756958008
Validation loss: 2.051856744673944

Epoch: 6| Step: 7
Training loss: 1.5520408153533936
Validation loss: 2.039749394180954

Epoch: 6| Step: 8
Training loss: 1.727842092514038
Validation loss: 2.041170758585776

Epoch: 6| Step: 9
Training loss: 2.332679271697998
Validation loss: 2.0604939537663616

Epoch: 6| Step: 10
Training loss: 2.7095274925231934
Validation loss: 2.024189349143736

Epoch: 6| Step: 11
Training loss: 1.8897578716278076
Validation loss: 2.0473443385093444

Epoch: 6| Step: 12
Training loss: 2.7846202850341797
Validation loss: 2.044241605266448

Epoch: 6| Step: 13
Training loss: 2.3943183422088623
Validation loss: 2.058111416396274

Epoch: 112| Step: 0
Training loss: 2.864598512649536
Validation loss: 2.03928303974931

Epoch: 6| Step: 1
Training loss: 2.007876396179199
Validation loss: 2.057237635376633

Epoch: 6| Step: 2
Training loss: 2.0414481163024902
Validation loss: 2.064942611161099

Epoch: 6| Step: 3
Training loss: 2.0895440578460693
Validation loss: 2.0460163342055453

Epoch: 6| Step: 4
Training loss: 1.353101134300232
Validation loss: 2.0474996541136052

Epoch: 6| Step: 5
Training loss: 1.5760669708251953
Validation loss: 2.0396842084905153

Epoch: 6| Step: 6
Training loss: 2.735367774963379
Validation loss: 2.0395684678067445

Epoch: 6| Step: 7
Training loss: 2.318145751953125
Validation loss: 2.029148590180182

Epoch: 6| Step: 8
Training loss: 1.6425330638885498
Validation loss: 2.0517221496951197

Epoch: 6| Step: 9
Training loss: 2.5396785736083984
Validation loss: 2.038271996282762

Epoch: 6| Step: 10
Training loss: 2.1676688194274902
Validation loss: 2.054577286525439

Epoch: 6| Step: 11
Training loss: 2.0175559520721436
Validation loss: 2.03703619715988

Epoch: 6| Step: 12
Training loss: 2.0571444034576416
Validation loss: 2.069867741677069

Epoch: 6| Step: 13
Training loss: 1.3860220909118652
Validation loss: 2.050257441818073

Epoch: 113| Step: 0
Training loss: 1.9463536739349365
Validation loss: 2.0307418274623092

Epoch: 6| Step: 1
Training loss: 2.266042709350586
Validation loss: 2.028864452915807

Epoch: 6| Step: 2
Training loss: 1.882952332496643
Validation loss: 2.0309593882612003

Epoch: 6| Step: 3
Training loss: 2.17879581451416
Validation loss: 2.047403504771571

Epoch: 6| Step: 4
Training loss: 1.0807892084121704
Validation loss: 2.0353765590216524

Epoch: 6| Step: 5
Training loss: 2.0747857093811035
Validation loss: 2.027985812515341

Epoch: 6| Step: 6
Training loss: 1.7269377708435059
Validation loss: 2.032640493044289

Epoch: 6| Step: 7
Training loss: 2.269761085510254
Validation loss: 2.0237980478553363

Epoch: 6| Step: 8
Training loss: 1.8370823860168457
Validation loss: 2.044599697154055

Epoch: 6| Step: 9
Training loss: 2.14524507522583
Validation loss: 2.025993880405221

Epoch: 6| Step: 10
Training loss: 2.2416539192199707
Validation loss: 2.0315929753806

Epoch: 6| Step: 11
Training loss: 3.2189230918884277
Validation loss: 2.0349096226435837

Epoch: 6| Step: 12
Training loss: 2.3794846534729004
Validation loss: 2.033833139686174

Epoch: 6| Step: 13
Training loss: 1.7885290384292603
Validation loss: 2.045729878128216

Epoch: 114| Step: 0
Training loss: 1.9424316883087158
Validation loss: 2.025338230594512

Epoch: 6| Step: 1
Training loss: 1.7835309505462646
Validation loss: 2.0264135919591433

Epoch: 6| Step: 2
Training loss: 2.221237897872925
Validation loss: 2.0375765267238823

Epoch: 6| Step: 3
Training loss: 1.689452886581421
Validation loss: 2.0362090974725704

Epoch: 6| Step: 4
Training loss: 2.632007598876953
Validation loss: 2.0327993131452993

Epoch: 6| Step: 5
Training loss: 1.9917994737625122
Validation loss: 2.0330106699338524

Epoch: 6| Step: 6
Training loss: 2.409585952758789
Validation loss: 2.0398986108841433

Epoch: 6| Step: 7
Training loss: 2.0496554374694824
Validation loss: 2.036876291357061

Epoch: 6| Step: 8
Training loss: 1.9371840953826904
Validation loss: 2.057181745447138

Epoch: 6| Step: 9
Training loss: 2.654918909072876
Validation loss: 2.047556902772637

Epoch: 6| Step: 10
Training loss: 2.287409782409668
Validation loss: 2.035987925785844

Epoch: 6| Step: 11
Training loss: 1.6449658870697021
Validation loss: 2.023733583829736

Epoch: 6| Step: 12
Training loss: 1.8973407745361328
Validation loss: 2.0496272963862263

Epoch: 6| Step: 13
Training loss: 1.7757344245910645
Validation loss: 2.030992269515991

Epoch: 115| Step: 0
Training loss: 1.9757001399993896
Validation loss: 2.0455785233487367

Epoch: 6| Step: 1
Training loss: 1.5796492099761963
Validation loss: 2.047986579197709

Epoch: 6| Step: 2
Training loss: 1.5632362365722656
Validation loss: 2.0423412912635395

Epoch: 6| Step: 3
Training loss: 2.250296115875244
Validation loss: 2.019819785189885

Epoch: 6| Step: 4
Training loss: 1.3399631977081299
Validation loss: 2.037416576057352

Epoch: 6| Step: 5
Training loss: 2.6404099464416504
Validation loss: 2.0182893968397573

Epoch: 6| Step: 6
Training loss: 2.4245760440826416
Validation loss: 2.0368575921622654

Epoch: 6| Step: 7
Training loss: 2.47271728515625
Validation loss: 2.039543346692157

Epoch: 6| Step: 8
Training loss: 2.2781243324279785
Validation loss: 2.0386070538592596

Epoch: 6| Step: 9
Training loss: 2.5631260871887207
Validation loss: 2.0352968477433726

Epoch: 6| Step: 10
Training loss: 1.295039176940918
Validation loss: 2.0464665735921552

Epoch: 6| Step: 11
Training loss: 2.246635675430298
Validation loss: 2.0313167982203986

Epoch: 6| Step: 12
Training loss: 2.2114462852478027
Validation loss: 2.0492835685771

Epoch: 6| Step: 13
Training loss: 1.8049882650375366
Validation loss: 2.0576276663810975

Epoch: 116| Step: 0
Training loss: 1.922560453414917
Validation loss: 2.0587559964067195

Epoch: 6| Step: 1
Training loss: 1.9194321632385254
Validation loss: 2.0385332056271133

Epoch: 6| Step: 2
Training loss: 2.15085506439209
Validation loss: 2.057024235366493

Epoch: 6| Step: 3
Training loss: 2.180907726287842
Validation loss: 2.0634197932417675

Epoch: 6| Step: 4
Training loss: 1.7960453033447266
Validation loss: 2.053504004273363

Epoch: 6| Step: 5
Training loss: 2.356873035430908
Validation loss: 2.070697861333047

Epoch: 6| Step: 6
Training loss: 2.2908167839050293
Validation loss: 2.0535224201858684

Epoch: 6| Step: 7
Training loss: 1.5717300176620483
Validation loss: 2.0473636068323606

Epoch: 6| Step: 8
Training loss: 2.245917797088623
Validation loss: 2.040038647190217

Epoch: 6| Step: 9
Training loss: 1.729648232460022
Validation loss: 2.036344160315811

Epoch: 6| Step: 10
Training loss: 2.46769380569458
Validation loss: 2.037340601285299

Epoch: 6| Step: 11
Training loss: 2.2151732444763184
Validation loss: 2.0298954697065454

Epoch: 6| Step: 12
Training loss: 1.7793407440185547
Validation loss: 2.0305205737390826

Epoch: 6| Step: 13
Training loss: 2.196296453475952
Validation loss: 2.0388109401990007

Epoch: 117| Step: 0
Training loss: 2.303440809249878
Validation loss: 2.0520864045748146

Epoch: 6| Step: 1
Training loss: 2.607323169708252
Validation loss: 2.0636178780627508

Epoch: 6| Step: 2
Training loss: 1.7373979091644287
Validation loss: 2.0327299769206713

Epoch: 6| Step: 3
Training loss: 1.675093173980713
Validation loss: 2.033744268519904

Epoch: 6| Step: 4
Training loss: 1.2812018394470215
Validation loss: 2.0462765360391266

Epoch: 6| Step: 5
Training loss: 1.899215579032898
Validation loss: 2.0225710292016306

Epoch: 6| Step: 6
Training loss: 1.878453016281128
Validation loss: 2.033405637228361

Epoch: 6| Step: 7
Training loss: 2.002819061279297
Validation loss: 2.0273989746647496

Epoch: 6| Step: 8
Training loss: 2.4808473587036133
Validation loss: 2.033543289348643

Epoch: 6| Step: 9
Training loss: 2.0784835815429688
Validation loss: 2.0240269937822895

Epoch: 6| Step: 10
Training loss: 2.435513973236084
Validation loss: 2.0540062535193657

Epoch: 6| Step: 11
Training loss: 2.828925609588623
Validation loss: 2.0393934378059964

Epoch: 6| Step: 12
Training loss: 1.7426365613937378
Validation loss: 2.053808968554261

Epoch: 6| Step: 13
Training loss: 1.896414041519165
Validation loss: 2.0251826227352185

Epoch: 118| Step: 0
Training loss: 2.3930349349975586
Validation loss: 2.032126562569731

Epoch: 6| Step: 1
Training loss: 1.8380697965621948
Validation loss: 2.028973912680021

Epoch: 6| Step: 2
Training loss: 1.7398309707641602
Validation loss: 2.014593929372808

Epoch: 6| Step: 3
Training loss: 1.3085637092590332
Validation loss: 2.0080330205220047

Epoch: 6| Step: 4
Training loss: 1.6432220935821533
Validation loss: 2.0470680536762362

Epoch: 6| Step: 5
Training loss: 2.184519052505493
Validation loss: 2.0388688400227535

Epoch: 6| Step: 6
Training loss: 2.068643808364868
Validation loss: 2.0422911015889977

Epoch: 6| Step: 7
Training loss: 2.6621108055114746
Validation loss: 2.0362238037970757

Epoch: 6| Step: 8
Training loss: 3.092334508895874
Validation loss: 2.0116284739586616

Epoch: 6| Step: 9
Training loss: 2.005535125732422
Validation loss: 2.019585742745348

Epoch: 6| Step: 10
Training loss: 2.2120957374572754
Validation loss: 2.0167720497295423

Epoch: 6| Step: 11
Training loss: 1.5290250778198242
Validation loss: 2.030568268991286

Epoch: 6| Step: 12
Training loss: 2.087862491607666
Validation loss: 2.0218869511799147

Epoch: 6| Step: 13
Training loss: 2.297457456588745
Validation loss: 2.0409514006747993

Epoch: 119| Step: 0
Training loss: 2.5844123363494873
Validation loss: 2.0219151409723426

Epoch: 6| Step: 1
Training loss: 1.6119998693466187
Validation loss: 2.01673295164621

Epoch: 6| Step: 2
Training loss: 1.8465948104858398
Validation loss: 2.0328904915881414

Epoch: 6| Step: 3
Training loss: 2.5398290157318115
Validation loss: 2.0292148051723355

Epoch: 6| Step: 4
Training loss: 1.112684965133667
Validation loss: 2.014363088915425

Epoch: 6| Step: 5
Training loss: 1.863539218902588
Validation loss: 2.033509567219724

Epoch: 6| Step: 6
Training loss: 1.940497636795044
Validation loss: 2.0170020852037656

Epoch: 6| Step: 7
Training loss: 2.2795071601867676
Validation loss: 2.0273413606869277

Epoch: 6| Step: 8
Training loss: 1.691790223121643
Validation loss: 2.0491362605043637

Epoch: 6| Step: 9
Training loss: 2.369798421859741
Validation loss: 2.0137134367419827

Epoch: 6| Step: 10
Training loss: 2.0489048957824707
Validation loss: 2.019469686733779

Epoch: 6| Step: 11
Training loss: 2.146169424057007
Validation loss: 2.018010443256747

Epoch: 6| Step: 12
Training loss: 1.9683843851089478
Validation loss: 2.0179084270231185

Epoch: 6| Step: 13
Training loss: 2.9601619243621826
Validation loss: 2.0150121617060837

Epoch: 120| Step: 0
Training loss: 1.7980737686157227
Validation loss: 2.019578472260506

Epoch: 6| Step: 1
Training loss: 1.885245680809021
Validation loss: 2.0010647414832987

Epoch: 6| Step: 2
Training loss: 1.942133903503418
Validation loss: 2.0481856202566497

Epoch: 6| Step: 3
Training loss: 2.176910877227783
Validation loss: 2.0305819562686387

Epoch: 6| Step: 4
Training loss: 1.7572355270385742
Validation loss: 2.0311284052428378

Epoch: 6| Step: 5
Training loss: 2.6871628761291504
Validation loss: 2.0473205133150985

Epoch: 6| Step: 6
Training loss: 1.9910855293273926
Validation loss: 2.005122947436507

Epoch: 6| Step: 7
Training loss: 2.04569411277771
Validation loss: 2.057096540286977

Epoch: 6| Step: 8
Training loss: 2.193775177001953
Validation loss: 2.0213745819625033

Epoch: 6| Step: 9
Training loss: 2.745680809020996
Validation loss: 2.025525394306388

Epoch: 6| Step: 10
Training loss: 2.2829654216766357
Validation loss: 2.0208979268227854

Epoch: 6| Step: 11
Training loss: 1.6759724617004395
Validation loss: 2.0238702733029603

Epoch: 6| Step: 12
Training loss: 2.2064027786254883
Validation loss: 2.02213772907052

Epoch: 6| Step: 13
Training loss: 0.9688364863395691
Validation loss: 2.0415896997656873

Epoch: 121| Step: 0
Training loss: 2.6763806343078613
Validation loss: 2.0352458646220546

Epoch: 6| Step: 1
Training loss: 1.9174280166625977
Validation loss: 2.0191303414683186

Epoch: 6| Step: 2
Training loss: 2.3419995307922363
Validation loss: 2.020867504099364

Epoch: 6| Step: 3
Training loss: 2.182861089706421
Validation loss: 2.0306404329115346

Epoch: 6| Step: 4
Training loss: 2.0952022075653076
Validation loss: 2.02852120707112

Epoch: 6| Step: 5
Training loss: 2.2037839889526367
Validation loss: 2.0406217036708707

Epoch: 6| Step: 6
Training loss: 2.009450912475586
Validation loss: 2.0550720717317317

Epoch: 6| Step: 7
Training loss: 2.473287582397461
Validation loss: 2.0174500352592877

Epoch: 6| Step: 8
Training loss: 1.6941943168640137
Validation loss: 2.022684911245941

Epoch: 6| Step: 9
Training loss: 2.218656063079834
Validation loss: 2.027882432424894

Epoch: 6| Step: 10
Training loss: 1.9197800159454346
Validation loss: 2.0131718779122956

Epoch: 6| Step: 11
Training loss: 1.590705394744873
Validation loss: 2.034953225043512

Epoch: 6| Step: 12
Training loss: 1.734805941581726
Validation loss: 2.0200709963357575

Epoch: 6| Step: 13
Training loss: 1.3778843879699707
Validation loss: 2.05107045173645

Epoch: 122| Step: 0
Training loss: 2.0613410472869873
Validation loss: 2.0402162151951946

Epoch: 6| Step: 1
Training loss: 1.9253958463668823
Validation loss: 2.019439599847281

Epoch: 6| Step: 2
Training loss: 1.8425986766815186
Validation loss: 2.0298992536401235

Epoch: 6| Step: 3
Training loss: 2.0555901527404785
Validation loss: 2.028933781449513

Epoch: 6| Step: 4
Training loss: 2.4525318145751953
Validation loss: 2.0302905523648827

Epoch: 6| Step: 5
Training loss: 2.4787168502807617
Validation loss: 2.0368928178664176

Epoch: 6| Step: 6
Training loss: 2.2970898151397705
Validation loss: 2.0137392090212916

Epoch: 6| Step: 7
Training loss: 1.8346195220947266
Validation loss: 2.0262428881019674

Epoch: 6| Step: 8
Training loss: 1.439134120941162
Validation loss: 2.02681779092358

Epoch: 6| Step: 9
Training loss: 2.1917500495910645
Validation loss: 2.0372303378197456

Epoch: 6| Step: 10
Training loss: 2.033541202545166
Validation loss: 2.0498747979440997

Epoch: 6| Step: 11
Training loss: 1.8402366638183594
Validation loss: 2.041044742830338

Epoch: 6| Step: 12
Training loss: 2.5021049976348877
Validation loss: 2.0355748694430114

Epoch: 6| Step: 13
Training loss: 1.5774773359298706
Validation loss: 2.03394119457532

Epoch: 123| Step: 0
Training loss: 2.2236640453338623
Validation loss: 2.0428186975499636

Epoch: 6| Step: 1
Training loss: 1.7600858211517334
Validation loss: 2.0399068260705597

Epoch: 6| Step: 2
Training loss: 1.8585587739944458
Validation loss: 2.046243841930102

Epoch: 6| Step: 3
Training loss: 2.196120262145996
Validation loss: 2.0190197678022486

Epoch: 6| Step: 4
Training loss: 2.0732412338256836
Validation loss: 2.058462299326415

Epoch: 6| Step: 5
Training loss: 2.3020100593566895
Validation loss: 2.0443737071047545

Epoch: 6| Step: 6
Training loss: 3.0485777854919434
Validation loss: 2.0314842782994753

Epoch: 6| Step: 7
Training loss: 1.649599552154541
Validation loss: 2.0150177735154347

Epoch: 6| Step: 8
Training loss: 1.705065369606018
Validation loss: 2.0310715078025736

Epoch: 6| Step: 9
Training loss: 1.567124605178833
Validation loss: 2.0232265303211827

Epoch: 6| Step: 10
Training loss: 1.818129062652588
Validation loss: 2.0237696901444466

Epoch: 6| Step: 11
Training loss: 1.988963007926941
Validation loss: 2.0369639063394196

Epoch: 6| Step: 12
Training loss: 2.225306510925293
Validation loss: 2.018398536148892

Epoch: 6| Step: 13
Training loss: 1.8086363077163696
Validation loss: 2.038674037943604

Epoch: 124| Step: 0
Training loss: 2.387377977371216
Validation loss: 2.0216235345409763

Epoch: 6| Step: 1
Training loss: 2.006002426147461
Validation loss: 2.018388784059914

Epoch: 6| Step: 2
Training loss: 2.810274124145508
Validation loss: 2.02408952354103

Epoch: 6| Step: 3
Training loss: 1.5982390642166138
Validation loss: 2.0270000298817954

Epoch: 6| Step: 4
Training loss: 1.5931917428970337
Validation loss: 2.0414508799070954

Epoch: 6| Step: 5
Training loss: 2.150303602218628
Validation loss: 2.0446235518301688

Epoch: 6| Step: 6
Training loss: 2.243690252304077
Validation loss: 2.0128493501294042

Epoch: 6| Step: 7
Training loss: 1.7641205787658691
Validation loss: 1.9865767853234404

Epoch: 6| Step: 8
Training loss: 2.085322618484497
Validation loss: 2.0178195174022386

Epoch: 6| Step: 9
Training loss: 1.4429806470870972
Validation loss: 2.0196264879677885

Epoch: 6| Step: 10
Training loss: 1.8128095865249634
Validation loss: 2.004216556907982

Epoch: 6| Step: 11
Training loss: 2.208031177520752
Validation loss: 2.023823748352707

Epoch: 6| Step: 12
Training loss: 2.060746192932129
Validation loss: 2.0155324448821363

Epoch: 6| Step: 13
Training loss: 2.5290021896362305
Validation loss: 2.0246836446946666

Epoch: 125| Step: 0
Training loss: 1.977757215499878
Validation loss: 2.0108103047135057

Epoch: 6| Step: 1
Training loss: 2.183629274368286
Validation loss: 2.0269467215384207

Epoch: 6| Step: 2
Training loss: 2.0339484214782715
Validation loss: 2.0059368097653953

Epoch: 6| Step: 3
Training loss: 2.1539559364318848
Validation loss: 2.0105789502461753

Epoch: 6| Step: 4
Training loss: 2.9131293296813965
Validation loss: 2.0267543331269295

Epoch: 6| Step: 5
Training loss: 2.0733227729797363
Validation loss: 2.042515593190347

Epoch: 6| Step: 6
Training loss: 2.2942609786987305
Validation loss: 2.017190097480692

Epoch: 6| Step: 7
Training loss: 1.5046197175979614
Validation loss: 2.0293682749553392

Epoch: 6| Step: 8
Training loss: 1.8804278373718262
Validation loss: 2.0076599877367736

Epoch: 6| Step: 9
Training loss: 1.7645636796951294
Validation loss: 2.0171987600223993

Epoch: 6| Step: 10
Training loss: 2.0608839988708496
Validation loss: 2.0373735658584105

Epoch: 6| Step: 11
Training loss: 1.7177698612213135
Validation loss: 2.0359713992764874

Epoch: 6| Step: 12
Training loss: 1.9231903553009033
Validation loss: 2.0025757666557067

Epoch: 6| Step: 13
Training loss: 1.7992019653320312
Validation loss: 2.033375729796707

Epoch: 126| Step: 0
Training loss: 2.1082119941711426
Validation loss: 1.9936640711240872

Epoch: 6| Step: 1
Training loss: 2.422835350036621
Validation loss: 2.0360620150002102

Epoch: 6| Step: 2
Training loss: 1.6070384979248047
Validation loss: 2.0096552500160794

Epoch: 6| Step: 3
Training loss: 1.8279976844787598
Validation loss: 1.9952530963446504

Epoch: 6| Step: 4
Training loss: 1.8080084323883057
Validation loss: 2.0185601557454755

Epoch: 6| Step: 5
Training loss: 2.3265318870544434
Validation loss: 2.030575695858207

Epoch: 6| Step: 6
Training loss: 2.7175347805023193
Validation loss: 2.044185979391939

Epoch: 6| Step: 7
Training loss: 1.9412397146224976
Validation loss: 2.060474270133562

Epoch: 6| Step: 8
Training loss: 2.060624122619629
Validation loss: 2.0563418096111667

Epoch: 6| Step: 9
Training loss: 2.161064624786377
Validation loss: 2.046410575989754

Epoch: 6| Step: 10
Training loss: 1.3855924606323242
Validation loss: 2.004911018956092

Epoch: 6| Step: 11
Training loss: 2.7499680519104004
Validation loss: 2.0383025266790904

Epoch: 6| Step: 12
Training loss: 1.8115689754486084
Validation loss: 2.0347135028531476

Epoch: 6| Step: 13
Training loss: 1.2349662780761719
Validation loss: 2.0388224804273216

Epoch: 127| Step: 0
Training loss: 2.027942180633545
Validation loss: 2.030566282169793

Epoch: 6| Step: 1
Training loss: 2.011967182159424
Validation loss: 2.043947635158416

Epoch: 6| Step: 2
Training loss: 1.6077895164489746
Validation loss: 2.015918888071532

Epoch: 6| Step: 3
Training loss: 2.872756004333496
Validation loss: 2.0389494408843336

Epoch: 6| Step: 4
Training loss: 2.1114840507507324
Validation loss: 2.0306123200283257

Epoch: 6| Step: 5
Training loss: 2.3457164764404297
Validation loss: 2.016418421140281

Epoch: 6| Step: 6
Training loss: 1.5282182693481445
Validation loss: 2.041524141065536

Epoch: 6| Step: 7
Training loss: 1.459586262702942
Validation loss: 2.015553141152987

Epoch: 6| Step: 8
Training loss: 1.4612462520599365
Validation loss: 1.9971045435115855

Epoch: 6| Step: 9
Training loss: 2.7840821743011475
Validation loss: 2.0364919452257055

Epoch: 6| Step: 10
Training loss: 2.7046308517456055
Validation loss: 2.013983016373009

Epoch: 6| Step: 11
Training loss: 2.1873974800109863
Validation loss: 2.041298363798408

Epoch: 6| Step: 12
Training loss: 1.3512474298477173
Validation loss: 2.009956109908319

Epoch: 6| Step: 13
Training loss: 1.9215534925460815
Validation loss: 2.0092679467252506

Epoch: 128| Step: 0
Training loss: 2.4761428833007812
Validation loss: 2.02499811110958

Epoch: 6| Step: 1
Training loss: 2.353116512298584
Validation loss: 2.021431969058129

Epoch: 6| Step: 2
Training loss: 1.3233342170715332
Validation loss: 2.043005710007042

Epoch: 6| Step: 3
Training loss: 2.197089672088623
Validation loss: 2.02514277350518

Epoch: 6| Step: 4
Training loss: 2.19909405708313
Validation loss: 1.998864773781069

Epoch: 6| Step: 5
Training loss: 1.4184266328811646
Validation loss: 2.026527964940635

Epoch: 6| Step: 6
Training loss: 1.7644424438476562
Validation loss: 2.0180898609981743

Epoch: 6| Step: 7
Training loss: 2.060600996017456
Validation loss: 1.9973254998524983

Epoch: 6| Step: 8
Training loss: 1.450472116470337
Validation loss: 2.0269934797799714

Epoch: 6| Step: 9
Training loss: 2.0421125888824463
Validation loss: 2.035150526672281

Epoch: 6| Step: 10
Training loss: 2.1894919872283936
Validation loss: 2.030075115542258

Epoch: 6| Step: 11
Training loss: 2.5064001083374023
Validation loss: 2.0413028809332077

Epoch: 6| Step: 12
Training loss: 2.01938533782959
Validation loss: 2.016544915655608

Epoch: 6| Step: 13
Training loss: 3.0865347385406494
Validation loss: 2.0117998187259962

Epoch: 129| Step: 0
Training loss: 1.4797825813293457
Validation loss: 2.0123282888884186

Epoch: 6| Step: 1
Training loss: 1.7158691883087158
Validation loss: 2.037163906199958

Epoch: 6| Step: 2
Training loss: 2.266383409500122
Validation loss: 2.032345517989128

Epoch: 6| Step: 3
Training loss: 2.463024854660034
Validation loss: 2.0138468973098265

Epoch: 6| Step: 4
Training loss: 2.1139445304870605
Validation loss: 2.0315278678812008

Epoch: 6| Step: 5
Training loss: 1.8809785842895508
Validation loss: 2.044792805948565

Epoch: 6| Step: 6
Training loss: 1.9077885150909424
Validation loss: 2.049082097186837

Epoch: 6| Step: 7
Training loss: 2.726186513900757
Validation loss: 2.043232353784705

Epoch: 6| Step: 8
Training loss: 1.577126145362854
Validation loss: 2.0252657372464418

Epoch: 6| Step: 9
Training loss: 1.5651512145996094
Validation loss: 2.050230618446104

Epoch: 6| Step: 10
Training loss: 1.9589262008666992
Validation loss: 2.0436306602211407

Epoch: 6| Step: 11
Training loss: 2.043684244155884
Validation loss: 2.0523996994059575

Epoch: 6| Step: 12
Training loss: 2.529592990875244
Validation loss: 2.041333839457522

Epoch: 6| Step: 13
Training loss: 2.2728888988494873
Validation loss: 2.0534246634411555

Epoch: 130| Step: 0
Training loss: 2.481222152709961
Validation loss: 2.046960125687302

Epoch: 6| Step: 1
Training loss: 1.5752537250518799
Validation loss: 2.0513478222713677

Epoch: 6| Step: 2
Training loss: 1.5689759254455566
Validation loss: 2.0084287069177114

Epoch: 6| Step: 3
Training loss: 2.178831100463867
Validation loss: 2.046513807389044

Epoch: 6| Step: 4
Training loss: 1.9814467430114746
Validation loss: 2.0641584832181215

Epoch: 6| Step: 5
Training loss: 1.853541612625122
Validation loss: 2.015312592188517

Epoch: 6| Step: 6
Training loss: 1.4750406742095947
Validation loss: 2.0429611065054454

Epoch: 6| Step: 7
Training loss: 1.6138070821762085
Validation loss: 2.050351486411146

Epoch: 6| Step: 8
Training loss: 1.840620994567871
Validation loss: 2.0302324974408714

Epoch: 6| Step: 9
Training loss: 2.203146457672119
Validation loss: 1.9987984165068595

Epoch: 6| Step: 10
Training loss: 1.9002615213394165
Validation loss: 2.0225583507168676

Epoch: 6| Step: 11
Training loss: 2.452061891555786
Validation loss: 2.0331990154840613

Epoch: 6| Step: 12
Training loss: 2.730653762817383
Validation loss: 2.003688725092078

Epoch: 6| Step: 13
Training loss: 3.0503196716308594
Validation loss: 1.9805926199882262

Epoch: 131| Step: 0
Training loss: 2.720273971557617
Validation loss: 2.0054802279318533

Epoch: 6| Step: 1
Training loss: 1.8256993293762207
Validation loss: 2.0511299538356003

Epoch: 6| Step: 2
Training loss: 2.357719659805298
Validation loss: 2.0106575591589815

Epoch: 6| Step: 3
Training loss: 2.6308910846710205
Validation loss: 2.025969739883177

Epoch: 6| Step: 4
Training loss: 2.416801691055298
Validation loss: 2.037287991533997

Epoch: 6| Step: 5
Training loss: 1.6445603370666504
Validation loss: 2.0136066739277174

Epoch: 6| Step: 6
Training loss: 1.3912793397903442
Validation loss: 2.017625903570524

Epoch: 6| Step: 7
Training loss: 1.6497857570648193
Validation loss: 2.0228618319316576

Epoch: 6| Step: 8
Training loss: 1.757845401763916
Validation loss: 2.0136152736602293

Epoch: 6| Step: 9
Training loss: 1.989773154258728
Validation loss: 2.0282839318757415

Epoch: 6| Step: 10
Training loss: 2.3336679935455322
Validation loss: 2.0298150713725756

Epoch: 6| Step: 11
Training loss: 2.3822691440582275
Validation loss: 1.9986391964779104

Epoch: 6| Step: 12
Training loss: 1.4343812465667725
Validation loss: 2.0440234702120543

Epoch: 6| Step: 13
Training loss: 1.8798179626464844
Validation loss: 2.0346549890374623

Epoch: 132| Step: 0
Training loss: 2.7124388217926025
Validation loss: 2.029424782722227

Epoch: 6| Step: 1
Training loss: 1.830682396888733
Validation loss: 2.0309285809916835

Epoch: 6| Step: 2
Training loss: 1.9701387882232666
Validation loss: 2.013405635792722

Epoch: 6| Step: 3
Training loss: 2.151991367340088
Validation loss: 2.0466509365266368

Epoch: 6| Step: 4
Training loss: 2.5301754474639893
Validation loss: 2.0221763400621313

Epoch: 6| Step: 5
Training loss: 2.120934009552002
Validation loss: 2.0241212280847694

Epoch: 6| Step: 6
Training loss: 1.8558512926101685
Validation loss: 2.041906335020578

Epoch: 6| Step: 7
Training loss: 2.0916330814361572
Validation loss: 2.025008055471605

Epoch: 6| Step: 8
Training loss: 1.4689199924468994
Validation loss: 2.0560803759482598

Epoch: 6| Step: 9
Training loss: 1.0399062633514404
Validation loss: 2.0205458107814995

Epoch: 6| Step: 10
Training loss: 2.5629172325134277
Validation loss: 2.018794575045186

Epoch: 6| Step: 11
Training loss: 1.8847870826721191
Validation loss: 2.0316626269330262

Epoch: 6| Step: 12
Training loss: 1.9391319751739502
Validation loss: 2.0233958818579234

Epoch: 6| Step: 13
Training loss: 2.6544976234436035
Validation loss: 2.031459882695188

Epoch: 133| Step: 0
Training loss: 1.9934608936309814
Validation loss: 2.0169867597600466

Epoch: 6| Step: 1
Training loss: 1.629948377609253
Validation loss: 2.0188384081727717

Epoch: 6| Step: 2
Training loss: 1.8988505601882935
Validation loss: 2.01396285205759

Epoch: 6| Step: 3
Training loss: 1.435600996017456
Validation loss: 2.0145917771964945

Epoch: 6| Step: 4
Training loss: 1.5933390855789185
Validation loss: 2.007955999784572

Epoch: 6| Step: 5
Training loss: 2.0603623390197754
Validation loss: 2.0317046001393306

Epoch: 6| Step: 6
Training loss: 2.5902140140533447
Validation loss: 2.013358933951265

Epoch: 6| Step: 7
Training loss: 2.112039089202881
Validation loss: 2.001423361480877

Epoch: 6| Step: 8
Training loss: 3.138408660888672
Validation loss: 2.0406287459916967

Epoch: 6| Step: 9
Training loss: 1.7251816987991333
Validation loss: 2.0260350678556707

Epoch: 6| Step: 10
Training loss: 2.0277180671691895
Validation loss: 1.9827120124652822

Epoch: 6| Step: 11
Training loss: 1.31587815284729
Validation loss: 2.0022096915911605

Epoch: 6| Step: 12
Training loss: 2.2183773517608643
Validation loss: 2.0313616004041446

Epoch: 6| Step: 13
Training loss: 2.7083470821380615
Validation loss: 2.037848593086325

Epoch: 134| Step: 0
Training loss: 2.1311678886413574
Validation loss: 2.008750642499616

Epoch: 6| Step: 1
Training loss: 2.352559804916382
Validation loss: 2.033940138355378

Epoch: 6| Step: 2
Training loss: 1.9148573875427246
Validation loss: 2.041352944989358

Epoch: 6| Step: 3
Training loss: 1.9828683137893677
Validation loss: 2.020618247729476

Epoch: 6| Step: 4
Training loss: 1.2582088708877563
Validation loss: 2.026995481983308

Epoch: 6| Step: 5
Training loss: 1.7721264362335205
Validation loss: 2.0381020038358626

Epoch: 6| Step: 6
Training loss: 1.3988192081451416
Validation loss: 2.017427913604244

Epoch: 6| Step: 7
Training loss: 2.54862642288208
Validation loss: 2.0165375048114407

Epoch: 6| Step: 8
Training loss: 2.5148744583129883
Validation loss: 2.034852663675944

Epoch: 6| Step: 9
Training loss: 2.46807861328125
Validation loss: 2.031878403438035

Epoch: 6| Step: 10
Training loss: 2.0115084648132324
Validation loss: 2.01967780692603

Epoch: 6| Step: 11
Training loss: 1.8194165229797363
Validation loss: 2.0393307747379428

Epoch: 6| Step: 12
Training loss: 1.7628934383392334
Validation loss: 2.028693619594779

Epoch: 6| Step: 13
Training loss: 2.4767873287200928
Validation loss: 2.030973393429992

Epoch: 135| Step: 0
Training loss: 1.205527424812317
Validation loss: 2.0696901980266778

Epoch: 6| Step: 1
Training loss: 1.4275134801864624
Validation loss: 2.0246313412984214

Epoch: 6| Step: 2
Training loss: 1.8022427558898926
Validation loss: 2.0004587993826917

Epoch: 6| Step: 3
Training loss: 2.4415459632873535
Validation loss: 2.022376896232687

Epoch: 6| Step: 4
Training loss: 2.5515570640563965
Validation loss: 2.0322996467672367

Epoch: 6| Step: 5
Training loss: 2.7569141387939453
Validation loss: 2.0318882362816924

Epoch: 6| Step: 6
Training loss: 2.3238437175750732
Validation loss: 2.0380361874898276

Epoch: 6| Step: 7
Training loss: 1.9134857654571533
Validation loss: 2.015486585196628

Epoch: 6| Step: 8
Training loss: 1.7209779024124146
Validation loss: 2.020693304718182

Epoch: 6| Step: 9
Training loss: 1.7380064725875854
Validation loss: 2.040065047561481

Epoch: 6| Step: 10
Training loss: 1.7609937191009521
Validation loss: 2.041411466495965

Epoch: 6| Step: 11
Training loss: 2.151005744934082
Validation loss: 2.032118987011653

Epoch: 6| Step: 12
Training loss: 2.3831350803375244
Validation loss: 2.026415806944652

Epoch: 6| Step: 13
Training loss: 2.1857645511627197
Validation loss: 2.0204330118753577

Epoch: 136| Step: 0
Training loss: 2.716327428817749
Validation loss: 2.02002356642036

Epoch: 6| Step: 1
Training loss: 2.684508800506592
Validation loss: 2.0382745970961866

Epoch: 6| Step: 2
Training loss: 1.8018854856491089
Validation loss: 2.016954552742743

Epoch: 6| Step: 3
Training loss: 1.9880874156951904
Validation loss: 2.0364521664957844

Epoch: 6| Step: 4
Training loss: 2.0927481651306152
Validation loss: 2.006893320750165

Epoch: 6| Step: 5
Training loss: 2.1729955673217773
Validation loss: 2.019491552024759

Epoch: 6| Step: 6
Training loss: 1.3394043445587158
Validation loss: 2.020593609861148

Epoch: 6| Step: 7
Training loss: 1.5821778774261475
Validation loss: 2.0212959858679

Epoch: 6| Step: 8
Training loss: 2.2359161376953125
Validation loss: 2.037581654005153

Epoch: 6| Step: 9
Training loss: 2.5407419204711914
Validation loss: 2.028804834171008

Epoch: 6| Step: 10
Training loss: 1.538484811782837
Validation loss: 2.0083854006182764

Epoch: 6| Step: 11
Training loss: 1.9386227130889893
Validation loss: 1.9935939747800109

Epoch: 6| Step: 12
Training loss: 1.2289388179779053
Validation loss: 2.024716474676645

Epoch: 6| Step: 13
Training loss: 2.540940761566162
Validation loss: 2.018434937282275

Epoch: 137| Step: 0
Training loss: 2.216095447540283
Validation loss: 2.007061912167457

Epoch: 6| Step: 1
Training loss: 2.548551082611084
Validation loss: 2.0071126863520634

Epoch: 6| Step: 2
Training loss: 1.9518438577651978
Validation loss: 2.0228352277509627

Epoch: 6| Step: 3
Training loss: 2.1806750297546387
Validation loss: 2.0020405605275142

Epoch: 6| Step: 4
Training loss: 1.7701704502105713
Validation loss: 2.005032424003847

Epoch: 6| Step: 5
Training loss: 1.7426118850708008
Validation loss: 1.980224504265734

Epoch: 6| Step: 6
Training loss: 1.8392277956008911
Validation loss: 2.015521826282624

Epoch: 6| Step: 7
Training loss: 2.6302573680877686
Validation loss: 2.0201673174417145

Epoch: 6| Step: 8
Training loss: 2.0358235836029053
Validation loss: 2.0157045830962477

Epoch: 6| Step: 9
Training loss: 1.5488684177398682
Validation loss: 2.007409959711054

Epoch: 6| Step: 10
Training loss: 1.5718731880187988
Validation loss: 1.97876267022984

Epoch: 6| Step: 11
Training loss: 1.5833953619003296
Validation loss: 2.030284543191233

Epoch: 6| Step: 12
Training loss: 2.436016798019409
Validation loss: 2.0175860338313605

Epoch: 6| Step: 13
Training loss: 2.1752851009368896
Validation loss: 1.9826058174974175

Epoch: 138| Step: 0
Training loss: 1.6341817378997803
Validation loss: 2.0115035439050324

Epoch: 6| Step: 1
Training loss: 2.177168607711792
Validation loss: 2.008302459152796

Epoch: 6| Step: 2
Training loss: 1.4794477224349976
Validation loss: 1.9955917814726472

Epoch: 6| Step: 3
Training loss: 2.4339370727539062
Validation loss: 2.024862604756509

Epoch: 6| Step: 4
Training loss: 2.4684488773345947
Validation loss: 2.011468082345942

Epoch: 6| Step: 5
Training loss: 1.7788982391357422
Validation loss: 2.0237565066224787

Epoch: 6| Step: 6
Training loss: 1.4322865009307861
Validation loss: 2.0021035850688977

Epoch: 6| Step: 7
Training loss: 1.794532060623169
Validation loss: 1.9884037753587127

Epoch: 6| Step: 8
Training loss: 1.8259518146514893
Validation loss: 2.034541383866341

Epoch: 6| Step: 9
Training loss: 2.044318437576294
Validation loss: 2.033322257380332

Epoch: 6| Step: 10
Training loss: 1.8931249380111694
Validation loss: 2.026518999889333

Epoch: 6| Step: 11
Training loss: 2.205909490585327
Validation loss: 1.998089833926129

Epoch: 6| Step: 12
Training loss: 2.6466405391693115
Validation loss: 2.011730130000781

Epoch: 6| Step: 13
Training loss: 2.317948818206787
Validation loss: 2.004992610664778

Epoch: 139| Step: 0
Training loss: 2.4254708290100098
Validation loss: 2.0088648193625995

Epoch: 6| Step: 1
Training loss: 1.912174940109253
Validation loss: 2.031645667168402

Epoch: 6| Step: 2
Training loss: 2.142732620239258
Validation loss: 2.0258030481235956

Epoch: 6| Step: 3
Training loss: 2.3557305335998535
Validation loss: 2.0400258700052896

Epoch: 6| Step: 4
Training loss: 1.5157557725906372
Validation loss: 2.035680599110101

Epoch: 6| Step: 5
Training loss: 1.469053030014038
Validation loss: 2.04405947654478

Epoch: 6| Step: 6
Training loss: 1.8209760189056396
Validation loss: 2.0103507375204437

Epoch: 6| Step: 7
Training loss: 1.6996550559997559
Validation loss: 2.0425755336720455

Epoch: 6| Step: 8
Training loss: 2.1985368728637695
Validation loss: 2.0572900003002537

Epoch: 6| Step: 9
Training loss: 2.0392236709594727
Validation loss: 2.031471675442111

Epoch: 6| Step: 10
Training loss: 2.1476516723632812
Validation loss: 2.058758028091923

Epoch: 6| Step: 11
Training loss: 1.85531747341156
Validation loss: 2.0163639130130893

Epoch: 6| Step: 12
Training loss: 2.3450002670288086
Validation loss: 2.0446645482893913

Epoch: 6| Step: 13
Training loss: 2.047125816345215
Validation loss: 2.0162851297727196

Epoch: 140| Step: 0
Training loss: 2.7064270973205566
Validation loss: 2.0124166832175305

Epoch: 6| Step: 1
Training loss: 2.3714914321899414
Validation loss: 2.0137150902901926

Epoch: 6| Step: 2
Training loss: 2.121797800064087
Validation loss: 2.0634779084113335

Epoch: 6| Step: 3
Training loss: 1.9553042650222778
Validation loss: 2.0272354541286344

Epoch: 6| Step: 4
Training loss: 1.5736429691314697
Validation loss: 2.038193113060408

Epoch: 6| Step: 5
Training loss: 1.6123390197753906
Validation loss: 2.015294224985184

Epoch: 6| Step: 6
Training loss: 1.5231603384017944
Validation loss: 2.033406501175255

Epoch: 6| Step: 7
Training loss: 2.616133213043213
Validation loss: 2.029046053527504

Epoch: 6| Step: 8
Training loss: 1.7258696556091309
Validation loss: 2.0122933618484007

Epoch: 6| Step: 9
Training loss: 1.386932373046875
Validation loss: 2.0335507879975023

Epoch: 6| Step: 10
Training loss: 1.9289956092834473
Validation loss: 2.0082604218554754

Epoch: 6| Step: 11
Training loss: 2.8441383838653564
Validation loss: 2.0086580989181355

Epoch: 6| Step: 12
Training loss: 1.4693694114685059
Validation loss: 2.021241675141037

Epoch: 6| Step: 13
Training loss: 1.9025039672851562
Validation loss: 2.0335651264395764

Epoch: 141| Step: 0
Training loss: 2.5369179248809814
Validation loss: 2.0024880081094723

Epoch: 6| Step: 1
Training loss: 1.9528964757919312
Validation loss: 2.0030250421134372

Epoch: 6| Step: 2
Training loss: 1.8983550071716309
Validation loss: 2.0106079732218096

Epoch: 6| Step: 3
Training loss: 1.8374381065368652
Validation loss: 2.004706576306333

Epoch: 6| Step: 4
Training loss: 1.5517959594726562
Validation loss: 1.9984160059241838

Epoch: 6| Step: 5
Training loss: 2.2559237480163574
Validation loss: 1.9735892870092904

Epoch: 6| Step: 6
Training loss: 1.9823806285858154
Validation loss: 1.991002328934208

Epoch: 6| Step: 7
Training loss: 1.9198698997497559
Validation loss: 1.9838715778884066

Epoch: 6| Step: 8
Training loss: 1.9567126035690308
Validation loss: 2.015461039799516

Epoch: 6| Step: 9
Training loss: 1.702099323272705
Validation loss: 1.9924168048366424

Epoch: 6| Step: 10
Training loss: 2.1859123706817627
Validation loss: 1.9923030535380046

Epoch: 6| Step: 11
Training loss: 2.076544761657715
Validation loss: 1.996681180051578

Epoch: 6| Step: 12
Training loss: 2.199751377105713
Validation loss: 1.9779406773146762

Epoch: 6| Step: 13
Training loss: 1.5377840995788574
Validation loss: 2.007216622752528

Epoch: 142| Step: 0
Training loss: 2.490419864654541
Validation loss: 2.0119734515425978

Epoch: 6| Step: 1
Training loss: 1.9681422710418701
Validation loss: 2.0158722041755595

Epoch: 6| Step: 2
Training loss: 1.8072757720947266
Validation loss: 2.0382498592458744

Epoch: 6| Step: 3
Training loss: 2.1283140182495117
Validation loss: 2.0310207387452484

Epoch: 6| Step: 4
Training loss: 1.3862963914871216
Validation loss: 2.0470711543995845

Epoch: 6| Step: 5
Training loss: 1.7564082145690918
Validation loss: 2.038381097137287

Epoch: 6| Step: 6
Training loss: 1.896490454673767
Validation loss: 2.0178003695703324

Epoch: 6| Step: 7
Training loss: 1.638217806816101
Validation loss: 2.0237349284592496

Epoch: 6| Step: 8
Training loss: 2.0144104957580566
Validation loss: 2.0196747190208844

Epoch: 6| Step: 9
Training loss: 2.61080265045166
Validation loss: 2.0367798113053843

Epoch: 6| Step: 10
Training loss: 2.234053134918213
Validation loss: 2.0291733677669237

Epoch: 6| Step: 11
Training loss: 2.4468095302581787
Validation loss: 2.024622377528939

Epoch: 6| Step: 12
Training loss: 1.6884311437606812
Validation loss: 2.0180754520559825

Epoch: 6| Step: 13
Training loss: 1.9449727535247803
Validation loss: 2.027861258035065

Epoch: 143| Step: 0
Training loss: 1.8042083978652954
Validation loss: 2.0179885561748216

Epoch: 6| Step: 1
Training loss: 1.9855213165283203
Validation loss: 2.0210554804853214

Epoch: 6| Step: 2
Training loss: 1.7249070405960083
Validation loss: 2.0262672901153564

Epoch: 6| Step: 3
Training loss: 2.1092641353607178
Validation loss: 1.9844487815774896

Epoch: 6| Step: 4
Training loss: 1.6836568117141724
Validation loss: 2.0123216798228603

Epoch: 6| Step: 5
Training loss: 2.4653334617614746
Validation loss: 1.9932181809538154

Epoch: 6| Step: 6
Training loss: 1.9791609048843384
Validation loss: 2.000687265908846

Epoch: 6| Step: 7
Training loss: 2.0294315814971924
Validation loss: 2.02036892085947

Epoch: 6| Step: 8
Training loss: 2.160463333129883
Validation loss: 1.9854047657341085

Epoch: 6| Step: 9
Training loss: 1.8143911361694336
Validation loss: 1.9952402614778089

Epoch: 6| Step: 10
Training loss: 1.9720674753189087
Validation loss: 2.0016715129216514

Epoch: 6| Step: 11
Training loss: 1.7885289192199707
Validation loss: 2.010344038727463

Epoch: 6| Step: 12
Training loss: 2.4233458042144775
Validation loss: 2.013150006212214

Epoch: 6| Step: 13
Training loss: 1.6098008155822754
Validation loss: 1.9904221783402145

Epoch: 144| Step: 0
Training loss: 2.1909687519073486
Validation loss: 2.0070740458785847

Epoch: 6| Step: 1
Training loss: 1.742021083831787
Validation loss: 2.0160402431282947

Epoch: 6| Step: 2
Training loss: 2.213151454925537
Validation loss: 1.9979533482623357

Epoch: 6| Step: 3
Training loss: 2.0352978706359863
Validation loss: 2.0092095252006286

Epoch: 6| Step: 4
Training loss: 2.2482569217681885
Validation loss: 1.9942003039903538

Epoch: 6| Step: 5
Training loss: 1.9730669260025024
Validation loss: 2.0058034363613335

Epoch: 6| Step: 6
Training loss: 0.7164899110794067
Validation loss: 1.9897073648309196

Epoch: 6| Step: 7
Training loss: 2.1900582313537598
Validation loss: 2.0047369926206526

Epoch: 6| Step: 8
Training loss: 2.350691795349121
Validation loss: 2.004515879897661

Epoch: 6| Step: 9
Training loss: 2.3318638801574707
Validation loss: 1.985515220190889

Epoch: 6| Step: 10
Training loss: 2.5490236282348633
Validation loss: 2.005928111332719

Epoch: 6| Step: 11
Training loss: 1.3372102975845337
Validation loss: 2.0223302251549176

Epoch: 6| Step: 12
Training loss: 2.0573060512542725
Validation loss: 2.0194111998363207

Epoch: 6| Step: 13
Training loss: 1.5435066223144531
Validation loss: 2.0110627425614225

Epoch: 145| Step: 0
Training loss: 1.7003557682037354
Validation loss: 2.016543076884362

Epoch: 6| Step: 1
Training loss: 2.5709879398345947
Validation loss: 2.0123058480601155

Epoch: 6| Step: 2
Training loss: 1.5142625570297241
Validation loss: 2.00307503438765

Epoch: 6| Step: 3
Training loss: 2.421849250793457
Validation loss: 1.9846926235383557

Epoch: 6| Step: 4
Training loss: 1.5775127410888672
Validation loss: 2.017475305065032

Epoch: 6| Step: 5
Training loss: 2.120049476623535
Validation loss: 1.9849155513189172

Epoch: 6| Step: 6
Training loss: 2.152956962585449
Validation loss: 2.0112824311820408

Epoch: 6| Step: 7
Training loss: 1.67958664894104
Validation loss: 1.9768359712375108

Epoch: 6| Step: 8
Training loss: 1.2808756828308105
Validation loss: 1.9925139642530871

Epoch: 6| Step: 9
Training loss: 2.1406190395355225
Validation loss: 2.022626470494014

Epoch: 6| Step: 10
Training loss: 1.5793070793151855
Validation loss: 1.998382806777954

Epoch: 6| Step: 11
Training loss: 2.340127944946289
Validation loss: 1.9804155980387042

Epoch: 6| Step: 12
Training loss: 1.8160393238067627
Validation loss: 1.9643241102977465

Epoch: 6| Step: 13
Training loss: 2.6355464458465576
Validation loss: 1.9946786690783758

Epoch: 146| Step: 0
Training loss: 2.5922281742095947
Validation loss: 2.0064849904788438

Epoch: 6| Step: 1
Training loss: 2.029693603515625
Validation loss: 1.984412198425621

Epoch: 6| Step: 2
Training loss: 1.8451368808746338
Validation loss: 2.001069682900624

Epoch: 6| Step: 3
Training loss: 2.000032901763916
Validation loss: 1.9943784385599115

Epoch: 6| Step: 4
Training loss: 1.9718775749206543
Validation loss: 2.0000395877386934

Epoch: 6| Step: 5
Training loss: 2.314876079559326
Validation loss: 1.97703581471597

Epoch: 6| Step: 6
Training loss: 1.6082971096038818
Validation loss: 2.016523245842226

Epoch: 6| Step: 7
Training loss: 1.7619460821151733
Validation loss: 2.007265762616229

Epoch: 6| Step: 8
Training loss: 1.6172456741333008
Validation loss: 1.9933230274467058

Epoch: 6| Step: 9
Training loss: 1.909255027770996
Validation loss: 2.024546279702135

Epoch: 6| Step: 10
Training loss: 2.2050864696502686
Validation loss: 1.9909047900989492

Epoch: 6| Step: 11
Training loss: 1.742796778678894
Validation loss: 2.0059598363855833

Epoch: 6| Step: 12
Training loss: 2.16171932220459
Validation loss: 1.987946255232698

Epoch: 6| Step: 13
Training loss: 1.6562162637710571
Validation loss: 1.991150725272394

Epoch: 147| Step: 0
Training loss: 2.112757682800293
Validation loss: 1.9914870826146935

Epoch: 6| Step: 1
Training loss: 1.6450691223144531
Validation loss: 2.009114908915694

Epoch: 6| Step: 2
Training loss: 1.9879153966903687
Validation loss: 2.0044847098729943

Epoch: 6| Step: 3
Training loss: 2.1945085525512695
Validation loss: 1.9620150699410388

Epoch: 6| Step: 4
Training loss: 2.4793179035186768
Validation loss: 1.9902602587976763

Epoch: 6| Step: 5
Training loss: 1.4108572006225586
Validation loss: 1.9857255412686257

Epoch: 6| Step: 6
Training loss: 2.217691659927368
Validation loss: 1.9698356966818533

Epoch: 6| Step: 7
Training loss: 2.556086540222168
Validation loss: 1.9862773213335263

Epoch: 6| Step: 8
Training loss: 2.049623966217041
Validation loss: 1.9764537529278827

Epoch: 6| Step: 9
Training loss: 2.0401039123535156
Validation loss: 2.0140555148483603

Epoch: 6| Step: 10
Training loss: 1.8493330478668213
Validation loss: 1.9782218138376872

Epoch: 6| Step: 11
Training loss: 1.7092835903167725
Validation loss: 1.9902667409630233

Epoch: 6| Step: 12
Training loss: 1.841638207435608
Validation loss: 2.005681574985545

Epoch: 6| Step: 13
Training loss: 1.3423038721084595
Validation loss: 2.0018263606614966

Epoch: 148| Step: 0
Training loss: 1.8676295280456543
Validation loss: 2.0106324675262615

Epoch: 6| Step: 1
Training loss: 2.1270484924316406
Validation loss: 2.0210407613426127

Epoch: 6| Step: 2
Training loss: 1.616722822189331
Validation loss: 2.00999625267521

Epoch: 6| Step: 3
Training loss: 2.775886058807373
Validation loss: 1.9844547061509983

Epoch: 6| Step: 4
Training loss: 1.4533944129943848
Validation loss: 1.9933637265236146

Epoch: 6| Step: 5
Training loss: 1.6157629489898682
Validation loss: 1.9737732641158565

Epoch: 6| Step: 6
Training loss: 2.2899694442749023
Validation loss: 2.003658349796008

Epoch: 6| Step: 7
Training loss: 2.299916982650757
Validation loss: 2.0178705710236744

Epoch: 6| Step: 8
Training loss: 2.1929092407226562
Validation loss: 2.003546905773942

Epoch: 6| Step: 9
Training loss: 2.029148578643799
Validation loss: 1.995172328846429

Epoch: 6| Step: 10
Training loss: 1.7515652179718018
Validation loss: 1.9736923863810878

Epoch: 6| Step: 11
Training loss: 1.7684810161590576
Validation loss: 1.9885671984764837

Epoch: 6| Step: 12
Training loss: 1.499898910522461
Validation loss: 1.9880757242120721

Epoch: 6| Step: 13
Training loss: 2.4173929691314697
Validation loss: 1.963314494779033

Epoch: 149| Step: 0
Training loss: 1.5586684942245483
Validation loss: 1.9521600815557665

Epoch: 6| Step: 1
Training loss: 1.9247370958328247
Validation loss: 1.9786681539268904

Epoch: 6| Step: 2
Training loss: 2.8685338497161865
Validation loss: 2.0016561887597524

Epoch: 6| Step: 3
Training loss: 2.6070480346679688
Validation loss: 1.9968268973852998

Epoch: 6| Step: 4
Training loss: 2.569234609603882
Validation loss: 1.9930484974256126

Epoch: 6| Step: 5
Training loss: 1.3734745979309082
Validation loss: 1.9964819057013399

Epoch: 6| Step: 6
Training loss: 1.8892662525177002
Validation loss: 2.0279289522478656

Epoch: 6| Step: 7
Training loss: 1.9287523031234741
Validation loss: 2.016777576938752

Epoch: 6| Step: 8
Training loss: 1.5890730619430542
Validation loss: 1.995230842662114

Epoch: 6| Step: 9
Training loss: 2.208336353302002
Validation loss: 2.0024551883820565

Epoch: 6| Step: 10
Training loss: 1.926598310470581
Validation loss: 2.0215240832298034

Epoch: 6| Step: 11
Training loss: 1.877868890762329
Validation loss: 2.006276028130644

Epoch: 6| Step: 12
Training loss: 1.4704551696777344
Validation loss: 1.9875687463309175

Epoch: 6| Step: 13
Training loss: 1.6585133075714111
Validation loss: 2.0242968477228636

Epoch: 150| Step: 0
Training loss: 2.3550355434417725
Validation loss: 2.0213112062023533

Epoch: 6| Step: 1
Training loss: 1.9644861221313477
Validation loss: 2.010827454187537

Epoch: 6| Step: 2
Training loss: 1.8589636087417603
Validation loss: 2.0017619530359902

Epoch: 6| Step: 3
Training loss: 1.6937841176986694
Validation loss: 2.017749482585538

Epoch: 6| Step: 4
Training loss: 1.3276004791259766
Validation loss: 1.995815328372422

Epoch: 6| Step: 5
Training loss: 2.304126262664795
Validation loss: 1.9992936836775912

Epoch: 6| Step: 6
Training loss: 1.9387028217315674
Validation loss: 1.9977198518732542

Epoch: 6| Step: 7
Training loss: 3.1808481216430664
Validation loss: 1.9958663473847091

Epoch: 6| Step: 8
Training loss: 2.380532741546631
Validation loss: 1.996233347923525

Epoch: 6| Step: 9
Training loss: 1.8910443782806396
Validation loss: 1.9801038593374274

Epoch: 6| Step: 10
Training loss: 1.4760113954544067
Validation loss: 1.9890518265385781

Epoch: 6| Step: 11
Training loss: 2.1141371726989746
Validation loss: 1.9646948665700934

Epoch: 6| Step: 12
Training loss: 1.1063233613967896
Validation loss: 2.0020858536484423

Epoch: 6| Step: 13
Training loss: 1.7927186489105225
Validation loss: 1.9858361418529222

Epoch: 151| Step: 0
Training loss: 2.4816784858703613
Validation loss: 1.9945153292789255

Epoch: 6| Step: 1
Training loss: 2.1160707473754883
Validation loss: 2.0005808786679338

Epoch: 6| Step: 2
Training loss: 1.0439751148223877
Validation loss: 1.9949823707662604

Epoch: 6| Step: 3
Training loss: 1.7816252708435059
Validation loss: 2.0025249527346705

Epoch: 6| Step: 4
Training loss: 2.3324131965637207
Validation loss: 2.0006117820739746

Epoch: 6| Step: 5
Training loss: 2.215573787689209
Validation loss: 2.0169806044588805

Epoch: 6| Step: 6
Training loss: 1.895203709602356
Validation loss: 2.004784604554535

Epoch: 6| Step: 7
Training loss: 2.2408347129821777
Validation loss: 2.015024867109073

Epoch: 6| Step: 8
Training loss: 2.1885571479797363
Validation loss: 1.9941311318387267

Epoch: 6| Step: 9
Training loss: 1.9030258655548096
Validation loss: 2.001668958253758

Epoch: 6| Step: 10
Training loss: 1.6961157321929932
Validation loss: 2.0159676831255675

Epoch: 6| Step: 11
Training loss: 1.8245954513549805
Validation loss: 2.0144900352724138

Epoch: 6| Step: 12
Training loss: 2.005068302154541
Validation loss: 1.9903961279058968

Epoch: 6| Step: 13
Training loss: 1.1347298622131348
Validation loss: 1.997982826284183

Epoch: 152| Step: 0
Training loss: 2.3634612560272217
Validation loss: 2.025281847164195

Epoch: 6| Step: 1
Training loss: 1.5360491275787354
Validation loss: 2.031526311751335

Epoch: 6| Step: 2
Training loss: 1.2910124063491821
Validation loss: 1.9989162183577014

Epoch: 6| Step: 3
Training loss: 2.285536766052246
Validation loss: 1.9875048745063044

Epoch: 6| Step: 4
Training loss: 2.227200984954834
Validation loss: 2.0011781454086304

Epoch: 6| Step: 5
Training loss: 2.236966133117676
Validation loss: 1.995452783441031

Epoch: 6| Step: 6
Training loss: 2.6316237449645996
Validation loss: 1.9920793041106193

Epoch: 6| Step: 7
Training loss: 1.9776878356933594
Validation loss: 1.9924794512410318

Epoch: 6| Step: 8
Training loss: 1.506866693496704
Validation loss: 2.017892495278389

Epoch: 6| Step: 9
Training loss: 1.324310302734375
Validation loss: 1.9745158174986481

Epoch: 6| Step: 10
Training loss: 1.773321270942688
Validation loss: 1.985653886231043

Epoch: 6| Step: 11
Training loss: 1.8002208471298218
Validation loss: 1.9832389764888312

Epoch: 6| Step: 12
Training loss: 2.4998385906219482
Validation loss: 1.982481333517259

Epoch: 6| Step: 13
Training loss: 1.5570255517959595
Validation loss: 1.9908884712444839

Epoch: 153| Step: 0
Training loss: 1.601473331451416
Validation loss: 1.9665137388372933

Epoch: 6| Step: 1
Training loss: 2.571423053741455
Validation loss: 1.976731901527733

Epoch: 6| Step: 2
Training loss: 2.621702194213867
Validation loss: 1.9843857108905751

Epoch: 6| Step: 3
Training loss: 2.3527233600616455
Validation loss: 1.98945495646487

Epoch: 6| Step: 4
Training loss: 1.5749003887176514
Validation loss: 1.9861137405518563

Epoch: 6| Step: 5
Training loss: 1.3204723596572876
Validation loss: 1.9733995224839898

Epoch: 6| Step: 6
Training loss: 2.1099891662597656
Validation loss: 1.9636951261951077

Epoch: 6| Step: 7
Training loss: 1.8158241510391235
Validation loss: 2.011861043591653

Epoch: 6| Step: 8
Training loss: 1.79725182056427
Validation loss: 1.9806483073901104

Epoch: 6| Step: 9
Training loss: 2.350287914276123
Validation loss: 1.9795278067229896

Epoch: 6| Step: 10
Training loss: 2.2952795028686523
Validation loss: 1.9592637861928632

Epoch: 6| Step: 11
Training loss: 1.6160070896148682
Validation loss: 1.9676080160243536

Epoch: 6| Step: 12
Training loss: 1.4490610361099243
Validation loss: 1.9672570536213536

Epoch: 6| Step: 13
Training loss: 1.8202868700027466
Validation loss: 1.9970216853644258

Epoch: 154| Step: 0
Training loss: 1.775736927986145
Validation loss: 1.9898378349119616

Epoch: 6| Step: 1
Training loss: 2.5271098613739014
Validation loss: 1.9668483811040078

Epoch: 6| Step: 2
Training loss: 1.9362030029296875
Validation loss: 1.9821160480540285

Epoch: 6| Step: 3
Training loss: 2.2357401847839355
Validation loss: 1.9846227925310853

Epoch: 6| Step: 4
Training loss: 1.9139113426208496
Validation loss: 1.9507209177940124

Epoch: 6| Step: 5
Training loss: 2.498108386993408
Validation loss: 1.9981484413146973

Epoch: 6| Step: 6
Training loss: 2.055422306060791
Validation loss: 1.9909917974984774

Epoch: 6| Step: 7
Training loss: 1.263738989830017
Validation loss: 1.9496942989287838

Epoch: 6| Step: 8
Training loss: 2.223431348800659
Validation loss: 1.978019493882374

Epoch: 6| Step: 9
Training loss: 1.5904242992401123
Validation loss: 1.985302020144719

Epoch: 6| Step: 10
Training loss: 1.9508037567138672
Validation loss: 1.9915009160195627

Epoch: 6| Step: 11
Training loss: 1.8166484832763672
Validation loss: 1.995970674740371

Epoch: 6| Step: 12
Training loss: 1.300981044769287
Validation loss: 1.9890223959440827

Epoch: 6| Step: 13
Training loss: 1.9890238046646118
Validation loss: 1.981455026134368

Epoch: 155| Step: 0
Training loss: 2.2492618560791016
Validation loss: 1.993653335878926

Epoch: 6| Step: 1
Training loss: 2.2462191581726074
Validation loss: 1.9880728619073027

Epoch: 6| Step: 2
Training loss: 1.3468750715255737
Validation loss: 1.9953622933356994

Epoch: 6| Step: 3
Training loss: 2.0982561111450195
Validation loss: 1.995431246296052

Epoch: 6| Step: 4
Training loss: 1.859665870666504
Validation loss: 1.9797509319038802

Epoch: 6| Step: 5
Training loss: 2.503617763519287
Validation loss: 2.0023853419929423

Epoch: 6| Step: 6
Training loss: 1.8680388927459717
Validation loss: 1.9970404268592916

Epoch: 6| Step: 7
Training loss: 2.176846742630005
Validation loss: 2.0143716296842022

Epoch: 6| Step: 8
Training loss: 2.133803129196167
Validation loss: 1.9830753534070906

Epoch: 6| Step: 9
Training loss: 1.9379924535751343
Validation loss: 2.0167247403052544

Epoch: 6| Step: 10
Training loss: 1.5792392492294312
Validation loss: 1.982167338812223

Epoch: 6| Step: 11
Training loss: 1.285976767539978
Validation loss: 1.97389385648953

Epoch: 6| Step: 12
Training loss: 1.6750003099441528
Validation loss: 1.9894604836740801

Epoch: 6| Step: 13
Training loss: 2.101632833480835
Validation loss: 1.9822197062994844

Epoch: 156| Step: 0
Training loss: 2.458876132965088
Validation loss: 1.9612951688869025

Epoch: 6| Step: 1
Training loss: 1.8824249505996704
Validation loss: 1.9792143978098387

Epoch: 6| Step: 2
Training loss: 1.9452810287475586
Validation loss: 1.9591081898699525

Epoch: 6| Step: 3
Training loss: 2.0278146266937256
Validation loss: 1.9861545985744846

Epoch: 6| Step: 4
Training loss: 1.9501601457595825
Validation loss: 1.9767241452329902

Epoch: 6| Step: 5
Training loss: 1.5925740003585815
Validation loss: 1.975049171396481

Epoch: 6| Step: 6
Training loss: 1.4551866054534912
Validation loss: 1.991144500752931

Epoch: 6| Step: 7
Training loss: 1.7489780187606812
Validation loss: 1.9861246488427604

Epoch: 6| Step: 8
Training loss: 1.693798303604126
Validation loss: 1.9709068062484905

Epoch: 6| Step: 9
Training loss: 2.3774471282958984
Validation loss: 1.9725945662426692

Epoch: 6| Step: 10
Training loss: 2.5011632442474365
Validation loss: 1.9546726134515577

Epoch: 6| Step: 11
Training loss: 2.101431369781494
Validation loss: 1.9684091037319553

Epoch: 6| Step: 12
Training loss: 2.13788104057312
Validation loss: 1.9716880808594406

Epoch: 6| Step: 13
Training loss: 0.7037020921707153
Validation loss: 1.9937506183501212

Epoch: 157| Step: 0
Training loss: 1.4264883995056152
Validation loss: 1.9971924840763051

Epoch: 6| Step: 1
Training loss: 2.4693374633789062
Validation loss: 1.9464369371373167

Epoch: 6| Step: 2
Training loss: 1.6034051179885864
Validation loss: 2.0089544750029042

Epoch: 6| Step: 3
Training loss: 2.218236207962036
Validation loss: 1.9909588034434984

Epoch: 6| Step: 4
Training loss: 2.2198731899261475
Validation loss: 1.969119953852828

Epoch: 6| Step: 5
Training loss: 2.279334545135498
Validation loss: 1.9784296122930383

Epoch: 6| Step: 6
Training loss: 2.0150511264801025
Validation loss: 1.9789547586953768

Epoch: 6| Step: 7
Training loss: 1.626276969909668
Validation loss: 1.993513878955636

Epoch: 6| Step: 8
Training loss: 1.5008879899978638
Validation loss: 1.957670542501634

Epoch: 6| Step: 9
Training loss: 2.4067368507385254
Validation loss: 1.9701911582741687

Epoch: 6| Step: 10
Training loss: 2.1281611919403076
Validation loss: 1.9834206937461771

Epoch: 6| Step: 11
Training loss: 1.8843846321105957
Validation loss: 1.9654247888954737

Epoch: 6| Step: 12
Training loss: 1.4501569271087646
Validation loss: 1.9713155441386725

Epoch: 6| Step: 13
Training loss: 1.6810272932052612
Validation loss: 1.9675802979418027

Epoch: 158| Step: 0
Training loss: 2.2713427543640137
Validation loss: 1.985620576848266

Epoch: 6| Step: 1
Training loss: 1.7240934371948242
Validation loss: 1.9822313170279227

Epoch: 6| Step: 2
Training loss: 1.7652387619018555
Validation loss: 1.962867534288796

Epoch: 6| Step: 3
Training loss: 1.9499084949493408
Validation loss: 2.021107289098924

Epoch: 6| Step: 4
Training loss: 1.4372690916061401
Validation loss: 2.0165901799355783

Epoch: 6| Step: 5
Training loss: 1.6419713497161865
Validation loss: 1.9979582396886681

Epoch: 6| Step: 6
Training loss: 2.049724578857422
Validation loss: 1.9998135592347832

Epoch: 6| Step: 7
Training loss: 2.420987844467163
Validation loss: 2.0211701380309237

Epoch: 6| Step: 8
Training loss: 1.6212332248687744
Validation loss: 2.0303760587528186

Epoch: 6| Step: 9
Training loss: 1.6980443000793457
Validation loss: 2.007149379740479

Epoch: 6| Step: 10
Training loss: 2.1280951499938965
Validation loss: 1.991029611197851

Epoch: 6| Step: 11
Training loss: 1.700907588005066
Validation loss: 2.0169091122124785

Epoch: 6| Step: 12
Training loss: 2.536198139190674
Validation loss: 1.9938177857347714

Epoch: 6| Step: 13
Training loss: 2.335645914077759
Validation loss: 1.9987725673183319

Epoch: 159| Step: 0
Training loss: 1.5731666088104248
Validation loss: 2.0112948443299983

Epoch: 6| Step: 1
Training loss: 1.3615747690200806
Validation loss: 2.004045690259626

Epoch: 6| Step: 2
Training loss: 2.5749239921569824
Validation loss: 2.0035794294008644

Epoch: 6| Step: 3
Training loss: 1.2183517217636108
Validation loss: 1.9467072268967986

Epoch: 6| Step: 4
Training loss: 2.071516990661621
Validation loss: 1.9879855930164296

Epoch: 6| Step: 5
Training loss: 1.215376377105713
Validation loss: 1.9567039525637062

Epoch: 6| Step: 6
Training loss: 2.893899440765381
Validation loss: 1.9856369315937001

Epoch: 6| Step: 7
Training loss: 2.7199432849884033
Validation loss: 1.9829211465774044

Epoch: 6| Step: 8
Training loss: 2.118664026260376
Validation loss: 1.9835503126985283

Epoch: 6| Step: 9
Training loss: 1.7620422840118408
Validation loss: 1.9652361997994043

Epoch: 6| Step: 10
Training loss: 2.080155372619629
Validation loss: 1.9564208958738594

Epoch: 6| Step: 11
Training loss: 1.744809627532959
Validation loss: 1.953316064291103

Epoch: 6| Step: 12
Training loss: 1.6955686807632446
Validation loss: 1.9523073678375573

Epoch: 6| Step: 13
Training loss: 1.8390984535217285
Validation loss: 1.9414790009939542

Epoch: 160| Step: 0
Training loss: 2.0931923389434814
Validation loss: 1.9488926908021331

Epoch: 6| Step: 1
Training loss: 1.4794846773147583
Validation loss: 1.9614075640196442

Epoch: 6| Step: 2
Training loss: 1.8151917457580566
Validation loss: 1.956471461121754

Epoch: 6| Step: 3
Training loss: 2.1874139308929443
Validation loss: 1.9312386999848068

Epoch: 6| Step: 4
Training loss: 2.1057209968566895
Validation loss: 1.9589365118293351

Epoch: 6| Step: 5
Training loss: 2.2514753341674805
Validation loss: 1.9463685584324661

Epoch: 6| Step: 6
Training loss: 1.9640228748321533
Validation loss: 1.9637165928399691

Epoch: 6| Step: 7
Training loss: 2.3815698623657227
Validation loss: 1.9547134137922717

Epoch: 6| Step: 8
Training loss: 1.3810880184173584
Validation loss: 1.9502546146351805

Epoch: 6| Step: 9
Training loss: 1.6061781644821167
Validation loss: 1.9576475927906651

Epoch: 6| Step: 10
Training loss: 1.7510521411895752
Validation loss: 1.9596733406025877

Epoch: 6| Step: 11
Training loss: 2.1651885509490967
Validation loss: 1.9781537286696895

Epoch: 6| Step: 12
Training loss: 1.7766258716583252
Validation loss: 1.9699535010963358

Epoch: 6| Step: 13
Training loss: 1.7056920528411865
Validation loss: 1.9473442313491658

Epoch: 161| Step: 0
Training loss: 1.9555821418762207
Validation loss: 1.9535541303696171

Epoch: 6| Step: 1
Training loss: 1.2893359661102295
Validation loss: 1.9821413024779289

Epoch: 6| Step: 2
Training loss: 2.225795269012451
Validation loss: 1.9584717135275564

Epoch: 6| Step: 3
Training loss: 1.6983728408813477
Validation loss: 1.982808025934363

Epoch: 6| Step: 4
Training loss: 1.828112244606018
Validation loss: 1.9763224791455012

Epoch: 6| Step: 5
Training loss: 1.7305183410644531
Validation loss: 1.9984580957761375

Epoch: 6| Step: 6
Training loss: 2.2086071968078613
Validation loss: 1.9878559086912422

Epoch: 6| Step: 7
Training loss: 2.5903141498565674
Validation loss: 1.9894540079178349

Epoch: 6| Step: 8
Training loss: 2.2065086364746094
Validation loss: 1.979141350715391

Epoch: 6| Step: 9
Training loss: 1.6881844997406006
Validation loss: 1.98014441228682

Epoch: 6| Step: 10
Training loss: 1.645287275314331
Validation loss: 1.9791618649677565

Epoch: 6| Step: 11
Training loss: 1.8794565200805664
Validation loss: 2.023316244925222

Epoch: 6| Step: 12
Training loss: 2.0266661643981934
Validation loss: 1.9870209719545098

Epoch: 6| Step: 13
Training loss: 2.116971015930176
Validation loss: 1.9989088786545621

Epoch: 162| Step: 0
Training loss: 2.271554470062256
Validation loss: 1.9828919672196912

Epoch: 6| Step: 1
Training loss: 1.82485032081604
Validation loss: 1.9691858599262853

Epoch: 6| Step: 2
Training loss: 2.110628366470337
Validation loss: 1.96954696665528

Epoch: 6| Step: 3
Training loss: 1.9707841873168945
Validation loss: 1.9956340917976954

Epoch: 6| Step: 4
Training loss: 1.9189140796661377
Validation loss: 2.009870442011023

Epoch: 6| Step: 5
Training loss: 1.9758681058883667
Validation loss: 1.9521537314179123

Epoch: 6| Step: 6
Training loss: 2.1849358081817627
Validation loss: 1.980191473037966

Epoch: 6| Step: 7
Training loss: 0.909896731376648
Validation loss: 1.9727484551809167

Epoch: 6| Step: 8
Training loss: 2.356748104095459
Validation loss: 1.9646846094439108

Epoch: 6| Step: 9
Training loss: 1.953953504562378
Validation loss: 1.982614613348438

Epoch: 6| Step: 10
Training loss: 2.1155788898468018
Validation loss: 1.968575475036457

Epoch: 6| Step: 11
Training loss: 1.285461187362671
Validation loss: 1.9829806217583277

Epoch: 6| Step: 12
Training loss: 2.17368483543396
Validation loss: 1.9681332777905207

Epoch: 6| Step: 13
Training loss: 1.8901034593582153
Validation loss: 1.9509801941533242

Epoch: 163| Step: 0
Training loss: 2.758058547973633
Validation loss: 1.9494074236962102

Epoch: 6| Step: 1
Training loss: 1.190366268157959
Validation loss: 1.9564358290805612

Epoch: 6| Step: 2
Training loss: 1.9537525177001953
Validation loss: 1.947150480362677

Epoch: 6| Step: 3
Training loss: 2.1907403469085693
Validation loss: 1.9700296514777726

Epoch: 6| Step: 4
Training loss: 2.332442283630371
Validation loss: 1.966903450668499

Epoch: 6| Step: 5
Training loss: 1.800983190536499
Validation loss: 1.9445845542415496

Epoch: 6| Step: 6
Training loss: 1.6794872283935547
Validation loss: 1.9685528714169738

Epoch: 6| Step: 7
Training loss: 2.4336931705474854
Validation loss: 1.9683130812901322

Epoch: 6| Step: 8
Training loss: 1.801512360572815
Validation loss: 1.9608951230202951

Epoch: 6| Step: 9
Training loss: 1.1949610710144043
Validation loss: 1.9865791566910282

Epoch: 6| Step: 10
Training loss: 0.9939727783203125
Validation loss: 1.968577936131467

Epoch: 6| Step: 11
Training loss: 2.261868953704834
Validation loss: 2.012112740547426

Epoch: 6| Step: 12
Training loss: 2.349583625793457
Validation loss: 1.9901079939257713

Epoch: 6| Step: 13
Training loss: 1.671100378036499
Validation loss: 1.960841562158318

Epoch: 164| Step: 0
Training loss: 1.5575294494628906
Validation loss: 2.001358192454102

Epoch: 6| Step: 1
Training loss: 2.470000743865967
Validation loss: 1.9602563163285613

Epoch: 6| Step: 2
Training loss: 2.2626070976257324
Validation loss: 1.996748742236886

Epoch: 6| Step: 3
Training loss: 1.7984061241149902
Validation loss: 1.9819051732299149

Epoch: 6| Step: 4
Training loss: 1.9639827013015747
Validation loss: 1.965041091365199

Epoch: 6| Step: 5
Training loss: 1.1988494396209717
Validation loss: 1.978988637206375

Epoch: 6| Step: 6
Training loss: 1.964819073677063
Validation loss: 1.9712286867121214

Epoch: 6| Step: 7
Training loss: 1.9028434753417969
Validation loss: 1.9633759055086362

Epoch: 6| Step: 8
Training loss: 1.9015352725982666
Validation loss: 1.9458248371719031

Epoch: 6| Step: 9
Training loss: 1.592926025390625
Validation loss: 1.9715237925129552

Epoch: 6| Step: 10
Training loss: 2.2434022426605225
Validation loss: 1.9663820856360978

Epoch: 6| Step: 11
Training loss: 1.9139976501464844
Validation loss: 1.950139513579748

Epoch: 6| Step: 12
Training loss: 1.8364319801330566
Validation loss: 1.9392672969448952

Epoch: 6| Step: 13
Training loss: 1.5841386318206787
Validation loss: 1.924335664318454

Epoch: 165| Step: 0
Training loss: 1.9772112369537354
Validation loss: 1.971603101299655

Epoch: 6| Step: 1
Training loss: 2.2669854164123535
Validation loss: 1.953843629488381

Epoch: 6| Step: 2
Training loss: 2.372264862060547
Validation loss: 1.9398881209793912

Epoch: 6| Step: 3
Training loss: 1.8728036880493164
Validation loss: 1.95140750433809

Epoch: 6| Step: 4
Training loss: 2.6380550861358643
Validation loss: 1.9530141815062492

Epoch: 6| Step: 5
Training loss: 1.6004785299301147
Validation loss: 1.9415026300696916

Epoch: 6| Step: 6
Training loss: 1.4878219366073608
Validation loss: 1.938459155380085

Epoch: 6| Step: 7
Training loss: 1.5630457401275635
Validation loss: 1.9339554976391535

Epoch: 6| Step: 8
Training loss: 1.9188673496246338
Validation loss: 1.9428356642364173

Epoch: 6| Step: 9
Training loss: 1.5598081350326538
Validation loss: 1.9576274195025045

Epoch: 6| Step: 10
Training loss: 2.066305160522461
Validation loss: 1.9221121098405571

Epoch: 6| Step: 11
Training loss: 2.147318124771118
Validation loss: 1.9590580232681767

Epoch: 6| Step: 12
Training loss: 1.6136226654052734
Validation loss: 1.9406649848466277

Epoch: 6| Step: 13
Training loss: 1.2380151748657227
Validation loss: 1.9588865926188808

Epoch: 166| Step: 0
Training loss: 2.967515230178833
Validation loss: 1.9472029875683528

Epoch: 6| Step: 1
Training loss: 1.9964394569396973
Validation loss: 1.9407440590602096

Epoch: 6| Step: 2
Training loss: 2.245753049850464
Validation loss: 1.9448363140065184

Epoch: 6| Step: 3
Training loss: 1.5343945026397705
Validation loss: 1.9680300861276605

Epoch: 6| Step: 4
Training loss: 1.501983642578125
Validation loss: 1.9436154775722052

Epoch: 6| Step: 5
Training loss: 1.6536674499511719
Validation loss: 1.9630035841336815

Epoch: 6| Step: 6
Training loss: 1.538977861404419
Validation loss: 1.979520619556468

Epoch: 6| Step: 7
Training loss: 1.597848653793335
Validation loss: 1.982067975946652

Epoch: 6| Step: 8
Training loss: 1.7482972145080566
Validation loss: 1.9767602900023102

Epoch: 6| Step: 9
Training loss: 2.3152079582214355
Validation loss: 1.954977411095814

Epoch: 6| Step: 10
Training loss: 1.953326940536499
Validation loss: 1.9653740467563752

Epoch: 6| Step: 11
Training loss: 2.0298798084259033
Validation loss: 1.9507322131946523

Epoch: 6| Step: 12
Training loss: 1.6331270933151245
Validation loss: 1.9596897555935768

Epoch: 6| Step: 13
Training loss: 1.9743502140045166
Validation loss: 1.961946678417985

Epoch: 167| Step: 0
Training loss: 1.4677120447158813
Validation loss: 1.9767687013072353

Epoch: 6| Step: 1
Training loss: 1.588608980178833
Validation loss: 1.940278583957303

Epoch: 6| Step: 2
Training loss: 1.5386641025543213
Validation loss: 1.9599973668334305

Epoch: 6| Step: 3
Training loss: 2.0158495903015137
Validation loss: 1.9388657167393675

Epoch: 6| Step: 4
Training loss: 1.7987884283065796
Validation loss: 1.9128637083115116

Epoch: 6| Step: 5
Training loss: 2.504836082458496
Validation loss: 1.9682070619316512

Epoch: 6| Step: 6
Training loss: 2.2579922676086426
Validation loss: 1.9202123995750182

Epoch: 6| Step: 7
Training loss: 2.418656826019287
Validation loss: 1.9449405259983514

Epoch: 6| Step: 8
Training loss: 1.5896329879760742
Validation loss: 1.948315271767237

Epoch: 6| Step: 9
Training loss: 1.8113398551940918
Validation loss: 1.9530616665399203

Epoch: 6| Step: 10
Training loss: 2.0075736045837402
Validation loss: 1.957647322326578

Epoch: 6| Step: 11
Training loss: 2.361041307449341
Validation loss: 1.9452454889974287

Epoch: 6| Step: 12
Training loss: 1.4096834659576416
Validation loss: 1.9091552124228528

Epoch: 6| Step: 13
Training loss: 1.8437418937683105
Validation loss: 1.94841339254892

Epoch: 168| Step: 0
Training loss: 1.7984707355499268
Validation loss: 1.925858816792888

Epoch: 6| Step: 1
Training loss: 1.179478406906128
Validation loss: 1.9363068803664176

Epoch: 6| Step: 2
Training loss: 1.8722338676452637
Validation loss: 1.9589792887369792

Epoch: 6| Step: 3
Training loss: 2.0381693840026855
Validation loss: 1.9511711751261065

Epoch: 6| Step: 4
Training loss: 1.8876261711120605
Validation loss: 1.9815118633290774

Epoch: 6| Step: 5
Training loss: 2.1863186359405518
Validation loss: 1.9494056419659687

Epoch: 6| Step: 6
Training loss: 1.8263506889343262
Validation loss: 1.9557369857706048

Epoch: 6| Step: 7
Training loss: 2.134939193725586
Validation loss: 1.9523831798184303

Epoch: 6| Step: 8
Training loss: 1.4529818296432495
Validation loss: 2.013670729052636

Epoch: 6| Step: 9
Training loss: 2.1719701290130615
Validation loss: 1.9980939767693962

Epoch: 6| Step: 10
Training loss: 1.4968737363815308
Validation loss: 2.0034810420005553

Epoch: 6| Step: 11
Training loss: 2.081634998321533
Validation loss: 2.019186650553057

Epoch: 6| Step: 12
Training loss: 1.8987157344818115
Validation loss: 1.9959149540111583

Epoch: 6| Step: 13
Training loss: 3.187504768371582
Validation loss: 1.9784890349193285

Epoch: 169| Step: 0
Training loss: 1.745971441268921
Validation loss: 1.9739735844314739

Epoch: 6| Step: 1
Training loss: 1.889417052268982
Validation loss: 1.9838220380967664

Epoch: 6| Step: 2
Training loss: 2.3743786811828613
Validation loss: 1.9497596845831922

Epoch: 6| Step: 3
Training loss: 1.8435981273651123
Validation loss: 1.9639891475759528

Epoch: 6| Step: 4
Training loss: 1.8825544118881226
Validation loss: 1.9686945612712572

Epoch: 6| Step: 5
Training loss: 1.8851513862609863
Validation loss: 1.9457102988355903

Epoch: 6| Step: 6
Training loss: 1.4359359741210938
Validation loss: 1.9426062696723527

Epoch: 6| Step: 7
Training loss: 1.3273937702178955
Validation loss: 1.9530300273690173

Epoch: 6| Step: 8
Training loss: 1.6438713073730469
Validation loss: 1.961345112451943

Epoch: 6| Step: 9
Training loss: 1.9034570455551147
Validation loss: 1.9278079989135906

Epoch: 6| Step: 10
Training loss: 2.1905016899108887
Validation loss: 1.9722881701684767

Epoch: 6| Step: 11
Training loss: 2.071873664855957
Validation loss: 1.9355308727551532

Epoch: 6| Step: 12
Training loss: 1.5223069190979004
Validation loss: 1.9390094408424952

Epoch: 6| Step: 13
Training loss: 2.939318895339966
Validation loss: 1.9389970943491945

Epoch: 170| Step: 0
Training loss: 1.753597378730774
Validation loss: 1.9563081559314524

Epoch: 6| Step: 1
Training loss: 1.912278652191162
Validation loss: 1.9424425414813462

Epoch: 6| Step: 2
Training loss: 1.2125580310821533
Validation loss: 1.9383285148169405

Epoch: 6| Step: 3
Training loss: 1.9403867721557617
Validation loss: 1.9358210448295838

Epoch: 6| Step: 4
Training loss: 1.498923897743225
Validation loss: 1.9472814554809241

Epoch: 6| Step: 5
Training loss: 1.6021084785461426
Validation loss: 1.9255405792626001

Epoch: 6| Step: 6
Training loss: 2.398930072784424
Validation loss: 1.9044376419436546

Epoch: 6| Step: 7
Training loss: 1.9867559671401978
Validation loss: 1.9191256530823246

Epoch: 6| Step: 8
Training loss: 2.419287919998169
Validation loss: 1.920488275507445

Epoch: 6| Step: 9
Training loss: 2.0918993949890137
Validation loss: 1.920272134965466

Epoch: 6| Step: 10
Training loss: 1.6208996772766113
Validation loss: 1.967430196782594

Epoch: 6| Step: 11
Training loss: 2.257052421569824
Validation loss: 1.9428058119230374

Epoch: 6| Step: 12
Training loss: 1.9045674800872803
Validation loss: 1.9726063025894987

Epoch: 6| Step: 13
Training loss: 1.5463178157806396
Validation loss: 1.9608136095026487

Epoch: 171| Step: 0
Training loss: 1.5433616638183594
Validation loss: 1.950104635248902

Epoch: 6| Step: 1
Training loss: 1.4701874256134033
Validation loss: 1.9579057719117852

Epoch: 6| Step: 2
Training loss: 1.3527361154556274
Validation loss: 1.9546875825492285

Epoch: 6| Step: 3
Training loss: 1.6576204299926758
Validation loss: 1.958384988128498

Epoch: 6| Step: 4
Training loss: 1.608741044998169
Validation loss: 1.9412128668959423

Epoch: 6| Step: 5
Training loss: 2.771573781967163
Validation loss: 1.9312798835897957

Epoch: 6| Step: 6
Training loss: 2.6140716075897217
Validation loss: 1.9707903272362166

Epoch: 6| Step: 7
Training loss: 2.099750518798828
Validation loss: 1.9723802433219007

Epoch: 6| Step: 8
Training loss: 2.588092565536499
Validation loss: 1.937606365449967

Epoch: 6| Step: 9
Training loss: 1.1272828578948975
Validation loss: 1.9573982979661675

Epoch: 6| Step: 10
Training loss: 1.9386216402053833
Validation loss: 1.9246750941840551

Epoch: 6| Step: 11
Training loss: 1.8993221521377563
Validation loss: 1.932156596132504

Epoch: 6| Step: 12
Training loss: 1.7520310878753662
Validation loss: 1.94165664334451

Epoch: 6| Step: 13
Training loss: 1.4860692024230957
Validation loss: 1.952539574715399

Epoch: 172| Step: 0
Training loss: 1.3776971101760864
Validation loss: 1.8809154854025891

Epoch: 6| Step: 1
Training loss: 2.136495351791382
Validation loss: 1.9541669237998225

Epoch: 6| Step: 2
Training loss: 2.1145243644714355
Validation loss: 1.914526854791949

Epoch: 6| Step: 3
Training loss: 1.6664342880249023
Validation loss: 1.9544595249237553

Epoch: 6| Step: 4
Training loss: 1.8439037799835205
Validation loss: 1.9356373599780503

Epoch: 6| Step: 5
Training loss: 1.8014379739761353
Validation loss: 1.9376077203340427

Epoch: 6| Step: 6
Training loss: 1.7361907958984375
Validation loss: 1.9353768466621317

Epoch: 6| Step: 7
Training loss: 1.4847197532653809
Validation loss: 1.961796486249534

Epoch: 6| Step: 8
Training loss: 1.5068714618682861
Validation loss: 1.9494252397168068

Epoch: 6| Step: 9
Training loss: 2.2822115421295166
Validation loss: 1.9176173684417561

Epoch: 6| Step: 10
Training loss: 1.6964898109436035
Validation loss: 1.9306140663803264

Epoch: 6| Step: 11
Training loss: 1.9977285861968994
Validation loss: 1.944383321269866

Epoch: 6| Step: 12
Training loss: 2.319802761077881
Validation loss: 1.921350545780633

Epoch: 6| Step: 13
Training loss: 2.102236032485962
Validation loss: 1.9439691753797634

Epoch: 173| Step: 0
Training loss: 1.8319456577301025
Validation loss: 1.9285563038241478

Epoch: 6| Step: 1
Training loss: 1.5844008922576904
Validation loss: 1.9337841926082489

Epoch: 6| Step: 2
Training loss: 2.725621223449707
Validation loss: 1.9336994027578702

Epoch: 6| Step: 3
Training loss: 1.5541224479675293
Validation loss: 1.9290045307528587

Epoch: 6| Step: 4
Training loss: 1.368931531906128
Validation loss: 1.9450832874544206

Epoch: 6| Step: 5
Training loss: 1.0623153448104858
Validation loss: 1.9182296235074279

Epoch: 6| Step: 6
Training loss: 1.829788327217102
Validation loss: 1.924331239474717

Epoch: 6| Step: 7
Training loss: 2.2356362342834473
Validation loss: 1.8926096039433633

Epoch: 6| Step: 8
Training loss: 1.6364561319351196
Validation loss: 1.8938357009682605

Epoch: 6| Step: 9
Training loss: 2.628180503845215
Validation loss: 1.914842786327485

Epoch: 6| Step: 10
Training loss: 1.3191560506820679
Validation loss: 1.9423401958198958

Epoch: 6| Step: 11
Training loss: 2.685699939727783
Validation loss: 1.9216704958228654

Epoch: 6| Step: 12
Training loss: 1.4776875972747803
Validation loss: 1.9056175197324445

Epoch: 6| Step: 13
Training loss: 2.075934410095215
Validation loss: 1.9439435594825334

Epoch: 174| Step: 0
Training loss: 2.2773802280426025
Validation loss: 1.9277646272413191

Epoch: 6| Step: 1
Training loss: 1.4004302024841309
Validation loss: 1.92183256149292

Epoch: 6| Step: 2
Training loss: 1.9947636127471924
Validation loss: 1.9418124127131637

Epoch: 6| Step: 3
Training loss: 1.7553722858428955
Validation loss: 1.925693231244241

Epoch: 6| Step: 4
Training loss: 2.246446132659912
Validation loss: 1.943844319671713

Epoch: 6| Step: 5
Training loss: 1.0545339584350586
Validation loss: 1.9257297054413827

Epoch: 6| Step: 6
Training loss: 2.0554981231689453
Validation loss: 1.9653355331831082

Epoch: 6| Step: 7
Training loss: 2.0013155937194824
Validation loss: 1.9551343046208864

Epoch: 6| Step: 8
Training loss: 1.9126054048538208
Validation loss: 1.9325590479758479

Epoch: 6| Step: 9
Training loss: 2.018169641494751
Validation loss: 1.949095783695098

Epoch: 6| Step: 10
Training loss: 2.2929630279541016
Validation loss: 1.9550272162242601

Epoch: 6| Step: 11
Training loss: 1.5503334999084473
Validation loss: 1.9359337309355378

Epoch: 6| Step: 12
Training loss: 1.493178129196167
Validation loss: 1.9466573320409304

Epoch: 6| Step: 13
Training loss: 2.1542649269104004
Validation loss: 1.9516721066608225

Epoch: 175| Step: 0
Training loss: 2.1768641471862793
Validation loss: 1.9472290290299283

Epoch: 6| Step: 1
Training loss: 1.0505048036575317
Validation loss: 1.9170748559377526

Epoch: 6| Step: 2
Training loss: 2.196697950363159
Validation loss: 1.9482529752997941

Epoch: 6| Step: 3
Training loss: 2.040050983428955
Validation loss: 1.9306079828610985

Epoch: 6| Step: 4
Training loss: 1.7109899520874023
Validation loss: 1.962023663264449

Epoch: 6| Step: 5
Training loss: 1.9411859512329102
Validation loss: 1.9755243793610604

Epoch: 6| Step: 6
Training loss: 1.6606783866882324
Validation loss: 1.9555941743235434

Epoch: 6| Step: 7
Training loss: 2.2740797996520996
Validation loss: 1.9545705113359677

Epoch: 6| Step: 8
Training loss: 1.5578429698944092
Validation loss: 1.9190591842897478

Epoch: 6| Step: 9
Training loss: 1.8376470804214478
Validation loss: 1.936457921099919

Epoch: 6| Step: 10
Training loss: 2.0389344692230225
Validation loss: 1.9340720484333653

Epoch: 6| Step: 11
Training loss: 1.434757947921753
Validation loss: 1.9305157046164236

Epoch: 6| Step: 12
Training loss: 1.9030119180679321
Validation loss: 1.9318744649169266

Epoch: 6| Step: 13
Training loss: 2.059717893600464
Validation loss: 1.92345170820913

Epoch: 176| Step: 0
Training loss: 1.9261738061904907
Validation loss: 1.9139878083300847

Epoch: 6| Step: 1
Training loss: 2.2610068321228027
Validation loss: 1.9428292782075944

Epoch: 6| Step: 2
Training loss: 1.9316960573196411
Validation loss: 1.9097649564025223

Epoch: 6| Step: 3
Training loss: 1.1541938781738281
Validation loss: 1.920317510122894

Epoch: 6| Step: 4
Training loss: 1.9668328762054443
Validation loss: 1.9126263549250941

Epoch: 6| Step: 5
Training loss: 1.9653069972991943
Validation loss: 1.9304434471232916

Epoch: 6| Step: 6
Training loss: 1.7180163860321045
Validation loss: 1.9046238160902453

Epoch: 6| Step: 7
Training loss: 1.347954273223877
Validation loss: 1.9151624505237868

Epoch: 6| Step: 8
Training loss: 1.3687841892242432
Validation loss: 1.9327025746786466

Epoch: 6| Step: 9
Training loss: 2.098348617553711
Validation loss: 1.9222845774824902

Epoch: 6| Step: 10
Training loss: 2.204411506652832
Validation loss: 1.9333974430637975

Epoch: 6| Step: 11
Training loss: 1.7940988540649414
Validation loss: 1.927569309870402

Epoch: 6| Step: 12
Training loss: 2.4254841804504395
Validation loss: 1.908103181469825

Epoch: 6| Step: 13
Training loss: 1.970467448234558
Validation loss: 1.9253458130744197

Epoch: 177| Step: 0
Training loss: 1.3578193187713623
Validation loss: 1.9155902324184295

Epoch: 6| Step: 1
Training loss: 2.320162296295166
Validation loss: 1.9284936381924538

Epoch: 6| Step: 2
Training loss: 1.6171538829803467
Validation loss: 1.8833335881592126

Epoch: 6| Step: 3
Training loss: 2.3932955265045166
Validation loss: 1.936401710715345

Epoch: 6| Step: 4
Training loss: 1.1669590473175049
Validation loss: 1.9253071008190032

Epoch: 6| Step: 5
Training loss: 2.2657318115234375
Validation loss: 1.9153676174020255

Epoch: 6| Step: 6
Training loss: 1.9235284328460693
Validation loss: 1.9323387556178595

Epoch: 6| Step: 7
Training loss: 1.8664968013763428
Validation loss: 1.94270920753479

Epoch: 6| Step: 8
Training loss: 1.3439395427703857
Validation loss: 1.9128475253300001

Epoch: 6| Step: 9
Training loss: 2.1320056915283203
Validation loss: 1.943584265247468

Epoch: 6| Step: 10
Training loss: 1.6046013832092285
Validation loss: 1.9591201607899

Epoch: 6| Step: 11
Training loss: 2.21846866607666
Validation loss: 1.9599709126257128

Epoch: 6| Step: 12
Training loss: 1.8794033527374268
Validation loss: 1.9400948965421287

Epoch: 6| Step: 13
Training loss: 1.5500422716140747
Validation loss: 1.9091390999414588

Epoch: 178| Step: 0
Training loss: 1.9197070598602295
Validation loss: 1.9488851049894929

Epoch: 6| Step: 1
Training loss: 1.629370093345642
Validation loss: 1.9422780300981255

Epoch: 6| Step: 2
Training loss: 2.0772812366485596
Validation loss: 1.944150036381137

Epoch: 6| Step: 3
Training loss: 1.6133532524108887
Validation loss: 1.9394854268720072

Epoch: 6| Step: 4
Training loss: 1.9246854782104492
Validation loss: 1.9640027297440397

Epoch: 6| Step: 5
Training loss: 1.9490821361541748
Validation loss: 1.9449334977775492

Epoch: 6| Step: 6
Training loss: 1.854203224182129
Validation loss: 1.8964187432360906

Epoch: 6| Step: 7
Training loss: 1.5398459434509277
Validation loss: 1.9376071986331735

Epoch: 6| Step: 8
Training loss: 1.743029236793518
Validation loss: 1.9253757333242765

Epoch: 6| Step: 9
Training loss: 1.813708782196045
Validation loss: 1.9241817766620266

Epoch: 6| Step: 10
Training loss: 2.1010591983795166
Validation loss: 1.9563189809040358

Epoch: 6| Step: 11
Training loss: 1.839728832244873
Validation loss: 1.8938602888455955

Epoch: 6| Step: 12
Training loss: 1.9030689001083374
Validation loss: 1.9097638963371195

Epoch: 6| Step: 13
Training loss: 2.0492541790008545
Validation loss: 1.907194468282884

Epoch: 179| Step: 0
Training loss: 2.322756052017212
Validation loss: 1.9057471508620887

Epoch: 6| Step: 1
Training loss: 0.913617730140686
Validation loss: 1.9509192858972857

Epoch: 6| Step: 2
Training loss: 2.60955548286438
Validation loss: 1.895385544787171

Epoch: 6| Step: 3
Training loss: 2.093438148498535
Validation loss: 1.9074543535068471

Epoch: 6| Step: 4
Training loss: 1.7199758291244507
Validation loss: 1.9423268020793956

Epoch: 6| Step: 5
Training loss: 2.057406425476074
Validation loss: 1.9254781943495556

Epoch: 6| Step: 6
Training loss: 1.765592098236084
Validation loss: 1.9100988270134054

Epoch: 6| Step: 7
Training loss: 2.1460375785827637
Validation loss: 1.9496441105360627

Epoch: 6| Step: 8
Training loss: 1.724913477897644
Validation loss: 1.935819149017334

Epoch: 6| Step: 9
Training loss: 1.6705536842346191
Validation loss: 1.933977867967339

Epoch: 6| Step: 10
Training loss: 1.6488232612609863
Validation loss: 1.949117673340664

Epoch: 6| Step: 11
Training loss: 1.8652656078338623
Validation loss: 1.9595399620712444

Epoch: 6| Step: 12
Training loss: 1.2000902891159058
Validation loss: 1.951048299830447

Epoch: 6| Step: 13
Training loss: 2.4084291458129883
Validation loss: 1.93371001110282

Epoch: 180| Step: 0
Training loss: 2.185098171234131
Validation loss: 1.9319154780398133

Epoch: 6| Step: 1
Training loss: 2.109858512878418
Validation loss: 1.9214203178241689

Epoch: 6| Step: 2
Training loss: 1.4105079174041748
Validation loss: 1.9350649131241666

Epoch: 6| Step: 3
Training loss: 1.7823882102966309
Validation loss: 1.913562213220904

Epoch: 6| Step: 4
Training loss: 2.1401021480560303
Validation loss: 1.9468233457175634

Epoch: 6| Step: 5
Training loss: 1.6230641603469849
Validation loss: 1.9187076322494014

Epoch: 6| Step: 6
Training loss: 1.5597434043884277
Validation loss: 1.916000763575236

Epoch: 6| Step: 7
Training loss: 1.674842119216919
Validation loss: 1.941747865369243

Epoch: 6| Step: 8
Training loss: 1.642747402191162
Validation loss: 1.8990928037192232

Epoch: 6| Step: 9
Training loss: 1.311084270477295
Validation loss: 1.9053315577968475

Epoch: 6| Step: 10
Training loss: 1.9466116428375244
Validation loss: 1.8905110410464707

Epoch: 6| Step: 11
Training loss: 2.0767006874084473
Validation loss: 1.9448923846726776

Epoch: 6| Step: 12
Training loss: 2.5089735984802246
Validation loss: 1.8991040055469801

Epoch: 6| Step: 13
Training loss: 2.1401517391204834
Validation loss: 1.9419151839389597

Epoch: 181| Step: 0
Training loss: 2.0202698707580566
Validation loss: 1.936411621750042

Epoch: 6| Step: 1
Training loss: 1.8985246419906616
Validation loss: 1.9286545809879099

Epoch: 6| Step: 2
Training loss: 2.4208736419677734
Validation loss: 1.9780707692587247

Epoch: 6| Step: 3
Training loss: 1.6537961959838867
Validation loss: 1.9860913317690614

Epoch: 6| Step: 4
Training loss: 2.0990793704986572
Validation loss: 1.9382451606053177

Epoch: 6| Step: 5
Training loss: 1.484535813331604
Validation loss: 1.9345055036647345

Epoch: 6| Step: 6
Training loss: 2.21867036819458
Validation loss: 1.9527879171474005

Epoch: 6| Step: 7
Training loss: 2.5955159664154053
Validation loss: 1.9449240392254246

Epoch: 6| Step: 8
Training loss: 1.198230266571045
Validation loss: 1.9560091521150322

Epoch: 6| Step: 9
Training loss: 1.523119568824768
Validation loss: 1.950030767789451

Epoch: 6| Step: 10
Training loss: 1.6607999801635742
Validation loss: 1.962428089111082

Epoch: 6| Step: 11
Training loss: 1.529428243637085
Validation loss: 1.9432833630551574

Epoch: 6| Step: 12
Training loss: 1.321298360824585
Validation loss: 1.9563921266986477

Epoch: 6| Step: 13
Training loss: 1.4658355712890625
Validation loss: 1.9629279528894732

Epoch: 182| Step: 0
Training loss: 2.0375888347625732
Validation loss: 1.930502845394996

Epoch: 6| Step: 1
Training loss: 1.1766306161880493
Validation loss: 1.9313480046487623

Epoch: 6| Step: 2
Training loss: 1.1233928203582764
Validation loss: 1.948167747066867

Epoch: 6| Step: 3
Training loss: 1.3841900825500488
Validation loss: 1.8934105519325501

Epoch: 6| Step: 4
Training loss: 1.842990756034851
Validation loss: 1.9145334869302728

Epoch: 6| Step: 5
Training loss: 2.6316874027252197
Validation loss: 1.9033623895337504

Epoch: 6| Step: 6
Training loss: 2.4051082134246826
Validation loss: 1.888599238088054

Epoch: 6| Step: 7
Training loss: 1.7247651815414429
Validation loss: 1.9098648191780172

Epoch: 6| Step: 8
Training loss: 2.3765642642974854
Validation loss: 1.921045627645267

Epoch: 6| Step: 9
Training loss: 2.2753047943115234
Validation loss: 1.9223950755211614

Epoch: 6| Step: 10
Training loss: 1.5633437633514404
Validation loss: 1.9185866950660624

Epoch: 6| Step: 11
Training loss: 1.2611041069030762
Validation loss: 1.9098717538259362

Epoch: 6| Step: 12
Training loss: 1.5465734004974365
Validation loss: 1.899113675599457

Epoch: 6| Step: 13
Training loss: 2.2692909240722656
Validation loss: 1.933930435488301

Epoch: 183| Step: 0
Training loss: 1.7346619367599487
Validation loss: 1.946757137134511

Epoch: 6| Step: 1
Training loss: 1.552534580230713
Validation loss: 1.9085147444919874

Epoch: 6| Step: 2
Training loss: 1.7206814289093018
Validation loss: 1.9504089996378908

Epoch: 6| Step: 3
Training loss: 1.9092552661895752
Validation loss: 1.9168914723139938

Epoch: 6| Step: 4
Training loss: 1.5220487117767334
Validation loss: 1.9197872723302534

Epoch: 6| Step: 5
Training loss: 1.9244146347045898
Validation loss: 1.9277669896361649

Epoch: 6| Step: 6
Training loss: 1.7455854415893555
Validation loss: 1.928031135630864

Epoch: 6| Step: 7
Training loss: 2.2757909297943115
Validation loss: 1.9430863600905224

Epoch: 6| Step: 8
Training loss: 1.1505008935928345
Validation loss: 1.9043635219656012

Epoch: 6| Step: 9
Training loss: 1.5084161758422852
Validation loss: 1.9205597075082923

Epoch: 6| Step: 10
Training loss: 2.5202736854553223
Validation loss: 1.8944429274528258

Epoch: 6| Step: 11
Training loss: 1.6262181997299194
Validation loss: 1.8818098473292526

Epoch: 6| Step: 12
Training loss: 1.6398863792419434
Validation loss: 1.9165926248796525

Epoch: 6| Step: 13
Training loss: 3.3051717281341553
Validation loss: 1.884051771574123

Epoch: 184| Step: 0
Training loss: 1.7421886920928955
Validation loss: 1.921711556373104

Epoch: 6| Step: 1
Training loss: 1.8272947072982788
Validation loss: 1.9733227222196517

Epoch: 6| Step: 2
Training loss: 1.9696853160858154
Validation loss: 1.9370083398716424

Epoch: 6| Step: 3
Training loss: 1.9653899669647217
Validation loss: 1.946244228270746

Epoch: 6| Step: 4
Training loss: 1.4330065250396729
Validation loss: 1.926118290552529

Epoch: 6| Step: 5
Training loss: 1.354982852935791
Validation loss: 1.9468482976318688

Epoch: 6| Step: 6
Training loss: 1.5247116088867188
Validation loss: 1.988470579988213

Epoch: 6| Step: 7
Training loss: 2.3239388465881348
Validation loss: 1.960996611143953

Epoch: 6| Step: 8
Training loss: 2.52565860748291
Validation loss: 1.951846335523872

Epoch: 6| Step: 9
Training loss: 1.3989992141723633
Validation loss: 1.9445421170162898

Epoch: 6| Step: 10
Training loss: 2.011411190032959
Validation loss: 1.9434106785763976

Epoch: 6| Step: 11
Training loss: 1.9222767353057861
Validation loss: 1.932396669541636

Epoch: 6| Step: 12
Training loss: 2.368199586868286
Validation loss: 1.9287479385252921

Epoch: 6| Step: 13
Training loss: 0.9393141269683838
Validation loss: 1.9213768256607877

Epoch: 185| Step: 0
Training loss: 2.371741771697998
Validation loss: 1.935108241214547

Epoch: 6| Step: 1
Training loss: 1.7132978439331055
Validation loss: 1.946712733596884

Epoch: 6| Step: 2
Training loss: 1.989863395690918
Validation loss: 1.9459446450715423

Epoch: 6| Step: 3
Training loss: 2.313490390777588
Validation loss: 1.9073052431947441

Epoch: 6| Step: 4
Training loss: 1.4611129760742188
Validation loss: 1.9195501317260086

Epoch: 6| Step: 5
Training loss: 1.6159132719039917
Validation loss: 1.9534216311670118

Epoch: 6| Step: 6
Training loss: 2.1863396167755127
Validation loss: 1.942428813185743

Epoch: 6| Step: 7
Training loss: 1.7079986333847046
Validation loss: 1.9015832972782913

Epoch: 6| Step: 8
Training loss: 1.5736868381500244
Validation loss: 1.8927841468523907

Epoch: 6| Step: 9
Training loss: 1.5208280086517334
Validation loss: 1.9103534606195265

Epoch: 6| Step: 10
Training loss: 1.7873992919921875
Validation loss: 1.9294973496467835

Epoch: 6| Step: 11
Training loss: 1.5568904876708984
Validation loss: 1.9230621707054876

Epoch: 6| Step: 12
Training loss: 1.8432986736297607
Validation loss: 1.9198325244329308

Epoch: 6| Step: 13
Training loss: 1.5749784708023071
Validation loss: 1.9283279911164315

Epoch: 186| Step: 0
Training loss: 1.5808701515197754
Validation loss: 1.8955093929844518

Epoch: 6| Step: 1
Training loss: 1.766913890838623
Validation loss: 1.9075826547479118

Epoch: 6| Step: 2
Training loss: 1.9072898626327515
Validation loss: 1.89986434290486

Epoch: 6| Step: 3
Training loss: 1.9058080911636353
Validation loss: 1.895542085811656

Epoch: 6| Step: 4
Training loss: 2.2318782806396484
Validation loss: 1.9134931077239334

Epoch: 6| Step: 5
Training loss: 2.066556692123413
Validation loss: 1.924177400527462

Epoch: 6| Step: 6
Training loss: 2.377260208129883
Validation loss: 1.8956827630278885

Epoch: 6| Step: 7
Training loss: 1.1164995431900024
Validation loss: 1.9015624484708231

Epoch: 6| Step: 8
Training loss: 2.067844867706299
Validation loss: 1.9317489285622873

Epoch: 6| Step: 9
Training loss: 1.7214889526367188
Validation loss: 1.9363060330831876

Epoch: 6| Step: 10
Training loss: 1.8630762100219727
Validation loss: 1.9259419877042052

Epoch: 6| Step: 11
Training loss: 1.7084152698516846
Validation loss: 1.9163308028251893

Epoch: 6| Step: 12
Training loss: 1.4202120304107666
Validation loss: 1.9339117914117792

Epoch: 6| Step: 13
Training loss: 1.6931326389312744
Validation loss: 1.911588704714211

Epoch: 187| Step: 0
Training loss: 1.599965214729309
Validation loss: 1.9239173089304278

Epoch: 6| Step: 1
Training loss: 2.8292016983032227
Validation loss: 1.9149373628759896

Epoch: 6| Step: 2
Training loss: 1.3391432762145996
Validation loss: 1.9414092020321918

Epoch: 6| Step: 3
Training loss: 1.590301275253296
Validation loss: 1.9100404964980258

Epoch: 6| Step: 4
Training loss: 1.2604477405548096
Validation loss: 1.9245098098631828

Epoch: 6| Step: 5
Training loss: 1.7188539505004883
Validation loss: 1.9542276474737352

Epoch: 6| Step: 6
Training loss: 1.7072534561157227
Validation loss: 1.9648457381033129

Epoch: 6| Step: 7
Training loss: 1.4939024448394775
Validation loss: 1.9234423316935056

Epoch: 6| Step: 8
Training loss: 2.16782808303833
Validation loss: 1.9255889820796188

Epoch: 6| Step: 9
Training loss: 1.6855219602584839
Validation loss: 1.9424545265013171

Epoch: 6| Step: 10
Training loss: 2.041667938232422
Validation loss: 1.8983382640346405

Epoch: 6| Step: 11
Training loss: 1.9349285364151
Validation loss: 1.9195143484300183

Epoch: 6| Step: 12
Training loss: 1.9462242126464844
Validation loss: 1.9288656929487824

Epoch: 6| Step: 13
Training loss: 1.964345932006836
Validation loss: 1.939670096161545

Epoch: 188| Step: 0
Training loss: 1.9615333080291748
Validation loss: 1.962666642281317

Epoch: 6| Step: 1
Training loss: 2.0029900074005127
Validation loss: 1.9124463937615837

Epoch: 6| Step: 2
Training loss: 1.4810727834701538
Validation loss: 1.9346216711946713

Epoch: 6| Step: 3
Training loss: 1.737419843673706
Validation loss: 1.8704006492450673

Epoch: 6| Step: 4
Training loss: 2.117337226867676
Validation loss: 1.9292610678621518

Epoch: 6| Step: 5
Training loss: 1.840815782546997
Validation loss: 1.936839202398895

Epoch: 6| Step: 6
Training loss: 1.3980662822723389
Validation loss: 1.9368665115807646

Epoch: 6| Step: 7
Training loss: 1.8856165409088135
Validation loss: 1.939902505566997

Epoch: 6| Step: 8
Training loss: 1.6125974655151367
Validation loss: 1.906005237692146

Epoch: 6| Step: 9
Training loss: 1.6795220375061035
Validation loss: 1.9319522867920578

Epoch: 6| Step: 10
Training loss: 1.692765235900879
Validation loss: 1.9495989379062448

Epoch: 6| Step: 11
Training loss: 2.1102025508880615
Validation loss: 1.9335057209896784

Epoch: 6| Step: 12
Training loss: 2.4653871059417725
Validation loss: 1.9574709476963166

Epoch: 6| Step: 13
Training loss: 1.2462913990020752
Validation loss: 1.9287528337970856

Epoch: 189| Step: 0
Training loss: 2.2441611289978027
Validation loss: 1.9497789439334665

Epoch: 6| Step: 1
Training loss: 1.336266279220581
Validation loss: 1.9251515865325928

Epoch: 6| Step: 2
Training loss: 1.112072229385376
Validation loss: 1.8946521487287296

Epoch: 6| Step: 3
Training loss: 1.7199195623397827
Validation loss: 1.942940019792126

Epoch: 6| Step: 4
Training loss: 1.9559173583984375
Validation loss: 1.912791020126753

Epoch: 6| Step: 5
Training loss: 2.0492541790008545
Validation loss: 1.949757952843943

Epoch: 6| Step: 6
Training loss: 2.7649986743927
Validation loss: 1.9140396336073517

Epoch: 6| Step: 7
Training loss: 1.8119549751281738
Validation loss: 1.9210314814762404

Epoch: 6| Step: 8
Training loss: 1.2308146953582764
Validation loss: 1.9119917731131277

Epoch: 6| Step: 9
Training loss: 1.4099595546722412
Validation loss: 1.9244188044660835

Epoch: 6| Step: 10
Training loss: 2.1731433868408203
Validation loss: 1.9126064200555124

Epoch: 6| Step: 11
Training loss: 2.2842824459075928
Validation loss: 1.892740309879344

Epoch: 6| Step: 12
Training loss: 1.230314016342163
Validation loss: 1.91656244057481

Epoch: 6| Step: 13
Training loss: 2.1064701080322266
Validation loss: 1.89849841466514

Epoch: 190| Step: 0
Training loss: 1.6242892742156982
Validation loss: 1.946052606387805

Epoch: 6| Step: 1
Training loss: 1.4846556186676025
Validation loss: 1.9202012477382537

Epoch: 6| Step: 2
Training loss: 1.7873344421386719
Validation loss: 1.9075184534954768

Epoch: 6| Step: 3
Training loss: 1.8796250820159912
Validation loss: 1.9096595958996845

Epoch: 6| Step: 4
Training loss: 1.4228096008300781
Validation loss: 1.9055892562353483

Epoch: 6| Step: 5
Training loss: 2.1320676803588867
Validation loss: 1.8956798584230485

Epoch: 6| Step: 6
Training loss: 2.028243064880371
Validation loss: 1.8739564341883506

Epoch: 6| Step: 7
Training loss: 1.829916000366211
Validation loss: 1.901157207386468

Epoch: 6| Step: 8
Training loss: 2.196199893951416
Validation loss: 1.9202443463827974

Epoch: 6| Step: 9
Training loss: 1.6047377586364746
Validation loss: 1.886812142146531

Epoch: 6| Step: 10
Training loss: 1.7325832843780518
Validation loss: 1.9015099592106317

Epoch: 6| Step: 11
Training loss: 2.5633175373077393
Validation loss: 1.916152351646013

Epoch: 6| Step: 12
Training loss: 1.1004611253738403
Validation loss: 1.9490723533015097

Epoch: 6| Step: 13
Training loss: 1.744981288909912
Validation loss: 1.9424592602637507

Epoch: 191| Step: 0
Training loss: 1.926162600517273
Validation loss: 1.9155927012043614

Epoch: 6| Step: 1
Training loss: 1.0163702964782715
Validation loss: 1.909120846820134

Epoch: 6| Step: 2
Training loss: 1.7942609786987305
Validation loss: 1.9242701658638575

Epoch: 6| Step: 3
Training loss: 1.3470467329025269
Validation loss: 1.932075168496819

Epoch: 6| Step: 4
Training loss: 2.005990982055664
Validation loss: 1.9310665681797972

Epoch: 6| Step: 5
Training loss: 1.6093567609786987
Validation loss: 1.941797749970549

Epoch: 6| Step: 6
Training loss: 2.194136142730713
Validation loss: 1.9161823026595577

Epoch: 6| Step: 7
Training loss: 1.6565892696380615
Validation loss: 1.926804611759801

Epoch: 6| Step: 8
Training loss: 2.0810954570770264
Validation loss: 1.912676126726212

Epoch: 6| Step: 9
Training loss: 2.0812840461730957
Validation loss: 1.9409310945900538

Epoch: 6| Step: 10
Training loss: 1.9839504957199097
Validation loss: 1.9180183231189687

Epoch: 6| Step: 11
Training loss: 1.5742727518081665
Validation loss: 1.9257625533688454

Epoch: 6| Step: 12
Training loss: 1.962828516960144
Validation loss: 1.9064946584804083

Epoch: 6| Step: 13
Training loss: 2.147719144821167
Validation loss: 1.9574704888046428

Epoch: 192| Step: 0
Training loss: 1.9697468280792236
Validation loss: 1.9183967216040498

Epoch: 6| Step: 1
Training loss: 1.7189284563064575
Validation loss: 1.970653969754455

Epoch: 6| Step: 2
Training loss: 2.6297054290771484
Validation loss: 1.9496326420896797

Epoch: 6| Step: 3
Training loss: 1.1817331314086914
Validation loss: 1.9456649954601

Epoch: 6| Step: 4
Training loss: 1.1422522068023682
Validation loss: 1.9443601241675756

Epoch: 6| Step: 5
Training loss: 2.048063278198242
Validation loss: 1.9349193239724765

Epoch: 6| Step: 6
Training loss: 1.832789421081543
Validation loss: 1.9732461385829474

Epoch: 6| Step: 7
Training loss: 1.4001470804214478
Validation loss: 1.952910432251551

Epoch: 6| Step: 8
Training loss: 1.7881488800048828
Validation loss: 1.9794154013356855

Epoch: 6| Step: 9
Training loss: 2.079345226287842
Validation loss: 1.9658267421107138

Epoch: 6| Step: 10
Training loss: 2.0158426761627197
Validation loss: 1.946000232491442

Epoch: 6| Step: 11
Training loss: 1.5302226543426514
Validation loss: 1.9734014823872557

Epoch: 6| Step: 12
Training loss: 2.0886611938476562
Validation loss: 1.9257248447787376

Epoch: 6| Step: 13
Training loss: 1.3681920766830444
Validation loss: 1.9591940115856867

Epoch: 193| Step: 0
Training loss: 1.8262861967086792
Validation loss: 1.9490937520098943

Epoch: 6| Step: 1
Training loss: 1.6188323497772217
Validation loss: 1.9454983601006128

Epoch: 6| Step: 2
Training loss: 2.175581932067871
Validation loss: 1.9184682433323195

Epoch: 6| Step: 3
Training loss: 2.5297536849975586
Validation loss: 1.9329479022692608

Epoch: 6| Step: 4
Training loss: 1.2579251527786255
Validation loss: 1.9272275022281113

Epoch: 6| Step: 5
Training loss: 1.4592740535736084
Validation loss: 1.8856538188072942

Epoch: 6| Step: 6
Training loss: 1.067446231842041
Validation loss: 1.8975386568295058

Epoch: 6| Step: 7
Training loss: 2.214169502258301
Validation loss: 1.9066225828662995

Epoch: 6| Step: 8
Training loss: 1.6156389713287354
Validation loss: 1.8781739434888285

Epoch: 6| Step: 9
Training loss: 1.779915690422058
Validation loss: 1.9168954100660098

Epoch: 6| Step: 10
Training loss: 2.103825092315674
Validation loss: 1.9522965941377866

Epoch: 6| Step: 11
Training loss: 1.9839450120925903
Validation loss: 1.8957173465400614

Epoch: 6| Step: 12
Training loss: 1.1610114574432373
Validation loss: 1.9133245586067118

Epoch: 6| Step: 13
Training loss: 2.3281819820404053
Validation loss: 1.9367882410685222

Epoch: 194| Step: 0
Training loss: 1.533419132232666
Validation loss: 1.94179186513347

Epoch: 6| Step: 1
Training loss: 2.035487413406372
Validation loss: 1.9389892880634596

Epoch: 6| Step: 2
Training loss: 1.6538794040679932
Validation loss: 1.9428583024650492

Epoch: 6| Step: 3
Training loss: 2.6785385608673096
Validation loss: 1.9309960667805006

Epoch: 6| Step: 4
Training loss: 1.8046095371246338
Validation loss: 1.9666608559188021

Epoch: 6| Step: 5
Training loss: 1.9807987213134766
Validation loss: 1.963915209616384

Epoch: 6| Step: 6
Training loss: 1.9894980192184448
Validation loss: 1.9704028790996921

Epoch: 6| Step: 7
Training loss: 1.5318806171417236
Validation loss: 1.9633693541249921

Epoch: 6| Step: 8
Training loss: 1.664206624031067
Validation loss: 1.9467217896574287

Epoch: 6| Step: 9
Training loss: 1.5229377746582031
Validation loss: 1.9556311997034217

Epoch: 6| Step: 10
Training loss: 1.7249047756195068
Validation loss: 1.9595887917344288

Epoch: 6| Step: 11
Training loss: 2.04335880279541
Validation loss: 1.938208859453919

Epoch: 6| Step: 12
Training loss: 1.0670424699783325
Validation loss: 1.9210228022708689

Epoch: 6| Step: 13
Training loss: 1.7342361211776733
Validation loss: 1.9112947089697725

Epoch: 195| Step: 0
Training loss: 1.4087023735046387
Validation loss: 1.9093396484210927

Epoch: 6| Step: 1
Training loss: 1.6669336557388306
Validation loss: 1.9443096242925173

Epoch: 6| Step: 2
Training loss: 2.0851025581359863
Validation loss: 1.9253018056192706

Epoch: 6| Step: 3
Training loss: 1.2792789936065674
Validation loss: 1.9068071457647509

Epoch: 6| Step: 4
Training loss: 1.2740983963012695
Validation loss: 1.8727361053548834

Epoch: 6| Step: 5
Training loss: 1.9552165269851685
Validation loss: 1.9002828892841135

Epoch: 6| Step: 6
Training loss: 2.3116908073425293
Validation loss: 1.8915086946179789

Epoch: 6| Step: 7
Training loss: 1.3923012018203735
Validation loss: 1.9069119781576178

Epoch: 6| Step: 8
Training loss: 2.021177291870117
Validation loss: 1.8864826245974469

Epoch: 6| Step: 9
Training loss: 2.1445417404174805
Validation loss: 1.890100348380304

Epoch: 6| Step: 10
Training loss: 1.135107398033142
Validation loss: 1.8912862218836302

Epoch: 6| Step: 11
Training loss: 1.7436091899871826
Validation loss: 1.889228597764046

Epoch: 6| Step: 12
Training loss: 2.181469440460205
Validation loss: 1.9110528230667114

Epoch: 6| Step: 13
Training loss: 2.59039306640625
Validation loss: 1.9149486544311687

Epoch: 196| Step: 0
Training loss: 1.780704379081726
Validation loss: 1.9171930679710962

Epoch: 6| Step: 1
Training loss: 1.3339691162109375
Validation loss: 1.9161260820204211

Epoch: 6| Step: 2
Training loss: 1.7464396953582764
Validation loss: 1.9293158054351807

Epoch: 6| Step: 3
Training loss: 1.966515064239502
Validation loss: 1.9253680808569795

Epoch: 6| Step: 4
Training loss: 1.8842421770095825
Validation loss: 1.951426439387824

Epoch: 6| Step: 5
Training loss: 1.3188565969467163
Validation loss: 1.9112487134113108

Epoch: 6| Step: 6
Training loss: 2.0444769859313965
Validation loss: 1.9224754174550374

Epoch: 6| Step: 7
Training loss: 2.0591158866882324
Validation loss: 1.9521357090242448

Epoch: 6| Step: 8
Training loss: 1.1558806896209717
Validation loss: 1.9411543928166872

Epoch: 6| Step: 9
Training loss: 1.9879261255264282
Validation loss: 1.9573804986092351

Epoch: 6| Step: 10
Training loss: 1.9687755107879639
Validation loss: 1.9634252107271584

Epoch: 6| Step: 11
Training loss: 2.0758516788482666
Validation loss: 1.9457830382931618

Epoch: 6| Step: 12
Training loss: 1.8945657014846802
Validation loss: 1.932609082550131

Epoch: 6| Step: 13
Training loss: 1.8386203050613403
Validation loss: 1.9565400820906445

Epoch: 197| Step: 0
Training loss: 1.2808220386505127
Validation loss: 1.9179495662771247

Epoch: 6| Step: 1
Training loss: 2.5007741451263428
Validation loss: 1.8859648807074434

Epoch: 6| Step: 2
Training loss: 1.3118741512298584
Validation loss: 1.9151268825736096

Epoch: 6| Step: 3
Training loss: 1.8160531520843506
Validation loss: 1.9068370685782483

Epoch: 6| Step: 4
Training loss: 1.8366838693618774
Validation loss: 1.896381611465126

Epoch: 6| Step: 5
Training loss: 1.4106051921844482
Validation loss: 1.9417875530899211

Epoch: 6| Step: 6
Training loss: 1.2916874885559082
Validation loss: 1.8760108281207342

Epoch: 6| Step: 7
Training loss: 1.7389090061187744
Validation loss: 1.8962949193933958

Epoch: 6| Step: 8
Training loss: 1.8931243419647217
Validation loss: 1.8631127829192786

Epoch: 6| Step: 9
Training loss: 1.9632792472839355
Validation loss: 1.9025999422996276

Epoch: 6| Step: 10
Training loss: 1.422278881072998
Validation loss: 1.8963592360096593

Epoch: 6| Step: 11
Training loss: 2.212451934814453
Validation loss: 1.9088975716662664

Epoch: 6| Step: 12
Training loss: 2.3190605640411377
Validation loss: 1.9104046296047907

Epoch: 6| Step: 13
Training loss: 1.8712351322174072
Validation loss: 1.895775083572634

Epoch: 198| Step: 0
Training loss: 1.9695249795913696
Validation loss: 1.8973607401694021

Epoch: 6| Step: 1
Training loss: 2.5580506324768066
Validation loss: 1.9025605288884972

Epoch: 6| Step: 2
Training loss: 1.5666053295135498
Validation loss: 1.92499723229357

Epoch: 6| Step: 3
Training loss: 1.9300912618637085
Validation loss: 1.9199257230245939

Epoch: 6| Step: 4
Training loss: 1.5399357080459595
Validation loss: 1.9611421656864945

Epoch: 6| Step: 5
Training loss: 1.3875267505645752
Validation loss: 1.9272177065572431

Epoch: 6| Step: 6
Training loss: 1.9574811458587646
Validation loss: 1.9085996894426243

Epoch: 6| Step: 7
Training loss: 1.1954776048660278
Validation loss: 1.93529115697389

Epoch: 6| Step: 8
Training loss: 2.1444272994995117
Validation loss: 1.9494657798479962

Epoch: 6| Step: 9
Training loss: 2.0013511180877686
Validation loss: 1.9330655067197737

Epoch: 6| Step: 10
Training loss: 1.6062531471252441
Validation loss: 1.9440302823179512

Epoch: 6| Step: 11
Training loss: 1.7014057636260986
Validation loss: 1.952200912660168

Epoch: 6| Step: 12
Training loss: 1.6363914012908936
Validation loss: 1.9205004194731354

Epoch: 6| Step: 13
Training loss: 1.2463858127593994
Validation loss: 1.9310114537515948

Epoch: 199| Step: 0
Training loss: 1.8262375593185425
Validation loss: 1.9331340802613126

Epoch: 6| Step: 1
Training loss: 2.173025608062744
Validation loss: 1.9122426714948428

Epoch: 6| Step: 2
Training loss: 1.3202416896820068
Validation loss: 1.9221955089158909

Epoch: 6| Step: 3
Training loss: 2.3655948638916016
Validation loss: 1.93628813118063

Epoch: 6| Step: 4
Training loss: 1.2602331638336182
Validation loss: 1.8823358115329538

Epoch: 6| Step: 5
Training loss: 1.443373203277588
Validation loss: 1.921222024066474

Epoch: 6| Step: 6
Training loss: 1.2633719444274902
Validation loss: 1.9489599325323617

Epoch: 6| Step: 7
Training loss: 2.442089557647705
Validation loss: 1.9000705493393766

Epoch: 6| Step: 8
Training loss: 2.352022647857666
Validation loss: 1.9337812098123695

Epoch: 6| Step: 9
Training loss: 1.1424071788787842
Validation loss: 1.9037485481590353

Epoch: 6| Step: 10
Training loss: 1.8880467414855957
Validation loss: 1.8984979634643884

Epoch: 6| Step: 11
Training loss: 2.1678690910339355
Validation loss: 1.8813904600758706

Epoch: 6| Step: 12
Training loss: 1.3418147563934326
Validation loss: 1.9374254518939602

Epoch: 6| Step: 13
Training loss: 1.6356256008148193
Validation loss: 1.9116738214287707

Epoch: 200| Step: 0
Training loss: 1.9421888589859009
Validation loss: 1.9327855315259708

Epoch: 6| Step: 1
Training loss: 1.709214687347412
Validation loss: 1.8978802593805457

Epoch: 6| Step: 2
Training loss: 1.8780694007873535
Validation loss: 1.9298335531706452

Epoch: 6| Step: 3
Training loss: 1.8786654472351074
Validation loss: 1.9022671971269833

Epoch: 6| Step: 4
Training loss: 1.274660587310791
Validation loss: 1.8938106875265799

Epoch: 6| Step: 5
Training loss: 2.0697505474090576
Validation loss: 1.9236781340773388

Epoch: 6| Step: 6
Training loss: 1.5887868404388428
Validation loss: 1.900545003593609

Epoch: 6| Step: 7
Training loss: 1.4586906433105469
Validation loss: 1.9255964448375087

Epoch: 6| Step: 8
Training loss: 1.3191719055175781
Validation loss: 1.9000578208636212

Epoch: 6| Step: 9
Training loss: 3.1381702423095703
Validation loss: 1.9570399945782078

Epoch: 6| Step: 10
Training loss: 1.4433112144470215
Validation loss: 1.9469753926800144

Epoch: 6| Step: 11
Training loss: 2.106468439102173
Validation loss: 1.9227185172419394

Epoch: 6| Step: 12
Training loss: 1.244872808456421
Validation loss: 1.9072267073456959

Epoch: 6| Step: 13
Training loss: 1.40811026096344
Validation loss: 1.9294937502953313

Epoch: 201| Step: 0
Training loss: 1.45974600315094
Validation loss: 1.9398759398409116

Epoch: 6| Step: 1
Training loss: 1.6637190580368042
Validation loss: 1.8982830009152811

Epoch: 6| Step: 2
Training loss: 1.734622597694397
Validation loss: 1.9016039204853836

Epoch: 6| Step: 3
Training loss: 2.515315055847168
Validation loss: 1.9136076665693713

Epoch: 6| Step: 4
Training loss: 1.3389983177185059
Validation loss: 1.8989031853214386

Epoch: 6| Step: 5
Training loss: 1.3435325622558594
Validation loss: 1.9326518953487437

Epoch: 6| Step: 6
Training loss: 1.6961866617202759
Validation loss: 1.8653320522718533

Epoch: 6| Step: 7
Training loss: 1.827242136001587
Validation loss: 1.939670616580594

Epoch: 6| Step: 8
Training loss: 1.7479777336120605
Validation loss: 1.9389771453795894

Epoch: 6| Step: 9
Training loss: 1.5968201160430908
Validation loss: 1.9063140666613014

Epoch: 6| Step: 10
Training loss: 1.7962455749511719
Validation loss: 1.902485470617971

Epoch: 6| Step: 11
Training loss: 2.0425782203674316
Validation loss: 1.8999912790072861

Epoch: 6| Step: 12
Training loss: 1.5762816667556763
Validation loss: 1.8800312806201238

Epoch: 6| Step: 13
Training loss: 2.2308692932128906
Validation loss: 1.939938255535659

Epoch: 202| Step: 0
Training loss: 2.1294500827789307
Validation loss: 1.8959797043954172

Epoch: 6| Step: 1
Training loss: 1.8012484312057495
Validation loss: 1.9516744793102305

Epoch: 6| Step: 2
Training loss: 1.9544153213500977
Validation loss: 1.9388988812764485

Epoch: 6| Step: 3
Training loss: 1.9232258796691895
Validation loss: 1.8893890867951095

Epoch: 6| Step: 4
Training loss: 2.783411741256714
Validation loss: 1.8997531680650608

Epoch: 6| Step: 5
Training loss: 1.2765991687774658
Validation loss: 1.9163448528576923

Epoch: 6| Step: 6
Training loss: 1.695882797241211
Validation loss: 1.938181789972449

Epoch: 6| Step: 7
Training loss: 1.2535943984985352
Validation loss: 1.9052092811112762

Epoch: 6| Step: 8
Training loss: 1.5064939260482788
Validation loss: 1.9490021569754488

Epoch: 6| Step: 9
Training loss: 1.83302640914917
Validation loss: 1.9391014857958722

Epoch: 6| Step: 10
Training loss: 1.9415113925933838
Validation loss: 1.9420161477981075

Epoch: 6| Step: 11
Training loss: 1.3935410976409912
Validation loss: 1.92111982581436

Epoch: 6| Step: 12
Training loss: 1.596454381942749
Validation loss: 1.9109272751756894

Epoch: 6| Step: 13
Training loss: 1.550947666168213
Validation loss: 1.9178474410887687

Epoch: 203| Step: 0
Training loss: 1.5307021141052246
Validation loss: 1.9351573733873264

Epoch: 6| Step: 1
Training loss: 2.4913265705108643
Validation loss: 1.9542189285319338

Epoch: 6| Step: 2
Training loss: 2.1745095252990723
Validation loss: 1.9207575141742665

Epoch: 6| Step: 3
Training loss: 2.015270709991455
Validation loss: 1.9325281804607761

Epoch: 6| Step: 4
Training loss: 2.0090861320495605
Validation loss: 1.916591126431701

Epoch: 6| Step: 5
Training loss: 1.1965547800064087
Validation loss: 1.9502463827850998

Epoch: 6| Step: 6
Training loss: 2.4087791442871094
Validation loss: 1.9277826175894788

Epoch: 6| Step: 7
Training loss: 1.6596368551254272
Validation loss: 1.9309856635268017

Epoch: 6| Step: 8
Training loss: 2.4294891357421875
Validation loss: 1.9369640593887658

Epoch: 6| Step: 9
Training loss: 1.1346946954727173
Validation loss: 1.9508899738711696

Epoch: 6| Step: 10
Training loss: 1.9711538553237915
Validation loss: 1.9755231424044537

Epoch: 6| Step: 11
Training loss: 1.1891177892684937
Validation loss: 1.9283770322799683

Epoch: 6| Step: 12
Training loss: 1.0551459789276123
Validation loss: 1.921613690673664

Epoch: 6| Step: 13
Training loss: 0.6610944867134094
Validation loss: 1.913729703554543

Epoch: 204| Step: 0
Training loss: 1.600639820098877
Validation loss: 1.9230469170437063

Epoch: 6| Step: 1
Training loss: 1.6593282222747803
Validation loss: 1.8945462075612878

Epoch: 6| Step: 2
Training loss: 1.044905424118042
Validation loss: 1.9252321412486415

Epoch: 6| Step: 3
Training loss: 2.10721492767334
Validation loss: 1.881257095644551

Epoch: 6| Step: 4
Training loss: 1.37931489944458
Validation loss: 1.881658862995845

Epoch: 6| Step: 5
Training loss: 1.8175922632217407
Validation loss: 1.9102304904691634

Epoch: 6| Step: 6
Training loss: 2.185297727584839
Validation loss: 1.9137435343957716

Epoch: 6| Step: 7
Training loss: 1.0997692346572876
Validation loss: 1.8970047363670923

Epoch: 6| Step: 8
Training loss: 1.424954891204834
Validation loss: 1.9071069776370961

Epoch: 6| Step: 9
Training loss: 2.0542092323303223
Validation loss: 1.9036907329354236

Epoch: 6| Step: 10
Training loss: 1.9652780294418335
Validation loss: 1.9078720808029175

Epoch: 6| Step: 11
Training loss: 2.237009048461914
Validation loss: 1.8917155265808105

Epoch: 6| Step: 12
Training loss: 1.8191167116165161
Validation loss: 1.9047990473367835

Epoch: 6| Step: 13
Training loss: 2.33657169342041
Validation loss: 1.9119639371031074

Epoch: 205| Step: 0
Training loss: 1.5240726470947266
Validation loss: 1.9112755662651473

Epoch: 6| Step: 1
Training loss: 2.020771026611328
Validation loss: 1.917996524482645

Epoch: 6| Step: 2
Training loss: 1.636798620223999
Validation loss: 1.9291591298195623

Epoch: 6| Step: 3
Training loss: 2.4398131370544434
Validation loss: 1.8944171346643919

Epoch: 6| Step: 4
Training loss: 1.3547327518463135
Validation loss: 1.9344482434693204

Epoch: 6| Step: 5
Training loss: 1.8761427402496338
Validation loss: 1.9026836861846268

Epoch: 6| Step: 6
Training loss: 1.4769484996795654
Validation loss: 1.8842675596155145

Epoch: 6| Step: 7
Training loss: 1.6942023038864136
Validation loss: 1.9359986012981785

Epoch: 6| Step: 8
Training loss: 2.0124950408935547
Validation loss: 1.9033726543508551

Epoch: 6| Step: 9
Training loss: 1.6527889966964722
Validation loss: 1.9296968444701164

Epoch: 6| Step: 10
Training loss: 1.5525509119033813
Validation loss: 1.9383876580064014

Epoch: 6| Step: 11
Training loss: 1.7167900800704956
Validation loss: 1.9532918648053241

Epoch: 6| Step: 12
Training loss: 1.7612406015396118
Validation loss: 1.8985531509563487

Epoch: 6| Step: 13
Training loss: 1.485953688621521
Validation loss: 1.915423003576135

Epoch: 206| Step: 0
Training loss: 1.3725407123565674
Validation loss: 1.9025328569514777

Epoch: 6| Step: 1
Training loss: 1.2932360172271729
Validation loss: 1.9052700470852595

Epoch: 6| Step: 2
Training loss: 2.273995876312256
Validation loss: 1.912934801911795

Epoch: 6| Step: 3
Training loss: 1.4130213260650635
Validation loss: 1.9120902604954217

Epoch: 6| Step: 4
Training loss: 1.609145164489746
Validation loss: 1.8837658282249206

Epoch: 6| Step: 5
Training loss: 1.8417435884475708
Validation loss: 1.9092580041577738

Epoch: 6| Step: 6
Training loss: 2.0657477378845215
Validation loss: 1.9098720371082265

Epoch: 6| Step: 7
Training loss: 1.7748616933822632
Validation loss: 1.8963543035650765

Epoch: 6| Step: 8
Training loss: 2.487398862838745
Validation loss: 1.916419574009475

Epoch: 6| Step: 9
Training loss: 1.5321133136749268
Validation loss: 1.9139606568121141

Epoch: 6| Step: 10
Training loss: 1.9594095945358276
Validation loss: 1.9589189124363724

Epoch: 6| Step: 11
Training loss: 0.9146367907524109
Validation loss: 1.8970284333793066

Epoch: 6| Step: 12
Training loss: 1.9178709983825684
Validation loss: 1.9362758333965013

Epoch: 6| Step: 13
Training loss: 1.772148609161377
Validation loss: 1.9162745270677792

Epoch: 207| Step: 0
Training loss: 1.8500950336456299
Validation loss: 1.8980892524924329

Epoch: 6| Step: 1
Training loss: 1.9488813877105713
Validation loss: 1.9329582375864829

Epoch: 6| Step: 2
Training loss: 1.5806163549423218
Validation loss: 1.8591543154049945

Epoch: 6| Step: 3
Training loss: 1.0334291458129883
Validation loss: 1.9405674844659784

Epoch: 6| Step: 4
Training loss: 1.359654426574707
Validation loss: 1.9083230136543192

Epoch: 6| Step: 5
Training loss: 1.2830173969268799
Validation loss: 1.8794651505767659

Epoch: 6| Step: 6
Training loss: 1.8578286170959473
Validation loss: 1.9043518317643033

Epoch: 6| Step: 7
Training loss: 1.9206128120422363
Validation loss: 1.9092721900632303

Epoch: 6| Step: 8
Training loss: 1.691849708557129
Validation loss: 1.9028172390435332

Epoch: 6| Step: 9
Training loss: 1.968654751777649
Validation loss: 1.911104925217167

Epoch: 6| Step: 10
Training loss: 1.9901256561279297
Validation loss: 1.9129556840465916

Epoch: 6| Step: 11
Training loss: 1.9827024936676025
Validation loss: 1.9329978137887933

Epoch: 6| Step: 12
Training loss: 1.7192782163619995
Validation loss: 1.8927405982889154

Epoch: 6| Step: 13
Training loss: 2.9893362522125244
Validation loss: 1.9047439777722923

Epoch: 208| Step: 0
Training loss: 1.6864285469055176
Validation loss: 1.9156188990480156

Epoch: 6| Step: 1
Training loss: 1.6920100450515747
Validation loss: 1.892150414887295

Epoch: 6| Step: 2
Training loss: 1.6288824081420898
Validation loss: 1.9238344495014479

Epoch: 6| Step: 3
Training loss: 1.1503099203109741
Validation loss: 1.9048132537513651

Epoch: 6| Step: 4
Training loss: 1.7283926010131836
Validation loss: 1.9407975058401785

Epoch: 6| Step: 5
Training loss: 1.8636367321014404
Validation loss: 1.9486344450263566

Epoch: 6| Step: 6
Training loss: 1.5582733154296875
Validation loss: 1.9323111503354964

Epoch: 6| Step: 7
Training loss: 1.0321431159973145
Validation loss: 1.9322570395726029

Epoch: 6| Step: 8
Training loss: 2.2527759075164795
Validation loss: 1.9233231057402909

Epoch: 6| Step: 9
Training loss: 1.4809995889663696
Validation loss: 1.9008418308791293

Epoch: 6| Step: 10
Training loss: 2.031080722808838
Validation loss: 1.9455821988403157

Epoch: 6| Step: 11
Training loss: 2.1844308376312256
Validation loss: 1.974821864917714

Epoch: 6| Step: 12
Training loss: 1.9064035415649414
Validation loss: 1.9481226526280886

Epoch: 6| Step: 13
Training loss: 2.48009991645813
Validation loss: 1.9326745053773284

Epoch: 209| Step: 0
Training loss: 1.886458158493042
Validation loss: 1.9559208090587328

Epoch: 6| Step: 1
Training loss: 1.4380052089691162
Validation loss: 1.8974772076452933

Epoch: 6| Step: 2
Training loss: 1.6768763065338135
Validation loss: 1.9469565101849136

Epoch: 6| Step: 3
Training loss: 2.0430941581726074
Validation loss: 1.902070790208796

Epoch: 6| Step: 4
Training loss: 1.56320059299469
Validation loss: 1.919937777262862

Epoch: 6| Step: 5
Training loss: 1.4375429153442383
Validation loss: 1.874176658609862

Epoch: 6| Step: 6
Training loss: 1.4243665933609009
Validation loss: 1.8836513014249905

Epoch: 6| Step: 7
Training loss: 2.5034141540527344
Validation loss: 1.8795952848208848

Epoch: 6| Step: 8
Training loss: 1.6871154308319092
Validation loss: 1.9320627873943699

Epoch: 6| Step: 9
Training loss: 1.3597835302352905
Validation loss: 1.900305107075681

Epoch: 6| Step: 10
Training loss: 1.5749471187591553
Validation loss: 1.8964718644336989

Epoch: 6| Step: 11
Training loss: 2.1742947101593018
Validation loss: 1.928196362269822

Epoch: 6| Step: 12
Training loss: 1.766191005706787
Validation loss: 1.8942516593522922

Epoch: 6| Step: 13
Training loss: 2.2921228408813477
Validation loss: 1.9140063267882153

Epoch: 210| Step: 0
Training loss: 1.8044626712799072
Validation loss: 1.8903353291173135

Epoch: 6| Step: 1
Training loss: 1.9003112316131592
Validation loss: 1.9321334528666672

Epoch: 6| Step: 2
Training loss: 0.9932845830917358
Validation loss: 1.9421661784571986

Epoch: 6| Step: 3
Training loss: 2.3414156436920166
Validation loss: 1.915969935796594

Epoch: 6| Step: 4
Training loss: 2.0778937339782715
Validation loss: 1.9219919814858386

Epoch: 6| Step: 5
Training loss: 1.4075727462768555
Validation loss: 1.943137224002551

Epoch: 6| Step: 6
Training loss: 1.7695475816726685
Validation loss: 1.9574506987807572

Epoch: 6| Step: 7
Training loss: 1.4814465045928955
Validation loss: 1.9468218536787136

Epoch: 6| Step: 8
Training loss: 1.5094051361083984
Validation loss: 1.9875674901470062

Epoch: 6| Step: 9
Training loss: 1.5044387578964233
Validation loss: 1.9301751018852316

Epoch: 6| Step: 10
Training loss: 2.170062780380249
Validation loss: 1.9703665741028324

Epoch: 6| Step: 11
Training loss: 1.576512098312378
Validation loss: 1.968295035823699

Epoch: 6| Step: 12
Training loss: 2.021785020828247
Validation loss: 1.9315757648919218

Epoch: 6| Step: 13
Training loss: 1.623293161392212
Validation loss: 1.9551920275534354

Epoch: 211| Step: 0
Training loss: 1.7271207571029663
Validation loss: 1.9396541272440264

Epoch: 6| Step: 1
Training loss: 2.343813896179199
Validation loss: 1.918734988858623

Epoch: 6| Step: 2
Training loss: 1.4620381593704224
Validation loss: 1.9258951089715446

Epoch: 6| Step: 3
Training loss: 1.6966997385025024
Validation loss: 1.9290353252041725

Epoch: 6| Step: 4
Training loss: 0.7344123721122742
Validation loss: 1.9063607031299221

Epoch: 6| Step: 5
Training loss: 2.128915548324585
Validation loss: 1.878328441291727

Epoch: 6| Step: 6
Training loss: 2.6596479415893555
Validation loss: 1.9151351233964324

Epoch: 6| Step: 7
Training loss: 1.460050344467163
Validation loss: 1.893100638543406

Epoch: 6| Step: 8
Training loss: 1.4537487030029297
Validation loss: 1.8803841375535535

Epoch: 6| Step: 9
Training loss: 1.6353390216827393
Validation loss: 1.8906930031314972

Epoch: 6| Step: 10
Training loss: 2.0415093898773193
Validation loss: 1.8862173018916961

Epoch: 6| Step: 11
Training loss: 1.5703496932983398
Validation loss: 1.8813031027393956

Epoch: 6| Step: 12
Training loss: 1.9257698059082031
Validation loss: 1.9160441429384294

Epoch: 6| Step: 13
Training loss: 1.5891976356506348
Validation loss: 1.8524395522250925

Epoch: 212| Step: 0
Training loss: 1.8644840717315674
Validation loss: 1.90497415168311

Epoch: 6| Step: 1
Training loss: 1.8581961393356323
Validation loss: 1.8866043577912033

Epoch: 6| Step: 2
Training loss: 1.9974082708358765
Validation loss: 1.8528333466540101

Epoch: 6| Step: 3
Training loss: 1.7342259883880615
Validation loss: 1.9042475351723291

Epoch: 6| Step: 4
Training loss: 1.9129879474639893
Validation loss: 1.9312083695524482

Epoch: 6| Step: 5
Training loss: 1.282819390296936
Validation loss: 1.9066612694853096

Epoch: 6| Step: 6
Training loss: 1.7143104076385498
Validation loss: 1.9194023186160671

Epoch: 6| Step: 7
Training loss: 1.4738070964813232
Validation loss: 1.8983339545547322

Epoch: 6| Step: 8
Training loss: 1.4419622421264648
Validation loss: 1.9283953712832542

Epoch: 6| Step: 9
Training loss: 2.1597466468811035
Validation loss: 1.9326911177686465

Epoch: 6| Step: 10
Training loss: 1.7648451328277588
Validation loss: 1.9463730524945002

Epoch: 6| Step: 11
Training loss: 1.5836689472198486
Validation loss: 1.9186581283487298

Epoch: 6| Step: 12
Training loss: 1.6907809972763062
Validation loss: 1.9195353382377214

Epoch: 6| Step: 13
Training loss: 2.254384994506836
Validation loss: 1.8750881943651425

Epoch: 213| Step: 0
Training loss: 1.8727309703826904
Validation loss: 1.9513961576646375

Epoch: 6| Step: 1
Training loss: 1.6429357528686523
Validation loss: 1.927344019694995

Epoch: 6| Step: 2
Training loss: 1.7978408336639404
Validation loss: 1.9255419482466996

Epoch: 6| Step: 3
Training loss: 1.1125363111495972
Validation loss: 1.947054801448699

Epoch: 6| Step: 4
Training loss: 1.5733489990234375
Validation loss: 1.9173307764914729

Epoch: 6| Step: 5
Training loss: 1.8404290676116943
Validation loss: 1.9235520234671972

Epoch: 6| Step: 6
Training loss: 2.0901308059692383
Validation loss: 1.8870131315723542

Epoch: 6| Step: 7
Training loss: 1.7518846988677979
Validation loss: 1.9220733873305782

Epoch: 6| Step: 8
Training loss: 2.1224749088287354
Validation loss: 1.8992752118777203

Epoch: 6| Step: 9
Training loss: 2.105037212371826
Validation loss: 1.9087766678102556

Epoch: 6| Step: 10
Training loss: 1.8956799507141113
Validation loss: 1.9757315727972216

Epoch: 6| Step: 11
Training loss: 1.5895919799804688
Validation loss: 1.908944401689755

Epoch: 6| Step: 12
Training loss: 1.2222862243652344
Validation loss: 1.9059028228123982

Epoch: 6| Step: 13
Training loss: 1.4485491514205933
Validation loss: 1.8527805356569187

Epoch: 214| Step: 0
Training loss: 1.3683841228485107
Validation loss: 1.9067029619729647

Epoch: 6| Step: 1
Training loss: 2.331817150115967
Validation loss: 1.8922011211354246

Epoch: 6| Step: 2
Training loss: 1.679553508758545
Validation loss: 1.938985086256458

Epoch: 6| Step: 3
Training loss: 2.001647472381592
Validation loss: 1.9191241687343967

Epoch: 6| Step: 4
Training loss: 1.6076796054840088
Validation loss: 1.876021659502419

Epoch: 6| Step: 5
Training loss: 1.692284345626831
Validation loss: 1.9166029473786712

Epoch: 6| Step: 6
Training loss: 2.020501136779785
Validation loss: 1.9085241543349398

Epoch: 6| Step: 7
Training loss: 1.5430294275283813
Validation loss: 1.9318329570113972

Epoch: 6| Step: 8
Training loss: 1.6343700885772705
Validation loss: 1.924833245174859

Epoch: 6| Step: 9
Training loss: 1.7470213174819946
Validation loss: 1.9011409564684796

Epoch: 6| Step: 10
Training loss: 1.2698862552642822
Validation loss: 1.925761353585028

Epoch: 6| Step: 11
Training loss: 1.613088846206665
Validation loss: 1.9134231921165221

Epoch: 6| Step: 12
Training loss: 1.5247490406036377
Validation loss: 1.9351397611761605

Epoch: 6| Step: 13
Training loss: 2.4930484294891357
Validation loss: 1.9092799643034577

Epoch: 215| Step: 0
Training loss: 1.879518985748291
Validation loss: 1.9071264036240116

Epoch: 6| Step: 1
Training loss: 1.541090965270996
Validation loss: 1.9057661243664321

Epoch: 6| Step: 2
Training loss: 1.8404409885406494
Validation loss: 1.9079447356603478

Epoch: 6| Step: 3
Training loss: 1.6628843545913696
Validation loss: 1.9451146843612834

Epoch: 6| Step: 4
Training loss: 2.023512363433838
Validation loss: 1.9053795350495206

Epoch: 6| Step: 5
Training loss: 1.6365938186645508
Validation loss: 1.938241720199585

Epoch: 6| Step: 6
Training loss: 1.1547865867614746
Validation loss: 1.9006597816303212

Epoch: 6| Step: 7
Training loss: 2.304335117340088
Validation loss: 1.9301945060812018

Epoch: 6| Step: 8
Training loss: 1.431740403175354
Validation loss: 1.9063335029027795

Epoch: 6| Step: 9
Training loss: 1.7839823961257935
Validation loss: 1.921844514467383

Epoch: 6| Step: 10
Training loss: 1.8043497800827026
Validation loss: 1.9064048977308377

Epoch: 6| Step: 11
Training loss: 1.569069266319275
Validation loss: 1.9023635759148547

Epoch: 6| Step: 12
Training loss: 1.829813003540039
Validation loss: 1.9295167141063239

Epoch: 6| Step: 13
Training loss: 1.8559439182281494
Validation loss: 1.9221471714717087

Epoch: 216| Step: 0
Training loss: 1.7726356983184814
Validation loss: 1.8915451021604641

Epoch: 6| Step: 1
Training loss: 1.2846195697784424
Validation loss: 1.9235186987025763

Epoch: 6| Step: 2
Training loss: 1.9471309185028076
Validation loss: 1.8845457441063338

Epoch: 6| Step: 3
Training loss: 1.560576319694519
Validation loss: 1.9222810858039445

Epoch: 6| Step: 4
Training loss: 1.8731144666671753
Validation loss: 1.903678140332622

Epoch: 6| Step: 5
Training loss: 1.8925976753234863
Validation loss: 1.948915199566913

Epoch: 6| Step: 6
Training loss: 1.2526260614395142
Validation loss: 1.940120994403798

Epoch: 6| Step: 7
Training loss: 2.022190570831299
Validation loss: 1.9608082963574318

Epoch: 6| Step: 8
Training loss: 1.7451711893081665
Validation loss: 1.9491381260656542

Epoch: 6| Step: 9
Training loss: 1.3968756198883057
Validation loss: 1.9399760051440167

Epoch: 6| Step: 10
Training loss: 1.7511625289916992
Validation loss: 1.928834907470211

Epoch: 6| Step: 11
Training loss: 2.837578773498535
Validation loss: 1.9200877502400389

Epoch: 6| Step: 12
Training loss: 1.3436853885650635
Validation loss: 1.9150200287501018

Epoch: 6| Step: 13
Training loss: 1.154531478881836
Validation loss: 1.9205532663611955

Epoch: 217| Step: 0
Training loss: 2.294996500015259
Validation loss: 1.8487733282068723

Epoch: 6| Step: 1
Training loss: 2.14162540435791
Validation loss: 1.8811742913338445

Epoch: 6| Step: 2
Training loss: 2.530566692352295
Validation loss: 1.8831731465555006

Epoch: 6| Step: 3
Training loss: 2.066641330718994
Validation loss: 1.902810150577176

Epoch: 6| Step: 4
Training loss: 1.222720980644226
Validation loss: 1.9151008718757219

Epoch: 6| Step: 5
Training loss: 1.2520713806152344
Validation loss: 1.8981821383199384

Epoch: 6| Step: 6
Training loss: 2.0005459785461426
Validation loss: 1.9052646198580343

Epoch: 6| Step: 7
Training loss: 1.5724997520446777
Validation loss: 1.9081684158694359

Epoch: 6| Step: 8
Training loss: 1.8487486839294434
Validation loss: 1.9242161499556674

Epoch: 6| Step: 9
Training loss: 0.9861181974411011
Validation loss: 1.9119936881526824

Epoch: 6| Step: 10
Training loss: 1.6857572793960571
Validation loss: 1.9094336853232434

Epoch: 6| Step: 11
Training loss: 1.6199743747711182
Validation loss: 1.8986849631032636

Epoch: 6| Step: 12
Training loss: 1.3127822875976562
Validation loss: 1.8622539709973078

Epoch: 6| Step: 13
Training loss: 1.2303907871246338
Validation loss: 1.927969854365113

Epoch: 218| Step: 0
Training loss: 1.4845037460327148
Validation loss: 1.8985154141661942

Epoch: 6| Step: 1
Training loss: 2.053138256072998
Validation loss: 1.9306554102128552

Epoch: 6| Step: 2
Training loss: 2.1349234580993652
Validation loss: 1.9196628011682981

Epoch: 6| Step: 3
Training loss: 2.4513742923736572
Validation loss: 1.906160682760259

Epoch: 6| Step: 4
Training loss: 1.192052960395813
Validation loss: 1.9829014603809645

Epoch: 6| Step: 5
Training loss: 1.5076605081558228
Validation loss: 1.9313392382796093

Epoch: 6| Step: 6
Training loss: 1.4687588214874268
Validation loss: 1.9492273651143557

Epoch: 6| Step: 7
Training loss: 1.3339624404907227
Validation loss: 1.950100225787009

Epoch: 6| Step: 8
Training loss: 1.502264380455017
Validation loss: 1.894124315631005

Epoch: 6| Step: 9
Training loss: 1.3847875595092773
Validation loss: 1.9286916755860852

Epoch: 6| Step: 10
Training loss: 1.8789488077163696
Validation loss: 1.9499520050582064

Epoch: 6| Step: 11
Training loss: 2.1812024116516113
Validation loss: 1.8808577368336339

Epoch: 6| Step: 12
Training loss: 1.9468529224395752
Validation loss: 1.9304430279680478

Epoch: 6| Step: 13
Training loss: 1.7529141902923584
Validation loss: 1.9158612246154456

Epoch: 219| Step: 0
Training loss: 2.2902884483337402
Validation loss: 1.9259704415516188

Epoch: 6| Step: 1
Training loss: 1.6655588150024414
Validation loss: 1.8891861169568953

Epoch: 6| Step: 2
Training loss: 1.4575756788253784
Validation loss: 1.911004666359194

Epoch: 6| Step: 3
Training loss: 1.6732780933380127
Validation loss: 1.9415900476517216

Epoch: 6| Step: 4
Training loss: 1.6273095607757568
Validation loss: 1.93013677161227

Epoch: 6| Step: 5
Training loss: 1.2743265628814697
Validation loss: 1.9643471240997314

Epoch: 6| Step: 6
Training loss: 2.045975685119629
Validation loss: 1.9029286138473018

Epoch: 6| Step: 7
Training loss: 1.9159395694732666
Validation loss: 1.9280903365022393

Epoch: 6| Step: 8
Training loss: 1.9763754606246948
Validation loss: 1.9340995614246657

Epoch: 6| Step: 9
Training loss: 1.449092149734497
Validation loss: 1.9212209460555867

Epoch: 6| Step: 10
Training loss: 1.4599390029907227
Validation loss: 1.9037875488240232

Epoch: 6| Step: 11
Training loss: 1.7841657400131226
Validation loss: 1.8970805419388639

Epoch: 6| Step: 12
Training loss: 1.5110965967178345
Validation loss: 1.8752276666702763

Epoch: 6| Step: 13
Training loss: 1.7007336616516113
Validation loss: 1.9285116708406838

Epoch: 220| Step: 0
Training loss: 1.534536361694336
Validation loss: 1.8817624020320114

Epoch: 6| Step: 1
Training loss: 1.5738354921340942
Validation loss: 1.879140568035905

Epoch: 6| Step: 2
Training loss: 1.1639442443847656
Validation loss: 1.9011686566055461

Epoch: 6| Step: 3
Training loss: 2.5248050689697266
Validation loss: 1.923994525786369

Epoch: 6| Step: 4
Training loss: 2.628183364868164
Validation loss: 1.873015857511951

Epoch: 6| Step: 5
Training loss: 1.158499836921692
Validation loss: 1.9342737108148553

Epoch: 6| Step: 6
Training loss: 2.173128128051758
Validation loss: 1.9202424133977583

Epoch: 6| Step: 7
Training loss: 2.059868574142456
Validation loss: 1.939031248451561

Epoch: 6| Step: 8
Training loss: 0.9526121020317078
Validation loss: 1.9517206043325446

Epoch: 6| Step: 9
Training loss: 1.7899653911590576
Validation loss: 1.938963936221215

Epoch: 6| Step: 10
Training loss: 1.683077335357666
Validation loss: 1.9280821354158464

Epoch: 6| Step: 11
Training loss: 1.4732950925827026
Validation loss: 1.9231357702644922

Epoch: 6| Step: 12
Training loss: 1.804825782775879
Validation loss: 1.916819712167145

Epoch: 6| Step: 13
Training loss: 1.4324321746826172
Validation loss: 1.9053139507129628

Epoch: 221| Step: 0
Training loss: 1.9660699367523193
Validation loss: 1.9263181032673005

Epoch: 6| Step: 1
Training loss: 1.9528820514678955
Validation loss: 1.9022129966366677

Epoch: 6| Step: 2
Training loss: 1.8969630002975464
Validation loss: 1.9466328428637596

Epoch: 6| Step: 3
Training loss: 1.4268053770065308
Validation loss: 1.8991834040611022

Epoch: 6| Step: 4
Training loss: 1.0998128652572632
Validation loss: 1.89226274336538

Epoch: 6| Step: 5
Training loss: 1.0525720119476318
Validation loss: 1.9082040261196833

Epoch: 6| Step: 6
Training loss: 2.130344867706299
Validation loss: 1.901893807995704

Epoch: 6| Step: 7
Training loss: 2.0605292320251465
Validation loss: 1.8784297653423843

Epoch: 6| Step: 8
Training loss: 1.5812311172485352
Validation loss: 1.9238415123313986

Epoch: 6| Step: 9
Training loss: 1.5989832878112793
Validation loss: 1.893497670850446

Epoch: 6| Step: 10
Training loss: 1.9438707828521729
Validation loss: 1.901380169776178

Epoch: 6| Step: 11
Training loss: 1.989025354385376
Validation loss: 1.8950457290936542

Epoch: 6| Step: 12
Training loss: 1.5742809772491455
Validation loss: 1.8702315515087498

Epoch: 6| Step: 13
Training loss: 1.6848292350769043
Validation loss: 1.8738660902105353

Epoch: 222| Step: 0
Training loss: 1.638824224472046
Validation loss: 1.9126586939698906

Epoch: 6| Step: 1
Training loss: 1.7445974349975586
Validation loss: 1.8799117316481888

Epoch: 6| Step: 2
Training loss: 1.8737661838531494
Validation loss: 1.9461266853476082

Epoch: 6| Step: 3
Training loss: 1.609014630317688
Validation loss: 1.8982671717161774

Epoch: 6| Step: 4
Training loss: 1.6950578689575195
Validation loss: 1.918548414784093

Epoch: 6| Step: 5
Training loss: 1.3914430141448975
Validation loss: 1.9190557131203272

Epoch: 6| Step: 6
Training loss: 1.607344627380371
Validation loss: 1.9101389659348356

Epoch: 6| Step: 7
Training loss: 2.124065637588501
Validation loss: 1.8741540344812537

Epoch: 6| Step: 8
Training loss: 1.7686636447906494
Validation loss: 1.8965909968140304

Epoch: 6| Step: 9
Training loss: 1.458042025566101
Validation loss: 1.917297504281485

Epoch: 6| Step: 10
Training loss: 1.7940361499786377
Validation loss: 1.9492274945782078

Epoch: 6| Step: 11
Training loss: 1.3574475049972534
Validation loss: 1.932962081765616

Epoch: 6| Step: 12
Training loss: 1.5277780294418335
Validation loss: 1.9170292744072535

Epoch: 6| Step: 13
Training loss: 2.482593536376953
Validation loss: 1.9751887782927482

Epoch: 223| Step: 0
Training loss: 1.5410499572753906
Validation loss: 1.9332435195164015

Epoch: 6| Step: 1
Training loss: 0.9038448333740234
Validation loss: 1.9100369920012772

Epoch: 6| Step: 2
Training loss: 1.8445446491241455
Validation loss: 1.9165321101424515

Epoch: 6| Step: 3
Training loss: 1.5218172073364258
Validation loss: 1.9388781324509652

Epoch: 6| Step: 4
Training loss: 1.5205819606781006
Validation loss: 1.92139486728176

Epoch: 6| Step: 5
Training loss: 1.9866358041763306
Validation loss: 1.9249608644875147

Epoch: 6| Step: 6
Training loss: 1.429333209991455
Validation loss: 1.9197956144168813

Epoch: 6| Step: 7
Training loss: 1.54814875125885
Validation loss: 1.8791425099936865

Epoch: 6| Step: 8
Training loss: 1.3612366914749146
Validation loss: 1.9049802967297134

Epoch: 6| Step: 9
Training loss: 1.6739401817321777
Validation loss: 1.897295876215863

Epoch: 6| Step: 10
Training loss: 1.598416805267334
Validation loss: 1.905479197861046

Epoch: 6| Step: 11
Training loss: 1.5956406593322754
Validation loss: 1.9172381931735623

Epoch: 6| Step: 12
Training loss: 3.333801746368408
Validation loss: 1.843540688996674

Epoch: 6| Step: 13
Training loss: 2.0570199489593506
Validation loss: 1.8830565047520462

Epoch: 224| Step: 0
Training loss: 1.267881155014038
Validation loss: 1.8984688635795348

Epoch: 6| Step: 1
Training loss: 2.0249621868133545
Validation loss: 1.8539095001835977

Epoch: 6| Step: 2
Training loss: 1.5610182285308838
Validation loss: 1.8836222963948404

Epoch: 6| Step: 3
Training loss: 1.4036343097686768
Validation loss: 1.9068204331141647

Epoch: 6| Step: 4
Training loss: 1.4948413372039795
Validation loss: 1.857964354176675

Epoch: 6| Step: 5
Training loss: 1.3797056674957275
Validation loss: 1.8730713064952562

Epoch: 6| Step: 6
Training loss: 2.2043747901916504
Validation loss: 1.861455221329966

Epoch: 6| Step: 7
Training loss: 1.3931173086166382
Validation loss: 1.917913072852678

Epoch: 6| Step: 8
Training loss: 2.1742305755615234
Validation loss: 1.8920156237899617

Epoch: 6| Step: 9
Training loss: 2.167069673538208
Validation loss: 1.894595060297238

Epoch: 6| Step: 10
Training loss: 1.3250763416290283
Validation loss: 1.8578374283288115

Epoch: 6| Step: 11
Training loss: 1.6444891691207886
Validation loss: 1.9144692626050723

Epoch: 6| Step: 12
Training loss: 2.0461959838867188
Validation loss: 1.8924448169687742

Epoch: 6| Step: 13
Training loss: 2.0205256938934326
Validation loss: 1.9223751098878923

Epoch: 225| Step: 0
Training loss: 2.530522346496582
Validation loss: 1.9368565262004893

Epoch: 6| Step: 1
Training loss: 2.1394128799438477
Validation loss: 1.9325320900127452

Epoch: 6| Step: 2
Training loss: 1.3862520456314087
Validation loss: 1.9116903389653852

Epoch: 6| Step: 3
Training loss: 1.662226676940918
Validation loss: 1.9212564934966385

Epoch: 6| Step: 4
Training loss: 1.5665528774261475
Validation loss: 1.9148832944131666

Epoch: 6| Step: 5
Training loss: 1.3305413722991943
Validation loss: 1.9078236523494925

Epoch: 6| Step: 6
Training loss: 1.5316903591156006
Validation loss: 1.8779699507580008

Epoch: 6| Step: 7
Training loss: 1.7439188957214355
Validation loss: 1.9294027000345209

Epoch: 6| Step: 8
Training loss: 2.1112823486328125
Validation loss: 1.9147820075352986

Epoch: 6| Step: 9
Training loss: 1.0401697158813477
Validation loss: 1.9275823126557052

Epoch: 6| Step: 10
Training loss: 1.527199625968933
Validation loss: 1.9089616421730287

Epoch: 6| Step: 11
Training loss: 1.7954027652740479
Validation loss: 1.8958910306294758

Epoch: 6| Step: 12
Training loss: 1.5582711696624756
Validation loss: 1.8870542010953348

Epoch: 6| Step: 13
Training loss: 1.4697943925857544
Validation loss: 1.9211238340664936

Epoch: 226| Step: 0
Training loss: 1.7152609825134277
Validation loss: 1.937108265456333

Epoch: 6| Step: 1
Training loss: 1.1601461172103882
Validation loss: 1.8999943348669237

Epoch: 6| Step: 2
Training loss: 1.8238978385925293
Validation loss: 1.9076651988490936

Epoch: 6| Step: 3
Training loss: 2.434191942214966
Validation loss: 1.9255960141458819

Epoch: 6| Step: 4
Training loss: 1.9221112728118896
Validation loss: 1.9459835816455144

Epoch: 6| Step: 5
Training loss: 1.0443905591964722
Validation loss: 1.9017312193429599

Epoch: 6| Step: 6
Training loss: 1.4574878215789795
Validation loss: 1.8673753840948946

Epoch: 6| Step: 7
Training loss: 1.500589370727539
Validation loss: 1.8822543133971512

Epoch: 6| Step: 8
Training loss: 2.3736510276794434
Validation loss: 1.8924886180508522

Epoch: 6| Step: 9
Training loss: 1.6753692626953125
Validation loss: 1.8703339548521145

Epoch: 6| Step: 10
Training loss: 1.3492751121520996
Validation loss: 1.9310089849656629

Epoch: 6| Step: 11
Training loss: 2.064661741256714
Validation loss: 1.908504674511571

Epoch: 6| Step: 12
Training loss: 1.245522141456604
Validation loss: 1.9181212507268435

Epoch: 6| Step: 13
Training loss: 1.7765311002731323
Validation loss: 1.901031712050079

Epoch: 227| Step: 0
Training loss: 1.6411912441253662
Validation loss: 1.966513861892044

Epoch: 6| Step: 1
Training loss: 1.7906265258789062
Validation loss: 1.9009544541758876

Epoch: 6| Step: 2
Training loss: 1.588774561882019
Validation loss: 1.9102593660354614

Epoch: 6| Step: 3
Training loss: 1.3757258653640747
Validation loss: 1.9013469860117922

Epoch: 6| Step: 4
Training loss: 1.2379893064498901
Validation loss: 1.9123819130723194

Epoch: 6| Step: 5
Training loss: 1.8769067525863647
Validation loss: 1.8857173996586953

Epoch: 6| Step: 6
Training loss: 1.3320252895355225
Validation loss: 1.9139240018783077

Epoch: 6| Step: 7
Training loss: 1.5879168510437012
Validation loss: 1.928769366715544

Epoch: 6| Step: 8
Training loss: 2.035831928253174
Validation loss: 1.896259109179179

Epoch: 6| Step: 9
Training loss: 1.8993381261825562
Validation loss: 1.9645777158839728

Epoch: 6| Step: 10
Training loss: 1.8759551048278809
Validation loss: 1.9337594355306318

Epoch: 6| Step: 11
Training loss: 1.8957934379577637
Validation loss: 1.939153830210368

Epoch: 6| Step: 12
Training loss: 1.4261642694473267
Validation loss: 1.9356686940757177

Epoch: 6| Step: 13
Training loss: 2.1313676834106445
Validation loss: 1.9190629784778883

Epoch: 228| Step: 0
Training loss: 1.60695219039917
Validation loss: 1.9150897969481766

Epoch: 6| Step: 1
Training loss: 1.8228588104248047
Validation loss: 1.8998803348951443

Epoch: 6| Step: 2
Training loss: 2.1320714950561523
Validation loss: 1.9327541910192019

Epoch: 6| Step: 3
Training loss: 2.1064882278442383
Validation loss: 1.9305855548509987

Epoch: 6| Step: 4
Training loss: 0.9403340816497803
Validation loss: 1.9442613996485227

Epoch: 6| Step: 5
Training loss: 2.0413222312927246
Validation loss: 1.8969502884854552

Epoch: 6| Step: 6
Training loss: 1.7302186489105225
Validation loss: 1.9074604024169266

Epoch: 6| Step: 7
Training loss: 1.7705644369125366
Validation loss: 1.919765672376079

Epoch: 6| Step: 8
Training loss: 1.0568711757659912
Validation loss: 1.9191533032283987

Epoch: 6| Step: 9
Training loss: 0.9196481108665466
Validation loss: 1.9083134769111552

Epoch: 6| Step: 10
Training loss: 2.6002755165100098
Validation loss: 1.9012902398263254

Epoch: 6| Step: 11
Training loss: 1.2172554731369019
Validation loss: 1.8528669354736165

Epoch: 6| Step: 12
Training loss: 1.505835771560669
Validation loss: 1.8999212377814836

Epoch: 6| Step: 13
Training loss: 2.298720121383667
Validation loss: 1.8473902953568326

Epoch: 229| Step: 0
Training loss: 1.614397406578064
Validation loss: 1.8725935592446277

Epoch: 6| Step: 1
Training loss: 1.3206195831298828
Validation loss: 1.8744251433239187

Epoch: 6| Step: 2
Training loss: 1.5533565282821655
Validation loss: 1.905535105736025

Epoch: 6| Step: 3
Training loss: 1.5791982412338257
Validation loss: 1.9105566163216867

Epoch: 6| Step: 4
Training loss: 1.3576676845550537
Validation loss: 1.9143867338857343

Epoch: 6| Step: 5
Training loss: 1.8147706985473633
Validation loss: 1.8989205719322286

Epoch: 6| Step: 6
Training loss: 1.4734004735946655
Validation loss: 1.9235947439747472

Epoch: 6| Step: 7
Training loss: 1.8110237121582031
Validation loss: 1.942621487443165

Epoch: 6| Step: 8
Training loss: 1.6965821981430054
Validation loss: 1.9247096353961575

Epoch: 6| Step: 9
Training loss: 1.6482739448547363
Validation loss: 1.9377381852878037

Epoch: 6| Step: 10
Training loss: 1.8639070987701416
Validation loss: 1.9254249449699157

Epoch: 6| Step: 11
Training loss: 2.1005616188049316
Validation loss: 1.9746681823525378

Epoch: 6| Step: 12
Training loss: 1.8304208517074585
Validation loss: 1.9674535489851428

Epoch: 6| Step: 13
Training loss: 2.213596820831299
Validation loss: 1.9600108054376417

Epoch: 230| Step: 0
Training loss: 1.6018953323364258
Validation loss: 1.9245692094167073

Epoch: 6| Step: 1
Training loss: 1.7768256664276123
Validation loss: 1.9244212694065546

Epoch: 6| Step: 2
Training loss: 1.6795889139175415
Validation loss: 1.9235514607480777

Epoch: 6| Step: 3
Training loss: 2.1608846187591553
Validation loss: 1.9184757432629984

Epoch: 6| Step: 4
Training loss: 1.8272278308868408
Validation loss: 1.9564856111362416

Epoch: 6| Step: 5
Training loss: 2.0522212982177734
Validation loss: 1.9416830488430556

Epoch: 6| Step: 6
Training loss: 1.5006320476531982
Validation loss: 1.9349047394209011

Epoch: 6| Step: 7
Training loss: 1.252005696296692
Validation loss: 1.906750843089114

Epoch: 6| Step: 8
Training loss: 1.5686140060424805
Validation loss: 1.8771480501339

Epoch: 6| Step: 9
Training loss: 1.6211321353912354
Validation loss: 1.891666881499752

Epoch: 6| Step: 10
Training loss: 1.539567232131958
Validation loss: 1.9218919251554756

Epoch: 6| Step: 11
Training loss: 1.7023371458053589
Validation loss: 1.939919674268333

Epoch: 6| Step: 12
Training loss: 1.1745219230651855
Validation loss: 1.8988870843764274

Epoch: 6| Step: 13
Training loss: 1.7171330451965332
Validation loss: 1.8712267798762168

Epoch: 231| Step: 0
Training loss: 1.4023736715316772
Validation loss: 1.909498813331768

Epoch: 6| Step: 1
Training loss: 2.2860591411590576
Validation loss: 1.9191514932981102

Epoch: 6| Step: 2
Training loss: 1.7712304592132568
Validation loss: 1.9032151058156004

Epoch: 6| Step: 3
Training loss: 1.9141416549682617
Validation loss: 1.8912935154412382

Epoch: 6| Step: 4
Training loss: 1.2018718719482422
Validation loss: 1.857992035086437

Epoch: 6| Step: 5
Training loss: 1.3273041248321533
Validation loss: 1.9144803734235867

Epoch: 6| Step: 6
Training loss: 1.8469922542572021
Validation loss: 1.8822840106102727

Epoch: 6| Step: 7
Training loss: 1.2472410202026367
Validation loss: 1.8857685622348581

Epoch: 6| Step: 8
Training loss: 1.741799235343933
Validation loss: 1.8960343253227971

Epoch: 6| Step: 9
Training loss: 1.7528572082519531
Validation loss: 1.9408604560359832

Epoch: 6| Step: 10
Training loss: 1.7606937885284424
Validation loss: 1.9192357076111661

Epoch: 6| Step: 11
Training loss: 1.1985974311828613
Validation loss: 1.916663041678808

Epoch: 6| Step: 12
Training loss: 1.8892256021499634
Validation loss: 1.9211403503212878

Epoch: 6| Step: 13
Training loss: 2.323603630065918
Validation loss: 1.903523209274456

Epoch: 232| Step: 0
Training loss: 2.127439498901367
Validation loss: 1.961787114861191

Epoch: 6| Step: 1
Training loss: 1.6607474088668823
Validation loss: 1.9422427210756528

Epoch: 6| Step: 2
Training loss: 1.775091290473938
Validation loss: 1.9124754077644759

Epoch: 6| Step: 3
Training loss: 1.460146188735962
Validation loss: 1.911335559301479

Epoch: 6| Step: 4
Training loss: 1.6087017059326172
Validation loss: 1.925967207518957

Epoch: 6| Step: 5
Training loss: 1.5561631917953491
Validation loss: 1.924175605979017

Epoch: 6| Step: 6
Training loss: 2.09578537940979
Validation loss: 1.9088278047500118

Epoch: 6| Step: 7
Training loss: 1.5700209140777588
Validation loss: 1.9020141081143451

Epoch: 6| Step: 8
Training loss: 0.9682737588882446
Validation loss: 1.9056550430995163

Epoch: 6| Step: 9
Training loss: 2.2210097312927246
Validation loss: 1.8424610258430563

Epoch: 6| Step: 10
Training loss: 1.5130274295806885
Validation loss: 1.8991758477303289

Epoch: 6| Step: 11
Training loss: 1.665926456451416
Validation loss: 1.8727262173929522

Epoch: 6| Step: 12
Training loss: 1.7171592712402344
Validation loss: 1.928353496777114

Epoch: 6| Step: 13
Training loss: 1.6105093955993652
Validation loss: 1.8594720248253114

Epoch: 233| Step: 0
Training loss: 1.5145517587661743
Validation loss: 1.8958548499691872

Epoch: 6| Step: 1
Training loss: 1.689447045326233
Validation loss: 1.8867573968825802

Epoch: 6| Step: 2
Training loss: 0.9043640494346619
Validation loss: 1.883569989153134

Epoch: 6| Step: 3
Training loss: 1.1788170337677002
Validation loss: 1.9050353137395715

Epoch: 6| Step: 4
Training loss: 1.503256916999817
Validation loss: 1.8907272649067703

Epoch: 6| Step: 5
Training loss: 2.0603766441345215
Validation loss: 1.9266896029954315

Epoch: 6| Step: 6
Training loss: 1.4197643995285034
Validation loss: 1.905856365798622

Epoch: 6| Step: 7
Training loss: 2.0676417350769043
Validation loss: 1.8849176104350756

Epoch: 6| Step: 8
Training loss: 2.311112403869629
Validation loss: 1.9080728151464974

Epoch: 6| Step: 9
Training loss: 1.9297538995742798
Validation loss: 1.9304393683710406

Epoch: 6| Step: 10
Training loss: 1.8373132944107056
Validation loss: 1.942529365580569

Epoch: 6| Step: 11
Training loss: 1.673015832901001
Validation loss: 1.9535097973321074

Epoch: 6| Step: 12
Training loss: 1.4197012186050415
Validation loss: 1.9288478282190138

Epoch: 6| Step: 13
Training loss: 1.6043665409088135
Validation loss: 1.9177587878319524

Epoch: 234| Step: 0
Training loss: 2.0405118465423584
Validation loss: 1.8860082062341834

Epoch: 6| Step: 1
Training loss: 1.625013828277588
Validation loss: 1.899463789437407

Epoch: 6| Step: 2
Training loss: 1.9054031372070312
Validation loss: 1.9044041787424395

Epoch: 6| Step: 3
Training loss: 1.178157091140747
Validation loss: 1.8887920302729453

Epoch: 6| Step: 4
Training loss: 2.2621278762817383
Validation loss: 1.8805435460100892

Epoch: 6| Step: 5
Training loss: 2.0060007572174072
Validation loss: 1.8838454369575746

Epoch: 6| Step: 6
Training loss: 1.8657883405685425
Validation loss: 1.8862788831034014

Epoch: 6| Step: 7
Training loss: 1.797776460647583
Validation loss: 1.9032587953793105

Epoch: 6| Step: 8
Training loss: 1.7432607412338257
Validation loss: 1.9000465267448015

Epoch: 6| Step: 9
Training loss: 1.5373153686523438
Validation loss: 1.891680557240722

Epoch: 6| Step: 10
Training loss: 1.2309643030166626
Validation loss: 1.8745965214185818

Epoch: 6| Step: 11
Training loss: 1.5025665760040283
Validation loss: 1.901396491194284

Epoch: 6| Step: 12
Training loss: 1.120781660079956
Validation loss: 1.8849260601946103

Epoch: 6| Step: 13
Training loss: 1.8127318620681763
Validation loss: 1.9080022842653337

Epoch: 235| Step: 0
Training loss: 1.632847785949707
Validation loss: 1.8364947175466886

Epoch: 6| Step: 1
Training loss: 2.5133848190307617
Validation loss: 1.8573912266762025

Epoch: 6| Step: 2
Training loss: 1.2988241910934448
Validation loss: 1.8731533891411238

Epoch: 6| Step: 3
Training loss: 1.5467324256896973
Validation loss: 1.8812989419506443

Epoch: 6| Step: 4
Training loss: 1.8957287073135376
Validation loss: 1.914440744666643

Epoch: 6| Step: 5
Training loss: 1.0154502391815186
Validation loss: 1.9012272742486769

Epoch: 6| Step: 6
Training loss: 1.938995361328125
Validation loss: 1.8692486927073488

Epoch: 6| Step: 7
Training loss: 1.866553783416748
Validation loss: 1.8859376189529256

Epoch: 6| Step: 8
Training loss: 1.85977041721344
Validation loss: 1.9246356359092138

Epoch: 6| Step: 9
Training loss: 0.703995406627655
Validation loss: 1.8822606212349349

Epoch: 6| Step: 10
Training loss: 1.505695104598999
Validation loss: 1.874620904204666

Epoch: 6| Step: 11
Training loss: 1.3705508708953857
Validation loss: 1.8970839784991356

Epoch: 6| Step: 12
Training loss: 2.1442413330078125
Validation loss: 1.9390544622175154

Epoch: 6| Step: 13
Training loss: 2.0053486824035645
Validation loss: 1.8865144842414445

Epoch: 236| Step: 0
Training loss: 0.8999346494674683
Validation loss: 1.8490814021838609

Epoch: 6| Step: 1
Training loss: 1.7354170083999634
Validation loss: 1.9216982305690806

Epoch: 6| Step: 2
Training loss: 1.1568655967712402
Validation loss: 1.8720503673758557

Epoch: 6| Step: 3
Training loss: 1.9216872453689575
Validation loss: 1.8952447060615785

Epoch: 6| Step: 4
Training loss: 1.4083253145217896
Validation loss: 1.9173851795093988

Epoch: 6| Step: 5
Training loss: 0.8374720811843872
Validation loss: 1.8839165331214986

Epoch: 6| Step: 6
Training loss: 1.919689655303955
Validation loss: 1.9153569923934115

Epoch: 6| Step: 7
Training loss: 1.4773889780044556
Validation loss: 1.9208591676527453

Epoch: 6| Step: 8
Training loss: 2.5565996170043945
Validation loss: 1.9183327408247097

Epoch: 6| Step: 9
Training loss: 2.07767915725708
Validation loss: 1.9347467730122228

Epoch: 6| Step: 10
Training loss: 1.022193431854248
Validation loss: 1.8930930847762732

Epoch: 6| Step: 11
Training loss: 2.019869089126587
Validation loss: 1.9180613025542228

Epoch: 6| Step: 12
Training loss: 2.2283029556274414
Validation loss: 1.8748283052957186

Epoch: 6| Step: 13
Training loss: 2.158450126647949
Validation loss: 1.894966197270219

Epoch: 237| Step: 0
Training loss: 1.8157601356506348
Validation loss: 1.8935230214108703

Epoch: 6| Step: 1
Training loss: 2.2029762268066406
Validation loss: 1.884029588391704

Epoch: 6| Step: 2
Training loss: 1.220167875289917
Validation loss: 1.8830643392378283

Epoch: 6| Step: 3
Training loss: 1.65941321849823
Validation loss: 1.8906711878315094

Epoch: 6| Step: 4
Training loss: 0.9813544750213623
Validation loss: 1.887168276694513

Epoch: 6| Step: 5
Training loss: 1.725356101989746
Validation loss: 1.9416979307769446

Epoch: 6| Step: 6
Training loss: 2.0618107318878174
Validation loss: 1.8989684812484249

Epoch: 6| Step: 7
Training loss: 1.3335940837860107
Validation loss: 1.906359334145823

Epoch: 6| Step: 8
Training loss: 1.7972195148468018
Validation loss: 1.8971823646176247

Epoch: 6| Step: 9
Training loss: 1.604327917098999
Validation loss: 1.8483052163995721

Epoch: 6| Step: 10
Training loss: 1.7190179824829102
Validation loss: 1.901015958478374

Epoch: 6| Step: 11
Training loss: 2.1083104610443115
Validation loss: 1.884555729486609

Epoch: 6| Step: 12
Training loss: 1.1636803150177002
Validation loss: 1.860267564814578

Epoch: 6| Step: 13
Training loss: 1.7447776794433594
Validation loss: 1.8894212733032882

Epoch: 238| Step: 0
Training loss: 1.4347666501998901
Validation loss: 1.9072514028959378

Epoch: 6| Step: 1
Training loss: 1.980420470237732
Validation loss: 1.9007790345017628

Epoch: 6| Step: 2
Training loss: 1.7906451225280762
Validation loss: 1.8899899169962893

Epoch: 6| Step: 3
Training loss: 1.489981770515442
Validation loss: 1.934160461989782

Epoch: 6| Step: 4
Training loss: 2.2815499305725098
Validation loss: 1.937123562700005

Epoch: 6| Step: 5
Training loss: 1.9156219959259033
Validation loss: 1.885645043465399

Epoch: 6| Step: 6
Training loss: 0.9660670757293701
Validation loss: 1.8684141469258133

Epoch: 6| Step: 7
Training loss: 1.2342967987060547
Validation loss: 1.8545946574980212

Epoch: 6| Step: 8
Training loss: 1.583756685256958
Validation loss: 1.9288146188182216

Epoch: 6| Step: 9
Training loss: 1.0044598579406738
Validation loss: 1.909848120904738

Epoch: 6| Step: 10
Training loss: 1.4361016750335693
Validation loss: 1.898001359355065

Epoch: 6| Step: 11
Training loss: 1.7485637664794922
Validation loss: 1.9174976989787111

Epoch: 6| Step: 12
Training loss: 2.0940990447998047
Validation loss: 1.8707725130101687

Epoch: 6| Step: 13
Training loss: 1.8791402578353882
Validation loss: 1.9083022712379374

Epoch: 239| Step: 0
Training loss: 1.8571412563323975
Validation loss: 1.9069433571189962

Epoch: 6| Step: 1
Training loss: 1.7140443325042725
Validation loss: 1.9234987112783617

Epoch: 6| Step: 2
Training loss: 1.9115839004516602
Validation loss: 1.8774330897997784

Epoch: 6| Step: 3
Training loss: 2.298231363296509
Validation loss: 1.9171660946261497

Epoch: 6| Step: 4
Training loss: 1.4750661849975586
Validation loss: 1.8736657557948944

Epoch: 6| Step: 5
Training loss: 1.3332586288452148
Validation loss: 1.8757534168099845

Epoch: 6| Step: 6
Training loss: 1.7330738306045532
Validation loss: 1.8733628078173565

Epoch: 6| Step: 7
Training loss: 1.050887107849121
Validation loss: 1.8992006983808292

Epoch: 6| Step: 8
Training loss: 1.7632415294647217
Validation loss: 1.9057725578226068

Epoch: 6| Step: 9
Training loss: 2.0308947563171387
Validation loss: 1.898838145758516

Epoch: 6| Step: 10
Training loss: 1.0518115758895874
Validation loss: 1.9019773352530696

Epoch: 6| Step: 11
Training loss: 1.6141111850738525
Validation loss: 1.887208043888051

Epoch: 6| Step: 12
Training loss: 1.1227061748504639
Validation loss: 1.9321395633041218

Epoch: 6| Step: 13
Training loss: 1.73192298412323
Validation loss: 1.9041287476016628

Epoch: 240| Step: 0
Training loss: 2.6701207160949707
Validation loss: 1.9208239996305077

Epoch: 6| Step: 1
Training loss: 2.0723447799682617
Validation loss: 1.8898134680204495

Epoch: 6| Step: 2
Training loss: 2.1118388175964355
Validation loss: 1.8851155375921598

Epoch: 6| Step: 3
Training loss: 1.481704592704773
Validation loss: 1.891043706606793

Epoch: 6| Step: 4
Training loss: 0.7889363169670105
Validation loss: 1.9016041448039394

Epoch: 6| Step: 5
Training loss: 1.004089593887329
Validation loss: 1.8989178173003658

Epoch: 6| Step: 6
Training loss: 0.9730914235115051
Validation loss: 1.9213610810618247

Epoch: 6| Step: 7
Training loss: 2.011259078979492
Validation loss: 1.8658855410032376

Epoch: 6| Step: 8
Training loss: 1.6871695518493652
Validation loss: 1.8466817666125555

Epoch: 6| Step: 9
Training loss: 1.5254952907562256
Validation loss: 1.8553332615924139

Epoch: 6| Step: 10
Training loss: 1.4310245513916016
Validation loss: 1.840401872511833

Epoch: 6| Step: 11
Training loss: 1.6094210147857666
Validation loss: 1.8892034484494118

Epoch: 6| Step: 12
Training loss: 1.647454023361206
Validation loss: 1.888790527979533

Epoch: 6| Step: 13
Training loss: 2.2505085468292236
Validation loss: 1.8772530632634317

Epoch: 241| Step: 0
Training loss: 1.4670934677124023
Validation loss: 1.8708434976557249

Epoch: 6| Step: 1
Training loss: 1.138720989227295
Validation loss: 1.882265515224908

Epoch: 6| Step: 2
Training loss: 0.9214747548103333
Validation loss: 1.8970878662601594

Epoch: 6| Step: 3
Training loss: 1.5720949172973633
Validation loss: 1.9103728955791843

Epoch: 6| Step: 4
Training loss: 1.3560798168182373
Validation loss: 1.9256553624265937

Epoch: 6| Step: 5
Training loss: 2.1346445083618164
Validation loss: 1.925514777501424

Epoch: 6| Step: 6
Training loss: 2.4960505962371826
Validation loss: 1.91260402946062

Epoch: 6| Step: 7
Training loss: 2.597872495651245
Validation loss: 1.866355485813592

Epoch: 6| Step: 8
Training loss: 1.587902307510376
Validation loss: 1.854296963701966

Epoch: 6| Step: 9
Training loss: 2.0786867141723633
Validation loss: 1.8969297293693788

Epoch: 6| Step: 10
Training loss: 1.0231680870056152
Validation loss: 1.9219141724289104

Epoch: 6| Step: 11
Training loss: 1.4900912046432495
Validation loss: 1.91895241250274

Epoch: 6| Step: 12
Training loss: 1.2535388469696045
Validation loss: 1.9193180235483314

Epoch: 6| Step: 13
Training loss: 1.9035186767578125
Validation loss: 1.8764984197514032

Epoch: 242| Step: 0
Training loss: 1.536595344543457
Validation loss: 1.8827088750818723

Epoch: 6| Step: 1
Training loss: 1.7697792053222656
Validation loss: 1.9032989612189672

Epoch: 6| Step: 2
Training loss: 1.7550816535949707
Validation loss: 1.8690272223564885

Epoch: 6| Step: 3
Training loss: 1.4331979751586914
Validation loss: 1.888575210366198

Epoch: 6| Step: 4
Training loss: 1.5512580871582031
Validation loss: 1.8812131189530896

Epoch: 6| Step: 5
Training loss: 1.243825912475586
Validation loss: 1.8782323765498337

Epoch: 6| Step: 6
Training loss: 1.9658188819885254
Validation loss: 1.8577043805071103

Epoch: 6| Step: 7
Training loss: 1.5399775505065918
Validation loss: 1.857613419973722

Epoch: 6| Step: 8
Training loss: 1.3049824237823486
Validation loss: 1.8798051444433068

Epoch: 6| Step: 9
Training loss: 2.457973003387451
Validation loss: 1.8913326237791328

Epoch: 6| Step: 10
Training loss: 1.558854341506958
Validation loss: 1.8755949440822806

Epoch: 6| Step: 11
Training loss: 1.911412239074707
Validation loss: 1.894264648037572

Epoch: 6| Step: 12
Training loss: 1.6157146692276
Validation loss: 1.8657710616306593

Epoch: 6| Step: 13
Training loss: 1.3564565181732178
Validation loss: 1.8798440425626692

Epoch: 243| Step: 0
Training loss: 1.6646990776062012
Validation loss: 1.9204567478549095

Epoch: 6| Step: 1
Training loss: 1.6520493030548096
Validation loss: 1.8796608050664265

Epoch: 6| Step: 2
Training loss: 1.4461071491241455
Validation loss: 1.9360365149795369

Epoch: 6| Step: 3
Training loss: 1.8245055675506592
Validation loss: 1.9315406263515513

Epoch: 6| Step: 4
Training loss: 0.8705577850341797
Validation loss: 1.9403654683020808

Epoch: 6| Step: 5
Training loss: 1.5240727663040161
Validation loss: 1.9209476645274828

Epoch: 6| Step: 6
Training loss: 2.1110618114471436
Validation loss: 1.9196119000834804

Epoch: 6| Step: 7
Training loss: 1.9993128776550293
Validation loss: 1.9050955810854513

Epoch: 6| Step: 8
Training loss: 0.9231142997741699
Validation loss: 1.980003459479219

Epoch: 6| Step: 9
Training loss: 1.9057972431182861
Validation loss: 1.9085370494473366

Epoch: 6| Step: 10
Training loss: 2.4541311264038086
Validation loss: 1.9171574243935205

Epoch: 6| Step: 11
Training loss: 1.6418328285217285
Validation loss: 1.9078345798677014

Epoch: 6| Step: 12
Training loss: 1.423863172531128
Validation loss: 1.9095086051571755

Epoch: 6| Step: 13
Training loss: 0.9911696314811707
Validation loss: 1.9028060705431047

Epoch: 244| Step: 0
Training loss: 1.3054008483886719
Validation loss: 1.8968497219906058

Epoch: 6| Step: 1
Training loss: 1.7523887157440186
Validation loss: 1.901374545148624

Epoch: 6| Step: 2
Training loss: 1.5387611389160156
Validation loss: 1.881726111135175

Epoch: 6| Step: 3
Training loss: 1.922527551651001
Validation loss: 1.907467931829473

Epoch: 6| Step: 4
Training loss: 1.817360281944275
Validation loss: 1.880158438477465

Epoch: 6| Step: 5
Training loss: 1.4329100847244263
Validation loss: 1.853161891301473

Epoch: 6| Step: 6
Training loss: 2.4489479064941406
Validation loss: 1.9205937898287209

Epoch: 6| Step: 7
Training loss: 1.4665136337280273
Validation loss: 1.8896211821545836

Epoch: 6| Step: 8
Training loss: 1.8163776397705078
Validation loss: 1.8911408493595738

Epoch: 6| Step: 9
Training loss: 1.1926162242889404
Validation loss: 1.8989077486017698

Epoch: 6| Step: 10
Training loss: 1.331627607345581
Validation loss: 1.9052838317809566

Epoch: 6| Step: 11
Training loss: 1.5659104585647583
Validation loss: 1.8689310268689228

Epoch: 6| Step: 12
Training loss: 2.1174042224884033
Validation loss: 1.9429027906028173

Epoch: 6| Step: 13
Training loss: 1.2159628868103027
Validation loss: 1.909577456853723

Epoch: 245| Step: 0
Training loss: 1.6709175109863281
Validation loss: 1.893214141168902

Epoch: 6| Step: 1
Training loss: 1.6462132930755615
Validation loss: 1.8931222833612913

Epoch: 6| Step: 2
Training loss: 1.3420192003250122
Validation loss: 1.9414607568453717

Epoch: 6| Step: 3
Training loss: 1.815904974937439
Validation loss: 1.8685157247768935

Epoch: 6| Step: 4
Training loss: 1.767474889755249
Validation loss: 1.8888452552979993

Epoch: 6| Step: 5
Training loss: 1.5491279363632202
Validation loss: 1.9210755799406318

Epoch: 6| Step: 6
Training loss: 0.9419273138046265
Validation loss: 1.9025509088270125

Epoch: 6| Step: 7
Training loss: 1.7048993110656738
Validation loss: 1.8936669403506863

Epoch: 6| Step: 8
Training loss: 2.127753973007202
Validation loss: 1.8961396114800566

Epoch: 6| Step: 9
Training loss: 1.2043302059173584
Validation loss: 1.8962529961780836

Epoch: 6| Step: 10
Training loss: 1.393393635749817
Validation loss: 1.8924939632415771

Epoch: 6| Step: 11
Training loss: 1.96754789352417
Validation loss: 1.9139664224399033

Epoch: 6| Step: 12
Training loss: 2.2599101066589355
Validation loss: 1.884949073996595

Epoch: 6| Step: 13
Training loss: 1.1786956787109375
Validation loss: 1.9089442940168484

Epoch: 246| Step: 0
Training loss: 2.2238404750823975
Validation loss: 1.9101587239132132

Epoch: 6| Step: 1
Training loss: 1.999288558959961
Validation loss: 1.8747913683614423

Epoch: 6| Step: 2
Training loss: 1.646166205406189
Validation loss: 1.9318497552666614

Epoch: 6| Step: 3
Training loss: 0.9257411360740662
Validation loss: 1.9302460442307174

Epoch: 6| Step: 4
Training loss: 1.2233505249023438
Validation loss: 1.8881448686763804

Epoch: 6| Step: 5
Training loss: 1.347348690032959
Validation loss: 1.8795489700891639

Epoch: 6| Step: 6
Training loss: 2.039459705352783
Validation loss: 1.9297233807143344

Epoch: 6| Step: 7
Training loss: 1.5074455738067627
Validation loss: 1.8938370058613438

Epoch: 6| Step: 8
Training loss: 1.8545329570770264
Validation loss: 1.8783016986744379

Epoch: 6| Step: 9
Training loss: 1.445645809173584
Validation loss: 1.8840141078477264

Epoch: 6| Step: 10
Training loss: 0.9422130584716797
Validation loss: 1.9389969982126707

Epoch: 6| Step: 11
Training loss: 1.8953191041946411
Validation loss: 1.9279020999067573

Epoch: 6| Step: 12
Training loss: 1.9838361740112305
Validation loss: 1.9155670699252878

Epoch: 6| Step: 13
Training loss: 1.3085359334945679
Validation loss: 1.9137466633191673

Epoch: 247| Step: 0
Training loss: 1.591471552848816
Validation loss: 1.9398612719710155

Epoch: 6| Step: 1
Training loss: 1.8828096389770508
Validation loss: 1.9170664266873432

Epoch: 6| Step: 2
Training loss: 1.9420827627182007
Validation loss: 1.9353186571469871

Epoch: 6| Step: 3
Training loss: 1.5589027404785156
Validation loss: 1.9228030033009027

Epoch: 6| Step: 4
Training loss: 1.3873367309570312
Validation loss: 1.9244296717387375

Epoch: 6| Step: 5
Training loss: 1.6378438472747803
Validation loss: 1.9085628691539969

Epoch: 6| Step: 6
Training loss: 2.121368408203125
Validation loss: 1.9304651906413417

Epoch: 6| Step: 7
Training loss: 1.4016728401184082
Validation loss: 1.8713604122079828

Epoch: 6| Step: 8
Training loss: 1.1185485124588013
Validation loss: 1.8872479059362923

Epoch: 6| Step: 9
Training loss: 1.6728849411010742
Validation loss: 1.9438171566173594

Epoch: 6| Step: 10
Training loss: 2.258366107940674
Validation loss: 1.922924445521447

Epoch: 6| Step: 11
Training loss: 1.4674009084701538
Validation loss: 1.8661428420774397

Epoch: 6| Step: 12
Training loss: 1.186535358428955
Validation loss: 1.907396529310493

Epoch: 6| Step: 13
Training loss: 1.4824366569519043
Validation loss: 1.8958875107508835

Epoch: 248| Step: 0
Training loss: 1.195580244064331
Validation loss: 1.867850608723138

Epoch: 6| Step: 1
Training loss: 1.261565923690796
Validation loss: 1.8936070549872615

Epoch: 6| Step: 2
Training loss: 1.8202892541885376
Validation loss: 1.9101570062739874

Epoch: 6| Step: 3
Training loss: 1.7024335861206055
Validation loss: 1.8907973727872294

Epoch: 6| Step: 4
Training loss: 2.0369739532470703
Validation loss: 1.8858657319058654

Epoch: 6| Step: 5
Training loss: 2.2059507369995117
Validation loss: 1.9308736426855928

Epoch: 6| Step: 6
Training loss: 1.7746202945709229
Validation loss: 1.8711894353230794

Epoch: 6| Step: 7
Training loss: 1.5646345615386963
Validation loss: 1.9015014979147142

Epoch: 6| Step: 8
Training loss: 1.5476124286651611
Validation loss: 1.8895918451329714

Epoch: 6| Step: 9
Training loss: 2.095219850540161
Validation loss: 1.9276766571947324

Epoch: 6| Step: 10
Training loss: 1.5308417081832886
Validation loss: 1.8887980048374464

Epoch: 6| Step: 11
Training loss: 0.905146598815918
Validation loss: 1.951052899001747

Epoch: 6| Step: 12
Training loss: 1.7857954502105713
Validation loss: 1.9380992407439857

Epoch: 6| Step: 13
Training loss: 1.238986849784851
Validation loss: 1.941483615547098

Epoch: 249| Step: 0
Training loss: 1.0367891788482666
Validation loss: 1.9246342925615207

Epoch: 6| Step: 1
Training loss: 0.8283457159996033
Validation loss: 1.91291348139445

Epoch: 6| Step: 2
Training loss: 1.5829135179519653
Validation loss: 1.921702782313029

Epoch: 6| Step: 3
Training loss: 1.5160744190216064
Validation loss: 1.890763021284534

Epoch: 6| Step: 4
Training loss: 2.1906204223632812
Validation loss: 1.8763800949178717

Epoch: 6| Step: 5
Training loss: 1.6009366512298584
Validation loss: 1.8413311230239047

Epoch: 6| Step: 6
Training loss: 1.6868391036987305
Validation loss: 1.883210382153911

Epoch: 6| Step: 7
Training loss: 1.5790503025054932
Validation loss: 1.8570688745026946

Epoch: 6| Step: 8
Training loss: 1.9452285766601562
Validation loss: 1.886501641683681

Epoch: 6| Step: 9
Training loss: 1.7794301509857178
Validation loss: 1.9251798045250677

Epoch: 6| Step: 10
Training loss: 2.083651065826416
Validation loss: 1.9056581015227942

Epoch: 6| Step: 11
Training loss: 1.8903545141220093
Validation loss: 1.8673033022111463

Epoch: 6| Step: 12
Training loss: 1.2698824405670166
Validation loss: 1.927049086939904

Epoch: 6| Step: 13
Training loss: 1.8682206869125366
Validation loss: 1.879004572027473

Epoch: 250| Step: 0
Training loss: 2.0914971828460693
Validation loss: 1.9114416260873117

Epoch: 6| Step: 1
Training loss: 1.823870062828064
Validation loss: 1.8963166026658909

Epoch: 6| Step: 2
Training loss: 1.7752033472061157
Validation loss: 1.905006726582845

Epoch: 6| Step: 3
Training loss: 1.5197505950927734
Validation loss: 1.914771596590678

Epoch: 6| Step: 4
Training loss: 1.289975881576538
Validation loss: 1.8899466645333074

Epoch: 6| Step: 5
Training loss: 1.997382640838623
Validation loss: 1.924531723863335

Epoch: 6| Step: 6
Training loss: 1.1519873142242432
Validation loss: 1.9530327550826534

Epoch: 6| Step: 7
Training loss: 0.9967393279075623
Validation loss: 1.8928166461247269

Epoch: 6| Step: 8
Training loss: 1.766953468322754
Validation loss: 1.9077384856439406

Epoch: 6| Step: 9
Training loss: 1.720052719116211
Validation loss: 1.863845238121607

Epoch: 6| Step: 10
Training loss: 1.8063437938690186
Validation loss: 1.9228007190970964

Epoch: 6| Step: 11
Training loss: 1.5324733257293701
Validation loss: 1.882422883023498

Epoch: 6| Step: 12
Training loss: 1.3243138790130615
Validation loss: 1.8873945487442838

Epoch: 6| Step: 13
Training loss: 2.3012075424194336
Validation loss: 1.91021361402286

Epoch: 251| Step: 0
Training loss: 1.7499748468399048
Validation loss: 1.8830434096756803

Epoch: 6| Step: 1
Training loss: 1.8669918775558472
Validation loss: 1.9014448965749433

Epoch: 6| Step: 2
Training loss: 1.440330982208252
Validation loss: 1.9065215433797529

Epoch: 6| Step: 3
Training loss: 1.2046363353729248
Validation loss: 1.8905140584514988

Epoch: 6| Step: 4
Training loss: 1.3564612865447998
Validation loss: 1.9291655273847683

Epoch: 6| Step: 5
Training loss: 1.5269572734832764
Validation loss: 1.927342632765411

Epoch: 6| Step: 6
Training loss: 1.3841238021850586
Validation loss: 1.9072721568487023

Epoch: 6| Step: 7
Training loss: 2.127272605895996
Validation loss: 1.8924600462759695

Epoch: 6| Step: 8
Training loss: 1.5614967346191406
Validation loss: 1.9037616586172452

Epoch: 6| Step: 9
Training loss: 1.4639317989349365
Validation loss: 1.9133113763665641

Epoch: 6| Step: 10
Training loss: 1.9528034925460815
Validation loss: 1.9064054771136212

Epoch: 6| Step: 11
Training loss: 1.6782647371292114
Validation loss: 1.9006100252110472

Epoch: 6| Step: 12
Training loss: 1.6303043365478516
Validation loss: 1.953914479542804

Epoch: 6| Step: 13
Training loss: 1.934980869293213
Validation loss: 1.9013583711398545

Epoch: 252| Step: 0
Training loss: 2.0711209774017334
Validation loss: 1.9216409908827914

Epoch: 6| Step: 1
Training loss: 1.3991506099700928
Validation loss: 1.8993458094135407

Epoch: 6| Step: 2
Training loss: 1.763047218322754
Validation loss: 1.8808657507742605

Epoch: 6| Step: 3
Training loss: 1.1773903369903564
Validation loss: 1.8816372912417176

Epoch: 6| Step: 4
Training loss: 1.713082194328308
Validation loss: 1.870849355574577

Epoch: 6| Step: 5
Training loss: 2.2434558868408203
Validation loss: 1.9177680451382872

Epoch: 6| Step: 6
Training loss: 1.8209426403045654
Validation loss: 1.891539550596668

Epoch: 6| Step: 7
Training loss: 1.1777904033660889
Validation loss: 1.8725371758143108

Epoch: 6| Step: 8
Training loss: 2.3022472858428955
Validation loss: 1.9024114160127537

Epoch: 6| Step: 9
Training loss: 1.1633092164993286
Validation loss: 1.933719818310071

Epoch: 6| Step: 10
Training loss: 1.3886470794677734
Validation loss: 1.8385462684016074

Epoch: 6| Step: 11
Training loss: 1.1866014003753662
Validation loss: 1.9272877670103503

Epoch: 6| Step: 12
Training loss: 1.3593854904174805
Validation loss: 1.9266751991805209

Epoch: 6| Step: 13
Training loss: 1.923642635345459
Validation loss: 1.902967619639571

Epoch: 253| Step: 0
Training loss: 2.07723331451416
Validation loss: 1.9163698714266542

Epoch: 6| Step: 1
Training loss: 1.602370023727417
Validation loss: 1.9460211261626212

Epoch: 6| Step: 2
Training loss: 1.4070470333099365
Validation loss: 1.9132254008323915

Epoch: 6| Step: 3
Training loss: 2.11285400390625
Validation loss: 1.894708728277555

Epoch: 6| Step: 4
Training loss: 1.3379255533218384
Validation loss: 1.8835856017246042

Epoch: 6| Step: 5
Training loss: 1.9216656684875488
Validation loss: 1.928870084465191

Epoch: 6| Step: 6
Training loss: 0.9801228046417236
Validation loss: 1.9006345977065384

Epoch: 6| Step: 7
Training loss: 1.11427903175354
Validation loss: 1.8938686168321999

Epoch: 6| Step: 8
Training loss: 1.3415672779083252
Validation loss: 1.8618899160815823

Epoch: 6| Step: 9
Training loss: 1.8725652694702148
Validation loss: 1.88655125710272

Epoch: 6| Step: 10
Training loss: 1.6784461736679077
Validation loss: 1.9191045671380975

Epoch: 6| Step: 11
Training loss: 1.4375019073486328
Validation loss: 1.9244133349387877

Epoch: 6| Step: 12
Training loss: 1.8223704099655151
Validation loss: 1.8916306162393222

Epoch: 6| Step: 13
Training loss: 1.6967918872833252
Validation loss: 1.8983998067917363

Epoch: 254| Step: 0
Training loss: 2.117126941680908
Validation loss: 1.8545673072979014

Epoch: 6| Step: 1
Training loss: 1.6398897171020508
Validation loss: 1.8739968115283596

Epoch: 6| Step: 2
Training loss: 1.0990145206451416
Validation loss: 1.9021330084851993

Epoch: 6| Step: 3
Training loss: 2.312244415283203
Validation loss: 1.9138216895441855

Epoch: 6| Step: 4
Training loss: 1.2485406398773193
Validation loss: 1.8551887248152046

Epoch: 6| Step: 5
Training loss: 2.4901819229125977
Validation loss: 1.8698554679911623

Epoch: 6| Step: 6
Training loss: 1.0864760875701904
Validation loss: 1.871843045757663

Epoch: 6| Step: 7
Training loss: 0.5776952505111694
Validation loss: 1.919075587744354

Epoch: 6| Step: 8
Training loss: 1.996382236480713
Validation loss: 1.8700290867077407

Epoch: 6| Step: 9
Training loss: 1.2536786794662476
Validation loss: 1.920842493734052

Epoch: 6| Step: 10
Training loss: 2.3993124961853027
Validation loss: 1.8911017820399294

Epoch: 6| Step: 11
Training loss: 1.1218596696853638
Validation loss: 1.8532879660206456

Epoch: 6| Step: 12
Training loss: 1.844237208366394
Validation loss: 1.8771808557612921

Epoch: 6| Step: 13
Training loss: 1.339627742767334
Validation loss: 1.8862400260022891

Epoch: 255| Step: 0
Training loss: 0.9649333953857422
Validation loss: 1.8546331262075773

Epoch: 6| Step: 1
Training loss: 1.3065545558929443
Validation loss: 1.871090627485706

Epoch: 6| Step: 2
Training loss: 1.930551528930664
Validation loss: 1.9401985419693815

Epoch: 6| Step: 3
Training loss: 1.4467016458511353
Validation loss: 1.874700653937555

Epoch: 6| Step: 4
Training loss: 1.644103765487671
Validation loss: 1.8579220207788611

Epoch: 6| Step: 5
Training loss: 1.327943205833435
Validation loss: 1.84081514932776

Epoch: 6| Step: 6
Training loss: 1.5681352615356445
Validation loss: 1.8627974846029793

Epoch: 6| Step: 7
Training loss: 1.8350036144256592
Validation loss: 1.9297164652937202

Epoch: 6| Step: 8
Training loss: 1.4010933637619019
Validation loss: 1.888755468912022

Epoch: 6| Step: 9
Training loss: 1.6103522777557373
Validation loss: 1.8763107920205722

Epoch: 6| Step: 10
Training loss: 1.7406136989593506
Validation loss: 1.8894974006119596

Epoch: 6| Step: 11
Training loss: 1.7215760946273804
Validation loss: 1.8983270160613521

Epoch: 6| Step: 12
Training loss: 1.687889814376831
Validation loss: 1.930937882392637

Epoch: 6| Step: 13
Training loss: 2.0161099433898926
Validation loss: 1.9418391361031482

Epoch: 256| Step: 0
Training loss: 1.0740182399749756
Validation loss: 1.8970147653292584

Epoch: 6| Step: 1
Training loss: 2.067770004272461
Validation loss: 1.9199760434448079

Epoch: 6| Step: 2
Training loss: 0.9800428152084351
Validation loss: 1.8816916481141122

Epoch: 6| Step: 3
Training loss: 1.810725450515747
Validation loss: 1.8856778196109238

Epoch: 6| Step: 4
Training loss: 2.072542190551758
Validation loss: 1.9129175755285448

Epoch: 6| Step: 5
Training loss: 1.2187647819519043
Validation loss: 1.9403160695106751

Epoch: 6| Step: 6
Training loss: 1.0591797828674316
Validation loss: 1.9053310425050798

Epoch: 6| Step: 7
Training loss: 1.7129181623458862
Validation loss: 1.9150708413893176

Epoch: 6| Step: 8
Training loss: 1.9296199083328247
Validation loss: 1.8919038426491521

Epoch: 6| Step: 9
Training loss: 1.9952664375305176
Validation loss: 1.873352760909706

Epoch: 6| Step: 10
Training loss: 1.7036532163619995
Validation loss: 1.8640613632817422

Epoch: 6| Step: 11
Training loss: 1.1692417860031128
Validation loss: 1.8984586846443914

Epoch: 6| Step: 12
Training loss: 1.402536153793335
Validation loss: 1.876057776071692

Epoch: 6| Step: 13
Training loss: 2.6644582748413086
Validation loss: 1.8710032086218558

Epoch: 257| Step: 0
Training loss: 1.7967360019683838
Validation loss: 1.858160247084915

Epoch: 6| Step: 1
Training loss: 1.3623261451721191
Validation loss: 1.8972485783279582

Epoch: 6| Step: 2
Training loss: 1.307603120803833
Validation loss: 1.838422502240827

Epoch: 6| Step: 3
Training loss: 1.5249824523925781
Validation loss: 1.909580297367547

Epoch: 6| Step: 4
Training loss: 1.291090965270996
Validation loss: 1.8908591872902327

Epoch: 6| Step: 5
Training loss: 1.4708216190338135
Validation loss: 1.875674625878693

Epoch: 6| Step: 6
Training loss: 1.5283265113830566
Validation loss: 1.8968905043858353

Epoch: 6| Step: 7
Training loss: 1.4445276260375977
Validation loss: 1.8671082168497064

Epoch: 6| Step: 8
Training loss: 1.7204457521438599
Validation loss: 1.891172234730054

Epoch: 6| Step: 9
Training loss: 1.8730294704437256
Validation loss: 1.8906072249976538

Epoch: 6| Step: 10
Training loss: 2.309230327606201
Validation loss: 1.8689760956712949

Epoch: 6| Step: 11
Training loss: 1.5071196556091309
Validation loss: 1.879039285003498

Epoch: 6| Step: 12
Training loss: 1.4405303001403809
Validation loss: 1.862591169213736

Epoch: 6| Step: 13
Training loss: 1.7117702960968018
Validation loss: 1.906702172371649

Epoch: 258| Step: 0
Training loss: 1.8597491979599
Validation loss: 1.8429878527118313

Epoch: 6| Step: 1
Training loss: 1.0633244514465332
Validation loss: 1.8734370867411296

Epoch: 6| Step: 2
Training loss: 1.506621241569519
Validation loss: 1.8745622199068788

Epoch: 6| Step: 3
Training loss: 1.5569934844970703
Validation loss: 1.8790220509293258

Epoch: 6| Step: 4
Training loss: 1.2931338548660278
Validation loss: 1.8957315901274323

Epoch: 6| Step: 5
Training loss: 1.3756071329116821
Validation loss: 1.8880007215725478

Epoch: 6| Step: 6
Training loss: 1.6636765003204346
Validation loss: 1.9114074040484685

Epoch: 6| Step: 7
Training loss: 1.6980407238006592
Validation loss: 1.8736849420814103

Epoch: 6| Step: 8
Training loss: 1.667443037033081
Validation loss: 1.8919810633505545

Epoch: 6| Step: 9
Training loss: 1.7593348026275635
Validation loss: 1.903762581527874

Epoch: 6| Step: 10
Training loss: 1.1424503326416016
Validation loss: 1.8954689348897626

Epoch: 6| Step: 11
Training loss: 2.4757399559020996
Validation loss: 1.912525233402047

Epoch: 6| Step: 12
Training loss: 1.273470401763916
Validation loss: 1.9115569309521747

Epoch: 6| Step: 13
Training loss: 1.906048059463501
Validation loss: 1.9267682939447381

Epoch: 259| Step: 0
Training loss: 1.227423906326294
Validation loss: 1.887448283933824

Epoch: 6| Step: 1
Training loss: 1.996152639389038
Validation loss: 1.8881388659118323

Epoch: 6| Step: 2
Training loss: 1.3207358121871948
Validation loss: 1.8792032785313104

Epoch: 6| Step: 3
Training loss: 1.2967987060546875
Validation loss: 1.8831892833914807

Epoch: 6| Step: 4
Training loss: 2.3008556365966797
Validation loss: 1.9679416302711732

Epoch: 6| Step: 5
Training loss: 1.4011831283569336
Validation loss: 1.8573589171132734

Epoch: 6| Step: 6
Training loss: 2.0235018730163574
Validation loss: 1.8795586145052345

Epoch: 6| Step: 7
Training loss: 2.0259807109832764
Validation loss: 1.8528219525532057

Epoch: 6| Step: 8
Training loss: 1.3629858493804932
Validation loss: 1.8805145345708376

Epoch: 6| Step: 9
Training loss: 1.0934958457946777
Validation loss: 1.8537316732509161

Epoch: 6| Step: 10
Training loss: 1.7902531623840332
Validation loss: 1.8879685196825253

Epoch: 6| Step: 11
Training loss: 1.224719524383545
Validation loss: 1.8529967518262966

Epoch: 6| Step: 12
Training loss: 1.3746986389160156
Validation loss: 1.8489409287770588

Epoch: 6| Step: 13
Training loss: 1.7862107753753662
Validation loss: 1.8984919530089184

Epoch: 260| Step: 0
Training loss: 1.778616189956665
Validation loss: 1.9037526384476693

Epoch: 6| Step: 1
Training loss: 1.9282885789871216
Validation loss: 1.9102542707996983

Epoch: 6| Step: 2
Training loss: 2.2881758213043213
Validation loss: 1.8907900420568322

Epoch: 6| Step: 3
Training loss: 1.864440679550171
Validation loss: 1.8972695732629428

Epoch: 6| Step: 4
Training loss: 0.8798174858093262
Validation loss: 1.9014289379119873

Epoch: 6| Step: 5
Training loss: 1.4874156713485718
Validation loss: 1.889724221280826

Epoch: 6| Step: 6
Training loss: 1.326486349105835
Validation loss: 1.9159275024167952

Epoch: 6| Step: 7
Training loss: 1.9761507511138916
Validation loss: 1.9628991311596287

Epoch: 6| Step: 8
Training loss: 0.7729967832565308
Validation loss: 1.9392458815728464

Epoch: 6| Step: 9
Training loss: 1.2382698059082031
Validation loss: 1.9301113825972362

Epoch: 6| Step: 10
Training loss: 2.009398937225342
Validation loss: 1.924166685791426

Epoch: 6| Step: 11
Training loss: 1.8527553081512451
Validation loss: 1.9239242640874719

Epoch: 6| Step: 12
Training loss: 1.1480004787445068
Validation loss: 1.8509724217076455

Epoch: 6| Step: 13
Training loss: 1.270539402961731
Validation loss: 1.9109846276621665

Epoch: 261| Step: 0
Training loss: 1.6611422300338745
Validation loss: 1.9088501007326188

Epoch: 6| Step: 1
Training loss: 1.2384378910064697
Validation loss: 1.918451911659651

Epoch: 6| Step: 2
Training loss: 1.7496235370635986
Validation loss: 1.9484807560520787

Epoch: 6| Step: 3
Training loss: 1.721529245376587
Validation loss: 1.9211309955966087

Epoch: 6| Step: 4
Training loss: 1.3527581691741943
Validation loss: 1.8751721074504237

Epoch: 6| Step: 5
Training loss: 1.655500888824463
Validation loss: 1.8557086272906231

Epoch: 6| Step: 6
Training loss: 1.1939775943756104
Validation loss: 1.8904464603752218

Epoch: 6| Step: 7
Training loss: 1.2474756240844727
Validation loss: 1.8930632042628464

Epoch: 6| Step: 8
Training loss: 1.6481070518493652
Validation loss: 1.8815376604757001

Epoch: 6| Step: 9
Training loss: 2.287109851837158
Validation loss: 1.8362503731122581

Epoch: 6| Step: 10
Training loss: 1.4133602380752563
Validation loss: 1.9183544984427832

Epoch: 6| Step: 11
Training loss: 1.17604660987854
Validation loss: 1.8740329678340624

Epoch: 6| Step: 12
Training loss: 1.537057876586914
Validation loss: 1.8262009210484003

Epoch: 6| Step: 13
Training loss: 2.2672464847564697
Validation loss: 1.848120133082072

Epoch: 262| Step: 0
Training loss: 1.5340421199798584
Validation loss: 1.9358384660495225

Epoch: 6| Step: 1
Training loss: 1.276023030281067
Validation loss: 1.9027143511720883

Epoch: 6| Step: 2
Training loss: 1.4765104055404663
Validation loss: 1.9228697822939964

Epoch: 6| Step: 3
Training loss: 1.631852149963379
Validation loss: 1.9134530572481052

Epoch: 6| Step: 4
Training loss: 1.495436191558838
Validation loss: 1.8655649423599243

Epoch: 6| Step: 5
Training loss: 1.2362598180770874
Validation loss: 1.9324768192024642

Epoch: 6| Step: 6
Training loss: 1.3242213726043701
Validation loss: 1.9051189550789454

Epoch: 6| Step: 7
Training loss: 1.3903629779815674
Validation loss: 1.8863357542663493

Epoch: 6| Step: 8
Training loss: 1.0615861415863037
Validation loss: 1.8967386343145882

Epoch: 6| Step: 9
Training loss: 2.2431411743164062
Validation loss: 1.89987942993

Epoch: 6| Step: 10
Training loss: 1.8477683067321777
Validation loss: 1.8815674986890567

Epoch: 6| Step: 11
Training loss: 2.2409045696258545
Validation loss: 1.9174290139188048

Epoch: 6| Step: 12
Training loss: 1.8291443586349487
Validation loss: 1.8678947187239123

Epoch: 6| Step: 13
Training loss: 1.2932641506195068
Validation loss: 1.900691173409903

Epoch: 263| Step: 0
Training loss: 1.5032782554626465
Validation loss: 1.9011752810529483

Epoch: 6| Step: 1
Training loss: 1.5497075319290161
Validation loss: 1.916006593294041

Epoch: 6| Step: 2
Training loss: 1.2688512802124023
Validation loss: 1.8921093146006267

Epoch: 6| Step: 3
Training loss: 1.3948769569396973
Validation loss: 1.8972484463004655

Epoch: 6| Step: 4
Training loss: 1.4607958793640137
Validation loss: 1.8507170741276076

Epoch: 6| Step: 5
Training loss: 2.2040915489196777
Validation loss: 1.9343828437148884

Epoch: 6| Step: 6
Training loss: 2.0343666076660156
Validation loss: 1.9039521704437912

Epoch: 6| Step: 7
Training loss: 1.6442593336105347
Validation loss: 1.8788581778926234

Epoch: 6| Step: 8
Training loss: 1.4022815227508545
Validation loss: 1.8888223273779756

Epoch: 6| Step: 9
Training loss: 1.5538740158081055
Validation loss: 1.9242575501882901

Epoch: 6| Step: 10
Training loss: 1.346144199371338
Validation loss: 1.9366534781712357

Epoch: 6| Step: 11
Training loss: 1.560884952545166
Validation loss: 1.9043745635658182

Epoch: 6| Step: 12
Training loss: 1.567314624786377
Validation loss: 1.9173492180403842

Epoch: 6| Step: 13
Training loss: 1.0049185752868652
Validation loss: 1.9725547272671935

Epoch: 264| Step: 0
Training loss: 1.1719294786453247
Validation loss: 1.8966400623321533

Epoch: 6| Step: 1
Training loss: 1.565637469291687
Validation loss: 1.9352335724779355

Epoch: 6| Step: 2
Training loss: 1.2190680503845215
Validation loss: 1.9229450200193672

Epoch: 6| Step: 3
Training loss: 1.6118985414505005
Validation loss: 1.9183542933515323

Epoch: 6| Step: 4
Training loss: 1.13466215133667
Validation loss: 1.8850717813737932

Epoch: 6| Step: 5
Training loss: 1.8015339374542236
Validation loss: 1.8899545079918318

Epoch: 6| Step: 6
Training loss: 1.5166401863098145
Validation loss: 1.9391094356454828

Epoch: 6| Step: 7
Training loss: 2.127706527709961
Validation loss: 1.9033773278677335

Epoch: 6| Step: 8
Training loss: 1.5785317420959473
Validation loss: 1.935165830837783

Epoch: 6| Step: 9
Training loss: 1.5044047832489014
Validation loss: 1.8829558126388057

Epoch: 6| Step: 10
Training loss: 2.064439535140991
Validation loss: 1.8896706873370754

Epoch: 6| Step: 11
Training loss: 1.065402626991272
Validation loss: 1.8619918175922927

Epoch: 6| Step: 12
Training loss: 1.9000194072723389
Validation loss: 1.873875787181239

Epoch: 6| Step: 13
Training loss: 1.366024374961853
Validation loss: 1.9041761095805834

Epoch: 265| Step: 0
Training loss: 1.7192437648773193
Validation loss: 1.8700541693677184

Epoch: 6| Step: 1
Training loss: 1.6102430820465088
Validation loss: 1.8893528189710391

Epoch: 6| Step: 2
Training loss: 1.8056070804595947
Validation loss: 1.8957709432930074

Epoch: 6| Step: 3
Training loss: 1.8861079216003418
Validation loss: 1.8863628269523702

Epoch: 6| Step: 4
Training loss: 1.8054970502853394
Validation loss: 1.8875912735539098

Epoch: 6| Step: 5
Training loss: 1.4311444759368896
Validation loss: 1.8848046372013707

Epoch: 6| Step: 6
Training loss: 1.4840614795684814
Validation loss: 1.9321084548068304

Epoch: 6| Step: 7
Training loss: 1.390976905822754
Validation loss: 1.8747532713797785

Epoch: 6| Step: 8
Training loss: 1.372310757637024
Validation loss: 1.9026612568927068

Epoch: 6| Step: 9
Training loss: 1.0219075679779053
Validation loss: 1.898560623968801

Epoch: 6| Step: 10
Training loss: 1.6683831214904785
Validation loss: 1.8756132638582619

Epoch: 6| Step: 11
Training loss: 1.2449232339859009
Validation loss: 1.8755779086902578

Epoch: 6| Step: 12
Training loss: 1.5160789489746094
Validation loss: 1.9057639926992438

Epoch: 6| Step: 13
Training loss: 1.7973322868347168
Validation loss: 1.8780532908696

Epoch: 266| Step: 0
Training loss: 0.7910650968551636
Validation loss: 1.8698522967676963

Epoch: 6| Step: 1
Training loss: 1.5601428747177124
Validation loss: 1.8789100711063673

Epoch: 6| Step: 2
Training loss: 1.256779432296753
Validation loss: 1.8966782144320908

Epoch: 6| Step: 3
Training loss: 1.9281221628189087
Validation loss: 1.8932885482747068

Epoch: 6| Step: 4
Training loss: 1.7765109539031982
Validation loss: 1.9004951266832248

Epoch: 6| Step: 5
Training loss: 1.3904705047607422
Validation loss: 1.8816026308203255

Epoch: 6| Step: 6
Training loss: 1.3139913082122803
Validation loss: 1.891668519666118

Epoch: 6| Step: 7
Training loss: 2.3380372524261475
Validation loss: 1.8765960047321935

Epoch: 6| Step: 8
Training loss: 0.9219138622283936
Validation loss: 1.9367381718850905

Epoch: 6| Step: 9
Training loss: 1.532242774963379
Validation loss: 1.8929074259214504

Epoch: 6| Step: 10
Training loss: 2.0741043090820312
Validation loss: 1.8959846881128126

Epoch: 6| Step: 11
Training loss: 1.9327458143234253
Validation loss: 1.8877648781704646

Epoch: 6| Step: 12
Training loss: 1.0589392185211182
Validation loss: 1.8738709649732035

Epoch: 6| Step: 13
Training loss: 1.7071601152420044
Validation loss: 1.875966856556554

Epoch: 267| Step: 0
Training loss: 1.0147669315338135
Validation loss: 1.883154566569995

Epoch: 6| Step: 1
Training loss: 1.383263111114502
Validation loss: 1.9071729516470304

Epoch: 6| Step: 2
Training loss: 1.9840397834777832
Validation loss: 1.900588232983825

Epoch: 6| Step: 3
Training loss: 1.4020395278930664
Validation loss: 1.9003456792523783

Epoch: 6| Step: 4
Training loss: 1.3542745113372803
Validation loss: 1.9173139333724976

Epoch: 6| Step: 5
Training loss: 1.3996691703796387
Validation loss: 1.8723374476996801

Epoch: 6| Step: 6
Training loss: 1.944207787513733
Validation loss: 1.8839290193332139

Epoch: 6| Step: 7
Training loss: 1.7168469429016113
Validation loss: 1.8775564227052914

Epoch: 6| Step: 8
Training loss: 1.8365461826324463
Validation loss: 1.882411592750139

Epoch: 6| Step: 9
Training loss: 1.121535062789917
Validation loss: 1.859093596858363

Epoch: 6| Step: 10
Training loss: 1.3114211559295654
Validation loss: 1.8641172685930807

Epoch: 6| Step: 11
Training loss: 1.749369502067566
Validation loss: 1.9166903675243419

Epoch: 6| Step: 12
Training loss: 1.8167450428009033
Validation loss: 1.9207258391123947

Epoch: 6| Step: 13
Training loss: 1.5905473232269287
Validation loss: 1.8843032006294496

Epoch: 268| Step: 0
Training loss: 1.012900471687317
Validation loss: 1.9070201919924827

Epoch: 6| Step: 1
Training loss: 2.052035331726074
Validation loss: 1.891429837032031

Epoch: 6| Step: 2
Training loss: 1.3383913040161133
Validation loss: 1.9020799641968102

Epoch: 6| Step: 3
Training loss: 1.0726608037948608
Validation loss: 1.8966906019436416

Epoch: 6| Step: 4
Training loss: 1.2836267948150635
Validation loss: 1.8751721253959082

Epoch: 6| Step: 5
Training loss: 1.5239958763122559
Validation loss: 1.9215260756913053

Epoch: 6| Step: 6
Training loss: 1.6271390914916992
Validation loss: 1.8513464671309277

Epoch: 6| Step: 7
Training loss: 1.2756166458129883
Validation loss: 1.9094919235475603

Epoch: 6| Step: 8
Training loss: 1.5975089073181152
Validation loss: 1.9043942933441491

Epoch: 6| Step: 9
Training loss: 1.6649341583251953
Validation loss: 1.9105700972259685

Epoch: 6| Step: 10
Training loss: 2.1131134033203125
Validation loss: 1.856912620605961

Epoch: 6| Step: 11
Training loss: 1.8295457363128662
Validation loss: 1.8348707716952088

Epoch: 6| Step: 12
Training loss: 1.951049566268921
Validation loss: 1.8841699002891459

Epoch: 6| Step: 13
Training loss: 1.1729365587234497
Validation loss: 1.9077806036959413

Epoch: 269| Step: 0
Training loss: 1.1469762325286865
Validation loss: 1.8869045165277296

Epoch: 6| Step: 1
Training loss: 1.2782038450241089
Validation loss: 1.9017556123836066

Epoch: 6| Step: 2
Training loss: 1.8096050024032593
Validation loss: 1.89282387943678

Epoch: 6| Step: 3
Training loss: 1.017289638519287
Validation loss: 1.8984776850669616

Epoch: 6| Step: 4
Training loss: 2.01469349861145
Validation loss: 1.8974538631336664

Epoch: 6| Step: 5
Training loss: 1.6502299308776855
Validation loss: 1.856624331525577

Epoch: 6| Step: 6
Training loss: 1.3676759004592896
Validation loss: 1.8788156842672696

Epoch: 6| Step: 7
Training loss: 1.6046130657196045
Validation loss: 1.8171923340007823

Epoch: 6| Step: 8
Training loss: 1.6456778049468994
Validation loss: 1.9116922552867601

Epoch: 6| Step: 9
Training loss: 1.797870397567749
Validation loss: 1.8593945259689002

Epoch: 6| Step: 10
Training loss: 1.6739692687988281
Validation loss: 1.8616986595174319

Epoch: 6| Step: 11
Training loss: 1.8222668170928955
Validation loss: 1.8799147105986072

Epoch: 6| Step: 12
Training loss: 1.2039880752563477
Validation loss: 1.9121014174594675

Epoch: 6| Step: 13
Training loss: 1.6530159711837769
Validation loss: 1.9044308816232989

Epoch: 270| Step: 0
Training loss: 1.6751081943511963
Validation loss: 1.922395142175818

Epoch: 6| Step: 1
Training loss: 1.3762555122375488
Validation loss: 1.8996930404375958

Epoch: 6| Step: 2
Training loss: 1.6684322357177734
Validation loss: 1.9209040736639371

Epoch: 6| Step: 3
Training loss: 1.1318211555480957
Validation loss: 1.9434702114392353

Epoch: 6| Step: 4
Training loss: 1.7811611890792847
Validation loss: 1.8997216327216035

Epoch: 6| Step: 5
Training loss: 1.7419352531433105
Validation loss: 1.8687247255797028

Epoch: 6| Step: 6
Training loss: 1.549026370048523
Validation loss: 1.8921425586105676

Epoch: 6| Step: 7
Training loss: 1.878307819366455
Validation loss: 1.8790113105568835

Epoch: 6| Step: 8
Training loss: 2.304309606552124
Validation loss: 1.9272103181449316

Epoch: 6| Step: 9
Training loss: 0.839514970779419
Validation loss: 1.8826360010331677

Epoch: 6| Step: 10
Training loss: 1.8576014041900635
Validation loss: 1.853997020311253

Epoch: 6| Step: 11
Training loss: 0.9071471691131592
Validation loss: 1.8861956160555604

Epoch: 6| Step: 12
Training loss: 1.1853833198547363
Validation loss: 1.872881588115487

Epoch: 6| Step: 13
Training loss: 1.4813894033432007
Validation loss: 1.872922469210881

Epoch: 271| Step: 0
Training loss: 1.3105064630508423
Validation loss: 1.8560478802650207

Epoch: 6| Step: 1
Training loss: 1.2058753967285156
Validation loss: 1.894379674747426

Epoch: 6| Step: 2
Training loss: 1.5870112180709839
Validation loss: 1.878837808485954

Epoch: 6| Step: 3
Training loss: 1.1257303953170776
Validation loss: 1.9026534300978466

Epoch: 6| Step: 4
Training loss: 1.4580028057098389
Validation loss: 1.871777795976208

Epoch: 6| Step: 5
Training loss: 2.5100302696228027
Validation loss: 1.8786855538686116

Epoch: 6| Step: 6
Training loss: 1.4266550540924072
Validation loss: 1.9091816973942581

Epoch: 6| Step: 7
Training loss: 1.0578800439834595
Validation loss: 1.871439459503338

Epoch: 6| Step: 8
Training loss: 1.1560509204864502
Validation loss: 1.8681679617974065

Epoch: 6| Step: 9
Training loss: 1.3799725770950317
Validation loss: 1.9528175823150142

Epoch: 6| Step: 10
Training loss: 1.4537506103515625
Validation loss: 1.9006810342111895

Epoch: 6| Step: 11
Training loss: 2.247926712036133
Validation loss: 1.8945229707225677

Epoch: 6| Step: 12
Training loss: 1.180280327796936
Validation loss: 1.9027792074347054

Epoch: 6| Step: 13
Training loss: 3.008519411087036
Validation loss: 1.9156129308926162

Epoch: 272| Step: 0
Training loss: 1.5919348001480103
Validation loss: 1.8974606042267175

Epoch: 6| Step: 1
Training loss: 1.4508135318756104
Validation loss: 1.8489760557810466

Epoch: 6| Step: 2
Training loss: 1.4496352672576904
Validation loss: 1.8716875853077057

Epoch: 6| Step: 3
Training loss: 1.4744435548782349
Validation loss: 1.9031316388037898

Epoch: 6| Step: 4
Training loss: 2.1318960189819336
Validation loss: 1.863092605785657

Epoch: 6| Step: 5
Training loss: 1.9943312406539917
Validation loss: 1.891277168386726

Epoch: 6| Step: 6
Training loss: 1.3765546083450317
Validation loss: 1.8733496319863103

Epoch: 6| Step: 7
Training loss: 1.3603018522262573
Validation loss: 1.8428957590492823

Epoch: 6| Step: 8
Training loss: 1.3549585342407227
Validation loss: 1.8542942180428454

Epoch: 6| Step: 9
Training loss: 2.1160221099853516
Validation loss: 1.848198659958378

Epoch: 6| Step: 10
Training loss: 1.5731794834136963
Validation loss: 1.881995516438638

Epoch: 6| Step: 11
Training loss: 1.002819299697876
Validation loss: 1.887882040392968

Epoch: 6| Step: 12
Training loss: 1.6582046747207642
Validation loss: 1.877868434434296

Epoch: 6| Step: 13
Training loss: 0.5274083018302917
Validation loss: 1.8716450724550473

Epoch: 273| Step: 0
Training loss: 2.043285369873047
Validation loss: 1.8871252600864699

Epoch: 6| Step: 1
Training loss: 2.3885202407836914
Validation loss: 1.8854089334446897

Epoch: 6| Step: 2
Training loss: 1.0850958824157715
Validation loss: 1.871942412468695

Epoch: 6| Step: 3
Training loss: 0.8063092231750488
Validation loss: 1.9076247240907402

Epoch: 6| Step: 4
Training loss: 1.1850814819335938
Validation loss: 1.900693876768953

Epoch: 6| Step: 5
Training loss: 1.8688368797302246
Validation loss: 1.8948752521186747

Epoch: 6| Step: 6
Training loss: 2.0289101600646973
Validation loss: 1.9207650000049221

Epoch: 6| Step: 7
Training loss: 1.2346972227096558
Validation loss: 1.8738818809550295

Epoch: 6| Step: 8
Training loss: 1.1923705339431763
Validation loss: 1.8820874973009991

Epoch: 6| Step: 9
Training loss: 1.654747486114502
Validation loss: 1.8630371324477657

Epoch: 6| Step: 10
Training loss: 1.6450682878494263
Validation loss: 1.872230165748186

Epoch: 6| Step: 11
Training loss: 0.9891074895858765
Validation loss: 1.8915668879785845

Epoch: 6| Step: 12
Training loss: 1.7713311910629272
Validation loss: 1.895356447465958

Epoch: 6| Step: 13
Training loss: 1.3157755136489868
Validation loss: 1.8625518993664814

Epoch: 274| Step: 0
Training loss: 0.9786003828048706
Validation loss: 1.8937655623241136

Epoch: 6| Step: 1
Training loss: 1.198217749595642
Validation loss: 1.8768316648339713

Epoch: 6| Step: 2
Training loss: 1.4443891048431396
Validation loss: 1.9378074471668532

Epoch: 6| Step: 3
Training loss: 1.2925678491592407
Validation loss: 1.8545244932174683

Epoch: 6| Step: 4
Training loss: 1.3617966175079346
Validation loss: 1.8710252431131178

Epoch: 6| Step: 5
Training loss: 1.2340610027313232
Validation loss: 1.8537167041532454

Epoch: 6| Step: 6
Training loss: 1.527034878730774
Validation loss: 1.9051913369086482

Epoch: 6| Step: 7
Training loss: 1.3281729221343994
Validation loss: 1.9265224113259265

Epoch: 6| Step: 8
Training loss: 1.771653175354004
Validation loss: 1.9205888112386067

Epoch: 6| Step: 9
Training loss: 1.938615322113037
Validation loss: 1.8268057172016432

Epoch: 6| Step: 10
Training loss: 1.0772892236709595
Validation loss: 1.8736731224162604

Epoch: 6| Step: 11
Training loss: 2.2648022174835205
Validation loss: 1.8703064316062517

Epoch: 6| Step: 12
Training loss: 2.20607852935791
Validation loss: 1.8864797494744743

Epoch: 6| Step: 13
Training loss: 1.6679904460906982
Validation loss: 1.938864520801011

Epoch: 275| Step: 0
Training loss: 1.6878788471221924
Validation loss: 1.9166392998028827

Epoch: 6| Step: 1
Training loss: 2.3623132705688477
Validation loss: 1.8933989155677058

Epoch: 6| Step: 2
Training loss: 1.4811227321624756
Validation loss: 1.8656948202399797

Epoch: 6| Step: 3
Training loss: 1.5721962451934814
Validation loss: 1.8724310526283838

Epoch: 6| Step: 4
Training loss: 1.41300630569458
Validation loss: 1.885697349425285

Epoch: 6| Step: 5
Training loss: 1.363144874572754
Validation loss: 1.8847639214607976

Epoch: 6| Step: 6
Training loss: 1.7051219940185547
Validation loss: 1.9515884704487299

Epoch: 6| Step: 7
Training loss: 1.0322868824005127
Validation loss: 1.928346195528584

Epoch: 6| Step: 8
Training loss: 1.4207301139831543
Validation loss: 1.8749054990788943

Epoch: 6| Step: 9
Training loss: 1.5740797519683838
Validation loss: 1.9420499981090587

Epoch: 6| Step: 10
Training loss: 1.3383088111877441
Validation loss: 1.8720852700612878

Epoch: 6| Step: 11
Training loss: 1.4017413854599
Validation loss: 1.8822487605515348

Epoch: 6| Step: 12
Training loss: 1.573768138885498
Validation loss: 1.88711106136281

Epoch: 6| Step: 13
Training loss: 1.3400838375091553
Validation loss: 1.8748691851092922

Epoch: 276| Step: 0
Training loss: 1.8717440366744995
Validation loss: 1.8663360636721376

Epoch: 6| Step: 1
Training loss: 1.1769957542419434
Validation loss: 1.8770559013530772

Epoch: 6| Step: 2
Training loss: 1.7321999073028564
Validation loss: 1.8888451104523034

Epoch: 6| Step: 3
Training loss: 1.2172547578811646
Validation loss: 1.8934634667570873

Epoch: 6| Step: 4
Training loss: 1.3875409364700317
Validation loss: 1.8590688833626368

Epoch: 6| Step: 5
Training loss: 1.8836545944213867
Validation loss: 1.8305408775165517

Epoch: 6| Step: 6
Training loss: 0.998443067073822
Validation loss: 1.8534586660323604

Epoch: 6| Step: 7
Training loss: 0.9662793278694153
Validation loss: 1.882762465425717

Epoch: 6| Step: 8
Training loss: 1.600050449371338
Validation loss: 1.8551263552840038

Epoch: 6| Step: 9
Training loss: 2.123631477355957
Validation loss: 1.859730294955674

Epoch: 6| Step: 10
Training loss: 1.4856294393539429
Validation loss: 1.8765246124677761

Epoch: 6| Step: 11
Training loss: 1.5257281064987183
Validation loss: 1.85960606990322

Epoch: 6| Step: 12
Training loss: 1.681309700012207
Validation loss: 1.8950589767066381

Epoch: 6| Step: 13
Training loss: 1.043656826019287
Validation loss: 1.9025152088493429

Epoch: 277| Step: 0
Training loss: 1.7258011102676392
Validation loss: 1.9069747681258826

Epoch: 6| Step: 1
Training loss: 1.8756157159805298
Validation loss: 1.9165561776007376

Epoch: 6| Step: 2
Training loss: 1.7528998851776123
Validation loss: 1.9248220689835087

Epoch: 6| Step: 3
Training loss: 1.2497116327285767
Validation loss: 1.8985801871104906

Epoch: 6| Step: 4
Training loss: 1.3055623769760132
Validation loss: 1.9627105394999187

Epoch: 6| Step: 5
Training loss: 1.4930424690246582
Validation loss: 1.9103669043510192

Epoch: 6| Step: 6
Training loss: 1.3585829734802246
Validation loss: 1.8781933182029313

Epoch: 6| Step: 7
Training loss: 0.9636760950088501
Validation loss: 1.951753334332538

Epoch: 6| Step: 8
Training loss: 1.492767572402954
Validation loss: 1.9384932825642247

Epoch: 6| Step: 9
Training loss: 1.9872504472732544
Validation loss: 1.868085552287358

Epoch: 6| Step: 10
Training loss: 1.836379051208496
Validation loss: 1.8541432170457737

Epoch: 6| Step: 11
Training loss: 1.5231351852416992
Validation loss: 1.8980668373005365

Epoch: 6| Step: 12
Training loss: 1.4836896657943726
Validation loss: 1.8747624402405114

Epoch: 6| Step: 13
Training loss: 1.0901241302490234
Validation loss: 1.8816598128247004

Epoch: 278| Step: 0
Training loss: 1.26239013671875
Validation loss: 1.8542651976308515

Epoch: 6| Step: 1
Training loss: 1.7312538623809814
Validation loss: 1.853046436463633

Epoch: 6| Step: 2
Training loss: 1.5311720371246338
Validation loss: 1.904450842129287

Epoch: 6| Step: 3
Training loss: 1.6548655033111572
Validation loss: 1.9246773463423534

Epoch: 6| Step: 4
Training loss: 1.2372841835021973
Validation loss: 1.8758189575646513

Epoch: 6| Step: 5
Training loss: 1.2021586894989014
Validation loss: 1.906795588872766

Epoch: 6| Step: 6
Training loss: 2.06675124168396
Validation loss: 1.8874455587838286

Epoch: 6| Step: 7
Training loss: 1.6395010948181152
Validation loss: 1.8929247215229978

Epoch: 6| Step: 8
Training loss: 1.8682730197906494
Validation loss: 1.8976564663712696

Epoch: 6| Step: 9
Training loss: 1.6661701202392578
Validation loss: 1.9586896550270818

Epoch: 6| Step: 10
Training loss: 1.2959890365600586
Validation loss: 1.9267732148529382

Epoch: 6| Step: 11
Training loss: 1.1864451169967651
Validation loss: 1.9785593876274683

Epoch: 6| Step: 12
Training loss: 1.4368343353271484
Validation loss: 1.95228075468412

Epoch: 6| Step: 13
Training loss: 1.7167863845825195
Validation loss: 1.9305894195392568

Epoch: 279| Step: 0
Training loss: 1.2645539045333862
Validation loss: 1.866234161520517

Epoch: 6| Step: 1
Training loss: 1.5967979431152344
Validation loss: 1.8861039338573333

Epoch: 6| Step: 2
Training loss: 1.7079529762268066
Validation loss: 1.8808156713362663

Epoch: 6| Step: 3
Training loss: 1.0758068561553955
Validation loss: 1.86567178721069

Epoch: 6| Step: 4
Training loss: 0.911841869354248
Validation loss: 1.87387724332912

Epoch: 6| Step: 5
Training loss: 1.2084755897521973
Validation loss: 1.8926563878213205

Epoch: 6| Step: 6
Training loss: 1.220967173576355
Validation loss: 1.9261124915974115

Epoch: 6| Step: 7
Training loss: 1.3499327898025513
Validation loss: 1.8588870597142044

Epoch: 6| Step: 8
Training loss: 1.7368006706237793
Validation loss: 1.8729492118281703

Epoch: 6| Step: 9
Training loss: 1.9829596281051636
Validation loss: 1.8802491106012815

Epoch: 6| Step: 10
Training loss: 2.022690773010254
Validation loss: 1.8879071948348836

Epoch: 6| Step: 11
Training loss: 1.9551020860671997
Validation loss: 1.873194420209495

Epoch: 6| Step: 12
Training loss: 1.628183126449585
Validation loss: 1.8858441729699411

Epoch: 6| Step: 13
Training loss: 1.4974958896636963
Validation loss: 1.900041853227923

Epoch: 280| Step: 0
Training loss: 1.8809833526611328
Validation loss: 1.8977175899731216

Epoch: 6| Step: 1
Training loss: 1.016305923461914
Validation loss: 1.9090542639455488

Epoch: 6| Step: 2
Training loss: 1.9448978900909424
Validation loss: 1.939847328329599

Epoch: 6| Step: 3
Training loss: 1.6207916736602783
Validation loss: 1.9473967424003027

Epoch: 6| Step: 4
Training loss: 1.6866968870162964
Validation loss: 1.9263517472051805

Epoch: 6| Step: 5
Training loss: 1.2463088035583496
Validation loss: 1.9598813979856429

Epoch: 6| Step: 6
Training loss: 1.7885034084320068
Validation loss: 1.948009539675969

Epoch: 6| Step: 7
Training loss: 1.291867733001709
Validation loss: 1.9358682593991678

Epoch: 6| Step: 8
Training loss: 1.601530909538269
Validation loss: 1.9783150534476004

Epoch: 6| Step: 9
Training loss: 1.4552072286605835
Validation loss: 1.951756379937613

Epoch: 6| Step: 10
Training loss: 1.4690332412719727
Validation loss: 1.9589760431679346

Epoch: 6| Step: 11
Training loss: 1.2619845867156982
Validation loss: 1.9377813223869569

Epoch: 6| Step: 12
Training loss: 1.9615139961242676
Validation loss: 1.9332830418822586

Epoch: 6| Step: 13
Training loss: 1.1086523532867432
Validation loss: 1.8969861691997898

Epoch: 281| Step: 0
Training loss: 1.285964012145996
Validation loss: 1.9142520120066981

Epoch: 6| Step: 1
Training loss: 1.2493289709091187
Validation loss: 1.9074201224952616

Epoch: 6| Step: 2
Training loss: 1.4956326484680176
Validation loss: 1.872085795607618

Epoch: 6| Step: 3
Training loss: 1.5316129922866821
Validation loss: 1.8755528042393346

Epoch: 6| Step: 4
Training loss: 1.687383770942688
Validation loss: 1.890869955862722

Epoch: 6| Step: 5
Training loss: 1.5327339172363281
Validation loss: 1.864688629104245

Epoch: 6| Step: 6
Training loss: 1.5281829833984375
Validation loss: 1.9072176576942526

Epoch: 6| Step: 7
Training loss: 1.50457763671875
Validation loss: 1.8621128887258551

Epoch: 6| Step: 8
Training loss: 1.8226220607757568
Validation loss: 1.8594691522659794

Epoch: 6| Step: 9
Training loss: 1.5414814949035645
Validation loss: 1.8829567765676847

Epoch: 6| Step: 10
Training loss: 1.3717411756515503
Validation loss: 1.8982972098935036

Epoch: 6| Step: 11
Training loss: 1.5331482887268066
Validation loss: 1.8825326158154396

Epoch: 6| Step: 12
Training loss: 1.4821906089782715
Validation loss: 1.9424855145074988

Epoch: 6| Step: 13
Training loss: 1.4975353479385376
Validation loss: 1.907346842109516

Epoch: 282| Step: 0
Training loss: 1.675977110862732
Validation loss: 1.8846601606697164

Epoch: 6| Step: 1
Training loss: 1.2537548542022705
Validation loss: 1.9232568740844727

Epoch: 6| Step: 2
Training loss: 1.252549409866333
Validation loss: 1.8914450727483278

Epoch: 6| Step: 3
Training loss: 1.2719476222991943
Validation loss: 1.9363455810854513

Epoch: 6| Step: 4
Training loss: 1.4603664875030518
Validation loss: 1.885012072901572

Epoch: 6| Step: 5
Training loss: 1.7678650617599487
Validation loss: 1.9173291165341613

Epoch: 6| Step: 6
Training loss: 2.147481918334961
Validation loss: 1.8957293443782355

Epoch: 6| Step: 7
Training loss: 1.6094844341278076
Validation loss: 1.9345474422618907

Epoch: 6| Step: 8
Training loss: 1.513819694519043
Validation loss: 1.866671472467402

Epoch: 6| Step: 9
Training loss: 2.0919318199157715
Validation loss: 1.8752461274464924

Epoch: 6| Step: 10
Training loss: 1.4492746591567993
Validation loss: 1.8574878656735985

Epoch: 6| Step: 11
Training loss: 1.372651219367981
Validation loss: 1.856926510410924

Epoch: 6| Step: 12
Training loss: 1.2859933376312256
Validation loss: 1.8797770187418947

Epoch: 6| Step: 13
Training loss: 1.3434545993804932
Validation loss: 1.8520020720779256

Epoch: 283| Step: 0
Training loss: 1.9640617370605469
Validation loss: 1.909001576003208

Epoch: 6| Step: 1
Training loss: 1.8655622005462646
Validation loss: 1.8758770765796784

Epoch: 6| Step: 2
Training loss: 1.0185598134994507
Validation loss: 1.8502298772975962

Epoch: 6| Step: 3
Training loss: 1.7480922937393188
Validation loss: 1.8463841663893832

Epoch: 6| Step: 4
Training loss: 1.5678876638412476
Validation loss: 1.8618238279896397

Epoch: 6| Step: 5
Training loss: 1.3740332126617432
Validation loss: 1.8346955442941317

Epoch: 6| Step: 6
Training loss: 1.6531974077224731
Validation loss: 1.895078077111193

Epoch: 6| Step: 7
Training loss: 1.2707297801971436
Validation loss: 1.9085675260072112

Epoch: 6| Step: 8
Training loss: 1.1197282075881958
Validation loss: 1.9189655344973329

Epoch: 6| Step: 9
Training loss: 1.6470203399658203
Validation loss: 1.8885895898265224

Epoch: 6| Step: 10
Training loss: 1.360983967781067
Validation loss: 1.872139830743113

Epoch: 6| Step: 11
Training loss: 1.4619100093841553
Validation loss: 1.9182518220716906

Epoch: 6| Step: 12
Training loss: 1.394862413406372
Validation loss: 1.9140487178679435

Epoch: 6| Step: 13
Training loss: 1.7455823421478271
Validation loss: 1.9502908504137428

Epoch: 284| Step: 0
Training loss: 1.8602561950683594
Validation loss: 1.908897735739267

Epoch: 6| Step: 1
Training loss: 1.0788788795471191
Validation loss: 1.907034699634839

Epoch: 6| Step: 2
Training loss: 2.0975396633148193
Validation loss: 1.919093419146794

Epoch: 6| Step: 3
Training loss: 1.7412810325622559
Validation loss: 1.9178845344051239

Epoch: 6| Step: 4
Training loss: 1.6770046949386597
Validation loss: 1.9060085934977378

Epoch: 6| Step: 5
Training loss: 0.9899709224700928
Validation loss: 1.8675375651287776

Epoch: 6| Step: 6
Training loss: 0.5523524880409241
Validation loss: 1.8852518425192883

Epoch: 6| Step: 7
Training loss: 1.630846381187439
Validation loss: 1.88563960213815

Epoch: 6| Step: 8
Training loss: 1.5744225978851318
Validation loss: 1.8813572314477736

Epoch: 6| Step: 9
Training loss: 1.2881889343261719
Validation loss: 1.8605112311660603

Epoch: 6| Step: 10
Training loss: 1.8063818216323853
Validation loss: 1.8607436226260277

Epoch: 6| Step: 11
Training loss: 2.1873486042022705
Validation loss: 1.8996942722669212

Epoch: 6| Step: 12
Training loss: 1.1835598945617676
Validation loss: 1.8832595117630497

Epoch: 6| Step: 13
Training loss: 1.1174815893173218
Validation loss: 1.8971365190321399

Epoch: 285| Step: 0
Training loss: 2.0230748653411865
Validation loss: 1.90239837092738

Epoch: 6| Step: 1
Training loss: 1.5984907150268555
Validation loss: 1.8734707088880642

Epoch: 6| Step: 2
Training loss: 1.4093482494354248
Validation loss: 1.8644120898298038

Epoch: 6| Step: 3
Training loss: 1.4363315105438232
Validation loss: 1.90422688504701

Epoch: 6| Step: 4
Training loss: 1.1774855852127075
Validation loss: 1.9009209050927112

Epoch: 6| Step: 5
Training loss: 1.2199666500091553
Validation loss: 1.8472110302217546

Epoch: 6| Step: 6
Training loss: 1.7982473373413086
Validation loss: 1.8867549614239765

Epoch: 6| Step: 7
Training loss: 1.11569344997406
Validation loss: 1.8436200772562334

Epoch: 6| Step: 8
Training loss: 1.711782455444336
Validation loss: 1.8769015689049997

Epoch: 6| Step: 9
Training loss: 1.9749858379364014
Validation loss: 1.8925339252718034

Epoch: 6| Step: 10
Training loss: 1.69376540184021
Validation loss: 1.8330093071024904

Epoch: 6| Step: 11
Training loss: 1.439497947692871
Validation loss: 1.9026054207996657

Epoch: 6| Step: 12
Training loss: 0.8760753870010376
Validation loss: 1.8705217492195867

Epoch: 6| Step: 13
Training loss: 1.047074794769287
Validation loss: 1.896177286742836

Epoch: 286| Step: 0
Training loss: 1.2035460472106934
Validation loss: 1.8773074380813106

Epoch: 6| Step: 1
Training loss: 1.2727470397949219
Validation loss: 1.888897866331121

Epoch: 6| Step: 2
Training loss: 1.9946221113204956
Validation loss: 1.8607100671337498

Epoch: 6| Step: 3
Training loss: 1.4892210960388184
Validation loss: 1.8786635501410371

Epoch: 6| Step: 4
Training loss: 1.3600258827209473
Validation loss: 1.9225151769576534

Epoch: 6| Step: 5
Training loss: 1.5915707349777222
Validation loss: 1.8915832747695267

Epoch: 6| Step: 6
Training loss: 1.2603263854980469
Validation loss: 1.8594237783903718

Epoch: 6| Step: 7
Training loss: 1.4530270099639893
Validation loss: 1.8963193047431208

Epoch: 6| Step: 8
Training loss: 1.9705039262771606
Validation loss: 1.9154555848849717

Epoch: 6| Step: 9
Training loss: 1.6958515644073486
Validation loss: 1.9025786563914309

Epoch: 6| Step: 10
Training loss: 1.268926739692688
Validation loss: 1.9309341612682547

Epoch: 6| Step: 11
Training loss: 1.6747958660125732
Validation loss: 1.8823284487570486

Epoch: 6| Step: 12
Training loss: 1.0746026039123535
Validation loss: 1.8709532958205028

Epoch: 6| Step: 13
Training loss: 1.592909336090088
Validation loss: 1.8670668435353104

Epoch: 287| Step: 0
Training loss: 1.128471851348877
Validation loss: 1.891929526482859

Epoch: 6| Step: 1
Training loss: 1.4318037033081055
Validation loss: 1.8861950212909329

Epoch: 6| Step: 2
Training loss: 2.433448314666748
Validation loss: 1.8733134743987874

Epoch: 6| Step: 3
Training loss: 1.683300256729126
Validation loss: 1.8543528831133278

Epoch: 6| Step: 4
Training loss: 1.2537031173706055
Validation loss: 1.8659912206793343

Epoch: 6| Step: 5
Training loss: 2.0840342044830322
Validation loss: 1.8749700015591038

Epoch: 6| Step: 6
Training loss: 1.350914478302002
Validation loss: 1.8650842148770568

Epoch: 6| Step: 7
Training loss: 1.0251096487045288
Validation loss: 1.884974286120425

Epoch: 6| Step: 8
Training loss: 1.4478825330734253
Validation loss: 1.823330399810627

Epoch: 6| Step: 9
Training loss: 1.1241364479064941
Validation loss: 1.8936290164147653

Epoch: 6| Step: 10
Training loss: 1.3794753551483154
Validation loss: 1.8805404939959127

Epoch: 6| Step: 11
Training loss: 1.5983457565307617
Validation loss: 1.9004553684624292

Epoch: 6| Step: 12
Training loss: 1.1827341318130493
Validation loss: 1.9346092759921987

Epoch: 6| Step: 13
Training loss: 1.8316915035247803
Validation loss: 1.861453402426935

Epoch: 288| Step: 0
Training loss: 1.5881097316741943
Validation loss: 1.8561230308266097

Epoch: 6| Step: 1
Training loss: 1.2510713338851929
Validation loss: 1.892690686769383

Epoch: 6| Step: 2
Training loss: 1.3197071552276611
Validation loss: 1.8584613518048358

Epoch: 6| Step: 3
Training loss: 1.7472426891326904
Validation loss: 1.8528192940578665

Epoch: 6| Step: 4
Training loss: 1.3696397542953491
Validation loss: 1.8989611851271762

Epoch: 6| Step: 5
Training loss: 1.6903634071350098
Validation loss: 1.881141411360874

Epoch: 6| Step: 6
Training loss: 1.4156734943389893
Validation loss: 1.9075761149006505

Epoch: 6| Step: 7
Training loss: 0.9731177687644958
Validation loss: 1.879670589200912

Epoch: 6| Step: 8
Training loss: 1.6740436553955078
Validation loss: 1.8390809765426062

Epoch: 6| Step: 9
Training loss: 1.3574297428131104
Validation loss: 1.8652400342367028

Epoch: 6| Step: 10
Training loss: 1.9033957719802856
Validation loss: 1.8969559746403848

Epoch: 6| Step: 11
Training loss: 1.5322883129119873
Validation loss: 1.8960240117965206

Epoch: 6| Step: 12
Training loss: 1.3265513181686401
Validation loss: 1.8946857426756172

Epoch: 6| Step: 13
Training loss: 2.680983543395996
Validation loss: 1.847283132614628

Epoch: 289| Step: 0
Training loss: 1.5699493885040283
Validation loss: 1.8513305699953468

Epoch: 6| Step: 1
Training loss: 2.0500199794769287
Validation loss: 1.9079394058514667

Epoch: 6| Step: 2
Training loss: 1.2720987796783447
Validation loss: 1.8655289744818082

Epoch: 6| Step: 3
Training loss: 1.1931352615356445
Validation loss: 1.8948309806085402

Epoch: 6| Step: 4
Training loss: 2.0455586910247803
Validation loss: 1.8696007882395098

Epoch: 6| Step: 5
Training loss: 1.9218876361846924
Validation loss: 1.8845896297885525

Epoch: 6| Step: 6
Training loss: 1.3325170278549194
Validation loss: 1.892421091756513

Epoch: 6| Step: 7
Training loss: 1.263977289199829
Validation loss: 1.8304145348969327

Epoch: 6| Step: 8
Training loss: 1.3250010013580322
Validation loss: 1.8783920477795344

Epoch: 6| Step: 9
Training loss: 1.3289740085601807
Validation loss: 1.8471459522042224

Epoch: 6| Step: 10
Training loss: 1.3310092687606812
Validation loss: 1.8972984795929284

Epoch: 6| Step: 11
Training loss: 2.0063114166259766
Validation loss: 1.850309823148994

Epoch: 6| Step: 12
Training loss: 1.3309507369995117
Validation loss: 1.8600377869862381

Epoch: 6| Step: 13
Training loss: 1.2605178356170654
Validation loss: 1.8811527567525064

Epoch: 290| Step: 0
Training loss: 0.7579960823059082
Validation loss: 1.9166114791747062

Epoch: 6| Step: 1
Training loss: 1.128846526145935
Validation loss: 1.8657107327574043

Epoch: 6| Step: 2
Training loss: 1.7638969421386719
Validation loss: 1.9454473449337868

Epoch: 6| Step: 3
Training loss: 1.436701774597168
Validation loss: 1.889445997053577

Epoch: 6| Step: 4
Training loss: 1.4970329999923706
Validation loss: 1.8877760671800183

Epoch: 6| Step: 5
Training loss: 1.374729037284851
Validation loss: 1.8782240857360184

Epoch: 6| Step: 6
Training loss: 1.39089035987854
Validation loss: 1.885365898891162

Epoch: 6| Step: 7
Training loss: 1.5135010480880737
Validation loss: 1.8389736439592095

Epoch: 6| Step: 8
Training loss: 1.218136191368103
Validation loss: 1.8333261487304524

Epoch: 6| Step: 9
Training loss: 2.075627326965332
Validation loss: 1.868829252899334

Epoch: 6| Step: 10
Training loss: 1.4283361434936523
Validation loss: 1.8762017667934459

Epoch: 6| Step: 11
Training loss: 1.2145389318466187
Validation loss: 1.9028204179579211

Epoch: 6| Step: 12
Training loss: 2.13067889213562
Validation loss: 1.8922024285921486

Epoch: 6| Step: 13
Training loss: 1.6535181999206543
Validation loss: 1.8770874123419485

Epoch: 291| Step: 0
Training loss: 1.6121255159378052
Validation loss: 1.8669748998457385

Epoch: 6| Step: 1
Training loss: 1.1881916522979736
Validation loss: 1.9026714371096702

Epoch: 6| Step: 2
Training loss: 1.6004968881607056
Validation loss: 1.9237989840968963

Epoch: 6| Step: 3
Training loss: 2.2850899696350098
Validation loss: 1.8664533989403838

Epoch: 6| Step: 4
Training loss: 1.2183377742767334
Validation loss: 1.8732275988465996

Epoch: 6| Step: 5
Training loss: 0.9336994886398315
Validation loss: 1.8924666732870123

Epoch: 6| Step: 6
Training loss: 1.2234036922454834
Validation loss: 1.8894813253033547

Epoch: 6| Step: 7
Training loss: 1.5993365049362183
Validation loss: 1.9097422130646244

Epoch: 6| Step: 8
Training loss: 1.4157276153564453
Validation loss: 1.8819423734500844

Epoch: 6| Step: 9
Training loss: 1.5496327877044678
Validation loss: 1.8463164632038405

Epoch: 6| Step: 10
Training loss: 1.1457159519195557
Validation loss: 1.8682981332143147

Epoch: 6| Step: 11
Training loss: 1.5830228328704834
Validation loss: 1.846851916723354

Epoch: 6| Step: 12
Training loss: 1.2429687976837158
Validation loss: 1.8409653773871801

Epoch: 6| Step: 13
Training loss: 2.286482572555542
Validation loss: 1.9023082640863234

Epoch: 292| Step: 0
Training loss: 1.2405622005462646
Validation loss: 1.8942763395206903

Epoch: 6| Step: 1
Training loss: 1.353208065032959
Validation loss: 1.8696885108947754

Epoch: 6| Step: 2
Training loss: 1.2430131435394287
Validation loss: 1.8960219954931608

Epoch: 6| Step: 3
Training loss: 1.2637085914611816
Validation loss: 1.8710894866656231

Epoch: 6| Step: 4
Training loss: 0.9581069946289062
Validation loss: 1.9154728689501364

Epoch: 6| Step: 5
Training loss: 1.0749626159667969
Validation loss: 1.9136130655965498

Epoch: 6| Step: 6
Training loss: 2.1623902320861816
Validation loss: 1.961921074057138

Epoch: 6| Step: 7
Training loss: 1.8289889097213745
Validation loss: 1.970099356866652

Epoch: 6| Step: 8
Training loss: 1.1075763702392578
Validation loss: 1.9580570908002957

Epoch: 6| Step: 9
Training loss: 1.5503547191619873
Validation loss: 1.9709823490470968

Epoch: 6| Step: 10
Training loss: 1.8675143718719482
Validation loss: 1.982000776516494

Epoch: 6| Step: 11
Training loss: 1.6544809341430664
Validation loss: 1.9018119150592434

Epoch: 6| Step: 12
Training loss: 1.9199802875518799
Validation loss: 1.886382887440343

Epoch: 6| Step: 13
Training loss: 1.8133103847503662
Validation loss: 1.8804261428053661

Epoch: 293| Step: 0
Training loss: 1.5431708097457886
Validation loss: 1.878564223166435

Epoch: 6| Step: 1
Training loss: 1.6034249067306519
Validation loss: 1.8778709442384782

Epoch: 6| Step: 2
Training loss: 1.9683024883270264
Validation loss: 1.8759186280670987

Epoch: 6| Step: 3
Training loss: 1.4911448955535889
Validation loss: 1.8595264214341358

Epoch: 6| Step: 4
Training loss: 1.4411444664001465
Validation loss: 1.8776824871699016

Epoch: 6| Step: 5
Training loss: 2.1056199073791504
Validation loss: 1.8714420641622236

Epoch: 6| Step: 6
Training loss: 1.4605662822723389
Validation loss: 1.866373920953402

Epoch: 6| Step: 7
Training loss: 1.362116813659668
Validation loss: 1.8854825829946866

Epoch: 6| Step: 8
Training loss: 1.3329360485076904
Validation loss: 1.8979416252464376

Epoch: 6| Step: 9
Training loss: 0.6967908143997192
Validation loss: 1.8765067387652654

Epoch: 6| Step: 10
Training loss: 1.378946304321289
Validation loss: 1.8618529317199544

Epoch: 6| Step: 11
Training loss: 0.8099557161331177
Validation loss: 1.8651940438055223

Epoch: 6| Step: 12
Training loss: 1.799206018447876
Validation loss: 1.8659465646231046

Epoch: 6| Step: 13
Training loss: 1.9762094020843506
Validation loss: 1.8748357116535146

Epoch: 294| Step: 0
Training loss: 2.057461738586426
Validation loss: 1.8769991449130479

Epoch: 6| Step: 1
Training loss: 1.639419436454773
Validation loss: 1.8519527989049112

Epoch: 6| Step: 2
Training loss: 1.2901058197021484
Validation loss: 1.8693022817693732

Epoch: 6| Step: 3
Training loss: 1.6394697427749634
Validation loss: 1.882515363795783

Epoch: 6| Step: 4
Training loss: 1.7069416046142578
Validation loss: 1.9753965434207712

Epoch: 6| Step: 5
Training loss: 1.5846495628356934
Validation loss: 1.9028915923128846

Epoch: 6| Step: 6
Training loss: 1.1857247352600098
Validation loss: 1.9311069698743923

Epoch: 6| Step: 7
Training loss: 1.6599035263061523
Validation loss: 1.928981775878578

Epoch: 6| Step: 8
Training loss: 1.4353587627410889
Validation loss: 1.9051133163513676

Epoch: 6| Step: 9
Training loss: 1.6021053791046143
Validation loss: 1.8985112841411302

Epoch: 6| Step: 10
Training loss: 1.0852140188217163
Validation loss: 1.8906612973059378

Epoch: 6| Step: 11
Training loss: 1.0074352025985718
Validation loss: 1.8997567328073646

Epoch: 6| Step: 12
Training loss: 1.244765043258667
Validation loss: 1.9077073310011177

Epoch: 6| Step: 13
Training loss: 1.4481197595596313
Validation loss: 1.8896047530635711

Epoch: 295| Step: 0
Training loss: 1.309949278831482
Validation loss: 1.8703571839999127

Epoch: 6| Step: 1
Training loss: 0.9284517168998718
Validation loss: 1.8909306346729238

Epoch: 6| Step: 2
Training loss: 1.212665319442749
Validation loss: 1.8674141924868348

Epoch: 6| Step: 3
Training loss: 1.3581717014312744
Validation loss: 1.8549023725653206

Epoch: 6| Step: 4
Training loss: 1.2715318202972412
Validation loss: 1.8287755853386336

Epoch: 6| Step: 5
Training loss: 2.0774688720703125
Validation loss: 1.8400677775823941

Epoch: 6| Step: 6
Training loss: 2.8470871448516846
Validation loss: 1.865476676212844

Epoch: 6| Step: 7
Training loss: 1.0957581996917725
Validation loss: 1.8581329417485062

Epoch: 6| Step: 8
Training loss: 1.3441511392593384
Validation loss: 1.8420373175733833

Epoch: 6| Step: 9
Training loss: 1.1812222003936768
Validation loss: 1.8251813598858413

Epoch: 6| Step: 10
Training loss: 1.4009993076324463
Validation loss: 1.8734154060322752

Epoch: 6| Step: 11
Training loss: 1.4875662326812744
Validation loss: 1.9041046263069235

Epoch: 6| Step: 12
Training loss: 1.2696421146392822
Validation loss: 1.8356737705969042

Epoch: 6| Step: 13
Training loss: 1.7336591482162476
Validation loss: 1.9017849276142735

Epoch: 296| Step: 0
Training loss: 1.9618923664093018
Validation loss: 1.9015151095646683

Epoch: 6| Step: 1
Training loss: 1.4477808475494385
Validation loss: 1.9171126478461809

Epoch: 6| Step: 2
Training loss: 1.1436665058135986
Validation loss: 1.9140304993557673

Epoch: 6| Step: 3
Training loss: 1.1376622915267944
Validation loss: 1.9072059469838296

Epoch: 6| Step: 4
Training loss: 1.9157534837722778
Validation loss: 1.9848244626034972

Epoch: 6| Step: 5
Training loss: 1.5489833354949951
Validation loss: 1.9344718122995028

Epoch: 6| Step: 6
Training loss: 1.6169531345367432
Validation loss: 1.8948292514329315

Epoch: 6| Step: 7
Training loss: 1.9954560995101929
Validation loss: 1.9876112438017322

Epoch: 6| Step: 8
Training loss: 1.4351615905761719
Validation loss: 1.935196461216096

Epoch: 6| Step: 9
Training loss: 1.2042514085769653
Validation loss: 1.9109775276594265

Epoch: 6| Step: 10
Training loss: 0.9879342317581177
Validation loss: 1.9125475793756463

Epoch: 6| Step: 11
Training loss: 1.2078497409820557
Validation loss: 1.8947394868378997

Epoch: 6| Step: 12
Training loss: 0.9955121278762817
Validation loss: 1.8914323186361661

Epoch: 6| Step: 13
Training loss: 2.6718690395355225
Validation loss: 1.8664521581383162

Epoch: 297| Step: 0
Training loss: 1.6888046264648438
Validation loss: 1.8512276064965032

Epoch: 6| Step: 1
Training loss: 1.9073920249938965
Validation loss: 1.9054463947972944

Epoch: 6| Step: 2
Training loss: 1.318312406539917
Validation loss: 1.8823368216073642

Epoch: 6| Step: 3
Training loss: 0.9031338691711426
Validation loss: 1.8459941110303324

Epoch: 6| Step: 4
Training loss: 1.7575069665908813
Validation loss: 1.8517050217556696

Epoch: 6| Step: 5
Training loss: 1.09263277053833
Validation loss: 1.9335088704221992

Epoch: 6| Step: 6
Training loss: 1.7143316268920898
Validation loss: 1.8574029412320865

Epoch: 6| Step: 7
Training loss: 1.336843729019165
Validation loss: 1.854569350519488

Epoch: 6| Step: 8
Training loss: 1.4719610214233398
Validation loss: 1.8380758941814463

Epoch: 6| Step: 9
Training loss: 0.9363399744033813
Validation loss: 1.8764510814861586

Epoch: 6| Step: 10
Training loss: 2.104375123977661
Validation loss: 1.9186858528403825

Epoch: 6| Step: 11
Training loss: 1.282211184501648
Validation loss: 1.8496519070799633

Epoch: 6| Step: 12
Training loss: 0.811145007610321
Validation loss: 1.9215222033121253

Epoch: 6| Step: 13
Training loss: 2.907714366912842
Validation loss: 1.844488548976119

Epoch: 298| Step: 0
Training loss: 0.8119252920150757
Validation loss: 1.9404791324369368

Epoch: 6| Step: 1
Training loss: 1.9042832851409912
Validation loss: 1.8805972119813323

Epoch: 6| Step: 2
Training loss: 1.262418508529663
Validation loss: 1.928827529312462

Epoch: 6| Step: 3
Training loss: 1.3343493938446045
Validation loss: 1.9236001532564881

Epoch: 6| Step: 4
Training loss: 1.5053067207336426
Validation loss: 1.8551448673330329

Epoch: 6| Step: 5
Training loss: 1.864166498184204
Validation loss: 1.872957529560212

Epoch: 6| Step: 6
Training loss: 1.276086449623108
Validation loss: 1.8675355449799569

Epoch: 6| Step: 7
Training loss: 1.7794245481491089
Validation loss: 1.9114724384841097

Epoch: 6| Step: 8
Training loss: 1.9339227676391602
Validation loss: 1.968142085177924

Epoch: 6| Step: 9
Training loss: 1.2051379680633545
Validation loss: 1.870901293652032

Epoch: 6| Step: 10
Training loss: 1.6410688161849976
Validation loss: 1.8872553533123386

Epoch: 6| Step: 11
Training loss: 1.4041180610656738
Validation loss: 1.877815882364909

Epoch: 6| Step: 12
Training loss: 1.0219109058380127
Validation loss: 1.9371226513257591

Epoch: 6| Step: 13
Training loss: 1.1348904371261597
Validation loss: 1.8536754064662482

Epoch: 299| Step: 0
Training loss: 1.0296679735183716
Validation loss: 1.84390079334218

Epoch: 6| Step: 1
Training loss: 1.1032652854919434
Validation loss: 1.8411588361186366

Epoch: 6| Step: 2
Training loss: 1.3907015323638916
Validation loss: 1.8465294966133692

Epoch: 6| Step: 3
Training loss: 1.853263020515442
Validation loss: 1.8657748506915184

Epoch: 6| Step: 4
Training loss: 2.0338940620422363
Validation loss: 1.8794819629320534

Epoch: 6| Step: 5
Training loss: 1.193481206893921
Validation loss: 1.8253451598587858

Epoch: 6| Step: 6
Training loss: 1.6157269477844238
Validation loss: 1.8949790218824982

Epoch: 6| Step: 7
Training loss: 1.173307180404663
Validation loss: 1.88359466163061

Epoch: 6| Step: 8
Training loss: 1.2956926822662354
Validation loss: 1.847109907416887

Epoch: 6| Step: 9
Training loss: 1.6915314197540283
Validation loss: 1.897644200632649

Epoch: 6| Step: 10
Training loss: 1.5868804454803467
Validation loss: 1.8540839187560543

Epoch: 6| Step: 11
Training loss: 1.5458025932312012
Validation loss: 1.8564412119568034

Epoch: 6| Step: 12
Training loss: 2.493480682373047
Validation loss: 1.8880700911245039

Epoch: 6| Step: 13
Training loss: 1.1213316917419434
Validation loss: 1.8344914169721707

Epoch: 300| Step: 0
Training loss: 1.376033067703247
Validation loss: 1.8859359154137232

Epoch: 6| Step: 1
Training loss: 1.1375482082366943
Validation loss: 1.8601950983847342

Epoch: 6| Step: 2
Training loss: 2.3116016387939453
Validation loss: 1.9453271204425442

Epoch: 6| Step: 3
Training loss: 1.555724859237671
Validation loss: 1.9278286246843235

Epoch: 6| Step: 4
Training loss: 1.9895098209381104
Validation loss: 1.9497122405677714

Epoch: 6| Step: 5
Training loss: 1.3359553813934326
Validation loss: 1.9741580383751982

Epoch: 6| Step: 6
Training loss: 1.5040173530578613
Validation loss: 1.9487046746797458

Epoch: 6| Step: 7
Training loss: 1.3190371990203857
Validation loss: 1.986392472379951

Epoch: 6| Step: 8
Training loss: 1.492081880569458
Validation loss: 1.9630284745206115

Epoch: 6| Step: 9
Training loss: 1.6455825567245483
Validation loss: 1.9288380325481456

Epoch: 6| Step: 10
Training loss: 1.1580572128295898
Validation loss: 1.9546848663719751

Epoch: 6| Step: 11
Training loss: 1.4667129516601562
Validation loss: 1.9067006611054944

Epoch: 6| Step: 12
Training loss: 1.0003530979156494
Validation loss: 1.864302178864838

Epoch: 6| Step: 13
Training loss: 1.9325052499771118
Validation loss: 1.8606473233110161

Testing loss: 2.2875261624654133
