Epoch: 1| Step: 0
Training loss: 5.411975860595703
Validation loss: 6.121882746296544

Epoch: 5| Step: 1
Training loss: 5.939438819885254
Validation loss: 6.115162029061266

Epoch: 5| Step: 2
Training loss: 6.436143398284912
Validation loss: 6.108314283432499

Epoch: 5| Step: 3
Training loss: 5.69069766998291
Validation loss: 6.102089481969034

Epoch: 5| Step: 4
Training loss: 7.181517601013184
Validation loss: 6.095535360356813

Epoch: 5| Step: 5
Training loss: 5.346026420593262
Validation loss: 6.087662496874409

Epoch: 5| Step: 6
Training loss: 7.368010520935059
Validation loss: 6.081937897589899

Epoch: 5| Step: 7
Training loss: 5.099090576171875
Validation loss: 6.074503888366043

Epoch: 5| Step: 8
Training loss: 4.98834753036499
Validation loss: 6.068710409184938

Epoch: 5| Step: 9
Training loss: 4.580574035644531
Validation loss: 6.060933184880082

Epoch: 5| Step: 10
Training loss: 6.818570613861084
Validation loss: 6.05436735768472

Epoch: 2| Step: 0
Training loss: 6.958039283752441
Validation loss: 6.047769695199946

Epoch: 5| Step: 1
Training loss: 6.464391231536865
Validation loss: 6.042087903586767

Epoch: 5| Step: 2
Training loss: 6.235054016113281
Validation loss: 6.0344120251235145

Epoch: 5| Step: 3
Training loss: 5.4049787521362305
Validation loss: 6.029164309142738

Epoch: 5| Step: 4
Training loss: 4.197640895843506
Validation loss: 6.022625907774894

Epoch: 5| Step: 5
Training loss: 5.9865827560424805
Validation loss: 6.013996765177737

Epoch: 5| Step: 6
Training loss: 5.7018938064575195
Validation loss: 6.009135723114014

Epoch: 5| Step: 7
Training loss: 5.52863073348999
Validation loss: 6.000816786161033

Epoch: 5| Step: 8
Training loss: 5.617304801940918
Validation loss: 5.9956684830368205

Epoch: 5| Step: 9
Training loss: 5.179103851318359
Validation loss: 5.99101294753372

Epoch: 5| Step: 10
Training loss: 6.765635013580322
Validation loss: 5.9835244353099535

Epoch: 3| Step: 0
Training loss: 5.387303352355957
Validation loss: 5.975020372739402

Epoch: 5| Step: 1
Training loss: 4.942957878112793
Validation loss: 5.9672091904506885

Epoch: 5| Step: 2
Training loss: 6.524959564208984
Validation loss: 5.961007605316818

Epoch: 5| Step: 3
Training loss: 5.032114505767822
Validation loss: 5.955120912162206

Epoch: 5| Step: 4
Training loss: 6.576432704925537
Validation loss: 5.947729572173087

Epoch: 5| Step: 5
Training loss: 6.275099754333496
Validation loss: 5.942333508563298

Epoch: 5| Step: 6
Training loss: 6.037531852722168
Validation loss: 5.935646939021285

Epoch: 5| Step: 7
Training loss: 5.96002721786499
Validation loss: 5.928063941258256

Epoch: 5| Step: 8
Training loss: 5.802839279174805
Validation loss: 5.919170600111767

Epoch: 5| Step: 9
Training loss: 5.004227638244629
Validation loss: 5.913700452414892

Epoch: 5| Step: 10
Training loss: 5.4883809089660645
Validation loss: 5.907889653277653

Epoch: 4| Step: 0
Training loss: 5.677272796630859
Validation loss: 5.900666206113754

Epoch: 5| Step: 1
Training loss: 6.25705099105835
Validation loss: 5.8967954471547115

Epoch: 5| Step: 2
Training loss: 5.547463893890381
Validation loss: 5.888235502345587

Epoch: 5| Step: 3
Training loss: 5.639725685119629
Validation loss: 5.882207849974273

Epoch: 5| Step: 4
Training loss: 6.099477767944336
Validation loss: 5.876394620505712

Epoch: 5| Step: 5
Training loss: 4.8410468101501465
Validation loss: 5.870469001031691

Epoch: 5| Step: 6
Training loss: 5.6400957107543945
Validation loss: 5.861020888051679

Epoch: 5| Step: 7
Training loss: 5.507901191711426
Validation loss: 5.852669772281442

Epoch: 5| Step: 8
Training loss: 5.600686073303223
Validation loss: 5.846818867550101

Epoch: 5| Step: 9
Training loss: 6.283764839172363
Validation loss: 5.840272995733446

Epoch: 5| Step: 10
Training loss: 5.059795379638672
Validation loss: 5.830980895667948

Epoch: 5| Step: 0
Training loss: 6.33444881439209
Validation loss: 5.826479537512666

Epoch: 5| Step: 1
Training loss: 6.219141483306885
Validation loss: 5.819577888775897

Epoch: 5| Step: 2
Training loss: 4.9972825050354
Validation loss: 5.813069261530394

Epoch: 5| Step: 3
Training loss: 5.470651626586914
Validation loss: 5.803699467771796

Epoch: 5| Step: 4
Training loss: 5.844412803649902
Validation loss: 5.797698528535904

Epoch: 5| Step: 5
Training loss: 5.5431718826293945
Validation loss: 5.789372567207582

Epoch: 5| Step: 6
Training loss: 5.125354290008545
Validation loss: 5.784083643267231

Epoch: 5| Step: 7
Training loss: 5.057370185852051
Validation loss: 5.776751661813387

Epoch: 5| Step: 8
Training loss: 6.562641143798828
Validation loss: 5.769286970938405

Epoch: 5| Step: 9
Training loss: 5.295041084289551
Validation loss: 5.762812132476478

Epoch: 5| Step: 10
Training loss: 4.806253910064697
Validation loss: 5.754682869039556

Epoch: 6| Step: 0
Training loss: 5.2177324295043945
Validation loss: 5.748842162470663

Epoch: 5| Step: 1
Training loss: 4.525885581970215
Validation loss: 5.741525665406258

Epoch: 5| Step: 2
Training loss: 5.602808475494385
Validation loss: 5.732080418576476

Epoch: 5| Step: 3
Training loss: 6.524167060852051
Validation loss: 5.725301158043646

Epoch: 5| Step: 4
Training loss: 5.371439456939697
Validation loss: 5.717959096354823

Epoch: 5| Step: 5
Training loss: 5.064187049865723
Validation loss: 5.713214382048576

Epoch: 5| Step: 6
Training loss: 5.043667793273926
Validation loss: 5.701867370195286

Epoch: 5| Step: 7
Training loss: 5.9083476066589355
Validation loss: 5.694671400131718

Epoch: 5| Step: 8
Training loss: 5.701716423034668
Validation loss: 5.68830660850771

Epoch: 5| Step: 9
Training loss: 5.62530517578125
Validation loss: 5.677724510110835

Epoch: 5| Step: 10
Training loss: 5.953807830810547
Validation loss: 5.66999533355877

Epoch: 7| Step: 0
Training loss: 6.531963348388672
Validation loss: 5.662901919375184

Epoch: 5| Step: 1
Training loss: 5.818177700042725
Validation loss: 5.653911349593952

Epoch: 5| Step: 2
Training loss: 5.860470294952393
Validation loss: 5.647735241920717

Epoch: 5| Step: 3
Training loss: 6.396505832672119
Validation loss: 5.6390803860079854

Epoch: 5| Step: 4
Training loss: 6.919046878814697
Validation loss: 5.630121005478726

Epoch: 5| Step: 5
Training loss: 4.0568342208862305
Validation loss: 5.618100504721364

Epoch: 5| Step: 6
Training loss: 5.117074966430664
Validation loss: 5.6131551650262645

Epoch: 5| Step: 7
Training loss: 4.8837385177612305
Validation loss: 5.600524927980157

Epoch: 5| Step: 8
Training loss: 4.866156578063965
Validation loss: 5.592572878765804

Epoch: 5| Step: 9
Training loss: 4.33394193649292
Validation loss: 5.586780948023642

Epoch: 5| Step: 10
Training loss: 4.563178539276123
Validation loss: 5.573872863605458

Epoch: 8| Step: 0
Training loss: 4.879894256591797
Validation loss: 5.567113876342773

Epoch: 5| Step: 1
Training loss: 5.225944519042969
Validation loss: 5.558802302165698

Epoch: 5| Step: 2
Training loss: 6.109623432159424
Validation loss: 5.549191444150863

Epoch: 5| Step: 3
Training loss: 4.288092136383057
Validation loss: 5.5396478355571785

Epoch: 5| Step: 4
Training loss: 5.427333831787109
Validation loss: 5.531908255751415

Epoch: 5| Step: 5
Training loss: 5.523420333862305
Validation loss: 5.520271019269061

Epoch: 5| Step: 6
Training loss: 5.141451835632324
Validation loss: 5.510295693592359

Epoch: 5| Step: 7
Training loss: 6.254964828491211
Validation loss: 5.50158514002318

Epoch: 5| Step: 8
Training loss: 5.648654937744141
Validation loss: 5.492718942703739

Epoch: 5| Step: 9
Training loss: 4.649308204650879
Validation loss: 5.484636701563353

Epoch: 5| Step: 10
Training loss: 5.217719554901123
Validation loss: 5.47066241951399

Epoch: 9| Step: 0
Training loss: 5.130557060241699
Validation loss: 5.459580380429504

Epoch: 5| Step: 1
Training loss: 4.795542240142822
Validation loss: 5.453120205992011

Epoch: 5| Step: 2
Training loss: 6.106228828430176
Validation loss: 5.445022726571688

Epoch: 5| Step: 3
Training loss: 5.096808433532715
Validation loss: 5.431400919473299

Epoch: 5| Step: 4
Training loss: 5.254585266113281
Validation loss: 5.420656675933509

Epoch: 5| Step: 5
Training loss: 5.878908634185791
Validation loss: 5.412869494448426

Epoch: 5| Step: 6
Training loss: 5.675080299377441
Validation loss: 5.400438113879132

Epoch: 5| Step: 7
Training loss: 4.556540489196777
Validation loss: 5.38886046665971

Epoch: 5| Step: 8
Training loss: 5.1237382888793945
Validation loss: 5.377188282628214

Epoch: 5| Step: 9
Training loss: 5.1070237159729
Validation loss: 5.3675820084028345

Epoch: 5| Step: 10
Training loss: 4.27791690826416
Validation loss: 5.354739496784825

Epoch: 10| Step: 0
Training loss: 5.206650733947754
Validation loss: 5.3438701578365855

Epoch: 5| Step: 1
Training loss: 4.463231563568115
Validation loss: 5.332089280569425

Epoch: 5| Step: 2
Training loss: 5.361083030700684
Validation loss: 5.319942987093362

Epoch: 5| Step: 3
Training loss: 4.616518497467041
Validation loss: 5.311315828754056

Epoch: 5| Step: 4
Training loss: 5.770160675048828
Validation loss: 5.294929719740344

Epoch: 5| Step: 5
Training loss: 4.549125671386719
Validation loss: 5.283397756597047

Epoch: 5| Step: 6
Training loss: 5.024163246154785
Validation loss: 5.27162225784794

Epoch: 5| Step: 7
Training loss: 4.093850612640381
Validation loss: 5.261908772171185

Epoch: 5| Step: 8
Training loss: 5.490789413452148
Validation loss: 5.247922138501239

Epoch: 5| Step: 9
Training loss: 4.537321090698242
Validation loss: 5.235867059358987

Epoch: 5| Step: 10
Training loss: 6.86958646774292
Validation loss: 5.22430601427632

Epoch: 11| Step: 0
Training loss: 4.5525007247924805
Validation loss: 5.210909751153761

Epoch: 5| Step: 1
Training loss: 4.080715179443359
Validation loss: 5.194427715834751

Epoch: 5| Step: 2
Training loss: 5.034486770629883
Validation loss: 5.179965296099263

Epoch: 5| Step: 3
Training loss: 3.3655624389648438
Validation loss: 5.172219655847036

Epoch: 5| Step: 4
Training loss: 4.284270286560059
Validation loss: 5.156292782034925

Epoch: 5| Step: 5
Training loss: 5.780542373657227
Validation loss: 5.144487452763383

Epoch: 5| Step: 6
Training loss: 5.057005882263184
Validation loss: 5.127066155915619

Epoch: 5| Step: 7
Training loss: 5.124328136444092
Validation loss: 5.114803396245485

Epoch: 5| Step: 8
Training loss: 6.032289981842041
Validation loss: 5.102771810306016

Epoch: 5| Step: 9
Training loss: 5.6885199546813965
Validation loss: 5.083093571406539

Epoch: 5| Step: 10
Training loss: 5.131961345672607
Validation loss: 5.070543104602445

Epoch: 12| Step: 0
Training loss: 6.493161678314209
Validation loss: 5.056437938444076

Epoch: 5| Step: 1
Training loss: 4.373919486999512
Validation loss: 5.042075823712093

Epoch: 5| Step: 2
Training loss: 4.605483055114746
Validation loss: 5.023878471825713

Epoch: 5| Step: 3
Training loss: 4.753814220428467
Validation loss: 5.0053556606333744

Epoch: 5| Step: 4
Training loss: 5.254876136779785
Validation loss: 4.994545387965377

Epoch: 5| Step: 5
Training loss: 3.7246146202087402
Validation loss: 4.978802532278081

Epoch: 5| Step: 6
Training loss: 5.076985836029053
Validation loss: 4.965629646855016

Epoch: 5| Step: 7
Training loss: 5.539864540100098
Validation loss: 4.949974229258876

Epoch: 5| Step: 8
Training loss: 3.5051560401916504
Validation loss: 4.93185225353446

Epoch: 5| Step: 9
Training loss: 4.158133029937744
Validation loss: 4.913050959187169

Epoch: 5| Step: 10
Training loss: 4.866745948791504
Validation loss: 4.900886458735312

Epoch: 13| Step: 0
Training loss: 4.552299499511719
Validation loss: 4.886772894090222

Epoch: 5| Step: 1
Training loss: 3.8507843017578125
Validation loss: 4.870028054842385

Epoch: 5| Step: 2
Training loss: 3.4034271240234375
Validation loss: 4.848833550689041

Epoch: 5| Step: 3
Training loss: 4.909976005554199
Validation loss: 4.837377358508366

Epoch: 5| Step: 4
Training loss: 4.941903114318848
Validation loss: 4.821254909679454

Epoch: 5| Step: 5
Training loss: 5.693082809448242
Validation loss: 4.800223042888026

Epoch: 5| Step: 6
Training loss: 5.23137092590332
Validation loss: 4.78542431451941

Epoch: 5| Step: 7
Training loss: 3.8777313232421875
Validation loss: 4.769758998706776

Epoch: 5| Step: 8
Training loss: 5.136488437652588
Validation loss: 4.752517730959

Epoch: 5| Step: 9
Training loss: 4.649613380432129
Validation loss: 4.733651750831194

Epoch: 5| Step: 10
Training loss: 4.03783655166626
Validation loss: 4.714106949426794

Epoch: 14| Step: 0
Training loss: 3.4790313243865967
Validation loss: 4.701429695211431

Epoch: 5| Step: 1
Training loss: 3.543627977371216
Validation loss: 4.673849480126494

Epoch: 5| Step: 2
Training loss: 4.796252250671387
Validation loss: 4.661284764607747

Epoch: 5| Step: 3
Training loss: 3.526216983795166
Validation loss: 4.644979082128053

Epoch: 5| Step: 4
Training loss: 5.464608192443848
Validation loss: 4.623792781624743

Epoch: 5| Step: 5
Training loss: 4.842111110687256
Validation loss: 4.6079236871452744

Epoch: 5| Step: 6
Training loss: 4.4726243019104
Validation loss: 4.583186011160573

Epoch: 5| Step: 7
Training loss: 4.598214626312256
Validation loss: 4.57447535504577

Epoch: 5| Step: 8
Training loss: 4.197934150695801
Validation loss: 4.546939121779575

Epoch: 5| Step: 9
Training loss: 4.727073669433594
Validation loss: 4.522517199157386

Epoch: 5| Step: 10
Training loss: 4.467700958251953
Validation loss: 4.506394381164222

Epoch: 15| Step: 0
Training loss: 4.255671501159668
Validation loss: 4.484998979876118

Epoch: 5| Step: 1
Training loss: 3.007880687713623
Validation loss: 4.465196578733383

Epoch: 5| Step: 2
Training loss: 4.9556074142456055
Validation loss: 4.444425462394633

Epoch: 5| Step: 3
Training loss: 4.6697492599487305
Validation loss: 4.42195580338919

Epoch: 5| Step: 4
Training loss: 3.9339518547058105
Validation loss: 4.406042545072494

Epoch: 5| Step: 5
Training loss: 3.93054461479187
Validation loss: 4.384837945302327

Epoch: 5| Step: 6
Training loss: 3.3823082447052
Validation loss: 4.355429980062669

Epoch: 5| Step: 7
Training loss: 3.6292946338653564
Validation loss: 4.337450017211258

Epoch: 5| Step: 8
Training loss: 3.8784267902374268
Validation loss: 4.320110741481986

Epoch: 5| Step: 9
Training loss: 5.282872676849365
Validation loss: 4.2976851976046

Epoch: 5| Step: 10
Training loss: 4.864889621734619
Validation loss: 4.280783653259277

Epoch: 16| Step: 0
Training loss: 5.213568687438965
Validation loss: 4.250088814766176

Epoch: 5| Step: 1
Training loss: 3.445344924926758
Validation loss: 4.236925155885758

Epoch: 5| Step: 2
Training loss: 4.866657257080078
Validation loss: 4.2168918066127326

Epoch: 5| Step: 3
Training loss: 2.9670028686523438
Validation loss: 4.1962178445631455

Epoch: 5| Step: 4
Training loss: 2.9410927295684814
Validation loss: 4.1669961149974535

Epoch: 5| Step: 5
Training loss: 3.8863232135772705
Validation loss: 4.149596393749278

Epoch: 5| Step: 6
Training loss: 3.563429594039917
Validation loss: 4.1282213990406325

Epoch: 5| Step: 7
Training loss: 4.582849502563477
Validation loss: 4.113629079634143

Epoch: 5| Step: 8
Training loss: 4.070811748504639
Validation loss: 4.091131723055276

Epoch: 5| Step: 9
Training loss: 3.9683890342712402
Validation loss: 4.061639473002444

Epoch: 5| Step: 10
Training loss: 3.8771066665649414
Validation loss: 4.037841889166063

Epoch: 17| Step: 0
Training loss: 3.088364362716675
Validation loss: 4.015877205838439

Epoch: 5| Step: 1
Training loss: 3.701143980026245
Validation loss: 4.001042053263674

Epoch: 5| Step: 2
Training loss: 3.1244893074035645
Validation loss: 3.9752384898483113

Epoch: 5| Step: 3
Training loss: 3.1726744174957275
Validation loss: 3.9628096601014495

Epoch: 5| Step: 4
Training loss: 4.175049781799316
Validation loss: 3.9359751542409263

Epoch: 5| Step: 5
Training loss: 3.5845909118652344
Validation loss: 3.9180967782133367

Epoch: 5| Step: 6
Training loss: 4.784543037414551
Validation loss: 3.894540391942506

Epoch: 5| Step: 7
Training loss: 3.849010467529297
Validation loss: 3.865731382882723

Epoch: 5| Step: 8
Training loss: 3.4909088611602783
Validation loss: 3.848737270601334

Epoch: 5| Step: 9
Training loss: 3.988312244415283
Validation loss: 3.8204844485047045

Epoch: 5| Step: 10
Training loss: 4.119793891906738
Validation loss: 3.805632834793419

Epoch: 18| Step: 0
Training loss: 3.8305447101593018
Validation loss: 3.781431057119882

Epoch: 5| Step: 1
Training loss: 3.4577057361602783
Validation loss: 3.7538497704331593

Epoch: 5| Step: 2
Training loss: 3.391979217529297
Validation loss: 3.7355176787222586

Epoch: 5| Step: 3
Training loss: 4.04318904876709
Validation loss: 3.707267379248014

Epoch: 5| Step: 4
Training loss: 3.0118186473846436
Validation loss: 3.6851861912717103

Epoch: 5| Step: 5
Training loss: 3.5669586658477783
Validation loss: 3.660576041026782

Epoch: 5| Step: 6
Training loss: 4.473086357116699
Validation loss: 3.63691226384973

Epoch: 5| Step: 7
Training loss: 3.0455827713012695
Validation loss: 3.6138940677847913

Epoch: 5| Step: 8
Training loss: 4.283330917358398
Validation loss: 3.5961066651087936

Epoch: 5| Step: 9
Training loss: 3.1003284454345703
Validation loss: 3.5703435764517835

Epoch: 5| Step: 10
Training loss: 2.364211320877075
Validation loss: 3.543066511871994

Epoch: 19| Step: 0
Training loss: 3.8300411701202393
Validation loss: 3.5230846969030236

Epoch: 5| Step: 1
Training loss: 3.2752766609191895
Validation loss: 3.5071231729240826

Epoch: 5| Step: 2
Training loss: 3.8075478076934814
Validation loss: 3.4825663002588416

Epoch: 5| Step: 3
Training loss: 3.5305798053741455
Validation loss: 3.4567683127618607

Epoch: 5| Step: 4
Training loss: 3.7726409435272217
Validation loss: 3.43947632082047

Epoch: 5| Step: 5
Training loss: 2.826775074005127
Validation loss: 3.411070362214119

Epoch: 5| Step: 6
Training loss: 3.8484673500061035
Validation loss: 3.3855947320179274

Epoch: 5| Step: 7
Training loss: 3.486410617828369
Validation loss: 3.364296285055017

Epoch: 5| Step: 8
Training loss: 2.0930402278900146
Validation loss: 3.3404046540619223

Epoch: 5| Step: 9
Training loss: 2.397204875946045
Validation loss: 3.315296306405016

Epoch: 5| Step: 10
Training loss: 3.504956007003784
Validation loss: 3.3031569834678405

Epoch: 20| Step: 0
Training loss: 3.3488128185272217
Validation loss: 3.2689883734590266

Epoch: 5| Step: 1
Training loss: 2.8181252479553223
Validation loss: 3.2423405339640956

Epoch: 5| Step: 2
Training loss: 2.5042614936828613
Validation loss: 3.2399522719844693

Epoch: 5| Step: 3
Training loss: 2.7933735847473145
Validation loss: 3.2091040918903966

Epoch: 5| Step: 4
Training loss: 3.2537026405334473
Validation loss: 3.1873828288047545

Epoch: 5| Step: 5
Training loss: 2.81687593460083
Validation loss: 3.1689797447573755

Epoch: 5| Step: 6
Training loss: 3.4314918518066406
Validation loss: 3.1573329048772014

Epoch: 5| Step: 7
Training loss: 3.601496934890747
Validation loss: 3.1303045339481805

Epoch: 5| Step: 8
Training loss: 2.7772445678710938
Validation loss: 3.1167642224219536

Epoch: 5| Step: 9
Training loss: 4.044538497924805
Validation loss: 3.0959558076755975

Epoch: 5| Step: 10
Training loss: 2.8524179458618164
Validation loss: 3.073213005578646

Epoch: 21| Step: 0
Training loss: 2.814570903778076
Validation loss: 3.0476558080283542

Epoch: 5| Step: 1
Training loss: 2.2217345237731934
Validation loss: 3.034608515360022

Epoch: 5| Step: 2
Training loss: 2.9839460849761963
Validation loss: 3.0064235835947017

Epoch: 5| Step: 3
Training loss: 2.3767733573913574
Validation loss: 2.9928960518170427

Epoch: 5| Step: 4
Training loss: 2.8103904724121094
Validation loss: 2.977736516665387

Epoch: 5| Step: 5
Training loss: 3.103116273880005
Validation loss: 2.967633852394678

Epoch: 5| Step: 6
Training loss: 3.6950879096984863
Validation loss: 2.955320704367853

Epoch: 5| Step: 7
Training loss: 3.727944850921631
Validation loss: 2.928285111663162

Epoch: 5| Step: 8
Training loss: 2.479916572570801
Validation loss: 2.9168140554940827

Epoch: 5| Step: 9
Training loss: 3.151869297027588
Validation loss: 2.8767591163676274

Epoch: 5| Step: 10
Training loss: 3.253598928451538
Validation loss: 2.8597827957522486

Epoch: 22| Step: 0
Training loss: 3.8506760597229004
Validation loss: 2.8395806435615785

Epoch: 5| Step: 1
Training loss: 2.144700527191162
Validation loss: 2.8229818882480746

Epoch: 5| Step: 2
Training loss: 2.8975753784179688
Validation loss: 2.8082867001974456

Epoch: 5| Step: 3
Training loss: 3.238025188446045
Validation loss: 2.7886398710230345

Epoch: 5| Step: 4
Training loss: 2.303513526916504
Validation loss: 2.7758784217219197

Epoch: 5| Step: 5
Training loss: 2.924091100692749
Validation loss: 2.751939150594896

Epoch: 5| Step: 6
Training loss: 2.9150328636169434
Validation loss: 2.7451428418518393

Epoch: 5| Step: 7
Training loss: 3.3047561645507812
Validation loss: 2.7266328206626316

Epoch: 5| Step: 8
Training loss: 2.4478187561035156
Validation loss: 2.690936626926545

Epoch: 5| Step: 9
Training loss: 2.6488194465637207
Validation loss: 2.693327678147183

Epoch: 5| Step: 10
Training loss: 2.3627328872680664
Validation loss: 2.662793705540319

Epoch: 23| Step: 0
Training loss: 2.328693151473999
Validation loss: 2.6516542255237536

Epoch: 5| Step: 1
Training loss: 2.6403465270996094
Validation loss: 2.622870804161154

Epoch: 5| Step: 2
Training loss: 2.3147435188293457
Validation loss: 2.611204977958433

Epoch: 5| Step: 3
Training loss: 2.4507737159729004
Validation loss: 2.5905145009358725

Epoch: 5| Step: 4
Training loss: 3.0056087970733643
Validation loss: 2.57659121482603

Epoch: 5| Step: 5
Training loss: 3.077439069747925
Validation loss: 2.560314457903626

Epoch: 5| Step: 6
Training loss: 2.1877779960632324
Validation loss: 2.5434605870195615

Epoch: 5| Step: 7
Training loss: 2.5256896018981934
Validation loss: 2.516061895637102

Epoch: 5| Step: 8
Training loss: 2.9395456314086914
Validation loss: 2.5107021844515236

Epoch: 5| Step: 9
Training loss: 2.6098504066467285
Validation loss: 2.4951697088056997

Epoch: 5| Step: 10
Training loss: 3.6325929164886475
Validation loss: 2.479912345127393

Epoch: 24| Step: 0
Training loss: 2.3510348796844482
Validation loss: 2.4658706111292683

Epoch: 5| Step: 1
Training loss: 2.914559841156006
Validation loss: 2.456028974184426

Epoch: 5| Step: 2
Training loss: 2.7960612773895264
Validation loss: 2.412244563461632

Epoch: 5| Step: 3
Training loss: 2.9841296672821045
Validation loss: 2.422973204684514

Epoch: 5| Step: 4
Training loss: 2.4604148864746094
Validation loss: 2.4244206592600834

Epoch: 5| Step: 5
Training loss: 2.68498158454895
Validation loss: 2.3984413454609532

Epoch: 5| Step: 6
Training loss: 2.1526267528533936
Validation loss: 2.3995226121717885

Epoch: 5| Step: 7
Training loss: 2.6968064308166504
Validation loss: 2.3926615997027327

Epoch: 5| Step: 8
Training loss: 2.3306360244750977
Validation loss: 2.3822584459858556

Epoch: 5| Step: 9
Training loss: 2.3888401985168457
Validation loss: 2.3642910911190893

Epoch: 5| Step: 10
Training loss: 2.6494126319885254
Validation loss: 2.358252884239279

Epoch: 25| Step: 0
Training loss: 3.079350709915161
Validation loss: 2.355005633446478

Epoch: 5| Step: 1
Training loss: 2.9745097160339355
Validation loss: 2.3293318440837245

Epoch: 5| Step: 2
Training loss: 2.680614948272705
Validation loss: 2.3178577884551017

Epoch: 5| Step: 3
Training loss: 2.5646166801452637
Validation loss: 2.3279376235059512

Epoch: 5| Step: 4
Training loss: 2.673337459564209
Validation loss: 2.3115927609064246

Epoch: 5| Step: 5
Training loss: 2.420093059539795
Validation loss: 2.3016237520402476

Epoch: 5| Step: 6
Training loss: 2.619148015975952
Validation loss: 2.30212753306153

Epoch: 5| Step: 7
Training loss: 2.1094555854797363
Validation loss: 2.2919473865980744

Epoch: 5| Step: 8
Training loss: 2.077889919281006
Validation loss: 2.2674778802420503

Epoch: 5| Step: 9
Training loss: 2.557323455810547
Validation loss: 2.2706695192603656

Epoch: 5| Step: 10
Training loss: 2.0026731491088867
Validation loss: 2.2649450712306525

Epoch: 26| Step: 0
Training loss: 2.1884100437164307
Validation loss: 2.2617401333265406

Epoch: 5| Step: 1
Training loss: 2.4712512493133545
Validation loss: 2.229722434474576

Epoch: 5| Step: 2
Training loss: 2.151270627975464
Validation loss: 2.2636355225757887

Epoch: 5| Step: 3
Training loss: 2.3009533882141113
Validation loss: 2.2315564732397757

Epoch: 5| Step: 4
Training loss: 2.8353395462036133
Validation loss: 2.242812643768967

Epoch: 5| Step: 5
Training loss: 2.8244519233703613
Validation loss: 2.2300361382064

Epoch: 5| Step: 6
Training loss: 2.6447558403015137
Validation loss: 2.241881493599184

Epoch: 5| Step: 7
Training loss: 3.1398508548736572
Validation loss: 2.235452005940099

Epoch: 5| Step: 8
Training loss: 2.204000473022461
Validation loss: 2.241283555184641

Epoch: 5| Step: 9
Training loss: 2.8084473609924316
Validation loss: 2.2365306603011263

Epoch: 5| Step: 10
Training loss: 1.9436488151550293
Validation loss: 2.2166024151668755

Epoch: 27| Step: 0
Training loss: 2.437070369720459
Validation loss: 2.224381700638802

Epoch: 5| Step: 1
Training loss: 2.1044318675994873
Validation loss: 2.2322280817134406

Epoch: 5| Step: 2
Training loss: 2.9904403686523438
Validation loss: 2.214019895881735

Epoch: 5| Step: 3
Training loss: 2.0727670192718506
Validation loss: 2.2096411976762997

Epoch: 5| Step: 4
Training loss: 2.4546597003936768
Validation loss: 2.229621874388828

Epoch: 5| Step: 5
Training loss: 3.123098850250244
Validation loss: 2.2244078395187215

Epoch: 5| Step: 6
Training loss: 2.5905981063842773
Validation loss: 2.218514039952268

Epoch: 5| Step: 7
Training loss: 2.75372576713562
Validation loss: 2.2277441511871996

Epoch: 5| Step: 8
Training loss: 2.7342000007629395
Validation loss: 2.2212866506268902

Epoch: 5| Step: 9
Training loss: 2.020394802093506
Validation loss: 2.2347927683143207

Epoch: 5| Step: 10
Training loss: 2.111107110977173
Validation loss: 2.2187499897454375

Epoch: 28| Step: 0
Training loss: 2.5452048778533936
Validation loss: 2.2198765431680987

Epoch: 5| Step: 1
Training loss: 1.9192603826522827
Validation loss: 2.2352359679437455

Epoch: 5| Step: 2
Training loss: 2.4728403091430664
Validation loss: 2.2175121538100706

Epoch: 5| Step: 3
Training loss: 2.5946860313415527
Validation loss: 2.229412437767111

Epoch: 5| Step: 4
Training loss: 2.6475794315338135
Validation loss: 2.210013722860685

Epoch: 5| Step: 5
Training loss: 1.924246072769165
Validation loss: 2.2326774263894684

Epoch: 5| Step: 6
Training loss: 3.427072525024414
Validation loss: 2.194510667554794

Epoch: 5| Step: 7
Training loss: 2.1960182189941406
Validation loss: 2.2225163623850834

Epoch: 5| Step: 8
Training loss: 3.2122809886932373
Validation loss: 2.216000021144908

Epoch: 5| Step: 9
Training loss: 1.8160209655761719
Validation loss: 2.209718550405195

Epoch: 5| Step: 10
Training loss: 2.600127696990967
Validation loss: 2.20100986829368

Epoch: 29| Step: 0
Training loss: 2.5616466999053955
Validation loss: 2.218619769619357

Epoch: 5| Step: 1
Training loss: 2.1134610176086426
Validation loss: 2.207847882342595

Epoch: 5| Step: 2
Training loss: 1.7441809177398682
Validation loss: 2.210983604513189

Epoch: 5| Step: 3
Training loss: 2.927034378051758
Validation loss: 2.2250991457252094

Epoch: 5| Step: 4
Training loss: 2.769888401031494
Validation loss: 2.2100271589012555

Epoch: 5| Step: 5
Training loss: 2.3886165618896484
Validation loss: 2.2231552677769817

Epoch: 5| Step: 6
Training loss: 2.24202299118042
Validation loss: 2.216519299373832

Epoch: 5| Step: 7
Training loss: 2.166527032852173
Validation loss: 2.2140787468161633

Epoch: 5| Step: 8
Training loss: 2.2677409648895264
Validation loss: 2.2120922239877845

Epoch: 5| Step: 9
Training loss: 3.116417407989502
Validation loss: 2.2101693871200725

Epoch: 5| Step: 10
Training loss: 3.296640396118164
Validation loss: 2.2052632377993677

Epoch: 30| Step: 0
Training loss: 3.018467664718628
Validation loss: 2.21011846808977

Epoch: 5| Step: 1
Training loss: 2.8924148082733154
Validation loss: 2.1975410753680813

Epoch: 5| Step: 2
Training loss: 2.5955111980438232
Validation loss: 2.203220792995986

Epoch: 5| Step: 3
Training loss: 1.6133531332015991
Validation loss: 2.210061498867568

Epoch: 5| Step: 4
Training loss: 2.744631052017212
Validation loss: 2.2034414814364527

Epoch: 5| Step: 5
Training loss: 2.0571155548095703
Validation loss: 2.1982745508993826

Epoch: 5| Step: 6
Training loss: 2.5970816612243652
Validation loss: 2.2032443374715824

Epoch: 5| Step: 7
Training loss: 2.815412998199463
Validation loss: 2.1891402736786874

Epoch: 5| Step: 8
Training loss: 2.4957878589630127
Validation loss: 2.210057489333614

Epoch: 5| Step: 9
Training loss: 2.414947032928467
Validation loss: 2.1842807313447357

Epoch: 5| Step: 10
Training loss: 1.8271031379699707
Validation loss: 2.184810612791328

Epoch: 31| Step: 0
Training loss: 2.2359619140625
Validation loss: 2.2055724461873374

Epoch: 5| Step: 1
Training loss: 2.655975103378296
Validation loss: 2.1995771136335147

Epoch: 5| Step: 2
Training loss: 2.8487327098846436
Validation loss: 2.1967277039763746

Epoch: 5| Step: 3
Training loss: 2.3919880390167236
Validation loss: 2.2102144354133197

Epoch: 5| Step: 4
Training loss: 2.2873668670654297
Validation loss: 2.21285319071944

Epoch: 5| Step: 5
Training loss: 2.640089511871338
Validation loss: 2.197897729053292

Epoch: 5| Step: 6
Training loss: 2.432685375213623
Validation loss: 2.194610905903642

Epoch: 5| Step: 7
Training loss: 3.103066921234131
Validation loss: 2.185288308769144

Epoch: 5| Step: 8
Training loss: 2.255749464035034
Validation loss: 2.1917080263937674

Epoch: 5| Step: 9
Training loss: 2.0147030353546143
Validation loss: 2.191291137408185

Epoch: 5| Step: 10
Training loss: 2.311000108718872
Validation loss: 2.190167966709342

Epoch: 32| Step: 0
Training loss: 1.9985183477401733
Validation loss: 2.185649610334827

Epoch: 5| Step: 1
Training loss: 2.495008707046509
Validation loss: 2.18531959672128

Epoch: 5| Step: 2
Training loss: 2.539593458175659
Validation loss: 2.195945025772177

Epoch: 5| Step: 3
Training loss: 2.0820298194885254
Validation loss: 2.1983271106596916

Epoch: 5| Step: 4
Training loss: 2.573057174682617
Validation loss: 2.196042399252615

Epoch: 5| Step: 5
Training loss: 2.519998550415039
Validation loss: 2.1953004149980444

Epoch: 5| Step: 6
Training loss: 2.3172523975372314
Validation loss: 2.1819286500253985

Epoch: 5| Step: 7
Training loss: 2.9849283695220947
Validation loss: 2.205084405919557

Epoch: 5| Step: 8
Training loss: 2.859768867492676
Validation loss: 2.1983343555081274

Epoch: 5| Step: 9
Training loss: 2.12666654586792
Validation loss: 2.2006966413990146

Epoch: 5| Step: 10
Training loss: 2.7812373638153076
Validation loss: 2.1940425365201888

Epoch: 33| Step: 0
Training loss: 2.2687408924102783
Validation loss: 2.196755104167487

Epoch: 5| Step: 1
Training loss: 2.9472663402557373
Validation loss: 2.190585328686622

Epoch: 5| Step: 2
Training loss: 2.1876027584075928
Validation loss: 2.1979051610474944

Epoch: 5| Step: 3
Training loss: 2.961223840713501
Validation loss: 2.2083076520632674

Epoch: 5| Step: 4
Training loss: 2.2993550300598145
Validation loss: 2.1986372765674385

Epoch: 5| Step: 5
Training loss: 2.560504913330078
Validation loss: 2.1871302089383526

Epoch: 5| Step: 6
Training loss: 2.0945827960968018
Validation loss: 2.206218488754765

Epoch: 5| Step: 7
Training loss: 2.2324912548065186
Validation loss: 2.183283958383786

Epoch: 5| Step: 8
Training loss: 2.298686981201172
Validation loss: 2.1774647338415987

Epoch: 5| Step: 9
Training loss: 2.549240827560425
Validation loss: 2.184676121639949

Epoch: 5| Step: 10
Training loss: 2.744668483734131
Validation loss: 2.1910024842908307

Epoch: 34| Step: 0
Training loss: 1.9210138320922852
Validation loss: 2.198199015791698

Epoch: 5| Step: 1
Training loss: 2.6215243339538574
Validation loss: 2.191414894596223

Epoch: 5| Step: 2
Training loss: 2.346841335296631
Validation loss: 2.1911197862317486

Epoch: 5| Step: 3
Training loss: 2.8986403942108154
Validation loss: 2.2034289606155886

Epoch: 5| Step: 4
Training loss: 1.7824814319610596
Validation loss: 2.17906674005652

Epoch: 5| Step: 5
Training loss: 1.8378589153289795
Validation loss: 2.18035154573379

Epoch: 5| Step: 6
Training loss: 3.156507730484009
Validation loss: 2.189838114605155

Epoch: 5| Step: 7
Training loss: 2.5428078174591064
Validation loss: 2.1830059841114986

Epoch: 5| Step: 8
Training loss: 2.5072264671325684
Validation loss: 2.1631898880004883

Epoch: 5| Step: 9
Training loss: 2.687133312225342
Validation loss: 2.1947014639454503

Epoch: 5| Step: 10
Training loss: 2.816690444946289
Validation loss: 2.1776662411228305

Epoch: 35| Step: 0
Training loss: 2.0916099548339844
Validation loss: 2.200585557568458

Epoch: 5| Step: 1
Training loss: 2.2683262825012207
Validation loss: 2.1823798943591375

Epoch: 5| Step: 2
Training loss: 2.581134796142578
Validation loss: 2.1767708255398657

Epoch: 5| Step: 3
Training loss: 2.46290922164917
Validation loss: 2.1799902967227403

Epoch: 5| Step: 4
Training loss: 3.0662243366241455
Validation loss: 2.16989500804614

Epoch: 5| Step: 5
Training loss: 2.3832385540008545
Validation loss: 2.212049291979882

Epoch: 5| Step: 6
Training loss: 2.456599473953247
Validation loss: 2.186060723438058

Epoch: 5| Step: 7
Training loss: 2.558582305908203
Validation loss: 2.18201006227924

Epoch: 5| Step: 8
Training loss: 2.2169365882873535
Validation loss: 2.1955135842805267

Epoch: 5| Step: 9
Training loss: 2.387676477432251
Validation loss: 2.1996325241622103

Epoch: 5| Step: 10
Training loss: 2.463735580444336
Validation loss: 2.192602757484682

Epoch: 36| Step: 0
Training loss: 2.199518918991089
Validation loss: 2.182786783864421

Epoch: 5| Step: 1
Training loss: 2.6504130363464355
Validation loss: 2.198905974306086

Epoch: 5| Step: 2
Training loss: 2.6249992847442627
Validation loss: 2.187585610215382

Epoch: 5| Step: 3
Training loss: 2.3324570655822754
Validation loss: 2.193810560370004

Epoch: 5| Step: 4
Training loss: 2.5348334312438965
Validation loss: 2.187320186245826

Epoch: 5| Step: 5
Training loss: 1.681735634803772
Validation loss: 2.1797438295938636

Epoch: 5| Step: 6
Training loss: 2.7673373222351074
Validation loss: 2.184556876459429

Epoch: 5| Step: 7
Training loss: 1.895237922668457
Validation loss: 2.1774033628484255

Epoch: 5| Step: 8
Training loss: 3.42826509475708
Validation loss: 2.1849949667530675

Epoch: 5| Step: 9
Training loss: 2.2360405921936035
Validation loss: 2.17528243987791

Epoch: 5| Step: 10
Training loss: 2.5836732387542725
Validation loss: 2.2058105686659455

Epoch: 37| Step: 0
Training loss: 2.8329906463623047
Validation loss: 2.175368542312294

Epoch: 5| Step: 1
Training loss: 2.422891139984131
Validation loss: 2.1846486547941804

Epoch: 5| Step: 2
Training loss: 2.908903121948242
Validation loss: 2.1709538839196645

Epoch: 5| Step: 3
Training loss: 2.450554132461548
Validation loss: 2.169686584062474

Epoch: 5| Step: 4
Training loss: 1.8368685245513916
Validation loss: 2.167742375404604

Epoch: 5| Step: 5
Training loss: 2.5870137214660645
Validation loss: 2.1974147340302825

Epoch: 5| Step: 6
Training loss: 3.104116916656494
Validation loss: 2.2029188858565463

Epoch: 5| Step: 7
Training loss: 2.10325288772583
Validation loss: 2.2035059326438495

Epoch: 5| Step: 8
Training loss: 1.5455248355865479
Validation loss: 2.1875134924406647

Epoch: 5| Step: 9
Training loss: 2.2164928913116455
Validation loss: 2.1787140189960437

Epoch: 5| Step: 10
Training loss: 2.740020990371704
Validation loss: 2.17701748365997

Epoch: 38| Step: 0
Training loss: 2.0817999839782715
Validation loss: 2.1674381930341005

Epoch: 5| Step: 1
Training loss: 2.5424129962921143
Validation loss: 2.1707489618691067

Epoch: 5| Step: 2
Training loss: 2.268688678741455
Validation loss: 2.1509390941230198

Epoch: 5| Step: 3
Training loss: 2.8716444969177246
Validation loss: 2.180045188114207

Epoch: 5| Step: 4
Training loss: 2.4285762310028076
Validation loss: 2.173732670404578

Epoch: 5| Step: 5
Training loss: 2.4492104053497314
Validation loss: 2.185931190367668

Epoch: 5| Step: 6
Training loss: 1.8388025760650635
Validation loss: 2.1509300047351467

Epoch: 5| Step: 7
Training loss: 2.5321593284606934
Validation loss: 2.1758525986825266

Epoch: 5| Step: 8
Training loss: 2.8192217350006104
Validation loss: 2.1572544113282235

Epoch: 5| Step: 9
Training loss: 2.1964950561523438
Validation loss: 2.179064663507605

Epoch: 5| Step: 10
Training loss: 2.8405606746673584
Validation loss: 2.171015226712791

Epoch: 39| Step: 0
Training loss: 1.9008817672729492
Validation loss: 2.169958799116073

Epoch: 5| Step: 1
Training loss: 2.3523178100585938
Validation loss: 2.163521880744606

Epoch: 5| Step: 2
Training loss: 2.388204574584961
Validation loss: 2.1625769984337593

Epoch: 5| Step: 3
Training loss: 2.396766424179077
Validation loss: 2.164254729465772

Epoch: 5| Step: 4
Training loss: 2.7721033096313477
Validation loss: 2.1661860712112917

Epoch: 5| Step: 5
Training loss: 2.4993062019348145
Validation loss: 2.161149868401148

Epoch: 5| Step: 6
Training loss: 2.099607229232788
Validation loss: 2.157674281827865

Epoch: 5| Step: 7
Training loss: 2.4803502559661865
Validation loss: 2.1685933682226364

Epoch: 5| Step: 8
Training loss: 2.9152207374572754
Validation loss: 2.161608208892166

Epoch: 5| Step: 9
Training loss: 2.350515842437744
Validation loss: 2.1700733912888395

Epoch: 5| Step: 10
Training loss: 2.485088586807251
Validation loss: 2.1501924914698445

Epoch: 40| Step: 0
Training loss: 2.7425904273986816
Validation loss: 2.1569816784192155

Epoch: 5| Step: 1
Training loss: 1.906050443649292
Validation loss: 2.163035523506903

Epoch: 5| Step: 2
Training loss: 2.388087749481201
Validation loss: 2.171420326796911

Epoch: 5| Step: 3
Training loss: 1.884312391281128
Validation loss: 2.1527765912394368

Epoch: 5| Step: 4
Training loss: 2.6064419746398926
Validation loss: 2.1633098612549486

Epoch: 5| Step: 5
Training loss: 2.5123648643493652
Validation loss: 2.1631238511813584

Epoch: 5| Step: 6
Training loss: 3.1283504962921143
Validation loss: 2.1519692354304816

Epoch: 5| Step: 7
Training loss: 2.4504027366638184
Validation loss: 2.1606300748804563

Epoch: 5| Step: 8
Training loss: 2.0481467247009277
Validation loss: 2.153025742500059

Epoch: 5| Step: 9
Training loss: 2.260439395904541
Validation loss: 2.1681890846580587

Epoch: 5| Step: 10
Training loss: 2.7739157676696777
Validation loss: 2.1664842354354037

Epoch: 41| Step: 0
Training loss: 2.6511759757995605
Validation loss: 2.164680498902516

Epoch: 5| Step: 1
Training loss: 2.5098347663879395
Validation loss: 2.1538579335776706

Epoch: 5| Step: 2
Training loss: 2.3404319286346436
Validation loss: 2.160318454106649

Epoch: 5| Step: 3
Training loss: 3.077770709991455
Validation loss: 2.159823002353791

Epoch: 5| Step: 4
Training loss: 2.7313811779022217
Validation loss: 2.1618611299863426

Epoch: 5| Step: 5
Training loss: 1.7789005041122437
Validation loss: 2.162950449092414

Epoch: 5| Step: 6
Training loss: 2.890542507171631
Validation loss: 2.1714453710022794

Epoch: 5| Step: 7
Training loss: 1.9182924032211304
Validation loss: 2.150728943527386

Epoch: 5| Step: 8
Training loss: 1.8671537637710571
Validation loss: 2.155497443291449

Epoch: 5| Step: 9
Training loss: 2.674504518508911
Validation loss: 2.169466044313164

Epoch: 5| Step: 10
Training loss: 2.1327173709869385
Validation loss: 2.161386492431805

Epoch: 42| Step: 0
Training loss: 2.224015474319458
Validation loss: 2.1549297994182957

Epoch: 5| Step: 1
Training loss: 2.478759527206421
Validation loss: 2.1692091136850338

Epoch: 5| Step: 2
Training loss: 2.274127960205078
Validation loss: 2.151919549511325

Epoch: 5| Step: 3
Training loss: 2.39729380607605
Validation loss: 2.163147844294066

Epoch: 5| Step: 4
Training loss: 2.7834391593933105
Validation loss: 2.163357224515689

Epoch: 5| Step: 5
Training loss: 2.183638572692871
Validation loss: 2.169688552938482

Epoch: 5| Step: 6
Training loss: 3.419214963912964
Validation loss: 2.1527150907824115

Epoch: 5| Step: 7
Training loss: 2.606478214263916
Validation loss: 2.148195796115424

Epoch: 5| Step: 8
Training loss: 1.7180900573730469
Validation loss: 2.175445830950173

Epoch: 5| Step: 9
Training loss: 1.9714082479476929
Validation loss: 2.144443545290219

Epoch: 5| Step: 10
Training loss: 2.5383191108703613
Validation loss: 2.1662057394622476

Epoch: 43| Step: 0
Training loss: 2.343869686126709
Validation loss: 2.18687452039411

Epoch: 5| Step: 1
Training loss: 2.706951379776001
Validation loss: 2.154350265379875

Epoch: 5| Step: 2
Training loss: 2.961632251739502
Validation loss: 2.148504558429923

Epoch: 5| Step: 3
Training loss: 1.98957097530365
Validation loss: 2.1704416275024414

Epoch: 5| Step: 4
Training loss: 2.17508864402771
Validation loss: 2.1551112705661404

Epoch: 5| Step: 5
Training loss: 2.305302143096924
Validation loss: 2.1709002474302888

Epoch: 5| Step: 6
Training loss: 2.4146764278411865
Validation loss: 2.1432422925067205

Epoch: 5| Step: 7
Training loss: 2.571821928024292
Validation loss: 2.1641708035622873

Epoch: 5| Step: 8
Training loss: 2.096810817718506
Validation loss: 2.1395809214602233

Epoch: 5| Step: 9
Training loss: 2.385899066925049
Validation loss: 2.1536014438957296

Epoch: 5| Step: 10
Training loss: 2.4915761947631836
Validation loss: 2.1516056624791955

Epoch: 44| Step: 0
Training loss: 2.382922410964966
Validation loss: 2.1433844130526305

Epoch: 5| Step: 1
Training loss: 2.5860018730163574
Validation loss: 2.1560295166507846

Epoch: 5| Step: 2
Training loss: 2.449282169342041
Validation loss: 2.1479264074756252

Epoch: 5| Step: 3
Training loss: 2.086555004119873
Validation loss: 2.1350877925913823

Epoch: 5| Step: 4
Training loss: 2.4386305809020996
Validation loss: 2.134866165858443

Epoch: 5| Step: 5
Training loss: 2.7037582397460938
Validation loss: 2.1468261621331655

Epoch: 5| Step: 6
Training loss: 2.3486530780792236
Validation loss: 2.1414623414316485

Epoch: 5| Step: 7
Training loss: 2.456446409225464
Validation loss: 2.1358173918980423

Epoch: 5| Step: 8
Training loss: 2.4246058464050293
Validation loss: 2.1432324019811486

Epoch: 5| Step: 9
Training loss: 2.1854708194732666
Validation loss: 2.1673289588702622

Epoch: 5| Step: 10
Training loss: 2.4484875202178955
Validation loss: 2.1410303064571914

Epoch: 45| Step: 0
Training loss: 2.1838502883911133
Validation loss: 2.151140853922854

Epoch: 5| Step: 1
Training loss: 2.8031814098358154
Validation loss: 2.1686806281407676

Epoch: 5| Step: 2
Training loss: 2.3346219062805176
Validation loss: 2.1368634764866163

Epoch: 5| Step: 3
Training loss: 2.488696575164795
Validation loss: 2.148915216486941

Epoch: 5| Step: 4
Training loss: 2.433666944503784
Validation loss: 2.1438094544154342

Epoch: 5| Step: 5
Training loss: 2.597288131713867
Validation loss: 2.1342345924787622

Epoch: 5| Step: 6
Training loss: 2.015932559967041
Validation loss: 2.1433732022521315

Epoch: 5| Step: 7
Training loss: 2.3796989917755127
Validation loss: 2.1505597535000054

Epoch: 5| Step: 8
Training loss: 2.464064359664917
Validation loss: 2.1263194699441232

Epoch: 5| Step: 9
Training loss: 2.258828639984131
Validation loss: 2.1699852315328454

Epoch: 5| Step: 10
Training loss: 2.3338687419891357
Validation loss: 2.132875839869181

Epoch: 46| Step: 0
Training loss: 3.1417019367218018
Validation loss: 2.1512228186412523

Epoch: 5| Step: 1
Training loss: 2.2255680561065674
Validation loss: 2.115703025171834

Epoch: 5| Step: 2
Training loss: 1.5823570489883423
Validation loss: 2.1448299372068016

Epoch: 5| Step: 3
Training loss: 2.176978349685669
Validation loss: 2.1276912458481325

Epoch: 5| Step: 4
Training loss: 2.514111042022705
Validation loss: 2.1376318059941775

Epoch: 5| Step: 5
Training loss: 2.3052728176116943
Validation loss: 2.116327110157218

Epoch: 5| Step: 6
Training loss: 2.683835506439209
Validation loss: 2.131529172261556

Epoch: 5| Step: 7
Training loss: 3.0855929851531982
Validation loss: 2.1443035423114734

Epoch: 5| Step: 8
Training loss: 1.9562091827392578
Validation loss: 2.1467216681408625

Epoch: 5| Step: 9
Training loss: 2.4740278720855713
Validation loss: 2.117768615804693

Epoch: 5| Step: 10
Training loss: 2.2729289531707764
Validation loss: 2.1340515972465597

Epoch: 47| Step: 0
Training loss: 2.1681981086730957
Validation loss: 2.1244460728860672

Epoch: 5| Step: 1
Training loss: 2.4883322715759277
Validation loss: 2.134127821973575

Epoch: 5| Step: 2
Training loss: 2.691253900527954
Validation loss: 2.135277525071175

Epoch: 5| Step: 3
Training loss: 3.0361335277557373
Validation loss: 2.155121539228706

Epoch: 5| Step: 4
Training loss: 1.929703950881958
Validation loss: 2.154260294411772

Epoch: 5| Step: 5
Training loss: 2.3908426761627197
Validation loss: 2.129219703776862

Epoch: 5| Step: 6
Training loss: 2.8558666706085205
Validation loss: 2.149966885966639

Epoch: 5| Step: 7
Training loss: 2.3820292949676514
Validation loss: 2.141865876413161

Epoch: 5| Step: 8
Training loss: 1.7822595834732056
Validation loss: 2.147594569831766

Epoch: 5| Step: 9
Training loss: 1.9656956195831299
Validation loss: 2.1257346548059934

Epoch: 5| Step: 10
Training loss: 2.5805797576904297
Validation loss: 2.1448331084302676

Epoch: 48| Step: 0
Training loss: 1.9138530492782593
Validation loss: 2.137708644713125

Epoch: 5| Step: 1
Training loss: 2.688727378845215
Validation loss: 2.1444336752737723

Epoch: 5| Step: 2
Training loss: 1.8269354104995728
Validation loss: 2.1351181460965063

Epoch: 5| Step: 3
Training loss: 2.1991019248962402
Validation loss: 2.1597189775077243

Epoch: 5| Step: 4
Training loss: 2.3636488914489746
Validation loss: 2.1474577598674323

Epoch: 5| Step: 5
Training loss: 2.5558838844299316
Validation loss: 2.135073684876965

Epoch: 5| Step: 6
Training loss: 2.3120551109313965
Validation loss: 2.135326564952891

Epoch: 5| Step: 7
Training loss: 2.6595592498779297
Validation loss: 2.1330194319448164

Epoch: 5| Step: 8
Training loss: 3.077208995819092
Validation loss: 2.1507404722193235

Epoch: 5| Step: 9
Training loss: 2.2380833625793457
Validation loss: 2.13456307559885

Epoch: 5| Step: 10
Training loss: 2.4443607330322266
Validation loss: 2.1335140723054127

Epoch: 49| Step: 0
Training loss: 2.771527051925659
Validation loss: 2.1459319540249404

Epoch: 5| Step: 1
Training loss: 2.504856824874878
Validation loss: 2.156390807961905

Epoch: 5| Step: 2
Training loss: 1.8177425861358643
Validation loss: 2.1509461146529003

Epoch: 5| Step: 3
Training loss: 2.825014114379883
Validation loss: 2.1398234367370605

Epoch: 5| Step: 4
Training loss: 2.207542896270752
Validation loss: 2.136330566098613

Epoch: 5| Step: 5
Training loss: 2.071013927459717
Validation loss: 2.1386156864063715

Epoch: 5| Step: 6
Training loss: 2.580054759979248
Validation loss: 2.120334374007358

Epoch: 5| Step: 7
Training loss: 2.1953299045562744
Validation loss: 2.1117151373176166

Epoch: 5| Step: 8
Training loss: 2.466264486312866
Validation loss: 2.1266329057755007

Epoch: 5| Step: 9
Training loss: 2.2642033100128174
Validation loss: 2.118473770797894

Epoch: 5| Step: 10
Training loss: 2.444171667098999
Validation loss: 2.1345796123627694

Epoch: 50| Step: 0
Training loss: 2.796180009841919
Validation loss: 2.143622722677005

Epoch: 5| Step: 1
Training loss: 2.4585678577423096
Validation loss: 2.1269422026090723

Epoch: 5| Step: 2
Training loss: 1.8401858806610107
Validation loss: 2.1364442712517193

Epoch: 5| Step: 3
Training loss: 2.27382755279541
Validation loss: 2.1326243710774246

Epoch: 5| Step: 4
Training loss: 2.6410913467407227
Validation loss: 2.1302279721024218

Epoch: 5| Step: 5
Training loss: 2.5139026641845703
Validation loss: 2.1319816291973157

Epoch: 5| Step: 6
Training loss: 2.495906114578247
Validation loss: 2.1388306771555254

Epoch: 5| Step: 7
Training loss: 2.1724700927734375
Validation loss: 2.126711740288683

Epoch: 5| Step: 8
Training loss: 2.3425745964050293
Validation loss: 2.141089541937715

Epoch: 5| Step: 9
Training loss: 2.4575045108795166
Validation loss: 2.1186299157399002

Epoch: 5| Step: 10
Training loss: 2.0639517307281494
Validation loss: 2.142345472048688

Epoch: 51| Step: 0
Training loss: 2.947925090789795
Validation loss: 2.129972373285601

Epoch: 5| Step: 1
Training loss: 2.334019184112549
Validation loss: 2.122038751520136

Epoch: 5| Step: 2
Training loss: 2.46132230758667
Validation loss: 2.110152979050913

Epoch: 5| Step: 3
Training loss: 2.94858455657959
Validation loss: 2.128676296562277

Epoch: 5| Step: 4
Training loss: 2.1942496299743652
Validation loss: 2.118438334875209

Epoch: 5| Step: 5
Training loss: 1.8475341796875
Validation loss: 2.1090006033579507

Epoch: 5| Step: 6
Training loss: 1.9862060546875
Validation loss: 2.109962022432717

Epoch: 5| Step: 7
Training loss: 2.39166259765625
Validation loss: 2.1260191291891117

Epoch: 5| Step: 8
Training loss: 2.8576385974884033
Validation loss: 2.142827336506177

Epoch: 5| Step: 9
Training loss: 1.849104881286621
Validation loss: 2.1379659868055776

Epoch: 5| Step: 10
Training loss: 2.2744784355163574
Validation loss: 2.12520952891278

Epoch: 52| Step: 0
Training loss: 2.3219192028045654
Validation loss: 2.130386637103173

Epoch: 5| Step: 1
Training loss: 2.2315471172332764
Validation loss: 2.1212330684866956

Epoch: 5| Step: 2
Training loss: 2.663370132446289
Validation loss: 2.1267244136461647

Epoch: 5| Step: 3
Training loss: 2.5365967750549316
Validation loss: 2.131755905766641

Epoch: 5| Step: 4
Training loss: 2.142305374145508
Validation loss: 2.1430793962171

Epoch: 5| Step: 5
Training loss: 2.4817302227020264
Validation loss: 2.1211074834228842

Epoch: 5| Step: 6
Training loss: 1.123152494430542
Validation loss: 2.1151225297681746

Epoch: 5| Step: 7
Training loss: 2.4351494312286377
Validation loss: 2.120825590625886

Epoch: 5| Step: 8
Training loss: 2.664733409881592
Validation loss: 2.118223051871023

Epoch: 5| Step: 9
Training loss: 2.755152940750122
Validation loss: 2.101242243602712

Epoch: 5| Step: 10
Training loss: 2.7274348735809326
Validation loss: 2.1228817457793863

Epoch: 53| Step: 0
Training loss: 3.256822109222412
Validation loss: 2.1088069587625484

Epoch: 5| Step: 1
Training loss: 2.3564107418060303
Validation loss: 2.1088019647905902

Epoch: 5| Step: 2
Training loss: 2.170649290084839
Validation loss: 2.1035569765234507

Epoch: 5| Step: 3
Training loss: 2.563408613204956
Validation loss: 2.108967945139895

Epoch: 5| Step: 4
Training loss: 2.1936233043670654
Validation loss: 2.1445790439523678

Epoch: 5| Step: 5
Training loss: 2.2900776863098145
Validation loss: 2.111128777586004

Epoch: 5| Step: 6
Training loss: 2.4530365467071533
Validation loss: 2.128130525671026

Epoch: 5| Step: 7
Training loss: 2.944607973098755
Validation loss: 2.1306088047642864

Epoch: 5| Step: 8
Training loss: 2.1146607398986816
Validation loss: 2.116163161493117

Epoch: 5| Step: 9
Training loss: 1.5875355005264282
Validation loss: 2.1171337404558734

Epoch: 5| Step: 10
Training loss: 2.0093257427215576
Validation loss: 2.1089074739845852

Epoch: 54| Step: 0
Training loss: 1.5107061862945557
Validation loss: 2.124988204689436

Epoch: 5| Step: 1
Training loss: 1.7960360050201416
Validation loss: 2.127556067641063

Epoch: 5| Step: 2
Training loss: 2.2881722450256348
Validation loss: 2.104162544332525

Epoch: 5| Step: 3
Training loss: 3.385540008544922
Validation loss: 2.1220900397146902

Epoch: 5| Step: 4
Training loss: 2.5904200077056885
Validation loss: 2.1175390033311743

Epoch: 5| Step: 5
Training loss: 2.163264751434326
Validation loss: 2.1303690582193355

Epoch: 5| Step: 6
Training loss: 2.8803181648254395
Validation loss: 2.1226078105229202

Epoch: 5| Step: 7
Training loss: 2.8057968616485596
Validation loss: 2.1303417157101374

Epoch: 5| Step: 8
Training loss: 2.1447770595550537
Validation loss: 2.113988353360084

Epoch: 5| Step: 9
Training loss: 2.519179582595825
Validation loss: 2.1305033776067916

Epoch: 5| Step: 10
Training loss: 1.6739187240600586
Validation loss: 2.109790048291606

Epoch: 55| Step: 0
Training loss: 2.6411406993865967
Validation loss: 2.089270335371776

Epoch: 5| Step: 1
Training loss: 2.13201904296875
Validation loss: 2.121008725576503

Epoch: 5| Step: 2
Training loss: 1.8155262470245361
Validation loss: 2.127294881369478

Epoch: 5| Step: 3
Training loss: 2.2296204566955566
Validation loss: 2.1284567720146588

Epoch: 5| Step: 4
Training loss: 2.7205402851104736
Validation loss: 2.095388607312274

Epoch: 5| Step: 5
Training loss: 2.748192071914673
Validation loss: 2.1270633769291702

Epoch: 5| Step: 6
Training loss: 2.002350330352783
Validation loss: 2.103002066253334

Epoch: 5| Step: 7
Training loss: 2.5513839721679688
Validation loss: 2.1203776572340276

Epoch: 5| Step: 8
Training loss: 2.667248487472534
Validation loss: 2.112440316907821

Epoch: 5| Step: 9
Training loss: 2.32245135307312
Validation loss: 2.116207416339587

Epoch: 5| Step: 10
Training loss: 2.0181350708007812
Validation loss: 2.1411197621335267

Epoch: 56| Step: 0
Training loss: 2.9542059898376465
Validation loss: 2.1241901792505735

Epoch: 5| Step: 1
Training loss: 2.697511911392212
Validation loss: 2.090952157974243

Epoch: 5| Step: 2
Training loss: 1.9398422241210938
Validation loss: 2.1234403835829867

Epoch: 5| Step: 3
Training loss: 2.2076401710510254
Validation loss: 2.12178805053875

Epoch: 5| Step: 4
Training loss: 2.156785249710083
Validation loss: 2.1113060135995187

Epoch: 5| Step: 5
Training loss: 2.2946643829345703
Validation loss: 2.1249525982846498

Epoch: 5| Step: 6
Training loss: 2.8449995517730713
Validation loss: 2.1107490319077686

Epoch: 5| Step: 7
Training loss: 1.7537472248077393
Validation loss: 2.098069331979239

Epoch: 5| Step: 8
Training loss: 2.5531604290008545
Validation loss: 2.097602541728686

Epoch: 5| Step: 9
Training loss: 2.376823902130127
Validation loss: 2.0975137731080413

Epoch: 5| Step: 10
Training loss: 1.9970512390136719
Validation loss: 2.1121980913223757

Epoch: 57| Step: 0
Training loss: 2.6252334117889404
Validation loss: 2.10667069496647

Epoch: 5| Step: 1
Training loss: 2.129335641860962
Validation loss: 2.106415443522956

Epoch: 5| Step: 2
Training loss: 2.7946557998657227
Validation loss: 2.1016883824461248

Epoch: 5| Step: 3
Training loss: 2.2259628772735596
Validation loss: 2.110958117310719

Epoch: 5| Step: 4
Training loss: 2.963460922241211
Validation loss: 2.105090110532699

Epoch: 5| Step: 5
Training loss: 2.532310962677002
Validation loss: 2.1157712167309177

Epoch: 5| Step: 6
Training loss: 1.8941634893417358
Validation loss: 2.1264209978042112

Epoch: 5| Step: 7
Training loss: 1.769095778465271
Validation loss: 2.1026128351047473

Epoch: 5| Step: 8
Training loss: 1.7549670934677124
Validation loss: 2.101432365755881

Epoch: 5| Step: 9
Training loss: 2.453037738800049
Validation loss: 2.1324599942853375

Epoch: 5| Step: 10
Training loss: 2.6334283351898193
Validation loss: 2.090019804175182

Epoch: 58| Step: 0
Training loss: 2.3463892936706543
Validation loss: 2.1157193209535334

Epoch: 5| Step: 1
Training loss: 2.0782148838043213
Validation loss: 2.0962040911438646

Epoch: 5| Step: 2
Training loss: 2.5287671089172363
Validation loss: 2.0869390528689147

Epoch: 5| Step: 3
Training loss: 2.4568190574645996
Validation loss: 2.1079523383930163

Epoch: 5| Step: 4
Training loss: 2.356767416000366
Validation loss: 2.111241368837254

Epoch: 5| Step: 5
Training loss: 3.0098791122436523
Validation loss: 2.1105201116172214

Epoch: 5| Step: 6
Training loss: 2.1198649406433105
Validation loss: 2.087916176806214

Epoch: 5| Step: 7
Training loss: 2.7205147743225098
Validation loss: 2.090971485260994

Epoch: 5| Step: 8
Training loss: 2.5062649250030518
Validation loss: 2.088976401154713

Epoch: 5| Step: 9
Training loss: 1.7186781167984009
Validation loss: 2.0910429198254823

Epoch: 5| Step: 10
Training loss: 1.827410101890564
Validation loss: 2.102524406166487

Epoch: 59| Step: 0
Training loss: 2.318955898284912
Validation loss: 2.0985664834258375

Epoch: 5| Step: 1
Training loss: 2.908390522003174
Validation loss: 2.1084419950362174

Epoch: 5| Step: 2
Training loss: 2.540748119354248
Validation loss: 2.0926091568444365

Epoch: 5| Step: 3
Training loss: 2.8764805793762207
Validation loss: 2.103946142299201

Epoch: 5| Step: 4
Training loss: 2.7400028705596924
Validation loss: 2.1074596502447642

Epoch: 5| Step: 5
Training loss: 1.9123985767364502
Validation loss: 2.116869870052543

Epoch: 5| Step: 6
Training loss: 1.741766333580017
Validation loss: 2.0968327624823457

Epoch: 5| Step: 7
Training loss: 1.7796533107757568
Validation loss: 2.1039252358098186

Epoch: 5| Step: 8
Training loss: 2.214743137359619
Validation loss: 2.090824701452768

Epoch: 5| Step: 9
Training loss: 2.643321990966797
Validation loss: 2.103487753099011

Epoch: 5| Step: 10
Training loss: 1.924986720085144
Validation loss: 2.0962128370038924

Epoch: 60| Step: 0
Training loss: 2.0586233139038086
Validation loss: 2.092081969784152

Epoch: 5| Step: 1
Training loss: 2.968139171600342
Validation loss: 2.109364217327487

Epoch: 5| Step: 2
Training loss: 1.9756253957748413
Validation loss: 2.088847214175809

Epoch: 5| Step: 3
Training loss: 2.17093563079834
Validation loss: 2.114604598732405

Epoch: 5| Step: 4
Training loss: 2.081965684890747
Validation loss: 2.1080443987282376

Epoch: 5| Step: 5
Training loss: 2.09354567527771
Validation loss: 2.115996140305714

Epoch: 5| Step: 6
Training loss: 2.160029411315918
Validation loss: 2.1258614447809037

Epoch: 5| Step: 7
Training loss: 2.748065948486328
Validation loss: 2.094641900831653

Epoch: 5| Step: 8
Training loss: 2.0278165340423584
Validation loss: 2.1176330145969184

Epoch: 5| Step: 9
Training loss: 2.5697429180145264
Validation loss: 2.1034288573008713

Epoch: 5| Step: 10
Training loss: 2.653224229812622
Validation loss: 2.105492394457581

Epoch: 61| Step: 0
Training loss: 2.297023296356201
Validation loss: 2.1149681793746127

Epoch: 5| Step: 1
Training loss: 2.0574231147766113
Validation loss: 2.0880183327582573

Epoch: 5| Step: 2
Training loss: 2.484835386276245
Validation loss: 2.0895378256356842

Epoch: 5| Step: 3
Training loss: 2.078240156173706
Validation loss: 2.104922394598684

Epoch: 5| Step: 4
Training loss: 2.3116791248321533
Validation loss: 2.109674633190196

Epoch: 5| Step: 5
Training loss: 2.932460308074951
Validation loss: 2.1064867845145603

Epoch: 5| Step: 6
Training loss: 1.7288687229156494
Validation loss: 2.121795964497392

Epoch: 5| Step: 7
Training loss: 1.9078038930892944
Validation loss: 2.1142743659275833

Epoch: 5| Step: 8
Training loss: 2.395700454711914
Validation loss: 2.107347952422275

Epoch: 5| Step: 9
Training loss: 2.2972419261932373
Validation loss: 2.1226385306286555

Epoch: 5| Step: 10
Training loss: 3.165571928024292
Validation loss: 2.109378171223466

Epoch: 62| Step: 0
Training loss: 2.0425026416778564
Validation loss: 2.092575539824783

Epoch: 5| Step: 1
Training loss: 2.3044967651367188
Validation loss: 2.1085488437324442

Epoch: 5| Step: 2
Training loss: 2.5759849548339844
Validation loss: 2.09474447209348

Epoch: 5| Step: 3
Training loss: 2.975182294845581
Validation loss: 2.0892085106142106

Epoch: 5| Step: 4
Training loss: 2.4711458683013916
Validation loss: 2.099764580367714

Epoch: 5| Step: 5
Training loss: 2.8592891693115234
Validation loss: 2.0778760403715153

Epoch: 5| Step: 6
Training loss: 2.1115658283233643
Validation loss: 2.0892300400682675

Epoch: 5| Step: 7
Training loss: 2.1774399280548096
Validation loss: 2.114252951837355

Epoch: 5| Step: 8
Training loss: 2.098482608795166
Validation loss: 2.082403962330152

Epoch: 5| Step: 9
Training loss: 2.1189770698547363
Validation loss: 2.088508170138123

Epoch: 5| Step: 10
Training loss: 1.758151650428772
Validation loss: 2.1048092694692713

Epoch: 63| Step: 0
Training loss: 2.100989580154419
Validation loss: 2.106046793281391

Epoch: 5| Step: 1
Training loss: 2.174870729446411
Validation loss: 2.0768631504428003

Epoch: 5| Step: 2
Training loss: 1.9897925853729248
Validation loss: 2.0887615014148015

Epoch: 5| Step: 3
Training loss: 2.0973942279815674
Validation loss: 2.0862223384200886

Epoch: 5| Step: 4
Training loss: 2.004176378250122
Validation loss: 2.0862731792593516

Epoch: 5| Step: 5
Training loss: 2.4248507022857666
Validation loss: 2.097889397733955

Epoch: 5| Step: 6
Training loss: 2.9267475605010986
Validation loss: 2.088187268985215

Epoch: 5| Step: 7
Training loss: 2.8240201473236084
Validation loss: 2.0879522241571897

Epoch: 5| Step: 8
Training loss: 2.5029773712158203
Validation loss: 2.084354567271407

Epoch: 5| Step: 9
Training loss: 2.1200129985809326
Validation loss: 2.108085282387272

Epoch: 5| Step: 10
Training loss: 2.1119792461395264
Validation loss: 2.0931989839000087

Epoch: 64| Step: 0
Training loss: 2.08296537399292
Validation loss: 2.1058446079172115

Epoch: 5| Step: 1
Training loss: 2.874484062194824
Validation loss: 2.090914807012004

Epoch: 5| Step: 2
Training loss: 2.1723265647888184
Validation loss: 2.108629318975633

Epoch: 5| Step: 3
Training loss: 2.2333297729492188
Validation loss: 2.08749359397478

Epoch: 5| Step: 4
Training loss: 1.9242961406707764
Validation loss: 2.0883700398988623

Epoch: 5| Step: 5
Training loss: 2.5782053470611572
Validation loss: 2.0966366285918863

Epoch: 5| Step: 6
Training loss: 2.7463278770446777
Validation loss: 2.0931504952010287

Epoch: 5| Step: 7
Training loss: 2.2488632202148438
Validation loss: 2.1094836111991637

Epoch: 5| Step: 8
Training loss: 2.516026735305786
Validation loss: 2.1103929294052945

Epoch: 5| Step: 9
Training loss: 2.329507350921631
Validation loss: 2.0812522249837078

Epoch: 5| Step: 10
Training loss: 1.816078782081604
Validation loss: 2.108084076194353

Epoch: 65| Step: 0
Training loss: 2.0496888160705566
Validation loss: 2.1226933489563646

Epoch: 5| Step: 1
Training loss: 2.1065125465393066
Validation loss: 2.1144200524976178

Epoch: 5| Step: 2
Training loss: 2.2794740200042725
Validation loss: 2.1199225661575154

Epoch: 5| Step: 3
Training loss: 2.6750919818878174
Validation loss: 2.089723607545258

Epoch: 5| Step: 4
Training loss: 2.271697759628296
Validation loss: 2.0833611513978694

Epoch: 5| Step: 5
Training loss: 2.0723626613616943
Validation loss: 2.086399045041812

Epoch: 5| Step: 6
Training loss: 1.9526722431182861
Validation loss: 2.110418813202971

Epoch: 5| Step: 7
Training loss: 2.615129232406616
Validation loss: 2.12324288839935

Epoch: 5| Step: 8
Training loss: 2.074368953704834
Validation loss: 2.098109463209747

Epoch: 5| Step: 9
Training loss: 2.5026814937591553
Validation loss: 2.099355484849663

Epoch: 5| Step: 10
Training loss: 2.8099074363708496
Validation loss: 2.081048200207372

Epoch: 66| Step: 0
Training loss: 2.7648701667785645
Validation loss: 2.103704785787931

Epoch: 5| Step: 1
Training loss: 2.5369462966918945
Validation loss: 2.082217175473449

Epoch: 5| Step: 2
Training loss: 2.014646530151367
Validation loss: 2.1179672876993814

Epoch: 5| Step: 3
Training loss: 1.641862154006958
Validation loss: 2.060272534688314

Epoch: 5| Step: 4
Training loss: 1.968140959739685
Validation loss: 2.0981531322643323

Epoch: 5| Step: 5
Training loss: 2.251875400543213
Validation loss: 2.083442944352345

Epoch: 5| Step: 6
Training loss: 2.5419766902923584
Validation loss: 2.1198283754369265

Epoch: 5| Step: 7
Training loss: 2.4375
Validation loss: 2.0861433757248746

Epoch: 5| Step: 8
Training loss: 2.5573315620422363
Validation loss: 2.1000466462104552

Epoch: 5| Step: 9
Training loss: 2.4615509510040283
Validation loss: 2.097283458196989

Epoch: 5| Step: 10
Training loss: 1.9647109508514404
Validation loss: 2.0950321612819547

Epoch: 67| Step: 0
Training loss: 2.552103042602539
Validation loss: 2.098073802968507

Epoch: 5| Step: 1
Training loss: 2.0979695320129395
Validation loss: 2.0799669578511226

Epoch: 5| Step: 2
Training loss: 2.1178691387176514
Validation loss: 2.0929675896962485

Epoch: 5| Step: 3
Training loss: 2.2414276599884033
Validation loss: 2.091173441179337

Epoch: 5| Step: 4
Training loss: 2.096426486968994
Validation loss: 2.0877994388662358

Epoch: 5| Step: 5
Training loss: 2.818878173828125
Validation loss: 2.099994833751391

Epoch: 5| Step: 6
Training loss: 2.346395254135132
Validation loss: 2.0819070826294603

Epoch: 5| Step: 7
Training loss: 2.600559711456299
Validation loss: 2.091189617751747

Epoch: 5| Step: 8
Training loss: 1.9253641366958618
Validation loss: 2.1006970418396818

Epoch: 5| Step: 9
Training loss: 2.2878406047821045
Validation loss: 2.1165208073072534

Epoch: 5| Step: 10
Training loss: 2.286653757095337
Validation loss: 2.1075794184079735

Epoch: 68| Step: 0
Training loss: 2.505725383758545
Validation loss: 2.087603756176528

Epoch: 5| Step: 1
Training loss: 2.1553664207458496
Validation loss: 2.0921516290274997

Epoch: 5| Step: 2
Training loss: 2.71018123626709
Validation loss: 2.0935044019452986

Epoch: 5| Step: 3
Training loss: 1.8220784664154053
Validation loss: 2.080714528278638

Epoch: 5| Step: 4
Training loss: 1.683214545249939
Validation loss: 2.116746708910952

Epoch: 5| Step: 5
Training loss: 3.1072700023651123
Validation loss: 2.1136257033194266

Epoch: 5| Step: 6
Training loss: 2.4593584537506104
Validation loss: 2.106437301123014

Epoch: 5| Step: 7
Training loss: 2.8563694953918457
Validation loss: 2.0693408161081295

Epoch: 5| Step: 8
Training loss: 2.1891188621520996
Validation loss: 2.0889202933157645

Epoch: 5| Step: 9
Training loss: 2.3287415504455566
Validation loss: 2.0980269370540494

Epoch: 5| Step: 10
Training loss: 1.2682253122329712
Validation loss: 2.100132970399754

Epoch: 69| Step: 0
Training loss: 2.3792991638183594
Validation loss: 2.1136103778757076

Epoch: 5| Step: 1
Training loss: 2.025423049926758
Validation loss: 2.074201471062117

Epoch: 5| Step: 2
Training loss: 2.5520176887512207
Validation loss: 2.0768040405806674

Epoch: 5| Step: 3
Training loss: 1.7690622806549072
Validation loss: 2.0733465507466304

Epoch: 5| Step: 4
Training loss: 2.2499613761901855
Validation loss: 2.0774308840433755

Epoch: 5| Step: 5
Training loss: 2.801485538482666
Validation loss: 2.0842277926783406

Epoch: 5| Step: 6
Training loss: 2.717830181121826
Validation loss: 2.099799809917327

Epoch: 5| Step: 7
Training loss: 2.0263516902923584
Validation loss: 2.097365661333966

Epoch: 5| Step: 8
Training loss: 2.1813032627105713
Validation loss: 2.099504922025947

Epoch: 5| Step: 9
Training loss: 1.8736969232559204
Validation loss: 2.087138250309934

Epoch: 5| Step: 10
Training loss: 2.7536489963531494
Validation loss: 2.0972443601136566

Epoch: 70| Step: 0
Training loss: 2.6451427936553955
Validation loss: 2.089616778076336

Epoch: 5| Step: 1
Training loss: 2.4333155155181885
Validation loss: 2.1029076191686813

Epoch: 5| Step: 2
Training loss: 2.13030743598938
Validation loss: 2.088308342041508

Epoch: 5| Step: 3
Training loss: 1.6882336139678955
Validation loss: 2.0813681835769327

Epoch: 5| Step: 4
Training loss: 2.1383399963378906
Validation loss: 2.0715381855605752

Epoch: 5| Step: 5
Training loss: 2.276176929473877
Validation loss: 2.099195379082875

Epoch: 5| Step: 6
Training loss: 2.45115327835083
Validation loss: 2.081925333187144

Epoch: 5| Step: 7
Training loss: 2.3933231830596924
Validation loss: 2.101271862624794

Epoch: 5| Step: 8
Training loss: 2.944059133529663
Validation loss: 2.114269851356424

Epoch: 5| Step: 9
Training loss: 2.086251735687256
Validation loss: 2.0778950850168862

Epoch: 5| Step: 10
Training loss: 1.8285986185073853
Validation loss: 2.0917187711243987

Epoch: 71| Step: 0
Training loss: 2.1243093013763428
Validation loss: 2.107098476861113

Epoch: 5| Step: 1
Training loss: 2.307433605194092
Validation loss: 2.1074960154871785

Epoch: 5| Step: 2
Training loss: 2.080322742462158
Validation loss: 2.0792118554474204

Epoch: 5| Step: 3
Training loss: 2.384333848953247
Validation loss: 2.101347590005526

Epoch: 5| Step: 4
Training loss: 2.178999423980713
Validation loss: 2.1029799317800872

Epoch: 5| Step: 5
Training loss: 2.103870153427124
Validation loss: 2.0913515167851604

Epoch: 5| Step: 6
Training loss: 2.2158520221710205
Validation loss: 2.083842590291013

Epoch: 5| Step: 7
Training loss: 2.4919159412384033
Validation loss: 2.096079795591293

Epoch: 5| Step: 8
Training loss: 2.6382815837860107
Validation loss: 2.1042569452716458

Epoch: 5| Step: 9
Training loss: 2.099067211151123
Validation loss: 2.0668837793411745

Epoch: 5| Step: 10
Training loss: 2.649564743041992
Validation loss: 2.1165347201849825

Epoch: 72| Step: 0
Training loss: 2.1261017322540283
Validation loss: 2.118554703650936

Epoch: 5| Step: 1
Training loss: 1.8599315881729126
Validation loss: 2.079711575661936

Epoch: 5| Step: 2
Training loss: 2.305635452270508
Validation loss: 2.0957992179419405

Epoch: 5| Step: 3
Training loss: 2.0159947872161865
Validation loss: 2.094256013952276

Epoch: 5| Step: 4
Training loss: 2.0417768955230713
Validation loss: 2.0757505662979616

Epoch: 5| Step: 5
Training loss: 1.732499122619629
Validation loss: 2.1192851784408733

Epoch: 5| Step: 6
Training loss: 2.699530839920044
Validation loss: 2.094262615326912

Epoch: 5| Step: 7
Training loss: 2.5715270042419434
Validation loss: 2.0993980015477827

Epoch: 5| Step: 8
Training loss: 2.965561866760254
Validation loss: 2.087672128472277

Epoch: 5| Step: 9
Training loss: 2.2301220893859863
Validation loss: 2.0920056963479645

Epoch: 5| Step: 10
Training loss: 2.5447440147399902
Validation loss: 2.0947302746516403

Epoch: 73| Step: 0
Training loss: 2.0476646423339844
Validation loss: 2.088091408052752

Epoch: 5| Step: 1
Training loss: 2.704749345779419
Validation loss: 2.065579572031575

Epoch: 5| Step: 2
Training loss: 1.6124131679534912
Validation loss: 2.0669836305802867

Epoch: 5| Step: 3
Training loss: 2.233072280883789
Validation loss: 2.092687499138617

Epoch: 5| Step: 4
Training loss: 1.9663864374160767
Validation loss: 2.0885851921573764

Epoch: 5| Step: 5
Training loss: 2.178283929824829
Validation loss: 2.0767586692687003

Epoch: 5| Step: 6
Training loss: 2.345421314239502
Validation loss: 2.1039600936315392

Epoch: 5| Step: 7
Training loss: 1.9944614171981812
Validation loss: 2.062853688834816

Epoch: 5| Step: 8
Training loss: 2.8009536266326904
Validation loss: 2.074605275225896

Epoch: 5| Step: 9
Training loss: 2.333845853805542
Validation loss: 2.0827216973868747

Epoch: 5| Step: 10
Training loss: 3.0249276161193848
Validation loss: 2.1099388804487003

Epoch: 74| Step: 0
Training loss: 1.8539860248565674
Validation loss: 2.1039973817845827

Epoch: 5| Step: 1
Training loss: 2.090942144393921
Validation loss: 2.089437093786014

Epoch: 5| Step: 2
Training loss: 2.5835795402526855
Validation loss: 2.063245136250732

Epoch: 5| Step: 3
Training loss: 2.7382826805114746
Validation loss: 2.106117048571187

Epoch: 5| Step: 4
Training loss: 2.0856075286865234
Validation loss: 2.088306712847884

Epoch: 5| Step: 5
Training loss: 2.5937001705169678
Validation loss: 2.101275190230339

Epoch: 5| Step: 6
Training loss: 1.6823536157608032
Validation loss: 2.1150256023612073

Epoch: 5| Step: 7
Training loss: 2.690904140472412
Validation loss: 2.075868591185539

Epoch: 5| Step: 8
Training loss: 2.366079807281494
Validation loss: 2.092480069847517

Epoch: 5| Step: 9
Training loss: 2.2687010765075684
Validation loss: 2.1065581870335404

Epoch: 5| Step: 10
Training loss: 2.083876609802246
Validation loss: 2.090040906783073

Epoch: 75| Step: 0
Training loss: 1.8354676961898804
Validation loss: 2.090423155856389

Epoch: 5| Step: 1
Training loss: 2.411513566970825
Validation loss: 2.09218696753184

Epoch: 5| Step: 2
Training loss: 1.9914672374725342
Validation loss: 2.110249282211386

Epoch: 5| Step: 3
Training loss: 2.4602229595184326
Validation loss: 2.089367630661175

Epoch: 5| Step: 4
Training loss: 2.275996208190918
Validation loss: 2.0997184015089467

Epoch: 5| Step: 5
Training loss: 2.8966546058654785
Validation loss: 2.1063311997280327

Epoch: 5| Step: 6
Training loss: 2.59224534034729
Validation loss: 2.0796329795673327

Epoch: 5| Step: 7
Training loss: 2.204378128051758
Validation loss: 2.093800442193144

Epoch: 5| Step: 8
Training loss: 2.0701260566711426
Validation loss: 2.10003464452682

Epoch: 5| Step: 9
Training loss: 2.1056020259857178
Validation loss: 2.0893611497776483

Epoch: 5| Step: 10
Training loss: 2.0146732330322266
Validation loss: 2.064764758592011

Epoch: 76| Step: 0
Training loss: 1.9957504272460938
Validation loss: 2.0845986822600007

Epoch: 5| Step: 1
Training loss: 2.34921932220459
Validation loss: 2.072896208814395

Epoch: 5| Step: 2
Training loss: 2.078192949295044
Validation loss: 2.123903541154759

Epoch: 5| Step: 3
Training loss: 1.6320476531982422
Validation loss: 2.0884526480910597

Epoch: 5| Step: 4
Training loss: 2.898710012435913
Validation loss: 2.0969870757031184

Epoch: 5| Step: 5
Training loss: 2.040409564971924
Validation loss: 2.118214429065745

Epoch: 5| Step: 6
Training loss: 2.7084643840789795
Validation loss: 2.085068743716004

Epoch: 5| Step: 7
Training loss: 2.27423095703125
Validation loss: 2.1041805500625284

Epoch: 5| Step: 8
Training loss: 2.304311752319336
Validation loss: 2.0925712739267657

Epoch: 5| Step: 9
Training loss: 1.991922378540039
Validation loss: 2.0772366164832987

Epoch: 5| Step: 10
Training loss: 2.619457244873047
Validation loss: 2.091925051904494

Epoch: 77| Step: 0
Training loss: 2.498445987701416
Validation loss: 2.089488988281578

Epoch: 5| Step: 1
Training loss: 2.1979453563690186
Validation loss: 2.087831522828789

Epoch: 5| Step: 2
Training loss: 2.5398502349853516
Validation loss: 2.087881768903425

Epoch: 5| Step: 3
Training loss: 2.155102014541626
Validation loss: 2.08192926965734

Epoch: 5| Step: 4
Training loss: 1.8923003673553467
Validation loss: 2.0919461763033302

Epoch: 5| Step: 5
Training loss: 1.6648533344268799
Validation loss: 2.1015324579772128

Epoch: 5| Step: 6
Training loss: 2.1924004554748535
Validation loss: 2.110025187974335

Epoch: 5| Step: 7
Training loss: 2.5219309329986572
Validation loss: 2.0969053058214087

Epoch: 5| Step: 8
Training loss: 3.462468385696411
Validation loss: 2.099487107287171

Epoch: 5| Step: 9
Training loss: 2.0370430946350098
Validation loss: 2.0634867145169165

Epoch: 5| Step: 10
Training loss: 1.6200863122940063
Validation loss: 2.093904032502123

Epoch: 78| Step: 0
Training loss: 1.9370033740997314
Validation loss: 2.1151165423854703

Epoch: 5| Step: 1
Training loss: 2.328022003173828
Validation loss: 2.0787063157686623

Epoch: 5| Step: 2
Training loss: 2.3293228149414062
Validation loss: 2.1063971929652716

Epoch: 5| Step: 3
Training loss: 2.9034667015075684
Validation loss: 2.0893267149566324

Epoch: 5| Step: 4
Training loss: 2.5790963172912598
Validation loss: 2.0861397276642504

Epoch: 5| Step: 5
Training loss: 2.10349702835083
Validation loss: 2.0843663959092993

Epoch: 5| Step: 6
Training loss: 2.0891165733337402
Validation loss: 2.0710240076946955

Epoch: 5| Step: 7
Training loss: 2.1521835327148438
Validation loss: 2.0904517186585294

Epoch: 5| Step: 8
Training loss: 2.480191469192505
Validation loss: 2.097720133360996

Epoch: 5| Step: 9
Training loss: 2.264425754547119
Validation loss: 2.077126979827881

Epoch: 5| Step: 10
Training loss: 1.5000379085540771
Validation loss: 2.0995033094959874

Epoch: 79| Step: 0
Training loss: 2.518115758895874
Validation loss: 2.105605204900106

Epoch: 5| Step: 1
Training loss: 2.289386510848999
Validation loss: 2.075613501251385

Epoch: 5| Step: 2
Training loss: 1.9906203746795654
Validation loss: 2.091232620259767

Epoch: 5| Step: 3
Training loss: 2.7372238636016846
Validation loss: 2.094596652574437

Epoch: 5| Step: 4
Training loss: 2.800079822540283
Validation loss: 2.0761259255870694

Epoch: 5| Step: 5
Training loss: 1.9508081674575806
Validation loss: 2.096354562749145

Epoch: 5| Step: 6
Training loss: 2.4538841247558594
Validation loss: 2.0885435381243305

Epoch: 5| Step: 7
Training loss: 2.1615097522735596
Validation loss: 2.0915204504484772

Epoch: 5| Step: 8
Training loss: 2.111445903778076
Validation loss: 2.0769514409444665

Epoch: 5| Step: 9
Training loss: 1.9972797632217407
Validation loss: 2.091408778262395

Epoch: 5| Step: 10
Training loss: 2.072946071624756
Validation loss: 2.079948486820344

Epoch: 80| Step: 0
Training loss: 2.0164542198181152
Validation loss: 2.0827168495424333

Epoch: 5| Step: 1
Training loss: 2.1672263145446777
Validation loss: 2.118228507298295

Epoch: 5| Step: 2
Training loss: 2.070338487625122
Validation loss: 2.090900175033077

Epoch: 5| Step: 3
Training loss: 2.2980048656463623
Validation loss: 2.0942368750931113

Epoch: 5| Step: 4
Training loss: 1.9313418865203857
Validation loss: 2.085999351675792

Epoch: 5| Step: 5
Training loss: 2.1473090648651123
Validation loss: 2.0815981562419603

Epoch: 5| Step: 6
Training loss: 2.6995694637298584
Validation loss: 2.108892410032211

Epoch: 5| Step: 7
Training loss: 2.338656187057495
Validation loss: 2.0941551116205033

Epoch: 5| Step: 8
Training loss: 1.8830363750457764
Validation loss: 2.0760844151178994

Epoch: 5| Step: 9
Training loss: 2.4107847213745117
Validation loss: 2.092611853794385

Epoch: 5| Step: 10
Training loss: 2.8003053665161133
Validation loss: 2.1027639681293118

Epoch: 81| Step: 0
Training loss: 2.770534038543701
Validation loss: 2.097923578754548

Epoch: 5| Step: 1
Training loss: 1.7203928232192993
Validation loss: 2.070612733082105

Epoch: 5| Step: 2
Training loss: 2.299665927886963
Validation loss: 2.0913241883759857

Epoch: 5| Step: 3
Training loss: 2.7444911003112793
Validation loss: 2.094366732464042

Epoch: 5| Step: 4
Training loss: 2.3616366386413574
Validation loss: 2.076150208391169

Epoch: 5| Step: 5
Training loss: 1.97897469997406
Validation loss: 2.113495885684926

Epoch: 5| Step: 6
Training loss: 2.630776882171631
Validation loss: 2.08448116753691

Epoch: 5| Step: 7
Training loss: 2.4407541751861572
Validation loss: 2.0979708151150773

Epoch: 5| Step: 8
Training loss: 1.6446616649627686
Validation loss: 2.0843622171750633

Epoch: 5| Step: 9
Training loss: 1.6929924488067627
Validation loss: 2.082433064778646

Epoch: 5| Step: 10
Training loss: 2.444859027862549
Validation loss: 2.0820714478851645

Epoch: 82| Step: 0
Training loss: 1.9441791772842407
Validation loss: 2.1232200873795377

Epoch: 5| Step: 1
Training loss: 2.8406729698181152
Validation loss: 2.086662846226846

Epoch: 5| Step: 2
Training loss: 2.4032211303710938
Validation loss: 2.0746766162175003

Epoch: 5| Step: 3
Training loss: 2.08286452293396
Validation loss: 2.0921126091352074

Epoch: 5| Step: 4
Training loss: 1.5933517217636108
Validation loss: 2.1019260908967707

Epoch: 5| Step: 5
Training loss: 2.0350868701934814
Validation loss: 2.099983189695625

Epoch: 5| Step: 6
Training loss: 2.469555377960205
Validation loss: 2.074780102699034

Epoch: 5| Step: 7
Training loss: 2.219043254852295
Validation loss: 2.1059650451906267

Epoch: 5| Step: 8
Training loss: 2.361834764480591
Validation loss: 2.0871354354325162

Epoch: 5| Step: 9
Training loss: 2.244647264480591
Validation loss: 2.091300182445075

Epoch: 5| Step: 10
Training loss: 2.699594020843506
Validation loss: 2.0643248199134745

Epoch: 83| Step: 0
Training loss: 2.2205262184143066
Validation loss: 2.101989687130015

Epoch: 5| Step: 1
Training loss: 2.636539936065674
Validation loss: 2.0988801012757006

Epoch: 5| Step: 2
Training loss: 2.4926884174346924
Validation loss: 2.101690250058328

Epoch: 5| Step: 3
Training loss: 2.185020685195923
Validation loss: 2.086141768322196

Epoch: 5| Step: 4
Training loss: 1.9341217279434204
Validation loss: 2.120489784466323

Epoch: 5| Step: 5
Training loss: 2.111565351486206
Validation loss: 2.1137668599364576

Epoch: 5| Step: 6
Training loss: 1.9751911163330078
Validation loss: 2.083424296430362

Epoch: 5| Step: 7
Training loss: 2.3885674476623535
Validation loss: 2.103451749329926

Epoch: 5| Step: 8
Training loss: 2.100219249725342
Validation loss: 2.094894847562236

Epoch: 5| Step: 9
Training loss: 1.9182751178741455
Validation loss: 2.090681578523369

Epoch: 5| Step: 10
Training loss: 3.076979875564575
Validation loss: 2.1127621102076706

Epoch: 84| Step: 0
Training loss: 2.106966257095337
Validation loss: 2.0942973936757734

Epoch: 5| Step: 1
Training loss: 2.3168420791625977
Validation loss: 2.0916242676396526

Epoch: 5| Step: 2
Training loss: 2.6051154136657715
Validation loss: 2.086279776788527

Epoch: 5| Step: 3
Training loss: 2.7721409797668457
Validation loss: 2.0927525387015393

Epoch: 5| Step: 4
Training loss: 2.6429996490478516
Validation loss: 2.080548289001629

Epoch: 5| Step: 5
Training loss: 1.5558432340621948
Validation loss: 2.079358245736809

Epoch: 5| Step: 6
Training loss: 1.9899766445159912
Validation loss: 2.0816577198684856

Epoch: 5| Step: 7
Training loss: 2.410468578338623
Validation loss: 2.0864617670736005

Epoch: 5| Step: 8
Training loss: 2.4408745765686035
Validation loss: 2.0977259489797775

Epoch: 5| Step: 9
Training loss: 2.0459372997283936
Validation loss: 2.1008839991784867

Epoch: 5| Step: 10
Training loss: 1.9559049606323242
Validation loss: 2.082124747255797

Epoch: 85| Step: 0
Training loss: 2.660771131515503
Validation loss: 2.1009765081508185

Epoch: 5| Step: 1
Training loss: 1.3436146974563599
Validation loss: 2.0893239744247927

Epoch: 5| Step: 2
Training loss: 2.470569610595703
Validation loss: 2.1017142957256687

Epoch: 5| Step: 3
Training loss: 2.477196216583252
Validation loss: 2.097993102124942

Epoch: 5| Step: 4
Training loss: 2.61316180229187
Validation loss: 2.099777508807439

Epoch: 5| Step: 5
Training loss: 2.1440634727478027
Validation loss: 2.0607810584447717

Epoch: 5| Step: 6
Training loss: 2.056885242462158
Validation loss: 2.0660572128911174

Epoch: 5| Step: 7
Training loss: 1.4756966829299927
Validation loss: 2.1040655618072837

Epoch: 5| Step: 8
Training loss: 2.2759227752685547
Validation loss: 2.0896975019926667

Epoch: 5| Step: 9
Training loss: 2.7823829650878906
Validation loss: 2.092371512484807

Epoch: 5| Step: 10
Training loss: 2.4649767875671387
Validation loss: 2.096405206188079

Epoch: 86| Step: 0
Training loss: 2.4648358821868896
Validation loss: 2.0797940197811333

Epoch: 5| Step: 1
Training loss: 1.9859565496444702
Validation loss: 2.0583368911538074

Epoch: 5| Step: 2
Training loss: 2.0691137313842773
Validation loss: 2.106085329927424

Epoch: 5| Step: 3
Training loss: 2.307708263397217
Validation loss: 2.096268371869159

Epoch: 5| Step: 4
Training loss: 1.8799946308135986
Validation loss: 2.078429255434262

Epoch: 5| Step: 5
Training loss: 2.58726167678833
Validation loss: 2.0936543672315535

Epoch: 5| Step: 6
Training loss: 1.9077460765838623
Validation loss: 2.102755090241791

Epoch: 5| Step: 7
Training loss: 2.5630404949188232
Validation loss: 2.0924525389107327

Epoch: 5| Step: 8
Training loss: 2.0584168434143066
Validation loss: 2.096115750651206

Epoch: 5| Step: 9
Training loss: 2.604647159576416
Validation loss: 2.0665563101409585

Epoch: 5| Step: 10
Training loss: 2.406655788421631
Validation loss: 2.087923449854697

Epoch: 87| Step: 0
Training loss: 2.0665442943573
Validation loss: 2.0885038927037227

Epoch: 5| Step: 1
Training loss: 2.8340585231781006
Validation loss: 2.107500437767275

Epoch: 5| Step: 2
Training loss: 2.8162970542907715
Validation loss: 2.062892711290749

Epoch: 5| Step: 3
Training loss: 2.4135241508483887
Validation loss: 2.0827491552599016

Epoch: 5| Step: 4
Training loss: 2.4725539684295654
Validation loss: 2.09107175565535

Epoch: 5| Step: 5
Training loss: 1.9458951950073242
Validation loss: 2.0995245108040432

Epoch: 5| Step: 6
Training loss: 2.185136318206787
Validation loss: 2.111654935344573

Epoch: 5| Step: 7
Training loss: 2.0853734016418457
Validation loss: 2.083050525316628

Epoch: 5| Step: 8
Training loss: 1.8706104755401611
Validation loss: 2.10292326506748

Epoch: 5| Step: 9
Training loss: 1.6575075387954712
Validation loss: 2.090812098595404

Epoch: 5| Step: 10
Training loss: 2.314424514770508
Validation loss: 2.0957147857194305

Epoch: 88| Step: 0
Training loss: 1.7088207006454468
Validation loss: 2.091447432835897

Epoch: 5| Step: 1
Training loss: 2.8069701194763184
Validation loss: 2.087767352340042

Epoch: 5| Step: 2
Training loss: 2.393350601196289
Validation loss: 2.0989425874525502

Epoch: 5| Step: 3
Training loss: 2.178678512573242
Validation loss: 2.0845229420610654

Epoch: 5| Step: 4
Training loss: 2.1675498485565186
Validation loss: 2.094595427154213

Epoch: 5| Step: 5
Training loss: 2.233248233795166
Validation loss: 2.0780867325362338

Epoch: 5| Step: 6
Training loss: 2.0031349658966064
Validation loss: 2.0783699058717295

Epoch: 5| Step: 7
Training loss: 1.9816348552703857
Validation loss: 2.07291240333229

Epoch: 5| Step: 8
Training loss: 1.8801854848861694
Validation loss: 2.0701752478076565

Epoch: 5| Step: 9
Training loss: 2.772036552429199
Validation loss: 2.0914819189297256

Epoch: 5| Step: 10
Training loss: 2.638392686843872
Validation loss: 2.093688794361648

Epoch: 89| Step: 0
Training loss: 2.237611770629883
Validation loss: 2.128990911668347

Epoch: 5| Step: 1
Training loss: 2.317603588104248
Validation loss: 2.092956295577429

Epoch: 5| Step: 2
Training loss: 2.2599003314971924
Validation loss: 2.0947627816148984

Epoch: 5| Step: 3
Training loss: 2.794257640838623
Validation loss: 2.0867404348106793

Epoch: 5| Step: 4
Training loss: 2.6384167671203613
Validation loss: 2.090775124488338

Epoch: 5| Step: 5
Training loss: 2.088770866394043
Validation loss: 2.0747536177276285

Epoch: 5| Step: 6
Training loss: 2.3473994731903076
Validation loss: 2.056679043718564

Epoch: 5| Step: 7
Training loss: 2.1837170124053955
Validation loss: 2.074263172764932

Epoch: 5| Step: 8
Training loss: 1.5847961902618408
Validation loss: 2.1041736730965237

Epoch: 5| Step: 9
Training loss: 2.409665584564209
Validation loss: 2.0941005163295294

Epoch: 5| Step: 10
Training loss: 1.920440912246704
Validation loss: 2.0970002194886566

Epoch: 90| Step: 0
Training loss: 2.4444546699523926
Validation loss: 2.083667637199484

Epoch: 5| Step: 1
Training loss: 2.1474881172180176
Validation loss: 2.10785944743823

Epoch: 5| Step: 2
Training loss: 2.2929797172546387
Validation loss: 2.0949030230122228

Epoch: 5| Step: 3
Training loss: 2.0191855430603027
Validation loss: 2.1033107772950204

Epoch: 5| Step: 4
Training loss: 2.571406602859497
Validation loss: 2.0824524561564126

Epoch: 5| Step: 5
Training loss: 1.9928791522979736
Validation loss: 2.1043635106855825

Epoch: 5| Step: 6
Training loss: 2.554734706878662
Validation loss: 2.0933730038263465

Epoch: 5| Step: 7
Training loss: 2.087772846221924
Validation loss: 2.1135520614603514

Epoch: 5| Step: 8
Training loss: 1.9610569477081299
Validation loss: 2.0841292463323122

Epoch: 5| Step: 9
Training loss: 2.295266628265381
Validation loss: 2.0903487218323575

Epoch: 5| Step: 10
Training loss: 2.5804901123046875
Validation loss: 2.112622594320646

Epoch: 91| Step: 0
Training loss: 2.211674451828003
Validation loss: 2.089049941749983

Epoch: 5| Step: 1
Training loss: 2.1554770469665527
Validation loss: 2.074511671579012

Epoch: 5| Step: 2
Training loss: 2.354841709136963
Validation loss: 2.0831694346602245

Epoch: 5| Step: 3
Training loss: 1.6675269603729248
Validation loss: 2.0786538098448064

Epoch: 5| Step: 4
Training loss: 2.7530033588409424
Validation loss: 2.0728868387078725

Epoch: 5| Step: 5
Training loss: 2.2459025382995605
Validation loss: 2.0920032198711107

Epoch: 5| Step: 6
Training loss: 2.375565528869629
Validation loss: 2.103858373498404

Epoch: 5| Step: 7
Training loss: 1.8073101043701172
Validation loss: 2.0819436888540945

Epoch: 5| Step: 8
Training loss: 2.4362926483154297
Validation loss: 2.0991963468572146

Epoch: 5| Step: 9
Training loss: 2.2994582653045654
Validation loss: 2.0814050794929586

Epoch: 5| Step: 10
Training loss: 2.163612127304077
Validation loss: 2.088816867079786

Epoch: 92| Step: 0
Training loss: 1.4050772190093994
Validation loss: 2.1083411196226716

Epoch: 5| Step: 1
Training loss: 2.8510584831237793
Validation loss: 2.096171866181076

Epoch: 5| Step: 2
Training loss: 1.8269405364990234
Validation loss: 2.0941036926802767

Epoch: 5| Step: 3
Training loss: 2.357339859008789
Validation loss: 2.086345039388185

Epoch: 5| Step: 4
Training loss: 2.6916117668151855
Validation loss: 2.0765424787357287

Epoch: 5| Step: 5
Training loss: 2.254246234893799
Validation loss: 2.0802103345112135

Epoch: 5| Step: 6
Training loss: 2.850724935531616
Validation loss: 2.107965538578649

Epoch: 5| Step: 7
Training loss: 1.7000401020050049
Validation loss: 2.09055971330212

Epoch: 5| Step: 8
Training loss: 2.841496229171753
Validation loss: 2.096211120646487

Epoch: 5| Step: 9
Training loss: 2.0976834297180176
Validation loss: 2.087710431827012

Epoch: 5| Step: 10
Training loss: 1.8311933279037476
Validation loss: 2.0914225347580446

Epoch: 93| Step: 0
Training loss: 2.950916290283203
Validation loss: 2.122838056215676

Epoch: 5| Step: 1
Training loss: 2.2784929275512695
Validation loss: 2.1104564218110937

Epoch: 5| Step: 2
Training loss: 2.452925205230713
Validation loss: 2.0958920025056407

Epoch: 5| Step: 3
Training loss: 2.267927646636963
Validation loss: 2.070683233199581

Epoch: 5| Step: 4
Training loss: 1.9055967330932617
Validation loss: 2.0871829781481015

Epoch: 5| Step: 5
Training loss: 2.225564479827881
Validation loss: 2.0934600881350938

Epoch: 5| Step: 6
Training loss: 1.7927970886230469
Validation loss: 2.0885635550304125

Epoch: 5| Step: 7
Training loss: 1.9091377258300781
Validation loss: 2.099505329644808

Epoch: 5| Step: 8
Training loss: 2.711897373199463
Validation loss: 2.109933912113149

Epoch: 5| Step: 9
Training loss: 2.112844467163086
Validation loss: 2.071039148556289

Epoch: 5| Step: 10
Training loss: 1.988215684890747
Validation loss: 2.10696534315745

Epoch: 94| Step: 0
Training loss: 2.7004640102386475
Validation loss: 2.084550803707492

Epoch: 5| Step: 1
Training loss: 2.4287819862365723
Validation loss: 2.095809404568006

Epoch: 5| Step: 2
Training loss: 2.248239040374756
Validation loss: 2.086744341799008

Epoch: 5| Step: 3
Training loss: 2.1238315105438232
Validation loss: 2.091454646920645

Epoch: 5| Step: 4
Training loss: 1.4520145654678345
Validation loss: 2.084656544910964

Epoch: 5| Step: 5
Training loss: 2.7340917587280273
Validation loss: 2.089805369736046

Epoch: 5| Step: 6
Training loss: 2.4507057666778564
Validation loss: 2.078197275438616

Epoch: 5| Step: 7
Training loss: 2.837006092071533
Validation loss: 2.068694350539997

Epoch: 5| Step: 8
Training loss: 1.4854267835617065
Validation loss: 2.121166172847953

Epoch: 5| Step: 9
Training loss: 2.21040940284729
Validation loss: 2.0821077349365398

Epoch: 5| Step: 10
Training loss: 1.793533205986023
Validation loss: 2.0944552626661075

Epoch: 95| Step: 0
Training loss: 2.035426139831543
Validation loss: 2.105430615845547

Epoch: 5| Step: 1
Training loss: 1.8709440231323242
Validation loss: 2.0671874976927236

Epoch: 5| Step: 2
Training loss: 2.1500096321105957
Validation loss: 2.1018982625776723

Epoch: 5| Step: 3
Training loss: 2.1929140090942383
Validation loss: 2.0948011118878602

Epoch: 5| Step: 4
Training loss: 2.1974499225616455
Validation loss: 2.074503003910024

Epoch: 5| Step: 5
Training loss: 1.9445441961288452
Validation loss: 2.1030016611981135

Epoch: 5| Step: 6
Training loss: 2.1793816089630127
Validation loss: 2.0718651304962816

Epoch: 5| Step: 7
Training loss: 2.416320323944092
Validation loss: 2.0890470961088776

Epoch: 5| Step: 8
Training loss: 2.236541271209717
Validation loss: 2.070910846033404

Epoch: 5| Step: 9
Training loss: 2.603943347930908
Validation loss: 2.0878185302980485

Epoch: 5| Step: 10
Training loss: 2.8433496952056885
Validation loss: 2.0825562989839943

Epoch: 96| Step: 0
Training loss: 2.273308038711548
Validation loss: 2.0995059526094826

Epoch: 5| Step: 1
Training loss: 2.6413609981536865
Validation loss: 2.0676090332769577

Epoch: 5| Step: 2
Training loss: 2.962183713912964
Validation loss: 2.0795149213524273

Epoch: 5| Step: 3
Training loss: 1.844811201095581
Validation loss: 2.0718924307054087

Epoch: 5| Step: 4
Training loss: 1.4547349214553833
Validation loss: 2.1107559293828984

Epoch: 5| Step: 5
Training loss: 2.7219719886779785
Validation loss: 2.0792532031254103

Epoch: 5| Step: 6
Training loss: 2.3416922092437744
Validation loss: 2.084842389629733

Epoch: 5| Step: 7
Training loss: 1.6399517059326172
Validation loss: 2.088899891863587

Epoch: 5| Step: 8
Training loss: 1.978887915611267
Validation loss: 2.0879302691387873

Epoch: 5| Step: 9
Training loss: 2.6699161529541016
Validation loss: 2.084620829551451

Epoch: 5| Step: 10
Training loss: 2.1584081649780273
Validation loss: 2.1012775872343328

Epoch: 97| Step: 0
Training loss: 2.0505197048187256
Validation loss: 2.0983892384395806

Epoch: 5| Step: 1
Training loss: 2.212742328643799
Validation loss: 2.0748152425212245

Epoch: 5| Step: 2
Training loss: 2.909008264541626
Validation loss: 2.083420379187471

Epoch: 5| Step: 3
Training loss: 2.4616003036499023
Validation loss: 2.0960099902204288

Epoch: 5| Step: 4
Training loss: 2.312469005584717
Validation loss: 2.077121132163591

Epoch: 5| Step: 5
Training loss: 2.294630289077759
Validation loss: 2.0925944594926733

Epoch: 5| Step: 6
Training loss: 1.498386025428772
Validation loss: 2.0978771691681235

Epoch: 5| Step: 7
Training loss: 2.4914016723632812
Validation loss: 2.1058919647688508

Epoch: 5| Step: 8
Training loss: 2.3895156383514404
Validation loss: 2.1313055074343117

Epoch: 5| Step: 9
Training loss: 2.2518601417541504
Validation loss: 2.0883146947430027

Epoch: 5| Step: 10
Training loss: 1.648808240890503
Validation loss: 2.086433615735782

Epoch: 98| Step: 0
Training loss: 2.2248499393463135
Validation loss: 2.0569267016585155

Epoch: 5| Step: 1
Training loss: 2.0741324424743652
Validation loss: 2.0793413526268414

Epoch: 5| Step: 2
Training loss: 2.15604567527771
Validation loss: 2.104636738377233

Epoch: 5| Step: 3
Training loss: 2.7594428062438965
Validation loss: 2.10224485910067

Epoch: 5| Step: 4
Training loss: 2.0801053047180176
Validation loss: 2.0698952674865723

Epoch: 5| Step: 5
Training loss: 1.870754599571228
Validation loss: 2.0749043828697613

Epoch: 5| Step: 6
Training loss: 2.108336925506592
Validation loss: 2.0718487001234487

Epoch: 5| Step: 7
Training loss: 2.4856865406036377
Validation loss: 2.0817123882232176

Epoch: 5| Step: 8
Training loss: 2.2595715522766113
Validation loss: 2.104753601935602

Epoch: 5| Step: 9
Training loss: 2.328115463256836
Validation loss: 2.087418381885816

Epoch: 5| Step: 10
Training loss: 2.0815210342407227
Validation loss: 2.070390227020428

Epoch: 99| Step: 0
Training loss: 2.3951125144958496
Validation loss: 2.0582599293801094

Epoch: 5| Step: 1
Training loss: 2.07236385345459
Validation loss: 2.0916908171869095

Epoch: 5| Step: 2
Training loss: 1.7748167514801025
Validation loss: 2.069619776100241

Epoch: 5| Step: 3
Training loss: 2.1212639808654785
Validation loss: 2.0640544378629295

Epoch: 5| Step: 4
Training loss: 1.3280503749847412
Validation loss: 2.094702859078684

Epoch: 5| Step: 5
Training loss: 2.5956473350524902
Validation loss: 2.0992082831680134

Epoch: 5| Step: 6
Training loss: 2.725944757461548
Validation loss: 2.1168944528025966

Epoch: 5| Step: 7
Training loss: 2.3304762840270996
Validation loss: 2.0857024141537246

Epoch: 5| Step: 8
Training loss: 1.9106918573379517
Validation loss: 2.08013331121014

Epoch: 5| Step: 9
Training loss: 2.331725597381592
Validation loss: 2.079135855038961

Epoch: 5| Step: 10
Training loss: 2.975788116455078
Validation loss: 2.107318453891303

Epoch: 100| Step: 0
Training loss: 1.831117868423462
Validation loss: 2.097486333180499

Epoch: 5| Step: 1
Training loss: 2.4145188331604004
Validation loss: 2.098915562834791

Epoch: 5| Step: 2
Training loss: 2.226888656616211
Validation loss: 2.1141339643027193

Epoch: 5| Step: 3
Training loss: 1.66455078125
Validation loss: 2.104185455588884

Epoch: 5| Step: 4
Training loss: 2.7009167671203613
Validation loss: 2.093455531263864

Epoch: 5| Step: 5
Training loss: 2.6022353172302246
Validation loss: 2.0778484113754763

Epoch: 5| Step: 6
Training loss: 2.2784576416015625
Validation loss: 2.088421321684314

Epoch: 5| Step: 7
Training loss: 1.6381593942642212
Validation loss: 2.0877062915473856

Epoch: 5| Step: 8
Training loss: 2.641200304031372
Validation loss: 2.1023435182468866

Epoch: 5| Step: 9
Training loss: 1.9828884601593018
Validation loss: 2.097883839761057

Epoch: 5| Step: 10
Training loss: 2.4029102325439453
Validation loss: 2.0620134030618975

Epoch: 101| Step: 0
Training loss: 1.8634169101715088
Validation loss: 2.086848997300671

Epoch: 5| Step: 1
Training loss: 1.8558928966522217
Validation loss: 2.0771513920958324

Epoch: 5| Step: 2
Training loss: 1.7846122980117798
Validation loss: 2.0869463259173977

Epoch: 5| Step: 3
Training loss: 2.0312397480010986
Validation loss: 2.0689608948205107

Epoch: 5| Step: 4
Training loss: 1.6540892124176025
Validation loss: 2.1133548610953876

Epoch: 5| Step: 5
Training loss: 1.757958173751831
Validation loss: 2.103974502573731

Epoch: 5| Step: 6
Training loss: 2.7249093055725098
Validation loss: 2.0901524405325613

Epoch: 5| Step: 7
Training loss: 3.1871016025543213
Validation loss: 2.07008110579624

Epoch: 5| Step: 8
Training loss: 2.3290863037109375
Validation loss: 2.086088965016027

Epoch: 5| Step: 9
Training loss: 2.6748828887939453
Validation loss: 2.0904763360177316

Epoch: 5| Step: 10
Training loss: 2.586338520050049
Validation loss: 2.0760589363754436

Epoch: 102| Step: 0
Training loss: 2.734621524810791
Validation loss: 2.0876200070945163

Epoch: 5| Step: 1
Training loss: 2.3282675743103027
Validation loss: 2.081625742297019

Epoch: 5| Step: 2
Training loss: 2.100991725921631
Validation loss: 2.091405466038694

Epoch: 5| Step: 3
Training loss: 2.4287688732147217
Validation loss: 2.0687493611407537

Epoch: 5| Step: 4
Training loss: 2.048046112060547
Validation loss: 2.0749696467512395

Epoch: 5| Step: 5
Training loss: 1.9263967275619507
Validation loss: 2.057721625092209

Epoch: 5| Step: 6
Training loss: 2.3802683353424072
Validation loss: 2.085488498851817

Epoch: 5| Step: 7
Training loss: 2.5399374961853027
Validation loss: 2.087751175767632

Epoch: 5| Step: 8
Training loss: 1.8724206686019897
Validation loss: 2.075546536394345

Epoch: 5| Step: 9
Training loss: 1.7076231241226196
Validation loss: 2.061873500065137

Epoch: 5| Step: 10
Training loss: 2.330726146697998
Validation loss: 2.0942068510158087

Epoch: 103| Step: 0
Training loss: 1.804342269897461
Validation loss: 2.0895373616167294

Epoch: 5| Step: 1
Training loss: 2.0689475536346436
Validation loss: 2.105512188326928

Epoch: 5| Step: 2
Training loss: 3.207246780395508
Validation loss: 2.0732328020116335

Epoch: 5| Step: 3
Training loss: 2.1200692653656006
Validation loss: 2.090096527530301

Epoch: 5| Step: 4
Training loss: 2.3544983863830566
Validation loss: 2.0905361303719143

Epoch: 5| Step: 5
Training loss: 2.266268491744995
Validation loss: 2.084707688259822

Epoch: 5| Step: 6
Training loss: 2.3528685569763184
Validation loss: 2.110584428233485

Epoch: 5| Step: 7
Training loss: 1.7722889184951782
Validation loss: 2.0694933270895355

Epoch: 5| Step: 8
Training loss: 2.6540870666503906
Validation loss: 2.0675253739920993

Epoch: 5| Step: 9
Training loss: 1.4941003322601318
Validation loss: 2.0798027425683956

Epoch: 5| Step: 10
Training loss: 2.26352596282959
Validation loss: 2.1169170307856735

Epoch: 104| Step: 0
Training loss: 2.0653254985809326
Validation loss: 2.0991815828507945

Epoch: 5| Step: 1
Training loss: 1.9081535339355469
Validation loss: 2.0938091816440707

Epoch: 5| Step: 2
Training loss: 2.135319471359253
Validation loss: 2.066957818564548

Epoch: 5| Step: 3
Training loss: 2.1290202140808105
Validation loss: 2.0794367815858577

Epoch: 5| Step: 4
Training loss: 1.9111888408660889
Validation loss: 2.099918926915815

Epoch: 5| Step: 5
Training loss: 2.399620532989502
Validation loss: 2.0858932002898185

Epoch: 5| Step: 6
Training loss: 2.270932912826538
Validation loss: 2.0797940659266647

Epoch: 5| Step: 7
Training loss: 2.613603115081787
Validation loss: 2.0943340845005487

Epoch: 5| Step: 8
Training loss: 2.5345611572265625
Validation loss: 2.1120433512554375

Epoch: 5| Step: 9
Training loss: 2.3779196739196777
Validation loss: 2.087450219738868

Epoch: 5| Step: 10
Training loss: 1.8630180358886719
Validation loss: 2.0841484736370783

Epoch: 105| Step: 0
Training loss: 2.3513383865356445
Validation loss: 2.1084021393970778

Epoch: 5| Step: 1
Training loss: 2.0504190921783447
Validation loss: 2.0723528323634977

Epoch: 5| Step: 2
Training loss: 2.9813709259033203
Validation loss: 2.08221237890182

Epoch: 5| Step: 3
Training loss: 2.590791702270508
Validation loss: 2.058906360339093

Epoch: 5| Step: 4
Training loss: 1.9412767887115479
Validation loss: 2.1019896550845076

Epoch: 5| Step: 5
Training loss: 2.3168091773986816
Validation loss: 2.0627118887439853

Epoch: 5| Step: 6
Training loss: 2.007469892501831
Validation loss: 2.1067167302613616

Epoch: 5| Step: 7
Training loss: 2.2869856357574463
Validation loss: 2.1116520409942954

Epoch: 5| Step: 8
Training loss: 2.1783878803253174
Validation loss: 2.096384735517604

Epoch: 5| Step: 9
Training loss: 1.8347995281219482
Validation loss: 2.088542148631106

Epoch: 5| Step: 10
Training loss: 1.6047531366348267
Validation loss: 2.0849362983498523

Epoch: 106| Step: 0
Training loss: 1.767673134803772
Validation loss: 2.0911767662212415

Epoch: 5| Step: 1
Training loss: 2.177555561065674
Validation loss: 2.076039045087753

Epoch: 5| Step: 2
Training loss: 2.7731704711914062
Validation loss: 2.08172704327491

Epoch: 5| Step: 3
Training loss: 1.8940833806991577
Validation loss: 2.110219253006802

Epoch: 5| Step: 4
Training loss: 2.0900611877441406
Validation loss: 2.059810479482015

Epoch: 5| Step: 5
Training loss: 2.0818934440612793
Validation loss: 2.085727548086515

Epoch: 5| Step: 6
Training loss: 2.3452749252319336
Validation loss: 2.0927247770370974

Epoch: 5| Step: 7
Training loss: 2.719472885131836
Validation loss: 2.075758005983086

Epoch: 5| Step: 8
Training loss: 2.3109164237976074
Validation loss: 2.0944364750257103

Epoch: 5| Step: 9
Training loss: 2.431056022644043
Validation loss: 2.082811640154931

Epoch: 5| Step: 10
Training loss: 1.7199702262878418
Validation loss: 2.0778078340714976

Epoch: 107| Step: 0
Training loss: 2.4852938652038574
Validation loss: 2.0625828491744174

Epoch: 5| Step: 1
Training loss: 2.1196236610412598
Validation loss: 2.0761503622096074

Epoch: 5| Step: 2
Training loss: 2.043684482574463
Validation loss: 2.0643103417529853

Epoch: 5| Step: 3
Training loss: 1.9109007120132446
Validation loss: 2.048262757639731

Epoch: 5| Step: 4
Training loss: 2.4283289909362793
Validation loss: 2.07235634967845

Epoch: 5| Step: 5
Training loss: 2.4744091033935547
Validation loss: 2.0831649611073155

Epoch: 5| Step: 6
Training loss: 1.9237371683120728
Validation loss: 2.0986883524925477

Epoch: 5| Step: 7
Training loss: 2.4893550872802734
Validation loss: 2.0806675649458364

Epoch: 5| Step: 8
Training loss: 2.630225658416748
Validation loss: 2.077484523096392

Epoch: 5| Step: 9
Training loss: 1.572295904159546
Validation loss: 2.0755538043155464

Epoch: 5| Step: 10
Training loss: 2.062607765197754
Validation loss: 2.1075592861380628

Epoch: 108| Step: 0
Training loss: 2.3722031116485596
Validation loss: 2.0773453891918225

Epoch: 5| Step: 1
Training loss: 2.3385512828826904
Validation loss: 2.0704193115234375

Epoch: 5| Step: 2
Training loss: 2.3283822536468506
Validation loss: 2.0758899373392903

Epoch: 5| Step: 3
Training loss: 2.764239549636841
Validation loss: 2.0561366568329515

Epoch: 5| Step: 4
Training loss: 1.710733413696289
Validation loss: 2.076972089787965

Epoch: 5| Step: 5
Training loss: 1.9799509048461914
Validation loss: 2.0582589718603317

Epoch: 5| Step: 6
Training loss: 2.2050366401672363
Validation loss: 2.082092818393502

Epoch: 5| Step: 7
Training loss: 2.3264214992523193
Validation loss: 2.097770587090523

Epoch: 5| Step: 8
Training loss: 2.093920946121216
Validation loss: 2.058493975670107

Epoch: 5| Step: 9
Training loss: 1.7445495128631592
Validation loss: 2.081084574422529

Epoch: 5| Step: 10
Training loss: 2.4453370571136475
Validation loss: 2.095581575106549

Epoch: 109| Step: 0
Training loss: 2.0631611347198486
Validation loss: 2.106393532086444

Epoch: 5| Step: 1
Training loss: 2.1872804164886475
Validation loss: 2.0838965677445933

Epoch: 5| Step: 2
Training loss: 2.168231964111328
Validation loss: 2.1017255539535196

Epoch: 5| Step: 3
Training loss: 2.2780184745788574
Validation loss: 2.0552880507643505

Epoch: 5| Step: 4
Training loss: 2.636103391647339
Validation loss: 2.0684434752310477

Epoch: 5| Step: 5
Training loss: 1.7879245281219482
Validation loss: 2.1005149323453187

Epoch: 5| Step: 6
Training loss: 2.190467357635498
Validation loss: 2.0993833208596833

Epoch: 5| Step: 7
Training loss: 2.1291489601135254
Validation loss: 2.08975996253311

Epoch: 5| Step: 8
Training loss: 2.56544828414917
Validation loss: 2.072829169611777

Epoch: 5| Step: 9
Training loss: 2.2444987297058105
Validation loss: 2.071401378159882

Epoch: 5| Step: 10
Training loss: 1.844310998916626
Validation loss: 2.073345950854722

Epoch: 110| Step: 0
Training loss: 2.2369487285614014
Validation loss: 2.0717859024642618

Epoch: 5| Step: 1
Training loss: 1.9802210330963135
Validation loss: 2.081086520225771

Epoch: 5| Step: 2
Training loss: 2.1628503799438477
Validation loss: 2.073962970446515

Epoch: 5| Step: 3
Training loss: 1.9445117712020874
Validation loss: 2.051688419875278

Epoch: 5| Step: 4
Training loss: 2.0101821422576904
Validation loss: 2.077051105037812

Epoch: 5| Step: 5
Training loss: 2.6847426891326904
Validation loss: 2.0416979994825137

Epoch: 5| Step: 6
Training loss: 2.128469944000244
Validation loss: 2.0921475092569985

Epoch: 5| Step: 7
Training loss: 2.2808995246887207
Validation loss: 2.075733410414829

Epoch: 5| Step: 8
Training loss: 2.4314048290252686
Validation loss: 2.06459677732119

Epoch: 5| Step: 9
Training loss: 2.3822593688964844
Validation loss: 2.091483813460155

Epoch: 5| Step: 10
Training loss: 1.9185928106307983
Validation loss: 2.0729188470430273

Epoch: 111| Step: 0
Training loss: 1.7766059637069702
Validation loss: 2.073128966874974

Epoch: 5| Step: 1
Training loss: 2.812295436859131
Validation loss: 2.0721798968571488

Epoch: 5| Step: 2
Training loss: 2.380153179168701
Validation loss: 2.042583675794704

Epoch: 5| Step: 3
Training loss: 2.2915477752685547
Validation loss: 2.067097253696893

Epoch: 5| Step: 4
Training loss: 2.8423051834106445
Validation loss: 2.07234767688218

Epoch: 5| Step: 5
Training loss: 1.978878378868103
Validation loss: 2.093260501020698

Epoch: 5| Step: 6
Training loss: 1.5700976848602295
Validation loss: 2.0871159568909676

Epoch: 5| Step: 7
Training loss: 2.4300408363342285
Validation loss: 2.091585810466479

Epoch: 5| Step: 8
Training loss: 1.4285752773284912
Validation loss: 2.100671043959997

Epoch: 5| Step: 9
Training loss: 2.6930699348449707
Validation loss: 2.087578529952675

Epoch: 5| Step: 10
Training loss: 2.058823585510254
Validation loss: 2.0922775422373125

Epoch: 112| Step: 0
Training loss: 1.6527736186981201
Validation loss: 2.093862928369994

Epoch: 5| Step: 1
Training loss: 2.4669528007507324
Validation loss: 2.070592631575882

Epoch: 5| Step: 2
Training loss: 1.647395372390747
Validation loss: 2.0863973607299147

Epoch: 5| Step: 3
Training loss: 2.289119243621826
Validation loss: 2.0951259918110345

Epoch: 5| Step: 4
Training loss: 2.553820848464966
Validation loss: 2.0909426289220012

Epoch: 5| Step: 5
Training loss: 1.5294780731201172
Validation loss: 2.103993453005309

Epoch: 5| Step: 6
Training loss: 2.727677583694458
Validation loss: 2.065027508684384

Epoch: 5| Step: 7
Training loss: 2.579394817352295
Validation loss: 2.0720548437487696

Epoch: 5| Step: 8
Training loss: 2.210435152053833
Validation loss: 2.114265643140321

Epoch: 5| Step: 9
Training loss: 2.197246551513672
Validation loss: 2.098675617607691

Epoch: 5| Step: 10
Training loss: 2.334581136703491
Validation loss: 2.079046828772432

Epoch: 113| Step: 0
Training loss: 1.9680715799331665
Validation loss: 2.0873113652711273

Epoch: 5| Step: 1
Training loss: 2.5622305870056152
Validation loss: 2.0847715523935135

Epoch: 5| Step: 2
Training loss: 2.1091835498809814
Validation loss: 2.0759658582748903

Epoch: 5| Step: 3
Training loss: 1.7435753345489502
Validation loss: 2.0846182761653775

Epoch: 5| Step: 4
Training loss: 2.1781132221221924
Validation loss: 2.0819194239954792

Epoch: 5| Step: 5
Training loss: 3.203472852706909
Validation loss: 2.1143180657458562

Epoch: 5| Step: 6
Training loss: 2.083782911300659
Validation loss: 2.090571677812966

Epoch: 5| Step: 7
Training loss: 2.177907705307007
Validation loss: 2.0716351206584642

Epoch: 5| Step: 8
Training loss: 2.0858750343322754
Validation loss: 2.100429916894564

Epoch: 5| Step: 9
Training loss: 2.096951961517334
Validation loss: 2.0544220619304205

Epoch: 5| Step: 10
Training loss: 2.0777339935302734
Validation loss: 2.095992644627889

Epoch: 114| Step: 0
Training loss: 1.8225196599960327
Validation loss: 2.089865643491027

Epoch: 5| Step: 1
Training loss: 2.596426010131836
Validation loss: 2.0858811114424016

Epoch: 5| Step: 2
Training loss: 2.5985188484191895
Validation loss: 2.0611490639307166

Epoch: 5| Step: 3
Training loss: 1.2406435012817383
Validation loss: 2.0867819504071305

Epoch: 5| Step: 4
Training loss: 1.448164939880371
Validation loss: 2.05351157598598

Epoch: 5| Step: 5
Training loss: 1.8817087411880493
Validation loss: 2.1007136708946637

Epoch: 5| Step: 6
Training loss: 2.067171812057495
Validation loss: 2.067503306173509

Epoch: 5| Step: 7
Training loss: 2.6129562854766846
Validation loss: 2.073732178698304

Epoch: 5| Step: 8
Training loss: 2.175447702407837
Validation loss: 2.0614602014582646

Epoch: 5| Step: 9
Training loss: 2.8123250007629395
Validation loss: 2.100599827304963

Epoch: 5| Step: 10
Training loss: 2.890096664428711
Validation loss: 2.056953663467079

Epoch: 115| Step: 0
Training loss: 1.5479055643081665
Validation loss: 2.09170042058473

Epoch: 5| Step: 1
Training loss: 2.618636131286621
Validation loss: 2.0733192146465345

Epoch: 5| Step: 2
Training loss: 2.820681571960449
Validation loss: 2.1052571445383053

Epoch: 5| Step: 3
Training loss: 1.8769166469573975
Validation loss: 2.068275918242752

Epoch: 5| Step: 4
Training loss: 2.2454731464385986
Validation loss: 2.0699930139767226

Epoch: 5| Step: 5
Training loss: 2.706127882003784
Validation loss: 2.092582154017623

Epoch: 5| Step: 6
Training loss: 2.3458356857299805
Validation loss: 2.103063157809678

Epoch: 5| Step: 7
Training loss: 1.9752147197723389
Validation loss: 2.058879042184481

Epoch: 5| Step: 8
Training loss: 1.879908800125122
Validation loss: 2.0618718670260523

Epoch: 5| Step: 9
Training loss: 1.5545103549957275
Validation loss: 2.071209220476048

Epoch: 5| Step: 10
Training loss: 2.250481367111206
Validation loss: 2.061617919193801

Epoch: 116| Step: 0
Training loss: 2.233874559402466
Validation loss: 2.067025976796304

Epoch: 5| Step: 1
Training loss: 2.9454345703125
Validation loss: 2.0688889641915598

Epoch: 5| Step: 2
Training loss: 2.2018723487854004
Validation loss: 2.068831992405717

Epoch: 5| Step: 3
Training loss: 2.0451018810272217
Validation loss: 2.059781648779428

Epoch: 5| Step: 4
Training loss: 2.074955701828003
Validation loss: 2.0636742986658567

Epoch: 5| Step: 5
Training loss: 1.9186220169067383
Validation loss: 2.0813984306909705

Epoch: 5| Step: 6
Training loss: 2.2340285778045654
Validation loss: 2.06694043836286

Epoch: 5| Step: 7
Training loss: 2.0001015663146973
Validation loss: 2.0824138515739032

Epoch: 5| Step: 8
Training loss: 2.5015406608581543
Validation loss: 2.0593144342463505

Epoch: 5| Step: 9
Training loss: 1.959071397781372
Validation loss: 2.047649629654423

Epoch: 5| Step: 10
Training loss: 1.8196065425872803
Validation loss: 2.09102717779016

Epoch: 117| Step: 0
Training loss: 1.4103357791900635
Validation loss: 2.095469577338106

Epoch: 5| Step: 1
Training loss: 2.8560543060302734
Validation loss: 2.0624970274586834

Epoch: 5| Step: 2
Training loss: 1.8513721227645874
Validation loss: 2.094236323910375

Epoch: 5| Step: 3
Training loss: 2.368103504180908
Validation loss: 2.0655996389286493

Epoch: 5| Step: 4
Training loss: 2.358058452606201
Validation loss: 2.0819195573047926

Epoch: 5| Step: 5
Training loss: 2.0493228435516357
Validation loss: 2.0698112300647202

Epoch: 5| Step: 6
Training loss: 2.2169125080108643
Validation loss: 2.068233402826453

Epoch: 5| Step: 7
Training loss: 1.634673833847046
Validation loss: 2.08504085130589

Epoch: 5| Step: 8
Training loss: 2.782219409942627
Validation loss: 2.0664314326419624

Epoch: 5| Step: 9
Training loss: 2.3283982276916504
Validation loss: 2.0822018474660893

Epoch: 5| Step: 10
Training loss: 2.2364602088928223
Validation loss: 2.1053034054335726

Epoch: 118| Step: 0
Training loss: 1.8245643377304077
Validation loss: 2.098361552402537

Epoch: 5| Step: 1
Training loss: 2.2822506427764893
Validation loss: 2.1173814471049974

Epoch: 5| Step: 2
Training loss: 2.379307270050049
Validation loss: 2.08907344777097

Epoch: 5| Step: 3
Training loss: 2.594024181365967
Validation loss: 2.0810306584963234

Epoch: 5| Step: 4
Training loss: 1.6786915063858032
Validation loss: 2.0995224880915817

Epoch: 5| Step: 5
Training loss: 2.0668654441833496
Validation loss: 2.056969445238831

Epoch: 5| Step: 6
Training loss: 2.3172898292541504
Validation loss: 2.0661046146064677

Epoch: 5| Step: 7
Training loss: 1.9845383167266846
Validation loss: 2.069932686385288

Epoch: 5| Step: 8
Training loss: 2.656628131866455
Validation loss: 2.0914159577379943

Epoch: 5| Step: 9
Training loss: 2.008625030517578
Validation loss: 2.101378212692917

Epoch: 5| Step: 10
Training loss: 2.231362819671631
Validation loss: 2.0965698072987218

Epoch: 119| Step: 0
Training loss: 2.7038350105285645
Validation loss: 2.0905537361739785

Epoch: 5| Step: 1
Training loss: 1.743157148361206
Validation loss: 2.058283161091548

Epoch: 5| Step: 2
Training loss: 1.7357518672943115
Validation loss: 2.076602446135654

Epoch: 5| Step: 3
Training loss: 2.1148769855499268
Validation loss: 2.090465977627744

Epoch: 5| Step: 4
Training loss: 1.921210527420044
Validation loss: 2.07930023952197

Epoch: 5| Step: 5
Training loss: 1.9214046001434326
Validation loss: 2.089225833133985

Epoch: 5| Step: 6
Training loss: 2.514061450958252
Validation loss: 2.061676823964683

Epoch: 5| Step: 7
Training loss: 2.3246207237243652
Validation loss: 2.1179519981466313

Epoch: 5| Step: 8
Training loss: 3.117185115814209
Validation loss: 2.0952998310007076

Epoch: 5| Step: 9
Training loss: 1.556257963180542
Validation loss: 2.0754525046194754

Epoch: 5| Step: 10
Training loss: 2.352067470550537
Validation loss: 2.0796986113312426

Epoch: 120| Step: 0
Training loss: 2.009917736053467
Validation loss: 2.065782226541991

Epoch: 5| Step: 1
Training loss: 2.176162004470825
Validation loss: 2.100538912639823

Epoch: 5| Step: 2
Training loss: 2.2536840438842773
Validation loss: 2.0751266069309686

Epoch: 5| Step: 3
Training loss: 2.5740208625793457
Validation loss: 2.051739272250924

Epoch: 5| Step: 4
Training loss: 1.5736067295074463
Validation loss: 2.104457591169624

Epoch: 5| Step: 5
Training loss: 1.6433101892471313
Validation loss: 2.0897662780618154

Epoch: 5| Step: 6
Training loss: 2.185913562774658
Validation loss: 2.1098638811419086

Epoch: 5| Step: 7
Training loss: 2.1961448192596436
Validation loss: 2.0879237472370105

Epoch: 5| Step: 8
Training loss: 2.3588738441467285
Validation loss: 2.110657274082143

Epoch: 5| Step: 9
Training loss: 3.009395122528076
Validation loss: 2.0934081897940686

Epoch: 5| Step: 10
Training loss: 2.0782241821289062
Validation loss: 2.061053168389105

Epoch: 121| Step: 0
Training loss: 2.4164605140686035
Validation loss: 2.1018110449596117

Epoch: 5| Step: 1
Training loss: 2.067701816558838
Validation loss: 2.097993102124942

Epoch: 5| Step: 2
Training loss: 2.6245102882385254
Validation loss: 2.0670807566694034

Epoch: 5| Step: 3
Training loss: 1.6470975875854492
Validation loss: 2.0869736902175413

Epoch: 5| Step: 4
Training loss: 2.1057944297790527
Validation loss: 2.100100214763354

Epoch: 5| Step: 5
Training loss: 2.244375705718994
Validation loss: 2.0675069734614384

Epoch: 5| Step: 6
Training loss: 1.889096975326538
Validation loss: 2.0733373754767963

Epoch: 5| Step: 7
Training loss: 2.218158006668091
Validation loss: 2.086734110309232

Epoch: 5| Step: 8
Training loss: 1.8048433065414429
Validation loss: 2.064629106111424

Epoch: 5| Step: 9
Training loss: 2.346081495285034
Validation loss: 2.0467200791963966

Epoch: 5| Step: 10
Training loss: 2.401862859725952
Validation loss: 2.074960832954735

Epoch: 122| Step: 0
Training loss: 1.7784801721572876
Validation loss: 2.0748641183299403

Epoch: 5| Step: 1
Training loss: 2.182649612426758
Validation loss: 2.061505966289069

Epoch: 5| Step: 2
Training loss: 2.3449838161468506
Validation loss: 2.059573560632685

Epoch: 5| Step: 3
Training loss: 2.5807769298553467
Validation loss: 2.087050099526682

Epoch: 5| Step: 4
Training loss: 2.1993050575256348
Validation loss: 2.077771452165419

Epoch: 5| Step: 5
Training loss: 1.7320448160171509
Validation loss: 2.035646959017682

Epoch: 5| Step: 6
Training loss: 2.4754230976104736
Validation loss: 2.09711875454072

Epoch: 5| Step: 7
Training loss: 2.174818754196167
Validation loss: 2.0821054930328042

Epoch: 5| Step: 8
Training loss: 2.2767624855041504
Validation loss: 2.10530508974547

Epoch: 5| Step: 9
Training loss: 1.6989933252334595
Validation loss: 2.094820491729244

Epoch: 5| Step: 10
Training loss: 2.2834861278533936
Validation loss: 2.057896855056927

Epoch: 123| Step: 0
Training loss: 1.8239126205444336
Validation loss: 2.0875512502526723

Epoch: 5| Step: 1
Training loss: 2.122994899749756
Validation loss: 2.0655967035601215

Epoch: 5| Step: 2
Training loss: 2.4987263679504395
Validation loss: 2.0696374600933445

Epoch: 5| Step: 3
Training loss: 1.8557039499282837
Validation loss: 2.0734262440794256

Epoch: 5| Step: 4
Training loss: 2.450047731399536
Validation loss: 2.0545972649769118

Epoch: 5| Step: 5
Training loss: 2.058655023574829
Validation loss: 2.096094972343855

Epoch: 5| Step: 6
Training loss: 1.9296214580535889
Validation loss: 2.078013199631886

Epoch: 5| Step: 7
Training loss: 1.6408946514129639
Validation loss: 2.0658127261746313

Epoch: 5| Step: 8
Training loss: 2.537473201751709
Validation loss: 2.060838435285835

Epoch: 5| Step: 9
Training loss: 2.6485207080841064
Validation loss: 2.054105638175882

Epoch: 5| Step: 10
Training loss: 2.4572434425354004
Validation loss: 2.0544956589257843

Epoch: 124| Step: 0
Training loss: 2.0753204822540283
Validation loss: 2.0708900779806156

Epoch: 5| Step: 1
Training loss: 1.9716078042984009
Validation loss: 2.0695523459424257

Epoch: 5| Step: 2
Training loss: 2.4419760704040527
Validation loss: 2.077844718451141

Epoch: 5| Step: 3
Training loss: 2.6092112064361572
Validation loss: 2.088781069683772

Epoch: 5| Step: 4
Training loss: 1.5534989833831787
Validation loss: 2.0916493631178334

Epoch: 5| Step: 5
Training loss: 2.272223711013794
Validation loss: 2.117053411340201

Epoch: 5| Step: 6
Training loss: 2.0077404975891113
Validation loss: 2.0764639454503215

Epoch: 5| Step: 7
Training loss: 2.0768749713897705
Validation loss: 2.095357629560655

Epoch: 5| Step: 8
Training loss: 2.188796043395996
Validation loss: 2.067640886511854

Epoch: 5| Step: 9
Training loss: 2.425450086593628
Validation loss: 2.073668146646151

Epoch: 5| Step: 10
Training loss: 2.2905421257019043
Validation loss: 2.073294496023527

Epoch: 125| Step: 0
Training loss: 1.8929898738861084
Validation loss: 2.077132296818559

Epoch: 5| Step: 1
Training loss: 1.6208547353744507
Validation loss: 2.077148414427234

Epoch: 5| Step: 2
Training loss: 2.015270948410034
Validation loss: 2.070373532592609

Epoch: 5| Step: 3
Training loss: 3.11323881149292
Validation loss: 2.06898069894442

Epoch: 5| Step: 4
Training loss: 2.4933273792266846
Validation loss: 2.068037509918213

Epoch: 5| Step: 5
Training loss: 1.682710886001587
Validation loss: 2.063298127984488

Epoch: 5| Step: 6
Training loss: 2.2668404579162598
Validation loss: 2.0893333394040345

Epoch: 5| Step: 7
Training loss: 2.1143157482147217
Validation loss: 2.061254157814928

Epoch: 5| Step: 8
Training loss: 2.0975501537323
Validation loss: 2.0521991201626357

Epoch: 5| Step: 9
Training loss: 2.183868885040283
Validation loss: 2.0577379734285417

Epoch: 5| Step: 10
Training loss: 2.3466339111328125
Validation loss: 2.0443957646687827

Epoch: 126| Step: 0
Training loss: 2.1157124042510986
Validation loss: 2.0933102510308705

Epoch: 5| Step: 1
Training loss: 1.7380084991455078
Validation loss: 2.0642466481013964

Epoch: 5| Step: 2
Training loss: 2.3090338706970215
Validation loss: 2.0736234418807493

Epoch: 5| Step: 3
Training loss: 1.9502300024032593
Validation loss: 2.0693971367292505

Epoch: 5| Step: 4
Training loss: 2.7160236835479736
Validation loss: 2.0738599402930147

Epoch: 5| Step: 5
Training loss: 2.0048928260803223
Validation loss: 2.0712642387677263

Epoch: 5| Step: 6
Training loss: 1.615654706954956
Validation loss: 2.1041919992816065

Epoch: 5| Step: 7
Training loss: 1.6794685125350952
Validation loss: 2.037481819429705

Epoch: 5| Step: 8
Training loss: 2.539842128753662
Validation loss: 2.0947522809428554

Epoch: 5| Step: 9
Training loss: 2.618140697479248
Validation loss: 2.084193527057607

Epoch: 5| Step: 10
Training loss: 2.476898431777954
Validation loss: 2.0810770783373105

Epoch: 127| Step: 0
Training loss: 2.7256181240081787
Validation loss: 2.072525078250516

Epoch: 5| Step: 1
Training loss: 2.3073315620422363
Validation loss: 2.0752448112733903

Epoch: 5| Step: 2
Training loss: 1.8924827575683594
Validation loss: 2.1055409703203427

Epoch: 5| Step: 3
Training loss: 3.365736484527588
Validation loss: 2.064184432388634

Epoch: 5| Step: 4
Training loss: 1.8244911432266235
Validation loss: 2.0908941043320524

Epoch: 5| Step: 5
Training loss: 2.3431661128997803
Validation loss: 2.067116191310267

Epoch: 5| Step: 6
Training loss: 1.912396788597107
Validation loss: 2.066325290228731

Epoch: 5| Step: 7
Training loss: 1.9344165325164795
Validation loss: 2.0887316939651326

Epoch: 5| Step: 8
Training loss: 1.9763330221176147
Validation loss: 2.0517338065690893

Epoch: 5| Step: 9
Training loss: 2.0421931743621826
Validation loss: 2.072874331987032

Epoch: 5| Step: 10
Training loss: 1.3016061782836914
Validation loss: 2.0916520831405476

Epoch: 128| Step: 0
Training loss: 2.516343355178833
Validation loss: 2.083154421980663

Epoch: 5| Step: 1
Training loss: 1.8087165355682373
Validation loss: 2.0783089258337535

Epoch: 5| Step: 2
Training loss: 1.928470253944397
Validation loss: 2.0918970697669574

Epoch: 5| Step: 3
Training loss: 2.0547049045562744
Validation loss: 2.0637069056110997

Epoch: 5| Step: 4
Training loss: 2.3451919555664062
Validation loss: 2.0769909620285034

Epoch: 5| Step: 5
Training loss: 2.479560375213623
Validation loss: 2.0975600980943248

Epoch: 5| Step: 6
Training loss: 2.2450833320617676
Validation loss: 2.07006061461664

Epoch: 5| Step: 7
Training loss: 1.8619197607040405
Validation loss: 2.0597356263027398

Epoch: 5| Step: 8
Training loss: 2.0170066356658936
Validation loss: 2.058977432148431

Epoch: 5| Step: 9
Training loss: 2.4131736755371094
Validation loss: 2.0590768283413303

Epoch: 5| Step: 10
Training loss: 2.2229959964752197
Validation loss: 2.056595486979331

Epoch: 129| Step: 0
Training loss: 2.2070367336273193
Validation loss: 2.063012966545679

Epoch: 5| Step: 1
Training loss: 1.6168291568756104
Validation loss: 2.0673889626738844

Epoch: 5| Step: 2
Training loss: 2.979215145111084
Validation loss: 2.089883799194008

Epoch: 5| Step: 3
Training loss: 1.7144196033477783
Validation loss: 2.0797786763919297

Epoch: 5| Step: 4
Training loss: 1.7171434164047241
Validation loss: 2.0601450704759166

Epoch: 5| Step: 5
Training loss: 2.3058087825775146
Validation loss: 2.060187997356538

Epoch: 5| Step: 6
Training loss: 2.243255615234375
Validation loss: 2.050872805298016

Epoch: 5| Step: 7
Training loss: 1.7796987295150757
Validation loss: 2.047317560001086

Epoch: 5| Step: 8
Training loss: 2.6102383136749268
Validation loss: 2.0593554050691667

Epoch: 5| Step: 9
Training loss: 1.9595390558242798
Validation loss: 2.061708568244852

Epoch: 5| Step: 10
Training loss: 2.658296585083008
Validation loss: 2.06661166298774

Epoch: 130| Step: 0
Training loss: 2.0169200897216797
Validation loss: 2.067055397136237

Epoch: 5| Step: 1
Training loss: 2.5076894760131836
Validation loss: 2.060733482401858

Epoch: 5| Step: 2
Training loss: 2.4585490226745605
Validation loss: 2.062815535453058

Epoch: 5| Step: 3
Training loss: 2.660501003265381
Validation loss: 2.0685768486351095

Epoch: 5| Step: 4
Training loss: 1.8988158702850342
Validation loss: 2.0639963585843324

Epoch: 5| Step: 5
Training loss: 1.6183801889419556
Validation loss: 2.087973153719338

Epoch: 5| Step: 6
Training loss: 1.9519535303115845
Validation loss: 2.053691517922186

Epoch: 5| Step: 7
Training loss: 2.915055990219116
Validation loss: 2.0868570368777037

Epoch: 5| Step: 8
Training loss: 2.1477673053741455
Validation loss: 2.0778905807002896

Epoch: 5| Step: 9
Training loss: 1.9882808923721313
Validation loss: 2.0677072642951884

Epoch: 5| Step: 10
Training loss: 1.807239055633545
Validation loss: 2.0623084409262544

Epoch: 131| Step: 0
Training loss: 2.085890769958496
Validation loss: 2.073969748712355

Epoch: 5| Step: 1
Training loss: 2.2255406379699707
Validation loss: 2.062991484518974

Epoch: 5| Step: 2
Training loss: 2.023024082183838
Validation loss: 2.078122967032976

Epoch: 5| Step: 3
Training loss: 1.6844030618667603
Validation loss: 2.07624586038692

Epoch: 5| Step: 4
Training loss: 1.7743829488754272
Validation loss: 2.107624782029019

Epoch: 5| Step: 5
Training loss: 2.274867057800293
Validation loss: 2.0655809897248463

Epoch: 5| Step: 6
Training loss: 2.42210054397583
Validation loss: 2.0431219288097915

Epoch: 5| Step: 7
Training loss: 2.0624289512634277
Validation loss: 2.0285289954113703

Epoch: 5| Step: 8
Training loss: 2.7913177013397217
Validation loss: 2.0979044027225946

Epoch: 5| Step: 9
Training loss: 2.046570062637329
Validation loss: 2.0875407752170356

Epoch: 5| Step: 10
Training loss: 2.445690155029297
Validation loss: 2.050338637444281

Epoch: 132| Step: 0
Training loss: 2.306623935699463
Validation loss: 2.0669791108818463

Epoch: 5| Step: 1
Training loss: 2.185352325439453
Validation loss: 2.0896430579564904

Epoch: 5| Step: 2
Training loss: 2.6041383743286133
Validation loss: 2.0410384798562653

Epoch: 5| Step: 3
Training loss: 2.029850482940674
Validation loss: 2.092204422079107

Epoch: 5| Step: 4
Training loss: 1.6474599838256836
Validation loss: 2.0684657071226384

Epoch: 5| Step: 5
Training loss: 1.6198276281356812
Validation loss: 2.0712114046978694

Epoch: 5| Step: 6
Training loss: 2.291952610015869
Validation loss: 2.0927779853984876

Epoch: 5| Step: 7
Training loss: 2.456191301345825
Validation loss: 2.069153365268502

Epoch: 5| Step: 8
Training loss: 2.91467547416687
Validation loss: 2.0636201930302445

Epoch: 5| Step: 9
Training loss: 1.5598397254943848
Validation loss: 2.087289616625796

Epoch: 5| Step: 10
Training loss: 1.793448805809021
Validation loss: 2.0548473429936234

Epoch: 133| Step: 0
Training loss: 2.5971827507019043
Validation loss: 2.0776734993021977

Epoch: 5| Step: 1
Training loss: 2.211013078689575
Validation loss: 2.089174747467041

Epoch: 5| Step: 2
Training loss: 1.8655030727386475
Validation loss: 2.0425998677489576

Epoch: 5| Step: 3
Training loss: 2.314390182495117
Validation loss: 2.110802196687268

Epoch: 5| Step: 4
Training loss: 1.7406193017959595
Validation loss: 2.0800485021324566

Epoch: 5| Step: 5
Training loss: 2.1794276237487793
Validation loss: 2.0861825994265977

Epoch: 5| Step: 6
Training loss: 2.1316421031951904
Validation loss: 2.048684493187935

Epoch: 5| Step: 7
Training loss: 2.05299711227417
Validation loss: 2.088537803260229

Epoch: 5| Step: 8
Training loss: 2.238884687423706
Validation loss: 2.0940322286339215

Epoch: 5| Step: 9
Training loss: 1.9649269580841064
Validation loss: 2.053757877760036

Epoch: 5| Step: 10
Training loss: 2.37172532081604
Validation loss: 2.056104037069505

Epoch: 134| Step: 0
Training loss: 1.9906930923461914
Validation loss: 2.033660469516631

Epoch: 5| Step: 1
Training loss: 2.4716758728027344
Validation loss: 2.0687769587321947

Epoch: 5| Step: 2
Training loss: 2.681734800338745
Validation loss: 2.0774851819520355

Epoch: 5| Step: 3
Training loss: 1.9004638195037842
Validation loss: 2.057077246327554

Epoch: 5| Step: 4
Training loss: 1.8893108367919922
Validation loss: 2.076063786783526

Epoch: 5| Step: 5
Training loss: 1.9925954341888428
Validation loss: 2.020153248181907

Epoch: 5| Step: 6
Training loss: 2.0462117195129395
Validation loss: 2.039799920974239

Epoch: 5| Step: 7
Training loss: 2.067809581756592
Validation loss: 2.0843368243145686

Epoch: 5| Step: 8
Training loss: 2.035268545150757
Validation loss: 2.0700081984202066

Epoch: 5| Step: 9
Training loss: 2.142253875732422
Validation loss: 2.066055546524704

Epoch: 5| Step: 10
Training loss: 2.441709280014038
Validation loss: 2.053610537641792

Epoch: 135| Step: 0
Training loss: 3.052680492401123
Validation loss: 2.064716980021487

Epoch: 5| Step: 1
Training loss: 1.8794244527816772
Validation loss: 2.0861310728134645

Epoch: 5| Step: 2
Training loss: 1.5863841772079468
Validation loss: 2.0800511426823114

Epoch: 5| Step: 3
Training loss: 2.601959466934204
Validation loss: 2.05611708728216

Epoch: 5| Step: 4
Training loss: 1.891608476638794
Validation loss: 2.0624986463977444

Epoch: 5| Step: 5
Training loss: 1.9276317358016968
Validation loss: 2.0775688027822845

Epoch: 5| Step: 6
Training loss: 2.4510021209716797
Validation loss: 2.0707530693341325

Epoch: 5| Step: 7
Training loss: 2.296506643295288
Validation loss: 2.0732272645478607

Epoch: 5| Step: 8
Training loss: 2.006824016571045
Validation loss: 2.0473656103175175

Epoch: 5| Step: 9
Training loss: 2.138540506362915
Validation loss: 2.0747551687302126

Epoch: 5| Step: 10
Training loss: 1.933789610862732
Validation loss: 2.0599580118733067

Epoch: 136| Step: 0
Training loss: 2.655078172683716
Validation loss: 2.049175270142094

Epoch: 5| Step: 1
Training loss: 2.8732528686523438
Validation loss: 2.04348942413125

Epoch: 5| Step: 2
Training loss: 1.7807285785675049
Validation loss: 2.0684015007429224

Epoch: 5| Step: 3
Training loss: 2.1148972511291504
Validation loss: 2.068757974973289

Epoch: 5| Step: 4
Training loss: 1.896664023399353
Validation loss: 2.0775867021212013

Epoch: 5| Step: 5
Training loss: 1.943352460861206
Validation loss: 2.05319223865386

Epoch: 5| Step: 6
Training loss: 2.1631999015808105
Validation loss: 2.073685887039349

Epoch: 5| Step: 7
Training loss: 2.060142755508423
Validation loss: 2.0722085455412507

Epoch: 5| Step: 8
Training loss: 2.4129700660705566
Validation loss: 2.0566648462767243

Epoch: 5| Step: 9
Training loss: 1.8512481451034546
Validation loss: 2.0442271924787954

Epoch: 5| Step: 10
Training loss: 1.9643433094024658
Validation loss: 2.066598364101943

Epoch: 137| Step: 0
Training loss: 2.1760478019714355
Validation loss: 2.0661933755361908

Epoch: 5| Step: 1
Training loss: 2.289207696914673
Validation loss: 2.0509260495503745

Epoch: 5| Step: 2
Training loss: 2.601968288421631
Validation loss: 2.050446588505981

Epoch: 5| Step: 3
Training loss: 2.0690560340881348
Validation loss: 2.078456663316296

Epoch: 5| Step: 4
Training loss: 1.796051025390625
Validation loss: 2.0718396555992866

Epoch: 5| Step: 5
Training loss: 2.1992905139923096
Validation loss: 2.0603713450893277

Epoch: 5| Step: 6
Training loss: 1.8681846857070923
Validation loss: 2.0635192419893

Epoch: 5| Step: 7
Training loss: 2.889200210571289
Validation loss: 2.046864360891363

Epoch: 5| Step: 8
Training loss: 1.7149312496185303
Validation loss: 2.0931162500894196

Epoch: 5| Step: 9
Training loss: 2.2790074348449707
Validation loss: 2.049694002315562

Epoch: 5| Step: 10
Training loss: 1.6828217506408691
Validation loss: 2.0830230866709063

Epoch: 138| Step: 0
Training loss: 3.1166224479675293
Validation loss: 2.0672080542451594

Epoch: 5| Step: 1
Training loss: 2.601720094680786
Validation loss: 2.086743900852819

Epoch: 5| Step: 2
Training loss: 2.361124277114868
Validation loss: 2.0604304985333513

Epoch: 5| Step: 3
Training loss: 1.9509891271591187
Validation loss: 2.0801630071414414

Epoch: 5| Step: 4
Training loss: 1.3383195400238037
Validation loss: 2.0691162540066625

Epoch: 5| Step: 5
Training loss: 1.4808820486068726
Validation loss: 2.076826548063627

Epoch: 5| Step: 6
Training loss: 2.1576647758483887
Validation loss: 2.0683014162125124

Epoch: 5| Step: 7
Training loss: 2.0155272483825684
Validation loss: 2.0472115996063396

Epoch: 5| Step: 8
Training loss: 2.0052547454833984
Validation loss: 2.060704938827022

Epoch: 5| Step: 9
Training loss: 2.8209517002105713
Validation loss: 2.0842242407542404

Epoch: 5| Step: 10
Training loss: 1.5211635828018188
Validation loss: 2.0662225305393176

Epoch: 139| Step: 0
Training loss: 1.843442678451538
Validation loss: 2.0843566181839153

Epoch: 5| Step: 1
Training loss: 1.7947165966033936
Validation loss: 2.088478511379611

Epoch: 5| Step: 2
Training loss: 2.1323018074035645
Validation loss: 2.0821176562257993

Epoch: 5| Step: 3
Training loss: 2.3395676612854004
Validation loss: 2.0813561280568442

Epoch: 5| Step: 4
Training loss: 1.4101815223693848
Validation loss: 2.045328704259729

Epoch: 5| Step: 5
Training loss: 2.976041078567505
Validation loss: 2.0427955299295406

Epoch: 5| Step: 6
Training loss: 1.7434660196304321
Validation loss: 2.0673412533216577

Epoch: 5| Step: 7
Training loss: 2.1101632118225098
Validation loss: 2.069209010370316

Epoch: 5| Step: 8
Training loss: 2.2707302570343018
Validation loss: 2.039084583200434

Epoch: 5| Step: 9
Training loss: 2.497680187225342
Validation loss: 2.081509910604005

Epoch: 5| Step: 10
Training loss: 2.535102367401123
Validation loss: 2.055203304495863

Epoch: 140| Step: 0
Training loss: 2.979205846786499
Validation loss: 2.0795261693257157

Epoch: 5| Step: 1
Training loss: 1.8111178874969482
Validation loss: 2.0791957724478936

Epoch: 5| Step: 2
Training loss: 2.187126398086548
Validation loss: 2.049179966731738

Epoch: 5| Step: 3
Training loss: 2.4808425903320312
Validation loss: 2.066214443534933

Epoch: 5| Step: 4
Training loss: 2.1969106197357178
Validation loss: 2.0704648007628736

Epoch: 5| Step: 5
Training loss: 1.9186493158340454
Validation loss: 2.077661386100195

Epoch: 5| Step: 6
Training loss: 1.8619906902313232
Validation loss: 2.051542793550799

Epoch: 5| Step: 7
Training loss: 1.9058749675750732
Validation loss: 2.0782703661149546

Epoch: 5| Step: 8
Training loss: 2.6898391246795654
Validation loss: 2.06370347802357

Epoch: 5| Step: 9
Training loss: 1.9419291019439697
Validation loss: 2.0571106454377532

Epoch: 5| Step: 10
Training loss: 1.6034225225448608
Validation loss: 2.039032010621922

Epoch: 141| Step: 0
Training loss: 1.8171520233154297
Validation loss: 2.0920650728287233

Epoch: 5| Step: 1
Training loss: 1.767538070678711
Validation loss: 2.0911047997013217

Epoch: 5| Step: 2
Training loss: 2.9073102474212646
Validation loss: 2.0464281548735914

Epoch: 5| Step: 3
Training loss: 2.219177484512329
Validation loss: 2.0696299537535636

Epoch: 5| Step: 4
Training loss: 2.3325912952423096
Validation loss: 2.0649860930699173

Epoch: 5| Step: 5
Training loss: 1.8272764682769775
Validation loss: 2.05409748067138

Epoch: 5| Step: 6
Training loss: 2.616323709487915
Validation loss: 2.0552395646290114

Epoch: 5| Step: 7
Training loss: 2.104398012161255
Validation loss: 2.0391704087616294

Epoch: 5| Step: 8
Training loss: 2.10788893699646
Validation loss: 2.048731157856603

Epoch: 5| Step: 9
Training loss: 1.8727827072143555
Validation loss: 2.0407021609685754

Epoch: 5| Step: 10
Training loss: 2.044959545135498
Validation loss: 2.0448953413194224

Epoch: 142| Step: 0
Training loss: 2.479374647140503
Validation loss: 2.0744710045476116

Epoch: 5| Step: 1
Training loss: 2.0440773963928223
Validation loss: 2.077698766544301

Epoch: 5| Step: 2
Training loss: 1.8118760585784912
Validation loss: 2.0816328615270634

Epoch: 5| Step: 3
Training loss: 2.4915249347686768
Validation loss: 2.055102176563714

Epoch: 5| Step: 4
Training loss: 2.43489408493042
Validation loss: 2.0539216905511837

Epoch: 5| Step: 5
Training loss: 2.257444381713867
Validation loss: 2.061740166397505

Epoch: 5| Step: 6
Training loss: 1.908272385597229
Validation loss: 2.0585217937346427

Epoch: 5| Step: 7
Training loss: 2.136936902999878
Validation loss: 2.1035878812113116

Epoch: 5| Step: 8
Training loss: 1.8391344547271729
Validation loss: 2.081566418370893

Epoch: 5| Step: 9
Training loss: 2.2959234714508057
Validation loss: 2.0631134304949033

Epoch: 5| Step: 10
Training loss: 1.5922030210494995
Validation loss: 2.0622231934660222

Epoch: 143| Step: 0
Training loss: 1.7122199535369873
Validation loss: 2.056067811545505

Epoch: 5| Step: 1
Training loss: 1.5679305791854858
Validation loss: 2.0792828541930004

Epoch: 5| Step: 2
Training loss: 2.792215585708618
Validation loss: 2.0768732499050837

Epoch: 5| Step: 3
Training loss: 2.4109950065612793
Validation loss: 2.0479140076585995

Epoch: 5| Step: 4
Training loss: 1.9971277713775635
Validation loss: 2.0489470304981356

Epoch: 5| Step: 5
Training loss: 2.2968924045562744
Validation loss: 2.0552332016729538

Epoch: 5| Step: 6
Training loss: 2.7260615825653076
Validation loss: 2.0406819056439143

Epoch: 5| Step: 7
Training loss: 2.4931418895721436
Validation loss: 2.049683799025833

Epoch: 5| Step: 8
Training loss: 1.8371856212615967
Validation loss: 2.076003974483859

Epoch: 5| Step: 9
Training loss: 2.0319924354553223
Validation loss: 2.064836581548055

Epoch: 5| Step: 10
Training loss: 1.6559115648269653
Validation loss: 2.053884742080524

Epoch: 144| Step: 0
Training loss: 1.5719060897827148
Validation loss: 2.043443182463287

Epoch: 5| Step: 1
Training loss: 1.724260687828064
Validation loss: 2.075904761591265

Epoch: 5| Step: 2
Training loss: 2.389476776123047
Validation loss: 2.075902355614529

Epoch: 5| Step: 3
Training loss: 2.0958263874053955
Validation loss: 2.0573963580592984

Epoch: 5| Step: 4
Training loss: 2.157066822052002
Validation loss: 2.05800401267185

Epoch: 5| Step: 5
Training loss: 2.125863552093506
Validation loss: 2.0550683595800914

Epoch: 5| Step: 6
Training loss: 1.7733421325683594
Validation loss: 2.085582992082001

Epoch: 5| Step: 7
Training loss: 2.308746814727783
Validation loss: 2.0436896047284527

Epoch: 5| Step: 8
Training loss: 2.066706418991089
Validation loss: 2.060732387727307

Epoch: 5| Step: 9
Training loss: 2.1671395301818848
Validation loss: 2.0783261406806206

Epoch: 5| Step: 10
Training loss: 3.040067195892334
Validation loss: 2.0783248614239436

Epoch: 145| Step: 0
Training loss: 2.1591951847076416
Validation loss: 2.064411852949409

Epoch: 5| Step: 1
Training loss: 2.254488468170166
Validation loss: 2.078497334193158

Epoch: 5| Step: 2
Training loss: 2.2958908081054688
Validation loss: 2.0698149960528136

Epoch: 5| Step: 3
Training loss: 2.1629137992858887
Validation loss: 2.0546765788908927

Epoch: 5| Step: 4
Training loss: 2.3483269214630127
Validation loss: 2.0939868047673214

Epoch: 5| Step: 5
Training loss: 2.1900157928466797
Validation loss: 2.0700353883927867

Epoch: 5| Step: 6
Training loss: 2.4642577171325684
Validation loss: 2.070031476277177

Epoch: 5| Step: 7
Training loss: 2.2419049739837646
Validation loss: 2.070781530872468

Epoch: 5| Step: 8
Training loss: 2.241992235183716
Validation loss: 2.0588045556058168

Epoch: 5| Step: 9
Training loss: 1.3812129497528076
Validation loss: 2.05611740901906

Epoch: 5| Step: 10
Training loss: 1.5819989442825317
Validation loss: 2.0541858275731406

Epoch: 146| Step: 0
Training loss: 2.6024646759033203
Validation loss: 2.0699766630767495

Epoch: 5| Step: 1
Training loss: 1.8848062753677368
Validation loss: 2.0546185713942333

Epoch: 5| Step: 2
Training loss: 2.0025382041931152
Validation loss: 2.0674620828320904

Epoch: 5| Step: 3
Training loss: 2.2097058296203613
Validation loss: 2.0710890972486107

Epoch: 5| Step: 4
Training loss: 1.8054533004760742
Validation loss: 2.084827458986672

Epoch: 5| Step: 5
Training loss: 1.83267343044281
Validation loss: 2.0660362807653283

Epoch: 5| Step: 6
Training loss: 2.460118055343628
Validation loss: 2.034309643571095

Epoch: 5| Step: 7
Training loss: 2.472149610519409
Validation loss: 2.0656310255809496

Epoch: 5| Step: 8
Training loss: 1.3630359172821045
Validation loss: 2.0367910477422897

Epoch: 5| Step: 9
Training loss: 2.1606340408325195
Validation loss: 2.065828154163976

Epoch: 5| Step: 10
Training loss: 2.6285839080810547
Validation loss: 2.0590500472694315

Epoch: 147| Step: 0
Training loss: 1.563664197921753
Validation loss: 2.039638788469376

Epoch: 5| Step: 1
Training loss: 2.0591018199920654
Validation loss: 2.0460217024690364

Epoch: 5| Step: 2
Training loss: 2.3313968181610107
Validation loss: 2.0529388484134468

Epoch: 5| Step: 3
Training loss: 1.9953947067260742
Validation loss: 2.0523830998328423

Epoch: 5| Step: 4
Training loss: 1.8892593383789062
Validation loss: 2.0479671724380983

Epoch: 5| Step: 5
Training loss: 2.5948777198791504
Validation loss: 2.0182592330440396

Epoch: 5| Step: 6
Training loss: 2.9135468006134033
Validation loss: 2.076205256164715

Epoch: 5| Step: 7
Training loss: 2.2595057487487793
Validation loss: 2.0656182407051005

Epoch: 5| Step: 8
Training loss: 1.7937654256820679
Validation loss: 2.0954417208189606

Epoch: 5| Step: 9
Training loss: 1.645244836807251
Validation loss: 2.051496910792525

Epoch: 5| Step: 10
Training loss: 2.289107322692871
Validation loss: 2.06966039698611

Epoch: 148| Step: 0
Training loss: 2.134624481201172
Validation loss: 2.0777238799679663

Epoch: 5| Step: 1
Training loss: 2.8527538776397705
Validation loss: 2.070263580609393

Epoch: 5| Step: 2
Training loss: 1.8580900430679321
Validation loss: 2.0716651588357906

Epoch: 5| Step: 3
Training loss: 1.7325588464736938
Validation loss: 2.0651739810102727

Epoch: 5| Step: 4
Training loss: 1.840606451034546
Validation loss: 2.0609009035172

Epoch: 5| Step: 5
Training loss: 2.147286891937256
Validation loss: 2.05980900667047

Epoch: 5| Step: 6
Training loss: 2.5791943073272705
Validation loss: 2.068423787752787

Epoch: 5| Step: 7
Training loss: 2.4613842964172363
Validation loss: 2.08648205700741

Epoch: 5| Step: 8
Training loss: 2.094480037689209
Validation loss: 2.0538505149143997

Epoch: 5| Step: 9
Training loss: 1.7169809341430664
Validation loss: 2.0365973185467463

Epoch: 5| Step: 10
Training loss: 1.9027550220489502
Validation loss: 2.0586985516291794

Epoch: 149| Step: 0
Training loss: 2.364382028579712
Validation loss: 2.0694011411359234

Epoch: 5| Step: 1
Training loss: 2.0707857608795166
Validation loss: 2.0619190392955655

Epoch: 5| Step: 2
Training loss: 2.3607020378112793
Validation loss: 2.051944250701576

Epoch: 5| Step: 3
Training loss: 1.8310273885726929
Validation loss: 2.064116880457888

Epoch: 5| Step: 4
Training loss: 1.5227737426757812
Validation loss: 2.0438642258285196

Epoch: 5| Step: 5
Training loss: 1.52382493019104
Validation loss: 2.0506371118689097

Epoch: 5| Step: 6
Training loss: 3.026747226715088
Validation loss: 2.031875953879408

Epoch: 5| Step: 7
Training loss: 1.380666971206665
Validation loss: 2.0563562544443275

Epoch: 5| Step: 8
Training loss: 2.517824649810791
Validation loss: 2.0583302308154363

Epoch: 5| Step: 9
Training loss: 2.8665239810943604
Validation loss: 2.0648268448409213

Epoch: 5| Step: 10
Training loss: 1.624230146408081
Validation loss: 2.069492801543205

Epoch: 150| Step: 0
Training loss: 2.146183490753174
Validation loss: 2.0524432556603545

Epoch: 5| Step: 1
Training loss: 2.0052666664123535
Validation loss: 2.061522512025731

Epoch: 5| Step: 2
Training loss: 2.5645859241485596
Validation loss: 2.060092833734328

Epoch: 5| Step: 3
Training loss: 1.698177695274353
Validation loss: 2.0493162793497883

Epoch: 5| Step: 4
Training loss: 2.1858842372894287
Validation loss: 2.0845992962519326

Epoch: 5| Step: 5
Training loss: 1.3607127666473389
Validation loss: 2.05256744610366

Epoch: 5| Step: 6
Training loss: 2.12825345993042
Validation loss: 2.0808702079198693

Epoch: 5| Step: 7
Training loss: 2.4811816215515137
Validation loss: 2.0479888480196715

Epoch: 5| Step: 8
Training loss: 1.5065650939941406
Validation loss: 2.0857146119558685

Epoch: 5| Step: 9
Training loss: 2.5058045387268066
Validation loss: 2.0534459262765865

Epoch: 5| Step: 10
Training loss: 2.5211877822875977
Validation loss: 2.0421109840434086

Epoch: 151| Step: 0
Training loss: 2.3432440757751465
Validation loss: 2.037335858550123

Epoch: 5| Step: 1
Training loss: 2.132892608642578
Validation loss: 2.053267689161403

Epoch: 5| Step: 2
Training loss: 2.4034364223480225
Validation loss: 2.060238265222119

Epoch: 5| Step: 3
Training loss: 1.8375571966171265
Validation loss: 2.0416069505035237

Epoch: 5| Step: 4
Training loss: 2.2015976905822754
Validation loss: 2.076682444541685

Epoch: 5| Step: 5
Training loss: 2.0513477325439453
Validation loss: 2.046182422227757

Epoch: 5| Step: 6
Training loss: 2.324850082397461
Validation loss: 2.0574233301224245

Epoch: 5| Step: 7
Training loss: 1.807543396949768
Validation loss: 2.0530888290815454

Epoch: 5| Step: 8
Training loss: 1.7021223306655884
Validation loss: 2.0432098245108

Epoch: 5| Step: 9
Training loss: 2.0743823051452637
Validation loss: 2.0554914243759645

Epoch: 5| Step: 10
Training loss: 2.468381643295288
Validation loss: 2.0694533560865667

Epoch: 152| Step: 0
Training loss: 2.701756715774536
Validation loss: 2.0946721902457615

Epoch: 5| Step: 1
Training loss: 1.4821139574050903
Validation loss: 2.0691888024730067

Epoch: 5| Step: 2
Training loss: 1.947988510131836
Validation loss: 2.048634780350552

Epoch: 5| Step: 3
Training loss: 2.2536396980285645
Validation loss: 2.0545531524124967

Epoch: 5| Step: 4
Training loss: 2.030792236328125
Validation loss: 2.056936115346929

Epoch: 5| Step: 5
Training loss: 1.4043693542480469
Validation loss: 2.053573787853282

Epoch: 5| Step: 6
Training loss: 2.1366569995880127
Validation loss: 2.0421123402093047

Epoch: 5| Step: 7
Training loss: 2.352656364440918
Validation loss: 2.0549613532199653

Epoch: 5| Step: 8
Training loss: 2.5066511631011963
Validation loss: 2.073190666014148

Epoch: 5| Step: 9
Training loss: 2.0779106616973877
Validation loss: 2.0316294418868197

Epoch: 5| Step: 10
Training loss: 2.28334641456604
Validation loss: 2.051546762066503

Epoch: 153| Step: 0
Training loss: 2.4660773277282715
Validation loss: 2.0368136885345622

Epoch: 5| Step: 1
Training loss: 2.2267355918884277
Validation loss: 2.0714995373961744

Epoch: 5| Step: 2
Training loss: 1.6266342401504517
Validation loss: 2.0856801181711178

Epoch: 5| Step: 3
Training loss: 2.781859874725342
Validation loss: 2.0622194736234603

Epoch: 5| Step: 4
Training loss: 1.944920539855957
Validation loss: 2.0822191699858634

Epoch: 5| Step: 5
Training loss: 1.9202215671539307
Validation loss: 2.0611371558199645

Epoch: 5| Step: 6
Training loss: 1.6254043579101562
Validation loss: 2.071052623051469

Epoch: 5| Step: 7
Training loss: 3.044450044631958
Validation loss: 2.0250203045465613

Epoch: 5| Step: 8
Training loss: 1.429023027420044
Validation loss: 2.058780021564935

Epoch: 5| Step: 9
Training loss: 2.481058359146118
Validation loss: 2.0450417123815066

Epoch: 5| Step: 10
Training loss: 1.4648447036743164
Validation loss: 2.079236835561773

Epoch: 154| Step: 0
Training loss: 2.8141958713531494
Validation loss: 2.055727740769745

Epoch: 5| Step: 1
Training loss: 2.3534352779388428
Validation loss: 2.0718313417127057

Epoch: 5| Step: 2
Training loss: 2.013598918914795
Validation loss: 2.080677399071314

Epoch: 5| Step: 3
Training loss: 1.6286672353744507
Validation loss: 2.0808730048518025

Epoch: 5| Step: 4
Training loss: 2.0816287994384766
Validation loss: 2.065231168141929

Epoch: 5| Step: 5
Training loss: 1.5829211473464966
Validation loss: 2.087043082842263

Epoch: 5| Step: 6
Training loss: 2.201903820037842
Validation loss: 2.109473879619311

Epoch: 5| Step: 7
Training loss: 1.9714996814727783
Validation loss: 2.067456761995951

Epoch: 5| Step: 8
Training loss: 2.41607666015625
Validation loss: 2.101245900636078

Epoch: 5| Step: 9
Training loss: 1.9328854084014893
Validation loss: 2.068890595948824

Epoch: 5| Step: 10
Training loss: 2.4485509395599365
Validation loss: 2.06240068199814

Epoch: 155| Step: 0
Training loss: 1.8211898803710938
Validation loss: 2.073829430405812

Epoch: 5| Step: 1
Training loss: 2.6250462532043457
Validation loss: 2.04224483941191

Epoch: 5| Step: 2
Training loss: 1.9677823781967163
Validation loss: 2.060781930082588

Epoch: 5| Step: 3
Training loss: 2.0201680660247803
Validation loss: 2.0825091087689964

Epoch: 5| Step: 4
Training loss: 1.987969160079956
Validation loss: 2.0528901725687008

Epoch: 5| Step: 5
Training loss: 2.3820960521698
Validation loss: 2.0517218318036807

Epoch: 5| Step: 6
Training loss: 1.7298024892807007
Validation loss: 2.058605496601392

Epoch: 5| Step: 7
Training loss: 1.9782383441925049
Validation loss: 2.0887261795741257

Epoch: 5| Step: 8
Training loss: 2.5375781059265137
Validation loss: 2.028828274819159

Epoch: 5| Step: 9
Training loss: 1.5889298915863037
Validation loss: 2.0606126836551133

Epoch: 5| Step: 10
Training loss: 2.2789556980133057
Validation loss: 2.047681898199102

Epoch: 156| Step: 0
Training loss: 2.3215222358703613
Validation loss: 2.0346757006901566

Epoch: 5| Step: 1
Training loss: 1.9339253902435303
Validation loss: 2.0699172455777406

Epoch: 5| Step: 2
Training loss: 1.7328379154205322
Validation loss: 2.0901386660914265

Epoch: 5| Step: 3
Training loss: 2.440655469894409
Validation loss: 2.0371573971163843

Epoch: 5| Step: 4
Training loss: 2.0239734649658203
Validation loss: 2.077696377231229

Epoch: 5| Step: 5
Training loss: 1.8665657043457031
Validation loss: 2.03189843444414

Epoch: 5| Step: 6
Training loss: 1.5374486446380615
Validation loss: 2.0554908962659937

Epoch: 5| Step: 7
Training loss: 2.128425121307373
Validation loss: 2.0586039981534405

Epoch: 5| Step: 8
Training loss: 2.561870574951172
Validation loss: 2.044145499506304

Epoch: 5| Step: 9
Training loss: 2.081003189086914
Validation loss: 2.036295795312492

Epoch: 5| Step: 10
Training loss: 2.4251630306243896
Validation loss: 2.062492360350906

Epoch: 157| Step: 0
Training loss: 2.8083901405334473
Validation loss: 2.0315834001828263

Epoch: 5| Step: 1
Training loss: 1.262250304222107
Validation loss: 2.061914766988447

Epoch: 5| Step: 2
Training loss: 2.3217837810516357
Validation loss: 2.026037960924128

Epoch: 5| Step: 3
Training loss: 1.8339035511016846
Validation loss: 2.0638193776530604

Epoch: 5| Step: 4
Training loss: 2.2915477752685547
Validation loss: 2.043695101173975

Epoch: 5| Step: 5
Training loss: 2.599085569381714
Validation loss: 2.0529913940737323

Epoch: 5| Step: 6
Training loss: 1.8708984851837158
Validation loss: 2.0902691259179065

Epoch: 5| Step: 7
Training loss: 2.303938865661621
Validation loss: 2.047545576608309

Epoch: 5| Step: 8
Training loss: 2.563570737838745
Validation loss: 2.083636688929732

Epoch: 5| Step: 9
Training loss: 1.88019597530365
Validation loss: 2.0549334787553355

Epoch: 5| Step: 10
Training loss: 1.3769069910049438
Validation loss: 2.0629298353707917

Epoch: 158| Step: 0
Training loss: 2.181305408477783
Validation loss: 2.0504364582800094

Epoch: 5| Step: 1
Training loss: 1.7256324291229248
Validation loss: 2.065560645954583

Epoch: 5| Step: 2
Training loss: 2.099055528640747
Validation loss: 2.0627952211646625

Epoch: 5| Step: 3
Training loss: 1.7362842559814453
Validation loss: 2.0536564114273235

Epoch: 5| Step: 4
Training loss: 2.2812323570251465
Validation loss: 2.0488868580069592

Epoch: 5| Step: 5
Training loss: 2.820909023284912
Validation loss: 2.078518139418735

Epoch: 5| Step: 6
Training loss: 2.1631274223327637
Validation loss: 2.0684204511745

Epoch: 5| Step: 7
Training loss: 2.5853545665740967
Validation loss: 2.086566919921547

Epoch: 5| Step: 8
Training loss: 1.680161714553833
Validation loss: 2.057479368743076

Epoch: 5| Step: 9
Training loss: 2.0758395195007324
Validation loss: 2.0497241020202637

Epoch: 5| Step: 10
Training loss: 1.8542042970657349
Validation loss: 2.063225266753986

Epoch: 159| Step: 0
Training loss: 2.4079794883728027
Validation loss: 2.04672900835673

Epoch: 5| Step: 1
Training loss: 2.176375150680542
Validation loss: 2.0672532768659693

Epoch: 5| Step: 2
Training loss: 2.2050929069519043
Validation loss: 2.0470387935638428

Epoch: 5| Step: 3
Training loss: 2.0086047649383545
Validation loss: 2.0496048619670253

Epoch: 5| Step: 4
Training loss: 2.2277743816375732
Validation loss: 2.026504057709889

Epoch: 5| Step: 5
Training loss: 2.2162086963653564
Validation loss: 2.0573298315848074

Epoch: 5| Step: 6
Training loss: 2.328951597213745
Validation loss: 2.0386550349573933

Epoch: 5| Step: 7
Training loss: 2.334412097930908
Validation loss: 2.068348810236941

Epoch: 5| Step: 8
Training loss: 1.7425076961517334
Validation loss: 2.0799719710503854

Epoch: 5| Step: 9
Training loss: 1.7043863534927368
Validation loss: 2.0416613496759886

Epoch: 5| Step: 10
Training loss: 1.834363579750061
Validation loss: 2.045613319643082

Epoch: 160| Step: 0
Training loss: 2.050858974456787
Validation loss: 2.0443153894075783

Epoch: 5| Step: 1
Training loss: 1.8993602991104126
Validation loss: 2.056113043139058

Epoch: 5| Step: 2
Training loss: 1.4703437089920044
Validation loss: 2.055910292492118

Epoch: 5| Step: 3
Training loss: 2.03981351852417
Validation loss: 2.0758417947317964

Epoch: 5| Step: 4
Training loss: 2.4076404571533203
Validation loss: 2.056955001687491

Epoch: 5| Step: 5
Training loss: 1.9423401355743408
Validation loss: 2.024838307852386

Epoch: 5| Step: 6
Training loss: 2.4691779613494873
Validation loss: 2.0348172572351273

Epoch: 5| Step: 7
Training loss: 2.170222759246826
Validation loss: 2.045949766712804

Epoch: 5| Step: 8
Training loss: 2.3861474990844727
Validation loss: 2.0730208043129212

Epoch: 5| Step: 9
Training loss: 2.2287824153900146
Validation loss: 2.043355805899507

Epoch: 5| Step: 10
Training loss: 2.022791624069214
Validation loss: 2.0601691046068744

Epoch: 161| Step: 0
Training loss: 1.9639489650726318
Validation loss: 2.0763311975745746

Epoch: 5| Step: 1
Training loss: 2.2128822803497314
Validation loss: 2.0546385498457056

Epoch: 5| Step: 2
Training loss: 2.2709903717041016
Validation loss: 2.0799003301128263

Epoch: 5| Step: 3
Training loss: 2.3139634132385254
Validation loss: 2.0528116482560352

Epoch: 5| Step: 4
Training loss: 1.94939386844635
Validation loss: 2.0927674975446475

Epoch: 5| Step: 5
Training loss: 2.002821445465088
Validation loss: 2.0495643795177503

Epoch: 5| Step: 6
Training loss: 1.921657919883728
Validation loss: 2.0722710086453344

Epoch: 5| Step: 7
Training loss: 1.6197093725204468
Validation loss: 2.060390358330101

Epoch: 5| Step: 8
Training loss: 2.4713995456695557
Validation loss: 2.064995291412518

Epoch: 5| Step: 9
Training loss: 2.5590624809265137
Validation loss: 2.0850816183192755

Epoch: 5| Step: 10
Training loss: 1.4806828498840332
Validation loss: 2.0733548928332586

Epoch: 162| Step: 0
Training loss: 1.4604836702346802
Validation loss: 2.0684610592421664

Epoch: 5| Step: 1
Training loss: 3.0489306449890137
Validation loss: 2.0457532482762493

Epoch: 5| Step: 2
Training loss: 2.0302131175994873
Validation loss: 2.0859748445531374

Epoch: 5| Step: 3
Training loss: 1.4768576622009277
Validation loss: 2.068398460265129

Epoch: 5| Step: 4
Training loss: 2.147834300994873
Validation loss: 2.0866821504408315

Epoch: 5| Step: 5
Training loss: 2.673576831817627
Validation loss: 2.090016030496167

Epoch: 5| Step: 6
Training loss: 2.4860658645629883
Validation loss: 2.0786981685187227

Epoch: 5| Step: 7
Training loss: 1.6205081939697266
Validation loss: 2.059253079916841

Epoch: 5| Step: 8
Training loss: 1.8251346349716187
Validation loss: 2.0722278125824465

Epoch: 5| Step: 9
Training loss: 2.535128116607666
Validation loss: 2.0599139505817043

Epoch: 5| Step: 10
Training loss: 1.6790064573287964
Validation loss: 2.0670956270669096

Epoch: 163| Step: 0
Training loss: 1.621899962425232
Validation loss: 2.059300971287553

Epoch: 5| Step: 1
Training loss: 1.930759072303772
Validation loss: 2.076283147258143

Epoch: 5| Step: 2
Training loss: 1.6897213459014893
Validation loss: 2.0815237491361556

Epoch: 5| Step: 3
Training loss: 3.1510825157165527
Validation loss: 2.047851045926412

Epoch: 5| Step: 4
Training loss: 2.0491833686828613
Validation loss: 2.0649879696548625

Epoch: 5| Step: 5
Training loss: 2.6493964195251465
Validation loss: 2.0545095000215756

Epoch: 5| Step: 6
Training loss: 1.807244896888733
Validation loss: 2.024532897498018

Epoch: 5| Step: 7
Training loss: 2.2287609577178955
Validation loss: 2.0127478325238792

Epoch: 5| Step: 8
Training loss: 2.0424554347991943
Validation loss: 2.0599334765506048

Epoch: 5| Step: 9
Training loss: 1.7831323146820068
Validation loss: 2.0697947727736605

Epoch: 5| Step: 10
Training loss: 1.9871457815170288
Validation loss: 2.051530476539366

Epoch: 164| Step: 0
Training loss: 2.006199359893799
Validation loss: 2.077714684189007

Epoch: 5| Step: 1
Training loss: 2.2331347465515137
Validation loss: 2.0316202794351885

Epoch: 5| Step: 2
Training loss: 1.510016918182373
Validation loss: 2.04971255025556

Epoch: 5| Step: 3
Training loss: 2.145832061767578
Validation loss: 2.086963084436232

Epoch: 5| Step: 4
Training loss: 1.8785438537597656
Validation loss: 2.0784022987529798

Epoch: 5| Step: 5
Training loss: 2.4184908866882324
Validation loss: 2.0408907885192544

Epoch: 5| Step: 6
Training loss: 2.8767189979553223
Validation loss: 2.029849713848483

Epoch: 5| Step: 7
Training loss: 2.011059045791626
Validation loss: 2.009574335108521

Epoch: 5| Step: 8
Training loss: 2.004612445831299
Validation loss: 2.0396389730515017

Epoch: 5| Step: 9
Training loss: 1.7588727474212646
Validation loss: 2.050737161790171

Epoch: 5| Step: 10
Training loss: 1.9800971746444702
Validation loss: 2.0592240402775426

Epoch: 165| Step: 0
Training loss: 2.1627726554870605
Validation loss: 2.0402732972175843

Epoch: 5| Step: 1
Training loss: 1.661979079246521
Validation loss: 2.038566161227483

Epoch: 5| Step: 2
Training loss: 2.418555736541748
Validation loss: 2.0643277450274398

Epoch: 5| Step: 3
Training loss: 2.192110538482666
Validation loss: 2.0621419722034084

Epoch: 5| Step: 4
Training loss: 1.6453062295913696
Validation loss: 2.045110697387367

Epoch: 5| Step: 5
Training loss: 1.6787223815917969
Validation loss: 2.0281876184607066

Epoch: 5| Step: 6
Training loss: 2.0244948863983154
Validation loss: 2.0608310802008516

Epoch: 5| Step: 7
Training loss: 1.8696949481964111
Validation loss: 2.042204198016915

Epoch: 5| Step: 8
Training loss: 2.9964373111724854
Validation loss: 2.0511877870046966

Epoch: 5| Step: 9
Training loss: 1.7671349048614502
Validation loss: 2.0676571630662486

Epoch: 5| Step: 10
Training loss: 2.58716082572937
Validation loss: 2.0276816609085246

Epoch: 166| Step: 0
Training loss: 2.187359094619751
Validation loss: 2.0457747277393135

Epoch: 5| Step: 1
Training loss: 1.917913794517517
Validation loss: 2.0688693420861357

Epoch: 5| Step: 2
Training loss: 1.4924192428588867
Validation loss: 2.0268697751465665

Epoch: 5| Step: 3
Training loss: 2.6558339595794678
Validation loss: 2.049990524527847

Epoch: 5| Step: 4
Training loss: 2.2858073711395264
Validation loss: 2.027846038982432

Epoch: 5| Step: 5
Training loss: 2.575234889984131
Validation loss: 2.0515375265511135

Epoch: 5| Step: 6
Training loss: 2.072756290435791
Validation loss: 2.0327900686571674

Epoch: 5| Step: 7
Training loss: 1.7589261531829834
Validation loss: 2.0063363916130474

Epoch: 5| Step: 8
Training loss: 2.412000894546509
Validation loss: 2.0295193438888877

Epoch: 5| Step: 9
Training loss: 1.9273914098739624
Validation loss: 2.0323307488554265

Epoch: 5| Step: 10
Training loss: 1.7188628911972046
Validation loss: 2.063993905180244

Epoch: 167| Step: 0
Training loss: 1.9110136032104492
Validation loss: 2.0662506780316754

Epoch: 5| Step: 1
Training loss: 2.4390816688537598
Validation loss: 2.063696689503167

Epoch: 5| Step: 2
Training loss: 1.6841802597045898
Validation loss: 2.0712559966630835

Epoch: 5| Step: 3
Training loss: 1.7004029750823975
Validation loss: 2.0425527480340775

Epoch: 5| Step: 4
Training loss: 1.7347453832626343
Validation loss: 2.0724723287808

Epoch: 5| Step: 5
Training loss: 2.4227356910705566
Validation loss: 2.083512424140848

Epoch: 5| Step: 6
Training loss: 1.6770069599151611
Validation loss: 2.109372913196523

Epoch: 5| Step: 7
Training loss: 2.1665613651275635
Validation loss: 2.0885727969549035

Epoch: 5| Step: 8
Training loss: 2.2206432819366455
Validation loss: 2.1186236514840076

Epoch: 5| Step: 9
Training loss: 3.1832032203674316
Validation loss: 2.053789734840393

Epoch: 5| Step: 10
Training loss: 1.7945525646209717
Validation loss: 2.0410512249956847

Epoch: 168| Step: 0
Training loss: 1.8762565851211548
Validation loss: 2.054094701684931

Epoch: 5| Step: 1
Training loss: 1.5884435176849365
Validation loss: 2.0399237781442623

Epoch: 5| Step: 2
Training loss: 1.8802711963653564
Validation loss: 2.0732913530001076

Epoch: 5| Step: 3
Training loss: 2.0752928256988525
Validation loss: 2.0557782085992957

Epoch: 5| Step: 4
Training loss: 2.0630178451538086
Validation loss: 2.044822453170694

Epoch: 5| Step: 5
Training loss: 1.8825056552886963
Validation loss: 2.037729270996586

Epoch: 5| Step: 6
Training loss: 2.685537815093994
Validation loss: 2.0469352096639652

Epoch: 5| Step: 7
Training loss: 1.923858642578125
Validation loss: 2.047654979972429

Epoch: 5| Step: 8
Training loss: 2.4929141998291016
Validation loss: 2.043891845210906

Epoch: 5| Step: 9
Training loss: 2.208857297897339
Validation loss: 2.031674692707677

Epoch: 5| Step: 10
Training loss: 2.4855716228485107
Validation loss: 2.0475888149712675

Epoch: 169| Step: 0
Training loss: 2.1210639476776123
Validation loss: 2.0342453064457064

Epoch: 5| Step: 1
Training loss: 1.907573938369751
Validation loss: 2.0242744620128343

Epoch: 5| Step: 2
Training loss: 1.6533033847808838
Validation loss: 2.0416239538500385

Epoch: 5| Step: 3
Training loss: 1.9052289724349976
Validation loss: 2.049829682996196

Epoch: 5| Step: 4
Training loss: 2.618006467819214
Validation loss: 2.0550287410777104

Epoch: 5| Step: 5
Training loss: 1.9779869318008423
Validation loss: 2.0331257645801832

Epoch: 5| Step: 6
Training loss: 2.3394181728363037
Validation loss: 2.0453961036538564

Epoch: 5| Step: 7
Training loss: 2.203106641769409
Validation loss: 2.0690810885480655

Epoch: 5| Step: 8
Training loss: 1.7775920629501343
Validation loss: 2.0516852589063745

Epoch: 5| Step: 9
Training loss: 1.9929794073104858
Validation loss: 2.0382273325356106

Epoch: 5| Step: 10
Training loss: 2.406034469604492
Validation loss: 2.047853439084945

Epoch: 170| Step: 0
Training loss: 2.2291464805603027
Validation loss: 2.056841447789182

Epoch: 5| Step: 1
Training loss: 2.4706478118896484
Validation loss: 2.0567984862994124

Epoch: 5| Step: 2
Training loss: 1.8841660022735596
Validation loss: 2.0599429389481902

Epoch: 5| Step: 3
Training loss: 1.555201530456543
Validation loss: 2.061804077958548

Epoch: 5| Step: 4
Training loss: 1.8885486125946045
Validation loss: 2.0728314743247083

Epoch: 5| Step: 5
Training loss: 2.1031031608581543
Validation loss: 2.061632740882135

Epoch: 5| Step: 6
Training loss: 1.664355993270874
Validation loss: 2.066690908965244

Epoch: 5| Step: 7
Training loss: 2.7060914039611816
Validation loss: 2.060227335140269

Epoch: 5| Step: 8
Training loss: 2.1274642944335938
Validation loss: 2.075209476614511

Epoch: 5| Step: 9
Training loss: 2.368135452270508
Validation loss: 2.011968799816665

Epoch: 5| Step: 10
Training loss: 1.8406879901885986
Validation loss: 2.0627580406845256

Epoch: 171| Step: 0
Training loss: 2.0613536834716797
Validation loss: 2.0470065557828514

Epoch: 5| Step: 1
Training loss: 2.473017930984497
Validation loss: 2.0604646308447725

Epoch: 5| Step: 2
Training loss: 1.9698423147201538
Validation loss: 2.0513672828674316

Epoch: 5| Step: 3
Training loss: 1.4875022172927856
Validation loss: 2.0572198001287316

Epoch: 5| Step: 4
Training loss: 2.4235546588897705
Validation loss: 2.0171410306807487

Epoch: 5| Step: 5
Training loss: 1.821799874305725
Validation loss: 2.027809819867534

Epoch: 5| Step: 6
Training loss: 1.4001842737197876
Validation loss: 2.0655330047812512

Epoch: 5| Step: 7
Training loss: 2.5961434841156006
Validation loss: 2.0466530733211066

Epoch: 5| Step: 8
Training loss: 1.7547740936279297
Validation loss: 2.0367923577626548

Epoch: 5| Step: 9
Training loss: 2.658656120300293
Validation loss: 2.0212859184511247

Epoch: 5| Step: 10
Training loss: 2.227904796600342
Validation loss: 2.042522385556211

Epoch: 172| Step: 0
Training loss: 1.717193603515625
Validation loss: 2.0487576082188594

Epoch: 5| Step: 1
Training loss: 2.086998701095581
Validation loss: 2.0488747178867297

Epoch: 5| Step: 2
Training loss: 2.038691759109497
Validation loss: 2.029390693992697

Epoch: 5| Step: 3
Training loss: 1.870652437210083
Validation loss: 2.0347991502413185

Epoch: 5| Step: 4
Training loss: 1.856821060180664
Validation loss: 2.0128758748372397

Epoch: 5| Step: 5
Training loss: 2.071258544921875
Validation loss: 2.047887853396836

Epoch: 5| Step: 6
Training loss: 1.9134395122528076
Validation loss: 2.0249404548316874

Epoch: 5| Step: 7
Training loss: 2.1196720600128174
Validation loss: 2.0673084874306955

Epoch: 5| Step: 8
Training loss: 2.650771379470825
Validation loss: 2.04032963578419

Epoch: 5| Step: 9
Training loss: 2.530266523361206
Validation loss: 2.0447269511479202

Epoch: 5| Step: 10
Training loss: 1.864478349685669
Validation loss: 2.0603276914165867

Epoch: 173| Step: 0
Training loss: 2.5863137245178223
Validation loss: 2.053457634423369

Epoch: 5| Step: 1
Training loss: 2.371281862258911
Validation loss: 2.0596592169935986

Epoch: 5| Step: 2
Training loss: 2.1529088020324707
Validation loss: 2.0342562519093996

Epoch: 5| Step: 3
Training loss: 2.055748701095581
Validation loss: 2.04258632147184

Epoch: 5| Step: 4
Training loss: 1.8798224925994873
Validation loss: 2.050103461870583

Epoch: 5| Step: 5
Training loss: 1.9461109638214111
Validation loss: 2.0287190483462427

Epoch: 5| Step: 6
Training loss: 2.208139657974243
Validation loss: 2.030755368612146

Epoch: 5| Step: 7
Training loss: 1.9377374649047852
Validation loss: 2.045503972679056

Epoch: 5| Step: 8
Training loss: 1.6777172088623047
Validation loss: 2.0613770805379397

Epoch: 5| Step: 9
Training loss: 1.7142207622528076
Validation loss: 2.051210117596452

Epoch: 5| Step: 10
Training loss: 2.1417396068573
Validation loss: 2.0471890485414894

Epoch: 174| Step: 0
Training loss: 1.4505302906036377
Validation loss: 2.068488246651106

Epoch: 5| Step: 1
Training loss: 1.6648547649383545
Validation loss: 2.0628223547371487

Epoch: 5| Step: 2
Training loss: 1.3705538511276245
Validation loss: 2.02699327212508

Epoch: 5| Step: 3
Training loss: 2.7009055614471436
Validation loss: 2.0778875043315272

Epoch: 5| Step: 4
Training loss: 2.0920119285583496
Validation loss: 2.0836246757097143

Epoch: 5| Step: 5
Training loss: 2.1231257915496826
Validation loss: 2.032007914717479

Epoch: 5| Step: 6
Training loss: 2.2057430744171143
Validation loss: 2.0147014792247484

Epoch: 5| Step: 7
Training loss: 2.3479223251342773
Validation loss: 2.0439656011519896

Epoch: 5| Step: 8
Training loss: 2.36971116065979
Validation loss: 2.0520854201368106

Epoch: 5| Step: 9
Training loss: 2.49994158744812
Validation loss: 2.0448925969421223

Epoch: 5| Step: 10
Training loss: 2.078129529953003
Validation loss: 2.04712922598726

Epoch: 175| Step: 0
Training loss: 2.16683292388916
Validation loss: 2.055476891097202

Epoch: 5| Step: 1
Training loss: 2.621621608734131
Validation loss: 2.0661594572887627

Epoch: 5| Step: 2
Training loss: 2.196897506713867
Validation loss: 2.0376661695459837

Epoch: 5| Step: 3
Training loss: 2.3815019130706787
Validation loss: 2.05569528764294

Epoch: 5| Step: 4
Training loss: 1.5888751745224
Validation loss: 2.0674400791045158

Epoch: 5| Step: 5
Training loss: 2.147184133529663
Validation loss: 2.06165220404184

Epoch: 5| Step: 6
Training loss: 1.9700038433074951
Validation loss: 2.0440727587669127

Epoch: 5| Step: 7
Training loss: 1.9763448238372803
Validation loss: 2.041161488461238

Epoch: 5| Step: 8
Training loss: 1.680307388305664
Validation loss: 2.0381686456741823

Epoch: 5| Step: 9
Training loss: 2.232300281524658
Validation loss: 2.0610751503257343

Epoch: 5| Step: 10
Training loss: 1.9107325077056885
Validation loss: 2.0628606786010084

Epoch: 176| Step: 0
Training loss: 1.482389211654663
Validation loss: 2.0796615141694264

Epoch: 5| Step: 1
Training loss: 2.047481060028076
Validation loss: 2.0665363457895096

Epoch: 5| Step: 2
Training loss: 2.74019455909729
Validation loss: 2.0372136523646693

Epoch: 5| Step: 3
Training loss: 2.2534170150756836
Validation loss: 2.0731258751243673

Epoch: 5| Step: 4
Training loss: 2.2103404998779297
Validation loss: 2.0447094081550516

Epoch: 5| Step: 5
Training loss: 1.6920286417007446
Validation loss: 2.074133211566556

Epoch: 5| Step: 6
Training loss: 2.516448497772217
Validation loss: 2.0338366223919775

Epoch: 5| Step: 7
Training loss: 1.9587678909301758
Validation loss: 2.0693910711555072

Epoch: 5| Step: 8
Training loss: 2.0573692321777344
Validation loss: 2.0389230430767102

Epoch: 5| Step: 9
Training loss: 2.110508441925049
Validation loss: 2.035506086964761

Epoch: 5| Step: 10
Training loss: 1.8061602115631104
Validation loss: 2.0670496174084243

Epoch: 177| Step: 0
Training loss: 1.7973436117172241
Validation loss: 2.029653036466209

Epoch: 5| Step: 1
Training loss: 1.977365255355835
Validation loss: 2.0554940085257254

Epoch: 5| Step: 2
Training loss: 2.1217434406280518
Validation loss: 2.0329499526690413

Epoch: 5| Step: 3
Training loss: 2.698761463165283
Validation loss: 2.067843482058535

Epoch: 5| Step: 4
Training loss: 1.9072116613388062
Validation loss: 2.0410198293706423

Epoch: 5| Step: 5
Training loss: 2.4049253463745117
Validation loss: 2.0280407026249874

Epoch: 5| Step: 6
Training loss: 1.9048877954483032
Validation loss: 2.0442146075669156

Epoch: 5| Step: 7
Training loss: 2.0315253734588623
Validation loss: 2.045226240670809

Epoch: 5| Step: 8
Training loss: 2.1544601917266846
Validation loss: 2.049368384063885

Epoch: 5| Step: 9
Training loss: 1.8517587184906006
Validation loss: 2.031970613746233

Epoch: 5| Step: 10
Training loss: 1.7235033512115479
Validation loss: 2.05427223379894

Epoch: 178| Step: 0
Training loss: 2.483527898788452
Validation loss: 2.0305631929828274

Epoch: 5| Step: 1
Training loss: 1.9842212200164795
Validation loss: 2.064539206925259

Epoch: 5| Step: 2
Training loss: 2.167638063430786
Validation loss: 2.0489763905925136

Epoch: 5| Step: 3
Training loss: 2.352569818496704
Validation loss: 2.0678610904242403

Epoch: 5| Step: 4
Training loss: 1.6743797063827515
Validation loss: 2.022652572201144

Epoch: 5| Step: 5
Training loss: 1.8739582300186157
Validation loss: 2.0490245819091797

Epoch: 5| Step: 6
Training loss: 2.112363815307617
Validation loss: 2.0252907212062548

Epoch: 5| Step: 7
Training loss: 1.6933187246322632
Validation loss: 2.0611213766118532

Epoch: 5| Step: 8
Training loss: 2.0632457733154297
Validation loss: 2.0720181260057675

Epoch: 5| Step: 9
Training loss: 2.015655994415283
Validation loss: 2.0629980846117904

Epoch: 5| Step: 10
Training loss: 2.4372050762176514
Validation loss: 2.053849971422585

Epoch: 179| Step: 0
Training loss: 2.5596964359283447
Validation loss: 2.0422721203937324

Epoch: 5| Step: 1
Training loss: 1.6780765056610107
Validation loss: 2.0544071812783518

Epoch: 5| Step: 2
Training loss: 1.6997153759002686
Validation loss: 2.0710523000327488

Epoch: 5| Step: 3
Training loss: 1.9324376583099365
Validation loss: 2.0452295170035413

Epoch: 5| Step: 4
Training loss: 2.361112356185913
Validation loss: 2.065045982278803

Epoch: 5| Step: 5
Training loss: 2.266923427581787
Validation loss: 2.036829888179738

Epoch: 5| Step: 6
Training loss: 2.2833335399627686
Validation loss: 2.0744059649846887

Epoch: 5| Step: 7
Training loss: 1.8880751132965088
Validation loss: 2.0855512375472696

Epoch: 5| Step: 8
Training loss: 1.9748446941375732
Validation loss: 2.060589544234737

Epoch: 5| Step: 9
Training loss: 2.2039990425109863
Validation loss: 2.06040257792319

Epoch: 5| Step: 10
Training loss: 1.9185023307800293
Validation loss: 2.060454450627809

Epoch: 180| Step: 0
Training loss: 2.0467123985290527
Validation loss: 2.0834846188945155

Epoch: 5| Step: 1
Training loss: 1.378965139389038
Validation loss: 2.0482389580818916

Epoch: 5| Step: 2
Training loss: 2.2261226177215576
Validation loss: 2.0696545852127897

Epoch: 5| Step: 3
Training loss: 2.3664565086364746
Validation loss: 2.0491227616545973

Epoch: 5| Step: 4
Training loss: 2.2164742946624756
Validation loss: 2.055397907892863

Epoch: 5| Step: 5
Training loss: 2.9002833366394043
Validation loss: 2.0583942397948234

Epoch: 5| Step: 6
Training loss: 1.452531099319458
Validation loss: 2.0370399387933875

Epoch: 5| Step: 7
Training loss: 1.6352379322052002
Validation loss: 2.062438371360943

Epoch: 5| Step: 8
Training loss: 1.9574401378631592
Validation loss: 2.0329576999910417

Epoch: 5| Step: 9
Training loss: 1.9155499935150146
Validation loss: 2.065245848830028

Epoch: 5| Step: 10
Training loss: 2.593533754348755
Validation loss: 2.0404190145513064

Epoch: 181| Step: 0
Training loss: 2.609480381011963
Validation loss: 2.0319542218280096

Epoch: 5| Step: 1
Training loss: 1.5892919301986694
Validation loss: 2.061317200301796

Epoch: 5| Step: 2
Training loss: 1.4893680810928345
Validation loss: 2.0299994202070337

Epoch: 5| Step: 3
Training loss: 1.4964442253112793
Validation loss: 2.042394024069591

Epoch: 5| Step: 4
Training loss: 2.180074691772461
Validation loss: 2.0177491954577866

Epoch: 5| Step: 5
Training loss: 1.9659912586212158
Validation loss: 2.0305603524690032

Epoch: 5| Step: 6
Training loss: 2.067140579223633
Validation loss: 2.07454921865976

Epoch: 5| Step: 7
Training loss: 2.146665573120117
Validation loss: 2.028993493767195

Epoch: 5| Step: 8
Training loss: 2.7527003288269043
Validation loss: 2.0420790885084417

Epoch: 5| Step: 9
Training loss: 2.0774264335632324
Validation loss: 2.0710093116247528

Epoch: 5| Step: 10
Training loss: 2.1178836822509766
Validation loss: 2.0321608307541057

Epoch: 182| Step: 0
Training loss: 1.797245740890503
Validation loss: 2.046857028879145

Epoch: 5| Step: 1
Training loss: 2.2473034858703613
Validation loss: 2.0247107846762544

Epoch: 5| Step: 2
Training loss: 1.912710428237915
Validation loss: 2.059501158293857

Epoch: 5| Step: 3
Training loss: 2.5211429595947266
Validation loss: 2.063533547104046

Epoch: 5| Step: 4
Training loss: 2.688502550125122
Validation loss: 2.0355676733037478

Epoch: 5| Step: 5
Training loss: 1.7162768840789795
Validation loss: 2.041934133857809

Epoch: 5| Step: 6
Training loss: 1.84356689453125
Validation loss: 2.0540725287570747

Epoch: 5| Step: 7
Training loss: 1.9487574100494385
Validation loss: 2.0438765941127652

Epoch: 5| Step: 8
Training loss: 1.995923638343811
Validation loss: 2.072203310587073

Epoch: 5| Step: 9
Training loss: 2.0423078536987305
Validation loss: 2.0937252301041798

Epoch: 5| Step: 10
Training loss: 1.9243861436843872
Validation loss: 2.048826984179917

Epoch: 183| Step: 0
Training loss: 1.513486623764038
Validation loss: 2.0763728323803154

Epoch: 5| Step: 1
Training loss: 2.0051867961883545
Validation loss: 2.067364843942786

Epoch: 5| Step: 2
Training loss: 2.160385847091675
Validation loss: 2.0697813469876527

Epoch: 5| Step: 3
Training loss: 1.9325288534164429
Validation loss: 2.040688204508956

Epoch: 5| Step: 4
Training loss: 2.622443914413452
Validation loss: 2.073780475124236

Epoch: 5| Step: 5
Training loss: 1.5339062213897705
Validation loss: 2.074470535401375

Epoch: 5| Step: 6
Training loss: 2.3751447200775146
Validation loss: 2.074979348849225

Epoch: 5| Step: 7
Training loss: 1.5406450033187866
Validation loss: 2.0440081447683354

Epoch: 5| Step: 8
Training loss: 1.7648576498031616
Validation loss: 2.042430039375059

Epoch: 5| Step: 9
Training loss: 2.530561923980713
Validation loss: 2.057938964136185

Epoch: 5| Step: 10
Training loss: 2.631469488143921
Validation loss: 2.05131632538252

Epoch: 184| Step: 0
Training loss: 2.2898285388946533
Validation loss: 2.0458769900824434

Epoch: 5| Step: 1
Training loss: 2.1891260147094727
Validation loss: 2.0530853348393596

Epoch: 5| Step: 2
Training loss: 1.999979019165039
Validation loss: 2.002914209519663

Epoch: 5| Step: 3
Training loss: 2.528809070587158
Validation loss: 2.0630256181122153

Epoch: 5| Step: 4
Training loss: 1.9262981414794922
Validation loss: 2.0537247837230725

Epoch: 5| Step: 5
Training loss: 1.9526793956756592
Validation loss: 2.059045655753023

Epoch: 5| Step: 6
Training loss: 2.049560546875
Validation loss: 2.0881146589914956

Epoch: 5| Step: 7
Training loss: 2.066275119781494
Validation loss: 2.074447084498662

Epoch: 5| Step: 8
Training loss: 2.065995693206787
Validation loss: 2.048157068990892

Epoch: 5| Step: 9
Training loss: 1.7716045379638672
Validation loss: 2.1052156879055883

Epoch: 5| Step: 10
Training loss: 1.7383201122283936
Validation loss: 2.069379630909171

Epoch: 185| Step: 0
Training loss: 2.1421871185302734
Validation loss: 2.073785927987868

Epoch: 5| Step: 1
Training loss: 2.093147039413452
Validation loss: 2.054307463348553

Epoch: 5| Step: 2
Training loss: 2.4592440128326416
Validation loss: 2.0529128274609967

Epoch: 5| Step: 3
Training loss: 1.7998344898223877
Validation loss: 2.064409661036666

Epoch: 5| Step: 4
Training loss: 2.4195661544799805
Validation loss: 2.0720843166433354

Epoch: 5| Step: 5
Training loss: 1.630720853805542
Validation loss: 2.035661276950631

Epoch: 5| Step: 6
Training loss: 1.6633656024932861
Validation loss: 2.065930483161762

Epoch: 5| Step: 7
Training loss: 2.2122035026550293
Validation loss: 2.0406704615521174

Epoch: 5| Step: 8
Training loss: 1.7702974081039429
Validation loss: 2.0336484537329724

Epoch: 5| Step: 9
Training loss: 1.6834895610809326
Validation loss: 2.0364819162635395

Epoch: 5| Step: 10
Training loss: 2.7212719917297363
Validation loss: 2.0432725721789944

Epoch: 186| Step: 0
Training loss: 1.8247638940811157
Validation loss: 2.041197669121527

Epoch: 5| Step: 1
Training loss: 2.1581199169158936
Validation loss: 2.029623152107321

Epoch: 5| Step: 2
Training loss: 1.671755075454712
Validation loss: 2.0343430811359036

Epoch: 5| Step: 3
Training loss: 2.4500551223754883
Validation loss: 2.055976415193209

Epoch: 5| Step: 4
Training loss: 2.2146213054656982
Validation loss: 2.0144469071460027

Epoch: 5| Step: 5
Training loss: 2.402100086212158
Validation loss: 2.0724831140169533

Epoch: 5| Step: 6
Training loss: 1.656764268875122
Validation loss: 2.0305631160736084

Epoch: 5| Step: 7
Training loss: 1.9464197158813477
Validation loss: 2.0429393924692625

Epoch: 5| Step: 8
Training loss: 2.759290933609009
Validation loss: 2.055259814826391

Epoch: 5| Step: 9
Training loss: 1.9209842681884766
Validation loss: 2.0014555736254622

Epoch: 5| Step: 10
Training loss: 1.4931936264038086
Validation loss: 2.0543561648297053

Epoch: 187| Step: 0
Training loss: 1.59121835231781
Validation loss: 2.023577282505651

Epoch: 5| Step: 1
Training loss: 2.3837122917175293
Validation loss: 2.0609328823704876

Epoch: 5| Step: 2
Training loss: 2.1091296672821045
Validation loss: 2.059627212503905

Epoch: 5| Step: 3
Training loss: 1.5680595636367798
Validation loss: 2.0692841186318347

Epoch: 5| Step: 4
Training loss: 2.1780431270599365
Validation loss: 2.036973399500693

Epoch: 5| Step: 5
Training loss: 1.690527319908142
Validation loss: 2.049315655103294

Epoch: 5| Step: 6
Training loss: 2.3778934478759766
Validation loss: 2.0329283629694292

Epoch: 5| Step: 7
Training loss: 1.8896335363388062
Validation loss: 2.0338157915299937

Epoch: 5| Step: 8
Training loss: 2.3952345848083496
Validation loss: 2.0631810388257428

Epoch: 5| Step: 9
Training loss: 2.4119508266448975
Validation loss: 2.0343835020578034

Epoch: 5| Step: 10
Training loss: 1.9125101566314697
Validation loss: 2.0681761977493123

Epoch: 188| Step: 0
Training loss: 2.309147596359253
Validation loss: 2.029079826929236

Epoch: 5| Step: 1
Training loss: 2.371371269226074
Validation loss: 2.021581801035071

Epoch: 5| Step: 2
Training loss: 2.428689479827881
Validation loss: 2.036319935193626

Epoch: 5| Step: 3
Training loss: 2.4739990234375
Validation loss: 2.04812963034517

Epoch: 5| Step: 4
Training loss: 1.648424506187439
Validation loss: 2.0280917331736577

Epoch: 5| Step: 5
Training loss: 2.245504856109619
Validation loss: 2.045984255370273

Epoch: 5| Step: 6
Training loss: 2.056006908416748
Validation loss: 2.0605916143745504

Epoch: 5| Step: 7
Training loss: 1.7053877115249634
Validation loss: 2.0441732278434177

Epoch: 5| Step: 8
Training loss: 1.3375779390335083
Validation loss: 2.0183023765522945

Epoch: 5| Step: 9
Training loss: 1.5773036479949951
Validation loss: 2.076850414276123

Epoch: 5| Step: 10
Training loss: 2.1889548301696777
Validation loss: 2.0006432071808846

Epoch: 189| Step: 0
Training loss: 2.1580822467803955
Validation loss: 2.044819344756424

Epoch: 5| Step: 1
Training loss: 2.382739543914795
Validation loss: 2.0366126337359027

Epoch: 5| Step: 2
Training loss: 1.875952124595642
Validation loss: 2.045561698175246

Epoch: 5| Step: 3
Training loss: 1.466933250427246
Validation loss: 2.016011558553224

Epoch: 5| Step: 4
Training loss: 2.7438912391662598
Validation loss: 2.033353469705069

Epoch: 5| Step: 5
Training loss: 1.279442548751831
Validation loss: 2.0477489707290486

Epoch: 5| Step: 6
Training loss: 2.0300381183624268
Validation loss: 2.030679351540022

Epoch: 5| Step: 7
Training loss: 2.294915199279785
Validation loss: 2.030202986091696

Epoch: 5| Step: 8
Training loss: 2.045504331588745
Validation loss: 2.0390743824743454

Epoch: 5| Step: 9
Training loss: 2.0689611434936523
Validation loss: 2.0203627463309997

Epoch: 5| Step: 10
Training loss: 2.1151459217071533
Validation loss: 2.059459368387858

Epoch: 190| Step: 0
Training loss: 1.889028549194336
Validation loss: 2.0271689481632684

Epoch: 5| Step: 1
Training loss: 1.6316665410995483
Validation loss: 2.063106426628687

Epoch: 5| Step: 2
Training loss: 1.8826919794082642
Validation loss: 2.0664305481859433

Epoch: 5| Step: 3
Training loss: 2.2139892578125
Validation loss: 2.057851240199099

Epoch: 5| Step: 4
Training loss: 2.280153751373291
Validation loss: 2.0421850783850557

Epoch: 5| Step: 5
Training loss: 2.597294569015503
Validation loss: 2.055138523860644

Epoch: 5| Step: 6
Training loss: 1.9626318216323853
Validation loss: 2.0672116023237987

Epoch: 5| Step: 7
Training loss: 2.1466660499572754
Validation loss: 2.0313542453191613

Epoch: 5| Step: 8
Training loss: 1.729124665260315
Validation loss: 2.050883880225561

Epoch: 5| Step: 9
Training loss: 1.9556238651275635
Validation loss: 2.0381112406330724

Epoch: 5| Step: 10
Training loss: 1.938311219215393
Validation loss: 2.042935686726724

Epoch: 191| Step: 0
Training loss: 1.508073091506958
Validation loss: 2.0114465016190723

Epoch: 5| Step: 1
Training loss: 1.5476648807525635
Validation loss: 2.048129571381436

Epoch: 5| Step: 2
Training loss: 2.176328420639038
Validation loss: 2.053540745089131

Epoch: 5| Step: 3
Training loss: 1.6263309717178345
Validation loss: 2.0561423224787556

Epoch: 5| Step: 4
Training loss: 1.9382225275039673
Validation loss: 2.055335183297434

Epoch: 5| Step: 5
Training loss: 2.3408050537109375
Validation loss: 2.0566887214619625

Epoch: 5| Step: 6
Training loss: 2.822838306427002
Validation loss: 2.006780061670529

Epoch: 5| Step: 7
Training loss: 1.6301053762435913
Validation loss: 2.0421935576264576

Epoch: 5| Step: 8
Training loss: 2.838007688522339
Validation loss: 2.0782376438058834

Epoch: 5| Step: 9
Training loss: 1.8924610614776611
Validation loss: 2.0453675664881223

Epoch: 5| Step: 10
Training loss: 2.0172858238220215
Validation loss: 2.061991814644106

Epoch: 192| Step: 0
Training loss: 2.296807050704956
Validation loss: 1.998184496356595

Epoch: 5| Step: 1
Training loss: 1.8845484256744385
Validation loss: 2.068062274686752

Epoch: 5| Step: 2
Training loss: 1.7561466693878174
Validation loss: 2.0593535848843154

Epoch: 5| Step: 3
Training loss: 2.3547940254211426
Validation loss: 2.047941638577369

Epoch: 5| Step: 4
Training loss: 2.0234196186065674
Validation loss: 2.065676563529558

Epoch: 5| Step: 5
Training loss: 2.044851779937744
Validation loss: 2.002191723033946

Epoch: 5| Step: 6
Training loss: 2.2537221908569336
Validation loss: 2.042716551852483

Epoch: 5| Step: 7
Training loss: 1.9615987539291382
Validation loss: 2.048658565808368

Epoch: 5| Step: 8
Training loss: 2.244166135787964
Validation loss: 2.027902739022368

Epoch: 5| Step: 9
Training loss: 1.923925757408142
Validation loss: 2.0632359058626237

Epoch: 5| Step: 10
Training loss: 1.4705569744110107
Validation loss: 2.0672871297405613

Epoch: 193| Step: 0
Training loss: 1.9735534191131592
Validation loss: 2.061614490324451

Epoch: 5| Step: 1
Training loss: 2.5611495971679688
Validation loss: 2.0504470999522875

Epoch: 5| Step: 2
Training loss: 1.3318573236465454
Validation loss: 2.0396009901518464

Epoch: 5| Step: 3
Training loss: 2.094982624053955
Validation loss: 2.058163886429161

Epoch: 5| Step: 4
Training loss: 1.7053508758544922
Validation loss: 2.0575845985002417

Epoch: 5| Step: 5
Training loss: 1.9470741748809814
Validation loss: 2.006268757645802

Epoch: 5| Step: 6
Training loss: 2.4488003253936768
Validation loss: 2.059096597856091

Epoch: 5| Step: 7
Training loss: 1.9915590286254883
Validation loss: 2.0698631860876597

Epoch: 5| Step: 8
Training loss: 1.1922836303710938
Validation loss: 2.0425103479816067

Epoch: 5| Step: 9
Training loss: 2.3188469409942627
Validation loss: 2.044202414892053

Epoch: 5| Step: 10
Training loss: 2.863579511642456
Validation loss: 2.045851839485989

Epoch: 194| Step: 0
Training loss: 2.0183091163635254
Validation loss: 2.026812440605574

Epoch: 5| Step: 1
Training loss: 2.8172924518585205
Validation loss: 2.059022775260351

Epoch: 5| Step: 2
Training loss: 2.023358106613159
Validation loss: 2.0406563217921923

Epoch: 5| Step: 3
Training loss: 2.137167453765869
Validation loss: 2.0605530687557754

Epoch: 5| Step: 4
Training loss: 2.0556206703186035
Validation loss: 2.0425716869292723

Epoch: 5| Step: 5
Training loss: 1.7289472818374634
Validation loss: 2.0836213327223256

Epoch: 5| Step: 6
Training loss: 1.7036945819854736
Validation loss: 2.079990904818299

Epoch: 5| Step: 7
Training loss: 1.218153715133667
Validation loss: 2.0610666685206915

Epoch: 5| Step: 8
Training loss: 2.7493560314178467
Validation loss: 2.0310320110731226

Epoch: 5| Step: 9
Training loss: 1.845084547996521
Validation loss: 2.032430188630217

Epoch: 5| Step: 10
Training loss: 1.946386456489563
Validation loss: 2.058132989432222

Epoch: 195| Step: 0
Training loss: 1.7077548503875732
Validation loss: 2.0460773180889826

Epoch: 5| Step: 1
Training loss: 1.9215056896209717
Validation loss: 2.0528695224433817

Epoch: 5| Step: 2
Training loss: 2.2386763095855713
Validation loss: 2.0338920572752595

Epoch: 5| Step: 3
Training loss: 2.0400047302246094
Validation loss: 2.0627135769013436

Epoch: 5| Step: 4
Training loss: 1.7703640460968018
Validation loss: 2.0514321660482757

Epoch: 5| Step: 5
Training loss: 1.9915720224380493
Validation loss: 2.0578176577885947

Epoch: 5| Step: 6
Training loss: 2.1518890857696533
Validation loss: 2.064209040775094

Epoch: 5| Step: 7
Training loss: 2.1627554893493652
Validation loss: 2.087065489061417

Epoch: 5| Step: 8
Training loss: 2.3564364910125732
Validation loss: 2.0561797849593626

Epoch: 5| Step: 9
Training loss: 2.0023679733276367
Validation loss: 2.0754864818306378

Epoch: 5| Step: 10
Training loss: 1.8261117935180664
Validation loss: 2.0759373044454925

Epoch: 196| Step: 0
Training loss: 2.3099873065948486
Validation loss: 2.0462634153263544

Epoch: 5| Step: 1
Training loss: 2.116393566131592
Validation loss: 2.068386895682222

Epoch: 5| Step: 2
Training loss: 1.714742660522461
Validation loss: 2.034486045119583

Epoch: 5| Step: 3
Training loss: 2.5681402683258057
Validation loss: 2.046646043818484

Epoch: 5| Step: 4
Training loss: 2.105681896209717
Validation loss: 2.0731540931168424

Epoch: 5| Step: 5
Training loss: 2.637226104736328
Validation loss: 2.074639199882425

Epoch: 5| Step: 6
Training loss: 2.026162624359131
Validation loss: 2.0698838054492907

Epoch: 5| Step: 7
Training loss: 1.901694655418396
Validation loss: 2.0393900102184666

Epoch: 5| Step: 8
Training loss: 1.4387037754058838
Validation loss: 2.0261100927988687

Epoch: 5| Step: 9
Training loss: 1.6382662057876587
Validation loss: 2.0504861493264475

Epoch: 5| Step: 10
Training loss: 1.5622837543487549
Validation loss: 2.023299063405683

Epoch: 197| Step: 0
Training loss: 2.0907580852508545
Validation loss: 2.0115099132701917

Epoch: 5| Step: 1
Training loss: 1.7369263172149658
Validation loss: 2.051203716185785

Epoch: 5| Step: 2
Training loss: 1.6676604747772217
Validation loss: 2.0814906730446765

Epoch: 5| Step: 3
Training loss: 1.7438936233520508
Validation loss: 2.0514261350836804

Epoch: 5| Step: 4
Training loss: 2.0091631412506104
Validation loss: 2.049306866943195

Epoch: 5| Step: 5
Training loss: 1.4661213159561157
Validation loss: 2.043681998406687

Epoch: 5| Step: 6
Training loss: 2.9791982173919678
Validation loss: 2.0357472999121553

Epoch: 5| Step: 7
Training loss: 2.455148935317993
Validation loss: 2.046739439810476

Epoch: 5| Step: 8
Training loss: 2.1780428886413574
Validation loss: 2.0209876247631606

Epoch: 5| Step: 9
Training loss: 2.1433908939361572
Validation loss: 2.050545148952033

Epoch: 5| Step: 10
Training loss: 1.2281348705291748
Validation loss: 2.0562971381730932

Epoch: 198| Step: 0
Training loss: 2.2141473293304443
Validation loss: 2.0576674707474245

Epoch: 5| Step: 1
Training loss: 1.9733879566192627
Validation loss: 2.0406147280047016

Epoch: 5| Step: 2
Training loss: 2.421721935272217
Validation loss: 2.064502816046438

Epoch: 5| Step: 3
Training loss: 1.8405582904815674
Validation loss: 2.014427096612992

Epoch: 5| Step: 4
Training loss: 1.9648959636688232
Validation loss: 2.042237840672975

Epoch: 5| Step: 5
Training loss: 2.248920202255249
Validation loss: 2.05589307508161

Epoch: 5| Step: 6
Training loss: 1.7791475057601929
Validation loss: 2.043796472651984

Epoch: 5| Step: 7
Training loss: 2.5682373046875
Validation loss: 2.010125611418037

Epoch: 5| Step: 8
Training loss: 1.8053697347640991
Validation loss: 2.0500743978766987

Epoch: 5| Step: 9
Training loss: 1.408770203590393
Validation loss: 2.0609097506410334

Epoch: 5| Step: 10
Training loss: 1.7861502170562744
Validation loss: 2.0489248562884588

Epoch: 199| Step: 0
Training loss: 2.2270634174346924
Validation loss: 2.0210578890256983

Epoch: 5| Step: 1
Training loss: 1.5018348693847656
Validation loss: 2.0795010597475114

Epoch: 5| Step: 2
Training loss: 1.6549097299575806
Validation loss: 2.0285064430646997

Epoch: 5| Step: 3
Training loss: 1.8940576314926147
Validation loss: 2.000629413512445

Epoch: 5| Step: 4
Training loss: 1.422344446182251
Validation loss: 2.04358656432039

Epoch: 5| Step: 5
Training loss: 2.2516303062438965
Validation loss: 2.0155186242954706

Epoch: 5| Step: 6
Training loss: 2.4145631790161133
Validation loss: 2.087598031566989

Epoch: 5| Step: 7
Training loss: 2.1064229011535645
Validation loss: 2.00548029586833

Epoch: 5| Step: 8
Training loss: 2.413918972015381
Validation loss: 2.0172333794255413

Epoch: 5| Step: 9
Training loss: 1.9548012018203735
Validation loss: 2.0453173319498696

Epoch: 5| Step: 10
Training loss: 2.227083921432495
Validation loss: 2.0101493738030873

Epoch: 200| Step: 0
Training loss: 1.8616554737091064
Validation loss: 2.068107963890158

Epoch: 5| Step: 1
Training loss: 1.98251473903656
Validation loss: 2.040079418049064

Epoch: 5| Step: 2
Training loss: 1.8857381343841553
Validation loss: 2.02713708467381

Epoch: 5| Step: 3
Training loss: 1.8508151769638062
Validation loss: 2.0473874115174815

Epoch: 5| Step: 4
Training loss: 1.5750678777694702
Validation loss: 2.0567514511846725

Epoch: 5| Step: 5
Training loss: 1.4409981966018677
Validation loss: 2.0273941768113004

Epoch: 5| Step: 6
Training loss: 2.9693806171417236
Validation loss: 2.0379991428826445

Epoch: 5| Step: 7
Training loss: 2.4951319694519043
Validation loss: 2.0729505720958916

Epoch: 5| Step: 8
Training loss: 1.437237024307251
Validation loss: 2.0379588552700576

Epoch: 5| Step: 9
Training loss: 2.1007509231567383
Validation loss: 2.0334116797293387

Epoch: 5| Step: 10
Training loss: 2.561518430709839
Validation loss: 2.0307511078414096

Epoch: 201| Step: 0
Training loss: 1.646624207496643
Validation loss: 2.0092228087045814

Epoch: 5| Step: 1
Training loss: 1.9860481023788452
Validation loss: 2.0338815360940914

Epoch: 5| Step: 2
Training loss: 2.381199836730957
Validation loss: 2.0298346486142886

Epoch: 5| Step: 3
Training loss: 1.9218746423721313
Validation loss: 1.984589720285067

Epoch: 5| Step: 4
Training loss: 1.5402565002441406
Validation loss: 2.0473812395526516

Epoch: 5| Step: 5
Training loss: 1.5643723011016846
Validation loss: 2.0423004396500124

Epoch: 5| Step: 6
Training loss: 3.141174793243408
Validation loss: 2.0387340643072642

Epoch: 5| Step: 7
Training loss: 1.8551769256591797
Validation loss: 2.0452766110820155

Epoch: 5| Step: 8
Training loss: 1.6641952991485596
Validation loss: 2.0401331019657913

Epoch: 5| Step: 9
Training loss: 2.5635008811950684
Validation loss: 2.0448965757123885

Epoch: 5| Step: 10
Training loss: 1.4454190731048584
Validation loss: 2.0790675045341573

Epoch: 202| Step: 0
Training loss: 2.032942295074463
Validation loss: 2.0542838906729095

Epoch: 5| Step: 1
Training loss: 2.4424195289611816
Validation loss: 2.052188980963922

Epoch: 5| Step: 2
Training loss: 2.065645694732666
Validation loss: 2.049688449469946

Epoch: 5| Step: 3
Training loss: 2.0667343139648438
Validation loss: 2.028159761941561

Epoch: 5| Step: 4
Training loss: 2.3985884189605713
Validation loss: 2.0648019788085774

Epoch: 5| Step: 5
Training loss: 1.7128807306289673
Validation loss: 2.0280499612131426

Epoch: 5| Step: 6
Training loss: 1.6833076477050781
Validation loss: 2.0483728877959715

Epoch: 5| Step: 7
Training loss: 2.2698750495910645
Validation loss: 2.035501262193085

Epoch: 5| Step: 8
Training loss: 1.4408631324768066
Validation loss: 2.0375461450187107

Epoch: 5| Step: 9
Training loss: 1.8857234716415405
Validation loss: 2.065339211494692

Epoch: 5| Step: 10
Training loss: 1.915492296218872
Validation loss: 2.048770514867639

Epoch: 203| Step: 0
Training loss: 1.9985698461532593
Validation loss: 2.0403744507861394

Epoch: 5| Step: 1
Training loss: 2.182288885116577
Validation loss: 2.0492123493584256

Epoch: 5| Step: 2
Training loss: 2.0334701538085938
Validation loss: 2.025948432184035

Epoch: 5| Step: 3
Training loss: 2.406609296798706
Validation loss: 2.0731420286240114

Epoch: 5| Step: 4
Training loss: 1.9155104160308838
Validation loss: 2.0521927008064846

Epoch: 5| Step: 5
Training loss: 2.004511594772339
Validation loss: 2.048057092133389

Epoch: 5| Step: 6
Training loss: 2.0369107723236084
Validation loss: 2.0404227343938683

Epoch: 5| Step: 7
Training loss: 2.3491768836975098
Validation loss: 2.0229172116966656

Epoch: 5| Step: 8
Training loss: 1.7304697036743164
Validation loss: 2.0265111166943788

Epoch: 5| Step: 9
Training loss: 1.4757829904556274
Validation loss: 2.0480647317824827

Epoch: 5| Step: 10
Training loss: 1.946912407875061
Validation loss: 2.051756371733963

Epoch: 204| Step: 0
Training loss: 1.3330409526824951
Validation loss: 2.0487629931460143

Epoch: 5| Step: 1
Training loss: 1.6430763006210327
Validation loss: 2.0378109421781314

Epoch: 5| Step: 2
Training loss: 2.3033175468444824
Validation loss: 2.0317130780989126

Epoch: 5| Step: 3
Training loss: 1.6495437622070312
Validation loss: 2.077853674529701

Epoch: 5| Step: 4
Training loss: 2.7653496265411377
Validation loss: 2.0376749346333165

Epoch: 5| Step: 5
Training loss: 1.4883906841278076
Validation loss: 2.017211244952294

Epoch: 5| Step: 6
Training loss: 2.218247413635254
Validation loss: 2.0151977321153045

Epoch: 5| Step: 7
Training loss: 2.4695961475372314
Validation loss: 2.0309723397736907

Epoch: 5| Step: 8
Training loss: 2.4049148559570312
Validation loss: 2.077026600478798

Epoch: 5| Step: 9
Training loss: 1.4608007669448853
Validation loss: 2.069194855228547

Epoch: 5| Step: 10
Training loss: 2.189326047897339
Validation loss: 2.038026830201508

Epoch: 205| Step: 0
Training loss: 2.3116836547851562
Validation loss: 2.0389222662935973

Epoch: 5| Step: 1
Training loss: 2.065775156021118
Validation loss: 2.0443478809889926

Epoch: 5| Step: 2
Training loss: 2.3704993724823
Validation loss: 2.046242358863995

Epoch: 5| Step: 3
Training loss: 1.4250034093856812
Validation loss: 2.054874432984219

Epoch: 5| Step: 4
Training loss: 1.7985680103302002
Validation loss: 2.057272252216134

Epoch: 5| Step: 5
Training loss: 1.6857717037200928
Validation loss: 2.020409437917894

Epoch: 5| Step: 6
Training loss: 1.5766264200210571
Validation loss: 2.072284278049264

Epoch: 5| Step: 7
Training loss: 2.4436450004577637
Validation loss: 2.033312628346105

Epoch: 5| Step: 8
Training loss: 2.678112506866455
Validation loss: 2.0368226112857943

Epoch: 5| Step: 9
Training loss: 1.7158902883529663
Validation loss: 2.051645235348773

Epoch: 5| Step: 10
Training loss: 1.7669446468353271
Validation loss: 2.0261217573637604

Epoch: 206| Step: 0
Training loss: 1.9173085689544678
Validation loss: 2.048972950186781

Epoch: 5| Step: 1
Training loss: 1.7138988971710205
Validation loss: 1.9866933655995194

Epoch: 5| Step: 2
Training loss: 2.1407113075256348
Validation loss: 2.024147727156198

Epoch: 5| Step: 3
Training loss: 2.10178542137146
Validation loss: 2.0618738923021542

Epoch: 5| Step: 4
Training loss: 1.5553314685821533
Validation loss: 2.0504802798712127

Epoch: 5| Step: 5
Training loss: 1.9183562994003296
Validation loss: 2.0296669044802265

Epoch: 5| Step: 6
Training loss: 1.9832727909088135
Validation loss: 2.025465549961213

Epoch: 5| Step: 7
Training loss: 1.9413121938705444
Validation loss: 2.030449075083579

Epoch: 5| Step: 8
Training loss: 2.2164535522460938
Validation loss: 2.026257568790067

Epoch: 5| Step: 9
Training loss: 2.1745524406433105
Validation loss: 2.0240309622979935

Epoch: 5| Step: 10
Training loss: 2.0692098140716553
Validation loss: 2.0540070828571113

Epoch: 207| Step: 0
Training loss: 1.8779363632202148
Validation loss: 2.0305968740934968

Epoch: 5| Step: 1
Training loss: 2.049741506576538
Validation loss: 1.9945277270450388

Epoch: 5| Step: 2
Training loss: 1.8631057739257812
Validation loss: 1.9973604474016415

Epoch: 5| Step: 3
Training loss: 1.6225049495697021
Validation loss: 2.0250037126643683

Epoch: 5| Step: 4
Training loss: 2.000108480453491
Validation loss: 2.066931051592673

Epoch: 5| Step: 5
Training loss: 1.9986110925674438
Validation loss: 2.0308104509948404

Epoch: 5| Step: 6
Training loss: 1.9466228485107422
Validation loss: 2.0454931720610587

Epoch: 5| Step: 7
Training loss: 2.4266574382781982
Validation loss: 2.027135092725036

Epoch: 5| Step: 8
Training loss: 2.2169597148895264
Validation loss: 2.040125452062135

Epoch: 5| Step: 9
Training loss: 1.856921911239624
Validation loss: 2.02053665602079

Epoch: 5| Step: 10
Training loss: 1.7688381671905518
Validation loss: 2.0260087802845943

Epoch: 208| Step: 0
Training loss: 1.8948265314102173
Validation loss: 2.039630115673106

Epoch: 5| Step: 1
Training loss: 1.5856415033340454
Validation loss: 2.0551347963271605

Epoch: 5| Step: 2
Training loss: 2.1855454444885254
Validation loss: 2.0293725511079193

Epoch: 5| Step: 3
Training loss: 1.519095540046692
Validation loss: 2.0075441765528854

Epoch: 5| Step: 4
Training loss: 2.439424991607666
Validation loss: 2.013023002173311

Epoch: 5| Step: 5
Training loss: 1.7414575815200806
Validation loss: 1.9910471541907198

Epoch: 5| Step: 6
Training loss: 1.858543038368225
Validation loss: 2.0196519154374317

Epoch: 5| Step: 7
Training loss: 2.0457205772399902
Validation loss: 2.0393660760694936

Epoch: 5| Step: 8
Training loss: 2.251695156097412
Validation loss: 2.0416199596979285

Epoch: 5| Step: 9
Training loss: 2.129361629486084
Validation loss: 2.026235904744876

Epoch: 5| Step: 10
Training loss: 2.132913827896118
Validation loss: 2.034471393913351

Epoch: 209| Step: 0
Training loss: 1.9913184642791748
Validation loss: 2.0603750380136634

Epoch: 5| Step: 1
Training loss: 2.381229877471924
Validation loss: 2.049232029145764

Epoch: 5| Step: 2
Training loss: 1.890621542930603
Validation loss: 2.0333779447822162

Epoch: 5| Step: 3
Training loss: 1.724264144897461
Validation loss: 2.050653406368789

Epoch: 5| Step: 4
Training loss: 2.1790058612823486
Validation loss: 2.038900311275195

Epoch: 5| Step: 5
Training loss: 2.15824556350708
Validation loss: 2.0557922265862905

Epoch: 5| Step: 6
Training loss: 1.710839867591858
Validation loss: 2.0385146384598105

Epoch: 5| Step: 7
Training loss: 1.5991060733795166
Validation loss: 2.0372722289895497

Epoch: 5| Step: 8
Training loss: 2.555384397506714
Validation loss: 2.0335237774797665

Epoch: 5| Step: 9
Training loss: 2.0221915245056152
Validation loss: 2.0525306014604467

Epoch: 5| Step: 10
Training loss: 1.5526703596115112
Validation loss: 2.031700271432118

Epoch: 210| Step: 0
Training loss: 1.8691589832305908
Validation loss: 2.0749854785139843

Epoch: 5| Step: 1
Training loss: 2.4290900230407715
Validation loss: 2.0312202438231437

Epoch: 5| Step: 2
Training loss: 2.134599208831787
Validation loss: 1.9880014901520104

Epoch: 5| Step: 3
Training loss: 1.7061541080474854
Validation loss: 2.0689457462679957

Epoch: 5| Step: 4
Training loss: 1.9260835647583008
Validation loss: 2.0295631475346063

Epoch: 5| Step: 5
Training loss: 1.6701780557632446
Validation loss: 2.048906563430704

Epoch: 5| Step: 6
Training loss: 1.6776268482208252
Validation loss: 2.032713540138737

Epoch: 5| Step: 7
Training loss: 2.0372402667999268
Validation loss: 2.017479342799033

Epoch: 5| Step: 8
Training loss: 1.8599283695220947
Validation loss: 2.043823879252198

Epoch: 5| Step: 9
Training loss: 2.0399787425994873
Validation loss: 2.0356772638136342

Epoch: 5| Step: 10
Training loss: 2.293924331665039
Validation loss: 2.030461185721941

Epoch: 211| Step: 0
Training loss: 1.948889970779419
Validation loss: 2.060527455422186

Epoch: 5| Step: 1
Training loss: 1.5186245441436768
Validation loss: 2.060421082281297

Epoch: 5| Step: 2
Training loss: 1.9245965480804443
Validation loss: 2.0323412726002354

Epoch: 5| Step: 3
Training loss: 2.119394302368164
Validation loss: 2.047608708822599

Epoch: 5| Step: 4
Training loss: 1.8598865270614624
Validation loss: 2.027397546716916

Epoch: 5| Step: 5
Training loss: 1.7632976770401
Validation loss: 2.0270368283794773

Epoch: 5| Step: 6
Training loss: 2.5400829315185547
Validation loss: 2.0016355514526367

Epoch: 5| Step: 7
Training loss: 2.378082752227783
Validation loss: 2.0189101952378468

Epoch: 5| Step: 8
Training loss: 1.8031244277954102
Validation loss: 2.0450121536049792

Epoch: 5| Step: 9
Training loss: 1.6461982727050781
Validation loss: 2.0326401943801553

Epoch: 5| Step: 10
Training loss: 2.103466510772705
Validation loss: 2.004810902380174

Epoch: 212| Step: 0
Training loss: 1.6483933925628662
Validation loss: 2.021056728978311

Epoch: 5| Step: 1
Training loss: 1.7533628940582275
Validation loss: 2.017530859157603

Epoch: 5| Step: 2
Training loss: 1.4251426458358765
Validation loss: 2.0610504035026795

Epoch: 5| Step: 3
Training loss: 1.7201526165008545
Validation loss: 1.9927851051412604

Epoch: 5| Step: 4
Training loss: 1.8729511499404907
Validation loss: 2.0442075114096365

Epoch: 5| Step: 5
Training loss: 2.092783212661743
Validation loss: 2.0067243294049333

Epoch: 5| Step: 6
Training loss: 2.2304351329803467
Validation loss: 2.0074531493648404

Epoch: 5| Step: 7
Training loss: 1.8892072439193726
Validation loss: 2.061630259278

Epoch: 5| Step: 8
Training loss: 1.9311624765396118
Validation loss: 2.0605239355435936

Epoch: 5| Step: 9
Training loss: 3.1972460746765137
Validation loss: 1.9982851230969993

Epoch: 5| Step: 10
Training loss: 1.6613709926605225
Validation loss: 2.0005714598522393

Epoch: 213| Step: 0
Training loss: 2.3689653873443604
Validation loss: 2.0454012155532837

Epoch: 5| Step: 1
Training loss: 1.885003685951233
Validation loss: 2.000492770184753

Epoch: 5| Step: 2
Training loss: 1.7202171087265015
Validation loss: 2.0428864776447253

Epoch: 5| Step: 3
Training loss: 1.2464549541473389
Validation loss: 2.0572987833330707

Epoch: 5| Step: 4
Training loss: 2.014493465423584
Validation loss: 2.0652477151604107

Epoch: 5| Step: 5
Training loss: 2.0655934810638428
Validation loss: 2.054970302889424

Epoch: 5| Step: 6
Training loss: 2.016451597213745
Validation loss: 2.0516605402833674

Epoch: 5| Step: 7
Training loss: 1.3860939741134644
Validation loss: 2.035369001409059

Epoch: 5| Step: 8
Training loss: 2.3354179859161377
Validation loss: 2.01270676812818

Epoch: 5| Step: 9
Training loss: 2.003596782684326
Validation loss: 2.007062059576793

Epoch: 5| Step: 10
Training loss: 2.4959356784820557
Validation loss: 2.041920828562911

Epoch: 214| Step: 0
Training loss: 2.107384204864502
Validation loss: 2.0130916718513734

Epoch: 5| Step: 1
Training loss: 2.4275963306427
Validation loss: 2.0215658705721617

Epoch: 5| Step: 2
Training loss: 2.4287617206573486
Validation loss: 2.0060329309073825

Epoch: 5| Step: 3
Training loss: 2.0317542552948
Validation loss: 2.027176110975204

Epoch: 5| Step: 4
Training loss: 1.6217063665390015
Validation loss: 2.0251961331213675

Epoch: 5| Step: 5
Training loss: 2.068107843399048
Validation loss: 2.050779519542571

Epoch: 5| Step: 6
Training loss: 1.7921221256256104
Validation loss: 2.0336680873747794

Epoch: 5| Step: 7
Training loss: 1.6961441040039062
Validation loss: 2.0485789634848155

Epoch: 5| Step: 8
Training loss: 1.7393944263458252
Validation loss: 2.0162277965135473

Epoch: 5| Step: 9
Training loss: 1.6386420726776123
Validation loss: 2.0050945922892582

Epoch: 5| Step: 10
Training loss: 2.154723644256592
Validation loss: 2.036317868899274

Epoch: 215| Step: 0
Training loss: 1.8959115743637085
Validation loss: 2.037161878360215

Epoch: 5| Step: 1
Training loss: 2.2117979526519775
Validation loss: 2.0568755185732277

Epoch: 5| Step: 2
Training loss: 1.9074859619140625
Validation loss: 2.0407764604014735

Epoch: 5| Step: 3
Training loss: 2.5276474952697754
Validation loss: 2.0701502087295696

Epoch: 5| Step: 4
Training loss: 1.9810069799423218
Validation loss: 2.040983244936953

Epoch: 5| Step: 5
Training loss: 1.63315749168396
Validation loss: 2.0041559973070697

Epoch: 5| Step: 6
Training loss: 1.8365682363510132
Validation loss: 2.0462783895513064

Epoch: 5| Step: 7
Training loss: 1.415809988975525
Validation loss: 2.0869207125838085

Epoch: 5| Step: 8
Training loss: 1.266823649406433
Validation loss: 2.0267497134465042

Epoch: 5| Step: 9
Training loss: 2.2325599193573
Validation loss: 2.028177284425305

Epoch: 5| Step: 10
Training loss: 2.7426395416259766
Validation loss: 2.0599443989415325

Epoch: 216| Step: 0
Training loss: 1.6390386819839478
Validation loss: 2.0446537104986047

Epoch: 5| Step: 1
Training loss: 2.2384705543518066
Validation loss: 2.033678895683699

Epoch: 5| Step: 2
Training loss: 2.3901963233947754
Validation loss: 2.0425504253756617

Epoch: 5| Step: 3
Training loss: 1.5724053382873535
Validation loss: 1.99884121905091

Epoch: 5| Step: 4
Training loss: 1.7482305765151978
Validation loss: 2.0427143343033327

Epoch: 5| Step: 5
Training loss: 1.8173456192016602
Validation loss: 2.0252416108244207

Epoch: 5| Step: 6
Training loss: 1.4846597909927368
Validation loss: 2.0547189763797227

Epoch: 5| Step: 7
Training loss: 1.8356914520263672
Validation loss: 2.0415997812824864

Epoch: 5| Step: 8
Training loss: 2.3276896476745605
Validation loss: 2.0117506160530993

Epoch: 5| Step: 9
Training loss: 1.8605144023895264
Validation loss: 2.044895769447409

Epoch: 5| Step: 10
Training loss: 2.4628350734710693
Validation loss: 2.0547507680872434

Epoch: 217| Step: 0
Training loss: 1.9503796100616455
Validation loss: 2.0577838472140733

Epoch: 5| Step: 1
Training loss: 1.5136945247650146
Validation loss: 2.0422005448290097

Epoch: 5| Step: 2
Training loss: 2.254026412963867
Validation loss: 2.03670532472672

Epoch: 5| Step: 3
Training loss: 2.6402587890625
Validation loss: 2.0161620314403246

Epoch: 5| Step: 4
Training loss: 1.736151933670044
Validation loss: 2.031652537725305

Epoch: 5| Step: 5
Training loss: 2.255148410797119
Validation loss: 2.007551085564398

Epoch: 5| Step: 6
Training loss: 1.482379674911499
Validation loss: 2.0151995946002264

Epoch: 5| Step: 7
Training loss: 1.2955955266952515
Validation loss: 2.0407797969797605

Epoch: 5| Step: 8
Training loss: 2.1254169940948486
Validation loss: 2.0272438090334655

Epoch: 5| Step: 9
Training loss: 2.4373152256011963
Validation loss: 2.0572822747691983

Epoch: 5| Step: 10
Training loss: 1.7381227016448975
Validation loss: 2.0145547441256944

Epoch: 218| Step: 0
Training loss: 1.6862995624542236
Validation loss: 2.0412124869644

Epoch: 5| Step: 1
Training loss: 2.5083510875701904
Validation loss: 2.039485054631387

Epoch: 5| Step: 2
Training loss: 1.9601446390151978
Validation loss: 2.0086077413251324

Epoch: 5| Step: 3
Training loss: 2.0528364181518555
Validation loss: 2.0208207817487818

Epoch: 5| Step: 4
Training loss: 1.808203935623169
Validation loss: 2.0247635764460408

Epoch: 5| Step: 5
Training loss: 2.172072410583496
Validation loss: 2.060621420542399

Epoch: 5| Step: 6
Training loss: 1.7184913158416748
Validation loss: 2.001610776429535

Epoch: 5| Step: 7
Training loss: 1.766418695449829
Validation loss: 2.0467214340804727

Epoch: 5| Step: 8
Training loss: 1.5920381546020508
Validation loss: 2.052656419815556

Epoch: 5| Step: 9
Training loss: 2.477299928665161
Validation loss: 2.0408330245684554

Epoch: 5| Step: 10
Training loss: 1.5812861919403076
Validation loss: 2.0631029144410165

Epoch: 219| Step: 0
Training loss: 2.197045087814331
Validation loss: 2.012791150359697

Epoch: 5| Step: 1
Training loss: 1.5930925607681274
Validation loss: 2.0434519513960807

Epoch: 5| Step: 2
Training loss: 1.9662110805511475
Validation loss: 2.040553335220583

Epoch: 5| Step: 3
Training loss: 1.6651369333267212
Validation loss: 2.025067126879128

Epoch: 5| Step: 4
Training loss: 2.4319655895233154
Validation loss: 2.0392353483425674

Epoch: 5| Step: 5
Training loss: 1.9777294397354126
Validation loss: 2.0277593853653118

Epoch: 5| Step: 6
Training loss: 1.7678883075714111
Validation loss: 2.0258439074280443

Epoch: 5| Step: 7
Training loss: 1.8750190734863281
Validation loss: 2.036196099814548

Epoch: 5| Step: 8
Training loss: 2.225632429122925
Validation loss: 2.029297705619566

Epoch: 5| Step: 9
Training loss: 2.421733856201172
Validation loss: 2.0137291159681094

Epoch: 5| Step: 10
Training loss: 1.1131227016448975
Validation loss: 2.035200039545695

Epoch: 220| Step: 0
Training loss: 1.8355731964111328
Validation loss: 2.0188171248282156

Epoch: 5| Step: 1
Training loss: 1.490509271621704
Validation loss: 2.0519443686290453

Epoch: 5| Step: 2
Training loss: 1.5388116836547852
Validation loss: 2.0283190588797293

Epoch: 5| Step: 3
Training loss: 2.3463284969329834
Validation loss: 2.0111709153780373

Epoch: 5| Step: 4
Training loss: 1.4390264749526978
Validation loss: 2.027651394567182

Epoch: 5| Step: 5
Training loss: 2.5885367393493652
Validation loss: 2.013264404830112

Epoch: 5| Step: 6
Training loss: 1.9724677801132202
Validation loss: 1.9898685819359236

Epoch: 5| Step: 7
Training loss: 1.6007344722747803
Validation loss: 2.0347515972711707

Epoch: 5| Step: 8
Training loss: 1.8578596115112305
Validation loss: 2.0124899853942213

Epoch: 5| Step: 9
Training loss: 2.264131546020508
Validation loss: 2.004260168280653

Epoch: 5| Step: 10
Training loss: 2.4298641681671143
Validation loss: 2.0615089324212845

Epoch: 221| Step: 0
Training loss: 1.6032276153564453
Validation loss: 1.9931260821639851

Epoch: 5| Step: 1
Training loss: 1.563976526260376
Validation loss: 2.030501006751932

Epoch: 5| Step: 2
Training loss: 1.7614209651947021
Validation loss: 2.0317528863107004

Epoch: 5| Step: 3
Training loss: 1.9285926818847656
Validation loss: 2.039189382265973

Epoch: 5| Step: 4
Training loss: 2.636526584625244
Validation loss: 2.025982560649995

Epoch: 5| Step: 5
Training loss: 2.2538394927978516
Validation loss: 2.0775737454814296

Epoch: 5| Step: 6
Training loss: 1.9833110570907593
Validation loss: 2.014996895226099

Epoch: 5| Step: 7
Training loss: 1.871249794960022
Validation loss: 2.0501454414859897

Epoch: 5| Step: 8
Training loss: 1.5575177669525146
Validation loss: 2.020828124015562

Epoch: 5| Step: 9
Training loss: 2.600189208984375
Validation loss: 2.033220805147643

Epoch: 5| Step: 10
Training loss: 1.4393227100372314
Validation loss: 2.0179695057612594

Epoch: 222| Step: 0
Training loss: 2.2639737129211426
Validation loss: 1.9985465067689137

Epoch: 5| Step: 1
Training loss: 2.7131543159484863
Validation loss: 2.0284609422888806

Epoch: 5| Step: 2
Training loss: 2.5216870307922363
Validation loss: 2.037823352762448

Epoch: 5| Step: 3
Training loss: 1.4557631015777588
Validation loss: 2.006625295967184

Epoch: 5| Step: 4
Training loss: 1.7928632497787476
Validation loss: 2.017945540848599

Epoch: 5| Step: 5
Training loss: 2.2463581562042236
Validation loss: 2.026452683633374

Epoch: 5| Step: 6
Training loss: 1.2394628524780273
Validation loss: 2.0159125686973653

Epoch: 5| Step: 7
Training loss: 1.70938241481781
Validation loss: 2.0045142045585056

Epoch: 5| Step: 8
Training loss: 2.3606951236724854
Validation loss: 2.022801968359178

Epoch: 5| Step: 9
Training loss: 1.4903602600097656
Validation loss: 2.077251899626947

Epoch: 5| Step: 10
Training loss: 1.3802945613861084
Validation loss: 2.0398973508547713

Epoch: 223| Step: 0
Training loss: 1.9566017389297485
Validation loss: 2.009052699612033

Epoch: 5| Step: 1
Training loss: 1.6230621337890625
Validation loss: 2.0260063525169127

Epoch: 5| Step: 2
Training loss: 2.53478741645813
Validation loss: 2.038682237748177

Epoch: 5| Step: 3
Training loss: 1.5469130277633667
Validation loss: 2.0198710349298294

Epoch: 5| Step: 4
Training loss: 1.8970258235931396
Validation loss: 2.0334616527762464

Epoch: 5| Step: 5
Training loss: 1.9106098413467407
Validation loss: 1.9991850327419978

Epoch: 5| Step: 6
Training loss: 1.8408758640289307
Validation loss: 2.0354670427178823

Epoch: 5| Step: 7
Training loss: 1.3471615314483643
Validation loss: 2.052389443561595

Epoch: 5| Step: 8
Training loss: 2.1263632774353027
Validation loss: 2.026502537470992

Epoch: 5| Step: 9
Training loss: 2.118821620941162
Validation loss: 2.0181426643043436

Epoch: 5| Step: 10
Training loss: 2.631331205368042
Validation loss: 1.9922280773039787

Epoch: 224| Step: 0
Training loss: 2.389997959136963
Validation loss: 2.011051975270753

Epoch: 5| Step: 1
Training loss: 2.1906485557556152
Validation loss: 1.9827459396854523

Epoch: 5| Step: 2
Training loss: 1.363228678703308
Validation loss: 2.030254284540812

Epoch: 5| Step: 3
Training loss: 2.301115036010742
Validation loss: 2.0493006116600445

Epoch: 5| Step: 4
Training loss: 1.6568024158477783
Validation loss: 2.0162608136412916

Epoch: 5| Step: 5
Training loss: 1.7517311573028564
Validation loss: 2.035366117313344

Epoch: 5| Step: 6
Training loss: 1.7338902950286865
Validation loss: 2.020386867625739

Epoch: 5| Step: 7
Training loss: 2.0870320796966553
Validation loss: 2.0268280031860515

Epoch: 5| Step: 8
Training loss: 1.5903440713882446
Validation loss: 2.0124231730737994

Epoch: 5| Step: 9
Training loss: 1.8526465892791748
Validation loss: 2.06093861979823

Epoch: 5| Step: 10
Training loss: 2.298064708709717
Validation loss: 2.003692937153642

Epoch: 225| Step: 0
Training loss: 2.1562328338623047
Validation loss: 2.034217514017577

Epoch: 5| Step: 1
Training loss: 1.487614393234253
Validation loss: 2.0079225237651537

Epoch: 5| Step: 2
Training loss: 1.759912133216858
Validation loss: 2.024132437603448

Epoch: 5| Step: 3
Training loss: 1.891115427017212
Validation loss: 2.0126310010110178

Epoch: 5| Step: 4
Training loss: 2.263307571411133
Validation loss: 2.044296735076494

Epoch: 5| Step: 5
Training loss: 1.805490493774414
Validation loss: 2.0069259956318843

Epoch: 5| Step: 6
Training loss: 1.960717797279358
Validation loss: 2.0374295852517568

Epoch: 5| Step: 7
Training loss: 1.9686203002929688
Validation loss: 2.0573084264673214

Epoch: 5| Step: 8
Training loss: 1.928741216659546
Validation loss: 2.042688118514194

Epoch: 5| Step: 9
Training loss: 2.1152124404907227
Validation loss: 2.0461732392670005

Epoch: 5| Step: 10
Training loss: 1.8678159713745117
Validation loss: 2.0549577333593882

Epoch: 226| Step: 0
Training loss: 1.8791415691375732
Validation loss: 2.064879286673761

Epoch: 5| Step: 1
Training loss: 2.0402331352233887
Validation loss: 2.025613256680068

Epoch: 5| Step: 2
Training loss: 2.0330185890197754
Validation loss: 2.0234373897634526

Epoch: 5| Step: 3
Training loss: 2.1219325065612793
Validation loss: 2.0282965860059186

Epoch: 5| Step: 4
Training loss: 2.070155382156372
Validation loss: 2.0410436686649116

Epoch: 5| Step: 5
Training loss: 1.8337352275848389
Validation loss: 2.017736796409853

Epoch: 5| Step: 6
Training loss: 1.7402715682983398
Validation loss: 2.0527452525272163

Epoch: 5| Step: 7
Training loss: 2.094123363494873
Validation loss: 2.0502833922704062

Epoch: 5| Step: 8
Training loss: 1.6197888851165771
Validation loss: 1.9995868795661516

Epoch: 5| Step: 9
Training loss: 1.1658060550689697
Validation loss: 1.9792631287728586

Epoch: 5| Step: 10
Training loss: 2.6946489810943604
Validation loss: 2.0542634712752474

Epoch: 227| Step: 0
Training loss: 1.5761255025863647
Validation loss: 2.0409536220694102

Epoch: 5| Step: 1
Training loss: 1.8016622066497803
Validation loss: 2.033347273385653

Epoch: 5| Step: 2
Training loss: 1.6153371334075928
Validation loss: 1.9947899208273938

Epoch: 5| Step: 3
Training loss: 1.8226677179336548
Validation loss: 2.0006893322031987

Epoch: 5| Step: 4
Training loss: 2.1755599975585938
Validation loss: 2.039133369281728

Epoch: 5| Step: 5
Training loss: 2.119626522064209
Validation loss: 2.0355778894116803

Epoch: 5| Step: 6
Training loss: 2.054800033569336
Validation loss: 2.0505130470439954

Epoch: 5| Step: 7
Training loss: 1.63804030418396
Validation loss: 1.9919389973404587

Epoch: 5| Step: 8
Training loss: 1.3484238386154175
Validation loss: 2.0432201380370767

Epoch: 5| Step: 9
Training loss: 2.305813789367676
Validation loss: 2.0056781929026366

Epoch: 5| Step: 10
Training loss: 2.407614231109619
Validation loss: 2.033076032515495

Epoch: 228| Step: 0
Training loss: 1.7618348598480225
Validation loss: 2.0523199599276305

Epoch: 5| Step: 1
Training loss: 1.4549345970153809
Validation loss: 2.0377316346732517

Epoch: 5| Step: 2
Training loss: 1.496559977531433
Validation loss: 2.015913042970883

Epoch: 5| Step: 3
Training loss: 2.369581937789917
Validation loss: 1.9982543401820685

Epoch: 5| Step: 4
Training loss: 1.5229358673095703
Validation loss: 2.0041684732642224

Epoch: 5| Step: 5
Training loss: 1.7623426914215088
Validation loss: 2.030896830302413

Epoch: 5| Step: 6
Training loss: 1.9855924844741821
Validation loss: 2.004860051216618

Epoch: 5| Step: 7
Training loss: 2.3909480571746826
Validation loss: 2.0014778926808345

Epoch: 5| Step: 8
Training loss: 2.4247026443481445
Validation loss: 2.0264955643684632

Epoch: 5| Step: 9
Training loss: 1.6812760829925537
Validation loss: 2.0241644151749147

Epoch: 5| Step: 10
Training loss: 2.0875298976898193
Validation loss: 2.005002539644959

Epoch: 229| Step: 0
Training loss: 1.6521037817001343
Validation loss: 2.0046122381764073

Epoch: 5| Step: 1
Training loss: 2.3612284660339355
Validation loss: 2.01101383983448

Epoch: 5| Step: 2
Training loss: 1.8578481674194336
Validation loss: 2.0432064148687545

Epoch: 5| Step: 3
Training loss: 1.5883129835128784
Validation loss: 2.0039846627942977

Epoch: 5| Step: 4
Training loss: 2.247959613800049
Validation loss: 2.0309599266257337

Epoch: 5| Step: 5
Training loss: 1.083268404006958
Validation loss: 2.019167738576089

Epoch: 5| Step: 6
Training loss: 2.5299265384674072
Validation loss: 2.0371151790823987

Epoch: 5| Step: 7
Training loss: 1.9933862686157227
Validation loss: 2.0181011487078924

Epoch: 5| Step: 8
Training loss: 1.9393974542617798
Validation loss: 2.0548001848241335

Epoch: 5| Step: 9
Training loss: 2.177943706512451
Validation loss: 1.9836360280231764

Epoch: 5| Step: 10
Training loss: 1.8063491582870483
Validation loss: 2.008182397452734

Epoch: 230| Step: 0
Training loss: 2.190469264984131
Validation loss: 2.0369716831432876

Epoch: 5| Step: 1
Training loss: 1.3326053619384766
Validation loss: 2.0573799738319973

Epoch: 5| Step: 2
Training loss: 1.9720290899276733
Validation loss: 2.0323109344769548

Epoch: 5| Step: 3
Training loss: 2.1631882190704346
Validation loss: 2.038623122758763

Epoch: 5| Step: 4
Training loss: 2.7742342948913574
Validation loss: 2.0662809751367055

Epoch: 5| Step: 5
Training loss: 1.764855980873108
Validation loss: 1.9964307290251537

Epoch: 5| Step: 6
Training loss: 1.2707980871200562
Validation loss: 2.005316456158956

Epoch: 5| Step: 7
Training loss: 2.236464023590088
Validation loss: 2.026284994617585

Epoch: 5| Step: 8
Training loss: 1.971597671508789
Validation loss: 2.032001961943924

Epoch: 5| Step: 9
Training loss: 1.3564708232879639
Validation loss: 2.0198674483965804

Epoch: 5| Step: 10
Training loss: 1.906633973121643
Validation loss: 2.0350362716182584

Epoch: 231| Step: 0
Training loss: 2.1686415672302246
Validation loss: 2.0447080673709994

Epoch: 5| Step: 1
Training loss: 2.3053689002990723
Validation loss: 2.034571241307002

Epoch: 5| Step: 2
Training loss: 1.2075592279434204
Validation loss: 2.045427512097102

Epoch: 5| Step: 3
Training loss: 1.5278441905975342
Validation loss: 2.006157216205392

Epoch: 5| Step: 4
Training loss: 1.822011947631836
Validation loss: 2.019385395511504

Epoch: 5| Step: 5
Training loss: 1.2718265056610107
Validation loss: 2.048206977946784

Epoch: 5| Step: 6
Training loss: 1.5934133529663086
Validation loss: 2.030892995096022

Epoch: 5| Step: 7
Training loss: 2.485366106033325
Validation loss: 2.044752641390729

Epoch: 5| Step: 8
Training loss: 2.0903663635253906
Validation loss: 2.0479071883745092

Epoch: 5| Step: 9
Training loss: 2.5353329181671143
Validation loss: 2.0056345924254386

Epoch: 5| Step: 10
Training loss: 1.7916860580444336
Validation loss: 2.0200213514348513

Epoch: 232| Step: 0
Training loss: 1.6255056858062744
Validation loss: 2.0263377056326917

Epoch: 5| Step: 1
Training loss: 1.9104783535003662
Validation loss: 2.004356325313609

Epoch: 5| Step: 2
Training loss: 2.068328380584717
Validation loss: 2.0157406906927786

Epoch: 5| Step: 3
Training loss: 1.6484324932098389
Validation loss: 1.980373191577132

Epoch: 5| Step: 4
Training loss: 2.2212722301483154
Validation loss: 2.0090412080928846

Epoch: 5| Step: 5
Training loss: 1.4765371084213257
Validation loss: 1.992088253780078

Epoch: 5| Step: 6
Training loss: 2.0054233074188232
Validation loss: 2.0353209177652993

Epoch: 5| Step: 7
Training loss: 2.7065722942352295
Validation loss: 2.019645788336313

Epoch: 5| Step: 8
Training loss: 1.9017083644866943
Validation loss: 2.006291372801668

Epoch: 5| Step: 9
Training loss: 1.5000401735305786
Validation loss: 1.9843424315093665

Epoch: 5| Step: 10
Training loss: 1.7084167003631592
Validation loss: 1.9702048224787558

Epoch: 233| Step: 0
Training loss: 1.5193105936050415
Validation loss: 2.049805356610206

Epoch: 5| Step: 1
Training loss: 1.80404531955719
Validation loss: 2.0136633739676526

Epoch: 5| Step: 2
Training loss: 2.22892689704895
Validation loss: 1.9829427388406569

Epoch: 5| Step: 3
Training loss: 2.0245862007141113
Validation loss: 2.0477341451952533

Epoch: 5| Step: 4
Training loss: 2.2135977745056152
Validation loss: 2.022208108696886

Epoch: 5| Step: 5
Training loss: 1.4999144077301025
Validation loss: 2.0696111661131664

Epoch: 5| Step: 6
Training loss: 2.0102922916412354
Validation loss: 2.045408155328484

Epoch: 5| Step: 7
Training loss: 1.987809181213379
Validation loss: 2.0720776486140426

Epoch: 5| Step: 8
Training loss: 2.341188907623291
Validation loss: 2.016795386550247

Epoch: 5| Step: 9
Training loss: 1.5632144212722778
Validation loss: 2.0410205805173485

Epoch: 5| Step: 10
Training loss: 1.564448595046997
Validation loss: 2.0846132129751225

Epoch: 234| Step: 0
Training loss: 1.7882812023162842
Validation loss: 2.01735524464679

Epoch: 5| Step: 1
Training loss: 1.7456655502319336
Validation loss: 2.009226870793168

Epoch: 5| Step: 2
Training loss: 1.7900667190551758
Validation loss: 2.0587625926540745

Epoch: 5| Step: 3
Training loss: 1.8973426818847656
Validation loss: 2.002611106441867

Epoch: 5| Step: 4
Training loss: 1.5233536958694458
Validation loss: 2.003083763584014

Epoch: 5| Step: 5
Training loss: 2.1253302097320557
Validation loss: 2.0076951262771443

Epoch: 5| Step: 6
Training loss: 2.011688709259033
Validation loss: 1.9845598641262259

Epoch: 5| Step: 7
Training loss: 1.800823450088501
Validation loss: 2.0497942406644105

Epoch: 5| Step: 8
Training loss: 1.9747145175933838
Validation loss: 2.017683120184047

Epoch: 5| Step: 9
Training loss: 2.4154300689697266
Validation loss: 1.9826338701350714

Epoch: 5| Step: 10
Training loss: 1.8810368776321411
Validation loss: 2.003100645157599

Epoch: 235| Step: 0
Training loss: 1.673372507095337
Validation loss: 2.036543990976067

Epoch: 5| Step: 1
Training loss: 2.08039927482605
Validation loss: 2.0436469201118714

Epoch: 5| Step: 2
Training loss: 1.805602788925171
Validation loss: 2.0511304665637273

Epoch: 5| Step: 3
Training loss: 1.6588302850723267
Validation loss: 1.982783616230052

Epoch: 5| Step: 4
Training loss: 2.339761257171631
Validation loss: 2.0051343261554675

Epoch: 5| Step: 5
Training loss: 2.1240410804748535
Validation loss: 2.0066459050742527

Epoch: 5| Step: 6
Training loss: 1.8717548847198486
Validation loss: 2.011506906119726

Epoch: 5| Step: 7
Training loss: 1.8687477111816406
Validation loss: 2.0021065717102378

Epoch: 5| Step: 8
Training loss: 1.6735241413116455
Validation loss: 2.034163251999886

Epoch: 5| Step: 9
Training loss: 1.5851956605911255
Validation loss: 2.0080074110338764

Epoch: 5| Step: 10
Training loss: 1.9431012868881226
Validation loss: 2.0060495791896695

Epoch: 236| Step: 0
Training loss: 1.8369004726409912
Validation loss: 2.019311543433897

Epoch: 5| Step: 1
Training loss: 2.0579299926757812
Validation loss: 2.0292638450540523

Epoch: 5| Step: 2
Training loss: 1.9654121398925781
Validation loss: 2.0052545916649605

Epoch: 5| Step: 3
Training loss: 1.9025523662567139
Validation loss: 2.0281039155939573

Epoch: 5| Step: 4
Training loss: 1.6048904657363892
Validation loss: 2.0223962132648756

Epoch: 5| Step: 5
Training loss: 1.3785136938095093
Validation loss: 2.043130795160929

Epoch: 5| Step: 6
Training loss: 2.2441494464874268
Validation loss: 2.03478826374136

Epoch: 5| Step: 7
Training loss: 2.054708480834961
Validation loss: 2.0143289873676915

Epoch: 5| Step: 8
Training loss: 1.809908151626587
Validation loss: 2.043550396478304

Epoch: 5| Step: 9
Training loss: 1.801428198814392
Validation loss: 2.002591530481974

Epoch: 5| Step: 10
Training loss: 2.300816297531128
Validation loss: 2.0170564318215973

Epoch: 237| Step: 0
Training loss: 1.3063037395477295
Validation loss: 2.0343294861496135

Epoch: 5| Step: 1
Training loss: 2.0378291606903076
Validation loss: 2.0170619128852763

Epoch: 5| Step: 2
Training loss: 1.9482561349868774
Validation loss: 2.0213673396777083

Epoch: 5| Step: 3
Training loss: 2.1147220134735107
Validation loss: 2.029255317103478

Epoch: 5| Step: 4
Training loss: 2.3914170265197754
Validation loss: 2.0502600336587555

Epoch: 5| Step: 5
Training loss: 1.7137435674667358
Validation loss: 2.013912393200782

Epoch: 5| Step: 6
Training loss: 1.4248313903808594
Validation loss: 1.9988241977589105

Epoch: 5| Step: 7
Training loss: 1.830959677696228
Validation loss: 2.0086490313212075

Epoch: 5| Step: 8
Training loss: 2.5424864292144775
Validation loss: 2.0377382091296616

Epoch: 5| Step: 9
Training loss: 1.7917063236236572
Validation loss: 2.0213742538165023

Epoch: 5| Step: 10
Training loss: 1.5238251686096191
Validation loss: 2.0299021351721978

Epoch: 238| Step: 0
Training loss: 1.7893604040145874
Validation loss: 2.0498574779879664

Epoch: 5| Step: 1
Training loss: 2.0268681049346924
Validation loss: 2.015362103780111

Epoch: 5| Step: 2
Training loss: 1.8112781047821045
Validation loss: 1.9962234138160624

Epoch: 5| Step: 3
Training loss: 1.5531114339828491
Validation loss: 2.038568901759322

Epoch: 5| Step: 4
Training loss: 1.7249075174331665
Validation loss: 2.024492666285525

Epoch: 5| Step: 5
Training loss: 2.556513547897339
Validation loss: 2.0442152151497464

Epoch: 5| Step: 6
Training loss: 1.9909343719482422
Validation loss: 2.029600767679112

Epoch: 5| Step: 7
Training loss: 2.08374285697937
Validation loss: 2.0145963776496147

Epoch: 5| Step: 8
Training loss: 1.1613714694976807
Validation loss: 2.062557012804093

Epoch: 5| Step: 9
Training loss: 2.2656476497650146
Validation loss: 2.0099610513256443

Epoch: 5| Step: 10
Training loss: 1.8100110292434692
Validation loss: 1.9554357541504728

Epoch: 239| Step: 0
Training loss: 1.9937183856964111
Validation loss: 2.0206960798591695

Epoch: 5| Step: 1
Training loss: 1.6144624948501587
Validation loss: 1.97911613346428

Epoch: 5| Step: 2
Training loss: 2.324455738067627
Validation loss: 2.0142256521409556

Epoch: 5| Step: 3
Training loss: 1.4645732641220093
Validation loss: 2.02751568055922

Epoch: 5| Step: 4
Training loss: 2.325416088104248
Validation loss: 2.0136953682027836

Epoch: 5| Step: 5
Training loss: 2.0472092628479004
Validation loss: 1.9791206505990797

Epoch: 5| Step: 6
Training loss: 1.732606291770935
Validation loss: 2.085820806923733

Epoch: 5| Step: 7
Training loss: 1.2090063095092773
Validation loss: 2.019642899113317

Epoch: 5| Step: 8
Training loss: 1.7017120122909546
Validation loss: 2.0361687906326784

Epoch: 5| Step: 9
Training loss: 2.0427799224853516
Validation loss: 1.9829653591238043

Epoch: 5| Step: 10
Training loss: 2.1576008796691895
Validation loss: 2.0298587596544655

Epoch: 240| Step: 0
Training loss: 2.7022693157196045
Validation loss: 1.9993359119661394

Epoch: 5| Step: 1
Training loss: 1.8171560764312744
Validation loss: 1.9859179412164996

Epoch: 5| Step: 2
Training loss: 1.35148024559021
Validation loss: 2.042396467219117

Epoch: 5| Step: 3
Training loss: 1.4979392290115356
Validation loss: 2.0216174048762166

Epoch: 5| Step: 4
Training loss: 1.8909698724746704
Validation loss: 2.0051044084692515

Epoch: 5| Step: 5
Training loss: 1.7590233087539673
Validation loss: 2.006334190727562

Epoch: 5| Step: 6
Training loss: 1.687829613685608
Validation loss: 2.002473332548654

Epoch: 5| Step: 7
Training loss: 1.9569969177246094
Validation loss: 1.984700438796833

Epoch: 5| Step: 8
Training loss: 1.5707651376724243
Validation loss: 2.049071455514559

Epoch: 5| Step: 9
Training loss: 2.272559642791748
Validation loss: 2.0511705208850164

Epoch: 5| Step: 10
Training loss: 1.8545658588409424
Validation loss: 2.0265196651540776

Epoch: 241| Step: 0
Training loss: 2.039019823074341
Validation loss: 2.055443645805441

Epoch: 5| Step: 1
Training loss: 1.9482738971710205
Validation loss: 2.024582350125877

Epoch: 5| Step: 2
Training loss: 1.9826042652130127
Validation loss: 2.0091577806780414

Epoch: 5| Step: 3
Training loss: 2.1085612773895264
Validation loss: 2.019880541550216

Epoch: 5| Step: 4
Training loss: 1.722909688949585
Validation loss: 1.9958670498222433

Epoch: 5| Step: 5
Training loss: 2.3024280071258545
Validation loss: 2.012285622217322

Epoch: 5| Step: 6
Training loss: 1.6295785903930664
Validation loss: 2.023757614115233

Epoch: 5| Step: 7
Training loss: 1.5500400066375732
Validation loss: 1.9887591023598947

Epoch: 5| Step: 8
Training loss: 1.3635343313217163
Validation loss: 1.9494967229904667

Epoch: 5| Step: 9
Training loss: 2.500134229660034
Validation loss: 2.0246891642129548

Epoch: 5| Step: 10
Training loss: 1.3631569147109985
Validation loss: 2.0038339758432038

Epoch: 242| Step: 0
Training loss: 1.7367883920669556
Validation loss: 2.004841809631676

Epoch: 5| Step: 1
Training loss: 1.5074994564056396
Validation loss: 2.0315121425095426

Epoch: 5| Step: 2
Training loss: 1.8588974475860596
Validation loss: 2.0416271981372627

Epoch: 5| Step: 3
Training loss: 2.37202787399292
Validation loss: 2.012690354419011

Epoch: 5| Step: 4
Training loss: 1.7568175792694092
Validation loss: 2.025658793346856

Epoch: 5| Step: 5
Training loss: 1.9582183361053467
Validation loss: 2.0519357676147134

Epoch: 5| Step: 6
Training loss: 1.806326150894165
Validation loss: 1.9663127019841184

Epoch: 5| Step: 7
Training loss: 2.0427134037017822
Validation loss: 2.0169187053557365

Epoch: 5| Step: 8
Training loss: 2.1590828895568848
Validation loss: 2.0142022602019773

Epoch: 5| Step: 9
Training loss: 1.4245892763137817
Validation loss: 2.0374542385019283

Epoch: 5| Step: 10
Training loss: 1.6741836071014404
Validation loss: 2.0405136551908267

Epoch: 243| Step: 0
Training loss: 1.5041478872299194
Validation loss: 2.0169153777501916

Epoch: 5| Step: 1
Training loss: 1.9561512470245361
Validation loss: 2.0233953742570776

Epoch: 5| Step: 2
Training loss: 1.9817298650741577
Validation loss: 2.0020390736159457

Epoch: 5| Step: 3
Training loss: 2.414252519607544
Validation loss: 2.0057673249193417

Epoch: 5| Step: 4
Training loss: 1.8202183246612549
Validation loss: 2.031705376922443

Epoch: 5| Step: 5
Training loss: 1.949737548828125
Validation loss: 2.0165750698376725

Epoch: 5| Step: 6
Training loss: 1.8839352130889893
Validation loss: 2.030669814796858

Epoch: 5| Step: 7
Training loss: 1.7834008932113647
Validation loss: 1.9695149044836722

Epoch: 5| Step: 8
Training loss: 1.8197076320648193
Validation loss: 2.0040658981569353

Epoch: 5| Step: 9
Training loss: 1.4897891283035278
Validation loss: 2.008403624257734

Epoch: 5| Step: 10
Training loss: 1.7064261436462402
Validation loss: 1.996359376497166

Epoch: 244| Step: 0
Training loss: 1.8898305892944336
Validation loss: 2.000732027074342

Epoch: 5| Step: 1
Training loss: 1.732067346572876
Validation loss: 2.0252205146256315

Epoch: 5| Step: 2
Training loss: 1.3976582288742065
Validation loss: 2.0095335847587994

Epoch: 5| Step: 3
Training loss: 1.9950952529907227
Validation loss: 2.0142516602752027

Epoch: 5| Step: 4
Training loss: 1.771898627281189
Validation loss: 2.023528693824686

Epoch: 5| Step: 5
Training loss: 2.508650302886963
Validation loss: 2.0202521726649296

Epoch: 5| Step: 6
Training loss: 1.2544009685516357
Validation loss: 2.036542198991263

Epoch: 5| Step: 7
Training loss: 2.1129117012023926
Validation loss: 1.9980823980864657

Epoch: 5| Step: 8
Training loss: 1.6246827840805054
Validation loss: 2.0295459429423013

Epoch: 5| Step: 9
Training loss: 1.7317851781845093
Validation loss: 2.0037205039813952

Epoch: 5| Step: 10
Training loss: 2.3376035690307617
Validation loss: 2.0445782933183896

Epoch: 245| Step: 0
Training loss: 1.4661051034927368
Validation loss: 2.0113327387840516

Epoch: 5| Step: 1
Training loss: 1.873000144958496
Validation loss: 2.014003679316531

Epoch: 5| Step: 2
Training loss: 1.7419685125350952
Validation loss: 2.049709382877555

Epoch: 5| Step: 3
Training loss: 2.074389696121216
Validation loss: 1.9945165034263366

Epoch: 5| Step: 4
Training loss: 1.7285188436508179
Validation loss: 2.0014631209834928

Epoch: 5| Step: 5
Training loss: 2.0000782012939453
Validation loss: 2.0024348881936844

Epoch: 5| Step: 6
Training loss: 2.2139892578125
Validation loss: 2.0292023228060816

Epoch: 5| Step: 7
Training loss: 1.9351847171783447
Validation loss: 2.0034904223616405

Epoch: 5| Step: 8
Training loss: 1.8088712692260742
Validation loss: 2.0444693667914278

Epoch: 5| Step: 9
Training loss: 1.8256572484970093
Validation loss: 2.003337542215983

Epoch: 5| Step: 10
Training loss: 1.7089701890945435
Validation loss: 2.0231658130563717

Epoch: 246| Step: 0
Training loss: 1.1822919845581055
Validation loss: 2.0499037824651247

Epoch: 5| Step: 1
Training loss: 2.2383241653442383
Validation loss: 2.0178597434874503

Epoch: 5| Step: 2
Training loss: 2.246051073074341
Validation loss: 1.9716862914382771

Epoch: 5| Step: 3
Training loss: 1.8772732019424438
Validation loss: 1.9817855652942453

Epoch: 5| Step: 4
Training loss: 1.6585371494293213
Validation loss: 2.0219216308286114

Epoch: 5| Step: 5
Training loss: 1.2836397886276245
Validation loss: 2.004702204017229

Epoch: 5| Step: 6
Training loss: 1.628932237625122
Validation loss: 1.9980932281863304

Epoch: 5| Step: 7
Training loss: 2.059084892272949
Validation loss: 2.0194081619221675

Epoch: 5| Step: 8
Training loss: 2.3322536945343018
Validation loss: 2.0308905481010355

Epoch: 5| Step: 9
Training loss: 2.050041675567627
Validation loss: 2.0505853429917367

Epoch: 5| Step: 10
Training loss: 1.7353715896606445
Validation loss: 2.0080259871739212

Epoch: 247| Step: 0
Training loss: 1.9799104928970337
Validation loss: 2.020500216432797

Epoch: 5| Step: 1
Training loss: 1.3182395696640015
Validation loss: 2.0266111409792336

Epoch: 5| Step: 2
Training loss: 1.9978488683700562
Validation loss: 1.9918289838298675

Epoch: 5| Step: 3
Training loss: 2.5066752433776855
Validation loss: 2.0343769699014644

Epoch: 5| Step: 4
Training loss: 1.7346620559692383
Validation loss: 1.9897734644592449

Epoch: 5| Step: 5
Training loss: 2.2712740898132324
Validation loss: 2.032144031217021

Epoch: 5| Step: 6
Training loss: 1.6940784454345703
Validation loss: 2.0379987711547525

Epoch: 5| Step: 7
Training loss: 1.6323444843292236
Validation loss: 2.051535621766121

Epoch: 5| Step: 8
Training loss: 1.7782642841339111
Validation loss: 1.9866994837278962

Epoch: 5| Step: 9
Training loss: 2.0520548820495605
Validation loss: 2.034601631984916

Epoch: 5| Step: 10
Training loss: 1.382615089416504
Validation loss: 1.9879264575178905

Epoch: 248| Step: 0
Training loss: 2.3763511180877686
Validation loss: 2.0073308239700975

Epoch: 5| Step: 1
Training loss: 1.5627599954605103
Validation loss: 2.023077021362961

Epoch: 5| Step: 2
Training loss: 2.0096123218536377
Validation loss: 1.9889140000907324

Epoch: 5| Step: 3
Training loss: 1.6305649280548096
Validation loss: 2.047473403715318

Epoch: 5| Step: 4
Training loss: 1.8900337219238281
Validation loss: 2.0487379322769823

Epoch: 5| Step: 5
Training loss: 2.4546685218811035
Validation loss: 2.0264002764096825

Epoch: 5| Step: 6
Training loss: 1.6575305461883545
Validation loss: 2.0021000882630706

Epoch: 5| Step: 7
Training loss: 1.5549179315567017
Validation loss: 2.0753430153733943

Epoch: 5| Step: 8
Training loss: 1.7763574123382568
Validation loss: 2.029776270671557

Epoch: 5| Step: 9
Training loss: 1.508198618888855
Validation loss: 2.0381719604615243

Epoch: 5| Step: 10
Training loss: 1.5108050107955933
Validation loss: 2.0591663032449703

Epoch: 249| Step: 0
Training loss: 2.326174736022949
Validation loss: 2.0497883058363393

Epoch: 5| Step: 1
Training loss: 2.087738513946533
Validation loss: 2.043168911369898

Epoch: 5| Step: 2
Training loss: 1.4883846044540405
Validation loss: 2.025451542228781

Epoch: 5| Step: 3
Training loss: 1.7767956256866455
Validation loss: 2.0428729159857637

Epoch: 5| Step: 4
Training loss: 2.3060381412506104
Validation loss: 2.0378664462797103

Epoch: 5| Step: 5
Training loss: 0.9108787775039673
Validation loss: 2.0128110685656146

Epoch: 5| Step: 6
Training loss: 1.7834011316299438
Validation loss: 2.0109682570221605

Epoch: 5| Step: 7
Training loss: 1.5214792490005493
Validation loss: 2.0200723243016068

Epoch: 5| Step: 8
Training loss: 1.559117078781128
Validation loss: 2.012076054849932

Epoch: 5| Step: 9
Training loss: 2.277308464050293
Validation loss: 2.0001001306759414

Epoch: 5| Step: 10
Training loss: 2.0467138290405273
Validation loss: 1.9839252015595794

Epoch: 250| Step: 0
Training loss: 1.3573402166366577
Validation loss: 2.0129830183521396

Epoch: 5| Step: 1
Training loss: 1.9419265985488892
Validation loss: 2.026853626774203

Epoch: 5| Step: 2
Training loss: 1.7683547735214233
Validation loss: 2.0194420763241347

Epoch: 5| Step: 3
Training loss: 1.781354546546936
Validation loss: 2.0076735814412436

Epoch: 5| Step: 4
Training loss: 1.8077051639556885
Validation loss: 1.9983676889891266

Epoch: 5| Step: 5
Training loss: 1.8511844873428345
Validation loss: 2.024646928233485

Epoch: 5| Step: 6
Training loss: 2.1366677284240723
Validation loss: 2.065242692988406

Epoch: 5| Step: 7
Training loss: 1.5444780588150024
Validation loss: 2.021925608317057

Epoch: 5| Step: 8
Training loss: 2.007479429244995
Validation loss: 2.039953649684947

Epoch: 5| Step: 9
Training loss: 2.0680136680603027
Validation loss: 1.9823015095085226

Epoch: 5| Step: 10
Training loss: 1.9861501455307007
Validation loss: 1.9582183437962686

Epoch: 251| Step: 0
Training loss: 1.66396963596344
Validation loss: 2.040806554978894

Epoch: 5| Step: 1
Training loss: 1.4872100353240967
Validation loss: 2.0608947533433155

Epoch: 5| Step: 2
Training loss: 1.8651241064071655
Validation loss: 1.998933587023007

Epoch: 5| Step: 3
Training loss: 1.7482872009277344
Validation loss: 2.0235071925706762

Epoch: 5| Step: 4
Training loss: 1.9946445226669312
Validation loss: 2.0110886942955757

Epoch: 5| Step: 5
Training loss: 2.715941905975342
Validation loss: 1.9992334073589695

Epoch: 5| Step: 6
Training loss: 1.6204992532730103
Validation loss: 1.9976147041525891

Epoch: 5| Step: 7
Training loss: 1.2489845752716064
Validation loss: 1.9833375664167507

Epoch: 5| Step: 8
Training loss: 2.468156337738037
Validation loss: 2.0524931056525118

Epoch: 5| Step: 9
Training loss: 1.771851897239685
Validation loss: 2.0193563571540256

Epoch: 5| Step: 10
Training loss: 1.5012438297271729
Validation loss: 2.0778819925041607

Epoch: 252| Step: 0
Training loss: 2.1362013816833496
Validation loss: 2.0374740759531655

Epoch: 5| Step: 1
Training loss: 1.1863740682601929
Validation loss: 2.0447953862528645

Epoch: 5| Step: 2
Training loss: 1.8019821643829346
Validation loss: 1.9773410853519235

Epoch: 5| Step: 3
Training loss: 1.601189374923706
Validation loss: 2.0283248809076126

Epoch: 5| Step: 4
Training loss: 1.3817522525787354
Validation loss: 2.007339177593108

Epoch: 5| Step: 5
Training loss: 1.9092810153961182
Validation loss: 2.0356247271260908

Epoch: 5| Step: 6
Training loss: 1.2839303016662598
Validation loss: 2.018023754960747

Epoch: 5| Step: 7
Training loss: 2.315622568130493
Validation loss: 2.0552299637948312

Epoch: 5| Step: 8
Training loss: 2.133760452270508
Validation loss: 2.0238066539969495

Epoch: 5| Step: 9
Training loss: 2.0055909156799316
Validation loss: 2.006862496816984

Epoch: 5| Step: 10
Training loss: 2.371594190597534
Validation loss: 2.0304054380745016

Epoch: 253| Step: 0
Training loss: 1.8938509225845337
Validation loss: 2.080660517497729

Epoch: 5| Step: 1
Training loss: 1.8842051029205322
Validation loss: 2.0544702801653134

Epoch: 5| Step: 2
Training loss: 2.2640366554260254
Validation loss: 2.0432137930265037

Epoch: 5| Step: 3
Training loss: 1.8426294326782227
Validation loss: 2.0139101551425074

Epoch: 5| Step: 4
Training loss: 2.5536956787109375
Validation loss: 1.9994258752433203

Epoch: 5| Step: 5
Training loss: 1.445357322692871
Validation loss: 2.0086090410909345

Epoch: 5| Step: 6
Training loss: 1.5353612899780273
Validation loss: 2.0197526844598914

Epoch: 5| Step: 7
Training loss: 1.707066535949707
Validation loss: 2.0149494358288345

Epoch: 5| Step: 8
Training loss: 1.5198204517364502
Validation loss: 2.0242417268855597

Epoch: 5| Step: 9
Training loss: 1.834388017654419
Validation loss: 2.035166269989424

Epoch: 5| Step: 10
Training loss: 1.3646743297576904
Validation loss: 2.0323691252739198

Epoch: 254| Step: 0
Training loss: 1.4519420862197876
Validation loss: 2.048631052817068

Epoch: 5| Step: 1
Training loss: 2.042171001434326
Validation loss: 2.0400811920883837

Epoch: 5| Step: 2
Training loss: 1.3697607517242432
Validation loss: 2.0301105001921296

Epoch: 5| Step: 3
Training loss: 1.7854417562484741
Validation loss: 2.019086883914086

Epoch: 5| Step: 4
Training loss: 1.8876268863677979
Validation loss: 1.9960986145081059

Epoch: 5| Step: 5
Training loss: 1.8294761180877686
Validation loss: 2.0035474172202488

Epoch: 5| Step: 6
Training loss: 2.108944892883301
Validation loss: 2.0290413313014533

Epoch: 5| Step: 7
Training loss: 2.1986188888549805
Validation loss: 2.0463193488377396

Epoch: 5| Step: 8
Training loss: 1.821438193321228
Validation loss: 2.0025902037979453

Epoch: 5| Step: 9
Training loss: 1.7004120349884033
Validation loss: 2.013263766483594

Epoch: 5| Step: 10
Training loss: 1.4521070718765259
Validation loss: 1.9977547994223974

Epoch: 255| Step: 0
Training loss: 1.7834879159927368
Validation loss: 1.9768637534110778

Epoch: 5| Step: 1
Training loss: 1.2451355457305908
Validation loss: 2.040739159430227

Epoch: 5| Step: 2
Training loss: 1.9468815326690674
Validation loss: 2.0233319344059115

Epoch: 5| Step: 3
Training loss: 2.2594470977783203
Validation loss: 2.0271109483575307

Epoch: 5| Step: 4
Training loss: 1.8670648336410522
Validation loss: 2.013771169929094

Epoch: 5| Step: 5
Training loss: 2.055382013320923
Validation loss: 2.004754343340474

Epoch: 5| Step: 6
Training loss: 1.8001590967178345
Validation loss: 2.0073130335859073

Epoch: 5| Step: 7
Training loss: 2.0335302352905273
Validation loss: 2.033541173063299

Epoch: 5| Step: 8
Training loss: 1.661624550819397
Validation loss: 2.0345207491228656

Epoch: 5| Step: 9
Training loss: 1.608803153038025
Validation loss: 2.035508281441145

Epoch: 5| Step: 10
Training loss: 1.720616340637207
Validation loss: 2.006773030886086

Epoch: 256| Step: 0
Training loss: 1.951847791671753
Validation loss: 2.020415118945542

Epoch: 5| Step: 1
Training loss: 1.8099123239517212
Validation loss: 2.0138063712786605

Epoch: 5| Step: 2
Training loss: 1.7405115365982056
Validation loss: 2.0212756420976374

Epoch: 5| Step: 3
Training loss: 1.6174980401992798
Validation loss: 2.038919028415475

Epoch: 5| Step: 4
Training loss: 1.4433538913726807
Validation loss: 2.0440802420339277

Epoch: 5| Step: 5
Training loss: 1.3939510583877563
Validation loss: 1.992262650561589

Epoch: 5| Step: 6
Training loss: 2.1097099781036377
Validation loss: 2.0102218248510875

Epoch: 5| Step: 7
Training loss: 2.1892223358154297
Validation loss: 2.07144509848728

Epoch: 5| Step: 8
Training loss: 1.766932725906372
Validation loss: 2.044627893355585

Epoch: 5| Step: 9
Training loss: 1.4493725299835205
Validation loss: 2.0170422753980084

Epoch: 5| Step: 10
Training loss: 2.1988046169281006
Validation loss: 1.976507140744117

Epoch: 257| Step: 0
Training loss: 1.590253472328186
Validation loss: 2.0134937096667547

Epoch: 5| Step: 1
Training loss: 1.8183491230010986
Validation loss: 1.9507826451332337

Epoch: 5| Step: 2
Training loss: 1.8714739084243774
Validation loss: 2.012472004018804

Epoch: 5| Step: 3
Training loss: 1.619400978088379
Validation loss: 2.0259016483060774

Epoch: 5| Step: 4
Training loss: 1.6846338510513306
Validation loss: 1.9604830741882324

Epoch: 5| Step: 5
Training loss: 1.9531368017196655
Validation loss: 2.030268822946856

Epoch: 5| Step: 6
Training loss: 1.4269154071807861
Validation loss: 2.0329239150529266

Epoch: 5| Step: 7
Training loss: 1.84005868434906
Validation loss: 2.018952949072725

Epoch: 5| Step: 8
Training loss: 1.9357948303222656
Validation loss: 2.0037121772766113

Epoch: 5| Step: 9
Training loss: 2.2738118171691895
Validation loss: 2.0068194558543544

Epoch: 5| Step: 10
Training loss: 1.9897222518920898
Validation loss: 2.010841957984432

Epoch: 258| Step: 0
Training loss: 2.0149619579315186
Validation loss: 2.039821378646358

Epoch: 5| Step: 1
Training loss: 1.9680696725845337
Validation loss: 2.0409811953062653

Epoch: 5| Step: 2
Training loss: 1.7999225854873657
Validation loss: 2.0125351131603284

Epoch: 5| Step: 3
Training loss: 1.6447376012802124
Validation loss: 1.980568851194074

Epoch: 5| Step: 4
Training loss: 1.143988847732544
Validation loss: 2.0618109421063493

Epoch: 5| Step: 5
Training loss: 1.522881269454956
Validation loss: 2.033393262535013

Epoch: 5| Step: 6
Training loss: 2.088975191116333
Validation loss: 1.9658391847405383

Epoch: 5| Step: 7
Training loss: 1.4872500896453857
Validation loss: 1.9923031637745519

Epoch: 5| Step: 8
Training loss: 2.3135266304016113
Validation loss: 1.9950709817230061

Epoch: 5| Step: 9
Training loss: 1.9501594305038452
Validation loss: 2.012205082883117

Epoch: 5| Step: 10
Training loss: 2.2353806495666504
Validation loss: 2.0345703991510535

Epoch: 259| Step: 0
Training loss: 2.2949252128601074
Validation loss: 1.98546600854525

Epoch: 5| Step: 1
Training loss: 1.4811116456985474
Validation loss: 1.9455947209429998

Epoch: 5| Step: 2
Training loss: 1.5470550060272217
Validation loss: 2.0230964511953373

Epoch: 5| Step: 3
Training loss: 1.7047302722930908
Validation loss: 1.9766357252674718

Epoch: 5| Step: 4
Training loss: 1.8822848796844482
Validation loss: 1.997945039503036

Epoch: 5| Step: 5
Training loss: 1.7738374471664429
Validation loss: 2.0646713292726906

Epoch: 5| Step: 6
Training loss: 1.5911329984664917
Validation loss: 2.0340214185817267

Epoch: 5| Step: 7
Training loss: 1.713226556777954
Validation loss: 2.036299946487591

Epoch: 5| Step: 8
Training loss: 2.208327531814575
Validation loss: 2.006785782434607

Epoch: 5| Step: 9
Training loss: 2.153751850128174
Validation loss: 1.9821230634566276

Epoch: 5| Step: 10
Training loss: 1.235985517501831
Validation loss: 2.0051025011206187

Epoch: 260| Step: 0
Training loss: 1.938818335533142
Validation loss: 2.0351316005952897

Epoch: 5| Step: 1
Training loss: 1.8133885860443115
Validation loss: 1.9880007415689447

Epoch: 5| Step: 2
Training loss: 1.4997358322143555
Validation loss: 1.9995616994878298

Epoch: 5| Step: 3
Training loss: 2.036278486251831
Validation loss: 1.9908655433244602

Epoch: 5| Step: 4
Training loss: 1.921539306640625
Validation loss: 1.9985787189134987

Epoch: 5| Step: 5
Training loss: 1.4587445259094238
Validation loss: 2.039716971817837

Epoch: 5| Step: 6
Training loss: 2.7929227352142334
Validation loss: 1.9715882937113445

Epoch: 5| Step: 7
Training loss: 1.3248765468597412
Validation loss: 2.013723200367343

Epoch: 5| Step: 8
Training loss: 1.491509199142456
Validation loss: 2.0008622472004225

Epoch: 5| Step: 9
Training loss: 0.990146279335022
Validation loss: 2.069287428291895

Epoch: 5| Step: 10
Training loss: 2.159775495529175
Validation loss: 2.0374839075150026

Epoch: 261| Step: 0
Training loss: 1.7154312133789062
Validation loss: 1.9991564571216542

Epoch: 5| Step: 1
Training loss: 1.9942855834960938
Validation loss: 2.01609545112938

Epoch: 5| Step: 2
Training loss: 2.151832103729248
Validation loss: 1.9771242680088166

Epoch: 5| Step: 3
Training loss: 1.2768049240112305
Validation loss: 2.018317109795027

Epoch: 5| Step: 4
Training loss: 1.878737449645996
Validation loss: 2.020612603874617

Epoch: 5| Step: 5
Training loss: 1.2167072296142578
Validation loss: 2.0461580984054075

Epoch: 5| Step: 6
Training loss: 2.4003663063049316
Validation loss: 2.0513429974996917

Epoch: 5| Step: 7
Training loss: 1.8715146780014038
Validation loss: 1.9944348130174863

Epoch: 5| Step: 8
Training loss: 1.7925841808319092
Validation loss: 1.9947286190525177

Epoch: 5| Step: 9
Training loss: 1.8682552576065063
Validation loss: 1.9976697044987832

Epoch: 5| Step: 10
Training loss: 1.470567226409912
Validation loss: 1.9826105781780776

Epoch: 262| Step: 0
Training loss: 2.4089672565460205
Validation loss: 2.0233356055393013

Epoch: 5| Step: 1
Training loss: 1.5944279432296753
Validation loss: 2.017504028094712

Epoch: 5| Step: 2
Training loss: 1.8752580881118774
Validation loss: 2.0100448849380657

Epoch: 5| Step: 3
Training loss: 2.0576324462890625
Validation loss: 2.025346158653177

Epoch: 5| Step: 4
Training loss: 1.6077251434326172
Validation loss: 1.9973011657755861

Epoch: 5| Step: 5
Training loss: 1.7208354473114014
Validation loss: 1.997556080100357

Epoch: 5| Step: 6
Training loss: 1.4477894306182861
Validation loss: 1.9769251743952434

Epoch: 5| Step: 7
Training loss: 2.107929229736328
Validation loss: 2.033324251892746

Epoch: 5| Step: 8
Training loss: 1.5910323858261108
Validation loss: 2.0273622120580366

Epoch: 5| Step: 9
Training loss: 1.6377861499786377
Validation loss: 1.9944998102803384

Epoch: 5| Step: 10
Training loss: 1.7779107093811035
Validation loss: 2.0074399619974117

Epoch: 263| Step: 0
Training loss: 1.586177110671997
Validation loss: 1.9920282133163945

Epoch: 5| Step: 1
Training loss: 1.804968237876892
Validation loss: 2.02292900828905

Epoch: 5| Step: 2
Training loss: 1.400208592414856
Validation loss: 2.035375496392609

Epoch: 5| Step: 3
Training loss: 1.3294498920440674
Validation loss: 1.9708564076372372

Epoch: 5| Step: 4
Training loss: 1.5044176578521729
Validation loss: 2.0635236386329896

Epoch: 5| Step: 5
Training loss: 1.9035991430282593
Validation loss: 2.037378026593116

Epoch: 5| Step: 6
Training loss: 1.8242963552474976
Validation loss: 2.0502680809267106

Epoch: 5| Step: 7
Training loss: 1.9003651142120361
Validation loss: 2.0468195048711633

Epoch: 5| Step: 8
Training loss: 1.9556610584259033
Validation loss: 2.0032486813042754

Epoch: 5| Step: 9
Training loss: 2.207287549972534
Validation loss: 1.9912952915314706

Epoch: 5| Step: 10
Training loss: 1.7375134229660034
Validation loss: 2.029311469806138

Epoch: 264| Step: 0
Training loss: 1.7080914974212646
Validation loss: 1.9976649643272482

Epoch: 5| Step: 1
Training loss: 1.545915961265564
Validation loss: 1.990889408255136

Epoch: 5| Step: 2
Training loss: 1.9938873052597046
Validation loss: 2.0351958787569435

Epoch: 5| Step: 3
Training loss: 1.2510563135147095
Validation loss: 2.0113675350783975

Epoch: 5| Step: 4
Training loss: 1.7250721454620361
Validation loss: 2.0002340603900213

Epoch: 5| Step: 5
Training loss: 1.917759656906128
Validation loss: 2.006316484943513

Epoch: 5| Step: 6
Training loss: 1.4434834718704224
Validation loss: 1.981930935254661

Epoch: 5| Step: 7
Training loss: 2.2102556228637695
Validation loss: 2.0121174730280393

Epoch: 5| Step: 8
Training loss: 1.255111575126648
Validation loss: 2.031932903874305

Epoch: 5| Step: 9
Training loss: 1.2961887121200562
Validation loss: 1.9776573437516407

Epoch: 5| Step: 10
Training loss: 3.2181947231292725
Validation loss: 2.0342990095897386

Epoch: 265| Step: 0
Training loss: 1.8167552947998047
Validation loss: 1.9927297458853772

Epoch: 5| Step: 1
Training loss: 1.723493218421936
Validation loss: 1.990775997920703

Epoch: 5| Step: 2
Training loss: 1.9437930583953857
Validation loss: 2.008828725866092

Epoch: 5| Step: 3
Training loss: 2.0561108589172363
Validation loss: 2.041324133514076

Epoch: 5| Step: 4
Training loss: 1.6509273052215576
Validation loss: 2.098892334968813

Epoch: 5| Step: 5
Training loss: 1.244296908378601
Validation loss: 2.024200593271563

Epoch: 5| Step: 6
Training loss: 1.7272764444351196
Validation loss: 2.0143828981666156

Epoch: 5| Step: 7
Training loss: 1.8009933233261108
Validation loss: 1.9949929688566475

Epoch: 5| Step: 8
Training loss: 1.582668423652649
Validation loss: 2.0611144265820904

Epoch: 5| Step: 9
Training loss: 2.049048900604248
Validation loss: 1.9928232674957604

Epoch: 5| Step: 10
Training loss: 1.7532765865325928
Validation loss: 1.9837212101105721

Epoch: 266| Step: 0
Training loss: 2.2638847827911377
Validation loss: 2.012090895765571

Epoch: 5| Step: 1
Training loss: 1.9325844049453735
Validation loss: 2.0033612148736113

Epoch: 5| Step: 2
Training loss: 1.6338865756988525
Validation loss: 2.0402659754599295

Epoch: 5| Step: 3
Training loss: 2.022672176361084
Validation loss: 2.0469318615492953

Epoch: 5| Step: 4
Training loss: 1.836758017539978
Validation loss: 1.9879003878562682

Epoch: 5| Step: 5
Training loss: 1.947104811668396
Validation loss: 2.00171495509404

Epoch: 5| Step: 6
Training loss: 1.5749690532684326
Validation loss: 2.0583828162121516

Epoch: 5| Step: 7
Training loss: 1.3162977695465088
Validation loss: 2.031262574657317

Epoch: 5| Step: 8
Training loss: 1.3205944299697876
Validation loss: 1.9990127778822375

Epoch: 5| Step: 9
Training loss: 1.9215776920318604
Validation loss: 1.9791605831474386

Epoch: 5| Step: 10
Training loss: 1.4886980056762695
Validation loss: 2.0351946328275945

Epoch: 267| Step: 0
Training loss: 1.2614374160766602
Validation loss: 2.0266321500142417

Epoch: 5| Step: 1
Training loss: 2.163036823272705
Validation loss: 1.9799811429874872

Epoch: 5| Step: 2
Training loss: 1.5572240352630615
Validation loss: 2.011262152784614

Epoch: 5| Step: 3
Training loss: 2.0718910694122314
Validation loss: 2.021566584546079

Epoch: 5| Step: 4
Training loss: 1.863576889038086
Validation loss: 2.0492855246349047

Epoch: 5| Step: 5
Training loss: 1.528949499130249
Validation loss: 1.9845744281686761

Epoch: 5| Step: 6
Training loss: 2.305849552154541
Validation loss: 2.032697921158165

Epoch: 5| Step: 7
Training loss: 1.8022123575210571
Validation loss: 2.0542134136281986

Epoch: 5| Step: 8
Training loss: 1.1435058116912842
Validation loss: 2.0125672753139208

Epoch: 5| Step: 9
Training loss: 2.0086779594421387
Validation loss: 2.0683791727148075

Epoch: 5| Step: 10
Training loss: 1.8085891008377075
Validation loss: 2.0052930821654615

Epoch: 268| Step: 0
Training loss: 1.8998626470565796
Validation loss: 1.9681772442274197

Epoch: 5| Step: 1
Training loss: 1.970893144607544
Validation loss: 2.037192097274206

Epoch: 5| Step: 2
Training loss: 2.0892128944396973
Validation loss: 1.9380262564587336

Epoch: 5| Step: 3
Training loss: 1.1032823324203491
Validation loss: 2.0322863568541822

Epoch: 5| Step: 4
Training loss: 1.1952234506607056
Validation loss: 2.008955714523151

Epoch: 5| Step: 5
Training loss: 1.8112857341766357
Validation loss: 2.026471450764646

Epoch: 5| Step: 6
Training loss: 1.8001930713653564
Validation loss: 2.016441032450686

Epoch: 5| Step: 7
Training loss: 1.9896522760391235
Validation loss: 2.002793122363347

Epoch: 5| Step: 8
Training loss: 1.944034218788147
Validation loss: 2.025392746412626

Epoch: 5| Step: 9
Training loss: 1.9077978134155273
Validation loss: 2.0177765738579536

Epoch: 5| Step: 10
Training loss: 2.080427885055542
Validation loss: 1.9922712131213116

Epoch: 269| Step: 0
Training loss: 1.3445074558258057
Validation loss: 2.0205878314151557

Epoch: 5| Step: 1
Training loss: 1.6606643199920654
Validation loss: 1.9750115153610066

Epoch: 5| Step: 2
Training loss: 1.7195619344711304
Validation loss: 2.031156175880022

Epoch: 5| Step: 3
Training loss: 1.4870259761810303
Validation loss: 1.9959592088576286

Epoch: 5| Step: 4
Training loss: 1.6515964269638062
Validation loss: 2.010209306593864

Epoch: 5| Step: 5
Training loss: 2.4664859771728516
Validation loss: 1.960273717039375

Epoch: 5| Step: 6
Training loss: 1.6393728256225586
Validation loss: 2.0309351234025854

Epoch: 5| Step: 7
Training loss: 2.464733123779297
Validation loss: 2.0193005172155236

Epoch: 5| Step: 8
Training loss: 1.2682002782821655
Validation loss: 2.024382660465856

Epoch: 5| Step: 9
Training loss: 1.7290433645248413
Validation loss: 2.037788603895454

Epoch: 5| Step: 10
Training loss: 1.791272521018982
Validation loss: 2.0148471081128685

Epoch: 270| Step: 0
Training loss: 1.3833348751068115
Validation loss: 2.00729117854949

Epoch: 5| Step: 1
Training loss: 1.1054894924163818
Validation loss: 2.002517887341079

Epoch: 5| Step: 2
Training loss: 1.7419865131378174
Validation loss: 2.015419119147844

Epoch: 5| Step: 3
Training loss: 1.961586356163025
Validation loss: 2.0176500953653806

Epoch: 5| Step: 4
Training loss: 2.3187098503112793
Validation loss: 1.9834767054486018

Epoch: 5| Step: 5
Training loss: 2.55537748336792
Validation loss: 1.99571317754766

Epoch: 5| Step: 6
Training loss: 1.63924241065979
Validation loss: 2.0136742848221973

Epoch: 5| Step: 7
Training loss: 1.6785905361175537
Validation loss: 2.043909352312806

Epoch: 5| Step: 8
Training loss: 1.5678291320800781
Validation loss: 2.0537293021396925

Epoch: 5| Step: 9
Training loss: 1.407485008239746
Validation loss: 2.054048974026916

Epoch: 5| Step: 10
Training loss: 1.9978657960891724
Validation loss: 2.0051483236333376

Epoch: 271| Step: 0
Training loss: 1.8741222620010376
Validation loss: 2.022687291586271

Epoch: 5| Step: 1
Training loss: 1.4587327241897583
Validation loss: 2.0324058622442265

Epoch: 5| Step: 2
Training loss: 2.654963970184326
Validation loss: 2.025543720491471

Epoch: 5| Step: 3
Training loss: 1.5804210901260376
Validation loss: 1.9983313570740402

Epoch: 5| Step: 4
Training loss: 2.755303144454956
Validation loss: 2.0426768038862493

Epoch: 5| Step: 5
Training loss: 1.2990354299545288
Validation loss: 1.9987473000762284

Epoch: 5| Step: 6
Training loss: 1.5962120294570923
Validation loss: 2.0448609885349067

Epoch: 5| Step: 7
Training loss: 1.3637009859085083
Validation loss: 1.9733992750926683

Epoch: 5| Step: 8
Training loss: 1.7396290302276611
Validation loss: 1.9991183460399669

Epoch: 5| Step: 9
Training loss: 1.290361762046814
Validation loss: 1.958897609864512

Epoch: 5| Step: 10
Training loss: 1.4352226257324219
Validation loss: 2.05182368909159

Epoch: 272| Step: 0
Training loss: 1.105787992477417
Validation loss: 1.971233029519358

Epoch: 5| Step: 1
Training loss: 1.883095383644104
Validation loss: 1.9938983686508671

Epoch: 5| Step: 2
Training loss: 2.0178110599517822
Validation loss: 1.9628584679736887

Epoch: 5| Step: 3
Training loss: 1.7315012216567993
Validation loss: 1.9839401552754063

Epoch: 5| Step: 4
Training loss: 1.7196012735366821
Validation loss: 2.0021304199772496

Epoch: 5| Step: 5
Training loss: 1.8970378637313843
Validation loss: 1.9981048671148156

Epoch: 5| Step: 6
Training loss: 2.272700309753418
Validation loss: 1.9693711137258878

Epoch: 5| Step: 7
Training loss: 1.7291576862335205
Validation loss: 1.992072461753763

Epoch: 5| Step: 8
Training loss: 1.6533594131469727
Validation loss: 1.9850926668413225

Epoch: 5| Step: 9
Training loss: 1.7093864679336548
Validation loss: 2.007789998926142

Epoch: 5| Step: 10
Training loss: 1.1264455318450928
Validation loss: 1.9915384810457948

Epoch: 273| Step: 0
Training loss: 1.713381052017212
Validation loss: 2.028930373089288

Epoch: 5| Step: 1
Training loss: 1.503826379776001
Validation loss: 2.0367457559031825

Epoch: 5| Step: 2
Training loss: 1.9560524225234985
Validation loss: 2.024659491354419

Epoch: 5| Step: 3
Training loss: 2.7304816246032715
Validation loss: 1.9981668661999445

Epoch: 5| Step: 4
Training loss: 1.6916351318359375
Validation loss: 2.018747925758362

Epoch: 5| Step: 5
Training loss: 1.412889003753662
Validation loss: 1.9931032119258758

Epoch: 5| Step: 6
Training loss: 1.1281440258026123
Validation loss: 2.0159073029795

Epoch: 5| Step: 7
Training loss: 1.8317115306854248
Validation loss: 1.9818061987559001

Epoch: 5| Step: 8
Training loss: 2.0177345275878906
Validation loss: 2.0294579882775583

Epoch: 5| Step: 9
Training loss: 1.9104557037353516
Validation loss: 2.0289096434911094

Epoch: 5| Step: 10
Training loss: 1.147998332977295
Validation loss: 2.011081252046811

Epoch: 274| Step: 0
Training loss: 1.9308414459228516
Validation loss: 1.9853445573519635

Epoch: 5| Step: 1
Training loss: 1.668540596961975
Validation loss: 2.015724379529235

Epoch: 5| Step: 2
Training loss: 1.8181114196777344
Validation loss: 2.018209071569545

Epoch: 5| Step: 3
Training loss: 2.3611655235290527
Validation loss: 1.9604042037840812

Epoch: 5| Step: 4
Training loss: 1.5081628561019897
Validation loss: 1.9762400068262571

Epoch: 5| Step: 5
Training loss: 1.3697659969329834
Validation loss: 1.9818182824760355

Epoch: 5| Step: 6
Training loss: 1.4246327877044678
Validation loss: 2.0204509022415325

Epoch: 5| Step: 7
Training loss: 1.6938343048095703
Validation loss: 1.960181108085058

Epoch: 5| Step: 8
Training loss: 1.6901788711547852
Validation loss: 1.9729962938575334

Epoch: 5| Step: 9
Training loss: 1.9087918996810913
Validation loss: 2.044685258660265

Epoch: 5| Step: 10
Training loss: 1.3224915266036987
Validation loss: 1.9613503230515348

Epoch: 275| Step: 0
Training loss: 1.8528144359588623
Validation loss: 2.0197655180449128

Epoch: 5| Step: 1
Training loss: 1.9388166666030884
Validation loss: 1.985078510417733

Epoch: 5| Step: 2
Training loss: 2.082200050354004
Validation loss: 2.0016299909160984

Epoch: 5| Step: 3
Training loss: 1.8138401508331299
Validation loss: 2.02075546274903

Epoch: 5| Step: 4
Training loss: 1.2786785364151
Validation loss: 1.9970228569481963

Epoch: 5| Step: 5
Training loss: 1.4485833644866943
Validation loss: 2.0142626198389197

Epoch: 5| Step: 6
Training loss: 1.844239592552185
Validation loss: 2.005099053023964

Epoch: 5| Step: 7
Training loss: 1.010304570198059
Validation loss: 2.014665829238071

Epoch: 5| Step: 8
Training loss: 1.9983934164047241
Validation loss: 1.9672234058380127

Epoch: 5| Step: 9
Training loss: 2.3025660514831543
Validation loss: 1.9861427199455999

Epoch: 5| Step: 10
Training loss: 1.6916133165359497
Validation loss: 2.024429549453079

Epoch: 276| Step: 0
Training loss: 1.7992767095565796
Validation loss: 2.0063703098604755

Epoch: 5| Step: 1
Training loss: 1.7789653539657593
Validation loss: 2.0206892131477274

Epoch: 5| Step: 2
Training loss: 1.5214933156967163
Validation loss: 2.018843181671635

Epoch: 5| Step: 3
Training loss: 1.289819359779358
Validation loss: 2.020843736587032

Epoch: 5| Step: 4
Training loss: 2.3633790016174316
Validation loss: 2.011263778132777

Epoch: 5| Step: 5
Training loss: 1.3651819229125977
Validation loss: 1.9906954278228104

Epoch: 5| Step: 6
Training loss: 1.8005006313323975
Validation loss: 2.021376306010831

Epoch: 5| Step: 7
Training loss: 1.8732315301895142
Validation loss: 1.9927091598510742

Epoch: 5| Step: 8
Training loss: 1.928815245628357
Validation loss: 2.0049759085460375

Epoch: 5| Step: 9
Training loss: 1.6072704792022705
Validation loss: 1.9876386529655867

Epoch: 5| Step: 10
Training loss: 2.080798864364624
Validation loss: 1.9991338919567805

Epoch: 277| Step: 0
Training loss: 1.2898422479629517
Validation loss: 1.9615486437274563

Epoch: 5| Step: 1
Training loss: 1.7327420711517334
Validation loss: 2.0609101351871284

Epoch: 5| Step: 2
Training loss: 1.6638275384902954
Validation loss: 2.010825360974958

Epoch: 5| Step: 3
Training loss: 1.9502897262573242
Validation loss: 1.9927933139185752

Epoch: 5| Step: 4
Training loss: 1.4948762655258179
Validation loss: 1.9775814702433925

Epoch: 5| Step: 5
Training loss: 2.126164436340332
Validation loss: 2.0493106226767264

Epoch: 5| Step: 6
Training loss: 1.5786035060882568
Validation loss: 2.0190749578578497

Epoch: 5| Step: 7
Training loss: 2.245480537414551
Validation loss: 1.988548009626327

Epoch: 5| Step: 8
Training loss: 1.4779099225997925
Validation loss: 1.9832039430577268

Epoch: 5| Step: 9
Training loss: 1.1562856435775757
Validation loss: 1.9757924695168771

Epoch: 5| Step: 10
Training loss: 2.36442494392395
Validation loss: 1.9767123678679108

Epoch: 278| Step: 0
Training loss: 1.268873929977417
Validation loss: 1.971377270196074

Epoch: 5| Step: 1
Training loss: 1.9879909753799438
Validation loss: 2.0115212522527224

Epoch: 5| Step: 2
Training loss: 1.4755254983901978
Validation loss: 2.0187395131716164

Epoch: 5| Step: 3
Training loss: 1.7125965356826782
Validation loss: 2.035707039217795

Epoch: 5| Step: 4
Training loss: 1.6018511056900024
Validation loss: 2.041161035978666

Epoch: 5| Step: 5
Training loss: 2.0495171546936035
Validation loss: 1.9912906039145686

Epoch: 5| Step: 6
Training loss: 1.7860177755355835
Validation loss: 2.0356785597339755

Epoch: 5| Step: 7
Training loss: 2.040710926055908
Validation loss: 2.000897322931597

Epoch: 5| Step: 8
Training loss: 1.450423002243042
Validation loss: 2.0076694744889454

Epoch: 5| Step: 9
Training loss: 1.8457838296890259
Validation loss: 1.9743049272926905

Epoch: 5| Step: 10
Training loss: 2.04510498046875
Validation loss: 1.9802833885274909

Epoch: 279| Step: 0
Training loss: 1.6619313955307007
Validation loss: 1.9989987188769924

Epoch: 5| Step: 1
Training loss: 1.5803637504577637
Validation loss: 2.0285395306925618

Epoch: 5| Step: 2
Training loss: 1.4617599248886108
Validation loss: 1.9844650055772515

Epoch: 5| Step: 3
Training loss: 2.2503950595855713
Validation loss: 2.032199103345153

Epoch: 5| Step: 4
Training loss: 1.2408082485198975
Validation loss: 2.0360442797342935

Epoch: 5| Step: 5
Training loss: 1.5603669881820679
Validation loss: 2.0458034776872203

Epoch: 5| Step: 6
Training loss: 2.099982500076294
Validation loss: 2.0522553638745378

Epoch: 5| Step: 7
Training loss: 1.8597095012664795
Validation loss: 1.970613118140928

Epoch: 5| Step: 8
Training loss: 1.4299613237380981
Validation loss: 2.0295742301530737

Epoch: 5| Step: 9
Training loss: 1.4101371765136719
Validation loss: 2.0645844680006786

Epoch: 5| Step: 10
Training loss: 2.220825433731079
Validation loss: 1.9977855118372108

Epoch: 280| Step: 0
Training loss: 2.0792269706726074
Validation loss: 2.0161628171961796

Epoch: 5| Step: 1
Training loss: 1.7812175750732422
Validation loss: 2.029998125568513

Epoch: 5| Step: 2
Training loss: 1.4298064708709717
Validation loss: 2.0144017870708177

Epoch: 5| Step: 3
Training loss: 2.159740447998047
Validation loss: 2.091478004250475

Epoch: 5| Step: 4
Training loss: 1.5001510381698608
Validation loss: 2.0433722619087464

Epoch: 5| Step: 5
Training loss: 1.8135039806365967
Validation loss: 1.9915681064769786

Epoch: 5| Step: 6
Training loss: 1.5471595525741577
Validation loss: 1.9879767612744403

Epoch: 5| Step: 7
Training loss: 1.648695707321167
Validation loss: 2.0081361647575133

Epoch: 5| Step: 8
Training loss: 1.508019208908081
Validation loss: 1.9842818872902983

Epoch: 5| Step: 9
Training loss: 1.897875189781189
Validation loss: 2.0249857056525444

Epoch: 5| Step: 10
Training loss: 1.2847137451171875
Validation loss: 1.9397209946827223

Epoch: 281| Step: 0
Training loss: 2.0617871284484863
Validation loss: 2.0222858203354703

Epoch: 5| Step: 1
Training loss: 1.7680962085723877
Validation loss: 2.023663575931262

Epoch: 5| Step: 2
Training loss: 1.2319862842559814
Validation loss: 1.979557269362993

Epoch: 5| Step: 3
Training loss: 1.7086594104766846
Validation loss: 1.995189482165921

Epoch: 5| Step: 4
Training loss: 2.0290305614471436
Validation loss: 2.056669940230667

Epoch: 5| Step: 5
Training loss: 1.339205265045166
Validation loss: 2.045206282728462

Epoch: 5| Step: 6
Training loss: 0.9918819665908813
Validation loss: 1.9485980503020748

Epoch: 5| Step: 7
Training loss: 2.09617280960083
Validation loss: 2.0065619753253077

Epoch: 5| Step: 8
Training loss: 1.8629188537597656
Validation loss: 1.9601445659514396

Epoch: 5| Step: 9
Training loss: 1.867749571800232
Validation loss: 1.9764373738278624

Epoch: 5| Step: 10
Training loss: 1.8071964979171753
Validation loss: 1.997536232394557

Epoch: 282| Step: 0
Training loss: 2.1760659217834473
Validation loss: 1.955045033526677

Epoch: 5| Step: 1
Training loss: 1.1508591175079346
Validation loss: 1.9614823415715208

Epoch: 5| Step: 2
Training loss: 1.5570794343948364
Validation loss: 2.0318783329379175

Epoch: 5| Step: 3
Training loss: 1.2186168432235718
Validation loss: 2.0105332251518004

Epoch: 5| Step: 4
Training loss: 1.8133163452148438
Validation loss: 1.9829931233518867

Epoch: 5| Step: 5
Training loss: 1.6405900716781616
Validation loss: 2.034924658395911

Epoch: 5| Step: 6
Training loss: 1.9196981191635132
Validation loss: 1.9855860522998277

Epoch: 5| Step: 7
Training loss: 1.615412712097168
Validation loss: 1.990567543173349

Epoch: 5| Step: 8
Training loss: 2.1020102500915527
Validation loss: 1.9807554444959086

Epoch: 5| Step: 9
Training loss: 1.7920970916748047
Validation loss: 1.9994026871137722

Epoch: 5| Step: 10
Training loss: 1.6788579225540161
Validation loss: 2.0273502795926985

Epoch: 283| Step: 0
Training loss: 1.5564768314361572
Validation loss: 2.0004724584599978

Epoch: 5| Step: 1
Training loss: 2.151369571685791
Validation loss: 1.9720376230055285

Epoch: 5| Step: 2
Training loss: 2.1854236125946045
Validation loss: 2.0170770255468224

Epoch: 5| Step: 3
Training loss: 1.697330117225647
Validation loss: 1.965781246462176

Epoch: 5| Step: 4
Training loss: 1.7452598810195923
Validation loss: 1.9989262921835786

Epoch: 5| Step: 5
Training loss: 1.2694333791732788
Validation loss: 2.021013976425253

Epoch: 5| Step: 6
Training loss: 1.3809572458267212
Validation loss: 1.9606152196084299

Epoch: 5| Step: 7
Training loss: 1.5949134826660156
Validation loss: 2.0160032985030965

Epoch: 5| Step: 8
Training loss: 2.0135951042175293
Validation loss: 1.961085909156389

Epoch: 5| Step: 9
Training loss: 1.8437025547027588
Validation loss: 2.025602512462165

Epoch: 5| Step: 10
Training loss: 1.4422311782836914
Validation loss: 1.949770950501965

Epoch: 284| Step: 0
Training loss: 1.6534544229507446
Validation loss: 2.0231985084472166

Epoch: 5| Step: 1
Training loss: 1.1575112342834473
Validation loss: 1.9991510529671945

Epoch: 5| Step: 2
Training loss: 1.2218267917633057
Validation loss: 2.0111982284053678

Epoch: 5| Step: 3
Training loss: 2.2302331924438477
Validation loss: 2.020593181733162

Epoch: 5| Step: 4
Training loss: 1.7428888082504272
Validation loss: 1.9780470966010966

Epoch: 5| Step: 5
Training loss: 2.0622875690460205
Validation loss: 1.958987371895903

Epoch: 5| Step: 6
Training loss: 1.8443187475204468
Validation loss: 2.0128861678543912

Epoch: 5| Step: 7
Training loss: 1.6278762817382812
Validation loss: 1.9677961141832414

Epoch: 5| Step: 8
Training loss: 1.5775282382965088
Validation loss: 2.0019694476999264

Epoch: 5| Step: 9
Training loss: 1.3977724313735962
Validation loss: 1.9876703895548338

Epoch: 5| Step: 10
Training loss: 2.19748854637146
Validation loss: 2.0320583940834127

Epoch: 285| Step: 0
Training loss: 1.7488648891448975
Validation loss: 1.9631254006457586

Epoch: 5| Step: 1
Training loss: 1.3744996786117554
Validation loss: 1.984854091880142

Epoch: 5| Step: 2
Training loss: 1.482438325881958
Validation loss: 2.024560889890117

Epoch: 5| Step: 3
Training loss: 1.9626095294952393
Validation loss: 2.0350761990393362

Epoch: 5| Step: 4
Training loss: 1.6631624698638916
Validation loss: 2.016212183942077

Epoch: 5| Step: 5
Training loss: 1.2905771732330322
Validation loss: 1.9764595031738281

Epoch: 5| Step: 6
Training loss: 2.353959560394287
Validation loss: 2.010992121952836

Epoch: 5| Step: 7
Training loss: 1.4677537679672241
Validation loss: 2.023141209797193

Epoch: 5| Step: 8
Training loss: 1.9573755264282227
Validation loss: 1.9806953245593655

Epoch: 5| Step: 9
Training loss: 1.5469286441802979
Validation loss: 1.9613293640075191

Epoch: 5| Step: 10
Training loss: 1.7330026626586914
Validation loss: 2.0164476850981354

Epoch: 286| Step: 0
Training loss: 1.459829568862915
Validation loss: 1.9545126679123088

Epoch: 5| Step: 1
Training loss: 1.8487913608551025
Validation loss: 1.9760056464902815

Epoch: 5| Step: 2
Training loss: 1.1871355772018433
Validation loss: 1.981550903730495

Epoch: 5| Step: 3
Training loss: 1.7685972452163696
Validation loss: 1.9626431208784862

Epoch: 5| Step: 4
Training loss: 2.3458151817321777
Validation loss: 2.0146545799829627

Epoch: 5| Step: 5
Training loss: 1.799603819847107
Validation loss: 2.065702410154445

Epoch: 5| Step: 6
Training loss: 2.2072770595550537
Validation loss: 1.9776681418059974

Epoch: 5| Step: 7
Training loss: 0.7589339017868042
Validation loss: 2.003961040127662

Epoch: 5| Step: 8
Training loss: 2.092214822769165
Validation loss: 1.9850476441844818

Epoch: 5| Step: 9
Training loss: 1.5087716579437256
Validation loss: 1.9315865014189033

Epoch: 5| Step: 10
Training loss: 1.9435806274414062
Validation loss: 1.9488619091690227

Epoch: 287| Step: 0
Training loss: 1.7357609272003174
Validation loss: 2.0176669436116375

Epoch: 5| Step: 1
Training loss: 1.7428112030029297
Validation loss: 1.988480068022205

Epoch: 5| Step: 2
Training loss: 1.1574386358261108
Validation loss: 1.98862704923076

Epoch: 5| Step: 3
Training loss: 1.9189777374267578
Validation loss: 2.0221567974295667

Epoch: 5| Step: 4
Training loss: 2.388981342315674
Validation loss: 1.9907698041649275

Epoch: 5| Step: 5
Training loss: 1.7400344610214233
Validation loss: 2.020980691397062

Epoch: 5| Step: 6
Training loss: 1.6401036977767944
Validation loss: 1.9744520533469416

Epoch: 5| Step: 7
Training loss: 1.5847179889678955
Validation loss: 1.964818932676828

Epoch: 5| Step: 8
Training loss: 1.2892524003982544
Validation loss: 2.0099053613601194

Epoch: 5| Step: 9
Training loss: 1.7500683069229126
Validation loss: 1.9589448590432443

Epoch: 5| Step: 10
Training loss: 2.2349390983581543
Validation loss: 2.0132669197615756

Epoch: 288| Step: 0
Training loss: 1.7875254154205322
Validation loss: 1.9840104503016318

Epoch: 5| Step: 1
Training loss: 1.8315308094024658
Validation loss: 1.9828932067399383

Epoch: 5| Step: 2
Training loss: 1.6531517505645752
Validation loss: 1.9931063523856543

Epoch: 5| Step: 3
Training loss: 1.3247392177581787
Validation loss: 1.9818439252914921

Epoch: 5| Step: 4
Training loss: 2.4207072257995605
Validation loss: 1.9706415745519823

Epoch: 5| Step: 5
Training loss: 1.9913558959960938
Validation loss: 1.9722708745669293

Epoch: 5| Step: 6
Training loss: 1.4490693807601929
Validation loss: 1.9807375541297338

Epoch: 5| Step: 7
Training loss: 1.5215532779693604
Validation loss: 2.0179567337036133

Epoch: 5| Step: 8
Training loss: 1.7644853591918945
Validation loss: 1.9716407842533563

Epoch: 5| Step: 9
Training loss: 1.2994956970214844
Validation loss: 1.9889394070512505

Epoch: 5| Step: 10
Training loss: 1.3927972316741943
Validation loss: 2.0311988271692747

Epoch: 289| Step: 0
Training loss: 1.9919109344482422
Validation loss: 2.005126960815922

Epoch: 5| Step: 1
Training loss: 1.2909642457962036
Validation loss: 1.9533523962061892

Epoch: 5| Step: 2
Training loss: 1.0989018678665161
Validation loss: 1.9602396001097977

Epoch: 5| Step: 3
Training loss: 1.8212871551513672
Validation loss: 1.9612086293517903

Epoch: 5| Step: 4
Training loss: 1.6338096857070923
Validation loss: 1.9964348705866004

Epoch: 5| Step: 5
Training loss: 2.415013074874878
Validation loss: 2.0156102898300334

Epoch: 5| Step: 6
Training loss: 1.7827446460723877
Validation loss: 1.9735992095803703

Epoch: 5| Step: 7
Training loss: 1.4175689220428467
Validation loss: 1.977081685937861

Epoch: 5| Step: 8
Training loss: 1.6057010889053345
Validation loss: 2.0550992847770773

Epoch: 5| Step: 9
Training loss: 1.8921918869018555
Validation loss: 2.056800760248656

Epoch: 5| Step: 10
Training loss: 1.5434036254882812
Validation loss: 1.9666278259728545

Epoch: 290| Step: 0
Training loss: 1.4992355108261108
Validation loss: 1.9963338541728195

Epoch: 5| Step: 1
Training loss: 2.135002374649048
Validation loss: 1.9976707402096

Epoch: 5| Step: 2
Training loss: 1.4626991748809814
Validation loss: 2.0349393185748847

Epoch: 5| Step: 3
Training loss: 1.733441710472107
Validation loss: 1.9835237738906697

Epoch: 5| Step: 4
Training loss: 1.7126076221466064
Validation loss: 1.987927334282988

Epoch: 5| Step: 5
Training loss: 1.2044317722320557
Validation loss: 1.9803148379889868

Epoch: 5| Step: 6
Training loss: 1.7873693704605103
Validation loss: 1.9793520101936914

Epoch: 5| Step: 7
Training loss: 1.2678320407867432
Validation loss: 2.0012757380803428

Epoch: 5| Step: 8
Training loss: 2.2148020267486572
Validation loss: 1.913770068076349

Epoch: 5| Step: 9
Training loss: 1.5417137145996094
Validation loss: 1.9912362329421505

Epoch: 5| Step: 10
Training loss: 2.2106471061706543
Validation loss: 1.997659396099788

Epoch: 291| Step: 0
Training loss: 1.570042610168457
Validation loss: 1.9849600356112245

Epoch: 5| Step: 1
Training loss: 1.5640662908554077
Validation loss: 2.002406261300528

Epoch: 5| Step: 2
Training loss: 1.514034628868103
Validation loss: 1.9644147619124381

Epoch: 5| Step: 3
Training loss: 1.436008334159851
Validation loss: 1.9884225399263444

Epoch: 5| Step: 4
Training loss: 1.7896955013275146
Validation loss: 1.9933235337657313

Epoch: 5| Step: 5
Training loss: 1.4871448278427124
Validation loss: 1.988009871975068

Epoch: 5| Step: 6
Training loss: 1.314086675643921
Validation loss: 2.030235057236046

Epoch: 5| Step: 7
Training loss: 2.488236904144287
Validation loss: 2.000384651204591

Epoch: 5| Step: 8
Training loss: 1.5617097616195679
Validation loss: 1.9759437140598093

Epoch: 5| Step: 9
Training loss: 2.1035549640655518
Validation loss: 1.9895863327928769

Epoch: 5| Step: 10
Training loss: 1.8233883380889893
Validation loss: 1.9794090896524408

Epoch: 292| Step: 0
Training loss: 1.2929799556732178
Validation loss: 2.0152424932808004

Epoch: 5| Step: 1
Training loss: 1.5206940174102783
Validation loss: 1.9819613887417702

Epoch: 5| Step: 2
Training loss: 1.6869049072265625
Validation loss: 1.9949867674099502

Epoch: 5| Step: 3
Training loss: 1.5088059902191162
Validation loss: 1.979799157829695

Epoch: 5| Step: 4
Training loss: 1.8821672201156616
Validation loss: 1.9761832221861808

Epoch: 5| Step: 5
Training loss: 1.6117839813232422
Validation loss: 2.03098028449602

Epoch: 5| Step: 6
Training loss: 1.8613617420196533
Validation loss: 1.9889396800789783

Epoch: 5| Step: 7
Training loss: 1.337093472480774
Validation loss: 1.8990464851420412

Epoch: 5| Step: 8
Training loss: 1.6168861389160156
Validation loss: 1.9874165160681612

Epoch: 5| Step: 9
Training loss: 1.9206463098526
Validation loss: 1.986967263683196

Epoch: 5| Step: 10
Training loss: 2.2535793781280518
Validation loss: 2.0392175592401975

Epoch: 293| Step: 0
Training loss: 2.3337271213531494
Validation loss: 1.9900882141564482

Epoch: 5| Step: 1
Training loss: 1.4155257940292358
Validation loss: 1.978111933636409

Epoch: 5| Step: 2
Training loss: 2.1039042472839355
Validation loss: 1.9854422179601525

Epoch: 5| Step: 3
Training loss: 1.74685800075531
Validation loss: 1.997006549630114

Epoch: 5| Step: 4
Training loss: 1.1405616998672485
Validation loss: 2.023950537045797

Epoch: 5| Step: 5
Training loss: 1.562829852104187
Validation loss: 1.9550332561615975

Epoch: 5| Step: 6
Training loss: 1.2157957553863525
Validation loss: 1.9979444562747914

Epoch: 5| Step: 7
Training loss: 1.5416457653045654
Validation loss: 2.022613145971811

Epoch: 5| Step: 8
Training loss: 2.216784715652466
Validation loss: 1.9748055088904597

Epoch: 5| Step: 9
Training loss: 1.4822998046875
Validation loss: 2.0137264664455126

Epoch: 5| Step: 10
Training loss: 1.885254979133606
Validation loss: 1.9868051723767353

Epoch: 294| Step: 0
Training loss: 1.5323010683059692
Validation loss: 1.9904183341610817

Epoch: 5| Step: 1
Training loss: 1.697370171546936
Validation loss: 1.949964263105905

Epoch: 5| Step: 2
Training loss: 1.632314682006836
Validation loss: 1.9757379229350756

Epoch: 5| Step: 3
Training loss: 1.763885259628296
Validation loss: 2.035562451167773

Epoch: 5| Step: 4
Training loss: 1.8902785778045654
Validation loss: 2.0200680071307766

Epoch: 5| Step: 5
Training loss: 2.022023916244507
Validation loss: 2.018429010145126

Epoch: 5| Step: 6
Training loss: 1.419532060623169
Validation loss: 2.038348745274287

Epoch: 5| Step: 7
Training loss: 1.9240741729736328
Validation loss: 2.0383606623577815

Epoch: 5| Step: 8
Training loss: 1.0461173057556152
Validation loss: 1.9869984439624253

Epoch: 5| Step: 9
Training loss: 1.6309051513671875
Validation loss: 1.981901559778439

Epoch: 5| Step: 10
Training loss: 1.7586829662322998
Validation loss: 1.9954547369351952

Epoch: 295| Step: 0
Training loss: 2.3090317249298096
Validation loss: 1.9829376948777067

Epoch: 5| Step: 1
Training loss: 1.9945745468139648
Validation loss: 2.0383897314789476

Epoch: 5| Step: 2
Training loss: 1.362599492073059
Validation loss: 2.0043542282555693

Epoch: 5| Step: 3
Training loss: 1.7746931314468384
Validation loss: 1.9903118020744734

Epoch: 5| Step: 4
Training loss: 1.6276092529296875
Validation loss: 2.024246249147641

Epoch: 5| Step: 5
Training loss: 1.1125942468643188
Validation loss: 1.99604215416857

Epoch: 5| Step: 6
Training loss: 1.9179483652114868
Validation loss: 1.9604417483011882

Epoch: 5| Step: 7
Training loss: 1.2111876010894775
Validation loss: 1.9623211353055892

Epoch: 5| Step: 8
Training loss: 1.4426885843276978
Validation loss: 2.022429503420348

Epoch: 5| Step: 9
Training loss: 1.701499581336975
Validation loss: 1.9721952074317521

Epoch: 5| Step: 10
Training loss: 1.594761848449707
Validation loss: 1.9938605600787747

Epoch: 296| Step: 0
Training loss: 1.9118013381958008
Validation loss: 2.018977556177365

Epoch: 5| Step: 1
Training loss: 1.3920347690582275
Validation loss: 1.9695412843458113

Epoch: 5| Step: 2
Training loss: 1.4790904521942139
Validation loss: 2.028189887282669

Epoch: 5| Step: 3
Training loss: 1.7059646844863892
Validation loss: 2.0402161459768973

Epoch: 5| Step: 4
Training loss: 1.9138338565826416
Validation loss: 1.9736299976225822

Epoch: 5| Step: 5
Training loss: 2.004206895828247
Validation loss: 2.0162595856574272

Epoch: 5| Step: 6
Training loss: 1.850147008895874
Validation loss: 1.9989511966705322

Epoch: 5| Step: 7
Training loss: 0.802464485168457
Validation loss: 2.035507297003141

Epoch: 5| Step: 8
Training loss: 1.4115782976150513
Validation loss: 2.056779157730841

Epoch: 5| Step: 9
Training loss: 1.624182939529419
Validation loss: 2.0135527631287933

Epoch: 5| Step: 10
Training loss: 2.014892578125
Validation loss: 2.0415402548287505

Epoch: 297| Step: 0
Training loss: 2.251333713531494
Validation loss: 2.023571960387691

Epoch: 5| Step: 1
Training loss: 1.2409368753433228
Validation loss: 2.024630456842402

Epoch: 5| Step: 2
Training loss: 1.0762107372283936
Validation loss: 1.958409574724013

Epoch: 5| Step: 3
Training loss: 1.8250839710235596
Validation loss: 1.9621165696010794

Epoch: 5| Step: 4
Training loss: 1.4984543323516846
Validation loss: 1.9687063142817507

Epoch: 5| Step: 5
Training loss: 2.3024239540100098
Validation loss: 1.9843461872428976

Epoch: 5| Step: 6
Training loss: 1.9885342121124268
Validation loss: 1.991259854326966

Epoch: 5| Step: 7
Training loss: 1.373652458190918
Validation loss: 2.001757344891948

Epoch: 5| Step: 8
Training loss: 1.525489091873169
Validation loss: 1.9648980940541914

Epoch: 5| Step: 9
Training loss: 1.9292736053466797
Validation loss: 1.9665512564361736

Epoch: 5| Step: 10
Training loss: 1.3057894706726074
Validation loss: 2.0216101472095778

Epoch: 298| Step: 0
Training loss: 1.8399016857147217
Validation loss: 1.9652730905881493

Epoch: 5| Step: 1
Training loss: 1.9009761810302734
Validation loss: 2.014898759062572

Epoch: 5| Step: 2
Training loss: 1.8647072315216064
Validation loss: 2.001575349479593

Epoch: 5| Step: 3
Training loss: 1.5097763538360596
Validation loss: 2.0143289745494886

Epoch: 5| Step: 4
Training loss: 1.1528732776641846
Validation loss: 1.9990835459001604

Epoch: 5| Step: 5
Training loss: 1.4845174551010132
Validation loss: 1.9567646147102438

Epoch: 5| Step: 6
Training loss: 1.7337923049926758
Validation loss: 1.966352319204679

Epoch: 5| Step: 7
Training loss: 1.7761008739471436
Validation loss: 1.983823218653279

Epoch: 5| Step: 8
Training loss: 1.5449762344360352
Validation loss: 1.9473116038947977

Epoch: 5| Step: 9
Training loss: 1.8662179708480835
Validation loss: 1.9592882766518542

Epoch: 5| Step: 10
Training loss: 1.9079612493515015
Validation loss: 1.959646048084382

Epoch: 299| Step: 0
Training loss: 1.1231887340545654
Validation loss: 2.01632381767355

Epoch: 5| Step: 1
Training loss: 1.3913325071334839
Validation loss: 1.931902204790423

Epoch: 5| Step: 2
Training loss: 1.6682615280151367
Validation loss: 2.028535968513899

Epoch: 5| Step: 3
Training loss: 1.874302864074707
Validation loss: 1.9865812511854275

Epoch: 5| Step: 4
Training loss: 1.6298786401748657
Validation loss: 1.9695495995142127

Epoch: 5| Step: 5
Training loss: 1.1729482412338257
Validation loss: 1.9453534041681597

Epoch: 5| Step: 6
Training loss: 1.9693485498428345
Validation loss: 1.9753118381705335

Epoch: 5| Step: 7
Training loss: 1.3059628009796143
Validation loss: 2.026368289865473

Epoch: 5| Step: 8
Training loss: 1.8622983694076538
Validation loss: 1.966519674947185

Epoch: 5| Step: 9
Training loss: 2.960996627807617
Validation loss: 1.9997481812712967

Epoch: 5| Step: 10
Training loss: 1.1273502111434937
Validation loss: 2.032842113125709

Epoch: 300| Step: 0
Training loss: 1.9052894115447998
Validation loss: 1.970436316664501

Epoch: 5| Step: 1
Training loss: 2.126275062561035
Validation loss: 2.0267540472809986

Epoch: 5| Step: 2
Training loss: 1.1950864791870117
Validation loss: 1.9863140877857004

Epoch: 5| Step: 3
Training loss: 1.8507468700408936
Validation loss: 1.9645762917815999

Epoch: 5| Step: 4
Training loss: 1.4755582809448242
Validation loss: 1.9579276807846562

Epoch: 5| Step: 5
Training loss: 1.506770372390747
Validation loss: 1.9968320490211569

Epoch: 5| Step: 6
Training loss: 1.7067598104476929
Validation loss: 1.9938401752902615

Epoch: 5| Step: 7
Training loss: 1.5481550693511963
Validation loss: 1.953990823479109

Epoch: 5| Step: 8
Training loss: 1.3210179805755615
Validation loss: 2.0016389085400488

Epoch: 5| Step: 9
Training loss: 1.6457408666610718
Validation loss: 1.989852564309233

Epoch: 5| Step: 10
Training loss: 1.720300555229187
Validation loss: 1.9737135441072526

Epoch: 301| Step: 0
Training loss: 1.1134452819824219
Validation loss: 2.023819705491425

Epoch: 5| Step: 1
Training loss: 1.6745141744613647
Validation loss: 2.002973505245742

Epoch: 5| Step: 2
Training loss: 1.6202083826065063
Validation loss: 2.006788828039682

Epoch: 5| Step: 3
Training loss: 1.853543996810913
Validation loss: 2.0049026063693467

Epoch: 5| Step: 4
Training loss: 1.4801329374313354
Validation loss: 2.0043886835857103

Epoch: 5| Step: 5
Training loss: 2.1199276447296143
Validation loss: 1.978596853953536

Epoch: 5| Step: 6
Training loss: 1.657888412475586
Validation loss: 1.9776380574831398

Epoch: 5| Step: 7
Training loss: 1.8213427066802979
Validation loss: 1.9792515975172802

Epoch: 5| Step: 8
Training loss: 1.5821561813354492
Validation loss: 1.9080371831053047

Epoch: 5| Step: 9
Training loss: 1.8139801025390625
Validation loss: 1.9679796785436652

Epoch: 5| Step: 10
Training loss: 1.1293039321899414
Validation loss: 1.9755038471632107

Epoch: 302| Step: 0
Training loss: 1.2864700555801392
Validation loss: 1.9793770569627003

Epoch: 5| Step: 1
Training loss: 1.3459829092025757
Validation loss: 1.9758482158824962

Epoch: 5| Step: 2
Training loss: 1.6299750804901123
Validation loss: 2.020155647749542

Epoch: 5| Step: 3
Training loss: 1.8950144052505493
Validation loss: 2.0296969413757324

Epoch: 5| Step: 4
Training loss: 2.105501413345337
Validation loss: 1.9569162784084198

Epoch: 5| Step: 5
Training loss: 1.8865816593170166
Validation loss: 1.986949638653827

Epoch: 5| Step: 6
Training loss: 1.4569953680038452
Validation loss: 1.9739605701097878

Epoch: 5| Step: 7
Training loss: 1.3409206867218018
Validation loss: 1.9577183018448532

Epoch: 5| Step: 8
Training loss: 2.059363603591919
Validation loss: 1.9707951430351502

Epoch: 5| Step: 9
Training loss: 1.6839323043823242
Validation loss: 1.9623699675324142

Epoch: 5| Step: 10
Training loss: 1.1665314435958862
Validation loss: 1.980384842042

Epoch: 303| Step: 0
Training loss: 1.5743430852890015
Validation loss: 1.9933638700874903

Epoch: 5| Step: 1
Training loss: 1.5362663269042969
Validation loss: 1.9985179772941015

Epoch: 5| Step: 2
Training loss: 1.9562517404556274
Validation loss: 1.9701960932823919

Epoch: 5| Step: 3
Training loss: 1.6700079441070557
Validation loss: 1.959591273338564

Epoch: 5| Step: 4
Training loss: 1.1468563079833984
Validation loss: 2.002392545823128

Epoch: 5| Step: 5
Training loss: 1.375488519668579
Validation loss: 2.0211051689681185

Epoch: 5| Step: 6
Training loss: 1.9894193410873413
Validation loss: 1.9941095985392088

Epoch: 5| Step: 7
Training loss: 1.226820945739746
Validation loss: 1.9619499932053268

Epoch: 5| Step: 8
Training loss: 2.1398892402648926
Validation loss: 1.9823101412865423

Epoch: 5| Step: 9
Training loss: 1.2930309772491455
Validation loss: 1.9511136931757773

Epoch: 5| Step: 10
Training loss: 2.336937189102173
Validation loss: 1.983266298488904

Epoch: 304| Step: 0
Training loss: 1.082106113433838
Validation loss: 2.0374478217094176

Epoch: 5| Step: 1
Training loss: 2.1970677375793457
Validation loss: 2.003482885258172

Epoch: 5| Step: 2
Training loss: 1.6671562194824219
Validation loss: 1.9603266023820447

Epoch: 5| Step: 3
Training loss: 1.2735320329666138
Validation loss: 1.9611727486374557

Epoch: 5| Step: 4
Training loss: 1.5022039413452148
Validation loss: 2.014381226672921

Epoch: 5| Step: 5
Training loss: 2.0057785511016846
Validation loss: 1.9932478756032965

Epoch: 5| Step: 6
Training loss: 1.3586201667785645
Validation loss: 1.956638265681523

Epoch: 5| Step: 7
Training loss: 1.8953510522842407
Validation loss: 1.963501194471954

Epoch: 5| Step: 8
Training loss: 1.8850767612457275
Validation loss: 2.020798726748395

Epoch: 5| Step: 9
Training loss: 1.7514530420303345
Validation loss: 2.0038551861240017

Epoch: 5| Step: 10
Training loss: 1.521713137626648
Validation loss: 2.002121579262518

Epoch: 305| Step: 0
Training loss: 1.7475624084472656
Validation loss: 2.0248458129103466

Epoch: 5| Step: 1
Training loss: 1.717540979385376
Validation loss: 1.957964774101011

Epoch: 5| Step: 2
Training loss: 1.4248651266098022
Validation loss: 1.9917701751955095

Epoch: 5| Step: 3
Training loss: 2.0204720497131348
Validation loss: 2.0183745648271296

Epoch: 5| Step: 4
Training loss: 1.427316427230835
Validation loss: 2.0162888162879535

Epoch: 5| Step: 5
Training loss: 2.0274035930633545
Validation loss: 1.9763985064721876

Epoch: 5| Step: 6
Training loss: 1.6904850006103516
Validation loss: 1.9739659127368723

Epoch: 5| Step: 7
Training loss: 1.4192034006118774
Validation loss: 1.9315875832752516

Epoch: 5| Step: 8
Training loss: 1.6709744930267334
Validation loss: 1.9021663781135314

Epoch: 5| Step: 9
Training loss: 1.1143748760223389
Validation loss: 1.9838710036329044

Epoch: 5| Step: 10
Training loss: 1.995835304260254
Validation loss: 1.9433018263950144

Epoch: 306| Step: 0
Training loss: 1.9679511785507202
Validation loss: 1.9556012102352676

Epoch: 5| Step: 1
Training loss: 1.2706435918807983
Validation loss: 1.990733040276394

Epoch: 5| Step: 2
Training loss: 1.6906139850616455
Validation loss: 1.9308112180361183

Epoch: 5| Step: 3
Training loss: 1.5121909379959106
Validation loss: 1.9847660718425628

Epoch: 5| Step: 4
Training loss: 1.259305715560913
Validation loss: 1.9988810375172605

Epoch: 5| Step: 5
Training loss: 1.4105618000030518
Validation loss: 2.022419165539485

Epoch: 5| Step: 6
Training loss: 2.0259692668914795
Validation loss: 1.9487174300737278

Epoch: 5| Step: 7
Training loss: 2.2451565265655518
Validation loss: 1.9646711887851838

Epoch: 5| Step: 8
Training loss: 1.5398261547088623
Validation loss: 1.9637252233361686

Epoch: 5| Step: 9
Training loss: 1.6818740367889404
Validation loss: 1.9625274571039344

Epoch: 5| Step: 10
Training loss: 1.573693037033081
Validation loss: 1.9520957264848935

Epoch: 307| Step: 0
Training loss: 1.5048929452896118
Validation loss: 1.972748944836278

Epoch: 5| Step: 1
Training loss: 1.741718053817749
Validation loss: 1.934097978376573

Epoch: 5| Step: 2
Training loss: 1.5627336502075195
Validation loss: 1.9582684091342393

Epoch: 5| Step: 3
Training loss: 1.6962518692016602
Validation loss: 1.9404782889991679

Epoch: 5| Step: 4
Training loss: 1.6102678775787354
Validation loss: 1.9447891776279738

Epoch: 5| Step: 5
Training loss: 1.8202003240585327
Validation loss: 1.940080254308639

Epoch: 5| Step: 6
Training loss: 1.8869860172271729
Validation loss: 1.990168188207893

Epoch: 5| Step: 7
Training loss: 2.097177505493164
Validation loss: 1.9792247395361624

Epoch: 5| Step: 8
Training loss: 1.3813754320144653
Validation loss: 1.9830648591441493

Epoch: 5| Step: 9
Training loss: 1.326964020729065
Validation loss: 1.9915292057939755

Epoch: 5| Step: 10
Training loss: 1.5462220907211304
Validation loss: 2.000035637168474

Epoch: 308| Step: 0
Training loss: 1.2610160112380981
Validation loss: 2.009912065280381

Epoch: 5| Step: 1
Training loss: 1.702048897743225
Validation loss: 1.9798081087809738

Epoch: 5| Step: 2
Training loss: 1.806836724281311
Validation loss: 1.9494851814803256

Epoch: 5| Step: 3
Training loss: 1.348962426185608
Validation loss: 1.965862859961807

Epoch: 5| Step: 4
Training loss: 1.4264787435531616
Validation loss: 1.9694438288288731

Epoch: 5| Step: 5
Training loss: 1.7747390270233154
Validation loss: 1.999087627216052

Epoch: 5| Step: 6
Training loss: 1.2463810443878174
Validation loss: 1.9737428311378724

Epoch: 5| Step: 7
Training loss: 1.7962744235992432
Validation loss: 1.963017730302708

Epoch: 5| Step: 8
Training loss: 2.0941848754882812
Validation loss: 1.9312227567036946

Epoch: 5| Step: 9
Training loss: 1.3685766458511353
Validation loss: 1.9817851025571105

Epoch: 5| Step: 10
Training loss: 1.9344686269760132
Validation loss: 1.9717469843485023

Epoch: 309| Step: 0
Training loss: 1.7309948205947876
Validation loss: 1.9518564465225383

Epoch: 5| Step: 1
Training loss: 1.6801321506500244
Validation loss: 1.9599216009980889

Epoch: 5| Step: 2
Training loss: 2.0071799755096436
Validation loss: 2.0136846778213338

Epoch: 5| Step: 3
Training loss: 1.719931960105896
Validation loss: 1.972078448982649

Epoch: 5| Step: 4
Training loss: 1.4765987396240234
Validation loss: 1.9863497903270106

Epoch: 5| Step: 5
Training loss: 1.5169777870178223
Validation loss: 1.9812412390144922

Epoch: 5| Step: 6
Training loss: 1.8352277278900146
Validation loss: 1.9674022492542063

Epoch: 5| Step: 7
Training loss: 1.4078607559204102
Validation loss: 1.9675218443716727

Epoch: 5| Step: 8
Training loss: 1.5426533222198486
Validation loss: 2.020956254774524

Epoch: 5| Step: 9
Training loss: 1.6145904064178467
Validation loss: 1.9118610018043107

Epoch: 5| Step: 10
Training loss: 1.4242513179779053
Validation loss: 1.9272521234327746

Epoch: 310| Step: 0
Training loss: 1.7922084331512451
Validation loss: 1.9562156764409875

Epoch: 5| Step: 1
Training loss: 1.8433997631072998
Validation loss: 1.9611834223552416

Epoch: 5| Step: 2
Training loss: 1.313025951385498
Validation loss: 1.9797089228066065

Epoch: 5| Step: 3
Training loss: 1.625150442123413
Validation loss: 2.0031657385569748

Epoch: 5| Step: 4
Training loss: 2.2880563735961914
Validation loss: 1.9621799940704017

Epoch: 5| Step: 5
Training loss: 1.9916794300079346
Validation loss: 2.056427865900019

Epoch: 5| Step: 6
Training loss: 1.5881545543670654
Validation loss: 1.9801965618646273

Epoch: 5| Step: 7
Training loss: 1.0047916173934937
Validation loss: 2.0410092287166144

Epoch: 5| Step: 8
Training loss: 1.7994734048843384
Validation loss: 1.9981734445018153

Epoch: 5| Step: 9
Training loss: 1.15648353099823
Validation loss: 1.981531209843133

Epoch: 5| Step: 10
Training loss: 1.4224845170974731
Validation loss: 1.978523523576798

Epoch: 311| Step: 0
Training loss: 1.359757661819458
Validation loss: 1.9867208260361866

Epoch: 5| Step: 1
Training loss: 1.511771559715271
Validation loss: 1.9390853835690407

Epoch: 5| Step: 2
Training loss: 1.265024185180664
Validation loss: 1.9765694577206847

Epoch: 5| Step: 3
Training loss: 1.6006920337677002
Validation loss: 1.9209525636447373

Epoch: 5| Step: 4
Training loss: 1.846105933189392
Validation loss: 1.940968753189169

Epoch: 5| Step: 5
Training loss: 1.154505729675293
Validation loss: 1.9307732184727986

Epoch: 5| Step: 6
Training loss: 1.8039623498916626
Validation loss: 1.949645911493609

Epoch: 5| Step: 7
Training loss: 2.42112398147583
Validation loss: 2.00718625514738

Epoch: 5| Step: 8
Training loss: 1.3071290254592896
Validation loss: 1.9417765768625403

Epoch: 5| Step: 9
Training loss: 1.3873125314712524
Validation loss: 1.981663844918692

Epoch: 5| Step: 10
Training loss: 1.999151349067688
Validation loss: 1.9335647911153815

Epoch: 312| Step: 0
Training loss: 1.350415587425232
Validation loss: 1.973055629320042

Epoch: 5| Step: 1
Training loss: 1.9708118438720703
Validation loss: 1.951087426113826

Epoch: 5| Step: 2
Training loss: 1.5332502126693726
Validation loss: 1.9750641827942224

Epoch: 5| Step: 3
Training loss: 1.5009154081344604
Validation loss: 1.9579910283447595

Epoch: 5| Step: 4
Training loss: 1.5822283029556274
Validation loss: 1.9761132835060038

Epoch: 5| Step: 5
Training loss: 1.3569982051849365
Validation loss: 1.9493370466334845

Epoch: 5| Step: 6
Training loss: 1.9260151386260986
Validation loss: 1.9896818924975652

Epoch: 5| Step: 7
Training loss: 1.3978664875030518
Validation loss: 1.9635447148353822

Epoch: 5| Step: 8
Training loss: 1.476394534111023
Validation loss: 1.9980635860914826

Epoch: 5| Step: 9
Training loss: 1.8481552600860596
Validation loss: 1.9589559826799618

Epoch: 5| Step: 10
Training loss: 1.6302202939987183
Validation loss: 1.986448493055118

Epoch: 313| Step: 0
Training loss: 1.291399359703064
Validation loss: 1.965784393331056

Epoch: 5| Step: 1
Training loss: 1.4003221988677979
Validation loss: 1.9605750178778043

Epoch: 5| Step: 2
Training loss: 1.8352868556976318
Validation loss: 1.967116419987012

Epoch: 5| Step: 3
Training loss: 1.9119876623153687
Validation loss: 1.9899746320580924

Epoch: 5| Step: 4
Training loss: 1.7107784748077393
Validation loss: 1.9953832100796443

Epoch: 5| Step: 5
Training loss: 0.8840716481208801
Validation loss: 1.9911405296735867

Epoch: 5| Step: 6
Training loss: 1.8894946575164795
Validation loss: 2.0159162244489117

Epoch: 5| Step: 7
Training loss: 1.7006889581680298
Validation loss: 1.967057043506253

Epoch: 5| Step: 8
Training loss: 1.463367223739624
Validation loss: 1.9887706874519266

Epoch: 5| Step: 9
Training loss: 1.4473974704742432
Validation loss: 1.973549945380098

Epoch: 5| Step: 10
Training loss: 1.6900029182434082
Validation loss: 1.9495938170340754

Epoch: 314| Step: 0
Training loss: 1.8982406854629517
Validation loss: 1.9578950789666945

Epoch: 5| Step: 1
Training loss: 1.6756826639175415
Validation loss: 1.9209728369148829

Epoch: 5| Step: 2
Training loss: 1.9103622436523438
Validation loss: 1.910298196218347

Epoch: 5| Step: 3
Training loss: 1.2749788761138916
Validation loss: 1.9584018350929342

Epoch: 5| Step: 4
Training loss: 1.3371437788009644
Validation loss: 1.9707954045264953

Epoch: 5| Step: 5
Training loss: 1.402980089187622
Validation loss: 2.005167559910846

Epoch: 5| Step: 6
Training loss: 1.7764956951141357
Validation loss: 1.9433863855177356

Epoch: 5| Step: 7
Training loss: 1.3650391101837158
Validation loss: 1.9451683618689095

Epoch: 5| Step: 8
Training loss: 2.1359927654266357
Validation loss: 1.9892405566348825

Epoch: 5| Step: 9
Training loss: 1.538772463798523
Validation loss: 1.9418519671245287

Epoch: 5| Step: 10
Training loss: 1.2655044794082642
Validation loss: 1.9395273936692106

Epoch: 315| Step: 0
Training loss: 1.5606181621551514
Validation loss: 1.9847229308979486

Epoch: 5| Step: 1
Training loss: 1.890913963317871
Validation loss: 2.0270940911385322

Epoch: 5| Step: 2
Training loss: 1.2337950468063354
Validation loss: 1.9578970119517336

Epoch: 5| Step: 3
Training loss: 1.7035973072052002
Validation loss: 1.903641208525627

Epoch: 5| Step: 4
Training loss: 1.9650005102157593
Validation loss: 1.9317878023270638

Epoch: 5| Step: 5
Training loss: 1.182715654373169
Validation loss: 1.9916720967138968

Epoch: 5| Step: 6
Training loss: 1.6867046356201172
Validation loss: 2.00855992814546

Epoch: 5| Step: 7
Training loss: 1.1838386058807373
Validation loss: 1.9673482371914772

Epoch: 5| Step: 8
Training loss: 1.7193078994750977
Validation loss: 1.9508886901281213

Epoch: 5| Step: 9
Training loss: 1.5256983041763306
Validation loss: 1.972020943959554

Epoch: 5| Step: 10
Training loss: 1.8024874925613403
Validation loss: 1.9619864866297732

Epoch: 316| Step: 0
Training loss: 1.9488868713378906
Validation loss: 1.9239356748519405

Epoch: 5| Step: 1
Training loss: 1.460282564163208
Validation loss: 1.995652792274311

Epoch: 5| Step: 2
Training loss: 1.5678460597991943
Validation loss: 1.927235593077957

Epoch: 5| Step: 3
Training loss: 1.9791433811187744
Validation loss: 1.9753665360071326

Epoch: 5| Step: 4
Training loss: 1.3398339748382568
Validation loss: 1.9797163125007384

Epoch: 5| Step: 5
Training loss: 1.3226072788238525
Validation loss: 1.954784789393025

Epoch: 5| Step: 6
Training loss: 1.9235029220581055
Validation loss: 1.9837869457019273

Epoch: 5| Step: 7
Training loss: 1.763922095298767
Validation loss: 1.9540242892439648

Epoch: 5| Step: 8
Training loss: 1.7083232402801514
Validation loss: 1.9493344778655677

Epoch: 5| Step: 9
Training loss: 1.3082311153411865
Validation loss: 1.9531226799052248

Epoch: 5| Step: 10
Training loss: 1.1494193077087402
Validation loss: 2.001970075791882

Epoch: 317| Step: 0
Training loss: 1.789494276046753
Validation loss: 1.9738573746014667

Epoch: 5| Step: 1
Training loss: 1.2731858491897583
Validation loss: 1.9201512439276582

Epoch: 5| Step: 2
Training loss: 1.3439571857452393
Validation loss: 1.9677756653037122

Epoch: 5| Step: 3
Training loss: 1.4396097660064697
Validation loss: 1.9374324813965829

Epoch: 5| Step: 4
Training loss: 2.0740292072296143
Validation loss: 1.9869801305955457

Epoch: 5| Step: 5
Training loss: 2.165982246398926
Validation loss: 1.9607511463985647

Epoch: 5| Step: 6
Training loss: 1.9096533060073853
Validation loss: 1.9546516531257219

Epoch: 5| Step: 7
Training loss: 1.2128220796585083
Validation loss: 2.0048389434814453

Epoch: 5| Step: 8
Training loss: 1.1669361591339111
Validation loss: 1.92714011925523

Epoch: 5| Step: 9
Training loss: 1.7180010080337524
Validation loss: 1.9203528370908511

Epoch: 5| Step: 10
Training loss: 1.601027488708496
Validation loss: 1.9773036292804185

Epoch: 318| Step: 0
Training loss: 1.7057174444198608
Validation loss: 1.9405568633028256

Epoch: 5| Step: 1
Training loss: 1.9240572452545166
Validation loss: 1.9637831064962572

Epoch: 5| Step: 2
Training loss: 1.7902368307113647
Validation loss: 1.9540790947534705

Epoch: 5| Step: 3
Training loss: 2.063542366027832
Validation loss: 1.9338176301730576

Epoch: 5| Step: 4
Training loss: 1.4187555313110352
Validation loss: 1.9904157064294303

Epoch: 5| Step: 5
Training loss: 1.1193430423736572
Validation loss: 1.9292862364040908

Epoch: 5| Step: 6
Training loss: 1.2781484127044678
Validation loss: 2.008324223179971

Epoch: 5| Step: 7
Training loss: 1.6990644931793213
Validation loss: 2.0081755832959245

Epoch: 5| Step: 8
Training loss: 1.3482749462127686
Validation loss: 1.9765009739065682

Epoch: 5| Step: 9
Training loss: 1.6377700567245483
Validation loss: 1.9815988463740195

Epoch: 5| Step: 10
Training loss: 1.650960922241211
Validation loss: 1.9433311057347122

Epoch: 319| Step: 0
Training loss: 2.067286729812622
Validation loss: 1.9694559240853915

Epoch: 5| Step: 1
Training loss: 1.5216422080993652
Validation loss: 1.9607015412340882

Epoch: 5| Step: 2
Training loss: 1.338653802871704
Validation loss: 1.9120966234514791

Epoch: 5| Step: 3
Training loss: 1.163439393043518
Validation loss: 1.9726095302130586

Epoch: 5| Step: 4
Training loss: 2.1377413272857666
Validation loss: 1.9383799773390575

Epoch: 5| Step: 5
Training loss: 1.5400795936584473
Validation loss: 1.9442567261316444

Epoch: 5| Step: 6
Training loss: 2.2576706409454346
Validation loss: 1.9891116978019796

Epoch: 5| Step: 7
Training loss: 1.584261178970337
Validation loss: 1.942995971248996

Epoch: 5| Step: 8
Training loss: 1.8253463506698608
Validation loss: 1.9714668950726908

Epoch: 5| Step: 9
Training loss: 1.0559688806533813
Validation loss: 1.9338175737729637

Epoch: 5| Step: 10
Training loss: 1.064284324645996
Validation loss: 1.938924676628523

Epoch: 320| Step: 0
Training loss: 1.4564003944396973
Validation loss: 1.9754980328262493

Epoch: 5| Step: 1
Training loss: 1.6370233297348022
Validation loss: 1.9866654001256472

Epoch: 5| Step: 2
Training loss: 1.1072790622711182
Validation loss: 1.963949034290929

Epoch: 5| Step: 3
Training loss: 1.957010269165039
Validation loss: 2.0035805471481813

Epoch: 5| Step: 4
Training loss: 1.6260502338409424
Validation loss: 2.016032854715983

Epoch: 5| Step: 5
Training loss: 1.7258373498916626
Validation loss: 1.9928002408755723

Epoch: 5| Step: 6
Training loss: 1.8252830505371094
Validation loss: 1.98688567069269

Epoch: 5| Step: 7
Training loss: 1.675588846206665
Validation loss: 1.9287824912737774

Epoch: 5| Step: 8
Training loss: 1.1165271997451782
Validation loss: 1.9592295987631685

Epoch: 5| Step: 9
Training loss: 1.721339225769043
Validation loss: 1.9799420359314128

Epoch: 5| Step: 10
Training loss: 1.7398303747177124
Validation loss: 2.0083878783769507

Epoch: 321| Step: 0
Training loss: 1.4853332042694092
Validation loss: 1.9821646931350871

Epoch: 5| Step: 1
Training loss: 1.4231336116790771
Validation loss: 1.9454361725878972

Epoch: 5| Step: 2
Training loss: 1.7239534854888916
Validation loss: 1.9375475529701478

Epoch: 5| Step: 3
Training loss: 1.7435325384140015
Validation loss: 1.9223266263161936

Epoch: 5| Step: 4
Training loss: 1.5834726095199585
Validation loss: 1.9671396978439823

Epoch: 5| Step: 5
Training loss: 1.6205867528915405
Validation loss: 1.9519035611101376

Epoch: 5| Step: 6
Training loss: 1.915736436843872
Validation loss: 1.9922603253395326

Epoch: 5| Step: 7
Training loss: 1.7066259384155273
Validation loss: 1.8796117062209754

Epoch: 5| Step: 8
Training loss: 1.7753006219863892
Validation loss: 2.001440376363775

Epoch: 5| Step: 9
Training loss: 1.262523889541626
Validation loss: 1.9337530777018557

Epoch: 5| Step: 10
Training loss: 1.2688225507736206
Validation loss: 1.8908094513800837

Epoch: 322| Step: 0
Training loss: 1.5332751274108887
Validation loss: 1.9361753425290507

Epoch: 5| Step: 1
Training loss: 1.9405412673950195
Validation loss: 1.9795803177741267

Epoch: 5| Step: 2
Training loss: 2.075326919555664
Validation loss: 1.9337477530202558

Epoch: 5| Step: 3
Training loss: 1.8916953802108765
Validation loss: 1.9836847474498134

Epoch: 5| Step: 4
Training loss: 1.3499146699905396
Validation loss: 1.944261622685258

Epoch: 5| Step: 5
Training loss: 1.2712469100952148
Validation loss: 1.929216584851665

Epoch: 5| Step: 6
Training loss: 1.790310263633728
Validation loss: 1.955724149621943

Epoch: 5| Step: 7
Training loss: 1.7186203002929688
Validation loss: 1.9616763027765418

Epoch: 5| Step: 8
Training loss: 1.4260550737380981
Validation loss: 1.930078464169656

Epoch: 5| Step: 9
Training loss: 1.2168195247650146
Validation loss: 1.9799239532921904

Epoch: 5| Step: 10
Training loss: 1.2812353372573853
Validation loss: 1.9291964320726291

Epoch: 323| Step: 0
Training loss: 1.858689546585083
Validation loss: 1.9149262982030069

Epoch: 5| Step: 1
Training loss: 1.710723876953125
Validation loss: 1.9539913772254862

Epoch: 5| Step: 2
Training loss: 1.2380998134613037
Validation loss: 1.9488850126984298

Epoch: 5| Step: 3
Training loss: 1.7294965982437134
Validation loss: 1.91404216776612

Epoch: 5| Step: 4
Training loss: 1.6126940250396729
Validation loss: 1.9598893632170975

Epoch: 5| Step: 5
Training loss: 1.515816330909729
Validation loss: 1.9657738875317317

Epoch: 5| Step: 6
Training loss: 1.6228281259536743
Validation loss: 1.9467081972347793

Epoch: 5| Step: 7
Training loss: 1.0840513706207275
Validation loss: 1.9622301183721071

Epoch: 5| Step: 8
Training loss: 1.4577070474624634
Validation loss: 1.9574664074887511

Epoch: 5| Step: 9
Training loss: 1.8427107334136963
Validation loss: 1.9795044904114099

Epoch: 5| Step: 10
Training loss: 1.8862690925598145
Validation loss: 1.9783512276987876

Epoch: 324| Step: 0
Training loss: 1.6891053915023804
Validation loss: 2.009088735426626

Epoch: 5| Step: 1
Training loss: 1.3035997152328491
Validation loss: 1.9274272687973515

Epoch: 5| Step: 2
Training loss: 1.7773211002349854
Validation loss: 1.9693082737666305

Epoch: 5| Step: 3
Training loss: 1.6306400299072266
Validation loss: 1.9331391037151378

Epoch: 5| Step: 4
Training loss: 1.7624576091766357
Validation loss: 1.9867870115464734

Epoch: 5| Step: 5
Training loss: 2.2156498432159424
Validation loss: 1.9843664489766604

Epoch: 5| Step: 6
Training loss: 1.077397346496582
Validation loss: 1.9702244522751018

Epoch: 5| Step: 7
Training loss: 1.0125079154968262
Validation loss: 1.9004950472103652

Epoch: 5| Step: 8
Training loss: 1.5770468711853027
Validation loss: 1.9274874297521447

Epoch: 5| Step: 9
Training loss: 1.6595404148101807
Validation loss: 1.969951965475595

Epoch: 5| Step: 10
Training loss: 2.0738370418548584
Validation loss: 1.9643167385490992

Epoch: 325| Step: 0
Training loss: 1.407880187034607
Validation loss: 1.9141709714807489

Epoch: 5| Step: 1
Training loss: 2.2242586612701416
Validation loss: 1.9843363249173729

Epoch: 5| Step: 2
Training loss: 1.6597198247909546
Validation loss: 1.9250950813293457

Epoch: 5| Step: 3
Training loss: 1.6305913925170898
Validation loss: 1.9497536613095192

Epoch: 5| Step: 4
Training loss: 1.396849274635315
Validation loss: 1.9328158696492512

Epoch: 5| Step: 5
Training loss: 1.0576629638671875
Validation loss: 1.9251892130862

Epoch: 5| Step: 6
Training loss: 1.3516649007797241
Validation loss: 1.9458883398322648

Epoch: 5| Step: 7
Training loss: 2.011425256729126
Validation loss: 1.9346319219117523

Epoch: 5| Step: 8
Training loss: 1.7231181859970093
Validation loss: 1.9928554001674856

Epoch: 5| Step: 9
Training loss: 1.420904278755188
Validation loss: 1.9515160975917694

Epoch: 5| Step: 10
Training loss: 1.1265721321105957
Validation loss: 1.989936182575841

Epoch: 326| Step: 0
Training loss: 2.1079580783843994
Validation loss: 1.9512196279341174

Epoch: 5| Step: 1
Training loss: 1.6137176752090454
Validation loss: 1.9274984957069479

Epoch: 5| Step: 2
Training loss: 1.2552868127822876
Validation loss: 1.9309226377035982

Epoch: 5| Step: 3
Training loss: 1.9947389364242554
Validation loss: 1.9618303160513602

Epoch: 5| Step: 4
Training loss: 1.0935747623443604
Validation loss: 1.945197561735748

Epoch: 5| Step: 5
Training loss: 1.4514065980911255
Validation loss: 1.9513144634103263

Epoch: 5| Step: 6
Training loss: 1.443472146987915
Validation loss: 1.98946746190389

Epoch: 5| Step: 7
Training loss: 1.0028412342071533
Validation loss: 1.9163069763491232

Epoch: 5| Step: 8
Training loss: 1.3647648096084595
Validation loss: 1.9902579271665184

Epoch: 5| Step: 9
Training loss: 2.4816322326660156
Validation loss: 1.9772613458735968

Epoch: 5| Step: 10
Training loss: 1.2810457944869995
Validation loss: 1.937656469242547

Epoch: 327| Step: 0
Training loss: 2.1317973136901855
Validation loss: 1.9524941136760097

Epoch: 5| Step: 1
Training loss: 1.7748548984527588
Validation loss: 1.9132525664503857

Epoch: 5| Step: 2
Training loss: 1.5004416704177856
Validation loss: 1.9598094699203328

Epoch: 5| Step: 3
Training loss: 1.9850494861602783
Validation loss: 1.919975342289094

Epoch: 5| Step: 4
Training loss: 1.6623233556747437
Validation loss: 1.9770932620571506

Epoch: 5| Step: 5
Training loss: 1.3656387329101562
Validation loss: 1.9811128608642086

Epoch: 5| Step: 6
Training loss: 1.2149560451507568
Validation loss: 1.988333015031712

Epoch: 5| Step: 7
Training loss: 1.5553548336029053
Validation loss: 1.9056158552887619

Epoch: 5| Step: 8
Training loss: 1.4352365732192993
Validation loss: 1.943581283733409

Epoch: 5| Step: 9
Training loss: 1.5390863418579102
Validation loss: 1.9820245645379508

Epoch: 5| Step: 10
Training loss: 1.2383828163146973
Validation loss: 1.9602612628731677

Epoch: 328| Step: 0
Training loss: 1.7707955837249756
Validation loss: 1.9365100873413907

Epoch: 5| Step: 1
Training loss: 1.8220945596694946
Validation loss: 1.9164420686742312

Epoch: 5| Step: 2
Training loss: 1.6189950704574585
Validation loss: 1.900246145904705

Epoch: 5| Step: 3
Training loss: 0.8898526430130005
Validation loss: 1.971223872195008

Epoch: 5| Step: 4
Training loss: 2.0737032890319824
Validation loss: 1.9830714682097077

Epoch: 5| Step: 5
Training loss: 1.291080117225647
Validation loss: 1.9336486426732873

Epoch: 5| Step: 6
Training loss: 1.9704875946044922
Validation loss: 1.9600215919556156

Epoch: 5| Step: 7
Training loss: 1.40622079372406
Validation loss: 1.913904018299554

Epoch: 5| Step: 8
Training loss: 1.4672294855117798
Validation loss: 1.913738073841218

Epoch: 5| Step: 9
Training loss: 1.472994089126587
Validation loss: 1.920298073881416

Epoch: 5| Step: 10
Training loss: 1.574011206626892
Validation loss: 2.000987925837117

Epoch: 329| Step: 0
Training loss: 1.721194863319397
Validation loss: 1.9505857344596618

Epoch: 5| Step: 1
Training loss: 1.6154037714004517
Validation loss: 1.945833190794914

Epoch: 5| Step: 2
Training loss: 1.5821685791015625
Validation loss: 1.9537803626829577

Epoch: 5| Step: 3
Training loss: 1.3967492580413818
Validation loss: 1.9302173852920532

Epoch: 5| Step: 4
Training loss: 1.3919994831085205
Validation loss: 1.928625678503385

Epoch: 5| Step: 5
Training loss: 0.9392117261886597
Validation loss: 1.9161470974645307

Epoch: 5| Step: 6
Training loss: 1.6281325817108154
Validation loss: 1.9847342750077606

Epoch: 5| Step: 7
Training loss: 1.4042248725891113
Validation loss: 1.9599577534583308

Epoch: 5| Step: 8
Training loss: 1.4727308750152588
Validation loss: 1.9538827685899631

Epoch: 5| Step: 9
Training loss: 2.135094404220581
Validation loss: 1.9967788137415403

Epoch: 5| Step: 10
Training loss: 1.9650380611419678
Validation loss: 1.949476049792382

Epoch: 330| Step: 0
Training loss: 1.542365550994873
Validation loss: 1.971113843302573

Epoch: 5| Step: 1
Training loss: 2.0124378204345703
Validation loss: 1.9519683096998481

Epoch: 5| Step: 2
Training loss: 1.6025264263153076
Validation loss: 1.9047947109386485

Epoch: 5| Step: 3
Training loss: 0.7735633254051208
Validation loss: 1.964824418867788

Epoch: 5| Step: 4
Training loss: 1.739884376525879
Validation loss: 1.9865834911664326

Epoch: 5| Step: 5
Training loss: 2.0624642372131348
Validation loss: 1.9201621522185623

Epoch: 5| Step: 6
Training loss: 1.2096089124679565
Validation loss: 1.9424346390590872

Epoch: 5| Step: 7
Training loss: 1.275347113609314
Validation loss: 1.9359862445503153

Epoch: 5| Step: 8
Training loss: 1.3725863695144653
Validation loss: 1.9934932416485203

Epoch: 5| Step: 9
Training loss: 1.5632299184799194
Validation loss: 1.9766807953516643

Epoch: 5| Step: 10
Training loss: 2.153019666671753
Validation loss: 1.966167167950702

Epoch: 331| Step: 0
Training loss: 1.9091684818267822
Validation loss: 1.9916933928766558

Epoch: 5| Step: 1
Training loss: 1.8407930135726929
Validation loss: 1.9571767596788303

Epoch: 5| Step: 2
Training loss: 1.8186664581298828
Validation loss: 1.974433914307625

Epoch: 5| Step: 3
Training loss: 1.2528822422027588
Validation loss: 1.970614476870465

Epoch: 5| Step: 4
Training loss: 1.946829080581665
Validation loss: 2.003841350155492

Epoch: 5| Step: 5
Training loss: 1.7366594076156616
Validation loss: 1.9370582590820968

Epoch: 5| Step: 6
Training loss: 1.8861503601074219
Validation loss: 1.9902344185818908

Epoch: 5| Step: 7
Training loss: 0.9491572380065918
Validation loss: 1.9542793971236034

Epoch: 5| Step: 8
Training loss: 0.9376675486564636
Validation loss: 1.9534444462868474

Epoch: 5| Step: 9
Training loss: 1.184435248374939
Validation loss: 1.94367334535045

Epoch: 5| Step: 10
Training loss: 1.7346967458724976
Validation loss: 1.9370829225868307

Epoch: 332| Step: 0
Training loss: 1.5978062152862549
Validation loss: 1.9252948940441172

Epoch: 5| Step: 1
Training loss: 0.9927195310592651
Validation loss: 1.9064260657115648

Epoch: 5| Step: 2
Training loss: 1.5145676136016846
Validation loss: 1.9540350180800243

Epoch: 5| Step: 3
Training loss: 1.7038862705230713
Validation loss: 2.0082856070610786

Epoch: 5| Step: 4
Training loss: 1.4161584377288818
Validation loss: 1.9212610490860478

Epoch: 5| Step: 5
Training loss: 1.364944577217102
Validation loss: 1.9746850446988178

Epoch: 5| Step: 6
Training loss: 1.7075783014297485
Validation loss: 1.9412148575628958

Epoch: 5| Step: 7
Training loss: 1.4900676012039185
Validation loss: 1.943841390712287

Epoch: 5| Step: 8
Training loss: 1.3989708423614502
Validation loss: 1.96906832725771

Epoch: 5| Step: 9
Training loss: 2.141347885131836
Validation loss: 1.9679817615016815

Epoch: 5| Step: 10
Training loss: 1.965683937072754
Validation loss: 1.9669904580680273

Epoch: 333| Step: 0
Training loss: 1.579769492149353
Validation loss: 1.9318012857949862

Epoch: 5| Step: 1
Training loss: 1.4450470209121704
Validation loss: 1.9227428564461329

Epoch: 5| Step: 2
Training loss: 1.525520920753479
Validation loss: 1.9709841538501043

Epoch: 5| Step: 3
Training loss: 1.3163673877716064
Validation loss: 1.9936994147557083

Epoch: 5| Step: 4
Training loss: 1.5078237056732178
Validation loss: 1.9297972609919887

Epoch: 5| Step: 5
Training loss: 1.599740982055664
Validation loss: 1.9468992576804212

Epoch: 5| Step: 6
Training loss: 1.583321213722229
Validation loss: 1.9664906711988552

Epoch: 5| Step: 7
Training loss: 1.1031333208084106
Validation loss: 1.992417404728551

Epoch: 5| Step: 8
Training loss: 1.3581361770629883
Validation loss: 1.9836070447839715

Epoch: 5| Step: 9
Training loss: 2.226018190383911
Validation loss: 1.9628462740170058

Epoch: 5| Step: 10
Training loss: 2.0458083152770996
Validation loss: 1.9086455004189604

Epoch: 334| Step: 0
Training loss: 1.9082940816879272
Validation loss: 1.9405317652610041

Epoch: 5| Step: 1
Training loss: 0.9843736886978149
Validation loss: 1.9952103014915221

Epoch: 5| Step: 2
Training loss: 2.0454187393188477
Validation loss: 1.953648978664029

Epoch: 5| Step: 3
Training loss: 1.3129689693450928
Validation loss: 1.9832828916529173

Epoch: 5| Step: 4
Training loss: 1.4741990566253662
Validation loss: 1.9343610784058929

Epoch: 5| Step: 5
Training loss: 1.8623148202896118
Validation loss: 1.905631225596192

Epoch: 5| Step: 6
Training loss: 1.2738186120986938
Validation loss: 1.958341299846608

Epoch: 5| Step: 7
Training loss: 1.1022462844848633
Validation loss: 1.9551209736895818

Epoch: 5| Step: 8
Training loss: 1.120802879333496
Validation loss: 1.9337875919957315

Epoch: 5| Step: 9
Training loss: 2.5922014713287354
Validation loss: 1.8803574346726941

Epoch: 5| Step: 10
Training loss: 1.3749208450317383
Validation loss: 1.960462349717335

Epoch: 335| Step: 0
Training loss: 1.3679327964782715
Validation loss: 1.9336557580578713

Epoch: 5| Step: 1
Training loss: 2.1591391563415527
Validation loss: 1.9648832057112007

Epoch: 5| Step: 2
Training loss: 1.5405784845352173
Validation loss: 2.0240340989123107

Epoch: 5| Step: 3
Training loss: 1.603065848350525
Validation loss: 1.977747001955586

Epoch: 5| Step: 4
Training loss: 1.289569616317749
Validation loss: 1.8989752941234137

Epoch: 5| Step: 5
Training loss: 1.6951045989990234
Validation loss: 1.9627485429086993

Epoch: 5| Step: 6
Training loss: 0.9585514068603516
Validation loss: 2.017655118819206

Epoch: 5| Step: 7
Training loss: 1.5463238954544067
Validation loss: 1.9527284099209694

Epoch: 5| Step: 8
Training loss: 2.102322816848755
Validation loss: 1.9707467222726474

Epoch: 5| Step: 9
Training loss: 1.5341002941131592
Validation loss: 1.8813035052309754

Epoch: 5| Step: 10
Training loss: 1.357007384300232
Validation loss: 1.9426036624498264

Epoch: 336| Step: 0
Training loss: 1.2432111501693726
Validation loss: 1.9585583338173487

Epoch: 5| Step: 1
Training loss: 1.3337901830673218
Validation loss: 1.9470269539022957

Epoch: 5| Step: 2
Training loss: 2.2729389667510986
Validation loss: 1.9500250649708573

Epoch: 5| Step: 3
Training loss: 1.4421600103378296
Validation loss: 1.9580157136404386

Epoch: 5| Step: 4
Training loss: 1.43325674533844
Validation loss: 1.9502330544174358

Epoch: 5| Step: 5
Training loss: 2.1482436656951904
Validation loss: 1.9007051324331632

Epoch: 5| Step: 6
Training loss: 0.9478095769882202
Validation loss: 1.942449895284509

Epoch: 5| Step: 7
Training loss: 1.7315212488174438
Validation loss: 1.9476448964047175

Epoch: 5| Step: 8
Training loss: 0.9776831865310669
Validation loss: 1.9237021271900465

Epoch: 5| Step: 9
Training loss: 1.7742118835449219
Validation loss: 1.8890521821155344

Epoch: 5| Step: 10
Training loss: 1.5223935842514038
Validation loss: 1.9562593249864475

Epoch: 337| Step: 0
Training loss: 1.1969718933105469
Validation loss: 1.9395031621379237

Epoch: 5| Step: 1
Training loss: 1.6311876773834229
Validation loss: 1.96349202176576

Epoch: 5| Step: 2
Training loss: 1.7775866985321045
Validation loss: 1.964805999109822

Epoch: 5| Step: 3
Training loss: 1.4980738162994385
Validation loss: 1.9459234450453071

Epoch: 5| Step: 4
Training loss: 1.6974785327911377
Validation loss: 1.9753364132296654

Epoch: 5| Step: 5
Training loss: 1.7392152547836304
Validation loss: 1.9245305086976738

Epoch: 5| Step: 6
Training loss: 1.933760404586792
Validation loss: 1.9408354374670214

Epoch: 5| Step: 7
Training loss: 1.0663903951644897
Validation loss: 1.89240562915802

Epoch: 5| Step: 8
Training loss: 1.623032808303833
Validation loss: 1.9687237624199159

Epoch: 5| Step: 9
Training loss: 1.7598154544830322
Validation loss: 1.9855157072826097

Epoch: 5| Step: 10
Training loss: 1.1374436616897583
Validation loss: 1.9195352818376274

Epoch: 338| Step: 0
Training loss: 1.4052155017852783
Validation loss: 1.9588594090554021

Epoch: 5| Step: 1
Training loss: 1.4360615015029907
Validation loss: 1.909408756481704

Epoch: 5| Step: 2
Training loss: 1.6686725616455078
Validation loss: 1.9660228990739392

Epoch: 5| Step: 3
Training loss: 1.5042585134506226
Validation loss: 1.9141832602921354

Epoch: 5| Step: 4
Training loss: 1.8023769855499268
Validation loss: 1.9209384174757107

Epoch: 5| Step: 5
Training loss: 1.9832799434661865
Validation loss: 1.9357290601217618

Epoch: 5| Step: 6
Training loss: 1.5718497037887573
Validation loss: 1.9410616146620883

Epoch: 5| Step: 7
Training loss: 1.14750075340271
Validation loss: 1.9603361775798183

Epoch: 5| Step: 8
Training loss: 1.5040805339813232
Validation loss: 1.9995852888271373

Epoch: 5| Step: 9
Training loss: 1.1640995740890503
Validation loss: 1.9282481362742763

Epoch: 5| Step: 10
Training loss: 1.6973457336425781
Validation loss: 1.9420157004428167

Epoch: 339| Step: 0
Training loss: 1.5540220737457275
Validation loss: 1.9336641193718038

Epoch: 5| Step: 1
Training loss: 1.324829339981079
Validation loss: 1.9456066444355955

Epoch: 5| Step: 2
Training loss: 1.20615816116333
Validation loss: 1.9626905879666727

Epoch: 5| Step: 3
Training loss: 1.1853001117706299
Validation loss: 1.9449177352331017

Epoch: 5| Step: 4
Training loss: 1.6370207071304321
Validation loss: 1.9361479872016496

Epoch: 5| Step: 5
Training loss: 1.74066960811615
Validation loss: 1.9004435987882717

Epoch: 5| Step: 6
Training loss: 2.046294927597046
Validation loss: 1.9261891534251552

Epoch: 5| Step: 7
Training loss: 1.3536792993545532
Validation loss: 1.9192309494941466

Epoch: 5| Step: 8
Training loss: 1.889081597328186
Validation loss: 1.9520557465091828

Epoch: 5| Step: 9
Training loss: 1.8441498279571533
Validation loss: 1.9585393821039507

Epoch: 5| Step: 10
Training loss: 0.9343308806419373
Validation loss: 1.928963786812239

Epoch: 340| Step: 0
Training loss: 1.5907691717147827
Validation loss: 1.971477577763219

Epoch: 5| Step: 1
Training loss: 1.0375343561172485
Validation loss: 1.9372992079745057

Epoch: 5| Step: 2
Training loss: 1.9062951803207397
Validation loss: 1.9346424020746702

Epoch: 5| Step: 3
Training loss: 1.2301840782165527
Validation loss: 1.9416717239605483

Epoch: 5| Step: 4
Training loss: 1.8274917602539062
Validation loss: 1.8990211486816406

Epoch: 5| Step: 5
Training loss: 1.1193691492080688
Validation loss: 1.959441815653155

Epoch: 5| Step: 6
Training loss: 1.986850380897522
Validation loss: 1.988720699023175

Epoch: 5| Step: 7
Training loss: 1.581473708152771
Validation loss: 1.8810685373121692

Epoch: 5| Step: 8
Training loss: 1.182140588760376
Validation loss: 1.9059617250196395

Epoch: 5| Step: 9
Training loss: 1.9823051691055298
Validation loss: 1.9417672798197756

Epoch: 5| Step: 10
Training loss: 1.3105629682540894
Validation loss: 1.922740090277887

Epoch: 341| Step: 0
Training loss: 1.8521206378936768
Validation loss: 1.9040982313053583

Epoch: 5| Step: 1
Training loss: 1.3982043266296387
Validation loss: 1.974192524469027

Epoch: 5| Step: 2
Training loss: 1.0339152812957764
Validation loss: 1.9170518587994319

Epoch: 5| Step: 3
Training loss: 1.9199879169464111
Validation loss: 1.9415372328091693

Epoch: 5| Step: 4
Training loss: 1.590847373008728
Validation loss: 1.9715544203276276

Epoch: 5| Step: 5
Training loss: 2.114330768585205
Validation loss: 1.9480724014261717

Epoch: 5| Step: 6
Training loss: 1.1018495559692383
Validation loss: 1.9432136063934655

Epoch: 5| Step: 7
Training loss: 1.3876022100448608
Validation loss: 1.9369451897118681

Epoch: 5| Step: 8
Training loss: 1.4366165399551392
Validation loss: 1.9617355241570422

Epoch: 5| Step: 9
Training loss: 1.4967682361602783
Validation loss: 1.951221909574283

Epoch: 5| Step: 10
Training loss: 1.5130524635314941
Validation loss: 1.952672799428304

Epoch: 342| Step: 0
Training loss: 1.4200090169906616
Validation loss: 1.9050385644358974

Epoch: 5| Step: 1
Training loss: 1.0630435943603516
Validation loss: 1.9553184624641173

Epoch: 5| Step: 2
Training loss: 1.2160049676895142
Validation loss: 1.9324948556961552

Epoch: 5| Step: 3
Training loss: 1.3501650094985962
Validation loss: 1.9507754054120792

Epoch: 5| Step: 4
Training loss: 1.406721830368042
Validation loss: 1.9269727519763413

Epoch: 5| Step: 5
Training loss: 1.4717185497283936
Validation loss: 1.9197773766774002

Epoch: 5| Step: 6
Training loss: 2.163327217102051
Validation loss: 1.9712269511274112

Epoch: 5| Step: 7
Training loss: 1.162907361984253
Validation loss: 1.9387246895861883

Epoch: 5| Step: 8
Training loss: 1.797624945640564
Validation loss: 1.9349488981308476

Epoch: 5| Step: 9
Training loss: 1.915911316871643
Validation loss: 1.9297899353888728

Epoch: 5| Step: 10
Training loss: 1.6591322422027588
Validation loss: 1.9561720919865433

Epoch: 343| Step: 0
Training loss: 1.3466498851776123
Validation loss: 1.9241504643553047

Epoch: 5| Step: 1
Training loss: 1.7342888116836548
Validation loss: 1.9377262246224187

Epoch: 5| Step: 2
Training loss: 1.5278539657592773
Validation loss: 1.880217029202369

Epoch: 5| Step: 3
Training loss: 1.5442988872528076
Validation loss: 1.9385494468032674

Epoch: 5| Step: 4
Training loss: 1.4839540719985962
Validation loss: 1.9046043888215096

Epoch: 5| Step: 5
Training loss: 1.5175644159317017
Validation loss: 1.9405248524040304

Epoch: 5| Step: 6
Training loss: 1.3139582872390747
Validation loss: 1.9682293245869298

Epoch: 5| Step: 7
Training loss: 1.1012723445892334
Validation loss: 1.89946577882254

Epoch: 5| Step: 8
Training loss: 1.3846886157989502
Validation loss: 1.9021366642367454

Epoch: 5| Step: 9
Training loss: 1.6230627298355103
Validation loss: 1.8924631995539511

Epoch: 5| Step: 10
Training loss: 2.428194999694824
Validation loss: 1.9781952481116019

Epoch: 344| Step: 0
Training loss: 2.176464557647705
Validation loss: 1.929989876285676

Epoch: 5| Step: 1
Training loss: 1.4814302921295166
Validation loss: 1.9525495882957213

Epoch: 5| Step: 2
Training loss: 1.1851656436920166
Validation loss: 1.9462907724483038

Epoch: 5| Step: 3
Training loss: 1.9038578271865845
Validation loss: 1.895014742369293

Epoch: 5| Step: 4
Training loss: 1.7922000885009766
Validation loss: 2.0137900024332027

Epoch: 5| Step: 5
Training loss: 1.2134737968444824
Validation loss: 1.9527166633195774

Epoch: 5| Step: 6
Training loss: 1.2034746408462524
Validation loss: 2.006957543793545

Epoch: 5| Step: 7
Training loss: 1.4508215188980103
Validation loss: 1.955441128823065

Epoch: 5| Step: 8
Training loss: 1.8158643245697021
Validation loss: 1.9171849014938518

Epoch: 5| Step: 9
Training loss: 1.1590869426727295
Validation loss: 1.9937742397349367

Epoch: 5| Step: 10
Training loss: 1.5292673110961914
Validation loss: 1.9943666919585197

Epoch: 345| Step: 0
Training loss: 1.5247523784637451
Validation loss: 1.964365279802712

Epoch: 5| Step: 1
Training loss: 0.8508325815200806
Validation loss: 1.9394245455341954

Epoch: 5| Step: 2
Training loss: 2.1455302238464355
Validation loss: 1.8976898629178283

Epoch: 5| Step: 3
Training loss: 1.2153434753417969
Validation loss: 1.996466149565994

Epoch: 5| Step: 4
Training loss: 1.2237541675567627
Validation loss: 1.9252444928692234

Epoch: 5| Step: 5
Training loss: 1.621649146080017
Validation loss: 1.9382525810631372

Epoch: 5| Step: 6
Training loss: 1.8130515813827515
Validation loss: 1.9004613225178053

Epoch: 5| Step: 7
Training loss: 1.119746446609497
Validation loss: 1.8993694192619734

Epoch: 5| Step: 8
Training loss: 1.8152167797088623
Validation loss: 1.9943936101851925

Epoch: 5| Step: 9
Training loss: 1.715511679649353
Validation loss: 1.953811212252545

Epoch: 5| Step: 10
Training loss: 1.275255799293518
Validation loss: 1.9476484714015838

Epoch: 346| Step: 0
Training loss: 1.4287668466567993
Validation loss: 1.991221015171338

Epoch: 5| Step: 1
Training loss: 1.866687536239624
Validation loss: 1.9558662317132438

Epoch: 5| Step: 2
Training loss: 1.4112157821655273
Validation loss: 1.891837171328965

Epoch: 5| Step: 3
Training loss: 1.657152533531189
Validation loss: 1.9147577542130665

Epoch: 5| Step: 4
Training loss: 1.9681904315948486
Validation loss: 1.8983455178558186

Epoch: 5| Step: 5
Training loss: 1.6763412952423096
Validation loss: 1.865590169865598

Epoch: 5| Step: 6
Training loss: 1.1329046487808228
Validation loss: 1.9334567464807981

Epoch: 5| Step: 7
Training loss: 1.2724227905273438
Validation loss: 1.918879585881387

Epoch: 5| Step: 8
Training loss: 1.5394468307495117
Validation loss: 1.9397475283632997

Epoch: 5| Step: 9
Training loss: 0.8297542333602905
Validation loss: 2.0092192337077153

Epoch: 5| Step: 10
Training loss: 2.0728583335876465
Validation loss: 1.9623773021082724

Epoch: 347| Step: 0
Training loss: 1.6441514492034912
Validation loss: 1.9518763480647918

Epoch: 5| Step: 1
Training loss: 1.6238540410995483
Validation loss: 1.874712041629258

Epoch: 5| Step: 2
Training loss: 1.1621520519256592
Validation loss: 1.9116793140288322

Epoch: 5| Step: 3
Training loss: 1.1030189990997314
Validation loss: 1.9289882234347764

Epoch: 5| Step: 4
Training loss: 1.7790343761444092
Validation loss: 1.9174112222527946

Epoch: 5| Step: 5
Training loss: 1.6607109308242798
Validation loss: 1.959795444242416

Epoch: 5| Step: 6
Training loss: 1.5204988718032837
Validation loss: 1.9602233620100125

Epoch: 5| Step: 7
Training loss: 1.7268565893173218
Validation loss: 1.9341934611720424

Epoch: 5| Step: 8
Training loss: 0.9384781122207642
Validation loss: 1.9343114027412989

Epoch: 5| Step: 9
Training loss: 1.536308765411377
Validation loss: 1.9305544258445821

Epoch: 5| Step: 10
Training loss: 1.7437416315078735
Validation loss: 1.920186504240959

Epoch: 348| Step: 0
Training loss: 1.894338607788086
Validation loss: 1.9779928474016086

Epoch: 5| Step: 1
Training loss: 1.2495677471160889
Validation loss: 1.9579318390097669

Epoch: 5| Step: 2
Training loss: 1.303187608718872
Validation loss: 1.9609300513421335

Epoch: 5| Step: 3
Training loss: 1.4678617715835571
Validation loss: 1.9100036185274842

Epoch: 5| Step: 4
Training loss: 1.0078016519546509
Validation loss: 1.9618701242631482

Epoch: 5| Step: 5
Training loss: 1.369340181350708
Validation loss: 1.9665417158475487

Epoch: 5| Step: 6
Training loss: 1.7324182987213135
Validation loss: 1.92974784938238

Epoch: 5| Step: 7
Training loss: 1.6646919250488281
Validation loss: 1.9330452590860345

Epoch: 5| Step: 8
Training loss: 1.9445598125457764
Validation loss: 1.9070426353844263

Epoch: 5| Step: 9
Training loss: 1.4567389488220215
Validation loss: 1.9206457778971682

Epoch: 5| Step: 10
Training loss: 1.2272156476974487
Validation loss: 1.9546273203306301

Epoch: 349| Step: 0
Training loss: 1.4272487163543701
Validation loss: 1.8847736979043612

Epoch: 5| Step: 1
Training loss: 0.9384652972221375
Validation loss: 1.9324771947758173

Epoch: 5| Step: 2
Training loss: 1.6414684057235718
Validation loss: 1.907972123033257

Epoch: 5| Step: 3
Training loss: 2.190441608428955
Validation loss: 1.952984945748442

Epoch: 5| Step: 4
Training loss: 1.1818463802337646
Validation loss: 1.9661867926197667

Epoch: 5| Step: 5
Training loss: 1.5347427129745483
Validation loss: 1.9016090913485455

Epoch: 5| Step: 6
Training loss: 1.9094318151474
Validation loss: 1.9375378649721864

Epoch: 5| Step: 7
Training loss: 1.064962387084961
Validation loss: 1.9801133589078022

Epoch: 5| Step: 8
Training loss: 1.7830480337142944
Validation loss: 1.9206728268695135

Epoch: 5| Step: 9
Training loss: 1.374112844467163
Validation loss: 1.930498476951353

Epoch: 5| Step: 10
Training loss: 1.3608136177062988
Validation loss: 1.873618346388622

Epoch: 350| Step: 0
Training loss: 1.1377480030059814
Validation loss: 1.9637783586338002

Epoch: 5| Step: 1
Training loss: 2.0019237995147705
Validation loss: 1.941670730549802

Epoch: 5| Step: 2
Training loss: 1.5843989849090576
Validation loss: 1.9756860040849256

Epoch: 5| Step: 3
Training loss: 1.4168150424957275
Validation loss: 1.9327851469798754

Epoch: 5| Step: 4
Training loss: 2.005970001220703
Validation loss: 1.9408980800259499

Epoch: 5| Step: 5
Training loss: 1.0803104639053345
Validation loss: 1.904111619918577

Epoch: 5| Step: 6
Training loss: 1.4442386627197266
Validation loss: 1.9032496137003745

Epoch: 5| Step: 7
Training loss: 1.518976092338562
Validation loss: 1.9438548267528575

Epoch: 5| Step: 8
Training loss: 1.445411205291748
Validation loss: 1.9380575431290494

Epoch: 5| Step: 9
Training loss: 1.1396732330322266
Validation loss: 1.9187637080428421

Epoch: 5| Step: 10
Training loss: 1.4278792142868042
Validation loss: 1.9737589077282978

Epoch: 351| Step: 0
Training loss: 1.8060553073883057
Validation loss: 1.9297846927437732

Epoch: 5| Step: 1
Training loss: 1.0587518215179443
Validation loss: 1.9300883764861732

Epoch: 5| Step: 2
Training loss: 1.7647740840911865
Validation loss: 1.90539300698106

Epoch: 5| Step: 3
Training loss: 1.7340103387832642
Validation loss: 1.8935275616184357

Epoch: 5| Step: 4
Training loss: 1.1677956581115723
Validation loss: 1.962163758534257

Epoch: 5| Step: 5
Training loss: 0.93115234375
Validation loss: 1.958723142582883

Epoch: 5| Step: 6
Training loss: 1.0612742900848389
Validation loss: 1.9162066239182667

Epoch: 5| Step: 7
Training loss: 1.8315483331680298
Validation loss: 1.888023994302237

Epoch: 5| Step: 8
Training loss: 1.802323579788208
Validation loss: 1.9070147096469838

Epoch: 5| Step: 9
Training loss: 2.0717928409576416
Validation loss: 1.8878029854066911

Epoch: 5| Step: 10
Training loss: 1.222272276878357
Validation loss: 1.9210461775461833

Epoch: 352| Step: 0
Training loss: 1.314171314239502
Validation loss: 1.9312619624599334

Epoch: 5| Step: 1
Training loss: 1.7044098377227783
Validation loss: 1.9424470970707555

Epoch: 5| Step: 2
Training loss: 1.4275505542755127
Validation loss: 2.028678089059809

Epoch: 5| Step: 3
Training loss: 1.7201220989227295
Validation loss: 1.9383639943215154

Epoch: 5| Step: 4
Training loss: 1.6385152339935303
Validation loss: 1.947498385624219

Epoch: 5| Step: 5
Training loss: 0.8464423418045044
Validation loss: 1.9507901258366083

Epoch: 5| Step: 6
Training loss: 1.4200668334960938
Validation loss: 1.9736849492596042

Epoch: 5| Step: 7
Training loss: 1.1806620359420776
Validation loss: 1.9536406314501198

Epoch: 5| Step: 8
Training loss: 1.416505217552185
Validation loss: 1.8956848165040374

Epoch: 5| Step: 9
Training loss: 1.7344658374786377
Validation loss: 1.9405668832922494

Epoch: 5| Step: 10
Training loss: 1.8036726713180542
Validation loss: 1.9011109593094035

Epoch: 353| Step: 0
Training loss: 1.4351766109466553
Validation loss: 1.910841021486508

Epoch: 5| Step: 1
Training loss: 1.0630567073822021
Validation loss: 1.9316757161130187

Epoch: 5| Step: 2
Training loss: 1.7632614374160767
Validation loss: 1.9426764185710619

Epoch: 5| Step: 3
Training loss: 1.2977960109710693
Validation loss: 1.9061556157245432

Epoch: 5| Step: 4
Training loss: 1.526313066482544
Validation loss: 1.9451856279885897

Epoch: 5| Step: 5
Training loss: 1.707405686378479
Validation loss: 1.9111694033427904

Epoch: 5| Step: 6
Training loss: 2.015507698059082
Validation loss: 1.8808725187855382

Epoch: 5| Step: 7
Training loss: 1.5998742580413818
Validation loss: 1.9430731445230462

Epoch: 5| Step: 8
Training loss: 1.049742341041565
Validation loss: 1.991267144039113

Epoch: 5| Step: 9
Training loss: 1.5280745029449463
Validation loss: 1.935112378930533

Epoch: 5| Step: 10
Training loss: 1.1244512796401978
Validation loss: 1.9535004233801236

Epoch: 354| Step: 0
Training loss: 1.931536078453064
Validation loss: 1.9276843455529982

Epoch: 5| Step: 1
Training loss: 1.5320308208465576
Validation loss: 1.9140809953853648

Epoch: 5| Step: 2
Training loss: 1.625006079673767
Validation loss: 1.8446473588225663

Epoch: 5| Step: 3
Training loss: 1.7291147708892822
Validation loss: 1.9322754080577562

Epoch: 5| Step: 4
Training loss: 1.5398566722869873
Validation loss: 1.9046425870669785

Epoch: 5| Step: 5
Training loss: 1.6218688488006592
Validation loss: 1.9643973355652184

Epoch: 5| Step: 6
Training loss: 1.2292238473892212
Validation loss: 1.9608236615375807

Epoch: 5| Step: 7
Training loss: 1.2528438568115234
Validation loss: 1.9469789561404978

Epoch: 5| Step: 8
Training loss: 1.1829171180725098
Validation loss: 1.936152894009826

Epoch: 5| Step: 9
Training loss: 1.4249298572540283
Validation loss: 1.889191835157333

Epoch: 5| Step: 10
Training loss: 1.1546610593795776
Validation loss: 1.9026576524139733

Epoch: 355| Step: 0
Training loss: 1.8547687530517578
Validation loss: 1.8946791618101058

Epoch: 5| Step: 1
Training loss: 0.9187577366828918
Validation loss: 1.9464269575252329

Epoch: 5| Step: 2
Training loss: 0.9410611987113953
Validation loss: 1.9445273145552604

Epoch: 5| Step: 3
Training loss: 1.6218557357788086
Validation loss: 1.9093040753436346

Epoch: 5| Step: 4
Training loss: 1.7122242450714111
Validation loss: 1.8733419167098178

Epoch: 5| Step: 5
Training loss: 1.136026382446289
Validation loss: 1.9205779426841325

Epoch: 5| Step: 6
Training loss: 1.8764606714248657
Validation loss: 1.8878509101047312

Epoch: 5| Step: 7
Training loss: 1.6047770977020264
Validation loss: 1.864872876033988

Epoch: 5| Step: 8
Training loss: 1.4907140731811523
Validation loss: 1.9429788486931914

Epoch: 5| Step: 9
Training loss: 1.6466090679168701
Validation loss: 1.9162903190940939

Epoch: 5| Step: 10
Training loss: 1.1837224960327148
Validation loss: 1.9421155824456164

Epoch: 356| Step: 0
Training loss: 1.7024037837982178
Validation loss: 1.955816573994134

Epoch: 5| Step: 1
Training loss: 1.3857699632644653
Validation loss: 1.9589942719346733

Epoch: 5| Step: 2
Training loss: 1.1924554109573364
Validation loss: 1.9353712502346243

Epoch: 5| Step: 3
Training loss: 1.2863404750823975
Validation loss: 1.9045630475526214

Epoch: 5| Step: 4
Training loss: 1.2392423152923584
Validation loss: 1.939720166626797

Epoch: 5| Step: 5
Training loss: 1.4376084804534912
Validation loss: 1.9581853612776725

Epoch: 5| Step: 6
Training loss: 1.6464630365371704
Validation loss: 1.9506423806631437

Epoch: 5| Step: 7
Training loss: 1.7307138442993164
Validation loss: 1.92191243556238

Epoch: 5| Step: 8
Training loss: 1.8186715841293335
Validation loss: 1.886043699838782

Epoch: 5| Step: 9
Training loss: 1.7372448444366455
Validation loss: 1.9827630237866474

Epoch: 5| Step: 10
Training loss: 1.3269357681274414
Validation loss: 1.9212465363164102

Epoch: 357| Step: 0
Training loss: 1.145652174949646
Validation loss: 1.9905407941469582

Epoch: 5| Step: 1
Training loss: 1.7604963779449463
Validation loss: 1.9537072399611115

Epoch: 5| Step: 2
Training loss: 1.3791849613189697
Validation loss: 1.9757449255194715

Epoch: 5| Step: 3
Training loss: 1.1858068704605103
Validation loss: 1.926250337272562

Epoch: 5| Step: 4
Training loss: 1.3821017742156982
Validation loss: 1.9254363736798685

Epoch: 5| Step: 5
Training loss: 1.2767813205718994
Validation loss: 1.941991690666445

Epoch: 5| Step: 6
Training loss: 0.7462427616119385
Validation loss: 1.9302407990219772

Epoch: 5| Step: 7
Training loss: 2.0401744842529297
Validation loss: 1.897178339701827

Epoch: 5| Step: 8
Training loss: 1.9731495380401611
Validation loss: 1.9015096118373256

Epoch: 5| Step: 9
Training loss: 1.589996337890625
Validation loss: 1.8942610358679166

Epoch: 5| Step: 10
Training loss: 1.594681739807129
Validation loss: 1.9275998082212222

Epoch: 358| Step: 0
Training loss: 0.9159780740737915
Validation loss: 1.9027773103406351

Epoch: 5| Step: 1
Training loss: 1.8451058864593506
Validation loss: 1.9484938524102653

Epoch: 5| Step: 2
Training loss: 1.6904449462890625
Validation loss: 1.8546996565275295

Epoch: 5| Step: 3
Training loss: 1.4828135967254639
Validation loss: 1.907816425446541

Epoch: 5| Step: 4
Training loss: 1.2958608865737915
Validation loss: 1.9379654058846094

Epoch: 5| Step: 5
Training loss: 1.0704915523529053
Validation loss: 1.9463463047499299

Epoch: 5| Step: 6
Training loss: 1.5620181560516357
Validation loss: 1.9357215319910357

Epoch: 5| Step: 7
Training loss: 1.5743639469146729
Validation loss: 1.9344037245678645

Epoch: 5| Step: 8
Training loss: 1.1619186401367188
Validation loss: 1.8410147402876167

Epoch: 5| Step: 9
Training loss: 1.9602031707763672
Validation loss: 1.9203383717485654

Epoch: 5| Step: 10
Training loss: 1.833479404449463
Validation loss: 1.9569051445171397

Epoch: 359| Step: 0
Training loss: 2.3581783771514893
Validation loss: 1.9491616807958132

Epoch: 5| Step: 1
Training loss: 1.1635433435440063
Validation loss: 1.8612464935548845

Epoch: 5| Step: 2
Training loss: 1.3703255653381348
Validation loss: 1.9505781371106383

Epoch: 5| Step: 3
Training loss: 1.7984501123428345
Validation loss: 1.9689771334330242

Epoch: 5| Step: 4
Training loss: 1.4325296878814697
Validation loss: 1.9517512577836231

Epoch: 5| Step: 5
Training loss: 0.7903832197189331
Validation loss: 1.9315223437483593

Epoch: 5| Step: 6
Training loss: 1.2367321252822876
Validation loss: 1.8867447036568836

Epoch: 5| Step: 7
Training loss: 1.3254432678222656
Validation loss: 1.9354347913495955

Epoch: 5| Step: 8
Training loss: 1.328368902206421
Validation loss: 1.8741567275857414

Epoch: 5| Step: 9
Training loss: 1.6082794666290283
Validation loss: 1.8874785054114558

Epoch: 5| Step: 10
Training loss: 1.7556861639022827
Validation loss: 1.8841422039975402

Epoch: 360| Step: 0
Training loss: 1.2628977298736572
Validation loss: 1.8998973843871907

Epoch: 5| Step: 1
Training loss: 1.5156924724578857
Validation loss: 1.9026549682822278

Epoch: 5| Step: 2
Training loss: 1.4397971630096436
Validation loss: 1.911220335191296

Epoch: 5| Step: 3
Training loss: 1.6441478729248047
Validation loss: 1.9785548897199734

Epoch: 5| Step: 4
Training loss: 1.2922556400299072
Validation loss: 1.8925529231307328

Epoch: 5| Step: 5
Training loss: 1.1365731954574585
Validation loss: 1.9701942474611345

Epoch: 5| Step: 6
Training loss: 1.5766475200653076
Validation loss: 1.8852431889503234

Epoch: 5| Step: 7
Training loss: 1.1004679203033447
Validation loss: 1.9394695656273955

Epoch: 5| Step: 8
Training loss: 1.9492247104644775
Validation loss: 1.9337575704820695

Epoch: 5| Step: 9
Training loss: 1.6791350841522217
Validation loss: 1.9150172125908635

Epoch: 5| Step: 10
Training loss: 1.4776005744934082
Validation loss: 1.945295359498711

Epoch: 361| Step: 0
Training loss: 1.5175620317459106
Validation loss: 1.8879324825861121

Epoch: 5| Step: 1
Training loss: 1.2605129480361938
Validation loss: 1.9258150375017555

Epoch: 5| Step: 2
Training loss: 1.0180226564407349
Validation loss: 1.8560903777358353

Epoch: 5| Step: 3
Training loss: 1.1378920078277588
Validation loss: 1.9023300281134985

Epoch: 5| Step: 4
Training loss: 1.615790605545044
Validation loss: 1.8785279604696459

Epoch: 5| Step: 5
Training loss: 1.653860330581665
Validation loss: 1.8662319631986721

Epoch: 5| Step: 6
Training loss: 1.5911827087402344
Validation loss: 1.9204536740497877

Epoch: 5| Step: 7
Training loss: 1.8923108577728271
Validation loss: 1.8880038133231543

Epoch: 5| Step: 8
Training loss: 1.0285789966583252
Validation loss: 1.9480941680169874

Epoch: 5| Step: 9
Training loss: 1.8907697200775146
Validation loss: 1.8738906191241356

Epoch: 5| Step: 10
Training loss: 1.6149775981903076
Validation loss: 1.9028695309033958

Epoch: 362| Step: 0
Training loss: 1.231365442276001
Validation loss: 1.9336366768806212

Epoch: 5| Step: 1
Training loss: 0.8410035371780396
Validation loss: 1.8821516677897463

Epoch: 5| Step: 2
Training loss: 1.676866888999939
Validation loss: 1.914289874415244

Epoch: 5| Step: 3
Training loss: 1.6116520166397095
Validation loss: 1.9073093347651984

Epoch: 5| Step: 4
Training loss: 1.6694303750991821
Validation loss: 1.943162892454414

Epoch: 5| Step: 5
Training loss: 1.4511538743972778
Validation loss: 1.8907438580707838

Epoch: 5| Step: 6
Training loss: 1.530637502670288
Validation loss: 1.94971756012209

Epoch: 5| Step: 7
Training loss: 1.6100728511810303
Validation loss: 1.9387235897843555

Epoch: 5| Step: 8
Training loss: 1.5245200395584106
Validation loss: 1.9277257675765662

Epoch: 5| Step: 9
Training loss: 1.4704475402832031
Validation loss: 1.8795503749642322

Epoch: 5| Step: 10
Training loss: 1.537640929222107
Validation loss: 1.9203769058309577

Epoch: 363| Step: 0
Training loss: 1.7278677225112915
Validation loss: 1.9443794988816785

Epoch: 5| Step: 1
Training loss: 0.8179782629013062
Validation loss: 1.9761786435240059

Epoch: 5| Step: 2
Training loss: 2.016737461090088
Validation loss: 1.8636010282783098

Epoch: 5| Step: 3
Training loss: 1.3162819147109985
Validation loss: 1.9342663723935363

Epoch: 5| Step: 4
Training loss: 1.2422764301300049
Validation loss: 1.9376314199098976

Epoch: 5| Step: 5
Training loss: 1.6926758289337158
Validation loss: 1.885625099623075

Epoch: 5| Step: 6
Training loss: 1.6603000164031982
Validation loss: 1.9174839450467018

Epoch: 5| Step: 7
Training loss: 1.5049407482147217
Validation loss: 1.965654832060619

Epoch: 5| Step: 8
Training loss: 1.6855655908584595
Validation loss: 1.8875919644550612

Epoch: 5| Step: 9
Training loss: 1.0864192247390747
Validation loss: 1.898856883407921

Epoch: 5| Step: 10
Training loss: 1.1485917568206787
Validation loss: 1.9171285616454257

Epoch: 364| Step: 0
Training loss: 1.5730040073394775
Validation loss: 1.9048392823947373

Epoch: 5| Step: 1
Training loss: 1.4837067127227783
Validation loss: 1.9514247140576761

Epoch: 5| Step: 2
Training loss: 1.1994503736495972
Validation loss: 1.9151825610027517

Epoch: 5| Step: 3
Training loss: 1.483595848083496
Validation loss: 1.911734991176154

Epoch: 5| Step: 4
Training loss: 0.7367407083511353
Validation loss: 1.937609326454901

Epoch: 5| Step: 5
Training loss: 1.0660468339920044
Validation loss: 1.9767179053316835

Epoch: 5| Step: 6
Training loss: 1.7214956283569336
Validation loss: 1.9329507697013117

Epoch: 5| Step: 7
Training loss: 1.7312740087509155
Validation loss: 1.9422279839874597

Epoch: 5| Step: 8
Training loss: 1.431330919265747
Validation loss: 1.895550181788783

Epoch: 5| Step: 9
Training loss: 1.8371530771255493
Validation loss: 1.9416373442578059

Epoch: 5| Step: 10
Training loss: 1.3446931838989258
Validation loss: 1.9523782832648164

Epoch: 365| Step: 0
Training loss: 1.2644453048706055
Validation loss: 1.8936436689028175

Epoch: 5| Step: 1
Training loss: 0.7139959335327148
Validation loss: 1.9099564219033847

Epoch: 5| Step: 2
Training loss: 1.4274332523345947
Validation loss: 1.9572555454828406

Epoch: 5| Step: 3
Training loss: 1.9556090831756592
Validation loss: 1.8874631312585646

Epoch: 5| Step: 4
Training loss: 1.8369662761688232
Validation loss: 1.907471223544049

Epoch: 5| Step: 5
Training loss: 1.6045900583267212
Validation loss: 1.8521479560482887

Epoch: 5| Step: 6
Training loss: 1.606966257095337
Validation loss: 1.8818016103518906

Epoch: 5| Step: 7
Training loss: 1.3893567323684692
Validation loss: 1.9179612180238128

Epoch: 5| Step: 8
Training loss: 1.3242002725601196
Validation loss: 1.9017773059106642

Epoch: 5| Step: 9
Training loss: 1.2420270442962646
Validation loss: 1.9546085942176081

Epoch: 5| Step: 10
Training loss: 1.5436104536056519
Validation loss: 1.8764895469911638

Epoch: 366| Step: 0
Training loss: 1.3972575664520264
Validation loss: 1.9479180587235319

Epoch: 5| Step: 1
Training loss: 1.498618483543396
Validation loss: 1.9470670261690695

Epoch: 5| Step: 2
Training loss: 1.2156990766525269
Validation loss: 1.9510416651284823

Epoch: 5| Step: 3
Training loss: 2.0146656036376953
Validation loss: 1.9072964742619505

Epoch: 5| Step: 4
Training loss: 0.9894646406173706
Validation loss: 1.952803183627385

Epoch: 5| Step: 5
Training loss: 1.5892854928970337
Validation loss: 1.9501742521921794

Epoch: 5| Step: 6
Training loss: 1.2665660381317139
Validation loss: 1.8993367007983628

Epoch: 5| Step: 7
Training loss: 1.8070558309555054
Validation loss: 1.8628145481950493

Epoch: 5| Step: 8
Training loss: 1.3346374034881592
Validation loss: 1.927262734341365

Epoch: 5| Step: 9
Training loss: 1.5448614358901978
Validation loss: 1.8958807529941681

Epoch: 5| Step: 10
Training loss: 1.2969578504562378
Validation loss: 1.8976000303863196

Epoch: 367| Step: 0
Training loss: 1.7951358556747437
Validation loss: 1.9337845233178907

Epoch: 5| Step: 1
Training loss: 1.6583678722381592
Validation loss: 1.9075742767703148

Epoch: 5| Step: 2
Training loss: 0.975794792175293
Validation loss: 1.9099731342766875

Epoch: 5| Step: 3
Training loss: 1.272155523300171
Validation loss: 1.9334706055220736

Epoch: 5| Step: 4
Training loss: 1.3400089740753174
Validation loss: 1.9474871568782355

Epoch: 5| Step: 5
Training loss: 1.3267074823379517
Validation loss: 1.891670516742173

Epoch: 5| Step: 6
Training loss: 1.0148111581802368
Validation loss: 1.8941350034488145

Epoch: 5| Step: 7
Training loss: 1.52011239528656
Validation loss: 1.8766221384848318

Epoch: 5| Step: 8
Training loss: 1.563990831375122
Validation loss: 1.9354742816699448

Epoch: 5| Step: 9
Training loss: 1.6036583185195923
Validation loss: 1.9249194463094075

Epoch: 5| Step: 10
Training loss: 1.6446887254714966
Validation loss: 1.9049333474969352

Epoch: 368| Step: 0
Training loss: 1.940504789352417
Validation loss: 1.903190646120297

Epoch: 5| Step: 1
Training loss: 1.936131477355957
Validation loss: 1.902802351982363

Epoch: 5| Step: 2
Training loss: 1.2111839056015015
Validation loss: 1.9396205204789356

Epoch: 5| Step: 3
Training loss: 1.324617624282837
Validation loss: 1.898370712034164

Epoch: 5| Step: 4
Training loss: 1.9554812908172607
Validation loss: 1.9091434991487892

Epoch: 5| Step: 5
Training loss: 1.1675918102264404
Validation loss: 1.929760242021212

Epoch: 5| Step: 6
Training loss: 1.2335407733917236
Validation loss: 1.9277495107343119

Epoch: 5| Step: 7
Training loss: 1.3373687267303467
Validation loss: 1.891031962569042

Epoch: 5| Step: 8
Training loss: 1.0990402698516846
Validation loss: 1.9259657987984278

Epoch: 5| Step: 9
Training loss: 1.4569305181503296
Validation loss: 1.9106299390075028

Epoch: 5| Step: 10
Training loss: 1.1401885747909546
Validation loss: 1.8800417966740106

Epoch: 369| Step: 0
Training loss: 1.7778174877166748
Validation loss: 1.9178826693565614

Epoch: 5| Step: 1
Training loss: 1.1397393941879272
Validation loss: 1.8319358300137263

Epoch: 5| Step: 2
Training loss: 1.4959895610809326
Validation loss: 1.917888092738326

Epoch: 5| Step: 3
Training loss: 2.094672679901123
Validation loss: 1.9129246550221597

Epoch: 5| Step: 4
Training loss: 1.807684302330017
Validation loss: 1.887850797304543

Epoch: 5| Step: 5
Training loss: 1.3034385442733765
Validation loss: 1.8994108066763928

Epoch: 5| Step: 6
Training loss: 1.2803242206573486
Validation loss: 1.8871384154083908

Epoch: 5| Step: 7
Training loss: 1.5468971729278564
Validation loss: 1.9675309465777489

Epoch: 5| Step: 8
Training loss: 0.854932427406311
Validation loss: 1.8639754428658435

Epoch: 5| Step: 9
Training loss: 1.5055779218673706
Validation loss: 1.9206447870500627

Epoch: 5| Step: 10
Training loss: 1.035731554031372
Validation loss: 1.9488014162227671

Epoch: 370| Step: 0
Training loss: 1.2139356136322021
Validation loss: 1.9194917114832069

Epoch: 5| Step: 1
Training loss: 1.4433937072753906
Validation loss: 1.9707763566765735

Epoch: 5| Step: 2
Training loss: 1.6004343032836914
Validation loss: 1.895872062252414

Epoch: 5| Step: 3
Training loss: 0.8244377970695496
Validation loss: 1.9448545684096634

Epoch: 5| Step: 4
Training loss: 0.9701094627380371
Validation loss: 1.9050224006816905

Epoch: 5| Step: 5
Training loss: 1.1624852418899536
Validation loss: 1.8992629935664516

Epoch: 5| Step: 6
Training loss: 1.6572338342666626
Validation loss: 1.8912782835704025

Epoch: 5| Step: 7
Training loss: 1.9768102169036865
Validation loss: 1.9274902651386876

Epoch: 5| Step: 8
Training loss: 1.593122124671936
Validation loss: 1.9274038973674978

Epoch: 5| Step: 9
Training loss: 1.9246963262557983
Validation loss: 1.9086908781400291

Epoch: 5| Step: 10
Training loss: 1.430575966835022
Validation loss: 1.9096990426381428

Epoch: 371| Step: 0
Training loss: 1.6348384618759155
Validation loss: 1.9239828484032744

Epoch: 5| Step: 1
Training loss: 1.2511117458343506
Validation loss: 1.8983691341133528

Epoch: 5| Step: 2
Training loss: 1.3154977560043335
Validation loss: 1.906282240344632

Epoch: 5| Step: 3
Training loss: 1.509503722190857
Validation loss: 1.9240973931486889

Epoch: 5| Step: 4
Training loss: 1.388445496559143
Validation loss: 1.9092267277420207

Epoch: 5| Step: 5
Training loss: 1.0511693954467773
Validation loss: 1.9043744148746613

Epoch: 5| Step: 6
Training loss: 1.3467015027999878
Validation loss: 1.9172377509455527

Epoch: 5| Step: 7
Training loss: 1.4702144861221313
Validation loss: 1.9245072487861878

Epoch: 5| Step: 8
Training loss: 1.8477652072906494
Validation loss: 1.8740634097847888

Epoch: 5| Step: 9
Training loss: 1.7223336696624756
Validation loss: 1.9103215304754113

Epoch: 5| Step: 10
Training loss: 1.1969481706619263
Validation loss: 1.9105884029019264

Epoch: 372| Step: 0
Training loss: 1.124171495437622
Validation loss: 1.9687107673255346

Epoch: 5| Step: 1
Training loss: 1.6342887878417969
Validation loss: 1.898406785021546

Epoch: 5| Step: 2
Training loss: 1.3530502319335938
Validation loss: 1.911577905378034

Epoch: 5| Step: 3
Training loss: 1.7317168712615967
Validation loss: 1.8854176575137722

Epoch: 5| Step: 4
Training loss: 1.5243726968765259
Validation loss: 1.935335777780061

Epoch: 5| Step: 5
Training loss: 1.6159751415252686
Validation loss: 1.919024855859818

Epoch: 5| Step: 6
Training loss: 1.182719349861145
Validation loss: 1.8942364954179334

Epoch: 5| Step: 7
Training loss: 1.4287440776824951
Validation loss: 1.8832636469153947

Epoch: 5| Step: 8
Training loss: 1.7742904424667358
Validation loss: 1.8952199207839144

Epoch: 5| Step: 9
Training loss: 1.3447165489196777
Validation loss: 1.875827040723575

Epoch: 5| Step: 10
Training loss: 1.0383745431900024
Validation loss: 1.8565902940688594

Epoch: 373| Step: 0
Training loss: 1.0717122554779053
Validation loss: 1.891697044013649

Epoch: 5| Step: 1
Training loss: 1.759042501449585
Validation loss: 1.9406841416512766

Epoch: 5| Step: 2
Training loss: 1.2984596490859985
Validation loss: 1.912957247867379

Epoch: 5| Step: 3
Training loss: 1.1209052801132202
Validation loss: 1.9194351716708111

Epoch: 5| Step: 4
Training loss: 1.523790955543518
Validation loss: 1.9471680989829443

Epoch: 5| Step: 5
Training loss: 1.2896957397460938
Validation loss: 1.8949266031224241

Epoch: 5| Step: 6
Training loss: 1.3354685306549072
Validation loss: 1.8580927759088495

Epoch: 5| Step: 7
Training loss: 1.4530330896377563
Validation loss: 1.9942832557103967

Epoch: 5| Step: 8
Training loss: 1.2979567050933838
Validation loss: 1.929737465355986

Epoch: 5| Step: 9
Training loss: 1.5161800384521484
Validation loss: 1.9833167188911027

Epoch: 5| Step: 10
Training loss: 2.0560991764068604
Validation loss: 1.8849632060655983

Epoch: 374| Step: 0
Training loss: 1.4473991394042969
Validation loss: 1.878404296854491

Epoch: 5| Step: 1
Training loss: 1.6190770864486694
Validation loss: 1.9123747451331026

Epoch: 5| Step: 2
Training loss: 1.3910223245620728
Validation loss: 1.9309308118717645

Epoch: 5| Step: 3
Training loss: 1.0429025888442993
Validation loss: 1.9383860582946448

Epoch: 5| Step: 4
Training loss: 1.4512760639190674
Validation loss: 1.9415848434612315

Epoch: 5| Step: 5
Training loss: 2.1127634048461914
Validation loss: 1.9583836601626488

Epoch: 5| Step: 6
Training loss: 1.2856320142745972
Validation loss: 1.9496105012073313

Epoch: 5| Step: 7
Training loss: 1.2180544137954712
Validation loss: 1.910240650177002

Epoch: 5| Step: 8
Training loss: 1.3824981451034546
Validation loss: 1.9036945604508924

Epoch: 5| Step: 9
Training loss: 1.390235424041748
Validation loss: 1.8861617311354606

Epoch: 5| Step: 10
Training loss: 1.3149043321609497
Validation loss: 1.905949713081442

Epoch: 375| Step: 0
Training loss: 1.094794750213623
Validation loss: 1.941032850614158

Epoch: 5| Step: 1
Training loss: 1.3762632608413696
Validation loss: 1.9347637866133003

Epoch: 5| Step: 2
Training loss: 1.1059033870697021
Validation loss: 1.9051819668021253

Epoch: 5| Step: 3
Training loss: 1.2169262170791626
Validation loss: 1.891532854367328

Epoch: 5| Step: 4
Training loss: 1.7321689128875732
Validation loss: 1.9263896352501326

Epoch: 5| Step: 5
Training loss: 1.3827784061431885
Validation loss: 1.965708665950324

Epoch: 5| Step: 6
Training loss: 1.3898283243179321
Validation loss: 1.9449311110281176

Epoch: 5| Step: 7
Training loss: 1.7544130086898804
Validation loss: 1.9034475562393025

Epoch: 5| Step: 8
Training loss: 2.1793265342712402
Validation loss: 1.839960236703196

Epoch: 5| Step: 9
Training loss: 1.3613582849502563
Validation loss: 1.8563077783071866

Epoch: 5| Step: 10
Training loss: 1.2157988548278809
Validation loss: 1.8864493498238184

Epoch: 376| Step: 0
Training loss: 1.071128487586975
Validation loss: 1.8971163829167683

Epoch: 5| Step: 1
Training loss: 1.5389827489852905
Validation loss: 1.9056257176142868

Epoch: 5| Step: 2
Training loss: 1.1997132301330566
Validation loss: 1.8937971207403368

Epoch: 5| Step: 3
Training loss: 1.2446987628936768
Validation loss: 1.9732127163999824

Epoch: 5| Step: 4
Training loss: 1.4378650188446045
Validation loss: 1.8851909381087109

Epoch: 5| Step: 5
Training loss: 1.7179969549179077
Validation loss: 1.9410371165121756

Epoch: 5| Step: 6
Training loss: 1.1218327283859253
Validation loss: 1.8911990017019293

Epoch: 5| Step: 7
Training loss: 1.8022029399871826
Validation loss: 1.9447198170487598

Epoch: 5| Step: 8
Training loss: 1.3756545782089233
Validation loss: 1.9621141097878898

Epoch: 5| Step: 9
Training loss: 1.5419379472732544
Validation loss: 1.9252440967867452

Epoch: 5| Step: 10
Training loss: 1.947503685951233
Validation loss: 1.8936052066023632

Epoch: 377| Step: 0
Training loss: 1.1278841495513916
Validation loss: 1.8857658037575342

Epoch: 5| Step: 1
Training loss: 0.9543550610542297
Validation loss: 1.9107197433389642

Epoch: 5| Step: 2
Training loss: 1.7086025476455688
Validation loss: 1.9413730867447392

Epoch: 5| Step: 3
Training loss: 1.6653823852539062
Validation loss: 1.972935071555517

Epoch: 5| Step: 4
Training loss: 0.8867802619934082
Validation loss: 1.935939194053732

Epoch: 5| Step: 5
Training loss: 1.5275156497955322
Validation loss: 1.870006033169326

Epoch: 5| Step: 6
Training loss: 1.3657169342041016
Validation loss: 1.920662828671035

Epoch: 5| Step: 7
Training loss: 1.3839424848556519
Validation loss: 1.9427975198274017

Epoch: 5| Step: 8
Training loss: 1.2587392330169678
Validation loss: 1.9353657973709928

Epoch: 5| Step: 9
Training loss: 1.988997459411621
Validation loss: 1.8956480820973713

Epoch: 5| Step: 10
Training loss: 1.5404268503189087
Validation loss: 1.9094815279847832

Epoch: 378| Step: 0
Training loss: 1.8396613597869873
Validation loss: 1.9629524882121752

Epoch: 5| Step: 1
Training loss: 1.1895372867584229
Validation loss: 1.9197981075573993

Epoch: 5| Step: 2
Training loss: 1.1647708415985107
Validation loss: 1.8910841480378182

Epoch: 5| Step: 3
Training loss: 1.6095021963119507
Validation loss: 1.9133249905801588

Epoch: 5| Step: 4
Training loss: 0.8755084276199341
Validation loss: 1.9272277355194092

Epoch: 5| Step: 5
Training loss: 1.9589691162109375
Validation loss: 1.9663770814095773

Epoch: 5| Step: 6
Training loss: 1.8551079034805298
Validation loss: 1.9225354092095488

Epoch: 5| Step: 7
Training loss: 1.339133620262146
Validation loss: 1.9329478689419326

Epoch: 5| Step: 8
Training loss: 1.330472707748413
Validation loss: 1.9414061051543041

Epoch: 5| Step: 9
Training loss: 1.1015514135360718
Validation loss: 1.900700193579479

Epoch: 5| Step: 10
Training loss: 1.0789767503738403
Validation loss: 1.9601039578837733

Epoch: 379| Step: 0
Training loss: 1.1410644054412842
Validation loss: 1.9120645343616445

Epoch: 5| Step: 1
Training loss: 1.8507732152938843
Validation loss: 1.9167469188731203

Epoch: 5| Step: 2
Training loss: 1.3991570472717285
Validation loss: 1.8940978293777795

Epoch: 5| Step: 3
Training loss: 1.558555006980896
Validation loss: 1.9042965532631002

Epoch: 5| Step: 4
Training loss: 1.7783420085906982
Validation loss: 1.9337022099443661

Epoch: 5| Step: 5
Training loss: 1.6372606754302979
Validation loss: 1.9271338960175872

Epoch: 5| Step: 6
Training loss: 1.164756178855896
Validation loss: 1.9499791668307396

Epoch: 5| Step: 7
Training loss: 1.5122610330581665
Validation loss: 1.9339137051695137

Epoch: 5| Step: 8
Training loss: 1.0497124195098877
Validation loss: 1.885438537084928

Epoch: 5| Step: 9
Training loss: 1.141318440437317
Validation loss: 1.8441652841465448

Epoch: 5| Step: 10
Training loss: 1.6228065490722656
Validation loss: 1.8813451772095056

Epoch: 380| Step: 0
Training loss: 0.8701573610305786
Validation loss: 1.853546948843105

Epoch: 5| Step: 1
Training loss: 1.9770734310150146
Validation loss: 1.9114150129338747

Epoch: 5| Step: 2
Training loss: 1.3937976360321045
Validation loss: 1.9179050794211767

Epoch: 5| Step: 3
Training loss: 1.456658124923706
Validation loss: 1.9404432876135713

Epoch: 5| Step: 4
Training loss: 1.020332932472229
Validation loss: 1.8944853531417025

Epoch: 5| Step: 5
Training loss: 1.5968583822250366
Validation loss: 1.8642009368506811

Epoch: 5| Step: 6
Training loss: 1.9548161029815674
Validation loss: 1.959739141566779

Epoch: 5| Step: 7
Training loss: 1.6843818426132202
Validation loss: 1.9289338934806086

Epoch: 5| Step: 8
Training loss: 1.4203050136566162
Validation loss: 1.9548698676529752

Epoch: 5| Step: 9
Training loss: 1.2714513540267944
Validation loss: 1.8913943985457062

Epoch: 5| Step: 10
Training loss: 1.3146350383758545
Validation loss: 1.918996662221929

Epoch: 381| Step: 0
Training loss: 1.4429527521133423
Validation loss: 1.9078798627340665

Epoch: 5| Step: 1
Training loss: 1.46550714969635
Validation loss: 1.9312476842634139

Epoch: 5| Step: 2
Training loss: 1.7394444942474365
Validation loss: 1.9152758300945323

Epoch: 5| Step: 3
Training loss: 1.0514233112335205
Validation loss: 1.9279190365986159

Epoch: 5| Step: 4
Training loss: 1.443903923034668
Validation loss: 1.9459421288582586

Epoch: 5| Step: 5
Training loss: 1.3957066535949707
Validation loss: 1.923904102335694

Epoch: 5| Step: 6
Training loss: 2.0446417331695557
Validation loss: 1.8925433158874512

Epoch: 5| Step: 7
Training loss: 1.6549466848373413
Validation loss: 1.8765791641768588

Epoch: 5| Step: 8
Training loss: 1.3256654739379883
Validation loss: 1.9065418166498984

Epoch: 5| Step: 9
Training loss: 1.0251659154891968
Validation loss: 1.8503629084556334

Epoch: 5| Step: 10
Training loss: 1.1166011095046997
Validation loss: 1.893340790143577

Epoch: 382| Step: 0
Training loss: 1.3144333362579346
Validation loss: 1.9024926077935003

Epoch: 5| Step: 1
Training loss: 1.607200026512146
Validation loss: 1.8624268757399691

Epoch: 5| Step: 2
Training loss: 1.4644581079483032
Validation loss: 1.9104635484756962

Epoch: 5| Step: 3
Training loss: 1.596463918685913
Validation loss: 1.8373398011730564

Epoch: 5| Step: 4
Training loss: 1.227936029434204
Validation loss: 1.9133750751454344

Epoch: 5| Step: 5
Training loss: 1.4835153818130493
Validation loss: 1.8595111549541514

Epoch: 5| Step: 6
Training loss: 0.8176651000976562
Validation loss: 1.9076003925774687

Epoch: 5| Step: 7
Training loss: 1.0360203981399536
Validation loss: 1.9383589272857995

Epoch: 5| Step: 8
Training loss: 1.9865849018096924
Validation loss: 1.948070441522906

Epoch: 5| Step: 9
Training loss: 1.1647982597351074
Validation loss: 1.8784781553411996

Epoch: 5| Step: 10
Training loss: 1.509411334991455
Validation loss: 1.8910690135853265

Epoch: 383| Step: 0
Training loss: 1.0268369913101196
Validation loss: 1.8978927596922843

Epoch: 5| Step: 1
Training loss: 1.483816146850586
Validation loss: 1.9003204158557359

Epoch: 5| Step: 2
Training loss: 1.685243010520935
Validation loss: 1.877316290332425

Epoch: 5| Step: 3
Training loss: 1.1511540412902832
Validation loss: 1.9076779286066692

Epoch: 5| Step: 4
Training loss: 1.6991363763809204
Validation loss: 1.8458873200160202

Epoch: 5| Step: 5
Training loss: 1.1905739307403564
Validation loss: 1.922540650572828

Epoch: 5| Step: 6
Training loss: 1.3563506603240967
Validation loss: 1.9474025618645452

Epoch: 5| Step: 7
Training loss: 1.227709412574768
Validation loss: 1.9195358548113095

Epoch: 5| Step: 8
Training loss: 1.6672251224517822
Validation loss: 1.8946511437816005

Epoch: 5| Step: 9
Training loss: 1.8607404232025146
Validation loss: 1.9246529174107376

Epoch: 5| Step: 10
Training loss: 1.0758426189422607
Validation loss: 1.8832250513056272

Epoch: 384| Step: 0
Training loss: 1.2277991771697998
Validation loss: 1.8646687499938472

Epoch: 5| Step: 1
Training loss: 1.5702917575836182
Validation loss: 1.9250844999026226

Epoch: 5| Step: 2
Training loss: 1.760461449623108
Validation loss: 1.8692219590628019

Epoch: 5| Step: 3
Training loss: 1.851525902748108
Validation loss: 1.8962142723862843

Epoch: 5| Step: 4
Training loss: 1.4073888063430786
Validation loss: 1.8825894107100785

Epoch: 5| Step: 5
Training loss: 1.584646463394165
Validation loss: 1.9195572586469754

Epoch: 5| Step: 6
Training loss: 1.1201250553131104
Validation loss: 1.8518762383409726

Epoch: 5| Step: 7
Training loss: 1.4288673400878906
Validation loss: 1.9450660405620452

Epoch: 5| Step: 8
Training loss: 1.6539567708969116
Validation loss: 1.9135338119281236

Epoch: 5| Step: 9
Training loss: 1.1418542861938477
Validation loss: 1.85833905589196

Epoch: 5| Step: 10
Training loss: 0.6321195363998413
Validation loss: 1.915854287403886

Epoch: 385| Step: 0
Training loss: 1.5230979919433594
Validation loss: 1.8612332382509786

Epoch: 5| Step: 1
Training loss: 1.2113902568817139
Validation loss: 1.8560173460232314

Epoch: 5| Step: 2
Training loss: 1.2195370197296143
Validation loss: 1.9235250437131493

Epoch: 5| Step: 3
Training loss: 1.1324074268341064
Validation loss: 1.8771784523481965

Epoch: 5| Step: 4
Training loss: 1.103070616722107
Validation loss: 1.8950290846568283

Epoch: 5| Step: 5
Training loss: 1.569949746131897
Validation loss: 1.893765805869974

Epoch: 5| Step: 6
Training loss: 1.8294782638549805
Validation loss: 1.8803960033642348

Epoch: 5| Step: 7
Training loss: 1.546884536743164
Validation loss: 1.9437830358423211

Epoch: 5| Step: 8
Training loss: 1.453412652015686
Validation loss: 1.864131078925184

Epoch: 5| Step: 9
Training loss: 1.3925848007202148
Validation loss: 1.8999394139935892

Epoch: 5| Step: 10
Training loss: 1.011333703994751
Validation loss: 1.8982147991016347

Epoch: 386| Step: 0
Training loss: 1.6538079977035522
Validation loss: 1.9152651256130588

Epoch: 5| Step: 1
Training loss: 1.3063361644744873
Validation loss: 1.869482062837129

Epoch: 5| Step: 2
Training loss: 1.1506654024124146
Validation loss: 1.9020228924289826

Epoch: 5| Step: 3
Training loss: 1.5448020696640015
Validation loss: 1.9355572654354958

Epoch: 5| Step: 4
Training loss: 1.8322193622589111
Validation loss: 1.909995851978179

Epoch: 5| Step: 5
Training loss: 1.0307897329330444
Validation loss: 1.932827047122422

Epoch: 5| Step: 6
Training loss: 1.528259038925171
Validation loss: 1.9630460867317774

Epoch: 5| Step: 7
Training loss: 1.3350353240966797
Validation loss: 1.8300270124148297

Epoch: 5| Step: 8
Training loss: 1.2823413610458374
Validation loss: 1.8854938463498188

Epoch: 5| Step: 9
Training loss: 1.15239679813385
Validation loss: 1.869568911931848

Epoch: 5| Step: 10
Training loss: 1.4636081457138062
Validation loss: 1.9621176424846853

Epoch: 387| Step: 0
Training loss: 1.3580950498580933
Validation loss: 1.9120893747575822

Epoch: 5| Step: 1
Training loss: 1.3312461376190186
Validation loss: 1.9338265183151409

Epoch: 5| Step: 2
Training loss: 1.6859136819839478
Validation loss: 1.9079272388130106

Epoch: 5| Step: 3
Training loss: 1.1741693019866943
Validation loss: 1.8638453252853886

Epoch: 5| Step: 4
Training loss: 1.2608835697174072
Validation loss: 1.9172939305664392

Epoch: 5| Step: 5
Training loss: 0.9490774869918823
Validation loss: 1.8995953708566644

Epoch: 5| Step: 6
Training loss: 1.4673711061477661
Validation loss: 1.9065133653661257

Epoch: 5| Step: 7
Training loss: 1.8988401889801025
Validation loss: 1.9305312428423154

Epoch: 5| Step: 8
Training loss: 1.311374545097351
Validation loss: 1.9000797579365392

Epoch: 5| Step: 9
Training loss: 1.1572763919830322
Validation loss: 1.9197291610061482

Epoch: 5| Step: 10
Training loss: 1.3648756742477417
Validation loss: 1.9051456861598517

Epoch: 388| Step: 0
Training loss: 1.2921485900878906
Validation loss: 1.946359142180412

Epoch: 5| Step: 1
Training loss: 1.7519422769546509
Validation loss: 1.8844251863418087

Epoch: 5| Step: 2
Training loss: 1.0695631504058838
Validation loss: 1.9389757661409275

Epoch: 5| Step: 3
Training loss: 1.287793517112732
Validation loss: 1.913568728713579

Epoch: 5| Step: 4
Training loss: 1.5489721298217773
Validation loss: 1.8879634052194574

Epoch: 5| Step: 5
Training loss: 1.5969301462173462
Validation loss: 1.934204157962594

Epoch: 5| Step: 6
Training loss: 1.2443678379058838
Validation loss: 1.895023892002721

Epoch: 5| Step: 7
Training loss: 1.5693919658660889
Validation loss: 1.8941952874583583

Epoch: 5| Step: 8
Training loss: 1.2428396940231323
Validation loss: 1.8908425454170472

Epoch: 5| Step: 9
Training loss: 1.3365129232406616
Validation loss: 1.916557486339282

Epoch: 5| Step: 10
Training loss: 1.3365494012832642
Validation loss: 1.9443243165169992

Epoch: 389| Step: 0
Training loss: 1.6812372207641602
Validation loss: 1.955943561369373

Epoch: 5| Step: 1
Training loss: 1.1203399896621704
Validation loss: 1.9200286455051874

Epoch: 5| Step: 2
Training loss: 1.4824597835540771
Validation loss: 1.8903454298614173

Epoch: 5| Step: 3
Training loss: 1.6156905889511108
Validation loss: 1.9362168004435878

Epoch: 5| Step: 4
Training loss: 1.489169716835022
Validation loss: 1.8614999132771646

Epoch: 5| Step: 5
Training loss: 1.210191011428833
Validation loss: 1.9436534066354074

Epoch: 5| Step: 6
Training loss: 1.3755625486373901
Validation loss: 1.868812745617282

Epoch: 5| Step: 7
Training loss: 0.9976640939712524
Validation loss: 1.91414826403382

Epoch: 5| Step: 8
Training loss: 1.5168834924697876
Validation loss: 1.9296535548343454

Epoch: 5| Step: 9
Training loss: 1.2671585083007812
Validation loss: 1.9889302087086502

Epoch: 5| Step: 10
Training loss: 1.7723257541656494
Validation loss: 1.9893061960897138

Epoch: 390| Step: 0
Training loss: 1.4022367000579834
Validation loss: 1.9551768713099982

Epoch: 5| Step: 1
Training loss: 1.3636581897735596
Validation loss: 1.9174025904747747

Epoch: 5| Step: 2
Training loss: 1.2722104787826538
Validation loss: 1.9461763725485852

Epoch: 5| Step: 3
Training loss: 1.3316247463226318
Validation loss: 1.9155918013664983

Epoch: 5| Step: 4
Training loss: 1.1694402694702148
Validation loss: 1.8715756759848645

Epoch: 5| Step: 5
Training loss: 1.4006106853485107
Validation loss: 1.9202921826352355

Epoch: 5| Step: 6
Training loss: 1.586342215538025
Validation loss: 1.941061483916416

Epoch: 5| Step: 7
Training loss: 1.1369900703430176
Validation loss: 1.9186335930260279

Epoch: 5| Step: 8
Training loss: 1.4280281066894531
Validation loss: 1.8354912316927345

Epoch: 5| Step: 9
Training loss: 1.314546823501587
Validation loss: 1.9078732177775393

Epoch: 5| Step: 10
Training loss: 1.8763710260391235
Validation loss: 1.9171668880729265

Epoch: 391| Step: 0
Training loss: 1.0398290157318115
Validation loss: 1.9113586333490187

Epoch: 5| Step: 1
Training loss: 2.014662504196167
Validation loss: 1.8839467084535988

Epoch: 5| Step: 2
Training loss: 1.5795866250991821
Validation loss: 1.9486620503087198

Epoch: 5| Step: 3
Training loss: 1.1190993785858154
Validation loss: 1.8788824568512619

Epoch: 5| Step: 4
Training loss: 0.998447597026825
Validation loss: 1.8901381518251152

Epoch: 5| Step: 5
Training loss: 0.6094751358032227
Validation loss: 1.8998010914812806

Epoch: 5| Step: 6
Training loss: 1.9705692529678345
Validation loss: 1.9157007740389915

Epoch: 5| Step: 7
Training loss: 1.5836204290390015
Validation loss: 1.9298781271903747

Epoch: 5| Step: 8
Training loss: 1.2563599348068237
Validation loss: 1.9616066448150142

Epoch: 5| Step: 9
Training loss: 1.457371473312378
Validation loss: 1.8758623843551965

Epoch: 5| Step: 10
Training loss: 1.073108196258545
Validation loss: 1.915970310088127

Epoch: 392| Step: 0
Training loss: 0.9475961923599243
Validation loss: 1.9184815447817567

Epoch: 5| Step: 1
Training loss: 1.3518388271331787
Validation loss: 1.891856570397654

Epoch: 5| Step: 2
Training loss: 1.8420976400375366
Validation loss: 1.8696694963721818

Epoch: 5| Step: 3
Training loss: 1.240549087524414
Validation loss: 1.9206025497887724

Epoch: 5| Step: 4
Training loss: 1.6514604091644287
Validation loss: 1.8786545581715082

Epoch: 5| Step: 5
Training loss: 1.3699686527252197
Validation loss: 1.8481258782007361

Epoch: 5| Step: 6
Training loss: 1.4293806552886963
Validation loss: 1.9021576783990348

Epoch: 5| Step: 7
Training loss: 1.5472739934921265
Validation loss: 1.902701549632575

Epoch: 5| Step: 8
Training loss: 1.0815727710723877
Validation loss: 1.9054998377318024

Epoch: 5| Step: 9
Training loss: 1.1483354568481445
Validation loss: 1.9396386505455099

Epoch: 5| Step: 10
Training loss: 1.4163789749145508
Validation loss: 1.924919674473424

Epoch: 393| Step: 0
Training loss: 1.0365387201309204
Validation loss: 1.9609416889887985

Epoch: 5| Step: 1
Training loss: 1.4263145923614502
Validation loss: 1.9249586277110602

Epoch: 5| Step: 2
Training loss: 1.4832878112792969
Validation loss: 1.955406517110845

Epoch: 5| Step: 3
Training loss: 1.341755986213684
Validation loss: 1.8991777486698602

Epoch: 5| Step: 4
Training loss: 1.0420974493026733
Validation loss: 1.925131304289705

Epoch: 5| Step: 5
Training loss: 1.3197567462921143
Validation loss: 1.8994041963290142

Epoch: 5| Step: 6
Training loss: 1.7598609924316406
Validation loss: 1.8822338042720672

Epoch: 5| Step: 7
Training loss: 0.7517411708831787
Validation loss: 1.9234810670216878

Epoch: 5| Step: 8
Training loss: 1.1939032077789307
Validation loss: 1.8916197105120587

Epoch: 5| Step: 9
Training loss: 1.3793107271194458
Validation loss: 1.9129092898420108

Epoch: 5| Step: 10
Training loss: 2.1348888874053955
Validation loss: 1.9183418661035516

Epoch: 394| Step: 0
Training loss: 1.300315260887146
Validation loss: 1.8399203310730636

Epoch: 5| Step: 1
Training loss: 1.082249641418457
Validation loss: 1.9342365944257347

Epoch: 5| Step: 2
Training loss: 1.4140547513961792
Validation loss: 1.9280526176575692

Epoch: 5| Step: 3
Training loss: 1.3711073398590088
Validation loss: 1.9258436502948884

Epoch: 5| Step: 4
Training loss: 1.3912689685821533
Validation loss: 1.9141816016166442

Epoch: 5| Step: 5
Training loss: 1.4162428379058838
Validation loss: 1.877396878375802

Epoch: 5| Step: 6
Training loss: 1.597780704498291
Validation loss: 1.848442469873736

Epoch: 5| Step: 7
Training loss: 1.2041621208190918
Validation loss: 1.8568196142873457

Epoch: 5| Step: 8
Training loss: 0.9290317296981812
Validation loss: 1.8611270740468016

Epoch: 5| Step: 9
Training loss: 1.8075520992279053
Validation loss: 1.9118292408604776

Epoch: 5| Step: 10
Training loss: 1.497644305229187
Validation loss: 1.937844414864817

Epoch: 395| Step: 0
Training loss: 1.2006345987319946
Validation loss: 1.9016914944494925

Epoch: 5| Step: 1
Training loss: 1.3020169734954834
Validation loss: 1.9146860056026007

Epoch: 5| Step: 2
Training loss: 1.4090709686279297
Validation loss: 1.9173658765772337

Epoch: 5| Step: 3
Training loss: 1.5691577196121216
Validation loss: 1.9261669240972048

Epoch: 5| Step: 4
Training loss: 1.3772860765457153
Validation loss: 1.9452613028146888

Epoch: 5| Step: 5
Training loss: 1.8274002075195312
Validation loss: 1.882895718338669

Epoch: 5| Step: 6
Training loss: 1.2314916849136353
Validation loss: 1.9460949103037517

Epoch: 5| Step: 7
Training loss: 1.0315017700195312
Validation loss: 1.9218739617255427

Epoch: 5| Step: 8
Training loss: 1.2335604429244995
Validation loss: 1.8872963100351312

Epoch: 5| Step: 9
Training loss: 1.1917216777801514
Validation loss: 1.93213302089322

Epoch: 5| Step: 10
Training loss: 1.6550946235656738
Validation loss: 1.9085085238179853

Epoch: 396| Step: 0
Training loss: 1.2954020500183105
Validation loss: 1.926024483096215

Epoch: 5| Step: 1
Training loss: 1.2862900495529175
Validation loss: 1.9187691160427627

Epoch: 5| Step: 2
Training loss: 1.4977529048919678
Validation loss: 1.9145903523250292

Epoch: 5| Step: 3
Training loss: 1.1553943157196045
Validation loss: 1.9631673366792741

Epoch: 5| Step: 4
Training loss: 1.1550004482269287
Validation loss: 1.8828308582305908

Epoch: 5| Step: 5
Training loss: 1.4674373865127563
Validation loss: 1.9447303484844904

Epoch: 5| Step: 6
Training loss: 1.7045806646347046
Validation loss: 1.891616908452844

Epoch: 5| Step: 7
Training loss: 1.2067806720733643
Validation loss: 1.9696729106287802

Epoch: 5| Step: 8
Training loss: 1.178985595703125
Validation loss: 1.8991266578756354

Epoch: 5| Step: 9
Training loss: 1.4233750104904175
Validation loss: 1.8366653009127545

Epoch: 5| Step: 10
Training loss: 1.6557718515396118
Validation loss: 1.886553910470778

Epoch: 397| Step: 0
Training loss: 1.5693355798721313
Validation loss: 1.8477413551781767

Epoch: 5| Step: 1
Training loss: 1.0679388046264648
Validation loss: 1.882822271316282

Epoch: 5| Step: 2
Training loss: 2.091003894805908
Validation loss: 1.8733899965081164

Epoch: 5| Step: 3
Training loss: 1.5130829811096191
Validation loss: 1.9242587499721076

Epoch: 5| Step: 4
Training loss: 1.0082577466964722
Validation loss: 1.9295486865505096

Epoch: 5| Step: 5
Training loss: 1.5076669454574585
Validation loss: 1.9513275751503565

Epoch: 5| Step: 6
Training loss: 0.9432311058044434
Validation loss: 1.9440213275212113

Epoch: 5| Step: 7
Training loss: 1.1943352222442627
Validation loss: 1.9603106565372919

Epoch: 5| Step: 8
Training loss: 1.9002224206924438
Validation loss: 1.9275975637538458

Epoch: 5| Step: 9
Training loss: 0.8762106895446777
Validation loss: 1.8475311520279094

Epoch: 5| Step: 10
Training loss: 1.2816110849380493
Validation loss: 1.8598699338974491

Epoch: 398| Step: 0
Training loss: 1.700108289718628
Validation loss: 1.8860709872297061

Epoch: 5| Step: 1
Training loss: 1.722670316696167
Validation loss: 1.9633151408164733

Epoch: 5| Step: 2
Training loss: 1.2949445247650146
Validation loss: 1.9624564006764402

Epoch: 5| Step: 3
Training loss: 1.3439832925796509
Validation loss: 1.9315575245888001

Epoch: 5| Step: 4
Training loss: 1.4761803150177002
Validation loss: 1.929941318368399

Epoch: 5| Step: 5
Training loss: 1.6841964721679688
Validation loss: 1.9219765778510802

Epoch: 5| Step: 6
Training loss: 1.4011399745941162
Validation loss: 1.9296842031581427

Epoch: 5| Step: 7
Training loss: 0.9582942128181458
Validation loss: 1.9480215951960573

Epoch: 5| Step: 8
Training loss: 0.922014057636261
Validation loss: 1.860483830974948

Epoch: 5| Step: 9
Training loss: 1.448875069618225
Validation loss: 1.9117459097216207

Epoch: 5| Step: 10
Training loss: 1.352104902267456
Validation loss: 1.9104093569581226

Epoch: 399| Step: 0
Training loss: 1.013695478439331
Validation loss: 1.8826293855585077

Epoch: 5| Step: 1
Training loss: 1.4991716146469116
Validation loss: 1.8953222305543962

Epoch: 5| Step: 2
Training loss: 1.0353344678878784
Validation loss: 1.8915617555700324

Epoch: 5| Step: 3
Training loss: 1.4117133617401123
Validation loss: 1.8581522485261321

Epoch: 5| Step: 4
Training loss: 1.8657617568969727
Validation loss: 1.9103732634616155

Epoch: 5| Step: 5
Training loss: 1.336531400680542
Validation loss: 1.9101896619284024

Epoch: 5| Step: 6
Training loss: 1.8444054126739502
Validation loss: 1.8902759411001717

Epoch: 5| Step: 7
Training loss: 1.264430284500122
Validation loss: 1.9793327598161594

Epoch: 5| Step: 8
Training loss: 1.2868850231170654
Validation loss: 1.950621602355793

Epoch: 5| Step: 9
Training loss: 0.8066202998161316
Validation loss: 1.9375157022988925

Epoch: 5| Step: 10
Training loss: 1.4557981491088867
Validation loss: 1.919968097440658

Epoch: 400| Step: 0
Training loss: 0.6525717973709106
Validation loss: 1.926626915572792

Epoch: 5| Step: 1
Training loss: 1.068145751953125
Validation loss: 1.9062278065630185

Epoch: 5| Step: 2
Training loss: 1.7354673147201538
Validation loss: 1.9215497880853631

Epoch: 5| Step: 3
Training loss: 1.3445602655410767
Validation loss: 1.8834326882516184

Epoch: 5| Step: 4
Training loss: 1.8162444829940796
Validation loss: 1.9705377073698147

Epoch: 5| Step: 5
Training loss: 1.6635334491729736
Validation loss: 1.9081526366613244

Epoch: 5| Step: 6
Training loss: 1.425970196723938
Validation loss: 1.874610008731965

Epoch: 5| Step: 7
Training loss: 1.3500938415527344
Validation loss: 1.88526871127467

Epoch: 5| Step: 8
Training loss: 1.2454103231430054
Validation loss: 1.8997944349883704

Epoch: 5| Step: 9
Training loss: 1.5599770545959473
Validation loss: 1.8837074054184781

Epoch: 5| Step: 10
Training loss: 0.6239771246910095
Validation loss: 1.8915222780678862

Epoch: 401| Step: 0
Training loss: 1.770015001296997
Validation loss: 1.9049797352924143

Epoch: 5| Step: 1
Training loss: 1.1442652940750122
Validation loss: 1.8687170154304915

Epoch: 5| Step: 2
Training loss: 1.4331817626953125
Validation loss: 1.9793513539016887

Epoch: 5| Step: 3
Training loss: 1.1217132806777954
Validation loss: 1.8959476627329344

Epoch: 5| Step: 4
Training loss: 1.0121668577194214
Validation loss: 1.9447082114476029

Epoch: 5| Step: 5
Training loss: 1.1119463443756104
Validation loss: 1.912189382378773

Epoch: 5| Step: 6
Training loss: 1.3424522876739502
Validation loss: 1.8684001738025295

Epoch: 5| Step: 7
Training loss: 1.2930954694747925
Validation loss: 1.9351737794055734

Epoch: 5| Step: 8
Training loss: 1.1153345108032227
Validation loss: 1.927535726178077

Epoch: 5| Step: 9
Training loss: 1.5971415042877197
Validation loss: 1.9348501877118183

Epoch: 5| Step: 10
Training loss: 1.7402249574661255
Validation loss: 1.9253227415905203

Epoch: 402| Step: 0
Training loss: 1.1773507595062256
Validation loss: 1.912158038026543

Epoch: 5| Step: 1
Training loss: 1.411420226097107
Validation loss: 1.898965266443068

Epoch: 5| Step: 2
Training loss: 1.3287224769592285
Validation loss: 1.8749962417028283

Epoch: 5| Step: 3
Training loss: 1.7718822956085205
Validation loss: 1.8824372009564472

Epoch: 5| Step: 4
Training loss: 1.394680380821228
Validation loss: 1.9630676520768033

Epoch: 5| Step: 5
Training loss: 1.1884055137634277
Validation loss: 1.832623508668715

Epoch: 5| Step: 6
Training loss: 1.4691740274429321
Validation loss: 1.9189941581859384

Epoch: 5| Step: 7
Training loss: 1.1401116847991943
Validation loss: 1.919588896536058

Epoch: 5| Step: 8
Training loss: 1.402147889137268
Validation loss: 1.8934567423277004

Epoch: 5| Step: 9
Training loss: 0.7160179018974304
Validation loss: 1.877257582961872

Epoch: 5| Step: 10
Training loss: 1.388140320777893
Validation loss: 1.9883489608764648

Epoch: 403| Step: 0
Training loss: 1.2763663530349731
Validation loss: 1.8859451086290422

Epoch: 5| Step: 1
Training loss: 1.2121998071670532
Validation loss: 1.916268128220753

Epoch: 5| Step: 2
Training loss: 1.6911414861679077
Validation loss: 1.9246871215040966

Epoch: 5| Step: 3
Training loss: 1.5550127029418945
Validation loss: 1.9482944178324875

Epoch: 5| Step: 4
Training loss: 1.3977293968200684
Validation loss: 1.8880788792846024

Epoch: 5| Step: 5
Training loss: 1.1922824382781982
Validation loss: 1.902137976820751

Epoch: 5| Step: 6
Training loss: 1.2164599895477295
Validation loss: 1.9070044384207776

Epoch: 5| Step: 7
Training loss: 1.411839246749878
Validation loss: 1.8972232828858078

Epoch: 5| Step: 8
Training loss: 1.248557448387146
Validation loss: 1.8851366773728402

Epoch: 5| Step: 9
Training loss: 1.4126580953598022
Validation loss: 1.8884502508307015

Epoch: 5| Step: 10
Training loss: 1.0476100444793701
Validation loss: 1.8636112520771642

Epoch: 404| Step: 0
Training loss: 1.1336779594421387
Validation loss: 1.8516514480754893

Epoch: 5| Step: 1
Training loss: 1.6457386016845703
Validation loss: 1.9022865397955782

Epoch: 5| Step: 2
Training loss: 1.0647327899932861
Validation loss: 1.8539647979121054

Epoch: 5| Step: 3
Training loss: 1.3254117965698242
Validation loss: 1.8835261303891417

Epoch: 5| Step: 4
Training loss: 1.2373878955841064
Validation loss: 1.8657715807678878

Epoch: 5| Step: 5
Training loss: 1.2092851400375366
Validation loss: 1.933431181856381

Epoch: 5| Step: 6
Training loss: 1.3984832763671875
Validation loss: 1.8569677927160775

Epoch: 5| Step: 7
Training loss: 1.7855011224746704
Validation loss: 1.9299815790627592

Epoch: 5| Step: 8
Training loss: 1.3223659992218018
Validation loss: 1.9050564612111738

Epoch: 5| Step: 9
Training loss: 1.5247085094451904
Validation loss: 1.911951937983113

Epoch: 5| Step: 10
Training loss: 1.3091797828674316
Validation loss: 1.934315573784613

Epoch: 405| Step: 0
Training loss: 2.5962045192718506
Validation loss: 1.9051032399618497

Epoch: 5| Step: 1
Training loss: 1.2018706798553467
Validation loss: 1.9164797183006042

Epoch: 5| Step: 2
Training loss: 1.1324241161346436
Validation loss: 1.9364052049575313

Epoch: 5| Step: 3
Training loss: 1.5223816633224487
Validation loss: 1.8690145400262648

Epoch: 5| Step: 4
Training loss: 1.1234557628631592
Validation loss: 1.8633895304895216

Epoch: 5| Step: 5
Training loss: 1.7425498962402344
Validation loss: 1.9282947945338424

Epoch: 5| Step: 6
Training loss: 1.2310765981674194
Validation loss: 1.8752682939652474

Epoch: 5| Step: 7
Training loss: 0.9110181927680969
Validation loss: 1.8881430343915058

Epoch: 5| Step: 8
Training loss: 1.3594783544540405
Validation loss: 1.9030755437830442

Epoch: 5| Step: 9
Training loss: 0.8402091860771179
Validation loss: 1.9068565214833906

Epoch: 5| Step: 10
Training loss: 0.9581738710403442
Validation loss: 1.9256321243060532

Epoch: 406| Step: 0
Training loss: 1.2779124975204468
Validation loss: 1.87327572735407

Epoch: 5| Step: 1
Training loss: 1.7797095775604248
Validation loss: 1.876392565747743

Epoch: 5| Step: 2
Training loss: 1.0457181930541992
Validation loss: 1.8960304772982033

Epoch: 5| Step: 3
Training loss: 1.3771953582763672
Validation loss: 1.8934339515624508

Epoch: 5| Step: 4
Training loss: 0.8948528170585632
Validation loss: 1.8983651873885945

Epoch: 5| Step: 5
Training loss: 0.8492908477783203
Validation loss: 1.913651813742935

Epoch: 5| Step: 6
Training loss: 1.3104832172393799
Validation loss: 1.8926160040722098

Epoch: 5| Step: 7
Training loss: 1.3193806409835815
Validation loss: 1.9037935785067979

Epoch: 5| Step: 8
Training loss: 1.6511859893798828
Validation loss: 1.9027601775302683

Epoch: 5| Step: 9
Training loss: 1.7083072662353516
Validation loss: 1.959883874462497

Epoch: 5| Step: 10
Training loss: 1.509443998336792
Validation loss: 1.8918479411832747

Epoch: 407| Step: 0
Training loss: 1.4154874086380005
Validation loss: 1.896415546376218

Epoch: 5| Step: 1
Training loss: 1.1938985586166382
Validation loss: 1.8713769694810272

Epoch: 5| Step: 2
Training loss: 1.9280424118041992
Validation loss: 1.9005910786249305

Epoch: 5| Step: 3
Training loss: 1.3846995830535889
Validation loss: 1.9031127011904152

Epoch: 5| Step: 4
Training loss: 1.2885297536849976
Validation loss: 1.8684118396492415

Epoch: 5| Step: 5
Training loss: 1.5526113510131836
Validation loss: 1.9061842310813166

Epoch: 5| Step: 6
Training loss: 1.26283860206604
Validation loss: 1.9010818530154485

Epoch: 5| Step: 7
Training loss: 1.1116865873336792
Validation loss: 1.9201227080437444

Epoch: 5| Step: 8
Training loss: 1.1819579601287842
Validation loss: 1.8714698540267123

Epoch: 5| Step: 9
Training loss: 1.1569002866744995
Validation loss: 1.893595576286316

Epoch: 5| Step: 10
Training loss: 1.205222487449646
Validation loss: 1.822602415597567

Epoch: 408| Step: 0
Training loss: 1.0902562141418457
Validation loss: 1.8684425841095627

Epoch: 5| Step: 1
Training loss: 1.094732642173767
Validation loss: 1.8748909247818815

Epoch: 5| Step: 2
Training loss: 1.5712422132492065
Validation loss: 1.8732954789233465

Epoch: 5| Step: 3
Training loss: 1.505340576171875
Validation loss: 1.8689148528601534

Epoch: 5| Step: 4
Training loss: 1.013449788093567
Validation loss: 1.8767278553337179

Epoch: 5| Step: 5
Training loss: 1.0456053018569946
Validation loss: 1.910780313194439

Epoch: 5| Step: 6
Training loss: 1.9700599908828735
Validation loss: 1.9164499569964666

Epoch: 5| Step: 7
Training loss: 1.5406701564788818
Validation loss: 1.8897770976507535

Epoch: 5| Step: 8
Training loss: 1.5010793209075928
Validation loss: 1.924544353638926

Epoch: 5| Step: 9
Training loss: 1.4480329751968384
Validation loss: 1.8952191132371143

Epoch: 5| Step: 10
Training loss: 1.0314257144927979
Validation loss: 1.87926834629428

Epoch: 409| Step: 0
Training loss: 1.376421570777893
Validation loss: 1.9414635089135939

Epoch: 5| Step: 1
Training loss: 0.9895269274711609
Validation loss: 1.8719282611723869

Epoch: 5| Step: 2
Training loss: 1.2571537494659424
Validation loss: 1.8829488036453084

Epoch: 5| Step: 3
Training loss: 1.463854193687439
Validation loss: 1.8995531476953977

Epoch: 5| Step: 4
Training loss: 1.3657325506210327
Validation loss: 1.9139078663241478

Epoch: 5| Step: 5
Training loss: 1.4840871095657349
Validation loss: 1.8904484292512298

Epoch: 5| Step: 6
Training loss: 1.009669303894043
Validation loss: 1.867954259277672

Epoch: 5| Step: 7
Training loss: 1.686332106590271
Validation loss: 1.8409326755872337

Epoch: 5| Step: 8
Training loss: 1.6240513324737549
Validation loss: 1.8870874092143068

Epoch: 5| Step: 9
Training loss: 1.0768847465515137
Validation loss: 1.8686009145552112

Epoch: 5| Step: 10
Training loss: 1.1325511932373047
Validation loss: 1.8440970336237261

Epoch: 410| Step: 0
Training loss: 1.76934015750885
Validation loss: 1.9210145986208351

Epoch: 5| Step: 1
Training loss: 1.2152199745178223
Validation loss: 1.8792487652071062

Epoch: 5| Step: 2
Training loss: 1.666653037071228
Validation loss: 1.9029957132954751

Epoch: 5| Step: 3
Training loss: 1.2463741302490234
Validation loss: 1.8826790522503596

Epoch: 5| Step: 4
Training loss: 1.1053663492202759
Validation loss: 1.8672971751100274

Epoch: 5| Step: 5
Training loss: 1.3457783460617065
Validation loss: 1.8609172708244734

Epoch: 5| Step: 6
Training loss: 1.3685030937194824
Validation loss: 1.9163462667055027

Epoch: 5| Step: 7
Training loss: 1.1094677448272705
Validation loss: 1.886662385796988

Epoch: 5| Step: 8
Training loss: 1.1619514226913452
Validation loss: 1.9046071575533958

Epoch: 5| Step: 9
Training loss: 1.3135263919830322
Validation loss: 1.9151061478481497

Epoch: 5| Step: 10
Training loss: 0.9169498085975647
Validation loss: 1.9259605971715783

Epoch: 411| Step: 0
Training loss: 1.2258256673812866
Validation loss: 1.9259470803763277

Epoch: 5| Step: 1
Training loss: 1.4103419780731201
Validation loss: 1.9060173009031562

Epoch: 5| Step: 2
Training loss: 1.2720181941986084
Validation loss: 1.9534363259551346

Epoch: 5| Step: 3
Training loss: 1.2808668613433838
Validation loss: 1.9255972600752307

Epoch: 5| Step: 4
Training loss: 1.389296531677246
Validation loss: 2.0033433719347884

Epoch: 5| Step: 5
Training loss: 0.9127162098884583
Validation loss: 1.8980970049417147

Epoch: 5| Step: 6
Training loss: 2.021528720855713
Validation loss: 1.9352337160418112

Epoch: 5| Step: 7
Training loss: 1.4480104446411133
Validation loss: 1.9147618124561925

Epoch: 5| Step: 8
Training loss: 1.5376628637313843
Validation loss: 1.9281611314383886

Epoch: 5| Step: 9
Training loss: 1.118374228477478
Validation loss: 1.8795260075599916

Epoch: 5| Step: 10
Training loss: 1.1554465293884277
Validation loss: 1.90164517330867

Epoch: 412| Step: 0
Training loss: 1.0585145950317383
Validation loss: 1.9116790192101591

Epoch: 5| Step: 1
Training loss: 1.8065675497055054
Validation loss: 1.837511251049657

Epoch: 5| Step: 2
Training loss: 1.5092425346374512
Validation loss: 1.905407339014033

Epoch: 5| Step: 3
Training loss: 1.1817485094070435
Validation loss: 1.8912859014285508

Epoch: 5| Step: 4
Training loss: 0.9043759107589722
Validation loss: 1.9438897050837034

Epoch: 5| Step: 5
Training loss: 1.2109007835388184
Validation loss: 1.8798549611081359

Epoch: 5| Step: 6
Training loss: 1.2731062173843384
Validation loss: 1.8629642609627015

Epoch: 5| Step: 7
Training loss: 1.8026186227798462
Validation loss: 1.9181185742860198

Epoch: 5| Step: 8
Training loss: 1.0847632884979248
Validation loss: 1.9533367336437266

Epoch: 5| Step: 9
Training loss: 1.3447849750518799
Validation loss: 1.8600064195612425

Epoch: 5| Step: 10
Training loss: 1.084959864616394
Validation loss: 1.888021158915694

Epoch: 413| Step: 0
Training loss: 1.1378936767578125
Validation loss: 1.906070097800224

Epoch: 5| Step: 1
Training loss: 1.0023324489593506
Validation loss: 1.8840546351607128

Epoch: 5| Step: 2
Training loss: 1.4240235090255737
Validation loss: 1.91671916361778

Epoch: 5| Step: 3
Training loss: 1.1670011281967163
Validation loss: 1.8876609968882736

Epoch: 5| Step: 4
Training loss: 1.3447810411453247
Validation loss: 1.8936929895031838

Epoch: 5| Step: 5
Training loss: 1.5517407655715942
Validation loss: 1.8958849983830606

Epoch: 5| Step: 6
Training loss: 1.8892261981964111
Validation loss: 1.8536029554182483

Epoch: 5| Step: 7
Training loss: 1.348986029624939
Validation loss: 1.888349853536134

Epoch: 5| Step: 8
Training loss: 0.9596691131591797
Validation loss: 1.898107974759994

Epoch: 5| Step: 9
Training loss: 1.457531213760376
Validation loss: 1.8631767226803688

Epoch: 5| Step: 10
Training loss: 1.4146664142608643
Validation loss: 1.9339906887341571

Epoch: 414| Step: 0
Training loss: 1.7016140222549438
Validation loss: 1.9051406178423154

Epoch: 5| Step: 1
Training loss: 1.0054185390472412
Validation loss: 1.8857127287054574

Epoch: 5| Step: 2
Training loss: 1.2592649459838867
Validation loss: 1.8913613762906802

Epoch: 5| Step: 3
Training loss: 1.1362627744674683
Validation loss: 1.8643433816971318

Epoch: 5| Step: 4
Training loss: 1.2382194995880127
Validation loss: 1.961365210112705

Epoch: 5| Step: 5
Training loss: 1.5133589506149292
Validation loss: 1.8677984437634867

Epoch: 5| Step: 6
Training loss: 1.59805428981781
Validation loss: 1.8845917460738972

Epoch: 5| Step: 7
Training loss: 1.3996303081512451
Validation loss: 1.8712799754194034

Epoch: 5| Step: 8
Training loss: 0.9094988107681274
Validation loss: 1.8885815399949268

Epoch: 5| Step: 9
Training loss: 1.4039385318756104
Validation loss: 1.8820568464135612

Epoch: 5| Step: 10
Training loss: 1.4200118780136108
Validation loss: 1.8752082470924623

Epoch: 415| Step: 0
Training loss: 1.6486613750457764
Validation loss: 1.9050985279903616

Epoch: 5| Step: 1
Training loss: 1.0892521142959595
Validation loss: 1.8948514833245227

Epoch: 5| Step: 2
Training loss: 1.4122580289840698
Validation loss: 1.910788853963216

Epoch: 5| Step: 3
Training loss: 1.2069928646087646
Validation loss: 1.9006175892327422

Epoch: 5| Step: 4
Training loss: 1.4908233880996704
Validation loss: 1.8951912720998128

Epoch: 5| Step: 5
Training loss: 1.2665870189666748
Validation loss: 1.8652051892331851

Epoch: 5| Step: 6
Training loss: 1.3043967485427856
Validation loss: 1.9047028608219598

Epoch: 5| Step: 7
Training loss: 1.2586264610290527
Validation loss: 1.9271988080393883

Epoch: 5| Step: 8
Training loss: 1.5499460697174072
Validation loss: 1.8829704510268344

Epoch: 5| Step: 9
Training loss: 0.8656074404716492
Validation loss: 1.8419775860283965

Epoch: 5| Step: 10
Training loss: 1.5290085077285767
Validation loss: 1.8618776375247585

Epoch: 416| Step: 0
Training loss: 0.9296398162841797
Validation loss: 1.9493271304715065

Epoch: 5| Step: 1
Training loss: 1.557013750076294
Validation loss: 1.8929637734607985

Epoch: 5| Step: 2
Training loss: 1.0737709999084473
Validation loss: 1.9291395500142088

Epoch: 5| Step: 3
Training loss: 1.6394026279449463
Validation loss: 1.8681982806933823

Epoch: 5| Step: 4
Training loss: 1.077629804611206
Validation loss: 1.9078959829063826

Epoch: 5| Step: 5
Training loss: 1.6852861642837524
Validation loss: 1.8918081560442526

Epoch: 5| Step: 6
Training loss: 1.1577503681182861
Validation loss: 1.8643970130592264

Epoch: 5| Step: 7
Training loss: 1.1038501262664795
Validation loss: 1.8983550956172328

Epoch: 5| Step: 8
Training loss: 1.6048376560211182
Validation loss: 1.8812198767098047

Epoch: 5| Step: 9
Training loss: 1.4297527074813843
Validation loss: 1.8970700040940316

Epoch: 5| Step: 10
Training loss: 1.185283899307251
Validation loss: 1.879928522212531

Epoch: 417| Step: 0
Training loss: 1.6445850133895874
Validation loss: 1.8513251940409343

Epoch: 5| Step: 1
Training loss: 0.8996481895446777
Validation loss: 1.8975127294499388

Epoch: 5| Step: 2
Training loss: 1.7338001728057861
Validation loss: 1.90833628818553

Epoch: 5| Step: 3
Training loss: 1.4785875082015991
Validation loss: 1.8942793825621247

Epoch: 5| Step: 4
Training loss: 1.6833670139312744
Validation loss: 1.8973808262937812

Epoch: 5| Step: 5
Training loss: 0.893510639667511
Validation loss: 1.910419923003002

Epoch: 5| Step: 6
Training loss: 1.2707980871200562
Validation loss: 1.8605055065565212

Epoch: 5| Step: 7
Training loss: 1.3068629503250122
Validation loss: 1.9371188661103607

Epoch: 5| Step: 8
Training loss: 1.472960114479065
Validation loss: 1.8753642010432419

Epoch: 5| Step: 9
Training loss: 1.0545854568481445
Validation loss: 1.9371368077493483

Epoch: 5| Step: 10
Training loss: 0.9492932558059692
Validation loss: 1.8971818852168258

Epoch: 418| Step: 0
Training loss: 1.53447687625885
Validation loss: 1.9334730909716698

Epoch: 5| Step: 1
Training loss: 1.676904320716858
Validation loss: 1.8778393242948799

Epoch: 5| Step: 2
Training loss: 1.0494292974472046
Validation loss: 1.8567289562635525

Epoch: 5| Step: 3
Training loss: 1.5023272037506104
Validation loss: 1.8538717659570838

Epoch: 5| Step: 4
Training loss: 0.9700808525085449
Validation loss: 1.888574520746867

Epoch: 5| Step: 5
Training loss: 1.541196584701538
Validation loss: 1.8910373308325326

Epoch: 5| Step: 6
Training loss: 0.929780125617981
Validation loss: 1.8722956347209152

Epoch: 5| Step: 7
Training loss: 0.953480064868927
Validation loss: 1.8352346061378397

Epoch: 5| Step: 8
Training loss: 1.4589651823043823
Validation loss: 1.9170657819317234

Epoch: 5| Step: 9
Training loss: 1.1047322750091553
Validation loss: 1.9366765060732443

Epoch: 5| Step: 10
Training loss: 1.1749258041381836
Validation loss: 1.8946088719111618

Epoch: 419| Step: 0
Training loss: 1.1688944101333618
Validation loss: 1.9025355667196295

Epoch: 5| Step: 1
Training loss: 0.9112066030502319
Validation loss: 1.905510297385595

Epoch: 5| Step: 2
Training loss: 1.5996413230895996
Validation loss: 1.8771789522581204

Epoch: 5| Step: 3
Training loss: 1.4808647632598877
Validation loss: 1.9399168440090713

Epoch: 5| Step: 4
Training loss: 1.6222827434539795
Validation loss: 1.893378262878746

Epoch: 5| Step: 5
Training loss: 1.339009165763855
Validation loss: 1.9115691569543654

Epoch: 5| Step: 6
Training loss: 1.4426157474517822
Validation loss: 1.8950413452681674

Epoch: 5| Step: 7
Training loss: 1.539868950843811
Validation loss: 1.8904588555776944

Epoch: 5| Step: 8
Training loss: 1.214829921722412
Validation loss: 1.9520099701419953

Epoch: 5| Step: 9
Training loss: 0.9558708071708679
Validation loss: 1.9036799528265511

Epoch: 5| Step: 10
Training loss: 1.4867390394210815
Validation loss: 1.8926591668077695

Epoch: 420| Step: 0
Training loss: 1.4505962133407593
Validation loss: 1.8628966064863308

Epoch: 5| Step: 1
Training loss: 1.4081114530563354
Validation loss: 1.9356077627469135

Epoch: 5| Step: 2
Training loss: 1.6595230102539062
Validation loss: 1.871571530577957

Epoch: 5| Step: 3
Training loss: 1.5124725103378296
Validation loss: 1.8669609177497126

Epoch: 5| Step: 4
Training loss: 1.1804765462875366
Validation loss: 1.95728438643999

Epoch: 5| Step: 5
Training loss: 0.9957160949707031
Validation loss: 1.8817515039956698

Epoch: 5| Step: 6
Training loss: 1.5824869871139526
Validation loss: 1.9446963430732809

Epoch: 5| Step: 7
Training loss: 0.92564457654953
Validation loss: 1.877921139040301

Epoch: 5| Step: 8
Training loss: 0.9797008633613586
Validation loss: 1.8633800860374206

Epoch: 5| Step: 9
Training loss: 1.437598466873169
Validation loss: 1.865860164806407

Epoch: 5| Step: 10
Training loss: 1.3376717567443848
Validation loss: 1.9047335104275775

Epoch: 421| Step: 0
Training loss: 1.109293818473816
Validation loss: 1.8817996773668515

Epoch: 5| Step: 1
Training loss: 1.216154932975769
Validation loss: 1.8702711674474901

Epoch: 5| Step: 2
Training loss: 1.489475965499878
Validation loss: 1.9008855973520586

Epoch: 5| Step: 3
Training loss: 1.107387661933899
Validation loss: 1.8951274284752466

Epoch: 5| Step: 4
Training loss: 0.7600422501564026
Validation loss: 1.9141065792370868

Epoch: 5| Step: 5
Training loss: 1.4128135442733765
Validation loss: 1.876321986157407

Epoch: 5| Step: 6
Training loss: 1.9859282970428467
Validation loss: 1.8919388709529754

Epoch: 5| Step: 7
Training loss: 0.9518629312515259
Validation loss: 1.8578820856668616

Epoch: 5| Step: 8
Training loss: 1.333261251449585
Validation loss: 1.9062416553497314

Epoch: 5| Step: 9
Training loss: 1.4790904521942139
Validation loss: 1.88269761044492

Epoch: 5| Step: 10
Training loss: 1.536252498626709
Validation loss: 1.8878871369105514

Epoch: 422| Step: 0
Training loss: 1.3317270278930664
Validation loss: 1.8526344171134375

Epoch: 5| Step: 1
Training loss: 1.2519882917404175
Validation loss: 1.877497451279753

Epoch: 5| Step: 2
Training loss: 1.3263375759124756
Validation loss: 1.8999447079115017

Epoch: 5| Step: 3
Training loss: 0.8604198694229126
Validation loss: 1.8917374764719317

Epoch: 5| Step: 4
Training loss: 1.626259207725525
Validation loss: 1.8705026911151024

Epoch: 5| Step: 5
Training loss: 0.9075651168823242
Validation loss: 1.8617971494633665

Epoch: 5| Step: 6
Training loss: 1.3550344705581665
Validation loss: 1.9154340746582195

Epoch: 5| Step: 7
Training loss: 1.3731554746627808
Validation loss: 1.8672170357037616

Epoch: 5| Step: 8
Training loss: 1.6250213384628296
Validation loss: 1.8748221807582404

Epoch: 5| Step: 9
Training loss: 1.178325891494751
Validation loss: 1.8638282668205999

Epoch: 5| Step: 10
Training loss: 1.1150100231170654
Validation loss: 1.9190438127004972

Epoch: 423| Step: 0
Training loss: 1.6235729455947876
Validation loss: 1.9098945125456779

Epoch: 5| Step: 1
Training loss: 0.8446582555770874
Validation loss: 1.915179532061341

Epoch: 5| Step: 2
Training loss: 1.1672465801239014
Validation loss: 1.872766520387383

Epoch: 5| Step: 3
Training loss: 1.1086422204971313
Validation loss: 1.8980074903016448

Epoch: 5| Step: 4
Training loss: 1.2722197771072388
Validation loss: 1.8544436449645667

Epoch: 5| Step: 5
Training loss: 1.0243914127349854
Validation loss: 1.8580258828337475

Epoch: 5| Step: 6
Training loss: 1.6144126653671265
Validation loss: 1.880191986278821

Epoch: 5| Step: 7
Training loss: 1.3292287588119507
Validation loss: 1.8899766604105632

Epoch: 5| Step: 8
Training loss: 1.6134746074676514
Validation loss: 1.837196966653229

Epoch: 5| Step: 9
Training loss: 1.095445156097412
Validation loss: 1.8886377888341104

Epoch: 5| Step: 10
Training loss: 1.2309038639068604
Validation loss: 1.8598867526618383

Epoch: 424| Step: 0
Training loss: 1.448299527168274
Validation loss: 1.8861250159560994

Epoch: 5| Step: 1
Training loss: 1.5808916091918945
Validation loss: 1.881140068013181

Epoch: 5| Step: 2
Training loss: 1.2700155973434448
Validation loss: 1.8891351966447727

Epoch: 5| Step: 3
Training loss: 1.7124550342559814
Validation loss: 1.8972159406190277

Epoch: 5| Step: 4
Training loss: 1.560585379600525
Validation loss: 1.8782511193265197

Epoch: 5| Step: 5
Training loss: 1.1204544305801392
Validation loss: 1.8843105736599173

Epoch: 5| Step: 6
Training loss: 1.1437941789627075
Validation loss: 1.8834035883667648

Epoch: 5| Step: 7
Training loss: 1.2421801090240479
Validation loss: 1.8876482107306038

Epoch: 5| Step: 8
Training loss: 1.7203019857406616
Validation loss: 1.871428023102463

Epoch: 5| Step: 9
Training loss: 0.9530272483825684
Validation loss: 1.8461074688101327

Epoch: 5| Step: 10
Training loss: 0.7604396343231201
Validation loss: 1.9160979973372592

Epoch: 425| Step: 0
Training loss: 1.450797438621521
Validation loss: 1.8879367497659498

Epoch: 5| Step: 1
Training loss: 1.0632227659225464
Validation loss: 1.931625432865594

Epoch: 5| Step: 2
Training loss: 1.4250335693359375
Validation loss: 1.8782826328790316

Epoch: 5| Step: 3
Training loss: 1.528127908706665
Validation loss: 1.8778477984090005

Epoch: 5| Step: 4
Training loss: 1.3164732456207275
Validation loss: 1.8857718513857933

Epoch: 5| Step: 5
Training loss: 0.9615058898925781
Validation loss: 1.869224565003508

Epoch: 5| Step: 6
Training loss: 1.5676472187042236
Validation loss: 1.8886097118418703

Epoch: 5| Step: 7
Training loss: 1.0772805213928223
Validation loss: 1.8954524583713983

Epoch: 5| Step: 8
Training loss: 1.0332473516464233
Validation loss: 1.8854659013850714

Epoch: 5| Step: 9
Training loss: 1.1537944078445435
Validation loss: 1.9175352973322715

Epoch: 5| Step: 10
Training loss: 1.794995665550232
Validation loss: 1.896683814705059

Epoch: 426| Step: 0
Training loss: 0.9525076150894165
Validation loss: 1.9074024692658456

Epoch: 5| Step: 1
Training loss: 1.10879385471344
Validation loss: 1.9611976441516672

Epoch: 5| Step: 2
Training loss: 1.4493389129638672
Validation loss: 1.8352768613446144

Epoch: 5| Step: 3
Training loss: 1.5427892208099365
Validation loss: 1.9258588437111146

Epoch: 5| Step: 4
Training loss: 0.8352707624435425
Validation loss: 1.9175775153662569

Epoch: 5| Step: 5
Training loss: 1.3738460540771484
Validation loss: 1.9375068115931686

Epoch: 5| Step: 6
Training loss: 1.4398410320281982
Validation loss: 1.9359402605282363

Epoch: 5| Step: 7
Training loss: 1.1472127437591553
Validation loss: 1.868916985809162

Epoch: 5| Step: 8
Training loss: 1.744065284729004
Validation loss: 1.910931441091722

Epoch: 5| Step: 9
Training loss: 1.5728123188018799
Validation loss: 1.9635200346669843

Epoch: 5| Step: 10
Training loss: 0.7167112827301025
Validation loss: 1.855231761932373

Epoch: 427| Step: 0
Training loss: 0.971638560295105
Validation loss: 1.8743523756663005

Epoch: 5| Step: 1
Training loss: 1.3473057746887207
Validation loss: 1.8670850735838695

Epoch: 5| Step: 2
Training loss: 1.375419020652771
Validation loss: 1.9054149171357513

Epoch: 5| Step: 3
Training loss: 1.688515067100525
Validation loss: 1.8931682263651202

Epoch: 5| Step: 4
Training loss: 1.2209618091583252
Validation loss: 1.9303616285324097

Epoch: 5| Step: 5
Training loss: 0.7816468477249146
Validation loss: 1.8117031845995175

Epoch: 5| Step: 6
Training loss: 1.2045894861221313
Validation loss: 1.9337075730805755

Epoch: 5| Step: 7
Training loss: 0.7404710054397583
Validation loss: 1.9787813412245883

Epoch: 5| Step: 8
Training loss: 1.3272299766540527
Validation loss: 1.845947725798494

Epoch: 5| Step: 9
Training loss: 1.7918331623077393
Validation loss: 1.8831444248076408

Epoch: 5| Step: 10
Training loss: 1.6174722909927368
Validation loss: 1.8712167252776444

Epoch: 428| Step: 0
Training loss: 0.8334161639213562
Validation loss: 1.9326297685664187

Epoch: 5| Step: 1
Training loss: 1.5329644680023193
Validation loss: 1.8512920679584626

Epoch: 5| Step: 2
Training loss: 1.7528024911880493
Validation loss: 1.8957828193582513

Epoch: 5| Step: 3
Training loss: 0.9905532002449036
Validation loss: 1.9202845583679855

Epoch: 5| Step: 4
Training loss: 1.2152882814407349
Validation loss: 1.9407840005813106

Epoch: 5| Step: 5
Training loss: 1.0939559936523438
Validation loss: 1.9256040229592273

Epoch: 5| Step: 6
Training loss: 1.1590988636016846
Validation loss: 1.8806889749342395

Epoch: 5| Step: 7
Training loss: 1.1265203952789307
Validation loss: 1.8960689780532674

Epoch: 5| Step: 8
Training loss: 1.3988587856292725
Validation loss: 1.8830789084075599

Epoch: 5| Step: 9
Training loss: 1.3968291282653809
Validation loss: 1.8966562773591729

Epoch: 5| Step: 10
Training loss: 1.7687921524047852
Validation loss: 1.8896884328575545

Epoch: 429| Step: 0
Training loss: 0.9293230772018433
Validation loss: 1.8662759296355709

Epoch: 5| Step: 1
Training loss: 1.0817492008209229
Validation loss: 1.8508466392435052

Epoch: 5| Step: 2
Training loss: 1.2781925201416016
Validation loss: 1.8282555969812537

Epoch: 5| Step: 3
Training loss: 1.3145967721939087
Validation loss: 1.8350718957121654

Epoch: 5| Step: 4
Training loss: 1.082411527633667
Validation loss: 1.9171978453154206

Epoch: 5| Step: 5
Training loss: 1.7316181659698486
Validation loss: 1.8937476309396888

Epoch: 5| Step: 6
Training loss: 1.4153966903686523
Validation loss: 1.8994139894362418

Epoch: 5| Step: 7
Training loss: 1.1419368982315063
Validation loss: 1.8341323880739109

Epoch: 5| Step: 8
Training loss: 1.2411469221115112
Validation loss: 1.901551709380201

Epoch: 5| Step: 9
Training loss: 1.1523091793060303
Validation loss: 1.8758010582257343

Epoch: 5| Step: 10
Training loss: 1.4949902296066284
Validation loss: 1.8697076394993772

Epoch: 430| Step: 0
Training loss: 1.3491339683532715
Validation loss: 1.8918144831093409

Epoch: 5| Step: 1
Training loss: 0.8915098309516907
Validation loss: 1.8463002943223523

Epoch: 5| Step: 2
Training loss: 1.7842895984649658
Validation loss: 1.869904468136449

Epoch: 5| Step: 3
Training loss: 1.385210633277893
Validation loss: 1.8915104199481267

Epoch: 5| Step: 4
Training loss: 0.7670992016792297
Validation loss: 1.902055601919851

Epoch: 5| Step: 5
Training loss: 1.3887403011322021
Validation loss: 1.889301020611999

Epoch: 5| Step: 6
Training loss: 1.284180998802185
Validation loss: 1.8506096793759255

Epoch: 5| Step: 7
Training loss: 1.2429096698760986
Validation loss: 1.8907976432513165

Epoch: 5| Step: 8
Training loss: 1.6631591320037842
Validation loss: 1.90018456597482

Epoch: 5| Step: 9
Training loss: 1.4253182411193848
Validation loss: 1.8241836486324188

Epoch: 5| Step: 10
Training loss: 1.015744924545288
Validation loss: 1.8573875042699999

Epoch: 431| Step: 0
Training loss: 1.2847459316253662
Validation loss: 1.9022040597854122

Epoch: 5| Step: 1
Training loss: 1.6311334371566772
Validation loss: 1.8995775638088104

Epoch: 5| Step: 2
Training loss: 1.625140905380249
Validation loss: 1.882186210283669

Epoch: 5| Step: 3
Training loss: 1.1594535112380981
Validation loss: 1.9134231344346078

Epoch: 5| Step: 4
Training loss: 0.8812838792800903
Validation loss: 1.900018871471446

Epoch: 5| Step: 5
Training loss: 1.0694773197174072
Validation loss: 1.8803611852789437

Epoch: 5| Step: 6
Training loss: 1.2602179050445557
Validation loss: 1.9232264744338168

Epoch: 5| Step: 7
Training loss: 1.2398922443389893
Validation loss: 1.8458637076039468

Epoch: 5| Step: 8
Training loss: 1.2570548057556152
Validation loss: 1.8961135623275593

Epoch: 5| Step: 9
Training loss: 1.6086772680282593
Validation loss: 1.9617465593481576

Epoch: 5| Step: 10
Training loss: 0.7717077732086182
Validation loss: 1.9262841683562084

Epoch: 432| Step: 0
Training loss: 1.3607065677642822
Validation loss: 1.8835536382531608

Epoch: 5| Step: 1
Training loss: 0.7171902656555176
Validation loss: 1.8930647860291183

Epoch: 5| Step: 2
Training loss: 1.7365020513534546
Validation loss: 1.9069538026727655

Epoch: 5| Step: 3
Training loss: 1.1041972637176514
Validation loss: 1.9008721805387927

Epoch: 5| Step: 4
Training loss: 0.7534366846084595
Validation loss: 1.903175446294969

Epoch: 5| Step: 5
Training loss: 1.0269321203231812
Validation loss: 1.8579033741386988

Epoch: 5| Step: 6
Training loss: 1.4975836277008057
Validation loss: 1.8884938378487863

Epoch: 5| Step: 7
Training loss: 1.4831962585449219
Validation loss: 1.8478286843146048

Epoch: 5| Step: 8
Training loss: 1.2114070653915405
Validation loss: 1.858224735465101

Epoch: 5| Step: 9
Training loss: 1.4744594097137451
Validation loss: 1.8403183849908973

Epoch: 5| Step: 10
Training loss: 1.6541494131088257
Validation loss: 1.8829840293494604

Epoch: 433| Step: 0
Training loss: 1.1798079013824463
Validation loss: 1.8569022865705593

Epoch: 5| Step: 1
Training loss: 1.069739580154419
Validation loss: 1.8366103659393966

Epoch: 5| Step: 2
Training loss: 1.1324141025543213
Validation loss: 1.8977161504889046

Epoch: 5| Step: 3
Training loss: 1.0810763835906982
Validation loss: 1.8016775628571868

Epoch: 5| Step: 4
Training loss: 1.4998677968978882
Validation loss: 1.819493688562865

Epoch: 5| Step: 5
Training loss: 1.383490800857544
Validation loss: 1.9009759618389992

Epoch: 5| Step: 6
Training loss: 1.1234636306762695
Validation loss: 1.921974858930034

Epoch: 5| Step: 7
Training loss: 1.413007140159607
Validation loss: 1.9044624067121936

Epoch: 5| Step: 8
Training loss: 1.2737598419189453
Validation loss: 1.8984426324085524

Epoch: 5| Step: 9
Training loss: 1.3170816898345947
Validation loss: 1.8576521271018571

Epoch: 5| Step: 10
Training loss: 1.9055984020233154
Validation loss: 1.901882371594829

Epoch: 434| Step: 0
Training loss: 1.4011415243148804
Validation loss: 1.8778345533596572

Epoch: 5| Step: 1
Training loss: 1.6630465984344482
Validation loss: 1.9090308861065937

Epoch: 5| Step: 2
Training loss: 1.3244147300720215
Validation loss: 1.9120649419805056

Epoch: 5| Step: 3
Training loss: 1.0731494426727295
Validation loss: 1.9287017532574233

Epoch: 5| Step: 4
Training loss: 1.5983043909072876
Validation loss: 1.924265435946885

Epoch: 5| Step: 5
Training loss: 1.1105592250823975
Validation loss: 1.9239284851217782

Epoch: 5| Step: 6
Training loss: 1.6946628093719482
Validation loss: 1.8514921331918368

Epoch: 5| Step: 7
Training loss: 1.1123664379119873
Validation loss: 1.8710221757170975

Epoch: 5| Step: 8
Training loss: 0.931967556476593
Validation loss: 1.8741417713062738

Epoch: 5| Step: 9
Training loss: 1.1551421880722046
Validation loss: 1.9122934187612226

Epoch: 5| Step: 10
Training loss: 1.006782054901123
Validation loss: 1.8159097086998723

Epoch: 435| Step: 0
Training loss: 0.9585739374160767
Validation loss: 1.8383920987447102

Epoch: 5| Step: 1
Training loss: 1.2856601476669312
Validation loss: 1.8612567763174734

Epoch: 5| Step: 2
Training loss: 1.3362998962402344
Validation loss: 1.9296238422393799

Epoch: 5| Step: 3
Training loss: 0.8893728256225586
Validation loss: 1.8747179174935946

Epoch: 5| Step: 4
Training loss: 1.6298997402191162
Validation loss: 1.864694623536961

Epoch: 5| Step: 5
Training loss: 1.0512733459472656
Validation loss: 1.8998856121493923

Epoch: 5| Step: 6
Training loss: 1.3936761617660522
Validation loss: 1.8771875122542023

Epoch: 5| Step: 7
Training loss: 1.2718403339385986
Validation loss: 1.8563841337798743

Epoch: 5| Step: 8
Training loss: 1.3457436561584473
Validation loss: 1.8791696499752741

Epoch: 5| Step: 9
Training loss: 1.3105839490890503
Validation loss: 1.8802914798900645

Epoch: 5| Step: 10
Training loss: 1.0529944896697998
Validation loss: 1.887477308191279

Epoch: 436| Step: 0
Training loss: 1.2669377326965332
Validation loss: 1.9158028992273475

Epoch: 5| Step: 1
Training loss: 1.10347580909729
Validation loss: 1.9193334169285272

Epoch: 5| Step: 2
Training loss: 1.3979071378707886
Validation loss: 1.8864253567111107

Epoch: 5| Step: 3
Training loss: 1.5442081689834595
Validation loss: 1.927829816777219

Epoch: 5| Step: 4
Training loss: 1.7391544580459595
Validation loss: 1.8456080613597747

Epoch: 5| Step: 5
Training loss: 1.0457942485809326
Validation loss: 1.90788217641974

Epoch: 5| Step: 6
Training loss: 1.077977180480957
Validation loss: 1.919571900880465

Epoch: 5| Step: 7
Training loss: 1.1129318475723267
Validation loss: 1.893257451313798

Epoch: 5| Step: 8
Training loss: 1.1780608892440796
Validation loss: 1.8662622923492103

Epoch: 5| Step: 9
Training loss: 1.483392357826233
Validation loss: 1.8842367497823571

Epoch: 5| Step: 10
Training loss: 0.8814687132835388
Validation loss: 1.8799708325375792

Epoch: 437| Step: 0
Training loss: 1.324022889137268
Validation loss: 1.848396243587617

Epoch: 5| Step: 1
Training loss: 1.673731803894043
Validation loss: 1.8853568607761013

Epoch: 5| Step: 2
Training loss: 1.074623703956604
Validation loss: 1.8986460214020104

Epoch: 5| Step: 3
Training loss: 0.9801194071769714
Validation loss: 1.9095726756639377

Epoch: 5| Step: 4
Training loss: 1.3158295154571533
Validation loss: 1.848501984791089

Epoch: 5| Step: 5
Training loss: 0.7370255589485168
Validation loss: 1.8510481196065103

Epoch: 5| Step: 6
Training loss: 1.12361478805542
Validation loss: 1.8437645563515284

Epoch: 5| Step: 7
Training loss: 1.1383004188537598
Validation loss: 1.952701800612993

Epoch: 5| Step: 8
Training loss: 1.749328374862671
Validation loss: 1.8886926430527882

Epoch: 5| Step: 9
Training loss: 1.4193298816680908
Validation loss: 1.9037540317863546

Epoch: 5| Step: 10
Training loss: 1.5290125608444214
Validation loss: 1.8408530835182435

Epoch: 438| Step: 0
Training loss: 1.4325472116470337
Validation loss: 1.903428348161841

Epoch: 5| Step: 1
Training loss: 0.8695230484008789
Validation loss: 1.8869352725244337

Epoch: 5| Step: 2
Training loss: 1.2458484172821045
Validation loss: 1.9252576443456835

Epoch: 5| Step: 3
Training loss: 0.7148033380508423
Validation loss: 1.8343626042847991

Epoch: 5| Step: 4
Training loss: 1.2489696741104126
Validation loss: 1.8191008965174358

Epoch: 5| Step: 5
Training loss: 0.9891554713249207
Validation loss: 1.8481853444089171

Epoch: 5| Step: 6
Training loss: 1.5075279474258423
Validation loss: 1.8579029024288218

Epoch: 5| Step: 7
Training loss: 1.4238674640655518
Validation loss: 1.9021747471183859

Epoch: 5| Step: 8
Training loss: 1.6801904439926147
Validation loss: 1.9055405752633208

Epoch: 5| Step: 9
Training loss: 1.6432863473892212
Validation loss: 1.9048855253445205

Epoch: 5| Step: 10
Training loss: 1.0298802852630615
Validation loss: 1.8648551599953764

Epoch: 439| Step: 0
Training loss: 1.0402454137802124
Validation loss: 1.887731776442579

Epoch: 5| Step: 1
Training loss: 1.92168390750885
Validation loss: 1.8764135747827508

Epoch: 5| Step: 2
Training loss: 0.9453259706497192
Validation loss: 1.9125271074233516

Epoch: 5| Step: 3
Training loss: 1.2995634078979492
Validation loss: 1.9353120352632256

Epoch: 5| Step: 4
Training loss: 1.185672402381897
Validation loss: 1.8762797309506325

Epoch: 5| Step: 5
Training loss: 0.8766921758651733
Validation loss: 1.883435571065513

Epoch: 5| Step: 6
Training loss: 1.9421831369400024
Validation loss: 1.8666618177967687

Epoch: 5| Step: 7
Training loss: 1.8491275310516357
Validation loss: 1.8868186063663934

Epoch: 5| Step: 8
Training loss: 0.8909137845039368
Validation loss: 1.8910054775976366

Epoch: 5| Step: 9
Training loss: 0.9860488772392273
Validation loss: 1.9026890826481644

Epoch: 5| Step: 10
Training loss: 0.755857527256012
Validation loss: 1.8512158496405489

Epoch: 440| Step: 0
Training loss: 1.7336238622665405
Validation loss: 1.8883864648880497

Epoch: 5| Step: 1
Training loss: 1.1703424453735352
Validation loss: 1.9429316277145057

Epoch: 5| Step: 2
Training loss: 0.8608438372612
Validation loss: 1.9117588407249861

Epoch: 5| Step: 3
Training loss: 1.3075344562530518
Validation loss: 1.9266805571894492

Epoch: 5| Step: 4
Training loss: 1.1755284070968628
Validation loss: 1.8920599850275184

Epoch: 5| Step: 5
Training loss: 1.0025482177734375
Validation loss: 1.8838273850820397

Epoch: 5| Step: 6
Training loss: 0.9722763895988464
Validation loss: 1.924334954189998

Epoch: 5| Step: 7
Training loss: 1.0999733209609985
Validation loss: 1.9092367643951087

Epoch: 5| Step: 8
Training loss: 1.6048396825790405
Validation loss: 1.9152441870781682

Epoch: 5| Step: 9
Training loss: 1.3251848220825195
Validation loss: 1.8883442314722205

Epoch: 5| Step: 10
Training loss: 1.0992043018341064
Validation loss: 1.918201813133814

Epoch: 441| Step: 0
Training loss: 0.8332840204238892
Validation loss: 1.9104855457941692

Epoch: 5| Step: 1
Training loss: 1.4346483945846558
Validation loss: 1.8850302850046465

Epoch: 5| Step: 2
Training loss: 1.6446495056152344
Validation loss: 1.9482808882190334

Epoch: 5| Step: 3
Training loss: 1.179681420326233
Validation loss: 1.9590004618449877

Epoch: 5| Step: 4
Training loss: 1.7841027975082397
Validation loss: 1.8729733395320114

Epoch: 5| Step: 5
Training loss: 0.8967863321304321
Validation loss: 1.8913409966294483

Epoch: 5| Step: 6
Training loss: 1.3429874181747437
Validation loss: 1.8917082573777886

Epoch: 5| Step: 7
Training loss: 1.4495782852172852
Validation loss: 1.9139834321955198

Epoch: 5| Step: 8
Training loss: 0.8537797927856445
Validation loss: 1.873667824652887

Epoch: 5| Step: 9
Training loss: 1.5610026121139526
Validation loss: 1.8789480206786946

Epoch: 5| Step: 10
Training loss: 0.7849778532981873
Validation loss: 1.8825424883955268

Epoch: 442| Step: 0
Training loss: 1.133467435836792
Validation loss: 1.8857933359761392

Epoch: 5| Step: 1
Training loss: 0.9088362455368042
Validation loss: 1.867424677777034

Epoch: 5| Step: 2
Training loss: 1.1601423025131226
Validation loss: 1.9012166043763519

Epoch: 5| Step: 3
Training loss: 0.8069195747375488
Validation loss: 1.855183204015096

Epoch: 5| Step: 4
Training loss: 1.3040043115615845
Validation loss: 1.8850631611321562

Epoch: 5| Step: 5
Training loss: 0.9312847256660461
Validation loss: 1.9127231887591782

Epoch: 5| Step: 6
Training loss: 1.0052213668823242
Validation loss: 1.917100937135758

Epoch: 5| Step: 7
Training loss: 1.7650845050811768
Validation loss: 1.8773515737184914

Epoch: 5| Step: 8
Training loss: 1.2229864597320557
Validation loss: 1.912899189097907

Epoch: 5| Step: 9
Training loss: 2.050243854522705
Validation loss: 1.8345132335539787

Epoch: 5| Step: 10
Training loss: 1.567852258682251
Validation loss: 1.8438566218140304

Epoch: 443| Step: 0
Training loss: 1.0456392765045166
Validation loss: 1.8339509912716445

Epoch: 5| Step: 1
Training loss: 1.7886251211166382
Validation loss: 1.9019673203909269

Epoch: 5| Step: 2
Training loss: 1.6500765085220337
Validation loss: 1.947448230558826

Epoch: 5| Step: 3
Training loss: 1.2554277181625366
Validation loss: 1.8407078904490317

Epoch: 5| Step: 4
Training loss: 0.8942244648933411
Validation loss: 1.9352867987848097

Epoch: 5| Step: 5
Training loss: 1.2570099830627441
Validation loss: 1.8881408860606532

Epoch: 5| Step: 6
Training loss: 0.7567842602729797
Validation loss: 1.915112139076315

Epoch: 5| Step: 7
Training loss: 1.3020718097686768
Validation loss: 1.9403228887947657

Epoch: 5| Step: 8
Training loss: 0.756125807762146
Validation loss: 1.9076734537719398

Epoch: 5| Step: 9
Training loss: 1.3307827711105347
Validation loss: 1.8596548149662633

Epoch: 5| Step: 10
Training loss: 1.664048671722412
Validation loss: 1.8936870354478077

Epoch: 444| Step: 0
Training loss: 1.1037625074386597
Validation loss: 1.8297360815027708

Epoch: 5| Step: 1
Training loss: 1.9129536151885986
Validation loss: 1.83674757711349

Epoch: 5| Step: 2
Training loss: 1.6866140365600586
Validation loss: 1.8955360522834204

Epoch: 5| Step: 3
Training loss: 1.2347452640533447
Validation loss: 1.8386463362683532

Epoch: 5| Step: 4
Training loss: 0.611129879951477
Validation loss: 1.8947156757436774

Epoch: 5| Step: 5
Training loss: 0.8958762884140015
Validation loss: 1.882486826630049

Epoch: 5| Step: 6
Training loss: 0.7946593761444092
Validation loss: 1.928180976580548

Epoch: 5| Step: 7
Training loss: 1.1221789121627808
Validation loss: 1.9072318166814826

Epoch: 5| Step: 8
Training loss: 0.9971631765365601
Validation loss: 1.8661130089913645

Epoch: 5| Step: 9
Training loss: 1.8532718420028687
Validation loss: 1.8667659938976329

Epoch: 5| Step: 10
Training loss: 1.5252434015274048
Validation loss: 1.9340397068249282

Epoch: 445| Step: 0
Training loss: 1.2665355205535889
Validation loss: 1.8354329139955583

Epoch: 5| Step: 1
Training loss: 0.981706440448761
Validation loss: 1.83668319384257

Epoch: 5| Step: 2
Training loss: 1.1640424728393555
Validation loss: 1.9119178928354734

Epoch: 5| Step: 3
Training loss: 1.2648646831512451
Validation loss: 1.8867294531996532

Epoch: 5| Step: 4
Training loss: 0.9844843745231628
Validation loss: 1.8716462427569973

Epoch: 5| Step: 5
Training loss: 1.7206166982650757
Validation loss: 1.881124218304952

Epoch: 5| Step: 6
Training loss: 1.2537930011749268
Validation loss: 1.9622558342513217

Epoch: 5| Step: 7
Training loss: 1.4481045007705688
Validation loss: 1.8671662794646395

Epoch: 5| Step: 8
Training loss: 1.7581729888916016
Validation loss: 1.9165026449388074

Epoch: 5| Step: 9
Training loss: 1.0035399198532104
Validation loss: 1.9051160786741523

Epoch: 5| Step: 10
Training loss: 0.6349474191665649
Validation loss: 1.865619351786952

Epoch: 446| Step: 0
Training loss: 1.1980119943618774
Validation loss: 1.8701758461613809

Epoch: 5| Step: 1
Training loss: 1.5021950006484985
Validation loss: 1.8796330946747974

Epoch: 5| Step: 2
Training loss: 1.404902696609497
Validation loss: 1.8717037734164987

Epoch: 5| Step: 3
Training loss: 0.8002740740776062
Validation loss: 1.89317185648026

Epoch: 5| Step: 4
Training loss: 1.4926750659942627
Validation loss: 1.8920557242567821

Epoch: 5| Step: 5
Training loss: 1.5293426513671875
Validation loss: 1.8674231729199808

Epoch: 5| Step: 6
Training loss: 1.1107233762741089
Validation loss: 1.9237262279756608

Epoch: 5| Step: 7
Training loss: 1.3522236347198486
Validation loss: 1.9443410032538957

Epoch: 5| Step: 8
Training loss: 1.390214443206787
Validation loss: 1.847078969401698

Epoch: 5| Step: 9
Training loss: 0.9161642789840698
Validation loss: 1.8632230733030586

Epoch: 5| Step: 10
Training loss: 0.9603926539421082
Validation loss: 1.8938599735177972

Epoch: 447| Step: 0
Training loss: 1.2469351291656494
Validation loss: 1.8411949898606987

Epoch: 5| Step: 1
Training loss: 1.2420278787612915
Validation loss: 1.9313156489403016

Epoch: 5| Step: 2
Training loss: 0.9794691801071167
Validation loss: 1.8358083309665802

Epoch: 5| Step: 3
Training loss: 0.7158086895942688
Validation loss: 1.8975426202179284

Epoch: 5| Step: 4
Training loss: 1.3285163640975952
Validation loss: 1.847941566539067

Epoch: 5| Step: 5
Training loss: 1.1122024059295654
Validation loss: 1.853594223658244

Epoch: 5| Step: 6
Training loss: 1.9081385135650635
Validation loss: 1.8920346966353796

Epoch: 5| Step: 7
Training loss: 1.5232700109481812
Validation loss: 1.9646842889888312

Epoch: 5| Step: 8
Training loss: 1.109250783920288
Validation loss: 1.8644611194569578

Epoch: 5| Step: 9
Training loss: 1.1665189266204834
Validation loss: 1.8385204307494625

Epoch: 5| Step: 10
Training loss: 1.215470314025879
Validation loss: 1.868565837542216

Epoch: 448| Step: 0
Training loss: 1.1212049722671509
Validation loss: 1.8616561761466406

Epoch: 5| Step: 1
Training loss: 1.0828492641448975
Validation loss: 1.8791981589409612

Epoch: 5| Step: 2
Training loss: 1.093731164932251
Validation loss: 1.9032723826746787

Epoch: 5| Step: 3
Training loss: 1.0485289096832275
Validation loss: 1.850541473716818

Epoch: 5| Step: 4
Training loss: 0.9154424667358398
Validation loss: 1.8668476561064362

Epoch: 5| Step: 5
Training loss: 1.2753018140792847
Validation loss: 1.8475616747333157

Epoch: 5| Step: 6
Training loss: 1.0940872430801392
Validation loss: 1.8524954524091495

Epoch: 5| Step: 7
Training loss: 1.5361247062683105
Validation loss: 1.9001705813151535

Epoch: 5| Step: 8
Training loss: 1.144248127937317
Validation loss: 1.8190297465170584

Epoch: 5| Step: 9
Training loss: 1.7903449535369873
Validation loss: 1.858604379879531

Epoch: 5| Step: 10
Training loss: 1.3735636472702026
Validation loss: 1.867409190823955

Epoch: 449| Step: 0
Training loss: 1.0372283458709717
Validation loss: 1.8851218441481232

Epoch: 5| Step: 1
Training loss: 0.9617821574211121
Validation loss: 1.8718362482645179

Epoch: 5| Step: 2
Training loss: 1.8028564453125
Validation loss: 1.8475929614036315

Epoch: 5| Step: 3
Training loss: 1.013113021850586
Validation loss: 1.8724937900420158

Epoch: 5| Step: 4
Training loss: 1.3530733585357666
Validation loss: 1.872869481322586

Epoch: 5| Step: 5
Training loss: 1.0104891061782837
Validation loss: 1.901809492418843

Epoch: 5| Step: 6
Training loss: 0.9902068972587585
Validation loss: 1.8379036482944284

Epoch: 5| Step: 7
Training loss: 1.1426500082015991
Validation loss: 1.8587237429875199

Epoch: 5| Step: 8
Training loss: 1.2052193880081177
Validation loss: 1.8620026393603253

Epoch: 5| Step: 9
Training loss: 1.2159770727157593
Validation loss: 1.8519200150684645

Epoch: 5| Step: 10
Training loss: 2.0065388679504395
Validation loss: 1.870801600076819

Epoch: 450| Step: 0
Training loss: 1.6823539733886719
Validation loss: 1.8669393684274407

Epoch: 5| Step: 1
Training loss: 1.2051670551300049
Validation loss: 1.8307330710913545

Epoch: 5| Step: 2
Training loss: 1.0182626247406006
Validation loss: 1.9171160241608978

Epoch: 5| Step: 3
Training loss: 0.9270663261413574
Validation loss: 1.86190866526737

Epoch: 5| Step: 4
Training loss: 1.409988284111023
Validation loss: 1.874188732075435

Epoch: 5| Step: 5
Training loss: 1.2749272584915161
Validation loss: 1.8478277960131246

Epoch: 5| Step: 6
Training loss: 1.1286624670028687
Validation loss: 1.8536705432399627

Epoch: 5| Step: 7
Training loss: 1.1073973178863525
Validation loss: 1.8645023210074312

Epoch: 5| Step: 8
Training loss: 0.8752210736274719
Validation loss: 1.912149626721618

Epoch: 5| Step: 9
Training loss: 1.683527946472168
Validation loss: 1.87601839598789

Epoch: 5| Step: 10
Training loss: 0.9019700884819031
Validation loss: 1.930746119509461

Epoch: 451| Step: 0
Training loss: 1.225113868713379
Validation loss: 1.8818260136471

Epoch: 5| Step: 1
Training loss: 1.5497033596038818
Validation loss: 1.8575416264995452

Epoch: 5| Step: 2
Training loss: 1.6536531448364258
Validation loss: 1.7788797706686041

Epoch: 5| Step: 3
Training loss: 0.8399089574813843
Validation loss: 1.9091239180616153

Epoch: 5| Step: 4
Training loss: 1.581538438796997
Validation loss: 1.8783575488675026

Epoch: 5| Step: 5
Training loss: 1.3642021417617798
Validation loss: 1.8771783792844383

Epoch: 5| Step: 6
Training loss: 1.2282027006149292
Validation loss: 1.8387827027228572

Epoch: 5| Step: 7
Training loss: 0.8370704650878906
Validation loss: 1.8575121151503695

Epoch: 5| Step: 8
Training loss: 0.8722779154777527
Validation loss: 1.849012913242463

Epoch: 5| Step: 9
Training loss: 0.9786432385444641
Validation loss: 1.856441556766469

Epoch: 5| Step: 10
Training loss: 1.2686355113983154
Validation loss: 1.882915186625655

Epoch: 452| Step: 0
Training loss: 1.4772703647613525
Validation loss: 1.8694407273364324

Epoch: 5| Step: 1
Training loss: 0.8799844980239868
Validation loss: 1.9011253592788533

Epoch: 5| Step: 2
Training loss: 0.9019757509231567
Validation loss: 1.8396614136234406

Epoch: 5| Step: 3
Training loss: 0.7262173891067505
Validation loss: 1.8815471549187937

Epoch: 5| Step: 4
Training loss: 1.3479896783828735
Validation loss: 1.8241999008322274

Epoch: 5| Step: 5
Training loss: 1.205733299255371
Validation loss: 1.893234920758073

Epoch: 5| Step: 6
Training loss: 1.1653493642807007
Validation loss: 1.9216031515470116

Epoch: 5| Step: 7
Training loss: 1.6379016637802124
Validation loss: 1.8608963950987785

Epoch: 5| Step: 8
Training loss: 1.4225988388061523
Validation loss: 1.872364091616805

Epoch: 5| Step: 9
Training loss: 1.3750274181365967
Validation loss: 1.805823508129325

Epoch: 5| Step: 10
Training loss: 0.957809329032898
Validation loss: 1.839978817970522

Epoch: 453| Step: 0
Training loss: 1.339605689048767
Validation loss: 1.8874588627969064

Epoch: 5| Step: 1
Training loss: 0.8810513615608215
Validation loss: 1.8767372280038812

Epoch: 5| Step: 2
Training loss: 1.2387187480926514
Validation loss: 1.858990348795409

Epoch: 5| Step: 3
Training loss: 1.2266645431518555
Validation loss: 1.8835470420058056

Epoch: 5| Step: 4
Training loss: 1.3816745281219482
Validation loss: 1.8886283969366422

Epoch: 5| Step: 5
Training loss: 1.2527399063110352
Validation loss: 1.8436676545809674

Epoch: 5| Step: 6
Training loss: 1.094414234161377
Validation loss: 1.8140014551019157

Epoch: 5| Step: 7
Training loss: 1.1101030111312866
Validation loss: 1.8838464047319146

Epoch: 5| Step: 8
Training loss: 1.8101844787597656
Validation loss: 1.9053876105175223

Epoch: 5| Step: 9
Training loss: 1.181970238685608
Validation loss: 1.8659629411594842

Epoch: 5| Step: 10
Training loss: 1.0092456340789795
Validation loss: 1.8262081376967891

Epoch: 454| Step: 0
Training loss: 1.3798552751541138
Validation loss: 1.8904594554696033

Epoch: 5| Step: 1
Training loss: 0.6528737545013428
Validation loss: 1.8725595422970351

Epoch: 5| Step: 2
Training loss: 1.5342892408370972
Validation loss: 1.8722690510493454

Epoch: 5| Step: 3
Training loss: 1.474679946899414
Validation loss: 1.8474882264291086

Epoch: 5| Step: 4
Training loss: 0.9902547597885132
Validation loss: 1.857292837994073

Epoch: 5| Step: 5
Training loss: 1.7738300561904907
Validation loss: 1.883224368095398

Epoch: 5| Step: 6
Training loss: 1.0662434101104736
Validation loss: 1.9347115306444065

Epoch: 5| Step: 7
Training loss: 1.325791597366333
Validation loss: 1.871626102796165

Epoch: 5| Step: 8
Training loss: 0.7984744310379028
Validation loss: 1.868382925628334

Epoch: 5| Step: 9
Training loss: 0.9586361646652222
Validation loss: 1.914814615762362

Epoch: 5| Step: 10
Training loss: 1.564584732055664
Validation loss: 1.8967062811697684

Epoch: 455| Step: 0
Training loss: 1.5234030485153198
Validation loss: 1.8515043053575742

Epoch: 5| Step: 1
Training loss: 1.3317224979400635
Validation loss: 1.8678113722032117

Epoch: 5| Step: 2
Training loss: 1.2503671646118164
Validation loss: 1.8453549133834017

Epoch: 5| Step: 3
Training loss: 0.8267587423324585
Validation loss: 1.8996053882824477

Epoch: 5| Step: 4
Training loss: 1.0797253847122192
Validation loss: 1.8723348558589976

Epoch: 5| Step: 5
Training loss: 1.2819803953170776
Validation loss: 1.8927252728451964

Epoch: 5| Step: 6
Training loss: 1.6034252643585205
Validation loss: 1.8438962992801462

Epoch: 5| Step: 7
Training loss: 0.9267750978469849
Validation loss: 1.8457525071277414

Epoch: 5| Step: 8
Training loss: 1.294176697731018
Validation loss: 1.9200501659865021

Epoch: 5| Step: 9
Training loss: 0.947771430015564
Validation loss: 1.8311233520507812

Epoch: 5| Step: 10
Training loss: 1.4608266353607178
Validation loss: 1.9334221193867345

Epoch: 456| Step: 0
Training loss: 1.1826958656311035
Validation loss: 1.922670861726166

Epoch: 5| Step: 1
Training loss: 1.3022289276123047
Validation loss: 1.8901943493914861

Epoch: 5| Step: 2
Training loss: 1.3500268459320068
Validation loss: 1.8694472466745684

Epoch: 5| Step: 3
Training loss: 1.3866932392120361
Validation loss: 1.9778069603827693

Epoch: 5| Step: 4
Training loss: 1.6605621576309204
Validation loss: 1.8061618061475857

Epoch: 5| Step: 5
Training loss: 1.076479434967041
Validation loss: 1.8580296885582708

Epoch: 5| Step: 6
Training loss: 1.4374797344207764
Validation loss: 1.9167883216693837

Epoch: 5| Step: 7
Training loss: 1.2574082612991333
Validation loss: 1.911175497116581

Epoch: 5| Step: 8
Training loss: 0.815719723701477
Validation loss: 1.8895045659875358

Epoch: 5| Step: 9
Training loss: 0.656510055065155
Validation loss: 1.8747400801668885

Epoch: 5| Step: 10
Training loss: 1.6771332025527954
Validation loss: 1.8904778803548505

Epoch: 457| Step: 0
Training loss: 1.0507571697235107
Validation loss: 1.839802365149221

Epoch: 5| Step: 1
Training loss: 1.1992920637130737
Validation loss: 1.8530381571862005

Epoch: 5| Step: 2
Training loss: 1.4399943351745605
Validation loss: 1.8975346498591925

Epoch: 5| Step: 3
Training loss: 0.8634073138237
Validation loss: 1.8523805833631946

Epoch: 5| Step: 4
Training loss: 1.132676124572754
Validation loss: 1.884056701455065

Epoch: 5| Step: 5
Training loss: 1.7408288717269897
Validation loss: 1.8535631164427726

Epoch: 5| Step: 6
Training loss: 0.9782134890556335
Validation loss: 1.912509904112867

Epoch: 5| Step: 7
Training loss: 1.324209451675415
Validation loss: 1.9551727964032082

Epoch: 5| Step: 8
Training loss: 1.3019908666610718
Validation loss: 1.8484747627730012

Epoch: 5| Step: 9
Training loss: 1.3733415603637695
Validation loss: 1.842290497595264

Epoch: 5| Step: 10
Training loss: 1.0749244689941406
Validation loss: 1.822266855547505

Epoch: 458| Step: 0
Training loss: 0.8385082483291626
Validation loss: 1.8799505855447503

Epoch: 5| Step: 1
Training loss: 1.0223557949066162
Validation loss: 1.847118446903844

Epoch: 5| Step: 2
Training loss: 1.2241573333740234
Validation loss: 1.8264421827049666

Epoch: 5| Step: 3
Training loss: 1.412011742591858
Validation loss: 1.8653245292684084

Epoch: 5| Step: 4
Training loss: 1.1259362697601318
Validation loss: 1.8652991351260935

Epoch: 5| Step: 5
Training loss: 1.1691491603851318
Validation loss: 1.8708390330755582

Epoch: 5| Step: 6
Training loss: 1.4717246294021606
Validation loss: 1.9019432003780077

Epoch: 5| Step: 7
Training loss: 1.4253346920013428
Validation loss: 1.867243618093511

Epoch: 5| Step: 8
Training loss: 1.3507943153381348
Validation loss: 1.863517463848155

Epoch: 5| Step: 9
Training loss: 1.1192076206207275
Validation loss: 1.900097490638815

Epoch: 5| Step: 10
Training loss: 1.2013533115386963
Validation loss: 1.800128383021201

Epoch: 459| Step: 0
Training loss: 1.7903106212615967
Validation loss: 1.9120776666108

Epoch: 5| Step: 1
Training loss: 1.849076509475708
Validation loss: 1.867048494277462

Epoch: 5| Step: 2
Training loss: 0.6604874730110168
Validation loss: 1.800466319566132

Epoch: 5| Step: 3
Training loss: 1.0097805261611938
Validation loss: 1.8740207354227703

Epoch: 5| Step: 4
Training loss: 1.2922395467758179
Validation loss: 1.9006000731581

Epoch: 5| Step: 5
Training loss: 0.8686891794204712
Validation loss: 1.904430697041173

Epoch: 5| Step: 6
Training loss: 1.6865791082382202
Validation loss: 1.8364536493055281

Epoch: 5| Step: 7
Training loss: 1.1387739181518555
Validation loss: 1.9150440231446297

Epoch: 5| Step: 8
Training loss: 1.3926671743392944
Validation loss: 1.8544177034849763

Epoch: 5| Step: 9
Training loss: 0.8927826881408691
Validation loss: 1.8748223268857567

Epoch: 5| Step: 10
Training loss: 1.2147544622421265
Validation loss: 1.8434798268861667

Epoch: 460| Step: 0
Training loss: 1.6667038202285767
Validation loss: 1.8773022287635392

Epoch: 5| Step: 1
Training loss: 1.2892537117004395
Validation loss: 1.8453307408158497

Epoch: 5| Step: 2
Training loss: 0.9505602121353149
Validation loss: 1.8472726755244757

Epoch: 5| Step: 3
Training loss: 1.060827374458313
Validation loss: 1.8824722715603408

Epoch: 5| Step: 4
Training loss: 0.9901878237724304
Validation loss: 1.869325118680154

Epoch: 5| Step: 5
Training loss: 1.202844500541687
Validation loss: 1.887686300021346

Epoch: 5| Step: 6
Training loss: 1.7222906351089478
Validation loss: 1.9364372812291628

Epoch: 5| Step: 7
Training loss: 1.1183788776397705
Validation loss: 1.8892052763251848

Epoch: 5| Step: 8
Training loss: 1.2460113763809204
Validation loss: 1.9077830545363887

Epoch: 5| Step: 9
Training loss: 0.9053150415420532
Validation loss: 1.9262026535567416

Epoch: 5| Step: 10
Training loss: 1.2564178705215454
Validation loss: 1.8572304261628019

Epoch: 461| Step: 0
Training loss: 1.595461368560791
Validation loss: 1.8720498777204944

Epoch: 5| Step: 1
Training loss: 1.5524091720581055
Validation loss: 1.9044500858552995

Epoch: 5| Step: 2
Training loss: 2.144077777862549
Validation loss: 1.8519898127484065

Epoch: 5| Step: 3
Training loss: 0.971710205078125
Validation loss: 1.8795450143916632

Epoch: 5| Step: 4
Training loss: 1.795602798461914
Validation loss: 1.8458823042531167

Epoch: 5| Step: 5
Training loss: 0.9914119839668274
Validation loss: 1.8432490005288074

Epoch: 5| Step: 6
Training loss: 1.3022581338882446
Validation loss: 1.909644740884022

Epoch: 5| Step: 7
Training loss: 0.7397621870040894
Validation loss: 1.8929556723563903

Epoch: 5| Step: 8
Training loss: 1.0463069677352905
Validation loss: 1.871206896279448

Epoch: 5| Step: 9
Training loss: 0.8339122533798218
Validation loss: 1.8849636149662796

Epoch: 5| Step: 10
Training loss: 0.6411786079406738
Validation loss: 1.9000404829620032

Epoch: 462| Step: 0
Training loss: 1.063659906387329
Validation loss: 1.8970589176301034

Epoch: 5| Step: 1
Training loss: 1.1364977359771729
Validation loss: 1.8903737452722364

Epoch: 5| Step: 2
Training loss: 1.4147288799285889
Validation loss: 1.8581793513349307

Epoch: 5| Step: 3
Training loss: 1.0817854404449463
Validation loss: 1.8648102104022939

Epoch: 5| Step: 4
Training loss: 1.7605400085449219
Validation loss: 1.9276810358929377

Epoch: 5| Step: 5
Training loss: 1.0602657794952393
Validation loss: 1.9111465689956502

Epoch: 5| Step: 6
Training loss: 0.839830756187439
Validation loss: 1.8630733002898514

Epoch: 5| Step: 7
Training loss: 1.5304651260375977
Validation loss: 1.8441416922435965

Epoch: 5| Step: 8
Training loss: 1.2723162174224854
Validation loss: 1.8624330489866194

Epoch: 5| Step: 9
Training loss: 1.3883116245269775
Validation loss: 1.8475014663511706

Epoch: 5| Step: 10
Training loss: 0.9501457214355469
Validation loss: 1.877962677709518

Epoch: 463| Step: 0
Training loss: 1.3534821271896362
Validation loss: 1.8863842846244894

Epoch: 5| Step: 1
Training loss: 1.1587789058685303
Validation loss: 1.869853267105677

Epoch: 5| Step: 2
Training loss: 1.2074711322784424
Validation loss: 1.9019706505601124

Epoch: 5| Step: 3
Training loss: 0.917779266834259
Validation loss: 1.8493998473690403

Epoch: 5| Step: 4
Training loss: 0.9421044588088989
Validation loss: 1.8637100676054597

Epoch: 5| Step: 5
Training loss: 1.4827333688735962
Validation loss: 1.8951288628321823

Epoch: 5| Step: 6
Training loss: 1.355146884918213
Validation loss: 1.880281243273007

Epoch: 5| Step: 7
Training loss: 1.6737775802612305
Validation loss: 1.8355363312587942

Epoch: 5| Step: 8
Training loss: 1.5139414072036743
Validation loss: 1.8545351887261996

Epoch: 5| Step: 9
Training loss: 0.9288851618766785
Validation loss: 1.8432092192352458

Epoch: 5| Step: 10
Training loss: 0.8688215613365173
Validation loss: 1.8628333678809545

Epoch: 464| Step: 0
Training loss: 1.257223129272461
Validation loss: 1.8530549554414646

Epoch: 5| Step: 1
Training loss: 1.275822401046753
Validation loss: 1.8650689740334787

Epoch: 5| Step: 2
Training loss: 1.5054508447647095
Validation loss: 1.8717277883201517

Epoch: 5| Step: 3
Training loss: 1.5518001317977905
Validation loss: 1.8870201803022815

Epoch: 5| Step: 4
Training loss: 0.7047768831253052
Validation loss: 1.8368392375207716

Epoch: 5| Step: 5
Training loss: 0.5994265675544739
Validation loss: 1.8969576768977667

Epoch: 5| Step: 6
Training loss: 1.5556416511535645
Validation loss: 1.8747438948641542

Epoch: 5| Step: 7
Training loss: 1.5231682062149048
Validation loss: 1.9230253273440945

Epoch: 5| Step: 8
Training loss: 1.3276069164276123
Validation loss: 1.909004936936081

Epoch: 5| Step: 9
Training loss: 1.1220271587371826
Validation loss: 1.8732495359195176

Epoch: 5| Step: 10
Training loss: 0.8164371252059937
Validation loss: 1.8829703741176154

Epoch: 465| Step: 0
Training loss: 1.1639206409454346
Validation loss: 1.9115604572398688

Epoch: 5| Step: 1
Training loss: 1.2760270833969116
Validation loss: 1.8801833711644655

Epoch: 5| Step: 2
Training loss: 1.351518154144287
Validation loss: 1.893536797133825

Epoch: 5| Step: 3
Training loss: 1.0757585763931274
Validation loss: 1.8253302061429588

Epoch: 5| Step: 4
Training loss: 1.0876544713974
Validation loss: 1.8857316073550974

Epoch: 5| Step: 5
Training loss: 1.6221859455108643
Validation loss: 1.8231403366211922

Epoch: 5| Step: 6
Training loss: 0.6730157136917114
Validation loss: 1.900160906135395

Epoch: 5| Step: 7
Training loss: 1.9950199127197266
Validation loss: 1.8739040449101438

Epoch: 5| Step: 8
Training loss: 1.132340431213379
Validation loss: 1.8911424580440725

Epoch: 5| Step: 9
Training loss: 0.7023857831954956
Validation loss: 1.8668740090503488

Epoch: 5| Step: 10
Training loss: 1.1676051616668701
Validation loss: 1.829876535682268

Epoch: 466| Step: 0
Training loss: 0.904059112071991
Validation loss: 1.8271459225685365

Epoch: 5| Step: 1
Training loss: 1.0302691459655762
Validation loss: 1.8741845238593318

Epoch: 5| Step: 2
Training loss: 1.501963496208191
Validation loss: 1.8711059888203938

Epoch: 5| Step: 3
Training loss: 1.7826669216156006
Validation loss: 1.8174356311880133

Epoch: 5| Step: 4
Training loss: 1.088300347328186
Validation loss: 1.8824670891607962

Epoch: 5| Step: 5
Training loss: 0.8977389335632324
Validation loss: 1.9142162184561453

Epoch: 5| Step: 6
Training loss: 0.879002571105957
Validation loss: 1.8636117417325255

Epoch: 5| Step: 7
Training loss: 1.047853708267212
Validation loss: 1.860628366470337

Epoch: 5| Step: 8
Training loss: 1.6117935180664062
Validation loss: 1.9046230649435392

Epoch: 5| Step: 9
Training loss: 1.2286667823791504
Validation loss: 1.8820590793445546

Epoch: 5| Step: 10
Training loss: 1.0848883390426636
Validation loss: 1.8844117400466756

Epoch: 467| Step: 0
Training loss: 1.2675210237503052
Validation loss: 1.8783119199096516

Epoch: 5| Step: 1
Training loss: 1.2408878803253174
Validation loss: 1.90357881463984

Epoch: 5| Step: 2
Training loss: 1.6540672779083252
Validation loss: 1.8845545681574012

Epoch: 5| Step: 3
Training loss: 1.004932165145874
Validation loss: 1.9076101792755948

Epoch: 5| Step: 4
Training loss: 1.0161164999008179
Validation loss: 1.796360287615048

Epoch: 5| Step: 5
Training loss: 1.4465961456298828
Validation loss: 1.9342882594754618

Epoch: 5| Step: 6
Training loss: 1.2061307430267334
Validation loss: 1.8922549780978952

Epoch: 5| Step: 7
Training loss: 1.3604261875152588
Validation loss: 1.8557755485657723

Epoch: 5| Step: 8
Training loss: 1.2520201206207275
Validation loss: 1.8785181430078322

Epoch: 5| Step: 9
Training loss: 0.8969573974609375
Validation loss: 1.8513839116660498

Epoch: 5| Step: 10
Training loss: 1.1070010662078857
Validation loss: 1.8841139501140964

Epoch: 468| Step: 0
Training loss: 0.9139520525932312
Validation loss: 1.8845803353094286

Epoch: 5| Step: 1
Training loss: 1.094472050666809
Validation loss: 1.9016995314628846

Epoch: 5| Step: 2
Training loss: 0.9078073501586914
Validation loss: 1.8597567158360635

Epoch: 5| Step: 3
Training loss: 1.4234342575073242
Validation loss: 1.869566373927619

Epoch: 5| Step: 4
Training loss: 1.2983558177947998
Validation loss: 1.848484916071738

Epoch: 5| Step: 5
Training loss: 1.2065377235412598
Validation loss: 1.8543560043458016

Epoch: 5| Step: 6
Training loss: 1.3186591863632202
Validation loss: 1.8739045076472785

Epoch: 5| Step: 7
Training loss: 1.3940709829330444
Validation loss: 1.8575401947062502

Epoch: 5| Step: 8
Training loss: 1.1316559314727783
Validation loss: 1.924303147100633

Epoch: 5| Step: 9
Training loss: 1.0879993438720703
Validation loss: 1.8338525872076712

Epoch: 5| Step: 10
Training loss: 1.1792958974838257
Validation loss: 1.858693725319319

Epoch: 469| Step: 0
Training loss: 1.0099084377288818
Validation loss: 1.879190480837258

Epoch: 5| Step: 1
Training loss: 1.3078888654708862
Validation loss: 1.8860163188749743

Epoch: 5| Step: 2
Training loss: 1.061625361442566
Validation loss: 1.8171060059660225

Epoch: 5| Step: 3
Training loss: 1.26878821849823
Validation loss: 1.9237374733853083

Epoch: 5| Step: 4
Training loss: 1.239978551864624
Validation loss: 1.8727871551308581

Epoch: 5| Step: 5
Training loss: 1.257338285446167
Validation loss: 1.858867415817835

Epoch: 5| Step: 6
Training loss: 0.9921404123306274
Validation loss: 1.931129382502648

Epoch: 5| Step: 7
Training loss: 1.2781627178192139
Validation loss: 1.857820906946736

Epoch: 5| Step: 8
Training loss: 1.5556058883666992
Validation loss: 1.8972941290947698

Epoch: 5| Step: 9
Training loss: 0.9896942377090454
Validation loss: 1.8604037787324639

Epoch: 5| Step: 10
Training loss: 1.0086699724197388
Validation loss: 1.8948608944492955

Epoch: 470| Step: 0
Training loss: 0.9356080293655396
Validation loss: 1.8502422455818421

Epoch: 5| Step: 1
Training loss: 1.4304511547088623
Validation loss: 1.8775364147719515

Epoch: 5| Step: 2
Training loss: 1.3349220752716064
Validation loss: 1.8634941539456766

Epoch: 5| Step: 3
Training loss: 1.3549023866653442
Validation loss: 1.8459954107961347

Epoch: 5| Step: 4
Training loss: 1.3631408214569092
Validation loss: 1.9103450813601095

Epoch: 5| Step: 5
Training loss: 1.3122916221618652
Validation loss: 1.8840769747252106

Epoch: 5| Step: 6
Training loss: 1.375303864479065
Validation loss: 1.8258876326263591

Epoch: 5| Step: 7
Training loss: 1.0497068166732788
Validation loss: 1.8640802021949523

Epoch: 5| Step: 8
Training loss: 1.3612072467803955
Validation loss: 1.8511489681018296

Epoch: 5| Step: 9
Training loss: 1.1537129878997803
Validation loss: 1.8952849859832435

Epoch: 5| Step: 10
Training loss: 0.8905684351921082
Validation loss: 1.8540233271096342

Epoch: 471| Step: 0
Training loss: 1.0491864681243896
Validation loss: 1.879446316790837

Epoch: 5| Step: 1
Training loss: 1.059079885482788
Validation loss: 1.8476370611498434

Epoch: 5| Step: 2
Training loss: 1.7572429180145264
Validation loss: 1.8542865681391891

Epoch: 5| Step: 3
Training loss: 0.9684274792671204
Validation loss: 1.880319813246368

Epoch: 5| Step: 4
Training loss: 1.6940017938613892
Validation loss: 1.8160600290503552

Epoch: 5| Step: 5
Training loss: 1.2795403003692627
Validation loss: 1.854790977252427

Epoch: 5| Step: 6
Training loss: 1.0911725759506226
Validation loss: 1.86535249217864

Epoch: 5| Step: 7
Training loss: 0.797791600227356
Validation loss: 1.8018497433713687

Epoch: 5| Step: 8
Training loss: 0.7017855048179626
Validation loss: 1.8559877731466805

Epoch: 5| Step: 9
Training loss: 1.038375735282898
Validation loss: 1.8076739247127245

Epoch: 5| Step: 10
Training loss: 1.4666104316711426
Validation loss: 1.898619305702948

Epoch: 472| Step: 0
Training loss: 1.466303825378418
Validation loss: 1.816156594983993

Epoch: 5| Step: 1
Training loss: 1.4840130805969238
Validation loss: 1.8491915836129138

Epoch: 5| Step: 2
Training loss: 0.9275237321853638
Validation loss: 1.822743099222901

Epoch: 5| Step: 3
Training loss: 0.9010080099105835
Validation loss: 1.840739421947028

Epoch: 5| Step: 4
Training loss: 0.6414980292320251
Validation loss: 1.8079676282021306

Epoch: 5| Step: 5
Training loss: 1.1410185098648071
Validation loss: 1.8922184923643708

Epoch: 5| Step: 6
Training loss: 1.7234423160552979
Validation loss: 1.8629721351849136

Epoch: 5| Step: 7
Training loss: 1.6929731369018555
Validation loss: 1.9229996153103408

Epoch: 5| Step: 8
Training loss: 0.9252588152885437
Validation loss: 1.8480465066048406

Epoch: 5| Step: 9
Training loss: 1.0071008205413818
Validation loss: 1.8722439273711173

Epoch: 5| Step: 10
Training loss: 1.114452600479126
Validation loss: 1.8827608528957571

Epoch: 473| Step: 0
Training loss: 1.2180707454681396
Validation loss: 1.8716671953919113

Epoch: 5| Step: 1
Training loss: 1.648221731185913
Validation loss: 1.84790022911564

Epoch: 5| Step: 2
Training loss: 1.1375064849853516
Validation loss: 1.8311544310662053

Epoch: 5| Step: 3
Training loss: 1.2002201080322266
Validation loss: 1.9163957770152757

Epoch: 5| Step: 4
Training loss: 1.34636390209198
Validation loss: 1.8477761309633973

Epoch: 5| Step: 5
Training loss: 1.2499711513519287
Validation loss: 1.8922397551998016

Epoch: 5| Step: 6
Training loss: 1.5959206819534302
Validation loss: 1.8798605177992134

Epoch: 5| Step: 7
Training loss: 1.441352128982544
Validation loss: 1.8913243406562394

Epoch: 5| Step: 8
Training loss: 1.2081472873687744
Validation loss: 1.8921637868368497

Epoch: 5| Step: 9
Training loss: 0.5700761079788208
Validation loss: 1.836792783070636

Epoch: 5| Step: 10
Training loss: 0.7705423831939697
Validation loss: 1.8878818891381706

Epoch: 474| Step: 0
Training loss: 0.6079522967338562
Validation loss: 1.8415661934883363

Epoch: 5| Step: 1
Training loss: 1.6979548931121826
Validation loss: 1.8666960090719245

Epoch: 5| Step: 2
Training loss: 1.402341604232788
Validation loss: 1.8961566519993607

Epoch: 5| Step: 3
Training loss: 0.8993908166885376
Validation loss: 1.9019310935851066

Epoch: 5| Step: 4
Training loss: 1.0979888439178467
Validation loss: 1.8330314543939406

Epoch: 5| Step: 5
Training loss: 1.3093817234039307
Validation loss: 1.8513632743589339

Epoch: 5| Step: 6
Training loss: 1.0438282489776611
Validation loss: 1.8931291180272256

Epoch: 5| Step: 7
Training loss: 1.0074079036712646
Validation loss: 1.8567048836779851

Epoch: 5| Step: 8
Training loss: 1.113447904586792
Validation loss: 1.8110579111242806

Epoch: 5| Step: 9
Training loss: 1.3930647373199463
Validation loss: 1.87295768209683

Epoch: 5| Step: 10
Training loss: 1.4603595733642578
Validation loss: 1.8563915888468425

Epoch: 475| Step: 0
Training loss: 1.2676059007644653
Validation loss: 1.8528980747345956

Epoch: 5| Step: 1
Training loss: 0.9991148114204407
Validation loss: 1.8729909645613803

Epoch: 5| Step: 2
Training loss: 1.225006103515625
Validation loss: 1.8583392609832108

Epoch: 5| Step: 3
Training loss: 1.389562964439392
Validation loss: 1.9035385475363782

Epoch: 5| Step: 4
Training loss: 1.0698182582855225
Validation loss: 1.8596271238019388

Epoch: 5| Step: 5
Training loss: 1.1692571640014648
Validation loss: 1.8639265491116432

Epoch: 5| Step: 6
Training loss: 1.2564480304718018
Validation loss: 1.8421308917383994

Epoch: 5| Step: 7
Training loss: 0.9051002264022827
Validation loss: 1.8384019713247977

Epoch: 5| Step: 8
Training loss: 1.2010570764541626
Validation loss: 1.8661463696469542

Epoch: 5| Step: 9
Training loss: 1.26443612575531
Validation loss: 1.9002026319503784

Epoch: 5| Step: 10
Training loss: 1.1997588872909546
Validation loss: 1.853186624024504

Epoch: 476| Step: 0
Training loss: 1.2566773891448975
Validation loss: 1.9232042861241165

Epoch: 5| Step: 1
Training loss: 1.1787853240966797
Validation loss: 1.859505364971776

Epoch: 5| Step: 2
Training loss: 1.6175609827041626
Validation loss: 1.8344705566283195

Epoch: 5| Step: 3
Training loss: 0.9987798929214478
Validation loss: 1.9110723157082834

Epoch: 5| Step: 4
Training loss: 1.0684219598770142
Validation loss: 1.8958050076679518

Epoch: 5| Step: 5
Training loss: 1.0143464803695679
Validation loss: 1.8355800246679654

Epoch: 5| Step: 6
Training loss: 1.3179553747177124
Validation loss: 1.8491013883262553

Epoch: 5| Step: 7
Training loss: 1.047568917274475
Validation loss: 1.814933387182092

Epoch: 5| Step: 8
Training loss: 1.201320767402649
Validation loss: 1.8822044967323222

Epoch: 5| Step: 9
Training loss: 1.3783271312713623
Validation loss: 1.8530900747545305

Epoch: 5| Step: 10
Training loss: 1.221714973449707
Validation loss: 1.8371294749680387

Epoch: 477| Step: 0
Training loss: 0.9312294721603394
Validation loss: 1.8283319755267071

Epoch: 5| Step: 1
Training loss: 1.3814690113067627
Validation loss: 1.8540258253774335

Epoch: 5| Step: 2
Training loss: 1.1143062114715576
Validation loss: 1.8893136144966207

Epoch: 5| Step: 3
Training loss: 1.261681318283081
Validation loss: 1.8782932553240048

Epoch: 5| Step: 4
Training loss: 1.0535523891448975
Validation loss: 1.8642635422368203

Epoch: 5| Step: 5
Training loss: 1.2752881050109863
Validation loss: 1.8812409088175783

Epoch: 5| Step: 6
Training loss: 1.0525939464569092
Validation loss: 1.8988043787658855

Epoch: 5| Step: 7
Training loss: 1.27708899974823
Validation loss: 1.8221308082662604

Epoch: 5| Step: 8
Training loss: 1.173196792602539
Validation loss: 1.8211930785127866

Epoch: 5| Step: 9
Training loss: 1.574964165687561
Validation loss: 1.8376687419029973

Epoch: 5| Step: 10
Training loss: 0.9516934752464294
Validation loss: 1.9220536613977084

Epoch: 478| Step: 0
Training loss: 1.1582601070404053
Validation loss: 1.9172179904035342

Epoch: 5| Step: 1
Training loss: 1.1783778667449951
Validation loss: 1.8757063304224322

Epoch: 5| Step: 2
Training loss: 1.2103484869003296
Validation loss: 1.9439418867070188

Epoch: 5| Step: 3
Training loss: 0.8866081237792969
Validation loss: 1.8508500001763786

Epoch: 5| Step: 4
Training loss: 1.2025487422943115
Validation loss: 1.9269527876248924

Epoch: 5| Step: 5
Training loss: 0.8828433752059937
Validation loss: 1.9083399016370055

Epoch: 5| Step: 6
Training loss: 1.1320583820343018
Validation loss: 1.8486793656503

Epoch: 5| Step: 7
Training loss: 1.1612299680709839
Validation loss: 1.8897319955210532

Epoch: 5| Step: 8
Training loss: 1.8977199792861938
Validation loss: 1.8330663634884743

Epoch: 5| Step: 9
Training loss: 1.1576381921768188
Validation loss: 1.8792131049658662

Epoch: 5| Step: 10
Training loss: 1.2188712358474731
Validation loss: 1.9300889238234489

Epoch: 479| Step: 0
Training loss: 1.3197613954544067
Validation loss: 1.8784359975527691

Epoch: 5| Step: 1
Training loss: 0.7745820879936218
Validation loss: 1.8318556072891399

Epoch: 5| Step: 2
Training loss: 0.8808650970458984
Validation loss: 1.82192365841199

Epoch: 5| Step: 3
Training loss: 1.3503644466400146
Validation loss: 1.91180508623841

Epoch: 5| Step: 4
Training loss: 1.1074309349060059
Validation loss: 1.8929375371625345

Epoch: 5| Step: 5
Training loss: 1.3811719417572021
Validation loss: 1.8348118688470574

Epoch: 5| Step: 6
Training loss: 1.476870059967041
Validation loss: 1.844640713866039

Epoch: 5| Step: 7
Training loss: 1.0052140951156616
Validation loss: 1.911934196308095

Epoch: 5| Step: 8
Training loss: 1.3806824684143066
Validation loss: 1.8896230446395053

Epoch: 5| Step: 9
Training loss: 1.6200263500213623
Validation loss: 1.8842436908393778

Epoch: 5| Step: 10
Training loss: 0.7181563377380371
Validation loss: 1.8428170924545617

Epoch: 480| Step: 0
Training loss: 0.9507085680961609
Validation loss: 1.8776383271781347

Epoch: 5| Step: 1
Training loss: 1.3509361743927002
Validation loss: 1.8553851637788998

Epoch: 5| Step: 2
Training loss: 0.8081089854240417
Validation loss: 1.831162332206644

Epoch: 5| Step: 3
Training loss: 1.4224971532821655
Validation loss: 1.9011297142633827

Epoch: 5| Step: 4
Training loss: 1.3671760559082031
Validation loss: 1.8798760291068786

Epoch: 5| Step: 5
Training loss: 0.7602220773696899
Validation loss: 1.9136812558738134

Epoch: 5| Step: 6
Training loss: 0.9903103709220886
Validation loss: 1.8681708330749183

Epoch: 5| Step: 7
Training loss: 1.4751497507095337
Validation loss: 1.8764741882201164

Epoch: 5| Step: 8
Training loss: 1.0507543087005615
Validation loss: 1.835583060018478

Epoch: 5| Step: 9
Training loss: 1.315288782119751
Validation loss: 1.8881489435831706

Epoch: 5| Step: 10
Training loss: 1.2698073387145996
Validation loss: 1.8674860180065196

Epoch: 481| Step: 0
Training loss: 0.7316396236419678
Validation loss: 1.8526473558077248

Epoch: 5| Step: 1
Training loss: 0.8969568014144897
Validation loss: 1.8700700934215257

Epoch: 5| Step: 2
Training loss: 1.7281090021133423
Validation loss: 1.89381928084999

Epoch: 5| Step: 3
Training loss: 1.2691938877105713
Validation loss: 1.8782292655719224

Epoch: 5| Step: 4
Training loss: 1.1935533285140991
Validation loss: 1.8654524331451745

Epoch: 5| Step: 5
Training loss: 0.9024654626846313
Validation loss: 1.865696108469399

Epoch: 5| Step: 6
Training loss: 1.5219924449920654
Validation loss: 1.873959674630114

Epoch: 5| Step: 7
Training loss: 1.1311734914779663
Validation loss: 1.848310302662593

Epoch: 5| Step: 8
Training loss: 1.3717875480651855
Validation loss: 1.8640341912546465

Epoch: 5| Step: 9
Training loss: 1.1179430484771729
Validation loss: 1.9086130511376165

Epoch: 5| Step: 10
Training loss: 1.0973262786865234
Validation loss: 1.8851501428952782

Epoch: 482| Step: 0
Training loss: 0.8194788694381714
Validation loss: 1.8430398689803256

Epoch: 5| Step: 1
Training loss: 1.2682275772094727
Validation loss: 1.8709327046589186

Epoch: 5| Step: 2
Training loss: 1.1231768131256104
Validation loss: 1.9138244736579157

Epoch: 5| Step: 3
Training loss: 1.310619592666626
Validation loss: 1.889869370768147

Epoch: 5| Step: 4
Training loss: 1.0927172899246216
Validation loss: 1.8717594710729455

Epoch: 5| Step: 5
Training loss: 1.64739990234375
Validation loss: 1.8609427918669998

Epoch: 5| Step: 6
Training loss: 0.6754944920539856
Validation loss: 1.8634374680057648

Epoch: 5| Step: 7
Training loss: 1.4152758121490479
Validation loss: 1.8902154327720724

Epoch: 5| Step: 8
Training loss: 1.2784423828125
Validation loss: 1.8549826491263606

Epoch: 5| Step: 9
Training loss: 1.3606207370758057
Validation loss: 1.8530089316829559

Epoch: 5| Step: 10
Training loss: 0.8983162641525269
Validation loss: 1.8621985796959168

Epoch: 483| Step: 0
Training loss: 1.17226243019104
Validation loss: 1.8991833604792112

Epoch: 5| Step: 1
Training loss: 1.4134031534194946
Validation loss: 1.8064501477826027

Epoch: 5| Step: 2
Training loss: 0.9862939119338989
Validation loss: 1.8230508373629661

Epoch: 5| Step: 3
Training loss: 0.7028412222862244
Validation loss: 1.8909607651413127

Epoch: 5| Step: 4
Training loss: 1.0830121040344238
Validation loss: 1.8406029362832346

Epoch: 5| Step: 5
Training loss: 0.7861993312835693
Validation loss: 1.8794879169874295

Epoch: 5| Step: 6
Training loss: 1.1558831930160522
Validation loss: 1.8333971936215636

Epoch: 5| Step: 7
Training loss: 1.506859302520752
Validation loss: 1.8793697536632579

Epoch: 5| Step: 8
Training loss: 1.2168316841125488
Validation loss: 1.8754913973551925

Epoch: 5| Step: 9
Training loss: 1.8348067998886108
Validation loss: 1.8549961710488925

Epoch: 5| Step: 10
Training loss: 0.9349161386489868
Validation loss: 1.9024128426787674

Epoch: 484| Step: 0
Training loss: 1.5167913436889648
Validation loss: 1.855823556582133

Epoch: 5| Step: 1
Training loss: 0.9259960055351257
Validation loss: 1.8496260937824045

Epoch: 5| Step: 2
Training loss: 0.738723635673523
Validation loss: 1.8156422556087535

Epoch: 5| Step: 3
Training loss: 1.0764100551605225
Validation loss: 1.8757704996293592

Epoch: 5| Step: 4
Training loss: 1.018913984298706
Validation loss: 1.8554569969895065

Epoch: 5| Step: 5
Training loss: 1.5162808895111084
Validation loss: 1.9017952821588004

Epoch: 5| Step: 6
Training loss: 0.7535509467124939
Validation loss: 1.831158270118057

Epoch: 5| Step: 7
Training loss: 1.2718597650527954
Validation loss: 1.8732875136918918

Epoch: 5| Step: 8
Training loss: 1.3094786405563354
Validation loss: 1.8367991511539747

Epoch: 5| Step: 9
Training loss: 1.0504916906356812
Validation loss: 1.8512385840057044

Epoch: 5| Step: 10
Training loss: 1.203092098236084
Validation loss: 1.8391208546136015

Epoch: 485| Step: 0
Training loss: 1.4686486721038818
Validation loss: 1.869315210209098

Epoch: 5| Step: 1
Training loss: 1.4457505941390991
Validation loss: 1.8486487006628385

Epoch: 5| Step: 2
Training loss: 1.140252709388733
Validation loss: 1.873028032241329

Epoch: 5| Step: 3
Training loss: 0.9495587348937988
Validation loss: 1.8635041649623583

Epoch: 5| Step: 4
Training loss: 1.4488168954849243
Validation loss: 1.8243275303994455

Epoch: 5| Step: 5
Training loss: 1.7341724634170532
Validation loss: 1.8656439858098184

Epoch: 5| Step: 6
Training loss: 1.2347103357315063
Validation loss: 1.8730663253415016

Epoch: 5| Step: 7
Training loss: 0.8136467933654785
Validation loss: 1.8321088616565993

Epoch: 5| Step: 8
Training loss: 0.5767609477043152
Validation loss: 1.773553982857735

Epoch: 5| Step: 9
Training loss: 0.8914028406143188
Validation loss: 1.8610027220941359

Epoch: 5| Step: 10
Training loss: 1.3345476388931274
Validation loss: 1.8227128123724332

Epoch: 486| Step: 0
Training loss: 1.4967060089111328
Validation loss: 1.7703901503675727

Epoch: 5| Step: 1
Training loss: 1.1562010049819946
Validation loss: 1.83406186872913

Epoch: 5| Step: 2
Training loss: 0.965231716632843
Validation loss: 1.8434255789684992

Epoch: 5| Step: 3
Training loss: 0.9379591941833496
Validation loss: 1.8492005614824192

Epoch: 5| Step: 4
Training loss: 1.5425443649291992
Validation loss: 1.846622996432807

Epoch: 5| Step: 5
Training loss: 0.8036537170410156
Validation loss: 1.8826984359372048

Epoch: 5| Step: 6
Training loss: 1.9161230325698853
Validation loss: 1.837353829414614

Epoch: 5| Step: 7
Training loss: 0.8923026919364929
Validation loss: 1.8940982446875623

Epoch: 5| Step: 8
Training loss: 1.0417053699493408
Validation loss: 1.8604298253213205

Epoch: 5| Step: 9
Training loss: 0.956344723701477
Validation loss: 1.8467995479542723

Epoch: 5| Step: 10
Training loss: 0.9095664024353027
Validation loss: 1.908269497656053

Epoch: 487| Step: 0
Training loss: 1.3420060873031616
Validation loss: 1.8046304859140867

Epoch: 5| Step: 1
Training loss: 0.9048036336898804
Validation loss: 1.8371555023295905

Epoch: 5| Step: 2
Training loss: 0.9394500851631165
Validation loss: 1.8244928236930602

Epoch: 5| Step: 3
Training loss: 1.488222599029541
Validation loss: 1.854667503346679

Epoch: 5| Step: 4
Training loss: 1.116126298904419
Validation loss: 1.9100412296992477

Epoch: 5| Step: 5
Training loss: 0.9834161996841431
Validation loss: 1.8860942445775515

Epoch: 5| Step: 6
Training loss: 1.4148353338241577
Validation loss: 1.86259082312225

Epoch: 5| Step: 7
Training loss: 0.9646615982055664
Validation loss: 1.9098732240738407

Epoch: 5| Step: 8
Training loss: 0.8447154760360718
Validation loss: 1.8997766087132115

Epoch: 5| Step: 9
Training loss: 1.2151710987091064
Validation loss: 1.9258155822753906

Epoch: 5| Step: 10
Training loss: 1.4021286964416504
Validation loss: 1.8930856745730165

Epoch: 488| Step: 0
Training loss: 1.2896082401275635
Validation loss: 1.8820937269477434

Epoch: 5| Step: 1
Training loss: 1.0973082780838013
Validation loss: 1.9235180654833395

Epoch: 5| Step: 2
Training loss: 0.7352038621902466
Validation loss: 1.844440496096047

Epoch: 5| Step: 3
Training loss: 0.9976524114608765
Validation loss: 1.837333426680616

Epoch: 5| Step: 4
Training loss: 1.4585590362548828
Validation loss: 1.8468936925293298

Epoch: 5| Step: 5
Training loss: 1.1830815076828003
Validation loss: 1.8485197200570056

Epoch: 5| Step: 6
Training loss: 1.3460344076156616
Validation loss: 1.8765586729972594

Epoch: 5| Step: 7
Training loss: 0.9370567202568054
Validation loss: 1.8702954899880193

Epoch: 5| Step: 8
Training loss: 1.0864050388336182
Validation loss: 1.8432189815787858

Epoch: 5| Step: 9
Training loss: 1.6246325969696045
Validation loss: 1.8295194487417898

Epoch: 5| Step: 10
Training loss: 1.2705202102661133
Validation loss: 1.8883221444263254

Epoch: 489| Step: 0
Training loss: 1.199960708618164
Validation loss: 1.852983054294381

Epoch: 5| Step: 1
Training loss: 1.1074763536453247
Validation loss: 1.9011905590693157

Epoch: 5| Step: 2
Training loss: 1.4881093502044678
Validation loss: 1.8507350426848217

Epoch: 5| Step: 3
Training loss: 1.0289742946624756
Validation loss: 1.8899274026193926

Epoch: 5| Step: 4
Training loss: 1.4515488147735596
Validation loss: 1.900379455217751

Epoch: 5| Step: 5
Training loss: 0.9987467527389526
Validation loss: 1.8489259148156771

Epoch: 5| Step: 6
Training loss: 0.822981059551239
Validation loss: 1.8437976567975936

Epoch: 5| Step: 7
Training loss: 1.1777857542037964
Validation loss: 1.9454826654926423

Epoch: 5| Step: 8
Training loss: 1.3583190441131592
Validation loss: 1.8810219328890565

Epoch: 5| Step: 9
Training loss: 1.2773139476776123
Validation loss: 1.8911331161375968

Epoch: 5| Step: 10
Training loss: 1.1471508741378784
Validation loss: 1.8876160729315974

Epoch: 490| Step: 0
Training loss: 1.1539751291275024
Validation loss: 1.8557017695519231

Epoch: 5| Step: 1
Training loss: 1.0379414558410645
Validation loss: 1.8666443440221971

Epoch: 5| Step: 2
Training loss: 1.3545663356781006
Validation loss: 1.91600509612791

Epoch: 5| Step: 3
Training loss: 0.614503026008606
Validation loss: 1.7921602879801104

Epoch: 5| Step: 4
Training loss: 1.599464774131775
Validation loss: 1.8601633425681823

Epoch: 5| Step: 5
Training loss: 1.4105464220046997
Validation loss: 1.8984317241176483

Epoch: 5| Step: 6
Training loss: 0.9791234731674194
Validation loss: 1.8634965701769757

Epoch: 5| Step: 7
Training loss: 1.1166126728057861
Validation loss: 1.8319105345715758

Epoch: 5| Step: 8
Training loss: 1.119938611984253
Validation loss: 1.8372131419438187

Epoch: 5| Step: 9
Training loss: 1.3403836488723755
Validation loss: 1.8374225631836922

Epoch: 5| Step: 10
Training loss: 0.7058897614479065
Validation loss: 1.8536847624727475

Epoch: 491| Step: 0
Training loss: 1.0181182622909546
Validation loss: 1.824587465614401

Epoch: 5| Step: 1
Training loss: 0.9354057312011719
Validation loss: 1.8362527098706973

Epoch: 5| Step: 2
Training loss: 1.5667816400527954
Validation loss: 1.8952513869090746

Epoch: 5| Step: 3
Training loss: 1.4713449478149414
Validation loss: 1.836158050003872

Epoch: 5| Step: 4
Training loss: 1.2957608699798584
Validation loss: 1.8052506152019705

Epoch: 5| Step: 5
Training loss: 1.2191282510757446
Validation loss: 1.8189363197613788

Epoch: 5| Step: 6
Training loss: 1.5937436819076538
Validation loss: 1.8476807058498423

Epoch: 5| Step: 7
Training loss: 0.9072807431221008
Validation loss: 1.8483025925133818

Epoch: 5| Step: 8
Training loss: 0.9641140699386597
Validation loss: 1.8509727844627955

Epoch: 5| Step: 9
Training loss: 1.004727840423584
Validation loss: 1.8742347096884122

Epoch: 5| Step: 10
Training loss: 0.5919491052627563
Validation loss: 1.8843951802099905

Epoch: 492| Step: 0
Training loss: 1.2359817028045654
Validation loss: 1.902404225000771

Epoch: 5| Step: 1
Training loss: 1.0377070903778076
Validation loss: 1.8310726534935735

Epoch: 5| Step: 2
Training loss: 1.5869057178497314
Validation loss: 1.8686375233434862

Epoch: 5| Step: 3
Training loss: 0.9361472129821777
Validation loss: 1.8493547285756757

Epoch: 5| Step: 4
Training loss: 0.8223831057548523
Validation loss: 1.8671592755984234

Epoch: 5| Step: 5
Training loss: 1.450408935546875
Validation loss: 1.8141460675065235

Epoch: 5| Step: 6
Training loss: 1.2180461883544922
Validation loss: 1.8410001224087131

Epoch: 5| Step: 7
Training loss: 1.0276179313659668
Validation loss: 1.8552171350807272

Epoch: 5| Step: 8
Training loss: 0.9548144340515137
Validation loss: 1.773955859163756

Epoch: 5| Step: 9
Training loss: 1.2832061052322388
Validation loss: 1.806940322281212

Epoch: 5| Step: 10
Training loss: 1.2305002212524414
Validation loss: 1.9268992485538605

Epoch: 493| Step: 0
Training loss: 1.274632453918457
Validation loss: 1.8543022268561906

Epoch: 5| Step: 1
Training loss: 1.2033120393753052
Validation loss: 1.9185137120626305

Epoch: 5| Step: 2
Training loss: 1.1249752044677734
Validation loss: 1.8404440802912558

Epoch: 5| Step: 3
Training loss: 1.0928128957748413
Validation loss: 1.7863393201622912

Epoch: 5| Step: 4
Training loss: 1.2309976816177368
Validation loss: 1.798199188324713

Epoch: 5| Step: 5
Training loss: 1.0330177545547485
Validation loss: 1.7802013504889704

Epoch: 5| Step: 6
Training loss: 1.2886426448822021
Validation loss: 1.889477499069706

Epoch: 5| Step: 7
Training loss: 1.1944372653961182
Validation loss: 1.8465031321330736

Epoch: 5| Step: 8
Training loss: 0.9849246144294739
Validation loss: 1.8398953637769144

Epoch: 5| Step: 9
Training loss: 1.1274009943008423
Validation loss: 1.8770534671762937

Epoch: 5| Step: 10
Training loss: 1.093546986579895
Validation loss: 1.903450942808582

Epoch: 494| Step: 0
Training loss: 1.0712621212005615
Validation loss: 1.8801582628680813

Epoch: 5| Step: 1
Training loss: 1.1825973987579346
Validation loss: 1.9083510727010748

Epoch: 5| Step: 2
Training loss: 0.9709353446960449
Validation loss: 1.8687090976263887

Epoch: 5| Step: 3
Training loss: 1.1658518314361572
Validation loss: 1.8371953964233398

Epoch: 5| Step: 4
Training loss: 0.9453970193862915
Validation loss: 1.9103480231377385

Epoch: 5| Step: 5
Training loss: 0.9000629186630249
Validation loss: 1.842405483286868

Epoch: 5| Step: 6
Training loss: 1.238425850868225
Validation loss: 1.893612729605808

Epoch: 5| Step: 7
Training loss: 1.5460205078125
Validation loss: 1.8557034602729223

Epoch: 5| Step: 8
Training loss: 1.191994309425354
Validation loss: 1.889367006158316

Epoch: 5| Step: 9
Training loss: 1.0729193687438965
Validation loss: 1.8781062954215593

Epoch: 5| Step: 10
Training loss: 1.3230162858963013
Validation loss: 1.8698241044116277

Epoch: 495| Step: 0
Training loss: 1.0369768142700195
Validation loss: 1.872335865933408

Epoch: 5| Step: 1
Training loss: 1.0955407619476318
Validation loss: 1.8490909568725094

Epoch: 5| Step: 2
Training loss: 1.10323166847229
Validation loss: 1.877549293220684

Epoch: 5| Step: 3
Training loss: 1.3864352703094482
Validation loss: 1.8697845935821533

Epoch: 5| Step: 4
Training loss: 1.2889492511749268
Validation loss: 1.8381877996588265

Epoch: 5| Step: 5
Training loss: 1.2748852968215942
Validation loss: 1.8455504448183122

Epoch: 5| Step: 6
Training loss: 0.4768184721469879
Validation loss: 1.8165386389660578

Epoch: 5| Step: 7
Training loss: 1.4632353782653809
Validation loss: 1.894839104785714

Epoch: 5| Step: 8
Training loss: 1.2411606311798096
Validation loss: 1.798858150359123

Epoch: 5| Step: 9
Training loss: 0.7693203091621399
Validation loss: 1.8736269217665478

Epoch: 5| Step: 10
Training loss: 1.4944043159484863
Validation loss: 1.8444508666633277

Epoch: 496| Step: 0
Training loss: 1.472060203552246
Validation loss: 1.8508301601615003

Epoch: 5| Step: 1
Training loss: 1.4908561706542969
Validation loss: 1.8272411746363486

Epoch: 5| Step: 2
Training loss: 0.8441879153251648
Validation loss: 1.8134048677259875

Epoch: 5| Step: 3
Training loss: 0.9020597338676453
Validation loss: 1.8477078971042429

Epoch: 5| Step: 4
Training loss: 1.2237675189971924
Validation loss: 1.815970649001419

Epoch: 5| Step: 5
Training loss: 1.419225811958313
Validation loss: 1.8410756421345535

Epoch: 5| Step: 6
Training loss: 1.0841178894042969
Validation loss: 1.8510222665725216

Epoch: 5| Step: 7
Training loss: 1.1066397428512573
Validation loss: 1.8291883366082304

Epoch: 5| Step: 8
Training loss: 0.6196064949035645
Validation loss: 1.8388261961680588

Epoch: 5| Step: 9
Training loss: 1.0447947978973389
Validation loss: 1.8865997124743719

Epoch: 5| Step: 10
Training loss: 1.6456068754196167
Validation loss: 1.835859303833336

Epoch: 497| Step: 0
Training loss: 1.1000077724456787
Validation loss: 1.866019283571551

Epoch: 5| Step: 1
Training loss: 0.7750290632247925
Validation loss: 1.9164681793541036

Epoch: 5| Step: 2
Training loss: 1.0067861080169678
Validation loss: 1.8885155570122503

Epoch: 5| Step: 3
Training loss: 1.1726840734481812
Validation loss: 1.8368390144840363

Epoch: 5| Step: 4
Training loss: 1.0507173538208008
Validation loss: 1.7956315496916413

Epoch: 5| Step: 5
Training loss: 1.5998685359954834
Validation loss: 1.8332742311621224

Epoch: 5| Step: 6
Training loss: 1.3295612335205078
Validation loss: 1.802769443040253

Epoch: 5| Step: 7
Training loss: 1.2107579708099365
Validation loss: 1.8251757929402013

Epoch: 5| Step: 8
Training loss: 0.9801715612411499
Validation loss: 1.87412263501075

Epoch: 5| Step: 9
Training loss: 1.3425462245941162
Validation loss: 1.8840394917354788

Epoch: 5| Step: 10
Training loss: 1.2818729877471924
Validation loss: 1.8545469789094822

Epoch: 498| Step: 0
Training loss: 0.9466875195503235
Validation loss: 1.8292979732636483

Epoch: 5| Step: 1
Training loss: 1.0405786037445068
Validation loss: 1.858499917932736

Epoch: 5| Step: 2
Training loss: 1.6456670761108398
Validation loss: 1.8641203193254368

Epoch: 5| Step: 3
Training loss: 1.3083198070526123
Validation loss: 1.9530863159446306

Epoch: 5| Step: 4
Training loss: 1.2168773412704468
Validation loss: 1.8809967925471645

Epoch: 5| Step: 5
Training loss: 1.0271624326705933
Validation loss: 1.8255337310093704

Epoch: 5| Step: 6
Training loss: 1.009530782699585
Validation loss: 1.9108288493207706

Epoch: 5| Step: 7
Training loss: 1.4845861196517944
Validation loss: 1.813124882277622

Epoch: 5| Step: 8
Training loss: 1.0915248394012451
Validation loss: 1.8122323636085755

Epoch: 5| Step: 9
Training loss: 0.9476474523544312
Validation loss: 1.8441005727296234

Epoch: 5| Step: 10
Training loss: 0.8824427723884583
Validation loss: 1.8014290114884735

Epoch: 499| Step: 0
Training loss: 1.265933871269226
Validation loss: 1.9457081492229173

Epoch: 5| Step: 1
Training loss: 1.13190758228302
Validation loss: 1.8628519888847106

Epoch: 5| Step: 2
Training loss: 1.119753122329712
Validation loss: 1.875964690280217

Epoch: 5| Step: 3
Training loss: 0.9956919550895691
Validation loss: 1.8488259725673224

Epoch: 5| Step: 4
Training loss: 1.0211122035980225
Validation loss: 1.8570345191545383

Epoch: 5| Step: 5
Training loss: 0.883296012878418
Validation loss: 1.8722280609992243

Epoch: 5| Step: 6
Training loss: 1.4099061489105225
Validation loss: 1.855557523747926

Epoch: 5| Step: 7
Training loss: 1.1110879182815552
Validation loss: 1.8318799990479664

Epoch: 5| Step: 8
Training loss: 1.3869235515594482
Validation loss: 1.8632884781847718

Epoch: 5| Step: 9
Training loss: 1.6053835153579712
Validation loss: 1.8219612593291907

Epoch: 5| Step: 10
Training loss: 0.6974480748176575
Validation loss: 1.7847030944721674

Epoch: 500| Step: 0
Training loss: 0.8446071743965149
Validation loss: 1.8660145933910082

Epoch: 5| Step: 1
Training loss: 1.9137474298477173
Validation loss: 1.8699534669999154

Epoch: 5| Step: 2
Training loss: 1.0477511882781982
Validation loss: 1.868048414107292

Epoch: 5| Step: 3
Training loss: 0.7561826705932617
Validation loss: 1.801186038601783

Epoch: 5| Step: 4
Training loss: 1.3928687572479248
Validation loss: 1.8518638187839138

Epoch: 5| Step: 5
Training loss: 1.2366459369659424
Validation loss: 1.8008264777480916

Epoch: 5| Step: 6
Training loss: 0.9210168123245239
Validation loss: 1.8423662493305821

Epoch: 5| Step: 7
Training loss: 1.0797173976898193
Validation loss: 1.83801773799363

Epoch: 5| Step: 8
Training loss: 0.8236306309700012
Validation loss: 1.8585381584782754

Epoch: 5| Step: 9
Training loss: 1.1437088251113892
Validation loss: 1.8768545645539478

Epoch: 5| Step: 10
Training loss: 1.3866558074951172
Validation loss: 1.7913846123603083

Epoch: 501| Step: 0
Training loss: 0.8376110792160034
Validation loss: 1.9226148448964602

Epoch: 5| Step: 1
Training loss: 1.1446380615234375
Validation loss: 1.863921724339967

Epoch: 5| Step: 2
Training loss: 1.1729886531829834
Validation loss: 1.8624025320494046

Epoch: 5| Step: 3
Training loss: 1.1617252826690674
Validation loss: 1.8649692022672264

Epoch: 5| Step: 4
Training loss: 1.042738914489746
Validation loss: 1.8648047639477638

Epoch: 5| Step: 5
Training loss: 0.6174883842468262
Validation loss: 1.8370770203169955

Epoch: 5| Step: 6
Training loss: 1.2545535564422607
Validation loss: 1.85322815884826

Epoch: 5| Step: 7
Training loss: 1.4785289764404297
Validation loss: 1.782925667301301

Epoch: 5| Step: 8
Training loss: 1.2438174486160278
Validation loss: 1.8282708557703162

Epoch: 5| Step: 9
Training loss: 1.2228587865829468
Validation loss: 1.925843596458435

Epoch: 5| Step: 10
Training loss: 1.2645305395126343
Validation loss: 1.8156200890899987

Epoch: 502| Step: 0
Training loss: 1.498062252998352
Validation loss: 1.8299571737166374

Epoch: 5| Step: 1
Training loss: 1.4876976013183594
Validation loss: 1.8691285169252785

Epoch: 5| Step: 2
Training loss: 0.9974085092544556
Validation loss: 1.869669977054801

Epoch: 5| Step: 3
Training loss: 0.7560757398605347
Validation loss: 1.9295699929678312

Epoch: 5| Step: 4
Training loss: 1.0506707429885864
Validation loss: 1.8322547853633921

Epoch: 5| Step: 5
Training loss: 1.0942890644073486
Validation loss: 1.800135443287511

Epoch: 5| Step: 6
Training loss: 1.015932321548462
Validation loss: 1.8583513075305569

Epoch: 5| Step: 7
Training loss: 1.2187942266464233
Validation loss: 1.8076083839580577

Epoch: 5| Step: 8
Training loss: 0.8959026336669922
Validation loss: 1.8858254686478646

Epoch: 5| Step: 9
Training loss: 1.5269653797149658
Validation loss: 1.871625255512935

Epoch: 5| Step: 10
Training loss: 1.177193522453308
Validation loss: 1.8370767254983225

Epoch: 503| Step: 0
Training loss: 1.1557525396347046
Validation loss: 1.8506064927706154

Epoch: 5| Step: 1
Training loss: 1.2433714866638184
Validation loss: 1.8398833377386934

Epoch: 5| Step: 2
Training loss: 1.5955356359481812
Validation loss: 1.84375133052949

Epoch: 5| Step: 3
Training loss: 0.6775508522987366
Validation loss: 1.846589542204334

Epoch: 5| Step: 4
Training loss: 1.067508339881897
Validation loss: 1.859813513294343

Epoch: 5| Step: 5
Training loss: 1.277935266494751
Validation loss: 1.8437686645856468

Epoch: 5| Step: 6
Training loss: 0.8148131370544434
Validation loss: 1.8162986911753172

Epoch: 5| Step: 7
Training loss: 1.1350483894348145
Validation loss: 1.833971933651996

Epoch: 5| Step: 8
Training loss: 1.0770175457000732
Validation loss: 1.8483665579108781

Epoch: 5| Step: 9
Training loss: 1.0384771823883057
Validation loss: 1.8823887584029988

Epoch: 5| Step: 10
Training loss: 1.3131757974624634
Validation loss: 1.8906166412497079

Epoch: 504| Step: 0
Training loss: 1.49909245967865
Validation loss: 1.8673463995738695

Epoch: 5| Step: 1
Training loss: 0.9413448572158813
Validation loss: 1.8852614548898512

Epoch: 5| Step: 2
Training loss: 1.0111225843429565
Validation loss: 1.884236934364483

Epoch: 5| Step: 3
Training loss: 1.35402512550354
Validation loss: 1.8512411604645431

Epoch: 5| Step: 4
Training loss: 1.014268159866333
Validation loss: 1.838209807231862

Epoch: 5| Step: 5
Training loss: 1.3778094053268433
Validation loss: 1.8251059106601182

Epoch: 5| Step: 6
Training loss: 1.2262794971466064
Validation loss: 1.8778816077017015

Epoch: 5| Step: 7
Training loss: 1.0951976776123047
Validation loss: 1.9137154125398206

Epoch: 5| Step: 8
Training loss: 0.7235218286514282
Validation loss: 1.8019757347722207

Epoch: 5| Step: 9
Training loss: 1.3283830881118774
Validation loss: 1.8346340656280518

Epoch: 5| Step: 10
Training loss: 0.674006998538971
Validation loss: 1.8141424553368681

Epoch: 505| Step: 0
Training loss: 1.1704816818237305
Validation loss: 1.8348139139913744

Epoch: 5| Step: 1
Training loss: 1.1045377254486084
Validation loss: 1.8309466223562918

Epoch: 5| Step: 2
Training loss: 0.7900122404098511
Validation loss: 1.822978050478043

Epoch: 5| Step: 3
Training loss: 1.1053251028060913
Validation loss: 1.8953493615632415

Epoch: 5| Step: 4
Training loss: 0.8008891940116882
Validation loss: 1.866849721118968

Epoch: 5| Step: 5
Training loss: 1.6881440877914429
Validation loss: 1.8657624452344832

Epoch: 5| Step: 6
Training loss: 1.1126036643981934
Validation loss: 1.8668888384296047

Epoch: 5| Step: 7
Training loss: 0.9216998219490051
Validation loss: 1.8520292710232478

Epoch: 5| Step: 8
Training loss: 1.2571519613265991
Validation loss: 1.8735133268499886

Epoch: 5| Step: 9
Training loss: 1.2614047527313232
Validation loss: 1.8383326004910212

Epoch: 5| Step: 10
Training loss: 1.3222565650939941
Validation loss: 1.8732992756751277

Epoch: 506| Step: 0
Training loss: 0.954740047454834
Validation loss: 1.8693999475048435

Epoch: 5| Step: 1
Training loss: 0.9516772031784058
Validation loss: 1.8190869874851678

Epoch: 5| Step: 2
Training loss: 0.9936404228210449
Validation loss: 1.8989951982293078

Epoch: 5| Step: 3
Training loss: 0.9041045904159546
Validation loss: 1.8825416693123438

Epoch: 5| Step: 4
Training loss: 1.8606294393539429
Validation loss: 1.8123887482509817

Epoch: 5| Step: 5
Training loss: 0.9320712089538574
Validation loss: 1.8549337797267462

Epoch: 5| Step: 6
Training loss: 0.7942683696746826
Validation loss: 1.8529311226260277

Epoch: 5| Step: 7
Training loss: 1.9173002243041992
Validation loss: 1.8601595201799948

Epoch: 5| Step: 8
Training loss: 1.0840390920639038
Validation loss: 1.8473025932106921

Epoch: 5| Step: 9
Training loss: 1.024097204208374
Validation loss: 1.8846364841666272

Epoch: 5| Step: 10
Training loss: 0.9974471926689148
Validation loss: 1.874233861123362

Epoch: 507| Step: 0
Training loss: 0.9222190976142883
Validation loss: 1.8439154471120527

Epoch: 5| Step: 1
Training loss: 0.8046268224716187
Validation loss: 1.8489940730474328

Epoch: 5| Step: 2
Training loss: 0.6706793904304504
Validation loss: 1.8188701701420609

Epoch: 5| Step: 3
Training loss: 1.008517861366272
Validation loss: 1.8751824594313098

Epoch: 5| Step: 4
Training loss: 0.9923938512802124
Validation loss: 1.8310810647984987

Epoch: 5| Step: 5
Training loss: 1.5561156272888184
Validation loss: 1.826321001975767

Epoch: 5| Step: 6
Training loss: 1.3570029735565186
Validation loss: 1.7968441106939828

Epoch: 5| Step: 7
Training loss: 1.4110772609710693
Validation loss: 1.8504956255676925

Epoch: 5| Step: 8
Training loss: 1.2654067277908325
Validation loss: 1.8782056416234663

Epoch: 5| Step: 9
Training loss: 1.358428955078125
Validation loss: 1.8761978751869612

Epoch: 5| Step: 10
Training loss: 0.9017119407653809
Validation loss: 1.8775569264606764

Epoch: 508| Step: 0
Training loss: 1.2369697093963623
Validation loss: 1.8199929960312382

Epoch: 5| Step: 1
Training loss: 1.1915429830551147
Validation loss: 1.9223535317246632

Epoch: 5| Step: 2
Training loss: 1.1341285705566406
Validation loss: 1.8283952461775912

Epoch: 5| Step: 3
Training loss: 1.1673529148101807
Validation loss: 1.9073353634085706

Epoch: 5| Step: 4
Training loss: 1.1277555227279663
Validation loss: 1.870080824821226

Epoch: 5| Step: 5
Training loss: 1.3075666427612305
Validation loss: 1.7971287273591565

Epoch: 5| Step: 6
Training loss: 1.0407681465148926
Validation loss: 1.8797123265522782

Epoch: 5| Step: 7
Training loss: 0.946382999420166
Validation loss: 1.8170571532300723

Epoch: 5| Step: 8
Training loss: 0.9327741861343384
Validation loss: 1.8240932469726892

Epoch: 5| Step: 9
Training loss: 1.2237579822540283
Validation loss: 1.8466251178454327

Epoch: 5| Step: 10
Training loss: 1.4474353790283203
Validation loss: 1.8243204368058072

Epoch: 509| Step: 0
Training loss: 0.691411554813385
Validation loss: 1.8693043301182408

Epoch: 5| Step: 1
Training loss: 0.7185788750648499
Validation loss: 1.7411414295114496

Epoch: 5| Step: 2
Training loss: 1.3005411624908447
Validation loss: 1.8031559234024377

Epoch: 5| Step: 3
Training loss: 1.0773286819458008
Validation loss: 1.8698757668977142

Epoch: 5| Step: 4
Training loss: 0.8696163892745972
Validation loss: 1.8750991103469685

Epoch: 5| Step: 5
Training loss: 1.7580196857452393
Validation loss: 1.7864389547737696

Epoch: 5| Step: 6
Training loss: 0.8562609553337097
Validation loss: 1.784803464848508

Epoch: 5| Step: 7
Training loss: 0.8950635194778442
Validation loss: 1.8495327413723033

Epoch: 5| Step: 8
Training loss: 1.4379669427871704
Validation loss: 1.7914502646333428

Epoch: 5| Step: 9
Training loss: 1.3248411417007446
Validation loss: 1.8503508234536776

Epoch: 5| Step: 10
Training loss: 1.2766127586364746
Validation loss: 1.7972066389617098

Epoch: 510| Step: 0
Training loss: 1.0361706018447876
Validation loss: 1.836849897138534

Epoch: 5| Step: 1
Training loss: 1.3707594871520996
Validation loss: 1.8200258388314197

Epoch: 5| Step: 2
Training loss: 1.2794711589813232
Validation loss: 1.8109947904463737

Epoch: 5| Step: 3
Training loss: 0.7993854880332947
Validation loss: 1.8511142628167265

Epoch: 5| Step: 4
Training loss: 1.4110891819000244
Validation loss: 1.8771128116115448

Epoch: 5| Step: 5
Training loss: 1.427025318145752
Validation loss: 1.7955659204913723

Epoch: 5| Step: 6
Training loss: 0.7660990953445435
Validation loss: 1.8025112216190626

Epoch: 5| Step: 7
Training loss: 1.1004756689071655
Validation loss: 1.7827982774344824

Epoch: 5| Step: 8
Training loss: 1.0754156112670898
Validation loss: 1.8577017220117713

Epoch: 5| Step: 9
Training loss: 1.0021919012069702
Validation loss: 1.832008623307751

Epoch: 5| Step: 10
Training loss: 1.053868293762207
Validation loss: 1.8626646713543964

Epoch: 511| Step: 0
Training loss: 1.4765441417694092
Validation loss: 1.8626599414374239

Epoch: 5| Step: 1
Training loss: 1.143670678138733
Validation loss: 1.8638437422372962

Epoch: 5| Step: 2
Training loss: 1.0980918407440186
Validation loss: 1.7836908999309744

Epoch: 5| Step: 3
Training loss: 0.6938362717628479
Validation loss: 1.9013628652018886

Epoch: 5| Step: 4
Training loss: 1.1013057231903076
Validation loss: 1.8459532940259544

Epoch: 5| Step: 5
Training loss: 0.9041463136672974
Validation loss: 1.7793730830633512

Epoch: 5| Step: 6
Training loss: 1.6211326122283936
Validation loss: 1.865341717197049

Epoch: 5| Step: 7
Training loss: 0.9016216397285461
Validation loss: 1.8139185379910212

Epoch: 5| Step: 8
Training loss: 1.227697730064392
Validation loss: 1.8365390723751438

Epoch: 5| Step: 9
Training loss: 1.1248674392700195
Validation loss: 1.8580242626128658

Epoch: 5| Step: 10
Training loss: 0.932576596736908
Validation loss: 1.8626700408997074

Epoch: 512| Step: 0
Training loss: 1.122902512550354
Validation loss: 1.8765393277650237

Epoch: 5| Step: 1
Training loss: 1.3198041915893555
Validation loss: 1.837536814392254

Epoch: 5| Step: 2
Training loss: 1.0507937669754028
Validation loss: 1.8283811640995804

Epoch: 5| Step: 3
Training loss: 1.045278787612915
Validation loss: 1.8186099131902058

Epoch: 5| Step: 4
Training loss: 1.4699018001556396
Validation loss: 1.8597149618210331

Epoch: 5| Step: 5
Training loss: 1.1711864471435547
Validation loss: 1.8666557893958142

Epoch: 5| Step: 6
Training loss: 0.9128372073173523
Validation loss: 1.852053439745339

Epoch: 5| Step: 7
Training loss: 0.7291749715805054
Validation loss: 1.8407668887927968

Epoch: 5| Step: 8
Training loss: 1.2559006214141846
Validation loss: 1.846923884525094

Epoch: 5| Step: 9
Training loss: 0.9806313514709473
Validation loss: 1.8682160608230098

Epoch: 5| Step: 10
Training loss: 1.2866787910461426
Validation loss: 1.820918477991576

Epoch: 513| Step: 0
Training loss: 0.8053845167160034
Validation loss: 1.8345325531498078

Epoch: 5| Step: 1
Training loss: 1.192726492881775
Validation loss: 1.8483027488954606

Epoch: 5| Step: 2
Training loss: 1.117010235786438
Validation loss: 1.8010572361689743

Epoch: 5| Step: 3
Training loss: 1.242026448249817
Validation loss: 1.8285760341152069

Epoch: 5| Step: 4
Training loss: 1.667370080947876
Validation loss: 1.8551216856125863

Epoch: 5| Step: 5
Training loss: 1.1382499933242798
Validation loss: 1.8610919496064544

Epoch: 5| Step: 6
Training loss: 1.0870387554168701
Validation loss: 1.9161604771050074

Epoch: 5| Step: 7
Training loss: 0.7212947607040405
Validation loss: 1.8041099476557907

Epoch: 5| Step: 8
Training loss: 1.393263816833496
Validation loss: 1.8422636037231774

Epoch: 5| Step: 9
Training loss: 1.357252597808838
Validation loss: 1.8349871635437012

Epoch: 5| Step: 10
Training loss: 0.6905667781829834
Validation loss: 1.8508615493774414

Epoch: 514| Step: 0
Training loss: 0.8663202524185181
Validation loss: 1.8717501073755243

Epoch: 5| Step: 1
Training loss: 1.3843326568603516
Validation loss: 1.8065671267048005

Epoch: 5| Step: 2
Training loss: 0.8146780729293823
Validation loss: 1.8624196847279866

Epoch: 5| Step: 3
Training loss: 1.1034990549087524
Validation loss: 1.8503587297213975

Epoch: 5| Step: 4
Training loss: 1.4028676748275757
Validation loss: 1.8468791118232153

Epoch: 5| Step: 5
Training loss: 0.8645423650741577
Validation loss: 1.844304900015554

Epoch: 5| Step: 6
Training loss: 1.1712400913238525
Validation loss: 1.9015351636435396

Epoch: 5| Step: 7
Training loss: 1.3981144428253174
Validation loss: 1.7897264906155166

Epoch: 5| Step: 8
Training loss: 0.8380805850028992
Validation loss: 1.801247130158127

Epoch: 5| Step: 9
Training loss: 1.1666200160980225
Validation loss: 1.8485222298611876

Epoch: 5| Step: 10
Training loss: 1.5799031257629395
Validation loss: 1.8285488710608533

Epoch: 515| Step: 0
Training loss: 1.1315807104110718
Validation loss: 1.8551015238608084

Epoch: 5| Step: 1
Training loss: 1.0393226146697998
Validation loss: 1.802565989955779

Epoch: 5| Step: 2
Training loss: 1.1161468029022217
Validation loss: 1.8251815918953187

Epoch: 5| Step: 3
Training loss: 0.9799027442932129
Validation loss: 1.8848888181870984

Epoch: 5| Step: 4
Training loss: 1.3232442140579224
Validation loss: 1.8585835874721568

Epoch: 5| Step: 5
Training loss: 1.3883891105651855
Validation loss: 1.8526003501748527

Epoch: 5| Step: 6
Training loss: 0.4214250445365906
Validation loss: 1.8533260258295203

Epoch: 5| Step: 7
Training loss: 1.4952049255371094
Validation loss: 1.8042081120193645

Epoch: 5| Step: 8
Training loss: 1.090580701828003
Validation loss: 1.8404358817685036

Epoch: 5| Step: 9
Training loss: 1.2714852094650269
Validation loss: 1.860901153215798

Epoch: 5| Step: 10
Training loss: 1.0231504440307617
Validation loss: 1.8503793042193177

Epoch: 516| Step: 0
Training loss: 0.6029699444770813
Validation loss: 1.82444945714807

Epoch: 5| Step: 1
Training loss: 0.8941410779953003
Validation loss: 1.8127122463718537

Epoch: 5| Step: 2
Training loss: 1.057857871055603
Validation loss: 1.8291052733698199

Epoch: 5| Step: 3
Training loss: 0.8857476115226746
Validation loss: 1.797551724218553

Epoch: 5| Step: 4
Training loss: 1.3110471963882446
Validation loss: 1.8623373175180087

Epoch: 5| Step: 5
Training loss: 1.1080360412597656
Validation loss: 1.7836535476869153

Epoch: 5| Step: 6
Training loss: 1.0828593969345093
Validation loss: 1.8586043862886326

Epoch: 5| Step: 7
Training loss: 1.2778202295303345
Validation loss: 1.867974317202004

Epoch: 5| Step: 8
Training loss: 1.9886465072631836
Validation loss: 1.8841298344314739

Epoch: 5| Step: 9
Training loss: 1.0299373865127563
Validation loss: 1.730409958029306

Epoch: 5| Step: 10
Training loss: 1.1569149494171143
Validation loss: 1.8772062806672947

Epoch: 517| Step: 0
Training loss: 0.9928016662597656
Validation loss: 1.8761930209334179

Epoch: 5| Step: 1
Training loss: 0.9236218333244324
Validation loss: 1.8585486040320447

Epoch: 5| Step: 2
Training loss: 1.0339981317520142
Validation loss: 1.888863145664174

Epoch: 5| Step: 3
Training loss: 1.4621329307556152
Validation loss: 1.8228027371950046

Epoch: 5| Step: 4
Training loss: 1.7343075275421143
Validation loss: 1.842948563637272

Epoch: 5| Step: 5
Training loss: 1.199528455734253
Validation loss: 1.8236190734371063

Epoch: 5| Step: 6
Training loss: 0.9008117914199829
Validation loss: 1.8426274202203239

Epoch: 5| Step: 7
Training loss: 1.0152161121368408
Validation loss: 1.8129494420943721

Epoch: 5| Step: 8
Training loss: 1.026950716972351
Validation loss: 1.865285038948059

Epoch: 5| Step: 9
Training loss: 1.172715663909912
Validation loss: 1.8212947999277422

Epoch: 5| Step: 10
Training loss: 0.9992313385009766
Validation loss: 1.8890409290149648

Epoch: 518| Step: 0
Training loss: 1.4040393829345703
Validation loss: 1.8169796389918174

Epoch: 5| Step: 1
Training loss: 1.0140597820281982
Validation loss: 1.7586215747300016

Epoch: 5| Step: 2
Training loss: 1.0723671913146973
Validation loss: 1.8822010601720502

Epoch: 5| Step: 3
Training loss: 1.3049185276031494
Validation loss: 1.7887408143730574

Epoch: 5| Step: 4
Training loss: 0.8270066976547241
Validation loss: 1.8470529599856305

Epoch: 5| Step: 5
Training loss: 2.0098531246185303
Validation loss: 1.7947996700963667

Epoch: 5| Step: 6
Training loss: 0.706656277179718
Validation loss: 1.8674872793177122

Epoch: 5| Step: 7
Training loss: 0.40493136644363403
Validation loss: 1.8144118849949171

Epoch: 5| Step: 8
Training loss: 1.0283217430114746
Validation loss: 1.837789309922085

Epoch: 5| Step: 9
Training loss: 1.2318310737609863
Validation loss: 1.7839888372728903

Epoch: 5| Step: 10
Training loss: 1.0944797992706299
Validation loss: 1.8486449128837996

Epoch: 519| Step: 0
Training loss: 1.0509191751480103
Validation loss: 1.8588917255401611

Epoch: 5| Step: 1
Training loss: 1.1036710739135742
Validation loss: 1.794233355470883

Epoch: 5| Step: 2
Training loss: 0.8952010869979858
Validation loss: 1.7933241551922214

Epoch: 5| Step: 3
Training loss: 1.51402747631073
Validation loss: 1.8878982682381906

Epoch: 5| Step: 4
Training loss: 0.8210474252700806
Validation loss: 1.793240418998144

Epoch: 5| Step: 5
Training loss: 0.9729191660881042
Validation loss: 1.8820075245313748

Epoch: 5| Step: 6
Training loss: 1.0949184894561768
Validation loss: 1.879982215102001

Epoch: 5| Step: 7
Training loss: 1.1330496072769165
Validation loss: 1.8456140423333773

Epoch: 5| Step: 8
Training loss: 0.9306246638298035
Validation loss: 1.8440189476936095

Epoch: 5| Step: 9
Training loss: 1.6636508703231812
Validation loss: 1.8602707257834814

Epoch: 5| Step: 10
Training loss: 0.9333741664886475
Validation loss: 1.8367314800139396

Epoch: 520| Step: 0
Training loss: 0.7718270421028137
Validation loss: 1.7970154567431378

Epoch: 5| Step: 1
Training loss: 0.9586232304573059
Validation loss: 1.8523787990693124

Epoch: 5| Step: 2
Training loss: 0.7219985127449036
Validation loss: 1.7636855033136183

Epoch: 5| Step: 3
Training loss: 1.0158060789108276
Validation loss: 1.8501973869980022

Epoch: 5| Step: 4
Training loss: 1.7592451572418213
Validation loss: 1.8184646227026497

Epoch: 5| Step: 5
Training loss: 0.9589412808418274
Validation loss: 1.8575651094477663

Epoch: 5| Step: 6
Training loss: 1.1160635948181152
Validation loss: 1.8980031359580256

Epoch: 5| Step: 7
Training loss: 1.2778561115264893
Validation loss: 1.8574513440491052

Epoch: 5| Step: 8
Training loss: 0.9842561483383179
Validation loss: 1.8243969281514485

Epoch: 5| Step: 9
Training loss: 1.089568018913269
Validation loss: 1.8959609475187076

Epoch: 5| Step: 10
Training loss: 1.4015156030654907
Validation loss: 1.8183769295292516

Epoch: 521| Step: 0
Training loss: 1.553650140762329
Validation loss: 1.816731591378489

Epoch: 5| Step: 1
Training loss: 1.405864953994751
Validation loss: 1.875177162949757

Epoch: 5| Step: 2
Training loss: 1.0555856227874756
Validation loss: 1.818810200178495

Epoch: 5| Step: 3
Training loss: 0.9857749938964844
Validation loss: 1.821754200484163

Epoch: 5| Step: 4
Training loss: 0.9702061414718628
Validation loss: 1.867771448627595

Epoch: 5| Step: 5
Training loss: 0.9608414769172668
Validation loss: 1.830171331282585

Epoch: 5| Step: 6
Training loss: 1.0723330974578857
Validation loss: 1.8188694600136048

Epoch: 5| Step: 7
Training loss: 1.1776660680770874
Validation loss: 1.844408178842196

Epoch: 5| Step: 8
Training loss: 0.9277704358100891
Validation loss: 1.8284353915081228

Epoch: 5| Step: 9
Training loss: 0.7763678431510925
Validation loss: 1.840010090540814

Epoch: 5| Step: 10
Training loss: 0.9402189254760742
Validation loss: 1.79785079597145

Epoch: 522| Step: 0
Training loss: 1.3372398614883423
Validation loss: 1.8501296735578967

Epoch: 5| Step: 1
Training loss: 1.2933942079544067
Validation loss: 1.8718466681818808

Epoch: 5| Step: 2
Training loss: 1.0865676403045654
Validation loss: 1.9015331960493518

Epoch: 5| Step: 3
Training loss: 1.2335641384124756
Validation loss: 1.801724439026207

Epoch: 5| Step: 4
Training loss: 0.735359787940979
Validation loss: 1.825029544932868

Epoch: 5| Step: 5
Training loss: 1.0283340215682983
Validation loss: 1.8700427829578359

Epoch: 5| Step: 6
Training loss: 0.6867560744285583
Validation loss: 1.831115040727841

Epoch: 5| Step: 7
Training loss: 0.9468916058540344
Validation loss: 1.8261944299103112

Epoch: 5| Step: 8
Training loss: 1.2310380935668945
Validation loss: 1.8469537740112634

Epoch: 5| Step: 9
Training loss: 1.1123878955841064
Validation loss: 1.8980037602045203

Epoch: 5| Step: 10
Training loss: 1.3853145837783813
Validation loss: 1.836250162893726

Epoch: 523| Step: 0
Training loss: 1.015202283859253
Validation loss: 1.8868930134721982

Epoch: 5| Step: 1
Training loss: 0.9370732307434082
Validation loss: 1.8650969625801168

Epoch: 5| Step: 2
Training loss: 1.2000755071640015
Validation loss: 1.841371391409187

Epoch: 5| Step: 3
Training loss: 1.1768584251403809
Validation loss: 1.8702488407011955

Epoch: 5| Step: 4
Training loss: 0.7095168828964233
Validation loss: 1.8945856607088478

Epoch: 5| Step: 5
Training loss: 1.4222038984298706
Validation loss: 1.8950216539444462

Epoch: 5| Step: 6
Training loss: 1.3175915479660034
Validation loss: 1.9498139889009538

Epoch: 5| Step: 7
Training loss: 1.0478973388671875
Validation loss: 1.8907372079869753

Epoch: 5| Step: 8
Training loss: 1.5701606273651123
Validation loss: 1.92042923742725

Epoch: 5| Step: 9
Training loss: 0.9644793272018433
Validation loss: 1.8731208937142485

Epoch: 5| Step: 10
Training loss: 0.8236284255981445
Validation loss: 1.836015914076118

Epoch: 524| Step: 0
Training loss: 0.8291465640068054
Validation loss: 1.8032261325467018

Epoch: 5| Step: 1
Training loss: 1.204181432723999
Validation loss: 1.8625502509455527

Epoch: 5| Step: 2
Training loss: 1.0323774814605713
Validation loss: 1.8562533086346042

Epoch: 5| Step: 3
Training loss: 0.7517210245132446
Validation loss: 1.861990459503666

Epoch: 5| Step: 4
Training loss: 1.3926618099212646
Validation loss: 1.8981585066805604

Epoch: 5| Step: 5
Training loss: 1.404441475868225
Validation loss: 1.8331566254297893

Epoch: 5| Step: 6
Training loss: 1.1387343406677246
Validation loss: 1.8904652544247207

Epoch: 5| Step: 7
Training loss: 0.9288187026977539
Validation loss: 1.8513462210214267

Epoch: 5| Step: 8
Training loss: 0.7177168726921082
Validation loss: 1.8880402580384286

Epoch: 5| Step: 9
Training loss: 1.4421088695526123
Validation loss: 1.8320075593968874

Epoch: 5| Step: 10
Training loss: 1.1800934076309204
Validation loss: 1.8630155517208962

Epoch: 525| Step: 0
Training loss: 1.0941864252090454
Validation loss: 1.8264578337310462

Epoch: 5| Step: 1
Training loss: 1.0139648914337158
Validation loss: 1.8502147018268544

Epoch: 5| Step: 2
Training loss: 1.0886633396148682
Validation loss: 1.8957380043563021

Epoch: 5| Step: 3
Training loss: 1.2090827226638794
Validation loss: 1.8404010521468295

Epoch: 5| Step: 4
Training loss: 1.409691572189331
Validation loss: 1.8587058654395483

Epoch: 5| Step: 5
Training loss: 1.316484808921814
Validation loss: 1.8518905011556481

Epoch: 5| Step: 6
Training loss: 1.0669939517974854
Validation loss: 1.9249522686004639

Epoch: 5| Step: 7
Training loss: 0.7449159026145935
Validation loss: 1.864749216264294

Epoch: 5| Step: 8
Training loss: 0.8306280374526978
Validation loss: 1.8335778085134362

Epoch: 5| Step: 9
Training loss: 1.0621607303619385
Validation loss: 1.819051622062601

Epoch: 5| Step: 10
Training loss: 1.0844155550003052
Validation loss: 1.811961753394014

Epoch: 526| Step: 0
Training loss: 1.1725727319717407
Validation loss: 1.8456938202663133

Epoch: 5| Step: 1
Training loss: 1.285742998123169
Validation loss: 1.7894305490678357

Epoch: 5| Step: 2
Training loss: 1.3873625993728638
Validation loss: 1.8727413377454203

Epoch: 5| Step: 3
Training loss: 0.8811022043228149
Validation loss: 1.8416993771829913

Epoch: 5| Step: 4
Training loss: 1.0300198793411255
Validation loss: 1.8250469366709392

Epoch: 5| Step: 5
Training loss: 0.903388500213623
Validation loss: 1.762386445076235

Epoch: 5| Step: 6
Training loss: 1.0188014507293701
Validation loss: 1.8150747411994523

Epoch: 5| Step: 7
Training loss: 0.9270386695861816
Validation loss: 1.8456521239331973

Epoch: 5| Step: 8
Training loss: 1.3072006702423096
Validation loss: 1.8696937702035392

Epoch: 5| Step: 9
Training loss: 1.3082044124603271
Validation loss: 1.9076061633325392

Epoch: 5| Step: 10
Training loss: 0.8048635125160217
Validation loss: 1.9012402103793236

Epoch: 527| Step: 0
Training loss: 0.8782075047492981
Validation loss: 1.8412190996190554

Epoch: 5| Step: 1
Training loss: 1.337522268295288
Validation loss: 1.811102464634885

Epoch: 5| Step: 2
Training loss: 0.5744324922561646
Validation loss: 1.854472473103513

Epoch: 5| Step: 3
Training loss: 1.1577980518341064
Validation loss: 1.8179108442798737

Epoch: 5| Step: 4
Training loss: 1.288894534111023
Validation loss: 1.8526429002003004

Epoch: 5| Step: 5
Training loss: 1.115479588508606
Validation loss: 1.872953898163252

Epoch: 5| Step: 6
Training loss: 1.1853421926498413
Validation loss: 1.846831713953326

Epoch: 5| Step: 7
Training loss: 1.1677263975143433
Validation loss: 1.9097562374607209

Epoch: 5| Step: 8
Training loss: 0.888515830039978
Validation loss: 1.842018053095828

Epoch: 5| Step: 9
Training loss: 1.5292048454284668
Validation loss: 1.7716999361591954

Epoch: 5| Step: 10
Training loss: 1.2247804403305054
Validation loss: 1.833437245379212

Epoch: 528| Step: 0
Training loss: 0.9431209564208984
Validation loss: 1.8966852157346663

Epoch: 5| Step: 1
Training loss: 0.7991946339607239
Validation loss: 1.7910245695421774

Epoch: 5| Step: 2
Training loss: 1.3581771850585938
Validation loss: 1.874661862209279

Epoch: 5| Step: 3
Training loss: 1.145179033279419
Validation loss: 1.8354728003983856

Epoch: 5| Step: 4
Training loss: 1.087563157081604
Validation loss: 1.8284845595718713

Epoch: 5| Step: 5
Training loss: 1.0929138660430908
Validation loss: 1.8249770069635043

Epoch: 5| Step: 6
Training loss: 1.0640770196914673
Validation loss: 1.8938404539579987

Epoch: 5| Step: 7
Training loss: 0.8812497854232788
Validation loss: 1.8558221786252913

Epoch: 5| Step: 8
Training loss: 1.12264084815979
Validation loss: 1.910628249568324

Epoch: 5| Step: 9
Training loss: 1.3452595472335815
Validation loss: 1.8420899170701222

Epoch: 5| Step: 10
Training loss: 1.1132370233535767
Validation loss: 1.8296965463187105

Epoch: 529| Step: 0
Training loss: 1.1812818050384521
Validation loss: 1.8492692132149973

Epoch: 5| Step: 1
Training loss: 1.1080518960952759
Validation loss: 1.8092260078717304

Epoch: 5| Step: 2
Training loss: 1.3229389190673828
Validation loss: 1.7858229683291527

Epoch: 5| Step: 3
Training loss: 1.139258623123169
Validation loss: 1.8523839301960443

Epoch: 5| Step: 4
Training loss: 1.3907482624053955
Validation loss: 1.8346559783463836

Epoch: 5| Step: 5
Training loss: 0.9698964357376099
Validation loss: 1.8430121355159308

Epoch: 5| Step: 6
Training loss: 0.8200163841247559
Validation loss: 1.8482501519623624

Epoch: 5| Step: 7
Training loss: 1.2852703332901
Validation loss: 1.870996686720079

Epoch: 5| Step: 8
Training loss: 0.5331023335456848
Validation loss: 1.8134751730067755

Epoch: 5| Step: 9
Training loss: 0.9487667083740234
Validation loss: 1.816271443520823

Epoch: 5| Step: 10
Training loss: 0.9062358140945435
Validation loss: 1.8090156124484154

Epoch: 530| Step: 0
Training loss: 1.2727290391921997
Validation loss: 1.8477006522558068

Epoch: 5| Step: 1
Training loss: 1.0819604396820068
Validation loss: 1.827240805472097

Epoch: 5| Step: 2
Training loss: 1.2058275938034058
Validation loss: 1.7996766862048899

Epoch: 5| Step: 3
Training loss: 1.049708604812622
Validation loss: 1.8379458688920545

Epoch: 5| Step: 4
Training loss: 0.8962136507034302
Validation loss: 1.8404399220661452

Epoch: 5| Step: 5
Training loss: 1.0948576927185059
Validation loss: 1.8400137373196181

Epoch: 5| Step: 6
Training loss: 0.6971513628959656
Validation loss: 1.8591899551371092

Epoch: 5| Step: 7
Training loss: 1.5333198308944702
Validation loss: 1.8744716900651173

Epoch: 5| Step: 8
Training loss: 1.27274751663208
Validation loss: 1.8522798527953446

Epoch: 5| Step: 9
Training loss: 1.3816235065460205
Validation loss: 1.8044514309975408

Epoch: 5| Step: 10
Training loss: 0.697925329208374
Validation loss: 1.8508479954094015

Epoch: 531| Step: 0
Training loss: 1.4791197776794434
Validation loss: 1.836212306894282

Epoch: 5| Step: 1
Training loss: 1.1440422534942627
Validation loss: 1.8615434246678506

Epoch: 5| Step: 2
Training loss: 1.0467572212219238
Validation loss: 1.8537897602204354

Epoch: 5| Step: 3
Training loss: 0.9723386764526367
Validation loss: 1.8486901380682503

Epoch: 5| Step: 4
Training loss: 1.1444895267486572
Validation loss: 1.8950074795753724

Epoch: 5| Step: 5
Training loss: 0.7668102979660034
Validation loss: 1.8639368972470682

Epoch: 5| Step: 6
Training loss: 1.0782039165496826
Validation loss: 1.843804072308284

Epoch: 5| Step: 7
Training loss: 0.8627177476882935
Validation loss: 1.8693544351926414

Epoch: 5| Step: 8
Training loss: 1.2519855499267578
Validation loss: 1.9418967129081808

Epoch: 5| Step: 9
Training loss: 1.104451298713684
Validation loss: 1.8266391741332186

Epoch: 5| Step: 10
Training loss: 0.9650307893753052
Validation loss: 1.8847264397528865

Epoch: 532| Step: 0
Training loss: 1.0981613397598267
Validation loss: 1.8360835198433167

Epoch: 5| Step: 1
Training loss: 1.1421291828155518
Validation loss: 1.816945933526562

Epoch: 5| Step: 2
Training loss: 1.7936656475067139
Validation loss: 1.8790164327108732

Epoch: 5| Step: 3
Training loss: 0.938761830329895
Validation loss: 1.8146453378021077

Epoch: 5| Step: 4
Training loss: 1.0880110263824463
Validation loss: 1.8483294299853745

Epoch: 5| Step: 5
Training loss: 1.1594024896621704
Validation loss: 1.859612814841732

Epoch: 5| Step: 6
Training loss: 0.8943337202072144
Validation loss: 1.8376919864326395

Epoch: 5| Step: 7
Training loss: 0.9068662524223328
Validation loss: 1.8284372373293805

Epoch: 5| Step: 8
Training loss: 0.9900659322738647
Validation loss: 1.9084401310131114

Epoch: 5| Step: 9
Training loss: 0.8233287930488586
Validation loss: 1.8207702290627263

Epoch: 5| Step: 10
Training loss: 1.0069050788879395
Validation loss: 1.8040758217534711

Epoch: 533| Step: 0
Training loss: 0.5187249183654785
Validation loss: 1.7908793623729418

Epoch: 5| Step: 1
Training loss: 1.0954217910766602
Validation loss: 1.8093366187105897

Epoch: 5| Step: 2
Training loss: 0.905309796333313
Validation loss: 1.845395585542084

Epoch: 5| Step: 3
Training loss: 0.9868318438529968
Validation loss: 1.9035432120805145

Epoch: 5| Step: 4
Training loss: 0.8515986204147339
Validation loss: 1.8440884236366517

Epoch: 5| Step: 5
Training loss: 1.027226209640503
Validation loss: 1.8139483172406432

Epoch: 5| Step: 6
Training loss: 1.1123268604278564
Validation loss: 1.8082310307410456

Epoch: 5| Step: 7
Training loss: 1.6957051753997803
Validation loss: 1.8363390199599727

Epoch: 5| Step: 8
Training loss: 1.0021336078643799
Validation loss: 1.8540998992099558

Epoch: 5| Step: 9
Training loss: 1.1177818775177002
Validation loss: 1.8206590067955755

Epoch: 5| Step: 10
Training loss: 1.3625749349594116
Validation loss: 1.7792009512583415

Epoch: 534| Step: 0
Training loss: 1.0757633447647095
Validation loss: 1.8202075407069216

Epoch: 5| Step: 1
Training loss: 0.9995023608207703
Validation loss: 1.8703075249989827

Epoch: 5| Step: 2
Training loss: 0.9782659411430359
Validation loss: 1.8265219990925123

Epoch: 5| Step: 3
Training loss: 1.0558563470840454
Validation loss: 1.8363081050175492

Epoch: 5| Step: 4
Training loss: 1.244094967842102
Validation loss: 1.8583412657501877

Epoch: 5| Step: 5
Training loss: 1.0197480916976929
Validation loss: 1.8284881140596123

Epoch: 5| Step: 6
Training loss: 1.0064036846160889
Validation loss: 1.820887706613028

Epoch: 5| Step: 7
Training loss: 1.4064304828643799
Validation loss: 1.8341372038728447

Epoch: 5| Step: 8
Training loss: 0.8058745265007019
Validation loss: 1.8600741176195041

Epoch: 5| Step: 9
Training loss: 1.319275140762329
Validation loss: 1.8393103589293778

Epoch: 5| Step: 10
Training loss: 0.8949306607246399
Validation loss: 1.770255696388983

Epoch: 535| Step: 0
Training loss: 0.9271335601806641
Validation loss: 1.8848927533754738

Epoch: 5| Step: 1
Training loss: 0.9216808080673218
Validation loss: 1.8558630353660994

Epoch: 5| Step: 2
Training loss: 0.8127025365829468
Validation loss: 1.824291172847953

Epoch: 5| Step: 3
Training loss: 1.13020920753479
Validation loss: 1.8677363062417636

Epoch: 5| Step: 4
Training loss: 1.3528451919555664
Validation loss: 1.8076919150608841

Epoch: 5| Step: 5
Training loss: 1.004472017288208
Validation loss: 1.8544497797566075

Epoch: 5| Step: 6
Training loss: 0.9642454981803894
Validation loss: 1.8625349152472712

Epoch: 5| Step: 7
Training loss: 1.6113910675048828
Validation loss: 1.8696248992796867

Epoch: 5| Step: 8
Training loss: 0.9526157379150391
Validation loss: 1.8825115503803376

Epoch: 5| Step: 9
Training loss: 0.7904967069625854
Validation loss: 1.8211124404784171

Epoch: 5| Step: 10
Training loss: 1.1453466415405273
Validation loss: 1.8705979085737658

Epoch: 536| Step: 0
Training loss: 1.3269731998443604
Validation loss: 1.8226379912386659

Epoch: 5| Step: 1
Training loss: 0.71712726354599
Validation loss: 1.843126299560711

Epoch: 5| Step: 2
Training loss: 1.30736243724823
Validation loss: 1.858801253380314

Epoch: 5| Step: 3
Training loss: 0.7671104669570923
Validation loss: 1.7992849196157148

Epoch: 5| Step: 4
Training loss: 1.1803476810455322
Validation loss: 1.8709986286778604

Epoch: 5| Step: 5
Training loss: 1.2203561067581177
Validation loss: 1.813411125572779

Epoch: 5| Step: 6
Training loss: 1.3252664804458618
Validation loss: 1.825293384572511

Epoch: 5| Step: 7
Training loss: 0.9013561010360718
Validation loss: 1.8367300315569806

Epoch: 5| Step: 8
Training loss: 1.01615571975708
Validation loss: 1.8176736600937382

Epoch: 5| Step: 9
Training loss: 0.9184558987617493
Validation loss: 1.8472391597686275

Epoch: 5| Step: 10
Training loss: 1.2743836641311646
Validation loss: 1.7791721718285674

Epoch: 537| Step: 0
Training loss: 0.9694870114326477
Validation loss: 1.8469750355648737

Epoch: 5| Step: 1
Training loss: 1.0318869352340698
Validation loss: 1.8351877145869757

Epoch: 5| Step: 2
Training loss: 0.9805504083633423
Validation loss: 1.861011146217264

Epoch: 5| Step: 3
Training loss: 1.3443340063095093
Validation loss: 1.8599936705763622

Epoch: 5| Step: 4
Training loss: 0.9266462326049805
Validation loss: 1.8582348105727986

Epoch: 5| Step: 5
Training loss: 1.1817104816436768
Validation loss: 1.8325337312554801

Epoch: 5| Step: 6
Training loss: 1.1740949153900146
Validation loss: 1.8635103446181103

Epoch: 5| Step: 7
Training loss: 0.9688171148300171
Validation loss: 1.8586173634375296

Epoch: 5| Step: 8
Training loss: 1.0756205320358276
Validation loss: 1.8143213910441245

Epoch: 5| Step: 9
Training loss: 1.0418704748153687
Validation loss: 1.8761054854239188

Epoch: 5| Step: 10
Training loss: 1.3932044506072998
Validation loss: 1.872032093745406

Epoch: 538| Step: 0
Training loss: 0.803449809551239
Validation loss: 1.8227911995303245

Epoch: 5| Step: 1
Training loss: 1.449646234512329
Validation loss: 1.8904024516382525

Epoch: 5| Step: 2
Training loss: 1.165158987045288
Validation loss: 1.8349563896015126

Epoch: 5| Step: 3
Training loss: 0.8217099905014038
Validation loss: 1.8312214753961051

Epoch: 5| Step: 4
Training loss: 0.9473434686660767
Validation loss: 1.859709470502792

Epoch: 5| Step: 5
Training loss: 1.12885582447052
Validation loss: 1.8420882917219592

Epoch: 5| Step: 6
Training loss: 1.3449270725250244
Validation loss: 1.7686286011049825

Epoch: 5| Step: 7
Training loss: 1.1370317935943604
Validation loss: 1.7872048539500083

Epoch: 5| Step: 8
Training loss: 1.072623372077942
Validation loss: 1.8326433704745384

Epoch: 5| Step: 9
Training loss: 1.1557629108428955
Validation loss: 1.8150898743701238

Epoch: 5| Step: 10
Training loss: 1.1810810565948486
Validation loss: 1.7738943099975586

Epoch: 539| Step: 0
Training loss: 1.4311742782592773
Validation loss: 1.841562130117929

Epoch: 5| Step: 1
Training loss: 1.3278809785842896
Validation loss: 1.8109240608830606

Epoch: 5| Step: 2
Training loss: 0.9098213315010071
Validation loss: 1.8488665883259108

Epoch: 5| Step: 3
Training loss: 0.9374703168869019
Validation loss: 1.8627046077482161

Epoch: 5| Step: 4
Training loss: 1.4120259284973145
Validation loss: 1.8255741814131379

Epoch: 5| Step: 5
Training loss: 1.2021310329437256
Validation loss: 1.8206581505396033

Epoch: 5| Step: 6
Training loss: 1.0241304636001587
Validation loss: 1.852138993560627

Epoch: 5| Step: 7
Training loss: 0.6958364248275757
Validation loss: 1.8387320041656494

Epoch: 5| Step: 8
Training loss: 0.8006450533866882
Validation loss: 1.825850171427573

Epoch: 5| Step: 9
Training loss: 1.1208090782165527
Validation loss: 1.823788026327728

Epoch: 5| Step: 10
Training loss: 1.0077886581420898
Validation loss: 1.8431388844725907

Epoch: 540| Step: 0
Training loss: 0.811077892780304
Validation loss: 1.8488774709804083

Epoch: 5| Step: 1
Training loss: 1.1049714088439941
Validation loss: 1.8610918996154622

Epoch: 5| Step: 2
Training loss: 1.0461941957473755
Validation loss: 1.8355160220976798

Epoch: 5| Step: 3
Training loss: 1.5969746112823486
Validation loss: 1.8150245822885984

Epoch: 5| Step: 4
Training loss: 0.669601321220398
Validation loss: 1.8440162443345594

Epoch: 5| Step: 5
Training loss: 0.7343636751174927
Validation loss: 1.8239711856329313

Epoch: 5| Step: 6
Training loss: 1.1492226123809814
Validation loss: 1.77654783187374

Epoch: 5| Step: 7
Training loss: 0.8933930397033691
Validation loss: 1.8118772019622147

Epoch: 5| Step: 8
Training loss: 1.3455957174301147
Validation loss: 1.8058490355809529

Epoch: 5| Step: 9
Training loss: 0.9189313650131226
Validation loss: 1.8262760677645284

Epoch: 5| Step: 10
Training loss: 1.2075753211975098
Validation loss: 1.878518060971332

Epoch: 541| Step: 0
Training loss: 1.6323320865631104
Validation loss: 1.8854274852301485

Epoch: 5| Step: 1
Training loss: 1.078857660293579
Validation loss: 1.8236300458190262

Epoch: 5| Step: 2
Training loss: 1.4301750659942627
Validation loss: 1.813642931240861

Epoch: 5| Step: 3
Training loss: 1.0346031188964844
Validation loss: 1.8348579727193361

Epoch: 5| Step: 4
Training loss: 1.0934808254241943
Validation loss: 1.7792278912759596

Epoch: 5| Step: 5
Training loss: 0.6422889828681946
Validation loss: 1.785120612831526

Epoch: 5| Step: 6
Training loss: 0.9505681991577148
Validation loss: 1.8545226384234685

Epoch: 5| Step: 7
Training loss: 0.9565544128417969
Validation loss: 1.7842394767269012

Epoch: 5| Step: 8
Training loss: 0.9862436056137085
Validation loss: 1.795922210139613

Epoch: 5| Step: 9
Training loss: 0.8973916172981262
Validation loss: 1.8627317874662337

Epoch: 5| Step: 10
Training loss: 0.8566145300865173
Validation loss: 1.8635372577175018

Epoch: 542| Step: 0
Training loss: 0.6318393349647522
Validation loss: 1.8625786407019502

Epoch: 5| Step: 1
Training loss: 0.8619910478591919
Validation loss: 1.871245607253044

Epoch: 5| Step: 2
Training loss: 1.3300079107284546
Validation loss: 1.8252515459573397

Epoch: 5| Step: 3
Training loss: 1.3234279155731201
Validation loss: 1.8681561011140064

Epoch: 5| Step: 4
Training loss: 1.1046922206878662
Validation loss: 1.8187379529399257

Epoch: 5| Step: 5
Training loss: 0.914913535118103
Validation loss: 1.8997089286004343

Epoch: 5| Step: 6
Training loss: 1.4336825609207153
Validation loss: 1.8181141832823395

Epoch: 5| Step: 7
Training loss: 0.866765022277832
Validation loss: 1.8365643972991614

Epoch: 5| Step: 8
Training loss: 1.1408336162567139
Validation loss: 1.8403255747210594

Epoch: 5| Step: 9
Training loss: 1.2326911687850952
Validation loss: 1.908500507313718

Epoch: 5| Step: 10
Training loss: 0.9210282564163208
Validation loss: 1.78107084766511

Epoch: 543| Step: 0
Training loss: 1.5951852798461914
Validation loss: 1.8186939890666673

Epoch: 5| Step: 1
Training loss: 0.9991298913955688
Validation loss: 1.8459359433061333

Epoch: 5| Step: 2
Training loss: 1.2717281579971313
Validation loss: 1.7863062940618044

Epoch: 5| Step: 3
Training loss: 0.8080055117607117
Validation loss: 1.8881502356580508

Epoch: 5| Step: 4
Training loss: 1.0518680810928345
Validation loss: 1.8213461534951323

Epoch: 5| Step: 5
Training loss: 0.8950129747390747
Validation loss: 1.8806262823843187

Epoch: 5| Step: 6
Training loss: 1.1787779331207275
Validation loss: 1.8249246176852976

Epoch: 5| Step: 7
Training loss: 0.916854977607727
Validation loss: 1.8779636890657487

Epoch: 5| Step: 8
Training loss: 1.2233545780181885
Validation loss: 1.8260222006869573

Epoch: 5| Step: 9
Training loss: 1.0129810571670532
Validation loss: 1.7954618982089463

Epoch: 5| Step: 10
Training loss: 0.8632138967514038
Validation loss: 1.8598846299673921

Epoch: 544| Step: 0
Training loss: 0.9464647173881531
Validation loss: 1.8311286228959278

Epoch: 5| Step: 1
Training loss: 0.712531328201294
Validation loss: 1.823225103398805

Epoch: 5| Step: 2
Training loss: 0.8968990445137024
Validation loss: 1.8667191126013314

Epoch: 5| Step: 3
Training loss: 0.7558981776237488
Validation loss: 1.8459379250003445

Epoch: 5| Step: 4
Training loss: 1.484383463859558
Validation loss: 1.828773767717423

Epoch: 5| Step: 5
Training loss: 1.1591063737869263
Validation loss: 1.8295754207077848

Epoch: 5| Step: 6
Training loss: 1.2058998346328735
Validation loss: 1.7719427590729089

Epoch: 5| Step: 7
Training loss: 1.2516529560089111
Validation loss: 1.8340002029172835

Epoch: 5| Step: 8
Training loss: 1.2293444871902466
Validation loss: 1.877808496516238

Epoch: 5| Step: 9
Training loss: 1.2647285461425781
Validation loss: 1.9083855562312628

Epoch: 5| Step: 10
Training loss: 1.3366023302078247
Validation loss: 1.8807855267678537

Epoch: 545| Step: 0
Training loss: 1.0282988548278809
Validation loss: 1.8126194771899973

Epoch: 5| Step: 1
Training loss: 0.8875544667243958
Validation loss: 1.8896238444953837

Epoch: 5| Step: 2
Training loss: 1.0272188186645508
Validation loss: 1.8297939492810158

Epoch: 5| Step: 3
Training loss: 0.9687209129333496
Validation loss: 1.8299440465947634

Epoch: 5| Step: 4
Training loss: 1.3179194927215576
Validation loss: 1.82936776966177

Epoch: 5| Step: 5
Training loss: 1.2614116668701172
Validation loss: 1.819262755814419

Epoch: 5| Step: 6
Training loss: 1.0603506565093994
Validation loss: 1.8501429275799823

Epoch: 5| Step: 7
Training loss: 1.4121131896972656
Validation loss: 1.8241695998817362

Epoch: 5| Step: 8
Training loss: 1.124396562576294
Validation loss: 1.8835180844030073

Epoch: 5| Step: 9
Training loss: 0.5789719223976135
Validation loss: 1.8450807115083099

Epoch: 5| Step: 10
Training loss: 1.1057425737380981
Validation loss: 1.8125659637553717

Epoch: 546| Step: 0
Training loss: 1.252471685409546
Validation loss: 1.8367373251145886

Epoch: 5| Step: 1
Training loss: 0.5653937458992004
Validation loss: 1.8253555861852502

Epoch: 5| Step: 2
Training loss: 1.294708013534546
Validation loss: 1.8285915518319735

Epoch: 5| Step: 3
Training loss: 0.7073667049407959
Validation loss: 1.8106385405345629

Epoch: 5| Step: 4
Training loss: 0.891732394695282
Validation loss: 1.8020672298246814

Epoch: 5| Step: 5
Training loss: 0.8871825933456421
Validation loss: 1.8815627713357248

Epoch: 5| Step: 6
Training loss: 1.5622763633728027
Validation loss: 1.9127251614806473

Epoch: 5| Step: 7
Training loss: 0.8870105743408203
Validation loss: 1.8535084391152987

Epoch: 5| Step: 8
Training loss: 1.0395654439926147
Validation loss: 1.8581661844766268

Epoch: 5| Step: 9
Training loss: 1.2088344097137451
Validation loss: 1.832661783823403

Epoch: 5| Step: 10
Training loss: 1.4813768863677979
Validation loss: 1.8258225212814987

Epoch: 547| Step: 0
Training loss: 1.3257948160171509
Validation loss: 1.8601285155101488

Epoch: 5| Step: 1
Training loss: 1.116166114807129
Validation loss: 1.8722877335804764

Epoch: 5| Step: 2
Training loss: 0.8481696248054504
Validation loss: 1.8629991431390085

Epoch: 5| Step: 3
Training loss: 1.1907541751861572
Validation loss: 1.8401986437459146

Epoch: 5| Step: 4
Training loss: 0.7389472126960754
Validation loss: 1.809264131771621

Epoch: 5| Step: 5
Training loss: 0.9776580929756165
Validation loss: 1.8072327247229956

Epoch: 5| Step: 6
Training loss: 1.1738731861114502
Validation loss: 1.853440643638693

Epoch: 5| Step: 7
Training loss: 1.2238860130310059
Validation loss: 1.8296308318773906

Epoch: 5| Step: 8
Training loss: 1.5100399255752563
Validation loss: 1.837734660794658

Epoch: 5| Step: 9
Training loss: 1.0939452648162842
Validation loss: 1.8366111581043532

Epoch: 5| Step: 10
Training loss: 0.7308429479598999
Validation loss: 1.8059582915357364

Epoch: 548| Step: 0
Training loss: 1.4758936166763306
Validation loss: 1.841251939855596

Epoch: 5| Step: 1
Training loss: 1.2395459413528442
Validation loss: 1.8374220709646902

Epoch: 5| Step: 2
Training loss: 0.817558765411377
Validation loss: 1.8416278105910107

Epoch: 5| Step: 3
Training loss: 1.7314847707748413
Validation loss: 1.823538980176372

Epoch: 5| Step: 4
Training loss: 1.0106946229934692
Validation loss: 1.8563824802316644

Epoch: 5| Step: 5
Training loss: 1.0827505588531494
Validation loss: 1.8137217337085354

Epoch: 5| Step: 6
Training loss: 0.7625635862350464
Validation loss: 1.84720439680161

Epoch: 5| Step: 7
Training loss: 0.919634997844696
Validation loss: 1.823414876896848

Epoch: 5| Step: 8
Training loss: 0.7963701486587524
Validation loss: 1.8535807376266809

Epoch: 5| Step: 9
Training loss: 0.9449464082717896
Validation loss: 1.8407819091632802

Epoch: 5| Step: 10
Training loss: 0.7254884243011475
Validation loss: 1.7951791119831864

Epoch: 549| Step: 0
Training loss: 1.285750389099121
Validation loss: 1.8234303817954114

Epoch: 5| Step: 1
Training loss: 1.2813141345977783
Validation loss: 1.7844584962373138

Epoch: 5| Step: 2
Training loss: 1.2483463287353516
Validation loss: 1.8051294972819667

Epoch: 5| Step: 3
Training loss: 0.8742977380752563
Validation loss: 1.8615839455717353

Epoch: 5| Step: 4
Training loss: 0.8565523028373718
Validation loss: 1.8152049356891262

Epoch: 5| Step: 5
Training loss: 1.1200428009033203
Validation loss: 1.8489701453075613

Epoch: 5| Step: 6
Training loss: 0.8387222290039062
Validation loss: 1.8081185971536944

Epoch: 5| Step: 7
Training loss: 1.2391579151153564
Validation loss: 1.8505887344319334

Epoch: 5| Step: 8
Training loss: 0.8065791130065918
Validation loss: 1.809355693478738

Epoch: 5| Step: 9
Training loss: 1.0720634460449219
Validation loss: 1.8685686972833448

Epoch: 5| Step: 10
Training loss: 1.2088537216186523
Validation loss: 1.845102220453242

Epoch: 550| Step: 0
Training loss: 0.9484724998474121
Validation loss: 1.8674950548397597

Epoch: 5| Step: 1
Training loss: 1.0256997346878052
Validation loss: 1.8478719649776336

Epoch: 5| Step: 2
Training loss: 0.9959198236465454
Validation loss: 1.8389054524001254

Epoch: 5| Step: 3
Training loss: 1.3075549602508545
Validation loss: 1.8870520412280996

Epoch: 5| Step: 4
Training loss: 1.4349091053009033
Validation loss: 1.8266488236765708

Epoch: 5| Step: 5
Training loss: 0.9304357767105103
Validation loss: 1.8192097858716083

Epoch: 5| Step: 6
Training loss: 1.0367790460586548
Validation loss: 1.8043532512521232

Epoch: 5| Step: 7
Training loss: 1.232277512550354
Validation loss: 1.7914458808078562

Epoch: 5| Step: 8
Training loss: 0.7394717931747437
Validation loss: 1.7416654171482209

Epoch: 5| Step: 9
Training loss: 1.1178653240203857
Validation loss: 1.7837867890634844

Epoch: 5| Step: 10
Training loss: 0.8895020484924316
Validation loss: 1.8521122727342831

Epoch: 551| Step: 0
Training loss: 0.9678889513015747
Validation loss: 1.7978074242991786

Epoch: 5| Step: 1
Training loss: 0.544818639755249
Validation loss: 1.784624222786196

Epoch: 5| Step: 2
Training loss: 0.8023872375488281
Validation loss: 1.803852233835446

Epoch: 5| Step: 3
Training loss: 1.4452919960021973
Validation loss: 1.845936941844161

Epoch: 5| Step: 4
Training loss: 0.9796199798583984
Validation loss: 1.8636886265970045

Epoch: 5| Step: 5
Training loss: 1.0404016971588135
Validation loss: 1.84207929847061

Epoch: 5| Step: 6
Training loss: 1.3257367610931396
Validation loss: 1.8179001115983533

Epoch: 5| Step: 7
Training loss: 1.2337777614593506
Validation loss: 1.816241947553491

Epoch: 5| Step: 8
Training loss: 0.8093496561050415
Validation loss: 1.8276340910183486

Epoch: 5| Step: 9
Training loss: 0.8525644540786743
Validation loss: 1.8325225960823797

Epoch: 5| Step: 10
Training loss: 1.3098301887512207
Validation loss: 1.8027796642754668

Epoch: 552| Step: 0
Training loss: 0.924126923084259
Validation loss: 1.8159875113476989

Epoch: 5| Step: 1
Training loss: 1.2175625562667847
Validation loss: 1.84631089497638

Epoch: 5| Step: 2
Training loss: 0.8671428561210632
Validation loss: 1.7966397680262083

Epoch: 5| Step: 3
Training loss: 0.7265941500663757
Validation loss: 1.8284460242076586

Epoch: 5| Step: 4
Training loss: 0.9969469308853149
Validation loss: 1.8497771037522184

Epoch: 5| Step: 5
Training loss: 0.9332932233810425
Validation loss: 1.7582410868778025

Epoch: 5| Step: 6
Training loss: 1.2270567417144775
Validation loss: 1.8592093734331028

Epoch: 5| Step: 7
Training loss: 0.8186159133911133
Validation loss: 1.8195103663270191

Epoch: 5| Step: 8
Training loss: 0.7240504622459412
Validation loss: 1.76341660048372

Epoch: 5| Step: 9
Training loss: 1.5616400241851807
Validation loss: 1.8445550767324304

Epoch: 5| Step: 10
Training loss: 1.4241667985916138
Validation loss: 1.8247965561446322

Epoch: 553| Step: 0
Training loss: 1.226096272468567
Validation loss: 1.8419280718731623

Epoch: 5| Step: 1
Training loss: 1.0062204599380493
Validation loss: 1.8162737174700665

Epoch: 5| Step: 2
Training loss: 1.4042854309082031
Validation loss: 1.8107570114956106

Epoch: 5| Step: 3
Training loss: 1.4953515529632568
Validation loss: 1.8344960853617678

Epoch: 5| Step: 4
Training loss: 0.8067271113395691
Validation loss: 1.834030141112625

Epoch: 5| Step: 5
Training loss: 1.2179416418075562
Validation loss: 1.8268077963141984

Epoch: 5| Step: 6
Training loss: 0.9490894079208374
Validation loss: 1.763728605803623

Epoch: 5| Step: 7
Training loss: 1.0828135013580322
Validation loss: 1.8613428223517634

Epoch: 5| Step: 8
Training loss: 0.597911536693573
Validation loss: 1.840180976416475

Epoch: 5| Step: 9
Training loss: 0.5741360783576965
Validation loss: 1.8414990748128583

Epoch: 5| Step: 10
Training loss: 0.9918034672737122
Validation loss: 1.7781162287599297

Epoch: 554| Step: 0
Training loss: 1.0296658277511597
Validation loss: 1.800755528993504

Epoch: 5| Step: 1
Training loss: 1.1050198078155518
Validation loss: 1.812627943613196

Epoch: 5| Step: 2
Training loss: 0.8797212839126587
Validation loss: 1.808148367430574

Epoch: 5| Step: 3
Training loss: 0.8785876035690308
Validation loss: 1.826351414444626

Epoch: 5| Step: 4
Training loss: 1.1676390171051025
Validation loss: 1.8124497910981536

Epoch: 5| Step: 5
Training loss: 1.7325235605239868
Validation loss: 1.7729938607062063

Epoch: 5| Step: 6
Training loss: 1.2466812133789062
Validation loss: 1.8510024547576904

Epoch: 5| Step: 7
Training loss: 0.8632439374923706
Validation loss: 1.8062105665924728

Epoch: 5| Step: 8
Training loss: 1.1865193843841553
Validation loss: 1.829973679716869

Epoch: 5| Step: 9
Training loss: 0.6471835970878601
Validation loss: 1.820369792240922

Epoch: 5| Step: 10
Training loss: 0.8231503367424011
Validation loss: 1.8293995395783456

Epoch: 555| Step: 0
Training loss: 1.436844825744629
Validation loss: 1.862710052920926

Epoch: 5| Step: 1
Training loss: 0.9264740943908691
Validation loss: 1.8803230024153186

Epoch: 5| Step: 2
Training loss: 1.1858137845993042
Validation loss: 1.8285248869208879

Epoch: 5| Step: 3
Training loss: 1.1023316383361816
Validation loss: 1.8364696400139922

Epoch: 5| Step: 4
Training loss: 1.0536222457885742
Validation loss: 1.829729789046831

Epoch: 5| Step: 5
Training loss: 1.057829737663269
Validation loss: 1.8172202328199982

Epoch: 5| Step: 6
Training loss: 1.0146595239639282
Validation loss: 1.7976639655328566

Epoch: 5| Step: 7
Training loss: 0.6831725239753723
Validation loss: 1.865399532420661

Epoch: 5| Step: 8
Training loss: 1.1670567989349365
Validation loss: 1.8584861627189062

Epoch: 5| Step: 9
Training loss: 0.7855709791183472
Validation loss: 1.8023834959153207

Epoch: 5| Step: 10
Training loss: 1.0722808837890625
Validation loss: 1.8486643939889886

Epoch: 556| Step: 0
Training loss: 1.1045587062835693
Validation loss: 1.8048542981506677

Epoch: 5| Step: 1
Training loss: 1.1832001209259033
Validation loss: 1.819942844170396

Epoch: 5| Step: 2
Training loss: 0.8139768838882446
Validation loss: 1.820744522156254

Epoch: 5| Step: 3
Training loss: 1.1033607721328735
Validation loss: 1.8372365710555867

Epoch: 5| Step: 4
Training loss: 0.9519044160842896
Validation loss: 1.7795808687004993

Epoch: 5| Step: 5
Training loss: 0.6262279152870178
Validation loss: 1.748290188850895

Epoch: 5| Step: 6
Training loss: 1.4499372243881226
Validation loss: 1.7497194595234369

Epoch: 5| Step: 7
Training loss: 1.2245945930480957
Validation loss: 1.8618104342491395

Epoch: 5| Step: 8
Training loss: 1.0855705738067627
Validation loss: 1.8635501207843903

Epoch: 5| Step: 9
Training loss: 0.7627426385879517
Validation loss: 1.772727019043379

Epoch: 5| Step: 10
Training loss: 1.0071548223495483
Validation loss: 1.8078799145196074

Epoch: 557| Step: 0
Training loss: 1.020154356956482
Validation loss: 1.8422322914164553

Epoch: 5| Step: 1
Training loss: 0.904682993888855
Validation loss: 1.864561564178877

Epoch: 5| Step: 2
Training loss: 1.597071886062622
Validation loss: 1.807086101142309

Epoch: 5| Step: 3
Training loss: 0.828557014465332
Validation loss: 1.7654785206240993

Epoch: 5| Step: 4
Training loss: 0.7784910202026367
Validation loss: 1.7886277450028287

Epoch: 5| Step: 5
Training loss: 0.8823772668838501
Validation loss: 1.8265900714423067

Epoch: 5| Step: 6
Training loss: 0.8452919125556946
Validation loss: 1.847272265341974

Epoch: 5| Step: 7
Training loss: 1.089167594909668
Validation loss: 1.8055760296442176

Epoch: 5| Step: 8
Training loss: 1.0140748023986816
Validation loss: 1.819867653231467

Epoch: 5| Step: 9
Training loss: 1.3180811405181885
Validation loss: 1.7567203121800576

Epoch: 5| Step: 10
Training loss: 1.2632153034210205
Validation loss: 1.8253901825156262

Epoch: 558| Step: 0
Training loss: 0.6508013010025024
Validation loss: 1.816102671366866

Epoch: 5| Step: 1
Training loss: 0.8358016014099121
Validation loss: 1.8383347693309988

Epoch: 5| Step: 2
Training loss: 1.4161046743392944
Validation loss: 1.807041875777706

Epoch: 5| Step: 3
Training loss: 0.9905177354812622
Validation loss: 1.8237748710058068

Epoch: 5| Step: 4
Training loss: 0.7285781502723694
Validation loss: 1.7963962849750315

Epoch: 5| Step: 5
Training loss: 1.0902453660964966
Validation loss: 1.8357974047301917

Epoch: 5| Step: 6
Training loss: 1.0566269159317017
Validation loss: 1.8316217237903225

Epoch: 5| Step: 7
Training loss: 1.2689536809921265
Validation loss: 1.8677329094179216

Epoch: 5| Step: 8
Training loss: 0.871538519859314
Validation loss: 1.802625217745381

Epoch: 5| Step: 9
Training loss: 0.6670887470245361
Validation loss: 1.8741775776750298

Epoch: 5| Step: 10
Training loss: 1.426328420639038
Validation loss: 1.8279078160562823

Epoch: 559| Step: 0
Training loss: 1.0205280780792236
Validation loss: 1.8029813048660115

Epoch: 5| Step: 1
Training loss: 1.3942333459854126
Validation loss: 1.7830091420040335

Epoch: 5| Step: 2
Training loss: 1.3091325759887695
Validation loss: 1.7900228538820822

Epoch: 5| Step: 3
Training loss: 1.1396453380584717
Validation loss: 1.8400033545750443

Epoch: 5| Step: 4
Training loss: 0.6751716136932373
Validation loss: 1.8239270692230554

Epoch: 5| Step: 5
Training loss: 1.3907690048217773
Validation loss: 1.7621039664873512

Epoch: 5| Step: 6
Training loss: 0.98028165102005
Validation loss: 1.8332486280830957

Epoch: 5| Step: 7
Training loss: 1.0552204847335815
Validation loss: 1.834009966542644

Epoch: 5| Step: 8
Training loss: 0.7772711515426636
Validation loss: 1.8084400264165734

Epoch: 5| Step: 9
Training loss: 0.7865537405014038
Validation loss: 1.8592403857938704

Epoch: 5| Step: 10
Training loss: 0.8551632165908813
Validation loss: 1.8109909142217329

Epoch: 560| Step: 0
Training loss: 1.0991443395614624
Validation loss: 1.8013103559453

Epoch: 5| Step: 1
Training loss: 0.8873705863952637
Validation loss: 1.8545203029468496

Epoch: 5| Step: 2
Training loss: 0.9633623361587524
Validation loss: 1.799796022394652

Epoch: 5| Step: 3
Training loss: 1.162760615348816
Validation loss: 1.821485298936085

Epoch: 5| Step: 4
Training loss: 0.8496004343032837
Validation loss: 1.784235256974415

Epoch: 5| Step: 5
Training loss: 0.9156651496887207
Validation loss: 1.7924520020843835

Epoch: 5| Step: 6
Training loss: 1.559537649154663
Validation loss: 1.867122680910172

Epoch: 5| Step: 7
Training loss: 1.0623505115509033
Validation loss: 1.8491746443574146

Epoch: 5| Step: 8
Training loss: 0.9323847889900208
Validation loss: 1.795595976614183

Epoch: 5| Step: 9
Training loss: 1.1240992546081543
Validation loss: 1.8717563408677296

Epoch: 5| Step: 10
Training loss: 0.5091630816459656
Validation loss: 1.8520529167626494

Epoch: 561| Step: 0
Training loss: 1.2939045429229736
Validation loss: 1.8436062656423098

Epoch: 5| Step: 1
Training loss: 0.9967204928398132
Validation loss: 1.8288957444570397

Epoch: 5| Step: 2
Training loss: 1.1324161291122437
Validation loss: 1.8689138376584618

Epoch: 5| Step: 3
Training loss: 0.6117182970046997
Validation loss: 1.8240209112885177

Epoch: 5| Step: 4
Training loss: 1.1959311962127686
Validation loss: 1.8436953047270417

Epoch: 5| Step: 5
Training loss: 0.9601923227310181
Validation loss: 1.861776263483109

Epoch: 5| Step: 6
Training loss: 0.9238485097885132
Validation loss: 1.8148342729896627

Epoch: 5| Step: 7
Training loss: 1.1182657480239868
Validation loss: 1.7978488142772386

Epoch: 5| Step: 8
Training loss: 0.956622302532196
Validation loss: 1.8117436491033083

Epoch: 5| Step: 9
Training loss: 1.1170084476470947
Validation loss: 1.8051679557369602

Epoch: 5| Step: 10
Training loss: 1.1595536470413208
Validation loss: 1.8011161742671844

Epoch: 562| Step: 0
Training loss: 0.8396121263504028
Validation loss: 1.8156810627188733

Epoch: 5| Step: 1
Training loss: 0.6374591588973999
Validation loss: 1.7678533459222445

Epoch: 5| Step: 2
Training loss: 1.692712426185608
Validation loss: 1.8688452346350557

Epoch: 5| Step: 3
Training loss: 1.1637158393859863
Validation loss: 1.7778616541175432

Epoch: 5| Step: 4
Training loss: 0.7414983510971069
Validation loss: 1.8210896740677536

Epoch: 5| Step: 5
Training loss: 1.0304721593856812
Validation loss: 1.8658145089303293

Epoch: 5| Step: 6
Training loss: 0.766596794128418
Validation loss: 1.8511231548042708

Epoch: 5| Step: 7
Training loss: 1.0663118362426758
Validation loss: 1.8532484436547885

Epoch: 5| Step: 8
Training loss: 1.1189372539520264
Validation loss: 1.8700389221150389

Epoch: 5| Step: 9
Training loss: 1.169461965560913
Validation loss: 1.7862250292172996

Epoch: 5| Step: 10
Training loss: 0.973272979259491
Validation loss: 1.8481599643666258

Epoch: 563| Step: 0
Training loss: 0.9233955144882202
Validation loss: 1.8313995958656393

Epoch: 5| Step: 1
Training loss: 0.9522832632064819
Validation loss: 1.835089207977377

Epoch: 5| Step: 2
Training loss: 1.1484137773513794
Validation loss: 1.8615044624574724

Epoch: 5| Step: 3
Training loss: 0.8688676953315735
Validation loss: 1.8601770990638322

Epoch: 5| Step: 4
Training loss: 1.0929244756698608
Validation loss: 1.84445099676809

Epoch: 5| Step: 5
Training loss: 0.9772790670394897
Validation loss: 1.8412944309173092

Epoch: 5| Step: 6
Training loss: 0.8660856485366821
Validation loss: 1.861687280798471

Epoch: 5| Step: 7
Training loss: 1.2639033794403076
Validation loss: 1.795881248289539

Epoch: 5| Step: 8
Training loss: 1.1320650577545166
Validation loss: 1.8714987821476434

Epoch: 5| Step: 9
Training loss: 0.9136662483215332
Validation loss: 1.8285386844347882

Epoch: 5| Step: 10
Training loss: 0.8748160004615784
Validation loss: 1.7791604021544098

Epoch: 564| Step: 0
Training loss: 0.9693707227706909
Validation loss: 1.8357820395500428

Epoch: 5| Step: 1
Training loss: 0.6973839998245239
Validation loss: 1.8435599855197373

Epoch: 5| Step: 2
Training loss: 0.9565204381942749
Validation loss: 1.8338000800019951

Epoch: 5| Step: 3
Training loss: 1.1318702697753906
Validation loss: 1.8430564159988074

Epoch: 5| Step: 4
Training loss: 1.3043631315231323
Validation loss: 1.772876944593204

Epoch: 5| Step: 5
Training loss: 1.3331104516983032
Validation loss: 1.8152804784877326

Epoch: 5| Step: 6
Training loss: 0.8300582766532898
Validation loss: 1.9128547150601622

Epoch: 5| Step: 7
Training loss: 1.2441366910934448
Validation loss: 1.8027721784448112

Epoch: 5| Step: 8
Training loss: 1.0312598943710327
Validation loss: 1.8684281867037538

Epoch: 5| Step: 9
Training loss: 0.9485462307929993
Validation loss: 1.8318686664745372

Epoch: 5| Step: 10
Training loss: 0.8153538703918457
Validation loss: 1.8337824934272355

Epoch: 565| Step: 0
Training loss: 1.297195315361023
Validation loss: 1.7837607283746042

Epoch: 5| Step: 1
Training loss: 1.0853153467178345
Validation loss: 1.8240060319182694

Epoch: 5| Step: 2
Training loss: 1.2232133150100708
Validation loss: 1.8580836249936012

Epoch: 5| Step: 3
Training loss: 1.1729196310043335
Validation loss: 1.8036597518510715

Epoch: 5| Step: 4
Training loss: 1.064870834350586
Validation loss: 1.8384373098291376

Epoch: 5| Step: 5
Training loss: 1.119215726852417
Validation loss: 1.821827660324753

Epoch: 5| Step: 6
Training loss: 0.785946249961853
Validation loss: 1.826973557472229

Epoch: 5| Step: 7
Training loss: 0.9003182649612427
Validation loss: 1.8017393312146586

Epoch: 5| Step: 8
Training loss: 0.725899338722229
Validation loss: 1.7947427034378052

Epoch: 5| Step: 9
Training loss: 1.0684010982513428
Validation loss: 1.8477664865473264

Epoch: 5| Step: 10
Training loss: 0.9007766842842102
Validation loss: 1.8523833777314873

Epoch: 566| Step: 0
Training loss: 0.6692861914634705
Validation loss: 1.7557273628891155

Epoch: 5| Step: 1
Training loss: 0.9200950860977173
Validation loss: 1.8151743540199854

Epoch: 5| Step: 2
Training loss: 0.7756689190864563
Validation loss: 1.808934106621691

Epoch: 5| Step: 3
Training loss: 1.3499534130096436
Validation loss: 1.8090907912100516

Epoch: 5| Step: 4
Training loss: 0.859281063079834
Validation loss: 1.8146710267630957

Epoch: 5| Step: 5
Training loss: 0.5226922035217285
Validation loss: 1.8317870299021404

Epoch: 5| Step: 6
Training loss: 0.8969370126724243
Validation loss: 1.8204086493420344

Epoch: 5| Step: 7
Training loss: 1.5447683334350586
Validation loss: 1.7705774307250977

Epoch: 5| Step: 8
Training loss: 0.9139634966850281
Validation loss: 1.857027611424846

Epoch: 5| Step: 9
Training loss: 1.6252877712249756
Validation loss: 1.7926616104700233

Epoch: 5| Step: 10
Training loss: 1.1195186376571655
Validation loss: 1.8002285342062674

Epoch: 567| Step: 0
Training loss: 1.09414803981781
Validation loss: 1.791883562200813

Epoch: 5| Step: 1
Training loss: 0.8373597860336304
Validation loss: 1.8206611935810377

Epoch: 5| Step: 2
Training loss: 0.8152267336845398
Validation loss: 1.8286949896043347

Epoch: 5| Step: 3
Training loss: 0.7663199305534363
Validation loss: 1.8954629475070583

Epoch: 5| Step: 4
Training loss: 0.962264358997345
Validation loss: 1.7971534190639373

Epoch: 5| Step: 5
Training loss: 1.3348584175109863
Validation loss: 1.8103555171720442

Epoch: 5| Step: 6
Training loss: 1.2729460000991821
Validation loss: 1.7990060929329164

Epoch: 5| Step: 7
Training loss: 0.9514331817626953
Validation loss: 1.836514111488096

Epoch: 5| Step: 8
Training loss: 1.368565320968628
Validation loss: 1.7974389573579193

Epoch: 5| Step: 9
Training loss: 0.8581041097640991
Validation loss: 1.855364199607603

Epoch: 5| Step: 10
Training loss: 0.9665778875350952
Validation loss: 1.8467743037849345

Epoch: 568| Step: 0
Training loss: 1.3561127185821533
Validation loss: 1.8354603295685143

Epoch: 5| Step: 1
Training loss: 1.1191279888153076
Validation loss: 1.8404083405771563

Epoch: 5| Step: 2
Training loss: 1.5729308128356934
Validation loss: 1.852837965052615

Epoch: 5| Step: 3
Training loss: 0.9626736640930176
Validation loss: 1.825487793132823

Epoch: 5| Step: 4
Training loss: 0.6768807172775269
Validation loss: 1.831387145544893

Epoch: 5| Step: 5
Training loss: 1.150858759880066
Validation loss: 1.8167656057624406

Epoch: 5| Step: 6
Training loss: 0.9060420989990234
Validation loss: 1.7996085023367276

Epoch: 5| Step: 7
Training loss: 0.6802682280540466
Validation loss: 1.8366449738061557

Epoch: 5| Step: 8
Training loss: 1.355399250984192
Validation loss: 1.8462594952634586

Epoch: 5| Step: 9
Training loss: 0.5005484819412231
Validation loss: 1.8056425151004587

Epoch: 5| Step: 10
Training loss: 0.7905277013778687
Validation loss: 1.777413493843489

Epoch: 569| Step: 0
Training loss: 1.043794870376587
Validation loss: 1.8760550381034933

Epoch: 5| Step: 1
Training loss: 0.9428768157958984
Validation loss: 1.798671095601974

Epoch: 5| Step: 2
Training loss: 1.0992944240570068
Validation loss: 1.7906254299225346

Epoch: 5| Step: 3
Training loss: 0.9800216555595398
Validation loss: 1.847698885907409

Epoch: 5| Step: 4
Training loss: 1.2783100605010986
Validation loss: 1.7881534163669874

Epoch: 5| Step: 5
Training loss: 1.2045910358428955
Validation loss: 1.856713064255253

Epoch: 5| Step: 6
Training loss: 1.1525779962539673
Validation loss: 1.8199749659466486

Epoch: 5| Step: 7
Training loss: 0.9029645919799805
Validation loss: 1.7726921945489862

Epoch: 5| Step: 8
Training loss: 0.7034735083580017
Validation loss: 1.8060549446331557

Epoch: 5| Step: 9
Training loss: 1.104919672012329
Validation loss: 1.8215752506768832

Epoch: 5| Step: 10
Training loss: 1.2698938846588135
Validation loss: 1.8032281450046006

Epoch: 570| Step: 0
Training loss: 1.1162687540054321
Validation loss: 1.853376688495759

Epoch: 5| Step: 1
Training loss: 1.0098459720611572
Validation loss: 1.8513031774951565

Epoch: 5| Step: 2
Training loss: 0.9409931302070618
Validation loss: 1.8494422538306123

Epoch: 5| Step: 3
Training loss: 1.2646552324295044
Validation loss: 1.8089038248985045

Epoch: 5| Step: 4
Training loss: 0.5727910995483398
Validation loss: 1.7782780380659207

Epoch: 5| Step: 5
Training loss: 0.7627670168876648
Validation loss: 1.7752072067670925

Epoch: 5| Step: 6
Training loss: 0.9718198776245117
Validation loss: 1.8447334702296923

Epoch: 5| Step: 7
Training loss: 0.6961396932601929
Validation loss: 1.8390845303894372

Epoch: 5| Step: 8
Training loss: 1.179219365119934
Validation loss: 1.845868500330115

Epoch: 5| Step: 9
Training loss: 1.3361811637878418
Validation loss: 1.818086116544662

Epoch: 5| Step: 10
Training loss: 1.392953634262085
Validation loss: 1.822182047751642

Epoch: 571| Step: 0
Training loss: 1.0117263793945312
Validation loss: 1.8231120109558105

Epoch: 5| Step: 1
Training loss: 0.7731598019599915
Validation loss: 1.8094476833138415

Epoch: 5| Step: 2
Training loss: 1.304075002670288
Validation loss: 1.759323004753359

Epoch: 5| Step: 3
Training loss: 0.5643250346183777
Validation loss: 1.775167251145968

Epoch: 5| Step: 4
Training loss: 0.7347648739814758
Validation loss: 1.8198870151273665

Epoch: 5| Step: 5
Training loss: 0.7223232984542847
Validation loss: 1.818008363887828

Epoch: 5| Step: 6
Training loss: 0.9198487997055054
Validation loss: 1.8295081738502748

Epoch: 5| Step: 7
Training loss: 1.455736756324768
Validation loss: 1.8025375681538736

Epoch: 5| Step: 8
Training loss: 1.4222089052200317
Validation loss: 1.7954180778995636

Epoch: 5| Step: 9
Training loss: 1.2682483196258545
Validation loss: 1.8388606232981528

Epoch: 5| Step: 10
Training loss: 1.2004766464233398
Validation loss: 1.8274510214405675

Epoch: 572| Step: 0
Training loss: 0.9296404123306274
Validation loss: 1.804560730534215

Epoch: 5| Step: 1
Training loss: 0.8137701153755188
Validation loss: 1.7794313225694882

Epoch: 5| Step: 2
Training loss: 1.0079423189163208
Validation loss: 1.7676957191959504

Epoch: 5| Step: 3
Training loss: 1.3828177452087402
Validation loss: 1.858858072629539

Epoch: 5| Step: 4
Training loss: 1.248185157775879
Validation loss: 1.809519116596509

Epoch: 5| Step: 5
Training loss: 0.7726709246635437
Validation loss: 1.8857872614296534

Epoch: 5| Step: 6
Training loss: 1.4812265634536743
Validation loss: 1.7902327506772933

Epoch: 5| Step: 7
Training loss: 1.173675537109375
Validation loss: 1.8419546619538338

Epoch: 5| Step: 8
Training loss: 0.6925263404846191
Validation loss: 1.8037439136094944

Epoch: 5| Step: 9
Training loss: 0.8064342737197876
Validation loss: 1.7726814593038251

Epoch: 5| Step: 10
Training loss: 1.0769981145858765
Validation loss: 1.835874104371635

Epoch: 573| Step: 0
Training loss: 1.0261881351470947
Validation loss: 1.843797024860177

Epoch: 5| Step: 1
Training loss: 1.0492794513702393
Validation loss: 1.7903682621576453

Epoch: 5| Step: 2
Training loss: 0.9251610636711121
Validation loss: 1.7979702180431736

Epoch: 5| Step: 3
Training loss: 1.1297527551651
Validation loss: 1.8489666549108361

Epoch: 5| Step: 4
Training loss: 1.1124404668807983
Validation loss: 1.7365656527139808

Epoch: 5| Step: 5
Training loss: 1.2883412837982178
Validation loss: 1.8507741715318413

Epoch: 5| Step: 6
Training loss: 1.0529582500457764
Validation loss: 1.7842743473668252

Epoch: 5| Step: 7
Training loss: 1.435429334640503
Validation loss: 1.7948314259129186

Epoch: 5| Step: 8
Training loss: 0.6160168647766113
Validation loss: 1.7970715056183517

Epoch: 5| Step: 9
Training loss: 0.5498701930046082
Validation loss: 1.8138417646449099

Epoch: 5| Step: 10
Training loss: 1.0282036066055298
Validation loss: 1.8022293839403378

Epoch: 574| Step: 0
Training loss: 0.8956867456436157
Validation loss: 1.827610408106158

Epoch: 5| Step: 1
Training loss: 1.003718376159668
Validation loss: 1.8191628456115723

Epoch: 5| Step: 2
Training loss: 0.7297670245170593
Validation loss: 1.9011748939432123

Epoch: 5| Step: 3
Training loss: 1.3263946771621704
Validation loss: 1.7768565877791374

Epoch: 5| Step: 4
Training loss: 1.0883512496948242
Validation loss: 1.7908710472045406

Epoch: 5| Step: 5
Training loss: 1.0923588275909424
Validation loss: 1.8694224819060294

Epoch: 5| Step: 6
Training loss: 0.7075446844100952
Validation loss: 1.821373660077331

Epoch: 5| Step: 7
Training loss: 1.0359646081924438
Validation loss: 1.8357153336207073

Epoch: 5| Step: 8
Training loss: 0.875507652759552
Validation loss: 1.7810628055244364

Epoch: 5| Step: 9
Training loss: 1.2558839321136475
Validation loss: 1.844060121044036

Epoch: 5| Step: 10
Training loss: 1.0365163087844849
Validation loss: 1.7778626385555472

Epoch: 575| Step: 0
Training loss: 1.6382261514663696
Validation loss: 1.8156856221537436

Epoch: 5| Step: 1
Training loss: 0.831800103187561
Validation loss: 1.8100144350400535

Epoch: 5| Step: 2
Training loss: 0.9689921140670776
Validation loss: 1.848610133253118

Epoch: 5| Step: 3
Training loss: 0.8983510732650757
Validation loss: 1.8704837099198373

Epoch: 5| Step: 4
Training loss: 0.6771801710128784
Validation loss: 1.806527909412179

Epoch: 5| Step: 5
Training loss: 0.6172860860824585
Validation loss: 1.8163447380065918

Epoch: 5| Step: 6
Training loss: 1.0943522453308105
Validation loss: 1.7958807996524278

Epoch: 5| Step: 7
Training loss: 1.2767735719680786
Validation loss: 1.8801221411715272

Epoch: 5| Step: 8
Training loss: 1.0945751667022705
Validation loss: 1.8132177117050334

Epoch: 5| Step: 9
Training loss: 1.2746394872665405
Validation loss: 1.8222228955197077

Epoch: 5| Step: 10
Training loss: 0.9823996424674988
Validation loss: 1.8691683379552697

Epoch: 576| Step: 0
Training loss: 0.8674659729003906
Validation loss: 1.848485090399301

Epoch: 5| Step: 1
Training loss: 1.0797803401947021
Validation loss: 1.8044665808318763

Epoch: 5| Step: 2
Training loss: 1.0863183736801147
Validation loss: 1.812807680458151

Epoch: 5| Step: 3
Training loss: 1.2568891048431396
Validation loss: 1.7549019603319065

Epoch: 5| Step: 4
Training loss: 1.2489227056503296
Validation loss: 1.8104338556207635

Epoch: 5| Step: 5
Training loss: 1.1430680751800537
Validation loss: 1.768259540680916

Epoch: 5| Step: 6
Training loss: 0.5967027544975281
Validation loss: 1.7962044413371752

Epoch: 5| Step: 7
Training loss: 0.8206773996353149
Validation loss: 1.7950717877316218

Epoch: 5| Step: 8
Training loss: 0.8248180150985718
Validation loss: 1.8822304817938036

Epoch: 5| Step: 9
Training loss: 0.9552786946296692
Validation loss: 1.830620269621572

Epoch: 5| Step: 10
Training loss: 1.5473527908325195
Validation loss: 1.8024203277403308

Epoch: 577| Step: 0
Training loss: 0.7873421907424927
Validation loss: 1.8644198820155153

Epoch: 5| Step: 1
Training loss: 0.7461605668067932
Validation loss: 1.8002235299797469

Epoch: 5| Step: 2
Training loss: 0.8432032465934753
Validation loss: 1.7811228036880493

Epoch: 5| Step: 3
Training loss: 1.0989840030670166
Validation loss: 1.833777461000668

Epoch: 5| Step: 4
Training loss: 0.7063933610916138
Validation loss: 1.8243828819644066

Epoch: 5| Step: 5
Training loss: 0.8578295707702637
Validation loss: 1.8032159779661445

Epoch: 5| Step: 6
Training loss: 1.4271783828735352
Validation loss: 1.8807792407210155

Epoch: 5| Step: 7
Training loss: 0.6962658166885376
Validation loss: 1.8318075313363025

Epoch: 5| Step: 8
Training loss: 1.3738783597946167
Validation loss: 1.8466540280208792

Epoch: 5| Step: 9
Training loss: 1.1096938848495483
Validation loss: 1.8793549383840253

Epoch: 5| Step: 10
Training loss: 1.3297373056411743
Validation loss: 1.7453230427157493

Epoch: 578| Step: 0
Training loss: 0.6430888175964355
Validation loss: 1.809084789727324

Epoch: 5| Step: 1
Training loss: 1.0550330877304077
Validation loss: 1.8007125957037813

Epoch: 5| Step: 2
Training loss: 0.7978187799453735
Validation loss: 1.8057953196187173

Epoch: 5| Step: 3
Training loss: 1.1772921085357666
Validation loss: 1.7980044990457513

Epoch: 5| Step: 4
Training loss: 0.6655052304267883
Validation loss: 1.7764276637825915

Epoch: 5| Step: 5
Training loss: 0.8230923414230347
Validation loss: 1.8473589343409385

Epoch: 5| Step: 6
Training loss: 0.9616571664810181
Validation loss: 1.817169625272033

Epoch: 5| Step: 7
Training loss: 0.8196375966072083
Validation loss: 1.7853962529090144

Epoch: 5| Step: 8
Training loss: 0.7626210451126099
Validation loss: 1.784989454412973

Epoch: 5| Step: 9
Training loss: 1.2008153200149536
Validation loss: 1.8560517487987396

Epoch: 5| Step: 10
Training loss: 1.8822119235992432
Validation loss: 1.805338616012245

Epoch: 579| Step: 0
Training loss: 0.8980603218078613
Validation loss: 1.830966197034364

Epoch: 5| Step: 1
Training loss: 1.3985726833343506
Validation loss: 1.8583996859929894

Epoch: 5| Step: 2
Training loss: 0.8955228924751282
Validation loss: 1.8496095134365944

Epoch: 5| Step: 3
Training loss: 0.9029960632324219
Validation loss: 1.8402825427311722

Epoch: 5| Step: 4
Training loss: 0.9761905670166016
Validation loss: 1.8454567334985221

Epoch: 5| Step: 5
Training loss: 0.8484021425247192
Validation loss: 1.8222959413323352

Epoch: 5| Step: 6
Training loss: 0.929634690284729
Validation loss: 1.8180468159337198

Epoch: 5| Step: 7
Training loss: 0.9129402041435242
Validation loss: 1.788591601515329

Epoch: 5| Step: 8
Training loss: 1.3792369365692139
Validation loss: 1.813110000343733

Epoch: 5| Step: 9
Training loss: 0.8189984560012817
Validation loss: 1.812957932872157

Epoch: 5| Step: 10
Training loss: 0.9527334570884705
Validation loss: 1.7984167093871741

Epoch: 580| Step: 0
Training loss: 1.1253567934036255
Validation loss: 1.7965236094690138

Epoch: 5| Step: 1
Training loss: 1.364189863204956
Validation loss: 1.8440515943752822

Epoch: 5| Step: 2
Training loss: 0.6921762228012085
Validation loss: 1.8253481195818992

Epoch: 5| Step: 3
Training loss: 1.1190707683563232
Validation loss: 1.8314636368905344

Epoch: 5| Step: 4
Training loss: 1.2312673330307007
Validation loss: 1.782966027977646

Epoch: 5| Step: 5
Training loss: 1.0300401449203491
Validation loss: 1.8013559868258815

Epoch: 5| Step: 6
Training loss: 1.0314563512802124
Validation loss: 1.7733644913601618

Epoch: 5| Step: 7
Training loss: 0.9536528587341309
Validation loss: 1.8532850332157587

Epoch: 5| Step: 8
Training loss: 1.0119205713272095
Validation loss: 1.7893152121574647

Epoch: 5| Step: 9
Training loss: 0.948749840259552
Validation loss: 1.7452866544005692

Epoch: 5| Step: 10
Training loss: 0.5414953827857971
Validation loss: 1.8041506864691292

Epoch: 581| Step: 0
Training loss: 1.1237059831619263
Validation loss: 1.8122032585964407

Epoch: 5| Step: 1
Training loss: 0.918692946434021
Validation loss: 1.8979303195912351

Epoch: 5| Step: 2
Training loss: 1.1700727939605713
Validation loss: 1.8299314334828367

Epoch: 5| Step: 3
Training loss: 0.9215677380561829
Validation loss: 1.8252519638307634

Epoch: 5| Step: 4
Training loss: 0.8773176074028015
Validation loss: 1.8354507979526316

Epoch: 5| Step: 5
Training loss: 0.7688589692115784
Validation loss: 1.8005753217204925

Epoch: 5| Step: 6
Training loss: 0.9544949531555176
Validation loss: 1.88628028926029

Epoch: 5| Step: 7
Training loss: 0.8670860528945923
Validation loss: 1.8475512381522887

Epoch: 5| Step: 8
Training loss: 0.9918421506881714
Validation loss: 1.8010742664337158

Epoch: 5| Step: 9
Training loss: 1.441881537437439
Validation loss: 1.776754379272461

Epoch: 5| Step: 10
Training loss: 0.8536497354507446
Validation loss: 1.80996149457911

Epoch: 582| Step: 0
Training loss: 0.7382296323776245
Validation loss: 1.7975026971550399

Epoch: 5| Step: 1
Training loss: 1.2977718114852905
Validation loss: 1.820030604639361

Epoch: 5| Step: 2
Training loss: 0.919105052947998
Validation loss: 1.7926005580091988

Epoch: 5| Step: 3
Training loss: 1.0454959869384766
Validation loss: 1.7627093766325264

Epoch: 5| Step: 4
Training loss: 0.9081375002861023
Validation loss: 1.8015742853123655

Epoch: 5| Step: 5
Training loss: 0.9888262748718262
Validation loss: 1.878488294539913

Epoch: 5| Step: 6
Training loss: 1.1285240650177002
Validation loss: 1.886500527781825

Epoch: 5| Step: 7
Training loss: 0.9387648701667786
Validation loss: 1.834473588133371

Epoch: 5| Step: 8
Training loss: 1.0471019744873047
Validation loss: 1.850523502595963

Epoch: 5| Step: 9
Training loss: 0.8043745160102844
Validation loss: 1.8565456944127237

Epoch: 5| Step: 10
Training loss: 1.2264090776443481
Validation loss: 1.7857963103120045

Epoch: 583| Step: 0
Training loss: 0.7151133418083191
Validation loss: 1.8173572594119656

Epoch: 5| Step: 1
Training loss: 0.7047951817512512
Validation loss: 1.809835668533079

Epoch: 5| Step: 2
Training loss: 1.0304359197616577
Validation loss: 1.833675749840275

Epoch: 5| Step: 3
Training loss: 0.9907239675521851
Validation loss: 1.7786126213689004

Epoch: 5| Step: 4
Training loss: 0.5757425427436829
Validation loss: 1.8047169459763395

Epoch: 5| Step: 5
Training loss: 1.0055055618286133
Validation loss: 1.8142744687295729

Epoch: 5| Step: 6
Training loss: 1.4003137350082397
Validation loss: 1.844505258785781

Epoch: 5| Step: 7
Training loss: 0.8991538286209106
Validation loss: 1.80565978634742

Epoch: 5| Step: 8
Training loss: 1.413102149963379
Validation loss: 1.8223764217028053

Epoch: 5| Step: 9
Training loss: 1.2429481744766235
Validation loss: 1.8294111644068072

Epoch: 5| Step: 10
Training loss: 0.6197203993797302
Validation loss: 1.7927358919574368

Epoch: 584| Step: 0
Training loss: 1.0536202192306519
Validation loss: 1.7860204686400711

Epoch: 5| Step: 1
Training loss: 0.9662126302719116
Validation loss: 1.7771022012156825

Epoch: 5| Step: 2
Training loss: 0.7944839000701904
Validation loss: 1.773580640874883

Epoch: 5| Step: 3
Training loss: 1.1203747987747192
Validation loss: 1.794369948807583

Epoch: 5| Step: 4
Training loss: 0.8698110580444336
Validation loss: 1.84222924452956

Epoch: 5| Step: 5
Training loss: 1.2736883163452148
Validation loss: 1.8305771350860596

Epoch: 5| Step: 6
Training loss: 1.4510247707366943
Validation loss: 1.8212920952868719

Epoch: 5| Step: 7
Training loss: 0.9425169825553894
Validation loss: 1.8155346865295081

Epoch: 5| Step: 8
Training loss: 0.7817105054855347
Validation loss: 1.805185002665366

Epoch: 5| Step: 9
Training loss: 0.6290231943130493
Validation loss: 1.8300519668927757

Epoch: 5| Step: 10
Training loss: 1.3864408731460571
Validation loss: 1.8034051233722317

Epoch: 585| Step: 0
Training loss: 0.7292794585227966
Validation loss: 1.855673409277393

Epoch: 5| Step: 1
Training loss: 0.8070892095565796
Validation loss: 1.8070988578181113

Epoch: 5| Step: 2
Training loss: 1.6902720928192139
Validation loss: 1.8155328842901415

Epoch: 5| Step: 3
Training loss: 0.6750354766845703
Validation loss: 1.815104365348816

Epoch: 5| Step: 4
Training loss: 0.8616692423820496
Validation loss: 1.7764543615361696

Epoch: 5| Step: 5
Training loss: 0.7385252714157104
Validation loss: 1.8056460195972073

Epoch: 5| Step: 6
Training loss: 0.9325919151306152
Validation loss: 1.7372287883553454

Epoch: 5| Step: 7
Training loss: 1.1193459033966064
Validation loss: 1.7948150070764686

Epoch: 5| Step: 8
Training loss: 0.9213287234306335
Validation loss: 1.856316807449505

Epoch: 5| Step: 9
Training loss: 0.7436640858650208
Validation loss: 1.7898147541989562

Epoch: 5| Step: 10
Training loss: 1.4796557426452637
Validation loss: 1.8864325983549959

Epoch: 586| Step: 0
Training loss: 1.0931349992752075
Validation loss: 1.844227081985884

Epoch: 5| Step: 1
Training loss: 1.2292438745498657
Validation loss: 1.8440420063593055

Epoch: 5| Step: 2
Training loss: 0.966335654258728
Validation loss: 1.8427255922748196

Epoch: 5| Step: 3
Training loss: 1.2394707202911377
Validation loss: 1.813415499143703

Epoch: 5| Step: 4
Training loss: 0.9264361262321472
Validation loss: 1.8452466277665989

Epoch: 5| Step: 5
Training loss: 1.1345643997192383
Validation loss: 1.8163766271324568

Epoch: 5| Step: 6
Training loss: 0.9929566383361816
Validation loss: 1.7889723136860838

Epoch: 5| Step: 7
Training loss: 0.8911408185958862
Validation loss: 1.7945104722053773

Epoch: 5| Step: 8
Training loss: 0.8399789929389954
Validation loss: 1.815839212427857

Epoch: 5| Step: 9
Training loss: 1.0038115978240967
Validation loss: 1.81216033299764

Epoch: 5| Step: 10
Training loss: 0.4813924729824066
Validation loss: 1.7845340082722325

Epoch: 587| Step: 0
Training loss: 0.8691269755363464
Validation loss: 1.862346633788078

Epoch: 5| Step: 1
Training loss: 1.282801866531372
Validation loss: 1.8260609206332956

Epoch: 5| Step: 2
Training loss: 1.0435829162597656
Validation loss: 1.8840699759862756

Epoch: 5| Step: 3
Training loss: 0.8365241885185242
Validation loss: 1.8902127691494521

Epoch: 5| Step: 4
Training loss: 1.0635102987289429
Validation loss: 1.8179279834993425

Epoch: 5| Step: 5
Training loss: 0.863282322883606
Validation loss: 1.782582095874253

Epoch: 5| Step: 6
Training loss: 0.9915698766708374
Validation loss: 1.840954529341831

Epoch: 5| Step: 7
Training loss: 0.872083306312561
Validation loss: 1.8080012631672684

Epoch: 5| Step: 8
Training loss: 0.9342464208602905
Validation loss: 1.8175950242627052

Epoch: 5| Step: 9
Training loss: 1.31795334815979
Validation loss: 1.8270238202105287

Epoch: 5| Step: 10
Training loss: 0.9720783233642578
Validation loss: 1.8034887877843713

Epoch: 588| Step: 0
Training loss: 0.836254894733429
Validation loss: 1.8347370496360205

Epoch: 5| Step: 1
Training loss: 0.7931094169616699
Validation loss: 1.8589408705311437

Epoch: 5| Step: 2
Training loss: 1.2919151782989502
Validation loss: 1.89176014033697

Epoch: 5| Step: 3
Training loss: 0.646949827671051
Validation loss: 1.7755575833782073

Epoch: 5| Step: 4
Training loss: 1.0033122301101685
Validation loss: 1.8490085242896952

Epoch: 5| Step: 5
Training loss: 1.5090965032577515
Validation loss: 1.8333244746731174

Epoch: 5| Step: 6
Training loss: 0.9554218053817749
Validation loss: 1.8676516907189482

Epoch: 5| Step: 7
Training loss: 0.898718535900116
Validation loss: 1.834149670857255

Epoch: 5| Step: 8
Training loss: 1.0520892143249512
Validation loss: 1.8374373682083622

Epoch: 5| Step: 9
Training loss: 1.0866286754608154
Validation loss: 1.81469254596259

Epoch: 5| Step: 10
Training loss: 0.9252442717552185
Validation loss: 1.8687003786845873

Epoch: 589| Step: 0
Training loss: 1.1097456216812134
Validation loss: 1.8506461471639655

Epoch: 5| Step: 1
Training loss: 1.1400686502456665
Validation loss: 1.8335477049632738

Epoch: 5| Step: 2
Training loss: 1.3039729595184326
Validation loss: 1.821455147958571

Epoch: 5| Step: 3
Training loss: 0.9555200338363647
Validation loss: 1.8381954726352487

Epoch: 5| Step: 4
Training loss: 0.6935913562774658
Validation loss: 1.8424574957099011

Epoch: 5| Step: 5
Training loss: 1.2073824405670166
Validation loss: 1.816525387507613

Epoch: 5| Step: 6
Training loss: 0.8364933729171753
Validation loss: 1.754510946171258

Epoch: 5| Step: 7
Training loss: 1.1057376861572266
Validation loss: 1.7643068490489837

Epoch: 5| Step: 8
Training loss: 0.7791134119033813
Validation loss: 1.8058663273370394

Epoch: 5| Step: 9
Training loss: 0.7215338349342346
Validation loss: 1.822361739732886

Epoch: 5| Step: 10
Training loss: 0.7006306648254395
Validation loss: 1.814980987579592

Epoch: 590| Step: 0
Training loss: 1.0461714267730713
Validation loss: 1.7525926174656037

Epoch: 5| Step: 1
Training loss: 1.0770410299301147
Validation loss: 1.7987768265508837

Epoch: 5| Step: 2
Training loss: 1.2012887001037598
Validation loss: 1.7954200262664466

Epoch: 5| Step: 3
Training loss: 0.8727058172225952
Validation loss: 1.8052142653413998

Epoch: 5| Step: 4
Training loss: 0.8328338861465454
Validation loss: 1.802334903388895

Epoch: 5| Step: 5
Training loss: 0.7806738615036011
Validation loss: 1.840352992857656

Epoch: 5| Step: 6
Training loss: 1.3597941398620605
Validation loss: 1.7699630568104405

Epoch: 5| Step: 7
Training loss: 1.072222113609314
Validation loss: 1.8061581414232972

Epoch: 5| Step: 8
Training loss: 1.0402486324310303
Validation loss: 1.8446711160803353

Epoch: 5| Step: 9
Training loss: 0.7268698215484619
Validation loss: 1.8646138598842006

Epoch: 5| Step: 10
Training loss: 1.0650014877319336
Validation loss: 1.8376391703082668

Epoch: 591| Step: 0
Training loss: 0.5202981233596802
Validation loss: 1.7898855773351525

Epoch: 5| Step: 1
Training loss: 1.0644272565841675
Validation loss: 1.7869797919386177

Epoch: 5| Step: 2
Training loss: 0.71001797914505
Validation loss: 1.8272762875403128

Epoch: 5| Step: 3
Training loss: 1.1293363571166992
Validation loss: 1.832997227227816

Epoch: 5| Step: 4
Training loss: 0.5335787534713745
Validation loss: 1.7941469761633104

Epoch: 5| Step: 5
Training loss: 1.1537092924118042
Validation loss: 1.8162247647521317

Epoch: 5| Step: 6
Training loss: 1.414398431777954
Validation loss: 1.7774834761055567

Epoch: 5| Step: 7
Training loss: 0.8149860501289368
Validation loss: 1.8132303837806947

Epoch: 5| Step: 8
Training loss: 1.3276028633117676
Validation loss: 1.8103051365062754

Epoch: 5| Step: 9
Training loss: 0.8124727010726929
Validation loss: 1.8482862287952053

Epoch: 5| Step: 10
Training loss: 0.8512309789657593
Validation loss: 1.8116047177263486

Epoch: 592| Step: 0
Training loss: 1.01839017868042
Validation loss: 1.8161484502976941

Epoch: 5| Step: 1
Training loss: 0.6294662356376648
Validation loss: 1.8094327859981085

Epoch: 5| Step: 2
Training loss: 0.7442231178283691
Validation loss: 1.8068059131663332

Epoch: 5| Step: 3
Training loss: 0.9606911540031433
Validation loss: 1.8125524213237147

Epoch: 5| Step: 4
Training loss: 1.1156666278839111
Validation loss: 1.7881215515957083

Epoch: 5| Step: 5
Training loss: 0.7198902368545532
Validation loss: 1.8709293667988112

Epoch: 5| Step: 6
Training loss: 1.1576138734817505
Validation loss: 1.861548577585528

Epoch: 5| Step: 7
Training loss: 1.1241309642791748
Validation loss: 1.8525624172661894

Epoch: 5| Step: 8
Training loss: 1.1509292125701904
Validation loss: 1.823591580954931

Epoch: 5| Step: 9
Training loss: 0.8632743954658508
Validation loss: 1.7825245959784395

Epoch: 5| Step: 10
Training loss: 1.2199983596801758
Validation loss: 1.844839411397134

Epoch: 593| Step: 0
Training loss: 1.4736545085906982
Validation loss: 1.7834712971923172

Epoch: 5| Step: 1
Training loss: 0.8087164163589478
Validation loss: 1.8103026113202494

Epoch: 5| Step: 2
Training loss: 1.2803232669830322
Validation loss: 1.8019405526499594

Epoch: 5| Step: 3
Training loss: 0.9590865969657898
Validation loss: 1.8360127825890817

Epoch: 5| Step: 4
Training loss: 0.7175580263137817
Validation loss: 1.8038077149339902

Epoch: 5| Step: 5
Training loss: 0.7468816041946411
Validation loss: 1.8074846882973947

Epoch: 5| Step: 6
Training loss: 1.1481425762176514
Validation loss: 1.7902380163951586

Epoch: 5| Step: 7
Training loss: 1.025688648223877
Validation loss: 1.774984102095327

Epoch: 5| Step: 8
Training loss: 0.9585204124450684
Validation loss: 1.8743729617006035

Epoch: 5| Step: 9
Training loss: 0.9571324586868286
Validation loss: 1.8257180747165476

Epoch: 5| Step: 10
Training loss: 0.7260639667510986
Validation loss: 1.8844447828108264

Epoch: 594| Step: 0
Training loss: 0.6383705735206604
Validation loss: 1.7597168722460348

Epoch: 5| Step: 1
Training loss: 0.7657975554466248
Validation loss: 1.7632341025978007

Epoch: 5| Step: 2
Training loss: 1.1283727884292603
Validation loss: 1.8076098195968135

Epoch: 5| Step: 3
Training loss: 0.9656046628952026
Validation loss: 1.8502385180483583

Epoch: 5| Step: 4
Training loss: 0.9850562810897827
Validation loss: 1.8174452538131385

Epoch: 5| Step: 5
Training loss: 0.9176653623580933
Validation loss: 1.8213795256871048

Epoch: 5| Step: 6
Training loss: 1.207472801208496
Validation loss: 1.8829534438348585

Epoch: 5| Step: 7
Training loss: 1.0085710287094116
Validation loss: 1.7954080963647494

Epoch: 5| Step: 8
Training loss: 0.8879408836364746
Validation loss: 1.841829707545619

Epoch: 5| Step: 9
Training loss: 1.2893450260162354
Validation loss: 1.8169385130687425

Epoch: 5| Step: 10
Training loss: 0.8368992209434509
Validation loss: 1.7685324812448153

Epoch: 595| Step: 0
Training loss: 1.1454740762710571
Validation loss: 1.9004515268469369

Epoch: 5| Step: 1
Training loss: 0.6283940672874451
Validation loss: 1.8072723868072673

Epoch: 5| Step: 2
Training loss: 0.9701768159866333
Validation loss: 1.7907932701931204

Epoch: 5| Step: 3
Training loss: 1.0300668478012085
Validation loss: 1.8060221877149356

Epoch: 5| Step: 4
Training loss: 0.8151544332504272
Validation loss: 1.7729153992027364

Epoch: 5| Step: 5
Training loss: 0.9662688970565796
Validation loss: 1.8407145495055823

Epoch: 5| Step: 6
Training loss: 0.7184261083602905
Validation loss: 1.760752086998314

Epoch: 5| Step: 7
Training loss: 0.8900159597396851
Validation loss: 1.824807959218179

Epoch: 5| Step: 8
Training loss: 0.8768677711486816
Validation loss: 1.7558612695304296

Epoch: 5| Step: 9
Training loss: 1.4164918661117554
Validation loss: 1.7895568955329157

Epoch: 5| Step: 10
Training loss: 0.7767597436904907
Validation loss: 1.870189553947859

Epoch: 596| Step: 0
Training loss: 0.821388840675354
Validation loss: 1.798722206905324

Epoch: 5| Step: 1
Training loss: 1.151397466659546
Validation loss: 1.7920300643290243

Epoch: 5| Step: 2
Training loss: 1.1302934885025024
Validation loss: 1.8799416160070768

Epoch: 5| Step: 3
Training loss: 0.9572547078132629
Validation loss: 1.741350689241963

Epoch: 5| Step: 4
Training loss: 0.7322405576705933
Validation loss: 1.826616133413007

Epoch: 5| Step: 5
Training loss: 1.249787449836731
Validation loss: 1.8115781609730055

Epoch: 5| Step: 6
Training loss: 1.1806132793426514
Validation loss: 1.8305194147171513

Epoch: 5| Step: 7
Training loss: 0.8260444402694702
Validation loss: 1.8161765170353714

Epoch: 5| Step: 8
Training loss: 0.8415233492851257
Validation loss: 1.8038267640657322

Epoch: 5| Step: 9
Training loss: 0.8581985235214233
Validation loss: 1.7883415311895392

Epoch: 5| Step: 10
Training loss: 1.0967738628387451
Validation loss: 1.7646678968142437

Epoch: 597| Step: 0
Training loss: 1.0014843940734863
Validation loss: 1.8192489506095968

Epoch: 5| Step: 1
Training loss: 1.2213904857635498
Validation loss: 1.7719193645702895

Epoch: 5| Step: 2
Training loss: 0.8516641855239868
Validation loss: 1.7983552191847114

Epoch: 5| Step: 3
Training loss: 0.7654473185539246
Validation loss: 1.855309937589912

Epoch: 5| Step: 4
Training loss: 1.0325267314910889
Validation loss: 1.7518271041172806

Epoch: 5| Step: 5
Training loss: 0.6729997396469116
Validation loss: 1.791991212034738

Epoch: 5| Step: 6
Training loss: 0.775380551815033
Validation loss: 1.7873481396705873

Epoch: 5| Step: 7
Training loss: 1.3387490510940552
Validation loss: 1.8448016002614012

Epoch: 5| Step: 8
Training loss: 0.9237667322158813
Validation loss: 1.8407514684943742

Epoch: 5| Step: 9
Training loss: 0.729490339756012
Validation loss: 1.8250728704596078

Epoch: 5| Step: 10
Training loss: 1.2140002250671387
Validation loss: 1.8153594770739157

Epoch: 598| Step: 0
Training loss: 1.5641463994979858
Validation loss: 1.792101688282464

Epoch: 5| Step: 1
Training loss: 0.9855808019638062
Validation loss: 1.81238127780217

Epoch: 5| Step: 2
Training loss: 0.8001209497451782
Validation loss: 1.7916977367093485

Epoch: 5| Step: 3
Training loss: 0.8560444116592407
Validation loss: 1.8093990997601581

Epoch: 5| Step: 4
Training loss: 0.9176737070083618
Validation loss: 1.8011715001957391

Epoch: 5| Step: 5
Training loss: 0.936271071434021
Validation loss: 1.8274814544185516

Epoch: 5| Step: 6
Training loss: 1.2510093450546265
Validation loss: 1.7377666606697986

Epoch: 5| Step: 7
Training loss: 0.8591371774673462
Validation loss: 1.7687719547620384

Epoch: 5| Step: 8
Training loss: 0.8398835062980652
Validation loss: 1.816934867571759

Epoch: 5| Step: 9
Training loss: 1.0329563617706299
Validation loss: 1.8331174068553473

Epoch: 5| Step: 10
Training loss: 0.7049761414527893
Validation loss: 1.8438681581968903

Epoch: 599| Step: 0
Training loss: 0.8118587732315063
Validation loss: 1.7768326856756722

Epoch: 5| Step: 1
Training loss: 1.185896873474121
Validation loss: 1.816305911669167

Epoch: 5| Step: 2
Training loss: 0.6995806694030762
Validation loss: 1.8261191370666667

Epoch: 5| Step: 3
Training loss: 1.441459059715271
Validation loss: 1.8617223949842556

Epoch: 5| Step: 4
Training loss: 1.2362055778503418
Validation loss: 1.8066759327406525

Epoch: 5| Step: 5
Training loss: 0.8901987075805664
Validation loss: 1.8029384472036873

Epoch: 5| Step: 6
Training loss: 0.9595457315444946
Validation loss: 1.7669826220440608

Epoch: 5| Step: 7
Training loss: 0.7653362154960632
Validation loss: 1.7825561825947096

Epoch: 5| Step: 8
Training loss: 0.9393256902694702
Validation loss: 1.8198486194815686

Epoch: 5| Step: 9
Training loss: 0.8922291994094849
Validation loss: 1.7048260217071862

Epoch: 5| Step: 10
Training loss: 0.5198513865470886
Validation loss: 1.8778576850891113

Epoch: 600| Step: 0
Training loss: 1.0489732027053833
Validation loss: 1.7669954517836213

Epoch: 5| Step: 1
Training loss: 0.6042619943618774
Validation loss: 1.8092260488899805

Epoch: 5| Step: 2
Training loss: 0.9040773510932922
Validation loss: 1.7930749757315523

Epoch: 5| Step: 3
Training loss: 1.0609698295593262
Validation loss: 1.8259776984491656

Epoch: 5| Step: 4
Training loss: 0.7783554196357727
Validation loss: 1.8175236178982643

Epoch: 5| Step: 5
Training loss: 0.8426721692085266
Validation loss: 1.7698894098240843

Epoch: 5| Step: 6
Training loss: 1.028670310974121
Validation loss: 1.7687121181077854

Epoch: 5| Step: 7
Training loss: 1.0646135807037354
Validation loss: 1.8044869951022569

Epoch: 5| Step: 8
Training loss: 1.2547705173492432
Validation loss: 1.7960060988703082

Epoch: 5| Step: 9
Training loss: 0.6828535795211792
Validation loss: 1.7951797734024704

Epoch: 5| Step: 10
Training loss: 1.186110496520996
Validation loss: 1.7787326574325562

Epoch: 601| Step: 0
Training loss: 1.0546098947525024
Validation loss: 1.829682134812878

Epoch: 5| Step: 1
Training loss: 0.8912470936775208
Validation loss: 1.8099217619947208

Epoch: 5| Step: 2
Training loss: 0.8470317125320435
Validation loss: 1.724110593077957

Epoch: 5| Step: 3
Training loss: 0.8633185625076294
Validation loss: 1.8553530593072214

Epoch: 5| Step: 4
Training loss: 1.018042802810669
Validation loss: 1.7846372601806477

Epoch: 5| Step: 5
Training loss: 0.8713914155960083
Validation loss: 1.7970623764940488

Epoch: 5| Step: 6
Training loss: 0.749773383140564
Validation loss: 1.7802312963752336

Epoch: 5| Step: 7
Training loss: 0.758247971534729
Validation loss: 1.8261314925327097

Epoch: 5| Step: 8
Training loss: 0.9191330075263977
Validation loss: 1.790611832372604

Epoch: 5| Step: 9
Training loss: 1.2503893375396729
Validation loss: 1.8565876355735205

Epoch: 5| Step: 10
Training loss: 1.405766248703003
Validation loss: 1.8165203960992957

Epoch: 602| Step: 0
Training loss: 1.0191676616668701
Validation loss: 1.7899406481814641

Epoch: 5| Step: 1
Training loss: 1.24686598777771
Validation loss: 1.7539476579235447

Epoch: 5| Step: 2
Training loss: 1.086699366569519
Validation loss: 1.8131558625928816

Epoch: 5| Step: 3
Training loss: 0.653870701789856
Validation loss: 1.8196322892301826

Epoch: 5| Step: 4
Training loss: 0.9949132800102234
Validation loss: 1.7772349772914764

Epoch: 5| Step: 5
Training loss: 0.8342803716659546
Validation loss: 1.8161572717851209

Epoch: 5| Step: 6
Training loss: 1.4729493856430054
Validation loss: 1.7982901809036091

Epoch: 5| Step: 7
Training loss: 0.6013819575309753
Validation loss: 1.7762832603146952

Epoch: 5| Step: 8
Training loss: 0.7425851821899414
Validation loss: 1.8238984782208678

Epoch: 5| Step: 9
Training loss: 1.0799405574798584
Validation loss: 1.782200538983909

Epoch: 5| Step: 10
Training loss: 0.8083829879760742
Validation loss: 1.8054241903366581

Epoch: 603| Step: 0
Training loss: 0.7662326097488403
Validation loss: 1.7876455181388444

Epoch: 5| Step: 1
Training loss: 1.4480955600738525
Validation loss: 1.80329050940852

Epoch: 5| Step: 2
Training loss: 1.3360445499420166
Validation loss: 1.8889141774946643

Epoch: 5| Step: 3
Training loss: 1.0330499410629272
Validation loss: 1.7793661548245339

Epoch: 5| Step: 4
Training loss: 1.1227900981903076
Validation loss: 1.7920980543218634

Epoch: 5| Step: 5
Training loss: 0.8969724774360657
Validation loss: 1.781686277799709

Epoch: 5| Step: 6
Training loss: 0.9323062896728516
Validation loss: 1.8128076535399242

Epoch: 5| Step: 7
Training loss: 0.815371036529541
Validation loss: 1.8763924862748833

Epoch: 5| Step: 8
Training loss: 0.6777475476264954
Validation loss: 1.8326383329206897

Epoch: 5| Step: 9
Training loss: 0.7719439268112183
Validation loss: 1.7838322526665145

Epoch: 5| Step: 10
Training loss: 0.9597775936126709
Validation loss: 1.8323756135920042

Epoch: 604| Step: 0
Training loss: 0.7789233922958374
Validation loss: 1.7909653186798096

Epoch: 5| Step: 1
Training loss: 0.8194926977157593
Validation loss: 1.845886286868844

Epoch: 5| Step: 2
Training loss: 1.1354787349700928
Validation loss: 1.7357438430991223

Epoch: 5| Step: 3
Training loss: 0.8654913902282715
Validation loss: 1.7825088321521718

Epoch: 5| Step: 4
Training loss: 0.9998354911804199
Validation loss: 1.7932403651616906

Epoch: 5| Step: 5
Training loss: 1.2965552806854248
Validation loss: 1.792579097132529

Epoch: 5| Step: 6
Training loss: 0.6158326864242554
Validation loss: 1.7912792557029313

Epoch: 5| Step: 7
Training loss: 1.1376042366027832
Validation loss: 1.8029823777496174

Epoch: 5| Step: 8
Training loss: 0.7996929287910461
Validation loss: 1.8041793005440825

Epoch: 5| Step: 9
Training loss: 1.3455173969268799
Validation loss: 1.821908676496116

Epoch: 5| Step: 10
Training loss: 1.007810115814209
Validation loss: 1.7947996508690618

Epoch: 605| Step: 0
Training loss: 0.8694720268249512
Validation loss: 1.824575767722181

Epoch: 5| Step: 1
Training loss: 0.9974795579910278
Validation loss: 1.7818989061540174

Epoch: 5| Step: 2
Training loss: 0.7828255891799927
Validation loss: 1.8406860495126376

Epoch: 5| Step: 3
Training loss: 0.9793719053268433
Validation loss: 1.853667288698176

Epoch: 5| Step: 4
Training loss: 1.6142008304595947
Validation loss: 1.788513134884578

Epoch: 5| Step: 5
Training loss: 1.0569868087768555
Validation loss: 1.8183124501218078

Epoch: 5| Step: 6
Training loss: 0.8843782544136047
Validation loss: 1.816675950122136

Epoch: 5| Step: 7
Training loss: 0.6020638346672058
Validation loss: 1.8558489635426512

Epoch: 5| Step: 8
Training loss: 0.6864193677902222
Validation loss: 1.7789610790949997

Epoch: 5| Step: 9
Training loss: 0.8327913284301758
Validation loss: 1.824215745413175

Epoch: 5| Step: 10
Training loss: 0.9151436686515808
Validation loss: 1.8234012626832532

Epoch: 606| Step: 0
Training loss: 0.6429973840713501
Validation loss: 1.7899142144828715

Epoch: 5| Step: 1
Training loss: 0.6722288131713867
Validation loss: 1.8480070201299523

Epoch: 5| Step: 2
Training loss: 1.0912855863571167
Validation loss: 1.793309260440129

Epoch: 5| Step: 3
Training loss: 0.88157719373703
Validation loss: 1.758842888698783

Epoch: 5| Step: 4
Training loss: 1.0106661319732666
Validation loss: 1.7949203650156658

Epoch: 5| Step: 5
Training loss: 1.4126429557800293
Validation loss: 1.801396123824581

Epoch: 5| Step: 6
Training loss: 1.1744672060012817
Validation loss: 1.798255310263685

Epoch: 5| Step: 7
Training loss: 1.051048994064331
Validation loss: 1.8405689372811267

Epoch: 5| Step: 8
Training loss: 0.9963123202323914
Validation loss: 1.8098662899386497

Epoch: 5| Step: 9
Training loss: 0.5884910821914673
Validation loss: 1.7588867807901034

Epoch: 5| Step: 10
Training loss: 1.2486658096313477
Validation loss: 1.7774240765520322

Epoch: 607| Step: 0
Training loss: 1.1779705286026
Validation loss: 1.795391144291047

Epoch: 5| Step: 1
Training loss: 1.162543773651123
Validation loss: 1.831941440541257

Epoch: 5| Step: 2
Training loss: 1.339205265045166
Validation loss: 1.8121397495269775

Epoch: 5| Step: 3
Training loss: 1.2341585159301758
Validation loss: 1.8189913508712605

Epoch: 5| Step: 4
Training loss: 1.2983548641204834
Validation loss: 1.813767058874971

Epoch: 5| Step: 5
Training loss: 0.6625347137451172
Validation loss: 1.7976495610770358

Epoch: 5| Step: 6
Training loss: 0.8567460775375366
Validation loss: 1.8362720486938313

Epoch: 5| Step: 7
Training loss: 0.7137775421142578
Validation loss: 1.7410152855739798

Epoch: 5| Step: 8
Training loss: 0.6089843511581421
Validation loss: 1.8043659002550188

Epoch: 5| Step: 9
Training loss: 0.838273823261261
Validation loss: 1.7960521431379421

Epoch: 5| Step: 10
Training loss: 0.607294499874115
Validation loss: 1.8285091436037453

Epoch: 608| Step: 0
Training loss: 0.8192356824874878
Validation loss: 1.792445005909089

Epoch: 5| Step: 1
Training loss: 1.0396225452423096
Validation loss: 1.8049238894575386

Epoch: 5| Step: 2
Training loss: 1.4729750156402588
Validation loss: 1.795520265897115

Epoch: 5| Step: 3
Training loss: 0.8605374097824097
Validation loss: 1.8075905230737501

Epoch: 5| Step: 4
Training loss: 1.3791437149047852
Validation loss: 1.764968963079555

Epoch: 5| Step: 5
Training loss: 0.5246787071228027
Validation loss: 1.8344347630777667

Epoch: 5| Step: 6
Training loss: 1.1915452480316162
Validation loss: 1.7909134075205813

Epoch: 5| Step: 7
Training loss: 0.9167003631591797
Validation loss: 1.753532878814205

Epoch: 5| Step: 8
Training loss: 0.7357764840126038
Validation loss: 1.7859495788492181

Epoch: 5| Step: 9
Training loss: 0.8218746185302734
Validation loss: 1.7853751592738654

Epoch: 5| Step: 10
Training loss: 0.5734879970550537
Validation loss: 1.782335606954431

Epoch: 609| Step: 0
Training loss: 1.1349992752075195
Validation loss: 1.7674252781816708

Epoch: 5| Step: 1
Training loss: 0.6236758828163147
Validation loss: 1.7769482879228489

Epoch: 5| Step: 2
Training loss: 1.1268365383148193
Validation loss: 1.8068573513338644

Epoch: 5| Step: 3
Training loss: 0.7159324288368225
Validation loss: 1.7927048193511141

Epoch: 5| Step: 4
Training loss: 0.8628712892532349
Validation loss: 1.8064519218219224

Epoch: 5| Step: 5
Training loss: 1.3193724155426025
Validation loss: 1.8661305160932644

Epoch: 5| Step: 6
Training loss: 0.726831316947937
Validation loss: 1.8174614829401816

Epoch: 5| Step: 7
Training loss: 1.1015479564666748
Validation loss: 1.8228163155176307

Epoch: 5| Step: 8
Training loss: 0.9401089549064636
Validation loss: 1.8457203513832503

Epoch: 5| Step: 9
Training loss: 1.074520468711853
Validation loss: 1.8360962047371814

Epoch: 5| Step: 10
Training loss: 0.6179570555686951
Validation loss: 1.8150977229559293

Epoch: 610| Step: 0
Training loss: 1.1572692394256592
Validation loss: 1.8212306871209094

Epoch: 5| Step: 1
Training loss: 0.7251129150390625
Validation loss: 1.8354439837958223

Epoch: 5| Step: 2
Training loss: 1.3928449153900146
Validation loss: 1.7774281732497677

Epoch: 5| Step: 3
Training loss: 0.682335376739502
Validation loss: 1.7777125181690339

Epoch: 5| Step: 4
Training loss: 1.435414433479309
Validation loss: 1.7699287411987141

Epoch: 5| Step: 5
Training loss: 1.0015065670013428
Validation loss: 1.7933922544602425

Epoch: 5| Step: 6
Training loss: 0.7590328454971313
Validation loss: 1.83138737627255

Epoch: 5| Step: 7
Training loss: 0.8022505044937134
Validation loss: 1.7728615922312583

Epoch: 5| Step: 8
Training loss: 0.7145481705665588
Validation loss: 1.8339290567623672

Epoch: 5| Step: 9
Training loss: 0.920724093914032
Validation loss: 1.81747301419576

Epoch: 5| Step: 10
Training loss: 0.8556714057922363
Validation loss: 1.7436967011420959

Epoch: 611| Step: 0
Training loss: 0.7042697668075562
Validation loss: 1.805923838769236

Epoch: 5| Step: 1
Training loss: 0.9311723709106445
Validation loss: 1.8216206053251862

Epoch: 5| Step: 2
Training loss: 0.9135838747024536
Validation loss: 1.8145885544438516

Epoch: 5| Step: 3
Training loss: 0.9473875761032104
Validation loss: 1.825608068896878

Epoch: 5| Step: 4
Training loss: 0.7540669441223145
Validation loss: 1.8238116874489734

Epoch: 5| Step: 5
Training loss: 0.950093150138855
Validation loss: 1.7627774643641647

Epoch: 5| Step: 6
Training loss: 1.3396564722061157
Validation loss: 1.819948504048009

Epoch: 5| Step: 7
Training loss: 1.1044459342956543
Validation loss: 1.8272321429303897

Epoch: 5| Step: 8
Training loss: 0.9933809041976929
Validation loss: 1.8214184455974127

Epoch: 5| Step: 9
Training loss: 0.9084196090698242
Validation loss: 1.8321734807824577

Epoch: 5| Step: 10
Training loss: 0.7418388724327087
Validation loss: 1.7932667860420801

Epoch: 612| Step: 0
Training loss: 0.9825793504714966
Validation loss: 1.8530572652816772

Epoch: 5| Step: 1
Training loss: 1.4914898872375488
Validation loss: 1.8608153943092591

Epoch: 5| Step: 2
Training loss: 1.1727933883666992
Validation loss: 1.82393729430373

Epoch: 5| Step: 3
Training loss: 0.6167634725570679
Validation loss: 1.8193430567300448

Epoch: 5| Step: 4
Training loss: 0.7198426723480225
Validation loss: 1.7187734201390257

Epoch: 5| Step: 5
Training loss: 1.0617802143096924
Validation loss: 1.7873873749086935

Epoch: 5| Step: 6
Training loss: 0.9701502919197083
Validation loss: 1.8077814655919229

Epoch: 5| Step: 7
Training loss: 0.9266507029533386
Validation loss: 1.7883364628720027

Epoch: 5| Step: 8
Training loss: 0.5164483189582825
Validation loss: 1.7958343785296205

Epoch: 5| Step: 9
Training loss: 0.7473233342170715
Validation loss: 1.790836718774611

Epoch: 5| Step: 10
Training loss: 0.9475960731506348
Validation loss: 1.7757186761466406

Epoch: 613| Step: 0
Training loss: 1.0099451541900635
Validation loss: 1.8660105313024213

Epoch: 5| Step: 1
Training loss: 1.452638030052185
Validation loss: 1.8311012560321438

Epoch: 5| Step: 2
Training loss: 0.8399021029472351
Validation loss: 1.8239988767972557

Epoch: 5| Step: 3
Training loss: 1.0355969667434692
Validation loss: 1.7729434633767733

Epoch: 5| Step: 4
Training loss: 0.6641010046005249
Validation loss: 1.8449109420981458

Epoch: 5| Step: 5
Training loss: 1.091848611831665
Validation loss: 1.8251354643093642

Epoch: 5| Step: 6
Training loss: 0.6951186060905457
Validation loss: 1.785057952327113

Epoch: 5| Step: 7
Training loss: 1.1913585662841797
Validation loss: 1.8094108361069874

Epoch: 5| Step: 8
Training loss: 1.0051910877227783
Validation loss: 1.8068295268602268

Epoch: 5| Step: 9
Training loss: 0.8364655375480652
Validation loss: 1.8024346110641316

Epoch: 5| Step: 10
Training loss: 0.7857018113136292
Validation loss: 1.788189095835532

Epoch: 614| Step: 0
Training loss: 0.8328787088394165
Validation loss: 1.7902151102660804

Epoch: 5| Step: 1
Training loss: 1.0434184074401855
Validation loss: 1.8276591659874044

Epoch: 5| Step: 2
Training loss: 0.8579809069633484
Validation loss: 1.7974208375459075

Epoch: 5| Step: 3
Training loss: 0.7344084978103638
Validation loss: 1.8026782325519028

Epoch: 5| Step: 4
Training loss: 0.9769197702407837
Validation loss: 1.8051028520830217

Epoch: 5| Step: 5
Training loss: 1.2011324167251587
Validation loss: 1.773370300569842

Epoch: 5| Step: 6
Training loss: 0.7383832931518555
Validation loss: 1.8152734387305476

Epoch: 5| Step: 7
Training loss: 1.3693077564239502
Validation loss: 1.7993557248064267

Epoch: 5| Step: 8
Training loss: 0.8486072421073914
Validation loss: 1.7881471392928914

Epoch: 5| Step: 9
Training loss: 0.6206710934638977
Validation loss: 1.8008662974962624

Epoch: 5| Step: 10
Training loss: 1.0387976169586182
Validation loss: 1.8059692998086252

Epoch: 615| Step: 0
Training loss: 0.9418298602104187
Validation loss: 1.8962889345743323

Epoch: 5| Step: 1
Training loss: 0.7317425608634949
Validation loss: 1.838899495781109

Epoch: 5| Step: 2
Training loss: 0.6681495904922485
Validation loss: 1.815709606293709

Epoch: 5| Step: 3
Training loss: 0.8761776089668274
Validation loss: 1.826063270209938

Epoch: 5| Step: 4
Training loss: 1.1074283123016357
Validation loss: 1.7767982406000937

Epoch: 5| Step: 5
Training loss: 1.108628511428833
Validation loss: 1.8374606409380514

Epoch: 5| Step: 6
Training loss: 0.8963040113449097
Validation loss: 1.7792950253332815

Epoch: 5| Step: 7
Training loss: 0.9440799951553345
Validation loss: 1.8136170051431144

Epoch: 5| Step: 8
Training loss: 0.6050537824630737
Validation loss: 1.779011191860322

Epoch: 5| Step: 9
Training loss: 1.380445122718811
Validation loss: 1.817790315997216

Epoch: 5| Step: 10
Training loss: 0.8735785484313965
Validation loss: 1.7975974185492403

Epoch: 616| Step: 0
Training loss: 1.0522937774658203
Validation loss: 1.8136936695344987

Epoch: 5| Step: 1
Training loss: 0.7754258513450623
Validation loss: 1.8265555084392588

Epoch: 5| Step: 2
Training loss: 1.0995421409606934
Validation loss: 1.7780023390246975

Epoch: 5| Step: 3
Training loss: 1.1173771619796753
Validation loss: 1.8445211956577916

Epoch: 5| Step: 4
Training loss: 0.8520060777664185
Validation loss: 1.8063584258479457

Epoch: 5| Step: 5
Training loss: 1.1708672046661377
Validation loss: 1.8132999174056514

Epoch: 5| Step: 6
Training loss: 0.798861563205719
Validation loss: 1.8010412211059241

Epoch: 5| Step: 7
Training loss: 0.6162144541740417
Validation loss: 1.7647726683206455

Epoch: 5| Step: 8
Training loss: 0.6632767915725708
Validation loss: 1.7890494305600402

Epoch: 5| Step: 9
Training loss: 1.0009138584136963
Validation loss: 1.7814670339707406

Epoch: 5| Step: 10
Training loss: 1.088240623474121
Validation loss: 1.8302847467442995

Epoch: 617| Step: 0
Training loss: 0.9610109329223633
Validation loss: 1.7981821721599949

Epoch: 5| Step: 1
Training loss: 0.9846482276916504
Validation loss: 1.863488733127553

Epoch: 5| Step: 2
Training loss: 1.2270007133483887
Validation loss: 1.800225030991339

Epoch: 5| Step: 3
Training loss: 0.7608205080032349
Validation loss: 1.8340306794771584

Epoch: 5| Step: 4
Training loss: 0.7810494899749756
Validation loss: 1.7865542519477107

Epoch: 5| Step: 5
Training loss: 1.0690357685089111
Validation loss: 1.7611962172292894

Epoch: 5| Step: 6
Training loss: 1.1567003726959229
Validation loss: 1.786560796922253

Epoch: 5| Step: 7
Training loss: 1.2285583019256592
Validation loss: 1.768248252971198

Epoch: 5| Step: 8
Training loss: 0.8224619626998901
Validation loss: 1.7955246279316563

Epoch: 5| Step: 9
Training loss: 0.7299516797065735
Validation loss: 1.7791180469656502

Epoch: 5| Step: 10
Training loss: 0.5896134376525879
Validation loss: 1.7718813265523603

Epoch: 618| Step: 0
Training loss: 0.8474684953689575
Validation loss: 1.8189967806621263

Epoch: 5| Step: 1
Training loss: 1.0527889728546143
Validation loss: 1.8074446057760587

Epoch: 5| Step: 2
Training loss: 0.6528571248054504
Validation loss: 1.7669535734320199

Epoch: 5| Step: 3
Training loss: 0.7610028982162476
Validation loss: 1.80889557766658

Epoch: 5| Step: 4
Training loss: 0.751236617565155
Validation loss: 1.8058632214864094

Epoch: 5| Step: 5
Training loss: 0.8409954309463501
Validation loss: 1.7670744952335153

Epoch: 5| Step: 6
Training loss: 0.9085142016410828
Validation loss: 1.71603895771888

Epoch: 5| Step: 7
Training loss: 1.3238486051559448
Validation loss: 1.7709587133058937

Epoch: 5| Step: 8
Training loss: 0.6690894365310669
Validation loss: 1.7532627762004893

Epoch: 5| Step: 9
Training loss: 1.1139442920684814
Validation loss: 1.7617162312230756

Epoch: 5| Step: 10
Training loss: 0.6688990592956543
Validation loss: 1.8095347073770338

Epoch: 619| Step: 0
Training loss: 0.5833000540733337
Validation loss: 1.762304541885212

Epoch: 5| Step: 1
Training loss: 0.8847675323486328
Validation loss: 1.7665112556949738

Epoch: 5| Step: 2
Training loss: 0.9207953214645386
Validation loss: 1.8422153021699639

Epoch: 5| Step: 3
Training loss: 0.6740737557411194
Validation loss: 1.8159897378695908

Epoch: 5| Step: 4
Training loss: 0.9899939298629761
Validation loss: 1.7260711539176203

Epoch: 5| Step: 5
Training loss: 1.1722056865692139
Validation loss: 1.836138916271989

Epoch: 5| Step: 6
Training loss: 1.3553037643432617
Validation loss: 1.8214215027388705

Epoch: 5| Step: 7
Training loss: 0.913730263710022
Validation loss: 1.785557461041276

Epoch: 5| Step: 8
Training loss: 0.6561460494995117
Validation loss: 1.811712303469258

Epoch: 5| Step: 9
Training loss: 0.8096820116043091
Validation loss: 1.7386983594586771

Epoch: 5| Step: 10
Training loss: 0.9944971799850464
Validation loss: 1.7608685108923143

Epoch: 620| Step: 0
Training loss: 1.2295734882354736
Validation loss: 1.7585120098565215

Epoch: 5| Step: 1
Training loss: 0.714724600315094
Validation loss: 1.7585970637618855

Epoch: 5| Step: 2
Training loss: 0.6718742847442627
Validation loss: 1.7997998088918707

Epoch: 5| Step: 3
Training loss: 0.8591898083686829
Validation loss: 1.7946586352522655

Epoch: 5| Step: 4
Training loss: 0.9625600576400757
Validation loss: 1.7874867787925146

Epoch: 5| Step: 5
Training loss: 0.9148733019828796
Validation loss: 1.7613612349315355

Epoch: 5| Step: 6
Training loss: 0.8567709922790527
Validation loss: 1.790654020924722

Epoch: 5| Step: 7
Training loss: 0.8694751858711243
Validation loss: 1.8087149461110432

Epoch: 5| Step: 8
Training loss: 1.2848570346832275
Validation loss: 1.7859125547511603

Epoch: 5| Step: 9
Training loss: 1.3566863536834717
Validation loss: 1.7887162880230976

Epoch: 5| Step: 10
Training loss: 0.780849277973175
Validation loss: 1.7668953569986487

Epoch: 621| Step: 0
Training loss: 0.4675193727016449
Validation loss: 1.7923256761284285

Epoch: 5| Step: 1
Training loss: 1.223303198814392
Validation loss: 1.8534969437506892

Epoch: 5| Step: 2
Training loss: 0.6700544357299805
Validation loss: 1.7731693867714173

Epoch: 5| Step: 3
Training loss: 0.806308925151825
Validation loss: 1.7503736230634874

Epoch: 5| Step: 4
Training loss: 1.0435329675674438
Validation loss: 1.7519171237945557

Epoch: 5| Step: 5
Training loss: 0.9929601550102234
Validation loss: 1.7547854454286638

Epoch: 5| Step: 6
Training loss: 0.8889421224594116
Validation loss: 1.836221452682249

Epoch: 5| Step: 7
Training loss: 1.1592721939086914
Validation loss: 1.80773707999978

Epoch: 5| Step: 8
Training loss: 1.0391396284103394
Validation loss: 1.7362269381041169

Epoch: 5| Step: 9
Training loss: 1.2013956308364868
Validation loss: 1.8495816594810897

Epoch: 5| Step: 10
Training loss: 1.2101339101791382
Validation loss: 1.8182690310221847

Epoch: 622| Step: 0
Training loss: 1.0089499950408936
Validation loss: 1.8180081088055846

Epoch: 5| Step: 1
Training loss: 1.0777702331542969
Validation loss: 1.8392333933102187

Epoch: 5| Step: 2
Training loss: 0.6242195963859558
Validation loss: 1.827510231284685

Epoch: 5| Step: 3
Training loss: 0.9567254781723022
Validation loss: 1.8246222952360749

Epoch: 5| Step: 4
Training loss: 1.0222632884979248
Validation loss: 1.8264980162343671

Epoch: 5| Step: 5
Training loss: 0.9174960255622864
Validation loss: 1.799450409027838

Epoch: 5| Step: 6
Training loss: 1.1668224334716797
Validation loss: 1.732633989344361

Epoch: 5| Step: 7
Training loss: 1.0028257369995117
Validation loss: 1.8326827210764731

Epoch: 5| Step: 8
Training loss: 0.7867162823677063
Validation loss: 1.788812634765461

Epoch: 5| Step: 9
Training loss: 0.6975243091583252
Validation loss: 1.721312956143451

Epoch: 5| Step: 10
Training loss: 0.7791875004768372
Validation loss: 1.7734063389480754

Epoch: 623| Step: 0
Training loss: 0.8398721814155579
Validation loss: 1.826994797234894

Epoch: 5| Step: 1
Training loss: 0.6382141709327698
Validation loss: 1.795975253146182

Epoch: 5| Step: 2
Training loss: 0.9149702787399292
Validation loss: 1.791962162140877

Epoch: 5| Step: 3
Training loss: 1.4349688291549683
Validation loss: 1.8062896331151326

Epoch: 5| Step: 4
Training loss: 0.8986175656318665
Validation loss: 1.7797908065139607

Epoch: 5| Step: 5
Training loss: 0.7384042143821716
Validation loss: 1.7665067885511665

Epoch: 5| Step: 6
Training loss: 0.9233232736587524
Validation loss: 1.819949419267716

Epoch: 5| Step: 7
Training loss: 0.6479901075363159
Validation loss: 1.818021487164241

Epoch: 5| Step: 8
Training loss: 0.8760875463485718
Validation loss: 1.7688223520914714

Epoch: 5| Step: 9
Training loss: 1.3103481531143188
Validation loss: 1.78356752087993

Epoch: 5| Step: 10
Training loss: 0.9568257331848145
Validation loss: 1.7909406359477709

Epoch: 624| Step: 0
Training loss: 0.6727983951568604
Validation loss: 1.8512235610715804

Epoch: 5| Step: 1
Training loss: 1.5433822870254517
Validation loss: 1.7663472006397862

Epoch: 5| Step: 2
Training loss: 0.6172687411308289
Validation loss: 1.7908293739441903

Epoch: 5| Step: 3
Training loss: 0.7119821310043335
Validation loss: 1.8232654230568999

Epoch: 5| Step: 4
Training loss: 1.013454794883728
Validation loss: 1.8475199367410393

Epoch: 5| Step: 5
Training loss: 1.0525486469268799
Validation loss: 1.7737895852775984

Epoch: 5| Step: 6
Training loss: 0.9306289553642273
Validation loss: 1.8360418901648572

Epoch: 5| Step: 7
Training loss: 1.2040882110595703
Validation loss: 1.8451270364945935

Epoch: 5| Step: 8
Training loss: 0.6910310983657837
Validation loss: 1.7606120263376543

Epoch: 5| Step: 9
Training loss: 1.0133793354034424
Validation loss: 1.7876942747382707

Epoch: 5| Step: 10
Training loss: 0.6188750267028809
Validation loss: 1.8198573576506747

Epoch: 625| Step: 0
Training loss: 1.4503402709960938
Validation loss: 1.8112538796599194

Epoch: 5| Step: 1
Training loss: 0.5755044221878052
Validation loss: 1.821242932350405

Epoch: 5| Step: 2
Training loss: 0.7947356104850769
Validation loss: 1.7751065941267117

Epoch: 5| Step: 3
Training loss: 1.2162573337554932
Validation loss: 1.8243199215140393

Epoch: 5| Step: 4
Training loss: 0.9268392324447632
Validation loss: 1.796591765137129

Epoch: 5| Step: 5
Training loss: 0.6440271139144897
Validation loss: 1.7587355695744997

Epoch: 5| Step: 6
Training loss: 0.7166426777839661
Validation loss: 1.777640946449772

Epoch: 5| Step: 7
Training loss: 0.8278929591178894
Validation loss: 1.8169827576606505

Epoch: 5| Step: 8
Training loss: 0.951014518737793
Validation loss: 1.7934555853566816

Epoch: 5| Step: 9
Training loss: 0.7112284898757935
Validation loss: 1.7427962762053295

Epoch: 5| Step: 10
Training loss: 0.894026517868042
Validation loss: 1.8389885784477316

Epoch: 626| Step: 0
Training loss: 1.310756802558899
Validation loss: 1.7732769263687955

Epoch: 5| Step: 1
Training loss: 0.7102128267288208
Validation loss: 1.7908178388431508

Epoch: 5| Step: 2
Training loss: 1.040299415588379
Validation loss: 1.7278434986709266

Epoch: 5| Step: 3
Training loss: 0.76920485496521
Validation loss: 1.814060995655675

Epoch: 5| Step: 4
Training loss: 1.0314942598342896
Validation loss: 1.8157291207262265

Epoch: 5| Step: 5
Training loss: 1.0680649280548096
Validation loss: 1.7758755209625408

Epoch: 5| Step: 6
Training loss: 0.8791453242301941
Validation loss: 1.8021396539544547

Epoch: 5| Step: 7
Training loss: 0.709549069404602
Validation loss: 1.7863574181833575

Epoch: 5| Step: 8
Training loss: 1.0778175592422485
Validation loss: 1.8237512906392415

Epoch: 5| Step: 9
Training loss: 0.7191838622093201
Validation loss: 1.857282239903686

Epoch: 5| Step: 10
Training loss: 0.8793171048164368
Validation loss: 1.7693321294682

Epoch: 627| Step: 0
Training loss: 0.8351548314094543
Validation loss: 1.8158223552088584

Epoch: 5| Step: 1
Training loss: 0.8774367570877075
Validation loss: 1.8016427409264348

Epoch: 5| Step: 2
Training loss: 1.1676781177520752
Validation loss: 1.796582119439238

Epoch: 5| Step: 3
Training loss: 0.9204904437065125
Validation loss: 1.7627710168079664

Epoch: 5| Step: 4
Training loss: 1.3867533206939697
Validation loss: 1.8432372616183372

Epoch: 5| Step: 5
Training loss: 0.5191648602485657
Validation loss: 1.7516962533356042

Epoch: 5| Step: 6
Training loss: 0.7827914953231812
Validation loss: 1.7680892944335938

Epoch: 5| Step: 7
Training loss: 0.769668698310852
Validation loss: 1.7774012768140404

Epoch: 5| Step: 8
Training loss: 1.0116815567016602
Validation loss: 1.7512465805135748

Epoch: 5| Step: 9
Training loss: 0.7899073362350464
Validation loss: 1.781837251878554

Epoch: 5| Step: 10
Training loss: 0.8064129948616028
Validation loss: 1.7862371372920212

Epoch: 628| Step: 0
Training loss: 1.1744250059127808
Validation loss: 1.6640654148594025

Epoch: 5| Step: 1
Training loss: 0.5960590839385986
Validation loss: 1.7879261765428769

Epoch: 5| Step: 2
Training loss: 0.9925300478935242
Validation loss: 1.8082147990503619

Epoch: 5| Step: 3
Training loss: 0.6109089851379395
Validation loss: 1.733792071701378

Epoch: 5| Step: 4
Training loss: 0.8371049761772156
Validation loss: 1.7368789718997093

Epoch: 5| Step: 5
Training loss: 0.9404158592224121
Validation loss: 1.7892490843290925

Epoch: 5| Step: 6
Training loss: 0.9364717602729797
Validation loss: 1.7808423362752444

Epoch: 5| Step: 7
Training loss: 0.8844385147094727
Validation loss: 1.791245246446261

Epoch: 5| Step: 8
Training loss: 0.8786755800247192
Validation loss: 1.7744971500929965

Epoch: 5| Step: 9
Training loss: 0.6894696354866028
Validation loss: 1.7903493591534194

Epoch: 5| Step: 10
Training loss: 1.7311958074569702
Validation loss: 1.7743540271635978

Epoch: 629| Step: 0
Training loss: 0.8670093417167664
Validation loss: 1.7495491940488097

Epoch: 5| Step: 1
Training loss: 0.8545335531234741
Validation loss: 1.772320890939364

Epoch: 5| Step: 2
Training loss: 1.170765995979309
Validation loss: 1.7666112774161882

Epoch: 5| Step: 3
Training loss: 0.9982074499130249
Validation loss: 1.8235358730439217

Epoch: 5| Step: 4
Training loss: 0.6453226804733276
Validation loss: 1.8417035559172272

Epoch: 5| Step: 5
Training loss: 1.1638050079345703
Validation loss: 1.8108756490932998

Epoch: 5| Step: 6
Training loss: 0.6468809843063354
Validation loss: 1.7579713303555724

Epoch: 5| Step: 7
Training loss: 0.9758210182189941
Validation loss: 1.8124307458118727

Epoch: 5| Step: 8
Training loss: 0.8322471380233765
Validation loss: 1.7888648894525343

Epoch: 5| Step: 9
Training loss: 1.0734748840332031
Validation loss: 1.8050751429732128

Epoch: 5| Step: 10
Training loss: 0.8173776268959045
Validation loss: 1.8004014774035382

Epoch: 630| Step: 0
Training loss: 0.8851693868637085
Validation loss: 1.7880915275184057

Epoch: 5| Step: 1
Training loss: 0.6831651926040649
Validation loss: 1.7951454641998454

Epoch: 5| Step: 2
Training loss: 1.054778814315796
Validation loss: 1.8496243953704834

Epoch: 5| Step: 3
Training loss: 0.47162070870399475
Validation loss: 1.762592270810117

Epoch: 5| Step: 4
Training loss: 0.9509810209274292
Validation loss: 1.7251273624358638

Epoch: 5| Step: 5
Training loss: 0.8372400999069214
Validation loss: 1.7965709701661141

Epoch: 5| Step: 6
Training loss: 0.5008489489555359
Validation loss: 1.7343549484847693

Epoch: 5| Step: 7
Training loss: 0.9435268640518188
Validation loss: 1.7161828215404222

Epoch: 5| Step: 8
Training loss: 1.1092418432235718
Validation loss: 1.7704234469321467

Epoch: 5| Step: 9
Training loss: 1.0465835332870483
Validation loss: 1.7994258685778546

Epoch: 5| Step: 10
Training loss: 1.4809902906417847
Validation loss: 1.7648386045168805

Epoch: 631| Step: 0
Training loss: 0.9998306035995483
Validation loss: 1.7839154120414489

Epoch: 5| Step: 1
Training loss: 0.6342798471450806
Validation loss: 1.7961829529013684

Epoch: 5| Step: 2
Training loss: 0.8594492077827454
Validation loss: 1.8165220124747163

Epoch: 5| Step: 3
Training loss: 0.8369666337966919
Validation loss: 1.762889459568967

Epoch: 5| Step: 4
Training loss: 1.1969503164291382
Validation loss: 1.7656909676008328

Epoch: 5| Step: 5
Training loss: 0.5869584083557129
Validation loss: 1.7668152752742972

Epoch: 5| Step: 6
Training loss: 1.2849788665771484
Validation loss: 1.8110213997543498

Epoch: 5| Step: 7
Training loss: 1.0056136846542358
Validation loss: 1.7566452385276876

Epoch: 5| Step: 8
Training loss: 0.9533330798149109
Validation loss: 1.7462211821668892

Epoch: 5| Step: 9
Training loss: 0.4510739743709564
Validation loss: 1.7665710000581638

Epoch: 5| Step: 10
Training loss: 1.1952457427978516
Validation loss: 1.8148933482426468

Epoch: 632| Step: 0
Training loss: 0.8322335481643677
Validation loss: 1.756756313385502

Epoch: 5| Step: 1
Training loss: 0.7939205765724182
Validation loss: 1.7606610521193473

Epoch: 5| Step: 2
Training loss: 1.1637879610061646
Validation loss: 1.7901520293246034

Epoch: 5| Step: 3
Training loss: 0.8757699131965637
Validation loss: 1.847673172591835

Epoch: 5| Step: 4
Training loss: 0.8833502531051636
Validation loss: 1.7623233795166016

Epoch: 5| Step: 5
Training loss: 0.8478401303291321
Validation loss: 1.7737419387345672

Epoch: 5| Step: 6
Training loss: 0.868548572063446
Validation loss: 1.7814797022009408

Epoch: 5| Step: 7
Training loss: 0.867228627204895
Validation loss: 1.777551858655868

Epoch: 5| Step: 8
Training loss: 0.6839226484298706
Validation loss: 1.7640421275169618

Epoch: 5| Step: 9
Training loss: 0.8497022390365601
Validation loss: 1.7886664431582215

Epoch: 5| Step: 10
Training loss: 0.7673527598381042
Validation loss: 1.8175911621380878

Epoch: 633| Step: 0
Training loss: 0.9226852655410767
Validation loss: 1.7401678664709932

Epoch: 5| Step: 1
Training loss: 1.3273435831069946
Validation loss: 1.7396294147737565

Epoch: 5| Step: 2
Training loss: 0.5015883445739746
Validation loss: 1.7386449408787552

Epoch: 5| Step: 3
Training loss: 0.8795021772384644
Validation loss: 1.7808900071728615

Epoch: 5| Step: 4
Training loss: 0.8433063626289368
Validation loss: 1.782256587859123

Epoch: 5| Step: 5
Training loss: 1.3376569747924805
Validation loss: 1.7803832510466218

Epoch: 5| Step: 6
Training loss: 0.8051323890686035
Validation loss: 1.839877777202155

Epoch: 5| Step: 7
Training loss: 0.6760441660881042
Validation loss: 1.7824964971952542

Epoch: 5| Step: 8
Training loss: 1.2261834144592285
Validation loss: 1.7707305172438264

Epoch: 5| Step: 9
Training loss: 0.8885456323623657
Validation loss: 1.7830103276878275

Epoch: 5| Step: 10
Training loss: 0.7333469986915588
Validation loss: 1.7620488982046805

Epoch: 634| Step: 0
Training loss: 0.6645668745040894
Validation loss: 1.8025474753431094

Epoch: 5| Step: 1
Training loss: 0.7428223490715027
Validation loss: 1.7384102690604426

Epoch: 5| Step: 2
Training loss: 0.8659726977348328
Validation loss: 1.7271184536718553

Epoch: 5| Step: 3
Training loss: 0.8881853818893433
Validation loss: 1.763024514721286

Epoch: 5| Step: 4
Training loss: 1.295837640762329
Validation loss: 1.7093663138727988

Epoch: 5| Step: 5
Training loss: 1.0870773792266846
Validation loss: 1.8064362310594129

Epoch: 5| Step: 6
Training loss: 0.646949291229248
Validation loss: 1.7613213139195596

Epoch: 5| Step: 7
Training loss: 0.8394312858581543
Validation loss: 1.827292069312065

Epoch: 5| Step: 8
Training loss: 0.6495623588562012
Validation loss: 1.819449887480787

Epoch: 5| Step: 9
Training loss: 1.197076439857483
Validation loss: 1.822469295993928

Epoch: 5| Step: 10
Training loss: 0.9031978249549866
Validation loss: 1.7217040267041934

Epoch: 635| Step: 0
Training loss: 1.071596384048462
Validation loss: 1.7872901962649437

Epoch: 5| Step: 1
Training loss: 0.8913162350654602
Validation loss: 1.836250005229827

Epoch: 5| Step: 2
Training loss: 0.7533506155014038
Validation loss: 1.7646936062843568

Epoch: 5| Step: 3
Training loss: 0.9394199252128601
Validation loss: 1.8073666082915438

Epoch: 5| Step: 4
Training loss: 0.9103166460990906
Validation loss: 1.751452528020387

Epoch: 5| Step: 5
Training loss: 1.0307066440582275
Validation loss: 1.790109161407717

Epoch: 5| Step: 6
Training loss: 0.354472815990448
Validation loss: 1.7649428793179092

Epoch: 5| Step: 7
Training loss: 0.7898808717727661
Validation loss: 1.722275628838488

Epoch: 5| Step: 8
Training loss: 0.866439938545227
Validation loss: 1.795179723411478

Epoch: 5| Step: 9
Training loss: 0.9033175706863403
Validation loss: 1.800038141589011

Epoch: 5| Step: 10
Training loss: 1.4957813024520874
Validation loss: 1.7919637451889694

Epoch: 636| Step: 0
Training loss: 0.8838849067687988
Validation loss: 1.7549811204274495

Epoch: 5| Step: 1
Training loss: 0.6329690217971802
Validation loss: 1.7605856977483278

Epoch: 5| Step: 2
Training loss: 0.8321467638015747
Validation loss: 1.7637305285340996

Epoch: 5| Step: 3
Training loss: 0.7706908583641052
Validation loss: 1.785453611804593

Epoch: 5| Step: 4
Training loss: 1.1021414995193481
Validation loss: 1.7822020502500637

Epoch: 5| Step: 5
Training loss: 0.9083733558654785
Validation loss: 1.7809032958040956

Epoch: 5| Step: 6
Training loss: 1.0776305198669434
Validation loss: 1.7933934401440363

Epoch: 5| Step: 7
Training loss: 1.0177804231643677
Validation loss: 1.7730490802436747

Epoch: 5| Step: 8
Training loss: 1.151764988899231
Validation loss: 1.7527759344347063

Epoch: 5| Step: 9
Training loss: 0.8994496464729309
Validation loss: 1.7791154256431005

Epoch: 5| Step: 10
Training loss: 0.7037702202796936
Validation loss: 1.843059325730929

Epoch: 637| Step: 0
Training loss: 0.5028499364852905
Validation loss: 1.8124464224743586

Epoch: 5| Step: 1
Training loss: 1.0443180799484253
Validation loss: 1.7529481328943723

Epoch: 5| Step: 2
Training loss: 0.6529949307441711
Validation loss: 1.801487527867799

Epoch: 5| Step: 3
Training loss: 1.068608045578003
Validation loss: 1.768881268398736

Epoch: 5| Step: 4
Training loss: 1.1648879051208496
Validation loss: 1.809270425509381

Epoch: 5| Step: 5
Training loss: 0.8147643208503723
Validation loss: 1.7561126998675767

Epoch: 5| Step: 6
Training loss: 0.963544487953186
Validation loss: 1.8075442057783886

Epoch: 5| Step: 7
Training loss: 1.0540711879730225
Validation loss: 1.74923574924469

Epoch: 5| Step: 8
Training loss: 0.8874635696411133
Validation loss: 1.7600273509179392

Epoch: 5| Step: 9
Training loss: 0.8787000775337219
Validation loss: 1.7849461493953582

Epoch: 5| Step: 10
Training loss: 1.0827800035476685
Validation loss: 1.7879232616834744

Epoch: 638| Step: 0
Training loss: 0.8442746996879578
Validation loss: 1.8138486518654773

Epoch: 5| Step: 1
Training loss: 0.9051586389541626
Validation loss: 1.7519236328781291

Epoch: 5| Step: 2
Training loss: 1.115928292274475
Validation loss: 1.8154733168181552

Epoch: 5| Step: 3
Training loss: 0.8570443987846375
Validation loss: 1.7453128599351453

Epoch: 5| Step: 4
Training loss: 1.0158926248550415
Validation loss: 1.7760910654580722

Epoch: 5| Step: 5
Training loss: 1.232010006904602
Validation loss: 1.8123640065552087

Epoch: 5| Step: 6
Training loss: 0.9036375284194946
Validation loss: 1.8266680932814074

Epoch: 5| Step: 7
Training loss: 0.538091778755188
Validation loss: 1.8537632957581551

Epoch: 5| Step: 8
Training loss: 0.6859302520751953
Validation loss: 1.8414277210030505

Epoch: 5| Step: 9
Training loss: 0.8370173573493958
Validation loss: 1.7895532320904475

Epoch: 5| Step: 10
Training loss: 0.7632582187652588
Validation loss: 1.7801808593093709

Epoch: 639| Step: 0
Training loss: 0.8523054122924805
Validation loss: 1.7966653390597271

Epoch: 5| Step: 1
Training loss: 0.623266875743866
Validation loss: 1.792957789154463

Epoch: 5| Step: 2
Training loss: 0.6556035876274109
Validation loss: 1.7879388550276398

Epoch: 5| Step: 3
Training loss: 0.7687448263168335
Validation loss: 1.739882792195966

Epoch: 5| Step: 4
Training loss: 1.4190105199813843
Validation loss: 1.7840854416611374

Epoch: 5| Step: 5
Training loss: 1.1241519451141357
Validation loss: 1.8028011975749847

Epoch: 5| Step: 6
Training loss: 0.834274172782898
Validation loss: 1.7584493775521555

Epoch: 5| Step: 7
Training loss: 1.1860973834991455
Validation loss: 1.7479222333559425

Epoch: 5| Step: 8
Training loss: 0.5872839689254761
Validation loss: 1.776997015040408

Epoch: 5| Step: 9
Training loss: 1.0883811712265015
Validation loss: 1.7888520750948178

Epoch: 5| Step: 10
Training loss: 0.6304616928100586
Validation loss: 1.807575205320953

Epoch: 640| Step: 0
Training loss: 0.9422948956489563
Validation loss: 1.769846930298754

Epoch: 5| Step: 1
Training loss: 1.0483037233352661
Validation loss: 1.7743020262769473

Epoch: 5| Step: 2
Training loss: 0.5961513519287109
Validation loss: 1.7808352990816998

Epoch: 5| Step: 3
Training loss: 1.1649550199508667
Validation loss: 1.783299220505581

Epoch: 5| Step: 4
Training loss: 0.787990152835846
Validation loss: 1.8318086401108773

Epoch: 5| Step: 5
Training loss: 0.6187826991081238
Validation loss: 1.7218699468079435

Epoch: 5| Step: 6
Training loss: 0.6929720640182495
Validation loss: 1.7721166097989647

Epoch: 5| Step: 7
Training loss: 1.024390459060669
Validation loss: 1.7766693638217064

Epoch: 5| Step: 8
Training loss: 0.937195897102356
Validation loss: 1.7646395660215808

Epoch: 5| Step: 9
Training loss: 0.857115626335144
Validation loss: 1.7726357995822866

Epoch: 5| Step: 10
Training loss: 0.7511298060417175
Validation loss: 1.7587492850518995

Epoch: 641| Step: 0
Training loss: 0.9684011340141296
Validation loss: 1.800976235379455

Epoch: 5| Step: 1
Training loss: 0.9097729921340942
Validation loss: 1.781124194463094

Epoch: 5| Step: 2
Training loss: 1.1358855962753296
Validation loss: 1.8169923187584005

Epoch: 5| Step: 3
Training loss: 1.1450467109680176
Validation loss: 1.7966673399812432

Epoch: 5| Step: 4
Training loss: 0.8150255084037781
Validation loss: 1.7518653305627967

Epoch: 5| Step: 5
Training loss: 0.9538007974624634
Validation loss: 1.7482793151691396

Epoch: 5| Step: 6
Training loss: 0.5324434638023376
Validation loss: 1.7628588061178885

Epoch: 5| Step: 7
Training loss: 0.996468722820282
Validation loss: 1.8709308921649892

Epoch: 5| Step: 8
Training loss: 0.7155064940452576
Validation loss: 1.7327445489104076

Epoch: 5| Step: 9
Training loss: 0.5110531449317932
Validation loss: 1.8082062851998113

Epoch: 5| Step: 10
Training loss: 0.9303702116012573
Validation loss: 1.7595749016731017

Epoch: 642| Step: 0
Training loss: 0.6771537661552429
Validation loss: 1.7442153192335559

Epoch: 5| Step: 1
Training loss: 0.8139215707778931
Validation loss: 1.7302663146808583

Epoch: 5| Step: 2
Training loss: 0.8018256425857544
Validation loss: 1.7484818158611175

Epoch: 5| Step: 3
Training loss: 0.806843638420105
Validation loss: 1.8493223536399104

Epoch: 5| Step: 4
Training loss: 1.123523473739624
Validation loss: 1.7203544211643997

Epoch: 5| Step: 5
Training loss: 0.7410674691200256
Validation loss: 1.7521982731357697

Epoch: 5| Step: 6
Training loss: 1.6418861150741577
Validation loss: 1.77444528636112

Epoch: 5| Step: 7
Training loss: 1.069361686706543
Validation loss: 1.756268624336489

Epoch: 5| Step: 8
Training loss: 1.0089011192321777
Validation loss: 1.758988977760397

Epoch: 5| Step: 9
Training loss: 0.8020215034484863
Validation loss: 1.74397752874641

Epoch: 5| Step: 10
Training loss: 0.6063370704650879
Validation loss: 1.7612035351414834

Epoch: 643| Step: 0
Training loss: 1.0864187479019165
Validation loss: 1.7957293025908931

Epoch: 5| Step: 1
Training loss: 0.8677741885185242
Validation loss: 1.7914829600241877

Epoch: 5| Step: 2
Training loss: 1.1814801692962646
Validation loss: 1.8183314236261512

Epoch: 5| Step: 3
Training loss: 1.0074254274368286
Validation loss: 1.762284517288208

Epoch: 5| Step: 4
Training loss: 1.1260976791381836
Validation loss: 1.7381613690366027

Epoch: 5| Step: 5
Training loss: 0.6275654435157776
Validation loss: 1.7516697555459955

Epoch: 5| Step: 6
Training loss: 0.5940221548080444
Validation loss: 1.839612099432176

Epoch: 5| Step: 7
Training loss: 0.7876712679862976
Validation loss: 1.783353890142133

Epoch: 5| Step: 8
Training loss: 0.7358870506286621
Validation loss: 1.7812627348848569

Epoch: 5| Step: 9
Training loss: 0.6966713070869446
Validation loss: 1.7597925175902664

Epoch: 5| Step: 10
Training loss: 0.808688223361969
Validation loss: 1.7297697528716056

Epoch: 644| Step: 0
Training loss: 0.9352401494979858
Validation loss: 1.7427192734133812

Epoch: 5| Step: 1
Training loss: 0.7292001843452454
Validation loss: 1.806499360710062

Epoch: 5| Step: 2
Training loss: 1.420248031616211
Validation loss: 1.7597153225252706

Epoch: 5| Step: 3
Training loss: 1.0244057178497314
Validation loss: 1.779314721784284

Epoch: 5| Step: 4
Training loss: 1.1353195905685425
Validation loss: 1.7917406174444384

Epoch: 5| Step: 5
Training loss: 0.8359082937240601
Validation loss: 1.7993313061293734

Epoch: 5| Step: 6
Training loss: 0.8254005312919617
Validation loss: 1.7572813444240118

Epoch: 5| Step: 7
Training loss: 0.7163442373275757
Validation loss: 1.7032879808897614

Epoch: 5| Step: 8
Training loss: 0.7712294459342957
Validation loss: 1.7774512075608777

Epoch: 5| Step: 9
Training loss: 1.076283574104309
Validation loss: 1.8104987118833809

Epoch: 5| Step: 10
Training loss: 0.35259053111076355
Validation loss: 1.7750275429858957

Epoch: 645| Step: 0
Training loss: 0.7863037586212158
Validation loss: 1.7684953007646786

Epoch: 5| Step: 1
Training loss: 0.7371253371238708
Validation loss: 1.7441989337244341

Epoch: 5| Step: 2
Training loss: 0.6086516976356506
Validation loss: 1.7683501615319202

Epoch: 5| Step: 3
Training loss: 0.8582147359848022
Validation loss: 1.7934426838351833

Epoch: 5| Step: 4
Training loss: 0.8376256823539734
Validation loss: 1.7917818484767791

Epoch: 5| Step: 5
Training loss: 1.097641944885254
Validation loss: 1.7698532022455686

Epoch: 5| Step: 6
Training loss: 0.5617581605911255
Validation loss: 1.7741877391774168

Epoch: 5| Step: 7
Training loss: 0.9716914892196655
Validation loss: 1.7361739630340247

Epoch: 5| Step: 8
Training loss: 0.8859186172485352
Validation loss: 1.7149244828890728

Epoch: 5| Step: 9
Training loss: 0.58428555727005
Validation loss: 1.811364801981116

Epoch: 5| Step: 10
Training loss: 1.7790499925613403
Validation loss: 1.8281118523690008

Epoch: 646| Step: 0
Training loss: 0.7641460299491882
Validation loss: 1.8292059078011462

Epoch: 5| Step: 1
Training loss: 0.8217253684997559
Validation loss: 1.7627375138703214

Epoch: 5| Step: 2
Training loss: 1.325243353843689
Validation loss: 1.719512495943295

Epoch: 5| Step: 3
Training loss: 0.5565527677536011
Validation loss: 1.722284818208346

Epoch: 5| Step: 4
Training loss: 0.9791914224624634
Validation loss: 1.7995396557674612

Epoch: 5| Step: 5
Training loss: 0.7212904691696167
Validation loss: 1.7690999969359367

Epoch: 5| Step: 6
Training loss: 0.6476994752883911
Validation loss: 1.734993000184336

Epoch: 5| Step: 7
Training loss: 0.9339207410812378
Validation loss: 1.8161698413151566

Epoch: 5| Step: 8
Training loss: 1.0807005167007446
Validation loss: 1.7724743594405472

Epoch: 5| Step: 9
Training loss: 1.1542346477508545
Validation loss: 1.7446031429434334

Epoch: 5| Step: 10
Training loss: 0.7276328206062317
Validation loss: 1.709668005666425

Epoch: 647| Step: 0
Training loss: 0.8068063855171204
Validation loss: 1.7878649388590167

Epoch: 5| Step: 1
Training loss: 0.5580347776412964
Validation loss: 1.8305131825067664

Epoch: 5| Step: 2
Training loss: 0.8960945010185242
Validation loss: 1.831636926179291

Epoch: 5| Step: 3
Training loss: 0.2928844392299652
Validation loss: 1.7911854187647502

Epoch: 5| Step: 4
Training loss: 1.0568768978118896
Validation loss: 1.78097306272035

Epoch: 5| Step: 5
Training loss: 1.3383712768554688
Validation loss: 1.8247397227953839

Epoch: 5| Step: 6
Training loss: 0.5812357664108276
Validation loss: 1.7935984724311418

Epoch: 5| Step: 7
Training loss: 1.08189058303833
Validation loss: 1.8263961948374265

Epoch: 5| Step: 8
Training loss: 1.1657475233078003
Validation loss: 1.7006839552233297

Epoch: 5| Step: 9
Training loss: 0.8212674856185913
Validation loss: 1.7484918525142055

Epoch: 5| Step: 10
Training loss: 1.087609052658081
Validation loss: 1.7525747668358587

Epoch: 648| Step: 0
Training loss: 0.9628227949142456
Validation loss: 1.716216714151444

Epoch: 5| Step: 1
Training loss: 1.652022123336792
Validation loss: 1.7413813529476043

Epoch: 5| Step: 2
Training loss: 0.6588461995124817
Validation loss: 1.8193478494562128

Epoch: 5| Step: 3
Training loss: 0.5258935689926147
Validation loss: 1.765552113133092

Epoch: 5| Step: 4
Training loss: 0.9117339849472046
Validation loss: 1.8156639055539203

Epoch: 5| Step: 5
Training loss: 0.916845977306366
Validation loss: 1.7853519506351923

Epoch: 5| Step: 6
Training loss: 0.9038538932800293
Validation loss: 1.7703652484442598

Epoch: 5| Step: 7
Training loss: 0.6937199831008911
Validation loss: 1.8148004149877897

Epoch: 5| Step: 8
Training loss: 0.8122326135635376
Validation loss: 1.7653697152291574

Epoch: 5| Step: 9
Training loss: 0.9225157499313354
Validation loss: 1.8292293099946872

Epoch: 5| Step: 10
Training loss: 0.8494267463684082
Validation loss: 1.7504966066729637

Epoch: 649| Step: 0
Training loss: 1.1168043613433838
Validation loss: 1.7651775831817298

Epoch: 5| Step: 1
Training loss: 0.9123882055282593
Validation loss: 1.7726604105323873

Epoch: 5| Step: 2
Training loss: 0.8656892776489258
Validation loss: 1.8017316441382132

Epoch: 5| Step: 3
Training loss: 0.9703024625778198
Validation loss: 1.8136944488812519

Epoch: 5| Step: 4
Training loss: 0.6636328101158142
Validation loss: 1.8207360890603834

Epoch: 5| Step: 5
Training loss: 0.816016674041748
Validation loss: 1.833326797331533

Epoch: 5| Step: 6
Training loss: 0.8835594058036804
Validation loss: 1.788617850631796

Epoch: 5| Step: 7
Training loss: 0.7885287404060364
Validation loss: 1.7313749123645086

Epoch: 5| Step: 8
Training loss: 0.6445814371109009
Validation loss: 1.833762361157325

Epoch: 5| Step: 9
Training loss: 1.1251055002212524
Validation loss: 1.7765479177557013

Epoch: 5| Step: 10
Training loss: 0.9517405033111572
Validation loss: 1.8187052370399557

Epoch: 650| Step: 0
Training loss: 1.0335749387741089
Validation loss: 1.8026601473490398

Epoch: 5| Step: 1
Training loss: 1.0246332883834839
Validation loss: 1.7572330518435406

Epoch: 5| Step: 2
Training loss: 0.8973425626754761
Validation loss: 1.7893710533777873

Epoch: 5| Step: 3
Training loss: 0.8192815780639648
Validation loss: 1.8266618802983274

Epoch: 5| Step: 4
Training loss: 0.40517234802246094
Validation loss: 1.8076686525857577

Epoch: 5| Step: 5
Training loss: 0.7513049840927124
Validation loss: 1.7456015104888587

Epoch: 5| Step: 6
Training loss: 1.0157454013824463
Validation loss: 1.7722033864708358

Epoch: 5| Step: 7
Training loss: 0.9613855481147766
Validation loss: 1.7992821303747033

Epoch: 5| Step: 8
Training loss: 0.7378201484680176
Validation loss: 1.7976964148142005

Epoch: 5| Step: 9
Training loss: 1.2281183004379272
Validation loss: 1.7861730475579538

Epoch: 5| Step: 10
Training loss: 1.0154410600662231
Validation loss: 1.7729027155906922

Testing loss: 2.3687325186199613
