Epoch: 1| Step: 0
Training loss: 5.240149021148682
Validation loss: 5.0673022526566704

Epoch: 5| Step: 1
Training loss: 5.491316318511963
Validation loss: 5.063162372958276

Epoch: 5| Step: 2
Training loss: 4.7132487297058105
Validation loss: 5.0591210908787225

Epoch: 5| Step: 3
Training loss: 4.627890586853027
Validation loss: 5.053926442259101

Epoch: 5| Step: 4
Training loss: 4.755303859710693
Validation loss: 5.049163244103872

Epoch: 5| Step: 5
Training loss: 5.866237640380859
Validation loss: 5.044864828868579

Epoch: 5| Step: 6
Training loss: 5.781414031982422
Validation loss: 5.039542316108622

Epoch: 5| Step: 7
Training loss: 4.356146812438965
Validation loss: 5.0347142680998775

Epoch: 5| Step: 8
Training loss: 3.803623914718628
Validation loss: 5.031000296274821

Epoch: 5| Step: 9
Training loss: 4.904313087463379
Validation loss: 5.026785871034027

Epoch: 5| Step: 10
Training loss: 3.544511318206787
Validation loss: 5.021640505841983

Epoch: 2| Step: 0
Training loss: 4.799289703369141
Validation loss: 5.019119237058906

Epoch: 5| Step: 1
Training loss: 4.418618202209473
Validation loss: 5.013296599029212

Epoch: 5| Step: 2
Training loss: 4.738722324371338
Validation loss: 5.008154987007059

Epoch: 5| Step: 3
Training loss: 4.6142425537109375
Validation loss: 5.002599147058302

Epoch: 5| Step: 4
Training loss: 4.883663654327393
Validation loss: 4.9991138417233705

Epoch: 5| Step: 5
Training loss: 4.313307762145996
Validation loss: 4.993707318459788

Epoch: 5| Step: 6
Training loss: 5.329958915710449
Validation loss: 4.990727352839644

Epoch: 5| Step: 7
Training loss: 5.27575159072876
Validation loss: 4.98613259612873

Epoch: 5| Step: 8
Training loss: 5.202940464019775
Validation loss: 4.981067237033639

Epoch: 5| Step: 9
Training loss: 5.6551833152771
Validation loss: 4.976189439014722

Epoch: 5| Step: 10
Training loss: 3.2454721927642822
Validation loss: 4.971076252639935

Epoch: 3| Step: 0
Training loss: 5.123232841491699
Validation loss: 4.967252977432743

Epoch: 5| Step: 1
Training loss: 5.214150905609131
Validation loss: 4.963220632204446

Epoch: 5| Step: 2
Training loss: 4.522487640380859
Validation loss: 4.958888494840232

Epoch: 5| Step: 3
Training loss: 5.583510398864746
Validation loss: 4.954923147796302

Epoch: 5| Step: 4
Training loss: 4.959502220153809
Validation loss: 4.947975686801377

Epoch: 5| Step: 5
Training loss: 4.381214141845703
Validation loss: 4.944827274609637

Epoch: 5| Step: 6
Training loss: 4.346662998199463
Validation loss: 4.941163314286099

Epoch: 5| Step: 7
Training loss: 3.767611026763916
Validation loss: 4.936254793597806

Epoch: 5| Step: 8
Training loss: 5.8597893714904785
Validation loss: 4.931714304031864

Epoch: 5| Step: 9
Training loss: 3.9979538917541504
Validation loss: 4.927765992379958

Epoch: 5| Step: 10
Training loss: 4.332794666290283
Validation loss: 4.92178878989271

Epoch: 4| Step: 0
Training loss: 4.415501594543457
Validation loss: 4.9177991754265244

Epoch: 5| Step: 1
Training loss: 4.287289619445801
Validation loss: 4.91375002297022

Epoch: 5| Step: 2
Training loss: 3.7671921253204346
Validation loss: 4.907872630703833

Epoch: 5| Step: 3
Training loss: 5.6421799659729
Validation loss: 4.90114712971513

Epoch: 5| Step: 4
Training loss: 4.617753505706787
Validation loss: 4.897781915562128

Epoch: 5| Step: 5
Training loss: 5.091788291931152
Validation loss: 4.893832042653074

Epoch: 5| Step: 6
Training loss: 5.608555793762207
Validation loss: 4.88808544220463

Epoch: 5| Step: 7
Training loss: 4.382914066314697
Validation loss: 4.883808730750956

Epoch: 5| Step: 8
Training loss: 3.895721912384033
Validation loss: 4.879143632868285

Epoch: 5| Step: 9
Training loss: 4.887098789215088
Validation loss: 4.873268071041312

Epoch: 5| Step: 10
Training loss: 5.033374786376953
Validation loss: 4.869516044534663

Epoch: 5| Step: 0
Training loss: 5.815776824951172
Validation loss: 4.863045830880442

Epoch: 5| Step: 1
Training loss: 4.939330101013184
Validation loss: 4.858585880648706

Epoch: 5| Step: 2
Training loss: 4.219141960144043
Validation loss: 4.855995014149656

Epoch: 5| Step: 3
Training loss: 4.233060359954834
Validation loss: 4.8509467109557125

Epoch: 5| Step: 4
Training loss: 3.954853057861328
Validation loss: 4.846318934553413

Epoch: 5| Step: 5
Training loss: 4.4258880615234375
Validation loss: 4.84044752326063

Epoch: 5| Step: 6
Training loss: 4.302347660064697
Validation loss: 4.83254635718561

Epoch: 5| Step: 7
Training loss: 4.167666435241699
Validation loss: 4.830965236950946

Epoch: 5| Step: 8
Training loss: 4.515028476715088
Validation loss: 4.823268541725733

Epoch: 5| Step: 9
Training loss: 4.739341735839844
Validation loss: 4.8187177873426865

Epoch: 5| Step: 10
Training loss: 5.831881523132324
Validation loss: 4.81205722337128

Epoch: 6| Step: 0
Training loss: 3.934070587158203
Validation loss: 4.808059425764187

Epoch: 5| Step: 1
Training loss: 3.4220473766326904
Validation loss: 4.8019697179076495

Epoch: 5| Step: 2
Training loss: 3.6920700073242188
Validation loss: 4.797055413646083

Epoch: 5| Step: 3
Training loss: 4.6190714836120605
Validation loss: 4.7909469450673745

Epoch: 5| Step: 4
Training loss: 3.6866531372070312
Validation loss: 4.785350758542297

Epoch: 5| Step: 5
Training loss: 4.622495651245117
Validation loss: 4.783488668421263

Epoch: 5| Step: 6
Training loss: 4.1881818771362305
Validation loss: 4.775874814679546

Epoch: 5| Step: 7
Training loss: 6.356287002563477
Validation loss: 4.770017259864397

Epoch: 5| Step: 8
Training loss: 4.713327884674072
Validation loss: 4.765273212104716

Epoch: 5| Step: 9
Training loss: 5.590688228607178
Validation loss: 4.757278811547064

Epoch: 5| Step: 10
Training loss: 5.639975070953369
Validation loss: 4.7520847218011015

Epoch: 7| Step: 0
Training loss: 3.5941948890686035
Validation loss: 4.74799931433893

Epoch: 5| Step: 1
Training loss: 4.171331882476807
Validation loss: 4.742497869717178

Epoch: 5| Step: 2
Training loss: 5.603662967681885
Validation loss: 4.735010095821914

Epoch: 5| Step: 3
Training loss: 4.771315574645996
Validation loss: 4.73004513402139

Epoch: 5| Step: 4
Training loss: 3.9402718544006348
Validation loss: 4.72258638053812

Epoch: 5| Step: 5
Training loss: 4.478401184082031
Validation loss: 4.718071291523595

Epoch: 5| Step: 6
Training loss: 3.867776870727539
Validation loss: 4.710158189137776

Epoch: 5| Step: 7
Training loss: 4.858658790588379
Validation loss: 4.706132922121274

Epoch: 5| Step: 8
Training loss: 4.618934154510498
Validation loss: 4.696098281491187

Epoch: 5| Step: 9
Training loss: 4.493691921234131
Validation loss: 4.693941311169696

Epoch: 5| Step: 10
Training loss: 5.309349536895752
Validation loss: 4.68742036819458

Epoch: 8| Step: 0
Training loss: 2.928163766860962
Validation loss: 4.681628375925044

Epoch: 5| Step: 1
Training loss: 5.187534332275391
Validation loss: 4.671724909095354

Epoch: 5| Step: 2
Training loss: 5.151852607727051
Validation loss: 4.665418635132492

Epoch: 5| Step: 3
Training loss: 4.858145713806152
Validation loss: 4.659659611281528

Epoch: 5| Step: 4
Training loss: 5.165802955627441
Validation loss: 4.652759244365077

Epoch: 5| Step: 5
Training loss: 4.185751438140869
Validation loss: 4.6478376593641055

Epoch: 5| Step: 6
Training loss: 4.558852672576904
Validation loss: 4.640190401384907

Epoch: 5| Step: 7
Training loss: 3.0854995250701904
Validation loss: 4.6337999682272635

Epoch: 5| Step: 8
Training loss: 5.217202186584473
Validation loss: 4.627625455138504

Epoch: 5| Step: 9
Training loss: 5.068202495574951
Validation loss: 4.619563953850859

Epoch: 5| Step: 10
Training loss: 3.2380762100219727
Validation loss: 4.611125787099202

Epoch: 9| Step: 0
Training loss: 4.252587795257568
Validation loss: 4.606225439297256

Epoch: 5| Step: 1
Training loss: 3.885953187942505
Validation loss: 4.597311988953622

Epoch: 5| Step: 2
Training loss: 4.261903285980225
Validation loss: 4.589324530734811

Epoch: 5| Step: 3
Training loss: 4.523310661315918
Validation loss: 4.5848015354525655

Epoch: 5| Step: 4
Training loss: 4.543205261230469
Validation loss: 4.574601196473645

Epoch: 5| Step: 5
Training loss: 4.499037742614746
Validation loss: 4.567931016286214

Epoch: 5| Step: 6
Training loss: 4.616950511932373
Validation loss: 4.560711881165863

Epoch: 5| Step: 7
Training loss: 4.458360195159912
Validation loss: 4.553822466122207

Epoch: 5| Step: 8
Training loss: 4.4620771408081055
Validation loss: 4.544896064266082

Epoch: 5| Step: 9
Training loss: 3.84552001953125
Validation loss: 4.536989609400432

Epoch: 5| Step: 10
Training loss: 4.67071008682251
Validation loss: 4.529943414913711

Epoch: 10| Step: 0
Training loss: 4.114274501800537
Validation loss: 4.520293256287934

Epoch: 5| Step: 1
Training loss: 4.024230003356934
Validation loss: 4.515928514542118

Epoch: 5| Step: 2
Training loss: 4.759533882141113
Validation loss: 4.506918317528181

Epoch: 5| Step: 3
Training loss: 4.368121147155762
Validation loss: 4.496548457812238

Epoch: 5| Step: 4
Training loss: 4.414811134338379
Validation loss: 4.489807559597876

Epoch: 5| Step: 5
Training loss: 3.91131854057312
Validation loss: 4.483614372950728

Epoch: 5| Step: 6
Training loss: 3.9425559043884277
Validation loss: 4.472930708239155

Epoch: 5| Step: 7
Training loss: 4.62201452255249
Validation loss: 4.467092232037616

Epoch: 5| Step: 8
Training loss: 3.8245601654052734
Validation loss: 4.4546897206255185

Epoch: 5| Step: 9
Training loss: 4.675720691680908
Validation loss: 4.449960431744976

Epoch: 5| Step: 10
Training loss: 4.399800777435303
Validation loss: 4.4389408788373395

Epoch: 11| Step: 0
Training loss: 4.913195610046387
Validation loss: 4.430352577599146

Epoch: 5| Step: 1
Training loss: 5.282147407531738
Validation loss: 4.419617417038128

Epoch: 5| Step: 2
Training loss: 4.911632537841797
Validation loss: 4.411446104767502

Epoch: 5| Step: 3
Training loss: 3.7874882221221924
Validation loss: 4.400693631941272

Epoch: 5| Step: 4
Training loss: 2.7584807872772217
Validation loss: 4.389427390149844

Epoch: 5| Step: 5
Training loss: 2.9917092323303223
Validation loss: 4.384083435099612

Epoch: 5| Step: 6
Training loss: 3.0818026065826416
Validation loss: 4.374860950695571

Epoch: 5| Step: 7
Training loss: 4.396076202392578
Validation loss: 4.366357085525348

Epoch: 5| Step: 8
Training loss: 4.340979099273682
Validation loss: 4.353828963413034

Epoch: 5| Step: 9
Training loss: 4.490448951721191
Validation loss: 4.345484579763105

Epoch: 5| Step: 10
Training loss: 5.2039618492126465
Validation loss: 4.3361278580081075

Epoch: 12| Step: 0
Training loss: 4.5209269523620605
Validation loss: 4.32660234615367

Epoch: 5| Step: 1
Training loss: 3.6890106201171875
Validation loss: 4.315576843036118

Epoch: 5| Step: 2
Training loss: 4.801477909088135
Validation loss: 4.308102289835612

Epoch: 5| Step: 3
Training loss: 3.6133060455322266
Validation loss: 4.295768440410655

Epoch: 5| Step: 4
Training loss: 3.6592788696289062
Validation loss: 4.287981799853745

Epoch: 5| Step: 5
Training loss: 3.4383888244628906
Validation loss: 4.277742329464163

Epoch: 5| Step: 6
Training loss: 3.7147116661071777
Validation loss: 4.265054507922101

Epoch: 5| Step: 7
Training loss: 3.9831504821777344
Validation loss: 4.255005992868895

Epoch: 5| Step: 8
Training loss: 4.120358467102051
Validation loss: 4.243901314273957

Epoch: 5| Step: 9
Training loss: 4.808518409729004
Validation loss: 4.236552120536886

Epoch: 5| Step: 10
Training loss: 4.669958591461182
Validation loss: 4.221399432869368

Epoch: 13| Step: 0
Training loss: 3.4493930339813232
Validation loss: 4.213403014726536

Epoch: 5| Step: 1
Training loss: 4.856832027435303
Validation loss: 4.201239293621432

Epoch: 5| Step: 2
Training loss: 3.8174827098846436
Validation loss: 4.194782067370671

Epoch: 5| Step: 3
Training loss: 3.9473929405212402
Validation loss: 4.181693646215623

Epoch: 5| Step: 4
Training loss: 3.8024392127990723
Validation loss: 4.17036045751264

Epoch: 5| Step: 5
Training loss: 4.171727657318115
Validation loss: 4.1582182299706245

Epoch: 5| Step: 6
Training loss: 4.645831108093262
Validation loss: 4.150554897964642

Epoch: 5| Step: 7
Training loss: 3.0984280109405518
Validation loss: 4.134417633856496

Epoch: 5| Step: 8
Training loss: 4.792430877685547
Validation loss: 4.12103941107309

Epoch: 5| Step: 9
Training loss: 3.333320140838623
Validation loss: 4.112252132866972

Epoch: 5| Step: 10
Training loss: 3.7897863388061523
Validation loss: 4.102767323934904

Epoch: 14| Step: 0
Training loss: 3.384805202484131
Validation loss: 4.0913199814417025

Epoch: 5| Step: 1
Training loss: 4.263433456420898
Validation loss: 4.077179078132875

Epoch: 5| Step: 2
Training loss: 4.519763469696045
Validation loss: 4.0638336571314

Epoch: 5| Step: 3
Training loss: 3.249605655670166
Validation loss: 4.053164702589794

Epoch: 5| Step: 4
Training loss: 3.849553346633911
Validation loss: 4.038068015088317

Epoch: 5| Step: 5
Training loss: 4.554513454437256
Validation loss: 4.02963278883247

Epoch: 5| Step: 6
Training loss: 3.7559196949005127
Validation loss: 4.011766326042913

Epoch: 5| Step: 7
Training loss: 3.9139370918273926
Validation loss: 3.9962288512978503

Epoch: 5| Step: 8
Training loss: 3.310211181640625
Validation loss: 3.985054636514315

Epoch: 5| Step: 9
Training loss: 3.3056411743164062
Validation loss: 3.973173910571683

Epoch: 5| Step: 10
Training loss: 4.471187114715576
Validation loss: 3.959833760415354

Epoch: 15| Step: 0
Training loss: 4.294717788696289
Validation loss: 3.95001111748398

Epoch: 5| Step: 1
Training loss: 4.931666851043701
Validation loss: 3.9351360054426294

Epoch: 5| Step: 2
Training loss: 3.861313581466675
Validation loss: 3.9204079643372567

Epoch: 5| Step: 3
Training loss: 3.7869057655334473
Validation loss: 3.91051362663187

Epoch: 5| Step: 4
Training loss: 2.8324899673461914
Validation loss: 3.89366489841092

Epoch: 5| Step: 5
Training loss: 3.7736034393310547
Validation loss: 3.885263740375478

Epoch: 5| Step: 6
Training loss: 3.327150821685791
Validation loss: 3.8722445605903544

Epoch: 5| Step: 7
Training loss: 3.3710715770721436
Validation loss: 3.858736494536041

Epoch: 5| Step: 8
Training loss: 3.2409234046936035
Validation loss: 3.8455417643311205

Epoch: 5| Step: 9
Training loss: 3.481818675994873
Validation loss: 3.8330296726636988

Epoch: 5| Step: 10
Training loss: 4.373925685882568
Validation loss: 3.8199626809807232

Epoch: 16| Step: 0
Training loss: 4.125252723693848
Validation loss: 3.8097877143531718

Epoch: 5| Step: 1
Training loss: 4.431614875793457
Validation loss: 3.794514335611815

Epoch: 5| Step: 2
Training loss: 3.6869149208068848
Validation loss: 3.7826798654371694

Epoch: 5| Step: 3
Training loss: 4.041450500488281
Validation loss: 3.7691167734002553

Epoch: 5| Step: 4
Training loss: 3.9161219596862793
Validation loss: 3.757305088863578

Epoch: 5| Step: 5
Training loss: 2.6761581897735596
Validation loss: 3.7395532925923667

Epoch: 5| Step: 6
Training loss: 3.375969648361206
Validation loss: 3.7264136806611092

Epoch: 5| Step: 7
Training loss: 4.054582595825195
Validation loss: 3.716476863430392

Epoch: 5| Step: 8
Training loss: 2.639570951461792
Validation loss: 3.701861409730809

Epoch: 5| Step: 9
Training loss: 3.288341522216797
Validation loss: 3.684455430635842

Epoch: 5| Step: 10
Training loss: 3.548003911972046
Validation loss: 3.671296376054005

Epoch: 17| Step: 0
Training loss: 3.8504586219787598
Validation loss: 3.658726769108926

Epoch: 5| Step: 1
Training loss: 3.198946475982666
Validation loss: 3.6474671799649476

Epoch: 5| Step: 2
Training loss: 3.6398468017578125
Validation loss: 3.6218951594445015

Epoch: 5| Step: 3
Training loss: 2.930351495742798
Validation loss: 3.613525054788077

Epoch: 5| Step: 4
Training loss: 3.4525306224823
Validation loss: 3.60059848395727

Epoch: 5| Step: 5
Training loss: 2.6473255157470703
Validation loss: 3.5870318028234665

Epoch: 5| Step: 6
Training loss: 3.4831535816192627
Validation loss: 3.568642780344973

Epoch: 5| Step: 7
Training loss: 3.462792158126831
Validation loss: 3.5510530061619257

Epoch: 5| Step: 8
Training loss: 4.069834232330322
Validation loss: 3.5386228663946993

Epoch: 5| Step: 9
Training loss: 3.807241439819336
Validation loss: 3.525677398968768

Epoch: 5| Step: 10
Training loss: 3.8359227180480957
Validation loss: 3.508961772405973

Epoch: 18| Step: 0
Training loss: 4.166688442230225
Validation loss: 3.4916724927963747

Epoch: 5| Step: 1
Training loss: 2.830981492996216
Validation loss: 3.476969042131978

Epoch: 5| Step: 2
Training loss: 3.2705142498016357
Validation loss: 3.461182176425893

Epoch: 5| Step: 3
Training loss: 3.8526172637939453
Validation loss: 3.4501238433263635

Epoch: 5| Step: 4
Training loss: 3.109135150909424
Validation loss: 3.4290272138452016

Epoch: 5| Step: 5
Training loss: 2.9630274772644043
Validation loss: 3.4177765718070408

Epoch: 5| Step: 6
Training loss: 3.3938026428222656
Validation loss: 3.398107987578197

Epoch: 5| Step: 7
Training loss: 3.517430067062378
Validation loss: 3.382244727944815

Epoch: 5| Step: 8
Training loss: 2.885589838027954
Validation loss: 3.366598916310136

Epoch: 5| Step: 9
Training loss: 2.8759357929229736
Validation loss: 3.345281429188226

Epoch: 5| Step: 10
Training loss: 3.8652536869049072
Validation loss: 3.342211272126885

Epoch: 19| Step: 0
Training loss: 2.9750008583068848
Validation loss: 3.3089268566459737

Epoch: 5| Step: 1
Training loss: 3.520387649536133
Validation loss: 3.289721627389231

Epoch: 5| Step: 2
Training loss: 2.6040077209472656
Validation loss: 3.2779133550582396

Epoch: 5| Step: 3
Training loss: 3.3183364868164062
Validation loss: 3.259365794479206

Epoch: 5| Step: 4
Training loss: 2.880645275115967
Validation loss: 3.2393503035268476

Epoch: 5| Step: 5
Training loss: 2.840766191482544
Validation loss: 3.2251060598640033

Epoch: 5| Step: 6
Training loss: 3.802845001220703
Validation loss: 3.197206812520181

Epoch: 5| Step: 7
Training loss: 3.1419119834899902
Validation loss: 3.176247776195567

Epoch: 5| Step: 8
Training loss: 3.2700812816619873
Validation loss: 3.1685715285680627

Epoch: 5| Step: 9
Training loss: 3.3277759552001953
Validation loss: 3.1410423837682253

Epoch: 5| Step: 10
Training loss: 3.225940465927124
Validation loss: 3.1332224133194133

Epoch: 20| Step: 0
Training loss: 3.5541701316833496
Validation loss: 3.1141198168518724

Epoch: 5| Step: 1
Training loss: 3.5732369422912598
Validation loss: 3.0945398730616414

Epoch: 5| Step: 2
Training loss: 3.108798027038574
Validation loss: 3.068916254146125

Epoch: 5| Step: 3
Training loss: 3.095301389694214
Validation loss: 3.0521457272191204

Epoch: 5| Step: 4
Training loss: 2.1880054473876953
Validation loss: 3.0339707994973786

Epoch: 5| Step: 5
Training loss: 3.0437283515930176
Validation loss: 3.008086189146965

Epoch: 5| Step: 6
Training loss: 3.6425976753234863
Validation loss: 2.990907935686009

Epoch: 5| Step: 7
Training loss: 2.486051559448242
Validation loss: 2.9715633956334924

Epoch: 5| Step: 8
Training loss: 3.1217727661132812
Validation loss: 2.952088499581942

Epoch: 5| Step: 9
Training loss: 2.666830062866211
Validation loss: 2.93336764202323

Epoch: 5| Step: 10
Training loss: 2.7108407020568848
Validation loss: 2.9087315144077426

Epoch: 21| Step: 0
Training loss: 2.2906785011291504
Validation loss: 2.8944024116762224

Epoch: 5| Step: 1
Training loss: 2.7851455211639404
Validation loss: 2.8677091367783083

Epoch: 5| Step: 2
Training loss: 2.7754111289978027
Validation loss: 2.852421260649158

Epoch: 5| Step: 3
Training loss: 3.032336711883545
Validation loss: 2.83949121352165

Epoch: 5| Step: 4
Training loss: 3.3142693042755127
Validation loss: 2.8320147452815885

Epoch: 5| Step: 5
Training loss: 2.1037049293518066
Validation loss: 2.804560528006605

Epoch: 5| Step: 6
Training loss: 2.612975835800171
Validation loss: 2.7945154507954917

Epoch: 5| Step: 7
Training loss: 3.812386989593506
Validation loss: 2.775035865845219

Epoch: 5| Step: 8
Training loss: 3.527048110961914
Validation loss: 2.743429322396555

Epoch: 5| Step: 9
Training loss: 2.2310280799865723
Validation loss: 2.7263170826819634

Epoch: 5| Step: 10
Training loss: 3.0677528381347656
Validation loss: 2.717145789054132

Epoch: 22| Step: 0
Training loss: 2.5528879165649414
Validation loss: 2.6942779787125124

Epoch: 5| Step: 1
Training loss: 2.37370228767395
Validation loss: 2.681616962596934

Epoch: 5| Step: 2
Training loss: 2.257814645767212
Validation loss: 2.6584425997990433

Epoch: 5| Step: 3
Training loss: 2.5731866359710693
Validation loss: 2.6411387048741823

Epoch: 5| Step: 4
Training loss: 3.301727294921875
Validation loss: 2.6242151209103164

Epoch: 5| Step: 5
Training loss: 2.7622125148773193
Validation loss: 2.6263626877979567

Epoch: 5| Step: 6
Training loss: 2.6352875232696533
Validation loss: 2.602591135168588

Epoch: 5| Step: 7
Training loss: 2.9786133766174316
Validation loss: 2.5830964503749723

Epoch: 5| Step: 8
Training loss: 2.4193472862243652
Validation loss: 2.56822528377656

Epoch: 5| Step: 9
Training loss: 3.3125548362731934
Validation loss: 2.5489958024794057

Epoch: 5| Step: 10
Training loss: 3.034494638442993
Validation loss: 2.540681051951583

Epoch: 23| Step: 0
Training loss: 2.1350440979003906
Validation loss: 2.520633982073876

Epoch: 5| Step: 1
Training loss: 2.98832368850708
Validation loss: 2.498312903988746

Epoch: 5| Step: 2
Training loss: 2.1342616081237793
Validation loss: 2.483797223337235

Epoch: 5| Step: 3
Training loss: 2.2892115116119385
Validation loss: 2.4791850530973045

Epoch: 5| Step: 4
Training loss: 2.7550048828125
Validation loss: 2.452582264459261

Epoch: 5| Step: 5
Training loss: 3.317530393600464
Validation loss: 2.441994159452377

Epoch: 5| Step: 6
Training loss: 2.5687198638916016
Validation loss: 2.4234106438134306

Epoch: 5| Step: 7
Training loss: 2.7678420543670654
Validation loss: 2.407878614241077

Epoch: 5| Step: 8
Training loss: 2.4019923210144043
Validation loss: 2.396039608986147

Epoch: 5| Step: 9
Training loss: 2.710174083709717
Validation loss: 2.3836590551560923

Epoch: 5| Step: 10
Training loss: 2.714261054992676
Validation loss: 2.3680571894491873

Epoch: 24| Step: 0
Training loss: 3.1891396045684814
Validation loss: 2.359703871511644

Epoch: 5| Step: 1
Training loss: 2.307927370071411
Validation loss: 2.348034740776144

Epoch: 5| Step: 2
Training loss: 2.5760128498077393
Validation loss: 2.3391743424118205

Epoch: 5| Step: 3
Training loss: 2.49113130569458
Validation loss: 2.3267923657612135

Epoch: 5| Step: 4
Training loss: 2.64685320854187
Validation loss: 2.3118394702993412

Epoch: 5| Step: 5
Training loss: 1.9943605661392212
Validation loss: 2.2979678453937655

Epoch: 5| Step: 6
Training loss: 3.2059147357940674
Validation loss: 2.299737109932848

Epoch: 5| Step: 7
Training loss: 2.0659823417663574
Validation loss: 2.2881249920014413

Epoch: 5| Step: 8
Training loss: 2.395676612854004
Validation loss: 2.2868951341157318

Epoch: 5| Step: 9
Training loss: 2.419412136077881
Validation loss: 2.277209228084933

Epoch: 5| Step: 10
Training loss: 2.3771822452545166
Validation loss: 2.253163631244372

Epoch: 25| Step: 0
Training loss: 2.6418638229370117
Validation loss: 2.2494622674039615

Epoch: 5| Step: 1
Training loss: 1.9552619457244873
Validation loss: 2.2415198997784684

Epoch: 5| Step: 2
Training loss: 2.4359757900238037
Validation loss: 2.2201554775238037

Epoch: 5| Step: 3
Training loss: 2.79060959815979
Validation loss: 2.229689062282603

Epoch: 5| Step: 4
Training loss: 2.5634210109710693
Validation loss: 2.2239499874012445

Epoch: 5| Step: 5
Training loss: 2.080029249191284
Validation loss: 2.2086635866472797

Epoch: 5| Step: 6
Training loss: 2.4020628929138184
Validation loss: 2.226637701834402

Epoch: 5| Step: 7
Training loss: 2.392012119293213
Validation loss: 2.2025877506502214

Epoch: 5| Step: 8
Training loss: 2.7650198936462402
Validation loss: 2.1911167662630797

Epoch: 5| Step: 9
Training loss: 2.0872068405151367
Validation loss: 2.197464801931894

Epoch: 5| Step: 10
Training loss: 3.0420665740966797
Validation loss: 2.1867891101426977

Epoch: 26| Step: 0
Training loss: 2.060084581375122
Validation loss: 2.1705336134920836

Epoch: 5| Step: 1
Training loss: 2.5297389030456543
Validation loss: 2.1861160980757846

Epoch: 5| Step: 2
Training loss: 2.911997079849243
Validation loss: 2.167563061560354

Epoch: 5| Step: 3
Training loss: 2.862149238586426
Validation loss: 2.1547588891880487

Epoch: 5| Step: 4
Training loss: 2.8350839614868164
Validation loss: 2.154674550538422

Epoch: 5| Step: 5
Training loss: 2.00970196723938
Validation loss: 2.1457011263857604

Epoch: 5| Step: 6
Training loss: 2.4180874824523926
Validation loss: 2.1432480017344155

Epoch: 5| Step: 7
Training loss: 1.8656213283538818
Validation loss: 2.13914773156566

Epoch: 5| Step: 8
Training loss: 2.1433026790618896
Validation loss: 2.1504070271727858

Epoch: 5| Step: 9
Training loss: 3.0411689281463623
Validation loss: 2.1500685599542435

Epoch: 5| Step: 10
Training loss: 2.1927478313446045
Validation loss: 2.12589011141049

Epoch: 27| Step: 0
Training loss: 2.65525221824646
Validation loss: 2.1407168244802826

Epoch: 5| Step: 1
Training loss: 2.53245210647583
Validation loss: 2.1250899568680794

Epoch: 5| Step: 2
Training loss: 2.112793445587158
Validation loss: 2.132535416592834

Epoch: 5| Step: 3
Training loss: 2.4039764404296875
Validation loss: 2.1298846942122265

Epoch: 5| Step: 4
Training loss: 2.9222898483276367
Validation loss: 2.1358467891652095

Epoch: 5| Step: 5
Training loss: 2.3248531818389893
Validation loss: 2.147393185605285

Epoch: 5| Step: 6
Training loss: 2.293470859527588
Validation loss: 2.126785127065515

Epoch: 5| Step: 7
Training loss: 2.41770339012146
Validation loss: 2.142833677671289

Epoch: 5| Step: 8
Training loss: 2.2891242504119873
Validation loss: 2.119326804273872

Epoch: 5| Step: 9
Training loss: 2.3278419971466064
Validation loss: 2.124532263766053

Epoch: 5| Step: 10
Training loss: 2.454528570175171
Validation loss: 2.132161319896739

Epoch: 28| Step: 0
Training loss: 2.5836539268493652
Validation loss: 2.120641807074188

Epoch: 5| Step: 1
Training loss: 2.988193988800049
Validation loss: 2.1167377271959857

Epoch: 5| Step: 2
Training loss: 2.158972978591919
Validation loss: 2.1278637557901363

Epoch: 5| Step: 3
Training loss: 2.666350841522217
Validation loss: 2.1196177326222903

Epoch: 5| Step: 4
Training loss: 1.9653351306915283
Validation loss: 2.101918702484459

Epoch: 5| Step: 5
Training loss: 2.4510345458984375
Validation loss: 2.1151490596032914

Epoch: 5| Step: 6
Training loss: 2.639742851257324
Validation loss: 2.105878947883524

Epoch: 5| Step: 7
Training loss: 2.348846912384033
Validation loss: 2.112684520342017

Epoch: 5| Step: 8
Training loss: 2.048459768295288
Validation loss: 2.114803183463312

Epoch: 5| Step: 9
Training loss: 2.3494534492492676
Validation loss: 2.120913290208386

Epoch: 5| Step: 10
Training loss: 2.4783997535705566
Validation loss: 2.102013429005941

Epoch: 29| Step: 0
Training loss: 2.31404185295105
Validation loss: 2.110002512572914

Epoch: 5| Step: 1
Training loss: 2.4620566368103027
Validation loss: 2.096068669390935

Epoch: 5| Step: 2
Training loss: 3.082280397415161
Validation loss: 2.1099210221280336

Epoch: 5| Step: 3
Training loss: 2.6046524047851562
Validation loss: 2.0999203856273363

Epoch: 5| Step: 4
Training loss: 2.558762550354004
Validation loss: 2.094215428957375

Epoch: 5| Step: 5
Training loss: 2.535473346710205
Validation loss: 2.102874558459046

Epoch: 5| Step: 6
Training loss: 2.381300210952759
Validation loss: 2.096205747255715

Epoch: 5| Step: 7
Training loss: 2.4694740772247314
Validation loss: 2.0872992546327653

Epoch: 5| Step: 8
Training loss: 1.7987287044525146
Validation loss: 2.0958962120035642

Epoch: 5| Step: 9
Training loss: 2.5257468223571777
Validation loss: 2.094413565051171

Epoch: 5| Step: 10
Training loss: 1.6539660692214966
Validation loss: 2.082756083498719

Epoch: 30| Step: 0
Training loss: 2.6928017139434814
Validation loss: 2.08682833948443

Epoch: 5| Step: 1
Training loss: 2.442018985748291
Validation loss: 2.0736899440006544

Epoch: 5| Step: 2
Training loss: 2.775308132171631
Validation loss: 2.090148061834356

Epoch: 5| Step: 3
Training loss: 2.539954662322998
Validation loss: 2.0721799917118524

Epoch: 5| Step: 4
Training loss: 2.1865344047546387
Validation loss: 2.07424674495574

Epoch: 5| Step: 5
Training loss: 2.536454439163208
Validation loss: 2.0787904429179367

Epoch: 5| Step: 6
Training loss: 1.9695942401885986
Validation loss: 2.096911197067589

Epoch: 5| Step: 7
Training loss: 2.6710638999938965
Validation loss: 2.0690923224213305

Epoch: 5| Step: 8
Training loss: 2.0018310546875
Validation loss: 2.082353340682163

Epoch: 5| Step: 9
Training loss: 2.5486226081848145
Validation loss: 2.0861066105545207

Epoch: 5| Step: 10
Training loss: 2.1875836849212646
Validation loss: 2.0646746645691576

Epoch: 31| Step: 0
Training loss: 2.949126720428467
Validation loss: 2.075159659949682

Epoch: 5| Step: 1
Training loss: 1.9896323680877686
Validation loss: 2.0815552460250033

Epoch: 5| Step: 2
Training loss: 2.3486711978912354
Validation loss: 2.0723775561137865

Epoch: 5| Step: 3
Training loss: 2.6605846881866455
Validation loss: 2.0744320807918424

Epoch: 5| Step: 4
Training loss: 2.4924659729003906
Validation loss: 2.0813180964480162

Epoch: 5| Step: 5
Training loss: 2.121615171432495
Validation loss: 2.090096357048199

Epoch: 5| Step: 6
Training loss: 2.2824134826660156
Validation loss: 2.0771777860579954

Epoch: 5| Step: 7
Training loss: 2.156491756439209
Validation loss: 2.0802324407844135

Epoch: 5| Step: 8
Training loss: 2.810295581817627
Validation loss: 2.0784288273062757

Epoch: 5| Step: 9
Training loss: 2.3293492794036865
Validation loss: 2.0773883558088735

Epoch: 5| Step: 10
Training loss: 2.2052204608917236
Validation loss: 2.0901759350171654

Epoch: 32| Step: 0
Training loss: 1.864691138267517
Validation loss: 2.069397844294066

Epoch: 5| Step: 1
Training loss: 2.575814723968506
Validation loss: 2.078378786322891

Epoch: 5| Step: 2
Training loss: 2.024465322494507
Validation loss: 2.076181577097985

Epoch: 5| Step: 3
Training loss: 2.454338788986206
Validation loss: 2.1013641562513126

Epoch: 5| Step: 4
Training loss: 2.51857328414917
Validation loss: 2.0829417628626667

Epoch: 5| Step: 5
Training loss: 3.0281808376312256
Validation loss: 2.0845721331975793

Epoch: 5| Step: 6
Training loss: 2.335026502609253
Validation loss: 2.0704176938661965

Epoch: 5| Step: 7
Training loss: 2.398355722427368
Validation loss: 2.067889259707543

Epoch: 5| Step: 8
Training loss: 1.9500287771224976
Validation loss: 2.077349670471684

Epoch: 5| Step: 9
Training loss: 2.632585048675537
Validation loss: 2.076789379119873

Epoch: 5| Step: 10
Training loss: 2.639256238937378
Validation loss: 2.0796054255577827

Epoch: 33| Step: 0
Training loss: 2.5239553451538086
Validation loss: 2.072897240679751

Epoch: 5| Step: 1
Training loss: 2.7305798530578613
Validation loss: 2.0633093259667836

Epoch: 5| Step: 2
Training loss: 2.0240635871887207
Validation loss: 2.083714997896584

Epoch: 5| Step: 3
Training loss: 2.2709434032440186
Validation loss: 2.0708094617371917

Epoch: 5| Step: 4
Training loss: 2.436398983001709
Validation loss: 2.0821641824578725

Epoch: 5| Step: 5
Training loss: 2.558180332183838
Validation loss: 2.0551470569384995

Epoch: 5| Step: 6
Training loss: 2.9802417755126953
Validation loss: 2.0639094665486324

Epoch: 5| Step: 7
Training loss: 1.7701812982559204
Validation loss: 2.0705112641857517

Epoch: 5| Step: 8
Training loss: 2.9407958984375
Validation loss: 2.0768333686295377

Epoch: 5| Step: 9
Training loss: 1.8004077672958374
Validation loss: 2.0672512233898206

Epoch: 5| Step: 10
Training loss: 2.2369654178619385
Validation loss: 2.065053606546053

Epoch: 34| Step: 0
Training loss: 2.8280391693115234
Validation loss: 2.0487778904617473

Epoch: 5| Step: 1
Training loss: 2.558032512664795
Validation loss: 2.058777000314446

Epoch: 5| Step: 2
Training loss: 2.116147518157959
Validation loss: 2.063703147313928

Epoch: 5| Step: 3
Training loss: 2.2849676609039307
Validation loss: 2.056488826710691

Epoch: 5| Step: 4
Training loss: 2.0774829387664795
Validation loss: 2.081693495473554

Epoch: 5| Step: 5
Training loss: 1.9341545104980469
Validation loss: 2.074929875712241

Epoch: 5| Step: 6
Training loss: 2.0852293968200684
Validation loss: 2.073650211416265

Epoch: 5| Step: 7
Training loss: 3.1066315174102783
Validation loss: 2.0569209462852887

Epoch: 5| Step: 8
Training loss: 2.44319486618042
Validation loss: 2.063691246894098

Epoch: 5| Step: 9
Training loss: 2.369889736175537
Validation loss: 2.054383006147159

Epoch: 5| Step: 10
Training loss: 2.565397262573242
Validation loss: 2.0598307873613093

Epoch: 35| Step: 0
Training loss: 3.0038700103759766
Validation loss: 2.0572880442424486

Epoch: 5| Step: 1
Training loss: 2.740461826324463
Validation loss: 2.0521481678050053

Epoch: 5| Step: 2
Training loss: 2.572052001953125
Validation loss: 2.051443971613402

Epoch: 5| Step: 3
Training loss: 2.250339984893799
Validation loss: 2.0409671081009733

Epoch: 5| Step: 4
Training loss: 2.395359516143799
Validation loss: 2.0701438637189966

Epoch: 5| Step: 5
Training loss: 2.704124927520752
Validation loss: 2.0510828225843367

Epoch: 5| Step: 6
Training loss: 2.330061912536621
Validation loss: 2.058865995817287

Epoch: 5| Step: 7
Training loss: 2.4162135124206543
Validation loss: 2.0524951450286375

Epoch: 5| Step: 8
Training loss: 2.112992525100708
Validation loss: 2.069308675745482

Epoch: 5| Step: 9
Training loss: 1.6628053188323975
Validation loss: 2.05506718543268

Epoch: 5| Step: 10
Training loss: 1.787703514099121
Validation loss: 2.060977764027093

Epoch: 36| Step: 0
Training loss: 2.1709787845611572
Validation loss: 2.0487408150908766

Epoch: 5| Step: 1
Training loss: 2.590646266937256
Validation loss: 2.0481294534539662

Epoch: 5| Step: 2
Training loss: 1.8933680057525635
Validation loss: 2.0588358345852105

Epoch: 5| Step: 3
Training loss: 2.6183955669403076
Validation loss: 2.0552379585081533

Epoch: 5| Step: 4
Training loss: 2.2782130241394043
Validation loss: 2.0582773788000948

Epoch: 5| Step: 5
Training loss: 2.313368558883667
Validation loss: 2.0593945954435613

Epoch: 5| Step: 6
Training loss: 2.6553995609283447
Validation loss: 2.0469460897548224

Epoch: 5| Step: 7
Training loss: 2.4549314975738525
Validation loss: 2.0510595690819526

Epoch: 5| Step: 8
Training loss: 1.9294582605361938
Validation loss: 2.0487528001108477

Epoch: 5| Step: 9
Training loss: 2.903658628463745
Validation loss: 2.051754761767644

Epoch: 5| Step: 10
Training loss: 2.339782476425171
Validation loss: 2.05008763651694

Epoch: 37| Step: 0
Training loss: 1.8826942443847656
Validation loss: 2.051911856538506

Epoch: 5| Step: 1
Training loss: 2.1023287773132324
Validation loss: 2.051437521493563

Epoch: 5| Step: 2
Training loss: 2.870913028717041
Validation loss: 2.0464518018948135

Epoch: 5| Step: 3
Training loss: 1.9849188327789307
Validation loss: 2.0449319295985724

Epoch: 5| Step: 4
Training loss: 2.63785719871521
Validation loss: 2.0481460017542683

Epoch: 5| Step: 5
Training loss: 2.4436702728271484
Validation loss: 2.038277708074098

Epoch: 5| Step: 6
Training loss: 2.2248764038085938
Validation loss: 2.034170578884822

Epoch: 5| Step: 7
Training loss: 2.5906620025634766
Validation loss: 2.0573340308281685

Epoch: 5| Step: 8
Training loss: 2.2304046154022217
Validation loss: 2.05550721896592

Epoch: 5| Step: 9
Training loss: 2.540095806121826
Validation loss: 2.0388871110895628

Epoch: 5| Step: 10
Training loss: 2.540287971496582
Validation loss: 2.039494199137534

Epoch: 38| Step: 0
Training loss: 2.1985831260681152
Validation loss: 2.0442225625438075

Epoch: 5| Step: 1
Training loss: 2.555629253387451
Validation loss: 2.065561899574854

Epoch: 5| Step: 2
Training loss: 2.493751287460327
Validation loss: 2.036483859503141

Epoch: 5| Step: 3
Training loss: 3.1534624099731445
Validation loss: 2.044786141764733

Epoch: 5| Step: 4
Training loss: 2.639954090118408
Validation loss: 2.0475918477581394

Epoch: 5| Step: 5
Training loss: 2.9445300102233887
Validation loss: 2.048587409398889

Epoch: 5| Step: 6
Training loss: 1.8652483224868774
Validation loss: 2.0488179806740052

Epoch: 5| Step: 7
Training loss: 2.4426002502441406
Validation loss: 2.052941576127083

Epoch: 5| Step: 8
Training loss: 1.6725928783416748
Validation loss: 2.060447346779608

Epoch: 5| Step: 9
Training loss: 1.72577702999115
Validation loss: 2.039598121437975

Epoch: 5| Step: 10
Training loss: 2.3871569633483887
Validation loss: 2.0425056949738534

Epoch: 39| Step: 0
Training loss: 2.0140957832336426
Validation loss: 2.041068911552429

Epoch: 5| Step: 1
Training loss: 2.706493854522705
Validation loss: 2.033084269492857

Epoch: 5| Step: 2
Training loss: 2.5526163578033447
Validation loss: 2.0453558557776996

Epoch: 5| Step: 3
Training loss: 2.8393173217773438
Validation loss: 2.047711089093198

Epoch: 5| Step: 4
Training loss: 2.1745963096618652
Validation loss: 2.0387967671117475

Epoch: 5| Step: 5
Training loss: 2.1995882987976074
Validation loss: 2.0325884716485136

Epoch: 5| Step: 6
Training loss: 2.608011245727539
Validation loss: 2.031281248215706

Epoch: 5| Step: 7
Training loss: 1.749884843826294
Validation loss: 2.03163307328378

Epoch: 5| Step: 8
Training loss: 2.7002296447753906
Validation loss: 2.0248083555570213

Epoch: 5| Step: 9
Training loss: 2.525135040283203
Validation loss: 2.02539808775789

Epoch: 5| Step: 10
Training loss: 1.7479850053787231
Validation loss: 2.0354334321073306

Epoch: 40| Step: 0
Training loss: 2.7714056968688965
Validation loss: 2.053903002892771

Epoch: 5| Step: 1
Training loss: 1.94063401222229
Validation loss: 2.042585899752955

Epoch: 5| Step: 2
Training loss: 1.8665263652801514
Validation loss: 2.0389597877379386

Epoch: 5| Step: 3
Training loss: 2.515990734100342
Validation loss: 2.0271133069069154

Epoch: 5| Step: 4
Training loss: 2.683802843093872
Validation loss: 2.0450294120337373

Epoch: 5| Step: 5
Training loss: 2.50219988822937
Validation loss: 2.031249216807786

Epoch: 5| Step: 6
Training loss: 2.449204921722412
Validation loss: 2.0227312413595055

Epoch: 5| Step: 7
Training loss: 1.8776636123657227
Validation loss: 2.039355957379905

Epoch: 5| Step: 8
Training loss: 2.2303569316864014
Validation loss: 2.0150893401074153

Epoch: 5| Step: 9
Training loss: 2.5027453899383545
Validation loss: 2.0261152380256244

Epoch: 5| Step: 10
Training loss: 2.6437249183654785
Validation loss: 2.0364164818999586

Epoch: 41| Step: 0
Training loss: 1.9458770751953125
Validation loss: 2.028416500296644

Epoch: 5| Step: 1
Training loss: 2.140836715698242
Validation loss: 2.041030937625516

Epoch: 5| Step: 2
Training loss: 1.9657446146011353
Validation loss: 2.04058446550882

Epoch: 5| Step: 3
Training loss: 2.1947312355041504
Validation loss: 2.030388473182596

Epoch: 5| Step: 4
Training loss: 2.4052350521087646
Validation loss: 2.030947544241464

Epoch: 5| Step: 5
Training loss: 3.320838451385498
Validation loss: 2.0274698657374226

Epoch: 5| Step: 6
Training loss: 2.3859198093414307
Validation loss: 2.0343362503154303

Epoch: 5| Step: 7
Training loss: 2.4417057037353516
Validation loss: 2.0232683509908695

Epoch: 5| Step: 8
Training loss: 2.54127836227417
Validation loss: 2.034674195833104

Epoch: 5| Step: 9
Training loss: 2.156881809234619
Validation loss: 2.0331897966323362

Epoch: 5| Step: 10
Training loss: 2.308448076248169
Validation loss: 2.0458918848345355

Epoch: 42| Step: 0
Training loss: 2.4242405891418457
Validation loss: 2.0180972173649776

Epoch: 5| Step: 1
Training loss: 3.0079567432403564
Validation loss: 2.0338299171898955

Epoch: 5| Step: 2
Training loss: 2.1378378868103027
Validation loss: 2.0381524165471396

Epoch: 5| Step: 3
Training loss: 2.221065044403076
Validation loss: 2.0258674493399997

Epoch: 5| Step: 4
Training loss: 2.8801517486572266
Validation loss: 2.0171504353964202

Epoch: 5| Step: 5
Training loss: 2.8808794021606445
Validation loss: 2.0225348562322636

Epoch: 5| Step: 6
Training loss: 2.1322226524353027
Validation loss: 2.0238544825584657

Epoch: 5| Step: 7
Training loss: 2.065195322036743
Validation loss: 2.0350267605115007

Epoch: 5| Step: 8
Training loss: 1.8706268072128296
Validation loss: 2.0340149876891926

Epoch: 5| Step: 9
Training loss: 2.059298515319824
Validation loss: 2.034463095408614

Epoch: 5| Step: 10
Training loss: 2.0736119747161865
Validation loss: 2.031412483543478

Epoch: 43| Step: 0
Training loss: 1.9227821826934814
Validation loss: 2.0318460925932853

Epoch: 5| Step: 1
Training loss: 1.8537960052490234
Validation loss: 2.03904051421791

Epoch: 5| Step: 2
Training loss: 2.594242811203003
Validation loss: 2.028281122125605

Epoch: 5| Step: 3
Training loss: 2.2153372764587402
Validation loss: 2.0305809949034

Epoch: 5| Step: 4
Training loss: 2.7163710594177246
Validation loss: 2.0310076039324523

Epoch: 5| Step: 5
Training loss: 2.338167905807495
Validation loss: 2.049203985480852

Epoch: 5| Step: 6
Training loss: 2.2546420097351074
Validation loss: 2.0347637463641424

Epoch: 5| Step: 7
Training loss: 2.0900704860687256
Validation loss: 2.0389210088278658

Epoch: 5| Step: 8
Training loss: 2.285585403442383
Validation loss: 2.0310634118254467

Epoch: 5| Step: 9
Training loss: 3.122069835662842
Validation loss: 2.038964890664624

Epoch: 5| Step: 10
Training loss: 2.4012300968170166
Validation loss: 2.0402315406389135

Epoch: 44| Step: 0
Training loss: 2.199540376663208
Validation loss: 2.0385030392677552

Epoch: 5| Step: 1
Training loss: 2.3028039932250977
Validation loss: 2.0277747056817494

Epoch: 5| Step: 2
Training loss: 2.113771438598633
Validation loss: 2.0341944335609354

Epoch: 5| Step: 3
Training loss: 2.773049831390381
Validation loss: 2.0208931097420315

Epoch: 5| Step: 4
Training loss: 2.6939048767089844
Validation loss: 2.0292239983876548

Epoch: 5| Step: 5
Training loss: 2.406195640563965
Validation loss: 2.0306793861491705

Epoch: 5| Step: 6
Training loss: 2.5616648197174072
Validation loss: 2.0465093197361117

Epoch: 5| Step: 7
Training loss: 2.3946282863616943
Validation loss: 2.037923535993022

Epoch: 5| Step: 8
Training loss: 2.489135265350342
Validation loss: 2.0229483086575746

Epoch: 5| Step: 9
Training loss: 1.7727477550506592
Validation loss: 2.0421828992905153

Epoch: 5| Step: 10
Training loss: 2.0125601291656494
Validation loss: 2.026005155296736

Epoch: 45| Step: 0
Training loss: 1.6041713953018188
Validation loss: 2.027303577751242

Epoch: 5| Step: 1
Training loss: 2.7854971885681152
Validation loss: 2.0203749492604244

Epoch: 5| Step: 2
Training loss: 2.434596300125122
Validation loss: 2.022005988705543

Epoch: 5| Step: 3
Training loss: 2.573402166366577
Validation loss: 2.0233196904582362

Epoch: 5| Step: 4
Training loss: 2.0795326232910156
Validation loss: 2.03643524518577

Epoch: 5| Step: 5
Training loss: 2.258654832839966
Validation loss: 2.017126944757277

Epoch: 5| Step: 6
Training loss: 2.306727409362793
Validation loss: 2.026019398884107

Epoch: 5| Step: 7
Training loss: 2.247910737991333
Validation loss: 2.023344983336746

Epoch: 5| Step: 8
Training loss: 2.550837993621826
Validation loss: 2.0147287486701884

Epoch: 5| Step: 9
Training loss: 2.0609774589538574
Validation loss: 2.032924948200103

Epoch: 5| Step: 10
Training loss: 2.8256962299346924
Validation loss: 2.029789129892985

Epoch: 46| Step: 0
Training loss: 2.3676979541778564
Validation loss: 2.0143601663651003

Epoch: 5| Step: 1
Training loss: 1.7145936489105225
Validation loss: 2.0253728961431854

Epoch: 5| Step: 2
Training loss: 2.200029134750366
Validation loss: 2.0363092948031682

Epoch: 5| Step: 3
Training loss: 2.33594012260437
Validation loss: 2.0082649543721187

Epoch: 5| Step: 4
Training loss: 2.8547110557556152
Validation loss: 2.0162431334936493

Epoch: 5| Step: 5
Training loss: 2.6064305305480957
Validation loss: 2.0071552312502297

Epoch: 5| Step: 6
Training loss: 2.565542697906494
Validation loss: 2.0240446200934787

Epoch: 5| Step: 7
Training loss: 1.9362643957138062
Validation loss: 2.012871152611189

Epoch: 5| Step: 8
Training loss: 2.4475414752960205
Validation loss: 2.021069147253549

Epoch: 5| Step: 9
Training loss: 2.1711411476135254
Validation loss: 2.027582291633852

Epoch: 5| Step: 10
Training loss: 2.3893966674804688
Validation loss: 2.0372750554033505

Epoch: 47| Step: 0
Training loss: 3.037254810333252
Validation loss: 2.0059593339120187

Epoch: 5| Step: 1
Training loss: 1.9298359155654907
Validation loss: 2.034001983622069

Epoch: 5| Step: 2
Training loss: 1.5835987329483032
Validation loss: 2.016665088233127

Epoch: 5| Step: 3
Training loss: 2.2610769271850586
Validation loss: 2.0425809711538334

Epoch: 5| Step: 4
Training loss: 2.294774293899536
Validation loss: 2.018570077034735

Epoch: 5| Step: 5
Training loss: 2.4087467193603516
Validation loss: 2.0169037542035504

Epoch: 5| Step: 6
Training loss: 2.107656955718994
Validation loss: 2.015850850330886

Epoch: 5| Step: 7
Training loss: 2.641214370727539
Validation loss: 2.0026735234004196

Epoch: 5| Step: 8
Training loss: 2.5008957386016846
Validation loss: 2.0148292946559128

Epoch: 5| Step: 9
Training loss: 2.4952311515808105
Validation loss: 2.0458848963501635

Epoch: 5| Step: 10
Training loss: 2.1534807682037354
Validation loss: 2.026323683800236

Epoch: 48| Step: 0
Training loss: 2.267071485519409
Validation loss: 2.013893553005752

Epoch: 5| Step: 1
Training loss: 2.7206783294677734
Validation loss: 2.0216788758513746

Epoch: 5| Step: 2
Training loss: 1.6792787313461304
Validation loss: 2.022553901518545

Epoch: 5| Step: 3
Training loss: 2.494462728500366
Validation loss: 2.0313884186488327

Epoch: 5| Step: 4
Training loss: 2.674164295196533
Validation loss: 2.0299810760764667

Epoch: 5| Step: 5
Training loss: 1.9207931756973267
Validation loss: 2.01835657447897

Epoch: 5| Step: 6
Training loss: 2.5947556495666504
Validation loss: 2.02470580480432

Epoch: 5| Step: 7
Training loss: 2.897904872894287
Validation loss: 2.0123578861195552

Epoch: 5| Step: 8
Training loss: 2.206110715866089
Validation loss: 2.017686508035147

Epoch: 5| Step: 9
Training loss: 2.14901065826416
Validation loss: 2.0060318362328315

Epoch: 5| Step: 10
Training loss: 1.7004917860031128
Validation loss: 2.0254518088474067

Epoch: 49| Step: 0
Training loss: 1.8061912059783936
Validation loss: 2.0102021360910065

Epoch: 5| Step: 1
Training loss: 2.518393039703369
Validation loss: 2.031355300257283

Epoch: 5| Step: 2
Training loss: 2.2990026473999023
Validation loss: 2.0089252328359954

Epoch: 5| Step: 3
Training loss: 2.1640326976776123
Validation loss: 2.008855378755959

Epoch: 5| Step: 4
Training loss: 2.3033533096313477
Validation loss: 2.0097980242903515

Epoch: 5| Step: 5
Training loss: 2.449216842651367
Validation loss: 1.9981734175835886

Epoch: 5| Step: 6
Training loss: 2.006070852279663
Validation loss: 2.010614747642189

Epoch: 5| Step: 7
Training loss: 2.4068892002105713
Validation loss: 2.0159719656872492

Epoch: 5| Step: 8
Training loss: 2.542858839035034
Validation loss: 2.0070077655135945

Epoch: 5| Step: 9
Training loss: 2.3013901710510254
Validation loss: 2.011410633722941

Epoch: 5| Step: 10
Training loss: 2.683168649673462
Validation loss: 2.027158925610204

Epoch: 50| Step: 0
Training loss: 2.5586462020874023
Validation loss: 2.02482029186782

Epoch: 5| Step: 1
Training loss: 2.192194700241089
Validation loss: 2.022929952990624

Epoch: 5| Step: 2
Training loss: 2.281805992126465
Validation loss: 2.0187679144643966

Epoch: 5| Step: 3
Training loss: 2.3885178565979004
Validation loss: 2.029728046027563

Epoch: 5| Step: 4
Training loss: 2.510902166366577
Validation loss: 2.009178756385721

Epoch: 5| Step: 5
Training loss: 2.3600857257843018
Validation loss: 2.010797646737868

Epoch: 5| Step: 6
Training loss: 2.3410778045654297
Validation loss: 2.014276676280524

Epoch: 5| Step: 7
Training loss: 2.3773419857025146
Validation loss: 2.00325208838268

Epoch: 5| Step: 8
Training loss: 2.109090805053711
Validation loss: 2.0180540879567466

Epoch: 5| Step: 9
Training loss: 1.9959754943847656
Validation loss: 2.0195698340733848

Epoch: 5| Step: 10
Training loss: 2.3452131748199463
Validation loss: 2.024798406067715

Epoch: 51| Step: 0
Training loss: 2.001329183578491
Validation loss: 2.008220975117017

Epoch: 5| Step: 1
Training loss: 2.4768357276916504
Validation loss: 1.9871253582739061

Epoch: 5| Step: 2
Training loss: 2.165994167327881
Validation loss: 2.018475463313441

Epoch: 5| Step: 3
Training loss: 2.3146309852600098
Validation loss: 2.016200221994872

Epoch: 5| Step: 4
Training loss: 2.09734845161438
Validation loss: 2.0027818423445507

Epoch: 5| Step: 5
Training loss: 2.2279255390167236
Validation loss: 2.0274429090561403

Epoch: 5| Step: 6
Training loss: 1.999959945678711
Validation loss: 1.9985008534564768

Epoch: 5| Step: 7
Training loss: 2.543919324874878
Validation loss: 2.0097643918888544

Epoch: 5| Step: 8
Training loss: 2.1585090160369873
Validation loss: 2.0187000715604393

Epoch: 5| Step: 9
Training loss: 3.1413867473602295
Validation loss: 2.0134220956474222

Epoch: 5| Step: 10
Training loss: 2.267591953277588
Validation loss: 2.007969299952189

Epoch: 52| Step: 0
Training loss: 2.0075557231903076
Validation loss: 1.9936100334249518

Epoch: 5| Step: 1
Training loss: 1.9150848388671875
Validation loss: 2.006616734689282

Epoch: 5| Step: 2
Training loss: 1.8322639465332031
Validation loss: 2.007343053817749

Epoch: 5| Step: 3
Training loss: 2.727476119995117
Validation loss: 1.9971779097792923

Epoch: 5| Step: 4
Training loss: 2.7765023708343506
Validation loss: 2.0112852691322245

Epoch: 5| Step: 5
Training loss: 2.550844192504883
Validation loss: 1.991945969161167

Epoch: 5| Step: 6
Training loss: 2.463986873626709
Validation loss: 2.0114591442128664

Epoch: 5| Step: 7
Training loss: 2.231147289276123
Validation loss: 2.017974881715672

Epoch: 5| Step: 8
Training loss: 2.448479652404785
Validation loss: 1.988697249402282

Epoch: 5| Step: 9
Training loss: 2.510666608810425
Validation loss: 2.011448061594399

Epoch: 5| Step: 10
Training loss: 1.8334773778915405
Validation loss: 2.0027674526296635

Epoch: 53| Step: 0
Training loss: 2.795836925506592
Validation loss: 1.9921839801214074

Epoch: 5| Step: 1
Training loss: 1.8518270254135132
Validation loss: 2.0044733683268228

Epoch: 5| Step: 2
Training loss: 2.793242931365967
Validation loss: 2.003559841904589

Epoch: 5| Step: 3
Training loss: 1.8807220458984375
Validation loss: 1.9954287698191981

Epoch: 5| Step: 4
Training loss: 2.7572574615478516
Validation loss: 2.0114291688447357

Epoch: 5| Step: 5
Training loss: 2.568723201751709
Validation loss: 2.020438089165636

Epoch: 5| Step: 6
Training loss: 2.007598400115967
Validation loss: 2.002316777424146

Epoch: 5| Step: 7
Training loss: 2.1118571758270264
Validation loss: 2.006987246133948

Epoch: 5| Step: 8
Training loss: 2.3360345363616943
Validation loss: 2.014151668035856

Epoch: 5| Step: 9
Training loss: 1.1622283458709717
Validation loss: 2.0081989842076458

Epoch: 5| Step: 10
Training loss: 2.9881958961486816
Validation loss: 1.9892030351905412

Epoch: 54| Step: 0
Training loss: 2.6292872428894043
Validation loss: 2.0036748314416535

Epoch: 5| Step: 1
Training loss: 2.338925838470459
Validation loss: 1.9940028370067637

Epoch: 5| Step: 2
Training loss: 2.3691389560699463
Validation loss: 2.014168962355583

Epoch: 5| Step: 3
Training loss: 2.4875035285949707
Validation loss: 2.003546637873496

Epoch: 5| Step: 4
Training loss: 2.099104642868042
Validation loss: 2.0322978265823854

Epoch: 5| Step: 5
Training loss: 2.004777193069458
Validation loss: 2.0040122027038247

Epoch: 5| Step: 6
Training loss: 2.348203182220459
Validation loss: 1.9810050251663371

Epoch: 5| Step: 7
Training loss: 1.910556435585022
Validation loss: 2.000158150990804

Epoch: 5| Step: 8
Training loss: 2.1725478172302246
Validation loss: 2.010210919123824

Epoch: 5| Step: 9
Training loss: 2.432976484298706
Validation loss: 1.9966137742483487

Epoch: 5| Step: 10
Training loss: 2.4537410736083984
Validation loss: 2.0021918678796418

Epoch: 55| Step: 0
Training loss: 2.499802827835083
Validation loss: 2.008764083667468

Epoch: 5| Step: 1
Training loss: 2.500901699066162
Validation loss: 2.0119850404800905

Epoch: 5| Step: 2
Training loss: 2.2921059131622314
Validation loss: 2.01237488818425

Epoch: 5| Step: 3
Training loss: 2.3825104236602783
Validation loss: 2.005425778768396

Epoch: 5| Step: 4
Training loss: 2.4115965366363525
Validation loss: 2.009361961836456

Epoch: 5| Step: 5
Training loss: 2.644786834716797
Validation loss: 2.0002515046827254

Epoch: 5| Step: 6
Training loss: 2.0364325046539307
Validation loss: 1.9925009999223935

Epoch: 5| Step: 7
Training loss: 1.7057511806488037
Validation loss: 2.0035274003141668

Epoch: 5| Step: 8
Training loss: 2.4019618034362793
Validation loss: 2.01045504436698

Epoch: 5| Step: 9
Training loss: 2.167332410812378
Validation loss: 2.0124469623770764

Epoch: 5| Step: 10
Training loss: 2.2238574028015137
Validation loss: 2.0049839558139926

Epoch: 56| Step: 0
Training loss: 2.472379207611084
Validation loss: 2.0098452824418263

Epoch: 5| Step: 1
Training loss: 2.263341188430786
Validation loss: 2.0111893992270193

Epoch: 5| Step: 2
Training loss: 2.028201103210449
Validation loss: 2.001129158081547

Epoch: 5| Step: 3
Training loss: 2.6868648529052734
Validation loss: 1.9909502190928305

Epoch: 5| Step: 4
Training loss: 1.781374216079712
Validation loss: 2.016464138543734

Epoch: 5| Step: 5
Training loss: 2.6609437465667725
Validation loss: 1.995620281465592

Epoch: 5| Step: 6
Training loss: 2.4603347778320312
Validation loss: 2.010372422074759

Epoch: 5| Step: 7
Training loss: 1.9614582061767578
Validation loss: 1.9845908226505402

Epoch: 5| Step: 8
Training loss: 2.6468710899353027
Validation loss: 2.012442555478824

Epoch: 5| Step: 9
Training loss: 2.215773344039917
Validation loss: 1.9936673833477883

Epoch: 5| Step: 10
Training loss: 1.951330542564392
Validation loss: 1.977733967124775

Epoch: 57| Step: 0
Training loss: 2.7143263816833496
Validation loss: 2.0045441273720033

Epoch: 5| Step: 1
Training loss: 1.937535047531128
Validation loss: 1.999699483635605

Epoch: 5| Step: 2
Training loss: 2.3888378143310547
Validation loss: 2.0049350236051824

Epoch: 5| Step: 3
Training loss: 2.39320707321167
Validation loss: 1.9884802487588698

Epoch: 5| Step: 4
Training loss: 2.6782774925231934
Validation loss: 2.0143428848635767

Epoch: 5| Step: 5
Training loss: 1.9061787128448486
Validation loss: 2.011728461070727

Epoch: 5| Step: 6
Training loss: 1.6786304712295532
Validation loss: 1.9975368104955202

Epoch: 5| Step: 7
Training loss: 2.403884172439575
Validation loss: 2.0052587319445867

Epoch: 5| Step: 8
Training loss: 2.657038450241089
Validation loss: 1.995633271432692

Epoch: 5| Step: 9
Training loss: 2.014456272125244
Validation loss: 1.99087837050038

Epoch: 5| Step: 10
Training loss: 2.487614631652832
Validation loss: 2.003130696153128

Epoch: 58| Step: 0
Training loss: 2.2444894313812256
Validation loss: 1.9889624631533058

Epoch: 5| Step: 1
Training loss: 2.5740115642547607
Validation loss: 1.994168335391629

Epoch: 5| Step: 2
Training loss: 3.047757387161255
Validation loss: 1.9903873307730562

Epoch: 5| Step: 3
Training loss: 2.5062355995178223
Validation loss: 1.9973352493778351

Epoch: 5| Step: 4
Training loss: 1.3114979267120361
Validation loss: 1.9911027826288694

Epoch: 5| Step: 5
Training loss: 1.9437936544418335
Validation loss: 1.9966020314924178

Epoch: 5| Step: 6
Training loss: 2.2837212085723877
Validation loss: 1.9950039412385674

Epoch: 5| Step: 7
Training loss: 2.337798833847046
Validation loss: 1.9952337280396493

Epoch: 5| Step: 8
Training loss: 2.079784393310547
Validation loss: 1.9860454400380452

Epoch: 5| Step: 9
Training loss: 2.577080726623535
Validation loss: 1.9759844862004763

Epoch: 5| Step: 10
Training loss: 2.1450233459472656
Validation loss: 2.002658332547834

Epoch: 59| Step: 0
Training loss: 2.39186429977417
Validation loss: 1.9938556058432466

Epoch: 5| Step: 1
Training loss: 2.498762845993042
Validation loss: 1.9831276427033127

Epoch: 5| Step: 2
Training loss: 2.467480421066284
Validation loss: 1.9680482546488445

Epoch: 5| Step: 3
Training loss: 1.8247016668319702
Validation loss: 1.9886694903014808

Epoch: 5| Step: 4
Training loss: 2.1821441650390625
Validation loss: 1.9869404441566878

Epoch: 5| Step: 5
Training loss: 1.9849746227264404
Validation loss: 1.9814187788194226

Epoch: 5| Step: 6
Training loss: 2.3237106800079346
Validation loss: 1.9970692408982145

Epoch: 5| Step: 7
Training loss: 1.924271583557129
Validation loss: 1.9964163418739074

Epoch: 5| Step: 8
Training loss: 2.2935738563537598
Validation loss: 1.9710115694230603

Epoch: 5| Step: 9
Training loss: 2.78767466545105
Validation loss: 1.987451562317469

Epoch: 5| Step: 10
Training loss: 2.2900164127349854
Validation loss: 1.9860387835451352

Epoch: 60| Step: 0
Training loss: 2.595716953277588
Validation loss: 1.9736259714249642

Epoch: 5| Step: 1
Training loss: 1.9221017360687256
Validation loss: 1.9917733387280536

Epoch: 5| Step: 2
Training loss: 2.0706825256347656
Validation loss: 1.9987494881435106

Epoch: 5| Step: 3
Training loss: 2.4390902519226074
Validation loss: 1.9948478411602717

Epoch: 5| Step: 4
Training loss: 1.9778724908828735
Validation loss: 1.999670651651198

Epoch: 5| Step: 5
Training loss: 2.0725455284118652
Validation loss: 1.9872520136576828

Epoch: 5| Step: 6
Training loss: 2.7910380363464355
Validation loss: 1.9781658290534891

Epoch: 5| Step: 7
Training loss: 2.443274736404419
Validation loss: 1.9899470908667451

Epoch: 5| Step: 8
Training loss: 2.0736446380615234
Validation loss: 1.9873032903158536

Epoch: 5| Step: 9
Training loss: 2.6531059741973877
Validation loss: 1.98254910848474

Epoch: 5| Step: 10
Training loss: 1.8286471366882324
Validation loss: 1.9814172226895568

Epoch: 61| Step: 0
Training loss: 2.266479015350342
Validation loss: 1.9816799099727342

Epoch: 5| Step: 1
Training loss: 2.7765698432922363
Validation loss: 1.9870989284207743

Epoch: 5| Step: 2
Training loss: 2.2128632068634033
Validation loss: 1.9828832995507024

Epoch: 5| Step: 3
Training loss: 2.314692497253418
Validation loss: 1.9889898325807305

Epoch: 5| Step: 4
Training loss: 2.105884075164795
Validation loss: 1.9920531754852624

Epoch: 5| Step: 5
Training loss: 2.4241280555725098
Validation loss: 1.9880930223772604

Epoch: 5| Step: 6
Training loss: 2.0069453716278076
Validation loss: 1.987670680528046

Epoch: 5| Step: 7
Training loss: 2.674434185028076
Validation loss: 1.9928791728070987

Epoch: 5| Step: 8
Training loss: 2.050657272338867
Validation loss: 1.991907629915463

Epoch: 5| Step: 9
Training loss: 2.097450017929077
Validation loss: 1.9776853105073333

Epoch: 5| Step: 10
Training loss: 2.1092519760131836
Validation loss: 1.9765596607679963

Epoch: 62| Step: 0
Training loss: 2.0559022426605225
Validation loss: 1.9925183596149567

Epoch: 5| Step: 1
Training loss: 2.1790249347686768
Validation loss: 1.9699405316383607

Epoch: 5| Step: 2
Training loss: 1.758001685142517
Validation loss: 1.9630737471324142

Epoch: 5| Step: 3
Training loss: 2.3564963340759277
Validation loss: 1.9908026982379217

Epoch: 5| Step: 4
Training loss: 2.685051441192627
Validation loss: 1.9759798537018478

Epoch: 5| Step: 5
Training loss: 2.5952067375183105
Validation loss: 1.9744643575401717

Epoch: 5| Step: 6
Training loss: 2.6642906665802
Validation loss: 1.9834078204247259

Epoch: 5| Step: 7
Training loss: 2.997246265411377
Validation loss: 1.9822543026298605

Epoch: 5| Step: 8
Training loss: 2.0560388565063477
Validation loss: 1.9805332255619827

Epoch: 5| Step: 9
Training loss: 1.7184808254241943
Validation loss: 1.9809781159124067

Epoch: 5| Step: 10
Training loss: 1.9260197877883911
Validation loss: 1.9850274491053757

Epoch: 63| Step: 0
Training loss: 2.41105318069458
Validation loss: 1.9885332199835009

Epoch: 5| Step: 1
Training loss: 1.5471274852752686
Validation loss: 1.9802367482134091

Epoch: 5| Step: 2
Training loss: 2.265394926071167
Validation loss: 1.9924669163201445

Epoch: 5| Step: 3
Training loss: 1.8785957098007202
Validation loss: 1.9848388984639158

Epoch: 5| Step: 4
Training loss: 2.923753261566162
Validation loss: 1.9752692048267653

Epoch: 5| Step: 5
Training loss: 2.3829703330993652
Validation loss: 1.9843476356998566

Epoch: 5| Step: 6
Training loss: 2.121119976043701
Validation loss: 1.9798245878629788

Epoch: 5| Step: 7
Training loss: 2.870309829711914
Validation loss: 1.996684274365825

Epoch: 5| Step: 8
Training loss: 2.4372479915618896
Validation loss: 1.9808056867250832

Epoch: 5| Step: 9
Training loss: 2.0635616779327393
Validation loss: 1.9893597620789722

Epoch: 5| Step: 10
Training loss: 2.0224671363830566
Validation loss: 1.989154428564092

Epoch: 64| Step: 0
Training loss: 2.325265645980835
Validation loss: 1.9752357954620032

Epoch: 5| Step: 1
Training loss: 1.7116397619247437
Validation loss: 1.9741155088588755

Epoch: 5| Step: 2
Training loss: 1.7666810750961304
Validation loss: 1.9794930309377692

Epoch: 5| Step: 3
Training loss: 2.4168334007263184
Validation loss: 1.9879351226232385

Epoch: 5| Step: 4
Training loss: 2.496245861053467
Validation loss: 1.9896626882655646

Epoch: 5| Step: 5
Training loss: 2.1591579914093018
Validation loss: 1.9891613798756753

Epoch: 5| Step: 6
Training loss: 1.8851149082183838
Validation loss: 1.9582937750765073

Epoch: 5| Step: 7
Training loss: 2.3548624515533447
Validation loss: 1.966031712870444

Epoch: 5| Step: 8
Training loss: 3.3427321910858154
Validation loss: 1.9731502161231091

Epoch: 5| Step: 9
Training loss: 2.062084197998047
Validation loss: 1.9833757723531416

Epoch: 5| Step: 10
Training loss: 2.4211318492889404
Validation loss: 1.9712043782716155

Epoch: 65| Step: 0
Training loss: 2.501425266265869
Validation loss: 1.985306478315784

Epoch: 5| Step: 1
Training loss: 2.184478282928467
Validation loss: 1.9825932197673346

Epoch: 5| Step: 2
Training loss: 1.9042942523956299
Validation loss: 1.9767407037878548

Epoch: 5| Step: 3
Training loss: 2.520935535430908
Validation loss: 1.9657730722940097

Epoch: 5| Step: 4
Training loss: 2.0550007820129395
Validation loss: 1.9840990984311668

Epoch: 5| Step: 5
Training loss: 2.133186101913452
Validation loss: 1.9852415464257682

Epoch: 5| Step: 6
Training loss: 2.1202046871185303
Validation loss: 1.9706481938721032

Epoch: 5| Step: 7
Training loss: 2.29791522026062
Validation loss: 1.9669666213373984

Epoch: 5| Step: 8
Training loss: 2.056063652038574
Validation loss: 1.9763817530806347

Epoch: 5| Step: 9
Training loss: 2.800157070159912
Validation loss: 1.9789414200731503

Epoch: 5| Step: 10
Training loss: 2.3764615058898926
Validation loss: 1.9741100739407282

Epoch: 66| Step: 0
Training loss: 2.470609664916992
Validation loss: 1.9684547173079623

Epoch: 5| Step: 1
Training loss: 1.6628917455673218
Validation loss: 1.9775775376186575

Epoch: 5| Step: 2
Training loss: 2.7637200355529785
Validation loss: 1.9828894881791965

Epoch: 5| Step: 3
Training loss: 1.8301979303359985
Validation loss: 1.9805953682109874

Epoch: 5| Step: 4
Training loss: 2.55022931098938
Validation loss: 1.9846153669459845

Epoch: 5| Step: 5
Training loss: 2.100482940673828
Validation loss: 1.9857084494765087

Epoch: 5| Step: 6
Training loss: 1.9898605346679688
Validation loss: 1.9835775834257885

Epoch: 5| Step: 7
Training loss: 2.792018175125122
Validation loss: 1.9846290952415877

Epoch: 5| Step: 8
Training loss: 2.619751453399658
Validation loss: 1.98162168072116

Epoch: 5| Step: 9
Training loss: 2.07145357131958
Validation loss: 1.9855826721396497

Epoch: 5| Step: 10
Training loss: 2.0485754013061523
Validation loss: 1.9917382271059099

Epoch: 67| Step: 0
Training loss: 2.52734637260437
Validation loss: 1.988038952632617

Epoch: 5| Step: 1
Training loss: 2.673957109451294
Validation loss: 1.9667826211580666

Epoch: 5| Step: 2
Training loss: 1.5205638408660889
Validation loss: 1.9889183941707815

Epoch: 5| Step: 3
Training loss: 2.2176952362060547
Validation loss: 1.9817130104187997

Epoch: 5| Step: 4
Training loss: 2.227306842803955
Validation loss: 1.9729618667274393

Epoch: 5| Step: 5
Training loss: 3.038289785385132
Validation loss: 1.9931610399676907

Epoch: 5| Step: 6
Training loss: 2.576735496520996
Validation loss: 1.972571731895529

Epoch: 5| Step: 7
Training loss: 1.8896585702896118
Validation loss: 1.989806399550489

Epoch: 5| Step: 8
Training loss: 1.367340326309204
Validation loss: 1.9789728310800367

Epoch: 5| Step: 9
Training loss: 1.9838184118270874
Validation loss: 1.9928267976289153

Epoch: 5| Step: 10
Training loss: 2.884765625
Validation loss: 1.9690482847152218

Epoch: 68| Step: 0
Training loss: 2.0802204608917236
Validation loss: 1.972894440415085

Epoch: 5| Step: 1
Training loss: 2.073136568069458
Validation loss: 1.978653477084252

Epoch: 5| Step: 2
Training loss: 2.0182528495788574
Validation loss: 1.983695468594951

Epoch: 5| Step: 3
Training loss: 1.7268158197402954
Validation loss: 1.953559567851405

Epoch: 5| Step: 4
Training loss: 2.0297231674194336
Validation loss: 1.961381955813336

Epoch: 5| Step: 5
Training loss: 2.3693814277648926
Validation loss: 1.9741999256995417

Epoch: 5| Step: 6
Training loss: 2.4665653705596924
Validation loss: 1.9715889782033942

Epoch: 5| Step: 7
Training loss: 2.2515218257904053
Validation loss: 1.9794938154118036

Epoch: 5| Step: 8
Training loss: 2.914278745651245
Validation loss: 1.9672032863863054

Epoch: 5| Step: 9
Training loss: 2.221693277359009
Validation loss: 1.9749683615981892

Epoch: 5| Step: 10
Training loss: 2.7227563858032227
Validation loss: 1.968515403809086

Epoch: 69| Step: 0
Training loss: 2.230062484741211
Validation loss: 1.9749591376191826

Epoch: 5| Step: 1
Training loss: 2.0309855937957764
Validation loss: 1.9636216343090098

Epoch: 5| Step: 2
Training loss: 2.0764589309692383
Validation loss: 1.9661670372050295

Epoch: 5| Step: 3
Training loss: 2.7023353576660156
Validation loss: 1.9614826902266471

Epoch: 5| Step: 4
Training loss: 2.43548321723938
Validation loss: 1.9731961950179069

Epoch: 5| Step: 5
Training loss: 2.3990588188171387
Validation loss: 1.9703436051645586

Epoch: 5| Step: 6
Training loss: 2.4960782527923584
Validation loss: 1.9417004521175096

Epoch: 5| Step: 7
Training loss: 2.127687692642212
Validation loss: 1.9638972564410138

Epoch: 5| Step: 8
Training loss: 2.370830535888672
Validation loss: 1.9725175006415254

Epoch: 5| Step: 9
Training loss: 1.9822429418563843
Validation loss: 1.965843044301515

Epoch: 5| Step: 10
Training loss: 1.908704161643982
Validation loss: 1.9593355681306572

Epoch: 70| Step: 0
Training loss: 2.5233726501464844
Validation loss: 1.967998004728748

Epoch: 5| Step: 1
Training loss: 2.049724817276001
Validation loss: 1.9506527762259207

Epoch: 5| Step: 2
Training loss: 2.463175058364868
Validation loss: 1.97173648752192

Epoch: 5| Step: 3
Training loss: 2.5571963787078857
Validation loss: 1.9699323869520617

Epoch: 5| Step: 4
Training loss: 2.327340602874756
Validation loss: 1.9635259566768524

Epoch: 5| Step: 5
Training loss: 2.110644817352295
Validation loss: 1.9721436346730878

Epoch: 5| Step: 6
Training loss: 1.7983204126358032
Validation loss: 1.9536435219549364

Epoch: 5| Step: 7
Training loss: 2.528637409210205
Validation loss: 1.9703695940715011

Epoch: 5| Step: 8
Training loss: 2.479217052459717
Validation loss: 1.9643170102950065

Epoch: 5| Step: 9
Training loss: 1.667601227760315
Validation loss: 1.9911279075889177

Epoch: 5| Step: 10
Training loss: 2.2567896842956543
Validation loss: 1.9745998754296252

Epoch: 71| Step: 0
Training loss: 2.3832695484161377
Validation loss: 1.973406163595056

Epoch: 5| Step: 1
Training loss: 2.2582552433013916
Validation loss: 1.9535366078858734

Epoch: 5| Step: 2
Training loss: 1.982967734336853
Validation loss: 1.9713912792103265

Epoch: 5| Step: 3
Training loss: 1.9611432552337646
Validation loss: 1.9648284707018124

Epoch: 5| Step: 4
Training loss: 2.5869975090026855
Validation loss: 1.9726845115743659

Epoch: 5| Step: 5
Training loss: 1.7435283660888672
Validation loss: 1.9759407428003126

Epoch: 5| Step: 6
Training loss: 2.394272565841675
Validation loss: 1.964233495855844

Epoch: 5| Step: 7
Training loss: 2.3166921138763428
Validation loss: 1.9723706911968928

Epoch: 5| Step: 8
Training loss: 2.5650150775909424
Validation loss: 1.9810664974233156

Epoch: 5| Step: 9
Training loss: 2.2234244346618652
Validation loss: 1.9948873084078553

Epoch: 5| Step: 10
Training loss: 2.249746561050415
Validation loss: 1.9688307674982215

Epoch: 72| Step: 0
Training loss: 1.7882499694824219
Validation loss: 1.9645217208452121

Epoch: 5| Step: 1
Training loss: 1.7297033071517944
Validation loss: 1.978112095145769

Epoch: 5| Step: 2
Training loss: 2.6214981079101562
Validation loss: 1.960305380564864

Epoch: 5| Step: 3
Training loss: 2.0983333587646484
Validation loss: 1.9829680817101591

Epoch: 5| Step: 4
Training loss: 2.769441604614258
Validation loss: 1.9637173619321597

Epoch: 5| Step: 5
Training loss: 1.683233618736267
Validation loss: 1.955879275516797

Epoch: 5| Step: 6
Training loss: 2.426368236541748
Validation loss: 1.965394079044301

Epoch: 5| Step: 7
Training loss: 2.528272867202759
Validation loss: 1.9624491391643402

Epoch: 5| Step: 8
Training loss: 2.5963265895843506
Validation loss: 1.9697341842036094

Epoch: 5| Step: 9
Training loss: 2.3047165870666504
Validation loss: 1.9601220879503476

Epoch: 5| Step: 10
Training loss: 2.1172373294830322
Validation loss: 1.9758857424541185

Epoch: 73| Step: 0
Training loss: 2.447709798812866
Validation loss: 1.969256967626592

Epoch: 5| Step: 1
Training loss: 1.971680998802185
Validation loss: 1.9748786969851422

Epoch: 5| Step: 2
Training loss: 2.2946879863739014
Validation loss: 1.9513179307342858

Epoch: 5| Step: 3
Training loss: 1.9111652374267578
Validation loss: 1.9871803406746156

Epoch: 5| Step: 4
Training loss: 2.574324369430542
Validation loss: 1.9827276506731588

Epoch: 5| Step: 5
Training loss: 2.0218164920806885
Validation loss: 1.9621789455413818

Epoch: 5| Step: 6
Training loss: 2.6535072326660156
Validation loss: 1.9619918971933343

Epoch: 5| Step: 7
Training loss: 3.1290438175201416
Validation loss: 1.9820687514479443

Epoch: 5| Step: 8
Training loss: 2.057379961013794
Validation loss: 1.9770845777244979

Epoch: 5| Step: 9
Training loss: 1.8962204456329346
Validation loss: 1.9506966811354443

Epoch: 5| Step: 10
Training loss: 1.711202621459961
Validation loss: 1.9620220225344422

Epoch: 74| Step: 0
Training loss: 2.7899117469787598
Validation loss: 1.9683393278429586

Epoch: 5| Step: 1
Training loss: 2.1790688037872314
Validation loss: 1.9606129136136783

Epoch: 5| Step: 2
Training loss: 2.493492841720581
Validation loss: 1.9610942896976267

Epoch: 5| Step: 3
Training loss: 2.1672475337982178
Validation loss: 1.9737418313180246

Epoch: 5| Step: 4
Training loss: 2.4996190071105957
Validation loss: 1.988109165622342

Epoch: 5| Step: 5
Training loss: 1.8535382747650146
Validation loss: 1.987594102018623

Epoch: 5| Step: 6
Training loss: 1.998530626296997
Validation loss: 1.977985526925774

Epoch: 5| Step: 7
Training loss: 2.1776881217956543
Validation loss: 1.9599564818925754

Epoch: 5| Step: 8
Training loss: 1.8208601474761963
Validation loss: 1.9662443719884402

Epoch: 5| Step: 9
Training loss: 2.4989259243011475
Validation loss: 1.9580099813399776

Epoch: 5| Step: 10
Training loss: 2.1548728942871094
Validation loss: 1.9740025868979834

Epoch: 75| Step: 0
Training loss: 2.0364460945129395
Validation loss: 1.9655772588586296

Epoch: 5| Step: 1
Training loss: 1.7115809917449951
Validation loss: 1.9676965872446697

Epoch: 5| Step: 2
Training loss: 2.414188861846924
Validation loss: 1.9906978799450783

Epoch: 5| Step: 3
Training loss: 2.4152188301086426
Validation loss: 1.9739337634014826

Epoch: 5| Step: 4
Training loss: 2.3940722942352295
Validation loss: 1.9809123008481917

Epoch: 5| Step: 5
Training loss: 2.383678436279297
Validation loss: 1.9682836712047618

Epoch: 5| Step: 6
Training loss: 1.7898677587509155
Validation loss: 1.9666501258009224

Epoch: 5| Step: 7
Training loss: 2.4017183780670166
Validation loss: 1.9787669079278105

Epoch: 5| Step: 8
Training loss: 2.6554391384124756
Validation loss: 1.9611120441908478

Epoch: 5| Step: 9
Training loss: 1.9545131921768188
Validation loss: 1.972818502815821

Epoch: 5| Step: 10
Training loss: 2.60977840423584
Validation loss: 1.9656471052477438

Epoch: 76| Step: 0
Training loss: 2.4767086505889893
Validation loss: 1.954086458811196

Epoch: 5| Step: 1
Training loss: 2.2384848594665527
Validation loss: 1.9739530240335772

Epoch: 5| Step: 2
Training loss: 2.6877427101135254
Validation loss: 1.9763768578088412

Epoch: 5| Step: 3
Training loss: 2.196819305419922
Validation loss: 1.9772893228838522

Epoch: 5| Step: 4
Training loss: 1.6159489154815674
Validation loss: 1.9621309798250917

Epoch: 5| Step: 5
Training loss: 1.6162570714950562
Validation loss: 1.9677540230494674

Epoch: 5| Step: 6
Training loss: 2.3683338165283203
Validation loss: 1.9678376490069973

Epoch: 5| Step: 7
Training loss: 2.8276267051696777
Validation loss: 1.96382479001117

Epoch: 5| Step: 8
Training loss: 2.2249956130981445
Validation loss: 1.9736914865432247

Epoch: 5| Step: 9
Training loss: 2.2851672172546387
Validation loss: 1.9769181551471833

Epoch: 5| Step: 10
Training loss: 1.8903836011886597
Validation loss: 1.9575320802709109

Epoch: 77| Step: 0
Training loss: 2.670405864715576
Validation loss: 1.9614864959511706

Epoch: 5| Step: 1
Training loss: 1.6286392211914062
Validation loss: 1.975042111130171

Epoch: 5| Step: 2
Training loss: 2.0358784198760986
Validation loss: 1.971955471141364

Epoch: 5| Step: 3
Training loss: 2.483084201812744
Validation loss: 1.972629685555735

Epoch: 5| Step: 4
Training loss: 2.469599485397339
Validation loss: 1.9610485953669394

Epoch: 5| Step: 5
Training loss: 2.807455062866211
Validation loss: 1.9665788681276384

Epoch: 5| Step: 6
Training loss: 2.2433204650878906
Validation loss: 1.972216534358199

Epoch: 5| Step: 7
Training loss: 2.0484280586242676
Validation loss: 1.9686206348480717

Epoch: 5| Step: 8
Training loss: 1.9334945678710938
Validation loss: 1.9794342235852314

Epoch: 5| Step: 9
Training loss: 1.9079406261444092
Validation loss: 1.9803272908733738

Epoch: 5| Step: 10
Training loss: 2.2020559310913086
Validation loss: 1.953222491407907

Epoch: 78| Step: 0
Training loss: 2.921644449234009
Validation loss: 1.979363526067426

Epoch: 5| Step: 1
Training loss: 2.1571590900421143
Validation loss: 1.9700726655221754

Epoch: 5| Step: 2
Training loss: 2.0459208488464355
Validation loss: 1.9731908203453146

Epoch: 5| Step: 3
Training loss: 1.9524357318878174
Validation loss: 1.9717501850538357

Epoch: 5| Step: 4
Training loss: 2.0508151054382324
Validation loss: 1.959885933065927

Epoch: 5| Step: 5
Training loss: 2.4496395587921143
Validation loss: 1.9735371874224754

Epoch: 5| Step: 6
Training loss: 1.7620868682861328
Validation loss: 1.9732546421789354

Epoch: 5| Step: 7
Training loss: 2.0498576164245605
Validation loss: 1.968842044953377

Epoch: 5| Step: 8
Training loss: 2.328364849090576
Validation loss: 1.9762453597079042

Epoch: 5| Step: 9
Training loss: 3.027860403060913
Validation loss: 1.9623983752342962

Epoch: 5| Step: 10
Training loss: 1.8406490087509155
Validation loss: 1.9552517757620862

Epoch: 79| Step: 0
Training loss: 2.4301908016204834
Validation loss: 1.9675385029085222

Epoch: 5| Step: 1
Training loss: 2.0074305534362793
Validation loss: 1.9808206122408631

Epoch: 5| Step: 2
Training loss: 2.56113338470459
Validation loss: 1.9719439116857385

Epoch: 5| Step: 3
Training loss: 2.369929075241089
Validation loss: 1.9732645852591402

Epoch: 5| Step: 4
Training loss: 2.0143420696258545
Validation loss: 1.9560743070417834

Epoch: 5| Step: 5
Training loss: 2.611778974533081
Validation loss: 1.981014323490922

Epoch: 5| Step: 6
Training loss: 2.3559508323669434
Validation loss: 1.9688662149572884

Epoch: 5| Step: 7
Training loss: 1.8656747341156006
Validation loss: 1.9725254966366677

Epoch: 5| Step: 8
Training loss: 2.200068950653076
Validation loss: 1.970051634696222

Epoch: 5| Step: 9
Training loss: 2.153925657272339
Validation loss: 1.9765700140307028

Epoch: 5| Step: 10
Training loss: 1.835361361503601
Validation loss: 1.962733676356654

Epoch: 80| Step: 0
Training loss: 2.079017400741577
Validation loss: 1.974345354623692

Epoch: 5| Step: 1
Training loss: 1.9658308029174805
Validation loss: 1.957670589928986

Epoch: 5| Step: 2
Training loss: 2.617233991622925
Validation loss: 1.9669724459289222

Epoch: 5| Step: 3
Training loss: 2.2054266929626465
Validation loss: 1.9735527910212034

Epoch: 5| Step: 4
Training loss: 2.1628754138946533
Validation loss: 1.990647828707131

Epoch: 5| Step: 5
Training loss: 1.968893051147461
Validation loss: 1.9774067760795675

Epoch: 5| Step: 6
Training loss: 2.388639450073242
Validation loss: 1.9641443247436194

Epoch: 5| Step: 7
Training loss: 1.2985999584197998
Validation loss: 1.9715157939541725

Epoch: 5| Step: 8
Training loss: 2.5372955799102783
Validation loss: 1.9732187268554524

Epoch: 5| Step: 9
Training loss: 2.583101511001587
Validation loss: 1.9777003142141527

Epoch: 5| Step: 10
Training loss: 2.7793490886688232
Validation loss: 1.9693002623896445

Epoch: 81| Step: 0
Training loss: 1.756605863571167
Validation loss: 1.9797351206502607

Epoch: 5| Step: 1
Training loss: 2.567396640777588
Validation loss: 1.960996699589555

Epoch: 5| Step: 2
Training loss: 1.8067384958267212
Validation loss: 1.9653852011567803

Epoch: 5| Step: 3
Training loss: 2.0239171981811523
Validation loss: 1.9953859108750538

Epoch: 5| Step: 4
Training loss: 2.5644986629486084
Validation loss: 1.9823831076263099

Epoch: 5| Step: 5
Training loss: 2.324704647064209
Validation loss: 1.9567692356724893

Epoch: 5| Step: 6
Training loss: 2.0798656940460205
Validation loss: 1.980713080334407

Epoch: 5| Step: 7
Training loss: 2.464885711669922
Validation loss: 1.9980331979772097

Epoch: 5| Step: 8
Training loss: 2.4716615676879883
Validation loss: 1.9574552338610414

Epoch: 5| Step: 9
Training loss: 2.345698118209839
Validation loss: 1.9717393485448693

Epoch: 5| Step: 10
Training loss: 1.94649076461792
Validation loss: 1.9642554278014808

Epoch: 82| Step: 0
Training loss: 1.8311446905136108
Validation loss: 1.9754406688033894

Epoch: 5| Step: 1
Training loss: 2.255640745162964
Validation loss: 1.9784000894074798

Epoch: 5| Step: 2
Training loss: 2.6474990844726562
Validation loss: 1.9880196304731472

Epoch: 5| Step: 3
Training loss: 2.469132900238037
Validation loss: 1.9648160216628865

Epoch: 5| Step: 4
Training loss: 1.6437667608261108
Validation loss: 1.9826481560225129

Epoch: 5| Step: 5
Training loss: 2.7533907890319824
Validation loss: 1.9724002922734907

Epoch: 5| Step: 6
Training loss: 2.0141282081604004
Validation loss: 1.972620274430962

Epoch: 5| Step: 7
Training loss: 2.039325714111328
Validation loss: 1.97884972505672

Epoch: 5| Step: 8
Training loss: 2.380033016204834
Validation loss: 1.9767670836499942

Epoch: 5| Step: 9
Training loss: 2.2359375953674316
Validation loss: 1.9705646653329172

Epoch: 5| Step: 10
Training loss: 2.137253522872925
Validation loss: 1.97579284380841

Epoch: 83| Step: 0
Training loss: 2.372612953186035
Validation loss: 1.9799876584801623

Epoch: 5| Step: 1
Training loss: 2.4667141437530518
Validation loss: 1.9776654128105409

Epoch: 5| Step: 2
Training loss: 2.2270383834838867
Validation loss: 1.98265109010922

Epoch: 5| Step: 3
Training loss: 2.0865540504455566
Validation loss: 1.9493817103806363

Epoch: 5| Step: 4
Training loss: 1.9075806140899658
Validation loss: 1.9700719848755868

Epoch: 5| Step: 5
Training loss: 2.235013484954834
Validation loss: 1.976685224040862

Epoch: 5| Step: 6
Training loss: 2.102006196975708
Validation loss: 1.9645200596060803

Epoch: 5| Step: 7
Training loss: 1.7891643047332764
Validation loss: 1.9494880758306032

Epoch: 5| Step: 8
Training loss: 2.3862388134002686
Validation loss: 1.9831153321009811

Epoch: 5| Step: 9
Training loss: 2.8064217567443848
Validation loss: 1.9731007032496954

Epoch: 5| Step: 10
Training loss: 2.0258893966674805
Validation loss: 1.962312517627593

Epoch: 84| Step: 0
Training loss: 2.0108470916748047
Validation loss: 1.9646214874841834

Epoch: 5| Step: 1
Training loss: 2.369093179702759
Validation loss: 1.9735680933921569

Epoch: 5| Step: 2
Training loss: 2.2284717559814453
Validation loss: 1.956455878032151

Epoch: 5| Step: 3
Training loss: 1.265582799911499
Validation loss: 1.978229179177233

Epoch: 5| Step: 4
Training loss: 2.9172110557556152
Validation loss: 1.9520186608837498

Epoch: 5| Step: 5
Training loss: 2.050114870071411
Validation loss: 1.9700023012776529

Epoch: 5| Step: 6
Training loss: 2.1754512786865234
Validation loss: 1.9865327599228069

Epoch: 5| Step: 7
Training loss: 2.412092685699463
Validation loss: 1.9515041382082048

Epoch: 5| Step: 8
Training loss: 2.4657158851623535
Validation loss: 1.9659513081273725

Epoch: 5| Step: 9
Training loss: 1.9589910507202148
Validation loss: 1.9657198575235182

Epoch: 5| Step: 10
Training loss: 2.504399061203003
Validation loss: 1.9784027786665066

Epoch: 85| Step: 0
Training loss: 2.7221672534942627
Validation loss: 1.9700651220096055

Epoch: 5| Step: 1
Training loss: 1.8731260299682617
Validation loss: 1.9775045892243743

Epoch: 5| Step: 2
Training loss: 1.4721769094467163
Validation loss: 1.9699129417378416

Epoch: 5| Step: 3
Training loss: 2.7488770484924316
Validation loss: 1.974375960647419

Epoch: 5| Step: 4
Training loss: 2.041754961013794
Validation loss: 1.9647913017580587

Epoch: 5| Step: 5
Training loss: 2.3600401878356934
Validation loss: 1.9837989973765549

Epoch: 5| Step: 6
Training loss: 2.552647113800049
Validation loss: 1.9977310267827844

Epoch: 5| Step: 7
Training loss: 2.287142515182495
Validation loss: 1.9856584200295069

Epoch: 5| Step: 8
Training loss: 2.365518093109131
Validation loss: 1.9811550468526862

Epoch: 5| Step: 9
Training loss: 2.0279672145843506
Validation loss: 1.9793120532907464

Epoch: 5| Step: 10
Training loss: 2.0078930854797363
Validation loss: 1.958009430157241

Epoch: 86| Step: 0
Training loss: 1.6395416259765625
Validation loss: 1.942254735577491

Epoch: 5| Step: 1
Training loss: 2.526690721511841
Validation loss: 1.9698416225371822

Epoch: 5| Step: 2
Training loss: 2.8120968341827393
Validation loss: 1.966941342558912

Epoch: 5| Step: 3
Training loss: 2.0931639671325684
Validation loss: 1.9561223778673398

Epoch: 5| Step: 4
Training loss: 2.3752846717834473
Validation loss: 1.9845703442891438

Epoch: 5| Step: 5
Training loss: 2.6400070190429688
Validation loss: 1.965827416348201

Epoch: 5| Step: 6
Training loss: 1.7990198135375977
Validation loss: 1.9695735887814594

Epoch: 5| Step: 7
Training loss: 1.9063043594360352
Validation loss: 1.9726486090690858

Epoch: 5| Step: 8
Training loss: 2.1107144355773926
Validation loss: 1.9588748498629498

Epoch: 5| Step: 9
Training loss: 2.082494020462036
Validation loss: 1.9846254523082445

Epoch: 5| Step: 10
Training loss: 2.389134168624878
Validation loss: 1.9494957693161503

Epoch: 87| Step: 0
Training loss: 1.916592001914978
Validation loss: 1.9710157379027335

Epoch: 5| Step: 1
Training loss: 2.473362922668457
Validation loss: 1.9513516502995645

Epoch: 5| Step: 2
Training loss: 2.3358359336853027
Validation loss: 1.9718358862784602

Epoch: 5| Step: 3
Training loss: 2.1196045875549316
Validation loss: 1.9705871587158532

Epoch: 5| Step: 4
Training loss: 2.034379243850708
Validation loss: 1.9698888588977117

Epoch: 5| Step: 5
Training loss: 2.5471761226654053
Validation loss: 1.9651481515617781

Epoch: 5| Step: 6
Training loss: 1.9134578704833984
Validation loss: 1.955578504070159

Epoch: 5| Step: 7
Training loss: 1.9532053470611572
Validation loss: 1.9777172867969801

Epoch: 5| Step: 8
Training loss: 2.0447309017181396
Validation loss: 1.9719611778054187

Epoch: 5| Step: 9
Training loss: 2.5278403759002686
Validation loss: 1.9783027838635188

Epoch: 5| Step: 10
Training loss: 2.556053400039673
Validation loss: 1.9647503219625002

Epoch: 88| Step: 0
Training loss: 1.8055862188339233
Validation loss: 1.966699618165211

Epoch: 5| Step: 1
Training loss: 1.849299669265747
Validation loss: 1.9894132908954416

Epoch: 5| Step: 2
Training loss: 2.5241215229034424
Validation loss: 1.9660754960070375

Epoch: 5| Step: 3
Training loss: 3.3371646404266357
Validation loss: 1.9742137027043167

Epoch: 5| Step: 4
Training loss: 1.8621270656585693
Validation loss: 1.948231529164058

Epoch: 5| Step: 5
Training loss: 2.4224584102630615
Validation loss: 1.975838932939755

Epoch: 5| Step: 6
Training loss: 2.206343412399292
Validation loss: 1.980771400595224

Epoch: 5| Step: 7
Training loss: 2.454965114593506
Validation loss: 1.988215390072074

Epoch: 5| Step: 8
Training loss: 1.7749437093734741
Validation loss: 1.9860457425476403

Epoch: 5| Step: 9
Training loss: 2.0190412998199463
Validation loss: 1.980441959955359

Epoch: 5| Step: 10
Training loss: 2.0501694679260254
Validation loss: 1.9897067854481358

Epoch: 89| Step: 0
Training loss: 2.28757381439209
Validation loss: 1.9892580406640166

Epoch: 5| Step: 1
Training loss: 1.8281742334365845
Validation loss: 1.9928165533209359

Epoch: 5| Step: 2
Training loss: 2.6897056102752686
Validation loss: 2.00247936607689

Epoch: 5| Step: 3
Training loss: 2.1975293159484863
Validation loss: 1.9811706530150546

Epoch: 5| Step: 4
Training loss: 2.4521021842956543
Validation loss: 1.9887006244351786

Epoch: 5| Step: 5
Training loss: 1.3166168928146362
Validation loss: 1.97403165858279

Epoch: 5| Step: 6
Training loss: 2.0944454669952393
Validation loss: 1.9978340876999723

Epoch: 5| Step: 7
Training loss: 1.9901330471038818
Validation loss: 1.9949546616564515

Epoch: 5| Step: 8
Training loss: 1.920713186264038
Validation loss: 1.9723771874622633

Epoch: 5| Step: 9
Training loss: 2.630296230316162
Validation loss: 1.9853301125188028

Epoch: 5| Step: 10
Training loss: 2.8566362857818604
Validation loss: 1.9750297659186906

Epoch: 90| Step: 0
Training loss: 2.702799081802368
Validation loss: 2.00064911893619

Epoch: 5| Step: 1
Training loss: 2.113190174102783
Validation loss: 1.9853475491205852

Epoch: 5| Step: 2
Training loss: 1.7508041858673096
Validation loss: 1.9891975874541907

Epoch: 5| Step: 3
Training loss: 2.6280906200408936
Validation loss: 2.0013625621795654

Epoch: 5| Step: 4
Training loss: 2.6767661571502686
Validation loss: 1.9683840197901572

Epoch: 5| Step: 5
Training loss: 2.2052314281463623
Validation loss: 1.9919566928699453

Epoch: 5| Step: 6
Training loss: 2.3517513275146484
Validation loss: 1.983028709247548

Epoch: 5| Step: 7
Training loss: 2.1833460330963135
Validation loss: 1.972584291171002

Epoch: 5| Step: 8
Training loss: 2.1887810230255127
Validation loss: 1.9782215600372643

Epoch: 5| Step: 9
Training loss: 1.8349958658218384
Validation loss: 1.9904346055881952

Epoch: 5| Step: 10
Training loss: 1.6763076782226562
Validation loss: 1.9719767416677167

Epoch: 91| Step: 0
Training loss: 2.60911226272583
Validation loss: 1.997300797893155

Epoch: 5| Step: 1
Training loss: 2.1522083282470703
Validation loss: 1.9823783982184626

Epoch: 5| Step: 2
Training loss: 1.716679334640503
Validation loss: 2.008228237910937

Epoch: 5| Step: 3
Training loss: 2.2231411933898926
Validation loss: 1.9698288568886377

Epoch: 5| Step: 4
Training loss: 2.552447557449341
Validation loss: 1.99023957919049

Epoch: 5| Step: 5
Training loss: 2.0032107830047607
Validation loss: 1.9915538577623264

Epoch: 5| Step: 6
Training loss: 2.246943712234497
Validation loss: 1.9798990590597993

Epoch: 5| Step: 7
Training loss: 2.2797000408172607
Validation loss: 1.972733433528613

Epoch: 5| Step: 8
Training loss: 2.431514263153076
Validation loss: 1.9763472003321494

Epoch: 5| Step: 9
Training loss: 2.17413330078125
Validation loss: 1.9615840476046327

Epoch: 5| Step: 10
Training loss: 1.7092862129211426
Validation loss: 1.967879904213772

Epoch: 92| Step: 0
Training loss: 2.3586056232452393
Validation loss: 1.9613935844872588

Epoch: 5| Step: 1
Training loss: 1.8402408361434937
Validation loss: 1.9737680099343742

Epoch: 5| Step: 2
Training loss: 1.7868140935897827
Validation loss: 1.9865353466362081

Epoch: 5| Step: 3
Training loss: 2.085148811340332
Validation loss: 1.977136432483632

Epoch: 5| Step: 4
Training loss: 2.5690133571624756
Validation loss: 1.9659529783392464

Epoch: 5| Step: 5
Training loss: 2.0062649250030518
Validation loss: 1.9763517302851523

Epoch: 5| Step: 6
Training loss: 2.2916831970214844
Validation loss: 1.9726701526231663

Epoch: 5| Step: 7
Training loss: 2.5445525646209717
Validation loss: 1.9835456064952317

Epoch: 5| Step: 8
Training loss: 2.3965001106262207
Validation loss: 1.9773805718268118

Epoch: 5| Step: 9
Training loss: 2.327059507369995
Validation loss: 1.9861580159074517

Epoch: 5| Step: 10
Training loss: 2.0206737518310547
Validation loss: 1.97906280332996

Epoch: 93| Step: 0
Training loss: 1.7054516077041626
Validation loss: 1.9804980870216125

Epoch: 5| Step: 1
Training loss: 2.9648499488830566
Validation loss: 1.9743528109724804

Epoch: 5| Step: 2
Training loss: 2.4089279174804688
Validation loss: 1.9844164425326931

Epoch: 5| Step: 3
Training loss: 2.731454372406006
Validation loss: 1.9889198477550218

Epoch: 5| Step: 4
Training loss: 1.3047316074371338
Validation loss: 1.9633711922553279

Epoch: 5| Step: 5
Training loss: 2.8505640029907227
Validation loss: 1.9745578227504608

Epoch: 5| Step: 6
Training loss: 2.0298643112182617
Validation loss: 1.9680552431332168

Epoch: 5| Step: 7
Training loss: 2.2098228931427
Validation loss: 1.9785444813389932

Epoch: 5| Step: 8
Training loss: 2.2990963459014893
Validation loss: 1.9684213156341224

Epoch: 5| Step: 9
Training loss: 1.7146981954574585
Validation loss: 1.9869350605113532

Epoch: 5| Step: 10
Training loss: 2.0266239643096924
Validation loss: 1.974259913608592

Epoch: 94| Step: 0
Training loss: 1.9757121801376343
Validation loss: 1.9710968258560344

Epoch: 5| Step: 1
Training loss: 2.392282485961914
Validation loss: 1.9809422672435801

Epoch: 5| Step: 2
Training loss: 2.1821703910827637
Validation loss: 1.9621385400013258

Epoch: 5| Step: 3
Training loss: 2.419532060623169
Validation loss: 1.9929565703997048

Epoch: 5| Step: 4
Training loss: 2.152477741241455
Validation loss: 1.9759040853028655

Epoch: 5| Step: 5
Training loss: 2.3245315551757812
Validation loss: 2.001400616861159

Epoch: 5| Step: 6
Training loss: 1.9003740549087524
Validation loss: 1.9841849239923621

Epoch: 5| Step: 7
Training loss: 1.7479972839355469
Validation loss: 1.97985279175543

Epoch: 5| Step: 8
Training loss: 2.1396756172180176
Validation loss: 1.9828254112633326

Epoch: 5| Step: 9
Training loss: 2.5810706615448
Validation loss: 1.9917993673714258

Epoch: 5| Step: 10
Training loss: 2.448671340942383
Validation loss: 1.992431027914888

Epoch: 95| Step: 0
Training loss: 2.2999768257141113
Validation loss: 1.9721333173013502

Epoch: 5| Step: 1
Training loss: 2.082028865814209
Validation loss: 1.9904890060424805

Epoch: 5| Step: 2
Training loss: 2.153886318206787
Validation loss: 1.9875474027408067

Epoch: 5| Step: 3
Training loss: 1.8120200634002686
Validation loss: 1.9891225945565008

Epoch: 5| Step: 4
Training loss: 2.5546841621398926
Validation loss: 1.9783405898719706

Epoch: 5| Step: 5
Training loss: 2.015801191329956
Validation loss: 1.9839602619089105

Epoch: 5| Step: 6
Training loss: 2.5330138206481934
Validation loss: 1.983524319946125

Epoch: 5| Step: 7
Training loss: 2.1138417720794678
Validation loss: 1.9744753709403418

Epoch: 5| Step: 8
Training loss: 2.302478313446045
Validation loss: 1.9836160072716333

Epoch: 5| Step: 9
Training loss: 2.042576313018799
Validation loss: 1.983846910538212

Epoch: 5| Step: 10
Training loss: 2.290013551712036
Validation loss: 1.976754144955707

Epoch: 96| Step: 0
Training loss: 2.791290044784546
Validation loss: 1.9785239542684248

Epoch: 5| Step: 1
Training loss: 1.9750179052352905
Validation loss: 1.9779925269465293

Epoch: 5| Step: 2
Training loss: 2.161133289337158
Validation loss: 1.9761846616703977

Epoch: 5| Step: 3
Training loss: 2.2878856658935547
Validation loss: 1.998593202201269

Epoch: 5| Step: 4
Training loss: 2.0091068744659424
Validation loss: 1.9895562074517692

Epoch: 5| Step: 5
Training loss: 2.1742725372314453
Validation loss: 1.9814373088139359

Epoch: 5| Step: 6
Training loss: 1.7377700805664062
Validation loss: 2.007556119272786

Epoch: 5| Step: 7
Training loss: 2.338301420211792
Validation loss: 1.9898696355922247

Epoch: 5| Step: 8
Training loss: 2.4065632820129395
Validation loss: 1.990067312794347

Epoch: 5| Step: 9
Training loss: 2.289705991744995
Validation loss: 1.997939314893497

Epoch: 5| Step: 10
Training loss: 1.8479009866714478
Validation loss: 1.998079857518596

Epoch: 97| Step: 0
Training loss: 2.0225775241851807
Validation loss: 1.9816184082338888

Epoch: 5| Step: 1
Training loss: 1.9551509618759155
Validation loss: 1.9934334498579784

Epoch: 5| Step: 2
Training loss: 2.278759717941284
Validation loss: 1.9757997758926884

Epoch: 5| Step: 3
Training loss: 2.3311095237731934
Validation loss: 1.9777151077024397

Epoch: 5| Step: 4
Training loss: 1.8576370477676392
Validation loss: 1.9821432098265617

Epoch: 5| Step: 5
Training loss: 2.436619520187378
Validation loss: 1.9949886568130986

Epoch: 5| Step: 6
Training loss: 2.298973798751831
Validation loss: 1.9614835631462835

Epoch: 5| Step: 7
Training loss: 1.928367018699646
Validation loss: 1.9669789293760895

Epoch: 5| Step: 8
Training loss: 2.4188151359558105
Validation loss: 1.9603109077740741

Epoch: 5| Step: 9
Training loss: 2.466283082962036
Validation loss: 1.982713504504132

Epoch: 5| Step: 10
Training loss: 2.068084478378296
Validation loss: 1.9820762603513655

Epoch: 98| Step: 0
Training loss: 1.9287704229354858
Validation loss: 1.9836483540073517

Epoch: 5| Step: 1
Training loss: 2.0698320865631104
Validation loss: 1.9891402311222528

Epoch: 5| Step: 2
Training loss: 2.503232717514038
Validation loss: 1.9690349717294016

Epoch: 5| Step: 3
Training loss: 2.154719114303589
Validation loss: 1.979462508232363

Epoch: 5| Step: 4
Training loss: 2.0272011756896973
Validation loss: 1.981476515851995

Epoch: 5| Step: 5
Training loss: 2.0425822734832764
Validation loss: 1.9970918496449788

Epoch: 5| Step: 6
Training loss: 2.4057610034942627
Validation loss: 1.9696875874714186

Epoch: 5| Step: 7
Training loss: 2.1847994327545166
Validation loss: 1.9963934383084696

Epoch: 5| Step: 8
Training loss: 2.408740997314453
Validation loss: 1.997475871475794

Epoch: 5| Step: 9
Training loss: 1.9796922206878662
Validation loss: 2.000610766872283

Epoch: 5| Step: 10
Training loss: 2.362074375152588
Validation loss: 1.985328443588749

Epoch: 99| Step: 0
Training loss: 2.034186601638794
Validation loss: 1.9808923762331727

Epoch: 5| Step: 1
Training loss: 2.1455276012420654
Validation loss: 2.003475284063688

Epoch: 5| Step: 2
Training loss: 2.055325746536255
Validation loss: 1.9880906740824382

Epoch: 5| Step: 3
Training loss: 1.9268585443496704
Validation loss: 1.984461433144026

Epoch: 5| Step: 4
Training loss: 2.4309682846069336
Validation loss: 1.99558138590987

Epoch: 5| Step: 5
Training loss: 2.2251601219177246
Validation loss: 2.000784491979948

Epoch: 5| Step: 6
Training loss: 3.226846694946289
Validation loss: 1.9825917469557894

Epoch: 5| Step: 7
Training loss: 2.5032758712768555
Validation loss: 1.9831018088966288

Epoch: 5| Step: 8
Training loss: 2.234612226486206
Validation loss: 1.9793359669305945

Epoch: 5| Step: 9
Training loss: 1.781372308731079
Validation loss: 1.981100497707244

Epoch: 5| Step: 10
Training loss: 1.5147807598114014
Validation loss: 1.9921718797376078

Epoch: 100| Step: 0
Training loss: 2.029815196990967
Validation loss: 1.9743130078879736

Epoch: 5| Step: 1
Training loss: 2.4818129539489746
Validation loss: 1.9980179571336316

Epoch: 5| Step: 2
Training loss: 2.188688039779663
Validation loss: 1.9848933771092405

Epoch: 5| Step: 3
Training loss: 2.2997257709503174
Validation loss: 1.9988049537904802

Epoch: 5| Step: 4
Training loss: 2.3517327308654785
Validation loss: 1.990739430150678

Epoch: 5| Step: 5
Training loss: 2.1732754707336426
Validation loss: 2.005115560306016

Epoch: 5| Step: 6
Training loss: 2.1436855792999268
Validation loss: 2.0019051144199986

Epoch: 5| Step: 7
Training loss: 1.509670615196228
Validation loss: 1.9815922808903519

Epoch: 5| Step: 8
Training loss: 2.2975707054138184
Validation loss: 1.9919202276455459

Epoch: 5| Step: 9
Training loss: 2.5969302654266357
Validation loss: 1.9901930978221278

Epoch: 5| Step: 10
Training loss: 1.9737375974655151
Validation loss: 1.9880260190656107

Epoch: 101| Step: 0
Training loss: 2.1821022033691406
Validation loss: 1.983617349337506

Epoch: 5| Step: 1
Training loss: 1.3052551746368408
Validation loss: 1.995637495030639

Epoch: 5| Step: 2
Training loss: 2.4019649028778076
Validation loss: 1.9831654000025924

Epoch: 5| Step: 3
Training loss: 2.0803494453430176
Validation loss: 1.9828084130440988

Epoch: 5| Step: 4
Training loss: 2.3595762252807617
Validation loss: 2.0007538616016345

Epoch: 5| Step: 5
Training loss: 2.29634952545166
Validation loss: 1.9977411082995835

Epoch: 5| Step: 6
Training loss: 2.3150923252105713
Validation loss: 1.989718009066838

Epoch: 5| Step: 7
Training loss: 2.096792697906494
Validation loss: 1.9937743781715311

Epoch: 5| Step: 8
Training loss: 2.8078231811523438
Validation loss: 1.98877368691147

Epoch: 5| Step: 9
Training loss: 2.1069183349609375
Validation loss: 1.9828671678420036

Epoch: 5| Step: 10
Training loss: 2.0157101154327393
Validation loss: 2.0009226901556856

Epoch: 102| Step: 0
Training loss: 2.219292163848877
Validation loss: 1.980790840682163

Epoch: 5| Step: 1
Training loss: 2.696331262588501
Validation loss: 2.000624454149636

Epoch: 5| Step: 2
Training loss: 2.126558542251587
Validation loss: 1.9890551925987325

Epoch: 5| Step: 3
Training loss: 2.3643486499786377
Validation loss: 1.9889372741022417

Epoch: 5| Step: 4
Training loss: 2.1747336387634277
Validation loss: 1.9817806725860925

Epoch: 5| Step: 5
Training loss: 2.196638822555542
Validation loss: 1.9826226516436505

Epoch: 5| Step: 6
Training loss: 1.6316900253295898
Validation loss: 1.9992780518788162

Epoch: 5| Step: 7
Training loss: 1.7903099060058594
Validation loss: 1.9991209814625401

Epoch: 5| Step: 8
Training loss: 1.684282660484314
Validation loss: 1.983712637296287

Epoch: 5| Step: 9
Training loss: 2.667194128036499
Validation loss: 1.9869497540176555

Epoch: 5| Step: 10
Training loss: 2.421372413635254
Validation loss: 2.0035743277559996

Epoch: 103| Step: 0
Training loss: 2.5698482990264893
Validation loss: 1.983294540835965

Epoch: 5| Step: 1
Training loss: 2.413288116455078
Validation loss: 1.9439201867708595

Epoch: 5| Step: 2
Training loss: 1.9323883056640625
Validation loss: 1.9853764669869536

Epoch: 5| Step: 3
Training loss: 2.0713419914245605
Validation loss: 1.9707120874876618

Epoch: 5| Step: 4
Training loss: 2.3272297382354736
Validation loss: 2.002843256919615

Epoch: 5| Step: 5
Training loss: 2.2123916149139404
Validation loss: 1.970740488780442

Epoch: 5| Step: 6
Training loss: 2.016819953918457
Validation loss: 1.9751689152051044

Epoch: 5| Step: 7
Training loss: 1.8327175378799438
Validation loss: 1.9660028437132477

Epoch: 5| Step: 8
Training loss: 2.0876083374023438
Validation loss: 1.9859125562893447

Epoch: 5| Step: 9
Training loss: 2.227604866027832
Validation loss: 1.9772714466177008

Epoch: 5| Step: 10
Training loss: 2.221620798110962
Validation loss: 1.97959598418205

Epoch: 104| Step: 0
Training loss: 1.7883269786834717
Validation loss: 1.9895861469289309

Epoch: 5| Step: 1
Training loss: 2.430798053741455
Validation loss: 1.9773402265323106

Epoch: 5| Step: 2
Training loss: 2.243278980255127
Validation loss: 1.9881858389864686

Epoch: 5| Step: 3
Training loss: 2.5242209434509277
Validation loss: 1.9671897490819295

Epoch: 5| Step: 4
Training loss: 2.1455535888671875
Validation loss: 1.9891290151944725

Epoch: 5| Step: 5
Training loss: 1.7167112827301025
Validation loss: 1.9787993982274046

Epoch: 5| Step: 6
Training loss: 2.2184243202209473
Validation loss: 1.9712437942463865

Epoch: 5| Step: 7
Training loss: 3.1013383865356445
Validation loss: 1.9514960371037966

Epoch: 5| Step: 8
Training loss: 2.11599063873291
Validation loss: 1.9665774965798983

Epoch: 5| Step: 9
Training loss: 1.759179711341858
Validation loss: 1.9887921348694833

Epoch: 5| Step: 10
Training loss: 2.014695405960083
Validation loss: 1.9804639303556053

Epoch: 105| Step: 0
Training loss: 2.165215015411377
Validation loss: 1.9888082435054164

Epoch: 5| Step: 1
Training loss: 2.3250632286071777
Validation loss: 1.9773310820261638

Epoch: 5| Step: 2
Training loss: 2.4883313179016113
Validation loss: 1.9902906930574806

Epoch: 5| Step: 3
Training loss: 1.8390769958496094
Validation loss: 1.987765622395341

Epoch: 5| Step: 4
Training loss: 1.9708354473114014
Validation loss: 1.9770670167861446

Epoch: 5| Step: 5
Training loss: 2.1233327388763428
Validation loss: 1.9789572428631526

Epoch: 5| Step: 6
Training loss: 2.3807671070098877
Validation loss: 1.9893599325610745

Epoch: 5| Step: 7
Training loss: 1.8076980113983154
Validation loss: 1.9450678261377479

Epoch: 5| Step: 8
Training loss: 2.603476047515869
Validation loss: 1.9585069341044272

Epoch: 5| Step: 9
Training loss: 1.9669631719589233
Validation loss: 1.9965415911007953

Epoch: 5| Step: 10
Training loss: 2.530438184738159
Validation loss: 1.9854311238053024

Epoch: 106| Step: 0
Training loss: 1.9705051183700562
Validation loss: 1.96377016908379

Epoch: 5| Step: 1
Training loss: 1.6946659088134766
Validation loss: 1.9873753106722267

Epoch: 5| Step: 2
Training loss: 2.2564268112182617
Validation loss: 1.9737737870985461

Epoch: 5| Step: 3
Training loss: 3.0485148429870605
Validation loss: 1.9721470417514924

Epoch: 5| Step: 4
Training loss: 1.7850395441055298
Validation loss: 1.9840645341462986

Epoch: 5| Step: 5
Training loss: 1.713680624961853
Validation loss: 1.9855209307004047

Epoch: 5| Step: 6
Training loss: 2.4753990173339844
Validation loss: 1.9649468929536882

Epoch: 5| Step: 7
Training loss: 2.747464656829834
Validation loss: 1.983430745781109

Epoch: 5| Step: 8
Training loss: 2.280729055404663
Validation loss: 1.9773517308696624

Epoch: 5| Step: 9
Training loss: 1.8792833089828491
Validation loss: 1.9582810953099241

Epoch: 5| Step: 10
Training loss: 2.244900941848755
Validation loss: 1.9751632880139094

Epoch: 107| Step: 0
Training loss: 2.128295421600342
Validation loss: 1.976565012367823

Epoch: 5| Step: 1
Training loss: 2.0098037719726562
Validation loss: 1.9864546252835182

Epoch: 5| Step: 2
Training loss: 2.037867307662964
Validation loss: 1.964725238020702

Epoch: 5| Step: 3
Training loss: 2.2678112983703613
Validation loss: 1.9737596460568008

Epoch: 5| Step: 4
Training loss: 2.867121458053589
Validation loss: 1.997551243792298

Epoch: 5| Step: 5
Training loss: 2.023474931716919
Validation loss: 1.97867968902793

Epoch: 5| Step: 6
Training loss: 2.0679264068603516
Validation loss: 1.9940130659328994

Epoch: 5| Step: 7
Training loss: 1.9799702167510986
Validation loss: 1.9869991476817797

Epoch: 5| Step: 8
Training loss: 2.2000505924224854
Validation loss: 1.9925007204855643

Epoch: 5| Step: 9
Training loss: 2.136831760406494
Validation loss: 1.9975689482945267

Epoch: 5| Step: 10
Training loss: 2.190816879272461
Validation loss: 1.979244924360706

Epoch: 108| Step: 0
Training loss: 2.3568572998046875
Validation loss: 1.9773947141503776

Epoch: 5| Step: 1
Training loss: 2.5110228061676025
Validation loss: 1.9973013195940243

Epoch: 5| Step: 2
Training loss: 2.0900566577911377
Validation loss: 1.992310276595495

Epoch: 5| Step: 3
Training loss: 2.022524356842041
Validation loss: 1.9968055525133688

Epoch: 5| Step: 4
Training loss: 1.8651542663574219
Validation loss: 1.9979382676462973

Epoch: 5| Step: 5
Training loss: 1.6157745122909546
Validation loss: 1.977824664884998

Epoch: 5| Step: 6
Training loss: 2.3733701705932617
Validation loss: 1.9734442375039543

Epoch: 5| Step: 7
Training loss: 2.565187931060791
Validation loss: 1.9907302497535624

Epoch: 5| Step: 8
Training loss: 1.8031530380249023
Validation loss: 2.0008043332766463

Epoch: 5| Step: 9
Training loss: 2.089569091796875
Validation loss: 2.000310799126984

Epoch: 5| Step: 10
Training loss: 2.6674716472625732
Validation loss: 1.9900720978295932

Epoch: 109| Step: 0
Training loss: 2.479231595993042
Validation loss: 1.9686788282086771

Epoch: 5| Step: 1
Training loss: 1.961024284362793
Validation loss: 1.9857232006647254

Epoch: 5| Step: 2
Training loss: 2.1638097763061523
Validation loss: 1.9731917304377402

Epoch: 5| Step: 3
Training loss: 2.1910529136657715
Validation loss: 1.990504563495677

Epoch: 5| Step: 4
Training loss: 2.092337131500244
Validation loss: 1.9654396669839018

Epoch: 5| Step: 5
Training loss: 2.180276870727539
Validation loss: 1.9763601890174292

Epoch: 5| Step: 6
Training loss: 1.520821452140808
Validation loss: 1.9958696878084572

Epoch: 5| Step: 7
Training loss: 2.3915882110595703
Validation loss: 1.9929571138915194

Epoch: 5| Step: 8
Training loss: 3.0487587451934814
Validation loss: 1.9827695200520177

Epoch: 5| Step: 9
Training loss: 2.177072525024414
Validation loss: 1.974629472660762

Epoch: 5| Step: 10
Training loss: 1.6107574701309204
Validation loss: 1.9935090567476006

Epoch: 110| Step: 0
Training loss: 1.8566615581512451
Validation loss: 1.9880593258847472

Epoch: 5| Step: 1
Training loss: 2.195054292678833
Validation loss: 2.0006256462425314

Epoch: 5| Step: 2
Training loss: 2.386406183242798
Validation loss: 1.9886333122048327

Epoch: 5| Step: 3
Training loss: 2.336318016052246
Validation loss: 1.977289875348409

Epoch: 5| Step: 4
Training loss: 2.0693039894104004
Validation loss: 1.9920971867858723

Epoch: 5| Step: 5
Training loss: 2.5361812114715576
Validation loss: 2.0017711500967703

Epoch: 5| Step: 6
Training loss: 1.9213165044784546
Validation loss: 1.9872124746281614

Epoch: 5| Step: 7
Training loss: 2.080636501312256
Validation loss: 1.9773209338547082

Epoch: 5| Step: 8
Training loss: 1.7745025157928467
Validation loss: 2.015648776485074

Epoch: 5| Step: 9
Training loss: 3.0155460834503174
Validation loss: 1.9810212632661224

Epoch: 5| Step: 10
Training loss: 1.6617857217788696
Validation loss: 2.0018357333316597

Epoch: 111| Step: 0
Training loss: 1.4378900527954102
Validation loss: 2.001660636676255

Epoch: 5| Step: 1
Training loss: 2.1409387588500977
Validation loss: 2.000129052387771

Epoch: 5| Step: 2
Training loss: 2.542816400527954
Validation loss: 2.004300707130022

Epoch: 5| Step: 3
Training loss: 1.9779828786849976
Validation loss: 1.9815727869669597

Epoch: 5| Step: 4
Training loss: 1.739402174949646
Validation loss: 2.000589757837275

Epoch: 5| Step: 5
Training loss: 1.8342262506484985
Validation loss: 1.9969330026257424

Epoch: 5| Step: 6
Training loss: 2.6070683002471924
Validation loss: 1.985190869659506

Epoch: 5| Step: 7
Training loss: 2.5141494274139404
Validation loss: 1.9904819175761232

Epoch: 5| Step: 8
Training loss: 2.3126914501190186
Validation loss: 1.98645733633349

Epoch: 5| Step: 9
Training loss: 2.1587586402893066
Validation loss: 1.9944820198961484

Epoch: 5| Step: 10
Training loss: 2.6527440547943115
Validation loss: 1.9966246979210966

Epoch: 112| Step: 0
Training loss: 1.9535983800888062
Validation loss: 1.9832885444805186

Epoch: 5| Step: 1
Training loss: 1.9832801818847656
Validation loss: 1.9890640756135345

Epoch: 5| Step: 2
Training loss: 1.7779325246810913
Validation loss: 1.9885462676325152

Epoch: 5| Step: 3
Training loss: 2.0383968353271484
Validation loss: 1.9929486897683912

Epoch: 5| Step: 4
Training loss: 2.578155040740967
Validation loss: 1.9966686848671205

Epoch: 5| Step: 5
Training loss: 1.9098074436187744
Validation loss: 2.0006688551236222

Epoch: 5| Step: 6
Training loss: 2.2980360984802246
Validation loss: 1.9997605559646443

Epoch: 5| Step: 7
Training loss: 2.3532793521881104
Validation loss: 1.9929568793184014

Epoch: 5| Step: 8
Training loss: 2.427410840988159
Validation loss: 1.9785438660652406

Epoch: 5| Step: 9
Training loss: 2.5299744606018066
Validation loss: 1.997560344716554

Epoch: 5| Step: 10
Training loss: 1.9783101081848145
Validation loss: 1.9976069888760966

Epoch: 113| Step: 0
Training loss: 2.736684560775757
Validation loss: 2.0022314799729215

Epoch: 5| Step: 1
Training loss: 1.5937813520431519
Validation loss: 1.9945561514105847

Epoch: 5| Step: 2
Training loss: 2.465305805206299
Validation loss: 2.0012165730999363

Epoch: 5| Step: 3
Training loss: 2.133122682571411
Validation loss: 1.9974516335354056

Epoch: 5| Step: 4
Training loss: 2.447723627090454
Validation loss: 1.972204028919179

Epoch: 5| Step: 5
Training loss: 1.8632032871246338
Validation loss: 1.9952397859224709

Epoch: 5| Step: 6
Training loss: 2.520897626876831
Validation loss: 2.012026313812502

Epoch: 5| Step: 7
Training loss: 1.9879953861236572
Validation loss: 2.006507678698468

Epoch: 5| Step: 8
Training loss: 2.0344550609588623
Validation loss: 2.0084927594789894

Epoch: 5| Step: 9
Training loss: 2.013262987136841
Validation loss: 1.9935525873655915

Epoch: 5| Step: 10
Training loss: 2.1181817054748535
Validation loss: 2.001380702500702

Epoch: 114| Step: 0
Training loss: 1.9802720546722412
Validation loss: 2.004266377418272

Epoch: 5| Step: 1
Training loss: 2.1344645023345947
Validation loss: 2.0015537918254895

Epoch: 5| Step: 2
Training loss: 1.9693447351455688
Validation loss: 2.000370943418113

Epoch: 5| Step: 3
Training loss: 2.6027979850769043
Validation loss: 1.9923241305094894

Epoch: 5| Step: 4
Training loss: 1.997614860534668
Validation loss: 1.9971535000749814

Epoch: 5| Step: 5
Training loss: 1.6963043212890625
Validation loss: 1.9851556170371272

Epoch: 5| Step: 6
Training loss: 2.5041415691375732
Validation loss: 1.9968749323198873

Epoch: 5| Step: 7
Training loss: 2.46226167678833
Validation loss: 1.9958360656615226

Epoch: 5| Step: 8
Training loss: 2.075644016265869
Validation loss: 1.9928818902661722

Epoch: 5| Step: 9
Training loss: 2.1921403408050537
Validation loss: 1.9914679168373026

Epoch: 5| Step: 10
Training loss: 2.0529541969299316
Validation loss: 1.9818830938749417

Epoch: 115| Step: 0
Training loss: 1.7898063659667969
Validation loss: 1.9956322664855628

Epoch: 5| Step: 1
Training loss: 1.619809865951538
Validation loss: 1.984404968959029

Epoch: 5| Step: 2
Training loss: 1.8977476358413696
Validation loss: 1.9800046720812399

Epoch: 5| Step: 3
Training loss: 2.625518560409546
Validation loss: 1.9846729860510877

Epoch: 5| Step: 4
Training loss: 2.344653606414795
Validation loss: 1.981208452614405

Epoch: 5| Step: 5
Training loss: 3.186852216720581
Validation loss: 1.98333268268134

Epoch: 5| Step: 6
Training loss: 1.7778434753417969
Validation loss: 1.9873097917085052

Epoch: 5| Step: 7
Training loss: 1.9284929037094116
Validation loss: 2.001182666388891

Epoch: 5| Step: 8
Training loss: 2.231936454772949
Validation loss: 2.0026770330244497

Epoch: 5| Step: 9
Training loss: 2.5661730766296387
Validation loss: 1.9940671151684177

Epoch: 5| Step: 10
Training loss: 1.8162025213241577
Validation loss: 2.005909514683549

Epoch: 116| Step: 0
Training loss: 2.754490613937378
Validation loss: 1.9766583442687988

Epoch: 5| Step: 1
Training loss: 1.443379282951355
Validation loss: 1.973067852758592

Epoch: 5| Step: 2
Training loss: 2.451474905014038
Validation loss: 1.9951428174972534

Epoch: 5| Step: 3
Training loss: 2.466651439666748
Validation loss: 1.969683301064276

Epoch: 5| Step: 4
Training loss: 2.099760055541992
Validation loss: 1.9865713939871839

Epoch: 5| Step: 5
Training loss: 2.0127153396606445
Validation loss: 1.9821740222233597

Epoch: 5| Step: 6
Training loss: 1.8513507843017578
Validation loss: 1.9951266383612027

Epoch: 5| Step: 7
Training loss: 2.043524742126465
Validation loss: 1.9898718300686087

Epoch: 5| Step: 8
Training loss: 2.6794350147247314
Validation loss: 2.003748433564299

Epoch: 5| Step: 9
Training loss: 2.096165418624878
Validation loss: 1.9862946887170114

Epoch: 5| Step: 10
Training loss: 1.7342298030853271
Validation loss: 2.011912538159278

Epoch: 117| Step: 0
Training loss: 2.0747883319854736
Validation loss: 1.990989303076139

Epoch: 5| Step: 1
Training loss: 2.343780040740967
Validation loss: 1.9971451015882595

Epoch: 5| Step: 2
Training loss: 1.9883089065551758
Validation loss: 2.001278974676645

Epoch: 5| Step: 3
Training loss: 2.4722087383270264
Validation loss: 1.9938938809979347

Epoch: 5| Step: 4
Training loss: 2.0590696334838867
Validation loss: 1.9852415720621746

Epoch: 5| Step: 5
Training loss: 2.1099796295166016
Validation loss: 1.9936311603874288

Epoch: 5| Step: 6
Training loss: 1.6410328149795532
Validation loss: 2.0003248363412838

Epoch: 5| Step: 7
Training loss: 1.722960114479065
Validation loss: 1.9848461766396799

Epoch: 5| Step: 8
Training loss: 1.9392898082733154
Validation loss: 1.9701124160520491

Epoch: 5| Step: 9
Training loss: 2.6157009601593018
Validation loss: 1.992404176342872

Epoch: 5| Step: 10
Training loss: 2.7244515419006348
Validation loss: 1.9941033086469095

Epoch: 118| Step: 0
Training loss: 2.4850566387176514
Validation loss: 2.008983004477716

Epoch: 5| Step: 1
Training loss: 2.24304461479187
Validation loss: 1.9774293104807537

Epoch: 5| Step: 2
Training loss: 1.8300228118896484
Validation loss: 1.983648657798767

Epoch: 5| Step: 3
Training loss: 1.9389982223510742
Validation loss: 2.000713276606734

Epoch: 5| Step: 4
Training loss: 1.8159234523773193
Validation loss: 2.0106630376590195

Epoch: 5| Step: 5
Training loss: 2.254976987838745
Validation loss: 1.9900336778292091

Epoch: 5| Step: 6
Training loss: 2.1370489597320557
Validation loss: 1.9992045715291014

Epoch: 5| Step: 7
Training loss: 2.718282699584961
Validation loss: 1.9850490041958389

Epoch: 5| Step: 8
Training loss: 2.1761555671691895
Validation loss: 2.010242355767117

Epoch: 5| Step: 9
Training loss: 1.9765888452529907
Validation loss: 1.9868783553441365

Epoch: 5| Step: 10
Training loss: 2.0990467071533203
Validation loss: 2.006411270428729

Epoch: 119| Step: 0
Training loss: 1.6280193328857422
Validation loss: 2.0065230682332027

Epoch: 5| Step: 1
Training loss: 2.440114974975586
Validation loss: 2.0166331709072156

Epoch: 5| Step: 2
Training loss: 2.5981955528259277
Validation loss: 1.9865785439809163

Epoch: 5| Step: 3
Training loss: 2.4074769020080566
Validation loss: 2.001982981158841

Epoch: 5| Step: 4
Training loss: 1.9196510314941406
Validation loss: 1.9919875591031966

Epoch: 5| Step: 5
Training loss: 2.4284934997558594
Validation loss: 2.008305093293549

Epoch: 5| Step: 6
Training loss: 1.833993673324585
Validation loss: 1.9975152143868067

Epoch: 5| Step: 7
Training loss: 2.3675856590270996
Validation loss: 1.9879556394392444

Epoch: 5| Step: 8
Training loss: 1.652775526046753
Validation loss: 1.9915271600087483

Epoch: 5| Step: 9
Training loss: 2.1861071586608887
Validation loss: 1.992564425673536

Epoch: 5| Step: 10
Training loss: 2.2039730548858643
Validation loss: 2.0119766650661344

Epoch: 120| Step: 0
Training loss: 1.9079067707061768
Validation loss: 2.005271689866179

Epoch: 5| Step: 1
Training loss: 2.377899169921875
Validation loss: 1.9943164548566263

Epoch: 5| Step: 2
Training loss: 2.470876693725586
Validation loss: 1.9973403138499106

Epoch: 5| Step: 3
Training loss: 1.9661363363265991
Validation loss: 1.9899750896679458

Epoch: 5| Step: 4
Training loss: 1.51412034034729
Validation loss: 1.990186204192459

Epoch: 5| Step: 5
Training loss: 2.31807804107666
Validation loss: 1.985990342273507

Epoch: 5| Step: 6
Training loss: 2.4938864707946777
Validation loss: 1.9897552574834516

Epoch: 5| Step: 7
Training loss: 1.8784462213516235
Validation loss: 1.988874271351804

Epoch: 5| Step: 8
Training loss: 1.7402461767196655
Validation loss: 1.9790110959801623

Epoch: 5| Step: 9
Training loss: 2.9875612258911133
Validation loss: 2.012612244134308

Epoch: 5| Step: 10
Training loss: 1.9064043760299683
Validation loss: 1.9956232963069793

Epoch: 121| Step: 0
Training loss: 2.155078411102295
Validation loss: 1.9845606703912058

Epoch: 5| Step: 1
Training loss: 2.2853848934173584
Validation loss: 1.962475799745129

Epoch: 5| Step: 2
Training loss: 2.350015163421631
Validation loss: 1.973688958793558

Epoch: 5| Step: 3
Training loss: 2.101747989654541
Validation loss: 1.9991386090555499

Epoch: 5| Step: 4
Training loss: 2.1170544624328613
Validation loss: 1.987590487285327

Epoch: 5| Step: 5
Training loss: 1.7967555522918701
Validation loss: 1.9800743146609234

Epoch: 5| Step: 6
Training loss: 1.9673877954483032
Validation loss: 1.9886889124429354

Epoch: 5| Step: 7
Training loss: 2.290870189666748
Validation loss: 1.9967154379813903

Epoch: 5| Step: 8
Training loss: 2.5151569843292236
Validation loss: 2.0017177686896375

Epoch: 5| Step: 9
Training loss: 1.9850231409072876
Validation loss: 1.9812146232974144

Epoch: 5| Step: 10
Training loss: 2.065951347351074
Validation loss: 1.9691276178565076

Epoch: 122| Step: 0
Training loss: 1.9561821222305298
Validation loss: 1.9747372929767897

Epoch: 5| Step: 1
Training loss: 2.19685959815979
Validation loss: 1.9886680777354906

Epoch: 5| Step: 2
Training loss: 3.1472342014312744
Validation loss: 1.9664640541999572

Epoch: 5| Step: 3
Training loss: 2.2011358737945557
Validation loss: 1.987793823724152

Epoch: 5| Step: 4
Training loss: 1.9543100595474243
Validation loss: 1.9972709353252123

Epoch: 5| Step: 5
Training loss: 2.036721706390381
Validation loss: 1.9799700321689728

Epoch: 5| Step: 6
Training loss: 2.494295597076416
Validation loss: 1.9629827442989554

Epoch: 5| Step: 7
Training loss: 2.4606027603149414
Validation loss: 1.9832747867030482

Epoch: 5| Step: 8
Training loss: 1.7508615255355835
Validation loss: 1.9968002432136125

Epoch: 5| Step: 9
Training loss: 1.7399219274520874
Validation loss: 1.9810452409969863

Epoch: 5| Step: 10
Training loss: 1.5008349418640137
Validation loss: 1.997202915530051

Epoch: 123| Step: 0
Training loss: 1.900352120399475
Validation loss: 1.9842066200830604

Epoch: 5| Step: 1
Training loss: 1.938510537147522
Validation loss: 1.9887298742930095

Epoch: 5| Step: 2
Training loss: 1.725142478942871
Validation loss: 1.9889035532551427

Epoch: 5| Step: 3
Training loss: 3.0001182556152344
Validation loss: 1.9896556228719733

Epoch: 5| Step: 4
Training loss: 2.0114803314208984
Validation loss: 1.9638434328058714

Epoch: 5| Step: 5
Training loss: 1.8771852254867554
Validation loss: 1.9757764441992647

Epoch: 5| Step: 6
Training loss: 3.0295748710632324
Validation loss: 1.9822741490538403

Epoch: 5| Step: 7
Training loss: 2.158881902694702
Validation loss: 1.983195674034857

Epoch: 5| Step: 8
Training loss: 1.8916184902191162
Validation loss: 1.9876656814288067

Epoch: 5| Step: 9
Training loss: 2.063363790512085
Validation loss: 1.9940383524023078

Epoch: 5| Step: 10
Training loss: 1.9939947128295898
Validation loss: 1.998470684533478

Epoch: 124| Step: 0
Training loss: 2.5187761783599854
Validation loss: 1.981567576367368

Epoch: 5| Step: 1
Training loss: 1.7967326641082764
Validation loss: 1.9801760899123324

Epoch: 5| Step: 2
Training loss: 2.1480841636657715
Validation loss: 2.012913655209285

Epoch: 5| Step: 3
Training loss: 2.3276278972625732
Validation loss: 1.9810079707894275

Epoch: 5| Step: 4
Training loss: 2.2078423500061035
Validation loss: 1.9946588854635916

Epoch: 5| Step: 5
Training loss: 2.6743314266204834
Validation loss: 1.977802400947899

Epoch: 5| Step: 6
Training loss: 2.081265926361084
Validation loss: 1.9863731630386845

Epoch: 5| Step: 7
Training loss: 1.882761001586914
Validation loss: 1.977574622759255

Epoch: 5| Step: 8
Training loss: 1.9644685983657837
Validation loss: 1.9822591197106145

Epoch: 5| Step: 9
Training loss: 1.6612708568572998
Validation loss: 1.9929951416548861

Epoch: 5| Step: 10
Training loss: 2.1859641075134277
Validation loss: 1.981115154040757

Epoch: 125| Step: 0
Training loss: 1.9435920715332031
Validation loss: 1.9921528511149909

Epoch: 5| Step: 1
Training loss: 2.7349839210510254
Validation loss: 1.9890099815143052

Epoch: 5| Step: 2
Training loss: 2.42490816116333
Validation loss: 1.9854275821357645

Epoch: 5| Step: 3
Training loss: 1.9632556438446045
Validation loss: 1.990200727216659

Epoch: 5| Step: 4
Training loss: 2.4698290824890137
Validation loss: 2.0002452558086765

Epoch: 5| Step: 5
Training loss: 2.345778226852417
Validation loss: 2.0103454641116563

Epoch: 5| Step: 6
Training loss: 1.9512393474578857
Validation loss: 2.000505519169633

Epoch: 5| Step: 7
Training loss: 1.6671850681304932
Validation loss: 1.9941214681953512

Epoch: 5| Step: 8
Training loss: 2.0673747062683105
Validation loss: 1.9989800696731896

Epoch: 5| Step: 9
Training loss: 2.4265613555908203
Validation loss: 2.0103616496568084

Epoch: 5| Step: 10
Training loss: 1.5286985635757446
Validation loss: 2.0113907321806876

Epoch: 126| Step: 0
Training loss: 2.292330741882324
Validation loss: 2.0030892228567474

Epoch: 5| Step: 1
Training loss: 1.7921911478042603
Validation loss: 1.983321141171199

Epoch: 5| Step: 2
Training loss: 1.9937549829483032
Validation loss: 2.0029205327392905

Epoch: 5| Step: 3
Training loss: 2.4186155796051025
Validation loss: 2.0167714421467116

Epoch: 5| Step: 4
Training loss: 2.500638961791992
Validation loss: 1.970113613272226

Epoch: 5| Step: 5
Training loss: 2.589324712753296
Validation loss: 2.0148471350310952

Epoch: 5| Step: 6
Training loss: 1.6032835245132446
Validation loss: 1.9850017639898485

Epoch: 5| Step: 7
Training loss: 2.1968624591827393
Validation loss: 1.9697395781035065

Epoch: 5| Step: 8
Training loss: 2.103498935699463
Validation loss: 1.9922510423967916

Epoch: 5| Step: 9
Training loss: 1.575482964515686
Validation loss: 1.995069016692459

Epoch: 5| Step: 10
Training loss: 2.461068630218506
Validation loss: 1.9784841857930666

Epoch: 127| Step: 0
Training loss: 2.327536106109619
Validation loss: 1.9736866438260643

Epoch: 5| Step: 1
Training loss: 2.3452134132385254
Validation loss: 1.969488775858315

Epoch: 5| Step: 2
Training loss: 2.2117602825164795
Validation loss: 1.984348044600538

Epoch: 5| Step: 3
Training loss: 2.1331653594970703
Validation loss: 1.9927929165542766

Epoch: 5| Step: 4
Training loss: 2.139268398284912
Validation loss: 2.0023342845260457

Epoch: 5| Step: 5
Training loss: 2.0275352001190186
Validation loss: 1.9913389631496963

Epoch: 5| Step: 6
Training loss: 1.5363000631332397
Validation loss: 1.9816477144918134

Epoch: 5| Step: 7
Training loss: 2.17171049118042
Validation loss: 1.976019359404041

Epoch: 5| Step: 8
Training loss: 2.5160820484161377
Validation loss: 1.9815783526307793

Epoch: 5| Step: 9
Training loss: 1.884916067123413
Validation loss: 2.006997449423677

Epoch: 5| Step: 10
Training loss: 2.1572043895721436
Validation loss: 1.9946473388261692

Epoch: 128| Step: 0
Training loss: 2.028238296508789
Validation loss: 1.98544220770559

Epoch: 5| Step: 1
Training loss: 2.665808916091919
Validation loss: 1.997126438284433

Epoch: 5| Step: 2
Training loss: 1.4542442560195923
Validation loss: 1.9852359243618545

Epoch: 5| Step: 3
Training loss: 2.2911486625671387
Validation loss: 2.004631039916828

Epoch: 5| Step: 4
Training loss: 2.0400710105895996
Validation loss: 1.9859161043679843

Epoch: 5| Step: 5
Training loss: 2.517732620239258
Validation loss: 1.9899900331292102

Epoch: 5| Step: 6
Training loss: 2.350364923477173
Validation loss: 1.9966667813639487

Epoch: 5| Step: 7
Training loss: 2.5255916118621826
Validation loss: 2.001183215007987

Epoch: 5| Step: 8
Training loss: 1.9285917282104492
Validation loss: 1.993761206185946

Epoch: 5| Step: 9
Training loss: 1.6501376628875732
Validation loss: 2.0050928028680945

Epoch: 5| Step: 10
Training loss: 2.0098962783813477
Validation loss: 1.993685963333294

Epoch: 129| Step: 0
Training loss: 1.7770837545394897
Validation loss: 1.9967960837066814

Epoch: 5| Step: 1
Training loss: 2.089860677719116
Validation loss: 1.9769697830241213

Epoch: 5| Step: 2
Training loss: 1.9504435062408447
Validation loss: 1.9604120639062697

Epoch: 5| Step: 3
Training loss: 1.7130584716796875
Validation loss: 1.9809665974750315

Epoch: 5| Step: 4
Training loss: 2.6296839714050293
Validation loss: 1.993468871680639

Epoch: 5| Step: 5
Training loss: 2.7391796112060547
Validation loss: 1.9767041821633615

Epoch: 5| Step: 6
Training loss: 1.9302517175674438
Validation loss: 1.9768523977648826

Epoch: 5| Step: 7
Training loss: 2.1644632816314697
Validation loss: 2.005755111735354

Epoch: 5| Step: 8
Training loss: 2.4966893196105957
Validation loss: 1.9806193382509294

Epoch: 5| Step: 9
Training loss: 1.8467308282852173
Validation loss: 1.9827764931545462

Epoch: 5| Step: 10
Training loss: 2.0538814067840576
Validation loss: 1.9836149138789023

Epoch: 130| Step: 0
Training loss: 2.5047380924224854
Validation loss: 1.9890582202583231

Epoch: 5| Step: 1
Training loss: 1.8607581853866577
Validation loss: 1.9926077729912215

Epoch: 5| Step: 2
Training loss: 2.388706684112549
Validation loss: 1.9893920165236278

Epoch: 5| Step: 3
Training loss: 1.8927814960479736
Validation loss: 1.9862210058396863

Epoch: 5| Step: 4
Training loss: 1.73673415184021
Validation loss: 1.9707105339214366

Epoch: 5| Step: 5
Training loss: 2.3731484413146973
Validation loss: 1.9924299409312587

Epoch: 5| Step: 6
Training loss: 2.0880188941955566
Validation loss: 1.9763880570729573

Epoch: 5| Step: 7
Training loss: 2.2469239234924316
Validation loss: 1.9672421870693084

Epoch: 5| Step: 8
Training loss: 2.3313167095184326
Validation loss: 1.9931697614731327

Epoch: 5| Step: 9
Training loss: 2.0122275352478027
Validation loss: 1.9742521611593102

Epoch: 5| Step: 10
Training loss: 2.137629270553589
Validation loss: 2.009648762723451

Epoch: 131| Step: 0
Training loss: 2.179131269454956
Validation loss: 1.991351947989515

Epoch: 5| Step: 1
Training loss: 2.4085233211517334
Validation loss: 1.990589444355298

Epoch: 5| Step: 2
Training loss: 2.352476119995117
Validation loss: 1.9705158613061393

Epoch: 5| Step: 3
Training loss: 1.7404091358184814
Validation loss: 1.9900280878108034

Epoch: 5| Step: 4
Training loss: 1.5701167583465576
Validation loss: 2.0083756959566506

Epoch: 5| Step: 5
Training loss: 1.7996050119400024
Validation loss: 2.0098177258686354

Epoch: 5| Step: 6
Training loss: 2.0432560443878174
Validation loss: 2.000475381010322

Epoch: 5| Step: 7
Training loss: 1.4168837070465088
Validation loss: 2.005337484421269

Epoch: 5| Step: 8
Training loss: 2.7532362937927246
Validation loss: 2.0001114235129407

Epoch: 5| Step: 9
Training loss: 2.541130542755127
Validation loss: 1.9920839289183259

Epoch: 5| Step: 10
Training loss: 2.503492832183838
Validation loss: 1.9772294593113724

Epoch: 132| Step: 0
Training loss: 1.617079496383667
Validation loss: 1.9849497554122761

Epoch: 5| Step: 1
Training loss: 2.590543746948242
Validation loss: 2.003675958161713

Epoch: 5| Step: 2
Training loss: 1.9516050815582275
Validation loss: 2.0051078168294763

Epoch: 5| Step: 3
Training loss: 2.5454049110412598
Validation loss: 2.003232653423022

Epoch: 5| Step: 4
Training loss: 1.6652837991714478
Validation loss: 1.9779611415760492

Epoch: 5| Step: 5
Training loss: 1.9164615869522095
Validation loss: 1.9844553509066183

Epoch: 5| Step: 6
Training loss: 1.8181426525115967
Validation loss: 1.9900971689531881

Epoch: 5| Step: 7
Training loss: 2.181022882461548
Validation loss: 1.9932863814856416

Epoch: 5| Step: 8
Training loss: 2.867568254470825
Validation loss: 1.993730216897944

Epoch: 5| Step: 9
Training loss: 2.5853729248046875
Validation loss: 1.995129931357599

Epoch: 5| Step: 10
Training loss: 1.6215993165969849
Validation loss: 1.994699635813313

Epoch: 133| Step: 0
Training loss: 1.722772240638733
Validation loss: 1.9982558745209889

Epoch: 5| Step: 1
Training loss: 1.6438919305801392
Validation loss: 1.9890478400773899

Epoch: 5| Step: 2
Training loss: 2.3634297847747803
Validation loss: 2.0012570350400862

Epoch: 5| Step: 3
Training loss: 1.8651692867279053
Validation loss: 1.984883713465865

Epoch: 5| Step: 4
Training loss: 2.202434778213501
Validation loss: 1.9794602753013693

Epoch: 5| Step: 5
Training loss: 1.6958421468734741
Validation loss: 2.0126414311829435

Epoch: 5| Step: 6
Training loss: 2.3542332649230957
Validation loss: 1.9904313074645175

Epoch: 5| Step: 7
Training loss: 2.0226359367370605
Validation loss: 1.9973493340194866

Epoch: 5| Step: 8
Training loss: 1.9466323852539062
Validation loss: 1.9966257054318663

Epoch: 5| Step: 9
Training loss: 3.10286021232605
Validation loss: 1.9955374374184558

Epoch: 5| Step: 10
Training loss: 2.3867344856262207
Validation loss: 1.990009505261657

Epoch: 134| Step: 0
Training loss: 1.4833927154541016
Validation loss: 2.0165163624671196

Epoch: 5| Step: 1
Training loss: 2.0530197620391846
Validation loss: 1.9960328109802739

Epoch: 5| Step: 2
Training loss: 2.631561279296875
Validation loss: 1.9952259281630158

Epoch: 5| Step: 3
Training loss: 2.1190593242645264
Validation loss: 1.9929715074518675

Epoch: 5| Step: 4
Training loss: 2.0569334030151367
Validation loss: 1.9989943222333026

Epoch: 5| Step: 5
Training loss: 1.9283555746078491
Validation loss: 2.0098285264866327

Epoch: 5| Step: 6
Training loss: 2.468674421310425
Validation loss: 1.9983411078811975

Epoch: 5| Step: 7
Training loss: 2.0309479236602783
Validation loss: 1.9945652638712237

Epoch: 5| Step: 8
Training loss: 2.2580924034118652
Validation loss: 1.998201306148242

Epoch: 5| Step: 9
Training loss: 1.716189980506897
Validation loss: 1.9893215779335267

Epoch: 5| Step: 10
Training loss: 2.5494112968444824
Validation loss: 2.003583028752317

Epoch: 135| Step: 0
Training loss: 2.1026594638824463
Validation loss: 1.9882943425127255

Epoch: 5| Step: 1
Training loss: 1.8065885305404663
Validation loss: 2.00844148922992

Epoch: 5| Step: 2
Training loss: 2.1236555576324463
Validation loss: 2.0030826560912596

Epoch: 5| Step: 3
Training loss: 1.7275091409683228
Validation loss: 1.9624359197514032

Epoch: 5| Step: 4
Training loss: 2.3015170097351074
Validation loss: 1.9903929771915558

Epoch: 5| Step: 5
Training loss: 2.517625093460083
Validation loss: 1.9716695457376459

Epoch: 5| Step: 6
Training loss: 2.0982697010040283
Validation loss: 1.9688984142836703

Epoch: 5| Step: 7
Training loss: 2.5552265644073486
Validation loss: 1.9837184554787093

Epoch: 5| Step: 8
Training loss: 2.344618320465088
Validation loss: 1.993829046526263

Epoch: 5| Step: 9
Training loss: 2.153649091720581
Validation loss: 1.9922524780355475

Epoch: 5| Step: 10
Training loss: 1.3665519952774048
Validation loss: 1.9755017526688115

Epoch: 136| Step: 0
Training loss: 1.6301519870758057
Validation loss: 2.0028789774064095

Epoch: 5| Step: 1
Training loss: 2.238457441329956
Validation loss: 1.9819919806654736

Epoch: 5| Step: 2
Training loss: 2.139249086380005
Validation loss: 1.9940945832960066

Epoch: 5| Step: 3
Training loss: 2.07666015625
Validation loss: 1.9988733517226351

Epoch: 5| Step: 4
Training loss: 2.3908228874206543
Validation loss: 1.9935609332976802

Epoch: 5| Step: 5
Training loss: 2.320772171020508
Validation loss: 1.985831165826449

Epoch: 5| Step: 6
Training loss: 2.4122042655944824
Validation loss: 1.9882477739805817

Epoch: 5| Step: 7
Training loss: 2.1349611282348633
Validation loss: 1.9886267954303372

Epoch: 5| Step: 8
Training loss: 2.209611654281616
Validation loss: 1.988858876689788

Epoch: 5| Step: 9
Training loss: 1.950402855873108
Validation loss: 1.987076259428455

Epoch: 5| Step: 10
Training loss: 1.7281484603881836
Validation loss: 1.9769423700148059

Epoch: 137| Step: 0
Training loss: 1.6957664489746094
Validation loss: 1.9858790059243479

Epoch: 5| Step: 1
Training loss: 1.7571769952774048
Validation loss: 1.9954830254277875

Epoch: 5| Step: 2
Training loss: 2.290133237838745
Validation loss: 1.996809080082883

Epoch: 5| Step: 3
Training loss: 1.9778715372085571
Validation loss: 2.0018613287197646

Epoch: 5| Step: 4
Training loss: 2.333515167236328
Validation loss: 2.005927442222513

Epoch: 5| Step: 5
Training loss: 2.453824996948242
Validation loss: 1.999260530676893

Epoch: 5| Step: 6
Training loss: 2.17256236076355
Validation loss: 2.0004374006743073

Epoch: 5| Step: 7
Training loss: 2.201540231704712
Validation loss: 1.9931564843782814

Epoch: 5| Step: 8
Training loss: 2.343435525894165
Validation loss: 1.9945936702912854

Epoch: 5| Step: 9
Training loss: 2.309394121170044
Validation loss: 1.9954163899985693

Epoch: 5| Step: 10
Training loss: 1.6649630069732666
Validation loss: 1.9980201541736562

Epoch: 138| Step: 0
Training loss: 2.562037944793701
Validation loss: 2.0019076024332354

Epoch: 5| Step: 1
Training loss: 1.6810986995697021
Validation loss: 2.003400497539069

Epoch: 5| Step: 2
Training loss: 1.413083791732788
Validation loss: 1.9940893932055401

Epoch: 5| Step: 3
Training loss: 1.6564912796020508
Validation loss: 2.0019449162226852

Epoch: 5| Step: 4
Training loss: 2.3679001331329346
Validation loss: 1.9804374684569657

Epoch: 5| Step: 5
Training loss: 2.493164539337158
Validation loss: 1.9871522739369383

Epoch: 5| Step: 6
Training loss: 1.5486690998077393
Validation loss: 1.981064796447754

Epoch: 5| Step: 7
Training loss: 2.4886221885681152
Validation loss: 1.9905967994402813

Epoch: 5| Step: 8
Training loss: 3.1597142219543457
Validation loss: 2.0053862435843355

Epoch: 5| Step: 9
Training loss: 1.9164924621582031
Validation loss: 1.9783501740424865

Epoch: 5| Step: 10
Training loss: 1.8555834293365479
Validation loss: 2.0103687214595016

Epoch: 139| Step: 0
Training loss: 2.6403040885925293
Validation loss: 1.9845319140341975

Epoch: 5| Step: 1
Training loss: 1.6182212829589844
Validation loss: 1.999516772967513

Epoch: 5| Step: 2
Training loss: 1.7468807697296143
Validation loss: 2.001504381497701

Epoch: 5| Step: 3
Training loss: 2.621816873550415
Validation loss: 1.9837944661417315

Epoch: 5| Step: 4
Training loss: 2.2785255908966064
Validation loss: 1.9909838681579919

Epoch: 5| Step: 5
Training loss: 2.777805805206299
Validation loss: 2.005670234721194

Epoch: 5| Step: 6
Training loss: 2.5105819702148438
Validation loss: 2.003116512811312

Epoch: 5| Step: 7
Training loss: 2.259273052215576
Validation loss: 1.9945464313671153

Epoch: 5| Step: 8
Training loss: 1.1839544773101807
Validation loss: 2.001155355925201

Epoch: 5| Step: 9
Training loss: 1.7192623615264893
Validation loss: 1.9828169115128056

Epoch: 5| Step: 10
Training loss: 1.7939355373382568
Validation loss: 2.00002335732983

Epoch: 140| Step: 0
Training loss: 2.237365245819092
Validation loss: 1.9813884150597356

Epoch: 5| Step: 1
Training loss: 2.153339385986328
Validation loss: 1.9710556973693192

Epoch: 5| Step: 2
Training loss: 1.8083359003067017
Validation loss: 1.9965244877722956

Epoch: 5| Step: 3
Training loss: 2.386627674102783
Validation loss: 1.9919481046738163

Epoch: 5| Step: 4
Training loss: 2.191688299179077
Validation loss: 1.9901836533700266

Epoch: 5| Step: 5
Training loss: 1.8454020023345947
Validation loss: 1.974147859440055

Epoch: 5| Step: 6
Training loss: 1.9949010610580444
Validation loss: 1.973898841488746

Epoch: 5| Step: 7
Training loss: 2.120863437652588
Validation loss: 1.990056994140789

Epoch: 5| Step: 8
Training loss: 1.8904632329940796
Validation loss: 1.9809340200116556

Epoch: 5| Step: 9
Training loss: 2.018153667449951
Validation loss: 1.9885859463804512

Epoch: 5| Step: 10
Training loss: 2.525585412979126
Validation loss: 1.9906543762453142

Epoch: 141| Step: 0
Training loss: 2.1735291481018066
Validation loss: 1.9836506305202362

Epoch: 5| Step: 1
Training loss: 2.4232699871063232
Validation loss: 1.9924572052494172

Epoch: 5| Step: 2
Training loss: 1.5677214860916138
Validation loss: 1.964563549205821

Epoch: 5| Step: 3
Training loss: 2.6080543994903564
Validation loss: 1.9868464008454354

Epoch: 5| Step: 4
Training loss: 1.7631609439849854
Validation loss: 1.9734192227804532

Epoch: 5| Step: 5
Training loss: 1.49587881565094
Validation loss: 1.9944354436730827

Epoch: 5| Step: 6
Training loss: 2.2367985248565674
Validation loss: 1.9841205214941373

Epoch: 5| Step: 7
Training loss: 2.249366044998169
Validation loss: 1.9912175388746365

Epoch: 5| Step: 8
Training loss: 2.1869311332702637
Validation loss: 2.0020657752149846

Epoch: 5| Step: 9
Training loss: 1.684218406677246
Validation loss: 1.9883083374269548

Epoch: 5| Step: 10
Training loss: 2.914433717727661
Validation loss: 1.998800980147495

Epoch: 142| Step: 0
Training loss: 1.8911672830581665
Validation loss: 1.9929301046556043

Epoch: 5| Step: 1
Training loss: 2.0542852878570557
Validation loss: 1.9772108062621085

Epoch: 5| Step: 2
Training loss: 2.284562826156616
Validation loss: 1.987889524429075

Epoch: 5| Step: 3
Training loss: 2.204242706298828
Validation loss: 2.002660330905709

Epoch: 5| Step: 4
Training loss: 2.3983850479125977
Validation loss: 1.999859889348348

Epoch: 5| Step: 5
Training loss: 1.5815554857254028
Validation loss: 2.0005576687474407

Epoch: 5| Step: 6
Training loss: 1.7568622827529907
Validation loss: 1.9918649081260926

Epoch: 5| Step: 7
Training loss: 2.4872522354125977
Validation loss: 2.020013227257677

Epoch: 5| Step: 8
Training loss: 2.1551876068115234
Validation loss: 2.0022054538931897

Epoch: 5| Step: 9
Training loss: 2.215811252593994
Validation loss: 1.9868564464712655

Epoch: 5| Step: 10
Training loss: 1.9316657781600952
Validation loss: 2.0073548593828754

Epoch: 143| Step: 0
Training loss: 2.2456612586975098
Validation loss: 2.0135089325648483

Epoch: 5| Step: 1
Training loss: 2.5579686164855957
Validation loss: 1.99725462800713

Epoch: 5| Step: 2
Training loss: 1.7449111938476562
Validation loss: 1.979511345586469

Epoch: 5| Step: 3
Training loss: 1.8572334051132202
Validation loss: 1.975862947843408

Epoch: 5| Step: 4
Training loss: 2.274326801300049
Validation loss: 1.9914662632890927

Epoch: 5| Step: 5
Training loss: 1.9244470596313477
Validation loss: 1.9929747581481934

Epoch: 5| Step: 6
Training loss: 1.6851074695587158
Validation loss: 1.9912488665632022

Epoch: 5| Step: 7
Training loss: 2.0454232692718506
Validation loss: 1.9811505643270348

Epoch: 5| Step: 8
Training loss: 2.8924388885498047
Validation loss: 1.995353585930281

Epoch: 5| Step: 9
Training loss: 2.2844672203063965
Validation loss: 2.005723448209865

Epoch: 5| Step: 10
Training loss: 1.3288145065307617
Validation loss: 1.98965278620361

Epoch: 144| Step: 0
Training loss: 2.522463321685791
Validation loss: 1.9838623180184314

Epoch: 5| Step: 1
Training loss: 2.4788644313812256
Validation loss: 1.9907643179739676

Epoch: 5| Step: 2
Training loss: 2.2331416606903076
Validation loss: 1.9980375920572588

Epoch: 5| Step: 3
Training loss: 2.048274517059326
Validation loss: 1.9744868663049513

Epoch: 5| Step: 4
Training loss: 2.276092290878296
Validation loss: 1.982360674488929

Epoch: 5| Step: 5
Training loss: 2.2195487022399902
Validation loss: 1.97250275458059

Epoch: 5| Step: 6
Training loss: 2.114091396331787
Validation loss: 1.96551267562374

Epoch: 5| Step: 7
Training loss: 2.1758358478546143
Validation loss: 2.0028235809777373

Epoch: 5| Step: 8
Training loss: 2.0028555393218994
Validation loss: 1.988486777069748

Epoch: 5| Step: 9
Training loss: 1.4894754886627197
Validation loss: 1.973234930346089

Epoch: 5| Step: 10
Training loss: 1.4548883438110352
Validation loss: 1.9687839208110687

Epoch: 145| Step: 0
Training loss: 2.6065876483917236
Validation loss: 1.9889537493387859

Epoch: 5| Step: 1
Training loss: 1.8497202396392822
Validation loss: 1.9961371908905685

Epoch: 5| Step: 2
Training loss: 2.109243869781494
Validation loss: 1.9943048800191572

Epoch: 5| Step: 3
Training loss: 1.848426103591919
Validation loss: 1.9768671194712322

Epoch: 5| Step: 4
Training loss: 2.2995522022247314
Validation loss: 1.9783776293518722

Epoch: 5| Step: 5
Training loss: 2.7176926136016846
Validation loss: 2.0043189320512997

Epoch: 5| Step: 6
Training loss: 1.9022455215454102
Validation loss: 1.9486101801677416

Epoch: 5| Step: 7
Training loss: 1.9067633152008057
Validation loss: 2.0007906113901446

Epoch: 5| Step: 8
Training loss: 2.238492965698242
Validation loss: 1.991490924230186

Epoch: 5| Step: 9
Training loss: 1.6516437530517578
Validation loss: 1.9893337911175144

Epoch: 5| Step: 10
Training loss: 1.9525136947631836
Validation loss: 1.9778721755550754

Epoch: 146| Step: 0
Training loss: 2.765752077102661
Validation loss: 1.9707291433888097

Epoch: 5| Step: 1
Training loss: 2.107417345046997
Validation loss: 1.978695470799682

Epoch: 5| Step: 2
Training loss: 2.3311867713928223
Validation loss: 1.9831016871236986

Epoch: 5| Step: 3
Training loss: 1.785220742225647
Validation loss: 1.9770985341841174

Epoch: 5| Step: 4
Training loss: 2.245723247528076
Validation loss: 1.98549610312267

Epoch: 5| Step: 5
Training loss: 1.473649024963379
Validation loss: 1.9929795867653304

Epoch: 5| Step: 6
Training loss: 1.4885075092315674
Validation loss: 1.972804997556953

Epoch: 5| Step: 7
Training loss: 2.3815770149230957
Validation loss: 1.9808059815437562

Epoch: 5| Step: 8
Training loss: 2.264429807662964
Validation loss: 1.991527421500093

Epoch: 5| Step: 9
Training loss: 2.1173253059387207
Validation loss: 1.9827502607017435

Epoch: 5| Step: 10
Training loss: 2.044013023376465
Validation loss: 1.98992528582132

Epoch: 147| Step: 0
Training loss: 2.3328585624694824
Validation loss: 2.010853651390281

Epoch: 5| Step: 1
Training loss: 2.052968740463257
Validation loss: 1.9794306267974198

Epoch: 5| Step: 2
Training loss: 1.8574155569076538
Validation loss: 1.9873718343755251

Epoch: 5| Step: 3
Training loss: 2.473726987838745
Validation loss: 1.9971713199410388

Epoch: 5| Step: 4
Training loss: 1.8048509359359741
Validation loss: 2.0162029907267582

Epoch: 5| Step: 5
Training loss: 1.8018567562103271
Validation loss: 1.9898564302793114

Epoch: 5| Step: 6
Training loss: 1.7346360683441162
Validation loss: 1.9922214836202643

Epoch: 5| Step: 7
Training loss: 2.3946995735168457
Validation loss: 1.9904607034498645

Epoch: 5| Step: 8
Training loss: 2.4269118309020996
Validation loss: 1.9883064608420096

Epoch: 5| Step: 9
Training loss: 2.4729485511779785
Validation loss: 1.9990102244961647

Epoch: 5| Step: 10
Training loss: 1.6878430843353271
Validation loss: 1.9998390930955128

Epoch: 148| Step: 0
Training loss: 1.797156572341919
Validation loss: 2.0104957408802484

Epoch: 5| Step: 1
Training loss: 1.9186904430389404
Validation loss: 1.9793266275877595

Epoch: 5| Step: 2
Training loss: 1.3953800201416016
Validation loss: 1.9952616563407324

Epoch: 5| Step: 3
Training loss: 2.162203311920166
Validation loss: 1.9996644386681177

Epoch: 5| Step: 4
Training loss: 2.2559261322021484
Validation loss: 2.001661023785991

Epoch: 5| Step: 5
Training loss: 2.004645586013794
Validation loss: 1.9834387212671258

Epoch: 5| Step: 6
Training loss: 2.438161849975586
Validation loss: 1.9934167054391676

Epoch: 5| Step: 7
Training loss: 2.1279361248016357
Validation loss: 1.9922777081048617

Epoch: 5| Step: 8
Training loss: 2.6519742012023926
Validation loss: 1.9933701612616097

Epoch: 5| Step: 9
Training loss: 2.238969326019287
Validation loss: 1.9968273896043018

Epoch: 5| Step: 10
Training loss: 1.9935331344604492
Validation loss: 1.975474811369373

Epoch: 149| Step: 0
Training loss: 1.4348853826522827
Validation loss: 1.9979329724465646

Epoch: 5| Step: 1
Training loss: 1.7974846363067627
Validation loss: 1.9806136918324295

Epoch: 5| Step: 2
Training loss: 2.489981174468994
Validation loss: 1.968567732841738

Epoch: 5| Step: 3
Training loss: 1.6273105144500732
Validation loss: 1.9875384338440434

Epoch: 5| Step: 4
Training loss: 2.5742645263671875
Validation loss: 1.9899757703145344

Epoch: 5| Step: 5
Training loss: 2.661661386489868
Validation loss: 1.9973631494788713

Epoch: 5| Step: 6
Training loss: 1.8911710977554321
Validation loss: 2.008374890973491

Epoch: 5| Step: 7
Training loss: 1.9487930536270142
Validation loss: 1.9933277740273425

Epoch: 5| Step: 8
Training loss: 2.2842230796813965
Validation loss: 2.001369442991031

Epoch: 5| Step: 9
Training loss: 2.4367587566375732
Validation loss: 1.9749838011239165

Epoch: 5| Step: 10
Training loss: 1.876516580581665
Validation loss: 2.004839022954305

Epoch: 150| Step: 0
Training loss: 1.8907325267791748
Validation loss: 1.961113255511048

Epoch: 5| Step: 1
Training loss: 1.95601487159729
Validation loss: 1.999447932807348

Epoch: 5| Step: 2
Training loss: 1.5800882577896118
Validation loss: 1.9970215597460348

Epoch: 5| Step: 3
Training loss: 2.1622958183288574
Validation loss: 1.9780427230301725

Epoch: 5| Step: 4
Training loss: 2.1521337032318115
Validation loss: 1.9799840604105303

Epoch: 5| Step: 5
Training loss: 2.566426992416382
Validation loss: 1.9802993010449153

Epoch: 5| Step: 6
Training loss: 2.112577199935913
Validation loss: 1.9901719272777598

Epoch: 5| Step: 7
Training loss: 2.1709582805633545
Validation loss: 1.9956058327869703

Epoch: 5| Step: 8
Training loss: 2.313218116760254
Validation loss: 1.9768927904867357

Epoch: 5| Step: 9
Training loss: 2.3108019828796387
Validation loss: 1.9831294885245703

Epoch: 5| Step: 10
Training loss: 1.5742241144180298
Validation loss: 1.997217494954345

Epoch: 151| Step: 0
Training loss: 1.6957435607910156
Validation loss: 1.96849996941064

Epoch: 5| Step: 1
Training loss: 2.3419833183288574
Validation loss: 1.990102901253649

Epoch: 5| Step: 2
Training loss: 2.249823808670044
Validation loss: 2.0129669302253315

Epoch: 5| Step: 3
Training loss: 3.040524959564209
Validation loss: 1.9990031719207764

Epoch: 5| Step: 4
Training loss: 2.13102388381958
Validation loss: 1.9745009791466497

Epoch: 5| Step: 5
Training loss: 1.8208467960357666
Validation loss: 1.9814596893966838

Epoch: 5| Step: 6
Training loss: 1.3107959032058716
Validation loss: 1.9711771549717072

Epoch: 5| Step: 7
Training loss: 1.8901304006576538
Validation loss: 1.9762615490985174

Epoch: 5| Step: 8
Training loss: 2.2129735946655273
Validation loss: 1.982374519430181

Epoch: 5| Step: 9
Training loss: 2.579338788986206
Validation loss: 1.9708021686923118

Epoch: 5| Step: 10
Training loss: 1.7131181955337524
Validation loss: 1.977867184146758

Epoch: 152| Step: 0
Training loss: 2.255471706390381
Validation loss: 1.9936756959525488

Epoch: 5| Step: 1
Training loss: 1.7827684879302979
Validation loss: 1.9786368390565277

Epoch: 5| Step: 2
Training loss: 1.8715585470199585
Validation loss: 1.9867450575674734

Epoch: 5| Step: 3
Training loss: 1.6570422649383545
Validation loss: 1.9761415245712444

Epoch: 5| Step: 4
Training loss: 2.4045321941375732
Validation loss: 1.9901254510366788

Epoch: 5| Step: 5
Training loss: 1.8136812448501587
Validation loss: 1.981384374762094

Epoch: 5| Step: 6
Training loss: 2.4138553142547607
Validation loss: 1.9981910618402625

Epoch: 5| Step: 7
Training loss: 2.3721585273742676
Validation loss: 1.9901185727888537

Epoch: 5| Step: 8
Training loss: 1.8248202800750732
Validation loss: 1.9912430035170687

Epoch: 5| Step: 9
Training loss: 2.1322922706604004
Validation loss: 1.9899981842246106

Epoch: 5| Step: 10
Training loss: 2.370957851409912
Validation loss: 2.0148675518651165

Epoch: 153| Step: 0
Training loss: 1.8832601308822632
Validation loss: 1.997339387093821

Epoch: 5| Step: 1
Training loss: 1.8993332386016846
Validation loss: 1.9783289099252352

Epoch: 5| Step: 2
Training loss: 2.1448628902435303
Validation loss: 1.9769961846772062

Epoch: 5| Step: 3
Training loss: 3.069281578063965
Validation loss: 1.983723158477455

Epoch: 5| Step: 4
Training loss: 2.0929653644561768
Validation loss: 1.9778074115835211

Epoch: 5| Step: 5
Training loss: 1.1847645044326782
Validation loss: 1.9828669063506588

Epoch: 5| Step: 6
Training loss: 1.8683996200561523
Validation loss: 1.997053518090197

Epoch: 5| Step: 7
Training loss: 1.9323604106903076
Validation loss: 1.990307733576785

Epoch: 5| Step: 8
Training loss: 2.1270430088043213
Validation loss: 1.9755164500205749

Epoch: 5| Step: 9
Training loss: 2.561586380004883
Validation loss: 2.0079942775029007

Epoch: 5| Step: 10
Training loss: 1.9229267835617065
Validation loss: 1.9900133789226573

Epoch: 154| Step: 0
Training loss: 1.512058973312378
Validation loss: 1.990122010630946

Epoch: 5| Step: 1
Training loss: 2.194681167602539
Validation loss: 1.973996255987434

Epoch: 5| Step: 2
Training loss: 2.66194486618042
Validation loss: 1.9882724374853156

Epoch: 5| Step: 3
Training loss: 2.016022205352783
Validation loss: 1.9811956523567118

Epoch: 5| Step: 4
Training loss: 2.205717086791992
Validation loss: 1.982623718118155

Epoch: 5| Step: 5
Training loss: 1.9436681270599365
Validation loss: 1.999029556910197

Epoch: 5| Step: 6
Training loss: 2.587101697921753
Validation loss: 2.0164191620324248

Epoch: 5| Step: 7
Training loss: 1.6660082340240479
Validation loss: 1.9998291961608394

Epoch: 5| Step: 8
Training loss: 1.9681873321533203
Validation loss: 1.9899321679146058

Epoch: 5| Step: 9
Training loss: 2.4293007850646973
Validation loss: 2.0018680044399795

Epoch: 5| Step: 10
Training loss: 1.4667829275131226
Validation loss: 1.985400039662597

Epoch: 155| Step: 0
Training loss: 2.5064120292663574
Validation loss: 1.993958278368878

Epoch: 5| Step: 1
Training loss: 2.167454242706299
Validation loss: 1.9897468705331125

Epoch: 5| Step: 2
Training loss: 2.308941125869751
Validation loss: 2.00218350912935

Epoch: 5| Step: 3
Training loss: 1.8309240341186523
Validation loss: 2.000262160455027

Epoch: 5| Step: 4
Training loss: 2.1482930183410645
Validation loss: 1.9741325839873283

Epoch: 5| Step: 5
Training loss: 3.117006778717041
Validation loss: 1.9837902938165972

Epoch: 5| Step: 6
Training loss: 1.7272999286651611
Validation loss: 1.9953638686928699

Epoch: 5| Step: 7
Training loss: 1.8459951877593994
Validation loss: 1.9939176497920867

Epoch: 5| Step: 8
Training loss: 2.1467461585998535
Validation loss: 2.005712952665103

Epoch: 5| Step: 9
Training loss: 1.354150414466858
Validation loss: 1.9793042700777772

Epoch: 5| Step: 10
Training loss: 1.5323814153671265
Validation loss: 2.002853746055275

Epoch: 156| Step: 0
Training loss: 1.8667373657226562
Validation loss: 1.9711058383346887

Epoch: 5| Step: 1
Training loss: 1.8197472095489502
Validation loss: 1.98305756045926

Epoch: 5| Step: 2
Training loss: 2.778944253921509
Validation loss: 1.9654846345224688

Epoch: 5| Step: 3
Training loss: 1.7453765869140625
Validation loss: 2.000382237536933

Epoch: 5| Step: 4
Training loss: 2.0820670127868652
Validation loss: 1.9754637889964606

Epoch: 5| Step: 5
Training loss: 1.8645541667938232
Validation loss: 1.982176556382128

Epoch: 5| Step: 6
Training loss: 2.20381236076355
Validation loss: 1.987122622869348

Epoch: 5| Step: 7
Training loss: 2.0819759368896484
Validation loss: 1.9773620200413529

Epoch: 5| Step: 8
Training loss: 2.0731072425842285
Validation loss: 1.9802655327704646

Epoch: 5| Step: 9
Training loss: 2.3145906925201416
Validation loss: 1.99775327661986

Epoch: 5| Step: 10
Training loss: 1.824437141418457
Validation loss: 1.9749366506453483

Epoch: 157| Step: 0
Training loss: 2.6270103454589844
Validation loss: 2.004073077632535

Epoch: 5| Step: 1
Training loss: 2.2012064456939697
Validation loss: 1.9960369820235877

Epoch: 5| Step: 2
Training loss: 1.482696294784546
Validation loss: 1.9722500719049925

Epoch: 5| Step: 3
Training loss: 2.309136390686035
Validation loss: 1.9749227890404322

Epoch: 5| Step: 4
Training loss: 2.183013439178467
Validation loss: 1.973137181292298

Epoch: 5| Step: 5
Training loss: 2.2279229164123535
Validation loss: 1.9780849846460486

Epoch: 5| Step: 6
Training loss: 1.5513808727264404
Validation loss: 1.9665005771062707

Epoch: 5| Step: 7
Training loss: 2.305385112762451
Validation loss: 1.9640911240731516

Epoch: 5| Step: 8
Training loss: 2.170452117919922
Validation loss: 1.986271071177657

Epoch: 5| Step: 9
Training loss: 1.5485212802886963
Validation loss: 1.9688299522604993

Epoch: 5| Step: 10
Training loss: 1.9964184761047363
Validation loss: 1.9764795662254415

Epoch: 158| Step: 0
Training loss: 1.9664733409881592
Validation loss: 1.9845441605455132

Epoch: 5| Step: 1
Training loss: 1.765960931777954
Validation loss: 1.9724711243824293

Epoch: 5| Step: 2
Training loss: 1.8485043048858643
Validation loss: 1.9770932607753302

Epoch: 5| Step: 3
Training loss: 2.4421863555908203
Validation loss: 1.9698470920644782

Epoch: 5| Step: 4
Training loss: 1.6700117588043213
Validation loss: 1.9830445038375033

Epoch: 5| Step: 5
Training loss: 1.9766149520874023
Validation loss: 1.9888541954819874

Epoch: 5| Step: 6
Training loss: 2.380872964859009
Validation loss: 2.0007346599332747

Epoch: 5| Step: 7
Training loss: 1.729984998703003
Validation loss: 1.9620600579887308

Epoch: 5| Step: 8
Training loss: 2.4131197929382324
Validation loss: 1.9754310282327796

Epoch: 5| Step: 9
Training loss: 2.051408290863037
Validation loss: 1.9736189021859118

Epoch: 5| Step: 10
Training loss: 2.6052613258361816
Validation loss: 1.9977364937464397

Epoch: 159| Step: 0
Training loss: 2.364231824874878
Validation loss: 1.9848571810671078

Epoch: 5| Step: 1
Training loss: 2.7024707794189453
Validation loss: 1.9791416250249392

Epoch: 5| Step: 2
Training loss: 2.0060572624206543
Validation loss: 1.974463819175638

Epoch: 5| Step: 3
Training loss: 2.1739981174468994
Validation loss: 1.9814870639513897

Epoch: 5| Step: 4
Training loss: 1.9043611288070679
Validation loss: 1.9911632653205626

Epoch: 5| Step: 5
Training loss: 1.7274820804595947
Validation loss: 1.97952357287048

Epoch: 5| Step: 6
Training loss: 1.8033908605575562
Validation loss: 1.9849998848412627

Epoch: 5| Step: 7
Training loss: 2.2400994300842285
Validation loss: 1.9782505830128987

Epoch: 5| Step: 8
Training loss: 1.8695083856582642
Validation loss: 1.9990266856326853

Epoch: 5| Step: 9
Training loss: 1.5918018817901611
Validation loss: 1.9750610038798342

Epoch: 5| Step: 10
Training loss: 2.4613027572631836
Validation loss: 2.0061213354910574

Epoch: 160| Step: 0
Training loss: 2.0274927616119385
Validation loss: 1.9547520581112112

Epoch: 5| Step: 1
Training loss: 1.363951325416565
Validation loss: 1.9985780639033164

Epoch: 5| Step: 2
Training loss: 1.9841362237930298
Validation loss: 1.9766872031714326

Epoch: 5| Step: 3
Training loss: 2.9958243370056152
Validation loss: 1.9754429401889924

Epoch: 5| Step: 4
Training loss: 1.8221467733383179
Validation loss: 1.9602635906588646

Epoch: 5| Step: 5
Training loss: 1.8030450344085693
Validation loss: 2.0022769281941075

Epoch: 5| Step: 6
Training loss: 2.366323947906494
Validation loss: 1.982817836987075

Epoch: 5| Step: 7
Training loss: 1.980960488319397
Validation loss: 1.9814061041801208

Epoch: 5| Step: 8
Training loss: 1.7396280765533447
Validation loss: 2.0048736295392438

Epoch: 5| Step: 9
Training loss: 2.2291982173919678
Validation loss: 1.9841450862987067

Epoch: 5| Step: 10
Training loss: 2.2837793827056885
Validation loss: 1.9828622700065694

Epoch: 161| Step: 0
Training loss: 1.8050003051757812
Validation loss: 1.9814710975975118

Epoch: 5| Step: 1
Training loss: 2.2085280418395996
Validation loss: 1.9689037735744188

Epoch: 5| Step: 2
Training loss: 2.287982940673828
Validation loss: 1.9863238514110606

Epoch: 5| Step: 3
Training loss: 1.755487084388733
Validation loss: 1.9691300866424397

Epoch: 5| Step: 4
Training loss: 2.3056769371032715
Validation loss: 1.9707750697289743

Epoch: 5| Step: 5
Training loss: 1.4564208984375
Validation loss: 1.9933781790476974

Epoch: 5| Step: 6
Training loss: 2.14176607131958
Validation loss: 1.9750523451835877

Epoch: 5| Step: 7
Training loss: 2.093777894973755
Validation loss: 1.964253346125285

Epoch: 5| Step: 8
Training loss: 1.814659833908081
Validation loss: 2.0042521569036666

Epoch: 5| Step: 9
Training loss: 2.2710964679718018
Validation loss: 2.0129881379424885

Epoch: 5| Step: 10
Training loss: 2.470132827758789
Validation loss: 1.9979365897435013

Epoch: 162| Step: 0
Training loss: 2.8190200328826904
Validation loss: 1.974621618947675

Epoch: 5| Step: 1
Training loss: 2.1323657035827637
Validation loss: 1.9666394533649567

Epoch: 5| Step: 2
Training loss: 1.9524732828140259
Validation loss: 1.9979676469679801

Epoch: 5| Step: 3
Training loss: 2.4160099029541016
Validation loss: 1.97866774887167

Epoch: 5| Step: 4
Training loss: 2.5060062408447266
Validation loss: 1.9565442582612396

Epoch: 5| Step: 5
Training loss: 1.5448493957519531
Validation loss: 1.9859012173068138

Epoch: 5| Step: 6
Training loss: 1.6244703531265259
Validation loss: 1.9563818875179495

Epoch: 5| Step: 7
Training loss: 2.0795974731445312
Validation loss: 1.9681843275664954

Epoch: 5| Step: 8
Training loss: 2.145756721496582
Validation loss: 1.9873824452841153

Epoch: 5| Step: 9
Training loss: 1.7480134963989258
Validation loss: 1.9790392537270822

Epoch: 5| Step: 10
Training loss: 1.5216923952102661
Validation loss: 1.9741745136117423

Epoch: 163| Step: 0
Training loss: 1.7315342426300049
Validation loss: 1.9575701734071136

Epoch: 5| Step: 1
Training loss: 2.327395439147949
Validation loss: 1.9753499197703537

Epoch: 5| Step: 2
Training loss: 2.2856833934783936
Validation loss: 1.9563526671419862

Epoch: 5| Step: 3
Training loss: 2.6466221809387207
Validation loss: 1.9710737479630338

Epoch: 5| Step: 4
Training loss: 1.9593760967254639
Validation loss: 1.971394245983452

Epoch: 5| Step: 5
Training loss: 2.1899161338806152
Validation loss: 1.9850888406076739

Epoch: 5| Step: 6
Training loss: 1.500931739807129
Validation loss: 1.9844993109344153

Epoch: 5| Step: 7
Training loss: 2.1184940338134766
Validation loss: 1.9740745162451139

Epoch: 5| Step: 8
Training loss: 1.5975685119628906
Validation loss: 1.946787247093775

Epoch: 5| Step: 9
Training loss: 1.7975289821624756
Validation loss: 1.9746844742887764

Epoch: 5| Step: 10
Training loss: 2.3685643672943115
Validation loss: 1.9737740229534846

Epoch: 164| Step: 0
Training loss: 2.747382402420044
Validation loss: 2.0021677991395355

Epoch: 5| Step: 1
Training loss: 1.9597721099853516
Validation loss: 1.9830947486303185

Epoch: 5| Step: 2
Training loss: 2.183384418487549
Validation loss: 1.985775625833901

Epoch: 5| Step: 3
Training loss: 1.6433216333389282
Validation loss: 2.006754454746041

Epoch: 5| Step: 4
Training loss: 2.6674602031707764
Validation loss: 1.9841431776682537

Epoch: 5| Step: 5
Training loss: 1.98745596408844
Validation loss: 1.9887812650331886

Epoch: 5| Step: 6
Training loss: 1.374521255493164
Validation loss: 1.998453818341737

Epoch: 5| Step: 7
Training loss: 1.8369414806365967
Validation loss: 1.9920238935819237

Epoch: 5| Step: 8
Training loss: 1.872929334640503
Validation loss: 2.002675658913069

Epoch: 5| Step: 9
Training loss: 2.100517988204956
Validation loss: 1.991464889177712

Epoch: 5| Step: 10
Training loss: 2.2617177963256836
Validation loss: 2.0051414018036215

Epoch: 165| Step: 0
Training loss: 2.492626428604126
Validation loss: 2.0067358068240586

Epoch: 5| Step: 1
Training loss: 1.9775364398956299
Validation loss: 1.9780610376788723

Epoch: 5| Step: 2
Training loss: 1.461606502532959
Validation loss: 1.990905782227875

Epoch: 5| Step: 3
Training loss: 1.683292031288147
Validation loss: 1.9775128646563458

Epoch: 5| Step: 4
Training loss: 2.2140886783599854
Validation loss: 1.9812207350166895

Epoch: 5| Step: 5
Training loss: 2.1648428440093994
Validation loss: 1.9911597364692277

Epoch: 5| Step: 6
Training loss: 1.8905935287475586
Validation loss: 1.9882522500971311

Epoch: 5| Step: 7
Training loss: 1.6936607360839844
Validation loss: 1.9721219616551553

Epoch: 5| Step: 8
Training loss: 2.0835423469543457
Validation loss: 1.99611617929192

Epoch: 5| Step: 9
Training loss: 2.7148289680480957
Validation loss: 1.9871816827404885

Epoch: 5| Step: 10
Training loss: 2.3163228034973145
Validation loss: 1.968198053298458

Epoch: 166| Step: 0
Training loss: 2.6186141967773438
Validation loss: 1.9732852776845295

Epoch: 5| Step: 1
Training loss: 1.8803889751434326
Validation loss: 1.9756516564276911

Epoch: 5| Step: 2
Training loss: 2.312507390975952
Validation loss: 1.9996603881159136

Epoch: 5| Step: 3
Training loss: 1.9526748657226562
Validation loss: 1.9666024587487663

Epoch: 5| Step: 4
Training loss: 2.2758166790008545
Validation loss: 1.99133897853154

Epoch: 5| Step: 5
Training loss: 1.7732837200164795
Validation loss: 1.9795915311382664

Epoch: 5| Step: 6
Training loss: 1.9466266632080078
Validation loss: 1.9726415987937682

Epoch: 5| Step: 7
Training loss: 2.520834445953369
Validation loss: 1.9557931525732881

Epoch: 5| Step: 8
Training loss: 1.182724952697754
Validation loss: 1.9735017027906192

Epoch: 5| Step: 9
Training loss: 1.9690606594085693
Validation loss: 1.9576812559558499

Epoch: 5| Step: 10
Training loss: 2.049511671066284
Validation loss: 1.9651948867305633

Epoch: 167| Step: 0
Training loss: 2.3288402557373047
Validation loss: 1.9900963883246146

Epoch: 5| Step: 1
Training loss: 1.7809158563613892
Validation loss: 1.9594584895718483

Epoch: 5| Step: 2
Training loss: 2.356081485748291
Validation loss: 1.9624229426025062

Epoch: 5| Step: 3
Training loss: 2.318373203277588
Validation loss: 1.990465010366132

Epoch: 5| Step: 4
Training loss: 1.6806840896606445
Validation loss: 1.9805068738998906

Epoch: 5| Step: 5
Training loss: 2.0983481407165527
Validation loss: 1.968981417276526

Epoch: 5| Step: 6
Training loss: 2.173532009124756
Validation loss: 1.9863033140859296

Epoch: 5| Step: 7
Training loss: 1.827038049697876
Validation loss: 1.9706823236198836

Epoch: 5| Step: 8
Training loss: 1.4293028116226196
Validation loss: 1.9664333251214796

Epoch: 5| Step: 9
Training loss: 1.9672229290008545
Validation loss: 1.98623824632296

Epoch: 5| Step: 10
Training loss: 2.446120500564575
Validation loss: 1.9758137515796128

Epoch: 168| Step: 0
Training loss: 2.046909809112549
Validation loss: 1.9789132097715973

Epoch: 5| Step: 1
Training loss: 2.481518507003784
Validation loss: 1.9785109361012776

Epoch: 5| Step: 2
Training loss: 1.4895875453948975
Validation loss: 1.968838873729911

Epoch: 5| Step: 3
Training loss: 1.9970241785049438
Validation loss: 1.961712347563877

Epoch: 5| Step: 4
Training loss: 2.385648250579834
Validation loss: 1.9716143851639123

Epoch: 5| Step: 5
Training loss: 2.3552727699279785
Validation loss: 1.972672462463379

Epoch: 5| Step: 6
Training loss: 2.0581653118133545
Validation loss: 1.9642744512968167

Epoch: 5| Step: 7
Training loss: 1.9762077331542969
Validation loss: 1.9698377270852365

Epoch: 5| Step: 8
Training loss: 1.855699896812439
Validation loss: 1.970593604990231

Epoch: 5| Step: 9
Training loss: 2.512857437133789
Validation loss: 2.0001478143917617

Epoch: 5| Step: 10
Training loss: 1.268782615661621
Validation loss: 1.9676026285335582

Epoch: 169| Step: 0
Training loss: 1.7900829315185547
Validation loss: 1.9465143590845086

Epoch: 5| Step: 1
Training loss: 1.7845208644866943
Validation loss: 1.984835027366556

Epoch: 5| Step: 2
Training loss: 2.350095272064209
Validation loss: 1.976141510471221

Epoch: 5| Step: 3
Training loss: 2.383626699447632
Validation loss: 1.970302850969376

Epoch: 5| Step: 4
Training loss: 1.9573562145233154
Validation loss: 1.992823495659777

Epoch: 5| Step: 5
Training loss: 1.5050010681152344
Validation loss: 1.9799533223593107

Epoch: 5| Step: 6
Training loss: 2.314862012863159
Validation loss: 1.9746347486331899

Epoch: 5| Step: 7
Training loss: 2.0128440856933594
Validation loss: 1.9795641373562556

Epoch: 5| Step: 8
Training loss: 1.8002121448516846
Validation loss: 1.980594055626982

Epoch: 5| Step: 9
Training loss: 2.1708731651306152
Validation loss: 1.985563096179757

Epoch: 5| Step: 10
Training loss: 2.4316959381103516
Validation loss: 1.975950038561257

Epoch: 170| Step: 0
Training loss: 2.0939512252807617
Validation loss: 1.98914885264571

Epoch: 5| Step: 1
Training loss: 2.1300411224365234
Validation loss: 1.9728623000524377

Epoch: 5| Step: 2
Training loss: 2.1411325931549072
Validation loss: 1.9749571533613308

Epoch: 5| Step: 3
Training loss: 2.50441575050354
Validation loss: 1.9709560486578173

Epoch: 5| Step: 4
Training loss: 2.0553975105285645
Validation loss: 1.9872351449023011

Epoch: 5| Step: 5
Training loss: 1.6124080419540405
Validation loss: 1.9864294439233758

Epoch: 5| Step: 6
Training loss: 1.6165130138397217
Validation loss: 1.9876637766438146

Epoch: 5| Step: 7
Training loss: 1.9730455875396729
Validation loss: 1.984158641548567

Epoch: 5| Step: 8
Training loss: 1.8740482330322266
Validation loss: 1.98675783218876

Epoch: 5| Step: 9
Training loss: 1.7849476337432861
Validation loss: 1.991724721847042

Epoch: 5| Step: 10
Training loss: 2.728759527206421
Validation loss: 1.9974190958084599

Epoch: 171| Step: 0
Training loss: 1.5914747714996338
Validation loss: 1.9767409191336682

Epoch: 5| Step: 1
Training loss: 2.2064287662506104
Validation loss: 1.9705489297066965

Epoch: 5| Step: 2
Training loss: 2.0377326011657715
Validation loss: 1.9760102251524567

Epoch: 5| Step: 3
Training loss: 2.610384941101074
Validation loss: 1.9896365032401135

Epoch: 5| Step: 4
Training loss: 2.281075954437256
Validation loss: 1.9807569314074773

Epoch: 5| Step: 5
Training loss: 1.6307226419448853
Validation loss: 1.9906927859911354

Epoch: 5| Step: 6
Training loss: 2.726522922515869
Validation loss: 1.9704377215395692

Epoch: 5| Step: 7
Training loss: 1.6955852508544922
Validation loss: 1.9658054562025173

Epoch: 5| Step: 8
Training loss: 2.489885091781616
Validation loss: 1.9873858497988792

Epoch: 5| Step: 9
Training loss: 1.0464861392974854
Validation loss: 1.9774198429558867

Epoch: 5| Step: 10
Training loss: 1.991072654724121
Validation loss: 1.9748606822823966

Epoch: 172| Step: 0
Training loss: 1.7566261291503906
Validation loss: 1.9977918568477835

Epoch: 5| Step: 1
Training loss: 2.350407361984253
Validation loss: 1.9701483890574465

Epoch: 5| Step: 2
Training loss: 2.0061893463134766
Validation loss: 1.9640174527322092

Epoch: 5| Step: 3
Training loss: 1.9276249408721924
Validation loss: 1.9620846368933236

Epoch: 5| Step: 4
Training loss: 3.0672755241394043
Validation loss: 1.9609124814310381

Epoch: 5| Step: 5
Training loss: 1.8679901361465454
Validation loss: 1.982341508711538

Epoch: 5| Step: 6
Training loss: 1.8152494430541992
Validation loss: 1.977087425929244

Epoch: 5| Step: 7
Training loss: 1.9267524480819702
Validation loss: 1.9859424406482327

Epoch: 5| Step: 8
Training loss: 1.516883373260498
Validation loss: 1.9652704167109665

Epoch: 5| Step: 9
Training loss: 2.1114070415496826
Validation loss: 1.9729625076375983

Epoch: 5| Step: 10
Training loss: 1.913487434387207
Validation loss: 1.9703099778903428

Epoch: 173| Step: 0
Training loss: 1.6461101770401
Validation loss: 1.964867232948221

Epoch: 5| Step: 1
Training loss: 2.7384238243103027
Validation loss: 1.9606822075382355

Epoch: 5| Step: 2
Training loss: 2.2186927795410156
Validation loss: 2.004068925816526

Epoch: 5| Step: 3
Training loss: 1.9637644290924072
Validation loss: 1.9603182064589633

Epoch: 5| Step: 4
Training loss: 1.569098949432373
Validation loss: 1.9983312224829068

Epoch: 5| Step: 5
Training loss: 1.9058735370635986
Validation loss: 1.9428948304986442

Epoch: 5| Step: 6
Training loss: 1.7308740615844727
Validation loss: 1.9850216091320079

Epoch: 5| Step: 7
Training loss: 1.39388906955719
Validation loss: 1.9959453331526888

Epoch: 5| Step: 8
Training loss: 2.915598154067993
Validation loss: 1.9597575792702295

Epoch: 5| Step: 9
Training loss: 2.437723398208618
Validation loss: 1.966425670090542

Epoch: 5| Step: 10
Training loss: 1.6783777475357056
Validation loss: 1.983007018284131

Epoch: 174| Step: 0
Training loss: 2.177664279937744
Validation loss: 1.97315675468855

Epoch: 5| Step: 1
Training loss: 2.329169750213623
Validation loss: 1.9858104490464734

Epoch: 5| Step: 2
Training loss: 2.0857791900634766
Validation loss: 1.989381633779054

Epoch: 5| Step: 3
Training loss: 2.0301172733306885
Validation loss: 1.9932927290598552

Epoch: 5| Step: 4
Training loss: 2.110461473464966
Validation loss: 1.9825899652255479

Epoch: 5| Step: 5
Training loss: 2.0604336261749268
Validation loss: 1.980695109213552

Epoch: 5| Step: 6
Training loss: 1.5648431777954102
Validation loss: 1.9922921490925614

Epoch: 5| Step: 7
Training loss: 2.1800551414489746
Validation loss: 1.9814353143015215

Epoch: 5| Step: 8
Training loss: 2.007922649383545
Validation loss: 1.9604940427246915

Epoch: 5| Step: 9
Training loss: 2.0064616203308105
Validation loss: 2.0068157360117924

Epoch: 5| Step: 10
Training loss: 1.5991212129592896
Validation loss: 1.9897427071807205

Epoch: 175| Step: 0
Training loss: 2.56194806098938
Validation loss: 1.9826380450238463

Epoch: 5| Step: 1
Training loss: 2.0356268882751465
Validation loss: 1.9788817769737654

Epoch: 5| Step: 2
Training loss: 2.172593593597412
Validation loss: 1.9699988121627479

Epoch: 5| Step: 3
Training loss: 1.9099292755126953
Validation loss: 1.9667697773184827

Epoch: 5| Step: 4
Training loss: 2.153123140335083
Validation loss: 1.9600008354392102

Epoch: 5| Step: 5
Training loss: 1.707144021987915
Validation loss: 1.980673954051028

Epoch: 5| Step: 6
Training loss: 1.75750732421875
Validation loss: 1.9707328632313719

Epoch: 5| Step: 7
Training loss: 2.266317129135132
Validation loss: 1.9754674203934208

Epoch: 5| Step: 8
Training loss: 1.672710657119751
Validation loss: 1.981416102378599

Epoch: 5| Step: 9
Training loss: 2.2852957248687744
Validation loss: 1.9768931699055496

Epoch: 5| Step: 10
Training loss: 1.627861738204956
Validation loss: 1.9885181662856892

Epoch: 176| Step: 0
Training loss: 2.1475021839141846
Validation loss: 1.9831503642502653

Epoch: 5| Step: 1
Training loss: 1.6690346002578735
Validation loss: 1.9731315887102516

Epoch: 5| Step: 2
Training loss: 1.5975377559661865
Validation loss: 1.9706374073541293

Epoch: 5| Step: 3
Training loss: 2.0943238735198975
Validation loss: 1.9872084663760277

Epoch: 5| Step: 4
Training loss: 2.3305230140686035
Validation loss: 1.967082751694546

Epoch: 5| Step: 5
Training loss: 1.633466124534607
Validation loss: 1.983303741742206

Epoch: 5| Step: 6
Training loss: 2.433382034301758
Validation loss: 1.98734765027159

Epoch: 5| Step: 7
Training loss: 2.149406909942627
Validation loss: 1.9884591397418772

Epoch: 5| Step: 8
Training loss: 2.327380418777466
Validation loss: 1.9749407742613105

Epoch: 5| Step: 9
Training loss: 1.7538807392120361
Validation loss: 1.9811510783369823

Epoch: 5| Step: 10
Training loss: 2.091796875
Validation loss: 1.9659489406052457

Epoch: 177| Step: 0
Training loss: 1.8237593173980713
Validation loss: 1.983814267702

Epoch: 5| Step: 1
Training loss: 1.6917502880096436
Validation loss: 1.9582237864053378

Epoch: 5| Step: 2
Training loss: 2.0258452892303467
Validation loss: 1.9602108847710393

Epoch: 5| Step: 3
Training loss: 2.5656745433807373
Validation loss: 1.9705356987573768

Epoch: 5| Step: 4
Training loss: 1.2556365728378296
Validation loss: 1.9674683770825785

Epoch: 5| Step: 5
Training loss: 2.144996166229248
Validation loss: 1.9754718554917203

Epoch: 5| Step: 6
Training loss: 1.9389606714248657
Validation loss: 1.9717300374020812

Epoch: 5| Step: 7
Training loss: 3.0749783515930176
Validation loss: 1.978516128755385

Epoch: 5| Step: 8
Training loss: 1.4183740615844727
Validation loss: 1.9654415627961517

Epoch: 5| Step: 9
Training loss: 2.122100830078125
Validation loss: 1.9872150395506172

Epoch: 5| Step: 10
Training loss: 2.105027198791504
Validation loss: 1.9669982515355593

Epoch: 178| Step: 0
Training loss: 2.0552735328674316
Validation loss: 1.9767341588133125

Epoch: 5| Step: 1
Training loss: 1.8977317810058594
Validation loss: 1.967069956564134

Epoch: 5| Step: 2
Training loss: 1.4006216526031494
Validation loss: 1.9808289325365456

Epoch: 5| Step: 3
Training loss: 1.8991397619247437
Validation loss: 1.969301672391994

Epoch: 5| Step: 4
Training loss: 1.8680185079574585
Validation loss: 1.9620879427079232

Epoch: 5| Step: 5
Training loss: 2.165496349334717
Validation loss: 1.9383349444276543

Epoch: 5| Step: 6
Training loss: 2.4683308601379395
Validation loss: 1.9852999128321165

Epoch: 5| Step: 7
Training loss: 2.58754301071167
Validation loss: 1.9709364124523696

Epoch: 5| Step: 8
Training loss: 2.1249265670776367
Validation loss: 1.97763491189608

Epoch: 5| Step: 9
Training loss: 1.904439926147461
Validation loss: 1.9721952715227682

Epoch: 5| Step: 10
Training loss: 1.7878957986831665
Validation loss: 1.9747995612441853

Epoch: 179| Step: 0
Training loss: 2.2117762565612793
Validation loss: 1.9745645087252381

Epoch: 5| Step: 1
Training loss: 2.5433785915374756
Validation loss: 1.9704149576925463

Epoch: 5| Step: 2
Training loss: 2.3715693950653076
Validation loss: 1.9880817397948234

Epoch: 5| Step: 3
Training loss: 1.3219079971313477
Validation loss: 1.977937259981709

Epoch: 5| Step: 4
Training loss: 2.3198659420013428
Validation loss: 1.9847571567822528

Epoch: 5| Step: 5
Training loss: 1.7852222919464111
Validation loss: 1.9634352409711449

Epoch: 5| Step: 6
Training loss: 2.1883349418640137
Validation loss: 1.9877510070800781

Epoch: 5| Step: 7
Training loss: 1.811898946762085
Validation loss: 1.9704556875331427

Epoch: 5| Step: 8
Training loss: 1.9549903869628906
Validation loss: 1.976303388995509

Epoch: 5| Step: 9
Training loss: 1.5181982517242432
Validation loss: 1.9524259644169961

Epoch: 5| Step: 10
Training loss: 2.083918809890747
Validation loss: 1.9594296063146284

Epoch: 180| Step: 0
Training loss: 1.423198938369751
Validation loss: 1.967802962949199

Epoch: 5| Step: 1
Training loss: 2.49222731590271
Validation loss: 1.9496520578220327

Epoch: 5| Step: 2
Training loss: 1.9798576831817627
Validation loss: 1.9665107150231638

Epoch: 5| Step: 3
Training loss: 2.103922128677368
Validation loss: 1.980737683593586

Epoch: 5| Step: 4
Training loss: 2.1474556922912598
Validation loss: 1.9865342673435007

Epoch: 5| Step: 5
Training loss: 1.588385820388794
Validation loss: 1.9585287058225243

Epoch: 5| Step: 6
Training loss: 2.4311938285827637
Validation loss: 1.9735145876484532

Epoch: 5| Step: 7
Training loss: 1.7291069030761719
Validation loss: 1.964310029501556

Epoch: 5| Step: 8
Training loss: 1.983534812927246
Validation loss: 1.971737297632361

Epoch: 5| Step: 9
Training loss: 2.259859085083008
Validation loss: 1.9614278013988207

Epoch: 5| Step: 10
Training loss: 2.0187129974365234
Validation loss: 1.982753735716625

Epoch: 181| Step: 0
Training loss: 1.8387361764907837
Validation loss: 1.9685539366096578

Epoch: 5| Step: 1
Training loss: 2.210587739944458
Validation loss: 1.992737723935035

Epoch: 5| Step: 2
Training loss: 2.472609758377075
Validation loss: 1.9667714385576145

Epoch: 5| Step: 3
Training loss: 1.9926446676254272
Validation loss: 1.9715447310478456

Epoch: 5| Step: 4
Training loss: 1.8395963907241821
Validation loss: 1.9792019385163502

Epoch: 5| Step: 5
Training loss: 1.553065299987793
Validation loss: 1.974061555759881

Epoch: 5| Step: 6
Training loss: 2.7007789611816406
Validation loss: 1.9935927980689592

Epoch: 5| Step: 7
Training loss: 1.7492752075195312
Validation loss: 1.9899612652358187

Epoch: 5| Step: 8
Training loss: 1.7749265432357788
Validation loss: 1.9923014384444042

Epoch: 5| Step: 9
Training loss: 1.7608312368392944
Validation loss: 1.9690592596607823

Epoch: 5| Step: 10
Training loss: 2.370500326156616
Validation loss: 1.9886429835391302

Epoch: 182| Step: 0
Training loss: 1.7253515720367432
Validation loss: 1.9817329452883812

Epoch: 5| Step: 1
Training loss: 2.3855655193328857
Validation loss: 1.9537372486565703

Epoch: 5| Step: 2
Training loss: 1.7601463794708252
Validation loss: 1.9756848248102332

Epoch: 5| Step: 3
Training loss: 2.487722873687744
Validation loss: 1.9543802122915945

Epoch: 5| Step: 4
Training loss: 2.5942015647888184
Validation loss: 1.9800194412149408

Epoch: 5| Step: 5
Training loss: 1.7620214223861694
Validation loss: 1.9981918591325

Epoch: 5| Step: 6
Training loss: 1.5670323371887207
Validation loss: 1.9876926534919328

Epoch: 5| Step: 7
Training loss: 1.3813480138778687
Validation loss: 1.9769900832124936

Epoch: 5| Step: 8
Training loss: 1.6354501247406006
Validation loss: 1.9761774898857198

Epoch: 5| Step: 9
Training loss: 2.152501106262207
Validation loss: 1.9640719685503232

Epoch: 5| Step: 10
Training loss: 2.581566333770752
Validation loss: 1.9942324417893604

Epoch: 183| Step: 0
Training loss: 1.480799913406372
Validation loss: 1.9539495283557522

Epoch: 5| Step: 1
Training loss: 1.6458173990249634
Validation loss: 1.9709007317020046

Epoch: 5| Step: 2
Training loss: 2.4432241916656494
Validation loss: 1.9611692120951991

Epoch: 5| Step: 3
Training loss: 2.068748950958252
Validation loss: 1.9824610243561447

Epoch: 5| Step: 4
Training loss: 1.7022628784179688
Validation loss: 1.9628452177970641

Epoch: 5| Step: 5
Training loss: 1.9228004217147827
Validation loss: 1.976152446962172

Epoch: 5| Step: 6
Training loss: 2.3902530670166016
Validation loss: 1.9803030080692743

Epoch: 5| Step: 7
Training loss: 1.472513198852539
Validation loss: 1.9658836677510252

Epoch: 5| Step: 8
Training loss: 1.7084993124008179
Validation loss: 1.9842848162497244

Epoch: 5| Step: 9
Training loss: 2.5469744205474854
Validation loss: 1.9663563633477816

Epoch: 5| Step: 10
Training loss: 2.720390796661377
Validation loss: 1.9625499991960422

Epoch: 184| Step: 0
Training loss: 2.4641263484954834
Validation loss: 1.982907631063974

Epoch: 5| Step: 1
Training loss: 1.8672399520874023
Validation loss: 1.9925944446235575

Epoch: 5| Step: 2
Training loss: 1.7949457168579102
Validation loss: 1.9596128745745587

Epoch: 5| Step: 3
Training loss: 2.2152392864227295
Validation loss: 1.9793598780068018

Epoch: 5| Step: 4
Training loss: 1.869397759437561
Validation loss: 1.978266103293306

Epoch: 5| Step: 5
Training loss: 2.319209337234497
Validation loss: 1.9594047941187376

Epoch: 5| Step: 6
Training loss: 1.8058147430419922
Validation loss: 1.9631028303536036

Epoch: 5| Step: 7
Training loss: 2.2407166957855225
Validation loss: 1.9640162285938059

Epoch: 5| Step: 8
Training loss: 2.076970338821411
Validation loss: 1.9662359555562336

Epoch: 5| Step: 9
Training loss: 1.7243874073028564
Validation loss: 1.9554543828451505

Epoch: 5| Step: 10
Training loss: 1.7523633241653442
Validation loss: 1.9692893092350294

Epoch: 185| Step: 0
Training loss: 1.9658514261245728
Validation loss: 1.9654483743893203

Epoch: 5| Step: 1
Training loss: 1.961530327796936
Validation loss: 1.9614090932312833

Epoch: 5| Step: 2
Training loss: 1.7466990947723389
Validation loss: 1.9823513595006799

Epoch: 5| Step: 3
Training loss: 2.06595778465271
Validation loss: 1.9657129356938023

Epoch: 5| Step: 4
Training loss: 1.3690952062606812
Validation loss: 1.9577281449430732

Epoch: 5| Step: 5
Training loss: 1.7981338500976562
Validation loss: 1.9558950495976273

Epoch: 5| Step: 6
Training loss: 2.076479911804199
Validation loss: 1.951386700394333

Epoch: 5| Step: 7
Training loss: 2.3509504795074463
Validation loss: 1.9601340473339122

Epoch: 5| Step: 8
Training loss: 1.6880050897598267
Validation loss: 1.9810425004651468

Epoch: 5| Step: 9
Training loss: 2.6902644634246826
Validation loss: 1.9885487428275488

Epoch: 5| Step: 10
Training loss: 2.125730037689209
Validation loss: 1.9770300234517744

Epoch: 186| Step: 0
Training loss: 2.156919002532959
Validation loss: 1.9823770215434413

Epoch: 5| Step: 1
Training loss: 1.395026445388794
Validation loss: 1.9906666971022082

Epoch: 5| Step: 2
Training loss: 1.5629826784133911
Validation loss: 1.9774937552790488

Epoch: 5| Step: 3
Training loss: 2.248558521270752
Validation loss: 1.9546570611256424

Epoch: 5| Step: 4
Training loss: 1.7107007503509521
Validation loss: 1.971167291364362

Epoch: 5| Step: 5
Training loss: 1.8935401439666748
Validation loss: 1.967788537343343

Epoch: 5| Step: 6
Training loss: 1.6747615337371826
Validation loss: 1.9887677623379616

Epoch: 5| Step: 7
Training loss: 2.1315293312072754
Validation loss: 1.9818803366794382

Epoch: 5| Step: 8
Training loss: 2.3301873207092285
Validation loss: 1.971353389883554

Epoch: 5| Step: 9
Training loss: 2.4592044353485107
Validation loss: 1.9747517724190988

Epoch: 5| Step: 10
Training loss: 2.3461508750915527
Validation loss: 1.9559022739369383

Epoch: 187| Step: 0
Training loss: 2.4945969581604004
Validation loss: 1.9745858343698646

Epoch: 5| Step: 1
Training loss: 1.7770172357559204
Validation loss: 1.9729678861556514

Epoch: 5| Step: 2
Training loss: 1.6561744213104248
Validation loss: 1.9692636984650806

Epoch: 5| Step: 3
Training loss: 1.5502688884735107
Validation loss: 1.951023247934157

Epoch: 5| Step: 4
Training loss: 2.2130796909332275
Validation loss: 1.9452174196961105

Epoch: 5| Step: 5
Training loss: 1.764228105545044
Validation loss: 1.970679436960528

Epoch: 5| Step: 6
Training loss: 2.251842498779297
Validation loss: 1.956897162622021

Epoch: 5| Step: 7
Training loss: 2.026042938232422
Validation loss: 1.9682167371114094

Epoch: 5| Step: 8
Training loss: 2.076773166656494
Validation loss: 1.9550831625538487

Epoch: 5| Step: 9
Training loss: 1.698038101196289
Validation loss: 1.9473176092229865

Epoch: 5| Step: 10
Training loss: 2.5607717037200928
Validation loss: 1.975942434803132

Epoch: 188| Step: 0
Training loss: 1.9463512897491455
Validation loss: 1.986376226589244

Epoch: 5| Step: 1
Training loss: 1.7000370025634766
Validation loss: 1.9762884134887366

Epoch: 5| Step: 2
Training loss: 1.6666759252548218
Validation loss: 1.9763639447509602

Epoch: 5| Step: 3
Training loss: 1.3844115734100342
Validation loss: 1.9683864180759718

Epoch: 5| Step: 4
Training loss: 3.1701550483703613
Validation loss: 1.9660183498936314

Epoch: 5| Step: 5
Training loss: 1.692591667175293
Validation loss: 1.9679253998623099

Epoch: 5| Step: 6
Training loss: 2.1882405281066895
Validation loss: 1.9672033145863523

Epoch: 5| Step: 7
Training loss: 1.6489124298095703
Validation loss: 1.957140386745494

Epoch: 5| Step: 8
Training loss: 1.904333472251892
Validation loss: 1.9542851704423145

Epoch: 5| Step: 9
Training loss: 2.5783252716064453
Validation loss: 1.9575700888069727

Epoch: 5| Step: 10
Training loss: 2.0882375240325928
Validation loss: 1.960865887262488

Epoch: 189| Step: 0
Training loss: 1.7606996297836304
Validation loss: 1.9803528426795878

Epoch: 5| Step: 1
Training loss: 2.1863279342651367
Validation loss: 1.9647743445570751

Epoch: 5| Step: 2
Training loss: 1.5901854038238525
Validation loss: 1.9708930253982544

Epoch: 5| Step: 3
Training loss: 1.9272180795669556
Validation loss: 1.9774484916399884

Epoch: 5| Step: 4
Training loss: 1.8207181692123413
Validation loss: 1.981673240661621

Epoch: 5| Step: 5
Training loss: 1.9814754724502563
Validation loss: 1.9741048556502148

Epoch: 5| Step: 6
Training loss: 2.0461838245391846
Validation loss: 1.9891010279296546

Epoch: 5| Step: 7
Training loss: 1.9932702779769897
Validation loss: 1.9960525804950344

Epoch: 5| Step: 8
Training loss: 2.2274069786071777
Validation loss: 1.9867177804311116

Epoch: 5| Step: 9
Training loss: 1.7585538625717163
Validation loss: 1.982242315046249

Epoch: 5| Step: 10
Training loss: 2.9878461360931396
Validation loss: 1.9953420854383899

Epoch: 190| Step: 0
Training loss: 1.750312089920044
Validation loss: 1.982208792881299

Epoch: 5| Step: 1
Training loss: 1.6087887287139893
Validation loss: 1.951567134549541

Epoch: 5| Step: 2
Training loss: 1.7736190557479858
Validation loss: 1.9821126307210615

Epoch: 5| Step: 3
Training loss: 1.7496334314346313
Validation loss: 1.9767786584874636

Epoch: 5| Step: 4
Training loss: 2.389320135116577
Validation loss: 1.9924791346314132

Epoch: 5| Step: 5
Training loss: 1.8573678731918335
Validation loss: 1.976905002388903

Epoch: 5| Step: 6
Training loss: 1.661354660987854
Validation loss: 1.9690433599615609

Epoch: 5| Step: 7
Training loss: 2.1278884410858154
Validation loss: 1.9763050463891798

Epoch: 5| Step: 8
Training loss: 1.833719253540039
Validation loss: 1.9994633954058412

Epoch: 5| Step: 9
Training loss: 2.5758962631225586
Validation loss: 1.9842686191681893

Epoch: 5| Step: 10
Training loss: 2.596238136291504
Validation loss: 1.980937271989802

Epoch: 191| Step: 0
Training loss: 2.2712996006011963
Validation loss: 1.9573659294395036

Epoch: 5| Step: 1
Training loss: 1.9785312414169312
Validation loss: 1.954560605428552

Epoch: 5| Step: 2
Training loss: 2.1814188957214355
Validation loss: 1.943158826520366

Epoch: 5| Step: 3
Training loss: 2.396775960922241
Validation loss: 1.9604632444279169

Epoch: 5| Step: 4
Training loss: 2.195328712463379
Validation loss: 1.952422018974058

Epoch: 5| Step: 5
Training loss: 1.7983379364013672
Validation loss: 1.9782227803302068

Epoch: 5| Step: 6
Training loss: 1.5066485404968262
Validation loss: 1.9526874685800204

Epoch: 5| Step: 7
Training loss: 2.103153705596924
Validation loss: 1.9664394265861922

Epoch: 5| Step: 8
Training loss: 1.6309000253677368
Validation loss: 1.9696427775967507

Epoch: 5| Step: 9
Training loss: 2.029163122177124
Validation loss: 1.9558666008774952

Epoch: 5| Step: 10
Training loss: 1.837921380996704
Validation loss: 1.9716084939177319

Epoch: 192| Step: 0
Training loss: 1.4847967624664307
Validation loss: 1.950139327715802

Epoch: 5| Step: 1
Training loss: 1.2944183349609375
Validation loss: 1.9509279266480477

Epoch: 5| Step: 2
Training loss: 1.74605393409729
Validation loss: 1.959412697822817

Epoch: 5| Step: 3
Training loss: 2.1710307598114014
Validation loss: 1.9725336361956853

Epoch: 5| Step: 4
Training loss: 2.386638879776001
Validation loss: 1.9841509660085042

Epoch: 5| Step: 5
Training loss: 2.2152748107910156
Validation loss: 1.9621979664730769

Epoch: 5| Step: 6
Training loss: 2.421095132827759
Validation loss: 1.9719171665048087

Epoch: 5| Step: 7
Training loss: 2.2322044372558594
Validation loss: 1.9627614098210489

Epoch: 5| Step: 8
Training loss: 1.9651451110839844
Validation loss: 1.9491282278491604

Epoch: 5| Step: 9
Training loss: 2.1510722637176514
Validation loss: 1.9551555161835046

Epoch: 5| Step: 10
Training loss: 1.733238697052002
Validation loss: 1.9429667957367436

Epoch: 193| Step: 0
Training loss: 2.502574920654297
Validation loss: 1.9462025703922394

Epoch: 5| Step: 1
Training loss: 1.6473859548568726
Validation loss: 1.9791329612014115

Epoch: 5| Step: 2
Training loss: 2.0983223915100098
Validation loss: 1.9728526979364374

Epoch: 5| Step: 3
Training loss: 1.3991279602050781
Validation loss: 1.9639665439564695

Epoch: 5| Step: 4
Training loss: 2.023172378540039
Validation loss: 1.968780025359123

Epoch: 5| Step: 5
Training loss: 1.7679694890975952
Validation loss: 1.9759537199492097

Epoch: 5| Step: 6
Training loss: 2.4247310161590576
Validation loss: 1.9600284048306045

Epoch: 5| Step: 7
Training loss: 2.1552023887634277
Validation loss: 1.9663167435635802

Epoch: 5| Step: 8
Training loss: 1.8486220836639404
Validation loss: 1.9370689840726956

Epoch: 5| Step: 9
Training loss: 1.8036772012710571
Validation loss: 1.9657988971279514

Epoch: 5| Step: 10
Training loss: 2.173715829849243
Validation loss: 1.9617428984693301

Epoch: 194| Step: 0
Training loss: 2.3777518272399902
Validation loss: 1.9571748933484476

Epoch: 5| Step: 1
Training loss: 3.3466758728027344
Validation loss: 1.9597571203785558

Epoch: 5| Step: 2
Training loss: 2.418154716491699
Validation loss: 1.9671267745315388

Epoch: 5| Step: 3
Training loss: 1.6263622045516968
Validation loss: 1.9495154298761839

Epoch: 5| Step: 4
Training loss: 1.8858579397201538
Validation loss: 1.9640171604771768

Epoch: 5| Step: 5
Training loss: 1.7769012451171875
Validation loss: 1.9832533867128435

Epoch: 5| Step: 6
Training loss: 2.168168544769287
Validation loss: 1.951884990097374

Epoch: 5| Step: 7
Training loss: 1.3865602016448975
Validation loss: 1.9610250585822648

Epoch: 5| Step: 8
Training loss: 2.054551601409912
Validation loss: 1.9650510767454743

Epoch: 5| Step: 9
Training loss: 1.286043643951416
Validation loss: 1.984051276278752

Epoch: 5| Step: 10
Training loss: 1.4233415126800537
Validation loss: 1.964015822256765

Epoch: 195| Step: 0
Training loss: 1.9169784784317017
Validation loss: 1.9503775488945745

Epoch: 5| Step: 1
Training loss: 1.8948274850845337
Validation loss: 1.9740517857254192

Epoch: 5| Step: 2
Training loss: 1.5824511051177979
Validation loss: 1.9545485806721512

Epoch: 5| Step: 3
Training loss: 1.9627020359039307
Validation loss: 1.9804546204946374

Epoch: 5| Step: 4
Training loss: 2.387664318084717
Validation loss: 1.960858820587076

Epoch: 5| Step: 5
Training loss: 1.8906265497207642
Validation loss: 1.974346972280933

Epoch: 5| Step: 6
Training loss: 1.9135081768035889
Validation loss: 1.955391860777332

Epoch: 5| Step: 7
Training loss: 2.1309099197387695
Validation loss: 1.9494517439155168

Epoch: 5| Step: 8
Training loss: 1.9999504089355469
Validation loss: 1.9518533804083382

Epoch: 5| Step: 9
Training loss: 1.8716013431549072
Validation loss: 1.962959611287681

Epoch: 5| Step: 10
Training loss: 2.195624828338623
Validation loss: 1.9629536956869147

Epoch: 196| Step: 0
Training loss: 1.0412814617156982
Validation loss: 1.9550915443769066

Epoch: 5| Step: 1
Training loss: 2.096221446990967
Validation loss: 1.9530251077426377

Epoch: 5| Step: 2
Training loss: 2.1317708492279053
Validation loss: 1.9501824737876974

Epoch: 5| Step: 3
Training loss: 2.7241122722625732
Validation loss: 1.9580357895102551

Epoch: 5| Step: 4
Training loss: 2.1493773460388184
Validation loss: 1.9376257324731478

Epoch: 5| Step: 5
Training loss: 1.922957181930542
Validation loss: 1.9770379297194942

Epoch: 5| Step: 6
Training loss: 1.6652326583862305
Validation loss: 1.9595087600010697

Epoch: 5| Step: 7
Training loss: 1.8578685522079468
Validation loss: 1.9633345591124667

Epoch: 5| Step: 8
Training loss: 2.315518379211426
Validation loss: 1.9649465853168118

Epoch: 5| Step: 9
Training loss: 1.6017318964004517
Validation loss: 1.9727703063718733

Epoch: 5| Step: 10
Training loss: 1.9681272506713867
Validation loss: 1.9810591948929654

Epoch: 197| Step: 0
Training loss: 1.899735450744629
Validation loss: 1.9576126760052097

Epoch: 5| Step: 1
Training loss: 1.896337866783142
Validation loss: 1.957908547052773

Epoch: 5| Step: 2
Training loss: 2.4916880130767822
Validation loss: 1.958431299014758

Epoch: 5| Step: 3
Training loss: 2.2936956882476807
Validation loss: 1.971937834575612

Epoch: 5| Step: 4
Training loss: 1.7239134311676025
Validation loss: 1.9803055717099098

Epoch: 5| Step: 5
Training loss: 1.725499153137207
Validation loss: 1.9632423308587843

Epoch: 5| Step: 6
Training loss: 1.6667455434799194
Validation loss: 1.9398896027636785

Epoch: 5| Step: 7
Training loss: 2.2405972480773926
Validation loss: 1.954538385073344

Epoch: 5| Step: 8
Training loss: 1.9898761510849
Validation loss: 1.9654009919012747

Epoch: 5| Step: 9
Training loss: 1.506920576095581
Validation loss: 1.9598786241264754

Epoch: 5| Step: 10
Training loss: 2.119859457015991
Validation loss: 1.9685086511796521

Epoch: 198| Step: 0
Training loss: 1.633954644203186
Validation loss: 1.9618946301039828

Epoch: 5| Step: 1
Training loss: 2.2099928855895996
Validation loss: 1.9750772458250805

Epoch: 5| Step: 2
Training loss: 1.8012441396713257
Validation loss: 1.9911371033678773

Epoch: 5| Step: 3
Training loss: 2.701690196990967
Validation loss: 1.9370604791948873

Epoch: 5| Step: 4
Training loss: 1.9490413665771484
Validation loss: 1.9637260052465624

Epoch: 5| Step: 5
Training loss: 2.352681875228882
Validation loss: 1.9395144511294622

Epoch: 5| Step: 6
Training loss: 2.5316262245178223
Validation loss: 1.9512771752572828

Epoch: 5| Step: 7
Training loss: 1.2947208881378174
Validation loss: 1.9489429163676437

Epoch: 5| Step: 8
Training loss: 1.709924340248108
Validation loss: 1.9621646673448625

Epoch: 5| Step: 9
Training loss: 1.432680368423462
Validation loss: 1.9715135994777884

Epoch: 5| Step: 10
Training loss: 1.847772240638733
Validation loss: 1.9430721677759641

Epoch: 199| Step: 0
Training loss: 1.898297667503357
Validation loss: 1.979227904350527

Epoch: 5| Step: 1
Training loss: 1.881434679031372
Validation loss: 1.945085105075631

Epoch: 5| Step: 2
Training loss: 1.6192245483398438
Validation loss: 1.957741577138183

Epoch: 5| Step: 3
Training loss: 1.6147115230560303
Validation loss: 1.9322836270896337

Epoch: 5| Step: 4
Training loss: 2.725796937942505
Validation loss: 1.9652231457412883

Epoch: 5| Step: 5
Training loss: 1.8816734552383423
Validation loss: 1.96084378868021

Epoch: 5| Step: 6
Training loss: 1.8811893463134766
Validation loss: 1.955808412644171

Epoch: 5| Step: 7
Training loss: 1.79946768283844
Validation loss: 1.9397307467716995

Epoch: 5| Step: 8
Training loss: 1.6482633352279663
Validation loss: 1.9433296739414174

Epoch: 5| Step: 9
Training loss: 2.293126344680786
Validation loss: 1.9449036377732472

Epoch: 5| Step: 10
Training loss: 2.272920846939087
Validation loss: 1.9629471968579035

Epoch: 200| Step: 0
Training loss: 2.390340805053711
Validation loss: 1.9995398265059277

Epoch: 5| Step: 1
Training loss: 1.1491973400115967
Validation loss: 1.9546474590096423

Epoch: 5| Step: 2
Training loss: 1.6521151065826416
Validation loss: 1.9532479201593707

Epoch: 5| Step: 3
Training loss: 2.0835602283477783
Validation loss: 1.9603593029001707

Epoch: 5| Step: 4
Training loss: 1.9963276386260986
Validation loss: 1.9612815175005185

Epoch: 5| Step: 5
Training loss: 2.3448448181152344
Validation loss: 1.94177120988087

Epoch: 5| Step: 6
Training loss: 1.8855005502700806
Validation loss: 1.9547222698888471

Epoch: 5| Step: 7
Training loss: 2.2913670539855957
Validation loss: 1.9432748402318647

Epoch: 5| Step: 8
Training loss: 2.102010488510132
Validation loss: 1.9695420111379316

Epoch: 5| Step: 9
Training loss: 1.6837289333343506
Validation loss: 1.963643625218381

Epoch: 5| Step: 10
Training loss: 1.8632479906082153
Validation loss: 1.9753084080193632

Epoch: 201| Step: 0
Training loss: 2.063000202178955
Validation loss: 1.9543960709725656

Epoch: 5| Step: 1
Training loss: 1.5152047872543335
Validation loss: 1.9354011807390439

Epoch: 5| Step: 2
Training loss: 1.4562718868255615
Validation loss: 1.9413574959642144

Epoch: 5| Step: 3
Training loss: 2.108508825302124
Validation loss: 1.9580048040677143

Epoch: 5| Step: 4
Training loss: 1.9688198566436768
Validation loss: 1.9808691778490621

Epoch: 5| Step: 5
Training loss: 1.4950315952301025
Validation loss: 1.9945240007933749

Epoch: 5| Step: 6
Training loss: 2.0804929733276367
Validation loss: 1.9786834447614607

Epoch: 5| Step: 7
Training loss: 2.0627989768981934
Validation loss: 1.9635097724135204

Epoch: 5| Step: 8
Training loss: 2.4528770446777344
Validation loss: 1.9835118555253552

Epoch: 5| Step: 9
Training loss: 2.26760196685791
Validation loss: 1.9751494033362276

Epoch: 5| Step: 10
Training loss: 2.2019543647766113
Validation loss: 1.9577569987184258

Epoch: 202| Step: 0
Training loss: 1.349281907081604
Validation loss: 1.975782649491423

Epoch: 5| Step: 1
Training loss: 2.763328790664673
Validation loss: 1.9500593703280213

Epoch: 5| Step: 2
Training loss: 1.802791953086853
Validation loss: 1.956557132864511

Epoch: 5| Step: 3
Training loss: 2.466195583343506
Validation loss: 1.96227010732056

Epoch: 5| Step: 4
Training loss: 1.7483360767364502
Validation loss: 1.9437692203829366

Epoch: 5| Step: 5
Training loss: 2.1528637409210205
Validation loss: 1.9842349380575202

Epoch: 5| Step: 6
Training loss: 2.2852518558502197
Validation loss: 1.9432608363448933

Epoch: 5| Step: 7
Training loss: 2.332165002822876
Validation loss: 1.9496120227280485

Epoch: 5| Step: 8
Training loss: 1.7690967321395874
Validation loss: 1.9633924576543993

Epoch: 5| Step: 9
Training loss: 1.2370662689208984
Validation loss: 1.9798554143598002

Epoch: 5| Step: 10
Training loss: 1.5365910530090332
Validation loss: 1.9576930256300076

Epoch: 203| Step: 0
Training loss: 2.0454277992248535
Validation loss: 1.9320444714638494

Epoch: 5| Step: 1
Training loss: 2.2785160541534424
Validation loss: 1.9272577942058604

Epoch: 5| Step: 2
Training loss: 2.3213298320770264
Validation loss: 1.9505534428422169

Epoch: 5| Step: 3
Training loss: 2.188602924346924
Validation loss: 1.9513944579708962

Epoch: 5| Step: 4
Training loss: 2.0009918212890625
Validation loss: 1.969791999427221

Epoch: 5| Step: 5
Training loss: 1.8911412954330444
Validation loss: 1.9562022378367763

Epoch: 5| Step: 6
Training loss: 1.4318575859069824
Validation loss: 1.9853596764226114

Epoch: 5| Step: 7
Training loss: 2.3403899669647217
Validation loss: 1.9704986797866

Epoch: 5| Step: 8
Training loss: 1.642613410949707
Validation loss: 1.9558820365577616

Epoch: 5| Step: 9
Training loss: 1.6351944208145142
Validation loss: 1.9869046570152364

Epoch: 5| Step: 10
Training loss: 1.5256284475326538
Validation loss: 1.9878863955056796

Epoch: 204| Step: 0
Training loss: 1.9580186605453491
Validation loss: 1.9637810876292567

Epoch: 5| Step: 1
Training loss: 2.290001630783081
Validation loss: 1.9739990990648988

Epoch: 5| Step: 2
Training loss: 1.5083379745483398
Validation loss: 1.954413612683614

Epoch: 5| Step: 3
Training loss: 1.9014440774917603
Validation loss: 1.9713347701616184

Epoch: 5| Step: 4
Training loss: 2.36064076423645
Validation loss: 1.954655647277832

Epoch: 5| Step: 5
Training loss: 2.0452592372894287
Validation loss: 1.9583966526933896

Epoch: 5| Step: 6
Training loss: 1.6297805309295654
Validation loss: 1.9566717147827148

Epoch: 5| Step: 7
Training loss: 1.7349309921264648
Validation loss: 1.9426866269880725

Epoch: 5| Step: 8
Training loss: 2.238912582397461
Validation loss: 1.9676258025630828

Epoch: 5| Step: 9
Training loss: 1.9915425777435303
Validation loss: 1.9681419018776185

Epoch: 5| Step: 10
Training loss: 1.859391212463379
Validation loss: 1.947469784367469

Epoch: 205| Step: 0
Training loss: 1.4575169086456299
Validation loss: 1.9590824816816597

Epoch: 5| Step: 1
Training loss: 2.3554325103759766
Validation loss: 1.9451685951602073

Epoch: 5| Step: 2
Training loss: 2.2396397590637207
Validation loss: 1.9637868032660535

Epoch: 5| Step: 3
Training loss: 2.0080699920654297
Validation loss: 1.930612043667865

Epoch: 5| Step: 4
Training loss: 1.8455928564071655
Validation loss: 1.9708803751135384

Epoch: 5| Step: 5
Training loss: 1.4674217700958252
Validation loss: 1.930929717197213

Epoch: 5| Step: 6
Training loss: 2.2579588890075684
Validation loss: 1.9472106836175407

Epoch: 5| Step: 7
Training loss: 2.2943837642669678
Validation loss: 1.9703265877180203

Epoch: 5| Step: 8
Training loss: 1.3184406757354736
Validation loss: 1.9140655353505125

Epoch: 5| Step: 9
Training loss: 2.120218276977539
Validation loss: 1.9374780449815976

Epoch: 5| Step: 10
Training loss: 1.939701795578003
Validation loss: 1.9417204869690763

Epoch: 206| Step: 0
Training loss: 1.9655708074569702
Validation loss: 1.938743584899492

Epoch: 5| Step: 1
Training loss: 1.802390694618225
Validation loss: 1.9475503275471349

Epoch: 5| Step: 2
Training loss: 1.6624069213867188
Validation loss: 1.9474450131898284

Epoch: 5| Step: 3
Training loss: 1.562278389930725
Validation loss: 1.9755407507701586

Epoch: 5| Step: 4
Training loss: 1.624894142150879
Validation loss: 1.94853941599528

Epoch: 5| Step: 5
Training loss: 2.522407054901123
Validation loss: 1.9546108207394999

Epoch: 5| Step: 6
Training loss: 1.6696128845214844
Validation loss: 1.9753563737356534

Epoch: 5| Step: 7
Training loss: 2.027601718902588
Validation loss: 1.9787586363413001

Epoch: 5| Step: 8
Training loss: 2.0804710388183594
Validation loss: 1.9622619280251123

Epoch: 5| Step: 9
Training loss: 2.2474565505981445
Validation loss: 1.9477261343309957

Epoch: 5| Step: 10
Training loss: 2.25419282913208
Validation loss: 1.9497092436718684

Epoch: 207| Step: 0
Training loss: 2.094813823699951
Validation loss: 1.9678272585715018

Epoch: 5| Step: 1
Training loss: 2.0243964195251465
Validation loss: 1.9693296263294835

Epoch: 5| Step: 2
Training loss: 2.0375266075134277
Validation loss: 1.9809752997531687

Epoch: 5| Step: 3
Training loss: 2.5068929195404053
Validation loss: 1.9495927377413678

Epoch: 5| Step: 4
Training loss: 1.6117569208145142
Validation loss: 1.9404829112432336

Epoch: 5| Step: 5
Training loss: 1.8632228374481201
Validation loss: 1.9615067717849568

Epoch: 5| Step: 6
Training loss: 1.8448333740234375
Validation loss: 1.9809376296176706

Epoch: 5| Step: 7
Training loss: 1.7577078342437744
Validation loss: 1.9709746632524716

Epoch: 5| Step: 8
Training loss: 2.118133068084717
Validation loss: 1.9749669464685584

Epoch: 5| Step: 9
Training loss: 1.782430648803711
Validation loss: 1.9539193004690192

Epoch: 5| Step: 10
Training loss: 1.7424339056015015
Validation loss: 1.97689817285025

Epoch: 208| Step: 0
Training loss: 1.9320627450942993
Validation loss: 1.9589091385564497

Epoch: 5| Step: 1
Training loss: 2.208580255508423
Validation loss: 1.978976195858371

Epoch: 5| Step: 2
Training loss: 2.221259117126465
Validation loss: 1.967229982858063

Epoch: 5| Step: 3
Training loss: 1.2997938394546509
Validation loss: 1.9436832102396155

Epoch: 5| Step: 4
Training loss: 1.7789630889892578
Validation loss: 1.937730537947788

Epoch: 5| Step: 5
Training loss: 1.9963462352752686
Validation loss: 1.925854330421776

Epoch: 5| Step: 6
Training loss: 1.4177205562591553
Validation loss: 1.958376238423009

Epoch: 5| Step: 7
Training loss: 2.145573616027832
Validation loss: 1.9293456564667404

Epoch: 5| Step: 8
Training loss: 2.3779091835021973
Validation loss: 1.9496269277347031

Epoch: 5| Step: 9
Training loss: 2.064696788787842
Validation loss: 1.9411389353454753

Epoch: 5| Step: 10
Training loss: 1.8888211250305176
Validation loss: 1.9252983293225687

Epoch: 209| Step: 0
Training loss: 2.57014536857605
Validation loss: 1.9721594882267777

Epoch: 5| Step: 1
Training loss: 2.527909994125366
Validation loss: 1.9542624540226434

Epoch: 5| Step: 2
Training loss: 1.7427276372909546
Validation loss: 1.965829090405536

Epoch: 5| Step: 3
Training loss: 2.0906403064727783
Validation loss: 1.9396958504953692

Epoch: 5| Step: 4
Training loss: 1.3642445802688599
Validation loss: 1.9618787124592771

Epoch: 5| Step: 5
Training loss: 2.036834239959717
Validation loss: 1.9257907290612497

Epoch: 5| Step: 6
Training loss: 1.413580298423767
Validation loss: 1.9431524187005975

Epoch: 5| Step: 7
Training loss: 1.1984041929244995
Validation loss: 1.964440494455317

Epoch: 5| Step: 8
Training loss: 2.246863603591919
Validation loss: 1.9660614972473474

Epoch: 5| Step: 9
Training loss: 1.6792494058609009
Validation loss: 1.9608940744912753

Epoch: 5| Step: 10
Training loss: 2.387664556503296
Validation loss: 1.9567504211138653

Epoch: 210| Step: 0
Training loss: 1.7583751678466797
Validation loss: 1.9403156798372987

Epoch: 5| Step: 1
Training loss: 1.664642572402954
Validation loss: 1.9413673480351765

Epoch: 5| Step: 2
Training loss: 2.3041281700134277
Validation loss: 1.9436247515422043

Epoch: 5| Step: 3
Training loss: 2.3627209663391113
Validation loss: 1.9567235951782556

Epoch: 5| Step: 4
Training loss: 1.9415127038955688
Validation loss: 1.9611334005991619

Epoch: 5| Step: 5
Training loss: 2.217285633087158
Validation loss: 1.9733553560831214

Epoch: 5| Step: 6
Training loss: 1.4367916584014893
Validation loss: 1.9762199232655187

Epoch: 5| Step: 7
Training loss: 1.188165545463562
Validation loss: 1.9491934596851308

Epoch: 5| Step: 8
Training loss: 2.286437511444092
Validation loss: 1.9695365890379875

Epoch: 5| Step: 9
Training loss: 1.9993953704833984
Validation loss: 1.9474138470106228

Epoch: 5| Step: 10
Training loss: 1.997533917427063
Validation loss: 1.9518579795796385

Epoch: 211| Step: 0
Training loss: 2.2049665451049805
Validation loss: 1.9712622088770713

Epoch: 5| Step: 1
Training loss: 1.7022106647491455
Validation loss: 1.9495777494163924

Epoch: 5| Step: 2
Training loss: 1.5213780403137207
Validation loss: 1.9761056797478789

Epoch: 5| Step: 3
Training loss: 1.75882089138031
Validation loss: 1.963334027157035

Epoch: 5| Step: 4
Training loss: 2.34271502494812
Validation loss: 1.9525450096335462

Epoch: 5| Step: 5
Training loss: 1.964975357055664
Validation loss: 1.9552820292852258

Epoch: 5| Step: 6
Training loss: 2.410726547241211
Validation loss: 1.959184080041865

Epoch: 5| Step: 7
Training loss: 1.7651050090789795
Validation loss: 1.9511712520353255

Epoch: 5| Step: 8
Training loss: 2.229095935821533
Validation loss: 1.9512715429388068

Epoch: 5| Step: 9
Training loss: 1.8375393152236938
Validation loss: 1.9551097244344733

Epoch: 5| Step: 10
Training loss: 1.3214335441589355
Validation loss: 1.959479985698577

Epoch: 212| Step: 0
Training loss: 1.494445562362671
Validation loss: 1.9557313008974957

Epoch: 5| Step: 1
Training loss: 1.8285019397735596
Validation loss: 1.948715966234925

Epoch: 5| Step: 2
Training loss: 2.0406253337860107
Validation loss: 1.941470520470732

Epoch: 5| Step: 3
Training loss: 1.5289199352264404
Validation loss: 1.9653930330789218

Epoch: 5| Step: 4
Training loss: 2.32850980758667
Validation loss: 1.9649110455666818

Epoch: 5| Step: 5
Training loss: 1.8144652843475342
Validation loss: 1.9620702420511553

Epoch: 5| Step: 6
Training loss: 2.026625871658325
Validation loss: 1.9448711615736767

Epoch: 5| Step: 7
Training loss: 1.5037075281143188
Validation loss: 1.9637560152238416

Epoch: 5| Step: 8
Training loss: 2.2428221702575684
Validation loss: 1.9770690010439964

Epoch: 5| Step: 9
Training loss: 1.835686445236206
Validation loss: 1.9528202369648924

Epoch: 5| Step: 10
Training loss: 2.44797420501709
Validation loss: 1.9520955457482287

Epoch: 213| Step: 0
Training loss: 2.115490674972534
Validation loss: 1.956674486078242

Epoch: 5| Step: 1
Training loss: 1.911241888999939
Validation loss: 1.944047321555435

Epoch: 5| Step: 2
Training loss: 1.580094575881958
Validation loss: 1.9502039288961759

Epoch: 5| Step: 3
Training loss: 1.587073564529419
Validation loss: 1.956673747749739

Epoch: 5| Step: 4
Training loss: 2.0730748176574707
Validation loss: 1.9521579178430701

Epoch: 5| Step: 5
Training loss: 1.9831173419952393
Validation loss: 1.9186687187481952

Epoch: 5| Step: 6
Training loss: 1.7190399169921875
Validation loss: 1.9473098990737752

Epoch: 5| Step: 7
Training loss: 1.495275616645813
Validation loss: 1.9485692388267928

Epoch: 5| Step: 8
Training loss: 2.0533502101898193
Validation loss: 1.9385459192337529

Epoch: 5| Step: 9
Training loss: 2.562903642654419
Validation loss: 1.9429911093045307

Epoch: 5| Step: 10
Training loss: 2.0871996879577637
Validation loss: 1.9332042676146313

Epoch: 214| Step: 0
Training loss: 1.804437279701233
Validation loss: 1.9711694332861132

Epoch: 5| Step: 1
Training loss: 2.120516538619995
Validation loss: 1.9327092862898303

Epoch: 5| Step: 2
Training loss: 2.362367630004883
Validation loss: 1.9290234081206783

Epoch: 5| Step: 3
Training loss: 1.6686954498291016
Validation loss: 1.9576703899650163

Epoch: 5| Step: 4
Training loss: 1.8053404092788696
Validation loss: 1.9225936141065372

Epoch: 5| Step: 5
Training loss: 1.3325581550598145
Validation loss: 1.9532492827343684

Epoch: 5| Step: 6
Training loss: 1.9462406635284424
Validation loss: 1.9422199674831924

Epoch: 5| Step: 7
Training loss: 2.012540817260742
Validation loss: 1.957852735314318

Epoch: 5| Step: 8
Training loss: 1.935093641281128
Validation loss: 1.971229273785827

Epoch: 5| Step: 9
Training loss: 2.0393242835998535
Validation loss: 1.9583980229593092

Epoch: 5| Step: 10
Training loss: 1.9291738271713257
Validation loss: 1.9665516320095267

Epoch: 215| Step: 0
Training loss: 1.8385365009307861
Validation loss: 1.9828248382896505

Epoch: 5| Step: 1
Training loss: 2.077873945236206
Validation loss: 1.9912983986639208

Epoch: 5| Step: 2
Training loss: 1.6707626581192017
Validation loss: 1.982270953475788

Epoch: 5| Step: 3
Training loss: 2.211303472518921
Validation loss: 1.9444950088377921

Epoch: 5| Step: 4
Training loss: 1.9374897480010986
Validation loss: 1.9828567145973124

Epoch: 5| Step: 5
Training loss: 2.4313199520111084
Validation loss: 1.9822942928601337

Epoch: 5| Step: 6
Training loss: 1.5769562721252441
Validation loss: 1.9621982100189372

Epoch: 5| Step: 7
Training loss: 2.186563491821289
Validation loss: 1.9721506077756163

Epoch: 5| Step: 8
Training loss: 1.8313385248184204
Validation loss: 1.9897714455922444

Epoch: 5| Step: 9
Training loss: 1.6497796773910522
Validation loss: 1.9800334169018654

Epoch: 5| Step: 10
Training loss: 1.4706302881240845
Validation loss: 1.9496898753668672

Epoch: 216| Step: 0
Training loss: 2.3009519577026367
Validation loss: 1.9452142318089802

Epoch: 5| Step: 1
Training loss: 1.5421826839447021
Validation loss: 1.960338149019467

Epoch: 5| Step: 2
Training loss: 2.173535108566284
Validation loss: 1.9663630903408091

Epoch: 5| Step: 3
Training loss: 1.687164306640625
Validation loss: 1.973729169496926

Epoch: 5| Step: 4
Training loss: 2.3441085815429688
Validation loss: 1.968577434939723

Epoch: 5| Step: 5
Training loss: 2.1423499584198
Validation loss: 1.9667031380438036

Epoch: 5| Step: 6
Training loss: 2.11700439453125
Validation loss: 1.9615516124233123

Epoch: 5| Step: 7
Training loss: 1.6077728271484375
Validation loss: 1.9559776552261845

Epoch: 5| Step: 8
Training loss: 1.5122243165969849
Validation loss: 1.9544000625610352

Epoch: 5| Step: 9
Training loss: 2.0280990600585938
Validation loss: 1.9579977809741933

Epoch: 5| Step: 10
Training loss: 1.408043622970581
Validation loss: 1.960897191878288

Epoch: 217| Step: 0
Training loss: 2.2175087928771973
Validation loss: 1.9488201910449612

Epoch: 5| Step: 1
Training loss: 1.6782455444335938
Validation loss: 1.9418559715312014

Epoch: 5| Step: 2
Training loss: 2.4411396980285645
Validation loss: 1.9371291668184343

Epoch: 5| Step: 3
Training loss: 1.946648359298706
Validation loss: 1.963464824102258

Epoch: 5| Step: 4
Training loss: 1.7744728326797485
Validation loss: 1.9383131547640728

Epoch: 5| Step: 5
Training loss: 1.4498518705368042
Validation loss: 1.9615836810040217

Epoch: 5| Step: 6
Training loss: 2.454272985458374
Validation loss: 1.9534801565190798

Epoch: 5| Step: 7
Training loss: 1.3032302856445312
Validation loss: 1.9744456429635324

Epoch: 5| Step: 8
Training loss: 2.3926594257354736
Validation loss: 1.9670141025256085

Epoch: 5| Step: 9
Training loss: 1.4925870895385742
Validation loss: 1.9602898192662064

Epoch: 5| Step: 10
Training loss: 1.8929041624069214
Validation loss: 1.9548540051265428

Epoch: 218| Step: 0
Training loss: 2.032353162765503
Validation loss: 1.9526192360026862

Epoch: 5| Step: 1
Training loss: 2.469062328338623
Validation loss: 1.9463893393034577

Epoch: 5| Step: 2
Training loss: 1.6723957061767578
Validation loss: 1.949440187023532

Epoch: 5| Step: 3
Training loss: 1.8241246938705444
Validation loss: 1.9820312697400329

Epoch: 5| Step: 4
Training loss: 1.998875617980957
Validation loss: 1.952854892259003

Epoch: 5| Step: 5
Training loss: 1.9180972576141357
Validation loss: 1.947129213681785

Epoch: 5| Step: 6
Training loss: 1.5175158977508545
Validation loss: 1.9430799304798085

Epoch: 5| Step: 7
Training loss: 1.839145302772522
Validation loss: 1.9785680129963865

Epoch: 5| Step: 8
Training loss: 1.7777624130249023
Validation loss: 1.9612214462731474

Epoch: 5| Step: 9
Training loss: 1.9621978998184204
Validation loss: 1.9532104871606315

Epoch: 5| Step: 10
Training loss: 1.8694425821304321
Validation loss: 1.9623785813649495

Epoch: 219| Step: 0
Training loss: 2.425226926803589
Validation loss: 1.9468466774109872

Epoch: 5| Step: 1
Training loss: 1.398634910583496
Validation loss: 1.9597648933369627

Epoch: 5| Step: 2
Training loss: 1.599138855934143
Validation loss: 1.9514705442613172

Epoch: 5| Step: 3
Training loss: 1.903655767440796
Validation loss: 1.9482217373386506

Epoch: 5| Step: 4
Training loss: 2.562006711959839
Validation loss: 1.957694133122762

Epoch: 5| Step: 5
Training loss: 1.9556595087051392
Validation loss: 1.9476815013475315

Epoch: 5| Step: 6
Training loss: 2.0120632648468018
Validation loss: 1.945377403689969

Epoch: 5| Step: 7
Training loss: 1.6468896865844727
Validation loss: 1.9726023212555917

Epoch: 5| Step: 8
Training loss: 1.8496620655059814
Validation loss: 1.9356836862461542

Epoch: 5| Step: 9
Training loss: 1.7349112033843994
Validation loss: 1.9412031148069648

Epoch: 5| Step: 10
Training loss: 1.9015345573425293
Validation loss: 1.9471739620290778

Epoch: 220| Step: 0
Training loss: 1.8476215600967407
Validation loss: 1.9211344103659354

Epoch: 5| Step: 1
Training loss: 1.9434115886688232
Validation loss: 1.9556305280295752

Epoch: 5| Step: 2
Training loss: 1.9234040975570679
Validation loss: 1.9447732869014944

Epoch: 5| Step: 3
Training loss: 1.7708364725112915
Validation loss: 1.9657425700977285

Epoch: 5| Step: 4
Training loss: 1.9234111309051514
Validation loss: 1.9652689964540544

Epoch: 5| Step: 5
Training loss: 2.221055030822754
Validation loss: 1.9151948139231691

Epoch: 5| Step: 6
Training loss: 1.9781811237335205
Validation loss: 1.9616296368260537

Epoch: 5| Step: 7
Training loss: 1.304517388343811
Validation loss: 1.9456007839531027

Epoch: 5| Step: 8
Training loss: 1.6959316730499268
Validation loss: 1.9495566198902745

Epoch: 5| Step: 9
Training loss: 2.1370060443878174
Validation loss: 1.9677750859209286

Epoch: 5| Step: 10
Training loss: 2.139273166656494
Validation loss: 1.9744590713131813

Epoch: 221| Step: 0
Training loss: 2.1261754035949707
Validation loss: 1.9611423989777923

Epoch: 5| Step: 1
Training loss: 1.7243397235870361
Validation loss: 1.943493946906059

Epoch: 5| Step: 2
Training loss: 1.509569764137268
Validation loss: 1.942159322000319

Epoch: 5| Step: 3
Training loss: 1.1201362609863281
Validation loss: 1.9365166259068314

Epoch: 5| Step: 4
Training loss: 2.143218517303467
Validation loss: 1.952756679186257

Epoch: 5| Step: 5
Training loss: 1.752698540687561
Validation loss: 1.9645781196573728

Epoch: 5| Step: 6
Training loss: 2.353048801422119
Validation loss: 1.9250374429969377

Epoch: 5| Step: 7
Training loss: 2.237596035003662
Validation loss: 1.9585962167350195

Epoch: 5| Step: 8
Training loss: 2.0661892890930176
Validation loss: 1.9672553667458155

Epoch: 5| Step: 9
Training loss: 2.174600124359131
Validation loss: 1.9753434119686004

Epoch: 5| Step: 10
Training loss: 1.586656928062439
Validation loss: 1.9297737267709547

Epoch: 222| Step: 0
Training loss: 2.2283453941345215
Validation loss: 1.9477191868648733

Epoch: 5| Step: 1
Training loss: 2.085946559906006
Validation loss: 1.9620806440230338

Epoch: 5| Step: 2
Training loss: 2.407012462615967
Validation loss: 1.957954745138845

Epoch: 5| Step: 3
Training loss: 2.0784854888916016
Validation loss: 1.9428667599155056

Epoch: 5| Step: 4
Training loss: 2.0738041400909424
Validation loss: 1.951401872019614

Epoch: 5| Step: 5
Training loss: 1.801477074623108
Validation loss: 1.9444657756436257

Epoch: 5| Step: 6
Training loss: 1.4920541048049927
Validation loss: 1.9590838134929698

Epoch: 5| Step: 7
Training loss: 1.5351543426513672
Validation loss: 1.9430583048892278

Epoch: 5| Step: 8
Training loss: 1.8321669101715088
Validation loss: 1.9535669447273336

Epoch: 5| Step: 9
Training loss: 1.7198388576507568
Validation loss: 1.9411999307652956

Epoch: 5| Step: 10
Training loss: 1.3566612005233765
Validation loss: 1.9273125766426005

Epoch: 223| Step: 0
Training loss: 1.6730787754058838
Validation loss: 1.951830430056459

Epoch: 5| Step: 1
Training loss: 1.375282645225525
Validation loss: 1.9464710015122608

Epoch: 5| Step: 2
Training loss: 1.747780203819275
Validation loss: 1.9320130502024004

Epoch: 5| Step: 3
Training loss: 2.1490347385406494
Validation loss: 1.9496894908207718

Epoch: 5| Step: 4
Training loss: 1.828583002090454
Validation loss: 1.942037159396756

Epoch: 5| Step: 5
Training loss: 2.6440441608428955
Validation loss: 1.9672175786828483

Epoch: 5| Step: 6
Training loss: 2.2047817707061768
Validation loss: 1.9624853185428086

Epoch: 5| Step: 7
Training loss: 1.9147403240203857
Validation loss: 1.9423513861112698

Epoch: 5| Step: 8
Training loss: 1.6084506511688232
Validation loss: 1.9682757546824794

Epoch: 5| Step: 9
Training loss: 1.94366455078125
Validation loss: 1.9603911997169576

Epoch: 5| Step: 10
Training loss: 1.8218542337417603
Validation loss: 1.9583362353745328

Epoch: 224| Step: 0
Training loss: 1.7180652618408203
Validation loss: 1.9405870270985428

Epoch: 5| Step: 1
Training loss: 1.7623004913330078
Validation loss: 1.9372224628284413

Epoch: 5| Step: 2
Training loss: 2.023092269897461
Validation loss: 1.9348752870354602

Epoch: 5| Step: 3
Training loss: 2.0758628845214844
Validation loss: 1.9286380147421232

Epoch: 5| Step: 4
Training loss: 2.0478248596191406
Validation loss: 1.966659467707398

Epoch: 5| Step: 5
Training loss: 1.841085433959961
Validation loss: 1.9290261806980256

Epoch: 5| Step: 6
Training loss: 1.8057801723480225
Validation loss: 1.9437401012707782

Epoch: 5| Step: 7
Training loss: 2.2739028930664062
Validation loss: 1.9350302860301027

Epoch: 5| Step: 8
Training loss: 1.857261061668396
Validation loss: 1.9574315060851395

Epoch: 5| Step: 9
Training loss: 1.408908724784851
Validation loss: 1.9472402218849427

Epoch: 5| Step: 10
Training loss: 1.980455756187439
Validation loss: 1.9782336335028372

Epoch: 225| Step: 0
Training loss: 2.6192002296447754
Validation loss: 1.9505132372661302

Epoch: 5| Step: 1
Training loss: 1.8780133724212646
Validation loss: 1.9258424184655631

Epoch: 5| Step: 2
Training loss: 1.9270751476287842
Validation loss: 1.962721509318198

Epoch: 5| Step: 3
Training loss: 1.4005576372146606
Validation loss: 1.9580540721134474

Epoch: 5| Step: 4
Training loss: 1.8082717657089233
Validation loss: 1.9602685333580099

Epoch: 5| Step: 5
Training loss: 1.5126667022705078
Validation loss: 1.948245176704981

Epoch: 5| Step: 6
Training loss: 1.9471145868301392
Validation loss: 1.9319063245609243

Epoch: 5| Step: 7
Training loss: 2.1324892044067383
Validation loss: 1.9763109953172746

Epoch: 5| Step: 8
Training loss: 1.7622795104980469
Validation loss: 1.933940932314883

Epoch: 5| Step: 9
Training loss: 1.3087340593338013
Validation loss: 1.942563308182583

Epoch: 5| Step: 10
Training loss: 2.5320026874542236
Validation loss: 1.9292032872476885

Epoch: 226| Step: 0
Training loss: 2.3463480472564697
Validation loss: 1.9533258971347605

Epoch: 5| Step: 1
Training loss: 2.525330066680908
Validation loss: 1.9278844966683337

Epoch: 5| Step: 2
Training loss: 1.050933837890625
Validation loss: 1.9490342473471036

Epoch: 5| Step: 3
Training loss: 1.4514808654785156
Validation loss: 1.946282796962287

Epoch: 5| Step: 4
Training loss: 2.1186928749084473
Validation loss: 1.9636778408481228

Epoch: 5| Step: 5
Training loss: 2.1127326488494873
Validation loss: 1.9478090258054837

Epoch: 5| Step: 6
Training loss: 2.6964850425720215
Validation loss: 1.9576652742201281

Epoch: 5| Step: 7
Training loss: 1.446650505065918
Validation loss: 1.9389000759329846

Epoch: 5| Step: 8
Training loss: 1.4349945783615112
Validation loss: 1.9195408974924395

Epoch: 5| Step: 9
Training loss: 1.8761355876922607
Validation loss: 1.9450949045919603

Epoch: 5| Step: 10
Training loss: 1.3276104927062988
Validation loss: 1.9264917501839258

Epoch: 227| Step: 0
Training loss: 1.8254649639129639
Validation loss: 1.934594464558427

Epoch: 5| Step: 1
Training loss: 1.7077891826629639
Validation loss: 1.9596694182324153

Epoch: 5| Step: 2
Training loss: 1.6436595916748047
Validation loss: 1.9407072028806132

Epoch: 5| Step: 3
Training loss: 1.642102599143982
Validation loss: 1.9821395015203824

Epoch: 5| Step: 4
Training loss: 2.18557071685791
Validation loss: 1.9412677262419014

Epoch: 5| Step: 5
Training loss: 1.8460109233856201
Validation loss: 1.9636689488605787

Epoch: 5| Step: 6
Training loss: 1.9199199676513672
Validation loss: 1.9721870268544843

Epoch: 5| Step: 7
Training loss: 1.5387914180755615
Validation loss: 1.942586455293881

Epoch: 5| Step: 8
Training loss: 1.8830257654190063
Validation loss: 1.958690885574587

Epoch: 5| Step: 9
Training loss: 2.140385866165161
Validation loss: 1.9773106959558302

Epoch: 5| Step: 10
Training loss: 2.437999725341797
Validation loss: 1.9527397835126488

Epoch: 228| Step: 0
Training loss: 1.594181776046753
Validation loss: 1.9436783662406347

Epoch: 5| Step: 1
Training loss: 1.8595050573349
Validation loss: 1.9709778242213751

Epoch: 5| Step: 2
Training loss: 1.8221635818481445
Validation loss: 1.9664877025029992

Epoch: 5| Step: 3
Training loss: 2.6003363132476807
Validation loss: 1.9514496044446064

Epoch: 5| Step: 4
Training loss: 1.8266302347183228
Validation loss: 1.9522320173119987

Epoch: 5| Step: 5
Training loss: 1.6659181118011475
Validation loss: 1.9391751597004552

Epoch: 5| Step: 6
Training loss: 1.5534062385559082
Validation loss: 1.953293244043986

Epoch: 5| Step: 7
Training loss: 2.0277390480041504
Validation loss: 1.944945543043075

Epoch: 5| Step: 8
Training loss: 1.8762404918670654
Validation loss: 1.9320255441050376

Epoch: 5| Step: 9
Training loss: 1.8072885274887085
Validation loss: 1.9350578528578564

Epoch: 5| Step: 10
Training loss: 1.8782148361206055
Validation loss: 1.9349824100412347

Epoch: 229| Step: 0
Training loss: 2.1539835929870605
Validation loss: 1.9634585354917793

Epoch: 5| Step: 1
Training loss: 1.6828737258911133
Validation loss: 1.9355372523748746

Epoch: 5| Step: 2
Training loss: 1.6635663509368896
Validation loss: 1.9141893130476757

Epoch: 5| Step: 3
Training loss: 1.882253646850586
Validation loss: 1.9289325821784236

Epoch: 5| Step: 4
Training loss: 1.7705796957015991
Validation loss: 1.9560754760619132

Epoch: 5| Step: 5
Training loss: 1.5434236526489258
Validation loss: 1.915716040518976

Epoch: 5| Step: 6
Training loss: 2.1956729888916016
Validation loss: 1.9201368952310214

Epoch: 5| Step: 7
Training loss: 2.2244739532470703
Validation loss: 1.9403665296493038

Epoch: 5| Step: 8
Training loss: 2.3398635387420654
Validation loss: 1.9568212352773195

Epoch: 5| Step: 9
Training loss: 1.5527008771896362
Validation loss: 1.9723750980951453

Epoch: 5| Step: 10
Training loss: 1.5286706686019897
Validation loss: 1.948333041642302

Epoch: 230| Step: 0
Training loss: 1.4110438823699951
Validation loss: 1.9451463607049757

Epoch: 5| Step: 1
Training loss: 1.1460468769073486
Validation loss: 1.9626960472394062

Epoch: 5| Step: 2
Training loss: 1.7384884357452393
Validation loss: 1.946653683980306

Epoch: 5| Step: 3
Training loss: 2.320645809173584
Validation loss: 1.9551006594011862

Epoch: 5| Step: 4
Training loss: 2.8286099433898926
Validation loss: 1.9355284860057216

Epoch: 5| Step: 5
Training loss: 2.438697099685669
Validation loss: 1.9482035970175138

Epoch: 5| Step: 6
Training loss: 1.5288469791412354
Validation loss: 1.917915141710671

Epoch: 5| Step: 7
Training loss: 2.3035831451416016
Validation loss: 1.9276075414431992

Epoch: 5| Step: 8
Training loss: 1.5445477962493896
Validation loss: 1.9235212649068525

Epoch: 5| Step: 9
Training loss: 1.6534159183502197
Validation loss: 1.9129959947319441

Epoch: 5| Step: 10
Training loss: 1.4897323846817017
Validation loss: 1.9317950407663982

Epoch: 231| Step: 0
Training loss: 1.7423734664916992
Validation loss: 1.9399560318198255

Epoch: 5| Step: 1
Training loss: 1.7959572076797485
Validation loss: 1.9455208316926034

Epoch: 5| Step: 2
Training loss: 2.063103675842285
Validation loss: 1.9369645682714318

Epoch: 5| Step: 3
Training loss: 2.2180333137512207
Validation loss: 1.950341099052019

Epoch: 5| Step: 4
Training loss: 1.968385100364685
Validation loss: 1.9386155887316632

Epoch: 5| Step: 5
Training loss: 1.7429418563842773
Validation loss: 1.9596286371190061

Epoch: 5| Step: 6
Training loss: 1.7733612060546875
Validation loss: 1.948530061270601

Epoch: 5| Step: 7
Training loss: 1.6482446193695068
Validation loss: 1.9443459549257833

Epoch: 5| Step: 8
Training loss: 2.0162389278411865
Validation loss: 1.9392808175856067

Epoch: 5| Step: 9
Training loss: 1.739911675453186
Validation loss: 1.9441016451005013

Epoch: 5| Step: 10
Training loss: 1.718042016029358
Validation loss: 1.9576705783926032

Epoch: 232| Step: 0
Training loss: 1.913891077041626
Validation loss: 1.9535950531241715

Epoch: 5| Step: 1
Training loss: 2.0555126667022705
Validation loss: 1.9333329187926425

Epoch: 5| Step: 2
Training loss: 2.260063409805298
Validation loss: 1.9375274053183935

Epoch: 5| Step: 3
Training loss: 1.4442074298858643
Validation loss: 1.9217697048699984

Epoch: 5| Step: 4
Training loss: 1.837113618850708
Validation loss: 1.951550281176003

Epoch: 5| Step: 5
Training loss: 2.0303874015808105
Validation loss: 1.930593825155689

Epoch: 5| Step: 6
Training loss: 1.603340744972229
Validation loss: 1.9367873104669715

Epoch: 5| Step: 7
Training loss: 1.949681282043457
Validation loss: 1.915417919876755

Epoch: 5| Step: 8
Training loss: 2.011357545852661
Validation loss: 1.9280302742476105

Epoch: 5| Step: 9
Training loss: 1.7434508800506592
Validation loss: 1.9202703570806852

Epoch: 5| Step: 10
Training loss: 1.6586979627609253
Validation loss: 1.9383015812084239

Epoch: 233| Step: 0
Training loss: 2.2348437309265137
Validation loss: 1.92240612224866

Epoch: 5| Step: 1
Training loss: 1.7855116128921509
Validation loss: 1.9376118388227237

Epoch: 5| Step: 2
Training loss: 2.0958964824676514
Validation loss: 1.9321467132978543

Epoch: 5| Step: 3
Training loss: 1.95267653465271
Validation loss: 1.9148810896822201

Epoch: 5| Step: 4
Training loss: 1.4565038681030273
Validation loss: 1.9464645629288049

Epoch: 5| Step: 5
Training loss: 1.612583875656128
Validation loss: 1.9393306906505297

Epoch: 5| Step: 6
Training loss: 2.104381799697876
Validation loss: 1.935293593714314

Epoch: 5| Step: 7
Training loss: 1.6047672033309937
Validation loss: 1.9438095554228751

Epoch: 5| Step: 8
Training loss: 2.123385190963745
Validation loss: 1.9471485230230516

Epoch: 5| Step: 9
Training loss: 1.983001947402954
Validation loss: 1.9668320007221674

Epoch: 5| Step: 10
Training loss: 1.5376530885696411
Validation loss: 1.965476728254749

Epoch: 234| Step: 0
Training loss: 2.046947717666626
Validation loss: 1.9240622943447483

Epoch: 5| Step: 1
Training loss: 1.7104657888412476
Validation loss: 1.9678481137880715

Epoch: 5| Step: 2
Training loss: 1.7781355381011963
Validation loss: 1.9338462980844642

Epoch: 5| Step: 3
Training loss: 1.6406002044677734
Validation loss: 1.9331530858111639

Epoch: 5| Step: 4
Training loss: 1.707313895225525
Validation loss: 1.9321649125827256

Epoch: 5| Step: 5
Training loss: 1.861969232559204
Validation loss: 1.9505584573233

Epoch: 5| Step: 6
Training loss: 2.1855788230895996
Validation loss: 1.9440455616161387

Epoch: 5| Step: 7
Training loss: 2.274315357208252
Validation loss: 1.9604439043229627

Epoch: 5| Step: 8
Training loss: 1.6210397481918335
Validation loss: 1.9056460242117605

Epoch: 5| Step: 9
Training loss: 1.7206923961639404
Validation loss: 1.948224429161318

Epoch: 5| Step: 10
Training loss: 1.808580756187439
Validation loss: 1.9501159575677687

Epoch: 235| Step: 0
Training loss: 2.277627468109131
Validation loss: 1.9596622515750188

Epoch: 5| Step: 1
Training loss: 1.814781904220581
Validation loss: 1.9270413806361537

Epoch: 5| Step: 2
Training loss: 2.02134108543396
Validation loss: 1.9465311445215696

Epoch: 5| Step: 3
Training loss: 1.968021035194397
Validation loss: 1.940445606426526

Epoch: 5| Step: 4
Training loss: 2.0171236991882324
Validation loss: 1.964498378897226

Epoch: 5| Step: 5
Training loss: 1.5826506614685059
Validation loss: 1.9279594472659531

Epoch: 5| Step: 6
Training loss: 2.1321964263916016
Validation loss: 1.934787029861122

Epoch: 5| Step: 7
Training loss: 1.899675965309143
Validation loss: 1.9428192338635843

Epoch: 5| Step: 8
Training loss: 1.5758118629455566
Validation loss: 1.9461928362487464

Epoch: 5| Step: 9
Training loss: 1.2150789499282837
Validation loss: 1.9447064297173613

Epoch: 5| Step: 10
Training loss: 1.8464131355285645
Validation loss: 1.9200539435109785

Epoch: 236| Step: 0
Training loss: 1.4566243886947632
Validation loss: 1.9319900133276497

Epoch: 5| Step: 1
Training loss: 2.476217746734619
Validation loss: 1.9345500084661669

Epoch: 5| Step: 2
Training loss: 2.041886806488037
Validation loss: 1.9195985755612772

Epoch: 5| Step: 3
Training loss: 1.6047970056533813
Validation loss: 1.9360820606190672

Epoch: 5| Step: 4
Training loss: 2.0884082317352295
Validation loss: 1.9445520806056198

Epoch: 5| Step: 5
Training loss: 1.3522056341171265
Validation loss: 1.9255466025362733

Epoch: 5| Step: 6
Training loss: 1.909589409828186
Validation loss: 1.9315969110817037

Epoch: 5| Step: 7
Training loss: 1.9950313568115234
Validation loss: 1.902978777885437

Epoch: 5| Step: 8
Training loss: 1.7449073791503906
Validation loss: 1.9250279690629692

Epoch: 5| Step: 9
Training loss: 2.03136944770813
Validation loss: 1.9287020493579168

Epoch: 5| Step: 10
Training loss: 1.5477004051208496
Validation loss: 1.9265435049610753

Epoch: 237| Step: 0
Training loss: 1.8601741790771484
Validation loss: 1.9271677976013513

Epoch: 5| Step: 1
Training loss: 1.672519326210022
Validation loss: 1.9477499351706555

Epoch: 5| Step: 2
Training loss: 1.6398630142211914
Validation loss: 1.9342572304510302

Epoch: 5| Step: 3
Training loss: 1.629920244216919
Validation loss: 1.9471780753904773

Epoch: 5| Step: 4
Training loss: 1.4480211734771729
Validation loss: 1.9599914217507968

Epoch: 5| Step: 5
Training loss: 1.7795522212982178
Validation loss: 1.9216974871132964

Epoch: 5| Step: 6
Training loss: 2.5407373905181885
Validation loss: 1.9663951191850888

Epoch: 5| Step: 7
Training loss: 1.8646748065948486
Validation loss: 1.9532205648319696

Epoch: 5| Step: 8
Training loss: 1.8280956745147705
Validation loss: 1.951052632383121

Epoch: 5| Step: 9
Training loss: 1.883863091468811
Validation loss: 1.9571807730582453

Epoch: 5| Step: 10
Training loss: 2.3719944953918457
Validation loss: 1.9476636353359427

Epoch: 238| Step: 0
Training loss: 1.9241926670074463
Validation loss: 1.9534015924699846

Epoch: 5| Step: 1
Training loss: 1.6742976903915405
Validation loss: 1.9275742871786958

Epoch: 5| Step: 2
Training loss: 1.8477554321289062
Validation loss: 1.9426868192611202

Epoch: 5| Step: 3
Training loss: 2.1638453006744385
Validation loss: 1.9330212916097333

Epoch: 5| Step: 4
Training loss: 2.3060710430145264
Validation loss: 1.9288653058390464

Epoch: 5| Step: 5
Training loss: 1.886643648147583
Validation loss: 1.9125855045933877

Epoch: 5| Step: 6
Training loss: 2.0560638904571533
Validation loss: 1.9563338487379012

Epoch: 5| Step: 7
Training loss: 1.2077252864837646
Validation loss: 1.9627646784628592

Epoch: 5| Step: 8
Training loss: 1.8670775890350342
Validation loss: 1.9147625110482658

Epoch: 5| Step: 9
Training loss: 1.4953304529190063
Validation loss: 1.9281224409739177

Epoch: 5| Step: 10
Training loss: 1.7385978698730469
Validation loss: 1.9131884151889431

Epoch: 239| Step: 0
Training loss: 1.1852219104766846
Validation loss: 1.952487704574421

Epoch: 5| Step: 1
Training loss: 1.9747921228408813
Validation loss: 1.9482805908367198

Epoch: 5| Step: 2
Training loss: 2.2155871391296387
Validation loss: 1.923876944408622

Epoch: 5| Step: 3
Training loss: 2.397319793701172
Validation loss: 1.9406411340159755

Epoch: 5| Step: 4
Training loss: 2.1339991092681885
Validation loss: 1.931718054638114

Epoch: 5| Step: 5
Training loss: 2.024521589279175
Validation loss: 1.915162512051162

Epoch: 5| Step: 6
Training loss: 1.8956348896026611
Validation loss: 1.9423188663298083

Epoch: 5| Step: 7
Training loss: 1.6470587253570557
Validation loss: 1.9269998970852102

Epoch: 5| Step: 8
Training loss: 1.6755332946777344
Validation loss: 1.944968077444261

Epoch: 5| Step: 9
Training loss: 2.0667927265167236
Validation loss: 1.9410807778758388

Epoch: 5| Step: 10
Training loss: 1.1146252155303955
Validation loss: 1.9412062757758684

Epoch: 240| Step: 0
Training loss: 1.8244578838348389
Validation loss: 1.9246379085766372

Epoch: 5| Step: 1
Training loss: 1.6586374044418335
Validation loss: 1.928941601066179

Epoch: 5| Step: 2
Training loss: 2.5872037410736084
Validation loss: 1.9203682894347816

Epoch: 5| Step: 3
Training loss: 1.4076333045959473
Validation loss: 1.9190559899935158

Epoch: 5| Step: 4
Training loss: 1.6400359869003296
Validation loss: 1.9356103968876663

Epoch: 5| Step: 5
Training loss: 1.7182519435882568
Validation loss: 1.9541191054928688

Epoch: 5| Step: 6
Training loss: 2.435800075531006
Validation loss: 1.9248104364641252

Epoch: 5| Step: 7
Training loss: 1.975325345993042
Validation loss: 1.9549288416421542

Epoch: 5| Step: 8
Training loss: 1.5114034414291382
Validation loss: 1.9505764028077484

Epoch: 5| Step: 9
Training loss: 2.0298099517822266
Validation loss: 1.9490329603995047

Epoch: 5| Step: 10
Training loss: 1.260119080543518
Validation loss: 1.92908525723283

Epoch: 241| Step: 0
Training loss: 1.777561902999878
Validation loss: 1.9507136729455763

Epoch: 5| Step: 1
Training loss: 2.0192205905914307
Validation loss: 1.9325259911116732

Epoch: 5| Step: 2
Training loss: 1.8257200717926025
Validation loss: 1.9256508799009426

Epoch: 5| Step: 3
Training loss: 1.7249752283096313
Validation loss: 1.9225534316032165

Epoch: 5| Step: 4
Training loss: 2.0142195224761963
Validation loss: 1.939310868581136

Epoch: 5| Step: 5
Training loss: 1.8634033203125
Validation loss: 1.9463354708046041

Epoch: 5| Step: 6
Training loss: 1.4084564447402954
Validation loss: 1.951917270178436

Epoch: 5| Step: 7
Training loss: 1.7028871774673462
Validation loss: 1.9159278626083045

Epoch: 5| Step: 8
Training loss: 1.3877617120742798
Validation loss: 1.933059584709906

Epoch: 5| Step: 9
Training loss: 1.9145805835723877
Validation loss: 1.9426323008793656

Epoch: 5| Step: 10
Training loss: 2.4618520736694336
Validation loss: 1.9610033291642384

Epoch: 242| Step: 0
Training loss: 1.7684223651885986
Validation loss: 1.9071725414645286

Epoch: 5| Step: 1
Training loss: 1.88018798828125
Validation loss: 1.9270399411519368

Epoch: 5| Step: 2
Training loss: 2.5707545280456543
Validation loss: 1.9286264091409662

Epoch: 5| Step: 3
Training loss: 1.835179328918457
Validation loss: 1.9304975642952868

Epoch: 5| Step: 4
Training loss: 1.8477833271026611
Validation loss: 1.9164890640525407

Epoch: 5| Step: 5
Training loss: 1.689314603805542
Validation loss: 1.9232899681214364

Epoch: 5| Step: 6
Training loss: 1.8702961206436157
Validation loss: 1.8988981593039729

Epoch: 5| Step: 7
Training loss: 1.6218382120132446
Validation loss: 1.9308664439826884

Epoch: 5| Step: 8
Training loss: 1.9968469142913818
Validation loss: 1.9339753479085944

Epoch: 5| Step: 9
Training loss: 1.7255241870880127
Validation loss: 1.9114701786348898

Epoch: 5| Step: 10
Training loss: 1.3181027173995972
Validation loss: 1.9153138642670007

Epoch: 243| Step: 0
Training loss: 1.3316428661346436
Validation loss: 1.9537950202982912

Epoch: 5| Step: 1
Training loss: 1.3796716928482056
Validation loss: 1.93233311048118

Epoch: 5| Step: 2
Training loss: 1.572270154953003
Validation loss: 1.9373874151578514

Epoch: 5| Step: 3
Training loss: 1.8625456094741821
Validation loss: 1.944724767438827

Epoch: 5| Step: 4
Training loss: 1.978390097618103
Validation loss: 1.9428872805769726

Epoch: 5| Step: 5
Training loss: 2.4411585330963135
Validation loss: 1.9461110817488803

Epoch: 5| Step: 6
Training loss: 2.2372148036956787
Validation loss: 1.9208776450926257

Epoch: 5| Step: 7
Training loss: 1.9082835912704468
Validation loss: 1.9535938539812643

Epoch: 5| Step: 8
Training loss: 1.6283252239227295
Validation loss: 1.9092884191902735

Epoch: 5| Step: 9
Training loss: 1.8300062417984009
Validation loss: 1.921660300224058

Epoch: 5| Step: 10
Training loss: 2.013552188873291
Validation loss: 1.917411377353053

Epoch: 244| Step: 0
Training loss: 1.4583104848861694
Validation loss: 1.933323279503853

Epoch: 5| Step: 1
Training loss: 2.0970098972320557
Validation loss: 1.914160838691137

Epoch: 5| Step: 2
Training loss: 1.5538403987884521
Validation loss: 1.9002460074681107

Epoch: 5| Step: 3
Training loss: 1.4729468822479248
Validation loss: 1.9377833809903873

Epoch: 5| Step: 4
Training loss: 1.3862476348876953
Validation loss: 1.919430640435988

Epoch: 5| Step: 5
Training loss: 1.9166622161865234
Validation loss: 1.9202850018778155

Epoch: 5| Step: 6
Training loss: 1.2514288425445557
Validation loss: 1.9356130861466931

Epoch: 5| Step: 7
Training loss: 1.9589780569076538
Validation loss: 1.9229047042067333

Epoch: 5| Step: 8
Training loss: 2.0972506999969482
Validation loss: 1.9418247694610267

Epoch: 5| Step: 9
Training loss: 2.763378381729126
Validation loss: 1.9448475812071113

Epoch: 5| Step: 10
Training loss: 2.195363998413086
Validation loss: 1.9530438300101989

Epoch: 245| Step: 0
Training loss: 1.8086382150650024
Validation loss: 1.93372481612749

Epoch: 5| Step: 1
Training loss: 1.7395248413085938
Validation loss: 1.9436175695029638

Epoch: 5| Step: 2
Training loss: 1.2670862674713135
Validation loss: 1.9541175929448937

Epoch: 5| Step: 3
Training loss: 2.1087276935577393
Validation loss: 1.957083253450291

Epoch: 5| Step: 4
Training loss: 1.3907887935638428
Validation loss: 1.9489924471865419

Epoch: 5| Step: 5
Training loss: 2.011643648147583
Validation loss: 1.9507649457582863

Epoch: 5| Step: 6
Training loss: 1.7076867818832397
Validation loss: 1.9469608132557203

Epoch: 5| Step: 7
Training loss: 1.9794480800628662
Validation loss: 1.9670720869495022

Epoch: 5| Step: 8
Training loss: 2.083831310272217
Validation loss: 1.9561659956491122

Epoch: 5| Step: 9
Training loss: 1.7998430728912354
Validation loss: 1.9318391020580004

Epoch: 5| Step: 10
Training loss: 2.324903726577759
Validation loss: 1.9385082234618485

Epoch: 246| Step: 0
Training loss: 1.8534252643585205
Validation loss: 1.9511339446549774

Epoch: 5| Step: 1
Training loss: 1.7160015106201172
Validation loss: 1.9353045930144608

Epoch: 5| Step: 2
Training loss: 1.5419702529907227
Validation loss: 1.9335022331565939

Epoch: 5| Step: 3
Training loss: 1.4017763137817383
Validation loss: 1.9351163884644866

Epoch: 5| Step: 4
Training loss: 1.6615524291992188
Validation loss: 1.951342922385021

Epoch: 5| Step: 5
Training loss: 2.1315810680389404
Validation loss: 1.9382700407376854

Epoch: 5| Step: 6
Training loss: 1.853264570236206
Validation loss: 1.942609328095631

Epoch: 5| Step: 7
Training loss: 2.237687587738037
Validation loss: 1.9252681104085778

Epoch: 5| Step: 8
Training loss: 1.9009555578231812
Validation loss: 1.9179410344810897

Epoch: 5| Step: 9
Training loss: 1.8982231616973877
Validation loss: 1.9304758887137137

Epoch: 5| Step: 10
Training loss: 1.9511860609054565
Validation loss: 1.9448360819970407

Epoch: 247| Step: 0
Training loss: 1.8596947193145752
Validation loss: 1.896552776777616

Epoch: 5| Step: 1
Training loss: 1.9892600774765015
Validation loss: 1.8830970064286263

Epoch: 5| Step: 2
Training loss: 2.385897159576416
Validation loss: 1.9261184905164985

Epoch: 5| Step: 3
Training loss: 1.431009292602539
Validation loss: 1.954303777346047

Epoch: 5| Step: 4
Training loss: 2.2922897338867188
Validation loss: 1.943205141252087

Epoch: 5| Step: 5
Training loss: 1.2954376935958862
Validation loss: 1.9618203460529287

Epoch: 5| Step: 6
Training loss: 2.0494022369384766
Validation loss: 1.975150103210121

Epoch: 5| Step: 7
Training loss: 1.6970226764678955
Validation loss: 1.9432279794446883

Epoch: 5| Step: 8
Training loss: 2.0335114002227783
Validation loss: 1.9658473742905485

Epoch: 5| Step: 9
Training loss: 1.5447957515716553
Validation loss: 1.9657600874541907

Epoch: 5| Step: 10
Training loss: 1.4086239337921143
Validation loss: 1.9524807955629082

Epoch: 248| Step: 0
Training loss: 1.4660311937332153
Validation loss: 1.9201920788775209

Epoch: 5| Step: 1
Training loss: 1.349367618560791
Validation loss: 1.9235521055036975

Epoch: 5| Step: 2
Training loss: 1.5127636194229126
Validation loss: 1.9481577745047949

Epoch: 5| Step: 3
Training loss: 1.9588396549224854
Validation loss: 1.9313993453979492

Epoch: 5| Step: 4
Training loss: 2.22322416305542
Validation loss: 1.9090141352786814

Epoch: 5| Step: 5
Training loss: 1.8644710779190063
Validation loss: 1.9025373228134648

Epoch: 5| Step: 6
Training loss: 1.7539695501327515
Validation loss: 1.915549805087428

Epoch: 5| Step: 7
Training loss: 1.9707443714141846
Validation loss: 1.9183487687059628

Epoch: 5| Step: 8
Training loss: 1.7739980220794678
Validation loss: 1.9520580473766531

Epoch: 5| Step: 9
Training loss: 1.7492564916610718
Validation loss: 1.9316137067733272

Epoch: 5| Step: 10
Training loss: 2.264622449874878
Validation loss: 1.930886145560972

Epoch: 249| Step: 0
Training loss: 1.716819405555725
Validation loss: 1.9222356529646023

Epoch: 5| Step: 1
Training loss: 1.2720444202423096
Validation loss: 1.9177499099444317

Epoch: 5| Step: 2
Training loss: 1.7195396423339844
Validation loss: 1.933856145028145

Epoch: 5| Step: 3
Training loss: 1.5518221855163574
Validation loss: 1.9092826612534062

Epoch: 5| Step: 4
Training loss: 2.0823874473571777
Validation loss: 1.9056091693139845

Epoch: 5| Step: 5
Training loss: 2.6649646759033203
Validation loss: 1.9179462027806107

Epoch: 5| Step: 6
Training loss: 1.3920223712921143
Validation loss: 1.9359680106562953

Epoch: 5| Step: 7
Training loss: 2.0413451194763184
Validation loss: 1.9206953458888556

Epoch: 5| Step: 8
Training loss: 1.6794769763946533
Validation loss: 1.9488304353529406

Epoch: 5| Step: 9
Training loss: 1.4076814651489258
Validation loss: 1.9446297948078444

Epoch: 5| Step: 10
Training loss: 2.633488655090332
Validation loss: 1.9447640885588944

Epoch: 250| Step: 0
Training loss: 1.6483869552612305
Validation loss: 1.9532733501926545

Epoch: 5| Step: 1
Training loss: 1.6370137929916382
Validation loss: 1.9517199454769012

Epoch: 5| Step: 2
Training loss: 1.5348600149154663
Validation loss: 1.9181301773235362

Epoch: 5| Step: 3
Training loss: 1.8468217849731445
Validation loss: 1.9307583570480347

Epoch: 5| Step: 4
Training loss: 1.8346866369247437
Validation loss: 1.9577599340869534

Epoch: 5| Step: 5
Training loss: 1.854058861732483
Validation loss: 1.9026491693271104

Epoch: 5| Step: 6
Training loss: 1.8300292491912842
Validation loss: 1.9076655244314542

Epoch: 5| Step: 7
Training loss: 2.0723302364349365
Validation loss: 1.9232218124533211

Epoch: 5| Step: 8
Training loss: 2.1492881774902344
Validation loss: 1.921240988598075

Epoch: 5| Step: 9
Training loss: 1.4522085189819336
Validation loss: 1.915883320634083

Epoch: 5| Step: 10
Training loss: 2.0755062103271484
Validation loss: 1.9486112799695743

Epoch: 251| Step: 0
Training loss: 1.5765209197998047
Validation loss: 1.9237933530602405

Epoch: 5| Step: 1
Training loss: 2.255093574523926
Validation loss: 1.9360040541618102

Epoch: 5| Step: 2
Training loss: 2.2068169116973877
Validation loss: 1.9307162684779013

Epoch: 5| Step: 3
Training loss: 1.550225019454956
Validation loss: 1.9258258112015263

Epoch: 5| Step: 4
Training loss: 2.0745151042938232
Validation loss: 1.9423653643618348

Epoch: 5| Step: 5
Training loss: 1.6351871490478516
Validation loss: 1.9275527051700059

Epoch: 5| Step: 6
Training loss: 1.6012636423110962
Validation loss: 1.9768723108435189

Epoch: 5| Step: 7
Training loss: 2.1758878231048584
Validation loss: 1.9279302089445052

Epoch: 5| Step: 8
Training loss: 1.4278937578201294
Validation loss: 1.9338402068743141

Epoch: 5| Step: 9
Training loss: 1.8200737237930298
Validation loss: 1.9496911174507552

Epoch: 5| Step: 10
Training loss: 1.4696530103683472
Validation loss: 1.9158997856160647

Epoch: 252| Step: 0
Training loss: 1.5052809715270996
Validation loss: 1.9448162253184984

Epoch: 5| Step: 1
Training loss: 2.0957984924316406
Validation loss: 1.9378984166729836

Epoch: 5| Step: 2
Training loss: 1.9261630773544312
Validation loss: 1.9198488112418883

Epoch: 5| Step: 3
Training loss: 2.1092605590820312
Validation loss: 1.9163302221605856

Epoch: 5| Step: 4
Training loss: 1.516228199005127
Validation loss: 1.9177839448375087

Epoch: 5| Step: 5
Training loss: 1.507729411125183
Validation loss: 1.9406527857626639

Epoch: 5| Step: 6
Training loss: 2.1715292930603027
Validation loss: 1.9331936682424238

Epoch: 5| Step: 7
Training loss: 1.6244041919708252
Validation loss: 1.9152887264887493

Epoch: 5| Step: 8
Training loss: 2.1377508640289307
Validation loss: 1.9236233657406223

Epoch: 5| Step: 9
Training loss: 1.6690925359725952
Validation loss: 1.946964785616885

Epoch: 5| Step: 10
Training loss: 1.8920633792877197
Validation loss: 1.941050814044091

Epoch: 253| Step: 0
Training loss: 2.3601956367492676
Validation loss: 1.969859428303216

Epoch: 5| Step: 1
Training loss: 1.6352999210357666
Validation loss: 1.9463272261363205

Epoch: 5| Step: 2
Training loss: 1.714010238647461
Validation loss: 1.9188913863192323

Epoch: 5| Step: 3
Training loss: 1.5736018419265747
Validation loss: 1.9368245255562566

Epoch: 5| Step: 4
Training loss: 1.92336905002594
Validation loss: 1.9569526333962717

Epoch: 5| Step: 5
Training loss: 1.492763876914978
Validation loss: 1.9623824216986214

Epoch: 5| Step: 6
Training loss: 2.5492143630981445
Validation loss: 1.9332079733571699

Epoch: 5| Step: 7
Training loss: 1.7134754657745361
Validation loss: 1.9467706218842538

Epoch: 5| Step: 8
Training loss: 1.544541835784912
Validation loss: 1.9384538319803053

Epoch: 5| Step: 9
Training loss: 1.4837409257888794
Validation loss: 1.9499898905395179

Epoch: 5| Step: 10
Training loss: 1.7188944816589355
Validation loss: 1.9560945585209837

Epoch: 254| Step: 0
Training loss: 1.5720564126968384
Validation loss: 1.938615499004241

Epoch: 5| Step: 1
Training loss: 1.5402748584747314
Validation loss: 1.9265932985531387

Epoch: 5| Step: 2
Training loss: 2.1811366081237793
Validation loss: 1.9376965543275237

Epoch: 5| Step: 3
Training loss: 2.3184924125671387
Validation loss: 1.8996824038925992

Epoch: 5| Step: 4
Training loss: 1.8793226480484009
Validation loss: 1.9102147830429899

Epoch: 5| Step: 5
Training loss: 1.4862775802612305
Validation loss: 1.931252851281115

Epoch: 5| Step: 6
Training loss: 2.217348098754883
Validation loss: 1.891201978088707

Epoch: 5| Step: 7
Training loss: 1.4383281469345093
Validation loss: 1.8997220159858785

Epoch: 5| Step: 8
Training loss: 2.117455005645752
Validation loss: 1.9215686795532063

Epoch: 5| Step: 9
Training loss: 1.6411447525024414
Validation loss: 1.9144528578686457

Epoch: 5| Step: 10
Training loss: 1.0436334609985352
Validation loss: 1.9155473580924414

Epoch: 255| Step: 0
Training loss: 1.918871283531189
Validation loss: 1.8811974397269629

Epoch: 5| Step: 1
Training loss: 1.843450903892517
Validation loss: 1.930858076259654

Epoch: 5| Step: 2
Training loss: 1.6842269897460938
Validation loss: 1.9356601571524015

Epoch: 5| Step: 3
Training loss: 1.2968876361846924
Validation loss: 1.9515349121503933

Epoch: 5| Step: 4
Training loss: 1.2256888151168823
Validation loss: 1.903861705974866

Epoch: 5| Step: 5
Training loss: 2.1622211933135986
Validation loss: 1.9184851954060216

Epoch: 5| Step: 6
Training loss: 1.592329978942871
Validation loss: 1.9101485847144999

Epoch: 5| Step: 7
Training loss: 2.2758309841156006
Validation loss: 1.899731916766013

Epoch: 5| Step: 8
Training loss: 2.004030466079712
Validation loss: 1.951599972222441

Epoch: 5| Step: 9
Training loss: 1.6357581615447998
Validation loss: 1.9416155276759979

Epoch: 5| Step: 10
Training loss: 1.7726517915725708
Validation loss: 1.9298634862387052

Epoch: 256| Step: 0
Training loss: 1.2825260162353516
Validation loss: 1.9457347149490027

Epoch: 5| Step: 1
Training loss: 1.6526613235473633
Validation loss: 1.9159324899796517

Epoch: 5| Step: 2
Training loss: 1.6194289922714233
Validation loss: 1.9508173363183134

Epoch: 5| Step: 3
Training loss: 1.8711235523223877
Validation loss: 1.9431060667960875

Epoch: 5| Step: 4
Training loss: 1.4583791494369507
Validation loss: 1.9087273343916862

Epoch: 5| Step: 5
Training loss: 2.5599818229675293
Validation loss: 1.9403002800480011

Epoch: 5| Step: 6
Training loss: 2.356632709503174
Validation loss: 1.938714292741591

Epoch: 5| Step: 7
Training loss: 1.2970411777496338
Validation loss: 1.9322885902979041

Epoch: 5| Step: 8
Training loss: 1.5725330114364624
Validation loss: 1.9267171582868021

Epoch: 5| Step: 9
Training loss: 2.0336854457855225
Validation loss: 1.937751623892015

Epoch: 5| Step: 10
Training loss: 2.1852684020996094
Validation loss: 1.9154844399421447

Epoch: 257| Step: 0
Training loss: 2.1355767250061035
Validation loss: 1.932782878157913

Epoch: 5| Step: 1
Training loss: 2.0417606830596924
Validation loss: 1.9309144250808223

Epoch: 5| Step: 2
Training loss: 1.3215922117233276
Validation loss: 1.916554299733972

Epoch: 5| Step: 3
Training loss: 1.8604822158813477
Validation loss: 1.9051799697260703

Epoch: 5| Step: 4
Training loss: 1.3570327758789062
Validation loss: 1.8926173769017702

Epoch: 5| Step: 5
Training loss: 2.362698793411255
Validation loss: 1.9094655667581866

Epoch: 5| Step: 6
Training loss: 1.7316986322402954
Validation loss: 1.8866278356121433

Epoch: 5| Step: 7
Training loss: 1.5389394760131836
Validation loss: 1.9240854555560696

Epoch: 5| Step: 8
Training loss: 1.7120414972305298
Validation loss: 1.930533835964818

Epoch: 5| Step: 9
Training loss: 1.954441785812378
Validation loss: 1.9059908954046105

Epoch: 5| Step: 10
Training loss: 1.6247797012329102
Validation loss: 1.9250863905875915

Epoch: 258| Step: 0
Training loss: 1.5034409761428833
Validation loss: 1.9198769689888082

Epoch: 5| Step: 1
Training loss: 1.7485859394073486
Validation loss: 1.8925511093549832

Epoch: 5| Step: 2
Training loss: 1.802984595298767
Validation loss: 1.9359571139017742

Epoch: 5| Step: 3
Training loss: 1.6527535915374756
Validation loss: 1.9013865288867746

Epoch: 5| Step: 4
Training loss: 1.9991436004638672
Validation loss: 1.9428708245677333

Epoch: 5| Step: 5
Training loss: 1.7933976650238037
Validation loss: 1.9255373208753523

Epoch: 5| Step: 6
Training loss: 1.9576959609985352
Validation loss: 1.9485768169485114

Epoch: 5| Step: 7
Training loss: 1.2878749370574951
Validation loss: 1.9376216319299513

Epoch: 5| Step: 8
Training loss: 1.8959461450576782
Validation loss: 1.941452177621985

Epoch: 5| Step: 9
Training loss: 2.0598559379577637
Validation loss: 1.9261289437611897

Epoch: 5| Step: 10
Training loss: 1.981632947921753
Validation loss: 1.918312503445533

Epoch: 259| Step: 0
Training loss: 2.0621376037597656
Validation loss: 1.908822528777584

Epoch: 5| Step: 1
Training loss: 1.8514970541000366
Validation loss: 1.9268506380819506

Epoch: 5| Step: 2
Training loss: 2.0723986625671387
Validation loss: 1.9266095302438224

Epoch: 5| Step: 3
Training loss: 2.290083885192871
Validation loss: 1.9331908123467558

Epoch: 5| Step: 4
Training loss: 1.3348543643951416
Validation loss: 1.9362673938915294

Epoch: 5| Step: 5
Training loss: 1.9332940578460693
Validation loss: 1.9338510062104912

Epoch: 5| Step: 6
Training loss: 1.5432077646255493
Validation loss: 1.9139707767835228

Epoch: 5| Step: 7
Training loss: 1.6157726049423218
Validation loss: 1.9059772696546329

Epoch: 5| Step: 8
Training loss: 1.8237502574920654
Validation loss: 1.881174482325072

Epoch: 5| Step: 9
Training loss: 1.5912684202194214
Validation loss: 1.908376577079937

Epoch: 5| Step: 10
Training loss: 1.4052022695541382
Validation loss: 1.9223276415178854

Epoch: 260| Step: 0
Training loss: 1.8100744485855103
Validation loss: 1.9036074492239183

Epoch: 5| Step: 1
Training loss: 1.3979551792144775
Validation loss: 1.9256072121281778

Epoch: 5| Step: 2
Training loss: 1.430731177330017
Validation loss: 1.908894331224503

Epoch: 5| Step: 3
Training loss: 2.1800029277801514
Validation loss: 1.9254666400212113

Epoch: 5| Step: 4
Training loss: 1.3785213232040405
Validation loss: 1.8942495674215338

Epoch: 5| Step: 5
Training loss: 2.0936896800994873
Validation loss: 1.904445622556953

Epoch: 5| Step: 6
Training loss: 1.7517521381378174
Validation loss: 1.9358209333112162

Epoch: 5| Step: 7
Training loss: 1.6867074966430664
Validation loss: 1.943903353906447

Epoch: 5| Step: 8
Training loss: 2.015620231628418
Validation loss: 1.93103458932651

Epoch: 5| Step: 9
Training loss: 1.8167911767959595
Validation loss: 1.919618138702967

Epoch: 5| Step: 10
Training loss: 1.9537270069122314
Validation loss: 1.8998294350921467

Epoch: 261| Step: 0
Training loss: 1.983838438987732
Validation loss: 1.8995671092822988

Epoch: 5| Step: 1
Training loss: 1.7813879251480103
Validation loss: 1.9180486894422961

Epoch: 5| Step: 2
Training loss: 1.5000396966934204
Validation loss: 1.9382987791492092

Epoch: 5| Step: 3
Training loss: 1.920101523399353
Validation loss: 1.937701734163428

Epoch: 5| Step: 4
Training loss: 2.0159292221069336
Validation loss: 1.9444932809440039

Epoch: 5| Step: 5
Training loss: 1.6046111583709717
Validation loss: 1.9345077596684939

Epoch: 5| Step: 6
Training loss: 1.9122755527496338
Validation loss: 1.9045672019322712

Epoch: 5| Step: 7
Training loss: 1.7047011852264404
Validation loss: 1.9453294969374133

Epoch: 5| Step: 8
Training loss: 1.6326128244400024
Validation loss: 1.9086212573512908

Epoch: 5| Step: 9
Training loss: 1.9209963083267212
Validation loss: 1.9421394294308079

Epoch: 5| Step: 10
Training loss: 1.4920806884765625
Validation loss: 1.9091814282119914

Epoch: 262| Step: 0
Training loss: 1.7902320623397827
Validation loss: 1.9511863390604656

Epoch: 5| Step: 1
Training loss: 1.8365452289581299
Validation loss: 1.897331586448095

Epoch: 5| Step: 2
Training loss: 2.034144878387451
Validation loss: 1.8898374483149538

Epoch: 5| Step: 3
Training loss: 1.7301146984100342
Validation loss: 1.9129494287634408

Epoch: 5| Step: 4
Training loss: 0.9283028841018677
Validation loss: 1.9069828987121582

Epoch: 5| Step: 5
Training loss: 1.8550984859466553
Validation loss: 1.9108101885805848

Epoch: 5| Step: 6
Training loss: 1.4036763906478882
Validation loss: 1.9092862170229676

Epoch: 5| Step: 7
Training loss: 1.775313138961792
Validation loss: 1.9131950306636032

Epoch: 5| Step: 8
Training loss: 2.2347121238708496
Validation loss: 1.9232178362466956

Epoch: 5| Step: 9
Training loss: 1.9471410512924194
Validation loss: 1.9089304221573697

Epoch: 5| Step: 10
Training loss: 1.9017291069030762
Validation loss: 1.8784708053834978

Epoch: 263| Step: 0
Training loss: 1.3478238582611084
Validation loss: 1.9094282504050963

Epoch: 5| Step: 1
Training loss: 2.0794620513916016
Validation loss: 1.858612996275707

Epoch: 5| Step: 2
Training loss: 1.6740707159042358
Validation loss: 1.9068321758700955

Epoch: 5| Step: 3
Training loss: 1.5827440023422241
Validation loss: 1.9255709622495918

Epoch: 5| Step: 4
Training loss: 1.5819127559661865
Validation loss: 1.914142208714639

Epoch: 5| Step: 5
Training loss: 1.3890529870986938
Validation loss: 1.892958007833009

Epoch: 5| Step: 6
Training loss: 1.8136684894561768
Validation loss: 1.9291974985471336

Epoch: 5| Step: 7
Training loss: 1.9192440509796143
Validation loss: 1.9109628533804288

Epoch: 5| Step: 8
Training loss: 2.1848177909851074
Validation loss: 1.9301514625549316

Epoch: 5| Step: 9
Training loss: 1.834525465965271
Validation loss: 1.93309994154079

Epoch: 5| Step: 10
Training loss: 1.8835225105285645
Validation loss: 1.909829035882027

Epoch: 264| Step: 0
Training loss: 1.9921420812606812
Validation loss: 1.9330438221654584

Epoch: 5| Step: 1
Training loss: 1.3074884414672852
Validation loss: 1.913056662005763

Epoch: 5| Step: 2
Training loss: 1.9054269790649414
Validation loss: 1.869304048117771

Epoch: 5| Step: 3
Training loss: 1.6714770793914795
Validation loss: 1.926989778395622

Epoch: 5| Step: 4
Training loss: 1.8368972539901733
Validation loss: 1.893951592906829

Epoch: 5| Step: 5
Training loss: 2.144798755645752
Validation loss: 1.9259190444023377

Epoch: 5| Step: 6
Training loss: 1.9590556621551514
Validation loss: 1.9191102545748475

Epoch: 5| Step: 7
Training loss: 1.3055827617645264
Validation loss: 1.9079109263676468

Epoch: 5| Step: 8
Training loss: 1.8535149097442627
Validation loss: 1.900735887148047

Epoch: 5| Step: 9
Training loss: 1.8287391662597656
Validation loss: 1.9169298371961039

Epoch: 5| Step: 10
Training loss: 1.6724027395248413
Validation loss: 1.899205397534114

Epoch: 265| Step: 0
Training loss: 1.5903003215789795
Validation loss: 1.9133499809490737

Epoch: 5| Step: 1
Training loss: 2.2173588275909424
Validation loss: 1.9316677560088455

Epoch: 5| Step: 2
Training loss: 1.8346874713897705
Validation loss: 1.917609348092028

Epoch: 5| Step: 3
Training loss: 1.8430559635162354
Validation loss: 1.875964936389718

Epoch: 5| Step: 4
Training loss: 1.2715860605239868
Validation loss: 1.9024981990937264

Epoch: 5| Step: 5
Training loss: 2.1855788230895996
Validation loss: 1.9080847758118824

Epoch: 5| Step: 6
Training loss: 1.1947101354599
Validation loss: 1.9124912574727049

Epoch: 5| Step: 7
Training loss: 2.235259771347046
Validation loss: 1.9128840123453448

Epoch: 5| Step: 8
Training loss: 1.8345661163330078
Validation loss: 1.9112135120617446

Epoch: 5| Step: 9
Training loss: 1.353110909461975
Validation loss: 1.9155356114910496

Epoch: 5| Step: 10
Training loss: 1.9554524421691895
Validation loss: 1.9040774529980076

Epoch: 266| Step: 0
Training loss: 2.470227003097534
Validation loss: 1.8936701961742934

Epoch: 5| Step: 1
Training loss: 1.5042880773544312
Validation loss: 1.9251581161252913

Epoch: 5| Step: 2
Training loss: 2.6214652061462402
Validation loss: 1.9324547475384128

Epoch: 5| Step: 3
Training loss: 1.5527265071868896
Validation loss: 1.9219840905999626

Epoch: 5| Step: 4
Training loss: 1.4622834920883179
Validation loss: 1.9448387225468953

Epoch: 5| Step: 5
Training loss: 1.206286072731018
Validation loss: 1.9045772219216952

Epoch: 5| Step: 6
Training loss: 1.8623065948486328
Validation loss: 1.9136639038721721

Epoch: 5| Step: 7
Training loss: 1.8811674118041992
Validation loss: 1.9279076771069599

Epoch: 5| Step: 8
Training loss: 1.8159433603286743
Validation loss: 1.9209593726742653

Epoch: 5| Step: 9
Training loss: 1.3791306018829346
Validation loss: 1.918582793205015

Epoch: 5| Step: 10
Training loss: 1.6106503009796143
Validation loss: 1.9093268712361653

Epoch: 267| Step: 0
Training loss: 1.7236340045928955
Validation loss: 1.8993313722713019

Epoch: 5| Step: 1
Training loss: 1.939705491065979
Validation loss: 1.9289624921737178

Epoch: 5| Step: 2
Training loss: 1.3693740367889404
Validation loss: 1.9124306273716751

Epoch: 5| Step: 3
Training loss: 1.96670663356781
Validation loss: 1.9085920779935774

Epoch: 5| Step: 4
Training loss: 1.6040165424346924
Validation loss: 1.9186219246156755

Epoch: 5| Step: 5
Training loss: 1.5711696147918701
Validation loss: 1.933209168013706

Epoch: 5| Step: 6
Training loss: 1.9249203205108643
Validation loss: 1.9137079497819305

Epoch: 5| Step: 7
Training loss: 1.2018091678619385
Validation loss: 1.9244258224323232

Epoch: 5| Step: 8
Training loss: 1.8702224493026733
Validation loss: 1.9161229543788458

Epoch: 5| Step: 9
Training loss: 1.631710410118103
Validation loss: 1.929330736078242

Epoch: 5| Step: 10
Training loss: 2.604419231414795
Validation loss: 1.925997700742496

Epoch: 268| Step: 0
Training loss: 1.2206451892852783
Validation loss: 1.9023139117866434

Epoch: 5| Step: 1
Training loss: 1.823002576828003
Validation loss: 1.938276760039791

Epoch: 5| Step: 2
Training loss: 1.6061818599700928
Validation loss: 1.8995515825927898

Epoch: 5| Step: 3
Training loss: 2.1582980155944824
Validation loss: 1.9130208312824208

Epoch: 5| Step: 4
Training loss: 1.9295459985733032
Validation loss: 1.910157480547505

Epoch: 5| Step: 5
Training loss: 1.4454786777496338
Validation loss: 1.9196741042598602

Epoch: 5| Step: 6
Training loss: 1.3954213857650757
Validation loss: 1.9126996788927304

Epoch: 5| Step: 7
Training loss: 1.4548925161361694
Validation loss: 1.9131413070104455

Epoch: 5| Step: 8
Training loss: 1.8848612308502197
Validation loss: 1.9216139060194775

Epoch: 5| Step: 9
Training loss: 2.3896307945251465
Validation loss: 1.90300041244876

Epoch: 5| Step: 10
Training loss: 1.8751661777496338
Validation loss: 1.9049442404059953

Epoch: 269| Step: 0
Training loss: 2.522475481033325
Validation loss: 1.9201497390706053

Epoch: 5| Step: 1
Training loss: 1.5850435495376587
Validation loss: 1.8850656158180648

Epoch: 5| Step: 2
Training loss: 2.290806531906128
Validation loss: 1.931529660378733

Epoch: 5| Step: 3
Training loss: 1.330925703048706
Validation loss: 1.9067795097187001

Epoch: 5| Step: 4
Training loss: 1.9840145111083984
Validation loss: 1.9139350985967984

Epoch: 5| Step: 5
Training loss: 1.9006140232086182
Validation loss: 1.8890946847136303

Epoch: 5| Step: 6
Training loss: 1.314502477645874
Validation loss: 1.931550472013412

Epoch: 5| Step: 7
Training loss: 1.3088338375091553
Validation loss: 1.9049617398169734

Epoch: 5| Step: 8
Training loss: 1.3827778100967407
Validation loss: 1.8995508276006228

Epoch: 5| Step: 9
Training loss: 1.6777671575546265
Validation loss: 1.9087612552027549

Epoch: 5| Step: 10
Training loss: 2.1044511795043945
Validation loss: 1.9127460923246158

Epoch: 270| Step: 0
Training loss: 1.6943082809448242
Validation loss: 1.9245637245075677

Epoch: 5| Step: 1
Training loss: 2.1878983974456787
Validation loss: 1.9084520288693008

Epoch: 5| Step: 2
Training loss: 0.9923408627510071
Validation loss: 1.9130444783036427

Epoch: 5| Step: 3
Training loss: 2.540224552154541
Validation loss: 1.9333432541098645

Epoch: 5| Step: 4
Training loss: 1.4398607015609741
Validation loss: 1.9104422933311873

Epoch: 5| Step: 5
Training loss: 1.41316556930542
Validation loss: 1.9070344868526663

Epoch: 5| Step: 6
Training loss: 2.0929934978485107
Validation loss: 1.9077953061749857

Epoch: 5| Step: 7
Training loss: 1.8798259496688843
Validation loss: 1.9230943764409711

Epoch: 5| Step: 8
Training loss: 1.4562146663665771
Validation loss: 1.9260520294148435

Epoch: 5| Step: 9
Training loss: 1.9062776565551758
Validation loss: 1.9407147925387147

Epoch: 5| Step: 10
Training loss: 1.7598506212234497
Validation loss: 1.9382137983076033

Epoch: 271| Step: 0
Training loss: 1.6418285369873047
Validation loss: 1.9260658910197597

Epoch: 5| Step: 1
Training loss: 1.97336745262146
Validation loss: 1.8831177629450315

Epoch: 5| Step: 2
Training loss: 1.1316148042678833
Validation loss: 1.9338311969593007

Epoch: 5| Step: 3
Training loss: 1.630780816078186
Validation loss: 1.903569588097193

Epoch: 5| Step: 4
Training loss: 2.169884204864502
Validation loss: 1.9096474134793846

Epoch: 5| Step: 5
Training loss: 1.656789779663086
Validation loss: 1.9364313874193417

Epoch: 5| Step: 6
Training loss: 1.1855015754699707
Validation loss: 1.9192965633125716

Epoch: 5| Step: 7
Training loss: 2.240659236907959
Validation loss: 1.918691832532165

Epoch: 5| Step: 8
Training loss: 1.6606858968734741
Validation loss: 1.9176862239837646

Epoch: 5| Step: 9
Training loss: 2.511230945587158
Validation loss: 1.9061875625323224

Epoch: 5| Step: 10
Training loss: 1.2812776565551758
Validation loss: 1.8957716521396433

Epoch: 272| Step: 0
Training loss: 1.9202296733856201
Validation loss: 1.9108564097394225

Epoch: 5| Step: 1
Training loss: 1.7993438243865967
Validation loss: 1.8926409136864446

Epoch: 5| Step: 2
Training loss: 1.278681755065918
Validation loss: 1.9121736159888647

Epoch: 5| Step: 3
Training loss: 1.3181829452514648
Validation loss: 1.8949656460874824

Epoch: 5| Step: 4
Training loss: 2.4610061645507812
Validation loss: 1.905758789790574

Epoch: 5| Step: 5
Training loss: 1.6841909885406494
Validation loss: 1.8962971651425926

Epoch: 5| Step: 6
Training loss: 1.5672214031219482
Validation loss: 1.8807365791772002

Epoch: 5| Step: 7
Training loss: 2.084367275238037
Validation loss: 1.883508284886678

Epoch: 5| Step: 8
Training loss: 2.411264419555664
Validation loss: 1.9041661498367146

Epoch: 5| Step: 9
Training loss: 1.1593480110168457
Validation loss: 1.923412315307125

Epoch: 5| Step: 10
Training loss: 1.4523485898971558
Validation loss: 1.9232596812709686

Epoch: 273| Step: 0
Training loss: 1.8840519189834595
Validation loss: 1.9264481529112785

Epoch: 5| Step: 1
Training loss: 1.7614858150482178
Validation loss: 1.8696548887478408

Epoch: 5| Step: 2
Training loss: 1.4630067348480225
Validation loss: 1.921399716408022

Epoch: 5| Step: 3
Training loss: 1.5814743041992188
Validation loss: 1.876875315943072

Epoch: 5| Step: 4
Training loss: 0.8991245031356812
Validation loss: 1.9042115570396505

Epoch: 5| Step: 5
Training loss: 1.7780640125274658
Validation loss: 1.9079305715458368

Epoch: 5| Step: 6
Training loss: 2.286499500274658
Validation loss: 1.8907675691830215

Epoch: 5| Step: 7
Training loss: 1.4032022953033447
Validation loss: 1.8973415333737609

Epoch: 5| Step: 8
Training loss: 2.203197479248047
Validation loss: 1.9309070674321984

Epoch: 5| Step: 9
Training loss: 1.6289743185043335
Validation loss: 1.8808889299310663

Epoch: 5| Step: 10
Training loss: 2.155146837234497
Validation loss: 1.9175493448011336

Epoch: 274| Step: 0
Training loss: 2.076036214828491
Validation loss: 1.9107633970117057

Epoch: 5| Step: 1
Training loss: 1.4298436641693115
Validation loss: 1.9234148917659637

Epoch: 5| Step: 2
Training loss: 1.7105588912963867
Validation loss: 1.912165113674697

Epoch: 5| Step: 3
Training loss: 1.4608283042907715
Validation loss: 1.9167531536471458

Epoch: 5| Step: 4
Training loss: 1.731532335281372
Validation loss: 1.9225226730428717

Epoch: 5| Step: 5
Training loss: 1.820050597190857
Validation loss: 1.9179111091039514

Epoch: 5| Step: 6
Training loss: 1.5617586374282837
Validation loss: 1.9329477535781039

Epoch: 5| Step: 7
Training loss: 1.884665846824646
Validation loss: 1.9005428129626858

Epoch: 5| Step: 8
Training loss: 1.9717296361923218
Validation loss: 1.9009419077186174

Epoch: 5| Step: 9
Training loss: 1.7678101062774658
Validation loss: 1.9285407040708809

Epoch: 5| Step: 10
Training loss: 1.615198016166687
Validation loss: 1.8929064453289073

Epoch: 275| Step: 0
Training loss: 1.4426522254943848
Validation loss: 1.9159853919859855

Epoch: 5| Step: 1
Training loss: 1.9452263116836548
Validation loss: 1.9007928576520694

Epoch: 5| Step: 2
Training loss: 1.5001157522201538
Validation loss: 1.8610810028609408

Epoch: 5| Step: 3
Training loss: 1.6162068843841553
Validation loss: 1.87007434650134

Epoch: 5| Step: 4
Training loss: 2.3358120918273926
Validation loss: 1.898711771093389

Epoch: 5| Step: 5
Training loss: 1.8998010158538818
Validation loss: 1.8815581208916121

Epoch: 5| Step: 6
Training loss: 1.390053629875183
Validation loss: 1.8622719972364363

Epoch: 5| Step: 7
Training loss: 1.4975533485412598
Validation loss: 1.8830942953786542

Epoch: 5| Step: 8
Training loss: 2.133248805999756
Validation loss: 1.8650698072166854

Epoch: 5| Step: 9
Training loss: 1.5527608394622803
Validation loss: 1.902066953720585

Epoch: 5| Step: 10
Training loss: 1.8257023096084595
Validation loss: 1.9112662089768278

Epoch: 276| Step: 0
Training loss: 1.4802080392837524
Validation loss: 1.9029716727554158

Epoch: 5| Step: 1
Training loss: 2.7180190086364746
Validation loss: 1.8960063034488308

Epoch: 5| Step: 2
Training loss: 2.146467685699463
Validation loss: 1.8832801375337826

Epoch: 5| Step: 3
Training loss: 1.6133356094360352
Validation loss: 1.919638450427722

Epoch: 5| Step: 4
Training loss: 2.0663912296295166
Validation loss: 1.895193051266414

Epoch: 5| Step: 5
Training loss: 1.3373374938964844
Validation loss: 1.9158442763872043

Epoch: 5| Step: 6
Training loss: 1.5723206996917725
Validation loss: 1.9025883366984706

Epoch: 5| Step: 7
Training loss: 1.351219654083252
Validation loss: 1.9064603390232209

Epoch: 5| Step: 8
Training loss: 1.0919681787490845
Validation loss: 1.9216830653529013

Epoch: 5| Step: 9
Training loss: 1.641679048538208
Validation loss: 1.9378332681553339

Epoch: 5| Step: 10
Training loss: 2.127495050430298
Validation loss: 1.9042640450180217

Epoch: 277| Step: 0
Training loss: 1.8419675827026367
Validation loss: 1.9128426364673081

Epoch: 5| Step: 1
Training loss: 1.3235620260238647
Validation loss: 1.9108651684176536

Epoch: 5| Step: 2
Training loss: 1.1654561758041382
Validation loss: 1.916473195117007

Epoch: 5| Step: 3
Training loss: 1.9736740589141846
Validation loss: 1.8985615058611798

Epoch: 5| Step: 4
Training loss: 2.2865777015686035
Validation loss: 1.8954086790802658

Epoch: 5| Step: 5
Training loss: 1.8866004943847656
Validation loss: 1.874118713922398

Epoch: 5| Step: 6
Training loss: 1.6162984371185303
Validation loss: 1.9188801691096316

Epoch: 5| Step: 7
Training loss: 1.3014854192733765
Validation loss: 1.9273940081237464

Epoch: 5| Step: 8
Training loss: 1.6330080032348633
Validation loss: 1.913683565714026

Epoch: 5| Step: 9
Training loss: 1.8601287603378296
Validation loss: 1.881255688205842

Epoch: 5| Step: 10
Training loss: 2.0341577529907227
Validation loss: 1.8754164249666276

Epoch: 278| Step: 0
Training loss: 2.296849489212036
Validation loss: 1.9078989105839883

Epoch: 5| Step: 1
Training loss: 0.962147057056427
Validation loss: 1.8745869667299333

Epoch: 5| Step: 2
Training loss: 1.4629404544830322
Validation loss: 1.9266363574612526

Epoch: 5| Step: 3
Training loss: 1.9721720218658447
Validation loss: 1.8831897589468187

Epoch: 5| Step: 4
Training loss: 1.9145517349243164
Validation loss: 1.8614043420360935

Epoch: 5| Step: 5
Training loss: 1.6714773178100586
Validation loss: 1.9107515094100789

Epoch: 5| Step: 6
Training loss: 1.3326454162597656
Validation loss: 1.8707397586555892

Epoch: 5| Step: 7
Training loss: 1.8317285776138306
Validation loss: 1.9008459532132713

Epoch: 5| Step: 8
Training loss: 2.034651517868042
Validation loss: 1.875569442267059

Epoch: 5| Step: 9
Training loss: 1.6424109935760498
Validation loss: 1.8978821795473817

Epoch: 5| Step: 10
Training loss: 2.007770538330078
Validation loss: 1.8997911099464662

Epoch: 279| Step: 0
Training loss: 1.3692071437835693
Validation loss: 1.9251304031700216

Epoch: 5| Step: 1
Training loss: 1.3040127754211426
Validation loss: 1.9008996435391006

Epoch: 5| Step: 2
Training loss: 1.9965457916259766
Validation loss: 1.8770428883132113

Epoch: 5| Step: 3
Training loss: 1.742130994796753
Validation loss: 1.879470923895477

Epoch: 5| Step: 4
Training loss: 1.8967292308807373
Validation loss: 1.88356033191886

Epoch: 5| Step: 5
Training loss: 1.8451347351074219
Validation loss: 1.8744292284852715

Epoch: 5| Step: 6
Training loss: 1.7244304418563843
Validation loss: 1.874369070094119

Epoch: 5| Step: 7
Training loss: 1.582478404045105
Validation loss: 1.8834451577996696

Epoch: 5| Step: 8
Training loss: 1.702275276184082
Validation loss: 1.8950180417747908

Epoch: 5| Step: 9
Training loss: 1.9978135824203491
Validation loss: 1.9068190884846512

Epoch: 5| Step: 10
Training loss: 1.7798830270767212
Validation loss: 1.8767374254042102

Epoch: 280| Step: 0
Training loss: 1.6993951797485352
Validation loss: 1.8765347593574113

Epoch: 5| Step: 1
Training loss: 1.5871745347976685
Validation loss: 1.8946427414494176

Epoch: 5| Step: 2
Training loss: 1.6801773309707642
Validation loss: 1.9083134051292174

Epoch: 5| Step: 3
Training loss: 1.7774848937988281
Validation loss: 1.9032310542239939

Epoch: 5| Step: 4
Training loss: 1.1912505626678467
Validation loss: 1.9082933805322135

Epoch: 5| Step: 5
Training loss: 2.2912516593933105
Validation loss: 1.8836343211512412

Epoch: 5| Step: 6
Training loss: 1.3357446193695068
Validation loss: 1.9588984789386872

Epoch: 5| Step: 7
Training loss: 1.6214077472686768
Validation loss: 1.9095706132150465

Epoch: 5| Step: 8
Training loss: 2.2324717044830322
Validation loss: 1.9262970891050113

Epoch: 5| Step: 9
Training loss: 1.7630960941314697
Validation loss: 1.9244133144296625

Epoch: 5| Step: 10
Training loss: 1.6486252546310425
Validation loss: 1.904235368133873

Epoch: 281| Step: 0
Training loss: 1.2669217586517334
Validation loss: 1.9318088664803454

Epoch: 5| Step: 1
Training loss: 1.4499242305755615
Validation loss: 1.938372181307885

Epoch: 5| Step: 2
Training loss: 2.509028196334839
Validation loss: 1.9267404130710069

Epoch: 5| Step: 3
Training loss: 1.721442461013794
Validation loss: 1.9201405958462787

Epoch: 5| Step: 4
Training loss: 2.19865083694458
Validation loss: 1.9211240994032992

Epoch: 5| Step: 5
Training loss: 1.2641175985336304
Validation loss: 1.9331679690268733

Epoch: 5| Step: 6
Training loss: 2.0411555767059326
Validation loss: 1.9369182766124766

Epoch: 5| Step: 7
Training loss: 1.9282766580581665
Validation loss: 1.8826372623443604

Epoch: 5| Step: 8
Training loss: 1.1772398948669434
Validation loss: 1.8884068996675554

Epoch: 5| Step: 9
Training loss: 1.758893609046936
Validation loss: 1.9249125911343483

Epoch: 5| Step: 10
Training loss: 1.4714444875717163
Validation loss: 1.9210354141009751

Epoch: 282| Step: 0
Training loss: 1.8017292022705078
Validation loss: 1.880251920351418

Epoch: 5| Step: 1
Training loss: 1.7339231967926025
Validation loss: 1.898326975043102

Epoch: 5| Step: 2
Training loss: 1.6060431003570557
Validation loss: 1.898894202324652

Epoch: 5| Step: 3
Training loss: 1.7389590740203857
Validation loss: 1.8843509189544185

Epoch: 5| Step: 4
Training loss: 1.6696875095367432
Validation loss: 1.897814578907464

Epoch: 5| Step: 5
Training loss: 1.7155323028564453
Validation loss: 1.8790978103555658

Epoch: 5| Step: 6
Training loss: 2.009700298309326
Validation loss: 1.9078743534703408

Epoch: 5| Step: 7
Training loss: 1.7097244262695312
Validation loss: 1.8796709263196556

Epoch: 5| Step: 8
Training loss: 1.8548223972320557
Validation loss: 1.9000094411193684

Epoch: 5| Step: 9
Training loss: 0.9412678480148315
Validation loss: 1.903575340906779

Epoch: 5| Step: 10
Training loss: 1.6772551536560059
Validation loss: 1.8715319172028573

Epoch: 283| Step: 0
Training loss: 1.58681058883667
Validation loss: 1.8937123770354896

Epoch: 5| Step: 1
Training loss: 1.4451290369033813
Validation loss: 1.8587886697502547

Epoch: 5| Step: 2
Training loss: 1.658347487449646
Validation loss: 1.8432317228727444

Epoch: 5| Step: 3
Training loss: 1.9133999347686768
Validation loss: 1.876615778092415

Epoch: 5| Step: 4
Training loss: 1.4947245121002197
Validation loss: 1.8941166298363799

Epoch: 5| Step: 5
Training loss: 2.1959049701690674
Validation loss: 1.8752031774931057

Epoch: 5| Step: 6
Training loss: 1.766736626625061
Validation loss: 1.906469670675134

Epoch: 5| Step: 7
Training loss: 1.453576683998108
Validation loss: 1.8972373444546935

Epoch: 5| Step: 8
Training loss: 1.8814958333969116
Validation loss: 1.9191166623946159

Epoch: 5| Step: 9
Training loss: 1.6840174198150635
Validation loss: 1.891242137519262

Epoch: 5| Step: 10
Training loss: 1.5775195360183716
Validation loss: 1.8874600574534426

Epoch: 284| Step: 0
Training loss: 1.594508409500122
Validation loss: 1.907415150314249

Epoch: 5| Step: 1
Training loss: 1.6471601724624634
Validation loss: 1.9299805446337628

Epoch: 5| Step: 2
Training loss: 1.2627627849578857
Validation loss: 1.9029715035551338

Epoch: 5| Step: 3
Training loss: 2.1031761169433594
Validation loss: 1.8676856064027356

Epoch: 5| Step: 4
Training loss: 2.1237730979919434
Validation loss: 1.8460506136699388

Epoch: 5| Step: 5
Training loss: 1.4829411506652832
Validation loss: 1.861543748968391

Epoch: 5| Step: 6
Training loss: 0.9700759649276733
Validation loss: 1.8888262497481478

Epoch: 5| Step: 7
Training loss: 2.4847474098205566
Validation loss: 1.9158396772159043

Epoch: 5| Step: 8
Training loss: 2.1483681201934814
Validation loss: 1.9144377644344042

Epoch: 5| Step: 9
Training loss: 1.2733752727508545
Validation loss: 1.9250916588690974

Epoch: 5| Step: 10
Training loss: 1.5724228620529175
Validation loss: 1.9038042535064041

Epoch: 285| Step: 0
Training loss: 1.6584274768829346
Validation loss: 1.9503269580102736

Epoch: 5| Step: 1
Training loss: 2.168671131134033
Validation loss: 1.9074873334618025

Epoch: 5| Step: 2
Training loss: 1.4609756469726562
Validation loss: 1.921056701290992

Epoch: 5| Step: 3
Training loss: 1.5516278743743896
Validation loss: 1.9008492654369724

Epoch: 5| Step: 4
Training loss: 2.26946759223938
Validation loss: 1.9087402615495908

Epoch: 5| Step: 5
Training loss: 1.1877793073654175
Validation loss: 1.9009981655305432

Epoch: 5| Step: 6
Training loss: 2.3059768676757812
Validation loss: 1.866732051295619

Epoch: 5| Step: 7
Training loss: 1.3352159261703491
Validation loss: 1.895169299135926

Epoch: 5| Step: 8
Training loss: 1.6317298412322998
Validation loss: 1.8945370399823753

Epoch: 5| Step: 9
Training loss: 1.776167631149292
Validation loss: 1.8863799777082217

Epoch: 5| Step: 10
Training loss: 1.3295384645462036
Validation loss: 1.861832203403596

Epoch: 286| Step: 0
Training loss: 1.8563587665557861
Validation loss: 1.8525391342819377

Epoch: 5| Step: 1
Training loss: 1.1025997400283813
Validation loss: 1.8852369862218057

Epoch: 5| Step: 2
Training loss: 2.392739772796631
Validation loss: 1.8744930657007361

Epoch: 5| Step: 3
Training loss: 2.0674006938934326
Validation loss: 1.8946727783449235

Epoch: 5| Step: 4
Training loss: 1.1279956102371216
Validation loss: 1.884173257376558

Epoch: 5| Step: 5
Training loss: 1.6498734951019287
Validation loss: 1.9031990856252692

Epoch: 5| Step: 6
Training loss: 2.1123859882354736
Validation loss: 1.933971446047547

Epoch: 5| Step: 7
Training loss: 1.3400156497955322
Validation loss: 1.8900970323111421

Epoch: 5| Step: 8
Training loss: 1.900442361831665
Validation loss: 1.9118670648144138

Epoch: 5| Step: 9
Training loss: 1.4807682037353516
Validation loss: 1.8871166308720906

Epoch: 5| Step: 10
Training loss: 1.6217381954193115
Validation loss: 1.9087108950461111

Epoch: 287| Step: 0
Training loss: 1.4995189905166626
Validation loss: 1.9012596043207313

Epoch: 5| Step: 1
Training loss: 1.4746993780136108
Validation loss: 1.8704242808844453

Epoch: 5| Step: 2
Training loss: 2.030876398086548
Validation loss: 1.8787678300693471

Epoch: 5| Step: 3
Training loss: 1.9213526248931885
Validation loss: 1.9053343778015466

Epoch: 5| Step: 4
Training loss: 2.00581693649292
Validation loss: 1.888597314075757

Epoch: 5| Step: 5
Training loss: 1.3247450590133667
Validation loss: 1.8933742738539172

Epoch: 5| Step: 6
Training loss: 1.3713737726211548
Validation loss: 1.8752756003410584

Epoch: 5| Step: 7
Training loss: 1.8299245834350586
Validation loss: 1.8770631769652009

Epoch: 5| Step: 8
Training loss: 1.4124786853790283
Validation loss: 1.8749100277500768

Epoch: 5| Step: 9
Training loss: 1.780165433883667
Validation loss: 1.8627607194326257

Epoch: 5| Step: 10
Training loss: 1.9196662902832031
Validation loss: 1.91192413145496

Epoch: 288| Step: 0
Training loss: 2.0694243907928467
Validation loss: 1.874905538815324

Epoch: 5| Step: 1
Training loss: 1.5796539783477783
Validation loss: 1.864902630929024

Epoch: 5| Step: 2
Training loss: 1.6898307800292969
Validation loss: 1.8954382314476916

Epoch: 5| Step: 3
Training loss: 1.9917097091674805
Validation loss: 1.8874566144840692

Epoch: 5| Step: 4
Training loss: 1.8535692691802979
Validation loss: 1.876593779492122

Epoch: 5| Step: 5
Training loss: 1.194679856300354
Validation loss: 1.8631371516053394

Epoch: 5| Step: 6
Training loss: 1.5757570266723633
Validation loss: 1.8740828114171182

Epoch: 5| Step: 7
Training loss: 1.5685474872589111
Validation loss: 1.9030984499121224

Epoch: 5| Step: 8
Training loss: 1.3954131603240967
Validation loss: 1.8810963784494708

Epoch: 5| Step: 9
Training loss: 1.8224233388900757
Validation loss: 1.860217785322538

Epoch: 5| Step: 10
Training loss: 1.6644665002822876
Validation loss: 1.9216029592739639

Epoch: 289| Step: 0
Training loss: 2.2285585403442383
Validation loss: 1.8965651450618621

Epoch: 5| Step: 1
Training loss: 1.369992733001709
Validation loss: 1.8815464896540488

Epoch: 5| Step: 2
Training loss: 1.7926769256591797
Validation loss: 1.8747232421751945

Epoch: 5| Step: 3
Training loss: 1.8037922382354736
Validation loss: 1.900264052934544

Epoch: 5| Step: 4
Training loss: 1.338878870010376
Validation loss: 1.8611763690107612

Epoch: 5| Step: 5
Training loss: 1.2929003238677979
Validation loss: 1.8954895375877299

Epoch: 5| Step: 6
Training loss: 1.4351892471313477
Validation loss: 1.886984848207043

Epoch: 5| Step: 7
Training loss: 2.048917531967163
Validation loss: 1.8841728164303688

Epoch: 5| Step: 8
Training loss: 1.481074333190918
Validation loss: 1.89195304916751

Epoch: 5| Step: 9
Training loss: 1.459613561630249
Validation loss: 1.8847689961874357

Epoch: 5| Step: 10
Training loss: 2.562880277633667
Validation loss: 1.8463789493806901

Epoch: 290| Step: 0
Training loss: 1.4167771339416504
Validation loss: 1.8816885832817323

Epoch: 5| Step: 1
Training loss: 1.5569140911102295
Validation loss: 1.8677985463091122

Epoch: 5| Step: 2
Training loss: 1.5593113899230957
Validation loss: 1.8598506963381203

Epoch: 5| Step: 3
Training loss: 1.602522850036621
Validation loss: 1.8637239074194303

Epoch: 5| Step: 4
Training loss: 1.8399509191513062
Validation loss: 1.8488596286824954

Epoch: 5| Step: 5
Training loss: 1.2765071392059326
Validation loss: 1.919761525687351

Epoch: 5| Step: 6
Training loss: 2.170820951461792
Validation loss: 1.8907009760538738

Epoch: 5| Step: 7
Training loss: 1.3349113464355469
Validation loss: 1.8957977410285705

Epoch: 5| Step: 8
Training loss: 1.912374496459961
Validation loss: 1.879412333170573

Epoch: 5| Step: 9
Training loss: 1.8156006336212158
Validation loss: 1.8737197191484514

Epoch: 5| Step: 10
Training loss: 2.1183083057403564
Validation loss: 1.8996957655875915

Epoch: 291| Step: 0
Training loss: 1.743515968322754
Validation loss: 1.8707181010195004

Epoch: 5| Step: 1
Training loss: 1.2678965330123901
Validation loss: 1.9110450052445935

Epoch: 5| Step: 2
Training loss: 1.9252912998199463
Validation loss: 1.905425927972281

Epoch: 5| Step: 3
Training loss: 1.504800796508789
Validation loss: 1.8797340623794063

Epoch: 5| Step: 4
Training loss: 1.9556480646133423
Validation loss: 1.908017607145412

Epoch: 5| Step: 5
Training loss: 1.533746600151062
Validation loss: 1.8912241433256416

Epoch: 5| Step: 6
Training loss: 1.1898961067199707
Validation loss: 1.880768641348808

Epoch: 5| Step: 7
Training loss: 2.295752763748169
Validation loss: 1.8812747347739436

Epoch: 5| Step: 8
Training loss: 1.3182145357131958
Validation loss: 1.851171665294196

Epoch: 5| Step: 9
Training loss: 1.8309484720230103
Validation loss: 1.8785455713989914

Epoch: 5| Step: 10
Training loss: 1.8710993528366089
Validation loss: 1.8682608463430916

Epoch: 292| Step: 0
Training loss: 1.7250659465789795
Validation loss: 1.8609609360335975

Epoch: 5| Step: 1
Training loss: 1.860001802444458
Validation loss: 1.8327519765464209

Epoch: 5| Step: 2
Training loss: 1.7771568298339844
Validation loss: 1.8866614910864061

Epoch: 5| Step: 3
Training loss: 1.4266483783721924
Validation loss: 1.8581259750550794

Epoch: 5| Step: 4
Training loss: 2.140476703643799
Validation loss: 1.847707797122258

Epoch: 5| Step: 5
Training loss: 1.30470871925354
Validation loss: 1.877215144454792

Epoch: 5| Step: 6
Training loss: 1.2955118417739868
Validation loss: 1.8746351990648495

Epoch: 5| Step: 7
Training loss: 1.587005853652954
Validation loss: 1.8668135622496247

Epoch: 5| Step: 8
Training loss: 1.8333866596221924
Validation loss: 1.8641974502994167

Epoch: 5| Step: 9
Training loss: 1.725254774093628
Validation loss: 1.8844399554755098

Epoch: 5| Step: 10
Training loss: 1.954235315322876
Validation loss: 1.8754182092605098

Epoch: 293| Step: 0
Training loss: 1.256853461265564
Validation loss: 1.921922827279696

Epoch: 5| Step: 1
Training loss: 1.4956268072128296
Validation loss: 1.919077314356322

Epoch: 5| Step: 2
Training loss: 1.0940111875534058
Validation loss: 1.906181038066905

Epoch: 5| Step: 3
Training loss: 2.27465558052063
Validation loss: 1.9243532406386508

Epoch: 5| Step: 4
Training loss: 2.1098875999450684
Validation loss: 1.9220157592527327

Epoch: 5| Step: 5
Training loss: 1.8806778192520142
Validation loss: 1.9286410231744089

Epoch: 5| Step: 6
Training loss: 1.4787298440933228
Validation loss: 1.9242732063416512

Epoch: 5| Step: 7
Training loss: 1.33445405960083
Validation loss: 1.9252534630478069

Epoch: 5| Step: 8
Training loss: 2.2107958793640137
Validation loss: 1.904326113321448

Epoch: 5| Step: 9
Training loss: 1.6923913955688477
Validation loss: 1.911434737584924

Epoch: 5| Step: 10
Training loss: 1.624310851097107
Validation loss: 1.9079369191200501

Epoch: 294| Step: 0
Training loss: 1.5083725452423096
Validation loss: 1.8906448605240032

Epoch: 5| Step: 1
Training loss: 1.8229507207870483
Validation loss: 1.8780777838922316

Epoch: 5| Step: 2
Training loss: 2.072349786758423
Validation loss: 1.8901686591486777

Epoch: 5| Step: 3
Training loss: 2.2573390007019043
Validation loss: 1.876581891890495

Epoch: 5| Step: 4
Training loss: 1.398181676864624
Validation loss: 1.8460729814344836

Epoch: 5| Step: 5
Training loss: 1.190725564956665
Validation loss: 1.8658355038653138

Epoch: 5| Step: 6
Training loss: 1.4636681079864502
Validation loss: 1.8840844605558662

Epoch: 5| Step: 7
Training loss: 1.7209079265594482
Validation loss: 1.8627100913755354

Epoch: 5| Step: 8
Training loss: 2.3024086952209473
Validation loss: 1.851665723708368

Epoch: 5| Step: 9
Training loss: 1.502845048904419
Validation loss: 1.8939433738749514

Epoch: 5| Step: 10
Training loss: 1.1236343383789062
Validation loss: 1.8520357339612898

Epoch: 295| Step: 0
Training loss: 1.3209853172302246
Validation loss: 1.855497730675564

Epoch: 5| Step: 1
Training loss: 1.6153810024261475
Validation loss: 1.8589586916790213

Epoch: 5| Step: 2
Training loss: 1.267524003982544
Validation loss: 1.8894242240536598

Epoch: 5| Step: 3
Training loss: 2.58235764503479
Validation loss: 1.9019396381993448

Epoch: 5| Step: 4
Training loss: 1.3388450145721436
Validation loss: 1.8742329510309363

Epoch: 5| Step: 5
Training loss: 1.683781623840332
Validation loss: 1.8669523526263494

Epoch: 5| Step: 6
Training loss: 1.6378297805786133
Validation loss: 1.9047206499243294

Epoch: 5| Step: 7
Training loss: 1.3489179611206055
Validation loss: 1.9321440836434722

Epoch: 5| Step: 8
Training loss: 1.9530830383300781
Validation loss: 1.9029810838801886

Epoch: 5| Step: 9
Training loss: 2.1827871799468994
Validation loss: 1.880971001040551

Epoch: 5| Step: 10
Training loss: 1.5470539331436157
Validation loss: 1.9238303079400012

Epoch: 296| Step: 0
Training loss: 1.960715889930725
Validation loss: 1.8870787415453183

Epoch: 5| Step: 1
Training loss: 1.7704479694366455
Validation loss: 1.9049325450774162

Epoch: 5| Step: 2
Training loss: 1.6894588470458984
Validation loss: 1.902971636864447

Epoch: 5| Step: 3
Training loss: 2.0473530292510986
Validation loss: 1.887996636411195

Epoch: 5| Step: 4
Training loss: 1.6889934539794922
Validation loss: 1.8993969591715003

Epoch: 5| Step: 5
Training loss: 1.7192809581756592
Validation loss: 1.8836544290665658

Epoch: 5| Step: 6
Training loss: 1.1200612783432007
Validation loss: 1.9008391403382825

Epoch: 5| Step: 7
Training loss: 1.6027538776397705
Validation loss: 1.8873868014222832

Epoch: 5| Step: 8
Training loss: 1.553075909614563
Validation loss: 1.8552778100454679

Epoch: 5| Step: 9
Training loss: 1.8432064056396484
Validation loss: 1.8280506774943361

Epoch: 5| Step: 10
Training loss: 1.3413029909133911
Validation loss: 1.8774941172651065

Epoch: 297| Step: 0
Training loss: 1.7526378631591797
Validation loss: 1.843068024163605

Epoch: 5| Step: 1
Training loss: 1.3901833295822144
Validation loss: 1.886255007918163

Epoch: 5| Step: 2
Training loss: 1.9024848937988281
Validation loss: 1.8837031190113356

Epoch: 5| Step: 3
Training loss: 1.2780208587646484
Validation loss: 1.8666960334265104

Epoch: 5| Step: 4
Training loss: 1.993391990661621
Validation loss: 1.8858946087539836

Epoch: 5| Step: 5
Training loss: 1.8931976556777954
Validation loss: 1.8545491490312802

Epoch: 5| Step: 6
Training loss: 1.6490052938461304
Validation loss: 1.8590072303689935

Epoch: 5| Step: 7
Training loss: 1.1071069240570068
Validation loss: 1.8662556345744798

Epoch: 5| Step: 8
Training loss: 1.4899654388427734
Validation loss: 1.8602176366313812

Epoch: 5| Step: 9
Training loss: 2.4608144760131836
Validation loss: 1.87266448749009

Epoch: 5| Step: 10
Training loss: 1.2116332054138184
Validation loss: 1.8508605572485155

Epoch: 298| Step: 0
Training loss: 1.4318196773529053
Validation loss: 1.8822396750091224

Epoch: 5| Step: 1
Training loss: 1.3770115375518799
Validation loss: 1.8654512231067946

Epoch: 5| Step: 2
Training loss: 2.1011462211608887
Validation loss: 1.8940064676346318

Epoch: 5| Step: 3
Training loss: 1.386639952659607
Validation loss: 1.9406036202625563

Epoch: 5| Step: 4
Training loss: 2.0756332874298096
Validation loss: 1.9459118484168925

Epoch: 5| Step: 5
Training loss: 1.7244231700897217
Validation loss: 1.9108502967383272

Epoch: 5| Step: 6
Training loss: 1.5192501544952393
Validation loss: 1.921861110195037

Epoch: 5| Step: 7
Training loss: 1.6097913980484009
Validation loss: 1.9184901201596825

Epoch: 5| Step: 8
Training loss: 1.3890447616577148
Validation loss: 1.90721905872386

Epoch: 5| Step: 9
Training loss: 1.951969861984253
Validation loss: 1.910969227872869

Epoch: 5| Step: 10
Training loss: 2.006319046020508
Validation loss: 1.8831417893850675

Epoch: 299| Step: 0
Training loss: 1.248041033744812
Validation loss: 1.8551795892818

Epoch: 5| Step: 1
Training loss: 1.9863197803497314
Validation loss: 1.8781431426284134

Epoch: 5| Step: 2
Training loss: 1.7753146886825562
Validation loss: 1.8323008975675028

Epoch: 5| Step: 3
Training loss: 2.093533992767334
Validation loss: 1.8628237093648603

Epoch: 5| Step: 4
Training loss: 1.8185904026031494
Validation loss: 1.8697038030111661

Epoch: 5| Step: 5
Training loss: 1.2688146829605103
Validation loss: 1.8209871938151698

Epoch: 5| Step: 6
Training loss: 1.3277819156646729
Validation loss: 1.8432493555930354

Epoch: 5| Step: 7
Training loss: 1.5995912551879883
Validation loss: 1.8575207751284364

Epoch: 5| Step: 8
Training loss: 1.3554513454437256
Validation loss: 1.8718449479790145

Epoch: 5| Step: 9
Training loss: 1.52312433719635
Validation loss: 1.825723022542974

Epoch: 5| Step: 10
Training loss: 2.3825876712799072
Validation loss: 1.8473745853670183

Epoch: 300| Step: 0
Training loss: 2.0741493701934814
Validation loss: 1.83411544112749

Epoch: 5| Step: 1
Training loss: 1.779152274131775
Validation loss: 1.8623628898333477

Epoch: 5| Step: 2
Training loss: 1.5769940614700317
Validation loss: 1.8576370400767173

Epoch: 5| Step: 3
Training loss: 2.1338701248168945
Validation loss: 1.8677137731223978

Epoch: 5| Step: 4
Training loss: 1.1505212783813477
Validation loss: 1.8952739238739014

Epoch: 5| Step: 5
Training loss: 1.4005687236785889
Validation loss: 1.8380637271429903

Epoch: 5| Step: 6
Training loss: 1.6293811798095703
Validation loss: 1.8582470083749423

Epoch: 5| Step: 7
Training loss: 1.6972382068634033
Validation loss: 1.9048608118487942

Epoch: 5| Step: 8
Training loss: 1.4056017398834229
Validation loss: 1.8748289692786433

Epoch: 5| Step: 9
Training loss: 1.6671193838119507
Validation loss: 1.9320267169706282

Epoch: 5| Step: 10
Training loss: 1.5041019916534424
Validation loss: 1.8471610007747528

Testing loss: 2.1102700763278537
