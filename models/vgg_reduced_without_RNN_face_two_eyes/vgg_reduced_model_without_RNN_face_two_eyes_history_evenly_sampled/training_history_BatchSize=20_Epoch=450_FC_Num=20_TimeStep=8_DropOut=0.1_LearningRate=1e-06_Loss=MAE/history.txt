Epoch: 1| Step: 0
Training loss: 7.298856258392334
Validation loss: 6.923439933407691

Epoch: 5| Step: 1
Training loss: 7.527734279632568
Validation loss: 6.918858553773614

Epoch: 5| Step: 2
Training loss: 7.992183685302734
Validation loss: 6.912427389493552

Epoch: 5| Step: 3
Training loss: 5.5333027839660645
Validation loss: 6.909571847608013

Epoch: 5| Step: 4
Training loss: 5.847960472106934
Validation loss: 6.903015664828721

Epoch: 5| Step: 5
Training loss: 6.107600212097168
Validation loss: 6.894007272617792

Epoch: 5| Step: 6
Training loss: 5.93887996673584
Validation loss: 6.887407333620133

Epoch: 5| Step: 7
Training loss: 7.746493339538574
Validation loss: 6.883173763111073

Epoch: 5| Step: 8
Training loss: 7.189391136169434
Validation loss: 6.878181785665532

Epoch: 5| Step: 9
Training loss: 7.107354640960693
Validation loss: 6.871314141058153

Epoch: 5| Step: 10
Training loss: 5.0403032302856445
Validation loss: 6.864281218539002

Epoch: 2| Step: 0
Training loss: 6.274184226989746
Validation loss: 6.85819721734652

Epoch: 5| Step: 1
Training loss: 6.911362648010254
Validation loss: 6.853603916783487

Epoch: 5| Step: 2
Training loss: 6.187872409820557
Validation loss: 6.844304792342648

Epoch: 5| Step: 3
Training loss: 6.739406585693359
Validation loss: 6.841298862170148

Epoch: 5| Step: 4
Training loss: 6.519673824310303
Validation loss: 6.832643339710851

Epoch: 5| Step: 5
Training loss: 6.600327491760254
Validation loss: 6.8259228019304174

Epoch: 5| Step: 6
Training loss: 7.704701900482178
Validation loss: 6.817772280785345

Epoch: 5| Step: 7
Training loss: 6.167198181152344
Validation loss: 6.813776831473073

Epoch: 5| Step: 8
Training loss: 5.7520246505737305
Validation loss: 6.806341776283839

Epoch: 5| Step: 9
Training loss: 6.878164768218994
Validation loss: 6.800702530850646

Epoch: 5| Step: 10
Training loss: 7.145770072937012
Validation loss: 6.793278360879549

Epoch: 3| Step: 0
Training loss: 6.166224479675293
Validation loss: 6.786417427883353

Epoch: 5| Step: 1
Training loss: 6.3155622482299805
Validation loss: 6.781209755969304

Epoch: 5| Step: 2
Training loss: 7.849059104919434
Validation loss: 6.773958944505261

Epoch: 5| Step: 3
Training loss: 6.816802978515625
Validation loss: 6.765979489972515

Epoch: 5| Step: 4
Training loss: 6.074279308319092
Validation loss: 6.756917999636743

Epoch: 5| Step: 5
Training loss: 6.969914436340332
Validation loss: 6.751793558879565

Epoch: 5| Step: 6
Training loss: 7.240048885345459
Validation loss: 6.744138081868489

Epoch: 5| Step: 7
Training loss: 7.174248695373535
Validation loss: 6.737671190692533

Epoch: 5| Step: 8
Training loss: 5.638055324554443
Validation loss: 6.728784663702852

Epoch: 5| Step: 9
Training loss: 5.4179277420043945
Validation loss: 6.724212338847499

Epoch: 5| Step: 10
Training loss: 6.27864933013916
Validation loss: 6.71570638943744

Epoch: 4| Step: 0
Training loss: 7.3179216384887695
Validation loss: 6.707262275039509

Epoch: 5| Step: 1
Training loss: 5.2218170166015625
Validation loss: 6.7016746715832785

Epoch: 5| Step: 2
Training loss: 5.946019172668457
Validation loss: 6.694046246108188

Epoch: 5| Step: 3
Training loss: 6.7093186378479
Validation loss: 6.686939285647485

Epoch: 5| Step: 4
Training loss: 6.137490272521973
Validation loss: 6.68092482577088

Epoch: 5| Step: 5
Training loss: 6.8577728271484375
Validation loss: 6.672654828717632

Epoch: 5| Step: 6
Training loss: 6.148264408111572
Validation loss: 6.664587584874964

Epoch: 5| Step: 7
Training loss: 7.140699863433838
Validation loss: 6.65754730983447

Epoch: 5| Step: 8
Training loss: 6.961855888366699
Validation loss: 6.648667735438193

Epoch: 5| Step: 9
Training loss: 5.9140801429748535
Validation loss: 6.641323299818142

Epoch: 5| Step: 10
Training loss: 6.754359722137451
Validation loss: 6.633838899673954

Epoch: 5| Step: 0
Training loss: 6.545500755310059
Validation loss: 6.62674117344682

Epoch: 5| Step: 1
Training loss: 5.684172630310059
Validation loss: 6.619060475339172

Epoch: 5| Step: 2
Training loss: 5.973177909851074
Validation loss: 6.612451102143975

Epoch: 5| Step: 3
Training loss: 6.566143989562988
Validation loss: 6.601302213566278

Epoch: 5| Step: 4
Training loss: 7.151986598968506
Validation loss: 6.594657103220622

Epoch: 5| Step: 5
Training loss: 6.545647621154785
Validation loss: 6.589323412987493

Epoch: 5| Step: 6
Training loss: 6.486189842224121
Validation loss: 6.578662887696297

Epoch: 5| Step: 7
Training loss: 7.062605857849121
Validation loss: 6.570151103440152

Epoch: 5| Step: 8
Training loss: 6.584582328796387
Validation loss: 6.561283444845548

Epoch: 5| Step: 9
Training loss: 6.276327610015869
Validation loss: 6.555534157701718

Epoch: 5| Step: 10
Training loss: 5.045423984527588
Validation loss: 6.544171594804333

Epoch: 6| Step: 0
Training loss: 6.9553093910217285
Validation loss: 6.538595379039806

Epoch: 5| Step: 1
Training loss: 5.743023872375488
Validation loss: 6.530003870687177

Epoch: 5| Step: 2
Training loss: 5.615899562835693
Validation loss: 6.519170617544523

Epoch: 5| Step: 3
Training loss: 7.0092453956604
Validation loss: 6.511406883116691

Epoch: 5| Step: 4
Training loss: 6.774095058441162
Validation loss: 6.506541893046389

Epoch: 5| Step: 5
Training loss: 6.594154357910156
Validation loss: 6.49810730513706

Epoch: 5| Step: 6
Training loss: 6.265688419342041
Validation loss: 6.487192107785132

Epoch: 5| Step: 7
Training loss: 6.6543755531311035
Validation loss: 6.481353713620093

Epoch: 5| Step: 8
Training loss: 4.648350238800049
Validation loss: 6.468645239389071

Epoch: 5| Step: 9
Training loss: 6.9310736656188965
Validation loss: 6.4653710703695975

Epoch: 5| Step: 10
Training loss: 5.851818561553955
Validation loss: 6.451234171467442

Epoch: 7| Step: 0
Training loss: 6.806448936462402
Validation loss: 6.441046837837465

Epoch: 5| Step: 1
Training loss: 5.7733964920043945
Validation loss: 6.436276974216584

Epoch: 5| Step: 2
Training loss: 6.575788974761963
Validation loss: 6.427509025860858

Epoch: 5| Step: 3
Training loss: 5.185191631317139
Validation loss: 6.413607315350604

Epoch: 5| Step: 4
Training loss: 5.987433433532715
Validation loss: 6.4072748768714165

Epoch: 5| Step: 5
Training loss: 7.729454040527344
Validation loss: 6.399007012767177

Epoch: 5| Step: 6
Training loss: 5.458364486694336
Validation loss: 6.387801037039808

Epoch: 5| Step: 7
Training loss: 5.3055925369262695
Validation loss: 6.383087035148375

Epoch: 5| Step: 8
Training loss: 6.506983757019043
Validation loss: 6.367423221629153

Epoch: 5| Step: 9
Training loss: 6.004714012145996
Validation loss: 6.360269387563069

Epoch: 5| Step: 10
Training loss: 6.732824325561523
Validation loss: 6.350785716887443

Epoch: 8| Step: 0
Training loss: 6.411433219909668
Validation loss: 6.339993994723084

Epoch: 5| Step: 1
Training loss: 5.59880256652832
Validation loss: 6.330742184833814

Epoch: 5| Step: 2
Training loss: 5.093152046203613
Validation loss: 6.319005817495366

Epoch: 5| Step: 3
Training loss: 6.981921195983887
Validation loss: 6.311076123227355

Epoch: 5| Step: 4
Training loss: 6.375447750091553
Validation loss: 6.297729456296531

Epoch: 5| Step: 5
Training loss: 6.181130886077881
Validation loss: 6.287429219932966

Epoch: 5| Step: 6
Training loss: 6.3155107498168945
Validation loss: 6.2774711475577405

Epoch: 5| Step: 7
Training loss: 5.320245265960693
Validation loss: 6.266795466023106

Epoch: 5| Step: 8
Training loss: 5.942803382873535
Validation loss: 6.2555669866582395

Epoch: 5| Step: 9
Training loss: 6.282375335693359
Validation loss: 6.24455480165379

Epoch: 5| Step: 10
Training loss: 6.255717754364014
Validation loss: 6.235214740999283

Epoch: 9| Step: 0
Training loss: 4.898005485534668
Validation loss: 6.22331767441124

Epoch: 5| Step: 1
Training loss: 6.494362831115723
Validation loss: 6.212141924006964

Epoch: 5| Step: 2
Training loss: 6.665698051452637
Validation loss: 6.2023255389223815

Epoch: 5| Step: 3
Training loss: 5.780178546905518
Validation loss: 6.190998456811392

Epoch: 5| Step: 4
Training loss: 6.733788967132568
Validation loss: 6.179206417452905

Epoch: 5| Step: 5
Training loss: 5.986952781677246
Validation loss: 6.163527211835308

Epoch: 5| Step: 6
Training loss: 6.377675533294678
Validation loss: 6.153676525239022

Epoch: 5| Step: 7
Training loss: 5.679060459136963
Validation loss: 6.142219051238029

Epoch: 5| Step: 8
Training loss: 5.683322429656982
Validation loss: 6.12865262903193

Epoch: 5| Step: 9
Training loss: 4.904183387756348
Validation loss: 6.1179011867892354

Epoch: 5| Step: 10
Training loss: 6.163452625274658
Validation loss: 6.103393759778751

Epoch: 10| Step: 0
Training loss: 4.898895740509033
Validation loss: 6.0928750191965415

Epoch: 5| Step: 1
Training loss: 4.872756004333496
Validation loss: 6.079313283325524

Epoch: 5| Step: 2
Training loss: 5.520035743713379
Validation loss: 6.065443074831399

Epoch: 5| Step: 3
Training loss: 5.423592567443848
Validation loss: 6.049047464965492

Epoch: 5| Step: 4
Training loss: 5.948482513427734
Validation loss: 6.039013396027268

Epoch: 5| Step: 5
Training loss: 5.983425140380859
Validation loss: 6.028470849478117

Epoch: 5| Step: 6
Training loss: 5.58931827545166
Validation loss: 6.012808322906494

Epoch: 5| Step: 7
Training loss: 6.914018154144287
Validation loss: 5.998306346196

Epoch: 5| Step: 8
Training loss: 6.338997840881348
Validation loss: 5.985385443574639

Epoch: 5| Step: 9
Training loss: 6.307751655578613
Validation loss: 5.975869999136976

Epoch: 5| Step: 10
Training loss: 5.994192600250244
Validation loss: 5.95657128672446

Epoch: 11| Step: 0
Training loss: 5.902554512023926
Validation loss: 5.945431842598864

Epoch: 5| Step: 1
Training loss: 4.672182083129883
Validation loss: 5.926309472771101

Epoch: 5| Step: 2
Training loss: 5.853725910186768
Validation loss: 5.9139254118806575

Epoch: 5| Step: 3
Training loss: 5.5936479568481445
Validation loss: 5.898406028747559

Epoch: 5| Step: 4
Training loss: 5.873843193054199
Validation loss: 5.882481605775895

Epoch: 5| Step: 5
Training loss: 4.976315498352051
Validation loss: 5.86647419775686

Epoch: 5| Step: 6
Training loss: 5.600730895996094
Validation loss: 5.853782823008876

Epoch: 5| Step: 7
Training loss: 6.677438259124756
Validation loss: 5.834641195112659

Epoch: 5| Step: 8
Training loss: 5.582109451293945
Validation loss: 5.8194687802304506

Epoch: 5| Step: 9
Training loss: 5.606699466705322
Validation loss: 5.8037159571083645

Epoch: 5| Step: 10
Training loss: 5.604947566986084
Validation loss: 5.783355477035687

Epoch: 12| Step: 0
Training loss: 5.353188991546631
Validation loss: 5.768704255421956

Epoch: 5| Step: 1
Training loss: 6.247575759887695
Validation loss: 5.754749359623078

Epoch: 5| Step: 2
Training loss: 6.076611518859863
Validation loss: 5.734256488020702

Epoch: 5| Step: 3
Training loss: 3.7226357460021973
Validation loss: 5.71510967644312

Epoch: 5| Step: 4
Training loss: 6.076840400695801
Validation loss: 5.705144502783335

Epoch: 5| Step: 5
Training loss: 5.580617427825928
Validation loss: 5.680975160291118

Epoch: 5| Step: 6
Training loss: 5.170853614807129
Validation loss: 5.672285520902244

Epoch: 5| Step: 7
Training loss: 5.8349714279174805
Validation loss: 5.651101973748976

Epoch: 5| Step: 8
Training loss: 4.8888840675354
Validation loss: 5.628212149425219

Epoch: 5| Step: 9
Training loss: 5.2059855461120605
Validation loss: 5.613683869761806

Epoch: 5| Step: 10
Training loss: 5.797010898590088
Validation loss: 5.591152739781205

Epoch: 13| Step: 0
Training loss: 5.394010543823242
Validation loss: 5.57439911237327

Epoch: 5| Step: 1
Training loss: 5.669574737548828
Validation loss: 5.559355274323495

Epoch: 5| Step: 2
Training loss: 5.148993968963623
Validation loss: 5.534561152099281

Epoch: 5| Step: 3
Training loss: 5.215806007385254
Validation loss: 5.511900855648902

Epoch: 5| Step: 4
Training loss: 6.277464866638184
Validation loss: 5.493316040244154

Epoch: 5| Step: 5
Training loss: 4.498649597167969
Validation loss: 5.471019385963358

Epoch: 5| Step: 6
Training loss: 5.62138557434082
Validation loss: 5.4475279982372

Epoch: 5| Step: 7
Training loss: 4.977053642272949
Validation loss: 5.427409905259327

Epoch: 5| Step: 8
Training loss: 4.949612617492676
Validation loss: 5.4080208398962535

Epoch: 5| Step: 9
Training loss: 4.99060583114624
Validation loss: 5.384673380082654

Epoch: 5| Step: 10
Training loss: 4.7316694259643555
Validation loss: 5.3636744458188295

Epoch: 14| Step: 0
Training loss: 5.226106643676758
Validation loss: 5.340098698933919

Epoch: 5| Step: 1
Training loss: 3.6304728984832764
Validation loss: 5.31498711083525

Epoch: 5| Step: 2
Training loss: 6.219152927398682
Validation loss: 5.295739107234503

Epoch: 5| Step: 3
Training loss: 5.196902275085449
Validation loss: 5.273745085603448

Epoch: 5| Step: 4
Training loss: 5.7789411544799805
Validation loss: 5.254168797564763

Epoch: 5| Step: 5
Training loss: 4.839253902435303
Validation loss: 5.227212147046161

Epoch: 5| Step: 6
Training loss: 5.088323593139648
Validation loss: 5.203032191081713

Epoch: 5| Step: 7
Training loss: 4.012612342834473
Validation loss: 5.18013685493059

Epoch: 5| Step: 8
Training loss: 5.622413635253906
Validation loss: 5.159027150882188

Epoch: 5| Step: 9
Training loss: 4.664852619171143
Validation loss: 5.129702588563324

Epoch: 5| Step: 10
Training loss: 4.362771034240723
Validation loss: 5.107714371014667

Epoch: 15| Step: 0
Training loss: 4.314699649810791
Validation loss: 5.079493194498042

Epoch: 5| Step: 1
Training loss: 4.5513529777526855
Validation loss: 5.0549841337306525

Epoch: 5| Step: 2
Training loss: 5.74090051651001
Validation loss: 5.0278514251914075

Epoch: 5| Step: 3
Training loss: 4.683976173400879
Validation loss: 5.0015763159721125

Epoch: 5| Step: 4
Training loss: 5.312605381011963
Validation loss: 4.97033643209806

Epoch: 5| Step: 5
Training loss: 4.821032524108887
Validation loss: 4.948709846824728

Epoch: 5| Step: 6
Training loss: 4.752840995788574
Validation loss: 4.919027410527711

Epoch: 5| Step: 7
Training loss: 4.271432399749756
Validation loss: 4.8905872324461575

Epoch: 5| Step: 8
Training loss: 4.4662957191467285
Validation loss: 4.866260056854577

Epoch: 5| Step: 9
Training loss: 5.258713722229004
Validation loss: 4.841444466703681

Epoch: 5| Step: 10
Training loss: 3.3542964458465576
Validation loss: 4.817171424947759

Epoch: 16| Step: 0
Training loss: 3.9867196083068848
Validation loss: 4.781257285866686

Epoch: 5| Step: 1
Training loss: 5.673844814300537
Validation loss: 4.751068889453847

Epoch: 5| Step: 2
Training loss: 4.216006755828857
Validation loss: 4.729539235432942

Epoch: 5| Step: 3
Training loss: 6.396666526794434
Validation loss: 4.699131888727988

Epoch: 5| Step: 4
Training loss: 4.492676734924316
Validation loss: 4.664677840407177

Epoch: 5| Step: 5
Training loss: 4.293622016906738
Validation loss: 4.632478662716445

Epoch: 5| Step: 6
Training loss: 3.9409141540527344
Validation loss: 4.607656063572053

Epoch: 5| Step: 7
Training loss: 3.1740376949310303
Validation loss: 4.580276494385094

Epoch: 5| Step: 8
Training loss: 4.15287971496582
Validation loss: 4.550617566672704

Epoch: 5| Step: 9
Training loss: 4.188687801361084
Validation loss: 4.522497643706619

Epoch: 5| Step: 10
Training loss: 3.699564218521118
Validation loss: 4.495037140384797

Epoch: 17| Step: 0
Training loss: 4.93731164932251
Validation loss: 4.462604040740638

Epoch: 5| Step: 1
Training loss: 4.420943260192871
Validation loss: 4.426149424686227

Epoch: 5| Step: 2
Training loss: 4.43358039855957
Validation loss: 4.405314304495371

Epoch: 5| Step: 3
Training loss: 2.803032398223877
Validation loss: 4.367482405836864

Epoch: 5| Step: 4
Training loss: 3.484825849533081
Validation loss: 4.3305667241414385

Epoch: 5| Step: 5
Training loss: 3.2899296283721924
Validation loss: 4.307675341124176

Epoch: 5| Step: 6
Training loss: 4.896637916564941
Validation loss: 4.2677432593478954

Epoch: 5| Step: 7
Training loss: 3.640500545501709
Validation loss: 4.244656732005458

Epoch: 5| Step: 8
Training loss: 5.138760566711426
Validation loss: 4.212781670272991

Epoch: 5| Step: 9
Training loss: 3.8349289894104004
Validation loss: 4.1918489958650325

Epoch: 5| Step: 10
Training loss: 4.032378673553467
Validation loss: 4.154495034166562

Epoch: 18| Step: 0
Training loss: 3.8789315223693848
Validation loss: 4.114474675988638

Epoch: 5| Step: 1
Training loss: 3.9810047149658203
Validation loss: 4.089373650089387

Epoch: 5| Step: 2
Training loss: 3.624300479888916
Validation loss: 4.059498822817239

Epoch: 5| Step: 3
Training loss: 4.132493019104004
Validation loss: 4.030298243286789

Epoch: 5| Step: 4
Training loss: 2.5001742839813232
Validation loss: 4.006672259299986

Epoch: 5| Step: 5
Training loss: 4.088123321533203
Validation loss: 3.9629311971766974

Epoch: 5| Step: 6
Training loss: 3.459312915802002
Validation loss: 3.931347462438768

Epoch: 5| Step: 7
Training loss: 4.0713725090026855
Validation loss: 3.908164352499029

Epoch: 5| Step: 8
Training loss: 3.703580141067505
Validation loss: 3.8780998004380094

Epoch: 5| Step: 9
Training loss: 3.76802134513855
Validation loss: 3.8421422486664145

Epoch: 5| Step: 10
Training loss: 4.257650375366211
Validation loss: 3.818363243533719

Epoch: 19| Step: 0
Training loss: 3.464991331100464
Validation loss: 3.7733111432803574

Epoch: 5| Step: 1
Training loss: 3.353273868560791
Validation loss: 3.7523733826093775

Epoch: 5| Step: 2
Training loss: 4.1426897048950195
Validation loss: 3.713270748815229

Epoch: 5| Step: 3
Training loss: 3.360283374786377
Validation loss: 3.6866996826664096

Epoch: 5| Step: 4
Training loss: 3.936227321624756
Validation loss: 3.6510532722678235

Epoch: 5| Step: 5
Training loss: 3.494863986968994
Validation loss: 3.632068059777701

Epoch: 5| Step: 6
Training loss: 3.0782976150512695
Validation loss: 3.5941378480644635

Epoch: 5| Step: 7
Training loss: 4.0810956954956055
Validation loss: 3.5763708083860335

Epoch: 5| Step: 8
Training loss: 2.6138997077941895
Validation loss: 3.5384659433877594

Epoch: 5| Step: 9
Training loss: 3.4618072509765625
Validation loss: 3.507751936553627

Epoch: 5| Step: 10
Training loss: 3.3349435329437256
Validation loss: 3.4914652788510887

Epoch: 20| Step: 0
Training loss: 2.600201368331909
Validation loss: 3.451644456514748

Epoch: 5| Step: 1
Training loss: 3.883887529373169
Validation loss: 3.4238967869871404

Epoch: 5| Step: 2
Training loss: 3.6254336833953857
Validation loss: 3.4050075572024108

Epoch: 5| Step: 3
Training loss: 2.942094087600708
Validation loss: 3.3676689414567846

Epoch: 5| Step: 4
Training loss: 2.8591270446777344
Validation loss: 3.327068018656905

Epoch: 5| Step: 5
Training loss: 3.3169968128204346
Validation loss: 3.3114756768749607

Epoch: 5| Step: 6
Training loss: 3.6276779174804688
Validation loss: 3.2839086132664836

Epoch: 5| Step: 7
Training loss: 3.573307752609253
Validation loss: 3.2503444712649108

Epoch: 5| Step: 8
Training loss: 2.161700963973999
Validation loss: 3.231069644292196

Epoch: 5| Step: 9
Training loss: 3.7647786140441895
Validation loss: 3.206484184470228

Epoch: 5| Step: 10
Training loss: 3.293699264526367
Validation loss: 3.188926148158248

Epoch: 21| Step: 0
Training loss: 2.243905544281006
Validation loss: 3.151795894868912

Epoch: 5| Step: 1
Training loss: 3.5786242485046387
Validation loss: 3.139568595476048

Epoch: 5| Step: 2
Training loss: 3.5337586402893066
Validation loss: 3.1048529353193057

Epoch: 5| Step: 3
Training loss: 3.1871469020843506
Validation loss: 3.075039161148892

Epoch: 5| Step: 4
Training loss: 3.140571117401123
Validation loss: 3.047371797664191

Epoch: 5| Step: 5
Training loss: 2.9344427585601807
Validation loss: 3.037335708577146

Epoch: 5| Step: 6
Training loss: 3.7427241802215576
Validation loss: 3.007860845135104

Epoch: 5| Step: 7
Training loss: 2.7495808601379395
Validation loss: 2.984652070588963

Epoch: 5| Step: 8
Training loss: 2.790738105773926
Validation loss: 2.9544955991929576

Epoch: 5| Step: 9
Training loss: 3.1170272827148438
Validation loss: 2.946494976679484

Epoch: 5| Step: 10
Training loss: 2.697768211364746
Validation loss: 2.9268859970954155

Epoch: 22| Step: 0
Training loss: 3.403743028640747
Validation loss: 2.9007133309559157

Epoch: 5| Step: 1
Training loss: 2.7119972705841064
Validation loss: 2.877166412209952

Epoch: 5| Step: 2
Training loss: 2.757082223892212
Validation loss: 2.8722876297530306

Epoch: 5| Step: 3
Training loss: 3.333597183227539
Validation loss: 2.8460704921394266

Epoch: 5| Step: 4
Training loss: 3.0359253883361816
Validation loss: 2.840143383190196

Epoch: 5| Step: 5
Training loss: 3.7846405506134033
Validation loss: 2.825306130993751

Epoch: 5| Step: 6
Training loss: 2.602740526199341
Validation loss: 2.8084667087883077

Epoch: 5| Step: 7
Training loss: 2.6933465003967285
Validation loss: 2.800108817315871

Epoch: 5| Step: 8
Training loss: 2.781611680984497
Validation loss: 2.7695784902059906

Epoch: 5| Step: 9
Training loss: 2.8217594623565674
Validation loss: 2.7598155954832673

Epoch: 5| Step: 10
Training loss: 1.9889360666275024
Validation loss: 2.7408833708814395

Epoch: 23| Step: 0
Training loss: 3.2484424114227295
Validation loss: 2.73065459856423

Epoch: 5| Step: 1
Training loss: 3.163182258605957
Validation loss: 2.718009087347215

Epoch: 5| Step: 2
Training loss: 3.042515516281128
Validation loss: 2.679888653498824

Epoch: 5| Step: 3
Training loss: 2.9201061725616455
Validation loss: 2.6694873276577202

Epoch: 5| Step: 4
Training loss: 1.978916883468628
Validation loss: 2.6604896078827562

Epoch: 5| Step: 5
Training loss: 3.263187885284424
Validation loss: 2.6551486138374574

Epoch: 5| Step: 6
Training loss: 1.98468017578125
Validation loss: 2.6299845941605104

Epoch: 5| Step: 7
Training loss: 2.7740678787231445
Validation loss: 2.5936331364416305

Epoch: 5| Step: 8
Training loss: 2.779033660888672
Validation loss: 2.615458852501326

Epoch: 5| Step: 9
Training loss: 3.2302327156066895
Validation loss: 2.5979788995558217

Epoch: 5| Step: 10
Training loss: 2.390972375869751
Validation loss: 2.5840557108643236

Epoch: 24| Step: 0
Training loss: 2.3346734046936035
Validation loss: 2.5672104589400755

Epoch: 5| Step: 1
Training loss: 3.5005428791046143
Validation loss: 2.5439918066865657

Epoch: 5| Step: 2
Training loss: 2.400547742843628
Validation loss: 2.5482087955679944

Epoch: 5| Step: 3
Training loss: 3.0291717052459717
Validation loss: 2.5445855432941067

Epoch: 5| Step: 4
Training loss: 2.7703378200531006
Validation loss: 2.5367285679745417

Epoch: 5| Step: 5
Training loss: 2.6986427307128906
Validation loss: 2.497359227108699

Epoch: 5| Step: 6
Training loss: 3.1028614044189453
Validation loss: 2.4860299915395756

Epoch: 5| Step: 7
Training loss: 2.1481471061706543
Validation loss: 2.4946963505078386

Epoch: 5| Step: 8
Training loss: 3.1274800300598145
Validation loss: 2.4813335851956437

Epoch: 5| Step: 9
Training loss: 2.454963207244873
Validation loss: 2.4898951284347044

Epoch: 5| Step: 10
Training loss: 2.3146719932556152
Validation loss: 2.4666395571924027

Epoch: 25| Step: 0
Training loss: 2.5374157428741455
Validation loss: 2.475242268654608

Epoch: 5| Step: 1
Training loss: 2.8965706825256348
Validation loss: 2.4775389035542807

Epoch: 5| Step: 2
Training loss: 2.252803325653076
Validation loss: 2.451421888925696

Epoch: 5| Step: 3
Training loss: 3.087186574935913
Validation loss: 2.4532791927296627

Epoch: 5| Step: 4
Training loss: 2.0025718212127686
Validation loss: 2.459123965232603

Epoch: 5| Step: 5
Training loss: 2.5838723182678223
Validation loss: 2.436836051684554

Epoch: 5| Step: 6
Training loss: 3.3865838050842285
Validation loss: 2.433695629078855

Epoch: 5| Step: 7
Training loss: 2.8981969356536865
Validation loss: 2.4549331485584216

Epoch: 5| Step: 8
Training loss: 2.4589202404022217
Validation loss: 2.415649716572095

Epoch: 5| Step: 9
Training loss: 2.1824753284454346
Validation loss: 2.428768104122531

Epoch: 5| Step: 10
Training loss: 3.3286190032958984
Validation loss: 2.405177470176451

Epoch: 26| Step: 0
Training loss: 2.589425802230835
Validation loss: 2.429660866337438

Epoch: 5| Step: 1
Training loss: 2.8114876747131348
Validation loss: 2.409383835331086

Epoch: 5| Step: 2
Training loss: 2.7693936824798584
Validation loss: 2.422027067471576

Epoch: 5| Step: 3
Training loss: 2.9545998573303223
Validation loss: 2.416192429040068

Epoch: 5| Step: 4
Training loss: 2.6087334156036377
Validation loss: 2.392879796284501

Epoch: 5| Step: 5
Training loss: 1.921811819076538
Validation loss: 2.3838544276452835

Epoch: 5| Step: 6
Training loss: 2.7396721839904785
Validation loss: 2.4079865435118317

Epoch: 5| Step: 7
Training loss: 2.2680013179779053
Validation loss: 2.4061617235983572

Epoch: 5| Step: 8
Training loss: 3.3166861534118652
Validation loss: 2.414454510135035

Epoch: 5| Step: 9
Training loss: 2.8986668586730957
Validation loss: 2.403437968223326

Epoch: 5| Step: 10
Training loss: 2.1624608039855957
Validation loss: 2.370145618274648

Epoch: 27| Step: 0
Training loss: 2.780574321746826
Validation loss: 2.383497397104899

Epoch: 5| Step: 1
Training loss: 2.492910861968994
Validation loss: 2.37231171002952

Epoch: 5| Step: 2
Training loss: 1.8356647491455078
Validation loss: 2.398182576702487

Epoch: 5| Step: 3
Training loss: 2.898977756500244
Validation loss: 2.380359019002607

Epoch: 5| Step: 4
Training loss: 2.8405985832214355
Validation loss: 2.367797343961654

Epoch: 5| Step: 5
Training loss: 2.812623977661133
Validation loss: 2.3733915975016933

Epoch: 5| Step: 6
Training loss: 3.2062911987304688
Validation loss: 2.3728854181945964

Epoch: 5| Step: 7
Training loss: 2.934412717819214
Validation loss: 2.347093810317337

Epoch: 5| Step: 8
Training loss: 3.165438413619995
Validation loss: 2.3842514791796283

Epoch: 5| Step: 9
Training loss: 2.2533109188079834
Validation loss: 2.3710912709595053

Epoch: 5| Step: 10
Training loss: 1.8371950387954712
Validation loss: 2.355388738775766

Epoch: 28| Step: 0
Training loss: 2.364152669906616
Validation loss: 2.33920911306976

Epoch: 5| Step: 1
Training loss: 2.34055495262146
Validation loss: 2.3779602537872973

Epoch: 5| Step: 2
Training loss: 3.2417101860046387
Validation loss: 2.3586966888878935

Epoch: 5| Step: 3
Training loss: 3.0198960304260254
Validation loss: 2.367428702692832

Epoch: 5| Step: 4
Training loss: 2.3549933433532715
Validation loss: 2.3484394140140985

Epoch: 5| Step: 5
Training loss: 2.7226929664611816
Validation loss: 2.3404312338880313

Epoch: 5| Step: 6
Training loss: 2.343762159347534
Validation loss: 2.3602084088069137

Epoch: 5| Step: 7
Training loss: 3.1344714164733887
Validation loss: 2.3555226043988298

Epoch: 5| Step: 8
Training loss: 2.674243450164795
Validation loss: 2.365974441651375

Epoch: 5| Step: 9
Training loss: 1.8466132879257202
Validation loss: 2.3669856825182514

Epoch: 5| Step: 10
Training loss: 2.9569432735443115
Validation loss: 2.3564931756706646

Epoch: 29| Step: 0
Training loss: 2.4494175910949707
Validation loss: 2.36111101283822

Epoch: 5| Step: 1
Training loss: 2.967817544937134
Validation loss: 2.349776480787544

Epoch: 5| Step: 2
Training loss: 2.182598829269409
Validation loss: 2.3326359769349456

Epoch: 5| Step: 3
Training loss: 2.8688759803771973
Validation loss: 2.3606309634383007

Epoch: 5| Step: 4
Training loss: 2.6871886253356934
Validation loss: 2.357897214992072

Epoch: 5| Step: 5
Training loss: 2.366947889328003
Validation loss: 2.3522340174644225

Epoch: 5| Step: 6
Training loss: 2.4336438179016113
Validation loss: 2.346512367648463

Epoch: 5| Step: 7
Training loss: 2.6855251789093018
Validation loss: 2.328556009518203

Epoch: 5| Step: 8
Training loss: 3.0018839836120605
Validation loss: 2.3267322022427797

Epoch: 5| Step: 9
Training loss: 2.9618911743164062
Validation loss: 2.354529775598998

Epoch: 5| Step: 10
Training loss: 2.2837839126586914
Validation loss: 2.350267797388056

Epoch: 30| Step: 0
Training loss: 2.602612257003784
Validation loss: 2.363451132210352

Epoch: 5| Step: 1
Training loss: 2.4784865379333496
Validation loss: 2.345584423311295

Epoch: 5| Step: 2
Training loss: 2.881021499633789
Validation loss: 2.3419289870928695

Epoch: 5| Step: 3
Training loss: 2.7255969047546387
Validation loss: 2.3425499008547876

Epoch: 5| Step: 4
Training loss: 2.94692325592041
Validation loss: 2.334880380220311

Epoch: 5| Step: 5
Training loss: 2.1657819747924805
Validation loss: 2.3285328162613737

Epoch: 5| Step: 6
Training loss: 2.972907781600952
Validation loss: 2.325446762064452

Epoch: 5| Step: 7
Training loss: 2.306807041168213
Validation loss: 2.3317271740205827

Epoch: 5| Step: 8
Training loss: 2.614401340484619
Validation loss: 2.3282442887624106

Epoch: 5| Step: 9
Training loss: 2.9450936317443848
Validation loss: 2.356242137570535

Epoch: 5| Step: 10
Training loss: 2.180675506591797
Validation loss: 2.3170868837705223

Epoch: 31| Step: 0
Training loss: 2.687363386154175
Validation loss: 2.344795032214093

Epoch: 5| Step: 1
Training loss: 3.172685146331787
Validation loss: 2.3331815683713524

Epoch: 5| Step: 2
Training loss: 2.6910958290100098
Validation loss: 2.327298164367676

Epoch: 5| Step: 3
Training loss: 2.7014083862304688
Validation loss: 2.3389548845188592

Epoch: 5| Step: 4
Training loss: 2.744253158569336
Validation loss: 2.332957488234325

Epoch: 5| Step: 5
Training loss: 2.471369743347168
Validation loss: 2.325724870927872

Epoch: 5| Step: 6
Training loss: 2.238706588745117
Validation loss: 2.335458437601725

Epoch: 5| Step: 7
Training loss: 2.2075958251953125
Validation loss: 2.3504420300965667

Epoch: 5| Step: 8
Training loss: 2.6076717376708984
Validation loss: 2.315006163812453

Epoch: 5| Step: 9
Training loss: 2.5976481437683105
Validation loss: 2.3269581487101894

Epoch: 5| Step: 10
Training loss: 2.7948875427246094
Validation loss: 2.338572084262807

Epoch: 32| Step: 0
Training loss: 2.4122462272644043
Validation loss: 2.3380780578941427

Epoch: 5| Step: 1
Training loss: 2.3068480491638184
Validation loss: 2.3581865833651636

Epoch: 5| Step: 2
Training loss: 3.077497720718384
Validation loss: 2.3346969645510436

Epoch: 5| Step: 3
Training loss: 3.0005440711975098
Validation loss: 2.3289842990136917

Epoch: 5| Step: 4
Training loss: 2.564754009246826
Validation loss: 2.325135833473616

Epoch: 5| Step: 5
Training loss: 2.023132085800171
Validation loss: 2.320010495442216

Epoch: 5| Step: 6
Training loss: 2.538710832595825
Validation loss: 2.321838476324594

Epoch: 5| Step: 7
Training loss: 2.439863681793213
Validation loss: 2.3589939660923456

Epoch: 5| Step: 8
Training loss: 2.525235891342163
Validation loss: 2.33063470291835

Epoch: 5| Step: 9
Training loss: 2.701423168182373
Validation loss: 2.338311513264974

Epoch: 5| Step: 10
Training loss: 3.1984808444976807
Validation loss: 2.342785717338644

Epoch: 33| Step: 0
Training loss: 2.717329502105713
Validation loss: 2.3148994855983283

Epoch: 5| Step: 1
Training loss: 2.228332281112671
Validation loss: 2.3335418547353437

Epoch: 5| Step: 2
Training loss: 3.1380066871643066
Validation loss: 2.3315094927305817

Epoch: 5| Step: 3
Training loss: 2.270745038986206
Validation loss: 2.332640233860221

Epoch: 5| Step: 4
Training loss: 2.4330761432647705
Validation loss: 2.3407742656687254

Epoch: 5| Step: 5
Training loss: 2.8909239768981934
Validation loss: 2.3297946991459018

Epoch: 5| Step: 6
Training loss: 2.633265256881714
Validation loss: 2.3070631719404653

Epoch: 5| Step: 7
Training loss: 2.6008875370025635
Validation loss: 2.3285456524100354

Epoch: 5| Step: 8
Training loss: 2.7903308868408203
Validation loss: 2.294681901572853

Epoch: 5| Step: 9
Training loss: 2.476963520050049
Validation loss: 2.3303899483014177

Epoch: 5| Step: 10
Training loss: 2.467714786529541
Validation loss: 2.304665134799096

Epoch: 34| Step: 0
Training loss: 2.762810230255127
Validation loss: 2.3247786952603247

Epoch: 5| Step: 1
Training loss: 2.7099037170410156
Validation loss: 2.335199802152572

Epoch: 5| Step: 2
Training loss: 2.222226619720459
Validation loss: 2.3251253366470337

Epoch: 5| Step: 3
Training loss: 2.4473278522491455
Validation loss: 2.3328643742428032

Epoch: 5| Step: 4
Training loss: 2.7039153575897217
Validation loss: 2.3460248772815993

Epoch: 5| Step: 5
Training loss: 2.3078341484069824
Validation loss: 2.3219006907555366

Epoch: 5| Step: 6
Training loss: 2.402087450027466
Validation loss: 2.3123730177520425

Epoch: 5| Step: 7
Training loss: 2.8154215812683105
Validation loss: 2.325983493558822

Epoch: 5| Step: 8
Training loss: 3.0148396492004395
Validation loss: 2.327832461685263

Epoch: 5| Step: 9
Training loss: 2.7316105365753174
Validation loss: 2.334785394771125

Epoch: 5| Step: 10
Training loss: 2.3921074867248535
Validation loss: 2.321285991258519

Epoch: 35| Step: 0
Training loss: 2.191066265106201
Validation loss: 2.3037662916286017

Epoch: 5| Step: 1
Training loss: 2.69803786277771
Validation loss: 2.3070539325796147

Epoch: 5| Step: 2
Training loss: 2.758998155593872
Validation loss: 2.313388668080812

Epoch: 5| Step: 3
Training loss: 2.30595064163208
Validation loss: 2.323391547767065

Epoch: 5| Step: 4
Training loss: 2.6973578929901123
Validation loss: 2.3213654923182663

Epoch: 5| Step: 5
Training loss: 2.05487060546875
Validation loss: 2.3169306862738823

Epoch: 5| Step: 6
Training loss: 2.648353099822998
Validation loss: 2.3256101710821993

Epoch: 5| Step: 7
Training loss: 2.8323967456817627
Validation loss: 2.337098844589726

Epoch: 5| Step: 8
Training loss: 3.054833173751831
Validation loss: 2.312371407785723

Epoch: 5| Step: 9
Training loss: 2.6493349075317383
Validation loss: 2.3175938924153647

Epoch: 5| Step: 10
Training loss: 2.5686147212982178
Validation loss: 2.305506698546871

Epoch: 36| Step: 0
Training loss: 2.1614108085632324
Validation loss: 2.306866379194362

Epoch: 5| Step: 1
Training loss: 2.886054277420044
Validation loss: 2.324151333942208

Epoch: 5| Step: 2
Training loss: 2.5373802185058594
Validation loss: 2.2968215070744997

Epoch: 5| Step: 3
Training loss: 2.8503482341766357
Validation loss: 2.3156273339384343

Epoch: 5| Step: 4
Training loss: 2.5417606830596924
Validation loss: 2.3076827103091824

Epoch: 5| Step: 5
Training loss: 2.6554207801818848
Validation loss: 2.3144839758514077

Epoch: 5| Step: 6
Training loss: 2.0556416511535645
Validation loss: 2.31546607581518

Epoch: 5| Step: 7
Training loss: 3.5383613109588623
Validation loss: 2.2970038895965903

Epoch: 5| Step: 8
Training loss: 2.7445600032806396
Validation loss: 2.305000343630391

Epoch: 5| Step: 9
Training loss: 1.7992206811904907
Validation loss: 2.3263471434193272

Epoch: 5| Step: 10
Training loss: 2.8112921714782715
Validation loss: 2.317068548612697

Epoch: 37| Step: 0
Training loss: 2.9404194355010986
Validation loss: 2.295380679509973

Epoch: 5| Step: 1
Training loss: 3.073002815246582
Validation loss: 2.3268815663553055

Epoch: 5| Step: 2
Training loss: 2.4797117710113525
Validation loss: 2.3369196512365855

Epoch: 5| Step: 3
Training loss: 3.0080957412719727
Validation loss: 2.309152712104141

Epoch: 5| Step: 4
Training loss: 2.5793349742889404
Validation loss: 2.293594468024469

Epoch: 5| Step: 5
Training loss: 2.105085849761963
Validation loss: 2.3035762310028076

Epoch: 5| Step: 6
Training loss: 2.4046683311462402
Validation loss: 2.3085049224156204

Epoch: 5| Step: 7
Training loss: 2.0710256099700928
Validation loss: 2.3045917095676547

Epoch: 5| Step: 8
Training loss: 2.248584032058716
Validation loss: 2.2867062912192395

Epoch: 5| Step: 9
Training loss: 2.5740597248077393
Validation loss: 2.296416997909546

Epoch: 5| Step: 10
Training loss: 2.8860034942626953
Validation loss: 2.304819154483016

Epoch: 38| Step: 0
Training loss: 2.190521478652954
Validation loss: 2.2876904728592082

Epoch: 5| Step: 1
Training loss: 2.402951717376709
Validation loss: 2.3105734381624448

Epoch: 5| Step: 2
Training loss: 2.593764543533325
Validation loss: 2.295444410334351

Epoch: 5| Step: 3
Training loss: 2.052454710006714
Validation loss: 2.3002410832271782

Epoch: 5| Step: 4
Training loss: 2.2426114082336426
Validation loss: 2.303026709505307

Epoch: 5| Step: 5
Training loss: 2.6135220527648926
Validation loss: 2.2951656131334204

Epoch: 5| Step: 6
Training loss: 2.415534019470215
Validation loss: 2.303826642292802

Epoch: 5| Step: 7
Training loss: 3.330475330352783
Validation loss: 2.310448723454629

Epoch: 5| Step: 8
Training loss: 2.9389147758483887
Validation loss: 2.2995481324452225

Epoch: 5| Step: 9
Training loss: 2.6504533290863037
Validation loss: 2.295439430462417

Epoch: 5| Step: 10
Training loss: 2.701739549636841
Validation loss: 2.288173467882218

Epoch: 39| Step: 0
Training loss: 2.091548442840576
Validation loss: 2.313505398329868

Epoch: 5| Step: 1
Training loss: 3.110112190246582
Validation loss: 2.303198799010246

Epoch: 5| Step: 2
Training loss: 1.8692601919174194
Validation loss: 2.2914449348244617

Epoch: 5| Step: 3
Training loss: 2.491758346557617
Validation loss: 2.291745852398616

Epoch: 5| Step: 4
Training loss: 2.950345993041992
Validation loss: 2.2875618832085722

Epoch: 5| Step: 5
Training loss: 2.7393710613250732
Validation loss: 2.2782131625759985

Epoch: 5| Step: 6
Training loss: 2.37243390083313
Validation loss: 2.2921369665412494

Epoch: 5| Step: 7
Training loss: 2.5201022624969482
Validation loss: 2.298368371942992

Epoch: 5| Step: 8
Training loss: 2.1120383739471436
Validation loss: 2.2954560146536878

Epoch: 5| Step: 9
Training loss: 3.0953738689422607
Validation loss: 2.2990111804777578

Epoch: 5| Step: 10
Training loss: 3.0034823417663574
Validation loss: 2.2850751312830115

Epoch: 40| Step: 0
Training loss: 1.885000228881836
Validation loss: 2.2755320802811654

Epoch: 5| Step: 1
Training loss: 2.4458746910095215
Validation loss: 2.289487825926914

Epoch: 5| Step: 2
Training loss: 2.6714835166931152
Validation loss: 2.290631195550324

Epoch: 5| Step: 3
Training loss: 2.8553271293640137
Validation loss: 2.289087657005556

Epoch: 5| Step: 4
Training loss: 2.2695250511169434
Validation loss: 2.29882336431934

Epoch: 5| Step: 5
Training loss: 2.2360000610351562
Validation loss: 2.3024316936410885

Epoch: 5| Step: 6
Training loss: 2.744772434234619
Validation loss: 2.2768267739203667

Epoch: 5| Step: 7
Training loss: 2.838449716567993
Validation loss: 2.292390708000429

Epoch: 5| Step: 8
Training loss: 3.0338637828826904
Validation loss: 2.2792414260166947

Epoch: 5| Step: 9
Training loss: 2.647212266921997
Validation loss: 2.2673650813359085

Epoch: 5| Step: 10
Training loss: 2.577252149581909
Validation loss: 2.303958245503005

Epoch: 41| Step: 0
Training loss: 2.771486759185791
Validation loss: 2.295592079880417

Epoch: 5| Step: 1
Training loss: 2.2845168113708496
Validation loss: 2.270266475216035

Epoch: 5| Step: 2
Training loss: 2.9319140911102295
Validation loss: 2.288491790012647

Epoch: 5| Step: 3
Training loss: 2.6801435947418213
Validation loss: 2.2828543006732898

Epoch: 5| Step: 4
Training loss: 2.4529433250427246
Validation loss: 2.2881260674486876

Epoch: 5| Step: 5
Training loss: 2.728912830352783
Validation loss: 2.2967994008012997

Epoch: 5| Step: 6
Training loss: 2.395428419113159
Validation loss: 2.2916880987023793

Epoch: 5| Step: 7
Training loss: 2.369274854660034
Validation loss: 2.290754210564398

Epoch: 5| Step: 8
Training loss: 2.5118789672851562
Validation loss: 2.3050646294829664

Epoch: 5| Step: 9
Training loss: 2.6987929344177246
Validation loss: 2.284885952549596

Epoch: 5| Step: 10
Training loss: 2.340099573135376
Validation loss: 2.28090000665316

Epoch: 42| Step: 0
Training loss: 2.882760524749756
Validation loss: 2.2706249862588863

Epoch: 5| Step: 1
Training loss: 2.3436503410339355
Validation loss: 2.262556532377838

Epoch: 5| Step: 2
Training loss: 2.5161566734313965
Validation loss: 2.2811349925174507

Epoch: 5| Step: 3
Training loss: 2.6184866428375244
Validation loss: 2.2917544828948153

Epoch: 5| Step: 4
Training loss: 2.6247732639312744
Validation loss: 2.2859105858751523

Epoch: 5| Step: 5
Training loss: 2.469907283782959
Validation loss: 2.2859305848357496

Epoch: 5| Step: 6
Training loss: 3.115697145462036
Validation loss: 2.2746229953663324

Epoch: 5| Step: 7
Training loss: 1.8121469020843506
Validation loss: 2.2687324490598453

Epoch: 5| Step: 8
Training loss: 3.2483551502227783
Validation loss: 2.272218883678477

Epoch: 5| Step: 9
Training loss: 2.1909985542297363
Validation loss: 2.2717183430989585

Epoch: 5| Step: 10
Training loss: 2.106842041015625
Validation loss: 2.269342178939491

Epoch: 43| Step: 0
Training loss: 2.4999051094055176
Validation loss: 2.2675976573780017

Epoch: 5| Step: 1
Training loss: 2.7389793395996094
Validation loss: 2.2695071722871516

Epoch: 5| Step: 2
Training loss: 2.83353328704834
Validation loss: 2.28501582402055

Epoch: 5| Step: 3
Training loss: 2.763080596923828
Validation loss: 2.2901486248098393

Epoch: 5| Step: 4
Training loss: 2.6317875385284424
Validation loss: 2.256892773412889

Epoch: 5| Step: 5
Training loss: 2.5728023052215576
Validation loss: 2.268510572371944

Epoch: 5| Step: 6
Training loss: 1.9131412506103516
Validation loss: 2.271065794011598

Epoch: 5| Step: 7
Training loss: 2.932816505432129
Validation loss: 2.259560295330581

Epoch: 5| Step: 8
Training loss: 2.0562567710876465
Validation loss: 2.283775470590079

Epoch: 5| Step: 9
Training loss: 2.572049140930176
Validation loss: 2.2574574844811552

Epoch: 5| Step: 10
Training loss: 2.4251468181610107
Validation loss: 2.2659212978937293

Epoch: 44| Step: 0
Training loss: 2.295598268508911
Validation loss: 2.2799114078603764

Epoch: 5| Step: 1
Training loss: 3.2376391887664795
Validation loss: 2.2910390797481743

Epoch: 5| Step: 2
Training loss: 2.374133348464966
Validation loss: 2.262423410210558

Epoch: 5| Step: 3
Training loss: 2.5848605632781982
Validation loss: 2.264383259639945

Epoch: 5| Step: 4
Training loss: 1.7513172626495361
Validation loss: 2.2548178498462965

Epoch: 5| Step: 5
Training loss: 2.585650682449341
Validation loss: 2.2688278382824314

Epoch: 5| Step: 6
Training loss: 2.417158603668213
Validation loss: 2.2559589942296348

Epoch: 5| Step: 7
Training loss: 2.196500301361084
Validation loss: 2.271084767515941

Epoch: 5| Step: 8
Training loss: 2.5961241722106934
Validation loss: 2.2593480617769304

Epoch: 5| Step: 9
Training loss: 3.3761603832244873
Validation loss: 2.2476733974231187

Epoch: 5| Step: 10
Training loss: 2.3421947956085205
Validation loss: 2.263775166644845

Epoch: 45| Step: 0
Training loss: 2.957697629928589
Validation loss: 2.2819053896011843

Epoch: 5| Step: 1
Training loss: 2.2649664878845215
Validation loss: 2.251601681914381

Epoch: 5| Step: 2
Training loss: 2.239515781402588
Validation loss: 2.2849368997799453

Epoch: 5| Step: 3
Training loss: 2.716073989868164
Validation loss: 2.249244092613138

Epoch: 5| Step: 4
Training loss: 2.513456344604492
Validation loss: 2.2638119805243706

Epoch: 5| Step: 5
Training loss: 2.3359670639038086
Validation loss: 2.230144598150766

Epoch: 5| Step: 6
Training loss: 2.5436928272247314
Validation loss: 2.2692925160931003

Epoch: 5| Step: 7
Training loss: 2.244597911834717
Validation loss: 2.2296902979573896

Epoch: 5| Step: 8
Training loss: 1.9984161853790283
Validation loss: 2.2685435484814387

Epoch: 5| Step: 9
Training loss: 2.241702079772949
Validation loss: 2.269817634295392

Epoch: 5| Step: 10
Training loss: 3.896122694015503
Validation loss: 2.2533945704019196

Epoch: 46| Step: 0
Training loss: 3.3446431159973145
Validation loss: 2.242315653831728

Epoch: 5| Step: 1
Training loss: 1.9400568008422852
Validation loss: 2.2531174587947067

Epoch: 5| Step: 2
Training loss: 2.723930835723877
Validation loss: 2.230029349685997

Epoch: 5| Step: 3
Training loss: 2.897047758102417
Validation loss: 2.253362609494117

Epoch: 5| Step: 4
Training loss: 2.1920595169067383
Validation loss: 2.2623873884959886

Epoch: 5| Step: 5
Training loss: 1.7665144205093384
Validation loss: 2.248855757456954

Epoch: 5| Step: 6
Training loss: 2.694507122039795
Validation loss: 2.2475102306694112

Epoch: 5| Step: 7
Training loss: 2.5749831199645996
Validation loss: 2.26273258783484

Epoch: 5| Step: 8
Training loss: 2.941739082336426
Validation loss: 2.2553925321948145

Epoch: 5| Step: 9
Training loss: 2.9153409004211426
Validation loss: 2.2505952465918755

Epoch: 5| Step: 10
Training loss: 1.7557697296142578
Validation loss: 2.2464933728659027

Epoch: 47| Step: 0
Training loss: 2.119171619415283
Validation loss: 2.256702735859861

Epoch: 5| Step: 1
Training loss: 2.8618111610412598
Validation loss: 2.2485984089553996

Epoch: 5| Step: 2
Training loss: 2.188567638397217
Validation loss: 2.248184223328867

Epoch: 5| Step: 3
Training loss: 2.8284873962402344
Validation loss: 2.246572748307259

Epoch: 5| Step: 4
Training loss: 2.947976589202881
Validation loss: 2.2671742772543304

Epoch: 5| Step: 5
Training loss: 2.2812917232513428
Validation loss: 2.2524622601847493

Epoch: 5| Step: 6
Training loss: 2.1330254077911377
Validation loss: 2.2313691762185868

Epoch: 5| Step: 7
Training loss: 2.776601791381836
Validation loss: 2.254792905622913

Epoch: 5| Step: 8
Training loss: 2.670478343963623
Validation loss: 2.216467885560887

Epoch: 5| Step: 9
Training loss: 2.1551342010498047
Validation loss: 2.2320577072840866

Epoch: 5| Step: 10
Training loss: 2.7141246795654297
Validation loss: 2.233920205023981

Epoch: 48| Step: 0
Training loss: 2.6195905208587646
Validation loss: 2.2491350789223947

Epoch: 5| Step: 1
Training loss: 2.194716691970825
Validation loss: 2.2555818865376134

Epoch: 5| Step: 2
Training loss: 2.366492748260498
Validation loss: 2.254133491105931

Epoch: 5| Step: 3
Training loss: 2.627530097961426
Validation loss: 2.2384925811521468

Epoch: 5| Step: 4
Training loss: 2.330899238586426
Validation loss: 2.261975662682646

Epoch: 5| Step: 5
Training loss: 2.4860422611236572
Validation loss: 2.2350965917751355

Epoch: 5| Step: 6
Training loss: 3.179680109024048
Validation loss: 2.2562972678933093

Epoch: 5| Step: 7
Training loss: 2.006105422973633
Validation loss: 2.2281636473953084

Epoch: 5| Step: 8
Training loss: 2.536377429962158
Validation loss: 2.233894395571883

Epoch: 5| Step: 9
Training loss: 2.8166770935058594
Validation loss: 2.228132317143102

Epoch: 5| Step: 10
Training loss: 2.40549373626709
Validation loss: 2.2437304040437103

Epoch: 49| Step: 0
Training loss: 2.797088146209717
Validation loss: 2.236946536648658

Epoch: 5| Step: 1
Training loss: 2.2566733360290527
Validation loss: 2.2399302528750513

Epoch: 5| Step: 2
Training loss: 2.0244698524475098
Validation loss: 2.2398123741149902

Epoch: 5| Step: 3
Training loss: 2.48899507522583
Validation loss: 2.254061375894854

Epoch: 5| Step: 4
Training loss: 2.5090060234069824
Validation loss: 2.260204830477315

Epoch: 5| Step: 5
Training loss: 3.0298702716827393
Validation loss: 2.20472538855768

Epoch: 5| Step: 6
Training loss: 2.425363779067993
Validation loss: 2.237322827821137

Epoch: 5| Step: 7
Training loss: 2.8794898986816406
Validation loss: 2.2392186605802147

Epoch: 5| Step: 8
Training loss: 2.0698981285095215
Validation loss: 2.2447164725231867

Epoch: 5| Step: 9
Training loss: 2.306849956512451
Validation loss: 2.2397346906764533

Epoch: 5| Step: 10
Training loss: 2.7116615772247314
Validation loss: 2.2386370089746292

Epoch: 50| Step: 0
Training loss: 2.309556245803833
Validation loss: 2.229436589825538

Epoch: 5| Step: 1
Training loss: 2.6933205127716064
Validation loss: 2.2350000976234354

Epoch: 5| Step: 2
Training loss: 2.9775302410125732
Validation loss: 2.2320468707751204

Epoch: 5| Step: 3
Training loss: 1.9301700592041016
Validation loss: 2.2306205521347704

Epoch: 5| Step: 4
Training loss: 1.7390835285186768
Validation loss: 2.216818460854151

Epoch: 5| Step: 5
Training loss: 2.2552456855773926
Validation loss: 2.2450962246105237

Epoch: 5| Step: 6
Training loss: 2.5638182163238525
Validation loss: 2.2413408243527977

Epoch: 5| Step: 7
Training loss: 2.957017421722412
Validation loss: 2.2563568930472098

Epoch: 5| Step: 8
Training loss: 2.6278624534606934
Validation loss: 2.2279060450933312

Epoch: 5| Step: 9
Training loss: 2.9430766105651855
Validation loss: 2.219718692123249

Epoch: 5| Step: 10
Training loss: 2.3195412158966064
Validation loss: 2.234766298724759

Epoch: 51| Step: 0
Training loss: 2.48361873626709
Validation loss: 2.2210094980014268

Epoch: 5| Step: 1
Training loss: 3.0356335639953613
Validation loss: 2.2147147706759873

Epoch: 5| Step: 2
Training loss: 1.7819328308105469
Validation loss: 2.2404959906813917

Epoch: 5| Step: 3
Training loss: 2.4615490436553955
Validation loss: 2.228268059351111

Epoch: 5| Step: 4
Training loss: 2.4376509189605713
Validation loss: 2.239455287174512

Epoch: 5| Step: 5
Training loss: 2.7101891040802
Validation loss: 2.2305350995832876

Epoch: 5| Step: 6
Training loss: 2.2399239540100098
Validation loss: 2.228670238166727

Epoch: 5| Step: 7
Training loss: 2.7392234802246094
Validation loss: 2.2157824193277667

Epoch: 5| Step: 8
Training loss: 1.9962810277938843
Validation loss: 2.253371987291562

Epoch: 5| Step: 9
Training loss: 2.548713445663452
Validation loss: 2.241132656733195

Epoch: 5| Step: 10
Training loss: 3.054119348526001
Validation loss: 2.2506728582484747

Epoch: 52| Step: 0
Training loss: 3.0913825035095215
Validation loss: 2.244927167892456

Epoch: 5| Step: 1
Training loss: 2.090938091278076
Validation loss: 2.2087705801892024

Epoch: 5| Step: 2
Training loss: 2.323300361633301
Validation loss: 2.2270005390208256

Epoch: 5| Step: 3
Training loss: 2.404531955718994
Validation loss: 2.241452973376038

Epoch: 5| Step: 4
Training loss: 2.8933963775634766
Validation loss: 2.2318546733548565

Epoch: 5| Step: 5
Training loss: 2.0668320655822754
Validation loss: 2.2127994978299705

Epoch: 5| Step: 6
Training loss: 1.9976203441619873
Validation loss: 2.2119105067304385

Epoch: 5| Step: 7
Training loss: 2.8594138622283936
Validation loss: 2.2304704984029136

Epoch: 5| Step: 8
Training loss: 1.915910005569458
Validation loss: 2.2155171517402894

Epoch: 5| Step: 9
Training loss: 3.2586090564727783
Validation loss: 2.22785125752931

Epoch: 5| Step: 10
Training loss: 2.5612430572509766
Validation loss: 2.233527637297107

Epoch: 53| Step: 0
Training loss: 2.1915228366851807
Validation loss: 2.2095065168155137

Epoch: 5| Step: 1
Training loss: 2.535202741622925
Validation loss: 2.2206141410335416

Epoch: 5| Step: 2
Training loss: 2.3593153953552246
Validation loss: 2.215563658745058

Epoch: 5| Step: 3
Training loss: 2.7018299102783203
Validation loss: 2.217739100097328

Epoch: 5| Step: 4
Training loss: 2.0601284503936768
Validation loss: 2.244402309899689

Epoch: 5| Step: 5
Training loss: 3.4806957244873047
Validation loss: 2.1912509369593796

Epoch: 5| Step: 6
Training loss: 2.3442740440368652
Validation loss: 2.2041520213568084

Epoch: 5| Step: 7
Training loss: 2.912440299987793
Validation loss: 2.2425426795918453

Epoch: 5| Step: 8
Training loss: 2.3176093101501465
Validation loss: 2.236919305657828

Epoch: 5| Step: 9
Training loss: 1.700710654258728
Validation loss: 2.213813799683766

Epoch: 5| Step: 10
Training loss: 2.793055534362793
Validation loss: 2.1895768180970223

Epoch: 54| Step: 0
Training loss: 2.1204779148101807
Validation loss: 2.2020621915017404

Epoch: 5| Step: 1
Training loss: 2.934705972671509
Validation loss: 2.2047433340421287

Epoch: 5| Step: 2
Training loss: 2.8420238494873047
Validation loss: 2.1963589755437707

Epoch: 5| Step: 3
Training loss: 2.9761462211608887
Validation loss: 2.2149456777880268

Epoch: 5| Step: 4
Training loss: 2.792874813079834
Validation loss: 2.215255791141141

Epoch: 5| Step: 5
Training loss: 2.1537559032440186
Validation loss: 2.2179648030188774

Epoch: 5| Step: 6
Training loss: 2.432739734649658
Validation loss: 2.202813151062176

Epoch: 5| Step: 7
Training loss: 2.1119465827941895
Validation loss: 2.2323317886680685

Epoch: 5| Step: 8
Training loss: 1.7992528676986694
Validation loss: 2.1972684296228553

Epoch: 5| Step: 9
Training loss: 2.985121726989746
Validation loss: 2.2147151911130516

Epoch: 5| Step: 10
Training loss: 1.9824610948562622
Validation loss: 2.1871154718501593

Epoch: 55| Step: 0
Training loss: 2.571916103363037
Validation loss: 2.2092576026916504

Epoch: 5| Step: 1
Training loss: 2.655782699584961
Validation loss: 2.215023955991191

Epoch: 5| Step: 2
Training loss: 2.4237470626831055
Validation loss: 2.220873753229777

Epoch: 5| Step: 3
Training loss: 2.0500292778015137
Validation loss: 2.2320801417032876

Epoch: 5| Step: 4
Training loss: 2.2498183250427246
Validation loss: 2.2148153487072197

Epoch: 5| Step: 5
Training loss: 2.833343505859375
Validation loss: 2.202105942592826

Epoch: 5| Step: 6
Training loss: 2.359175443649292
Validation loss: 2.1920197625314035

Epoch: 5| Step: 7
Training loss: 2.4920005798339844
Validation loss: 2.2086874028687835

Epoch: 5| Step: 8
Training loss: 2.3500547409057617
Validation loss: 2.2129019819280153

Epoch: 5| Step: 9
Training loss: 2.6984446048736572
Validation loss: 2.2357953633031538

Epoch: 5| Step: 10
Training loss: 2.550750494003296
Validation loss: 2.189551589309528

Epoch: 56| Step: 0
Training loss: 2.2881014347076416
Validation loss: 2.2076536737462527

Epoch: 5| Step: 1
Training loss: 2.650369644165039
Validation loss: 2.207760344269455

Epoch: 5| Step: 2
Training loss: 2.5002381801605225
Validation loss: 2.1927036905801423

Epoch: 5| Step: 3
Training loss: 2.5833981037139893
Validation loss: 2.207170090367717

Epoch: 5| Step: 4
Training loss: 2.347708225250244
Validation loss: 2.2168157357041554

Epoch: 5| Step: 5
Training loss: 1.9834884405136108
Validation loss: 2.2179527923625004

Epoch: 5| Step: 6
Training loss: 2.4647741317749023
Validation loss: 2.186613675086729

Epoch: 5| Step: 7
Training loss: 2.87237811088562
Validation loss: 2.20203830862558

Epoch: 5| Step: 8
Training loss: 2.8358232975006104
Validation loss: 2.2116695322016233

Epoch: 5| Step: 9
Training loss: 2.27190899848938
Validation loss: 2.213076978601435

Epoch: 5| Step: 10
Training loss: 2.198005199432373
Validation loss: 2.2225213858389083

Epoch: 57| Step: 0
Training loss: 2.3104782104492188
Validation loss: 2.216051975886027

Epoch: 5| Step: 1
Training loss: 2.5793280601501465
Validation loss: 2.222839270868609

Epoch: 5| Step: 2
Training loss: 2.6521427631378174
Validation loss: 2.2106998325676046

Epoch: 5| Step: 3
Training loss: 3.2181525230407715
Validation loss: 2.2130604995194303

Epoch: 5| Step: 4
Training loss: 1.904732346534729
Validation loss: 2.1858635538367817

Epoch: 5| Step: 5
Training loss: 2.631126880645752
Validation loss: 2.209504178775254

Epoch: 5| Step: 6
Training loss: 2.1786704063415527
Validation loss: 2.202474546688859

Epoch: 5| Step: 7
Training loss: 2.62345814704895
Validation loss: 2.2035843300563034

Epoch: 5| Step: 8
Training loss: 2.180589199066162
Validation loss: 2.1906661295121714

Epoch: 5| Step: 9
Training loss: 1.9407447576522827
Validation loss: 2.18950750238152

Epoch: 5| Step: 10
Training loss: 2.584794521331787
Validation loss: 2.2134337425231934

Epoch: 58| Step: 0
Training loss: 2.3984429836273193
Validation loss: 2.209822679078707

Epoch: 5| Step: 1
Training loss: 2.9452507495880127
Validation loss: 2.2053622174006637

Epoch: 5| Step: 2
Training loss: 1.8485454320907593
Validation loss: 2.1969522071141068

Epoch: 5| Step: 3
Training loss: 2.6773383617401123
Validation loss: 2.203936226906315

Epoch: 5| Step: 4
Training loss: 2.394397735595703
Validation loss: 2.201433474017728

Epoch: 5| Step: 5
Training loss: 2.8825440406799316
Validation loss: 2.172364100333183

Epoch: 5| Step: 6
Training loss: 2.616441488265991
Validation loss: 2.1939168463471117

Epoch: 5| Step: 7
Training loss: 2.341409683227539
Validation loss: 2.2096842617116947

Epoch: 5| Step: 8
Training loss: 2.4444167613983154
Validation loss: 2.194062679044662

Epoch: 5| Step: 9
Training loss: 2.0641162395477295
Validation loss: 2.212249989150673

Epoch: 5| Step: 10
Training loss: 2.234126091003418
Validation loss: 2.217008803480415

Epoch: 59| Step: 0
Training loss: 2.315934896469116
Validation loss: 2.216514951439314

Epoch: 5| Step: 1
Training loss: 2.380687713623047
Validation loss: 2.1873280130406862

Epoch: 5| Step: 2
Training loss: 2.733297824859619
Validation loss: 2.2160015926566174

Epoch: 5| Step: 3
Training loss: 2.7792186737060547
Validation loss: 2.193921107117848

Epoch: 5| Step: 4
Training loss: 2.579258441925049
Validation loss: 2.1970483615834224

Epoch: 5| Step: 5
Training loss: 2.4495768547058105
Validation loss: 2.208069024547454

Epoch: 5| Step: 6
Training loss: 2.2072887420654297
Validation loss: 2.197787582233388

Epoch: 5| Step: 7
Training loss: 1.9035812616348267
Validation loss: 2.173298312771705

Epoch: 5| Step: 8
Training loss: 1.6809202432632446
Validation loss: 2.1799011127923125

Epoch: 5| Step: 9
Training loss: 2.841042995452881
Validation loss: 2.189964084215062

Epoch: 5| Step: 10
Training loss: 3.0260777473449707
Validation loss: 2.1887271468357374

Epoch: 60| Step: 0
Training loss: 2.6443469524383545
Validation loss: 2.208150863647461

Epoch: 5| Step: 1
Training loss: 2.608215093612671
Validation loss: 2.177542289098104

Epoch: 5| Step: 2
Training loss: 2.138453722000122
Validation loss: 2.1893249891137563

Epoch: 5| Step: 3
Training loss: 2.434920072555542
Validation loss: 2.179429537506514

Epoch: 5| Step: 4
Training loss: 2.3387253284454346
Validation loss: 2.183829060164831

Epoch: 5| Step: 5
Training loss: 2.204932689666748
Validation loss: 2.177047206509498

Epoch: 5| Step: 6
Training loss: 2.9691803455352783
Validation loss: 2.188555666195449

Epoch: 5| Step: 7
Training loss: 1.957585096359253
Validation loss: 2.1613343505449194

Epoch: 5| Step: 8
Training loss: 2.6237428188323975
Validation loss: 2.1988505240409606

Epoch: 5| Step: 9
Training loss: 3.065621852874756
Validation loss: 2.172884107917868

Epoch: 5| Step: 10
Training loss: 1.8094428777694702
Validation loss: 2.1930028828241492

Epoch: 61| Step: 0
Training loss: 1.6263424158096313
Validation loss: 2.1676424267471477

Epoch: 5| Step: 1
Training loss: 2.4105172157287598
Validation loss: 2.1901429442949194

Epoch: 5| Step: 2
Training loss: 2.5920207500457764
Validation loss: 2.177811889238255

Epoch: 5| Step: 3
Training loss: 2.2955679893493652
Validation loss: 2.1697341088325746

Epoch: 5| Step: 4
Training loss: 2.0471322536468506
Validation loss: 2.1650199813227498

Epoch: 5| Step: 5
Training loss: 1.9261852502822876
Validation loss: 2.1903254293626353

Epoch: 5| Step: 6
Training loss: 2.542018175125122
Validation loss: 2.163750256261518

Epoch: 5| Step: 7
Training loss: 2.8229548931121826
Validation loss: 2.158087166406775

Epoch: 5| Step: 8
Training loss: 2.862928867340088
Validation loss: 2.1545359229528778

Epoch: 5| Step: 9
Training loss: 2.2104439735412598
Validation loss: 2.1780013832994687

Epoch: 5| Step: 10
Training loss: 3.4642293453216553
Validation loss: 2.17185309497259

Epoch: 62| Step: 0
Training loss: 2.4952547550201416
Validation loss: 2.1519767622793875

Epoch: 5| Step: 1
Training loss: 2.2819085121154785
Validation loss: 2.160058565037225

Epoch: 5| Step: 2
Training loss: 2.2219138145446777
Validation loss: 2.169438208303144

Epoch: 5| Step: 3
Training loss: 2.6096138954162598
Validation loss: 2.17126307436215

Epoch: 5| Step: 4
Training loss: 2.5352089405059814
Validation loss: 2.1657218856196248

Epoch: 5| Step: 5
Training loss: 2.492051124572754
Validation loss: 2.1641770716636413

Epoch: 5| Step: 6
Training loss: 2.4824774265289307
Validation loss: 2.159954288954376

Epoch: 5| Step: 7
Training loss: 2.323638439178467
Validation loss: 2.169374665906352

Epoch: 5| Step: 8
Training loss: 2.6348652839660645
Validation loss: 2.1589624907380793

Epoch: 5| Step: 9
Training loss: 1.9904712438583374
Validation loss: 2.1876024712798414

Epoch: 5| Step: 10
Training loss: 2.4891486167907715
Validation loss: 2.163395135633407

Epoch: 63| Step: 0
Training loss: 1.970280408859253
Validation loss: 2.1593817651912732

Epoch: 5| Step: 1
Training loss: 2.710361957550049
Validation loss: 2.162835295482348

Epoch: 5| Step: 2
Training loss: 2.6461992263793945
Validation loss: 2.183548934998051

Epoch: 5| Step: 3
Training loss: 2.149660110473633
Validation loss: 2.1518593475382817

Epoch: 5| Step: 4
Training loss: 2.3096609115600586
Validation loss: 2.1818236202322026

Epoch: 5| Step: 5
Training loss: 2.8396759033203125
Validation loss: 2.1849528704920123

Epoch: 5| Step: 6
Training loss: 2.0014774799346924
Validation loss: 2.1878501035833873

Epoch: 5| Step: 7
Training loss: 2.691185474395752
Validation loss: 2.169223347017842

Epoch: 5| Step: 8
Training loss: 2.0071425437927246
Validation loss: 2.1851016680399575

Epoch: 5| Step: 9
Training loss: 2.6463370323181152
Validation loss: 2.166962351850284

Epoch: 5| Step: 10
Training loss: 2.5720651149749756
Validation loss: 2.1446512963182185

Epoch: 64| Step: 0
Training loss: 2.4746670722961426
Validation loss: 2.171830379834739

Epoch: 5| Step: 1
Training loss: 1.941564917564392
Validation loss: 2.171695690001211

Epoch: 5| Step: 2
Training loss: 2.401815891265869
Validation loss: 2.136245612175234

Epoch: 5| Step: 3
Training loss: 2.286327600479126
Validation loss: 2.1799579205051547

Epoch: 5| Step: 4
Training loss: 2.330852746963501
Validation loss: 2.1739687099251697

Epoch: 5| Step: 5
Training loss: 2.6596262454986572
Validation loss: 2.1610797951298375

Epoch: 5| Step: 6
Training loss: 2.2069287300109863
Validation loss: 2.174876138728152

Epoch: 5| Step: 7
Training loss: 3.2102177143096924
Validation loss: 2.174387384486455

Epoch: 5| Step: 8
Training loss: 2.34454607963562
Validation loss: 2.1781054645456295

Epoch: 5| Step: 9
Training loss: 2.113828182220459
Validation loss: 2.188332462823519

Epoch: 5| Step: 10
Training loss: 2.7452633380889893
Validation loss: 2.1661895692989392

Epoch: 65| Step: 0
Training loss: 2.107856512069702
Validation loss: 2.1769771729746172

Epoch: 5| Step: 1
Training loss: 1.9153835773468018
Validation loss: 2.1862683539749472

Epoch: 5| Step: 2
Training loss: 2.2478187084198
Validation loss: 2.156654591201454

Epoch: 5| Step: 3
Training loss: 3.2433536052703857
Validation loss: 2.16425298875378

Epoch: 5| Step: 4
Training loss: 1.627785325050354
Validation loss: 2.1765148280769266

Epoch: 5| Step: 5
Training loss: 2.515314817428589
Validation loss: 2.174664489684566

Epoch: 5| Step: 6
Training loss: 2.481649875640869
Validation loss: 2.164092989378078

Epoch: 5| Step: 7
Training loss: 2.6561596393585205
Validation loss: 2.152082286855226

Epoch: 5| Step: 8
Training loss: 2.506676435470581
Validation loss: 2.1507257441038727

Epoch: 5| Step: 9
Training loss: 2.605377674102783
Validation loss: 2.1565492383895384

Epoch: 5| Step: 10
Training loss: 2.650357961654663
Validation loss: 2.146250799138059

Epoch: 66| Step: 0
Training loss: 2.705167293548584
Validation loss: 2.1444837072844147

Epoch: 5| Step: 1
Training loss: 2.385615587234497
Validation loss: 2.1638969644423454

Epoch: 5| Step: 2
Training loss: 1.7507216930389404
Validation loss: 2.1548496625756703

Epoch: 5| Step: 3
Training loss: 3.2321670055389404
Validation loss: 2.174152604995235

Epoch: 5| Step: 4
Training loss: 1.752572774887085
Validation loss: 2.1589569058469547

Epoch: 5| Step: 5
Training loss: 2.4573638439178467
Validation loss: 2.140044827615061

Epoch: 5| Step: 6
Training loss: 2.3235747814178467
Validation loss: 2.1404943966096446

Epoch: 5| Step: 7
Training loss: 2.3128790855407715
Validation loss: 2.1530228866043912

Epoch: 5| Step: 8
Training loss: 2.65565824508667
Validation loss: 2.15010594296199

Epoch: 5| Step: 9
Training loss: 2.6501994132995605
Validation loss: 2.1258763497875584

Epoch: 5| Step: 10
Training loss: 2.214139699935913
Validation loss: 2.154075216221553

Epoch: 67| Step: 0
Training loss: 2.9003641605377197
Validation loss: 2.1466575463612876

Epoch: 5| Step: 1
Training loss: 2.1133532524108887
Validation loss: 2.132055828648229

Epoch: 5| Step: 2
Training loss: 2.6732418537139893
Validation loss: 2.1310255245495866

Epoch: 5| Step: 3
Training loss: 2.504030227661133
Validation loss: 2.1493672401674333

Epoch: 5| Step: 4
Training loss: 2.7641139030456543
Validation loss: 2.1514964975336546

Epoch: 5| Step: 5
Training loss: 1.6046674251556396
Validation loss: 2.148118911250945

Epoch: 5| Step: 6
Training loss: 1.761282205581665
Validation loss: 2.1436806571099067

Epoch: 5| Step: 7
Training loss: 2.051144599914551
Validation loss: 2.1476229467699604

Epoch: 5| Step: 8
Training loss: 2.767458438873291
Validation loss: 2.1211976825550036

Epoch: 5| Step: 9
Training loss: 2.8864190578460693
Validation loss: 2.1350764946271013

Epoch: 5| Step: 10
Training loss: 2.1522772312164307
Validation loss: 2.1383675811111287

Epoch: 68| Step: 0
Training loss: 2.460573673248291
Validation loss: 2.1363073151598693

Epoch: 5| Step: 1
Training loss: 2.6255974769592285
Validation loss: 2.1628618445447696

Epoch: 5| Step: 2
Training loss: 2.511013984680176
Validation loss: 2.161237806402227

Epoch: 5| Step: 3
Training loss: 2.4125685691833496
Validation loss: 2.144506190412788

Epoch: 5| Step: 4
Training loss: 2.233677864074707
Validation loss: 2.1311589620446645

Epoch: 5| Step: 5
Training loss: 2.460031509399414
Validation loss: 2.1523738125319123

Epoch: 5| Step: 6
Training loss: 2.586515426635742
Validation loss: 2.11841292278741

Epoch: 5| Step: 7
Training loss: 1.7356849908828735
Validation loss: 2.1300428452030307

Epoch: 5| Step: 8
Training loss: 2.4690327644348145
Validation loss: 2.1323736585596555

Epoch: 5| Step: 9
Training loss: 1.8996753692626953
Validation loss: 2.1203543473315496

Epoch: 5| Step: 10
Training loss: 2.792208433151245
Validation loss: 2.1472696411994194

Epoch: 69| Step: 0
Training loss: 2.399041175842285
Validation loss: 2.1443529462301605

Epoch: 5| Step: 1
Training loss: 1.850831389427185
Validation loss: 2.123467699173958

Epoch: 5| Step: 2
Training loss: 2.2953057289123535
Validation loss: 2.132742658738167

Epoch: 5| Step: 3
Training loss: 2.1220755577087402
Validation loss: 2.1451167175846715

Epoch: 5| Step: 4
Training loss: 2.1735572814941406
Validation loss: 2.127901627171424

Epoch: 5| Step: 5
Training loss: 1.8456470966339111
Validation loss: 2.1435554130103

Epoch: 5| Step: 6
Training loss: 2.47115421295166
Validation loss: 2.1369338189401934

Epoch: 5| Step: 7
Training loss: 2.827226161956787
Validation loss: 2.1234147343584286

Epoch: 5| Step: 8
Training loss: 2.9311132431030273
Validation loss: 2.142848592932506

Epoch: 5| Step: 9
Training loss: 2.3768749237060547
Validation loss: 2.128330813941135

Epoch: 5| Step: 10
Training loss: 3.05057430267334
Validation loss: 2.1534967512212773

Epoch: 70| Step: 0
Training loss: 2.2245213985443115
Validation loss: 2.1121434011766986

Epoch: 5| Step: 1
Training loss: 2.873796224594116
Validation loss: 2.122997929972987

Epoch: 5| Step: 2
Training loss: 1.944944977760315
Validation loss: 2.1303289192979054

Epoch: 5| Step: 3
Training loss: 2.2138776779174805
Validation loss: 2.134312396408409

Epoch: 5| Step: 4
Training loss: 2.5466601848602295
Validation loss: 2.1353174691559165

Epoch: 5| Step: 5
Training loss: 2.7157959938049316
Validation loss: 2.1424611101868334

Epoch: 5| Step: 6
Training loss: 1.8507124185562134
Validation loss: 2.130343221849011

Epoch: 5| Step: 7
Training loss: 2.992954730987549
Validation loss: 2.125633857583487

Epoch: 5| Step: 8
Training loss: 2.048031806945801
Validation loss: 2.1376569014723583

Epoch: 5| Step: 9
Training loss: 2.771353244781494
Validation loss: 2.1399666211938344

Epoch: 5| Step: 10
Training loss: 2.016528606414795
Validation loss: 2.132674609461138

Epoch: 71| Step: 0
Training loss: 2.3361449241638184
Validation loss: 2.1353104178623488

Epoch: 5| Step: 1
Training loss: 2.4189937114715576
Validation loss: 2.1193205976998932

Epoch: 5| Step: 2
Training loss: 2.326859951019287
Validation loss: 2.140975926512031

Epoch: 5| Step: 3
Training loss: 2.7914175987243652
Validation loss: 2.1414974094719015

Epoch: 5| Step: 4
Training loss: 2.5773937702178955
Validation loss: 2.1094050471500685

Epoch: 5| Step: 5
Training loss: 2.367243766784668
Validation loss: 2.1428674318457164

Epoch: 5| Step: 6
Training loss: 2.5516574382781982
Validation loss: 2.136037418919225

Epoch: 5| Step: 7
Training loss: 2.1392674446105957
Validation loss: 2.12498551799405

Epoch: 5| Step: 8
Training loss: 2.398467540740967
Validation loss: 2.1692589982863395

Epoch: 5| Step: 9
Training loss: 2.0401229858398438
Validation loss: 2.137814265425487

Epoch: 5| Step: 10
Training loss: 2.1335833072662354
Validation loss: 2.151364549513786

Epoch: 72| Step: 0
Training loss: 1.8207852840423584
Validation loss: 2.126188467907649

Epoch: 5| Step: 1
Training loss: 2.594637632369995
Validation loss: 2.166780903775205

Epoch: 5| Step: 2
Training loss: 1.9190113544464111
Validation loss: 2.129553169332525

Epoch: 5| Step: 3
Training loss: 2.4816040992736816
Validation loss: 2.140819711069907

Epoch: 5| Step: 4
Training loss: 2.841125965118408
Validation loss: 2.1325971900775866

Epoch: 5| Step: 5
Training loss: 2.7465789318084717
Validation loss: 2.1516523130478395

Epoch: 5| Step: 6
Training loss: 2.6755807399749756
Validation loss: 2.135797041718678

Epoch: 5| Step: 7
Training loss: 2.038661241531372
Validation loss: 2.146698595375143

Epoch: 5| Step: 8
Training loss: 2.353916883468628
Validation loss: 2.140812409821377

Epoch: 5| Step: 9
Training loss: 1.875079870223999
Validation loss: 2.1184887052864156

Epoch: 5| Step: 10
Training loss: 2.888570547103882
Validation loss: 2.13265130084048

Epoch: 73| Step: 0
Training loss: 2.2514584064483643
Validation loss: 2.137803075134113

Epoch: 5| Step: 1
Training loss: 2.8662819862365723
Validation loss: 2.124863588681785

Epoch: 5| Step: 2
Training loss: 1.676269292831421
Validation loss: 2.1284249815889584

Epoch: 5| Step: 3
Training loss: 1.9816277027130127
Validation loss: 2.1111235541682087

Epoch: 5| Step: 4
Training loss: 2.7180047035217285
Validation loss: 2.114637223623132

Epoch: 5| Step: 5
Training loss: 1.8814423084259033
Validation loss: 2.1255126678815452

Epoch: 5| Step: 6
Training loss: 2.8032984733581543
Validation loss: 2.116340329570155

Epoch: 5| Step: 7
Training loss: 1.9006292819976807
Validation loss: 2.1071030529596473

Epoch: 5| Step: 8
Training loss: 2.236457109451294
Validation loss: 2.104308451375654

Epoch: 5| Step: 9
Training loss: 2.756225109100342
Validation loss: 2.129294841520248

Epoch: 5| Step: 10
Training loss: 2.945392608642578
Validation loss: 2.087990555711972

Epoch: 74| Step: 0
Training loss: 2.5303359031677246
Validation loss: 2.1406999211157522

Epoch: 5| Step: 1
Training loss: 1.7268588542938232
Validation loss: 2.1171181112207393

Epoch: 5| Step: 2
Training loss: 2.4758028984069824
Validation loss: 2.122842450295725

Epoch: 5| Step: 3
Training loss: 2.1256489753723145
Validation loss: 2.1328890349275325

Epoch: 5| Step: 4
Training loss: 2.3585307598114014
Validation loss: 2.1293096260357927

Epoch: 5| Step: 5
Training loss: 2.389397382736206
Validation loss: 2.1379367459204888

Epoch: 5| Step: 6
Training loss: 3.177354335784912
Validation loss: 2.1185212468588226

Epoch: 5| Step: 7
Training loss: 2.0231316089630127
Validation loss: 2.1181002099026918

Epoch: 5| Step: 8
Training loss: 2.4773411750793457
Validation loss: 2.1010798613230386

Epoch: 5| Step: 9
Training loss: 2.5865046977996826
Validation loss: 2.1273130575815835

Epoch: 5| Step: 10
Training loss: 2.0202934741973877
Validation loss: 2.148117744794456

Epoch: 75| Step: 0
Training loss: 2.4420106410980225
Validation loss: 2.1143962080760668

Epoch: 5| Step: 1
Training loss: 2.4100472927093506
Validation loss: 2.132104622420444

Epoch: 5| Step: 2
Training loss: 2.2513747215270996
Validation loss: 2.1419759796511744

Epoch: 5| Step: 3
Training loss: 2.5352070331573486
Validation loss: 2.104144189947395

Epoch: 5| Step: 4
Training loss: 2.541231632232666
Validation loss: 2.134046805802212

Epoch: 5| Step: 5
Training loss: 2.8322136402130127
Validation loss: 2.1393567874867427

Epoch: 5| Step: 6
Training loss: 1.5987061262130737
Validation loss: 2.1214898709327943

Epoch: 5| Step: 7
Training loss: 1.9171472787857056
Validation loss: 2.1079448217986734

Epoch: 5| Step: 8
Training loss: 2.887092351913452
Validation loss: 2.1207716798269622

Epoch: 5| Step: 9
Training loss: 1.4467812776565552
Validation loss: 2.133417626862885

Epoch: 5| Step: 10
Training loss: 3.159350633621216
Validation loss: 2.148196825417139

Epoch: 76| Step: 0
Training loss: 2.775815486907959
Validation loss: 2.121250298715407

Epoch: 5| Step: 1
Training loss: 1.8540452718734741
Validation loss: 2.1377048107885543

Epoch: 5| Step: 2
Training loss: 2.7775192260742188
Validation loss: 2.117350306562198

Epoch: 5| Step: 3
Training loss: 2.904581308364868
Validation loss: 2.1187959422347364

Epoch: 5| Step: 4
Training loss: 1.8415231704711914
Validation loss: 2.118892841441657

Epoch: 5| Step: 5
Training loss: 1.8761355876922607
Validation loss: 2.143763756239286

Epoch: 5| Step: 6
Training loss: 1.840897798538208
Validation loss: 2.131645341073313

Epoch: 5| Step: 7
Training loss: 2.0379457473754883
Validation loss: 2.106796900431315

Epoch: 5| Step: 8
Training loss: 2.6021389961242676
Validation loss: 2.125921590353853

Epoch: 5| Step: 9
Training loss: 2.2036681175231934
Validation loss: 2.1304691799225344

Epoch: 5| Step: 10
Training loss: 3.191615104675293
Validation loss: 2.1188932259877524

Epoch: 77| Step: 0
Training loss: 2.0843892097473145
Validation loss: 2.138038353253436

Epoch: 5| Step: 1
Training loss: 2.652600049972534
Validation loss: 2.105263154993775

Epoch: 5| Step: 2
Training loss: 1.943749189376831
Validation loss: 2.0984729977064234

Epoch: 5| Step: 3
Training loss: 2.5315017700195312
Validation loss: 2.118167905397313

Epoch: 5| Step: 4
Training loss: 1.6025638580322266
Validation loss: 2.1094558290255967

Epoch: 5| Step: 5
Training loss: 2.9434165954589844
Validation loss: 2.099358827837052

Epoch: 5| Step: 6
Training loss: 3.063502073287964
Validation loss: 2.127067055753482

Epoch: 5| Step: 7
Training loss: 1.9339298009872437
Validation loss: 2.105479855691233

Epoch: 5| Step: 8
Training loss: 1.8538239002227783
Validation loss: 2.1063753686925417

Epoch: 5| Step: 9
Training loss: 2.604708194732666
Validation loss: 2.0973719396898822

Epoch: 5| Step: 10
Training loss: 2.5220611095428467
Validation loss: 2.0866854588190713

Epoch: 78| Step: 0
Training loss: 1.9612973928451538
Validation loss: 2.119121002894576

Epoch: 5| Step: 1
Training loss: 2.4638309478759766
Validation loss: 2.106238522837239

Epoch: 5| Step: 2
Training loss: 2.4132399559020996
Validation loss: 2.0995489781902683

Epoch: 5| Step: 3
Training loss: 1.4426038265228271
Validation loss: 2.1151275711674846

Epoch: 5| Step: 4
Training loss: 2.8530635833740234
Validation loss: 2.1084718588859803

Epoch: 5| Step: 5
Training loss: 2.3785789012908936
Validation loss: 2.1423816885999454

Epoch: 5| Step: 6
Training loss: 2.9739151000976562
Validation loss: 2.104627432361726

Epoch: 5| Step: 7
Training loss: 2.3467795848846436
Validation loss: 2.1289006458815707

Epoch: 5| Step: 8
Training loss: 2.1296706199645996
Validation loss: 2.1090426880826234

Epoch: 5| Step: 9
Training loss: 2.5466320514678955
Validation loss: 2.106927074411864

Epoch: 5| Step: 10
Training loss: 2.2134692668914795
Validation loss: 2.1196357575795983

Epoch: 79| Step: 0
Training loss: 2.8392748832702637
Validation loss: 2.1250453110664123

Epoch: 5| Step: 1
Training loss: 2.502173900604248
Validation loss: 2.11657484885185

Epoch: 5| Step: 2
Training loss: 2.4547526836395264
Validation loss: 2.1246272569061606

Epoch: 5| Step: 3
Training loss: 2.7397639751434326
Validation loss: 2.115539086762295

Epoch: 5| Step: 4
Training loss: 2.355581283569336
Validation loss: 2.109530237413222

Epoch: 5| Step: 5
Training loss: 2.2367923259735107
Validation loss: 2.102937521473054

Epoch: 5| Step: 6
Training loss: 2.721325635910034
Validation loss: 2.1261399510086223

Epoch: 5| Step: 7
Training loss: 2.2930119037628174
Validation loss: 2.1210128209924184

Epoch: 5| Step: 8
Training loss: 2.0331201553344727
Validation loss: 2.1209913530657367

Epoch: 5| Step: 9
Training loss: 1.7931272983551025
Validation loss: 2.1115047213851765

Epoch: 5| Step: 10
Training loss: 1.7204563617706299
Validation loss: 2.1288440791509484

Epoch: 80| Step: 0
Training loss: 2.2823445796966553
Validation loss: 2.124432756054786

Epoch: 5| Step: 1
Training loss: 2.446042537689209
Validation loss: 2.125860530843017

Epoch: 5| Step: 2
Training loss: 2.4306628704071045
Validation loss: 2.0865373816541446

Epoch: 5| Step: 3
Training loss: 2.248645782470703
Validation loss: 2.1256553383283716

Epoch: 5| Step: 4
Training loss: 2.209409236907959
Validation loss: 2.1050398875308294

Epoch: 5| Step: 5
Training loss: 2.1907544136047363
Validation loss: 2.106595928950976

Epoch: 5| Step: 6
Training loss: 1.7732185125350952
Validation loss: 2.1124566037167787

Epoch: 5| Step: 7
Training loss: 2.260848045349121
Validation loss: 2.1103982989506056

Epoch: 5| Step: 8
Training loss: 3.0963985919952393
Validation loss: 2.102843225643199

Epoch: 5| Step: 9
Training loss: 1.701846718788147
Validation loss: 2.1179778293896745

Epoch: 5| Step: 10
Training loss: 3.123148202896118
Validation loss: 2.083788470555377

Epoch: 81| Step: 0
Training loss: 2.67905330657959
Validation loss: 2.1041781338312293

Epoch: 5| Step: 1
Training loss: 2.2675700187683105
Validation loss: 2.0854125676616544

Epoch: 5| Step: 2
Training loss: 2.8245956897735596
Validation loss: 2.0813414255777993

Epoch: 5| Step: 3
Training loss: 2.789116859436035
Validation loss: 2.1145450145967546

Epoch: 5| Step: 4
Training loss: 1.9190731048583984
Validation loss: 2.0978755233108357

Epoch: 5| Step: 5
Training loss: 2.170051097869873
Validation loss: 2.1316584951134137

Epoch: 5| Step: 6
Training loss: 2.97365140914917
Validation loss: 2.097317748172309

Epoch: 5| Step: 7
Training loss: 1.9754295349121094
Validation loss: 2.110409016250282

Epoch: 5| Step: 8
Training loss: 2.1659557819366455
Validation loss: 2.098727176266332

Epoch: 5| Step: 9
Training loss: 2.3436102867126465
Validation loss: 2.097961983373088

Epoch: 5| Step: 10
Training loss: 1.4513392448425293
Validation loss: 2.0931400176017516

Epoch: 82| Step: 0
Training loss: 2.4871973991394043
Validation loss: 2.107160614382836

Epoch: 5| Step: 1
Training loss: 2.1277053356170654
Validation loss: 2.0821700224312405

Epoch: 5| Step: 2
Training loss: 2.594697952270508
Validation loss: 2.1126206305719193

Epoch: 5| Step: 3
Training loss: 2.148963212966919
Validation loss: 2.119254469871521

Epoch: 5| Step: 4
Training loss: 2.5936474800109863
Validation loss: 2.1306850897368563

Epoch: 5| Step: 5
Training loss: 2.1750378608703613
Validation loss: 2.0923418165535055

Epoch: 5| Step: 6
Training loss: 2.450178861618042
Validation loss: 2.104343598888766

Epoch: 5| Step: 7
Training loss: 2.108222007751465
Validation loss: 2.100163754596505

Epoch: 5| Step: 8
Training loss: 2.498006582260132
Validation loss: 2.0670681948302896

Epoch: 5| Step: 9
Training loss: 1.6758893728256226
Validation loss: 2.101110881374728

Epoch: 5| Step: 10
Training loss: 2.4556939601898193
Validation loss: 2.1154637605913225

Epoch: 83| Step: 0
Training loss: 2.366957426071167
Validation loss: 2.125831596312984

Epoch: 5| Step: 1
Training loss: 1.8056033849716187
Validation loss: 2.079158582995015

Epoch: 5| Step: 2
Training loss: 2.6613364219665527
Validation loss: 2.0967015784273864

Epoch: 5| Step: 3
Training loss: 1.8435335159301758
Validation loss: 2.0934345645289265

Epoch: 5| Step: 4
Training loss: 2.5344161987304688
Validation loss: 2.0962546563917592

Epoch: 5| Step: 5
Training loss: 2.3735153675079346
Validation loss: 2.096688747406006

Epoch: 5| Step: 6
Training loss: 1.888977289199829
Validation loss: 2.1197296547633346

Epoch: 5| Step: 7
Training loss: 2.403787136077881
Validation loss: 2.0907440108637654

Epoch: 5| Step: 8
Training loss: 3.106837511062622
Validation loss: 2.109114703311715

Epoch: 5| Step: 9
Training loss: 2.124082088470459
Validation loss: 2.1020694535265685

Epoch: 5| Step: 10
Training loss: 2.4242658615112305
Validation loss: 2.108456873124646

Epoch: 84| Step: 0
Training loss: 2.92010235786438
Validation loss: 2.1009007243699926

Epoch: 5| Step: 1
Training loss: 2.4085469245910645
Validation loss: 2.106925199108739

Epoch: 5| Step: 2
Training loss: 2.3514246940612793
Validation loss: 2.1195768169177476

Epoch: 5| Step: 3
Training loss: 2.5398097038269043
Validation loss: 2.1034905590036863

Epoch: 5| Step: 4
Training loss: 2.7359700202941895
Validation loss: 2.0773835528281426

Epoch: 5| Step: 5
Training loss: 1.8986501693725586
Validation loss: 2.101373282811975

Epoch: 5| Step: 6
Training loss: 2.3569698333740234
Validation loss: 2.0880421182160736

Epoch: 5| Step: 7
Training loss: 1.6410585641860962
Validation loss: 2.0950342057853617

Epoch: 5| Step: 8
Training loss: 1.6081355810165405
Validation loss: 2.1162089634967107

Epoch: 5| Step: 9
Training loss: 2.414048671722412
Validation loss: 2.092698194647348

Epoch: 5| Step: 10
Training loss: 2.6104655265808105
Validation loss: 2.0940840680112123

Epoch: 85| Step: 0
Training loss: 2.201381206512451
Validation loss: 2.113053625629794

Epoch: 5| Step: 1
Training loss: 1.6627328395843506
Validation loss: 2.1080301064316944

Epoch: 5| Step: 2
Training loss: 2.4430344104766846
Validation loss: 2.0989293334304646

Epoch: 5| Step: 3
Training loss: 2.0531115531921387
Validation loss: 2.0795123718118154

Epoch: 5| Step: 4
Training loss: 2.1846470832824707
Validation loss: 2.102077345694265

Epoch: 5| Step: 5
Training loss: 2.3719677925109863
Validation loss: 2.0674996734947286

Epoch: 5| Step: 6
Training loss: 2.3979735374450684
Validation loss: 2.087155601029755

Epoch: 5| Step: 7
Training loss: 2.4635403156280518
Validation loss: 2.0818301977649813

Epoch: 5| Step: 8
Training loss: 2.987363338470459
Validation loss: 2.0981376747931204

Epoch: 5| Step: 9
Training loss: 2.416651725769043
Validation loss: 2.098876404505904

Epoch: 5| Step: 10
Training loss: 2.1652326583862305
Validation loss: 2.096174927167995

Epoch: 86| Step: 0
Training loss: 2.29209566116333
Validation loss: 2.09427470801979

Epoch: 5| Step: 1
Training loss: 2.070648193359375
Validation loss: 2.1053217867369294

Epoch: 5| Step: 2
Training loss: 2.8671176433563232
Validation loss: 2.1085439035969396

Epoch: 5| Step: 3
Training loss: 2.099367380142212
Validation loss: 2.074358437650947

Epoch: 5| Step: 4
Training loss: 2.5068132877349854
Validation loss: 2.105304156580279

Epoch: 5| Step: 5
Training loss: 2.2183709144592285
Validation loss: 2.120871966884982

Epoch: 5| Step: 6
Training loss: 2.9424355030059814
Validation loss: 2.1065381137273644

Epoch: 5| Step: 7
Training loss: 1.5718772411346436
Validation loss: 2.100348675122825

Epoch: 5| Step: 8
Training loss: 2.2749783992767334
Validation loss: 2.110170086224874

Epoch: 5| Step: 9
Training loss: 2.116058349609375
Validation loss: 2.109210603980608

Epoch: 5| Step: 10
Training loss: 2.4992496967315674
Validation loss: 2.0786169575106714

Epoch: 87| Step: 0
Training loss: 1.9785112142562866
Validation loss: 2.0976516251922934

Epoch: 5| Step: 1
Training loss: 2.4711127281188965
Validation loss: 2.0733487695776005

Epoch: 5| Step: 2
Training loss: 3.1128499507904053
Validation loss: 2.0924325168773694

Epoch: 5| Step: 3
Training loss: 2.3985064029693604
Validation loss: 2.0971171817471905

Epoch: 5| Step: 4
Training loss: 2.60168194770813
Validation loss: 2.0893328241122666

Epoch: 5| Step: 5
Training loss: 2.0997698307037354
Validation loss: 2.0929388153937554

Epoch: 5| Step: 6
Training loss: 1.5741169452667236
Validation loss: 2.09942025779396

Epoch: 5| Step: 7
Training loss: 2.3817379474639893
Validation loss: 2.103789614092919

Epoch: 5| Step: 8
Training loss: 1.6145871877670288
Validation loss: 2.116334448578537

Epoch: 5| Step: 9
Training loss: 2.8106446266174316
Validation loss: 2.0650346266326083

Epoch: 5| Step: 10
Training loss: 2.275975465774536
Validation loss: 2.0929404971420125

Epoch: 88| Step: 0
Training loss: 1.787557601928711
Validation loss: 2.0852709598438715

Epoch: 5| Step: 1
Training loss: 2.4629080295562744
Validation loss: 2.0971474416794313

Epoch: 5| Step: 2
Training loss: 2.064891815185547
Validation loss: 2.0711288490603046

Epoch: 5| Step: 3
Training loss: 2.7967522144317627
Validation loss: 2.0855711608804683

Epoch: 5| Step: 4
Training loss: 2.5500941276550293
Validation loss: 2.092310784965433

Epoch: 5| Step: 5
Training loss: 2.1356570720672607
Validation loss: 2.087736814252792

Epoch: 5| Step: 6
Training loss: 2.9882025718688965
Validation loss: 2.070519919036537

Epoch: 5| Step: 7
Training loss: 2.09143328666687
Validation loss: 2.079606863760179

Epoch: 5| Step: 8
Training loss: 2.1205146312713623
Validation loss: 2.0872668861061014

Epoch: 5| Step: 9
Training loss: 2.161616563796997
Validation loss: 2.0862878266201226

Epoch: 5| Step: 10
Training loss: 2.2594685554504395
Validation loss: 2.0795278754285587

Epoch: 89| Step: 0
Training loss: 2.8277993202209473
Validation loss: 2.068366055847496

Epoch: 5| Step: 1
Training loss: 2.0436415672302246
Validation loss: 2.1146429777145386

Epoch: 5| Step: 2
Training loss: 2.374879837036133
Validation loss: 2.084265214140697

Epoch: 5| Step: 3
Training loss: 1.7208143472671509
Validation loss: 2.1153475469158542

Epoch: 5| Step: 4
Training loss: 2.2854549884796143
Validation loss: 2.0859733884052565

Epoch: 5| Step: 5
Training loss: 1.6087566614151
Validation loss: 2.1092819577904156

Epoch: 5| Step: 6
Training loss: 2.5009350776672363
Validation loss: 2.086764779142154

Epoch: 5| Step: 7
Training loss: 2.4258193969726562
Validation loss: 2.0993687670717955

Epoch: 5| Step: 8
Training loss: 1.7359129190444946
Validation loss: 2.0877115239379225

Epoch: 5| Step: 9
Training loss: 2.5455751419067383
Validation loss: 2.082862554057952

Epoch: 5| Step: 10
Training loss: 3.252239942550659
Validation loss: 2.0982747154851116

Epoch: 90| Step: 0
Training loss: 1.6887346506118774
Validation loss: 2.1069185938886417

Epoch: 5| Step: 1
Training loss: 2.172036647796631
Validation loss: 2.1041396612762124

Epoch: 5| Step: 2
Training loss: 2.0632271766662598
Validation loss: 2.117141185268279

Epoch: 5| Step: 3
Training loss: 2.4936652183532715
Validation loss: 2.0958834258458947

Epoch: 5| Step: 4
Training loss: 2.532627582550049
Validation loss: 2.114175997754579

Epoch: 5| Step: 5
Training loss: 2.356541633605957
Validation loss: 2.086057360454272

Epoch: 5| Step: 6
Training loss: 1.4183995723724365
Validation loss: 2.108673744304206

Epoch: 5| Step: 7
Training loss: 3.1423840522766113
Validation loss: 2.1092099092339955

Epoch: 5| Step: 8
Training loss: 2.755218505859375
Validation loss: 2.0903611759985647

Epoch: 5| Step: 9
Training loss: 2.1810085773468018
Validation loss: 2.1158739930839947

Epoch: 5| Step: 10
Training loss: 2.271317481994629
Validation loss: 2.095279292393756

Epoch: 91| Step: 0
Training loss: 2.3989028930664062
Validation loss: 2.1027203067656486

Epoch: 5| Step: 1
Training loss: 2.621184825897217
Validation loss: 2.110137188306419

Epoch: 5| Step: 2
Training loss: 2.2864279747009277
Validation loss: 2.0806162998240483

Epoch: 5| Step: 3
Training loss: 2.991856813430786
Validation loss: 2.1060536651201147

Epoch: 5| Step: 4
Training loss: 2.0369484424591064
Validation loss: 2.0988491427513862

Epoch: 5| Step: 5
Training loss: 2.526005744934082
Validation loss: 2.1124069075430594

Epoch: 5| Step: 6
Training loss: 1.9066909551620483
Validation loss: 2.1055696523317726

Epoch: 5| Step: 7
Training loss: 2.8094379901885986
Validation loss: 2.1099578539530435

Epoch: 5| Step: 8
Training loss: 1.983036994934082
Validation loss: 2.084467754569105

Epoch: 5| Step: 9
Training loss: 1.3964636325836182
Validation loss: 2.114463580551968

Epoch: 5| Step: 10
Training loss: 2.0160279273986816
Validation loss: 2.097846842581226

Epoch: 92| Step: 0
Training loss: 1.9689395427703857
Validation loss: 2.102623725450167

Epoch: 5| Step: 1
Training loss: 2.1653542518615723
Validation loss: 2.0922377981165403

Epoch: 5| Step: 2
Training loss: 1.815732717514038
Validation loss: 2.101701921032321

Epoch: 5| Step: 3
Training loss: 2.5938315391540527
Validation loss: 2.094841053408961

Epoch: 5| Step: 4
Training loss: 2.838660478591919
Validation loss: 2.1182772151885496

Epoch: 5| Step: 5
Training loss: 2.879335880279541
Validation loss: 2.114741434333145

Epoch: 5| Step: 6
Training loss: 2.530702590942383
Validation loss: 2.1065521035143124

Epoch: 5| Step: 7
Training loss: 2.0547845363616943
Validation loss: 2.0884047541567075

Epoch: 5| Step: 8
Training loss: 1.8483164310455322
Validation loss: 2.133003334845266

Epoch: 5| Step: 9
Training loss: 2.438727617263794
Validation loss: 2.080933763134864

Epoch: 5| Step: 10
Training loss: 1.9678926467895508
Validation loss: 2.1213230830366894

Epoch: 93| Step: 0
Training loss: 1.6583635807037354
Validation loss: 2.1098070606108634

Epoch: 5| Step: 1
Training loss: 2.732928514480591
Validation loss: 2.0998874736088577

Epoch: 5| Step: 2
Training loss: 2.1246049404144287
Validation loss: 2.1338815304540817

Epoch: 5| Step: 3
Training loss: 3.249037265777588
Validation loss: 2.120112552437731

Epoch: 5| Step: 4
Training loss: 2.4298105239868164
Validation loss: 2.1299134762056413

Epoch: 5| Step: 5
Training loss: 2.285320520401001
Validation loss: 2.0842572886456727

Epoch: 5| Step: 6
Training loss: 2.0904619693756104
Validation loss: 2.098312263847679

Epoch: 5| Step: 7
Training loss: 1.499713659286499
Validation loss: 2.109541498204713

Epoch: 5| Step: 8
Training loss: 2.23827862739563
Validation loss: 2.076395767991261

Epoch: 5| Step: 9
Training loss: 2.385197162628174
Validation loss: 2.1082762390054683

Epoch: 5| Step: 10
Training loss: 2.1813766956329346
Validation loss: 2.1189042240060787

Epoch: 94| Step: 0
Training loss: 2.483030319213867
Validation loss: 2.1078724668871973

Epoch: 5| Step: 1
Training loss: 1.711342215538025
Validation loss: 2.1107842537664596

Epoch: 5| Step: 2
Training loss: 2.785006046295166
Validation loss: 2.102874676386515

Epoch: 5| Step: 3
Training loss: 2.300706386566162
Validation loss: 2.1029077473507134

Epoch: 5| Step: 4
Training loss: 1.772179365158081
Validation loss: 2.123575815590479

Epoch: 5| Step: 5
Training loss: 2.6214237213134766
Validation loss: 2.094806250705514

Epoch: 5| Step: 6
Training loss: 2.695314884185791
Validation loss: 2.078634872231432

Epoch: 5| Step: 7
Training loss: 2.1664650440216064
Validation loss: 2.1076097219221053

Epoch: 5| Step: 8
Training loss: 2.351294994354248
Validation loss: 2.102603740589593

Epoch: 5| Step: 9
Training loss: 1.8731788396835327
Validation loss: 2.101806588070367

Epoch: 5| Step: 10
Training loss: 2.507282257080078
Validation loss: 2.078316006609189

Epoch: 95| Step: 0
Training loss: 2.637791633605957
Validation loss: 2.0987937565772765

Epoch: 5| Step: 1
Training loss: 1.8956295251846313
Validation loss: 2.1025870487254155

Epoch: 5| Step: 2
Training loss: 2.6129965782165527
Validation loss: 2.0938060424661122

Epoch: 5| Step: 3
Training loss: 2.6964151859283447
Validation loss: 2.082310953447896

Epoch: 5| Step: 4
Training loss: 2.320979595184326
Validation loss: 2.1188227233066352

Epoch: 5| Step: 5
Training loss: 2.220114231109619
Validation loss: 2.075315411372851

Epoch: 5| Step: 6
Training loss: 2.3920481204986572
Validation loss: 2.0998172606191328

Epoch: 5| Step: 7
Training loss: 1.7234493494033813
Validation loss: 2.0986135928861556

Epoch: 5| Step: 8
Training loss: 2.4105167388916016
Validation loss: 2.0848510162804716

Epoch: 5| Step: 9
Training loss: 1.7911522388458252
Validation loss: 2.1103585663662163

Epoch: 5| Step: 10
Training loss: 2.353544235229492
Validation loss: 2.096556455858292

Epoch: 96| Step: 0
Training loss: 2.5397636890411377
Validation loss: 2.1048463134355444

Epoch: 5| Step: 1
Training loss: 2.4547603130340576
Validation loss: 2.102626203208841

Epoch: 5| Step: 2
Training loss: 2.106700897216797
Validation loss: 2.1199224328482025

Epoch: 5| Step: 3
Training loss: 2.694481611251831
Validation loss: 2.0978660429677656

Epoch: 5| Step: 4
Training loss: 1.635732650756836
Validation loss: 2.1088727622903805

Epoch: 5| Step: 5
Training loss: 1.9145641326904297
Validation loss: 2.105059608336418

Epoch: 5| Step: 6
Training loss: 2.411834239959717
Validation loss: 2.083762325266356

Epoch: 5| Step: 7
Training loss: 2.404963254928589
Validation loss: 2.1105670518772577

Epoch: 5| Step: 8
Training loss: 2.3155481815338135
Validation loss: 2.102518748211604

Epoch: 5| Step: 9
Training loss: 1.8855434656143188
Validation loss: 2.125878954446444

Epoch: 5| Step: 10
Training loss: 2.76741361618042
Validation loss: 2.062988852941862

Epoch: 97| Step: 0
Training loss: 1.7572345733642578
Validation loss: 2.1162973603894635

Epoch: 5| Step: 1
Training loss: 2.9004833698272705
Validation loss: 2.112522852036261

Epoch: 5| Step: 2
Training loss: 2.4544260501861572
Validation loss: 2.0991511883274203

Epoch: 5| Step: 3
Training loss: 2.534109115600586
Validation loss: 2.091128821014076

Epoch: 5| Step: 4
Training loss: 1.443007469177246
Validation loss: 2.113705297952057

Epoch: 5| Step: 5
Training loss: 2.640270948410034
Validation loss: 2.082857488304056

Epoch: 5| Step: 6
Training loss: 2.1916708946228027
Validation loss: 2.112695147914271

Epoch: 5| Step: 7
Training loss: 2.1251587867736816
Validation loss: 2.0972435230849893

Epoch: 5| Step: 8
Training loss: 2.041395902633667
Validation loss: 2.1077193662684452

Epoch: 5| Step: 9
Training loss: 2.642529010772705
Validation loss: 2.077660540098785

Epoch: 5| Step: 10
Training loss: 2.029689073562622
Validation loss: 2.1250853820513655

Epoch: 98| Step: 0
Training loss: 2.6874032020568848
Validation loss: 2.079330699418181

Epoch: 5| Step: 1
Training loss: 2.855783700942993
Validation loss: 2.103985717219691

Epoch: 5| Step: 2
Training loss: 1.7964985370635986
Validation loss: 2.0896523255173878

Epoch: 5| Step: 3
Training loss: 2.0849616527557373
Validation loss: 2.104216739695559

Epoch: 5| Step: 4
Training loss: 1.6361520290374756
Validation loss: 2.105140350198233

Epoch: 5| Step: 5
Training loss: 2.620049238204956
Validation loss: 2.0989287002112276

Epoch: 5| Step: 6
Training loss: 2.375014543533325
Validation loss: 2.093213196723692

Epoch: 5| Step: 7
Training loss: 2.128528118133545
Validation loss: 2.107231056818398

Epoch: 5| Step: 8
Training loss: 2.5896434783935547
Validation loss: 2.1009434884594334

Epoch: 5| Step: 9
Training loss: 2.318577289581299
Validation loss: 2.1017675015234176

Epoch: 5| Step: 10
Training loss: 1.8096609115600586
Validation loss: 2.0953185455773466

Epoch: 99| Step: 0
Training loss: 2.4915947914123535
Validation loss: 2.0846858768052954

Epoch: 5| Step: 1
Training loss: 2.483085870742798
Validation loss: 2.0882097187862603

Epoch: 5| Step: 2
Training loss: 2.4785807132720947
Validation loss: 2.098307080166314

Epoch: 5| Step: 3
Training loss: 2.249638080596924
Validation loss: 2.1021254011379775

Epoch: 5| Step: 4
Training loss: 2.377532482147217
Validation loss: 2.1155939922537854

Epoch: 5| Step: 5
Training loss: 2.721391439437866
Validation loss: 2.1017507994046776

Epoch: 5| Step: 6
Training loss: 1.7902683019638062
Validation loss: 2.0877223912105767

Epoch: 5| Step: 7
Training loss: 1.9933655261993408
Validation loss: 2.086576355400906

Epoch: 5| Step: 8
Training loss: 1.994375228881836
Validation loss: 2.095068035587188

Epoch: 5| Step: 9
Training loss: 1.5542471408843994
Validation loss: 2.108980780006737

Epoch: 5| Step: 10
Training loss: 2.610339641571045
Validation loss: 2.078276526543402

Epoch: 100| Step: 0
Training loss: 2.424340009689331
Validation loss: 2.1089207318521317

Epoch: 5| Step: 1
Training loss: 2.473168134689331
Validation loss: 2.1086136807677565

Epoch: 5| Step: 2
Training loss: 1.9180179834365845
Validation loss: 2.086921771367391

Epoch: 5| Step: 3
Training loss: 2.50303316116333
Validation loss: 2.101569596157279

Epoch: 5| Step: 4
Training loss: 2.1489920616149902
Validation loss: 2.09342255515437

Epoch: 5| Step: 5
Training loss: 2.0847649574279785
Validation loss: 2.0992538313711844

Epoch: 5| Step: 6
Training loss: 2.258383274078369
Validation loss: 2.1028284911186463

Epoch: 5| Step: 7
Training loss: 2.599609136581421
Validation loss: 2.0874745909885695

Epoch: 5| Step: 8
Training loss: 1.6770610809326172
Validation loss: 2.0843260493329776

Epoch: 5| Step: 9
Training loss: 2.4255330562591553
Validation loss: 2.10111500370887

Epoch: 5| Step: 10
Training loss: 2.2768726348876953
Validation loss: 2.084741618043633

Epoch: 101| Step: 0
Training loss: 2.313385248184204
Validation loss: 2.083317275970213

Epoch: 5| Step: 1
Training loss: 2.519840955734253
Validation loss: 2.1070594428687968

Epoch: 5| Step: 2
Training loss: 2.4834001064300537
Validation loss: 2.0905910025360765

Epoch: 5| Step: 3
Training loss: 2.4959609508514404
Validation loss: 2.1008180495231383

Epoch: 5| Step: 4
Training loss: 2.121729850769043
Validation loss: 2.133690280299033

Epoch: 5| Step: 5
Training loss: 2.097367286682129
Validation loss: 2.1031676543656217

Epoch: 5| Step: 6
Training loss: 2.0702998638153076
Validation loss: 2.120361174306562

Epoch: 5| Step: 7
Training loss: 2.0884833335876465
Validation loss: 2.0965363761430145

Epoch: 5| Step: 8
Training loss: 2.1195521354675293
Validation loss: 2.121700826511588

Epoch: 5| Step: 9
Training loss: 1.8219926357269287
Validation loss: 2.1322772451626357

Epoch: 5| Step: 10
Training loss: 2.6849400997161865
Validation loss: 2.0998541514078775

Epoch: 102| Step: 0
Training loss: 2.446773052215576
Validation loss: 2.1354327483843734

Epoch: 5| Step: 1
Training loss: 2.3256664276123047
Validation loss: 2.0997532029305734

Epoch: 5| Step: 2
Training loss: 2.151315689086914
Validation loss: 2.1276804939393075

Epoch: 5| Step: 3
Training loss: 2.703880786895752
Validation loss: 2.114583125678442

Epoch: 5| Step: 4
Training loss: 2.509605646133423
Validation loss: 2.096535118677283

Epoch: 5| Step: 5
Training loss: 2.168586015701294
Validation loss: 2.11585824207593

Epoch: 5| Step: 6
Training loss: 2.5303876399993896
Validation loss: 2.1149171706168883

Epoch: 5| Step: 7
Training loss: 1.8302676677703857
Validation loss: 2.083329874982116

Epoch: 5| Step: 8
Training loss: 2.094229221343994
Validation loss: 2.1179451122078845

Epoch: 5| Step: 9
Training loss: 2.3049511909484863
Validation loss: 2.1286638423960698

Epoch: 5| Step: 10
Training loss: 1.723591923713684
Validation loss: 2.1044974993633967

Epoch: 103| Step: 0
Training loss: 2.3285422325134277
Validation loss: 2.090604564195038

Epoch: 5| Step: 1
Training loss: 1.9177261590957642
Validation loss: 2.1169132955612673

Epoch: 5| Step: 2
Training loss: 2.1924657821655273
Validation loss: 2.096034821643624

Epoch: 5| Step: 3
Training loss: 2.1782424449920654
Validation loss: 2.124605829997729

Epoch: 5| Step: 4
Training loss: 2.2487716674804688
Validation loss: 2.1131433927884666

Epoch: 5| Step: 5
Training loss: 2.1202425956726074
Validation loss: 2.0942191462362967

Epoch: 5| Step: 6
Training loss: 2.145443916320801
Validation loss: 2.121271871751355

Epoch: 5| Step: 7
Training loss: 2.3101229667663574
Validation loss: 2.119899638237492

Epoch: 5| Step: 8
Training loss: 2.4871020317077637
Validation loss: 2.13150203868907

Epoch: 5| Step: 9
Training loss: 2.513185501098633
Validation loss: 2.11583383365344

Epoch: 5| Step: 10
Training loss: 2.4061439037323
Validation loss: 2.136222408663842

Epoch: 104| Step: 0
Training loss: 1.8540241718292236
Validation loss: 2.1029278988479287

Epoch: 5| Step: 1
Training loss: 2.0210046768188477
Validation loss: 2.1350613101836173

Epoch: 5| Step: 2
Training loss: 2.378617763519287
Validation loss: 2.1209620121986634

Epoch: 5| Step: 3
Training loss: 1.7048254013061523
Validation loss: 2.113643523185484

Epoch: 5| Step: 4
Training loss: 2.511120557785034
Validation loss: 2.1193997885591243

Epoch: 5| Step: 5
Training loss: 2.603701114654541
Validation loss: 2.1173049531957155

Epoch: 5| Step: 6
Training loss: 2.661381244659424
Validation loss: 2.1151401458248014

Epoch: 5| Step: 7
Training loss: 2.934807300567627
Validation loss: 2.0897801819668023

Epoch: 5| Step: 8
Training loss: 2.4061455726623535
Validation loss: 2.0984266541337453

Epoch: 5| Step: 9
Training loss: 1.6338590383529663
Validation loss: 2.1049566858558246

Epoch: 5| Step: 10
Training loss: 1.9306492805480957
Validation loss: 2.0774078010230936

Epoch: 105| Step: 0
Training loss: 3.130356550216675
Validation loss: 2.098602118030671

Epoch: 5| Step: 1
Training loss: 2.0881710052490234
Validation loss: 2.099041433744533

Epoch: 5| Step: 2
Training loss: 2.603308916091919
Validation loss: 2.127898161129285

Epoch: 5| Step: 3
Training loss: 2.0396218299865723
Validation loss: 2.114888741124061

Epoch: 5| Step: 4
Training loss: 2.3938872814178467
Validation loss: 2.131173162050145

Epoch: 5| Step: 5
Training loss: 2.5099542140960693
Validation loss: 2.0979945070000103

Epoch: 5| Step: 6
Training loss: 2.5476720333099365
Validation loss: 2.1170341122534966

Epoch: 5| Step: 7
Training loss: 1.4197267293930054
Validation loss: 2.0919674442660425

Epoch: 5| Step: 8
Training loss: 1.8315693140029907
Validation loss: 2.0882159971421763

Epoch: 5| Step: 9
Training loss: 2.558408260345459
Validation loss: 2.113182771590448

Epoch: 5| Step: 10
Training loss: 1.4567756652832031
Validation loss: 2.1049051861609183

Epoch: 106| Step: 0
Training loss: 2.972923517227173
Validation loss: 2.1254414435355895

Epoch: 5| Step: 1
Training loss: 1.5808875560760498
Validation loss: 2.0868120039663007

Epoch: 5| Step: 2
Training loss: 2.1729490756988525
Validation loss: 2.07875144609841

Epoch: 5| Step: 3
Training loss: 1.8556849956512451
Validation loss: 2.1158710218244985

Epoch: 5| Step: 4
Training loss: 2.762359142303467
Validation loss: 2.07576798495426

Epoch: 5| Step: 5
Training loss: 2.447512149810791
Validation loss: 2.109624453770217

Epoch: 5| Step: 6
Training loss: 1.6672617197036743
Validation loss: 2.0846544158074165

Epoch: 5| Step: 7
Training loss: 1.8693612813949585
Validation loss: 2.1098931143360753

Epoch: 5| Step: 8
Training loss: 2.9845879077911377
Validation loss: 2.0926299992428032

Epoch: 5| Step: 9
Training loss: 1.651593804359436
Validation loss: 2.1309707190400813

Epoch: 5| Step: 10
Training loss: 2.6487505435943604
Validation loss: 2.1235089532790647

Epoch: 107| Step: 0
Training loss: 3.250499725341797
Validation loss: 2.103106966582678

Epoch: 5| Step: 1
Training loss: 2.28407621383667
Validation loss: 2.12915289273826

Epoch: 5| Step: 2
Training loss: 2.4046390056610107
Validation loss: 2.1003319524949595

Epoch: 5| Step: 3
Training loss: 1.9245319366455078
Validation loss: 2.099302910989331

Epoch: 5| Step: 4
Training loss: 1.7546653747558594
Validation loss: 2.082165728333176

Epoch: 5| Step: 5
Training loss: 2.804556131362915
Validation loss: 2.119695730106805

Epoch: 5| Step: 6
Training loss: 1.9820152521133423
Validation loss: 2.094613157292848

Epoch: 5| Step: 7
Training loss: 2.2981820106506348
Validation loss: 2.0826472941265313

Epoch: 5| Step: 8
Training loss: 1.996267557144165
Validation loss: 2.11477981844256

Epoch: 5| Step: 9
Training loss: 1.734758734703064
Validation loss: 2.1137793192299466

Epoch: 5| Step: 10
Training loss: 2.1727731227874756
Validation loss: 2.0992945753118044

Epoch: 108| Step: 0
Training loss: 2.2014002799987793
Validation loss: 2.1036835896071566

Epoch: 5| Step: 1
Training loss: 2.394153118133545
Validation loss: 2.100226266409761

Epoch: 5| Step: 2
Training loss: 2.3841614723205566
Validation loss: 2.1046208848235426

Epoch: 5| Step: 3
Training loss: 2.614956855773926
Validation loss: 2.104211402195756

Epoch: 5| Step: 4
Training loss: 2.4422669410705566
Validation loss: 2.128756833332841

Epoch: 5| Step: 5
Training loss: 2.3343067169189453
Validation loss: 2.1167650607324417

Epoch: 5| Step: 6
Training loss: 2.0220837593078613
Validation loss: 2.1068683157684984

Epoch: 5| Step: 7
Training loss: 2.0009536743164062
Validation loss: 2.109368803680584

Epoch: 5| Step: 8
Training loss: 1.7587556838989258
Validation loss: 2.1104466915130615

Epoch: 5| Step: 9
Training loss: 2.353470802307129
Validation loss: 2.1037775829274166

Epoch: 5| Step: 10
Training loss: 1.8496474027633667
Validation loss: 2.10246717545294

Epoch: 109| Step: 0
Training loss: 2.173602342605591
Validation loss: 2.1087782485510713

Epoch: 5| Step: 1
Training loss: 2.1947219371795654
Validation loss: 2.1094325639868297

Epoch: 5| Step: 2
Training loss: 2.0510363578796387
Validation loss: 2.1122993333365327

Epoch: 5| Step: 3
Training loss: 2.1182239055633545
Validation loss: 2.1295046626880603

Epoch: 5| Step: 4
Training loss: 2.4290544986724854
Validation loss: 2.1132013849032822

Epoch: 5| Step: 5
Training loss: 2.2120203971862793
Validation loss: 2.077681267133323

Epoch: 5| Step: 6
Training loss: 2.17942476272583
Validation loss: 2.131735465859854

Epoch: 5| Step: 7
Training loss: 1.8032814264297485
Validation loss: 2.1104269732711134

Epoch: 5| Step: 8
Training loss: 2.9101364612579346
Validation loss: 2.0948804988655993

Epoch: 5| Step: 9
Training loss: 2.6129703521728516
Validation loss: 2.1123190554239417

Epoch: 5| Step: 10
Training loss: 1.769552230834961
Validation loss: 2.1059390985837547

Epoch: 110| Step: 0
Training loss: 2.87196683883667
Validation loss: 2.1096450359590593

Epoch: 5| Step: 1
Training loss: 2.4903368949890137
Validation loss: 2.093515614027618

Epoch: 5| Step: 2
Training loss: 2.0975115299224854
Validation loss: 2.117789041611456

Epoch: 5| Step: 3
Training loss: 2.4680111408233643
Validation loss: 2.1082948471910212

Epoch: 5| Step: 4
Training loss: 2.34012508392334
Validation loss: 2.1330452503696566

Epoch: 5| Step: 5
Training loss: 2.081368923187256
Validation loss: 2.1264719770800684

Epoch: 5| Step: 6
Training loss: 2.163386821746826
Validation loss: 2.1184580454262356

Epoch: 5| Step: 7
Training loss: 1.7508989572525024
Validation loss: 2.128091804442867

Epoch: 5| Step: 8
Training loss: 2.6399803161621094
Validation loss: 2.1056508248852146

Epoch: 5| Step: 9
Training loss: 1.9068416357040405
Validation loss: 2.1079720040803314

Epoch: 5| Step: 10
Training loss: 1.6892534494400024
Validation loss: 2.09293536473346

Epoch: 111| Step: 0
Training loss: 2.1897761821746826
Validation loss: 2.1028736073483705

Epoch: 5| Step: 1
Training loss: 2.2547104358673096
Validation loss: 2.130173515248042

Epoch: 5| Step: 2
Training loss: 1.8872716426849365
Validation loss: 2.1125633332037155

Epoch: 5| Step: 3
Training loss: 2.297600269317627
Validation loss: 2.1302645360269854

Epoch: 5| Step: 4
Training loss: 2.0762112140655518
Validation loss: 2.1279535601215978

Epoch: 5| Step: 5
Training loss: 2.3782219886779785
Validation loss: 2.1117933283569994

Epoch: 5| Step: 6
Training loss: 2.3409018516540527
Validation loss: 2.0906246221193703

Epoch: 5| Step: 7
Training loss: 2.33597993850708
Validation loss: 2.0987105651568343

Epoch: 5| Step: 8
Training loss: 1.6972920894622803
Validation loss: 2.095230640903596

Epoch: 5| Step: 9
Training loss: 2.664903163909912
Validation loss: 2.1218933738687986

Epoch: 5| Step: 10
Training loss: 2.3685383796691895
Validation loss: 2.0954202804514157

Epoch: 112| Step: 0
Training loss: 1.3783074617385864
Validation loss: 2.094447802471858

Epoch: 5| Step: 1
Training loss: 3.070185899734497
Validation loss: 2.1024095730115007

Epoch: 5| Step: 2
Training loss: 2.285802125930786
Validation loss: 2.089705326223886

Epoch: 5| Step: 3
Training loss: 2.4351143836975098
Validation loss: 2.1375175752947406

Epoch: 5| Step: 4
Training loss: 2.3238608837127686
Validation loss: 2.1072087018720564

Epoch: 5| Step: 5
Training loss: 2.18522310256958
Validation loss: 2.0921816543866227

Epoch: 5| Step: 6
Training loss: 1.8589900732040405
Validation loss: 2.109178473872523

Epoch: 5| Step: 7
Training loss: 2.6522884368896484
Validation loss: 2.0933406865724953

Epoch: 5| Step: 8
Training loss: 2.120378017425537
Validation loss: 2.1061951345013035

Epoch: 5| Step: 9
Training loss: 1.4746607542037964
Validation loss: 2.107731080824329

Epoch: 5| Step: 10
Training loss: 2.6894443035125732
Validation loss: 2.129265405798471

Epoch: 113| Step: 0
Training loss: 2.740696430206299
Validation loss: 2.1072475333367624

Epoch: 5| Step: 1
Training loss: 2.378014087677002
Validation loss: 2.0970986812345442

Epoch: 5| Step: 2
Training loss: 2.170210123062134
Validation loss: 2.086909105700831

Epoch: 5| Step: 3
Training loss: 1.814443588256836
Validation loss: 2.1055635354852162

Epoch: 5| Step: 4
Training loss: 2.3447468280792236
Validation loss: 2.1015040207934637

Epoch: 5| Step: 5
Training loss: 2.499220371246338
Validation loss: 2.0864199976767264

Epoch: 5| Step: 6
Training loss: 2.1651570796966553
Validation loss: 2.1098714464454242

Epoch: 5| Step: 7
Training loss: 1.9076378345489502
Validation loss: 2.1011614017589118

Epoch: 5| Step: 8
Training loss: 1.6400045156478882
Validation loss: 2.1190758841012114

Epoch: 5| Step: 9
Training loss: 2.4786810874938965
Validation loss: 2.1165364429514897

Epoch: 5| Step: 10
Training loss: 2.236326217651367
Validation loss: 2.0700188990562194

Epoch: 114| Step: 0
Training loss: 2.2598462104797363
Validation loss: 2.116895580804476

Epoch: 5| Step: 1
Training loss: 1.6910922527313232
Validation loss: 2.104984534684048

Epoch: 5| Step: 2
Training loss: 1.3756014108657837
Validation loss: 2.1098154860158123

Epoch: 5| Step: 3
Training loss: 2.228959560394287
Validation loss: 2.116252669724085

Epoch: 5| Step: 4
Training loss: 3.0258097648620605
Validation loss: 2.084455613167055

Epoch: 5| Step: 5
Training loss: 2.5747334957122803
Validation loss: 2.1031196373765186

Epoch: 5| Step: 6
Training loss: 2.171302556991577
Validation loss: 2.093688175242434

Epoch: 5| Step: 7
Training loss: 2.251410961151123
Validation loss: 2.1263423530004357

Epoch: 5| Step: 8
Training loss: 2.767678737640381
Validation loss: 2.1256853316419866

Epoch: 5| Step: 9
Training loss: 1.3972989320755005
Validation loss: 2.0820018809328795

Epoch: 5| Step: 10
Training loss: 2.7102954387664795
Validation loss: 2.1192343542652745

Epoch: 115| Step: 0
Training loss: 1.8493648767471313
Validation loss: 2.0907278214731524

Epoch: 5| Step: 1
Training loss: 2.4141314029693604
Validation loss: 2.0902126822420346

Epoch: 5| Step: 2
Training loss: 2.6291356086730957
Validation loss: 2.0780662003383843

Epoch: 5| Step: 3
Training loss: 2.180264711380005
Validation loss: 2.1214460865143807

Epoch: 5| Step: 4
Training loss: 1.836189866065979
Validation loss: 2.1161632460932576

Epoch: 5| Step: 5
Training loss: 2.4693827629089355
Validation loss: 2.119476423468641

Epoch: 5| Step: 6
Training loss: 2.538724899291992
Validation loss: 2.1121657484321186

Epoch: 5| Step: 7
Training loss: 2.3021483421325684
Validation loss: 2.103765954253494

Epoch: 5| Step: 8
Training loss: 1.928598403930664
Validation loss: 2.1096933272577103

Epoch: 5| Step: 9
Training loss: 1.6757196187973022
Validation loss: 2.0947218274557464

Epoch: 5| Step: 10
Training loss: 2.62764573097229
Validation loss: 2.123525616943195

Epoch: 116| Step: 0
Training loss: 2.4512200355529785
Validation loss: 2.1250376393718104

Epoch: 5| Step: 1
Training loss: 2.2301113605499268
Validation loss: 2.1261229925258185

Epoch: 5| Step: 2
Training loss: 2.166379928588867
Validation loss: 2.1357895533243814

Epoch: 5| Step: 3
Training loss: 2.6901698112487793
Validation loss: 2.117669226020895

Epoch: 5| Step: 4
Training loss: 2.839205503463745
Validation loss: 2.10256713949224

Epoch: 5| Step: 5
Training loss: 1.943516731262207
Validation loss: 2.0993152023643575

Epoch: 5| Step: 6
Training loss: 1.6347153186798096
Validation loss: 2.122165810677313

Epoch: 5| Step: 7
Training loss: 2.2364373207092285
Validation loss: 2.112579068829936

Epoch: 5| Step: 8
Training loss: 2.017263412475586
Validation loss: 2.094419848534369

Epoch: 5| Step: 9
Training loss: 2.251002550125122
Validation loss: 2.110581497992239

Epoch: 5| Step: 10
Training loss: 1.8859224319458008
Validation loss: 2.132424659626458

Epoch: 117| Step: 0
Training loss: 2.033658504486084
Validation loss: 2.135012657411637

Epoch: 5| Step: 1
Training loss: 1.601718544960022
Validation loss: 2.143940064214891

Epoch: 5| Step: 2
Training loss: 2.5963003635406494
Validation loss: 2.087226285729357

Epoch: 5| Step: 3
Training loss: 2.5522665977478027
Validation loss: 2.121519814255417

Epoch: 5| Step: 4
Training loss: 2.0928051471710205
Validation loss: 2.112484319235689

Epoch: 5| Step: 5
Training loss: 2.256643772125244
Validation loss: 2.1063804421373593

Epoch: 5| Step: 6
Training loss: 2.4596028327941895
Validation loss: 2.097963135729554

Epoch: 5| Step: 7
Training loss: 1.9894450902938843
Validation loss: 2.1115623827903502

Epoch: 5| Step: 8
Training loss: 2.5458407402038574
Validation loss: 2.1239632714179253

Epoch: 5| Step: 9
Training loss: 2.0274839401245117
Validation loss: 2.1386363378135105

Epoch: 5| Step: 10
Training loss: 1.8329342603683472
Validation loss: 2.1079675382183445

Epoch: 118| Step: 0
Training loss: 1.853703260421753
Validation loss: 2.1064554568259948

Epoch: 5| Step: 1
Training loss: 2.0207583904266357
Validation loss: 2.105693189046716

Epoch: 5| Step: 2
Training loss: 2.197667121887207
Validation loss: 2.1311382914102204

Epoch: 5| Step: 3
Training loss: 1.8970434665679932
Validation loss: 2.1033088776373092

Epoch: 5| Step: 4
Training loss: 2.0964787006378174
Validation loss: 2.0997896373912854

Epoch: 5| Step: 5
Training loss: 2.355374574661255
Validation loss: 2.1121372510028142

Epoch: 5| Step: 6
Training loss: 2.243579864501953
Validation loss: 2.1131202892590593

Epoch: 5| Step: 7
Training loss: 2.3766367435455322
Validation loss: 2.103424567048268

Epoch: 5| Step: 8
Training loss: 2.509021759033203
Validation loss: 2.10982927455697

Epoch: 5| Step: 9
Training loss: 2.079672336578369
Validation loss: 2.10534377508266

Epoch: 5| Step: 10
Training loss: 2.5425891876220703
Validation loss: 2.107553461546539

Epoch: 119| Step: 0
Training loss: 2.554670572280884
Validation loss: 2.1056650735998668

Epoch: 5| Step: 1
Training loss: 2.982722759246826
Validation loss: 2.123416430206709

Epoch: 5| Step: 2
Training loss: 1.3497564792633057
Validation loss: 2.1030213602127565

Epoch: 5| Step: 3
Training loss: 2.421360492706299
Validation loss: 2.1018069456982356

Epoch: 5| Step: 4
Training loss: 1.8299165964126587
Validation loss: 2.117428078446337

Epoch: 5| Step: 5
Training loss: 2.199646234512329
Validation loss: 2.105179596972722

Epoch: 5| Step: 6
Training loss: 2.519165277481079
Validation loss: 2.095323554931148

Epoch: 5| Step: 7
Training loss: 2.0297718048095703
Validation loss: 2.1349600156148276

Epoch: 5| Step: 8
Training loss: 2.6372618675231934
Validation loss: 2.135685584878409

Epoch: 5| Step: 9
Training loss: 1.694546103477478
Validation loss: 2.140741696921728

Epoch: 5| Step: 10
Training loss: 2.194340705871582
Validation loss: 2.1039657900410313

Epoch: 120| Step: 0
Training loss: 2.0583577156066895
Validation loss: 2.1242793631810013

Epoch: 5| Step: 1
Training loss: 2.117178440093994
Validation loss: 2.118336384014417

Epoch: 5| Step: 2
Training loss: 1.6439332962036133
Validation loss: 2.1038234772220736

Epoch: 5| Step: 3
Training loss: 2.2893097400665283
Validation loss: 2.0994715306066696

Epoch: 5| Step: 4
Training loss: 2.080288887023926
Validation loss: 2.1250500525197675

Epoch: 5| Step: 5
Training loss: 2.738234043121338
Validation loss: 2.100724894513366

Epoch: 5| Step: 6
Training loss: 2.742577314376831
Validation loss: 2.1193714962210706

Epoch: 5| Step: 7
Training loss: 2.26849627494812
Validation loss: 2.11525833734902

Epoch: 5| Step: 8
Training loss: 2.029202461242676
Validation loss: 2.079883445975601

Epoch: 5| Step: 9
Training loss: 2.286186695098877
Validation loss: 2.1071625730042816

Epoch: 5| Step: 10
Training loss: 1.9396216869354248
Validation loss: 2.0804706696541078

Epoch: 121| Step: 0
Training loss: 2.4278526306152344
Validation loss: 2.103815722209151

Epoch: 5| Step: 1
Training loss: 2.2202744483947754
Validation loss: 2.1179027865009923

Epoch: 5| Step: 2
Training loss: 2.432802438735962
Validation loss: 2.1022274301898096

Epoch: 5| Step: 3
Training loss: 2.702709674835205
Validation loss: 2.097943928933913

Epoch: 5| Step: 4
Training loss: 1.7261269092559814
Validation loss: 2.126456945173202

Epoch: 5| Step: 5
Training loss: 2.3703956604003906
Validation loss: 2.097212576097058

Epoch: 5| Step: 6
Training loss: 1.904531717300415
Validation loss: 2.1129770330203477

Epoch: 5| Step: 7
Training loss: 1.5405713319778442
Validation loss: 2.1064963404850294

Epoch: 5| Step: 8
Training loss: 2.2817397117614746
Validation loss: 2.0916857950149046

Epoch: 5| Step: 9
Training loss: 1.852574348449707
Validation loss: 2.108838910697609

Epoch: 5| Step: 10
Training loss: 2.6720223426818848
Validation loss: 2.0992963878057336

Epoch: 122| Step: 0
Training loss: 1.784351110458374
Validation loss: 2.0862908068523613

Epoch: 5| Step: 1
Training loss: 1.9369478225708008
Validation loss: 2.1004276198725544

Epoch: 5| Step: 2
Training loss: 2.5841870307922363
Validation loss: 2.0877567439950924

Epoch: 5| Step: 3
Training loss: 2.1957528591156006
Validation loss: 2.100641635156447

Epoch: 5| Step: 4
Training loss: 2.3984885215759277
Validation loss: 2.1183536373158938

Epoch: 5| Step: 5
Training loss: 2.4327666759490967
Validation loss: 2.0926898089788293

Epoch: 5| Step: 6
Training loss: 1.8375768661499023
Validation loss: 2.135422968095349

Epoch: 5| Step: 7
Training loss: 2.0186679363250732
Validation loss: 2.1255596978690035

Epoch: 5| Step: 8
Training loss: 2.2020821571350098
Validation loss: 2.1188671563261297

Epoch: 5| Step: 9
Training loss: 2.3640050888061523
Validation loss: 2.0929737526883363

Epoch: 5| Step: 10
Training loss: 2.607260227203369
Validation loss: 2.1241457154673915

Epoch: 123| Step: 0
Training loss: 2.4639687538146973
Validation loss: 2.117571282130416

Epoch: 5| Step: 1
Training loss: 1.8124815225601196
Validation loss: 2.108423955978886

Epoch: 5| Step: 2
Training loss: 1.5966198444366455
Validation loss: 2.124374989540346

Epoch: 5| Step: 3
Training loss: 1.3921822309494019
Validation loss: 2.124326358559311

Epoch: 5| Step: 4
Training loss: 2.0118408203125
Validation loss: 2.096658613092156

Epoch: 5| Step: 5
Training loss: 2.1680748462677
Validation loss: 2.1076268521688317

Epoch: 5| Step: 6
Training loss: 3.18149995803833
Validation loss: 2.095779590709235

Epoch: 5| Step: 7
Training loss: 2.229166030883789
Validation loss: 2.1432725691026255

Epoch: 5| Step: 8
Training loss: 2.4743762016296387
Validation loss: 2.142624093640235

Epoch: 5| Step: 9
Training loss: 2.465790271759033
Validation loss: 2.0750335467759

Epoch: 5| Step: 10
Training loss: 2.3580071926116943
Validation loss: 2.1228453715642295

Epoch: 124| Step: 0
Training loss: 2.335413932800293
Validation loss: 2.090106684674499

Epoch: 5| Step: 1
Training loss: 2.615954875946045
Validation loss: 2.105492330366565

Epoch: 5| Step: 2
Training loss: 2.1410515308380127
Validation loss: 2.1214638935622347

Epoch: 5| Step: 3
Training loss: 2.329637050628662
Validation loss: 2.1118658255505305

Epoch: 5| Step: 4
Training loss: 2.3173470497131348
Validation loss: 2.1304874304802186

Epoch: 5| Step: 5
Training loss: 1.6875932216644287
Validation loss: 2.1230663279051423

Epoch: 5| Step: 6
Training loss: 1.8668386936187744
Validation loss: 2.1109093966022616

Epoch: 5| Step: 7
Training loss: 2.156820774078369
Validation loss: 2.0892205276796894

Epoch: 5| Step: 8
Training loss: 2.2011075019836426
Validation loss: 2.147440743702714

Epoch: 5| Step: 9
Training loss: 2.0720155239105225
Validation loss: 2.117369286475643

Epoch: 5| Step: 10
Training loss: 2.3751423358917236
Validation loss: 2.1230280271140476

Epoch: 125| Step: 0
Training loss: 2.358994483947754
Validation loss: 2.0714049275203417

Epoch: 5| Step: 1
Training loss: 2.100764274597168
Validation loss: 2.1305154741451306

Epoch: 5| Step: 2
Training loss: 1.844906210899353
Validation loss: 2.109192878969254

Epoch: 5| Step: 3
Training loss: 2.8193938732147217
Validation loss: 2.1153067081205306

Epoch: 5| Step: 4
Training loss: 2.2733798027038574
Validation loss: 2.1018216084408503

Epoch: 5| Step: 5
Training loss: 2.2807726860046387
Validation loss: 2.0951099472661174

Epoch: 5| Step: 6
Training loss: 2.5635085105895996
Validation loss: 2.1145590556565153

Epoch: 5| Step: 7
Training loss: 2.0140442848205566
Validation loss: 2.1011690452534664

Epoch: 5| Step: 8
Training loss: 1.7776010036468506
Validation loss: 2.089150869718162

Epoch: 5| Step: 9
Training loss: 2.608839511871338
Validation loss: 2.1080016923207108

Epoch: 5| Step: 10
Training loss: 1.436787724494934
Validation loss: 2.0591138127029582

Epoch: 126| Step: 0
Training loss: 2.327004909515381
Validation loss: 2.0810783857940347

Epoch: 5| Step: 1
Training loss: 2.4037320613861084
Validation loss: 2.092493695597495

Epoch: 5| Step: 2
Training loss: 1.8927913904190063
Validation loss: 2.1043558300182386

Epoch: 5| Step: 3
Training loss: 1.32476007938385
Validation loss: 2.0903841295549945

Epoch: 5| Step: 4
Training loss: 2.983515501022339
Validation loss: 2.0857025090084282

Epoch: 5| Step: 5
Training loss: 2.7041265964508057
Validation loss: 2.1182508930083244

Epoch: 5| Step: 6
Training loss: 2.454090118408203
Validation loss: 2.1288398991348925

Epoch: 5| Step: 7
Training loss: 1.8191840648651123
Validation loss: 2.093833549048311

Epoch: 5| Step: 8
Training loss: 1.8800281286239624
Validation loss: 2.0924863699943788

Epoch: 5| Step: 9
Training loss: 1.9168434143066406
Validation loss: 2.099206583474272

Epoch: 5| Step: 10
Training loss: 2.2009451389312744
Validation loss: 2.1147433250181136

Epoch: 127| Step: 0
Training loss: 1.5653235912322998
Validation loss: 2.112146016090147

Epoch: 5| Step: 1
Training loss: 2.8526370525360107
Validation loss: 2.106275725108321

Epoch: 5| Step: 2
Training loss: 2.082162857055664
Validation loss: 2.0976295330191173

Epoch: 5| Step: 3
Training loss: 2.421123504638672
Validation loss: 2.103317250487625

Epoch: 5| Step: 4
Training loss: 1.692949891090393
Validation loss: 2.060020080176733

Epoch: 5| Step: 5
Training loss: 2.1673710346221924
Validation loss: 2.1140069859002226

Epoch: 5| Step: 6
Training loss: 1.80709707736969
Validation loss: 2.112007523095736

Epoch: 5| Step: 7
Training loss: 1.7996339797973633
Validation loss: 2.0950539471000753

Epoch: 5| Step: 8
Training loss: 2.368556261062622
Validation loss: 2.099756181880992

Epoch: 5| Step: 9
Training loss: 2.7738430500030518
Validation loss: 2.131704322753414

Epoch: 5| Step: 10
Training loss: 2.4876840114593506
Validation loss: 2.119668153024489

Epoch: 128| Step: 0
Training loss: 2.020101547241211
Validation loss: 2.128135053060388

Epoch: 5| Step: 1
Training loss: 3.0774903297424316
Validation loss: 2.1022086348584903

Epoch: 5| Step: 2
Training loss: 1.4876909255981445
Validation loss: 2.114840307543355

Epoch: 5| Step: 3
Training loss: 2.050443172454834
Validation loss: 2.1041162244735228

Epoch: 5| Step: 4
Training loss: 1.9117921590805054
Validation loss: 2.1083085075501473

Epoch: 5| Step: 5
Training loss: 2.4816019535064697
Validation loss: 2.0947549009835846

Epoch: 5| Step: 6
Training loss: 2.2340502738952637
Validation loss: 2.1061066722357147

Epoch: 5| Step: 7
Training loss: 2.457742691040039
Validation loss: 2.126921684511246

Epoch: 5| Step: 8
Training loss: 1.3678171634674072
Validation loss: 2.117779856087059

Epoch: 5| Step: 9
Training loss: 2.269012928009033
Validation loss: 2.109199288070843

Epoch: 5| Step: 10
Training loss: 2.7411961555480957
Validation loss: 2.1246550429251885

Epoch: 129| Step: 0
Training loss: 2.5114967823028564
Validation loss: 2.128761201776484

Epoch: 5| Step: 1
Training loss: 2.570115089416504
Validation loss: 2.128927861490557

Epoch: 5| Step: 2
Training loss: 2.322667121887207
Validation loss: 2.149688384866202

Epoch: 5| Step: 3
Training loss: 2.336714267730713
Validation loss: 2.121531909511935

Epoch: 5| Step: 4
Training loss: 2.239386796951294
Validation loss: 2.1140543440336823

Epoch: 5| Step: 5
Training loss: 1.9808051586151123
Validation loss: 2.0843011435642036

Epoch: 5| Step: 6
Training loss: 1.5220052003860474
Validation loss: 2.090269560454994

Epoch: 5| Step: 7
Training loss: 2.0315167903900146
Validation loss: 2.109668053606505

Epoch: 5| Step: 8
Training loss: 2.2214083671569824
Validation loss: 2.1031469478402087

Epoch: 5| Step: 9
Training loss: 1.588883638381958
Validation loss: 2.1391362028737224

Epoch: 5| Step: 10
Training loss: 2.5998737812042236
Validation loss: 2.1110309503411733

Epoch: 130| Step: 0
Training loss: 1.8934777975082397
Validation loss: 2.1133352479627057

Epoch: 5| Step: 1
Training loss: 2.408933401107788
Validation loss: 2.122979442278544

Epoch: 5| Step: 2
Training loss: 1.974590539932251
Validation loss: 2.1108458195963213

Epoch: 5| Step: 3
Training loss: 2.423595905303955
Validation loss: 2.0715347105456936

Epoch: 5| Step: 4
Training loss: 2.0993363857269287
Validation loss: 2.1057056842311734

Epoch: 5| Step: 5
Training loss: 1.316373348236084
Validation loss: 2.1018887155799457

Epoch: 5| Step: 6
Training loss: 2.8248143196105957
Validation loss: 2.140007600989393

Epoch: 5| Step: 7
Training loss: 2.237064838409424
Validation loss: 2.135801907508604

Epoch: 5| Step: 8
Training loss: 1.8022133111953735
Validation loss: 2.1173623197822162

Epoch: 5| Step: 9
Training loss: 2.5147690773010254
Validation loss: 2.0894332752432874

Epoch: 5| Step: 10
Training loss: 2.446800947189331
Validation loss: 2.1326890632670414

Epoch: 131| Step: 0
Training loss: 2.8068511486053467
Validation loss: 2.0999801620360343

Epoch: 5| Step: 1
Training loss: 2.0215349197387695
Validation loss: 2.096402084955605

Epoch: 5| Step: 2
Training loss: 2.7084801197052
Validation loss: 2.084857568945936

Epoch: 5| Step: 3
Training loss: 1.7974010705947876
Validation loss: 2.1093987828941754

Epoch: 5| Step: 4
Training loss: 1.5685813426971436
Validation loss: 2.1250222101006457

Epoch: 5| Step: 5
Training loss: 1.9017244577407837
Validation loss: 2.1017076302600164

Epoch: 5| Step: 6
Training loss: 2.4610824584960938
Validation loss: 2.1066838438792894

Epoch: 5| Step: 7
Training loss: 2.1224703788757324
Validation loss: 2.110587793011819

Epoch: 5| Step: 8
Training loss: 2.2105417251586914
Validation loss: 2.110754903926644

Epoch: 5| Step: 9
Training loss: 2.1671810150146484
Validation loss: 2.0612588902955413

Epoch: 5| Step: 10
Training loss: 2.1743009090423584
Validation loss: 2.1118641232931488

Epoch: 132| Step: 0
Training loss: 2.5526881217956543
Validation loss: 2.0981884028321955

Epoch: 5| Step: 1
Training loss: 2.1348423957824707
Validation loss: 2.1082069873809814

Epoch: 5| Step: 2
Training loss: 2.0786490440368652
Validation loss: 2.1231977144877114

Epoch: 5| Step: 3
Training loss: 2.1653964519500732
Validation loss: 2.0986885614292596

Epoch: 5| Step: 4
Training loss: 2.6355478763580322
Validation loss: 2.0954237823845236

Epoch: 5| Step: 5
Training loss: 1.650475263595581
Validation loss: 2.094445010667206

Epoch: 5| Step: 6
Training loss: 1.668765664100647
Validation loss: 2.1151694277281403

Epoch: 5| Step: 7
Training loss: 2.6997196674346924
Validation loss: 2.1207548161988616

Epoch: 5| Step: 8
Training loss: 2.816195011138916
Validation loss: 2.1152691559125016

Epoch: 5| Step: 9
Training loss: 1.9538838863372803
Validation loss: 2.104795781514978

Epoch: 5| Step: 10
Training loss: 0.994592547416687
Validation loss: 2.118952722959621

Epoch: 133| Step: 0
Training loss: 2.2118308544158936
Validation loss: 2.1120409273332164

Epoch: 5| Step: 1
Training loss: 1.7790381908416748
Validation loss: 2.1244984044823596

Epoch: 5| Step: 2
Training loss: 1.4529497623443604
Validation loss: 2.1235899566322245

Epoch: 5| Step: 3
Training loss: 2.5540716648101807
Validation loss: 2.1073860250493532

Epoch: 5| Step: 4
Training loss: 2.651931047439575
Validation loss: 2.120783687919699

Epoch: 5| Step: 5
Training loss: 2.580331802368164
Validation loss: 2.1011050965196345

Epoch: 5| Step: 6
Training loss: 2.257826328277588
Validation loss: 2.1139859768652145

Epoch: 5| Step: 7
Training loss: 1.229365587234497
Validation loss: 2.098580703940443

Epoch: 5| Step: 8
Training loss: 1.775111436843872
Validation loss: 2.12212263384173

Epoch: 5| Step: 9
Training loss: 2.965564727783203
Validation loss: 2.1022776019188667

Epoch: 5| Step: 10
Training loss: 2.3131260871887207
Validation loss: 2.125324644068236

Epoch: 134| Step: 0
Training loss: 2.4920756816864014
Validation loss: 2.1064534123225878

Epoch: 5| Step: 1
Training loss: 2.00541353225708
Validation loss: 2.118453018126949

Epoch: 5| Step: 2
Training loss: 2.2615439891815186
Validation loss: 2.0980363609970256

Epoch: 5| Step: 3
Training loss: 2.266775608062744
Validation loss: 2.102378765741984

Epoch: 5| Step: 4
Training loss: 1.957787275314331
Validation loss: 2.093373344790551

Epoch: 5| Step: 5
Training loss: 2.699756622314453
Validation loss: 2.136054465847631

Epoch: 5| Step: 6
Training loss: 2.356928586959839
Validation loss: 2.1171436566178516

Epoch: 5| Step: 7
Training loss: 1.9658136367797852
Validation loss: 2.1398810507148824

Epoch: 5| Step: 8
Training loss: 2.11677885055542
Validation loss: 2.0980282598926174

Epoch: 5| Step: 9
Training loss: 1.5977727174758911
Validation loss: 2.1297051816858272

Epoch: 5| Step: 10
Training loss: 1.9907509088516235
Validation loss: 2.1341666483109996

Epoch: 135| Step: 0
Training loss: 2.1242895126342773
Validation loss: 2.1363402387147308

Epoch: 5| Step: 1
Training loss: 1.7781938314437866
Validation loss: 2.12333349515033

Epoch: 5| Step: 2
Training loss: 2.3411142826080322
Validation loss: 2.0909958757380003

Epoch: 5| Step: 3
Training loss: 1.9565603733062744
Validation loss: 2.1182871928779026

Epoch: 5| Step: 4
Training loss: 1.8741233348846436
Validation loss: 2.1095286748742543

Epoch: 5| Step: 5
Training loss: 2.657841444015503
Validation loss: 2.098395001503729

Epoch: 5| Step: 6
Training loss: 2.210819959640503
Validation loss: 2.1082161447053314

Epoch: 5| Step: 7
Training loss: 2.5775790214538574
Validation loss: 2.099964234136766

Epoch: 5| Step: 8
Training loss: 1.6181066036224365
Validation loss: 2.1005720579495994

Epoch: 5| Step: 9
Training loss: 2.5590081214904785
Validation loss: 2.12750885563512

Epoch: 5| Step: 10
Training loss: 2.0619773864746094
Validation loss: 2.113517551011937

Epoch: 136| Step: 0
Training loss: 1.4642090797424316
Validation loss: 2.134373946856427

Epoch: 5| Step: 1
Training loss: 2.3573691844940186
Validation loss: 2.070922656725812

Epoch: 5| Step: 2
Training loss: 2.5173439979553223
Validation loss: 2.080626045503924

Epoch: 5| Step: 3
Training loss: 2.8112292289733887
Validation loss: 2.1243739769022953

Epoch: 5| Step: 4
Training loss: 1.9852616786956787
Validation loss: 2.1080990529829458

Epoch: 5| Step: 5
Training loss: 1.7926428318023682
Validation loss: 2.131473179786436

Epoch: 5| Step: 6
Training loss: 2.309114694595337
Validation loss: 2.098051360858384

Epoch: 5| Step: 7
Training loss: 2.232597827911377
Validation loss: 2.109236099386728

Epoch: 5| Step: 8
Training loss: 2.2703940868377686
Validation loss: 2.1268390455553607

Epoch: 5| Step: 9
Training loss: 2.1068782806396484
Validation loss: 2.113008876000681

Epoch: 5| Step: 10
Training loss: 1.9167684316635132
Validation loss: 2.1198227764457784

Epoch: 137| Step: 0
Training loss: 1.7583873271942139
Validation loss: 2.111747557117093

Epoch: 5| Step: 1
Training loss: 1.8692848682403564
Validation loss: 2.1163782124878256

Epoch: 5| Step: 2
Training loss: 1.9379847049713135
Validation loss: 2.1201165158261537

Epoch: 5| Step: 3
Training loss: 2.1253228187561035
Validation loss: 2.12022130720077

Epoch: 5| Step: 4
Training loss: 2.258241653442383
Validation loss: 2.1388866619397233

Epoch: 5| Step: 5
Training loss: 2.496291160583496
Validation loss: 2.1128156338968584

Epoch: 5| Step: 6
Training loss: 2.2429258823394775
Validation loss: 2.067131257826282

Epoch: 5| Step: 7
Training loss: 2.6529364585876465
Validation loss: 2.1076857069487214

Epoch: 5| Step: 8
Training loss: 2.381202459335327
Validation loss: 2.118286245612688

Epoch: 5| Step: 9
Training loss: 2.1064817905426025
Validation loss: 2.12683795344445

Epoch: 5| Step: 10
Training loss: 1.975524663925171
Validation loss: 2.0969887984696256

Epoch: 138| Step: 0
Training loss: 1.9829975366592407
Validation loss: 2.1112532282388337

Epoch: 5| Step: 1
Training loss: 2.1084470748901367
Validation loss: 2.1089382325449297

Epoch: 5| Step: 2
Training loss: 1.884178876876831
Validation loss: 2.105640099894616

Epoch: 5| Step: 3
Training loss: 2.1750664710998535
Validation loss: 2.1143363957764

Epoch: 5| Step: 4
Training loss: 2.3748250007629395
Validation loss: 2.1234953070199616

Epoch: 5| Step: 5
Training loss: 2.3246827125549316
Validation loss: 2.101183937441918

Epoch: 5| Step: 6
Training loss: 1.8329414129257202
Validation loss: 2.0871427738538353

Epoch: 5| Step: 7
Training loss: 1.7480106353759766
Validation loss: 2.104541823428164

Epoch: 5| Step: 8
Training loss: 2.759050130844116
Validation loss: 2.097504661929223

Epoch: 5| Step: 9
Training loss: 2.9294910430908203
Validation loss: 2.1008724294682986

Epoch: 5| Step: 10
Training loss: 1.3631997108459473
Validation loss: 2.1173813753230597

Epoch: 139| Step: 0
Training loss: 2.0489251613616943
Validation loss: 2.121288694361205

Epoch: 5| Step: 1
Training loss: 2.6620960235595703
Validation loss: 2.084542086047511

Epoch: 5| Step: 2
Training loss: 1.5072582960128784
Validation loss: 2.110574076252599

Epoch: 5| Step: 3
Training loss: 2.026073694229126
Validation loss: 2.111062122929481

Epoch: 5| Step: 4
Training loss: 2.2479164600372314
Validation loss: 2.088738518376504

Epoch: 5| Step: 5
Training loss: 2.3682684898376465
Validation loss: 2.109862491648684

Epoch: 5| Step: 6
Training loss: 2.5046322345733643
Validation loss: 2.09728588340103

Epoch: 5| Step: 7
Training loss: 1.9779589176177979
Validation loss: 2.1124393440062

Epoch: 5| Step: 8
Training loss: 1.7966610193252563
Validation loss: 2.1195357461129465

Epoch: 5| Step: 9
Training loss: 1.8466565608978271
Validation loss: 2.098273838720014

Epoch: 5| Step: 10
Training loss: 2.8167858123779297
Validation loss: 2.1193404941148657

Epoch: 140| Step: 0
Training loss: 2.257275104522705
Validation loss: 2.1048892005797355

Epoch: 5| Step: 1
Training loss: 2.3930301666259766
Validation loss: 2.1063680956440587

Epoch: 5| Step: 2
Training loss: 1.8282842636108398
Validation loss: 2.125882419206763

Epoch: 5| Step: 3
Training loss: 1.5802297592163086
Validation loss: 2.1046135528113252

Epoch: 5| Step: 4
Training loss: 2.5749082565307617
Validation loss: 2.079658241682155

Epoch: 5| Step: 5
Training loss: 1.9791902303695679
Validation loss: 2.115211111243053

Epoch: 5| Step: 6
Training loss: 1.7372668981552124
Validation loss: 2.107367368154628

Epoch: 5| Step: 7
Training loss: 2.080780506134033
Validation loss: 2.0949685419759443

Epoch: 5| Step: 8
Training loss: 2.4927406311035156
Validation loss: 2.1342456315153386

Epoch: 5| Step: 9
Training loss: 2.1466410160064697
Validation loss: 2.098999486174635

Epoch: 5| Step: 10
Training loss: 2.5692379474639893
Validation loss: 2.122352642397727

Epoch: 141| Step: 0
Training loss: 2.0779576301574707
Validation loss: 2.0961999252278316

Epoch: 5| Step: 1
Training loss: 2.3965487480163574
Validation loss: 2.0957759144485637

Epoch: 5| Step: 2
Training loss: 1.4688093662261963
Validation loss: 2.1267548427786878

Epoch: 5| Step: 3
Training loss: 2.0237324237823486
Validation loss: 2.08799401662683

Epoch: 5| Step: 4
Training loss: 2.596698045730591
Validation loss: 2.1082452881720757

Epoch: 5| Step: 5
Training loss: 1.881556510925293
Validation loss: 2.1448746022357734

Epoch: 5| Step: 6
Training loss: 2.3659732341766357
Validation loss: 2.0959925741277714

Epoch: 5| Step: 7
Training loss: 2.3957371711730957
Validation loss: 2.1602716087013163

Epoch: 5| Step: 8
Training loss: 2.0325303077697754
Validation loss: 2.1339087998995216

Epoch: 5| Step: 9
Training loss: 2.477623701095581
Validation loss: 2.1092605129365

Epoch: 5| Step: 10
Training loss: 1.7607760429382324
Validation loss: 2.116421894360614

Epoch: 142| Step: 0
Training loss: 2.226261854171753
Validation loss: 2.1094830612982474

Epoch: 5| Step: 1
Training loss: 2.946164608001709
Validation loss: 2.1060900547171153

Epoch: 5| Step: 2
Training loss: 2.397906541824341
Validation loss: 2.1109076135901996

Epoch: 5| Step: 3
Training loss: 2.0026447772979736
Validation loss: 2.1218418587920485

Epoch: 5| Step: 4
Training loss: 1.8133366107940674
Validation loss: 2.1251109582121654

Epoch: 5| Step: 5
Training loss: 2.1212048530578613
Validation loss: 2.1046991245720976

Epoch: 5| Step: 6
Training loss: 1.6732585430145264
Validation loss: 2.104967645419541

Epoch: 5| Step: 7
Training loss: 1.8828128576278687
Validation loss: 2.1201693140050417

Epoch: 5| Step: 8
Training loss: 2.6526758670806885
Validation loss: 2.1031375597882014

Epoch: 5| Step: 9
Training loss: 2.2015175819396973
Validation loss: 2.127348135876399

Epoch: 5| Step: 10
Training loss: 1.6307742595672607
Validation loss: 2.1077310218605945

Epoch: 143| Step: 0
Training loss: 1.7877624034881592
Validation loss: 2.1012854396655993

Epoch: 5| Step: 1
Training loss: 1.9977947473526
Validation loss: 2.1420256386521044

Epoch: 5| Step: 2
Training loss: 1.5485771894454956
Validation loss: 2.088188858442409

Epoch: 5| Step: 3
Training loss: 2.6039271354675293
Validation loss: 2.11795037792575

Epoch: 5| Step: 4
Training loss: 2.098698377609253
Validation loss: 2.111877396542539

Epoch: 5| Step: 5
Training loss: 2.2829430103302
Validation loss: 2.0984709878121652

Epoch: 5| Step: 6
Training loss: 2.4705095291137695
Validation loss: 2.0963677462711128

Epoch: 5| Step: 7
Training loss: 1.8295917510986328
Validation loss: 2.094761492103659

Epoch: 5| Step: 8
Training loss: 2.44555926322937
Validation loss: 2.1259666565925843

Epoch: 5| Step: 9
Training loss: 1.982602834701538
Validation loss: 2.1238845599594938

Epoch: 5| Step: 10
Training loss: 2.3959312438964844
Validation loss: 2.0934736779941026

Epoch: 144| Step: 0
Training loss: 1.9185596704483032
Validation loss: 2.122297015241397

Epoch: 5| Step: 1
Training loss: 2.561654567718506
Validation loss: 2.137143519616896

Epoch: 5| Step: 2
Training loss: 2.413115978240967
Validation loss: 2.0974651536633893

Epoch: 5| Step: 3
Training loss: 1.9104223251342773
Validation loss: 2.1118663139240716

Epoch: 5| Step: 4
Training loss: 1.9933178424835205
Validation loss: 2.1549767832602225

Epoch: 5| Step: 5
Training loss: 2.1883082389831543
Validation loss: 2.1427510784518335

Epoch: 5| Step: 6
Training loss: 2.0720818042755127
Validation loss: 2.1149688638666624

Epoch: 5| Step: 7
Training loss: 1.8847191333770752
Validation loss: 2.1269504177954888

Epoch: 5| Step: 8
Training loss: 1.3583654165267944
Validation loss: 2.141684562929215

Epoch: 5| Step: 9
Training loss: 3.365170955657959
Validation loss: 2.116007835634293

Epoch: 5| Step: 10
Training loss: 1.904017686843872
Validation loss: 2.1392131056836856

Epoch: 145| Step: 0
Training loss: 1.7935031652450562
Validation loss: 2.0884603082492785

Epoch: 5| Step: 1
Training loss: 2.335108757019043
Validation loss: 2.0953759249820503

Epoch: 5| Step: 2
Training loss: 1.9753824472427368
Validation loss: 2.1213723433915006

Epoch: 5| Step: 3
Training loss: 2.241208553314209
Validation loss: 2.0917153435368694

Epoch: 5| Step: 4
Training loss: 2.2162225246429443
Validation loss: 2.099791044829994

Epoch: 5| Step: 5
Training loss: 2.2158923149108887
Validation loss: 2.120695129517586

Epoch: 5| Step: 6
Training loss: 2.3953475952148438
Validation loss: 2.1233492500038555

Epoch: 5| Step: 7
Training loss: 2.205645799636841
Validation loss: 2.099396267244893

Epoch: 5| Step: 8
Training loss: 2.409266710281372
Validation loss: 2.108413803961969

Epoch: 5| Step: 9
Training loss: 2.0002901554107666
Validation loss: 2.1109648212309806

Epoch: 5| Step: 10
Training loss: 1.7840603590011597
Validation loss: 2.1087975399468535

Epoch: 146| Step: 0
Training loss: 2.139533042907715
Validation loss: 2.1032120720032723

Epoch: 5| Step: 1
Training loss: 2.1543755531311035
Validation loss: 2.1178729226512294

Epoch: 5| Step: 2
Training loss: 2.1932384967803955
Validation loss: 2.0900298421100905

Epoch: 5| Step: 3
Training loss: 1.8053090572357178
Validation loss: 2.093723040755077

Epoch: 5| Step: 4
Training loss: 1.9720203876495361
Validation loss: 2.0928579889317995

Epoch: 5| Step: 5
Training loss: 2.147118091583252
Validation loss: 2.080436296360467

Epoch: 5| Step: 6
Training loss: 2.1020565032958984
Validation loss: 2.1081472032813617

Epoch: 5| Step: 7
Training loss: 1.9518266916275024
Validation loss: 2.1111081582243725

Epoch: 5| Step: 8
Training loss: 2.39237642288208
Validation loss: 2.0875704083391415

Epoch: 5| Step: 9
Training loss: 2.4670228958129883
Validation loss: 2.1142294996528217

Epoch: 5| Step: 10
Training loss: 2.146202564239502
Validation loss: 2.1122708089890017

Epoch: 147| Step: 0
Training loss: 2.7485430240631104
Validation loss: 2.115303434351439

Epoch: 5| Step: 1
Training loss: 1.7062389850616455
Validation loss: 2.0929046036094747

Epoch: 5| Step: 2
Training loss: 1.8191159963607788
Validation loss: 2.1219331090168287

Epoch: 5| Step: 3
Training loss: 1.9917945861816406
Validation loss: 2.0758633049585486

Epoch: 5| Step: 4
Training loss: 1.966719388961792
Validation loss: 2.0957235443976616

Epoch: 5| Step: 5
Training loss: 2.896184206008911
Validation loss: 2.1197358715918755

Epoch: 5| Step: 6
Training loss: 2.3765923976898193
Validation loss: 2.122285589095085

Epoch: 5| Step: 7
Training loss: 2.325894832611084
Validation loss: 2.1141870496093587

Epoch: 5| Step: 8
Training loss: 1.7184534072875977
Validation loss: 2.093452752277415

Epoch: 5| Step: 9
Training loss: 1.5509806871414185
Validation loss: 2.1105882416489306

Epoch: 5| Step: 10
Training loss: 2.631202220916748
Validation loss: 2.0894622956552813

Epoch: 148| Step: 0
Training loss: 2.3035356998443604
Validation loss: 2.1003575043011735

Epoch: 5| Step: 1
Training loss: 2.562840700149536
Validation loss: 2.115649930892452

Epoch: 5| Step: 2
Training loss: 2.0007917881011963
Validation loss: 2.0973478747952368

Epoch: 5| Step: 3
Training loss: 1.8678131103515625
Validation loss: 2.0940006727813394

Epoch: 5| Step: 4
Training loss: 2.594883680343628
Validation loss: 2.1108172516668997

Epoch: 5| Step: 5
Training loss: 1.9129911661148071
Validation loss: 2.108661554192984

Epoch: 5| Step: 6
Training loss: 2.4244155883789062
Validation loss: 2.0857114458596833

Epoch: 5| Step: 7
Training loss: 1.641601800918579
Validation loss: 2.0974251813786005

Epoch: 5| Step: 8
Training loss: 2.2887954711914062
Validation loss: 2.0891010389533093

Epoch: 5| Step: 9
Training loss: 1.5358388423919678
Validation loss: 2.084869989784815

Epoch: 5| Step: 10
Training loss: 2.0696253776550293
Validation loss: 2.085721908077117

Epoch: 149| Step: 0
Training loss: 1.6625452041625977
Validation loss: 2.098201920909266

Epoch: 5| Step: 1
Training loss: 2.3437225818634033
Validation loss: 2.0943295007110923

Epoch: 5| Step: 2
Training loss: 2.4013519287109375
Validation loss: 2.0930554238698815

Epoch: 5| Step: 3
Training loss: 1.9417428970336914
Validation loss: 2.107590795845114

Epoch: 5| Step: 4
Training loss: 2.304971694946289
Validation loss: 2.082108925747615

Epoch: 5| Step: 5
Training loss: 2.3055195808410645
Validation loss: 2.093669613202413

Epoch: 5| Step: 6
Training loss: 2.492828607559204
Validation loss: 2.0985256907760457

Epoch: 5| Step: 7
Training loss: 2.0852179527282715
Validation loss: 2.1079054212057464

Epoch: 5| Step: 8
Training loss: 2.3914718627929688
Validation loss: 2.121743820046866

Epoch: 5| Step: 9
Training loss: 1.429062843322754
Validation loss: 2.1038537281815723

Epoch: 5| Step: 10
Training loss: 2.0034193992614746
Validation loss: 2.112603913071335

Epoch: 150| Step: 0
Training loss: 2.444619655609131
Validation loss: 2.123027117021622

Epoch: 5| Step: 1
Training loss: 2.606870412826538
Validation loss: 2.0805793936534593

Epoch: 5| Step: 2
Training loss: 1.400649070739746
Validation loss: 2.0651210354220484

Epoch: 5| Step: 3
Training loss: 2.4212536811828613
Validation loss: 2.1200006572149133

Epoch: 5| Step: 4
Training loss: 2.091991901397705
Validation loss: 2.087280402901352

Epoch: 5| Step: 5
Training loss: 1.957972764968872
Validation loss: 2.136216502035818

Epoch: 5| Step: 6
Training loss: 1.9910447597503662
Validation loss: 2.128086159306188

Epoch: 5| Step: 7
Training loss: 2.039780378341675
Validation loss: 2.10271623826796

Epoch: 5| Step: 8
Training loss: 2.206935405731201
Validation loss: 2.10509241268199

Epoch: 5| Step: 9
Training loss: 2.0460920333862305
Validation loss: 2.1082160959961596

Epoch: 5| Step: 10
Training loss: 2.070673704147339
Validation loss: 2.106197013649889

Epoch: 151| Step: 0
Training loss: 2.2762961387634277
Validation loss: 2.112539845128213

Epoch: 5| Step: 1
Training loss: 2.2484545707702637
Validation loss: 2.1328981922518824

Epoch: 5| Step: 2
Training loss: 2.4742579460144043
Validation loss: 2.0872544216853317

Epoch: 5| Step: 3
Training loss: 2.2604851722717285
Validation loss: 2.1244215349997244

Epoch: 5| Step: 4
Training loss: 2.2450175285339355
Validation loss: 2.1022075376202984

Epoch: 5| Step: 5
Training loss: 2.077639102935791
Validation loss: 2.1089231147561023

Epoch: 5| Step: 6
Training loss: 1.9862667322158813
Validation loss: 2.1120335901937177

Epoch: 5| Step: 7
Training loss: 2.225862979888916
Validation loss: 2.0989572014859927

Epoch: 5| Step: 8
Training loss: 1.7680097818374634
Validation loss: 2.1490627104236233

Epoch: 5| Step: 9
Training loss: 1.8586361408233643
Validation loss: 2.107440802358812

Epoch: 5| Step: 10
Training loss: 1.8173439502716064
Validation loss: 2.09029754131071

Epoch: 152| Step: 0
Training loss: 1.6697295904159546
Validation loss: 2.0708389935954923

Epoch: 5| Step: 1
Training loss: 2.034416913986206
Validation loss: 2.0818963409751974

Epoch: 5| Step: 2
Training loss: 2.1706480979919434
Validation loss: 2.088692936846005

Epoch: 5| Step: 3
Training loss: 1.168777346611023
Validation loss: 2.0910793530043734

Epoch: 5| Step: 4
Training loss: 2.479970932006836
Validation loss: 2.1320013077028337

Epoch: 5| Step: 5
Training loss: 2.1533730030059814
Validation loss: 2.0870779099002963

Epoch: 5| Step: 6
Training loss: 2.5723729133605957
Validation loss: 2.0974590598895984

Epoch: 5| Step: 7
Training loss: 2.1148040294647217
Validation loss: 2.073332405859424

Epoch: 5| Step: 8
Training loss: 1.8417508602142334
Validation loss: 2.09090744808156

Epoch: 5| Step: 9
Training loss: 2.7879931926727295
Validation loss: 2.106101205272059

Epoch: 5| Step: 10
Training loss: 2.295961380004883
Validation loss: 2.1001601731905373

Epoch: 153| Step: 0
Training loss: 1.4251455068588257
Validation loss: 2.1231806406410794

Epoch: 5| Step: 1
Training loss: 2.12341046333313
Validation loss: 2.084619314439835

Epoch: 5| Step: 2
Training loss: 2.907571315765381
Validation loss: 2.074187422311434

Epoch: 5| Step: 3
Training loss: 2.758167028427124
Validation loss: 2.081659056807077

Epoch: 5| Step: 4
Training loss: 1.8755733966827393
Validation loss: 2.114104526017302

Epoch: 5| Step: 5
Training loss: 1.9523680210113525
Validation loss: 2.10565120943131

Epoch: 5| Step: 6
Training loss: 1.9814542531967163
Validation loss: 2.104456384976705

Epoch: 5| Step: 7
Training loss: 2.36614727973938
Validation loss: 2.075750150988179

Epoch: 5| Step: 8
Training loss: 1.6807750463485718
Validation loss: 2.097310648169569

Epoch: 5| Step: 9
Training loss: 1.753211259841919
Validation loss: 2.088689652822351

Epoch: 5| Step: 10
Training loss: 2.429285764694214
Validation loss: 2.1067138974384596

Epoch: 154| Step: 0
Training loss: 1.4828450679779053
Validation loss: 2.0730163140963485

Epoch: 5| Step: 1
Training loss: 2.4916982650756836
Validation loss: 2.119420918085242

Epoch: 5| Step: 2
Training loss: 2.241534471511841
Validation loss: 2.0825339594194965

Epoch: 5| Step: 3
Training loss: 1.9171016216278076
Validation loss: 2.1123017277768863

Epoch: 5| Step: 4
Training loss: 2.2184464931488037
Validation loss: 2.111685597768394

Epoch: 5| Step: 5
Training loss: 2.055424213409424
Validation loss: 2.089124748783727

Epoch: 5| Step: 6
Training loss: 2.06488037109375
Validation loss: 2.0879141540937525

Epoch: 5| Step: 7
Training loss: 2.1240124702453613
Validation loss: 2.0920365959085445

Epoch: 5| Step: 8
Training loss: 1.9838354587554932
Validation loss: 2.0772762067856325

Epoch: 5| Step: 9
Training loss: 2.217247486114502
Validation loss: 2.0989020434758996

Epoch: 5| Step: 10
Training loss: 2.2536864280700684
Validation loss: 2.1146964411581717

Epoch: 155| Step: 0
Training loss: 1.7784290313720703
Validation loss: 2.108402056078757

Epoch: 5| Step: 1
Training loss: 1.5766487121582031
Validation loss: 2.069543625718804

Epoch: 5| Step: 2
Training loss: 2.30716609954834
Validation loss: 2.068261956655851

Epoch: 5| Step: 3
Training loss: 1.5955482721328735
Validation loss: 2.1011225279941352

Epoch: 5| Step: 4
Training loss: 2.5747158527374268
Validation loss: 2.0980364584153697

Epoch: 5| Step: 5
Training loss: 2.2611777782440186
Validation loss: 2.110038782960625

Epoch: 5| Step: 6
Training loss: 1.6180963516235352
Validation loss: 2.0906538604408182

Epoch: 5| Step: 7
Training loss: 1.1624640226364136
Validation loss: 2.1096863182642127

Epoch: 5| Step: 8
Training loss: 2.778379440307617
Validation loss: 2.1074105924175632

Epoch: 5| Step: 9
Training loss: 3.0440855026245117
Validation loss: 2.1150194393691195

Epoch: 5| Step: 10
Training loss: 2.3768723011016846
Validation loss: 2.090583780760406

Epoch: 156| Step: 0
Training loss: 1.4418855905532837
Validation loss: 2.089905374793596

Epoch: 5| Step: 1
Training loss: 1.6998398303985596
Validation loss: 2.09911221970794

Epoch: 5| Step: 2
Training loss: 1.622948408126831
Validation loss: 2.122847903159357

Epoch: 5| Step: 3
Training loss: 1.9424415826797485
Validation loss: 2.0877886344027776

Epoch: 5| Step: 4
Training loss: 1.76603102684021
Validation loss: 2.1263053878661125

Epoch: 5| Step: 5
Training loss: 2.07830548286438
Validation loss: 2.0956896735775854

Epoch: 5| Step: 6
Training loss: 2.3463284969329834
Validation loss: 2.106359125465475

Epoch: 5| Step: 7
Training loss: 2.520413875579834
Validation loss: 2.088459684002784

Epoch: 5| Step: 8
Training loss: 2.0250890254974365
Validation loss: 2.091279419519568

Epoch: 5| Step: 9
Training loss: 2.7872796058654785
Validation loss: 2.0842130671265306

Epoch: 5| Step: 10
Training loss: 2.582266330718994
Validation loss: 2.1043935565538305

Epoch: 157| Step: 0
Training loss: 1.7650543451309204
Validation loss: 2.086131275341075

Epoch: 5| Step: 1
Training loss: 1.823861837387085
Validation loss: 2.0894800809121903

Epoch: 5| Step: 2
Training loss: 1.7242727279663086
Validation loss: 2.0768787386596843

Epoch: 5| Step: 3
Training loss: 1.9874664545059204
Validation loss: 2.092879943950202

Epoch: 5| Step: 4
Training loss: 2.764206647872925
Validation loss: 2.089308225980369

Epoch: 5| Step: 5
Training loss: 2.450549602508545
Validation loss: 2.0700755170596543

Epoch: 5| Step: 6
Training loss: 2.330047607421875
Validation loss: 2.0725258678518315

Epoch: 5| Step: 7
Training loss: 2.184083938598633
Validation loss: 2.1269805662093626

Epoch: 5| Step: 8
Training loss: 1.778454065322876
Validation loss: 2.0985902073562785

Epoch: 5| Step: 9
Training loss: 2.7859034538269043
Validation loss: 2.114143156236218

Epoch: 5| Step: 10
Training loss: 1.4619710445404053
Validation loss: 2.1074514747947775

Epoch: 158| Step: 0
Training loss: 2.130244731903076
Validation loss: 2.0845584830930157

Epoch: 5| Step: 1
Training loss: 2.9754798412323
Validation loss: 2.090331715922202

Epoch: 5| Step: 2
Training loss: 1.8201806545257568
Validation loss: 2.079152291820895

Epoch: 5| Step: 3
Training loss: 1.5766149759292603
Validation loss: 2.0794599915063507

Epoch: 5| Step: 4
Training loss: 2.0585548877716064
Validation loss: 2.0671436273923485

Epoch: 5| Step: 5
Training loss: 1.9534575939178467
Validation loss: 2.093665933096281

Epoch: 5| Step: 6
Training loss: 2.293283462524414
Validation loss: 2.1314201098616405

Epoch: 5| Step: 7
Training loss: 2.2249624729156494
Validation loss: 2.0990738407258065

Epoch: 5| Step: 8
Training loss: 2.137437105178833
Validation loss: 2.0601020141314437

Epoch: 5| Step: 9
Training loss: 1.9090057611465454
Validation loss: 2.105150520160634

Epoch: 5| Step: 10
Training loss: 1.9979779720306396
Validation loss: 2.130370598967357

Epoch: 159| Step: 0
Training loss: 1.6444947719573975
Validation loss: 2.119566732837308

Epoch: 5| Step: 1
Training loss: 2.294424057006836
Validation loss: 2.0849526005406536

Epoch: 5| Step: 2
Training loss: 2.288698434829712
Validation loss: 2.0950858439168623

Epoch: 5| Step: 3
Training loss: 2.4603168964385986
Validation loss: 2.1018199715563046

Epoch: 5| Step: 4
Training loss: 1.520655632019043
Validation loss: 2.153351583788472

Epoch: 5| Step: 5
Training loss: 1.7871824502944946
Validation loss: 2.113901038323679

Epoch: 5| Step: 6
Training loss: 2.0320119857788086
Validation loss: 2.072913487752279

Epoch: 5| Step: 7
Training loss: 2.210690975189209
Validation loss: 2.1058644517775504

Epoch: 5| Step: 8
Training loss: 2.5507972240448
Validation loss: 2.086519777133901

Epoch: 5| Step: 9
Training loss: 1.9540703296661377
Validation loss: 2.086342247583533

Epoch: 5| Step: 10
Training loss: 2.1687450408935547
Validation loss: 2.1042875705226773

Epoch: 160| Step: 0
Training loss: 1.9536319971084595
Validation loss: 2.095027267291982

Epoch: 5| Step: 1
Training loss: 1.9917619228363037
Validation loss: 2.1079224130158782

Epoch: 5| Step: 2
Training loss: 2.2930078506469727
Validation loss: 2.0863728689891037

Epoch: 5| Step: 3
Training loss: 2.1794276237487793
Validation loss: 2.1337464983745287

Epoch: 5| Step: 4
Training loss: 1.7166259288787842
Validation loss: 2.0814127640057634

Epoch: 5| Step: 5
Training loss: 2.1615149974823
Validation loss: 2.105582311589231

Epoch: 5| Step: 6
Training loss: 2.14042329788208
Validation loss: 2.0720000138846775

Epoch: 5| Step: 7
Training loss: 1.991593599319458
Validation loss: 2.083003314592505

Epoch: 5| Step: 8
Training loss: 1.619868516921997
Validation loss: 2.0506243398112636

Epoch: 5| Step: 9
Training loss: 1.6397466659545898
Validation loss: 2.094065846935395

Epoch: 5| Step: 10
Training loss: 3.5694313049316406
Validation loss: 2.114585199663716

Epoch: 161| Step: 0
Training loss: 1.58426833152771
Validation loss: 2.1094555495887675

Epoch: 5| Step: 1
Training loss: 2.208829402923584
Validation loss: 2.0456751264551634

Epoch: 5| Step: 2
Training loss: 1.5783050060272217
Validation loss: 2.1008150757000013

Epoch: 5| Step: 3
Training loss: 2.186183214187622
Validation loss: 2.103173396920645

Epoch: 5| Step: 4
Training loss: 2.7221217155456543
Validation loss: 2.090320138521092

Epoch: 5| Step: 5
Training loss: 1.3511857986450195
Validation loss: 2.0778381414310907

Epoch: 5| Step: 6
Training loss: 1.8967784643173218
Validation loss: 2.1134854170583908

Epoch: 5| Step: 7
Training loss: 2.9313220977783203
Validation loss: 2.0658693390507854

Epoch: 5| Step: 8
Training loss: 2.1925277709960938
Validation loss: 2.087694439836728

Epoch: 5| Step: 9
Training loss: 1.7598717212677002
Validation loss: 2.0758045693879486

Epoch: 5| Step: 10
Training loss: 2.322777271270752
Validation loss: 2.0673584656048845

Epoch: 162| Step: 0
Training loss: 1.8167978525161743
Validation loss: 2.063337415777227

Epoch: 5| Step: 1
Training loss: 1.9189850091934204
Validation loss: 2.12003759543101

Epoch: 5| Step: 2
Training loss: 2.112429618835449
Validation loss: 2.10107010410678

Epoch: 5| Step: 3
Training loss: 2.0234265327453613
Validation loss: 2.1097820651146675

Epoch: 5| Step: 4
Training loss: 2.114514112472534
Validation loss: 2.084432312237319

Epoch: 5| Step: 5
Training loss: 1.826666235923767
Validation loss: 2.131579065835604

Epoch: 5| Step: 6
Training loss: 2.1132092475891113
Validation loss: 2.1284606482393

Epoch: 5| Step: 7
Training loss: 3.0268428325653076
Validation loss: 2.11198829835461

Epoch: 5| Step: 8
Training loss: 1.827359914779663
Validation loss: 2.096765190042475

Epoch: 5| Step: 9
Training loss: 2.285053253173828
Validation loss: 2.1389093040138163

Epoch: 5| Step: 10
Training loss: 2.0771889686584473
Validation loss: 2.1215533466749292

Epoch: 163| Step: 0
Training loss: 0.9632201194763184
Validation loss: 2.109129613445651

Epoch: 5| Step: 1
Training loss: 1.8587697744369507
Validation loss: 2.109206347055333

Epoch: 5| Step: 2
Training loss: 2.10960054397583
Validation loss: 2.124347420148952

Epoch: 5| Step: 3
Training loss: 2.938309907913208
Validation loss: 2.088752600454515

Epoch: 5| Step: 4
Training loss: 1.6012370586395264
Validation loss: 2.081925135786815

Epoch: 5| Step: 5
Training loss: 1.9382909536361694
Validation loss: 2.100419121403848

Epoch: 5| Step: 6
Training loss: 2.31730055809021
Validation loss: 2.064229042299332

Epoch: 5| Step: 7
Training loss: 2.1998448371887207
Validation loss: 2.0787995835786224

Epoch: 5| Step: 8
Training loss: 2.204440116882324
Validation loss: 2.099521034507341

Epoch: 5| Step: 9
Training loss: 2.3082966804504395
Validation loss: 2.0876621020737516

Epoch: 5| Step: 10
Training loss: 2.571969509124756
Validation loss: 2.0746910866870674

Epoch: 164| Step: 0
Training loss: 1.8845469951629639
Validation loss: 2.0695469917789584

Epoch: 5| Step: 1
Training loss: 2.1203205585479736
Validation loss: 2.082530129340387

Epoch: 5| Step: 2
Training loss: 1.7873138189315796
Validation loss: 2.069968934982054

Epoch: 5| Step: 3
Training loss: 2.131486177444458
Validation loss: 2.0689578081971858

Epoch: 5| Step: 4
Training loss: 2.1381783485412598
Validation loss: 2.065325347326135

Epoch: 5| Step: 5
Training loss: 1.9572890996932983
Validation loss: 2.065816730581304

Epoch: 5| Step: 6
Training loss: 1.9228076934814453
Validation loss: 2.1053450389574935

Epoch: 5| Step: 7
Training loss: 2.064805746078491
Validation loss: 2.057129203632314

Epoch: 5| Step: 8
Training loss: 2.781374454498291
Validation loss: 2.032746663657568

Epoch: 5| Step: 9
Training loss: 2.2472708225250244
Validation loss: 2.0517316813110025

Epoch: 5| Step: 10
Training loss: 1.8751765489578247
Validation loss: 2.071918756731095

Epoch: 165| Step: 0
Training loss: 1.8659706115722656
Validation loss: 2.057385003694924

Epoch: 5| Step: 1
Training loss: 2.347111225128174
Validation loss: 2.0597972100780857

Epoch: 5| Step: 2
Training loss: 1.6132383346557617
Validation loss: 2.071454071229504

Epoch: 5| Step: 3
Training loss: 2.340562343597412
Validation loss: 2.0561875476632068

Epoch: 5| Step: 4
Training loss: 1.8427654504776
Validation loss: 2.050548061247795

Epoch: 5| Step: 5
Training loss: 2.159899950027466
Validation loss: 2.094604862633572

Epoch: 5| Step: 6
Training loss: 2.0118072032928467
Validation loss: 2.097960525943387

Epoch: 5| Step: 7
Training loss: 2.1287033557891846
Validation loss: 2.063991477412562

Epoch: 5| Step: 8
Training loss: 2.049149990081787
Validation loss: 2.100507857978985

Epoch: 5| Step: 9
Training loss: 2.505768060684204
Validation loss: 2.0932897213966615

Epoch: 5| Step: 10
Training loss: 1.9329683780670166
Validation loss: 2.105689461513232

Epoch: 166| Step: 0
Training loss: 1.2802705764770508
Validation loss: 2.07683277258309

Epoch: 5| Step: 1
Training loss: 2.9434244632720947
Validation loss: 2.1011599084382415

Epoch: 5| Step: 2
Training loss: 2.5526931285858154
Validation loss: 2.079330644299907

Epoch: 5| Step: 3
Training loss: 2.825526714324951
Validation loss: 2.084673967412723

Epoch: 5| Step: 4
Training loss: 1.650734305381775
Validation loss: 2.08704105500252

Epoch: 5| Step: 5
Training loss: 2.3730759620666504
Validation loss: 2.0738591622280818

Epoch: 5| Step: 6
Training loss: 1.6756900548934937
Validation loss: 2.1233685888269895

Epoch: 5| Step: 7
Training loss: 2.063939332962036
Validation loss: 2.0725475177969983

Epoch: 5| Step: 8
Training loss: 1.6391916275024414
Validation loss: 2.0804644028345742

Epoch: 5| Step: 9
Training loss: 1.8813339471817017
Validation loss: 2.0871904870515228

Epoch: 5| Step: 10
Training loss: 1.8897511959075928
Validation loss: 2.080143044071813

Epoch: 167| Step: 0
Training loss: 1.6531333923339844
Validation loss: 2.062332267402321

Epoch: 5| Step: 1
Training loss: 2.0323550701141357
Validation loss: 2.0829106671835786

Epoch: 5| Step: 2
Training loss: 2.8754236698150635
Validation loss: 2.0717918847196843

Epoch: 5| Step: 3
Training loss: 1.8891351222991943
Validation loss: 2.083388974589686

Epoch: 5| Step: 4
Training loss: 2.002840518951416
Validation loss: 2.0865322902638423

Epoch: 5| Step: 5
Training loss: 2.225454807281494
Validation loss: 2.094720346953279

Epoch: 5| Step: 6
Training loss: 1.8494666814804077
Validation loss: 2.0932017551955355

Epoch: 5| Step: 7
Training loss: 2.05458402633667
Validation loss: 2.0736211576769428

Epoch: 5| Step: 8
Training loss: 1.345723032951355
Validation loss: 2.0913023589759745

Epoch: 5| Step: 9
Training loss: 1.8596233129501343
Validation loss: 2.085540110065091

Epoch: 5| Step: 10
Training loss: 2.648319959640503
Validation loss: 2.0812956633106356

Epoch: 168| Step: 0
Training loss: 2.526732921600342
Validation loss: 2.0987963907180296

Epoch: 5| Step: 1
Training loss: 1.9593496322631836
Validation loss: 2.096505800882975

Epoch: 5| Step: 2
Training loss: 1.9561229944229126
Validation loss: 2.0726213096290507

Epoch: 5| Step: 3
Training loss: 1.9089593887329102
Validation loss: 2.039017705507176

Epoch: 5| Step: 4
Training loss: 2.5272440910339355
Validation loss: 2.070703019378006

Epoch: 5| Step: 5
Training loss: 2.31284761428833
Validation loss: 2.0613008071017522

Epoch: 5| Step: 6
Training loss: 2.081958055496216
Validation loss: 2.065612071303911

Epoch: 5| Step: 7
Training loss: 1.7972078323364258
Validation loss: 2.06557890676683

Epoch: 5| Step: 8
Training loss: 1.5248311758041382
Validation loss: 2.0471437413205384

Epoch: 5| Step: 9
Training loss: 1.8640435934066772
Validation loss: 2.0746987429998254

Epoch: 5| Step: 10
Training loss: 2.064641237258911
Validation loss: 2.061574564185194

Epoch: 169| Step: 0
Training loss: 2.18477201461792
Validation loss: 2.0703046526960147

Epoch: 5| Step: 1
Training loss: 2.276750087738037
Validation loss: 2.0856870758918022

Epoch: 5| Step: 2
Training loss: 1.9028505086898804
Validation loss: 2.0379835956840107

Epoch: 5| Step: 3
Training loss: 2.140097141265869
Validation loss: 2.081398089726766

Epoch: 5| Step: 4
Training loss: 1.8976414203643799
Validation loss: 2.0683439777743433

Epoch: 5| Step: 5
Training loss: 2.492914915084839
Validation loss: 2.0591203730593444

Epoch: 5| Step: 6
Training loss: 1.9333324432373047
Validation loss: 2.1263620263786724

Epoch: 5| Step: 7
Training loss: 2.1090664863586426
Validation loss: 2.0901275552729124

Epoch: 5| Step: 8
Training loss: 1.9206130504608154
Validation loss: 2.1206610382244153

Epoch: 5| Step: 9
Training loss: 1.9584882259368896
Validation loss: 2.0902279961493706

Epoch: 5| Step: 10
Training loss: 1.8564684391021729
Validation loss: 2.0891798593664683

Epoch: 170| Step: 0
Training loss: 1.9837232828140259
Validation loss: 2.057288464679513

Epoch: 5| Step: 1
Training loss: 2.1434905529022217
Validation loss: 2.0729532908367854

Epoch: 5| Step: 2
Training loss: 1.8361294269561768
Validation loss: 2.075432645377292

Epoch: 5| Step: 3
Training loss: 1.8289334774017334
Validation loss: 2.0775321914303686

Epoch: 5| Step: 4
Training loss: 1.9786691665649414
Validation loss: 2.0616247961598058

Epoch: 5| Step: 5
Training loss: 1.7934108972549438
Validation loss: 2.0835266984919065

Epoch: 5| Step: 6
Training loss: 2.313929319381714
Validation loss: 2.074531488521125

Epoch: 5| Step: 7
Training loss: 2.4963393211364746
Validation loss: 2.0943222968809065

Epoch: 5| Step: 8
Training loss: 2.241419553756714
Validation loss: 2.0900211975138676

Epoch: 5| Step: 9
Training loss: 2.1946892738342285
Validation loss: 2.075023830577891

Epoch: 5| Step: 10
Training loss: 1.5685158967971802
Validation loss: 2.0670878887176514

Epoch: 171| Step: 0
Training loss: 1.761635184288025
Validation loss: 2.070467197766868

Epoch: 5| Step: 1
Training loss: 2.488856315612793
Validation loss: 2.089751802464967

Epoch: 5| Step: 2
Training loss: 2.62571382522583
Validation loss: 2.0577441210387857

Epoch: 5| Step: 3
Training loss: 2.155000686645508
Validation loss: 2.0533280244437595

Epoch: 5| Step: 4
Training loss: 2.4492990970611572
Validation loss: 2.0923225700214343

Epoch: 5| Step: 5
Training loss: 1.6788673400878906
Validation loss: 2.055705926751578

Epoch: 5| Step: 6
Training loss: 1.630519151687622
Validation loss: 2.0653335099579184

Epoch: 5| Step: 7
Training loss: 2.340034008026123
Validation loss: 2.0724374248135473

Epoch: 5| Step: 8
Training loss: 2.3416779041290283
Validation loss: 2.092546154093999

Epoch: 5| Step: 9
Training loss: 1.3399546146392822
Validation loss: 2.0938013881765385

Epoch: 5| Step: 10
Training loss: 1.607039213180542
Validation loss: 2.069706912963621

Epoch: 172| Step: 0
Training loss: 2.15132474899292
Validation loss: 2.062904771938119

Epoch: 5| Step: 1
Training loss: 1.5301563739776611
Validation loss: 2.067124071941581

Epoch: 5| Step: 2
Training loss: 2.4570930004119873
Validation loss: 2.052628545350926

Epoch: 5| Step: 3
Training loss: 2.486546754837036
Validation loss: 2.0761276111807874

Epoch: 5| Step: 4
Training loss: 2.468543529510498
Validation loss: 2.0279058794821463

Epoch: 5| Step: 5
Training loss: 2.39125657081604
Validation loss: 2.1066351449617775

Epoch: 5| Step: 6
Training loss: 1.4525787830352783
Validation loss: 2.0517063922779535

Epoch: 5| Step: 7
Training loss: 1.878129243850708
Validation loss: 2.044477879360158

Epoch: 5| Step: 8
Training loss: 1.7317135334014893
Validation loss: 2.04095140323844

Epoch: 5| Step: 9
Training loss: 2.221278667449951
Validation loss: 2.0626208397649948

Epoch: 5| Step: 10
Training loss: 1.618879795074463
Validation loss: 2.053598086039225

Epoch: 173| Step: 0
Training loss: 2.647517681121826
Validation loss: 2.0760243515814505

Epoch: 5| Step: 1
Training loss: 1.628058671951294
Validation loss: 2.031220333550566

Epoch: 5| Step: 2
Training loss: 1.517059326171875
Validation loss: 2.1013635461048414

Epoch: 5| Step: 3
Training loss: 1.8517253398895264
Validation loss: 2.0660472198199202

Epoch: 5| Step: 4
Training loss: 1.8752262592315674
Validation loss: 2.031901551831153

Epoch: 5| Step: 5
Training loss: 2.1480321884155273
Validation loss: 2.0538965848184403

Epoch: 5| Step: 6
Training loss: 2.4848849773406982
Validation loss: 2.0470932568273237

Epoch: 5| Step: 7
Training loss: 2.006338596343994
Validation loss: 2.0632163401572936

Epoch: 5| Step: 8
Training loss: 1.485525131225586
Validation loss: 2.0780583427798365

Epoch: 5| Step: 9
Training loss: 2.3979854583740234
Validation loss: 2.062605916812856

Epoch: 5| Step: 10
Training loss: 2.2067439556121826
Validation loss: 2.058675742918445

Epoch: 174| Step: 0
Training loss: 2.2946701049804688
Validation loss: 2.063943927006055

Epoch: 5| Step: 1
Training loss: 2.4984891414642334
Validation loss: 2.051809513440696

Epoch: 5| Step: 2
Training loss: 1.5151822566986084
Validation loss: 2.0425588879533993

Epoch: 5| Step: 3
Training loss: 2.14776873588562
Validation loss: 2.055982553830711

Epoch: 5| Step: 4
Training loss: 1.987938642501831
Validation loss: 2.0569454726352485

Epoch: 5| Step: 5
Training loss: 2.6971967220306396
Validation loss: 2.0588154882513066

Epoch: 5| Step: 6
Training loss: 1.4493025541305542
Validation loss: 2.0652470434865644

Epoch: 5| Step: 7
Training loss: 2.4048385620117188
Validation loss: 2.0793772589775825

Epoch: 5| Step: 8
Training loss: 1.534635066986084
Validation loss: 2.03791977513221

Epoch: 5| Step: 9
Training loss: 1.757624864578247
Validation loss: 2.084383039064305

Epoch: 5| Step: 10
Training loss: 1.9157010316848755
Validation loss: 2.086612170742404

Epoch: 175| Step: 0
Training loss: 2.20801043510437
Validation loss: 2.075077872122488

Epoch: 5| Step: 1
Training loss: 1.8908212184906006
Validation loss: 2.0494713065444783

Epoch: 5| Step: 2
Training loss: 1.5365073680877686
Validation loss: 2.0501270230098436

Epoch: 5| Step: 3
Training loss: 2.0795607566833496
Validation loss: 2.043234041942063

Epoch: 5| Step: 4
Training loss: 1.7007598876953125
Validation loss: 2.066865401883279

Epoch: 5| Step: 5
Training loss: 2.4410314559936523
Validation loss: 2.031059036972702

Epoch: 5| Step: 6
Training loss: 2.549316883087158
Validation loss: 2.0492024511419316

Epoch: 5| Step: 7
Training loss: 1.515653371810913
Validation loss: 2.063263198380829

Epoch: 5| Step: 8
Training loss: 2.1152946949005127
Validation loss: 2.0401031201885593

Epoch: 5| Step: 9
Training loss: 2.177523374557495
Validation loss: 2.0007438108485234

Epoch: 5| Step: 10
Training loss: 1.7030439376831055
Validation loss: 2.055029651170136

Epoch: 176| Step: 0
Training loss: 1.4860615730285645
Validation loss: 2.0681923589398785

Epoch: 5| Step: 1
Training loss: 2.2401866912841797
Validation loss: 2.0690575440724692

Epoch: 5| Step: 2
Training loss: 1.989169716835022
Validation loss: 2.036752135522904

Epoch: 5| Step: 3
Training loss: 2.1525778770446777
Validation loss: 2.021531328078239

Epoch: 5| Step: 4
Training loss: 2.150819778442383
Validation loss: 2.0640052621082594

Epoch: 5| Step: 5
Training loss: 2.728999376296997
Validation loss: 2.016793753511162

Epoch: 5| Step: 6
Training loss: 1.5452073812484741
Validation loss: 2.0150057500408542

Epoch: 5| Step: 7
Training loss: 2.042991876602173
Validation loss: 2.005565648437828

Epoch: 5| Step: 8
Training loss: 1.5323512554168701
Validation loss: 2.0446326194270963

Epoch: 5| Step: 9
Training loss: 1.9196069240570068
Validation loss: 2.016639935073032

Epoch: 5| Step: 10
Training loss: 2.284038543701172
Validation loss: 2.048064019090386

Epoch: 177| Step: 0
Training loss: 2.2056941986083984
Validation loss: 2.040954379625218

Epoch: 5| Step: 1
Training loss: 2.4788119792938232
Validation loss: 2.0162522113451393

Epoch: 5| Step: 2
Training loss: 2.257627010345459
Validation loss: 2.079243734318723

Epoch: 5| Step: 3
Training loss: 2.0383143424987793
Validation loss: 2.0328855437617146

Epoch: 5| Step: 4
Training loss: 2.311427593231201
Validation loss: 2.050222917269635

Epoch: 5| Step: 5
Training loss: 1.9744367599487305
Validation loss: 2.0759593671368015

Epoch: 5| Step: 6
Training loss: 1.9508743286132812
Validation loss: 2.0731242472125637

Epoch: 5| Step: 7
Training loss: 2.0015361309051514
Validation loss: 2.0666343012163715

Epoch: 5| Step: 8
Training loss: 1.7155134677886963
Validation loss: 2.05754400965988

Epoch: 5| Step: 9
Training loss: 1.6158097982406616
Validation loss: 2.088002940659882

Epoch: 5| Step: 10
Training loss: 1.1930153369903564
Validation loss: 2.048669557417593

Epoch: 178| Step: 0
Training loss: 2.460618257522583
Validation loss: 2.0307351286693285

Epoch: 5| Step: 1
Training loss: 2.271146774291992
Validation loss: 2.0577629125246437

Epoch: 5| Step: 2
Training loss: 2.2871580123901367
Validation loss: 2.0418999028462235

Epoch: 5| Step: 3
Training loss: 1.9152084589004517
Validation loss: 2.0876154233050603

Epoch: 5| Step: 4
Training loss: 2.0431253910064697
Validation loss: 2.070887907858818

Epoch: 5| Step: 5
Training loss: 1.5879390239715576
Validation loss: 2.0608218895491732

Epoch: 5| Step: 6
Training loss: 1.6959764957427979
Validation loss: 2.083617656461654

Epoch: 5| Step: 7
Training loss: 2.249962329864502
Validation loss: 2.0803850094477334

Epoch: 5| Step: 8
Training loss: 1.51340651512146
Validation loss: 2.0057055027254167

Epoch: 5| Step: 9
Training loss: 2.2395613193511963
Validation loss: 2.052826175125696

Epoch: 5| Step: 10
Training loss: 2.090036630630493
Validation loss: 2.021833449281672

Epoch: 179| Step: 0
Training loss: 2.1075644493103027
Validation loss: 2.0650708444656862

Epoch: 5| Step: 1
Training loss: 1.8809864521026611
Validation loss: 2.0149388018474785

Epoch: 5| Step: 2
Training loss: 2.5425758361816406
Validation loss: 2.039898846739082

Epoch: 5| Step: 3
Training loss: 2.3208377361297607
Validation loss: 2.0240406477323143

Epoch: 5| Step: 4
Training loss: 1.953590989112854
Validation loss: 2.0458855039329937

Epoch: 5| Step: 5
Training loss: 2.424036741256714
Validation loss: 2.089647258481672

Epoch: 5| Step: 6
Training loss: 1.7701460123062134
Validation loss: 2.033806793151363

Epoch: 5| Step: 7
Training loss: 1.719578742980957
Validation loss: 2.077137891964246

Epoch: 5| Step: 8
Training loss: 1.8559821844100952
Validation loss: 2.012632394349703

Epoch: 5| Step: 9
Training loss: 1.5101397037506104
Validation loss: 2.004392503410257

Epoch: 5| Step: 10
Training loss: 2.009526014328003
Validation loss: 2.0611869981212

Epoch: 180| Step: 0
Training loss: 2.077420473098755
Validation loss: 2.02403030344235

Epoch: 5| Step: 1
Training loss: 1.9797627925872803
Validation loss: 2.0106081898494432

Epoch: 5| Step: 2
Training loss: 1.4222911596298218
Validation loss: 2.0511643450747252

Epoch: 5| Step: 3
Training loss: 1.7721812725067139
Validation loss: 2.0080287507785264

Epoch: 5| Step: 4
Training loss: 1.5808918476104736
Validation loss: 2.018296677579162

Epoch: 5| Step: 5
Training loss: 2.2407212257385254
Validation loss: 2.0387690554382982

Epoch: 5| Step: 6
Training loss: 2.0473575592041016
Validation loss: 2.0345018961096324

Epoch: 5| Step: 7
Training loss: 2.067903995513916
Validation loss: 2.012384817164431

Epoch: 5| Step: 8
Training loss: 2.229780673980713
Validation loss: 2.0765765802834624

Epoch: 5| Step: 9
Training loss: 2.789714813232422
Validation loss: 2.0540401666395125

Epoch: 5| Step: 10
Training loss: 1.9365348815917969
Validation loss: 2.027617323783136

Epoch: 181| Step: 0
Training loss: 1.5880680084228516
Validation loss: 2.0342442143347954

Epoch: 5| Step: 1
Training loss: 2.3378303050994873
Validation loss: 2.0683740595335602

Epoch: 5| Step: 2
Training loss: 2.17264986038208
Validation loss: 2.0633004019337315

Epoch: 5| Step: 3
Training loss: 2.1095259189605713
Validation loss: 2.046331917085955

Epoch: 5| Step: 4
Training loss: 1.755232572555542
Validation loss: 2.0515309969584146

Epoch: 5| Step: 5
Training loss: 2.3149094581604004
Validation loss: 2.0363999541087816

Epoch: 5| Step: 6
Training loss: 2.0123932361602783
Validation loss: 2.0326368988201184

Epoch: 5| Step: 7
Training loss: 1.8864736557006836
Validation loss: 2.0142155539604927

Epoch: 5| Step: 8
Training loss: 1.4285417795181274
Validation loss: 1.9789813180123605

Epoch: 5| Step: 9
Training loss: 2.513021945953369
Validation loss: 2.0395539460643644

Epoch: 5| Step: 10
Training loss: 2.2094991207122803
Validation loss: 2.0603525484761884

Epoch: 182| Step: 0
Training loss: 1.5599706172943115
Validation loss: 2.023279663055174

Epoch: 5| Step: 1
Training loss: 2.1347548961639404
Validation loss: 2.023555119832357

Epoch: 5| Step: 2
Training loss: 2.3765511512756348
Validation loss: 2.04066801071167

Epoch: 5| Step: 3
Training loss: 2.215428113937378
Validation loss: 2.0497013932915142

Epoch: 5| Step: 4
Training loss: 1.5424104928970337
Validation loss: 2.0211394858616654

Epoch: 5| Step: 5
Training loss: 1.5003702640533447
Validation loss: 2.015116407025245

Epoch: 5| Step: 6
Training loss: 2.4568309783935547
Validation loss: 2.0028241962514897

Epoch: 5| Step: 7
Training loss: 2.505439519882202
Validation loss: 2.008862576177043

Epoch: 5| Step: 8
Training loss: 1.8138478994369507
Validation loss: 2.028979150197839

Epoch: 5| Step: 9
Training loss: 1.676608681678772
Validation loss: 2.040952754277055

Epoch: 5| Step: 10
Training loss: 2.023076295852661
Validation loss: 2.0221957570763043

Epoch: 183| Step: 0
Training loss: 2.2610011100769043
Validation loss: 2.001950022994831

Epoch: 5| Step: 1
Training loss: 2.442063570022583
Validation loss: 2.008046055352816

Epoch: 5| Step: 2
Training loss: 2.102412462234497
Validation loss: 2.055275983707879

Epoch: 5| Step: 3
Training loss: 1.6957066059112549
Validation loss: 2.0726612101319017

Epoch: 5| Step: 4
Training loss: 1.764900803565979
Validation loss: 2.045148188068021

Epoch: 5| Step: 5
Training loss: 2.096890687942505
Validation loss: 2.050666711663687

Epoch: 5| Step: 6
Training loss: 1.8142839670181274
Validation loss: 2.098460671722248

Epoch: 5| Step: 7
Training loss: 1.3024675846099854
Validation loss: 2.061661220365955

Epoch: 5| Step: 8
Training loss: 2.0138022899627686
Validation loss: 2.0334755271993656

Epoch: 5| Step: 9
Training loss: 1.7733135223388672
Validation loss: 2.043720514543595

Epoch: 5| Step: 10
Training loss: 2.752990484237671
Validation loss: 2.02760104081964

Epoch: 184| Step: 0
Training loss: 1.9312816858291626
Validation loss: 2.0132767859325615

Epoch: 5| Step: 1
Training loss: 1.8101301193237305
Validation loss: 2.028702756410004

Epoch: 5| Step: 2
Training loss: 2.7400825023651123
Validation loss: 2.0001680158799693

Epoch: 5| Step: 3
Training loss: 2.202014207839966
Validation loss: 2.026716068226804

Epoch: 5| Step: 4
Training loss: 1.0930684804916382
Validation loss: 2.023722771675356

Epoch: 5| Step: 5
Training loss: 1.798945665359497
Validation loss: 2.009206510359241

Epoch: 5| Step: 6
Training loss: 1.9088363647460938
Validation loss: 1.9837976809470885

Epoch: 5| Step: 7
Training loss: 2.1875181198120117
Validation loss: 2.0003458325580885

Epoch: 5| Step: 8
Training loss: 1.6831543445587158
Validation loss: 2.0154921649604716

Epoch: 5| Step: 9
Training loss: 2.53926420211792
Validation loss: 1.994897997507485

Epoch: 5| Step: 10
Training loss: 2.005674362182617
Validation loss: 2.036343438650972

Epoch: 185| Step: 0
Training loss: 2.050246000289917
Validation loss: 2.0313515868238223

Epoch: 5| Step: 1
Training loss: 2.0044796466827393
Validation loss: 2.0121542792166434

Epoch: 5| Step: 2
Training loss: 2.301474094390869
Validation loss: 2.04496072441019

Epoch: 5| Step: 3
Training loss: 1.7254753112792969
Validation loss: 2.0330759658608386

Epoch: 5| Step: 4
Training loss: 1.808852195739746
Validation loss: 2.026549126512261

Epoch: 5| Step: 5
Training loss: 1.9319747686386108
Validation loss: 2.0331979464459162

Epoch: 5| Step: 6
Training loss: 2.1735877990722656
Validation loss: 2.022881720655708

Epoch: 5| Step: 7
Training loss: 1.8880714178085327
Validation loss: 2.003513446418188

Epoch: 5| Step: 8
Training loss: 2.1487927436828613
Validation loss: 2.0290268544227845

Epoch: 5| Step: 9
Training loss: 1.9608447551727295
Validation loss: 2.0417868527032996

Epoch: 5| Step: 10
Training loss: 1.6468526124954224
Validation loss: 2.0240375508544264

Epoch: 186| Step: 0
Training loss: 2.6297967433929443
Validation loss: 1.9999929038427209

Epoch: 5| Step: 1
Training loss: 2.500765323638916
Validation loss: 2.0536938508351645

Epoch: 5| Step: 2
Training loss: 1.6607354879379272
Validation loss: 2.05582312486505

Epoch: 5| Step: 3
Training loss: 1.4420057535171509
Validation loss: 2.038005148210833

Epoch: 5| Step: 4
Training loss: 1.6829725503921509
Validation loss: 2.0490713632234963

Epoch: 5| Step: 5
Training loss: 2.339331865310669
Validation loss: 2.017199739333122

Epoch: 5| Step: 6
Training loss: 1.7672741413116455
Validation loss: 2.0487642083116757

Epoch: 5| Step: 7
Training loss: 2.3072404861450195
Validation loss: 2.067884865627494

Epoch: 5| Step: 8
Training loss: 1.664065957069397
Validation loss: 2.017602784659273

Epoch: 5| Step: 9
Training loss: 2.21522855758667
Validation loss: 2.0404960532342233

Epoch: 5| Step: 10
Training loss: 1.7122535705566406
Validation loss: 2.0503030887214084

Epoch: 187| Step: 0
Training loss: 2.110084295272827
Validation loss: 2.020419805280624

Epoch: 5| Step: 1
Training loss: 2.5763535499572754
Validation loss: 2.0068581270915207

Epoch: 5| Step: 2
Training loss: 2.1523501873016357
Validation loss: 2.007530200865961

Epoch: 5| Step: 3
Training loss: 2.1543338298797607
Validation loss: 1.990541127420241

Epoch: 5| Step: 4
Training loss: 1.9638614654541016
Validation loss: 2.040226487703221

Epoch: 5| Step: 5
Training loss: 1.6531345844268799
Validation loss: 2.0342654694793043

Epoch: 5| Step: 6
Training loss: 1.9161674976348877
Validation loss: 2.0238363563373523

Epoch: 5| Step: 7
Training loss: 2.3422179222106934
Validation loss: 1.9802001137887277

Epoch: 5| Step: 8
Training loss: 1.7150379419326782
Validation loss: 1.9979018165219216

Epoch: 5| Step: 9
Training loss: 1.5571881532669067
Validation loss: 1.9982392031659362

Epoch: 5| Step: 10
Training loss: 1.5717319250106812
Validation loss: 2.018143153959705

Epoch: 188| Step: 0
Training loss: 1.9243618249893188
Validation loss: 2.039295450333626

Epoch: 5| Step: 1
Training loss: 2.0711798667907715
Validation loss: 1.993828401770643

Epoch: 5| Step: 2
Training loss: 1.9948232173919678
Validation loss: 2.008592155671889

Epoch: 5| Step: 3
Training loss: 2.541123628616333
Validation loss: 2.0490559019068235

Epoch: 5| Step: 4
Training loss: 2.023815631866455
Validation loss: 2.0365679110250166

Epoch: 5| Step: 5
Training loss: 2.623166561126709
Validation loss: 2.0383331442392

Epoch: 5| Step: 6
Training loss: 2.0976104736328125
Validation loss: 2.048188353097567

Epoch: 5| Step: 7
Training loss: 1.2501708269119263
Validation loss: 2.0733777066712737

Epoch: 5| Step: 8
Training loss: 1.484786868095398
Validation loss: 2.0344230231418403

Epoch: 5| Step: 9
Training loss: 2.1912732124328613
Validation loss: 2.0630620525729273

Epoch: 5| Step: 10
Training loss: 1.424935221672058
Validation loss: 2.0228575788518435

Epoch: 189| Step: 0
Training loss: 2.171530246734619
Validation loss: 2.0285946822935537

Epoch: 5| Step: 1
Training loss: 2.2354233264923096
Validation loss: 2.040236937102451

Epoch: 5| Step: 2
Training loss: 1.8948408365249634
Validation loss: 2.0033909684868267

Epoch: 5| Step: 3
Training loss: 2.3415629863739014
Validation loss: 2.0308607291149836

Epoch: 5| Step: 4
Training loss: 2.082751512527466
Validation loss: 2.0117068239437637

Epoch: 5| Step: 5
Training loss: 1.3554661273956299
Validation loss: 2.029483090164841

Epoch: 5| Step: 6
Training loss: 1.865182876586914
Validation loss: 2.0451829407804754

Epoch: 5| Step: 7
Training loss: 1.9786384105682373
Validation loss: 2.03106955559023

Epoch: 5| Step: 8
Training loss: 2.079946994781494
Validation loss: 1.9927993987196235

Epoch: 5| Step: 9
Training loss: 1.6457226276397705
Validation loss: 2.011780374793596

Epoch: 5| Step: 10
Training loss: 1.870917797088623
Validation loss: 2.0137167464020433

Epoch: 190| Step: 0
Training loss: 1.8074079751968384
Validation loss: 2.007012390321301

Epoch: 5| Step: 1
Training loss: 2.1744346618652344
Validation loss: 2.040622067707841

Epoch: 5| Step: 2
Training loss: 1.3807425498962402
Validation loss: 2.0366381829784763

Epoch: 5| Step: 3
Training loss: 1.657687783241272
Validation loss: 2.0216081911517727

Epoch: 5| Step: 4
Training loss: 1.4202407598495483
Validation loss: 2.0143187661324777

Epoch: 5| Step: 5
Training loss: 2.7915713787078857
Validation loss: 1.9896103105237406

Epoch: 5| Step: 6
Training loss: 2.062127113342285
Validation loss: 2.048496530902001

Epoch: 5| Step: 7
Training loss: 1.7232568264007568
Validation loss: 2.0394669886558288

Epoch: 5| Step: 8
Training loss: 2.560558795928955
Validation loss: 1.9979535892445555

Epoch: 5| Step: 9
Training loss: 2.3796772956848145
Validation loss: 2.0716823736826577

Epoch: 5| Step: 10
Training loss: 1.829645037651062
Validation loss: 2.0469767816605104

Epoch: 191| Step: 0
Training loss: 1.8667739629745483
Validation loss: 2.031028457867202

Epoch: 5| Step: 1
Training loss: 2.229430675506592
Validation loss: 2.0296990307428504

Epoch: 5| Step: 2
Training loss: 2.3522210121154785
Validation loss: 2.033715478835567

Epoch: 5| Step: 3
Training loss: 1.9981848001480103
Validation loss: 2.028622055566439

Epoch: 5| Step: 4
Training loss: 1.8320724964141846
Validation loss: 2.0496350616537113

Epoch: 5| Step: 5
Training loss: 2.3584814071655273
Validation loss: 2.018018373879053

Epoch: 5| Step: 6
Training loss: 2.1778640747070312
Validation loss: 2.042752164666371

Epoch: 5| Step: 7
Training loss: 2.18267822265625
Validation loss: 2.0422624182957474

Epoch: 5| Step: 8
Training loss: 1.3432457447052002
Validation loss: 2.0416237641406316

Epoch: 5| Step: 9
Training loss: 1.528306007385254
Validation loss: 2.0280633203444944

Epoch: 5| Step: 10
Training loss: 1.4958233833312988
Validation loss: 2.0194441041638775

Epoch: 192| Step: 0
Training loss: 2.3860361576080322
Validation loss: 2.0126645872669835

Epoch: 5| Step: 1
Training loss: 1.9505447149276733
Validation loss: 2.014715438248009

Epoch: 5| Step: 2
Training loss: 2.411824941635132
Validation loss: 2.00755629744581

Epoch: 5| Step: 3
Training loss: 1.5105278491973877
Validation loss: 1.9954431646613664

Epoch: 5| Step: 4
Training loss: 2.2572693824768066
Validation loss: 2.04256018259192

Epoch: 5| Step: 5
Training loss: 1.8632808923721313
Validation loss: 2.0208340357708674

Epoch: 5| Step: 6
Training loss: 1.8649498224258423
Validation loss: 1.990396007414787

Epoch: 5| Step: 7
Training loss: 1.4742233753204346
Validation loss: 1.9869491566893875

Epoch: 5| Step: 8
Training loss: 1.610635757446289
Validation loss: 2.0003939033836446

Epoch: 5| Step: 9
Training loss: 2.018928050994873
Validation loss: 1.9862429916217763

Epoch: 5| Step: 10
Training loss: 2.2805447578430176
Validation loss: 1.9523040325410905

Epoch: 193| Step: 0
Training loss: 2.0447893142700195
Validation loss: 1.999222078631001

Epoch: 5| Step: 1
Training loss: 1.5536956787109375
Validation loss: 2.0554866278043358

Epoch: 5| Step: 2
Training loss: 1.8648267984390259
Validation loss: 1.975043809542092

Epoch: 5| Step: 3
Training loss: 1.4228901863098145
Validation loss: 2.037420408700102

Epoch: 5| Step: 4
Training loss: 1.7769315242767334
Validation loss: 2.0001997601601387

Epoch: 5| Step: 5
Training loss: 1.8545894622802734
Validation loss: 2.004840532938639

Epoch: 5| Step: 6
Training loss: 2.4488046169281006
Validation loss: 2.0207319105825117

Epoch: 5| Step: 7
Training loss: 1.6981604099273682
Validation loss: 2.0400711426170925

Epoch: 5| Step: 8
Training loss: 2.0194878578186035
Validation loss: 1.9661423160183815

Epoch: 5| Step: 9
Training loss: 2.4501163959503174
Validation loss: 2.016807876607423

Epoch: 5| Step: 10
Training loss: 2.193931818008423
Validation loss: 2.023973591866032

Epoch: 194| Step: 0
Training loss: 1.6381514072418213
Validation loss: 2.0147391455147856

Epoch: 5| Step: 1
Training loss: 2.0407068729400635
Validation loss: 2.0213007286030757

Epoch: 5| Step: 2
Training loss: 1.45822274684906
Validation loss: 2.0246094349891908

Epoch: 5| Step: 3
Training loss: 2.3917157649993896
Validation loss: 2.0484397385710027

Epoch: 5| Step: 4
Training loss: 2.2793257236480713
Validation loss: 1.9934962039352746

Epoch: 5| Step: 5
Training loss: 1.4921371936798096
Validation loss: 1.9862847866550568

Epoch: 5| Step: 6
Training loss: 2.2049121856689453
Validation loss: 2.013600912145389

Epoch: 5| Step: 7
Training loss: 1.8907527923583984
Validation loss: 1.9797333901928318

Epoch: 5| Step: 8
Training loss: 2.0669050216674805
Validation loss: 2.0027768637544368

Epoch: 5| Step: 9
Training loss: 1.8955154418945312
Validation loss: 1.9875683233302126

Epoch: 5| Step: 10
Training loss: 1.8039213418960571
Validation loss: 1.996659263487785

Epoch: 195| Step: 0
Training loss: 1.7270488739013672
Validation loss: 1.9890926602066203

Epoch: 5| Step: 1
Training loss: 1.9615402221679688
Validation loss: 1.9918042793068835

Epoch: 5| Step: 2
Training loss: 2.262328624725342
Validation loss: 2.0143018614861274

Epoch: 5| Step: 3
Training loss: 1.8595561981201172
Validation loss: 1.9708915654049124

Epoch: 5| Step: 4
Training loss: 1.5299949645996094
Validation loss: 1.9635221701796337

Epoch: 5| Step: 5
Training loss: 1.9788240194320679
Validation loss: 1.967173284099948

Epoch: 5| Step: 6
Training loss: 2.184915065765381
Validation loss: 1.994656842242005

Epoch: 5| Step: 7
Training loss: 2.2001736164093018
Validation loss: 1.9906501180382186

Epoch: 5| Step: 8
Training loss: 2.15580677986145
Validation loss: 2.0324814588792863

Epoch: 5| Step: 9
Training loss: 1.7847201824188232
Validation loss: 1.9829599370238602

Epoch: 5| Step: 10
Training loss: 1.8247350454330444
Validation loss: 1.9812480788077078

Epoch: 196| Step: 0
Training loss: 1.5773861408233643
Validation loss: 1.9909991231015933

Epoch: 5| Step: 1
Training loss: 2.014878749847412
Validation loss: 2.009567246642164

Epoch: 5| Step: 2
Training loss: 2.245326280593872
Validation loss: 1.9767059677390642

Epoch: 5| Step: 3
Training loss: 1.7311859130859375
Validation loss: 2.0063501481086976

Epoch: 5| Step: 4
Training loss: 1.8237483501434326
Validation loss: 1.9862155363123903

Epoch: 5| Step: 5
Training loss: 2.5005435943603516
Validation loss: 1.9624778147666686

Epoch: 5| Step: 6
Training loss: 2.034062147140503
Validation loss: 1.9704289846522833

Epoch: 5| Step: 7
Training loss: 1.7012100219726562
Validation loss: 2.0324425005143687

Epoch: 5| Step: 8
Training loss: 2.5114638805389404
Validation loss: 2.0169225379984868

Epoch: 5| Step: 9
Training loss: 1.481022596359253
Validation loss: 2.0322506248310046

Epoch: 5| Step: 10
Training loss: 1.7042555809020996
Validation loss: 1.9967280741660827

Epoch: 197| Step: 0
Training loss: 1.4783074855804443
Validation loss: 2.007217184189827

Epoch: 5| Step: 1
Training loss: 1.841030478477478
Validation loss: 2.013602637475537

Epoch: 5| Step: 2
Training loss: 2.3689417839050293
Validation loss: 1.9929764527146534

Epoch: 5| Step: 3
Training loss: 1.826894760131836
Validation loss: 1.979919627148618

Epoch: 5| Step: 4
Training loss: 1.9672706127166748
Validation loss: 1.959825929775033

Epoch: 5| Step: 5
Training loss: 2.070960283279419
Validation loss: 1.9735521167837164

Epoch: 5| Step: 6
Training loss: 1.82004714012146
Validation loss: 1.9942373870521464

Epoch: 5| Step: 7
Training loss: 2.263099193572998
Validation loss: 2.000651437749145

Epoch: 5| Step: 8
Training loss: 1.33815598487854
Validation loss: 1.9427724717765726

Epoch: 5| Step: 9
Training loss: 1.8435561656951904
Validation loss: 1.9514947373379943

Epoch: 5| Step: 10
Training loss: 2.5481176376342773
Validation loss: 2.0098743259265857

Epoch: 198| Step: 0
Training loss: 1.841469168663025
Validation loss: 1.9928567665879444

Epoch: 5| Step: 1
Training loss: 2.1144535541534424
Validation loss: 1.9840872544114307

Epoch: 5| Step: 2
Training loss: 1.5689080953598022
Validation loss: 1.9773600396289621

Epoch: 5| Step: 3
Training loss: 2.448209285736084
Validation loss: 1.9704126004249818

Epoch: 5| Step: 4
Training loss: 2.071810722351074
Validation loss: 1.9700678881778513

Epoch: 5| Step: 5
Training loss: 1.5019853115081787
Validation loss: 1.9325375454400175

Epoch: 5| Step: 6
Training loss: 1.9158751964569092
Validation loss: 1.9723703707418134

Epoch: 5| Step: 7
Training loss: 2.079334259033203
Validation loss: 1.9713239515981367

Epoch: 5| Step: 8
Training loss: 1.4649165868759155
Validation loss: 1.9808050176148773

Epoch: 5| Step: 9
Training loss: 1.9870529174804688
Validation loss: 1.9573630068891792

Epoch: 5| Step: 10
Training loss: 2.221719741821289
Validation loss: 1.9785133689962409

Epoch: 199| Step: 0
Training loss: 2.2799646854400635
Validation loss: 1.998261167157081

Epoch: 5| Step: 1
Training loss: 1.451778531074524
Validation loss: 1.9626658257617746

Epoch: 5| Step: 2
Training loss: 2.1740269660949707
Validation loss: 2.0018933883277317

Epoch: 5| Step: 3
Training loss: 1.6975634098052979
Validation loss: 1.9769676526387532

Epoch: 5| Step: 4
Training loss: 2.415330410003662
Validation loss: 2.0067723156303487

Epoch: 5| Step: 5
Training loss: 3.0599522590637207
Validation loss: 2.0059096005655106

Epoch: 5| Step: 6
Training loss: 1.4833862781524658
Validation loss: 2.0041591339213873

Epoch: 5| Step: 7
Training loss: 1.7676751613616943
Validation loss: 1.9937368195544007

Epoch: 5| Step: 8
Training loss: 1.9178205728530884
Validation loss: 1.9727995241841962

Epoch: 5| Step: 9
Training loss: 1.4699642658233643
Validation loss: 1.961096667474316

Epoch: 5| Step: 10
Training loss: 1.4782700538635254
Validation loss: 1.9838236736994919

Epoch: 200| Step: 0
Training loss: 2.0043911933898926
Validation loss: 1.985766327509316

Epoch: 5| Step: 1
Training loss: 1.7515252828598022
Validation loss: 2.005385609083278

Epoch: 5| Step: 2
Training loss: 2.485673189163208
Validation loss: 1.9698202302378993

Epoch: 5| Step: 3
Training loss: 1.3388125896453857
Validation loss: 2.044758266018283

Epoch: 5| Step: 4
Training loss: 1.2230333089828491
Validation loss: 1.954358470055365

Epoch: 5| Step: 5
Training loss: 2.1241722106933594
Validation loss: 1.9598765719321467

Epoch: 5| Step: 6
Training loss: 2.0494773387908936
Validation loss: 1.9899904343389696

Epoch: 5| Step: 7
Training loss: 1.5583820343017578
Validation loss: 1.9313600832416165

Epoch: 5| Step: 8
Training loss: 2.18251371383667
Validation loss: 1.997851158982964

Epoch: 5| Step: 9
Training loss: 2.2069151401519775
Validation loss: 1.9400336921855967

Epoch: 5| Step: 10
Training loss: 2.773630142211914
Validation loss: 1.9437074738164102

Epoch: 201| Step: 0
Training loss: 1.6852328777313232
Validation loss: 1.9926974004314792

Epoch: 5| Step: 1
Training loss: 1.6845922470092773
Validation loss: 1.977118811299724

Epoch: 5| Step: 2
Training loss: 1.4334776401519775
Validation loss: 1.9636686463509836

Epoch: 5| Step: 3
Training loss: 1.4064457416534424
Validation loss: 1.9647681020921277

Epoch: 5| Step: 4
Training loss: 1.7624307870864868
Validation loss: 1.9690574804941814

Epoch: 5| Step: 5
Training loss: 2.0010082721710205
Validation loss: 2.0093446008620726

Epoch: 5| Step: 6
Training loss: 2.014078140258789
Validation loss: 1.961112282609427

Epoch: 5| Step: 7
Training loss: 1.6815662384033203
Validation loss: 1.9962554003602715

Epoch: 5| Step: 8
Training loss: 2.8616816997528076
Validation loss: 2.015621546776064

Epoch: 5| Step: 9
Training loss: 1.9439342021942139
Validation loss: 1.9570258086727512

Epoch: 5| Step: 10
Training loss: 2.5384700298309326
Validation loss: 1.9735465190743888

Epoch: 202| Step: 0
Training loss: 2.366084337234497
Validation loss: 1.991624637316632

Epoch: 5| Step: 1
Training loss: 2.0731070041656494
Validation loss: 1.978867962796201

Epoch: 5| Step: 2
Training loss: 1.70565927028656
Validation loss: 1.9904311510824388

Epoch: 5| Step: 3
Training loss: 1.7799568176269531
Validation loss: 1.9759177507892731

Epoch: 5| Step: 4
Training loss: 2.191577434539795
Validation loss: 1.9628334891411565

Epoch: 5| Step: 5
Training loss: 2.086334705352783
Validation loss: 1.9672687028044014

Epoch: 5| Step: 6
Training loss: 0.9684969186782837
Validation loss: 2.0062327167039276

Epoch: 5| Step: 7
Training loss: 2.354045867919922
Validation loss: 1.9580950147362166

Epoch: 5| Step: 8
Training loss: 1.9113857746124268
Validation loss: 1.918372687473092

Epoch: 5| Step: 9
Training loss: 1.5157560110092163
Validation loss: 1.9754019437297698

Epoch: 5| Step: 10
Training loss: 2.1906025409698486
Validation loss: 1.9946116068029915

Epoch: 203| Step: 0
Training loss: 2.1224703788757324
Validation loss: 2.003339159873224

Epoch: 5| Step: 1
Training loss: 1.7085899114608765
Validation loss: 2.0278093250848914

Epoch: 5| Step: 2
Training loss: 1.341576337814331
Validation loss: 1.9814685019113685

Epoch: 5| Step: 3
Training loss: 2.122641086578369
Validation loss: 1.9191866151748165

Epoch: 5| Step: 4
Training loss: 2.099529266357422
Validation loss: 1.9779053080466487

Epoch: 5| Step: 5
Training loss: 1.583698034286499
Validation loss: 1.997114840374198

Epoch: 5| Step: 6
Training loss: 2.191394567489624
Validation loss: 1.9865480456300961

Epoch: 5| Step: 7
Training loss: 1.685400366783142
Validation loss: 1.9594045505728772

Epoch: 5| Step: 8
Training loss: 1.748615026473999
Validation loss: 2.0037658509387763

Epoch: 5| Step: 9
Training loss: 1.9616104364395142
Validation loss: 2.0313569409872896

Epoch: 5| Step: 10
Training loss: 2.3223657608032227
Validation loss: 1.9685218641834874

Epoch: 204| Step: 0
Training loss: 2.061248779296875
Validation loss: 1.9915398987390662

Epoch: 5| Step: 1
Training loss: 1.9954074621200562
Validation loss: 1.9987568316921112

Epoch: 5| Step: 2
Training loss: 2.821742534637451
Validation loss: 1.9812690288789812

Epoch: 5| Step: 3
Training loss: 1.8007194995880127
Validation loss: 1.9486964723115325

Epoch: 5| Step: 4
Training loss: 1.8475404977798462
Validation loss: 2.0090685800839494

Epoch: 5| Step: 5
Training loss: 1.6890064477920532
Validation loss: 1.9578043081427132

Epoch: 5| Step: 6
Training loss: 1.6344654560089111
Validation loss: 1.9793564017101

Epoch: 5| Step: 7
Training loss: 1.5523252487182617
Validation loss: 1.9358271706488825

Epoch: 5| Step: 8
Training loss: 1.306405782699585
Validation loss: 1.9590504630919425

Epoch: 5| Step: 9
Training loss: 2.079841136932373
Validation loss: 2.0028017182503977

Epoch: 5| Step: 10
Training loss: 2.113905191421509
Validation loss: 1.9437800479191605

Epoch: 205| Step: 0
Training loss: 2.1121716499328613
Validation loss: 1.9652065589863768

Epoch: 5| Step: 1
Training loss: 2.1443867683410645
Validation loss: 1.9560146062604842

Epoch: 5| Step: 2
Training loss: 1.823822259902954
Validation loss: 2.0195397394959644

Epoch: 5| Step: 3
Training loss: 1.673501968383789
Validation loss: 1.995481401361445

Epoch: 5| Step: 4
Training loss: 1.4578272104263306
Validation loss: 1.9897708175002888

Epoch: 5| Step: 5
Training loss: 1.284303903579712
Validation loss: 2.007544502135246

Epoch: 5| Step: 6
Training loss: 1.7211021184921265
Validation loss: 1.9621918047628095

Epoch: 5| Step: 7
Training loss: 2.2605104446411133
Validation loss: 1.9909287678298129

Epoch: 5| Step: 8
Training loss: 2.1564152240753174
Validation loss: 1.963902775959302

Epoch: 5| Step: 9
Training loss: 2.2981045246124268
Validation loss: 1.9965985321229505

Epoch: 5| Step: 10
Training loss: 2.0518224239349365
Validation loss: 1.9693678604659213

Epoch: 206| Step: 0
Training loss: 2.079576015472412
Validation loss: 1.937505296481553

Epoch: 5| Step: 1
Training loss: 1.8936455249786377
Validation loss: 1.9912419139697988

Epoch: 5| Step: 2
Training loss: 1.0151766538619995
Validation loss: 1.9769321154522639

Epoch: 5| Step: 3
Training loss: 1.9750702381134033
Validation loss: 1.9614296613201019

Epoch: 5| Step: 4
Training loss: 1.7598083019256592
Validation loss: 1.9679781198501587

Epoch: 5| Step: 5
Training loss: 1.7814571857452393
Validation loss: 1.979738336737438

Epoch: 5| Step: 6
Training loss: 2.2158236503601074
Validation loss: 1.9593916990423714

Epoch: 5| Step: 7
Training loss: 2.3619377613067627
Validation loss: 2.001233737955811

Epoch: 5| Step: 8
Training loss: 1.7030302286148071
Validation loss: 1.9973532717715028

Epoch: 5| Step: 9
Training loss: 1.8711059093475342
Validation loss: 1.9964178159672727

Epoch: 5| Step: 10
Training loss: 2.2101824283599854
Validation loss: 1.9615408092416742

Epoch: 207| Step: 0
Training loss: 1.1599124670028687
Validation loss: 2.022973067017012

Epoch: 5| Step: 1
Training loss: 1.4062845706939697
Validation loss: 1.9823578391023862

Epoch: 5| Step: 2
Training loss: 2.2678210735321045
Validation loss: 1.9492516210002284

Epoch: 5| Step: 3
Training loss: 1.9251174926757812
Validation loss: 1.9925101469921809

Epoch: 5| Step: 4
Training loss: 1.8535093069076538
Validation loss: 1.9659945810994794

Epoch: 5| Step: 5
Training loss: 2.304220199584961
Validation loss: 1.9857159045434767

Epoch: 5| Step: 6
Training loss: 1.8122695684432983
Validation loss: 1.9578287780925792

Epoch: 5| Step: 7
Training loss: 2.0230681896209717
Validation loss: 1.9442300565781132

Epoch: 5| Step: 8
Training loss: 1.8618383407592773
Validation loss: 1.984508422113234

Epoch: 5| Step: 9
Training loss: 2.4002060890197754
Validation loss: 1.9691352382782967

Epoch: 5| Step: 10
Training loss: 2.2769176959991455
Validation loss: 1.9248921140547721

Epoch: 208| Step: 0
Training loss: 1.7592580318450928
Validation loss: 1.9763592391885736

Epoch: 5| Step: 1
Training loss: 2.087477445602417
Validation loss: 1.9676425354455107

Epoch: 5| Step: 2
Training loss: 1.7990779876708984
Validation loss: 1.96492725546642

Epoch: 5| Step: 3
Training loss: 2.4590039253234863
Validation loss: 1.961547338834373

Epoch: 5| Step: 4
Training loss: 1.6617435216903687
Validation loss: 1.9706460557958132

Epoch: 5| Step: 5
Training loss: 1.804600477218628
Validation loss: 1.9632424039225425

Epoch: 5| Step: 6
Training loss: 1.626186728477478
Validation loss: 1.9413400773079164

Epoch: 5| Step: 7
Training loss: 1.947269082069397
Validation loss: 1.9798166367315477

Epoch: 5| Step: 8
Training loss: 1.5943108797073364
Validation loss: 1.981714315311883

Epoch: 5| Step: 9
Training loss: 2.3264007568359375
Validation loss: 2.0141234808070685

Epoch: 5| Step: 10
Training loss: 1.5742461681365967
Validation loss: 1.97032303707574

Epoch: 209| Step: 0
Training loss: 1.828744649887085
Validation loss: 2.01039905189186

Epoch: 5| Step: 1
Training loss: 1.9824473857879639
Validation loss: 1.972494953422136

Epoch: 5| Step: 2
Training loss: 2.005528211593628
Validation loss: 1.9938166128691805

Epoch: 5| Step: 3
Training loss: 1.395432949066162
Validation loss: 1.9858936276487125

Epoch: 5| Step: 4
Training loss: 1.3984849452972412
Validation loss: 2.018238441918486

Epoch: 5| Step: 5
Training loss: 2.3589999675750732
Validation loss: 1.959124215187565

Epoch: 5| Step: 6
Training loss: 2.0208582878112793
Validation loss: 1.9486577536470147

Epoch: 5| Step: 7
Training loss: 2.0190017223358154
Validation loss: 1.9953115088965303

Epoch: 5| Step: 8
Training loss: 2.1395132541656494
Validation loss: 1.961727039788359

Epoch: 5| Step: 9
Training loss: 1.2413032054901123
Validation loss: 1.9828780953602125

Epoch: 5| Step: 10
Training loss: 2.6176700592041016
Validation loss: 1.9931319631556028

Epoch: 210| Step: 0
Training loss: 0.9298926591873169
Validation loss: 1.9551853518332205

Epoch: 5| Step: 1
Training loss: 1.7957299947738647
Validation loss: 1.9610681610722696

Epoch: 5| Step: 2
Training loss: 2.1517434120178223
Validation loss: 1.9450696924681306

Epoch: 5| Step: 3
Training loss: 1.9105052947998047
Validation loss: 1.9785833666401524

Epoch: 5| Step: 4
Training loss: 2.1616456508636475
Validation loss: 1.9475959347140404

Epoch: 5| Step: 5
Training loss: 1.9590399265289307
Validation loss: 1.9519691492921563

Epoch: 5| Step: 6
Training loss: 1.782785415649414
Validation loss: 2.0088729243124686

Epoch: 5| Step: 7
Training loss: 1.8210008144378662
Validation loss: 1.9719610239869805

Epoch: 5| Step: 8
Training loss: 2.2522218227386475
Validation loss: 1.961928488105856

Epoch: 5| Step: 9
Training loss: 2.476998805999756
Validation loss: 2.008373978317425

Epoch: 5| Step: 10
Training loss: 1.1642628908157349
Validation loss: 1.9515972111814766

Epoch: 211| Step: 0
Training loss: 1.9156713485717773
Validation loss: 1.9128868220954813

Epoch: 5| Step: 1
Training loss: 1.9735444784164429
Validation loss: 2.0249872951097387

Epoch: 5| Step: 2
Training loss: 1.6089061498641968
Validation loss: 2.001899988420548

Epoch: 5| Step: 3
Training loss: 1.9415889978408813
Validation loss: 1.9745846358678674

Epoch: 5| Step: 4
Training loss: 2.069847583770752
Validation loss: 1.965979579956301

Epoch: 5| Step: 5
Training loss: 1.897071123123169
Validation loss: 1.9889486566666634

Epoch: 5| Step: 6
Training loss: 1.902970314025879
Validation loss: 1.9309832703682683

Epoch: 5| Step: 7
Training loss: 1.2851605415344238
Validation loss: 1.9295316178311583

Epoch: 5| Step: 8
Training loss: 2.541771411895752
Validation loss: 1.9286579124389156

Epoch: 5| Step: 9
Training loss: 1.8856112957000732
Validation loss: 1.9439988700292443

Epoch: 5| Step: 10
Training loss: 1.9115737676620483
Validation loss: 1.9495522155556628

Epoch: 212| Step: 0
Training loss: 1.513829231262207
Validation loss: 1.9717053367245583

Epoch: 5| Step: 1
Training loss: 1.1121551990509033
Validation loss: 1.9222488723775393

Epoch: 5| Step: 2
Training loss: 2.1909146308898926
Validation loss: 1.9631777655693792

Epoch: 5| Step: 3
Training loss: 1.8789300918579102
Validation loss: 1.9646102100290277

Epoch: 5| Step: 4
Training loss: 1.6082465648651123
Validation loss: 1.9497998863138177

Epoch: 5| Step: 5
Training loss: 1.9432344436645508
Validation loss: 1.997121577621788

Epoch: 5| Step: 6
Training loss: 2.283527135848999
Validation loss: 1.970550811418923

Epoch: 5| Step: 7
Training loss: 1.5385770797729492
Validation loss: 2.028263589387299

Epoch: 5| Step: 8
Training loss: 2.4059081077575684
Validation loss: 1.9612755801088066

Epoch: 5| Step: 9
Training loss: 2.816007137298584
Validation loss: 1.9841541141592047

Epoch: 5| Step: 10
Training loss: 1.6052567958831787
Validation loss: 1.978462129510859

Epoch: 213| Step: 0
Training loss: 1.8908847570419312
Validation loss: 2.0144748739016953

Epoch: 5| Step: 1
Training loss: 1.8113197088241577
Validation loss: 1.9696237271831882

Epoch: 5| Step: 2
Training loss: 2.2955832481384277
Validation loss: 1.946601567729827

Epoch: 5| Step: 3
Training loss: 2.3989949226379395
Validation loss: 1.9870866267911849

Epoch: 5| Step: 4
Training loss: 1.8110415935516357
Validation loss: 1.939603687614523

Epoch: 5| Step: 5
Training loss: 1.7118854522705078
Validation loss: 1.95891910470942

Epoch: 5| Step: 6
Training loss: 2.067500591278076
Validation loss: 1.926799892097391

Epoch: 5| Step: 7
Training loss: 2.3413119316101074
Validation loss: 1.9923249829200007

Epoch: 5| Step: 8
Training loss: 1.4950697422027588
Validation loss: 1.907572433512698

Epoch: 5| Step: 9
Training loss: 1.5088711977005005
Validation loss: 1.9026989552282518

Epoch: 5| Step: 10
Training loss: 1.641221046447754
Validation loss: 1.9287556281653784

Epoch: 214| Step: 0
Training loss: 1.9109461307525635
Validation loss: 1.9968481474025275

Epoch: 5| Step: 1
Training loss: 2.14675235748291
Validation loss: 1.97906324683979

Epoch: 5| Step: 2
Training loss: 1.3352714776992798
Validation loss: 1.9400733004334152

Epoch: 5| Step: 3
Training loss: 1.523167371749878
Validation loss: 1.949098430654054

Epoch: 5| Step: 4
Training loss: 1.9520593881607056
Validation loss: 1.9743680671979023

Epoch: 5| Step: 5
Training loss: 2.311929941177368
Validation loss: 1.9492137444916593

Epoch: 5| Step: 6
Training loss: 2.060774326324463
Validation loss: 1.9390059209639026

Epoch: 5| Step: 7
Training loss: 2.2873871326446533
Validation loss: 1.9628672804883731

Epoch: 5| Step: 8
Training loss: 1.365520715713501
Validation loss: 1.9699391293269333

Epoch: 5| Step: 9
Training loss: 2.055736780166626
Validation loss: 1.8939796442626624

Epoch: 5| Step: 10
Training loss: 1.7799410820007324
Validation loss: 1.9664196468168689

Epoch: 215| Step: 0
Training loss: 1.6236000061035156
Validation loss: 1.9430668892398957

Epoch: 5| Step: 1
Training loss: 1.8207499980926514
Validation loss: 1.9694317207541516

Epoch: 5| Step: 2
Training loss: 1.9514764547348022
Validation loss: 1.9678835433016542

Epoch: 5| Step: 3
Training loss: 1.6021264791488647
Validation loss: 1.985215199890957

Epoch: 5| Step: 4
Training loss: 2.0499019622802734
Validation loss: 1.9665963419022099

Epoch: 5| Step: 5
Training loss: 1.6323349475860596
Validation loss: 1.9486814852683776

Epoch: 5| Step: 6
Training loss: 2.5258193016052246
Validation loss: 1.9753740320923507

Epoch: 5| Step: 7
Training loss: 2.352144718170166
Validation loss: 1.9251175529213362

Epoch: 5| Step: 8
Training loss: 1.405576467514038
Validation loss: 1.9883421210832493

Epoch: 5| Step: 9
Training loss: 1.573070764541626
Validation loss: 1.9950295827722038

Epoch: 5| Step: 10
Training loss: 1.6693181991577148
Validation loss: 1.972093673162563

Epoch: 216| Step: 0
Training loss: 1.890768051147461
Validation loss: 1.938169139687733

Epoch: 5| Step: 1
Training loss: 1.9014205932617188
Validation loss: 1.969350677664562

Epoch: 5| Step: 2
Training loss: 1.384351372718811
Validation loss: 2.0019240584424747

Epoch: 5| Step: 3
Training loss: 1.8176839351654053
Validation loss: 1.9286645112499115

Epoch: 5| Step: 4
Training loss: 2.095555543899536
Validation loss: 1.9398929521601687

Epoch: 5| Step: 5
Training loss: 1.7501556873321533
Validation loss: 1.9649768644763577

Epoch: 5| Step: 6
Training loss: 2.331547975540161
Validation loss: 1.9156150587143437

Epoch: 5| Step: 7
Training loss: 1.896709680557251
Validation loss: 1.9719865629749913

Epoch: 5| Step: 8
Training loss: 2.1106338500976562
Validation loss: 1.9571014040259904

Epoch: 5| Step: 9
Training loss: 1.6682401895523071
Validation loss: 1.9172750647350023

Epoch: 5| Step: 10
Training loss: 1.7606565952301025
Validation loss: 1.8940106373961254

Epoch: 217| Step: 0
Training loss: 1.840684175491333
Validation loss: 2.009172513920774

Epoch: 5| Step: 1
Training loss: 2.0246739387512207
Validation loss: 1.9079388572323708

Epoch: 5| Step: 2
Training loss: 2.137219190597534
Validation loss: 1.9429247456212198

Epoch: 5| Step: 3
Training loss: 1.4225246906280518
Validation loss: 1.9214586878335604

Epoch: 5| Step: 4
Training loss: 1.913683533668518
Validation loss: 1.9548872799001715

Epoch: 5| Step: 5
Training loss: 2.685335874557495
Validation loss: 1.971195573447853

Epoch: 5| Step: 6
Training loss: 2.253218173980713
Validation loss: 1.97038955842295

Epoch: 5| Step: 7
Training loss: 1.145861268043518
Validation loss: 1.9419548498686923

Epoch: 5| Step: 8
Training loss: 1.4298489093780518
Validation loss: 1.9372975031534831

Epoch: 5| Step: 9
Training loss: 1.966897964477539
Validation loss: 1.919076181227161

Epoch: 5| Step: 10
Training loss: 1.7874953746795654
Validation loss: 1.9348150735260339

Epoch: 218| Step: 0
Training loss: 2.32534122467041
Validation loss: 1.9255027206995154

Epoch: 5| Step: 1
Training loss: 1.887611746788025
Validation loss: 1.9639812695082797

Epoch: 5| Step: 2
Training loss: 2.2095725536346436
Validation loss: 1.9299283630104476

Epoch: 5| Step: 3
Training loss: 1.983648657798767
Validation loss: 1.9461235154059626

Epoch: 5| Step: 4
Training loss: 1.6627676486968994
Validation loss: 1.9237135520545385

Epoch: 5| Step: 5
Training loss: 1.8416450023651123
Validation loss: 1.986087518353616

Epoch: 5| Step: 6
Training loss: 1.7877280712127686
Validation loss: 1.9857631088584982

Epoch: 5| Step: 7
Training loss: 1.738422155380249
Validation loss: 1.9757248445223736

Epoch: 5| Step: 8
Training loss: 1.7722488641738892
Validation loss: 1.9683404481539162

Epoch: 5| Step: 9
Training loss: 1.7014538049697876
Validation loss: 1.9849547211841871

Epoch: 5| Step: 10
Training loss: 1.9280121326446533
Validation loss: 1.9817581253667031

Epoch: 219| Step: 0
Training loss: 1.4609768390655518
Validation loss: 1.9537277580589376

Epoch: 5| Step: 1
Training loss: 1.9324594736099243
Validation loss: 1.9702197454308952

Epoch: 5| Step: 2
Training loss: 2.137946128845215
Validation loss: 1.9735024744464504

Epoch: 5| Step: 3
Training loss: 2.1108317375183105
Validation loss: 1.9736397112569501

Epoch: 5| Step: 4
Training loss: 2.007568836212158
Validation loss: 1.9279544379121514

Epoch: 5| Step: 5
Training loss: 2.1983706951141357
Validation loss: 1.9281391238653531

Epoch: 5| Step: 6
Training loss: 1.1803481578826904
Validation loss: 1.9393392378284084

Epoch: 5| Step: 7
Training loss: 0.9934623837471008
Validation loss: 1.9595231368977537

Epoch: 5| Step: 8
Training loss: 1.9307302236557007
Validation loss: 1.9043264017310193

Epoch: 5| Step: 9
Training loss: 2.11204195022583
Validation loss: 1.951054839677708

Epoch: 5| Step: 10
Training loss: 2.329232931137085
Validation loss: 1.9277888113452541

Epoch: 220| Step: 0
Training loss: 1.4923298358917236
Validation loss: 1.929203139838352

Epoch: 5| Step: 1
Training loss: 1.270439624786377
Validation loss: 1.9500385151114514

Epoch: 5| Step: 2
Training loss: 1.8758987188339233
Validation loss: 1.9622096195015857

Epoch: 5| Step: 3
Training loss: 1.6302181482315063
Validation loss: 1.897379599591737

Epoch: 5| Step: 4
Training loss: 1.467108130455017
Validation loss: 1.974232276280721

Epoch: 5| Step: 5
Training loss: 1.7333059310913086
Validation loss: 1.920850899911696

Epoch: 5| Step: 6
Training loss: 2.172004222869873
Validation loss: 1.9701148976561844

Epoch: 5| Step: 7
Training loss: 1.562600016593933
Validation loss: 1.9547324872785998

Epoch: 5| Step: 8
Training loss: 2.3846123218536377
Validation loss: 1.9666707759262414

Epoch: 5| Step: 9
Training loss: 2.4021389484405518
Validation loss: 1.9325069253162672

Epoch: 5| Step: 10
Training loss: 2.472291946411133
Validation loss: 1.9940520281432776

Epoch: 221| Step: 0
Training loss: 2.207057476043701
Validation loss: 1.9226210899250482

Epoch: 5| Step: 1
Training loss: 1.9194633960723877
Validation loss: 1.9641387129342684

Epoch: 5| Step: 2
Training loss: 2.1728603839874268
Validation loss: 1.9417205523419123

Epoch: 5| Step: 3
Training loss: 1.8803173303604126
Validation loss: 1.9735689342662852

Epoch: 5| Step: 4
Training loss: 1.6180404424667358
Validation loss: 1.975181064298076

Epoch: 5| Step: 5
Training loss: 1.7079441547393799
Validation loss: 1.9596984155716435

Epoch: 5| Step: 6
Training loss: 2.3085789680480957
Validation loss: 1.985364665267288

Epoch: 5| Step: 7
Training loss: 1.8148752450942993
Validation loss: 1.9492303709830008

Epoch: 5| Step: 8
Training loss: 1.8481128215789795
Validation loss: 1.970943897001205

Epoch: 5| Step: 9
Training loss: 1.7912477254867554
Validation loss: 1.9500620852234543

Epoch: 5| Step: 10
Training loss: 1.1812328100204468
Validation loss: 1.9390367205424974

Epoch: 222| Step: 0
Training loss: 1.8552385568618774
Validation loss: 1.946000820846968

Epoch: 5| Step: 1
Training loss: 1.3558257818222046
Validation loss: 1.9451093032795896

Epoch: 5| Step: 2
Training loss: 1.8781830072402954
Validation loss: 1.907710236887778

Epoch: 5| Step: 3
Training loss: 1.286516785621643
Validation loss: 1.922692584735091

Epoch: 5| Step: 4
Training loss: 2.473236560821533
Validation loss: 1.9281498668014363

Epoch: 5| Step: 5
Training loss: 2.149484634399414
Validation loss: 1.9355778437788769

Epoch: 5| Step: 6
Training loss: 2.3341362476348877
Validation loss: 1.942220518665929

Epoch: 5| Step: 7
Training loss: 1.6525135040283203
Validation loss: 1.9599376416975451

Epoch: 5| Step: 8
Training loss: 2.0337209701538086
Validation loss: 1.9460909405062277

Epoch: 5| Step: 9
Training loss: 1.5970836877822876
Validation loss: 1.942395556357599

Epoch: 5| Step: 10
Training loss: 2.0024280548095703
Validation loss: 1.9696194574397097

Epoch: 223| Step: 0
Training loss: 2.1728358268737793
Validation loss: 1.914160072162587

Epoch: 5| Step: 1
Training loss: 1.734065055847168
Validation loss: 1.946222669334822

Epoch: 5| Step: 2
Training loss: 1.9176113605499268
Validation loss: 1.967066216212447

Epoch: 5| Step: 3
Training loss: 1.5738331079483032
Validation loss: 1.9681101601610902

Epoch: 5| Step: 4
Training loss: 1.856196641921997
Validation loss: 2.005700975336054

Epoch: 5| Step: 5
Training loss: 2.167233943939209
Validation loss: 2.0090780668361212

Epoch: 5| Step: 6
Training loss: 2.3898158073425293
Validation loss: 1.9991563597033102

Epoch: 5| Step: 7
Training loss: 1.2443764209747314
Validation loss: 1.9863626905666885

Epoch: 5| Step: 8
Training loss: 2.6641221046447754
Validation loss: 2.0466945901993783

Epoch: 5| Step: 9
Training loss: 1.385038137435913
Validation loss: 1.9880988367142216

Epoch: 5| Step: 10
Training loss: 1.4119722843170166
Validation loss: 1.9619057921953098

Epoch: 224| Step: 0
Training loss: 2.1694350242614746
Validation loss: 1.9299957316408876

Epoch: 5| Step: 1
Training loss: 1.686590552330017
Validation loss: 1.9244757454882386

Epoch: 5| Step: 2
Training loss: 1.8366416692733765
Validation loss: 2.0026287609531033

Epoch: 5| Step: 3
Training loss: 1.505537986755371
Validation loss: 1.938819275107435

Epoch: 5| Step: 4
Training loss: 1.7848243713378906
Validation loss: 1.9235784161475398

Epoch: 5| Step: 5
Training loss: 2.1498093605041504
Validation loss: 1.9083123373728927

Epoch: 5| Step: 6
Training loss: 1.8536897897720337
Validation loss: 1.9099039916069276

Epoch: 5| Step: 7
Training loss: 1.9205608367919922
Validation loss: 1.8825061692986438

Epoch: 5| Step: 8
Training loss: 1.5303484201431274
Validation loss: 1.891043827097903

Epoch: 5| Step: 9
Training loss: 1.8365745544433594
Validation loss: 1.965551871125416

Epoch: 5| Step: 10
Training loss: 2.2564339637756348
Validation loss: 1.9625317614565614

Epoch: 225| Step: 0
Training loss: 2.2040114402770996
Validation loss: 1.9421621996869323

Epoch: 5| Step: 1
Training loss: 1.9641907215118408
Validation loss: 1.9212030967076619

Epoch: 5| Step: 2
Training loss: 1.613330602645874
Validation loss: 1.9370638196186354

Epoch: 5| Step: 3
Training loss: 1.8732101917266846
Validation loss: 1.921003149401757

Epoch: 5| Step: 4
Training loss: 2.0724658966064453
Validation loss: 1.9728120142413723

Epoch: 5| Step: 5
Training loss: 1.7863457202911377
Validation loss: 1.9415131512508597

Epoch: 5| Step: 6
Training loss: 1.8510452508926392
Validation loss: 2.003487438283941

Epoch: 5| Step: 7
Training loss: 1.9681476354599
Validation loss: 1.9241321881612141

Epoch: 5| Step: 8
Training loss: 1.6885486841201782
Validation loss: 1.9076843671901251

Epoch: 5| Step: 9
Training loss: 1.628157377243042
Validation loss: 1.9265145858128865

Epoch: 5| Step: 10
Training loss: 1.9430837631225586
Validation loss: 1.9505792997216667

Epoch: 226| Step: 0
Training loss: 2.0400569438934326
Validation loss: 1.9964045939906951

Epoch: 5| Step: 1
Training loss: 1.4195462465286255
Validation loss: 1.973323227256857

Epoch: 5| Step: 2
Training loss: 2.2422404289245605
Validation loss: 1.9595861640027774

Epoch: 5| Step: 3
Training loss: 2.3042874336242676
Validation loss: 1.985852849098944

Epoch: 5| Step: 4
Training loss: 1.709557294845581
Validation loss: 1.9978004655530375

Epoch: 5| Step: 5
Training loss: 2.0237715244293213
Validation loss: 2.0088086333326114

Epoch: 5| Step: 6
Training loss: 2.133247137069702
Validation loss: 1.9573787694336267

Epoch: 5| Step: 7
Training loss: 1.9186651706695557
Validation loss: 1.977833540208878

Epoch: 5| Step: 8
Training loss: 1.5505952835083008
Validation loss: 2.0027365069235525

Epoch: 5| Step: 9
Training loss: 1.7375710010528564
Validation loss: 1.9590881742456907

Epoch: 5| Step: 10
Training loss: 1.523411750793457
Validation loss: 1.9537962752003823

Epoch: 227| Step: 0
Training loss: 2.532209634780884
Validation loss: 1.9618487101729198

Epoch: 5| Step: 1
Training loss: 2.3752195835113525
Validation loss: 1.9711016403731478

Epoch: 5| Step: 2
Training loss: 1.9750747680664062
Validation loss: 1.9605247487304032

Epoch: 5| Step: 3
Training loss: 1.779659628868103
Validation loss: 1.9566174873741724

Epoch: 5| Step: 4
Training loss: 1.492950677871704
Validation loss: 1.970359944528149

Epoch: 5| Step: 5
Training loss: 1.12788987159729
Validation loss: 1.956269779512959

Epoch: 5| Step: 6
Training loss: 1.830715537071228
Validation loss: 1.9695208175207979

Epoch: 5| Step: 7
Training loss: 1.9047905206680298
Validation loss: 1.9614312366772724

Epoch: 5| Step: 8
Training loss: 1.607017159461975
Validation loss: 1.9120955403133104

Epoch: 5| Step: 9
Training loss: 2.009025812149048
Validation loss: 1.9293766611365861

Epoch: 5| Step: 10
Training loss: 1.4641693830490112
Validation loss: 1.9442819933737479

Epoch: 228| Step: 0
Training loss: 1.463047981262207
Validation loss: 1.9939021474571639

Epoch: 5| Step: 1
Training loss: 1.4872570037841797
Validation loss: 1.9609179009673416

Epoch: 5| Step: 2
Training loss: 2.1104578971862793
Validation loss: 1.9587829241188623

Epoch: 5| Step: 3
Training loss: 1.3840041160583496
Validation loss: 1.956128921560062

Epoch: 5| Step: 4
Training loss: 1.8309186697006226
Validation loss: 1.9671268706680627

Epoch: 5| Step: 5
Training loss: 2.1577019691467285
Validation loss: 1.9455028733899515

Epoch: 5| Step: 6
Training loss: 1.8786643743515015
Validation loss: 1.952619275739116

Epoch: 5| Step: 7
Training loss: 2.035226345062256
Validation loss: 1.9404948834450013

Epoch: 5| Step: 8
Training loss: 2.2695045471191406
Validation loss: 1.9080230907727314

Epoch: 5| Step: 9
Training loss: 2.4141147136688232
Validation loss: 1.9105408678772628

Epoch: 5| Step: 10
Training loss: 1.4342106580734253
Validation loss: 1.9262500898812407

Epoch: 229| Step: 0
Training loss: 2.0275511741638184
Validation loss: 1.8704119561820902

Epoch: 5| Step: 1
Training loss: 1.6229159832000732
Validation loss: 1.9821269768540577

Epoch: 5| Step: 2
Training loss: 1.8227145671844482
Validation loss: 1.9141893130476757

Epoch: 5| Step: 3
Training loss: 1.86956787109375
Validation loss: 1.9089842022106212

Epoch: 5| Step: 4
Training loss: 1.7819883823394775
Validation loss: 1.9464648897929857

Epoch: 5| Step: 5
Training loss: 1.7106937170028687
Validation loss: 1.961198700371609

Epoch: 5| Step: 6
Training loss: 1.7616889476776123
Validation loss: 1.964580351306546

Epoch: 5| Step: 7
Training loss: 1.8437381982803345
Validation loss: 1.9446794576542352

Epoch: 5| Step: 8
Training loss: 1.7582130432128906
Validation loss: 1.9338061835176201

Epoch: 5| Step: 9
Training loss: 1.8754332065582275
Validation loss: 1.9236431814009143

Epoch: 5| Step: 10
Training loss: 2.097085475921631
Validation loss: 1.949102186387585

Epoch: 230| Step: 0
Training loss: 1.832760214805603
Validation loss: 1.8908546073462373

Epoch: 5| Step: 1
Training loss: 1.913712501525879
Validation loss: 1.9732725492087744

Epoch: 5| Step: 2
Training loss: 1.5497795343399048
Validation loss: 1.9156461351661271

Epoch: 5| Step: 3
Training loss: 1.4851875305175781
Validation loss: 1.964466998654027

Epoch: 5| Step: 4
Training loss: 1.9738479852676392
Validation loss: 1.9444365116857714

Epoch: 5| Step: 5
Training loss: 2.2334542274475098
Validation loss: 1.969269403847315

Epoch: 5| Step: 6
Training loss: 2.191699981689453
Validation loss: 1.9336291282407698

Epoch: 5| Step: 7
Training loss: 1.4862143993377686
Validation loss: 1.9578281218005764

Epoch: 5| Step: 8
Training loss: 1.9933608770370483
Validation loss: 1.9094443680137716

Epoch: 5| Step: 9
Training loss: 1.639875054359436
Validation loss: 1.9370235230333062

Epoch: 5| Step: 10
Training loss: 2.2446534633636475
Validation loss: 1.9657617794570101

Epoch: 231| Step: 0
Training loss: 2.0219197273254395
Validation loss: 1.9527541450274888

Epoch: 5| Step: 1
Training loss: 2.1171982288360596
Validation loss: 2.000121799848413

Epoch: 5| Step: 2
Training loss: 1.850843071937561
Validation loss: 1.9251029465788154

Epoch: 5| Step: 3
Training loss: 2.063225269317627
Validation loss: 1.920518445712264

Epoch: 5| Step: 4
Training loss: 1.7531534433364868
Validation loss: 2.0177874770215762

Epoch: 5| Step: 5
Training loss: 1.8852803707122803
Validation loss: 1.9395557616346626

Epoch: 5| Step: 6
Training loss: 0.9770711660385132
Validation loss: 1.9642330626005768

Epoch: 5| Step: 7
Training loss: 2.525653839111328
Validation loss: 1.967072202313331

Epoch: 5| Step: 8
Training loss: 1.3063268661499023
Validation loss: 1.9672028467219362

Epoch: 5| Step: 9
Training loss: 1.6819751262664795
Validation loss: 1.9642150709705968

Epoch: 5| Step: 10
Training loss: 1.7200580835342407
Validation loss: 2.0005376723504837

Epoch: 232| Step: 0
Training loss: 1.3975919485092163
Validation loss: 1.9359588110318748

Epoch: 5| Step: 1
Training loss: 2.341235637664795
Validation loss: 1.9010264078776042

Epoch: 5| Step: 2
Training loss: 2.126255989074707
Validation loss: 1.9208643039067586

Epoch: 5| Step: 3
Training loss: 2.3756232261657715
Validation loss: 1.8957033298348869

Epoch: 5| Step: 4
Training loss: 2.3368537425994873
Validation loss: 1.9465259762220486

Epoch: 5| Step: 5
Training loss: 1.6294864416122437
Validation loss: 1.9465116429072555

Epoch: 5| Step: 6
Training loss: 1.193568229675293
Validation loss: 1.871784730624127

Epoch: 5| Step: 7
Training loss: 1.692186713218689
Validation loss: 1.9031840114183323

Epoch: 5| Step: 8
Training loss: 1.371869683265686
Validation loss: 1.8919699986775715

Epoch: 5| Step: 9
Training loss: 1.6400429010391235
Validation loss: 1.9253786148563508

Epoch: 5| Step: 10
Training loss: 1.988421082496643
Validation loss: 1.900657690981383

Epoch: 233| Step: 0
Training loss: 1.8891404867172241
Validation loss: 1.9367964690731418

Epoch: 5| Step: 1
Training loss: 1.8543657064437866
Validation loss: 1.928019900475779

Epoch: 5| Step: 2
Training loss: 1.8814423084259033
Validation loss: 1.8820156102539392

Epoch: 5| Step: 3
Training loss: 2.0206103324890137
Validation loss: 1.96500603998861

Epoch: 5| Step: 4
Training loss: 1.7155160903930664
Validation loss: 1.926395268850429

Epoch: 5| Step: 5
Training loss: 1.8808380365371704
Validation loss: 1.8879347796081214

Epoch: 5| Step: 6
Training loss: 1.540138602256775
Validation loss: 1.9633832131662676

Epoch: 5| Step: 7
Training loss: 2.2811598777770996
Validation loss: 1.9547097298406786

Epoch: 5| Step: 8
Training loss: 1.8500728607177734
Validation loss: 1.8918081227169241

Epoch: 5| Step: 9
Training loss: 1.830667495727539
Validation loss: 1.9373589882286646

Epoch: 5| Step: 10
Training loss: 1.8103901147842407
Validation loss: 1.9541996294452297

Epoch: 234| Step: 0
Training loss: 0.8638227581977844
Validation loss: 1.9199102873443274

Epoch: 5| Step: 1
Training loss: 2.400722026824951
Validation loss: 1.900847868252826

Epoch: 5| Step: 2
Training loss: 2.4211342334747314
Validation loss: 1.960073547978555

Epoch: 5| Step: 3
Training loss: 2.393315076828003
Validation loss: 1.9120919806982881

Epoch: 5| Step: 4
Training loss: 1.2567845582962036
Validation loss: 1.9127592668738416

Epoch: 5| Step: 5
Training loss: 1.4622457027435303
Validation loss: 1.9445795474513885

Epoch: 5| Step: 6
Training loss: 2.01300311088562
Validation loss: 1.9283948841915335

Epoch: 5| Step: 7
Training loss: 1.2160848379135132
Validation loss: 1.898386013123297

Epoch: 5| Step: 8
Training loss: 2.220768690109253
Validation loss: 1.9300084985712522

Epoch: 5| Step: 9
Training loss: 1.5179469585418701
Validation loss: 1.9613429448937858

Epoch: 5| Step: 10
Training loss: 2.1683640480041504
Validation loss: 1.9306478884912306

Epoch: 235| Step: 0
Training loss: 1.5397064685821533
Validation loss: 1.951251281205044

Epoch: 5| Step: 1
Training loss: 1.1660953760147095
Validation loss: 1.9237606627966768

Epoch: 5| Step: 2
Training loss: 2.006282329559326
Validation loss: 1.9180804055224183

Epoch: 5| Step: 3
Training loss: 2.024695873260498
Validation loss: 1.9573370820732527

Epoch: 5| Step: 4
Training loss: 1.7378692626953125
Validation loss: 1.9132826071913525

Epoch: 5| Step: 5
Training loss: 1.6124517917633057
Validation loss: 1.9548813732721473

Epoch: 5| Step: 6
Training loss: 1.7653074264526367
Validation loss: 1.9464048621475056

Epoch: 5| Step: 7
Training loss: 2.000159740447998
Validation loss: 1.953476353358197

Epoch: 5| Step: 8
Training loss: 2.6721129417419434
Validation loss: 1.9734538806382047

Epoch: 5| Step: 9
Training loss: 1.6846109628677368
Validation loss: 1.9275425070075578

Epoch: 5| Step: 10
Training loss: 1.9834628105163574
Validation loss: 1.958071998370591

Epoch: 236| Step: 0
Training loss: 1.7246649265289307
Validation loss: 1.9367108460395568

Epoch: 5| Step: 1
Training loss: 1.912651777267456
Validation loss: 1.9370661127951838

Epoch: 5| Step: 2
Training loss: 1.723755121231079
Validation loss: 1.9106139418899373

Epoch: 5| Step: 3
Training loss: 1.9495785236358643
Validation loss: 1.9259077259289321

Epoch: 5| Step: 4
Training loss: 1.3246115446090698
Validation loss: 1.9335086089308544

Epoch: 5| Step: 5
Training loss: 1.7077795267105103
Validation loss: 1.9449508907974407

Epoch: 5| Step: 6
Training loss: 2.5882580280303955
Validation loss: 1.9039117508037116

Epoch: 5| Step: 7
Training loss: 2.279689311981201
Validation loss: 1.9416723738434494

Epoch: 5| Step: 8
Training loss: 1.3613629341125488
Validation loss: 1.9527374095814203

Epoch: 5| Step: 9
Training loss: 1.6572997570037842
Validation loss: 1.876548744017078

Epoch: 5| Step: 10
Training loss: 1.5845097303390503
Validation loss: 1.9408429335522395

Epoch: 237| Step: 0
Training loss: 1.4146002531051636
Validation loss: 1.9470046771469938

Epoch: 5| Step: 1
Training loss: 1.921393632888794
Validation loss: 1.9567806682279032

Epoch: 5| Step: 2
Training loss: 1.9482243061065674
Validation loss: 1.9449740199632541

Epoch: 5| Step: 3
Training loss: 1.6518417596817017
Validation loss: 1.9297563388783445

Epoch: 5| Step: 4
Training loss: 1.9283485412597656
Validation loss: 1.9266638140524588

Epoch: 5| Step: 5
Training loss: 1.8902466297149658
Validation loss: 1.897287832793369

Epoch: 5| Step: 6
Training loss: 1.9460551738739014
Validation loss: 1.9552042663738292

Epoch: 5| Step: 7
Training loss: 1.5187501907348633
Validation loss: 1.9246611056789276

Epoch: 5| Step: 8
Training loss: 1.5411094427108765
Validation loss: 1.9016494353612263

Epoch: 5| Step: 9
Training loss: 1.9533294439315796
Validation loss: 1.8906474728738107

Epoch: 5| Step: 10
Training loss: 2.1625168323516846
Validation loss: 1.9107475306398125

Epoch: 238| Step: 0
Training loss: 1.4159531593322754
Validation loss: 1.8921962104817873

Epoch: 5| Step: 1
Training loss: 1.0972764492034912
Validation loss: 1.9632976798601047

Epoch: 5| Step: 2
Training loss: 1.7131025791168213
Validation loss: 1.9480502810529483

Epoch: 5| Step: 3
Training loss: 1.5712257623672485
Validation loss: 1.9377039196670696

Epoch: 5| Step: 4
Training loss: 2.698803663253784
Validation loss: 1.905754062437242

Epoch: 5| Step: 5
Training loss: 1.9844367504119873
Validation loss: 1.9286664326985676

Epoch: 5| Step: 6
Training loss: 1.9699337482452393
Validation loss: 1.8987069975945257

Epoch: 5| Step: 7
Training loss: 2.0141682624816895
Validation loss: 1.9460371540438743

Epoch: 5| Step: 8
Training loss: 2.397383451461792
Validation loss: 1.9683089999742405

Epoch: 5| Step: 9
Training loss: 1.6911932229995728
Validation loss: 1.8644496048650434

Epoch: 5| Step: 10
Training loss: 1.6854168176651
Validation loss: 1.940303853763047

Epoch: 239| Step: 0
Training loss: 2.071737766265869
Validation loss: 1.8995729941193775

Epoch: 5| Step: 1
Training loss: 1.441400408744812
Validation loss: 1.9145330575204664

Epoch: 5| Step: 2
Training loss: 1.6891807317733765
Validation loss: 1.8971980002618605

Epoch: 5| Step: 3
Training loss: 1.747450828552246
Validation loss: 1.9272526925609959

Epoch: 5| Step: 4
Training loss: 1.9875818490982056
Validation loss: 1.9272571699593657

Epoch: 5| Step: 5
Training loss: 1.4036881923675537
Validation loss: 1.881357043020187

Epoch: 5| Step: 6
Training loss: 2.2475268840789795
Validation loss: 1.9154665982851418

Epoch: 5| Step: 7
Training loss: 2.0057766437530518
Validation loss: 1.9329063212999733

Epoch: 5| Step: 8
Training loss: 2.2499608993530273
Validation loss: 1.9339518303512244

Epoch: 5| Step: 9
Training loss: 1.9314197301864624
Validation loss: 1.926368236541748

Epoch: 5| Step: 10
Training loss: 1.3012752532958984
Validation loss: 1.9332939886277722

Epoch: 240| Step: 0
Training loss: 1.7862460613250732
Validation loss: 1.8922033284300117

Epoch: 5| Step: 1
Training loss: 1.8142344951629639
Validation loss: 1.9542568883588236

Epoch: 5| Step: 2
Training loss: 1.7235323190689087
Validation loss: 1.934781277051536

Epoch: 5| Step: 3
Training loss: 1.7840280532836914
Validation loss: 1.970781300657539

Epoch: 5| Step: 4
Training loss: 2.0182809829711914
Validation loss: 1.9939750599604782

Epoch: 5| Step: 5
Training loss: 2.0924291610717773
Validation loss: 1.941948195939423

Epoch: 5| Step: 6
Training loss: 1.5117536783218384
Validation loss: 1.886629061032367

Epoch: 5| Step: 7
Training loss: 1.7139427661895752
Validation loss: 1.9071235182464763

Epoch: 5| Step: 8
Training loss: 2.171278715133667
Validation loss: 1.9250808415874359

Epoch: 5| Step: 9
Training loss: 1.8831520080566406
Validation loss: 1.9719646438475578

Epoch: 5| Step: 10
Training loss: 1.204408884048462
Validation loss: 1.9470009778135566

Epoch: 241| Step: 0
Training loss: 1.9488639831542969
Validation loss: 1.960359170872678

Epoch: 5| Step: 1
Training loss: 2.0764636993408203
Validation loss: 1.9189856507444893

Epoch: 5| Step: 2
Training loss: 1.6019260883331299
Validation loss: 1.910802387422131

Epoch: 5| Step: 3
Training loss: 1.6651264429092407
Validation loss: 1.9380671029449792

Epoch: 5| Step: 4
Training loss: 1.4428220987319946
Validation loss: 1.908928745536394

Epoch: 5| Step: 5
Training loss: 1.7493865489959717
Validation loss: 1.9056069876558037

Epoch: 5| Step: 6
Training loss: 1.2625234127044678
Validation loss: 1.9126641647790068

Epoch: 5| Step: 7
Training loss: 2.0166776180267334
Validation loss: 1.9311514105848087

Epoch: 5| Step: 8
Training loss: 1.646527886390686
Validation loss: 1.9491895296240365

Epoch: 5| Step: 9
Training loss: 2.676178216934204
Validation loss: 1.926366985485118

Epoch: 5| Step: 10
Training loss: 1.679616093635559
Validation loss: 1.9240661564693655

Epoch: 242| Step: 0
Training loss: 1.185643196105957
Validation loss: 1.9391484145195252

Epoch: 5| Step: 1
Training loss: 1.8172705173492432
Validation loss: 1.9024202772366103

Epoch: 5| Step: 2
Training loss: 1.8147246837615967
Validation loss: 1.9250062857904742

Epoch: 5| Step: 3
Training loss: 0.9721687436103821
Validation loss: 1.9366343623848372

Epoch: 5| Step: 4
Training loss: 2.2430968284606934
Validation loss: 1.8866199434444468

Epoch: 5| Step: 5
Training loss: 1.713382363319397
Validation loss: 1.873942849456623

Epoch: 5| Step: 6
Training loss: 2.006808042526245
Validation loss: 1.9247186632566555

Epoch: 5| Step: 7
Training loss: 1.953675627708435
Validation loss: 1.944340762271676

Epoch: 5| Step: 8
Training loss: 1.9345811605453491
Validation loss: 1.848763414608535

Epoch: 5| Step: 9
Training loss: 1.9278366565704346
Validation loss: 1.9234796903466667

Epoch: 5| Step: 10
Training loss: 2.1681525707244873
Validation loss: 1.880789452983487

Epoch: 243| Step: 0
Training loss: 1.8482630252838135
Validation loss: 1.916050822504105

Epoch: 5| Step: 1
Training loss: 1.9030730724334717
Validation loss: 1.9708319825510825

Epoch: 5| Step: 2
Training loss: 1.7180168628692627
Validation loss: 1.9014012480294833

Epoch: 5| Step: 3
Training loss: 1.5101133584976196
Validation loss: 1.9466958609960412

Epoch: 5| Step: 4
Training loss: 1.3893747329711914
Validation loss: 1.9564787572430027

Epoch: 5| Step: 5
Training loss: 2.302319288253784
Validation loss: 1.9182052714850313

Epoch: 5| Step: 6
Training loss: 1.9028068780899048
Validation loss: 1.9616015072791808

Epoch: 5| Step: 7
Training loss: 1.8942054510116577
Validation loss: 1.931630410173888

Epoch: 5| Step: 8
Training loss: 1.451724648475647
Validation loss: 1.9216285264620216

Epoch: 5| Step: 9
Training loss: 1.6824232339859009
Validation loss: 1.922901326610196

Epoch: 5| Step: 10
Training loss: 2.229037284851074
Validation loss: 1.926667599267857

Epoch: 244| Step: 0
Training loss: 1.8083198070526123
Validation loss: 1.9444397329002299

Epoch: 5| Step: 1
Training loss: 1.9704208374023438
Validation loss: 1.9743905644262991

Epoch: 5| Step: 2
Training loss: 2.306889057159424
Validation loss: 1.9442684752966768

Epoch: 5| Step: 3
Training loss: 1.716027021408081
Validation loss: 1.9254002007105018

Epoch: 5| Step: 4
Training loss: 1.5238450765609741
Validation loss: 1.9014030900052799

Epoch: 5| Step: 5
Training loss: 2.3441390991210938
Validation loss: 1.9577837964539886

Epoch: 5| Step: 6
Training loss: 1.4757587909698486
Validation loss: 1.9664094678817257

Epoch: 5| Step: 7
Training loss: 1.796128511428833
Validation loss: 1.926863375530448

Epoch: 5| Step: 8
Training loss: 1.65359365940094
Validation loss: 1.9950094158931444

Epoch: 5| Step: 9
Training loss: 1.4893535375595093
Validation loss: 1.92917053673857

Epoch: 5| Step: 10
Training loss: 2.096933603286743
Validation loss: 1.907150669764447

Epoch: 245| Step: 0
Training loss: 1.557725191116333
Validation loss: 1.9077807793053247

Epoch: 5| Step: 1
Training loss: 0.7225725054740906
Validation loss: 1.9064907822557675

Epoch: 5| Step: 2
Training loss: 2.3140616416931152
Validation loss: 1.9468433844145907

Epoch: 5| Step: 3
Training loss: 1.6978667974472046
Validation loss: 1.8810855150222778

Epoch: 5| Step: 4
Training loss: 1.2543104887008667
Validation loss: 1.8979135533814788

Epoch: 5| Step: 5
Training loss: 2.512998104095459
Validation loss: 1.9174189259929042

Epoch: 5| Step: 6
Training loss: 2.2140653133392334
Validation loss: 1.8907710352251608

Epoch: 5| Step: 7
Training loss: 2.8783135414123535
Validation loss: 1.907110709016041

Epoch: 5| Step: 8
Training loss: 1.675283432006836
Validation loss: 1.9267801495008572

Epoch: 5| Step: 9
Training loss: 1.69668447971344
Validation loss: 1.8961795350556732

Epoch: 5| Step: 10
Training loss: 1.2154762744903564
Validation loss: 1.8940837947271203

Epoch: 246| Step: 0
Training loss: 2.2379109859466553
Validation loss: 1.8885742733555455

Epoch: 5| Step: 1
Training loss: 1.6190030574798584
Validation loss: 1.9110357684473838

Epoch: 5| Step: 2
Training loss: 1.7703168392181396
Validation loss: 1.9140789073000672

Epoch: 5| Step: 3
Training loss: 1.6180362701416016
Validation loss: 1.9202896292491625

Epoch: 5| Step: 4
Training loss: 2.2513906955718994
Validation loss: 1.9334046584303661

Epoch: 5| Step: 5
Training loss: 1.511816143989563
Validation loss: 1.9169722462213168

Epoch: 5| Step: 6
Training loss: 1.934002161026001
Validation loss: 1.9590916454151113

Epoch: 5| Step: 7
Training loss: 1.7097638845443726
Validation loss: 1.8449014002277004

Epoch: 5| Step: 8
Training loss: 1.781751036643982
Validation loss: 1.9028803545941588

Epoch: 5| Step: 9
Training loss: 1.612844705581665
Validation loss: 1.90962206163714

Epoch: 5| Step: 10
Training loss: 1.5183740854263306
Validation loss: 1.9206112802669566

Epoch: 247| Step: 0
Training loss: 2.3807549476623535
Validation loss: 1.8804605750627414

Epoch: 5| Step: 1
Training loss: 2.031095504760742
Validation loss: 1.942815375584428

Epoch: 5| Step: 2
Training loss: 1.574306845664978
Validation loss: 1.9094990940504177

Epoch: 5| Step: 3
Training loss: 1.643723726272583
Validation loss: 1.9135256582690823

Epoch: 5| Step: 4
Training loss: 2.12687349319458
Validation loss: 1.920647176363135

Epoch: 5| Step: 5
Training loss: 2.0315675735473633
Validation loss: 1.952126064608174

Epoch: 5| Step: 6
Training loss: 1.6267173290252686
Validation loss: 1.9055434837136218

Epoch: 5| Step: 7
Training loss: 1.9055793285369873
Validation loss: 1.9360908667246501

Epoch: 5| Step: 8
Training loss: 1.5484817028045654
Validation loss: 1.957727643751329

Epoch: 5| Step: 9
Training loss: 1.4385489225387573
Validation loss: 1.920289119084676

Epoch: 5| Step: 10
Training loss: 1.7322735786437988
Validation loss: 1.9524999895403463

Epoch: 248| Step: 0
Training loss: 1.6511682271957397
Validation loss: 1.877037694377284

Epoch: 5| Step: 1
Training loss: 1.3463175296783447
Validation loss: 1.8923105526995916

Epoch: 5| Step: 2
Training loss: 1.744546890258789
Validation loss: 1.8940448478985858

Epoch: 5| Step: 3
Training loss: 2.0954575538635254
Validation loss: 1.905738797239078

Epoch: 5| Step: 4
Training loss: 1.8272987604141235
Validation loss: 1.93942133713794

Epoch: 5| Step: 5
Training loss: 1.4739210605621338
Validation loss: 1.9389376332682948

Epoch: 5| Step: 6
Training loss: 2.518484115600586
Validation loss: 1.960861265018422

Epoch: 5| Step: 7
Training loss: 1.8826414346694946
Validation loss: 1.906705899905133

Epoch: 5| Step: 8
Training loss: 1.1013444662094116
Validation loss: 1.923501572301311

Epoch: 5| Step: 9
Training loss: 1.851171851158142
Validation loss: 1.9485188402155393

Epoch: 5| Step: 10
Training loss: 2.137329339981079
Validation loss: 1.9171712859984367

Epoch: 249| Step: 0
Training loss: 1.470025897026062
Validation loss: 1.866972505405385

Epoch: 5| Step: 1
Training loss: 1.5543527603149414
Validation loss: 1.8911859091892038

Epoch: 5| Step: 2
Training loss: 2.1302733421325684
Validation loss: 1.9324476257447274

Epoch: 5| Step: 3
Training loss: 1.8938567638397217
Validation loss: 1.8973893657807381

Epoch: 5| Step: 4
Training loss: 1.9731323719024658
Validation loss: 1.9154321570550241

Epoch: 5| Step: 5
Training loss: 1.7038990259170532
Validation loss: 1.883203665415446

Epoch: 5| Step: 6
Training loss: 1.522485375404358
Validation loss: 1.8946024076912993

Epoch: 5| Step: 7
Training loss: 1.9334408044815063
Validation loss: 1.9310620484813568

Epoch: 5| Step: 8
Training loss: 1.3927805423736572
Validation loss: 1.9161961027370986

Epoch: 5| Step: 9
Training loss: 1.8856544494628906
Validation loss: 1.9475330768092987

Epoch: 5| Step: 10
Training loss: 2.0923008918762207
Validation loss: 1.9198807016495736

Epoch: 250| Step: 0
Training loss: 1.2084790468215942
Validation loss: 1.931021495531964

Epoch: 5| Step: 1
Training loss: 2.4779484272003174
Validation loss: 1.8992128667011057

Epoch: 5| Step: 2
Training loss: 1.9096587896347046
Validation loss: 1.9095848170659875

Epoch: 5| Step: 3
Training loss: 1.9765971899032593
Validation loss: 1.865947538806546

Epoch: 5| Step: 4
Training loss: 1.6348060369491577
Validation loss: 1.879030240479336

Epoch: 5| Step: 5
Training loss: 1.5872974395751953
Validation loss: 1.941496012031391

Epoch: 5| Step: 6
Training loss: 1.4274415969848633
Validation loss: 1.9041615788654616

Epoch: 5| Step: 7
Training loss: 1.6512874364852905
Validation loss: 1.8957791751430881

Epoch: 5| Step: 8
Training loss: 2.1378626823425293
Validation loss: 1.955192640263547

Epoch: 5| Step: 9
Training loss: 2.0014491081237793
Validation loss: 1.9166087206973825

Epoch: 5| Step: 10
Training loss: 1.6986831426620483
Validation loss: 1.8998239758194133

Epoch: 251| Step: 0
Training loss: 1.9592621326446533
Validation loss: 1.8810152610143025

Epoch: 5| Step: 1
Training loss: 1.844813346862793
Validation loss: 1.8931238215456727

Epoch: 5| Step: 2
Training loss: 1.3967808485031128
Validation loss: 1.897982543514621

Epoch: 5| Step: 3
Training loss: 1.424910068511963
Validation loss: 1.937635793480822

Epoch: 5| Step: 4
Training loss: 2.0077643394470215
Validation loss: 1.8985809562026814

Epoch: 5| Step: 5
Training loss: 1.4142944812774658
Validation loss: 1.9048222598209177

Epoch: 5| Step: 6
Training loss: 2.7509453296661377
Validation loss: 1.945999260871641

Epoch: 5| Step: 7
Training loss: 2.007016658782959
Validation loss: 1.8827091288822952

Epoch: 5| Step: 8
Training loss: 1.841536521911621
Validation loss: 1.8625823938718407

Epoch: 5| Step: 9
Training loss: 1.7161672115325928
Validation loss: 1.9037125648990754

Epoch: 5| Step: 10
Training loss: 1.2217726707458496
Validation loss: 1.8970842271722772

Epoch: 252| Step: 0
Training loss: 2.082298755645752
Validation loss: 1.9079429680301296

Epoch: 5| Step: 1
Training loss: 1.9519150257110596
Validation loss: 1.909627797783062

Epoch: 5| Step: 2
Training loss: 1.7427431344985962
Validation loss: 1.9079623837624826

Epoch: 5| Step: 3
Training loss: 2.028280735015869
Validation loss: 1.9066398271950342

Epoch: 5| Step: 4
Training loss: 1.9356149435043335
Validation loss: 1.9250545027435466

Epoch: 5| Step: 5
Training loss: 1.7093174457550049
Validation loss: 1.9018743538087415

Epoch: 5| Step: 6
Training loss: 1.32355797290802
Validation loss: 1.9090657849465646

Epoch: 5| Step: 7
Training loss: 1.21270751953125
Validation loss: 1.9164090605192288

Epoch: 5| Step: 8
Training loss: 2.188490390777588
Validation loss: 1.9270727736975557

Epoch: 5| Step: 9
Training loss: 2.3780388832092285
Validation loss: 1.9682676138416413

Epoch: 5| Step: 10
Training loss: 1.2487542629241943
Validation loss: 1.9369892445943688

Epoch: 253| Step: 0
Training loss: 2.7269339561462402
Validation loss: 1.9132793270131594

Epoch: 5| Step: 1
Training loss: 2.2386250495910645
Validation loss: 1.9119325914690573

Epoch: 5| Step: 2
Training loss: 2.064845323562622
Validation loss: 1.8477215305451424

Epoch: 5| Step: 3
Training loss: 1.5404924154281616
Validation loss: 1.9150495054901286

Epoch: 5| Step: 4
Training loss: 1.4835031032562256
Validation loss: 1.919335017922104

Epoch: 5| Step: 5
Training loss: 1.4947834014892578
Validation loss: 1.9165352031748781

Epoch: 5| Step: 6
Training loss: 1.5552338361740112
Validation loss: 1.9157635704163583

Epoch: 5| Step: 7
Training loss: 1.2300535440444946
Validation loss: 1.942125976726573

Epoch: 5| Step: 8
Training loss: 2.213318347930908
Validation loss: 1.909518159845824

Epoch: 5| Step: 9
Training loss: 1.5792137384414673
Validation loss: 1.8852514579731932

Epoch: 5| Step: 10
Training loss: 1.5486618280410767
Validation loss: 1.861983239009816

Epoch: 254| Step: 0
Training loss: 1.5661156177520752
Validation loss: 1.9126002250179168

Epoch: 5| Step: 1
Training loss: 2.1510231494903564
Validation loss: 1.9453862072319112

Epoch: 5| Step: 2
Training loss: 1.1457327604293823
Validation loss: 1.9168931438076882

Epoch: 5| Step: 3
Training loss: 1.3532209396362305
Validation loss: 1.8836492799943494

Epoch: 5| Step: 4
Training loss: 1.4411163330078125
Validation loss: 1.9099199348880398

Epoch: 5| Step: 5
Training loss: 1.831547498703003
Validation loss: 1.903548377816395

Epoch: 5| Step: 6
Training loss: 2.0101478099823
Validation loss: 1.9205657102728402

Epoch: 5| Step: 7
Training loss: 1.7387259006500244
Validation loss: 1.899195586481402

Epoch: 5| Step: 8
Training loss: 1.8762843608856201
Validation loss: 1.867755102854903

Epoch: 5| Step: 9
Training loss: 1.9664283990859985
Validation loss: 1.9559135334466093

Epoch: 5| Step: 10
Training loss: 2.5192854404449463
Validation loss: 1.8854436579570975

Epoch: 255| Step: 0
Training loss: 1.5579389333724976
Validation loss: 1.9171307112580986

Epoch: 5| Step: 1
Training loss: 1.2013301849365234
Validation loss: 1.9258593243937339

Epoch: 5| Step: 2
Training loss: 1.8935699462890625
Validation loss: 1.8974948929202171

Epoch: 5| Step: 3
Training loss: 1.876866340637207
Validation loss: 1.9330474138259888

Epoch: 5| Step: 4
Training loss: 1.6732351779937744
Validation loss: 1.896887622853761

Epoch: 5| Step: 5
Training loss: 1.802638292312622
Validation loss: 1.990656724540136

Epoch: 5| Step: 6
Training loss: 1.7195136547088623
Validation loss: 1.9227673507505847

Epoch: 5| Step: 7
Training loss: 1.685455322265625
Validation loss: 1.9060134253194254

Epoch: 5| Step: 8
Training loss: 2.1855628490448
Validation loss: 1.9582008366943688

Epoch: 5| Step: 9
Training loss: 1.7136571407318115
Validation loss: 1.8981660950568415

Epoch: 5| Step: 10
Training loss: 2.1727488040924072
Validation loss: 1.9225237407991964

Epoch: 256| Step: 0
Training loss: 1.9440513849258423
Validation loss: 1.9061413054825158

Epoch: 5| Step: 1
Training loss: 1.6419918537139893
Validation loss: 1.8997567417801067

Epoch: 5| Step: 2
Training loss: 1.932172179222107
Validation loss: 1.9310838060994302

Epoch: 5| Step: 3
Training loss: 1.865230917930603
Validation loss: 1.9232604798450266

Epoch: 5| Step: 4
Training loss: 1.6959877014160156
Validation loss: 1.9796109532797208

Epoch: 5| Step: 5
Training loss: 1.6915079355239868
Validation loss: 1.90230300605938

Epoch: 5| Step: 6
Training loss: 1.8375030755996704
Validation loss: 1.9255006467142413

Epoch: 5| Step: 7
Training loss: 1.843062162399292
Validation loss: 1.9234077392085906

Epoch: 5| Step: 8
Training loss: 1.557265043258667
Validation loss: 1.9391360180352324

Epoch: 5| Step: 9
Training loss: 2.023310899734497
Validation loss: 1.9363177348208684

Epoch: 5| Step: 10
Training loss: 1.4089030027389526
Validation loss: 1.9036783659329979

Epoch: 257| Step: 0
Training loss: 1.3616042137145996
Validation loss: 1.9210687914202291

Epoch: 5| Step: 1
Training loss: 1.8215526342391968
Validation loss: 1.8988419066193283

Epoch: 5| Step: 2
Training loss: 1.622194528579712
Validation loss: 1.9285073972517444

Epoch: 5| Step: 3
Training loss: 1.8737976551055908
Validation loss: 1.9246335734603226

Epoch: 5| Step: 4
Training loss: 2.208658218383789
Validation loss: 1.9108370606617262

Epoch: 5| Step: 5
Training loss: 2.2379517555236816
Validation loss: 1.8681413358257664

Epoch: 5| Step: 6
Training loss: 1.5675832033157349
Validation loss: 1.8853482994981992

Epoch: 5| Step: 7
Training loss: 1.8131967782974243
Validation loss: 1.9331286799523137

Epoch: 5| Step: 8
Training loss: 1.7124744653701782
Validation loss: 1.8956615591561923

Epoch: 5| Step: 9
Training loss: 1.9673112630844116
Validation loss: 1.866922168321507

Epoch: 5| Step: 10
Training loss: 1.365382194519043
Validation loss: 1.9562044784586916

Epoch: 258| Step: 0
Training loss: 1.4745644330978394
Validation loss: 1.8672636772996636

Epoch: 5| Step: 1
Training loss: 1.8382530212402344
Validation loss: 1.8951559156499884

Epoch: 5| Step: 2
Training loss: 2.046363353729248
Validation loss: 1.8836607715134979

Epoch: 5| Step: 3
Training loss: 2.267477035522461
Validation loss: 1.8848858546185236

Epoch: 5| Step: 4
Training loss: 1.243874192237854
Validation loss: 1.8782021819904287

Epoch: 5| Step: 5
Training loss: 1.9062808752059937
Validation loss: 1.9107434198420534

Epoch: 5| Step: 6
Training loss: 2.0436947345733643
Validation loss: 1.89154980644103

Epoch: 5| Step: 7
Training loss: 1.8719661235809326
Validation loss: 1.9058331597235896

Epoch: 5| Step: 8
Training loss: 1.518367052078247
Validation loss: 1.8724535408840384

Epoch: 5| Step: 9
Training loss: 1.5420540571212769
Validation loss: 1.8951518740705264

Epoch: 5| Step: 10
Training loss: 1.5739961862564087
Validation loss: 1.848747553363923

Epoch: 259| Step: 0
Training loss: 1.7617571353912354
Validation loss: 1.8994284675967308

Epoch: 5| Step: 1
Training loss: 1.5640448331832886
Validation loss: 1.8977942159098964

Epoch: 5| Step: 2
Training loss: 1.6680071353912354
Validation loss: 1.9248000755104968

Epoch: 5| Step: 3
Training loss: 2.4320273399353027
Validation loss: 1.86760103061635

Epoch: 5| Step: 4
Training loss: 1.7304966449737549
Validation loss: 1.9053005761997674

Epoch: 5| Step: 5
Training loss: 1.3652708530426025
Validation loss: 1.8461034246670303

Epoch: 5| Step: 6
Training loss: 1.9799878597259521
Validation loss: 1.8981965011165989

Epoch: 5| Step: 7
Training loss: 0.9537251591682434
Validation loss: 1.8996457874134023

Epoch: 5| Step: 8
Training loss: 1.795248031616211
Validation loss: 1.8996533014441048

Epoch: 5| Step: 9
Training loss: 2.231902599334717
Validation loss: 1.928341152847454

Epoch: 5| Step: 10
Training loss: 2.042651653289795
Validation loss: 1.8853127892299364

Epoch: 260| Step: 0
Training loss: 1.7342151403427124
Validation loss: 1.8919179952272804

Epoch: 5| Step: 1
Training loss: 2.2659804821014404
Validation loss: 1.8733002075584986

Epoch: 5| Step: 2
Training loss: 1.5184201002120972
Validation loss: 1.8884212829733407

Epoch: 5| Step: 3
Training loss: 1.4931074380874634
Validation loss: 1.952405139964114

Epoch: 5| Step: 4
Training loss: 1.533464789390564
Validation loss: 1.8904160376518004

Epoch: 5| Step: 5
Training loss: 1.5369750261306763
Validation loss: 1.9009907271272393

Epoch: 5| Step: 6
Training loss: 1.0543047189712524
Validation loss: 1.9221206557366155

Epoch: 5| Step: 7
Training loss: 2.264416217803955
Validation loss: 1.8416750341333368

Epoch: 5| Step: 8
Training loss: 1.7385412454605103
Validation loss: 1.8590841998336136

Epoch: 5| Step: 9
Training loss: 2.2505130767822266
Validation loss: 1.8698346948110929

Epoch: 5| Step: 10
Training loss: 2.1612823009490967
Validation loss: 1.8631727810828917

Epoch: 261| Step: 0
Training loss: 1.8599010705947876
Validation loss: 1.9402831408285326

Epoch: 5| Step: 1
Training loss: 1.6034303903579712
Validation loss: 1.8890352761873634

Epoch: 5| Step: 2
Training loss: 1.5964019298553467
Validation loss: 1.9315759315285632

Epoch: 5| Step: 3
Training loss: 1.6251996755599976
Validation loss: 1.879620361071761

Epoch: 5| Step: 4
Training loss: 1.6149694919586182
Validation loss: 1.9455393783507808

Epoch: 5| Step: 5
Training loss: 1.4803431034088135
Validation loss: 1.849134172162702

Epoch: 5| Step: 6
Training loss: 1.6669590473175049
Validation loss: 1.8758073737544398

Epoch: 5| Step: 7
Training loss: 2.327209949493408
Validation loss: 1.8716318940603605

Epoch: 5| Step: 8
Training loss: 2.26865553855896
Validation loss: 1.927151612056199

Epoch: 5| Step: 9
Training loss: 1.4591926336288452
Validation loss: 1.8785173726338211

Epoch: 5| Step: 10
Training loss: 2.182589530944824
Validation loss: 1.871098478635152

Epoch: 262| Step: 0
Training loss: 1.7179158926010132
Validation loss: 1.8537146840044247

Epoch: 5| Step: 1
Training loss: 1.6128511428833008
Validation loss: 1.9356258966589486

Epoch: 5| Step: 2
Training loss: 1.9206085205078125
Validation loss: 1.8939966976001699

Epoch: 5| Step: 3
Training loss: 1.6234142780303955
Validation loss: 1.928873417198017

Epoch: 5| Step: 4
Training loss: 1.853333830833435
Validation loss: 1.932864946703757

Epoch: 5| Step: 5
Training loss: 1.3637006282806396
Validation loss: 1.885207950427968

Epoch: 5| Step: 6
Training loss: 1.6647402048110962
Validation loss: 1.9149525421921925

Epoch: 5| Step: 7
Training loss: 1.5409808158874512
Validation loss: 1.895212455462384

Epoch: 5| Step: 8
Training loss: 2.2426390647888184
Validation loss: 1.9692484947942919

Epoch: 5| Step: 9
Training loss: 1.9880176782608032
Validation loss: 1.8775679065335182

Epoch: 5| Step: 10
Training loss: 1.9465054273605347
Validation loss: 1.9064205872115267

Epoch: 263| Step: 0
Training loss: 2.0099596977233887
Validation loss: 1.9041805831334924

Epoch: 5| Step: 1
Training loss: 1.980352759361267
Validation loss: 1.9024185749792284

Epoch: 5| Step: 2
Training loss: 1.2723681926727295
Validation loss: 1.8437051465434413

Epoch: 5| Step: 3
Training loss: 2.0536162853240967
Validation loss: 1.955822463958494

Epoch: 5| Step: 4
Training loss: 1.5407474040985107
Validation loss: 1.9202267431443738

Epoch: 5| Step: 5
Training loss: 1.7211319208145142
Validation loss: 1.9259482250418714

Epoch: 5| Step: 6
Training loss: 2.2122387886047363
Validation loss: 1.9455659774041945

Epoch: 5| Step: 7
Training loss: 1.589744210243225
Validation loss: 1.911929827864452

Epoch: 5| Step: 8
Training loss: 1.5112826824188232
Validation loss: 1.8872972688367289

Epoch: 5| Step: 9
Training loss: 1.7428882122039795
Validation loss: 1.8740400768095447

Epoch: 5| Step: 10
Training loss: 1.7926653623580933
Validation loss: 1.884322033133558

Epoch: 264| Step: 0
Training loss: 1.5878740549087524
Validation loss: 1.900612905461301

Epoch: 5| Step: 1
Training loss: 1.4894336462020874
Validation loss: 1.8885884156791113

Epoch: 5| Step: 2
Training loss: 1.467349886894226
Validation loss: 1.9069717007298623

Epoch: 5| Step: 3
Training loss: 1.4752051830291748
Validation loss: 1.8923788852589105

Epoch: 5| Step: 4
Training loss: 2.1631081104278564
Validation loss: 1.9116394314714658

Epoch: 5| Step: 5
Training loss: 1.5999399423599243
Validation loss: 1.8527552338056668

Epoch: 5| Step: 6
Training loss: 1.5516788959503174
Validation loss: 1.9296667281017508

Epoch: 5| Step: 7
Training loss: 2.059608221054077
Validation loss: 1.8894044365934146

Epoch: 5| Step: 8
Training loss: 1.7258504629135132
Validation loss: 1.90455029344046

Epoch: 5| Step: 9
Training loss: 1.6017614603042603
Validation loss: 1.8840009115075553

Epoch: 5| Step: 10
Training loss: 2.458679676055908
Validation loss: 1.9234170183058708

Epoch: 265| Step: 0
Training loss: 1.314094066619873
Validation loss: 1.8959469949045489

Epoch: 5| Step: 1
Training loss: 1.6766811609268188
Validation loss: 1.8635021871136082

Epoch: 5| Step: 2
Training loss: 1.4957354068756104
Validation loss: 1.9279566682795042

Epoch: 5| Step: 3
Training loss: 2.2856202125549316
Validation loss: 1.8646860199589883

Epoch: 5| Step: 4
Training loss: 2.177485227584839
Validation loss: 1.9444907378124934

Epoch: 5| Step: 5
Training loss: 1.7055549621582031
Validation loss: 1.8769715960307787

Epoch: 5| Step: 6
Training loss: 1.737229585647583
Validation loss: 1.8969902248792752

Epoch: 5| Step: 7
Training loss: 1.6439183950424194
Validation loss: 1.8882588596754177

Epoch: 5| Step: 8
Training loss: 1.7145092487335205
Validation loss: 1.8745634889089933

Epoch: 5| Step: 9
Training loss: 1.7896209955215454
Validation loss: 1.9353517383657477

Epoch: 5| Step: 10
Training loss: 1.7384958267211914
Validation loss: 1.9175607414655789

Epoch: 266| Step: 0
Training loss: 1.7593944072723389
Validation loss: 1.9113170895525204

Epoch: 5| Step: 1
Training loss: 1.5469125509262085
Validation loss: 1.925445714304524

Epoch: 5| Step: 2
Training loss: 2.323272228240967
Validation loss: 1.9378012803293043

Epoch: 5| Step: 3
Training loss: 1.9073383808135986
Validation loss: 1.908327119324797

Epoch: 5| Step: 4
Training loss: 1.212943196296692
Validation loss: 1.8727437655131023

Epoch: 5| Step: 5
Training loss: 1.5022977590560913
Validation loss: 1.9586883219339515

Epoch: 5| Step: 6
Training loss: 1.7039234638214111
Validation loss: 1.893703519657094

Epoch: 5| Step: 7
Training loss: 1.7336928844451904
Validation loss: 1.9145649915100427

Epoch: 5| Step: 8
Training loss: 2.3503246307373047
Validation loss: 1.95700115542258

Epoch: 5| Step: 9
Training loss: 1.8018100261688232
Validation loss: 1.8495812800622755

Epoch: 5| Step: 10
Training loss: 1.6418811082839966
Validation loss: 1.8901435611068562

Epoch: 267| Step: 0
Training loss: 1.5963854789733887
Validation loss: 1.8738117525654454

Epoch: 5| Step: 1
Training loss: 1.1314560174942017
Validation loss: 1.8739930442584458

Epoch: 5| Step: 2
Training loss: 2.0455470085144043
Validation loss: 1.8670593692410378

Epoch: 5| Step: 3
Training loss: 1.6439259052276611
Validation loss: 1.9602482780333488

Epoch: 5| Step: 4
Training loss: 1.970580816268921
Validation loss: 1.8107244917141494

Epoch: 5| Step: 5
Training loss: 1.7595516443252563
Validation loss: 1.925691596923336

Epoch: 5| Step: 6
Training loss: 1.7055978775024414
Validation loss: 1.8843666507351784

Epoch: 5| Step: 7
Training loss: 1.0227453708648682
Validation loss: 1.8782285874889744

Epoch: 5| Step: 8
Training loss: 1.593371033668518
Validation loss: 1.8832235874668244

Epoch: 5| Step: 9
Training loss: 2.5793347358703613
Validation loss: 1.8643755246234197

Epoch: 5| Step: 10
Training loss: 2.0236189365386963
Validation loss: 1.8385425024135138

Epoch: 268| Step: 0
Training loss: 2.0637388229370117
Validation loss: 1.837929174464236

Epoch: 5| Step: 1
Training loss: 1.88520085811615
Validation loss: 1.8783224603181243

Epoch: 5| Step: 2
Training loss: 1.7440910339355469
Validation loss: 1.871450790794947

Epoch: 5| Step: 3
Training loss: 1.6926367282867432
Validation loss: 1.8785140270827918

Epoch: 5| Step: 4
Training loss: 1.7203556299209595
Validation loss: 1.9002014565211471

Epoch: 5| Step: 5
Training loss: 1.5663723945617676
Validation loss: 1.8919568113101426

Epoch: 5| Step: 6
Training loss: 2.042302131652832
Validation loss: 1.9074219426801127

Epoch: 5| Step: 7
Training loss: 1.8939573764801025
Validation loss: 1.904141044103971

Epoch: 5| Step: 8
Training loss: 1.6224342584609985
Validation loss: 1.8889632558309903

Epoch: 5| Step: 9
Training loss: 1.5406317710876465
Validation loss: 1.8886840804930656

Epoch: 5| Step: 10
Training loss: 1.1818560361862183
Validation loss: 1.9227922155011086

Epoch: 269| Step: 0
Training loss: 1.571280837059021
Validation loss: 1.834824792800411

Epoch: 5| Step: 1
Training loss: 1.5809528827667236
Validation loss: 1.8863915064001595

Epoch: 5| Step: 2
Training loss: 1.602010726928711
Validation loss: 1.8759715300734325

Epoch: 5| Step: 3
Training loss: 1.8826383352279663
Validation loss: 1.9243864782394902

Epoch: 5| Step: 4
Training loss: 1.6695327758789062
Validation loss: 1.8842713076581237

Epoch: 5| Step: 5
Training loss: 1.7411391735076904
Validation loss: 1.8916945944550216

Epoch: 5| Step: 6
Training loss: 1.9835602045059204
Validation loss: 1.8536473243467269

Epoch: 5| Step: 7
Training loss: 2.2827796936035156
Validation loss: 1.8610892706019904

Epoch: 5| Step: 8
Training loss: 1.8738594055175781
Validation loss: 1.9060801241987495

Epoch: 5| Step: 9
Training loss: 1.3160916566848755
Validation loss: 1.852109871884828

Epoch: 5| Step: 10
Training loss: 1.4528322219848633
Validation loss: 1.8709192224728164

Epoch: 270| Step: 0
Training loss: 1.2772176265716553
Validation loss: 1.8737610527264175

Epoch: 5| Step: 1
Training loss: 1.756134033203125
Validation loss: 1.8446971319055046

Epoch: 5| Step: 2
Training loss: 1.7733932733535767
Validation loss: 1.8729299088960052

Epoch: 5| Step: 3
Training loss: 1.9586150646209717
Validation loss: 1.9233392848763415

Epoch: 5| Step: 4
Training loss: 1.7824699878692627
Validation loss: 1.9380510904455697

Epoch: 5| Step: 5
Training loss: 1.144763708114624
Validation loss: 1.8882725520800518

Epoch: 5| Step: 6
Training loss: 1.6315265893936157
Validation loss: 1.9055898227999288

Epoch: 5| Step: 7
Training loss: 1.9984114170074463
Validation loss: 1.9447615890092746

Epoch: 5| Step: 8
Training loss: 1.81792414188385
Validation loss: 1.92406544762273

Epoch: 5| Step: 9
Training loss: 1.795708417892456
Validation loss: 1.9063481489817302

Epoch: 5| Step: 10
Training loss: 2.0932488441467285
Validation loss: 1.8555212277238087

Epoch: 271| Step: 0
Training loss: 2.0331292152404785
Validation loss: 1.9132824123546641

Epoch: 5| Step: 1
Training loss: 1.5730782747268677
Validation loss: 1.928419554105369

Epoch: 5| Step: 2
Training loss: 1.9550052881240845
Validation loss: 1.8842504255233272

Epoch: 5| Step: 3
Training loss: 1.953348159790039
Validation loss: 1.894542319800264

Epoch: 5| Step: 4
Training loss: 1.7339198589324951
Validation loss: 1.9309530386360743

Epoch: 5| Step: 5
Training loss: 1.855452299118042
Validation loss: 1.8479983716882684

Epoch: 5| Step: 6
Training loss: 1.6904869079589844
Validation loss: 1.8760607255402433

Epoch: 5| Step: 7
Training loss: 1.491834044456482
Validation loss: 1.9025932896521784

Epoch: 5| Step: 8
Training loss: 1.6829172372817993
Validation loss: 1.8497739504742365

Epoch: 5| Step: 9
Training loss: 1.1392138004302979
Validation loss: 1.8994699357658305

Epoch: 5| Step: 10
Training loss: 1.527732253074646
Validation loss: 1.891784519277593

Epoch: 272| Step: 0
Training loss: 1.536116361618042
Validation loss: 1.90939595237855

Epoch: 5| Step: 1
Training loss: 1.5868513584136963
Validation loss: 1.8911118545839865

Epoch: 5| Step: 2
Training loss: 0.9028427004814148
Validation loss: 1.8661914640857327

Epoch: 5| Step: 3
Training loss: 2.2783772945404053
Validation loss: 1.878174469035159

Epoch: 5| Step: 4
Training loss: 1.4767519235610962
Validation loss: 1.8806955416997273

Epoch: 5| Step: 5
Training loss: 1.7574684619903564
Validation loss: 1.9047809916157876

Epoch: 5| Step: 6
Training loss: 1.7996231317520142
Validation loss: 1.8755656724335046

Epoch: 5| Step: 7
Training loss: 2.7615137100219727
Validation loss: 1.8814773072478592

Epoch: 5| Step: 8
Training loss: 1.3023741245269775
Validation loss: 1.9263416336428734

Epoch: 5| Step: 9
Training loss: 1.325268030166626
Validation loss: 1.8442721623246388

Epoch: 5| Step: 10
Training loss: 1.7559430599212646
Validation loss: 1.8779952000546198

Epoch: 273| Step: 0
Training loss: 1.4398932456970215
Validation loss: 1.8327980477322814

Epoch: 5| Step: 1
Training loss: 1.4569774866104126
Validation loss: 1.909320367279873

Epoch: 5| Step: 2
Training loss: 1.9297285079956055
Validation loss: 1.831584056218465

Epoch: 5| Step: 3
Training loss: 1.8364585638046265
Validation loss: 1.855971888829303

Epoch: 5| Step: 4
Training loss: 1.70211660861969
Validation loss: 1.8455920809058732

Epoch: 5| Step: 5
Training loss: 1.3721038103103638
Validation loss: 1.870628309506242

Epoch: 5| Step: 6
Training loss: 1.56174635887146
Validation loss: 1.8975772421847108

Epoch: 5| Step: 7
Training loss: 1.5536943674087524
Validation loss: 1.918451693750197

Epoch: 5| Step: 8
Training loss: 1.884490728378296
Validation loss: 1.9352723488243677

Epoch: 5| Step: 9
Training loss: 1.9162458181381226
Validation loss: 1.9491009789128457

Epoch: 5| Step: 10
Training loss: 2.3305094242095947
Validation loss: 1.9192460916375602

Epoch: 274| Step: 0
Training loss: 1.425179362297058
Validation loss: 1.912731450091126

Epoch: 5| Step: 1
Training loss: 1.3894822597503662
Validation loss: 1.9395225778702767

Epoch: 5| Step: 2
Training loss: 1.4906924962997437
Validation loss: 1.9622556445419148

Epoch: 5| Step: 3
Training loss: 2.0125575065612793
Validation loss: 1.8991181158250379

Epoch: 5| Step: 4
Training loss: 1.8062292337417603
Validation loss: 1.929931345806327

Epoch: 5| Step: 5
Training loss: 1.816415548324585
Validation loss: 1.8855924349959179

Epoch: 5| Step: 6
Training loss: 1.097198247909546
Validation loss: 1.856141233956942

Epoch: 5| Step: 7
Training loss: 1.9052232503890991
Validation loss: 1.919683143656741

Epoch: 5| Step: 8
Training loss: 2.5427639484405518
Validation loss: 1.864062827120545

Epoch: 5| Step: 9
Training loss: 1.7761268615722656
Validation loss: 1.8684882720311482

Epoch: 5| Step: 10
Training loss: 1.944371223449707
Validation loss: 1.8645534592290078

Epoch: 275| Step: 0
Training loss: 2.0656440258026123
Validation loss: 1.8895968032139603

Epoch: 5| Step: 1
Training loss: 1.1740607023239136
Validation loss: 1.8641881186475036

Epoch: 5| Step: 2
Training loss: 1.5850006341934204
Validation loss: 1.8936655841847903

Epoch: 5| Step: 3
Training loss: 1.9742071628570557
Validation loss: 1.894684596728253

Epoch: 5| Step: 4
Training loss: 1.6592910289764404
Validation loss: 1.8799062672481741

Epoch: 5| Step: 5
Training loss: 1.966611623764038
Validation loss: 1.9579877443211053

Epoch: 5| Step: 6
Training loss: 1.863612174987793
Validation loss: 1.9125904601107362

Epoch: 5| Step: 7
Training loss: 1.7316089868545532
Validation loss: 1.8626566779228948

Epoch: 5| Step: 8
Training loss: 1.5159529447555542
Validation loss: 1.9477699597676594

Epoch: 5| Step: 9
Training loss: 1.8926118612289429
Validation loss: 1.9035257754787323

Epoch: 5| Step: 10
Training loss: 1.8073222637176514
Validation loss: 1.8844972272073068

Epoch: 276| Step: 0
Training loss: 1.3347268104553223
Validation loss: 1.8618955355818554

Epoch: 5| Step: 1
Training loss: 1.3393592834472656
Validation loss: 1.903334499687277

Epoch: 5| Step: 2
Training loss: 2.006803512573242
Validation loss: 1.8832074032034924

Epoch: 5| Step: 3
Training loss: 2.045361280441284
Validation loss: 1.8838356617958314

Epoch: 5| Step: 4
Training loss: 1.436011552810669
Validation loss: 1.8868570404668008

Epoch: 5| Step: 5
Training loss: 1.6866458654403687
Validation loss: 1.889810513424617

Epoch: 5| Step: 6
Training loss: 1.3549842834472656
Validation loss: 1.8831266831326228

Epoch: 5| Step: 7
Training loss: 1.4752699136734009
Validation loss: 1.8663328257940148

Epoch: 5| Step: 8
Training loss: 1.5994418859481812
Validation loss: 1.853323672407417

Epoch: 5| Step: 9
Training loss: 2.3789241313934326
Validation loss: 1.898239476706392

Epoch: 5| Step: 10
Training loss: 2.2296698093414307
Validation loss: 1.9057111483748241

Epoch: 277| Step: 0
Training loss: 1.8683608770370483
Validation loss: 1.915164424527076

Epoch: 5| Step: 1
Training loss: 1.9893372058868408
Validation loss: 1.9081905887972923

Epoch: 5| Step: 2
Training loss: 1.873250961303711
Validation loss: 1.8381644897563483

Epoch: 5| Step: 3
Training loss: 1.5894749164581299
Validation loss: 1.8560136389988724

Epoch: 5| Step: 4
Training loss: 1.5432721376419067
Validation loss: 1.826507617068547

Epoch: 5| Step: 5
Training loss: 1.5912330150604248
Validation loss: 1.846452989885884

Epoch: 5| Step: 6
Training loss: 2.0921921730041504
Validation loss: 1.8859717051188152

Epoch: 5| Step: 7
Training loss: 1.189733862876892
Validation loss: 1.9090453476034186

Epoch: 5| Step: 8
Training loss: 1.8603334426879883
Validation loss: 1.8668565724485664

Epoch: 5| Step: 9
Training loss: 1.6584322452545166
Validation loss: 1.8861243148003854

Epoch: 5| Step: 10
Training loss: 1.4690933227539062
Validation loss: 1.8993245119689612

Epoch: 278| Step: 0
Training loss: 1.4265964031219482
Validation loss: 1.9078048262544858

Epoch: 5| Step: 1
Training loss: 1.7086677551269531
Validation loss: 1.8762014476201867

Epoch: 5| Step: 2
Training loss: 1.7602545022964478
Validation loss: 1.916471201886413

Epoch: 5| Step: 3
Training loss: 1.6206344366073608
Validation loss: 1.881942218349826

Epoch: 5| Step: 4
Training loss: 1.555829405784607
Validation loss: 1.8885546550955823

Epoch: 5| Step: 5
Training loss: 1.8180240392684937
Validation loss: 1.8613484521065988

Epoch: 5| Step: 6
Training loss: 2.05243182182312
Validation loss: 1.870654672704717

Epoch: 5| Step: 7
Training loss: 2.3577094078063965
Validation loss: 1.9001982583794543

Epoch: 5| Step: 8
Training loss: 1.6967840194702148
Validation loss: 1.8646167837163454

Epoch: 5| Step: 9
Training loss: 1.630889654159546
Validation loss: 1.8520008338394987

Epoch: 5| Step: 10
Training loss: 1.1290942430496216
Validation loss: 1.9436693537619807

Epoch: 279| Step: 0
Training loss: 1.472658395767212
Validation loss: 1.865142850465672

Epoch: 5| Step: 1
Training loss: 1.961756706237793
Validation loss: 1.8807956839120517

Epoch: 5| Step: 2
Training loss: 1.9648075103759766
Validation loss: 1.8634858362136348

Epoch: 5| Step: 3
Training loss: 1.2132771015167236
Validation loss: 1.8928547982246644

Epoch: 5| Step: 4
Training loss: 1.8960462808609009
Validation loss: 1.9116000065239527

Epoch: 5| Step: 5
Training loss: 1.8584734201431274
Validation loss: 1.8803965840288388

Epoch: 5| Step: 6
Training loss: 1.2942564487457275
Validation loss: 1.9059860578147314

Epoch: 5| Step: 7
Training loss: 1.0940974950790405
Validation loss: 1.887526963346748

Epoch: 5| Step: 8
Training loss: 1.6495510339736938
Validation loss: 1.867160863773797

Epoch: 5| Step: 9
Training loss: 2.1630337238311768
Validation loss: 1.9269627319869174

Epoch: 5| Step: 10
Training loss: 2.1628072261810303
Validation loss: 1.8750237957123788

Epoch: 280| Step: 0
Training loss: 1.8965365886688232
Validation loss: 1.8757695369823004

Epoch: 5| Step: 1
Training loss: 1.6010808944702148
Validation loss: 1.936223050599457

Epoch: 5| Step: 2
Training loss: 1.506425380706787
Validation loss: 1.8723411829240861

Epoch: 5| Step: 3
Training loss: 1.5122443437576294
Validation loss: 1.887859639301095

Epoch: 5| Step: 4
Training loss: 1.7635962963104248
Validation loss: 1.8909371347837551

Epoch: 5| Step: 5
Training loss: 2.215122699737549
Validation loss: 1.926198273576716

Epoch: 5| Step: 6
Training loss: 1.4682655334472656
Validation loss: 1.8886978856978878

Epoch: 5| Step: 7
Training loss: 1.3044843673706055
Validation loss: 1.901879769499584

Epoch: 5| Step: 8
Training loss: 1.8090641498565674
Validation loss: 1.9041762749354045

Epoch: 5| Step: 9
Training loss: 2.275581121444702
Validation loss: 1.8455991488631054

Epoch: 5| Step: 10
Training loss: 1.5313010215759277
Validation loss: 1.8681253951082948

Epoch: 281| Step: 0
Training loss: 2.0358173847198486
Validation loss: 1.8468582091792938

Epoch: 5| Step: 1
Training loss: 1.5448572635650635
Validation loss: 1.873798261406601

Epoch: 5| Step: 2
Training loss: 1.537355661392212
Validation loss: 1.914046795137467

Epoch: 5| Step: 3
Training loss: 2.0306990146636963
Validation loss: 1.963520533295088

Epoch: 5| Step: 4
Training loss: 1.561444878578186
Validation loss: 1.8910608035261913

Epoch: 5| Step: 5
Training loss: 1.3592860698699951
Validation loss: 1.9264416015276344

Epoch: 5| Step: 6
Training loss: 1.2755558490753174
Validation loss: 1.8697505215162873

Epoch: 5| Step: 7
Training loss: 2.021024703979492
Validation loss: 1.8954424473547167

Epoch: 5| Step: 8
Training loss: 2.27119779586792
Validation loss: 1.8847054845543318

Epoch: 5| Step: 9
Training loss: 1.5003560781478882
Validation loss: 1.9275270200544787

Epoch: 5| Step: 10
Training loss: 1.5859229564666748
Validation loss: 1.8858217885417323

Epoch: 282| Step: 0
Training loss: 1.2619826793670654
Validation loss: 1.8617861604177823

Epoch: 5| Step: 1
Training loss: 1.5942051410675049
Validation loss: 1.861129629996515

Epoch: 5| Step: 2
Training loss: 1.8758796453475952
Validation loss: 1.8532305558522542

Epoch: 5| Step: 3
Training loss: 1.5809695720672607
Validation loss: 1.8667819423060263

Epoch: 5| Step: 4
Training loss: 1.6892839670181274
Validation loss: 1.8420611799404185

Epoch: 5| Step: 5
Training loss: 1.952214002609253
Validation loss: 1.8775646840372393

Epoch: 5| Step: 6
Training loss: 1.9821202754974365
Validation loss: 1.8525897533662858

Epoch: 5| Step: 7
Training loss: 1.9287109375
Validation loss: 1.8922165927066599

Epoch: 5| Step: 8
Training loss: 1.1649765968322754
Validation loss: 1.839599145356045

Epoch: 5| Step: 9
Training loss: 1.5945651531219482
Validation loss: 1.8800167293958767

Epoch: 5| Step: 10
Training loss: 2.015901803970337
Validation loss: 1.8472177802875478

Epoch: 283| Step: 0
Training loss: 1.5189366340637207
Validation loss: 1.872337697654642

Epoch: 5| Step: 1
Training loss: 1.2407556772232056
Validation loss: 1.9006808239926574

Epoch: 5| Step: 2
Training loss: 1.830291986465454
Validation loss: 1.9078337274571902

Epoch: 5| Step: 3
Training loss: 1.401288628578186
Validation loss: 1.8939285098865468

Epoch: 5| Step: 4
Training loss: 1.6256892681121826
Validation loss: 1.8807323132791827

Epoch: 5| Step: 5
Training loss: 2.16607928276062
Validation loss: 1.891241378681634

Epoch: 5| Step: 6
Training loss: 2.183135509490967
Validation loss: 1.9224750136816373

Epoch: 5| Step: 7
Training loss: 1.4959588050842285
Validation loss: 1.8620936537301669

Epoch: 5| Step: 8
Training loss: 1.8855499029159546
Validation loss: 1.9264919988570675

Epoch: 5| Step: 9
Training loss: 1.76864755153656
Validation loss: 1.8703412522551834

Epoch: 5| Step: 10
Training loss: 1.6315815448760986
Validation loss: 1.8684051216289561

Epoch: 284| Step: 0
Training loss: 1.6592918634414673
Validation loss: 1.889128485033589

Epoch: 5| Step: 1
Training loss: 1.9748814105987549
Validation loss: 1.8547047517632926

Epoch: 5| Step: 2
Training loss: 1.4118000268936157
Validation loss: 1.8831526258940339

Epoch: 5| Step: 3
Training loss: 1.8089908361434937
Validation loss: 1.8563103227205173

Epoch: 5| Step: 4
Training loss: 2.383500576019287
Validation loss: 1.8524179996982697

Epoch: 5| Step: 5
Training loss: 1.3119218349456787
Validation loss: 1.8106670238638436

Epoch: 5| Step: 6
Training loss: 1.5090093612670898
Validation loss: 1.8567547977611583

Epoch: 5| Step: 7
Training loss: 1.369121789932251
Validation loss: 1.8245564365899691

Epoch: 5| Step: 8
Training loss: 1.8796355724334717
Validation loss: 1.859903786772041

Epoch: 5| Step: 9
Training loss: 1.7238237857818604
Validation loss: 1.892982793110673

Epoch: 5| Step: 10
Training loss: 1.4753893613815308
Validation loss: 1.8229669986232635

Epoch: 285| Step: 0
Training loss: 2.3419196605682373
Validation loss: 1.8270407184477775

Epoch: 5| Step: 1
Training loss: 1.700129747390747
Validation loss: 1.90360685061383

Epoch: 5| Step: 2
Training loss: 2.0887866020202637
Validation loss: 1.8712671649071477

Epoch: 5| Step: 3
Training loss: 1.9146474599838257
Validation loss: 1.8560549264313073

Epoch: 5| Step: 4
Training loss: 1.5984680652618408
Validation loss: 1.8937015341174217

Epoch: 5| Step: 5
Training loss: 1.8375428915023804
Validation loss: 1.9026454238481418

Epoch: 5| Step: 6
Training loss: 1.6653759479522705
Validation loss: 1.8490416285812215

Epoch: 5| Step: 7
Training loss: 1.4367424249649048
Validation loss: 1.8416542827442128

Epoch: 5| Step: 8
Training loss: 1.1428301334381104
Validation loss: 1.909964051297916

Epoch: 5| Step: 9
Training loss: 1.5835378170013428
Validation loss: 1.8547189299778273

Epoch: 5| Step: 10
Training loss: 1.3902846574783325
Validation loss: 1.8059864044189453

Epoch: 286| Step: 0
Training loss: 1.3581992387771606
Validation loss: 1.8346707743983115

Epoch: 5| Step: 1
Training loss: 2.1687119007110596
Validation loss: 1.8184550513503372

Epoch: 5| Step: 2
Training loss: 2.245668411254883
Validation loss: 1.802141586939494

Epoch: 5| Step: 3
Training loss: 1.3621002435684204
Validation loss: 1.8554026285807292

Epoch: 5| Step: 4
Training loss: 1.411095142364502
Validation loss: 1.8733815377758396

Epoch: 5| Step: 5
Training loss: 1.8124185800552368
Validation loss: 1.8765980787174676

Epoch: 5| Step: 6
Training loss: 1.292777419090271
Validation loss: 1.8149453850202664

Epoch: 5| Step: 7
Training loss: 1.883608102798462
Validation loss: 1.8581064183224913

Epoch: 5| Step: 8
Training loss: 1.6687638759613037
Validation loss: 1.8918314262103009

Epoch: 5| Step: 9
Training loss: 1.4232773780822754
Validation loss: 1.865465856367542

Epoch: 5| Step: 10
Training loss: 1.790871024131775
Validation loss: 1.855653896126696

Epoch: 287| Step: 0
Training loss: 1.9855749607086182
Validation loss: 1.8606008239971694

Epoch: 5| Step: 1
Training loss: 1.4370043277740479
Validation loss: 1.883152997621926

Epoch: 5| Step: 2
Training loss: 1.6230157613754272
Validation loss: 1.8823777116755003

Epoch: 5| Step: 3
Training loss: 1.2177565097808838
Validation loss: 1.9205676483851608

Epoch: 5| Step: 4
Training loss: 1.5952634811401367
Validation loss: 1.945612274190431

Epoch: 5| Step: 5
Training loss: 1.7914469242095947
Validation loss: 1.8516887951922674

Epoch: 5| Step: 6
Training loss: 1.6065387725830078
Validation loss: 1.9169985786561043

Epoch: 5| Step: 7
Training loss: 1.6801913976669312
Validation loss: 1.8685627663007347

Epoch: 5| Step: 8
Training loss: 2.410494089126587
Validation loss: 1.905087940154537

Epoch: 5| Step: 9
Training loss: 1.9594627618789673
Validation loss: 1.9173248903725737

Epoch: 5| Step: 10
Training loss: 1.7868034839630127
Validation loss: 1.9684087050858365

Epoch: 288| Step: 0
Training loss: 2.4592292308807373
Validation loss: 1.8932646051529916

Epoch: 5| Step: 1
Training loss: 2.1994900703430176
Validation loss: 1.9142863301820652

Epoch: 5| Step: 2
Training loss: 1.5327932834625244
Validation loss: 1.8655449113538187

Epoch: 5| Step: 3
Training loss: 1.5127986669540405
Validation loss: 1.8617281606120448

Epoch: 5| Step: 4
Training loss: 1.5762637853622437
Validation loss: 1.8595205263424945

Epoch: 5| Step: 5
Training loss: 1.6922338008880615
Validation loss: 1.9473230120956257

Epoch: 5| Step: 6
Training loss: 1.6862766742706299
Validation loss: 1.8682968552394579

Epoch: 5| Step: 7
Training loss: 1.4995784759521484
Validation loss: 1.8739503224690754

Epoch: 5| Step: 8
Training loss: 1.5177890062332153
Validation loss: 1.881348563778785

Epoch: 5| Step: 9
Training loss: 1.4817426204681396
Validation loss: 1.8744707735635902

Epoch: 5| Step: 10
Training loss: 1.5095815658569336
Validation loss: 1.808427854250836

Epoch: 289| Step: 0
Training loss: 1.2043688297271729
Validation loss: 1.8872710094656995

Epoch: 5| Step: 1
Training loss: 1.785132646560669
Validation loss: 1.852181144939956

Epoch: 5| Step: 2
Training loss: 1.5210976600646973
Validation loss: 1.827257062799187

Epoch: 5| Step: 3
Training loss: 1.6290937662124634
Validation loss: 1.8457524609822098

Epoch: 5| Step: 4
Training loss: 2.1285548210144043
Validation loss: 1.8611148198445637

Epoch: 5| Step: 5
Training loss: 1.4433567523956299
Validation loss: 1.8537942107005785

Epoch: 5| Step: 6
Training loss: 1.4837491512298584
Validation loss: 1.8060381207414853

Epoch: 5| Step: 7
Training loss: 2.226463794708252
Validation loss: 1.8460664133871756

Epoch: 5| Step: 8
Training loss: 1.3195127248764038
Validation loss: 1.8744564915216098

Epoch: 5| Step: 9
Training loss: 2.0239055156707764
Validation loss: 1.8986414312034525

Epoch: 5| Step: 10
Training loss: 1.8041764497756958
Validation loss: 1.9156142357856996

Epoch: 290| Step: 0
Training loss: 1.4592348337173462
Validation loss: 1.934514311052138

Epoch: 5| Step: 1
Training loss: 2.0680277347564697
Validation loss: 1.8875358207251436

Epoch: 5| Step: 2
Training loss: 1.523036241531372
Validation loss: 1.9510295391082764

Epoch: 5| Step: 3
Training loss: 2.197643756866455
Validation loss: 1.937986320064914

Epoch: 5| Step: 4
Training loss: 1.9684417247772217
Validation loss: 1.905819946719754

Epoch: 5| Step: 5
Training loss: 1.1793673038482666
Validation loss: 1.9396090943326232

Epoch: 5| Step: 6
Training loss: 1.6478917598724365
Validation loss: 1.9312588553274832

Epoch: 5| Step: 7
Training loss: 1.8316389322280884
Validation loss: 1.9239324908102713

Epoch: 5| Step: 8
Training loss: 1.4105767011642456
Validation loss: 1.8603558809526506

Epoch: 5| Step: 9
Training loss: 1.795941948890686
Validation loss: 1.9046766142691336

Epoch: 5| Step: 10
Training loss: 1.521886944770813
Validation loss: 1.8713895236292193

Epoch: 291| Step: 0
Training loss: 1.877280831336975
Validation loss: 1.9223617635747439

Epoch: 5| Step: 1
Training loss: 1.6963764429092407
Validation loss: 1.8748331134037306

Epoch: 5| Step: 2
Training loss: 1.4483137130737305
Validation loss: 1.8435969301449355

Epoch: 5| Step: 3
Training loss: 1.7463817596435547
Validation loss: 1.8755364623121036

Epoch: 5| Step: 4
Training loss: 1.9039167165756226
Validation loss: 1.8780651682166642

Epoch: 5| Step: 5
Training loss: 2.2884128093719482
Validation loss: 1.8714461762418029

Epoch: 5| Step: 6
Training loss: 1.3700988292694092
Validation loss: 1.823645878863591

Epoch: 5| Step: 7
Training loss: 1.7216947078704834
Validation loss: 1.8393602396852227

Epoch: 5| Step: 8
Training loss: 1.2953786849975586
Validation loss: 1.8948877037212413

Epoch: 5| Step: 9
Training loss: 1.4655892848968506
Validation loss: 1.8477634838832322

Epoch: 5| Step: 10
Training loss: 1.4141312837600708
Validation loss: 1.8429636109259822

Epoch: 292| Step: 0
Training loss: 1.8639602661132812
Validation loss: 1.9061784769899102

Epoch: 5| Step: 1
Training loss: 1.1535011529922485
Validation loss: 1.938384497037498

Epoch: 5| Step: 2
Training loss: 1.31368088722229
Validation loss: 1.8345405106903405

Epoch: 5| Step: 3
Training loss: 1.8704359531402588
Validation loss: 1.8690478865818312

Epoch: 5| Step: 4
Training loss: 2.329242467880249
Validation loss: 1.848271252006613

Epoch: 5| Step: 5
Training loss: 1.6803557872772217
Validation loss: 1.8526683494608889

Epoch: 5| Step: 6
Training loss: 1.213919997215271
Validation loss: 1.8738188717954902

Epoch: 5| Step: 7
Training loss: 1.4821406602859497
Validation loss: 1.8450782375950967

Epoch: 5| Step: 8
Training loss: 1.6607158184051514
Validation loss: 1.8511625669335807

Epoch: 5| Step: 9
Training loss: 2.00407338142395
Validation loss: 1.835776852023217

Epoch: 5| Step: 10
Training loss: 1.7985936403274536
Validation loss: 1.8416261108972694

Epoch: 293| Step: 0
Training loss: 2.126366376876831
Validation loss: 1.9067271460768997

Epoch: 5| Step: 1
Training loss: 1.848484754562378
Validation loss: 1.882326287607993

Epoch: 5| Step: 2
Training loss: 2.1310465335845947
Validation loss: 1.8592074250662198

Epoch: 5| Step: 3
Training loss: 1.8138091564178467
Validation loss: 1.887781730262182

Epoch: 5| Step: 4
Training loss: 1.3997570276260376
Validation loss: 1.8980613511095765

Epoch: 5| Step: 5
Training loss: 1.323947787284851
Validation loss: 1.8908803296345535

Epoch: 5| Step: 6
Training loss: 1.993406057357788
Validation loss: 1.8826773371747745

Epoch: 5| Step: 7
Training loss: 1.1919853687286377
Validation loss: 1.916894902465164

Epoch: 5| Step: 8
Training loss: 1.726973295211792
Validation loss: 1.8991408014810214

Epoch: 5| Step: 9
Training loss: 1.6187922954559326
Validation loss: 1.9098261428135697

Epoch: 5| Step: 10
Training loss: 1.4528069496154785
Validation loss: 1.8469941564785537

Epoch: 294| Step: 0
Training loss: 1.5971397161483765
Validation loss: 1.8883839820020942

Epoch: 5| Step: 1
Training loss: 1.7231318950653076
Validation loss: 1.785332300329721

Epoch: 5| Step: 2
Training loss: 1.1449739933013916
Validation loss: 1.8470974045415078

Epoch: 5| Step: 3
Training loss: 1.6933708190917969
Validation loss: 1.8957676323511268

Epoch: 5| Step: 4
Training loss: 1.9920380115509033
Validation loss: 1.8850526681510351

Epoch: 5| Step: 5
Training loss: 2.0018322467803955
Validation loss: 1.8832394487114363

Epoch: 5| Step: 6
Training loss: 1.3745468854904175
Validation loss: 1.795679828172089

Epoch: 5| Step: 7
Training loss: 1.3921191692352295
Validation loss: 1.8924919200199906

Epoch: 5| Step: 8
Training loss: 1.7687181234359741
Validation loss: 1.8579888292538222

Epoch: 5| Step: 9
Training loss: 2.185265302658081
Validation loss: 1.8524479866027832

Epoch: 5| Step: 10
Training loss: 1.5322093963623047
Validation loss: 1.918537078365203

Epoch: 295| Step: 0
Training loss: 1.603966474533081
Validation loss: 1.8766701631648566

Epoch: 5| Step: 1
Training loss: 1.7424596548080444
Validation loss: 1.8734591532778997

Epoch: 5| Step: 2
Training loss: 1.3279517889022827
Validation loss: 1.8557897331894084

Epoch: 5| Step: 3
Training loss: 1.8190345764160156
Validation loss: 1.854165651464975

Epoch: 5| Step: 4
Training loss: 1.4497768878936768
Validation loss: 1.9216533360942718

Epoch: 5| Step: 5
Training loss: 1.9290882349014282
Validation loss: 1.823536721608972

Epoch: 5| Step: 6
Training loss: 2.1996922492980957
Validation loss: 1.9003070336516186

Epoch: 5| Step: 7
Training loss: 2.0969467163085938
Validation loss: 1.8575828229227374

Epoch: 5| Step: 8
Training loss: 1.2535040378570557
Validation loss: 1.9026800253057992

Epoch: 5| Step: 9
Training loss: 1.2199558019638062
Validation loss: 1.9080317174234698

Epoch: 5| Step: 10
Training loss: 2.0041534900665283
Validation loss: 1.9171006371898036

Epoch: 296| Step: 0
Training loss: 1.9785823822021484
Validation loss: 1.9145631879888556

Epoch: 5| Step: 1
Training loss: 1.6599805355072021
Validation loss: 1.8913150679680608

Epoch: 5| Step: 2
Training loss: 1.701857328414917
Validation loss: 1.878611437736019

Epoch: 5| Step: 3
Training loss: 1.2035915851593018
Validation loss: 1.9187314253981396

Epoch: 5| Step: 4
Training loss: 1.4840291738510132
Validation loss: 1.9183328651612805

Epoch: 5| Step: 5
Training loss: 1.4625715017318726
Validation loss: 1.8681793840982581

Epoch: 5| Step: 6
Training loss: 1.9432684183120728
Validation loss: 1.8712479260659987

Epoch: 5| Step: 7
Training loss: 1.7887380123138428
Validation loss: 1.8328603493270053

Epoch: 5| Step: 8
Training loss: 1.0439732074737549
Validation loss: 1.8630536704935052

Epoch: 5| Step: 9
Training loss: 2.020322799682617
Validation loss: 1.8699515429876183

Epoch: 5| Step: 10
Training loss: 1.8459100723266602
Validation loss: 1.8938293021212342

Epoch: 297| Step: 0
Training loss: 1.815171241760254
Validation loss: 1.8839708758938698

Epoch: 5| Step: 1
Training loss: 1.946977972984314
Validation loss: 1.8675845323070404

Epoch: 5| Step: 2
Training loss: 1.74679434299469
Validation loss: 1.8540760624793269

Epoch: 5| Step: 3
Training loss: 1.9316425323486328
Validation loss: 1.846720318640432

Epoch: 5| Step: 4
Training loss: 1.1979678869247437
Validation loss: 1.8455405581382014

Epoch: 5| Step: 5
Training loss: 1.258826494216919
Validation loss: 1.8514390478851974

Epoch: 5| Step: 6
Training loss: 1.6022180318832397
Validation loss: 1.8619512024746145

Epoch: 5| Step: 7
Training loss: 1.3914031982421875
Validation loss: 1.835890296966799

Epoch: 5| Step: 8
Training loss: 1.914131760597229
Validation loss: 1.8470696377497848

Epoch: 5| Step: 9
Training loss: 1.8629947900772095
Validation loss: 1.8696934843576083

Epoch: 5| Step: 10
Training loss: 1.8629411458969116
Validation loss: 1.8564918989776282

Epoch: 298| Step: 0
Training loss: 1.8440492153167725
Validation loss: 1.9065938713730022

Epoch: 5| Step: 1
Training loss: 1.7750667333602905
Validation loss: 1.869503592932096

Epoch: 5| Step: 2
Training loss: 1.4647585153579712
Validation loss: 1.8553184950223534

Epoch: 5| Step: 3
Training loss: 1.0335109233856201
Validation loss: 1.8463830345420427

Epoch: 5| Step: 4
Training loss: 1.2601475715637207
Validation loss: 1.8408590311645179

Epoch: 5| Step: 5
Training loss: 2.170222759246826
Validation loss: 1.83547011498482

Epoch: 5| Step: 6
Training loss: 1.7323507070541382
Validation loss: 1.8566243328073972

Epoch: 5| Step: 7
Training loss: 2.0698118209838867
Validation loss: 1.813022776316571

Epoch: 5| Step: 8
Training loss: 1.5701202154159546
Validation loss: 1.848897300740724

Epoch: 5| Step: 9
Training loss: 2.2242941856384277
Validation loss: 1.891371480880245

Epoch: 5| Step: 10
Training loss: 0.9446855187416077
Validation loss: 1.9039457613422024

Epoch: 299| Step: 0
Training loss: 1.5174363851547241
Validation loss: 1.8797355787728423

Epoch: 5| Step: 1
Training loss: 1.9482120275497437
Validation loss: 1.8152943554744925

Epoch: 5| Step: 2
Training loss: 1.1973655223846436
Validation loss: 1.8174208838452575

Epoch: 5| Step: 3
Training loss: 1.9875478744506836
Validation loss: 1.8701205099782636

Epoch: 5| Step: 4
Training loss: 1.6787983179092407
Validation loss: 1.8691885907162902

Epoch: 5| Step: 5
Training loss: 1.593042016029358
Validation loss: 1.9131721283799858

Epoch: 5| Step: 6
Training loss: 1.393681287765503
Validation loss: 1.9145496686299641

Epoch: 5| Step: 7
Training loss: 1.7764770984649658
Validation loss: 1.9097617672335716

Epoch: 5| Step: 8
Training loss: 1.7910572290420532
Validation loss: 1.8598766480722735

Epoch: 5| Step: 9
Training loss: 2.0057437419891357
Validation loss: 1.8609247502460275

Epoch: 5| Step: 10
Training loss: 1.433372974395752
Validation loss: 1.8267786964293449

Epoch: 300| Step: 0
Training loss: 2.3777055740356445
Validation loss: 1.8379758019601145

Epoch: 5| Step: 1
Training loss: 1.3452740907669067
Validation loss: 1.866104902759675

Epoch: 5| Step: 2
Training loss: 1.8900489807128906
Validation loss: 1.8265456307318904

Epoch: 5| Step: 3
Training loss: 1.2891677618026733
Validation loss: 1.8764572015372656

Epoch: 5| Step: 4
Training loss: 2.031787872314453
Validation loss: 1.86992867659497

Epoch: 5| Step: 5
Training loss: 1.5843063592910767
Validation loss: 1.8940215040278692

Epoch: 5| Step: 6
Training loss: 1.5988643169403076
Validation loss: 1.8130052602419289

Epoch: 5| Step: 7
Training loss: 2.0661025047302246
Validation loss: 1.851092097579792

Epoch: 5| Step: 8
Training loss: 1.122788429260254
Validation loss: 1.9042500308764878

Epoch: 5| Step: 9
Training loss: 1.2778352499008179
Validation loss: 1.8436268273220267

Epoch: 5| Step: 10
Training loss: 1.8664320707321167
Validation loss: 1.8406116975251066

Epoch: 301| Step: 0
Training loss: 1.0840728282928467
Validation loss: 1.867911647724849

Epoch: 5| Step: 1
Training loss: 1.75760018825531
Validation loss: 1.8605205820452781

Epoch: 5| Step: 2
Training loss: 2.3263161182403564
Validation loss: 1.8364865164602957

Epoch: 5| Step: 3
Training loss: 1.4831960201263428
Validation loss: 1.8676409080464353

Epoch: 5| Step: 4
Training loss: 1.4982678890228271
Validation loss: 1.8493254235995713

Epoch: 5| Step: 5
Training loss: 1.9303516149520874
Validation loss: 1.8767091433207195

Epoch: 5| Step: 6
Training loss: 1.5749623775482178
Validation loss: 1.9092408559655631

Epoch: 5| Step: 7
Training loss: 1.7680343389511108
Validation loss: 1.8802666702578146

Epoch: 5| Step: 8
Training loss: 1.6130279302597046
Validation loss: 1.9060192338881954

Epoch: 5| Step: 9
Training loss: 1.637102484703064
Validation loss: 1.7924646049417474

Epoch: 5| Step: 10
Training loss: 1.4318358898162842
Validation loss: 1.8508103047647784

Epoch: 302| Step: 0
Training loss: 1.6405140161514282
Validation loss: 1.8533529773835213

Epoch: 5| Step: 1
Training loss: 2.1127705574035645
Validation loss: 1.834879030463516

Epoch: 5| Step: 2
Training loss: 1.6153075695037842
Validation loss: 1.8462253257792482

Epoch: 5| Step: 3
Training loss: 1.299876093864441
Validation loss: 1.8604368830239901

Epoch: 5| Step: 4
Training loss: 2.1897552013397217
Validation loss: 1.8524297565542243

Epoch: 5| Step: 5
Training loss: 1.5674442052841187
Validation loss: 1.8375827035596293

Epoch: 5| Step: 6
Training loss: 1.5323865413665771
Validation loss: 1.8417398263049383

Epoch: 5| Step: 7
Training loss: 1.266851782798767
Validation loss: 1.808870820588963

Epoch: 5| Step: 8
Training loss: 1.6079498529434204
Validation loss: 1.8690368603634577

Epoch: 5| Step: 9
Training loss: 1.4928920269012451
Validation loss: 1.8588226533705188

Epoch: 5| Step: 10
Training loss: 1.952149748802185
Validation loss: 1.8574827819742181

Epoch: 303| Step: 0
Training loss: 1.4272496700286865
Validation loss: 1.8537694766957273

Epoch: 5| Step: 1
Training loss: 1.169360637664795
Validation loss: 1.8474950444313787

Epoch: 5| Step: 2
Training loss: 1.8141038417816162
Validation loss: 1.8353241412870345

Epoch: 5| Step: 3
Training loss: 1.7460720539093018
Validation loss: 1.8006010747724963

Epoch: 5| Step: 4
Training loss: 1.9586719274520874
Validation loss: 1.8453687493519118

Epoch: 5| Step: 5
Training loss: 1.8540394306182861
Validation loss: 1.8197534507320774

Epoch: 5| Step: 6
Training loss: 1.2419836521148682
Validation loss: 1.835069756354055

Epoch: 5| Step: 7
Training loss: 1.837947130203247
Validation loss: 1.837110298936085

Epoch: 5| Step: 8
Training loss: 1.7604118585586548
Validation loss: 1.8516661454272527

Epoch: 5| Step: 9
Training loss: 1.5604279041290283
Validation loss: 1.9097323699664044

Epoch: 5| Step: 10
Training loss: 2.0474367141723633
Validation loss: 1.8145935150884813

Epoch: 304| Step: 0
Training loss: 2.277393341064453
Validation loss: 1.7892644251546552

Epoch: 5| Step: 1
Training loss: 1.5307680368423462
Validation loss: 1.8277002778104556

Epoch: 5| Step: 2
Training loss: 1.7096840143203735
Validation loss: 1.8829189449228265

Epoch: 5| Step: 3
Training loss: 1.000840425491333
Validation loss: 1.840411643828115

Epoch: 5| Step: 4
Training loss: 1.5506906509399414
Validation loss: 1.8446794107396116

Epoch: 5| Step: 5
Training loss: 1.9925451278686523
Validation loss: 1.897507990560224

Epoch: 5| Step: 6
Training loss: 1.3179352283477783
Validation loss: 1.9175410706509826

Epoch: 5| Step: 7
Training loss: 1.5941873788833618
Validation loss: 1.8347423858540033

Epoch: 5| Step: 8
Training loss: 1.7482478618621826
Validation loss: 1.858062962050079

Epoch: 5| Step: 9
Training loss: 1.3569157123565674
Validation loss: 1.8799100639999553

Epoch: 5| Step: 10
Training loss: 1.93459951877594
Validation loss: 1.814795644052567

Epoch: 305| Step: 0
Training loss: 1.1814461946487427
Validation loss: 1.8410828421192784

Epoch: 5| Step: 1
Training loss: 2.0336098670959473
Validation loss: 1.841643674399263

Epoch: 5| Step: 2
Training loss: 1.6858018636703491
Validation loss: 1.9198062035345262

Epoch: 5| Step: 3
Training loss: 2.04896879196167
Validation loss: 1.88764859784034

Epoch: 5| Step: 4
Training loss: 1.8859952688217163
Validation loss: 1.8281751127653225

Epoch: 5| Step: 5
Training loss: 1.6943089962005615
Validation loss: 1.9079136386994393

Epoch: 5| Step: 6
Training loss: 1.2852413654327393
Validation loss: 1.879746331963488

Epoch: 5| Step: 7
Training loss: 1.2913309335708618
Validation loss: 1.890242584290043

Epoch: 5| Step: 8
Training loss: 2.0494368076324463
Validation loss: 1.838775586056453

Epoch: 5| Step: 9
Training loss: 1.0817407369613647
Validation loss: 1.8856408878039288

Epoch: 5| Step: 10
Training loss: 2.005697250366211
Validation loss: 1.8507958073769846

Epoch: 306| Step: 0
Training loss: 1.1849453449249268
Validation loss: 1.9057835045681204

Epoch: 5| Step: 1
Training loss: 1.6353296041488647
Validation loss: 1.8721643801658385

Epoch: 5| Step: 2
Training loss: 1.5247471332550049
Validation loss: 1.8820864449265182

Epoch: 5| Step: 3
Training loss: 1.7882511615753174
Validation loss: 1.8657449112143567

Epoch: 5| Step: 4
Training loss: 2.350637435913086
Validation loss: 1.838310791600135

Epoch: 5| Step: 5
Training loss: 1.3752902746200562
Validation loss: 1.8789139447673675

Epoch: 5| Step: 6
Training loss: 1.9174762964248657
Validation loss: 1.86951236314671

Epoch: 5| Step: 7
Training loss: 1.8442020416259766
Validation loss: 1.883129890247058

Epoch: 5| Step: 8
Training loss: 0.9031323194503784
Validation loss: 1.8163401695989794

Epoch: 5| Step: 9
Training loss: 2.1085989475250244
Validation loss: 1.853206184602553

Epoch: 5| Step: 10
Training loss: 1.3754433393478394
Validation loss: 1.8256079522512292

Epoch: 307| Step: 0
Training loss: 1.6665302515029907
Validation loss: 1.857510038601455

Epoch: 5| Step: 1
Training loss: 2.067593574523926
Validation loss: 1.8791617321711716

Epoch: 5| Step: 2
Training loss: 1.1947880983352661
Validation loss: 1.9080420796589186

Epoch: 5| Step: 3
Training loss: 1.8050625324249268
Validation loss: 1.810655438771812

Epoch: 5| Step: 4
Training loss: 1.1264408826828003
Validation loss: 1.8658108442060408

Epoch: 5| Step: 5
Training loss: 1.7988134622573853
Validation loss: 1.8603423231391496

Epoch: 5| Step: 6
Training loss: 1.5779602527618408
Validation loss: 1.8942993392226517

Epoch: 5| Step: 7
Training loss: 1.7087314128875732
Validation loss: 1.8678466645620202

Epoch: 5| Step: 8
Training loss: 1.8850818872451782
Validation loss: 1.8516088813863776

Epoch: 5| Step: 9
Training loss: 1.5630167722702026
Validation loss: 1.8804224203991633

Epoch: 5| Step: 10
Training loss: 1.4324895143508911
Validation loss: 1.8623875084743704

Epoch: 308| Step: 0
Training loss: 1.7049400806427002
Validation loss: 1.8135171564676429

Epoch: 5| Step: 1
Training loss: 1.370162010192871
Validation loss: 1.7794675891117384

Epoch: 5| Step: 2
Training loss: 0.9642124176025391
Validation loss: 1.834907893211611

Epoch: 5| Step: 3
Training loss: 1.663116455078125
Validation loss: 1.8325929000813475

Epoch: 5| Step: 4
Training loss: 1.7570304870605469
Validation loss: 1.8923529232701948

Epoch: 5| Step: 5
Training loss: 2.063500165939331
Validation loss: 1.8701822014265164

Epoch: 5| Step: 6
Training loss: 1.1552401781082153
Validation loss: 1.8387848997628817

Epoch: 5| Step: 7
Training loss: 1.7968896627426147
Validation loss: 1.8168242733965638

Epoch: 5| Step: 8
Training loss: 1.7325836420059204
Validation loss: 1.8895103072607389

Epoch: 5| Step: 9
Training loss: 2.1458020210266113
Validation loss: 1.859530710404919

Epoch: 5| Step: 10
Training loss: 1.613063097000122
Validation loss: 1.8390755627744941

Epoch: 309| Step: 0
Training loss: 2.033257484436035
Validation loss: 1.8272563821525984

Epoch: 5| Step: 1
Training loss: 1.531920075416565
Validation loss: 1.8799567350777246

Epoch: 5| Step: 2
Training loss: 1.2234750986099243
Validation loss: 1.8028610201292141

Epoch: 5| Step: 3
Training loss: 1.9909855127334595
Validation loss: 1.8271157485182568

Epoch: 5| Step: 4
Training loss: 2.1975533962249756
Validation loss: 1.855147498910145

Epoch: 5| Step: 5
Training loss: 2.0826897621154785
Validation loss: 1.8713530263593119

Epoch: 5| Step: 6
Training loss: 1.7611351013183594
Validation loss: 1.8631299644388177

Epoch: 5| Step: 7
Training loss: 1.16749906539917
Validation loss: 1.850441191786079

Epoch: 5| Step: 8
Training loss: 1.3549120426177979
Validation loss: 1.8134590528344596

Epoch: 5| Step: 9
Training loss: 1.244227647781372
Validation loss: 1.8465708583913825

Epoch: 5| Step: 10
Training loss: 1.3261107206344604
Validation loss: 1.9000490762854134

Epoch: 310| Step: 0
Training loss: 1.4049890041351318
Validation loss: 1.8545526689098728

Epoch: 5| Step: 1
Training loss: 1.932157278060913
Validation loss: 1.84532731322832

Epoch: 5| Step: 2
Training loss: 1.4614512920379639
Validation loss: 1.8499911395452355

Epoch: 5| Step: 3
Training loss: 1.2556370496749878
Validation loss: 1.8633689008733278

Epoch: 5| Step: 4
Training loss: 1.5779776573181152
Validation loss: 1.8500962795749787

Epoch: 5| Step: 5
Training loss: 1.556563377380371
Validation loss: 1.8786164586262037

Epoch: 5| Step: 6
Training loss: 1.385225772857666
Validation loss: 1.786103247314371

Epoch: 5| Step: 7
Training loss: 2.158357858657837
Validation loss: 1.8533991831605152

Epoch: 5| Step: 8
Training loss: 1.7446790933609009
Validation loss: 1.849548198843515

Epoch: 5| Step: 9
Training loss: 1.6341781616210938
Validation loss: 1.815700029814115

Epoch: 5| Step: 10
Training loss: 1.8326889276504517
Validation loss: 1.8860024149699877

Epoch: 311| Step: 0
Training loss: 2.4218974113464355
Validation loss: 1.842776236995574

Epoch: 5| Step: 1
Training loss: 2.254964828491211
Validation loss: 1.8525512705567062

Epoch: 5| Step: 2
Training loss: 1.6686046123504639
Validation loss: 1.839825378951206

Epoch: 5| Step: 3
Training loss: 1.3406085968017578
Validation loss: 1.8626638253529866

Epoch: 5| Step: 4
Training loss: 1.9004634618759155
Validation loss: 1.7614262680853567

Epoch: 5| Step: 5
Training loss: 1.5110582113265991
Validation loss: 1.8462092338069793

Epoch: 5| Step: 6
Training loss: 1.0308395624160767
Validation loss: 1.848627681373268

Epoch: 5| Step: 7
Training loss: 1.5927038192749023
Validation loss: 1.829329107397346

Epoch: 5| Step: 8
Training loss: 1.4472131729125977
Validation loss: 1.8072605363784298

Epoch: 5| Step: 9
Training loss: 1.3142119646072388
Validation loss: 1.8662369199978408

Epoch: 5| Step: 10
Training loss: 1.4118399620056152
Validation loss: 1.8371087325516569

Epoch: 312| Step: 0
Training loss: 0.7963652610778809
Validation loss: 1.7913657798562

Epoch: 5| Step: 1
Training loss: 1.4125983715057373
Validation loss: 1.855962299531506

Epoch: 5| Step: 2
Training loss: 1.5337660312652588
Validation loss: 1.8643619501462547

Epoch: 5| Step: 3
Training loss: 1.2586034536361694
Validation loss: 1.8486461472767655

Epoch: 5| Step: 4
Training loss: 1.4916393756866455
Validation loss: 1.8571486191083026

Epoch: 5| Step: 5
Training loss: 1.988861083984375
Validation loss: 1.8270366845592376

Epoch: 5| Step: 6
Training loss: 2.078382968902588
Validation loss: 1.8839391226409583

Epoch: 5| Step: 7
Training loss: 2.0084569454193115
Validation loss: 1.8647672463488836

Epoch: 5| Step: 8
Training loss: 1.5644850730895996
Validation loss: 1.8600527471111667

Epoch: 5| Step: 9
Training loss: 1.9592615365982056
Validation loss: 1.8272067269971293

Epoch: 5| Step: 10
Training loss: 1.9378583431243896
Validation loss: 1.901301242971933

Epoch: 313| Step: 0
Training loss: 1.1313211917877197
Validation loss: 1.851881419458697

Epoch: 5| Step: 1
Training loss: 2.3075358867645264
Validation loss: 1.8503801130479383

Epoch: 5| Step: 2
Training loss: 2.0421411991119385
Validation loss: 1.884143247399279

Epoch: 5| Step: 3
Training loss: 1.388620376586914
Validation loss: 1.8106714320439163

Epoch: 5| Step: 4
Training loss: 1.810120940208435
Validation loss: 1.8404492396180347

Epoch: 5| Step: 5
Training loss: 1.6104005575180054
Validation loss: 1.872913973305815

Epoch: 5| Step: 6
Training loss: 1.2419862747192383
Validation loss: 1.8595066301284298

Epoch: 5| Step: 7
Training loss: 2.178952693939209
Validation loss: 1.8494701936680784

Epoch: 5| Step: 8
Training loss: 1.2021514177322388
Validation loss: 1.855604890854128

Epoch: 5| Step: 9
Training loss: 1.4178385734558105
Validation loss: 1.7792338081585464

Epoch: 5| Step: 10
Training loss: 1.3771264553070068
Validation loss: 1.7746103053451867

Epoch: 314| Step: 0
Training loss: 1.8605527877807617
Validation loss: 1.8182060539081533

Epoch: 5| Step: 1
Training loss: 1.720412015914917
Validation loss: 1.818415258520393

Epoch: 5| Step: 2
Training loss: 1.9462162256240845
Validation loss: 1.8535820284197408

Epoch: 5| Step: 3
Training loss: 1.2485992908477783
Validation loss: 1.8437087779404016

Epoch: 5| Step: 4
Training loss: 1.6440608501434326
Validation loss: 1.7934408764685354

Epoch: 5| Step: 5
Training loss: 2.000044584274292
Validation loss: 1.8392024745223343

Epoch: 5| Step: 6
Training loss: 0.8517736196517944
Validation loss: 1.817350294000359

Epoch: 5| Step: 7
Training loss: 1.5276687145233154
Validation loss: 1.8586666725015129

Epoch: 5| Step: 8
Training loss: 2.0753672122955322
Validation loss: 1.8534144919405702

Epoch: 5| Step: 9
Training loss: 1.5124051570892334
Validation loss: 1.8476953865379415

Epoch: 5| Step: 10
Training loss: 1.3506929874420166
Validation loss: 1.8735071792397449

Epoch: 315| Step: 0
Training loss: 1.2769604921340942
Validation loss: 1.8958181027443177

Epoch: 5| Step: 1
Training loss: 1.4826992750167847
Validation loss: 1.8214301780987812

Epoch: 5| Step: 2
Training loss: 1.8071140050888062
Validation loss: 1.8571752040616927

Epoch: 5| Step: 3
Training loss: 1.8080066442489624
Validation loss: 1.945453918108376

Epoch: 5| Step: 4
Training loss: 1.1162620782852173
Validation loss: 1.8409180974447599

Epoch: 5| Step: 5
Training loss: 1.6214873790740967
Validation loss: 1.8450924914370301

Epoch: 5| Step: 6
Training loss: 2.3641467094421387
Validation loss: 1.8395498542375461

Epoch: 5| Step: 7
Training loss: 1.0753799676895142
Validation loss: 1.8463031091997701

Epoch: 5| Step: 8
Training loss: 1.4910978078842163
Validation loss: 1.8584710192936722

Epoch: 5| Step: 9
Training loss: 1.5695159435272217
Validation loss: 1.8627533553749003

Epoch: 5| Step: 10
Training loss: 2.308277130126953
Validation loss: 1.8793934955391833

Epoch: 316| Step: 0
Training loss: 1.4569276571273804
Validation loss: 1.8434577552221154

Epoch: 5| Step: 1
Training loss: 1.5715439319610596
Validation loss: 1.8538898665417907

Epoch: 5| Step: 2
Training loss: 2.1045632362365723
Validation loss: 1.8304635132512739

Epoch: 5| Step: 3
Training loss: 1.6649086475372314
Validation loss: 1.7975685750284502

Epoch: 5| Step: 4
Training loss: 1.9820226430892944
Validation loss: 1.7827256828226068

Epoch: 5| Step: 5
Training loss: 1.4998773336410522
Validation loss: 1.817711946784809

Epoch: 5| Step: 6
Training loss: 1.208777666091919
Validation loss: 1.855061037566072

Epoch: 5| Step: 7
Training loss: 2.1417269706726074
Validation loss: 1.8255032365040114

Epoch: 5| Step: 8
Training loss: 1.7298446893692017
Validation loss: 1.8162182607958395

Epoch: 5| Step: 9
Training loss: 1.422730803489685
Validation loss: 1.8152356327220958

Epoch: 5| Step: 10
Training loss: 1.5729209184646606
Validation loss: 1.8132585992095291

Epoch: 317| Step: 0
Training loss: 1.7053836584091187
Validation loss: 1.831527179287326

Epoch: 5| Step: 1
Training loss: 1.6071010828018188
Validation loss: 1.8441927856014622

Epoch: 5| Step: 2
Training loss: 1.5197957754135132
Validation loss: 1.85576690653319

Epoch: 5| Step: 3
Training loss: 1.9201809167861938
Validation loss: 1.8769101763284335

Epoch: 5| Step: 4
Training loss: 1.8582903146743774
Validation loss: 1.8698731551888168

Epoch: 5| Step: 5
Training loss: 1.573394536972046
Validation loss: 1.8908046548084547

Epoch: 5| Step: 6
Training loss: 1.322060465812683
Validation loss: 1.8462958335876465

Epoch: 5| Step: 7
Training loss: 1.4194090366363525
Validation loss: 1.9295209735952399

Epoch: 5| Step: 8
Training loss: 1.847333550453186
Validation loss: 1.8700019851807625

Epoch: 5| Step: 9
Training loss: 1.5068776607513428
Validation loss: 1.8291107980153893

Epoch: 5| Step: 10
Training loss: 1.5135985612869263
Validation loss: 1.8625205703960952

Epoch: 318| Step: 0
Training loss: 1.2518324851989746
Validation loss: 1.8686352058123517

Epoch: 5| Step: 1
Training loss: 2.200307846069336
Validation loss: 1.873338468613163

Epoch: 5| Step: 2
Training loss: 1.2946135997772217
Validation loss: 1.8500891911086215

Epoch: 5| Step: 3
Training loss: 1.8563024997711182
Validation loss: 1.8449634326401578

Epoch: 5| Step: 4
Training loss: 1.2263587713241577
Validation loss: 1.8127788177100561

Epoch: 5| Step: 5
Training loss: 1.5307673215866089
Validation loss: 1.8462399667309177

Epoch: 5| Step: 6
Training loss: 2.007871627807617
Validation loss: 1.7888754619065153

Epoch: 5| Step: 7
Training loss: 1.4007163047790527
Validation loss: 1.8616923619342107

Epoch: 5| Step: 8
Training loss: 1.7495132684707642
Validation loss: 1.876093969550184

Epoch: 5| Step: 9
Training loss: 1.0502803325653076
Validation loss: 1.8232204862820205

Epoch: 5| Step: 10
Training loss: 2.2250194549560547
Validation loss: 1.8195825546018538

Epoch: 319| Step: 0
Training loss: 1.4002846479415894
Validation loss: 1.8558966472584715

Epoch: 5| Step: 1
Training loss: 1.1296601295471191
Validation loss: 1.8352709944530199

Epoch: 5| Step: 2
Training loss: 1.5327045917510986
Validation loss: 1.8395859438885924

Epoch: 5| Step: 3
Training loss: 2.3565077781677246
Validation loss: 1.8378595126572477

Epoch: 5| Step: 4
Training loss: 1.797080397605896
Validation loss: 1.810943002341896

Epoch: 5| Step: 5
Training loss: 1.6692657470703125
Validation loss: 1.818749809777865

Epoch: 5| Step: 6
Training loss: 1.88497793674469
Validation loss: 1.8807165725256807

Epoch: 5| Step: 7
Training loss: 1.399489402770996
Validation loss: 1.8467654912702498

Epoch: 5| Step: 8
Training loss: 1.788879156112671
Validation loss: 1.826534878823065

Epoch: 5| Step: 9
Training loss: 1.546377420425415
Validation loss: 1.811069562870969

Epoch: 5| Step: 10
Training loss: 1.2109465599060059
Validation loss: 1.8293620104430823

Epoch: 320| Step: 0
Training loss: 1.397470235824585
Validation loss: 1.8636746829555881

Epoch: 5| Step: 1
Training loss: 1.3609493970870972
Validation loss: 1.8376836007641209

Epoch: 5| Step: 2
Training loss: 2.141014575958252
Validation loss: 1.8354171988784627

Epoch: 5| Step: 3
Training loss: 1.9920545816421509
Validation loss: 1.9019413968568206

Epoch: 5| Step: 4
Training loss: 1.8908395767211914
Validation loss: 1.9053353340395036

Epoch: 5| Step: 5
Training loss: 1.3517605066299438
Validation loss: 1.884860755294882

Epoch: 5| Step: 6
Training loss: 1.6903263330459595
Validation loss: 1.89388221181849

Epoch: 5| Step: 7
Training loss: 1.609025239944458
Validation loss: 1.877428868765472

Epoch: 5| Step: 8
Training loss: 1.376465082168579
Validation loss: 1.9623077928379018

Epoch: 5| Step: 9
Training loss: 1.5591907501220703
Validation loss: 1.8423985358207458

Epoch: 5| Step: 10
Training loss: 1.8673696517944336
Validation loss: 1.8664588697495

Epoch: 321| Step: 0
Training loss: 2.1947245597839355
Validation loss: 1.838645645367202

Epoch: 5| Step: 1
Training loss: 1.3724333047866821
Validation loss: 1.8590837370964788

Epoch: 5| Step: 2
Training loss: 1.1410061120986938
Validation loss: 1.8408004096759263

Epoch: 5| Step: 3
Training loss: 1.913344383239746
Validation loss: 1.906672836631857

Epoch: 5| Step: 4
Training loss: 1.7117153406143188
Validation loss: 1.9340118003147904

Epoch: 5| Step: 5
Training loss: 1.9798524379730225
Validation loss: 1.886769425484442

Epoch: 5| Step: 6
Training loss: 1.6975435018539429
Validation loss: 1.8769228560950166

Epoch: 5| Step: 7
Training loss: 1.488199234008789
Validation loss: 1.8837309011849024

Epoch: 5| Step: 8
Training loss: 0.9869333505630493
Validation loss: 1.830143977237004

Epoch: 5| Step: 9
Training loss: 1.373924970626831
Validation loss: 1.8600294795087589

Epoch: 5| Step: 10
Training loss: 1.799515724182129
Validation loss: 1.799906490951456

Epoch: 322| Step: 0
Training loss: 1.4746339321136475
Validation loss: 1.8303965676215388

Epoch: 5| Step: 1
Training loss: 1.8033344745635986
Validation loss: 1.835064362454158

Epoch: 5| Step: 2
Training loss: 1.8110805749893188
Validation loss: 1.856257862942193

Epoch: 5| Step: 3
Training loss: 1.9001216888427734
Validation loss: 1.824197228236865

Epoch: 5| Step: 4
Training loss: 1.5447351932525635
Validation loss: 1.8028159500450216

Epoch: 5| Step: 5
Training loss: 1.8737949132919312
Validation loss: 1.8486363759604834

Epoch: 5| Step: 6
Training loss: 1.770483374595642
Validation loss: 1.8273520290210683

Epoch: 5| Step: 7
Training loss: 1.2847630977630615
Validation loss: 1.8382607698440552

Epoch: 5| Step: 8
Training loss: 0.8930082321166992
Validation loss: 1.8956196923409738

Epoch: 5| Step: 9
Training loss: 1.841183066368103
Validation loss: 1.8166264180214173

Epoch: 5| Step: 10
Training loss: 1.6852500438690186
Validation loss: 1.9057119008033507

Epoch: 323| Step: 0
Training loss: 1.5844343900680542
Validation loss: 1.814938627263551

Epoch: 5| Step: 1
Training loss: 1.4505165815353394
Validation loss: 1.8674625145491732

Epoch: 5| Step: 2
Training loss: 1.782997488975525
Validation loss: 1.876029808034179

Epoch: 5| Step: 3
Training loss: 1.6983041763305664
Validation loss: 1.8522631327311199

Epoch: 5| Step: 4
Training loss: 1.512080192565918
Validation loss: 1.8358023346111338

Epoch: 5| Step: 5
Training loss: 1.796633005142212
Validation loss: 1.8668844033313055

Epoch: 5| Step: 6
Training loss: 1.4893072843551636
Validation loss: 1.8382571166561497

Epoch: 5| Step: 7
Training loss: 1.0305213928222656
Validation loss: 1.8598605394363403

Epoch: 5| Step: 8
Training loss: 1.795142412185669
Validation loss: 1.8976329603502828

Epoch: 5| Step: 9
Training loss: 1.6267497539520264
Validation loss: 1.9054728579777542

Epoch: 5| Step: 10
Training loss: 2.3715946674346924
Validation loss: 1.8382885084357312

Epoch: 324| Step: 0
Training loss: 1.3653377294540405
Validation loss: 1.8657055606124222

Epoch: 5| Step: 1
Training loss: 1.8551914691925049
Validation loss: 1.821199454287047

Epoch: 5| Step: 2
Training loss: 1.1645244359970093
Validation loss: 1.9026362703692528

Epoch: 5| Step: 3
Training loss: 1.6948573589324951
Validation loss: 1.8927033639723254

Epoch: 5| Step: 4
Training loss: 1.6643253564834595
Validation loss: 1.9011164942095358

Epoch: 5| Step: 5
Training loss: 1.7566051483154297
Validation loss: 1.8620042352266208

Epoch: 5| Step: 6
Training loss: 1.584468960762024
Validation loss: 1.9188221321311048

Epoch: 5| Step: 7
Training loss: 1.545514702796936
Validation loss: 1.8999916840625066

Epoch: 5| Step: 8
Training loss: 1.1860233545303345
Validation loss: 1.8523633172435146

Epoch: 5| Step: 9
Training loss: 1.2856675386428833
Validation loss: 1.8590090800357122

Epoch: 5| Step: 10
Training loss: 2.4850897789001465
Validation loss: 1.8664606578888432

Epoch: 325| Step: 0
Training loss: 1.1113911867141724
Validation loss: 1.8562178073390838

Epoch: 5| Step: 1
Training loss: 1.5967940092086792
Validation loss: 1.8407179206930182

Epoch: 5| Step: 2
Training loss: 1.8460975885391235
Validation loss: 1.8291337848991476

Epoch: 5| Step: 3
Training loss: 1.4564011096954346
Validation loss: 1.9216039334574053

Epoch: 5| Step: 4
Training loss: 1.8245861530303955
Validation loss: 1.8837354413924678

Epoch: 5| Step: 5
Training loss: 1.4838857650756836
Validation loss: 1.868700317157212

Epoch: 5| Step: 6
Training loss: 1.5365469455718994
Validation loss: 1.8402604826035038

Epoch: 5| Step: 7
Training loss: 1.469461441040039
Validation loss: 1.8407683116133495

Epoch: 5| Step: 8
Training loss: 2.182508707046509
Validation loss: 1.853918025570531

Epoch: 5| Step: 9
Training loss: 1.119876503944397
Validation loss: 1.8351113373233425

Epoch: 5| Step: 10
Training loss: 1.8866569995880127
Validation loss: 1.8771047399890037

Epoch: 326| Step: 0
Training loss: 1.5131640434265137
Validation loss: 1.8209027064743863

Epoch: 5| Step: 1
Training loss: 1.2920448780059814
Validation loss: 1.8563944896062214

Epoch: 5| Step: 2
Training loss: 1.6622775793075562
Validation loss: 1.8407496611277263

Epoch: 5| Step: 3
Training loss: 1.7478984594345093
Validation loss: 1.797781999393176

Epoch: 5| Step: 4
Training loss: 1.9307689666748047
Validation loss: 1.8641663546203284

Epoch: 5| Step: 5
Training loss: 1.5626922845840454
Validation loss: 1.8519990226273895

Epoch: 5| Step: 6
Training loss: 1.3483736515045166
Validation loss: 1.8436187223721576

Epoch: 5| Step: 7
Training loss: 1.300868272781372
Validation loss: 1.8831058432978969

Epoch: 5| Step: 8
Training loss: 2.0343425273895264
Validation loss: 1.8729328673372987

Epoch: 5| Step: 9
Training loss: 1.4786217212677002
Validation loss: 1.889612385021743

Epoch: 5| Step: 10
Training loss: 1.9898475408554077
Validation loss: 1.851414947099583

Epoch: 327| Step: 0
Training loss: 2.3137259483337402
Validation loss: 1.8540379834431473

Epoch: 5| Step: 1
Training loss: 1.5293248891830444
Validation loss: 1.8335820808205554

Epoch: 5| Step: 2
Training loss: 1.1640422344207764
Validation loss: 1.9293254319057669

Epoch: 5| Step: 3
Training loss: 1.8231464624404907
Validation loss: 1.8759561815569479

Epoch: 5| Step: 4
Training loss: 1.6931997537612915
Validation loss: 1.9040546417236328

Epoch: 5| Step: 5
Training loss: 1.1147063970565796
Validation loss: 1.8726340263120589

Epoch: 5| Step: 6
Training loss: 1.1085013151168823
Validation loss: 1.9088901486448062

Epoch: 5| Step: 7
Training loss: 1.5828001499176025
Validation loss: 1.851124011060243

Epoch: 5| Step: 8
Training loss: 2.0514302253723145
Validation loss: 1.8948065798769715

Epoch: 5| Step: 9
Training loss: 1.7015794515609741
Validation loss: 1.88729231075574

Epoch: 5| Step: 10
Training loss: 1.4532302618026733
Validation loss: 1.7903846053666965

Epoch: 328| Step: 0
Training loss: 1.6054000854492188
Validation loss: 1.79875091327134

Epoch: 5| Step: 1
Training loss: 1.615077257156372
Validation loss: 1.8346194682582733

Epoch: 5| Step: 2
Training loss: 2.3070504665374756
Validation loss: 1.8183594672910628

Epoch: 5| Step: 3
Training loss: 1.1865302324295044
Validation loss: 1.8265430004365983

Epoch: 5| Step: 4
Training loss: 1.4925940036773682
Validation loss: 1.861707664305164

Epoch: 5| Step: 5
Training loss: 1.8473446369171143
Validation loss: 1.7874488830566406

Epoch: 5| Step: 6
Training loss: 1.6299667358398438
Validation loss: 1.9072095232625161

Epoch: 5| Step: 7
Training loss: 1.6232973337173462
Validation loss: 1.8629273201829644

Epoch: 5| Step: 8
Training loss: 1.3576314449310303
Validation loss: 1.8273822992078719

Epoch: 5| Step: 9
Training loss: 1.303570032119751
Validation loss: 1.80917525804171

Epoch: 5| Step: 10
Training loss: 1.3763583898544312
Validation loss: 1.808943481855495

Epoch: 329| Step: 0
Training loss: 1.5660979747772217
Validation loss: 1.8788191323639245

Epoch: 5| Step: 1
Training loss: 1.3749557733535767
Validation loss: 1.8065571592700096

Epoch: 5| Step: 2
Training loss: 1.4953129291534424
Validation loss: 1.8737943300636866

Epoch: 5| Step: 3
Training loss: 1.6541236639022827
Validation loss: 1.881149693201947

Epoch: 5| Step: 4
Training loss: 1.7744649648666382
Validation loss: 1.8920223571920907

Epoch: 5| Step: 5
Training loss: 2.151306629180908
Validation loss: 1.8612949796902236

Epoch: 5| Step: 6
Training loss: 1.7036311626434326
Validation loss: 1.864024084101441

Epoch: 5| Step: 7
Training loss: 1.575361967086792
Validation loss: 1.8817910225160661

Epoch: 5| Step: 8
Training loss: 1.5092259645462036
Validation loss: 1.8196779733063073

Epoch: 5| Step: 9
Training loss: 1.5003366470336914
Validation loss: 1.8440064012363393

Epoch: 5| Step: 10
Training loss: 0.8293632864952087
Validation loss: 1.8874612598009006

Epoch: 330| Step: 0
Training loss: 1.3537447452545166
Validation loss: 1.8158091729687107

Epoch: 5| Step: 1
Training loss: 1.454398512840271
Validation loss: 1.842896928069412

Epoch: 5| Step: 2
Training loss: 1.9025970697402954
Validation loss: 1.846293657056747

Epoch: 5| Step: 3
Training loss: 1.5612789392471313
Validation loss: 1.823009317921054

Epoch: 5| Step: 4
Training loss: 1.510538935661316
Validation loss: 1.844189154204502

Epoch: 5| Step: 5
Training loss: 1.244638204574585
Validation loss: 1.848033239764552

Epoch: 5| Step: 6
Training loss: 2.0751588344573975
Validation loss: 1.8377870090546147

Epoch: 5| Step: 7
Training loss: 1.1512761116027832
Validation loss: 1.8377504707664571

Epoch: 5| Step: 8
Training loss: 1.6279951333999634
Validation loss: 1.8345626297817434

Epoch: 5| Step: 9
Training loss: 1.90936279296875
Validation loss: 1.8639967313376806

Epoch: 5| Step: 10
Training loss: 1.670097827911377
Validation loss: 1.8710322559520762

Epoch: 331| Step: 0
Training loss: 1.7320806980133057
Validation loss: 1.833276423715776

Epoch: 5| Step: 1
Training loss: 1.444389820098877
Validation loss: 1.8521416430832238

Epoch: 5| Step: 2
Training loss: 1.2929413318634033
Validation loss: 1.8121419696397678

Epoch: 5| Step: 3
Training loss: 0.8897126317024231
Validation loss: 1.7766482817229403

Epoch: 5| Step: 4
Training loss: 1.4762367010116577
Validation loss: 1.8592637956783336

Epoch: 5| Step: 5
Training loss: 1.2086820602416992
Validation loss: 1.8606853818380704

Epoch: 5| Step: 6
Training loss: 2.5251169204711914
Validation loss: 1.8210557019838722

Epoch: 5| Step: 7
Training loss: 2.2434375286102295
Validation loss: 1.872784750435942

Epoch: 5| Step: 8
Training loss: 1.7209148406982422
Validation loss: 1.8390321718749179

Epoch: 5| Step: 9
Training loss: 1.4725127220153809
Validation loss: 1.8024976586782804

Epoch: 5| Step: 10
Training loss: 1.6469886302947998
Validation loss: 1.8420975439010128

Epoch: 332| Step: 0
Training loss: 1.553405523300171
Validation loss: 1.8398766645821192

Epoch: 5| Step: 1
Training loss: 1.4272587299346924
Validation loss: 1.8455395262728456

Epoch: 5| Step: 2
Training loss: 1.904144525527954
Validation loss: 1.812751821292344

Epoch: 5| Step: 3
Training loss: 1.3926959037780762
Validation loss: 1.8532544541102585

Epoch: 5| Step: 4
Training loss: 1.3100237846374512
Validation loss: 1.8067406544121363

Epoch: 5| Step: 5
Training loss: 1.723367691040039
Validation loss: 1.8441508123951573

Epoch: 5| Step: 6
Training loss: 1.6426242589950562
Validation loss: 1.840290823290425

Epoch: 5| Step: 7
Training loss: 1.7180421352386475
Validation loss: 1.857533049839799

Epoch: 5| Step: 8
Training loss: 1.4159590005874634
Validation loss: 1.8405063600950344

Epoch: 5| Step: 9
Training loss: 1.5394519567489624
Validation loss: 1.7779578034595778

Epoch: 5| Step: 10
Training loss: 1.681103229522705
Validation loss: 1.8074433957376788

Epoch: 333| Step: 0
Training loss: 0.971411406993866
Validation loss: 1.7839556817085511

Epoch: 5| Step: 1
Training loss: 1.8835818767547607
Validation loss: 1.8958528118748819

Epoch: 5| Step: 2
Training loss: 1.6714503765106201
Validation loss: 1.8331306621592531

Epoch: 5| Step: 3
Training loss: 0.9755603075027466
Validation loss: 1.8109038799039778

Epoch: 5| Step: 4
Training loss: 1.7914295196533203
Validation loss: 1.8422054295898767

Epoch: 5| Step: 5
Training loss: 1.6239211559295654
Validation loss: 1.8209475060944915

Epoch: 5| Step: 6
Training loss: 1.5486104488372803
Validation loss: 1.8511020355327155

Epoch: 5| Step: 7
Training loss: 2.387737989425659
Validation loss: 1.8257050770585255

Epoch: 5| Step: 8
Training loss: 0.8729619979858398
Validation loss: 1.826983142924565

Epoch: 5| Step: 9
Training loss: 1.7417396306991577
Validation loss: 1.8453543045187508

Epoch: 5| Step: 10
Training loss: 1.9075452089309692
Validation loss: 1.8086284924578924

Epoch: 334| Step: 0
Training loss: 2.094677686691284
Validation loss: 1.8138774287316106

Epoch: 5| Step: 1
Training loss: 1.9859774112701416
Validation loss: 1.8180687324975127

Epoch: 5| Step: 2
Training loss: 1.81036376953125
Validation loss: 1.862675920609505

Epoch: 5| Step: 3
Training loss: 1.7755695581436157
Validation loss: 1.8583978940081853

Epoch: 5| Step: 4
Training loss: 1.779547929763794
Validation loss: 1.8923047921990837

Epoch: 5| Step: 5
Training loss: 1.799437165260315
Validation loss: 1.8274424422171809

Epoch: 5| Step: 6
Training loss: 1.3976798057556152
Validation loss: 1.8432490582107215

Epoch: 5| Step: 7
Training loss: 1.4931304454803467
Validation loss: 1.85017547299785

Epoch: 5| Step: 8
Training loss: 1.0990166664123535
Validation loss: 1.9019442271160822

Epoch: 5| Step: 9
Training loss: 0.5898198485374451
Validation loss: 1.8630431262395715

Epoch: 5| Step: 10
Training loss: 1.660273551940918
Validation loss: 1.8750535236891879

Epoch: 335| Step: 0
Training loss: 1.6912133693695068
Validation loss: 1.8729583037796842

Epoch: 5| Step: 1
Training loss: 1.3213984966278076
Validation loss: 1.8289301626143917

Epoch: 5| Step: 2
Training loss: 1.2509353160858154
Validation loss: 1.8292213191268265

Epoch: 5| Step: 3
Training loss: 1.4361286163330078
Validation loss: 1.861355786682457

Epoch: 5| Step: 4
Training loss: 1.5893075466156006
Validation loss: 1.8494736725284207

Epoch: 5| Step: 5
Training loss: 1.4516240358352661
Validation loss: 1.7931558239844538

Epoch: 5| Step: 6
Training loss: 1.641785979270935
Validation loss: 1.8138511001422841

Epoch: 5| Step: 7
Training loss: 1.5132725238800049
Validation loss: 1.864369846159412

Epoch: 5| Step: 8
Training loss: 1.4900187253952026
Validation loss: 1.8889365068045996

Epoch: 5| Step: 9
Training loss: 2.133845567703247
Validation loss: 1.8654063286319855

Epoch: 5| Step: 10
Training loss: 2.1027581691741943
Validation loss: 1.8332364507900771

Epoch: 336| Step: 0
Training loss: 1.4858449697494507
Validation loss: 1.8356545971285911

Epoch: 5| Step: 1
Training loss: 1.8169151544570923
Validation loss: 1.8646221186525078

Epoch: 5| Step: 2
Training loss: 0.8771787881851196
Validation loss: 1.8224519965469197

Epoch: 5| Step: 3
Training loss: 1.4744970798492432
Validation loss: 1.8471974916355585

Epoch: 5| Step: 4
Training loss: 2.402618885040283
Validation loss: 1.8221871109418972

Epoch: 5| Step: 5
Training loss: 1.5427067279815674
Validation loss: 1.8596998735140728

Epoch: 5| Step: 6
Training loss: 1.6787567138671875
Validation loss: 1.816451197029442

Epoch: 5| Step: 7
Training loss: 0.9925386309623718
Validation loss: 1.8727905724638252

Epoch: 5| Step: 8
Training loss: 1.767122507095337
Validation loss: 1.8407469590504963

Epoch: 5| Step: 9
Training loss: 1.6668555736541748
Validation loss: 1.8460925381670716

Epoch: 5| Step: 10
Training loss: 1.5573140382766724
Validation loss: 1.8379920605690248

Epoch: 337| Step: 0
Training loss: 1.259458303451538
Validation loss: 1.8405542322384414

Epoch: 5| Step: 1
Training loss: 1.4545100927352905
Validation loss: 1.8185933046443488

Epoch: 5| Step: 2
Training loss: 1.0471251010894775
Validation loss: 1.8675052324930828

Epoch: 5| Step: 3
Training loss: 1.8047316074371338
Validation loss: 1.866989968925394

Epoch: 5| Step: 4
Training loss: 1.303984522819519
Validation loss: 1.8323769210487284

Epoch: 5| Step: 5
Training loss: 1.8511936664581299
Validation loss: 1.7905175429518505

Epoch: 5| Step: 6
Training loss: 1.5814242362976074
Validation loss: 1.8295106118725193

Epoch: 5| Step: 7
Training loss: 1.271611213684082
Validation loss: 1.8098051855641026

Epoch: 5| Step: 8
Training loss: 1.3869879245758057
Validation loss: 1.8009016154914774

Epoch: 5| Step: 9
Training loss: 2.440028667449951
Validation loss: 1.8820465303236438

Epoch: 5| Step: 10
Training loss: 1.325440526008606
Validation loss: 1.8254088022375619

Epoch: 338| Step: 0
Training loss: 1.250030755996704
Validation loss: 1.8743397010269987

Epoch: 5| Step: 1
Training loss: 2.6366562843322754
Validation loss: 1.8145458775181924

Epoch: 5| Step: 2
Training loss: 1.7246544361114502
Validation loss: 1.871350803682881

Epoch: 5| Step: 3
Training loss: 1.1106781959533691
Validation loss: 1.8825790753928564

Epoch: 5| Step: 4
Training loss: 1.1420118808746338
Validation loss: 1.841615640988914

Epoch: 5| Step: 5
Training loss: 1.6948268413543701
Validation loss: 1.8793245797516198

Epoch: 5| Step: 6
Training loss: 1.5877113342285156
Validation loss: 1.8559952730773597

Epoch: 5| Step: 7
Training loss: 1.8977813720703125
Validation loss: 1.8558808347230316

Epoch: 5| Step: 8
Training loss: 1.4989155530929565
Validation loss: 1.9041297858761204

Epoch: 5| Step: 9
Training loss: 1.0309339761734009
Validation loss: 1.8905100181538572

Epoch: 5| Step: 10
Training loss: 1.530799388885498
Validation loss: 1.8252919976429274

Epoch: 339| Step: 0
Training loss: 1.511651873588562
Validation loss: 1.8826734917138213

Epoch: 5| Step: 1
Training loss: 1.6732738018035889
Validation loss: 1.8585538030952535

Epoch: 5| Step: 2
Training loss: 1.8002914190292358
Validation loss: 1.848145998934264

Epoch: 5| Step: 3
Training loss: 1.1404640674591064
Validation loss: 1.865272541199961

Epoch: 5| Step: 4
Training loss: 1.0657379627227783
Validation loss: 1.865802041945919

Epoch: 5| Step: 5
Training loss: 1.912095308303833
Validation loss: 1.8839065156957155

Epoch: 5| Step: 6
Training loss: 1.8575754165649414
Validation loss: 1.8455626964569092

Epoch: 5| Step: 7
Training loss: 1.5712335109710693
Validation loss: 1.850834156877251

Epoch: 5| Step: 8
Training loss: 1.5653672218322754
Validation loss: 1.817809053646621

Epoch: 5| Step: 9
Training loss: 1.6012359857559204
Validation loss: 1.86467864436488

Epoch: 5| Step: 10
Training loss: 1.7276960611343384
Validation loss: 1.7766819653972503

Epoch: 340| Step: 0
Training loss: 0.8956966400146484
Validation loss: 1.8455758902334398

Epoch: 5| Step: 1
Training loss: 1.2993900775909424
Validation loss: 1.8556130675859348

Epoch: 5| Step: 2
Training loss: 1.3522093296051025
Validation loss: 1.8102717604688419

Epoch: 5| Step: 3
Training loss: 1.8279640674591064
Validation loss: 1.839420239130656

Epoch: 5| Step: 4
Training loss: 1.2202788591384888
Validation loss: 1.7908577867733535

Epoch: 5| Step: 5
Training loss: 1.588172435760498
Validation loss: 1.8276294098105481

Epoch: 5| Step: 6
Training loss: 1.529252529144287
Validation loss: 1.8395087193417292

Epoch: 5| Step: 7
Training loss: 1.9427295923233032
Validation loss: 1.8423574316886164

Epoch: 5| Step: 8
Training loss: 1.385610580444336
Validation loss: 1.8851928352027811

Epoch: 5| Step: 9
Training loss: 1.452813744544983
Validation loss: 1.8884755834456413

Epoch: 5| Step: 10
Training loss: 2.5328292846679688
Validation loss: 1.884729286675812

Epoch: 341| Step: 0
Training loss: 1.9824469089508057
Validation loss: 1.8792107887165521

Epoch: 5| Step: 1
Training loss: 1.7251436710357666
Validation loss: 1.882119845318538

Epoch: 5| Step: 2
Training loss: 1.2971086502075195
Validation loss: 1.8368860611351587

Epoch: 5| Step: 3
Training loss: 0.9374990463256836
Validation loss: 1.8696726624683668

Epoch: 5| Step: 4
Training loss: 1.5879623889923096
Validation loss: 1.854425617443618

Epoch: 5| Step: 5
Training loss: 1.0965465307235718
Validation loss: 1.817387721871817

Epoch: 5| Step: 6
Training loss: 1.4415863752365112
Validation loss: 1.8247737615339217

Epoch: 5| Step: 7
Training loss: 1.6443630456924438
Validation loss: 1.8359663332662275

Epoch: 5| Step: 8
Training loss: 1.7902721166610718
Validation loss: 1.831765031301847

Epoch: 5| Step: 9
Training loss: 1.7955032587051392
Validation loss: 1.909126917521159

Epoch: 5| Step: 10
Training loss: 1.924896240234375
Validation loss: 1.8334339177736672

Epoch: 342| Step: 0
Training loss: 1.9800586700439453
Validation loss: 1.827651208446872

Epoch: 5| Step: 1
Training loss: 1.5823503732681274
Validation loss: 1.8578208620830248

Epoch: 5| Step: 2
Training loss: 1.9655317068099976
Validation loss: 1.8453761787824734

Epoch: 5| Step: 3
Training loss: 1.314833164215088
Validation loss: 1.8159863641185146

Epoch: 5| Step: 4
Training loss: 1.6790993213653564
Validation loss: 1.842109735294055

Epoch: 5| Step: 5
Training loss: 1.3327733278274536
Validation loss: 1.7812415656223093

Epoch: 5| Step: 6
Training loss: 1.411168098449707
Validation loss: 1.8385029608203518

Epoch: 5| Step: 7
Training loss: 0.9267122149467468
Validation loss: 1.8200592507598221

Epoch: 5| Step: 8
Training loss: 1.543581247329712
Validation loss: 1.8545033880459365

Epoch: 5| Step: 9
Training loss: 1.141070008277893
Validation loss: 1.811251478810464

Epoch: 5| Step: 10
Training loss: 2.3010425567626953
Validation loss: 1.816950963389489

Epoch: 343| Step: 0
Training loss: 1.6899954080581665
Validation loss: 1.849223361220411

Epoch: 5| Step: 1
Training loss: 1.5087502002716064
Validation loss: 1.8517706983832902

Epoch: 5| Step: 2
Training loss: 1.09784734249115
Validation loss: 1.8376784811737716

Epoch: 5| Step: 3
Training loss: 1.8737554550170898
Validation loss: 1.841503797038909

Epoch: 5| Step: 4
Training loss: 1.8492157459259033
Validation loss: 1.8100914967957364

Epoch: 5| Step: 5
Training loss: 1.3604388236999512
Validation loss: 1.7959846745255172

Epoch: 5| Step: 6
Training loss: 1.4759438037872314
Validation loss: 1.8648568353345316

Epoch: 5| Step: 7
Training loss: 1.4739850759506226
Validation loss: 1.8481852674996981

Epoch: 5| Step: 8
Training loss: 1.7912654876708984
Validation loss: 1.830079718302655

Epoch: 5| Step: 9
Training loss: 1.7853132486343384
Validation loss: 1.8127394401898949

Epoch: 5| Step: 10
Training loss: 1.0889732837677002
Validation loss: 1.8195039738890946

Epoch: 344| Step: 0
Training loss: 1.585663080215454
Validation loss: 1.8103271453611312

Epoch: 5| Step: 1
Training loss: 1.5773816108703613
Validation loss: 1.800154879528989

Epoch: 5| Step: 2
Training loss: 2.091669797897339
Validation loss: 1.7337671838780886

Epoch: 5| Step: 3
Training loss: 1.3587353229522705
Validation loss: 1.7822067968307003

Epoch: 5| Step: 4
Training loss: 1.6867058277130127
Validation loss: 1.8359867462547876

Epoch: 5| Step: 5
Training loss: 1.8416532278060913
Validation loss: 1.8201112119100427

Epoch: 5| Step: 6
Training loss: 1.803950548171997
Validation loss: 1.8558793811387913

Epoch: 5| Step: 7
Training loss: 0.8997367024421692
Validation loss: 1.8743178921361123

Epoch: 5| Step: 8
Training loss: 1.3303102254867554
Validation loss: 1.8491731100184943

Epoch: 5| Step: 9
Training loss: 1.7267833948135376
Validation loss: 1.8218010817804644

Epoch: 5| Step: 10
Training loss: 1.3503754138946533
Validation loss: 1.869597747761716

Epoch: 345| Step: 0
Training loss: 1.8504610061645508
Validation loss: 1.8481813271840413

Epoch: 5| Step: 1
Training loss: 1.4895433187484741
Validation loss: 1.831071057627278

Epoch: 5| Step: 2
Training loss: 1.8596560955047607
Validation loss: 1.8454143975370674

Epoch: 5| Step: 3
Training loss: 1.373225450515747
Validation loss: 1.8650995351934945

Epoch: 5| Step: 4
Training loss: 1.170253038406372
Validation loss: 1.83453703952092

Epoch: 5| Step: 5
Training loss: 1.623954176902771
Validation loss: 1.8257374237942439

Epoch: 5| Step: 6
Training loss: 1.8968188762664795
Validation loss: 1.8551675786254227

Epoch: 5| Step: 7
Training loss: 1.2153129577636719
Validation loss: 1.8722923981246127

Epoch: 5| Step: 8
Training loss: 1.2213375568389893
Validation loss: 1.8137099025070027

Epoch: 5| Step: 9
Training loss: 1.9923473596572876
Validation loss: 1.7991728564744354

Epoch: 5| Step: 10
Training loss: 1.594592571258545
Validation loss: 1.8440261810056624

Epoch: 346| Step: 0
Training loss: 1.655928611755371
Validation loss: 1.8265778377491941

Epoch: 5| Step: 1
Training loss: 1.600327730178833
Validation loss: 1.835939532967024

Epoch: 5| Step: 2
Training loss: 1.444475769996643
Validation loss: 1.8389056216004074

Epoch: 5| Step: 3
Training loss: 1.3935470581054688
Validation loss: 1.887639327715802

Epoch: 5| Step: 4
Training loss: 1.2844682931900024
Validation loss: 1.7685920192349343

Epoch: 5| Step: 5
Training loss: 1.1416561603546143
Validation loss: 1.817522644996643

Epoch: 5| Step: 6
Training loss: 1.2823154926300049
Validation loss: 1.8544151988080753

Epoch: 5| Step: 7
Training loss: 1.6752521991729736
Validation loss: 1.9105931558916647

Epoch: 5| Step: 8
Training loss: 1.702122449874878
Validation loss: 1.8663432354568152

Epoch: 5| Step: 9
Training loss: 2.4071218967437744
Validation loss: 1.7906666891549223

Epoch: 5| Step: 10
Training loss: 1.5354243516921997
Validation loss: 1.8448992788150747

Epoch: 347| Step: 0
Training loss: 1.4036465883255005
Validation loss: 1.8181816249765375

Epoch: 5| Step: 1
Training loss: 2.0292251110076904
Validation loss: 1.8067173137459704

Epoch: 5| Step: 2
Training loss: 1.6684767007827759
Validation loss: 1.8006857518226869

Epoch: 5| Step: 3
Training loss: 1.4494677782058716
Validation loss: 1.812934785760859

Epoch: 5| Step: 4
Training loss: 1.635960340499878
Validation loss: 1.8514460158604447

Epoch: 5| Step: 5
Training loss: 1.7542235851287842
Validation loss: 1.8019129871040263

Epoch: 5| Step: 6
Training loss: 1.947186827659607
Validation loss: 1.7943505279479488

Epoch: 5| Step: 7
Training loss: 1.5926169157028198
Validation loss: 1.8454813136849353

Epoch: 5| Step: 8
Training loss: 1.6062242984771729
Validation loss: 1.815477890353049

Epoch: 5| Step: 9
Training loss: 1.0805222988128662
Validation loss: 1.8585219331966933

Epoch: 5| Step: 10
Training loss: 1.1425237655639648
Validation loss: 1.8142182967996086

Epoch: 348| Step: 0
Training loss: 1.3217326402664185
Validation loss: 1.773442493971958

Epoch: 5| Step: 1
Training loss: 1.7638742923736572
Validation loss: 1.8206347650097263

Epoch: 5| Step: 2
Training loss: 1.668823003768921
Validation loss: 1.8244046203551754

Epoch: 5| Step: 3
Training loss: 1.6756376028060913
Validation loss: 1.810860304422276

Epoch: 5| Step: 4
Training loss: 1.6764144897460938
Validation loss: 1.8687874412023893

Epoch: 5| Step: 5
Training loss: 1.4971753358840942
Validation loss: 1.8717128487043484

Epoch: 5| Step: 6
Training loss: 1.447473168373108
Validation loss: 1.827366969918692

Epoch: 5| Step: 7
Training loss: 1.1645700931549072
Validation loss: 1.8676435588508524

Epoch: 5| Step: 8
Training loss: 1.7529799938201904
Validation loss: 1.8560175844418105

Epoch: 5| Step: 9
Training loss: 1.268021821975708
Validation loss: 1.9444983595161027

Epoch: 5| Step: 10
Training loss: 1.9540364742279053
Validation loss: 1.8713811700062086

Epoch: 349| Step: 0
Training loss: 1.3263225555419922
Validation loss: 1.8915336747323312

Epoch: 5| Step: 1
Training loss: 1.396109938621521
Validation loss: 1.9075597050369426

Epoch: 5| Step: 2
Training loss: 1.6721792221069336
Validation loss: 1.8927559750054472

Epoch: 5| Step: 3
Training loss: 1.7591989040374756
Validation loss: 1.8165984371657014

Epoch: 5| Step: 4
Training loss: 1.5321277379989624
Validation loss: 1.792684555053711

Epoch: 5| Step: 5
Training loss: 1.4296802282333374
Validation loss: 1.803878814943375

Epoch: 5| Step: 6
Training loss: 1.5924583673477173
Validation loss: 1.8403389441069735

Epoch: 5| Step: 7
Training loss: 1.6695473194122314
Validation loss: 1.8444288930585306

Epoch: 5| Step: 8
Training loss: 1.5127147436141968
Validation loss: 1.8361962867039505

Epoch: 5| Step: 9
Training loss: 1.4297069311141968
Validation loss: 1.7661017807581092

Epoch: 5| Step: 10
Training loss: 1.8204187154769897
Validation loss: 1.7816430420003913

Epoch: 350| Step: 0
Training loss: 1.1429541110992432
Validation loss: 1.8003529053862377

Epoch: 5| Step: 1
Training loss: 1.8437063694000244
Validation loss: 1.7963291227176625

Epoch: 5| Step: 2
Training loss: 1.756173849105835
Validation loss: 1.829623551778896

Epoch: 5| Step: 3
Training loss: 1.7971560955047607
Validation loss: 1.826723457664572

Epoch: 5| Step: 4
Training loss: 1.261533498764038
Validation loss: 1.8405355279163649

Epoch: 5| Step: 5
Training loss: 1.2931654453277588
Validation loss: 1.8212749381219187

Epoch: 5| Step: 6
Training loss: 1.6560789346694946
Validation loss: 1.825706979279877

Epoch: 5| Step: 7
Training loss: 1.3276269435882568
Validation loss: 1.8521170590513496

Epoch: 5| Step: 8
Training loss: 1.8104006052017212
Validation loss: 1.869424040599536

Epoch: 5| Step: 9
Training loss: 1.6365197896957397
Validation loss: 1.8251332941875662

Epoch: 5| Step: 10
Training loss: 1.075920581817627
Validation loss: 1.8652703403144755

Epoch: 351| Step: 0
Training loss: 1.762442946434021
Validation loss: 1.8579457703457083

Epoch: 5| Step: 1
Training loss: 1.2876752614974976
Validation loss: 1.9139798571986537

Epoch: 5| Step: 2
Training loss: 1.7216625213623047
Validation loss: 1.868526776631673

Epoch: 5| Step: 3
Training loss: 1.7850234508514404
Validation loss: 1.8761584207575808

Epoch: 5| Step: 4
Training loss: 1.3534801006317139
Validation loss: 1.8404885735563052

Epoch: 5| Step: 5
Training loss: 1.3976860046386719
Validation loss: 1.8788742583285096

Epoch: 5| Step: 6
Training loss: 1.3266607522964478
Validation loss: 1.844416965720474

Epoch: 5| Step: 7
Training loss: 1.8139556646347046
Validation loss: 1.8900652290672384

Epoch: 5| Step: 8
Training loss: 1.7380154132843018
Validation loss: 1.8561247753840622

Epoch: 5| Step: 9
Training loss: 1.3316723108291626
Validation loss: 1.8157883638976722

Epoch: 5| Step: 10
Training loss: 1.7940950393676758
Validation loss: 1.858673390521798

Epoch: 352| Step: 0
Training loss: 1.65896475315094
Validation loss: 1.7922306663246566

Epoch: 5| Step: 1
Training loss: 1.532943844795227
Validation loss: 1.8159683032702374

Epoch: 5| Step: 2
Training loss: 2.0814640522003174
Validation loss: 1.8093193372090657

Epoch: 5| Step: 3
Training loss: 1.9510536193847656
Validation loss: 1.7764300812957108

Epoch: 5| Step: 4
Training loss: 1.3118773698806763
Validation loss: 1.7924266515239593

Epoch: 5| Step: 5
Training loss: 1.7987617254257202
Validation loss: 1.846433283180319

Epoch: 5| Step: 6
Training loss: 1.4197250604629517
Validation loss: 1.7809695992418515

Epoch: 5| Step: 7
Training loss: 1.4741483926773071
Validation loss: 1.7886806431637015

Epoch: 5| Step: 8
Training loss: 1.4159425497055054
Validation loss: 1.8204598862637755

Epoch: 5| Step: 9
Training loss: 1.3057588338851929
Validation loss: 1.8592002648179249

Epoch: 5| Step: 10
Training loss: 1.473616600036621
Validation loss: 1.768998384475708

Epoch: 353| Step: 0
Training loss: 1.3313300609588623
Validation loss: 1.841929699784966

Epoch: 5| Step: 1
Training loss: 1.5769239664077759
Validation loss: 1.7699499258431055

Epoch: 5| Step: 2
Training loss: 2.0446529388427734
Validation loss: 1.8434309241592244

Epoch: 5| Step: 3
Training loss: 1.008697509765625
Validation loss: 1.8736875659676009

Epoch: 5| Step: 4
Training loss: 1.5666388273239136
Validation loss: 1.8825666353266726

Epoch: 5| Step: 5
Training loss: 1.3600881099700928
Validation loss: 1.8619950612386067

Epoch: 5| Step: 6
Training loss: 1.492712140083313
Validation loss: 1.847102931750718

Epoch: 5| Step: 7
Training loss: 1.7624047994613647
Validation loss: 1.887871855048723

Epoch: 5| Step: 8
Training loss: 1.4939152002334595
Validation loss: 1.8687852685169508

Epoch: 5| Step: 9
Training loss: 1.5239357948303223
Validation loss: 1.808864665287797

Epoch: 5| Step: 10
Training loss: 1.9411473274230957
Validation loss: 1.7562147109739241

Epoch: 354| Step: 0
Training loss: 1.779123067855835
Validation loss: 1.8683408537218649

Epoch: 5| Step: 1
Training loss: 1.5291463136672974
Validation loss: 1.8141252917628135

Epoch: 5| Step: 2
Training loss: 1.5883915424346924
Validation loss: 1.8448815525219004

Epoch: 5| Step: 3
Training loss: 1.786176085472107
Validation loss: 1.8283206314168952

Epoch: 5| Step: 4
Training loss: 1.8980653285980225
Validation loss: 1.7884530918572539

Epoch: 5| Step: 5
Training loss: 1.2977547645568848
Validation loss: 1.8040892680486043

Epoch: 5| Step: 6
Training loss: 1.1882559061050415
Validation loss: 1.872713053098289

Epoch: 5| Step: 7
Training loss: 1.172353982925415
Validation loss: 1.8267481609057354

Epoch: 5| Step: 8
Training loss: 1.6174571514129639
Validation loss: 1.8224471358842746

Epoch: 5| Step: 9
Training loss: 1.3925724029541016
Validation loss: 1.8269927886224562

Epoch: 5| Step: 10
Training loss: 2.1295409202575684
Validation loss: 1.7965905922715382

Epoch: 355| Step: 0
Training loss: 1.725935935974121
Validation loss: 1.815468325409838

Epoch: 5| Step: 1
Training loss: 1.4292892217636108
Validation loss: 1.8353566597866755

Epoch: 5| Step: 2
Training loss: 1.4493944644927979
Validation loss: 1.8289998769760132

Epoch: 5| Step: 3
Training loss: 1.9226211309432983
Validation loss: 1.857103076032413

Epoch: 5| Step: 4
Training loss: 1.6392886638641357
Validation loss: 1.8400715115249797

Epoch: 5| Step: 5
Training loss: 1.6690576076507568
Validation loss: 1.8387578866815055

Epoch: 5| Step: 6
Training loss: 1.8027019500732422
Validation loss: 1.861544568051574

Epoch: 5| Step: 7
Training loss: 1.1316499710083008
Validation loss: 1.8537858481048255

Epoch: 5| Step: 8
Training loss: 1.4772913455963135
Validation loss: 1.844581292521569

Epoch: 5| Step: 9
Training loss: 1.1658952236175537
Validation loss: 1.8769559168046521

Epoch: 5| Step: 10
Training loss: 1.7293932437896729
Validation loss: 1.8091716740721016

Epoch: 356| Step: 0
Training loss: 1.3331620693206787
Validation loss: 1.8461003200982207

Epoch: 5| Step: 1
Training loss: 1.6659759283065796
Validation loss: 1.8300766893612441

Epoch: 5| Step: 2
Training loss: 0.8920220136642456
Validation loss: 1.8158352874940442

Epoch: 5| Step: 3
Training loss: 1.7440866231918335
Validation loss: 1.8614833560041202

Epoch: 5| Step: 4
Training loss: 1.4304683208465576
Validation loss: 1.8339369297027588

Epoch: 5| Step: 5
Training loss: 1.1445810794830322
Validation loss: 1.7957246893195695

Epoch: 5| Step: 6
Training loss: 1.224077582359314
Validation loss: 1.8705912507990354

Epoch: 5| Step: 7
Training loss: 1.867919921875
Validation loss: 1.8597739819557435

Epoch: 5| Step: 8
Training loss: 1.9285236597061157
Validation loss: 1.8182067076365154

Epoch: 5| Step: 9
Training loss: 1.987845778465271
Validation loss: 1.8268373550907258

Epoch: 5| Step: 10
Training loss: 1.4811309576034546
Validation loss: 1.7647015792067333

Epoch: 357| Step: 0
Training loss: 1.3571113348007202
Validation loss: 1.733791321836492

Epoch: 5| Step: 1
Training loss: 1.9142080545425415
Validation loss: 1.8636664190599996

Epoch: 5| Step: 2
Training loss: 0.9870710372924805
Validation loss: 1.821510486705329

Epoch: 5| Step: 3
Training loss: 1.8795433044433594
Validation loss: 1.8000744427404096

Epoch: 5| Step: 4
Training loss: 1.7265369892120361
Validation loss: 1.8369296186713762

Epoch: 5| Step: 5
Training loss: 1.513122797012329
Validation loss: 1.8573177411992063

Epoch: 5| Step: 6
Training loss: 1.204616665840149
Validation loss: 1.8134027040132912

Epoch: 5| Step: 7
Training loss: 1.7247896194458008
Validation loss: 1.847539588969241

Epoch: 5| Step: 8
Training loss: 1.314633846282959
Validation loss: 1.838102840608166

Epoch: 5| Step: 9
Training loss: 1.202053427696228
Validation loss: 1.828820001694464

Epoch: 5| Step: 10
Training loss: 1.6500623226165771
Validation loss: 1.8384370393650507

Epoch: 358| Step: 0
Training loss: 1.6718814373016357
Validation loss: 1.8320673204237414

Epoch: 5| Step: 1
Training loss: 1.3445286750793457
Validation loss: 1.8249386074722453

Epoch: 5| Step: 2
Training loss: 1.2876310348510742
Validation loss: 1.8716615207733647

Epoch: 5| Step: 3
Training loss: 2.176027536392212
Validation loss: 1.875233591243785

Epoch: 5| Step: 4
Training loss: 1.5393788814544678
Validation loss: 1.8316912420334355

Epoch: 5| Step: 5
Training loss: 1.640953779220581
Validation loss: 1.8489722141655542

Epoch: 5| Step: 6
Training loss: 1.4175450801849365
Validation loss: 1.855357152159496

Epoch: 5| Step: 7
Training loss: 1.1782692670822144
Validation loss: 1.8149640521695536

Epoch: 5| Step: 8
Training loss: 1.848299264907837
Validation loss: 1.8226897716522217

Epoch: 5| Step: 9
Training loss: 1.2478066682815552
Validation loss: 1.8316271240993212

Epoch: 5| Step: 10
Training loss: 1.3432568311691284
Validation loss: 1.8281606679321618

Epoch: 359| Step: 0
Training loss: 0.8974038362503052
Validation loss: 1.8048411505196684

Epoch: 5| Step: 1
Training loss: 1.8743915557861328
Validation loss: 1.8241559074771019

Epoch: 5| Step: 2
Training loss: 1.4232714176177979
Validation loss: 1.8189724119760657

Epoch: 5| Step: 3
Training loss: 1.2476505041122437
Validation loss: 1.8088213166882914

Epoch: 5| Step: 4
Training loss: 1.899280309677124
Validation loss: 1.8800095294111518

Epoch: 5| Step: 5
Training loss: 2.017127752304077
Validation loss: 1.7733531267412248

Epoch: 5| Step: 6
Training loss: 1.2914512157440186
Validation loss: 1.7585921748991935

Epoch: 5| Step: 7
Training loss: 1.5061066150665283
Validation loss: 1.7801818975838282

Epoch: 5| Step: 8
Training loss: 1.6008415222167969
Validation loss: 1.8088441869264007

Epoch: 5| Step: 9
Training loss: 0.9548214077949524
Validation loss: 1.843607815363074

Epoch: 5| Step: 10
Training loss: 2.031343698501587
Validation loss: 1.9057577117796867

Epoch: 360| Step: 0
Training loss: 1.2144291400909424
Validation loss: 1.811281365732993

Epoch: 5| Step: 1
Training loss: 1.1462841033935547
Validation loss: 1.852677377321387

Epoch: 5| Step: 2
Training loss: 1.7001278400421143
Validation loss: 1.906531277523246

Epoch: 5| Step: 3
Training loss: 2.094942569732666
Validation loss: 1.8666443952950098

Epoch: 5| Step: 4
Training loss: 1.5587348937988281
Validation loss: 1.8324195902834657

Epoch: 5| Step: 5
Training loss: 1.443781852722168
Validation loss: 1.8070134257757535

Epoch: 5| Step: 6
Training loss: 1.71636962890625
Validation loss: 1.8017254401278753

Epoch: 5| Step: 7
Training loss: 1.2820111513137817
Validation loss: 1.8096919008480605

Epoch: 5| Step: 8
Training loss: 1.0832545757293701
Validation loss: 1.781685011361235

Epoch: 5| Step: 9
Training loss: 1.7540283203125
Validation loss: 1.8426065803855978

Epoch: 5| Step: 10
Training loss: 1.8756945133209229
Validation loss: 1.8517546730656778

Epoch: 361| Step: 0
Training loss: 1.3370351791381836
Validation loss: 1.8474363998700214

Epoch: 5| Step: 1
Training loss: 1.5555123090744019
Validation loss: 1.8471675149856075

Epoch: 5| Step: 2
Training loss: 1.3288540840148926
Validation loss: 1.8314966360727947

Epoch: 5| Step: 3
Training loss: 1.468435287475586
Validation loss: 1.8221977192868468

Epoch: 5| Step: 4
Training loss: 2.134359836578369
Validation loss: 1.7895241091328282

Epoch: 5| Step: 5
Training loss: 1.6155102252960205
Validation loss: 1.831015145906838

Epoch: 5| Step: 6
Training loss: 1.3974113464355469
Validation loss: 1.8302646324198732

Epoch: 5| Step: 7
Training loss: 1.8116642236709595
Validation loss: 1.7962277627760364

Epoch: 5| Step: 8
Training loss: 1.073987364768982
Validation loss: 1.8072156213944959

Epoch: 5| Step: 9
Training loss: 0.9085448980331421
Validation loss: 1.8556942862849082

Epoch: 5| Step: 10
Training loss: 2.214094638824463
Validation loss: 1.8209938900445097

Epoch: 362| Step: 0
Training loss: 1.0217589139938354
Validation loss: 1.8617833173403175

Epoch: 5| Step: 1
Training loss: 1.4690260887145996
Validation loss: 1.8057525696293

Epoch: 5| Step: 2
Training loss: 1.6697165966033936
Validation loss: 1.7866941049534788

Epoch: 5| Step: 3
Training loss: 1.1633201837539673
Validation loss: 1.8758927878513132

Epoch: 5| Step: 4
Training loss: 1.9574339389801025
Validation loss: 1.7917250279457337

Epoch: 5| Step: 5
Training loss: 0.9727503061294556
Validation loss: 1.867559366328742

Epoch: 5| Step: 6
Training loss: 1.7467296123504639
Validation loss: 1.877327178114204

Epoch: 5| Step: 7
Training loss: 1.5575759410858154
Validation loss: 1.8368906231336697

Epoch: 5| Step: 8
Training loss: 2.0667054653167725
Validation loss: 1.8442783727440784

Epoch: 5| Step: 9
Training loss: 1.6801971197128296
Validation loss: 1.8052538133436633

Epoch: 5| Step: 10
Training loss: 1.3432142734527588
Validation loss: 1.8303746202940583

Epoch: 363| Step: 0
Training loss: 0.87116938829422
Validation loss: 1.8334104784073368

Epoch: 5| Step: 1
Training loss: 1.1287128925323486
Validation loss: 1.8253329851294076

Epoch: 5| Step: 2
Training loss: 1.884590744972229
Validation loss: 1.8442909922651065

Epoch: 5| Step: 3
Training loss: 1.0926059484481812
Validation loss: 1.8347331080385434

Epoch: 5| Step: 4
Training loss: 1.8037338256835938
Validation loss: 1.8307959571961434

Epoch: 5| Step: 5
Training loss: 0.9383689165115356
Validation loss: 1.8004556227755804

Epoch: 5| Step: 6
Training loss: 1.4981417655944824
Validation loss: 1.8345414605191959

Epoch: 5| Step: 7
Training loss: 2.1767001152038574
Validation loss: 1.7758303073144728

Epoch: 5| Step: 8
Training loss: 2.040527105331421
Validation loss: 1.8307699029163649

Epoch: 5| Step: 9
Training loss: 1.7352062463760376
Validation loss: 1.7743206934262348

Epoch: 5| Step: 10
Training loss: 1.671922206878662
Validation loss: 1.798358776236093

Epoch: 364| Step: 0
Training loss: 1.4046134948730469
Validation loss: 1.7800889348471036

Epoch: 5| Step: 1
Training loss: 1.8707606792449951
Validation loss: 1.7614794187648322

Epoch: 5| Step: 2
Training loss: 1.3289358615875244
Validation loss: 1.8319058020909627

Epoch: 5| Step: 3
Training loss: 1.2938450574874878
Validation loss: 1.806468597022436

Epoch: 5| Step: 4
Training loss: 1.327497124671936
Validation loss: 1.8545869012032785

Epoch: 5| Step: 5
Training loss: 1.6292946338653564
Validation loss: 1.8294469912846882

Epoch: 5| Step: 6
Training loss: 1.4540349245071411
Validation loss: 1.7614315453396048

Epoch: 5| Step: 7
Training loss: 1.4722411632537842
Validation loss: 1.8526301871063888

Epoch: 5| Step: 8
Training loss: 1.1777284145355225
Validation loss: 1.8201477989073722

Epoch: 5| Step: 9
Training loss: 1.8920196294784546
Validation loss: 1.847999962427283

Epoch: 5| Step: 10
Training loss: 1.846567988395691
Validation loss: 1.8433293552808865

Epoch: 365| Step: 0
Training loss: 1.2229347229003906
Validation loss: 1.8459774781298894

Epoch: 5| Step: 1
Training loss: 1.760654091835022
Validation loss: 1.860239263503782

Epoch: 5| Step: 2
Training loss: 1.8846909999847412
Validation loss: 1.8105645833476898

Epoch: 5| Step: 3
Training loss: 1.66945481300354
Validation loss: 1.8465029244781823

Epoch: 5| Step: 4
Training loss: 1.786090612411499
Validation loss: 1.8157220155962053

Epoch: 5| Step: 5
Training loss: 1.1675440073013306
Validation loss: 1.816031761066888

Epoch: 5| Step: 6
Training loss: 1.2129472494125366
Validation loss: 1.8118447219171832

Epoch: 5| Step: 7
Training loss: 1.8333337306976318
Validation loss: 1.7591403530490013

Epoch: 5| Step: 8
Training loss: 1.4961286783218384
Validation loss: 1.8324762710960962

Epoch: 5| Step: 9
Training loss: 1.7140769958496094
Validation loss: 1.8510330864178237

Epoch: 5| Step: 10
Training loss: 0.9098513126373291
Validation loss: 1.803483731003218

Epoch: 366| Step: 0
Training loss: 1.5014184713363647
Validation loss: 1.7810179469405965

Epoch: 5| Step: 1
Training loss: 1.0346282720565796
Validation loss: 1.8034411989232546

Epoch: 5| Step: 2
Training loss: 1.704878568649292
Validation loss: 1.8153493301842802

Epoch: 5| Step: 3
Training loss: 1.4456062316894531
Validation loss: 1.8219704589536112

Epoch: 5| Step: 4
Training loss: 1.50223708152771
Validation loss: 1.8784008269668908

Epoch: 5| Step: 5
Training loss: 1.9393103122711182
Validation loss: 1.867663486029512

Epoch: 5| Step: 6
Training loss: 2.019819974899292
Validation loss: 1.8198721383207588

Epoch: 5| Step: 7
Training loss: 1.6461560726165771
Validation loss: 1.8270535674146426

Epoch: 5| Step: 8
Training loss: 1.4793815612792969
Validation loss: 1.8370290879280335

Epoch: 5| Step: 9
Training loss: 1.3207123279571533
Validation loss: 1.8349027441393944

Epoch: 5| Step: 10
Training loss: 0.9996289610862732
Validation loss: 1.7939763056334628

Epoch: 367| Step: 0
Training loss: 1.1988849639892578
Validation loss: 1.8129483730562272

Epoch: 5| Step: 1
Training loss: 1.24251127243042
Validation loss: 1.8743024192830569

Epoch: 5| Step: 2
Training loss: 1.4467453956604004
Validation loss: 1.8242489766049128

Epoch: 5| Step: 3
Training loss: 1.1492427587509155
Validation loss: 1.8425232518103816

Epoch: 5| Step: 4
Training loss: 1.7986739873886108
Validation loss: 1.837798322400739

Epoch: 5| Step: 5
Training loss: 1.5795855522155762
Validation loss: 1.8156878281665105

Epoch: 5| Step: 6
Training loss: 1.7748444080352783
Validation loss: 1.844986254169095

Epoch: 5| Step: 7
Training loss: 1.833815336227417
Validation loss: 1.7961741634594497

Epoch: 5| Step: 8
Training loss: 1.2883710861206055
Validation loss: 1.8572013365325106

Epoch: 5| Step: 9
Training loss: 1.7213661670684814
Validation loss: 1.792987415867467

Epoch: 5| Step: 10
Training loss: 1.5077229738235474
Validation loss: 1.834146092014928

Epoch: 368| Step: 0
Training loss: 1.1763148307800293
Validation loss: 1.8460961208548596

Epoch: 5| Step: 1
Training loss: 1.7036727666854858
Validation loss: 1.832969702700133

Epoch: 5| Step: 2
Training loss: 1.5622265338897705
Validation loss: 1.7849520855052496

Epoch: 5| Step: 3
Training loss: 2.013064384460449
Validation loss: 1.8017668262604745

Epoch: 5| Step: 4
Training loss: 1.4507949352264404
Validation loss: 1.796431479915496

Epoch: 5| Step: 5
Training loss: 1.6976747512817383
Validation loss: 1.8763236461147186

Epoch: 5| Step: 6
Training loss: 1.643972635269165
Validation loss: 1.8274308314887426

Epoch: 5| Step: 7
Training loss: 0.9399407505989075
Validation loss: 1.7828234049581713

Epoch: 5| Step: 8
Training loss: 1.1755592823028564
Validation loss: 1.8593117678037254

Epoch: 5| Step: 9
Training loss: 1.3453651666641235
Validation loss: 1.850266993686717

Epoch: 5| Step: 10
Training loss: 1.6357324123382568
Validation loss: 1.8275999612705682

Epoch: 369| Step: 0
Training loss: 1.7658382654190063
Validation loss: 1.8544277247562204

Epoch: 5| Step: 1
Training loss: 1.8474544286727905
Validation loss: 1.8389653877545429

Epoch: 5| Step: 2
Training loss: 1.1473599672317505
Validation loss: 1.809886779836429

Epoch: 5| Step: 3
Training loss: 1.2404024600982666
Validation loss: 1.8459951544320712

Epoch: 5| Step: 4
Training loss: 2.151564836502075
Validation loss: 1.831501801808675

Epoch: 5| Step: 5
Training loss: 1.1024682521820068
Validation loss: 1.8026546547489781

Epoch: 5| Step: 6
Training loss: 0.871353030204773
Validation loss: 1.8074875634203675

Epoch: 5| Step: 7
Training loss: 1.3881173133850098
Validation loss: 1.8402647331196775

Epoch: 5| Step: 8
Training loss: 1.922044038772583
Validation loss: 1.8059427648462274

Epoch: 5| Step: 9
Training loss: 1.1317838430404663
Validation loss: 1.8583078948400353

Epoch: 5| Step: 10
Training loss: 2.0951972007751465
Validation loss: 1.7970435439899404

Epoch: 370| Step: 0
Training loss: 1.927638053894043
Validation loss: 1.7934946014035134

Epoch: 5| Step: 1
Training loss: 1.3100712299346924
Validation loss: 1.8249146810141943

Epoch: 5| Step: 2
Training loss: 1.6396968364715576
Validation loss: 1.74562301687015

Epoch: 5| Step: 3
Training loss: 1.441120982170105
Validation loss: 1.7911385720775974

Epoch: 5| Step: 4
Training loss: 1.5746691226959229
Validation loss: 1.7896163489228936

Epoch: 5| Step: 5
Training loss: 1.2065749168395996
Validation loss: 1.866559829763187

Epoch: 5| Step: 6
Training loss: 1.377970814704895
Validation loss: 1.8003874722347464

Epoch: 5| Step: 7
Training loss: 1.3805757761001587
Validation loss: 1.8133389667798114

Epoch: 5| Step: 8
Training loss: 1.6939818859100342
Validation loss: 1.7950491302756852

Epoch: 5| Step: 9
Training loss: 1.6166406869888306
Validation loss: 1.8502559046591482

Epoch: 5| Step: 10
Training loss: 1.4347341060638428
Validation loss: 1.777025540669759

Epoch: 371| Step: 0
Training loss: 1.1934157609939575
Validation loss: 1.804258204275562

Epoch: 5| Step: 1
Training loss: 1.9660037755966187
Validation loss: 1.8172922057490195

Epoch: 5| Step: 2
Training loss: 1.625659704208374
Validation loss: 1.8280286071121052

Epoch: 5| Step: 3
Training loss: 1.0937527418136597
Validation loss: 1.7931257204342914

Epoch: 5| Step: 4
Training loss: 1.8848259449005127
Validation loss: 1.815561459910485

Epoch: 5| Step: 5
Training loss: 1.313796043395996
Validation loss: 1.8264942066643828

Epoch: 5| Step: 6
Training loss: 1.2889608144760132
Validation loss: 1.8071249941343903

Epoch: 5| Step: 7
Training loss: 1.7019799947738647
Validation loss: 1.8298660555193502

Epoch: 5| Step: 8
Training loss: 1.0379048585891724
Validation loss: 1.8073521762765863

Epoch: 5| Step: 9
Training loss: 1.7750778198242188
Validation loss: 1.7661240126497002

Epoch: 5| Step: 10
Training loss: 1.6567741632461548
Validation loss: 1.8431635082408946

Epoch: 372| Step: 0
Training loss: 1.6217072010040283
Validation loss: 1.7983583327262633

Epoch: 5| Step: 1
Training loss: 1.0840644836425781
Validation loss: 1.811681297517592

Epoch: 5| Step: 2
Training loss: 1.4766261577606201
Validation loss: 1.8697627629003217

Epoch: 5| Step: 3
Training loss: 1.471954584121704
Validation loss: 1.8702218660744288

Epoch: 5| Step: 4
Training loss: 2.0591368675231934
Validation loss: 1.8290884699872745

Epoch: 5| Step: 5
Training loss: 1.6221449375152588
Validation loss: 1.8370102195329563

Epoch: 5| Step: 6
Training loss: 1.3376209735870361
Validation loss: 1.8497382530602076

Epoch: 5| Step: 7
Training loss: 0.9933822751045227
Validation loss: 1.8330289497170398

Epoch: 5| Step: 8
Training loss: 1.6412553787231445
Validation loss: 1.8164452493831675

Epoch: 5| Step: 9
Training loss: 1.8439964056015015
Validation loss: 1.8568438073640228

Epoch: 5| Step: 10
Training loss: 1.105011224746704
Validation loss: 1.8786869100345078

Epoch: 373| Step: 0
Training loss: 1.3896716833114624
Validation loss: 1.8114869235664286

Epoch: 5| Step: 1
Training loss: 1.1534197330474854
Validation loss: 1.835730396291261

Epoch: 5| Step: 2
Training loss: 1.4221112728118896
Validation loss: 1.7989790003786805

Epoch: 5| Step: 3
Training loss: 1.4756916761398315
Validation loss: 1.8746167229067894

Epoch: 5| Step: 4
Training loss: 1.6939224004745483
Validation loss: 1.8025276250736688

Epoch: 5| Step: 5
Training loss: 1.0555120706558228
Validation loss: 1.8182513329290575

Epoch: 5| Step: 6
Training loss: 1.835921049118042
Validation loss: 1.7872910627754786

Epoch: 5| Step: 7
Training loss: 1.6348035335540771
Validation loss: 1.7981161481590682

Epoch: 5| Step: 8
Training loss: 1.0728939771652222
Validation loss: 1.7919068541578067

Epoch: 5| Step: 9
Training loss: 2.038954019546509
Validation loss: 1.8116838521854852

Epoch: 5| Step: 10
Training loss: 1.5027341842651367
Validation loss: 1.7897466921037244

Epoch: 374| Step: 0
Training loss: 1.4005773067474365
Validation loss: 1.7507940441049554

Epoch: 5| Step: 1
Training loss: 1.133832573890686
Validation loss: 1.8060786608726747

Epoch: 5| Step: 2
Training loss: 1.4987156391143799
Validation loss: 1.7880296258516208

Epoch: 5| Step: 3
Training loss: 1.5193607807159424
Validation loss: 1.798389728351306

Epoch: 5| Step: 4
Training loss: 1.8244540691375732
Validation loss: 1.8018126205731464

Epoch: 5| Step: 5
Training loss: 1.4717963933944702
Validation loss: 1.7846563528942805

Epoch: 5| Step: 6
Training loss: 1.5648362636566162
Validation loss: 1.8095992201118059

Epoch: 5| Step: 7
Training loss: 1.3339555263519287
Validation loss: 1.8222095607429423

Epoch: 5| Step: 8
Training loss: 1.354608416557312
Validation loss: 1.754547235786274

Epoch: 5| Step: 9
Training loss: 1.6408021450042725
Validation loss: 1.8397200235756495

Epoch: 5| Step: 10
Training loss: 1.9918230772018433
Validation loss: 1.8060017401172268

Epoch: 375| Step: 0
Training loss: 2.0500519275665283
Validation loss: 1.8070825351181852

Epoch: 5| Step: 1
Training loss: 2.005643844604492
Validation loss: 1.8200074959826726

Epoch: 5| Step: 2
Training loss: 1.3508144617080688
Validation loss: 1.7947949440248552

Epoch: 5| Step: 3
Training loss: 1.3435189723968506
Validation loss: 1.7533989260273595

Epoch: 5| Step: 4
Training loss: 1.6655296087265015
Validation loss: 1.801202784302414

Epoch: 5| Step: 5
Training loss: 1.0533632040023804
Validation loss: 1.8173782312741844

Epoch: 5| Step: 6
Training loss: 1.2370765209197998
Validation loss: 1.7586462074710476

Epoch: 5| Step: 7
Training loss: 1.616681694984436
Validation loss: 1.795010974330287

Epoch: 5| Step: 8
Training loss: 1.8352752923965454
Validation loss: 1.8406235466721237

Epoch: 5| Step: 9
Training loss: 1.2330553531646729
Validation loss: 1.8697231226069952

Epoch: 5| Step: 10
Training loss: 1.098299264907837
Validation loss: 1.8537592862242012

Epoch: 376| Step: 0
Training loss: 1.32907235622406
Validation loss: 1.8896903043152184

Epoch: 5| Step: 1
Training loss: 1.2621879577636719
Validation loss: 1.7753765736856768

Epoch: 5| Step: 2
Training loss: 1.7800376415252686
Validation loss: 1.8207560611027542

Epoch: 5| Step: 3
Training loss: 1.6239277124404907
Validation loss: 1.8281744757006246

Epoch: 5| Step: 4
Training loss: 1.6653690338134766
Validation loss: 1.8534786496111142

Epoch: 5| Step: 5
Training loss: 1.1623334884643555
Validation loss: 1.8713042043870496

Epoch: 5| Step: 6
Training loss: 1.5087361335754395
Validation loss: 1.7917504720790411

Epoch: 5| Step: 7
Training loss: 1.4181135892868042
Validation loss: 1.8734336976082093

Epoch: 5| Step: 8
Training loss: 1.526444911956787
Validation loss: 1.873677352423309

Epoch: 5| Step: 9
Training loss: 1.6576511859893799
Validation loss: 1.8387894604795723

Epoch: 5| Step: 10
Training loss: 1.3006701469421387
Validation loss: 1.811872027253592

Epoch: 377| Step: 0
Training loss: 1.7734107971191406
Validation loss: 1.8326365434995262

Epoch: 5| Step: 1
Training loss: 1.8270008563995361
Validation loss: 1.8643204435225456

Epoch: 5| Step: 2
Training loss: 1.7116920948028564
Validation loss: 1.797069994352197

Epoch: 5| Step: 3
Training loss: 1.6549196243286133
Validation loss: 1.827916669589217

Epoch: 5| Step: 4
Training loss: 1.5699663162231445
Validation loss: 1.7911128241528746

Epoch: 5| Step: 5
Training loss: 1.5223515033721924
Validation loss: 1.8741788018134333

Epoch: 5| Step: 6
Training loss: 1.2860922813415527
Validation loss: 1.8237172070369925

Epoch: 5| Step: 7
Training loss: 1.5852973461151123
Validation loss: 1.8578155309923234

Epoch: 5| Step: 8
Training loss: 1.1954624652862549
Validation loss: 1.8044016438145791

Epoch: 5| Step: 9
Training loss: 1.5770471096038818
Validation loss: 1.8609172426244265

Epoch: 5| Step: 10
Training loss: 0.7202854156494141
Validation loss: 1.8111727237701416

Epoch: 378| Step: 0
Training loss: 1.4458061456680298
Validation loss: 1.8377425529623543

Epoch: 5| Step: 1
Training loss: 1.3908305168151855
Validation loss: 1.8085678969660113

Epoch: 5| Step: 2
Training loss: 1.4101307392120361
Validation loss: 1.7843902790418236

Epoch: 5| Step: 3
Training loss: 1.6100711822509766
Validation loss: 1.8224774714439147

Epoch: 5| Step: 4
Training loss: 1.3395395278930664
Validation loss: 1.8162653394924697

Epoch: 5| Step: 5
Training loss: 1.7360260486602783
Validation loss: 1.8160514241905623

Epoch: 5| Step: 6
Training loss: 1.918587327003479
Validation loss: 1.8066482313217656

Epoch: 5| Step: 7
Training loss: 1.09407639503479
Validation loss: 1.8373072211460402

Epoch: 5| Step: 8
Training loss: 1.657349944114685
Validation loss: 1.7972339507072204

Epoch: 5| Step: 9
Training loss: 1.4103965759277344
Validation loss: 1.8092131614685059

Epoch: 5| Step: 10
Training loss: 1.1945139169692993
Validation loss: 1.7870188195218322

Epoch: 379| Step: 0
Training loss: 1.7908999919891357
Validation loss: 1.8038801480365056

Epoch: 5| Step: 1
Training loss: 1.02979576587677
Validation loss: 1.8761070748811126

Epoch: 5| Step: 2
Training loss: 1.23505699634552
Validation loss: 1.8694815494680916

Epoch: 5| Step: 3
Training loss: 2.013143301010132
Validation loss: 1.7912578441763436

Epoch: 5| Step: 4
Training loss: 1.2675094604492188
Validation loss: 1.8202441020678448

Epoch: 5| Step: 5
Training loss: 1.3867660760879517
Validation loss: 1.7891397771014963

Epoch: 5| Step: 6
Training loss: 1.0900897979736328
Validation loss: 1.815593163172404

Epoch: 5| Step: 7
Training loss: 1.29094398021698
Validation loss: 1.7900566695838847

Epoch: 5| Step: 8
Training loss: 1.9657981395721436
Validation loss: 1.8353222441929642

Epoch: 5| Step: 9
Training loss: 1.9983088970184326
Validation loss: 1.8089142871159378

Epoch: 5| Step: 10
Training loss: 1.4792615175247192
Validation loss: 1.8182533364142142

Epoch: 380| Step: 0
Training loss: 1.6546348333358765
Validation loss: 1.8018829860994894

Epoch: 5| Step: 1
Training loss: 1.9021081924438477
Validation loss: 1.7133039556523806

Epoch: 5| Step: 2
Training loss: 1.1249345541000366
Validation loss: 1.8110547911736272

Epoch: 5| Step: 3
Training loss: 1.4603359699249268
Validation loss: 1.820280101991469

Epoch: 5| Step: 4
Training loss: 1.2642760276794434
Validation loss: 1.8196594817664034

Epoch: 5| Step: 5
Training loss: 1.5122077465057373
Validation loss: 1.8373405818016297

Epoch: 5| Step: 6
Training loss: 1.5777226686477661
Validation loss: 1.8363258813017158

Epoch: 5| Step: 7
Training loss: 1.250867486000061
Validation loss: 1.8495762489175285

Epoch: 5| Step: 8
Training loss: 1.4844986200332642
Validation loss: 1.830150870866673

Epoch: 5| Step: 9
Training loss: 0.9978170394897461
Validation loss: 1.8332933392575992

Epoch: 5| Step: 10
Training loss: 2.4913275241851807
Validation loss: 1.802613212216285

Epoch: 381| Step: 0
Training loss: 1.90798020362854
Validation loss: 1.828963630942888

Epoch: 5| Step: 1
Training loss: 1.021783709526062
Validation loss: 1.8502833086957213

Epoch: 5| Step: 2
Training loss: 1.9108409881591797
Validation loss: 1.849216479127125

Epoch: 5| Step: 3
Training loss: 1.4013705253601074
Validation loss: 1.8245170142060967

Epoch: 5| Step: 4
Training loss: 0.7921559810638428
Validation loss: 1.7849038595794349

Epoch: 5| Step: 5
Training loss: 1.3755078315734863
Validation loss: 1.8586423909792336

Epoch: 5| Step: 6
Training loss: 1.7800407409667969
Validation loss: 1.772022706206127

Epoch: 5| Step: 7
Training loss: 1.1300959587097168
Validation loss: 1.868897222703503

Epoch: 5| Step: 8
Training loss: 1.3181926012039185
Validation loss: 1.8048006116702993

Epoch: 5| Step: 9
Training loss: 1.803946852684021
Validation loss: 1.8131047666713755

Epoch: 5| Step: 10
Training loss: 2.007099151611328
Validation loss: 1.8334437044717933

Epoch: 382| Step: 0
Training loss: 1.2868674993515015
Validation loss: 1.8433502361338625

Epoch: 5| Step: 1
Training loss: 1.5058934688568115
Validation loss: 1.8014845437900995

Epoch: 5| Step: 2
Training loss: 1.3988549709320068
Validation loss: 1.756512882888958

Epoch: 5| Step: 3
Training loss: 1.282860517501831
Validation loss: 1.808485669474448

Epoch: 5| Step: 4
Training loss: 1.1661617755889893
Validation loss: 1.7861703236897786

Epoch: 5| Step: 5
Training loss: 1.3960399627685547
Validation loss: 1.8287827789142568

Epoch: 5| Step: 6
Training loss: 1.143580675125122
Validation loss: 1.7501969516918223

Epoch: 5| Step: 7
Training loss: 1.6999366283416748
Validation loss: 1.806970711677305

Epoch: 5| Step: 8
Training loss: 1.8807157278060913
Validation loss: 1.7556088957735287

Epoch: 5| Step: 9
Training loss: 1.299428105354309
Validation loss: 1.7896710211230862

Epoch: 5| Step: 10
Training loss: 2.0153427124023438
Validation loss: 1.7897019219654862

Epoch: 383| Step: 0
Training loss: 1.5215446949005127
Validation loss: 1.858570510341275

Epoch: 5| Step: 1
Training loss: 2.1413636207580566
Validation loss: 1.834906957482779

Epoch: 5| Step: 2
Training loss: 1.219009280204773
Validation loss: 1.8836976558931413

Epoch: 5| Step: 3
Training loss: 0.9136630892753601
Validation loss: 1.8702967782174387

Epoch: 5| Step: 4
Training loss: 1.2844161987304688
Validation loss: 1.8688467382102885

Epoch: 5| Step: 5
Training loss: 1.4571548700332642
Validation loss: 1.8491639898669334

Epoch: 5| Step: 6
Training loss: 1.5526549816131592
Validation loss: 1.8513198526956702

Epoch: 5| Step: 7
Training loss: 1.6124681234359741
Validation loss: 1.8603831555253716

Epoch: 5| Step: 8
Training loss: 1.357439398765564
Validation loss: 1.790802578772268

Epoch: 5| Step: 9
Training loss: 1.764681100845337
Validation loss: 1.8284126571429673

Epoch: 5| Step: 10
Training loss: 1.8402169942855835
Validation loss: 1.794466544223088

Epoch: 384| Step: 0
Training loss: 2.0945162773132324
Validation loss: 1.7913517080327517

Epoch: 5| Step: 1
Training loss: 0.9802772402763367
Validation loss: 1.7875965808027534

Epoch: 5| Step: 2
Training loss: 0.9789192080497742
Validation loss: 1.832620620727539

Epoch: 5| Step: 3
Training loss: 1.3556509017944336
Validation loss: 1.756549455786264

Epoch: 5| Step: 4
Training loss: 1.9765796661376953
Validation loss: 1.8043853954602314

Epoch: 5| Step: 5
Training loss: 1.576004981994629
Validation loss: 1.8255390813273769

Epoch: 5| Step: 6
Training loss: 1.426234483718872
Validation loss: 1.823403286677535

Epoch: 5| Step: 7
Training loss: 1.3933149576187134
Validation loss: 1.8356958743064635

Epoch: 5| Step: 8
Training loss: 1.9120458364486694
Validation loss: 1.775501287111672

Epoch: 5| Step: 9
Training loss: 1.3012220859527588
Validation loss: 1.8552794738482403

Epoch: 5| Step: 10
Training loss: 1.2742787599563599
Validation loss: 1.8009713336985598

Epoch: 385| Step: 0
Training loss: 1.3343276977539062
Validation loss: 1.8470837358505494

Epoch: 5| Step: 1
Training loss: 1.0521360635757446
Validation loss: 1.8343823699540989

Epoch: 5| Step: 2
Training loss: 1.1341325044631958
Validation loss: 1.8480370442072551

Epoch: 5| Step: 3
Training loss: 0.972649097442627
Validation loss: 1.8247278287846556

Epoch: 5| Step: 4
Training loss: 1.6169230937957764
Validation loss: 1.7583299708622757

Epoch: 5| Step: 5
Training loss: 1.6660114526748657
Validation loss: 1.8123318828562254

Epoch: 5| Step: 6
Training loss: 1.8272716999053955
Validation loss: 1.8086037763985254

Epoch: 5| Step: 7
Training loss: 0.9265009760856628
Validation loss: 1.843844506048387

Epoch: 5| Step: 8
Training loss: 1.6375715732574463
Validation loss: 1.8684337985131048

Epoch: 5| Step: 9
Training loss: 1.9094717502593994
Validation loss: 1.824148404982782

Epoch: 5| Step: 10
Training loss: 2.399087905883789
Validation loss: 1.7825770019203104

Epoch: 386| Step: 0
Training loss: 1.642589807510376
Validation loss: 1.8504878833729734

Epoch: 5| Step: 1
Training loss: 1.2598797082901
Validation loss: 1.8302629557988976

Epoch: 5| Step: 2
Training loss: 1.346379041671753
Validation loss: 1.8470672330548685

Epoch: 5| Step: 3
Training loss: 1.5324920415878296
Validation loss: 1.8139449691259733

Epoch: 5| Step: 4
Training loss: 1.5387680530548096
Validation loss: 1.8113996995392667

Epoch: 5| Step: 5
Training loss: 1.1268507242202759
Validation loss: 1.8335254935808079

Epoch: 5| Step: 6
Training loss: 2.04351544380188
Validation loss: 1.804789230387698

Epoch: 5| Step: 7
Training loss: 1.4956411123275757
Validation loss: 1.799888700567266

Epoch: 5| Step: 8
Training loss: 1.1845858097076416
Validation loss: 1.8146158226074711

Epoch: 5| Step: 9
Training loss: 1.683387041091919
Validation loss: 1.7991966098867438

Epoch: 5| Step: 10
Training loss: 1.081941843032837
Validation loss: 1.8290422193465694

Epoch: 387| Step: 0
Training loss: 1.9695316553115845
Validation loss: 1.8166443288967173

Epoch: 5| Step: 1
Training loss: 1.7132747173309326
Validation loss: 1.8332846626158683

Epoch: 5| Step: 2
Training loss: 0.9124187231063843
Validation loss: 1.8706459563265565

Epoch: 5| Step: 3
Training loss: 1.7805989980697632
Validation loss: 1.7916283094754784

Epoch: 5| Step: 4
Training loss: 1.585869550704956
Validation loss: 1.823065762878746

Epoch: 5| Step: 5
Training loss: 0.9391727447509766
Validation loss: 1.8267903327941895

Epoch: 5| Step: 6
Training loss: 1.359484076499939
Validation loss: 1.7533323534073368

Epoch: 5| Step: 7
Training loss: 1.6990448236465454
Validation loss: 1.8553569573228077

Epoch: 5| Step: 8
Training loss: 1.5841118097305298
Validation loss: 1.7548451564645255

Epoch: 5| Step: 9
Training loss: 1.2710975408554077
Validation loss: 1.7626482517488542

Epoch: 5| Step: 10
Training loss: 0.9259636998176575
Validation loss: 1.8235170661762197

Epoch: 388| Step: 0
Training loss: 1.358710527420044
Validation loss: 1.8354557470608783

Epoch: 5| Step: 1
Training loss: 1.118802785873413
Validation loss: 1.7803009607458626

Epoch: 5| Step: 2
Training loss: 1.7771480083465576
Validation loss: 1.8154210031673472

Epoch: 5| Step: 3
Training loss: 1.8665735721588135
Validation loss: 1.8645977768846738

Epoch: 5| Step: 4
Training loss: 1.3793214559555054
Validation loss: 1.803797725708254

Epoch: 5| Step: 5
Training loss: 1.0729308128356934
Validation loss: 1.8408515376429404

Epoch: 5| Step: 6
Training loss: 1.3888473510742188
Validation loss: 1.806199751874452

Epoch: 5| Step: 7
Training loss: 1.587145209312439
Validation loss: 1.8122063388106644

Epoch: 5| Step: 8
Training loss: 1.383472204208374
Validation loss: 1.8188861339322981

Epoch: 5| Step: 9
Training loss: 1.6109085083007812
Validation loss: 1.824068848804761

Epoch: 5| Step: 10
Training loss: 1.5699973106384277
Validation loss: 1.8602148102175804

Epoch: 389| Step: 0
Training loss: 1.4650002717971802
Validation loss: 1.7680591517879116

Epoch: 5| Step: 1
Training loss: 1.5199300050735474
Validation loss: 1.8223327385481967

Epoch: 5| Step: 2
Training loss: 1.2805407047271729
Validation loss: 1.7880925273382535

Epoch: 5| Step: 3
Training loss: 1.3975191116333008
Validation loss: 1.7993353028451242

Epoch: 5| Step: 4
Training loss: 1.3723304271697998
Validation loss: 1.7628508754955825

Epoch: 5| Step: 5
Training loss: 1.243969440460205
Validation loss: 1.8117065455323906

Epoch: 5| Step: 6
Training loss: 1.6074895858764648
Validation loss: 1.8580227744194768

Epoch: 5| Step: 7
Training loss: 0.9494386911392212
Validation loss: 1.804045969440091

Epoch: 5| Step: 8
Training loss: 1.4162721633911133
Validation loss: 1.8565907619332755

Epoch: 5| Step: 9
Training loss: 2.1858458518981934
Validation loss: 1.8304966175428001

Epoch: 5| Step: 10
Training loss: 1.0502064228057861
Validation loss: 1.8670629352651618

Epoch: 390| Step: 0
Training loss: 1.3986647129058838
Validation loss: 1.797786320409467

Epoch: 5| Step: 1
Training loss: 1.4894678592681885
Validation loss: 1.7701356410980225

Epoch: 5| Step: 2
Training loss: 1.31313157081604
Validation loss: 1.797385077322683

Epoch: 5| Step: 3
Training loss: 1.192694902420044
Validation loss: 1.833876468802011

Epoch: 5| Step: 4
Training loss: 1.2131717205047607
Validation loss: 1.8036570651556856

Epoch: 5| Step: 5
Training loss: 1.6129356622695923
Validation loss: 1.8739386399586995

Epoch: 5| Step: 6
Training loss: 1.5603992938995361
Validation loss: 1.8323895187788113

Epoch: 5| Step: 7
Training loss: 1.4540640115737915
Validation loss: 1.8466752370198567

Epoch: 5| Step: 8
Training loss: 1.669123649597168
Validation loss: 1.8146584597967004

Epoch: 5| Step: 9
Training loss: 1.1282529830932617
Validation loss: 1.8323911172087475

Epoch: 5| Step: 10
Training loss: 1.6122710704803467
Validation loss: 1.8169371235755183

Epoch: 391| Step: 0
Training loss: 1.664942979812622
Validation loss: 1.793333673989901

Epoch: 5| Step: 1
Training loss: 1.2860453128814697
Validation loss: 1.7978775475614814

Epoch: 5| Step: 2
Training loss: 1.2649363279342651
Validation loss: 1.794992668654329

Epoch: 5| Step: 3
Training loss: 1.2913051843643188
Validation loss: 1.7915961306582215

Epoch: 5| Step: 4
Training loss: 1.2799063920974731
Validation loss: 1.8272412669274114

Epoch: 5| Step: 5
Training loss: 1.3631856441497803
Validation loss: 1.813511040902907

Epoch: 5| Step: 6
Training loss: 2.0915474891662598
Validation loss: 1.7715657141900831

Epoch: 5| Step: 7
Training loss: 1.2909986972808838
Validation loss: 1.7910421573987572

Epoch: 5| Step: 8
Training loss: 1.3922455310821533
Validation loss: 1.7895668296403782

Epoch: 5| Step: 9
Training loss: 1.4409502744674683
Validation loss: 1.8517828359398791

Epoch: 5| Step: 10
Training loss: 1.3607326745986938
Validation loss: 1.795127901979672

Epoch: 392| Step: 0
Training loss: 1.2341313362121582
Validation loss: 1.823631666039908

Epoch: 5| Step: 1
Training loss: 1.9196475744247437
Validation loss: 1.8086504346580916

Epoch: 5| Step: 2
Training loss: 1.6370131969451904
Validation loss: 1.8204370967803463

Epoch: 5| Step: 3
Training loss: 1.4840301275253296
Validation loss: 1.8330537426856257

Epoch: 5| Step: 4
Training loss: 1.2831400632858276
Validation loss: 1.812721683133033

Epoch: 5| Step: 5
Training loss: 1.036123514175415
Validation loss: 1.8024733707468996

Epoch: 5| Step: 6
Training loss: 1.5870168209075928
Validation loss: 1.7940976773538897

Epoch: 5| Step: 7
Training loss: 1.3211942911148071
Validation loss: 1.8749981157241329

Epoch: 5| Step: 8
Training loss: 1.0685924291610718
Validation loss: 1.8371300056416502

Epoch: 5| Step: 9
Training loss: 1.737513542175293
Validation loss: 1.8337808475699475

Epoch: 5| Step: 10
Training loss: 1.6766903400421143
Validation loss: 1.8357929298954625

Epoch: 393| Step: 0
Training loss: 1.1112663745880127
Validation loss: 1.7978953417911325

Epoch: 5| Step: 1
Training loss: 1.7206299304962158
Validation loss: 1.7763972859228812

Epoch: 5| Step: 2
Training loss: 1.2311111688613892
Validation loss: 1.7725259834720242

Epoch: 5| Step: 3
Training loss: 1.6063365936279297
Validation loss: 1.8203103683328117

Epoch: 5| Step: 4
Training loss: 0.9308913350105286
Validation loss: 1.7978379931501163

Epoch: 5| Step: 5
Training loss: 0.8240677118301392
Validation loss: 1.7718057286354802

Epoch: 5| Step: 6
Training loss: 1.679964303970337
Validation loss: 1.8140946242117113

Epoch: 5| Step: 7
Training loss: 1.4933490753173828
Validation loss: 1.7733633236218524

Epoch: 5| Step: 8
Training loss: 1.3696588277816772
Validation loss: 1.80692062839385

Epoch: 5| Step: 9
Training loss: 1.4701206684112549
Validation loss: 1.8071931715934508

Epoch: 5| Step: 10
Training loss: 2.644352912902832
Validation loss: 1.8105474031099709

Epoch: 394| Step: 0
Training loss: 1.243607759475708
Validation loss: 1.8187806119201004

Epoch: 5| Step: 1
Training loss: 1.8625818490982056
Validation loss: 1.786638412424313

Epoch: 5| Step: 2
Training loss: 1.7722746133804321
Validation loss: 1.7557047669605543

Epoch: 5| Step: 3
Training loss: 1.3862344026565552
Validation loss: 1.8161368331601542

Epoch: 5| Step: 4
Training loss: 1.3506193161010742
Validation loss: 1.8613766367717455

Epoch: 5| Step: 5
Training loss: 1.4360320568084717
Validation loss: 1.8502370067822036

Epoch: 5| Step: 6
Training loss: 1.4387118816375732
Validation loss: 1.8481140393082813

Epoch: 5| Step: 7
Training loss: 1.9662988185882568
Validation loss: 1.9446718128778602

Epoch: 5| Step: 8
Training loss: 1.5562174320220947
Validation loss: 1.896687820393552

Epoch: 5| Step: 9
Training loss: 1.1120483875274658
Validation loss: 1.8697669454800185

Epoch: 5| Step: 10
Training loss: 1.3297972679138184
Validation loss: 1.8196811086388045

Epoch: 395| Step: 0
Training loss: 1.2504857778549194
Validation loss: 1.8670955332376624

Epoch: 5| Step: 1
Training loss: 1.111487627029419
Validation loss: 1.8023272893762077

Epoch: 5| Step: 2
Training loss: 1.6469802856445312
Validation loss: 1.8037540322990828

Epoch: 5| Step: 3
Training loss: 1.8286155462265015
Validation loss: 1.7844729051795056

Epoch: 5| Step: 4
Training loss: 1.297330617904663
Validation loss: 1.8291973465232438

Epoch: 5| Step: 5
Training loss: 1.6679306030273438
Validation loss: 1.8145539029952018

Epoch: 5| Step: 6
Training loss: 1.5356050729751587
Validation loss: 1.82586359336812

Epoch: 5| Step: 7
Training loss: 1.4715583324432373
Validation loss: 1.7931641019800657

Epoch: 5| Step: 8
Training loss: 1.4617410898208618
Validation loss: 1.7544821244414135

Epoch: 5| Step: 9
Training loss: 1.5546467304229736
Validation loss: 1.7810103918916436

Epoch: 5| Step: 10
Training loss: 1.1143312454223633
Validation loss: 1.8420789575064054

Epoch: 396| Step: 0
Training loss: 1.0758826732635498
Validation loss: 1.8124912810581986

Epoch: 5| Step: 1
Training loss: 1.3187637329101562
Validation loss: 1.8092940738124232

Epoch: 5| Step: 2
Training loss: 1.7530813217163086
Validation loss: 1.7865948715517599

Epoch: 5| Step: 3
Training loss: 1.3295738697052002
Validation loss: 1.8046706004809308

Epoch: 5| Step: 4
Training loss: 1.396562933921814
Validation loss: 1.8810954004205682

Epoch: 5| Step: 5
Training loss: 1.3718035221099854
Validation loss: 1.8632653426098567

Epoch: 5| Step: 6
Training loss: 1.3094011545181274
Validation loss: 1.8282040242225892

Epoch: 5| Step: 7
Training loss: 1.9913690090179443
Validation loss: 1.8488104740778606

Epoch: 5| Step: 8
Training loss: 1.3636391162872314
Validation loss: 1.8503019873813917

Epoch: 5| Step: 9
Training loss: 1.719543695449829
Validation loss: 1.8187162824856338

Epoch: 5| Step: 10
Training loss: 1.283013105392456
Validation loss: 1.872193733851115

Epoch: 397| Step: 0
Training loss: 1.4792912006378174
Validation loss: 1.8270724153005948

Epoch: 5| Step: 1
Training loss: 2.0016586780548096
Validation loss: 1.8232150436729513

Epoch: 5| Step: 2
Training loss: 0.8181807398796082
Validation loss: 1.8752695821946668

Epoch: 5| Step: 3
Training loss: 1.6902633905410767
Validation loss: 1.8364996397367088

Epoch: 5| Step: 4
Training loss: 1.2990138530731201
Validation loss: 1.738335854263716

Epoch: 5| Step: 5
Training loss: 1.3083982467651367
Validation loss: 1.7843716913653958

Epoch: 5| Step: 6
Training loss: 1.0499364137649536
Validation loss: 1.7737499206296858

Epoch: 5| Step: 7
Training loss: 1.541069746017456
Validation loss: 1.8052852717779015

Epoch: 5| Step: 8
Training loss: 1.0730558633804321
Validation loss: 1.8405903334258704

Epoch: 5| Step: 9
Training loss: 1.9926750659942627
Validation loss: 1.8002856316105011

Epoch: 5| Step: 10
Training loss: 1.252703070640564
Validation loss: 1.8594428775131062

Epoch: 398| Step: 0
Training loss: 1.458707571029663
Validation loss: 1.793822782014006

Epoch: 5| Step: 1
Training loss: 1.3608894348144531
Validation loss: 1.8567776244173768

Epoch: 5| Step: 2
Training loss: 1.5250458717346191
Validation loss: 1.7844844812987952

Epoch: 5| Step: 3
Training loss: 1.715699553489685
Validation loss: 1.812254576272862

Epoch: 5| Step: 4
Training loss: 1.1014395952224731
Validation loss: 1.7921253019763577

Epoch: 5| Step: 5
Training loss: 1.7151094675064087
Validation loss: 1.7967708303082375

Epoch: 5| Step: 6
Training loss: 1.6584641933441162
Validation loss: 1.847078683555767

Epoch: 5| Step: 7
Training loss: 1.4935942888259888
Validation loss: 1.7994404915840394

Epoch: 5| Step: 8
Training loss: 0.8954936265945435
Validation loss: 1.8265706659645162

Epoch: 5| Step: 9
Training loss: 1.1046110391616821
Validation loss: 1.8447879104204075

Epoch: 5| Step: 10
Training loss: 1.6745686531066895
Validation loss: 1.8181137448997908

Epoch: 399| Step: 0
Training loss: 1.1645586490631104
Validation loss: 1.8239813338043869

Epoch: 5| Step: 1
Training loss: 1.563786268234253
Validation loss: 1.7898987416298158

Epoch: 5| Step: 2
Training loss: 0.9031581878662109
Validation loss: 1.8042292671818887

Epoch: 5| Step: 3
Training loss: 1.9152004718780518
Validation loss: 1.7989147657989173

Epoch: 5| Step: 4
Training loss: 1.712720513343811
Validation loss: 1.7829560720792381

Epoch: 5| Step: 5
Training loss: 1.0923874378204346
Validation loss: 1.7970931517180575

Epoch: 5| Step: 6
Training loss: 1.9063384532928467
Validation loss: 1.8073148932508243

Epoch: 5| Step: 7
Training loss: 1.1530654430389404
Validation loss: 1.7860577760204193

Epoch: 5| Step: 8
Training loss: 1.6657966375350952
Validation loss: 1.8084524831464213

Epoch: 5| Step: 9
Training loss: 1.5176483392715454
Validation loss: 1.771015872237503

Epoch: 5| Step: 10
Training loss: 0.8198683261871338
Validation loss: 1.8371466628966793

Epoch: 400| Step: 0
Training loss: 1.2798665761947632
Validation loss: 1.7826450537609797

Epoch: 5| Step: 1
Training loss: 1.5069202184677124
Validation loss: 1.805711087360177

Epoch: 5| Step: 2
Training loss: 1.6538009643554688
Validation loss: 1.82227865470353

Epoch: 5| Step: 3
Training loss: 0.9587529301643372
Validation loss: 1.7815941008188392

Epoch: 5| Step: 4
Training loss: 2.1725406646728516
Validation loss: 1.8735829655842116

Epoch: 5| Step: 5
Training loss: 1.2880014181137085
Validation loss: 1.8450583257982809

Epoch: 5| Step: 6
Training loss: 1.6958153247833252
Validation loss: 1.7895834497226182

Epoch: 5| Step: 7
Training loss: 1.133544683456421
Validation loss: 1.8508928770660071

Epoch: 5| Step: 8
Training loss: 1.3771419525146484
Validation loss: 1.8029586692010202

Epoch: 5| Step: 9
Training loss: 1.5143128633499146
Validation loss: 1.8074471027620378

Epoch: 5| Step: 10
Training loss: 1.457638144493103
Validation loss: 1.7459474840471823

Epoch: 401| Step: 0
Training loss: 1.6017802953720093
Validation loss: 1.7736007564811296

Epoch: 5| Step: 1
Training loss: 1.2733198404312134
Validation loss: 1.824202150426885

Epoch: 5| Step: 2
Training loss: 1.7981901168823242
Validation loss: 1.7458885959399644

Epoch: 5| Step: 3
Training loss: 1.2151625156402588
Validation loss: 1.7951861222585042

Epoch: 5| Step: 4
Training loss: 1.4814473390579224
Validation loss: 1.7959254428904543

Epoch: 5| Step: 5
Training loss: 1.6064962148666382
Validation loss: 1.7847001437217958

Epoch: 5| Step: 6
Training loss: 0.9878641366958618
Validation loss: 1.7777333003218456

Epoch: 5| Step: 7
Training loss: 1.2296932935714722
Validation loss: 1.780221305867677

Epoch: 5| Step: 8
Training loss: 1.2507768869400024
Validation loss: 1.7931542934909943

Epoch: 5| Step: 9
Training loss: 1.5499318838119507
Validation loss: 1.766997338623129

Epoch: 5| Step: 10
Training loss: 1.88430655002594
Validation loss: 1.7817952363721785

Epoch: 402| Step: 0
Training loss: 1.5135924816131592
Validation loss: 1.8810196025397188

Epoch: 5| Step: 1
Training loss: 1.2792565822601318
Validation loss: 1.8208648517567625

Epoch: 5| Step: 2
Training loss: 1.1247749328613281
Validation loss: 1.7934154592534548

Epoch: 5| Step: 3
Training loss: 1.537516474723816
Validation loss: 1.8488851542113929

Epoch: 5| Step: 4
Training loss: 1.4615930318832397
Validation loss: 1.8033737444108533

Epoch: 5| Step: 5
Training loss: 1.3419480323791504
Validation loss: 1.788994550704956

Epoch: 5| Step: 6
Training loss: 1.9779952764511108
Validation loss: 1.8375066775147633

Epoch: 5| Step: 7
Training loss: 1.2342731952667236
Validation loss: 1.7890154187397291

Epoch: 5| Step: 8
Training loss: 1.1252518892288208
Validation loss: 1.7970470228502828

Epoch: 5| Step: 9
Training loss: 1.4402834177017212
Validation loss: 1.7885708270534393

Epoch: 5| Step: 10
Training loss: 1.7167236804962158
Validation loss: 1.805353299263985

Epoch: 403| Step: 0
Training loss: 1.6960636377334595
Validation loss: 1.8403251965840657

Epoch: 5| Step: 1
Training loss: 1.8809512853622437
Validation loss: 1.8000087353491014

Epoch: 5| Step: 2
Training loss: 1.0319783687591553
Validation loss: 1.815795583109702

Epoch: 5| Step: 3
Training loss: 0.9891179800033569
Validation loss: 1.7702658676332044

Epoch: 5| Step: 4
Training loss: 1.3559033870697021
Validation loss: 1.8036954172195927

Epoch: 5| Step: 5
Training loss: 0.8658086657524109
Validation loss: 1.797966185436454

Epoch: 5| Step: 6
Training loss: 1.2294784784317017
Validation loss: 1.8165579854801137

Epoch: 5| Step: 7
Training loss: 1.5545141696929932
Validation loss: 1.8471293205855994

Epoch: 5| Step: 8
Training loss: 1.6133167743682861
Validation loss: 1.7783654607752317

Epoch: 5| Step: 9
Training loss: 1.6617943048477173
Validation loss: 1.846756996647004

Epoch: 5| Step: 10
Training loss: 1.3341623544692993
Validation loss: 1.8274315736627067

Epoch: 404| Step: 0
Training loss: 1.6091026067733765
Validation loss: 1.775890665669595

Epoch: 5| Step: 1
Training loss: 1.2853691577911377
Validation loss: 1.7932857915919314

Epoch: 5| Step: 2
Training loss: 1.6451938152313232
Validation loss: 1.8050860736959724

Epoch: 5| Step: 3
Training loss: 1.0698245763778687
Validation loss: 1.7605578527655652

Epoch: 5| Step: 4
Training loss: 1.6503522396087646
Validation loss: 1.7925046823358024

Epoch: 5| Step: 5
Training loss: 1.2924224138259888
Validation loss: 1.8076595824251893

Epoch: 5| Step: 6
Training loss: 1.8249118328094482
Validation loss: 1.8131810503621255

Epoch: 5| Step: 7
Training loss: 1.389349341392517
Validation loss: 1.809119641139943

Epoch: 5| Step: 8
Training loss: 1.7331323623657227
Validation loss: 1.8128703153261574

Epoch: 5| Step: 9
Training loss: 1.0423390865325928
Validation loss: 1.8161660471270162

Epoch: 5| Step: 10
Training loss: 1.3802144527435303
Validation loss: 1.8132966526093022

Epoch: 405| Step: 0
Training loss: 1.3148260116577148
Validation loss: 1.812962511534332

Epoch: 5| Step: 1
Training loss: 1.0192499160766602
Validation loss: 1.8261446875910605

Epoch: 5| Step: 2
Training loss: 1.2267954349517822
Validation loss: 1.82141294787007

Epoch: 5| Step: 3
Training loss: 1.232468843460083
Validation loss: 1.812185695094447

Epoch: 5| Step: 4
Training loss: 1.5912485122680664
Validation loss: 1.830988419953213

Epoch: 5| Step: 5
Training loss: 1.6573219299316406
Validation loss: 1.7804481637093328

Epoch: 5| Step: 6
Training loss: 1.1940126419067383
Validation loss: 1.7947189538709578

Epoch: 5| Step: 7
Training loss: 1.469902753829956
Validation loss: 1.8083574156607352

Epoch: 5| Step: 8
Training loss: 1.7570127248764038
Validation loss: 1.7740535889902422

Epoch: 5| Step: 9
Training loss: 1.6153857707977295
Validation loss: 1.8020945697702386

Epoch: 5| Step: 10
Training loss: 1.8148252964019775
Validation loss: 1.8177811330364597

Epoch: 406| Step: 0
Training loss: 1.4379103183746338
Validation loss: 1.7912143084310717

Epoch: 5| Step: 1
Training loss: 1.6060060262680054
Validation loss: 1.8452392367906467

Epoch: 5| Step: 2
Training loss: 0.9587400555610657
Validation loss: 1.867877742295624

Epoch: 5| Step: 3
Training loss: 0.7547829151153564
Validation loss: 1.8622352359115437

Epoch: 5| Step: 4
Training loss: 1.0107331275939941
Validation loss: 1.8242122088709185

Epoch: 5| Step: 5
Training loss: 1.6098207235336304
Validation loss: 1.8815883205782982

Epoch: 5| Step: 6
Training loss: 1.4738681316375732
Validation loss: 1.8186811157452163

Epoch: 5| Step: 7
Training loss: 1.8868930339813232
Validation loss: 1.8434723654100973

Epoch: 5| Step: 8
Training loss: 1.089626669883728
Validation loss: 1.8083058903294225

Epoch: 5| Step: 9
Training loss: 1.9648425579071045
Validation loss: 1.8346620887838385

Epoch: 5| Step: 10
Training loss: 1.8874648809432983
Validation loss: 1.7852034825150684

Epoch: 407| Step: 0
Training loss: 1.5421934127807617
Validation loss: 1.8284191239264704

Epoch: 5| Step: 1
Training loss: 2.1084980964660645
Validation loss: 1.7970515553669264

Epoch: 5| Step: 2
Training loss: 1.6886581182479858
Validation loss: 1.7667682440050188

Epoch: 5| Step: 3
Training loss: 1.6040500402450562
Validation loss: 1.7591810482804493

Epoch: 5| Step: 4
Training loss: 1.6316347122192383
Validation loss: 1.8185998368006882

Epoch: 5| Step: 5
Training loss: 1.2239230871200562
Validation loss: 1.8301149132431194

Epoch: 5| Step: 6
Training loss: 1.4415420293807983
Validation loss: 1.8191353172384284

Epoch: 5| Step: 7
Training loss: 0.9317336082458496
Validation loss: 1.7802815411680488

Epoch: 5| Step: 8
Training loss: 0.8316888809204102
Validation loss: 1.8657248122717744

Epoch: 5| Step: 9
Training loss: 1.153301477432251
Validation loss: 1.7405402762915498

Epoch: 5| Step: 10
Training loss: 1.1460142135620117
Validation loss: 1.7869559129079182

Epoch: 408| Step: 0
Training loss: 1.5398677587509155
Validation loss: 1.8313411884410407

Epoch: 5| Step: 1
Training loss: 1.1722259521484375
Validation loss: 1.8047332404762186

Epoch: 5| Step: 2
Training loss: 1.6366838216781616
Validation loss: 1.797101181040528

Epoch: 5| Step: 3
Training loss: 1.2789146900177002
Validation loss: 1.7877444208309214

Epoch: 5| Step: 4
Training loss: 1.1702077388763428
Validation loss: 1.8425159620982345

Epoch: 5| Step: 5
Training loss: 1.0775598287582397
Validation loss: 1.7822485675093949

Epoch: 5| Step: 6
Training loss: 1.1665600538253784
Validation loss: 1.7962647804649927

Epoch: 5| Step: 7
Training loss: 2.118882417678833
Validation loss: 1.778940531515306

Epoch: 5| Step: 8
Training loss: 1.2357587814331055
Validation loss: 1.876910077628269

Epoch: 5| Step: 9
Training loss: 1.4792420864105225
Validation loss: 1.796448067952228

Epoch: 5| Step: 10
Training loss: 1.8808428049087524
Validation loss: 1.8093852573825466

Epoch: 409| Step: 0
Training loss: 0.8574658632278442
Validation loss: 1.8201960479059527

Epoch: 5| Step: 1
Training loss: 1.5940295457839966
Validation loss: 1.8182862638145365

Epoch: 5| Step: 2
Training loss: 1.8356714248657227
Validation loss: 1.8413937835283176

Epoch: 5| Step: 3
Training loss: 1.2733904123306274
Validation loss: 1.7771989850587742

Epoch: 5| Step: 4
Training loss: 1.6300342082977295
Validation loss: 1.8105461674351846

Epoch: 5| Step: 5
Training loss: 1.6798391342163086
Validation loss: 1.8148904872196976

Epoch: 5| Step: 6
Training loss: 1.7441043853759766
Validation loss: 1.786514933391284

Epoch: 5| Step: 7
Training loss: 1.2738882303237915
Validation loss: 1.8245330164509435

Epoch: 5| Step: 8
Training loss: 1.2907688617706299
Validation loss: 1.8003134163477088

Epoch: 5| Step: 9
Training loss: 1.3638185262680054
Validation loss: 1.817401095103192

Epoch: 5| Step: 10
Training loss: 0.9534109830856323
Validation loss: 1.7758300304412842

Epoch: 410| Step: 0
Training loss: 1.547428846359253
Validation loss: 1.8106199656763384

Epoch: 5| Step: 1
Training loss: 1.2013174295425415
Validation loss: 1.803941777957383

Epoch: 5| Step: 2
Training loss: 1.3484654426574707
Validation loss: 1.74427741958249

Epoch: 5| Step: 3
Training loss: 1.2355570793151855
Validation loss: 1.7458023204598376

Epoch: 5| Step: 4
Training loss: 1.9425628185272217
Validation loss: 1.8416149321422781

Epoch: 5| Step: 5
Training loss: 1.5350315570831299
Validation loss: 1.8769805149365497

Epoch: 5| Step: 6
Training loss: 1.274074912071228
Validation loss: 1.8176892367742394

Epoch: 5| Step: 7
Training loss: 1.412949800491333
Validation loss: 1.7967845118173988

Epoch: 5| Step: 8
Training loss: 1.7262961864471436
Validation loss: 1.7869625142825547

Epoch: 5| Step: 9
Training loss: 1.0707974433898926
Validation loss: 1.755166910027945

Epoch: 5| Step: 10
Training loss: 1.52597177028656
Validation loss: 1.813423623320877

Epoch: 411| Step: 0
Training loss: 0.8920906186103821
Validation loss: 1.871799336966648

Epoch: 5| Step: 1
Training loss: 1.9104411602020264
Validation loss: 1.7735232589065388

Epoch: 5| Step: 2
Training loss: 1.4461820125579834
Validation loss: 1.7928735594595633

Epoch: 5| Step: 3
Training loss: 2.0681653022766113
Validation loss: 1.843564087344754

Epoch: 5| Step: 4
Training loss: 1.5681723356246948
Validation loss: 1.831675414116152

Epoch: 5| Step: 5
Training loss: 1.806286096572876
Validation loss: 1.852427162149901

Epoch: 5| Step: 6
Training loss: 1.4284483194351196
Validation loss: 1.8209366747128066

Epoch: 5| Step: 7
Training loss: 1.5182762145996094
Validation loss: 1.7913403511047363

Epoch: 5| Step: 8
Training loss: 0.8311734199523926
Validation loss: 1.7694507773204515

Epoch: 5| Step: 9
Training loss: 1.125443458557129
Validation loss: 1.8282347404828636

Epoch: 5| Step: 10
Training loss: 1.1219711303710938
Validation loss: 1.798597547315782

Epoch: 412| Step: 0
Training loss: 1.7492519617080688
Validation loss: 1.8060187127000542

Epoch: 5| Step: 1
Training loss: 1.5512731075286865
Validation loss: 1.7935629326810119

Epoch: 5| Step: 2
Training loss: 2.01688814163208
Validation loss: 1.7626630952281337

Epoch: 5| Step: 3
Training loss: 1.0614314079284668
Validation loss: 1.8013232292667511

Epoch: 5| Step: 4
Training loss: 1.6596463918685913
Validation loss: 1.816737126278621

Epoch: 5| Step: 5
Training loss: 1.4226149320602417
Validation loss: 1.8157525549652755

Epoch: 5| Step: 6
Training loss: 0.7236915826797485
Validation loss: 1.7589164305758733

Epoch: 5| Step: 7
Training loss: 1.5541210174560547
Validation loss: 1.783213702581262

Epoch: 5| Step: 8
Training loss: 1.3828625679016113
Validation loss: 1.800382375717163

Epoch: 5| Step: 9
Training loss: 1.4383678436279297
Validation loss: 1.740088359002144

Epoch: 5| Step: 10
Training loss: 1.0636721849441528
Validation loss: 1.7981682426186019

Epoch: 413| Step: 0
Training loss: 1.6498539447784424
Validation loss: 1.7448402156112015

Epoch: 5| Step: 1
Training loss: 1.6733999252319336
Validation loss: 1.7350636618111723

Epoch: 5| Step: 2
Training loss: 1.3100191354751587
Validation loss: 1.8320090411811747

Epoch: 5| Step: 3
Training loss: 1.2457292079925537
Validation loss: 1.8276921497878207

Epoch: 5| Step: 4
Training loss: 1.5452789068222046
Validation loss: 1.8184926253493114

Epoch: 5| Step: 5
Training loss: 1.8571596145629883
Validation loss: 1.8050411298710813

Epoch: 5| Step: 6
Training loss: 1.4316051006317139
Validation loss: 1.8513999754382717

Epoch: 5| Step: 7
Training loss: 1.1590886116027832
Validation loss: 1.911013932638271

Epoch: 5| Step: 8
Training loss: 1.4683427810668945
Validation loss: 1.8548282192599388

Epoch: 5| Step: 9
Training loss: 1.0548369884490967
Validation loss: 1.7980680440061836

Epoch: 5| Step: 10
Training loss: 1.0781123638153076
Validation loss: 1.8016043619443012

Epoch: 414| Step: 0
Training loss: 1.3177322149276733
Validation loss: 1.7503414794962893

Epoch: 5| Step: 1
Training loss: 1.8000290393829346
Validation loss: 1.7890163339594358

Epoch: 5| Step: 2
Training loss: 1.4382274150848389
Validation loss: 1.7787367451575495

Epoch: 5| Step: 3
Training loss: 2.009305238723755
Validation loss: 1.7361317808910082

Epoch: 5| Step: 4
Training loss: 1.4882763624191284
Validation loss: 1.7756077845891316

Epoch: 5| Step: 5
Training loss: 1.1822229623794556
Validation loss: 1.7994361564677248

Epoch: 5| Step: 6
Training loss: 0.9733064770698547
Validation loss: 1.7929936865324616

Epoch: 5| Step: 7
Training loss: 0.8937522172927856
Validation loss: 1.725369079138643

Epoch: 5| Step: 8
Training loss: 1.1913378238677979
Validation loss: 1.7297524713700818

Epoch: 5| Step: 9
Training loss: 1.0191038846969604
Validation loss: 1.790098964527089

Epoch: 5| Step: 10
Training loss: 2.433878183364868
Validation loss: 1.750355948684036

Epoch: 415| Step: 0
Training loss: 1.147723913192749
Validation loss: 1.8071826747668687

Epoch: 5| Step: 1
Training loss: 1.5214530229568481
Validation loss: 1.7813599109649658

Epoch: 5| Step: 2
Training loss: 1.4668331146240234
Validation loss: 1.7712894332024358

Epoch: 5| Step: 3
Training loss: 1.4852015972137451
Validation loss: 1.8031303767235047

Epoch: 5| Step: 4
Training loss: 1.4541116952896118
Validation loss: 1.8255362279953495

Epoch: 5| Step: 5
Training loss: 0.9965786933898926
Validation loss: 1.8138677791882587

Epoch: 5| Step: 6
Training loss: 1.1901342868804932
Validation loss: 1.782317158996418

Epoch: 5| Step: 7
Training loss: 1.3463681936264038
Validation loss: 1.8269249418730378

Epoch: 5| Step: 8
Training loss: 1.5912153720855713
Validation loss: 1.793621361896556

Epoch: 5| Step: 9
Training loss: 1.422196388244629
Validation loss: 1.8645843536623063

Epoch: 5| Step: 10
Training loss: 1.8225305080413818
Validation loss: 1.8530100327666088

Epoch: 416| Step: 0
Training loss: 1.3080629110336304
Validation loss: 1.8352277548082414

Epoch: 5| Step: 1
Training loss: 1.2605732679367065
Validation loss: 1.7902016819164317

Epoch: 5| Step: 2
Training loss: 1.9895715713500977
Validation loss: 1.7729139456184961

Epoch: 5| Step: 3
Training loss: 1.7992985248565674
Validation loss: 1.7803921904615176

Epoch: 5| Step: 4
Training loss: 1.0434396266937256
Validation loss: 1.781430769992131

Epoch: 5| Step: 5
Training loss: 1.0479822158813477
Validation loss: 1.7572809829506824

Epoch: 5| Step: 6
Training loss: 1.24698805809021
Validation loss: 1.8163776474614297

Epoch: 5| Step: 7
Training loss: 1.522386908531189
Validation loss: 1.779084623500865

Epoch: 5| Step: 8
Training loss: 1.345882534980774
Validation loss: 1.8148009059249715

Epoch: 5| Step: 9
Training loss: 1.2056515216827393
Validation loss: 1.754297464124618

Epoch: 5| Step: 10
Training loss: 1.5860906839370728
Validation loss: 1.7745484741785194

Epoch: 417| Step: 0
Training loss: 1.3552112579345703
Validation loss: 1.7795228612038396

Epoch: 5| Step: 1
Training loss: 1.6288474798202515
Validation loss: 1.803794817257953

Epoch: 5| Step: 2
Training loss: 0.7906849384307861
Validation loss: 1.7704347743782947

Epoch: 5| Step: 3
Training loss: 1.7868562936782837
Validation loss: 1.81038543229462

Epoch: 5| Step: 4
Training loss: 1.5504072904586792
Validation loss: 1.8392732169038506

Epoch: 5| Step: 5
Training loss: 1.8282448053359985
Validation loss: 1.819957648554156

Epoch: 5| Step: 6
Training loss: 1.2935349941253662
Validation loss: 1.8225719377558718

Epoch: 5| Step: 7
Training loss: 1.3186976909637451
Validation loss: 1.7715269314345492

Epoch: 5| Step: 8
Training loss: 1.3382976055145264
Validation loss: 1.7281958608217136

Epoch: 5| Step: 9
Training loss: 1.1285240650177002
Validation loss: 1.8059163349930958

Epoch: 5| Step: 10
Training loss: 1.303325891494751
Validation loss: 1.758656899134318

Epoch: 418| Step: 0
Training loss: 1.0142428874969482
Validation loss: 1.8356344725496025

Epoch: 5| Step: 1
Training loss: 1.9066654443740845
Validation loss: 1.8299477818191692

Epoch: 5| Step: 2
Training loss: 1.3153365850448608
Validation loss: 1.8131631805050759

Epoch: 5| Step: 3
Training loss: 1.5704147815704346
Validation loss: 1.8227862747766639

Epoch: 5| Step: 4
Training loss: 1.6362855434417725
Validation loss: 1.789424060493387

Epoch: 5| Step: 5
Training loss: 1.215235710144043
Validation loss: 1.7700292551389305

Epoch: 5| Step: 6
Training loss: 1.3385651111602783
Validation loss: 1.7710061842395413

Epoch: 5| Step: 7
Training loss: 1.3186285495758057
Validation loss: 1.8352185974838913

Epoch: 5| Step: 8
Training loss: 1.046504020690918
Validation loss: 1.7839432544605707

Epoch: 5| Step: 9
Training loss: 2.0184102058410645
Validation loss: 1.8216971735800467

Epoch: 5| Step: 10
Training loss: 1.0492279529571533
Validation loss: 1.7826765865407965

Epoch: 419| Step: 0
Training loss: 1.83074951171875
Validation loss: 1.8103881247581974

Epoch: 5| Step: 1
Training loss: 1.3451282978057861
Validation loss: 1.7861969624796221

Epoch: 5| Step: 2
Training loss: 1.5413264036178589
Validation loss: 1.8183123142488542

Epoch: 5| Step: 3
Training loss: 1.4461778402328491
Validation loss: 1.7955987094551005

Epoch: 5| Step: 4
Training loss: 1.2867587804794312
Validation loss: 1.7606040457243561

Epoch: 5| Step: 5
Training loss: 1.525793194770813
Validation loss: 1.784690454442014

Epoch: 5| Step: 6
Training loss: 1.0178889036178589
Validation loss: 1.7600071891661613

Epoch: 5| Step: 7
Training loss: 0.9075658917427063
Validation loss: 1.8048013025714504

Epoch: 5| Step: 8
Training loss: 1.2677689790725708
Validation loss: 1.7587135966106127

Epoch: 5| Step: 9
Training loss: 1.4914557933807373
Validation loss: 1.8028321253356112

Epoch: 5| Step: 10
Training loss: 1.3446215391159058
Validation loss: 1.807559105657762

Epoch: 420| Step: 0
Training loss: 1.2233160734176636
Validation loss: 1.7263034518047045

Epoch: 5| Step: 1
Training loss: 1.3435194492340088
Validation loss: 1.7924344872915616

Epoch: 5| Step: 2
Training loss: 1.4367356300354004
Validation loss: 1.7516450830685195

Epoch: 5| Step: 3
Training loss: 1.5812991857528687
Validation loss: 1.731228627184386

Epoch: 5| Step: 4
Training loss: 0.9752333760261536
Validation loss: 1.8178632451641945

Epoch: 5| Step: 5
Training loss: 1.8443443775177002
Validation loss: 1.7664849206965456

Epoch: 5| Step: 6
Training loss: 1.4750282764434814
Validation loss: 1.7728608269845285

Epoch: 5| Step: 7
Training loss: 1.7624984979629517
Validation loss: 1.7565944322975733

Epoch: 5| Step: 8
Training loss: 1.5010578632354736
Validation loss: 1.7672594260143977

Epoch: 5| Step: 9
Training loss: 0.9535163640975952
Validation loss: 1.8017566229707451

Epoch: 5| Step: 10
Training loss: 1.155946969985962
Validation loss: 1.7979544644714684

Epoch: 421| Step: 0
Training loss: 1.5312764644622803
Validation loss: 1.807017977519702

Epoch: 5| Step: 1
Training loss: 1.7872884273529053
Validation loss: 1.7631732135690668

Epoch: 5| Step: 2
Training loss: 1.1974949836730957
Validation loss: 1.7297630438240625

Epoch: 5| Step: 3
Training loss: 1.7364552021026611
Validation loss: 1.804240257509293

Epoch: 5| Step: 4
Training loss: 1.302695393562317
Validation loss: 1.7398421790010186

Epoch: 5| Step: 5
Training loss: 1.3869953155517578
Validation loss: 1.828251325955955

Epoch: 5| Step: 6
Training loss: 1.0224134922027588
Validation loss: 1.7738082434541436

Epoch: 5| Step: 7
Training loss: 1.0997015237808228
Validation loss: 1.7618071776564403

Epoch: 5| Step: 8
Training loss: 1.431728482246399
Validation loss: 1.825415229284635

Epoch: 5| Step: 9
Training loss: 1.5662745237350464
Validation loss: 1.7747125843519806

Epoch: 5| Step: 10
Training loss: 0.8802781105041504
Validation loss: 1.8347368381356681

Epoch: 422| Step: 0
Training loss: 1.4822388887405396
Validation loss: 1.8489529855789677

Epoch: 5| Step: 1
Training loss: 1.7724273204803467
Validation loss: 1.8077771074028426

Epoch: 5| Step: 2
Training loss: 1.4836872816085815
Validation loss: 1.762113953149447

Epoch: 5| Step: 3
Training loss: 1.613989233970642
Validation loss: 1.8135780044781264

Epoch: 5| Step: 4
Training loss: 1.7022857666015625
Validation loss: 1.814351733012866

Epoch: 5| Step: 5
Training loss: 0.9183534383773804
Validation loss: 1.7490379105332077

Epoch: 5| Step: 6
Training loss: 1.4356509447097778
Validation loss: 1.8133048498502342

Epoch: 5| Step: 7
Training loss: 1.073941946029663
Validation loss: 1.8237106864170363

Epoch: 5| Step: 8
Training loss: 1.349287748336792
Validation loss: 1.7309125341394895

Epoch: 5| Step: 9
Training loss: 1.453413724899292
Validation loss: 1.7828166266923309

Epoch: 5| Step: 10
Training loss: 1.4111275672912598
Validation loss: 1.7864477634429932

Epoch: 423| Step: 0
Training loss: 1.2747547626495361
Validation loss: 1.7602972445949432

Epoch: 5| Step: 1
Training loss: 2.0204079151153564
Validation loss: 1.8479312786491968

Epoch: 5| Step: 2
Training loss: 1.3066937923431396
Validation loss: 1.7833258131498932

Epoch: 5| Step: 3
Training loss: 0.8112010955810547
Validation loss: 1.8251707259044851

Epoch: 5| Step: 4
Training loss: 1.119584083557129
Validation loss: 1.872105501031363

Epoch: 5| Step: 5
Training loss: 1.7630484104156494
Validation loss: 1.8453239343499626

Epoch: 5| Step: 6
Training loss: 1.297242522239685
Validation loss: 1.8129584725185106

Epoch: 5| Step: 7
Training loss: 1.3604310750961304
Validation loss: 1.7646165868287444

Epoch: 5| Step: 8
Training loss: 1.3475797176361084
Validation loss: 1.7787605767608972

Epoch: 5| Step: 9
Training loss: 1.4775059223175049
Validation loss: 1.8359024268324657

Epoch: 5| Step: 10
Training loss: 1.2843444347381592
Validation loss: 1.772681966904671

Epoch: 424| Step: 0
Training loss: 1.2896487712860107
Validation loss: 1.7502512598550448

Epoch: 5| Step: 1
Training loss: 1.0899498462677002
Validation loss: 1.7625340107948548

Epoch: 5| Step: 2
Training loss: 1.1460689306259155
Validation loss: 1.7846520972508255

Epoch: 5| Step: 3
Training loss: 1.537697434425354
Validation loss: 1.8627088557007492

Epoch: 5| Step: 4
Training loss: 1.2237790822982788
Validation loss: 1.7615900860037854

Epoch: 5| Step: 5
Training loss: 1.4819214344024658
Validation loss: 1.785284003903789

Epoch: 5| Step: 6
Training loss: 1.3604508638381958
Validation loss: 1.7310235795154367

Epoch: 5| Step: 7
Training loss: 1.2738144397735596
Validation loss: 1.801682896511529

Epoch: 5| Step: 8
Training loss: 1.4449865818023682
Validation loss: 1.8438314263538649

Epoch: 5| Step: 9
Training loss: 1.699798583984375
Validation loss: 1.7309178178028395

Epoch: 5| Step: 10
Training loss: 1.2829099893569946
Validation loss: 1.7515239279757264

Epoch: 425| Step: 0
Training loss: 1.6834716796875
Validation loss: 1.7990456434988207

Epoch: 5| Step: 1
Training loss: 1.5551519393920898
Validation loss: 1.7855056306367278

Epoch: 5| Step: 2
Training loss: 1.4264756441116333
Validation loss: 1.7992983607835666

Epoch: 5| Step: 3
Training loss: 1.298012137413025
Validation loss: 1.7958203797699304

Epoch: 5| Step: 4
Training loss: 1.3088401556015015
Validation loss: 1.7733911596318728

Epoch: 5| Step: 5
Training loss: 0.9924535751342773
Validation loss: 1.83030108738971

Epoch: 5| Step: 6
Training loss: 1.3739798069000244
Validation loss: 1.8131201767152356

Epoch: 5| Step: 7
Training loss: 1.2202121019363403
Validation loss: 1.8315372261949765

Epoch: 5| Step: 8
Training loss: 1.322972297668457
Validation loss: 1.853943197957931

Epoch: 5| Step: 9
Training loss: 1.5614588260650635
Validation loss: 1.7751037933493172

Epoch: 5| Step: 10
Training loss: 1.391188621520996
Validation loss: 1.795351602697885

Epoch: 426| Step: 0
Training loss: 1.4449337720870972
Validation loss: 1.8653793642597813

Epoch: 5| Step: 1
Training loss: 1.961059331893921
Validation loss: 1.779992731668616

Epoch: 5| Step: 2
Training loss: 1.0409502983093262
Validation loss: 1.780672570710541

Epoch: 5| Step: 3
Training loss: 1.360478401184082
Validation loss: 1.786135591486449

Epoch: 5| Step: 4
Training loss: 1.6698787212371826
Validation loss: 1.8130080571738623

Epoch: 5| Step: 5
Training loss: 0.9519802927970886
Validation loss: 1.7830633219852243

Epoch: 5| Step: 6
Training loss: 1.13210928440094
Validation loss: 1.7239254879695114

Epoch: 5| Step: 7
Training loss: 1.0831944942474365
Validation loss: 1.7380606589778778

Epoch: 5| Step: 8
Training loss: 1.6928989887237549
Validation loss: 1.8436513587992678

Epoch: 5| Step: 9
Training loss: 1.2815845012664795
Validation loss: 1.780378467293196

Epoch: 5| Step: 10
Training loss: 1.3079367876052856
Validation loss: 1.8222560780022734

Epoch: 427| Step: 0
Training loss: 1.7051317691802979
Validation loss: 1.8013630784967893

Epoch: 5| Step: 1
Training loss: 1.6400432586669922
Validation loss: 1.7755825699016612

Epoch: 5| Step: 2
Training loss: 1.3965222835540771
Validation loss: 1.827871923805565

Epoch: 5| Step: 3
Training loss: 1.5668580532073975
Validation loss: 1.8705362786528885

Epoch: 5| Step: 4
Training loss: 1.1573659181594849
Validation loss: 1.817914278276505

Epoch: 5| Step: 5
Training loss: 1.8177064657211304
Validation loss: 1.761975924173991

Epoch: 5| Step: 6
Training loss: 0.8348514437675476
Validation loss: 1.8635073400312854

Epoch: 5| Step: 7
Training loss: 1.187234878540039
Validation loss: 1.853608141663254

Epoch: 5| Step: 8
Training loss: 1.5761862993240356
Validation loss: 1.823009011565998

Epoch: 5| Step: 9
Training loss: 1.3614637851715088
Validation loss: 1.8161179224650066

Epoch: 5| Step: 10
Training loss: 0.9891295433044434
Validation loss: 1.8625510764378372

Epoch: 428| Step: 0
Training loss: 1.0646793842315674
Validation loss: 1.8280832370122273

Epoch: 5| Step: 1
Training loss: 1.3223384618759155
Validation loss: 1.824664838852421

Epoch: 5| Step: 2
Training loss: 1.6774975061416626
Validation loss: 1.7980617374502204

Epoch: 5| Step: 3
Training loss: 1.2739925384521484
Validation loss: 1.788405208177464

Epoch: 5| Step: 4
Training loss: 0.9300432205200195
Validation loss: 1.8445142981826619

Epoch: 5| Step: 5
Training loss: 1.265454649925232
Validation loss: 1.8270783924287366

Epoch: 5| Step: 6
Training loss: 1.4219508171081543
Validation loss: 1.8000304058033934

Epoch: 5| Step: 7
Training loss: 1.5952391624450684
Validation loss: 1.757851964683943

Epoch: 5| Step: 8
Training loss: 1.886670470237732
Validation loss: 1.7931900203868907

Epoch: 5| Step: 9
Training loss: 1.278490662574768
Validation loss: 1.7599342728173861

Epoch: 5| Step: 10
Training loss: 1.3488364219665527
Validation loss: 1.7509224966008177

Epoch: 429| Step: 0
Training loss: 1.5099685192108154
Validation loss: 1.778434391944639

Epoch: 5| Step: 1
Training loss: 1.167750358581543
Validation loss: 1.8520146928807741

Epoch: 5| Step: 2
Training loss: 1.505807876586914
Validation loss: 1.7696056263421172

Epoch: 5| Step: 3
Training loss: 0.8575929403305054
Validation loss: 1.7752392138204267

Epoch: 5| Step: 4
Training loss: 1.4486186504364014
Validation loss: 1.8168661581572665

Epoch: 5| Step: 5
Training loss: 0.8070497512817383
Validation loss: 1.7788037638510428

Epoch: 5| Step: 6
Training loss: 1.2796727418899536
Validation loss: 1.832067794697259

Epoch: 5| Step: 7
Training loss: 1.7257916927337646
Validation loss: 1.8296771049499512

Epoch: 5| Step: 8
Training loss: 1.3361663818359375
Validation loss: 1.8473939062446676

Epoch: 5| Step: 9
Training loss: 2.0130743980407715
Validation loss: 1.8569037760457685

Epoch: 5| Step: 10
Training loss: 1.340084195137024
Validation loss: 1.8715767488684705

Epoch: 430| Step: 0
Training loss: 1.9937465190887451
Validation loss: 1.8332378313105593

Epoch: 5| Step: 1
Training loss: 1.064197301864624
Validation loss: 1.7933316756320257

Epoch: 5| Step: 2
Training loss: 1.5642058849334717
Validation loss: 1.8798276352626022

Epoch: 5| Step: 3
Training loss: 1.3792046308517456
Validation loss: 1.9159058165806595

Epoch: 5| Step: 4
Training loss: 2.2987937927246094
Validation loss: 1.9533627802325833

Epoch: 5| Step: 5
Training loss: 1.350256323814392
Validation loss: 1.819427441525203

Epoch: 5| Step: 6
Training loss: 1.0376057624816895
Validation loss: 1.835667323040706

Epoch: 5| Step: 7
Training loss: 1.718743920326233
Validation loss: 1.8219823721916444

Epoch: 5| Step: 8
Training loss: 0.7025333642959595
Validation loss: 1.8287329776312715

Epoch: 5| Step: 9
Training loss: 0.7235904335975647
Validation loss: 1.868364143115218

Epoch: 5| Step: 10
Training loss: 1.2705475091934204
Validation loss: 1.7786728771783973

Epoch: 431| Step: 0
Training loss: 1.2741681337356567
Validation loss: 1.8163279359058668

Epoch: 5| Step: 1
Training loss: 0.9336687326431274
Validation loss: 1.7851326106697

Epoch: 5| Step: 2
Training loss: 1.1479442119598389
Validation loss: 1.8148870532230665

Epoch: 5| Step: 3
Training loss: 1.2215839624404907
Validation loss: 1.8190954731356712

Epoch: 5| Step: 4
Training loss: 1.0631041526794434
Validation loss: 1.8019034080607916

Epoch: 5| Step: 5
Training loss: 1.20011305809021
Validation loss: 1.7938271543031097

Epoch: 5| Step: 6
Training loss: 1.6857086420059204
Validation loss: 1.764920582053482

Epoch: 5| Step: 7
Training loss: 1.685689926147461
Validation loss: 1.8234508601568078

Epoch: 5| Step: 8
Training loss: 1.365452527999878
Validation loss: 1.7419273584119734

Epoch: 5| Step: 9
Training loss: 1.915197730064392
Validation loss: 1.791671702938695

Epoch: 5| Step: 10
Training loss: 1.3661741018295288
Validation loss: 1.7970575094223022

Epoch: 432| Step: 0
Training loss: 1.1617906093597412
Validation loss: 1.7892111809022966

Epoch: 5| Step: 1
Training loss: 1.1389269828796387
Validation loss: 1.7912287622369745

Epoch: 5| Step: 2
Training loss: 0.8473127484321594
Validation loss: 1.7325660080038092

Epoch: 5| Step: 3
Training loss: 1.8379684686660767
Validation loss: 1.7755658472737958

Epoch: 5| Step: 4
Training loss: 1.6035776138305664
Validation loss: 1.833628608334449

Epoch: 5| Step: 5
Training loss: 1.0200049877166748
Validation loss: 1.8436995731886996

Epoch: 5| Step: 6
Training loss: 1.2113685607910156
Validation loss: 1.8089486001640238

Epoch: 5| Step: 7
Training loss: 1.266782522201538
Validation loss: 1.828231426977342

Epoch: 5| Step: 8
Training loss: 1.9638891220092773
Validation loss: 1.8148926637505973

Epoch: 5| Step: 9
Training loss: 1.742346167564392
Validation loss: 1.8275556243875974

Epoch: 5| Step: 10
Training loss: 1.1158249378204346
Validation loss: 1.923702024644421

Epoch: 433| Step: 0
Training loss: 1.7850475311279297
Validation loss: 1.8519020772749377

Epoch: 5| Step: 1
Training loss: 1.2987884283065796
Validation loss: 1.8344248520430697

Epoch: 5| Step: 2
Training loss: 1.191866397857666
Validation loss: 1.757461206887358

Epoch: 5| Step: 3
Training loss: 1.1663236618041992
Validation loss: 1.7321378812995007

Epoch: 5| Step: 4
Training loss: 1.4462599754333496
Validation loss: 1.8380264133535407

Epoch: 5| Step: 5
Training loss: 1.4233977794647217
Validation loss: 1.8544654243735856

Epoch: 5| Step: 6
Training loss: 1.5070772171020508
Validation loss: 1.8090484091030654

Epoch: 5| Step: 7
Training loss: 1.480597972869873
Validation loss: 1.7995512780322824

Epoch: 5| Step: 8
Training loss: 1.2575355768203735
Validation loss: 1.7954801090302006

Epoch: 5| Step: 9
Training loss: 1.4673436880111694
Validation loss: 1.7877851942534089

Epoch: 5| Step: 10
Training loss: 1.0744714736938477
Validation loss: 1.7586855965275918

Epoch: 434| Step: 0
Training loss: 0.650844931602478
Validation loss: 1.7561905589154971

Epoch: 5| Step: 1
Training loss: 1.1934351921081543
Validation loss: 1.78561915633499

Epoch: 5| Step: 2
Training loss: 1.331289291381836
Validation loss: 1.79757446371099

Epoch: 5| Step: 3
Training loss: 0.6769252419471741
Validation loss: 1.777770346210849

Epoch: 5| Step: 4
Training loss: 1.4687362909317017
Validation loss: 1.7664772002927718

Epoch: 5| Step: 5
Training loss: 1.7669063806533813
Validation loss: 1.7639747665774437

Epoch: 5| Step: 6
Training loss: 1.4888336658477783
Validation loss: 1.7858681383953299

Epoch: 5| Step: 7
Training loss: 1.7905547618865967
Validation loss: 1.8136667564351072

Epoch: 5| Step: 8
Training loss: 1.4342195987701416
Validation loss: 1.824256202226044

Epoch: 5| Step: 9
Training loss: 1.3953157663345337
Validation loss: 1.7676565647125244

Epoch: 5| Step: 10
Training loss: 1.4402563571929932
Validation loss: 1.7768225080223494

Epoch: 435| Step: 0
Training loss: 1.2453616857528687
Validation loss: 1.8220514994795605

Epoch: 5| Step: 1
Training loss: 1.6237618923187256
Validation loss: 1.7871706472930087

Epoch: 5| Step: 2
Training loss: 1.1164271831512451
Validation loss: 1.7874058100485033

Epoch: 5| Step: 3
Training loss: 1.1003425121307373
Validation loss: 1.7985903037491666

Epoch: 5| Step: 4
Training loss: 1.3712373971939087
Validation loss: 1.7855587338888517

Epoch: 5| Step: 5
Training loss: 0.9135446548461914
Validation loss: 1.8455706245155745

Epoch: 5| Step: 6
Training loss: 1.7249324321746826
Validation loss: 1.7704717215671335

Epoch: 5| Step: 7
Training loss: 1.580625295639038
Validation loss: 1.7707953888882872

Epoch: 5| Step: 8
Training loss: 1.1080806255340576
Validation loss: 1.822818870185524

Epoch: 5| Step: 9
Training loss: 1.2150344848632812
Validation loss: 1.8324602726967103

Epoch: 5| Step: 10
Training loss: 1.7477381229400635
Validation loss: 1.8017778024878552

Epoch: 436| Step: 0
Training loss: 1.5427446365356445
Validation loss: 1.8080961281253445

Epoch: 5| Step: 1
Training loss: 1.1526556015014648
Validation loss: 1.794287891798122

Epoch: 5| Step: 2
Training loss: 1.635128378868103
Validation loss: 1.8450558775214738

Epoch: 5| Step: 3
Training loss: 1.0286725759506226
Validation loss: 1.8144095354182745

Epoch: 5| Step: 4
Training loss: 1.5865504741668701
Validation loss: 1.7526092298569218

Epoch: 5| Step: 5
Training loss: 0.8136497735977173
Validation loss: 1.759292487175234

Epoch: 5| Step: 6
Training loss: 1.7367668151855469
Validation loss: 1.8106323775424753

Epoch: 5| Step: 7
Training loss: 0.9813923835754395
Validation loss: 1.7699365154389413

Epoch: 5| Step: 8
Training loss: 1.6468263864517212
Validation loss: 1.8393284710504676

Epoch: 5| Step: 9
Training loss: 1.3380577564239502
Validation loss: 1.744270646443931

Epoch: 5| Step: 10
Training loss: 1.315245509147644
Validation loss: 1.7790311075025989

Epoch: 437| Step: 0
Training loss: 2.052396297454834
Validation loss: 1.799337035866194

Epoch: 5| Step: 1
Training loss: 0.8534631729125977
Validation loss: 1.7840636507157357

Epoch: 5| Step: 2
Training loss: 1.3822720050811768
Validation loss: 1.8294224354528612

Epoch: 5| Step: 3
Training loss: 1.4339030981063843
Validation loss: 1.7998157624275453

Epoch: 5| Step: 4
Training loss: 1.4922292232513428
Validation loss: 1.7400335060652865

Epoch: 5| Step: 5
Training loss: 1.1813485622406006
Validation loss: 1.8699440187023533

Epoch: 5| Step: 6
Training loss: 0.976966381072998
Validation loss: 1.8457879020321755

Epoch: 5| Step: 7
Training loss: 1.9479217529296875
Validation loss: 1.8158249034676501

Epoch: 5| Step: 8
Training loss: 1.3718916177749634
Validation loss: 1.7928104708271642

Epoch: 5| Step: 9
Training loss: 1.3561900854110718
Validation loss: 1.7965286072864328

Epoch: 5| Step: 10
Training loss: 0.8910733461380005
Validation loss: 1.8155796015134422

Epoch: 438| Step: 0
Training loss: 1.4942665100097656
Validation loss: 1.8319643569248978

Epoch: 5| Step: 1
Training loss: 1.1593652963638306
Validation loss: 1.802214079005744

Epoch: 5| Step: 2
Training loss: 1.4867987632751465
Validation loss: 1.789017572197863

Epoch: 5| Step: 3
Training loss: 1.5840387344360352
Validation loss: 1.7313964418185654

Epoch: 5| Step: 4
Training loss: 0.9094374775886536
Validation loss: 1.7840277277013308

Epoch: 5| Step: 5
Training loss: 1.3758951425552368
Validation loss: 1.7709837767385668

Epoch: 5| Step: 6
Training loss: 1.1028844118118286
Validation loss: 1.7754584563675748

Epoch: 5| Step: 7
Training loss: 1.3344228267669678
Validation loss: 1.7668944251152776

Epoch: 5| Step: 8
Training loss: 1.5063273906707764
Validation loss: 1.8054762142960743

Epoch: 5| Step: 9
Training loss: 1.3075424432754517
Validation loss: 1.8034629206503592

Epoch: 5| Step: 10
Training loss: 1.4101057052612305
Validation loss: 1.7565391499509093

Epoch: 439| Step: 0
Training loss: 0.8975545763969421
Validation loss: 1.7442030522131151

Epoch: 5| Step: 1
Training loss: 1.6103706359863281
Validation loss: 1.8396185316065305

Epoch: 5| Step: 2
Training loss: 1.1759182214736938
Validation loss: 1.8165344166499313

Epoch: 5| Step: 3
Training loss: 1.467678427696228
Validation loss: 1.8624807186024164

Epoch: 5| Step: 4
Training loss: 1.1294010877609253
Validation loss: 1.8225064213557909

Epoch: 5| Step: 5
Training loss: 1.3656957149505615
Validation loss: 1.8603373009671447

Epoch: 5| Step: 6
Training loss: 1.5880446434020996
Validation loss: 1.8011523395456293

Epoch: 5| Step: 7
Training loss: 1.4269332885742188
Validation loss: 1.8586268322442168

Epoch: 5| Step: 8
Training loss: 1.7913020849227905
Validation loss: 1.8428489444076375

Epoch: 5| Step: 9
Training loss: 1.3540388345718384
Validation loss: 1.846834824931237

Epoch: 5| Step: 10
Training loss: 1.3646149635314941
Validation loss: 1.8401409118406233

Epoch: 440| Step: 0
Training loss: 1.2992274761199951
Validation loss: 1.777751144542489

Epoch: 5| Step: 1
Training loss: 1.69780695438385
Validation loss: 1.8443309363498483

Epoch: 5| Step: 2
Training loss: 1.2874767780303955
Validation loss: 1.7909986319080475

Epoch: 5| Step: 3
Training loss: 1.4940718412399292
Validation loss: 1.7440948012054607

Epoch: 5| Step: 4
Training loss: 0.973339855670929
Validation loss: 1.7672478511769285

Epoch: 5| Step: 5
Training loss: 0.8475151062011719
Validation loss: 1.806174200068238

Epoch: 5| Step: 6
Training loss: 1.5161606073379517
Validation loss: 1.7678920607413016

Epoch: 5| Step: 7
Training loss: 1.3160302639007568
Validation loss: 1.7720382803229875

Epoch: 5| Step: 8
Training loss: 1.2148017883300781
Validation loss: 1.7806459473025413

Epoch: 5| Step: 9
Training loss: 1.332821011543274
Validation loss: 1.8187195524092643

Epoch: 5| Step: 10
Training loss: 1.7454733848571777
Validation loss: 1.774352535124748

Epoch: 441| Step: 0
Training loss: 1.5134646892547607
Validation loss: 1.8120622904069963

Epoch: 5| Step: 1
Training loss: 1.6245880126953125
Validation loss: 1.7360473525139593

Epoch: 5| Step: 2
Training loss: 0.895682156085968
Validation loss: 1.7986926135196482

Epoch: 5| Step: 3
Training loss: 1.43499755859375
Validation loss: 1.765909191100828

Epoch: 5| Step: 4
Training loss: 1.6561729907989502
Validation loss: 1.8519933556997648

Epoch: 5| Step: 5
Training loss: 1.581486463546753
Validation loss: 1.8290769207862116

Epoch: 5| Step: 6
Training loss: 1.0399279594421387
Validation loss: 1.8004000468920636

Epoch: 5| Step: 7
Training loss: 1.0688631534576416
Validation loss: 1.787313235703335

Epoch: 5| Step: 8
Training loss: 1.7823054790496826
Validation loss: 1.8463342497425694

Epoch: 5| Step: 9
Training loss: 1.1276899576187134
Validation loss: 1.8573941620447303

Epoch: 5| Step: 10
Training loss: 1.4061816930770874
Validation loss: 1.8156188534152122

Epoch: 442| Step: 0
Training loss: 1.6605396270751953
Validation loss: 1.770730467252834

Epoch: 5| Step: 1
Training loss: 1.6896467208862305
Validation loss: 1.8075071355347991

Epoch: 5| Step: 2
Training loss: 1.7068006992340088
Validation loss: 1.8268116635660971

Epoch: 5| Step: 3
Training loss: 0.6152389645576477
Validation loss: 1.8262537512727963

Epoch: 5| Step: 4
Training loss: 0.9883478283882141
Validation loss: 1.7981096185663694

Epoch: 5| Step: 5
Training loss: 1.1430742740631104
Validation loss: 1.7820353392631776

Epoch: 5| Step: 6
Training loss: 1.9879481792449951
Validation loss: 1.8394046368137482

Epoch: 5| Step: 7
Training loss: 1.0278550386428833
Validation loss: 1.7465579317462059

Epoch: 5| Step: 8
Training loss: 1.6099598407745361
Validation loss: 1.7678095640674714

Epoch: 5| Step: 9
Training loss: 1.3955848217010498
Validation loss: 1.7721128848291212

Epoch: 5| Step: 10
Training loss: 1.1209421157836914
Validation loss: 1.76830602845838

Epoch: 443| Step: 0
Training loss: 1.0978920459747314
Validation loss: 1.764764319184006

Epoch: 5| Step: 1
Training loss: 1.244135856628418
Validation loss: 1.7701042800821283

Epoch: 5| Step: 2
Training loss: 0.8006242513656616
Validation loss: 1.795140294618504

Epoch: 5| Step: 3
Training loss: 1.3424081802368164
Validation loss: 1.7988033897133284

Epoch: 5| Step: 4
Training loss: 1.3347923755645752
Validation loss: 1.7834424639260897

Epoch: 5| Step: 5
Training loss: 1.5794060230255127
Validation loss: 1.820762263831272

Epoch: 5| Step: 6
Training loss: 1.2483837604522705
Validation loss: 1.7881282529523295

Epoch: 5| Step: 7
Training loss: 1.239436388015747
Validation loss: 1.880689844008415

Epoch: 5| Step: 8
Training loss: 2.56156063079834
Validation loss: 1.8814938170935518

Epoch: 5| Step: 9
Training loss: 1.6721986532211304
Validation loss: 1.857355986872027

Epoch: 5| Step: 10
Training loss: 1.0492029190063477
Validation loss: 1.859780200066105

Epoch: 444| Step: 0
Training loss: 1.1986225843429565
Validation loss: 1.8228532383518834

Epoch: 5| Step: 1
Training loss: 1.4021446704864502
Validation loss: 1.8512040210026566

Epoch: 5| Step: 2
Training loss: 1.079060435295105
Validation loss: 1.723167009251092

Epoch: 5| Step: 3
Training loss: 1.4753623008728027
Validation loss: 1.7820765344045495

Epoch: 5| Step: 4
Training loss: 1.2961511611938477
Validation loss: 1.7835910089554325

Epoch: 5| Step: 5
Training loss: 1.270165205001831
Validation loss: 1.7064854778269285

Epoch: 5| Step: 6
Training loss: 1.608660101890564
Validation loss: 1.8147587635183846

Epoch: 5| Step: 7
Training loss: 1.4429142475128174
Validation loss: 1.8961689318380048

Epoch: 5| Step: 8
Training loss: 1.2913000583648682
Validation loss: 1.7739778103366974

Epoch: 5| Step: 9
Training loss: 1.0834248065948486
Validation loss: 1.781405682204872

Epoch: 5| Step: 10
Training loss: 1.460871934890747
Validation loss: 1.7694666295923211

Epoch: 445| Step: 0
Training loss: 1.6555604934692383
Validation loss: 1.777037343671245

Epoch: 5| Step: 1
Training loss: 1.4316474199295044
Validation loss: 1.758167432200524

Epoch: 5| Step: 2
Training loss: 1.2111998796463013
Validation loss: 1.8298262011620305

Epoch: 5| Step: 3
Training loss: 1.735291838645935
Validation loss: 1.7809096100509807

Epoch: 5| Step: 4
Training loss: 1.1799840927124023
Validation loss: 1.7732098538388488

Epoch: 5| Step: 5
Training loss: 1.6392780542373657
Validation loss: 1.811677259783591

Epoch: 5| Step: 6
Training loss: 1.1660971641540527
Validation loss: 1.7770109304817774

Epoch: 5| Step: 7
Training loss: 1.2317222356796265
Validation loss: 1.8055646650252803

Epoch: 5| Step: 8
Training loss: 1.3692950010299683
Validation loss: 1.7584009670442151

Epoch: 5| Step: 9
Training loss: 0.9318224787712097
Validation loss: 1.7933133148377942

Epoch: 5| Step: 10
Training loss: 0.9946218132972717
Validation loss: 1.7911991573149157

Epoch: 446| Step: 0
Training loss: 0.9320691227912903
Validation loss: 1.8442762513314523

Epoch: 5| Step: 1
Training loss: 1.179628610610962
Validation loss: 1.8134728170210315

Epoch: 5| Step: 2
Training loss: 1.5333524942398071
Validation loss: 1.8692372255427863

Epoch: 5| Step: 3
Training loss: 1.5203298330307007
Validation loss: 1.777830276437985

Epoch: 5| Step: 4
Training loss: 0.6612359881401062
Validation loss: 1.8114810605202951

Epoch: 5| Step: 5
Training loss: 2.0282294750213623
Validation loss: 1.8265933785387265

Epoch: 5| Step: 6
Training loss: 1.177469253540039
Validation loss: 1.8329687003166444

Epoch: 5| Step: 7
Training loss: 1.916476845741272
Validation loss: 1.8826401054218251

Epoch: 5| Step: 8
Training loss: 1.3942253589630127
Validation loss: 1.9010586764222832

Epoch: 5| Step: 9
Training loss: 1.2444835901260376
Validation loss: 1.8263033859191402

Epoch: 5| Step: 10
Training loss: 0.9566879272460938
Validation loss: 1.8487006502766763

Epoch: 447| Step: 0
Training loss: 1.7881040573120117
Validation loss: 1.8485720465260167

Epoch: 5| Step: 1
Training loss: 1.5049059391021729
Validation loss: 1.8066650731589204

Epoch: 5| Step: 2
Training loss: 1.402462363243103
Validation loss: 1.8332706651379984

Epoch: 5| Step: 3
Training loss: 0.874284565448761
Validation loss: 1.8211193930718206

Epoch: 5| Step: 4
Training loss: 1.2827837467193604
Validation loss: 1.7708137907007688

Epoch: 5| Step: 5
Training loss: 0.8590182065963745
Validation loss: 1.7725123051674134

Epoch: 5| Step: 6
Training loss: 1.4580732583999634
Validation loss: 1.8115952091832315

Epoch: 5| Step: 7
Training loss: 1.1207733154296875
Validation loss: 1.78053758734016

Epoch: 5| Step: 8
Training loss: 1.3927714824676514
Validation loss: 1.7975090703656595

Epoch: 5| Step: 9
Training loss: 1.5292937755584717
Validation loss: 1.7841373066748343

Epoch: 5| Step: 10
Training loss: 1.0558440685272217
Validation loss: 1.7952664206104894

Epoch: 448| Step: 0
Training loss: 1.1337653398513794
Validation loss: 1.8339519398186797

Epoch: 5| Step: 1
Training loss: 1.1367849111557007
Validation loss: 1.7470433558187177

Epoch: 5| Step: 2
Training loss: 1.5309947729110718
Validation loss: 1.7907394478397984

Epoch: 5| Step: 3
Training loss: 1.5152283906936646
Validation loss: 1.824336996642492

Epoch: 5| Step: 4
Training loss: 1.392249584197998
Validation loss: 1.7904444176663634

Epoch: 5| Step: 5
Training loss: 1.2785756587982178
Validation loss: 1.7809736831213838

Epoch: 5| Step: 6
Training loss: 1.562338948249817
Validation loss: 1.7644510064073788

Epoch: 5| Step: 7
Training loss: 1.1787490844726562
Validation loss: 1.7826197083278368

Epoch: 5| Step: 8
Training loss: 1.1901953220367432
Validation loss: 1.8031745597880373

Epoch: 5| Step: 9
Training loss: 1.4561750888824463
Validation loss: 1.8009335815265615

Epoch: 5| Step: 10
Training loss: 1.0927906036376953
Validation loss: 1.784401939761254

Epoch: 449| Step: 0
Training loss: 0.8866910934448242
Validation loss: 1.7130442486014417

Epoch: 5| Step: 1
Training loss: 1.8856470584869385
Validation loss: 1.7929294801527453

Epoch: 5| Step: 2
Training loss: 1.395707130432129
Validation loss: 1.6917796314403575

Epoch: 5| Step: 3
Training loss: 1.9943933486938477
Validation loss: 1.7519449815955213

Epoch: 5| Step: 4
Training loss: 0.9294670224189758
Validation loss: 1.798829404256677

Epoch: 5| Step: 5
Training loss: 0.9010607004165649
Validation loss: 1.8723394306757117

Epoch: 5| Step: 6
Training loss: 1.4731483459472656
Validation loss: 1.810356511864611

Epoch: 5| Step: 7
Training loss: 1.7382938861846924
Validation loss: 1.735606248019844

Epoch: 5| Step: 8
Training loss: 1.032198190689087
Validation loss: 1.7911166606410858

Epoch: 5| Step: 9
Training loss: 1.3796064853668213
Validation loss: 1.7799142355559974

Epoch: 5| Step: 10
Training loss: 1.239762783050537
Validation loss: 1.7552137080059256

Epoch: 450| Step: 0
Training loss: 0.9992696642875671
Validation loss: 1.7823408201176634

Epoch: 5| Step: 1
Training loss: 1.6227366924285889
Validation loss: 1.8159673457504601

Epoch: 5| Step: 2
Training loss: 1.651946783065796
Validation loss: 1.7647234919250652

Epoch: 5| Step: 3
Training loss: 1.7669923305511475
Validation loss: 1.8816007465444586

Epoch: 5| Step: 4
Training loss: 1.0783607959747314
Validation loss: 1.8521017848804433

Epoch: 5| Step: 5
Training loss: 1.474474310874939
Validation loss: 1.7944523608812721

Epoch: 5| Step: 6
Training loss: 1.7115042209625244
Validation loss: 1.741338679867406

Epoch: 5| Step: 7
Training loss: 0.6620770692825317
Validation loss: 1.771844196063216

Epoch: 5| Step: 8
Training loss: 0.5946937203407288
Validation loss: 1.7605066043074413

Epoch: 5| Step: 9
Training loss: 1.6699163913726807
Validation loss: 1.8263323550583215

Epoch: 5| Step: 10
Training loss: 1.699965476989746
Validation loss: 1.7895538255732546

Testing loss: 2.238104502360026
