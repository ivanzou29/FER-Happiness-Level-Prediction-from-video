Epoch: 1| Step: 0
Training loss: 5.307617457020462
Validation loss: 4.869133390777123

Epoch: 6| Step: 1
Training loss: 4.080555626303893
Validation loss: 4.863485517518513

Epoch: 6| Step: 2
Training loss: 6.055011962072399
Validation loss: 4.859035218787107

Epoch: 6| Step: 3
Training loss: 4.831180926343621
Validation loss: 4.855203609239538

Epoch: 6| Step: 4
Training loss: 5.183130837233313
Validation loss: 4.852293450657977

Epoch: 6| Step: 5
Training loss: 5.151955960873338
Validation loss: 4.845915967381872

Epoch: 6| Step: 6
Training loss: 4.517087494974595
Validation loss: 4.8447938385115314

Epoch: 6| Step: 7
Training loss: 4.078801241525639
Validation loss: 4.839014363147384

Epoch: 6| Step: 8
Training loss: 6.055539884556705
Validation loss: 4.837264645673209

Epoch: 6| Step: 9
Training loss: 5.0049429302791815
Validation loss: 4.829096424706365

Epoch: 6| Step: 10
Training loss: 4.5822626886349775
Validation loss: 4.825661991780323

Epoch: 6| Step: 11
Training loss: 5.283068462354968
Validation loss: 4.821210053707181

Epoch: 6| Step: 12
Training loss: 3.8482181042028594
Validation loss: 4.817189242249528

Epoch: 6| Step: 13
Training loss: 3.9817874659441825
Validation loss: 4.8115466712730655

Epoch: 2| Step: 0
Training loss: 5.325986729569901
Validation loss: 4.806332336545794

Epoch: 6| Step: 1
Training loss: 5.204997141138294
Validation loss: 4.802239389490625

Epoch: 6| Step: 2
Training loss: 3.7824735317073146
Validation loss: 4.797724017072977

Epoch: 6| Step: 3
Training loss: 6.308908781801322
Validation loss: 4.795209760139365

Epoch: 6| Step: 4
Training loss: 4.638870883888942
Validation loss: 4.78921873563185

Epoch: 6| Step: 5
Training loss: 3.983714090023254
Validation loss: 4.78631211438354

Epoch: 6| Step: 6
Training loss: 4.922262897041145
Validation loss: 4.780103785889433

Epoch: 6| Step: 7
Training loss: 4.198861267487117
Validation loss: 4.7767163537502295

Epoch: 6| Step: 8
Training loss: 5.348010768243282
Validation loss: 4.772663889237094

Epoch: 6| Step: 9
Training loss: 4.42138475052586
Validation loss: 4.770136973892964

Epoch: 6| Step: 10
Training loss: 5.260632420512302
Validation loss: 4.761646237526561

Epoch: 6| Step: 11
Training loss: 5.0932339834007205
Validation loss: 4.758645417904773

Epoch: 6| Step: 12
Training loss: 4.810627164182291
Validation loss: 4.755371344703009

Epoch: 6| Step: 13
Training loss: 3.7728066242810208
Validation loss: 4.75062454815403

Epoch: 3| Step: 0
Training loss: 4.432270030571396
Validation loss: 4.743780603428585

Epoch: 6| Step: 1
Training loss: 4.421428105177988
Validation loss: 4.7412524847246775

Epoch: 6| Step: 2
Training loss: 5.20723051475437
Validation loss: 4.736806171574544

Epoch: 6| Step: 3
Training loss: 5.152041110390076
Validation loss: 4.731969531407824

Epoch: 6| Step: 4
Training loss: 5.16395483323134
Validation loss: 4.72845555478884

Epoch: 6| Step: 5
Training loss: 5.273251226455502
Validation loss: 4.7222331403830875

Epoch: 6| Step: 6
Training loss: 3.6259155432685555
Validation loss: 4.719590020284161

Epoch: 6| Step: 7
Training loss: 4.437317105674721
Validation loss: 4.711556008623822

Epoch: 6| Step: 8
Training loss: 5.295727270681474
Validation loss: 4.709300403701099

Epoch: 6| Step: 9
Training loss: 4.807927721568834
Validation loss: 4.704377075542401

Epoch: 6| Step: 10
Training loss: 4.871143478470101
Validation loss: 4.698468070929255

Epoch: 6| Step: 11
Training loss: 5.061312689304625
Validation loss: 4.693815719100499

Epoch: 6| Step: 12
Training loss: 4.710521470863478
Validation loss: 4.687383340457208

Epoch: 6| Step: 13
Training loss: 4.343634953793471
Validation loss: 4.6828526627085045

Epoch: 4| Step: 0
Training loss: 5.337420010469859
Validation loss: 4.6765753540083

Epoch: 6| Step: 1
Training loss: 5.1035757955456
Validation loss: 4.673405891588834

Epoch: 6| Step: 2
Training loss: 5.359639419839114
Validation loss: 4.666571916476768

Epoch: 6| Step: 3
Training loss: 4.159429037085593
Validation loss: 4.663623155022213

Epoch: 6| Step: 4
Training loss: 3.7057928462755223
Validation loss: 4.657706555433056

Epoch: 6| Step: 5
Training loss: 5.471127761545539
Validation loss: 4.6534207245062325

Epoch: 6| Step: 6
Training loss: 4.75627544862453
Validation loss: 4.643930409753798

Epoch: 6| Step: 7
Training loss: 4.3147519631114175
Validation loss: 4.641286451004037

Epoch: 6| Step: 8
Training loss: 4.585531759428085
Validation loss: 4.637473080539831

Epoch: 6| Step: 9
Training loss: 3.731767709876717
Validation loss: 4.630441951151483

Epoch: 6| Step: 10
Training loss: 5.693018656721692
Validation loss: 4.622686470966679

Epoch: 6| Step: 11
Training loss: 4.807175899060874
Validation loss: 4.621639996759537

Epoch: 6| Step: 12
Training loss: 4.327270423445587
Validation loss: 4.611875292742334

Epoch: 6| Step: 13
Training loss: 4.257791893585457
Validation loss: 4.606721953603164

Epoch: 5| Step: 0
Training loss: 4.242307994950795
Validation loss: 4.601964708079682

Epoch: 6| Step: 1
Training loss: 4.812662493451926
Validation loss: 4.596230696589326

Epoch: 6| Step: 2
Training loss: 4.02451489291455
Validation loss: 4.589830599565066

Epoch: 6| Step: 3
Training loss: 3.962075816654258
Validation loss: 4.583389717418982

Epoch: 6| Step: 4
Training loss: 6.013573551891892
Validation loss: 4.580008587185908

Epoch: 6| Step: 5
Training loss: 4.6055403971579185
Validation loss: 4.572126808583582

Epoch: 6| Step: 6
Training loss: 5.591374580194473
Validation loss: 4.566872055456556

Epoch: 6| Step: 7
Training loss: 4.368489898666469
Validation loss: 4.562587874854854

Epoch: 6| Step: 8
Training loss: 5.293278466203754
Validation loss: 4.5548653527860195

Epoch: 6| Step: 9
Training loss: 3.996569831657083
Validation loss: 4.550108350536251

Epoch: 6| Step: 10
Training loss: 3.6228039107380874
Validation loss: 4.54590251482679

Epoch: 6| Step: 11
Training loss: 4.877685980680085
Validation loss: 4.536100518014649

Epoch: 6| Step: 12
Training loss: 4.068576903990096
Validation loss: 4.53008136438871

Epoch: 6| Step: 13
Training loss: 5.5017784017784095
Validation loss: 4.5229698127961555

Epoch: 6| Step: 0
Training loss: 4.4512382927526115
Validation loss: 4.517056858908559

Epoch: 6| Step: 1
Training loss: 4.022356025011133
Validation loss: 4.5142998280770295

Epoch: 6| Step: 2
Training loss: 5.35757140125823
Validation loss: 4.507565383932412

Epoch: 6| Step: 3
Training loss: 4.778408028682169
Validation loss: 4.499167708312208

Epoch: 6| Step: 4
Training loss: 4.644242953888835
Validation loss: 4.491102304804572

Epoch: 6| Step: 5
Training loss: 3.957189347779518
Validation loss: 4.487864546351206

Epoch: 6| Step: 6
Training loss: 4.464109558989685
Validation loss: 4.4817881615442285

Epoch: 6| Step: 7
Training loss: 3.7380735843900204
Validation loss: 4.472203976027437

Epoch: 6| Step: 8
Training loss: 5.415208747482279
Validation loss: 4.4650309093024525

Epoch: 6| Step: 9
Training loss: 4.621982518016548
Validation loss: 4.458686042214993

Epoch: 6| Step: 10
Training loss: 4.3474557561306675
Validation loss: 4.453806724675111

Epoch: 6| Step: 11
Training loss: 4.878394876623419
Validation loss: 4.447716805891783

Epoch: 6| Step: 12
Training loss: 4.627880951849582
Validation loss: 4.440097570253526

Epoch: 6| Step: 13
Training loss: 4.459595593648231
Validation loss: 4.434914510061839

Epoch: 7| Step: 0
Training loss: 3.9210847461184355
Validation loss: 4.425888727661015

Epoch: 6| Step: 1
Training loss: 4.108411320583853
Validation loss: 4.419193310529326

Epoch: 6| Step: 2
Training loss: 3.612957782185124
Validation loss: 4.414353419430814

Epoch: 6| Step: 3
Training loss: 4.466290417287341
Validation loss: 4.404827692729384

Epoch: 6| Step: 4
Training loss: 4.807701195341845
Validation loss: 4.399982410500161

Epoch: 6| Step: 5
Training loss: 5.5182634046235615
Validation loss: 4.39346134512674

Epoch: 6| Step: 6
Training loss: 4.1771545150412255
Validation loss: 4.386349343151422

Epoch: 6| Step: 7
Training loss: 4.675294167142471
Validation loss: 4.378599427130345

Epoch: 6| Step: 8
Training loss: 5.219103772627358
Validation loss: 4.367164800925661

Epoch: 6| Step: 9
Training loss: 4.262284420524434
Validation loss: 4.360956275789503

Epoch: 6| Step: 10
Training loss: 4.635234540583229
Validation loss: 4.355536895532283

Epoch: 6| Step: 11
Training loss: 4.017054915493663
Validation loss: 4.3498962137723955

Epoch: 6| Step: 12
Training loss: 4.847079996659696
Validation loss: 4.340325168714586

Epoch: 6| Step: 13
Training loss: 3.9127708024465258
Validation loss: 4.331585053797344

Epoch: 8| Step: 0
Training loss: 4.439121863328429
Validation loss: 4.324668936951187

Epoch: 6| Step: 1
Training loss: 3.620723437948738
Validation loss: 4.316527322000953

Epoch: 6| Step: 2
Training loss: 3.7231815123675673
Validation loss: 4.304696428420599

Epoch: 6| Step: 3
Training loss: 5.068430876181588
Validation loss: 4.302266030500701

Epoch: 6| Step: 4
Training loss: 4.476656661449698
Validation loss: 4.289720551405359

Epoch: 6| Step: 5
Training loss: 4.795521498594438
Validation loss: 4.285157622409857

Epoch: 6| Step: 6
Training loss: 4.298437659743045
Validation loss: 4.272748203428239

Epoch: 6| Step: 7
Training loss: 4.137823114138806
Validation loss: 4.2621425359567375

Epoch: 6| Step: 8
Training loss: 4.259235445284651
Validation loss: 4.25788967201492

Epoch: 6| Step: 9
Training loss: 3.817896291452291
Validation loss: 4.246769267675863

Epoch: 6| Step: 10
Training loss: 4.245998069155411
Validation loss: 4.238680126114456

Epoch: 6| Step: 11
Training loss: 5.00881638485066
Validation loss: 4.229909561952573

Epoch: 6| Step: 12
Training loss: 4.455834992974846
Validation loss: 4.2203203020193305

Epoch: 6| Step: 13
Training loss: 5.005877664080909
Validation loss: 4.21253457534616

Epoch: 9| Step: 0
Training loss: 3.0609480370364035
Validation loss: 4.207122474208703

Epoch: 6| Step: 1
Training loss: 4.355028398773764
Validation loss: 4.194085875916613

Epoch: 6| Step: 2
Training loss: 3.7851436524235673
Validation loss: 4.190108386675145

Epoch: 6| Step: 3
Training loss: 4.9779439832172505
Validation loss: 4.17388296448547

Epoch: 6| Step: 4
Training loss: 4.594175773144286
Validation loss: 4.171115591202991

Epoch: 6| Step: 5
Training loss: 4.731623791299619
Validation loss: 4.15999213309053

Epoch: 6| Step: 6
Training loss: 4.832984232079018
Validation loss: 4.146867315293259

Epoch: 6| Step: 7
Training loss: 3.8996094679314197
Validation loss: 4.140522572602373

Epoch: 6| Step: 8
Training loss: 3.9539837413370598
Validation loss: 4.130394504198953

Epoch: 6| Step: 9
Training loss: 3.857603338295035
Validation loss: 4.118322387528845

Epoch: 6| Step: 10
Training loss: 4.205468187610263
Validation loss: 4.108665437177106

Epoch: 6| Step: 11
Training loss: 4.109875086535929
Validation loss: 4.100654686441544

Epoch: 6| Step: 12
Training loss: 4.681386190350889
Validation loss: 4.088321957609972

Epoch: 6| Step: 13
Training loss: 4.3970973410712055
Validation loss: 4.083419421361877

Epoch: 10| Step: 0
Training loss: 4.776391646424545
Validation loss: 4.070038702395454

Epoch: 6| Step: 1
Training loss: 4.128652400619553
Validation loss: 4.063613789405336

Epoch: 6| Step: 2
Training loss: 4.619817975244224
Validation loss: 4.053777196679715

Epoch: 6| Step: 3
Training loss: 3.6925043319645745
Validation loss: 4.042535473874026

Epoch: 6| Step: 4
Training loss: 4.584543149395791
Validation loss: 4.025297850162219

Epoch: 6| Step: 5
Training loss: 3.6844671676276572
Validation loss: 4.016313701523136

Epoch: 6| Step: 6
Training loss: 2.0719627856591076
Validation loss: 4.0077419371143

Epoch: 6| Step: 7
Training loss: 3.5188366948724212
Validation loss: 3.9981753484274205

Epoch: 6| Step: 8
Training loss: 4.536407482097252
Validation loss: 3.983340907354607

Epoch: 6| Step: 9
Training loss: 3.8771296155908055
Validation loss: 3.9776079118175174

Epoch: 6| Step: 10
Training loss: 4.746686884233373
Validation loss: 3.966772381111575

Epoch: 6| Step: 11
Training loss: 4.234840283044969
Validation loss: 3.9594742370482288

Epoch: 6| Step: 12
Training loss: 4.33392496227303
Validation loss: 3.945705739667512

Epoch: 6| Step: 13
Training loss: 4.481144076788703
Validation loss: 3.936132181407111

Epoch: 11| Step: 0
Training loss: 3.690739388756374
Validation loss: 3.9220212392649674

Epoch: 6| Step: 1
Training loss: 4.1159369580007334
Validation loss: 3.9095714573075755

Epoch: 6| Step: 2
Training loss: 4.2840869720492405
Validation loss: 3.9004264964347857

Epoch: 6| Step: 3
Training loss: 4.732288870396741
Validation loss: 3.8891187924128943

Epoch: 6| Step: 4
Training loss: 4.594667096619707
Validation loss: 3.87715302010885

Epoch: 6| Step: 5
Training loss: 4.459706365387582
Validation loss: 3.862824685334909

Epoch: 6| Step: 6
Training loss: 4.185596773719711
Validation loss: 3.855610517105143

Epoch: 6| Step: 7
Training loss: 3.537056663958775
Validation loss: 3.8383055354256417

Epoch: 6| Step: 8
Training loss: 3.5696501336575257
Validation loss: 3.8347216727450113

Epoch: 6| Step: 9
Training loss: 4.10770373572252
Validation loss: 3.8099401074407426

Epoch: 6| Step: 10
Training loss: 3.3951585407346787
Validation loss: 3.802863263576312

Epoch: 6| Step: 11
Training loss: 4.130285171749716
Validation loss: 3.7940198638361595

Epoch: 6| Step: 12
Training loss: 3.4479344915906944
Validation loss: 3.7751966101848775

Epoch: 6| Step: 13
Training loss: 2.749523988620842
Validation loss: 3.7580796300034973

Epoch: 12| Step: 0
Training loss: 4.444764973420452
Validation loss: 3.7486667929321453

Epoch: 6| Step: 1
Training loss: 4.242346210918083
Validation loss: 3.7382751767223645

Epoch: 6| Step: 2
Training loss: 3.074334303587898
Validation loss: 3.72393363923223

Epoch: 6| Step: 3
Training loss: 4.571511344500896
Validation loss: 3.7110162991078908

Epoch: 6| Step: 4
Training loss: 3.813256985916004
Validation loss: 3.701694112214818

Epoch: 6| Step: 5
Training loss: 3.2612745884896475
Validation loss: 3.679930965131398

Epoch: 6| Step: 6
Training loss: 3.5098107302680424
Validation loss: 3.6783786028393153

Epoch: 6| Step: 7
Training loss: 3.509594437081437
Validation loss: 3.6653061232198545

Epoch: 6| Step: 8
Training loss: 3.575163969534491
Validation loss: 3.648416349628972

Epoch: 6| Step: 9
Training loss: 3.6735944901787247
Validation loss: 3.6398646189834554

Epoch: 6| Step: 10
Training loss: 3.9558163855729185
Validation loss: 3.6265335177352798

Epoch: 6| Step: 11
Training loss: 3.7784479020603134
Validation loss: 3.6065697971976816

Epoch: 6| Step: 12
Training loss: 3.9371533922500968
Validation loss: 3.5994417207160416

Epoch: 6| Step: 13
Training loss: 4.187704280596187
Validation loss: 3.5758569384651757

Epoch: 13| Step: 0
Training loss: 2.941484062715781
Validation loss: 3.5665621191792565

Epoch: 6| Step: 1
Training loss: 3.868322217520724
Validation loss: 3.553093260203217

Epoch: 6| Step: 2
Training loss: 4.069114113262007
Validation loss: 3.544494593392369

Epoch: 6| Step: 3
Training loss: 3.8348755153062672
Validation loss: 3.5252211557873214

Epoch: 6| Step: 4
Training loss: 3.233817379562481
Validation loss: 3.5107867018887045

Epoch: 6| Step: 5
Training loss: 3.094133757863071
Validation loss: 3.5027050751099984

Epoch: 6| Step: 6
Training loss: 3.7043149943453164
Validation loss: 3.487307076688774

Epoch: 6| Step: 7
Training loss: 4.395587546662117
Validation loss: 3.4796646824764346

Epoch: 6| Step: 8
Training loss: 3.8548228487112466
Validation loss: 3.457912895174948

Epoch: 6| Step: 9
Training loss: 3.1276124334212843
Validation loss: 3.445849605606745

Epoch: 6| Step: 10
Training loss: 3.528620728500793
Validation loss: 3.43031547807568

Epoch: 6| Step: 11
Training loss: 3.6192319295434303
Validation loss: 3.419509781252237

Epoch: 6| Step: 12
Training loss: 4.154570275955919
Validation loss: 3.4028044373036677

Epoch: 6| Step: 13
Training loss: 3.173017023761621
Validation loss: 3.386296174534755

Epoch: 14| Step: 0
Training loss: 3.096062922703266
Validation loss: 3.3679458764942667

Epoch: 6| Step: 1
Training loss: 3.0453775491906185
Validation loss: 3.3533274470045846

Epoch: 6| Step: 2
Training loss: 3.532472651997376
Validation loss: 3.3342132704127643

Epoch: 6| Step: 3
Training loss: 4.0451203891111005
Validation loss: 3.3221969177318242

Epoch: 6| Step: 4
Training loss: 3.374560857389389
Validation loss: 3.308222843644782

Epoch: 6| Step: 5
Training loss: 2.8622960247011524
Validation loss: 3.292964438555765

Epoch: 6| Step: 6
Training loss: 3.915940007647417
Validation loss: 3.279248430207593

Epoch: 6| Step: 7
Training loss: 3.4031722136445954
Validation loss: 3.260523258906824

Epoch: 6| Step: 8
Training loss: 3.8370890394213886
Validation loss: 3.252777279174229

Epoch: 6| Step: 9
Training loss: 3.522627033138707
Validation loss: 3.2276674953959827

Epoch: 6| Step: 10
Training loss: 3.4586686733929244
Validation loss: 3.215690693711966

Epoch: 6| Step: 11
Training loss: 3.902614763565301
Validation loss: 3.1948817998049055

Epoch: 6| Step: 12
Training loss: 3.3135603161386644
Validation loss: 3.1885769074657055

Epoch: 6| Step: 13
Training loss: 2.777298423944487
Validation loss: 3.1663562772850233

Epoch: 15| Step: 0
Training loss: 3.2738086426308506
Validation loss: 3.154545708355673

Epoch: 6| Step: 1
Training loss: 3.5190017420424855
Validation loss: 3.1452583961651976

Epoch: 6| Step: 2
Training loss: 4.06917598621479
Validation loss: 3.138593132040591

Epoch: 6| Step: 3
Training loss: 2.4776898534805123
Validation loss: 3.1137688902923375

Epoch: 6| Step: 4
Training loss: 2.5635615685310573
Validation loss: 3.104665592387006

Epoch: 6| Step: 5
Training loss: 3.49458711862198
Validation loss: 3.0821758404631074

Epoch: 6| Step: 6
Training loss: 3.6440172885857334
Validation loss: 3.070524770560944

Epoch: 6| Step: 7
Training loss: 3.425926562090596
Validation loss: 3.062010944720935

Epoch: 6| Step: 8
Training loss: 3.2450009559665207
Validation loss: 3.048757481768085

Epoch: 6| Step: 9
Training loss: 3.938051215447595
Validation loss: 3.0323894571974384

Epoch: 6| Step: 10
Training loss: 2.076349173697257
Validation loss: 3.0114154495101455

Epoch: 6| Step: 11
Training loss: 3.12960872312941
Validation loss: 2.9955700071629976

Epoch: 6| Step: 12
Training loss: 3.562346471857992
Validation loss: 2.991860631593447

Epoch: 6| Step: 13
Training loss: 2.8923178175094986
Validation loss: 2.9751356272340077

Epoch: 16| Step: 0
Training loss: 2.652997078299756
Validation loss: 2.9550970441938915

Epoch: 6| Step: 1
Training loss: 3.861158939373325
Validation loss: 2.9502737510603083

Epoch: 6| Step: 2
Training loss: 3.868188840136182
Validation loss: 2.928894911443971

Epoch: 6| Step: 3
Training loss: 3.1146881868367986
Validation loss: 2.919812607141434

Epoch: 6| Step: 4
Training loss: 2.6513666479626523
Validation loss: 2.902387219524172

Epoch: 6| Step: 5
Training loss: 3.488927492979688
Validation loss: 2.895576951428331

Epoch: 6| Step: 6
Training loss: 3.2729400038215983
Validation loss: 2.8766913314417097

Epoch: 6| Step: 7
Training loss: 3.6365806807420604
Validation loss: 2.862365960468854

Epoch: 6| Step: 8
Training loss: 2.466670065525222
Validation loss: 2.8514956653161097

Epoch: 6| Step: 9
Training loss: 3.380983629152638
Validation loss: 2.8451245130194707

Epoch: 6| Step: 10
Training loss: 3.211007890138582
Validation loss: 2.8310252988677713

Epoch: 6| Step: 11
Training loss: 2.733598522564782
Validation loss: 2.8233148436061897

Epoch: 6| Step: 12
Training loss: 2.1437535500010467
Validation loss: 2.8110724906609033

Epoch: 6| Step: 13
Training loss: 2.83343260722055
Validation loss: 2.8009511100615936

Epoch: 17| Step: 0
Training loss: 2.993813015905727
Validation loss: 2.7958385522191964

Epoch: 6| Step: 1
Training loss: 3.929761396740894
Validation loss: 2.781232675496337

Epoch: 6| Step: 2
Training loss: 2.5335353377599104
Validation loss: 2.7651673829343344

Epoch: 6| Step: 3
Training loss: 2.9666718286476517
Validation loss: 2.750144842813695

Epoch: 6| Step: 4
Training loss: 2.879383725616171
Validation loss: 2.7372862560050346

Epoch: 6| Step: 5
Training loss: 3.5861775103928366
Validation loss: 2.7358391273690588

Epoch: 6| Step: 6
Training loss: 2.9000139499197246
Validation loss: 2.7150393859578448

Epoch: 6| Step: 7
Training loss: 2.8511042814634644
Validation loss: 2.709545219009645

Epoch: 6| Step: 8
Training loss: 3.1335786182358722
Validation loss: 2.715151934786577

Epoch: 6| Step: 9
Training loss: 3.145271015225287
Validation loss: 2.69574949417514

Epoch: 6| Step: 10
Training loss: 2.9583437386629745
Validation loss: 2.7002785703424657

Epoch: 6| Step: 11
Training loss: 2.497933105550404
Validation loss: 2.6730367901235765

Epoch: 6| Step: 12
Training loss: 2.991261311504499
Validation loss: 2.6776789711271904

Epoch: 6| Step: 13
Training loss: 2.665543756890414
Validation loss: 2.672247383301044

Epoch: 18| Step: 0
Training loss: 2.8698152978458387
Validation loss: 2.6562012920703313

Epoch: 6| Step: 1
Training loss: 3.2003834971466456
Validation loss: 2.6492118616926295

Epoch: 6| Step: 2
Training loss: 2.9053963668845695
Validation loss: 2.6553483295231266

Epoch: 6| Step: 3
Training loss: 3.3227188545749478
Validation loss: 2.649874435169576

Epoch: 6| Step: 4
Training loss: 2.5623321478228775
Validation loss: 2.6426113332636914

Epoch: 6| Step: 5
Training loss: 2.975216218159582
Validation loss: 2.6300143347101965

Epoch: 6| Step: 6
Training loss: 3.657043240565621
Validation loss: 2.6245360543109375

Epoch: 6| Step: 7
Training loss: 2.776071248901853
Validation loss: 2.621624504452146

Epoch: 6| Step: 8
Training loss: 2.8816080859708895
Validation loss: 2.6134955543964233

Epoch: 6| Step: 9
Training loss: 2.923061843786843
Validation loss: 2.6106857250971665

Epoch: 6| Step: 10
Training loss: 2.978385947484451
Validation loss: 2.6058449601865887

Epoch: 6| Step: 11
Training loss: 2.7162190199172374
Validation loss: 2.6012614396648184

Epoch: 6| Step: 12
Training loss: 2.65433891212573
Validation loss: 2.5999835104533804

Epoch: 6| Step: 13
Training loss: 2.6149374328188757
Validation loss: 2.5962267862824797

Epoch: 19| Step: 0
Training loss: 2.295833117790235
Validation loss: 2.5844298036103406

Epoch: 6| Step: 1
Training loss: 3.539460755565111
Validation loss: 2.5766501684538463

Epoch: 6| Step: 2
Training loss: 2.9575325504423904
Validation loss: 2.5854420224578933

Epoch: 6| Step: 3
Training loss: 2.832478749666018
Validation loss: 2.589393835125454

Epoch: 6| Step: 4
Training loss: 2.873665375461192
Validation loss: 2.566318427237517

Epoch: 6| Step: 5
Training loss: 3.0971078856328242
Validation loss: 2.578511705976321

Epoch: 6| Step: 6
Training loss: 3.026882210281231
Validation loss: 2.557618237967931

Epoch: 6| Step: 7
Training loss: 2.6032015016449463
Validation loss: 2.5627018568648317

Epoch: 6| Step: 8
Training loss: 3.3596624207077297
Validation loss: 2.5578723874074845

Epoch: 6| Step: 9
Training loss: 3.0187158112732235
Validation loss: 2.556164237964934

Epoch: 6| Step: 10
Training loss: 2.66507833583993
Validation loss: 2.5660729409011034

Epoch: 6| Step: 11
Training loss: 2.899988299379093
Validation loss: 2.5544702862108744

Epoch: 6| Step: 12
Training loss: 2.355546181388212
Validation loss: 2.560063650310282

Epoch: 6| Step: 13
Training loss: 3.0811320686598176
Validation loss: 2.55068119717622

Epoch: 20| Step: 0
Training loss: 2.4811351451667325
Validation loss: 2.552716572201377

Epoch: 6| Step: 1
Training loss: 2.636509504139418
Validation loss: 2.5536720385383163

Epoch: 6| Step: 2
Training loss: 2.4029785310037806
Validation loss: 2.549773068658378

Epoch: 6| Step: 3
Training loss: 2.8854062370543305
Validation loss: 2.5442500525716523

Epoch: 6| Step: 4
Training loss: 2.4088225051586183
Validation loss: 2.540853608024886

Epoch: 6| Step: 5
Training loss: 3.3061254813213288
Validation loss: 2.538981529945211

Epoch: 6| Step: 6
Training loss: 3.0329932479808397
Validation loss: 2.549010522388935

Epoch: 6| Step: 7
Training loss: 3.513298383776599
Validation loss: 2.5394766470586863

Epoch: 6| Step: 8
Training loss: 3.0581687349380413
Validation loss: 2.5472331547336355

Epoch: 6| Step: 9
Training loss: 2.6213977256554903
Validation loss: 2.539659468753835

Epoch: 6| Step: 10
Training loss: 2.6856819035656274
Validation loss: 2.5390657794385354

Epoch: 6| Step: 11
Training loss: 3.215654384526972
Validation loss: 2.530968219321215

Epoch: 6| Step: 12
Training loss: 3.3332977928810066
Validation loss: 2.559665356640895

Epoch: 6| Step: 13
Training loss: 2.2934863986270457
Validation loss: 2.544287696018644

Epoch: 21| Step: 0
Training loss: 3.509637914169241
Validation loss: 2.5423429172160943

Epoch: 6| Step: 1
Training loss: 2.925188113953385
Validation loss: 2.5330671995856764

Epoch: 6| Step: 2
Training loss: 2.6938851377926487
Validation loss: 2.5507135796681655

Epoch: 6| Step: 3
Training loss: 2.769794144951519
Validation loss: 2.533896299183747

Epoch: 6| Step: 4
Training loss: 2.6745761357266202
Validation loss: 2.5315553984034245

Epoch: 6| Step: 5
Training loss: 2.9167917678888426
Validation loss: 2.531328331492251

Epoch: 6| Step: 6
Training loss: 2.8998194276562628
Validation loss: 2.5370304883842736

Epoch: 6| Step: 7
Training loss: 2.466855734804756
Validation loss: 2.5322519879294014

Epoch: 6| Step: 8
Training loss: 2.8088339754597063
Validation loss: 2.5305356701914485

Epoch: 6| Step: 9
Training loss: 2.818978710157768
Validation loss: 2.5358923490536154

Epoch: 6| Step: 10
Training loss: 2.966379283172626
Validation loss: 2.533106347152378

Epoch: 6| Step: 11
Training loss: 2.918964262129022
Validation loss: 2.521137564625164

Epoch: 6| Step: 12
Training loss: 2.3089710837329984
Validation loss: 2.5405181836479134

Epoch: 6| Step: 13
Training loss: 3.839943963079071
Validation loss: 2.5381943781568563

Epoch: 22| Step: 0
Training loss: 2.3756718939990455
Validation loss: 2.537533652765766

Epoch: 6| Step: 1
Training loss: 2.830720669272454
Validation loss: 2.5344077714581794

Epoch: 6| Step: 2
Training loss: 3.1146600175856247
Validation loss: 2.5315373281819333

Epoch: 6| Step: 3
Training loss: 2.3923450340859027
Validation loss: 2.526844153870081

Epoch: 6| Step: 4
Training loss: 2.60418550611675
Validation loss: 2.5186114959429444

Epoch: 6| Step: 5
Training loss: 2.8441084751092873
Validation loss: 2.53511096443611

Epoch: 6| Step: 6
Training loss: 2.7760181724217374
Validation loss: 2.5159953558172203

Epoch: 6| Step: 7
Training loss: 3.3241275187613257
Validation loss: 2.524877349447857

Epoch: 6| Step: 8
Training loss: 3.01401014030386
Validation loss: 2.51177410859001

Epoch: 6| Step: 9
Training loss: 2.800779717736244
Validation loss: 2.524566315622181

Epoch: 6| Step: 10
Training loss: 3.6495385805874543
Validation loss: 2.5184583799603697

Epoch: 6| Step: 11
Training loss: 2.6017111429359057
Validation loss: 2.525211095093145

Epoch: 6| Step: 12
Training loss: 2.859408685871419
Validation loss: 2.5184734556131882

Epoch: 6| Step: 13
Training loss: 2.869344040610793
Validation loss: 2.5261243726517315

Epoch: 23| Step: 0
Training loss: 2.647050432428761
Validation loss: 2.5267350221564695

Epoch: 6| Step: 1
Training loss: 2.558893596755082
Validation loss: 2.5176575427169205

Epoch: 6| Step: 2
Training loss: 2.593063263580012
Validation loss: 2.5188897298926687

Epoch: 6| Step: 3
Training loss: 3.135336299301368
Validation loss: 2.5297664770035215

Epoch: 6| Step: 4
Training loss: 3.250300320174381
Validation loss: 2.5215298117549874

Epoch: 6| Step: 5
Training loss: 2.166718873593217
Validation loss: 2.513638430912166

Epoch: 6| Step: 6
Training loss: 2.579597191526659
Validation loss: 2.5159890974986863

Epoch: 6| Step: 7
Training loss: 3.549848075087323
Validation loss: 2.5248320003500093

Epoch: 6| Step: 8
Training loss: 3.0363109066454252
Validation loss: 2.520922678990691

Epoch: 6| Step: 9
Training loss: 2.61368328474545
Validation loss: 2.532818581058361

Epoch: 6| Step: 10
Training loss: 3.2020431552435378
Validation loss: 2.52956325471114

Epoch: 6| Step: 11
Training loss: 2.878130162469498
Validation loss: 2.5192379935266036

Epoch: 6| Step: 12
Training loss: 3.0420450123322738
Validation loss: 2.5210211621239935

Epoch: 6| Step: 13
Training loss: 2.2462504191284127
Validation loss: 2.518141588677017

Epoch: 24| Step: 0
Training loss: 3.324241127091253
Validation loss: 2.517825325688809

Epoch: 6| Step: 1
Training loss: 3.043609904172888
Validation loss: 2.534068226687151

Epoch: 6| Step: 2
Training loss: 3.089815971548647
Validation loss: 2.5231289954544285

Epoch: 6| Step: 3
Training loss: 2.6634540478305206
Validation loss: 2.518318857178655

Epoch: 6| Step: 4
Training loss: 3.0607450478278544
Validation loss: 2.5327620067544383

Epoch: 6| Step: 5
Training loss: 3.040783549269145
Validation loss: 2.5333585192502963

Epoch: 6| Step: 6
Training loss: 1.9887027556000483
Validation loss: 2.5317336248001645

Epoch: 6| Step: 7
Training loss: 3.2042049913301183
Validation loss: 2.526714634580287

Epoch: 6| Step: 8
Training loss: 2.7596501179771185
Validation loss: 2.517087150341457

Epoch: 6| Step: 9
Training loss: 2.414744654201582
Validation loss: 2.5194425777937868

Epoch: 6| Step: 10
Training loss: 2.2899282855669414
Validation loss: 2.527366850967174

Epoch: 6| Step: 11
Training loss: 3.0609781025972853
Validation loss: 2.5120328411040793

Epoch: 6| Step: 12
Training loss: 2.262162081104925
Validation loss: 2.5173874051242877

Epoch: 6| Step: 13
Training loss: 3.8930270581641406
Validation loss: 2.5151236754381943

Epoch: 25| Step: 0
Training loss: 2.9795664450145005
Validation loss: 2.5266862333390065

Epoch: 6| Step: 1
Training loss: 2.6011227531051264
Validation loss: 2.52591196041578

Epoch: 6| Step: 2
Training loss: 3.0201249618445014
Validation loss: 2.526122459656283

Epoch: 6| Step: 3
Training loss: 2.9167714962966995
Validation loss: 2.516171723546051

Epoch: 6| Step: 4
Training loss: 2.670601703123488
Validation loss: 2.5299070293107246

Epoch: 6| Step: 5
Training loss: 3.2492127565446496
Validation loss: 2.5277930398262662

Epoch: 6| Step: 6
Training loss: 2.8101746164824117
Validation loss: 2.5309952121907684

Epoch: 6| Step: 7
Training loss: 3.3992486796796304
Validation loss: 2.516653883989231

Epoch: 6| Step: 8
Training loss: 3.105276963171783
Validation loss: 2.529873034768942

Epoch: 6| Step: 9
Training loss: 2.7078301377995966
Validation loss: 2.5214537075235315

Epoch: 6| Step: 10
Training loss: 2.8939674641771322
Validation loss: 2.526425542271276

Epoch: 6| Step: 11
Training loss: 2.3273423690766193
Validation loss: 2.521011362185304

Epoch: 6| Step: 12
Training loss: 2.339002964482706
Validation loss: 2.5292209598806132

Epoch: 6| Step: 13
Training loss: 2.788734993819451
Validation loss: 2.529030452026131

Epoch: 26| Step: 0
Training loss: 3.2793881901744215
Validation loss: 2.520289541840951

Epoch: 6| Step: 1
Training loss: 2.6814258153221715
Validation loss: 2.5214645021354984

Epoch: 6| Step: 2
Training loss: 3.1763729280946404
Validation loss: 2.528206535422002

Epoch: 6| Step: 3
Training loss: 3.150597978781388
Validation loss: 2.51222600229048

Epoch: 6| Step: 4
Training loss: 3.1511423310313167
Validation loss: 2.51795789034967

Epoch: 6| Step: 5
Training loss: 2.0212501279586723
Validation loss: 2.5239370807726016

Epoch: 6| Step: 6
Training loss: 2.7042108019815974
Validation loss: 2.5158666770927653

Epoch: 6| Step: 7
Training loss: 3.065659119769034
Validation loss: 2.5256463832038176

Epoch: 6| Step: 8
Training loss: 3.096764531171758
Validation loss: 2.518482849093836

Epoch: 6| Step: 9
Training loss: 2.9400245694022633
Validation loss: 2.5193439423875335

Epoch: 6| Step: 10
Training loss: 2.4809362256341982
Validation loss: 2.5205720087879886

Epoch: 6| Step: 11
Training loss: 2.550527936850101
Validation loss: 2.5188051073246545

Epoch: 6| Step: 12
Training loss: 2.6264633459543276
Validation loss: 2.517844695782259

Epoch: 6| Step: 13
Training loss: 2.5980722653541024
Validation loss: 2.5220579964005876

Epoch: 27| Step: 0
Training loss: 2.779396897082392
Validation loss: 2.5115122442845506

Epoch: 6| Step: 1
Training loss: 1.7243769695385494
Validation loss: 2.513341773633618

Epoch: 6| Step: 2
Training loss: 2.7369225541831534
Validation loss: 2.513869709422239

Epoch: 6| Step: 3
Training loss: 3.370195430443149
Validation loss: 2.517603252355533

Epoch: 6| Step: 4
Training loss: 2.505286444849341
Validation loss: 2.525531846157112

Epoch: 6| Step: 5
Training loss: 2.8247314663079903
Validation loss: 2.5310540082257846

Epoch: 6| Step: 6
Training loss: 2.053353344254189
Validation loss: 2.5294224745146603

Epoch: 6| Step: 7
Training loss: 2.641921046992601
Validation loss: 2.5177799249210335

Epoch: 6| Step: 8
Training loss: 3.130567550147282
Validation loss: 2.5069417268797425

Epoch: 6| Step: 9
Training loss: 2.1230198104803777
Validation loss: 2.521518880167451

Epoch: 6| Step: 10
Training loss: 3.636747333483939
Validation loss: 2.5172430521422196

Epoch: 6| Step: 11
Training loss: 2.7258386388867195
Validation loss: 2.528804538143494

Epoch: 6| Step: 12
Training loss: 3.417436900585353
Validation loss: 2.5149063534022007

Epoch: 6| Step: 13
Training loss: 3.813191710712175
Validation loss: 2.5090177267960896

Epoch: 28| Step: 0
Training loss: 2.8026552621129683
Validation loss: 2.5192764615092473

Epoch: 6| Step: 1
Training loss: 3.1798646019954884
Validation loss: 2.5163101621669233

Epoch: 6| Step: 2
Training loss: 2.37392511638877
Validation loss: 2.524994777315437

Epoch: 6| Step: 3
Training loss: 2.612451076505784
Validation loss: 2.5218765397240017

Epoch: 6| Step: 4
Training loss: 2.589304227715815
Validation loss: 2.5301178922742844

Epoch: 6| Step: 5
Training loss: 3.048649197984748
Validation loss: 2.5099601076844795

Epoch: 6| Step: 6
Training loss: 2.647899111597758
Validation loss: 2.5155521128255756

Epoch: 6| Step: 7
Training loss: 3.171777582786657
Validation loss: 2.5144623689022563

Epoch: 6| Step: 8
Training loss: 2.867314723048082
Validation loss: 2.527626556470216

Epoch: 6| Step: 9
Training loss: 2.84650061749174
Validation loss: 2.526983294205144

Epoch: 6| Step: 10
Training loss: 3.595878700391559
Validation loss: 2.5333241535874818

Epoch: 6| Step: 11
Training loss: 2.4405038371275762
Validation loss: 2.515375943199742

Epoch: 6| Step: 12
Training loss: 2.3396914118880185
Validation loss: 2.5067818852499326

Epoch: 6| Step: 13
Training loss: 3.095034554185391
Validation loss: 2.518079513730159

Epoch: 29| Step: 0
Training loss: 2.3434061433958204
Validation loss: 2.514990350799392

Epoch: 6| Step: 1
Training loss: 3.4959584471024807
Validation loss: 2.518867543511237

Epoch: 6| Step: 2
Training loss: 2.621753319700454
Validation loss: 2.519059000084562

Epoch: 6| Step: 3
Training loss: 2.789998044522602
Validation loss: 2.519990457893376

Epoch: 6| Step: 4
Training loss: 2.8758611633257085
Validation loss: 2.5180902077626177

Epoch: 6| Step: 5
Training loss: 2.4593826468323385
Validation loss: 2.5231280088637513

Epoch: 6| Step: 6
Training loss: 2.939459938218848
Validation loss: 2.530544780823243

Epoch: 6| Step: 7
Training loss: 3.430974558074113
Validation loss: 2.518946835084773

Epoch: 6| Step: 8
Training loss: 2.67193924676047
Validation loss: 2.5223827686844564

Epoch: 6| Step: 9
Training loss: 2.8313315743995604
Validation loss: 2.5132810964231784

Epoch: 6| Step: 10
Training loss: 2.8274325371341185
Validation loss: 2.512533607966261

Epoch: 6| Step: 11
Training loss: 2.2665744239138994
Validation loss: 2.5159584690102754

Epoch: 6| Step: 12
Training loss: 3.38634561949354
Validation loss: 2.5082259452147326

Epoch: 6| Step: 13
Training loss: 2.0608712903681945
Validation loss: 2.5154564557141192

Epoch: 30| Step: 0
Training loss: 2.895267861316036
Validation loss: 2.521553838306876

Epoch: 6| Step: 1
Training loss: 3.0872526432674436
Validation loss: 2.520809024648499

Epoch: 6| Step: 2
Training loss: 2.6793495610183817
Validation loss: 2.509034814829996

Epoch: 6| Step: 3
Training loss: 3.4755801752551276
Validation loss: 2.5145492347769047

Epoch: 6| Step: 4
Training loss: 3.005346302763815
Validation loss: 2.516082053630725

Epoch: 6| Step: 5
Training loss: 2.358041752918786
Validation loss: 2.5252705932939086

Epoch: 6| Step: 6
Training loss: 2.549274367515745
Validation loss: 2.5084010962298335

Epoch: 6| Step: 7
Training loss: 2.8520646162698378
Validation loss: 2.517158659895454

Epoch: 6| Step: 8
Training loss: 2.7098660949056756
Validation loss: 2.5287466691358422

Epoch: 6| Step: 9
Training loss: 2.8390924228567234
Validation loss: 2.5197464455714473

Epoch: 6| Step: 10
Training loss: 2.9742050647546
Validation loss: 2.5136784521897253

Epoch: 6| Step: 11
Training loss: 2.8126382581848364
Validation loss: 2.5191534101341557

Epoch: 6| Step: 12
Training loss: 2.6722550149792568
Validation loss: 2.516725800068123

Epoch: 6| Step: 13
Training loss: 2.5219486911222195
Validation loss: 2.5210192605097315

Epoch: 31| Step: 0
Training loss: 2.62292889225307
Validation loss: 2.516758603157503

Epoch: 6| Step: 1
Training loss: 3.035167561513671
Validation loss: 2.5065155135785964

Epoch: 6| Step: 2
Training loss: 2.8482846167252203
Validation loss: 2.5135678778480153

Epoch: 6| Step: 3
Training loss: 2.614615471833623
Validation loss: 2.522158692732727

Epoch: 6| Step: 4
Training loss: 2.555408807586207
Validation loss: 2.5187875410477374

Epoch: 6| Step: 5
Training loss: 2.3954322700392634
Validation loss: 2.515330999670975

Epoch: 6| Step: 6
Training loss: 3.3879944049919617
Validation loss: 2.516383883159439

Epoch: 6| Step: 7
Training loss: 2.728836117205544
Validation loss: 2.5059959117316337

Epoch: 6| Step: 8
Training loss: 2.9524952050411555
Validation loss: 2.50835623469221

Epoch: 6| Step: 9
Training loss: 3.4221977186220256
Validation loss: 2.5159224121203487

Epoch: 6| Step: 10
Training loss: 2.3597668455007397
Validation loss: 2.5037497936988764

Epoch: 6| Step: 11
Training loss: 2.738924263894869
Validation loss: 2.49164218203948

Epoch: 6| Step: 12
Training loss: 2.8075550264857867
Validation loss: 2.50894868582616

Epoch: 6| Step: 13
Training loss: 3.1481242816826533
Validation loss: 2.508765545217101

Epoch: 32| Step: 0
Training loss: 2.472804349830181
Validation loss: 2.513618650021981

Epoch: 6| Step: 1
Training loss: 2.990722616390306
Validation loss: 2.507290980886419

Epoch: 6| Step: 2
Training loss: 2.836433472362722
Validation loss: 2.5149475869111404

Epoch: 6| Step: 3
Training loss: 2.710268669183052
Validation loss: 2.512208768605488

Epoch: 6| Step: 4
Training loss: 3.5339790533942192
Validation loss: 2.513734815011793

Epoch: 6| Step: 5
Training loss: 2.483806041129454
Validation loss: 2.524487956089741

Epoch: 6| Step: 6
Training loss: 3.247237718898872
Validation loss: 2.5080016235478717

Epoch: 6| Step: 7
Training loss: 2.6695990433540038
Validation loss: 2.5144844075749404

Epoch: 6| Step: 8
Training loss: 2.277700196730848
Validation loss: 2.5264195046185716

Epoch: 6| Step: 9
Training loss: 2.4510156589289553
Validation loss: 2.521741451450939

Epoch: 6| Step: 10
Training loss: 2.967944869236316
Validation loss: 2.5074959908754773

Epoch: 6| Step: 11
Training loss: 2.6622721901444457
Validation loss: 2.526874354670735

Epoch: 6| Step: 12
Training loss: 2.9878977810024288
Validation loss: 2.522492377324359

Epoch: 6| Step: 13
Training loss: 3.2270092227734253
Validation loss: 2.512126914130788

Epoch: 33| Step: 0
Training loss: 2.713686645696045
Validation loss: 2.5115794509665395

Epoch: 6| Step: 1
Training loss: 3.161630406899893
Validation loss: 2.519155906451902

Epoch: 6| Step: 2
Training loss: 2.691057379137438
Validation loss: 2.5221528044483854

Epoch: 6| Step: 3
Training loss: 3.152415448475984
Validation loss: 2.5199968141104954

Epoch: 6| Step: 4
Training loss: 2.7248234052919567
Validation loss: 2.5093283748829887

Epoch: 6| Step: 5
Training loss: 3.0050651388360055
Validation loss: 2.514273096098911

Epoch: 6| Step: 6
Training loss: 2.839288586446264
Validation loss: 2.516481167601894

Epoch: 6| Step: 7
Training loss: 2.773790363913732
Validation loss: 2.511311822118821

Epoch: 6| Step: 8
Training loss: 3.367593479685662
Validation loss: 2.521922641347911

Epoch: 6| Step: 9
Training loss: 2.967990657668307
Validation loss: 2.517265407132473

Epoch: 6| Step: 10
Training loss: 2.477288076688859
Validation loss: 2.5195387266302025

Epoch: 6| Step: 11
Training loss: 2.4516505773220807
Validation loss: 2.51358064722636

Epoch: 6| Step: 12
Training loss: 2.3159930679270255
Validation loss: 2.5139710345622

Epoch: 6| Step: 13
Training loss: 2.5684891468522033
Validation loss: 2.493664799259537

Epoch: 34| Step: 0
Training loss: 2.2406104519636454
Validation loss: 2.515735614362241

Epoch: 6| Step: 1
Training loss: 2.8448579746723963
Validation loss: 2.5098770859329376

Epoch: 6| Step: 2
Training loss: 3.215248351286292
Validation loss: 2.502985189266281

Epoch: 6| Step: 3
Training loss: 2.8573320939201814
Validation loss: 2.5262844512406106

Epoch: 6| Step: 4
Training loss: 2.384835207062272
Validation loss: 2.5195002891073557

Epoch: 6| Step: 5
Training loss: 2.7472756502643043
Validation loss: 2.5187793812724766

Epoch: 6| Step: 6
Training loss: 2.7410142785208054
Validation loss: 2.508045511681838

Epoch: 6| Step: 7
Training loss: 2.5950007353030067
Validation loss: 2.5136858473006187

Epoch: 6| Step: 8
Training loss: 2.983414899964809
Validation loss: 2.516171638980211

Epoch: 6| Step: 9
Training loss: 2.6215392414934287
Validation loss: 2.507976626921104

Epoch: 6| Step: 10
Training loss: 3.4263223810076235
Validation loss: 2.5047571502823858

Epoch: 6| Step: 11
Training loss: 3.0116323020788585
Validation loss: 2.5053399276802257

Epoch: 6| Step: 12
Training loss: 2.5574539557793403
Validation loss: 2.5022174845110006

Epoch: 6| Step: 13
Training loss: 3.053226990104173
Validation loss: 2.510286649403182

Epoch: 35| Step: 0
Training loss: 2.9956057473130473
Validation loss: 2.508377916668022

Epoch: 6| Step: 1
Training loss: 2.6514922672786962
Validation loss: 2.506461919798275

Epoch: 6| Step: 2
Training loss: 3.479743102665321
Validation loss: 2.5211450588625537

Epoch: 6| Step: 3
Training loss: 1.8793524135073454
Validation loss: 2.5071225052001753

Epoch: 6| Step: 4
Training loss: 2.9206127357347857
Validation loss: 2.500781688717121

Epoch: 6| Step: 5
Training loss: 2.877378392172841
Validation loss: 2.5106633240088803

Epoch: 6| Step: 6
Training loss: 3.0700680390314194
Validation loss: 2.5158644434677413

Epoch: 6| Step: 7
Training loss: 2.315174000176343
Validation loss: 2.511252529150139

Epoch: 6| Step: 8
Training loss: 2.6300284044015543
Validation loss: 2.4920936196726027

Epoch: 6| Step: 9
Training loss: 3.1829736023676256
Validation loss: 2.5020815069720244

Epoch: 6| Step: 10
Training loss: 2.4378875033152783
Validation loss: 2.5122088196291257

Epoch: 6| Step: 11
Training loss: 2.8236573058268797
Validation loss: 2.5225058180218944

Epoch: 6| Step: 12
Training loss: 2.4875026185295086
Validation loss: 2.5086103250075253

Epoch: 6| Step: 13
Training loss: 3.41611152108644
Validation loss: 2.508352255886978

Epoch: 36| Step: 0
Training loss: 2.427053121179539
Validation loss: 2.517277703540053

Epoch: 6| Step: 1
Training loss: 2.8714883338549093
Validation loss: 2.5187988844858324

Epoch: 6| Step: 2
Training loss: 2.6774171158528817
Validation loss: 2.502469818858339

Epoch: 6| Step: 3
Training loss: 2.960217551922817
Validation loss: 2.5042303052022525

Epoch: 6| Step: 4
Training loss: 2.2586989197182796
Validation loss: 2.5003017838154795

Epoch: 6| Step: 5
Training loss: 2.371736894891608
Validation loss: 2.5086336332285732

Epoch: 6| Step: 6
Training loss: 3.3011022287536957
Validation loss: 2.512933947611414

Epoch: 6| Step: 7
Training loss: 2.5556735780893733
Validation loss: 2.5083710394102647

Epoch: 6| Step: 8
Training loss: 3.509194830246451
Validation loss: 2.5192676255871027

Epoch: 6| Step: 9
Training loss: 2.4200911320322853
Validation loss: 2.5040919962720327

Epoch: 6| Step: 10
Training loss: 2.268225184078348
Validation loss: 2.509588401515693

Epoch: 6| Step: 11
Training loss: 3.2181520369552126
Validation loss: 2.5046679765264863

Epoch: 6| Step: 12
Training loss: 3.2191258183303
Validation loss: 2.5091514106827497

Epoch: 6| Step: 13
Training loss: 2.8837940230231633
Validation loss: 2.5175960001108093

Epoch: 37| Step: 0
Training loss: 2.3291124131691694
Validation loss: 2.5113404942107733

Epoch: 6| Step: 1
Training loss: 2.0565690972767676
Validation loss: 2.5132141790408857

Epoch: 6| Step: 2
Training loss: 3.3889088308723863
Validation loss: 2.5146256356460466

Epoch: 6| Step: 3
Training loss: 2.678479781626562
Validation loss: 2.5042111517650474

Epoch: 6| Step: 4
Training loss: 3.3381371850678945
Validation loss: 2.5101970082416982

Epoch: 6| Step: 5
Training loss: 3.00523364994662
Validation loss: 2.5153858680315846

Epoch: 6| Step: 6
Training loss: 2.626770875415972
Validation loss: 2.4973296208731695

Epoch: 6| Step: 7
Training loss: 3.356085013484732
Validation loss: 2.5024303354438104

Epoch: 6| Step: 8
Training loss: 2.020094890631869
Validation loss: 2.5104205220388214

Epoch: 6| Step: 9
Training loss: 2.7032703514931167
Validation loss: 2.5135072907513183

Epoch: 6| Step: 10
Training loss: 3.0477763089976766
Validation loss: 2.4979245615486683

Epoch: 6| Step: 11
Training loss: 2.6543920863396315
Validation loss: 2.5147413860999293

Epoch: 6| Step: 12
Training loss: 2.667223713231753
Validation loss: 2.5075954506507063

Epoch: 6| Step: 13
Training loss: 2.777552858359575
Validation loss: 2.511714812244897

Epoch: 38| Step: 0
Training loss: 2.821868889718606
Validation loss: 2.4983567795407886

Epoch: 6| Step: 1
Training loss: 3.1292524777230644
Validation loss: 2.5123033166896676

Epoch: 6| Step: 2
Training loss: 2.09282846240512
Validation loss: 2.5007571632499084

Epoch: 6| Step: 3
Training loss: 2.8390673975883907
Validation loss: 2.5095701629048506

Epoch: 6| Step: 4
Training loss: 3.2171650660187954
Validation loss: 2.5192787216197927

Epoch: 6| Step: 5
Training loss: 2.632121281203593
Validation loss: 2.511046015721549

Epoch: 6| Step: 6
Training loss: 2.824678797733252
Validation loss: 2.5226536889151947

Epoch: 6| Step: 7
Training loss: 2.24484595095206
Validation loss: 2.4994242351232954

Epoch: 6| Step: 8
Training loss: 2.4528355518802867
Validation loss: 2.49472199135753

Epoch: 6| Step: 9
Training loss: 2.4835831441829814
Validation loss: 2.5195385455144907

Epoch: 6| Step: 10
Training loss: 2.9808770096369344
Validation loss: 2.4947903372982214

Epoch: 6| Step: 11
Training loss: 2.747990741169975
Validation loss: 2.509351820484882

Epoch: 6| Step: 12
Training loss: 2.765933089687532
Validation loss: 2.514048211678959

Epoch: 6| Step: 13
Training loss: 3.8599497255203885
Validation loss: 2.523373643808868

Epoch: 39| Step: 0
Training loss: 2.4518372867356923
Validation loss: 2.4976905307474366

Epoch: 6| Step: 1
Training loss: 3.1632880876184126
Validation loss: 2.500784299736435

Epoch: 6| Step: 2
Training loss: 3.05853341580219
Validation loss: 2.5165124794071927

Epoch: 6| Step: 3
Training loss: 2.700769004098828
Validation loss: 2.5126888745554337

Epoch: 6| Step: 4
Training loss: 2.3701683890804963
Validation loss: 2.5128080483366326

Epoch: 6| Step: 5
Training loss: 2.652872428958583
Validation loss: 2.500626989927082

Epoch: 6| Step: 6
Training loss: 2.7161393182273454
Validation loss: 2.513054742488166

Epoch: 6| Step: 7
Training loss: 2.0390587583777933
Validation loss: 2.51928250813994

Epoch: 6| Step: 8
Training loss: 3.010905788157632
Validation loss: 2.5153999052114866

Epoch: 6| Step: 9
Training loss: 2.7851954560376044
Validation loss: 2.5072169945756375

Epoch: 6| Step: 10
Training loss: 2.904259440957475
Validation loss: 2.5051486792957935

Epoch: 6| Step: 11
Training loss: 3.6094385447007116
Validation loss: 2.5094460175132483

Epoch: 6| Step: 12
Training loss: 2.746807412627731
Validation loss: 2.5101963280620594

Epoch: 6| Step: 13
Training loss: 2.399417341553773
Validation loss: 2.523203022184643

Epoch: 40| Step: 0
Training loss: 3.514729703709336
Validation loss: 2.513814810008484

Epoch: 6| Step: 1
Training loss: 1.9481760420123169
Validation loss: 2.5084007661167664

Epoch: 6| Step: 2
Training loss: 1.9225675994139728
Validation loss: 2.5128080962874138

Epoch: 6| Step: 3
Training loss: 2.976720930874303
Validation loss: 2.514623882119252

Epoch: 6| Step: 4
Training loss: 2.761861708419802
Validation loss: 2.5195034556260016

Epoch: 6| Step: 5
Training loss: 2.6780746544253193
Validation loss: 2.508650940525843

Epoch: 6| Step: 6
Training loss: 2.614782247284487
Validation loss: 2.5014790886919758

Epoch: 6| Step: 7
Training loss: 2.5789543898514533
Validation loss: 2.4883719856088837

Epoch: 6| Step: 8
Training loss: 2.8262650079678786
Validation loss: 2.502803473450537

Epoch: 6| Step: 9
Training loss: 3.1856739573152955
Validation loss: 2.516819043739299

Epoch: 6| Step: 10
Training loss: 3.0330301936778867
Validation loss: 2.494295545188052

Epoch: 6| Step: 11
Training loss: 2.912953838303469
Validation loss: 2.5089136429932433

Epoch: 6| Step: 12
Training loss: 2.75399819078573
Validation loss: 2.517603739096287

Epoch: 6| Step: 13
Training loss: 3.1375940985076043
Validation loss: 2.5026274953142424

Epoch: 41| Step: 0
Training loss: 2.727120241323882
Validation loss: 2.5023123127804094

Epoch: 6| Step: 1
Training loss: 2.4991221794128147
Validation loss: 2.5120522354518635

Epoch: 6| Step: 2
Training loss: 2.1074168971500526
Validation loss: 2.501835090071505

Epoch: 6| Step: 3
Training loss: 2.6869901129054803
Validation loss: 2.5227519840527366

Epoch: 6| Step: 4
Training loss: 2.5486406630056693
Validation loss: 2.4966368788429256

Epoch: 6| Step: 5
Training loss: 2.9925246882874275
Validation loss: 2.514393558999833

Epoch: 6| Step: 6
Training loss: 3.1190464528676842
Validation loss: 2.502798359077432

Epoch: 6| Step: 7
Training loss: 3.005981522148635
Validation loss: 2.4997600368473356

Epoch: 6| Step: 8
Training loss: 2.7732222352639013
Validation loss: 2.5093243598182973

Epoch: 6| Step: 9
Training loss: 2.7622972716085137
Validation loss: 2.5029566805958634

Epoch: 6| Step: 10
Training loss: 3.438795781830928
Validation loss: 2.5135407365840465

Epoch: 6| Step: 11
Training loss: 2.7196031306147073
Validation loss: 2.5066550255004194

Epoch: 6| Step: 12
Training loss: 2.601345477059059
Validation loss: 2.51073038391636

Epoch: 6| Step: 13
Training loss: 2.8943139533926208
Validation loss: 2.5057128472601318

Epoch: 42| Step: 0
Training loss: 2.7078672937307218
Validation loss: 2.5096786436069562

Epoch: 6| Step: 1
Training loss: 1.8242840969626042
Validation loss: 2.5011435754221485

Epoch: 6| Step: 2
Training loss: 3.5488982626702867
Validation loss: 2.501708799278488

Epoch: 6| Step: 3
Training loss: 2.817867667064391
Validation loss: 2.509579511052238

Epoch: 6| Step: 4
Training loss: 2.347926678053716
Validation loss: 2.501050277279455

Epoch: 6| Step: 5
Training loss: 2.0771198566660276
Validation loss: 2.5022026018899464

Epoch: 6| Step: 6
Training loss: 3.279756623984963
Validation loss: 2.514129346918146

Epoch: 6| Step: 7
Training loss: 2.6494668856176746
Validation loss: 2.5185087196659266

Epoch: 6| Step: 8
Training loss: 2.692624905521736
Validation loss: 2.500870736571113

Epoch: 6| Step: 9
Training loss: 3.805532623989196
Validation loss: 2.5146539029409367

Epoch: 6| Step: 10
Training loss: 2.9865345755669948
Validation loss: 2.5245630823393155

Epoch: 6| Step: 11
Training loss: 1.7331700993972936
Validation loss: 2.500128891401273

Epoch: 6| Step: 12
Training loss: 2.7978148346465863
Validation loss: 2.5173867207771994

Epoch: 6| Step: 13
Training loss: 2.996660917430054
Validation loss: 2.513653649699915

Epoch: 43| Step: 0
Training loss: 2.3744987159543993
Validation loss: 2.505139720885287

Epoch: 6| Step: 1
Training loss: 2.0651728332828094
Validation loss: 2.5059282320267307

Epoch: 6| Step: 2
Training loss: 2.7304858642391046
Validation loss: 2.4960445286415527

Epoch: 6| Step: 3
Training loss: 1.909900359505633
Validation loss: 2.5158085746842906

Epoch: 6| Step: 4
Training loss: 2.575778332454937
Validation loss: 2.5076026260051094

Epoch: 6| Step: 5
Training loss: 3.05429816142942
Validation loss: 2.502942440478397

Epoch: 6| Step: 6
Training loss: 2.1143897458113967
Validation loss: 2.5045096096454325

Epoch: 6| Step: 7
Training loss: 3.557492132761252
Validation loss: 2.511228284597015

Epoch: 6| Step: 8
Training loss: 2.9631904344750364
Validation loss: 2.508204399397933

Epoch: 6| Step: 9
Training loss: 2.8271254991513306
Validation loss: 2.5056042050896057

Epoch: 6| Step: 10
Training loss: 2.40351613288228
Validation loss: 2.488299661137676

Epoch: 6| Step: 11
Training loss: 3.5265798829427313
Validation loss: 2.5147245718269327

Epoch: 6| Step: 12
Training loss: 3.099088744082875
Validation loss: 2.5051719051101435

Epoch: 6| Step: 13
Training loss: 3.1896385050228826
Validation loss: 2.500067133668664

Epoch: 44| Step: 0
Training loss: 3.0531974729215903
Validation loss: 2.5000740286418552

Epoch: 6| Step: 1
Training loss: 3.2694062604450678
Validation loss: 2.519673570786824

Epoch: 6| Step: 2
Training loss: 2.877135934608975
Validation loss: 2.5013785775916504

Epoch: 6| Step: 3
Training loss: 2.7946954684787473
Validation loss: 2.501628539115724

Epoch: 6| Step: 4
Training loss: 3.2209568791219616
Validation loss: 2.5147964987338174

Epoch: 6| Step: 5
Training loss: 2.5034516348824876
Validation loss: 2.508312507347795

Epoch: 6| Step: 6
Training loss: 2.482134114296111
Validation loss: 2.506494288537127

Epoch: 6| Step: 7
Training loss: 1.968680244299941
Validation loss: 2.506928679789812

Epoch: 6| Step: 8
Training loss: 2.790191507363986
Validation loss: 2.5108932899110425

Epoch: 6| Step: 9
Training loss: 2.7044923003403243
Validation loss: 2.501170892212014

Epoch: 6| Step: 10
Training loss: 2.102289123846123
Validation loss: 2.508897186640528

Epoch: 6| Step: 11
Training loss: 3.0104825937692605
Validation loss: 2.4987855094229166

Epoch: 6| Step: 12
Training loss: 3.088252104919156
Validation loss: 2.506937127656629

Epoch: 6| Step: 13
Training loss: 2.240385600858354
Validation loss: 2.495841419160924

Epoch: 45| Step: 0
Training loss: 2.8307208377232476
Validation loss: 2.5015747238083628

Epoch: 6| Step: 1
Training loss: 2.7237758441625046
Validation loss: 2.4950766229303123

Epoch: 6| Step: 2
Training loss: 2.776434941493224
Validation loss: 2.506933100581191

Epoch: 6| Step: 3
Training loss: 2.4077512343408167
Validation loss: 2.514788491155764

Epoch: 6| Step: 4
Training loss: 3.1597110920431737
Validation loss: 2.510018520127565

Epoch: 6| Step: 5
Training loss: 2.7399833493527335
Validation loss: 2.4932110497882976

Epoch: 6| Step: 6
Training loss: 2.699187569776268
Validation loss: 2.512456064947701

Epoch: 6| Step: 7
Training loss: 2.862331508691719
Validation loss: 2.506123641619152

Epoch: 6| Step: 8
Training loss: 2.326922317257398
Validation loss: 2.510276564498283

Epoch: 6| Step: 9
Training loss: 2.2158861617033527
Validation loss: 2.5027279962064632

Epoch: 6| Step: 10
Training loss: 2.840223200449067
Validation loss: 2.5043424588197944

Epoch: 6| Step: 11
Training loss: 3.4215436104338326
Validation loss: 2.505089452289858

Epoch: 6| Step: 12
Training loss: 3.1324876726277853
Validation loss: 2.5087215235491134

Epoch: 6| Step: 13
Training loss: 2.024937489804554
Validation loss: 2.505927078048231

Epoch: 46| Step: 0
Training loss: 2.451792944537385
Validation loss: 2.5035117321378286

Epoch: 6| Step: 1
Training loss: 2.8578306936912323
Validation loss: 2.5084711200989727

Epoch: 6| Step: 2
Training loss: 2.9786203234672373
Validation loss: 2.5184269386376874

Epoch: 6| Step: 3
Training loss: 2.7704766600843738
Validation loss: 2.51027452708726

Epoch: 6| Step: 4
Training loss: 3.7013231231464347
Validation loss: 2.506586645613514

Epoch: 6| Step: 5
Training loss: 3.122089709286399
Validation loss: 2.522481871679755

Epoch: 6| Step: 6
Training loss: 2.466781894037299
Validation loss: 2.4983605146538093

Epoch: 6| Step: 7
Training loss: 2.7126184358538037
Validation loss: 2.49595432359725

Epoch: 6| Step: 8
Training loss: 2.2966644813442305
Validation loss: 2.504047361090601

Epoch: 6| Step: 9
Training loss: 2.4707013880305158
Validation loss: 2.520198192498537

Epoch: 6| Step: 10
Training loss: 2.5047783009995523
Validation loss: 2.506737760225327

Epoch: 6| Step: 11
Training loss: 2.4407571402713635
Validation loss: 2.513448542219654

Epoch: 6| Step: 12
Training loss: 2.8212141883345123
Validation loss: 2.507157592496079

Epoch: 6| Step: 13
Training loss: 2.852712738903643
Validation loss: 2.499662221629252

Epoch: 47| Step: 0
Training loss: 2.73374068395966
Validation loss: 2.5033605712793467

Epoch: 6| Step: 1
Training loss: 2.631127064204753
Validation loss: 2.515101460931887

Epoch: 6| Step: 2
Training loss: 3.4205604013776245
Validation loss: 2.5077816193288474

Epoch: 6| Step: 3
Training loss: 2.403196800558193
Validation loss: 2.497626001919916

Epoch: 6| Step: 4
Training loss: 2.923245521656163
Validation loss: 2.503308098935945

Epoch: 6| Step: 5
Training loss: 2.8228701673293264
Validation loss: 2.505860207769449

Epoch: 6| Step: 6
Training loss: 2.5297969839191032
Validation loss: 2.5076160596119217

Epoch: 6| Step: 7
Training loss: 2.7608021209116163
Validation loss: 2.5134064722091414

Epoch: 6| Step: 8
Training loss: 2.8778847858199783
Validation loss: 2.4944417600512745

Epoch: 6| Step: 9
Training loss: 2.776177570578177
Validation loss: 2.5119182272895695

Epoch: 6| Step: 10
Training loss: 2.516553340238175
Validation loss: 2.509009721210394

Epoch: 6| Step: 11
Training loss: 2.5053729494274215
Validation loss: 2.5013675138677858

Epoch: 6| Step: 12
Training loss: 2.773537475503304
Validation loss: 2.4954885589746754

Epoch: 6| Step: 13
Training loss: 2.8961241505182134
Validation loss: 2.50280896066037

Epoch: 48| Step: 0
Training loss: 3.23338074075873
Validation loss: 2.504313463992248

Epoch: 6| Step: 1
Training loss: 3.0216090466966605
Validation loss: 2.5039055087278

Epoch: 6| Step: 2
Training loss: 2.291692999486197
Validation loss: 2.512793276391799

Epoch: 6| Step: 3
Training loss: 2.02904167443085
Validation loss: 2.501719931176122

Epoch: 6| Step: 4
Training loss: 2.9995711337946855
Validation loss: 2.508350956360604

Epoch: 6| Step: 5
Training loss: 2.222530314492995
Validation loss: 2.483016595367817

Epoch: 6| Step: 6
Training loss: 2.81585374722208
Validation loss: 2.506896523232087

Epoch: 6| Step: 7
Training loss: 1.8778360534907388
Validation loss: 2.514008704119357

Epoch: 6| Step: 8
Training loss: 2.5435117267857987
Validation loss: 2.518458421695928

Epoch: 6| Step: 9
Training loss: 3.2079413698884216
Validation loss: 2.50795091041279

Epoch: 6| Step: 10
Training loss: 2.697331830316421
Validation loss: 2.507683434096342

Epoch: 6| Step: 11
Training loss: 3.17071376646953
Validation loss: 2.5140111025517444

Epoch: 6| Step: 12
Training loss: 3.2426892731070964
Validation loss: 2.502491497027685

Epoch: 6| Step: 13
Training loss: 2.6215934447652693
Validation loss: 2.4977513229158363

Epoch: 49| Step: 0
Training loss: 2.289649653725259
Validation loss: 2.513201068627343

Epoch: 6| Step: 1
Training loss: 3.70294266263913
Validation loss: 2.5236111188196224

Epoch: 6| Step: 2
Training loss: 2.4468605089793805
Validation loss: 2.5114780538370325

Epoch: 6| Step: 3
Training loss: 2.7186573933581513
Validation loss: 2.5136494079896856

Epoch: 6| Step: 4
Training loss: 2.5319435205653793
Validation loss: 2.5075189505987976

Epoch: 6| Step: 5
Training loss: 3.3481860815404354
Validation loss: 2.505056603851431

Epoch: 6| Step: 6
Training loss: 2.6310876465497883
Validation loss: 2.515676869972456

Epoch: 6| Step: 7
Training loss: 2.5852850237787717
Validation loss: 2.5100940018211317

Epoch: 6| Step: 8
Training loss: 2.051497619486206
Validation loss: 2.4928430710886325

Epoch: 6| Step: 9
Training loss: 2.2828397045564146
Validation loss: 2.5056400902162173

Epoch: 6| Step: 10
Training loss: 3.114120466015319
Validation loss: 2.4916570670332243

Epoch: 6| Step: 11
Training loss: 2.2770679758385244
Validation loss: 2.500432349320765

Epoch: 6| Step: 12
Training loss: 3.2242346395106107
Validation loss: 2.500201572987748

Epoch: 6| Step: 13
Training loss: 3.04181489626821
Validation loss: 2.5076317944247046

Epoch: 50| Step: 0
Training loss: 1.9871154845053638
Validation loss: 2.480692939552083

Epoch: 6| Step: 1
Training loss: 3.0567030245228195
Validation loss: 2.5003406251588953

Epoch: 6| Step: 2
Training loss: 2.5696791590346835
Validation loss: 2.49970922522369

Epoch: 6| Step: 3
Training loss: 2.5605921272102576
Validation loss: 2.498073075229809

Epoch: 6| Step: 4
Training loss: 2.698514148041054
Validation loss: 2.514009006727821

Epoch: 6| Step: 5
Training loss: 3.289813827998202
Validation loss: 2.4947842354160383

Epoch: 6| Step: 6
Training loss: 3.0168256988195563
Validation loss: 2.4939103828212232

Epoch: 6| Step: 7
Training loss: 2.8404520215033386
Validation loss: 2.507799100158015

Epoch: 6| Step: 8
Training loss: 2.5373618666159903
Validation loss: 2.497986474880387

Epoch: 6| Step: 9
Training loss: 2.4962587018498863
Validation loss: 2.504994972722892

Epoch: 6| Step: 10
Training loss: 3.06545348703528
Validation loss: 2.506167677208888

Epoch: 6| Step: 11
Training loss: 2.1825965419535307
Validation loss: 2.503509604227887

Epoch: 6| Step: 12
Training loss: 2.718740529010982
Validation loss: 2.497764878272484

Epoch: 6| Step: 13
Training loss: 3.2959385124878446
Validation loss: 2.5044091556809933

Epoch: 51| Step: 0
Training loss: 2.813684680236462
Validation loss: 2.49840439565686

Epoch: 6| Step: 1
Training loss: 3.3718170415583293
Validation loss: 2.5041756797181836

Epoch: 6| Step: 2
Training loss: 2.306301573303345
Validation loss: 2.5110289755761506

Epoch: 6| Step: 3
Training loss: 2.9996744615041147
Validation loss: 2.5000310475462184

Epoch: 6| Step: 4
Training loss: 2.519927426912918
Validation loss: 2.527278275148952

Epoch: 6| Step: 5
Training loss: 2.542180139757227
Validation loss: 2.499538788244648

Epoch: 6| Step: 6
Training loss: 2.510190982619863
Validation loss: 2.4936807310768483

Epoch: 6| Step: 7
Training loss: 2.3923612784385777
Validation loss: 2.5136999031527023

Epoch: 6| Step: 8
Training loss: 2.540435513683063
Validation loss: 2.5089043853501694

Epoch: 6| Step: 9
Training loss: 2.4766574203640355
Validation loss: 2.5058568991973016

Epoch: 6| Step: 10
Training loss: 2.114239769697839
Validation loss: 2.5024994794148365

Epoch: 6| Step: 11
Training loss: 2.983322836859226
Validation loss: 2.4954546693248694

Epoch: 6| Step: 12
Training loss: 3.3443488894893885
Validation loss: 2.498295285848471

Epoch: 6| Step: 13
Training loss: 3.498032970816169
Validation loss: 2.505534411123778

Epoch: 52| Step: 0
Training loss: 2.5415448540019048
Validation loss: 2.511040850753949

Epoch: 6| Step: 1
Training loss: 2.720835094441598
Validation loss: 2.50995790659452

Epoch: 6| Step: 2
Training loss: 2.6982750574816565
Validation loss: 2.5005726953038794

Epoch: 6| Step: 3
Training loss: 2.3575626511405234
Validation loss: 2.511956450675723

Epoch: 6| Step: 4
Training loss: 2.762246001981697
Validation loss: 2.50455912832825

Epoch: 6| Step: 5
Training loss: 2.320605532448685
Validation loss: 2.508448590155871

Epoch: 6| Step: 6
Training loss: 2.8159366380162942
Validation loss: 2.5053661437352672

Epoch: 6| Step: 7
Training loss: 2.5508483597484095
Validation loss: 2.5146227066439195

Epoch: 6| Step: 8
Training loss: 2.5630269322939356
Validation loss: 2.5056062422056113

Epoch: 6| Step: 9
Training loss: 3.0302787876604396
Validation loss: 2.4927166198905657

Epoch: 6| Step: 10
Training loss: 2.8207043827245846
Validation loss: 2.5101703370957082

Epoch: 6| Step: 11
Training loss: 2.449570333990635
Validation loss: 2.5148742234164265

Epoch: 6| Step: 12
Training loss: 3.3449848782549667
Validation loss: 2.50346721051903

Epoch: 6| Step: 13
Training loss: 3.6838831863687735
Validation loss: 2.5005675071656106

Epoch: 53| Step: 0
Training loss: 3.060856592297862
Validation loss: 2.5062248482601936

Epoch: 6| Step: 1
Training loss: 2.465855700550521
Validation loss: 2.510285379983964

Epoch: 6| Step: 2
Training loss: 2.2604910725478664
Validation loss: 2.501629205228284

Epoch: 6| Step: 3
Training loss: 3.396330502552477
Validation loss: 2.4984111638769115

Epoch: 6| Step: 4
Training loss: 3.203526615923561
Validation loss: 2.5134412841068277

Epoch: 6| Step: 5
Training loss: 2.438599363022249
Validation loss: 2.514626505272544

Epoch: 6| Step: 6
Training loss: 2.9641944063604755
Validation loss: 2.5067127203141664

Epoch: 6| Step: 7
Training loss: 2.238654886053797
Validation loss: 2.515228997497195

Epoch: 6| Step: 8
Training loss: 2.9549282159493444
Validation loss: 2.488471767262655

Epoch: 6| Step: 9
Training loss: 2.5414926021152304
Validation loss: 2.499340161030417

Epoch: 6| Step: 10
Training loss: 3.009480120604467
Validation loss: 2.5182721225461355

Epoch: 6| Step: 11
Training loss: 2.3212888570808703
Validation loss: 2.502427006969948

Epoch: 6| Step: 12
Training loss: 2.4903116371286367
Validation loss: 2.4991080466996594

Epoch: 6| Step: 13
Training loss: 2.6688857283014573
Validation loss: 2.5085155559733447

Epoch: 54| Step: 0
Training loss: 2.5604123240952155
Validation loss: 2.509082983372601

Epoch: 6| Step: 1
Training loss: 3.142101187637351
Validation loss: 2.498009579478949

Epoch: 6| Step: 2
Training loss: 3.2887062731583128
Validation loss: 2.513768178269801

Epoch: 6| Step: 3
Training loss: 2.61590326030007
Validation loss: 2.5041226880005056

Epoch: 6| Step: 4
Training loss: 2.806104636728518
Validation loss: 2.5040566295238107

Epoch: 6| Step: 5
Training loss: 2.8342862116356162
Validation loss: 2.4941897975918743

Epoch: 6| Step: 6
Training loss: 2.348264085530643
Validation loss: 2.499199587348927

Epoch: 6| Step: 7
Training loss: 2.282599272224767
Validation loss: 2.501864915955506

Epoch: 6| Step: 8
Training loss: 2.5092301684397165
Validation loss: 2.504052472912696

Epoch: 6| Step: 9
Training loss: 2.546010157244994
Validation loss: 2.5044155478607544

Epoch: 6| Step: 10
Training loss: 2.458311005399353
Validation loss: 2.509780917323173

Epoch: 6| Step: 11
Training loss: 3.618623057298252
Validation loss: 2.528436320160125

Epoch: 6| Step: 12
Training loss: 2.4516693461507457
Validation loss: 2.4965645073063594

Epoch: 6| Step: 13
Training loss: 2.418041813598514
Validation loss: 2.5165369481056667

Epoch: 55| Step: 0
Training loss: 2.7636202857927876
Validation loss: 2.4952377244948147

Epoch: 6| Step: 1
Training loss: 2.898153532774986
Validation loss: 2.507539931310107

Epoch: 6| Step: 2
Training loss: 2.433012328029245
Validation loss: 2.4926917641266617

Epoch: 6| Step: 3
Training loss: 3.4550801951573082
Validation loss: 2.5015870481519227

Epoch: 6| Step: 4
Training loss: 2.7339489414160645
Validation loss: 2.5006258263257894

Epoch: 6| Step: 5
Training loss: 2.349237046267244
Validation loss: 2.510621576971694

Epoch: 6| Step: 6
Training loss: 2.99476006974953
Validation loss: 2.5008963977481753

Epoch: 6| Step: 7
Training loss: 2.4634812544552163
Validation loss: 2.5046059786088946

Epoch: 6| Step: 8
Training loss: 2.600694666275221
Validation loss: 2.506357443458676

Epoch: 6| Step: 9
Training loss: 2.187581741985577
Validation loss: 2.5043385667924736

Epoch: 6| Step: 10
Training loss: 2.787758402116176
Validation loss: 2.4999316657376744

Epoch: 6| Step: 11
Training loss: 2.664362468220221
Validation loss: 2.494977620212459

Epoch: 6| Step: 12
Training loss: 2.2981013961878713
Validation loss: 2.4998840602529513

Epoch: 6| Step: 13
Training loss: 3.840984931636175
Validation loss: 2.5040149586733413

Epoch: 56| Step: 0
Training loss: 2.623414150949782
Validation loss: 2.509517228912497

Epoch: 6| Step: 1
Training loss: 2.712912068512264
Validation loss: 2.503330302373926

Epoch: 6| Step: 2
Training loss: 3.291248311043439
Validation loss: 2.513355560088035

Epoch: 6| Step: 3
Training loss: 2.79426120117651
Validation loss: 2.507230276873786

Epoch: 6| Step: 4
Training loss: 3.08808333720283
Validation loss: 2.494048135964225

Epoch: 6| Step: 5
Training loss: 2.7443264609839675
Validation loss: 2.510272145509973

Epoch: 6| Step: 6
Training loss: 2.600137406166225
Validation loss: 2.514120668294218

Epoch: 6| Step: 7
Training loss: 2.525058851406035
Validation loss: 2.5054512775100357

Epoch: 6| Step: 8
Training loss: 2.2973792113056892
Validation loss: 2.514466152479755

Epoch: 6| Step: 9
Training loss: 2.600136305830701
Validation loss: 2.4993068021149494

Epoch: 6| Step: 10
Training loss: 2.4333417587482784
Validation loss: 2.5123803562620255

Epoch: 6| Step: 11
Training loss: 2.3823244689453396
Validation loss: 2.47770358274259

Epoch: 6| Step: 12
Training loss: 3.008090078253023
Validation loss: 2.497644242557761

Epoch: 6| Step: 13
Training loss: 3.2109827934096367
Validation loss: 2.5040825662117987

Epoch: 57| Step: 0
Training loss: 1.7816885023619737
Validation loss: 2.4979110219401206

Epoch: 6| Step: 1
Training loss: 3.264619517333765
Validation loss: 2.506058841976846

Epoch: 6| Step: 2
Training loss: 2.49068297889454
Validation loss: 2.506864958375184

Epoch: 6| Step: 3
Training loss: 3.4831739331389318
Validation loss: 2.5078672916055775

Epoch: 6| Step: 4
Training loss: 2.4506755675955687
Validation loss: 2.517404536145102

Epoch: 6| Step: 5
Training loss: 2.989920372301349
Validation loss: 2.495621286993593

Epoch: 6| Step: 6
Training loss: 2.287309619923328
Validation loss: 2.505687083986105

Epoch: 6| Step: 7
Training loss: 2.1814040121451326
Validation loss: 2.4859507361905733

Epoch: 6| Step: 8
Training loss: 2.4977860184058795
Validation loss: 2.4831195382561257

Epoch: 6| Step: 9
Training loss: 3.160500261328176
Validation loss: 2.504825048926622

Epoch: 6| Step: 10
Training loss: 2.8556140283451885
Validation loss: 2.5052095043572

Epoch: 6| Step: 11
Training loss: 3.0477428276322445
Validation loss: 2.49875221158611

Epoch: 6| Step: 12
Training loss: 2.5261756048710287
Validation loss: 2.504898797828783

Epoch: 6| Step: 13
Training loss: 2.526507892384178
Validation loss: 2.508546646309589

Epoch: 58| Step: 0
Training loss: 3.1673730932282895
Validation loss: 2.4951949292781275

Epoch: 6| Step: 1
Training loss: 3.4760139632652427
Validation loss: 2.505394499129074

Epoch: 6| Step: 2
Training loss: 2.509680886823367
Validation loss: 2.5040263291039198

Epoch: 6| Step: 3
Training loss: 2.4770276327797975
Validation loss: 2.5059283527443093

Epoch: 6| Step: 4
Training loss: 2.8522654045920097
Validation loss: 2.5033021140818277

Epoch: 6| Step: 5
Training loss: 2.7834781765131114
Validation loss: 2.510720553000018

Epoch: 6| Step: 6
Training loss: 2.6346702473586507
Validation loss: 2.517453205449992

Epoch: 6| Step: 7
Training loss: 2.52148967006609
Validation loss: 2.5083907124667237

Epoch: 6| Step: 8
Training loss: 2.793243949510069
Validation loss: 2.4965607833690564

Epoch: 6| Step: 9
Training loss: 1.6650159369957482
Validation loss: 2.498912379859094

Epoch: 6| Step: 10
Training loss: 2.4602427637292084
Validation loss: 2.491372636324359

Epoch: 6| Step: 11
Training loss: 3.047172962193554
Validation loss: 2.4924001830245817

Epoch: 6| Step: 12
Training loss: 2.8086457015579382
Validation loss: 2.4975483019410882

Epoch: 6| Step: 13
Training loss: 2.3570256947220227
Validation loss: 2.505220916438784

Epoch: 59| Step: 0
Training loss: 2.5678950016862174
Validation loss: 2.5121392612027647

Epoch: 6| Step: 1
Training loss: 2.8615840862476882
Validation loss: 2.509372920215503

Epoch: 6| Step: 2
Training loss: 2.6887569593040674
Validation loss: 2.507498496753884

Epoch: 6| Step: 3
Training loss: 3.0033830005915307
Validation loss: 2.523833400968659

Epoch: 6| Step: 4
Training loss: 1.944749497901625
Validation loss: 2.5127905533820605

Epoch: 6| Step: 5
Training loss: 2.614324387168274
Validation loss: 2.47787765809779

Epoch: 6| Step: 6
Training loss: 3.1547675853311374
Validation loss: 2.506176793567701

Epoch: 6| Step: 7
Training loss: 3.1387732061563574
Validation loss: 2.5017691822860693

Epoch: 6| Step: 8
Training loss: 2.6362746479298447
Validation loss: 2.507043234366434

Epoch: 6| Step: 9
Training loss: 2.352749141752544
Validation loss: 2.49909933129864

Epoch: 6| Step: 10
Training loss: 3.2716519896426957
Validation loss: 2.5120672515789315

Epoch: 6| Step: 11
Training loss: 2.6789539100410114
Validation loss: 2.4923738120722865

Epoch: 6| Step: 12
Training loss: 2.0713210618255466
Validation loss: 2.514404995670718

Epoch: 6| Step: 13
Training loss: 2.7062244616706463
Validation loss: 2.4841385311747883

Epoch: 60| Step: 0
Training loss: 2.6351387772035975
Validation loss: 2.5241095398763997

Epoch: 6| Step: 1
Training loss: 2.573544496443961
Validation loss: 2.488584119084331

Epoch: 6| Step: 2
Training loss: 2.484385364438876
Validation loss: 2.502272771556248

Epoch: 6| Step: 3
Training loss: 3.3158486192888903
Validation loss: 2.503793799365601

Epoch: 6| Step: 4
Training loss: 3.2184442171196532
Validation loss: 2.488938043613942

Epoch: 6| Step: 5
Training loss: 2.2231502687885825
Validation loss: 2.501037840612568

Epoch: 6| Step: 6
Training loss: 2.9294443258453535
Validation loss: 2.497595923206174

Epoch: 6| Step: 7
Training loss: 2.5704053496776753
Validation loss: 2.498320451170863

Epoch: 6| Step: 8
Training loss: 2.720623905208831
Validation loss: 2.498207383781222

Epoch: 6| Step: 9
Training loss: 2.3555025569583665
Validation loss: 2.503814562997533

Epoch: 6| Step: 10
Training loss: 2.625173381347413
Validation loss: 2.4769595620973495

Epoch: 6| Step: 11
Training loss: 1.9728638794660556
Validation loss: 2.4971607533927678

Epoch: 6| Step: 12
Training loss: 3.6814058021515024
Validation loss: 2.502520820292004

Epoch: 6| Step: 13
Training loss: 2.164039804497981
Validation loss: 2.5193661296615053

Epoch: 61| Step: 0
Training loss: 3.0364888333096918
Validation loss: 2.50327075890641

Epoch: 6| Step: 1
Training loss: 2.9681199860906995
Validation loss: 2.515975372346386

Epoch: 6| Step: 2
Training loss: 2.268378327666432
Validation loss: 2.492296975948107

Epoch: 6| Step: 3
Training loss: 3.028204262781642
Validation loss: 2.4859459150847414

Epoch: 6| Step: 4
Training loss: 2.925467338070648
Validation loss: 2.5130644903142554

Epoch: 6| Step: 5
Training loss: 2.6519722994455215
Validation loss: 2.4888197818251583

Epoch: 6| Step: 6
Training loss: 2.632773198137202
Validation loss: 2.52436399492106

Epoch: 6| Step: 7
Training loss: 2.1476673202257093
Validation loss: 2.497310859011024

Epoch: 6| Step: 8
Training loss: 2.571536436543378
Validation loss: 2.500477765689634

Epoch: 6| Step: 9
Training loss: 2.464299306575339
Validation loss: 2.498188025618793

Epoch: 6| Step: 10
Training loss: 2.755313854444339
Validation loss: 2.5057830066144264

Epoch: 6| Step: 11
Training loss: 3.327735842308046
Validation loss: 2.5180459683407124

Epoch: 6| Step: 12
Training loss: 2.2454712112813557
Validation loss: 2.490219562831501

Epoch: 6| Step: 13
Training loss: 2.725773738239551
Validation loss: 2.503591939097078

Epoch: 62| Step: 0
Training loss: 2.6968175252047937
Validation loss: 2.5081516021654457

Epoch: 6| Step: 1
Training loss: 2.6628568275861944
Validation loss: 2.4892868663181873

Epoch: 6| Step: 2
Training loss: 2.7863996172746717
Validation loss: 2.5094418024035896

Epoch: 6| Step: 3
Training loss: 2.2008475578375153
Validation loss: 2.496771379651119

Epoch: 6| Step: 4
Training loss: 3.4683224526240313
Validation loss: 2.511801988493189

Epoch: 6| Step: 5
Training loss: 2.8142111764930573
Validation loss: 2.490475200386356

Epoch: 6| Step: 6
Training loss: 2.667265814786238
Validation loss: 2.492155335312281

Epoch: 6| Step: 7
Training loss: 2.724618475567239
Validation loss: 2.502134616713513

Epoch: 6| Step: 8
Training loss: 1.9872281446408058
Validation loss: 2.5006798629884734

Epoch: 6| Step: 9
Training loss: 2.3438567073690653
Validation loss: 2.494483293811707

Epoch: 6| Step: 10
Training loss: 2.563206645015909
Validation loss: 2.493305217068264

Epoch: 6| Step: 11
Training loss: 3.23510601241444
Validation loss: 2.51320033876726

Epoch: 6| Step: 12
Training loss: 2.613602098232813
Validation loss: 2.5056577568503724

Epoch: 6| Step: 13
Training loss: 2.963863326294849
Validation loss: 2.501762522549918

Epoch: 63| Step: 0
Training loss: 2.2449043640972484
Validation loss: 2.503804200145207

Epoch: 6| Step: 1
Training loss: 2.753822617579832
Validation loss: 2.4993930736223136

Epoch: 6| Step: 2
Training loss: 3.0306902496431776
Validation loss: 2.5034194643836005

Epoch: 6| Step: 3
Training loss: 2.9157942057387602
Validation loss: 2.5229888682810455

Epoch: 6| Step: 4
Training loss: 2.8024963490498944
Validation loss: 2.491812123109429

Epoch: 6| Step: 5
Training loss: 3.198722083509178
Validation loss: 2.4941031672509686

Epoch: 6| Step: 6
Training loss: 1.971302436610142
Validation loss: 2.5071605087462827

Epoch: 6| Step: 7
Training loss: 2.3877790877110483
Validation loss: 2.5003696701575593

Epoch: 6| Step: 8
Training loss: 3.064337821235415
Validation loss: 2.506419461468095

Epoch: 6| Step: 9
Training loss: 2.5331285828951655
Validation loss: 2.502715365056575

Epoch: 6| Step: 10
Training loss: 2.779295759810695
Validation loss: 2.5002265007205624

Epoch: 6| Step: 11
Training loss: 2.0749444931143617
Validation loss: 2.495479241254548

Epoch: 6| Step: 12
Training loss: 2.885314352009519
Validation loss: 2.497722295709871

Epoch: 6| Step: 13
Training loss: 3.0897474503008535
Validation loss: 2.503053732064811

Epoch: 64| Step: 0
Training loss: 3.145822958687018
Validation loss: 2.4880770080797765

Epoch: 6| Step: 1
Training loss: 2.5877515071687243
Validation loss: 2.499154279054934

Epoch: 6| Step: 2
Training loss: 2.1285216377776837
Validation loss: 2.492445847580299

Epoch: 6| Step: 3
Training loss: 3.025815674073561
Validation loss: 2.4989479004572646

Epoch: 6| Step: 4
Training loss: 2.4546952779878564
Validation loss: 2.507214916845652

Epoch: 6| Step: 5
Training loss: 2.4792180309798284
Validation loss: 2.504401468051087

Epoch: 6| Step: 6
Training loss: 2.944250426308017
Validation loss: 2.4954436918294256

Epoch: 6| Step: 7
Training loss: 2.0192729260861233
Validation loss: 2.512050579120811

Epoch: 6| Step: 8
Training loss: 2.6654659389250925
Validation loss: 2.509606466333733

Epoch: 6| Step: 9
Training loss: 1.7563713439073683
Validation loss: 2.494172573932914

Epoch: 6| Step: 10
Training loss: 2.8527152461852676
Validation loss: 2.5115975269818636

Epoch: 6| Step: 11
Training loss: 3.1235174095385525
Validation loss: 2.5003490901580423

Epoch: 6| Step: 12
Training loss: 3.1437157752295684
Validation loss: 2.4967841579240226

Epoch: 6| Step: 13
Training loss: 3.372980856014677
Validation loss: 2.49787240504418

Epoch: 65| Step: 0
Training loss: 2.936253059811092
Validation loss: 2.510789025533358

Epoch: 6| Step: 1
Training loss: 3.2837895329785396
Validation loss: 2.486983426633791

Epoch: 6| Step: 2
Training loss: 2.1996528915195155
Validation loss: 2.5006113289360035

Epoch: 6| Step: 3
Training loss: 2.3385193504395834
Validation loss: 2.5038026847754

Epoch: 6| Step: 4
Training loss: 2.651566269286876
Validation loss: 2.532207336842548

Epoch: 6| Step: 5
Training loss: 2.350391793563778
Validation loss: 2.5027782108245398

Epoch: 6| Step: 6
Training loss: 2.2530707491667306
Validation loss: 2.5052423814901266

Epoch: 6| Step: 7
Training loss: 2.4529082573064587
Validation loss: 2.507609940888976

Epoch: 6| Step: 8
Training loss: 2.3922554390178012
Validation loss: 2.502729627977158

Epoch: 6| Step: 9
Training loss: 2.6118537870204275
Validation loss: 2.487170059221721

Epoch: 6| Step: 10
Training loss: 2.504812853098337
Validation loss: 2.513403475487059

Epoch: 6| Step: 11
Training loss: 3.6414405007624744
Validation loss: 2.512957877819415

Epoch: 6| Step: 12
Training loss: 2.825481296151352
Validation loss: 2.4810401760214695

Epoch: 6| Step: 13
Training loss: 3.221225416262117
Validation loss: 2.4887278120001852

Epoch: 66| Step: 0
Training loss: 2.8973977416642125
Validation loss: 2.4946053638952743

Epoch: 6| Step: 1
Training loss: 2.152765305459047
Validation loss: 2.495314837869646

Epoch: 6| Step: 2
Training loss: 2.8007734184208846
Validation loss: 2.5012942266072065

Epoch: 6| Step: 3
Training loss: 2.4265764441154007
Validation loss: 2.5073395796422298

Epoch: 6| Step: 4
Training loss: 2.967474733805895
Validation loss: 2.508042008714068

Epoch: 6| Step: 5
Training loss: 2.834599118693204
Validation loss: 2.489991625721379

Epoch: 6| Step: 6
Training loss: 3.4753694351646223
Validation loss: 2.5039473830961634

Epoch: 6| Step: 7
Training loss: 2.59327242947268
Validation loss: 2.505401696647203

Epoch: 6| Step: 8
Training loss: 2.9894595945760063
Validation loss: 2.5075458278383325

Epoch: 6| Step: 9
Training loss: 2.710333853142358
Validation loss: 2.5108227648762997

Epoch: 6| Step: 10
Training loss: 2.306892400658898
Validation loss: 2.497523375191998

Epoch: 6| Step: 11
Training loss: 2.173694534515447
Validation loss: 2.495251824676264

Epoch: 6| Step: 12
Training loss: 2.1156331229793515
Validation loss: 2.509658734462692

Epoch: 6| Step: 13
Training loss: 3.3267148751210347
Validation loss: 2.4916252216603505

Epoch: 67| Step: 0
Training loss: 2.3316155195682047
Validation loss: 2.5205593551787713

Epoch: 6| Step: 1
Training loss: 2.728275318527088
Validation loss: 2.4978729982626757

Epoch: 6| Step: 2
Training loss: 2.8209680022676817
Validation loss: 2.50573398991033

Epoch: 6| Step: 3
Training loss: 2.8714697351602725
Validation loss: 2.5028740154969698

Epoch: 6| Step: 4
Training loss: 2.728929426835804
Validation loss: 2.499095551127612

Epoch: 6| Step: 5
Training loss: 2.2075570619494065
Validation loss: 2.5028913615972725

Epoch: 6| Step: 6
Training loss: 2.6822554403778405
Validation loss: 2.4895564169777438

Epoch: 6| Step: 7
Training loss: 3.4894126432814985
Validation loss: 2.4842190349460456

Epoch: 6| Step: 8
Training loss: 2.601861793325107
Validation loss: 2.507195461561106

Epoch: 6| Step: 9
Training loss: 2.2865007146037155
Validation loss: 2.5085185851059477

Epoch: 6| Step: 10
Training loss: 2.04698937948255
Validation loss: 2.5169342655274445

Epoch: 6| Step: 11
Training loss: 3.4885371371710914
Validation loss: 2.5117217630215083

Epoch: 6| Step: 12
Training loss: 2.6597365889951123
Validation loss: 2.5063948275129926

Epoch: 6| Step: 13
Training loss: 2.082902164346423
Validation loss: 2.492334239691515

Epoch: 68| Step: 0
Training loss: 2.987109304762079
Validation loss: 2.501703000178619

Epoch: 6| Step: 1
Training loss: 2.625168567876285
Validation loss: 2.493304538449763

Epoch: 6| Step: 2
Training loss: 2.3316799391213574
Validation loss: 2.5040395648507476

Epoch: 6| Step: 3
Training loss: 2.7932388281787
Validation loss: 2.4992739484510746

Epoch: 6| Step: 4
Training loss: 2.9070213688818565
Validation loss: 2.5031476970308937

Epoch: 6| Step: 5
Training loss: 3.2708718526398433
Validation loss: 2.503847313055902

Epoch: 6| Step: 6
Training loss: 3.104513076467156
Validation loss: 2.5021311177655217

Epoch: 6| Step: 7
Training loss: 2.488597041381951
Validation loss: 2.5115106605814614

Epoch: 6| Step: 8
Training loss: 2.487417409474638
Validation loss: 2.5198623143369745

Epoch: 6| Step: 9
Training loss: 2.548465910565502
Validation loss: 2.496945851589395

Epoch: 6| Step: 10
Training loss: 2.4115271232356217
Validation loss: 2.5073547446415083

Epoch: 6| Step: 11
Training loss: 2.6021125830499616
Validation loss: 2.5118883921815036

Epoch: 6| Step: 12
Training loss: 2.5952068052409607
Validation loss: 2.5097820685082484

Epoch: 6| Step: 13
Training loss: 2.0464548160160687
Validation loss: 2.5035702489524803

Epoch: 69| Step: 0
Training loss: 2.944681358003086
Validation loss: 2.4997616695298723

Epoch: 6| Step: 1
Training loss: 2.837429694426452
Validation loss: 2.5152846549245895

Epoch: 6| Step: 2
Training loss: 2.244810052665122
Validation loss: 2.4980593845407917

Epoch: 6| Step: 3
Training loss: 2.3755855842256994
Validation loss: 2.500163004288457

Epoch: 6| Step: 4
Training loss: 2.9951603317014026
Validation loss: 2.5179881442804946

Epoch: 6| Step: 5
Training loss: 3.185282066467041
Validation loss: 2.507659450488165

Epoch: 6| Step: 6
Training loss: 2.515471744015461
Validation loss: 2.505911425627789

Epoch: 6| Step: 7
Training loss: 2.9351859210263345
Validation loss: 2.5101291640108925

Epoch: 6| Step: 8
Training loss: 2.0847834562926066
Validation loss: 2.505296005452203

Epoch: 6| Step: 9
Training loss: 3.1564935269216137
Validation loss: 2.5136807632279585

Epoch: 6| Step: 10
Training loss: 1.7969730516301328
Validation loss: 2.501112066086191

Epoch: 6| Step: 11
Training loss: 3.2415962139668624
Validation loss: 2.496848718775755

Epoch: 6| Step: 12
Training loss: 2.4125357432509427
Validation loss: 2.485665329181094

Epoch: 6| Step: 13
Training loss: 2.1548337846633014
Validation loss: 2.4916377464649435

Epoch: 70| Step: 0
Training loss: 3.4545809753088466
Validation loss: 2.498290615808263

Epoch: 6| Step: 1
Training loss: 2.8157436739587935
Validation loss: 2.4987725946722934

Epoch: 6| Step: 2
Training loss: 2.3439480507142263
Validation loss: 2.5063746948743773

Epoch: 6| Step: 3
Training loss: 2.954982274449302
Validation loss: 2.485587944285857

Epoch: 6| Step: 4
Training loss: 2.8308237592842
Validation loss: 2.5122421062091416

Epoch: 6| Step: 5
Training loss: 2.510802960782374
Validation loss: 2.500955665624308

Epoch: 6| Step: 6
Training loss: 2.417791061158404
Validation loss: 2.503938139854659

Epoch: 6| Step: 7
Training loss: 1.7005497772729001
Validation loss: 2.504115234958492

Epoch: 6| Step: 8
Training loss: 2.410228363392646
Validation loss: 2.491184552929614

Epoch: 6| Step: 9
Training loss: 3.148372677876434
Validation loss: 2.4957005076785914

Epoch: 6| Step: 10
Training loss: 2.398419805703766
Validation loss: 2.500045287839813

Epoch: 6| Step: 11
Training loss: 3.3097512698574123
Validation loss: 2.483964286170436

Epoch: 6| Step: 12
Training loss: 2.3896976242958408
Validation loss: 2.487038990227472

Epoch: 6| Step: 13
Training loss: 2.2742179238970825
Validation loss: 2.4895363458836686

Epoch: 71| Step: 0
Training loss: 2.3200360785342724
Validation loss: 2.493312095781739

Epoch: 6| Step: 1
Training loss: 2.4316047390047766
Validation loss: 2.4937711355558783

Epoch: 6| Step: 2
Training loss: 2.3257825703436166
Validation loss: 2.5011781551828185

Epoch: 6| Step: 3
Training loss: 2.50495115190646
Validation loss: 2.493580895697394

Epoch: 6| Step: 4
Training loss: 2.4081697608635175
Validation loss: 2.502692875490311

Epoch: 6| Step: 5
Training loss: 2.8596894971982083
Validation loss: 2.498526940081382

Epoch: 6| Step: 6
Training loss: 2.699592354695568
Validation loss: 2.4883253448077647

Epoch: 6| Step: 7
Training loss: 2.6997808155526934
Validation loss: 2.4994171016783593

Epoch: 6| Step: 8
Training loss: 2.2604278939198306
Validation loss: 2.4938664289113226

Epoch: 6| Step: 9
Training loss: 2.484052529189638
Validation loss: 2.507416971096295

Epoch: 6| Step: 10
Training loss: 2.7389068541884387
Validation loss: 2.5069911581528372

Epoch: 6| Step: 11
Training loss: 3.1700846312383946
Validation loss: 2.493281221622784

Epoch: 6| Step: 12
Training loss: 3.4693292357557155
Validation loss: 2.514034552410437

Epoch: 6| Step: 13
Training loss: 3.1269761512952163
Validation loss: 2.520163331521141

Epoch: 72| Step: 0
Training loss: 2.947647423911713
Validation loss: 2.4980574043850767

Epoch: 6| Step: 1
Training loss: 3.0670816831753163
Validation loss: 2.5060249515416047

Epoch: 6| Step: 2
Training loss: 3.4209015040665673
Validation loss: 2.5022718448733494

Epoch: 6| Step: 3
Training loss: 2.4991445985307124
Validation loss: 2.50755857216419

Epoch: 6| Step: 4
Training loss: 2.4595746823283164
Validation loss: 2.495841817700863

Epoch: 6| Step: 5
Training loss: 3.177461261888299
Validation loss: 2.505156732013744

Epoch: 6| Step: 6
Training loss: 2.256452632691753
Validation loss: 2.505035014400791

Epoch: 6| Step: 7
Training loss: 2.6073635366249914
Validation loss: 2.5051411464147133

Epoch: 6| Step: 8
Training loss: 2.0162464928404358
Validation loss: 2.5223933469028443

Epoch: 6| Step: 9
Training loss: 2.331069313390176
Validation loss: 2.50503945593172

Epoch: 6| Step: 10
Training loss: 2.3093143893948613
Validation loss: 2.511127355158334

Epoch: 6| Step: 11
Training loss: 2.8159946347207194
Validation loss: 2.5021972567882065

Epoch: 6| Step: 12
Training loss: 2.296377115069356
Validation loss: 2.5106342704562357

Epoch: 6| Step: 13
Training loss: 2.957289408572845
Validation loss: 2.5001495952353534

Epoch: 73| Step: 0
Training loss: 2.463209768335512
Validation loss: 2.4972131454798805

Epoch: 6| Step: 1
Training loss: 3.1223438418749674
Validation loss: 2.513516558979658

Epoch: 6| Step: 2
Training loss: 2.89468181594312
Validation loss: 2.515442222151725

Epoch: 6| Step: 3
Training loss: 2.2584139013053774
Validation loss: 2.506845570937922

Epoch: 6| Step: 4
Training loss: 2.418576461520232
Validation loss: 2.520906409846234

Epoch: 6| Step: 5
Training loss: 3.2586159572974105
Validation loss: 2.499058649792746

Epoch: 6| Step: 6
Training loss: 2.5586196548664755
Validation loss: 2.5065920846539447

Epoch: 6| Step: 7
Training loss: 2.7145760603187856
Validation loss: 2.5018492534912697

Epoch: 6| Step: 8
Training loss: 2.9956512721258886
Validation loss: 2.508069980700323

Epoch: 6| Step: 9
Training loss: 2.118996160830467
Validation loss: 2.493532223099811

Epoch: 6| Step: 10
Training loss: 2.654806036320661
Validation loss: 2.503430430970632

Epoch: 6| Step: 11
Training loss: 2.4288393361717153
Validation loss: 2.4985751932043283

Epoch: 6| Step: 12
Training loss: 2.398942428273326
Validation loss: 2.4888637486367147

Epoch: 6| Step: 13
Training loss: 3.027670093297428
Validation loss: 2.5077428380321054

Epoch: 74| Step: 0
Training loss: 2.387983271235109
Validation loss: 2.503611252915987

Epoch: 6| Step: 1
Training loss: 2.7982263124353377
Validation loss: 2.5071807066511713

Epoch: 6| Step: 2
Training loss: 2.530988891697761
Validation loss: 2.5138022345667204

Epoch: 6| Step: 3
Training loss: 2.0820093779998556
Validation loss: 2.5115940146780407

Epoch: 6| Step: 4
Training loss: 2.650451434568616
Validation loss: 2.4967344090542567

Epoch: 6| Step: 5
Training loss: 3.1102839535921243
Validation loss: 2.5024140526181715

Epoch: 6| Step: 6
Training loss: 2.219994639141037
Validation loss: 2.515783649512635

Epoch: 6| Step: 7
Training loss: 2.4371914790600733
Validation loss: 2.503392802954978

Epoch: 6| Step: 8
Training loss: 2.8862244798433254
Validation loss: 2.4976942740416024

Epoch: 6| Step: 9
Training loss: 2.8065218651478956
Validation loss: 2.506252251849778

Epoch: 6| Step: 10
Training loss: 2.2273929586497374
Validation loss: 2.5031826700326745

Epoch: 6| Step: 11
Training loss: 3.1320489347686054
Validation loss: 2.513648894986016

Epoch: 6| Step: 12
Training loss: 3.4262672697214462
Validation loss: 2.5036604765481236

Epoch: 6| Step: 13
Training loss: 2.112352431520932
Validation loss: 2.500179200261525

Epoch: 75| Step: 0
Training loss: 2.5813068522180034
Validation loss: 2.4838594910620593

Epoch: 6| Step: 1
Training loss: 2.6047938901229735
Validation loss: 2.4847167911125996

Epoch: 6| Step: 2
Training loss: 2.552698136578091
Validation loss: 2.490458610873607

Epoch: 6| Step: 3
Training loss: 2.6143329596735847
Validation loss: 2.5067004313984342

Epoch: 6| Step: 4
Training loss: 2.8190487384026808
Validation loss: 2.5067699402960697

Epoch: 6| Step: 5
Training loss: 2.3295967519318292
Validation loss: 2.497929030090879

Epoch: 6| Step: 6
Training loss: 2.967821156606735
Validation loss: 2.497963977633104

Epoch: 6| Step: 7
Training loss: 2.491632477473657
Validation loss: 2.5086504622672248

Epoch: 6| Step: 8
Training loss: 2.814315803137384
Validation loss: 2.510115453797741

Epoch: 6| Step: 9
Training loss: 2.7728888170394783
Validation loss: 2.499101479376996

Epoch: 6| Step: 10
Training loss: 2.8074854758507723
Validation loss: 2.492502159807004

Epoch: 6| Step: 11
Training loss: 2.6817610033637593
Validation loss: 2.491054557579888

Epoch: 6| Step: 12
Training loss: 2.724267731716592
Validation loss: 2.506505148596702

Epoch: 6| Step: 13
Training loss: 2.2860752442292513
Validation loss: 2.5023534157302865

Testing loss: 2.477547426117332
