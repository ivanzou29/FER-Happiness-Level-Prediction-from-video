Epoch: 1| Step: 0
Training loss: 6.518848966320904
Validation loss: 5.739942624688348

Epoch: 6| Step: 1
Training loss: 5.162369489521057
Validation loss: 5.734166406221457

Epoch: 6| Step: 2
Training loss: 5.796491337750215
Validation loss: 5.728834599541548

Epoch: 6| Step: 3
Training loss: 5.871591431417891
Validation loss: 5.722236431709634

Epoch: 6| Step: 4
Training loss: 5.777788765399626
Validation loss: 5.7157887305606545

Epoch: 6| Step: 5
Training loss: 6.0067234515611885
Validation loss: 5.710231228673622

Epoch: 6| Step: 6
Training loss: 5.60280094262771
Validation loss: 5.704458465419816

Epoch: 6| Step: 7
Training loss: 5.211077137781889
Validation loss: 5.700955803120314

Epoch: 6| Step: 8
Training loss: 5.855299363794172
Validation loss: 5.691529013567952

Epoch: 6| Step: 9
Training loss: 5.309791143587984
Validation loss: 5.688627379895636

Epoch: 6| Step: 10
Training loss: 4.322525974987699
Validation loss: 5.680308244288675

Epoch: 6| Step: 11
Training loss: 4.667593636863295
Validation loss: 5.676402836958276

Epoch: 6| Step: 12
Training loss: 6.699850211675386
Validation loss: 5.672279472983892

Epoch: 6| Step: 13
Training loss: 7.7935825651120645
Validation loss: 5.666572672566857

Epoch: 2| Step: 0
Training loss: 5.520896057156463
Validation loss: 5.657444200285206

Epoch: 6| Step: 1
Training loss: 6.262066294257962
Validation loss: 5.652018471982985

Epoch: 6| Step: 2
Training loss: 6.3366924546366015
Validation loss: 5.645828384501986

Epoch: 6| Step: 3
Training loss: 6.02552895657659
Validation loss: 5.640214117153511

Epoch: 6| Step: 4
Training loss: 5.434345952944043
Validation loss: 5.633665167223031

Epoch: 6| Step: 5
Training loss: 4.645185394036572
Validation loss: 5.62922954081392

Epoch: 6| Step: 6
Training loss: 5.638776566128483
Validation loss: 5.623708657416752

Epoch: 6| Step: 7
Training loss: 6.626144598205515
Validation loss: 5.619226325086796

Epoch: 6| Step: 8
Training loss: 5.922657937503882
Validation loss: 5.612919794561957

Epoch: 6| Step: 9
Training loss: 5.203823833102146
Validation loss: 5.606832387271662

Epoch: 6| Step: 10
Training loss: 5.941367084642444
Validation loss: 5.601890370960005

Epoch: 6| Step: 11
Training loss: 5.172903091263315
Validation loss: 5.593965868239937

Epoch: 6| Step: 12
Training loss: 4.9532270451091165
Validation loss: 5.587059490601706

Epoch: 6| Step: 13
Training loss: 4.916760503013559
Validation loss: 5.5844208648902764

Epoch: 3| Step: 0
Training loss: 5.693457197916039
Validation loss: 5.577228216111613

Epoch: 6| Step: 1
Training loss: 5.832297133193191
Validation loss: 5.57229443092265

Epoch: 6| Step: 2
Training loss: 4.13967850141684
Validation loss: 5.566889948889673

Epoch: 6| Step: 3
Training loss: 5.651821700256842
Validation loss: 5.562440498331536

Epoch: 6| Step: 4
Training loss: 6.331560723379952
Validation loss: 5.554005095318553

Epoch: 6| Step: 5
Training loss: 4.627012485108887
Validation loss: 5.550229294376919

Epoch: 6| Step: 6
Training loss: 5.590571859244715
Validation loss: 5.541881664743051

Epoch: 6| Step: 7
Training loss: 5.846495610645147
Validation loss: 5.540079053942089

Epoch: 6| Step: 8
Training loss: 5.549082142306988
Validation loss: 5.530078494826581

Epoch: 6| Step: 9
Training loss: 4.477469094498308
Validation loss: 5.52772508934386

Epoch: 6| Step: 10
Training loss: 6.709339453394716
Validation loss: 5.5239264483902435

Epoch: 6| Step: 11
Training loss: 5.794262567292793
Validation loss: 5.5157063424248465

Epoch: 6| Step: 12
Training loss: 5.725614503089453
Validation loss: 5.510812354356333

Epoch: 6| Step: 13
Training loss: 5.7284660142115325
Validation loss: 5.506067762275716

Epoch: 4| Step: 0
Training loss: 5.713931862910545
Validation loss: 5.497159185074736

Epoch: 6| Step: 1
Training loss: 5.530073310131583
Validation loss: 5.490855022652511

Epoch: 6| Step: 2
Training loss: 4.037548733349224
Validation loss: 5.4840971552017805

Epoch: 6| Step: 3
Training loss: 4.86062655016872
Validation loss: 5.481990881598711

Epoch: 6| Step: 4
Training loss: 4.783273505568874
Validation loss: 5.472926633751994

Epoch: 6| Step: 5
Training loss: 4.333178933156124
Validation loss: 5.469250804747192

Epoch: 6| Step: 6
Training loss: 6.0754093487503225
Validation loss: 5.462548706110875

Epoch: 6| Step: 7
Training loss: 4.975522589911999
Validation loss: 5.456564910412167

Epoch: 6| Step: 8
Training loss: 6.4736236051988
Validation loss: 5.449406573300087

Epoch: 6| Step: 9
Training loss: 6.601770232955721
Validation loss: 5.440645706595269

Epoch: 6| Step: 10
Training loss: 5.209075549328622
Validation loss: 5.43783224710521

Epoch: 6| Step: 11
Training loss: 5.616282680678742
Validation loss: 5.429843572493888

Epoch: 6| Step: 12
Training loss: 5.656684142254143
Validation loss: 5.4233499149600695

Epoch: 6| Step: 13
Training loss: 7.053620824934054
Validation loss: 5.415290142045214

Epoch: 5| Step: 0
Training loss: 4.944839623669163
Validation loss: 5.408122623040754

Epoch: 6| Step: 1
Training loss: 4.744595916875189
Validation loss: 5.401813481797256

Epoch: 6| Step: 2
Training loss: 6.003401110215502
Validation loss: 5.397878788986586

Epoch: 6| Step: 3
Training loss: 6.059671587716331
Validation loss: 5.389144323635583

Epoch: 6| Step: 4
Training loss: 5.327478990517858
Validation loss: 5.381426995002456

Epoch: 6| Step: 5
Training loss: 4.873770534318517
Validation loss: 5.373057184810243

Epoch: 6| Step: 6
Training loss: 5.853932368068653
Validation loss: 5.364134101763412

Epoch: 6| Step: 7
Training loss: 6.724417349948549
Validation loss: 5.361193699411085

Epoch: 6| Step: 8
Training loss: 5.37096679537461
Validation loss: 5.349838667346002

Epoch: 6| Step: 9
Training loss: 6.0457715350970584
Validation loss: 5.344250625641592

Epoch: 6| Step: 10
Training loss: 4.963596190252847
Validation loss: 5.34058108324707

Epoch: 6| Step: 11
Training loss: 4.632847906430891
Validation loss: 5.3302539285153845

Epoch: 6| Step: 12
Training loss: 5.310832760556079
Validation loss: 5.322591228356504

Epoch: 6| Step: 13
Training loss: 3.357566311111115
Validation loss: 5.317397167256079

Epoch: 6| Step: 0
Training loss: 5.7107591509856555
Validation loss: 5.306304042085897

Epoch: 6| Step: 1
Training loss: 3.6580586972624136
Validation loss: 5.298214494909924

Epoch: 6| Step: 2
Training loss: 4.836143969933567
Validation loss: 5.289671697777012

Epoch: 6| Step: 3
Training loss: 6.683329199633505
Validation loss: 5.281803638719479

Epoch: 6| Step: 4
Training loss: 5.680316790490829
Validation loss: 5.274411977335587

Epoch: 6| Step: 5
Training loss: 4.835653121055907
Validation loss: 5.270005257350867

Epoch: 6| Step: 6
Training loss: 5.065822876554803
Validation loss: 5.259296809343307

Epoch: 6| Step: 7
Training loss: 5.523654010851132
Validation loss: 5.250867380349049

Epoch: 6| Step: 8
Training loss: 5.932530300932679
Validation loss: 5.241038027690211

Epoch: 6| Step: 9
Training loss: 4.913465308940634
Validation loss: 5.23580531935957

Epoch: 6| Step: 10
Training loss: 4.549649679929544
Validation loss: 5.225520991293456

Epoch: 6| Step: 11
Training loss: 5.7209205052160925
Validation loss: 5.215890139240726

Epoch: 6| Step: 12
Training loss: 5.245396003138021
Validation loss: 5.206384242759037

Epoch: 6| Step: 13
Training loss: 5.221443440600842
Validation loss: 5.2005666907543215

Epoch: 7| Step: 0
Training loss: 5.13309342125088
Validation loss: 5.18796943708034

Epoch: 6| Step: 1
Training loss: 6.006673598262557
Validation loss: 5.177831868722386

Epoch: 6| Step: 2
Training loss: 4.717306560518733
Validation loss: 5.168969060470138

Epoch: 6| Step: 3
Training loss: 3.7310058207143153
Validation loss: 5.163177780323562

Epoch: 6| Step: 4
Training loss: 4.850572862908944
Validation loss: 5.1492031794760775

Epoch: 6| Step: 5
Training loss: 6.231243216951862
Validation loss: 5.141988083393636

Epoch: 6| Step: 6
Training loss: 5.334744366113734
Validation loss: 5.129731813892029

Epoch: 6| Step: 7
Training loss: 4.782481315484566
Validation loss: 5.1208362768208096

Epoch: 6| Step: 8
Training loss: 4.516464208215515
Validation loss: 5.1089148403113445

Epoch: 6| Step: 9
Training loss: 3.7346061092353096
Validation loss: 5.102022301778209

Epoch: 6| Step: 10
Training loss: 6.080253483357006
Validation loss: 5.086962974350878

Epoch: 6| Step: 11
Training loss: 5.6702633083771445
Validation loss: 5.080217506287557

Epoch: 6| Step: 12
Training loss: 5.5206049841914515
Validation loss: 5.069864935617408

Epoch: 6| Step: 13
Training loss: 5.600488280398579
Validation loss: 5.060381305346283

Epoch: 8| Step: 0
Training loss: 5.066569258774134
Validation loss: 5.048839190299536

Epoch: 6| Step: 1
Training loss: 5.632942695541548
Validation loss: 5.039572639967606

Epoch: 6| Step: 2
Training loss: 4.829524655220816
Validation loss: 5.025036807643

Epoch: 6| Step: 3
Training loss: 5.021910914522323
Validation loss: 5.01133923004794

Epoch: 6| Step: 4
Training loss: 5.357806896652892
Validation loss: 5.002855722088698

Epoch: 6| Step: 5
Training loss: 5.4201963612927075
Validation loss: 4.989692245789199

Epoch: 6| Step: 6
Training loss: 5.158430713397899
Validation loss: 4.981870328677487

Epoch: 6| Step: 7
Training loss: 4.593876635823606
Validation loss: 4.9708290716419

Epoch: 6| Step: 8
Training loss: 4.274828473492615
Validation loss: 4.958036535694916

Epoch: 6| Step: 9
Training loss: 4.91117815477304
Validation loss: 4.943469919163676

Epoch: 6| Step: 10
Training loss: 4.7308983454163425
Validation loss: 4.9334547804196065

Epoch: 6| Step: 11
Training loss: 4.495315656770268
Validation loss: 4.926474522449311

Epoch: 6| Step: 12
Training loss: 5.5444170596750935
Validation loss: 4.909187456988513

Epoch: 6| Step: 13
Training loss: 5.432824766700902
Validation loss: 4.901356476551751

Epoch: 9| Step: 0
Training loss: 5.630335671969544
Validation loss: 4.885765922571229

Epoch: 6| Step: 1
Training loss: 5.17807474244338
Validation loss: 4.872574450223032

Epoch: 6| Step: 2
Training loss: 4.69114441661094
Validation loss: 4.861215681288314

Epoch: 6| Step: 3
Training loss: 3.7967985169042495
Validation loss: 4.846906078225207

Epoch: 6| Step: 4
Training loss: 4.5295964874356365
Validation loss: 4.83868774771421

Epoch: 6| Step: 5
Training loss: 5.311045009852552
Validation loss: 4.8224895129289145

Epoch: 6| Step: 6
Training loss: 4.440023859664455
Validation loss: 4.812783143315068

Epoch: 6| Step: 7
Training loss: 5.344440259467002
Validation loss: 4.799232443673888

Epoch: 6| Step: 8
Training loss: 4.797843313491534
Validation loss: 4.785031573253715

Epoch: 6| Step: 9
Training loss: 4.323529278960117
Validation loss: 4.7731237284037835

Epoch: 6| Step: 10
Training loss: 5.21149749263325
Validation loss: 4.760285432665813

Epoch: 6| Step: 11
Training loss: 4.647736414764496
Validation loss: 4.745191191916491

Epoch: 6| Step: 12
Training loss: 4.780414383615415
Validation loss: 4.733301320993915

Epoch: 6| Step: 13
Training loss: 5.4084901964258
Validation loss: 4.720750588494148

Epoch: 10| Step: 0
Training loss: 5.09520246708038
Validation loss: 4.705237957857158

Epoch: 6| Step: 1
Training loss: 4.758007728317033
Validation loss: 4.688919685886135

Epoch: 6| Step: 2
Training loss: 3.703982225824475
Validation loss: 4.678421101426429

Epoch: 6| Step: 3
Training loss: 4.818805477550297
Validation loss: 4.663504150067915

Epoch: 6| Step: 4
Training loss: 5.0833576180967155
Validation loss: 4.650597800276343

Epoch: 6| Step: 5
Training loss: 4.606125749959339
Validation loss: 4.6340969720294485

Epoch: 6| Step: 6
Training loss: 4.499785524131521
Validation loss: 4.625110847721228

Epoch: 6| Step: 7
Training loss: 5.8724122537071795
Validation loss: 4.60028344645825

Epoch: 6| Step: 8
Training loss: 4.251722099115306
Validation loss: 4.588007657498123

Epoch: 6| Step: 9
Training loss: 4.625663091190616
Validation loss: 4.57442373941881

Epoch: 6| Step: 10
Training loss: 4.426431094722714
Validation loss: 4.55835560707361

Epoch: 6| Step: 11
Training loss: 4.79347869224663
Validation loss: 4.543847188945358

Epoch: 6| Step: 12
Training loss: 4.520568886799839
Validation loss: 4.5286012097860535

Epoch: 6| Step: 13
Training loss: 3.8807369955855355
Validation loss: 4.514263885966865

Epoch: 11| Step: 0
Training loss: 4.855392737802542
Validation loss: 4.4990414495240305

Epoch: 6| Step: 1
Training loss: 3.960829392863333
Validation loss: 4.4852007016796875

Epoch: 6| Step: 2
Training loss: 5.057891632017284
Validation loss: 4.465856265618453

Epoch: 6| Step: 3
Training loss: 3.9253640024301832
Validation loss: 4.45250847806488

Epoch: 6| Step: 4
Training loss: 4.877907106272808
Validation loss: 4.4333671864294875

Epoch: 6| Step: 5
Training loss: 4.625118357200736
Validation loss: 4.419254201308006

Epoch: 6| Step: 6
Training loss: 4.629816794674071
Validation loss: 4.399709433808608

Epoch: 6| Step: 7
Training loss: 4.33172325642339
Validation loss: 4.3821425981122895

Epoch: 6| Step: 8
Training loss: 4.888837688832991
Validation loss: 4.375825011345976

Epoch: 6| Step: 9
Training loss: 4.269645389242288
Validation loss: 4.355254144879884

Epoch: 6| Step: 10
Training loss: 4.154115745566495
Validation loss: 4.334861111365265

Epoch: 6| Step: 11
Training loss: 3.965449004179544
Validation loss: 4.316942047984445

Epoch: 6| Step: 12
Training loss: 4.7730003443953
Validation loss: 4.302235613027313

Epoch: 6| Step: 13
Training loss: 3.898975159410633
Validation loss: 4.283944895182788

Epoch: 12| Step: 0
Training loss: 4.1894367351078
Validation loss: 4.266393275660628

Epoch: 6| Step: 1
Training loss: 3.9724601164556774
Validation loss: 4.252089410879118

Epoch: 6| Step: 2
Training loss: 4.471988811417506
Validation loss: 4.2312186356210875

Epoch: 6| Step: 3
Training loss: 4.439073310578397
Validation loss: 4.222757328686724

Epoch: 6| Step: 4
Training loss: 4.03637936750716
Validation loss: 4.187289391089855

Epoch: 6| Step: 5
Training loss: 4.743723889104379
Validation loss: 4.171543082478477

Epoch: 6| Step: 6
Training loss: 3.570095865367629
Validation loss: 4.1641563228417375

Epoch: 6| Step: 7
Training loss: 3.3836970417231527
Validation loss: 4.13540426033217

Epoch: 6| Step: 8
Training loss: 3.7168664088838677
Validation loss: 4.115137326116362

Epoch: 6| Step: 9
Training loss: 4.99011473988199
Validation loss: 4.098821895293696

Epoch: 6| Step: 10
Training loss: 4.317565596567592
Validation loss: 4.087105710953288

Epoch: 6| Step: 11
Training loss: 4.123648682246081
Validation loss: 4.06217437776984

Epoch: 6| Step: 12
Training loss: 4.820194385138681
Validation loss: 4.034244855450885

Epoch: 6| Step: 13
Training loss: 4.418174678141672
Validation loss: 4.024012942828344

Epoch: 13| Step: 0
Training loss: 3.5518570247089913
Validation loss: 4.009064412383999

Epoch: 6| Step: 1
Training loss: 4.2148919443056725
Validation loss: 3.981768184127586

Epoch: 6| Step: 2
Training loss: 4.358459595309484
Validation loss: 3.9611876105518835

Epoch: 6| Step: 3
Training loss: 4.243903780638341
Validation loss: 3.9404845950925242

Epoch: 6| Step: 4
Training loss: 3.9733249997898583
Validation loss: 3.9182877485819527

Epoch: 6| Step: 5
Training loss: 4.022229889311488
Validation loss: 3.907375257952583

Epoch: 6| Step: 6
Training loss: 4.7051800771825745
Validation loss: 3.876630792546421

Epoch: 6| Step: 7
Training loss: 2.79977113605856
Validation loss: 3.8552209868209872

Epoch: 6| Step: 8
Training loss: 3.8289830083183607
Validation loss: 3.8380876665222825

Epoch: 6| Step: 9
Training loss: 3.4934120847352683
Validation loss: 3.8065367940809764

Epoch: 6| Step: 10
Training loss: 4.536508179604997
Validation loss: 3.7939534346327446

Epoch: 6| Step: 11
Training loss: 3.5956266064559874
Validation loss: 3.7721719296138114

Epoch: 6| Step: 12
Training loss: 4.4147404242963155
Validation loss: 3.7467025629441397

Epoch: 6| Step: 13
Training loss: 3.5190910377358184
Validation loss: 3.7305449148300562

Epoch: 14| Step: 0
Training loss: 4.29265639858338
Validation loss: 3.7030738241005787

Epoch: 6| Step: 1
Training loss: 4.153763794693841
Validation loss: 3.678814360836322

Epoch: 6| Step: 2
Training loss: 3.600644340072522
Validation loss: 3.662880229409512

Epoch: 6| Step: 3
Training loss: 4.551149436889478
Validation loss: 3.640211681578617

Epoch: 6| Step: 4
Training loss: 3.3007777829123803
Validation loss: 3.626055009844724

Epoch: 6| Step: 5
Training loss: 3.4043580846924777
Validation loss: 3.5998194264685726

Epoch: 6| Step: 6
Training loss: 4.005120576145964
Validation loss: 3.5771472764918464

Epoch: 6| Step: 7
Training loss: 3.736597142203719
Validation loss: 3.5544199838710355

Epoch: 6| Step: 8
Training loss: 3.7792853934337867
Validation loss: 3.5463539974321936

Epoch: 6| Step: 9
Training loss: 3.397458411180435
Validation loss: 3.5077036853905397

Epoch: 6| Step: 10
Training loss: 3.511695938121125
Validation loss: 3.501740632212801

Epoch: 6| Step: 11
Training loss: 2.5015300836791874
Validation loss: 3.4788462315860014

Epoch: 6| Step: 12
Training loss: 4.219301992967715
Validation loss: 3.466185000086237

Epoch: 6| Step: 13
Training loss: 2.353668689103287
Validation loss: 3.42726634514654

Epoch: 15| Step: 0
Training loss: 4.8560302606107975
Validation loss: 3.4100138038449925

Epoch: 6| Step: 1
Training loss: 4.114234053196587
Validation loss: 3.4011089133186987

Epoch: 6| Step: 2
Training loss: 4.21210708370463
Validation loss: 3.376467570658779

Epoch: 6| Step: 3
Training loss: 2.6636076508127586
Validation loss: 3.3513986386980195

Epoch: 6| Step: 4
Training loss: 3.735204628441795
Validation loss: 3.3311727771775073

Epoch: 6| Step: 5
Training loss: 3.816199586986997
Validation loss: 3.309034469929372

Epoch: 6| Step: 6
Training loss: 1.850081998708982
Validation loss: 3.2850933749076385

Epoch: 6| Step: 7
Training loss: 2.7738487261152316
Validation loss: 3.269602730943983

Epoch: 6| Step: 8
Training loss: 3.7833843670286473
Validation loss: 3.255911295275472

Epoch: 6| Step: 9
Training loss: 2.693197553944975
Validation loss: 3.225449754928794

Epoch: 6| Step: 10
Training loss: 3.1714895230282147
Validation loss: 3.217877279344479

Epoch: 6| Step: 11
Training loss: 3.446838732863232
Validation loss: 3.2011920337922826

Epoch: 6| Step: 12
Training loss: 2.9603673542022064
Validation loss: 3.18602288733772

Epoch: 6| Step: 13
Training loss: 3.4375407823397564
Validation loss: 3.1572664456388595

Epoch: 16| Step: 0
Training loss: 3.5487188848331983
Validation loss: 3.1494377532294338

Epoch: 6| Step: 1
Training loss: 2.6598703283956144
Validation loss: 3.1283462492556606

Epoch: 6| Step: 2
Training loss: 2.3219660252098877
Validation loss: 3.1131804807845413

Epoch: 6| Step: 3
Training loss: 3.3841282353915343
Validation loss: 3.110666807360457

Epoch: 6| Step: 4
Training loss: 3.024865889926126
Validation loss: 3.0890515911262737

Epoch: 6| Step: 5
Training loss: 3.5202343372890263
Validation loss: 3.0649775816630465

Epoch: 6| Step: 6
Training loss: 3.6729599668677158
Validation loss: 3.0620726504240605

Epoch: 6| Step: 7
Training loss: 3.202824871609924
Validation loss: 3.041255780454237

Epoch: 6| Step: 8
Training loss: 2.8307149419394975
Validation loss: 3.0331738135812936

Epoch: 6| Step: 9
Training loss: 3.9662145490531766
Validation loss: 3.0126921639986337

Epoch: 6| Step: 10
Training loss: 3.7806829862834888
Validation loss: 3.0043706213481807

Epoch: 6| Step: 11
Training loss: 3.170550591339948
Validation loss: 2.9937318962879327

Epoch: 6| Step: 12
Training loss: 2.9037535415082627
Validation loss: 2.9750444212613436

Epoch: 6| Step: 13
Training loss: 3.4602885100632834
Validation loss: 2.9577237485748373

Epoch: 17| Step: 0
Training loss: 2.921489832985609
Validation loss: 2.943829909642749

Epoch: 6| Step: 1
Training loss: 2.988953119680526
Validation loss: 2.935681294322894

Epoch: 6| Step: 2
Training loss: 3.5678018302453887
Validation loss: 2.918625336252814

Epoch: 6| Step: 3
Training loss: 2.7715673024282936
Validation loss: 2.9130781579102574

Epoch: 6| Step: 4
Training loss: 3.1459610431002782
Validation loss: 2.9008087443508668

Epoch: 6| Step: 5
Training loss: 3.2991400436274025
Validation loss: 2.8990515066940676

Epoch: 6| Step: 6
Training loss: 3.299570726159497
Validation loss: 2.883754887997246

Epoch: 6| Step: 7
Training loss: 2.313515002219961
Validation loss: 2.874330611234203

Epoch: 6| Step: 8
Training loss: 2.859583112303588
Validation loss: 2.8626337765177405

Epoch: 6| Step: 9
Training loss: 3.7401372274426694
Validation loss: 2.865848587744049

Epoch: 6| Step: 10
Training loss: 2.8361970977086166
Validation loss: 2.8548850510309087

Epoch: 6| Step: 11
Training loss: 3.6100752510406577
Validation loss: 2.8339977088681767

Epoch: 6| Step: 12
Training loss: 3.074167874023112
Validation loss: 2.827995524402587

Epoch: 6| Step: 13
Training loss: 2.839501025732211
Validation loss: 2.8192837946523017

Epoch: 18| Step: 0
Training loss: 3.3609737406700506
Validation loss: 2.810807064720415

Epoch: 6| Step: 1
Training loss: 3.097666409681479
Validation loss: 2.793711404918542

Epoch: 6| Step: 2
Training loss: 2.969916506020729
Validation loss: 2.7928717474396145

Epoch: 6| Step: 3
Training loss: 3.240315312713512
Validation loss: 2.778316578207529

Epoch: 6| Step: 4
Training loss: 2.403107014800831
Validation loss: 2.7732443696480953

Epoch: 6| Step: 5
Training loss: 2.2115700831114142
Validation loss: 2.7661260539488213

Epoch: 6| Step: 6
Training loss: 3.329098697839043
Validation loss: 2.776505960588495

Epoch: 6| Step: 7
Training loss: 3.0291053027654384
Validation loss: 2.770423746626972

Epoch: 6| Step: 8
Training loss: 3.054423991591566
Validation loss: 2.749721096248331

Epoch: 6| Step: 9
Training loss: 2.8536827252579338
Validation loss: 2.748196873976585

Epoch: 6| Step: 10
Training loss: 2.965681397491683
Validation loss: 2.7499358858631355

Epoch: 6| Step: 11
Training loss: 3.3261040654329137
Validation loss: 2.745105055293316

Epoch: 6| Step: 12
Training loss: 2.8584986943790267
Validation loss: 2.746912632712796

Epoch: 6| Step: 13
Training loss: 3.897326355027294
Validation loss: 2.7306362016662655

Epoch: 19| Step: 0
Training loss: 3.0824503450501366
Validation loss: 2.7373472967451864

Epoch: 6| Step: 1
Training loss: 3.6475753255574084
Validation loss: 2.7302815529547497

Epoch: 6| Step: 2
Training loss: 3.9487224685853946
Validation loss: 2.735553892582778

Epoch: 6| Step: 3
Training loss: 2.775376536624165
Validation loss: 2.706733587691403

Epoch: 6| Step: 4
Training loss: 2.7952622180422977
Validation loss: 2.729724491364458

Epoch: 6| Step: 5
Training loss: 3.1586403434990946
Validation loss: 2.7278033278899474

Epoch: 6| Step: 6
Training loss: 3.0116275521211637
Validation loss: 2.7130255484767054

Epoch: 6| Step: 7
Training loss: 3.0018851397230115
Validation loss: 2.70805677054149

Epoch: 6| Step: 8
Training loss: 2.4255946973732634
Validation loss: 2.7155661048574267

Epoch: 6| Step: 9
Training loss: 2.7934149965838673
Validation loss: 2.7038410316510695

Epoch: 6| Step: 10
Training loss: 3.0383199456345964
Validation loss: 2.7007663244320024

Epoch: 6| Step: 11
Training loss: 1.7301073235093236
Validation loss: 2.7092949257422183

Epoch: 6| Step: 12
Training loss: 2.864913662446728
Validation loss: 2.6945009012808825

Epoch: 6| Step: 13
Training loss: 3.2282320372274422
Validation loss: 2.703477347040842

Epoch: 20| Step: 0
Training loss: 2.564326310054646
Validation loss: 2.6941716601535264

Epoch: 6| Step: 1
Training loss: 3.1603017049729725
Validation loss: 2.6953621437526554

Epoch: 6| Step: 2
Training loss: 3.368043441138924
Validation loss: 2.701024271227919

Epoch: 6| Step: 3
Training loss: 2.4536488939424226
Validation loss: 2.69548162209431

Epoch: 6| Step: 4
Training loss: 3.0526931379172573
Validation loss: 2.6859716050530342

Epoch: 6| Step: 5
Training loss: 3.3087860015536132
Validation loss: 2.683939382506018

Epoch: 6| Step: 6
Training loss: 3.3194555994446695
Validation loss: 2.702230251942158

Epoch: 6| Step: 7
Training loss: 3.3965203150053647
Validation loss: 2.6866371666082003

Epoch: 6| Step: 8
Training loss: 2.6444313560112076
Validation loss: 2.6765649203486417

Epoch: 6| Step: 9
Training loss: 2.835266201970312
Validation loss: 2.685366720382378

Epoch: 6| Step: 10
Training loss: 2.878093879191818
Validation loss: 2.6959305306583192

Epoch: 6| Step: 11
Training loss: 2.963543955037195
Validation loss: 2.678944752914763

Epoch: 6| Step: 12
Training loss: 2.737568064501023
Validation loss: 2.6758480721466773

Epoch: 6| Step: 13
Training loss: 2.781334436399339
Validation loss: 2.683091077344497

Epoch: 21| Step: 0
Training loss: 2.40510660724339
Validation loss: 2.6899235894535196

Epoch: 6| Step: 1
Training loss: 2.7664672086431463
Validation loss: 2.6826973623924117

Epoch: 6| Step: 2
Training loss: 2.7177486987398143
Validation loss: 2.6809363326292392

Epoch: 6| Step: 3
Training loss: 3.0239686326917985
Validation loss: 2.673664331743245

Epoch: 6| Step: 4
Training loss: 3.167138382427782
Validation loss: 2.6832972281514866

Epoch: 6| Step: 5
Training loss: 3.015614563918956
Validation loss: 2.6989684033567047

Epoch: 6| Step: 6
Training loss: 2.774711037102153
Validation loss: 2.6879764887119184

Epoch: 6| Step: 7
Training loss: 2.918436403602127
Validation loss: 2.6781662339270893

Epoch: 6| Step: 8
Training loss: 2.4698881591928203
Validation loss: 2.6763743974970837

Epoch: 6| Step: 9
Training loss: 3.0520113957143593
Validation loss: 2.69572053911615

Epoch: 6| Step: 10
Training loss: 2.9451039693254835
Validation loss: 2.670834122508992

Epoch: 6| Step: 11
Training loss: 4.044073011182586
Validation loss: 2.6705436793538744

Epoch: 6| Step: 12
Training loss: 3.3275555763790936
Validation loss: 2.672166577313694

Epoch: 6| Step: 13
Training loss: 2.4668227773531206
Validation loss: 2.6946818461202833

Epoch: 22| Step: 0
Training loss: 3.133516836542063
Validation loss: 2.670792891182576

Epoch: 6| Step: 1
Training loss: 2.739430750863331
Validation loss: 2.6505441067976916

Epoch: 6| Step: 2
Training loss: 3.0397463619932936
Validation loss: 2.661254002909646

Epoch: 6| Step: 3
Training loss: 2.6656738956524006
Validation loss: 2.6756169238080503

Epoch: 6| Step: 4
Training loss: 3.352580878343937
Validation loss: 2.675261433487853

Epoch: 6| Step: 5
Training loss: 2.5926708136470027
Validation loss: 2.669350992595362

Epoch: 6| Step: 6
Training loss: 3.0639697849188243
Validation loss: 2.681847009182021

Epoch: 6| Step: 7
Training loss: 3.747418214237624
Validation loss: 2.676345810428022

Epoch: 6| Step: 8
Training loss: 3.6490626973698244
Validation loss: 2.664928616055213

Epoch: 6| Step: 9
Training loss: 2.4569411996614305
Validation loss: 2.673262458430797

Epoch: 6| Step: 10
Training loss: 2.119285529320001
Validation loss: 2.659129837762707

Epoch: 6| Step: 11
Training loss: 3.219740335645018
Validation loss: 2.6693196238758987

Epoch: 6| Step: 12
Training loss: 2.58293747688973
Validation loss: 2.662388653766461

Epoch: 6| Step: 13
Training loss: 2.755333842908417
Validation loss: 2.671015599010153

Epoch: 23| Step: 0
Training loss: 3.8163720151835783
Validation loss: 2.6682164152271928

Epoch: 6| Step: 1
Training loss: 2.916665558587727
Validation loss: 2.665378259949075

Epoch: 6| Step: 2
Training loss: 3.0263336268407794
Validation loss: 2.677996180106652

Epoch: 6| Step: 3
Training loss: 2.856777992112061
Validation loss: 2.6827905844208253

Epoch: 6| Step: 4
Training loss: 2.676058522358562
Validation loss: 2.670217047016129

Epoch: 6| Step: 5
Training loss: 3.120043371339265
Validation loss: 2.661936607626312

Epoch: 6| Step: 6
Training loss: 2.8549015927432677
Validation loss: 2.6662060198102107

Epoch: 6| Step: 7
Training loss: 2.9245971402258446
Validation loss: 2.6717102070964045

Epoch: 6| Step: 8
Training loss: 2.5055271085978985
Validation loss: 2.6763989430128774

Epoch: 6| Step: 9
Training loss: 2.647825457314886
Validation loss: 2.671282815065002

Epoch: 6| Step: 10
Training loss: 3.466154072228931
Validation loss: 2.6624783020660585

Epoch: 6| Step: 11
Training loss: 2.4404162055074776
Validation loss: 2.6606533683534783

Epoch: 6| Step: 12
Training loss: 3.449461637868363
Validation loss: 2.6605202223770825

Epoch: 6| Step: 13
Training loss: 2.0839692734633246
Validation loss: 2.6683935725228785

Epoch: 24| Step: 0
Training loss: 2.9157565922290143
Validation loss: 2.6682506523991822

Epoch: 6| Step: 1
Training loss: 2.4716314569573266
Validation loss: 2.6635449105489717

Epoch: 6| Step: 2
Training loss: 2.6704309141489566
Validation loss: 2.680145690409606

Epoch: 6| Step: 3
Training loss: 3.5423789411385775
Validation loss: 2.6819369314000867

Epoch: 6| Step: 4
Training loss: 2.7409025915095557
Validation loss: 2.6700369372640944

Epoch: 6| Step: 5
Training loss: 3.408401929418445
Validation loss: 2.6760989799389945

Epoch: 6| Step: 6
Training loss: 3.2703047080204595
Validation loss: 2.6778134333238075

Epoch: 6| Step: 7
Training loss: 3.162983877685444
Validation loss: 2.6765185063894292

Epoch: 6| Step: 8
Training loss: 3.301252595553087
Validation loss: 2.6752084220551584

Epoch: 6| Step: 9
Training loss: 2.495530137977833
Validation loss: 2.674528793895546

Epoch: 6| Step: 10
Training loss: 3.1565980624914856
Validation loss: 2.682176697454702

Epoch: 6| Step: 11
Training loss: 2.5019264428222043
Validation loss: 2.669621901497046

Epoch: 6| Step: 12
Training loss: 2.411790290762489
Validation loss: 2.6760615074576166

Epoch: 6| Step: 13
Training loss: 3.0437950804581586
Validation loss: 2.6661088697217505

Epoch: 25| Step: 0
Training loss: 2.5482982567052375
Validation loss: 2.6775813784798874

Epoch: 6| Step: 1
Training loss: 2.722128862177058
Validation loss: 2.666065810431857

Epoch: 6| Step: 2
Training loss: 2.687392831484242
Validation loss: 2.6592987226598392

Epoch: 6| Step: 3
Training loss: 3.524416091931045
Validation loss: 2.6729270937604683

Epoch: 6| Step: 4
Training loss: 2.9592238326169786
Validation loss: 2.665755618758631

Epoch: 6| Step: 5
Training loss: 2.356386831342804
Validation loss: 2.661947168669486

Epoch: 6| Step: 6
Training loss: 3.331562684576811
Validation loss: 2.662902741256899

Epoch: 6| Step: 7
Training loss: 2.968289952019144
Validation loss: 2.675363011761965

Epoch: 6| Step: 8
Training loss: 3.162559020204115
Validation loss: 2.683210893330593

Epoch: 6| Step: 9
Training loss: 3.4656688305600167
Validation loss: 2.681926751136611

Epoch: 6| Step: 10
Training loss: 2.4583100355520653
Validation loss: 2.675731462363201

Epoch: 6| Step: 11
Training loss: 3.698978468635061
Validation loss: 2.6663885362488853

Epoch: 6| Step: 12
Training loss: 2.6977809051957804
Validation loss: 2.665088893090675

Epoch: 6| Step: 13
Training loss: 1.9875419156434964
Validation loss: 2.6688944569495643

Epoch: 26| Step: 0
Training loss: 2.966657362791181
Validation loss: 2.664189036251794

Epoch: 6| Step: 1
Training loss: 3.402049002597796
Validation loss: 2.6685333051009787

Epoch: 6| Step: 2
Training loss: 3.641734465805215
Validation loss: 2.669126530350062

Epoch: 6| Step: 3
Training loss: 2.4522997202935564
Validation loss: 2.675446244656426

Epoch: 6| Step: 4
Training loss: 3.2765734088881646
Validation loss: 2.6466416023942645

Epoch: 6| Step: 5
Training loss: 2.7057868332113277
Validation loss: 2.6556521365996475

Epoch: 6| Step: 6
Training loss: 2.4939077532976253
Validation loss: 2.6601845176281107

Epoch: 6| Step: 7
Training loss: 3.1388154391657084
Validation loss: 2.654341759391581

Epoch: 6| Step: 8
Training loss: 2.7244121302371456
Validation loss: 2.65397650790129

Epoch: 6| Step: 9
Training loss: 2.821863059930053
Validation loss: 2.6601142855295516

Epoch: 6| Step: 10
Training loss: 2.743394200363197
Validation loss: 2.658130133332703

Epoch: 6| Step: 11
Training loss: 2.3992149261076454
Validation loss: 2.6570597775731

Epoch: 6| Step: 12
Training loss: 3.013291478949452
Validation loss: 2.6569385637431093

Epoch: 6| Step: 13
Training loss: 3.2972385874935477
Validation loss: 2.6580006697726324

Epoch: 27| Step: 0
Training loss: 2.718420600667562
Validation loss: 2.6612431626415636

Epoch: 6| Step: 1
Training loss: 2.8650266731977845
Validation loss: 2.672610554113228

Epoch: 6| Step: 2
Training loss: 3.68574637402225
Validation loss: 2.662260628916253

Epoch: 6| Step: 3
Training loss: 2.7112400204943987
Validation loss: 2.6480911129518523

Epoch: 6| Step: 4
Training loss: 3.4865308173746192
Validation loss: 2.676858463437632

Epoch: 6| Step: 5
Training loss: 1.6984350743140453
Validation loss: 2.6404364520321875

Epoch: 6| Step: 6
Training loss: 3.2846197354702453
Validation loss: 2.662104592683033

Epoch: 6| Step: 7
Training loss: 3.189930606194885
Validation loss: 2.656837080971451

Epoch: 6| Step: 8
Training loss: 3.186837220941528
Validation loss: 2.649537559600908

Epoch: 6| Step: 9
Training loss: 2.966500805565194
Validation loss: 2.6467055676439295

Epoch: 6| Step: 10
Training loss: 2.63741183743767
Validation loss: 2.648945880040723

Epoch: 6| Step: 11
Training loss: 2.7229340902723007
Validation loss: 2.662654358408722

Epoch: 6| Step: 12
Training loss: 2.41472362366388
Validation loss: 2.6664788105640618

Epoch: 6| Step: 13
Training loss: 2.9944236109033815
Validation loss: 2.650501298573196

Epoch: 28| Step: 0
Training loss: 2.3182651722383865
Validation loss: 2.667550018217109

Epoch: 6| Step: 1
Training loss: 3.34921673400263
Validation loss: 2.6607522823627736

Epoch: 6| Step: 2
Training loss: 2.871598595070512
Validation loss: 2.6771651211979806

Epoch: 6| Step: 3
Training loss: 3.19553708357491
Validation loss: 2.6502407288910588

Epoch: 6| Step: 4
Training loss: 2.9639107865924212
Validation loss: 2.650973154827424

Epoch: 6| Step: 5
Training loss: 2.8145208939620305
Validation loss: 2.6670083594856124

Epoch: 6| Step: 6
Training loss: 3.369219598259209
Validation loss: 2.6493063872994536

Epoch: 6| Step: 7
Training loss: 3.301668126970713
Validation loss: 2.6498840110456343

Epoch: 6| Step: 8
Training loss: 1.8753202164918221
Validation loss: 2.6506685725779024

Epoch: 6| Step: 9
Training loss: 2.1837686594890275
Validation loss: 2.6587010607759813

Epoch: 6| Step: 10
Training loss: 3.500190729666452
Validation loss: 2.6439022681208773

Epoch: 6| Step: 11
Training loss: 3.234501343254345
Validation loss: 2.6588746414841706

Epoch: 6| Step: 12
Training loss: 2.570334390935465
Validation loss: 2.646262390782602

Epoch: 6| Step: 13
Training loss: 3.1260659497919634
Validation loss: 2.6620428455161207

Epoch: 29| Step: 0
Training loss: 3.2862825583451722
Validation loss: 2.660371445322169

Epoch: 6| Step: 1
Training loss: 2.9442363361573767
Validation loss: 2.6597076312873433

Epoch: 6| Step: 2
Training loss: 2.4681551252793303
Validation loss: 2.662278349179047

Epoch: 6| Step: 3
Training loss: 3.647939251812194
Validation loss: 2.6540320597984155

Epoch: 6| Step: 4
Training loss: 2.443862924137497
Validation loss: 2.6539474786504664

Epoch: 6| Step: 5
Training loss: 3.260886519014818
Validation loss: 2.656789837003784

Epoch: 6| Step: 6
Training loss: 2.739299764328931
Validation loss: 2.6599682306342722

Epoch: 6| Step: 7
Training loss: 2.676847860664989
Validation loss: 2.665240596406225

Epoch: 6| Step: 8
Training loss: 3.0314406502142646
Validation loss: 2.6526585407716143

Epoch: 6| Step: 9
Training loss: 2.6973667443482032
Validation loss: 2.651775386623889

Epoch: 6| Step: 10
Training loss: 3.1232662732210237
Validation loss: 2.6538656923512685

Epoch: 6| Step: 11
Training loss: 2.7343246891297888
Validation loss: 2.6465772946293824

Epoch: 6| Step: 12
Training loss: 2.5447138879179136
Validation loss: 2.665414421624357

Epoch: 6| Step: 13
Training loss: 2.909687593345571
Validation loss: 2.660798791170227

Epoch: 30| Step: 0
Training loss: 3.4498785301607025
Validation loss: 2.651373074058051

Epoch: 6| Step: 1
Training loss: 2.7920281380216494
Validation loss: 2.646457142858741

Epoch: 6| Step: 2
Training loss: 3.265748820170546
Validation loss: 2.6461970894996427

Epoch: 6| Step: 3
Training loss: 2.5414166145101635
Validation loss: 2.6519928222391083

Epoch: 6| Step: 4
Training loss: 2.9257465355396337
Validation loss: 2.64590255831489

Epoch: 6| Step: 5
Training loss: 2.78121828211154
Validation loss: 2.657713884451798

Epoch: 6| Step: 6
Training loss: 2.387687923365356
Validation loss: 2.652824688693715

Epoch: 6| Step: 7
Training loss: 2.4456316949843875
Validation loss: 2.6436746123849817

Epoch: 6| Step: 8
Training loss: 3.0729596323576414
Validation loss: 2.6537996681637535

Epoch: 6| Step: 9
Training loss: 3.4202866024816156
Validation loss: 2.6426458012751657

Epoch: 6| Step: 10
Training loss: 2.86734116477698
Validation loss: 2.6371654554740016

Epoch: 6| Step: 11
Training loss: 2.936520352249377
Validation loss: 2.642575266999578

Epoch: 6| Step: 12
Training loss: 2.4905447493467237
Validation loss: 2.6455394015424165

Epoch: 6| Step: 13
Training loss: 3.3749066092674114
Validation loss: 2.655571743716194

Epoch: 31| Step: 0
Training loss: 2.960811884085082
Validation loss: 2.641932243096667

Epoch: 6| Step: 1
Training loss: 2.289232371409962
Validation loss: 2.6468305219346817

Epoch: 6| Step: 2
Training loss: 2.8999805712871205
Validation loss: 2.653229862953973

Epoch: 6| Step: 3
Training loss: 2.410047531767205
Validation loss: 2.6446579898418805

Epoch: 6| Step: 4
Training loss: 3.563206786598968
Validation loss: 2.6485411243504293

Epoch: 6| Step: 5
Training loss: 2.426138490672293
Validation loss: 2.6548667495827303

Epoch: 6| Step: 6
Training loss: 3.310598871503536
Validation loss: 2.644717287213211

Epoch: 6| Step: 7
Training loss: 3.4657312953047708
Validation loss: 2.6488742224484976

Epoch: 6| Step: 8
Training loss: 2.2605738665741035
Validation loss: 2.6423346056784345

Epoch: 6| Step: 9
Training loss: 3.470675097488127
Validation loss: 2.6348926302527977

Epoch: 6| Step: 10
Training loss: 2.648616638426761
Validation loss: 2.639449157096557

Epoch: 6| Step: 11
Training loss: 2.6501502516274758
Validation loss: 2.6340167852502225

Epoch: 6| Step: 12
Training loss: 2.8603445608483784
Validation loss: 2.638492103161252

Epoch: 6| Step: 13
Training loss: 3.3918831596044408
Validation loss: 2.642856001789358

Epoch: 32| Step: 0
Training loss: 2.375284980942737
Validation loss: 2.6442142099679056

Epoch: 6| Step: 1
Training loss: 3.0823986767577662
Validation loss: 2.6422090108822047

Epoch: 6| Step: 2
Training loss: 2.693379469167927
Validation loss: 2.6261168944331974

Epoch: 6| Step: 3
Training loss: 2.6515099811916394
Validation loss: 2.641309902363948

Epoch: 6| Step: 4
Training loss: 2.231584313401814
Validation loss: 2.643481102250391

Epoch: 6| Step: 5
Training loss: 2.752881188048306
Validation loss: 2.6374063260278158

Epoch: 6| Step: 6
Training loss: 3.464358462439246
Validation loss: 2.6530281269035876

Epoch: 6| Step: 7
Training loss: 2.900350510034035
Validation loss: 2.65087264191186

Epoch: 6| Step: 8
Training loss: 3.396417828829834
Validation loss: 2.6568068459324543

Epoch: 6| Step: 9
Training loss: 2.6850466508559863
Validation loss: 2.6460897372955032

Epoch: 6| Step: 10
Training loss: 2.6940760333313465
Validation loss: 2.644760733820406

Epoch: 6| Step: 11
Training loss: 3.368403168837857
Validation loss: 2.6459844318550405

Epoch: 6| Step: 12
Training loss: 3.025729471320621
Validation loss: 2.647975534682034

Epoch: 6| Step: 13
Training loss: 3.198420498369032
Validation loss: 2.6536209887970075

Epoch: 33| Step: 0
Training loss: 2.8734345527870286
Validation loss: 2.659269117169682

Epoch: 6| Step: 1
Training loss: 2.6712388736991173
Validation loss: 2.648344290375665

Epoch: 6| Step: 2
Training loss: 1.9572584435318223
Validation loss: 2.652292014547801

Epoch: 6| Step: 3
Training loss: 2.8409842990977134
Validation loss: 2.648606951497355

Epoch: 6| Step: 4
Training loss: 2.6750549667272647
Validation loss: 2.6329046850167783

Epoch: 6| Step: 5
Training loss: 2.9634094387561407
Validation loss: 2.6486867795273454

Epoch: 6| Step: 6
Training loss: 2.9863638916268878
Validation loss: 2.6361896750058498

Epoch: 6| Step: 7
Training loss: 3.0283787293321627
Validation loss: 2.6402047998834126

Epoch: 6| Step: 8
Training loss: 2.404525931856468
Validation loss: 2.639547775004055

Epoch: 6| Step: 9
Training loss: 2.7503734681816465
Validation loss: 2.6284758500681082

Epoch: 6| Step: 10
Training loss: 2.7582142999171726
Validation loss: 2.6459507243151417

Epoch: 6| Step: 11
Training loss: 3.0620946810564815
Validation loss: 2.6396616400322577

Epoch: 6| Step: 12
Training loss: 3.7870151927110376
Validation loss: 2.6402522386660685

Epoch: 6| Step: 13
Training loss: 3.8249386352403736
Validation loss: 2.6209620383731447

Epoch: 34| Step: 0
Training loss: 3.275878142059551
Validation loss: 2.6476519849312576

Epoch: 6| Step: 1
Training loss: 3.292437853389585
Validation loss: 2.657897187558518

Epoch: 6| Step: 2
Training loss: 2.6378503250394614
Validation loss: 2.649849035421224

Epoch: 6| Step: 3
Training loss: 3.3311362814325194
Validation loss: 2.6358498541499173

Epoch: 6| Step: 4
Training loss: 2.810264716389558
Validation loss: 2.6363253012994723

Epoch: 6| Step: 5
Training loss: 2.526298955549655
Validation loss: 2.6516293142475704

Epoch: 6| Step: 6
Training loss: 2.5890520131296464
Validation loss: 2.6365533485323733

Epoch: 6| Step: 7
Training loss: 2.357454238075289
Validation loss: 2.6444220647981993

Epoch: 6| Step: 8
Training loss: 2.83504520386949
Validation loss: 2.642174468283007

Epoch: 6| Step: 9
Training loss: 3.1994956692002954
Validation loss: 2.652317278779425

Epoch: 6| Step: 10
Training loss: 3.4010325378638173
Validation loss: 2.6555197149196705

Epoch: 6| Step: 11
Training loss: 2.309755088076338
Validation loss: 2.6459530700017675

Epoch: 6| Step: 12
Training loss: 2.8939539530583196
Validation loss: 2.649146765692001

Epoch: 6| Step: 13
Training loss: 3.0179421807091527
Validation loss: 2.6342386909694944

Epoch: 35| Step: 0
Training loss: 3.0410206426580313
Validation loss: 2.645848436403726

Epoch: 6| Step: 1
Training loss: 1.8157839785913905
Validation loss: 2.646247766070363

Epoch: 6| Step: 2
Training loss: 2.5108575605237946
Validation loss: 2.6314592588410264

Epoch: 6| Step: 3
Training loss: 2.8914824992373713
Validation loss: 2.6376384426419675

Epoch: 6| Step: 4
Training loss: 3.818451660289837
Validation loss: 2.6492651784880117

Epoch: 6| Step: 5
Training loss: 1.8588896045707506
Validation loss: 2.6454291512575434

Epoch: 6| Step: 6
Training loss: 3.1228547934793935
Validation loss: 2.646246133670004

Epoch: 6| Step: 7
Training loss: 3.8340066373764636
Validation loss: 2.648402813094939

Epoch: 6| Step: 8
Training loss: 2.886515567633818
Validation loss: 2.64333066981321

Epoch: 6| Step: 9
Training loss: 2.9513945176812646
Validation loss: 2.630190131239084

Epoch: 6| Step: 10
Training loss: 3.283199348878703
Validation loss: 2.63618423494945

Epoch: 6| Step: 11
Training loss: 2.6951420384559315
Validation loss: 2.6477700617942914

Epoch: 6| Step: 12
Training loss: 2.0227423103326854
Validation loss: 2.6389457779260783

Epoch: 6| Step: 13
Training loss: 2.6267231326480487
Validation loss: 2.634023036631897

Epoch: 36| Step: 0
Training loss: 3.2634820797315562
Validation loss: 2.641570885219904

Epoch: 6| Step: 1
Training loss: 3.7200757396329927
Validation loss: 2.6288355508953916

Epoch: 6| Step: 2
Training loss: 3.0948573741188294
Validation loss: 2.6367991819765093

Epoch: 6| Step: 3
Training loss: 2.918884052081732
Validation loss: 2.6326697574885336

Epoch: 6| Step: 4
Training loss: 2.7119838663032025
Validation loss: 2.6277554821714

Epoch: 6| Step: 5
Training loss: 2.0768579047593216
Validation loss: 2.627623601033595

Epoch: 6| Step: 6
Training loss: 2.934949538724787
Validation loss: 2.6426119492875433

Epoch: 6| Step: 7
Training loss: 3.0682981449770694
Validation loss: 2.6380689501768826

Epoch: 6| Step: 8
Training loss: 2.4601346114010467
Validation loss: 2.635772101017608

Epoch: 6| Step: 9
Training loss: 2.944377558526304
Validation loss: 2.6506672050026308

Epoch: 6| Step: 10
Training loss: 2.312210064832158
Validation loss: 2.6462899736844414

Epoch: 6| Step: 11
Training loss: 2.918725912578773
Validation loss: 2.6202508044598334

Epoch: 6| Step: 12
Training loss: 3.0932034096344236
Validation loss: 2.6390374621276127

Epoch: 6| Step: 13
Training loss: 2.37652749581927
Validation loss: 2.6447457818937243

Epoch: 37| Step: 0
Training loss: 2.276088571537988
Validation loss: 2.6178211417915724

Epoch: 6| Step: 1
Training loss: 2.805427644875177
Validation loss: 2.639024154472031

Epoch: 6| Step: 2
Training loss: 3.0960401285414667
Validation loss: 2.6315124326286616

Epoch: 6| Step: 3
Training loss: 2.407418499891152
Validation loss: 2.632714722360686

Epoch: 6| Step: 4
Training loss: 2.569460278253197
Validation loss: 2.6408840721511018

Epoch: 6| Step: 5
Training loss: 2.838739697375934
Validation loss: 2.651199269088127

Epoch: 6| Step: 6
Training loss: 2.37131957937904
Validation loss: 2.6372786515294515

Epoch: 6| Step: 7
Training loss: 3.161217133037057
Validation loss: 2.6428176272582546

Epoch: 6| Step: 8
Training loss: 4.2430079669576415
Validation loss: 2.6434429210579338

Epoch: 6| Step: 9
Training loss: 2.619013271890974
Validation loss: 2.628535511518513

Epoch: 6| Step: 10
Training loss: 3.04615376078999
Validation loss: 2.6406522563652115

Epoch: 6| Step: 11
Training loss: 3.1291107606190103
Validation loss: 2.6387734015653628

Epoch: 6| Step: 12
Training loss: 2.546836057025891
Validation loss: 2.6413130024406857

Epoch: 6| Step: 13
Training loss: 2.4382165686948634
Validation loss: 2.6386374774966526

Epoch: 38| Step: 0
Training loss: 3.125467646893787
Validation loss: 2.6363639142494084

Epoch: 6| Step: 1
Training loss: 3.1619121261440886
Validation loss: 2.621009637641358

Epoch: 6| Step: 2
Training loss: 2.618750626375037
Validation loss: 2.630999070376682

Epoch: 6| Step: 3
Training loss: 2.84587571059958
Validation loss: 2.643255649694437

Epoch: 6| Step: 4
Training loss: 2.829620808784949
Validation loss: 2.635924409101151

Epoch: 6| Step: 5
Training loss: 2.312342045518706
Validation loss: 2.6193981851686035

Epoch: 6| Step: 6
Training loss: 2.5770340894487895
Validation loss: 2.63219834548389

Epoch: 6| Step: 7
Training loss: 2.5630540946523657
Validation loss: 2.6480345602652418

Epoch: 6| Step: 8
Training loss: 3.9204798188733063
Validation loss: 2.653195434850548

Epoch: 6| Step: 9
Training loss: 2.682715570723915
Validation loss: 2.6193771799330343

Epoch: 6| Step: 10
Training loss: 2.842256594044021
Validation loss: 2.630111400792249

Epoch: 6| Step: 11
Training loss: 3.2452188683099426
Validation loss: 2.6273232017546535

Epoch: 6| Step: 12
Training loss: 2.58374465211002
Validation loss: 2.628221104988184

Epoch: 6| Step: 13
Training loss: 2.2796704820464444
Validation loss: 2.636763219971095

Epoch: 39| Step: 0
Training loss: 2.9821449455991402
Validation loss: 2.632831278258362

Epoch: 6| Step: 1
Training loss: 2.7009616199013595
Validation loss: 2.633863825678741

Epoch: 6| Step: 2
Training loss: 2.957975733102297
Validation loss: 2.627050574503739

Epoch: 6| Step: 3
Training loss: 3.1759187825770026
Validation loss: 2.6412307443504046

Epoch: 6| Step: 4
Training loss: 3.187497008079172
Validation loss: 2.626662570169787

Epoch: 6| Step: 5
Training loss: 3.3354251655757845
Validation loss: 2.63364046133939

Epoch: 6| Step: 6
Training loss: 3.5137093305049216
Validation loss: 2.642820351131109

Epoch: 6| Step: 7
Training loss: 2.7141948555675324
Validation loss: 2.637949913323692

Epoch: 6| Step: 8
Training loss: 2.3119776367769096
Validation loss: 2.628243004232509

Epoch: 6| Step: 9
Training loss: 2.840978928141073
Validation loss: 2.6339923265646727

Epoch: 6| Step: 10
Training loss: 2.530889603189502
Validation loss: 2.627027426938797

Epoch: 6| Step: 11
Training loss: 2.248995450732293
Validation loss: 2.6293132658099894

Epoch: 6| Step: 12
Training loss: 3.0027458022966993
Validation loss: 2.6395250526910186

Epoch: 6| Step: 13
Training loss: 1.933088756854227
Validation loss: 2.6473855463655127

Epoch: 40| Step: 0
Training loss: 2.8066664490809172
Validation loss: 2.6368005256322866

Epoch: 6| Step: 1
Training loss: 2.4820109701844033
Validation loss: 2.635114446163795

Epoch: 6| Step: 2
Training loss: 2.5964301176960456
Validation loss: 2.637873981156835

Epoch: 6| Step: 3
Training loss: 2.251510748708585
Validation loss: 2.630198256307715

Epoch: 6| Step: 4
Training loss: 3.2108653262303726
Validation loss: 2.623426892830074

Epoch: 6| Step: 5
Training loss: 2.901143170994565
Validation loss: 2.627557189658715

Epoch: 6| Step: 6
Training loss: 2.6275208494337363
Validation loss: 2.6316217832635687

Epoch: 6| Step: 7
Training loss: 2.916520378440529
Validation loss: 2.631047407876235

Epoch: 6| Step: 8
Training loss: 2.464534588995749
Validation loss: 2.6364165661230703

Epoch: 6| Step: 9
Training loss: 3.326737235422257
Validation loss: 2.631944887023029

Epoch: 6| Step: 10
Training loss: 3.691370985074608
Validation loss: 2.636925633319214

Epoch: 6| Step: 11
Training loss: 2.4692579302195523
Validation loss: 2.623728819858268

Epoch: 6| Step: 12
Training loss: 2.708438303942818
Validation loss: 2.6311614897403373

Epoch: 6| Step: 13
Training loss: 3.5806191093408355
Validation loss: 2.636695457850875

Epoch: 41| Step: 0
Training loss: 2.8284159136622673
Validation loss: 2.6266006779188404

Epoch: 6| Step: 1
Training loss: 2.443862631463234
Validation loss: 2.6411629920197113

Epoch: 6| Step: 2
Training loss: 2.345834034388309
Validation loss: 2.622134108684005

Epoch: 6| Step: 3
Training loss: 3.025406070913605
Validation loss: 2.6314306134665517

Epoch: 6| Step: 4
Training loss: 3.054189499947067
Validation loss: 2.619014907561251

Epoch: 6| Step: 5
Training loss: 2.916466261018659
Validation loss: 2.630191037707917

Epoch: 6| Step: 6
Training loss: 2.8328871282141073
Validation loss: 2.6304445267685415

Epoch: 6| Step: 7
Training loss: 3.628659735807628
Validation loss: 2.6433796216907677

Epoch: 6| Step: 8
Training loss: 2.828909917837998
Validation loss: 2.6290124871935947

Epoch: 6| Step: 9
Training loss: 2.754790381957028
Validation loss: 2.6188800939708683

Epoch: 6| Step: 10
Training loss: 3.4888908648097225
Validation loss: 2.6372379707222273

Epoch: 6| Step: 11
Training loss: 2.7901892856937143
Validation loss: 2.6288681165251027

Epoch: 6| Step: 12
Training loss: 2.162192076882057
Validation loss: 2.6324035389225258

Epoch: 6| Step: 13
Training loss: 2.5576212891337864
Validation loss: 2.6196054831876863

Epoch: 42| Step: 0
Training loss: 2.923497692897324
Validation loss: 2.6329905711205375

Epoch: 6| Step: 1
Training loss: 2.598011147484713
Validation loss: 2.6068210001784493

Epoch: 6| Step: 2
Training loss: 2.117716705510868
Validation loss: 2.618018455137684

Epoch: 6| Step: 3
Training loss: 2.339345226134042
Validation loss: 2.619169080805304

Epoch: 6| Step: 4
Training loss: 3.1158738200504184
Validation loss: 2.640344445507026

Epoch: 6| Step: 5
Training loss: 3.3213582624737485
Validation loss: 2.641686942647463

Epoch: 6| Step: 6
Training loss: 2.8751963672748726
Validation loss: 2.638074714809999

Epoch: 6| Step: 7
Training loss: 2.71072140582697
Validation loss: 2.6298821535271824

Epoch: 6| Step: 8
Training loss: 2.5937645233850732
Validation loss: 2.6166721121210994

Epoch: 6| Step: 9
Training loss: 3.0284095905999076
Validation loss: 2.6107927066580277

Epoch: 6| Step: 10
Training loss: 3.04566000163857
Validation loss: 2.6307944621940353

Epoch: 6| Step: 11
Training loss: 2.886518045553696
Validation loss: 2.6251154137849833

Epoch: 6| Step: 12
Training loss: 3.429191397063645
Validation loss: 2.6303688555094573

Epoch: 6| Step: 13
Training loss: 2.371201137266517
Validation loss: 2.6067785527844807

Epoch: 43| Step: 0
Training loss: 3.513536163304657
Validation loss: 2.6214513675780395

Epoch: 6| Step: 1
Training loss: 2.237284866305149
Validation loss: 2.6335789900663644

Epoch: 6| Step: 2
Training loss: 3.087488793727291
Validation loss: 2.6409298916822874

Epoch: 6| Step: 3
Training loss: 2.6758006742565956
Validation loss: 2.629825618698597

Epoch: 6| Step: 4
Training loss: 2.9957181254921736
Validation loss: 2.6130028673008887

Epoch: 6| Step: 5
Training loss: 2.853373247859726
Validation loss: 2.627340766377381

Epoch: 6| Step: 6
Training loss: 2.3594154202870423
Validation loss: 2.620946938942513

Epoch: 6| Step: 7
Training loss: 3.0719732010785075
Validation loss: 2.606294323098302

Epoch: 6| Step: 8
Training loss: 3.707869182785168
Validation loss: 2.617543953951016

Epoch: 6| Step: 9
Training loss: 2.850175745046071
Validation loss: 2.618852086306598

Epoch: 6| Step: 10
Training loss: 2.7732702930175317
Validation loss: 2.606237760558217

Epoch: 6| Step: 11
Training loss: 1.9502599836313266
Validation loss: 2.6185036506584383

Epoch: 6| Step: 12
Training loss: 2.9333837360328885
Validation loss: 2.614114629542483

Epoch: 6| Step: 13
Training loss: 2.259018097648385
Validation loss: 2.615327406045114

Epoch: 44| Step: 0
Training loss: 2.804515695224315
Validation loss: 2.6113562928812

Epoch: 6| Step: 1
Training loss: 2.691738246599771
Validation loss: 2.615600463267526

Epoch: 6| Step: 2
Training loss: 2.721865392727107
Validation loss: 2.615538270044391

Epoch: 6| Step: 3
Training loss: 3.5445423942459673
Validation loss: 2.6174785405049628

Epoch: 6| Step: 4
Training loss: 3.253799564952752
Validation loss: 2.625540134275105

Epoch: 6| Step: 5
Training loss: 2.565649469702652
Validation loss: 2.6209550965779496

Epoch: 6| Step: 6
Training loss: 3.448976259790807
Validation loss: 2.6203356319016007

Epoch: 6| Step: 7
Training loss: 2.2022963243718583
Validation loss: 2.6280855082099417

Epoch: 6| Step: 8
Training loss: 2.849838446338152
Validation loss: 2.613978935059189

Epoch: 6| Step: 9
Training loss: 2.653072925501401
Validation loss: 2.612515349965416

Epoch: 6| Step: 10
Training loss: 2.619624492147376
Validation loss: 2.6157228321759445

Epoch: 6| Step: 11
Training loss: 3.09185332140119
Validation loss: 2.6286034620480443

Epoch: 6| Step: 12
Training loss: 2.3949227191983913
Validation loss: 2.62571020524409

Epoch: 6| Step: 13
Training loss: 2.6465595079856192
Validation loss: 2.633150125981278

Epoch: 45| Step: 0
Training loss: 2.4357449987078836
Validation loss: 2.623928057267431

Epoch: 6| Step: 1
Training loss: 2.9998757018724245
Validation loss: 2.6329314176200254

Epoch: 6| Step: 2
Training loss: 3.419148373450677
Validation loss: 2.622234033788923

Epoch: 6| Step: 3
Training loss: 2.390570346980466
Validation loss: 2.6197533665945616

Epoch: 6| Step: 4
Training loss: 2.6407445395233635
Validation loss: 2.627734456912109

Epoch: 6| Step: 5
Training loss: 3.6839941136896117
Validation loss: 2.6279774268831546

Epoch: 6| Step: 6
Training loss: 3.3754652197177095
Validation loss: 2.625174459958266

Epoch: 6| Step: 7
Training loss: 2.662521856513778
Validation loss: 2.6166733838145304

Epoch: 6| Step: 8
Training loss: 2.6664467263914795
Validation loss: 2.6271969146999523

Epoch: 6| Step: 9
Training loss: 3.3830264686769085
Validation loss: 2.6205417698661795

Epoch: 6| Step: 10
Training loss: 2.0974145959646897
Validation loss: 2.6296746809832334

Epoch: 6| Step: 11
Training loss: 2.411829832612469
Validation loss: 2.6206825571642143

Epoch: 6| Step: 12
Training loss: 2.1482278617535906
Validation loss: 2.608306892127592

Epoch: 6| Step: 13
Training loss: 2.813759585296017
Validation loss: 2.620977927062736

Epoch: 46| Step: 0
Training loss: 2.917541554342196
Validation loss: 2.617990070061249

Epoch: 6| Step: 1
Training loss: 2.6828825562116587
Validation loss: 2.616689918712073

Epoch: 6| Step: 2
Training loss: 2.9689241057088314
Validation loss: 2.614528821308206

Epoch: 6| Step: 3
Training loss: 2.1996146298052577
Validation loss: 2.616703811197939

Epoch: 6| Step: 4
Training loss: 3.0459302171013656
Validation loss: 2.62574060211034

Epoch: 6| Step: 5
Training loss: 2.8451023449448085
Validation loss: 2.606846157323743

Epoch: 6| Step: 6
Training loss: 2.3387593350002436
Validation loss: 2.612727661544341

Epoch: 6| Step: 7
Training loss: 2.9215889040979635
Validation loss: 2.615319223014012

Epoch: 6| Step: 8
Training loss: 3.322557834555306
Validation loss: 2.613700323097643

Epoch: 6| Step: 9
Training loss: 3.1492087505752466
Validation loss: 2.615907685092017

Epoch: 6| Step: 10
Training loss: 2.2836541871599567
Validation loss: 2.613854379245844

Epoch: 6| Step: 11
Training loss: 1.9389831649694729
Validation loss: 2.622606305292484

Epoch: 6| Step: 12
Training loss: 3.5715164391743977
Validation loss: 2.6088760279119345

Epoch: 6| Step: 13
Training loss: 3.0647741165438296
Validation loss: 2.615454183882488

Epoch: 47| Step: 0
Training loss: 2.4514586018803985
Validation loss: 2.6254891761601997

Epoch: 6| Step: 1
Training loss: 2.3950831911296193
Validation loss: 2.6181699375430405

Epoch: 6| Step: 2
Training loss: 3.0105443661190403
Validation loss: 2.6239798321884313

Epoch: 6| Step: 3
Training loss: 2.6493718572419307
Validation loss: 2.61380476554382

Epoch: 6| Step: 4
Training loss: 2.2812628549710046
Validation loss: 2.6142899232951393

Epoch: 6| Step: 5
Training loss: 3.79752385125069
Validation loss: 2.629887674856455

Epoch: 6| Step: 6
Training loss: 2.809594242761748
Validation loss: 2.6134226157901983

Epoch: 6| Step: 7
Training loss: 3.3751305448927984
Validation loss: 2.618665336414861

Epoch: 6| Step: 8
Training loss: 2.897958062920898
Validation loss: 2.6163870079337217

Epoch: 6| Step: 9
Training loss: 2.907501115478931
Validation loss: 2.6080716794429075

Epoch: 6| Step: 10
Training loss: 2.1709241363610476
Validation loss: 2.605222904405189

Epoch: 6| Step: 11
Training loss: 3.2429674795980405
Validation loss: 2.616932362373948

Epoch: 6| Step: 12
Training loss: 2.437716939026534
Validation loss: 2.616733138013004

Epoch: 6| Step: 13
Training loss: 2.3843091923142943
Validation loss: 2.6194542032001022

Epoch: 48| Step: 0
Training loss: 2.8086227818714224
Validation loss: 2.615304079241697

Epoch: 6| Step: 1
Training loss: 2.790201846652363
Validation loss: 2.619029610928452

Epoch: 6| Step: 2
Training loss: 2.8320261988101505
Validation loss: 2.6172678484985727

Epoch: 6| Step: 3
Training loss: 3.1208256115752078
Validation loss: 2.617638124190257

Epoch: 6| Step: 4
Training loss: 3.1652120126882677
Validation loss: 2.6055708186262163

Epoch: 6| Step: 5
Training loss: 2.882022408244095
Validation loss: 2.621248816161002

Epoch: 6| Step: 6
Training loss: 2.854543136679675
Validation loss: 2.6247086585469677

Epoch: 6| Step: 7
Training loss: 2.9672218003382125
Validation loss: 2.6152888089292587

Epoch: 6| Step: 8
Training loss: 2.477042263023127
Validation loss: 2.61372271966658

Epoch: 6| Step: 9
Training loss: 2.468775398992911
Validation loss: 2.6111124183856895

Epoch: 6| Step: 10
Training loss: 3.003715757126392
Validation loss: 2.614524818755624

Epoch: 6| Step: 11
Training loss: 2.9684054526111
Validation loss: 2.6071554579630063

Epoch: 6| Step: 12
Training loss: 2.8042495088021657
Validation loss: 2.6134767058728965

Epoch: 6| Step: 13
Training loss: 1.8056463031297756
Validation loss: 2.609975459709085

Epoch: 49| Step: 0
Training loss: 3.0846575050105276
Validation loss: 2.610362345014053

Epoch: 6| Step: 1
Training loss: 3.0671702994176706
Validation loss: 2.6178093950232673

Epoch: 6| Step: 2
Training loss: 2.4431384479955733
Validation loss: 2.6135394641115877

Epoch: 6| Step: 3
Training loss: 3.5628886763713012
Validation loss: 2.615259556102019

Epoch: 6| Step: 4
Training loss: 2.5882049484819936
Validation loss: 2.6026103469021478

Epoch: 6| Step: 5
Training loss: 2.650252089116101
Validation loss: 2.609228458063584

Epoch: 6| Step: 6
Training loss: 2.7566707506191843
Validation loss: 2.6245221290467766

Epoch: 6| Step: 7
Training loss: 2.441550972273059
Validation loss: 2.6095544602173395

Epoch: 6| Step: 8
Training loss: 2.963757141181905
Validation loss: 2.598039194309893

Epoch: 6| Step: 9
Training loss: 2.9208187703319655
Validation loss: 2.618035953908544

Epoch: 6| Step: 10
Training loss: 2.9712242657514323
Validation loss: 2.61198433455212

Epoch: 6| Step: 11
Training loss: 2.611874964655401
Validation loss: 2.6194245682183324

Epoch: 6| Step: 12
Training loss: 2.396043806920612
Validation loss: 2.63051988301205

Epoch: 6| Step: 13
Training loss: 2.795359110137097
Validation loss: 2.619228869094043

Epoch: 50| Step: 0
Training loss: 2.9141240254061285
Validation loss: 2.6251889427928923

Epoch: 6| Step: 1
Training loss: 3.193539153005227
Validation loss: 2.6127126558208587

Epoch: 6| Step: 2
Training loss: 2.2681624311110986
Validation loss: 2.609435741181074

Epoch: 6| Step: 3
Training loss: 2.6579003087989723
Validation loss: 2.608213297122869

Epoch: 6| Step: 4
Training loss: 3.068372739766406
Validation loss: 2.6055738510273256

Epoch: 6| Step: 5
Training loss: 2.5586742592295235
Validation loss: 2.607343946657122

Epoch: 6| Step: 6
Training loss: 2.869584331649829
Validation loss: 2.6159741344726735

Epoch: 6| Step: 7
Training loss: 2.7560810132459292
Validation loss: 2.598051639294683

Epoch: 6| Step: 8
Training loss: 2.8581640462170625
Validation loss: 2.6041864905474466

Epoch: 6| Step: 9
Training loss: 3.0139747017530882
Validation loss: 2.6095521024430917

Epoch: 6| Step: 10
Training loss: 3.0508237633081374
Validation loss: 2.6165928250280284

Epoch: 6| Step: 11
Training loss: 2.783818976545933
Validation loss: 2.611418731975713

Epoch: 6| Step: 12
Training loss: 2.906594860986492
Validation loss: 2.6137845480702393

Epoch: 6| Step: 13
Training loss: 2.307549513164731
Validation loss: 2.609282100606299

Testing loss: 2.6207354464139128
