Epoch: 1| Step: 0
Training loss: 7.995944664203101
Validation loss: 7.939052503275388

Epoch: 6| Step: 1
Training loss: 8.608066909473273
Validation loss: 7.9335531896933755

Epoch: 6| Step: 2
Training loss: 6.628127313637768
Validation loss: 7.923333291585486

Epoch: 6| Step: 3
Training loss: 8.43350373750598
Validation loss: 7.915071705206588

Epoch: 6| Step: 4
Training loss: 7.125919215821223
Validation loss: 7.909619468545328

Epoch: 6| Step: 5
Training loss: 8.82104856732738
Validation loss: 7.9040472705774825

Epoch: 6| Step: 6
Training loss: 8.170900246597295
Validation loss: 7.894485459455169

Epoch: 6| Step: 7
Training loss: 8.333641300868605
Validation loss: 7.88863497047207

Epoch: 6| Step: 8
Training loss: 6.98217301785551
Validation loss: 7.881447486979065

Epoch: 6| Step: 9
Training loss: 7.844992976091302
Validation loss: 7.873332263557847

Epoch: 6| Step: 10
Training loss: 7.688995463980792
Validation loss: 7.866144832525988

Epoch: 6| Step: 11
Training loss: 8.473813728422634
Validation loss: 7.861950040204072

Epoch: 6| Step: 12
Training loss: 7.263277720634831
Validation loss: 7.8511293954113315

Epoch: 6| Step: 13
Training loss: 6.800537245227797
Validation loss: 7.846991721148101

Epoch: 2| Step: 0
Training loss: 7.3872460026330495
Validation loss: 7.836563290986102

Epoch: 6| Step: 1
Training loss: 7.537540831700402
Validation loss: 7.8305967792065525

Epoch: 6| Step: 2
Training loss: 8.518590008470996
Validation loss: 7.825958740164355

Epoch: 6| Step: 3
Training loss: 7.334499815442401
Validation loss: 7.812506788681526

Epoch: 6| Step: 4
Training loss: 6.995885457186826
Validation loss: 7.806945015079481

Epoch: 6| Step: 5
Training loss: 7.472277969221729
Validation loss: 7.799702521878664

Epoch: 6| Step: 6
Training loss: 7.794879788003393
Validation loss: 7.7919592673827305

Epoch: 6| Step: 7
Training loss: 7.6859531241900045
Validation loss: 7.7854972166888485

Epoch: 6| Step: 8
Training loss: 8.17562214295135
Validation loss: 7.776429027548701

Epoch: 6| Step: 9
Training loss: 7.744178554446837
Validation loss: 7.772186473795781

Epoch: 6| Step: 10
Training loss: 7.791867285880917
Validation loss: 7.76488350517423

Epoch: 6| Step: 11
Training loss: 8.001832752099867
Validation loss: 7.756216416074662

Epoch: 6| Step: 12
Training loss: 7.744105404633023
Validation loss: 7.751648543968013

Epoch: 6| Step: 13
Training loss: 8.645768964290378
Validation loss: 7.745117078269708

Epoch: 3| Step: 0
Training loss: 7.396083114775944
Validation loss: 7.738222197408755

Epoch: 6| Step: 1
Training loss: 7.789381321051505
Validation loss: 7.732068509630404

Epoch: 6| Step: 2
Training loss: 7.879299624925156
Validation loss: 7.727232939884396

Epoch: 6| Step: 3
Training loss: 8.326527626621708
Validation loss: 7.716192341105557

Epoch: 6| Step: 4
Training loss: 8.357181553640427
Validation loss: 7.711500430374351

Epoch: 6| Step: 5
Training loss: 8.236357535295488
Validation loss: 7.7032246439173635

Epoch: 6| Step: 6
Training loss: 7.186056506288568
Validation loss: 7.696627460901928

Epoch: 6| Step: 7
Training loss: 8.453254515383733
Validation loss: 7.690111307867086

Epoch: 6| Step: 8
Training loss: 6.5969895635258915
Validation loss: 7.683463539495673

Epoch: 6| Step: 9
Training loss: 7.258688620256406
Validation loss: 7.6728668109788885

Epoch: 6| Step: 10
Training loss: 7.097350698138922
Validation loss: 7.668118643889825

Epoch: 6| Step: 11
Training loss: 8.31305296930136
Validation loss: 7.662598506548111

Epoch: 6| Step: 12
Training loss: 6.022335758210359
Validation loss: 7.6527733649770715

Epoch: 6| Step: 13
Training loss: 8.00755573140168
Validation loss: 7.647883451497171

Epoch: 4| Step: 0
Training loss: 7.454288287918206
Validation loss: 7.639200246462262

Epoch: 6| Step: 1
Training loss: 7.196053101306049
Validation loss: 7.63372903971336

Epoch: 6| Step: 2
Training loss: 6.84257211521044
Validation loss: 7.626737313640744

Epoch: 6| Step: 3
Training loss: 7.612022487653269
Validation loss: 7.622146753107573

Epoch: 6| Step: 4
Training loss: 7.866122615988491
Validation loss: 7.611853385682229

Epoch: 6| Step: 5
Training loss: 8.468356302829948
Validation loss: 7.603977343845745

Epoch: 6| Step: 6
Training loss: 7.105382850635253
Validation loss: 7.597433424631238

Epoch: 6| Step: 7
Training loss: 6.402797457135405
Validation loss: 7.590784623235042

Epoch: 6| Step: 8
Training loss: 8.661778856786126
Validation loss: 7.582590661998151

Epoch: 6| Step: 9
Training loss: 7.479896559382523
Validation loss: 7.5794186454496675

Epoch: 6| Step: 10
Training loss: 8.035961387104786
Validation loss: 7.567923458548363

Epoch: 6| Step: 11
Training loss: 7.3567434088721875
Validation loss: 7.559591155783018

Epoch: 6| Step: 12
Training loss: 7.58746932147641
Validation loss: 7.556024403937595

Epoch: 6| Step: 13
Training loss: 7.394213460551116
Validation loss: 7.54694772713022

Epoch: 5| Step: 0
Training loss: 6.615751901165387
Validation loss: 7.539188898739841

Epoch: 6| Step: 1
Training loss: 8.432597678846136
Validation loss: 7.533208330413018

Epoch: 6| Step: 2
Training loss: 8.551563713342688
Validation loss: 7.5250612624287045

Epoch: 6| Step: 3
Training loss: 7.121741905157184
Validation loss: 7.51536158078602

Epoch: 6| Step: 4
Training loss: 8.391376028422908
Validation loss: 7.508224009076385

Epoch: 6| Step: 5
Training loss: 7.849724306744443
Validation loss: 7.4981070286476275

Epoch: 6| Step: 6
Training loss: 6.86535634004392
Validation loss: 7.4935032807222095

Epoch: 6| Step: 7
Training loss: 7.604969668556737
Validation loss: 7.485014483337772

Epoch: 6| Step: 8
Training loss: 7.925229898962932
Validation loss: 7.47364211463796

Epoch: 6| Step: 9
Training loss: 6.917221813060789
Validation loss: 7.466767048417353

Epoch: 6| Step: 10
Training loss: 6.624356796422472
Validation loss: 7.461036683960803

Epoch: 6| Step: 11
Training loss: 7.121436047553508
Validation loss: 7.45238184227661

Epoch: 6| Step: 12
Training loss: 6.936474423595838
Validation loss: 7.447627659433907

Epoch: 6| Step: 13
Training loss: 6.642846882426927
Validation loss: 7.436315847416791

Epoch: 6| Step: 0
Training loss: 7.7942264316431435
Validation loss: 7.423805374890352

Epoch: 6| Step: 1
Training loss: 7.619429758116232
Validation loss: 7.422218784040585

Epoch: 6| Step: 2
Training loss: 6.164724645598916
Validation loss: 7.412742462395553

Epoch: 6| Step: 3
Training loss: 7.386705322898955
Validation loss: 7.403388551317358

Epoch: 6| Step: 4
Training loss: 7.287199152237779
Validation loss: 7.393403850624388

Epoch: 6| Step: 5
Training loss: 7.006089967368345
Validation loss: 7.387694892611912

Epoch: 6| Step: 6
Training loss: 7.004016269004833
Validation loss: 7.377017115712243

Epoch: 6| Step: 7
Training loss: 6.954031278718167
Validation loss: 7.36944836090448

Epoch: 6| Step: 8
Training loss: 6.748422508991511
Validation loss: 7.363593004732327

Epoch: 6| Step: 9
Training loss: 8.305710852399804
Validation loss: 7.350071440274116

Epoch: 6| Step: 10
Training loss: 8.625141529635904
Validation loss: 7.343944840736327

Epoch: 6| Step: 11
Training loss: 7.611970869945729
Validation loss: 7.332949125828447

Epoch: 6| Step: 12
Training loss: 6.695948602823232
Validation loss: 7.325173859655798

Epoch: 6| Step: 13
Training loss: 7.052861210694863
Validation loss: 7.3158123604730125

Epoch: 7| Step: 0
Training loss: 6.359511765267686
Validation loss: 7.305906481391799

Epoch: 6| Step: 1
Training loss: 6.788384828447896
Validation loss: 7.297812897638807

Epoch: 6| Step: 2
Training loss: 8.45549657697768
Validation loss: 7.288562195586667

Epoch: 6| Step: 3
Training loss: 6.7114678241055366
Validation loss: 7.279732184854054

Epoch: 6| Step: 4
Training loss: 7.709077651370706
Validation loss: 7.268612027602215

Epoch: 6| Step: 5
Training loss: 6.701636658229524
Validation loss: 7.263256664470753

Epoch: 6| Step: 6
Training loss: 6.635436851993761
Validation loss: 7.253417078613879

Epoch: 6| Step: 7
Training loss: 6.274075334363585
Validation loss: 7.246158253841162

Epoch: 6| Step: 8
Training loss: 6.844737081891082
Validation loss: 7.230427924338358

Epoch: 6| Step: 9
Training loss: 6.495022261583619
Validation loss: 7.217860118315236

Epoch: 6| Step: 10
Training loss: 7.3751306037330036
Validation loss: 7.210503412701769

Epoch: 6| Step: 11
Training loss: 8.34386292570469
Validation loss: 7.198784768016784

Epoch: 6| Step: 12
Training loss: 8.519630204176586
Validation loss: 7.192824439528388

Epoch: 6| Step: 13
Training loss: 7.151871186941874
Validation loss: 7.18022822711307

Epoch: 8| Step: 0
Training loss: 6.92172978164895
Validation loss: 7.171582224878346

Epoch: 6| Step: 1
Training loss: 7.152201877689048
Validation loss: 7.156170164068562

Epoch: 6| Step: 2
Training loss: 7.758005253144168
Validation loss: 7.1528356273475655

Epoch: 6| Step: 3
Training loss: 6.600212509895515
Validation loss: 7.13657188851517

Epoch: 6| Step: 4
Training loss: 7.629962744465637
Validation loss: 7.1264514319078

Epoch: 6| Step: 5
Training loss: 7.2628189410825374
Validation loss: 7.115216881544889

Epoch: 6| Step: 6
Training loss: 7.49544234076876
Validation loss: 7.10276681572511

Epoch: 6| Step: 7
Training loss: 6.5646396600245165
Validation loss: 7.093855610185507

Epoch: 6| Step: 8
Training loss: 6.35898388308939
Validation loss: 7.079564567025096

Epoch: 6| Step: 9
Training loss: 6.811128530779094
Validation loss: 7.06646184123305

Epoch: 6| Step: 10
Training loss: 6.894252661244733
Validation loss: 7.058442848441615

Epoch: 6| Step: 11
Training loss: 7.466369760377638
Validation loss: 7.044537065951499

Epoch: 6| Step: 12
Training loss: 7.363831161080249
Validation loss: 7.030043515115181

Epoch: 6| Step: 13
Training loss: 5.916961161130282
Validation loss: 7.020464917948935

Epoch: 9| Step: 0
Training loss: 6.968673910914483
Validation loss: 7.00952700786859

Epoch: 6| Step: 1
Training loss: 6.687038512661956
Validation loss: 6.998450648334167

Epoch: 6| Step: 2
Training loss: 6.823588175646323
Validation loss: 6.982243005876857

Epoch: 6| Step: 3
Training loss: 7.728058549631544
Validation loss: 6.974637101306327

Epoch: 6| Step: 4
Training loss: 6.47120096702045
Validation loss: 6.960169019932287

Epoch: 6| Step: 5
Training loss: 7.420186639787918
Validation loss: 6.951943647778581

Epoch: 6| Step: 6
Training loss: 6.69815441162509
Validation loss: 6.941989009881224

Epoch: 6| Step: 7
Training loss: 6.155990982415905
Validation loss: 6.9264128013891435

Epoch: 6| Step: 8
Training loss: 7.663318842934604
Validation loss: 6.906889356207245

Epoch: 6| Step: 9
Training loss: 7.1742032662089255
Validation loss: 6.90477571874506

Epoch: 6| Step: 10
Training loss: 6.58715316756999
Validation loss: 6.886060940524267

Epoch: 6| Step: 11
Training loss: 5.280895695285263
Validation loss: 6.870837965225014

Epoch: 6| Step: 12
Training loss: 6.773308529445458
Validation loss: 6.858369442097316

Epoch: 6| Step: 13
Training loss: 8.200881854764205
Validation loss: 6.8478524803690695

Epoch: 10| Step: 0
Training loss: 6.844453679666165
Validation loss: 6.832689758695979

Epoch: 6| Step: 1
Training loss: 6.784690160121364
Validation loss: 6.8232205481460335

Epoch: 6| Step: 2
Training loss: 6.370709340411003
Validation loss: 6.806972588796792

Epoch: 6| Step: 3
Training loss: 7.052496382892578
Validation loss: 6.786285591856221

Epoch: 6| Step: 4
Training loss: 6.987436737156317
Validation loss: 6.779482169547137

Epoch: 6| Step: 5
Training loss: 7.443821376455127
Validation loss: 6.755958260917274

Epoch: 6| Step: 6
Training loss: 6.862292110441905
Validation loss: 6.738499514347212

Epoch: 6| Step: 7
Training loss: 6.524795774574278
Validation loss: 6.733458559099695

Epoch: 6| Step: 8
Training loss: 6.80038887482745
Validation loss: 6.723340943150308

Epoch: 6| Step: 9
Training loss: 6.1382250573148625
Validation loss: 6.703192501357857

Epoch: 6| Step: 10
Training loss: 5.899222578134104
Validation loss: 6.689241354518214

Epoch: 6| Step: 11
Training loss: 6.356270897154839
Validation loss: 6.67400974697089

Epoch: 6| Step: 12
Training loss: 7.372660896353972
Validation loss: 6.657890926755849

Epoch: 6| Step: 13
Training loss: 5.960743272249361
Validation loss: 6.638590705143005

Epoch: 11| Step: 0
Training loss: 6.4579079108455035
Validation loss: 6.622766633353603

Epoch: 6| Step: 1
Training loss: 7.20192432119518
Validation loss: 6.610093664283522

Epoch: 6| Step: 2
Training loss: 6.640911643629668
Validation loss: 6.593407876367559

Epoch: 6| Step: 3
Training loss: 5.66290667086176
Validation loss: 6.577260127998352

Epoch: 6| Step: 4
Training loss: 6.249399995613642
Validation loss: 6.563895575310426

Epoch: 6| Step: 5
Training loss: 6.119225407368292
Validation loss: 6.549462221524473

Epoch: 6| Step: 6
Training loss: 7.064972031329409
Validation loss: 6.532348697407831

Epoch: 6| Step: 7
Training loss: 6.809922596943903
Validation loss: 6.511067641135751

Epoch: 6| Step: 8
Training loss: 6.185301418993163
Validation loss: 6.497199692970343

Epoch: 6| Step: 9
Training loss: 6.567388838868053
Validation loss: 6.4778416949938755

Epoch: 6| Step: 10
Training loss: 6.467571648789564
Validation loss: 6.461895904103646

Epoch: 6| Step: 11
Training loss: 6.62828932382644
Validation loss: 6.447397879305699

Epoch: 6| Step: 12
Training loss: 6.466970005327432
Validation loss: 6.43652774148362

Epoch: 6| Step: 13
Training loss: 5.998046875
Validation loss: 6.415111295175682

Epoch: 12| Step: 0
Training loss: 7.1614512902427485
Validation loss: 6.396730150130281

Epoch: 6| Step: 1
Training loss: 5.971347742843888
Validation loss: 6.376892413781092

Epoch: 6| Step: 2
Training loss: 6.145581601262279
Validation loss: 6.357149277516284

Epoch: 6| Step: 3
Training loss: 7.389592878925047
Validation loss: 6.339520925372026

Epoch: 6| Step: 4
Training loss: 6.788430345820644
Validation loss: 6.31971704880024

Epoch: 6| Step: 5
Training loss: 6.2877097244626015
Validation loss: 6.30599912781472

Epoch: 6| Step: 6
Training loss: 6.104813611983625
Validation loss: 6.285858535389913

Epoch: 6| Step: 7
Training loss: 5.72099085195257
Validation loss: 6.262362755917698

Epoch: 6| Step: 8
Training loss: 6.530232765524046
Validation loss: 6.24910746446473

Epoch: 6| Step: 9
Training loss: 5.758091747701766
Validation loss: 6.235768147329278

Epoch: 6| Step: 10
Training loss: 5.8904776719183936
Validation loss: 6.20460439010147

Epoch: 6| Step: 11
Training loss: 6.054339392714761
Validation loss: 6.193086334950918

Epoch: 6| Step: 12
Training loss: 5.544868901649038
Validation loss: 6.163811959387377

Epoch: 6| Step: 13
Training loss: 5.503350017914337
Validation loss: 6.146363314105732

Epoch: 13| Step: 0
Training loss: 5.488819201838292
Validation loss: 6.133067390156601

Epoch: 6| Step: 1
Training loss: 6.030995101681306
Validation loss: 6.109699421197084

Epoch: 6| Step: 2
Training loss: 6.310626667903148
Validation loss: 6.093053021787186

Epoch: 6| Step: 3
Training loss: 6.418300106993107
Validation loss: 6.0703291682736165

Epoch: 6| Step: 4
Training loss: 4.5462499234753055
Validation loss: 6.059363124183185

Epoch: 6| Step: 5
Training loss: 5.580025998126756
Validation loss: 6.034502969194037

Epoch: 6| Step: 6
Training loss: 6.401992499611968
Validation loss: 6.012426371090848

Epoch: 6| Step: 7
Training loss: 6.12806873908471
Validation loss: 5.989874200022576

Epoch: 6| Step: 8
Training loss: 5.8816931724797845
Validation loss: 5.9723644062556716

Epoch: 6| Step: 9
Training loss: 6.609761688968895
Validation loss: 5.950718581598605

Epoch: 6| Step: 10
Training loss: 6.977301990920973
Validation loss: 5.936608740380774

Epoch: 6| Step: 11
Training loss: 5.513394431560196
Validation loss: 5.90994723573639

Epoch: 6| Step: 12
Training loss: 5.736538595794084
Validation loss: 5.886744468577204

Epoch: 6| Step: 13
Training loss: 5.260544315212027
Validation loss: 5.857768600500207

Epoch: 14| Step: 0
Training loss: 5.27721725075073
Validation loss: 5.845675461119287

Epoch: 6| Step: 1
Training loss: 6.1790044240643995
Validation loss: 5.819409862008343

Epoch: 6| Step: 2
Training loss: 6.052445401398848
Validation loss: 5.809269122154154

Epoch: 6| Step: 3
Training loss: 5.565908352184045
Validation loss: 5.77701708040593

Epoch: 6| Step: 4
Training loss: 5.951090788030612
Validation loss: 5.753539113976567

Epoch: 6| Step: 5
Training loss: 5.707858026397619
Validation loss: 5.731118792056995

Epoch: 6| Step: 6
Training loss: 5.393492005367477
Validation loss: 5.7086565851181055

Epoch: 6| Step: 7
Training loss: 5.798828125
Validation loss: 5.680126772561622

Epoch: 6| Step: 8
Training loss: 4.5854654150380165
Validation loss: 5.668949754255401

Epoch: 6| Step: 9
Training loss: 5.994609954846286
Validation loss: 5.635236985366512

Epoch: 6| Step: 10
Training loss: 5.351264176789903
Validation loss: 5.615870938965115

Epoch: 6| Step: 11
Training loss: 5.970557772907729
Validation loss: 5.590508055979527

Epoch: 6| Step: 12
Training loss: 6.051006315415579
Validation loss: 5.570974558955481

Epoch: 6| Step: 13
Training loss: 4.9584229832513245
Validation loss: 5.54763089335514

Epoch: 15| Step: 0
Training loss: 5.870894275761399
Validation loss: 5.516191497781993

Epoch: 6| Step: 1
Training loss: 3.3048059609105676
Validation loss: 5.5021012991546865

Epoch: 6| Step: 2
Training loss: 5.588319667970488
Validation loss: 5.460245884046552

Epoch: 6| Step: 3
Training loss: 6.436106114263693
Validation loss: 5.463193433538878

Epoch: 6| Step: 4
Training loss: 4.3529136107986535
Validation loss: 5.420150402646052

Epoch: 6| Step: 5
Training loss: 5.505509131618968
Validation loss: 5.390717488821556

Epoch: 6| Step: 6
Training loss: 5.093928608951612
Validation loss: 5.390257821605037

Epoch: 6| Step: 7
Training loss: 5.970595788412034
Validation loss: 5.338429340308341

Epoch: 6| Step: 8
Training loss: 5.724971867787901
Validation loss: 5.328503312926636

Epoch: 6| Step: 9
Training loss: 5.223577402462474
Validation loss: 5.3007421257599265

Epoch: 6| Step: 10
Training loss: 5.1688147765670625
Validation loss: 5.266377368477377

Epoch: 6| Step: 11
Training loss: 5.355849104381699
Validation loss: 5.2411002194906375

Epoch: 6| Step: 12
Training loss: 5.353640677693954
Validation loss: 5.221350286522881

Epoch: 6| Step: 13
Training loss: 4.859654065916715
Validation loss: 5.191748111075291

Epoch: 16| Step: 0
Training loss: 5.382721788060038
Validation loss: 5.162013876801643

Epoch: 6| Step: 1
Training loss: 4.2788277337972715
Validation loss: 5.1405936774212115

Epoch: 6| Step: 2
Training loss: 5.213509675447656
Validation loss: 5.112303246290081

Epoch: 6| Step: 3
Training loss: 4.576505302887075
Validation loss: 5.089225321164217

Epoch: 6| Step: 4
Training loss: 3.2842245515724664
Validation loss: 5.060854422679054

Epoch: 6| Step: 5
Training loss: 3.943908804282135
Validation loss: 5.022971082342868

Epoch: 6| Step: 6
Training loss: 5.892060527379262
Validation loss: 5.010635799275313

Epoch: 6| Step: 7
Training loss: 4.6057542966371114
Validation loss: 4.968693343928381

Epoch: 6| Step: 8
Training loss: 6.391094162561412
Validation loss: 4.951969538723444

Epoch: 6| Step: 9
Training loss: 4.909141514578312
Validation loss: 4.927715005113461

Epoch: 6| Step: 10
Training loss: 5.761828653612822
Validation loss: 4.896162502277917

Epoch: 6| Step: 11
Training loss: 4.601145493891389
Validation loss: 4.865569649358067

Epoch: 6| Step: 12
Training loss: 5.76768361791857
Validation loss: 4.840101687601206

Epoch: 6| Step: 13
Training loss: 3.068728127955167
Validation loss: 4.807614718572312

Epoch: 17| Step: 0
Training loss: 4.496634390347308
Validation loss: 4.79399637064964

Epoch: 6| Step: 1
Training loss: 4.480964666457549
Validation loss: 4.740044958907738

Epoch: 6| Step: 2
Training loss: 5.742494743587229
Validation loss: 4.72243266029852

Epoch: 6| Step: 3
Training loss: 5.255274711419039
Validation loss: 4.68203437269172

Epoch: 6| Step: 4
Training loss: 3.8021868687297853
Validation loss: 4.6488372672196725

Epoch: 6| Step: 5
Training loss: 4.873379951668073
Validation loss: 4.634975005352573

Epoch: 6| Step: 6
Training loss: 4.251132814115206
Validation loss: 4.598302722987462

Epoch: 6| Step: 7
Training loss: 3.918683337750385
Validation loss: 4.577919235513626

Epoch: 6| Step: 8
Training loss: 3.8275487349264807
Validation loss: 4.549422203770637

Epoch: 6| Step: 9
Training loss: 5.363812180680746
Validation loss: 4.514417710965291

Epoch: 6| Step: 10
Training loss: 4.606143555776447
Validation loss: 4.490745414403778

Epoch: 6| Step: 11
Training loss: 4.445810407432261
Validation loss: 4.452712923970239

Epoch: 6| Step: 12
Training loss: 4.364375483526372
Validation loss: 4.431720345394365

Epoch: 6| Step: 13
Training loss: 4.491391318709961
Validation loss: 4.391259235888814

Epoch: 18| Step: 0
Training loss: 4.14827335701041
Validation loss: 4.371275525615629

Epoch: 6| Step: 1
Training loss: 4.477307216087206
Validation loss: 4.340756713869328

Epoch: 6| Step: 2
Training loss: 4.146455625415523
Validation loss: 4.317575993466602

Epoch: 6| Step: 3
Training loss: 3.436586987015421
Validation loss: 4.283303657101109

Epoch: 6| Step: 4
Training loss: 4.054739244310967
Validation loss: 4.251362521266426

Epoch: 6| Step: 5
Training loss: 5.064021129256728
Validation loss: 4.208700240613005

Epoch: 6| Step: 6
Training loss: 4.1727049498509645
Validation loss: 4.20098890010026

Epoch: 6| Step: 7
Training loss: 4.0066994353957455
Validation loss: 4.1742498823227585

Epoch: 6| Step: 8
Training loss: 3.5416347427425343
Validation loss: 4.147417716884489

Epoch: 6| Step: 9
Training loss: 4.303978503318906
Validation loss: 4.11279432356461

Epoch: 6| Step: 10
Training loss: 4.794070340311711
Validation loss: 4.074705014478726

Epoch: 6| Step: 11
Training loss: 4.502006930942022
Validation loss: 4.05712606623995

Epoch: 6| Step: 12
Training loss: 3.6805488890261624
Validation loss: 4.033515437981499

Epoch: 6| Step: 13
Training loss: 4.242697107325343
Validation loss: 3.9999151964324624

Epoch: 19| Step: 0
Training loss: 3.8937505094426834
Validation loss: 3.979572499436972

Epoch: 6| Step: 1
Training loss: 4.446167982544509
Validation loss: 3.936643577317572

Epoch: 6| Step: 2
Training loss: 4.188315468712225
Validation loss: 3.8902156789297306

Epoch: 6| Step: 3
Training loss: 3.9530081147415324
Validation loss: 3.888750460476044

Epoch: 6| Step: 4
Training loss: 3.8825182429055167
Validation loss: 3.8564311369655493

Epoch: 6| Step: 5
Training loss: 4.324156997639467
Validation loss: 3.8466682657695705

Epoch: 6| Step: 6
Training loss: 3.528587485343623
Validation loss: 3.8049796963927887

Epoch: 6| Step: 7
Training loss: 3.627048702757559
Validation loss: 3.7842333841685427

Epoch: 6| Step: 8
Training loss: 3.466392196891589
Validation loss: 3.744380779773307

Epoch: 6| Step: 9
Training loss: 3.4384786426523815
Validation loss: 3.7274331835756405

Epoch: 6| Step: 10
Training loss: 3.614962262052938
Validation loss: 3.7066727852020205

Epoch: 6| Step: 11
Training loss: 3.7431649542214567
Validation loss: 3.6860398797410907

Epoch: 6| Step: 12
Training loss: 3.4812776629514834
Validation loss: 3.63339514177879

Epoch: 6| Step: 13
Training loss: 3.912086825750977
Validation loss: 3.6278432474253424

Epoch: 20| Step: 0
Training loss: 3.3833988377536133
Validation loss: 3.59131055361317

Epoch: 6| Step: 1
Training loss: 3.7769898936262956
Validation loss: 3.5602503324279904

Epoch: 6| Step: 2
Training loss: 3.444043676243388
Validation loss: 3.5294742734974647

Epoch: 6| Step: 3
Training loss: 3.700124047751643
Validation loss: 3.5207894770267036

Epoch: 6| Step: 4
Training loss: 2.723798952612496
Validation loss: 3.4924430040697065

Epoch: 6| Step: 5
Training loss: 3.5915078507881546
Validation loss: 3.4802276416222853

Epoch: 6| Step: 6
Training loss: 3.235685810816743
Validation loss: 3.433271133352444

Epoch: 6| Step: 7
Training loss: 3.714017790259264
Validation loss: 3.425464752967124

Epoch: 6| Step: 8
Training loss: 4.227702270938579
Validation loss: 3.4127121111300616

Epoch: 6| Step: 9
Training loss: 3.587772606251673
Validation loss: 3.395026876653193

Epoch: 6| Step: 10
Training loss: 3.264205551117124
Validation loss: 3.363049102131136

Epoch: 6| Step: 11
Training loss: 3.0660159111630327
Validation loss: 3.333779405669606

Epoch: 6| Step: 12
Training loss: 3.1855356484033472
Validation loss: 3.3049173447051836

Epoch: 6| Step: 13
Training loss: 4.530696229968091
Validation loss: 3.305597257697211

Epoch: 21| Step: 0
Training loss: 3.816210832541646
Validation loss: 3.2776766945049283

Epoch: 6| Step: 1
Training loss: 4.469489616596209
Validation loss: 3.2510415010480846

Epoch: 6| Step: 2
Training loss: 2.0324550868628672
Validation loss: 3.237596694377149

Epoch: 6| Step: 3
Training loss: 3.642012957789221
Validation loss: 3.214586773101217

Epoch: 6| Step: 4
Training loss: 2.701315389862919
Validation loss: 3.2197617110544834

Epoch: 6| Step: 5
Training loss: 2.785771327430324
Validation loss: 3.1932636954248728

Epoch: 6| Step: 6
Training loss: 3.5496794918603682
Validation loss: 3.183948253565423

Epoch: 6| Step: 7
Training loss: 3.491441207441003
Validation loss: 3.1451296946734684

Epoch: 6| Step: 8
Training loss: 2.8419116439453544
Validation loss: 3.148402198457819

Epoch: 6| Step: 9
Training loss: 4.214827006309421
Validation loss: 3.1325761801399077

Epoch: 6| Step: 10
Training loss: 2.974751078986878
Validation loss: 3.1220390057569922

Epoch: 6| Step: 11
Training loss: 2.7088250716385867
Validation loss: 3.0983027534710286

Epoch: 6| Step: 12
Training loss: 3.1879723890729057
Validation loss: 3.091038387839902

Epoch: 6| Step: 13
Training loss: 2.7191057520535735
Validation loss: 3.0641004855842136

Epoch: 22| Step: 0
Training loss: 2.7796801304840124
Validation loss: 3.0704801003793816

Epoch: 6| Step: 1
Training loss: 3.7042906652807015
Validation loss: 3.0449150064481123

Epoch: 6| Step: 2
Training loss: 2.270979453702341
Validation loss: 3.0432451551693265

Epoch: 6| Step: 3
Training loss: 2.683816647885804
Validation loss: 3.0327940918494782

Epoch: 6| Step: 4
Training loss: 3.1053388460448055
Validation loss: 3.0311155281986593

Epoch: 6| Step: 5
Training loss: 2.9667010816085244
Validation loss: 3.000186203404395

Epoch: 6| Step: 6
Training loss: 3.8447373525455015
Validation loss: 3.0139646384692207

Epoch: 6| Step: 7
Training loss: 2.512852058606878
Validation loss: 2.996025363079445

Epoch: 6| Step: 8
Training loss: 2.464834464126724
Validation loss: 2.9974014964836484

Epoch: 6| Step: 9
Training loss: 3.591253060041824
Validation loss: 2.999860732971754

Epoch: 6| Step: 10
Training loss: 3.9515973784573073
Validation loss: 2.973378153401582

Epoch: 6| Step: 11
Training loss: 2.817491129308646
Validation loss: 2.9701652240781975

Epoch: 6| Step: 12
Training loss: 3.323376774199485
Validation loss: 2.9695119910737655

Epoch: 6| Step: 13
Training loss: 4.154616185351302
Validation loss: 2.949478124317634

Epoch: 23| Step: 0
Training loss: 3.1175634783635084
Validation loss: 2.9634135202873764

Epoch: 6| Step: 1
Training loss: 3.279171530604037
Validation loss: 2.9491919505637436

Epoch: 6| Step: 2
Training loss: 3.488682568949851
Validation loss: 2.9485736652386976

Epoch: 6| Step: 3
Training loss: 2.697002378706684
Validation loss: 2.958494878434307

Epoch: 6| Step: 4
Training loss: 2.1946260186684214
Validation loss: 2.942935108910348

Epoch: 6| Step: 5
Training loss: 2.9238767243998685
Validation loss: 2.938353998884679

Epoch: 6| Step: 6
Training loss: 3.7529000830295396
Validation loss: 2.922207696537194

Epoch: 6| Step: 7
Training loss: 3.6607774921769014
Validation loss: 2.9236369935448767

Epoch: 6| Step: 8
Training loss: 3.1628824176189516
Validation loss: 2.929190294740533

Epoch: 6| Step: 9
Training loss: 3.8005663349358287
Validation loss: 2.9201525926915677

Epoch: 6| Step: 10
Training loss: 2.510700405015038
Validation loss: 2.9113555918839227

Epoch: 6| Step: 11
Training loss: 3.726649253363237
Validation loss: 2.9174106858970856

Epoch: 6| Step: 12
Training loss: 1.884190478550523
Validation loss: 2.9205989265469636

Epoch: 6| Step: 13
Training loss: 2.9579515524218123
Validation loss: 2.9228063255845638

Epoch: 24| Step: 0
Training loss: 3.386793652754459
Validation loss: 2.915403741044871

Epoch: 6| Step: 1
Training loss: 3.147243377428892
Validation loss: 2.920429469890864

Epoch: 6| Step: 2
Training loss: 2.6921945422363276
Validation loss: 2.919225802045942

Epoch: 6| Step: 3
Training loss: 2.746086196563447
Validation loss: 2.9069310961573613

Epoch: 6| Step: 4
Training loss: 4.005176056267592
Validation loss: 2.9172448017437578

Epoch: 6| Step: 5
Training loss: 2.834910982002593
Validation loss: 2.901278488865403

Epoch: 6| Step: 6
Training loss: 3.218573556156385
Validation loss: 2.8935606501603135

Epoch: 6| Step: 7
Training loss: 3.658728908508001
Validation loss: 2.876393847475444

Epoch: 6| Step: 8
Training loss: 2.684352362185359
Validation loss: 2.892826610142972

Epoch: 6| Step: 9
Training loss: 3.6798067174822298
Validation loss: 2.9067223048560415

Epoch: 6| Step: 10
Training loss: 1.9932715963076202
Validation loss: 2.914993718416187

Epoch: 6| Step: 11
Training loss: 2.8370678543189207
Validation loss: 2.895761389970011

Epoch: 6| Step: 12
Training loss: 2.9652972571879412
Validation loss: 2.9009837232806985

Epoch: 6| Step: 13
Training loss: 2.8867154463360665
Validation loss: 2.900629674261733

Epoch: 25| Step: 0
Training loss: 3.0541976184673065
Validation loss: 2.8999759036581083

Epoch: 6| Step: 1
Training loss: 2.9026831611978867
Validation loss: 2.9121802985698686

Epoch: 6| Step: 2
Training loss: 3.3833051151044726
Validation loss: 2.897728579022981

Epoch: 6| Step: 3
Training loss: 2.9815983662708536
Validation loss: 2.8815463929876883

Epoch: 6| Step: 4
Training loss: 3.3608906010645776
Validation loss: 2.894004966679986

Epoch: 6| Step: 5
Training loss: 3.648163811753482
Validation loss: 2.8709714922512344

Epoch: 6| Step: 6
Training loss: 3.1438865616792726
Validation loss: 2.8868437642589257

Epoch: 6| Step: 7
Training loss: 2.714356127521169
Validation loss: 2.8835396491965586

Epoch: 6| Step: 8
Training loss: 2.837614210073738
Validation loss: 2.8694149133535034

Epoch: 6| Step: 9
Training loss: 3.5215840338782227
Validation loss: 2.89503273587254

Epoch: 6| Step: 10
Training loss: 2.964744676786714
Validation loss: 2.8723283314499373

Epoch: 6| Step: 11
Training loss: 1.840970222986569
Validation loss: 2.8887517507116343

Epoch: 6| Step: 12
Training loss: 3.758772951340829
Validation loss: 2.862633315307842

Epoch: 6| Step: 13
Training loss: 2.5844198423690488
Validation loss: 2.8563681629308864

Epoch: 26| Step: 0
Training loss: 3.2121165540267733
Validation loss: 2.8900141510970214

Epoch: 6| Step: 1
Training loss: 3.4482237956621526
Validation loss: 2.8841441663954805

Epoch: 6| Step: 2
Training loss: 2.956416158059245
Validation loss: 2.884416831592484

Epoch: 6| Step: 3
Training loss: 3.261274296065832
Validation loss: 2.885815922241538

Epoch: 6| Step: 4
Training loss: 3.199663478322637
Validation loss: 2.8812624004220755

Epoch: 6| Step: 5
Training loss: 2.920408972488161
Validation loss: 2.891249070762161

Epoch: 6| Step: 6
Training loss: 2.6672701053532033
Validation loss: 2.8821414567014716

Epoch: 6| Step: 7
Training loss: 3.339974241328705
Validation loss: 2.8786619422824167

Epoch: 6| Step: 8
Training loss: 3.511606182802004
Validation loss: 2.8804171755601686

Epoch: 6| Step: 9
Training loss: 3.2892632864874884
Validation loss: 2.886469137771852

Epoch: 6| Step: 10
Training loss: 3.0606961289986603
Validation loss: 2.8588810312539557

Epoch: 6| Step: 11
Training loss: 3.0451019605782306
Validation loss: 2.872932781433752

Epoch: 6| Step: 12
Training loss: 2.4412132736232723
Validation loss: 2.896056373725665

Epoch: 6| Step: 13
Training loss: 2.2672447991310976
Validation loss: 2.850895137463025

Epoch: 27| Step: 0
Training loss: 3.6246857342476058
Validation loss: 2.8810732799864494

Epoch: 6| Step: 1
Training loss: 3.9232219191693427
Validation loss: 2.8731286439830117

Epoch: 6| Step: 2
Training loss: 3.029342050910325
Validation loss: 2.8676142574332357

Epoch: 6| Step: 3
Training loss: 2.7013321592448256
Validation loss: 2.8744038538479524

Epoch: 6| Step: 4
Training loss: 1.717793146294696
Validation loss: 2.8549452054364926

Epoch: 6| Step: 5
Training loss: 3.1449279155869823
Validation loss: 2.8637585055231303

Epoch: 6| Step: 6
Training loss: 3.076201016727044
Validation loss: 2.8658469900799326

Epoch: 6| Step: 7
Training loss: 2.4475863186477094
Validation loss: 2.8651543384684652

Epoch: 6| Step: 8
Training loss: 2.8826727277578503
Validation loss: 2.8845671487166644

Epoch: 6| Step: 9
Training loss: 3.0105545029989647
Validation loss: 2.8574144516683746

Epoch: 6| Step: 10
Training loss: 4.102006579382208
Validation loss: 2.848884917368331

Epoch: 6| Step: 11
Training loss: 3.019423706192473
Validation loss: 2.864092939506308

Epoch: 6| Step: 12
Training loss: 3.2587425313204803
Validation loss: 2.849354756514174

Epoch: 6| Step: 13
Training loss: 2.2549730021008805
Validation loss: 2.8651565288530434

Epoch: 28| Step: 0
Training loss: 3.4467369128016334
Validation loss: 2.8581881400840974

Epoch: 6| Step: 1
Training loss: 3.558438043297002
Validation loss: 2.8640470072419313

Epoch: 6| Step: 2
Training loss: 2.8053071339052256
Validation loss: 2.865438573405272

Epoch: 6| Step: 3
Training loss: 3.329427974473548
Validation loss: 2.892470161399728

Epoch: 6| Step: 4
Training loss: 2.5802360445910533
Validation loss: 2.8710242170293876

Epoch: 6| Step: 5
Training loss: 3.0213331839395043
Validation loss: 2.8573235883112433

Epoch: 6| Step: 6
Training loss: 3.18466629028744
Validation loss: 2.870372861581104

Epoch: 6| Step: 7
Training loss: 3.4576801617754143
Validation loss: 2.8843544698616577

Epoch: 6| Step: 8
Training loss: 2.1067850672771886
Validation loss: 2.87226683544033

Epoch: 6| Step: 9
Training loss: 3.3228045278220546
Validation loss: 2.8649304460250766

Epoch: 6| Step: 10
Training loss: 3.019286783643575
Validation loss: 2.8624663345299606

Epoch: 6| Step: 11
Training loss: 2.9040118387364546
Validation loss: 2.8681632258784076

Epoch: 6| Step: 12
Training loss: 2.8105017450989247
Validation loss: 2.8579065981651213

Epoch: 6| Step: 13
Training loss: 3.5767950393188452
Validation loss: 2.8807825126148368

Epoch: 29| Step: 0
Training loss: 2.6029983544654054
Validation loss: 2.8710208711965657

Epoch: 6| Step: 1
Training loss: 2.496510836479372
Validation loss: 2.8869423060153876

Epoch: 6| Step: 2
Training loss: 3.114434501298497
Validation loss: 2.8641396417000133

Epoch: 6| Step: 3
Training loss: 3.7278157492035153
Validation loss: 2.8584587681929188

Epoch: 6| Step: 4
Training loss: 2.6529398319971875
Validation loss: 2.871580392584039

Epoch: 6| Step: 5
Training loss: 2.6343752244471843
Validation loss: 2.886083756278905

Epoch: 6| Step: 6
Training loss: 3.3968669199913246
Validation loss: 2.848293130425146

Epoch: 6| Step: 7
Training loss: 3.403404377100221
Validation loss: 2.870951952602222

Epoch: 6| Step: 8
Training loss: 2.567115163219303
Validation loss: 2.845204021838088

Epoch: 6| Step: 9
Training loss: 2.7723736509077925
Validation loss: 2.872856368218599

Epoch: 6| Step: 10
Training loss: 3.503621815988103
Validation loss: 2.8641925280432283

Epoch: 6| Step: 11
Training loss: 3.7095505220556833
Validation loss: 2.872201379569058

Epoch: 6| Step: 12
Training loss: 3.123749291953029
Validation loss: 2.8555941807174734

Epoch: 6| Step: 13
Training loss: 2.6970980272423706
Validation loss: 2.855255873619247

Epoch: 30| Step: 0
Training loss: 3.284232101453218
Validation loss: 2.864462482367988

Epoch: 6| Step: 1
Training loss: 2.6265630155854454
Validation loss: 2.860533767018195

Epoch: 6| Step: 2
Training loss: 2.9510610321052257
Validation loss: 2.8536102480702805

Epoch: 6| Step: 3
Training loss: 2.4645971788504917
Validation loss: 2.859317996167805

Epoch: 6| Step: 4
Training loss: 2.9107119855278216
Validation loss: 2.8684916347292093

Epoch: 6| Step: 5
Training loss: 3.511671632444265
Validation loss: 2.867843182340165

Epoch: 6| Step: 6
Training loss: 2.924587357587084
Validation loss: 2.859627472994293

Epoch: 6| Step: 7
Training loss: 3.297234972063492
Validation loss: 2.8486792740850695

Epoch: 6| Step: 8
Training loss: 3.0113409574776844
Validation loss: 2.845801260808636

Epoch: 6| Step: 9
Training loss: 3.3569574217904323
Validation loss: 2.84192716334166

Epoch: 6| Step: 10
Training loss: 3.0030486193419907
Validation loss: 2.85665708435755

Epoch: 6| Step: 11
Training loss: 2.622805631881515
Validation loss: 2.8537631491005087

Epoch: 6| Step: 12
Training loss: 3.67953380741596
Validation loss: 2.8484637113827738

Epoch: 6| Step: 13
Training loss: 3.2018264743598492
Validation loss: 2.8418882618536645

Epoch: 31| Step: 0
Training loss: 3.5121771287327963
Validation loss: 2.8582391328075074

Epoch: 6| Step: 1
Training loss: 2.5326897564938595
Validation loss: 2.857128025445296

Epoch: 6| Step: 2
Training loss: 2.524315837668342
Validation loss: 2.8555283749873004

Epoch: 6| Step: 3
Training loss: 3.9183789967405103
Validation loss: 2.8524865658465033

Epoch: 6| Step: 4
Training loss: 3.6172310021175953
Validation loss: 2.8497607976489645

Epoch: 6| Step: 5
Training loss: 2.5960363399507194
Validation loss: 2.843673162313614

Epoch: 6| Step: 6
Training loss: 3.8638208396240232
Validation loss: 2.8218834636830534

Epoch: 6| Step: 7
Training loss: 2.485615546515705
Validation loss: 2.8459018452618667

Epoch: 6| Step: 8
Training loss: 3.4932875980654456
Validation loss: 2.864901680508025

Epoch: 6| Step: 9
Training loss: 2.7668842961612086
Validation loss: 2.867519394659081

Epoch: 6| Step: 10
Training loss: 2.400103757522787
Validation loss: 2.8645865581117675

Epoch: 6| Step: 11
Training loss: 2.7165399096664395
Validation loss: 2.8445186718773

Epoch: 6| Step: 12
Training loss: 2.5242705018415292
Validation loss: 2.844239430915621

Epoch: 6| Step: 13
Training loss: 3.2349213217080877
Validation loss: 2.8725871964708176

Epoch: 32| Step: 0
Training loss: 2.2829111400392765
Validation loss: 2.8340363161236026

Epoch: 6| Step: 1
Training loss: 3.244642389985621
Validation loss: 2.8482576650582647

Epoch: 6| Step: 2
Training loss: 2.805563957109451
Validation loss: 2.8670114742202686

Epoch: 6| Step: 3
Training loss: 3.6830550737408876
Validation loss: 2.831650728963571

Epoch: 6| Step: 4
Training loss: 2.9680814291382096
Validation loss: 2.851564706219112

Epoch: 6| Step: 5
Training loss: 2.8447723227846278
Validation loss: 2.85080288737421

Epoch: 6| Step: 6
Training loss: 2.3642469214433164
Validation loss: 2.864137426370518

Epoch: 6| Step: 7
Training loss: 3.8438699595022676
Validation loss: 2.8529729784870663

Epoch: 6| Step: 8
Training loss: 3.6519786958271525
Validation loss: 2.8503556616633174

Epoch: 6| Step: 9
Training loss: 3.2094907448167618
Validation loss: 2.840187122521461

Epoch: 6| Step: 10
Training loss: 2.998744224933948
Validation loss: 2.8465496022745134

Epoch: 6| Step: 11
Training loss: 2.619591636428145
Validation loss: 2.8434933782480964

Epoch: 6| Step: 12
Training loss: 2.9172772631246158
Validation loss: 2.833268074506209

Epoch: 6| Step: 13
Training loss: 2.9328044942056586
Validation loss: 2.860994228945508

Epoch: 33| Step: 0
Training loss: 2.595485887701109
Validation loss: 2.8540853697322452

Epoch: 6| Step: 1
Training loss: 2.577894720717096
Validation loss: 2.8233296493700144

Epoch: 6| Step: 2
Training loss: 2.6053825489980422
Validation loss: 2.8427982678195938

Epoch: 6| Step: 3
Training loss: 2.144628192537932
Validation loss: 2.8446997843985895

Epoch: 6| Step: 4
Training loss: 3.650018582231434
Validation loss: 2.8554411434058244

Epoch: 6| Step: 5
Training loss: 3.064525946194997
Validation loss: 2.8530606332740405

Epoch: 6| Step: 6
Training loss: 2.902931205268139
Validation loss: 2.8427826251222856

Epoch: 6| Step: 7
Training loss: 3.648225504497363
Validation loss: 2.8243939590984146

Epoch: 6| Step: 8
Training loss: 3.268677667287944
Validation loss: 2.856222747021451

Epoch: 6| Step: 9
Training loss: 3.144054002264088
Validation loss: 2.841386397178765

Epoch: 6| Step: 10
Training loss: 3.4194603330227724
Validation loss: 2.853059159638437

Epoch: 6| Step: 11
Training loss: 2.905549652048228
Validation loss: 2.8351508800831775

Epoch: 6| Step: 12
Training loss: 2.943320331681575
Validation loss: 2.8398898345046675

Epoch: 6| Step: 13
Training loss: 3.546393542445332
Validation loss: 2.8488962890674316

Epoch: 34| Step: 0
Training loss: 3.324316863820894
Validation loss: 2.847941478765161

Epoch: 6| Step: 1
Training loss: 2.3836377325160525
Validation loss: 2.851520227289452

Epoch: 6| Step: 2
Training loss: 3.181593864757674
Validation loss: 2.839585161886011

Epoch: 6| Step: 3
Training loss: 2.568625131064151
Validation loss: 2.8413453666165056

Epoch: 6| Step: 4
Training loss: 2.7103955169564093
Validation loss: 2.8519793569992515

Epoch: 6| Step: 5
Training loss: 2.301363134716473
Validation loss: 2.835383596927629

Epoch: 6| Step: 6
Training loss: 3.5093808480653075
Validation loss: 2.856006167563272

Epoch: 6| Step: 7
Training loss: 3.3614732443887902
Validation loss: 2.8222817738246966

Epoch: 6| Step: 8
Training loss: 3.119778963720139
Validation loss: 2.848901850268001

Epoch: 6| Step: 9
Training loss: 2.557746572233261
Validation loss: 2.8410806840252545

Epoch: 6| Step: 10
Training loss: 3.5457267078784978
Validation loss: 2.8428216370157555

Epoch: 6| Step: 11
Training loss: 2.304094451637222
Validation loss: 2.83595724835423

Epoch: 6| Step: 12
Training loss: 3.3886611806387443
Validation loss: 2.8324378204160485

Epoch: 6| Step: 13
Training loss: 4.2333814292838845
Validation loss: 2.8244255724431833

Epoch: 35| Step: 0
Training loss: 2.987146977591639
Validation loss: 2.8491724246576413

Epoch: 6| Step: 1
Training loss: 2.613227056788137
Validation loss: 2.855773501917492

Epoch: 6| Step: 2
Training loss: 2.397156612558778
Validation loss: 2.83628052832696

Epoch: 6| Step: 3
Training loss: 3.252762720638021
Validation loss: 2.863348074608902

Epoch: 6| Step: 4
Training loss: 2.9275542363486102
Validation loss: 2.8374607514429866

Epoch: 6| Step: 5
Training loss: 2.552811893608291
Validation loss: 2.826497537628078

Epoch: 6| Step: 6
Training loss: 2.9836742916658245
Validation loss: 2.8523632633945217

Epoch: 6| Step: 7
Training loss: 2.284799818623426
Validation loss: 2.8306072027062057

Epoch: 6| Step: 8
Training loss: 3.3664139215254028
Validation loss: 2.8362844158869898

Epoch: 6| Step: 9
Training loss: 3.3441706597799996
Validation loss: 2.8753028672649497

Epoch: 6| Step: 10
Training loss: 2.9730987820963883
Validation loss: 2.8228576672759265

Epoch: 6| Step: 11
Training loss: 3.9046700906537164
Validation loss: 2.8501332250982028

Epoch: 6| Step: 12
Training loss: 3.5967636077892835
Validation loss: 2.8441398039723667

Epoch: 6| Step: 13
Training loss: 2.641848669992587
Validation loss: 2.8377233988581088

Epoch: 36| Step: 0
Training loss: 3.707295962048313
Validation loss: 2.8466743813235555

Epoch: 6| Step: 1
Training loss: 2.3101194345883913
Validation loss: 2.826162500939456

Epoch: 6| Step: 2
Training loss: 2.462403747691326
Validation loss: 2.82267385179472

Epoch: 6| Step: 3
Training loss: 3.1312949293495675
Validation loss: 2.8399549888644295

Epoch: 6| Step: 4
Training loss: 2.4396396929069826
Validation loss: 2.8316035715015544

Epoch: 6| Step: 5
Training loss: 2.7670551632427247
Validation loss: 2.829974931731772

Epoch: 6| Step: 6
Training loss: 3.442390985141008
Validation loss: 2.8389359088166968

Epoch: 6| Step: 7
Training loss: 3.2355857462691295
Validation loss: 2.831255582243317

Epoch: 6| Step: 8
Training loss: 2.6653069864350893
Validation loss: 2.825764968250296

Epoch: 6| Step: 9
Training loss: 3.508812980453549
Validation loss: 2.838067479569527

Epoch: 6| Step: 10
Training loss: 2.9356719477056523
Validation loss: 2.811905770552631

Epoch: 6| Step: 11
Training loss: 2.8842073699744852
Validation loss: 2.8213335609731174

Epoch: 6| Step: 12
Training loss: 3.0820160878706577
Validation loss: 2.834748036790031

Epoch: 6| Step: 13
Training loss: 3.7521675203499436
Validation loss: 2.8177467855954625

Epoch: 37| Step: 0
Training loss: 2.7414098435750973
Validation loss: 2.8302140964686084

Epoch: 6| Step: 1
Training loss: 3.46597976726211
Validation loss: 2.807988892163664

Epoch: 6| Step: 2
Training loss: 2.7208612071581606
Validation loss: 2.8380197702099466

Epoch: 6| Step: 3
Training loss: 3.109140665243297
Validation loss: 2.8334648616333107

Epoch: 6| Step: 4
Training loss: 2.534526258816116
Validation loss: 2.832435960434093

Epoch: 6| Step: 5
Training loss: 3.0662148191142067
Validation loss: 2.8365582553688276

Epoch: 6| Step: 6
Training loss: 1.6557945488948875
Validation loss: 2.8382551620833207

Epoch: 6| Step: 7
Training loss: 3.0290957002228236
Validation loss: 2.8112900796492832

Epoch: 6| Step: 8
Training loss: 3.7108128576929524
Validation loss: 2.856143784596201

Epoch: 6| Step: 9
Training loss: 2.9710703565753374
Validation loss: 2.8472309383202563

Epoch: 6| Step: 10
Training loss: 3.6835435234844582
Validation loss: 2.8408035209408604

Epoch: 6| Step: 11
Training loss: 3.261247977815047
Validation loss: 2.843270212776552

Epoch: 6| Step: 12
Training loss: 2.5631561369680167
Validation loss: 2.8332596491208792

Epoch: 6| Step: 13
Training loss: 3.0179469207282303
Validation loss: 2.8513493310868827

Epoch: 38| Step: 0
Training loss: 3.912221144223705
Validation loss: 2.8283929049237297

Epoch: 6| Step: 1
Training loss: 2.324600419194068
Validation loss: 2.8490397789665307

Epoch: 6| Step: 2
Training loss: 3.348723233732907
Validation loss: 2.84776124938307

Epoch: 6| Step: 3
Training loss: 3.0583963732411292
Validation loss: 2.8476294256260437

Epoch: 6| Step: 4
Training loss: 2.453889375402124
Validation loss: 2.8430071526157676

Epoch: 6| Step: 5
Training loss: 2.7767402003863983
Validation loss: 2.824182091814321

Epoch: 6| Step: 6
Training loss: 3.299494565924297
Validation loss: 2.84680293714543

Epoch: 6| Step: 7
Training loss: 2.1008458386838
Validation loss: 2.8464204513871323

Epoch: 6| Step: 8
Training loss: 3.127908497576914
Validation loss: 2.834382442645445

Epoch: 6| Step: 9
Training loss: 2.5657763121726815
Validation loss: 2.8184531054017845

Epoch: 6| Step: 10
Training loss: 3.1439184124773285
Validation loss: 2.815960706270148

Epoch: 6| Step: 11
Training loss: 3.2080528499977845
Validation loss: 2.8243777960276533

Epoch: 6| Step: 12
Training loss: 3.060900523501296
Validation loss: 2.818181105354307

Epoch: 6| Step: 13
Training loss: 3.548395444351177
Validation loss: 2.8401315515069525

Epoch: 39| Step: 0
Training loss: 2.8135475750865475
Validation loss: 2.822809083282044

Epoch: 6| Step: 1
Training loss: 3.055707288115085
Validation loss: 2.817675217384272

Epoch: 6| Step: 2
Training loss: 3.7021851453518457
Validation loss: 2.801851657253428

Epoch: 6| Step: 3
Training loss: 3.2752649855245046
Validation loss: 2.799043378667525

Epoch: 6| Step: 4
Training loss: 2.780936234166648
Validation loss: 2.823059447735979

Epoch: 6| Step: 5
Training loss: 2.7341708733796515
Validation loss: 2.8200883391940947

Epoch: 6| Step: 6
Training loss: 2.9479531509424244
Validation loss: 2.8238847075709637

Epoch: 6| Step: 7
Training loss: 3.2381702215397805
Validation loss: 2.8182886892363217

Epoch: 6| Step: 8
Training loss: 2.8839682973211778
Validation loss: 2.799481026872311

Epoch: 6| Step: 9
Training loss: 2.987575233182552
Validation loss: 2.793624226184314

Epoch: 6| Step: 10
Training loss: 2.919023233894285
Validation loss: 2.821086269388089

Epoch: 6| Step: 11
Training loss: 3.103350145790895
Validation loss: 2.830786205383908

Epoch: 6| Step: 12
Training loss: 2.8223478206294086
Validation loss: 2.7988322257915472

Epoch: 6| Step: 13
Training loss: 1.9930906754196975
Validation loss: 2.8232291951131705

Epoch: 40| Step: 0
Training loss: 3.591424073230464
Validation loss: 2.804669121021539

Epoch: 6| Step: 1
Training loss: 3.4649682952619365
Validation loss: 2.8161441278839465

Epoch: 6| Step: 2
Training loss: 2.9416654556171062
Validation loss: 2.8065527476322396

Epoch: 6| Step: 3
Training loss: 2.9152616840766643
Validation loss: 2.8339834378275297

Epoch: 6| Step: 4
Training loss: 2.8436150152007733
Validation loss: 2.8061701105129275

Epoch: 6| Step: 5
Training loss: 2.638142880738626
Validation loss: 2.794861420267471

Epoch: 6| Step: 6
Training loss: 2.458020519031271
Validation loss: 2.81884649986621

Epoch: 6| Step: 7
Training loss: 2.990319209075842
Validation loss: 2.8125524117201945

Epoch: 6| Step: 8
Training loss: 2.950978947511694
Validation loss: 2.8252377123202645

Epoch: 6| Step: 9
Training loss: 3.018727658270068
Validation loss: 2.8366386694606374

Epoch: 6| Step: 10
Training loss: 2.775511661819096
Validation loss: 2.8200092686125764

Epoch: 6| Step: 11
Training loss: 2.9536745882033193
Validation loss: 2.813243019464424

Epoch: 6| Step: 12
Training loss: 3.043889387569753
Validation loss: 2.8073707770477543

Epoch: 6| Step: 13
Training loss: 3.367868447541241
Validation loss: 2.8115783530347582

Epoch: 41| Step: 0
Training loss: 3.3241385641860197
Validation loss: 2.8281977803962453

Epoch: 6| Step: 1
Training loss: 3.0313380906980973
Validation loss: 2.823008912025593

Epoch: 6| Step: 2
Training loss: 2.941315790130415
Validation loss: 2.8156295646856373

Epoch: 6| Step: 3
Training loss: 3.090774183848117
Validation loss: 2.812506678674714

Epoch: 6| Step: 4
Training loss: 3.2783739837262087
Validation loss: 2.8264347582919322

Epoch: 6| Step: 5
Training loss: 2.6599925882910243
Validation loss: 2.812721385924811

Epoch: 6| Step: 6
Training loss: 2.8527465034445383
Validation loss: 2.816923707368161

Epoch: 6| Step: 7
Training loss: 2.8810808310008835
Validation loss: 2.788513331746778

Epoch: 6| Step: 8
Training loss: 2.4601172639453717
Validation loss: 2.8123502210616014

Epoch: 6| Step: 9
Training loss: 2.861308793663367
Validation loss: 2.8289491436948815

Epoch: 6| Step: 10
Training loss: 3.714025493561035
Validation loss: 2.7909799415924375

Epoch: 6| Step: 11
Training loss: 2.5422793624402202
Validation loss: 2.8067441866067697

Epoch: 6| Step: 12
Training loss: 3.2620478115729377
Validation loss: 2.809580318597026

Epoch: 6| Step: 13
Training loss: 2.872211596799078
Validation loss: 2.817641453837024

Epoch: 42| Step: 0
Training loss: 2.7006645691649345
Validation loss: 2.7959992483692773

Epoch: 6| Step: 1
Training loss: 3.3026263796284874
Validation loss: 2.8007132822208107

Epoch: 6| Step: 2
Training loss: 3.258880952311749
Validation loss: 2.794175972757264

Epoch: 6| Step: 3
Training loss: 2.8231519106058864
Validation loss: 2.802905077068377

Epoch: 6| Step: 4
Training loss: 2.6954572113552593
Validation loss: 2.8011011351822646

Epoch: 6| Step: 5
Training loss: 3.2955277569330694
Validation loss: 2.8148079748821084

Epoch: 6| Step: 6
Training loss: 3.075246636648954
Validation loss: 2.7989095040252407

Epoch: 6| Step: 7
Training loss: 2.4630902275258015
Validation loss: 2.799647085081213

Epoch: 6| Step: 8
Training loss: 3.6877953362596836
Validation loss: 2.8098046352440798

Epoch: 6| Step: 9
Training loss: 3.473562527841792
Validation loss: 2.8073007990341745

Epoch: 6| Step: 10
Training loss: 2.4706226441313985
Validation loss: 2.790150470494863

Epoch: 6| Step: 11
Training loss: 2.3277366365465606
Validation loss: 2.7763504539656854

Epoch: 6| Step: 12
Training loss: 2.888096378715403
Validation loss: 2.799069787570628

Epoch: 6| Step: 13
Training loss: 2.835464648294617
Validation loss: 2.8275690950459103

Epoch: 43| Step: 0
Training loss: 3.5462944463096626
Validation loss: 2.7903999891894427

Epoch: 6| Step: 1
Training loss: 2.908096547220209
Validation loss: 2.799871997939864

Epoch: 6| Step: 2
Training loss: 2.0968284181062664
Validation loss: 2.7769027919970646

Epoch: 6| Step: 3
Training loss: 3.2620687148518255
Validation loss: 2.7877772539848644

Epoch: 6| Step: 4
Training loss: 2.968290273306579
Validation loss: 2.819953859976197

Epoch: 6| Step: 5
Training loss: 3.5360865596515922
Validation loss: 2.7855730065824615

Epoch: 6| Step: 6
Training loss: 3.182705133843558
Validation loss: 2.7997721029961817

Epoch: 6| Step: 7
Training loss: 2.81044032655055
Validation loss: 2.8058729141169394

Epoch: 6| Step: 8
Training loss: 3.072440383121683
Validation loss: 2.8085343042851174

Epoch: 6| Step: 9
Training loss: 2.888141286738425
Validation loss: 2.8008953271536106

Epoch: 6| Step: 10
Training loss: 2.4272179518491552
Validation loss: 2.8167827152573985

Epoch: 6| Step: 11
Training loss: 2.6238805109416594
Validation loss: 2.8060265169505523

Epoch: 6| Step: 12
Training loss: 3.21642463906762
Validation loss: 2.793273830180448

Epoch: 6| Step: 13
Training loss: 2.572299363270579
Validation loss: 2.8163517089667383

Epoch: 44| Step: 0
Training loss: 2.8631769970575505
Validation loss: 2.7986952769877824

Epoch: 6| Step: 1
Training loss: 3.2328468435241535
Validation loss: 2.8135665129314655

Epoch: 6| Step: 2
Training loss: 3.0792510011210963
Validation loss: 2.8040350497508406

Epoch: 6| Step: 3
Training loss: 3.303178447193537
Validation loss: 2.8083499018337177

Epoch: 6| Step: 4
Training loss: 2.0744539116782628
Validation loss: 2.7734491329824396

Epoch: 6| Step: 5
Training loss: 2.664904508901762
Validation loss: 2.80541674121863

Epoch: 6| Step: 6
Training loss: 2.927398031203352
Validation loss: 2.81359792447035

Epoch: 6| Step: 7
Training loss: 3.580512703566062
Validation loss: 2.788333928069947

Epoch: 6| Step: 8
Training loss: 2.9524165519788914
Validation loss: 2.7975051929774977

Epoch: 6| Step: 9
Training loss: 2.467179003767927
Validation loss: 2.7992243306195292

Epoch: 6| Step: 10
Training loss: 2.8977875919149847
Validation loss: 2.81193216532463

Epoch: 6| Step: 11
Training loss: 2.7795073804131185
Validation loss: 2.805639255786178

Epoch: 6| Step: 12
Training loss: 3.7658276008775613
Validation loss: 2.79538367012811

Epoch: 6| Step: 13
Training loss: 2.6852795499051707
Validation loss: 2.8042353661160337

Epoch: 45| Step: 0
Training loss: 2.334441966126571
Validation loss: 2.7977831331999936

Epoch: 6| Step: 1
Training loss: 2.564294884267214
Validation loss: 2.788709750154984

Epoch: 6| Step: 2
Training loss: 2.8865343997715414
Validation loss: 2.788053035813131

Epoch: 6| Step: 3
Training loss: 3.426074094880798
Validation loss: 2.810468014868211

Epoch: 6| Step: 4
Training loss: 2.501755288943512
Validation loss: 2.8043481289715335

Epoch: 6| Step: 5
Training loss: 2.453495362138456
Validation loss: 2.812711121213324

Epoch: 6| Step: 6
Training loss: 3.620671812492717
Validation loss: 2.7912934298206786

Epoch: 6| Step: 7
Training loss: 2.8980972625017127
Validation loss: 2.7797614180450023

Epoch: 6| Step: 8
Training loss: 2.5780478726034275
Validation loss: 2.778945731523145

Epoch: 6| Step: 9
Training loss: 2.7857071383877123
Validation loss: 2.7865414907294728

Epoch: 6| Step: 10
Training loss: 3.429135497559132
Validation loss: 2.7889409040894564

Epoch: 6| Step: 11
Training loss: 3.7221776728708114
Validation loss: 2.8030685819523757

Epoch: 6| Step: 12
Training loss: 2.4977343783599784
Validation loss: 2.774633800042567

Epoch: 6| Step: 13
Training loss: 3.743706699432982
Validation loss: 2.791557378440331

Epoch: 46| Step: 0
Training loss: 2.8679986372855337
Validation loss: 2.8041602139582404

Epoch: 6| Step: 1
Training loss: 2.372742232245971
Validation loss: 2.802042320882396

Epoch: 6| Step: 2
Training loss: 3.0739350436414323
Validation loss: 2.78574809070756

Epoch: 6| Step: 3
Training loss: 3.715915401009024
Validation loss: 2.818772940513567

Epoch: 6| Step: 4
Training loss: 2.3791269284574597
Validation loss: 2.8056140367500624

Epoch: 6| Step: 5
Training loss: 3.4381617515997664
Validation loss: 2.798065007548055

Epoch: 6| Step: 6
Training loss: 2.8424035542279866
Validation loss: 2.813237327629237

Epoch: 6| Step: 7
Training loss: 3.2196825769004147
Validation loss: 2.7762216406030564

Epoch: 6| Step: 8
Training loss: 2.1891890408239356
Validation loss: 2.782937771421264

Epoch: 6| Step: 9
Training loss: 2.684958653620046
Validation loss: 2.7776444576086234

Epoch: 6| Step: 10
Training loss: 2.997263295910896
Validation loss: 2.801733207732565

Epoch: 6| Step: 11
Training loss: 3.0551907254134467
Validation loss: 2.799455752817367

Epoch: 6| Step: 12
Training loss: 3.2186937049461175
Validation loss: 2.8107173251463657

Epoch: 6| Step: 13
Training loss: 2.9215701347053016
Validation loss: 2.7671402152951092

Epoch: 47| Step: 0
Training loss: 2.9922015237106097
Validation loss: 2.7654177300276093

Epoch: 6| Step: 1
Training loss: 2.1284093994472193
Validation loss: 2.777533717423147

Epoch: 6| Step: 2
Training loss: 2.6211457794528625
Validation loss: 2.827464103811422

Epoch: 6| Step: 3
Training loss: 2.3886517128518463
Validation loss: 2.7871341668145413

Epoch: 6| Step: 4
Training loss: 3.226745452496983
Validation loss: 2.7967516712141447

Epoch: 6| Step: 5
Training loss: 3.231816851185558
Validation loss: 2.78583194353553

Epoch: 6| Step: 6
Training loss: 3.4021922448956388
Validation loss: 2.776530781525494

Epoch: 6| Step: 7
Training loss: 2.6946315623939316
Validation loss: 2.7745909771051998

Epoch: 6| Step: 8
Training loss: 2.6112710608422365
Validation loss: 2.7724862384930815

Epoch: 6| Step: 9
Training loss: 2.8075284462877823
Validation loss: 2.7989844949105382

Epoch: 6| Step: 10
Training loss: 3.655833033073372
Validation loss: 2.777737523132477

Epoch: 6| Step: 11
Training loss: 3.328938129651094
Validation loss: 2.7746265876295952

Epoch: 6| Step: 12
Training loss: 2.6511952493743602
Validation loss: 2.7650820968222765

Epoch: 6| Step: 13
Training loss: 2.734779981867802
Validation loss: 2.7789647501869092

Epoch: 48| Step: 0
Training loss: 3.5956378787874472
Validation loss: 2.7834062116411693

Epoch: 6| Step: 1
Training loss: 2.5356536988478844
Validation loss: 2.808098708854353

Epoch: 6| Step: 2
Training loss: 2.7588530136393095
Validation loss: 2.8031806966881305

Epoch: 6| Step: 3
Training loss: 3.4122591821006325
Validation loss: 2.7803645709222677

Epoch: 6| Step: 4
Training loss: 2.4117230681296378
Validation loss: 2.787365267463627

Epoch: 6| Step: 5
Training loss: 2.4911622237433884
Validation loss: 2.765286869369737

Epoch: 6| Step: 6
Training loss: 3.1289038116407477
Validation loss: 2.8041205279719397

Epoch: 6| Step: 7
Training loss: 3.064288492928743
Validation loss: 2.777106302449138

Epoch: 6| Step: 8
Training loss: 2.938209285732161
Validation loss: 2.737013474100478

Epoch: 6| Step: 9
Training loss: 2.589802138970959
Validation loss: 2.768406455526624

Epoch: 6| Step: 10
Training loss: 2.6297294155504347
Validation loss: 2.7685101949431346

Epoch: 6| Step: 11
Training loss: 2.559876564447497
Validation loss: 2.769007757204532

Epoch: 6| Step: 12
Training loss: 3.286526025880005
Validation loss: 2.8024172074882263

Epoch: 6| Step: 13
Training loss: 3.684935114171523
Validation loss: 2.776148640817651

Epoch: 49| Step: 0
Training loss: 2.098915219554366
Validation loss: 2.7777741149823503

Epoch: 6| Step: 1
Training loss: 3.2491938251365773
Validation loss: 2.780598526234702

Epoch: 6| Step: 2
Training loss: 3.8716104510973706
Validation loss: 2.810479099605487

Epoch: 6| Step: 3
Training loss: 2.638687325749314
Validation loss: 2.7960862787867984

Epoch: 6| Step: 4
Training loss: 2.939363091696339
Validation loss: 2.7859095336120654

Epoch: 6| Step: 5
Training loss: 2.9133412795609526
Validation loss: 2.786536400320218

Epoch: 6| Step: 6
Training loss: 3.039764715425601
Validation loss: 2.7601162976704794

Epoch: 6| Step: 7
Training loss: 3.376112295461658
Validation loss: 2.7643193752224846

Epoch: 6| Step: 8
Training loss: 2.1166245954442537
Validation loss: 2.756188617635096

Epoch: 6| Step: 9
Training loss: 2.765053037993572
Validation loss: 2.777499134553922

Epoch: 6| Step: 10
Training loss: 2.9824668016528575
Validation loss: 2.7710760952263196

Epoch: 6| Step: 11
Training loss: 2.7976179787692703
Validation loss: 2.81072200236457

Epoch: 6| Step: 12
Training loss: 2.1401344349783904
Validation loss: 2.774812388598078

Epoch: 6| Step: 13
Training loss: 3.9895239975835364
Validation loss: 2.7650540281979805

Epoch: 50| Step: 0
Training loss: 2.4592304424761946
Validation loss: 2.776219953499694

Epoch: 6| Step: 1
Training loss: 2.1883944181510175
Validation loss: 2.7692620720372454

Epoch: 6| Step: 2
Training loss: 2.6828820230121666
Validation loss: 2.77625653672566

Epoch: 6| Step: 3
Training loss: 2.65449591670007
Validation loss: 2.770158545979372

Epoch: 6| Step: 4
Training loss: 2.2721056625618674
Validation loss: 2.761497712776031

Epoch: 6| Step: 5
Training loss: 2.8001815600794853
Validation loss: 2.773007732244683

Epoch: 6| Step: 6
Training loss: 3.4099312584623998
Validation loss: 2.791775454435747

Epoch: 6| Step: 7
Training loss: 2.828824120198203
Validation loss: 2.7850825482613573

Epoch: 6| Step: 8
Training loss: 2.816467792404713
Validation loss: 2.783427505184633

Epoch: 6| Step: 9
Training loss: 2.575159667907228
Validation loss: 2.7598977617957443

Epoch: 6| Step: 10
Training loss: 4.007431279840802
Validation loss: 2.787822906245447

Epoch: 6| Step: 11
Training loss: 3.4401185206023084
Validation loss: 2.7862233567816044

Epoch: 6| Step: 12
Training loss: 3.451770775841385
Validation loss: 2.787505291018161

Epoch: 6| Step: 13
Training loss: 2.932061375484308
Validation loss: 2.7929353789586098

Epoch: 51| Step: 0
Training loss: 2.194507383364123
Validation loss: 2.784996246384259

Epoch: 6| Step: 1
Training loss: 2.7456585687139157
Validation loss: 2.757018882299176

Epoch: 6| Step: 2
Training loss: 3.220239239210569
Validation loss: 2.786038622308818

Epoch: 6| Step: 3
Training loss: 2.870335817527855
Validation loss: 2.7670535057569863

Epoch: 6| Step: 4
Training loss: 3.6490803383001382
Validation loss: 2.768842316894034

Epoch: 6| Step: 5
Training loss: 2.945883293393664
Validation loss: 2.7741088350468184

Epoch: 6| Step: 6
Training loss: 3.1809490428729745
Validation loss: 2.7601316769656985

Epoch: 6| Step: 7
Training loss: 2.509314256742869
Validation loss: 2.774591241360794

Epoch: 6| Step: 8
Training loss: 2.599654130672212
Validation loss: 2.785444887546146

Epoch: 6| Step: 9
Training loss: 3.225612251065846
Validation loss: 2.795355827812766

Epoch: 6| Step: 10
Training loss: 3.143941617855582
Validation loss: 2.769410435948193

Epoch: 6| Step: 11
Training loss: 3.2430658460549555
Validation loss: 2.7542860986474804

Epoch: 6| Step: 12
Training loss: 2.2847630871716116
Validation loss: 2.771117282270264

Epoch: 6| Step: 13
Training loss: 2.4879748097337377
Validation loss: 2.7793924171131534

Epoch: 52| Step: 0
Training loss: 2.547130080479029
Validation loss: 2.776589423131669

Epoch: 6| Step: 1
Training loss: 3.259418923949752
Validation loss: 2.7833213407132726

Epoch: 6| Step: 2
Training loss: 2.4400733666255574
Validation loss: 2.7754306691458805

Epoch: 6| Step: 3
Training loss: 2.5640471835146776
Validation loss: 2.7679660187273227

Epoch: 6| Step: 4
Training loss: 3.8235341473373157
Validation loss: 2.769340213378649

Epoch: 6| Step: 5
Training loss: 3.201457710841141
Validation loss: 2.76139021128945

Epoch: 6| Step: 6
Training loss: 2.3544391260611595
Validation loss: 2.7597727369109673

Epoch: 6| Step: 7
Training loss: 2.4824967872007235
Validation loss: 2.7591302286832726

Epoch: 6| Step: 8
Training loss: 2.656294788656173
Validation loss: 2.761079507017733

Epoch: 6| Step: 9
Training loss: 2.456683159992368
Validation loss: 2.8012259143182043

Epoch: 6| Step: 10
Training loss: 3.5871308778145123
Validation loss: 2.7782465770573737

Epoch: 6| Step: 11
Training loss: 3.6075318489598627
Validation loss: 2.7657463511053564

Epoch: 6| Step: 12
Training loss: 2.912478428052656
Validation loss: 2.771519621217698

Epoch: 6| Step: 13
Training loss: 1.9957819207988565
Validation loss: 2.785406305357637

Epoch: 53| Step: 0
Training loss: 3.026515448681602
Validation loss: 2.7699876972608077

Epoch: 6| Step: 1
Training loss: 2.8424402930867667
Validation loss: 2.74479818443553

Epoch: 6| Step: 2
Training loss: 2.9940030239907935
Validation loss: 2.7504550663593554

Epoch: 6| Step: 3
Training loss: 3.006090181349482
Validation loss: 2.782628081032255

Epoch: 6| Step: 4
Training loss: 2.9408139953525163
Validation loss: 2.727161849682201

Epoch: 6| Step: 5
Training loss: 3.3140508512142044
Validation loss: 2.7673539521391293

Epoch: 6| Step: 6
Training loss: 2.2123270689198486
Validation loss: 2.7608038452942285

Epoch: 6| Step: 7
Training loss: 2.4713264252070704
Validation loss: 2.7674163843581683

Epoch: 6| Step: 8
Training loss: 2.679947554089385
Validation loss: 2.7579529773056692

Epoch: 6| Step: 9
Training loss: 3.4986171715460825
Validation loss: 2.758976488483001

Epoch: 6| Step: 10
Training loss: 2.619393492232673
Validation loss: 2.7498380272113145

Epoch: 6| Step: 11
Training loss: 2.5606699665898787
Validation loss: 2.775068868085357

Epoch: 6| Step: 12
Training loss: 3.6568296576182524
Validation loss: 2.7760019520972024

Epoch: 6| Step: 13
Training loss: 2.50996282967937
Validation loss: 2.767405330936166

Epoch: 54| Step: 0
Training loss: 3.129749503547537
Validation loss: 2.745060247566311

Epoch: 6| Step: 1
Training loss: 2.2775675694714965
Validation loss: 2.7514940642537815

Epoch: 6| Step: 2
Training loss: 4.173357639384151
Validation loss: 2.788840002621169

Epoch: 6| Step: 3
Training loss: 2.705868425845625
Validation loss: 2.785377570851894

Epoch: 6| Step: 4
Training loss: 2.722014560909972
Validation loss: 2.762393101921832

Epoch: 6| Step: 5
Training loss: 2.7781294557688008
Validation loss: 2.7467520757360124

Epoch: 6| Step: 6
Training loss: 2.8506829564468004
Validation loss: 2.753831406560089

Epoch: 6| Step: 7
Training loss: 3.0133807275921556
Validation loss: 2.744376836046137

Epoch: 6| Step: 8
Training loss: 3.5281954357053036
Validation loss: 2.7644124831536034

Epoch: 6| Step: 9
Training loss: 2.5332117837891723
Validation loss: 2.7543223989163517

Epoch: 6| Step: 10
Training loss: 2.5096193263537017
Validation loss: 2.7650681877113716

Epoch: 6| Step: 11
Training loss: 2.836039895975538
Validation loss: 2.784881006126951

Epoch: 6| Step: 12
Training loss: 2.306888473334973
Validation loss: 2.7808207685001536

Epoch: 6| Step: 13
Training loss: 2.722676828489977
Validation loss: 2.7765854806138464

Epoch: 55| Step: 0
Training loss: 2.5272609219546682
Validation loss: 2.738021463071467

Epoch: 6| Step: 1
Training loss: 2.6941972719674965
Validation loss: 2.738884614531509

Epoch: 6| Step: 2
Training loss: 2.052441896459504
Validation loss: 2.7603191325222536

Epoch: 6| Step: 3
Training loss: 3.7614342887967016
Validation loss: 2.7847409518833044

Epoch: 6| Step: 4
Training loss: 2.3448003831179154
Validation loss: 2.7741247226655887

Epoch: 6| Step: 5
Training loss: 2.9569835180262514
Validation loss: 2.7740445508088594

Epoch: 6| Step: 6
Training loss: 3.5469513603426703
Validation loss: 2.7717505919907137

Epoch: 6| Step: 7
Training loss: 2.7142352622943413
Validation loss: 2.785068635020251

Epoch: 6| Step: 8
Training loss: 3.0965121490668897
Validation loss: 2.7469989775558807

Epoch: 6| Step: 9
Training loss: 2.9395292050474104
Validation loss: 2.777366589975445

Epoch: 6| Step: 10
Training loss: 2.5852038676815385
Validation loss: 2.7725753597304186

Epoch: 6| Step: 11
Training loss: 2.819089671981776
Validation loss: 2.7549374128479225

Epoch: 6| Step: 12
Training loss: 3.299209997231907
Validation loss: 2.7620090302417615

Epoch: 6| Step: 13
Training loss: 2.726333389930835
Validation loss: 2.754953083470898

Epoch: 56| Step: 0
Training loss: 2.9206765720965997
Validation loss: 2.766080592270148

Epoch: 6| Step: 1
Training loss: 3.651920461350476
Validation loss: 2.7648318908763643

Epoch: 6| Step: 2
Training loss: 2.6666745444022486
Validation loss: 2.752345665820569

Epoch: 6| Step: 3
Training loss: 2.45196214072293
Validation loss: 2.770407411190338

Epoch: 6| Step: 4
Training loss: 3.4904349279607154
Validation loss: 2.773109055395424

Epoch: 6| Step: 5
Training loss: 2.2648810908281303
Validation loss: 2.7774193970074714

Epoch: 6| Step: 6
Training loss: 3.3547874176397094
Validation loss: 2.779637080011067

Epoch: 6| Step: 7
Training loss: 2.4344456438384396
Validation loss: 2.752061560561292

Epoch: 6| Step: 8
Training loss: 3.1085164020480507
Validation loss: 2.7760780069053954

Epoch: 6| Step: 9
Training loss: 2.3668337516726097
Validation loss: 2.7522212246907096

Epoch: 6| Step: 10
Training loss: 2.5492131084972436
Validation loss: 2.756909822481978

Epoch: 6| Step: 11
Training loss: 2.9111436231349086
Validation loss: 2.7634834965416952

Epoch: 6| Step: 12
Training loss: 3.0624634098280494
Validation loss: 2.7331492236950052

Epoch: 6| Step: 13
Training loss: 3.281286766209569
Validation loss: 2.766332144873728

Epoch: 57| Step: 0
Training loss: 3.6156380879817274
Validation loss: 2.8049242852780027

Epoch: 6| Step: 1
Training loss: 3.14675366073981
Validation loss: 2.7549272473676325

Epoch: 6| Step: 2
Training loss: 2.9826194832619186
Validation loss: 2.7514422257498627

Epoch: 6| Step: 3
Training loss: 3.2651330312642743
Validation loss: 2.7249300415731694

Epoch: 6| Step: 4
Training loss: 2.4519880053178595
Validation loss: 2.752049934053071

Epoch: 6| Step: 5
Training loss: 2.35868997292283
Validation loss: 2.7394393820069824

Epoch: 6| Step: 6
Training loss: 2.699571865187156
Validation loss: 2.7483484076068856

Epoch: 6| Step: 7
Training loss: 2.939805769440582
Validation loss: 2.734818202136448

Epoch: 6| Step: 8
Training loss: 2.6849450675132935
Validation loss: 2.7545838826102735

Epoch: 6| Step: 9
Training loss: 3.4370804964194814
Validation loss: 2.7429756289633858

Epoch: 6| Step: 10
Training loss: 2.8256940141099767
Validation loss: 2.7482455950857405

Epoch: 6| Step: 11
Training loss: 3.1435721314850738
Validation loss: 2.747683460175821

Epoch: 6| Step: 12
Training loss: 2.051069548187946
Validation loss: 2.7438241133148904

Epoch: 6| Step: 13
Training loss: 2.341121369355345
Validation loss: 2.75981438246687

Epoch: 58| Step: 0
Training loss: 2.7974670465486953
Validation loss: 2.7548888482394776

Epoch: 6| Step: 1
Training loss: 2.751730634414459
Validation loss: 2.766563688655537

Epoch: 6| Step: 2
Training loss: 2.0603945996755257
Validation loss: 2.744218467134134

Epoch: 6| Step: 3
Training loss: 2.7049392168757116
Validation loss: 2.7454314462958918

Epoch: 6| Step: 4
Training loss: 3.497473486035664
Validation loss: 2.7508597871060916

Epoch: 6| Step: 5
Training loss: 2.5519690559388613
Validation loss: 2.7618640494128077

Epoch: 6| Step: 6
Training loss: 2.676233852004573
Validation loss: 2.7464030449632584

Epoch: 6| Step: 7
Training loss: 2.913517059742343
Validation loss: 2.7588978761235765

Epoch: 6| Step: 8
Training loss: 3.6802293900852785
Validation loss: 2.746283817909285

Epoch: 6| Step: 9
Training loss: 2.3746552468092563
Validation loss: 2.7649546851937403

Epoch: 6| Step: 10
Training loss: 2.907177520738106
Validation loss: 2.737639100178103

Epoch: 6| Step: 11
Training loss: 2.8927597823402476
Validation loss: 2.757596080614744

Epoch: 6| Step: 12
Training loss: 3.3508318480328887
Validation loss: 2.7643416856886494

Epoch: 6| Step: 13
Training loss: 3.2492782084699363
Validation loss: 2.743030464456021

Epoch: 59| Step: 0
Training loss: 3.0258046427796836
Validation loss: 2.7414532409275894

Epoch: 6| Step: 1
Training loss: 2.7588032355830623
Validation loss: 2.7749675656823043

Epoch: 6| Step: 2
Training loss: 3.00231605773114
Validation loss: 2.7403773353385525

Epoch: 6| Step: 3
Training loss: 2.9942718497010437
Validation loss: 2.7328649276595356

Epoch: 6| Step: 4
Training loss: 3.026504735045839
Validation loss: 2.7375505375389166

Epoch: 6| Step: 5
Training loss: 3.3035723741449012
Validation loss: 2.7545974547071417

Epoch: 6| Step: 6
Training loss: 3.4529204847436614
Validation loss: 2.7351321680078415

Epoch: 6| Step: 7
Training loss: 2.64061109550472
Validation loss: 2.760115391145753

Epoch: 6| Step: 8
Training loss: 2.575423981658697
Validation loss: 2.7304456698309085

Epoch: 6| Step: 9
Training loss: 3.253373082913482
Validation loss: 2.760505606730942

Epoch: 6| Step: 10
Training loss: 1.8908242995459785
Validation loss: 2.745236265844238

Epoch: 6| Step: 11
Training loss: 2.391753186068761
Validation loss: 2.746749317728856

Epoch: 6| Step: 12
Training loss: 2.6028659064229274
Validation loss: 2.746087442867906

Epoch: 6| Step: 13
Training loss: 3.0899142752796007
Validation loss: 2.7727644657608788

Epoch: 60| Step: 0
Training loss: 2.8289073894575343
Validation loss: 2.7632816454451277

Epoch: 6| Step: 1
Training loss: 3.0095536381989088
Validation loss: 2.724022170786027

Epoch: 6| Step: 2
Training loss: 3.4252741404618834
Validation loss: 2.7439036172127906

Epoch: 6| Step: 3
Training loss: 2.1453321174008035
Validation loss: 2.7564232605168724

Epoch: 6| Step: 4
Training loss: 2.427818732664269
Validation loss: 2.759165831550824

Epoch: 6| Step: 5
Training loss: 3.1703662008566424
Validation loss: 2.7403804271855807

Epoch: 6| Step: 6
Training loss: 2.5611579916472764
Validation loss: 2.7418829991301776

Epoch: 6| Step: 7
Training loss: 2.891157441461526
Validation loss: 2.7616484005422777

Epoch: 6| Step: 8
Training loss: 2.4820138519416988
Validation loss: 2.765484369177526

Epoch: 6| Step: 9
Training loss: 2.7189367822086217
Validation loss: 2.7559993955975655

Epoch: 6| Step: 10
Training loss: 3.1844189282383155
Validation loss: 2.756756712640944

Epoch: 6| Step: 11
Training loss: 3.8033723222593547
Validation loss: 2.775763853164696

Epoch: 6| Step: 12
Training loss: 2.687480128015194
Validation loss: 2.7354019275856727

Epoch: 6| Step: 13
Training loss: 2.3854604547693326
Validation loss: 2.7592011208441303

Epoch: 61| Step: 0
Training loss: 2.229126748651578
Validation loss: 2.7705030673914037

Epoch: 6| Step: 1
Training loss: 3.6031750029562417
Validation loss: 2.7638270755841208

Epoch: 6| Step: 2
Training loss: 3.041828534422134
Validation loss: 2.7295548658365294

Epoch: 6| Step: 3
Training loss: 2.5302368773892856
Validation loss: 2.7360841308943673

Epoch: 6| Step: 4
Training loss: 3.3138259537092547
Validation loss: 2.762971649346085

Epoch: 6| Step: 5
Training loss: 2.4478886595943266
Validation loss: 2.7655481052386355

Epoch: 6| Step: 6
Training loss: 3.2823195394633755
Validation loss: 2.763106493266574

Epoch: 6| Step: 7
Training loss: 2.296690226278546
Validation loss: 2.728329530509416

Epoch: 6| Step: 8
Training loss: 3.568093175620854
Validation loss: 2.704204200449889

Epoch: 6| Step: 9
Training loss: 2.1850130385439757
Validation loss: 2.7569837631359304

Epoch: 6| Step: 10
Training loss: 3.6368855275265446
Validation loss: 2.7295918378100246

Epoch: 6| Step: 11
Training loss: 2.4904262334180225
Validation loss: 2.7485599233790485

Epoch: 6| Step: 12
Training loss: 2.609982539736052
Validation loss: 2.7518440498090824

Epoch: 6| Step: 13
Training loss: 2.2314694593195705
Validation loss: 2.7500163373340665

Epoch: 62| Step: 0
Training loss: 2.17630935368897
Validation loss: 2.7286616702560376

Epoch: 6| Step: 1
Training loss: 3.291204556891403
Validation loss: 2.735769934112597

Epoch: 6| Step: 2
Training loss: 3.1657762948849326
Validation loss: 2.753187978086417

Epoch: 6| Step: 3
Training loss: 2.8486393407642883
Validation loss: 2.7431164716882406

Epoch: 6| Step: 4
Training loss: 3.25651352414615
Validation loss: 2.7506065836987856

Epoch: 6| Step: 5
Training loss: 3.364915545963929
Validation loss: 2.757780332208341

Epoch: 6| Step: 6
Training loss: 2.6574701536122824
Validation loss: 2.7391139738496295

Epoch: 6| Step: 7
Training loss: 2.9101498597350144
Validation loss: 2.754868426616186

Epoch: 6| Step: 8
Training loss: 2.5800991938248394
Validation loss: 2.7325616320681965

Epoch: 6| Step: 9
Training loss: 3.1653857066324367
Validation loss: 2.8009426062283005

Epoch: 6| Step: 10
Training loss: 2.5321465305637614
Validation loss: 2.732778728183116

Epoch: 6| Step: 11
Training loss: 3.2010287240624615
Validation loss: 2.7252957097713257

Epoch: 6| Step: 12
Training loss: 2.281888271555447
Validation loss: 2.7497205993177207

Epoch: 6| Step: 13
Training loss: 2.0322534283498688
Validation loss: 2.794090759171212

Epoch: 63| Step: 0
Training loss: 2.828520857784139
Validation loss: 2.748572155060156

Epoch: 6| Step: 1
Training loss: 2.025920743365455
Validation loss: 2.7406460800629557

Epoch: 6| Step: 2
Training loss: 3.0909602370084897
Validation loss: 2.7410167523592213

Epoch: 6| Step: 3
Training loss: 3.3623459564432907
Validation loss: 2.7354525119838464

Epoch: 6| Step: 4
Training loss: 2.554693659503756
Validation loss: 2.753934134356204

Epoch: 6| Step: 5
Training loss: 2.7905291806779826
Validation loss: 2.76262287955533

Epoch: 6| Step: 6
Training loss: 2.581942789060014
Validation loss: 2.7430772689043716

Epoch: 6| Step: 7
Training loss: 2.747227311351945
Validation loss: 2.7321611865709428

Epoch: 6| Step: 8
Training loss: 2.784906448354491
Validation loss: 2.7600100864272465

Epoch: 6| Step: 9
Training loss: 3.570654120263907
Validation loss: 2.752287576047388

Epoch: 6| Step: 10
Training loss: 3.0049696132754793
Validation loss: 2.747352143845063

Epoch: 6| Step: 11
Training loss: 3.208366459927314
Validation loss: 2.7688316080411863

Epoch: 6| Step: 12
Training loss: 2.64887569257079
Validation loss: 2.766217722039426

Epoch: 6| Step: 13
Training loss: 1.8627282047637512
Validation loss: 2.757526719758917

Epoch: 64| Step: 0
Training loss: 2.7673018377495717
Validation loss: 2.738610333046399

Epoch: 6| Step: 1
Training loss: 3.184307069961706
Validation loss: 2.749913222658157

Epoch: 6| Step: 2
Training loss: 2.606270044922073
Validation loss: 2.752632847781652

Epoch: 6| Step: 3
Training loss: 2.975294108238306
Validation loss: 2.7309767234593334

Epoch: 6| Step: 4
Training loss: 2.906273954559376
Validation loss: 2.745620033421743

Epoch: 6| Step: 5
Training loss: 2.736926996887477
Validation loss: 2.720862015579896

Epoch: 6| Step: 6
Training loss: 2.7630089925259997
Validation loss: 2.7044129602211786

Epoch: 6| Step: 7
Training loss: 2.703191502805949
Validation loss: 2.6965879851545176

Epoch: 6| Step: 8
Training loss: 2.6385897405506618
Validation loss: 2.746114373175236

Epoch: 6| Step: 9
Training loss: 3.1326767280819157
Validation loss: 2.7306941389749544

Epoch: 6| Step: 10
Training loss: 2.8356287764552905
Validation loss: 2.756644195925532

Epoch: 6| Step: 11
Training loss: 2.695355224270757
Validation loss: 2.754854450116981

Epoch: 6| Step: 12
Training loss: 3.0821732753041355
Validation loss: 2.7509045031638806

Epoch: 6| Step: 13
Training loss: 3.15370029913786
Validation loss: 2.7392133124991216

Epoch: 65| Step: 0
Training loss: 2.5516398972349394
Validation loss: 2.761573624894209

Epoch: 6| Step: 1
Training loss: 2.8959785992163583
Validation loss: 2.7258491075288136

Epoch: 6| Step: 2
Training loss: 2.9562792205979394
Validation loss: 2.7248103067951357

Epoch: 6| Step: 3
Training loss: 2.3701414304294244
Validation loss: 2.7512215635435404

Epoch: 6| Step: 4
Training loss: 2.4416121006967004
Validation loss: 2.7356686158726724

Epoch: 6| Step: 5
Training loss: 2.719441643794532
Validation loss: 2.7381311900115395

Epoch: 6| Step: 6
Training loss: 3.0705600473719126
Validation loss: 2.719142528576126

Epoch: 6| Step: 7
Training loss: 2.8574687669704155
Validation loss: 2.741491921756268

Epoch: 6| Step: 8
Training loss: 2.861543760539308
Validation loss: 2.7386584730183405

Epoch: 6| Step: 9
Training loss: 2.668128437496642
Validation loss: 2.752082147399518

Epoch: 6| Step: 10
Training loss: 2.96251352685343
Validation loss: 2.750251105059909

Epoch: 6| Step: 11
Training loss: 3.776815036194777
Validation loss: 2.712956428224419

Epoch: 6| Step: 12
Training loss: 2.5920203083149334
Validation loss: 2.740178781872445

Epoch: 6| Step: 13
Training loss: 3.346456270354802
Validation loss: 2.729203756932509

Epoch: 66| Step: 0
Training loss: 2.419348598800324
Validation loss: 2.763542238751374

Epoch: 6| Step: 1
Training loss: 2.583266893168244
Validation loss: 2.7512362704041364

Epoch: 6| Step: 2
Training loss: 3.034229190988589
Validation loss: 2.723325099353746

Epoch: 6| Step: 3
Training loss: 2.981692401681815
Validation loss: 2.7827107970544844

Epoch: 6| Step: 4
Training loss: 2.9026420922536516
Validation loss: 2.7084428681467396

Epoch: 6| Step: 5
Training loss: 2.8846962002902057
Validation loss: 2.7392043708579226

Epoch: 6| Step: 6
Training loss: 2.7982316802485165
Validation loss: 2.7277901008491954

Epoch: 6| Step: 7
Training loss: 3.2478062488382333
Validation loss: 2.737624206961693

Epoch: 6| Step: 8
Training loss: 3.4485448781672248
Validation loss: 2.746894491542003

Epoch: 6| Step: 9
Training loss: 2.864873050719826
Validation loss: 2.757399623310807

Epoch: 6| Step: 10
Training loss: 2.2103141202398895
Validation loss: 2.7191218922253024

Epoch: 6| Step: 11
Training loss: 3.113549884995026
Validation loss: 2.7470016037240588

Epoch: 6| Step: 12
Training loss: 2.556931283163963
Validation loss: 2.767024729830406

Epoch: 6| Step: 13
Training loss: 2.9709756639652944
Validation loss: 2.7482988329337252

Epoch: 67| Step: 0
Training loss: 2.707847747309184
Validation loss: 2.728676253494422

Epoch: 6| Step: 1
Training loss: 2.7724108877901386
Validation loss: 2.7182119032902143

Epoch: 6| Step: 2
Training loss: 2.2113930600188785
Validation loss: 2.740950070175609

Epoch: 6| Step: 3
Training loss: 2.37371671037598
Validation loss: 2.730658042839099

Epoch: 6| Step: 4
Training loss: 3.128960350607113
Validation loss: 2.7624311415268505

Epoch: 6| Step: 5
Training loss: 2.6168516940000845
Validation loss: 2.725366882834955

Epoch: 6| Step: 6
Training loss: 3.0159265238971567
Validation loss: 2.7287261696326888

Epoch: 6| Step: 7
Training loss: 3.0719480550467115
Validation loss: 2.7226749340136664

Epoch: 6| Step: 8
Training loss: 2.6313872059185672
Validation loss: 2.769950411143793

Epoch: 6| Step: 9
Training loss: 2.8039978369515386
Validation loss: 2.7452917252725944

Epoch: 6| Step: 10
Training loss: 3.2159316677596275
Validation loss: 2.7304253545763704

Epoch: 6| Step: 11
Training loss: 3.5841564002056683
Validation loss: 2.7446640429251596

Epoch: 6| Step: 12
Training loss: 2.6817298868747437
Validation loss: 2.724641051843189

Epoch: 6| Step: 13
Training loss: 2.7748964582491915
Validation loss: 2.7477267201901983

Epoch: 68| Step: 0
Training loss: 2.6610064835266924
Validation loss: 2.738533394017339

Epoch: 6| Step: 1
Training loss: 3.039364679606521
Validation loss: 2.7363138153610094

Epoch: 6| Step: 2
Training loss: 2.2370766265800817
Validation loss: 2.771577952149743

Epoch: 6| Step: 3
Training loss: 2.6427556758534942
Validation loss: 2.7325488661934214

Epoch: 6| Step: 4
Training loss: 3.4076708708676895
Validation loss: 2.7422781584168705

Epoch: 6| Step: 5
Training loss: 2.6339277401384793
Validation loss: 2.756870799101596

Epoch: 6| Step: 6
Training loss: 2.300354171518509
Validation loss: 2.7060461715590476

Epoch: 6| Step: 7
Training loss: 2.86463719172854
Validation loss: 2.717809004850814

Epoch: 6| Step: 8
Training loss: 2.1464388341819287
Validation loss: 2.716944796642665

Epoch: 6| Step: 9
Training loss: 3.038962865142536
Validation loss: 2.765400336931318

Epoch: 6| Step: 10
Training loss: 3.310462180885657
Validation loss: 2.7698013606922256

Epoch: 6| Step: 11
Training loss: 3.5204954869323073
Validation loss: 2.740334427999935

Epoch: 6| Step: 12
Training loss: 2.913944027207999
Validation loss: 2.716395090785755

Epoch: 6| Step: 13
Training loss: 2.3764340939716218
Validation loss: 2.755177782399039

Epoch: 69| Step: 0
Training loss: 2.8805875798694007
Validation loss: 2.733219051698219

Epoch: 6| Step: 1
Training loss: 3.747182805110334
Validation loss: 2.719433436562322

Epoch: 6| Step: 2
Training loss: 3.0075452016983535
Validation loss: 2.7295783254641113

Epoch: 6| Step: 3
Training loss: 3.0626021387623243
Validation loss: 2.74154636612716

Epoch: 6| Step: 4
Training loss: 2.4783801800067704
Validation loss: 2.747646008541412

Epoch: 6| Step: 5
Training loss: 2.8413328860369216
Validation loss: 2.7554422561441427

Epoch: 6| Step: 6
Training loss: 2.701744829757627
Validation loss: 2.7291624446016813

Epoch: 6| Step: 7
Training loss: 2.506230981616685
Validation loss: 2.7349527403195206

Epoch: 6| Step: 8
Training loss: 2.0864932573594843
Validation loss: 2.7410978125892647

Epoch: 6| Step: 9
Training loss: 2.815372441318804
Validation loss: 2.72022901377722

Epoch: 6| Step: 10
Training loss: 2.981628432337019
Validation loss: 2.752537234623947

Epoch: 6| Step: 11
Training loss: 3.1897229689603734
Validation loss: 2.7631619275629293

Epoch: 6| Step: 12
Training loss: 2.386432436987511
Validation loss: 2.7439200553114005

Epoch: 6| Step: 13
Training loss: 2.180532858933605
Validation loss: 2.769446326919552

Epoch: 70| Step: 0
Training loss: 2.335733972568964
Validation loss: 2.755283625373567

Epoch: 6| Step: 1
Training loss: 2.9276798133779325
Validation loss: 2.7411062710725878

Epoch: 6| Step: 2
Training loss: 2.168391775838529
Validation loss: 2.762625173504702

Epoch: 6| Step: 3
Training loss: 3.1744641790539516
Validation loss: 2.7569994593222193

Epoch: 6| Step: 4
Training loss: 3.2601764984562456
Validation loss: 2.726434101626571

Epoch: 6| Step: 5
Training loss: 2.5883877028506674
Validation loss: 2.75456194449538

Epoch: 6| Step: 6
Training loss: 2.4803275481156035
Validation loss: 2.757174618235072

Epoch: 6| Step: 7
Training loss: 2.5820660610420494
Validation loss: 2.729420488946405

Epoch: 6| Step: 8
Training loss: 3.300585931721182
Validation loss: 2.78623592181789

Epoch: 6| Step: 9
Training loss: 2.630509724990395
Validation loss: 2.718221532680953

Epoch: 6| Step: 10
Training loss: 2.9447848305197244
Validation loss: 2.7474799080290895

Epoch: 6| Step: 11
Training loss: 3.7884197515814377
Validation loss: 2.732578525862533

Epoch: 6| Step: 12
Training loss: 2.348267436008788
Validation loss: 2.7523934006967696

Epoch: 6| Step: 13
Training loss: 2.6842461338574943
Validation loss: 2.756535874602608

Epoch: 71| Step: 0
Training loss: 1.7693929386610727
Validation loss: 2.7563680673788835

Epoch: 6| Step: 1
Training loss: 3.032354094791895
Validation loss: 2.740417662853284

Epoch: 6| Step: 2
Training loss: 2.414328551214695
Validation loss: 2.722287204330422

Epoch: 6| Step: 3
Training loss: 2.4934115378546986
Validation loss: 2.7418584685515173

Epoch: 6| Step: 4
Training loss: 3.7116408153422196
Validation loss: 2.718689125406395

Epoch: 6| Step: 5
Training loss: 3.180034046830547
Validation loss: 2.714380239852657

Epoch: 6| Step: 6
Training loss: 3.002963192140325
Validation loss: 2.75596795918668

Epoch: 6| Step: 7
Training loss: 2.381851753035335
Validation loss: 2.7384592669300822

Epoch: 6| Step: 8
Training loss: 2.780190512489402
Validation loss: 2.7047468198812736

Epoch: 6| Step: 9
Training loss: 2.9218665138162194
Validation loss: 2.7531488090683958

Epoch: 6| Step: 10
Training loss: 2.485608448475113
Validation loss: 2.7284637469024657

Epoch: 6| Step: 11
Training loss: 3.1339994926330506
Validation loss: 2.756802936253108

Epoch: 6| Step: 12
Training loss: 2.745846472686064
Validation loss: 2.741561224945457

Epoch: 6| Step: 13
Training loss: 3.3254181505728972
Validation loss: 2.7356278603655553

Epoch: 72| Step: 0
Training loss: 3.072008901881195
Validation loss: 2.7206897710975047

Epoch: 6| Step: 1
Training loss: 2.42296925097078
Validation loss: 2.7670831689500197

Epoch: 6| Step: 2
Training loss: 2.6618491008472196
Validation loss: 2.72409275317524

Epoch: 6| Step: 3
Training loss: 2.4834077499641065
Validation loss: 2.7281695995259176

Epoch: 6| Step: 4
Training loss: 3.109097415667818
Validation loss: 2.7094603313207215

Epoch: 6| Step: 5
Training loss: 2.7639598251602893
Validation loss: 2.7211779346250617

Epoch: 6| Step: 6
Training loss: 3.4385791818505442
Validation loss: 2.731200880306981

Epoch: 6| Step: 7
Training loss: 2.88191883326006
Validation loss: 2.7610277096690474

Epoch: 6| Step: 8
Training loss: 2.7002824600256394
Validation loss: 2.737589946825006

Epoch: 6| Step: 9
Training loss: 2.9948054481963244
Validation loss: 2.743666512332434

Epoch: 6| Step: 10
Training loss: 3.480591640165272
Validation loss: 2.738268967668912

Epoch: 6| Step: 11
Training loss: 2.5293706816873716
Validation loss: 2.7339013383508

Epoch: 6| Step: 12
Training loss: 2.0385332261035685
Validation loss: 2.7260707189939466

Epoch: 6| Step: 13
Training loss: 2.615757884816789
Validation loss: 2.726495499097228

Epoch: 73| Step: 0
Training loss: 2.8534267236750295
Validation loss: 2.7223029743791027

Epoch: 6| Step: 1
Training loss: 3.0411534507844653
Validation loss: 2.722129450788143

Epoch: 6| Step: 2
Training loss: 2.759881645512196
Validation loss: 2.7349674531131236

Epoch: 6| Step: 3
Training loss: 2.88760828913302
Validation loss: 2.7136153590070395

Epoch: 6| Step: 4
Training loss: 3.641635738098887
Validation loss: 2.7192855965573464

Epoch: 6| Step: 5
Training loss: 2.163724356443705
Validation loss: 2.741588366627449

Epoch: 6| Step: 6
Training loss: 3.364600796649283
Validation loss: 2.7407180256049917

Epoch: 6| Step: 7
Training loss: 2.614463550108548
Validation loss: 2.720475630452469

Epoch: 6| Step: 8
Training loss: 3.2196119321041112
Validation loss: 2.686082403609271

Epoch: 6| Step: 9
Training loss: 2.664573553294551
Validation loss: 2.6959903976799744

Epoch: 6| Step: 10
Training loss: 2.8244564647537165
Validation loss: 2.7498543328778062

Epoch: 6| Step: 11
Training loss: 2.5246660294949588
Validation loss: 2.728699476403148

Epoch: 6| Step: 12
Training loss: 2.1464119535382746
Validation loss: 2.7173027794905535

Epoch: 6| Step: 13
Training loss: 2.3208344254642386
Validation loss: 2.733286225442952

Epoch: 74| Step: 0
Training loss: 2.5291535915013736
Validation loss: 2.730629297400858

Epoch: 6| Step: 1
Training loss: 3.4610124498092136
Validation loss: 2.7629035299365263

Epoch: 6| Step: 2
Training loss: 3.4962102263243944
Validation loss: 2.724240715310278

Epoch: 6| Step: 3
Training loss: 2.724758742965502
Validation loss: 2.717964055932951

Epoch: 6| Step: 4
Training loss: 2.9440610943964907
Validation loss: 2.70462873188183

Epoch: 6| Step: 5
Training loss: 3.0075191998840003
Validation loss: 2.7367801740079973

Epoch: 6| Step: 6
Training loss: 3.0107429793929383
Validation loss: 2.744609283037294

Epoch: 6| Step: 7
Training loss: 3.2242911335995985
Validation loss: 2.726427717985522

Epoch: 6| Step: 8
Training loss: 2.9787538326877487
Validation loss: 2.694377448898223

Epoch: 6| Step: 9
Training loss: 1.9087361866988897
Validation loss: 2.7373564195853337

Epoch: 6| Step: 10
Training loss: 2.33815443292165
Validation loss: 2.7173782922184424

Epoch: 6| Step: 11
Training loss: 2.17829002510494
Validation loss: 2.7316442680235173

Epoch: 6| Step: 12
Training loss: 2.464458743826809
Validation loss: 2.761298111839529

Epoch: 6| Step: 13
Training loss: 2.968026484615477
Validation loss: 2.7260989021766218

Epoch: 75| Step: 0
Training loss: 3.728678296608546
Validation loss: 2.7271439442156393

Epoch: 6| Step: 1
Training loss: 2.622022666000992
Validation loss: 2.7094418196938954

Epoch: 6| Step: 2
Training loss: 2.78426805969448
Validation loss: 2.7394617912225225

Epoch: 6| Step: 3
Training loss: 1.8692065698675953
Validation loss: 2.724063943162919

Epoch: 6| Step: 4
Training loss: 2.577855321477852
Validation loss: 2.7065962184544996

Epoch: 6| Step: 5
Training loss: 2.7541257080941506
Validation loss: 2.730116076368332

Epoch: 6| Step: 6
Training loss: 2.8510711664679027
Validation loss: 2.713048775895533

Epoch: 6| Step: 7
Training loss: 2.2008851481468206
Validation loss: 2.7248852596039224

Epoch: 6| Step: 8
Training loss: 3.056063525043942
Validation loss: 2.7483930954989746

Epoch: 6| Step: 9
Training loss: 2.8975483232209243
Validation loss: 2.7064859613215084

Epoch: 6| Step: 10
Training loss: 2.539922762169524
Validation loss: 2.7437432420153884

Epoch: 6| Step: 11
Training loss: 3.0312245161420726
Validation loss: 2.7440331890638254

Epoch: 6| Step: 12
Training loss: 3.545489069852818
Validation loss: 2.7183096697298867

Epoch: 6| Step: 13
Training loss: 2.211690929349708
Validation loss: 2.750298636731986

Epoch: 76| Step: 0
Training loss: 2.4132781004337147
Validation loss: 2.7318622609746663

Epoch: 6| Step: 1
Training loss: 3.032546719712455
Validation loss: 2.7010317561077315

Epoch: 6| Step: 2
Training loss: 2.7730611196523665
Validation loss: 2.739178464828746

Epoch: 6| Step: 3
Training loss: 2.5577888911794147
Validation loss: 2.718455803078114

Epoch: 6| Step: 4
Training loss: 3.3774663602451174
Validation loss: 2.7085337417199002

Epoch: 6| Step: 5
Training loss: 2.978095993749335
Validation loss: 2.7368239819919813

Epoch: 6| Step: 6
Training loss: 2.47024046897227
Validation loss: 2.7312791850893565

Epoch: 6| Step: 7
Training loss: 2.3504241520001066
Validation loss: 2.7596750236326737

Epoch: 6| Step: 8
Training loss: 3.34786733809764
Validation loss: 2.736516632177688

Epoch: 6| Step: 9
Training loss: 2.0385830487271344
Validation loss: 2.7185868179030175

Epoch: 6| Step: 10
Training loss: 2.719112766661855
Validation loss: 2.7520210226704274

Epoch: 6| Step: 11
Training loss: 3.093406581121054
Validation loss: 2.707152180227965

Epoch: 6| Step: 12
Training loss: 2.6400049147415654
Validation loss: 2.712129935927582

Epoch: 6| Step: 13
Training loss: 3.8100140080231997
Validation loss: 2.7547448560480463

Epoch: 77| Step: 0
Training loss: 2.456034690214316
Validation loss: 2.7082289518651304

Epoch: 6| Step: 1
Training loss: 3.063347679688486
Validation loss: 2.756580483705239

Epoch: 6| Step: 2
Training loss: 2.09706741109688
Validation loss: 2.7298200987189944

Epoch: 6| Step: 3
Training loss: 2.4320137687469026
Validation loss: 2.7262591126127687

Epoch: 6| Step: 4
Training loss: 2.707673760330593
Validation loss: 2.7142529265888915

Epoch: 6| Step: 5
Training loss: 2.417960270141128
Validation loss: 2.731493748625974

Epoch: 6| Step: 6
Training loss: 2.4034601858296227
Validation loss: 2.7204300419969836

Epoch: 6| Step: 7
Training loss: 2.3286261307211267
Validation loss: 2.7492294779567934

Epoch: 6| Step: 8
Training loss: 3.125112607834397
Validation loss: 2.76375903662446

Epoch: 6| Step: 9
Training loss: 3.76608843345759
Validation loss: 2.71921637003594

Epoch: 6| Step: 10
Training loss: 2.2243458204078497
Validation loss: 2.7517856508600986

Epoch: 6| Step: 11
Training loss: 3.2675646994269916
Validation loss: 2.761077273528974

Epoch: 6| Step: 12
Training loss: 3.016433054131345
Validation loss: 2.7282736055334196

Epoch: 6| Step: 13
Training loss: 3.7369757498305733
Validation loss: 2.736806950476846

Epoch: 78| Step: 0
Training loss: 2.929763670884791
Validation loss: 2.7307974470688574

Epoch: 6| Step: 1
Training loss: 2.1492872742378872
Validation loss: 2.7348083105886714

Epoch: 6| Step: 2
Training loss: 2.1698146350638132
Validation loss: 2.728949384972355

Epoch: 6| Step: 3
Training loss: 2.821925919623601
Validation loss: 2.7542812753295935

Epoch: 6| Step: 4
Training loss: 3.740368108126465
Validation loss: 2.712631161322204

Epoch: 6| Step: 5
Training loss: 2.6413741093157874
Validation loss: 2.7150439201801166

Epoch: 6| Step: 6
Training loss: 2.4488143465351526
Validation loss: 2.7312858615044417

Epoch: 6| Step: 7
Training loss: 2.505509219007825
Validation loss: 2.7387593371172034

Epoch: 6| Step: 8
Training loss: 3.0929101902292957
Validation loss: 2.7239478916197175

Epoch: 6| Step: 9
Training loss: 2.5016010879504478
Validation loss: 2.6851706076524007

Epoch: 6| Step: 10
Training loss: 3.2190326455467493
Validation loss: 2.737226886641714

Epoch: 6| Step: 11
Training loss: 2.8045020932090976
Validation loss: 2.699982100563772

Epoch: 6| Step: 12
Training loss: 2.963212641377601
Validation loss: 2.7097547465952676

Epoch: 6| Step: 13
Training loss: 3.1254754277021477
Validation loss: 2.7335960148160594

Epoch: 79| Step: 0
Training loss: 2.920338272462687
Validation loss: 2.698143289157299

Epoch: 6| Step: 1
Training loss: 2.541249246142154
Validation loss: 2.7024546777304326

Epoch: 6| Step: 2
Training loss: 2.0711586428692237
Validation loss: 2.70413953757818

Epoch: 6| Step: 3
Training loss: 3.0985603312019974
Validation loss: 2.74631456330959

Epoch: 6| Step: 4
Training loss: 2.9789267134345
Validation loss: 2.722318062536748

Epoch: 6| Step: 5
Training loss: 3.654939856915024
Validation loss: 2.716142730259642

Epoch: 6| Step: 6
Training loss: 2.6975611939794195
Validation loss: 2.729140452434632

Epoch: 6| Step: 7
Training loss: 2.6641338260532894
Validation loss: 2.7102035361546477

Epoch: 6| Step: 8
Training loss: 2.560014496255601
Validation loss: 2.7171761390672935

Epoch: 6| Step: 9
Training loss: 3.14601015179276
Validation loss: 2.7386265099162665

Epoch: 6| Step: 10
Training loss: 2.768069291664244
Validation loss: 2.6846848357571913

Epoch: 6| Step: 11
Training loss: 2.003868414984565
Validation loss: 2.7282989244663374

Epoch: 6| Step: 12
Training loss: 3.1718737973365947
Validation loss: 2.7100802792670002

Epoch: 6| Step: 13
Training loss: 2.250692578852824
Validation loss: 2.694389657283683

Epoch: 80| Step: 0
Training loss: 2.5374771568134555
Validation loss: 2.6928797484604385

Epoch: 6| Step: 1
Training loss: 3.366533326507963
Validation loss: 2.731826625091466

Epoch: 6| Step: 2
Training loss: 3.23223732597232
Validation loss: 2.7353619445933424

Epoch: 6| Step: 3
Training loss: 3.4031234531031265
Validation loss: 2.7544354237204742

Epoch: 6| Step: 4
Training loss: 3.8162770556913053
Validation loss: 2.7482307826688928

Epoch: 6| Step: 5
Training loss: 2.6037905205235052
Validation loss: 2.7546558382518564

Epoch: 6| Step: 6
Training loss: 2.8169048148456985
Validation loss: 2.7374093578685237

Epoch: 6| Step: 7
Training loss: 1.9304701110019926
Validation loss: 2.737870853713012

Epoch: 6| Step: 8
Training loss: 3.104527207159357
Validation loss: 2.7489377708247167

Epoch: 6| Step: 9
Training loss: 2.380598897352703
Validation loss: 2.7263920336363046

Epoch: 6| Step: 10
Training loss: 2.3636121281801863
Validation loss: 2.7680202906151363

Epoch: 6| Step: 11
Training loss: 1.9200059439646584
Validation loss: 2.7451419765946476

Epoch: 6| Step: 12
Training loss: 2.4268820901590815
Validation loss: 2.7303308529019215

Epoch: 6| Step: 13
Training loss: 2.467804739858854
Validation loss: 2.6965549206282406

Epoch: 81| Step: 0
Training loss: 2.8096207185585245
Validation loss: 2.6724739912086237

Epoch: 6| Step: 1
Training loss: 2.7215326910765985
Validation loss: 2.737351355715084

Epoch: 6| Step: 2
Training loss: 2.097529402152806
Validation loss: 2.715163873198022

Epoch: 6| Step: 3
Training loss: 2.8362619934231947
Validation loss: 2.7581096411122714

Epoch: 6| Step: 4
Training loss: 2.9495031358644326
Validation loss: 2.714682740271886

Epoch: 6| Step: 5
Training loss: 3.260748475632227
Validation loss: 2.73802268870278

Epoch: 6| Step: 6
Training loss: 2.5318290142402256
Validation loss: 2.7033791409247954

Epoch: 6| Step: 7
Training loss: 2.7899917208641023
Validation loss: 2.7147655075341355

Epoch: 6| Step: 8
Training loss: 3.5841581297288445
Validation loss: 2.7224932248222493

Epoch: 6| Step: 9
Training loss: 2.8438405452188875
Validation loss: 2.7275092935150496

Epoch: 6| Step: 10
Training loss: 2.2088796791474823
Validation loss: 2.7115037452080237

Epoch: 6| Step: 11
Training loss: 3.362503653031531
Validation loss: 2.7420947836313103

Epoch: 6| Step: 12
Training loss: 2.063946303534099
Validation loss: 2.7410805289198934

Epoch: 6| Step: 13
Training loss: 2.5234469481489143
Validation loss: 2.7512168354896698

Epoch: 82| Step: 0
Training loss: 2.041078703421201
Validation loss: 2.714464009886567

Epoch: 6| Step: 1
Training loss: 2.077400712304302
Validation loss: 2.7202308119437313

Epoch: 6| Step: 2
Training loss: 2.9880125236606245
Validation loss: 2.7303225873239056

Epoch: 6| Step: 3
Training loss: 2.742441453613069
Validation loss: 2.7460124992879194

Epoch: 6| Step: 4
Training loss: 3.144893800673894
Validation loss: 2.72139882053378

Epoch: 6| Step: 5
Training loss: 3.390524585836694
Validation loss: 2.718519710961509

Epoch: 6| Step: 6
Training loss: 2.704095743323912
Validation loss: 2.7559418516702126

Epoch: 6| Step: 7
Training loss: 2.950745446369446
Validation loss: 2.736468127568328

Epoch: 6| Step: 8
Training loss: 2.708050600601828
Validation loss: 2.7261522734744363

Epoch: 6| Step: 9
Training loss: 2.6921641662613753
Validation loss: 2.7374748582819057

Epoch: 6| Step: 10
Training loss: 3.4821066550584217
Validation loss: 2.7207666616159627

Epoch: 6| Step: 11
Training loss: 2.2088129734286954
Validation loss: 2.741809899490125

Epoch: 6| Step: 12
Training loss: 2.8221267402029544
Validation loss: 2.7183442398212327

Epoch: 6| Step: 13
Training loss: 2.491679364005135
Validation loss: 2.749934379339139

Epoch: 83| Step: 0
Training loss: 3.2485442202286934
Validation loss: 2.7384394043156255

Epoch: 6| Step: 1
Training loss: 3.1242154471705943
Validation loss: 2.7168249892527037

Epoch: 6| Step: 2
Training loss: 2.201244011198754
Validation loss: 2.718650366259131

Epoch: 6| Step: 3
Training loss: 2.254810911992474
Validation loss: 2.7236394276518014

Epoch: 6| Step: 4
Training loss: 3.624884768002816
Validation loss: 2.716373823413329

Epoch: 6| Step: 5
Training loss: 2.8811293239518854
Validation loss: 2.722119292755622

Epoch: 6| Step: 6
Training loss: 2.19530294287288
Validation loss: 2.681090001141493

Epoch: 6| Step: 7
Training loss: 2.556358980499925
Validation loss: 2.727301728714954

Epoch: 6| Step: 8
Training loss: 2.4289313117814375
Validation loss: 2.7449444458230663

Epoch: 6| Step: 9
Training loss: 2.689021544779092
Validation loss: 2.708900250970382

Epoch: 6| Step: 10
Training loss: 3.4802211754767565
Validation loss: 2.7386797952750777

Epoch: 6| Step: 11
Training loss: 2.095100764216184
Validation loss: 2.7209686488240434

Epoch: 6| Step: 12
Training loss: 3.1935322845962886
Validation loss: 2.6983925789276353

Epoch: 6| Step: 13
Training loss: 1.896283910117466
Validation loss: 2.695082534983388

Epoch: 84| Step: 0
Training loss: 2.7188638246759154
Validation loss: 2.755242977641373

Epoch: 6| Step: 1
Training loss: 3.3677544702841895
Validation loss: 2.7040333869090345

Epoch: 6| Step: 2
Training loss: 1.5224211603807913
Validation loss: 2.711813714376107

Epoch: 6| Step: 3
Training loss: 3.3299077233711736
Validation loss: 2.7057389743928044

Epoch: 6| Step: 4
Training loss: 2.4841255686560673
Validation loss: 2.764256214584087

Epoch: 6| Step: 5
Training loss: 2.6991434928682048
Validation loss: 2.7189502616377563

Epoch: 6| Step: 6
Training loss: 2.4100661299563835
Validation loss: 2.721184362142115

Epoch: 6| Step: 7
Training loss: 2.721050473048944
Validation loss: 2.7328566219037516

Epoch: 6| Step: 8
Training loss: 2.7869627498988447
Validation loss: 2.703385316784598

Epoch: 6| Step: 9
Training loss: 3.405286880260963
Validation loss: 2.7243495500154995

Epoch: 6| Step: 10
Training loss: 2.9119384224218345
Validation loss: 2.7389088956226457

Epoch: 6| Step: 11
Training loss: 2.755873390124267
Validation loss: 2.7356128235948507

Epoch: 6| Step: 12
Training loss: 2.8110631027277013
Validation loss: 2.711329220338934

Epoch: 6| Step: 13
Training loss: 2.485569121126185
Validation loss: 2.7087612057069674

Epoch: 85| Step: 0
Training loss: 3.039191785087438
Validation loss: 2.6788059452679707

Epoch: 6| Step: 1
Training loss: 2.74667156972108
Validation loss: 2.6732552899466913

Epoch: 6| Step: 2
Training loss: 2.7601747418801024
Validation loss: 2.710634568852918

Epoch: 6| Step: 3
Training loss: 1.9008725722545705
Validation loss: 2.7069581032319348

Epoch: 6| Step: 4
Training loss: 2.075275044424176
Validation loss: 2.7333294075588284

Epoch: 6| Step: 5
Training loss: 3.3206054558260485
Validation loss: 2.7091856007549886

Epoch: 6| Step: 6
Training loss: 3.50787353462526
Validation loss: 2.7245731982509818

Epoch: 6| Step: 7
Training loss: 3.2335725977616643
Validation loss: 2.7315152370893183

Epoch: 6| Step: 8
Training loss: 2.7579416563572563
Validation loss: 2.710073349119782

Epoch: 6| Step: 9
Training loss: 1.93774332548982
Validation loss: 2.728673153083044

Epoch: 6| Step: 10
Training loss: 2.494654280689726
Validation loss: 2.7106340879281214

Epoch: 6| Step: 11
Training loss: 3.387309057055505
Validation loss: 2.714566172452046

Epoch: 6| Step: 12
Training loss: 2.267919391511533
Validation loss: 2.707081533054172

Epoch: 6| Step: 13
Training loss: 3.2904991944582616
Validation loss: 2.6700033691877825

Epoch: 86| Step: 0
Training loss: 2.705754406945606
Validation loss: 2.71364268336771

Epoch: 6| Step: 1
Training loss: 2.922744213698574
Validation loss: 2.755598390057525

Epoch: 6| Step: 2
Training loss: 3.288144669944344
Validation loss: 2.701046671704802

Epoch: 6| Step: 3
Training loss: 3.755739143657045
Validation loss: 2.682419940968797

Epoch: 6| Step: 4
Training loss: 1.8600575452537143
Validation loss: 2.7122078876786726

Epoch: 6| Step: 5
Training loss: 2.776018344191918
Validation loss: 2.7259013269340695

Epoch: 6| Step: 6
Training loss: 2.3040880361135554
Validation loss: 2.740999991943363

Epoch: 6| Step: 7
Training loss: 2.4250616950612858
Validation loss: 2.728013147507387

Epoch: 6| Step: 8
Training loss: 2.5832044097560316
Validation loss: 2.712480092503679

Epoch: 6| Step: 9
Training loss: 2.77721223372246
Validation loss: 2.728793166496919

Epoch: 6| Step: 10
Training loss: 1.9684081007764607
Validation loss: 2.7380268833726404

Epoch: 6| Step: 11
Training loss: 3.2018138155730926
Validation loss: 2.6989873738829133

Epoch: 6| Step: 12
Training loss: 2.8383414008279217
Validation loss: 2.708327207408505

Epoch: 6| Step: 13
Training loss: 2.967459307731446
Validation loss: 2.7492812383594685

Epoch: 87| Step: 0
Training loss: 2.856375032522168
Validation loss: 2.6963536973360767

Epoch: 6| Step: 1
Training loss: 2.5797210376946222
Validation loss: 2.714986225838738

Epoch: 6| Step: 2
Training loss: 2.8357939040134843
Validation loss: 2.722946264772986

Epoch: 6| Step: 3
Training loss: 2.8932453547636308
Validation loss: 2.6934752406466984

Epoch: 6| Step: 4
Training loss: 2.4932050869678517
Validation loss: 2.710822116871259

Epoch: 6| Step: 5
Training loss: 3.705638692273679
Validation loss: 2.746974901430813

Epoch: 6| Step: 6
Training loss: 2.172555940212931
Validation loss: 2.707074976877199

Epoch: 6| Step: 7
Training loss: 3.0345547938092765
Validation loss: 2.6963624620922775

Epoch: 6| Step: 8
Training loss: 3.1856101922642868
Validation loss: 2.71884626388565

Epoch: 6| Step: 9
Training loss: 2.6400104236397004
Validation loss: 2.7122865234013287

Epoch: 6| Step: 10
Training loss: 2.448241603198474
Validation loss: 2.6843043451676665

Epoch: 6| Step: 11
Training loss: 2.2484280075074334
Validation loss: 2.7223927835639077

Epoch: 6| Step: 12
Training loss: 2.6009288852507275
Validation loss: 2.7494024511281783

Epoch: 6| Step: 13
Training loss: 3.133920982392018
Validation loss: 2.7354933928735887

Epoch: 88| Step: 0
Training loss: 2.642412111378053
Validation loss: 2.707761139608018

Epoch: 6| Step: 1
Training loss: 2.3851844863394764
Validation loss: 2.706466005193598

Epoch: 6| Step: 2
Training loss: 3.010697999543961
Validation loss: 2.7116913687770468

Epoch: 6| Step: 3
Training loss: 2.6494364697091997
Validation loss: 2.7006320215923316

Epoch: 6| Step: 4
Training loss: 2.5079636572801034
Validation loss: 2.724438001653656

Epoch: 6| Step: 5
Training loss: 1.9560010562730055
Validation loss: 2.7175904562808473

Epoch: 6| Step: 6
Training loss: 2.5700769751335413
Validation loss: 2.686316079395111

Epoch: 6| Step: 7
Training loss: 3.402076894672668
Validation loss: 2.7085141007241496

Epoch: 6| Step: 8
Training loss: 3.6550075669738673
Validation loss: 2.7225400932536794

Epoch: 6| Step: 9
Training loss: 2.826608493614189
Validation loss: 2.7212753684074693

Epoch: 6| Step: 10
Training loss: 2.745251022979265
Validation loss: 2.7049125737119004

Epoch: 6| Step: 11
Training loss: 2.465280726853399
Validation loss: 2.7125572762212866

Epoch: 6| Step: 12
Training loss: 2.898180186733632
Validation loss: 2.7280246697141184

Epoch: 6| Step: 13
Training loss: 1.7929992008324462
Validation loss: 2.7066432390280646

Epoch: 89| Step: 0
Training loss: 3.671272130944292
Validation loss: 2.739680225148825

Epoch: 6| Step: 1
Training loss: 2.4748456039821565
Validation loss: 2.731528830422517

Epoch: 6| Step: 2
Training loss: 2.48351892080793
Validation loss: 2.728830263405152

Epoch: 6| Step: 3
Training loss: 3.5622565202998024
Validation loss: 2.7064197222859594

Epoch: 6| Step: 4
Training loss: 3.4006074138425704
Validation loss: 2.71105772832667

Epoch: 6| Step: 5
Training loss: 2.8210367979281825
Validation loss: 2.7289793176761403

Epoch: 6| Step: 6
Training loss: 2.343133769086341
Validation loss: 2.7490363889200538

Epoch: 6| Step: 7
Training loss: 2.6065355944871285
Validation loss: 2.710231949132091

Epoch: 6| Step: 8
Training loss: 2.556090456733515
Validation loss: 2.7001231255860643

Epoch: 6| Step: 9
Training loss: 2.4241606724746814
Validation loss: 2.70779387131654

Epoch: 6| Step: 10
Training loss: 2.256991649688296
Validation loss: 2.73924844236557

Epoch: 6| Step: 11
Training loss: 3.019136746039202
Validation loss: 2.708179155856666

Epoch: 6| Step: 12
Training loss: 1.8747585141123035
Validation loss: 2.7198278063232944

Epoch: 6| Step: 13
Training loss: 2.2320877853139325
Validation loss: 2.7121356310524383

Epoch: 90| Step: 0
Training loss: 2.8316160121231664
Validation loss: 2.7021114628893455

Epoch: 6| Step: 1
Training loss: 2.541969489730109
Validation loss: 2.7210992251618706

Epoch: 6| Step: 2
Training loss: 2.87330477948911
Validation loss: 2.721297868791119

Epoch: 6| Step: 3
Training loss: 3.2352575305155113
Validation loss: 2.7322458761168806

Epoch: 6| Step: 4
Training loss: 3.15442234415707
Validation loss: 2.7360287008046087

Epoch: 6| Step: 5
Training loss: 2.9030171122793975
Validation loss: 2.6978258634024503

Epoch: 6| Step: 6
Training loss: 2.9179154765259074
Validation loss: 2.707234996849978

Epoch: 6| Step: 7
Training loss: 2.685027115896252
Validation loss: 2.716408896155986

Epoch: 6| Step: 8
Training loss: 2.593520096850482
Validation loss: 2.743239906751499

Epoch: 6| Step: 9
Training loss: 2.2019044998969095
Validation loss: 2.709388087051641

Epoch: 6| Step: 10
Training loss: 2.9433810835090295
Validation loss: 2.7330189594888257

Epoch: 6| Step: 11
Training loss: 2.1858242700902504
Validation loss: 2.750922198526176

Epoch: 6| Step: 12
Training loss: 3.2155268558691015
Validation loss: 2.6729490573708823

Epoch: 6| Step: 13
Training loss: 2.5705740659320404
Validation loss: 2.730269130410734

Epoch: 91| Step: 0
Training loss: 1.8520823203714503
Validation loss: 2.735092525534959

Epoch: 6| Step: 1
Training loss: 2.7370891942134583
Validation loss: 2.7680523014350134

Epoch: 6| Step: 2
Training loss: 2.731883630645112
Validation loss: 2.7212614709079133

Epoch: 6| Step: 3
Training loss: 2.918137061640947
Validation loss: 2.771225644198128

Epoch: 6| Step: 4
Training loss: 2.482114903448448
Validation loss: 2.721003105049074

Epoch: 6| Step: 5
Training loss: 2.368315475185357
Validation loss: 2.7172793327578493

Epoch: 6| Step: 6
Training loss: 2.0172375283512287
Validation loss: 2.6940515803569056

Epoch: 6| Step: 7
Training loss: 3.2765381906287065
Validation loss: 2.699818386121025

Epoch: 6| Step: 8
Training loss: 2.8391821089192963
Validation loss: 2.6946464477723837

Epoch: 6| Step: 9
Training loss: 2.919488268651453
Validation loss: 2.7195755578898964

Epoch: 6| Step: 10
Training loss: 2.7953782152241766
Validation loss: 2.7011986428495005

Epoch: 6| Step: 11
Training loss: 3.2098319941967737
Validation loss: 2.724190816736622

Epoch: 6| Step: 12
Training loss: 3.0159845483723067
Validation loss: 2.723863271605318

Epoch: 6| Step: 13
Training loss: 3.6066284298471123
Validation loss: 2.7236264251170637

Epoch: 92| Step: 0
Training loss: 2.299182796423997
Validation loss: 2.665670155507951

Epoch: 6| Step: 1
Training loss: 2.7669316023247412
Validation loss: 2.7091410136977445

Epoch: 6| Step: 2
Training loss: 3.3037444227722177
Validation loss: 2.7264595805646725

Epoch: 6| Step: 3
Training loss: 2.3566172063224458
Validation loss: 2.7216988162135336

Epoch: 6| Step: 4
Training loss: 2.13059082576775
Validation loss: 2.7519613414468735

Epoch: 6| Step: 5
Training loss: 2.2673399649843393
Validation loss: 2.715002575573232

Epoch: 6| Step: 6
Training loss: 2.6118364431397483
Validation loss: 2.743228671806004

Epoch: 6| Step: 7
Training loss: 3.316442770245769
Validation loss: 2.714528255407411

Epoch: 6| Step: 8
Training loss: 3.336472336645134
Validation loss: 2.7308441316721312

Epoch: 6| Step: 9
Training loss: 3.1154694758465604
Validation loss: 2.7380061290571724

Epoch: 6| Step: 10
Training loss: 2.6731806905393545
Validation loss: 2.732520717636918

Epoch: 6| Step: 11
Training loss: 2.5275095866065835
Validation loss: 2.725136551827639

Epoch: 6| Step: 12
Training loss: 3.119998744573096
Validation loss: 2.71254874572611

Epoch: 6| Step: 13
Training loss: 2.206566253559511
Validation loss: 2.6956054708993604

Epoch: 93| Step: 0
Training loss: 2.830393687386641
Validation loss: 2.74398754540856

Epoch: 6| Step: 1
Training loss: 2.33233589470042
Validation loss: 2.6815750676541787

Epoch: 6| Step: 2
Training loss: 2.3391758342799283
Validation loss: 2.7502579838363146

Epoch: 6| Step: 3
Training loss: 2.9876641328168096
Validation loss: 2.719862871757918

Epoch: 6| Step: 4
Training loss: 2.301022994548653
Validation loss: 2.7237101037290126

Epoch: 6| Step: 5
Training loss: 2.9380437469445484
Validation loss: 2.712564712265882

Epoch: 6| Step: 6
Training loss: 3.200825680067518
Validation loss: 2.7179369334792427

Epoch: 6| Step: 7
Training loss: 2.4610205257882005
Validation loss: 2.6759893362944815

Epoch: 6| Step: 8
Training loss: 3.27523164585108
Validation loss: 2.726589723758998

Epoch: 6| Step: 9
Training loss: 3.001654168893177
Validation loss: 2.6936937738038127

Epoch: 6| Step: 10
Training loss: 2.4024306863080667
Validation loss: 2.704507187373045

Epoch: 6| Step: 11
Training loss: 3.1062052303288596
Validation loss: 2.714520850240933

Epoch: 6| Step: 12
Training loss: 2.5875906370938546
Validation loss: 2.73820250693461

Epoch: 6| Step: 13
Training loss: 2.379764996955553
Validation loss: 2.6868317735100273

Epoch: 94| Step: 0
Training loss: 2.9298251920768124
Validation loss: 2.70891814311306

Epoch: 6| Step: 1
Training loss: 1.5051137857100938
Validation loss: 2.7469405815287242

Epoch: 6| Step: 2
Training loss: 1.8101345938488969
Validation loss: 2.737447632267041

Epoch: 6| Step: 3
Training loss: 1.9975864032682888
Validation loss: 2.721352875435396

Epoch: 6| Step: 4
Training loss: 2.5471659301099123
Validation loss: 2.7193104863176396

Epoch: 6| Step: 5
Training loss: 3.022671388069081
Validation loss: 2.7216933511496504

Epoch: 6| Step: 6
Training loss: 2.764028228323031
Validation loss: 2.721066289835266

Epoch: 6| Step: 7
Training loss: 2.8593518198876855
Validation loss: 2.7136679262486534

Epoch: 6| Step: 8
Training loss: 2.7575519211723694
Validation loss: 2.736467733157454

Epoch: 6| Step: 9
Training loss: 2.914336736216415
Validation loss: 2.7049359906893806

Epoch: 6| Step: 10
Training loss: 2.9856927169521374
Validation loss: 2.7497682566989052

Epoch: 6| Step: 11
Training loss: 3.471336019382228
Validation loss: 2.688742584799373

Epoch: 6| Step: 12
Training loss: 2.6884078333307633
Validation loss: 2.7422812901893345

Epoch: 6| Step: 13
Training loss: 4.284022415088245
Validation loss: 2.7156040546129603

Epoch: 95| Step: 0
Training loss: 2.5228176241354503
Validation loss: 2.7152315370525377

Epoch: 6| Step: 1
Training loss: 2.273337240728486
Validation loss: 2.7151435616270794

Epoch: 6| Step: 2
Training loss: 3.803467478569347
Validation loss: 2.7295200996087843

Epoch: 6| Step: 3
Training loss: 2.4234926789308737
Validation loss: 2.7381416931114626

Epoch: 6| Step: 4
Training loss: 2.6284058592019717
Validation loss: 2.6645978938679704

Epoch: 6| Step: 5
Training loss: 3.396476232289693
Validation loss: 2.7127027365987946

Epoch: 6| Step: 6
Training loss: 2.25430447714804
Validation loss: 2.724662877092416

Epoch: 6| Step: 7
Training loss: 3.179453248339095
Validation loss: 2.7020567856095012

Epoch: 6| Step: 8
Training loss: 2.7739288324689477
Validation loss: 2.715446720959579

Epoch: 6| Step: 9
Training loss: 2.765770773628849
Validation loss: 2.7089812662466244

Epoch: 6| Step: 10
Training loss: 2.2397221958373246
Validation loss: 2.7727859917326403

Epoch: 6| Step: 11
Training loss: 3.12754656981902
Validation loss: 2.7162600421007776

Epoch: 6| Step: 12
Training loss: 2.5006545163724447
Validation loss: 2.71633659838644

Epoch: 6| Step: 13
Training loss: 2.131071504965834
Validation loss: 2.743662939242144

Epoch: 96| Step: 0
Training loss: 3.473672484267062
Validation loss: 2.713869209039205

Epoch: 6| Step: 1
Training loss: 1.9522129828663166
Validation loss: 2.7015496801081196

Epoch: 6| Step: 2
Training loss: 2.6152493260634992
Validation loss: 2.7165500460949876

Epoch: 6| Step: 3
Training loss: 3.278685812167312
Validation loss: 2.6973669230278077

Epoch: 6| Step: 4
Training loss: 2.318074492487713
Validation loss: 2.730115796070078

Epoch: 6| Step: 5
Training loss: 2.4393358408555437
Validation loss: 2.692817547882306

Epoch: 6| Step: 6
Training loss: 3.2217115092491015
Validation loss: 2.7566610807004692

Epoch: 6| Step: 7
Training loss: 3.1791487853687688
Validation loss: 2.7239837152769106

Epoch: 6| Step: 8
Training loss: 2.8114951139920157
Validation loss: 2.7246311365208915

Epoch: 6| Step: 9
Training loss: 2.8725356445225767
Validation loss: 2.739976754947353

Epoch: 6| Step: 10
Training loss: 2.96844239900054
Validation loss: 2.730547105821893

Epoch: 6| Step: 11
Training loss: 2.248577091849039
Validation loss: 2.716647609998927

Epoch: 6| Step: 12
Training loss: 2.47950305312827
Validation loss: 2.7486535054539862

Epoch: 6| Step: 13
Training loss: 2.0397345944334915
Validation loss: 2.717178816703253

Epoch: 97| Step: 0
Training loss: 2.337452782954711
Validation loss: 2.7017323974596112

Epoch: 6| Step: 1
Training loss: 2.212204101948547
Validation loss: 2.7278610246307013

Epoch: 6| Step: 2
Training loss: 2.1444265204533206
Validation loss: 2.708116213770158

Epoch: 6| Step: 3
Training loss: 3.26295091574925
Validation loss: 2.7429648023007585

Epoch: 6| Step: 4
Training loss: 2.5289661795156118
Validation loss: 2.7292895808780884

Epoch: 6| Step: 5
Training loss: 2.7493271438030695
Validation loss: 2.704326041547605

Epoch: 6| Step: 6
Training loss: 2.6321471870683997
Validation loss: 2.7057891402897014

Epoch: 6| Step: 7
Training loss: 2.9662894241278734
Validation loss: 2.763749444379454

Epoch: 6| Step: 8
Training loss: 2.825076910676772
Validation loss: 2.6558253933939397

Epoch: 6| Step: 9
Training loss: 2.9013150883596492
Validation loss: 2.714497071596305

Epoch: 6| Step: 10
Training loss: 3.4041565227629778
Validation loss: 2.680896597351875

Epoch: 6| Step: 11
Training loss: 2.643346704334565
Validation loss: 2.7025840218419996

Epoch: 6| Step: 12
Training loss: 2.930722961545759
Validation loss: 2.711784980947307

Epoch: 6| Step: 13
Training loss: 3.229442724097695
Validation loss: 2.7039563429146

Epoch: 98| Step: 0
Training loss: 2.69282129125808
Validation loss: 2.7042898541547986

Epoch: 6| Step: 1
Training loss: 2.8702673728356634
Validation loss: 2.6946696547562876

Epoch: 6| Step: 2
Training loss: 2.1699604405255974
Validation loss: 2.740690987084043

Epoch: 6| Step: 3
Training loss: 2.5534469905719384
Validation loss: 2.7416466891725415

Epoch: 6| Step: 4
Training loss: 2.5126884807281784
Validation loss: 2.710039358411365

Epoch: 6| Step: 5
Training loss: 3.0005783477252184
Validation loss: 2.7387353233514435

Epoch: 6| Step: 6
Training loss: 2.20350719410393
Validation loss: 2.7331507844940877

Epoch: 6| Step: 7
Training loss: 3.2787099543637206
Validation loss: 2.731553883611973

Epoch: 6| Step: 8
Training loss: 2.7742670242462366
Validation loss: 2.736764136103183

Epoch: 6| Step: 9
Training loss: 3.016121462736293
Validation loss: 2.68127472752296

Epoch: 6| Step: 10
Training loss: 3.1329423301982664
Validation loss: 2.713057320882252

Epoch: 6| Step: 11
Training loss: 2.170923477419693
Validation loss: 2.7177478177014964

Epoch: 6| Step: 12
Training loss: 3.052225432923294
Validation loss: 2.7248121546259694

Epoch: 6| Step: 13
Training loss: 3.0798873890689094
Validation loss: 2.7332231017914803

Epoch: 99| Step: 0
Training loss: 2.4421902061637777
Validation loss: 2.6962480074501913

Epoch: 6| Step: 1
Training loss: 2.706449371817155
Validation loss: 2.694139972380946

Epoch: 6| Step: 2
Training loss: 2.8441436830432676
Validation loss: 2.7179406243371402

Epoch: 6| Step: 3
Training loss: 1.983544183256769
Validation loss: 2.7181102229530842

Epoch: 6| Step: 4
Training loss: 2.165007016741018
Validation loss: 2.703614306757916

Epoch: 6| Step: 5
Training loss: 3.0409333028657546
Validation loss: 2.737115120016997

Epoch: 6| Step: 6
Training loss: 2.698008816788776
Validation loss: 2.718853230131959

Epoch: 6| Step: 7
Training loss: 3.092023117067842
Validation loss: 2.697548241560701

Epoch: 6| Step: 8
Training loss: 3.0071078973814926
Validation loss: 2.701460955446621

Epoch: 6| Step: 9
Training loss: 2.8396978327690263
Validation loss: 2.711440587194976

Epoch: 6| Step: 10
Training loss: 3.3069559883116635
Validation loss: 2.7197401228493194

Epoch: 6| Step: 11
Training loss: 2.4337330590017525
Validation loss: 2.7054972536747073

Epoch: 6| Step: 12
Training loss: 3.141421696212958
Validation loss: 2.7134907251433664

Epoch: 6| Step: 13
Training loss: 2.3635608854446932
Validation loss: 2.6796146486840278

Epoch: 100| Step: 0
Training loss: 2.387237542391052
Validation loss: 2.692662818717455

Epoch: 6| Step: 1
Training loss: 2.3196512943501597
Validation loss: 2.687928152546723

Epoch: 6| Step: 2
Training loss: 3.0807898744656947
Validation loss: 2.6782403029684767

Epoch: 6| Step: 3
Training loss: 2.883135356243594
Validation loss: 2.7139979912080476

Epoch: 6| Step: 4
Training loss: 3.034719467646796
Validation loss: 2.717484057455225

Epoch: 6| Step: 5
Training loss: 2.152617781514744
Validation loss: 2.7308331883823187

Epoch: 6| Step: 6
Training loss: 3.230116394827484
Validation loss: 2.7226761571374394

Epoch: 6| Step: 7
Training loss: 2.5914275100935353
Validation loss: 2.6903890104285684

Epoch: 6| Step: 8
Training loss: 2.5380667744082266
Validation loss: 2.7060006128566076

Epoch: 6| Step: 9
Training loss: 3.1722850816343975
Validation loss: 2.705007227475778

Epoch: 6| Step: 10
Training loss: 3.0008057465927678
Validation loss: 2.6996974853834477

Epoch: 6| Step: 11
Training loss: 2.756050995370153
Validation loss: 2.715774378751105

Epoch: 6| Step: 12
Training loss: 2.1777243028074253
Validation loss: 2.73924829730231

Epoch: 6| Step: 13
Training loss: 2.8801947392745895
Validation loss: 2.6910229138801913

Epoch: 101| Step: 0
Training loss: 2.7910450105608406
Validation loss: 2.7225572450918465

Epoch: 6| Step: 1
Training loss: 2.8985852309260087
Validation loss: 2.7163781548566726

Epoch: 6| Step: 2
Training loss: 3.2634074151342674
Validation loss: 2.7119602133550087

Epoch: 6| Step: 3
Training loss: 2.451349575698875
Validation loss: 2.729207168600453

Epoch: 6| Step: 4
Training loss: 2.754088310554468
Validation loss: 2.7460222011033437

Epoch: 6| Step: 5
Training loss: 1.9593524377914062
Validation loss: 2.701721336253071

Epoch: 6| Step: 6
Training loss: 2.666600782852098
Validation loss: 2.698624399333549

Epoch: 6| Step: 7
Training loss: 2.91521114180118
Validation loss: 2.7088554401264857

Epoch: 6| Step: 8
Training loss: 2.511316816049646
Validation loss: 2.7020657097609573

Epoch: 6| Step: 9
Training loss: 2.914472044937164
Validation loss: 2.7263597781558593

Epoch: 6| Step: 10
Training loss: 2.2913759798586084
Validation loss: 2.725132775701032

Epoch: 6| Step: 11
Training loss: 2.7697441331319395
Validation loss: 2.729730363908629

Epoch: 6| Step: 12
Training loss: 3.6781522297722287
Validation loss: 2.729830463815211

Epoch: 6| Step: 13
Training loss: 1.7799607011121517
Validation loss: 2.737394604817563

Epoch: 102| Step: 0
Training loss: 3.332832410049164
Validation loss: 2.733905639680252

Epoch: 6| Step: 1
Training loss: 1.950309249613614
Validation loss: 2.689646898122846

Epoch: 6| Step: 2
Training loss: 3.3137236440352242
Validation loss: 2.7161670475905875

Epoch: 6| Step: 3
Training loss: 2.940525525931095
Validation loss: 2.710971034044333

Epoch: 6| Step: 4
Training loss: 3.2920233295860863
Validation loss: 2.714009214913866

Epoch: 6| Step: 5
Training loss: 2.416644841676576
Validation loss: 2.7420021071353635

Epoch: 6| Step: 6
Training loss: 2.4080655073336072
Validation loss: 2.7183230787071864

Epoch: 6| Step: 7
Training loss: 2.5197316644491408
Validation loss: 2.6934572925579987

Epoch: 6| Step: 8
Training loss: 2.4902055566653574
Validation loss: 2.701380540273715

Epoch: 6| Step: 9
Training loss: 2.8909502825847686
Validation loss: 2.7387777961407034

Epoch: 6| Step: 10
Training loss: 2.611853513170575
Validation loss: 2.675246219844077

Epoch: 6| Step: 11
Training loss: 2.9498321097493
Validation loss: 2.702093429850804

Epoch: 6| Step: 12
Training loss: 2.269973685494375
Validation loss: 2.7090678018197383

Epoch: 6| Step: 13
Training loss: 2.4509407572814004
Validation loss: 2.6919951881093613

Epoch: 103| Step: 0
Training loss: 3.081917068048888
Validation loss: 2.6871753276157455

Epoch: 6| Step: 1
Training loss: 3.15716101463043
Validation loss: 2.7253857627344997

Epoch: 6| Step: 2
Training loss: 1.9999694225834856
Validation loss: 2.7144003399098255

Epoch: 6| Step: 3
Training loss: 2.844138988677252
Validation loss: 2.682772733990505

Epoch: 6| Step: 4
Training loss: 2.292661578059708
Validation loss: 2.7274042403890975

Epoch: 6| Step: 5
Training loss: 2.483163790281018
Validation loss: 2.7595083149558794

Epoch: 6| Step: 6
Training loss: 2.362039236519664
Validation loss: 2.7501622671392103

Epoch: 6| Step: 7
Training loss: 3.026523956541809
Validation loss: 2.719238969007163

Epoch: 6| Step: 8
Training loss: 2.269060463588543
Validation loss: 2.6884985468810503

Epoch: 6| Step: 9
Training loss: 2.112138195768952
Validation loss: 2.724877898577856

Epoch: 6| Step: 10
Training loss: 3.247354457727258
Validation loss: 2.6826392724592294

Epoch: 6| Step: 11
Training loss: 2.9656987622235667
Validation loss: 2.692493581456563

Epoch: 6| Step: 12
Training loss: 2.515031543177439
Validation loss: 2.6828304101375036

Epoch: 6| Step: 13
Training loss: 3.37227775141165
Validation loss: 2.72005271606284

Epoch: 104| Step: 0
Training loss: 2.2714852146924502
Validation loss: 2.702544435997484

Epoch: 6| Step: 1
Training loss: 3.098107246192606
Validation loss: 2.707978472562122

Epoch: 6| Step: 2
Training loss: 2.7523800347540837
Validation loss: 2.7258965850576122

Epoch: 6| Step: 3
Training loss: 2.63578614872796
Validation loss: 2.748926211307864

Epoch: 6| Step: 4
Training loss: 3.4220508547671096
Validation loss: 2.7364366354142726

Epoch: 6| Step: 5
Training loss: 2.904427069469584
Validation loss: 2.676084932130886

Epoch: 6| Step: 6
Training loss: 2.6720364170505215
Validation loss: 2.6851780899418354

Epoch: 6| Step: 7
Training loss: 1.945122031573444
Validation loss: 2.695299980963188

Epoch: 6| Step: 8
Training loss: 2.517677370280059
Validation loss: 2.7482848426137294

Epoch: 6| Step: 9
Training loss: 2.463837673692386
Validation loss: 2.736261827930346

Epoch: 6| Step: 10
Training loss: 2.1637542174511406
Validation loss: 2.7360585691778656

Epoch: 6| Step: 11
Training loss: 2.7421852394377257
Validation loss: 2.7100138840200314

Epoch: 6| Step: 12
Training loss: 2.653144457131291
Validation loss: 2.7397826180103917

Epoch: 6| Step: 13
Training loss: 3.6665028333186105
Validation loss: 2.7155447427228916

Epoch: 105| Step: 0
Training loss: 2.351532590555483
Validation loss: 2.717884571427814

Epoch: 6| Step: 1
Training loss: 3.1280961529814526
Validation loss: 2.7168608662552374

Epoch: 6| Step: 2
Training loss: 2.390664891926152
Validation loss: 2.7332302264893777

Epoch: 6| Step: 3
Training loss: 2.609511503201194
Validation loss: 2.717440431091032

Epoch: 6| Step: 4
Training loss: 2.8255178331397284
Validation loss: 2.692051296309541

Epoch: 6| Step: 5
Training loss: 2.0859491583680527
Validation loss: 2.686501720373477

Epoch: 6| Step: 6
Training loss: 2.92943944262346
Validation loss: 2.731224113663258

Epoch: 6| Step: 7
Training loss: 2.9797427991947605
Validation loss: 2.694374444129294

Epoch: 6| Step: 8
Training loss: 2.196928793627044
Validation loss: 2.6768349449735425

Epoch: 6| Step: 9
Training loss: 3.118705513738176
Validation loss: 2.6966567577663354

Epoch: 6| Step: 10
Training loss: 3.9336626033571793
Validation loss: 2.7195423420475136

Epoch: 6| Step: 11
Training loss: 2.471979081654851
Validation loss: 2.707096364179693

Epoch: 6| Step: 12
Training loss: 2.3838297689260486
Validation loss: 2.6875081330481807

Epoch: 6| Step: 13
Training loss: 1.9707725066569695
Validation loss: 2.6943682009927636

Epoch: 106| Step: 0
Training loss: 2.3874957978376385
Validation loss: 2.7430833567885

Epoch: 6| Step: 1
Training loss: 2.574889956595081
Validation loss: 2.698175202604141

Epoch: 6| Step: 2
Training loss: 3.2960734907216183
Validation loss: 2.6911052294588966

Epoch: 6| Step: 3
Training loss: 3.217205825316237
Validation loss: 2.681627536411891

Epoch: 6| Step: 4
Training loss: 2.286787653837294
Validation loss: 2.6870793144256533

Epoch: 6| Step: 5
Training loss: 2.5252367343023545
Validation loss: 2.7250240371906855

Epoch: 6| Step: 6
Training loss: 2.3055269425951685
Validation loss: 2.7166156653664824

Epoch: 6| Step: 7
Training loss: 2.950222789304354
Validation loss: 2.754726092677489

Epoch: 6| Step: 8
Training loss: 3.1136763835276606
Validation loss: 2.6986191853603767

Epoch: 6| Step: 9
Training loss: 3.253452081571591
Validation loss: 2.7014321527087652

Epoch: 6| Step: 10
Training loss: 2.2018699588333535
Validation loss: 2.686725802085907

Epoch: 6| Step: 11
Training loss: 2.765351535186653
Validation loss: 2.723195892646125

Epoch: 6| Step: 12
Training loss: 2.39373128699416
Validation loss: 2.7086048365608066

Epoch: 6| Step: 13
Training loss: 2.3808337390949603
Validation loss: 2.6989945034683944

Epoch: 107| Step: 0
Training loss: 2.8234105727954697
Validation loss: 2.709277915149556

Epoch: 6| Step: 1
Training loss: 2.5998352548783825
Validation loss: 2.7436414725708826

Epoch: 6| Step: 2
Training loss: 3.0583979323491666
Validation loss: 2.7009183132492005

Epoch: 6| Step: 3
Training loss: 2.898640833711781
Validation loss: 2.711305089383785

Epoch: 6| Step: 4
Training loss: 3.051489050665358
Validation loss: 2.7073332865724873

Epoch: 6| Step: 5
Training loss: 2.6430929715752303
Validation loss: 2.6823325265857987

Epoch: 6| Step: 6
Training loss: 2.5826345134316355
Validation loss: 2.6842610987940687

Epoch: 6| Step: 7
Training loss: 2.969484900815607
Validation loss: 2.7128355110316957

Epoch: 6| Step: 8
Training loss: 2.4249198231764755
Validation loss: 2.6405910920093874

Epoch: 6| Step: 9
Training loss: 2.262054787347538
Validation loss: 2.6666509015119773

Epoch: 6| Step: 10
Training loss: 2.8649258125646155
Validation loss: 2.704669658770075

Epoch: 6| Step: 11
Training loss: 2.4139720319567366
Validation loss: 2.736603520496844

Epoch: 6| Step: 12
Training loss: 2.5273526175341923
Validation loss: 2.7104296053493826

Epoch: 6| Step: 13
Training loss: 2.633372804691962
Validation loss: 2.704454421217061

Epoch: 108| Step: 0
Training loss: 3.223493617535937
Validation loss: 2.6806887934769064

Epoch: 6| Step: 1
Training loss: 1.949465137879301
Validation loss: 2.686136113799926

Epoch: 6| Step: 2
Training loss: 3.4482088608645114
Validation loss: 2.726936071921465

Epoch: 6| Step: 3
Training loss: 3.2915371897539307
Validation loss: 2.6669164016389093

Epoch: 6| Step: 4
Training loss: 2.2802864025327354
Validation loss: 2.6992973372114255

Epoch: 6| Step: 5
Training loss: 2.3011044338421494
Validation loss: 2.6963243846125686

Epoch: 6| Step: 6
Training loss: 2.035814292382497
Validation loss: 2.708970792986395

Epoch: 6| Step: 7
Training loss: 3.16989690426471
Validation loss: 2.7110598607074374

Epoch: 6| Step: 8
Training loss: 1.934412742332821
Validation loss: 2.699651640064049

Epoch: 6| Step: 9
Training loss: 2.7691177468384605
Validation loss: 2.751447433729749

Epoch: 6| Step: 10
Training loss: 2.5023499888027616
Validation loss: 2.6818315480304262

Epoch: 6| Step: 11
Training loss: 2.7568640442299506
Validation loss: 2.6986071058325813

Epoch: 6| Step: 12
Training loss: 2.7910101578847786
Validation loss: 2.7512577532933853

Epoch: 6| Step: 13
Training loss: 3.151697785136292
Validation loss: 2.7116116673128072

Epoch: 109| Step: 0
Training loss: 3.0377638525629322
Validation loss: 2.7013845289652285

Epoch: 6| Step: 1
Training loss: 2.383162876071268
Validation loss: 2.723432808581251

Epoch: 6| Step: 2
Training loss: 3.4128357103821405
Validation loss: 2.6848941741426122

Epoch: 6| Step: 3
Training loss: 3.14399060642499
Validation loss: 2.7146828979801763

Epoch: 6| Step: 4
Training loss: 2.9113164240464915
Validation loss: 2.682040488770826

Epoch: 6| Step: 5
Training loss: 2.0551162098421125
Validation loss: 2.747979737420441

Epoch: 6| Step: 6
Training loss: 2.607993668285243
Validation loss: 2.717163108434054

Epoch: 6| Step: 7
Training loss: 2.9798821788256356
Validation loss: 2.711754671264817

Epoch: 6| Step: 8
Training loss: 2.8302159456822964
Validation loss: 2.6812593510356137

Epoch: 6| Step: 9
Training loss: 2.5201593133734055
Validation loss: 2.746571016722986

Epoch: 6| Step: 10
Training loss: 2.5181553595429578
Validation loss: 2.7159267670650133

Epoch: 6| Step: 11
Training loss: 1.9937902847094664
Validation loss: 2.7285144655662084

Epoch: 6| Step: 12
Training loss: 2.614898409356215
Validation loss: 2.7044199797609263

Epoch: 6| Step: 13
Training loss: 3.250403159151413
Validation loss: 2.675998907815352

Epoch: 110| Step: 0
Training loss: 2.476783140925513
Validation loss: 2.720521974838407

Epoch: 6| Step: 1
Training loss: 2.6939520456963817
Validation loss: 2.680556293600584

Epoch: 6| Step: 2
Training loss: 3.3000350198910504
Validation loss: 2.713882152522297

Epoch: 6| Step: 3
Training loss: 2.8249574911244517
Validation loss: 2.6971233337189546

Epoch: 6| Step: 4
Training loss: 2.6166871460844146
Validation loss: 2.705724841705229

Epoch: 6| Step: 5
Training loss: 3.1312259452337483
Validation loss: 2.7371951849909846

Epoch: 6| Step: 6
Training loss: 1.780906041716406
Validation loss: 2.686357178394552

Epoch: 6| Step: 7
Training loss: 2.5300474724820274
Validation loss: 2.698331356228629

Epoch: 6| Step: 8
Training loss: 3.075277647804176
Validation loss: 2.689950360588353

Epoch: 6| Step: 9
Training loss: 2.3855886827662234
Validation loss: 2.706495303747188

Epoch: 6| Step: 10
Training loss: 1.734382010780805
Validation loss: 2.674107414675183

Epoch: 6| Step: 11
Training loss: 2.832323361820738
Validation loss: 2.6714057445526187

Epoch: 6| Step: 12
Training loss: 3.0835882201820506
Validation loss: 2.6969045917626753

Epoch: 6| Step: 13
Training loss: 2.785359293637595
Validation loss: 2.6567282934343153

Epoch: 111| Step: 0
Training loss: 3.3086490919220433
Validation loss: 2.73378595151378

Epoch: 6| Step: 1
Training loss: 2.5264771286053564
Validation loss: 2.734407691584347

Epoch: 6| Step: 2
Training loss: 2.0983538897140948
Validation loss: 2.699735045716358

Epoch: 6| Step: 3
Training loss: 1.8810715600232286
Validation loss: 2.696275739810741

Epoch: 6| Step: 4
Training loss: 3.3931336856659904
Validation loss: 2.6956706290205936

Epoch: 6| Step: 5
Training loss: 2.5694938677825765
Validation loss: 2.7008675614036735

Epoch: 6| Step: 6
Training loss: 2.3979240141180727
Validation loss: 2.724783314585697

Epoch: 6| Step: 7
Training loss: 1.8195463868654402
Validation loss: 2.6824934491152077

Epoch: 6| Step: 8
Training loss: 2.624704889330036
Validation loss: 2.717740406214747

Epoch: 6| Step: 9
Training loss: 3.8399105590099736
Validation loss: 2.6944286131858015

Epoch: 6| Step: 10
Training loss: 1.873269808711457
Validation loss: 2.6940268245511727

Epoch: 6| Step: 11
Training loss: 2.8464694591648105
Validation loss: 2.6902315605378737

Epoch: 6| Step: 12
Training loss: 2.8011919515877333
Validation loss: 2.7096209176521273

Epoch: 6| Step: 13
Training loss: 2.6047970021645357
Validation loss: 2.700097081008776

Epoch: 112| Step: 0
Training loss: 2.7763931214164246
Validation loss: 2.70769996588873

Epoch: 6| Step: 1
Training loss: 2.7274199178741707
Validation loss: 2.7003295421216484

Epoch: 6| Step: 2
Training loss: 2.8433621320201463
Validation loss: 2.711803783349486

Epoch: 6| Step: 3
Training loss: 2.069229245642084
Validation loss: 2.6788294004918822

Epoch: 6| Step: 4
Training loss: 2.959029496355644
Validation loss: 2.699523132655906

Epoch: 6| Step: 5
Training loss: 2.243397137196052
Validation loss: 2.703183470053396

Epoch: 6| Step: 6
Training loss: 2.614470480703543
Validation loss: 2.7187784561442654

Epoch: 6| Step: 7
Training loss: 2.4881448992824833
Validation loss: 2.6849652924452947

Epoch: 6| Step: 8
Training loss: 2.1235542989443865
Validation loss: 2.647008756059117

Epoch: 6| Step: 9
Training loss: 2.7325691581552998
Validation loss: 2.7519729701925093

Epoch: 6| Step: 10
Training loss: 3.540824266366594
Validation loss: 2.7352413425863764

Epoch: 6| Step: 11
Training loss: 2.55793662914791
Validation loss: 2.7398930463492395

Epoch: 6| Step: 12
Training loss: 2.4570144628488033
Validation loss: 2.75069364113419

Epoch: 6| Step: 13
Training loss: 3.7507231968664017
Validation loss: 2.736664639229236

Epoch: 113| Step: 0
Training loss: 2.619075356167317
Validation loss: 2.719620925950003

Epoch: 6| Step: 1
Training loss: 2.6898497134632016
Validation loss: 2.699585652128776

Epoch: 6| Step: 2
Training loss: 2.5711628629007177
Validation loss: 2.7559723097952373

Epoch: 6| Step: 3
Training loss: 2.2926018858455173
Validation loss: 2.7114443729352895

Epoch: 6| Step: 4
Training loss: 3.131390712721
Validation loss: 2.7047839366560193

Epoch: 6| Step: 5
Training loss: 3.7183477360474817
Validation loss: 2.6925108685209698

Epoch: 6| Step: 6
Training loss: 2.8359375
Validation loss: 2.680305672984335

Epoch: 6| Step: 7
Training loss: 2.324363178285681
Validation loss: 2.6991309146662195

Epoch: 6| Step: 8
Training loss: 2.472254330239644
Validation loss: 2.7083218431505127

Epoch: 6| Step: 9
Training loss: 2.6322849548842004
Validation loss: 2.7090911947089285

Epoch: 6| Step: 10
Training loss: 2.728088214359713
Validation loss: 2.735261709236566

Epoch: 6| Step: 11
Training loss: 2.0182814724614846
Validation loss: 2.7380915029479005

Epoch: 6| Step: 12
Training loss: 2.838517457817972
Validation loss: 2.7021109410742743

Epoch: 6| Step: 13
Training loss: 2.3531463459966724
Validation loss: 2.704158632045393

Epoch: 114| Step: 0
Training loss: 2.909433077878878
Validation loss: 2.710060738401021

Epoch: 6| Step: 1
Training loss: 2.497539835660863
Validation loss: 2.668509285752406

Epoch: 6| Step: 2
Training loss: 2.4382147107980767
Validation loss: 2.700717557448511

Epoch: 6| Step: 3
Training loss: 2.419074919412121
Validation loss: 2.6604673643296737

Epoch: 6| Step: 4
Training loss: 2.778570019808835
Validation loss: 2.697856529124014

Epoch: 6| Step: 5
Training loss: 3.0368379036128723
Validation loss: 2.730060689907323

Epoch: 6| Step: 6
Training loss: 2.5543051150594933
Validation loss: 2.7201348420981315

Epoch: 6| Step: 7
Training loss: 3.6614065731870378
Validation loss: 2.700689251785631

Epoch: 6| Step: 8
Training loss: 2.42614831773275
Validation loss: 2.717729232820232

Epoch: 6| Step: 9
Training loss: 3.0378872283135667
Validation loss: 2.717192301079336

Epoch: 6| Step: 10
Training loss: 2.629251851325577
Validation loss: 2.726217650338718

Epoch: 6| Step: 11
Training loss: 2.5093998623919145
Validation loss: 2.7331042194897854

Epoch: 6| Step: 12
Training loss: 2.7403178130951082
Validation loss: 2.711830813996693

Epoch: 6| Step: 13
Training loss: 1.262577343450644
Validation loss: 2.696856565812544

Epoch: 115| Step: 0
Training loss: 1.5789220326883902
Validation loss: 2.7245298077244544

Epoch: 6| Step: 1
Training loss: 3.4631950644782434
Validation loss: 2.6892088341100453

Epoch: 6| Step: 2
Training loss: 2.5003625606850477
Validation loss: 2.6884723124516627

Epoch: 6| Step: 3
Training loss: 3.2272169728658797
Validation loss: 2.719905249035924

Epoch: 6| Step: 4
Training loss: 3.023395232464564
Validation loss: 2.6885052608780495

Epoch: 6| Step: 5
Training loss: 2.9531434073707072
Validation loss: 2.7269580216991947

Epoch: 6| Step: 6
Training loss: 2.871891663412705
Validation loss: 2.70309801507289

Epoch: 6| Step: 7
Training loss: 2.4714811645506254
Validation loss: 2.7224467256594553

Epoch: 6| Step: 8
Training loss: 2.5460974319585894
Validation loss: 2.7068929535257062

Epoch: 6| Step: 9
Training loss: 2.3430077967072385
Validation loss: 2.7373963973273314

Epoch: 6| Step: 10
Training loss: 2.895394509271379
Validation loss: 2.710067198433738

Epoch: 6| Step: 11
Training loss: 2.598526474742042
Validation loss: 2.681337101690423

Epoch: 6| Step: 12
Training loss: 2.4280662892827634
Validation loss: 2.6947288981126984

Epoch: 6| Step: 13
Training loss: 2.3628276295020507
Validation loss: 2.687268448680119

Epoch: 116| Step: 0
Training loss: 2.5348178537754635
Validation loss: 2.7044642929696194

Epoch: 6| Step: 1
Training loss: 2.5752497505622625
Validation loss: 2.7180253268751677

Epoch: 6| Step: 2
Training loss: 3.3662311939574017
Validation loss: 2.7320440470447607

Epoch: 6| Step: 3
Training loss: 1.9708019039021751
Validation loss: 2.699383520802346

Epoch: 6| Step: 4
Training loss: 2.6685969002827554
Validation loss: 2.744443742294668

Epoch: 6| Step: 5
Training loss: 2.5819383566993634
Validation loss: 2.722220614278437

Epoch: 6| Step: 6
Training loss: 2.6370980449122903
Validation loss: 2.7326807579687085

Epoch: 6| Step: 7
Training loss: 2.944043925973511
Validation loss: 2.661183028359322

Epoch: 6| Step: 8
Training loss: 2.6170721683427005
Validation loss: 2.709950495460242

Epoch: 6| Step: 9
Training loss: 2.832132945372387
Validation loss: 2.72554678826042

Epoch: 6| Step: 10
Training loss: 2.4040989364348118
Validation loss: 2.657793829603719

Epoch: 6| Step: 11
Training loss: 2.7151088667481966
Validation loss: 2.721487386914219

Epoch: 6| Step: 12
Training loss: 2.9520636371896827
Validation loss: 2.689474925054133

Epoch: 6| Step: 13
Training loss: 1.8801006874555157
Validation loss: 2.722465091887828

Epoch: 117| Step: 0
Training loss: 2.466861630372843
Validation loss: 2.6942565209534153

Epoch: 6| Step: 1
Training loss: 2.549152783292351
Validation loss: 2.6802498296692945

Epoch: 6| Step: 2
Training loss: 2.1677766182107376
Validation loss: 2.7048789745088486

Epoch: 6| Step: 3
Training loss: 3.0499988680978145
Validation loss: 2.7133399016513535

Epoch: 6| Step: 4
Training loss: 2.714351208692578
Validation loss: 2.708173079438987

Epoch: 6| Step: 5
Training loss: 3.223202782728519
Validation loss: 2.6606513227615096

Epoch: 6| Step: 6
Training loss: 2.648859941218051
Validation loss: 2.680875103355569

Epoch: 6| Step: 7
Training loss: 2.0616564326031024
Validation loss: 2.7085239756640607

Epoch: 6| Step: 8
Training loss: 2.872638727860366
Validation loss: 2.676405438317361

Epoch: 6| Step: 9
Training loss: 2.3360164973447213
Validation loss: 2.687072180893579

Epoch: 6| Step: 10
Training loss: 3.1759339468306558
Validation loss: 2.7345249342353752

Epoch: 6| Step: 11
Training loss: 2.76110548146333
Validation loss: 2.695630820870106

Epoch: 6| Step: 12
Training loss: 2.922259953073546
Validation loss: 2.7131945179532355

Epoch: 6| Step: 13
Training loss: 2.311217081053174
Validation loss: 2.6794830983833102

Epoch: 118| Step: 0
Training loss: 2.84005866621432
Validation loss: 2.705402111984281

Epoch: 6| Step: 1
Training loss: 2.9999740917358646
Validation loss: 2.725633927519021

Epoch: 6| Step: 2
Training loss: 2.2949873245321384
Validation loss: 2.702990999776437

Epoch: 6| Step: 3
Training loss: 3.1232563494867622
Validation loss: 2.672210214653966

Epoch: 6| Step: 4
Training loss: 2.8537884946642125
Validation loss: 2.7101190900342167

Epoch: 6| Step: 5
Training loss: 2.6841097006743047
Validation loss: 2.7091010457802196

Epoch: 6| Step: 6
Training loss: 1.8666001038377489
Validation loss: 2.73627356555745

Epoch: 6| Step: 7
Training loss: 2.416042466504091
Validation loss: 2.7104424271655945

Epoch: 6| Step: 8
Training loss: 2.236022128696846
Validation loss: 2.689423407247613

Epoch: 6| Step: 9
Training loss: 2.7780386569119004
Validation loss: 2.7012137482881085

Epoch: 6| Step: 10
Training loss: 1.9527387923823873
Validation loss: 2.6837364118615215

Epoch: 6| Step: 11
Training loss: 3.2441495910189917
Validation loss: 2.7087476831458965

Epoch: 6| Step: 12
Training loss: 3.4536814521782575
Validation loss: 2.715665620470554

Epoch: 6| Step: 13
Training loss: 2.269981457806786
Validation loss: 2.695059655926628

Epoch: 119| Step: 0
Training loss: 2.5128845072451957
Validation loss: 2.698286214524249

Epoch: 6| Step: 1
Training loss: 2.6087741731146097
Validation loss: 2.6968386354743017

Epoch: 6| Step: 2
Training loss: 2.176795709279243
Validation loss: 2.68642282994077

Epoch: 6| Step: 3
Training loss: 3.117620528888337
Validation loss: 2.713537709386763

Epoch: 6| Step: 4
Training loss: 2.4566087223018944
Validation loss: 2.6862379269577294

Epoch: 6| Step: 5
Training loss: 2.481505266026035
Validation loss: 2.7161575581565716

Epoch: 6| Step: 6
Training loss: 3.182333854899276
Validation loss: 2.681290791373803

Epoch: 6| Step: 7
Training loss: 2.3750967708749275
Validation loss: 2.685046424572076

Epoch: 6| Step: 8
Training loss: 2.0373902460973397
Validation loss: 2.7531158437056678

Epoch: 6| Step: 9
Training loss: 2.005161182460219
Validation loss: 2.6537244146034302

Epoch: 6| Step: 10
Training loss: 2.721515870955791
Validation loss: 2.709773235743807

Epoch: 6| Step: 11
Training loss: 2.6871673023198124
Validation loss: 2.705617307783645

Epoch: 6| Step: 12
Training loss: 2.7711830109727424
Validation loss: 2.694727779320372

Epoch: 6| Step: 13
Training loss: 4.454442950185799
Validation loss: 2.7085676585664737

Epoch: 120| Step: 0
Training loss: 1.799020895636741
Validation loss: 2.705930321215555

Epoch: 6| Step: 1
Training loss: 1.4218882465793499
Validation loss: 2.723686022225064

Epoch: 6| Step: 2
Training loss: 3.333620647127912
Validation loss: 2.7105051847111845

Epoch: 6| Step: 3
Training loss: 2.0060750962308287
Validation loss: 2.750077139330934

Epoch: 6| Step: 4
Training loss: 3.0204590313410584
Validation loss: 2.6990903549556813

Epoch: 6| Step: 5
Training loss: 2.1552862695019
Validation loss: 2.7220115489763086

Epoch: 6| Step: 6
Training loss: 2.633373981677169
Validation loss: 2.7429130105594832

Epoch: 6| Step: 7
Training loss: 2.432684420801625
Validation loss: 2.6935220486460505

Epoch: 6| Step: 8
Training loss: 3.1673318431992326
Validation loss: 2.714921263116939

Epoch: 6| Step: 9
Training loss: 3.1175457358963112
Validation loss: 2.6694893276890923

Epoch: 6| Step: 10
Training loss: 2.729387191909454
Validation loss: 2.720022946671268

Epoch: 6| Step: 11
Training loss: 3.2022559498953447
Validation loss: 2.673949970096924

Epoch: 6| Step: 12
Training loss: 3.22131615721416
Validation loss: 2.7408723307029166

Epoch: 6| Step: 13
Training loss: 2.296191678290318
Validation loss: 2.6954000992916263

Epoch: 121| Step: 0
Training loss: 2.2161139289062586
Validation loss: 2.6987914216415447

Epoch: 6| Step: 1
Training loss: 3.6811371557689236
Validation loss: 2.682852747521853

Epoch: 6| Step: 2
Training loss: 2.7478372565752593
Validation loss: 2.7032350025441043

Epoch: 6| Step: 3
Training loss: 1.6317361450729255
Validation loss: 2.687521006985462

Epoch: 6| Step: 4
Training loss: 2.8247923209222927
Validation loss: 2.7015908899269037

Epoch: 6| Step: 5
Training loss: 2.271842580613826
Validation loss: 2.7112881736651446

Epoch: 6| Step: 6
Training loss: 2.717152444044096
Validation loss: 2.686842136513592

Epoch: 6| Step: 7
Training loss: 2.3357521417365654
Validation loss: 2.69555923452561

Epoch: 6| Step: 8
Training loss: 3.436583379432471
Validation loss: 2.707376092909983

Epoch: 6| Step: 9
Training loss: 1.9843055532723681
Validation loss: 2.725906158147197

Epoch: 6| Step: 10
Training loss: 2.8840921348002393
Validation loss: 2.691818649825331

Epoch: 6| Step: 11
Training loss: 2.6151160397868187
Validation loss: 2.6917805237841415

Epoch: 6| Step: 12
Training loss: 2.6349896674342674
Validation loss: 2.6696897919953178

Epoch: 6| Step: 13
Training loss: 2.2707902630095766
Validation loss: 2.744900913138319

Epoch: 122| Step: 0
Training loss: 2.856923871503817
Validation loss: 2.6738761848937593

Epoch: 6| Step: 1
Training loss: 2.856740102309973
Validation loss: 2.6663021125587303

Epoch: 6| Step: 2
Training loss: 3.062687303693055
Validation loss: 2.678846206322061

Epoch: 6| Step: 3
Training loss: 2.851692928309962
Validation loss: 2.6830130072585345

Epoch: 6| Step: 4
Training loss: 2.381580872464213
Validation loss: 2.735303053163793

Epoch: 6| Step: 5
Training loss: 1.7438631766175974
Validation loss: 2.690371138469734

Epoch: 6| Step: 6
Training loss: 2.5686530695909373
Validation loss: 2.6908835793533

Epoch: 6| Step: 7
Training loss: 2.7716032598158375
Validation loss: 2.707662544448417

Epoch: 6| Step: 8
Training loss: 2.3264071892418685
Validation loss: 2.7101558286412044

Epoch: 6| Step: 9
Training loss: 2.7454758623180955
Validation loss: 2.6972893759176677

Epoch: 6| Step: 10
Training loss: 2.7947789015012203
Validation loss: 2.7197249525221583

Epoch: 6| Step: 11
Training loss: 3.216987794121901
Validation loss: 2.6898251563045577

Epoch: 6| Step: 12
Training loss: 2.3416394712921083
Validation loss: 2.693873382963991

Epoch: 6| Step: 13
Training loss: 2.352942179230869
Validation loss: 2.6817835790826026

Epoch: 123| Step: 0
Training loss: 2.782611299466905
Validation loss: 2.693466896232788

Epoch: 6| Step: 1
Training loss: 2.526968454976977
Validation loss: 2.711266653011973

Epoch: 6| Step: 2
Training loss: 2.275001014457728
Validation loss: 2.7387418491369933

Epoch: 6| Step: 3
Training loss: 2.0438561928134416
Validation loss: 2.7260142962687772

Epoch: 6| Step: 4
Training loss: 2.7956466108374225
Validation loss: 2.7162212360219447

Epoch: 6| Step: 5
Training loss: 2.868267967931912
Validation loss: 2.6942711115310964

Epoch: 6| Step: 6
Training loss: 2.49579094376864
Validation loss: 2.7094245895603413

Epoch: 6| Step: 7
Training loss: 2.4325645560532316
Validation loss: 2.665883899854057

Epoch: 6| Step: 8
Training loss: 2.3886655868235405
Validation loss: 2.704704648692635

Epoch: 6| Step: 9
Training loss: 2.94528465359018
Validation loss: 2.698328245652806

Epoch: 6| Step: 10
Training loss: 3.525375746592565
Validation loss: 2.6726062030552815

Epoch: 6| Step: 11
Training loss: 2.481510454243843
Validation loss: 2.663867522656886

Epoch: 6| Step: 12
Training loss: 2.8080127948186915
Validation loss: 2.7113789178376777

Epoch: 6| Step: 13
Training loss: 3.0858644114663543
Validation loss: 2.725294870681538

Epoch: 124| Step: 0
Training loss: 3.5152732842728684
Validation loss: 2.7314333420079815

Epoch: 6| Step: 1
Training loss: 2.6369350316388123
Validation loss: 2.6920545522215082

Epoch: 6| Step: 2
Training loss: 1.7783056318252142
Validation loss: 2.7257976997241298

Epoch: 6| Step: 3
Training loss: 2.550752835312639
Validation loss: 2.730058055894285

Epoch: 6| Step: 4
Training loss: 2.493153160779632
Validation loss: 2.705879117654265

Epoch: 6| Step: 5
Training loss: 2.145448360044794
Validation loss: 2.6885418562056214

Epoch: 6| Step: 6
Training loss: 2.3745372722991402
Validation loss: 2.706920773819296

Epoch: 6| Step: 7
Training loss: 2.7278518033088655
Validation loss: 2.729016452448166

Epoch: 6| Step: 8
Training loss: 2.197881532602192
Validation loss: 2.712968603087049

Epoch: 6| Step: 9
Training loss: 3.5819729433129415
Validation loss: 2.699020735355597

Epoch: 6| Step: 10
Training loss: 3.1524765572822058
Validation loss: 2.663546028001935

Epoch: 6| Step: 11
Training loss: 2.6658042069330876
Validation loss: 2.7403916298396194

Epoch: 6| Step: 12
Training loss: 2.488878690418663
Validation loss: 2.719652619419628

Epoch: 6| Step: 13
Training loss: 2.1088035657192643
Validation loss: 2.730075354881044

Epoch: 125| Step: 0
Training loss: 2.9538981722338145
Validation loss: 2.7040785701398464

Epoch: 6| Step: 1
Training loss: 2.138597182271598
Validation loss: 2.6565572359492777

Epoch: 6| Step: 2
Training loss: 2.622577094007662
Validation loss: 2.711090498720434

Epoch: 6| Step: 3
Training loss: 2.8184051404212593
Validation loss: 2.6547963304518416

Epoch: 6| Step: 4
Training loss: 3.0444388798696087
Validation loss: 2.6564985859878076

Epoch: 6| Step: 5
Training loss: 2.0994452833770847
Validation loss: 2.7154108290492713

Epoch: 6| Step: 6
Training loss: 2.420278502903377
Validation loss: 2.6581684579933675

Epoch: 6| Step: 7
Training loss: 2.5815311010963504
Validation loss: 2.698331665005813

Epoch: 6| Step: 8
Training loss: 2.730532316633102
Validation loss: 2.687773690354254

Epoch: 6| Step: 9
Training loss: 2.11329050114946
Validation loss: 2.6867934908295212

Epoch: 6| Step: 10
Training loss: 3.481223421663086
Validation loss: 2.6895799307799555

Epoch: 6| Step: 11
Training loss: 2.6334081140193426
Validation loss: 2.70603923771215

Epoch: 6| Step: 12
Training loss: 2.3186997482735974
Validation loss: 2.68557254997502

Epoch: 6| Step: 13
Training loss: 3.515422357441036
Validation loss: 2.705299724172144

Epoch: 126| Step: 0
Training loss: 2.6217565934880467
Validation loss: 2.677406277830329

Epoch: 6| Step: 1
Training loss: 2.7180170408532938
Validation loss: 2.673450791596499

Epoch: 6| Step: 2
Training loss: 2.903753048866041
Validation loss: 2.6702639065305527

Epoch: 6| Step: 3
Training loss: 2.2862120707907643
Validation loss: 2.712515995785037

Epoch: 6| Step: 4
Training loss: 3.1153854476985563
Validation loss: 2.6513518647899903

Epoch: 6| Step: 5
Training loss: 2.412745144104866
Validation loss: 2.681686704619862

Epoch: 6| Step: 6
Training loss: 1.7908335086662073
Validation loss: 2.7291312974336432

Epoch: 6| Step: 7
Training loss: 2.4066861240449304
Validation loss: 2.6883443320242835

Epoch: 6| Step: 8
Training loss: 2.093886413685214
Validation loss: 2.698554443760608

Epoch: 6| Step: 9
Training loss: 2.6815022810044793
Validation loss: 2.698617027474572

Epoch: 6| Step: 10
Training loss: 2.716774058023345
Validation loss: 2.7107072679064452

Epoch: 6| Step: 11
Training loss: 2.475794050208262
Validation loss: 2.6787632470268514

Epoch: 6| Step: 12
Training loss: 2.930055803672394
Validation loss: 2.7064412862163745

Epoch: 6| Step: 13
Training loss: 3.9545273536259895
Validation loss: 2.6911288165944955

Epoch: 127| Step: 0
Training loss: 3.1858870969548585
Validation loss: 2.687581129058637

Epoch: 6| Step: 1
Training loss: 2.55170137829865
Validation loss: 2.6875774298939423

Epoch: 6| Step: 2
Training loss: 1.968991037781382
Validation loss: 2.7148533582867778

Epoch: 6| Step: 3
Training loss: 1.9542801759636592
Validation loss: 2.7002660021748386

Epoch: 6| Step: 4
Training loss: 3.309578813106891
Validation loss: 2.725042882775506

Epoch: 6| Step: 5
Training loss: 2.3686973867889214
Validation loss: 2.7180519127147016

Epoch: 6| Step: 6
Training loss: 2.3441268617912177
Validation loss: 2.7073341975138514

Epoch: 6| Step: 7
Training loss: 2.674801300369798
Validation loss: 2.716935708115017

Epoch: 6| Step: 8
Training loss: 2.6803506191977005
Validation loss: 2.7452892720954343

Epoch: 6| Step: 9
Training loss: 2.798049254032302
Validation loss: 2.6891947403877614

Epoch: 6| Step: 10
Training loss: 3.5232864652010827
Validation loss: 2.710220113856635

Epoch: 6| Step: 11
Training loss: 2.540488256549327
Validation loss: 2.649332951017575

Epoch: 6| Step: 12
Training loss: 2.750500893491965
Validation loss: 2.661756429254423

Epoch: 6| Step: 13
Training loss: 1.733996375743418
Validation loss: 2.69386892921046

Epoch: 128| Step: 0
Training loss: 2.7293101459866813
Validation loss: 2.6703516977410215

Epoch: 6| Step: 1
Training loss: 2.1205464986655986
Validation loss: 2.667681322821404

Epoch: 6| Step: 2
Training loss: 2.9669355770634493
Validation loss: 2.7026218731114113

Epoch: 6| Step: 3
Training loss: 2.555737574172017
Validation loss: 2.704679855798713

Epoch: 6| Step: 4
Training loss: 2.306755043699812
Validation loss: 2.7618657267210094

Epoch: 6| Step: 5
Training loss: 1.8756879815901195
Validation loss: 2.698142155628204

Epoch: 6| Step: 6
Training loss: 3.1207122378586907
Validation loss: 2.699627929871399

Epoch: 6| Step: 7
Training loss: 2.6340533764991516
Validation loss: 2.7018236286247888

Epoch: 6| Step: 8
Training loss: 2.7332207559646884
Validation loss: 2.671811408002347

Epoch: 6| Step: 9
Training loss: 2.99070539695275
Validation loss: 2.690935553173967

Epoch: 6| Step: 10
Training loss: 2.4179731871236045
Validation loss: 2.695200067225736

Epoch: 6| Step: 11
Training loss: 2.668472800945512
Validation loss: 2.6926849441018694

Epoch: 6| Step: 12
Training loss: 3.287073689367346
Validation loss: 2.6983045067297193

Epoch: 6| Step: 13
Training loss: 2.5473203679207157
Validation loss: 2.683873604302062

Epoch: 129| Step: 0
Training loss: 2.9441077401722557
Validation loss: 2.6781484522278296

Epoch: 6| Step: 1
Training loss: 3.281677072978985
Validation loss: 2.6981279489432017

Epoch: 6| Step: 2
Training loss: 2.3214006024027687
Validation loss: 2.6597420001564833

Epoch: 6| Step: 3
Training loss: 2.418457869204756
Validation loss: 2.680534049933688

Epoch: 6| Step: 4
Training loss: 2.5018697422495517
Validation loss: 2.657274842576923

Epoch: 6| Step: 5
Training loss: 2.480041563239517
Validation loss: 2.6764718904782474

Epoch: 6| Step: 6
Training loss: 3.2581198567917515
Validation loss: 2.6595039391269544

Epoch: 6| Step: 7
Training loss: 2.5814036473688913
Validation loss: 2.6983777256152157

Epoch: 6| Step: 8
Training loss: 2.381671770044531
Validation loss: 2.647712616304182

Epoch: 6| Step: 9
Training loss: 2.472913779878632
Validation loss: 2.7089066938966893

Epoch: 6| Step: 10
Training loss: 2.0896934954381967
Validation loss: 2.70260676226298

Epoch: 6| Step: 11
Training loss: 2.005020040283507
Validation loss: 2.7265893382617867

Epoch: 6| Step: 12
Training loss: 3.7788813714988247
Validation loss: 2.7122179675154947

Epoch: 6| Step: 13
Training loss: 1.8967355390937426
Validation loss: 2.670279925252747

Epoch: 130| Step: 0
Training loss: 2.667634867697136
Validation loss: 2.700196170782642

Epoch: 6| Step: 1
Training loss: 3.0836007457621903
Validation loss: 2.651561617815005

Epoch: 6| Step: 2
Training loss: 2.4602869536348955
Validation loss: 2.6654426104049955

Epoch: 6| Step: 3
Training loss: 2.4381360911312875
Validation loss: 2.715639425697935

Epoch: 6| Step: 4
Training loss: 2.2378065527932947
Validation loss: 2.7014080813900136

Epoch: 6| Step: 5
Training loss: 2.232629053843345
Validation loss: 2.6438841648289717

Epoch: 6| Step: 6
Training loss: 2.4516945331095386
Validation loss: 2.6972886469218653

Epoch: 6| Step: 7
Training loss: 2.392159162935324
Validation loss: 2.681660088074137

Epoch: 6| Step: 8
Training loss: 2.5465222447905087
Validation loss: 2.698972092608276

Epoch: 6| Step: 9
Training loss: 2.9361296358930633
Validation loss: 2.72324548278708

Epoch: 6| Step: 10
Training loss: 2.963801063667249
Validation loss: 2.6986752560619816

Epoch: 6| Step: 11
Training loss: 3.03523370160389
Validation loss: 2.6945702685128987

Epoch: 6| Step: 12
Training loss: 2.9778683018407497
Validation loss: 2.6778445034160976

Epoch: 6| Step: 13
Training loss: 2.407103350041448
Validation loss: 2.7391326560427407

Epoch: 131| Step: 0
Training loss: 2.0264421343444368
Validation loss: 2.708861911077888

Epoch: 6| Step: 1
Training loss: 2.727850579686361
Validation loss: 2.690461079752469

Epoch: 6| Step: 2
Training loss: 2.611817912445233
Validation loss: 2.7077898163250653

Epoch: 6| Step: 3
Training loss: 3.225860593249131
Validation loss: 2.6506915059556957

Epoch: 6| Step: 4
Training loss: 2.209939360671292
Validation loss: 2.7112097501069776

Epoch: 6| Step: 5
Training loss: 2.147398097292823
Validation loss: 2.689717908869088

Epoch: 6| Step: 6
Training loss: 3.793446189618389
Validation loss: 2.6708717355204956

Epoch: 6| Step: 7
Training loss: 2.768064554415393
Validation loss: 2.724039874198211

Epoch: 6| Step: 8
Training loss: 2.940934466335202
Validation loss: 2.6888342185666123

Epoch: 6| Step: 9
Training loss: 2.3677891133585685
Validation loss: 2.69341412889951

Epoch: 6| Step: 10
Training loss: 2.204078738424415
Validation loss: 2.686680143817895

Epoch: 6| Step: 11
Training loss: 2.504609816995091
Validation loss: 2.7189068322921033

Epoch: 6| Step: 12
Training loss: 2.178479588022272
Validation loss: 2.675996003119613

Epoch: 6| Step: 13
Training loss: 2.730026886077508
Validation loss: 2.6968489818890946

Epoch: 132| Step: 0
Training loss: 2.7758139301569758
Validation loss: 2.6919967261055886

Epoch: 6| Step: 1
Training loss: 2.948232645055359
Validation loss: 2.6816780281253227

Epoch: 6| Step: 2
Training loss: 2.418108268989505
Validation loss: 2.6808444642872904

Epoch: 6| Step: 3
Training loss: 2.982031416299609
Validation loss: 2.6667415908957772

Epoch: 6| Step: 4
Training loss: 2.914993587375608
Validation loss: 2.732806625486071

Epoch: 6| Step: 5
Training loss: 2.547102561098903
Validation loss: 2.6915686197449036

Epoch: 6| Step: 6
Training loss: 2.9850811347605806
Validation loss: 2.6891399644499594

Epoch: 6| Step: 7
Training loss: 1.9729632148233018
Validation loss: 2.658260544384632

Epoch: 6| Step: 8
Training loss: 2.591966958347518
Validation loss: 2.6604993616171315

Epoch: 6| Step: 9
Training loss: 2.37774018270812
Validation loss: 2.7494864147365425

Epoch: 6| Step: 10
Training loss: 2.6689973917519954
Validation loss: 2.689240622885347

Epoch: 6| Step: 11
Training loss: 3.0434441446086273
Validation loss: 2.667678647397227

Epoch: 6| Step: 12
Training loss: 1.6728524888944092
Validation loss: 2.6977059329568096

Epoch: 6| Step: 13
Training loss: 2.460619030887804
Validation loss: 2.7098792126590143

Epoch: 133| Step: 0
Training loss: 2.842197539409839
Validation loss: 2.6692362436393946

Epoch: 6| Step: 1
Training loss: 3.157839837349971
Validation loss: 2.698296514534283

Epoch: 6| Step: 2
Training loss: 2.4566694760489822
Validation loss: 2.6958444606296945

Epoch: 6| Step: 3
Training loss: 2.468603781703836
Validation loss: 2.753396005982633

Epoch: 6| Step: 4
Training loss: 2.8303220866208267
Validation loss: 2.660073305347842

Epoch: 6| Step: 5
Training loss: 2.70559235790827
Validation loss: 2.7107127948406067

Epoch: 6| Step: 6
Training loss: 1.810795344120863
Validation loss: 2.73286535917541

Epoch: 6| Step: 7
Training loss: 2.1412457310978636
Validation loss: 2.6962389680100842

Epoch: 6| Step: 8
Training loss: 2.7252649755875678
Validation loss: 2.704148705138721

Epoch: 6| Step: 9
Training loss: 3.0586888479987744
Validation loss: 2.7047611861049927

Epoch: 6| Step: 10
Training loss: 2.8615990832669924
Validation loss: 2.713398202607108

Epoch: 6| Step: 11
Training loss: 2.3335791072379672
Validation loss: 2.6553303428860184

Epoch: 6| Step: 12
Training loss: 2.7892823546706684
Validation loss: 2.6380410568323303

Epoch: 6| Step: 13
Training loss: 2.388621070053283
Validation loss: 2.6776037720999537

Epoch: 134| Step: 0
Training loss: 2.1067055093628846
Validation loss: 2.7013206503542557

Epoch: 6| Step: 1
Training loss: 3.102442849468191
Validation loss: 2.718321077455947

Epoch: 6| Step: 2
Training loss: 2.5997501510002325
Validation loss: 2.6860694278121033

Epoch: 6| Step: 3
Training loss: 2.0661494017918702
Validation loss: 2.6465794779941456

Epoch: 6| Step: 4
Training loss: 2.8622405488485163
Validation loss: 2.7104933988656557

Epoch: 6| Step: 5
Training loss: 2.32463016234693
Validation loss: 2.705060212196803

Epoch: 6| Step: 6
Training loss: 2.610505276145491
Validation loss: 2.6966155942319796

Epoch: 6| Step: 7
Training loss: 1.936108674124314
Validation loss: 2.688632069408274

Epoch: 6| Step: 8
Training loss: 3.4961980878721834
Validation loss: 2.6823542354146563

Epoch: 6| Step: 9
Training loss: 2.168141511099333
Validation loss: 2.7234293501439266

Epoch: 6| Step: 10
Training loss: 2.8917550842076887
Validation loss: 2.648655401276545

Epoch: 6| Step: 11
Training loss: 2.62272545499064
Validation loss: 2.6970489971693445

Epoch: 6| Step: 12
Training loss: 2.776882299619255
Validation loss: 2.692986853317088

Epoch: 6| Step: 13
Training loss: 2.7647609761899212
Validation loss: 2.714799393741313

Epoch: 135| Step: 0
Training loss: 2.585308447905779
Validation loss: 2.7277902004704613

Epoch: 6| Step: 1
Training loss: 2.5404302581061478
Validation loss: 2.6919431176096387

Epoch: 6| Step: 2
Training loss: 1.8365978595470678
Validation loss: 2.7020797050405476

Epoch: 6| Step: 3
Training loss: 2.749081978589599
Validation loss: 2.670670863652016

Epoch: 6| Step: 4
Training loss: 3.032120727068041
Validation loss: 2.6945530522213583

Epoch: 6| Step: 5
Training loss: 2.6310411601426433
Validation loss: 2.7129473811434877

Epoch: 6| Step: 6
Training loss: 3.4211149024701464
Validation loss: 2.683419633044592

Epoch: 6| Step: 7
Training loss: 2.2981557583922685
Validation loss: 2.6776393215512604

Epoch: 6| Step: 8
Training loss: 3.364264615831292
Validation loss: 2.6621723349522486

Epoch: 6| Step: 9
Training loss: 2.388353652530476
Validation loss: 2.691087585650939

Epoch: 6| Step: 10
Training loss: 2.3297987688127964
Validation loss: 2.7153744655484657

Epoch: 6| Step: 11
Training loss: 3.1152962131401676
Validation loss: 2.6694331971176717

Epoch: 6| Step: 12
Training loss: 2.08867908003538
Validation loss: 2.6575509058018065

Epoch: 6| Step: 13
Training loss: 2.1135578644346307
Validation loss: 2.7100115426987004

Epoch: 136| Step: 0
Training loss: 1.814575585379047
Validation loss: 2.688392407050185

Epoch: 6| Step: 1
Training loss: 2.1961467420331284
Validation loss: 2.670125270723986

Epoch: 6| Step: 2
Training loss: 2.3574387645353454
Validation loss: 2.700331007015605

Epoch: 6| Step: 3
Training loss: 2.480063962573016
Validation loss: 2.640007337085022

Epoch: 6| Step: 4
Training loss: 2.2801320720366562
Validation loss: 2.680449645120604

Epoch: 6| Step: 5
Training loss: 3.599414905049348
Validation loss: 2.6771024544729967

Epoch: 6| Step: 6
Training loss: 2.688717056420192
Validation loss: 2.6781345424840346

Epoch: 6| Step: 7
Training loss: 2.469418302449369
Validation loss: 2.726683509849955

Epoch: 6| Step: 8
Training loss: 3.4778541480045537
Validation loss: 2.7358254476899395

Epoch: 6| Step: 9
Training loss: 2.430698883432534
Validation loss: 2.6900122867585265

Epoch: 6| Step: 10
Training loss: 2.84036724402543
Validation loss: 2.7202578427291533

Epoch: 6| Step: 11
Training loss: 3.3417129729020294
Validation loss: 2.708112275699574

Epoch: 6| Step: 12
Training loss: 2.0800464896361937
Validation loss: 2.6710570236547224

Epoch: 6| Step: 13
Training loss: 2.471234773271545
Validation loss: 2.6985764457903287

Epoch: 137| Step: 0
Training loss: 2.380302533067127
Validation loss: 2.6814803272208434

Epoch: 6| Step: 1
Training loss: 2.9064626308304846
Validation loss: 2.709152338906303

Epoch: 6| Step: 2
Training loss: 2.600603081377729
Validation loss: 2.6789287544242852

Epoch: 6| Step: 3
Training loss: 2.2151763504815842
Validation loss: 2.6588532297952048

Epoch: 6| Step: 4
Training loss: 2.6876205594722626
Validation loss: 2.704665164975311

Epoch: 6| Step: 5
Training loss: 2.473339113072774
Validation loss: 2.70120875427773

Epoch: 6| Step: 6
Training loss: 2.5014771865698076
Validation loss: 2.6487963318992125

Epoch: 6| Step: 7
Training loss: 2.7268901289267298
Validation loss: 2.7003611999834716

Epoch: 6| Step: 8
Training loss: 2.90577086734245
Validation loss: 2.684242831226391

Epoch: 6| Step: 9
Training loss: 2.691540984613961
Validation loss: 2.6601968492048567

Epoch: 6| Step: 10
Training loss: 2.448290099750563
Validation loss: 2.6780150694459994

Epoch: 6| Step: 11
Training loss: 1.926334819968493
Validation loss: 2.7151047339254806

Epoch: 6| Step: 12
Training loss: 2.596897834833513
Validation loss: 2.6352122802027202

Epoch: 6| Step: 13
Training loss: 3.465321539069733
Validation loss: 2.7099556481360487

Epoch: 138| Step: 0
Training loss: 2.6266869165475843
Validation loss: 2.664035771844843

Epoch: 6| Step: 1
Training loss: 2.6589580419701098
Validation loss: 2.7213786383979532

Epoch: 6| Step: 2
Training loss: 2.478092623447421
Validation loss: 2.7058671524896143

Epoch: 6| Step: 3
Training loss: 2.3924918272064195
Validation loss: 2.707033197093611

Epoch: 6| Step: 4
Training loss: 3.5593247568337136
Validation loss: 2.6770192821704506

Epoch: 6| Step: 5
Training loss: 2.886808112675094
Validation loss: 2.6861314811521937

Epoch: 6| Step: 6
Training loss: 2.71662451432491
Validation loss: 2.6757085213187106

Epoch: 6| Step: 7
Training loss: 2.0905646390996635
Validation loss: 2.6454541612355045

Epoch: 6| Step: 8
Training loss: 2.5437290912490558
Validation loss: 2.6700019731092226

Epoch: 6| Step: 9
Training loss: 2.9077572759419685
Validation loss: 2.7019579196751655

Epoch: 6| Step: 10
Training loss: 2.4974132506738074
Validation loss: 2.696666530674179

Epoch: 6| Step: 11
Training loss: 2.036379163004773
Validation loss: 2.6967064946538732

Epoch: 6| Step: 12
Training loss: 2.5295711648449695
Validation loss: 2.6804518276744

Epoch: 6| Step: 13
Training loss: 2.1400297130767982
Validation loss: 2.6895452244972478

Epoch: 139| Step: 0
Training loss: 3.3154194760059976
Validation loss: 2.6688192572736225

Epoch: 6| Step: 1
Training loss: 2.6720346325040447
Validation loss: 2.702994675475886

Epoch: 6| Step: 2
Training loss: 2.407460886478091
Validation loss: 2.692295715881677

Epoch: 6| Step: 3
Training loss: 2.423991502885435
Validation loss: 2.6943861311202024

Epoch: 6| Step: 4
Training loss: 2.597508292896298
Validation loss: 2.7219884677342585

Epoch: 6| Step: 5
Training loss: 2.7095285761512957
Validation loss: 2.682080885747931

Epoch: 6| Step: 6
Training loss: 2.3073844001223502
Validation loss: 2.655567161527517

Epoch: 6| Step: 7
Training loss: 3.3234387568591153
Validation loss: 2.7114586516714945

Epoch: 6| Step: 8
Training loss: 1.8946379012144088
Validation loss: 2.7318691696313593

Epoch: 6| Step: 9
Training loss: 2.5090833634613627
Validation loss: 2.683943931061191

Epoch: 6| Step: 10
Training loss: 2.076841947813143
Validation loss: 2.7625506748549338

Epoch: 6| Step: 11
Training loss: 3.2233010126786112
Validation loss: 2.663981176288714

Epoch: 6| Step: 12
Training loss: 2.6466593216506675
Validation loss: 2.7106860471739744

Epoch: 6| Step: 13
Training loss: 1.6224345717440978
Validation loss: 2.7088734343016663

Epoch: 140| Step: 0
Training loss: 2.3608323200662173
Validation loss: 2.6834878823754527

Epoch: 6| Step: 1
Training loss: 1.6004439751240862
Validation loss: 2.652048328688286

Epoch: 6| Step: 2
Training loss: 2.9253848613326183
Validation loss: 2.7231242391952346

Epoch: 6| Step: 3
Training loss: 2.9789414398491925
Validation loss: 2.685690382895881

Epoch: 6| Step: 4
Training loss: 2.6730325433396214
Validation loss: 2.6991149911844055

Epoch: 6| Step: 5
Training loss: 2.745090436991682
Validation loss: 2.6990969048825257

Epoch: 6| Step: 6
Training loss: 2.127338693243623
Validation loss: 2.710134555347647

Epoch: 6| Step: 7
Training loss: 2.7078815572465817
Validation loss: 2.702877352232677

Epoch: 6| Step: 8
Training loss: 2.304553011833441
Validation loss: 2.721415119496325

Epoch: 6| Step: 9
Training loss: 2.834671452505977
Validation loss: 2.7078457600912267

Epoch: 6| Step: 10
Training loss: 2.9751832024079836
Validation loss: 2.6915898188050003

Epoch: 6| Step: 11
Training loss: 2.3654065372675057
Validation loss: 2.684899767581394

Epoch: 6| Step: 12
Training loss: 2.848943641713052
Validation loss: 2.6431823470917895

Epoch: 6| Step: 13
Training loss: 2.628723047456596
Validation loss: 2.6966319517236017

Epoch: 141| Step: 0
Training loss: 2.7302341169362143
Validation loss: 2.634641783826628

Epoch: 6| Step: 1
Training loss: 3.3217000777087025
Validation loss: 2.711335470278979

Epoch: 6| Step: 2
Training loss: 2.2578194694015488
Validation loss: 2.677644021549775

Epoch: 6| Step: 3
Training loss: 2.466056319924744
Validation loss: 2.7083127256860475

Epoch: 6| Step: 4
Training loss: 1.9469394850728583
Validation loss: 2.6489675421419205

Epoch: 6| Step: 5
Training loss: 2.718174840663585
Validation loss: 2.6132061069188643

Epoch: 6| Step: 6
Training loss: 2.3777937268626403
Validation loss: 2.697543372389337

Epoch: 6| Step: 7
Training loss: 2.512792283702566
Validation loss: 2.738667092554532

Epoch: 6| Step: 8
Training loss: 2.5536935721804412
Validation loss: 2.690923847386007

Epoch: 6| Step: 9
Training loss: 2.6408424965035517
Validation loss: 2.6728761183066063

Epoch: 6| Step: 10
Training loss: 2.7339835622442625
Validation loss: 2.7355677493357136

Epoch: 6| Step: 11
Training loss: 2.423303884023824
Validation loss: 2.644811681209431

Epoch: 6| Step: 12
Training loss: 3.178643732488493
Validation loss: 2.6694849398522247

Epoch: 6| Step: 13
Training loss: 2.706265163599397
Validation loss: 2.669978661657955

Epoch: 142| Step: 0
Training loss: 2.6017324947685756
Validation loss: 2.6885341591944014

Epoch: 6| Step: 1
Training loss: 3.3132619881064422
Validation loss: 2.669580671614667

Epoch: 6| Step: 2
Training loss: 2.663203394572374
Validation loss: 2.6949033564860096

Epoch: 6| Step: 3
Training loss: 2.7378916769397144
Validation loss: 2.6408249459631006

Epoch: 6| Step: 4
Training loss: 2.702368216887694
Validation loss: 2.6884352670408664

Epoch: 6| Step: 5
Training loss: 1.6123510454561591
Validation loss: 2.6686543352341605

Epoch: 6| Step: 6
Training loss: 2.6394323782044067
Validation loss: 2.7051150420024923

Epoch: 6| Step: 7
Training loss: 2.467171562776314
Validation loss: 2.657360254573131

Epoch: 6| Step: 8
Training loss: 1.814457986782036
Validation loss: 2.713632227153488

Epoch: 6| Step: 9
Training loss: 2.441513962467665
Validation loss: 2.725572180493829

Epoch: 6| Step: 10
Training loss: 2.870921019463963
Validation loss: 2.727911310923709

Epoch: 6| Step: 11
Training loss: 2.7183197382577817
Validation loss: 2.6556922476616833

Epoch: 6| Step: 12
Training loss: 2.4548223175575883
Validation loss: 2.6825150362253987

Epoch: 6| Step: 13
Training loss: 3.247534183266494
Validation loss: 2.70634651730973

Epoch: 143| Step: 0
Training loss: 2.3683373204984486
Validation loss: 2.6587738535679035

Epoch: 6| Step: 1
Training loss: 2.131418296456088
Validation loss: 2.693314573536765

Epoch: 6| Step: 2
Training loss: 2.913780382833402
Validation loss: 2.6774492772996794

Epoch: 6| Step: 3
Training loss: 2.4878763920476743
Validation loss: 2.6885202431100046

Epoch: 6| Step: 4
Training loss: 2.7417703077521267
Validation loss: 2.6747036142258493

Epoch: 6| Step: 5
Training loss: 2.004566582045667
Validation loss: 2.720235292275875

Epoch: 6| Step: 6
Training loss: 2.966502252230359
Validation loss: 2.6810849792089124

Epoch: 6| Step: 7
Training loss: 2.4971659809474755
Validation loss: 2.7098652756352584

Epoch: 6| Step: 8
Training loss: 3.219650142689544
Validation loss: 2.663200780107629

Epoch: 6| Step: 9
Training loss: 2.1375812135850256
Validation loss: 2.703285727013141

Epoch: 6| Step: 10
Training loss: 2.582931938571358
Validation loss: 2.701071308123416

Epoch: 6| Step: 11
Training loss: 2.730341088362637
Validation loss: 2.698260619669909

Epoch: 6| Step: 12
Training loss: 2.177204207817131
Validation loss: 2.6888409462653593

Epoch: 6| Step: 13
Training loss: 3.385875557340364
Validation loss: 2.6666332506834354

Epoch: 144| Step: 0
Training loss: 2.3579512588795617
Validation loss: 2.653056117781555

Epoch: 6| Step: 1
Training loss: 2.5442794961043242
Validation loss: 2.652023267796001

Epoch: 6| Step: 2
Training loss: 2.894000912163307
Validation loss: 2.686791071069461

Epoch: 6| Step: 3
Training loss: 3.0324474997508393
Validation loss: 2.6879697242762313

Epoch: 6| Step: 4
Training loss: 2.6157594343159483
Validation loss: 2.6839925366964485

Epoch: 6| Step: 5
Training loss: 3.194642833870249
Validation loss: 2.6419949338042983

Epoch: 6| Step: 6
Training loss: 2.4896792043531186
Validation loss: 2.6813122141537553

Epoch: 6| Step: 7
Training loss: 2.7961548458820475
Validation loss: 2.7138790295418795

Epoch: 6| Step: 8
Training loss: 2.072795487381069
Validation loss: 2.7090059014814294

Epoch: 6| Step: 9
Training loss: 2.502151707697789
Validation loss: 2.693554800151323

Epoch: 6| Step: 10
Training loss: 2.5218807177851073
Validation loss: 2.682399877477503

Epoch: 6| Step: 11
Training loss: 2.7234881100353916
Validation loss: 2.6601512039674224

Epoch: 6| Step: 12
Training loss: 2.866895780352902
Validation loss: 2.7092196504344463

Epoch: 6| Step: 13
Training loss: 1.298868692094385
Validation loss: 2.666413745755598

Epoch: 145| Step: 0
Training loss: 2.3769922433485062
Validation loss: 2.677398830314888

Epoch: 6| Step: 1
Training loss: 2.1069434951425805
Validation loss: 2.7178888217023816

Epoch: 6| Step: 2
Training loss: 2.4232369807877587
Validation loss: 2.725797353616341

Epoch: 6| Step: 3
Training loss: 2.904589927475056
Validation loss: 2.681150480649783

Epoch: 6| Step: 4
Training loss: 2.8426961098745154
Validation loss: 2.6594425595835185

Epoch: 6| Step: 5
Training loss: 2.6912346551283153
Validation loss: 2.697034415916391

Epoch: 6| Step: 6
Training loss: 2.564260854725802
Validation loss: 2.700179269020495

Epoch: 6| Step: 7
Training loss: 2.4373870236551016
Validation loss: 2.6496851298877204

Epoch: 6| Step: 8
Training loss: 2.6769363026498825
Validation loss: 2.67102655030512

Epoch: 6| Step: 9
Training loss: 2.6726513008132065
Validation loss: 2.705982089404312

Epoch: 6| Step: 10
Training loss: 3.0775316315178896
Validation loss: 2.6616375618003434

Epoch: 6| Step: 11
Training loss: 2.5769115944835383
Validation loss: 2.68234265943339

Epoch: 6| Step: 12
Training loss: 2.8643398851926203
Validation loss: 2.676054355572398

Epoch: 6| Step: 13
Training loss: 1.3266096558294076
Validation loss: 2.6266976564053506

Epoch: 146| Step: 0
Training loss: 2.4186361990877416
Validation loss: 2.655553405260162

Epoch: 6| Step: 1
Training loss: 2.8395789441424393
Validation loss: 2.6434398884564727

Epoch: 6| Step: 2
Training loss: 2.9701139830221255
Validation loss: 2.694249375975605

Epoch: 6| Step: 3
Training loss: 2.125513351366191
Validation loss: 2.6860386642662597

Epoch: 6| Step: 4
Training loss: 2.354184941133671
Validation loss: 2.6885080586102394

Epoch: 6| Step: 5
Training loss: 2.5394221124543606
Validation loss: 2.7047021440112022

Epoch: 6| Step: 6
Training loss: 2.550274505051749
Validation loss: 2.652613218845063

Epoch: 6| Step: 7
Training loss: 2.073095789954577
Validation loss: 2.65683705202379

Epoch: 6| Step: 8
Training loss: 2.729275203808249
Validation loss: 2.6959155011711995

Epoch: 6| Step: 9
Training loss: 1.7894839660744788
Validation loss: 2.6452036049987613

Epoch: 6| Step: 10
Training loss: 3.4848279444776473
Validation loss: 2.7346922875241

Epoch: 6| Step: 11
Training loss: 2.002592076007539
Validation loss: 2.696086482435832

Epoch: 6| Step: 12
Training loss: 3.1392506491297447
Validation loss: 2.6623386021975497

Epoch: 6| Step: 13
Training loss: 3.1041396649784274
Validation loss: 2.6798716113260754

Epoch: 147| Step: 0
Training loss: 3.242083223803164
Validation loss: 2.714590885440613

Epoch: 6| Step: 1
Training loss: 2.4319198509360773
Validation loss: 2.681129014505648

Epoch: 6| Step: 2
Training loss: 1.9235450497640234
Validation loss: 2.7308426268198316

Epoch: 6| Step: 3
Training loss: 1.9790497460881207
Validation loss: 2.6590230520398017

Epoch: 6| Step: 4
Training loss: 2.816920642199468
Validation loss: 2.7356516680653837

Epoch: 6| Step: 5
Training loss: 2.8514272161295433
Validation loss: 2.705397298169005

Epoch: 6| Step: 6
Training loss: 2.11586548468176
Validation loss: 2.718799216739982

Epoch: 6| Step: 7
Training loss: 3.1482074360053893
Validation loss: 2.7445281032714

Epoch: 6| Step: 8
Training loss: 2.1579727809416207
Validation loss: 2.706060802779813

Epoch: 6| Step: 9
Training loss: 3.286996224099762
Validation loss: 2.695833734728897

Epoch: 6| Step: 10
Training loss: 2.1515950252426514
Validation loss: 2.67900457080508

Epoch: 6| Step: 11
Training loss: 3.0771402245705217
Validation loss: 2.7045419158808364

Epoch: 6| Step: 12
Training loss: 2.4105618968613634
Validation loss: 2.698469359007475

Epoch: 6| Step: 13
Training loss: 2.745270824170317
Validation loss: 2.7000837296355975

Epoch: 148| Step: 0
Training loss: 1.9665846042430395
Validation loss: 2.707897106343549

Epoch: 6| Step: 1
Training loss: 2.765067437644677
Validation loss: 2.6952084776125593

Epoch: 6| Step: 2
Training loss: 1.7265042256320975
Validation loss: 2.674625403314578

Epoch: 6| Step: 3
Training loss: 2.94187925469322
Validation loss: 2.718124894869534

Epoch: 6| Step: 4
Training loss: 2.6992046173653175
Validation loss: 2.733227217535501

Epoch: 6| Step: 5
Training loss: 1.846190889686849
Validation loss: 2.7031897843489685

Epoch: 6| Step: 6
Training loss: 2.753097350450421
Validation loss: 2.6822973251083972

Epoch: 6| Step: 7
Training loss: 2.360125491798293
Validation loss: 2.7052134741392666

Epoch: 6| Step: 8
Training loss: 2.4107609860372547
Validation loss: 2.695156113443776

Epoch: 6| Step: 9
Training loss: 3.0795235337146147
Validation loss: 2.7124223672573304

Epoch: 6| Step: 10
Training loss: 2.4866172220906857
Validation loss: 2.6700905429582846

Epoch: 6| Step: 11
Training loss: 3.207296938931595
Validation loss: 2.660137011226687

Epoch: 6| Step: 12
Training loss: 2.686457409562101
Validation loss: 2.6868316590120207

Epoch: 6| Step: 13
Training loss: 3.1945477528844335
Validation loss: 2.72134674082243

Epoch: 149| Step: 0
Training loss: 2.15340844490845
Validation loss: 2.6442302323448463

Epoch: 6| Step: 1
Training loss: 2.068148651771723
Validation loss: 2.7280869711091045

Epoch: 6| Step: 2
Training loss: 1.9085018427827176
Validation loss: 2.701120935250889

Epoch: 6| Step: 3
Training loss: 2.5510400521047543
Validation loss: 2.6866713570170355

Epoch: 6| Step: 4
Training loss: 2.2775895524241245
Validation loss: 2.6958673025955746

Epoch: 6| Step: 5
Training loss: 3.153015897014503
Validation loss: 2.6682874131055243

Epoch: 6| Step: 6
Training loss: 1.9429970561666368
Validation loss: 2.6911342079787923

Epoch: 6| Step: 7
Training loss: 3.3902255759117867
Validation loss: 2.6583289179143406

Epoch: 6| Step: 8
Training loss: 2.8044462392424765
Validation loss: 2.6823049936621564

Epoch: 6| Step: 9
Training loss: 2.2004306631781403
Validation loss: 2.684578596711479

Epoch: 6| Step: 10
Training loss: 3.2468810153938503
Validation loss: 2.6956107843794928

Epoch: 6| Step: 11
Training loss: 3.137112147458618
Validation loss: 2.672600339283665

Epoch: 6| Step: 12
Training loss: 1.9807044496548
Validation loss: 2.668255763821194

Epoch: 6| Step: 13
Training loss: 2.7900855488120686
Validation loss: 2.6752526192444614

Epoch: 150| Step: 0
Training loss: 2.888686401248128
Validation loss: 2.6525116394523063

Epoch: 6| Step: 1
Training loss: 2.8330340694879395
Validation loss: 2.65222936907945

Epoch: 6| Step: 2
Training loss: 2.7312759712433508
Validation loss: 2.63587617173608

Epoch: 6| Step: 3
Training loss: 2.4699457869970236
Validation loss: 2.631530161207313

Epoch: 6| Step: 4
Training loss: 2.9007000176942404
Validation loss: 2.6836959662492212

Epoch: 6| Step: 5
Training loss: 3.3001545147412403
Validation loss: 2.6821054363901977

Epoch: 6| Step: 6
Training loss: 1.714058524642688
Validation loss: 2.6882908776586523

Epoch: 6| Step: 7
Training loss: 2.319767743521022
Validation loss: 2.715714263459072

Epoch: 6| Step: 8
Training loss: 2.380426131174627
Validation loss: 2.7111499685739675

Epoch: 6| Step: 9
Training loss: 2.4275481688948393
Validation loss: 2.7174438009233817

Epoch: 6| Step: 10
Training loss: 2.229974000377224
Validation loss: 2.669414914032039

Epoch: 6| Step: 11
Training loss: 2.3525741276833587
Validation loss: 2.750229008406522

Epoch: 6| Step: 12
Training loss: 3.380059723411065
Validation loss: 2.707479235923114

Epoch: 6| Step: 13
Training loss: 1.9018495140912879
Validation loss: 2.671113182008009

Epoch: 151| Step: 0
Training loss: 2.0022767935760686
Validation loss: 2.7012134493310764

Epoch: 6| Step: 1
Training loss: 2.8228680558377053
Validation loss: 2.75338479758082

Epoch: 6| Step: 2
Training loss: 2.2306239513374444
Validation loss: 2.6830555470969943

Epoch: 6| Step: 3
Training loss: 2.2734203010249345
Validation loss: 2.7213948809594637

Epoch: 6| Step: 4
Training loss: 3.1458109840121273
Validation loss: 2.7207613661694268

Epoch: 6| Step: 5
Training loss: 2.1748271610381833
Validation loss: 2.7010116457851203

Epoch: 6| Step: 6
Training loss: 2.79512557401046
Validation loss: 2.6863990497513552

Epoch: 6| Step: 7
Training loss: 2.2814059269538243
Validation loss: 2.654815872517649

Epoch: 6| Step: 8
Training loss: 3.091423315734264
Validation loss: 2.685226203514955

Epoch: 6| Step: 9
Training loss: 2.7790006478368245
Validation loss: 2.715045060816264

Epoch: 6| Step: 10
Training loss: 2.4493793635659213
Validation loss: 2.6973358516071357

Epoch: 6| Step: 11
Training loss: 2.4086991763729073
Validation loss: 2.713969330024382

Epoch: 6| Step: 12
Training loss: 2.533115688394392
Validation loss: 2.690989299873909

Epoch: 6| Step: 13
Training loss: 2.607834869709376
Validation loss: 2.714635411316705

Epoch: 152| Step: 0
Training loss: 2.2498432740622216
Validation loss: 2.7128416403212565

Epoch: 6| Step: 1
Training loss: 2.809667559741659
Validation loss: 2.700373481949113

Epoch: 6| Step: 2
Training loss: 2.04172689647455
Validation loss: 2.6572647694666145

Epoch: 6| Step: 3
Training loss: 2.0356396706848603
Validation loss: 2.687821003009816

Epoch: 6| Step: 4
Training loss: 3.613169867371103
Validation loss: 2.6814228725257827

Epoch: 6| Step: 5
Training loss: 2.2349487848409
Validation loss: 2.6480556170002885

Epoch: 6| Step: 6
Training loss: 2.7927776991584032
Validation loss: 2.681189757033495

Epoch: 6| Step: 7
Training loss: 2.809638708380645
Validation loss: 2.686272358172167

Epoch: 6| Step: 8
Training loss: 1.7279981625246945
Validation loss: 2.6724940764577574

Epoch: 6| Step: 9
Training loss: 2.497216487062757
Validation loss: 2.69115130801226

Epoch: 6| Step: 10
Training loss: 2.1124694731724407
Validation loss: 2.683147952183582

Epoch: 6| Step: 11
Training loss: 3.1675728622281785
Validation loss: 2.690426197120087

Epoch: 6| Step: 12
Training loss: 2.2716233398753856
Validation loss: 2.678309457686819

Epoch: 6| Step: 13
Training loss: 3.4259059626672568
Validation loss: 2.6804351371181454

Epoch: 153| Step: 0
Training loss: 2.4020729966835903
Validation loss: 2.649451542241432

Epoch: 6| Step: 1
Training loss: 2.6325955174172115
Validation loss: 2.668945414317711

Epoch: 6| Step: 2
Training loss: 2.098817301540699
Validation loss: 2.70880123731629

Epoch: 6| Step: 3
Training loss: 3.278449761928906
Validation loss: 2.6477338266449406

Epoch: 6| Step: 4
Training loss: 1.9119118577759533
Validation loss: 2.670725433804977

Epoch: 6| Step: 5
Training loss: 2.5382556748444642
Validation loss: 2.677487784544208

Epoch: 6| Step: 6
Training loss: 3.1472426198814794
Validation loss: 2.7083645751766667

Epoch: 6| Step: 7
Training loss: 1.8508708321890321
Validation loss: 2.6916196421719567

Epoch: 6| Step: 8
Training loss: 2.7041559623737594
Validation loss: 2.6867313206246344

Epoch: 6| Step: 9
Training loss: 2.0111889187752587
Validation loss: 2.6661846246906165

Epoch: 6| Step: 10
Training loss: 2.6456368641234724
Validation loss: 2.656723827588537

Epoch: 6| Step: 11
Training loss: 3.0277916755318426
Validation loss: 2.6919305905219884

Epoch: 6| Step: 12
Training loss: 2.1642595883078064
Validation loss: 2.6717300745138584

Epoch: 6| Step: 13
Training loss: 3.049418791127923
Validation loss: 2.6484044141581564

Epoch: 154| Step: 0
Training loss: 3.0230174795560907
Validation loss: 2.7119722362419916

Epoch: 6| Step: 1
Training loss: 2.2995055828254816
Validation loss: 2.674899590575958

Epoch: 6| Step: 2
Training loss: 2.895719256086612
Validation loss: 2.6878599596885486

Epoch: 6| Step: 3
Training loss: 3.0298106128689817
Validation loss: 2.6528918489401403

Epoch: 6| Step: 4
Training loss: 2.575343070277524
Validation loss: 2.6941857031005503

Epoch: 6| Step: 5
Training loss: 2.5760447114298395
Validation loss: 2.6305064728168683

Epoch: 6| Step: 6
Training loss: 3.1352537161389327
Validation loss: 2.7027135001479325

Epoch: 6| Step: 7
Training loss: 2.1655308118102163
Validation loss: 2.7001373834876445

Epoch: 6| Step: 8
Training loss: 1.8526352619617645
Validation loss: 2.66144378570157

Epoch: 6| Step: 9
Training loss: 2.0961990836140854
Validation loss: 2.632651843774348

Epoch: 6| Step: 10
Training loss: 2.2362973140276527
Validation loss: 2.698563352894255

Epoch: 6| Step: 11
Training loss: 1.7663416125599096
Validation loss: 2.6909638918878813

Epoch: 6| Step: 12
Training loss: 3.095994231679506
Validation loss: 2.6568807163172643

Epoch: 6| Step: 13
Training loss: 2.2473584669652786
Validation loss: 2.6855909173212265

Epoch: 155| Step: 0
Training loss: 3.0920877325878884
Validation loss: 2.7094890179658986

Epoch: 6| Step: 1
Training loss: 2.960999661802139
Validation loss: 2.6599258208126506

Epoch: 6| Step: 2
Training loss: 2.1326226789241507
Validation loss: 2.7146855478558276

Epoch: 6| Step: 3
Training loss: 2.7603076745354613
Validation loss: 2.653157520035702

Epoch: 6| Step: 4
Training loss: 2.9148568305685965
Validation loss: 2.683388698202632

Epoch: 6| Step: 5
Training loss: 2.1963514808479756
Validation loss: 2.694925242777573

Epoch: 6| Step: 6
Training loss: 1.72433811702737
Validation loss: 2.707253440708242

Epoch: 6| Step: 7
Training loss: 2.767901415844367
Validation loss: 2.678182013937619

Epoch: 6| Step: 8
Training loss: 2.2390812747272
Validation loss: 2.675927080815721

Epoch: 6| Step: 9
Training loss: 1.9248305753982704
Validation loss: 2.7052857573962252

Epoch: 6| Step: 10
Training loss: 2.826868188964951
Validation loss: 2.659458980875732

Epoch: 6| Step: 11
Training loss: 2.2577286543011845
Validation loss: 2.6574735232798776

Epoch: 6| Step: 12
Training loss: 2.735837795808956
Validation loss: 2.644685529376868

Epoch: 6| Step: 13
Training loss: 2.491889864090522
Validation loss: 2.693202157304093

Epoch: 156| Step: 0
Training loss: 2.5322209132698266
Validation loss: 2.659619795251763

Epoch: 6| Step: 1
Training loss: 2.521466976847413
Validation loss: 2.685751796388087

Epoch: 6| Step: 2
Training loss: 2.2806592202435323
Validation loss: 2.6928351108576556

Epoch: 6| Step: 3
Training loss: 2.1344265262756963
Validation loss: 2.701208450574786

Epoch: 6| Step: 4
Training loss: 2.5067813452737946
Validation loss: 2.6749626424253043

Epoch: 6| Step: 5
Training loss: 2.92765326511646
Validation loss: 2.6515677263145285

Epoch: 6| Step: 6
Training loss: 2.4301326626015745
Validation loss: 2.6365417620386076

Epoch: 6| Step: 7
Training loss: 2.413707916983391
Validation loss: 2.7024557620189804

Epoch: 6| Step: 8
Training loss: 2.9140116096532367
Validation loss: 2.6718084186345927

Epoch: 6| Step: 9
Training loss: 2.924046000566293
Validation loss: 2.666091801864

Epoch: 6| Step: 10
Training loss: 2.5723735117608384
Validation loss: 2.6828474775747777

Epoch: 6| Step: 11
Training loss: 1.6677926392683402
Validation loss: 2.717489170610952

Epoch: 6| Step: 12
Training loss: 2.6061236746564775
Validation loss: 2.671378539978799

Epoch: 6| Step: 13
Training loss: 3.450958815314248
Validation loss: 2.6601615793555644

Epoch: 157| Step: 0
Training loss: 2.67636160021401
Validation loss: 2.6878167147266754

Epoch: 6| Step: 1
Training loss: 2.545787743026497
Validation loss: 2.6722021434546566

Epoch: 6| Step: 2
Training loss: 2.9356209446743198
Validation loss: 2.6635524728377846

Epoch: 6| Step: 3
Training loss: 2.8390815058204817
Validation loss: 2.76190348955573

Epoch: 6| Step: 4
Training loss: 2.517144922787898
Validation loss: 2.6934805573773817

Epoch: 6| Step: 5
Training loss: 1.8960621105394504
Validation loss: 2.708426171187488

Epoch: 6| Step: 6
Training loss: 2.8600954909488934
Validation loss: 2.70415621170755

Epoch: 6| Step: 7
Training loss: 1.7375659628223301
Validation loss: 2.721429669031046

Epoch: 6| Step: 8
Training loss: 2.1537339278212024
Validation loss: 2.67123042047441

Epoch: 6| Step: 9
Training loss: 2.524176427403147
Validation loss: 2.742899695622773

Epoch: 6| Step: 10
Training loss: 2.547675258608843
Validation loss: 2.682188225406342

Epoch: 6| Step: 11
Training loss: 1.9039529186566515
Validation loss: 2.7234394919942293

Epoch: 6| Step: 12
Training loss: 2.4896374514349278
Validation loss: 2.6810616221265873

Epoch: 6| Step: 13
Training loss: 4.295394808971744
Validation loss: 2.67862880858232

Epoch: 158| Step: 0
Training loss: 2.7128913280686633
Validation loss: 2.6641712517163403

Epoch: 6| Step: 1
Training loss: 2.150515685225835
Validation loss: 2.701350761084259

Epoch: 6| Step: 2
Training loss: 2.866231733048495
Validation loss: 2.6953257095086935

Epoch: 6| Step: 3
Training loss: 2.502432212254452
Validation loss: 2.688534047629533

Epoch: 6| Step: 4
Training loss: 2.130206293852808
Validation loss: 2.7091822074027303

Epoch: 6| Step: 5
Training loss: 2.961596735134211
Validation loss: 2.6335535850125322

Epoch: 6| Step: 6
Training loss: 2.4069132695787294
Validation loss: 2.699436030893865

Epoch: 6| Step: 7
Training loss: 2.8271434619181175
Validation loss: 2.6654680337209884

Epoch: 6| Step: 8
Training loss: 3.127842487759712
Validation loss: 2.655468546257915

Epoch: 6| Step: 9
Training loss: 2.459560432859535
Validation loss: 2.659775174364028

Epoch: 6| Step: 10
Training loss: 2.331954878126801
Validation loss: 2.7180841743529434

Epoch: 6| Step: 11
Training loss: 2.8596474773052023
Validation loss: 2.700353937296822

Epoch: 6| Step: 12
Training loss: 2.0616997987166017
Validation loss: 2.6220346158383654

Epoch: 6| Step: 13
Training loss: 2.290182731367565
Validation loss: 2.6565736171757113

Epoch: 159| Step: 0
Training loss: 2.0963100894693363
Validation loss: 2.628276094170276

Epoch: 6| Step: 1
Training loss: 2.572982560728405
Validation loss: 2.658115526657275

Epoch: 6| Step: 2
Training loss: 2.7692816746956117
Validation loss: 2.660956435825966

Epoch: 6| Step: 3
Training loss: 2.0632343718790707
Validation loss: 2.634924936161907

Epoch: 6| Step: 4
Training loss: 1.5962109732281873
Validation loss: 2.7326112426916525

Epoch: 6| Step: 5
Training loss: 3.577484606610442
Validation loss: 2.65599826051743

Epoch: 6| Step: 6
Training loss: 2.7607965076069614
Validation loss: 2.686055041311068

Epoch: 6| Step: 7
Training loss: 2.132498134598805
Validation loss: 2.6439543810562673

Epoch: 6| Step: 8
Training loss: 3.185797442341231
Validation loss: 2.6630765939263252

Epoch: 6| Step: 9
Training loss: 3.015268887854689
Validation loss: 2.684602929704026

Epoch: 6| Step: 10
Training loss: 2.570789142230894
Validation loss: 2.622496710708091

Epoch: 6| Step: 11
Training loss: 2.27732218344473
Validation loss: 2.649539692147271

Epoch: 6| Step: 12
Training loss: 2.4816013423741423
Validation loss: 2.6646595087089047

Epoch: 6| Step: 13
Training loss: 1.8718609282357923
Validation loss: 2.626214652199721

Epoch: 160| Step: 0
Training loss: 2.2602342335670387
Validation loss: 2.6750260751745447

Epoch: 6| Step: 1
Training loss: 2.550590379475801
Validation loss: 2.6703486668975236

Epoch: 6| Step: 2
Training loss: 2.779652340234001
Validation loss: 2.6655218813367396

Epoch: 6| Step: 3
Training loss: 1.9618258344864354
Validation loss: 2.671997046416263

Epoch: 6| Step: 4
Training loss: 2.674640495884739
Validation loss: 2.7054430139069257

Epoch: 6| Step: 5
Training loss: 1.9053654103489823
Validation loss: 2.7069859058091357

Epoch: 6| Step: 6
Training loss: 2.682236773969312
Validation loss: 2.706403088625065

Epoch: 6| Step: 7
Training loss: 2.550259920972814
Validation loss: 2.6927600528038136

Epoch: 6| Step: 8
Training loss: 2.551983349975992
Validation loss: 2.615233070257844

Epoch: 6| Step: 9
Training loss: 2.2264320736882044
Validation loss: 2.710342054823598

Epoch: 6| Step: 10
Training loss: 2.60412892632158
Validation loss: 2.7151623568225087

Epoch: 6| Step: 11
Training loss: 2.8205453031621284
Validation loss: 2.7364055635498827

Epoch: 6| Step: 12
Training loss: 3.2005301036446974
Validation loss: 2.7002845676866247

Epoch: 6| Step: 13
Training loss: 2.6273876412247854
Validation loss: 2.6515199669095186

Epoch: 161| Step: 0
Training loss: 2.705001179946952
Validation loss: 2.6997760923693885

Epoch: 6| Step: 1
Training loss: 2.7853690516858545
Validation loss: 2.6750973590318594

Epoch: 6| Step: 2
Training loss: 2.3987447436236846
Validation loss: 2.656439678023794

Epoch: 6| Step: 3
Training loss: 2.6763304209485654
Validation loss: 2.660606844477744

Epoch: 6| Step: 4
Training loss: 2.3912598010199813
Validation loss: 2.67100530369616

Epoch: 6| Step: 5
Training loss: 2.5359751549896647
Validation loss: 2.657247884065703

Epoch: 6| Step: 6
Training loss: 2.8508626000549535
Validation loss: 2.6886599098824617

Epoch: 6| Step: 7
Training loss: 2.743122691259762
Validation loss: 2.6578698707609076

Epoch: 6| Step: 8
Training loss: 2.7136270774437286
Validation loss: 2.649789075995676

Epoch: 6| Step: 9
Training loss: 2.8543390003905267
Validation loss: 2.6734394606668443

Epoch: 6| Step: 10
Training loss: 2.076360082125283
Validation loss: 2.6748310157257573

Epoch: 6| Step: 11
Training loss: 1.9757548253896937
Validation loss: 2.6911478547678294

Epoch: 6| Step: 12
Training loss: 2.5868359068271216
Validation loss: 2.679391524662153

Epoch: 6| Step: 13
Training loss: 1.3065561857438173
Validation loss: 2.653629537726767

Epoch: 162| Step: 0
Training loss: 2.3950951365009754
Validation loss: 2.697640963693834

Epoch: 6| Step: 1
Training loss: 3.050405481619603
Validation loss: 2.6640643861171114

Epoch: 6| Step: 2
Training loss: 1.8591144283016932
Validation loss: 2.663163307114411

Epoch: 6| Step: 3
Training loss: 3.036989107847857
Validation loss: 2.661917601784254

Epoch: 6| Step: 4
Training loss: 2.7095045540534306
Validation loss: 2.6145705251490723

Epoch: 6| Step: 5
Training loss: 2.684336730186858
Validation loss: 2.6811239314505384

Epoch: 6| Step: 6
Training loss: 2.8403588500780668
Validation loss: 2.6683763511477587

Epoch: 6| Step: 7
Training loss: 2.4252665736968404
Validation loss: 2.6631386501979373

Epoch: 6| Step: 8
Training loss: 1.9136557633453088
Validation loss: 2.71546052831904

Epoch: 6| Step: 9
Training loss: 2.4781627599237406
Validation loss: 2.670776189218645

Epoch: 6| Step: 10
Training loss: 3.079522294984665
Validation loss: 2.6943237716884867

Epoch: 6| Step: 11
Training loss: 1.73581484576761
Validation loss: 2.6458492154229396

Epoch: 6| Step: 12
Training loss: 2.0620098109488274
Validation loss: 2.7200383297555777

Epoch: 6| Step: 13
Training loss: 2.7685141262736424
Validation loss: 2.706695249311508

Epoch: 163| Step: 0
Training loss: 3.1234178734258617
Validation loss: 2.661929491948163

Epoch: 6| Step: 1
Training loss: 2.5599404554594716
Validation loss: 2.675933235246693

Epoch: 6| Step: 2
Training loss: 2.0120619397801147
Validation loss: 2.6219441156325587

Epoch: 6| Step: 3
Training loss: 2.380942489512651
Validation loss: 2.68961480151198

Epoch: 6| Step: 4
Training loss: 2.257982399431802
Validation loss: 2.692313832636956

Epoch: 6| Step: 5
Training loss: 2.5183015409928946
Validation loss: 2.7003003627494935

Epoch: 6| Step: 6
Training loss: 2.543735558471176
Validation loss: 2.6755576817355946

Epoch: 6| Step: 7
Training loss: 2.8827374042768104
Validation loss: 2.678897196408772

Epoch: 6| Step: 8
Training loss: 3.2029752370667333
Validation loss: 2.6363046720982135

Epoch: 6| Step: 9
Training loss: 2.4952704515061424
Validation loss: 2.688428793172054

Epoch: 6| Step: 10
Training loss: 2.4870133695530656
Validation loss: 2.701030195731252

Epoch: 6| Step: 11
Training loss: 1.9672169847528507
Validation loss: 2.6715245957718867

Epoch: 6| Step: 12
Training loss: 2.664711791981672
Validation loss: 2.641396503201391

Epoch: 6| Step: 13
Training loss: 1.6516282717222632
Validation loss: 2.607129765926745

Epoch: 164| Step: 0
Training loss: 2.6460526342945316
Validation loss: 2.6892766781811432

Epoch: 6| Step: 1
Training loss: 2.377685434067439
Validation loss: 2.667352383136524

Epoch: 6| Step: 2
Training loss: 2.440971641003856
Validation loss: 2.6854397774649565

Epoch: 6| Step: 3
Training loss: 2.4334562945543325
Validation loss: 2.7375917682370776

Epoch: 6| Step: 4
Training loss: 2.3871596408321483
Validation loss: 2.727353869548959

Epoch: 6| Step: 5
Training loss: 2.2466146644588436
Validation loss: 2.6675720049571328

Epoch: 6| Step: 6
Training loss: 2.655009080831799
Validation loss: 2.7170030664794145

Epoch: 6| Step: 7
Training loss: 2.1925106971331876
Validation loss: 2.6849484914974817

Epoch: 6| Step: 8
Training loss: 3.142246112627752
Validation loss: 2.690880711684671

Epoch: 6| Step: 9
Training loss: 2.2624234434210826
Validation loss: 2.6756790950021503

Epoch: 6| Step: 10
Training loss: 1.8744259273355859
Validation loss: 2.6831119081671346

Epoch: 6| Step: 11
Training loss: 3.426908788130067
Validation loss: 2.652576764020948

Epoch: 6| Step: 12
Training loss: 2.2409296528278926
Validation loss: 2.676951428159506

Epoch: 6| Step: 13
Training loss: 3.173060153481157
Validation loss: 2.7154825802966673

Epoch: 165| Step: 0
Training loss: 2.1740057942050903
Validation loss: 2.6783357409314994

Epoch: 6| Step: 1
Training loss: 2.613513702409204
Validation loss: 2.7307583734823573

Epoch: 6| Step: 2
Training loss: 2.2210812209048
Validation loss: 2.662074492586692

Epoch: 6| Step: 3
Training loss: 2.7822380453979427
Validation loss: 2.6990356839123315

Epoch: 6| Step: 4
Training loss: 2.5730159189537583
Validation loss: 2.6662880227491184

Epoch: 6| Step: 5
Training loss: 2.406240488008797
Validation loss: 2.6664353765145767

Epoch: 6| Step: 6
Training loss: 2.193992136229173
Validation loss: 2.657064061464393

Epoch: 6| Step: 7
Training loss: 3.050248064052873
Validation loss: 2.6426769579140474

Epoch: 6| Step: 8
Training loss: 2.4728297071799483
Validation loss: 2.6795415423280726

Epoch: 6| Step: 9
Training loss: 1.7910670082766884
Validation loss: 2.7131491681046374

Epoch: 6| Step: 10
Training loss: 2.381841743215044
Validation loss: 2.7081148780454165

Epoch: 6| Step: 11
Training loss: 2.7797925752332713
Validation loss: 2.6880949315321994

Epoch: 6| Step: 12
Training loss: 2.682889132330017
Validation loss: 2.6693105057300066

Epoch: 6| Step: 13
Training loss: 2.572367023853267
Validation loss: 2.713381680697336

Epoch: 166| Step: 0
Training loss: 2.178628206071547
Validation loss: 2.7077230411127666

Epoch: 6| Step: 1
Training loss: 2.975117490355784
Validation loss: 2.632438670373235

Epoch: 6| Step: 2
Training loss: 2.1732458824084477
Validation loss: 2.6573258790179892

Epoch: 6| Step: 3
Training loss: 2.9058632542045455
Validation loss: 2.644656244013752

Epoch: 6| Step: 4
Training loss: 2.9092765553799786
Validation loss: 2.6142717139877756

Epoch: 6| Step: 5
Training loss: 2.595145803629528
Validation loss: 2.649980190665096

Epoch: 6| Step: 6
Training loss: 2.3031390662003144
Validation loss: 2.6638326069665084

Epoch: 6| Step: 7
Training loss: 2.3706356907026955
Validation loss: 2.6429599380963418

Epoch: 6| Step: 8
Training loss: 2.7563289293678497
Validation loss: 2.683820357010165

Epoch: 6| Step: 9
Training loss: 2.631675678533288
Validation loss: 2.6743867787115128

Epoch: 6| Step: 10
Training loss: 2.359412995089347
Validation loss: 2.666197975626921

Epoch: 6| Step: 11
Training loss: 2.171762147894278
Validation loss: 2.635493655338546

Epoch: 6| Step: 12
Training loss: 2.298259499488634
Validation loss: 2.704663817119784

Epoch: 6| Step: 13
Training loss: 2.559510045104334
Validation loss: 2.6724260902826784

Epoch: 167| Step: 0
Training loss: 2.0983830902930785
Validation loss: 2.6441001948541683

Epoch: 6| Step: 1
Training loss: 1.7450584397463262
Validation loss: 2.6799426983780728

Epoch: 6| Step: 2
Training loss: 2.77801050694719
Validation loss: 2.694058565992089

Epoch: 6| Step: 3
Training loss: 2.4803072659049286
Validation loss: 2.708688783314341

Epoch: 6| Step: 4
Training loss: 3.2069860494683127
Validation loss: 2.6659700091903673

Epoch: 6| Step: 5
Training loss: 2.342058614145578
Validation loss: 2.6562515828214175

Epoch: 6| Step: 6
Training loss: 2.8622725350569618
Validation loss: 2.6967461091556664

Epoch: 6| Step: 7
Training loss: 2.195124390711889
Validation loss: 2.665866705540986

Epoch: 6| Step: 8
Training loss: 3.354200627567705
Validation loss: 2.6512365669450557

Epoch: 6| Step: 9
Training loss: 2.894804042054407
Validation loss: 2.6846298302911045

Epoch: 6| Step: 10
Training loss: 2.074125413536776
Validation loss: 2.6143834909911017

Epoch: 6| Step: 11
Training loss: 2.5363330431522852
Validation loss: 2.647354125577012

Epoch: 6| Step: 12
Training loss: 2.2685771781735964
Validation loss: 2.6196664387886326

Epoch: 6| Step: 13
Training loss: 0.5843605182505656
Validation loss: 2.6418729957794156

Epoch: 168| Step: 0
Training loss: 3.4685009016344037
Validation loss: 2.6935082844432308

Epoch: 6| Step: 1
Training loss: 2.3983234788463776
Validation loss: 2.633172471029513

Epoch: 6| Step: 2
Training loss: 2.511837210464683
Validation loss: 2.716084159747321

Epoch: 6| Step: 3
Training loss: 1.9634645145008298
Validation loss: 2.6825694084433276

Epoch: 6| Step: 4
Training loss: 2.693848762560381
Validation loss: 2.687403147488771

Epoch: 6| Step: 5
Training loss: 1.9334140886782532
Validation loss: 2.625695917140605

Epoch: 6| Step: 6
Training loss: 1.7774073327397553
Validation loss: 2.657543385279573

Epoch: 6| Step: 7
Training loss: 2.7834607885116043
Validation loss: 2.69057357144576

Epoch: 6| Step: 8
Training loss: 2.4198523165825274
Validation loss: 2.6741561952649104

Epoch: 6| Step: 9
Training loss: 2.882426414377609
Validation loss: 2.691955947481159

Epoch: 6| Step: 10
Training loss: 2.166613235792947
Validation loss: 2.675236939823872

Epoch: 6| Step: 11
Training loss: 2.166407227266616
Validation loss: 2.6880379281787548

Epoch: 6| Step: 12
Training loss: 2.7620918421188163
Validation loss: 2.692226411930588

Epoch: 6| Step: 13
Training loss: 2.36721257866898
Validation loss: 2.6926168907555708

Epoch: 169| Step: 0
Training loss: 2.422948193420166
Validation loss: 2.6632720426057976

Epoch: 6| Step: 1
Training loss: 3.0490258083733814
Validation loss: 2.680199530091386

Epoch: 6| Step: 2
Training loss: 2.445063861722804
Validation loss: 2.7021271893995564

Epoch: 6| Step: 3
Training loss: 3.190915689854293
Validation loss: 2.6322497678154853

Epoch: 6| Step: 4
Training loss: 1.90420760507907
Validation loss: 2.6567231723784666

Epoch: 6| Step: 5
Training loss: 1.8340315645136995
Validation loss: 2.6649273919198126

Epoch: 6| Step: 6
Training loss: 2.6334595380390353
Validation loss: 2.6676895672240764

Epoch: 6| Step: 7
Training loss: 2.047399439129646
Validation loss: 2.64403781682246

Epoch: 6| Step: 8
Training loss: 2.531097219118498
Validation loss: 2.6348428931283956

Epoch: 6| Step: 9
Training loss: 2.239422518848559
Validation loss: 2.6676520895344527

Epoch: 6| Step: 10
Training loss: 2.6372202756535366
Validation loss: 2.705243660944841

Epoch: 6| Step: 11
Training loss: 2.6005610007488236
Validation loss: 2.61987908382486

Epoch: 6| Step: 12
Training loss: 2.7271273227424206
Validation loss: 2.6649726090399875

Epoch: 6| Step: 13
Training loss: 2.354477808373243
Validation loss: 2.6475168100916218

Epoch: 170| Step: 0
Training loss: 2.6321571507946655
Validation loss: 2.6960060467384905

Epoch: 6| Step: 1
Training loss: 2.1531678437730424
Validation loss: 2.6793235393636112

Epoch: 6| Step: 2
Training loss: 2.8608731373537393
Validation loss: 2.6692637639386043

Epoch: 6| Step: 3
Training loss: 1.7696739290832928
Validation loss: 2.691026989373669

Epoch: 6| Step: 4
Training loss: 2.0462030370655997
Validation loss: 2.7104679192833356

Epoch: 6| Step: 5
Training loss: 2.5576328482481587
Validation loss: 2.6829872284819163

Epoch: 6| Step: 6
Training loss: 2.764366941360502
Validation loss: 2.698766691265731

Epoch: 6| Step: 7
Training loss: 2.773179163116918
Validation loss: 2.6835152450556445

Epoch: 6| Step: 8
Training loss: 2.289059375331165
Validation loss: 2.697389078256641

Epoch: 6| Step: 9
Training loss: 2.2336117167649197
Validation loss: 2.6865126066323213

Epoch: 6| Step: 10
Training loss: 2.2431819186000235
Validation loss: 2.6696621531711573

Epoch: 6| Step: 11
Training loss: 2.69618348132879
Validation loss: 2.719481725577318

Epoch: 6| Step: 12
Training loss: 2.8401449639301326
Validation loss: 2.6558511346469946

Epoch: 6| Step: 13
Training loss: 2.842363962962734
Validation loss: 2.65465808339249

Epoch: 171| Step: 0
Training loss: 2.064396073374999
Validation loss: 2.6706043506606925

Epoch: 6| Step: 1
Training loss: 2.2264296107204737
Validation loss: 2.6808212456839695

Epoch: 6| Step: 2
Training loss: 2.2856242426098308
Validation loss: 2.617857515308184

Epoch: 6| Step: 3
Training loss: 2.7356315123611474
Validation loss: 2.7252868268828054

Epoch: 6| Step: 4
Training loss: 2.988732796256131
Validation loss: 2.6946126630013287

Epoch: 6| Step: 5
Training loss: 2.752476963844188
Validation loss: 2.7011517733133203

Epoch: 6| Step: 6
Training loss: 2.710053665361744
Validation loss: 2.6502187091268143

Epoch: 6| Step: 7
Training loss: 2.6806372913906844
Validation loss: 2.6779351104931015

Epoch: 6| Step: 8
Training loss: 2.2540892422601093
Validation loss: 2.6460138962919246

Epoch: 6| Step: 9
Training loss: 2.65661241639514
Validation loss: 2.618275162227209

Epoch: 6| Step: 10
Training loss: 2.2118547781100464
Validation loss: 2.631558859078677

Epoch: 6| Step: 11
Training loss: 2.3187750144082213
Validation loss: 2.6850429376969163

Epoch: 6| Step: 12
Training loss: 2.530498534377962
Validation loss: 2.690520182332446

Epoch: 6| Step: 13
Training loss: 2.8955751665332303
Validation loss: 2.6857000677989338

Epoch: 172| Step: 0
Training loss: 2.1407065271598547
Validation loss: 2.657454219744027

Epoch: 6| Step: 1
Training loss: 2.147079093815903
Validation loss: 2.6798549391587274

Epoch: 6| Step: 2
Training loss: 2.1687803106910715
Validation loss: 2.666474117805618

Epoch: 6| Step: 3
Training loss: 2.688979695190624
Validation loss: 2.657716668296606

Epoch: 6| Step: 4
Training loss: 2.0242141941480116
Validation loss: 2.6414831254629005

Epoch: 6| Step: 5
Training loss: 2.7478063677404068
Validation loss: 2.6668051105626978

Epoch: 6| Step: 6
Training loss: 2.5407190171754648
Validation loss: 2.6615363102124436

Epoch: 6| Step: 7
Training loss: 3.008074384905891
Validation loss: 2.6561071493787525

Epoch: 6| Step: 8
Training loss: 2.4025450087190663
Validation loss: 2.638082314155379

Epoch: 6| Step: 9
Training loss: 2.797280053158922
Validation loss: 2.7086339785269855

Epoch: 6| Step: 10
Training loss: 2.04244364012861
Validation loss: 2.648679441933966

Epoch: 6| Step: 11
Training loss: 2.3745490198109938
Validation loss: 2.6968296037175836

Epoch: 6| Step: 12
Training loss: 2.5446702272095263
Validation loss: 2.70515239728079

Epoch: 6| Step: 13
Training loss: 3.003137378488488
Validation loss: 2.6648834554280842

Epoch: 173| Step: 0
Training loss: 2.262448524184575
Validation loss: 2.6443710963300955

Epoch: 6| Step: 1
Training loss: 2.0607087419760686
Validation loss: 2.646541190387984

Epoch: 6| Step: 2
Training loss: 2.3255682097105552
Validation loss: 2.6977954168452536

Epoch: 6| Step: 3
Training loss: 2.890437434529114
Validation loss: 2.6678077739154076

Epoch: 6| Step: 4
Training loss: 2.7989283009375323
Validation loss: 2.70586094487048

Epoch: 6| Step: 5
Training loss: 1.909507969098719
Validation loss: 2.6910339247481008

Epoch: 6| Step: 6
Training loss: 3.0411871614874824
Validation loss: 2.6091968460086052

Epoch: 6| Step: 7
Training loss: 2.702892756545744
Validation loss: 2.6169193880452144

Epoch: 6| Step: 8
Training loss: 2.377343778080584
Validation loss: 2.7045577448496694

Epoch: 6| Step: 9
Training loss: 2.0431805531863065
Validation loss: 2.6537405090114397

Epoch: 6| Step: 10
Training loss: 2.427698922301225
Validation loss: 2.6608997682990294

Epoch: 6| Step: 11
Training loss: 2.623255195213357
Validation loss: 2.652995135032178

Epoch: 6| Step: 12
Training loss: 2.601168582637483
Validation loss: 2.6453623553937406

Epoch: 6| Step: 13
Training loss: 2.0594426238052495
Validation loss: 2.6253272446876696

Epoch: 174| Step: 0
Training loss: 2.7453087760539625
Validation loss: 2.5655673027707895

Epoch: 6| Step: 1
Training loss: 2.6364547032140737
Validation loss: 2.710181509802825

Epoch: 6| Step: 2
Training loss: 2.3259506825067495
Validation loss: 2.664865924207836

Epoch: 6| Step: 3
Training loss: 2.388062743329132
Validation loss: 2.665597700113314

Epoch: 6| Step: 4
Training loss: 2.186947235022087
Validation loss: 2.6614549353183143

Epoch: 6| Step: 5
Training loss: 3.9203288765569413
Validation loss: 2.625319035211855

Epoch: 6| Step: 6
Training loss: 2.7704454212606024
Validation loss: 2.7510817424073046

Epoch: 6| Step: 7
Training loss: 1.7205048359163007
Validation loss: 2.64781509942627

Epoch: 6| Step: 8
Training loss: 2.1077477854528275
Validation loss: 2.702600370718613

Epoch: 6| Step: 9
Training loss: 2.270399547990051
Validation loss: 2.6826068320666296

Epoch: 6| Step: 10
Training loss: 2.4593718861968554
Validation loss: 2.610820369712692

Epoch: 6| Step: 11
Training loss: 2.3810848789586783
Validation loss: 2.6366513426021285

Epoch: 6| Step: 12
Training loss: 1.7659595138859918
Validation loss: 2.662686792523135

Epoch: 6| Step: 13
Training loss: 2.4597448940896784
Validation loss: 2.74099764809579

Epoch: 175| Step: 0
Training loss: 3.3079246736227694
Validation loss: 2.682826467439898

Epoch: 6| Step: 1
Training loss: 2.552850371850479
Validation loss: 2.65273025076546

Epoch: 6| Step: 2
Training loss: 2.0155817071567945
Validation loss: 2.664844009900086

Epoch: 6| Step: 3
Training loss: 2.362674856022462
Validation loss: 2.7055669743019966

Epoch: 6| Step: 4
Training loss: 2.0866744779048556
Validation loss: 2.6995359094086107

Epoch: 6| Step: 5
Training loss: 2.7088250716385867
Validation loss: 2.653249872616335

Epoch: 6| Step: 6
Training loss: 1.9817664956351557
Validation loss: 2.704009094139799

Epoch: 6| Step: 7
Training loss: 2.120191969007315
Validation loss: 2.6827062314917525

Epoch: 6| Step: 8
Training loss: 2.965528486990695
Validation loss: 2.6281524193232424

Epoch: 6| Step: 9
Training loss: 2.0085878767523404
Validation loss: 2.6423081418793415

Epoch: 6| Step: 10
Training loss: 2.7960756321011218
Validation loss: 2.6335070749644465

Epoch: 6| Step: 11
Training loss: 2.5993149588516697
Validation loss: 2.6714594657666586

Epoch: 6| Step: 12
Training loss: 2.9088015276939485
Validation loss: 2.6968275551463052

Epoch: 6| Step: 13
Training loss: 1.9708651730288855
Validation loss: 2.657576403647985

Testing loss: 2.4850471392415456
