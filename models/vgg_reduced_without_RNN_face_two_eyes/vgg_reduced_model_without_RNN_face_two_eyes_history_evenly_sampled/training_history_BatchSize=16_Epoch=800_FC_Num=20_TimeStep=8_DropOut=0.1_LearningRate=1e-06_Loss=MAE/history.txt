Epoch: 1| Step: 0
Training loss: 6.006904125213623
Validation loss: 6.546284029560704

Epoch: 6| Step: 1
Training loss: 5.518716812133789
Validation loss: 6.54117807777979

Epoch: 6| Step: 2
Training loss: 5.665010929107666
Validation loss: 6.533583794870684

Epoch: 6| Step: 3
Training loss: 5.375555038452148
Validation loss: 6.527702413579469

Epoch: 6| Step: 4
Training loss: 6.412640571594238
Validation loss: 6.522198097680205

Epoch: 6| Step: 5
Training loss: 6.805612564086914
Validation loss: 6.5177523807812765

Epoch: 6| Step: 6
Training loss: 5.907397270202637
Validation loss: 6.509812406314317

Epoch: 6| Step: 7
Training loss: 7.882745742797852
Validation loss: 6.501935707625522

Epoch: 6| Step: 8
Training loss: 6.773005485534668
Validation loss: 6.499157013431672

Epoch: 6| Step: 9
Training loss: 6.886272430419922
Validation loss: 6.49202698533253

Epoch: 6| Step: 10
Training loss: 6.370732307434082
Validation loss: 6.487187308649863

Epoch: 6| Step: 11
Training loss: 6.046413421630859
Validation loss: 6.479184237859583

Epoch: 6| Step: 12
Training loss: 6.384496688842773
Validation loss: 6.47608930833878

Epoch: 6| Step: 13
Training loss: 6.1684699058532715
Validation loss: 6.4685426886363695

Epoch: 2| Step: 0
Training loss: 6.22991418838501
Validation loss: 6.461257914061187

Epoch: 6| Step: 1
Training loss: 6.126372337341309
Validation loss: 6.4571479059034775

Epoch: 6| Step: 2
Training loss: 5.193264961242676
Validation loss: 6.450543244679769

Epoch: 6| Step: 3
Training loss: 6.739201545715332
Validation loss: 6.445027443670457

Epoch: 6| Step: 4
Training loss: 6.636722564697266
Validation loss: 6.438516514275664

Epoch: 6| Step: 5
Training loss: 6.520687103271484
Validation loss: 6.4334597895222325

Epoch: 6| Step: 6
Training loss: 6.596729278564453
Validation loss: 6.42449277447116

Epoch: 6| Step: 7
Training loss: 6.390883922576904
Validation loss: 6.419627333200106

Epoch: 6| Step: 8
Training loss: 6.006773948669434
Validation loss: 6.41318230987877

Epoch: 6| Step: 9
Training loss: 6.267087936401367
Validation loss: 6.406857910976615

Epoch: 6| Step: 10
Training loss: 5.933250427246094
Validation loss: 6.4019328548062235

Epoch: 6| Step: 11
Training loss: 6.478369235992432
Validation loss: 6.394985511738767

Epoch: 6| Step: 12
Training loss: 5.688823699951172
Validation loss: 6.387143934926679

Epoch: 6| Step: 13
Training loss: 6.328680515289307
Validation loss: 6.382632681118545

Epoch: 3| Step: 0
Training loss: 7.138603687286377
Validation loss: 6.376840242775538

Epoch: 6| Step: 1
Training loss: 6.107240676879883
Validation loss: 6.371383364482592

Epoch: 6| Step: 2
Training loss: 4.827424049377441
Validation loss: 6.36494243273171

Epoch: 6| Step: 3
Training loss: 6.70192813873291
Validation loss: 6.356506424565469

Epoch: 6| Step: 4
Training loss: 5.768370628356934
Validation loss: 6.348494278487339

Epoch: 6| Step: 5
Training loss: 7.141282081604004
Validation loss: 6.345932109381563

Epoch: 6| Step: 6
Training loss: 6.17338228225708
Validation loss: 6.341399105646277

Epoch: 6| Step: 7
Training loss: 6.4219207763671875
Validation loss: 6.3302349018794235

Epoch: 6| Step: 8
Training loss: 5.328371047973633
Validation loss: 6.3270609660815165

Epoch: 6| Step: 9
Training loss: 6.528933525085449
Validation loss: 6.320858365745955

Epoch: 6| Step: 10
Training loss: 6.460208415985107
Validation loss: 6.312169956904586

Epoch: 6| Step: 11
Training loss: 4.519211769104004
Validation loss: 6.305121744832685

Epoch: 6| Step: 12
Training loss: 6.558077812194824
Validation loss: 6.296959225849439

Epoch: 6| Step: 13
Training loss: 6.151431560516357
Validation loss: 6.293080663168302

Epoch: 4| Step: 0
Training loss: 5.64479923248291
Validation loss: 6.283552210818055

Epoch: 6| Step: 1
Training loss: 6.585566997528076
Validation loss: 6.278204420561432

Epoch: 6| Step: 2
Training loss: 6.583422660827637
Validation loss: 6.271542969570365

Epoch: 6| Step: 3
Training loss: 5.950654983520508
Validation loss: 6.264352203697286

Epoch: 6| Step: 4
Training loss: 5.895346164703369
Validation loss: 6.255897588627313

Epoch: 6| Step: 5
Training loss: 5.1667351722717285
Validation loss: 6.247733018731558

Epoch: 6| Step: 6
Training loss: 5.372330665588379
Validation loss: 6.240859277786747

Epoch: 6| Step: 7
Training loss: 7.056456565856934
Validation loss: 6.234805609590264

Epoch: 6| Step: 8
Training loss: 6.508037567138672
Validation loss: 6.227707837217597

Epoch: 6| Step: 9
Training loss: 6.866438865661621
Validation loss: 6.22148323059082

Epoch: 6| Step: 10
Training loss: 5.348221778869629
Validation loss: 6.211361644088581

Epoch: 6| Step: 11
Training loss: 5.691192626953125
Validation loss: 6.205007358263898

Epoch: 6| Step: 12
Training loss: 6.050030708312988
Validation loss: 6.1938186153288814

Epoch: 6| Step: 13
Training loss: 5.441920280456543
Validation loss: 6.189750025349278

Epoch: 5| Step: 0
Training loss: 5.610006332397461
Validation loss: 6.182004067205614

Epoch: 6| Step: 1
Training loss: 6.134186744689941
Validation loss: 6.172785584644605

Epoch: 6| Step: 2
Training loss: 6.529477596282959
Validation loss: 6.165415425454417

Epoch: 6| Step: 3
Training loss: 4.804795265197754
Validation loss: 6.156647641171691

Epoch: 6| Step: 4
Training loss: 7.054661750793457
Validation loss: 6.149383616703813

Epoch: 6| Step: 5
Training loss: 5.68550968170166
Validation loss: 6.142191456210229

Epoch: 6| Step: 6
Training loss: 5.594480037689209
Validation loss: 6.1342137603349585

Epoch: 6| Step: 7
Training loss: 3.9314498901367188
Validation loss: 6.122028391848328

Epoch: 6| Step: 8
Training loss: 5.135396957397461
Validation loss: 6.11747230509276

Epoch: 6| Step: 9
Training loss: 5.826887130737305
Validation loss: 6.107272225041544

Epoch: 6| Step: 10
Training loss: 6.0280914306640625
Validation loss: 6.103253959327616

Epoch: 6| Step: 11
Training loss: 7.201706886291504
Validation loss: 6.089458173321139

Epoch: 6| Step: 12
Training loss: 6.560120582580566
Validation loss: 6.085462344590054

Epoch: 6| Step: 13
Training loss: 7.430318355560303
Validation loss: 6.0755940201461955

Epoch: 6| Step: 0
Training loss: 5.1520867347717285
Validation loss: 6.068237361087594

Epoch: 6| Step: 1
Training loss: 5.887158393859863
Validation loss: 6.058979393333517

Epoch: 6| Step: 2
Training loss: 4.98845100402832
Validation loss: 6.0498451468765095

Epoch: 6| Step: 3
Training loss: 6.017239093780518
Validation loss: 6.040399397573164

Epoch: 6| Step: 4
Training loss: 5.923349380493164
Validation loss: 6.032551273222892

Epoch: 6| Step: 5
Training loss: 6.084356307983398
Validation loss: 6.022056220680155

Epoch: 6| Step: 6
Training loss: 6.123534202575684
Validation loss: 6.013107566423313

Epoch: 6| Step: 7
Training loss: 6.984930515289307
Validation loss: 6.002911162632768

Epoch: 6| Step: 8
Training loss: 5.658559799194336
Validation loss: 5.995495021984142

Epoch: 6| Step: 9
Training loss: 6.774596214294434
Validation loss: 5.989168608060447

Epoch: 6| Step: 10
Training loss: 5.944072723388672
Validation loss: 5.977305730183919

Epoch: 6| Step: 11
Training loss: 3.8796486854553223
Validation loss: 5.968528311739686

Epoch: 6| Step: 12
Training loss: 5.452492713928223
Validation loss: 5.959042918297552

Epoch: 6| Step: 13
Training loss: 6.61650276184082
Validation loss: 5.947762643137286

Epoch: 7| Step: 0
Training loss: 6.148552894592285
Validation loss: 5.9402047434160785

Epoch: 6| Step: 1
Training loss: 5.646304130554199
Validation loss: 5.929481839620939

Epoch: 6| Step: 2
Training loss: 5.477628707885742
Validation loss: 5.91886059955884

Epoch: 6| Step: 3
Training loss: 5.8148193359375
Validation loss: 5.907747663477416

Epoch: 6| Step: 4
Training loss: 4.104865550994873
Validation loss: 5.897890152469758

Epoch: 6| Step: 5
Training loss: 6.289419651031494
Validation loss: 5.888623493973927

Epoch: 6| Step: 6
Training loss: 6.141796112060547
Validation loss: 5.876551043602728

Epoch: 6| Step: 7
Training loss: 6.0353007316589355
Validation loss: 5.867857666425808

Epoch: 6| Step: 8
Training loss: 6.506541728973389
Validation loss: 5.855047733552994

Epoch: 6| Step: 9
Training loss: 4.809979438781738
Validation loss: 5.845980603207824

Epoch: 6| Step: 10
Training loss: 5.848255157470703
Validation loss: 5.836740150246569

Epoch: 6| Step: 11
Training loss: 5.952541828155518
Validation loss: 5.820947493276289

Epoch: 6| Step: 12
Training loss: 4.466409683227539
Validation loss: 5.808762606754098

Epoch: 6| Step: 13
Training loss: 6.148395538330078
Validation loss: 5.798223044282647

Epoch: 8| Step: 0
Training loss: 6.531793594360352
Validation loss: 5.787245909372966

Epoch: 6| Step: 1
Training loss: 4.511510848999023
Validation loss: 5.777806922953616

Epoch: 6| Step: 2
Training loss: 6.403968334197998
Validation loss: 5.764394539658741

Epoch: 6| Step: 3
Training loss: 5.130619049072266
Validation loss: 5.7545115152994795

Epoch: 6| Step: 4
Training loss: 5.7072553634643555
Validation loss: 5.740864610159269

Epoch: 6| Step: 5
Training loss: 5.380975723266602
Validation loss: 5.7274617841166835

Epoch: 6| Step: 6
Training loss: 5.5640459060668945
Validation loss: 5.716220840331046

Epoch: 6| Step: 7
Training loss: 5.6594462394714355
Validation loss: 5.701813590142034

Epoch: 6| Step: 8
Training loss: 5.137321472167969
Validation loss: 5.693276620680286

Epoch: 6| Step: 9
Training loss: 5.772738456726074
Validation loss: 5.67744481179022

Epoch: 6| Step: 10
Training loss: 4.889078140258789
Validation loss: 5.662806423761511

Epoch: 6| Step: 11
Training loss: 5.104205131530762
Validation loss: 5.650174274239489

Epoch: 6| Step: 12
Training loss: 5.049868583679199
Validation loss: 5.637825468535064

Epoch: 6| Step: 13
Training loss: 6.342455863952637
Validation loss: 5.623263420597199

Epoch: 9| Step: 0
Training loss: 4.910369873046875
Validation loss: 5.61239117960776

Epoch: 6| Step: 1
Training loss: 6.109684944152832
Validation loss: 5.597779689296599

Epoch: 6| Step: 2
Training loss: 6.3979692459106445
Validation loss: 5.578853904560048

Epoch: 6| Step: 3
Training loss: 4.0728840827941895
Validation loss: 5.5679405632839405

Epoch: 6| Step: 4
Training loss: 5.930333137512207
Validation loss: 5.552371527559014

Epoch: 6| Step: 5
Training loss: 5.390086650848389
Validation loss: 5.535375800184024

Epoch: 6| Step: 6
Training loss: 3.925732135772705
Validation loss: 5.521636993654313

Epoch: 6| Step: 7
Training loss: 4.242405414581299
Validation loss: 5.502091571848879

Epoch: 6| Step: 8
Training loss: 6.650142192840576
Validation loss: 5.487066284302743

Epoch: 6| Step: 9
Training loss: 5.538355350494385
Validation loss: 5.473238493806573

Epoch: 6| Step: 10
Training loss: 4.6951189041137695
Validation loss: 5.456415730137979

Epoch: 6| Step: 11
Training loss: 5.310154438018799
Validation loss: 5.446722820240964

Epoch: 6| Step: 12
Training loss: 5.27509880065918
Validation loss: 5.42580202574371

Epoch: 6| Step: 13
Training loss: 5.711664199829102
Validation loss: 5.409879771612024

Epoch: 10| Step: 0
Training loss: 3.8780174255371094
Validation loss: 5.394615691195252

Epoch: 6| Step: 1
Training loss: 4.937259674072266
Validation loss: 5.369872616183374

Epoch: 6| Step: 2
Training loss: 4.758965492248535
Validation loss: 5.3587776768592095

Epoch: 6| Step: 3
Training loss: 4.303600311279297
Validation loss: 5.338064121943648

Epoch: 6| Step: 4
Training loss: 3.5147273540496826
Validation loss: 5.321278167027299

Epoch: 6| Step: 5
Training loss: 6.096925735473633
Validation loss: 5.303962317846155

Epoch: 6| Step: 6
Training loss: 4.576292514801025
Validation loss: 5.283933429307835

Epoch: 6| Step: 7
Training loss: 5.818865776062012
Validation loss: 5.262633651815435

Epoch: 6| Step: 8
Training loss: 5.074697017669678
Validation loss: 5.24631566386069

Epoch: 6| Step: 9
Training loss: 4.722975254058838
Validation loss: 5.229367497146771

Epoch: 6| Step: 10
Training loss: 6.620179176330566
Validation loss: 5.209272594862087

Epoch: 6| Step: 11
Training loss: 6.654234409332275
Validation loss: 5.18577790516679

Epoch: 6| Step: 12
Training loss: 4.9958906173706055
Validation loss: 5.165391168286724

Epoch: 6| Step: 13
Training loss: 4.287679195404053
Validation loss: 5.144728686219903

Epoch: 11| Step: 0
Training loss: 4.6341071128845215
Validation loss: 5.130173980548817

Epoch: 6| Step: 1
Training loss: 4.022002696990967
Validation loss: 5.108667640275852

Epoch: 6| Step: 2
Training loss: 4.295352458953857
Validation loss: 5.092770622622583

Epoch: 6| Step: 3
Training loss: 4.759219169616699
Validation loss: 5.063451782349618

Epoch: 6| Step: 4
Training loss: 5.767031192779541
Validation loss: 5.0479775603099535

Epoch: 6| Step: 5
Training loss: 5.471808433532715
Validation loss: 5.0231180498676915

Epoch: 6| Step: 6
Training loss: 5.921321868896484
Validation loss: 4.998532710536834

Epoch: 6| Step: 7
Training loss: 5.238611698150635
Validation loss: 4.970338857302102

Epoch: 6| Step: 8
Training loss: 4.3371195793151855
Validation loss: 4.952663478030954

Epoch: 6| Step: 9
Training loss: 3.761892080307007
Validation loss: 4.933142979939778

Epoch: 6| Step: 10
Training loss: 4.840304374694824
Validation loss: 4.910215136825397

Epoch: 6| Step: 11
Training loss: 4.084061145782471
Validation loss: 4.882986345598774

Epoch: 6| Step: 12
Training loss: 4.667115211486816
Validation loss: 4.85805272030574

Epoch: 6| Step: 13
Training loss: 4.740384578704834
Validation loss: 4.836215742172733

Epoch: 12| Step: 0
Training loss: 5.278132915496826
Validation loss: 4.8173737884849634

Epoch: 6| Step: 1
Training loss: 4.5480732917785645
Validation loss: 4.789518099959179

Epoch: 6| Step: 2
Training loss: 4.060457229614258
Validation loss: 4.769754122662288

Epoch: 6| Step: 3
Training loss: 4.42041540145874
Validation loss: 4.736961882601502

Epoch: 6| Step: 4
Training loss: 5.060077667236328
Validation loss: 4.723709016717891

Epoch: 6| Step: 5
Training loss: 3.9347891807556152
Validation loss: 4.692543716840847

Epoch: 6| Step: 6
Training loss: 4.603419780731201
Validation loss: 4.665971540635632

Epoch: 6| Step: 7
Training loss: 4.572700500488281
Validation loss: 4.643718076008622

Epoch: 6| Step: 8
Training loss: 4.345436096191406
Validation loss: 4.613421788779638

Epoch: 6| Step: 9
Training loss: 4.221686363220215
Validation loss: 4.5920683286523305

Epoch: 6| Step: 10
Training loss: 4.938126087188721
Validation loss: 4.573048283976894

Epoch: 6| Step: 11
Training loss: 2.936175584793091
Validation loss: 4.536642484767462

Epoch: 6| Step: 12
Training loss: 3.5268373489379883
Validation loss: 4.515940748235231

Epoch: 6| Step: 13
Training loss: 6.227725028991699
Validation loss: 4.484081745147705

Epoch: 13| Step: 0
Training loss: 5.263991355895996
Validation loss: 4.462018812856367

Epoch: 6| Step: 1
Training loss: 3.9794955253601074
Validation loss: 4.433023534795289

Epoch: 6| Step: 2
Training loss: 4.515880107879639
Validation loss: 4.412114230535364

Epoch: 6| Step: 3
Training loss: 3.3888885974884033
Validation loss: 4.381159931100825

Epoch: 6| Step: 4
Training loss: 4.447963237762451
Validation loss: 4.354011627935594

Epoch: 6| Step: 5
Training loss: 3.161182403564453
Validation loss: 4.318202582738733

Epoch: 6| Step: 6
Training loss: 4.327304840087891
Validation loss: 4.28835085386871

Epoch: 6| Step: 7
Training loss: 4.322675704956055
Validation loss: 4.266511937623383

Epoch: 6| Step: 8
Training loss: 3.8214879035949707
Validation loss: 4.22569973750781

Epoch: 6| Step: 9
Training loss: 4.784408092498779
Validation loss: 4.219031559523716

Epoch: 6| Step: 10
Training loss: 4.124423980712891
Validation loss: 4.175757792688185

Epoch: 6| Step: 11
Training loss: 3.825613260269165
Validation loss: 4.147240043968282

Epoch: 6| Step: 12
Training loss: 3.2592225074768066
Validation loss: 4.12133264541626

Epoch: 6| Step: 13
Training loss: 3.66416597366333
Validation loss: 4.093083945653772

Epoch: 14| Step: 0
Training loss: 3.659870147705078
Validation loss: 4.072991806973693

Epoch: 6| Step: 1
Training loss: 2.4938364028930664
Validation loss: 4.048439307879376

Epoch: 6| Step: 2
Training loss: 2.7266480922698975
Validation loss: 4.013092246106876

Epoch: 6| Step: 3
Training loss: 4.795816421508789
Validation loss: 3.988832494264008

Epoch: 6| Step: 4
Training loss: 3.982069492340088
Validation loss: 3.965411252872918

Epoch: 6| Step: 5
Training loss: 4.381227493286133
Validation loss: 3.94128018553539

Epoch: 6| Step: 6
Training loss: 2.840719223022461
Validation loss: 3.903931515191191

Epoch: 6| Step: 7
Training loss: 3.2426750659942627
Validation loss: 3.885310419144169

Epoch: 6| Step: 8
Training loss: 3.3793692588806152
Validation loss: 3.860782746345766

Epoch: 6| Step: 9
Training loss: 5.000290870666504
Validation loss: 3.8408395808230162

Epoch: 6| Step: 10
Training loss: 3.7752420902252197
Validation loss: 3.803741019259217

Epoch: 6| Step: 11
Training loss: 4.284119606018066
Validation loss: 3.769168251304216

Epoch: 6| Step: 12
Training loss: 3.1265604496002197
Validation loss: 3.742902783937352

Epoch: 6| Step: 13
Training loss: 4.771727561950684
Validation loss: 3.7279266593276814

Epoch: 15| Step: 0
Training loss: 3.3656249046325684
Validation loss: 3.687584702686597

Epoch: 6| Step: 1
Training loss: 4.740841388702393
Validation loss: 3.6630349569423224

Epoch: 6| Step: 2
Training loss: 3.008932590484619
Validation loss: 3.641403349496985

Epoch: 6| Step: 3
Training loss: 2.7138333320617676
Validation loss: 3.6120697067629908

Epoch: 6| Step: 4
Training loss: 4.369080066680908
Validation loss: 3.567574293382706

Epoch: 6| Step: 5
Training loss: 3.395508289337158
Validation loss: 3.5504465154422227

Epoch: 6| Step: 6
Training loss: 2.3545756340026855
Validation loss: 3.524005238727857

Epoch: 6| Step: 7
Training loss: 3.2910196781158447
Validation loss: 3.503237655085902

Epoch: 6| Step: 8
Training loss: 2.599655866622925
Validation loss: 3.46159178210843

Epoch: 6| Step: 9
Training loss: 3.6595780849456787
Validation loss: 3.4508246862760155

Epoch: 6| Step: 10
Training loss: 3.8865275382995605
Validation loss: 3.404834965223907

Epoch: 6| Step: 11
Training loss: 3.6783156394958496
Validation loss: 3.3733484027206257

Epoch: 6| Step: 12
Training loss: 2.615934371948242
Validation loss: 3.350790492949947

Epoch: 6| Step: 13
Training loss: 3.5883636474609375
Validation loss: 3.310416821510561

Epoch: 16| Step: 0
Training loss: 2.488004207611084
Validation loss: 3.2810428527093705

Epoch: 6| Step: 1
Training loss: 3.926865339279175
Validation loss: 3.258962861953243

Epoch: 6| Step: 2
Training loss: 3.101109027862549
Validation loss: 3.236378920975552

Epoch: 6| Step: 3
Training loss: 3.4463438987731934
Validation loss: 3.2158449542137886

Epoch: 6| Step: 4
Training loss: 3.277395248413086
Validation loss: 3.1563256273987474

Epoch: 6| Step: 5
Training loss: 3.0331363677978516
Validation loss: 3.156490251582156

Epoch: 6| Step: 6
Training loss: 2.859363317489624
Validation loss: 3.1129928532467095

Epoch: 6| Step: 7
Training loss: 2.6568033695220947
Validation loss: 3.0878470354182745

Epoch: 6| Step: 8
Training loss: 3.074496269226074
Validation loss: 3.0658717565639044

Epoch: 6| Step: 9
Training loss: 2.64229154586792
Validation loss: 3.0172558433266095

Epoch: 6| Step: 10
Training loss: 3.3619768619537354
Validation loss: 3.0193877143244587

Epoch: 6| Step: 11
Training loss: 2.9617600440979004
Validation loss: 2.972117890593826

Epoch: 6| Step: 12
Training loss: 3.8200063705444336
Validation loss: 2.9581509713203675

Epoch: 6| Step: 13
Training loss: 2.5196070671081543
Validation loss: 2.9498455139898483

Epoch: 17| Step: 0
Training loss: 2.566567897796631
Validation loss: 2.921429382857456

Epoch: 6| Step: 1
Training loss: 3.8395633697509766
Validation loss: 2.9106425290466635

Epoch: 6| Step: 2
Training loss: 3.769282817840576
Validation loss: 2.8833515233890985

Epoch: 6| Step: 3
Training loss: 3.423875093460083
Validation loss: 2.859375746019425

Epoch: 6| Step: 4
Training loss: 2.7370824813842773
Validation loss: 2.8386533183436238

Epoch: 6| Step: 5
Training loss: 3.085928440093994
Validation loss: 2.8484852160176923

Epoch: 6| Step: 6
Training loss: 3.5807743072509766
Validation loss: 2.781054655710856

Epoch: 6| Step: 7
Training loss: 2.1807117462158203
Validation loss: 2.780465551601943

Epoch: 6| Step: 8
Training loss: 2.8918209075927734
Validation loss: 2.7674581825092273

Epoch: 6| Step: 9
Training loss: 2.189326286315918
Validation loss: 2.735997756322225

Epoch: 6| Step: 10
Training loss: 2.289001226425171
Validation loss: 2.70670183115108

Epoch: 6| Step: 11
Training loss: 2.303269863128662
Validation loss: 2.7072406020215762

Epoch: 6| Step: 12
Training loss: 2.917773723602295
Validation loss: 2.6946040250921763

Epoch: 6| Step: 13
Training loss: 2.3627445697784424
Validation loss: 2.6663124279309343

Epoch: 18| Step: 0
Training loss: 2.7467386722564697
Validation loss: 2.6472398491315943

Epoch: 6| Step: 1
Training loss: 2.8154923915863037
Validation loss: 2.6354155873739593

Epoch: 6| Step: 2
Training loss: 2.294149875640869
Validation loss: 2.6223886013031006

Epoch: 6| Step: 3
Training loss: 2.4210190773010254
Validation loss: 2.5930526525743547

Epoch: 6| Step: 4
Training loss: 2.2545037269592285
Validation loss: 2.5725433057354343

Epoch: 6| Step: 5
Training loss: 3.552672863006592
Validation loss: 2.5795157776083997

Epoch: 6| Step: 6
Training loss: 2.68066143989563
Validation loss: 2.551890791103404

Epoch: 6| Step: 7
Training loss: 2.764404058456421
Validation loss: 2.545903246889832

Epoch: 6| Step: 8
Training loss: 2.8451664447784424
Validation loss: 2.515530001732611

Epoch: 6| Step: 9
Training loss: 3.4484193325042725
Validation loss: 2.4823114692523913

Epoch: 6| Step: 10
Training loss: 2.6157684326171875
Validation loss: 2.4815751224435787

Epoch: 6| Step: 11
Training loss: 2.7201428413391113
Validation loss: 2.4833219897362495

Epoch: 6| Step: 12
Training loss: 1.7761759757995605
Validation loss: 2.428107601340099

Epoch: 6| Step: 13
Training loss: 2.3769824504852295
Validation loss: 2.423471261096257

Epoch: 19| Step: 0
Training loss: 2.868419647216797
Validation loss: 2.4024647487107145

Epoch: 6| Step: 1
Training loss: 2.7247443199157715
Validation loss: 2.3868494828542075

Epoch: 6| Step: 2
Training loss: 2.741786479949951
Validation loss: 2.3960106911197787

Epoch: 6| Step: 3
Training loss: 2.5925798416137695
Validation loss: 2.38574730965399

Epoch: 6| Step: 4
Training loss: 2.8363912105560303
Validation loss: 2.364642937978109

Epoch: 6| Step: 5
Training loss: 2.740709066390991
Validation loss: 2.381083578191778

Epoch: 6| Step: 6
Training loss: 2.160907745361328
Validation loss: 2.3499447402133735

Epoch: 6| Step: 7
Training loss: 3.286674737930298
Validation loss: 2.3191926222975536

Epoch: 6| Step: 8
Training loss: 2.2081546783447266
Validation loss: 2.3234238547663533

Epoch: 6| Step: 9
Training loss: 2.604264736175537
Validation loss: 2.295601147477345

Epoch: 6| Step: 10
Training loss: 1.720811367034912
Validation loss: 2.3108938176144838

Epoch: 6| Step: 11
Training loss: 2.7687792778015137
Validation loss: 2.290958604504985

Epoch: 6| Step: 12
Training loss: 2.5788278579711914
Validation loss: 2.2843017411488358

Epoch: 6| Step: 13
Training loss: 1.499791145324707
Validation loss: 2.2792678891971545

Epoch: 20| Step: 0
Training loss: 2.5657694339752197
Validation loss: 2.2887012150979813

Epoch: 6| Step: 1
Training loss: 2.7802622318267822
Validation loss: 2.292801687794347

Epoch: 6| Step: 2
Training loss: 3.6173977851867676
Validation loss: 2.253796615908223

Epoch: 6| Step: 3
Training loss: 2.6069746017456055
Validation loss: 2.2818447184819046

Epoch: 6| Step: 4
Training loss: 2.2066359519958496
Validation loss: 2.261290419486261

Epoch: 6| Step: 5
Training loss: 3.788630962371826
Validation loss: 2.2761216522544943

Epoch: 6| Step: 6
Training loss: 1.8067145347595215
Validation loss: 2.228354214340128

Epoch: 6| Step: 7
Training loss: 2.5199642181396484
Validation loss: 2.2521884979740268

Epoch: 6| Step: 8
Training loss: 1.7353631258010864
Validation loss: 2.2382661655385006

Epoch: 6| Step: 9
Training loss: 2.190343141555786
Validation loss: 2.2489950464617823

Epoch: 6| Step: 10
Training loss: 1.9260379076004028
Validation loss: 2.2403226872926116

Epoch: 6| Step: 11
Training loss: 2.979642391204834
Validation loss: 2.240550838490968

Epoch: 6| Step: 12
Training loss: 2.544743061065674
Validation loss: 2.219474438698061

Epoch: 6| Step: 13
Training loss: 1.5262351036071777
Validation loss: 2.242628002679476

Epoch: 21| Step: 0
Training loss: 1.9720125198364258
Validation loss: 2.242729922776581

Epoch: 6| Step: 1
Training loss: 2.595677137374878
Validation loss: 2.239450449584633

Epoch: 6| Step: 2
Training loss: 3.0461349487304688
Validation loss: 2.2324905472417034

Epoch: 6| Step: 3
Training loss: 3.331066846847534
Validation loss: 2.218717651982461

Epoch: 6| Step: 4
Training loss: 2.2786829471588135
Validation loss: 2.224006550286406

Epoch: 6| Step: 5
Training loss: 1.863230586051941
Validation loss: 2.2117526620946903

Epoch: 6| Step: 6
Training loss: 2.6766762733459473
Validation loss: 2.2414085685565905

Epoch: 6| Step: 7
Training loss: 2.808807373046875
Validation loss: 2.208004872004191

Epoch: 6| Step: 8
Training loss: 3.0238749980926514
Validation loss: 2.236583337988905

Epoch: 6| Step: 9
Training loss: 2.3340396881103516
Validation loss: 2.2320734685467136

Epoch: 6| Step: 10
Training loss: 2.548079490661621
Validation loss: 2.2242063732557398

Epoch: 6| Step: 11
Training loss: 2.3874897956848145
Validation loss: 2.2426175712257304

Epoch: 6| Step: 12
Training loss: 1.9667788743972778
Validation loss: 2.2398260537014214

Epoch: 6| Step: 13
Training loss: 1.9805997610092163
Validation loss: 2.2173785419874292

Epoch: 22| Step: 0
Training loss: 1.5850948095321655
Validation loss: 2.2350118775521555

Epoch: 6| Step: 1
Training loss: 2.833177328109741
Validation loss: 2.2319009765501945

Epoch: 6| Step: 2
Training loss: 2.2737889289855957
Validation loss: 2.2059576255018993

Epoch: 6| Step: 3
Training loss: 3.144907236099243
Validation loss: 2.2093585357871106

Epoch: 6| Step: 4
Training loss: 2.045766592025757
Validation loss: 2.2294151449716217

Epoch: 6| Step: 5
Training loss: 2.7914700508117676
Validation loss: 2.2077352090548445

Epoch: 6| Step: 6
Training loss: 2.7457430362701416
Validation loss: 2.1915994126309633

Epoch: 6| Step: 7
Training loss: 2.7500147819519043
Validation loss: 2.2079690758899977

Epoch: 6| Step: 8
Training loss: 2.1974329948425293
Validation loss: 2.212584049470963

Epoch: 6| Step: 9
Training loss: 3.1883292198181152
Validation loss: 2.213946775723529

Epoch: 6| Step: 10
Training loss: 2.660003662109375
Validation loss: 2.184726599724062

Epoch: 6| Step: 11
Training loss: 1.5734496116638184
Validation loss: 2.181728416873563

Epoch: 6| Step: 12
Training loss: 2.2968509197235107
Validation loss: 2.2095337747245707

Epoch: 6| Step: 13
Training loss: 3.301741600036621
Validation loss: 2.179576760979109

Epoch: 23| Step: 0
Training loss: 2.666252374649048
Validation loss: 2.215023051026047

Epoch: 6| Step: 1
Training loss: 2.746150255203247
Validation loss: 2.1905267520617415

Epoch: 6| Step: 2
Training loss: 2.018294334411621
Validation loss: 2.207227856882157

Epoch: 6| Step: 3
Training loss: 1.8756005764007568
Validation loss: 2.2192943288433935

Epoch: 6| Step: 4
Training loss: 1.950070858001709
Validation loss: 2.2306228504386

Epoch: 6| Step: 5
Training loss: 2.610490083694458
Validation loss: 2.22011423367326

Epoch: 6| Step: 6
Training loss: 2.193169355392456
Validation loss: 2.1918723942131124

Epoch: 6| Step: 7
Training loss: 1.8910157680511475
Validation loss: 2.2021019510043565

Epoch: 6| Step: 8
Training loss: 2.4330716133117676
Validation loss: 2.203044693957093

Epoch: 6| Step: 9
Training loss: 2.2290303707122803
Validation loss: 2.2013211199032363

Epoch: 6| Step: 10
Training loss: 3.256291389465332
Validation loss: 2.1915111541748047

Epoch: 6| Step: 11
Training loss: 3.686739683151245
Validation loss: 2.198890023334052

Epoch: 6| Step: 12
Training loss: 2.55928897857666
Validation loss: 2.2073791155251126

Epoch: 6| Step: 13
Training loss: 2.985260009765625
Validation loss: 2.198602925064743

Epoch: 24| Step: 0
Training loss: 2.039095163345337
Validation loss: 2.2077408400915

Epoch: 6| Step: 1
Training loss: 2.9192473888397217
Validation loss: 2.1975045434890257

Epoch: 6| Step: 2
Training loss: 2.1336793899536133
Validation loss: 2.181168407522222

Epoch: 6| Step: 3
Training loss: 3.5381669998168945
Validation loss: 2.199087873581917

Epoch: 6| Step: 4
Training loss: 2.8783347606658936
Validation loss: 2.210087617238363

Epoch: 6| Step: 5
Training loss: 2.0443108081817627
Validation loss: 2.206398069217641

Epoch: 6| Step: 6
Training loss: 2.5545923709869385
Validation loss: 2.1947511678100913

Epoch: 6| Step: 7
Training loss: 2.2110795974731445
Validation loss: 2.183127277640886

Epoch: 6| Step: 8
Training loss: 2.3632678985595703
Validation loss: 2.1963959829781645

Epoch: 6| Step: 9
Training loss: 3.1713438034057617
Validation loss: 2.1860107145001813

Epoch: 6| Step: 10
Training loss: 2.6742610931396484
Validation loss: 2.209559681595013

Epoch: 6| Step: 11
Training loss: 1.999539852142334
Validation loss: 2.180381897957094

Epoch: 6| Step: 12
Training loss: 1.826422095298767
Validation loss: 2.1841344974374257

Epoch: 6| Step: 13
Training loss: 2.588196277618408
Validation loss: 2.179965631936186

Epoch: 25| Step: 0
Training loss: 2.4120116233825684
Validation loss: 2.1769028299598285

Epoch: 6| Step: 1
Training loss: 2.2600975036621094
Validation loss: 2.183701394706644

Epoch: 6| Step: 2
Training loss: 2.662337303161621
Validation loss: 2.1922077658355876

Epoch: 6| Step: 3
Training loss: 2.817633628845215
Validation loss: 2.215339199189217

Epoch: 6| Step: 4
Training loss: 2.371865749359131
Validation loss: 2.173577311218426

Epoch: 6| Step: 5
Training loss: 2.3333868980407715
Validation loss: 2.1940097655019453

Epoch: 6| Step: 6
Training loss: 2.2584609985351562
Validation loss: 2.2006293624959965

Epoch: 6| Step: 7
Training loss: 2.7454538345336914
Validation loss: 2.188348188195177

Epoch: 6| Step: 8
Training loss: 2.1012372970581055
Validation loss: 2.227657010478358

Epoch: 6| Step: 9
Training loss: 2.6766915321350098
Validation loss: 2.1873506346056537

Epoch: 6| Step: 10
Training loss: 1.678370475769043
Validation loss: 2.196627022117697

Epoch: 6| Step: 11
Training loss: 2.508671760559082
Validation loss: 2.19607215030219

Epoch: 6| Step: 12
Training loss: 2.7340028285980225
Validation loss: 2.1872716065376037

Epoch: 6| Step: 13
Training loss: 3.613415241241455
Validation loss: 2.1694440457128708

Epoch: 26| Step: 0
Training loss: 2.340696334838867
Validation loss: 2.1775301528233353

Epoch: 6| Step: 1
Training loss: 2.23222017288208
Validation loss: 2.211363930856028

Epoch: 6| Step: 2
Training loss: 2.00508189201355
Validation loss: 2.191656190861938

Epoch: 6| Step: 3
Training loss: 2.9111440181732178
Validation loss: 2.1922344751255487

Epoch: 6| Step: 4
Training loss: 3.0186526775360107
Validation loss: 2.1882286520414453

Epoch: 6| Step: 5
Training loss: 2.7025649547576904
Validation loss: 2.171041570683961

Epoch: 6| Step: 6
Training loss: 2.6945719718933105
Validation loss: 2.1719260408032324

Epoch: 6| Step: 7
Training loss: 3.4603488445281982
Validation loss: 2.1622547026603454

Epoch: 6| Step: 8
Training loss: 2.2711548805236816
Validation loss: 2.171552037680021

Epoch: 6| Step: 9
Training loss: 1.7593666315078735
Validation loss: 2.166951911423796

Epoch: 6| Step: 10
Training loss: 1.701420545578003
Validation loss: 2.1709105404474403

Epoch: 6| Step: 11
Training loss: 2.0629701614379883
Validation loss: 2.1869644041984313

Epoch: 6| Step: 12
Training loss: 2.6441023349761963
Validation loss: 2.1845086184881066

Epoch: 6| Step: 13
Training loss: 2.962324380874634
Validation loss: 2.182228203742735

Epoch: 27| Step: 0
Training loss: 2.4705119132995605
Validation loss: 2.1643917727214035

Epoch: 6| Step: 1
Training loss: 2.6084015369415283
Validation loss: 2.197581955181655

Epoch: 6| Step: 2
Training loss: 2.805213451385498
Validation loss: 2.166799121005561

Epoch: 6| Step: 3
Training loss: 3.119462251663208
Validation loss: 2.1866150568890315

Epoch: 6| Step: 4
Training loss: 2.590418815612793
Validation loss: 2.1844321604697936

Epoch: 6| Step: 5
Training loss: 1.6096408367156982
Validation loss: 2.2079298368064304

Epoch: 6| Step: 6
Training loss: 2.1015944480895996
Validation loss: 2.1827948657415246

Epoch: 6| Step: 7
Training loss: 2.702004909515381
Validation loss: 2.17885434755715

Epoch: 6| Step: 8
Training loss: 2.785337448120117
Validation loss: 2.1918558048945602

Epoch: 6| Step: 9
Training loss: 2.769322633743286
Validation loss: 2.19422088643556

Epoch: 6| Step: 10
Training loss: 1.9488123655319214
Validation loss: 2.2086658452146795

Epoch: 6| Step: 11
Training loss: 1.7760801315307617
Validation loss: 2.185060331898351

Epoch: 6| Step: 12
Training loss: 2.596226930618286
Validation loss: 2.1892471531386017

Epoch: 6| Step: 13
Training loss: 2.515284299850464
Validation loss: 2.1868772506713867

Epoch: 28| Step: 0
Training loss: 3.3315844535827637
Validation loss: 2.2006203948810534

Epoch: 6| Step: 1
Training loss: 3.2829041481018066
Validation loss: 2.207442581012685

Epoch: 6| Step: 2
Training loss: 2.5292460918426514
Validation loss: 2.1953107515970864

Epoch: 6| Step: 3
Training loss: 2.652444362640381
Validation loss: 2.180588677365293

Epoch: 6| Step: 4
Training loss: 1.9144794940948486
Validation loss: 2.177254371745612

Epoch: 6| Step: 5
Training loss: 1.9934213161468506
Validation loss: 2.1670277426319737

Epoch: 6| Step: 6
Training loss: 1.9955273866653442
Validation loss: 2.183046110214726

Epoch: 6| Step: 7
Training loss: 1.9901732206344604
Validation loss: 2.1744025676481185

Epoch: 6| Step: 8
Training loss: 2.493330955505371
Validation loss: 2.199982020162767

Epoch: 6| Step: 9
Training loss: 2.522570848464966
Validation loss: 2.1801768323426605

Epoch: 6| Step: 10
Training loss: 2.76426100730896
Validation loss: 2.191383559216735

Epoch: 6| Step: 11
Training loss: 2.0382165908813477
Validation loss: 2.166866430672266

Epoch: 6| Step: 12
Training loss: 2.238600254058838
Validation loss: 2.154506616694953

Epoch: 6| Step: 13
Training loss: 2.7975218296051025
Validation loss: 2.192568286772697

Epoch: 29| Step: 0
Training loss: 1.8668969869613647
Validation loss: 2.1920689331587924

Epoch: 6| Step: 1
Training loss: 2.55777645111084
Validation loss: 2.163234641475062

Epoch: 6| Step: 2
Training loss: 2.099940299987793
Validation loss: 2.1742998066768853

Epoch: 6| Step: 3
Training loss: 3.5147242546081543
Validation loss: 2.179480657782606

Epoch: 6| Step: 4
Training loss: 1.8997893333435059
Validation loss: 2.1536475637907624

Epoch: 6| Step: 5
Training loss: 2.4201481342315674
Validation loss: 2.162007616412255

Epoch: 6| Step: 6
Training loss: 2.55610990524292
Validation loss: 2.2037631414269887

Epoch: 6| Step: 7
Training loss: 1.911299467086792
Validation loss: 2.1551852636439826

Epoch: 6| Step: 8
Training loss: 2.578099250793457
Validation loss: 2.154963087010127

Epoch: 6| Step: 9
Training loss: 2.799466609954834
Validation loss: 2.191686063684443

Epoch: 6| Step: 10
Training loss: 3.034613609313965
Validation loss: 2.1660577430520007

Epoch: 6| Step: 11
Training loss: 2.6490306854248047
Validation loss: 2.1629046727252264

Epoch: 6| Step: 12
Training loss: 2.1284146308898926
Validation loss: 2.1647157630612774

Epoch: 6| Step: 13
Training loss: 2.0217955112457275
Validation loss: 2.170378759343137

Epoch: 30| Step: 0
Training loss: 3.0428738594055176
Validation loss: 2.150936908619378

Epoch: 6| Step: 1
Training loss: 3.4118523597717285
Validation loss: 2.158910325778428

Epoch: 6| Step: 2
Training loss: 1.6195532083511353
Validation loss: 2.1521200723545526

Epoch: 6| Step: 3
Training loss: 2.4201228618621826
Validation loss: 2.160748136940823

Epoch: 6| Step: 4
Training loss: 2.365093231201172
Validation loss: 2.1624222468304377

Epoch: 6| Step: 5
Training loss: 2.2379395961761475
Validation loss: 2.163373480560959

Epoch: 6| Step: 6
Training loss: 2.8748388290405273
Validation loss: 2.1637739032827397

Epoch: 6| Step: 7
Training loss: 2.813234329223633
Validation loss: 2.147419812858746

Epoch: 6| Step: 8
Training loss: 2.74491548538208
Validation loss: 2.163534423356415

Epoch: 6| Step: 9
Training loss: 1.8263564109802246
Validation loss: 2.1564370765480945

Epoch: 6| Step: 10
Training loss: 2.5156335830688477
Validation loss: 2.1725792423371346

Epoch: 6| Step: 11
Training loss: 2.1837174892425537
Validation loss: 2.161624285482591

Epoch: 6| Step: 12
Training loss: 1.719178318977356
Validation loss: 2.1291386978600615

Epoch: 6| Step: 13
Training loss: 2.1444613933563232
Validation loss: 2.14901162475668

Epoch: 31| Step: 0
Training loss: 2.5416855812072754
Validation loss: 2.1618635449358212

Epoch: 6| Step: 1
Training loss: 2.42449951171875
Validation loss: 2.1614879228735484

Epoch: 6| Step: 2
Training loss: 3.319261074066162
Validation loss: 2.1578646949542466

Epoch: 6| Step: 3
Training loss: 2.1419317722320557
Validation loss: 2.138650578837241

Epoch: 6| Step: 4
Training loss: 2.5724334716796875
Validation loss: 2.1326444956564132

Epoch: 6| Step: 5
Training loss: 2.1398589611053467
Validation loss: 2.1242574748172554

Epoch: 6| Step: 6
Training loss: 2.4408068656921387
Validation loss: 2.1306278526142077

Epoch: 6| Step: 7
Training loss: 2.927135705947876
Validation loss: 2.159778110442623

Epoch: 6| Step: 8
Training loss: 2.269543170928955
Validation loss: 2.128416292129024

Epoch: 6| Step: 9
Training loss: 1.4658973217010498
Validation loss: 2.1391943987979682

Epoch: 6| Step: 10
Training loss: 3.080824851989746
Validation loss: 2.163754368341097

Epoch: 6| Step: 11
Training loss: 2.657329559326172
Validation loss: 2.126467894482356

Epoch: 6| Step: 12
Training loss: 1.6095526218414307
Validation loss: 2.1629910827964864

Epoch: 6| Step: 13
Training loss: 2.888108968734741
Validation loss: 2.1646422058023433

Epoch: 32| Step: 0
Training loss: 2.375230312347412
Validation loss: 2.1621109747117564

Epoch: 6| Step: 1
Training loss: 2.0975284576416016
Validation loss: 2.1391218298224994

Epoch: 6| Step: 2
Training loss: 2.677912712097168
Validation loss: 2.1484235768677085

Epoch: 6| Step: 3
Training loss: 3.0095200538635254
Validation loss: 2.1243512220280145

Epoch: 6| Step: 4
Training loss: 2.1958727836608887
Validation loss: 2.1631258610756166

Epoch: 6| Step: 5
Training loss: 2.1223762035369873
Validation loss: 2.150931158373433

Epoch: 6| Step: 6
Training loss: 2.273308277130127
Validation loss: 2.127633488306435

Epoch: 6| Step: 7
Training loss: 2.300199270248413
Validation loss: 2.162570966187344

Epoch: 6| Step: 8
Training loss: 1.9047588109970093
Validation loss: 2.1466375294552056

Epoch: 6| Step: 9
Training loss: 2.4789443016052246
Validation loss: 2.154969894757835

Epoch: 6| Step: 10
Training loss: 2.103238582611084
Validation loss: 2.144451311839524

Epoch: 6| Step: 11
Training loss: 2.8385634422302246
Validation loss: 2.136258448323896

Epoch: 6| Step: 12
Training loss: 2.910508155822754
Validation loss: 2.1334907111301216

Epoch: 6| Step: 13
Training loss: 2.60895037651062
Validation loss: 2.1479134277630876

Epoch: 33| Step: 0
Training loss: 2.002521514892578
Validation loss: 2.1401832437002533

Epoch: 6| Step: 1
Training loss: 2.136695146560669
Validation loss: 2.141475824899571

Epoch: 6| Step: 2
Training loss: 2.69236421585083
Validation loss: 2.1364176375891573

Epoch: 6| Step: 3
Training loss: 2.6465835571289062
Validation loss: 2.1473743672012002

Epoch: 6| Step: 4
Training loss: 2.492339611053467
Validation loss: 2.1235996882120767

Epoch: 6| Step: 5
Training loss: 2.492642641067505
Validation loss: 2.147674147800733

Epoch: 6| Step: 6
Training loss: 2.53936767578125
Validation loss: 2.1400189732992523

Epoch: 6| Step: 7
Training loss: 2.1453001499176025
Validation loss: 2.1309250324003157

Epoch: 6| Step: 8
Training loss: 2.40814208984375
Validation loss: 2.144026533249886

Epoch: 6| Step: 9
Training loss: 2.6262547969818115
Validation loss: 2.1436204000185897

Epoch: 6| Step: 10
Training loss: 1.7925595045089722
Validation loss: 2.122090647297521

Epoch: 6| Step: 11
Training loss: 2.8729958534240723
Validation loss: 2.1470649050128077

Epoch: 6| Step: 12
Training loss: 2.2611544132232666
Validation loss: 2.111575970085718

Epoch: 6| Step: 13
Training loss: 2.872471809387207
Validation loss: 2.1214824761113813

Epoch: 34| Step: 0
Training loss: 2.6807055473327637
Validation loss: 2.13193634633095

Epoch: 6| Step: 1
Training loss: 2.341773509979248
Validation loss: 2.132267157236735

Epoch: 6| Step: 2
Training loss: 2.6528420448303223
Validation loss: 2.1490670839945474

Epoch: 6| Step: 3
Training loss: 2.8087968826293945
Validation loss: 2.157875176398985

Epoch: 6| Step: 4
Training loss: 2.3201560974121094
Validation loss: 2.1406418687553814

Epoch: 6| Step: 5
Training loss: 2.660243034362793
Validation loss: 2.1332698663075766

Epoch: 6| Step: 6
Training loss: 2.425706386566162
Validation loss: 2.1357999001779864

Epoch: 6| Step: 7
Training loss: 1.534125804901123
Validation loss: 2.1331634752212034

Epoch: 6| Step: 8
Training loss: 2.028597116470337
Validation loss: 2.1358589151854157

Epoch: 6| Step: 9
Training loss: 2.361987829208374
Validation loss: 2.1431797973571287

Epoch: 6| Step: 10
Training loss: 3.383759021759033
Validation loss: 2.1198874865808794

Epoch: 6| Step: 11
Training loss: 2.3455970287323
Validation loss: 2.1379574678277455

Epoch: 6| Step: 12
Training loss: 2.4123356342315674
Validation loss: 2.1426987648010254

Epoch: 6| Step: 13
Training loss: 1.3580883741378784
Validation loss: 2.1349289622358096

Epoch: 35| Step: 0
Training loss: 2.6788928508758545
Validation loss: 2.1496388835291707

Epoch: 6| Step: 1
Training loss: 2.1688485145568848
Validation loss: 2.141184219750025

Epoch: 6| Step: 2
Training loss: 2.464771270751953
Validation loss: 2.1310693628044537

Epoch: 6| Step: 3
Training loss: 2.8317151069641113
Validation loss: 2.127543249437886

Epoch: 6| Step: 4
Training loss: 2.349095344543457
Validation loss: 2.139050775958646

Epoch: 6| Step: 5
Training loss: 2.1813805103302
Validation loss: 2.1463640095085226

Epoch: 6| Step: 6
Training loss: 2.483243465423584
Validation loss: 2.1413761454243816

Epoch: 6| Step: 7
Training loss: 2.7076830863952637
Validation loss: 2.1383108938893964

Epoch: 6| Step: 8
Training loss: 2.5784435272216797
Validation loss: 2.173040989906557

Epoch: 6| Step: 9
Training loss: 2.5672426223754883
Validation loss: 2.155094059564734

Epoch: 6| Step: 10
Training loss: 2.2980422973632812
Validation loss: 2.12531953729609

Epoch: 6| Step: 11
Training loss: 1.956003189086914
Validation loss: 2.1577823200533466

Epoch: 6| Step: 12
Training loss: 1.8974061012268066
Validation loss: 2.144152561823527

Epoch: 6| Step: 13
Training loss: 2.573772430419922
Validation loss: 2.1328208446502686

Epoch: 36| Step: 0
Training loss: 2.507340908050537
Validation loss: 2.145214560211346

Epoch: 6| Step: 1
Training loss: 3.0215208530426025
Validation loss: 2.1435219139181156

Epoch: 6| Step: 2
Training loss: 2.0143659114837646
Validation loss: 2.1369979766107376

Epoch: 6| Step: 3
Training loss: 2.1447253227233887
Validation loss: 2.152800651006801

Epoch: 6| Step: 4
Training loss: 2.851034164428711
Validation loss: 2.111633800691174

Epoch: 6| Step: 5
Training loss: 0.8660293817520142
Validation loss: 2.12362309937836

Epoch: 6| Step: 6
Training loss: 2.0151970386505127
Validation loss: 2.121551887963408

Epoch: 6| Step: 7
Training loss: 2.1420016288757324
Validation loss: 2.115087478391586

Epoch: 6| Step: 8
Training loss: 2.7891082763671875
Validation loss: 2.1164706753146265

Epoch: 6| Step: 9
Training loss: 2.7167673110961914
Validation loss: 2.122748239066011

Epoch: 6| Step: 10
Training loss: 2.6321890354156494
Validation loss: 2.1090106887202107

Epoch: 6| Step: 11
Training loss: 3.021533489227295
Validation loss: 2.136210908171951

Epoch: 6| Step: 12
Training loss: 2.045419216156006
Validation loss: 2.1014302930524273

Epoch: 6| Step: 13
Training loss: 3.5532636642456055
Validation loss: 2.108290903029903

Epoch: 37| Step: 0
Training loss: 2.868192672729492
Validation loss: 2.127892988984303

Epoch: 6| Step: 1
Training loss: 2.693601131439209
Validation loss: 2.1226354286234868

Epoch: 6| Step: 2
Training loss: 2.8941473960876465
Validation loss: 2.1295421226050264

Epoch: 6| Step: 3
Training loss: 2.9946699142456055
Validation loss: 2.1113465755216536

Epoch: 6| Step: 4
Training loss: 2.721668243408203
Validation loss: 2.1180272820175334

Epoch: 6| Step: 5
Training loss: 2.4922828674316406
Validation loss: 2.114651115991736

Epoch: 6| Step: 6
Training loss: 1.9897172451019287
Validation loss: 2.1327942725150817

Epoch: 6| Step: 7
Training loss: 2.504611015319824
Validation loss: 2.139687873983896

Epoch: 6| Step: 8
Training loss: 2.251366376876831
Validation loss: 2.1361712922332106

Epoch: 6| Step: 9
Training loss: 1.585790991783142
Validation loss: 2.1149817128335275

Epoch: 6| Step: 10
Training loss: 1.5028131008148193
Validation loss: 2.1324582830552132

Epoch: 6| Step: 11
Training loss: 2.0471858978271484
Validation loss: 2.109081955366237

Epoch: 6| Step: 12
Training loss: 2.537078380584717
Validation loss: 2.1218233544339418

Epoch: 6| Step: 13
Training loss: 2.3434627056121826
Validation loss: 2.128135791388891

Epoch: 38| Step: 0
Training loss: 2.7132468223571777
Validation loss: 2.1158798663846907

Epoch: 6| Step: 1
Training loss: 1.537564992904663
Validation loss: 2.1109158339038974

Epoch: 6| Step: 2
Training loss: 2.9818873405456543
Validation loss: 2.1191266839222243

Epoch: 6| Step: 3
Training loss: 2.115797519683838
Validation loss: 2.1247163690546507

Epoch: 6| Step: 4
Training loss: 2.6077706813812256
Validation loss: 2.119317344439927

Epoch: 6| Step: 5
Training loss: 2.0796914100646973
Validation loss: 2.130373377953806

Epoch: 6| Step: 6
Training loss: 2.2527647018432617
Validation loss: 2.129746949800881

Epoch: 6| Step: 7
Training loss: 2.492490291595459
Validation loss: 2.128280476857257

Epoch: 6| Step: 8
Training loss: 2.3172168731689453
Validation loss: 2.1021231861524683

Epoch: 6| Step: 9
Training loss: 1.6858627796173096
Validation loss: 2.121952058807496

Epoch: 6| Step: 10
Training loss: 2.593197822570801
Validation loss: 2.132540269564557

Epoch: 6| Step: 11
Training loss: 2.292280673980713
Validation loss: 2.093285068388908

Epoch: 6| Step: 12
Training loss: 3.4829020500183105
Validation loss: 2.1152106433786373

Epoch: 6| Step: 13
Training loss: 1.916520595550537
Validation loss: 2.1362161892716602

Epoch: 39| Step: 0
Training loss: 2.803251266479492
Validation loss: 2.11819794870192

Epoch: 6| Step: 1
Training loss: 1.7678978443145752
Validation loss: 2.1388738052819365

Epoch: 6| Step: 2
Training loss: 2.2626922130584717
Validation loss: 2.096943142593548

Epoch: 6| Step: 3
Training loss: 3.1459898948669434
Validation loss: 2.126868119803808

Epoch: 6| Step: 4
Training loss: 2.0802900791168213
Validation loss: 2.1080270198083695

Epoch: 6| Step: 5
Training loss: 2.5854287147521973
Validation loss: 2.141913826747607

Epoch: 6| Step: 6
Training loss: 2.082057476043701
Validation loss: 2.124376978925479

Epoch: 6| Step: 7
Training loss: 1.92555832862854
Validation loss: 2.1446292118359636

Epoch: 6| Step: 8
Training loss: 2.204235792160034
Validation loss: 2.1138298255141064

Epoch: 6| Step: 9
Training loss: 2.595614433288574
Validation loss: 2.1103632398830947

Epoch: 6| Step: 10
Training loss: 2.1177706718444824
Validation loss: 2.134189828749626

Epoch: 6| Step: 11
Training loss: 2.1079025268554688
Validation loss: 2.142800236261019

Epoch: 6| Step: 12
Training loss: 2.659062385559082
Validation loss: 2.1311436391645864

Epoch: 6| Step: 13
Training loss: 3.622901439666748
Validation loss: 2.1199299750789518

Epoch: 40| Step: 0
Training loss: 3.1294665336608887
Validation loss: 2.130804528472244

Epoch: 6| Step: 1
Training loss: 2.6045737266540527
Validation loss: 2.138080264932366

Epoch: 6| Step: 2
Training loss: 1.717369556427002
Validation loss: 2.1415794985268706

Epoch: 6| Step: 3
Training loss: 2.3386788368225098
Validation loss: 2.1109618115168747

Epoch: 6| Step: 4
Training loss: 2.03733229637146
Validation loss: 2.116305071820495

Epoch: 6| Step: 5
Training loss: 2.260873317718506
Validation loss: 2.1180440238727036

Epoch: 6| Step: 6
Training loss: 2.0698227882385254
Validation loss: 2.121961764110032

Epoch: 6| Step: 7
Training loss: 2.2271766662597656
Validation loss: 2.1218067984427176

Epoch: 6| Step: 8
Training loss: 3.2400360107421875
Validation loss: 2.142348929118085

Epoch: 6| Step: 9
Training loss: 2.6270954608917236
Validation loss: 2.095189158634473

Epoch: 6| Step: 10
Training loss: 1.542755365371704
Validation loss: 2.132984321604493

Epoch: 6| Step: 11
Training loss: 2.7823987007141113
Validation loss: 2.1332285737478607

Epoch: 6| Step: 12
Training loss: 2.72503662109375
Validation loss: 2.1307728828922397

Epoch: 6| Step: 13
Training loss: 1.92947256565094
Validation loss: 2.1180540412984867

Epoch: 41| Step: 0
Training loss: 2.1829581260681152
Validation loss: 2.1350688062688357

Epoch: 6| Step: 1
Training loss: 2.2755532264709473
Validation loss: 2.1224454038886615

Epoch: 6| Step: 2
Training loss: 2.278944969177246
Validation loss: 2.11816575706646

Epoch: 6| Step: 3
Training loss: 1.4328910112380981
Validation loss: 2.1297796477553663

Epoch: 6| Step: 4
Training loss: 2.3293514251708984
Validation loss: 2.1286305535224175

Epoch: 6| Step: 5
Training loss: 3.3016297817230225
Validation loss: 2.136857303239966

Epoch: 6| Step: 6
Training loss: 2.0481200218200684
Validation loss: 2.119358075562344

Epoch: 6| Step: 7
Training loss: 2.5428638458251953
Validation loss: 2.128589681399766

Epoch: 6| Step: 8
Training loss: 2.456634044647217
Validation loss: 2.1298379757071055

Epoch: 6| Step: 9
Training loss: 2.412419319152832
Validation loss: 2.1183663440007034

Epoch: 6| Step: 10
Training loss: 2.2974371910095215
Validation loss: 2.100548387855612

Epoch: 6| Step: 11
Training loss: 2.3026070594787598
Validation loss: 2.143961174513704

Epoch: 6| Step: 12
Training loss: 2.1643872261047363
Validation loss: 2.118152569699031

Epoch: 6| Step: 13
Training loss: 3.511695623397827
Validation loss: 2.14200823537765

Epoch: 42| Step: 0
Training loss: 1.1050522327423096
Validation loss: 2.118324469494563

Epoch: 6| Step: 1
Training loss: 2.6101109981536865
Validation loss: 2.125303699124244

Epoch: 6| Step: 2
Training loss: 3.0464987754821777
Validation loss: 2.1110950144388343

Epoch: 6| Step: 3
Training loss: 1.8592559099197388
Validation loss: 2.1282492747870823

Epoch: 6| Step: 4
Training loss: 1.593058466911316
Validation loss: 2.1142946891887213

Epoch: 6| Step: 5
Training loss: 3.7987220287323
Validation loss: 2.128498333756642

Epoch: 6| Step: 6
Training loss: 2.803281784057617
Validation loss: 2.1167153440495974

Epoch: 6| Step: 7
Training loss: 1.9700393676757812
Validation loss: 2.1136847542178248

Epoch: 6| Step: 8
Training loss: 2.9910831451416016
Validation loss: 2.115827819352509

Epoch: 6| Step: 9
Training loss: 1.4817264080047607
Validation loss: 2.122921892391738

Epoch: 6| Step: 10
Training loss: 2.778069496154785
Validation loss: 2.107480069642426

Epoch: 6| Step: 11
Training loss: 2.764051675796509
Validation loss: 2.1109564893989154

Epoch: 6| Step: 12
Training loss: 2.3072562217712402
Validation loss: 2.1224903432271813

Epoch: 6| Step: 13
Training loss: 1.5963484048843384
Validation loss: 2.099262060657624

Epoch: 43| Step: 0
Training loss: 2.850884199142456
Validation loss: 2.105820099512736

Epoch: 6| Step: 1
Training loss: 1.7900794744491577
Validation loss: 2.108610660799088

Epoch: 6| Step: 2
Training loss: 2.4180612564086914
Validation loss: 2.1058754767141035

Epoch: 6| Step: 3
Training loss: 2.9429821968078613
Validation loss: 2.0912022462455173

Epoch: 6| Step: 4
Training loss: 1.5638220310211182
Validation loss: 2.1002817794840825

Epoch: 6| Step: 5
Training loss: 1.9331711530685425
Validation loss: 2.09945204693784

Epoch: 6| Step: 6
Training loss: 2.2527310848236084
Validation loss: 2.1370916315304336

Epoch: 6| Step: 7
Training loss: 3.2942612171173096
Validation loss: 2.1115644990756945

Epoch: 6| Step: 8
Training loss: 2.40750789642334
Validation loss: 2.114694849137337

Epoch: 6| Step: 9
Training loss: 3.0312304496765137
Validation loss: 2.101344193181684

Epoch: 6| Step: 10
Training loss: 1.9301668405532837
Validation loss: 2.1047026905962216

Epoch: 6| Step: 11
Training loss: 2.0737266540527344
Validation loss: 2.134309361057897

Epoch: 6| Step: 12
Training loss: 1.908444881439209
Validation loss: 2.112037976582845

Epoch: 6| Step: 13
Training loss: 2.723700761795044
Validation loss: 2.0999573494798396

Epoch: 44| Step: 0
Training loss: 1.7373301982879639
Validation loss: 2.1109728684989353

Epoch: 6| Step: 1
Training loss: 2.9494500160217285
Validation loss: 2.1053241837409233

Epoch: 6| Step: 2
Training loss: 2.0616066455841064
Validation loss: 2.1058014438998316

Epoch: 6| Step: 3
Training loss: 2.7077414989471436
Validation loss: 2.10499640434019

Epoch: 6| Step: 4
Training loss: 1.7671329975128174
Validation loss: 2.1152072516820764

Epoch: 6| Step: 5
Training loss: 2.600109577178955
Validation loss: 2.116620176581926

Epoch: 6| Step: 6
Training loss: 2.215324640274048
Validation loss: 2.1089763615721013

Epoch: 6| Step: 7
Training loss: 2.4896597862243652
Validation loss: 2.129524677030502

Epoch: 6| Step: 8
Training loss: 1.8149099349975586
Validation loss: 2.1235726546215754

Epoch: 6| Step: 9
Training loss: 2.472891330718994
Validation loss: 2.127956759545111

Epoch: 6| Step: 10
Training loss: 2.142019271850586
Validation loss: 2.1390981315284647

Epoch: 6| Step: 11
Training loss: 2.790182113647461
Validation loss: 2.1326341090663785

Epoch: 6| Step: 12
Training loss: 2.689781665802002
Validation loss: 2.116846425558931

Epoch: 6| Step: 13
Training loss: 2.8738768100738525
Validation loss: 2.1530152674644225

Epoch: 45| Step: 0
Training loss: 1.422447681427002
Validation loss: 2.119876807735812

Epoch: 6| Step: 1
Training loss: 2.2642710208892822
Validation loss: 2.1192587767877886

Epoch: 6| Step: 2
Training loss: 2.2666287422180176
Validation loss: 2.1177400004479194

Epoch: 6| Step: 3
Training loss: 2.063042402267456
Validation loss: 2.114698645889118

Epoch: 6| Step: 4
Training loss: 2.575490713119507
Validation loss: 2.109370678983709

Epoch: 6| Step: 5
Training loss: 2.230408191680908
Validation loss: 2.120069323047515

Epoch: 6| Step: 6
Training loss: 2.624674081802368
Validation loss: 2.102390455943282

Epoch: 6| Step: 7
Training loss: 2.161755084991455
Validation loss: 2.109913185078611

Epoch: 6| Step: 8
Training loss: 3.273160934448242
Validation loss: 2.0994676761729743

Epoch: 6| Step: 9
Training loss: 2.2383322715759277
Validation loss: 2.095180292283335

Epoch: 6| Step: 10
Training loss: 2.3298091888427734
Validation loss: 2.121160857139095

Epoch: 6| Step: 11
Training loss: 1.663390874862671
Validation loss: 2.0997004432062947

Epoch: 6| Step: 12
Training loss: 3.2539186477661133
Validation loss: 2.1138061144018687

Epoch: 6| Step: 13
Training loss: 2.6293938159942627
Validation loss: 2.0969167063313146

Epoch: 46| Step: 0
Training loss: 1.6175942420959473
Validation loss: 2.1025049712068293

Epoch: 6| Step: 1
Training loss: 2.937774658203125
Validation loss: 2.1121003371413036

Epoch: 6| Step: 2
Training loss: 2.1224067211151123
Validation loss: 2.0881414721089024

Epoch: 6| Step: 3
Training loss: 2.081028699874878
Validation loss: 2.097756620376341

Epoch: 6| Step: 4
Training loss: 2.5472071170806885
Validation loss: 2.111494033567367

Epoch: 6| Step: 5
Training loss: 2.1977860927581787
Validation loss: 2.1080845991770425

Epoch: 6| Step: 6
Training loss: 2.9324679374694824
Validation loss: 2.0833362507563766

Epoch: 6| Step: 7
Training loss: 2.4074528217315674
Validation loss: 2.1217539515546573

Epoch: 6| Step: 8
Training loss: 1.9315208196640015
Validation loss: 2.1019931275357484

Epoch: 6| Step: 9
Training loss: 2.693106174468994
Validation loss: 2.0881089651456444

Epoch: 6| Step: 10
Training loss: 1.7887229919433594
Validation loss: 2.11037205624324

Epoch: 6| Step: 11
Training loss: 3.085914134979248
Validation loss: 2.1081827994315856

Epoch: 6| Step: 12
Training loss: 2.022451162338257
Validation loss: 2.1078832354596866

Epoch: 6| Step: 13
Training loss: 2.468759059906006
Validation loss: 2.116271802174148

Epoch: 47| Step: 0
Training loss: 1.9076213836669922
Validation loss: 2.1131927608161845

Epoch: 6| Step: 1
Training loss: 1.9854297637939453
Validation loss: 2.1205959448250393

Epoch: 6| Step: 2
Training loss: 2.297654628753662
Validation loss: 2.0955385905440136

Epoch: 6| Step: 3
Training loss: 1.8632409572601318
Validation loss: 2.08277710535193

Epoch: 6| Step: 4
Training loss: 1.9057502746582031
Validation loss: 2.102332563810451

Epoch: 6| Step: 5
Training loss: 1.9534155130386353
Validation loss: 2.125377696047547

Epoch: 6| Step: 6
Training loss: 3.3799498081207275
Validation loss: 2.11021747127656

Epoch: 6| Step: 7
Training loss: 2.9241442680358887
Validation loss: 2.1002757882559173

Epoch: 6| Step: 8
Training loss: 2.615473747253418
Validation loss: 2.1136872512038036

Epoch: 6| Step: 9
Training loss: 2.398852825164795
Validation loss: 2.1230869639304375

Epoch: 6| Step: 10
Training loss: 1.9196135997772217
Validation loss: 2.109912310877154

Epoch: 6| Step: 11
Training loss: 2.5216565132141113
Validation loss: 2.117281154919696

Epoch: 6| Step: 12
Training loss: 2.936049461364746
Validation loss: 2.1073325398147746

Epoch: 6| Step: 13
Training loss: 2.573920965194702
Validation loss: 2.120870522273484

Epoch: 48| Step: 0
Training loss: 3.169602870941162
Validation loss: 2.098366973220661

Epoch: 6| Step: 1
Training loss: 2.5452888011932373
Validation loss: 2.104522879405688

Epoch: 6| Step: 2
Training loss: 2.500915765762329
Validation loss: 2.1138887315668087

Epoch: 6| Step: 3
Training loss: 2.6753759384155273
Validation loss: 2.1011132553059566

Epoch: 6| Step: 4
Training loss: 2.1071090698242188
Validation loss: 2.102994124094645

Epoch: 6| Step: 5
Training loss: 2.3121352195739746
Validation loss: 2.1218910140375935

Epoch: 6| Step: 6
Training loss: 1.974719524383545
Validation loss: 2.127253509336902

Epoch: 6| Step: 7
Training loss: 2.686699390411377
Validation loss: 2.1381675684323875

Epoch: 6| Step: 8
Training loss: 1.8995192050933838
Validation loss: 2.151441558714836

Epoch: 6| Step: 9
Training loss: 2.3589048385620117
Validation loss: 2.1232818429188063

Epoch: 6| Step: 10
Training loss: 2.5140252113342285
Validation loss: 2.121534744898478

Epoch: 6| Step: 11
Training loss: 1.5197006464004517
Validation loss: 2.134943862115183

Epoch: 6| Step: 12
Training loss: 2.256897449493408
Validation loss: 2.116267740085561

Epoch: 6| Step: 13
Training loss: 2.415308952331543
Validation loss: 2.116891599470569

Epoch: 49| Step: 0
Training loss: 3.2303078174591064
Validation loss: 2.1382894490354802

Epoch: 6| Step: 1
Training loss: 2.0527617931365967
Validation loss: 2.122479664382114

Epoch: 6| Step: 2
Training loss: 2.1740808486938477
Validation loss: 2.1021824780330864

Epoch: 6| Step: 3
Training loss: 2.5475363731384277
Validation loss: 2.130323197252007

Epoch: 6| Step: 4
Training loss: 2.066488265991211
Validation loss: 2.1275575314798663

Epoch: 6| Step: 5
Training loss: 1.3534698486328125
Validation loss: 2.105669415125283

Epoch: 6| Step: 6
Training loss: 2.0720436573028564
Validation loss: 2.1351886205775763

Epoch: 6| Step: 7
Training loss: 2.0304629802703857
Validation loss: 2.114891270155548

Epoch: 6| Step: 8
Training loss: 2.5877156257629395
Validation loss: 2.119892768962409

Epoch: 6| Step: 9
Training loss: 2.3525943756103516
Validation loss: 2.114156018021286

Epoch: 6| Step: 10
Training loss: 2.797175645828247
Validation loss: 2.103403996395808

Epoch: 6| Step: 11
Training loss: 1.4619301557540894
Validation loss: 2.122532465124643

Epoch: 6| Step: 12
Training loss: 3.158108711242676
Validation loss: 2.1171847056317072

Epoch: 6| Step: 13
Training loss: 2.9885106086730957
Validation loss: 2.111315627251902

Epoch: 50| Step: 0
Training loss: 2.7399520874023438
Validation loss: 2.111648340379038

Epoch: 6| Step: 1
Training loss: 2.9709954261779785
Validation loss: 2.1084504742776193

Epoch: 6| Step: 2
Training loss: 2.3712403774261475
Validation loss: 2.1184991572492864

Epoch: 6| Step: 3
Training loss: 2.346585273742676
Validation loss: 2.106014223508937

Epoch: 6| Step: 4
Training loss: 2.471998929977417
Validation loss: 2.125241264220207

Epoch: 6| Step: 5
Training loss: 1.9086058139801025
Validation loss: 2.106771861353228

Epoch: 6| Step: 6
Training loss: 2.038541793823242
Validation loss: 2.1228168728531047

Epoch: 6| Step: 7
Training loss: 2.556546211242676
Validation loss: 2.126620625936857

Epoch: 6| Step: 8
Training loss: 1.9208106994628906
Validation loss: 2.152812119453184

Epoch: 6| Step: 9
Training loss: 2.471949577331543
Validation loss: 2.121936680168234

Epoch: 6| Step: 10
Training loss: 2.1024246215820312
Validation loss: 2.0945571673813688

Epoch: 6| Step: 11
Training loss: 1.5585286617279053
Validation loss: 2.137608153845674

Epoch: 6| Step: 12
Training loss: 2.570871114730835
Validation loss: 2.1163274421486804

Epoch: 6| Step: 13
Training loss: 3.0183725357055664
Validation loss: 2.1446252945930726

Epoch: 51| Step: 0
Training loss: 1.9534153938293457
Validation loss: 2.110959176094301

Epoch: 6| Step: 1
Training loss: 2.1453733444213867
Validation loss: 2.107256944461535

Epoch: 6| Step: 2
Training loss: 2.5234344005584717
Validation loss: 2.09361671632336

Epoch: 6| Step: 3
Training loss: 2.248586654663086
Validation loss: 2.117387899788477

Epoch: 6| Step: 4
Training loss: 2.3498191833496094
Validation loss: 2.0969137504536617

Epoch: 6| Step: 5
Training loss: 2.0430893898010254
Validation loss: 2.107622951589605

Epoch: 6| Step: 6
Training loss: 1.954620122909546
Validation loss: 2.0971732357496857

Epoch: 6| Step: 7
Training loss: 2.5311264991760254
Validation loss: 2.116455929253691

Epoch: 6| Step: 8
Training loss: 2.474532127380371
Validation loss: 2.119952122370402

Epoch: 6| Step: 9
Training loss: 2.3799076080322266
Validation loss: 2.103172175345882

Epoch: 6| Step: 10
Training loss: 2.663723945617676
Validation loss: 2.1263308704540296

Epoch: 6| Step: 11
Training loss: 2.375929832458496
Validation loss: 2.1117095421719294

Epoch: 6| Step: 12
Training loss: 2.1678054332733154
Validation loss: 2.1275060381940616

Epoch: 6| Step: 13
Training loss: 3.115713357925415
Validation loss: 2.1008278977486396

Epoch: 52| Step: 0
Training loss: 2.168555736541748
Validation loss: 2.119960295256748

Epoch: 6| Step: 1
Training loss: 2.730959415435791
Validation loss: 2.096220390771025

Epoch: 6| Step: 2
Training loss: 1.9441802501678467
Validation loss: 2.0935630618884997

Epoch: 6| Step: 3
Training loss: 2.761599063873291
Validation loss: 2.114372653345908

Epoch: 6| Step: 4
Training loss: 2.32478928565979
Validation loss: 2.114757260968608

Epoch: 6| Step: 5
Training loss: 3.235377073287964
Validation loss: 2.118440180696467

Epoch: 6| Step: 6
Training loss: 1.5874409675598145
Validation loss: 2.110482395336192

Epoch: 6| Step: 7
Training loss: 3.1681747436523438
Validation loss: 2.096599263529624

Epoch: 6| Step: 8
Training loss: 2.0089759826660156
Validation loss: 2.1154509769972933

Epoch: 6| Step: 9
Training loss: 2.1946568489074707
Validation loss: 2.1050430549088346

Epoch: 6| Step: 10
Training loss: 2.6659648418426514
Validation loss: 2.12430344089385

Epoch: 6| Step: 11
Training loss: 2.092257499694824
Validation loss: 2.111955914446103

Epoch: 6| Step: 12
Training loss: 1.8167762756347656
Validation loss: 2.125398087245162

Epoch: 6| Step: 13
Training loss: 1.4328608512878418
Validation loss: 2.12426318148131

Epoch: 53| Step: 0
Training loss: 1.937953233718872
Validation loss: 2.1064430590598815

Epoch: 6| Step: 1
Training loss: 2.2624964714050293
Validation loss: 2.101684654912641

Epoch: 6| Step: 2
Training loss: 2.099987030029297
Validation loss: 2.1156358334325973

Epoch: 6| Step: 3
Training loss: 2.4807240962982178
Validation loss: 2.115179133671586

Epoch: 6| Step: 4
Training loss: 2.1878042221069336
Validation loss: 2.11729875943994

Epoch: 6| Step: 5
Training loss: 2.468646764755249
Validation loss: 2.145909377323684

Epoch: 6| Step: 6
Training loss: 1.8500561714172363
Validation loss: 2.1251835438512985

Epoch: 6| Step: 7
Training loss: 2.523122787475586
Validation loss: 2.1155851092389835

Epoch: 6| Step: 8
Training loss: 2.6250929832458496
Validation loss: 2.1234703922784455

Epoch: 6| Step: 9
Training loss: 1.9323146343231201
Validation loss: 2.09052364800566

Epoch: 6| Step: 10
Training loss: 2.67092227935791
Validation loss: 2.108316816309447

Epoch: 6| Step: 11
Training loss: 2.7181236743927
Validation loss: 2.1149616113273044

Epoch: 6| Step: 12
Training loss: 1.9159340858459473
Validation loss: 2.118216130041307

Epoch: 6| Step: 13
Training loss: 3.0035197734832764
Validation loss: 2.143644286740211

Epoch: 54| Step: 0
Training loss: 2.153794050216675
Validation loss: 2.1065160689815396

Epoch: 6| Step: 1
Training loss: 1.5049140453338623
Validation loss: 2.141460867338283

Epoch: 6| Step: 2
Training loss: 2.9414591789245605
Validation loss: 2.119551422775433

Epoch: 6| Step: 3
Training loss: 1.99904203414917
Validation loss: 2.1157790717258247

Epoch: 6| Step: 4
Training loss: 1.9723479747772217
Validation loss: 2.1389856287228164

Epoch: 6| Step: 5
Training loss: 3.062098979949951
Validation loss: 2.1363379698927685

Epoch: 6| Step: 6
Training loss: 2.229884386062622
Validation loss: 2.1213554079814623

Epoch: 6| Step: 7
Training loss: 2.1632378101348877
Validation loss: 2.112468747682469

Epoch: 6| Step: 8
Training loss: 2.9112906455993652
Validation loss: 2.123717782317951

Epoch: 6| Step: 9
Training loss: 2.7624597549438477
Validation loss: 2.1134278940898117

Epoch: 6| Step: 10
Training loss: 2.205066442489624
Validation loss: 2.125504525758887

Epoch: 6| Step: 11
Training loss: 2.3247179985046387
Validation loss: 2.119028322158321

Epoch: 6| Step: 12
Training loss: 1.8461589813232422
Validation loss: 2.096732577969951

Epoch: 6| Step: 13
Training loss: 2.2725377082824707
Validation loss: 2.100671064469122

Epoch: 55| Step: 0
Training loss: 2.456866502761841
Validation loss: 2.123753224649737

Epoch: 6| Step: 1
Training loss: 2.567178726196289
Validation loss: 2.123726834533035

Epoch: 6| Step: 2
Training loss: 2.3081212043762207
Validation loss: 2.121554159349011

Epoch: 6| Step: 3
Training loss: 2.3269152641296387
Validation loss: 2.096961416223998

Epoch: 6| Step: 4
Training loss: 2.3484764099121094
Validation loss: 2.1167797119386735

Epoch: 6| Step: 5
Training loss: 2.1292402744293213
Validation loss: 2.088476343821454

Epoch: 6| Step: 6
Training loss: 1.5326672792434692
Validation loss: 2.130217044584213

Epoch: 6| Step: 7
Training loss: 2.561997652053833
Validation loss: 2.1216644497327906

Epoch: 6| Step: 8
Training loss: 2.6199116706848145
Validation loss: 2.1280531601239274

Epoch: 6| Step: 9
Training loss: 2.287062406539917
Validation loss: 2.1121055515863563

Epoch: 6| Step: 10
Training loss: 2.4372105598449707
Validation loss: 2.1216212934063328

Epoch: 6| Step: 11
Training loss: 1.9719873666763306
Validation loss: 2.117869231008714

Epoch: 6| Step: 12
Training loss: 2.346062183380127
Validation loss: 2.124673092237083

Epoch: 6| Step: 13
Training loss: 2.6615564823150635
Validation loss: 2.114450817467064

Epoch: 56| Step: 0
Training loss: 2.2890679836273193
Validation loss: 2.1404405665654007

Epoch: 6| Step: 1
Training loss: 1.8694899082183838
Validation loss: 2.133594270675413

Epoch: 6| Step: 2
Training loss: 2.4447972774505615
Validation loss: 2.1251413027445474

Epoch: 6| Step: 3
Training loss: 2.0279481410980225
Validation loss: 2.106222494955986

Epoch: 6| Step: 4
Training loss: 2.0722575187683105
Validation loss: 2.105215609714549

Epoch: 6| Step: 5
Training loss: 2.9419918060302734
Validation loss: 2.1392424824417278

Epoch: 6| Step: 6
Training loss: 2.850409746170044
Validation loss: 2.1346309902847453

Epoch: 6| Step: 7
Training loss: 1.5774366855621338
Validation loss: 2.1358805177032307

Epoch: 6| Step: 8
Training loss: 2.8864586353302
Validation loss: 2.1280562595654557

Epoch: 6| Step: 9
Training loss: 3.1065421104431152
Validation loss: 2.106432014896024

Epoch: 6| Step: 10
Training loss: 1.8233214616775513
Validation loss: 2.1495099093324397

Epoch: 6| Step: 11
Training loss: 2.395362377166748
Validation loss: 2.140068451563517

Epoch: 6| Step: 12
Training loss: 1.9943971633911133
Validation loss: 2.1250105134902464

Epoch: 6| Step: 13
Training loss: 2.123051643371582
Validation loss: 2.1458682321733042

Epoch: 57| Step: 0
Training loss: 2.4214463233947754
Validation loss: 2.138785400698262

Epoch: 6| Step: 1
Training loss: 2.2552497386932373
Validation loss: 2.115182251058599

Epoch: 6| Step: 2
Training loss: 2.484327554702759
Validation loss: 2.13461027350477

Epoch: 6| Step: 3
Training loss: 2.0223963260650635
Validation loss: 2.1280725784199213

Epoch: 6| Step: 4
Training loss: 2.7280113697052
Validation loss: 2.11552837587172

Epoch: 6| Step: 5
Training loss: 2.469548463821411
Validation loss: 2.1086594827713503

Epoch: 6| Step: 6
Training loss: 2.326261281967163
Validation loss: 2.1091101425950245

Epoch: 6| Step: 7
Training loss: 2.392144203186035
Validation loss: 2.12469877607079

Epoch: 6| Step: 8
Training loss: 2.0839908123016357
Validation loss: 2.1248195786629953

Epoch: 6| Step: 9
Training loss: 2.0762124061584473
Validation loss: 2.118060586273029

Epoch: 6| Step: 10
Training loss: 2.424985647201538
Validation loss: 2.1181626460885488

Epoch: 6| Step: 11
Training loss: 1.931240200996399
Validation loss: 2.082290682741391

Epoch: 6| Step: 12
Training loss: 2.539069652557373
Validation loss: 2.102552952304963

Epoch: 6| Step: 13
Training loss: 2.1853950023651123
Validation loss: 2.0967152657047397

Epoch: 58| Step: 0
Training loss: 2.27754282951355
Validation loss: 2.093716780344645

Epoch: 6| Step: 1
Training loss: 2.689013957977295
Validation loss: 2.0858386511443765

Epoch: 6| Step: 2
Training loss: 2.0217692852020264
Validation loss: 2.07571840798983

Epoch: 6| Step: 3
Training loss: 1.9615259170532227
Validation loss: 2.0881125901335027

Epoch: 6| Step: 4
Training loss: 2.6115660667419434
Validation loss: 2.125129279269967

Epoch: 6| Step: 5
Training loss: 2.275477409362793
Validation loss: 2.094483237112722

Epoch: 6| Step: 6
Training loss: 2.4751172065734863
Validation loss: 2.0960392118782125

Epoch: 6| Step: 7
Training loss: 2.229536294937134
Validation loss: 2.1021394473250195

Epoch: 6| Step: 8
Training loss: 2.4106192588806152
Validation loss: 2.1125518532209497

Epoch: 6| Step: 9
Training loss: 1.930091381072998
Validation loss: 2.1021031128462924

Epoch: 6| Step: 10
Training loss: 2.1164112091064453
Validation loss: 2.1033514417627805

Epoch: 6| Step: 11
Training loss: 2.306088924407959
Validation loss: 2.1009223435514714

Epoch: 6| Step: 12
Training loss: 2.4743828773498535
Validation loss: 2.115455509513937

Epoch: 6| Step: 13
Training loss: 2.5562705993652344
Validation loss: 2.1065912785068637

Epoch: 59| Step: 0
Training loss: 2.481863021850586
Validation loss: 2.10470332894274

Epoch: 6| Step: 1
Training loss: 1.6695129871368408
Validation loss: 2.0971376972813762

Epoch: 6| Step: 2
Training loss: 1.846503496170044
Validation loss: 2.1161074176911385

Epoch: 6| Step: 3
Training loss: 1.8872907161712646
Validation loss: 2.104258297592081

Epoch: 6| Step: 4
Training loss: 2.031820297241211
Validation loss: 2.1269868035470285

Epoch: 6| Step: 5
Training loss: 3.195173501968384
Validation loss: 2.0975166930947253

Epoch: 6| Step: 6
Training loss: 2.106151580810547
Validation loss: 2.1136952907808366

Epoch: 6| Step: 7
Training loss: 2.1190249919891357
Validation loss: 2.0947258498079036

Epoch: 6| Step: 8
Training loss: 2.7001607418060303
Validation loss: 2.0926280636941232

Epoch: 6| Step: 9
Training loss: 2.389705181121826
Validation loss: 2.087518822762274

Epoch: 6| Step: 10
Training loss: 2.416888475418091
Validation loss: 2.0903858959033923

Epoch: 6| Step: 11
Training loss: 2.1076607704162598
Validation loss: 2.1008769594213015

Epoch: 6| Step: 12
Training loss: 2.359144687652588
Validation loss: 2.1059502888751287

Epoch: 6| Step: 13
Training loss: 3.3631441593170166
Validation loss: 2.1020441157843477

Epoch: 60| Step: 0
Training loss: 3.416317939758301
Validation loss: 2.1131756613331456

Epoch: 6| Step: 1
Training loss: 2.500431537628174
Validation loss: 2.0951230679788897

Epoch: 6| Step: 2
Training loss: 2.4553685188293457
Validation loss: 2.1157191068895402

Epoch: 6| Step: 3
Training loss: 2.1606757640838623
Validation loss: 2.0970674304551977

Epoch: 6| Step: 4
Training loss: 2.465555429458618
Validation loss: 2.1013889453744374

Epoch: 6| Step: 5
Training loss: 2.076190233230591
Validation loss: 2.1156483132352113

Epoch: 6| Step: 6
Training loss: 2.5472145080566406
Validation loss: 2.1199939814946984

Epoch: 6| Step: 7
Training loss: 1.7282718420028687
Validation loss: 2.1143737864750687

Epoch: 6| Step: 8
Training loss: 2.007565975189209
Validation loss: 2.125965916982261

Epoch: 6| Step: 9
Training loss: 2.178023338317871
Validation loss: 2.131803507445961

Epoch: 6| Step: 10
Training loss: 2.3895654678344727
Validation loss: 2.132636764998077

Epoch: 6| Step: 11
Training loss: 2.2162282466888428
Validation loss: 2.0969206030650804

Epoch: 6| Step: 12
Training loss: 1.6839755773544312
Validation loss: 2.1213869997250137

Epoch: 6| Step: 13
Training loss: 2.2875118255615234
Validation loss: 2.1284942985862814

Epoch: 61| Step: 0
Training loss: 3.1259312629699707
Validation loss: 2.12251792928224

Epoch: 6| Step: 1
Training loss: 1.598408579826355
Validation loss: 2.109693370839601

Epoch: 6| Step: 2
Training loss: 2.660053253173828
Validation loss: 2.101374408250214

Epoch: 6| Step: 3
Training loss: 2.0568532943725586
Validation loss: 2.1488882418601745

Epoch: 6| Step: 4
Training loss: 2.3939452171325684
Validation loss: 2.1128319694149877

Epoch: 6| Step: 5
Training loss: 1.9222102165222168
Validation loss: 2.1099791321703183

Epoch: 6| Step: 6
Training loss: 2.0883734226226807
Validation loss: 2.089415688668528

Epoch: 6| Step: 7
Training loss: 2.771592855453491
Validation loss: 2.0838331163570447

Epoch: 6| Step: 8
Training loss: 2.8859455585479736
Validation loss: 2.1222047741695116

Epoch: 6| Step: 9
Training loss: 2.520099639892578
Validation loss: 2.102115378584913

Epoch: 6| Step: 10
Training loss: 2.011690616607666
Validation loss: 2.1054609385869836

Epoch: 6| Step: 11
Training loss: 2.219223976135254
Validation loss: 2.0896743420631654

Epoch: 6| Step: 12
Training loss: 1.903900384902954
Validation loss: 2.1124716215236212

Epoch: 6| Step: 13
Training loss: 2.1747303009033203
Validation loss: 2.1228357591936664

Epoch: 62| Step: 0
Training loss: 2.0354273319244385
Validation loss: 2.0930748549840783

Epoch: 6| Step: 1
Training loss: 1.546295166015625
Validation loss: 2.118536679975448

Epoch: 6| Step: 2
Training loss: 1.6943401098251343
Validation loss: 2.1046379112428233

Epoch: 6| Step: 3
Training loss: 1.881321907043457
Validation loss: 2.09784677849021

Epoch: 6| Step: 4
Training loss: 2.5881800651550293
Validation loss: 2.1132866977363505

Epoch: 6| Step: 5
Training loss: 3.2862956523895264
Validation loss: 2.105374309324449

Epoch: 6| Step: 6
Training loss: 2.301877498626709
Validation loss: 2.10843563079834

Epoch: 6| Step: 7
Training loss: 2.409052848815918
Validation loss: 2.1001412586499284

Epoch: 6| Step: 8
Training loss: 2.404766082763672
Validation loss: 2.113535160659462

Epoch: 6| Step: 9
Training loss: 2.230583667755127
Validation loss: 2.11394767351048

Epoch: 6| Step: 10
Training loss: 2.9593138694763184
Validation loss: 2.1068973541259766

Epoch: 6| Step: 11
Training loss: 2.695230484008789
Validation loss: 2.0966074133432038

Epoch: 6| Step: 12
Training loss: 1.8214625120162964
Validation loss: 2.112261938792403

Epoch: 6| Step: 13
Training loss: 2.657897472381592
Validation loss: 2.1144457735041136

Epoch: 63| Step: 0
Training loss: 1.5579851865768433
Validation loss: 2.1161105094417447

Epoch: 6| Step: 1
Training loss: 2.301297664642334
Validation loss: 2.0943973538696126

Epoch: 6| Step: 2
Training loss: 2.5522069931030273
Validation loss: 2.1013153842700425

Epoch: 6| Step: 3
Training loss: 2.242223024368286
Validation loss: 2.1105561128226658

Epoch: 6| Step: 4
Training loss: 2.9929258823394775
Validation loss: 2.1167630200744956

Epoch: 6| Step: 5
Training loss: 2.4574689865112305
Validation loss: 2.099567110820483

Epoch: 6| Step: 6
Training loss: 1.8076577186584473
Validation loss: 2.1684815973363896

Epoch: 6| Step: 7
Training loss: 2.2681221961975098
Validation loss: 2.1321392751509145

Epoch: 6| Step: 8
Training loss: 2.396538734436035
Validation loss: 2.1249555439077397

Epoch: 6| Step: 9
Training loss: 2.3243203163146973
Validation loss: 2.1120001193015807

Epoch: 6| Step: 10
Training loss: 2.2108242511749268
Validation loss: 2.137371274732774

Epoch: 6| Step: 11
Training loss: 2.6909525394439697
Validation loss: 2.1189436925354825

Epoch: 6| Step: 12
Training loss: 1.4074923992156982
Validation loss: 2.127713364939536

Epoch: 6| Step: 13
Training loss: 3.3878226280212402
Validation loss: 2.1120893237411336

Epoch: 64| Step: 0
Training loss: 3.2834596633911133
Validation loss: 2.1166755204559653

Epoch: 6| Step: 1
Training loss: 2.4257326126098633
Validation loss: 2.1357114033032487

Epoch: 6| Step: 2
Training loss: 2.0733842849731445
Validation loss: 2.1308890670858402

Epoch: 6| Step: 3
Training loss: 1.8069729804992676
Validation loss: 2.111546254927112

Epoch: 6| Step: 4
Training loss: 1.636269211769104
Validation loss: 2.1210599586527836

Epoch: 6| Step: 5
Training loss: 2.702944040298462
Validation loss: 2.112861620482578

Epoch: 6| Step: 6
Training loss: 1.8992698192596436
Validation loss: 2.138816600204796

Epoch: 6| Step: 7
Training loss: 2.4426162242889404
Validation loss: 2.1276321231677966

Epoch: 6| Step: 8
Training loss: 2.6145410537719727
Validation loss: 2.1153949717039704

Epoch: 6| Step: 9
Training loss: 2.103181838989258
Validation loss: 2.1265044955797094

Epoch: 6| Step: 10
Training loss: 1.8739778995513916
Validation loss: 2.1037295736292356

Epoch: 6| Step: 11
Training loss: 2.5441665649414062
Validation loss: 2.1055499379352858

Epoch: 6| Step: 12
Training loss: 2.0526204109191895
Validation loss: 2.0929755010912494

Epoch: 6| Step: 13
Training loss: 2.945500373840332
Validation loss: 2.1164134612647434

Epoch: 65| Step: 0
Training loss: 2.086763858795166
Validation loss: 2.0925834666016283

Epoch: 6| Step: 1
Training loss: 2.256176710128784
Validation loss: 2.1143023583196823

Epoch: 6| Step: 2
Training loss: 2.745556116104126
Validation loss: 2.0846615965648363

Epoch: 6| Step: 3
Training loss: 2.0153393745422363
Validation loss: 2.0950078887324177

Epoch: 6| Step: 4
Training loss: 2.7678492069244385
Validation loss: 2.1148065700325915

Epoch: 6| Step: 5
Training loss: 3.289823532104492
Validation loss: 2.0978561396239908

Epoch: 6| Step: 6
Training loss: 2.026571750640869
Validation loss: 2.09647883138349

Epoch: 6| Step: 7
Training loss: 2.2832303047180176
Validation loss: 2.1133395010425198

Epoch: 6| Step: 8
Training loss: 1.7603923082351685
Validation loss: 2.1173314484216834

Epoch: 6| Step: 9
Training loss: 2.1310770511627197
Validation loss: 2.1030775987973778

Epoch: 6| Step: 10
Training loss: 1.7910490036010742
Validation loss: 2.098285190520748

Epoch: 6| Step: 11
Training loss: 1.930537462234497
Validation loss: 2.1032858945990123

Epoch: 6| Step: 12
Training loss: 2.4038913249969482
Validation loss: 2.111490181697312

Epoch: 6| Step: 13
Training loss: 2.528162717819214
Validation loss: 2.0981126857060257

Epoch: 66| Step: 0
Training loss: 1.8091470003128052
Validation loss: 2.126147577839513

Epoch: 6| Step: 1
Training loss: 2.525771141052246
Validation loss: 2.103077639815628

Epoch: 6| Step: 2
Training loss: 2.696535110473633
Validation loss: 2.0940899323391657

Epoch: 6| Step: 3
Training loss: 2.082625389099121
Validation loss: 2.119454158249722

Epoch: 6| Step: 4
Training loss: 2.2762253284454346
Validation loss: 2.1318613726605653

Epoch: 6| Step: 5
Training loss: 1.598570466041565
Validation loss: 2.130883865458991

Epoch: 6| Step: 6
Training loss: 2.347809076309204
Validation loss: 2.0797824910891953

Epoch: 6| Step: 7
Training loss: 2.414219617843628
Validation loss: 2.077606466508681

Epoch: 6| Step: 8
Training loss: 1.8671188354492188
Validation loss: 2.1146793762842813

Epoch: 6| Step: 9
Training loss: 2.571631908416748
Validation loss: 2.0994485552592943

Epoch: 6| Step: 10
Training loss: 1.9832292795181274
Validation loss: 2.1217534926629837

Epoch: 6| Step: 11
Training loss: 2.1528279781341553
Validation loss: 2.1140811315146824

Epoch: 6| Step: 12
Training loss: 3.1092467308044434
Validation loss: 2.111398248262303

Epoch: 6| Step: 13
Training loss: 2.694394826889038
Validation loss: 2.115333769911079

Epoch: 67| Step: 0
Training loss: 2.694492816925049
Validation loss: 2.123801931258171

Epoch: 6| Step: 1
Training loss: 2.430436134338379
Validation loss: 2.106040467498123

Epoch: 6| Step: 2
Training loss: 2.004404067993164
Validation loss: 2.1068841129220943

Epoch: 6| Step: 3
Training loss: 1.9205385446548462
Validation loss: 2.1262141504595355

Epoch: 6| Step: 4
Training loss: 1.8160018920898438
Validation loss: 2.1168989212282243

Epoch: 6| Step: 5
Training loss: 2.6036829948425293
Validation loss: 2.145491248817854

Epoch: 6| Step: 6
Training loss: 2.5183286666870117
Validation loss: 2.1355199378023864

Epoch: 6| Step: 7
Training loss: 2.726468324661255
Validation loss: 2.1212834568433863

Epoch: 6| Step: 8
Training loss: 1.9953583478927612
Validation loss: 2.1288741275828373

Epoch: 6| Step: 9
Training loss: 1.9048186540603638
Validation loss: 2.107783877721397

Epoch: 6| Step: 10
Training loss: 2.258211612701416
Validation loss: 2.113229195276896

Epoch: 6| Step: 11
Training loss: 2.1992695331573486
Validation loss: 2.112123086888303

Epoch: 6| Step: 12
Training loss: 2.5835120677948
Validation loss: 2.130892721555566

Epoch: 6| Step: 13
Training loss: 2.1075899600982666
Validation loss: 2.0994699949859292

Epoch: 68| Step: 0
Training loss: 2.2968053817749023
Validation loss: 2.104373085883356

Epoch: 6| Step: 1
Training loss: 1.6359189748764038
Validation loss: 2.140635557072137

Epoch: 6| Step: 2
Training loss: 2.815865993499756
Validation loss: 2.1315473997464744

Epoch: 6| Step: 3
Training loss: 1.6970347166061401
Validation loss: 2.1323370523350214

Epoch: 6| Step: 4
Training loss: 2.4518065452575684
Validation loss: 2.1167236963907876

Epoch: 6| Step: 5
Training loss: 2.0877933502197266
Validation loss: 2.132962598595568

Epoch: 6| Step: 6
Training loss: 2.606692314147949
Validation loss: 2.1133850107910814

Epoch: 6| Step: 7
Training loss: 1.8971794843673706
Validation loss: 2.1128961014491257

Epoch: 6| Step: 8
Training loss: 2.1138107776641846
Validation loss: 2.1192201106779036

Epoch: 6| Step: 9
Training loss: 2.2771236896514893
Validation loss: 2.118960781763959

Epoch: 6| Step: 10
Training loss: 2.2131152153015137
Validation loss: 2.0971259288890387

Epoch: 6| Step: 11
Training loss: 2.862245798110962
Validation loss: 2.109220020232662

Epoch: 6| Step: 12
Training loss: 2.009284496307373
Validation loss: 2.1245303948720298

Epoch: 6| Step: 13
Training loss: 3.5530502796173096
Validation loss: 2.1188502311706543

Epoch: 69| Step: 0
Training loss: 2.077043056488037
Validation loss: 2.107766851302116

Epoch: 6| Step: 1
Training loss: 1.669968843460083
Validation loss: 2.134828549559398

Epoch: 6| Step: 2
Training loss: 2.1993613243103027
Validation loss: 2.0877856977524294

Epoch: 6| Step: 3
Training loss: 2.1756739616394043
Validation loss: 2.107575111491706

Epoch: 6| Step: 4
Training loss: 3.0168464183807373
Validation loss: 2.1284082269155853

Epoch: 6| Step: 5
Training loss: 2.4904518127441406
Validation loss: 2.1095262137792443

Epoch: 6| Step: 6
Training loss: 2.3165011405944824
Validation loss: 2.1216362471221597

Epoch: 6| Step: 7
Training loss: 1.5889452695846558
Validation loss: 2.1146500251626454

Epoch: 6| Step: 8
Training loss: 2.0102005004882812
Validation loss: 2.107516598957841

Epoch: 6| Step: 9
Training loss: 2.2335922718048096
Validation loss: 2.1393349734685754

Epoch: 6| Step: 10
Training loss: 1.93369722366333
Validation loss: 2.1196037184807563

Epoch: 6| Step: 11
Training loss: 2.4714767932891846
Validation loss: 2.113244810412007

Epoch: 6| Step: 12
Training loss: 3.48354434967041
Validation loss: 2.1220006788930585

Epoch: 6| Step: 13
Training loss: 2.089219331741333
Validation loss: 2.1173306998386177

Epoch: 70| Step: 0
Training loss: 1.9457740783691406
Validation loss: 2.1185830485436226

Epoch: 6| Step: 1
Training loss: 2.316000461578369
Validation loss: 2.108822238060736

Epoch: 6| Step: 2
Training loss: 2.31834077835083
Validation loss: 2.1021485405583538

Epoch: 6| Step: 3
Training loss: 2.2146430015563965
Validation loss: 2.1334010567716373

Epoch: 6| Step: 4
Training loss: 2.600940704345703
Validation loss: 2.1434620067637455

Epoch: 6| Step: 5
Training loss: 2.409672737121582
Validation loss: 2.1256068893658218

Epoch: 6| Step: 6
Training loss: 2.2946724891662598
Validation loss: 2.12498814059842

Epoch: 6| Step: 7
Training loss: 2.188450336456299
Validation loss: 2.12361228722398

Epoch: 6| Step: 8
Training loss: 1.9080942869186401
Validation loss: 2.1488928923042874

Epoch: 6| Step: 9
Training loss: 2.2708983421325684
Validation loss: 2.1306948379803727

Epoch: 6| Step: 10
Training loss: 2.0200986862182617
Validation loss: 2.1521664434863674

Epoch: 6| Step: 11
Training loss: 1.5780267715454102
Validation loss: 2.1360886020045124

Epoch: 6| Step: 12
Training loss: 2.711509943008423
Validation loss: 2.1175090318085044

Epoch: 6| Step: 13
Training loss: 3.682103157043457
Validation loss: 2.131108094287175

Epoch: 71| Step: 0
Training loss: 2.600886583328247
Validation loss: 2.1011609544036207

Epoch: 6| Step: 1
Training loss: 2.0650103092193604
Validation loss: 2.098759525565691

Epoch: 6| Step: 2
Training loss: 2.443770408630371
Validation loss: 2.1358413298924765

Epoch: 6| Step: 3
Training loss: 2.272857427597046
Validation loss: 2.124667682955342

Epoch: 6| Step: 4
Training loss: 2.6595935821533203
Validation loss: 2.1218838896802676

Epoch: 6| Step: 5
Training loss: 1.8708751201629639
Validation loss: 2.1382191437546925

Epoch: 6| Step: 6
Training loss: 1.8396342992782593
Validation loss: 2.1144926445458525

Epoch: 6| Step: 7
Training loss: 2.0494823455810547
Validation loss: 2.1044114635836695

Epoch: 6| Step: 8
Training loss: 1.8338439464569092
Validation loss: 2.0923882799763835

Epoch: 6| Step: 9
Training loss: 1.8996235132217407
Validation loss: 2.1372571452971427

Epoch: 6| Step: 10
Training loss: 2.204256296157837
Validation loss: 2.106452597084866

Epoch: 6| Step: 11
Training loss: 3.2414779663085938
Validation loss: 2.106183127690387

Epoch: 6| Step: 12
Training loss: 2.6472620964050293
Validation loss: 2.1296888730859243

Epoch: 6| Step: 13
Training loss: 2.2271711826324463
Validation loss: 2.1025036304227767

Epoch: 72| Step: 0
Training loss: 1.9419586658477783
Validation loss: 2.1170340712352465

Epoch: 6| Step: 1
Training loss: 1.703884243965149
Validation loss: 2.109516910327378

Epoch: 6| Step: 2
Training loss: 2.759383201599121
Validation loss: 2.131012498691518

Epoch: 6| Step: 3
Training loss: 2.4193646907806396
Validation loss: 2.121203091836745

Epoch: 6| Step: 4
Training loss: 2.5607943534851074
Validation loss: 2.136819886904891

Epoch: 6| Step: 5
Training loss: 1.9931836128234863
Validation loss: 2.103962452180924

Epoch: 6| Step: 6
Training loss: 2.848069190979004
Validation loss: 2.1122309725771666

Epoch: 6| Step: 7
Training loss: 2.419325351715088
Validation loss: 2.118664194178838

Epoch: 6| Step: 8
Training loss: 1.7834396362304688
Validation loss: 2.1301479647236485

Epoch: 6| Step: 9
Training loss: 2.2934465408325195
Validation loss: 2.1040330189530567

Epoch: 6| Step: 10
Training loss: 2.2907896041870117
Validation loss: 2.1130199458009455

Epoch: 6| Step: 11
Training loss: 1.5831260681152344
Validation loss: 2.1146785008010043

Epoch: 6| Step: 12
Training loss: 2.7554564476013184
Validation loss: 2.125087312472764

Epoch: 6| Step: 13
Training loss: 2.783541679382324
Validation loss: 2.1331884066263833

Epoch: 73| Step: 0
Training loss: 2.068772315979004
Validation loss: 2.121365234416018

Epoch: 6| Step: 1
Training loss: 1.5847489833831787
Validation loss: 2.1310081405024373

Epoch: 6| Step: 2
Training loss: 2.241640567779541
Validation loss: 2.1466397726407616

Epoch: 6| Step: 3
Training loss: 2.7134456634521484
Validation loss: 2.109848209606704

Epoch: 6| Step: 4
Training loss: 1.9963772296905518
Validation loss: 2.1260334035401702

Epoch: 6| Step: 5
Training loss: 2.3559699058532715
Validation loss: 2.13673597510143

Epoch: 6| Step: 6
Training loss: 1.953608751296997
Validation loss: 2.1223480137445594

Epoch: 6| Step: 7
Training loss: 2.876674175262451
Validation loss: 2.12125797681911

Epoch: 6| Step: 8
Training loss: 1.8314019441604614
Validation loss: 2.1282910018838863

Epoch: 6| Step: 9
Training loss: 2.3070735931396484
Validation loss: 2.1351716390220066

Epoch: 6| Step: 10
Training loss: 2.4487929344177246
Validation loss: 2.117682949189217

Epoch: 6| Step: 11
Training loss: 2.381772994995117
Validation loss: 2.13699613078948

Epoch: 6| Step: 12
Training loss: 2.5809121131896973
Validation loss: 2.1125398784555416

Epoch: 6| Step: 13
Training loss: 2.480565071105957
Validation loss: 2.1279424698122087

Epoch: 74| Step: 0
Training loss: 2.3549513816833496
Validation loss: 2.111447803435787

Epoch: 6| Step: 1
Training loss: 2.0434534549713135
Validation loss: 2.1319924195607505

Epoch: 6| Step: 2
Training loss: 2.0962443351745605
Validation loss: 2.128349788727299

Epoch: 6| Step: 3
Training loss: 2.5706801414489746
Validation loss: 2.1349603463244695

Epoch: 6| Step: 4
Training loss: 2.284208297729492
Validation loss: 2.1319536624416227

Epoch: 6| Step: 5
Training loss: 2.454892158508301
Validation loss: 2.1287483528096187

Epoch: 6| Step: 6
Training loss: 2.442626476287842
Validation loss: 2.1184839612694195

Epoch: 6| Step: 7
Training loss: 1.962594747543335
Validation loss: 2.1213833003915767

Epoch: 6| Step: 8
Training loss: 2.79241943359375
Validation loss: 2.0991372600678475

Epoch: 6| Step: 9
Training loss: 2.1540403366088867
Validation loss: 2.138623877238202

Epoch: 6| Step: 10
Training loss: 2.2805795669555664
Validation loss: 2.107262985680693

Epoch: 6| Step: 11
Training loss: 1.733971118927002
Validation loss: 2.117914386974868

Epoch: 6| Step: 12
Training loss: 2.1138622760772705
Validation loss: 2.12792065066676

Epoch: 6| Step: 13
Training loss: 2.5429036617279053
Validation loss: 2.1264263122312483

Epoch: 75| Step: 0
Training loss: 1.5699450969696045
Validation loss: 2.1234055437067503

Epoch: 6| Step: 1
Training loss: 2.131985664367676
Validation loss: 2.127649825106385

Epoch: 6| Step: 2
Training loss: 2.5596845149993896
Validation loss: 2.09517409980938

Epoch: 6| Step: 3
Training loss: 2.502687454223633
Validation loss: 2.1340208925226682

Epoch: 6| Step: 4
Training loss: 2.6226773262023926
Validation loss: 2.1491106364034835

Epoch: 6| Step: 5
Training loss: 2.811143398284912
Validation loss: 2.1153913287706274

Epoch: 6| Step: 6
Training loss: 2.1842682361602783
Validation loss: 2.134704533443656

Epoch: 6| Step: 7
Training loss: 1.9887452125549316
Validation loss: 2.114535559890091

Epoch: 6| Step: 8
Training loss: 1.870191216468811
Validation loss: 2.1363628602796987

Epoch: 6| Step: 9
Training loss: 2.070955276489258
Validation loss: 2.117373961274342

Epoch: 6| Step: 10
Training loss: 2.7388100624084473
Validation loss: 2.1173731614184637

Epoch: 6| Step: 11
Training loss: 1.9326740503311157
Validation loss: 2.1425365722307594

Epoch: 6| Step: 12
Training loss: 2.2527554035186768
Validation loss: 2.1340542941965084

Epoch: 6| Step: 13
Training loss: 2.6657354831695557
Validation loss: 2.116201223865632

Epoch: 76| Step: 0
Training loss: 3.3226490020751953
Validation loss: 2.125088176419658

Epoch: 6| Step: 1
Training loss: 2.9369075298309326
Validation loss: 2.1169053803208056

Epoch: 6| Step: 2
Training loss: 2.043997287750244
Validation loss: 2.115834782200475

Epoch: 6| Step: 3
Training loss: 2.402247667312622
Validation loss: 2.1384554678393948

Epoch: 6| Step: 4
Training loss: 1.9502863883972168
Validation loss: 2.1059318075897875

Epoch: 6| Step: 5
Training loss: 2.5417914390563965
Validation loss: 2.146927664356847

Epoch: 6| Step: 6
Training loss: 2.9602012634277344
Validation loss: 2.1580998589915614

Epoch: 6| Step: 7
Training loss: 2.1568026542663574
Validation loss: 2.1772559714573685

Epoch: 6| Step: 8
Training loss: 2.1028716564178467
Validation loss: 2.1359348348391953

Epoch: 6| Step: 9
Training loss: 1.1089850664138794
Validation loss: 2.150520404179891

Epoch: 6| Step: 10
Training loss: 2.5512731075286865
Validation loss: 2.152355001818749

Epoch: 6| Step: 11
Training loss: 1.6444549560546875
Validation loss: 2.1552164349504697

Epoch: 6| Step: 12
Training loss: 2.044499158859253
Validation loss: 2.142929130984891

Epoch: 6| Step: 13
Training loss: 1.682482123374939
Validation loss: 2.1542182455780687

Epoch: 77| Step: 0
Training loss: 2.8934662342071533
Validation loss: 2.1354562108234694

Epoch: 6| Step: 1
Training loss: 1.2642742395401
Validation loss: 2.1410408571202266

Epoch: 6| Step: 2
Training loss: 2.326467990875244
Validation loss: 2.1390602293834893

Epoch: 6| Step: 3
Training loss: 2.643105983734131
Validation loss: 2.1070977500689927

Epoch: 6| Step: 4
Training loss: 1.7126271724700928
Validation loss: 2.1112380630226544

Epoch: 6| Step: 5
Training loss: 2.119797945022583
Validation loss: 2.129962387905326

Epoch: 6| Step: 6
Training loss: 2.1009132862091064
Validation loss: 2.093051856563937

Epoch: 6| Step: 7
Training loss: 2.3845252990722656
Validation loss: 2.1254940109868206

Epoch: 6| Step: 8
Training loss: 2.8110432624816895
Validation loss: 2.100485796569496

Epoch: 6| Step: 9
Training loss: 2.4883527755737305
Validation loss: 2.1159903528869792

Epoch: 6| Step: 10
Training loss: 1.7273670434951782
Validation loss: 2.0896597139296995

Epoch: 6| Step: 11
Training loss: 2.3012688159942627
Validation loss: 2.1194600469322613

Epoch: 6| Step: 12
Training loss: 2.286243200302124
Validation loss: 2.104835187235186

Epoch: 6| Step: 13
Training loss: 2.789379119873047
Validation loss: 2.0927684230189167

Epoch: 78| Step: 0
Training loss: 2.342674732208252
Validation loss: 2.120185036813059

Epoch: 6| Step: 1
Training loss: 1.3664395809173584
Validation loss: 2.101547020737843

Epoch: 6| Step: 2
Training loss: 2.5961830615997314
Validation loss: 2.120324091244769

Epoch: 6| Step: 3
Training loss: 2.2963368892669678
Validation loss: 2.100616462769047

Epoch: 6| Step: 4
Training loss: 2.461028575897217
Validation loss: 2.1025139721491004

Epoch: 6| Step: 5
Training loss: 1.911592721939087
Validation loss: 2.1008850810348347

Epoch: 6| Step: 6
Training loss: 2.3127059936523438
Validation loss: 2.086360211013466

Epoch: 6| Step: 7
Training loss: 2.2188303470611572
Validation loss: 2.086062119853112

Epoch: 6| Step: 8
Training loss: 1.975138783454895
Validation loss: 2.1134833135912494

Epoch: 6| Step: 9
Training loss: 2.4544076919555664
Validation loss: 2.1067221792795325

Epoch: 6| Step: 10
Training loss: 2.7916107177734375
Validation loss: 2.086744693017775

Epoch: 6| Step: 11
Training loss: 2.2613024711608887
Validation loss: 2.1040021732289302

Epoch: 6| Step: 12
Training loss: 2.7429251670837402
Validation loss: 2.0886412115507227

Epoch: 6| Step: 13
Training loss: 1.4286608695983887
Validation loss: 2.0971564118580153

Epoch: 79| Step: 0
Training loss: 1.5159143209457397
Validation loss: 2.1023251254071473

Epoch: 6| Step: 1
Training loss: 2.154614210128784
Validation loss: 2.107344397934534

Epoch: 6| Step: 2
Training loss: 2.1409566402435303
Validation loss: 2.119350589731688

Epoch: 6| Step: 3
Training loss: 2.6452383995056152
Validation loss: 2.1328711727614045

Epoch: 6| Step: 4
Training loss: 2.02280330657959
Validation loss: 2.1373476482206777

Epoch: 6| Step: 5
Training loss: 2.5168657302856445
Validation loss: 2.124587553803639

Epoch: 6| Step: 6
Training loss: 2.4557137489318848
Validation loss: 2.118305852336268

Epoch: 6| Step: 7
Training loss: 2.3028199672698975
Validation loss: 2.1337492747973372

Epoch: 6| Step: 8
Training loss: 1.4834916591644287
Validation loss: 2.100539981677968

Epoch: 6| Step: 9
Training loss: 2.514148235321045
Validation loss: 2.11680269241333

Epoch: 6| Step: 10
Training loss: 2.7317607402801514
Validation loss: 2.098043228990288

Epoch: 6| Step: 11
Training loss: 2.000070810317993
Validation loss: 2.119336292307864

Epoch: 6| Step: 12
Training loss: 2.357297420501709
Validation loss: 2.1356132722670034

Epoch: 6| Step: 13
Training loss: 2.825115919113159
Validation loss: 2.119304795419016

Epoch: 80| Step: 0
Training loss: 2.5571975708007812
Validation loss: 2.1263853631993777

Epoch: 6| Step: 1
Training loss: 2.379988431930542
Validation loss: 2.117695471291901

Epoch: 6| Step: 2
Training loss: 2.5826539993286133
Validation loss: 2.1334562763091056

Epoch: 6| Step: 3
Training loss: 1.752176284790039
Validation loss: 2.1154954958987493

Epoch: 6| Step: 4
Training loss: 2.318469524383545
Validation loss: 2.1030200040468605

Epoch: 6| Step: 5
Training loss: 2.025330066680908
Validation loss: 2.125077796238725

Epoch: 6| Step: 6
Training loss: 1.7661763429641724
Validation loss: 2.1291711509868665

Epoch: 6| Step: 7
Training loss: 2.3337955474853516
Validation loss: 2.114627351043045

Epoch: 6| Step: 8
Training loss: 2.044123649597168
Validation loss: 2.1116433835798696

Epoch: 6| Step: 9
Training loss: 2.6184263229370117
Validation loss: 2.1138576615241265

Epoch: 6| Step: 10
Training loss: 2.0194365978240967
Validation loss: 2.1272711869209044

Epoch: 6| Step: 11
Training loss: 1.9598944187164307
Validation loss: 2.122038613083542

Epoch: 6| Step: 12
Training loss: 2.586182117462158
Validation loss: 2.115697568462741

Epoch: 6| Step: 13
Training loss: 2.473686933517456
Validation loss: 2.130210191972794

Epoch: 81| Step: 0
Training loss: 2.9610695838928223
Validation loss: 2.1155496015343616

Epoch: 6| Step: 1
Training loss: 2.0851826667785645
Validation loss: 2.12389660778866

Epoch: 6| Step: 2
Training loss: 2.043111801147461
Validation loss: 2.1286161227892806

Epoch: 6| Step: 3
Training loss: 2.1375722885131836
Validation loss: 2.121170529755213

Epoch: 6| Step: 4
Training loss: 2.483595371246338
Validation loss: 2.1472725663133847

Epoch: 6| Step: 5
Training loss: 2.2695348262786865
Validation loss: 2.104625166103404

Epoch: 6| Step: 6
Training loss: 2.5692484378814697
Validation loss: 2.104497125071864

Epoch: 6| Step: 7
Training loss: 1.972078800201416
Validation loss: 2.09201317961498

Epoch: 6| Step: 8
Training loss: 2.3901162147521973
Validation loss: 2.120197944743659

Epoch: 6| Step: 9
Training loss: 2.2249579429626465
Validation loss: 2.099230691950808

Epoch: 6| Step: 10
Training loss: 2.0803616046905518
Validation loss: 2.1376619787626367

Epoch: 6| Step: 11
Training loss: 2.168057918548584
Validation loss: 2.121427345019515

Epoch: 6| Step: 12
Training loss: 1.9513704776763916
Validation loss: 2.1360774270949827

Epoch: 6| Step: 13
Training loss: 1.7864956855773926
Validation loss: 2.1095489096897904

Epoch: 82| Step: 0
Training loss: 2.093390464782715
Validation loss: 2.127304107912125

Epoch: 6| Step: 1
Training loss: 3.0145103931427
Validation loss: 2.110739883556161

Epoch: 6| Step: 2
Training loss: 2.108114719390869
Validation loss: 2.1010295511573873

Epoch: 6| Step: 3
Training loss: 1.878483533859253
Validation loss: 2.118533900988999

Epoch: 6| Step: 4
Training loss: 2.4875738620758057
Validation loss: 2.1134519243753083

Epoch: 6| Step: 5
Training loss: 2.513820171356201
Validation loss: 2.1330616576697237

Epoch: 6| Step: 6
Training loss: 2.4580676555633545
Validation loss: 2.097932687369726

Epoch: 6| Step: 7
Training loss: 1.9401416778564453
Validation loss: 2.1349451131718133

Epoch: 6| Step: 8
Training loss: 1.9288424253463745
Validation loss: 2.103311418205179

Epoch: 6| Step: 9
Training loss: 2.0215232372283936
Validation loss: 2.1177908835872525

Epoch: 6| Step: 10
Training loss: 2.350356101989746
Validation loss: 2.1187021219602196

Epoch: 6| Step: 11
Training loss: 2.105630397796631
Validation loss: 2.121121656510138

Epoch: 6| Step: 12
Training loss: 2.3536386489868164
Validation loss: 2.112340660505397

Epoch: 6| Step: 13
Training loss: 1.8116683959960938
Validation loss: 2.106111059906662

Epoch: 83| Step: 0
Training loss: 2.708240032196045
Validation loss: 2.108778504915135

Epoch: 6| Step: 1
Training loss: 2.063617706298828
Validation loss: 2.1206472637832805

Epoch: 6| Step: 2
Training loss: 2.5590648651123047
Validation loss: 2.1142509803977063

Epoch: 6| Step: 3
Training loss: 2.427666664123535
Validation loss: 2.1088939866712018

Epoch: 6| Step: 4
Training loss: 1.9319761991500854
Validation loss: 2.1180131999395226

Epoch: 6| Step: 5
Training loss: 1.6637952327728271
Validation loss: 2.11735967154144

Epoch: 6| Step: 6
Training loss: 2.219357490539551
Validation loss: 2.1151296374618367

Epoch: 6| Step: 7
Training loss: 2.6461939811706543
Validation loss: 2.131328830154993

Epoch: 6| Step: 8
Training loss: 1.6246585845947266
Validation loss: 2.114770309899443

Epoch: 6| Step: 9
Training loss: 2.879971742630005
Validation loss: 2.1221854340645576

Epoch: 6| Step: 10
Training loss: 2.3097686767578125
Validation loss: 2.127757533904045

Epoch: 6| Step: 11
Training loss: 2.2077136039733887
Validation loss: 2.118799163449195

Epoch: 6| Step: 12
Training loss: 2.049490213394165
Validation loss: 2.1275160376743605

Epoch: 6| Step: 13
Training loss: 1.6049145460128784
Validation loss: 2.1389114113264185

Epoch: 84| Step: 0
Training loss: 2.467562675476074
Validation loss: 2.123362361743886

Epoch: 6| Step: 1
Training loss: 2.4733810424804688
Validation loss: 2.118904285533454

Epoch: 6| Step: 2
Training loss: 1.8350210189819336
Validation loss: 2.136056684678601

Epoch: 6| Step: 3
Training loss: 2.684382915496826
Validation loss: 2.129316932411604

Epoch: 6| Step: 4
Training loss: 1.7607395648956299
Validation loss: 2.1220025016415502

Epoch: 6| Step: 5
Training loss: 2.7169346809387207
Validation loss: 2.1319351324471096

Epoch: 6| Step: 6
Training loss: 1.574301838874817
Validation loss: 2.1073331679067304

Epoch: 6| Step: 7
Training loss: 2.203186511993408
Validation loss: 2.143400405042915

Epoch: 6| Step: 8
Training loss: 2.8498830795288086
Validation loss: 2.131583657315982

Epoch: 6| Step: 9
Training loss: 1.9170989990234375
Validation loss: 2.1297770136146137

Epoch: 6| Step: 10
Training loss: 2.034762144088745
Validation loss: 2.1088679862278763

Epoch: 6| Step: 11
Training loss: 2.0810866355895996
Validation loss: 2.095373576687228

Epoch: 6| Step: 12
Training loss: 2.502337694168091
Validation loss: 2.1099196031529415

Epoch: 6| Step: 13
Training loss: 2.2089364528656006
Validation loss: 2.103165620116777

Epoch: 85| Step: 0
Training loss: 2.3435568809509277
Validation loss: 2.1292407961301905

Epoch: 6| Step: 1
Training loss: 2.5516510009765625
Validation loss: 2.1313394577272478

Epoch: 6| Step: 2
Training loss: 1.941352128982544
Validation loss: 2.1585071035610732

Epoch: 6| Step: 3
Training loss: 1.915689468383789
Validation loss: 2.1141501088296213

Epoch: 6| Step: 4
Training loss: 2.080045461654663
Validation loss: 2.1145811644933556

Epoch: 6| Step: 5
Training loss: 2.0248429775238037
Validation loss: 2.1534108051689724

Epoch: 6| Step: 6
Training loss: 1.974324107170105
Validation loss: 2.112528318999916

Epoch: 6| Step: 7
Training loss: 2.719722270965576
Validation loss: 2.1180838487481557

Epoch: 6| Step: 8
Training loss: 2.032289981842041
Validation loss: 2.0977808185802993

Epoch: 6| Step: 9
Training loss: 2.817002296447754
Validation loss: 2.149449543286395

Epoch: 6| Step: 10
Training loss: 2.0725502967834473
Validation loss: 2.1123608055935112

Epoch: 6| Step: 11
Training loss: 2.0130786895751953
Validation loss: 2.1504481697595246

Epoch: 6| Step: 12
Training loss: 2.610466480255127
Validation loss: 2.124619701857208

Epoch: 6| Step: 13
Training loss: 2.1214799880981445
Validation loss: 2.1324094110919583

Epoch: 86| Step: 0
Training loss: 1.858877182006836
Validation loss: 2.117029277227258

Epoch: 6| Step: 1
Training loss: 2.181476593017578
Validation loss: 2.108829008635654

Epoch: 6| Step: 2
Training loss: 2.0693209171295166
Validation loss: 2.1285771272515737

Epoch: 6| Step: 3
Training loss: 1.5886361598968506
Validation loss: 2.1013553129729403

Epoch: 6| Step: 4
Training loss: 2.910806894302368
Validation loss: 2.111102791242702

Epoch: 6| Step: 5
Training loss: 2.637418270111084
Validation loss: 2.134533005376016

Epoch: 6| Step: 6
Training loss: 2.7129015922546387
Validation loss: 2.1343172288710073

Epoch: 6| Step: 7
Training loss: 2.1998472213745117
Validation loss: 2.1357126030870663

Epoch: 6| Step: 8
Training loss: 1.663548469543457
Validation loss: 2.1178983898573023

Epoch: 6| Step: 9
Training loss: 2.209554672241211
Validation loss: 2.1190108919656403

Epoch: 6| Step: 10
Training loss: 1.3211443424224854
Validation loss: 2.1344153624708935

Epoch: 6| Step: 11
Training loss: 2.7187283039093018
Validation loss: 2.114186474072036

Epoch: 6| Step: 12
Training loss: 2.6794443130493164
Validation loss: 2.145337140688332

Epoch: 6| Step: 13
Training loss: 2.6989448070526123
Validation loss: 2.115505225555871

Epoch: 87| Step: 0
Training loss: 2.8396365642547607
Validation loss: 2.135696870024486

Epoch: 6| Step: 1
Training loss: 1.3235225677490234
Validation loss: 2.1055144289488434

Epoch: 6| Step: 2
Training loss: 1.4452152252197266
Validation loss: 2.1147403999041487

Epoch: 6| Step: 3
Training loss: 2.767122745513916
Validation loss: 2.123681124820504

Epoch: 6| Step: 4
Training loss: 2.3270864486694336
Validation loss: 2.123243634418775

Epoch: 6| Step: 5
Training loss: 2.1564388275146484
Validation loss: 2.1232238046584593

Epoch: 6| Step: 6
Training loss: 2.0682644844055176
Validation loss: 2.139663819343813

Epoch: 6| Step: 7
Training loss: 2.3345751762390137
Validation loss: 2.1346189052827897

Epoch: 6| Step: 8
Training loss: 3.1018755435943604
Validation loss: 2.1216603325259302

Epoch: 6| Step: 9
Training loss: 1.8890149593353271
Validation loss: 2.114513720235517

Epoch: 6| Step: 10
Training loss: 3.046055793762207
Validation loss: 2.1327728597066735

Epoch: 6| Step: 11
Training loss: 1.9920251369476318
Validation loss: 2.1193063374488585

Epoch: 6| Step: 12
Training loss: 1.8548903465270996
Validation loss: 2.0945549934141097

Epoch: 6| Step: 13
Training loss: 1.7134252786636353
Validation loss: 2.120567625568759

Epoch: 88| Step: 0
Training loss: 2.1940200328826904
Validation loss: 2.1226353594051894

Epoch: 6| Step: 1
Training loss: 1.7713422775268555
Validation loss: 2.091522870525237

Epoch: 6| Step: 2
Training loss: 1.8113332986831665
Validation loss: 2.136923484904792

Epoch: 6| Step: 3
Training loss: 2.146251916885376
Validation loss: 2.105905848164712

Epoch: 6| Step: 4
Training loss: 2.0346779823303223
Validation loss: 2.1282459843543267

Epoch: 6| Step: 5
Training loss: 1.98820960521698
Validation loss: 2.113740897947742

Epoch: 6| Step: 6
Training loss: 2.897488594055176
Validation loss: 2.122981475245568

Epoch: 6| Step: 7
Training loss: 2.216331958770752
Validation loss: 2.1271849627135904

Epoch: 6| Step: 8
Training loss: 1.7218103408813477
Validation loss: 2.10431182512673

Epoch: 6| Step: 9
Training loss: 2.093672275543213
Validation loss: 2.1369903856708157

Epoch: 6| Step: 10
Training loss: 2.4395499229431152
Validation loss: 2.1088122962623514

Epoch: 6| Step: 11
Training loss: 3.1263842582702637
Validation loss: 2.1178210243102042

Epoch: 6| Step: 12
Training loss: 2.363102912902832
Validation loss: 2.095864131886472

Epoch: 6| Step: 13
Training loss: 2.6309125423431396
Validation loss: 2.1252596532144854

Epoch: 89| Step: 0
Training loss: 2.097529888153076
Validation loss: 2.1145113437406478

Epoch: 6| Step: 1
Training loss: 1.7058278322219849
Validation loss: 2.1192750546240036

Epoch: 6| Step: 2
Training loss: 2.7618777751922607
Validation loss: 2.111424312796644

Epoch: 6| Step: 3
Training loss: 2.115184783935547
Validation loss: 2.1087701448830227

Epoch: 6| Step: 4
Training loss: 2.2306361198425293
Validation loss: 2.121761615558337

Epoch: 6| Step: 5
Training loss: 2.612663745880127
Validation loss: 2.1105777832769577

Epoch: 6| Step: 6
Training loss: 2.061735153198242
Validation loss: 2.133478567164431

Epoch: 6| Step: 7
Training loss: 1.980430245399475
Validation loss: 2.1142495088679816

Epoch: 6| Step: 8
Training loss: 2.1617431640625
Validation loss: 2.1280148926601616

Epoch: 6| Step: 9
Training loss: 1.967607021331787
Validation loss: 2.117475326343249

Epoch: 6| Step: 10
Training loss: 2.603679656982422
Validation loss: 2.1227949050164994

Epoch: 6| Step: 11
Training loss: 2.198906421661377
Validation loss: 2.104272081005958

Epoch: 6| Step: 12
Training loss: 2.3443050384521484
Validation loss: 2.137329652745237

Epoch: 6| Step: 13
Training loss: 2.0313949584960938
Validation loss: 2.106233408374171

Epoch: 90| Step: 0
Training loss: 2.484123945236206
Validation loss: 2.1252415692934425

Epoch: 6| Step: 1
Training loss: 1.5817804336547852
Validation loss: 2.0978907154452417

Epoch: 6| Step: 2
Training loss: 2.7020645141601562
Validation loss: 2.1116504105188514

Epoch: 6| Step: 3
Training loss: 2.850148916244507
Validation loss: 2.113074569291966

Epoch: 6| Step: 4
Training loss: 2.028773546218872
Validation loss: 2.103440021955839

Epoch: 6| Step: 5
Training loss: 1.724353313446045
Validation loss: 2.1148932249315324

Epoch: 6| Step: 6
Training loss: 2.887988328933716
Validation loss: 2.099666528804328

Epoch: 6| Step: 7
Training loss: 1.910317301750183
Validation loss: 2.1108390169758953

Epoch: 6| Step: 8
Training loss: 2.4233593940734863
Validation loss: 2.097011007288451

Epoch: 6| Step: 9
Training loss: 2.078805923461914
Validation loss: 2.104182961166546

Epoch: 6| Step: 10
Training loss: 2.2178192138671875
Validation loss: 2.11361446175524

Epoch: 6| Step: 11
Training loss: 1.8125089406967163
Validation loss: 2.1057439670767835

Epoch: 6| Step: 12
Training loss: 2.0533671379089355
Validation loss: 2.071270958069832

Epoch: 6| Step: 13
Training loss: 2.060173273086548
Validation loss: 2.1300116662056214

Epoch: 91| Step: 0
Training loss: 2.0283594131469727
Validation loss: 2.1130053202311196

Epoch: 6| Step: 1
Training loss: 2.4966413974761963
Validation loss: 2.118237054476174

Epoch: 6| Step: 2
Training loss: 1.8612316846847534
Validation loss: 2.1171306948507986

Epoch: 6| Step: 3
Training loss: 2.08294939994812
Validation loss: 2.1027946831077657

Epoch: 6| Step: 4
Training loss: 2.947185516357422
Validation loss: 2.1126351228324314

Epoch: 6| Step: 5
Training loss: 2.780306100845337
Validation loss: 2.1072809004014537

Epoch: 6| Step: 6
Training loss: 2.2293601036071777
Validation loss: 2.0916085999499083

Epoch: 6| Step: 7
Training loss: 2.4268593788146973
Validation loss: 2.135183862460557

Epoch: 6| Step: 8
Training loss: 2.1156482696533203
Validation loss: 2.09091507234881

Epoch: 6| Step: 9
Training loss: 2.080376148223877
Validation loss: 2.129849908172443

Epoch: 6| Step: 10
Training loss: 1.2551908493041992
Validation loss: 2.1066787319798626

Epoch: 6| Step: 11
Training loss: 2.133730411529541
Validation loss: 2.129277111381613

Epoch: 6| Step: 12
Training loss: 2.491960048675537
Validation loss: 2.0852306196766515

Epoch: 6| Step: 13
Training loss: 2.015946626663208
Validation loss: 2.1099623185332104

Epoch: 92| Step: 0
Training loss: 2.273101568222046
Validation loss: 2.1072836832333635

Epoch: 6| Step: 1
Training loss: 1.7865183353424072
Validation loss: 2.1155663664622972

Epoch: 6| Step: 2
Training loss: 2.6484246253967285
Validation loss: 2.1080859861066266

Epoch: 6| Step: 3
Training loss: 1.748168706893921
Validation loss: 2.1063600099214943

Epoch: 6| Step: 4
Training loss: 2.7732126712799072
Validation loss: 2.135049812255367

Epoch: 6| Step: 5
Training loss: 2.238170862197876
Validation loss: 2.1457595056103123

Epoch: 6| Step: 6
Training loss: 1.8802679777145386
Validation loss: 2.121008680712792

Epoch: 6| Step: 7
Training loss: 2.428333282470703
Validation loss: 2.128498340165743

Epoch: 6| Step: 8
Training loss: 2.285635471343994
Validation loss: 2.1232807469624344

Epoch: 6| Step: 9
Training loss: 2.821288585662842
Validation loss: 2.1124245851270613

Epoch: 6| Step: 10
Training loss: 2.0066609382629395
Validation loss: 2.107542132818571

Epoch: 6| Step: 11
Training loss: 1.5613436698913574
Validation loss: 2.125065429236299

Epoch: 6| Step: 12
Training loss: 1.9617791175842285
Validation loss: 2.1230946561341644

Epoch: 6| Step: 13
Training loss: 2.945570707321167
Validation loss: 2.099306598786385

Epoch: 93| Step: 0
Training loss: 2.5233917236328125
Validation loss: 2.114585866210281

Epoch: 6| Step: 1
Training loss: 3.152921199798584
Validation loss: 2.1204656298442552

Epoch: 6| Step: 2
Training loss: 1.9907371997833252
Validation loss: 2.1057049612845145

Epoch: 6| Step: 3
Training loss: 1.544288158416748
Validation loss: 2.1084711936212357

Epoch: 6| Step: 4
Training loss: 2.4822258949279785
Validation loss: 2.135561402126025

Epoch: 6| Step: 5
Training loss: 3.100532054901123
Validation loss: 2.0971012474388204

Epoch: 6| Step: 6
Training loss: 2.440566301345825
Validation loss: 2.116606121422142

Epoch: 6| Step: 7
Training loss: 1.7870140075683594
Validation loss: 2.1149824678256945

Epoch: 6| Step: 8
Training loss: 2.3450889587402344
Validation loss: 2.123573112231429

Epoch: 6| Step: 9
Training loss: 2.1471943855285645
Validation loss: 2.1295951976571033

Epoch: 6| Step: 10
Training loss: 1.8893179893493652
Validation loss: 2.1098728231204453

Epoch: 6| Step: 11
Training loss: 1.7244466543197632
Validation loss: 2.1032372854089223

Epoch: 6| Step: 12
Training loss: 1.763371467590332
Validation loss: 2.096496133394139

Epoch: 6| Step: 13
Training loss: 1.9740701913833618
Validation loss: 2.1345229353955997

Epoch: 94| Step: 0
Training loss: 2.03410005569458
Validation loss: 2.1245050596934494

Epoch: 6| Step: 1
Training loss: 1.8607072830200195
Validation loss: 2.117359783059807

Epoch: 6| Step: 2
Training loss: 1.4828054904937744
Validation loss: 2.0786864808810654

Epoch: 6| Step: 3
Training loss: 1.9545702934265137
Validation loss: 2.1234588264137186

Epoch: 6| Step: 4
Training loss: 2.272775411605835
Validation loss: 2.096801104084138

Epoch: 6| Step: 5
Training loss: 1.9141807556152344
Validation loss: 2.140817347393241

Epoch: 6| Step: 6
Training loss: 2.6829543113708496
Validation loss: 2.113871045010064

Epoch: 6| Step: 7
Training loss: 2.494198799133301
Validation loss: 2.0910966998787335

Epoch: 6| Step: 8
Training loss: 2.4860641956329346
Validation loss: 2.1161945891636673

Epoch: 6| Step: 9
Training loss: 2.7306969165802
Validation loss: 2.1109706483861452

Epoch: 6| Step: 10
Training loss: 1.7992358207702637
Validation loss: 2.107906779935283

Epoch: 6| Step: 11
Training loss: 2.918809652328491
Validation loss: 2.0938099686817457

Epoch: 6| Step: 12
Training loss: 2.0292301177978516
Validation loss: 2.11396453713858

Epoch: 6| Step: 13
Training loss: 2.3220536708831787
Validation loss: 2.1257655082210416

Epoch: 95| Step: 0
Training loss: 2.7249908447265625
Validation loss: 2.1230589779474403

Epoch: 6| Step: 1
Training loss: 2.229280948638916
Validation loss: 2.1314784660134265

Epoch: 6| Step: 2
Training loss: 2.916132926940918
Validation loss: 2.1227996067334245

Epoch: 6| Step: 3
Training loss: 2.0443572998046875
Validation loss: 2.109906724704209

Epoch: 6| Step: 4
Training loss: 1.5575225353240967
Validation loss: 2.1073877401249383

Epoch: 6| Step: 5
Training loss: 2.502314805984497
Validation loss: 2.1141510445584535

Epoch: 6| Step: 6
Training loss: 1.940495252609253
Validation loss: 2.1228747316586074

Epoch: 6| Step: 7
Training loss: 2.1170053482055664
Validation loss: 2.091298444296724

Epoch: 6| Step: 8
Training loss: 1.6198511123657227
Validation loss: 2.0997537233496226

Epoch: 6| Step: 9
Training loss: 2.288182258605957
Validation loss: 2.095635493596395

Epoch: 6| Step: 10
Training loss: 2.5460104942321777
Validation loss: 2.1117387651115336

Epoch: 6| Step: 11
Training loss: 2.2844111919403076
Validation loss: 2.0960126307702835

Epoch: 6| Step: 12
Training loss: 1.487209677696228
Validation loss: 2.1234116169714157

Epoch: 6| Step: 13
Training loss: 2.6301591396331787
Validation loss: 2.1099932321938137

Epoch: 96| Step: 0
Training loss: 2.2911996841430664
Validation loss: 2.1137556722087245

Epoch: 6| Step: 1
Training loss: 2.833195924758911
Validation loss: 2.119238192035306

Epoch: 6| Step: 2
Training loss: 2.1313271522521973
Validation loss: 2.1037533103778796

Epoch: 6| Step: 3
Training loss: 2.7414605617523193
Validation loss: 2.1130394307515954

Epoch: 6| Step: 4
Training loss: 1.5527030229568481
Validation loss: 2.119924774733923

Epoch: 6| Step: 5
Training loss: 3.011821746826172
Validation loss: 2.1003030807741228

Epoch: 6| Step: 6
Training loss: 1.456105351448059
Validation loss: 2.126485450293428

Epoch: 6| Step: 7
Training loss: 1.5444377660751343
Validation loss: 2.109195036272849

Epoch: 6| Step: 8
Training loss: 2.2004001140594482
Validation loss: 2.1229017626854683

Epoch: 6| Step: 9
Training loss: 1.6796963214874268
Validation loss: 2.09518503373669

Epoch: 6| Step: 10
Training loss: 2.104816436767578
Validation loss: 2.1191021755177486

Epoch: 6| Step: 11
Training loss: 2.4899253845214844
Validation loss: 2.084783895041353

Epoch: 6| Step: 12
Training loss: 2.426949977874756
Validation loss: 2.10302383412597

Epoch: 6| Step: 13
Training loss: 2.6586225032806396
Validation loss: 2.1194486900042464

Epoch: 97| Step: 0
Training loss: 2.470961809158325
Validation loss: 2.0934198184679915

Epoch: 6| Step: 1
Training loss: 2.4200353622436523
Validation loss: 2.123298930865462

Epoch: 6| Step: 2
Training loss: 1.8158302307128906
Validation loss: 2.1125428881696475

Epoch: 6| Step: 3
Training loss: 2.0392038822174072
Validation loss: 2.1218519595361527

Epoch: 6| Step: 4
Training loss: 1.9733843803405762
Validation loss: 2.129938848557011

Epoch: 6| Step: 5
Training loss: 2.134915590286255
Validation loss: 2.129146993801158

Epoch: 6| Step: 6
Training loss: 1.5938150882720947
Validation loss: 2.11940247525451

Epoch: 6| Step: 7
Training loss: 2.1909019947052
Validation loss: 2.1299402226683912

Epoch: 6| Step: 8
Training loss: 2.0003228187561035
Validation loss: 2.1159934843740156

Epoch: 6| Step: 9
Training loss: 2.492002487182617
Validation loss: 2.1027942229342718

Epoch: 6| Step: 10
Training loss: 3.014035224914551
Validation loss: 2.112327719247469

Epoch: 6| Step: 11
Training loss: 1.760132908821106
Validation loss: 2.1027108828226724

Epoch: 6| Step: 12
Training loss: 2.4080874919891357
Validation loss: 2.111678572111232

Epoch: 6| Step: 13
Training loss: 2.463736057281494
Validation loss: 2.122721654112621

Epoch: 98| Step: 0
Training loss: 2.1628105640411377
Validation loss: 2.103976764986592

Epoch: 6| Step: 1
Training loss: 2.251479387283325
Validation loss: 2.12312481223896

Epoch: 6| Step: 2
Training loss: 2.1746227741241455
Validation loss: 2.0881471967184417

Epoch: 6| Step: 3
Training loss: 2.5201258659362793
Validation loss: 2.1278393704404115

Epoch: 6| Step: 4
Training loss: 1.7339746952056885
Validation loss: 2.1227017371885237

Epoch: 6| Step: 5
Training loss: 2.0493807792663574
Validation loss: 2.1169334970494753

Epoch: 6| Step: 6
Training loss: 1.9271082878112793
Validation loss: 2.1386509069832425

Epoch: 6| Step: 7
Training loss: 1.6831672191619873
Validation loss: 2.1119598675799627

Epoch: 6| Step: 8
Training loss: 2.9157297611236572
Validation loss: 2.128906447400329

Epoch: 6| Step: 9
Training loss: 2.2294816970825195
Validation loss: 2.102682361038782

Epoch: 6| Step: 10
Training loss: 2.789020538330078
Validation loss: 2.1162973014257287

Epoch: 6| Step: 11
Training loss: 2.233096122741699
Validation loss: 2.09879486022457

Epoch: 6| Step: 12
Training loss: 1.9274200201034546
Validation loss: 2.1335037754428003

Epoch: 6| Step: 13
Training loss: 1.8709375858306885
Validation loss: 2.143998053766066

Epoch: 99| Step: 0
Training loss: 2.509709358215332
Validation loss: 2.135293545261506

Epoch: 6| Step: 1
Training loss: 1.9424352645874023
Validation loss: 2.1136012397786623

Epoch: 6| Step: 2
Training loss: 1.4772310256958008
Validation loss: 2.12196062585359

Epoch: 6| Step: 3
Training loss: 1.5714199542999268
Validation loss: 2.1401988203807543

Epoch: 6| Step: 4
Training loss: 2.052227020263672
Validation loss: 2.134528854841827

Epoch: 6| Step: 5
Training loss: 3.5635011196136475
Validation loss: 2.141378806483361

Epoch: 6| Step: 6
Training loss: 2.590695381164551
Validation loss: 2.1449626209915325

Epoch: 6| Step: 7
Training loss: 2.5333166122436523
Validation loss: 2.109061228331699

Epoch: 6| Step: 8
Training loss: 1.453080415725708
Validation loss: 2.1297513848991803

Epoch: 6| Step: 9
Training loss: 2.2404913902282715
Validation loss: 2.1028827082726265

Epoch: 6| Step: 10
Training loss: 2.037405490875244
Validation loss: 2.121416425192228

Epoch: 6| Step: 11
Training loss: 2.4353113174438477
Validation loss: 2.109243377562492

Epoch: 6| Step: 12
Training loss: 2.5877420902252197
Validation loss: 2.1178274308481524

Epoch: 6| Step: 13
Training loss: 1.68281090259552
Validation loss: 2.118281190113355

Epoch: 100| Step: 0
Training loss: 1.9137049913406372
Validation loss: 2.1393385625654653

Epoch: 6| Step: 1
Training loss: 2.011298656463623
Validation loss: 2.117299049131332

Epoch: 6| Step: 2
Training loss: 1.7481367588043213
Validation loss: 2.108281502159693

Epoch: 6| Step: 3
Training loss: 2.227363109588623
Validation loss: 2.1397287666156726

Epoch: 6| Step: 4
Training loss: 2.190216064453125
Validation loss: 2.142002590240971

Epoch: 6| Step: 5
Training loss: 2.757762908935547
Validation loss: 2.1231111429070912

Epoch: 6| Step: 6
Training loss: 2.106271743774414
Validation loss: 2.127971754279188

Epoch: 6| Step: 7
Training loss: 1.8708078861236572
Validation loss: 2.1370316038849535

Epoch: 6| Step: 8
Training loss: 2.017591953277588
Validation loss: 2.1207849184672036

Epoch: 6| Step: 9
Training loss: 2.666207790374756
Validation loss: 2.1530364431360716

Epoch: 6| Step: 10
Training loss: 2.3632497787475586
Validation loss: 2.1182513442090762

Epoch: 6| Step: 11
Training loss: 2.3337502479553223
Validation loss: 2.1025666011277067

Epoch: 6| Step: 12
Training loss: 2.1478593349456787
Validation loss: 2.1159790254408315

Epoch: 6| Step: 13
Training loss: 2.474323272705078
Validation loss: 2.1260441298125894

Epoch: 101| Step: 0
Training loss: 2.409701347351074
Validation loss: 2.1109033053921116

Epoch: 6| Step: 1
Training loss: 2.7109663486480713
Validation loss: 2.1222143429581837

Epoch: 6| Step: 2
Training loss: 2.2433972358703613
Validation loss: 2.1123811429546726

Epoch: 6| Step: 3
Training loss: 2.086030960083008
Validation loss: 2.1209248958095426

Epoch: 6| Step: 4
Training loss: 2.5355913639068604
Validation loss: 2.1199048975462556

Epoch: 6| Step: 5
Training loss: 1.945096492767334
Validation loss: 2.136051283087782

Epoch: 6| Step: 6
Training loss: 2.0834760665893555
Validation loss: 2.1212037763287945

Epoch: 6| Step: 7
Training loss: 2.236833333969116
Validation loss: 2.150827319391312

Epoch: 6| Step: 8
Training loss: 2.560570240020752
Validation loss: 2.1509516944167433

Epoch: 6| Step: 9
Training loss: 1.669172763824463
Validation loss: 2.121656381955711

Epoch: 6| Step: 10
Training loss: 2.1127848625183105
Validation loss: 2.1267996475260746

Epoch: 6| Step: 11
Training loss: 1.955822467803955
Validation loss: 2.124557348989671

Epoch: 6| Step: 12
Training loss: 2.1247973442077637
Validation loss: 2.106433883790047

Epoch: 6| Step: 13
Training loss: 1.710959792137146
Validation loss: 2.097293943487188

Epoch: 102| Step: 0
Training loss: 2.0906119346618652
Validation loss: 2.1259621830396753

Epoch: 6| Step: 1
Training loss: 2.0768938064575195
Validation loss: 2.1188328778871925

Epoch: 6| Step: 2
Training loss: 2.6047234535217285
Validation loss: 2.1325644113684215

Epoch: 6| Step: 3
Training loss: 2.071594476699829
Validation loss: 2.1083123299383346

Epoch: 6| Step: 4
Training loss: 2.5548300743103027
Validation loss: 2.1401956863300775

Epoch: 6| Step: 5
Training loss: 1.8183083534240723
Validation loss: 2.131674151266775

Epoch: 6| Step: 6
Training loss: 1.7916629314422607
Validation loss: 2.1086122720472273

Epoch: 6| Step: 7
Training loss: 2.342341184616089
Validation loss: 2.126417144652336

Epoch: 6| Step: 8
Training loss: 3.284367084503174
Validation loss: 2.1007116251094367

Epoch: 6| Step: 9
Training loss: 1.715946912765503
Validation loss: 2.1059121098569644

Epoch: 6| Step: 10
Training loss: 1.9520061016082764
Validation loss: 2.1219679258202993

Epoch: 6| Step: 11
Training loss: 1.8279050588607788
Validation loss: 2.1110968359055056

Epoch: 6| Step: 12
Training loss: 2.1650161743164062
Validation loss: 2.11821932946482

Epoch: 6| Step: 13
Training loss: 2.5788965225219727
Validation loss: 2.120597367645592

Epoch: 103| Step: 0
Training loss: 1.7825669050216675
Validation loss: 2.1400635139916533

Epoch: 6| Step: 1
Training loss: 2.016211748123169
Validation loss: 2.114197284944596

Epoch: 6| Step: 2
Training loss: 1.7413413524627686
Validation loss: 2.09396223099001

Epoch: 6| Step: 3
Training loss: 2.0694077014923096
Validation loss: 2.136115348467263

Epoch: 6| Step: 4
Training loss: 1.9333670139312744
Validation loss: 2.102442741394043

Epoch: 6| Step: 5
Training loss: 2.9053351879119873
Validation loss: 2.1145055793946788

Epoch: 6| Step: 6
Training loss: 2.387129306793213
Validation loss: 2.133496089648175

Epoch: 6| Step: 7
Training loss: 2.3508143424987793
Validation loss: 2.144024520791987

Epoch: 6| Step: 8
Training loss: 2.0717873573303223
Validation loss: 2.10840658603176

Epoch: 6| Step: 9
Training loss: 2.6292293071746826
Validation loss: 2.1421878363496516

Epoch: 6| Step: 10
Training loss: 1.6462477445602417
Validation loss: 2.0990221628578762

Epoch: 6| Step: 11
Training loss: 3.0158774852752686
Validation loss: 2.1354633761990454

Epoch: 6| Step: 12
Training loss: 1.7676641941070557
Validation loss: 2.1396278450565953

Epoch: 6| Step: 13
Training loss: 2.2054905891418457
Validation loss: 2.1149160477422897

Epoch: 104| Step: 0
Training loss: 2.3030436038970947
Validation loss: 2.08335986445027

Epoch: 6| Step: 1
Training loss: 2.4753808975219727
Validation loss: 2.1391904277186238

Epoch: 6| Step: 2
Training loss: 2.3555891513824463
Validation loss: 2.1068812929173952

Epoch: 6| Step: 3
Training loss: 1.690279245376587
Validation loss: 2.143644371340352

Epoch: 6| Step: 4
Training loss: 1.9094284772872925
Validation loss: 2.1524439498942387

Epoch: 6| Step: 5
Training loss: 2.0371251106262207
Validation loss: 2.1328969950317056

Epoch: 6| Step: 6
Training loss: 2.346137523651123
Validation loss: 2.150538615001145

Epoch: 6| Step: 7
Training loss: 2.2239632606506348
Validation loss: 2.1632276811907367

Epoch: 6| Step: 8
Training loss: 2.648540496826172
Validation loss: 2.1210556773729223

Epoch: 6| Step: 9
Training loss: 1.7892167568206787
Validation loss: 2.123227095091215

Epoch: 6| Step: 10
Training loss: 2.334425449371338
Validation loss: 2.1387036564529582

Epoch: 6| Step: 11
Training loss: 1.4427825212478638
Validation loss: 2.1291530798840266

Epoch: 6| Step: 12
Training loss: 2.400688886642456
Validation loss: 2.105376466628044

Epoch: 6| Step: 13
Training loss: 3.396050453186035
Validation loss: 2.0984889204784105

Epoch: 105| Step: 0
Training loss: 2.15777587890625
Validation loss: 2.120517817876672

Epoch: 6| Step: 1
Training loss: 1.6171269416809082
Validation loss: 2.125089330057944

Epoch: 6| Step: 2
Training loss: 3.0830979347229004
Validation loss: 2.161584396516123

Epoch: 6| Step: 3
Training loss: 2.1487889289855957
Validation loss: 2.1135708337189048

Epoch: 6| Step: 4
Training loss: 2.494508743286133
Validation loss: 2.1231869882152927

Epoch: 6| Step: 5
Training loss: 1.8724713325500488
Validation loss: 2.118539705071398

Epoch: 6| Step: 6
Training loss: 1.7207798957824707
Validation loss: 2.12438936515521

Epoch: 6| Step: 7
Training loss: 2.3969173431396484
Validation loss: 2.1231637744493383

Epoch: 6| Step: 8
Training loss: 1.6763336658477783
Validation loss: 2.1202068469857656

Epoch: 6| Step: 9
Training loss: 2.4571805000305176
Validation loss: 2.129764631230344

Epoch: 6| Step: 10
Training loss: 1.8522738218307495
Validation loss: 2.1046062925810456

Epoch: 6| Step: 11
Training loss: 2.0545780658721924
Validation loss: 2.1306316365477858

Epoch: 6| Step: 12
Training loss: 2.249018430709839
Validation loss: 2.1226037292070288

Epoch: 6| Step: 13
Training loss: 2.8922080993652344
Validation loss: 2.131013601056991

Epoch: 106| Step: 0
Training loss: 1.7158222198486328
Validation loss: 2.11815829430857

Epoch: 6| Step: 1
Training loss: 2.0502493381500244
Validation loss: 2.120558677181121

Epoch: 6| Step: 2
Training loss: 1.9543088674545288
Validation loss: 2.1082636182026198

Epoch: 6| Step: 3
Training loss: 2.6189732551574707
Validation loss: 2.118019337295204

Epoch: 6| Step: 4
Training loss: 2.1196813583374023
Validation loss: 2.1337668613720964

Epoch: 6| Step: 5
Training loss: 2.1872100830078125
Validation loss: 2.1207979276616085

Epoch: 6| Step: 6
Training loss: 2.741647243499756
Validation loss: 2.1126118859937115

Epoch: 6| Step: 7
Training loss: 2.5281481742858887
Validation loss: 2.106905432157619

Epoch: 6| Step: 8
Training loss: 2.564847230911255
Validation loss: 2.1319562440277426

Epoch: 6| Step: 9
Training loss: 1.5212126970291138
Validation loss: 2.1456308454595585

Epoch: 6| Step: 10
Training loss: 1.920408010482788
Validation loss: 2.122927837474372

Epoch: 6| Step: 11
Training loss: 2.3813817501068115
Validation loss: 2.114595854154197

Epoch: 6| Step: 12
Training loss: 2.2898664474487305
Validation loss: 2.1435457301396195

Epoch: 6| Step: 13
Training loss: 1.5698083639144897
Validation loss: 2.1377751365784676

Epoch: 107| Step: 0
Training loss: 1.8269751071929932
Validation loss: 2.1071839127489316

Epoch: 6| Step: 1
Training loss: 1.7146008014678955
Validation loss: 2.095232830252699

Epoch: 6| Step: 2
Training loss: 1.6826905012130737
Validation loss: 2.087840857044343

Epoch: 6| Step: 3
Training loss: 1.8426628112792969
Validation loss: 2.1211839158047914

Epoch: 6| Step: 4
Training loss: 1.82421875
Validation loss: 2.0880096266346593

Epoch: 6| Step: 5
Training loss: 2.2331507205963135
Validation loss: 2.1037223146807764

Epoch: 6| Step: 6
Training loss: 3.303281784057617
Validation loss: 2.107598384221395

Epoch: 6| Step: 7
Training loss: 2.2820544242858887
Validation loss: 2.0949118162996028

Epoch: 6| Step: 8
Training loss: 2.506840705871582
Validation loss: 2.1212556259606474

Epoch: 6| Step: 9
Training loss: 2.192627191543579
Validation loss: 2.0941925125737346

Epoch: 6| Step: 10
Training loss: 2.32163143157959
Validation loss: 2.12542397873376

Epoch: 6| Step: 11
Training loss: 2.25532865524292
Validation loss: 2.1221885822152577

Epoch: 6| Step: 12
Training loss: 2.5502805709838867
Validation loss: 2.1492453493097776

Epoch: 6| Step: 13
Training loss: 1.6722469329833984
Validation loss: 2.128184054487495

Epoch: 108| Step: 0
Training loss: 2.8469998836517334
Validation loss: 2.1175111416847474

Epoch: 6| Step: 1
Training loss: 2.6837549209594727
Validation loss: 2.1191735318911973

Epoch: 6| Step: 2
Training loss: 1.7940781116485596
Validation loss: 2.1283013384829284

Epoch: 6| Step: 3
Training loss: 1.986096978187561
Validation loss: 2.126288019200807

Epoch: 6| Step: 4
Training loss: 2.160409927368164
Validation loss: 2.1111752640816475

Epoch: 6| Step: 5
Training loss: 2.4474191665649414
Validation loss: 2.1012221869601997

Epoch: 6| Step: 6
Training loss: 1.3247909545898438
Validation loss: 2.0834574789129277

Epoch: 6| Step: 7
Training loss: 3.0628294944763184
Validation loss: 2.103348196193736

Epoch: 6| Step: 8
Training loss: 2.010226249694824
Validation loss: 2.101214663956755

Epoch: 6| Step: 9
Training loss: 2.3130524158477783
Validation loss: 2.091725098189487

Epoch: 6| Step: 10
Training loss: 1.4644739627838135
Validation loss: 2.109212516456522

Epoch: 6| Step: 11
Training loss: 1.9017993211746216
Validation loss: 2.0888122614993843

Epoch: 6| Step: 12
Training loss: 2.3105578422546387
Validation loss: 2.0827056643783406

Epoch: 6| Step: 13
Training loss: 2.1775035858154297
Validation loss: 2.088825243775563

Epoch: 109| Step: 0
Training loss: 2.153550148010254
Validation loss: 2.1258600450331167

Epoch: 6| Step: 1
Training loss: 2.282839298248291
Validation loss: 2.1137982722251647

Epoch: 6| Step: 2
Training loss: 2.0551443099975586
Validation loss: 2.1012176993072673

Epoch: 6| Step: 3
Training loss: 2.531493663787842
Validation loss: 2.0812979423871605

Epoch: 6| Step: 4
Training loss: 2.560804843902588
Validation loss: 2.1095735116671492

Epoch: 6| Step: 5
Training loss: 1.578765630722046
Validation loss: 2.1082246406103975

Epoch: 6| Step: 6
Training loss: 2.5316109657287598
Validation loss: 2.106397416002007

Epoch: 6| Step: 7
Training loss: 2.095777988433838
Validation loss: 2.0904439828729116

Epoch: 6| Step: 8
Training loss: 2.790182113647461
Validation loss: 2.1037696305141655

Epoch: 6| Step: 9
Training loss: 1.4857532978057861
Validation loss: 2.1134710978436213

Epoch: 6| Step: 10
Training loss: 2.002476692199707
Validation loss: 2.106906734487062

Epoch: 6| Step: 11
Training loss: 1.905674934387207
Validation loss: 2.087721956673489

Epoch: 6| Step: 12
Training loss: 2.1595091819763184
Validation loss: 2.1093115909125215

Epoch: 6| Step: 13
Training loss: 2.131805896759033
Validation loss: 2.1391686419005036

Epoch: 110| Step: 0
Training loss: 2.2066457271575928
Validation loss: 2.1143713433255433

Epoch: 6| Step: 1
Training loss: 1.9544317722320557
Validation loss: 2.1207452871466197

Epoch: 6| Step: 2
Training loss: 2.0110769271850586
Validation loss: 2.1174864358799432

Epoch: 6| Step: 3
Training loss: 2.8856358528137207
Validation loss: 2.1098563286565963

Epoch: 6| Step: 4
Training loss: 1.9002645015716553
Validation loss: 2.1223192548239105

Epoch: 6| Step: 5
Training loss: 2.3168210983276367
Validation loss: 2.1246496195434244

Epoch: 6| Step: 6
Training loss: 2.458036422729492
Validation loss: 2.104649527098543

Epoch: 6| Step: 7
Training loss: 2.788525104522705
Validation loss: 2.1285642603392243

Epoch: 6| Step: 8
Training loss: 2.2598047256469727
Validation loss: 2.0927353059091875

Epoch: 6| Step: 9
Training loss: 1.5419641733169556
Validation loss: 2.1043858207682127

Epoch: 6| Step: 10
Training loss: 2.0393214225769043
Validation loss: 2.0955386495077484

Epoch: 6| Step: 11
Training loss: 1.8625472784042358
Validation loss: 2.1058651657514673

Epoch: 6| Step: 12
Training loss: 2.244278907775879
Validation loss: 2.1127074918439313

Epoch: 6| Step: 13
Training loss: 1.4331305027008057
Validation loss: 2.0923232045224918

Epoch: 111| Step: 0
Training loss: 1.9905349016189575
Validation loss: 2.1018686461192306

Epoch: 6| Step: 1
Training loss: 2.193774700164795
Validation loss: 2.1270556167889665

Epoch: 6| Step: 2
Training loss: 2.1440913677215576
Validation loss: 2.1420371532440186

Epoch: 6| Step: 3
Training loss: 1.749197244644165
Validation loss: 2.127854739466021

Epoch: 6| Step: 4
Training loss: 2.0036773681640625
Validation loss: 2.1075789261889715

Epoch: 6| Step: 5
Training loss: 2.3865067958831787
Validation loss: 2.119299914247246

Epoch: 6| Step: 6
Training loss: 2.395861864089966
Validation loss: 2.0987796732174453

Epoch: 6| Step: 7
Training loss: 2.0119216442108154
Validation loss: 2.137202183405558

Epoch: 6| Step: 8
Training loss: 2.0525050163269043
Validation loss: 2.1358167843152116

Epoch: 6| Step: 9
Training loss: 2.022711753845215
Validation loss: 2.1266427783555883

Epoch: 6| Step: 10
Training loss: 1.645715594291687
Validation loss: 2.1309804685654177

Epoch: 6| Step: 11
Training loss: 3.0768730640411377
Validation loss: 2.144644166833611

Epoch: 6| Step: 12
Training loss: 2.1360974311828613
Validation loss: 2.1388468306551696

Epoch: 6| Step: 13
Training loss: 2.8106491565704346
Validation loss: 2.1274826552278254

Epoch: 112| Step: 0
Training loss: 2.62246036529541
Validation loss: 2.1159651074358212

Epoch: 6| Step: 1
Training loss: 1.5293526649475098
Validation loss: 2.1218955670633624

Epoch: 6| Step: 2
Training loss: 2.2863030433654785
Validation loss: 2.0910785018756823

Epoch: 6| Step: 3
Training loss: 2.3532445430755615
Validation loss: 2.1378167598478255

Epoch: 6| Step: 4
Training loss: 1.8632872104644775
Validation loss: 2.1260261433098906

Epoch: 6| Step: 5
Training loss: 2.3519816398620605
Validation loss: 2.122092634119013

Epoch: 6| Step: 6
Training loss: 1.5412797927856445
Validation loss: 2.116069442482405

Epoch: 6| Step: 7
Training loss: 2.973466396331787
Validation loss: 2.103379080372472

Epoch: 6| Step: 8
Training loss: 2.009037971496582
Validation loss: 2.098039678348008

Epoch: 6| Step: 9
Training loss: 1.8459899425506592
Validation loss: 2.101315603461317

Epoch: 6| Step: 10
Training loss: 1.3263983726501465
Validation loss: 2.099841025567824

Epoch: 6| Step: 11
Training loss: 2.433100700378418
Validation loss: 2.137023941163094

Epoch: 6| Step: 12
Training loss: 2.894977569580078
Validation loss: 2.113978224415933

Epoch: 6| Step: 13
Training loss: 2.2753751277923584
Validation loss: 2.11647020616839

Epoch: 113| Step: 0
Training loss: 3.0081379413604736
Validation loss: 2.064125394308439

Epoch: 6| Step: 1
Training loss: 2.265479564666748
Validation loss: 2.127503664262833

Epoch: 6| Step: 2
Training loss: 1.455201268196106
Validation loss: 2.1543296332000406

Epoch: 6| Step: 3
Training loss: 1.9584027528762817
Validation loss: 2.065254726717549

Epoch: 6| Step: 4
Training loss: 2.069674253463745
Validation loss: 2.1158882546168503

Epoch: 6| Step: 5
Training loss: 2.5949149131774902
Validation loss: 2.1172660986582437

Epoch: 6| Step: 6
Training loss: 1.632256269454956
Validation loss: 2.1141396363576255

Epoch: 6| Step: 7
Training loss: 1.802236557006836
Validation loss: 2.141429624249858

Epoch: 6| Step: 8
Training loss: 2.0293684005737305
Validation loss: 2.1239591234473774

Epoch: 6| Step: 9
Training loss: 1.6986486911773682
Validation loss: 2.0949986339897237

Epoch: 6| Step: 10
Training loss: 2.5517525672912598
Validation loss: 2.131216977232246

Epoch: 6| Step: 11
Training loss: 2.2347824573516846
Validation loss: 2.11595808306048

Epoch: 6| Step: 12
Training loss: 2.716742515563965
Validation loss: 2.115693382037583

Epoch: 6| Step: 13
Training loss: 2.4028303623199463
Validation loss: 2.1394037585104666

Epoch: 114| Step: 0
Training loss: 2.737061023712158
Validation loss: 2.0972622338161675

Epoch: 6| Step: 1
Training loss: 1.5041614770889282
Validation loss: 2.1005691815448064

Epoch: 6| Step: 2
Training loss: 2.258629083633423
Validation loss: 2.0949325279522966

Epoch: 6| Step: 3
Training loss: 2.2056164741516113
Validation loss: 2.0910826267734652

Epoch: 6| Step: 4
Training loss: 2.076129913330078
Validation loss: 2.1329211829811014

Epoch: 6| Step: 5
Training loss: 1.5521838665008545
Validation loss: 2.1074737528319

Epoch: 6| Step: 6
Training loss: 1.8940284252166748
Validation loss: 2.123400770207887

Epoch: 6| Step: 7
Training loss: 1.9457899332046509
Validation loss: 2.0988308024662796

Epoch: 6| Step: 8
Training loss: 2.6661319732666016
Validation loss: 2.1050991755659862

Epoch: 6| Step: 9
Training loss: 2.206733226776123
Validation loss: 2.0954011512059036

Epoch: 6| Step: 10
Training loss: 2.20204496383667
Validation loss: 2.0807945548847155

Epoch: 6| Step: 11
Training loss: 2.341326951980591
Validation loss: 2.0981097195738103

Epoch: 6| Step: 12
Training loss: 2.1623048782348633
Validation loss: 2.101906156027189

Epoch: 6| Step: 13
Training loss: 2.3226521015167236
Validation loss: 2.078507759237802

Epoch: 115| Step: 0
Training loss: 2.630811929702759
Validation loss: 2.121364785778907

Epoch: 6| Step: 1
Training loss: 2.1582632064819336
Validation loss: 2.113080309283349

Epoch: 6| Step: 2
Training loss: 2.5555357933044434
Validation loss: 2.1161792560290267

Epoch: 6| Step: 3
Training loss: 1.451831340789795
Validation loss: 2.090675728295439

Epoch: 6| Step: 4
Training loss: 1.8185621500015259
Validation loss: 2.0832790238882906

Epoch: 6| Step: 5
Training loss: 2.6239218711853027
Validation loss: 2.112323964795759

Epoch: 6| Step: 6
Training loss: 2.7468483448028564
Validation loss: 2.1097716054608746

Epoch: 6| Step: 7
Training loss: 2.0278029441833496
Validation loss: 2.0960884107056486

Epoch: 6| Step: 8
Training loss: 2.003983497619629
Validation loss: 2.0895392971654094

Epoch: 6| Step: 9
Training loss: 1.6632369756698608
Validation loss: 2.1038543024370746

Epoch: 6| Step: 10
Training loss: 1.7458468675613403
Validation loss: 2.0838496121027137

Epoch: 6| Step: 11
Training loss: 2.0964503288269043
Validation loss: 2.1099082141794185

Epoch: 6| Step: 12
Training loss: 2.2492165565490723
Validation loss: 2.1225157424967778

Epoch: 6| Step: 13
Training loss: 2.286506175994873
Validation loss: 2.1225127738009215

Epoch: 116| Step: 0
Training loss: 1.2129600048065186
Validation loss: 2.0931163141804356

Epoch: 6| Step: 1
Training loss: 2.5848641395568848
Validation loss: 2.1114852607891126

Epoch: 6| Step: 2
Training loss: 2.4828343391418457
Validation loss: 2.1203473037289036

Epoch: 6| Step: 3
Training loss: 2.619692802429199
Validation loss: 2.1132641787170083

Epoch: 6| Step: 4
Training loss: 2.9940714836120605
Validation loss: 2.0951423862928986

Epoch: 6| Step: 5
Training loss: 2.4486114978790283
Validation loss: 2.1107094210963093

Epoch: 6| Step: 6
Training loss: 2.1337759494781494
Validation loss: 2.0982432698690765

Epoch: 6| Step: 7
Training loss: 1.3573068380355835
Validation loss: 2.097674914585647

Epoch: 6| Step: 8
Training loss: 1.5761457681655884
Validation loss: 2.1240155055958736

Epoch: 6| Step: 9
Training loss: 2.0669126510620117
Validation loss: 2.0710002683824107

Epoch: 6| Step: 10
Training loss: 2.3336472511291504
Validation loss: 2.1008228768584547

Epoch: 6| Step: 11
Training loss: 2.005910873413086
Validation loss: 2.096955468577723

Epoch: 6| Step: 12
Training loss: 2.116631507873535
Validation loss: 2.078843355178833

Epoch: 6| Step: 13
Training loss: 2.108811855316162
Validation loss: 2.0991731766731507

Epoch: 117| Step: 0
Training loss: 1.9846932888031006
Validation loss: 2.100044217160953

Epoch: 6| Step: 1
Training loss: 2.4385507106781006
Validation loss: 2.1062811728446715

Epoch: 6| Step: 2
Training loss: 1.5432732105255127
Validation loss: 2.11333405715163

Epoch: 6| Step: 3
Training loss: 3.199464797973633
Validation loss: 2.1286485477160384

Epoch: 6| Step: 4
Training loss: 2.2133371829986572
Validation loss: 2.1216658340987338

Epoch: 6| Step: 5
Training loss: 2.7705013751983643
Validation loss: 2.1015467528373963

Epoch: 6| Step: 6
Training loss: 1.715668797492981
Validation loss: 2.108065559018043

Epoch: 6| Step: 7
Training loss: 1.973475456237793
Validation loss: 2.102332294628184

Epoch: 6| Step: 8
Training loss: 1.355078935623169
Validation loss: 2.1173037021390853

Epoch: 6| Step: 9
Training loss: 2.338505744934082
Validation loss: 2.075185224574099

Epoch: 6| Step: 10
Training loss: 1.7085622549057007
Validation loss: 2.129074212043516

Epoch: 6| Step: 11
Training loss: 2.528264045715332
Validation loss: 2.0945500148239957

Epoch: 6| Step: 12
Training loss: 2.156480073928833
Validation loss: 2.098081575926914

Epoch: 6| Step: 13
Training loss: 2.0094523429870605
Validation loss: 2.0750999886502504

Epoch: 118| Step: 0
Training loss: 2.3627262115478516
Validation loss: 2.0841612610765683

Epoch: 6| Step: 1
Training loss: 2.139085292816162
Validation loss: 2.100540599515361

Epoch: 6| Step: 2
Training loss: 1.826490879058838
Validation loss: 2.122298973862843

Epoch: 6| Step: 3
Training loss: 2.6421010494232178
Validation loss: 2.122245280973373

Epoch: 6| Step: 4
Training loss: 2.4789888858795166
Validation loss: 2.130142832315096

Epoch: 6| Step: 5
Training loss: 1.538973093032837
Validation loss: 2.09227111775388

Epoch: 6| Step: 6
Training loss: 2.257739305496216
Validation loss: 2.118770399401265

Epoch: 6| Step: 7
Training loss: 1.9721215963363647
Validation loss: 2.076567265295213

Epoch: 6| Step: 8
Training loss: 1.717674732208252
Validation loss: 2.108825368265952

Epoch: 6| Step: 9
Training loss: 2.525310516357422
Validation loss: 2.1202626048877673

Epoch: 6| Step: 10
Training loss: 2.300541877746582
Validation loss: 2.088007593667635

Epoch: 6| Step: 11
Training loss: 2.1295106410980225
Validation loss: 2.0791384737978698

Epoch: 6| Step: 12
Training loss: 2.0678555965423584
Validation loss: 2.1087182619238414

Epoch: 6| Step: 13
Training loss: 2.0815305709838867
Validation loss: 2.1070704588326077

Epoch: 119| Step: 0
Training loss: 1.321998953819275
Validation loss: 2.122513424965643

Epoch: 6| Step: 1
Training loss: 2.25894832611084
Validation loss: 2.095036934780818

Epoch: 6| Step: 2
Training loss: 2.4506924152374268
Validation loss: 2.0840849568766933

Epoch: 6| Step: 3
Training loss: 1.959104061126709
Validation loss: 2.1213403248017833

Epoch: 6| Step: 4
Training loss: 2.4904651641845703
Validation loss: 2.1172681957162838

Epoch: 6| Step: 5
Training loss: 2.6475162506103516
Validation loss: 2.0923055577021774

Epoch: 6| Step: 6
Training loss: 1.4171624183654785
Validation loss: 2.108103931591075

Epoch: 6| Step: 7
Training loss: 2.0949926376342773
Validation loss: 2.0954517267083608

Epoch: 6| Step: 8
Training loss: 1.8931379318237305
Validation loss: 2.12257569836032

Epoch: 6| Step: 9
Training loss: 3.105916976928711
Validation loss: 2.1146452491001417

Epoch: 6| Step: 10
Training loss: 1.9124794006347656
Validation loss: 2.1367138854918943

Epoch: 6| Step: 11
Training loss: 2.0832228660583496
Validation loss: 2.1045435141491633

Epoch: 6| Step: 12
Training loss: 2.135415554046631
Validation loss: 2.1185032667652255

Epoch: 6| Step: 13
Training loss: 2.5874056816101074
Validation loss: 2.1045613058151735

Epoch: 120| Step: 0
Training loss: 2.861703395843506
Validation loss: 2.098890132801507

Epoch: 6| Step: 1
Training loss: 2.217365264892578
Validation loss: 2.1135980006187194

Epoch: 6| Step: 2
Training loss: 1.7841202020645142
Validation loss: 2.1218169491778136

Epoch: 6| Step: 3
Training loss: 2.0377395153045654
Validation loss: 2.1103611953796877

Epoch: 6| Step: 4
Training loss: 2.3250036239624023
Validation loss: 2.1116158987886164

Epoch: 6| Step: 5
Training loss: 2.0237386226654053
Validation loss: 2.100180390060589

Epoch: 6| Step: 6
Training loss: 2.9465584754943848
Validation loss: 2.086453853114959

Epoch: 6| Step: 7
Training loss: 1.3885221481323242
Validation loss: 2.111989745529749

Epoch: 6| Step: 8
Training loss: 1.4300974607467651
Validation loss: 2.1124860035475863

Epoch: 6| Step: 9
Training loss: 1.9814558029174805
Validation loss: 2.1254827976226807

Epoch: 6| Step: 10
Training loss: 2.146240234375
Validation loss: 2.1061391740716915

Epoch: 6| Step: 11
Training loss: 2.5120859146118164
Validation loss: 2.0754366664476294

Epoch: 6| Step: 12
Training loss: 1.7802945375442505
Validation loss: 2.118294547962886

Epoch: 6| Step: 13
Training loss: 2.49544620513916
Validation loss: 2.0941333527206094

Epoch: 121| Step: 0
Training loss: 1.269810438156128
Validation loss: 2.1213773783817085

Epoch: 6| Step: 1
Training loss: 2.192075252532959
Validation loss: 2.1332234592847925

Epoch: 6| Step: 2
Training loss: 2.3277931213378906
Validation loss: 2.111044991400934

Epoch: 6| Step: 3
Training loss: 2.6585533618927
Validation loss: 2.1369713916573474

Epoch: 6| Step: 4
Training loss: 2.010756015777588
Validation loss: 2.1277972652066137

Epoch: 6| Step: 5
Training loss: 1.712870478630066
Validation loss: 2.118133391103437

Epoch: 6| Step: 6
Training loss: 2.114016532897949
Validation loss: 2.103696092482536

Epoch: 6| Step: 7
Training loss: 1.8726752996444702
Validation loss: 2.1049204359772387

Epoch: 6| Step: 8
Training loss: 2.3603763580322266
Validation loss: 2.1154353259712138

Epoch: 6| Step: 9
Training loss: 1.6452827453613281
Validation loss: 2.0851523671098935

Epoch: 6| Step: 10
Training loss: 2.8689279556274414
Validation loss: 2.0937143089950725

Epoch: 6| Step: 11
Training loss: 2.581149101257324
Validation loss: 2.086078164398029

Epoch: 6| Step: 12
Training loss: 1.760337471961975
Validation loss: 2.11360510446692

Epoch: 6| Step: 13
Training loss: 2.929387092590332
Validation loss: 2.0896268813840804

Epoch: 122| Step: 0
Training loss: 1.6742357015609741
Validation loss: 2.1218989228689544

Epoch: 6| Step: 1
Training loss: 2.358804225921631
Validation loss: 2.0982342304721957

Epoch: 6| Step: 2
Training loss: 1.629899501800537
Validation loss: 2.127211049038877

Epoch: 6| Step: 3
Training loss: 1.833966851234436
Validation loss: 2.1172623557429158

Epoch: 6| Step: 4
Training loss: 2.9816598892211914
Validation loss: 2.0965646389992005

Epoch: 6| Step: 5
Training loss: 3.2472262382507324
Validation loss: 2.086228007911354

Epoch: 6| Step: 6
Training loss: 1.5834641456604004
Validation loss: 2.107212976742816

Epoch: 6| Step: 7
Training loss: 2.591472625732422
Validation loss: 2.098232610251314

Epoch: 6| Step: 8
Training loss: 2.086864471435547
Validation loss: 2.100730937014344

Epoch: 6| Step: 9
Training loss: 2.559276580810547
Validation loss: 2.090189662030948

Epoch: 6| Step: 10
Training loss: 2.0160017013549805
Validation loss: 2.0932196776072183

Epoch: 6| Step: 11
Training loss: 1.8900315761566162
Validation loss: 2.1044819867739113

Epoch: 6| Step: 12
Training loss: 1.748288869857788
Validation loss: 2.093746985158613

Epoch: 6| Step: 13
Training loss: 1.4453206062316895
Validation loss: 2.0982463154741513

Epoch: 123| Step: 0
Training loss: 1.876973271369934
Validation loss: 2.1332714070555983

Epoch: 6| Step: 1
Training loss: 2.2202539443969727
Validation loss: 2.1250334247466056

Epoch: 6| Step: 2
Training loss: 2.1458704471588135
Validation loss: 2.134181099553262

Epoch: 6| Step: 3
Training loss: 2.0261809825897217
Validation loss: 2.0862476787259503

Epoch: 6| Step: 4
Training loss: 2.0636744499206543
Validation loss: 2.0892313718795776

Epoch: 6| Step: 5
Training loss: 2.014767646789551
Validation loss: 2.15482940981465

Epoch: 6| Step: 6
Training loss: 2.474879264831543
Validation loss: 2.1121192106636624

Epoch: 6| Step: 7
Training loss: 2.835360527038574
Validation loss: 2.091490699398902

Epoch: 6| Step: 8
Training loss: 2.400576591491699
Validation loss: 2.0991258672488633

Epoch: 6| Step: 9
Training loss: 1.756756067276001
Validation loss: 2.1079255214301487

Epoch: 6| Step: 10
Training loss: 1.9438875913619995
Validation loss: 2.128070109633989

Epoch: 6| Step: 11
Training loss: 1.783470630645752
Validation loss: 2.0934178393374205

Epoch: 6| Step: 12
Training loss: 1.3912261724472046
Validation loss: 2.095411516004993

Epoch: 6| Step: 13
Training loss: 2.9498300552368164
Validation loss: 2.120886593736628

Epoch: 124| Step: 0
Training loss: 1.4462199211120605
Validation loss: 2.114882125649401

Epoch: 6| Step: 1
Training loss: 2.104865550994873
Validation loss: 2.082901095831266

Epoch: 6| Step: 2
Training loss: 2.0914366245269775
Validation loss: 2.1037378464975665

Epoch: 6| Step: 3
Training loss: 2.2574360370635986
Validation loss: 2.076862589005501

Epoch: 6| Step: 4
Training loss: 1.9769599437713623
Validation loss: 2.0982520118836434

Epoch: 6| Step: 5
Training loss: 2.69520902633667
Validation loss: 2.0966151042651107

Epoch: 6| Step: 6
Training loss: 1.9956327676773071
Validation loss: 2.0893679716253795

Epoch: 6| Step: 7
Training loss: 1.8415336608886719
Validation loss: 2.100816547229726

Epoch: 6| Step: 8
Training loss: 2.5179052352905273
Validation loss: 2.100166025982108

Epoch: 6| Step: 9
Training loss: 2.5906636714935303
Validation loss: 2.0870618333098707

Epoch: 6| Step: 10
Training loss: 1.8283298015594482
Validation loss: 2.108851589182372

Epoch: 6| Step: 11
Training loss: 1.8366492986679077
Validation loss: 2.088829537873627

Epoch: 6| Step: 12
Training loss: 2.4182448387145996
Validation loss: 2.0614846880717943

Epoch: 6| Step: 13
Training loss: 2.19718599319458
Validation loss: 2.0852817437982045

Epoch: 125| Step: 0
Training loss: 2.1247034072875977
Validation loss: 2.084624118702386

Epoch: 6| Step: 1
Training loss: 1.881075143814087
Validation loss: 2.0999685641257995

Epoch: 6| Step: 2
Training loss: 2.0743842124938965
Validation loss: 2.088842245840257

Epoch: 6| Step: 3
Training loss: 2.018509864807129
Validation loss: 2.0826567795968827

Epoch: 6| Step: 4
Training loss: 2.154703378677368
Validation loss: 2.09241848094489

Epoch: 6| Step: 5
Training loss: 1.9698543548583984
Validation loss: 2.1118882112605597

Epoch: 6| Step: 6
Training loss: 1.7483081817626953
Validation loss: 2.1097821599693707

Epoch: 6| Step: 7
Training loss: 2.294046640396118
Validation loss: 2.096561275502687

Epoch: 6| Step: 8
Training loss: 2.2703018188476562
Validation loss: 2.0876271788791945

Epoch: 6| Step: 9
Training loss: 1.848624587059021
Validation loss: 2.0895294745763144

Epoch: 6| Step: 10
Training loss: 1.7942341566085815
Validation loss: 2.1110958155765327

Epoch: 6| Step: 11
Training loss: 2.924410820007324
Validation loss: 2.1037125305462907

Epoch: 6| Step: 12
Training loss: 2.283857583999634
Validation loss: 2.104364997597151

Epoch: 6| Step: 13
Training loss: 2.608793020248413
Validation loss: 2.084091467242087

Epoch: 126| Step: 0
Training loss: 1.5715241432189941
Validation loss: 2.113548166008406

Epoch: 6| Step: 1
Training loss: 1.8956362009048462
Validation loss: 2.1049807943323606

Epoch: 6| Step: 2
Training loss: 2.4540505409240723
Validation loss: 2.079134072026899

Epoch: 6| Step: 3
Training loss: 2.0044379234313965
Validation loss: 2.084768302979008

Epoch: 6| Step: 4
Training loss: 2.7048468589782715
Validation loss: 2.1256876453276603

Epoch: 6| Step: 5
Training loss: 2.5462632179260254
Validation loss: 2.095210644506639

Epoch: 6| Step: 6
Training loss: 1.7898743152618408
Validation loss: 2.0879745432125625

Epoch: 6| Step: 7
Training loss: 2.2349700927734375
Validation loss: 2.060401383266654

Epoch: 6| Step: 8
Training loss: 1.6617980003356934
Validation loss: 2.094689024391995

Epoch: 6| Step: 9
Training loss: 2.061152458190918
Validation loss: 2.1226818587190364

Epoch: 6| Step: 10
Training loss: 2.0639302730560303
Validation loss: 2.0831639125782955

Epoch: 6| Step: 11
Training loss: 1.857444167137146
Validation loss: 2.1431285001898326

Epoch: 6| Step: 12
Training loss: 2.271486282348633
Validation loss: 2.103519544806532

Epoch: 6| Step: 13
Training loss: 2.4800870418548584
Validation loss: 2.1004467984681487

Epoch: 127| Step: 0
Training loss: 1.9458242654800415
Validation loss: 2.11055786378922

Epoch: 6| Step: 1
Training loss: 1.7870157957077026
Validation loss: 2.0805860206645024

Epoch: 6| Step: 2
Training loss: 2.3450894355773926
Validation loss: 2.1077194803504535

Epoch: 6| Step: 3
Training loss: 1.7146179676055908
Validation loss: 2.0886870289361603

Epoch: 6| Step: 4
Training loss: 2.526045322418213
Validation loss: 2.091435432434082

Epoch: 6| Step: 5
Training loss: 1.870365023612976
Validation loss: 2.1073795633931316

Epoch: 6| Step: 6
Training loss: 2.0616049766540527
Validation loss: 2.1014412154433546

Epoch: 6| Step: 7
Training loss: 2.315291404724121
Validation loss: 2.092895286057585

Epoch: 6| Step: 8
Training loss: 2.217255115509033
Validation loss: 2.0993503883320797

Epoch: 6| Step: 9
Training loss: 2.5266201496124268
Validation loss: 2.08098877117198

Epoch: 6| Step: 10
Training loss: 2.2636122703552246
Validation loss: 2.094036622713971

Epoch: 6| Step: 11
Training loss: 2.4314770698547363
Validation loss: 2.1219771344174623

Epoch: 6| Step: 12
Training loss: 1.604175090789795
Validation loss: 2.0747007195667555

Epoch: 6| Step: 13
Training loss: 1.625483751296997
Validation loss: 2.1039871913130566

Epoch: 128| Step: 0
Training loss: 1.3333160877227783
Validation loss: 2.0934881664091542

Epoch: 6| Step: 1
Training loss: 2.8954925537109375
Validation loss: 2.0788149013314197

Epoch: 6| Step: 2
Training loss: 2.042109251022339
Validation loss: 2.098421417256837

Epoch: 6| Step: 3
Training loss: 2.86462664604187
Validation loss: 2.1134112496529855

Epoch: 6| Step: 4
Training loss: 2.292597770690918
Validation loss: 2.0891544741968953

Epoch: 6| Step: 5
Training loss: 2.1186959743499756
Validation loss: 2.1153825406105287

Epoch: 6| Step: 6
Training loss: 2.2704267501831055
Validation loss: 2.0729615983142646

Epoch: 6| Step: 7
Training loss: 1.8633581399917603
Validation loss: 2.109866947256109

Epoch: 6| Step: 8
Training loss: 2.6646604537963867
Validation loss: 2.067956002809668

Epoch: 6| Step: 9
Training loss: 2.278977632522583
Validation loss: 2.121631306986655

Epoch: 6| Step: 10
Training loss: 1.2310338020324707
Validation loss: 2.1057614395695348

Epoch: 6| Step: 11
Training loss: 1.9457964897155762
Validation loss: 2.0911688189352713

Epoch: 6| Step: 12
Training loss: 2.0744688510894775
Validation loss: 2.1217749785351496

Epoch: 6| Step: 13
Training loss: 1.6455812454223633
Validation loss: 2.090780177424031

Epoch: 129| Step: 0
Training loss: 1.7096636295318604
Validation loss: 2.0998456567846318

Epoch: 6| Step: 1
Training loss: 2.178825855255127
Validation loss: 2.11375359565981

Epoch: 6| Step: 2
Training loss: 1.9221434593200684
Validation loss: 2.1081142963901645

Epoch: 6| Step: 3
Training loss: 2.06195068359375
Validation loss: 2.1161559807356967

Epoch: 6| Step: 4
Training loss: 2.591154098510742
Validation loss: 2.111405103437362

Epoch: 6| Step: 5
Training loss: 2.183237075805664
Validation loss: 2.1015290316715034

Epoch: 6| Step: 6
Training loss: 1.7932276725769043
Validation loss: 2.0669366031564693

Epoch: 6| Step: 7
Training loss: 2.426877021789551
Validation loss: 2.1028192889305855

Epoch: 6| Step: 8
Training loss: 2.2230944633483887
Validation loss: 2.110823982505388

Epoch: 6| Step: 9
Training loss: 2.2436652183532715
Validation loss: 2.115528839890675

Epoch: 6| Step: 10
Training loss: 1.7504911422729492
Validation loss: 2.10326753252296

Epoch: 6| Step: 11
Training loss: 2.350374698638916
Validation loss: 2.097150320647865

Epoch: 6| Step: 12
Training loss: 1.8787875175476074
Validation loss: 2.0801782646486835

Epoch: 6| Step: 13
Training loss: 1.9905242919921875
Validation loss: 2.102997951610114

Epoch: 130| Step: 0
Training loss: 2.544757127761841
Validation loss: 2.103516868365708

Epoch: 6| Step: 1
Training loss: 1.6705257892608643
Validation loss: 2.071111600886109

Epoch: 6| Step: 2
Training loss: 2.403501033782959
Validation loss: 2.0893803847733365

Epoch: 6| Step: 3
Training loss: 2.242910385131836
Validation loss: 2.122288255281346

Epoch: 6| Step: 4
Training loss: 1.7587559223175049
Validation loss: 2.0982942760631604

Epoch: 6| Step: 5
Training loss: 1.9763550758361816
Validation loss: 2.07311951216831

Epoch: 6| Step: 6
Training loss: 1.1181665658950806
Validation loss: 2.0755384660536245

Epoch: 6| Step: 7
Training loss: 2.2636489868164062
Validation loss: 2.07692410356255

Epoch: 6| Step: 8
Training loss: 2.112877130508423
Validation loss: 2.100027912406511

Epoch: 6| Step: 9
Training loss: 2.14396071434021
Validation loss: 2.0983909817152124

Epoch: 6| Step: 10
Training loss: 2.4373250007629395
Validation loss: 2.058609349753267

Epoch: 6| Step: 11
Training loss: 2.0813698768615723
Validation loss: 2.080236332390898

Epoch: 6| Step: 12
Training loss: 2.7126612663269043
Validation loss: 2.0542197022386777

Epoch: 6| Step: 13
Training loss: 1.872437834739685
Validation loss: 2.1047053670370452

Epoch: 131| Step: 0
Training loss: 1.8753423690795898
Validation loss: 2.115962824513835

Epoch: 6| Step: 1
Training loss: 2.5259838104248047
Validation loss: 2.087095114492601

Epoch: 6| Step: 2
Training loss: 3.208573579788208
Validation loss: 2.0862618595041256

Epoch: 6| Step: 3
Training loss: 2.152719020843506
Validation loss: 2.080146480632085

Epoch: 6| Step: 4
Training loss: 2.2216572761535645
Validation loss: 2.095922754656884

Epoch: 6| Step: 5
Training loss: 2.45534086227417
Validation loss: 2.106846888860067

Epoch: 6| Step: 6
Training loss: 1.4199317693710327
Validation loss: 2.118269125620524

Epoch: 6| Step: 7
Training loss: 1.7385523319244385
Validation loss: 2.128532246876788

Epoch: 6| Step: 8
Training loss: 1.7797613143920898
Validation loss: 2.097707017775505

Epoch: 6| Step: 9
Training loss: 1.826887845993042
Validation loss: 2.1003832047985447

Epoch: 6| Step: 10
Training loss: 2.552309989929199
Validation loss: 2.102441913338118

Epoch: 6| Step: 11
Training loss: 1.232988953590393
Validation loss: 2.081847410048208

Epoch: 6| Step: 12
Training loss: 2.0208704471588135
Validation loss: 2.0797352726741503

Epoch: 6| Step: 13
Training loss: 2.398339033126831
Validation loss: 2.1174588152157363

Epoch: 132| Step: 0
Training loss: 1.2766149044036865
Validation loss: 2.0992001846272457

Epoch: 6| Step: 1
Training loss: 1.8071599006652832
Validation loss: 2.0850780599860737

Epoch: 6| Step: 2
Training loss: 1.803122639656067
Validation loss: 2.0989393136834584

Epoch: 6| Step: 3
Training loss: 2.713637351989746
Validation loss: 2.081724497579759

Epoch: 6| Step: 4
Training loss: 2.140835762023926
Validation loss: 2.113201895067769

Epoch: 6| Step: 5
Training loss: 2.893850326538086
Validation loss: 2.0748403790176555

Epoch: 6| Step: 6
Training loss: 2.1087701320648193
Validation loss: 2.1017257475083873

Epoch: 6| Step: 7
Training loss: 2.5888140201568604
Validation loss: 2.1021525475286666

Epoch: 6| Step: 8
Training loss: 2.1384243965148926
Validation loss: 2.103959955194945

Epoch: 6| Step: 9
Training loss: 1.8967006206512451
Validation loss: 2.1099899507338002

Epoch: 6| Step: 10
Training loss: 1.765249490737915
Validation loss: 2.097651889247279

Epoch: 6| Step: 11
Training loss: 1.8780241012573242
Validation loss: 2.1062945858124764

Epoch: 6| Step: 12
Training loss: 1.6382819414138794
Validation loss: 2.1193682814157135

Epoch: 6| Step: 13
Training loss: 2.6664533615112305
Validation loss: 2.11631299859734

Epoch: 133| Step: 0
Training loss: 2.0835013389587402
Validation loss: 2.106774373721051

Epoch: 6| Step: 1
Training loss: 2.537336826324463
Validation loss: 2.09057165345838

Epoch: 6| Step: 2
Training loss: 2.5515670776367188
Validation loss: 2.133462646956085

Epoch: 6| Step: 3
Training loss: 2.0442168712615967
Validation loss: 2.087695501183951

Epoch: 6| Step: 4
Training loss: 1.3995997905731201
Validation loss: 2.09694383734016

Epoch: 6| Step: 5
Training loss: 1.718220591545105
Validation loss: 2.0840807742969965

Epoch: 6| Step: 6
Training loss: 1.925075888633728
Validation loss: 2.0840183124747327

Epoch: 6| Step: 7
Training loss: 2.5159249305725098
Validation loss: 2.1055028835932412

Epoch: 6| Step: 8
Training loss: 1.5266673564910889
Validation loss: 2.101778056031914

Epoch: 6| Step: 9
Training loss: 2.254556894302368
Validation loss: 2.12300980219277

Epoch: 6| Step: 10
Training loss: 2.2750210762023926
Validation loss: 2.1308473233253724

Epoch: 6| Step: 11
Training loss: 2.818472385406494
Validation loss: 2.0994154035404162

Epoch: 6| Step: 12
Training loss: 2.331749200820923
Validation loss: 2.1307773077359764

Epoch: 6| Step: 13
Training loss: 1.0142015218734741
Validation loss: 2.102812264555244

Epoch: 134| Step: 0
Training loss: 2.000180244445801
Validation loss: 2.1319726205641225

Epoch: 6| Step: 1
Training loss: 2.252139091491699
Validation loss: 2.1127820386681506

Epoch: 6| Step: 2
Training loss: 2.511929512023926
Validation loss: 2.135718248223746

Epoch: 6| Step: 3
Training loss: 2.0322816371917725
Validation loss: 2.129443089167277

Epoch: 6| Step: 4
Training loss: 2.0950701236724854
Validation loss: 2.103475578369633

Epoch: 6| Step: 5
Training loss: 1.3659214973449707
Validation loss: 2.1260556969591367

Epoch: 6| Step: 6
Training loss: 2.1720688343048096
Validation loss: 2.081728909605293

Epoch: 6| Step: 7
Training loss: 2.1246397495269775
Validation loss: 2.1387290518770934

Epoch: 6| Step: 8
Training loss: 2.0763094425201416
Validation loss: 2.0948601127952657

Epoch: 6| Step: 9
Training loss: 1.7821369171142578
Validation loss: 2.090745417020654

Epoch: 6| Step: 10
Training loss: 2.3584673404693604
Validation loss: 2.119923134003916

Epoch: 6| Step: 11
Training loss: 2.01632022857666
Validation loss: 2.1030703449761994

Epoch: 6| Step: 12
Training loss: 2.33333683013916
Validation loss: 2.097674218557214

Epoch: 6| Step: 13
Training loss: 2.2601242065429688
Validation loss: 2.089125117947978

Epoch: 135| Step: 0
Training loss: 2.730313301086426
Validation loss: 2.0545197943205475

Epoch: 6| Step: 1
Training loss: 2.1100988388061523
Validation loss: 2.1080130146395777

Epoch: 6| Step: 2
Training loss: 1.9835667610168457
Validation loss: 2.1054832602059967

Epoch: 6| Step: 3
Training loss: 1.3158477544784546
Validation loss: 2.0763680370905067

Epoch: 6| Step: 4
Training loss: 2.4840378761291504
Validation loss: 2.108207861582438

Epoch: 6| Step: 5
Training loss: 2.106227159500122
Validation loss: 2.094778630041307

Epoch: 6| Step: 6
Training loss: 1.6550891399383545
Validation loss: 2.0966343149062125

Epoch: 6| Step: 7
Training loss: 2.477588653564453
Validation loss: 2.0671624957874255

Epoch: 6| Step: 8
Training loss: 2.283409595489502
Validation loss: 2.1187637877720658

Epoch: 6| Step: 9
Training loss: 1.3025517463684082
Validation loss: 2.0760414754190752

Epoch: 6| Step: 10
Training loss: 2.615100622177124
Validation loss: 2.097195033104189

Epoch: 6| Step: 11
Training loss: 2.0386769771575928
Validation loss: 2.1376245252547728

Epoch: 6| Step: 12
Training loss: 1.8050808906555176
Validation loss: 2.103450023999778

Epoch: 6| Step: 13
Training loss: 2.2719547748565674
Validation loss: 2.1216064319815686

Epoch: 136| Step: 0
Training loss: 2.6381337642669678
Validation loss: 2.111456422395604

Epoch: 6| Step: 1
Training loss: 2.215299606323242
Validation loss: 2.0990602175394693

Epoch: 6| Step: 2
Training loss: 1.560319185256958
Validation loss: 2.100273024651312

Epoch: 6| Step: 3
Training loss: 1.4096490144729614
Validation loss: 2.0864381687615507

Epoch: 6| Step: 4
Training loss: 1.9952194690704346
Validation loss: 2.072686015918691

Epoch: 6| Step: 5
Training loss: 2.1834499835968018
Validation loss: 2.0824473109296573

Epoch: 6| Step: 6
Training loss: 1.918129563331604
Validation loss: 2.100272185059004

Epoch: 6| Step: 7
Training loss: 2.2062032222747803
Validation loss: 2.1085496999884166

Epoch: 6| Step: 8
Training loss: 1.8492774963378906
Validation loss: 2.1087359356623825

Epoch: 6| Step: 9
Training loss: 2.2384209632873535
Validation loss: 2.1377718371729695

Epoch: 6| Step: 10
Training loss: 2.557133913040161
Validation loss: 2.083967508808259

Epoch: 6| Step: 11
Training loss: 2.6045241355895996
Validation loss: 2.101711707730447

Epoch: 6| Step: 12
Training loss: 1.8794482946395874
Validation loss: 2.083458782524191

Epoch: 6| Step: 13
Training loss: 1.5542676448822021
Validation loss: 2.0955990693902455

Epoch: 137| Step: 0
Training loss: 2.42105770111084
Validation loss: 2.095660880047788

Epoch: 6| Step: 1
Training loss: 1.7892991304397583
Validation loss: 2.0907973884254374

Epoch: 6| Step: 2
Training loss: 2.295457363128662
Validation loss: 2.097922712244013

Epoch: 6| Step: 3
Training loss: 2.83624267578125
Validation loss: 2.0845589099391812

Epoch: 6| Step: 4
Training loss: 1.8641259670257568
Validation loss: 2.089817939266082

Epoch: 6| Step: 5
Training loss: 2.156909465789795
Validation loss: 2.124292960730932

Epoch: 6| Step: 6
Training loss: 1.8583483695983887
Validation loss: 2.0949647503514446

Epoch: 6| Step: 7
Training loss: 1.8237570524215698
Validation loss: 2.093019316273351

Epoch: 6| Step: 8
Training loss: 2.887857675552368
Validation loss: 2.1083554452465427

Epoch: 6| Step: 9
Training loss: 2.20186185836792
Validation loss: 2.1449943998808503

Epoch: 6| Step: 10
Training loss: 2.001680374145508
Validation loss: 2.0762265190001457

Epoch: 6| Step: 11
Training loss: 1.539787769317627
Validation loss: 2.13798644978513

Epoch: 6| Step: 12
Training loss: 1.4840008020401
Validation loss: 2.05730757405681

Epoch: 6| Step: 13
Training loss: 1.6807299852371216
Validation loss: 2.1081622697973765

Epoch: 138| Step: 0
Training loss: 2.4207241535186768
Validation loss: 2.107050923890965

Epoch: 6| Step: 1
Training loss: 1.013380765914917
Validation loss: 2.085209492714174

Epoch: 6| Step: 2
Training loss: 2.6269712448120117
Validation loss: 2.100160152681412

Epoch: 6| Step: 3
Training loss: 2.635441303253174
Validation loss: 2.0661757146158526

Epoch: 6| Step: 4
Training loss: 2.4116268157958984
Validation loss: 2.084570050239563

Epoch: 6| Step: 5
Training loss: 1.7587206363677979
Validation loss: 2.075332615965156

Epoch: 6| Step: 6
Training loss: 1.9438765048980713
Validation loss: 2.094421576428157

Epoch: 6| Step: 7
Training loss: 1.9863444566726685
Validation loss: 2.0850146047530638

Epoch: 6| Step: 8
Training loss: 2.0918173789978027
Validation loss: 2.074037290388538

Epoch: 6| Step: 9
Training loss: 2.1682612895965576
Validation loss: 2.098808801302346

Epoch: 6| Step: 10
Training loss: 1.6387498378753662
Validation loss: 2.092151193208592

Epoch: 6| Step: 11
Training loss: 2.5826644897460938
Validation loss: 2.1088091788753385

Epoch: 6| Step: 12
Training loss: 1.888444423675537
Validation loss: 2.0914845594795803

Epoch: 6| Step: 13
Training loss: 1.8281275033950806
Validation loss: 2.0970810382596907

Epoch: 139| Step: 0
Training loss: 1.765857219696045
Validation loss: 2.086338250867782

Epoch: 6| Step: 1
Training loss: 1.8337041139602661
Validation loss: 2.1266313829729633

Epoch: 6| Step: 2
Training loss: 1.8814696073532104
Validation loss: 2.081052262295959

Epoch: 6| Step: 3
Training loss: 1.6578689813613892
Validation loss: 2.102629333414057

Epoch: 6| Step: 4
Training loss: 1.56148362159729
Validation loss: 2.0829316749367663

Epoch: 6| Step: 5
Training loss: 2.6219630241394043
Validation loss: 2.1033216368767524

Epoch: 6| Step: 6
Training loss: 2.1374242305755615
Validation loss: 2.095947027206421

Epoch: 6| Step: 7
Training loss: 3.036487340927124
Validation loss: 2.0994244108917894

Epoch: 6| Step: 8
Training loss: 2.502696990966797
Validation loss: 2.0910576979319253

Epoch: 6| Step: 9
Training loss: 2.2656404972076416
Validation loss: 2.0402840568173315

Epoch: 6| Step: 10
Training loss: 1.741330862045288
Validation loss: 2.0873638558131393

Epoch: 6| Step: 11
Training loss: 1.3185863494873047
Validation loss: 2.1036714789687947

Epoch: 6| Step: 12
Training loss: 2.3510043621063232
Validation loss: 2.0893537036834227

Epoch: 6| Step: 13
Training loss: 2.040045976638794
Validation loss: 2.079236891961867

Epoch: 140| Step: 0
Training loss: 2.475100517272949
Validation loss: 2.066423803247431

Epoch: 6| Step: 1
Training loss: 2.2172484397888184
Validation loss: 2.0933923285494567

Epoch: 6| Step: 2
Training loss: 2.0851664543151855
Validation loss: 2.0754983117503505

Epoch: 6| Step: 3
Training loss: 2.490959644317627
Validation loss: 2.1165084377411874

Epoch: 6| Step: 4
Training loss: 2.266815423965454
Validation loss: 2.0737225189003894

Epoch: 6| Step: 5
Training loss: 2.0333611965179443
Validation loss: 2.123013255416706

Epoch: 6| Step: 6
Training loss: 1.2646605968475342
Validation loss: 2.0840429593158025

Epoch: 6| Step: 7
Training loss: 1.6415576934814453
Validation loss: 2.0986345532119914

Epoch: 6| Step: 8
Training loss: 2.1677703857421875
Validation loss: 2.1183469962048274

Epoch: 6| Step: 9
Training loss: 1.9830604791641235
Validation loss: 2.091612692802183

Epoch: 6| Step: 10
Training loss: 2.233426094055176
Validation loss: 2.107563462308658

Epoch: 6| Step: 11
Training loss: 1.5471593141555786
Validation loss: 2.074912601901639

Epoch: 6| Step: 12
Training loss: 2.610607147216797
Validation loss: 2.0861758185971166

Epoch: 6| Step: 13
Training loss: 1.9069641828536987
Validation loss: 2.0632644712284045

Epoch: 141| Step: 0
Training loss: 2.3873205184936523
Validation loss: 2.094135215205531

Epoch: 6| Step: 1
Training loss: 1.7347126007080078
Validation loss: 2.0842544814591766

Epoch: 6| Step: 2
Training loss: 2.0739474296569824
Validation loss: 2.1069150470918223

Epoch: 6| Step: 3
Training loss: 2.6269819736480713
Validation loss: 2.089130268302015

Epoch: 6| Step: 4
Training loss: 2.1068248748779297
Validation loss: 2.0630650635688537

Epoch: 6| Step: 5
Training loss: 1.9856131076812744
Validation loss: 2.0909573262737644

Epoch: 6| Step: 6
Training loss: 2.104560613632202
Validation loss: 2.0643964403419086

Epoch: 6| Step: 7
Training loss: 1.521059513092041
Validation loss: 2.108947746215328

Epoch: 6| Step: 8
Training loss: 2.1909964084625244
Validation loss: 2.080527924722241

Epoch: 6| Step: 9
Training loss: 1.6517093181610107
Validation loss: 2.066824774588308

Epoch: 6| Step: 10
Training loss: 1.9549864530563354
Validation loss: 2.092101038143199

Epoch: 6| Step: 11
Training loss: 2.099484443664551
Validation loss: 2.0808985848580637

Epoch: 6| Step: 12
Training loss: 2.194878578186035
Validation loss: 2.0671574684881393

Epoch: 6| Step: 13
Training loss: 2.1430959701538086
Validation loss: 2.1037200932861655

Epoch: 142| Step: 0
Training loss: 2.3642868995666504
Validation loss: 2.1066325454301733

Epoch: 6| Step: 1
Training loss: 2.165393829345703
Validation loss: 2.113198734098865

Epoch: 6| Step: 2
Training loss: 1.801328182220459
Validation loss: 2.1018107373227357

Epoch: 6| Step: 3
Training loss: 2.484332323074341
Validation loss: 2.1178978822564565

Epoch: 6| Step: 4
Training loss: 2.07947039604187
Validation loss: 2.1317094449074037

Epoch: 6| Step: 5
Training loss: 2.1687798500061035
Validation loss: 2.076827453028771

Epoch: 6| Step: 6
Training loss: 2.866866111755371
Validation loss: 2.0801512361854635

Epoch: 6| Step: 7
Training loss: 1.4722504615783691
Validation loss: 2.0539009955621537

Epoch: 6| Step: 8
Training loss: 1.9275827407836914
Validation loss: 2.076703045957832

Epoch: 6| Step: 9
Training loss: 1.8609004020690918
Validation loss: 2.060064656760103

Epoch: 6| Step: 10
Training loss: 2.1076934337615967
Validation loss: 2.0917679930246003

Epoch: 6| Step: 11
Training loss: 1.8349677324295044
Validation loss: 2.0848447302336335

Epoch: 6| Step: 12
Training loss: 1.851539134979248
Validation loss: 2.078708307717436

Epoch: 6| Step: 13
Training loss: 1.8602436780929565
Validation loss: 2.058588698346128

Epoch: 143| Step: 0
Training loss: 1.76108980178833
Validation loss: 2.0612737850476335

Epoch: 6| Step: 1
Training loss: 2.268953323364258
Validation loss: 2.0815421688941216

Epoch: 6| Step: 2
Training loss: 1.9974333047866821
Validation loss: 2.0860742522824194

Epoch: 6| Step: 3
Training loss: 1.60005521774292
Validation loss: 2.0800671192907516

Epoch: 6| Step: 4
Training loss: 1.917976975440979
Validation loss: 2.0873065071721233

Epoch: 6| Step: 5
Training loss: 2.4646811485290527
Validation loss: 2.0986013617566837

Epoch: 6| Step: 6
Training loss: 2.23419451713562
Validation loss: 2.0904043079704366

Epoch: 6| Step: 7
Training loss: 2.0377137660980225
Validation loss: 2.0635368054912937

Epoch: 6| Step: 8
Training loss: 2.7292098999023438
Validation loss: 2.095832445288217

Epoch: 6| Step: 9
Training loss: 2.4098072052001953
Validation loss: 2.080250777224059

Epoch: 6| Step: 10
Training loss: 1.4278191328048706
Validation loss: 2.0933317061393493

Epoch: 6| Step: 11
Training loss: 1.6641470193862915
Validation loss: 2.0747696456088813

Epoch: 6| Step: 12
Training loss: 1.7596213817596436
Validation loss: 2.073567682696927

Epoch: 6| Step: 13
Training loss: 2.549313545227051
Validation loss: 2.094869316265147

Epoch: 144| Step: 0
Training loss: 2.1449592113494873
Validation loss: 2.0709523539389334

Epoch: 6| Step: 1
Training loss: 1.8278515338897705
Validation loss: 2.0833594376041042

Epoch: 6| Step: 2
Training loss: 2.3974497318267822
Validation loss: 2.0617856210277927

Epoch: 6| Step: 3
Training loss: 1.9328787326812744
Validation loss: 2.086369019682689

Epoch: 6| Step: 4
Training loss: 1.3208638429641724
Validation loss: 2.1000743617293653

Epoch: 6| Step: 5
Training loss: 2.4461669921875
Validation loss: 2.0995800213147233

Epoch: 6| Step: 6
Training loss: 1.29742431640625
Validation loss: 2.077743358509515

Epoch: 6| Step: 7
Training loss: 2.464722156524658
Validation loss: 2.0762276008564937

Epoch: 6| Step: 8
Training loss: 2.007277011871338
Validation loss: 2.1017988445938274

Epoch: 6| Step: 9
Training loss: 2.166384696960449
Validation loss: 2.104113724923903

Epoch: 6| Step: 10
Training loss: 2.510833263397217
Validation loss: 2.04270827129323

Epoch: 6| Step: 11
Training loss: 1.917533278465271
Validation loss: 2.090182278745918

Epoch: 6| Step: 12
Training loss: 1.9428592920303345
Validation loss: 2.0753565475504887

Epoch: 6| Step: 13
Training loss: 3.11444091796875
Validation loss: 2.0856878706203994

Epoch: 145| Step: 0
Training loss: 1.3358690738677979
Validation loss: 2.1105534325363817

Epoch: 6| Step: 1
Training loss: 1.8800528049468994
Validation loss: 2.1170101960500083

Epoch: 6| Step: 2
Training loss: 1.9740393161773682
Validation loss: 2.110712000118789

Epoch: 6| Step: 3
Training loss: 1.4869320392608643
Validation loss: 2.086294671540619

Epoch: 6| Step: 4
Training loss: 2.683394432067871
Validation loss: 2.0724042743764897

Epoch: 6| Step: 5
Training loss: 2.2473044395446777
Validation loss: 2.098869877476846

Epoch: 6| Step: 6
Training loss: 2.1415858268737793
Validation loss: 2.0990159639748196

Epoch: 6| Step: 7
Training loss: 2.377572774887085
Validation loss: 2.109994960087602

Epoch: 6| Step: 8
Training loss: 1.9749162197113037
Validation loss: 2.095354013545539

Epoch: 6| Step: 9
Training loss: 1.846280574798584
Validation loss: 2.1220420534892748

Epoch: 6| Step: 10
Training loss: 2.0623295307159424
Validation loss: 2.075363862899042

Epoch: 6| Step: 11
Training loss: 2.2520573139190674
Validation loss: 2.082680061299314

Epoch: 6| Step: 12
Training loss: 2.447847843170166
Validation loss: 2.0807961315237065

Epoch: 6| Step: 13
Training loss: 1.7802306413650513
Validation loss: 2.0825047723708616

Epoch: 146| Step: 0
Training loss: 2.6691718101501465
Validation loss: 2.0928444682910876

Epoch: 6| Step: 1
Training loss: 2.4414281845092773
Validation loss: 2.048895194966306

Epoch: 6| Step: 2
Training loss: 2.2711713314056396
Validation loss: 2.0944477204353578

Epoch: 6| Step: 3
Training loss: 2.8237967491149902
Validation loss: 2.0867969835958173

Epoch: 6| Step: 4
Training loss: 2.03206205368042
Validation loss: 2.1229266581996793

Epoch: 6| Step: 5
Training loss: 1.8081508874893188
Validation loss: 2.085083435940486

Epoch: 6| Step: 6
Training loss: 2.1666226387023926
Validation loss: 2.081832355068576

Epoch: 6| Step: 7
Training loss: 1.5872459411621094
Validation loss: 2.095054154754967

Epoch: 6| Step: 8
Training loss: 1.4848545789718628
Validation loss: 2.0887668619873705

Epoch: 6| Step: 9
Training loss: 1.8757606744766235
Validation loss: 2.0677415068431566

Epoch: 6| Step: 10
Training loss: 2.27435040473938
Validation loss: 2.039920215965599

Epoch: 6| Step: 11
Training loss: 1.6098192930221558
Validation loss: 2.1068364458699382

Epoch: 6| Step: 12
Training loss: 1.5284287929534912
Validation loss: 2.1241885257023636

Epoch: 6| Step: 13
Training loss: 2.140864372253418
Validation loss: 2.0817288403869956

Epoch: 147| Step: 0
Training loss: 1.7397277355194092
Validation loss: 2.1046994219544115

Epoch: 6| Step: 1
Training loss: 1.6491142511367798
Validation loss: 2.082401734526439

Epoch: 6| Step: 2
Training loss: 1.1257469654083252
Validation loss: 2.0727079414552256

Epoch: 6| Step: 3
Training loss: 3.3519985675811768
Validation loss: 2.0844108032923874

Epoch: 6| Step: 4
Training loss: 2.1700663566589355
Validation loss: 2.099774532420661

Epoch: 6| Step: 5
Training loss: 2.065675973892212
Validation loss: 2.0993866997380413

Epoch: 6| Step: 6
Training loss: 1.7750152349472046
Validation loss: 2.074271330269434

Epoch: 6| Step: 7
Training loss: 2.514143705368042
Validation loss: 2.0798601181276384

Epoch: 6| Step: 8
Training loss: 1.6630769968032837
Validation loss: 2.072861848338958

Epoch: 6| Step: 9
Training loss: 2.1261491775512695
Validation loss: 2.063441325259465

Epoch: 6| Step: 10
Training loss: 1.7385377883911133
Validation loss: 2.1090244144521733

Epoch: 6| Step: 11
Training loss: 2.1738052368164062
Validation loss: 2.083111111835767

Epoch: 6| Step: 12
Training loss: 2.1338319778442383
Validation loss: 2.085223905501827

Epoch: 6| Step: 13
Training loss: 2.44111704826355
Validation loss: 2.109607414532733

Epoch: 148| Step: 0
Training loss: 2.388317108154297
Validation loss: 2.0661822980450046

Epoch: 6| Step: 1
Training loss: 2.1055617332458496
Validation loss: 2.0942187181083103

Epoch: 6| Step: 2
Training loss: 2.1583502292633057
Validation loss: 2.0753733829785417

Epoch: 6| Step: 3
Training loss: 2.336026430130005
Validation loss: 2.1060718797868296

Epoch: 6| Step: 4
Training loss: 2.246025562286377
Validation loss: 2.1024431464492634

Epoch: 6| Step: 5
Training loss: 1.7413544654846191
Validation loss: 2.0784292579979025

Epoch: 6| Step: 6
Training loss: 2.172092914581299
Validation loss: 2.0896646309924383

Epoch: 6| Step: 7
Training loss: 1.8736166954040527
Validation loss: 2.0602934232322117

Epoch: 6| Step: 8
Training loss: 1.6961725950241089
Validation loss: 2.0904628461407078

Epoch: 6| Step: 9
Training loss: 2.2240543365478516
Validation loss: 2.1097138774010444

Epoch: 6| Step: 10
Training loss: 1.5010530948638916
Validation loss: 2.0822089641324935

Epoch: 6| Step: 11
Training loss: 1.7340598106384277
Validation loss: 2.1186702815435265

Epoch: 6| Step: 12
Training loss: 2.3763020038604736
Validation loss: 2.1186398844565115

Epoch: 6| Step: 13
Training loss: 2.3565990924835205
Validation loss: 2.053462069521668

Epoch: 149| Step: 0
Training loss: 1.4550210237503052
Validation loss: 2.073525715899724

Epoch: 6| Step: 1
Training loss: 2.473393678665161
Validation loss: 2.1074660785736574

Epoch: 6| Step: 2
Training loss: 1.994707465171814
Validation loss: 2.0729911788817375

Epoch: 6| Step: 3
Training loss: 1.640613079071045
Validation loss: 2.0650470974624797

Epoch: 6| Step: 4
Training loss: 2.574615001678467
Validation loss: 2.0636117637798352

Epoch: 6| Step: 5
Training loss: 2.049229860305786
Validation loss: 2.0775785856349493

Epoch: 6| Step: 6
Training loss: 1.7744910717010498
Validation loss: 2.0983645659621044

Epoch: 6| Step: 7
Training loss: 2.6051487922668457
Validation loss: 2.083199208782565

Epoch: 6| Step: 8
Training loss: 1.7329230308532715
Validation loss: 2.0841390548213834

Epoch: 6| Step: 9
Training loss: 2.4059159755706787
Validation loss: 2.085402804036294

Epoch: 6| Step: 10
Training loss: 2.046876907348633
Validation loss: 2.0946442375900927

Epoch: 6| Step: 11
Training loss: 1.4885989427566528
Validation loss: 2.0873161259517876

Epoch: 6| Step: 12
Training loss: 2.1738996505737305
Validation loss: 2.0791751979499735

Epoch: 6| Step: 13
Training loss: 1.6577731370925903
Validation loss: 2.076668511154831

Epoch: 150| Step: 0
Training loss: 2.4124014377593994
Validation loss: 2.0787771671049056

Epoch: 6| Step: 1
Training loss: 2.8544442653656006
Validation loss: 2.090631595221899

Epoch: 6| Step: 2
Training loss: 1.250166654586792
Validation loss: 2.101353309487784

Epoch: 6| Step: 3
Training loss: 1.4066181182861328
Validation loss: 2.103885939044337

Epoch: 6| Step: 4
Training loss: 1.9605320692062378
Validation loss: 2.1243471202029975

Epoch: 6| Step: 5
Training loss: 1.8197999000549316
Validation loss: 2.0871892180494083

Epoch: 6| Step: 6
Training loss: 2.078679084777832
Validation loss: 2.07802999916897

Epoch: 6| Step: 7
Training loss: 2.550551652908325
Validation loss: 2.0677101689000286

Epoch: 6| Step: 8
Training loss: 2.2511937618255615
Validation loss: 2.093753432714811

Epoch: 6| Step: 9
Training loss: 2.6311914920806885
Validation loss: 2.0798845880775043

Epoch: 6| Step: 10
Training loss: 1.3724443912506104
Validation loss: 2.0644750441274335

Epoch: 6| Step: 11
Training loss: 1.850879430770874
Validation loss: 2.0742038014114543

Epoch: 6| Step: 12
Training loss: 1.5132179260253906
Validation loss: 2.0792807135530698

Epoch: 6| Step: 13
Training loss: 2.428189516067505
Validation loss: 2.1049445470174155

Epoch: 151| Step: 0
Training loss: 1.8772239685058594
Validation loss: 2.1099548519298597

Epoch: 6| Step: 1
Training loss: 1.8999125957489014
Validation loss: 2.1021206378936768

Epoch: 6| Step: 2
Training loss: 3.0981082916259766
Validation loss: 2.1027641193841093

Epoch: 6| Step: 3
Training loss: 1.9558480978012085
Validation loss: 2.058702274035382

Epoch: 6| Step: 4
Training loss: 1.6662334203720093
Validation loss: 2.100521690102034

Epoch: 6| Step: 5
Training loss: 1.5609564781188965
Validation loss: 2.0514206886291504

Epoch: 6| Step: 6
Training loss: 1.5476477146148682
Validation loss: 2.0933304653372815

Epoch: 6| Step: 7
Training loss: 2.260206699371338
Validation loss: 2.0566808997943835

Epoch: 6| Step: 8
Training loss: 1.834145426750183
Validation loss: 2.11553160349528

Epoch: 6| Step: 9
Training loss: 1.8191207647323608
Validation loss: 2.084774109625047

Epoch: 6| Step: 10
Training loss: 2.3094592094421387
Validation loss: 2.095612751540317

Epoch: 6| Step: 11
Training loss: 2.037879705429077
Validation loss: 2.0619696122343822

Epoch: 6| Step: 12
Training loss: 2.6282596588134766
Validation loss: 2.0954956162360405

Epoch: 6| Step: 13
Training loss: 2.104038715362549
Validation loss: 2.0871621780498053

Epoch: 152| Step: 0
Training loss: 1.4979078769683838
Validation loss: 2.0843901544488888

Epoch: 6| Step: 1
Training loss: 2.0877695083618164
Validation loss: 2.088359994273032

Epoch: 6| Step: 2
Training loss: 2.5559334754943848
Validation loss: 2.0799033718724407

Epoch: 6| Step: 3
Training loss: 1.859502911567688
Validation loss: 2.093188989546991

Epoch: 6| Step: 4
Training loss: 1.4073436260223389
Validation loss: 2.0870796775305145

Epoch: 6| Step: 5
Training loss: 2.3281688690185547
Validation loss: 2.0991395237625285

Epoch: 6| Step: 6
Training loss: 2.8940253257751465
Validation loss: 2.069071456950198

Epoch: 6| Step: 7
Training loss: 2.189490795135498
Validation loss: 2.0480052412197156

Epoch: 6| Step: 8
Training loss: 2.157017230987549
Validation loss: 2.0624857333398636

Epoch: 6| Step: 9
Training loss: 1.992553949356079
Validation loss: 2.0831830206737725

Epoch: 6| Step: 10
Training loss: 2.231747627258301
Validation loss: 2.0528662102196806

Epoch: 6| Step: 11
Training loss: 1.5510536432266235
Validation loss: 2.106412649154663

Epoch: 6| Step: 12
Training loss: 1.8156801462173462
Validation loss: 2.0669920290670087

Epoch: 6| Step: 13
Training loss: 1.8456965684890747
Validation loss: 2.0554653418961393

Epoch: 153| Step: 0
Training loss: 1.1070531606674194
Validation loss: 2.094154910374713

Epoch: 6| Step: 1
Training loss: 1.7539379596710205
Validation loss: 2.089303555027131

Epoch: 6| Step: 2
Training loss: 2.2638204097747803
Validation loss: 2.05891114793798

Epoch: 6| Step: 3
Training loss: 1.7523465156555176
Validation loss: 2.074417209112516

Epoch: 6| Step: 4
Training loss: 2.461935043334961
Validation loss: 2.1110958258310952

Epoch: 6| Step: 5
Training loss: 2.7764978408813477
Validation loss: 2.0927563790352113

Epoch: 6| Step: 6
Training loss: 1.4424151182174683
Validation loss: 2.080788790538747

Epoch: 6| Step: 7
Training loss: 2.5363430976867676
Validation loss: 2.087422873384209

Epoch: 6| Step: 8
Training loss: 1.406619668006897
Validation loss: 2.0780719851934784

Epoch: 6| Step: 9
Training loss: 1.8200603723526
Validation loss: 2.0784139735724336

Epoch: 6| Step: 10
Training loss: 2.535879611968994
Validation loss: 2.0962779111759637

Epoch: 6| Step: 11
Training loss: 2.089437484741211
Validation loss: 2.047200528524255

Epoch: 6| Step: 12
Training loss: 1.9406192302703857
Validation loss: 2.0601983506192445

Epoch: 6| Step: 13
Training loss: 3.278613567352295
Validation loss: 2.0952536470146588

Epoch: 154| Step: 0
Training loss: 1.5411015748977661
Validation loss: 2.0777185322136007

Epoch: 6| Step: 1
Training loss: 2.2305586338043213
Validation loss: 2.063277744477795

Epoch: 6| Step: 2
Training loss: 2.00577712059021
Validation loss: 2.065507677293593

Epoch: 6| Step: 3
Training loss: 1.9916090965270996
Validation loss: 2.077499343502906

Epoch: 6| Step: 4
Training loss: 1.8399467468261719
Validation loss: 2.1075081158709783

Epoch: 6| Step: 5
Training loss: 1.8332905769348145
Validation loss: 2.093771867854621

Epoch: 6| Step: 6
Training loss: 3.3349366188049316
Validation loss: 2.0735434473201795

Epoch: 6| Step: 7
Training loss: 1.6003750562667847
Validation loss: 2.045087883549352

Epoch: 6| Step: 8
Training loss: 2.114177703857422
Validation loss: 2.0841172023486068

Epoch: 6| Step: 9
Training loss: 2.208672285079956
Validation loss: 2.084745583995696

Epoch: 6| Step: 10
Training loss: 1.8329702615737915
Validation loss: 2.10381902674193

Epoch: 6| Step: 11
Training loss: 2.1026787757873535
Validation loss: 2.0725675231666973

Epoch: 6| Step: 12
Training loss: 1.6905999183654785
Validation loss: 2.09284685760416

Epoch: 6| Step: 13
Training loss: 1.765878438949585
Validation loss: 2.1165720673017603

Epoch: 155| Step: 0
Training loss: 1.1183760166168213
Validation loss: 2.077008935712999

Epoch: 6| Step: 1
Training loss: 1.4217000007629395
Validation loss: 2.0782292504464426

Epoch: 6| Step: 2
Training loss: 2.0495715141296387
Validation loss: 2.0609742197939145

Epoch: 6| Step: 3
Training loss: 2.7591123580932617
Validation loss: 2.042197286441762

Epoch: 6| Step: 4
Training loss: 2.15944242477417
Validation loss: 2.0669067482794485

Epoch: 6| Step: 5
Training loss: 1.5973401069641113
Validation loss: 2.07174769268241

Epoch: 6| Step: 6
Training loss: 2.2726283073425293
Validation loss: 2.1041208185175413

Epoch: 6| Step: 7
Training loss: 2.2013916969299316
Validation loss: 2.0764453898194017

Epoch: 6| Step: 8
Training loss: 1.970532774925232
Validation loss: 2.0757211536489506

Epoch: 6| Step: 9
Training loss: 2.2465500831604004
Validation loss: 2.082936518935747

Epoch: 6| Step: 10
Training loss: 1.450360655784607
Validation loss: 2.0770571718933764

Epoch: 6| Step: 11
Training loss: 2.2259230613708496
Validation loss: 2.117324759883265

Epoch: 6| Step: 12
Training loss: 2.2377066612243652
Validation loss: 2.0960779984792075

Epoch: 6| Step: 13
Training loss: 2.5388758182525635
Validation loss: 2.055721631614111

Epoch: 156| Step: 0
Training loss: 1.6489815711975098
Validation loss: 2.061612685521444

Epoch: 6| Step: 1
Training loss: 2.222240924835205
Validation loss: 2.0423732085894515

Epoch: 6| Step: 2
Training loss: 1.7569222450256348
Validation loss: 2.0510675214952037

Epoch: 6| Step: 3
Training loss: 1.960367202758789
Validation loss: 2.080817840432608

Epoch: 6| Step: 4
Training loss: 2.3408944606781006
Validation loss: 2.0600491646797425

Epoch: 6| Step: 5
Training loss: 2.304888963699341
Validation loss: 2.1222554419630315

Epoch: 6| Step: 6
Training loss: 1.9675285816192627
Validation loss: 2.0771556926029984

Epoch: 6| Step: 7
Training loss: 1.7381126880645752
Validation loss: 2.090063538602603

Epoch: 6| Step: 8
Training loss: 2.256319761276245
Validation loss: 2.054352129659345

Epoch: 6| Step: 9
Training loss: 1.9373929500579834
Validation loss: 2.1267226895978375

Epoch: 6| Step: 10
Training loss: 1.9997766017913818
Validation loss: 2.083444397936585

Epoch: 6| Step: 11
Training loss: 1.7765504121780396
Validation loss: 2.1135456074950514

Epoch: 6| Step: 12
Training loss: 2.6149022579193115
Validation loss: 2.130586221653928

Epoch: 6| Step: 13
Training loss: 1.3625673055648804
Validation loss: 2.075020081253462

Epoch: 157| Step: 0
Training loss: 2.3088221549987793
Validation loss: 2.082315109109366

Epoch: 6| Step: 1
Training loss: 2.135591506958008
Validation loss: 2.0757079829451857

Epoch: 6| Step: 2
Training loss: 2.2206647396087646
Validation loss: 2.0652411342948995

Epoch: 6| Step: 3
Training loss: 1.747215747833252
Validation loss: 2.0390102901766376

Epoch: 6| Step: 4
Training loss: 1.9343862533569336
Validation loss: 2.0639302986924366

Epoch: 6| Step: 5
Training loss: 1.8537209033966064
Validation loss: 2.0674751984175814

Epoch: 6| Step: 6
Training loss: 2.8848695755004883
Validation loss: 2.0647573624887774

Epoch: 6| Step: 7
Training loss: 2.2431740760803223
Validation loss: 2.0769556876151793

Epoch: 6| Step: 8
Training loss: 1.7610048055648804
Validation loss: 2.0698903478601927

Epoch: 6| Step: 9
Training loss: 1.682302474975586
Validation loss: 2.095598492571103

Epoch: 6| Step: 10
Training loss: 1.2928695678710938
Validation loss: 2.0574907692529822

Epoch: 6| Step: 11
Training loss: 2.4765825271606445
Validation loss: 2.0936448343338503

Epoch: 6| Step: 12
Training loss: 2.283322334289551
Validation loss: 2.0755100109243907

Epoch: 6| Step: 13
Training loss: 1.1001040935516357
Validation loss: 2.0744285839860157

Epoch: 158| Step: 0
Training loss: 1.5813329219818115
Validation loss: 2.0527167204887635

Epoch: 6| Step: 1
Training loss: 1.9181995391845703
Validation loss: 2.1223194214605514

Epoch: 6| Step: 2
Training loss: 2.9493961334228516
Validation loss: 2.091804236494085

Epoch: 6| Step: 3
Training loss: 1.6087679862976074
Validation loss: 2.099263637296615

Epoch: 6| Step: 4
Training loss: 2.0622246265411377
Validation loss: 2.0787284194782214

Epoch: 6| Step: 5
Training loss: 2.0151548385620117
Validation loss: 2.0601476161710677

Epoch: 6| Step: 6
Training loss: 2.18973708152771
Validation loss: 2.0539005341068393

Epoch: 6| Step: 7
Training loss: 2.2461800575256348
Validation loss: 2.073407229556832

Epoch: 6| Step: 8
Training loss: 1.9497255086898804
Validation loss: 2.0908700112373597

Epoch: 6| Step: 9
Training loss: 2.0437610149383545
Validation loss: 2.052432897270367

Epoch: 6| Step: 10
Training loss: 2.1422908306121826
Validation loss: 2.069139535709094

Epoch: 6| Step: 11
Training loss: 1.8856873512268066
Validation loss: 2.077848453675547

Epoch: 6| Step: 12
Training loss: 1.6648060083389282
Validation loss: 2.088408076634971

Epoch: 6| Step: 13
Training loss: 1.8267817497253418
Validation loss: 2.048304065581291

Epoch: 159| Step: 0
Training loss: 2.5065107345581055
Validation loss: 2.0260963824487503

Epoch: 6| Step: 1
Training loss: 2.8641066551208496
Validation loss: 2.0869984780588458

Epoch: 6| Step: 2
Training loss: 1.1803500652313232
Validation loss: 2.104715557508571

Epoch: 6| Step: 3
Training loss: 2.9178104400634766
Validation loss: 2.069920083527924

Epoch: 6| Step: 4
Training loss: 1.5387152433395386
Validation loss: 2.0724108603692826

Epoch: 6| Step: 5
Training loss: 1.3306238651275635
Validation loss: 2.053959369659424

Epoch: 6| Step: 6
Training loss: 2.219708204269409
Validation loss: 2.082053622891826

Epoch: 6| Step: 7
Training loss: 2.2961721420288086
Validation loss: 2.0954933115231094

Epoch: 6| Step: 8
Training loss: 2.03981351852417
Validation loss: 2.132220196467574

Epoch: 6| Step: 9
Training loss: 2.2311007976531982
Validation loss: 2.076035830282396

Epoch: 6| Step: 10
Training loss: 1.7472540140151978
Validation loss: 2.0765527884165444

Epoch: 6| Step: 11
Training loss: 1.5122053623199463
Validation loss: 2.0527262162136775

Epoch: 6| Step: 12
Training loss: 1.576145887374878
Validation loss: 2.085672350339992

Epoch: 6| Step: 13
Training loss: 1.486459732055664
Validation loss: 2.0681286293973207

Epoch: 160| Step: 0
Training loss: 1.475650429725647
Validation loss: 2.122131170765046

Epoch: 6| Step: 1
Training loss: 2.0990288257598877
Validation loss: 2.0739415050834737

Epoch: 6| Step: 2
Training loss: 1.845247745513916
Validation loss: 2.030562439272481

Epoch: 6| Step: 3
Training loss: 1.792983889579773
Validation loss: 2.083576517720376

Epoch: 6| Step: 4
Training loss: 2.2855043411254883
Validation loss: 2.049307686026378

Epoch: 6| Step: 5
Training loss: 1.7605115175247192
Validation loss: 2.0874329279827815

Epoch: 6| Step: 6
Training loss: 2.433985710144043
Validation loss: 2.054175120528026

Epoch: 6| Step: 7
Training loss: 1.9013820886611938
Validation loss: 2.0903478104581117

Epoch: 6| Step: 8
Training loss: 1.8421469926834106
Validation loss: 2.1010087882318804

Epoch: 6| Step: 9
Training loss: 2.3103079795837402
Validation loss: 2.08819777734818

Epoch: 6| Step: 10
Training loss: 2.0844242572784424
Validation loss: 2.11311936378479

Epoch: 6| Step: 11
Training loss: 2.1135830879211426
Validation loss: 2.059246160650766

Epoch: 6| Step: 12
Training loss: 2.0050206184387207
Validation loss: 2.058514879595849

Epoch: 6| Step: 13
Training loss: 1.6888728141784668
Validation loss: 2.093327345386628

Epoch: 161| Step: 0
Training loss: 1.8240901231765747
Validation loss: 2.0991086588110974

Epoch: 6| Step: 1
Training loss: 1.1889790296554565
Validation loss: 2.083680909167054

Epoch: 6| Step: 2
Training loss: 2.2474050521850586
Validation loss: 2.11052062947263

Epoch: 6| Step: 3
Training loss: 2.428783416748047
Validation loss: 2.091550450171194

Epoch: 6| Step: 4
Training loss: 1.6207389831542969
Validation loss: 2.0677333775387017

Epoch: 6| Step: 5
Training loss: 2.4048104286193848
Validation loss: 2.0803187688191733

Epoch: 6| Step: 6
Training loss: 1.8985998630523682
Validation loss: 2.050750635003531

Epoch: 6| Step: 7
Training loss: 2.585439443588257
Validation loss: 2.1002447233405164

Epoch: 6| Step: 8
Training loss: 1.6917991638183594
Validation loss: 2.08600212425314

Epoch: 6| Step: 9
Training loss: 2.8233699798583984
Validation loss: 2.0312659983993857

Epoch: 6| Step: 10
Training loss: 2.080505132675171
Validation loss: 2.084749719148041

Epoch: 6| Step: 11
Training loss: 1.1880595684051514
Validation loss: 2.044182382604127

Epoch: 6| Step: 12
Training loss: 1.6135756969451904
Validation loss: 2.0146097111445602

Epoch: 6| Step: 13
Training loss: 2.4269707202911377
Validation loss: 2.0851386452233918

Epoch: 162| Step: 0
Training loss: 1.8829445838928223
Validation loss: 2.0814537168830953

Epoch: 6| Step: 1
Training loss: 1.608151912689209
Validation loss: 2.081137672547371

Epoch: 6| Step: 2
Training loss: 3.1369266510009766
Validation loss: 2.0730337673617947

Epoch: 6| Step: 3
Training loss: 1.4933992624282837
Validation loss: 2.101073590658044

Epoch: 6| Step: 4
Training loss: 2.3026347160339355
Validation loss: 2.0301994687767437

Epoch: 6| Step: 5
Training loss: 1.7817766666412354
Validation loss: 2.069309138482617

Epoch: 6| Step: 6
Training loss: 1.8219525814056396
Validation loss: 2.092702696400304

Epoch: 6| Step: 7
Training loss: 1.3781946897506714
Validation loss: 2.0653539626829085

Epoch: 6| Step: 8
Training loss: 1.937751054763794
Validation loss: 2.0949056045983427

Epoch: 6| Step: 9
Training loss: 1.670528531074524
Validation loss: 2.087964875723726

Epoch: 6| Step: 10
Training loss: 2.3493897914886475
Validation loss: 2.047562993982787

Epoch: 6| Step: 11
Training loss: 2.015326738357544
Validation loss: 2.0230485918701335

Epoch: 6| Step: 12
Training loss: 2.408811330795288
Validation loss: 2.0759659864569224

Epoch: 6| Step: 13
Training loss: 1.3523828983306885
Validation loss: 2.049158218086407

Epoch: 163| Step: 0
Training loss: 1.333176612854004
Validation loss: 2.054823237080728

Epoch: 6| Step: 1
Training loss: 2.2847259044647217
Validation loss: 2.0967273968522266

Epoch: 6| Step: 2
Training loss: 1.4730266332626343
Validation loss: 2.0288582873600784

Epoch: 6| Step: 3
Training loss: 2.0181875228881836
Validation loss: 2.0609468772847164

Epoch: 6| Step: 4
Training loss: 2.3275458812713623
Validation loss: 2.0874750716711885

Epoch: 6| Step: 5
Training loss: 2.4309661388397217
Validation loss: 2.036637701014037

Epoch: 6| Step: 6
Training loss: 2.7714338302612305
Validation loss: 2.0428035438701673

Epoch: 6| Step: 7
Training loss: 1.7238311767578125
Validation loss: 2.0687483074844524

Epoch: 6| Step: 8
Training loss: 2.8625669479370117
Validation loss: 2.0826795831803353

Epoch: 6| Step: 9
Training loss: 2.182375431060791
Validation loss: 2.073121060607254

Epoch: 6| Step: 10
Training loss: 1.6512237787246704
Validation loss: 2.0645301854738625

Epoch: 6| Step: 11
Training loss: 1.850914716720581
Validation loss: 2.0865456711861396

Epoch: 6| Step: 12
Training loss: 1.5314184427261353
Validation loss: 2.0430508326458674

Epoch: 6| Step: 13
Training loss: 1.2963958978652954
Validation loss: 2.046101870075349

Epoch: 164| Step: 0
Training loss: 1.4550913572311401
Validation loss: 2.0536945327635734

Epoch: 6| Step: 1
Training loss: 1.6794507503509521
Validation loss: 2.0851407204904864

Epoch: 6| Step: 2
Training loss: 1.7436715364456177
Validation loss: 2.070233165576894

Epoch: 6| Step: 3
Training loss: 1.243485927581787
Validation loss: 2.1091367198574926

Epoch: 6| Step: 4
Training loss: 2.43984317779541
Validation loss: 2.0550942228686426

Epoch: 6| Step: 5
Training loss: 2.6758408546447754
Validation loss: 2.0934505693374144

Epoch: 6| Step: 6
Training loss: 1.968388557434082
Validation loss: 2.0726099168100665

Epoch: 6| Step: 7
Training loss: 2.248711347579956
Validation loss: 2.1183844689399964

Epoch: 6| Step: 8
Training loss: 1.6333261728286743
Validation loss: 2.1080114046732583

Epoch: 6| Step: 9
Training loss: 2.193422794342041
Validation loss: 2.072219056467856

Epoch: 6| Step: 10
Training loss: 1.653914451599121
Validation loss: 2.088946152758855

Epoch: 6| Step: 11
Training loss: 2.5006003379821777
Validation loss: 2.0729594435743106

Epoch: 6| Step: 12
Training loss: 2.6839001178741455
Validation loss: 2.0820824369307487

Epoch: 6| Step: 13
Training loss: 2.080385208129883
Validation loss: 2.064921550853278

Epoch: 165| Step: 0
Training loss: 1.8940240144729614
Validation loss: 2.119427569450871

Epoch: 6| Step: 1
Training loss: 1.939860224723816
Validation loss: 2.0560718915795766

Epoch: 6| Step: 2
Training loss: 1.5713037252426147
Validation loss: 2.116239668220602

Epoch: 6| Step: 3
Training loss: 1.5359649658203125
Validation loss: 2.0849582123500046

Epoch: 6| Step: 4
Training loss: 2.079148054122925
Validation loss: 2.076343513304187

Epoch: 6| Step: 5
Training loss: 2.07102632522583
Validation loss: 2.0599655156494467

Epoch: 6| Step: 6
Training loss: 1.7055426836013794
Validation loss: 2.061062692314066

Epoch: 6| Step: 7
Training loss: 1.0904490947723389
Validation loss: 2.04883300617177

Epoch: 6| Step: 8
Training loss: 2.2805044651031494
Validation loss: 2.074355932974046

Epoch: 6| Step: 9
Training loss: 1.6325478553771973
Validation loss: 2.0461960287504297

Epoch: 6| Step: 10
Training loss: 2.24878191947937
Validation loss: 2.0532290486879248

Epoch: 6| Step: 11
Training loss: 2.3648743629455566
Validation loss: 2.0816756499710904

Epoch: 6| Step: 12
Training loss: 2.905372142791748
Validation loss: 2.0399056852504773

Epoch: 6| Step: 13
Training loss: 2.5530405044555664
Validation loss: 2.05262658544766

Epoch: 166| Step: 0
Training loss: 2.3170557022094727
Validation loss: 2.01468889944015

Epoch: 6| Step: 1
Training loss: 1.5414378643035889
Validation loss: 2.089100710807308

Epoch: 6| Step: 2
Training loss: 2.036287307739258
Validation loss: 2.050916479479882

Epoch: 6| Step: 3
Training loss: 2.3517773151397705
Validation loss: 2.0702007791047454

Epoch: 6| Step: 4
Training loss: 2.1847352981567383
Validation loss: 2.080534806815527

Epoch: 6| Step: 5
Training loss: 1.90799880027771
Validation loss: 2.0563557096706924

Epoch: 6| Step: 6
Training loss: 2.2442073822021484
Validation loss: 2.095556661646853

Epoch: 6| Step: 7
Training loss: 1.2421574592590332
Validation loss: 2.041691518598987

Epoch: 6| Step: 8
Training loss: 2.5119402408599854
Validation loss: 2.0775167454955397

Epoch: 6| Step: 9
Training loss: 1.7656363248825073
Validation loss: 2.1011316981366885

Epoch: 6| Step: 10
Training loss: 1.9097341299057007
Validation loss: 2.0597886667456677

Epoch: 6| Step: 11
Training loss: 1.8956528902053833
Validation loss: 2.084005746790158

Epoch: 6| Step: 12
Training loss: 1.5784809589385986
Validation loss: 2.0830257938754175

Epoch: 6| Step: 13
Training loss: 2.7632036209106445
Validation loss: 2.1143466580298638

Epoch: 167| Step: 0
Training loss: 2.3141417503356934
Validation loss: 2.1124055334316787

Epoch: 6| Step: 1
Training loss: 2.2066657543182373
Validation loss: 2.075659687801074

Epoch: 6| Step: 2
Training loss: 1.733417272567749
Validation loss: 2.1040959896579867

Epoch: 6| Step: 3
Training loss: 2.0710608959198
Validation loss: 2.0840616982470275

Epoch: 6| Step: 4
Training loss: 1.5540250539779663
Validation loss: 2.0687214200214674

Epoch: 6| Step: 5
Training loss: 1.831425428390503
Validation loss: 2.1082252328113844

Epoch: 6| Step: 6
Training loss: 1.8176493644714355
Validation loss: 2.0843177764646468

Epoch: 6| Step: 7
Training loss: 1.817116379737854
Validation loss: 2.0630708996967604

Epoch: 6| Step: 8
Training loss: 1.5213743448257446
Validation loss: 2.094681719298004

Epoch: 6| Step: 9
Training loss: 2.2363038063049316
Validation loss: 2.0829728726417787

Epoch: 6| Step: 10
Training loss: 2.1944985389709473
Validation loss: 2.114666454253658

Epoch: 6| Step: 11
Training loss: 1.9190082550048828
Validation loss: 2.0491933617540585

Epoch: 6| Step: 12
Training loss: 2.4485862255096436
Validation loss: 2.0911221888757523

Epoch: 6| Step: 13
Training loss: 2.0364677906036377
Validation loss: 2.054478406906128

Epoch: 168| Step: 0
Training loss: 2.4065089225769043
Validation loss: 2.0620884485142206

Epoch: 6| Step: 1
Training loss: 1.7311758995056152
Validation loss: 2.064642375515353

Epoch: 6| Step: 2
Training loss: 2.0125436782836914
Validation loss: 2.063240381979173

Epoch: 6| Step: 3
Training loss: 2.5206947326660156
Validation loss: 2.0525994377751506

Epoch: 6| Step: 4
Training loss: 2.412973165512085
Validation loss: 2.0374185064787507

Epoch: 6| Step: 5
Training loss: 1.5798571109771729
Validation loss: 2.0531013140114407

Epoch: 6| Step: 6
Training loss: 2.1977224349975586
Validation loss: 2.0557005379789617

Epoch: 6| Step: 7
Training loss: 1.539093017578125
Validation loss: 2.036350219480453

Epoch: 6| Step: 8
Training loss: 1.7051907777786255
Validation loss: 2.0771460225505214

Epoch: 6| Step: 9
Training loss: 2.0527548789978027
Validation loss: 2.0067265238813174

Epoch: 6| Step: 10
Training loss: 1.665297031402588
Validation loss: 2.055031591846097

Epoch: 6| Step: 11
Training loss: 2.0555622577667236
Validation loss: 2.052669995574541

Epoch: 6| Step: 12
Training loss: 2.309929370880127
Validation loss: 2.0754050811131797

Epoch: 6| Step: 13
Training loss: 0.8995312452316284
Validation loss: 2.0876366758859284

Epoch: 169| Step: 0
Training loss: 1.6971580982208252
Validation loss: 2.063414266032557

Epoch: 6| Step: 1
Training loss: 2.1507210731506348
Validation loss: 2.050491625262845

Epoch: 6| Step: 2
Training loss: 1.9255741834640503
Validation loss: 2.044978082820933

Epoch: 6| Step: 3
Training loss: 2.9993977546691895
Validation loss: 2.050572495306692

Epoch: 6| Step: 4
Training loss: 1.883396029472351
Validation loss: 2.090105366963212

Epoch: 6| Step: 5
Training loss: 1.6952109336853027
Validation loss: 2.089867500848668

Epoch: 6| Step: 6
Training loss: 2.008505344390869
Validation loss: 2.0620698108468005

Epoch: 6| Step: 7
Training loss: 1.6107110977172852
Validation loss: 2.042535892096899

Epoch: 6| Step: 8
Training loss: 2.0656991004943848
Validation loss: 2.062325977510022

Epoch: 6| Step: 9
Training loss: 1.9623960256576538
Validation loss: 2.0536116374436246

Epoch: 6| Step: 10
Training loss: 1.9538159370422363
Validation loss: 2.062458269057735

Epoch: 6| Step: 11
Training loss: 2.127354621887207
Validation loss: 2.029983943508517

Epoch: 6| Step: 12
Training loss: 2.024515151977539
Validation loss: 2.046433251391175

Epoch: 6| Step: 13
Training loss: 1.2290736436843872
Validation loss: 2.062634362969347

Epoch: 170| Step: 0
Training loss: 2.234253406524658
Validation loss: 2.050740049731347

Epoch: 6| Step: 1
Training loss: 2.041105031967163
Validation loss: 2.034017385975007

Epoch: 6| Step: 2
Training loss: 3.0745582580566406
Validation loss: 2.0848629961731615

Epoch: 6| Step: 3
Training loss: 1.7299963235855103
Validation loss: 2.0487335087150655

Epoch: 6| Step: 4
Training loss: 2.615845203399658
Validation loss: 2.0569466980554725

Epoch: 6| Step: 5
Training loss: 2.1001877784729004
Validation loss: 2.0550322250653337

Epoch: 6| Step: 6
Training loss: 0.9292068481445312
Validation loss: 2.115122413122526

Epoch: 6| Step: 7
Training loss: 1.9521205425262451
Validation loss: 2.0313977887553554

Epoch: 6| Step: 8
Training loss: 2.038787603378296
Validation loss: 2.037831869176639

Epoch: 6| Step: 9
Training loss: 1.7641360759735107
Validation loss: 2.0281839191272693

Epoch: 6| Step: 10
Training loss: 1.8813776969909668
Validation loss: 2.050634353391586

Epoch: 6| Step: 11
Training loss: 1.2614868879318237
Validation loss: 2.062079632154075

Epoch: 6| Step: 12
Training loss: 1.8832470178604126
Validation loss: 2.056248628964988

Epoch: 6| Step: 13
Training loss: 1.976166844367981
Validation loss: 2.0978461721892

Epoch: 171| Step: 0
Training loss: 2.4456372261047363
Validation loss: 2.100048767623081

Epoch: 6| Step: 1
Training loss: 1.6274793148040771
Validation loss: 2.0764952987752934

Epoch: 6| Step: 2
Training loss: 1.6917792558670044
Validation loss: 2.0479387455089118

Epoch: 6| Step: 3
Training loss: 1.8228224515914917
Validation loss: 2.0943803505230973

Epoch: 6| Step: 4
Training loss: 1.5970244407653809
Validation loss: 2.053260298185451

Epoch: 6| Step: 5
Training loss: 1.7577316761016846
Validation loss: 2.0495958840975197

Epoch: 6| Step: 6
Training loss: 2.16959285736084
Validation loss: 2.0541596220385645

Epoch: 6| Step: 7
Training loss: 2.471363067626953
Validation loss: 2.046541711335541

Epoch: 6| Step: 8
Training loss: 2.153031349182129
Validation loss: 2.0790326390215146

Epoch: 6| Step: 9
Training loss: 2.0470635890960693
Validation loss: 2.0622935833469516

Epoch: 6| Step: 10
Training loss: 2.214841842651367
Validation loss: 2.0334351011501846

Epoch: 6| Step: 11
Training loss: 1.5571943521499634
Validation loss: 2.0788731754467054

Epoch: 6| Step: 12
Training loss: 1.7390567064285278
Validation loss: 2.0848455787986837

Epoch: 6| Step: 13
Training loss: 2.4877586364746094
Validation loss: 2.1017651763013614

Epoch: 172| Step: 0
Training loss: 1.771374225616455
Validation loss: 2.0577828679033505

Epoch: 6| Step: 1
Training loss: 1.1415674686431885
Validation loss: 2.085928696458058

Epoch: 6| Step: 2
Training loss: 1.6750125885009766
Validation loss: 2.0524149402495353

Epoch: 6| Step: 3
Training loss: 2.40816330909729
Validation loss: 2.056165833627024

Epoch: 6| Step: 4
Training loss: 2.4767706394195557
Validation loss: 2.067090421594599

Epoch: 6| Step: 5
Training loss: 1.6630864143371582
Validation loss: 2.0753851411163167

Epoch: 6| Step: 6
Training loss: 1.9497950077056885
Validation loss: 2.0638772954222975

Epoch: 6| Step: 7
Training loss: 2.070417881011963
Validation loss: 2.058373015414002

Epoch: 6| Step: 8
Training loss: 1.2661024332046509
Validation loss: 2.0302061521878807

Epoch: 6| Step: 9
Training loss: 2.621260643005371
Validation loss: 2.068681146508904

Epoch: 6| Step: 10
Training loss: 1.9172828197479248
Validation loss: 2.0812873942877657

Epoch: 6| Step: 11
Training loss: 2.0752508640289307
Validation loss: 2.075269747805852

Epoch: 6| Step: 12
Training loss: 1.918470859527588
Validation loss: 2.0441178506420505

Epoch: 6| Step: 13
Training loss: 2.6085216999053955
Validation loss: 2.0823280042217625

Epoch: 173| Step: 0
Training loss: 1.4450191259384155
Validation loss: 2.0878661178773448

Epoch: 6| Step: 1
Training loss: 2.63555908203125
Validation loss: 2.0662495449025142

Epoch: 6| Step: 2
Training loss: 1.5093235969543457
Validation loss: 2.079948432983891

Epoch: 6| Step: 3
Training loss: 2.054874897003174
Validation loss: 2.126806902629073

Epoch: 6| Step: 4
Training loss: 1.938549518585205
Validation loss: 2.052527545600809

Epoch: 6| Step: 5
Training loss: 1.977967619895935
Validation loss: 2.021030295279718

Epoch: 6| Step: 6
Training loss: 2.3774476051330566
Validation loss: 2.091035140457974

Epoch: 6| Step: 7
Training loss: 2.0068435668945312
Validation loss: 2.058170387821813

Epoch: 6| Step: 8
Training loss: 1.8712198734283447
Validation loss: 2.060931187804027

Epoch: 6| Step: 9
Training loss: 1.3039594888687134
Validation loss: 2.0535196053084506

Epoch: 6| Step: 10
Training loss: 1.9819049835205078
Validation loss: 2.0688205777957873

Epoch: 6| Step: 11
Training loss: 2.119940757751465
Validation loss: 2.070398292233867

Epoch: 6| Step: 12
Training loss: 2.3258860111236572
Validation loss: 2.053616977507068

Epoch: 6| Step: 13
Training loss: 1.886505365371704
Validation loss: 2.080362489146571

Epoch: 174| Step: 0
Training loss: 2.3844237327575684
Validation loss: 2.0577246450608775

Epoch: 6| Step: 1
Training loss: 2.151901960372925
Validation loss: 2.064376264490107

Epoch: 6| Step: 2
Training loss: 2.120227098464966
Validation loss: 2.065776873660344

Epoch: 6| Step: 3
Training loss: 2.6763782501220703
Validation loss: 2.121096455922691

Epoch: 6| Step: 4
Training loss: 1.253007173538208
Validation loss: 2.0421557170088573

Epoch: 6| Step: 5
Training loss: 1.6420588493347168
Validation loss: 2.0477198246986634

Epoch: 6| Step: 6
Training loss: 2.136711597442627
Validation loss: 2.056372624571605

Epoch: 6| Step: 7
Training loss: 1.3093369007110596
Validation loss: 2.072085121626495

Epoch: 6| Step: 8
Training loss: 1.8459563255310059
Validation loss: 2.082631846909882

Epoch: 6| Step: 9
Training loss: 3.299647808074951
Validation loss: 2.080005681642922

Epoch: 6| Step: 10
Training loss: 1.7808998823165894
Validation loss: 2.0896603240761706

Epoch: 6| Step: 11
Training loss: 1.8759181499481201
Validation loss: 2.0749339595917733

Epoch: 6| Step: 12
Training loss: 1.60788893699646
Validation loss: 2.0801153426529257

Epoch: 6| Step: 13
Training loss: 0.9893702268600464
Validation loss: 2.0188211753804195

Epoch: 175| Step: 0
Training loss: 1.882631540298462
Validation loss: 2.0563651810410204

Epoch: 6| Step: 1
Training loss: 1.9100110530853271
Validation loss: 2.0479446021459435

Epoch: 6| Step: 2
Training loss: 1.6702734231948853
Validation loss: 2.0376846123767156

Epoch: 6| Step: 3
Training loss: 1.9048045873641968
Validation loss: 2.051336896034979

Epoch: 6| Step: 4
Training loss: 1.8063373565673828
Validation loss: 2.050616092579339

Epoch: 6| Step: 5
Training loss: 1.4336384534835815
Validation loss: 2.0531146193063385

Epoch: 6| Step: 6
Training loss: 2.361079454421997
Validation loss: 2.0391152520333566

Epoch: 6| Step: 7
Training loss: 2.5267081260681152
Validation loss: 2.058921462746077

Epoch: 6| Step: 8
Training loss: 1.4658470153808594
Validation loss: 2.0518323195877897

Epoch: 6| Step: 9
Training loss: 1.7282509803771973
Validation loss: 2.063019150046892

Epoch: 6| Step: 10
Training loss: 1.9360051155090332
Validation loss: 2.029723767311342

Epoch: 6| Step: 11
Training loss: 2.2296125888824463
Validation loss: 2.0340402510858353

Epoch: 6| Step: 12
Training loss: 2.119050979614258
Validation loss: 2.0452172935649915

Epoch: 6| Step: 13
Training loss: 2.5717620849609375
Validation loss: 2.0606725369730303

Epoch: 176| Step: 0
Training loss: 3.287285327911377
Validation loss: 2.032534312176448

Epoch: 6| Step: 1
Training loss: 1.5961443185806274
Validation loss: 2.0558157326072775

Epoch: 6| Step: 2
Training loss: 1.7021121978759766
Validation loss: 2.059989752308015

Epoch: 6| Step: 3
Training loss: 2.7177553176879883
Validation loss: 2.032645938216999

Epoch: 6| Step: 4
Training loss: 2.0675010681152344
Validation loss: 2.0331215422640563

Epoch: 6| Step: 5
Training loss: 1.9551873207092285
Validation loss: 2.0206104209346156

Epoch: 6| Step: 6
Training loss: 1.8175239562988281
Validation loss: 2.069543551373225

Epoch: 6| Step: 7
Training loss: 2.051612377166748
Validation loss: 2.050434192021688

Epoch: 6| Step: 8
Training loss: 2.22469162940979
Validation loss: 2.042369479774147

Epoch: 6| Step: 9
Training loss: 1.5503132343292236
Validation loss: 2.0441519906443935

Epoch: 6| Step: 10
Training loss: 1.1560790538787842
Validation loss: 2.0285321140802033

Epoch: 6| Step: 11
Training loss: 1.7157058715820312
Validation loss: 2.049177856855495

Epoch: 6| Step: 12
Training loss: 1.584091067314148
Validation loss: 2.066315943194974

Epoch: 6| Step: 13
Training loss: 2.0343992710113525
Validation loss: 2.0199660383244997

Epoch: 177| Step: 0
Training loss: 1.3337171077728271
Validation loss: 2.0495627054604153

Epoch: 6| Step: 1
Training loss: 1.4347035884857178
Validation loss: 2.052877728657056

Epoch: 6| Step: 2
Training loss: 2.8008298873901367
Validation loss: 2.06708352540129

Epoch: 6| Step: 3
Training loss: 2.3562731742858887
Validation loss: 2.0544738051711873

Epoch: 6| Step: 4
Training loss: 1.4640905857086182
Validation loss: 2.0795410217777377

Epoch: 6| Step: 5
Training loss: 2.533221483230591
Validation loss: 2.058298626253682

Epoch: 6| Step: 6
Training loss: 2.016462802886963
Validation loss: 2.0465663863766577

Epoch: 6| Step: 7
Training loss: 2.1796064376831055
Validation loss: 2.034592964315927

Epoch: 6| Step: 8
Training loss: 2.1560657024383545
Validation loss: 2.063642014739334

Epoch: 6| Step: 9
Training loss: 1.944263219833374
Validation loss: 2.041145618243884

Epoch: 6| Step: 10
Training loss: 2.039541482925415
Validation loss: 2.059860501238095

Epoch: 6| Step: 11
Training loss: 1.6225380897521973
Validation loss: 2.035211270855319

Epoch: 6| Step: 12
Training loss: 1.953607201576233
Validation loss: 2.041754532885808

Epoch: 6| Step: 13
Training loss: 1.316373586654663
Validation loss: 2.043073249119584

Epoch: 178| Step: 0
Training loss: 2.1460304260253906
Validation loss: 2.049045507625867

Epoch: 6| Step: 1
Training loss: 1.6094598770141602
Validation loss: 2.0370771500372116

Epoch: 6| Step: 2
Training loss: 1.0771512985229492
Validation loss: 2.0309301140487834

Epoch: 6| Step: 3
Training loss: 2.232862949371338
Validation loss: 2.0509562774371077

Epoch: 6| Step: 4
Training loss: 1.7290040254592896
Validation loss: 2.0623440537401425

Epoch: 6| Step: 5
Training loss: 2.478144645690918
Validation loss: 2.0089067823143414

Epoch: 6| Step: 6
Training loss: 1.864194631576538
Validation loss: 2.025868288932308

Epoch: 6| Step: 7
Training loss: 2.47029185295105
Validation loss: 2.02306116268199

Epoch: 6| Step: 8
Training loss: 1.9076529741287231
Validation loss: 2.009516616021433

Epoch: 6| Step: 9
Training loss: 2.3385009765625
Validation loss: 2.0095746235180925

Epoch: 6| Step: 10
Training loss: 2.223555088043213
Validation loss: 2.0558760986533215

Epoch: 6| Step: 11
Training loss: 1.87221097946167
Validation loss: 2.0479090265048447

Epoch: 6| Step: 12
Training loss: 1.3281381130218506
Validation loss: 2.0568826454941944

Epoch: 6| Step: 13
Training loss: 1.5746779441833496
Validation loss: 2.0421167291620725

Epoch: 179| Step: 0
Training loss: 2.0955796241760254
Validation loss: 2.0831021929299958

Epoch: 6| Step: 1
Training loss: 1.898245930671692
Validation loss: 2.0090813047142437

Epoch: 6| Step: 2
Training loss: 1.5120489597320557
Validation loss: 2.06430676931976

Epoch: 6| Step: 3
Training loss: 1.961754322052002
Validation loss: 2.0579625560391333

Epoch: 6| Step: 4
Training loss: 1.3001773357391357
Validation loss: 2.071061897021468

Epoch: 6| Step: 5
Training loss: 1.5713989734649658
Validation loss: 2.0562759099468106

Epoch: 6| Step: 6
Training loss: 1.6503047943115234
Validation loss: 2.071134594178969

Epoch: 6| Step: 7
Training loss: 2.1193060874938965
Validation loss: 2.0446900808683006

Epoch: 6| Step: 8
Training loss: 1.5961132049560547
Validation loss: 2.0768374371272262

Epoch: 6| Step: 9
Training loss: 2.2244081497192383
Validation loss: 2.080332386878229

Epoch: 6| Step: 10
Training loss: 1.720235824584961
Validation loss: 2.0784963792370212

Epoch: 6| Step: 11
Training loss: 2.9364728927612305
Validation loss: 2.0093142947843

Epoch: 6| Step: 12
Training loss: 2.463956832885742
Validation loss: 2.0304956000338317

Epoch: 6| Step: 13
Training loss: 2.126345157623291
Validation loss: 2.0501491254375828

Epoch: 180| Step: 0
Training loss: 1.8192572593688965
Validation loss: 2.032716367834358

Epoch: 6| Step: 1
Training loss: 1.6924500465393066
Validation loss: 2.076513869788057

Epoch: 6| Step: 2
Training loss: 1.6507811546325684
Validation loss: 2.0190521209470687

Epoch: 6| Step: 3
Training loss: 2.019116163253784
Validation loss: 2.0551391852799283

Epoch: 6| Step: 4
Training loss: 2.146113872528076
Validation loss: 2.034211604825912

Epoch: 6| Step: 5
Training loss: 1.7237250804901123
Validation loss: 2.042067967435365

Epoch: 6| Step: 6
Training loss: 2.0010931491851807
Validation loss: 2.0117613666801044

Epoch: 6| Step: 7
Training loss: 2.1929984092712402
Validation loss: 2.0630498868162914

Epoch: 6| Step: 8
Training loss: 1.9480712413787842
Validation loss: 2.050387824735334

Epoch: 6| Step: 9
Training loss: 1.7955536842346191
Validation loss: 2.096763018638857

Epoch: 6| Step: 10
Training loss: 2.428450107574463
Validation loss: 2.07015739076881

Epoch: 6| Step: 11
Training loss: 2.6085495948791504
Validation loss: 2.0147752608022382

Epoch: 6| Step: 12
Training loss: 1.4134880304336548
Validation loss: 2.038115350149011

Epoch: 6| Step: 13
Training loss: 1.6481388807296753
Validation loss: 2.0563019731993317

Epoch: 181| Step: 0
Training loss: 2.1260764598846436
Validation loss: 2.0688560598640033

Epoch: 6| Step: 1
Training loss: 2.3307671546936035
Validation loss: 2.01191698351214

Epoch: 6| Step: 2
Training loss: 1.7971203327178955
Validation loss: 2.0231304335337814

Epoch: 6| Step: 3
Training loss: 1.4804754257202148
Validation loss: 2.0442914937132146

Epoch: 6| Step: 4
Training loss: 1.9640265703201294
Validation loss: 2.0444316184648903

Epoch: 6| Step: 5
Training loss: 1.9254251718521118
Validation loss: 2.0595871607462564

Epoch: 6| Step: 6
Training loss: 1.7417476177215576
Validation loss: 2.0423881840962235

Epoch: 6| Step: 7
Training loss: 2.3420493602752686
Validation loss: 2.0465301454708142

Epoch: 6| Step: 8
Training loss: 1.459578037261963
Validation loss: 2.0178579412480837

Epoch: 6| Step: 9
Training loss: 2.224374771118164
Validation loss: 2.0030526461139804

Epoch: 6| Step: 10
Training loss: 1.8987449407577515
Validation loss: 2.0657110368051836

Epoch: 6| Step: 11
Training loss: 1.762031078338623
Validation loss: 2.0888668619176394

Epoch: 6| Step: 12
Training loss: 1.834075689315796
Validation loss: 2.027684914168491

Epoch: 6| Step: 13
Training loss: 2.0598018169403076
Validation loss: 2.064819597428845

Epoch: 182| Step: 0
Training loss: 2.1876320838928223
Validation loss: 2.0423412592180314

Epoch: 6| Step: 1
Training loss: 1.9182380437850952
Validation loss: 2.0507202776529456

Epoch: 6| Step: 2
Training loss: 1.8026129007339478
Validation loss: 2.032288715403567

Epoch: 6| Step: 3
Training loss: 1.5526713132858276
Validation loss: 2.034362298186107

Epoch: 6| Step: 4
Training loss: 1.5504357814788818
Validation loss: 2.054165788876113

Epoch: 6| Step: 5
Training loss: 1.4564149379730225
Validation loss: 2.0037472978714974

Epoch: 6| Step: 6
Training loss: 1.4190471172332764
Validation loss: 2.047972877820333

Epoch: 6| Step: 7
Training loss: 2.117887258529663
Validation loss: 2.0497783025105796

Epoch: 6| Step: 8
Training loss: 2.3443050384521484
Validation loss: 2.074173924743488

Epoch: 6| Step: 9
Training loss: 2.0025954246520996
Validation loss: 2.06560452266406

Epoch: 6| Step: 10
Training loss: 2.7399234771728516
Validation loss: 2.044235324346891

Epoch: 6| Step: 11
Training loss: 2.301447868347168
Validation loss: 2.0966583195553032

Epoch: 6| Step: 12
Training loss: 1.6044683456420898
Validation loss: 2.056755163336313

Epoch: 6| Step: 13
Training loss: 2.2390828132629395
Validation loss: 2.0084959460842993

Epoch: 183| Step: 0
Training loss: 1.7287886142730713
Validation loss: 2.0461720420468237

Epoch: 6| Step: 1
Training loss: 2.080136775970459
Validation loss: 2.107610769169305

Epoch: 6| Step: 2
Training loss: 2.15842342376709
Validation loss: 2.0282320463529198

Epoch: 6| Step: 3
Training loss: 1.8532698154449463
Validation loss: 2.05567773695915

Epoch: 6| Step: 4
Training loss: 1.5289828777313232
Validation loss: 1.98525414031039

Epoch: 6| Step: 5
Training loss: 1.9202228784561157
Validation loss: 2.0317454235528105

Epoch: 6| Step: 6
Training loss: 2.10501766204834
Validation loss: 2.0357376760052097

Epoch: 6| Step: 7
Training loss: 1.8762485980987549
Validation loss: 2.007051942169025

Epoch: 6| Step: 8
Training loss: 1.480777621269226
Validation loss: 2.010828164315993

Epoch: 6| Step: 9
Training loss: 2.697115182876587
Validation loss: 2.043914133502591

Epoch: 6| Step: 10
Training loss: 2.168401002883911
Validation loss: 2.0398928273108696

Epoch: 6| Step: 11
Training loss: 1.6034986972808838
Validation loss: 2.013759215672811

Epoch: 6| Step: 12
Training loss: 1.434514045715332
Validation loss: 1.9900839867130402

Epoch: 6| Step: 13
Training loss: 1.9180128574371338
Validation loss: 2.036113744140953

Epoch: 184| Step: 0
Training loss: 2.3449208736419678
Validation loss: 2.0062077481259584

Epoch: 6| Step: 1
Training loss: 2.033649444580078
Validation loss: 2.020874810475175

Epoch: 6| Step: 2
Training loss: 1.5750305652618408
Validation loss: 2.0500469669218986

Epoch: 6| Step: 3
Training loss: 1.6897965669631958
Validation loss: 2.042457543393617

Epoch: 6| Step: 4
Training loss: 1.822638988494873
Validation loss: 1.9781512586019372

Epoch: 6| Step: 5
Training loss: 1.5213178396224976
Validation loss: 2.000351021366735

Epoch: 6| Step: 6
Training loss: 2.255615472793579
Validation loss: 1.9967140843791347

Epoch: 6| Step: 7
Training loss: 1.420698881149292
Validation loss: 1.9981602494434645

Epoch: 6| Step: 8
Training loss: 2.4523963928222656
Validation loss: 2.0161538021538847

Epoch: 6| Step: 9
Training loss: 1.8294787406921387
Validation loss: 2.0018230048559045

Epoch: 6| Step: 10
Training loss: 1.2191588878631592
Validation loss: 2.005783183600313

Epoch: 6| Step: 11
Training loss: 1.8285422325134277
Validation loss: 2.027633205536873

Epoch: 6| Step: 12
Training loss: 2.356187105178833
Validation loss: 2.000874610357387

Epoch: 6| Step: 13
Training loss: 2.3584375381469727
Validation loss: 2.0141034997919554

Epoch: 185| Step: 0
Training loss: 2.16253662109375
Validation loss: 2.075993925012568

Epoch: 6| Step: 1
Training loss: 2.4249935150146484
Validation loss: 2.0062317232931814

Epoch: 6| Step: 2
Training loss: 1.9526058435440063
Validation loss: 2.004170488285762

Epoch: 6| Step: 3
Training loss: 1.9130580425262451
Validation loss: 2.0469854980386715

Epoch: 6| Step: 4
Training loss: 2.041191816329956
Validation loss: 2.0123152220120994

Epoch: 6| Step: 5
Training loss: 1.8272944688796997
Validation loss: 2.017410970503284

Epoch: 6| Step: 6
Training loss: 2.1650235652923584
Validation loss: 2.053633878307958

Epoch: 6| Step: 7
Training loss: 1.1705230474472046
Validation loss: 2.0259736237987394

Epoch: 6| Step: 8
Training loss: 1.8031091690063477
Validation loss: 2.0403121607277983

Epoch: 6| Step: 9
Training loss: 2.046560764312744
Validation loss: 2.0225363713438793

Epoch: 6| Step: 10
Training loss: 1.9928619861602783
Validation loss: 2.0240611799301638

Epoch: 6| Step: 11
Training loss: 2.6660709381103516
Validation loss: 1.98616405969025

Epoch: 6| Step: 12
Training loss: 1.2938168048858643
Validation loss: 1.986674388249715

Epoch: 6| Step: 13
Training loss: 1.2207046747207642
Validation loss: 1.9941970968759188

Epoch: 186| Step: 0
Training loss: 1.7588156461715698
Validation loss: 2.010165391429778

Epoch: 6| Step: 1
Training loss: 2.339339256286621
Validation loss: 2.053832883475929

Epoch: 6| Step: 2
Training loss: 2.4577155113220215
Validation loss: 2.018606291022352

Epoch: 6| Step: 3
Training loss: 2.7031869888305664
Validation loss: 1.9696641186232209

Epoch: 6| Step: 4
Training loss: 1.3660194873809814
Validation loss: 2.028470681559655

Epoch: 6| Step: 5
Training loss: 1.2308721542358398
Validation loss: 2.050024417138869

Epoch: 6| Step: 6
Training loss: 1.7416054010391235
Validation loss: 1.9967639369349326

Epoch: 6| Step: 7
Training loss: 1.930008888244629
Validation loss: 2.0167700423989245

Epoch: 6| Step: 8
Training loss: 1.8426194190979004
Validation loss: 2.061760543495096

Epoch: 6| Step: 9
Training loss: 1.9670257568359375
Validation loss: 2.0116491766386133

Epoch: 6| Step: 10
Training loss: 1.5616580247879028
Validation loss: 2.0263560510450795

Epoch: 6| Step: 11
Training loss: 2.2612457275390625
Validation loss: 2.0512469045577513

Epoch: 6| Step: 12
Training loss: 2.043090343475342
Validation loss: 2.0724448196349607

Epoch: 6| Step: 13
Training loss: 1.6548380851745605
Validation loss: 2.0786854810612176

Epoch: 187| Step: 0
Training loss: 1.7474610805511475
Validation loss: 2.076881621473579

Epoch: 6| Step: 1
Training loss: 1.428277611732483
Validation loss: 2.0395601987838745

Epoch: 6| Step: 2
Training loss: 1.9841434955596924
Validation loss: 2.050896190827893

Epoch: 6| Step: 3
Training loss: 1.5030102729797363
Validation loss: 2.025759143214072

Epoch: 6| Step: 4
Training loss: 2.0206713676452637
Validation loss: 2.02810679071693

Epoch: 6| Step: 5
Training loss: 2.326723098754883
Validation loss: 2.0315813300430134

Epoch: 6| Step: 6
Training loss: 2.6625800132751465
Validation loss: 2.0126530970296552

Epoch: 6| Step: 7
Training loss: 1.5233983993530273
Validation loss: 2.0422303599696003

Epoch: 6| Step: 8
Training loss: 1.8910956382751465
Validation loss: 2.0466115705428587

Epoch: 6| Step: 9
Training loss: 1.8218951225280762
Validation loss: 2.056972478025703

Epoch: 6| Step: 10
Training loss: 2.813927173614502
Validation loss: 2.0062150365562847

Epoch: 6| Step: 11
Training loss: 1.863060712814331
Validation loss: 2.0740175772738714

Epoch: 6| Step: 12
Training loss: 1.5714070796966553
Validation loss: 2.0440639065157984

Epoch: 6| Step: 13
Training loss: 1.2273670434951782
Validation loss: 2.007633729647565

Epoch: 188| Step: 0
Training loss: 1.84067964553833
Validation loss: 2.0528744446334017

Epoch: 6| Step: 1
Training loss: 1.57112717628479
Validation loss: 2.015708541357389

Epoch: 6| Step: 2
Training loss: 1.477418065071106
Validation loss: 2.029806396012665

Epoch: 6| Step: 3
Training loss: 2.437854528427124
Validation loss: 2.0291615865563832

Epoch: 6| Step: 4
Training loss: 1.3502073287963867
Validation loss: 2.005933097613755

Epoch: 6| Step: 5
Training loss: 1.7886779308319092
Validation loss: 2.02243358601806

Epoch: 6| Step: 6
Training loss: 2.037346363067627
Validation loss: 1.9845112023815032

Epoch: 6| Step: 7
Training loss: 1.5242316722869873
Validation loss: 2.037699745547387

Epoch: 6| Step: 8
Training loss: 2.3662173748016357
Validation loss: 1.9899280532713859

Epoch: 6| Step: 9
Training loss: 1.1533650159835815
Validation loss: 2.0577995879675752

Epoch: 6| Step: 10
Training loss: 2.248399496078491
Validation loss: 2.028064404764483

Epoch: 6| Step: 11
Training loss: 3.1471633911132812
Validation loss: 2.024823181090816

Epoch: 6| Step: 12
Training loss: 1.2318476438522339
Validation loss: 2.054859547204869

Epoch: 6| Step: 13
Training loss: 2.653202772140503
Validation loss: 2.0026848905829975

Epoch: 189| Step: 0
Training loss: 2.191012382507324
Validation loss: 2.003358394868912

Epoch: 6| Step: 1
Training loss: 2.0160741806030273
Validation loss: 2.011257202394547

Epoch: 6| Step: 2
Training loss: 2.0839927196502686
Validation loss: 1.986702238359759

Epoch: 6| Step: 3
Training loss: 3.1574859619140625
Validation loss: 2.0431688472788823

Epoch: 6| Step: 4
Training loss: 2.2270374298095703
Validation loss: 2.008862903041224

Epoch: 6| Step: 5
Training loss: 1.66861093044281
Validation loss: 1.9939245434217556

Epoch: 6| Step: 6
Training loss: 1.8469874858856201
Validation loss: 2.076071487959995

Epoch: 6| Step: 7
Training loss: 1.7888553142547607
Validation loss: 2.0196553430249615

Epoch: 6| Step: 8
Training loss: 1.142047643661499
Validation loss: 2.072030081543871

Epoch: 6| Step: 9
Training loss: 1.2586686611175537
Validation loss: 1.9598834694072764

Epoch: 6| Step: 10
Training loss: 1.5901931524276733
Validation loss: 2.003559434285728

Epoch: 6| Step: 11
Training loss: 1.4765182733535767
Validation loss: 2.011840340911701

Epoch: 6| Step: 12
Training loss: 2.108941078186035
Validation loss: 2.037593969734766

Epoch: 6| Step: 13
Training loss: 2.3682007789611816
Validation loss: 2.0158101076720865

Epoch: 190| Step: 0
Training loss: 1.9770872592926025
Validation loss: 2.0313483386911373

Epoch: 6| Step: 1
Training loss: 1.7175066471099854
Validation loss: 2.038630941862701

Epoch: 6| Step: 2
Training loss: 1.634551763534546
Validation loss: 2.0007701304651078

Epoch: 6| Step: 3
Training loss: 1.3398234844207764
Validation loss: 2.019249307212009

Epoch: 6| Step: 4
Training loss: 2.3278253078460693
Validation loss: 2.031993137892856

Epoch: 6| Step: 5
Training loss: 2.031388282775879
Validation loss: 1.9839308569508214

Epoch: 6| Step: 6
Training loss: 1.9541298151016235
Validation loss: 2.024293330407912

Epoch: 6| Step: 7
Training loss: 2.1902222633361816
Validation loss: 2.069337162920224

Epoch: 6| Step: 8
Training loss: 1.626741647720337
Validation loss: 2.0801055149365495

Epoch: 6| Step: 9
Training loss: 2.436660051345825
Validation loss: 2.085484367544933

Epoch: 6| Step: 10
Training loss: 2.0425539016723633
Validation loss: 1.9958364066257273

Epoch: 6| Step: 11
Training loss: 2.123422384262085
Validation loss: 2.0046521976429927

Epoch: 6| Step: 12
Training loss: 1.387483835220337
Validation loss: 2.0301954259154615

Epoch: 6| Step: 13
Training loss: 1.5032087564468384
Validation loss: 2.024448546030188

Epoch: 191| Step: 0
Training loss: 2.250749349594116
Validation loss: 2.0139289017646544

Epoch: 6| Step: 1
Training loss: 1.8102304935455322
Validation loss: 2.0254297282106135

Epoch: 6| Step: 2
Training loss: 1.514158010482788
Validation loss: 2.080031507758684

Epoch: 6| Step: 3
Training loss: 1.7008655071258545
Validation loss: 1.9946196540709464

Epoch: 6| Step: 4
Training loss: 2.0481510162353516
Validation loss: 2.064083453147642

Epoch: 6| Step: 5
Training loss: 1.7365460395812988
Validation loss: 2.00207777689862

Epoch: 6| Step: 6
Training loss: 1.1767675876617432
Validation loss: 2.0666031734917754

Epoch: 6| Step: 7
Training loss: 1.6449755430221558
Validation loss: 1.9898546793127572

Epoch: 6| Step: 8
Training loss: 2.4845776557922363
Validation loss: 2.044140253015744

Epoch: 6| Step: 9
Training loss: 1.8308203220367432
Validation loss: 2.032905947777533

Epoch: 6| Step: 10
Training loss: 1.674039363861084
Validation loss: 1.9823071033723894

Epoch: 6| Step: 11
Training loss: 1.582600474357605
Validation loss: 2.0472838904268

Epoch: 6| Step: 12
Training loss: 2.880586624145508
Validation loss: 2.0457024856280257

Epoch: 6| Step: 13
Training loss: 2.367180109024048
Validation loss: 2.0091067091111214

Epoch: 192| Step: 0
Training loss: 2.12129545211792
Validation loss: 2.0397113830812517

Epoch: 6| Step: 1
Training loss: 2.012589693069458
Validation loss: 1.9467516240253244

Epoch: 6| Step: 2
Training loss: 1.546617865562439
Validation loss: 1.9938676946906633

Epoch: 6| Step: 3
Training loss: 2.498934030532837
Validation loss: 1.9621011916027273

Epoch: 6| Step: 4
Training loss: 1.554239273071289
Validation loss: 1.9677395846254082

Epoch: 6| Step: 5
Training loss: 2.672279119491577
Validation loss: 1.9973573377055507

Epoch: 6| Step: 6
Training loss: 1.8718879222869873
Validation loss: 2.006598182903823

Epoch: 6| Step: 7
Training loss: 1.6343296766281128
Validation loss: 1.989776562618953

Epoch: 6| Step: 8
Training loss: 1.8345451354980469
Validation loss: 1.9967861406264766

Epoch: 6| Step: 9
Training loss: 1.2741389274597168
Validation loss: 1.9879380554281256

Epoch: 6| Step: 10
Training loss: 1.6626845598220825
Validation loss: 2.0421412555120324

Epoch: 6| Step: 11
Training loss: 2.336733818054199
Validation loss: 1.9781518610574866

Epoch: 6| Step: 12
Training loss: 1.532541036605835
Validation loss: 2.0111126169081657

Epoch: 6| Step: 13
Training loss: 1.748715877532959
Validation loss: 1.9673999842777048

Epoch: 193| Step: 0
Training loss: 1.8665831089019775
Validation loss: 2.0398533856996925

Epoch: 6| Step: 1
Training loss: 1.7019957304000854
Validation loss: 2.048746257699946

Epoch: 6| Step: 2
Training loss: 1.6336510181427002
Validation loss: 2.0249507299033542

Epoch: 6| Step: 3
Training loss: 2.253453016281128
Validation loss: 2.0289524498806206

Epoch: 6| Step: 4
Training loss: 1.434034824371338
Validation loss: 1.9926732958004039

Epoch: 6| Step: 5
Training loss: 2.059256076812744
Validation loss: 1.9946062372576805

Epoch: 6| Step: 6
Training loss: 2.166741371154785
Validation loss: 1.9840231005863478

Epoch: 6| Step: 7
Training loss: 1.5391528606414795
Validation loss: 2.0718132295916156

Epoch: 6| Step: 8
Training loss: 1.433082103729248
Validation loss: 1.9644146529577111

Epoch: 6| Step: 9
Training loss: 2.6847405433654785
Validation loss: 2.0197117956735755

Epoch: 6| Step: 10
Training loss: 1.911576271057129
Validation loss: 2.0231830304668796

Epoch: 6| Step: 11
Training loss: 2.1782827377319336
Validation loss: 1.9970287405034548

Epoch: 6| Step: 12
Training loss: 1.8803470134735107
Validation loss: 2.0231343917949225

Epoch: 6| Step: 13
Training loss: 1.5402352809906006
Validation loss: 1.9984352755290207

Epoch: 194| Step: 0
Training loss: 2.1306936740875244
Validation loss: 2.019808619253097

Epoch: 6| Step: 1
Training loss: 2.328789234161377
Validation loss: 2.0372629960378013

Epoch: 6| Step: 2
Training loss: 1.8963778018951416
Validation loss: 2.0148190631661365

Epoch: 6| Step: 3
Training loss: 1.9947959184646606
Validation loss: 2.057019659267959

Epoch: 6| Step: 4
Training loss: 1.695742130279541
Validation loss: 2.0739565946722545

Epoch: 6| Step: 5
Training loss: 2.539155960083008
Validation loss: 2.023424208805125

Epoch: 6| Step: 6
Training loss: 2.298236131668091
Validation loss: 2.0287212184680405

Epoch: 6| Step: 7
Training loss: 1.802704930305481
Validation loss: 1.9799730547012822

Epoch: 6| Step: 8
Training loss: 1.967160940170288
Validation loss: 2.0261039477522655

Epoch: 6| Step: 9
Training loss: 1.3449755907058716
Validation loss: 2.0194696534064507

Epoch: 6| Step: 10
Training loss: 1.6742253303527832
Validation loss: 2.0670064623637865

Epoch: 6| Step: 11
Training loss: 1.4116533994674683
Validation loss: 2.0166076793465564

Epoch: 6| Step: 12
Training loss: 2.2487194538116455
Validation loss: 1.9891078741319719

Epoch: 6| Step: 13
Training loss: 0.8322039246559143
Validation loss: 2.0522485766359555

Epoch: 195| Step: 0
Training loss: 1.703315019607544
Validation loss: 2.021319112470073

Epoch: 6| Step: 1
Training loss: 1.7456700801849365
Validation loss: 1.9862477740933817

Epoch: 6| Step: 2
Training loss: 2.5106191635131836
Validation loss: 1.993939297173613

Epoch: 6| Step: 3
Training loss: 1.3693405389785767
Validation loss: 2.0371810415739655

Epoch: 6| Step: 4
Training loss: 0.9547519087791443
Validation loss: 2.002624624518938

Epoch: 6| Step: 5
Training loss: 1.6815125942230225
Validation loss: 2.0280871698933263

Epoch: 6| Step: 6
Training loss: 2.388732433319092
Validation loss: 2.0111003716786704

Epoch: 6| Step: 7
Training loss: 2.0409321784973145
Validation loss: 1.991524459213339

Epoch: 6| Step: 8
Training loss: 2.4467921257019043
Validation loss: 1.9907339362687961

Epoch: 6| Step: 9
Training loss: 2.435248374938965
Validation loss: 1.980197109201903

Epoch: 6| Step: 10
Training loss: 1.417985200881958
Validation loss: 1.9773620610596032

Epoch: 6| Step: 11
Training loss: 1.6144325733184814
Validation loss: 2.008842947662518

Epoch: 6| Step: 12
Training loss: 1.6076264381408691
Validation loss: 2.009299878151186

Epoch: 6| Step: 13
Training loss: 2.2270328998565674
Validation loss: 2.012195380785132

Epoch: 196| Step: 0
Training loss: 2.416170358657837
Validation loss: 2.02117516404839

Epoch: 6| Step: 1
Training loss: 1.5325990915298462
Validation loss: 1.965670524104949

Epoch: 6| Step: 2
Training loss: 1.531213402748108
Validation loss: 2.0122024307968798

Epoch: 6| Step: 3
Training loss: 2.4124467372894287
Validation loss: 2.005611314568468

Epoch: 6| Step: 4
Training loss: 1.9993174076080322
Validation loss: 1.9884801808223929

Epoch: 6| Step: 5
Training loss: 1.6809306144714355
Validation loss: 2.053257683272003

Epoch: 6| Step: 6
Training loss: 1.988477349281311
Validation loss: 2.054943787154331

Epoch: 6| Step: 7
Training loss: 1.8838156461715698
Validation loss: 2.0081133573285994

Epoch: 6| Step: 8
Training loss: 2.108158588409424
Validation loss: 1.9796687223578011

Epoch: 6| Step: 9
Training loss: 1.5619404315948486
Validation loss: 1.9772258368871545

Epoch: 6| Step: 10
Training loss: 1.5929782390594482
Validation loss: 1.9882549291015954

Epoch: 6| Step: 11
Training loss: 1.522897481918335
Validation loss: 1.9851889674381544

Epoch: 6| Step: 12
Training loss: 2.0804429054260254
Validation loss: 1.9697309181254397

Epoch: 6| Step: 13
Training loss: 1.7031350135803223
Validation loss: 2.0024307543231594

Epoch: 197| Step: 0
Training loss: 1.548454999923706
Validation loss: 2.04757781182566

Epoch: 6| Step: 1
Training loss: 2.0870909690856934
Validation loss: 2.0072352963109172

Epoch: 6| Step: 2
Training loss: 1.3780322074890137
Validation loss: 1.9985135037411925

Epoch: 6| Step: 3
Training loss: 1.9551725387573242
Validation loss: 1.9967142164066274

Epoch: 6| Step: 4
Training loss: 1.5695743560791016
Validation loss: 1.9999813213143298

Epoch: 6| Step: 5
Training loss: 2.1539764404296875
Validation loss: 2.0073287346029796

Epoch: 6| Step: 6
Training loss: 1.6872279644012451
Validation loss: 2.011956548178068

Epoch: 6| Step: 7
Training loss: 2.148815155029297
Validation loss: 1.9623088170123357

Epoch: 6| Step: 8
Training loss: 1.5458199977874756
Validation loss: 1.9666262057519728

Epoch: 6| Step: 9
Training loss: 1.8976246118545532
Validation loss: 2.0123793284098306

Epoch: 6| Step: 10
Training loss: 2.3813271522521973
Validation loss: 2.055401300871244

Epoch: 6| Step: 11
Training loss: 1.6591455936431885
Validation loss: 1.9869325571162726

Epoch: 6| Step: 12
Training loss: 2.3304243087768555
Validation loss: 2.023365301470603

Epoch: 6| Step: 13
Training loss: 1.7700114250183105
Validation loss: 1.9814527368032804

Epoch: 198| Step: 0
Training loss: 1.8494460582733154
Validation loss: 2.0104777864230576

Epoch: 6| Step: 1
Training loss: 2.3627560138702393
Validation loss: 2.0071544313943512

Epoch: 6| Step: 2
Training loss: 2.0879669189453125
Validation loss: 1.9849639002994826

Epoch: 6| Step: 3
Training loss: 2.1490142345428467
Validation loss: 2.036847911855226

Epoch: 6| Step: 4
Training loss: 1.828284502029419
Validation loss: 1.9999823775342715

Epoch: 6| Step: 5
Training loss: 1.5771347284317017
Validation loss: 1.9984299931474911

Epoch: 6| Step: 6
Training loss: 1.8244421482086182
Validation loss: 2.0224691001317834

Epoch: 6| Step: 7
Training loss: 1.4526726007461548
Validation loss: 2.008936419281908

Epoch: 6| Step: 8
Training loss: 1.7503526210784912
Validation loss: 2.03974344653468

Epoch: 6| Step: 9
Training loss: 1.2934157848358154
Validation loss: 2.036047425321353

Epoch: 6| Step: 10
Training loss: 1.6834708452224731
Validation loss: 2.0045035859589935

Epoch: 6| Step: 11
Training loss: 2.0210776329040527
Validation loss: 1.9974395562243719

Epoch: 6| Step: 12
Training loss: 1.8863558769226074
Validation loss: 2.0169554833442933

Epoch: 6| Step: 13
Training loss: 2.241215944290161
Validation loss: 2.051451470262261

Epoch: 199| Step: 0
Training loss: 1.9863464832305908
Validation loss: 2.0369189144462667

Epoch: 6| Step: 1
Training loss: 1.39905846118927
Validation loss: 1.966446889344082

Epoch: 6| Step: 2
Training loss: 1.0935927629470825
Validation loss: 2.0113446417675225

Epoch: 6| Step: 3
Training loss: 2.448202133178711
Validation loss: 2.0336691884584326

Epoch: 6| Step: 4
Training loss: 2.700380563735962
Validation loss: 1.9699919915968371

Epoch: 6| Step: 5
Training loss: 1.464970350265503
Validation loss: 1.9602564457924134

Epoch: 6| Step: 6
Training loss: 2.1553797721862793
Validation loss: 2.0069816099700106

Epoch: 6| Step: 7
Training loss: 2.4427053928375244
Validation loss: 1.9936742218591834

Epoch: 6| Step: 8
Training loss: 2.0269017219543457
Validation loss: 2.04005830390479

Epoch: 6| Step: 9
Training loss: 1.7990354299545288
Validation loss: 1.9971175091240996

Epoch: 6| Step: 10
Training loss: 1.3682217597961426
Validation loss: 2.007523816118958

Epoch: 6| Step: 11
Training loss: 1.8064156770706177
Validation loss: 2.011002955898162

Epoch: 6| Step: 12
Training loss: 1.6390600204467773
Validation loss: 2.027553739086274

Epoch: 6| Step: 13
Training loss: 1.9530595541000366
Validation loss: 2.0240906694883942

Epoch: 200| Step: 0
Training loss: 1.6601495742797852
Validation loss: 2.0007360545537805

Epoch: 6| Step: 1
Training loss: 2.044532537460327
Validation loss: 1.9932946312812068

Epoch: 6| Step: 2
Training loss: 1.7682969570159912
Validation loss: 2.0422503204755884

Epoch: 6| Step: 3
Training loss: 1.939162015914917
Validation loss: 1.993964707979592

Epoch: 6| Step: 4
Training loss: 2.356067419052124
Validation loss: 2.044680828689247

Epoch: 6| Step: 5
Training loss: 1.369879961013794
Validation loss: 1.9864500773850309

Epoch: 6| Step: 6
Training loss: 1.3165981769561768
Validation loss: 2.00314171724422

Epoch: 6| Step: 7
Training loss: 1.949420690536499
Validation loss: 2.0067221144194245

Epoch: 6| Step: 8
Training loss: 1.9314324855804443
Validation loss: 2.0245158287786666

Epoch: 6| Step: 9
Training loss: 1.735018014907837
Validation loss: 2.018732938715207

Epoch: 6| Step: 10
Training loss: 2.269367218017578
Validation loss: 2.0244312850377892

Epoch: 6| Step: 11
Training loss: 2.5311684608459473
Validation loss: 2.011584461376231

Epoch: 6| Step: 12
Training loss: 1.554159164428711
Validation loss: 2.0429095645104685

Epoch: 6| Step: 13
Training loss: 2.000004291534424
Validation loss: 1.9823398833633752

Epoch: 201| Step: 0
Training loss: 1.7636103630065918
Validation loss: 2.023880688093042

Epoch: 6| Step: 1
Training loss: 1.6793851852416992
Validation loss: 2.038616729039018

Epoch: 6| Step: 2
Training loss: 2.2509002685546875
Validation loss: 2.0202422526574906

Epoch: 6| Step: 3
Training loss: 2.1955368518829346
Validation loss: 2.037011167054535

Epoch: 6| Step: 4
Training loss: 2.1332898139953613
Validation loss: 2.027562828474147

Epoch: 6| Step: 5
Training loss: 2.0093488693237305
Validation loss: 2.006155440884252

Epoch: 6| Step: 6
Training loss: 1.2323155403137207
Validation loss: 2.0278393799258816

Epoch: 6| Step: 7
Training loss: 2.2395639419555664
Validation loss: 2.011183686153863

Epoch: 6| Step: 8
Training loss: 2.1575229167938232
Validation loss: 1.9944709911141345

Epoch: 6| Step: 9
Training loss: 1.465705156326294
Validation loss: 2.0331688696338284

Epoch: 6| Step: 10
Training loss: 1.5890004634857178
Validation loss: 1.9900636429427772

Epoch: 6| Step: 11
Training loss: 1.4360448122024536
Validation loss: 1.9980475979466592

Epoch: 6| Step: 12
Training loss: 2.2917158603668213
Validation loss: 2.0039724919103805

Epoch: 6| Step: 13
Training loss: 1.0897068977355957
Validation loss: 2.0220264234850482

Epoch: 202| Step: 0
Training loss: 1.4355530738830566
Validation loss: 1.9841865211404779

Epoch: 6| Step: 1
Training loss: 1.5317060947418213
Validation loss: 2.0278993780894945

Epoch: 6| Step: 2
Training loss: 2.0755419731140137
Validation loss: 1.9889943740701164

Epoch: 6| Step: 3
Training loss: 2.2763397693634033
Validation loss: 2.013254463031728

Epoch: 6| Step: 4
Training loss: 1.3985257148742676
Validation loss: 1.9815433435542609

Epoch: 6| Step: 5
Training loss: 1.7808210849761963
Validation loss: 2.035618233424361

Epoch: 6| Step: 6
Training loss: 2.1605281829833984
Validation loss: 1.9567422213092927

Epoch: 6| Step: 7
Training loss: 1.919661521911621
Validation loss: 1.9678527808958484

Epoch: 6| Step: 8
Training loss: 2.2051897048950195
Validation loss: 2.022772982556333

Epoch: 6| Step: 9
Training loss: 1.8343256711959839
Validation loss: 1.980117928597235

Epoch: 6| Step: 10
Training loss: 1.7561906576156616
Validation loss: 1.9787794697669245

Epoch: 6| Step: 11
Training loss: 2.1447811126708984
Validation loss: 1.9784612335184568

Epoch: 6| Step: 12
Training loss: 1.6283354759216309
Validation loss: 1.9647948562457997

Epoch: 6| Step: 13
Training loss: 2.281690835952759
Validation loss: 2.001693679440406

Epoch: 203| Step: 0
Training loss: 1.4953844547271729
Validation loss: 2.0037929883567234

Epoch: 6| Step: 1
Training loss: 1.4593431949615479
Validation loss: 1.9810754560655164

Epoch: 6| Step: 2
Training loss: 1.8272236585617065
Validation loss: 1.9797163214734805

Epoch: 6| Step: 3
Training loss: 1.9634824991226196
Validation loss: 1.9857048526886971

Epoch: 6| Step: 4
Training loss: 1.9567230939865112
Validation loss: 1.9520811752606464

Epoch: 6| Step: 5
Training loss: 2.154448986053467
Validation loss: 2.0225436649014874

Epoch: 6| Step: 6
Training loss: 1.444347858428955
Validation loss: 2.0284324525504984

Epoch: 6| Step: 7
Training loss: 1.8824893236160278
Validation loss: 1.9522416207098192

Epoch: 6| Step: 8
Training loss: 2.0061771869659424
Validation loss: 1.9756382908872379

Epoch: 6| Step: 9
Training loss: 1.9052010774612427
Validation loss: 1.941684284517842

Epoch: 6| Step: 10
Training loss: 1.954052448272705
Validation loss: 1.9940412820026439

Epoch: 6| Step: 11
Training loss: 1.8502146005630493
Validation loss: 2.082347728872812

Epoch: 6| Step: 12
Training loss: 1.7531275749206543
Validation loss: 2.0011241948732765

Epoch: 6| Step: 13
Training loss: 2.2196316719055176
Validation loss: 2.020184697643403

Epoch: 204| Step: 0
Training loss: 2.3302724361419678
Validation loss: 1.9573182598237069

Epoch: 6| Step: 1
Training loss: 2.2459487915039062
Validation loss: 2.028319670308021

Epoch: 6| Step: 2
Training loss: 1.1861090660095215
Validation loss: 2.030310369306995

Epoch: 6| Step: 3
Training loss: 2.342653751373291
Validation loss: 2.0091593188624226

Epoch: 6| Step: 4
Training loss: 2.1216039657592773
Validation loss: 2.0265000840669036

Epoch: 6| Step: 5
Training loss: 1.628577709197998
Validation loss: 1.9826393717078752

Epoch: 6| Step: 6
Training loss: 1.4263882637023926
Validation loss: 2.0058427651723227

Epoch: 6| Step: 7
Training loss: 1.686684489250183
Validation loss: 1.9663677830849924

Epoch: 6| Step: 8
Training loss: 1.6392625570297241
Validation loss: 2.007391973208356

Epoch: 6| Step: 9
Training loss: 1.9027674198150635
Validation loss: 2.0026124677350445

Epoch: 6| Step: 10
Training loss: 1.8764499425888062
Validation loss: 1.9705177635274909

Epoch: 6| Step: 11
Training loss: 2.46925950050354
Validation loss: 2.019156652112161

Epoch: 6| Step: 12
Training loss: 1.734209418296814
Validation loss: 1.9432753388599684

Epoch: 6| Step: 13
Training loss: 1.2575459480285645
Validation loss: 2.0000689670603764

Epoch: 205| Step: 0
Training loss: 1.4536175727844238
Validation loss: 1.997661828994751

Epoch: 6| Step: 1
Training loss: 1.441462516784668
Validation loss: 1.965397096449329

Epoch: 6| Step: 2
Training loss: 1.4658560752868652
Validation loss: 1.9695438902865174

Epoch: 6| Step: 3
Training loss: 1.2313218116760254
Validation loss: 1.9827500030558596

Epoch: 6| Step: 4
Training loss: 1.9152393341064453
Validation loss: 2.000649135599854

Epoch: 6| Step: 5
Training loss: 1.7938878536224365
Validation loss: 2.005734060400276

Epoch: 6| Step: 6
Training loss: 2.368809223175049
Validation loss: 1.9646860732827136

Epoch: 6| Step: 7
Training loss: 1.819061040878296
Validation loss: 1.9930103158438077

Epoch: 6| Step: 8
Training loss: 2.197058916091919
Validation loss: 1.980610010444477

Epoch: 6| Step: 9
Training loss: 1.8639373779296875
Validation loss: 1.9937527846264582

Epoch: 6| Step: 10
Training loss: 2.3170313835144043
Validation loss: 2.022562866569847

Epoch: 6| Step: 11
Training loss: 2.3529253005981445
Validation loss: 2.01703711991669

Epoch: 6| Step: 12
Training loss: 1.950042963027954
Validation loss: 2.051742745983985

Epoch: 6| Step: 13
Training loss: 2.10394024848938
Validation loss: 2.0006772331012193

Epoch: 206| Step: 0
Training loss: 2.3567891120910645
Validation loss: 2.0246281726385957

Epoch: 6| Step: 1
Training loss: 1.8361212015151978
Validation loss: 2.0373273203449864

Epoch: 6| Step: 2
Training loss: 2.150035858154297
Validation loss: 2.0080571815531743

Epoch: 6| Step: 3
Training loss: 1.8131487369537354
Validation loss: 2.0342508592913227

Epoch: 6| Step: 4
Training loss: 1.5813223123550415
Validation loss: 2.068500271407507

Epoch: 6| Step: 5
Training loss: 2.4390690326690674
Validation loss: 2.0353609925957135

Epoch: 6| Step: 6
Training loss: 1.4741225242614746
Validation loss: 2.0662016996773342

Epoch: 6| Step: 7
Training loss: 1.4196386337280273
Validation loss: 2.0473356708403556

Epoch: 6| Step: 8
Training loss: 1.4869470596313477
Validation loss: 2.086334200315578

Epoch: 6| Step: 9
Training loss: 2.069028377532959
Validation loss: 2.0800307719938216

Epoch: 6| Step: 10
Training loss: 2.3048181533813477
Validation loss: 2.0556161839474916

Epoch: 6| Step: 11
Training loss: 1.7775745391845703
Validation loss: 2.03641406695048

Epoch: 6| Step: 12
Training loss: 1.6931074857711792
Validation loss: 2.018854756509104

Epoch: 6| Step: 13
Training loss: 1.6379525661468506
Validation loss: 2.018540643876599

Epoch: 207| Step: 0
Training loss: 1.505098581314087
Validation loss: 2.011730353037516

Epoch: 6| Step: 1
Training loss: 1.6500871181488037
Validation loss: 1.9481629889498475

Epoch: 6| Step: 2
Training loss: 2.0653395652770996
Validation loss: 1.9715369542439778

Epoch: 6| Step: 3
Training loss: 1.9695265293121338
Validation loss: 2.000778191833086

Epoch: 6| Step: 4
Training loss: 1.7530251741409302
Validation loss: 1.9987749591950448

Epoch: 6| Step: 5
Training loss: 1.698562502861023
Validation loss: 1.9825800875181794

Epoch: 6| Step: 6
Training loss: 2.46319317817688
Validation loss: 2.017033105255455

Epoch: 6| Step: 7
Training loss: 1.1995110511779785
Validation loss: 1.9851113468088128

Epoch: 6| Step: 8
Training loss: 2.034075975418091
Validation loss: 2.000683758848457

Epoch: 6| Step: 9
Training loss: 1.7562611103057861
Validation loss: 1.9812250752602854

Epoch: 6| Step: 10
Training loss: 1.6011930704116821
Validation loss: 2.030630926932058

Epoch: 6| Step: 11
Training loss: 1.7995108366012573
Validation loss: 1.978417238881511

Epoch: 6| Step: 12
Training loss: 2.760646343231201
Validation loss: 1.9850747431478193

Epoch: 6| Step: 13
Training loss: 1.2663787603378296
Validation loss: 1.973516692397415

Epoch: 208| Step: 0
Training loss: 2.1300737857818604
Validation loss: 1.9836845744040705

Epoch: 6| Step: 1
Training loss: 1.441711664199829
Validation loss: 1.9882266905999952

Epoch: 6| Step: 2
Training loss: 2.5397071838378906
Validation loss: 2.011591015323516

Epoch: 6| Step: 3
Training loss: 0.8607218265533447
Validation loss: 1.9823613153990878

Epoch: 6| Step: 4
Training loss: 2.4490389823913574
Validation loss: 1.9802909512673654

Epoch: 6| Step: 5
Training loss: 1.31606924533844
Validation loss: 1.927044665941628

Epoch: 6| Step: 6
Training loss: 1.910054087638855
Validation loss: 1.95797142546664

Epoch: 6| Step: 7
Training loss: 2.1146769523620605
Validation loss: 2.0359714684947843

Epoch: 6| Step: 8
Training loss: 1.8218860626220703
Validation loss: 2.0031694173812866

Epoch: 6| Step: 9
Training loss: 1.791243076324463
Validation loss: 1.9835127912541872

Epoch: 6| Step: 10
Training loss: 1.530245065689087
Validation loss: 1.974461555480957

Epoch: 6| Step: 11
Training loss: 1.95985746383667
Validation loss: 1.9753635826931204

Epoch: 6| Step: 12
Training loss: 2.415461540222168
Validation loss: 1.9939439437722648

Epoch: 6| Step: 13
Training loss: 1.4911088943481445
Validation loss: 1.9405366002872426

Epoch: 209| Step: 0
Training loss: 1.6216988563537598
Validation loss: 2.0218521087400374

Epoch: 6| Step: 1
Training loss: 2.0728657245635986
Validation loss: 1.9412473901625602

Epoch: 6| Step: 2
Training loss: 1.6509077548980713
Validation loss: 1.999552240935705

Epoch: 6| Step: 3
Training loss: 1.836256504058838
Validation loss: 2.0248163028429915

Epoch: 6| Step: 4
Training loss: 1.7477439641952515
Validation loss: 2.006246212990053

Epoch: 6| Step: 5
Training loss: 1.4821970462799072
Validation loss: 2.00842043148574

Epoch: 6| Step: 6
Training loss: 1.891050934791565
Validation loss: 1.9419899614908362

Epoch: 6| Step: 7
Training loss: 2.4124255180358887
Validation loss: 1.986730835771048

Epoch: 6| Step: 8
Training loss: 2.2306764125823975
Validation loss: 1.9946893850962322

Epoch: 6| Step: 9
Training loss: 1.9972268342971802
Validation loss: 2.010651029566283

Epoch: 6| Step: 10
Training loss: 2.068237781524658
Validation loss: 2.0510177535395466

Epoch: 6| Step: 11
Training loss: 1.6477632522583008
Validation loss: 2.005283245476343

Epoch: 6| Step: 12
Training loss: 1.7923405170440674
Validation loss: 2.0363787310097807

Epoch: 6| Step: 13
Training loss: 1.7585816383361816
Validation loss: 1.99211516944311

Epoch: 210| Step: 0
Training loss: 1.3434858322143555
Validation loss: 1.9741308971117901

Epoch: 6| Step: 1
Training loss: 2.3167781829833984
Validation loss: 2.013689024474031

Epoch: 6| Step: 2
Training loss: 1.4807536602020264
Validation loss: 2.0068071490974835

Epoch: 6| Step: 3
Training loss: 1.438448429107666
Validation loss: 2.014885143567157

Epoch: 6| Step: 4
Training loss: 1.7049946784973145
Validation loss: 1.9712186013498614

Epoch: 6| Step: 5
Training loss: 1.4627163410186768
Validation loss: 2.007936954498291

Epoch: 6| Step: 6
Training loss: 1.6614577770233154
Validation loss: 1.9965187118899437

Epoch: 6| Step: 7
Training loss: 2.7762372493743896
Validation loss: 1.992383026307629

Epoch: 6| Step: 8
Training loss: 2.058262348175049
Validation loss: 1.9579974246281449

Epoch: 6| Step: 9
Training loss: 2.2271804809570312
Validation loss: 1.9923896648550545

Epoch: 6| Step: 10
Training loss: 2.335864543914795
Validation loss: 1.9644806513222315

Epoch: 6| Step: 11
Training loss: 1.5860590934753418
Validation loss: 1.981890683533043

Epoch: 6| Step: 12
Training loss: 1.9867568016052246
Validation loss: 2.027996273450954

Epoch: 6| Step: 13
Training loss: 0.9689784646034241
Validation loss: 2.0254016435274513

Epoch: 211| Step: 0
Training loss: 1.1149356365203857
Validation loss: 2.005310845631425

Epoch: 6| Step: 1
Training loss: 2.1333794593811035
Validation loss: 2.001439598298842

Epoch: 6| Step: 2
Training loss: 1.7613495588302612
Validation loss: 2.0398617354772424

Epoch: 6| Step: 3
Training loss: 2.3736164569854736
Validation loss: 1.9939567542845202

Epoch: 6| Step: 4
Training loss: 1.738037109375
Validation loss: 2.001582794291999

Epoch: 6| Step: 5
Training loss: 2.7567849159240723
Validation loss: 2.0008174065620667

Epoch: 6| Step: 6
Training loss: 1.8271886110305786
Validation loss: 1.9845326395444973

Epoch: 6| Step: 7
Training loss: 1.9100630283355713
Validation loss: 2.0386932075664563

Epoch: 6| Step: 8
Training loss: 1.8591454029083252
Validation loss: 1.9956209813394854

Epoch: 6| Step: 9
Training loss: 1.7557021379470825
Validation loss: 2.0131051566011164

Epoch: 6| Step: 10
Training loss: 1.4267044067382812
Validation loss: 1.9982114248378302

Epoch: 6| Step: 11
Training loss: 1.4376050233840942
Validation loss: 2.0235765851953977

Epoch: 6| Step: 12
Training loss: 1.5365231037139893
Validation loss: 2.0448608065164215

Epoch: 6| Step: 13
Training loss: 1.9613423347473145
Validation loss: 2.0266503839082617

Epoch: 212| Step: 0
Training loss: 1.8658214807510376
Validation loss: 2.031742586243537

Epoch: 6| Step: 1
Training loss: 1.7651253938674927
Validation loss: 1.950305345237896

Epoch: 6| Step: 2
Training loss: 1.4901032447814941
Validation loss: 2.013922163235244

Epoch: 6| Step: 3
Training loss: 1.9653162956237793
Validation loss: 2.057482422039073

Epoch: 6| Step: 4
Training loss: 1.8563885688781738
Validation loss: 1.9687611723458895

Epoch: 6| Step: 5
Training loss: 1.5856424570083618
Validation loss: 1.9324577957071283

Epoch: 6| Step: 6
Training loss: 2.4646835327148438
Validation loss: 1.9695528976378902

Epoch: 6| Step: 7
Training loss: 1.1990011930465698
Validation loss: 1.9697197098885812

Epoch: 6| Step: 8
Training loss: 1.5346486568450928
Validation loss: 2.0011526666661745

Epoch: 6| Step: 9
Training loss: 1.535294532775879
Validation loss: 1.970885253721668

Epoch: 6| Step: 10
Training loss: 2.122206449508667
Validation loss: 1.9847133774911203

Epoch: 6| Step: 11
Training loss: 2.6504058837890625
Validation loss: 2.0046426019360943

Epoch: 6| Step: 12
Training loss: 1.909142255783081
Validation loss: 2.0044853789832002

Epoch: 6| Step: 13
Training loss: 1.64877188205719
Validation loss: 1.9849448191222323

Epoch: 213| Step: 0
Training loss: 2.3290212154388428
Validation loss: 1.985507793323968

Epoch: 6| Step: 1
Training loss: 1.6666371822357178
Validation loss: 1.9781201116500362

Epoch: 6| Step: 2
Training loss: 2.5204758644104004
Validation loss: 2.027774203208185

Epoch: 6| Step: 3
Training loss: 2.017122745513916
Validation loss: 2.0377221056210097

Epoch: 6| Step: 4
Training loss: 1.9013917446136475
Validation loss: 2.018105076205346

Epoch: 6| Step: 5
Training loss: 1.263537049293518
Validation loss: 2.014974332624866

Epoch: 6| Step: 6
Training loss: 1.5594240427017212
Validation loss: 2.0326892099072857

Epoch: 6| Step: 7
Training loss: 1.7422456741333008
Validation loss: 2.045760562342982

Epoch: 6| Step: 8
Training loss: 1.889045000076294
Validation loss: 2.0533824274616856

Epoch: 6| Step: 9
Training loss: 1.7170846462249756
Validation loss: 1.9847432246772192

Epoch: 6| Step: 10
Training loss: 1.5447360277175903
Validation loss: 1.997852461312407

Epoch: 6| Step: 11
Training loss: 1.8981726169586182
Validation loss: 2.0059078893353863

Epoch: 6| Step: 12
Training loss: 1.6014856100082397
Validation loss: 2.055281562189902

Epoch: 6| Step: 13
Training loss: 2.1273183822631836
Validation loss: 2.0808095239823863

Epoch: 214| Step: 0
Training loss: 2.0441360473632812
Validation loss: 2.0636318960497455

Epoch: 6| Step: 1
Training loss: 1.932603120803833
Validation loss: 2.0671186293325117

Epoch: 6| Step: 2
Training loss: 1.0394706726074219
Validation loss: 2.04850483581584

Epoch: 6| Step: 3
Training loss: 1.6630010604858398
Validation loss: 1.9692855304287327

Epoch: 6| Step: 4
Training loss: 1.268131136894226
Validation loss: 1.9775551044812767

Epoch: 6| Step: 5
Training loss: 2.2492051124572754
Validation loss: 1.9823991162802583

Epoch: 6| Step: 6
Training loss: 2.1722989082336426
Validation loss: 2.0115710586629887

Epoch: 6| Step: 7
Training loss: 2.32220458984375
Validation loss: 2.0263415100753948

Epoch: 6| Step: 8
Training loss: 2.144158124923706
Validation loss: 1.922402730552099

Epoch: 6| Step: 9
Training loss: 1.3290269374847412
Validation loss: 1.9700493889470254

Epoch: 6| Step: 10
Training loss: 1.507278323173523
Validation loss: 1.981320159409636

Epoch: 6| Step: 11
Training loss: 2.6505162715911865
Validation loss: 2.0244925714308217

Epoch: 6| Step: 12
Training loss: 1.6733708381652832
Validation loss: 2.013961608691882

Epoch: 6| Step: 13
Training loss: 2.303269624710083
Validation loss: 1.9537572386444255

Epoch: 215| Step: 0
Training loss: 1.8946864604949951
Validation loss: 1.974691496100477

Epoch: 6| Step: 1
Training loss: 1.9241094589233398
Validation loss: 1.9671153970943984

Epoch: 6| Step: 2
Training loss: 1.9614977836608887
Validation loss: 1.9746765385391891

Epoch: 6| Step: 3
Training loss: 2.35538911819458
Validation loss: 1.9811437001792334

Epoch: 6| Step: 4
Training loss: 2.146725654602051
Validation loss: 1.981799711463272

Epoch: 6| Step: 5
Training loss: 1.7754329442977905
Validation loss: 2.0055797894795737

Epoch: 6| Step: 6
Training loss: 1.5125614404678345
Validation loss: 1.9756989696974396

Epoch: 6| Step: 7
Training loss: 1.4692978858947754
Validation loss: 2.020737888992474

Epoch: 6| Step: 8
Training loss: 1.7721755504608154
Validation loss: 1.9962171726329352

Epoch: 6| Step: 9
Training loss: 1.6086143255233765
Validation loss: 2.0233507015371837

Epoch: 6| Step: 10
Training loss: 1.6305562257766724
Validation loss: 1.9967329348287275

Epoch: 6| Step: 11
Training loss: 1.321634292602539
Validation loss: 1.9929891004357287

Epoch: 6| Step: 12
Training loss: 2.586894989013672
Validation loss: 1.9841975165951637

Epoch: 6| Step: 13
Training loss: 1.626232624053955
Validation loss: 1.991443318705405

Epoch: 216| Step: 0
Training loss: 1.6644172668457031
Validation loss: 1.9165375424969582

Epoch: 6| Step: 1
Training loss: 1.3789361715316772
Validation loss: 2.038764574194467

Epoch: 6| Step: 2
Training loss: 1.792220950126648
Validation loss: 1.9489867405224872

Epoch: 6| Step: 3
Training loss: 1.5903944969177246
Validation loss: 1.9803518556779431

Epoch: 6| Step: 4
Training loss: 1.2215170860290527
Validation loss: 1.9877217213312786

Epoch: 6| Step: 5
Training loss: 1.9852275848388672
Validation loss: 1.9413402747082453

Epoch: 6| Step: 6
Training loss: 1.8892199993133545
Validation loss: 2.0217973211760163

Epoch: 6| Step: 7
Training loss: 1.5147972106933594
Validation loss: 2.0032076720268495

Epoch: 6| Step: 8
Training loss: 1.768979549407959
Validation loss: 1.9867927284650906

Epoch: 6| Step: 9
Training loss: 1.9418323040008545
Validation loss: 2.009645886318658

Epoch: 6| Step: 10
Training loss: 2.2499938011169434
Validation loss: 1.907489320283295

Epoch: 6| Step: 11
Training loss: 1.5998961925506592
Validation loss: 2.0117034912109375

Epoch: 6| Step: 12
Training loss: 2.8420357704162598
Validation loss: 1.9783536516210085

Epoch: 6| Step: 13
Training loss: 1.3886804580688477
Validation loss: 1.9087772959022111

Epoch: 217| Step: 0
Training loss: 1.1441717147827148
Validation loss: 2.0265094618643484

Epoch: 6| Step: 1
Training loss: 2.912480354309082
Validation loss: 1.9802272204429872

Epoch: 6| Step: 2
Training loss: 1.3549065589904785
Validation loss: 1.9609728500407229

Epoch: 6| Step: 3
Training loss: 1.8900710344314575
Validation loss: 1.9457158862903554

Epoch: 6| Step: 4
Training loss: 1.501821756362915
Validation loss: 1.9710710548585462

Epoch: 6| Step: 5
Training loss: 1.3031047582626343
Validation loss: 1.95696634246457

Epoch: 6| Step: 6
Training loss: 2.7794532775878906
Validation loss: 2.0042955093486334

Epoch: 6| Step: 7
Training loss: 2.0142629146575928
Validation loss: 1.9694985151290894

Epoch: 6| Step: 8
Training loss: 0.8919705152511597
Validation loss: 1.9443421671467442

Epoch: 6| Step: 9
Training loss: 2.3837411403656006
Validation loss: 1.9872312981595275

Epoch: 6| Step: 10
Training loss: 2.1475017070770264
Validation loss: 1.9949871352923814

Epoch: 6| Step: 11
Training loss: 1.6307754516601562
Validation loss: 1.9991436389184767

Epoch: 6| Step: 12
Training loss: 1.5361108779907227
Validation loss: 2.014229569383847

Epoch: 6| Step: 13
Training loss: 1.4930531978607178
Validation loss: 2.0059202114741006

Epoch: 218| Step: 0
Training loss: 1.7508829832077026
Validation loss: 1.9696964012679232

Epoch: 6| Step: 1
Training loss: 2.4704887866973877
Validation loss: 2.0052478928719797

Epoch: 6| Step: 2
Training loss: 1.2980207204818726
Validation loss: 1.9563401053028722

Epoch: 6| Step: 3
Training loss: 1.4188228845596313
Validation loss: 1.9534886524241457

Epoch: 6| Step: 4
Training loss: 1.5035624504089355
Validation loss: 2.0338513748620146

Epoch: 6| Step: 5
Training loss: 1.7318041324615479
Validation loss: 2.0282146148784186

Epoch: 6| Step: 6
Training loss: 2.100125551223755
Validation loss: 2.066744171163087

Epoch: 6| Step: 7
Training loss: 1.7371419668197632
Validation loss: 2.0265488111844627

Epoch: 6| Step: 8
Training loss: 2.2319998741149902
Validation loss: 2.0054091843225623

Epoch: 6| Step: 9
Training loss: 1.6341581344604492
Validation loss: 1.9876485640002834

Epoch: 6| Step: 10
Training loss: 2.1875815391540527
Validation loss: 2.0040656623019966

Epoch: 6| Step: 11
Training loss: 1.5707933902740479
Validation loss: 1.9993851441209034

Epoch: 6| Step: 12
Training loss: 1.9141597747802734
Validation loss: 2.0116330487753755

Epoch: 6| Step: 13
Training loss: 2.097951650619507
Validation loss: 2.0077035427093506

Epoch: 219| Step: 0
Training loss: 2.4407074451446533
Validation loss: 1.9471427907225907

Epoch: 6| Step: 1
Training loss: 2.0301365852355957
Validation loss: 2.000820072748328

Epoch: 6| Step: 2
Training loss: 1.7138932943344116
Validation loss: 1.9857460529573503

Epoch: 6| Step: 3
Training loss: 1.7721569538116455
Validation loss: 1.9408318150428034

Epoch: 6| Step: 4
Training loss: 1.1910276412963867
Validation loss: 1.9834102353742045

Epoch: 6| Step: 5
Training loss: 1.8878074884414673
Validation loss: 1.9671518828279229

Epoch: 6| Step: 6
Training loss: 1.5315805673599243
Validation loss: 2.0030269827893985

Epoch: 6| Step: 7
Training loss: 1.7074463367462158
Validation loss: 1.9797297844322779

Epoch: 6| Step: 8
Training loss: 1.7873446941375732
Validation loss: 2.0546817984632266

Epoch: 6| Step: 9
Training loss: 1.6123273372650146
Validation loss: 2.016821433139104

Epoch: 6| Step: 10
Training loss: 2.312222480773926
Validation loss: 1.9576031059347174

Epoch: 6| Step: 11
Training loss: 1.466369390487671
Validation loss: 1.9785974205181163

Epoch: 6| Step: 12
Training loss: 2.402777910232544
Validation loss: 1.9882683471966816

Epoch: 6| Step: 13
Training loss: 1.8019235134124756
Validation loss: 2.0159299835082023

Epoch: 220| Step: 0
Training loss: 1.594858169555664
Validation loss: 2.0255824865833407

Epoch: 6| Step: 1
Training loss: 2.1270711421966553
Validation loss: 1.995104569260792

Epoch: 6| Step: 2
Training loss: 2.1613972187042236
Validation loss: 1.9829206415401992

Epoch: 6| Step: 3
Training loss: 1.42460298538208
Validation loss: 1.9800162981915217

Epoch: 6| Step: 4
Training loss: 1.7115322351455688
Validation loss: 1.9823979139328003

Epoch: 6| Step: 5
Training loss: 2.3865578174591064
Validation loss: 1.9437591311752156

Epoch: 6| Step: 6
Training loss: 1.7471277713775635
Validation loss: 1.9636019173488821

Epoch: 6| Step: 7
Training loss: 1.7342530488967896
Validation loss: 2.014275761060817

Epoch: 6| Step: 8
Training loss: 2.4766249656677246
Validation loss: 2.0128569551693496

Epoch: 6| Step: 9
Training loss: 2.270514488220215
Validation loss: 1.9685566591960129

Epoch: 6| Step: 10
Training loss: 0.9714992642402649
Validation loss: 1.955552944573023

Epoch: 6| Step: 11
Training loss: 1.7517051696777344
Validation loss: 1.9941856066385906

Epoch: 6| Step: 12
Training loss: 1.8914988040924072
Validation loss: 1.916716847368466

Epoch: 6| Step: 13
Training loss: 0.6669768691062927
Validation loss: 1.9895625345168575

Epoch: 221| Step: 0
Training loss: 1.320015549659729
Validation loss: 1.992401376847298

Epoch: 6| Step: 1
Training loss: 1.3738943338394165
Validation loss: 2.019496581887686

Epoch: 6| Step: 2
Training loss: 2.38193678855896
Validation loss: 1.970953610635573

Epoch: 6| Step: 3
Training loss: 1.9763145446777344
Validation loss: 1.9528057216316141

Epoch: 6| Step: 4
Training loss: 1.7286032438278198
Validation loss: 1.9780053592497302

Epoch: 6| Step: 5
Training loss: 1.100953221321106
Validation loss: 2.029410041788573

Epoch: 6| Step: 6
Training loss: 2.534778594970703
Validation loss: 2.003925956705565

Epoch: 6| Step: 7
Training loss: 1.5029540061950684
Validation loss: 1.980188056986819

Epoch: 6| Step: 8
Training loss: 1.6489555835723877
Validation loss: 2.0102957038469214

Epoch: 6| Step: 9
Training loss: 2.5587234497070312
Validation loss: 1.9765771986335836

Epoch: 6| Step: 10
Training loss: 1.735102653503418
Validation loss: 2.021227587935745

Epoch: 6| Step: 11
Training loss: 1.8852235078811646
Validation loss: 1.957730157400972

Epoch: 6| Step: 12
Training loss: 1.9132001399993896
Validation loss: 2.026286704565889

Epoch: 6| Step: 13
Training loss: 1.3408762216567993
Validation loss: 1.968842657663489

Epoch: 222| Step: 0
Training loss: 1.5041773319244385
Validation loss: 1.9176867392755323

Epoch: 6| Step: 1
Training loss: 1.836786150932312
Validation loss: 1.9911225021526378

Epoch: 6| Step: 2
Training loss: 1.7891789674758911
Validation loss: 2.0198577065621652

Epoch: 6| Step: 3
Training loss: 1.5394871234893799
Validation loss: 1.9890585663498088

Epoch: 6| Step: 4
Training loss: 2.1070632934570312
Validation loss: 1.9519942473339778

Epoch: 6| Step: 5
Training loss: 1.6351282596588135
Validation loss: 1.9604999326890515

Epoch: 6| Step: 6
Training loss: 1.5911846160888672
Validation loss: 1.9946897465695617

Epoch: 6| Step: 7
Training loss: 2.357318162918091
Validation loss: 1.9829067978807675

Epoch: 6| Step: 8
Training loss: 1.6120574474334717
Validation loss: 1.9849322611285793

Epoch: 6| Step: 9
Training loss: 1.843045949935913
Validation loss: 1.9570308128992717

Epoch: 6| Step: 10
Training loss: 1.685866355895996
Validation loss: 1.9839653917538222

Epoch: 6| Step: 11
Training loss: 2.2354938983917236
Validation loss: 1.951304945894467

Epoch: 6| Step: 12
Training loss: 2.0038647651672363
Validation loss: 1.9935357865466867

Epoch: 6| Step: 13
Training loss: 1.1442350149154663
Validation loss: 2.0103437797997588

Epoch: 223| Step: 0
Training loss: 2.0535058975219727
Validation loss: 1.9458289825788109

Epoch: 6| Step: 1
Training loss: 1.3840978145599365
Validation loss: 1.9780128014984952

Epoch: 6| Step: 2
Training loss: 2.3638758659362793
Validation loss: 1.969539701297719

Epoch: 6| Step: 3
Training loss: 1.6497399806976318
Validation loss: 2.0342283043810117

Epoch: 6| Step: 4
Training loss: 2.142634391784668
Validation loss: 1.9593749917963499

Epoch: 6| Step: 5
Training loss: 1.8011943101882935
Validation loss: 1.9846676229148783

Epoch: 6| Step: 6
Training loss: 1.6310174465179443
Validation loss: 1.9137643639759352

Epoch: 6| Step: 7
Training loss: 1.745930790901184
Validation loss: 1.9747559408987723

Epoch: 6| Step: 8
Training loss: 1.8636130094528198
Validation loss: 1.9523634833674277

Epoch: 6| Step: 9
Training loss: 1.2513055801391602
Validation loss: 1.9281136912684287

Epoch: 6| Step: 10
Training loss: 1.5690363645553589
Validation loss: 1.984250351946841

Epoch: 6| Step: 11
Training loss: 2.905252456665039
Validation loss: 1.9471449441807245

Epoch: 6| Step: 12
Training loss: 1.3798128366470337
Validation loss: 1.9898747321098083

Epoch: 6| Step: 13
Training loss: 1.4350634813308716
Validation loss: 1.9946557270583285

Epoch: 224| Step: 0
Training loss: 1.257091999053955
Validation loss: 1.9663059224364579

Epoch: 6| Step: 1
Training loss: 1.9797050952911377
Validation loss: 1.9627221797102241

Epoch: 6| Step: 2
Training loss: 0.8805394172668457
Validation loss: 1.936385485433763

Epoch: 6| Step: 3
Training loss: 1.5079909563064575
Validation loss: 1.9570519372981081

Epoch: 6| Step: 4
Training loss: 2.376436233520508
Validation loss: 1.9724313712889148

Epoch: 6| Step: 5
Training loss: 1.5396767854690552
Validation loss: 2.0151564152010026

Epoch: 6| Step: 6
Training loss: 1.5399813652038574
Validation loss: 1.9624866695814236

Epoch: 6| Step: 7
Training loss: 1.9486963748931885
Validation loss: 1.9400511377601213

Epoch: 6| Step: 8
Training loss: 1.7584822177886963
Validation loss: 2.0287854197204753

Epoch: 6| Step: 9
Training loss: 1.9102592468261719
Validation loss: 1.9980900954174738

Epoch: 6| Step: 10
Training loss: 1.0313947200775146
Validation loss: 2.0002260182493474

Epoch: 6| Step: 11
Training loss: 2.490222454071045
Validation loss: 1.9741799446844286

Epoch: 6| Step: 12
Training loss: 2.1678836345672607
Validation loss: 1.9558689453268563

Epoch: 6| Step: 13
Training loss: 2.9327332973480225
Validation loss: 1.9592364449654855

Epoch: 225| Step: 0
Training loss: 1.1298730373382568
Validation loss: 1.9715557098388672

Epoch: 6| Step: 1
Training loss: 1.355868935585022
Validation loss: 2.0256318764020036

Epoch: 6| Step: 2
Training loss: 2.148526191711426
Validation loss: 1.981405378669821

Epoch: 6| Step: 3
Training loss: 1.9448436498641968
Validation loss: 1.9786793660092097

Epoch: 6| Step: 4
Training loss: 1.7727856636047363
Validation loss: 1.9706876483014835

Epoch: 6| Step: 5
Training loss: 2.097667694091797
Validation loss: 2.0027559508559523

Epoch: 6| Step: 6
Training loss: 2.169266939163208
Validation loss: 2.018943296965732

Epoch: 6| Step: 7
Training loss: 1.111365556716919
Validation loss: 1.9962133258901618

Epoch: 6| Step: 8
Training loss: 2.0128390789031982
Validation loss: 2.0234738165332424

Epoch: 6| Step: 9
Training loss: 1.5281730890274048
Validation loss: 2.007685069114931

Epoch: 6| Step: 10
Training loss: 2.020390272140503
Validation loss: 1.9377027609015023

Epoch: 6| Step: 11
Training loss: 1.3236043453216553
Validation loss: 1.953956352767124

Epoch: 6| Step: 12
Training loss: 2.3792951107025146
Validation loss: 1.9605091720499017

Epoch: 6| Step: 13
Training loss: 2.8850324153900146
Validation loss: 2.018752444174982

Epoch: 226| Step: 0
Training loss: 1.783496618270874
Validation loss: 2.010722306466872

Epoch: 6| Step: 1
Training loss: 2.362163543701172
Validation loss: 1.9628419196733864

Epoch: 6| Step: 2
Training loss: 3.007948637008667
Validation loss: 1.9507804314295452

Epoch: 6| Step: 3
Training loss: 0.9296650886535645
Validation loss: 2.02948978254872

Epoch: 6| Step: 4
Training loss: 1.8946022987365723
Validation loss: 2.0053320007939495

Epoch: 6| Step: 5
Training loss: 1.6287548542022705
Validation loss: 2.0153912408377535

Epoch: 6| Step: 6
Training loss: 1.9978342056274414
Validation loss: 2.0122687778165265

Epoch: 6| Step: 7
Training loss: 1.7250123023986816
Validation loss: 2.0614665759507047

Epoch: 6| Step: 8
Training loss: 1.8436115980148315
Validation loss: 1.9938201186477498

Epoch: 6| Step: 9
Training loss: 1.6763157844543457
Validation loss: 2.0623227421955397

Epoch: 6| Step: 10
Training loss: 1.8377376794815063
Validation loss: 1.968389416253695

Epoch: 6| Step: 11
Training loss: 1.2581405639648438
Validation loss: 1.987149191159074

Epoch: 6| Step: 12
Training loss: 1.4560282230377197
Validation loss: 2.0049419454348985

Epoch: 6| Step: 13
Training loss: 1.6034965515136719
Validation loss: 2.0044605693509503

Epoch: 227| Step: 0
Training loss: 1.9648878574371338
Validation loss: 2.0485251411314933

Epoch: 6| Step: 1
Training loss: 1.7008554935455322
Validation loss: 1.9825662643678728

Epoch: 6| Step: 2
Training loss: 1.3136436939239502
Validation loss: 1.970528136017502

Epoch: 6| Step: 3
Training loss: 1.325118064880371
Validation loss: 2.0003186361764067

Epoch: 6| Step: 4
Training loss: 2.6086506843566895
Validation loss: 1.951260591066012

Epoch: 6| Step: 5
Training loss: 1.6676729917526245
Validation loss: 1.932946200011879

Epoch: 6| Step: 6
Training loss: 1.8830955028533936
Validation loss: 1.9763590648610105

Epoch: 6| Step: 7
Training loss: 1.6599152088165283
Validation loss: 1.9789451873430641

Epoch: 6| Step: 8
Training loss: 2.1560916900634766
Validation loss: 2.035560046472857

Epoch: 6| Step: 9
Training loss: 1.7585277557373047
Validation loss: 1.9057840044780443

Epoch: 6| Step: 10
Training loss: 1.1101710796356201
Validation loss: 1.980986690008512

Epoch: 6| Step: 11
Training loss: 2.762911796569824
Validation loss: 1.987825430849547

Epoch: 6| Step: 12
Training loss: 1.4318585395812988
Validation loss: 1.9663573952131375

Epoch: 6| Step: 13
Training loss: 1.2487201690673828
Validation loss: 1.9470359689445906

Epoch: 228| Step: 0
Training loss: 1.6098790168762207
Validation loss: 1.9950416831560032

Epoch: 6| Step: 1
Training loss: 1.6892049312591553
Validation loss: 1.9469414218779533

Epoch: 6| Step: 2
Training loss: 1.5782957077026367
Validation loss: 1.9936694714330858

Epoch: 6| Step: 3
Training loss: 1.8612680435180664
Validation loss: 1.9950158596038818

Epoch: 6| Step: 4
Training loss: 2.25399112701416
Validation loss: 2.02843407148956

Epoch: 6| Step: 5
Training loss: 1.560030221939087
Validation loss: 2.0088011423746743

Epoch: 6| Step: 6
Training loss: 1.1913981437683105
Validation loss: 1.9722785154978435

Epoch: 6| Step: 7
Training loss: 1.9776017665863037
Validation loss: 1.9794791488237278

Epoch: 6| Step: 8
Training loss: 1.9272229671478271
Validation loss: 1.9494424686636975

Epoch: 6| Step: 9
Training loss: 2.709712505340576
Validation loss: 1.9755473739357405

Epoch: 6| Step: 10
Training loss: 1.6928038597106934
Validation loss: 1.976256734581404

Epoch: 6| Step: 11
Training loss: 1.536576747894287
Validation loss: 1.930666999150348

Epoch: 6| Step: 12
Training loss: 1.7312859296798706
Validation loss: 1.993479488998331

Epoch: 6| Step: 13
Training loss: 1.8627209663391113
Validation loss: 1.9551940425749748

Epoch: 229| Step: 0
Training loss: 1.8438663482666016
Validation loss: 1.955464275934363

Epoch: 6| Step: 1
Training loss: 2.0144500732421875
Validation loss: 1.9458415879998157

Epoch: 6| Step: 2
Training loss: 2.1808526515960693
Validation loss: 1.9497643132363596

Epoch: 6| Step: 3
Training loss: 1.555519938468933
Validation loss: 1.9923030561016453

Epoch: 6| Step: 4
Training loss: 1.5463367700576782
Validation loss: 2.008299966012278

Epoch: 6| Step: 5
Training loss: 2.2100319862365723
Validation loss: 1.8912290808975056

Epoch: 6| Step: 6
Training loss: 1.6113128662109375
Validation loss: 1.9706260978534658

Epoch: 6| Step: 7
Training loss: 2.1878864765167236
Validation loss: 1.943912354848718

Epoch: 6| Step: 8
Training loss: 1.2370027303695679
Validation loss: 2.0392129767325615

Epoch: 6| Step: 9
Training loss: 1.6031711101531982
Validation loss: 1.9503434742650678

Epoch: 6| Step: 10
Training loss: 1.842749834060669
Validation loss: 1.9777897968087146

Epoch: 6| Step: 11
Training loss: 2.576828956604004
Validation loss: 1.9803967796346194

Epoch: 6| Step: 12
Training loss: 1.519301176071167
Validation loss: 1.9642830792293753

Epoch: 6| Step: 13
Training loss: 0.8475261926651001
Validation loss: 1.9653443559523551

Epoch: 230| Step: 0
Training loss: 1.6828505992889404
Validation loss: 1.9529528489676855

Epoch: 6| Step: 1
Training loss: 1.7250950336456299
Validation loss: 2.013392963717061

Epoch: 6| Step: 2
Training loss: 1.7384142875671387
Validation loss: 1.992310477841285

Epoch: 6| Step: 3
Training loss: 2.225672721862793
Validation loss: 1.9849024613698323

Epoch: 6| Step: 4
Training loss: 2.1363844871520996
Validation loss: 1.9590875410264539

Epoch: 6| Step: 5
Training loss: 1.309070348739624
Validation loss: 1.9951401000381799

Epoch: 6| Step: 6
Training loss: 2.0029685497283936
Validation loss: 1.9893202012585056

Epoch: 6| Step: 7
Training loss: 2.3610129356384277
Validation loss: 1.9474161171144055

Epoch: 6| Step: 8
Training loss: 1.6683762073516846
Validation loss: 1.9641762292513283

Epoch: 6| Step: 9
Training loss: 1.539259433746338
Validation loss: 2.0551100853950746

Epoch: 6| Step: 10
Training loss: 1.1122841835021973
Validation loss: 1.9577858319846533

Epoch: 6| Step: 11
Training loss: 1.7993545532226562
Validation loss: 1.9442201711798226

Epoch: 6| Step: 12
Training loss: 1.7545337677001953
Validation loss: 1.9952473409714238

Epoch: 6| Step: 13
Training loss: 2.8075177669525146
Validation loss: 1.9970821744652205

Epoch: 231| Step: 0
Training loss: 1.0987434387207031
Validation loss: 1.9810332880225232

Epoch: 6| Step: 1
Training loss: 1.5511442422866821
Validation loss: 1.9452919652385097

Epoch: 6| Step: 2
Training loss: 1.267927646636963
Validation loss: 1.999792956536816

Epoch: 6| Step: 3
Training loss: 1.628028154373169
Validation loss: 1.9559926730330273

Epoch: 6| Step: 4
Training loss: 1.9232947826385498
Validation loss: 1.9281700170168312

Epoch: 6| Step: 5
Training loss: 2.3114211559295654
Validation loss: 1.967167232626228

Epoch: 6| Step: 6
Training loss: 2.0367863178253174
Validation loss: 2.0066828791813185

Epoch: 6| Step: 7
Training loss: 2.3600940704345703
Validation loss: 1.9817233380450998

Epoch: 6| Step: 8
Training loss: 1.9853273630142212
Validation loss: 1.8948508565143873

Epoch: 6| Step: 9
Training loss: 2.131836414337158
Validation loss: 1.971557823560571

Epoch: 6| Step: 10
Training loss: 1.5927540063858032
Validation loss: 2.008863816979111

Epoch: 6| Step: 11
Training loss: 1.8265223503112793
Validation loss: 2.0069179406730075

Epoch: 6| Step: 12
Training loss: 1.2027044296264648
Validation loss: 2.022362623163449

Epoch: 6| Step: 13
Training loss: 2.212376832962036
Validation loss: 2.0364166100819907

Epoch: 232| Step: 0
Training loss: 1.3172119855880737
Validation loss: 1.968419180121473

Epoch: 6| Step: 1
Training loss: 1.2454712390899658
Validation loss: 2.0028180396685036

Epoch: 6| Step: 2
Training loss: 1.4680440425872803
Validation loss: 2.0006219033272035

Epoch: 6| Step: 3
Training loss: 2.9335134029388428
Validation loss: 1.9756944910172494

Epoch: 6| Step: 4
Training loss: 1.8276981115341187
Validation loss: 1.9976188880141064

Epoch: 6| Step: 5
Training loss: 1.7151753902435303
Validation loss: 1.9618262180718042

Epoch: 6| Step: 6
Training loss: 2.01517915725708
Validation loss: 1.9919596102929884

Epoch: 6| Step: 7
Training loss: 1.6425230503082275
Validation loss: 1.9467241366704304

Epoch: 6| Step: 8
Training loss: 1.995157241821289
Validation loss: 1.9329566827384375

Epoch: 6| Step: 9
Training loss: 2.048130512237549
Validation loss: 1.963757804645005

Epoch: 6| Step: 10
Training loss: 1.3980116844177246
Validation loss: 1.9563703126804803

Epoch: 6| Step: 11
Training loss: 2.4776501655578613
Validation loss: 1.9518160627734276

Epoch: 6| Step: 12
Training loss: 1.281059741973877
Validation loss: 1.9783699563754502

Epoch: 6| Step: 13
Training loss: 1.538915753364563
Validation loss: 1.9465801203122703

Epoch: 233| Step: 0
Training loss: 2.356706380844116
Validation loss: 1.949283835708454

Epoch: 6| Step: 1
Training loss: 2.3232226371765137
Validation loss: 1.9842970050791258

Epoch: 6| Step: 2
Training loss: 1.4829063415527344
Validation loss: 1.955402676777173

Epoch: 6| Step: 3
Training loss: 1.467136025428772
Validation loss: 1.9815274669278053

Epoch: 6| Step: 4
Training loss: 2.498439073562622
Validation loss: 1.9808695841861028

Epoch: 6| Step: 5
Training loss: 1.6806843280792236
Validation loss: 1.9978085922938522

Epoch: 6| Step: 6
Training loss: 1.8701233863830566
Validation loss: 1.9328407933635097

Epoch: 6| Step: 7
Training loss: 1.2338619232177734
Validation loss: 1.9622023310712589

Epoch: 6| Step: 8
Training loss: 1.1356182098388672
Validation loss: 1.9701758136031449

Epoch: 6| Step: 9
Training loss: 1.9231774806976318
Validation loss: 2.0318654634619273

Epoch: 6| Step: 10
Training loss: 1.833460807800293
Validation loss: 2.0186762476480133

Epoch: 6| Step: 11
Training loss: 1.483335018157959
Validation loss: 2.0158788850230556

Epoch: 6| Step: 12
Training loss: 1.6086866855621338
Validation loss: 2.0179867359899704

Epoch: 6| Step: 13
Training loss: 2.144862174987793
Validation loss: 1.93568770347103

Epoch: 234| Step: 0
Training loss: 1.1641182899475098
Validation loss: 2.0094502420835596

Epoch: 6| Step: 1
Training loss: 2.1409876346588135
Validation loss: 1.9635370316043976

Epoch: 6| Step: 2
Training loss: 1.6134798526763916
Validation loss: 2.013257036926926

Epoch: 6| Step: 3
Training loss: 1.7347404956817627
Validation loss: 1.9066187591962918

Epoch: 6| Step: 4
Training loss: 1.4593524932861328
Validation loss: 1.9832010140983007

Epoch: 6| Step: 5
Training loss: 1.797428846359253
Validation loss: 1.9864532998813096

Epoch: 6| Step: 6
Training loss: 2.058021068572998
Validation loss: 1.99265803060224

Epoch: 6| Step: 7
Training loss: 1.7642319202423096
Validation loss: 1.9830663229829522

Epoch: 6| Step: 8
Training loss: 1.7158756256103516
Validation loss: 1.9482475916544597

Epoch: 6| Step: 9
Training loss: 1.6476045846939087
Validation loss: 1.983519825884091

Epoch: 6| Step: 10
Training loss: 2.2601242065429688
Validation loss: 1.9452106862939813

Epoch: 6| Step: 11
Training loss: 1.7822730541229248
Validation loss: 1.9949398527863205

Epoch: 6| Step: 12
Training loss: 2.0825881958007812
Validation loss: 1.9293597385447512

Epoch: 6| Step: 13
Training loss: 1.7912766933441162
Validation loss: 1.9641866863414805

Epoch: 235| Step: 0
Training loss: 1.7965914011001587
Validation loss: 1.9999902043291318

Epoch: 6| Step: 1
Training loss: 1.300621509552002
Validation loss: 1.9820983473972609

Epoch: 6| Step: 2
Training loss: 1.6276817321777344
Validation loss: 2.0030064326460644

Epoch: 6| Step: 3
Training loss: 1.9872732162475586
Validation loss: 2.0324391626542613

Epoch: 6| Step: 4
Training loss: 1.2316832542419434
Validation loss: 2.0149746889709146

Epoch: 6| Step: 5
Training loss: 1.797074794769287
Validation loss: 2.021521734934981

Epoch: 6| Step: 6
Training loss: 2.240720272064209
Validation loss: 1.9978673740099835

Epoch: 6| Step: 7
Training loss: 1.4162702560424805
Validation loss: 1.9997606380011446

Epoch: 6| Step: 8
Training loss: 1.0860059261322021
Validation loss: 1.9407672394988358

Epoch: 6| Step: 9
Training loss: 2.3586082458496094
Validation loss: 1.9792533766838811

Epoch: 6| Step: 10
Training loss: 1.7412769794464111
Validation loss: 1.9754902162859518

Epoch: 6| Step: 11
Training loss: 1.9897072315216064
Validation loss: 1.9992673909792336

Epoch: 6| Step: 12
Training loss: 2.0115694999694824
Validation loss: 2.0101874592483684

Epoch: 6| Step: 13
Training loss: 2.046614408493042
Validation loss: 1.9809489442456154

Epoch: 236| Step: 0
Training loss: 1.7039873600006104
Validation loss: 1.977436896293394

Epoch: 6| Step: 1
Training loss: 2.247422218322754
Validation loss: 1.9533062647747736

Epoch: 6| Step: 2
Training loss: 1.7529535293579102
Validation loss: 1.9835947200816164

Epoch: 6| Step: 3
Training loss: 1.1620948314666748
Validation loss: 1.9709126539127801

Epoch: 6| Step: 4
Training loss: 1.8209800720214844
Validation loss: 1.967654066701089

Epoch: 6| Step: 5
Training loss: 1.500209093093872
Validation loss: 1.9650335875890588

Epoch: 6| Step: 6
Training loss: 1.6258149147033691
Validation loss: 1.993025718196746

Epoch: 6| Step: 7
Training loss: 1.078128457069397
Validation loss: 1.8978895166868806

Epoch: 6| Step: 8
Training loss: 2.749459743499756
Validation loss: 1.933436119428245

Epoch: 6| Step: 9
Training loss: 2.305891752243042
Validation loss: 1.9732470704663185

Epoch: 6| Step: 10
Training loss: 1.264397144317627
Validation loss: 1.942180174653248

Epoch: 6| Step: 11
Training loss: 1.916520357131958
Validation loss: 1.967718303844493

Epoch: 6| Step: 12
Training loss: 1.794203281402588
Validation loss: 1.9784281766542824

Epoch: 6| Step: 13
Training loss: 1.0582420825958252
Validation loss: 1.9080293332376788

Epoch: 237| Step: 0
Training loss: 1.3120944499969482
Validation loss: 1.9866261379693144

Epoch: 6| Step: 1
Training loss: 1.4136358499526978
Validation loss: 1.964103760257844

Epoch: 6| Step: 2
Training loss: 1.8509165048599243
Validation loss: 1.9533377975545905

Epoch: 6| Step: 3
Training loss: 1.7069038152694702
Validation loss: 1.9723532379314463

Epoch: 6| Step: 4
Training loss: 1.7120074033737183
Validation loss: 1.9711794109754666

Epoch: 6| Step: 5
Training loss: 2.3460776805877686
Validation loss: 1.97658202468708

Epoch: 6| Step: 6
Training loss: 1.8167295455932617
Validation loss: 1.9715309501976095

Epoch: 6| Step: 7
Training loss: 1.9828484058380127
Validation loss: 1.8989758658152756

Epoch: 6| Step: 8
Training loss: 1.706822395324707
Validation loss: 1.9957225694451282

Epoch: 6| Step: 9
Training loss: 1.4198102951049805
Validation loss: 1.9947264335488761

Epoch: 6| Step: 10
Training loss: 2.2491626739501953
Validation loss: 1.9779939087488319

Epoch: 6| Step: 11
Training loss: 1.9262343645095825
Validation loss: 1.9145566635234381

Epoch: 6| Step: 12
Training loss: 1.3133971691131592
Validation loss: 1.969988307645244

Epoch: 6| Step: 13
Training loss: 2.4253573417663574
Validation loss: 2.0230449963641424

Epoch: 238| Step: 0
Training loss: 1.462392807006836
Validation loss: 2.007229999829364

Epoch: 6| Step: 1
Training loss: 2.0499887466430664
Validation loss: 1.976386644506967

Epoch: 6| Step: 2
Training loss: 2.364607334136963
Validation loss: 1.9772552674816501

Epoch: 6| Step: 3
Training loss: 1.2581737041473389
Validation loss: 2.0003764552454792

Epoch: 6| Step: 4
Training loss: 2.0464835166931152
Validation loss: 2.0655920838796966

Epoch: 6| Step: 5
Training loss: 2.4646644592285156
Validation loss: 1.9941312587389382

Epoch: 6| Step: 6
Training loss: 1.3754686117172241
Validation loss: 1.9407660948332919

Epoch: 6| Step: 7
Training loss: 1.731583595275879
Validation loss: 2.0582910481319634

Epoch: 6| Step: 8
Training loss: 1.1564455032348633
Validation loss: 1.8936961517539075

Epoch: 6| Step: 9
Training loss: 2.0744316577911377
Validation loss: 1.9589688162649832

Epoch: 6| Step: 10
Training loss: 1.667478322982788
Validation loss: 1.9811754457412227

Epoch: 6| Step: 11
Training loss: 1.5239293575286865
Validation loss: 1.982809510282291

Epoch: 6| Step: 12
Training loss: 1.8625590801239014
Validation loss: 1.9557844246587446

Epoch: 6| Step: 13
Training loss: 1.9235708713531494
Validation loss: 1.9428048133850098

Epoch: 239| Step: 0
Training loss: 1.140982985496521
Validation loss: 1.9465906209843133

Epoch: 6| Step: 1
Training loss: 1.54445481300354
Validation loss: 1.9535336930264708

Epoch: 6| Step: 2
Training loss: 1.3431434631347656
Validation loss: 1.9834605468216764

Epoch: 6| Step: 3
Training loss: 2.6391682624816895
Validation loss: 1.948740005493164

Epoch: 6| Step: 4
Training loss: 1.3064873218536377
Validation loss: 1.9312416661170222

Epoch: 6| Step: 5
Training loss: 1.8434815406799316
Validation loss: 1.974876303826609

Epoch: 6| Step: 6
Training loss: 2.3153059482574463
Validation loss: 1.9599093314140075

Epoch: 6| Step: 7
Training loss: 1.352306604385376
Validation loss: 1.951198572753578

Epoch: 6| Step: 8
Training loss: 1.4611353874206543
Validation loss: 1.944425312421655

Epoch: 6| Step: 9
Training loss: 1.5031943321228027
Validation loss: 1.9460702865354476

Epoch: 6| Step: 10
Training loss: 2.434215545654297
Validation loss: 1.987093617839198

Epoch: 6| Step: 11
Training loss: 2.3715381622314453
Validation loss: 1.9275828548656997

Epoch: 6| Step: 12
Training loss: 1.6934075355529785
Validation loss: 1.9448067013935377

Epoch: 6| Step: 13
Training loss: 1.7387880086898804
Validation loss: 1.9398953222459363

Epoch: 240| Step: 0
Training loss: 1.9170455932617188
Validation loss: 1.9711872121339202

Epoch: 6| Step: 1
Training loss: 2.165973663330078
Validation loss: 1.9690077381749307

Epoch: 6| Step: 2
Training loss: 1.4314744472503662
Validation loss: 2.0015526304962816

Epoch: 6| Step: 3
Training loss: 2.100964069366455
Validation loss: 1.9773411353429158

Epoch: 6| Step: 4
Training loss: 2.148888111114502
Validation loss: 1.9290648660352152

Epoch: 6| Step: 5
Training loss: 1.548438310623169
Validation loss: 1.9845730091935845

Epoch: 6| Step: 6
Training loss: 1.6601427793502808
Validation loss: 1.9385604807125625

Epoch: 6| Step: 7
Training loss: 1.6989779472351074
Validation loss: 1.9517529933683333

Epoch: 6| Step: 8
Training loss: 1.1118426322937012
Validation loss: 1.980121022911482

Epoch: 6| Step: 9
Training loss: 1.7268646955490112
Validation loss: 2.0463726571811143

Epoch: 6| Step: 10
Training loss: 1.7728312015533447
Validation loss: 2.010509983185799

Epoch: 6| Step: 11
Training loss: 1.6707499027252197
Validation loss: 2.020421056337254

Epoch: 6| Step: 12
Training loss: 1.8124455213546753
Validation loss: 2.007302471386489

Epoch: 6| Step: 13
Training loss: 1.698090672492981
Validation loss: 2.00330190761115

Epoch: 241| Step: 0
Training loss: 2.186429500579834
Validation loss: 2.012552488234735

Epoch: 6| Step: 1
Training loss: 1.2070989608764648
Validation loss: 1.9815122594115555

Epoch: 6| Step: 2
Training loss: 1.5979537963867188
Validation loss: 1.9876144432252454

Epoch: 6| Step: 3
Training loss: 1.1307275295257568
Validation loss: 2.002407084229172

Epoch: 6| Step: 4
Training loss: 1.7203807830810547
Validation loss: 1.9743963185177054

Epoch: 6| Step: 5
Training loss: 2.3734591007232666
Validation loss: 1.9935665104978828

Epoch: 6| Step: 6
Training loss: 1.6281883716583252
Validation loss: 1.9831177419231785

Epoch: 6| Step: 7
Training loss: 1.949050784111023
Validation loss: 1.9765633216468237

Epoch: 6| Step: 8
Training loss: 1.4689724445343018
Validation loss: 1.9539745392337922

Epoch: 6| Step: 9
Training loss: 1.5899055004119873
Validation loss: 1.9858799108894922

Epoch: 6| Step: 10
Training loss: 2.1972362995147705
Validation loss: 2.001409511412344

Epoch: 6| Step: 11
Training loss: 1.8238531351089478
Validation loss: 1.9720609341898272

Epoch: 6| Step: 12
Training loss: 1.7110090255737305
Validation loss: 1.9916446414045108

Epoch: 6| Step: 13
Training loss: 2.083857536315918
Validation loss: 1.9672039452419485

Epoch: 242| Step: 0
Training loss: 1.7087361812591553
Validation loss: 1.9763977835255284

Epoch: 6| Step: 1
Training loss: 1.953107237815857
Validation loss: 1.9851417951686408

Epoch: 6| Step: 2
Training loss: 1.950645923614502
Validation loss: 1.9165107768069032

Epoch: 6| Step: 3
Training loss: 1.800307035446167
Validation loss: 1.9873584431986655

Epoch: 6| Step: 4
Training loss: 1.401429295539856
Validation loss: 1.9733036538606048

Epoch: 6| Step: 5
Training loss: 1.4604213237762451
Validation loss: 1.929806609307566

Epoch: 6| Step: 6
Training loss: 1.6407461166381836
Validation loss: 1.9511080788027855

Epoch: 6| Step: 7
Training loss: 2.4861176013946533
Validation loss: 1.931295464115758

Epoch: 6| Step: 8
Training loss: 1.5914599895477295
Validation loss: 1.8845547476122457

Epoch: 6| Step: 9
Training loss: 1.5341893434524536
Validation loss: 1.9277591166957733

Epoch: 6| Step: 10
Training loss: 1.6819809675216675
Validation loss: 1.9632862511501517

Epoch: 6| Step: 11
Training loss: 1.2397894859313965
Validation loss: 1.9913258847369943

Epoch: 6| Step: 12
Training loss: 2.536876678466797
Validation loss: 1.9505009433274627

Epoch: 6| Step: 13
Training loss: 1.9769134521484375
Validation loss: 1.9361413037905129

Epoch: 243| Step: 0
Training loss: 1.2151648998260498
Validation loss: 1.9621508352218135

Epoch: 6| Step: 1
Training loss: 1.9631346464157104
Validation loss: 2.0074252569547264

Epoch: 6| Step: 2
Training loss: 1.601786494255066
Validation loss: 1.9113170818615985

Epoch: 6| Step: 3
Training loss: 2.2282474040985107
Validation loss: 1.9646750419370589

Epoch: 6| Step: 4
Training loss: 1.4395345449447632
Validation loss: 1.9461250356448594

Epoch: 6| Step: 5
Training loss: 2.1767473220825195
Validation loss: 1.914103005522041

Epoch: 6| Step: 6
Training loss: 1.207413673400879
Validation loss: 1.9608733115657684

Epoch: 6| Step: 7
Training loss: 1.8246458768844604
Validation loss: 1.9929490217598536

Epoch: 6| Step: 8
Training loss: 1.2748687267303467
Validation loss: 1.9905041263949486

Epoch: 6| Step: 9
Training loss: 2.379147529602051
Validation loss: 1.9012065549050607

Epoch: 6| Step: 10
Training loss: 1.8241603374481201
Validation loss: 1.9846091270446777

Epoch: 6| Step: 11
Training loss: 2.201749324798584
Validation loss: 1.8953018752477502

Epoch: 6| Step: 12
Training loss: 1.2920596599578857
Validation loss: 1.9851575320766819

Epoch: 6| Step: 13
Training loss: 2.4427366256713867
Validation loss: 1.918365668225032

Epoch: 244| Step: 0
Training loss: 2.5758309364318848
Validation loss: 1.9697871028736074

Epoch: 6| Step: 1
Training loss: 1.6387529373168945
Validation loss: 1.966300582373014

Epoch: 6| Step: 2
Training loss: 2.1925816535949707
Validation loss: 1.9417004175083612

Epoch: 6| Step: 3
Training loss: 1.8782081604003906
Validation loss: 1.9795784975892754

Epoch: 6| Step: 4
Training loss: 2.0793044567108154
Validation loss: 1.922615763961628

Epoch: 6| Step: 5
Training loss: 1.6562480926513672
Validation loss: 1.967240656575849

Epoch: 6| Step: 6
Training loss: 1.5644313097000122
Validation loss: 1.9541543658061693

Epoch: 6| Step: 7
Training loss: 1.1306042671203613
Validation loss: 2.025771874253468

Epoch: 6| Step: 8
Training loss: 1.6684329509735107
Validation loss: 1.9665789219640917

Epoch: 6| Step: 9
Training loss: 1.750657081604004
Validation loss: 1.9908599776606406

Epoch: 6| Step: 10
Training loss: 1.4091942310333252
Validation loss: 1.9744571191008373

Epoch: 6| Step: 11
Training loss: 1.2540538311004639
Validation loss: 1.9556544467967043

Epoch: 6| Step: 12
Training loss: 1.4487078189849854
Validation loss: 2.0124198326500515

Epoch: 6| Step: 13
Training loss: 2.1480817794799805
Validation loss: 1.9450905297392158

Epoch: 245| Step: 0
Training loss: 0.6811560392379761
Validation loss: 1.946105767321843

Epoch: 6| Step: 1
Training loss: 1.7824504375457764
Validation loss: 1.978686010965737

Epoch: 6| Step: 2
Training loss: 1.9530404806137085
Validation loss: 1.975159422043831

Epoch: 6| Step: 3
Training loss: 1.7887685298919678
Validation loss: 1.9856985397236322

Epoch: 6| Step: 4
Training loss: 1.7488572597503662
Validation loss: 2.0134846728335143

Epoch: 6| Step: 5
Training loss: 1.472454309463501
Validation loss: 1.923049356347771

Epoch: 6| Step: 6
Training loss: 1.9167364835739136
Validation loss: 1.948505634902626

Epoch: 6| Step: 7
Training loss: 1.708740472793579
Validation loss: 1.9115357539987052

Epoch: 6| Step: 8
Training loss: 1.752679705619812
Validation loss: 2.000703301481021

Epoch: 6| Step: 9
Training loss: 2.5986456871032715
Validation loss: 1.9170975826119865

Epoch: 6| Step: 10
Training loss: 1.48673677444458
Validation loss: 1.9005361000696819

Epoch: 6| Step: 11
Training loss: 1.6404674053192139
Validation loss: 1.945945752564297

Epoch: 6| Step: 12
Training loss: 1.503458023071289
Validation loss: 2.00991996642082

Epoch: 6| Step: 13
Training loss: 1.8515572547912598
Validation loss: 1.9463453203119256

Epoch: 246| Step: 0
Training loss: 2.084263801574707
Validation loss: 1.9645185906399962

Epoch: 6| Step: 1
Training loss: 1.577925443649292
Validation loss: 1.9615010958845898

Epoch: 6| Step: 2
Training loss: 1.9102370738983154
Validation loss: 1.9235790147576282

Epoch: 6| Step: 3
Training loss: 1.5251259803771973
Validation loss: 1.9926864613768875

Epoch: 6| Step: 4
Training loss: 1.7274086475372314
Validation loss: 1.9780685299186296

Epoch: 6| Step: 5
Training loss: 1.1727685928344727
Validation loss: 1.993434658614538

Epoch: 6| Step: 6
Training loss: 2.102631092071533
Validation loss: 1.9408683341036561

Epoch: 6| Step: 7
Training loss: 1.6252179145812988
Validation loss: 1.942844072977702

Epoch: 6| Step: 8
Training loss: 1.3769443035125732
Validation loss: 1.9525978360124814

Epoch: 6| Step: 9
Training loss: 1.5948225259780884
Validation loss: 1.9162225018265426

Epoch: 6| Step: 10
Training loss: 1.5710169076919556
Validation loss: 1.9488498677489579

Epoch: 6| Step: 11
Training loss: 1.7075893878936768
Validation loss: 1.9239563557409471

Epoch: 6| Step: 12
Training loss: 2.030449867248535
Validation loss: 1.9538709553339149

Epoch: 6| Step: 13
Training loss: 1.8694424629211426
Validation loss: 1.9420721684732745

Epoch: 247| Step: 0
Training loss: 1.3825969696044922
Validation loss: 1.9630772234291158

Epoch: 6| Step: 1
Training loss: 1.842155933380127
Validation loss: 1.9694517530420774

Epoch: 6| Step: 2
Training loss: 2.1421399116516113
Validation loss: 1.9299857001150809

Epoch: 6| Step: 3
Training loss: 1.621657133102417
Validation loss: 1.9066235788406865

Epoch: 6| Step: 4
Training loss: 1.4791383743286133
Validation loss: 1.9250622398109847

Epoch: 6| Step: 5
Training loss: 1.5254241228103638
Validation loss: 1.9181901319052583

Epoch: 6| Step: 6
Training loss: 1.651146650314331
Validation loss: 1.9525349652895363

Epoch: 6| Step: 7
Training loss: 1.4921860694885254
Validation loss: 1.9113298180282756

Epoch: 6| Step: 8
Training loss: 1.5462453365325928
Validation loss: 1.9410273336595105

Epoch: 6| Step: 9
Training loss: 1.6816227436065674
Validation loss: 1.8872154887004564

Epoch: 6| Step: 10
Training loss: 1.4745910167694092
Validation loss: 1.906528055026967

Epoch: 6| Step: 11
Training loss: 2.051541805267334
Validation loss: 1.9718407200228782

Epoch: 6| Step: 12
Training loss: 2.288747787475586
Validation loss: 1.942152787280339

Epoch: 6| Step: 13
Training loss: 1.7101739645004272
Validation loss: 1.954286285625991

Epoch: 248| Step: 0
Training loss: 1.6144956350326538
Validation loss: 1.9322000831686041

Epoch: 6| Step: 1
Training loss: 1.4265313148498535
Validation loss: 1.969841061099883

Epoch: 6| Step: 2
Training loss: 1.9427151679992676
Validation loss: 1.8933730817610217

Epoch: 6| Step: 3
Training loss: 1.2543307542800903
Validation loss: 1.9685152076905774

Epoch: 6| Step: 4
Training loss: 1.9114007949829102
Validation loss: 1.9488501535948886

Epoch: 6| Step: 5
Training loss: 1.6898601055145264
Validation loss: 1.8638487772275043

Epoch: 6| Step: 6
Training loss: 1.8136943578720093
Validation loss: 1.9589639991842291

Epoch: 6| Step: 7
Training loss: 1.653658390045166
Validation loss: 1.9804316938564341

Epoch: 6| Step: 8
Training loss: 1.9403358697891235
Validation loss: 1.9689811532215407

Epoch: 6| Step: 9
Training loss: 2.2691240310668945
Validation loss: 1.9128837098357498

Epoch: 6| Step: 10
Training loss: 1.5211342573165894
Validation loss: 1.9405630275767336

Epoch: 6| Step: 11
Training loss: 1.956831932067871
Validation loss: 1.9661362658264816

Epoch: 6| Step: 12
Training loss: 1.496543526649475
Validation loss: 1.9117889981116019

Epoch: 6| Step: 13
Training loss: 1.5978895425796509
Validation loss: 1.9750417060749506

Epoch: 249| Step: 0
Training loss: 2.30372953414917
Validation loss: 1.9779223062658822

Epoch: 6| Step: 1
Training loss: 1.545046329498291
Validation loss: 2.0021870546443488

Epoch: 6| Step: 2
Training loss: 1.911834478378296
Validation loss: 1.9705878252624183

Epoch: 6| Step: 3
Training loss: 1.439404010772705
Validation loss: 1.9563700434982136

Epoch: 6| Step: 4
Training loss: 1.801047682762146
Validation loss: 2.0187778254990936

Epoch: 6| Step: 5
Training loss: 2.204061508178711
Validation loss: 1.9176356279721825

Epoch: 6| Step: 6
Training loss: 1.5047416687011719
Validation loss: 1.9559487001870268

Epoch: 6| Step: 7
Training loss: 1.9129250049591064
Validation loss: 1.9670327068657003

Epoch: 6| Step: 8
Training loss: 1.4126458168029785
Validation loss: 1.9534463177445114

Epoch: 6| Step: 9
Training loss: 1.9816097021102905
Validation loss: 1.9201977419596847

Epoch: 6| Step: 10
Training loss: 1.7294912338256836
Validation loss: 1.9531448579603625

Epoch: 6| Step: 11
Training loss: 1.2942421436309814
Validation loss: 1.9779771297208724

Epoch: 6| Step: 12
Training loss: 1.3076105117797852
Validation loss: 1.9533777070301834

Epoch: 6| Step: 13
Training loss: 2.3224523067474365
Validation loss: 1.9452436662489367

Epoch: 250| Step: 0
Training loss: 1.808617115020752
Validation loss: 1.9194212639203636

Epoch: 6| Step: 1
Training loss: 1.2841110229492188
Validation loss: 1.8986456496741182

Epoch: 6| Step: 2
Training loss: 1.7913140058517456
Validation loss: 1.921327043605107

Epoch: 6| Step: 3
Training loss: 1.6152563095092773
Validation loss: 1.9252126293797647

Epoch: 6| Step: 4
Training loss: 1.8611524105072021
Validation loss: 2.008776003314603

Epoch: 6| Step: 5
Training loss: 1.422632098197937
Validation loss: 1.9191653523393857

Epoch: 6| Step: 6
Training loss: 1.7514334917068481
Validation loss: 1.9454176041387743

Epoch: 6| Step: 7
Training loss: 1.6800628900527954
Validation loss: 1.9466859614977272

Epoch: 6| Step: 8
Training loss: 1.4547691345214844
Validation loss: 1.914756562120171

Epoch: 6| Step: 9
Training loss: 1.516775369644165
Validation loss: 1.9563913909337853

Epoch: 6| Step: 10
Training loss: 1.5853475332260132
Validation loss: 1.978452028766755

Epoch: 6| Step: 11
Training loss: 2.2961840629577637
Validation loss: 1.9569599269538798

Epoch: 6| Step: 12
Training loss: 1.5636667013168335
Validation loss: 1.976603377249933

Epoch: 6| Step: 13
Training loss: 2.6909780502319336
Validation loss: 1.936497530629558

Epoch: 251| Step: 0
Training loss: 1.7120405435562134
Validation loss: 1.952306660272742

Epoch: 6| Step: 1
Training loss: 2.5293259620666504
Validation loss: 1.9855117362032655

Epoch: 6| Step: 2
Training loss: 1.5684432983398438
Validation loss: 2.0497475119047266

Epoch: 6| Step: 3
Training loss: 1.169396162033081
Validation loss: 1.9868673316894039

Epoch: 6| Step: 4
Training loss: 2.041557788848877
Validation loss: 1.9642398536846202

Epoch: 6| Step: 5
Training loss: 1.9294190406799316
Validation loss: 1.9430179903584142

Epoch: 6| Step: 6
Training loss: 1.5504157543182373
Validation loss: 1.980390751233665

Epoch: 6| Step: 7
Training loss: 1.3648552894592285
Validation loss: 1.9041818636719898

Epoch: 6| Step: 8
Training loss: 1.8930131196975708
Validation loss: 1.9407665934613956

Epoch: 6| Step: 9
Training loss: 2.1873550415039062
Validation loss: 1.9422222209233109

Epoch: 6| Step: 10
Training loss: 1.1463525295257568
Validation loss: 1.9256990686539681

Epoch: 6| Step: 11
Training loss: 1.2910760641098022
Validation loss: 1.9105586697978358

Epoch: 6| Step: 12
Training loss: 2.011522054672241
Validation loss: 1.933757338472592

Epoch: 6| Step: 13
Training loss: 1.802915096282959
Validation loss: 1.9602156582699026

Epoch: 252| Step: 0
Training loss: 1.6414482593536377
Validation loss: 1.9008161624272664

Epoch: 6| Step: 1
Training loss: 1.926113247871399
Validation loss: 1.9728067626235306

Epoch: 6| Step: 2
Training loss: 1.5951416492462158
Validation loss: 1.879600917139361

Epoch: 6| Step: 3
Training loss: 1.6943672895431519
Validation loss: 1.958200018893006

Epoch: 6| Step: 4
Training loss: 2.3247933387756348
Validation loss: 1.9490879030637844

Epoch: 6| Step: 5
Training loss: 1.6877596378326416
Validation loss: 1.953598912044238

Epoch: 6| Step: 6
Training loss: 1.8973792791366577
Validation loss: 1.9041802857511787

Epoch: 6| Step: 7
Training loss: 1.5235532522201538
Validation loss: 1.9846773186037618

Epoch: 6| Step: 8
Training loss: 1.3415656089782715
Validation loss: 1.9331488070949432

Epoch: 6| Step: 9
Training loss: 1.876971960067749
Validation loss: 1.8971952802391463

Epoch: 6| Step: 10
Training loss: 1.6386988162994385
Validation loss: 1.9378347243032148

Epoch: 6| Step: 11
Training loss: 1.0849307775497437
Validation loss: 1.9620276022982854

Epoch: 6| Step: 12
Training loss: 1.1403734683990479
Validation loss: 1.9136322339375813

Epoch: 6| Step: 13
Training loss: 2.652405023574829
Validation loss: 1.9097958739085863

Epoch: 253| Step: 0
Training loss: 1.1575543880462646
Validation loss: 1.902419767072124

Epoch: 6| Step: 1
Training loss: 1.9738879203796387
Validation loss: 2.0200457906210296

Epoch: 6| Step: 2
Training loss: 2.2980527877807617
Validation loss: 1.914827735193314

Epoch: 6| Step: 3
Training loss: 1.6972885131835938
Validation loss: 1.9233807312544955

Epoch: 6| Step: 4
Training loss: 2.0318422317504883
Validation loss: 1.96219039476046

Epoch: 6| Step: 5
Training loss: 1.1984548568725586
Validation loss: 1.995504548472743

Epoch: 6| Step: 6
Training loss: 1.8538920879364014
Validation loss: 1.9908498512801303

Epoch: 6| Step: 7
Training loss: 1.2392914295196533
Validation loss: 1.9990128547914567

Epoch: 6| Step: 8
Training loss: 1.9490833282470703
Validation loss: 1.9186800103033743

Epoch: 6| Step: 9
Training loss: 1.8950276374816895
Validation loss: 1.9408370397424186

Epoch: 6| Step: 10
Training loss: 1.4152802228927612
Validation loss: 1.9795304806001726

Epoch: 6| Step: 11
Training loss: 2.3184280395507812
Validation loss: 1.9807726708791589

Epoch: 6| Step: 12
Training loss: 1.113533616065979
Validation loss: 1.9707608453689083

Epoch: 6| Step: 13
Training loss: 1.7248101234436035
Validation loss: 1.9403666296312887

Epoch: 254| Step: 0
Training loss: 1.8231821060180664
Validation loss: 1.932735921234213

Epoch: 6| Step: 1
Training loss: 1.108553409576416
Validation loss: 1.9228552720879997

Epoch: 6| Step: 2
Training loss: 1.4307358264923096
Validation loss: 1.9230644408092703

Epoch: 6| Step: 3
Training loss: 1.1845126152038574
Validation loss: 1.9659205008578557

Epoch: 6| Step: 4
Training loss: 2.1065051555633545
Validation loss: 1.9414912821144186

Epoch: 6| Step: 5
Training loss: 1.5936909914016724
Validation loss: 1.9426078181112967

Epoch: 6| Step: 6
Training loss: 1.2809038162231445
Validation loss: 1.9469250081687846

Epoch: 6| Step: 7
Training loss: 2.1201882362365723
Validation loss: 1.9484141001137354

Epoch: 6| Step: 8
Training loss: 1.4006884098052979
Validation loss: 1.9789267842487623

Epoch: 6| Step: 9
Training loss: 2.4063897132873535
Validation loss: 1.9758565836055304

Epoch: 6| Step: 10
Training loss: 2.5178723335266113
Validation loss: 1.9618069305214831

Epoch: 6| Step: 11
Training loss: 1.0552080869674683
Validation loss: 1.9450085893754037

Epoch: 6| Step: 12
Training loss: 1.7979754209518433
Validation loss: 2.0296638832297376

Epoch: 6| Step: 13
Training loss: 1.7809104919433594
Validation loss: 1.9074248575395154

Epoch: 255| Step: 0
Training loss: 1.176668405532837
Validation loss: 1.9699731821654944

Epoch: 6| Step: 1
Training loss: 1.6563007831573486
Validation loss: 1.942310408879352

Epoch: 6| Step: 2
Training loss: 1.5591751337051392
Validation loss: 1.875725438517909

Epoch: 6| Step: 3
Training loss: 1.6275503635406494
Validation loss: 1.960441081754623

Epoch: 6| Step: 4
Training loss: 2.5174684524536133
Validation loss: 1.9013604848615584

Epoch: 6| Step: 5
Training loss: 0.979137659072876
Validation loss: 1.9160063574391026

Epoch: 6| Step: 6
Training loss: 1.513071060180664
Validation loss: 1.9369727103940901

Epoch: 6| Step: 7
Training loss: 2.1459567546844482
Validation loss: 1.991244359682965

Epoch: 6| Step: 8
Training loss: 1.7613139152526855
Validation loss: 1.9845084810769686

Epoch: 6| Step: 9
Training loss: 1.1639339923858643
Validation loss: 1.9952951080055648

Epoch: 6| Step: 10
Training loss: 2.1727867126464844
Validation loss: 1.9653817607510475

Epoch: 6| Step: 11
Training loss: 1.4166312217712402
Validation loss: 1.974184843801683

Epoch: 6| Step: 12
Training loss: 2.028433084487915
Validation loss: 1.9527942736943562

Epoch: 6| Step: 13
Training loss: 2.8104846477508545
Validation loss: 2.0357207969952653

Epoch: 256| Step: 0
Training loss: 1.8409273624420166
Validation loss: 1.9335487068340342

Epoch: 6| Step: 1
Training loss: 1.7614176273345947
Validation loss: 2.001917598068073

Epoch: 6| Step: 2
Training loss: 1.3560436964035034
Validation loss: 1.9324830501310286

Epoch: 6| Step: 3
Training loss: 1.9721266031265259
Validation loss: 1.9600569330235964

Epoch: 6| Step: 4
Training loss: 1.4607501029968262
Validation loss: 2.001697040373279

Epoch: 6| Step: 5
Training loss: 2.1984050273895264
Validation loss: 2.009797185979864

Epoch: 6| Step: 6
Training loss: 1.8593230247497559
Validation loss: 1.9883520526270713

Epoch: 6| Step: 7
Training loss: 1.540657639503479
Validation loss: 1.9788687434247745

Epoch: 6| Step: 8
Training loss: 1.7680892944335938
Validation loss: 2.015487942644345

Epoch: 6| Step: 9
Training loss: 1.7186510562896729
Validation loss: 2.006417691066701

Epoch: 6| Step: 10
Training loss: 1.8333756923675537
Validation loss: 1.9694870774463942

Epoch: 6| Step: 11
Training loss: 1.8001360893249512
Validation loss: 1.9551393960111885

Epoch: 6| Step: 12
Training loss: 1.34798264503479
Validation loss: 1.9697794273335447

Epoch: 6| Step: 13
Training loss: 1.3266091346740723
Validation loss: 1.9685984401292698

Epoch: 257| Step: 0
Training loss: 1.5319164991378784
Validation loss: 1.9618140676970124

Epoch: 6| Step: 1
Training loss: 2.0181779861450195
Validation loss: 1.9922772351131643

Epoch: 6| Step: 2
Training loss: 1.6075561046600342
Validation loss: 1.9298565541544268

Epoch: 6| Step: 3
Training loss: 2.2682812213897705
Validation loss: 1.9276314858467347

Epoch: 6| Step: 4
Training loss: 1.7148401737213135
Validation loss: 1.9473842856704549

Epoch: 6| Step: 5
Training loss: 2.119210720062256
Validation loss: 1.9671894145268265

Epoch: 6| Step: 6
Training loss: 2.046450614929199
Validation loss: 1.9858238863688644

Epoch: 6| Step: 7
Training loss: 2.1751797199249268
Validation loss: 1.9373631990084084

Epoch: 6| Step: 8
Training loss: 1.350909948348999
Validation loss: 1.9724069385118381

Epoch: 6| Step: 9
Training loss: 1.2934110164642334
Validation loss: 1.9737161385115756

Epoch: 6| Step: 10
Training loss: 1.1200642585754395
Validation loss: 1.9675671785108504

Epoch: 6| Step: 11
Training loss: 0.8402384519577026
Validation loss: 1.9826451347720238

Epoch: 6| Step: 12
Training loss: 1.6969444751739502
Validation loss: 1.9123310594148533

Epoch: 6| Step: 13
Training loss: 1.5005342960357666
Validation loss: 1.9212546169116933

Epoch: 258| Step: 0
Training loss: 1.1682604551315308
Validation loss: 1.935549589895433

Epoch: 6| Step: 1
Training loss: 2.0574276447296143
Validation loss: 1.9551107011815554

Epoch: 6| Step: 2
Training loss: 2.102426528930664
Validation loss: 1.9336717526117961

Epoch: 6| Step: 3
Training loss: 1.6089544296264648
Validation loss: 1.8547396864942325

Epoch: 6| Step: 4
Training loss: 2.0576088428497314
Validation loss: 2.000838982161655

Epoch: 6| Step: 5
Training loss: 1.720348834991455
Validation loss: 1.9482189942431707

Epoch: 6| Step: 6
Training loss: 1.3076443672180176
Validation loss: 1.894589852261287

Epoch: 6| Step: 7
Training loss: 1.5060653686523438
Validation loss: 1.9322306776559481

Epoch: 6| Step: 8
Training loss: 1.4915812015533447
Validation loss: 1.9366655913732385

Epoch: 6| Step: 9
Training loss: 1.9485387802124023
Validation loss: 1.915245529144041

Epoch: 6| Step: 10
Training loss: 1.8205723762512207
Validation loss: 1.9238733207025835

Epoch: 6| Step: 11
Training loss: 2.1039767265319824
Validation loss: 1.915319969577174

Epoch: 6| Step: 12
Training loss: 1.7936149835586548
Validation loss: 1.9439098770900438

Epoch: 6| Step: 13
Training loss: 1.4132682085037231
Validation loss: 1.9124777291410713

Epoch: 259| Step: 0
Training loss: 1.8622632026672363
Validation loss: 1.9305189322399836

Epoch: 6| Step: 1
Training loss: 1.4190552234649658
Validation loss: 1.9588294054872246

Epoch: 6| Step: 2
Training loss: 1.9640865325927734
Validation loss: 1.9873807917359054

Epoch: 6| Step: 3
Training loss: 1.2104302644729614
Validation loss: 1.9625656553494033

Epoch: 6| Step: 4
Training loss: 1.3781837224960327
Validation loss: 1.9727040759978756

Epoch: 6| Step: 5
Training loss: 1.8489893674850464
Validation loss: 1.9531714288137292

Epoch: 6| Step: 6
Training loss: 2.2460687160491943
Validation loss: 1.9379410897531817

Epoch: 6| Step: 7
Training loss: 1.5450799465179443
Validation loss: 1.9885380268096924

Epoch: 6| Step: 8
Training loss: 1.5675976276397705
Validation loss: 1.9528725762521066

Epoch: 6| Step: 9
Training loss: 2.154149293899536
Validation loss: 1.9336350374324347

Epoch: 6| Step: 10
Training loss: 2.2169697284698486
Validation loss: 1.9710098415292718

Epoch: 6| Step: 11
Training loss: 1.9167845249176025
Validation loss: 1.958437983707715

Epoch: 6| Step: 12
Training loss: 1.2548662424087524
Validation loss: 1.9328803452112342

Epoch: 6| Step: 13
Training loss: 0.8695299029350281
Validation loss: 1.9417997944739558

Epoch: 260| Step: 0
Training loss: 2.24741268157959
Validation loss: 1.9108471960149787

Epoch: 6| Step: 1
Training loss: 1.4576404094696045
Validation loss: 1.9199921328534362

Epoch: 6| Step: 2
Training loss: 1.2195172309875488
Validation loss: 1.8998833984457038

Epoch: 6| Step: 3
Training loss: 1.569318413734436
Validation loss: 1.9827831714384017

Epoch: 6| Step: 4
Training loss: 1.619184970855713
Validation loss: 1.9471188129917267

Epoch: 6| Step: 5
Training loss: 1.5837123394012451
Validation loss: 1.976078530793549

Epoch: 6| Step: 6
Training loss: 2.3205347061157227
Validation loss: 1.9841016800172868

Epoch: 6| Step: 7
Training loss: 2.404694080352783
Validation loss: 2.0020814454683693

Epoch: 6| Step: 8
Training loss: 1.115767002105713
Validation loss: 1.9411217551077566

Epoch: 6| Step: 9
Training loss: 1.6848468780517578
Validation loss: 1.9799835489642235

Epoch: 6| Step: 10
Training loss: 1.4153077602386475
Validation loss: 2.0057425550235215

Epoch: 6| Step: 11
Training loss: 1.463671326637268
Validation loss: 1.949416829693702

Epoch: 6| Step: 12
Training loss: 1.9878582954406738
Validation loss: 1.9748154519706644

Epoch: 6| Step: 13
Training loss: 1.3636360168457031
Validation loss: 2.0055892288043933

Epoch: 261| Step: 0
Training loss: 1.561331868171692
Validation loss: 1.9582358201344807

Epoch: 6| Step: 1
Training loss: 1.536338210105896
Validation loss: 1.9348079760869343

Epoch: 6| Step: 2
Training loss: 1.2343848943710327
Validation loss: 1.9794466649332354

Epoch: 6| Step: 3
Training loss: 1.8154046535491943
Validation loss: 1.9503655356745566

Epoch: 6| Step: 4
Training loss: 1.7630317211151123
Validation loss: 1.9649268375929965

Epoch: 6| Step: 5
Training loss: 1.1772751808166504
Validation loss: 1.9818131154583347

Epoch: 6| Step: 6
Training loss: 1.7299085855484009
Validation loss: 1.965773646549512

Epoch: 6| Step: 7
Training loss: 1.6528420448303223
Validation loss: 2.0175940939175185

Epoch: 6| Step: 8
Training loss: 2.310415744781494
Validation loss: 1.9423515745388564

Epoch: 6| Step: 9
Training loss: 2.0135951042175293
Validation loss: 1.9512084094426965

Epoch: 6| Step: 10
Training loss: 1.5408713817596436
Validation loss: 1.985268738961989

Epoch: 6| Step: 11
Training loss: 1.7293938398361206
Validation loss: 1.930391070663288

Epoch: 6| Step: 12
Training loss: 1.9048984050750732
Validation loss: 1.9001065659266647

Epoch: 6| Step: 13
Training loss: 1.2807855606079102
Validation loss: 1.897344225196428

Epoch: 262| Step: 0
Training loss: 2.8319554328918457
Validation loss: 1.9454759807996853

Epoch: 6| Step: 1
Training loss: 1.2339956760406494
Validation loss: 1.964015491547123

Epoch: 6| Step: 2
Training loss: 1.5081939697265625
Validation loss: 1.9363385272282425

Epoch: 6| Step: 3
Training loss: 1.602866768836975
Validation loss: 1.9629522446663148

Epoch: 6| Step: 4
Training loss: 1.0290367603302002
Validation loss: 1.9769462564940095

Epoch: 6| Step: 5
Training loss: 0.8548769950866699
Validation loss: 2.005836166361327

Epoch: 6| Step: 6
Training loss: 1.4081780910491943
Validation loss: 1.939971923828125

Epoch: 6| Step: 7
Training loss: 1.7453861236572266
Validation loss: 1.8825195092026905

Epoch: 6| Step: 8
Training loss: 1.9327869415283203
Validation loss: 1.9982516534866825

Epoch: 6| Step: 9
Training loss: 1.7734344005584717
Validation loss: 1.894772215556073

Epoch: 6| Step: 10
Training loss: 2.183063268661499
Validation loss: 1.9085268051393571

Epoch: 6| Step: 11
Training loss: 2.1715593338012695
Validation loss: 1.9458256460005237

Epoch: 6| Step: 12
Training loss: 1.6751775741577148
Validation loss: 2.0362378884387273

Epoch: 6| Step: 13
Training loss: 1.416256070137024
Validation loss: 1.9809394882571312

Epoch: 263| Step: 0
Training loss: 1.5471267700195312
Validation loss: 1.984105570341951

Epoch: 6| Step: 1
Training loss: 1.6129744052886963
Validation loss: 1.9542649202449347

Epoch: 6| Step: 2
Training loss: 1.6642892360687256
Validation loss: 1.932440721860496

Epoch: 6| Step: 3
Training loss: 1.6006674766540527
Validation loss: 1.9705437896072224

Epoch: 6| Step: 4
Training loss: 1.4827370643615723
Validation loss: 1.990052451369583

Epoch: 6| Step: 5
Training loss: 1.7275683879852295
Validation loss: 2.0528912416068454

Epoch: 6| Step: 6
Training loss: 2.1471691131591797
Validation loss: 2.0312354436484714

Epoch: 6| Step: 7
Training loss: 2.223315715789795
Validation loss: 1.9838462721916936

Epoch: 6| Step: 8
Training loss: 1.3945984840393066
Validation loss: 2.033526853848529

Epoch: 6| Step: 9
Training loss: 1.6324924230575562
Validation loss: 2.043513922281163

Epoch: 6| Step: 10
Training loss: 0.8964085578918457
Validation loss: 1.9914381504058838

Epoch: 6| Step: 11
Training loss: 1.5010986328125
Validation loss: 1.9992906303815945

Epoch: 6| Step: 12
Training loss: 2.2475719451904297
Validation loss: 1.9698388948235461

Epoch: 6| Step: 13
Training loss: 2.177591562271118
Validation loss: 1.9683537893397833

Epoch: 264| Step: 0
Training loss: 1.2858057022094727
Validation loss: 1.9664680932157783

Epoch: 6| Step: 1
Training loss: 1.7737808227539062
Validation loss: 1.991818335748488

Epoch: 6| Step: 2
Training loss: 1.9361648559570312
Validation loss: 1.9830681124041158

Epoch: 6| Step: 3
Training loss: 1.4519498348236084
Validation loss: 1.9704778784064836

Epoch: 6| Step: 4
Training loss: 1.5429333448410034
Validation loss: 2.025447319912654

Epoch: 6| Step: 5
Training loss: 1.373016357421875
Validation loss: 1.929851730664571

Epoch: 6| Step: 6
Training loss: 1.5446555614471436
Validation loss: 1.9592345811987435

Epoch: 6| Step: 7
Training loss: 2.033323049545288
Validation loss: 2.0395281596850325

Epoch: 6| Step: 8
Training loss: 1.2983033657073975
Validation loss: 1.9844695034847464

Epoch: 6| Step: 9
Training loss: 2.3976097106933594
Validation loss: 1.982891854419503

Epoch: 6| Step: 10
Training loss: 1.8412108421325684
Validation loss: 1.9201784903003323

Epoch: 6| Step: 11
Training loss: 1.463800311088562
Validation loss: 1.9560970426887594

Epoch: 6| Step: 12
Training loss: 1.3585920333862305
Validation loss: 1.9709973027629237

Epoch: 6| Step: 13
Training loss: 2.4383418560028076
Validation loss: 1.9759668086164741

Epoch: 265| Step: 0
Training loss: 1.3285516500473022
Validation loss: 2.00454084719381

Epoch: 6| Step: 1
Training loss: 2.146376848220825
Validation loss: 1.9406105767014206

Epoch: 6| Step: 2
Training loss: 2.296417713165283
Validation loss: 1.9535717374535018

Epoch: 6| Step: 3
Training loss: 1.506002426147461
Validation loss: 1.8849209764952302

Epoch: 6| Step: 4
Training loss: 1.4807746410369873
Validation loss: 1.9596070166557067

Epoch: 6| Step: 5
Training loss: 1.3508687019348145
Validation loss: 1.9274644518411288

Epoch: 6| Step: 6
Training loss: 1.2590689659118652
Validation loss: 1.9104185988826137

Epoch: 6| Step: 7
Training loss: 1.5651490688323975
Validation loss: 1.8925187023737098

Epoch: 6| Step: 8
Training loss: 2.018857955932617
Validation loss: 1.9033295967245614

Epoch: 6| Step: 9
Training loss: 1.7594417333602905
Validation loss: 1.9057654296198199

Epoch: 6| Step: 10
Training loss: 1.3832356929779053
Validation loss: 1.903199500935052

Epoch: 6| Step: 11
Training loss: 1.907454252243042
Validation loss: 1.9339805572263655

Epoch: 6| Step: 12
Training loss: 1.7641990184783936
Validation loss: 1.9151097497632426

Epoch: 6| Step: 13
Training loss: 1.7600011825561523
Validation loss: 1.9663700185796267

Epoch: 266| Step: 0
Training loss: 2.004222869873047
Validation loss: 1.9922537931831934

Epoch: 6| Step: 1
Training loss: 0.9336941242218018
Validation loss: 1.9599055449167888

Epoch: 6| Step: 2
Training loss: 1.8726344108581543
Validation loss: 1.9334284438881824

Epoch: 6| Step: 3
Training loss: 1.0575801134109497
Validation loss: 1.9517246433483657

Epoch: 6| Step: 4
Training loss: 1.3934963941574097
Validation loss: 2.0245931263892882

Epoch: 6| Step: 5
Training loss: 1.5319368839263916
Validation loss: 1.957222366845736

Epoch: 6| Step: 6
Training loss: 2.5957906246185303
Validation loss: 1.9790869118064962

Epoch: 6| Step: 7
Training loss: 1.4414876699447632
Validation loss: 1.9841069226623864

Epoch: 6| Step: 8
Training loss: 1.2493114471435547
Validation loss: 1.986871104086599

Epoch: 6| Step: 9
Training loss: 1.7797514200210571
Validation loss: 1.9765805531573553

Epoch: 6| Step: 10
Training loss: 2.4048354625701904
Validation loss: 2.007498884713778

Epoch: 6| Step: 11
Training loss: 2.373995780944824
Validation loss: 2.004840632920624

Epoch: 6| Step: 12
Training loss: 0.6594574451446533
Validation loss: 1.949250873698983

Epoch: 6| Step: 13
Training loss: 1.1188958883285522
Validation loss: 1.8975547206017278

Epoch: 267| Step: 0
Training loss: 2.1063270568847656
Validation loss: 1.9268071702731553

Epoch: 6| Step: 1
Training loss: 1.166579008102417
Validation loss: 1.8773932174969745

Epoch: 6| Step: 2
Training loss: 1.814799427986145
Validation loss: 1.9399687961865497

Epoch: 6| Step: 3
Training loss: 1.9801651239395142
Validation loss: 1.9644363695575344

Epoch: 6| Step: 4
Training loss: 2.0018250942230225
Validation loss: 1.9159572611572921

Epoch: 6| Step: 5
Training loss: 1.7777173519134521
Validation loss: 1.9292311719668809

Epoch: 6| Step: 6
Training loss: 1.8760154247283936
Validation loss: 1.9063143307162869

Epoch: 6| Step: 7
Training loss: 1.2317432165145874
Validation loss: 1.9247057091805242

Epoch: 6| Step: 8
Training loss: 1.2634775638580322
Validation loss: 1.9404000902688632

Epoch: 6| Step: 9
Training loss: 1.1596643924713135
Validation loss: 1.941230494488952

Epoch: 6| Step: 10
Training loss: 1.4934210777282715
Validation loss: 1.9458363427910754

Epoch: 6| Step: 11
Training loss: 1.8452107906341553
Validation loss: 1.919544348152735

Epoch: 6| Step: 12
Training loss: 1.7808620929718018
Validation loss: 1.9821910294153358

Epoch: 6| Step: 13
Training loss: 2.203949451446533
Validation loss: 1.9746080649796354

Epoch: 268| Step: 0
Training loss: 1.86793053150177
Validation loss: 1.9477977906503985

Epoch: 6| Step: 1
Training loss: 1.525241494178772
Validation loss: 1.9288302390806136

Epoch: 6| Step: 2
Training loss: 1.633225679397583
Validation loss: 1.9829426170677267

Epoch: 6| Step: 3
Training loss: 1.6276142597198486
Validation loss: 1.9232398425379107

Epoch: 6| Step: 4
Training loss: 1.7180061340332031
Validation loss: 1.945935885111491

Epoch: 6| Step: 5
Training loss: 1.8136699199676514
Validation loss: 1.9087186577499553

Epoch: 6| Step: 6
Training loss: 2.469780683517456
Validation loss: 1.9628024960076937

Epoch: 6| Step: 7
Training loss: 1.4575707912445068
Validation loss: 1.959537277939499

Epoch: 6| Step: 8
Training loss: 1.5168861150741577
Validation loss: 1.9917298670737975

Epoch: 6| Step: 9
Training loss: 1.1284739971160889
Validation loss: 1.981092026156764

Epoch: 6| Step: 10
Training loss: 1.8663033246994019
Validation loss: 1.9323846858034852

Epoch: 6| Step: 11
Training loss: 1.3317185640335083
Validation loss: 1.9744979437961374

Epoch: 6| Step: 12
Training loss: 1.4776653051376343
Validation loss: 1.9499750368056759

Epoch: 6| Step: 13
Training loss: 1.1345106363296509
Validation loss: 1.926637000935052

Epoch: 269| Step: 0
Training loss: 2.5010409355163574
Validation loss: 1.8901576790758359

Epoch: 6| Step: 1
Training loss: 1.82322096824646
Validation loss: 1.9290580493147655

Epoch: 6| Step: 2
Training loss: 1.5863844156265259
Validation loss: 1.9975254022946922

Epoch: 6| Step: 3
Training loss: 1.7991833686828613
Validation loss: 1.9617315671777213

Epoch: 6| Step: 4
Training loss: 1.5382287502288818
Validation loss: 1.9875363098677767

Epoch: 6| Step: 5
Training loss: 1.0910677909851074
Validation loss: 1.9467574422077467

Epoch: 6| Step: 6
Training loss: 2.3152379989624023
Validation loss: 1.9212362253537743

Epoch: 6| Step: 7
Training loss: 1.4330003261566162
Validation loss: 1.9473225557675926

Epoch: 6| Step: 8
Training loss: 1.7802774906158447
Validation loss: 1.9163330242198

Epoch: 6| Step: 9
Training loss: 1.3974794149398804
Validation loss: 1.925012767955821

Epoch: 6| Step: 10
Training loss: 1.0347797870635986
Validation loss: 1.9218511607057305

Epoch: 6| Step: 11
Training loss: 1.5361700057983398
Validation loss: 1.9749246989527056

Epoch: 6| Step: 12
Training loss: 2.10931396484375
Validation loss: 1.9465041404129357

Epoch: 6| Step: 13
Training loss: 1.8398772478103638
Validation loss: 1.9379734326434392

Epoch: 270| Step: 0
Training loss: 2.3917527198791504
Validation loss: 1.962774395942688

Epoch: 6| Step: 1
Training loss: 1.9728683233261108
Validation loss: 1.8908104447908298

Epoch: 6| Step: 2
Training loss: 0.9790085554122925
Validation loss: 1.8942423610277073

Epoch: 6| Step: 3
Training loss: 1.6415600776672363
Validation loss: 1.9202173345832414

Epoch: 6| Step: 4
Training loss: 1.8424668312072754
Validation loss: 1.8670407187554143

Epoch: 6| Step: 5
Training loss: 1.2240418195724487
Validation loss: 1.912644072245526

Epoch: 6| Step: 6
Training loss: 1.6627960205078125
Validation loss: 1.9645319754077541

Epoch: 6| Step: 7
Training loss: 1.4111582040786743
Validation loss: 1.9357771540200839

Epoch: 6| Step: 8
Training loss: 1.2868611812591553
Validation loss: 1.8811896924049623

Epoch: 6| Step: 9
Training loss: 1.6194106340408325
Validation loss: 1.973431561582832

Epoch: 6| Step: 10
Training loss: 1.3726818561553955
Validation loss: 1.9400834575776131

Epoch: 6| Step: 11
Training loss: 2.2577438354492188
Validation loss: 1.92626557811614

Epoch: 6| Step: 12
Training loss: 1.7525484561920166
Validation loss: 1.9503818667063149

Epoch: 6| Step: 13
Training loss: 1.1673121452331543
Validation loss: 1.9519952292083411

Epoch: 271| Step: 0
Training loss: 0.9614441394805908
Validation loss: 1.9176297828715334

Epoch: 6| Step: 1
Training loss: 1.333437204360962
Validation loss: 1.9038869616805867

Epoch: 6| Step: 2
Training loss: 2.136601448059082
Validation loss: 1.993772816914384

Epoch: 6| Step: 3
Training loss: 1.9286470413208008
Validation loss: 1.9462364373668548

Epoch: 6| Step: 4
Training loss: 1.901626706123352
Validation loss: 1.947059678775008

Epoch: 6| Step: 5
Training loss: 1.4024146795272827
Validation loss: 1.914093106023727

Epoch: 6| Step: 6
Training loss: 1.52053964138031
Validation loss: 1.9296818048723283

Epoch: 6| Step: 7
Training loss: 1.150282382965088
Validation loss: 1.9580808788217523

Epoch: 6| Step: 8
Training loss: 1.583836317062378
Validation loss: 1.9767290417866041

Epoch: 6| Step: 9
Training loss: 1.8528343439102173
Validation loss: 1.9052222108328214

Epoch: 6| Step: 10
Training loss: 1.0972394943237305
Validation loss: 1.9536779208849835

Epoch: 6| Step: 11
Training loss: 2.112483263015747
Validation loss: 1.9227010332128054

Epoch: 6| Step: 12
Training loss: 1.3626062870025635
Validation loss: 1.9301967197848904

Epoch: 6| Step: 13
Training loss: 3.82802414894104
Validation loss: 1.959840807863461

Epoch: 272| Step: 0
Training loss: 1.128070592880249
Validation loss: 1.9275951411134453

Epoch: 6| Step: 1
Training loss: 1.910433292388916
Validation loss: 1.9677813617132043

Epoch: 6| Step: 2
Training loss: 2.4808506965637207
Validation loss: 1.9441388601897864

Epoch: 6| Step: 3
Training loss: 1.571852445602417
Validation loss: 1.868407682705951

Epoch: 6| Step: 4
Training loss: 1.2621560096740723
Validation loss: 1.918549637640676

Epoch: 6| Step: 5
Training loss: 1.7606308460235596
Validation loss: 1.8964782645625453

Epoch: 6| Step: 6
Training loss: 1.5196384191513062
Validation loss: 1.9661877693668488

Epoch: 6| Step: 7
Training loss: 1.6649670600891113
Validation loss: 1.9404734180819603

Epoch: 6| Step: 8
Training loss: 1.651304006576538
Validation loss: 1.9755999683051981

Epoch: 6| Step: 9
Training loss: 1.6187330484390259
Validation loss: 2.038709727666711

Epoch: 6| Step: 10
Training loss: 1.5756651163101196
Validation loss: 1.93707190662302

Epoch: 6| Step: 11
Training loss: 1.3109787702560425
Validation loss: 1.9909112786733976

Epoch: 6| Step: 12
Training loss: 1.9303663969039917
Validation loss: 1.9347036679585774

Epoch: 6| Step: 13
Training loss: 1.4730453491210938
Validation loss: 1.9890241546015586

Epoch: 273| Step: 0
Training loss: 1.9854729175567627
Validation loss: 1.9809296592589347

Epoch: 6| Step: 1
Training loss: 1.4025071859359741
Validation loss: 1.9389091948027253

Epoch: 6| Step: 2
Training loss: 2.002302646636963
Validation loss: 1.918009514449745

Epoch: 6| Step: 3
Training loss: 1.2902541160583496
Validation loss: 1.9847488710957188

Epoch: 6| Step: 4
Training loss: 1.4158294200897217
Validation loss: 1.923339928350141

Epoch: 6| Step: 5
Training loss: 2.0115010738372803
Validation loss: 1.9938006503607637

Epoch: 6| Step: 6
Training loss: 1.8002452850341797
Validation loss: 1.9475206559704197

Epoch: 6| Step: 7
Training loss: 2.094757556915283
Validation loss: 1.8854678164246261

Epoch: 6| Step: 8
Training loss: 2.144157886505127
Validation loss: 1.9107041358947754

Epoch: 6| Step: 9
Training loss: 1.360764503479004
Validation loss: 1.9885389061384304

Epoch: 6| Step: 10
Training loss: 1.9064080715179443
Validation loss: 1.9802405629106747

Epoch: 6| Step: 11
Training loss: 1.7352087497711182
Validation loss: 1.9506895670326807

Epoch: 6| Step: 12
Training loss: 1.4065427780151367
Validation loss: 1.9425560838432723

Epoch: 6| Step: 13
Training loss: 1.0685269832611084
Validation loss: 1.9334707285768242

Epoch: 274| Step: 0
Training loss: 1.5530990362167358
Validation loss: 1.9241850670947824

Epoch: 6| Step: 1
Training loss: 2.224534034729004
Validation loss: 1.9714620241554834

Epoch: 6| Step: 2
Training loss: 1.6091086864471436
Validation loss: 1.9271874248340566

Epoch: 6| Step: 3
Training loss: 2.0725841522216797
Validation loss: 1.938702332076206

Epoch: 6| Step: 4
Training loss: 1.537022590637207
Validation loss: 1.9113982672332435

Epoch: 6| Step: 5
Training loss: 2.3273138999938965
Validation loss: 1.8542014475791686

Epoch: 6| Step: 6
Training loss: 1.2405139207839966
Validation loss: 1.9415007893757155

Epoch: 6| Step: 7
Training loss: 1.3904600143432617
Validation loss: 1.9564928085573259

Epoch: 6| Step: 8
Training loss: 1.277242660522461
Validation loss: 1.8903219930587276

Epoch: 6| Step: 9
Training loss: 1.175317645072937
Validation loss: 1.8831223864709177

Epoch: 6| Step: 10
Training loss: 2.1029300689697266
Validation loss: 1.893463005301773

Epoch: 6| Step: 11
Training loss: 1.5241541862487793
Validation loss: 1.9246280436874719

Epoch: 6| Step: 12
Training loss: 1.084580659866333
Validation loss: 1.9353099510233889

Epoch: 6| Step: 13
Training loss: 2.0250704288482666
Validation loss: 1.8700101631943897

Epoch: 275| Step: 0
Training loss: 1.5153776407241821
Validation loss: 1.9720872653427945

Epoch: 6| Step: 1
Training loss: 2.1604838371276855
Validation loss: 1.9564105977294266

Epoch: 6| Step: 2
Training loss: 1.4133107662200928
Validation loss: 1.9318518946247716

Epoch: 6| Step: 3
Training loss: 1.4476737976074219
Validation loss: 1.952991993196549

Epoch: 6| Step: 4
Training loss: 2.0571000576019287
Validation loss: 1.8799556827032438

Epoch: 6| Step: 5
Training loss: 1.5928564071655273
Validation loss: 1.9850038097750755

Epoch: 6| Step: 6
Training loss: 1.3835573196411133
Validation loss: 1.9738262058586202

Epoch: 6| Step: 7
Training loss: 1.1594140529632568
Validation loss: 1.9423469651129939

Epoch: 6| Step: 8
Training loss: 1.769740104675293
Validation loss: 1.9875900976119503

Epoch: 6| Step: 9
Training loss: 1.5782219171524048
Validation loss: 1.9140097172029558

Epoch: 6| Step: 10
Training loss: 1.835911512374878
Validation loss: 1.8819521896300777

Epoch: 6| Step: 11
Training loss: 2.23342227935791
Validation loss: 1.9607601037589453

Epoch: 6| Step: 12
Training loss: 1.1744135618209839
Validation loss: 1.9290234606753114

Epoch: 6| Step: 13
Training loss: 1.9497315883636475
Validation loss: 1.9482367974455639

Epoch: 276| Step: 0
Training loss: 1.4882054328918457
Validation loss: 1.9167190008265997

Epoch: 6| Step: 1
Training loss: 1.5745337009429932
Validation loss: 1.8959896743938487

Epoch: 6| Step: 2
Training loss: 1.840899109840393
Validation loss: 1.9163067853578957

Epoch: 6| Step: 3
Training loss: 1.3362709283828735
Validation loss: 1.8988764619314542

Epoch: 6| Step: 4
Training loss: 0.9518864750862122
Validation loss: 1.9471449082897556

Epoch: 6| Step: 5
Training loss: 2.2764668464660645
Validation loss: 1.9593288834377

Epoch: 6| Step: 6
Training loss: 1.77097749710083
Validation loss: 1.9548786942676832

Epoch: 6| Step: 7
Training loss: 1.919643521308899
Validation loss: 1.8896490886647215

Epoch: 6| Step: 8
Training loss: 1.1526635885238647
Validation loss: 1.900351066743174

Epoch: 6| Step: 9
Training loss: 2.222156524658203
Validation loss: 1.9128505311986452

Epoch: 6| Step: 10
Training loss: 2.2844696044921875
Validation loss: 1.9351374077540573

Epoch: 6| Step: 11
Training loss: 1.1377791166305542
Validation loss: 1.9010890581274544

Epoch: 6| Step: 12
Training loss: 1.4444937705993652
Validation loss: 1.864932596042592

Epoch: 6| Step: 13
Training loss: 1.2938077449798584
Validation loss: 1.9530353725597422

Epoch: 277| Step: 0
Training loss: 1.8603869676589966
Validation loss: 1.9162720326454408

Epoch: 6| Step: 1
Training loss: 2.247509479522705
Validation loss: 1.9314187944576304

Epoch: 6| Step: 2
Training loss: 1.8146591186523438
Validation loss: 1.928664074149183

Epoch: 6| Step: 3
Training loss: 1.7732492685317993
Validation loss: 1.9037595743774085

Epoch: 6| Step: 4
Training loss: 1.3882378339767456
Validation loss: 1.9663879986732238

Epoch: 6| Step: 5
Training loss: 1.3410053253173828
Validation loss: 2.018955607568064

Epoch: 6| Step: 6
Training loss: 1.447767734527588
Validation loss: 1.9251140894428376

Epoch: 6| Step: 7
Training loss: 1.3036854267120361
Validation loss: 2.0233830700638475

Epoch: 6| Step: 8
Training loss: 1.7498797178268433
Validation loss: 2.0045221415899133

Epoch: 6| Step: 9
Training loss: 1.3012452125549316
Validation loss: 1.9681007054544264

Epoch: 6| Step: 10
Training loss: 1.1491268873214722
Validation loss: 2.0123783106444986

Epoch: 6| Step: 11
Training loss: 1.7857720851898193
Validation loss: 1.893144836989782

Epoch: 6| Step: 12
Training loss: 1.845967173576355
Validation loss: 1.9617940366909068

Epoch: 6| Step: 13
Training loss: 1.8559362888336182
Validation loss: 1.9562568446641326

Epoch: 278| Step: 0
Training loss: 1.3997371196746826
Validation loss: 2.0467839343573457

Epoch: 6| Step: 1
Training loss: 2.0313329696655273
Validation loss: 1.9123963745691444

Epoch: 6| Step: 2
Training loss: 1.4127781391143799
Validation loss: 2.0030427466156664

Epoch: 6| Step: 3
Training loss: 1.93450927734375
Validation loss: 1.9337659035959551

Epoch: 6| Step: 4
Training loss: 1.6948890686035156
Validation loss: 1.928409703316227

Epoch: 6| Step: 5
Training loss: 1.2936549186706543
Validation loss: 1.9269660954834313

Epoch: 6| Step: 6
Training loss: 1.4898931980133057
Validation loss: 1.9824180115935623

Epoch: 6| Step: 7
Training loss: 1.6589899063110352
Validation loss: 1.9448045697263492

Epoch: 6| Step: 8
Training loss: 1.914504051208496
Validation loss: 1.921079288246811

Epoch: 6| Step: 9
Training loss: 1.3701896667480469
Validation loss: 1.9033805760004188

Epoch: 6| Step: 10
Training loss: 2.293200969696045
Validation loss: 1.8722800721404373

Epoch: 6| Step: 11
Training loss: 1.518099069595337
Validation loss: 1.9173743109549246

Epoch: 6| Step: 12
Training loss: 1.5583446025848389
Validation loss: 1.9401526835656935

Epoch: 6| Step: 13
Training loss: 1.195890188217163
Validation loss: 1.8854137133526545

Epoch: 279| Step: 0
Training loss: 1.8558862209320068
Validation loss: 1.8994962784551805

Epoch: 6| Step: 1
Training loss: 1.7814806699752808
Validation loss: 1.9591681854699248

Epoch: 6| Step: 2
Training loss: 2.3516910076141357
Validation loss: 1.9885193891422723

Epoch: 6| Step: 3
Training loss: 1.264144778251648
Validation loss: 1.8901058089348577

Epoch: 6| Step: 4
Training loss: 1.8544836044311523
Validation loss: 1.9392931576698058

Epoch: 6| Step: 5
Training loss: 1.5997501611709595
Validation loss: 1.8831903665296492

Epoch: 6| Step: 6
Training loss: 2.004631996154785
Validation loss: 1.943491058964883

Epoch: 6| Step: 7
Training loss: 1.922734022140503
Validation loss: 2.0038001050231276

Epoch: 6| Step: 8
Training loss: 1.1905486583709717
Validation loss: 1.9399563035657328

Epoch: 6| Step: 9
Training loss: 1.5706521272659302
Validation loss: 1.9281285385931692

Epoch: 6| Step: 10
Training loss: 1.5249719619750977
Validation loss: 1.8818735435444822

Epoch: 6| Step: 11
Training loss: 1.2480021715164185
Validation loss: 1.9163635405161048

Epoch: 6| Step: 12
Training loss: 1.3712613582611084
Validation loss: 2.0166739520206245

Epoch: 6| Step: 13
Training loss: 1.0322356224060059
Validation loss: 1.9867942615221905

Epoch: 280| Step: 0
Training loss: 1.3268615007400513
Validation loss: 1.8968360859860656

Epoch: 6| Step: 1
Training loss: 2.128589153289795
Validation loss: 1.9365010992173226

Epoch: 6| Step: 2
Training loss: 1.8404145240783691
Validation loss: 1.9262283450813704

Epoch: 6| Step: 3
Training loss: 2.168618679046631
Validation loss: 1.8789871008165422

Epoch: 6| Step: 4
Training loss: 1.7324868440628052
Validation loss: 1.9009003959676272

Epoch: 6| Step: 5
Training loss: 1.3711764812469482
Validation loss: 1.9033660209307106

Epoch: 6| Step: 6
Training loss: 2.1311581134796143
Validation loss: 1.8983729244560323

Epoch: 6| Step: 7
Training loss: 1.2582287788391113
Validation loss: 1.9080052529611895

Epoch: 6| Step: 8
Training loss: 1.9351551532745361
Validation loss: 1.901096155566554

Epoch: 6| Step: 9
Training loss: 1.4392703771591187
Validation loss: 1.9176720803783787

Epoch: 6| Step: 10
Training loss: 1.4677555561065674
Validation loss: 1.9442540612272037

Epoch: 6| Step: 11
Training loss: 0.9903852343559265
Validation loss: 1.948775214533652

Epoch: 6| Step: 12
Training loss: 1.9546411037445068
Validation loss: 1.9610431463487688

Epoch: 6| Step: 13
Training loss: 0.9913733005523682
Validation loss: 1.9007938587537376

Epoch: 281| Step: 0
Training loss: 1.3729360103607178
Validation loss: 1.9399795122044061

Epoch: 6| Step: 1
Training loss: 1.524452567100525
Validation loss: 1.8962817615078342

Epoch: 6| Step: 2
Training loss: 1.3566248416900635
Validation loss: 1.9751317693341164

Epoch: 6| Step: 3
Training loss: 1.0931416749954224
Validation loss: 1.954195619911276

Epoch: 6| Step: 4
Training loss: 2.0682454109191895
Validation loss: 1.9282105251025128

Epoch: 6| Step: 5
Training loss: 1.7075093984603882
Validation loss: 1.9706239982317852

Epoch: 6| Step: 6
Training loss: 2.046438217163086
Validation loss: 1.9825784339699695

Epoch: 6| Step: 7
Training loss: 1.902695655822754
Validation loss: 1.9252103964487712

Epoch: 6| Step: 8
Training loss: 1.8171188831329346
Validation loss: 1.9428419323377712

Epoch: 6| Step: 9
Training loss: 1.3691006898880005
Validation loss: 1.9595402607353785

Epoch: 6| Step: 10
Training loss: 1.5742895603179932
Validation loss: 1.9861270907104656

Epoch: 6| Step: 11
Training loss: 1.4794657230377197
Validation loss: 1.9901591936747234

Epoch: 6| Step: 12
Training loss: 1.4235916137695312
Validation loss: 1.9166251228701683

Epoch: 6| Step: 13
Training loss: 2.1029627323150635
Validation loss: 1.9377193515018751

Epoch: 282| Step: 0
Training loss: 1.9085720777511597
Validation loss: 1.938824007588048

Epoch: 6| Step: 1
Training loss: 2.382152557373047
Validation loss: 1.873855225501522

Epoch: 6| Step: 2
Training loss: 1.5379703044891357
Validation loss: 1.9341733506930772

Epoch: 6| Step: 3
Training loss: 1.5809590816497803
Validation loss: 1.94006944728154

Epoch: 6| Step: 4
Training loss: 1.4327462911605835
Validation loss: 1.9687982297712756

Epoch: 6| Step: 5
Training loss: 1.6381474733352661
Validation loss: 1.960175250166206

Epoch: 6| Step: 6
Training loss: 1.4710381031036377
Validation loss: 1.929414447917733

Epoch: 6| Step: 7
Training loss: 1.4586749076843262
Validation loss: 1.9154778552311722

Epoch: 6| Step: 8
Training loss: 1.2167787551879883
Validation loss: 1.9082514073259087

Epoch: 6| Step: 9
Training loss: 1.1366251707077026
Validation loss: 1.8497347690725838

Epoch: 6| Step: 10
Training loss: 1.467032790184021
Validation loss: 1.818505822971303

Epoch: 6| Step: 11
Training loss: 2.3853836059570312
Validation loss: 1.90085175729567

Epoch: 6| Step: 12
Training loss: 2.06135892868042
Validation loss: 1.9012263756926342

Epoch: 6| Step: 13
Training loss: 0.9449701309204102
Validation loss: 1.8945405137154363

Epoch: 283| Step: 0
Training loss: 1.7174122333526611
Validation loss: 1.9672317120336718

Epoch: 6| Step: 1
Training loss: 1.0343458652496338
Validation loss: 1.9346333396050237

Epoch: 6| Step: 2
Training loss: 1.2154916524887085
Validation loss: 1.915777947313042

Epoch: 6| Step: 3
Training loss: 1.5770787000656128
Validation loss: 1.9746767654213855

Epoch: 6| Step: 4
Training loss: 1.0833330154418945
Validation loss: 1.9538423938135947

Epoch: 6| Step: 5
Training loss: 1.8513134717941284
Validation loss: 2.0029954333459177

Epoch: 6| Step: 6
Training loss: 1.9497463703155518
Validation loss: 1.9129981994628906

Epoch: 6| Step: 7
Training loss: 2.1327109336853027
Validation loss: 1.9667159831652077

Epoch: 6| Step: 8
Training loss: 2.0758094787597656
Validation loss: 1.9598713023688203

Epoch: 6| Step: 9
Training loss: 1.3130308389663696
Validation loss: 2.0116480345367105

Epoch: 6| Step: 10
Training loss: 1.8536055088043213
Validation loss: 1.9649281873497912

Epoch: 6| Step: 11
Training loss: 1.7953002452850342
Validation loss: 1.9770771367575533

Epoch: 6| Step: 12
Training loss: 1.7718327045440674
Validation loss: 1.904490578559137

Epoch: 6| Step: 13
Training loss: 1.4888291358947754
Validation loss: 1.952709823526362

Epoch: 284| Step: 0
Training loss: 1.0443546772003174
Validation loss: 1.9482827442948536

Epoch: 6| Step: 1
Training loss: 1.8879395723342896
Validation loss: 1.9231558217797229

Epoch: 6| Step: 2
Training loss: 1.1674226522445679
Validation loss: 1.9551480816256614

Epoch: 6| Step: 3
Training loss: 1.5097990036010742
Validation loss: 1.9565977563140213

Epoch: 6| Step: 4
Training loss: 1.5229511260986328
Validation loss: 1.9537756494296494

Epoch: 6| Step: 5
Training loss: 1.6755845546722412
Validation loss: 1.8883766730626423

Epoch: 6| Step: 6
Training loss: 1.3937959671020508
Validation loss: 1.937276013435856

Epoch: 6| Step: 7
Training loss: 1.475698709487915
Validation loss: 1.8896659446018997

Epoch: 6| Step: 8
Training loss: 1.6247400045394897
Validation loss: 1.8500776060165898

Epoch: 6| Step: 9
Training loss: 2.0905673503875732
Validation loss: 1.89792489364583

Epoch: 6| Step: 10
Training loss: 1.5501956939697266
Validation loss: 1.8288245175474434

Epoch: 6| Step: 11
Training loss: 2.128730058670044
Validation loss: 1.953254416424741

Epoch: 6| Step: 12
Training loss: 1.0834635496139526
Validation loss: 1.9037803988302908

Epoch: 6| Step: 13
Training loss: 2.430933713912964
Validation loss: 1.9414918076607488

Epoch: 285| Step: 0
Training loss: 1.4487533569335938
Validation loss: 1.8989668738457464

Epoch: 6| Step: 1
Training loss: 1.683972954750061
Validation loss: 1.9314216388169156

Epoch: 6| Step: 2
Training loss: 1.848719835281372
Validation loss: 1.8959845009670462

Epoch: 6| Step: 3
Training loss: 1.5566868782043457
Validation loss: 1.8972579458708405

Epoch: 6| Step: 4
Training loss: 1.5116808414459229
Validation loss: 1.9571578477018623

Epoch: 6| Step: 5
Training loss: 1.4541434049606323
Validation loss: 1.9306027466251003

Epoch: 6| Step: 6
Training loss: 1.7011222839355469
Validation loss: 1.9065017802740938

Epoch: 6| Step: 7
Training loss: 1.4481885433197021
Validation loss: 1.9150866180337884

Epoch: 6| Step: 8
Training loss: 1.233686089515686
Validation loss: 1.917805601191777

Epoch: 6| Step: 9
Training loss: 1.6397199630737305
Validation loss: 1.9160635061161493

Epoch: 6| Step: 10
Training loss: 1.713823676109314
Validation loss: 1.8950588921064973

Epoch: 6| Step: 11
Training loss: 1.3507367372512817
Validation loss: 1.8766760595383183

Epoch: 6| Step: 12
Training loss: 1.3219738006591797
Validation loss: 1.9421981547468452

Epoch: 6| Step: 13
Training loss: 2.7459707260131836
Validation loss: 1.9485771079217233

Epoch: 286| Step: 0
Training loss: 1.6872761249542236
Validation loss: 1.9466667188111173

Epoch: 6| Step: 1
Training loss: 1.729509949684143
Validation loss: 1.9571634466930101

Epoch: 6| Step: 2
Training loss: 2.155421257019043
Validation loss: 1.8649465871113602

Epoch: 6| Step: 3
Training loss: 1.3627065420150757
Validation loss: 1.9306105593199372

Epoch: 6| Step: 4
Training loss: 1.2605514526367188
Validation loss: 1.9118305636990456

Epoch: 6| Step: 5
Training loss: 1.8357853889465332
Validation loss: 1.95219511114141

Epoch: 6| Step: 6
Training loss: 1.4064252376556396
Validation loss: 1.9537952946078392

Epoch: 6| Step: 7
Training loss: 1.9547711610794067
Validation loss: 1.946937366198468

Epoch: 6| Step: 8
Training loss: 1.6331839561462402
Validation loss: 1.9190146461609872

Epoch: 6| Step: 9
Training loss: 1.8773168325424194
Validation loss: 2.016947820622434

Epoch: 6| Step: 10
Training loss: 1.1087124347686768
Validation loss: 1.9424918031179776

Epoch: 6| Step: 11
Training loss: 1.2809205055236816
Validation loss: 1.9241057993263326

Epoch: 6| Step: 12
Training loss: 1.1040525436401367
Validation loss: 2.0036128644020326

Epoch: 6| Step: 13
Training loss: 2.1161298751831055
Validation loss: 1.935795912178614

Epoch: 287| Step: 0
Training loss: 1.4887492656707764
Validation loss: 1.970473148489511

Epoch: 6| Step: 1
Training loss: 1.3396433591842651
Validation loss: 1.8920756770718483

Epoch: 6| Step: 2
Training loss: 2.038193464279175
Validation loss: 1.984013706125239

Epoch: 6| Step: 3
Training loss: 1.3956767320632935
Validation loss: 1.9259281030265234

Epoch: 6| Step: 4
Training loss: 1.4341156482696533
Validation loss: 1.9281471275514173

Epoch: 6| Step: 5
Training loss: 1.4967041015625
Validation loss: 1.9865069722616544

Epoch: 6| Step: 6
Training loss: 1.8090364933013916
Validation loss: 1.936860728007491

Epoch: 6| Step: 7
Training loss: 1.6286959648132324
Validation loss: 1.9537060952955676

Epoch: 6| Step: 8
Training loss: 2.250624895095825
Validation loss: 1.9388930682213075

Epoch: 6| Step: 9
Training loss: 1.6499621868133545
Validation loss: 1.8912305972909416

Epoch: 6| Step: 10
Training loss: 1.198641061782837
Validation loss: 1.936514868531176

Epoch: 6| Step: 11
Training loss: 1.7132771015167236
Validation loss: 1.958856185277303

Epoch: 6| Step: 12
Training loss: 1.5187771320343018
Validation loss: 1.9360924510545627

Epoch: 6| Step: 13
Training loss: 1.5037016868591309
Validation loss: 1.9228114620331795

Epoch: 288| Step: 0
Training loss: 1.4976580142974854
Validation loss: 1.972556128296801

Epoch: 6| Step: 1
Training loss: 1.2710680961608887
Validation loss: 1.969637583660823

Epoch: 6| Step: 2
Training loss: 1.5951367616653442
Validation loss: 1.8092083443877518

Epoch: 6| Step: 3
Training loss: 1.561480164527893
Validation loss: 1.9165080055113761

Epoch: 6| Step: 4
Training loss: 1.5331255197525024
Validation loss: 1.9254633970158075

Epoch: 6| Step: 5
Training loss: 1.326650619506836
Validation loss: 1.903483767663279

Epoch: 6| Step: 6
Training loss: 1.856589913368225
Validation loss: 1.953954537709554

Epoch: 6| Step: 7
Training loss: 1.370009422302246
Validation loss: 1.8512880827790947

Epoch: 6| Step: 8
Training loss: 2.0353593826293945
Validation loss: 1.9583125909169514

Epoch: 6| Step: 9
Training loss: 1.8142390251159668
Validation loss: 1.9443825060321438

Epoch: 6| Step: 10
Training loss: 1.6551826000213623
Validation loss: 1.984584455849022

Epoch: 6| Step: 11
Training loss: 1.088111162185669
Validation loss: 1.919870444523391

Epoch: 6| Step: 12
Training loss: 2.3470983505249023
Validation loss: 1.9325683604004562

Epoch: 6| Step: 13
Training loss: 0.9889541268348694
Validation loss: 1.9647463931832263

Epoch: 289| Step: 0
Training loss: 1.238163709640503
Validation loss: 1.9996725769453152

Epoch: 6| Step: 1
Training loss: 0.8715465068817139
Validation loss: 1.9384278866552538

Epoch: 6| Step: 2
Training loss: 1.8258051872253418
Validation loss: 1.9629732178103538

Epoch: 6| Step: 3
Training loss: 1.6396701335906982
Validation loss: 1.935593358932003

Epoch: 6| Step: 4
Training loss: 1.3156073093414307
Validation loss: 1.9474545704421176

Epoch: 6| Step: 5
Training loss: 1.8578243255615234
Validation loss: 1.8914534917441748

Epoch: 6| Step: 6
Training loss: 1.3555890321731567
Validation loss: 1.8996871133004465

Epoch: 6| Step: 7
Training loss: 1.8212307691574097
Validation loss: 1.9314807384244856

Epoch: 6| Step: 8
Training loss: 2.1015095710754395
Validation loss: 1.8239189424822408

Epoch: 6| Step: 9
Training loss: 0.777869701385498
Validation loss: 1.9422871566587878

Epoch: 6| Step: 10
Training loss: 1.8405166864395142
Validation loss: 1.8839041058735182

Epoch: 6| Step: 11
Training loss: 1.9400545358657837
Validation loss: 1.9462905622297717

Epoch: 6| Step: 12
Training loss: 1.7905011177062988
Validation loss: 1.9329070775739607

Epoch: 6| Step: 13
Training loss: 1.8481330871582031
Validation loss: 1.8792181091923867

Epoch: 290| Step: 0
Training loss: 1.2923152446746826
Validation loss: 1.9121004048214163

Epoch: 6| Step: 1
Training loss: 1.6923398971557617
Validation loss: 1.9165428223148469

Epoch: 6| Step: 2
Training loss: 1.175260305404663
Validation loss: 1.9499750457784182

Epoch: 6| Step: 3
Training loss: 1.7399345636367798
Validation loss: 1.9009485975388558

Epoch: 6| Step: 4
Training loss: 1.0948216915130615
Validation loss: 1.9223174895009687

Epoch: 6| Step: 5
Training loss: 1.643479585647583
Validation loss: 1.879982304829423

Epoch: 6| Step: 6
Training loss: 1.160107970237732
Validation loss: 1.909020234179753

Epoch: 6| Step: 7
Training loss: 1.8350789546966553
Validation loss: 1.9047185272298834

Epoch: 6| Step: 8
Training loss: 2.547032117843628
Validation loss: 1.9689421769111388

Epoch: 6| Step: 9
Training loss: 1.9307540655136108
Validation loss: 1.8830931468676495

Epoch: 6| Step: 10
Training loss: 1.704216480255127
Validation loss: 1.9415775422127015

Epoch: 6| Step: 11
Training loss: 1.2046289443969727
Validation loss: 1.9483465802284978

Epoch: 6| Step: 12
Training loss: 1.7710177898406982
Validation loss: 1.9551625764498146

Epoch: 6| Step: 13
Training loss: 1.0655657052993774
Validation loss: 1.9366546215549592

Epoch: 291| Step: 0
Training loss: 1.467113971710205
Validation loss: 1.939112683778168

Epoch: 6| Step: 1
Training loss: 2.0586464405059814
Validation loss: 1.9699524525673158

Epoch: 6| Step: 2
Training loss: 1.316662311553955
Validation loss: 1.932357415076225

Epoch: 6| Step: 3
Training loss: 1.625601053237915
Validation loss: 1.9390846567769204

Epoch: 6| Step: 4
Training loss: 1.4986129999160767
Validation loss: 1.886640202614569

Epoch: 6| Step: 5
Training loss: 1.0394483804702759
Validation loss: 1.9065171903179539

Epoch: 6| Step: 6
Training loss: 1.654353141784668
Validation loss: 1.9696095925505444

Epoch: 6| Step: 7
Training loss: 1.1706106662750244
Validation loss: 1.9187744253425187

Epoch: 6| Step: 8
Training loss: 1.666883945465088
Validation loss: 1.9006096560467955

Epoch: 6| Step: 9
Training loss: 1.2643601894378662
Validation loss: 1.9019397753541187

Epoch: 6| Step: 10
Training loss: 2.4369349479675293
Validation loss: 1.8770531967122068

Epoch: 6| Step: 11
Training loss: 1.3098490238189697
Validation loss: 1.9235134778484222

Epoch: 6| Step: 12
Training loss: 1.4058098793029785
Validation loss: 1.9257754523267028

Epoch: 6| Step: 13
Training loss: 2.413740396499634
Validation loss: 1.8494957031742219

Epoch: 292| Step: 0
Training loss: 1.2378535270690918
Validation loss: 1.9344180604462982

Epoch: 6| Step: 1
Training loss: 1.6580008268356323
Validation loss: 1.9121729173967916

Epoch: 6| Step: 2
Training loss: 0.9846018552780151
Validation loss: 1.9012465515444357

Epoch: 6| Step: 3
Training loss: 1.7799344062805176
Validation loss: 1.8647968166617936

Epoch: 6| Step: 4
Training loss: 2.0738158226013184
Validation loss: 1.8778188972062961

Epoch: 6| Step: 5
Training loss: 1.0723352432250977
Validation loss: 1.8484825190677439

Epoch: 6| Step: 6
Training loss: 1.560166835784912
Validation loss: 1.8840447548897035

Epoch: 6| Step: 7
Training loss: 1.239311933517456
Validation loss: 1.9722625991349578

Epoch: 6| Step: 8
Training loss: 1.601083517074585
Validation loss: 1.899361575803449

Epoch: 6| Step: 9
Training loss: 1.1945726871490479
Validation loss: 1.8523261431724793

Epoch: 6| Step: 10
Training loss: 1.7175146341323853
Validation loss: 1.9396732481577064

Epoch: 6| Step: 11
Training loss: 2.223446846008301
Validation loss: 1.9285222125309769

Epoch: 6| Step: 12
Training loss: 2.189154624938965
Validation loss: 1.872725325246011

Epoch: 6| Step: 13
Training loss: 1.7603422403335571
Validation loss: 1.8874653834168629

Epoch: 293| Step: 0
Training loss: 1.8806257247924805
Validation loss: 1.9032110027087632

Epoch: 6| Step: 1
Training loss: 0.9654008746147156
Validation loss: 1.9230192733067337

Epoch: 6| Step: 2
Training loss: 1.488844871520996
Validation loss: 1.9390364129056212

Epoch: 6| Step: 3
Training loss: 1.3555418252944946
Validation loss: 1.9546204600282895

Epoch: 6| Step: 4
Training loss: 1.6486631631851196
Validation loss: 1.9458503441144062

Epoch: 6| Step: 5
Training loss: 1.4000864028930664
Validation loss: 1.9556504308536489

Epoch: 6| Step: 6
Training loss: 1.2115745544433594
Validation loss: 1.870767944602556

Epoch: 6| Step: 7
Training loss: 1.9222943782806396
Validation loss: 1.915620134722802

Epoch: 6| Step: 8
Training loss: 1.9229342937469482
Validation loss: 1.9793650527154245

Epoch: 6| Step: 9
Training loss: 0.957460880279541
Validation loss: 1.9618530991256877

Epoch: 6| Step: 10
Training loss: 2.054875373840332
Validation loss: 1.9343744362554243

Epoch: 6| Step: 11
Training loss: 1.5518999099731445
Validation loss: 1.9121761168203046

Epoch: 6| Step: 12
Training loss: 1.9924516677856445
Validation loss: 1.85981192768261

Epoch: 6| Step: 13
Training loss: 2.499091386795044
Validation loss: 1.8638784321405555

Epoch: 294| Step: 0
Training loss: 1.3323856592178345
Validation loss: 1.9333745497529224

Epoch: 6| Step: 1
Training loss: 2.101933479309082
Validation loss: 1.9412397979408182

Epoch: 6| Step: 2
Training loss: 1.6733920574188232
Validation loss: 1.9147835726379066

Epoch: 6| Step: 3
Training loss: 1.690298080444336
Validation loss: 1.832479012909756

Epoch: 6| Step: 4
Training loss: 1.4649040699005127
Validation loss: 1.8444310952258367

Epoch: 6| Step: 5
Training loss: 1.4909682273864746
Validation loss: 1.9165522513851043

Epoch: 6| Step: 6
Training loss: 1.6594544649124146
Validation loss: 1.8997102604117444

Epoch: 6| Step: 7
Training loss: 1.833721399307251
Validation loss: 1.9542642370347054

Epoch: 6| Step: 8
Training loss: 1.0907365083694458
Validation loss: 1.8804120927728631

Epoch: 6| Step: 9
Training loss: 1.230006217956543
Validation loss: 1.9385257703001781

Epoch: 6| Step: 10
Training loss: 1.7644023895263672
Validation loss: 1.9222429285767257

Epoch: 6| Step: 11
Training loss: 1.4457111358642578
Validation loss: 1.989132167190634

Epoch: 6| Step: 12
Training loss: 1.5515035390853882
Validation loss: 1.9314175293009768

Epoch: 6| Step: 13
Training loss: 2.2579638957977295
Validation loss: 1.9469173723651516

Epoch: 295| Step: 0
Training loss: 1.2771192789077759
Validation loss: 1.9565116577250983

Epoch: 6| Step: 1
Training loss: 1.2693109512329102
Validation loss: 1.9500819944566297

Epoch: 6| Step: 2
Training loss: 1.7919869422912598
Validation loss: 1.9793112188257196

Epoch: 6| Step: 3
Training loss: 1.3056695461273193
Validation loss: 1.958377835571125

Epoch: 6| Step: 4
Training loss: 2.0056257247924805
Validation loss: 1.9581177580741145

Epoch: 6| Step: 5
Training loss: 1.8909261226654053
Validation loss: 1.9628079488713255

Epoch: 6| Step: 6
Training loss: 1.6531866788864136
Validation loss: 1.9538761056879514

Epoch: 6| Step: 7
Training loss: 1.9368128776550293
Validation loss: 1.8950857193239274

Epoch: 6| Step: 8
Training loss: 1.587586760520935
Validation loss: 1.9512718403211204

Epoch: 6| Step: 9
Training loss: 1.2331442832946777
Validation loss: 1.984418620345413

Epoch: 6| Step: 10
Training loss: 1.5577120780944824
Validation loss: 1.9680309282836093

Epoch: 6| Step: 11
Training loss: 1.2965937852859497
Validation loss: 1.9473635842723231

Epoch: 6| Step: 12
Training loss: 1.6544525623321533
Validation loss: 1.9256957461757045

Epoch: 6| Step: 13
Training loss: 1.5202422142028809
Validation loss: 1.9179002443949382

Epoch: 296| Step: 0
Training loss: 1.9872233867645264
Validation loss: 1.978507782823296

Epoch: 6| Step: 1
Training loss: 1.6095043420791626
Validation loss: 1.9011361163149598

Epoch: 6| Step: 2
Training loss: 1.81314218044281
Validation loss: 1.9175690220248314

Epoch: 6| Step: 3
Training loss: 1.4529881477355957
Validation loss: 1.8592966320694133

Epoch: 6| Step: 4
Training loss: 1.0912550687789917
Validation loss: 1.9192384442975443

Epoch: 6| Step: 5
Training loss: 2.03243350982666
Validation loss: 1.9160336909755584

Epoch: 6| Step: 6
Training loss: 1.9217218160629272
Validation loss: 1.9360402668676069

Epoch: 6| Step: 7
Training loss: 0.9943593740463257
Validation loss: 1.9038676959212109

Epoch: 6| Step: 8
Training loss: 1.4382801055908203
Validation loss: 1.9378301123137116

Epoch: 6| Step: 9
Training loss: 1.9062386751174927
Validation loss: 1.9145260010996172

Epoch: 6| Step: 10
Training loss: 1.4140251874923706
Validation loss: 1.891144899911778

Epoch: 6| Step: 11
Training loss: 1.7467894554138184
Validation loss: 1.996363498831308

Epoch: 6| Step: 12
Training loss: 1.381563425064087
Validation loss: 1.9186944166819255

Epoch: 6| Step: 13
Training loss: 0.9442121982574463
Validation loss: 1.8922703650689894

Epoch: 297| Step: 0
Training loss: 1.5766277313232422
Validation loss: 1.949375157715172

Epoch: 6| Step: 1
Training loss: 1.1645333766937256
Validation loss: 1.8629988239657493

Epoch: 6| Step: 2
Training loss: 1.66541588306427
Validation loss: 1.9273949002706876

Epoch: 6| Step: 3
Training loss: 1.620713233947754
Validation loss: 1.9134094420299734

Epoch: 6| Step: 4
Training loss: 1.4811232089996338
Validation loss: 1.9181748884980396

Epoch: 6| Step: 5
Training loss: 1.5024316310882568
Validation loss: 1.8999472407884495

Epoch: 6| Step: 6
Training loss: 0.9534426927566528
Validation loss: 1.8805386199746081

Epoch: 6| Step: 7
Training loss: 1.4189138412475586
Validation loss: 1.9751642775791947

Epoch: 6| Step: 8
Training loss: 1.911609411239624
Validation loss: 1.9671511701358262

Epoch: 6| Step: 9
Training loss: 1.824285864830017
Validation loss: 1.9441769687078332

Epoch: 6| Step: 10
Training loss: 1.5220118761062622
Validation loss: 1.8681020262420818

Epoch: 6| Step: 11
Training loss: 1.3758695125579834
Validation loss: 1.9126082235766995

Epoch: 6| Step: 12
Training loss: 2.037794589996338
Validation loss: 1.8602182121687039

Epoch: 6| Step: 13
Training loss: 2.0890493392944336
Validation loss: 1.9215609809403777

Epoch: 298| Step: 0
Training loss: 1.4650208950042725
Validation loss: 1.8932257057518087

Epoch: 6| Step: 1
Training loss: 1.7447584867477417
Validation loss: 1.873001193487516

Epoch: 6| Step: 2
Training loss: 1.5630772113800049
Validation loss: 1.899016744347029

Epoch: 6| Step: 3
Training loss: 1.5412662029266357
Validation loss: 1.8517151673634846

Epoch: 6| Step: 4
Training loss: 1.4917442798614502
Validation loss: 1.8331671299472931

Epoch: 6| Step: 5
Training loss: 1.2003896236419678
Validation loss: 1.8489098779616817

Epoch: 6| Step: 6
Training loss: 1.9757122993469238
Validation loss: 1.914439771765022

Epoch: 6| Step: 7
Training loss: 1.6752188205718994
Validation loss: 1.9202229592107958

Epoch: 6| Step: 8
Training loss: 1.6188294887542725
Validation loss: 1.8576126149905625

Epoch: 6| Step: 9
Training loss: 1.1729971170425415
Validation loss: 1.8252556759824035

Epoch: 6| Step: 10
Training loss: 1.6762430667877197
Validation loss: 1.8486266110533027

Epoch: 6| Step: 11
Training loss: 1.5525619983673096
Validation loss: 1.9040343017988308

Epoch: 6| Step: 12
Training loss: 1.8133571147918701
Validation loss: 1.951290330579204

Epoch: 6| Step: 13
Training loss: 1.883360505104065
Validation loss: 1.9055573273730535

Epoch: 299| Step: 0
Training loss: 2.5725948810577393
Validation loss: 1.9431993653697353

Epoch: 6| Step: 1
Training loss: 1.057005524635315
Validation loss: 1.9170242394170454

Epoch: 6| Step: 2
Training loss: 1.3061619997024536
Validation loss: 1.975109036250781

Epoch: 6| Step: 3
Training loss: 1.593660593032837
Validation loss: 1.9627543239183323

Epoch: 6| Step: 4
Training loss: 1.1160460710525513
Validation loss: 1.9121818363025624

Epoch: 6| Step: 5
Training loss: 1.4815856218338013
Validation loss: 1.958790954723153

Epoch: 6| Step: 6
Training loss: 1.7264699935913086
Validation loss: 1.8766822456031718

Epoch: 6| Step: 7
Training loss: 1.1633164882659912
Validation loss: 1.9421075108230754

Epoch: 6| Step: 8
Training loss: 2.5014307498931885
Validation loss: 1.9514270469706545

Epoch: 6| Step: 9
Training loss: 1.0695301294326782
Validation loss: 2.005078449044176

Epoch: 6| Step: 10
Training loss: 1.4509916305541992
Validation loss: 1.9363501405203214

Epoch: 6| Step: 11
Training loss: 1.5851330757141113
Validation loss: 1.9756063004975677

Epoch: 6| Step: 12
Training loss: 1.670733094215393
Validation loss: 1.9985962913882347

Epoch: 6| Step: 13
Training loss: 1.3754267692565918
Validation loss: 1.9389910095481462

Epoch: 300| Step: 0
Training loss: 2.259891986846924
Validation loss: 1.913428061751909

Epoch: 6| Step: 1
Training loss: 2.0302579402923584
Validation loss: 1.9192257940128286

Epoch: 6| Step: 2
Training loss: 1.2588577270507812
Validation loss: 1.9547927046334872

Epoch: 6| Step: 3
Training loss: 1.0195770263671875
Validation loss: 1.8752046054409397

Epoch: 6| Step: 4
Training loss: 1.6655066013336182
Validation loss: 1.9259904687122633

Epoch: 6| Step: 5
Training loss: 2.1425790786743164
Validation loss: 1.9246193055183656

Epoch: 6| Step: 6
Training loss: 1.8418920040130615
Validation loss: 1.9170399801705473

Epoch: 6| Step: 7
Training loss: 1.4169633388519287
Validation loss: 1.9194065422140143

Epoch: 6| Step: 8
Training loss: 1.4112998247146606
Validation loss: 1.8764543943507697

Epoch: 6| Step: 9
Training loss: 1.29531729221344
Validation loss: 1.9042443139578706

Epoch: 6| Step: 10
Training loss: 1.1978979110717773
Validation loss: 1.9196466809959822

Epoch: 6| Step: 11
Training loss: 1.2285432815551758
Validation loss: 1.9533647362903883

Epoch: 6| Step: 12
Training loss: 1.5293052196502686
Validation loss: 1.9091002505312684

Epoch: 6| Step: 13
Training loss: 1.45737886428833
Validation loss: 1.922831460993777

Epoch: 301| Step: 0
Training loss: 1.5671641826629639
Validation loss: 1.9678230542008595

Epoch: 6| Step: 1
Training loss: 1.3650528192520142
Validation loss: 1.908009680368567

Epoch: 6| Step: 2
Training loss: 1.4929381608963013
Validation loss: 1.8807917782055434

Epoch: 6| Step: 3
Training loss: 1.2470057010650635
Validation loss: 1.902277131234446

Epoch: 6| Step: 4
Training loss: 1.9947760105133057
Validation loss: 1.9208175366924656

Epoch: 6| Step: 5
Training loss: 2.0660147666931152
Validation loss: 1.9444879972806541

Epoch: 6| Step: 6
Training loss: 1.6827902793884277
Validation loss: 1.974653318364133

Epoch: 6| Step: 7
Training loss: 1.7401889562606812
Validation loss: 1.9300377702200284

Epoch: 6| Step: 8
Training loss: 1.0587148666381836
Validation loss: 1.8858173252433859

Epoch: 6| Step: 9
Training loss: 1.7345378398895264
Validation loss: 1.9307798019019506

Epoch: 6| Step: 10
Training loss: 1.5322344303131104
Validation loss: 1.8622479925873459

Epoch: 6| Step: 11
Training loss: 2.0187339782714844
Validation loss: 1.8932186583037018

Epoch: 6| Step: 12
Training loss: 1.3354575634002686
Validation loss: 1.896401261770597

Epoch: 6| Step: 13
Training loss: 0.8487909436225891
Validation loss: 1.9025506293901833

Epoch: 302| Step: 0
Training loss: 1.997787594795227
Validation loss: 1.8526604175567627

Epoch: 6| Step: 1
Training loss: 1.540732741355896
Validation loss: 1.9407393829796904

Epoch: 6| Step: 2
Training loss: 1.4669227600097656
Validation loss: 1.8661633140297347

Epoch: 6| Step: 3
Training loss: 1.510662317276001
Validation loss: 1.9015583146002986

Epoch: 6| Step: 4
Training loss: 1.419628381729126
Validation loss: 1.8933068142142346

Epoch: 6| Step: 5
Training loss: 1.950677752494812
Validation loss: 1.8878384303021174

Epoch: 6| Step: 6
Training loss: 1.4653470516204834
Validation loss: 1.8495439098727318

Epoch: 6| Step: 7
Training loss: 2.0160675048828125
Validation loss: 1.8605362663986862

Epoch: 6| Step: 8
Training loss: 1.2664289474487305
Validation loss: 1.848453224346202

Epoch: 6| Step: 9
Training loss: 1.8723236322402954
Validation loss: 1.8161834311741654

Epoch: 6| Step: 10
Training loss: 1.8993326425552368
Validation loss: 1.8877340055281115

Epoch: 6| Step: 11
Training loss: 1.6291654109954834
Validation loss: 1.8933293909154914

Epoch: 6| Step: 12
Training loss: 1.3511950969696045
Validation loss: 1.8496660314580446

Epoch: 6| Step: 13
Training loss: 1.0570590496063232
Validation loss: 1.8432291861503356

Epoch: 303| Step: 0
Training loss: 1.7682149410247803
Validation loss: 1.8561332700073079

Epoch: 6| Step: 1
Training loss: 1.5437517166137695
Validation loss: 1.931521290092058

Epoch: 6| Step: 2
Training loss: 1.7345563173294067
Validation loss: 1.893501627829767

Epoch: 6| Step: 3
Training loss: 1.222693681716919
Validation loss: 1.9404348942541307

Epoch: 6| Step: 4
Training loss: 1.6331467628479004
Validation loss: 1.9621602617284304

Epoch: 6| Step: 5
Training loss: 1.5252019166946411
Validation loss: 1.8718397027702742

Epoch: 6| Step: 6
Training loss: 1.5540322065353394
Validation loss: 1.8917134410591536

Epoch: 6| Step: 7
Training loss: 1.4478607177734375
Validation loss: 1.9503905516798778

Epoch: 6| Step: 8
Training loss: 2.407341480255127
Validation loss: 1.884190946496943

Epoch: 6| Step: 9
Training loss: 1.238770842552185
Validation loss: 1.8966946307049002

Epoch: 6| Step: 10
Training loss: 1.76393461227417
Validation loss: 1.8746083116018644

Epoch: 6| Step: 11
Training loss: 1.4722579717636108
Validation loss: 1.9379912448185745

Epoch: 6| Step: 12
Training loss: 1.5556119680404663
Validation loss: 1.9940959753528718

Epoch: 6| Step: 13
Training loss: 0.6552050113677979
Validation loss: 1.9857185861115814

Epoch: 304| Step: 0
Training loss: 1.0286213159561157
Validation loss: 1.8771872802447247

Epoch: 6| Step: 1
Training loss: 1.5078556537628174
Validation loss: 1.8552715957805674

Epoch: 6| Step: 2
Training loss: 1.4458658695220947
Validation loss: 1.8947630005498086

Epoch: 6| Step: 3
Training loss: 2.5881166458129883
Validation loss: 1.9706518278327039

Epoch: 6| Step: 4
Training loss: 1.4632270336151123
Validation loss: 1.9094912672555575

Epoch: 6| Step: 5
Training loss: 2.1652071475982666
Validation loss: 1.9124170734036354

Epoch: 6| Step: 6
Training loss: 1.320167064666748
Validation loss: 1.911616926552147

Epoch: 6| Step: 7
Training loss: 1.2293412685394287
Validation loss: 1.9596409054212673

Epoch: 6| Step: 8
Training loss: 1.4473915100097656
Validation loss: 1.8700894668538084

Epoch: 6| Step: 9
Training loss: 1.4422574043273926
Validation loss: 1.8758500455528178

Epoch: 6| Step: 10
Training loss: 1.68212890625
Validation loss: 1.947867516548403

Epoch: 6| Step: 11
Training loss: 1.5379693508148193
Validation loss: 1.8889904419581096

Epoch: 6| Step: 12
Training loss: 2.0258126258850098
Validation loss: 1.8306918592863186

Epoch: 6| Step: 13
Training loss: 0.5638791918754578
Validation loss: 1.903079863517515

Epoch: 305| Step: 0
Training loss: 1.6636686325073242
Validation loss: 1.9506627167424848

Epoch: 6| Step: 1
Training loss: 1.4659204483032227
Validation loss: 1.9285965299093595

Epoch: 6| Step: 2
Training loss: 1.3791133165359497
Validation loss: 1.9332305974857782

Epoch: 6| Step: 3
Training loss: 2.063694953918457
Validation loss: 1.901375856450809

Epoch: 6| Step: 4
Training loss: 1.1000131368637085
Validation loss: 1.8489585230427403

Epoch: 6| Step: 5
Training loss: 1.7643232345581055
Validation loss: 1.868857378600746

Epoch: 6| Step: 6
Training loss: 2.2475898265838623
Validation loss: 1.8572570675162858

Epoch: 6| Step: 7
Training loss: 1.1265500783920288
Validation loss: 1.8646057754434564

Epoch: 6| Step: 8
Training loss: 1.9820806980133057
Validation loss: 1.8788581817380843

Epoch: 6| Step: 9
Training loss: 1.6425220966339111
Validation loss: 1.8531943828828874

Epoch: 6| Step: 10
Training loss: 0.9829361438751221
Validation loss: 1.9001374706145255

Epoch: 6| Step: 11
Training loss: 1.0272703170776367
Validation loss: 1.912198269239036

Epoch: 6| Step: 12
Training loss: 2.141172170639038
Validation loss: 1.9618049180635841

Epoch: 6| Step: 13
Training loss: 1.6453673839569092
Validation loss: 1.8652910212034821

Epoch: 306| Step: 0
Training loss: 1.2337843179702759
Validation loss: 1.947092781784714

Epoch: 6| Step: 1
Training loss: 1.4782919883728027
Validation loss: 1.9763916423243861

Epoch: 6| Step: 2
Training loss: 1.3630588054656982
Validation loss: 1.9067514557992258

Epoch: 6| Step: 3
Training loss: 1.33221435546875
Validation loss: 1.9448548824556413

Epoch: 6| Step: 4
Training loss: 2.0245747566223145
Validation loss: 1.9494508158776067

Epoch: 6| Step: 5
Training loss: 1.9510619640350342
Validation loss: 1.9474148699032363

Epoch: 6| Step: 6
Training loss: 1.3340760469436646
Validation loss: 1.959035478612428

Epoch: 6| Step: 7
Training loss: 1.0823018550872803
Validation loss: 1.8907745935583626

Epoch: 6| Step: 8
Training loss: 1.2233366966247559
Validation loss: 1.976096785196694

Epoch: 6| Step: 9
Training loss: 1.334585428237915
Validation loss: 1.9901293221340384

Epoch: 6| Step: 10
Training loss: 2.0880842208862305
Validation loss: 1.9108645057165494

Epoch: 6| Step: 11
Training loss: 1.2454439401626587
Validation loss: 1.9143799428016908

Epoch: 6| Step: 12
Training loss: 2.307119369506836
Validation loss: 1.914708481040052

Epoch: 6| Step: 13
Training loss: 1.4079968929290771
Validation loss: 1.902130675572221

Epoch: 307| Step: 0
Training loss: 1.631548523902893
Validation loss: 1.95748092538567

Epoch: 6| Step: 1
Training loss: 1.1293131113052368
Validation loss: 1.9430682851422219

Epoch: 6| Step: 2
Training loss: 1.6508243083953857
Validation loss: 1.8769741109622422

Epoch: 6| Step: 3
Training loss: 2.563668727874756
Validation loss: 1.9384966819517073

Epoch: 6| Step: 4
Training loss: 1.6267099380493164
Validation loss: 1.904078120826393

Epoch: 6| Step: 5
Training loss: 1.8580533266067505
Validation loss: 1.896992419355659

Epoch: 6| Step: 6
Training loss: 1.8335373401641846
Validation loss: 1.9534394817967569

Epoch: 6| Step: 7
Training loss: 2.0109004974365234
Validation loss: 1.9001751522864065

Epoch: 6| Step: 8
Training loss: 1.4191923141479492
Validation loss: 1.8734933778803835

Epoch: 6| Step: 9
Training loss: 1.4708489179611206
Validation loss: 1.9055407970182356

Epoch: 6| Step: 10
Training loss: 1.573913335800171
Validation loss: 1.8862199039869412

Epoch: 6| Step: 11
Training loss: 1.1054471731185913
Validation loss: 1.8947278120184456

Epoch: 6| Step: 12
Training loss: 1.1630237102508545
Validation loss: 1.9086960682304956

Epoch: 6| Step: 13
Training loss: 0.7265519499778748
Validation loss: 1.9096421900615896

Epoch: 308| Step: 0
Training loss: 1.3477556705474854
Validation loss: 1.890285143288233

Epoch: 6| Step: 1
Training loss: 1.3757728338241577
Validation loss: 1.8248023858634375

Epoch: 6| Step: 2
Training loss: 1.5384752750396729
Validation loss: 1.8719342652187552

Epoch: 6| Step: 3
Training loss: 1.5220603942871094
Validation loss: 1.9013900961927188

Epoch: 6| Step: 4
Training loss: 2.5914554595947266
Validation loss: 1.9495685574828938

Epoch: 6| Step: 5
Training loss: 1.7145593166351318
Validation loss: 1.9181998724578528

Epoch: 6| Step: 6
Training loss: 0.9396425485610962
Validation loss: 2.010424760080153

Epoch: 6| Step: 7
Training loss: 1.3365617990493774
Validation loss: 1.9142736811791696

Epoch: 6| Step: 8
Training loss: 1.3057671785354614
Validation loss: 1.9050710906264603

Epoch: 6| Step: 9
Training loss: 1.156103253364563
Validation loss: 1.9667262697732577

Epoch: 6| Step: 10
Training loss: 1.53436279296875
Validation loss: 1.878468995453209

Epoch: 6| Step: 11
Training loss: 1.8610641956329346
Validation loss: 1.9421378861191452

Epoch: 6| Step: 12
Training loss: 0.9776408076286316
Validation loss: 1.923614937772033

Epoch: 6| Step: 13
Training loss: 2.021466016769409
Validation loss: 1.828434887752738

Epoch: 309| Step: 0
Training loss: 1.64504075050354
Validation loss: 1.8589889285384968

Epoch: 6| Step: 1
Training loss: 2.394099712371826
Validation loss: 1.8898584304317352

Epoch: 6| Step: 2
Training loss: 1.175913691520691
Validation loss: 1.9390276785819762

Epoch: 6| Step: 3
Training loss: 1.0637954473495483
Validation loss: 1.8682564817449099

Epoch: 6| Step: 4
Training loss: 1.774411678314209
Validation loss: 1.8852798541386921

Epoch: 6| Step: 5
Training loss: 1.8793362379074097
Validation loss: 1.9184562801032938

Epoch: 6| Step: 6
Training loss: 1.0707483291625977
Validation loss: 1.9068789071934198

Epoch: 6| Step: 7
Training loss: 1.4041506052017212
Validation loss: 1.9490741888682048

Epoch: 6| Step: 8
Training loss: 1.9832067489624023
Validation loss: 1.9116485144502373

Epoch: 6| Step: 9
Training loss: 0.511780321598053
Validation loss: 1.9452282754323815

Epoch: 6| Step: 10
Training loss: 1.6039690971374512
Validation loss: 1.9030420498181415

Epoch: 6| Step: 11
Training loss: 1.7776660919189453
Validation loss: 1.9259355837298977

Epoch: 6| Step: 12
Training loss: 1.4224116802215576
Validation loss: 1.8841760748176164

Epoch: 6| Step: 13
Training loss: 1.508260726928711
Validation loss: 1.8608099132455804

Epoch: 310| Step: 0
Training loss: 1.414198398590088
Validation loss: 1.9664933681488037

Epoch: 6| Step: 1
Training loss: 1.552428126335144
Validation loss: 1.947469478012413

Epoch: 6| Step: 2
Training loss: 2.244810104370117
Validation loss: 1.9408706195892826

Epoch: 6| Step: 3
Training loss: 1.6592674255371094
Validation loss: 1.9109277609855897

Epoch: 6| Step: 4
Training loss: 0.9291223287582397
Validation loss: 1.8617985684384581

Epoch: 6| Step: 5
Training loss: 1.383048415184021
Validation loss: 1.9027159149928758

Epoch: 6| Step: 6
Training loss: 1.7884362936019897
Validation loss: 1.8283375334996048

Epoch: 6| Step: 7
Training loss: 1.0303049087524414
Validation loss: 1.9054918532730432

Epoch: 6| Step: 8
Training loss: 1.94069504737854
Validation loss: 1.9234176861342562

Epoch: 6| Step: 9
Training loss: 1.4204373359680176
Validation loss: 1.8244513709058043

Epoch: 6| Step: 10
Training loss: 0.8784239292144775
Validation loss: 1.898517338178491

Epoch: 6| Step: 11
Training loss: 2.019805908203125
Validation loss: 1.8594754716401458

Epoch: 6| Step: 12
Training loss: 1.4838900566101074
Validation loss: 1.8743598512423936

Epoch: 6| Step: 13
Training loss: 1.8057376146316528
Validation loss: 1.8466314154286538

Epoch: 311| Step: 0
Training loss: 1.1566691398620605
Validation loss: 1.9709197526337

Epoch: 6| Step: 1
Training loss: 1.3711812496185303
Validation loss: 1.8897559540246123

Epoch: 6| Step: 2
Training loss: 1.6480690240859985
Validation loss: 1.8559178626665505

Epoch: 6| Step: 3
Training loss: 1.5057377815246582
Validation loss: 1.8324175675710042

Epoch: 6| Step: 4
Training loss: 1.82672917842865
Validation loss: 1.887819351688508

Epoch: 6| Step: 5
Training loss: 1.9194412231445312
Validation loss: 1.8796060700570383

Epoch: 6| Step: 6
Training loss: 1.144870400428772
Validation loss: 1.8790586456175773

Epoch: 6| Step: 7
Training loss: 1.5926263332366943
Validation loss: 1.9130230821588987

Epoch: 6| Step: 8
Training loss: 1.6409754753112793
Validation loss: 1.962541522518281

Epoch: 6| Step: 9
Training loss: 2.1027989387512207
Validation loss: 1.924689080125542

Epoch: 6| Step: 10
Training loss: 0.8293271660804749
Validation loss: 1.888491460072097

Epoch: 6| Step: 11
Training loss: 1.2756708860397339
Validation loss: 1.9468779845904278

Epoch: 6| Step: 12
Training loss: 2.0998945236206055
Validation loss: 1.9416874377958235

Epoch: 6| Step: 13
Training loss: 1.5887783765792847
Validation loss: 1.9592061119694864

Epoch: 312| Step: 0
Training loss: 1.3391082286834717
Validation loss: 1.9509402398140199

Epoch: 6| Step: 1
Training loss: 1.1700220108032227
Validation loss: 1.9536172882203133

Epoch: 6| Step: 2
Training loss: 1.0821609497070312
Validation loss: 1.8826990025017851

Epoch: 6| Step: 3
Training loss: 1.9407109022140503
Validation loss: 1.8752742621206469

Epoch: 6| Step: 4
Training loss: 1.6586418151855469
Validation loss: 1.899790096026595

Epoch: 6| Step: 5
Training loss: 1.9166631698608398
Validation loss: 1.9384823217186877

Epoch: 6| Step: 6
Training loss: 2.1803202629089355
Validation loss: 1.942691090286419

Epoch: 6| Step: 7
Training loss: 2.0093483924865723
Validation loss: 1.8267396342369817

Epoch: 6| Step: 8
Training loss: 0.9842479228973389
Validation loss: 1.8764397008444673

Epoch: 6| Step: 9
Training loss: 1.3874603509902954
Validation loss: 1.86309826502236

Epoch: 6| Step: 10
Training loss: 1.5329222679138184
Validation loss: 1.9124559305047477

Epoch: 6| Step: 11
Training loss: 0.9757642149925232
Validation loss: 1.86698991188439

Epoch: 6| Step: 12
Training loss: 1.172922134399414
Validation loss: 1.9079132310805782

Epoch: 6| Step: 13
Training loss: 1.8114914894104004
Validation loss: 1.8153423263180641

Epoch: 313| Step: 0
Training loss: 1.4207961559295654
Validation loss: 1.898846031517111

Epoch: 6| Step: 1
Training loss: 1.121878981590271
Validation loss: 1.8681571663066905

Epoch: 6| Step: 2
Training loss: 1.9453521966934204
Validation loss: 1.9005848541054675

Epoch: 6| Step: 3
Training loss: 1.6209518909454346
Validation loss: 1.9039730205330798

Epoch: 6| Step: 4
Training loss: 1.8596328496932983
Validation loss: 1.911189740703952

Epoch: 6| Step: 5
Training loss: 1.2685370445251465
Validation loss: 1.9492413997650146

Epoch: 6| Step: 6
Training loss: 1.2738935947418213
Validation loss: 1.8460174324691936

Epoch: 6| Step: 7
Training loss: 1.293807029724121
Validation loss: 1.923977678821933

Epoch: 6| Step: 8
Training loss: 2.1067376136779785
Validation loss: 1.892074772106704

Epoch: 6| Step: 9
Training loss: 1.9693868160247803
Validation loss: 1.9011030517598635

Epoch: 6| Step: 10
Training loss: 1.6202598810195923
Validation loss: 1.8419874047720304

Epoch: 6| Step: 11
Training loss: 1.5353600978851318
Validation loss: 1.943653706581362

Epoch: 6| Step: 12
Training loss: 1.142285943031311
Validation loss: 1.8855399188174997

Epoch: 6| Step: 13
Training loss: 1.1761736869812012
Validation loss: 1.9113918248043265

Epoch: 314| Step: 0
Training loss: 1.5225170850753784
Validation loss: 1.8423207959821146

Epoch: 6| Step: 1
Training loss: 1.4783470630645752
Validation loss: 1.9101588905498545

Epoch: 6| Step: 2
Training loss: 1.9883979558944702
Validation loss: 1.870402705284857

Epoch: 6| Step: 3
Training loss: 1.067962884902954
Validation loss: 1.9084217791916223

Epoch: 6| Step: 4
Training loss: 1.3168452978134155
Validation loss: 1.8618235895710606

Epoch: 6| Step: 5
Training loss: 1.8263548612594604
Validation loss: 1.8846957811745264

Epoch: 6| Step: 6
Training loss: 1.630340814590454
Validation loss: 1.922857217891242

Epoch: 6| Step: 7
Training loss: 1.3639552593231201
Validation loss: 1.861413077641559

Epoch: 6| Step: 8
Training loss: 1.7002019882202148
Validation loss: 1.9438223877260763

Epoch: 6| Step: 9
Training loss: 1.471561312675476
Validation loss: 1.9281065143564695

Epoch: 6| Step: 10
Training loss: 1.5610923767089844
Validation loss: 1.8761433298869798

Epoch: 6| Step: 11
Training loss: 1.5259895324707031
Validation loss: 1.843723056136921

Epoch: 6| Step: 12
Training loss: 1.3837566375732422
Validation loss: 1.8911794462511617

Epoch: 6| Step: 13
Training loss: 1.605088710784912
Validation loss: 1.8505092692631546

Epoch: 315| Step: 0
Training loss: 1.9425685405731201
Validation loss: 1.8943482727132819

Epoch: 6| Step: 1
Training loss: 2.142228841781616
Validation loss: 1.9160963835254792

Epoch: 6| Step: 2
Training loss: 1.5038561820983887
Validation loss: 1.9021747099455966

Epoch: 6| Step: 3
Training loss: 0.9929221272468567
Validation loss: 1.832230216713362

Epoch: 6| Step: 4
Training loss: 1.4836153984069824
Validation loss: 1.8753371636072795

Epoch: 6| Step: 5
Training loss: 2.2024383544921875
Validation loss: 1.9351916620808263

Epoch: 6| Step: 6
Training loss: 1.3368606567382812
Validation loss: 1.877713426466911

Epoch: 6| Step: 7
Training loss: 2.0643270015716553
Validation loss: 1.9242559466310727

Epoch: 6| Step: 8
Training loss: 0.9158459901809692
Validation loss: 1.9176074663798015

Epoch: 6| Step: 9
Training loss: 1.6825143098831177
Validation loss: 1.92930987317075

Epoch: 6| Step: 10
Training loss: 1.110224962234497
Validation loss: 1.9359773576900523

Epoch: 6| Step: 11
Training loss: 1.460127830505371
Validation loss: 1.962385812113362

Epoch: 6| Step: 12
Training loss: 0.8655588626861572
Validation loss: 1.8859612864832724

Epoch: 6| Step: 13
Training loss: 1.8389235734939575
Validation loss: 1.9095662614350677

Epoch: 316| Step: 0
Training loss: 1.1123331785202026
Validation loss: 1.9597800854713685

Epoch: 6| Step: 1
Training loss: 2.259213447570801
Validation loss: 1.9669639064419655

Epoch: 6| Step: 2
Training loss: 1.3961023092269897
Validation loss: 1.9617630409938034

Epoch: 6| Step: 3
Training loss: 1.9080066680908203
Validation loss: 1.9465505666630243

Epoch: 6| Step: 4
Training loss: 1.2491413354873657
Validation loss: 1.8883885670733709

Epoch: 6| Step: 5
Training loss: 1.127030849456787
Validation loss: 1.9253236324556413

Epoch: 6| Step: 6
Training loss: 1.320515751838684
Validation loss: 1.86022053610894

Epoch: 6| Step: 7
Training loss: 1.4973726272583008
Validation loss: 1.8712413336641045

Epoch: 6| Step: 8
Training loss: 1.3338396549224854
Validation loss: 1.9000849826361543

Epoch: 6| Step: 9
Training loss: 1.9925153255462646
Validation loss: 1.8674722243380804

Epoch: 6| Step: 10
Training loss: 1.681347370147705
Validation loss: 1.8754437828576693

Epoch: 6| Step: 11
Training loss: 1.4688818454742432
Validation loss: 1.8806780768978981

Epoch: 6| Step: 12
Training loss: 1.5170797109603882
Validation loss: 1.9045235469777098

Epoch: 6| Step: 13
Training loss: 1.728212833404541
Validation loss: 1.9060458342234294

Epoch: 317| Step: 0
Training loss: 1.4320518970489502
Validation loss: 1.8998929031433598

Epoch: 6| Step: 1
Training loss: 1.5957955121994019
Validation loss: 1.862028609039963

Epoch: 6| Step: 2
Training loss: 1.2379292249679565
Validation loss: 1.877110609444239

Epoch: 6| Step: 3
Training loss: 2.3782572746276855
Validation loss: 1.9044675250207224

Epoch: 6| Step: 4
Training loss: 1.0375797748565674
Validation loss: 1.9575664445918093

Epoch: 6| Step: 5
Training loss: 1.282711386680603
Validation loss: 1.9448542377000213

Epoch: 6| Step: 6
Training loss: 1.9865320920944214
Validation loss: 1.9349375501755746

Epoch: 6| Step: 7
Training loss: 0.9022186398506165
Validation loss: 1.9420393692549838

Epoch: 6| Step: 8
Training loss: 1.1667964458465576
Validation loss: 1.9084320555451095

Epoch: 6| Step: 9
Training loss: 2.1631767749786377
Validation loss: 1.9041600816993303

Epoch: 6| Step: 10
Training loss: 1.2022414207458496
Validation loss: 1.9462607983619935

Epoch: 6| Step: 11
Training loss: 1.3914313316345215
Validation loss: 1.9029448468198058

Epoch: 6| Step: 12
Training loss: 1.459517002105713
Validation loss: 1.8885206073843024

Epoch: 6| Step: 13
Training loss: 2.070512056350708
Validation loss: 1.8710001207167102

Epoch: 318| Step: 0
Training loss: 1.893273949623108
Validation loss: 1.9506898567240725

Epoch: 6| Step: 1
Training loss: 1.4384071826934814
Validation loss: 1.8756608193920505

Epoch: 6| Step: 2
Training loss: 1.86871337890625
Validation loss: 1.9266328709099882

Epoch: 6| Step: 3
Training loss: 1.1232247352600098
Validation loss: 1.8853215504718084

Epoch: 6| Step: 4
Training loss: 1.7056005001068115
Validation loss: 1.9481678342306485

Epoch: 6| Step: 5
Training loss: 1.6636302471160889
Validation loss: 1.8940977819504277

Epoch: 6| Step: 6
Training loss: 0.9086066484451294
Validation loss: 1.8662256207517398

Epoch: 6| Step: 7
Training loss: 2.07853364944458
Validation loss: 1.911240868670966

Epoch: 6| Step: 8
Training loss: 1.395613193511963
Validation loss: 1.8567709756153885

Epoch: 6| Step: 9
Training loss: 1.6355137825012207
Validation loss: 1.860839488685772

Epoch: 6| Step: 10
Training loss: 1.5735316276550293
Validation loss: 1.9639087082237325

Epoch: 6| Step: 11
Training loss: 1.5010020732879639
Validation loss: 1.8845287522962015

Epoch: 6| Step: 12
Training loss: 1.4308381080627441
Validation loss: 1.9356208103959278

Epoch: 6| Step: 13
Training loss: 0.8645904064178467
Validation loss: 1.9179244220897715

Epoch: 319| Step: 0
Training loss: 1.7835679054260254
Validation loss: 1.8951500513220345

Epoch: 6| Step: 1
Training loss: 1.2447388172149658
Validation loss: 1.863779866567222

Epoch: 6| Step: 2
Training loss: 1.412900447845459
Validation loss: 1.9051519850248932

Epoch: 6| Step: 3
Training loss: 1.4260931015014648
Validation loss: 1.9228999448078934

Epoch: 6| Step: 4
Training loss: 1.1295747756958008
Validation loss: 1.9230131000600836

Epoch: 6| Step: 5
Training loss: 0.6517755389213562
Validation loss: 1.922469751809233

Epoch: 6| Step: 6
Training loss: 1.1631841659545898
Validation loss: 1.9150488068980556

Epoch: 6| Step: 7
Training loss: 2.4116997718811035
Validation loss: 1.9457324140815324

Epoch: 6| Step: 8
Training loss: 1.19965660572052
Validation loss: 1.8968705772071757

Epoch: 6| Step: 9
Training loss: 1.9979710578918457
Validation loss: 1.9268701076507568

Epoch: 6| Step: 10
Training loss: 1.3095699548721313
Validation loss: 1.7672552318983181

Epoch: 6| Step: 11
Training loss: 2.072024345397949
Validation loss: 1.9137898004183205

Epoch: 6| Step: 12
Training loss: 1.685607671737671
Validation loss: 1.8342597894771124

Epoch: 6| Step: 13
Training loss: 1.3660475015640259
Validation loss: 1.8928496619706512

Epoch: 320| Step: 0
Training loss: 1.5941556692123413
Validation loss: 1.9429510139649915

Epoch: 6| Step: 1
Training loss: 1.4141911268234253
Validation loss: 1.8588976578045917

Epoch: 6| Step: 2
Training loss: 1.4069204330444336
Validation loss: 1.8462995739393337

Epoch: 6| Step: 3
Training loss: 1.8706626892089844
Validation loss: 1.932286221493957

Epoch: 6| Step: 4
Training loss: 1.9561384916305542
Validation loss: 1.8966654577562887

Epoch: 6| Step: 5
Training loss: 1.8035637140274048
Validation loss: 1.9555928553304365

Epoch: 6| Step: 6
Training loss: 1.646932601928711
Validation loss: 1.9485521342164727

Epoch: 6| Step: 7
Training loss: 1.0315558910369873
Validation loss: 1.9167723655700684

Epoch: 6| Step: 8
Training loss: 1.2706499099731445
Validation loss: 1.8786351270573114

Epoch: 6| Step: 9
Training loss: 0.9509942531585693
Validation loss: 2.0338412100268948

Epoch: 6| Step: 10
Training loss: 1.113616704940796
Validation loss: 1.9304181721902662

Epoch: 6| Step: 11
Training loss: 1.8159083127975464
Validation loss: 1.8267154283421014

Epoch: 6| Step: 12
Training loss: 1.598375678062439
Validation loss: 1.900344188495349

Epoch: 6| Step: 13
Training loss: 1.065733790397644
Validation loss: 1.9248329477925454

Epoch: 321| Step: 0
Training loss: 1.0832171440124512
Validation loss: 1.8912543455759685

Epoch: 6| Step: 1
Training loss: 0.7435331344604492
Validation loss: 1.8842450572598366

Epoch: 6| Step: 2
Training loss: 2.2079052925109863
Validation loss: 1.8390008736682195

Epoch: 6| Step: 3
Training loss: 1.4182119369506836
Validation loss: 1.9079745020917667

Epoch: 6| Step: 4
Training loss: 1.3486956357955933
Validation loss: 1.849484743610505

Epoch: 6| Step: 5
Training loss: 1.5590604543685913
Validation loss: 1.846879074650426

Epoch: 6| Step: 6
Training loss: 1.6189923286437988
Validation loss: 1.9039322881288425

Epoch: 6| Step: 7
Training loss: 2.0967726707458496
Validation loss: 1.904452496959317

Epoch: 6| Step: 8
Training loss: 1.1651334762573242
Validation loss: 1.9156993845457673

Epoch: 6| Step: 9
Training loss: 1.9461307525634766
Validation loss: 1.8983040522503596

Epoch: 6| Step: 10
Training loss: 1.769468069076538
Validation loss: 1.8581109559664162

Epoch: 6| Step: 11
Training loss: 1.572267770767212
Validation loss: 1.886051054923765

Epoch: 6| Step: 12
Training loss: 1.6355174779891968
Validation loss: 1.8452960880853797

Epoch: 6| Step: 13
Training loss: 0.7169661521911621
Validation loss: 1.9409859821360598

Epoch: 322| Step: 0
Training loss: 1.5182855129241943
Validation loss: 1.8542942680338377

Epoch: 6| Step: 1
Training loss: 1.4179182052612305
Validation loss: 1.8839313817280594

Epoch: 6| Step: 2
Training loss: 1.3320801258087158
Validation loss: 1.8242387438333163

Epoch: 6| Step: 3
Training loss: 1.6084240674972534
Validation loss: 1.8815060905230943

Epoch: 6| Step: 4
Training loss: 0.9506357312202454
Validation loss: 1.8582041596853605

Epoch: 6| Step: 5
Training loss: 1.3803249597549438
Validation loss: 1.928322986889911

Epoch: 6| Step: 6
Training loss: 1.3950763940811157
Validation loss: 1.9245408760604037

Epoch: 6| Step: 7
Training loss: 2.0135393142700195
Validation loss: 1.923470236921823

Epoch: 6| Step: 8
Training loss: 2.024590015411377
Validation loss: 1.8657969326101325

Epoch: 6| Step: 9
Training loss: 1.2036609649658203
Validation loss: 1.8995313477772537

Epoch: 6| Step: 10
Training loss: 1.2399723529815674
Validation loss: 1.931145309120096

Epoch: 6| Step: 11
Training loss: 1.7038426399230957
Validation loss: 1.8556764330915225

Epoch: 6| Step: 12
Training loss: 1.5312066078186035
Validation loss: 1.9133158473558323

Epoch: 6| Step: 13
Training loss: 2.2802484035491943
Validation loss: 1.925957856639739

Epoch: 323| Step: 0
Training loss: 1.8152371644973755
Validation loss: 1.923450252061249

Epoch: 6| Step: 1
Training loss: 1.6650112867355347
Validation loss: 1.907452202612354

Epoch: 6| Step: 2
Training loss: 0.7461096048355103
Validation loss: 1.914162225620721

Epoch: 6| Step: 3
Training loss: 1.5160646438598633
Validation loss: 1.8959825859274915

Epoch: 6| Step: 4
Training loss: 0.8806312084197998
Validation loss: 1.9359529890039915

Epoch: 6| Step: 5
Training loss: 1.503021478652954
Validation loss: 1.975520477500013

Epoch: 6| Step: 6
Training loss: 1.8519434928894043
Validation loss: 1.8859129823664182

Epoch: 6| Step: 7
Training loss: 1.3824788331985474
Validation loss: 1.9015277290856967

Epoch: 6| Step: 8
Training loss: 1.083612322807312
Validation loss: 1.9012829693414832

Epoch: 6| Step: 9
Training loss: 1.4671387672424316
Validation loss: 1.8985446127512122

Epoch: 6| Step: 10
Training loss: 1.8778164386749268
Validation loss: 1.8797899317997757

Epoch: 6| Step: 11
Training loss: 1.3463377952575684
Validation loss: 1.8330512867178967

Epoch: 6| Step: 12
Training loss: 2.539721727371216
Validation loss: 1.8709004655961068

Epoch: 6| Step: 13
Training loss: 1.5875210762023926
Validation loss: 1.7983601503474738

Epoch: 324| Step: 0
Training loss: 0.7365731000900269
Validation loss: 1.8433447730156682

Epoch: 6| Step: 1
Training loss: 0.9238406419754028
Validation loss: 1.8968031880676106

Epoch: 6| Step: 2
Training loss: 1.834180235862732
Validation loss: 1.867874007071218

Epoch: 6| Step: 3
Training loss: 1.4012246131896973
Validation loss: 1.8711293846048334

Epoch: 6| Step: 4
Training loss: 1.7917399406433105
Validation loss: 1.8592340882106493

Epoch: 6| Step: 5
Training loss: 1.2121272087097168
Validation loss: 1.8423207844457319

Epoch: 6| Step: 6
Training loss: 1.407132625579834
Validation loss: 1.882008949915568

Epoch: 6| Step: 7
Training loss: 1.6712732315063477
Validation loss: 1.8483869798721806

Epoch: 6| Step: 8
Training loss: 1.9406347274780273
Validation loss: 1.8828252387303177

Epoch: 6| Step: 9
Training loss: 1.3497796058654785
Validation loss: 1.8410783929209555

Epoch: 6| Step: 10
Training loss: 2.4561033248901367
Validation loss: 1.8934960698568692

Epoch: 6| Step: 11
Training loss: 1.589316725730896
Validation loss: 1.8952296113455167

Epoch: 6| Step: 12
Training loss: 1.0703425407409668
Validation loss: 1.849554923272902

Epoch: 6| Step: 13
Training loss: 1.1818040609359741
Validation loss: 1.9807671552063317

Epoch: 325| Step: 0
Training loss: 1.6282508373260498
Validation loss: 1.9970334601658646

Epoch: 6| Step: 1
Training loss: 1.5314966440200806
Validation loss: 1.9510489202314807

Epoch: 6| Step: 2
Training loss: 1.622868537902832
Validation loss: 1.960340040986256

Epoch: 6| Step: 3
Training loss: 1.9362789392471313
Validation loss: 2.0067476816074823

Epoch: 6| Step: 4
Training loss: 1.2425155639648438
Validation loss: 1.885494824378721

Epoch: 6| Step: 5
Training loss: 0.6019402742385864
Validation loss: 1.9106239593157204

Epoch: 6| Step: 6
Training loss: 1.6571376323699951
Validation loss: 1.9652854960451844

Epoch: 6| Step: 7
Training loss: 1.7994471788406372
Validation loss: 1.882578621628464

Epoch: 6| Step: 8
Training loss: 1.2091705799102783
Validation loss: 1.8810683014572307

Epoch: 6| Step: 9
Training loss: 1.4436030387878418
Validation loss: 1.8702620178140619

Epoch: 6| Step: 10
Training loss: 1.3888230323791504
Validation loss: 1.8724123406153854

Epoch: 6| Step: 11
Training loss: 1.39644455909729
Validation loss: 1.8344371882818078

Epoch: 6| Step: 12
Training loss: 2.003406047821045
Validation loss: 1.895765350710961

Epoch: 6| Step: 13
Training loss: 1.8812198638916016
Validation loss: 1.7977967948041937

Epoch: 326| Step: 0
Training loss: 1.7955684661865234
Validation loss: 1.8912865525932723

Epoch: 6| Step: 1
Training loss: 1.150833010673523
Validation loss: 1.8264979982888827

Epoch: 6| Step: 2
Training loss: 1.3106660842895508
Validation loss: 1.8845700012740267

Epoch: 6| Step: 3
Training loss: 1.7253118753433228
Validation loss: 1.8723538473088255

Epoch: 6| Step: 4
Training loss: 1.4218645095825195
Validation loss: 1.8964903790463683

Epoch: 6| Step: 5
Training loss: 1.3625900745391846
Validation loss: 1.8612371260120022

Epoch: 6| Step: 6
Training loss: 1.195631980895996
Validation loss: 1.9012340704600017

Epoch: 6| Step: 7
Training loss: 1.4649899005889893
Validation loss: 1.8974796995039909

Epoch: 6| Step: 8
Training loss: 1.175439476966858
Validation loss: 1.9566484805076354

Epoch: 6| Step: 9
Training loss: 1.9310517311096191
Validation loss: 1.8919557525265602

Epoch: 6| Step: 10
Training loss: 1.5404852628707886
Validation loss: 1.910098063048496

Epoch: 6| Step: 11
Training loss: 1.8587530851364136
Validation loss: 1.9747769627519833

Epoch: 6| Step: 12
Training loss: 1.5628541707992554
Validation loss: 1.9139013572405743

Epoch: 6| Step: 13
Training loss: 1.778271198272705
Validation loss: 1.9231334245333107

Epoch: 327| Step: 0
Training loss: 1.089294672012329
Validation loss: 2.001677856650404

Epoch: 6| Step: 1
Training loss: 1.1626585721969604
Validation loss: 1.875024172567552

Epoch: 6| Step: 2
Training loss: 1.651033878326416
Validation loss: 1.9367198457000077

Epoch: 6| Step: 3
Training loss: 1.2769739627838135
Validation loss: 1.9434101812301143

Epoch: 6| Step: 4
Training loss: 1.6148605346679688
Validation loss: 1.924919327100118

Epoch: 6| Step: 5
Training loss: 1.7503662109375
Validation loss: 1.9665161742958972

Epoch: 6| Step: 6
Training loss: 1.1693825721740723
Validation loss: 1.964933572276946

Epoch: 6| Step: 7
Training loss: 2.712993621826172
Validation loss: 1.9176378634668165

Epoch: 6| Step: 8
Training loss: 1.1316227912902832
Validation loss: 1.932757484015598

Epoch: 6| Step: 9
Training loss: 1.7509269714355469
Validation loss: 1.9045954622248167

Epoch: 6| Step: 10
Training loss: 1.3680384159088135
Validation loss: 1.892236182766576

Epoch: 6| Step: 11
Training loss: 2.3155393600463867
Validation loss: 1.8809135985630814

Epoch: 6| Step: 12
Training loss: 1.4683244228363037
Validation loss: 1.8649741770118795

Epoch: 6| Step: 13
Training loss: 1.3045188188552856
Validation loss: 1.8261681269573908

Epoch: 328| Step: 0
Training loss: 1.9426051378250122
Validation loss: 1.8701519145760486

Epoch: 6| Step: 1
Training loss: 1.1007949113845825
Validation loss: 1.8818317754294283

Epoch: 6| Step: 2
Training loss: 1.1150838136672974
Validation loss: 1.916654025354693

Epoch: 6| Step: 3
Training loss: 1.0396919250488281
Validation loss: 1.9235355982216455

Epoch: 6| Step: 4
Training loss: 1.996687889099121
Validation loss: 1.8786447394278742

Epoch: 6| Step: 5
Training loss: 1.1040539741516113
Validation loss: 1.8986472327222106

Epoch: 6| Step: 6
Training loss: 2.0932624340057373
Validation loss: 1.894224041251726

Epoch: 6| Step: 7
Training loss: 1.1115689277648926
Validation loss: 1.8675506102141513

Epoch: 6| Step: 8
Training loss: 1.844623327255249
Validation loss: 1.8997132778167725

Epoch: 6| Step: 9
Training loss: 1.6887118816375732
Validation loss: 1.9116747379302979

Epoch: 6| Step: 10
Training loss: 1.2337756156921387
Validation loss: 1.8549854678492392

Epoch: 6| Step: 11
Training loss: 1.2123230695724487
Validation loss: 1.8616994119459582

Epoch: 6| Step: 12
Training loss: 1.7709603309631348
Validation loss: 1.9066091147802209

Epoch: 6| Step: 13
Training loss: 1.3940796852111816
Validation loss: 1.9123168081365607

Epoch: 329| Step: 0
Training loss: 1.8486484289169312
Validation loss: 1.946333808283652

Epoch: 6| Step: 1
Training loss: 2.1959304809570312
Validation loss: 1.9017175295019662

Epoch: 6| Step: 2
Training loss: 1.2266956567764282
Validation loss: 1.927113627874723

Epoch: 6| Step: 3
Training loss: 1.587292194366455
Validation loss: 1.9246838220985987

Epoch: 6| Step: 4
Training loss: 1.840691328048706
Validation loss: 1.8523976546461864

Epoch: 6| Step: 5
Training loss: 1.5670840740203857
Validation loss: 1.8919489396515714

Epoch: 6| Step: 6
Training loss: 1.7894686460494995
Validation loss: 1.8531413027035293

Epoch: 6| Step: 7
Training loss: 1.6721810102462769
Validation loss: 1.912292903469455

Epoch: 6| Step: 8
Training loss: 1.3732101917266846
Validation loss: 1.9163457257773286

Epoch: 6| Step: 9
Training loss: 1.346362829208374
Validation loss: 1.8762909776421004

Epoch: 6| Step: 10
Training loss: 1.276127576828003
Validation loss: 1.8844284139653689

Epoch: 6| Step: 11
Training loss: 1.0232958793640137
Validation loss: 1.905132847447549

Epoch: 6| Step: 12
Training loss: 1.25148344039917
Validation loss: 1.875223610990791

Epoch: 6| Step: 13
Training loss: 1.3245841264724731
Validation loss: 1.8489381792724773

Epoch: 330| Step: 0
Training loss: 1.6779470443725586
Validation loss: 1.8987433192550496

Epoch: 6| Step: 1
Training loss: 2.20485258102417
Validation loss: 1.833116719799657

Epoch: 6| Step: 2
Training loss: 2.084299087524414
Validation loss: 1.8637155243145522

Epoch: 6| Step: 3
Training loss: 0.9908358454704285
Validation loss: 1.92403842044133

Epoch: 6| Step: 4
Training loss: 1.0781458616256714
Validation loss: 1.8648266100114392

Epoch: 6| Step: 5
Training loss: 1.0325523614883423
Validation loss: 1.8636671086793304

Epoch: 6| Step: 6
Training loss: 2.1084322929382324
Validation loss: 1.9354369204531434

Epoch: 6| Step: 7
Training loss: 1.5924923419952393
Validation loss: 1.8867834306532336

Epoch: 6| Step: 8
Training loss: 1.3693381547927856
Validation loss: 1.9370470867362073

Epoch: 6| Step: 9
Training loss: 1.118143081665039
Validation loss: 1.8628070815916984

Epoch: 6| Step: 10
Training loss: 1.0426661968231201
Validation loss: 1.8267350799293929

Epoch: 6| Step: 11
Training loss: 1.6836581230163574
Validation loss: 1.914529896551563

Epoch: 6| Step: 12
Training loss: 1.4256248474121094
Validation loss: 1.8722351046018704

Epoch: 6| Step: 13
Training loss: 1.20338773727417
Validation loss: 1.9127921250558668

Epoch: 331| Step: 0
Training loss: 1.483655333518982
Validation loss: 1.9010673056366623

Epoch: 6| Step: 1
Training loss: 1.1849536895751953
Validation loss: 1.8752285793263426

Epoch: 6| Step: 2
Training loss: 1.2921233177185059
Validation loss: 1.8789922037432272

Epoch: 6| Step: 3
Training loss: 1.683132290840149
Validation loss: 1.843663986011218

Epoch: 6| Step: 4
Training loss: 1.2324745655059814
Validation loss: 1.9261562516612392

Epoch: 6| Step: 5
Training loss: 1.821030855178833
Validation loss: 1.799532877501621

Epoch: 6| Step: 6
Training loss: 1.3640763759613037
Validation loss: 1.8799410443152151

Epoch: 6| Step: 7
Training loss: 1.4539753198623657
Validation loss: 1.8604473298595798

Epoch: 6| Step: 8
Training loss: 0.9419184923171997
Validation loss: 1.8976057178230696

Epoch: 6| Step: 9
Training loss: 1.7857822179794312
Validation loss: 1.8694240841814267

Epoch: 6| Step: 10
Training loss: 1.5638554096221924
Validation loss: 1.920839625020181

Epoch: 6| Step: 11
Training loss: 1.8266379833221436
Validation loss: 1.8417354552976546

Epoch: 6| Step: 12
Training loss: 1.6551189422607422
Validation loss: 1.874600500188848

Epoch: 6| Step: 13
Training loss: 1.340139627456665
Validation loss: 1.8789698026513542

Epoch: 332| Step: 0
Training loss: 2.0638856887817383
Validation loss: 1.897123021464194

Epoch: 6| Step: 1
Training loss: 1.644106388092041
Validation loss: 1.8612439350415302

Epoch: 6| Step: 2
Training loss: 1.6086536645889282
Validation loss: 1.8091391107087493

Epoch: 6| Step: 3
Training loss: 2.114699602127075
Validation loss: 1.8832185114583662

Epoch: 6| Step: 4
Training loss: 1.069860577583313
Validation loss: 1.922115691246525

Epoch: 6| Step: 5
Training loss: 0.7537599802017212
Validation loss: 1.8607026441122896

Epoch: 6| Step: 6
Training loss: 1.1872193813323975
Validation loss: 1.896431928039879

Epoch: 6| Step: 7
Training loss: 1.6466699838638306
Validation loss: 1.9704614582882132

Epoch: 6| Step: 8
Training loss: 1.1717286109924316
Validation loss: 1.8923851443875221

Epoch: 6| Step: 9
Training loss: 1.1574920415878296
Validation loss: 1.9555587153280936

Epoch: 6| Step: 10
Training loss: 1.7616844177246094
Validation loss: 1.932143767674764

Epoch: 6| Step: 11
Training loss: 1.3926560878753662
Validation loss: 1.8521240001083703

Epoch: 6| Step: 12
Training loss: 1.6263775825500488
Validation loss: 1.9470903770897978

Epoch: 6| Step: 13
Training loss: 1.8012150526046753
Validation loss: 1.8751239392065233

Epoch: 333| Step: 0
Training loss: 1.4157276153564453
Validation loss: 1.9206285297229726

Epoch: 6| Step: 1
Training loss: 1.4104628562927246
Validation loss: 1.8699543437650126

Epoch: 6| Step: 2
Training loss: 0.9184458255767822
Validation loss: 1.7940574807505454

Epoch: 6| Step: 3
Training loss: 1.284499168395996
Validation loss: 1.803900650752488

Epoch: 6| Step: 4
Training loss: 1.530137538909912
Validation loss: 1.8359369411263415

Epoch: 6| Step: 5
Training loss: 1.189619779586792
Validation loss: 1.829643605857767

Epoch: 6| Step: 6
Training loss: 2.0765457153320312
Validation loss: 1.9094043342016076

Epoch: 6| Step: 7
Training loss: 1.6724152565002441
Validation loss: 1.8287740112632833

Epoch: 6| Step: 8
Training loss: 1.6468281745910645
Validation loss: 1.850491004605447

Epoch: 6| Step: 9
Training loss: 1.4956707954406738
Validation loss: 1.8215983862517982

Epoch: 6| Step: 10
Training loss: 1.9853535890579224
Validation loss: 1.8432329598293509

Epoch: 6| Step: 11
Training loss: 1.387593150138855
Validation loss: 1.8727637234554495

Epoch: 6| Step: 12
Training loss: 1.4818367958068848
Validation loss: 1.8719827231540476

Epoch: 6| Step: 13
Training loss: 1.7629246711730957
Validation loss: 1.8127857062124437

Epoch: 334| Step: 0
Training loss: 1.4444854259490967
Validation loss: 1.9294131173882434

Epoch: 6| Step: 1
Training loss: 1.2937260866165161
Validation loss: 1.884825938491411

Epoch: 6| Step: 2
Training loss: 1.6962045431137085
Validation loss: 1.828702744617257

Epoch: 6| Step: 3
Training loss: 1.586197853088379
Validation loss: 1.8277142355518956

Epoch: 6| Step: 4
Training loss: 1.7410920858383179
Validation loss: 1.9153530713050597

Epoch: 6| Step: 5
Training loss: 1.1995357275009155
Validation loss: 1.8765629312043548

Epoch: 6| Step: 6
Training loss: 1.3560502529144287
Validation loss: 1.9097612775782102

Epoch: 6| Step: 7
Training loss: 1.4444690942764282
Validation loss: 1.9064313698840398

Epoch: 6| Step: 8
Training loss: 1.9601173400878906
Validation loss: 1.8768995218379523

Epoch: 6| Step: 9
Training loss: 2.0284106731414795
Validation loss: 1.8875915491452782

Epoch: 6| Step: 10
Training loss: 0.9070114493370056
Validation loss: 1.9099202899522678

Epoch: 6| Step: 11
Training loss: 1.1846504211425781
Validation loss: 1.906552485240403

Epoch: 6| Step: 12
Training loss: 1.8303191661834717
Validation loss: 1.8827044912563857

Epoch: 6| Step: 13
Training loss: 1.1086900234222412
Validation loss: 1.916099100984553

Epoch: 335| Step: 0
Training loss: 1.7491110563278198
Validation loss: 1.8984421337804487

Epoch: 6| Step: 1
Training loss: 1.6254332065582275
Validation loss: 1.8797954026088919

Epoch: 6| Step: 2
Training loss: 1.4035680294036865
Validation loss: 1.9512413060793312

Epoch: 6| Step: 3
Training loss: 1.082228422164917
Validation loss: 1.8831341497359737

Epoch: 6| Step: 4
Training loss: 1.4456732273101807
Validation loss: 1.8822503602632912

Epoch: 6| Step: 5
Training loss: 1.3757376670837402
Validation loss: 1.8623830515851256

Epoch: 6| Step: 6
Training loss: 1.3546067476272583
Validation loss: 1.8351628934183428

Epoch: 6| Step: 7
Training loss: 1.9363330602645874
Validation loss: 1.916415940048874

Epoch: 6| Step: 8
Training loss: 0.9082236289978027
Validation loss: 1.8092754771632533

Epoch: 6| Step: 9
Training loss: 1.100843906402588
Validation loss: 1.8841239303670905

Epoch: 6| Step: 10
Training loss: 1.6930663585662842
Validation loss: 1.913532756990002

Epoch: 6| Step: 11
Training loss: 1.7396645545959473
Validation loss: 1.8833485713569067

Epoch: 6| Step: 12
Training loss: 1.5674669742584229
Validation loss: 1.7961472336963942

Epoch: 6| Step: 13
Training loss: 1.1427689790725708
Validation loss: 1.8635707747551702

Epoch: 336| Step: 0
Training loss: 1.6528650522232056
Validation loss: 1.8505793284344416

Epoch: 6| Step: 1
Training loss: 1.891221523284912
Validation loss: 1.8461553665899462

Epoch: 6| Step: 2
Training loss: 1.4648114442825317
Validation loss: 1.8636962457369732

Epoch: 6| Step: 3
Training loss: 1.1485532522201538
Validation loss: 1.8294476180948236

Epoch: 6| Step: 4
Training loss: 1.1769402027130127
Validation loss: 1.8395820112638577

Epoch: 6| Step: 5
Training loss: 0.9261124134063721
Validation loss: 1.95503830909729

Epoch: 6| Step: 6
Training loss: 1.46250581741333
Validation loss: 1.856531516198189

Epoch: 6| Step: 7
Training loss: 1.375167727470398
Validation loss: 1.8106584882223478

Epoch: 6| Step: 8
Training loss: 0.9504765272140503
Validation loss: 1.8281428083296745

Epoch: 6| Step: 9
Training loss: 1.8849701881408691
Validation loss: 1.8872708607745428

Epoch: 6| Step: 10
Training loss: 1.2920897006988525
Validation loss: 1.8714489052372594

Epoch: 6| Step: 11
Training loss: 1.7692265510559082
Validation loss: 1.8894943780796503

Epoch: 6| Step: 12
Training loss: 1.6339607238769531
Validation loss: 1.91100223090059

Epoch: 6| Step: 13
Training loss: 1.7721750736236572
Validation loss: 1.980955986566441

Epoch: 337| Step: 0
Training loss: 1.0473488569259644
Validation loss: 1.9525456274709394

Epoch: 6| Step: 1
Training loss: 1.4465022087097168
Validation loss: 1.8893533240082443

Epoch: 6| Step: 2
Training loss: 2.2111525535583496
Validation loss: 1.9016218800698557

Epoch: 6| Step: 3
Training loss: 1.5765552520751953
Validation loss: 1.961339609597319

Epoch: 6| Step: 4
Training loss: 0.858105480670929
Validation loss: 1.906782442523587

Epoch: 6| Step: 5
Training loss: 1.299403429031372
Validation loss: 1.9109587733463576

Epoch: 6| Step: 6
Training loss: 1.290075421333313
Validation loss: 1.9274725683273808

Epoch: 6| Step: 7
Training loss: 1.6394076347351074
Validation loss: 1.9258922402576735

Epoch: 6| Step: 8
Training loss: 1.247728705406189
Validation loss: 1.9202272917634697

Epoch: 6| Step: 9
Training loss: 2.6388168334960938
Validation loss: 1.8458004971986175

Epoch: 6| Step: 10
Training loss: 1.3178316354751587
Validation loss: 1.8511900555702947

Epoch: 6| Step: 11
Training loss: 1.4130654335021973
Validation loss: 1.8219532530794862

Epoch: 6| Step: 12
Training loss: 1.5946093797683716
Validation loss: 1.8461953222110707

Epoch: 6| Step: 13
Training loss: 2.0534470081329346
Validation loss: 1.850078434072515

Epoch: 338| Step: 0
Training loss: 1.0765541791915894
Validation loss: 1.8966341941587386

Epoch: 6| Step: 1
Training loss: 1.7567998170852661
Validation loss: 1.8561852644848567

Epoch: 6| Step: 2
Training loss: 1.0652978420257568
Validation loss: 1.8326981682931223

Epoch: 6| Step: 3
Training loss: 1.2368388175964355
Validation loss: 1.852562427520752

Epoch: 6| Step: 4
Training loss: 1.7324378490447998
Validation loss: 1.9121693475272066

Epoch: 6| Step: 5
Training loss: 1.3714052438735962
Validation loss: 1.8283376744998399

Epoch: 6| Step: 6
Training loss: 1.6769092082977295
Validation loss: 1.807021535852904

Epoch: 6| Step: 7
Training loss: 2.076625347137451
Validation loss: 1.7983656275656916

Epoch: 6| Step: 8
Training loss: 1.1609539985656738
Validation loss: 1.8610417765955771

Epoch: 6| Step: 9
Training loss: 1.4386624097824097
Validation loss: 1.8837698903135074

Epoch: 6| Step: 10
Training loss: 1.8574316501617432
Validation loss: 1.8648973049656037

Epoch: 6| Step: 11
Training loss: 1.539396047592163
Validation loss: 1.9305342448654996

Epoch: 6| Step: 12
Training loss: 1.603089690208435
Validation loss: 1.9501308933381112

Epoch: 6| Step: 13
Training loss: 1.698972463607788
Validation loss: 1.8726078515411706

Epoch: 339| Step: 0
Training loss: 1.0775105953216553
Validation loss: 1.8925365606943767

Epoch: 6| Step: 1
Training loss: 1.5639474391937256
Validation loss: 1.941501002157888

Epoch: 6| Step: 2
Training loss: 1.2240774631500244
Validation loss: 1.911939162080006

Epoch: 6| Step: 3
Training loss: 1.0823068618774414
Validation loss: 1.8822136989203833

Epoch: 6| Step: 4
Training loss: 1.207910180091858
Validation loss: 1.9399911767692977

Epoch: 6| Step: 5
Training loss: 1.9506633281707764
Validation loss: 1.892358208215365

Epoch: 6| Step: 6
Training loss: 1.018931269645691
Validation loss: 1.9515878564567977

Epoch: 6| Step: 7
Training loss: 1.4552578926086426
Validation loss: 1.8778050894378333

Epoch: 6| Step: 8
Training loss: 1.943909764289856
Validation loss: 1.9222428465402255

Epoch: 6| Step: 9
Training loss: 1.3469674587249756
Validation loss: 1.8739939556326917

Epoch: 6| Step: 10
Training loss: 1.5620543956756592
Validation loss: 1.9168037265859625

Epoch: 6| Step: 11
Training loss: 1.757896065711975
Validation loss: 1.8928936143075266

Epoch: 6| Step: 12
Training loss: 1.6835768222808838
Validation loss: 1.7755442755196684

Epoch: 6| Step: 13
Training loss: 1.7676780223846436
Validation loss: 1.8347039299626504

Epoch: 340| Step: 0
Training loss: 1.2598820924758911
Validation loss: 1.8835817229363225

Epoch: 6| Step: 1
Training loss: 1.5155278444290161
Validation loss: 1.8697860061481435

Epoch: 6| Step: 2
Training loss: 1.467594861984253
Validation loss: 1.876330029579901

Epoch: 6| Step: 3
Training loss: 1.0784509181976318
Validation loss: 1.8161219601990075

Epoch: 6| Step: 4
Training loss: 2.3892769813537598
Validation loss: 1.880701252209243

Epoch: 6| Step: 5
Training loss: 1.7111315727233887
Validation loss: 1.8125279795738958

Epoch: 6| Step: 6
Training loss: 1.4551753997802734
Validation loss: 1.854816186812616

Epoch: 6| Step: 7
Training loss: 1.1732392311096191
Validation loss: 1.8972460787783387

Epoch: 6| Step: 8
Training loss: 1.5095796585083008
Validation loss: 1.8473640987949986

Epoch: 6| Step: 9
Training loss: 1.836652159690857
Validation loss: 1.819533569838411

Epoch: 6| Step: 10
Training loss: 0.653073787689209
Validation loss: 1.8586144472963066

Epoch: 6| Step: 11
Training loss: 0.7696470618247986
Validation loss: 1.8514814287103631

Epoch: 6| Step: 12
Training loss: 1.9301769733428955
Validation loss: 1.871008998604231

Epoch: 6| Step: 13
Training loss: 2.314467668533325
Validation loss: 1.8446080556479834

Epoch: 341| Step: 0
Training loss: 0.8847838640213013
Validation loss: 1.9364689921820035

Epoch: 6| Step: 1
Training loss: 1.205511450767517
Validation loss: 1.917911575686547

Epoch: 6| Step: 2
Training loss: 1.4725538492202759
Validation loss: 1.9159858816413469

Epoch: 6| Step: 3
Training loss: 1.2764636278152466
Validation loss: 1.9082758529211885

Epoch: 6| Step: 4
Training loss: 1.7126317024230957
Validation loss: 1.9448058041193153

Epoch: 6| Step: 5
Training loss: 1.4705604314804077
Validation loss: 1.8434132401661207

Epoch: 6| Step: 6
Training loss: 1.2132868766784668
Validation loss: 1.9787892936378397

Epoch: 6| Step: 7
Training loss: 1.9152122735977173
Validation loss: 1.948153341970136

Epoch: 6| Step: 8
Training loss: 0.7722243666648865
Validation loss: 1.9669190952854771

Epoch: 6| Step: 9
Training loss: 1.9385359287261963
Validation loss: 1.9599164890986618

Epoch: 6| Step: 10
Training loss: 2.966507911682129
Validation loss: 1.8951466737254974

Epoch: 6| Step: 11
Training loss: 1.3158206939697266
Validation loss: 1.8921911408824306

Epoch: 6| Step: 12
Training loss: 1.1077680587768555
Validation loss: 1.879920647990319

Epoch: 6| Step: 13
Training loss: 1.1166424751281738
Validation loss: 1.8983286798641246

Epoch: 342| Step: 0
Training loss: 0.9951443672180176
Validation loss: 1.8835841225039573

Epoch: 6| Step: 1
Training loss: 1.082541584968567
Validation loss: 1.9034537294859528

Epoch: 6| Step: 2
Training loss: 1.2940037250518799
Validation loss: 1.9137486847498084

Epoch: 6| Step: 3
Training loss: 1.9703624248504639
Validation loss: 1.8668837790848107

Epoch: 6| Step: 4
Training loss: 1.2973747253417969
Validation loss: 1.8858587370123914

Epoch: 6| Step: 5
Training loss: 2.2508959770202637
Validation loss: 1.8444006660933137

Epoch: 6| Step: 6
Training loss: 1.7375717163085938
Validation loss: 1.86519334905891

Epoch: 6| Step: 7
Training loss: 1.6979798078536987
Validation loss: 1.8303860387494486

Epoch: 6| Step: 8
Training loss: 1.554295539855957
Validation loss: 1.8286787463772682

Epoch: 6| Step: 9
Training loss: 1.0757778882980347
Validation loss: 1.8797377091582104

Epoch: 6| Step: 10
Training loss: 2.002171039581299
Validation loss: 1.9236915496087843

Epoch: 6| Step: 11
Training loss: 1.0011502504348755
Validation loss: 1.9180770638168498

Epoch: 6| Step: 12
Training loss: 1.5299121141433716
Validation loss: 1.8887463923423522

Epoch: 6| Step: 13
Training loss: 1.1174719333648682
Validation loss: 1.9134905863833684

Epoch: 343| Step: 0
Training loss: 2.0550265312194824
Validation loss: 1.9111858234610608

Epoch: 6| Step: 1
Training loss: 1.28975510597229
Validation loss: 1.9110073428000174

Epoch: 6| Step: 2
Training loss: 1.6461234092712402
Validation loss: 1.8717484563909552

Epoch: 6| Step: 3
Training loss: 1.0588562488555908
Validation loss: 1.8755737171378186

Epoch: 6| Step: 4
Training loss: 1.4712097644805908
Validation loss: 1.8845346038059523

Epoch: 6| Step: 5
Training loss: 2.1715164184570312
Validation loss: 1.9168056749528455

Epoch: 6| Step: 6
Training loss: 0.9307451844215393
Validation loss: 1.8666567597337949

Epoch: 6| Step: 7
Training loss: 1.257277011871338
Validation loss: 1.8899643267354658

Epoch: 6| Step: 8
Training loss: 1.7506787776947021
Validation loss: 1.873751430101292

Epoch: 6| Step: 9
Training loss: 1.401587963104248
Validation loss: 1.9383297094734766

Epoch: 6| Step: 10
Training loss: 1.5516159534454346
Validation loss: 1.8866310388811174

Epoch: 6| Step: 11
Training loss: 0.910698652267456
Validation loss: 1.8215940139626945

Epoch: 6| Step: 12
Training loss: 1.71042799949646
Validation loss: 1.8103716226034268

Epoch: 6| Step: 13
Training loss: 1.0460189580917358
Validation loss: 1.8244854916808426

Epoch: 344| Step: 0
Training loss: 0.9998929500579834
Validation loss: 1.9499590678881573

Epoch: 6| Step: 1
Training loss: 1.521752953529358
Validation loss: 1.9135336183732556

Epoch: 6| Step: 2
Training loss: 0.8919310569763184
Validation loss: 1.9190014690481207

Epoch: 6| Step: 3
Training loss: 1.634721279144287
Validation loss: 1.932029269074881

Epoch: 6| Step: 4
Training loss: 2.1306493282318115
Validation loss: 1.8458814287698397

Epoch: 6| Step: 5
Training loss: 1.2343494892120361
Validation loss: 1.851654621862596

Epoch: 6| Step: 6
Training loss: 1.5114428997039795
Validation loss: 1.8678833797413816

Epoch: 6| Step: 7
Training loss: 1.5772175788879395
Validation loss: 1.9379808697649228

Epoch: 6| Step: 8
Training loss: 1.332766056060791
Validation loss: 1.9597776013035928

Epoch: 6| Step: 9
Training loss: 1.8606146574020386
Validation loss: 1.95971816842274

Epoch: 6| Step: 10
Training loss: 1.0298560857772827
Validation loss: 1.9090541870363298

Epoch: 6| Step: 11
Training loss: 1.5111072063446045
Validation loss: 1.9430671456039592

Epoch: 6| Step: 12
Training loss: 2.1343994140625
Validation loss: 1.910721673760363

Epoch: 6| Step: 13
Training loss: 1.2051317691802979
Validation loss: 1.8624601466681368

Epoch: 345| Step: 0
Training loss: 2.200376510620117
Validation loss: 1.883974080444664

Epoch: 6| Step: 1
Training loss: 1.1500353813171387
Validation loss: 1.8905983778738207

Epoch: 6| Step: 2
Training loss: 1.3194401264190674
Validation loss: 1.8582398647903113

Epoch: 6| Step: 3
Training loss: 1.2209889888763428
Validation loss: 1.8731843143381097

Epoch: 6| Step: 4
Training loss: 1.4982619285583496
Validation loss: 1.8246274532810334

Epoch: 6| Step: 5
Training loss: 1.031335711479187
Validation loss: 1.8944887781655917

Epoch: 6| Step: 6
Training loss: 1.4845194816589355
Validation loss: 1.8856137119313723

Epoch: 6| Step: 7
Training loss: 1.857790470123291
Validation loss: 1.8986665305270944

Epoch: 6| Step: 8
Training loss: 1.5103037357330322
Validation loss: 1.8328308738687986

Epoch: 6| Step: 9
Training loss: 1.1808733940124512
Validation loss: 1.8341387189844602

Epoch: 6| Step: 10
Training loss: 1.3002760410308838
Validation loss: 1.8881665557943366

Epoch: 6| Step: 11
Training loss: 1.6918598413467407
Validation loss: 1.8376385755436395

Epoch: 6| Step: 12
Training loss: 1.7487636804580688
Validation loss: 1.862281709588984

Epoch: 6| Step: 13
Training loss: 0.9161326289176941
Validation loss: 1.847207885916515

Epoch: 346| Step: 0
Training loss: 1.4340052604675293
Validation loss: 1.8248359593012

Epoch: 6| Step: 1
Training loss: 1.5407323837280273
Validation loss: 1.8887775944125267

Epoch: 6| Step: 2
Training loss: 1.6843281984329224
Validation loss: 1.8477489256089734

Epoch: 6| Step: 3
Training loss: 1.0396140813827515
Validation loss: 1.8506784797996603

Epoch: 6| Step: 4
Training loss: 1.5438206195831299
Validation loss: 1.8423107465108235

Epoch: 6| Step: 5
Training loss: 1.4823238849639893
Validation loss: 1.8481798120724258

Epoch: 6| Step: 6
Training loss: 2.116671085357666
Validation loss: 1.9258141158729472

Epoch: 6| Step: 7
Training loss: 1.8118441104888916
Validation loss: 1.8490709438118884

Epoch: 6| Step: 8
Training loss: 0.6911965012550354
Validation loss: 1.8540544996979416

Epoch: 6| Step: 9
Training loss: 1.5759378671646118
Validation loss: 1.8716724213733469

Epoch: 6| Step: 10
Training loss: 1.2501120567321777
Validation loss: 1.8505886985409645

Epoch: 6| Step: 11
Training loss: 1.6380996704101562
Validation loss: 1.8520994417129024

Epoch: 6| Step: 12
Training loss: 1.1982653141021729
Validation loss: 1.9447038942767727

Epoch: 6| Step: 13
Training loss: 1.056999683380127
Validation loss: 1.8935448264562955

Epoch: 347| Step: 0
Training loss: 1.5156409740447998
Validation loss: 1.9421586426355506

Epoch: 6| Step: 1
Training loss: 1.7372264862060547
Validation loss: 1.855553416795628

Epoch: 6| Step: 2
Training loss: 1.3578131198883057
Validation loss: 1.9454495983739053

Epoch: 6| Step: 3
Training loss: 1.885152816772461
Validation loss: 1.85548996925354

Epoch: 6| Step: 4
Training loss: 2.068599224090576
Validation loss: 1.8612069801617694

Epoch: 6| Step: 5
Training loss: 1.6371427774429321
Validation loss: 1.8767239227089831

Epoch: 6| Step: 6
Training loss: 1.1199259757995605
Validation loss: 1.8350993074396604

Epoch: 6| Step: 7
Training loss: 1.2114734649658203
Validation loss: 1.8449689701039305

Epoch: 6| Step: 8
Training loss: 1.1503291130065918
Validation loss: 1.8665641123248684

Epoch: 6| Step: 9
Training loss: 1.9973034858703613
Validation loss: 1.8104253148519864

Epoch: 6| Step: 10
Training loss: 1.5727620124816895
Validation loss: 1.861010169470182

Epoch: 6| Step: 11
Training loss: 1.2006276845932007
Validation loss: 1.85416974559907

Epoch: 6| Step: 12
Training loss: 0.96415114402771
Validation loss: 1.8660661840951571

Epoch: 6| Step: 13
Training loss: 1.0863538980484009
Validation loss: 1.8244653081381192

Epoch: 348| Step: 0
Training loss: 0.9356756806373596
Validation loss: 1.8488667113806612

Epoch: 6| Step: 1
Training loss: 0.694534420967102
Validation loss: 1.8981062366116432

Epoch: 6| Step: 2
Training loss: 1.5016586780548096
Validation loss: 1.8381674187157744

Epoch: 6| Step: 3
Training loss: 1.1956876516342163
Validation loss: 1.8638939203754548

Epoch: 6| Step: 4
Training loss: 1.2329235076904297
Validation loss: 1.9129573811766922

Epoch: 6| Step: 5
Training loss: 1.6907289028167725
Validation loss: 1.8835233565299743

Epoch: 6| Step: 6
Training loss: 1.5154023170471191
Validation loss: 1.8329949353330879

Epoch: 6| Step: 7
Training loss: 1.5334571599960327
Validation loss: 1.8903914420835433

Epoch: 6| Step: 8
Training loss: 1.865549087524414
Validation loss: 1.8713113864262898

Epoch: 6| Step: 9
Training loss: 1.6283526420593262
Validation loss: 1.9057976494553268

Epoch: 6| Step: 10
Training loss: 2.0079309940338135
Validation loss: 1.8866198485897434

Epoch: 6| Step: 11
Training loss: 1.8469407558441162
Validation loss: 1.9345674181497226

Epoch: 6| Step: 12
Training loss: 1.3173251152038574
Validation loss: 1.9177211997329549

Epoch: 6| Step: 13
Training loss: 1.4634166955947876
Validation loss: 1.8687570659063195

Epoch: 349| Step: 0
Training loss: 0.8624244928359985
Validation loss: 1.9075885306122482

Epoch: 6| Step: 1
Training loss: 1.5305445194244385
Validation loss: 1.8651427966292187

Epoch: 6| Step: 2
Training loss: 0.9758131504058838
Validation loss: 1.9260595460091867

Epoch: 6| Step: 3
Training loss: 1.3901188373565674
Validation loss: 1.891864186973982

Epoch: 6| Step: 4
Training loss: 2.0754780769348145
Validation loss: 1.8420690708262946

Epoch: 6| Step: 5
Training loss: 1.2406702041625977
Validation loss: 1.8493465505620486

Epoch: 6| Step: 6
Training loss: 1.4933714866638184
Validation loss: 1.8693025419788976

Epoch: 6| Step: 7
Training loss: 1.531173586845398
Validation loss: 1.8480881362833002

Epoch: 6| Step: 8
Training loss: 1.8160436153411865
Validation loss: 1.8249372333608649

Epoch: 6| Step: 9
Training loss: 1.3688130378723145
Validation loss: 1.889906039801977

Epoch: 6| Step: 10
Training loss: 1.6740325689315796
Validation loss: 1.7932808578655284

Epoch: 6| Step: 11
Training loss: 1.1566256284713745
Validation loss: 1.9053545767261135

Epoch: 6| Step: 12
Training loss: 1.1978250741958618
Validation loss: 1.9051672899594871

Epoch: 6| Step: 13
Training loss: 1.5351265668869019
Validation loss: 1.838987632464337

Epoch: 350| Step: 0
Training loss: 0.8209449052810669
Validation loss: 1.8624450904066845

Epoch: 6| Step: 1
Training loss: 0.9835233092308044
Validation loss: 1.829690343590193

Epoch: 6| Step: 2
Training loss: 1.6905231475830078
Validation loss: 1.8419962954777542

Epoch: 6| Step: 3
Training loss: 1.744161605834961
Validation loss: 1.8804594778245496

Epoch: 6| Step: 4
Training loss: 1.7853009700775146
Validation loss: 1.8798736692756735

Epoch: 6| Step: 5
Training loss: 1.8667638301849365
Validation loss: 1.8632717606841878

Epoch: 6| Step: 6
Training loss: 1.9135197401046753
Validation loss: 1.8725277275167487

Epoch: 6| Step: 7
Training loss: 0.983997106552124
Validation loss: 1.7855638919338104

Epoch: 6| Step: 8
Training loss: 2.1939697265625
Validation loss: 1.940826408324703

Epoch: 6| Step: 9
Training loss: 1.3323529958724976
Validation loss: 1.8683965052327802

Epoch: 6| Step: 10
Training loss: 1.3888132572174072
Validation loss: 1.911145374339114

Epoch: 6| Step: 11
Training loss: 1.2915465831756592
Validation loss: 1.9053188626484205

Epoch: 6| Step: 12
Training loss: 1.3527569770812988
Validation loss: 1.9115762402934413

Epoch: 6| Step: 13
Training loss: 0.5808597803115845
Validation loss: 1.8836818895032328

Epoch: 351| Step: 0
Training loss: 0.8616081476211548
Validation loss: 1.9034308361750778

Epoch: 6| Step: 1
Training loss: 1.4607219696044922
Validation loss: 1.8800874333227835

Epoch: 6| Step: 2
Training loss: 1.5798070430755615
Validation loss: 1.8915542838394002

Epoch: 6| Step: 3
Training loss: 1.2135980129241943
Validation loss: 1.8819496785440752

Epoch: 6| Step: 4
Training loss: 1.619748592376709
Validation loss: 1.8856776504106418

Epoch: 6| Step: 5
Training loss: 1.4916518926620483
Validation loss: 1.8664297749919276

Epoch: 6| Step: 6
Training loss: 1.6337618827819824
Validation loss: 1.8356889640131304

Epoch: 6| Step: 7
Training loss: 1.4597172737121582
Validation loss: 1.870308659409964

Epoch: 6| Step: 8
Training loss: 1.4170883893966675
Validation loss: 1.8073040067508657

Epoch: 6| Step: 9
Training loss: 2.0780386924743652
Validation loss: 1.918486011925564

Epoch: 6| Step: 10
Training loss: 1.3107519149780273
Validation loss: 1.8908438182646228

Epoch: 6| Step: 11
Training loss: 1.5621789693832397
Validation loss: 1.8649979624696957

Epoch: 6| Step: 12
Training loss: 1.2759405374526978
Validation loss: 1.8660544041664369

Epoch: 6| Step: 13
Training loss: 1.5901678800582886
Validation loss: 1.8567768296887797

Epoch: 352| Step: 0
Training loss: 1.738328456878662
Validation loss: 1.9298202978667391

Epoch: 6| Step: 1
Training loss: 1.9964083433151245
Validation loss: 1.8604654535170524

Epoch: 6| Step: 2
Training loss: 1.754610538482666
Validation loss: 1.890837646299793

Epoch: 6| Step: 3
Training loss: 1.5630841255187988
Validation loss: 1.8440477271233835

Epoch: 6| Step: 4
Training loss: 1.240856647491455
Validation loss: 1.8285113944802234

Epoch: 6| Step: 5
Training loss: 1.223618745803833
Validation loss: 1.9385629225802679

Epoch: 6| Step: 6
Training loss: 1.5163118839263916
Validation loss: 1.8955992114159368

Epoch: 6| Step: 7
Training loss: 1.2027815580368042
Validation loss: 1.8772865380010297

Epoch: 6| Step: 8
Training loss: 1.1294091939926147
Validation loss: 1.8647997212666336

Epoch: 6| Step: 9
Training loss: 1.976119875907898
Validation loss: 1.8714202783441032

Epoch: 6| Step: 10
Training loss: 0.8591433763504028
Validation loss: 1.7815124360463952

Epoch: 6| Step: 11
Training loss: 0.987779974937439
Validation loss: 1.8576910944395169

Epoch: 6| Step: 12
Training loss: 1.4930212497711182
Validation loss: 1.8621616786526096

Epoch: 6| Step: 13
Training loss: 1.2566498517990112
Validation loss: 1.888677372727343

Epoch: 353| Step: 0
Training loss: 1.1374289989471436
Validation loss: 1.8385955364473405

Epoch: 6| Step: 1
Training loss: 1.390840768814087
Validation loss: 1.8550357164875153

Epoch: 6| Step: 2
Training loss: 0.8696582317352295
Validation loss: 1.848554075405162

Epoch: 6| Step: 3
Training loss: 1.1008228063583374
Validation loss: 1.8420388954941944

Epoch: 6| Step: 4
Training loss: 1.37489914894104
Validation loss: 1.8974823413356658

Epoch: 6| Step: 5
Training loss: 1.664142370223999
Validation loss: 1.8789149304871917

Epoch: 6| Step: 6
Training loss: 1.264979600906372
Validation loss: 1.8310543080811859

Epoch: 6| Step: 7
Training loss: 1.2624456882476807
Validation loss: 1.898607825720182

Epoch: 6| Step: 8
Training loss: 1.5748705863952637
Validation loss: 1.8623816800373856

Epoch: 6| Step: 9
Training loss: 1.5632680654525757
Validation loss: 1.809363983010733

Epoch: 6| Step: 10
Training loss: 2.038017988204956
Validation loss: 1.8581208862284178

Epoch: 6| Step: 11
Training loss: 2.012436628341675
Validation loss: 1.9618322387818368

Epoch: 6| Step: 12
Training loss: 1.7566673755645752
Validation loss: 1.9039224052941928

Epoch: 6| Step: 13
Training loss: 2.020221710205078
Validation loss: 1.8767078800867962

Epoch: 354| Step: 0
Training loss: 1.8492207527160645
Validation loss: 1.8489572437860633

Epoch: 6| Step: 1
Training loss: 1.1208497285842896
Validation loss: 1.854166385948017

Epoch: 6| Step: 2
Training loss: 1.493032455444336
Validation loss: 1.7872620705635316

Epoch: 6| Step: 3
Training loss: 1.4420239925384521
Validation loss: 1.8578780658783451

Epoch: 6| Step: 4
Training loss: 1.6914680004119873
Validation loss: 1.9105453901393439

Epoch: 6| Step: 5
Training loss: 1.4890766143798828
Validation loss: 1.8050702976924118

Epoch: 6| Step: 6
Training loss: 1.3883867263793945
Validation loss: 1.880288230475559

Epoch: 6| Step: 7
Training loss: 0.9565531611442566
Validation loss: 1.839828832175142

Epoch: 6| Step: 8
Training loss: 1.0132622718811035
Validation loss: 1.8890086361156997

Epoch: 6| Step: 9
Training loss: 1.1865229606628418
Validation loss: 1.9350287042638308

Epoch: 6| Step: 10
Training loss: 1.4541034698486328
Validation loss: 1.8508253007806756

Epoch: 6| Step: 11
Training loss: 0.9464847445487976
Validation loss: 1.896048713755864

Epoch: 6| Step: 12
Training loss: 2.1043336391448975
Validation loss: 1.9446758172845329

Epoch: 6| Step: 13
Training loss: 1.5013891458511353
Validation loss: 1.9140251759559876

Epoch: 355| Step: 0
Training loss: 1.738797664642334
Validation loss: 1.8220315876827444

Epoch: 6| Step: 1
Training loss: 1.7705862522125244
Validation loss: 1.8448356748909078

Epoch: 6| Step: 2
Training loss: 1.6746232509613037
Validation loss: 1.8867340036617812

Epoch: 6| Step: 3
Training loss: 1.181176781654358
Validation loss: 1.858385080932289

Epoch: 6| Step: 4
Training loss: 1.720345377922058
Validation loss: 1.8114313861375213

Epoch: 6| Step: 5
Training loss: 1.671575903892517
Validation loss: 1.8077404704145206

Epoch: 6| Step: 6
Training loss: 1.574912428855896
Validation loss: 1.8288806305136731

Epoch: 6| Step: 7
Training loss: 1.410283088684082
Validation loss: 1.8525404981387559

Epoch: 6| Step: 8
Training loss: 2.254162549972534
Validation loss: 1.8203924714878041

Epoch: 6| Step: 9
Training loss: 0.6993000507354736
Validation loss: 1.8461146341857089

Epoch: 6| Step: 10
Training loss: 0.6613378524780273
Validation loss: 1.8227708596055225

Epoch: 6| Step: 11
Training loss: 1.1434929370880127
Validation loss: 1.879517242472659

Epoch: 6| Step: 12
Training loss: 1.4773211479187012
Validation loss: 1.822744284906695

Epoch: 6| Step: 13
Training loss: 0.7563288807868958
Validation loss: 1.8594587925941712

Epoch: 356| Step: 0
Training loss: 1.4330060482025146
Validation loss: 1.835534143191512

Epoch: 6| Step: 1
Training loss: 1.8426318168640137
Validation loss: 1.9112714054763957

Epoch: 6| Step: 2
Training loss: 1.4865565299987793
Validation loss: 1.8268760840098064

Epoch: 6| Step: 3
Training loss: 1.7355918884277344
Validation loss: 1.8527225243147982

Epoch: 6| Step: 4
Training loss: 2.0470521450042725
Validation loss: 1.8844938380743868

Epoch: 6| Step: 5
Training loss: 1.4106218814849854
Validation loss: 1.8470701530415525

Epoch: 6| Step: 6
Training loss: 0.7799059152603149
Validation loss: 1.8242509570173038

Epoch: 6| Step: 7
Training loss: 1.419248342514038
Validation loss: 1.8116048715447868

Epoch: 6| Step: 8
Training loss: 1.3027701377868652
Validation loss: 1.8436386226325907

Epoch: 6| Step: 9
Training loss: 1.494533896446228
Validation loss: 1.8348819568593016

Epoch: 6| Step: 10
Training loss: 0.9471371173858643
Validation loss: 1.9148639632809548

Epoch: 6| Step: 11
Training loss: 1.163991928100586
Validation loss: 1.8520153568636986

Epoch: 6| Step: 12
Training loss: 1.5532844066619873
Validation loss: 1.789712941774758

Epoch: 6| Step: 13
Training loss: 1.2736963033676147
Validation loss: 1.9151139361884004

Epoch: 357| Step: 0
Training loss: 1.2685458660125732
Validation loss: 1.8445554189784552

Epoch: 6| Step: 1
Training loss: 1.7942523956298828
Validation loss: 1.8505015065593104

Epoch: 6| Step: 2
Training loss: 1.5208230018615723
Validation loss: 1.8120654782941263

Epoch: 6| Step: 3
Training loss: 1.7322266101837158
Validation loss: 1.869421402613322

Epoch: 6| Step: 4
Training loss: 1.3908648490905762
Validation loss: 1.8382040275040494

Epoch: 6| Step: 5
Training loss: 1.3984222412109375
Validation loss: 1.8746157384687854

Epoch: 6| Step: 6
Training loss: 1.6205921173095703
Validation loss: 1.8766903569621425

Epoch: 6| Step: 7
Training loss: 0.8923068046569824
Validation loss: 1.9004147950039114

Epoch: 6| Step: 8
Training loss: 1.6030269861221313
Validation loss: 1.801268349411667

Epoch: 6| Step: 9
Training loss: 0.937018871307373
Validation loss: 1.7985865813429638

Epoch: 6| Step: 10
Training loss: 1.112506628036499
Validation loss: 1.87052414237812

Epoch: 6| Step: 11
Training loss: 1.728134036064148
Validation loss: 1.8390715070950088

Epoch: 6| Step: 12
Training loss: 1.1698198318481445
Validation loss: 1.8743565056913642

Epoch: 6| Step: 13
Training loss: 1.9447835683822632
Validation loss: 1.8529130040958364

Epoch: 358| Step: 0
Training loss: 1.1023235321044922
Validation loss: 1.866854151089986

Epoch: 6| Step: 1
Training loss: 1.7827754020690918
Validation loss: 1.8396196083355976

Epoch: 6| Step: 2
Training loss: 1.0871741771697998
Validation loss: 1.8335521477524952

Epoch: 6| Step: 3
Training loss: 1.751758337020874
Validation loss: 1.8289968916164931

Epoch: 6| Step: 4
Training loss: 1.2918621301651
Validation loss: 1.8625224674901655

Epoch: 6| Step: 5
Training loss: 1.0668801069259644
Validation loss: 1.8141148115998955

Epoch: 6| Step: 6
Training loss: 1.7053914070129395
Validation loss: 1.7983639496628956

Epoch: 6| Step: 7
Training loss: 1.7292264699935913
Validation loss: 1.8761610049073414

Epoch: 6| Step: 8
Training loss: 1.2904472351074219
Validation loss: 1.8787271617561259

Epoch: 6| Step: 9
Training loss: 1.2748808860778809
Validation loss: 1.8568980181089012

Epoch: 6| Step: 10
Training loss: 1.5885367393493652
Validation loss: 1.883269856053014

Epoch: 6| Step: 11
Training loss: 1.667065978050232
Validation loss: 1.8642935009412869

Epoch: 6| Step: 12
Training loss: 1.1618309020996094
Validation loss: 1.8289860768984723

Epoch: 6| Step: 13
Training loss: 1.424386739730835
Validation loss: 1.9086949774014053

Epoch: 359| Step: 0
Training loss: 2.047236442565918
Validation loss: 1.8552210561690792

Epoch: 6| Step: 1
Training loss: 1.4552059173583984
Validation loss: 1.844181631201057

Epoch: 6| Step: 2
Training loss: 1.4932178258895874
Validation loss: 1.8723150991624402

Epoch: 6| Step: 3
Training loss: 1.8008238077163696
Validation loss: 1.8423719765037618

Epoch: 6| Step: 4
Training loss: 0.9848713874816895
Validation loss: 1.9190942984755321

Epoch: 6| Step: 5
Training loss: 0.9604886770248413
Validation loss: 1.9165642299959738

Epoch: 6| Step: 6
Training loss: 1.5636718273162842
Validation loss: 1.8348925972497592

Epoch: 6| Step: 7
Training loss: 1.5163819789886475
Validation loss: 1.8947825944551857

Epoch: 6| Step: 8
Training loss: 0.7764095067977905
Validation loss: 1.9213251093382477

Epoch: 6| Step: 9
Training loss: 1.77974534034729
Validation loss: 1.899547379503968

Epoch: 6| Step: 10
Training loss: 1.191275715827942
Validation loss: 1.869538760954334

Epoch: 6| Step: 11
Training loss: 1.5069692134857178
Validation loss: 1.89706681107962

Epoch: 6| Step: 12
Training loss: 1.502190113067627
Validation loss: 1.8820620723949966

Epoch: 6| Step: 13
Training loss: 0.9505836963653564
Validation loss: 1.8749209911592546

Epoch: 360| Step: 0
Training loss: 1.6249110698699951
Validation loss: 1.868900099108296

Epoch: 6| Step: 1
Training loss: 1.5342106819152832
Validation loss: 1.8183873840557632

Epoch: 6| Step: 2
Training loss: 1.5631930828094482
Validation loss: 1.9034111660013917

Epoch: 6| Step: 3
Training loss: 1.2852157354354858
Validation loss: 1.932984677694177

Epoch: 6| Step: 4
Training loss: 1.6341710090637207
Validation loss: 1.8423197653985792

Epoch: 6| Step: 5
Training loss: 1.3880631923675537
Validation loss: 1.831557112355386

Epoch: 6| Step: 6
Training loss: 1.782984733581543
Validation loss: 1.8399636437816005

Epoch: 6| Step: 7
Training loss: 1.2894511222839355
Validation loss: 1.9322101364853561

Epoch: 6| Step: 8
Training loss: 1.6711852550506592
Validation loss: 1.953783997925379

Epoch: 6| Step: 9
Training loss: 1.2063429355621338
Validation loss: 1.8985956996999762

Epoch: 6| Step: 10
Training loss: 1.1196258068084717
Validation loss: 1.8855408289099251

Epoch: 6| Step: 11
Training loss: 1.1635963916778564
Validation loss: 1.8863143100533435

Epoch: 6| Step: 12
Training loss: 1.118272066116333
Validation loss: 1.8546586600683068

Epoch: 6| Step: 13
Training loss: 1.2800683975219727
Validation loss: 1.8672023075883106

Epoch: 361| Step: 0
Training loss: 1.4914062023162842
Validation loss: 1.867696480084491

Epoch: 6| Step: 1
Training loss: 0.8535203337669373
Validation loss: 1.782965644713371

Epoch: 6| Step: 2
Training loss: 1.3892570734024048
Validation loss: 1.8375943976063882

Epoch: 6| Step: 3
Training loss: 1.4465460777282715
Validation loss: 1.8994509045795729

Epoch: 6| Step: 4
Training loss: 1.7725305557250977
Validation loss: 1.8340748958690192

Epoch: 6| Step: 5
Training loss: 1.7076096534729004
Validation loss: 1.828771366867968

Epoch: 6| Step: 6
Training loss: 1.1309540271759033
Validation loss: 1.7927973321689072

Epoch: 6| Step: 7
Training loss: 1.4121885299682617
Validation loss: 1.8547780590672647

Epoch: 6| Step: 8
Training loss: 1.7303004264831543
Validation loss: 1.8698730596932032

Epoch: 6| Step: 9
Training loss: 1.4069733619689941
Validation loss: 1.8942356314710391

Epoch: 6| Step: 10
Training loss: 1.7878899574279785
Validation loss: 1.8596949551695137

Epoch: 6| Step: 11
Training loss: 1.3827013969421387
Validation loss: 1.8698921665068595

Epoch: 6| Step: 12
Training loss: 1.0703580379486084
Validation loss: 1.8767978196503015

Epoch: 6| Step: 13
Training loss: 1.6347559690475464
Validation loss: 1.8852609242162397

Epoch: 362| Step: 0
Training loss: 1.7482309341430664
Validation loss: 1.916428554442621

Epoch: 6| Step: 1
Training loss: 1.4393861293792725
Validation loss: 1.8369785367801625

Epoch: 6| Step: 2
Training loss: 0.7548319101333618
Validation loss: 1.9084558153665194

Epoch: 6| Step: 3
Training loss: 1.8135321140289307
Validation loss: 1.8797407022086523

Epoch: 6| Step: 4
Training loss: 1.3770040273666382
Validation loss: 1.842865313253095

Epoch: 6| Step: 5
Training loss: 1.4381203651428223
Validation loss: 1.8802275978108889

Epoch: 6| Step: 6
Training loss: 1.6300249099731445
Validation loss: 1.8685523066469418

Epoch: 6| Step: 7
Training loss: 1.2804689407348633
Validation loss: 1.9396304404863747

Epoch: 6| Step: 8
Training loss: 0.6715279221534729
Validation loss: 1.8533668928248908

Epoch: 6| Step: 9
Training loss: 1.775287389755249
Validation loss: 1.9098578089026994

Epoch: 6| Step: 10
Training loss: 1.2129182815551758
Validation loss: 1.8876970224483038

Epoch: 6| Step: 11
Training loss: 1.8742454051971436
Validation loss: 1.9130980455747215

Epoch: 6| Step: 12
Training loss: 1.2122163772583008
Validation loss: 1.917007214279585

Epoch: 6| Step: 13
Training loss: 1.9822232723236084
Validation loss: 1.9235892718838108

Epoch: 363| Step: 0
Training loss: 0.9574580192565918
Validation loss: 1.8896232189670685

Epoch: 6| Step: 1
Training loss: 1.9231336116790771
Validation loss: 1.8625996100005282

Epoch: 6| Step: 2
Training loss: 1.296739101409912
Validation loss: 1.9176440828589982

Epoch: 6| Step: 3
Training loss: 1.0721774101257324
Validation loss: 1.8545446498419649

Epoch: 6| Step: 4
Training loss: 1.3869009017944336
Validation loss: 1.7852682477684432

Epoch: 6| Step: 5
Training loss: 1.517890214920044
Validation loss: 1.888487696647644

Epoch: 6| Step: 6
Training loss: 1.693120002746582
Validation loss: 1.8341759340737456

Epoch: 6| Step: 7
Training loss: 0.936450719833374
Validation loss: 1.7915188086930143

Epoch: 6| Step: 8
Training loss: 1.9143427610397339
Validation loss: 1.8760675050879037

Epoch: 6| Step: 9
Training loss: 1.7985012531280518
Validation loss: 1.839604091900651

Epoch: 6| Step: 10
Training loss: 1.2461917400360107
Validation loss: 1.813909965176736

Epoch: 6| Step: 11
Training loss: 1.449519395828247
Validation loss: 1.8406161903053202

Epoch: 6| Step: 12
Training loss: 1.098397970199585
Validation loss: 1.8205523811360842

Epoch: 6| Step: 13
Training loss: 1.6484745740890503
Validation loss: 1.8349731852931361

Epoch: 364| Step: 0
Training loss: 1.6325470209121704
Validation loss: 1.8902504854304816

Epoch: 6| Step: 1
Training loss: 1.602683663368225
Validation loss: 1.8098015695489862

Epoch: 6| Step: 2
Training loss: 0.9342546463012695
Validation loss: 1.8593958731620543

Epoch: 6| Step: 3
Training loss: 1.654430866241455
Validation loss: 1.950817866991925

Epoch: 6| Step: 4
Training loss: 1.1195354461669922
Validation loss: 1.9053382335170623

Epoch: 6| Step: 5
Training loss: 1.4213684797286987
Validation loss: 1.903769229048042

Epoch: 6| Step: 6
Training loss: 1.1661425828933716
Validation loss: 1.907881175318072

Epoch: 6| Step: 7
Training loss: 1.2606940269470215
Validation loss: 1.8780153130972257

Epoch: 6| Step: 8
Training loss: 2.009960651397705
Validation loss: 1.8945673255510227

Epoch: 6| Step: 9
Training loss: 1.3220653533935547
Validation loss: 1.8293363304548367

Epoch: 6| Step: 10
Training loss: 1.765769362449646
Validation loss: 1.8240818387718611

Epoch: 6| Step: 11
Training loss: 1.7805198431015015
Validation loss: 1.8818162307944348

Epoch: 6| Step: 12
Training loss: 0.9948064684867859
Validation loss: 1.820913835238385

Epoch: 6| Step: 13
Training loss: 1.1203581094741821
Validation loss: 1.8328988513638895

Epoch: 365| Step: 0
Training loss: 1.1522749662399292
Validation loss: 1.757804928287383

Epoch: 6| Step: 1
Training loss: 1.5250014066696167
Validation loss: 1.8207162964728572

Epoch: 6| Step: 2
Training loss: 1.0444600582122803
Validation loss: 1.813739586901921

Epoch: 6| Step: 3
Training loss: 2.009646415710449
Validation loss: 1.8031789782226726

Epoch: 6| Step: 4
Training loss: 1.9622220993041992
Validation loss: 1.8206743232665523

Epoch: 6| Step: 5
Training loss: 1.3363633155822754
Validation loss: 1.842593668609537

Epoch: 6| Step: 6
Training loss: 1.1314315795898438
Validation loss: 1.8573950823917185

Epoch: 6| Step: 7
Training loss: 1.1217584609985352
Validation loss: 1.8423167761935983

Epoch: 6| Step: 8
Training loss: 1.3612873554229736
Validation loss: 1.8152447169826877

Epoch: 6| Step: 9
Training loss: 2.223703622817993
Validation loss: 1.842508917213768

Epoch: 6| Step: 10
Training loss: 1.092216968536377
Validation loss: 1.856895863368947

Epoch: 6| Step: 11
Training loss: 1.5707064867019653
Validation loss: 1.8621760568311136

Epoch: 6| Step: 12
Training loss: 1.091726303100586
Validation loss: 1.8935791471953034

Epoch: 6| Step: 13
Training loss: 1.046418309211731
Validation loss: 1.7990603229050994

Epoch: 366| Step: 0
Training loss: 1.2116270065307617
Validation loss: 1.8819551506350118

Epoch: 6| Step: 1
Training loss: 2.475900173187256
Validation loss: 1.8597272185869114

Epoch: 6| Step: 2
Training loss: 0.9755048751831055
Validation loss: 1.8768828376646964

Epoch: 6| Step: 3
Training loss: 1.2478662729263306
Validation loss: 1.8645131305981708

Epoch: 6| Step: 4
Training loss: 1.3539540767669678
Validation loss: 1.8416872716719104

Epoch: 6| Step: 5
Training loss: 1.4958642721176147
Validation loss: 1.8941543743174563

Epoch: 6| Step: 6
Training loss: 1.568903923034668
Validation loss: 1.8981966203258884

Epoch: 6| Step: 7
Training loss: 1.0464036464691162
Validation loss: 1.894709252542065

Epoch: 6| Step: 8
Training loss: 1.3787603378295898
Validation loss: 1.879258245550176

Epoch: 6| Step: 9
Training loss: 1.3936092853546143
Validation loss: 1.887570426028262

Epoch: 6| Step: 10
Training loss: 1.4931132793426514
Validation loss: 1.8303952678557365

Epoch: 6| Step: 11
Training loss: 1.1164581775665283
Validation loss: 1.8382429204961306

Epoch: 6| Step: 12
Training loss: 1.752150535583496
Validation loss: 1.8388998777635637

Epoch: 6| Step: 13
Training loss: 1.878913402557373
Validation loss: 1.8858230062710342

Epoch: 367| Step: 0
Training loss: 2.1510579586029053
Validation loss: 1.8469308909549509

Epoch: 6| Step: 1
Training loss: 1.5438355207443237
Validation loss: 1.8110931791285032

Epoch: 6| Step: 2
Training loss: 1.116971731185913
Validation loss: 1.8150246540705364

Epoch: 6| Step: 3
Training loss: 1.508652687072754
Validation loss: 1.868239519416645

Epoch: 6| Step: 4
Training loss: 1.6420514583587646
Validation loss: 1.8214026394710745

Epoch: 6| Step: 5
Training loss: 1.5766260623931885
Validation loss: 1.8102160833215202

Epoch: 6| Step: 6
Training loss: 0.7463988065719604
Validation loss: 1.888035317902924

Epoch: 6| Step: 7
Training loss: 1.35298490524292
Validation loss: 1.745990563464421

Epoch: 6| Step: 8
Training loss: 1.0969507694244385
Validation loss: 1.8318898562462098

Epoch: 6| Step: 9
Training loss: 1.421295166015625
Validation loss: 1.8297726672182801

Epoch: 6| Step: 10
Training loss: 1.4691561460494995
Validation loss: 1.9304367573030534

Epoch: 6| Step: 11
Training loss: 1.4258431196212769
Validation loss: 1.8639162022580382

Epoch: 6| Step: 12
Training loss: 1.4723042249679565
Validation loss: 1.7985410305761522

Epoch: 6| Step: 13
Training loss: 1.3654793500900269
Validation loss: 1.9068274331349198

Epoch: 368| Step: 0
Training loss: 1.414811372756958
Validation loss: 1.8252001398353166

Epoch: 6| Step: 1
Training loss: 1.0499199628829956
Validation loss: 1.893901244286568

Epoch: 6| Step: 2
Training loss: 1.2382405996322632
Validation loss: 1.934443937834873

Epoch: 6| Step: 3
Training loss: 1.3662991523742676
Validation loss: 1.9146674345898371

Epoch: 6| Step: 4
Training loss: 1.321448564529419
Validation loss: 1.9184747357522287

Epoch: 6| Step: 5
Training loss: 1.5841155052185059
Validation loss: 1.9091041677741594

Epoch: 6| Step: 6
Training loss: 1.2348816394805908
Validation loss: 1.9579335412671488

Epoch: 6| Step: 7
Training loss: 1.2451555728912354
Validation loss: 1.9375439254186486

Epoch: 6| Step: 8
Training loss: 2.6203856468200684
Validation loss: 1.9132490478536135

Epoch: 6| Step: 9
Training loss: 0.9555315375328064
Validation loss: 1.8989105583519064

Epoch: 6| Step: 10
Training loss: 1.7833585739135742
Validation loss: 1.8824270335576867

Epoch: 6| Step: 11
Training loss: 1.3286888599395752
Validation loss: 1.9190262286893782

Epoch: 6| Step: 12
Training loss: 1.5229299068450928
Validation loss: 1.818768109044721

Epoch: 6| Step: 13
Training loss: 1.5486044883728027
Validation loss: 1.8183922947094004

Epoch: 369| Step: 0
Training loss: 1.7997117042541504
Validation loss: 1.863251232331799

Epoch: 6| Step: 1
Training loss: 0.9905579090118408
Validation loss: 1.8079575979581444

Epoch: 6| Step: 2
Training loss: 1.9894967079162598
Validation loss: 1.8710817367799821

Epoch: 6| Step: 3
Training loss: 1.3810193538665771
Validation loss: 1.8857923297471897

Epoch: 6| Step: 4
Training loss: 1.5862782001495361
Validation loss: 1.8579212439957487

Epoch: 6| Step: 5
Training loss: 0.9521652460098267
Validation loss: 1.8003015595097696

Epoch: 6| Step: 6
Training loss: 1.103751301765442
Validation loss: 1.84492628805099

Epoch: 6| Step: 7
Training loss: 1.5145741701126099
Validation loss: 1.7932631200359714

Epoch: 6| Step: 8
Training loss: 1.3419322967529297
Validation loss: 1.836536789453158

Epoch: 6| Step: 9
Training loss: 1.2422771453857422
Validation loss: 1.8339565389899797

Epoch: 6| Step: 10
Training loss: 1.982412576675415
Validation loss: 1.7933642838590889

Epoch: 6| Step: 11
Training loss: 0.931662917137146
Validation loss: 1.8472280950956448

Epoch: 6| Step: 12
Training loss: 1.224170207977295
Validation loss: 1.8239143253654562

Epoch: 6| Step: 13
Training loss: 2.119788646697998
Validation loss: 1.818716255567407

Epoch: 370| Step: 0
Training loss: 1.6541547775268555
Validation loss: 1.8369618269705004

Epoch: 6| Step: 1
Training loss: 1.0931000709533691
Validation loss: 1.8532652162736463

Epoch: 6| Step: 2
Training loss: 1.5985133647918701
Validation loss: 1.8404357035954793

Epoch: 6| Step: 3
Training loss: 1.128563642501831
Validation loss: 1.924089434326336

Epoch: 6| Step: 4
Training loss: 1.4244012832641602
Validation loss: 1.8978033783615276

Epoch: 6| Step: 5
Training loss: 1.4649908542633057
Validation loss: 1.8278076648712158

Epoch: 6| Step: 6
Training loss: 0.7807173728942871
Validation loss: 1.8329762271655503

Epoch: 6| Step: 7
Training loss: 1.5640673637390137
Validation loss: 1.8899212678273518

Epoch: 6| Step: 8
Training loss: 1.9761931896209717
Validation loss: 1.8291149382950158

Epoch: 6| Step: 9
Training loss: 1.227217674255371
Validation loss: 1.8351544769861365

Epoch: 6| Step: 10
Training loss: 1.377622127532959
Validation loss: 1.8638712283103698

Epoch: 6| Step: 11
Training loss: 1.2591989040374756
Validation loss: 1.862756149743193

Epoch: 6| Step: 12
Training loss: 1.447744607925415
Validation loss: 1.81341790768408

Epoch: 6| Step: 13
Training loss: 1.7441904544830322
Validation loss: 1.8513590328155025

Epoch: 371| Step: 0
Training loss: 1.0443036556243896
Validation loss: 1.8690749291450746

Epoch: 6| Step: 1
Training loss: 1.2909046411514282
Validation loss: 1.841611300745318

Epoch: 6| Step: 2
Training loss: 1.580885410308838
Validation loss: 1.843501526822326

Epoch: 6| Step: 3
Training loss: 1.0573002099990845
Validation loss: 1.8900047297118812

Epoch: 6| Step: 4
Training loss: 1.3591350317001343
Validation loss: 1.8557589695017824

Epoch: 6| Step: 5
Training loss: 1.0785548686981201
Validation loss: 1.842126332303529

Epoch: 6| Step: 6
Training loss: 1.2905399799346924
Validation loss: 1.8163833874528126

Epoch: 6| Step: 7
Training loss: 1.8463690280914307
Validation loss: 1.8786598405530375

Epoch: 6| Step: 8
Training loss: 1.5843956470489502
Validation loss: 1.830927166887509

Epoch: 6| Step: 9
Training loss: 1.3093490600585938
Validation loss: 1.8831991969898183

Epoch: 6| Step: 10
Training loss: 1.7737997770309448
Validation loss: 1.8502990943129345

Epoch: 6| Step: 11
Training loss: 1.522057056427002
Validation loss: 1.8606781459623767

Epoch: 6| Step: 12
Training loss: 1.640390396118164
Validation loss: 1.826044241587321

Epoch: 6| Step: 13
Training loss: 1.2068901062011719
Validation loss: 1.8462593657996065

Epoch: 372| Step: 0
Training loss: 0.9806261658668518
Validation loss: 1.8802303601336736

Epoch: 6| Step: 1
Training loss: 1.695474624633789
Validation loss: 1.9271967885314778

Epoch: 6| Step: 2
Training loss: 0.7622162103652954
Validation loss: 1.9104286457902642

Epoch: 6| Step: 3
Training loss: 2.0049843788146973
Validation loss: 1.8540961434764247

Epoch: 6| Step: 4
Training loss: 1.0618276596069336
Validation loss: 1.879779900273969

Epoch: 6| Step: 5
Training loss: 1.755987524986267
Validation loss: 1.8739718032139603

Epoch: 6| Step: 6
Training loss: 1.1499221324920654
Validation loss: 1.9293291568756104

Epoch: 6| Step: 7
Training loss: 1.9109382629394531
Validation loss: 1.8520247385066042

Epoch: 6| Step: 8
Training loss: 1.1684224605560303
Validation loss: 1.9320348821660525

Epoch: 6| Step: 9
Training loss: 1.661541223526001
Validation loss: 1.8856287387109572

Epoch: 6| Step: 10
Training loss: 1.3511631488800049
Validation loss: 1.8617368564810803

Epoch: 6| Step: 11
Training loss: 1.8242005109786987
Validation loss: 1.9123671567568215

Epoch: 6| Step: 12
Training loss: 0.802332878112793
Validation loss: 1.9061480209391604

Epoch: 6| Step: 13
Training loss: 1.1340649127960205
Validation loss: 1.8769831926591936

Epoch: 373| Step: 0
Training loss: 1.019430160522461
Validation loss: 1.8428973702974216

Epoch: 6| Step: 1
Training loss: 1.015388011932373
Validation loss: 1.9057187982784805

Epoch: 6| Step: 2
Training loss: 1.058821439743042
Validation loss: 1.8072371226485058

Epoch: 6| Step: 3
Training loss: 1.8401920795440674
Validation loss: 1.8819166152707991

Epoch: 6| Step: 4
Training loss: 2.004411220550537
Validation loss: 1.816739816819468

Epoch: 6| Step: 5
Training loss: 0.9059436321258545
Validation loss: 1.8682055306690994

Epoch: 6| Step: 6
Training loss: 1.8168113231658936
Validation loss: 1.7893615499619515

Epoch: 6| Step: 7
Training loss: 1.1611734628677368
Validation loss: 1.9037010810708488

Epoch: 6| Step: 8
Training loss: 1.425919771194458
Validation loss: 1.8504902021859282

Epoch: 6| Step: 9
Training loss: 0.8942856788635254
Validation loss: 1.843726150451168

Epoch: 6| Step: 10
Training loss: 1.8943325281143188
Validation loss: 1.8937145381845453

Epoch: 6| Step: 11
Training loss: 1.5380773544311523
Validation loss: 1.8546896160289805

Epoch: 6| Step: 12
Training loss: 1.6121671199798584
Validation loss: 1.8272495333866408

Epoch: 6| Step: 13
Training loss: 1.7194416522979736
Validation loss: 1.869341686207761

Epoch: 374| Step: 0
Training loss: 1.3175241947174072
Validation loss: 1.8357492339226507

Epoch: 6| Step: 1
Training loss: 1.6963415145874023
Validation loss: 1.8645535681837349

Epoch: 6| Step: 2
Training loss: 1.158003330230713
Validation loss: 1.8401619131847093

Epoch: 6| Step: 3
Training loss: 1.8148870468139648
Validation loss: 1.86254681053982

Epoch: 6| Step: 4
Training loss: 1.570556640625
Validation loss: 1.8055960106593307

Epoch: 6| Step: 5
Training loss: 1.4034847021102905
Validation loss: 1.8450159513822166

Epoch: 6| Step: 6
Training loss: 0.9678648114204407
Validation loss: 1.950833874364053

Epoch: 6| Step: 7
Training loss: 1.3173048496246338
Validation loss: 1.9215532938639324

Epoch: 6| Step: 8
Training loss: 1.5702049732208252
Validation loss: 1.8080571646331458

Epoch: 6| Step: 9
Training loss: 1.1822264194488525
Validation loss: 1.9323008573183449

Epoch: 6| Step: 10
Training loss: 1.076610803604126
Validation loss: 1.7947753988286501

Epoch: 6| Step: 11
Training loss: 1.953406572341919
Validation loss: 1.896904992800887

Epoch: 6| Step: 12
Training loss: 1.3557649850845337
Validation loss: 1.8529294767687399

Epoch: 6| Step: 13
Training loss: 1.5153194665908813
Validation loss: 1.8630282122601745

Epoch: 375| Step: 0
Training loss: 1.5647521018981934
Validation loss: 1.9108183255759619

Epoch: 6| Step: 1
Training loss: 1.5451637506484985
Validation loss: 1.8349692488229403

Epoch: 6| Step: 2
Training loss: 1.035343050956726
Validation loss: 1.823104335415748

Epoch: 6| Step: 3
Training loss: 1.6604238748550415
Validation loss: 1.920404282949304

Epoch: 6| Step: 4
Training loss: 0.9734625220298767
Validation loss: 1.874458909034729

Epoch: 6| Step: 5
Training loss: 1.4127216339111328
Validation loss: 1.8232131158151934

Epoch: 6| Step: 6
Training loss: 1.4816234111785889
Validation loss: 1.799262422387318

Epoch: 6| Step: 7
Training loss: 0.9939199686050415
Validation loss: 1.8364348693560528

Epoch: 6| Step: 8
Training loss: 1.17976975440979
Validation loss: 1.8700448338703444

Epoch: 6| Step: 9
Training loss: 1.9888193607330322
Validation loss: 1.8479511866005518

Epoch: 6| Step: 10
Training loss: 1.9938868284225464
Validation loss: 1.8668526487965738

Epoch: 6| Step: 11
Training loss: 1.3638930320739746
Validation loss: 1.7749460256227882

Epoch: 6| Step: 12
Training loss: 1.1781607866287231
Validation loss: 1.8344004923297512

Epoch: 6| Step: 13
Training loss: 0.9832413196563721
Validation loss: 1.818194600843614

Epoch: 376| Step: 0
Training loss: 1.6872894763946533
Validation loss: 1.9057357131793935

Epoch: 6| Step: 1
Training loss: 1.2493207454681396
Validation loss: 1.8502349520242343

Epoch: 6| Step: 2
Training loss: 1.0680480003356934
Validation loss: 1.8629237016042073

Epoch: 6| Step: 3
Training loss: 2.0395452976226807
Validation loss: 1.8861937574160996

Epoch: 6| Step: 4
Training loss: 1.4023891687393188
Validation loss: 1.9046028519189486

Epoch: 6| Step: 5
Training loss: 1.2599990367889404
Validation loss: 1.8215572846833097

Epoch: 6| Step: 6
Training loss: 1.424676775932312
Validation loss: 1.8910718540991507

Epoch: 6| Step: 7
Training loss: 1.290841817855835
Validation loss: 1.8696904515707364

Epoch: 6| Step: 8
Training loss: 1.5919270515441895
Validation loss: 1.9225042417485227

Epoch: 6| Step: 9
Training loss: 1.0424308776855469
Validation loss: 1.9097788462074854

Epoch: 6| Step: 10
Training loss: 1.1236799955368042
Validation loss: 1.97974943858321

Epoch: 6| Step: 11
Training loss: 1.296558141708374
Validation loss: 1.8446152530690676

Epoch: 6| Step: 12
Training loss: 1.1160109043121338
Validation loss: 1.8472923976118847

Epoch: 6| Step: 13
Training loss: 1.6414580345153809
Validation loss: 1.8417298870701944

Epoch: 377| Step: 0
Training loss: 1.953824520111084
Validation loss: 1.869982252838791

Epoch: 6| Step: 1
Training loss: 1.4900643825531006
Validation loss: 1.8588279203702045

Epoch: 6| Step: 2
Training loss: 1.5133421421051025
Validation loss: 1.8164311532051332

Epoch: 6| Step: 3
Training loss: 1.437497854232788
Validation loss: 1.859214021313575

Epoch: 6| Step: 4
Training loss: 1.5019651651382446
Validation loss: 1.8378743164000972

Epoch: 6| Step: 5
Training loss: 0.9237161874771118
Validation loss: 1.8598190699854205

Epoch: 6| Step: 6
Training loss: 2.22446346282959
Validation loss: 1.822283644830027

Epoch: 6| Step: 7
Training loss: 1.346825361251831
Validation loss: 1.805794269807877

Epoch: 6| Step: 8
Training loss: 2.0430729389190674
Validation loss: 1.8885431469127696

Epoch: 6| Step: 9
Training loss: 1.646329641342163
Validation loss: 1.7940856384974655

Epoch: 6| Step: 10
Training loss: 0.7333004474639893
Validation loss: 1.8794302222549275

Epoch: 6| Step: 11
Training loss: 0.9107223153114319
Validation loss: 1.8670406905553674

Epoch: 6| Step: 12
Training loss: 1.1366193294525146
Validation loss: 1.8463225992777015

Epoch: 6| Step: 13
Training loss: 0.9560614824295044
Validation loss: 1.8653118482200048

Epoch: 378| Step: 0
Training loss: 1.0083119869232178
Validation loss: 1.8945915109367781

Epoch: 6| Step: 1
Training loss: 1.499480962753296
Validation loss: 1.8913137271840086

Epoch: 6| Step: 2
Training loss: 1.1659284830093384
Validation loss: 1.8873610945158108

Epoch: 6| Step: 3
Training loss: 2.162022113800049
Validation loss: 1.9050145636322677

Epoch: 6| Step: 4
Training loss: 1.1518454551696777
Validation loss: 1.8713336990725609

Epoch: 6| Step: 5
Training loss: 1.4196054935455322
Validation loss: 1.8760632520080895

Epoch: 6| Step: 6
Training loss: 0.9458996057510376
Validation loss: 1.827624221001902

Epoch: 6| Step: 7
Training loss: 1.283538818359375
Validation loss: 1.853543951947202

Epoch: 6| Step: 8
Training loss: 1.3320107460021973
Validation loss: 1.8638463507416427

Epoch: 6| Step: 9
Training loss: 1.6686228513717651
Validation loss: 1.8210262406256892

Epoch: 6| Step: 10
Training loss: 1.276910424232483
Validation loss: 1.8897075294166483

Epoch: 6| Step: 11
Training loss: 1.373774766921997
Validation loss: 1.8408239259514758

Epoch: 6| Step: 12
Training loss: 1.3711495399475098
Validation loss: 1.8136489622054561

Epoch: 6| Step: 13
Training loss: 1.4629520177841187
Validation loss: 1.7730102808244768

Epoch: 379| Step: 0
Training loss: 1.5499951839447021
Validation loss: 1.8775590081368723

Epoch: 6| Step: 1
Training loss: 1.1555384397506714
Validation loss: 1.819054013939314

Epoch: 6| Step: 2
Training loss: 1.110734462738037
Validation loss: 1.8559177767845891

Epoch: 6| Step: 3
Training loss: 1.2983607053756714
Validation loss: 1.832010099964757

Epoch: 6| Step: 4
Training loss: 1.8272309303283691
Validation loss: 1.8411946911965646

Epoch: 6| Step: 5
Training loss: 1.295371651649475
Validation loss: 1.8838045802167667

Epoch: 6| Step: 6
Training loss: 1.3798232078552246
Validation loss: 1.7926302712450746

Epoch: 6| Step: 7
Training loss: 1.1473498344421387
Validation loss: 1.8388492291973484

Epoch: 6| Step: 8
Training loss: 1.5214723348617554
Validation loss: 1.9092025936290782

Epoch: 6| Step: 9
Training loss: 1.5449458360671997
Validation loss: 1.8951258543998963

Epoch: 6| Step: 10
Training loss: 1.1887017488479614
Validation loss: 1.892037300653355

Epoch: 6| Step: 11
Training loss: 1.3973315954208374
Validation loss: 1.891689851719846

Epoch: 6| Step: 12
Training loss: 1.0748510360717773
Validation loss: 1.9740259942188059

Epoch: 6| Step: 13
Training loss: 2.0522892475128174
Validation loss: 1.8401332875733734

Epoch: 380| Step: 0
Training loss: 2.0695362091064453
Validation loss: 1.77884679584093

Epoch: 6| Step: 1
Training loss: 1.909376621246338
Validation loss: 1.8403714344065676

Epoch: 6| Step: 2
Training loss: 1.6282614469528198
Validation loss: 1.8726535074172481

Epoch: 6| Step: 3
Training loss: 1.2040209770202637
Validation loss: 1.8895542390884892

Epoch: 6| Step: 4
Training loss: 1.3360679149627686
Validation loss: 1.859807901484992

Epoch: 6| Step: 5
Training loss: 1.0395573377609253
Validation loss: 1.8630919071935839

Epoch: 6| Step: 6
Training loss: 0.7713409662246704
Validation loss: 1.8576250101930352

Epoch: 6| Step: 7
Training loss: 1.0359010696411133
Validation loss: 1.805253456997615

Epoch: 6| Step: 8
Training loss: 1.9194719791412354
Validation loss: 1.8204362315516318

Epoch: 6| Step: 9
Training loss: 1.3346025943756104
Validation loss: 1.9095042238953293

Epoch: 6| Step: 10
Training loss: 0.8537358045578003
Validation loss: 1.8765151218701435

Epoch: 6| Step: 11
Training loss: 1.74076509475708
Validation loss: 1.801491298983174

Epoch: 6| Step: 12
Training loss: 1.1711912155151367
Validation loss: 1.8380443767834735

Epoch: 6| Step: 13
Training loss: 1.8448213338851929
Validation loss: 1.8143394429196593

Epoch: 381| Step: 0
Training loss: 1.5111058950424194
Validation loss: 1.8608876441114692

Epoch: 6| Step: 1
Training loss: 1.7336034774780273
Validation loss: 1.8783394200827486

Epoch: 6| Step: 2
Training loss: 1.8664910793304443
Validation loss: 1.8979436851316882

Epoch: 6| Step: 3
Training loss: 1.9375624656677246
Validation loss: 1.8432699454727994

Epoch: 6| Step: 4
Training loss: 1.1887856721878052
Validation loss: 1.879282477081463

Epoch: 6| Step: 5
Training loss: 1.7274084091186523
Validation loss: 1.8239343422715382

Epoch: 6| Step: 6
Training loss: 1.2452538013458252
Validation loss: 1.9099422859889206

Epoch: 6| Step: 7
Training loss: 1.5535063743591309
Validation loss: 1.8590458951970583

Epoch: 6| Step: 8
Training loss: 1.4577312469482422
Validation loss: 1.8552013802272018

Epoch: 6| Step: 9
Training loss: 1.0177741050720215
Validation loss: 1.8435110481836463

Epoch: 6| Step: 10
Training loss: 0.6566815376281738
Validation loss: 1.9234346523079822

Epoch: 6| Step: 11
Training loss: 0.44831159710884094
Validation loss: 1.82382970599718

Epoch: 6| Step: 12
Training loss: 1.6646764278411865
Validation loss: 1.8592888642382879

Epoch: 6| Step: 13
Training loss: 0.7823355197906494
Validation loss: 1.8847284547744259

Epoch: 382| Step: 0
Training loss: 1.4428601264953613
Validation loss: 1.823327100405129

Epoch: 6| Step: 1
Training loss: 1.245024561882019
Validation loss: 1.8748355988533265

Epoch: 6| Step: 2
Training loss: 1.241768479347229
Validation loss: 1.837502969208584

Epoch: 6| Step: 3
Training loss: 1.1447391510009766
Validation loss: 1.8450811857818274

Epoch: 6| Step: 4
Training loss: 0.9821608662605286
Validation loss: 1.8155535831246326

Epoch: 6| Step: 5
Training loss: 1.6154834032058716
Validation loss: 1.7790600189598658

Epoch: 6| Step: 6
Training loss: 1.4583954811096191
Validation loss: 1.8615553404695244

Epoch: 6| Step: 7
Training loss: 1.3337650299072266
Validation loss: 1.8552622461831698

Epoch: 6| Step: 8
Training loss: 1.4268887042999268
Validation loss: 1.8092741248428181

Epoch: 6| Step: 9
Training loss: 1.768632411956787
Validation loss: 1.8210168782100882

Epoch: 6| Step: 10
Training loss: 1.2018837928771973
Validation loss: 1.838230682957557

Epoch: 6| Step: 11
Training loss: 1.3035218715667725
Validation loss: 1.8105932333136117

Epoch: 6| Step: 12
Training loss: 1.4995911121368408
Validation loss: 1.8729084319965814

Epoch: 6| Step: 13
Training loss: 1.7060177326202393
Validation loss: 1.8281321935756232

Epoch: 383| Step: 0
Training loss: 1.0695043802261353
Validation loss: 1.8004462308781122

Epoch: 6| Step: 1
Training loss: 1.278967022895813
Validation loss: 1.8226703495107672

Epoch: 6| Step: 2
Training loss: 0.7635303139686584
Validation loss: 1.84699079298204

Epoch: 6| Step: 3
Training loss: 0.8532236218452454
Validation loss: 1.781892494488788

Epoch: 6| Step: 4
Training loss: 2.3922231197357178
Validation loss: 1.823134369747613

Epoch: 6| Step: 5
Training loss: 1.4926302433013916
Validation loss: 1.7883590241914153

Epoch: 6| Step: 6
Training loss: 1.1561909914016724
Validation loss: 1.8417081525248866

Epoch: 6| Step: 7
Training loss: 1.2395994663238525
Validation loss: 1.8497287534898328

Epoch: 6| Step: 8
Training loss: 1.5392396450042725
Validation loss: 1.8388832089721516

Epoch: 6| Step: 9
Training loss: 1.142446517944336
Validation loss: 1.8030696402313888

Epoch: 6| Step: 10
Training loss: 1.5101258754730225
Validation loss: 1.799333518551242

Epoch: 6| Step: 11
Training loss: 1.2119026184082031
Validation loss: 1.8501876669545327

Epoch: 6| Step: 12
Training loss: 1.9356439113616943
Validation loss: 1.7862879512130574

Epoch: 6| Step: 13
Training loss: 0.9925855994224548
Validation loss: 1.8369473065099409

Epoch: 384| Step: 0
Training loss: 1.439218521118164
Validation loss: 1.878400146320302

Epoch: 6| Step: 1
Training loss: 1.1977304220199585
Validation loss: 1.8649264958596998

Epoch: 6| Step: 2
Training loss: 1.471954584121704
Validation loss: 1.865927650082496

Epoch: 6| Step: 3
Training loss: 1.3302454948425293
Validation loss: 1.8273855883588073

Epoch: 6| Step: 4
Training loss: 1.3299070596694946
Validation loss: 1.8267888048643708

Epoch: 6| Step: 5
Training loss: 1.1352782249450684
Validation loss: 1.8287984325039772

Epoch: 6| Step: 6
Training loss: 1.6548411846160889
Validation loss: 1.8512135731276644

Epoch: 6| Step: 7
Training loss: 1.461828351020813
Validation loss: 1.925578522425826

Epoch: 6| Step: 8
Training loss: 1.7324650287628174
Validation loss: 1.8506343800534484

Epoch: 6| Step: 9
Training loss: 1.342886209487915
Validation loss: 1.8528987925539735

Epoch: 6| Step: 10
Training loss: 1.5196785926818848
Validation loss: 1.907447761104953

Epoch: 6| Step: 11
Training loss: 0.7442119717597961
Validation loss: 1.78759676923034

Epoch: 6| Step: 12
Training loss: 1.7713191509246826
Validation loss: 1.8914289948760823

Epoch: 6| Step: 13
Training loss: 0.7163094282150269
Validation loss: 1.8541382423011206

Epoch: 385| Step: 0
Training loss: 1.2056300640106201
Validation loss: 1.8588424562126078

Epoch: 6| Step: 1
Training loss: 1.936901330947876
Validation loss: 1.8859882995646486

Epoch: 6| Step: 2
Training loss: 1.5198469161987305
Validation loss: 1.8302545867940432

Epoch: 6| Step: 3
Training loss: 1.6319688558578491
Validation loss: 1.8102048109936457

Epoch: 6| Step: 4
Training loss: 0.9188827276229858
Validation loss: 1.815418920209331

Epoch: 6| Step: 5
Training loss: 1.1423786878585815
Validation loss: 1.8551643356200187

Epoch: 6| Step: 6
Training loss: 1.9190170764923096
Validation loss: 1.8249162435531616

Epoch: 6| Step: 7
Training loss: 1.2600109577178955
Validation loss: 1.8210582758790703

Epoch: 6| Step: 8
Training loss: 1.087276816368103
Validation loss: 1.8262659721477057

Epoch: 6| Step: 9
Training loss: 1.1192010641098022
Validation loss: 1.776400032863822

Epoch: 6| Step: 10
Training loss: 1.294931411743164
Validation loss: 1.846549707074319

Epoch: 6| Step: 11
Training loss: 1.2106335163116455
Validation loss: 1.8576887884447653

Epoch: 6| Step: 12
Training loss: 2.0285258293151855
Validation loss: 1.815811139281078

Epoch: 6| Step: 13
Training loss: 0.7249983549118042
Validation loss: 1.8610066624097927

Epoch: 386| Step: 0
Training loss: 1.5019367933273315
Validation loss: 1.9002614277665333

Epoch: 6| Step: 1
Training loss: 1.1025770902633667
Validation loss: 1.8591223045061993

Epoch: 6| Step: 2
Training loss: 1.1363036632537842
Validation loss: 1.8046382191360637

Epoch: 6| Step: 3
Training loss: 1.301398515701294
Validation loss: 1.8079982944714126

Epoch: 6| Step: 4
Training loss: 1.0002737045288086
Validation loss: 1.8140675688302645

Epoch: 6| Step: 5
Training loss: 1.5547552108764648
Validation loss: 1.8800304538460189

Epoch: 6| Step: 6
Training loss: 1.4452099800109863
Validation loss: 1.773073891157745

Epoch: 6| Step: 7
Training loss: 1.2552543878555298
Validation loss: 1.8361243253113122

Epoch: 6| Step: 8
Training loss: 0.6092217564582825
Validation loss: 1.8786904132494362

Epoch: 6| Step: 9
Training loss: 1.3826367855072021
Validation loss: 1.8832235426031134

Epoch: 6| Step: 10
Training loss: 2.0285024642944336
Validation loss: 1.8999543318184473

Epoch: 6| Step: 11
Training loss: 1.7849361896514893
Validation loss: 1.8379247355204757

Epoch: 6| Step: 12
Training loss: 1.1854593753814697
Validation loss: 1.877266881286457

Epoch: 6| Step: 13
Training loss: 1.5919156074523926
Validation loss: 1.87666569986651

Epoch: 387| Step: 0
Training loss: 1.6797432899475098
Validation loss: 1.972383617072977

Epoch: 6| Step: 1
Training loss: 0.9957371950149536
Validation loss: 1.915441713025493

Epoch: 6| Step: 2
Training loss: 0.8944764137268066
Validation loss: 1.8625140702852638

Epoch: 6| Step: 3
Training loss: 1.357362985610962
Validation loss: 1.8620502461669266

Epoch: 6| Step: 4
Training loss: 1.4434988498687744
Validation loss: 1.8694500089973531

Epoch: 6| Step: 5
Training loss: 1.5941739082336426
Validation loss: 1.9023326289269231

Epoch: 6| Step: 6
Training loss: 1.1846144199371338
Validation loss: 1.8060232144530102

Epoch: 6| Step: 7
Training loss: 1.5496437549591064
Validation loss: 1.8138027575708204

Epoch: 6| Step: 8
Training loss: 1.678105354309082
Validation loss: 1.8194157602966472

Epoch: 6| Step: 9
Training loss: 1.4024957418441772
Validation loss: 1.8147733544790616

Epoch: 6| Step: 10
Training loss: 1.3657333850860596
Validation loss: 1.8831373568504088

Epoch: 6| Step: 11
Training loss: 0.9226711988449097
Validation loss: 1.8165043579634799

Epoch: 6| Step: 12
Training loss: 1.4626655578613281
Validation loss: 1.8367697820868543

Epoch: 6| Step: 13
Training loss: 1.3978333473205566
Validation loss: 1.8600622671906666

Epoch: 388| Step: 0
Training loss: 0.8169554471969604
Validation loss: 1.8360790591086111

Epoch: 6| Step: 1
Training loss: 1.376699686050415
Validation loss: 1.814348501543845

Epoch: 6| Step: 2
Training loss: 1.8207184076309204
Validation loss: 1.811532856315695

Epoch: 6| Step: 3
Training loss: 0.8327825665473938
Validation loss: 1.8723434094459779

Epoch: 6| Step: 4
Training loss: 0.9571952819824219
Validation loss: 1.763588684861378

Epoch: 6| Step: 5
Training loss: 1.7863941192626953
Validation loss: 1.850025233402047

Epoch: 6| Step: 6
Training loss: 1.4907047748565674
Validation loss: 1.8329237199598742

Epoch: 6| Step: 7
Training loss: 0.8882389068603516
Validation loss: 1.8419976324163458

Epoch: 6| Step: 8
Training loss: 1.3966450691223145
Validation loss: 1.8668237040119786

Epoch: 6| Step: 9
Training loss: 0.8491076827049255
Validation loss: 1.8737677604921403

Epoch: 6| Step: 10
Training loss: 1.8106694221496582
Validation loss: 1.8121589499135171

Epoch: 6| Step: 11
Training loss: 1.523395299911499
Validation loss: 1.8851590759010726

Epoch: 6| Step: 12
Training loss: 1.5216472148895264
Validation loss: 1.7897569517935477

Epoch: 6| Step: 13
Training loss: 1.867613673210144
Validation loss: 1.8104676303043161

Epoch: 389| Step: 0
Training loss: 1.259072184562683
Validation loss: 1.900581277826781

Epoch: 6| Step: 1
Training loss: 1.2290329933166504
Validation loss: 1.8845016879420127

Epoch: 6| Step: 2
Training loss: 1.1400530338287354
Validation loss: 1.9211802046786073

Epoch: 6| Step: 3
Training loss: 1.5680732727050781
Validation loss: 1.9062634885952037

Epoch: 6| Step: 4
Training loss: 1.022270917892456
Validation loss: 1.8205867480206233

Epoch: 6| Step: 5
Training loss: 1.7870962619781494
Validation loss: 1.8319285736289075

Epoch: 6| Step: 6
Training loss: 1.519419550895691
Validation loss: 1.8751075472882999

Epoch: 6| Step: 7
Training loss: 1.4546031951904297
Validation loss: 1.8935584009334605

Epoch: 6| Step: 8
Training loss: 1.2811002731323242
Validation loss: 1.8225168835732244

Epoch: 6| Step: 9
Training loss: 1.4786176681518555
Validation loss: 1.8325550786910518

Epoch: 6| Step: 10
Training loss: 1.5257513523101807
Validation loss: 1.8172635109193864

Epoch: 6| Step: 11
Training loss: 1.4728031158447266
Validation loss: 1.8253064642670334

Epoch: 6| Step: 12
Training loss: 1.1542694568634033
Validation loss: 1.8009926221703971

Epoch: 6| Step: 13
Training loss: 1.2632588148117065
Validation loss: 1.8056534862005582

Epoch: 390| Step: 0
Training loss: 1.4977670907974243
Validation loss: 1.8544994708030456

Epoch: 6| Step: 1
Training loss: 1.069046974182129
Validation loss: 1.8380832044027184

Epoch: 6| Step: 2
Training loss: 1.173280119895935
Validation loss: 1.8888229990518222

Epoch: 6| Step: 3
Training loss: 0.8731672167778015
Validation loss: 1.9025287205173123

Epoch: 6| Step: 4
Training loss: 1.1281675100326538
Validation loss: 1.84904876319311

Epoch: 6| Step: 5
Training loss: 0.6724478006362915
Validation loss: 1.8358016232008576

Epoch: 6| Step: 6
Training loss: 1.4510703086853027
Validation loss: 1.8675809957647835

Epoch: 6| Step: 7
Training loss: 1.9036513566970825
Validation loss: 1.8552107695610291

Epoch: 6| Step: 8
Training loss: 1.3423268795013428
Validation loss: 1.8491024817189863

Epoch: 6| Step: 9
Training loss: 1.9200142621994019
Validation loss: 1.854903414685239

Epoch: 6| Step: 10
Training loss: 2.181931495666504
Validation loss: 1.868397202543033

Epoch: 6| Step: 11
Training loss: 0.9728909134864807
Validation loss: 1.95691696546411

Epoch: 6| Step: 12
Training loss: 1.0134824514389038
Validation loss: 1.900483262154364

Epoch: 6| Step: 13
Training loss: 1.5825788974761963
Validation loss: 1.9380193859018304

Epoch: 391| Step: 0
Training loss: 1.6454185247421265
Validation loss: 1.9423663077815887

Epoch: 6| Step: 1
Training loss: 0.9684624671936035
Validation loss: 1.9210336644162413

Epoch: 6| Step: 2
Training loss: 0.956121027469635
Validation loss: 1.8280004942288963

Epoch: 6| Step: 3
Training loss: 1.852060317993164
Validation loss: 1.8422302469130485

Epoch: 6| Step: 4
Training loss: 1.1726932525634766
Validation loss: 1.9049206856758363

Epoch: 6| Step: 5
Training loss: 1.116905927658081
Validation loss: 1.8947228488101755

Epoch: 6| Step: 6
Training loss: 1.4547089338302612
Validation loss: 1.8779241026088755

Epoch: 6| Step: 7
Training loss: 1.4471147060394287
Validation loss: 1.8270120095181208

Epoch: 6| Step: 8
Training loss: 2.3479113578796387
Validation loss: 1.793976451760979

Epoch: 6| Step: 9
Training loss: 1.1798444986343384
Validation loss: 1.822587110662973

Epoch: 6| Step: 10
Training loss: 1.0320708751678467
Validation loss: 1.8411013900592763

Epoch: 6| Step: 11
Training loss: 0.934105634689331
Validation loss: 1.864585429109553

Epoch: 6| Step: 12
Training loss: 1.3677685260772705
Validation loss: 1.8635965290889944

Epoch: 6| Step: 13
Training loss: 1.6716524362564087
Validation loss: 1.8938463246950539

Epoch: 392| Step: 0
Training loss: 1.2953245639801025
Validation loss: 1.8463861391108523

Epoch: 6| Step: 1
Training loss: 1.0493649244308472
Validation loss: 1.7647684543363509

Epoch: 6| Step: 2
Training loss: 1.0756793022155762
Validation loss: 1.8077784225504885

Epoch: 6| Step: 3
Training loss: 1.0255625247955322
Validation loss: 1.87045156955719

Epoch: 6| Step: 4
Training loss: 2.2427561283111572
Validation loss: 1.865643229535831

Epoch: 6| Step: 5
Training loss: 1.1157817840576172
Validation loss: 1.8561062658986738

Epoch: 6| Step: 6
Training loss: 1.642716884613037
Validation loss: 1.940041890708349

Epoch: 6| Step: 7
Training loss: 1.1578360795974731
Validation loss: 1.8672236550238825

Epoch: 6| Step: 8
Training loss: 1.5703709125518799
Validation loss: 1.8435803215990785

Epoch: 6| Step: 9
Training loss: 2.098423719406128
Validation loss: 1.8892957292577273

Epoch: 6| Step: 10
Training loss: 1.3790805339813232
Validation loss: 1.8245985097782587

Epoch: 6| Step: 11
Training loss: 0.8860684037208557
Validation loss: 1.8630791428268596

Epoch: 6| Step: 12
Training loss: 1.4447591304779053
Validation loss: 1.8928804602674258

Epoch: 6| Step: 13
Training loss: 1.4605764150619507
Validation loss: 1.907878847532375

Epoch: 393| Step: 0
Training loss: 1.5643374919891357
Validation loss: 1.8789045567153602

Epoch: 6| Step: 1
Training loss: 0.9728584289550781
Validation loss: 1.8951372254279353

Epoch: 6| Step: 2
Training loss: 1.4394397735595703
Validation loss: 1.8430622495630735

Epoch: 6| Step: 3
Training loss: 0.6788051128387451
Validation loss: 1.8090244621358893

Epoch: 6| Step: 4
Training loss: 1.2173583507537842
Validation loss: 1.7793232305075533

Epoch: 6| Step: 5
Training loss: 0.9551514983177185
Validation loss: 1.9039911416269117

Epoch: 6| Step: 6
Training loss: 2.0928499698638916
Validation loss: 1.7613064012219828

Epoch: 6| Step: 7
Training loss: 2.072406053543091
Validation loss: 1.860833252629926

Epoch: 6| Step: 8
Training loss: 1.3192138671875
Validation loss: 1.844713403332618

Epoch: 6| Step: 9
Training loss: 1.4747259616851807
Validation loss: 1.8090455250073505

Epoch: 6| Step: 10
Training loss: 1.2575236558914185
Validation loss: 1.8246471266592703

Epoch: 6| Step: 11
Training loss: 1.4206500053405762
Validation loss: 1.8352542641342326

Epoch: 6| Step: 12
Training loss: 1.001515507698059
Validation loss: 1.8458272898068993

Epoch: 6| Step: 13
Training loss: 1.3125805854797363
Validation loss: 1.7414850233703532

Epoch: 394| Step: 0
Training loss: 1.1103675365447998
Validation loss: 1.8179087728582404

Epoch: 6| Step: 1
Training loss: 1.3624932765960693
Validation loss: 1.7577542284483552

Epoch: 6| Step: 2
Training loss: 0.7733340263366699
Validation loss: 1.7950513747430616

Epoch: 6| Step: 3
Training loss: 1.8208138942718506
Validation loss: 1.8651196456724597

Epoch: 6| Step: 4
Training loss: 1.333935260772705
Validation loss: 1.7746819962737381

Epoch: 6| Step: 5
Training loss: 1.2103986740112305
Validation loss: 1.8392013695932203

Epoch: 6| Step: 6
Training loss: 2.0516579151153564
Validation loss: 1.870760756154214

Epoch: 6| Step: 7
Training loss: 1.638055443763733
Validation loss: 1.8603308995564778

Epoch: 6| Step: 8
Training loss: 1.1897013187408447
Validation loss: 1.844653114195793

Epoch: 6| Step: 9
Training loss: 1.5978577136993408
Validation loss: 1.9201362427844797

Epoch: 6| Step: 10
Training loss: 0.9185104370117188
Validation loss: 1.8187011980241345

Epoch: 6| Step: 11
Training loss: 1.0566447973251343
Validation loss: 1.857118224584928

Epoch: 6| Step: 12
Training loss: 1.6356174945831299
Validation loss: 1.833818006259139

Epoch: 6| Step: 13
Training loss: 1.9535048007965088
Validation loss: 1.7651362572946856

Epoch: 395| Step: 0
Training loss: 1.2302643060684204
Validation loss: 1.8512394043707079

Epoch: 6| Step: 1
Training loss: 1.9826892614364624
Validation loss: 1.8598981159989552

Epoch: 6| Step: 2
Training loss: 1.3912646770477295
Validation loss: 1.8163725163346978

Epoch: 6| Step: 3
Training loss: 1.0262207984924316
Validation loss: 1.862848861243135

Epoch: 6| Step: 4
Training loss: 2.15309476852417
Validation loss: 1.8248694712115872

Epoch: 6| Step: 5
Training loss: 1.3309838771820068
Validation loss: 1.8812129625710108

Epoch: 6| Step: 6
Training loss: 1.0297269821166992
Validation loss: 1.7982553179546068

Epoch: 6| Step: 7
Training loss: 1.4468553066253662
Validation loss: 1.8937532363399383

Epoch: 6| Step: 8
Training loss: 1.080000400543213
Validation loss: 1.801230292166433

Epoch: 6| Step: 9
Training loss: 1.0283080339431763
Validation loss: 1.870142057377805

Epoch: 6| Step: 10
Training loss: 1.681020736694336
Validation loss: 1.8774641918879684

Epoch: 6| Step: 11
Training loss: 1.3736045360565186
Validation loss: 1.8393063724681895

Epoch: 6| Step: 12
Training loss: 0.6651134490966797
Validation loss: 1.8511870535471107

Epoch: 6| Step: 13
Training loss: 1.6230074167251587
Validation loss: 1.8130326527421192

Epoch: 396| Step: 0
Training loss: 0.8200335502624512
Validation loss: 1.8244134418426021

Epoch: 6| Step: 1
Training loss: 1.8353487253189087
Validation loss: 1.8037017263391966

Epoch: 6| Step: 2
Training loss: 1.2831164598464966
Validation loss: 1.8203924086786085

Epoch: 6| Step: 3
Training loss: 1.4654350280761719
Validation loss: 1.8897898376628917

Epoch: 6| Step: 4
Training loss: 1.5730153322219849
Validation loss: 1.8386327502548054

Epoch: 6| Step: 5
Training loss: 1.4114742279052734
Validation loss: 1.8293514405527422

Epoch: 6| Step: 6
Training loss: 1.8838294744491577
Validation loss: 1.8224945965633597

Epoch: 6| Step: 7
Training loss: 1.6848015785217285
Validation loss: 1.7882054345582121

Epoch: 6| Step: 8
Training loss: 0.8995644450187683
Validation loss: 1.856027082730365

Epoch: 6| Step: 9
Training loss: 1.0022015571594238
Validation loss: 1.9198444530528078

Epoch: 6| Step: 10
Training loss: 1.2059766054153442
Validation loss: 1.879511147417048

Epoch: 6| Step: 11
Training loss: 0.8273086547851562
Validation loss: 1.8849621011364845

Epoch: 6| Step: 12
Training loss: 1.1239416599273682
Validation loss: 1.8227340072713873

Epoch: 6| Step: 13
Training loss: 1.6861441135406494
Validation loss: 1.8719051678975422

Epoch: 397| Step: 0
Training loss: 1.5903894901275635
Validation loss: 1.8064701813523487

Epoch: 6| Step: 1
Training loss: 1.236115574836731
Validation loss: 1.8873661538606048

Epoch: 6| Step: 2
Training loss: 1.3245176076889038
Validation loss: 1.8733733238712433

Epoch: 6| Step: 3
Training loss: 1.241140365600586
Validation loss: 1.8113905563149402

Epoch: 6| Step: 4
Training loss: 1.2564609050750732
Validation loss: 1.8484950898796

Epoch: 6| Step: 5
Training loss: 1.6113353967666626
Validation loss: 1.861306325081856

Epoch: 6| Step: 6
Training loss: 1.216372013092041
Validation loss: 1.9041949638756372

Epoch: 6| Step: 7
Training loss: 1.0802063941955566
Validation loss: 1.821725606918335

Epoch: 6| Step: 8
Training loss: 1.4985506534576416
Validation loss: 1.775974678736861

Epoch: 6| Step: 9
Training loss: 1.5979299545288086
Validation loss: 1.8780647785432878

Epoch: 6| Step: 10
Training loss: 1.1846623420715332
Validation loss: 1.8090799239373976

Epoch: 6| Step: 11
Training loss: 1.167096495628357
Validation loss: 1.8177853438162035

Epoch: 6| Step: 12
Training loss: 1.4321284294128418
Validation loss: 1.8461945262006534

Epoch: 6| Step: 13
Training loss: 1.0522961616516113
Validation loss: 1.8522397856558523

Epoch: 398| Step: 0
Training loss: 1.3827455043792725
Validation loss: 1.80143174048393

Epoch: 6| Step: 1
Training loss: 1.0663527250289917
Validation loss: 1.8486075106487478

Epoch: 6| Step: 2
Training loss: 1.1653149127960205
Validation loss: 1.7673409446593253

Epoch: 6| Step: 3
Training loss: 1.6190333366394043
Validation loss: 1.8591879760065386

Epoch: 6| Step: 4
Training loss: 1.554381251335144
Validation loss: 1.7975619749356342

Epoch: 6| Step: 5
Training loss: 1.4597361087799072
Validation loss: 1.8601693632782146

Epoch: 6| Step: 6
Training loss: 1.5404560565948486
Validation loss: 1.7980609145215762

Epoch: 6| Step: 7
Training loss: 0.9325214624404907
Validation loss: 1.844090264330628

Epoch: 6| Step: 8
Training loss: 1.7552788257598877
Validation loss: 1.794347551561171

Epoch: 6| Step: 9
Training loss: 1.8315640687942505
Validation loss: 1.8142219717784593

Epoch: 6| Step: 10
Training loss: 1.444727897644043
Validation loss: 1.7893905332011562

Epoch: 6| Step: 11
Training loss: 1.1094894409179688
Validation loss: 1.8571635779514108

Epoch: 6| Step: 12
Training loss: 0.9266483783721924
Validation loss: 1.8304970392616846

Epoch: 6| Step: 13
Training loss: 1.347720980644226
Validation loss: 1.8347124912405526

Epoch: 399| Step: 0
Training loss: 1.0167236328125
Validation loss: 1.7965631818258634

Epoch: 6| Step: 1
Training loss: 1.2352057695388794
Validation loss: 1.7825686111245105

Epoch: 6| Step: 2
Training loss: 1.5442839860916138
Validation loss: 1.8479665325533958

Epoch: 6| Step: 3
Training loss: 1.1223125457763672
Validation loss: 1.8616622673567904

Epoch: 6| Step: 4
Training loss: 1.5966709852218628
Validation loss: 1.838770116529157

Epoch: 6| Step: 5
Training loss: 1.752143383026123
Validation loss: 1.8134695265882759

Epoch: 6| Step: 6
Training loss: 1.3091678619384766
Validation loss: 1.8339098102302962

Epoch: 6| Step: 7
Training loss: 1.308347225189209
Validation loss: 1.8792495701902656

Epoch: 6| Step: 8
Training loss: 1.2570576667785645
Validation loss: 1.788728452497913

Epoch: 6| Step: 9
Training loss: 1.1118137836456299
Validation loss: 1.7691371927979171

Epoch: 6| Step: 10
Training loss: 2.037226438522339
Validation loss: 1.7943321556173346

Epoch: 6| Step: 11
Training loss: 1.4075130224227905
Validation loss: 1.822693367158213

Epoch: 6| Step: 12
Training loss: 0.8633444905281067
Validation loss: 1.7760489063878213

Epoch: 6| Step: 13
Training loss: 1.3418081998825073
Validation loss: 1.8631961576400264

Epoch: 400| Step: 0
Training loss: 1.1352572441101074
Validation loss: 1.7877861222913187

Epoch: 6| Step: 1
Training loss: 1.6182546615600586
Validation loss: 1.805097500483195

Epoch: 6| Step: 2
Training loss: 1.8567403554916382
Validation loss: 1.8318658900517288

Epoch: 6| Step: 3
Training loss: 1.5805855989456177
Validation loss: 1.8641861818170036

Epoch: 6| Step: 4
Training loss: 1.9771753549575806
Validation loss: 1.8376129032463155

Epoch: 6| Step: 5
Training loss: 1.676755428314209
Validation loss: 1.7874842484792073

Epoch: 6| Step: 6
Training loss: 1.044162631034851
Validation loss: 1.837826733948082

Epoch: 6| Step: 7
Training loss: 1.2969927787780762
Validation loss: 1.8195630940057899

Epoch: 6| Step: 8
Training loss: 1.0326424837112427
Validation loss: 1.7866404620550012

Epoch: 6| Step: 9
Training loss: 0.9587920904159546
Validation loss: 1.8725001991436045

Epoch: 6| Step: 10
Training loss: 1.4689360857009888
Validation loss: 1.8190195086181804

Epoch: 6| Step: 11
Training loss: 1.234621524810791
Validation loss: 1.832272901329943

Epoch: 6| Step: 12
Training loss: 1.4400663375854492
Validation loss: 1.8804529251590851

Epoch: 6| Step: 13
Training loss: 1.0207849740982056
Validation loss: 1.806954986305647

Epoch: 401| Step: 0
Training loss: 1.7405426502227783
Validation loss: 1.8582277631246915

Epoch: 6| Step: 1
Training loss: 1.1880803108215332
Validation loss: 1.827250729324997

Epoch: 6| Step: 2
Training loss: 1.19462251663208
Validation loss: 1.7781721507349322

Epoch: 6| Step: 3
Training loss: 1.206563949584961
Validation loss: 1.86664786518261

Epoch: 6| Step: 4
Training loss: 1.341457724571228
Validation loss: 1.8597174767524964

Epoch: 6| Step: 5
Training loss: 1.0765085220336914
Validation loss: 1.8409813334864955

Epoch: 6| Step: 6
Training loss: 1.4060397148132324
Validation loss: 1.8489562875481063

Epoch: 6| Step: 7
Training loss: 0.8606817722320557
Validation loss: 1.8418840195543023

Epoch: 6| Step: 8
Training loss: 1.6124993562698364
Validation loss: 1.9210642435217415

Epoch: 6| Step: 9
Training loss: 1.7932935953140259
Validation loss: 1.8797953000632666

Epoch: 6| Step: 10
Training loss: 1.6533896923065186
Validation loss: 1.8324220872694446

Epoch: 6| Step: 11
Training loss: 0.8640295267105103
Validation loss: 1.8037511097487582

Epoch: 6| Step: 12
Training loss: 1.381581425666809
Validation loss: 1.8501569173669303

Epoch: 6| Step: 13
Training loss: 0.9603909254074097
Validation loss: 1.8114165747037498

Epoch: 402| Step: 0
Training loss: 1.722205400466919
Validation loss: 1.859966072984921

Epoch: 6| Step: 1
Training loss: 1.4167377948760986
Validation loss: 1.8600169638151764

Epoch: 6| Step: 2
Training loss: 1.0143578052520752
Validation loss: 1.7976044544609644

Epoch: 6| Step: 3
Training loss: 1.2746779918670654
Validation loss: 1.8230016641719367

Epoch: 6| Step: 4
Training loss: 1.492460012435913
Validation loss: 1.8342453766894597

Epoch: 6| Step: 5
Training loss: 1.3560638427734375
Validation loss: 1.859458323447935

Epoch: 6| Step: 6
Training loss: 1.3385415077209473
Validation loss: 1.7576574971598964

Epoch: 6| Step: 7
Training loss: 1.700418472290039
Validation loss: 1.8111740709632955

Epoch: 6| Step: 8
Training loss: 1.2909305095672607
Validation loss: 1.8652229924355783

Epoch: 6| Step: 9
Training loss: 1.231888771057129
Validation loss: 1.8222065228287891

Epoch: 6| Step: 10
Training loss: 0.872465968132019
Validation loss: 1.839336633682251

Epoch: 6| Step: 11
Training loss: 1.42659330368042
Validation loss: 1.868587229841499

Epoch: 6| Step: 12
Training loss: 1.3949865102767944
Validation loss: 1.807202059735534

Epoch: 6| Step: 13
Training loss: 0.8716251254081726
Validation loss: 1.8361532829141105

Epoch: 403| Step: 0
Training loss: 1.157266616821289
Validation loss: 1.8112868596148748

Epoch: 6| Step: 1
Training loss: 1.223010540008545
Validation loss: 1.8731588945593884

Epoch: 6| Step: 2
Training loss: 1.4202220439910889
Validation loss: 1.7912073827558948

Epoch: 6| Step: 3
Training loss: 1.0471763610839844
Validation loss: 1.7888782793475735

Epoch: 6| Step: 4
Training loss: 1.4895775318145752
Validation loss: 1.8213818996183333

Epoch: 6| Step: 5
Training loss: 2.2779715061187744
Validation loss: 1.8849504634898195

Epoch: 6| Step: 6
Training loss: 1.0651357173919678
Validation loss: 1.8376792220659153

Epoch: 6| Step: 7
Training loss: 0.8884710073471069
Validation loss: 1.8567651702511696

Epoch: 6| Step: 8
Training loss: 1.1488691568374634
Validation loss: 1.8909799668096727

Epoch: 6| Step: 9
Training loss: 1.1879812479019165
Validation loss: 1.8240448800466393

Epoch: 6| Step: 10
Training loss: 1.0565340518951416
Validation loss: 1.7738880559962282

Epoch: 6| Step: 11
Training loss: 1.0088051557540894
Validation loss: 1.818695750287784

Epoch: 6| Step: 12
Training loss: 1.7633216381072998
Validation loss: 1.8123293666429416

Epoch: 6| Step: 13
Training loss: 1.687849521636963
Validation loss: 1.8462381926915978

Epoch: 404| Step: 0
Training loss: 1.3669979572296143
Validation loss: 1.866165840497581

Epoch: 6| Step: 1
Training loss: 1.347421646118164
Validation loss: 1.7780168133397256

Epoch: 6| Step: 2
Training loss: 1.761920690536499
Validation loss: 1.8151463359914801

Epoch: 6| Step: 3
Training loss: 1.119781732559204
Validation loss: 1.8144678441427087

Epoch: 6| Step: 4
Training loss: 1.5832219123840332
Validation loss: 1.7723005215326946

Epoch: 6| Step: 5
Training loss: 1.4136147499084473
Validation loss: 1.826737473087926

Epoch: 6| Step: 6
Training loss: 1.3889739513397217
Validation loss: 1.8347867932370914

Epoch: 6| Step: 7
Training loss: 1.4640140533447266
Validation loss: 1.786432611045017

Epoch: 6| Step: 8
Training loss: 1.488037109375
Validation loss: 1.808783031279041

Epoch: 6| Step: 9
Training loss: 0.9239521622657776
Validation loss: 1.7915425659507833

Epoch: 6| Step: 10
Training loss: 0.9284383058547974
Validation loss: 1.8710323097885295

Epoch: 6| Step: 11
Training loss: 1.3781285285949707
Validation loss: 1.8204155737353909

Epoch: 6| Step: 12
Training loss: 1.2685952186584473
Validation loss: 1.8483231477839972

Epoch: 6| Step: 13
Training loss: 0.9667640328407288
Validation loss: 1.8694190197093512

Epoch: 405| Step: 0
Training loss: 0.7461014986038208
Validation loss: 1.8470175061174618

Epoch: 6| Step: 1
Training loss: 0.7339946627616882
Validation loss: 1.8546425379732603

Epoch: 6| Step: 2
Training loss: 1.3168047666549683
Validation loss: 1.8399199157632806

Epoch: 6| Step: 3
Training loss: 1.71644926071167
Validation loss: 1.8712394570791593

Epoch: 6| Step: 4
Training loss: 1.0322790145874023
Validation loss: 1.7796458813451952

Epoch: 6| Step: 5
Training loss: 1.7872281074523926
Validation loss: 1.8199797061181837

Epoch: 6| Step: 6
Training loss: 1.1254537105560303
Validation loss: 1.8093728326982068

Epoch: 6| Step: 7
Training loss: 1.4127087593078613
Validation loss: 1.809282111865218

Epoch: 6| Step: 8
Training loss: 1.9479162693023682
Validation loss: 1.8588029543558757

Epoch: 6| Step: 9
Training loss: 1.4734742641448975
Validation loss: 1.7981576073554255

Epoch: 6| Step: 10
Training loss: 1.3043806552886963
Validation loss: 1.819954792658488

Epoch: 6| Step: 11
Training loss: 1.412925124168396
Validation loss: 1.829890933088077

Epoch: 6| Step: 12
Training loss: 1.0263187885284424
Validation loss: 1.822604981801843

Epoch: 6| Step: 13
Training loss: 2.1470305919647217
Validation loss: 1.8517563650684972

Epoch: 406| Step: 0
Training loss: 1.228440761566162
Validation loss: 1.778822136181657

Epoch: 6| Step: 1
Training loss: 1.3689191341400146
Validation loss: 1.8707482366151706

Epoch: 6| Step: 2
Training loss: 1.177361249923706
Validation loss: 1.7865218372755154

Epoch: 6| Step: 3
Training loss: 0.7775421738624573
Validation loss: 1.89631494527222

Epoch: 6| Step: 4
Training loss: 1.2823832035064697
Validation loss: 1.8865796853137273

Epoch: 6| Step: 5
Training loss: 1.4687130451202393
Validation loss: 1.8458065102177281

Epoch: 6| Step: 6
Training loss: 0.9257497787475586
Validation loss: 1.828013834132943

Epoch: 6| Step: 7
Training loss: 1.9988553524017334
Validation loss: 1.8858115096246042

Epoch: 6| Step: 8
Training loss: 1.038758397102356
Validation loss: 1.9009325094120477

Epoch: 6| Step: 9
Training loss: 1.1681369543075562
Validation loss: 1.8634705146153767

Epoch: 6| Step: 10
Training loss: 1.5439021587371826
Validation loss: 1.8575993763503207

Epoch: 6| Step: 11
Training loss: 1.3888992071151733
Validation loss: 1.7981882172246133

Epoch: 6| Step: 12
Training loss: 1.944388508796692
Validation loss: 1.9086021274648688

Epoch: 6| Step: 13
Training loss: 1.0095893144607544
Validation loss: 1.8230914479942733

Epoch: 407| Step: 0
Training loss: 1.3444523811340332
Validation loss: 1.9060925476012691

Epoch: 6| Step: 1
Training loss: 1.7745044231414795
Validation loss: 1.8346754966243621

Epoch: 6| Step: 2
Training loss: 2.0006494522094727
Validation loss: 1.8453869204367361

Epoch: 6| Step: 3
Training loss: 1.2436847686767578
Validation loss: 1.8107051823728828

Epoch: 6| Step: 4
Training loss: 1.2117891311645508
Validation loss: 1.8565321404446837

Epoch: 6| Step: 5
Training loss: 1.1800578832626343
Validation loss: 1.8344193068883752

Epoch: 6| Step: 6
Training loss: 1.0177488327026367
Validation loss: 1.8368406129139725

Epoch: 6| Step: 7
Training loss: 1.3344640731811523
Validation loss: 1.8057355188554334

Epoch: 6| Step: 8
Training loss: 1.4865565299987793
Validation loss: 1.79673485730284

Epoch: 6| Step: 9
Training loss: 1.650511622428894
Validation loss: 1.7950181499604256

Epoch: 6| Step: 10
Training loss: 1.6874487400054932
Validation loss: 1.8591565944815194

Epoch: 6| Step: 11
Training loss: 1.09903085231781
Validation loss: 1.8461293892193866

Epoch: 6| Step: 12
Training loss: 0.5082187652587891
Validation loss: 1.7865690659451228

Epoch: 6| Step: 13
Training loss: 0.5249043703079224
Validation loss: 1.8247006952121694

Epoch: 408| Step: 0
Training loss: 1.3699100017547607
Validation loss: 1.8324076783272527

Epoch: 6| Step: 1
Training loss: 0.9719747304916382
Validation loss: 1.8664676450913953

Epoch: 6| Step: 2
Training loss: 1.331885814666748
Validation loss: 1.8589836666660924

Epoch: 6| Step: 3
Training loss: 1.3520780801773071
Validation loss: 1.8330071177533878

Epoch: 6| Step: 4
Training loss: 1.1928119659423828
Validation loss: 1.8419314763879264

Epoch: 6| Step: 5
Training loss: 1.310136318206787
Validation loss: 1.7937699876805788

Epoch: 6| Step: 6
Training loss: 1.8666446208953857
Validation loss: 1.9218752691822667

Epoch: 6| Step: 7
Training loss: 1.4515538215637207
Validation loss: 1.9021926362027404

Epoch: 6| Step: 8
Training loss: 1.578951120376587
Validation loss: 1.8801879626448437

Epoch: 6| Step: 9
Training loss: 1.2536263465881348
Validation loss: 1.8649246295293171

Epoch: 6| Step: 10
Training loss: 1.0195930004119873
Validation loss: 1.8236374406404392

Epoch: 6| Step: 11
Training loss: 1.2742769718170166
Validation loss: 1.880609135473928

Epoch: 6| Step: 12
Training loss: 1.3913135528564453
Validation loss: 1.7858608486831828

Epoch: 6| Step: 13
Training loss: 1.1953520774841309
Validation loss: 1.8792100683335335

Epoch: 409| Step: 0
Training loss: 0.8845882415771484
Validation loss: 1.7978107544683641

Epoch: 6| Step: 1
Training loss: 0.9742673635482788
Validation loss: 1.866769415076061

Epoch: 6| Step: 2
Training loss: 1.176229476928711
Validation loss: 1.7729717326420609

Epoch: 6| Step: 3
Training loss: 1.3706200122833252
Validation loss: 1.838535717738572

Epoch: 6| Step: 4
Training loss: 1.0913432836532593
Validation loss: 1.8057043296034618

Epoch: 6| Step: 5
Training loss: 1.2673743963241577
Validation loss: 1.8512657303963937

Epoch: 6| Step: 6
Training loss: 2.01403546333313
Validation loss: 1.80677152961813

Epoch: 6| Step: 7
Training loss: 1.437984824180603
Validation loss: 1.877990209928123

Epoch: 6| Step: 8
Training loss: 1.7511117458343506
Validation loss: 1.8296243375347507

Epoch: 6| Step: 9
Training loss: 1.3504137992858887
Validation loss: 1.8462970410623858

Epoch: 6| Step: 10
Training loss: 1.1540149450302124
Validation loss: 1.8470002220522972

Epoch: 6| Step: 11
Training loss: 0.6317421197891235
Validation loss: 1.8150503789224932

Epoch: 6| Step: 12
Training loss: 1.6260995864868164
Validation loss: 1.8315725813629806

Epoch: 6| Step: 13
Training loss: 1.3204987049102783
Validation loss: 1.8309395069717078

Epoch: 410| Step: 0
Training loss: 1.3026490211486816
Validation loss: 1.8606450737163585

Epoch: 6| Step: 1
Training loss: 1.7749624252319336
Validation loss: 1.816846957770727

Epoch: 6| Step: 2
Training loss: 1.8081573247909546
Validation loss: 1.829962440716323

Epoch: 6| Step: 3
Training loss: 1.5877294540405273
Validation loss: 1.8967471584197013

Epoch: 6| Step: 4
Training loss: 0.5513138175010681
Validation loss: 1.8847108502541818

Epoch: 6| Step: 5
Training loss: 1.450279712677002
Validation loss: 1.9196968309340938

Epoch: 6| Step: 6
Training loss: 0.9816317558288574
Validation loss: 1.8935784165577223

Epoch: 6| Step: 7
Training loss: 1.4728525876998901
Validation loss: 1.899769224146361

Epoch: 6| Step: 8
Training loss: 1.5458183288574219
Validation loss: 1.8579040752944125

Epoch: 6| Step: 9
Training loss: 0.6437815427780151
Validation loss: 1.798552018339916

Epoch: 6| Step: 10
Training loss: 1.8182542324066162
Validation loss: 1.8066849247101815

Epoch: 6| Step: 11
Training loss: 1.1641297340393066
Validation loss: 1.8041200137907458

Epoch: 6| Step: 12
Training loss: 1.4207288026809692
Validation loss: 1.8436623414357503

Epoch: 6| Step: 13
Training loss: 1.1900063753128052
Validation loss: 1.827299520533572

Epoch: 411| Step: 0
Training loss: 1.4950611591339111
Validation loss: 1.788887708417831

Epoch: 6| Step: 1
Training loss: 1.085204005241394
Validation loss: 1.8655684327566495

Epoch: 6| Step: 2
Training loss: 1.1942620277404785
Validation loss: 1.8291800586126183

Epoch: 6| Step: 3
Training loss: 0.9171980023384094
Validation loss: 1.845962409050234

Epoch: 6| Step: 4
Training loss: 1.3177196979522705
Validation loss: 1.8304289489664056

Epoch: 6| Step: 5
Training loss: 2.049370765686035
Validation loss: 1.7656866465845416

Epoch: 6| Step: 6
Training loss: 1.6882424354553223
Validation loss: 1.8730400467431674

Epoch: 6| Step: 7
Training loss: 0.7494640350341797
Validation loss: 1.8086599611466931

Epoch: 6| Step: 8
Training loss: 1.2403110265731812
Validation loss: 1.807019386240231

Epoch: 6| Step: 9
Training loss: 1.1588205099105835
Validation loss: 1.8539205058928458

Epoch: 6| Step: 10
Training loss: 1.0664825439453125
Validation loss: 1.8014507716701877

Epoch: 6| Step: 11
Training loss: 1.705389142036438
Validation loss: 1.7696666999529767

Epoch: 6| Step: 12
Training loss: 1.5612088441848755
Validation loss: 1.8093731582805674

Epoch: 6| Step: 13
Training loss: 1.2623381614685059
Validation loss: 1.8453241330321117

Epoch: 412| Step: 0
Training loss: 1.8393688201904297
Validation loss: 1.8247024269514187

Epoch: 6| Step: 1
Training loss: 1.219104290008545
Validation loss: 1.8478632639813166

Epoch: 6| Step: 2
Training loss: 1.2893953323364258
Validation loss: 1.8420277885211411

Epoch: 6| Step: 3
Training loss: 2.0633153915405273
Validation loss: 1.8437968505326139

Epoch: 6| Step: 4
Training loss: 1.0327672958374023
Validation loss: 1.8053216844476678

Epoch: 6| Step: 5
Training loss: 1.402206540107727
Validation loss: 1.864280480210499

Epoch: 6| Step: 6
Training loss: 1.2419863939285278
Validation loss: 1.8536700202572731

Epoch: 6| Step: 7
Training loss: 1.3391942977905273
Validation loss: 1.822225014368693

Epoch: 6| Step: 8
Training loss: 1.3415005207061768
Validation loss: 1.8115704213419268

Epoch: 6| Step: 9
Training loss: 0.9829765558242798
Validation loss: 1.8865118180551836

Epoch: 6| Step: 10
Training loss: 0.8872324228286743
Validation loss: 1.8437150139962473

Epoch: 6| Step: 11
Training loss: 1.778391718864441
Validation loss: 1.791108239081598

Epoch: 6| Step: 12
Training loss: 1.5237023830413818
Validation loss: 1.8942085030258342

Epoch: 6| Step: 13
Training loss: 0.7872505187988281
Validation loss: 1.894897291737218

Epoch: 413| Step: 0
Training loss: 1.3191323280334473
Validation loss: 1.8692299986398349

Epoch: 6| Step: 1
Training loss: 0.9498888254165649
Validation loss: 1.845897448960171

Epoch: 6| Step: 2
Training loss: 1.2769978046417236
Validation loss: 1.8667406497463104

Epoch: 6| Step: 3
Training loss: 0.9732820391654968
Validation loss: 1.8915110762401293

Epoch: 6| Step: 4
Training loss: 1.2912280559539795
Validation loss: 1.801233555680962

Epoch: 6| Step: 5
Training loss: 1.200329303741455
Validation loss: 1.9004149308768652

Epoch: 6| Step: 6
Training loss: 1.4029207229614258
Validation loss: 1.8442104401126984

Epoch: 6| Step: 7
Training loss: 1.0693106651306152
Validation loss: 1.7885323391165784

Epoch: 6| Step: 8
Training loss: 1.7116901874542236
Validation loss: 1.8506444423429427

Epoch: 6| Step: 9
Training loss: 1.8406380414962769
Validation loss: 1.871042259277836

Epoch: 6| Step: 10
Training loss: 1.5924177169799805
Validation loss: 1.8437858230324202

Epoch: 6| Step: 11
Training loss: 1.1543662548065186
Validation loss: 1.904264380854945

Epoch: 6| Step: 12
Training loss: 0.9904899597167969
Validation loss: 1.8586976605076944

Epoch: 6| Step: 13
Training loss: 2.10196590423584
Validation loss: 1.8197267337511944

Epoch: 414| Step: 0
Training loss: 1.0681240558624268
Validation loss: 1.7910850855611986

Epoch: 6| Step: 1
Training loss: 1.4202184677124023
Validation loss: 1.8023389436865365

Epoch: 6| Step: 2
Training loss: 1.2172719240188599
Validation loss: 1.8103352016018284

Epoch: 6| Step: 3
Training loss: 1.342235803604126
Validation loss: 1.8183630307515461

Epoch: 6| Step: 4
Training loss: 0.6372077465057373
Validation loss: 1.773901826591902

Epoch: 6| Step: 5
Training loss: 1.5097618103027344
Validation loss: 1.8178477697474982

Epoch: 6| Step: 6
Training loss: 1.7020645141601562
Validation loss: 1.8298764844094553

Epoch: 6| Step: 7
Training loss: 1.7688171863555908
Validation loss: 1.8484710570304625

Epoch: 6| Step: 8
Training loss: 1.0661804676055908
Validation loss: 1.8442560459977837

Epoch: 6| Step: 9
Training loss: 1.584627628326416
Validation loss: 1.8335822628390404

Epoch: 6| Step: 10
Training loss: 1.4747806787490845
Validation loss: 1.8954371777913903

Epoch: 6| Step: 11
Training loss: 1.3111915588378906
Validation loss: 1.8280486547818748

Epoch: 6| Step: 12
Training loss: 0.7963337898254395
Validation loss: 1.8722395820002402

Epoch: 6| Step: 13
Training loss: 1.506013035774231
Validation loss: 1.8273565576922508

Epoch: 415| Step: 0
Training loss: 1.692260503768921
Validation loss: 1.7525127190415577

Epoch: 6| Step: 1
Training loss: 1.4354634284973145
Validation loss: 1.8149108104808356

Epoch: 6| Step: 2
Training loss: 1.3817002773284912
Validation loss: 1.84907183852247

Epoch: 6| Step: 3
Training loss: 1.8236422538757324
Validation loss: 1.7569225218988234

Epoch: 6| Step: 4
Training loss: 1.437434434890747
Validation loss: 1.842659898983535

Epoch: 6| Step: 5
Training loss: 1.1716132164001465
Validation loss: 1.8256542105828562

Epoch: 6| Step: 6
Training loss: 1.3118062019348145
Validation loss: 1.7964682655949746

Epoch: 6| Step: 7
Training loss: 0.9128730893135071
Validation loss: 1.842450088070285

Epoch: 6| Step: 8
Training loss: 1.3867902755737305
Validation loss: 1.7699246150191112

Epoch: 6| Step: 9
Training loss: 0.8169257044792175
Validation loss: 1.8458482142417663

Epoch: 6| Step: 10
Training loss: 0.8345068693161011
Validation loss: 1.8302203916734265

Epoch: 6| Step: 11
Training loss: 1.3074573278427124
Validation loss: 1.7630333310814315

Epoch: 6| Step: 12
Training loss: 1.421858787536621
Validation loss: 1.8059852123260498

Epoch: 6| Step: 13
Training loss: 1.4148796796798706
Validation loss: 1.8929892342577699

Epoch: 416| Step: 0
Training loss: 1.335875391960144
Validation loss: 1.83245768854695

Epoch: 6| Step: 1
Training loss: 1.111674427986145
Validation loss: 1.859891653060913

Epoch: 6| Step: 2
Training loss: 1.5786291360855103
Validation loss: 1.7847632977270311

Epoch: 6| Step: 3
Training loss: 0.8985415101051331
Validation loss: 1.8450414647338211

Epoch: 6| Step: 4
Training loss: 1.6044663190841675
Validation loss: 1.8510702233160696

Epoch: 6| Step: 5
Training loss: 1.1210768222808838
Validation loss: 1.8498239850485196

Epoch: 6| Step: 6
Training loss: 1.1298409700393677
Validation loss: 1.8690965265356085

Epoch: 6| Step: 7
Training loss: 1.3582065105438232
Validation loss: 1.8432076695144817

Epoch: 6| Step: 8
Training loss: 1.610426902770996
Validation loss: 1.8671589448887815

Epoch: 6| Step: 9
Training loss: 1.3119131326675415
Validation loss: 1.805022483230919

Epoch: 6| Step: 10
Training loss: 1.4364022016525269
Validation loss: 1.8126102096291

Epoch: 6| Step: 11
Training loss: 1.0419623851776123
Validation loss: 1.7783978844201693

Epoch: 6| Step: 12
Training loss: 1.3537284135818481
Validation loss: 1.8479587519040672

Epoch: 6| Step: 13
Training loss: 1.2982430458068848
Validation loss: 1.8819266852512155

Epoch: 417| Step: 0
Training loss: 1.0066664218902588
Validation loss: 1.8597229757616598

Epoch: 6| Step: 1
Training loss: 0.7781621813774109
Validation loss: 1.862666396684544

Epoch: 6| Step: 2
Training loss: 1.508613109588623
Validation loss: 1.8077128420593918

Epoch: 6| Step: 3
Training loss: 1.4679055213928223
Validation loss: 1.8364223382806266

Epoch: 6| Step: 4
Training loss: 1.1757988929748535
Validation loss: 1.877289782288254

Epoch: 6| Step: 5
Training loss: 2.391061305999756
Validation loss: 1.8685890500263502

Epoch: 6| Step: 6
Training loss: 1.033271312713623
Validation loss: 1.8580345158935876

Epoch: 6| Step: 7
Training loss: 1.517035722732544
Validation loss: 1.8832722056296565

Epoch: 6| Step: 8
Training loss: 1.5234565734863281
Validation loss: 1.890716201515608

Epoch: 6| Step: 9
Training loss: 1.5758633613586426
Validation loss: 1.8575726004057034

Epoch: 6| Step: 10
Training loss: 1.0146965980529785
Validation loss: 1.8408935236674484

Epoch: 6| Step: 11
Training loss: 0.9463985562324524
Validation loss: 1.816750407218933

Epoch: 6| Step: 12
Training loss: 1.1964383125305176
Validation loss: 1.801968313032581

Epoch: 6| Step: 13
Training loss: 1.3146992921829224
Validation loss: 1.847918612982637

Epoch: 418| Step: 0
Training loss: 1.3624980449676514
Validation loss: 1.7633703190793273

Epoch: 6| Step: 1
Training loss: 1.2331770658493042
Validation loss: 1.803242475755753

Epoch: 6| Step: 2
Training loss: 1.3071829080581665
Validation loss: 1.8787298740879181

Epoch: 6| Step: 3
Training loss: 1.4977892637252808
Validation loss: 1.871541662882733

Epoch: 6| Step: 4
Training loss: 1.437131404876709
Validation loss: 1.8344931038477088

Epoch: 6| Step: 5
Training loss: 1.2639153003692627
Validation loss: 1.8133651210415749

Epoch: 6| Step: 6
Training loss: 0.7248632311820984
Validation loss: 1.7568804025650024

Epoch: 6| Step: 7
Training loss: 1.0410010814666748
Validation loss: 1.7961039735424904

Epoch: 6| Step: 8
Training loss: 0.7607004046440125
Validation loss: 1.803393263970652

Epoch: 6| Step: 9
Training loss: 1.7089002132415771
Validation loss: 1.8031719935837613

Epoch: 6| Step: 10
Training loss: 1.4898723363876343
Validation loss: 1.7973344800292805

Epoch: 6| Step: 11
Training loss: 1.0621014833450317
Validation loss: 1.8072658187599593

Epoch: 6| Step: 12
Training loss: 1.9720755815505981
Validation loss: 1.8573663414165538

Epoch: 6| Step: 13
Training loss: 0.8350673913955688
Validation loss: 1.822914925954675

Epoch: 419| Step: 0
Training loss: 0.902414083480835
Validation loss: 1.8488595357505224

Epoch: 6| Step: 1
Training loss: 0.8937824368476868
Validation loss: 1.849103513584342

Epoch: 6| Step: 2
Training loss: 0.8674418926239014
Validation loss: 1.822552211823002

Epoch: 6| Step: 3
Training loss: 1.8641043901443481
Validation loss: 1.8049963264055149

Epoch: 6| Step: 4
Training loss: 1.6973897218704224
Validation loss: 1.845782285095543

Epoch: 6| Step: 5
Training loss: 1.306678056716919
Validation loss: 1.8537310118316321

Epoch: 6| Step: 6
Training loss: 1.708502173423767
Validation loss: 1.8583197388597714

Epoch: 6| Step: 7
Training loss: 1.2394723892211914
Validation loss: 1.8749521547748196

Epoch: 6| Step: 8
Training loss: 1.6909692287445068
Validation loss: 1.8414576822711575

Epoch: 6| Step: 9
Training loss: 0.6697065830230713
Validation loss: 1.8389842689678233

Epoch: 6| Step: 10
Training loss: 1.0855696201324463
Validation loss: 1.8857944498779953

Epoch: 6| Step: 11
Training loss: 1.4695481061935425
Validation loss: 1.8433584320929743

Epoch: 6| Step: 12
Training loss: 1.411848783493042
Validation loss: 1.8645167248223418

Epoch: 6| Step: 13
Training loss: 1.382599949836731
Validation loss: 1.8335974729189308

Epoch: 420| Step: 0
Training loss: 1.4472408294677734
Validation loss: 1.8473656754339896

Epoch: 6| Step: 1
Training loss: 0.8884209394454956
Validation loss: 1.8214976044111355

Epoch: 6| Step: 2
Training loss: 1.4826421737670898
Validation loss: 1.8169724095252253

Epoch: 6| Step: 3
Training loss: 2.0553956031799316
Validation loss: 1.8350652315283333

Epoch: 6| Step: 4
Training loss: 1.7228314876556396
Validation loss: 1.7760613733722317

Epoch: 6| Step: 5
Training loss: 0.6886098384857178
Validation loss: 1.7962541849382463

Epoch: 6| Step: 6
Training loss: 1.1273534297943115
Validation loss: 1.8925639724218717

Epoch: 6| Step: 7
Training loss: 1.3343524932861328
Validation loss: 1.8027555609262118

Epoch: 6| Step: 8
Training loss: 1.0900254249572754
Validation loss: 1.711682568314255

Epoch: 6| Step: 9
Training loss: 1.322287678718567
Validation loss: 1.8034370970982376

Epoch: 6| Step: 10
Training loss: 0.8355761170387268
Validation loss: 1.8369430290755404

Epoch: 6| Step: 11
Training loss: 1.7557517290115356
Validation loss: 1.7992235960498932

Epoch: 6| Step: 12
Training loss: 1.4505966901779175
Validation loss: 1.8810407359112975

Epoch: 6| Step: 13
Training loss: 0.8153195977210999
Validation loss: 1.7876939055740193

Epoch: 421| Step: 0
Training loss: 1.112539291381836
Validation loss: 1.8301125470028128

Epoch: 6| Step: 1
Training loss: 1.5898751020431519
Validation loss: 1.7861163910999094

Epoch: 6| Step: 2
Training loss: 0.9970651268959045
Validation loss: 1.8979968806748748

Epoch: 6| Step: 3
Training loss: 1.230430006980896
Validation loss: 1.8267862309691727

Epoch: 6| Step: 4
Training loss: 1.0747144222259521
Validation loss: 1.821981260853429

Epoch: 6| Step: 5
Training loss: 1.4204927682876587
Validation loss: 1.7818500623908093

Epoch: 6| Step: 6
Training loss: 1.7655692100524902
Validation loss: 1.8273907130764377

Epoch: 6| Step: 7
Training loss: 0.949569582939148
Validation loss: 1.880123189700547

Epoch: 6| Step: 8
Training loss: 0.7887585163116455
Validation loss: 1.8263305169279858

Epoch: 6| Step: 9
Training loss: 1.4448955059051514
Validation loss: 1.8310210897076515

Epoch: 6| Step: 10
Training loss: 1.4397329092025757
Validation loss: 1.7888267732435656

Epoch: 6| Step: 11
Training loss: 1.40018630027771
Validation loss: 1.795462392991589

Epoch: 6| Step: 12
Training loss: 1.4338188171386719
Validation loss: 1.7822980393645584

Epoch: 6| Step: 13
Training loss: 1.2862752676010132
Validation loss: 1.721760908762614

Epoch: 422| Step: 0
Training loss: 0.7845569849014282
Validation loss: 1.812473027936874

Epoch: 6| Step: 1
Training loss: 1.1103448867797852
Validation loss: 1.8273399517100344

Epoch: 6| Step: 2
Training loss: 1.6962361335754395
Validation loss: 1.8487099024557299

Epoch: 6| Step: 3
Training loss: 1.5302786827087402
Validation loss: 1.8370803325406966

Epoch: 6| Step: 4
Training loss: 1.7343173027038574
Validation loss: 1.882319816979029

Epoch: 6| Step: 5
Training loss: 0.9133061170578003
Validation loss: 1.7942660534253685

Epoch: 6| Step: 6
Training loss: 1.3002126216888428
Validation loss: 1.8707417929044334

Epoch: 6| Step: 7
Training loss: 1.3428430557250977
Validation loss: 1.822587251663208

Epoch: 6| Step: 8
Training loss: 1.2597092390060425
Validation loss: 1.9170869678579352

Epoch: 6| Step: 9
Training loss: 0.9812285900115967
Validation loss: 1.832783365762362

Epoch: 6| Step: 10
Training loss: 0.7409530282020569
Validation loss: 1.848324030958196

Epoch: 6| Step: 11
Training loss: 1.922023057937622
Validation loss: 1.8598474905055056

Epoch: 6| Step: 12
Training loss: 1.427355170249939
Validation loss: 1.811765214448334

Epoch: 6| Step: 13
Training loss: 0.8009862899780273
Validation loss: 1.8190084670179634

Epoch: 423| Step: 0
Training loss: 1.4663091897964478
Validation loss: 1.850763169668054

Epoch: 6| Step: 1
Training loss: 1.0203676223754883
Validation loss: 1.8374150132620206

Epoch: 6| Step: 2
Training loss: 1.2014591693878174
Validation loss: 1.8052754094523769

Epoch: 6| Step: 3
Training loss: 1.0965051651000977
Validation loss: 1.7751230206540836

Epoch: 6| Step: 4
Training loss: 0.7256588935852051
Validation loss: 1.7988152862876974

Epoch: 6| Step: 5
Training loss: 0.9331867694854736
Validation loss: 1.7907137729788338

Epoch: 6| Step: 6
Training loss: 1.491018295288086
Validation loss: 1.8284702877844534

Epoch: 6| Step: 7
Training loss: 0.8486389517784119
Validation loss: 1.8076130446567331

Epoch: 6| Step: 8
Training loss: 1.3011741638183594
Validation loss: 1.8619464776849235

Epoch: 6| Step: 9
Training loss: 1.7435144186019897
Validation loss: 1.7624210516611736

Epoch: 6| Step: 10
Training loss: 1.307530164718628
Validation loss: 1.8080547804473548

Epoch: 6| Step: 11
Training loss: 1.4887946844100952
Validation loss: 1.8224822385336763

Epoch: 6| Step: 12
Training loss: 1.3842347860336304
Validation loss: 1.8562833032300394

Epoch: 6| Step: 13
Training loss: 2.0973401069641113
Validation loss: 1.7964156725073372

Epoch: 424| Step: 0
Training loss: 1.732135534286499
Validation loss: 1.8985828840604393

Epoch: 6| Step: 1
Training loss: 1.4888436794281006
Validation loss: 1.8923442145829559

Epoch: 6| Step: 2
Training loss: 1.0258634090423584
Validation loss: 1.8504024820943032

Epoch: 6| Step: 3
Training loss: 1.419217586517334
Validation loss: 1.8707491172257291

Epoch: 6| Step: 4
Training loss: 1.1375954151153564
Validation loss: 1.8816697212957567

Epoch: 6| Step: 5
Training loss: 0.85637366771698
Validation loss: 1.8421764578870548

Epoch: 6| Step: 6
Training loss: 1.4078047275543213
Validation loss: 1.8120363271364601

Epoch: 6| Step: 7
Training loss: 1.05846107006073
Validation loss: 1.7930119486265286

Epoch: 6| Step: 8
Training loss: 1.8271923065185547
Validation loss: 1.7740215370731969

Epoch: 6| Step: 9
Training loss: 1.068152904510498
Validation loss: 1.7940712295552736

Epoch: 6| Step: 10
Training loss: 1.1228550672531128
Validation loss: 1.8359504771488968

Epoch: 6| Step: 11
Training loss: 1.650498867034912
Validation loss: 1.7323621357640913

Epoch: 6| Step: 12
Training loss: 1.3273876905441284
Validation loss: 1.8224845470920685

Epoch: 6| Step: 13
Training loss: 1.061889886856079
Validation loss: 1.8629645352722497

Epoch: 425| Step: 0
Training loss: 1.1089787483215332
Validation loss: 1.7635405896812357

Epoch: 6| Step: 1
Training loss: 1.1373965740203857
Validation loss: 1.8840939960172098

Epoch: 6| Step: 2
Training loss: 0.9331958293914795
Validation loss: 1.816597911619371

Epoch: 6| Step: 3
Training loss: 1.1104764938354492
Validation loss: 1.7841915968925721

Epoch: 6| Step: 4
Training loss: 1.5718886852264404
Validation loss: 1.8217973478378788

Epoch: 6| Step: 5
Training loss: 1.7358245849609375
Validation loss: 1.840638558069865

Epoch: 6| Step: 6
Training loss: 1.4486620426177979
Validation loss: 1.8617026203422136

Epoch: 6| Step: 7
Training loss: 1.523144245147705
Validation loss: 1.814210686632382

Epoch: 6| Step: 8
Training loss: 1.4026453495025635
Validation loss: 1.8597790733460458

Epoch: 6| Step: 9
Training loss: 1.5843417644500732
Validation loss: 1.8717577047245477

Epoch: 6| Step: 10
Training loss: 1.363128662109375
Validation loss: 1.8600087473469396

Epoch: 6| Step: 11
Training loss: 1.186601996421814
Validation loss: 1.8903170785596293

Epoch: 6| Step: 12
Training loss: 1.1055573225021362
Validation loss: 1.9284355435320126

Epoch: 6| Step: 13
Training loss: 1.0525827407836914
Validation loss: 1.9764638254719396

Epoch: 426| Step: 0
Training loss: 0.8195075988769531
Validation loss: 1.9046207345942014

Epoch: 6| Step: 1
Training loss: 1.7641255855560303
Validation loss: 1.8483752435253513

Epoch: 6| Step: 2
Training loss: 1.6307294368743896
Validation loss: 1.892552334775207

Epoch: 6| Step: 3
Training loss: 1.3879417181015015
Validation loss: 1.7845149604223107

Epoch: 6| Step: 4
Training loss: 1.4973630905151367
Validation loss: 1.824432106428249

Epoch: 6| Step: 5
Training loss: 1.4897490739822388
Validation loss: 1.8079146941502888

Epoch: 6| Step: 6
Training loss: 1.0783964395523071
Validation loss: 1.8345715076692644

Epoch: 6| Step: 7
Training loss: 0.8189944624900818
Validation loss: 1.7901292372775335

Epoch: 6| Step: 8
Training loss: 1.2561556100845337
Validation loss: 1.7767079901951615

Epoch: 6| Step: 9
Training loss: 1.145959734916687
Validation loss: 1.774030521351804

Epoch: 6| Step: 10
Training loss: 1.7052675485610962
Validation loss: 1.8353681436149023

Epoch: 6| Step: 11
Training loss: 1.3418256044387817
Validation loss: 1.8698284869552941

Epoch: 6| Step: 12
Training loss: 0.8966808915138245
Validation loss: 1.814204539022138

Epoch: 6| Step: 13
Training loss: 0.9294450283050537
Validation loss: 1.8041207982647804

Epoch: 427| Step: 0
Training loss: 1.6444764137268066
Validation loss: 1.8014719832328059

Epoch: 6| Step: 1
Training loss: 1.4368579387664795
Validation loss: 1.7644574770363428

Epoch: 6| Step: 2
Training loss: 1.0720540285110474
Validation loss: 1.8479549115703953

Epoch: 6| Step: 3
Training loss: 1.3864275217056274
Validation loss: 1.8584962826903149

Epoch: 6| Step: 4
Training loss: 1.2307071685791016
Validation loss: 1.807940253647425

Epoch: 6| Step: 5
Training loss: 1.4140591621398926
Validation loss: 1.8593439235482165

Epoch: 6| Step: 6
Training loss: 1.0997545719146729
Validation loss: 1.9345589863356722

Epoch: 6| Step: 7
Training loss: 1.4929630756378174
Validation loss: 1.8791552256512385

Epoch: 6| Step: 8
Training loss: 1.0382330417633057
Validation loss: 1.8974795700401388

Epoch: 6| Step: 9
Training loss: 1.0884249210357666
Validation loss: 1.7820965538742721

Epoch: 6| Step: 10
Training loss: 1.467920184135437
Validation loss: 1.8119405251677319

Epoch: 6| Step: 11
Training loss: 1.227186918258667
Validation loss: 1.8920743260332333

Epoch: 6| Step: 12
Training loss: 1.1506118774414062
Validation loss: 1.8688925491866244

Epoch: 6| Step: 13
Training loss: 0.9096090793609619
Validation loss: 1.863034120170019

Epoch: 428| Step: 0
Training loss: 1.154586911201477
Validation loss: 1.7989050124281196

Epoch: 6| Step: 1
Training loss: 1.5832221508026123
Validation loss: 1.888840772772348

Epoch: 6| Step: 2
Training loss: 0.9572851657867432
Validation loss: 1.8408358571349934

Epoch: 6| Step: 3
Training loss: 1.2537027597427368
Validation loss: 1.8395628006227556

Epoch: 6| Step: 4
Training loss: 0.9403564929962158
Validation loss: 1.8525237357744606

Epoch: 6| Step: 5
Training loss: 1.0137395858764648
Validation loss: 1.802154411551773

Epoch: 6| Step: 6
Training loss: 1.7728679180145264
Validation loss: 1.827348098959974

Epoch: 6| Step: 7
Training loss: 2.0806503295898438
Validation loss: 1.809968609963694

Epoch: 6| Step: 8
Training loss: 0.81563401222229
Validation loss: 1.7820731875717

Epoch: 6| Step: 9
Training loss: 1.373209834098816
Validation loss: 1.8129149124186525

Epoch: 6| Step: 10
Training loss: 1.255060076713562
Validation loss: 1.8022067059752762

Epoch: 6| Step: 11
Training loss: 1.44956636428833
Validation loss: 1.8027335828350437

Epoch: 6| Step: 12
Training loss: 1.2316746711730957
Validation loss: 1.8363066411787463

Epoch: 6| Step: 13
Training loss: 0.7922258973121643
Validation loss: 1.7880777261590446

Epoch: 429| Step: 0
Training loss: 1.1902821063995361
Validation loss: 1.7930106321970622

Epoch: 6| Step: 1
Training loss: 1.5016390085220337
Validation loss: 1.838253193004157

Epoch: 6| Step: 2
Training loss: 0.600802481174469
Validation loss: 1.743569427920926

Epoch: 6| Step: 3
Training loss: 1.3320200443267822
Validation loss: 1.786681067559027

Epoch: 6| Step: 4
Training loss: 1.4778399467468262
Validation loss: 1.7946491728546798

Epoch: 6| Step: 5
Training loss: 1.3813899755477905
Validation loss: 1.8145290228628344

Epoch: 6| Step: 6
Training loss: 1.6956737041473389
Validation loss: 1.8002159108397782

Epoch: 6| Step: 7
Training loss: 1.207395315170288
Validation loss: 1.8451273646405948

Epoch: 6| Step: 8
Training loss: 1.5256128311157227
Validation loss: 1.7938104162934005

Epoch: 6| Step: 9
Training loss: 1.1281182765960693
Validation loss: 1.8390985432491507

Epoch: 6| Step: 10
Training loss: 1.2367348670959473
Validation loss: 1.8136162706600722

Epoch: 6| Step: 11
Training loss: 1.7538645267486572
Validation loss: 1.799506777076311

Epoch: 6| Step: 12
Training loss: 0.8855355978012085
Validation loss: 1.8310829721471316

Epoch: 6| Step: 13
Training loss: 0.9241326451301575
Validation loss: 1.8188236996691713

Epoch: 430| Step: 0
Training loss: 1.6321253776550293
Validation loss: 1.8207966512249363

Epoch: 6| Step: 1
Training loss: 1.0090835094451904
Validation loss: 1.8040908664785407

Epoch: 6| Step: 2
Training loss: 1.6241693496704102
Validation loss: 1.8015792626206593

Epoch: 6| Step: 3
Training loss: 0.7809105515480042
Validation loss: 1.8009730474923247

Epoch: 6| Step: 4
Training loss: 0.8918147683143616
Validation loss: 1.8936595878293436

Epoch: 6| Step: 5
Training loss: 1.5801780223846436
Validation loss: 1.76996495005905

Epoch: 6| Step: 6
Training loss: 1.1837732791900635
Validation loss: 1.8409548792787778

Epoch: 6| Step: 7
Training loss: 1.305171012878418
Validation loss: 1.8086574333970264

Epoch: 6| Step: 8
Training loss: 0.7936514616012573
Validation loss: 1.8280861992989816

Epoch: 6| Step: 9
Training loss: 0.7957919836044312
Validation loss: 1.8377036971430625

Epoch: 6| Step: 10
Training loss: 1.517076849937439
Validation loss: 1.8131310939788818

Epoch: 6| Step: 11
Training loss: 1.779736876487732
Validation loss: 1.8396422888642998

Epoch: 6| Step: 12
Training loss: 1.87223482131958
Validation loss: 1.8145436471508396

Epoch: 6| Step: 13
Training loss: 1.0594229698181152
Validation loss: 1.8046947217756701

Epoch: 431| Step: 0
Training loss: 1.574829339981079
Validation loss: 1.7896983700413858

Epoch: 6| Step: 1
Training loss: 1.5978389978408813
Validation loss: 1.8306746905849827

Epoch: 6| Step: 2
Training loss: 1.2419190406799316
Validation loss: 1.8041873285847325

Epoch: 6| Step: 3
Training loss: 0.7749491930007935
Validation loss: 1.7883900109157767

Epoch: 6| Step: 4
Training loss: 1.441028356552124
Validation loss: 1.8207516080589705

Epoch: 6| Step: 5
Training loss: 1.175363540649414
Validation loss: 1.772938815496301

Epoch: 6| Step: 6
Training loss: 0.9860249161720276
Validation loss: 1.7608732972093808

Epoch: 6| Step: 7
Training loss: 2.023141860961914
Validation loss: 1.789104405269828

Epoch: 6| Step: 8
Training loss: 0.9866098761558533
Validation loss: 1.781400893324165

Epoch: 6| Step: 9
Training loss: 1.065812110900879
Validation loss: 1.8308629707623554

Epoch: 6| Step: 10
Training loss: 1.0444424152374268
Validation loss: 1.8070714319905927

Epoch: 6| Step: 11
Training loss: 1.4953241348266602
Validation loss: 1.8900341923518846

Epoch: 6| Step: 12
Training loss: 1.9014290571212769
Validation loss: 1.8119213773358254

Epoch: 6| Step: 13
Training loss: 0.7450048923492432
Validation loss: 1.8323836454781153

Epoch: 432| Step: 0
Training loss: 1.3695604801177979
Validation loss: 1.7859685677354054

Epoch: 6| Step: 1
Training loss: 1.6760116815567017
Validation loss: 1.827833233341094

Epoch: 6| Step: 2
Training loss: 0.920682430267334
Validation loss: 1.8073503202007664

Epoch: 6| Step: 3
Training loss: 1.4209799766540527
Validation loss: 1.8536264229846258

Epoch: 6| Step: 4
Training loss: 1.098798155784607
Validation loss: 1.8247319882915867

Epoch: 6| Step: 5
Training loss: 1.5277185440063477
Validation loss: 1.8537511466651835

Epoch: 6| Step: 6
Training loss: 0.8007214069366455
Validation loss: 1.8868223185180335

Epoch: 6| Step: 7
Training loss: 1.7052359580993652
Validation loss: 1.7822990212389218

Epoch: 6| Step: 8
Training loss: 1.280026912689209
Validation loss: 1.820920628886069

Epoch: 6| Step: 9
Training loss: 1.4845151901245117
Validation loss: 1.8304061197465467

Epoch: 6| Step: 10
Training loss: 1.4703474044799805
Validation loss: 1.892222987708225

Epoch: 6| Step: 11
Training loss: 0.8382138609886169
Validation loss: 1.802026314120139

Epoch: 6| Step: 12
Training loss: 1.180332899093628
Validation loss: 1.8120604330493557

Epoch: 6| Step: 13
Training loss: 1.1287623643875122
Validation loss: 1.8702226825939712

Epoch: 433| Step: 0
Training loss: 1.6100425720214844
Validation loss: 1.8270120325908865

Epoch: 6| Step: 1
Training loss: 0.813381552696228
Validation loss: 1.7159302183376846

Epoch: 6| Step: 2
Training loss: 1.7396423816680908
Validation loss: 1.8237440047725555

Epoch: 6| Step: 3
Training loss: 1.8162809610366821
Validation loss: 1.8393119842775407

Epoch: 6| Step: 4
Training loss: 1.3685542345046997
Validation loss: 1.819685443755119

Epoch: 6| Step: 5
Training loss: 1.2614738941192627
Validation loss: 1.814964703334275

Epoch: 6| Step: 6
Training loss: 1.0393211841583252
Validation loss: 1.7895148082446026

Epoch: 6| Step: 7
Training loss: 0.79158616065979
Validation loss: 1.8348734276269072

Epoch: 6| Step: 8
Training loss: 0.9948902726173401
Validation loss: 1.8161363511957147

Epoch: 6| Step: 9
Training loss: 1.5835590362548828
Validation loss: 1.8160450099616923

Epoch: 6| Step: 10
Training loss: 0.9666780233383179
Validation loss: 1.7808766929052209

Epoch: 6| Step: 11
Training loss: 1.7652900218963623
Validation loss: 1.7866460020824144

Epoch: 6| Step: 12
Training loss: 1.0615323781967163
Validation loss: 1.8364020803923249

Epoch: 6| Step: 13
Training loss: 0.6609601378440857
Validation loss: 1.8132492534575924

Epoch: 434| Step: 0
Training loss: 1.1552282571792603
Validation loss: 1.862749615023213

Epoch: 6| Step: 1
Training loss: 1.0331696271896362
Validation loss: 1.9321697732453704

Epoch: 6| Step: 2
Training loss: 1.5373919010162354
Validation loss: 1.874737080707345

Epoch: 6| Step: 3
Training loss: 1.324283242225647
Validation loss: 1.8203547026521416

Epoch: 6| Step: 4
Training loss: 1.4768471717834473
Validation loss: 1.8584336106495192

Epoch: 6| Step: 5
Training loss: 1.3950973749160767
Validation loss: 1.8241754219096193

Epoch: 6| Step: 6
Training loss: 0.3927077054977417
Validation loss: 1.8430657822598693

Epoch: 6| Step: 7
Training loss: 0.9410703182220459
Validation loss: 1.8081649080399544

Epoch: 6| Step: 8
Training loss: 1.4969098567962646
Validation loss: 1.8500003942879297

Epoch: 6| Step: 9
Training loss: 1.9195610284805298
Validation loss: 1.8304827097923524

Epoch: 6| Step: 10
Training loss: 1.9153919219970703
Validation loss: 1.7928535066625124

Epoch: 6| Step: 11
Training loss: 1.162845492362976
Validation loss: 1.825503667195638

Epoch: 6| Step: 12
Training loss: 1.5171295404434204
Validation loss: 1.8265815396462717

Epoch: 6| Step: 13
Training loss: 0.7932923436164856
Validation loss: 1.7680156923109485

Epoch: 435| Step: 0
Training loss: 1.298732042312622
Validation loss: 1.7967946555024834

Epoch: 6| Step: 1
Training loss: 1.689924716949463
Validation loss: 1.791251754248014

Epoch: 6| Step: 2
Training loss: 0.8027209043502808
Validation loss: 1.7959931358214347

Epoch: 6| Step: 3
Training loss: 1.6211330890655518
Validation loss: 1.8168645225545412

Epoch: 6| Step: 4
Training loss: 0.8391116857528687
Validation loss: 1.8230160705504879

Epoch: 6| Step: 5
Training loss: 1.5147383213043213
Validation loss: 1.8124444561619912

Epoch: 6| Step: 6
Training loss: 1.1196494102478027
Validation loss: 1.7940452162937452

Epoch: 6| Step: 7
Training loss: 1.364567756652832
Validation loss: 1.798126200194

Epoch: 6| Step: 8
Training loss: 0.8135635852813721
Validation loss: 1.7389952777534403

Epoch: 6| Step: 9
Training loss: 1.4167636632919312
Validation loss: 1.7771401213061424

Epoch: 6| Step: 10
Training loss: 1.031961441040039
Validation loss: 1.8109248145934074

Epoch: 6| Step: 11
Training loss: 1.4822063446044922
Validation loss: 1.8425772600276495

Epoch: 6| Step: 12
Training loss: 2.0584402084350586
Validation loss: 1.869440483790572

Epoch: 6| Step: 13
Training loss: 1.2593212127685547
Validation loss: 1.8108898644806237

Epoch: 436| Step: 0
Training loss: 0.7724827527999878
Validation loss: 1.8408036424267677

Epoch: 6| Step: 1
Training loss: 1.0207072496414185
Validation loss: 1.8783102496977775

Epoch: 6| Step: 2
Training loss: 1.9253541231155396
Validation loss: 1.8708551288932882

Epoch: 6| Step: 3
Training loss: 1.0969243049621582
Validation loss: 1.807247269538141

Epoch: 6| Step: 4
Training loss: 2.122756004333496
Validation loss: 1.8954844936247794

Epoch: 6| Step: 5
Training loss: 0.6986110210418701
Validation loss: 1.8698826669364847

Epoch: 6| Step: 6
Training loss: 1.4818854331970215
Validation loss: 1.872099789240027

Epoch: 6| Step: 7
Training loss: 0.7622877359390259
Validation loss: 1.8079777866281488

Epoch: 6| Step: 8
Training loss: 1.3257665634155273
Validation loss: 1.8285219412977978

Epoch: 6| Step: 9
Training loss: 1.1492924690246582
Validation loss: 1.8260286636249994

Epoch: 6| Step: 10
Training loss: 0.8578921556472778
Validation loss: 1.830085580066968

Epoch: 6| Step: 11
Training loss: 1.5487645864486694
Validation loss: 1.8395300962591683

Epoch: 6| Step: 12
Training loss: 1.3920234441757202
Validation loss: 1.7663411748024724

Epoch: 6| Step: 13
Training loss: 1.8098551034927368
Validation loss: 1.8377684162509056

Epoch: 437| Step: 0
Training loss: 0.8926988840103149
Validation loss: 1.8494946200360534

Epoch: 6| Step: 1
Training loss: 0.9160900115966797
Validation loss: 1.8064841942120624

Epoch: 6| Step: 2
Training loss: 1.2786966562271118
Validation loss: 1.83305327610303

Epoch: 6| Step: 3
Training loss: 1.7404890060424805
Validation loss: 1.8098158682546308

Epoch: 6| Step: 4
Training loss: 1.8750395774841309
Validation loss: 1.8380672085669734

Epoch: 6| Step: 5
Training loss: 1.3143166303634644
Validation loss: 1.8482834600633191

Epoch: 6| Step: 6
Training loss: 1.0664012432098389
Validation loss: 1.7909782099467453

Epoch: 6| Step: 7
Training loss: 1.1536061763763428
Validation loss: 1.8164088546588857

Epoch: 6| Step: 8
Training loss: 1.1638267040252686
Validation loss: 1.840247283699692

Epoch: 6| Step: 9
Training loss: 1.4047242403030396
Validation loss: 1.83493588560371

Epoch: 6| Step: 10
Training loss: 1.8869450092315674
Validation loss: 1.8002318233572028

Epoch: 6| Step: 11
Training loss: 1.2409485578536987
Validation loss: 1.7705688040743592

Epoch: 6| Step: 12
Training loss: 0.8442394733428955
Validation loss: 1.8055826284552132

Epoch: 6| Step: 13
Training loss: 0.6722024083137512
Validation loss: 1.740964944644641

Epoch: 438| Step: 0
Training loss: 1.7282190322875977
Validation loss: 1.8152001416811379

Epoch: 6| Step: 1
Training loss: 1.3775229454040527
Validation loss: 1.775197184214028

Epoch: 6| Step: 2
Training loss: 1.2431464195251465
Validation loss: 1.7786477458092473

Epoch: 6| Step: 3
Training loss: 1.2924790382385254
Validation loss: 1.8571147700791717

Epoch: 6| Step: 4
Training loss: 0.76169753074646
Validation loss: 1.8151285930346417

Epoch: 6| Step: 5
Training loss: 1.2593868970870972
Validation loss: 1.797299103070331

Epoch: 6| Step: 6
Training loss: 1.3588392734527588
Validation loss: 1.8148351138637913

Epoch: 6| Step: 7
Training loss: 1.2067385911941528
Validation loss: 1.76375755827914

Epoch: 6| Step: 8
Training loss: 0.7805287837982178
Validation loss: 1.7754723128452097

Epoch: 6| Step: 9
Training loss: 0.8257476687431335
Validation loss: 1.8195770222653624

Epoch: 6| Step: 10
Training loss: 0.841489315032959
Validation loss: 1.8256050207281624

Epoch: 6| Step: 11
Training loss: 1.2312155961990356
Validation loss: 1.7691267292986634

Epoch: 6| Step: 12
Training loss: 2.170252799987793
Validation loss: 1.8001852522614181

Epoch: 6| Step: 13
Training loss: 2.1503069400787354
Validation loss: 1.8082341276189333

Epoch: 439| Step: 0
Training loss: 1.5044443607330322
Validation loss: 1.8405889208598802

Epoch: 6| Step: 1
Training loss: 0.8953590989112854
Validation loss: 1.7936191379383046

Epoch: 6| Step: 2
Training loss: 1.156888723373413
Validation loss: 1.8239962862383934

Epoch: 6| Step: 3
Training loss: 1.0296889543533325
Validation loss: 1.8213663844652073

Epoch: 6| Step: 4
Training loss: 1.6412434577941895
Validation loss: 1.7784516837007256

Epoch: 6| Step: 5
Training loss: 1.0713495016098022
Validation loss: 1.8038205510826522

Epoch: 6| Step: 6
Training loss: 1.6881319284439087
Validation loss: 1.782496662550075

Epoch: 6| Step: 7
Training loss: 1.4843330383300781
Validation loss: 1.845603976198422

Epoch: 6| Step: 8
Training loss: 1.2479552030563354
Validation loss: 1.8514781626321937

Epoch: 6| Step: 9
Training loss: 1.4143306016921997
Validation loss: 1.8033113364250428

Epoch: 6| Step: 10
Training loss: 1.7727888822555542
Validation loss: 1.8477248709688905

Epoch: 6| Step: 11
Training loss: 0.6111482381820679
Validation loss: 1.8187747924558577

Epoch: 6| Step: 12
Training loss: 1.2372980117797852
Validation loss: 1.8147844268429665

Epoch: 6| Step: 13
Training loss: 0.6798499822616577
Validation loss: 1.798986634900493

Epoch: 440| Step: 0
Training loss: 1.0673186779022217
Validation loss: 1.7768207045011624

Epoch: 6| Step: 1
Training loss: 1.335923194885254
Validation loss: 1.7761833411391064

Epoch: 6| Step: 2
Training loss: 0.9140400886535645
Validation loss: 1.7355670800773046

Epoch: 6| Step: 3
Training loss: 0.8985234498977661
Validation loss: 1.8294341153995965

Epoch: 6| Step: 4
Training loss: 1.0031521320343018
Validation loss: 1.8082087116856729

Epoch: 6| Step: 5
Training loss: 1.5345345735549927
Validation loss: 1.8302139505263297

Epoch: 6| Step: 6
Training loss: 1.7446131706237793
Validation loss: 1.7946718623561244

Epoch: 6| Step: 7
Training loss: 1.5637465715408325
Validation loss: 1.745870481255234

Epoch: 6| Step: 8
Training loss: 1.408664345741272
Validation loss: 1.8249021191750803

Epoch: 6| Step: 9
Training loss: 1.3468358516693115
Validation loss: 1.7863203825489167

Epoch: 6| Step: 10
Training loss: 1.0614612102508545
Validation loss: 1.8253329428293372

Epoch: 6| Step: 11
Training loss: 0.98450767993927
Validation loss: 1.8019910320158927

Epoch: 6| Step: 12
Training loss: 1.012523889541626
Validation loss: 1.8257810813124462

Epoch: 6| Step: 13
Training loss: 1.6964482069015503
Validation loss: 1.819463663203742

Epoch: 441| Step: 0
Training loss: 1.980822205543518
Validation loss: 1.7922779719034831

Epoch: 6| Step: 1
Training loss: 1.1606316566467285
Validation loss: 1.8268401289498934

Epoch: 6| Step: 2
Training loss: 0.8712263107299805
Validation loss: 1.755805464201076

Epoch: 6| Step: 3
Training loss: 1.1330816745758057
Validation loss: 1.8272050644761773

Epoch: 6| Step: 4
Training loss: 0.7060655355453491
Validation loss: 1.8126488167752501

Epoch: 6| Step: 5
Training loss: 0.9498604536056519
Validation loss: 1.828780948474843

Epoch: 6| Step: 6
Training loss: 2.131544589996338
Validation loss: 1.8353699343178862

Epoch: 6| Step: 7
Training loss: 1.4029289484024048
Validation loss: 1.830295539671375

Epoch: 6| Step: 8
Training loss: 0.8601890206336975
Validation loss: 1.806218695896928

Epoch: 6| Step: 9
Training loss: 1.2597708702087402
Validation loss: 1.8235876944757277

Epoch: 6| Step: 10
Training loss: 1.8758443593978882
Validation loss: 1.8335739604888424

Epoch: 6| Step: 11
Training loss: 0.9435925483703613
Validation loss: 1.7540828950943486

Epoch: 6| Step: 12
Training loss: 0.8307090401649475
Validation loss: 1.7476065876663371

Epoch: 6| Step: 13
Training loss: 0.5779390335083008
Validation loss: 1.8454606071595223

Epoch: 442| Step: 0
Training loss: 0.5730651617050171
Validation loss: 1.7854174977989608

Epoch: 6| Step: 1
Training loss: 0.8762100338935852
Validation loss: 1.7682377035899828

Epoch: 6| Step: 2
Training loss: 1.0880606174468994
Validation loss: 1.7990712440142067

Epoch: 6| Step: 3
Training loss: 2.253978729248047
Validation loss: 1.786684169564196

Epoch: 6| Step: 4
Training loss: 1.348558783531189
Validation loss: 1.766964936769137

Epoch: 6| Step: 5
Training loss: 1.0584970712661743
Validation loss: 1.7703828837281914

Epoch: 6| Step: 6
Training loss: 1.534287929534912
Validation loss: 1.8160509870898338

Epoch: 6| Step: 7
Training loss: 1.35690176486969
Validation loss: 1.8217246801622453

Epoch: 6| Step: 8
Training loss: 1.8619890213012695
Validation loss: 1.7632574278821227

Epoch: 6| Step: 9
Training loss: 1.1629667282104492
Validation loss: 1.8133889398267191

Epoch: 6| Step: 10
Training loss: 1.0974959135055542
Validation loss: 1.7770407148586806

Epoch: 6| Step: 11
Training loss: 1.1674633026123047
Validation loss: 1.7647059649549506

Epoch: 6| Step: 12
Training loss: 1.6407390832901
Validation loss: 1.816542907427716

Epoch: 6| Step: 13
Training loss: 1.2239422798156738
Validation loss: 1.7888839962661907

Epoch: 443| Step: 0
Training loss: 0.9524692296981812
Validation loss: 1.8408517683705976

Epoch: 6| Step: 1
Training loss: 0.7787783741950989
Validation loss: 1.8135596449657152

Epoch: 6| Step: 2
Training loss: 1.5444092750549316
Validation loss: 1.8331255899962557

Epoch: 6| Step: 3
Training loss: 1.3748178482055664
Validation loss: 1.8421508086624967

Epoch: 6| Step: 4
Training loss: 0.9459291696548462
Validation loss: 1.8132994482594151

Epoch: 6| Step: 5
Training loss: 0.6664519906044006
Validation loss: 1.8327668238711614

Epoch: 6| Step: 6
Training loss: 1.2501496076583862
Validation loss: 1.8183825682568293

Epoch: 6| Step: 7
Training loss: 1.0086030960083008
Validation loss: 1.819643585912643

Epoch: 6| Step: 8
Training loss: 1.47604501247406
Validation loss: 1.7829487567306848

Epoch: 6| Step: 9
Training loss: 1.11495041847229
Validation loss: 1.8380853758063367

Epoch: 6| Step: 10
Training loss: 1.6362428665161133
Validation loss: 1.8427478395482546

Epoch: 6| Step: 11
Training loss: 1.941185712814331
Validation loss: 1.8188353956386607

Epoch: 6| Step: 12
Training loss: 1.328224778175354
Validation loss: 1.76976223914854

Epoch: 6| Step: 13
Training loss: 1.1798287630081177
Validation loss: 1.8076174477095246

Epoch: 444| Step: 0
Training loss: 1.172823429107666
Validation loss: 1.82702076050543

Epoch: 6| Step: 1
Training loss: 1.5355256795883179
Validation loss: 1.798706744306831

Epoch: 6| Step: 2
Training loss: 0.9555471539497375
Validation loss: 1.7774121338321316

Epoch: 6| Step: 3
Training loss: 1.5934795141220093
Validation loss: 1.8405213150926816

Epoch: 6| Step: 4
Training loss: 1.349117398262024
Validation loss: 1.7720171456695886

Epoch: 6| Step: 5
Training loss: 1.2201792001724243
Validation loss: 1.7970777942288307

Epoch: 6| Step: 6
Training loss: 1.2020618915557861
Validation loss: 1.8455318456055017

Epoch: 6| Step: 7
Training loss: 1.219823956489563
Validation loss: 1.7488910164884341

Epoch: 6| Step: 8
Training loss: 1.1399261951446533
Validation loss: 1.7604812229833295

Epoch: 6| Step: 9
Training loss: 1.2749712467193604
Validation loss: 1.8501818115993212

Epoch: 6| Step: 10
Training loss: 1.5070507526397705
Validation loss: 1.8675305766444052

Epoch: 6| Step: 11
Training loss: 1.306473970413208
Validation loss: 1.8560978699755926

Epoch: 6| Step: 12
Training loss: 1.4266541004180908
Validation loss: 1.782022786396806

Epoch: 6| Step: 13
Training loss: 1.167351245880127
Validation loss: 1.847525176181588

Epoch: 445| Step: 0
Training loss: 1.2096956968307495
Validation loss: 1.782785810450072

Epoch: 6| Step: 1
Training loss: 0.5186695456504822
Validation loss: 1.804787362775495

Epoch: 6| Step: 2
Training loss: 0.9602803587913513
Validation loss: 1.7574253120730001

Epoch: 6| Step: 3
Training loss: 0.9971246123313904
Validation loss: 1.7985823154449463

Epoch: 6| Step: 4
Training loss: 1.3779492378234863
Validation loss: 1.795087722039992

Epoch: 6| Step: 5
Training loss: 1.070267915725708
Validation loss: 1.768953521405497

Epoch: 6| Step: 6
Training loss: 1.7641667127609253
Validation loss: 1.7406095714979275

Epoch: 6| Step: 7
Training loss: 1.3546249866485596
Validation loss: 1.871278029616161

Epoch: 6| Step: 8
Training loss: 1.1324622631072998
Validation loss: 1.9102421447794924

Epoch: 6| Step: 9
Training loss: 1.2092610597610474
Validation loss: 1.7778266552955873

Epoch: 6| Step: 10
Training loss: 1.6305463314056396
Validation loss: 1.8398950984401088

Epoch: 6| Step: 11
Training loss: 1.0778815746307373
Validation loss: 1.8445749359746133

Epoch: 6| Step: 12
Training loss: 1.405916452407837
Validation loss: 1.8180686953247234

Epoch: 6| Step: 13
Training loss: 1.474942922592163
Validation loss: 1.809987501431537

Epoch: 446| Step: 0
Training loss: 1.4422926902770996
Validation loss: 1.8391642083403885

Epoch: 6| Step: 1
Training loss: 1.441331148147583
Validation loss: 1.8058432238076323

Epoch: 6| Step: 2
Training loss: 1.1804128885269165
Validation loss: 1.8414536612008208

Epoch: 6| Step: 3
Training loss: 1.1466848850250244
Validation loss: 1.8255190464758104

Epoch: 6| Step: 4
Training loss: 1.27656888961792
Validation loss: 1.7997049003519037

Epoch: 6| Step: 5
Training loss: 1.0131888389587402
Validation loss: 1.7690110180967598

Epoch: 6| Step: 6
Training loss: 1.7156267166137695
Validation loss: 1.7610047068647159

Epoch: 6| Step: 7
Training loss: 0.9174814820289612
Validation loss: 1.874705215936066

Epoch: 6| Step: 8
Training loss: 1.1510674953460693
Validation loss: 1.808658786999282

Epoch: 6| Step: 9
Training loss: 1.3105359077453613
Validation loss: 1.8224079852463098

Epoch: 6| Step: 10
Training loss: 1.343963861465454
Validation loss: 1.8536490214768278

Epoch: 6| Step: 11
Training loss: 1.6677557229995728
Validation loss: 1.7943313519159954

Epoch: 6| Step: 12
Training loss: 0.9367156028747559
Validation loss: 1.7861263264891922

Epoch: 6| Step: 13
Training loss: 0.9624468684196472
Validation loss: 1.8198409131778184

Epoch: 447| Step: 0
Training loss: 0.6947579979896545
Validation loss: 1.8405257758273874

Epoch: 6| Step: 1
Training loss: 0.715161144733429
Validation loss: 1.784859299659729

Epoch: 6| Step: 2
Training loss: 1.524430751800537
Validation loss: 1.7996730214806014

Epoch: 6| Step: 3
Training loss: 1.2910592555999756
Validation loss: 1.7955309806331512

Epoch: 6| Step: 4
Training loss: 1.0538578033447266
Validation loss: 1.7828398250764417

Epoch: 6| Step: 5
Training loss: 1.0893654823303223
Validation loss: 1.7854578302752586

Epoch: 6| Step: 6
Training loss: 1.7428981065750122
Validation loss: 1.8500845727100168

Epoch: 6| Step: 7
Training loss: 0.9335240721702576
Validation loss: 1.8011116250868766

Epoch: 6| Step: 8
Training loss: 1.258751392364502
Validation loss: 1.7656114357773975

Epoch: 6| Step: 9
Training loss: 1.7699904441833496
Validation loss: 1.838693432910468

Epoch: 6| Step: 10
Training loss: 0.9616731405258179
Validation loss: 1.8047153578009656

Epoch: 6| Step: 11
Training loss: 1.6082918643951416
Validation loss: 1.7971056302388508

Epoch: 6| Step: 12
Training loss: 1.4665303230285645
Validation loss: 1.8258173773365636

Epoch: 6| Step: 13
Training loss: 1.077445387840271
Validation loss: 1.7965705381926669

Epoch: 448| Step: 0
Training loss: 1.7314692735671997
Validation loss: 1.798340711542355

Epoch: 6| Step: 1
Training loss: 0.9261875152587891
Validation loss: 1.864711820438344

Epoch: 6| Step: 2
Training loss: 1.4610217809677124
Validation loss: 1.7737582242617043

Epoch: 6| Step: 3
Training loss: 1.7326210737228394
Validation loss: 1.774003227551778

Epoch: 6| Step: 4
Training loss: 1.2339286804199219
Validation loss: 1.7978814891589585

Epoch: 6| Step: 5
Training loss: 1.3233085870742798
Validation loss: 1.7976979465894802

Epoch: 6| Step: 6
Training loss: 1.4449448585510254
Validation loss: 1.8149960669138099

Epoch: 6| Step: 7
Training loss: 1.4725860357284546
Validation loss: 1.8554090402459587

Epoch: 6| Step: 8
Training loss: 1.0354799032211304
Validation loss: 1.8630189011173863

Epoch: 6| Step: 9
Training loss: 0.8364840745925903
Validation loss: 1.8408925187203191

Epoch: 6| Step: 10
Training loss: 1.2431796789169312
Validation loss: 1.7979212371251916

Epoch: 6| Step: 11
Training loss: 1.2753849029541016
Validation loss: 1.8676345348358154

Epoch: 6| Step: 12
Training loss: 0.6976731419563293
Validation loss: 1.8430644132757699

Epoch: 6| Step: 13
Training loss: 0.3172298073768616
Validation loss: 1.8203494984616515

Epoch: 449| Step: 0
Training loss: 1.6190595626831055
Validation loss: 1.807624024729575

Epoch: 6| Step: 1
Training loss: 1.1811683177947998
Validation loss: 1.8091224675537438

Epoch: 6| Step: 2
Training loss: 1.1934559345245361
Validation loss: 1.8369236543614378

Epoch: 6| Step: 3
Training loss: 0.9126380681991577
Validation loss: 1.835583080527603

Epoch: 6| Step: 4
Training loss: 1.468747615814209
Validation loss: 1.8229358888441516

Epoch: 6| Step: 5
Training loss: 1.485814094543457
Validation loss: 1.8319477317153767

Epoch: 6| Step: 6
Training loss: 1.070902705192566
Validation loss: 1.8273038139907263

Epoch: 6| Step: 7
Training loss: 1.2270327806472778
Validation loss: 1.8479947133730816

Epoch: 6| Step: 8
Training loss: 1.4725041389465332
Validation loss: 1.8269338325787616

Epoch: 6| Step: 9
Training loss: 0.8956854939460754
Validation loss: 1.8432445603032266

Epoch: 6| Step: 10
Training loss: 0.7025122046470642
Validation loss: 1.779345876427107

Epoch: 6| Step: 11
Training loss: 1.1594336032867432
Validation loss: 1.836334079824468

Epoch: 6| Step: 12
Training loss: 0.8225864171981812
Validation loss: 1.81768338910995

Epoch: 6| Step: 13
Training loss: 2.4072163105010986
Validation loss: 1.7851603300340715

Epoch: 450| Step: 0
Training loss: 0.9021490812301636
Validation loss: 1.8399389802768666

Epoch: 6| Step: 1
Training loss: 1.3237183094024658
Validation loss: 1.8864572740370227

Epoch: 6| Step: 2
Training loss: 1.7728245258331299
Validation loss: 1.8143061630187496

Epoch: 6| Step: 3
Training loss: 1.09463632106781
Validation loss: 1.7892788898560308

Epoch: 6| Step: 4
Training loss: 0.937688410282135
Validation loss: 1.7784422559122885

Epoch: 6| Step: 5
Training loss: 0.9492554664611816
Validation loss: 1.8297898538651005

Epoch: 6| Step: 6
Training loss: 1.0283854007720947
Validation loss: 1.849983899824081

Epoch: 6| Step: 7
Training loss: 1.0643216371536255
Validation loss: 1.8086929129016014

Epoch: 6| Step: 8
Training loss: 1.3115607500076294
Validation loss: 1.7925708005505223

Epoch: 6| Step: 9
Training loss: 1.3746726512908936
Validation loss: 1.805836498096425

Epoch: 6| Step: 10
Training loss: 1.468113660812378
Validation loss: 1.8215265991867229

Epoch: 6| Step: 11
Training loss: 1.1189484596252441
Validation loss: 1.8334539654434368

Epoch: 6| Step: 12
Training loss: 1.637542963027954
Validation loss: 1.759816644012287

Epoch: 6| Step: 13
Training loss: 1.162147045135498
Validation loss: 1.780284406036459

Epoch: 451| Step: 0
Training loss: 1.7501976490020752
Validation loss: 1.8314965168635051

Epoch: 6| Step: 1
Training loss: 1.3186091184616089
Validation loss: 1.7928959477332331

Epoch: 6| Step: 2
Training loss: 1.0285313129425049
Validation loss: 1.817678331046976

Epoch: 6| Step: 3
Training loss: 1.452073574066162
Validation loss: 1.8485641966583908

Epoch: 6| Step: 4
Training loss: 1.2501143217086792
Validation loss: 1.819083659879623

Epoch: 6| Step: 5
Training loss: 1.4056857824325562
Validation loss: 1.8019964823158838

Epoch: 6| Step: 6
Training loss: 1.1218667030334473
Validation loss: 1.817733585193593

Epoch: 6| Step: 7
Training loss: 1.308561086654663
Validation loss: 1.8377637286340036

Epoch: 6| Step: 8
Training loss: 0.4827706217765808
Validation loss: 1.7476748125527495

Epoch: 6| Step: 9
Training loss: 1.6783368587493896
Validation loss: 1.7627000706170195

Epoch: 6| Step: 10
Training loss: 1.3748459815979004
Validation loss: 1.770933974173761

Epoch: 6| Step: 11
Training loss: 1.2931616306304932
Validation loss: 1.817770904110324

Epoch: 6| Step: 12
Training loss: 0.9385676383972168
Validation loss: 1.8130571483283915

Epoch: 6| Step: 13
Training loss: 1.110145092010498
Validation loss: 1.769456817257789

Epoch: 452| Step: 0
Training loss: 0.9886178374290466
Validation loss: 1.8149860764062533

Epoch: 6| Step: 1
Training loss: 1.1669554710388184
Validation loss: 1.8149772215914983

Epoch: 6| Step: 2
Training loss: 1.4504084587097168
Validation loss: 1.805861028291846

Epoch: 6| Step: 3
Training loss: 0.7870070934295654
Validation loss: 1.8123624581162647

Epoch: 6| Step: 4
Training loss: 1.1491888761520386
Validation loss: 1.822382603922198

Epoch: 6| Step: 5
Training loss: 1.6787867546081543
Validation loss: 1.8154834060258762

Epoch: 6| Step: 6
Training loss: 0.7760822772979736
Validation loss: 1.9110316679041872

Epoch: 6| Step: 7
Training loss: 1.266361951828003
Validation loss: 1.7961865676346647

Epoch: 6| Step: 8
Training loss: 1.5648598670959473
Validation loss: 1.845105912095757

Epoch: 6| Step: 9
Training loss: 1.0958428382873535
Validation loss: 1.881035545820831

Epoch: 6| Step: 10
Training loss: 1.480297565460205
Validation loss: 1.7777386724307973

Epoch: 6| Step: 11
Training loss: 0.6168279647827148
Validation loss: 1.806077016297207

Epoch: 6| Step: 12
Training loss: 1.4580397605895996
Validation loss: 1.794198279739708

Epoch: 6| Step: 13
Training loss: 1.2599964141845703
Validation loss: 1.8052233252474057

Epoch: 453| Step: 0
Training loss: 2.0014495849609375
Validation loss: 1.8636812266483103

Epoch: 6| Step: 1
Training loss: 0.7361596822738647
Validation loss: 1.7989315268813924

Epoch: 6| Step: 2
Training loss: 2.147268056869507
Validation loss: 1.8221038208212903

Epoch: 6| Step: 3
Training loss: 1.3064826726913452
Validation loss: 1.7615639830148349

Epoch: 6| Step: 4
Training loss: 1.2024791240692139
Validation loss: 1.8219749824975127

Epoch: 6| Step: 5
Training loss: 1.2822024822235107
Validation loss: 1.7486762923579062

Epoch: 6| Step: 6
Training loss: 0.652423083782196
Validation loss: 1.7633440186900478

Epoch: 6| Step: 7
Training loss: 0.9712505340576172
Validation loss: 1.741861698448017

Epoch: 6| Step: 8
Training loss: 1.948594093322754
Validation loss: 1.8443498983178088

Epoch: 6| Step: 9
Training loss: 1.1474153995513916
Validation loss: 1.7884488336501583

Epoch: 6| Step: 10
Training loss: 1.253810167312622
Validation loss: 1.8378854951550883

Epoch: 6| Step: 11
Training loss: 1.066178798675537
Validation loss: 1.811056984368191

Epoch: 6| Step: 12
Training loss: 0.824552059173584
Validation loss: 1.8561986620708177

Epoch: 6| Step: 13
Training loss: 0.6073324680328369
Validation loss: 1.8403865496317546

Epoch: 454| Step: 0
Training loss: 0.7897062301635742
Validation loss: 1.8898525686674221

Epoch: 6| Step: 1
Training loss: 0.9418686628341675
Validation loss: 1.8250563042138213

Epoch: 6| Step: 2
Training loss: 1.626554250717163
Validation loss: 1.840331862049718

Epoch: 6| Step: 3
Training loss: 1.1544034481048584
Validation loss: 1.7790736908553748

Epoch: 6| Step: 4
Training loss: 1.4441514015197754
Validation loss: 1.7724426228513

Epoch: 6| Step: 5
Training loss: 0.9561320543289185
Validation loss: 1.8754955440439203

Epoch: 6| Step: 6
Training loss: 1.1917524337768555
Validation loss: 1.8346314942964943

Epoch: 6| Step: 7
Training loss: 1.4722466468811035
Validation loss: 1.7987528219017932

Epoch: 6| Step: 8
Training loss: 0.9943686723709106
Validation loss: 1.781653719563638

Epoch: 6| Step: 9
Training loss: 1.1922435760498047
Validation loss: 1.7557752337507022

Epoch: 6| Step: 10
Training loss: 1.139782190322876
Validation loss: 1.829665507039716

Epoch: 6| Step: 11
Training loss: 1.2300291061401367
Validation loss: 1.8552113143346642

Epoch: 6| Step: 12
Training loss: 0.9988052248954773
Validation loss: 1.7823362863191994

Epoch: 6| Step: 13
Training loss: 2.266835927963257
Validation loss: 1.8200275205796765

Epoch: 455| Step: 0
Training loss: 1.328062653541565
Validation loss: 1.7309636005791285

Epoch: 6| Step: 1
Training loss: 1.0437917709350586
Validation loss: 1.772656916290201

Epoch: 6| Step: 2
Training loss: 1.003501057624817
Validation loss: 1.7356941866618332

Epoch: 6| Step: 3
Training loss: 1.0473204851150513
Validation loss: 1.8376767378981396

Epoch: 6| Step: 4
Training loss: 1.674271583557129
Validation loss: 1.8249836032108595

Epoch: 6| Step: 5
Training loss: 1.1137410402297974
Validation loss: 1.779345961027248

Epoch: 6| Step: 6
Training loss: 1.3494391441345215
Validation loss: 1.8205493163037043

Epoch: 6| Step: 7
Training loss: 1.5276362895965576
Validation loss: 1.7406569001495198

Epoch: 6| Step: 8
Training loss: 1.1749110221862793
Validation loss: 1.7802746206201532

Epoch: 6| Step: 9
Training loss: 1.5981664657592773
Validation loss: 1.7988796708404378

Epoch: 6| Step: 10
Training loss: 1.2225096225738525
Validation loss: 1.812596644124677

Epoch: 6| Step: 11
Training loss: 0.8422225713729858
Validation loss: 1.8056789534066313

Epoch: 6| Step: 12
Training loss: 1.2518284320831299
Validation loss: 1.8333385670056908

Epoch: 6| Step: 13
Training loss: 1.7444682121276855
Validation loss: 1.8221790188102311

Epoch: 456| Step: 0
Training loss: 0.8667830228805542
Validation loss: 1.861594941026421

Epoch: 6| Step: 1
Training loss: 1.246387004852295
Validation loss: 1.8226143185810377

Epoch: 6| Step: 2
Training loss: 1.537984013557434
Validation loss: 1.8380863717807236

Epoch: 6| Step: 3
Training loss: 1.5249154567718506
Validation loss: 1.8227987545792774

Epoch: 6| Step: 4
Training loss: 1.4248948097229004
Validation loss: 1.7973450037740892

Epoch: 6| Step: 5
Training loss: 0.8761647343635559
Validation loss: 1.8233840119454168

Epoch: 6| Step: 6
Training loss: 1.6074442863464355
Validation loss: 1.864153108289165

Epoch: 6| Step: 7
Training loss: 0.7769670486450195
Validation loss: 1.8602804855633808

Epoch: 6| Step: 8
Training loss: 1.2821450233459473
Validation loss: 1.8216690773605018

Epoch: 6| Step: 9
Training loss: 1.417184591293335
Validation loss: 1.8476706640694731

Epoch: 6| Step: 10
Training loss: 1.1353473663330078
Validation loss: 1.8269543058128768

Epoch: 6| Step: 11
Training loss: 1.0874632596969604
Validation loss: 1.8381180699153612

Epoch: 6| Step: 12
Training loss: 0.9035125970840454
Validation loss: 1.7616378812379734

Epoch: 6| Step: 13
Training loss: 1.4514288902282715
Validation loss: 1.8067808933155511

Epoch: 457| Step: 0
Training loss: 1.4993491172790527
Validation loss: 1.8136294862275482

Epoch: 6| Step: 1
Training loss: 1.3070974349975586
Validation loss: 1.7570847670237224

Epoch: 6| Step: 2
Training loss: 0.9649958610534668
Validation loss: 1.7956011974683372

Epoch: 6| Step: 3
Training loss: 1.2704147100448608
Validation loss: 1.7810313599084013

Epoch: 6| Step: 4
Training loss: 1.6230623722076416
Validation loss: 1.8019558178481234

Epoch: 6| Step: 5
Training loss: 0.9591235518455505
Validation loss: 1.7681167382065968

Epoch: 6| Step: 6
Training loss: 0.8026595711708069
Validation loss: 1.8472688044271162

Epoch: 6| Step: 7
Training loss: 0.6834844350814819
Validation loss: 1.8622191785484232

Epoch: 6| Step: 8
Training loss: 1.9662476778030396
Validation loss: 1.8112762935699955

Epoch: 6| Step: 9
Training loss: 1.2195314168930054
Validation loss: 1.8173850415855326

Epoch: 6| Step: 10
Training loss: 0.9409608840942383
Validation loss: 1.7854829219079786

Epoch: 6| Step: 11
Training loss: 0.9104876518249512
Validation loss: 1.8432133736148957

Epoch: 6| Step: 12
Training loss: 1.081233263015747
Validation loss: 1.8307906158508793

Epoch: 6| Step: 13
Training loss: 1.5846291780471802
Validation loss: 1.8799728347409157

Epoch: 458| Step: 0
Training loss: 1.2164256572723389
Validation loss: 1.8115579466665945

Epoch: 6| Step: 1
Training loss: 1.2625935077667236
Validation loss: 1.8736450364512782

Epoch: 6| Step: 2
Training loss: 1.7323567867279053
Validation loss: 1.7915417551994324

Epoch: 6| Step: 3
Training loss: 1.0916225910186768
Validation loss: 1.828837102459323

Epoch: 6| Step: 4
Training loss: 1.8542474508285522
Validation loss: 1.7747086119908158

Epoch: 6| Step: 5
Training loss: 0.9834288954734802
Validation loss: 1.822419383192575

Epoch: 6| Step: 6
Training loss: 0.9097465872764587
Validation loss: 1.8489237754575667

Epoch: 6| Step: 7
Training loss: 0.7641910314559937
Validation loss: 1.8053962799810594

Epoch: 6| Step: 8
Training loss: 1.4545048475265503
Validation loss: 1.7486978077119397

Epoch: 6| Step: 9
Training loss: 0.819195568561554
Validation loss: 1.8118176575629943

Epoch: 6| Step: 10
Training loss: 1.4418556690216064
Validation loss: 1.8007004863472396

Epoch: 6| Step: 11
Training loss: 1.0122323036193848
Validation loss: 1.7822391358754968

Epoch: 6| Step: 12
Training loss: 1.0712720155715942
Validation loss: 1.8002321938032746

Epoch: 6| Step: 13
Training loss: 1.499589443206787
Validation loss: 1.7903197093676495

Epoch: 459| Step: 0
Training loss: 1.2858434915542603
Validation loss: 1.7792383201660649

Epoch: 6| Step: 1
Training loss: 1.3438419103622437
Validation loss: 1.794701632633004

Epoch: 6| Step: 2
Training loss: 1.1937918663024902
Validation loss: 1.8255895671024118

Epoch: 6| Step: 3
Training loss: 0.6452118158340454
Validation loss: 1.756270831631076

Epoch: 6| Step: 4
Training loss: 1.1764729022979736
Validation loss: 1.8184668146153933

Epoch: 6| Step: 5
Training loss: 1.2686433792114258
Validation loss: 1.839364158209934

Epoch: 6| Step: 6
Training loss: 1.5791144371032715
Validation loss: 1.7610451508593816

Epoch: 6| Step: 7
Training loss: 0.8487321138381958
Validation loss: 1.7761722892843268

Epoch: 6| Step: 8
Training loss: 0.8885213732719421
Validation loss: 1.8029309882912585

Epoch: 6| Step: 9
Training loss: 1.3317978382110596
Validation loss: 1.8299795927539948

Epoch: 6| Step: 10
Training loss: 1.5266631841659546
Validation loss: 1.787382725746401

Epoch: 6| Step: 11
Training loss: 0.9622902870178223
Validation loss: 1.8349477655144149

Epoch: 6| Step: 12
Training loss: 1.5444568395614624
Validation loss: 1.8738825334015714

Epoch: 6| Step: 13
Training loss: 1.4579097032546997
Validation loss: 1.8446186909111597

Epoch: 460| Step: 0
Training loss: 0.931039571762085
Validation loss: 1.8261342753646195

Epoch: 6| Step: 1
Training loss: 1.0410001277923584
Validation loss: 1.818733722932877

Epoch: 6| Step: 2
Training loss: 1.4408936500549316
Validation loss: 1.816904442284697

Epoch: 6| Step: 3
Training loss: 1.4812510013580322
Validation loss: 1.8505751150910572

Epoch: 6| Step: 4
Training loss: 1.1791168451309204
Validation loss: 1.818663162569846

Epoch: 6| Step: 5
Training loss: 0.9050761461257935
Validation loss: 1.7946367827794885

Epoch: 6| Step: 6
Training loss: 1.3292196989059448
Validation loss: 1.7980037530263264

Epoch: 6| Step: 7
Training loss: 1.514134407043457
Validation loss: 1.8153101475008073

Epoch: 6| Step: 8
Training loss: 0.8783429265022278
Validation loss: 1.7996851974917996

Epoch: 6| Step: 9
Training loss: 0.8134006261825562
Validation loss: 1.7714662910789571

Epoch: 6| Step: 10
Training loss: 1.1485631465911865
Validation loss: 1.8265199533072851

Epoch: 6| Step: 11
Training loss: 1.713200569152832
Validation loss: 1.8183206383899977

Epoch: 6| Step: 12
Training loss: 1.361130952835083
Validation loss: 1.7862611047683223

Epoch: 6| Step: 13
Training loss: 1.864432692527771
Validation loss: 1.773659908643333

Epoch: 461| Step: 0
Training loss: 0.8995894193649292
Validation loss: 1.8127329875064153

Epoch: 6| Step: 1
Training loss: 1.203190803527832
Validation loss: 1.8644063844475696

Epoch: 6| Step: 2
Training loss: 1.837137222290039
Validation loss: 1.7528155696007512

Epoch: 6| Step: 3
Training loss: 1.2978215217590332
Validation loss: 1.813830546153489

Epoch: 6| Step: 4
Training loss: 0.8054773211479187
Validation loss: 1.7637751858721498

Epoch: 6| Step: 5
Training loss: 0.8780377507209778
Validation loss: 1.8639051798851258

Epoch: 6| Step: 6
Training loss: 0.9699653387069702
Validation loss: 1.8305153974922754

Epoch: 6| Step: 7
Training loss: 1.3663630485534668
Validation loss: 1.7819915407447404

Epoch: 6| Step: 8
Training loss: 1.6191486120224
Validation loss: 1.7813106070282638

Epoch: 6| Step: 9
Training loss: 1.235764980316162
Validation loss: 1.7602320230135353

Epoch: 6| Step: 10
Training loss: 1.4327812194824219
Validation loss: 1.7976748892056045

Epoch: 6| Step: 11
Training loss: 1.386725902557373
Validation loss: 1.7862562761511853

Epoch: 6| Step: 12
Training loss: 0.6644266843795776
Validation loss: 1.8288103098510413

Epoch: 6| Step: 13
Training loss: 1.2017067670822144
Validation loss: 1.8828671375910442

Epoch: 462| Step: 0
Training loss: 0.8871474266052246
Validation loss: 1.8182048284879295

Epoch: 6| Step: 1
Training loss: 0.8788003325462341
Validation loss: 1.8735282254475418

Epoch: 6| Step: 2
Training loss: 1.5770277976989746
Validation loss: 1.8362425373446556

Epoch: 6| Step: 3
Training loss: 1.6436042785644531
Validation loss: 1.7793454559900428

Epoch: 6| Step: 4
Training loss: 1.0942734479904175
Validation loss: 1.8486936630741242

Epoch: 6| Step: 5
Training loss: 1.0990591049194336
Validation loss: 1.8561532010314286

Epoch: 6| Step: 6
Training loss: 0.7427209615707397
Validation loss: 1.810354805761768

Epoch: 6| Step: 7
Training loss: 1.12709379196167
Validation loss: 1.8528592150698426

Epoch: 6| Step: 8
Training loss: 1.316372036933899
Validation loss: 1.8800998272434357

Epoch: 6| Step: 9
Training loss: 1.140434741973877
Validation loss: 1.788274626578054

Epoch: 6| Step: 10
Training loss: 1.0662851333618164
Validation loss: 1.7846390944655224

Epoch: 6| Step: 11
Training loss: 1.503015398979187
Validation loss: 1.7705430715314803

Epoch: 6| Step: 12
Training loss: 1.5845524072647095
Validation loss: 1.7091857925538094

Epoch: 6| Step: 13
Training loss: 1.2411824464797974
Validation loss: 1.7995753262632637

Epoch: 463| Step: 0
Training loss: 1.091960072517395
Validation loss: 1.8571428047713412

Epoch: 6| Step: 1
Training loss: 1.2698334455490112
Validation loss: 1.743386491652458

Epoch: 6| Step: 2
Training loss: 1.1196173429489136
Validation loss: 1.8230948127726072

Epoch: 6| Step: 3
Training loss: 1.2016507387161255
Validation loss: 1.8840031341839862

Epoch: 6| Step: 4
Training loss: 0.8999955058097839
Validation loss: 1.8379453074547552

Epoch: 6| Step: 5
Training loss: 1.2987391948699951
Validation loss: 1.8446490751799716

Epoch: 6| Step: 6
Training loss: 1.1742063760757446
Validation loss: 1.847907195809067

Epoch: 6| Step: 7
Training loss: 1.2409250736236572
Validation loss: 1.8193231474968694

Epoch: 6| Step: 8
Training loss: 1.276340126991272
Validation loss: 1.8115546472610966

Epoch: 6| Step: 9
Training loss: 1.2965965270996094
Validation loss: 1.8932796550053421

Epoch: 6| Step: 10
Training loss: 0.980546236038208
Validation loss: 1.802589516485891

Epoch: 6| Step: 11
Training loss: 1.450913906097412
Validation loss: 1.9110964959667576

Epoch: 6| Step: 12
Training loss: 1.8528714179992676
Validation loss: 1.7831497359019455

Epoch: 6| Step: 13
Training loss: 0.6767404079437256
Validation loss: 1.7486289713972358

Epoch: 464| Step: 0
Training loss: 0.805573046207428
Validation loss: 1.7812104250795098

Epoch: 6| Step: 1
Training loss: 1.3098928928375244
Validation loss: 1.7497867307355326

Epoch: 6| Step: 2
Training loss: 1.5820331573486328
Validation loss: 1.7956405403793498

Epoch: 6| Step: 3
Training loss: 1.6036136150360107
Validation loss: 1.8702529450898528

Epoch: 6| Step: 4
Training loss: 1.2051403522491455
Validation loss: 1.8167790828212615

Epoch: 6| Step: 5
Training loss: 1.3070616722106934
Validation loss: 1.828557099065473

Epoch: 6| Step: 6
Training loss: 1.5260676145553589
Validation loss: 1.8409043947855632

Epoch: 6| Step: 7
Training loss: 0.6635756492614746
Validation loss: 1.7380654581131474

Epoch: 6| Step: 8
Training loss: 1.1643586158752441
Validation loss: 1.8038825706769062

Epoch: 6| Step: 9
Training loss: 1.0977144241333008
Validation loss: 1.8443080994390673

Epoch: 6| Step: 10
Training loss: 1.364233136177063
Validation loss: 1.7917956613725232

Epoch: 6| Step: 11
Training loss: 0.9053569436073303
Validation loss: 1.8571998617982353

Epoch: 6| Step: 12
Training loss: 1.6137136220932007
Validation loss: 1.7882887868471042

Epoch: 6| Step: 13
Training loss: 1.2848246097564697
Validation loss: 1.7984481575668498

Epoch: 465| Step: 0
Training loss: 1.364051103591919
Validation loss: 1.8408573378798783

Epoch: 6| Step: 1
Training loss: 1.2683403491973877
Validation loss: 1.8635170293110672

Epoch: 6| Step: 2
Training loss: 1.6691055297851562
Validation loss: 1.8600349605724376

Epoch: 6| Step: 3
Training loss: 0.8387446999549866
Validation loss: 1.8381930769130748

Epoch: 6| Step: 4
Training loss: 1.3267967700958252
Validation loss: 1.8032452214148738

Epoch: 6| Step: 5
Training loss: 1.087061882019043
Validation loss: 1.8074875300930393

Epoch: 6| Step: 6
Training loss: 1.0535106658935547
Validation loss: 1.815828561782837

Epoch: 6| Step: 7
Training loss: 1.4364185333251953
Validation loss: 1.858745664678594

Epoch: 6| Step: 8
Training loss: 1.080669641494751
Validation loss: 1.7795367727997482

Epoch: 6| Step: 9
Training loss: 1.2060579061508179
Validation loss: 1.8049348297939505

Epoch: 6| Step: 10
Training loss: 0.8783212304115295
Validation loss: 1.7932990033139464

Epoch: 6| Step: 11
Training loss: 1.3004403114318848
Validation loss: 1.8347126796681394

Epoch: 6| Step: 12
Training loss: 1.302632451057434
Validation loss: 1.7899906430193173

Epoch: 6| Step: 13
Training loss: 1.3240396976470947
Validation loss: 1.7918730365332736

Epoch: 466| Step: 0
Training loss: 1.2437450885772705
Validation loss: 1.8044726117964713

Epoch: 6| Step: 1
Training loss: 1.249483346939087
Validation loss: 1.8323273825389084

Epoch: 6| Step: 2
Training loss: 1.3038370609283447
Validation loss: 1.7919177662941717

Epoch: 6| Step: 3
Training loss: 0.9979948401451111
Validation loss: 1.790046117639029

Epoch: 6| Step: 4
Training loss: 1.2720774412155151
Validation loss: 1.7905812827489709

Epoch: 6| Step: 5
Training loss: 1.5135931968688965
Validation loss: 1.7787883679072063

Epoch: 6| Step: 6
Training loss: 1.0168616771697998
Validation loss: 1.795863377150669

Epoch: 6| Step: 7
Training loss: 0.9711081981658936
Validation loss: 1.726785154752834

Epoch: 6| Step: 8
Training loss: 1.218908667564392
Validation loss: 1.8409834113172305

Epoch: 6| Step: 9
Training loss: 1.2627655267715454
Validation loss: 1.785867441085077

Epoch: 6| Step: 10
Training loss: 1.1762444972991943
Validation loss: 1.7873616372385333

Epoch: 6| Step: 11
Training loss: 1.0376207828521729
Validation loss: 1.8127511380821146

Epoch: 6| Step: 12
Training loss: 1.3688148260116577
Validation loss: 1.866909521882252

Epoch: 6| Step: 13
Training loss: 1.1082946062088013
Validation loss: 1.8494405387550272

Epoch: 467| Step: 0
Training loss: 1.0751302242279053
Validation loss: 1.8642586520923081

Epoch: 6| Step: 1
Training loss: 1.5541218519210815
Validation loss: 1.8632952013323385

Epoch: 6| Step: 2
Training loss: 1.701077938079834
Validation loss: 1.8026288901605914

Epoch: 6| Step: 3
Training loss: 1.6393579244613647
Validation loss: 1.8069935588426487

Epoch: 6| Step: 4
Training loss: 0.7427625060081482
Validation loss: 1.7931093156978648

Epoch: 6| Step: 5
Training loss: 1.0592572689056396
Validation loss: 1.8166471501832366

Epoch: 6| Step: 6
Training loss: 1.1389706134796143
Validation loss: 1.7787172858433058

Epoch: 6| Step: 7
Training loss: 0.939281702041626
Validation loss: 1.805906303467289

Epoch: 6| Step: 8
Training loss: 1.399977684020996
Validation loss: 1.771220394360122

Epoch: 6| Step: 9
Training loss: 0.9883052110671997
Validation loss: 1.773164374853975

Epoch: 6| Step: 10
Training loss: 1.1232819557189941
Validation loss: 1.7811671098073323

Epoch: 6| Step: 11
Training loss: 1.0060365200042725
Validation loss: 1.7253328177236742

Epoch: 6| Step: 12
Training loss: 1.239768624305725
Validation loss: 1.8462399974946053

Epoch: 6| Step: 13
Training loss: 2.014012336730957
Validation loss: 1.8343568771116194

Epoch: 468| Step: 0
Training loss: 1.0569508075714111
Validation loss: 1.8115816347060665

Epoch: 6| Step: 1
Training loss: 1.2194715738296509
Validation loss: 1.7735618904072752

Epoch: 6| Step: 2
Training loss: 1.0359824895858765
Validation loss: 1.7953955793893466

Epoch: 6| Step: 3
Training loss: 1.6697146892547607
Validation loss: 1.7935475444280973

Epoch: 6| Step: 4
Training loss: 0.8856219053268433
Validation loss: 1.7999599697769328

Epoch: 6| Step: 5
Training loss: 0.6022703051567078
Validation loss: 1.8014725228791595

Epoch: 6| Step: 6
Training loss: 1.1319990158081055
Validation loss: 1.7775829017803233

Epoch: 6| Step: 7
Training loss: 1.3073453903198242
Validation loss: 1.780828236251749

Epoch: 6| Step: 8
Training loss: 1.241450548171997
Validation loss: 1.804152791218091

Epoch: 6| Step: 9
Training loss: 1.5448877811431885
Validation loss: 1.7660658872255715

Epoch: 6| Step: 10
Training loss: 1.562792420387268
Validation loss: 1.8114209098200644

Epoch: 6| Step: 11
Training loss: 0.6846973896026611
Validation loss: 1.7645037661316574

Epoch: 6| Step: 12
Training loss: 1.2003767490386963
Validation loss: 1.8001605605566373

Epoch: 6| Step: 13
Training loss: 0.9526268839836121
Validation loss: 1.8305645117195704

Epoch: 469| Step: 0
Training loss: 0.773648738861084
Validation loss: 1.8286694095980736

Epoch: 6| Step: 1
Training loss: 1.3920533657073975
Validation loss: 1.8914379073727516

Epoch: 6| Step: 2
Training loss: 1.205566644668579
Validation loss: 1.8486550905371224

Epoch: 6| Step: 3
Training loss: 1.0112444162368774
Validation loss: 1.8465704661543652

Epoch: 6| Step: 4
Training loss: 1.3156296014785767
Validation loss: 1.7893405255450998

Epoch: 6| Step: 5
Training loss: 1.1587239503860474
Validation loss: 1.832022936113419

Epoch: 6| Step: 6
Training loss: 1.31534743309021
Validation loss: 1.855006751193795

Epoch: 6| Step: 7
Training loss: 1.3495972156524658
Validation loss: 1.7594882698469265

Epoch: 6| Step: 8
Training loss: 1.642686128616333
Validation loss: 1.8081676703627392

Epoch: 6| Step: 9
Training loss: 0.9588542580604553
Validation loss: 1.765503598797706

Epoch: 6| Step: 10
Training loss: 0.8156645894050598
Validation loss: 1.8142033341110393

Epoch: 6| Step: 11
Training loss: 1.190894365310669
Validation loss: 1.7676344353665587

Epoch: 6| Step: 12
Training loss: 1.2660754919052124
Validation loss: 1.778480980344998

Epoch: 6| Step: 13
Training loss: 1.282751441001892
Validation loss: 1.7535803907661027

Epoch: 470| Step: 0
Training loss: 1.4644949436187744
Validation loss: 1.7745083570480347

Epoch: 6| Step: 1
Training loss: 0.8878751993179321
Validation loss: 1.7685194976868168

Epoch: 6| Step: 2
Training loss: 0.8343919515609741
Validation loss: 1.8028142554785616

Epoch: 6| Step: 3
Training loss: 1.3412542343139648
Validation loss: 1.7925044618627077

Epoch: 6| Step: 4
Training loss: 0.7586190700531006
Validation loss: 1.7868387250490085

Epoch: 6| Step: 5
Training loss: 1.669844388961792
Validation loss: 1.8028918632896997

Epoch: 6| Step: 6
Training loss: 1.3710150718688965
Validation loss: 1.7665901004627187

Epoch: 6| Step: 7
Training loss: 0.6876245737075806
Validation loss: 1.7727736196210306

Epoch: 6| Step: 8
Training loss: 1.3527252674102783
Validation loss: 1.7595695398187126

Epoch: 6| Step: 9
Training loss: 1.0987412929534912
Validation loss: 1.7509905702324324

Epoch: 6| Step: 10
Training loss: 1.3521931171417236
Validation loss: 1.7589399660787275

Epoch: 6| Step: 11
Training loss: 1.7283549308776855
Validation loss: 1.7987540511674778

Epoch: 6| Step: 12
Training loss: 0.9161218404769897
Validation loss: 1.7901277131931757

Epoch: 6| Step: 13
Training loss: 1.2944674491882324
Validation loss: 1.7971591936644686

Epoch: 471| Step: 0
Training loss: 1.1559934616088867
Validation loss: 1.8082921210155691

Epoch: 6| Step: 1
Training loss: 1.7339527606964111
Validation loss: 1.7939382342882053

Epoch: 6| Step: 2
Training loss: 1.0989279747009277
Validation loss: 1.8318002300877725

Epoch: 6| Step: 3
Training loss: 1.583693265914917
Validation loss: 1.8497175529438963

Epoch: 6| Step: 4
Training loss: 0.7219324707984924
Validation loss: 1.7832794445817188

Epoch: 6| Step: 5
Training loss: 0.8353651762008667
Validation loss: 1.8054567639545729

Epoch: 6| Step: 6
Training loss: 1.2750929594039917
Validation loss: 1.853365417449705

Epoch: 6| Step: 7
Training loss: 1.7893891334533691
Validation loss: 1.80711022884615

Epoch: 6| Step: 8
Training loss: 0.5743504762649536
Validation loss: 1.7686039299093268

Epoch: 6| Step: 9
Training loss: 1.4708595275878906
Validation loss: 1.7857117409347205

Epoch: 6| Step: 10
Training loss: 0.9175630807876587
Validation loss: 1.7907801199984807

Epoch: 6| Step: 11
Training loss: 1.5419167280197144
Validation loss: 1.7781780201901671

Epoch: 6| Step: 12
Training loss: 1.110694169998169
Validation loss: 1.7850774090777162

Epoch: 6| Step: 13
Training loss: 1.0352187156677246
Validation loss: 1.8359883703211302

Epoch: 472| Step: 0
Training loss: 0.9297232627868652
Validation loss: 1.8407131523214362

Epoch: 6| Step: 1
Training loss: 1.8440721035003662
Validation loss: 1.7688662954556045

Epoch: 6| Step: 2
Training loss: 1.5032188892364502
Validation loss: 1.8284586706469137

Epoch: 6| Step: 3
Training loss: 1.1964612007141113
Validation loss: 1.7730345136375838

Epoch: 6| Step: 4
Training loss: 1.0999176502227783
Validation loss: 1.7395955708719069

Epoch: 6| Step: 5
Training loss: 0.7997990846633911
Validation loss: 1.8161615517831617

Epoch: 6| Step: 6
Training loss: 0.9608213901519775
Validation loss: 1.7604826099129134

Epoch: 6| Step: 7
Training loss: 1.2146564722061157
Validation loss: 1.8111853009910994

Epoch: 6| Step: 8
Training loss: 1.089731216430664
Validation loss: 1.8940042347036383

Epoch: 6| Step: 9
Training loss: 0.6007221341133118
Validation loss: 1.8503461999277915

Epoch: 6| Step: 10
Training loss: 0.7819970846176147
Validation loss: 1.8586052451082455

Epoch: 6| Step: 11
Training loss: 1.8500452041625977
Validation loss: 1.8314523389262538

Epoch: 6| Step: 12
Training loss: 1.5384702682495117
Validation loss: 1.8200342450090634

Epoch: 6| Step: 13
Training loss: 1.3069733381271362
Validation loss: 1.8227625739189885

Epoch: 473| Step: 0
Training loss: 1.2943143844604492
Validation loss: 1.8654515512527958

Epoch: 6| Step: 1
Training loss: 0.9858236312866211
Validation loss: 1.8557242488348356

Epoch: 6| Step: 2
Training loss: 0.8713902235031128
Validation loss: 1.778254016753166

Epoch: 6| Step: 3
Training loss: 0.7173606157302856
Validation loss: 1.8191181613552956

Epoch: 6| Step: 4
Training loss: 1.5284162759780884
Validation loss: 1.8075625857999247

Epoch: 6| Step: 5
Training loss: 1.3502471446990967
Validation loss: 1.812685675518487

Epoch: 6| Step: 6
Training loss: 1.316201090812683
Validation loss: 1.8084783054167224

Epoch: 6| Step: 7
Training loss: 0.9312872886657715
Validation loss: 1.7610900120068622

Epoch: 6| Step: 8
Training loss: 0.9195467829704285
Validation loss: 1.7652897578413769

Epoch: 6| Step: 9
Training loss: 1.197385311126709
Validation loss: 1.7854046321684314

Epoch: 6| Step: 10
Training loss: 1.1862030029296875
Validation loss: 1.8225862544070008

Epoch: 6| Step: 11
Training loss: 1.2945250272750854
Validation loss: 1.8264522244853358

Epoch: 6| Step: 12
Training loss: 1.8689165115356445
Validation loss: 1.7990547764685847

Epoch: 6| Step: 13
Training loss: 1.3909636735916138
Validation loss: 1.7425198426810644

Epoch: 474| Step: 0
Training loss: 0.984484851360321
Validation loss: 1.8342001181776806

Epoch: 6| Step: 1
Training loss: 0.808762788772583
Validation loss: 1.828303216606058

Epoch: 6| Step: 2
Training loss: 1.8847732543945312
Validation loss: 1.8410048266892791

Epoch: 6| Step: 3
Training loss: 0.9110417366027832
Validation loss: 1.8064600139535882

Epoch: 6| Step: 4
Training loss: 0.8716895580291748
Validation loss: 1.7504702114289807

Epoch: 6| Step: 5
Training loss: 1.2990703582763672
Validation loss: 1.8164317146424325

Epoch: 6| Step: 6
Training loss: 1.0162386894226074
Validation loss: 1.7655923815183743

Epoch: 6| Step: 7
Training loss: 0.8704779744148254
Validation loss: 1.7772923336234143

Epoch: 6| Step: 8
Training loss: 1.41780686378479
Validation loss: 1.7840927326551048

Epoch: 6| Step: 9
Training loss: 1.0819052457809448
Validation loss: 1.8066228461521927

Epoch: 6| Step: 10
Training loss: 1.909131407737732
Validation loss: 1.8735863393352878

Epoch: 6| Step: 11
Training loss: 0.818040132522583
Validation loss: 1.8044605896037111

Epoch: 6| Step: 12
Training loss: 1.397872805595398
Validation loss: 1.7647898735538605

Epoch: 6| Step: 13
Training loss: 1.3004266023635864
Validation loss: 1.77001892623081

Epoch: 475| Step: 0
Training loss: 1.5870945453643799
Validation loss: 1.806527768411944

Epoch: 6| Step: 1
Training loss: 0.9281302690505981
Validation loss: 1.8381160805302281

Epoch: 6| Step: 2
Training loss: 0.981692373752594
Validation loss: 1.813034035826242

Epoch: 6| Step: 3
Training loss: 1.1641631126403809
Validation loss: 1.763848945658694

Epoch: 6| Step: 4
Training loss: 1.3930779695510864
Validation loss: 1.8579696275854622

Epoch: 6| Step: 5
Training loss: 1.6711609363555908
Validation loss: 1.8259604720659153

Epoch: 6| Step: 6
Training loss: 0.6700857877731323
Validation loss: 1.8207867760812082

Epoch: 6| Step: 7
Training loss: 1.0715725421905518
Validation loss: 1.7950356442441222

Epoch: 6| Step: 8
Training loss: 1.0681164264678955
Validation loss: 1.787524495073544

Epoch: 6| Step: 9
Training loss: 1.2196898460388184
Validation loss: 1.7430556794648528

Epoch: 6| Step: 10
Training loss: 1.1797183752059937
Validation loss: 1.8125447996201054

Epoch: 6| Step: 11
Training loss: 1.1120045185089111
Validation loss: 1.7854814683237383

Epoch: 6| Step: 12
Training loss: 1.1120140552520752
Validation loss: 1.837546246026152

Epoch: 6| Step: 13
Training loss: 0.9878027439117432
Validation loss: 1.7739569961383779

Epoch: 476| Step: 0
Training loss: 1.0497053861618042
Validation loss: 1.7688667594745595

Epoch: 6| Step: 1
Training loss: 1.318253993988037
Validation loss: 1.7960136064919092

Epoch: 6| Step: 2
Training loss: 1.1823785305023193
Validation loss: 1.825689346559586

Epoch: 6| Step: 3
Training loss: 1.2219722270965576
Validation loss: 1.7934159091723862

Epoch: 6| Step: 4
Training loss: 1.23133385181427
Validation loss: 1.754334322867855

Epoch: 6| Step: 5
Training loss: 0.979087233543396
Validation loss: 1.7923770027775918

Epoch: 6| Step: 6
Training loss: 0.8816705942153931
Validation loss: 1.8027682176200293

Epoch: 6| Step: 7
Training loss: 1.4607101678848267
Validation loss: 1.8139761904234528

Epoch: 6| Step: 8
Training loss: 0.9951343536376953
Validation loss: 1.7853630858082925

Epoch: 6| Step: 9
Training loss: 1.252939224243164
Validation loss: 1.8338436695837206

Epoch: 6| Step: 10
Training loss: 0.888741135597229
Validation loss: 1.7726894834990143

Epoch: 6| Step: 11
Training loss: 1.4048213958740234
Validation loss: 1.7776317416980703

Epoch: 6| Step: 12
Training loss: 1.1719344854354858
Validation loss: 1.8078034180466847

Epoch: 6| Step: 13
Training loss: 1.4107108116149902
Validation loss: 1.7936367706585956

Epoch: 477| Step: 0
Training loss: 1.6608800888061523
Validation loss: 1.7725420690351916

Epoch: 6| Step: 1
Training loss: 1.4500831365585327
Validation loss: 1.8535766345198437

Epoch: 6| Step: 2
Training loss: 1.3328208923339844
Validation loss: 1.845306110638444

Epoch: 6| Step: 3
Training loss: 0.8281886577606201
Validation loss: 1.8417847028342627

Epoch: 6| Step: 4
Training loss: 0.7341941595077515
Validation loss: 1.818917841039678

Epoch: 6| Step: 5
Training loss: 1.5142279863357544
Validation loss: 1.773403803507487

Epoch: 6| Step: 6
Training loss: 1.269982099533081
Validation loss: 1.8239804275574223

Epoch: 6| Step: 7
Training loss: 0.7948616743087769
Validation loss: 1.8214385406945341

Epoch: 6| Step: 8
Training loss: 0.95045006275177
Validation loss: 1.7240796127626974

Epoch: 6| Step: 9
Training loss: 1.4541031122207642
Validation loss: 1.8239183092630038

Epoch: 6| Step: 10
Training loss: 1.5623273849487305
Validation loss: 1.8422928676810315

Epoch: 6| Step: 11
Training loss: 0.7722265720367432
Validation loss: 1.7811546018046718

Epoch: 6| Step: 12
Training loss: 1.519704818725586
Validation loss: 1.8235401594510643

Epoch: 6| Step: 13
Training loss: 0.966120183467865
Validation loss: 1.8300348430551507

Epoch: 478| Step: 0
Training loss: 1.2315492630004883
Validation loss: 1.7606168408547678

Epoch: 6| Step: 1
Training loss: 0.7997745871543884
Validation loss: 1.7986490803380166

Epoch: 6| Step: 2
Training loss: 1.6984245777130127
Validation loss: 1.8166678810632357

Epoch: 6| Step: 3
Training loss: 0.7496564388275146
Validation loss: 1.8253509331774969

Epoch: 6| Step: 4
Training loss: 1.1096045970916748
Validation loss: 1.8353612910034836

Epoch: 6| Step: 5
Training loss: 1.319210410118103
Validation loss: 1.8025219030277704

Epoch: 6| Step: 6
Training loss: 1.0188935995101929
Validation loss: 1.7656353212171985

Epoch: 6| Step: 7
Training loss: 1.2480038404464722
Validation loss: 1.8223862045554704

Epoch: 6| Step: 8
Training loss: 1.5188658237457275
Validation loss: 1.8376441719711467

Epoch: 6| Step: 9
Training loss: 1.4843324422836304
Validation loss: 1.8162591739367413

Epoch: 6| Step: 10
Training loss: 1.1349622011184692
Validation loss: 1.8317303170440018

Epoch: 6| Step: 11
Training loss: 1.3642908334732056
Validation loss: 1.8396550186218754

Epoch: 6| Step: 12
Training loss: 1.6406786441802979
Validation loss: 1.8190951180714432

Epoch: 6| Step: 13
Training loss: 1.334949016571045
Validation loss: 1.850753007396575

Epoch: 479| Step: 0
Training loss: 1.0979982614517212
Validation loss: 1.832578771857805

Epoch: 6| Step: 1
Training loss: 0.885138213634491
Validation loss: 1.8345124080616941

Epoch: 6| Step: 2
Training loss: 1.1405971050262451
Validation loss: 1.809690983064713

Epoch: 6| Step: 3
Training loss: 1.2256813049316406
Validation loss: 1.7870635089053903

Epoch: 6| Step: 4
Training loss: 0.6929699182510376
Validation loss: 1.8561445666897682

Epoch: 6| Step: 5
Training loss: 1.1124612092971802
Validation loss: 1.7946365353881673

Epoch: 6| Step: 6
Training loss: 1.667905569076538
Validation loss: 1.8074037656989148

Epoch: 6| Step: 7
Training loss: 1.592391014099121
Validation loss: 1.82260238739752

Epoch: 6| Step: 8
Training loss: 0.7347027063369751
Validation loss: 1.8052238520755564

Epoch: 6| Step: 9
Training loss: 1.167980670928955
Validation loss: 1.8548660637230001

Epoch: 6| Step: 10
Training loss: 0.7351213097572327
Validation loss: 1.860636604729519

Epoch: 6| Step: 11
Training loss: 1.777470588684082
Validation loss: 1.8204668375753588

Epoch: 6| Step: 12
Training loss: 1.3401098251342773
Validation loss: 1.8057319002766763

Epoch: 6| Step: 13
Training loss: 0.7020944952964783
Validation loss: 1.802092964931201

Epoch: 480| Step: 0
Training loss: 1.2222137451171875
Validation loss: 1.8261366531413088

Epoch: 6| Step: 1
Training loss: 1.0414115190505981
Validation loss: 1.8335340087131788

Epoch: 6| Step: 2
Training loss: 0.9567581415176392
Validation loss: 1.7503935265284714

Epoch: 6| Step: 3
Training loss: 0.8370278477668762
Validation loss: 1.8107555591931908

Epoch: 6| Step: 4
Training loss: 1.613318681716919
Validation loss: 1.7766582978669034

Epoch: 6| Step: 5
Training loss: 1.5524325370788574
Validation loss: 1.7488022735041957

Epoch: 6| Step: 6
Training loss: 1.0163958072662354
Validation loss: 1.8049635694872948

Epoch: 6| Step: 7
Training loss: 1.1280200481414795
Validation loss: 1.7720885315249044

Epoch: 6| Step: 8
Training loss: 1.361546277999878
Validation loss: 1.7975533444394347

Epoch: 6| Step: 9
Training loss: 1.1391063928604126
Validation loss: 1.7361878297662223

Epoch: 6| Step: 10
Training loss: 0.8230760097503662
Validation loss: 1.771821968017086

Epoch: 6| Step: 11
Training loss: 1.2270102500915527
Validation loss: 1.7630933382177865

Epoch: 6| Step: 12
Training loss: 1.7223899364471436
Validation loss: 1.830119825178577

Epoch: 6| Step: 13
Training loss: 1.0523878335952759
Validation loss: 1.8373842213743476

Epoch: 481| Step: 0
Training loss: 1.1726576089859009
Validation loss: 1.8114611538507606

Epoch: 6| Step: 1
Training loss: 1.2806897163391113
Validation loss: 1.78486680728133

Epoch: 6| Step: 2
Training loss: 0.9234781265258789
Validation loss: 1.8200618836187548

Epoch: 6| Step: 3
Training loss: 1.1641309261322021
Validation loss: 1.8809007675417009

Epoch: 6| Step: 4
Training loss: 1.8872272968292236
Validation loss: 1.8024432607876357

Epoch: 6| Step: 5
Training loss: 0.881619393825531
Validation loss: 1.8644193705692087

Epoch: 6| Step: 6
Training loss: 1.1131874322891235
Validation loss: 1.8467247947569816

Epoch: 6| Step: 7
Training loss: 1.3072359561920166
Validation loss: 1.8397192173106696

Epoch: 6| Step: 8
Training loss: 0.8449423313140869
Validation loss: 1.8459467477695917

Epoch: 6| Step: 9
Training loss: 1.4564251899719238
Validation loss: 1.8263568185990857

Epoch: 6| Step: 10
Training loss: 1.1419925689697266
Validation loss: 1.8702447311852568

Epoch: 6| Step: 11
Training loss: 0.8389068841934204
Validation loss: 1.8482482664046749

Epoch: 6| Step: 12
Training loss: 2.01863956451416
Validation loss: 1.830407661776389

Epoch: 6| Step: 13
Training loss: 1.0722734928131104
Validation loss: 1.7910125153039091

Epoch: 482| Step: 0
Training loss: 1.2617602348327637
Validation loss: 1.7762478666920816

Epoch: 6| Step: 1
Training loss: 1.4308991432189941
Validation loss: 1.83399078922887

Epoch: 6| Step: 2
Training loss: 0.895280122756958
Validation loss: 1.9079619274344495

Epoch: 6| Step: 3
Training loss: 1.1341614723205566
Validation loss: 1.7627759800162366

Epoch: 6| Step: 4
Training loss: 1.4155268669128418
Validation loss: 1.8026607651864328

Epoch: 6| Step: 5
Training loss: 1.3744691610336304
Validation loss: 1.8294991754716443

Epoch: 6| Step: 6
Training loss: 1.5336647033691406
Validation loss: 1.7601484855016072

Epoch: 6| Step: 7
Training loss: 0.8527570366859436
Validation loss: 1.7342826781734344

Epoch: 6| Step: 8
Training loss: 1.06235933303833
Validation loss: 1.7980809852641115

Epoch: 6| Step: 9
Training loss: 0.6936387419700623
Validation loss: 1.7811454995985954

Epoch: 6| Step: 10
Training loss: 1.287651777267456
Validation loss: 1.786544023021575

Epoch: 6| Step: 11
Training loss: 1.5781618356704712
Validation loss: 1.7548310628501318

Epoch: 6| Step: 12
Training loss: 1.174065351486206
Validation loss: 1.785718862728406

Epoch: 6| Step: 13
Training loss: 0.8918806910514832
Validation loss: 1.8280994494756062

Epoch: 483| Step: 0
Training loss: 1.3532906770706177
Validation loss: 1.7828210553815287

Epoch: 6| Step: 1
Training loss: 1.4760905504226685
Validation loss: 1.831443912239485

Epoch: 6| Step: 2
Training loss: 0.9599366188049316
Validation loss: 1.8268271389827933

Epoch: 6| Step: 3
Training loss: 1.3377115726470947
Validation loss: 1.8351212739944458

Epoch: 6| Step: 4
Training loss: 1.5318608283996582
Validation loss: 1.780519372673445

Epoch: 6| Step: 5
Training loss: 0.8775137662887573
Validation loss: 1.8075084929825158

Epoch: 6| Step: 6
Training loss: 1.0620121955871582
Validation loss: 1.839548933890558

Epoch: 6| Step: 7
Training loss: 1.5917116403579712
Validation loss: 1.8029027895260883

Epoch: 6| Step: 8
Training loss: 1.2053121328353882
Validation loss: 1.828541894112864

Epoch: 6| Step: 9
Training loss: 0.9194235801696777
Validation loss: 1.7486124371969571

Epoch: 6| Step: 10
Training loss: 0.8973668813705444
Validation loss: 1.7556446700967767

Epoch: 6| Step: 11
Training loss: 1.1488837003707886
Validation loss: 1.7776074832485569

Epoch: 6| Step: 12
Training loss: 1.149993896484375
Validation loss: 1.8308977683385212

Epoch: 6| Step: 13
Training loss: 0.9995043277740479
Validation loss: 1.7811418002651584

Epoch: 484| Step: 0
Training loss: 1.2777917385101318
Validation loss: 1.856202898486968

Epoch: 6| Step: 1
Training loss: 1.089570164680481
Validation loss: 1.7724627499939294

Epoch: 6| Step: 2
Training loss: 1.5703240633010864
Validation loss: 1.8452878023988457

Epoch: 6| Step: 3
Training loss: 1.4187339544296265
Validation loss: 1.8014152139745734

Epoch: 6| Step: 4
Training loss: 1.2351648807525635
Validation loss: 1.7885063303414213

Epoch: 6| Step: 5
Training loss: 1.1336355209350586
Validation loss: 1.808967936423517

Epoch: 6| Step: 6
Training loss: 0.9137266874313354
Validation loss: 1.8029236319244548

Epoch: 6| Step: 7
Training loss: 1.5241806507110596
Validation loss: 1.7671199562729045

Epoch: 6| Step: 8
Training loss: 1.0697517395019531
Validation loss: 1.7818283611728298

Epoch: 6| Step: 9
Training loss: 1.2317802906036377
Validation loss: 1.7984411152460242

Epoch: 6| Step: 10
Training loss: 1.1429004669189453
Validation loss: 1.7559812017666396

Epoch: 6| Step: 11
Training loss: 1.156052827835083
Validation loss: 1.7811453624438214

Epoch: 6| Step: 12
Training loss: 0.9953285455703735
Validation loss: 1.8091269411066526

Epoch: 6| Step: 13
Training loss: 1.21219003200531
Validation loss: 1.838261196690221

Epoch: 485| Step: 0
Training loss: 1.0707242488861084
Validation loss: 1.8135089643539921

Epoch: 6| Step: 1
Training loss: 1.1448025703430176
Validation loss: 1.7644146988468785

Epoch: 6| Step: 2
Training loss: 0.9171417355537415
Validation loss: 1.815324225733357

Epoch: 6| Step: 3
Training loss: 1.182863473892212
Validation loss: 1.8381125593698153

Epoch: 6| Step: 4
Training loss: 1.3964974880218506
Validation loss: 1.8204555844747892

Epoch: 6| Step: 5
Training loss: 1.16143000125885
Validation loss: 1.8083785887687438

Epoch: 6| Step: 6
Training loss: 1.3747761249542236
Validation loss: 1.8729549325922483

Epoch: 6| Step: 7
Training loss: 0.9355855584144592
Validation loss: 1.7732479508205126

Epoch: 6| Step: 8
Training loss: 1.047785758972168
Validation loss: 1.822666532249861

Epoch: 6| Step: 9
Training loss: 2.062814950942993
Validation loss: 1.7978878482695548

Epoch: 6| Step: 10
Training loss: 0.6991382837295532
Validation loss: 1.8270224832719373

Epoch: 6| Step: 11
Training loss: 1.3420556783676147
Validation loss: 1.8274534261354836

Epoch: 6| Step: 12
Training loss: 1.141446590423584
Validation loss: 1.8202467579995432

Epoch: 6| Step: 13
Training loss: 0.5404389500617981
Validation loss: 1.79688137321062

Epoch: 486| Step: 0
Training loss: 1.0613768100738525
Validation loss: 1.7827980979796378

Epoch: 6| Step: 1
Training loss: 1.1431077718734741
Validation loss: 1.793303701185411

Epoch: 6| Step: 2
Training loss: 1.217461109161377
Validation loss: 1.7928202511161886

Epoch: 6| Step: 3
Training loss: 0.8347464799880981
Validation loss: 1.8079791735577326

Epoch: 6| Step: 4
Training loss: 0.9735108017921448
Validation loss: 1.7907269757281068

Epoch: 6| Step: 5
Training loss: 0.2879587411880493
Validation loss: 1.8053127796419206

Epoch: 6| Step: 6
Training loss: 1.0522916316986084
Validation loss: 1.8285968816408547

Epoch: 6| Step: 7
Training loss: 1.190041184425354
Validation loss: 1.7118459170864475

Epoch: 6| Step: 8
Training loss: 1.673703908920288
Validation loss: 1.8092887388762606

Epoch: 6| Step: 9
Training loss: 1.2630890607833862
Validation loss: 1.8174289247041107

Epoch: 6| Step: 10
Training loss: 1.7076220512390137
Validation loss: 1.8287309151823803

Epoch: 6| Step: 11
Training loss: 1.0632810592651367
Validation loss: 1.8027502067627446

Epoch: 6| Step: 12
Training loss: 1.3087716102600098
Validation loss: 1.8385056987885506

Epoch: 6| Step: 13
Training loss: 1.4712156057357788
Validation loss: 1.7690337447709934

Epoch: 487| Step: 0
Training loss: 1.3508124351501465
Validation loss: 1.8086123748492169

Epoch: 6| Step: 1
Training loss: 1.6148051023483276
Validation loss: 1.781701018733363

Epoch: 6| Step: 2
Training loss: 1.3114148378372192
Validation loss: 1.815331938446209

Epoch: 6| Step: 3
Training loss: 1.382117509841919
Validation loss: 1.7684496987250544

Epoch: 6| Step: 4
Training loss: 0.4579693078994751
Validation loss: 1.7289921083757955

Epoch: 6| Step: 5
Training loss: 0.6870462894439697
Validation loss: 1.8148717675157773

Epoch: 6| Step: 6
Training loss: 1.761061191558838
Validation loss: 1.763437919719245

Epoch: 6| Step: 7
Training loss: 1.3602017164230347
Validation loss: 1.7812145845864409

Epoch: 6| Step: 8
Training loss: 0.9855272769927979
Validation loss: 1.7347055353144163

Epoch: 6| Step: 9
Training loss: 0.938312292098999
Validation loss: 1.8070457571296281

Epoch: 6| Step: 10
Training loss: 1.1726619005203247
Validation loss: 1.7673181526122554

Epoch: 6| Step: 11
Training loss: 0.8559808135032654
Validation loss: 1.8245548740510018

Epoch: 6| Step: 12
Training loss: 0.854096531867981
Validation loss: 1.919228966518115

Epoch: 6| Step: 13
Training loss: 1.1205590963363647
Validation loss: 1.797630040876327

Epoch: 488| Step: 0
Training loss: 1.5560059547424316
Validation loss: 1.8287660332136257

Epoch: 6| Step: 1
Training loss: 1.2186408042907715
Validation loss: 1.7801238400961763

Epoch: 6| Step: 2
Training loss: 1.0418728590011597
Validation loss: 1.8860940625590663

Epoch: 6| Step: 3
Training loss: 0.8207844495773315
Validation loss: 1.7949519593228576

Epoch: 6| Step: 4
Training loss: 1.2131667137145996
Validation loss: 1.847059960647296

Epoch: 6| Step: 5
Training loss: 1.0202045440673828
Validation loss: 1.8186849650516306

Epoch: 6| Step: 6
Training loss: 1.4258697032928467
Validation loss: 1.9069454157224266

Epoch: 6| Step: 7
Training loss: 0.6914925575256348
Validation loss: 1.804768196998104

Epoch: 6| Step: 8
Training loss: 1.7813446521759033
Validation loss: 1.80804996080296

Epoch: 6| Step: 9
Training loss: 1.2612639665603638
Validation loss: 1.7809976762340916

Epoch: 6| Step: 10
Training loss: 1.4295904636383057
Validation loss: 1.8126695899553196

Epoch: 6| Step: 11
Training loss: 0.9434747695922852
Validation loss: 1.7877283788496448

Epoch: 6| Step: 12
Training loss: 1.0027066469192505
Validation loss: 1.7679938424018122

Epoch: 6| Step: 13
Training loss: 1.6823010444641113
Validation loss: 1.8107094521163611

Epoch: 489| Step: 0
Training loss: 0.633905827999115
Validation loss: 1.7940875073914886

Epoch: 6| Step: 1
Training loss: 1.6048338413238525
Validation loss: 1.7807650643010293

Epoch: 6| Step: 2
Training loss: 1.1195659637451172
Validation loss: 1.7480798344458304

Epoch: 6| Step: 3
Training loss: 1.3183889389038086
Validation loss: 1.7519588060276483

Epoch: 6| Step: 4
Training loss: 0.9589195847511292
Validation loss: 1.7881178099622008

Epoch: 6| Step: 5
Training loss: 1.2714256048202515
Validation loss: 1.8362879201930056

Epoch: 6| Step: 6
Training loss: 1.0707924365997314
Validation loss: 1.7552014832855554

Epoch: 6| Step: 7
Training loss: 1.27730131149292
Validation loss: 1.859599683874397

Epoch: 6| Step: 8
Training loss: 1.398834466934204
Validation loss: 1.812224522713692

Epoch: 6| Step: 9
Training loss: 1.5229904651641846
Validation loss: 1.7797046194794357

Epoch: 6| Step: 10
Training loss: 1.1411337852478027
Validation loss: 1.8197870869790354

Epoch: 6| Step: 11
Training loss: 0.6657314300537109
Validation loss: 1.8750305483418126

Epoch: 6| Step: 12
Training loss: 1.5041794776916504
Validation loss: 1.8306765056425525

Epoch: 6| Step: 13
Training loss: 0.9339998960494995
Validation loss: 1.839776195505614

Epoch: 490| Step: 0
Training loss: 0.6099098920822144
Validation loss: 1.8013056247465071

Epoch: 6| Step: 1
Training loss: 1.3525490760803223
Validation loss: 1.794840920356012

Epoch: 6| Step: 2
Training loss: 1.1793341636657715
Validation loss: 1.8194241395560644

Epoch: 6| Step: 3
Training loss: 1.2774604558944702
Validation loss: 1.764718782517218

Epoch: 6| Step: 4
Training loss: 1.231238842010498
Validation loss: 1.7752512911314606

Epoch: 6| Step: 5
Training loss: 1.0302839279174805
Validation loss: 1.723128366213973

Epoch: 6| Step: 6
Training loss: 1.1686770915985107
Validation loss: 1.8012775695452126

Epoch: 6| Step: 7
Training loss: 1.3686258792877197
Validation loss: 1.833950960507957

Epoch: 6| Step: 8
Training loss: 1.0815004110336304
Validation loss: 1.7617869633500294

Epoch: 6| Step: 9
Training loss: 0.5354501008987427
Validation loss: 1.7373362279707385

Epoch: 6| Step: 10
Training loss: 1.8408020734786987
Validation loss: 1.8098615728398806

Epoch: 6| Step: 11
Training loss: 1.5007011890411377
Validation loss: 1.7766798004027335

Epoch: 6| Step: 12
Training loss: 1.5741193294525146
Validation loss: 1.752521990447916

Epoch: 6| Step: 13
Training loss: 0.6629714965820312
Validation loss: 1.7811505025432957

Epoch: 491| Step: 0
Training loss: 1.2835166454315186
Validation loss: 1.7621482815793765

Epoch: 6| Step: 1
Training loss: 0.8628273010253906
Validation loss: 1.8516723776376376

Epoch: 6| Step: 2
Training loss: 1.2023673057556152
Validation loss: 1.805205443853973

Epoch: 6| Step: 3
Training loss: 1.1854342222213745
Validation loss: 1.7548284299911991

Epoch: 6| Step: 4
Training loss: 1.0049902200698853
Validation loss: 1.7764218789274975

Epoch: 6| Step: 5
Training loss: 1.2734118700027466
Validation loss: 1.7901772183756675

Epoch: 6| Step: 6
Training loss: 1.679414987564087
Validation loss: 1.8449625686932636

Epoch: 6| Step: 7
Training loss: 0.761236310005188
Validation loss: 1.7750093244737195

Epoch: 6| Step: 8
Training loss: 1.074347972869873
Validation loss: 1.8512088739743797

Epoch: 6| Step: 9
Training loss: 0.9196712374687195
Validation loss: 1.779275389127834

Epoch: 6| Step: 10
Training loss: 1.6174269914627075
Validation loss: 1.799121992562407

Epoch: 6| Step: 11
Training loss: 1.2254993915557861
Validation loss: 1.8100459857653546

Epoch: 6| Step: 12
Training loss: 1.1406028270721436
Validation loss: 1.7799420664387364

Epoch: 6| Step: 13
Training loss: 0.6744889616966248
Validation loss: 1.7628557297491259

Epoch: 492| Step: 0
Training loss: 0.9738802909851074
Validation loss: 1.7809277067902267

Epoch: 6| Step: 1
Training loss: 1.1510378122329712
Validation loss: 1.8030456150731733

Epoch: 6| Step: 2
Training loss: 1.1416361331939697
Validation loss: 1.859760046005249

Epoch: 6| Step: 3
Training loss: 1.5183751583099365
Validation loss: 1.775583549212384

Epoch: 6| Step: 4
Training loss: 0.9854316115379333
Validation loss: 1.7853247375898464

Epoch: 6| Step: 5
Training loss: 1.1373460292816162
Validation loss: 1.7811633656101842

Epoch: 6| Step: 6
Training loss: 1.3253552913665771
Validation loss: 1.7905927742681196

Epoch: 6| Step: 7
Training loss: 0.6965656280517578
Validation loss: 1.825043885938583

Epoch: 6| Step: 8
Training loss: 1.602989673614502
Validation loss: 1.8236040530666229

Epoch: 6| Step: 9
Training loss: 1.051940679550171
Validation loss: 1.786573245961179

Epoch: 6| Step: 10
Training loss: 1.1923441886901855
Validation loss: 1.7709781726201375

Epoch: 6| Step: 11
Training loss: 2.0693037509918213
Validation loss: 1.7728395987582464

Epoch: 6| Step: 12
Training loss: 0.928210973739624
Validation loss: 1.7916909661344302

Epoch: 6| Step: 13
Training loss: 0.6405100226402283
Validation loss: 1.7649344987766717

Epoch: 493| Step: 0
Training loss: 1.3501224517822266
Validation loss: 1.7782756577255905

Epoch: 6| Step: 1
Training loss: 1.2991455793380737
Validation loss: 1.8183384121105235

Epoch: 6| Step: 2
Training loss: 1.1850191354751587
Validation loss: 1.8405789457341677

Epoch: 6| Step: 3
Training loss: 1.0954229831695557
Validation loss: 1.751071906858875

Epoch: 6| Step: 4
Training loss: 0.8588671684265137
Validation loss: 1.81351149723094

Epoch: 6| Step: 5
Training loss: 1.2693251371383667
Validation loss: 1.7904400325590564

Epoch: 6| Step: 6
Training loss: 1.0338139533996582
Validation loss: 1.803548812866211

Epoch: 6| Step: 7
Training loss: 1.1903445720672607
Validation loss: 1.7603822664547992

Epoch: 6| Step: 8
Training loss: 0.9740663766860962
Validation loss: 1.806704193033198

Epoch: 6| Step: 9
Training loss: 0.9591858386993408
Validation loss: 1.7582335677198184

Epoch: 6| Step: 10
Training loss: 1.3502756357192993
Validation loss: 1.787473250460881

Epoch: 6| Step: 11
Training loss: 1.0795977115631104
Validation loss: 1.760026793326101

Epoch: 6| Step: 12
Training loss: 1.0876376628875732
Validation loss: 1.7815105376705047

Epoch: 6| Step: 13
Training loss: 1.2865967750549316
Validation loss: 1.8235787576244724

Epoch: 494| Step: 0
Training loss: 1.2912757396697998
Validation loss: 1.786405276226741

Epoch: 6| Step: 1
Training loss: 1.3924500942230225
Validation loss: 1.7691263332161853

Epoch: 6| Step: 2
Training loss: 1.0498793125152588
Validation loss: 1.8693419066808556

Epoch: 6| Step: 3
Training loss: 1.5366302728652954
Validation loss: 1.8644931034375263

Epoch: 6| Step: 4
Training loss: 1.0202219486236572
Validation loss: 1.7826166896409885

Epoch: 6| Step: 5
Training loss: 1.2426377534866333
Validation loss: 1.851245698108468

Epoch: 6| Step: 6
Training loss: 1.0594990253448486
Validation loss: 1.786349775970623

Epoch: 6| Step: 7
Training loss: 1.1314871311187744
Validation loss: 1.7826376538122854

Epoch: 6| Step: 8
Training loss: 1.210681676864624
Validation loss: 1.7878054188143822

Epoch: 6| Step: 9
Training loss: 1.4256799221038818
Validation loss: 1.7716639400810323

Epoch: 6| Step: 10
Training loss: 0.453884482383728
Validation loss: 1.8087810803485174

Epoch: 6| Step: 11
Training loss: 1.280639410018921
Validation loss: 1.813293218612671

Epoch: 6| Step: 12
Training loss: 0.8953510522842407
Validation loss: 1.807996775514336

Epoch: 6| Step: 13
Training loss: 1.3057831525802612
Validation loss: 1.8023379797576575

Epoch: 495| Step: 0
Training loss: 0.8498250246047974
Validation loss: 1.7312837967308619

Epoch: 6| Step: 1
Training loss: 1.6188414096832275
Validation loss: 1.7840116024017334

Epoch: 6| Step: 2
Training loss: 0.9935933351516724
Validation loss: 1.7280646639485513

Epoch: 6| Step: 3
Training loss: 1.25626802444458
Validation loss: 1.8065778093953286

Epoch: 6| Step: 4
Training loss: 1.3363807201385498
Validation loss: 1.7953798655540711

Epoch: 6| Step: 5
Training loss: 1.1762171983718872
Validation loss: 1.8064635517776653

Epoch: 6| Step: 6
Training loss: 1.1630178689956665
Validation loss: 1.7457682150666431

Epoch: 6| Step: 7
Training loss: 1.0461138486862183
Validation loss: 1.7831675403861589

Epoch: 6| Step: 8
Training loss: 1.6541860103607178
Validation loss: 1.7748089375034455

Epoch: 6| Step: 9
Training loss: 1.3296420574188232
Validation loss: 1.7608801716117448

Epoch: 6| Step: 10
Training loss: 0.6747227311134338
Validation loss: 1.7944519596715127

Epoch: 6| Step: 11
Training loss: 1.2796039581298828
Validation loss: 1.7525876183663645

Epoch: 6| Step: 12
Training loss: 1.143852710723877
Validation loss: 1.7479894840589134

Epoch: 6| Step: 13
Training loss: 0.4917970895767212
Validation loss: 1.7597295699581024

Epoch: 496| Step: 0
Training loss: 0.5669149160385132
Validation loss: 1.8244869324468798

Epoch: 6| Step: 1
Training loss: 1.5738599300384521
Validation loss: 1.8235543594565442

Epoch: 6| Step: 2
Training loss: 1.1962072849273682
Validation loss: 1.787363672769198

Epoch: 6| Step: 3
Training loss: 0.966402530670166
Validation loss: 1.8441047001910467

Epoch: 6| Step: 4
Training loss: 1.111877679824829
Validation loss: 1.797509926621632

Epoch: 6| Step: 5
Training loss: 1.1003632545471191
Validation loss: 1.804116205502582

Epoch: 6| Step: 6
Training loss: 1.1652781963348389
Validation loss: 1.8831721505811136

Epoch: 6| Step: 7
Training loss: 0.8665871024131775
Validation loss: 1.795138128342167

Epoch: 6| Step: 8
Training loss: 1.2299343347549438
Validation loss: 1.83415913005029

Epoch: 6| Step: 9
Training loss: 1.7154343128204346
Validation loss: 1.7955402789577362

Epoch: 6| Step: 10
Training loss: 0.8147028684616089
Validation loss: 1.7547471984740226

Epoch: 6| Step: 11
Training loss: 1.9812536239624023
Validation loss: 1.8014221499043126

Epoch: 6| Step: 12
Training loss: 0.49623584747314453
Validation loss: 1.788378543751214

Epoch: 6| Step: 13
Training loss: 1.6510423421859741
Validation loss: 1.8150128600417927

Epoch: 497| Step: 0
Training loss: 0.7008872628211975
Validation loss: 1.6998232269799838

Epoch: 6| Step: 1
Training loss: 1.2967149019241333
Validation loss: 1.7481307816761795

Epoch: 6| Step: 2
Training loss: 2.2270655632019043
Validation loss: 1.7445881802548644

Epoch: 6| Step: 3
Training loss: 0.9473137855529785
Validation loss: 1.741300457267351

Epoch: 6| Step: 4
Training loss: 0.882564902305603
Validation loss: 1.779239986532478

Epoch: 6| Step: 5
Training loss: 2.0011444091796875
Validation loss: 1.8179830274274271

Epoch: 6| Step: 6
Training loss: 1.0530762672424316
Validation loss: 1.8050378548201693

Epoch: 6| Step: 7
Training loss: 0.7701634764671326
Validation loss: 1.8018696526045441

Epoch: 6| Step: 8
Training loss: 1.8942304849624634
Validation loss: 1.7974423311089958

Epoch: 6| Step: 9
Training loss: 0.8163565993309021
Validation loss: 1.8403118579618392

Epoch: 6| Step: 10
Training loss: 0.9610874652862549
Validation loss: 1.8683412895407727

Epoch: 6| Step: 11
Training loss: 0.8078643083572388
Validation loss: 1.8305600881576538

Epoch: 6| Step: 12
Training loss: 0.7586001753807068
Validation loss: 1.7659293720799107

Epoch: 6| Step: 13
Training loss: 0.8952635526657104
Validation loss: 1.7986560265223186

Epoch: 498| Step: 0
Training loss: 1.2442917823791504
Validation loss: 1.8517144995350991

Epoch: 6| Step: 1
Training loss: 0.41897323727607727
Validation loss: 1.7854503880264938

Epoch: 6| Step: 2
Training loss: 1.030077338218689
Validation loss: 1.7793853475201515

Epoch: 6| Step: 3
Training loss: 1.0810890197753906
Validation loss: 1.7772060299432406

Epoch: 6| Step: 4
Training loss: 1.0669152736663818
Validation loss: 1.8143174930285382

Epoch: 6| Step: 5
Training loss: 1.159384846687317
Validation loss: 1.7507622652156378

Epoch: 6| Step: 6
Training loss: 1.1365910768508911
Validation loss: 1.7899022897084553

Epoch: 6| Step: 7
Training loss: 1.350205659866333
Validation loss: 1.762838670002517

Epoch: 6| Step: 8
Training loss: 0.8730082511901855
Validation loss: 1.8020223661135601

Epoch: 6| Step: 9
Training loss: 1.7314971685409546
Validation loss: 1.8444285367124824

Epoch: 6| Step: 10
Training loss: 1.3693352937698364
Validation loss: 1.8050496462852723

Epoch: 6| Step: 11
Training loss: 1.6700855493545532
Validation loss: 1.7734351247869513

Epoch: 6| Step: 12
Training loss: 0.9214315414428711
Validation loss: 1.803819078271107

Epoch: 6| Step: 13
Training loss: 1.0520024299621582
Validation loss: 1.795582317536877

Epoch: 499| Step: 0
Training loss: 1.1535168886184692
Validation loss: 1.780463252016293

Epoch: 6| Step: 1
Training loss: 1.0928785800933838
Validation loss: 1.7905421551837717

Epoch: 6| Step: 2
Training loss: 0.8076515197753906
Validation loss: 1.805910555265283

Epoch: 6| Step: 3
Training loss: 0.8895963430404663
Validation loss: 1.884418623421782

Epoch: 6| Step: 4
Training loss: 0.8074280023574829
Validation loss: 1.7744274934132893

Epoch: 6| Step: 5
Training loss: 1.8084607124328613
Validation loss: 1.8090216562312136

Epoch: 6| Step: 6
Training loss: 1.164332628250122
Validation loss: 1.7907511880320888

Epoch: 6| Step: 7
Training loss: 1.7772313356399536
Validation loss: 1.7663211373872654

Epoch: 6| Step: 8
Training loss: 1.1917760372161865
Validation loss: 1.7819907408888622

Epoch: 6| Step: 9
Training loss: 0.738029956817627
Validation loss: 1.8370868941789031

Epoch: 6| Step: 10
Training loss: 0.8585319519042969
Validation loss: 1.830875394164875

Epoch: 6| Step: 11
Training loss: 2.0438742637634277
Validation loss: 1.806283191968036

Epoch: 6| Step: 12
Training loss: 0.9676687717437744
Validation loss: 1.835202350411364

Epoch: 6| Step: 13
Training loss: 0.41699472069740295
Validation loss: 1.8187673643071165

Epoch: 500| Step: 0
Training loss: 1.058595895767212
Validation loss: 1.8067762877351494

Epoch: 6| Step: 1
Training loss: 1.2336115837097168
Validation loss: 1.85140440540929

Epoch: 6| Step: 2
Training loss: 0.9108365774154663
Validation loss: 1.8539917187024189

Epoch: 6| Step: 3
Training loss: 1.6668643951416016
Validation loss: 1.814861427071274

Epoch: 6| Step: 4
Training loss: 1.5707166194915771
Validation loss: 1.8057533246214672

Epoch: 6| Step: 5
Training loss: 1.2664518356323242
Validation loss: 1.7970305027500275

Epoch: 6| Step: 6
Training loss: 1.261526107788086
Validation loss: 1.7981099210759646

Epoch: 6| Step: 7
Training loss: 1.064914584159851
Validation loss: 1.7744100209205382

Epoch: 6| Step: 8
Training loss: 1.8210283517837524
Validation loss: 1.7635787558811966

Epoch: 6| Step: 9
Training loss: 1.163555383682251
Validation loss: 1.797613315684821

Epoch: 6| Step: 10
Training loss: 0.6370174288749695
Validation loss: 1.733513387300635

Epoch: 6| Step: 11
Training loss: 0.8935467004776001
Validation loss: 1.7318127924396145

Epoch: 6| Step: 12
Training loss: 0.9177098274230957
Validation loss: 1.7940612685295843

Epoch: 6| Step: 13
Training loss: 0.6966766119003296
Validation loss: 1.7789532523001395

Epoch: 501| Step: 0
Training loss: 1.1475715637207031
Validation loss: 1.7428864817465506

Epoch: 6| Step: 1
Training loss: 0.8072146773338318
Validation loss: 1.783366431472122

Epoch: 6| Step: 2
Training loss: 1.0320230722427368
Validation loss: 1.808007021104136

Epoch: 6| Step: 3
Training loss: 1.0408551692962646
Validation loss: 1.8333999572261688

Epoch: 6| Step: 4
Training loss: 1.7436230182647705
Validation loss: 1.82077274527601

Epoch: 6| Step: 5
Training loss: 1.2886159420013428
Validation loss: 1.840737804289787

Epoch: 6| Step: 6
Training loss: 0.6628913283348083
Validation loss: 1.8470609854626399

Epoch: 6| Step: 7
Training loss: 1.284001111984253
Validation loss: 1.7595781498057868

Epoch: 6| Step: 8
Training loss: 1.5508131980895996
Validation loss: 1.8351319823213803

Epoch: 6| Step: 9
Training loss: 1.455930471420288
Validation loss: 1.8043666270471388

Epoch: 6| Step: 10
Training loss: 0.7558794617652893
Validation loss: 1.8264755779697048

Epoch: 6| Step: 11
Training loss: 1.0820016860961914
Validation loss: 1.8037460414312219

Epoch: 6| Step: 12
Training loss: 1.2943377494812012
Validation loss: 1.7677593628565471

Epoch: 6| Step: 13
Training loss: 0.9520499110221863
Validation loss: 1.8097326050522506

Epoch: 502| Step: 0
Training loss: 1.1315150260925293
Validation loss: 1.8348897349449895

Epoch: 6| Step: 1
Training loss: 0.9148218631744385
Validation loss: 1.7833449186817292

Epoch: 6| Step: 2
Training loss: 1.3255178928375244
Validation loss: 1.7890019109172206

Epoch: 6| Step: 3
Training loss: 1.4142835140228271
Validation loss: 1.7933199764579855

Epoch: 6| Step: 4
Training loss: 1.2694706916809082
Validation loss: 1.8361245291207426

Epoch: 6| Step: 5
Training loss: 0.987939178943634
Validation loss: 1.8379063824171662

Epoch: 6| Step: 6
Training loss: 1.0738656520843506
Validation loss: 1.7143693547095022

Epoch: 6| Step: 7
Training loss: 1.3401119709014893
Validation loss: 1.8324504924076859

Epoch: 6| Step: 8
Training loss: 1.1269830465316772
Validation loss: 1.7732574862818564

Epoch: 6| Step: 9
Training loss: 0.8671869039535522
Validation loss: 1.7596085609928254

Epoch: 6| Step: 10
Training loss: 0.8581154942512512
Validation loss: 1.8566472658547022

Epoch: 6| Step: 11
Training loss: 0.9401963949203491
Validation loss: 1.8115576274933354

Epoch: 6| Step: 12
Training loss: 1.7757785320281982
Validation loss: 1.8125693669883154

Epoch: 6| Step: 13
Training loss: 0.49383825063705444
Validation loss: 1.7999383326499694

Epoch: 503| Step: 0
Training loss: 0.9754223823547363
Validation loss: 1.7853485999568817

Epoch: 6| Step: 1
Training loss: 0.939518928527832
Validation loss: 1.7859621919611448

Epoch: 6| Step: 2
Training loss: 1.2148936986923218
Validation loss: 1.7239869832992554

Epoch: 6| Step: 3
Training loss: 0.8992506861686707
Validation loss: 1.807316372471471

Epoch: 6| Step: 4
Training loss: 1.3164558410644531
Validation loss: 1.823559312410252

Epoch: 6| Step: 5
Training loss: 1.0627214908599854
Validation loss: 1.7614962298382995

Epoch: 6| Step: 6
Training loss: 1.073101282119751
Validation loss: 1.827890573009368

Epoch: 6| Step: 7
Training loss: 1.7339165210723877
Validation loss: 1.7698118686676025

Epoch: 6| Step: 8
Training loss: 1.2666497230529785
Validation loss: 1.7358027171063166

Epoch: 6| Step: 9
Training loss: 0.7430373430252075
Validation loss: 1.8038747605457102

Epoch: 6| Step: 10
Training loss: 1.0696592330932617
Validation loss: 1.7590929333881666

Epoch: 6| Step: 11
Training loss: 0.9661084413528442
Validation loss: 1.8085118737272037

Epoch: 6| Step: 12
Training loss: 1.1682082414627075
Validation loss: 1.7824306077854608

Epoch: 6| Step: 13
Training loss: 0.7838044762611389
Validation loss: 1.79223729589934

Epoch: 504| Step: 0
Training loss: 0.8089726567268372
Validation loss: 1.7250988560338174

Epoch: 6| Step: 1
Training loss: 1.1593384742736816
Validation loss: 1.7778183644817722

Epoch: 6| Step: 2
Training loss: 1.279456377029419
Validation loss: 1.7943371124165033

Epoch: 6| Step: 3
Training loss: 1.6090110540390015
Validation loss: 1.771117869243827

Epoch: 6| Step: 4
Training loss: 1.12269926071167
Validation loss: 1.7848415746483752

Epoch: 6| Step: 5
Training loss: 1.1925264596939087
Validation loss: 1.7699952125549316

Epoch: 6| Step: 6
Training loss: 1.1611571311950684
Validation loss: 1.8108161341759466

Epoch: 6| Step: 7
Training loss: 1.2105991840362549
Validation loss: 1.8041383169030631

Epoch: 6| Step: 8
Training loss: 1.0325528383255005
Validation loss: 1.844885713310652

Epoch: 6| Step: 9
Training loss: 1.0125627517700195
Validation loss: 1.7601233502869964

Epoch: 6| Step: 10
Training loss: 1.309039831161499
Validation loss: 1.8303422274128083

Epoch: 6| Step: 11
Training loss: 1.0195454359054565
Validation loss: 1.8528237342834473

Epoch: 6| Step: 12
Training loss: 1.0178933143615723
Validation loss: 1.8283173820023895

Epoch: 6| Step: 13
Training loss: 0.7060451507568359
Validation loss: 1.7851527455032512

Epoch: 505| Step: 0
Training loss: 1.8775734901428223
Validation loss: 1.8334471423138854

Epoch: 6| Step: 1
Training loss: 0.5262995958328247
Validation loss: 1.817946026402135

Epoch: 6| Step: 2
Training loss: 1.1753716468811035
Validation loss: 1.7890806377574962

Epoch: 6| Step: 3
Training loss: 0.7230900526046753
Validation loss: 1.8051231548350344

Epoch: 6| Step: 4
Training loss: 1.455372929573059
Validation loss: 1.7857802209033762

Epoch: 6| Step: 5
Training loss: 0.7418844103813171
Validation loss: 1.8033243122921194

Epoch: 6| Step: 6
Training loss: 1.2162574529647827
Validation loss: 1.835909366607666

Epoch: 6| Step: 7
Training loss: 1.1995875835418701
Validation loss: 1.7833073113554267

Epoch: 6| Step: 8
Training loss: 1.5144093036651611
Validation loss: 1.7980218061836817

Epoch: 6| Step: 9
Training loss: 0.9507720470428467
Validation loss: 1.8513159008436306

Epoch: 6| Step: 10
Training loss: 0.9977648258209229
Validation loss: 1.7600344073387884

Epoch: 6| Step: 11
Training loss: 0.9260941743850708
Validation loss: 1.7665221614222373

Epoch: 6| Step: 12
Training loss: 0.8457536697387695
Validation loss: 1.797135974771233

Epoch: 6| Step: 13
Training loss: 2.3146989345550537
Validation loss: 1.771592596525787

Epoch: 506| Step: 0
Training loss: 1.6709282398223877
Validation loss: 1.784588804808996

Epoch: 6| Step: 1
Training loss: 1.0709898471832275
Validation loss: 1.7766455937457342

Epoch: 6| Step: 2
Training loss: 1.3201626539230347
Validation loss: 1.786152091077579

Epoch: 6| Step: 3
Training loss: 1.1594288349151611
Validation loss: 1.7723723150068713

Epoch: 6| Step: 4
Training loss: 0.8093358278274536
Validation loss: 1.8054439213968092

Epoch: 6| Step: 5
Training loss: 1.0301644802093506
Validation loss: 1.771001656850179

Epoch: 6| Step: 6
Training loss: 1.0575188398361206
Validation loss: 1.8051441164426907

Epoch: 6| Step: 7
Training loss: 1.1210756301879883
Validation loss: 1.7487230685449415

Epoch: 6| Step: 8
Training loss: 1.2356212139129639
Validation loss: 1.7287776598366358

Epoch: 6| Step: 9
Training loss: 1.1141905784606934
Validation loss: 1.7363945207288187

Epoch: 6| Step: 10
Training loss: 0.9733051061630249
Validation loss: 1.76599641512799

Epoch: 6| Step: 11
Training loss: 0.9703184962272644
Validation loss: 1.7532709131958664

Epoch: 6| Step: 12
Training loss: 0.9350045919418335
Validation loss: 1.7383062172961492

Epoch: 6| Step: 13
Training loss: 1.8556194305419922
Validation loss: 1.7708579660743795

Epoch: 507| Step: 0
Training loss: 0.9634706377983093
Validation loss: 1.7843895343042189

Epoch: 6| Step: 1
Training loss: 0.9829317927360535
Validation loss: 1.733956817657717

Epoch: 6| Step: 2
Training loss: 0.6647956967353821
Validation loss: 1.8461347818374634

Epoch: 6| Step: 3
Training loss: 1.0238978862762451
Validation loss: 1.7463532993870396

Epoch: 6| Step: 4
Training loss: 1.2781589031219482
Validation loss: 1.8517765883476502

Epoch: 6| Step: 5
Training loss: 1.811241865158081
Validation loss: 1.8083625480692873

Epoch: 6| Step: 6
Training loss: 1.3736381530761719
Validation loss: 1.796710075870637

Epoch: 6| Step: 7
Training loss: 0.9550312161445618
Validation loss: 1.8019892554129324

Epoch: 6| Step: 8
Training loss: 1.5074738264083862
Validation loss: 1.6983082627737394

Epoch: 6| Step: 9
Training loss: 0.9307519197463989
Validation loss: 1.7182012937402213

Epoch: 6| Step: 10
Training loss: 0.6142475605010986
Validation loss: 1.7484261938320693

Epoch: 6| Step: 11
Training loss: 0.8686131238937378
Validation loss: 1.8087437857863724

Epoch: 6| Step: 12
Training loss: 1.2511777877807617
Validation loss: 1.7983712073295348

Epoch: 6| Step: 13
Training loss: 1.1401220560073853
Validation loss: 1.7758414104420652

Epoch: 508| Step: 0
Training loss: 0.8831261396408081
Validation loss: 1.793116646428262

Epoch: 6| Step: 1
Training loss: 1.163901925086975
Validation loss: 1.761529880185281

Epoch: 6| Step: 2
Training loss: 0.9807258248329163
Validation loss: 1.8703788647087671

Epoch: 6| Step: 3
Training loss: 1.2967078685760498
Validation loss: 1.802911199549193

Epoch: 6| Step: 4
Training loss: 1.5170550346374512
Validation loss: 1.7999717804693407

Epoch: 6| Step: 5
Training loss: 1.3216958045959473
Validation loss: 1.7965237620056316

Epoch: 6| Step: 6
Training loss: 1.0441105365753174
Validation loss: 1.7603949295577181

Epoch: 6| Step: 7
Training loss: 1.1099750995635986
Validation loss: 1.7397977203451178

Epoch: 6| Step: 8
Training loss: 0.6841411590576172
Validation loss: 1.7404384484855078

Epoch: 6| Step: 9
Training loss: 0.5592143535614014
Validation loss: 1.8254140859009118

Epoch: 6| Step: 10
Training loss: 0.7737793922424316
Validation loss: 1.7695668692229896

Epoch: 6| Step: 11
Training loss: 1.3677537441253662
Validation loss: 1.8071990038758965

Epoch: 6| Step: 12
Training loss: 1.6850104331970215
Validation loss: 1.742820337254514

Epoch: 6| Step: 13
Training loss: 1.76913321018219
Validation loss: 1.7919445665933753

Epoch: 509| Step: 0
Training loss: 1.3184837102890015
Validation loss: 1.7530847749402445

Epoch: 6| Step: 1
Training loss: 1.726480484008789
Validation loss: 1.7797414500226256

Epoch: 6| Step: 2
Training loss: 1.1084518432617188
Validation loss: 1.7953233872690508

Epoch: 6| Step: 3
Training loss: 1.3182499408721924
Validation loss: 1.7835838051252468

Epoch: 6| Step: 4
Training loss: 0.9846388101577759
Validation loss: 1.8224714917521323

Epoch: 6| Step: 5
Training loss: 1.1146321296691895
Validation loss: 1.7988014439100861

Epoch: 6| Step: 6
Training loss: 1.4089891910552979
Validation loss: 1.7206032109516922

Epoch: 6| Step: 7
Training loss: 0.8180036544799805
Validation loss: 1.8454094497106408

Epoch: 6| Step: 8
Training loss: 1.275153636932373
Validation loss: 1.7335741609655402

Epoch: 6| Step: 9
Training loss: 0.9085320234298706
Validation loss: 1.7897491865260626

Epoch: 6| Step: 10
Training loss: 1.072106122970581
Validation loss: 1.826714482358707

Epoch: 6| Step: 11
Training loss: 1.0898654460906982
Validation loss: 1.8150010493493849

Epoch: 6| Step: 12
Training loss: 0.580039381980896
Validation loss: 1.8242120973525509

Epoch: 6| Step: 13
Training loss: 0.522065281867981
Validation loss: 1.7799349895087622

Epoch: 510| Step: 0
Training loss: 1.0908238887786865
Validation loss: 1.811470006101875

Epoch: 6| Step: 1
Training loss: 1.3785115480422974
Validation loss: 1.8039850868204588

Epoch: 6| Step: 2
Training loss: 0.7717791795730591
Validation loss: 1.7845582039125505

Epoch: 6| Step: 3
Training loss: 0.9674568176269531
Validation loss: 1.8365488808642152

Epoch: 6| Step: 4
Training loss: 1.2377716302871704
Validation loss: 1.8109826939080351

Epoch: 6| Step: 5
Training loss: 1.0522758960723877
Validation loss: 1.7589342953056417

Epoch: 6| Step: 6
Training loss: 0.8872820138931274
Validation loss: 1.7293716758810065

Epoch: 6| Step: 7
Training loss: 0.769777774810791
Validation loss: 1.7416568956067484

Epoch: 6| Step: 8
Training loss: 1.1103299856185913
Validation loss: 1.7966121627438454

Epoch: 6| Step: 9
Training loss: 0.9630030393600464
Validation loss: 1.7590209335409186

Epoch: 6| Step: 10
Training loss: 2.157043218612671
Validation loss: 1.839349715940414

Epoch: 6| Step: 11
Training loss: 1.242981195449829
Validation loss: 1.7270569352693455

Epoch: 6| Step: 12
Training loss: 0.7518172264099121
Validation loss: 1.799003683110719

Epoch: 6| Step: 13
Training loss: 1.2530690431594849
Validation loss: 1.7261694605632494

Epoch: 511| Step: 0
Training loss: 1.4883891344070435
Validation loss: 1.753741261779621

Epoch: 6| Step: 1
Training loss: 1.2161331176757812
Validation loss: 1.7651289316915697

Epoch: 6| Step: 2
Training loss: 1.1957755088806152
Validation loss: 1.7702592572858256

Epoch: 6| Step: 3
Training loss: 1.0562630891799927
Validation loss: 1.7519689817582407

Epoch: 6| Step: 4
Training loss: 1.194591760635376
Validation loss: 1.788796155683456

Epoch: 6| Step: 5
Training loss: 0.8091610670089722
Validation loss: 1.8082348351837487

Epoch: 6| Step: 6
Training loss: 0.5521963238716125
Validation loss: 1.7810448023580736

Epoch: 6| Step: 7
Training loss: 0.3635184168815613
Validation loss: 1.8166285637886292

Epoch: 6| Step: 8
Training loss: 1.4105238914489746
Validation loss: 1.778547215205367

Epoch: 6| Step: 9
Training loss: 0.9414821863174438
Validation loss: 1.7873347869483374

Epoch: 6| Step: 10
Training loss: 1.2151355743408203
Validation loss: 1.794958600433924

Epoch: 6| Step: 11
Training loss: 0.8992431163787842
Validation loss: 1.7968703880104968

Epoch: 6| Step: 12
Training loss: 1.3027760982513428
Validation loss: 1.809026397684569

Epoch: 6| Step: 13
Training loss: 1.461977243423462
Validation loss: 1.79086430739331

Epoch: 512| Step: 0
Training loss: 1.2256524562835693
Validation loss: 1.831172109932028

Epoch: 6| Step: 1
Training loss: 1.1220088005065918
Validation loss: 1.7834117040839246

Epoch: 6| Step: 2
Training loss: 1.605981469154358
Validation loss: 1.740017552529612

Epoch: 6| Step: 3
Training loss: 1.5729024410247803
Validation loss: 1.771384737824881

Epoch: 6| Step: 4
Training loss: 1.0565903186798096
Validation loss: 1.8318083222194383

Epoch: 6| Step: 5
Training loss: 0.49138200283050537
Validation loss: 1.7600019337028585

Epoch: 6| Step: 6
Training loss: 0.9283804893493652
Validation loss: 1.7959778385777627

Epoch: 6| Step: 7
Training loss: 1.3633275032043457
Validation loss: 1.7925655059916998

Epoch: 6| Step: 8
Training loss: 0.835253894329071
Validation loss: 1.8028859810162616

Epoch: 6| Step: 9
Training loss: 1.112929105758667
Validation loss: 1.7334996423413676

Epoch: 6| Step: 10
Training loss: 0.9738147258758545
Validation loss: 1.766911534852879

Epoch: 6| Step: 11
Training loss: 0.6851680278778076
Validation loss: 1.7404102804840251

Epoch: 6| Step: 12
Training loss: 0.9957721829414368
Validation loss: 1.7517178494443175

Epoch: 6| Step: 13
Training loss: 1.437773585319519
Validation loss: 1.8244784698691419

Epoch: 513| Step: 0
Training loss: 0.9917052984237671
Validation loss: 1.8336185293812906

Epoch: 6| Step: 1
Training loss: 0.9871657490730286
Validation loss: 1.7760512290462371

Epoch: 6| Step: 2
Training loss: 1.205256700515747
Validation loss: 1.7562207470658004

Epoch: 6| Step: 3
Training loss: 0.9173797369003296
Validation loss: 1.8255193105307959

Epoch: 6| Step: 4
Training loss: 0.9739290475845337
Validation loss: 1.7563002455619074

Epoch: 6| Step: 5
Training loss: 1.5022377967834473
Validation loss: 1.8032473492366012

Epoch: 6| Step: 6
Training loss: 1.1773353815078735
Validation loss: 1.8274210652997416

Epoch: 6| Step: 7
Training loss: 0.8983861207962036
Validation loss: 1.8123579089359572

Epoch: 6| Step: 8
Training loss: 1.273634910583496
Validation loss: 1.7999552924145934

Epoch: 6| Step: 9
Training loss: 1.3414862155914307
Validation loss: 1.8064182368657922

Epoch: 6| Step: 10
Training loss: 1.0042105913162231
Validation loss: 1.8816444066263014

Epoch: 6| Step: 11
Training loss: 1.142523169517517
Validation loss: 1.7719789346059163

Epoch: 6| Step: 12
Training loss: 1.3909498453140259
Validation loss: 1.8219488025993429

Epoch: 6| Step: 13
Training loss: 1.9708867073059082
Validation loss: 1.8096154953843804

Epoch: 514| Step: 0
Training loss: 1.0394108295440674
Validation loss: 1.766602526428879

Epoch: 6| Step: 1
Training loss: 1.399501919746399
Validation loss: 1.7662715296591482

Epoch: 6| Step: 2
Training loss: 1.454477310180664
Validation loss: 1.8157576053373274

Epoch: 6| Step: 3
Training loss: 1.32370924949646
Validation loss: 1.749861063495759

Epoch: 6| Step: 4
Training loss: 1.3958615064620972
Validation loss: 1.7550372295482184

Epoch: 6| Step: 5
Training loss: 0.8595280647277832
Validation loss: 1.771921375746368

Epoch: 6| Step: 6
Training loss: 1.0583224296569824
Validation loss: 1.7545350943842242

Epoch: 6| Step: 7
Training loss: 0.9300206303596497
Validation loss: 1.7837257462163125

Epoch: 6| Step: 8
Training loss: 0.6602827906608582
Validation loss: 1.8391228645078597

Epoch: 6| Step: 9
Training loss: 1.3312911987304688
Validation loss: 1.8184728096890193

Epoch: 6| Step: 10
Training loss: 1.0004042387008667
Validation loss: 1.7964848151770971

Epoch: 6| Step: 11
Training loss: 1.1397823095321655
Validation loss: 1.8084993426517775

Epoch: 6| Step: 12
Training loss: 1.0640510320663452
Validation loss: 1.778539788338446

Epoch: 6| Step: 13
Training loss: 0.9978575110435486
Validation loss: 1.8307954649771414

Epoch: 515| Step: 0
Training loss: 0.641837477684021
Validation loss: 1.8270849720124276

Epoch: 6| Step: 1
Training loss: 1.009651780128479
Validation loss: 1.8190751998655257

Epoch: 6| Step: 2
Training loss: 1.0803663730621338
Validation loss: 1.810561510824388

Epoch: 6| Step: 3
Training loss: 0.7841635942459106
Validation loss: 1.799933889860748

Epoch: 6| Step: 4
Training loss: 1.1080920696258545
Validation loss: 1.764261943037792

Epoch: 6| Step: 5
Training loss: 1.2352683544158936
Validation loss: 1.8198665713751188

Epoch: 6| Step: 6
Training loss: 1.172792673110962
Validation loss: 1.740631280406829

Epoch: 6| Step: 7
Training loss: 1.4519834518432617
Validation loss: 1.845728656297089

Epoch: 6| Step: 8
Training loss: 1.0454820394515991
Validation loss: 1.7660740267845891

Epoch: 6| Step: 9
Training loss: 1.4767134189605713
Validation loss: 1.746986791651736

Epoch: 6| Step: 10
Training loss: 1.5748670101165771
Validation loss: 1.857585794182234

Epoch: 6| Step: 11
Training loss: 0.7725455164909363
Validation loss: 1.7610722946864303

Epoch: 6| Step: 12
Training loss: 0.7677115797996521
Validation loss: 1.811019810297156

Epoch: 6| Step: 13
Training loss: 1.3555376529693604
Validation loss: 1.7512120046923239

Epoch: 516| Step: 0
Training loss: 0.8764172196388245
Validation loss: 1.8152907099775089

Epoch: 6| Step: 1
Training loss: 1.2853705883026123
Validation loss: 1.781830653067558

Epoch: 6| Step: 2
Training loss: 1.1975634098052979
Validation loss: 1.7680818278302428

Epoch: 6| Step: 3
Training loss: 0.7859997749328613
Validation loss: 1.7692058496577765

Epoch: 6| Step: 4
Training loss: 1.1611307859420776
Validation loss: 1.7236936476922804

Epoch: 6| Step: 5
Training loss: 1.1199597120285034
Validation loss: 1.7417949527822516

Epoch: 6| Step: 6
Training loss: 1.4432711601257324
Validation loss: 1.713628181847193

Epoch: 6| Step: 7
Training loss: 1.193519115447998
Validation loss: 1.758190607511869

Epoch: 6| Step: 8
Training loss: 1.4396255016326904
Validation loss: 1.7677065877504246

Epoch: 6| Step: 9
Training loss: 0.8911172747612
Validation loss: 1.7835042322835615

Epoch: 6| Step: 10
Training loss: 0.8385847210884094
Validation loss: 1.7969081786371046

Epoch: 6| Step: 11
Training loss: 1.6343430280685425
Validation loss: 1.7693451322535032

Epoch: 6| Step: 12
Training loss: 1.1962121725082397
Validation loss: 1.8564958777478946

Epoch: 6| Step: 13
Training loss: 0.5233321785926819
Validation loss: 1.8363034699552803

Epoch: 517| Step: 0
Training loss: 0.7599323987960815
Validation loss: 1.8695309546685988

Epoch: 6| Step: 1
Training loss: 1.546752691268921
Validation loss: 1.8772088981443835

Epoch: 6| Step: 2
Training loss: 1.5032086372375488
Validation loss: 1.8847063946467575

Epoch: 6| Step: 3
Training loss: 1.3098965883255005
Validation loss: 1.8302281697591145

Epoch: 6| Step: 4
Training loss: 1.088942527770996
Validation loss: 1.8936774179499636

Epoch: 6| Step: 5
Training loss: 0.9472562074661255
Validation loss: 1.922754426156321

Epoch: 6| Step: 6
Training loss: 1.3299050331115723
Validation loss: 1.8170173552728468

Epoch: 6| Step: 7
Training loss: 1.0278451442718506
Validation loss: 1.863433640490296

Epoch: 6| Step: 8
Training loss: 0.9850856065750122
Validation loss: 1.8755628960106963

Epoch: 6| Step: 9
Training loss: 0.8276728391647339
Validation loss: 1.8233009115342171

Epoch: 6| Step: 10
Training loss: 1.3082044124603271
Validation loss: 1.760870805350683

Epoch: 6| Step: 11
Training loss: 1.0351905822753906
Validation loss: 1.8071728111595236

Epoch: 6| Step: 12
Training loss: 1.4118731021881104
Validation loss: 1.7518816904355121

Epoch: 6| Step: 13
Training loss: 0.6891326308250427
Validation loss: 1.742390214755971

Epoch: 518| Step: 0
Training loss: 1.2582963705062866
Validation loss: 1.82687847845016

Epoch: 6| Step: 1
Training loss: 1.177908182144165
Validation loss: 1.834121823310852

Epoch: 6| Step: 2
Training loss: 0.8421668410301208
Validation loss: 1.7689731723518782

Epoch: 6| Step: 3
Training loss: 1.0506207942962646
Validation loss: 1.7660739601299327

Epoch: 6| Step: 4
Training loss: 1.4821044206619263
Validation loss: 1.7847200670549948

Epoch: 6| Step: 5
Training loss: 1.1220084428787231
Validation loss: 1.7773601432000437

Epoch: 6| Step: 6
Training loss: 0.8980496525764465
Validation loss: 1.7815720471002723

Epoch: 6| Step: 7
Training loss: 0.7886477112770081
Validation loss: 1.7315486913086267

Epoch: 6| Step: 8
Training loss: 1.172979712486267
Validation loss: 1.8569504958327099

Epoch: 6| Step: 9
Training loss: 1.579152226448059
Validation loss: 1.8171041985993743

Epoch: 6| Step: 10
Training loss: 1.060225248336792
Validation loss: 1.7968208700098016

Epoch: 6| Step: 11
Training loss: 0.9559222459793091
Validation loss: 1.871821798304076

Epoch: 6| Step: 12
Training loss: 1.259889841079712
Validation loss: 1.8492731343033493

Epoch: 6| Step: 13
Training loss: 0.5344642996788025
Validation loss: 1.8016003254921205

Epoch: 519| Step: 0
Training loss: 1.4637951850891113
Validation loss: 1.8278417766735118

Epoch: 6| Step: 1
Training loss: 0.9950746297836304
Validation loss: 1.7774662369041032

Epoch: 6| Step: 2
Training loss: 0.8954954147338867
Validation loss: 1.8284030704088108

Epoch: 6| Step: 3
Training loss: 0.9984384775161743
Validation loss: 1.7939318918412732

Epoch: 6| Step: 4
Training loss: 0.5556075572967529
Validation loss: 1.8105060900411298

Epoch: 6| Step: 5
Training loss: 1.4484338760375977
Validation loss: 1.8057460323456795

Epoch: 6| Step: 6
Training loss: 1.1431829929351807
Validation loss: 1.837310939706782

Epoch: 6| Step: 7
Training loss: 1.205335259437561
Validation loss: 1.7701682172795778

Epoch: 6| Step: 8
Training loss: 1.1361815929412842
Validation loss: 1.7678108343514063

Epoch: 6| Step: 9
Training loss: 1.4323583841323853
Validation loss: 1.8024059341799827

Epoch: 6| Step: 10
Training loss: 0.5997728109359741
Validation loss: 1.8362504359214538

Epoch: 6| Step: 11
Training loss: 1.6240171194076538
Validation loss: 1.7958291307572396

Epoch: 6| Step: 12
Training loss: 1.1262657642364502
Validation loss: 1.7814629488093878

Epoch: 6| Step: 13
Training loss: 0.6990125179290771
Validation loss: 1.7055784668973697

Epoch: 520| Step: 0
Training loss: 0.7152776718139648
Validation loss: 1.8458538875784924

Epoch: 6| Step: 1
Training loss: 1.227733850479126
Validation loss: 1.777138429303323

Epoch: 6| Step: 2
Training loss: 1.578385591506958
Validation loss: 1.739271709995885

Epoch: 6| Step: 3
Training loss: 0.8768446445465088
Validation loss: 1.7953133506159629

Epoch: 6| Step: 4
Training loss: 1.147594690322876
Validation loss: 1.7720460199540662

Epoch: 6| Step: 5
Training loss: 1.0808507204055786
Validation loss: 1.873746455356639

Epoch: 6| Step: 6
Training loss: 1.0381667613983154
Validation loss: 1.8076482165244319

Epoch: 6| Step: 7
Training loss: 1.1874866485595703
Validation loss: 1.7914913572290891

Epoch: 6| Step: 8
Training loss: 0.7963241338729858
Validation loss: 1.8093206215930242

Epoch: 6| Step: 9
Training loss: 1.0636029243469238
Validation loss: 1.7842224708167456

Epoch: 6| Step: 10
Training loss: 1.0613960027694702
Validation loss: 1.7572518907567507

Epoch: 6| Step: 11
Training loss: 1.6193517446517944
Validation loss: 1.7732667461518319

Epoch: 6| Step: 12
Training loss: 0.8505652546882629
Validation loss: 1.8194630530572706

Epoch: 6| Step: 13
Training loss: 1.9078466892242432
Validation loss: 1.8200757477873115

Epoch: 521| Step: 0
Training loss: 1.2987315654754639
Validation loss: 1.7462544979587677

Epoch: 6| Step: 1
Training loss: 1.058672547340393
Validation loss: 1.7975370614759383

Epoch: 6| Step: 2
Training loss: 1.094861388206482
Validation loss: 1.7366193340670677

Epoch: 6| Step: 3
Training loss: 0.8430846929550171
Validation loss: 1.74661882205676

Epoch: 6| Step: 4
Training loss: 0.7896816730499268
Validation loss: 1.783632013105577

Epoch: 6| Step: 5
Training loss: 0.7900374531745911
Validation loss: 1.8536021991442608

Epoch: 6| Step: 6
Training loss: 1.222252368927002
Validation loss: 1.7454532500236266

Epoch: 6| Step: 7
Training loss: 1.3363616466522217
Validation loss: 1.75571991807671

Epoch: 6| Step: 8
Training loss: 1.088062047958374
Validation loss: 1.744036538626558

Epoch: 6| Step: 9
Training loss: 1.1605944633483887
Validation loss: 1.7580754628745459

Epoch: 6| Step: 10
Training loss: 1.4929232597351074
Validation loss: 1.7575985436798425

Epoch: 6| Step: 11
Training loss: 0.9315201044082642
Validation loss: 1.8072446725701774

Epoch: 6| Step: 12
Training loss: 1.1575477123260498
Validation loss: 1.7482741314877746

Epoch: 6| Step: 13
Training loss: 0.670041024684906
Validation loss: 1.7755530367615402

Epoch: 522| Step: 0
Training loss: 1.3825492858886719
Validation loss: 1.7527988354365032

Epoch: 6| Step: 1
Training loss: 1.605502963066101
Validation loss: 1.7531931938663605

Epoch: 6| Step: 2
Training loss: 0.9397323727607727
Validation loss: 1.8224171412888395

Epoch: 6| Step: 3
Training loss: 0.7978293895721436
Validation loss: 1.7315546094730336

Epoch: 6| Step: 4
Training loss: 0.8188948035240173
Validation loss: 1.7747201355554725

Epoch: 6| Step: 5
Training loss: 0.7632132768630981
Validation loss: 1.7986943747407647

Epoch: 6| Step: 6
Training loss: 1.235978126525879
Validation loss: 1.7258164293022566

Epoch: 6| Step: 7
Training loss: 1.0934255123138428
Validation loss: 1.7665682120989727

Epoch: 6| Step: 8
Training loss: 0.7895587682723999
Validation loss: 1.766467208503395

Epoch: 6| Step: 9
Training loss: 1.1916186809539795
Validation loss: 1.789410606507332

Epoch: 6| Step: 10
Training loss: 1.2455778121948242
Validation loss: 1.7313893866795365

Epoch: 6| Step: 11
Training loss: 1.0498112440109253
Validation loss: 1.7396588440864318

Epoch: 6| Step: 12
Training loss: 0.9252536296844482
Validation loss: 1.724062829889277

Epoch: 6| Step: 13
Training loss: 1.4349942207336426
Validation loss: 1.7551455587469122

Epoch: 523| Step: 0
Training loss: 0.7954760789871216
Validation loss: 1.7640135852239465

Epoch: 6| Step: 1
Training loss: 1.0583972930908203
Validation loss: 1.7745084006299254

Epoch: 6| Step: 2
Training loss: 0.6923421025276184
Validation loss: 1.7637503839308215

Epoch: 6| Step: 3
Training loss: 2.005011558532715
Validation loss: 1.7088817281107749

Epoch: 6| Step: 4
Training loss: 1.1505086421966553
Validation loss: 1.7489531463192356

Epoch: 6| Step: 5
Training loss: 0.9627737402915955
Validation loss: 1.7174500521793161

Epoch: 6| Step: 6
Training loss: 1.3418374061584473
Validation loss: 1.782642646502423

Epoch: 6| Step: 7
Training loss: 1.328229308128357
Validation loss: 1.7415084838867188

Epoch: 6| Step: 8
Training loss: 0.6419892311096191
Validation loss: 1.701274441134545

Epoch: 6| Step: 9
Training loss: 0.9762314558029175
Validation loss: 1.7687741979475944

Epoch: 6| Step: 10
Training loss: 0.8916847109794617
Validation loss: 1.7292008297417754

Epoch: 6| Step: 11
Training loss: 1.1943870782852173
Validation loss: 1.8519482727973693

Epoch: 6| Step: 12
Training loss: 0.8833794593811035
Validation loss: 1.7740802841801797

Epoch: 6| Step: 13
Training loss: 1.2527351379394531
Validation loss: 1.7682944138844807

Epoch: 524| Step: 0
Training loss: 2.048403739929199
Validation loss: 1.8147104068468976

Epoch: 6| Step: 1
Training loss: 1.435995101928711
Validation loss: 1.8330701128129037

Epoch: 6| Step: 2
Training loss: 1.0834444761276245
Validation loss: 1.8975679669328915

Epoch: 6| Step: 3
Training loss: 0.8748976588249207
Validation loss: 1.8352225442086496

Epoch: 6| Step: 4
Training loss: 1.1120901107788086
Validation loss: 1.7912281072267922

Epoch: 6| Step: 5
Training loss: 1.133933663368225
Validation loss: 1.8592698984248663

Epoch: 6| Step: 6
Training loss: 1.3769497871398926
Validation loss: 1.8631451860550912

Epoch: 6| Step: 7
Training loss: 0.8430184721946716
Validation loss: 1.7954610804075837

Epoch: 6| Step: 8
Training loss: 1.1197313070297241
Validation loss: 1.8627765037680184

Epoch: 6| Step: 9
Training loss: 1.0242531299591064
Validation loss: 1.833439947456442

Epoch: 6| Step: 10
Training loss: 0.9732270240783691
Validation loss: 1.773635677112046

Epoch: 6| Step: 11
Training loss: 1.3140184879302979
Validation loss: 1.8114736310897335

Epoch: 6| Step: 12
Training loss: 0.9820836782455444
Validation loss: 1.7745495829530942

Epoch: 6| Step: 13
Training loss: 0.6787830591201782
Validation loss: 1.7537941548132128

Epoch: 525| Step: 0
Training loss: 1.1881685256958008
Validation loss: 1.7104689844192997

Epoch: 6| Step: 1
Training loss: 1.6080279350280762
Validation loss: 1.7330069939295452

Epoch: 6| Step: 2
Training loss: 0.481781005859375
Validation loss: 1.796285185762631

Epoch: 6| Step: 3
Training loss: 0.6802740097045898
Validation loss: 1.7626545595866379

Epoch: 6| Step: 4
Training loss: 1.1143840551376343
Validation loss: 1.76362697539791

Epoch: 6| Step: 5
Training loss: 1.4097102880477905
Validation loss: 1.774317652948441

Epoch: 6| Step: 6
Training loss: 1.5791326761245728
Validation loss: 1.7425295358063073

Epoch: 6| Step: 7
Training loss: 0.9421308040618896
Validation loss: 1.756660379389281

Epoch: 6| Step: 8
Training loss: 0.8746531009674072
Validation loss: 1.6777936258623678

Epoch: 6| Step: 9
Training loss: 0.911790132522583
Validation loss: 1.7667770578015236

Epoch: 6| Step: 10
Training loss: 0.9937463998794556
Validation loss: 1.7652436994737195

Epoch: 6| Step: 11
Training loss: 0.6477341651916504
Validation loss: 1.7875979177413448

Epoch: 6| Step: 12
Training loss: 1.9259724617004395
Validation loss: 1.7689756219105055

Epoch: 6| Step: 13
Training loss: 0.6532396674156189
Validation loss: 1.8014261440564228

Epoch: 526| Step: 0
Training loss: 1.0706771612167358
Validation loss: 1.7974904032163723

Epoch: 6| Step: 1
Training loss: 1.0421682596206665
Validation loss: 1.7637465589789934

Epoch: 6| Step: 2
Training loss: 1.1544013023376465
Validation loss: 1.7748962371580062

Epoch: 6| Step: 3
Training loss: 1.2100725173950195
Validation loss: 1.837323655364334

Epoch: 6| Step: 4
Training loss: 0.6170459985733032
Validation loss: 1.7374440662322506

Epoch: 6| Step: 5
Training loss: 1.0274863243103027
Validation loss: 1.7340138894255444

Epoch: 6| Step: 6
Training loss: 1.0214588642120361
Validation loss: 1.7941598135937926

Epoch: 6| Step: 7
Training loss: 0.929774284362793
Validation loss: 1.7823886614973827

Epoch: 6| Step: 8
Training loss: 1.0964279174804688
Validation loss: 1.817031979560852

Epoch: 6| Step: 9
Training loss: 0.8102070689201355
Validation loss: 1.8936660571764874

Epoch: 6| Step: 10
Training loss: 2.2276127338409424
Validation loss: 1.8389189935499621

Epoch: 6| Step: 11
Training loss: 0.47326093912124634
Validation loss: 1.8125615927480883

Epoch: 6| Step: 12
Training loss: 1.101033329963684
Validation loss: 1.7924926896249094

Epoch: 6| Step: 13
Training loss: 1.3630571365356445
Validation loss: 1.7459265288486276

Epoch: 527| Step: 0
Training loss: 1.217069149017334
Validation loss: 1.7435217467687463

Epoch: 6| Step: 1
Training loss: 0.9965152740478516
Validation loss: 1.7371089022646669

Epoch: 6| Step: 2
Training loss: 1.378523588180542
Validation loss: 1.7723957223276938

Epoch: 6| Step: 3
Training loss: 0.6006159782409668
Validation loss: 1.744873539094002

Epoch: 6| Step: 4
Training loss: 0.616095244884491
Validation loss: 1.7544943363435808

Epoch: 6| Step: 5
Training loss: 0.9352547526359558
Validation loss: 1.7817627294089204

Epoch: 6| Step: 6
Training loss: 1.6296448707580566
Validation loss: 1.734738681906013

Epoch: 6| Step: 7
Training loss: 0.6663575172424316
Validation loss: 1.791685978571574

Epoch: 6| Step: 8
Training loss: 0.9257913827896118
Validation loss: 1.777356909167382

Epoch: 6| Step: 9
Training loss: 1.453782558441162
Validation loss: 1.787432252719838

Epoch: 6| Step: 10
Training loss: 0.8729076385498047
Validation loss: 1.720147277719231

Epoch: 6| Step: 11
Training loss: 1.7642185688018799
Validation loss: 1.7707440314754364

Epoch: 6| Step: 12
Training loss: 0.7971045970916748
Validation loss: 1.719070356379273

Epoch: 6| Step: 13
Training loss: 1.2268433570861816
Validation loss: 1.7791296384667838

Epoch: 528| Step: 0
Training loss: 1.6667424440383911
Validation loss: 1.7407433781572568

Epoch: 6| Step: 1
Training loss: 0.4773462414741516
Validation loss: 1.7714762995319981

Epoch: 6| Step: 2
Training loss: 1.1024287939071655
Validation loss: 1.7786765701027327

Epoch: 6| Step: 3
Training loss: 1.1207232475280762
Validation loss: 1.7906493961170156

Epoch: 6| Step: 4
Training loss: 1.1480443477630615
Validation loss: 1.835324679651568

Epoch: 6| Step: 5
Training loss: 0.9490218162536621
Validation loss: 1.75611594030934

Epoch: 6| Step: 6
Training loss: 1.3947182893753052
Validation loss: 1.7765502763050858

Epoch: 6| Step: 7
Training loss: 0.9628424048423767
Validation loss: 1.7845614725543606

Epoch: 6| Step: 8
Training loss: 1.468808650970459
Validation loss: 1.7836415357487176

Epoch: 6| Step: 9
Training loss: 0.7174336910247803
Validation loss: 1.765786906724335

Epoch: 6| Step: 10
Training loss: 1.0569610595703125
Validation loss: 1.8244734938426683

Epoch: 6| Step: 11
Training loss: 0.9619439840316772
Validation loss: 1.7693477484487719

Epoch: 6| Step: 12
Training loss: 1.0266475677490234
Validation loss: 1.7138330808249853

Epoch: 6| Step: 13
Training loss: 1.0786648988723755
Validation loss: 1.8123805125554402

Epoch: 529| Step: 0
Training loss: 1.4120986461639404
Validation loss: 1.7840131867316462

Epoch: 6| Step: 1
Training loss: 1.557942271232605
Validation loss: 1.814596418411501

Epoch: 6| Step: 2
Training loss: 1.3201569318771362
Validation loss: 1.7594892824849775

Epoch: 6| Step: 3
Training loss: 0.7679730653762817
Validation loss: 1.7962636857904413

Epoch: 6| Step: 4
Training loss: 0.8786469101905823
Validation loss: 1.7644438653863885

Epoch: 6| Step: 5
Training loss: 0.8442580103874207
Validation loss: 1.7636018709469867

Epoch: 6| Step: 6
Training loss: 0.7968312501907349
Validation loss: 1.7886002397024503

Epoch: 6| Step: 7
Training loss: 0.6485593318939209
Validation loss: 1.805494628926759

Epoch: 6| Step: 8
Training loss: 1.5209672451019287
Validation loss: 1.7996771181783369

Epoch: 6| Step: 9
Training loss: 1.0803289413452148
Validation loss: 1.7097839655414704

Epoch: 6| Step: 10
Training loss: 1.2196123600006104
Validation loss: 1.7665647152931458

Epoch: 6| Step: 11
Training loss: 1.2114920616149902
Validation loss: 1.7966992419253114

Epoch: 6| Step: 12
Training loss: 1.2921717166900635
Validation loss: 1.7829696234836374

Epoch: 6| Step: 13
Training loss: 1.2217249870300293
Validation loss: 1.7082495740664903

Epoch: 530| Step: 0
Training loss: 1.9709018468856812
Validation loss: 1.800885518391927

Epoch: 6| Step: 1
Training loss: 1.1942951679229736
Validation loss: 1.7975907556472286

Epoch: 6| Step: 2
Training loss: 0.7299491763114929
Validation loss: 1.7373994037669191

Epoch: 6| Step: 3
Training loss: 1.0200402736663818
Validation loss: 1.7603400958481656

Epoch: 6| Step: 4
Training loss: 1.0729010105133057
Validation loss: 1.7394191795779812

Epoch: 6| Step: 5
Training loss: 0.8817099928855896
Validation loss: 1.8236988423973002

Epoch: 6| Step: 6
Training loss: 1.2337706089019775
Validation loss: 1.7495451755421136

Epoch: 6| Step: 7
Training loss: 0.9570356011390686
Validation loss: 1.7328865963925597

Epoch: 6| Step: 8
Training loss: 1.0444834232330322
Validation loss: 1.7122707379761564

Epoch: 6| Step: 9
Training loss: 1.3132222890853882
Validation loss: 1.7710170694576797

Epoch: 6| Step: 10
Training loss: 0.969045877456665
Validation loss: 1.7704922281285769

Epoch: 6| Step: 11
Training loss: 0.6872736215591431
Validation loss: 1.7528265240371868

Epoch: 6| Step: 12
Training loss: 0.8249865770339966
Validation loss: 1.8051237803633495

Epoch: 6| Step: 13
Training loss: 1.24269437789917
Validation loss: 1.77118137703147

Epoch: 531| Step: 0
Training loss: 0.9346234798431396
Validation loss: 1.7391740301603913

Epoch: 6| Step: 1
Training loss: 1.3564937114715576
Validation loss: 1.8254840463720343

Epoch: 6| Step: 2
Training loss: 0.9522493481636047
Validation loss: 1.788534036246679

Epoch: 6| Step: 3
Training loss: 0.6797859072685242
Validation loss: 1.8358138197211809

Epoch: 6| Step: 4
Training loss: 1.2235028743743896
Validation loss: 1.7558631973881875

Epoch: 6| Step: 5
Training loss: 1.3886505365371704
Validation loss: 1.787229513609281

Epoch: 6| Step: 6
Training loss: 0.9843923449516296
Validation loss: 1.812637959757159

Epoch: 6| Step: 7
Training loss: 0.7190241813659668
Validation loss: 1.8210630288688086

Epoch: 6| Step: 8
Training loss: 1.0935907363891602
Validation loss: 1.7287846214027816

Epoch: 6| Step: 9
Training loss: 0.7962168455123901
Validation loss: 1.7181586873146795

Epoch: 6| Step: 10
Training loss: 1.3358656167984009
Validation loss: 1.6937144020552277

Epoch: 6| Step: 11
Training loss: 1.332962989807129
Validation loss: 1.7895661028482581

Epoch: 6| Step: 12
Training loss: 1.0128614902496338
Validation loss: 1.7511288401901082

Epoch: 6| Step: 13
Training loss: 1.0118792057037354
Validation loss: 1.6743294090353034

Epoch: 532| Step: 0
Training loss: 0.808013916015625
Validation loss: 1.728504434708626

Epoch: 6| Step: 1
Training loss: 0.7936378121376038
Validation loss: 1.8317507646417106

Epoch: 6| Step: 2
Training loss: 1.0928711891174316
Validation loss: 1.7578871134788758

Epoch: 6| Step: 3
Training loss: 1.498958706855774
Validation loss: 1.7755177764482395

Epoch: 6| Step: 4
Training loss: 1.4054348468780518
Validation loss: 1.7824193111030004

Epoch: 6| Step: 5
Training loss: 0.8544971346855164
Validation loss: 1.7429608119431363

Epoch: 6| Step: 6
Training loss: 1.4415024518966675
Validation loss: 1.7388042096168763

Epoch: 6| Step: 7
Training loss: 0.8503478765487671
Validation loss: 1.7943105838632072

Epoch: 6| Step: 8
Training loss: 1.163625717163086
Validation loss: 1.8077715007207726

Epoch: 6| Step: 9
Training loss: 0.8223659992218018
Validation loss: 1.9045292215962564

Epoch: 6| Step: 10
Training loss: 1.0694811344146729
Validation loss: 1.8566385828038698

Epoch: 6| Step: 11
Training loss: 1.1256086826324463
Validation loss: 1.8397735485466578

Epoch: 6| Step: 12
Training loss: 1.4770361185073853
Validation loss: 1.8058595964985509

Epoch: 6| Step: 13
Training loss: 1.5796968936920166
Validation loss: 1.85278703576775

Epoch: 533| Step: 0
Training loss: 1.2524268627166748
Validation loss: 1.874300068424594

Epoch: 6| Step: 1
Training loss: 0.9090354442596436
Validation loss: 1.8253963262804094

Epoch: 6| Step: 2
Training loss: 1.0162887573242188
Validation loss: 1.7932499467685659

Epoch: 6| Step: 3
Training loss: 1.5269763469696045
Validation loss: 1.732733158655064

Epoch: 6| Step: 4
Training loss: 1.1874339580535889
Validation loss: 1.7189210666123258

Epoch: 6| Step: 5
Training loss: 0.6953065395355225
Validation loss: 1.745871268292909

Epoch: 6| Step: 6
Training loss: 1.1996005773544312
Validation loss: 1.772972031306195

Epoch: 6| Step: 7
Training loss: 1.1836856603622437
Validation loss: 1.7564350802411315

Epoch: 6| Step: 8
Training loss: 1.3732669353485107
Validation loss: 1.783187912356469

Epoch: 6| Step: 9
Training loss: 1.2014485597610474
Validation loss: 1.8084219988956247

Epoch: 6| Step: 10
Training loss: 0.8512383699417114
Validation loss: 1.7671599477849982

Epoch: 6| Step: 11
Training loss: 1.1707801818847656
Validation loss: 1.7353078716544694

Epoch: 6| Step: 12
Training loss: 0.9629431366920471
Validation loss: 1.7839820359342842

Epoch: 6| Step: 13
Training loss: 0.7190226316452026
Validation loss: 1.8083776197125834

Epoch: 534| Step: 0
Training loss: 0.7589103579521179
Validation loss: 1.8359746445891678

Epoch: 6| Step: 1
Training loss: 1.2312867641448975
Validation loss: 1.7941960506541754

Epoch: 6| Step: 2
Training loss: 1.392392873764038
Validation loss: 1.7840043062804847

Epoch: 6| Step: 3
Training loss: 1.2750036716461182
Validation loss: 1.7386356322996077

Epoch: 6| Step: 4
Training loss: 1.068395972251892
Validation loss: 1.7860374707047657

Epoch: 6| Step: 5
Training loss: 0.9389185309410095
Validation loss: 1.8055965836330126

Epoch: 6| Step: 6
Training loss: 1.3804841041564941
Validation loss: 1.7499902248382568

Epoch: 6| Step: 7
Training loss: 0.9468367099761963
Validation loss: 1.8343872549713298

Epoch: 6| Step: 8
Training loss: 0.975278913974762
Validation loss: 1.8308047351016794

Epoch: 6| Step: 9
Training loss: 0.9274822473526001
Validation loss: 1.7996871650859874

Epoch: 6| Step: 10
Training loss: 1.1034742593765259
Validation loss: 1.7987145762289725

Epoch: 6| Step: 11
Training loss: 0.89825040102005
Validation loss: 1.7635401859078357

Epoch: 6| Step: 12
Training loss: 1.2059330940246582
Validation loss: 1.785949214812248

Epoch: 6| Step: 13
Training loss: 0.8210143446922302
Validation loss: 1.8191434311610397

Epoch: 535| Step: 0
Training loss: 1.2584655284881592
Validation loss: 1.7908479436751334

Epoch: 6| Step: 1
Training loss: 0.8638347387313843
Validation loss: 1.8336124932894142

Epoch: 6| Step: 2
Training loss: 1.284360647201538
Validation loss: 1.797827568105472

Epoch: 6| Step: 3
Training loss: 1.4832465648651123
Validation loss: 1.7453343393982097

Epoch: 6| Step: 4
Training loss: 0.6071659326553345
Validation loss: 1.7968810168645715

Epoch: 6| Step: 5
Training loss: 0.9233313202857971
Validation loss: 1.800724628151104

Epoch: 6| Step: 6
Training loss: 0.9637780785560608
Validation loss: 1.804034916303491

Epoch: 6| Step: 7
Training loss: 1.7515289783477783
Validation loss: 1.7266265653794812

Epoch: 6| Step: 8
Training loss: 1.2142717838287354
Validation loss: 1.8153402497691493

Epoch: 6| Step: 9
Training loss: 1.4421639442443848
Validation loss: 1.7304239708890197

Epoch: 6| Step: 10
Training loss: 0.8587294816970825
Validation loss: 1.7668375430568573

Epoch: 6| Step: 11
Training loss: 1.0198220014572144
Validation loss: 1.7750699930293585

Epoch: 6| Step: 12
Training loss: 0.8875700235366821
Validation loss: 1.789853306226833

Epoch: 6| Step: 13
Training loss: 0.4790485203266144
Validation loss: 1.7506615833569599

Epoch: 536| Step: 0
Training loss: 0.8180311322212219
Validation loss: 1.7561582788344352

Epoch: 6| Step: 1
Training loss: 1.06782066822052
Validation loss: 1.7817607823238577

Epoch: 6| Step: 2
Training loss: 0.9869555234909058
Validation loss: 1.7766810335138792

Epoch: 6| Step: 3
Training loss: 1.4938138723373413
Validation loss: 1.8216812559353408

Epoch: 6| Step: 4
Training loss: 0.6834412813186646
Validation loss: 1.814290121037473

Epoch: 6| Step: 5
Training loss: 1.094412088394165
Validation loss: 1.7849562245030557

Epoch: 6| Step: 6
Training loss: 1.3411922454833984
Validation loss: 1.783875089178803

Epoch: 6| Step: 7
Training loss: 1.2844617366790771
Validation loss: 1.768701946863564

Epoch: 6| Step: 8
Training loss: 1.1296908855438232
Validation loss: 1.7658226861748645

Epoch: 6| Step: 9
Training loss: 0.8519209623336792
Validation loss: 1.7713610677308933

Epoch: 6| Step: 10
Training loss: 0.813687801361084
Validation loss: 1.7778953672737203

Epoch: 6| Step: 11
Training loss: 0.6477199792861938
Validation loss: 1.7835147867920578

Epoch: 6| Step: 12
Training loss: 0.9396061897277832
Validation loss: 1.7547326113588066

Epoch: 6| Step: 13
Training loss: 1.8001817464828491
Validation loss: 1.726256012916565

Epoch: 537| Step: 0
Training loss: 0.9210714101791382
Validation loss: 1.7466998843736545

Epoch: 6| Step: 1
Training loss: 0.5051436424255371
Validation loss: 1.8222792212681105

Epoch: 6| Step: 2
Training loss: 1.0509527921676636
Validation loss: 1.784402875490086

Epoch: 6| Step: 3
Training loss: 1.5109915733337402
Validation loss: 1.7550562145889446

Epoch: 6| Step: 4
Training loss: 1.1786136627197266
Validation loss: 1.8003034425038162

Epoch: 6| Step: 5
Training loss: 1.6700520515441895
Validation loss: 1.7462694145018054

Epoch: 6| Step: 6
Training loss: 0.713039219379425
Validation loss: 1.7927086737848097

Epoch: 6| Step: 7
Training loss: 1.0914868116378784
Validation loss: 1.8361260442323581

Epoch: 6| Step: 8
Training loss: 1.0322552919387817
Validation loss: 1.7810436410288657

Epoch: 6| Step: 9
Training loss: 1.2296435832977295
Validation loss: 1.7722879520026587

Epoch: 6| Step: 10
Training loss: 0.9478365778923035
Validation loss: 1.766747364433863

Epoch: 6| Step: 11
Training loss: 0.8007619380950928
Validation loss: 1.7934456897038284

Epoch: 6| Step: 12
Training loss: 1.1886072158813477
Validation loss: 1.7550904238095848

Epoch: 6| Step: 13
Training loss: 1.4762628078460693
Validation loss: 1.8179738803576397

Epoch: 538| Step: 0
Training loss: 1.2272509336471558
Validation loss: 1.7366151809692383

Epoch: 6| Step: 1
Training loss: 1.4590235948562622
Validation loss: 1.7497213386720227

Epoch: 6| Step: 2
Training loss: 1.3265173435211182
Validation loss: 1.709368243012377

Epoch: 6| Step: 3
Training loss: 1.4633593559265137
Validation loss: 1.7770880217193274

Epoch: 6| Step: 4
Training loss: 0.576363205909729
Validation loss: 1.7523589852035686

Epoch: 6| Step: 5
Training loss: 1.0619416236877441
Validation loss: 1.729821680694498

Epoch: 6| Step: 6
Training loss: 0.8320596814155579
Validation loss: 1.7191290829771309

Epoch: 6| Step: 7
Training loss: 1.0665282011032104
Validation loss: 1.6974649544685119

Epoch: 6| Step: 8
Training loss: 0.9184674620628357
Validation loss: 1.7782997380020797

Epoch: 6| Step: 9
Training loss: 1.0879383087158203
Validation loss: 1.7854407256649387

Epoch: 6| Step: 10
Training loss: 0.9458495378494263
Validation loss: 1.7790433245320474

Epoch: 6| Step: 11
Training loss: 1.1369540691375732
Validation loss: 1.7407613774781585

Epoch: 6| Step: 12
Training loss: 0.9716838598251343
Validation loss: 1.8026193739265524

Epoch: 6| Step: 13
Training loss: 1.2606773376464844
Validation loss: 1.753190912226195

Epoch: 539| Step: 0
Training loss: 1.1284466981887817
Validation loss: 1.8400987027793803

Epoch: 6| Step: 1
Training loss: 0.9298430681228638
Validation loss: 1.6990304967408538

Epoch: 6| Step: 2
Training loss: 1.486189842224121
Validation loss: 1.7814459185446463

Epoch: 6| Step: 3
Training loss: 0.8569449186325073
Validation loss: 1.8781451409862888

Epoch: 6| Step: 4
Training loss: 1.3310723304748535
Validation loss: 1.7580486702662643

Epoch: 6| Step: 5
Training loss: 2.2728805541992188
Validation loss: 1.746364455069265

Epoch: 6| Step: 6
Training loss: 0.6213173866271973
Validation loss: 1.7463089958313973

Epoch: 6| Step: 7
Training loss: 0.8645455837249756
Validation loss: 1.8308627643892843

Epoch: 6| Step: 8
Training loss: 0.49907588958740234
Validation loss: 1.7377742567370016

Epoch: 6| Step: 9
Training loss: 1.0340557098388672
Validation loss: 1.7550545251497658

Epoch: 6| Step: 10
Training loss: 1.1908628940582275
Validation loss: 1.792989819280563

Epoch: 6| Step: 11
Training loss: 1.486584186553955
Validation loss: 1.747599760691325

Epoch: 6| Step: 12
Training loss: 0.8550843000411987
Validation loss: 1.7774433487205095

Epoch: 6| Step: 13
Training loss: 1.0013086795806885
Validation loss: 1.7462264671120593

Epoch: 540| Step: 0
Training loss: 1.1020715236663818
Validation loss: 1.7525915868820683

Epoch: 6| Step: 1
Training loss: 1.3655720949172974
Validation loss: 1.739018577401356

Epoch: 6| Step: 2
Training loss: 0.7790660858154297
Validation loss: 1.804209477158003

Epoch: 6| Step: 3
Training loss: 0.8819133043289185
Validation loss: 1.7806966689325148

Epoch: 6| Step: 4
Training loss: 1.0548142194747925
Validation loss: 1.8031496694011073

Epoch: 6| Step: 5
Training loss: 1.2720869779586792
Validation loss: 1.7276097497632426

Epoch: 6| Step: 6
Training loss: 0.6254796385765076
Validation loss: 1.7837324386001916

Epoch: 6| Step: 7
Training loss: 1.4159560203552246
Validation loss: 1.7945763718697332

Epoch: 6| Step: 8
Training loss: 1.4523200988769531
Validation loss: 1.8284550918045865

Epoch: 6| Step: 9
Training loss: 1.208099603652954
Validation loss: 1.796731601479233

Epoch: 6| Step: 10
Training loss: 1.1887001991271973
Validation loss: 1.8680298302763252

Epoch: 6| Step: 11
Training loss: 1.0081959962844849
Validation loss: 1.8552311184585735

Epoch: 6| Step: 12
Training loss: 0.8154376745223999
Validation loss: 1.8160181365987307

Epoch: 6| Step: 13
Training loss: 0.7943383455276489
Validation loss: 1.831640285830344

Epoch: 541| Step: 0
Training loss: 0.9510236978530884
Validation loss: 1.7579371852259482

Epoch: 6| Step: 1
Training loss: 0.9244376420974731
Validation loss: 1.7849617632486487

Epoch: 6| Step: 2
Training loss: 1.07602858543396
Validation loss: 1.8522361004224388

Epoch: 6| Step: 3
Training loss: 0.9056106805801392
Validation loss: 1.7926408475445164

Epoch: 6| Step: 4
Training loss: 1.0434355735778809
Validation loss: 1.7441896879544823

Epoch: 6| Step: 5
Training loss: 1.5434787273406982
Validation loss: 1.7533410928582633

Epoch: 6| Step: 6
Training loss: 0.41325223445892334
Validation loss: 1.7315445330835157

Epoch: 6| Step: 7
Training loss: 0.7242486476898193
Validation loss: 1.7807698083180252

Epoch: 6| Step: 8
Training loss: 1.7761080265045166
Validation loss: 1.8115760485331218

Epoch: 6| Step: 9
Training loss: 1.4994890689849854
Validation loss: 1.8032945484243414

Epoch: 6| Step: 10
Training loss: 0.867496907711029
Validation loss: 1.7684915001674364

Epoch: 6| Step: 11
Training loss: 1.6603213548660278
Validation loss: 1.7650502189513175

Epoch: 6| Step: 12
Training loss: 0.8867416977882385
Validation loss: 1.8544390355387042

Epoch: 6| Step: 13
Training loss: 0.26630353927612305
Validation loss: 1.801236039848738

Epoch: 542| Step: 0
Training loss: 1.4683009386062622
Validation loss: 1.7860120701533493

Epoch: 6| Step: 1
Training loss: 0.6032242774963379
Validation loss: 1.7731532871082265

Epoch: 6| Step: 2
Training loss: 1.1966497898101807
Validation loss: 1.7244461467189174

Epoch: 6| Step: 3
Training loss: 0.9484317302703857
Validation loss: 1.7537701078640517

Epoch: 6| Step: 4
Training loss: 1.0454118251800537
Validation loss: 1.7843226771200857

Epoch: 6| Step: 5
Training loss: 1.8690650463104248
Validation loss: 1.806472501447124

Epoch: 6| Step: 6
Training loss: 0.6024344563484192
Validation loss: 1.7388205541077482

Epoch: 6| Step: 7
Training loss: 1.2277283668518066
Validation loss: 1.7538136179729173

Epoch: 6| Step: 8
Training loss: 1.0605591535568237
Validation loss: 1.7968841457879672

Epoch: 6| Step: 9
Training loss: 0.7362464666366577
Validation loss: 1.7685578817962317

Epoch: 6| Step: 10
Training loss: 1.2405955791473389
Validation loss: 1.750217996617799

Epoch: 6| Step: 11
Training loss: 1.0197540521621704
Validation loss: 1.7437986943029589

Epoch: 6| Step: 12
Training loss: 0.836930513381958
Validation loss: 1.6879791957075878

Epoch: 6| Step: 13
Training loss: 0.4653509855270386
Validation loss: 1.7450237658716017

Epoch: 543| Step: 0
Training loss: 1.1300957202911377
Validation loss: 1.8017714049226494

Epoch: 6| Step: 1
Training loss: 1.039748191833496
Validation loss: 1.8428911047597085

Epoch: 6| Step: 2
Training loss: 1.281936526298523
Validation loss: 1.7441782797536542

Epoch: 6| Step: 3
Training loss: 1.213518738746643
Validation loss: 1.7633305031766173

Epoch: 6| Step: 4
Training loss: 0.7070399522781372
Validation loss: 1.8411194509075535

Epoch: 6| Step: 5
Training loss: 1.3169432878494263
Validation loss: 1.79726545528699

Epoch: 6| Step: 6
Training loss: 1.5812187194824219
Validation loss: 1.8176003066442346

Epoch: 6| Step: 7
Training loss: 0.9331849813461304
Validation loss: 1.7795748185085993

Epoch: 6| Step: 8
Training loss: 0.8114258050918579
Validation loss: 1.773514191309611

Epoch: 6| Step: 9
Training loss: 1.0223016738891602
Validation loss: 1.771273301493737

Epoch: 6| Step: 10
Training loss: 0.585746169090271
Validation loss: 1.7905283653607933

Epoch: 6| Step: 11
Training loss: 1.4932849407196045
Validation loss: 1.8095060292110647

Epoch: 6| Step: 12
Training loss: 1.0532574653625488
Validation loss: 1.8227199790298299

Epoch: 6| Step: 13
Training loss: 0.7929590344429016
Validation loss: 1.7694865875346686

Epoch: 544| Step: 0
Training loss: 1.1906851530075073
Validation loss: 1.777425709591117

Epoch: 6| Step: 1
Training loss: 0.7722469568252563
Validation loss: 1.7656180525338778

Epoch: 6| Step: 2
Training loss: 0.8340328335762024
Validation loss: 1.7614032927379812

Epoch: 6| Step: 3
Training loss: 1.4091161489486694
Validation loss: 1.7157273664269397

Epoch: 6| Step: 4
Training loss: 1.4851164817810059
Validation loss: 1.7593271219602196

Epoch: 6| Step: 5
Training loss: 1.158995509147644
Validation loss: 1.7771488825480144

Epoch: 6| Step: 6
Training loss: 0.8764408230781555
Validation loss: 1.7308567595738236

Epoch: 6| Step: 7
Training loss: 1.3930413722991943
Validation loss: 1.7160240950122956

Epoch: 6| Step: 8
Training loss: 1.0330195426940918
Validation loss: 1.7380349155395263

Epoch: 6| Step: 9
Training loss: 1.0532265901565552
Validation loss: 1.7968117934401318

Epoch: 6| Step: 10
Training loss: 1.006671667098999
Validation loss: 1.8963064019398024

Epoch: 6| Step: 11
Training loss: 0.7618900537490845
Validation loss: 1.7613082265341153

Epoch: 6| Step: 12
Training loss: 1.0561754703521729
Validation loss: 1.824029613566655

Epoch: 6| Step: 13
Training loss: 1.299582839012146
Validation loss: 1.7767560840934835

Epoch: 545| Step: 0
Training loss: 1.37579345703125
Validation loss: 1.6828018132076468

Epoch: 6| Step: 1
Training loss: 0.8081694841384888
Validation loss: 1.8009927977797806

Epoch: 6| Step: 2
Training loss: 0.8061345219612122
Validation loss: 1.8234632399774366

Epoch: 6| Step: 3
Training loss: 1.4100595712661743
Validation loss: 1.7055805960009176

Epoch: 6| Step: 4
Training loss: 1.112398624420166
Validation loss: 1.7333175764288953

Epoch: 6| Step: 5
Training loss: 0.9565691947937012
Validation loss: 1.7914678127534929

Epoch: 6| Step: 6
Training loss: 1.351592779159546
Validation loss: 1.787759521956085

Epoch: 6| Step: 7
Training loss: 1.3877973556518555
Validation loss: 1.8098774751027424

Epoch: 6| Step: 8
Training loss: 1.1979336738586426
Validation loss: 1.7483056258129817

Epoch: 6| Step: 9
Training loss: 1.0129997730255127
Validation loss: 1.7367649296278596

Epoch: 6| Step: 10
Training loss: 1.1979397535324097
Validation loss: 1.8283331663377824

Epoch: 6| Step: 11
Training loss: 0.8163684606552124
Validation loss: 1.801449482158948

Epoch: 6| Step: 12
Training loss: 1.2755329608917236
Validation loss: 1.7437168385392876

Epoch: 6| Step: 13
Training loss: 0.36478662490844727
Validation loss: 1.7970787991759598

Epoch: 546| Step: 0
Training loss: 1.0338752269744873
Validation loss: 1.7961489526174401

Epoch: 6| Step: 1
Training loss: 0.9572504758834839
Validation loss: 1.8499818437842912

Epoch: 6| Step: 2
Training loss: 0.7751220464706421
Validation loss: 1.8346829234912831

Epoch: 6| Step: 3
Training loss: 0.7535547018051147
Validation loss: 1.7629619093351467

Epoch: 6| Step: 4
Training loss: 0.8794903755187988
Validation loss: 1.7924017303733415

Epoch: 6| Step: 5
Training loss: 1.247166395187378
Validation loss: 1.7177015555802213

Epoch: 6| Step: 6
Training loss: 1.1510791778564453
Validation loss: 1.7969176423165105

Epoch: 6| Step: 7
Training loss: 0.5228185057640076
Validation loss: 1.812408616465907

Epoch: 6| Step: 8
Training loss: 1.3352768421173096
Validation loss: 1.7779786381670224

Epoch: 6| Step: 9
Training loss: 1.353447437286377
Validation loss: 1.7711222312783683

Epoch: 6| Step: 10
Training loss: 1.2651031017303467
Validation loss: 1.7694417135689848

Epoch: 6| Step: 11
Training loss: 0.7210527658462524
Validation loss: 1.7549617162314795

Epoch: 6| Step: 12
Training loss: 1.2171168327331543
Validation loss: 1.7835722841242307

Epoch: 6| Step: 13
Training loss: 0.9848452806472778
Validation loss: 1.7511945052813458

Epoch: 547| Step: 0
Training loss: 1.2692121267318726
Validation loss: 1.792557103659517

Epoch: 6| Step: 1
Training loss: 1.6472909450531006
Validation loss: 1.7697703146165418

Epoch: 6| Step: 2
Training loss: 1.4499348402023315
Validation loss: 1.8161310816323886

Epoch: 6| Step: 3
Training loss: 0.6613785028457642
Validation loss: 1.780362081784074

Epoch: 6| Step: 4
Training loss: 0.8691474199295044
Validation loss: 1.7904443087116364

Epoch: 6| Step: 5
Training loss: 0.9319888353347778
Validation loss: 1.8470321509145922

Epoch: 6| Step: 6
Training loss: 0.9277443885803223
Validation loss: 1.73853051406081

Epoch: 6| Step: 7
Training loss: 0.7629634737968445
Validation loss: 1.7295932462138515

Epoch: 6| Step: 8
Training loss: 0.9118881225585938
Validation loss: 1.835731194865319

Epoch: 6| Step: 9
Training loss: 1.0052539110183716
Validation loss: 1.7328196469173636

Epoch: 6| Step: 10
Training loss: 0.7864506244659424
Validation loss: 1.8577593859805857

Epoch: 6| Step: 11
Training loss: 0.925015926361084
Validation loss: 1.7674605705404793

Epoch: 6| Step: 12
Training loss: 1.6609978675842285
Validation loss: 1.7874520619710286

Epoch: 6| Step: 13
Training loss: 0.9862658977508545
Validation loss: 1.6889391176162227

Epoch: 548| Step: 0
Training loss: 0.8919246196746826
Validation loss: 1.7475070094549527

Epoch: 6| Step: 1
Training loss: 1.2836673259735107
Validation loss: 1.8103528227857364

Epoch: 6| Step: 2
Training loss: 1.0855381488800049
Validation loss: 1.7287259409504552

Epoch: 6| Step: 3
Training loss: 1.0031152963638306
Validation loss: 1.7944361317542292

Epoch: 6| Step: 4
Training loss: 1.1028687953948975
Validation loss: 1.795850807620633

Epoch: 6| Step: 5
Training loss: 1.1948683261871338
Validation loss: 1.8176897969297183

Epoch: 6| Step: 6
Training loss: 1.3497756719589233
Validation loss: 1.765823410403344

Epoch: 6| Step: 7
Training loss: 0.6264878511428833
Validation loss: 1.73548456545799

Epoch: 6| Step: 8
Training loss: 1.0866127014160156
Validation loss: 1.8407860545701877

Epoch: 6| Step: 9
Training loss: 1.0452659130096436
Validation loss: 1.7824348313834077

Epoch: 6| Step: 10
Training loss: 1.3199589252471924
Validation loss: 1.7728390232209237

Epoch: 6| Step: 11
Training loss: 1.1480354070663452
Validation loss: 1.7839383925161054

Epoch: 6| Step: 12
Training loss: 0.7050421237945557
Validation loss: 1.7959139795713528

Epoch: 6| Step: 13
Training loss: 1.1116632223129272
Validation loss: 1.8115276072614936

Epoch: 549| Step: 0
Training loss: 0.8555915355682373
Validation loss: 1.769431492333771

Epoch: 6| Step: 1
Training loss: 1.0787888765335083
Validation loss: 1.7591021586489934

Epoch: 6| Step: 2
Training loss: 0.8767966032028198
Validation loss: 1.7818871595526253

Epoch: 6| Step: 3
Training loss: 0.8088588118553162
Validation loss: 1.7397236349762126

Epoch: 6| Step: 4
Training loss: 1.3064974546432495
Validation loss: 1.7292717656781595

Epoch: 6| Step: 5
Training loss: 0.9247006177902222
Validation loss: 1.703612937722155

Epoch: 6| Step: 6
Training loss: 1.1367733478546143
Validation loss: 1.7662548788132206

Epoch: 6| Step: 7
Training loss: 1.3262027502059937
Validation loss: 1.7542422727871967

Epoch: 6| Step: 8
Training loss: 0.46012580394744873
Validation loss: 1.781124686682096

Epoch: 6| Step: 9
Training loss: 1.2604172229766846
Validation loss: 1.7681554325165287

Epoch: 6| Step: 10
Training loss: 1.0441696643829346
Validation loss: 1.7702044338308356

Epoch: 6| Step: 11
Training loss: 0.7897346019744873
Validation loss: 1.784123920625256

Epoch: 6| Step: 12
Training loss: 1.1629083156585693
Validation loss: 1.7372322146610548

Epoch: 6| Step: 13
Training loss: 1.4406882524490356
Validation loss: 1.7820961449735908

Epoch: 550| Step: 0
Training loss: 1.0047029256820679
Validation loss: 1.739260337686026

Epoch: 6| Step: 1
Training loss: 0.7865267395973206
Validation loss: 1.7899678086721769

Epoch: 6| Step: 2
Training loss: 1.0713069438934326
Validation loss: 1.8087557156880696

Epoch: 6| Step: 3
Training loss: 1.2463544607162476
Validation loss: 1.7734666678213304

Epoch: 6| Step: 4
Training loss: 1.1760873794555664
Validation loss: 1.7944298713437972

Epoch: 6| Step: 5
Training loss: 1.0493440628051758
Validation loss: 1.8574541332901164

Epoch: 6| Step: 6
Training loss: 1.032812476158142
Validation loss: 1.7759013650237874

Epoch: 6| Step: 7
Training loss: 0.9174344539642334
Validation loss: 1.845798728286579

Epoch: 6| Step: 8
Training loss: 1.4595242738723755
Validation loss: 1.779322075587447

Epoch: 6| Step: 9
Training loss: 1.2783825397491455
Validation loss: 1.7635401423259447

Epoch: 6| Step: 10
Training loss: 0.9606766104698181
Validation loss: 1.8142179058444114

Epoch: 6| Step: 11
Training loss: 0.9314748048782349
Validation loss: 1.8755056127425163

Epoch: 6| Step: 12
Training loss: 0.55657559633255
Validation loss: 1.755478584638206

Epoch: 6| Step: 13
Training loss: 0.7775267362594604
Validation loss: 1.754138163340989

Epoch: 551| Step: 0
Training loss: 0.9092626571655273
Validation loss: 1.7641150374566354

Epoch: 6| Step: 1
Training loss: 1.4019577503204346
Validation loss: 1.7837040437165128

Epoch: 6| Step: 2
Training loss: 1.1255123615264893
Validation loss: 1.7858122715386011

Epoch: 6| Step: 3
Training loss: 0.9487172961235046
Validation loss: 1.6810174552343224

Epoch: 6| Step: 4
Training loss: 0.7346580028533936
Validation loss: 1.7527476318420903

Epoch: 6| Step: 5
Training loss: 0.7342128753662109
Validation loss: 1.793612495545418

Epoch: 6| Step: 6
Training loss: 1.3082760572433472
Validation loss: 1.70808740456899

Epoch: 6| Step: 7
Training loss: 0.728793203830719
Validation loss: 1.7900275414989841

Epoch: 6| Step: 8
Training loss: 1.4027304649353027
Validation loss: 1.8041171796860234

Epoch: 6| Step: 9
Training loss: 1.3360798358917236
Validation loss: 1.7341480434581797

Epoch: 6| Step: 10
Training loss: 1.1364935636520386
Validation loss: 1.6897636716083815

Epoch: 6| Step: 11
Training loss: 0.9671592116355896
Validation loss: 1.770662833285588

Epoch: 6| Step: 12
Training loss: 0.8621671199798584
Validation loss: 1.7554028226483254

Epoch: 6| Step: 13
Training loss: 0.733349084854126
Validation loss: 1.812360148276052

Epoch: 552| Step: 0
Training loss: 0.7759454846382141
Validation loss: 1.8261987034992506

Epoch: 6| Step: 1
Training loss: 1.3312017917633057
Validation loss: 1.7799870455136864

Epoch: 6| Step: 2
Training loss: 1.3010722398757935
Validation loss: 1.7802053754047682

Epoch: 6| Step: 3
Training loss: 0.8228092193603516
Validation loss: 1.8027045572957685

Epoch: 6| Step: 4
Training loss: 0.8212392926216125
Validation loss: 1.8521493481051536

Epoch: 6| Step: 5
Training loss: 1.5816572904586792
Validation loss: 1.7980050681739725

Epoch: 6| Step: 6
Training loss: 0.9516841173171997
Validation loss: 1.7852472156606696

Epoch: 6| Step: 7
Training loss: 1.3607749938964844
Validation loss: 1.8072072280350553

Epoch: 6| Step: 8
Training loss: 1.0602688789367676
Validation loss: 1.7592532019461355

Epoch: 6| Step: 9
Training loss: 0.9495700597763062
Validation loss: 1.7768475278731315

Epoch: 6| Step: 10
Training loss: 0.959418535232544
Validation loss: 1.7815167288626395

Epoch: 6| Step: 11
Training loss: 1.0822408199310303
Validation loss: 1.8324045032583258

Epoch: 6| Step: 12
Training loss: 1.322021722793579
Validation loss: 1.7644773837058776

Epoch: 6| Step: 13
Training loss: 0.7841430306434631
Validation loss: 1.7628544504924486

Epoch: 553| Step: 0
Training loss: 0.9776446223258972
Validation loss: 1.7618276393541725

Epoch: 6| Step: 1
Training loss: 0.956792950630188
Validation loss: 1.7771889407147643

Epoch: 6| Step: 2
Training loss: 0.8643589019775391
Validation loss: 1.798073766052082

Epoch: 6| Step: 3
Training loss: 0.7770248055458069
Validation loss: 1.7785223171275149

Epoch: 6| Step: 4
Training loss: 1.259890079498291
Validation loss: 1.717820188050629

Epoch: 6| Step: 5
Training loss: 0.9628627300262451
Validation loss: 1.771413880009805

Epoch: 6| Step: 6
Training loss: 1.326054334640503
Validation loss: 1.7931730234494774

Epoch: 6| Step: 7
Training loss: 1.1162748336791992
Validation loss: 1.778112825526986

Epoch: 6| Step: 8
Training loss: 1.0076024532318115
Validation loss: 1.7769327958424885

Epoch: 6| Step: 9
Training loss: 1.0491211414337158
Validation loss: 1.7336781024932861

Epoch: 6| Step: 10
Training loss: 1.3452482223510742
Validation loss: 1.8510008319731681

Epoch: 6| Step: 11
Training loss: 1.0105786323547363
Validation loss: 1.7940161048725087

Epoch: 6| Step: 12
Training loss: 1.145622730255127
Validation loss: 1.8021575814934188

Epoch: 6| Step: 13
Training loss: 0.9399880170822144
Validation loss: 1.86529161853175

Epoch: 554| Step: 0
Training loss: 1.3943569660186768
Validation loss: 1.7351791166490125

Epoch: 6| Step: 1
Training loss: 0.727812647819519
Validation loss: 1.8081256574200046

Epoch: 6| Step: 2
Training loss: 1.0120563507080078
Validation loss: 1.8198937908295663

Epoch: 6| Step: 3
Training loss: 1.4368386268615723
Validation loss: 1.7600375388258247

Epoch: 6| Step: 4
Training loss: 1.1607298851013184
Validation loss: 1.8814978573911934

Epoch: 6| Step: 5
Training loss: 1.8531150817871094
Validation loss: 1.7440902058796217

Epoch: 6| Step: 6
Training loss: 1.4602210521697998
Validation loss: 1.7728764908288115

Epoch: 6| Step: 7
Training loss: 0.817913830280304
Validation loss: 1.8025563429760676

Epoch: 6| Step: 8
Training loss: 0.5080629587173462
Validation loss: 1.7644512678987236

Epoch: 6| Step: 9
Training loss: 1.0499815940856934
Validation loss: 1.7418758023169734

Epoch: 6| Step: 10
Training loss: 0.7187052965164185
Validation loss: 1.7531335238487489

Epoch: 6| Step: 11
Training loss: 1.1632449626922607
Validation loss: 1.7214877182437527

Epoch: 6| Step: 12
Training loss: 0.47020119428634644
Validation loss: 1.8223543718296995

Epoch: 6| Step: 13
Training loss: 0.7233384251594543
Validation loss: 1.7708302133826799

Epoch: 555| Step: 0
Training loss: 1.0216833353042603
Validation loss: 1.7197191433240009

Epoch: 6| Step: 1
Training loss: 0.7859637141227722
Validation loss: 1.7594141524325135

Epoch: 6| Step: 2
Training loss: 0.9697010517120361
Validation loss: 1.7518148806787306

Epoch: 6| Step: 3
Training loss: 1.350301742553711
Validation loss: 1.712295332262593

Epoch: 6| Step: 4
Training loss: 1.5774072408676147
Validation loss: 1.7686176723049534

Epoch: 6| Step: 5
Training loss: 0.4728216528892517
Validation loss: 1.7519873214024368

Epoch: 6| Step: 6
Training loss: 1.3075162172317505
Validation loss: 1.7160268829714866

Epoch: 6| Step: 7
Training loss: 0.7215065956115723
Validation loss: 1.6790045807438512

Epoch: 6| Step: 8
Training loss: 1.0817785263061523
Validation loss: 1.7673441517737605

Epoch: 6| Step: 9
Training loss: 1.4990170001983643
Validation loss: 1.7827663370358047

Epoch: 6| Step: 10
Training loss: 0.6240371465682983
Validation loss: 1.7859050035476685

Epoch: 6| Step: 11
Training loss: 1.0390839576721191
Validation loss: 1.8234733894307127

Epoch: 6| Step: 12
Training loss: 1.1274383068084717
Validation loss: 1.7639272084800146

Epoch: 6| Step: 13
Training loss: 1.215787649154663
Validation loss: 1.799717846737113

Epoch: 556| Step: 0
Training loss: 0.9332640171051025
Validation loss: 1.756886511720637

Epoch: 6| Step: 1
Training loss: 1.4033629894256592
Validation loss: 1.738899774448846

Epoch: 6| Step: 2
Training loss: 0.9849072694778442
Validation loss: 1.7484706371061263

Epoch: 6| Step: 3
Training loss: 1.0569392442703247
Validation loss: 1.7762097799649803

Epoch: 6| Step: 4
Training loss: 1.1607849597930908
Validation loss: 1.7664936742474955

Epoch: 6| Step: 5
Training loss: 0.7305139899253845
Validation loss: 1.7808489094498337

Epoch: 6| Step: 6
Training loss: 0.7074785232543945
Validation loss: 1.8245975740494267

Epoch: 6| Step: 7
Training loss: 1.563570499420166
Validation loss: 1.7382675358044204

Epoch: 6| Step: 8
Training loss: 1.5096821784973145
Validation loss: 1.78978475575806

Epoch: 6| Step: 9
Training loss: 0.7656810283660889
Validation loss: 1.7867300766770557

Epoch: 6| Step: 10
Training loss: 0.7365367412567139
Validation loss: 1.7742954120841077

Epoch: 6| Step: 11
Training loss: 0.9095975756645203
Validation loss: 1.7555801150619343

Epoch: 6| Step: 12
Training loss: 1.4068758487701416
Validation loss: 1.8059395487590502

Epoch: 6| Step: 13
Training loss: 0.8235105872154236
Validation loss: 1.885451578324841

Epoch: 557| Step: 0
Training loss: 0.5012139678001404
Validation loss: 1.8008865361572595

Epoch: 6| Step: 1
Training loss: 0.4952549338340759
Validation loss: 1.8057061126155238

Epoch: 6| Step: 2
Training loss: 0.8607039451599121
Validation loss: 1.8091776755548292

Epoch: 6| Step: 3
Training loss: 1.555660367012024
Validation loss: 1.7606134055763163

Epoch: 6| Step: 4
Training loss: 1.1434282064437866
Validation loss: 1.7340273767389276

Epoch: 6| Step: 5
Training loss: 1.1222044229507446
Validation loss: 1.7227941277206584

Epoch: 6| Step: 6
Training loss: 1.5830320119857788
Validation loss: 1.7939163933518112

Epoch: 6| Step: 7
Training loss: 0.8774453401565552
Validation loss: 1.8149413601044686

Epoch: 6| Step: 8
Training loss: 0.9159562587738037
Validation loss: 1.766001655209449

Epoch: 6| Step: 9
Training loss: 1.2574574947357178
Validation loss: 1.7852563101758239

Epoch: 6| Step: 10
Training loss: 1.440481185913086
Validation loss: 1.7593679146100116

Epoch: 6| Step: 11
Training loss: 1.2317538261413574
Validation loss: 1.7316960173268472

Epoch: 6| Step: 12
Training loss: 1.236360788345337
Validation loss: 1.7557352537749915

Epoch: 6| Step: 13
Training loss: 0.6514438986778259
Validation loss: 1.8638494745377572

Epoch: 558| Step: 0
Training loss: 1.3658828735351562
Validation loss: 1.864056867937888

Epoch: 6| Step: 1
Training loss: 0.8311702013015747
Validation loss: 1.8584832094048942

Epoch: 6| Step: 2
Training loss: 0.7861905097961426
Validation loss: 1.8500554869251866

Epoch: 6| Step: 3
Training loss: 1.2774888277053833
Validation loss: 1.880445429073867

Epoch: 6| Step: 4
Training loss: 0.6265461444854736
Validation loss: 1.802291267661638

Epoch: 6| Step: 5
Training loss: 0.8878192901611328
Validation loss: 1.808267601074711

Epoch: 6| Step: 6
Training loss: 0.8693389892578125
Validation loss: 1.821590349238406

Epoch: 6| Step: 7
Training loss: 0.9887771010398865
Validation loss: 1.7807558582675072

Epoch: 6| Step: 8
Training loss: 1.3059852123260498
Validation loss: 1.8113826269744544

Epoch: 6| Step: 9
Training loss: 1.3760387897491455
Validation loss: 1.787644301691363

Epoch: 6| Step: 10
Training loss: 0.9835321307182312
Validation loss: 1.777313893841159

Epoch: 6| Step: 11
Training loss: 0.6685296297073364
Validation loss: 1.7754594164509927

Epoch: 6| Step: 12
Training loss: 1.2438580989837646
Validation loss: 1.7996910233651437

Epoch: 6| Step: 13
Training loss: 1.3797640800476074
Validation loss: 1.7802064944339056

Epoch: 559| Step: 0
Training loss: 1.2974352836608887
Validation loss: 1.7450831051795714

Epoch: 6| Step: 1
Training loss: 0.7528808116912842
Validation loss: 1.7670716393378474

Epoch: 6| Step: 2
Training loss: 1.4392999410629272
Validation loss: 1.7271456769717637

Epoch: 6| Step: 3
Training loss: 1.34345281124115
Validation loss: 1.781131846930391

Epoch: 6| Step: 4
Training loss: 0.9631621837615967
Validation loss: 1.7592214615114274

Epoch: 6| Step: 5
Training loss: 1.1368768215179443
Validation loss: 1.8458709947524532

Epoch: 6| Step: 6
Training loss: 0.846577525138855
Validation loss: 1.834913178156781

Epoch: 6| Step: 7
Training loss: 1.0360854864120483
Validation loss: 1.8487968880643126

Epoch: 6| Step: 8
Training loss: 1.0215678215026855
Validation loss: 1.8504771365914294

Epoch: 6| Step: 9
Training loss: 0.8785402178764343
Validation loss: 1.782163034203232

Epoch: 6| Step: 10
Training loss: 0.6359918117523193
Validation loss: 1.8409595912502659

Epoch: 6| Step: 11
Training loss: 0.9046763181686401
Validation loss: 1.834410362346198

Epoch: 6| Step: 12
Training loss: 0.6438912153244019
Validation loss: 1.797352167867845

Epoch: 6| Step: 13
Training loss: 1.5872293710708618
Validation loss: 1.7103813873824252

Epoch: 560| Step: 0
Training loss: 1.2614526748657227
Validation loss: 1.7212707945095596

Epoch: 6| Step: 1
Training loss: 1.0190287828445435
Validation loss: 1.7803620356385426

Epoch: 6| Step: 2
Training loss: 0.6887965202331543
Validation loss: 1.746030035839286

Epoch: 6| Step: 3
Training loss: 1.0451595783233643
Validation loss: 1.7746422111347158

Epoch: 6| Step: 4
Training loss: 0.9642273187637329
Validation loss: 1.7172255105869745

Epoch: 6| Step: 5
Training loss: 0.6904827952384949
Validation loss: 1.7910706150916316

Epoch: 6| Step: 6
Training loss: 0.9163730144500732
Validation loss: 1.7201377672533835

Epoch: 6| Step: 7
Training loss: 1.33148193359375
Validation loss: 1.7860659809522732

Epoch: 6| Step: 8
Training loss: 1.0715422630310059
Validation loss: 1.7223759171783284

Epoch: 6| Step: 9
Training loss: 0.8571434617042542
Validation loss: 1.7452843150784891

Epoch: 6| Step: 10
Training loss: 0.9604197144508362
Validation loss: 1.7870889068931661

Epoch: 6| Step: 11
Training loss: 1.6669154167175293
Validation loss: 1.8114594336478942

Epoch: 6| Step: 12
Training loss: 0.698099672794342
Validation loss: 1.7599146930120324

Epoch: 6| Step: 13
Training loss: 1.639818787574768
Validation loss: 1.7507333717038553

Epoch: 561| Step: 0
Training loss: 1.0716869831085205
Validation loss: 1.7956816624569636

Epoch: 6| Step: 1
Training loss: 0.7329975962638855
Validation loss: 1.752589915388374

Epoch: 6| Step: 2
Training loss: 1.2515394687652588
Validation loss: 1.795257758068782

Epoch: 6| Step: 3
Training loss: 1.0527567863464355
Validation loss: 1.7835277472772906

Epoch: 6| Step: 4
Training loss: 0.8867915868759155
Validation loss: 1.7439228155279671

Epoch: 6| Step: 5
Training loss: 1.0156989097595215
Validation loss: 1.7268693113839755

Epoch: 6| Step: 6
Training loss: 0.983225405216217
Validation loss: 1.8038392964229788

Epoch: 6| Step: 7
Training loss: 1.0208041667938232
Validation loss: 1.684158730250533

Epoch: 6| Step: 8
Training loss: 1.4535915851593018
Validation loss: 1.7843360413787186

Epoch: 6| Step: 9
Training loss: 0.858496904373169
Validation loss: 1.7604311409816946

Epoch: 6| Step: 10
Training loss: 0.8413726091384888
Validation loss: 1.7384584898589759

Epoch: 6| Step: 11
Training loss: 1.0357344150543213
Validation loss: 1.6974344125358007

Epoch: 6| Step: 12
Training loss: 0.526165246963501
Validation loss: 1.7237835558511878

Epoch: 6| Step: 13
Training loss: 2.1809306144714355
Validation loss: 1.7251347226481284

Epoch: 562| Step: 0
Training loss: 1.419983983039856
Validation loss: 1.7935766737948182

Epoch: 6| Step: 1
Training loss: 0.7478867769241333
Validation loss: 1.8010596254820466

Epoch: 6| Step: 2
Training loss: 1.057926058769226
Validation loss: 1.7467946262769802

Epoch: 6| Step: 3
Training loss: 0.762680172920227
Validation loss: 1.801417375123629

Epoch: 6| Step: 4
Training loss: 1.0978623628616333
Validation loss: 1.806273961579928

Epoch: 6| Step: 5
Training loss: 0.7664157152175903
Validation loss: 1.8264930760988625

Epoch: 6| Step: 6
Training loss: 0.9642060995101929
Validation loss: 1.7310813229571107

Epoch: 6| Step: 7
Training loss: 0.9148983359336853
Validation loss: 1.7342338062101794

Epoch: 6| Step: 8
Training loss: 1.8505120277404785
Validation loss: 1.778234835593931

Epoch: 6| Step: 9
Training loss: 1.1567370891571045
Validation loss: 1.7854936827895462

Epoch: 6| Step: 10
Training loss: 0.7027138471603394
Validation loss: 1.7754473199126541

Epoch: 6| Step: 11
Training loss: 0.948596179485321
Validation loss: 1.7777779820144817

Epoch: 6| Step: 12
Training loss: 0.9948464035987854
Validation loss: 1.7471240130803918

Epoch: 6| Step: 13
Training loss: 1.1228872537612915
Validation loss: 1.7485022634588263

Epoch: 563| Step: 0
Training loss: 1.0765620470046997
Validation loss: 1.7959854090085594

Epoch: 6| Step: 1
Training loss: 0.524335503578186
Validation loss: 1.6978705339534308

Epoch: 6| Step: 2
Training loss: 1.2867741584777832
Validation loss: 1.8437526482407764

Epoch: 6| Step: 3
Training loss: 1.6552717685699463
Validation loss: 1.7247800929571993

Epoch: 6| Step: 4
Training loss: 1.4415677785873413
Validation loss: 1.7404536008834839

Epoch: 6| Step: 5
Training loss: 1.169919729232788
Validation loss: 1.7542933610177809

Epoch: 6| Step: 6
Training loss: 0.6970509886741638
Validation loss: 1.7739159804518505

Epoch: 6| Step: 7
Training loss: 0.46648311614990234
Validation loss: 1.7430491780722013

Epoch: 6| Step: 8
Training loss: 0.7907989621162415
Validation loss: 1.8173684907215897

Epoch: 6| Step: 9
Training loss: 1.4471416473388672
Validation loss: 1.8631193548120477

Epoch: 6| Step: 10
Training loss: 0.7774964570999146
Validation loss: 1.7632971143209806

Epoch: 6| Step: 11
Training loss: 0.9255411028862
Validation loss: 1.7861724694569905

Epoch: 6| Step: 12
Training loss: 0.8910168409347534
Validation loss: 1.7981027134003178

Epoch: 6| Step: 13
Training loss: 1.0743029117584229
Validation loss: 1.7707720777039886

Epoch: 564| Step: 0
Training loss: 0.740182101726532
Validation loss: 1.838584053900934

Epoch: 6| Step: 1
Training loss: 0.8379575610160828
Validation loss: 1.7989814563464093

Epoch: 6| Step: 2
Training loss: 0.9081389904022217
Validation loss: 1.8045472944936445

Epoch: 6| Step: 3
Training loss: 0.886441707611084
Validation loss: 1.816199484691825

Epoch: 6| Step: 4
Training loss: 0.8371927738189697
Validation loss: 1.8142986425789454

Epoch: 6| Step: 5
Training loss: 1.4184331893920898
Validation loss: 1.7266725519652009

Epoch: 6| Step: 6
Training loss: 0.9122756719589233
Validation loss: 1.7783128599966727

Epoch: 6| Step: 7
Training loss: 0.8282990455627441
Validation loss: 1.7701140501165902

Epoch: 6| Step: 8
Training loss: 1.0932780504226685
Validation loss: 1.7764519119775424

Epoch: 6| Step: 9
Training loss: 0.9116760492324829
Validation loss: 1.7336328170632804

Epoch: 6| Step: 10
Training loss: 1.065272569656372
Validation loss: 1.8067736087306854

Epoch: 6| Step: 11
Training loss: 1.111687183380127
Validation loss: 1.7883754161096388

Epoch: 6| Step: 12
Training loss: 1.3276286125183105
Validation loss: 1.7838025298169864

Epoch: 6| Step: 13
Training loss: 1.577736496925354
Validation loss: 1.7447039247840963

Epoch: 565| Step: 0
Training loss: 1.1942824125289917
Validation loss: 1.758093544231948

Epoch: 6| Step: 1
Training loss: 0.9202619791030884
Validation loss: 1.7317850910207278

Epoch: 6| Step: 2
Training loss: 1.0360658168792725
Validation loss: 1.724533196418516

Epoch: 6| Step: 3
Training loss: 1.0811364650726318
Validation loss: 1.7316562142423404

Epoch: 6| Step: 4
Training loss: 1.2649540901184082
Validation loss: 1.844533255023341

Epoch: 6| Step: 5
Training loss: 1.7932740449905396
Validation loss: 1.6879819298303256

Epoch: 6| Step: 6
Training loss: 0.8409308195114136
Validation loss: 1.7786663347674954

Epoch: 6| Step: 7
Training loss: 0.418237566947937
Validation loss: 1.7539880275726318

Epoch: 6| Step: 8
Training loss: 1.1287627220153809
Validation loss: 1.7911222250230852

Epoch: 6| Step: 9
Training loss: 1.1556248664855957
Validation loss: 1.794169505437215

Epoch: 6| Step: 10
Training loss: 0.7817986607551575
Validation loss: 1.7783338933862665

Epoch: 6| Step: 11
Training loss: 0.9443172812461853
Validation loss: 1.7089917749486945

Epoch: 6| Step: 12
Training loss: 0.7260630130767822
Validation loss: 1.7491410240050285

Epoch: 6| Step: 13
Training loss: 1.0123291015625
Validation loss: 1.8207251653876355

Epoch: 566| Step: 0
Training loss: 0.587585985660553
Validation loss: 1.736800362986903

Epoch: 6| Step: 1
Training loss: 0.8084403276443481
Validation loss: 1.7708333153878488

Epoch: 6| Step: 2
Training loss: 1.05076265335083
Validation loss: 1.7583025668257026

Epoch: 6| Step: 3
Training loss: 1.599480390548706
Validation loss: 1.8120848747991747

Epoch: 6| Step: 4
Training loss: 0.8862535953521729
Validation loss: 1.7949019644850044

Epoch: 6| Step: 5
Training loss: 0.8442440629005432
Validation loss: 1.701189979430168

Epoch: 6| Step: 6
Training loss: 1.081196665763855
Validation loss: 1.762380233374975

Epoch: 6| Step: 7
Training loss: 1.1625244617462158
Validation loss: 1.7345261407154862

Epoch: 6| Step: 8
Training loss: 0.9662505984306335
Validation loss: 1.7148109277089436

Epoch: 6| Step: 9
Training loss: 1.355634093284607
Validation loss: 1.8012632195667555

Epoch: 6| Step: 10
Training loss: 0.5555740594863892
Validation loss: 1.766452629079101

Epoch: 6| Step: 11
Training loss: 1.7853765487670898
Validation loss: 1.7465649625306487

Epoch: 6| Step: 12
Training loss: 0.8764058351516724
Validation loss: 1.7753209901112381

Epoch: 6| Step: 13
Training loss: 0.647719144821167
Validation loss: 1.6988539567557714

Epoch: 567| Step: 0
Training loss: 0.9075454473495483
Validation loss: 1.7866085447290891

Epoch: 6| Step: 1
Training loss: 1.5983067750930786
Validation loss: 1.7703882481462212

Epoch: 6| Step: 2
Training loss: 1.0486059188842773
Validation loss: 1.7875686742926156

Epoch: 6| Step: 3
Training loss: 1.8297631740570068
Validation loss: 1.7421641618974748

Epoch: 6| Step: 4
Training loss: 1.1253321170806885
Validation loss: 1.7966420112117645

Epoch: 6| Step: 5
Training loss: 0.7524377703666687
Validation loss: 1.7272020411747757

Epoch: 6| Step: 6
Training loss: 0.7481523752212524
Validation loss: 1.7101841139537033

Epoch: 6| Step: 7
Training loss: 0.678726851940155
Validation loss: 1.7762264782382595

Epoch: 6| Step: 8
Training loss: 1.0936088562011719
Validation loss: 1.723239000125598

Epoch: 6| Step: 9
Training loss: 0.9995574355125427
Validation loss: 1.7872689962387085

Epoch: 6| Step: 10
Training loss: 0.8847576975822449
Validation loss: 1.7878795528924594

Epoch: 6| Step: 11
Training loss: 0.9095138907432556
Validation loss: 1.775246480459808

Epoch: 6| Step: 12
Training loss: 0.9019287824630737
Validation loss: 1.8217044133012013

Epoch: 6| Step: 13
Training loss: 0.7917103171348572
Validation loss: 1.7748025886474117

Epoch: 568| Step: 0
Training loss: 1.252322793006897
Validation loss: 1.7234955603076565

Epoch: 6| Step: 1
Training loss: 1.7071391344070435
Validation loss: 1.7595326721027333

Epoch: 6| Step: 2
Training loss: 0.8351569175720215
Validation loss: 1.830472933348789

Epoch: 6| Step: 3
Training loss: 0.6164320707321167
Validation loss: 1.7149070975601033

Epoch: 6| Step: 4
Training loss: 0.7891892194747925
Validation loss: 1.7387592907874816

Epoch: 6| Step: 5
Training loss: 0.5098246932029724
Validation loss: 1.7352864562824208

Epoch: 6| Step: 6
Training loss: 0.49651971459388733
Validation loss: 1.7416869760841451

Epoch: 6| Step: 7
Training loss: 1.138841152191162
Validation loss: 1.848966037073443

Epoch: 6| Step: 8
Training loss: 1.3397367000579834
Validation loss: 1.7188057822565879

Epoch: 6| Step: 9
Training loss: 1.1120612621307373
Validation loss: 1.800899504333414

Epoch: 6| Step: 10
Training loss: 1.2497799396514893
Validation loss: 1.7251109333448513

Epoch: 6| Step: 11
Training loss: 0.8427422046661377
Validation loss: 1.7094774887125979

Epoch: 6| Step: 12
Training loss: 1.7075339555740356
Validation loss: 1.7109983787741712

Epoch: 6| Step: 13
Training loss: 1.6394459009170532
Validation loss: 1.7605635043113463

Epoch: 569| Step: 0
Training loss: 0.9843565821647644
Validation loss: 1.83403693860577

Epoch: 6| Step: 1
Training loss: 0.8188039660453796
Validation loss: 1.7927144624853646

Epoch: 6| Step: 2
Training loss: 1.2957675457000732
Validation loss: 1.8402659662308232

Epoch: 6| Step: 3
Training loss: 1.29915452003479
Validation loss: 1.8521226939334665

Epoch: 6| Step: 4
Training loss: 1.033054232597351
Validation loss: 1.716067656393974

Epoch: 6| Step: 5
Training loss: 0.5629733204841614
Validation loss: 1.8016966940254293

Epoch: 6| Step: 6
Training loss: 1.3220689296722412
Validation loss: 1.7852662968379196

Epoch: 6| Step: 7
Training loss: 0.7832647562026978
Validation loss: 1.8418045787401096

Epoch: 6| Step: 8
Training loss: 0.965086042881012
Validation loss: 1.7699305947108934

Epoch: 6| Step: 9
Training loss: 1.2419679164886475
Validation loss: 1.768798767879445

Epoch: 6| Step: 10
Training loss: 0.9020884037017822
Validation loss: 1.7546582324530489

Epoch: 6| Step: 11
Training loss: 1.3358969688415527
Validation loss: 1.795488311398414

Epoch: 6| Step: 12
Training loss: 0.8417773246765137
Validation loss: 1.7513193135620446

Epoch: 6| Step: 13
Training loss: 1.3274832963943481
Validation loss: 1.7665120299144457

Epoch: 570| Step: 0
Training loss: 0.7838482856750488
Validation loss: 1.742474009913783

Epoch: 6| Step: 1
Training loss: 1.1663014888763428
Validation loss: 1.6945916350169847

Epoch: 6| Step: 2
Training loss: 1.397346019744873
Validation loss: 1.765616342585574

Epoch: 6| Step: 3
Training loss: 0.5153833627700806
Validation loss: 1.783899821260924

Epoch: 6| Step: 4
Training loss: 1.0268759727478027
Validation loss: 1.7124191996871785

Epoch: 6| Step: 5
Training loss: 1.1943076848983765
Validation loss: 1.7563467987122074

Epoch: 6| Step: 6
Training loss: 1.0346349477767944
Validation loss: 1.77679854823697

Epoch: 6| Step: 7
Training loss: 1.6405870914459229
Validation loss: 1.7697005502639278

Epoch: 6| Step: 8
Training loss: 0.8658203482627869
Validation loss: 1.7912057240804036

Epoch: 6| Step: 9
Training loss: 1.0623559951782227
Validation loss: 1.74493319501159

Epoch: 6| Step: 10
Training loss: 0.8774871230125427
Validation loss: 1.706324085112541

Epoch: 6| Step: 11
Training loss: 1.0821105241775513
Validation loss: 1.8080280019390969

Epoch: 6| Step: 12
Training loss: 0.8686732649803162
Validation loss: 1.8198277411922332

Epoch: 6| Step: 13
Training loss: 0.611363410949707
Validation loss: 1.7736339030727264

Epoch: 571| Step: 0
Training loss: 0.9531113505363464
Validation loss: 1.775996151790824

Epoch: 6| Step: 1
Training loss: 1.0755484104156494
Validation loss: 1.790758761026526

Epoch: 6| Step: 2
Training loss: 1.1020030975341797
Validation loss: 1.8263010594152636

Epoch: 6| Step: 3
Training loss: 1.0649200677871704
Validation loss: 1.7686008663587673

Epoch: 6| Step: 4
Training loss: 0.9555820226669312
Validation loss: 1.8001996060853362

Epoch: 6| Step: 5
Training loss: 1.0989596843719482
Validation loss: 1.8099387166320637

Epoch: 6| Step: 6
Training loss: 0.8599578142166138
Validation loss: 1.7604726975963962

Epoch: 6| Step: 7
Training loss: 0.9126975536346436
Validation loss: 1.7510527795360935

Epoch: 6| Step: 8
Training loss: 0.875985860824585
Validation loss: 1.7617161620047785

Epoch: 6| Step: 9
Training loss: 1.6987507343292236
Validation loss: 1.7587695147401543

Epoch: 6| Step: 10
Training loss: 1.1559356451034546
Validation loss: 1.7843263918353665

Epoch: 6| Step: 11
Training loss: 0.8280206918716431
Validation loss: 1.7328329945123324

Epoch: 6| Step: 12
Training loss: 0.8895671367645264
Validation loss: 1.8051830927530925

Epoch: 6| Step: 13
Training loss: 0.40576717257499695
Validation loss: 1.7293889855825773

Epoch: 572| Step: 0
Training loss: 0.8303443193435669
Validation loss: 1.7871124744415283

Epoch: 6| Step: 1
Training loss: 1.1728010177612305
Validation loss: 1.728278842023624

Epoch: 6| Step: 2
Training loss: 1.2888540029525757
Validation loss: 1.7471618178070232

Epoch: 6| Step: 3
Training loss: 0.5740187168121338
Validation loss: 1.8083935296663673

Epoch: 6| Step: 4
Training loss: 0.6554203033447266
Validation loss: 1.794843840342696

Epoch: 6| Step: 5
Training loss: 0.8423095941543579
Validation loss: 1.754431031083548

Epoch: 6| Step: 6
Training loss: 1.5910828113555908
Validation loss: 1.8061299554763302

Epoch: 6| Step: 7
Training loss: 1.2042675018310547
Validation loss: 1.7745192307297901

Epoch: 6| Step: 8
Training loss: 0.9503599405288696
Validation loss: 1.8010622788501043

Epoch: 6| Step: 9
Training loss: 0.6204995512962341
Validation loss: 1.7602468818746588

Epoch: 6| Step: 10
Training loss: 1.114236831665039
Validation loss: 1.7659319344387259

Epoch: 6| Step: 11
Training loss: 0.8732070326805115
Validation loss: 1.7903241585659724

Epoch: 6| Step: 12
Training loss: 1.170223355293274
Validation loss: 1.806043235204553

Epoch: 6| Step: 13
Training loss: 0.975692868232727
Validation loss: 1.7992488620101765

Epoch: 573| Step: 0
Training loss: 0.9318770170211792
Validation loss: 1.8368714522289973

Epoch: 6| Step: 1
Training loss: 0.7623339295387268
Validation loss: 1.7444482862308461

Epoch: 6| Step: 2
Training loss: 1.1700100898742676
Validation loss: 1.6983363256659558

Epoch: 6| Step: 3
Training loss: 1.0515323877334595
Validation loss: 1.757041658124616

Epoch: 6| Step: 4
Training loss: 0.7100461721420288
Validation loss: 1.7821415790947535

Epoch: 6| Step: 5
Training loss: 1.6891639232635498
Validation loss: 1.7018486274186002

Epoch: 6| Step: 6
Training loss: 0.748470664024353
Validation loss: 1.7802841496723953

Epoch: 6| Step: 7
Training loss: 1.1341136693954468
Validation loss: 1.7777843462523593

Epoch: 6| Step: 8
Training loss: 1.193605899810791
Validation loss: 1.7684685094382173

Epoch: 6| Step: 9
Training loss: 1.092259168624878
Validation loss: 1.7684145947938323

Epoch: 6| Step: 10
Training loss: 1.146822214126587
Validation loss: 1.7186546582047657

Epoch: 6| Step: 11
Training loss: 0.6893339157104492
Validation loss: 1.7383043214838991

Epoch: 6| Step: 12
Training loss: 0.8223135471343994
Validation loss: 1.7501695015097176

Epoch: 6| Step: 13
Training loss: 1.1267859935760498
Validation loss: 1.8109128667462258

Epoch: 574| Step: 0
Training loss: 0.7287061214447021
Validation loss: 1.7458369578084638

Epoch: 6| Step: 1
Training loss: 0.7987627387046814
Validation loss: 1.808393915494283

Epoch: 6| Step: 2
Training loss: 0.7575706243515015
Validation loss: 1.7934084682054416

Epoch: 6| Step: 3
Training loss: 0.9172205924987793
Validation loss: 1.8067474647234845

Epoch: 6| Step: 4
Training loss: 0.5884528756141663
Validation loss: 1.7217669089635212

Epoch: 6| Step: 5
Training loss: 1.2721055746078491
Validation loss: 1.7650522955002323

Epoch: 6| Step: 6
Training loss: 1.0124542713165283
Validation loss: 1.730332011817604

Epoch: 6| Step: 7
Training loss: 0.8777279853820801
Validation loss: 1.7607196505351732

Epoch: 6| Step: 8
Training loss: 0.8438780903816223
Validation loss: 1.7976058093450402

Epoch: 6| Step: 9
Training loss: 1.6581699848175049
Validation loss: 1.7699345157992454

Epoch: 6| Step: 10
Training loss: 1.1668503284454346
Validation loss: 1.758044247986168

Epoch: 6| Step: 11
Training loss: 1.365710735321045
Validation loss: 1.7323013569719048

Epoch: 6| Step: 12
Training loss: 1.2131612300872803
Validation loss: 1.71090954413978

Epoch: 6| Step: 13
Training loss: 1.2976529598236084
Validation loss: 1.7734868193185458

Epoch: 575| Step: 0
Training loss: 1.0718270540237427
Validation loss: 1.7172072049110167

Epoch: 6| Step: 1
Training loss: 0.708308219909668
Validation loss: 1.7532003528328353

Epoch: 6| Step: 2
Training loss: 0.8310377597808838
Validation loss: 1.7149226806497062

Epoch: 6| Step: 3
Training loss: 0.9763591885566711
Validation loss: 1.7576846294505621

Epoch: 6| Step: 4
Training loss: 0.7637966275215149
Validation loss: 1.7149087511083132

Epoch: 6| Step: 5
Training loss: 1.0555554628372192
Validation loss: 1.724366134212863

Epoch: 6| Step: 6
Training loss: 1.0570957660675049
Validation loss: 1.747124215608002

Epoch: 6| Step: 7
Training loss: 1.1939070224761963
Validation loss: 1.744453937776627

Epoch: 6| Step: 8
Training loss: 1.159961462020874
Validation loss: 1.7351962815048874

Epoch: 6| Step: 9
Training loss: 0.9060789346694946
Validation loss: 1.781507408747109

Epoch: 6| Step: 10
Training loss: 0.586588978767395
Validation loss: 1.7576014072664323

Epoch: 6| Step: 11
Training loss: 1.9572697877883911
Validation loss: 1.6923329343077957

Epoch: 6| Step: 12
Training loss: 0.724287748336792
Validation loss: 1.7198324549582698

Epoch: 6| Step: 13
Training loss: 1.5112758874893188
Validation loss: 1.7861887870296356

Epoch: 576| Step: 0
Training loss: 1.4323416948318481
Validation loss: 1.7736325071704002

Epoch: 6| Step: 1
Training loss: 0.6574823260307312
Validation loss: 1.7299678428198701

Epoch: 6| Step: 2
Training loss: 1.152303695678711
Validation loss: 1.7351297165757866

Epoch: 6| Step: 3
Training loss: 0.8437992334365845
Validation loss: 1.7513283068133938

Epoch: 6| Step: 4
Training loss: 0.7998563051223755
Validation loss: 1.7542484691066127

Epoch: 6| Step: 5
Training loss: 0.770240843296051
Validation loss: 1.8223218969119492

Epoch: 6| Step: 6
Training loss: 0.9080709218978882
Validation loss: 1.7982696397330171

Epoch: 6| Step: 7
Training loss: 1.6406865119934082
Validation loss: 1.7377166504501014

Epoch: 6| Step: 8
Training loss: 0.5636816024780273
Validation loss: 1.7249763870751986

Epoch: 6| Step: 9
Training loss: 0.7858958840370178
Validation loss: 1.7435758575316398

Epoch: 6| Step: 10
Training loss: 0.9821765422821045
Validation loss: 1.7310595102207635

Epoch: 6| Step: 11
Training loss: 1.3394336700439453
Validation loss: 1.7556940253062914

Epoch: 6| Step: 12
Training loss: 1.356559157371521
Validation loss: 1.7559050706125074

Epoch: 6| Step: 13
Training loss: 1.0079020261764526
Validation loss: 1.7684191978105934

Epoch: 577| Step: 0
Training loss: 1.4924049377441406
Validation loss: 1.769279415889453

Epoch: 6| Step: 1
Training loss: 1.0885765552520752
Validation loss: 1.74358735545989

Epoch: 6| Step: 2
Training loss: 0.7617042064666748
Validation loss: 1.7745772433537308

Epoch: 6| Step: 3
Training loss: 0.70058274269104
Validation loss: 1.780879770555804

Epoch: 6| Step: 4
Training loss: 0.7105771899223328
Validation loss: 1.6987690130869548

Epoch: 6| Step: 5
Training loss: 0.7882894277572632
Validation loss: 1.7721995628008278

Epoch: 6| Step: 6
Training loss: 0.6635558605194092
Validation loss: 1.810365217988209

Epoch: 6| Step: 7
Training loss: 1.0866153240203857
Validation loss: 1.7406234536119687

Epoch: 6| Step: 8
Training loss: 1.0238384008407593
Validation loss: 1.75410795211792

Epoch: 6| Step: 9
Training loss: 1.2876724004745483
Validation loss: 1.7826983108315417

Epoch: 6| Step: 10
Training loss: 1.6079649925231934
Validation loss: 1.8283292426857898

Epoch: 6| Step: 11
Training loss: 0.7543410062789917
Validation loss: 1.7595113156944193

Epoch: 6| Step: 12
Training loss: 0.9022045731544495
Validation loss: 1.8048813394320908

Epoch: 6| Step: 13
Training loss: 1.2985085248947144
Validation loss: 1.7842126892459007

Epoch: 578| Step: 0
Training loss: 0.792719304561615
Validation loss: 1.7287494110804733

Epoch: 6| Step: 1
Training loss: 1.1132087707519531
Validation loss: 1.757446071153046

Epoch: 6| Step: 2
Training loss: 1.0249416828155518
Validation loss: 1.709008119439566

Epoch: 6| Step: 3
Training loss: 0.6021362543106079
Validation loss: 1.7643858758352136

Epoch: 6| Step: 4
Training loss: 0.9436252117156982
Validation loss: 1.713599435744747

Epoch: 6| Step: 5
Training loss: 0.9484856128692627
Validation loss: 1.7445910797324231

Epoch: 6| Step: 6
Training loss: 1.400414228439331
Validation loss: 1.7830438383163945

Epoch: 6| Step: 7
Training loss: 1.3320882320404053
Validation loss: 1.7258991310673375

Epoch: 6| Step: 8
Training loss: 0.8587182760238647
Validation loss: 1.761545660675213

Epoch: 6| Step: 9
Training loss: 1.1063261032104492
Validation loss: 1.6812549047572638

Epoch: 6| Step: 10
Training loss: 0.9239276647567749
Validation loss: 1.7111849092668103

Epoch: 6| Step: 11
Training loss: 0.8820672035217285
Validation loss: 1.7424606828279392

Epoch: 6| Step: 12
Training loss: 0.9102286100387573
Validation loss: 1.7469438839984197

Epoch: 6| Step: 13
Training loss: 1.6532666683197021
Validation loss: 1.7903795883219729

Epoch: 579| Step: 0
Training loss: 1.076329231262207
Validation loss: 1.731305690221889

Epoch: 6| Step: 1
Training loss: 1.1928787231445312
Validation loss: 1.781842993151757

Epoch: 6| Step: 2
Training loss: 1.203885793685913
Validation loss: 1.779491441224211

Epoch: 6| Step: 3
Training loss: 1.0604987144470215
Validation loss: 1.766845041705716

Epoch: 6| Step: 4
Training loss: 0.7232397794723511
Validation loss: 1.8145224842973935

Epoch: 6| Step: 5
Training loss: 0.9556809663772583
Validation loss: 1.767371493001138

Epoch: 6| Step: 6
Training loss: 0.8935916423797607
Validation loss: 1.828547220076284

Epoch: 6| Step: 7
Training loss: 1.3214486837387085
Validation loss: 1.7807699634182839

Epoch: 6| Step: 8
Training loss: 1.0136946439743042
Validation loss: 1.8259915613359021

Epoch: 6| Step: 9
Training loss: 0.6705135107040405
Validation loss: 1.7014923582794845

Epoch: 6| Step: 10
Training loss: 0.9741706252098083
Validation loss: 1.73981560045673

Epoch: 6| Step: 11
Training loss: 0.7994652390480042
Validation loss: 1.778093816131674

Epoch: 6| Step: 12
Training loss: 1.4098663330078125
Validation loss: 1.7519262811189056

Epoch: 6| Step: 13
Training loss: 0.8526552319526672
Validation loss: 1.7419961934448571

Epoch: 580| Step: 0
Training loss: 0.972557783126831
Validation loss: 1.746063773350049

Epoch: 6| Step: 1
Training loss: 1.2235090732574463
Validation loss: 1.8010820881012948

Epoch: 6| Step: 2
Training loss: 0.9135037660598755
Validation loss: 1.6845218007282545

Epoch: 6| Step: 3
Training loss: 1.3110918998718262
Validation loss: 1.7484042054863387

Epoch: 6| Step: 4
Training loss: 1.0446152687072754
Validation loss: 1.8155021052206717

Epoch: 6| Step: 5
Training loss: 1.2447280883789062
Validation loss: 1.7609344759295065

Epoch: 6| Step: 6
Training loss: 0.7272920608520508
Validation loss: 1.7734461740780902

Epoch: 6| Step: 7
Training loss: 0.5516756176948547
Validation loss: 1.7059226702618342

Epoch: 6| Step: 8
Training loss: 1.0353236198425293
Validation loss: 1.782581942055815

Epoch: 6| Step: 9
Training loss: 0.7995191812515259
Validation loss: 1.8148416549928728

Epoch: 6| Step: 10
Training loss: 1.085669755935669
Validation loss: 1.7328207108282274

Epoch: 6| Step: 11
Training loss: 1.7508795261383057
Validation loss: 1.7383447129239318

Epoch: 6| Step: 12
Training loss: 0.851138710975647
Validation loss: 1.7580082057624735

Epoch: 6| Step: 13
Training loss: 0.6427731513977051
Validation loss: 1.7265887568073888

Epoch: 581| Step: 0
Training loss: 0.6220728158950806
Validation loss: 1.7490139084477578

Epoch: 6| Step: 1
Training loss: 1.0677599906921387
Validation loss: 1.761546904040921

Epoch: 6| Step: 2
Training loss: 0.8107844591140747
Validation loss: 1.769395823119789

Epoch: 6| Step: 3
Training loss: 0.8209025263786316
Validation loss: 1.7380361595461447

Epoch: 6| Step: 4
Training loss: 0.7743831872940063
Validation loss: 1.7874632881533714

Epoch: 6| Step: 5
Training loss: 1.7562233209609985
Validation loss: 1.7184202953051495

Epoch: 6| Step: 6
Training loss: 0.9768924713134766
Validation loss: 1.782444138680735

Epoch: 6| Step: 7
Training loss: 0.9163055419921875
Validation loss: 1.7809117442818099

Epoch: 6| Step: 8
Training loss: 1.1692217588424683
Validation loss: 1.816848870246641

Epoch: 6| Step: 9
Training loss: 0.7494328022003174
Validation loss: 1.852692775828864

Epoch: 6| Step: 10
Training loss: 0.6784903407096863
Validation loss: 1.8036053231967393

Epoch: 6| Step: 11
Training loss: 1.2062164545059204
Validation loss: 1.7775502371531662

Epoch: 6| Step: 12
Training loss: 1.3349133729934692
Validation loss: 1.8129153918194514

Epoch: 6| Step: 13
Training loss: 1.6332253217697144
Validation loss: 1.7796504523164483

Epoch: 582| Step: 0
Training loss: 0.9422878623008728
Validation loss: 1.7768341174689672

Epoch: 6| Step: 1
Training loss: 1.2399160861968994
Validation loss: 1.7982158314797185

Epoch: 6| Step: 2
Training loss: 1.070588231086731
Validation loss: 1.8487895034974622

Epoch: 6| Step: 3
Training loss: 0.7479696273803711
Validation loss: 1.7669545271063363

Epoch: 6| Step: 4
Training loss: 1.3141076564788818
Validation loss: 1.7702800778932468

Epoch: 6| Step: 5
Training loss: 0.9245758056640625
Validation loss: 1.747355204756542

Epoch: 6| Step: 6
Training loss: 0.6286115646362305
Validation loss: 1.7856433071115965

Epoch: 6| Step: 7
Training loss: 0.5560110807418823
Validation loss: 1.745211273111323

Epoch: 6| Step: 8
Training loss: 1.4050979614257812
Validation loss: 1.7371704783490909

Epoch: 6| Step: 9
Training loss: 0.8656709790229797
Validation loss: 1.7313357976175123

Epoch: 6| Step: 10
Training loss: 0.7730729579925537
Validation loss: 1.758737002649615

Epoch: 6| Step: 11
Training loss: 0.6604881882667542
Validation loss: 1.7221947690492034

Epoch: 6| Step: 12
Training loss: 1.9053764343261719
Validation loss: 1.7140874811398086

Epoch: 6| Step: 13
Training loss: 1.1485432386398315
Validation loss: 1.7330210337074854

Epoch: 583| Step: 0
Training loss: 0.7284138202667236
Validation loss: 1.8190984072223786

Epoch: 6| Step: 1
Training loss: 1.0928730964660645
Validation loss: 1.7336329965181247

Epoch: 6| Step: 2
Training loss: 0.8285540342330933
Validation loss: 1.680371198602902

Epoch: 6| Step: 3
Training loss: 1.0854835510253906
Validation loss: 1.7541348203536002

Epoch: 6| Step: 4
Training loss: 0.8090943694114685
Validation loss: 1.7335224715612267

Epoch: 6| Step: 5
Training loss: 1.0746179819107056
Validation loss: 1.7918220207255373

Epoch: 6| Step: 6
Training loss: 1.1028293371200562
Validation loss: 1.7626806356573617

Epoch: 6| Step: 7
Training loss: 1.530336856842041
Validation loss: 1.7466689719948718

Epoch: 6| Step: 8
Training loss: 0.7640309929847717
Validation loss: 1.7437377245195451

Epoch: 6| Step: 9
Training loss: 1.0903688669204712
Validation loss: 1.768443166568715

Epoch: 6| Step: 10
Training loss: 0.8595343828201294
Validation loss: 1.799598136255818

Epoch: 6| Step: 11
Training loss: 1.0048234462738037
Validation loss: 1.7943402567217428

Epoch: 6| Step: 12
Training loss: 1.1670148372650146
Validation loss: 1.7736747444316905

Epoch: 6| Step: 13
Training loss: 0.5137417912483215
Validation loss: 1.746515489393665

Epoch: 584| Step: 0
Training loss: 1.0596381425857544
Validation loss: 1.7776764592816752

Epoch: 6| Step: 1
Training loss: 0.8815740346908569
Validation loss: 1.7795138628252092

Epoch: 6| Step: 2
Training loss: 1.3116142749786377
Validation loss: 1.7674341842692385

Epoch: 6| Step: 3
Training loss: 0.6842352151870728
Validation loss: 1.778344021048597

Epoch: 6| Step: 4
Training loss: 0.9356062412261963
Validation loss: 1.811396224524385

Epoch: 6| Step: 5
Training loss: 0.8566511869430542
Validation loss: 1.7400730886766989

Epoch: 6| Step: 6
Training loss: 1.243146538734436
Validation loss: 1.7406887828662831

Epoch: 6| Step: 7
Training loss: 0.6215127110481262
Validation loss: 1.7779690604056082

Epoch: 6| Step: 8
Training loss: 0.7699669599533081
Validation loss: 1.7785815141534294

Epoch: 6| Step: 9
Training loss: 1.1772950887680054
Validation loss: 1.788549800072947

Epoch: 6| Step: 10
Training loss: 0.7777760028839111
Validation loss: 1.7638011311972013

Epoch: 6| Step: 11
Training loss: 1.4047948122024536
Validation loss: 1.7564559482759046

Epoch: 6| Step: 12
Training loss: 0.7757874131202698
Validation loss: 1.82664474620614

Epoch: 6| Step: 13
Training loss: 1.4255374670028687
Validation loss: 1.7808385625962289

Epoch: 585| Step: 0
Training loss: 1.0546225309371948
Validation loss: 1.803548098892294

Epoch: 6| Step: 1
Training loss: 0.8983280658721924
Validation loss: 1.7595724149416851

Epoch: 6| Step: 2
Training loss: 1.3153598308563232
Validation loss: 1.7573976337268788

Epoch: 6| Step: 3
Training loss: 1.7553961277008057
Validation loss: 1.7827143746037637

Epoch: 6| Step: 4
Training loss: 0.6553131937980652
Validation loss: 1.8184760526944233

Epoch: 6| Step: 5
Training loss: 1.003806233406067
Validation loss: 1.7838703829755065

Epoch: 6| Step: 6
Training loss: 0.834111750125885
Validation loss: 1.7468885734517088

Epoch: 6| Step: 7
Training loss: 1.4222275018692017
Validation loss: 1.84209817840207

Epoch: 6| Step: 8
Training loss: 1.0144213438034058
Validation loss: 1.7714076734358264

Epoch: 6| Step: 9
Training loss: 1.0618422031402588
Validation loss: 1.794183333714803

Epoch: 6| Step: 10
Training loss: 0.7340173721313477
Validation loss: 1.794024698195919

Epoch: 6| Step: 11
Training loss: 0.837009072303772
Validation loss: 1.7432186058772507

Epoch: 6| Step: 12
Training loss: 0.5167375802993774
Validation loss: 1.8059638546359154

Epoch: 6| Step: 13
Training loss: 1.204282283782959
Validation loss: 1.7712821498993905

Epoch: 586| Step: 0
Training loss: 0.7218115329742432
Validation loss: 1.7735525331189554

Epoch: 6| Step: 1
Training loss: 0.7728447914123535
Validation loss: 1.7809464059850222

Epoch: 6| Step: 2
Training loss: 0.76024329662323
Validation loss: 1.7595298033888622

Epoch: 6| Step: 3
Training loss: 1.1931421756744385
Validation loss: 1.7522925202564528

Epoch: 6| Step: 4
Training loss: 1.1356182098388672
Validation loss: 1.7558967631350282

Epoch: 6| Step: 5
Training loss: 0.9157665371894836
Validation loss: 1.83866411383434

Epoch: 6| Step: 6
Training loss: 1.2093058824539185
Validation loss: 1.7202153000780331

Epoch: 6| Step: 7
Training loss: 0.6066712141036987
Validation loss: 1.7526172796885173

Epoch: 6| Step: 8
Training loss: 1.4303284883499146
Validation loss: 1.780607800329885

Epoch: 6| Step: 9
Training loss: 0.991688072681427
Validation loss: 1.7255815536745134

Epoch: 6| Step: 10
Training loss: 1.0800331830978394
Validation loss: 1.81300264276484

Epoch: 6| Step: 11
Training loss: 0.595514178276062
Validation loss: 1.7717955445730558

Epoch: 6| Step: 12
Training loss: 1.11801016330719
Validation loss: 1.751243043971318

Epoch: 6| Step: 13
Training loss: 1.608112096786499
Validation loss: 1.7481658445891513

Epoch: 587| Step: 0
Training loss: 0.7420792579650879
Validation loss: 1.724618791252054

Epoch: 6| Step: 1
Training loss: 0.8445248603820801
Validation loss: 1.7889428933461506

Epoch: 6| Step: 2
Training loss: 0.9018492698669434
Validation loss: 1.7460354041027766

Epoch: 6| Step: 3
Training loss: 1.3574230670928955
Validation loss: 1.7587824970163324

Epoch: 6| Step: 4
Training loss: 1.0962765216827393
Validation loss: 1.7558783818316717

Epoch: 6| Step: 5
Training loss: 0.7209066152572632
Validation loss: 1.747606849157682

Epoch: 6| Step: 6
Training loss: 0.48486822843551636
Validation loss: 1.7878289940536662

Epoch: 6| Step: 7
Training loss: 1.294546127319336
Validation loss: 1.8038868314476424

Epoch: 6| Step: 8
Training loss: 1.0335966348648071
Validation loss: 1.7242500884558565

Epoch: 6| Step: 9
Training loss: 1.2953662872314453
Validation loss: 1.7902687441918157

Epoch: 6| Step: 10
Training loss: 1.4315294027328491
Validation loss: 1.756298174140274

Epoch: 6| Step: 11
Training loss: 1.0665233135223389
Validation loss: 1.696434708051784

Epoch: 6| Step: 12
Training loss: 0.4621872305870056
Validation loss: 1.7682821891641105

Epoch: 6| Step: 13
Training loss: 1.1068388223648071
Validation loss: 1.728063468010195

Epoch: 588| Step: 0
Training loss: 1.2174677848815918
Validation loss: 1.719611011525636

Epoch: 6| Step: 1
Training loss: 1.2414764165878296
Validation loss: 1.774224208247277

Epoch: 6| Step: 2
Training loss: 0.8157045841217041
Validation loss: 1.822978352987638

Epoch: 6| Step: 3
Training loss: 0.9705492258071899
Validation loss: 1.7658695879802908

Epoch: 6| Step: 4
Training loss: 0.7140768766403198
Validation loss: 1.7929485946573236

Epoch: 6| Step: 5
Training loss: 0.8477256298065186
Validation loss: 1.7590774195168608

Epoch: 6| Step: 6
Training loss: 1.0496946573257446
Validation loss: 1.8214297884254045

Epoch: 6| Step: 7
Training loss: 1.497243881225586
Validation loss: 1.7082375787919568

Epoch: 6| Step: 8
Training loss: 0.8344022035598755
Validation loss: 1.8284281697324527

Epoch: 6| Step: 9
Training loss: 0.5629626512527466
Validation loss: 1.7947187551888086

Epoch: 6| Step: 10
Training loss: 1.019826054573059
Validation loss: 1.726914071267651

Epoch: 6| Step: 11
Training loss: 1.2599340677261353
Validation loss: 1.7423208246948898

Epoch: 6| Step: 12
Training loss: 1.035433053970337
Validation loss: 1.6946818431218464

Epoch: 6| Step: 13
Training loss: 1.1185590028762817
Validation loss: 1.7148718641650291

Epoch: 589| Step: 0
Training loss: 0.8560993671417236
Validation loss: 1.7401215363574285

Epoch: 6| Step: 1
Training loss: 0.9684269428253174
Validation loss: 1.730777161095732

Epoch: 6| Step: 2
Training loss: 0.7188812494277954
Validation loss: 1.7420981468692902

Epoch: 6| Step: 3
Training loss: 1.2163491249084473
Validation loss: 1.7258463136611446

Epoch: 6| Step: 4
Training loss: 1.03709077835083
Validation loss: 1.7304503981785109

Epoch: 6| Step: 5
Training loss: 0.9412778615951538
Validation loss: 1.7161111459937146

Epoch: 6| Step: 6
Training loss: 0.7727382183074951
Validation loss: 1.7577749003646195

Epoch: 6| Step: 7
Training loss: 0.8180521130561829
Validation loss: 1.761401822490077

Epoch: 6| Step: 8
Training loss: 0.8213912844657898
Validation loss: 1.7456852107919671

Epoch: 6| Step: 9
Training loss: 1.7663075923919678
Validation loss: 1.6888465496801561

Epoch: 6| Step: 10
Training loss: 0.8969584703445435
Validation loss: 1.75849526287407

Epoch: 6| Step: 11
Training loss: 1.087689757347107
Validation loss: 1.724765549423874

Epoch: 6| Step: 12
Training loss: 1.336075782775879
Validation loss: 1.7667640562980407

Epoch: 6| Step: 13
Training loss: 0.8996107578277588
Validation loss: 1.8124642090130878

Epoch: 590| Step: 0
Training loss: 0.6410191059112549
Validation loss: 1.7278592663426553

Epoch: 6| Step: 1
Training loss: 1.0264543294906616
Validation loss: 1.759302564846572

Epoch: 6| Step: 2
Training loss: 1.473726749420166
Validation loss: 1.7253181421628563

Epoch: 6| Step: 3
Training loss: 0.6902621388435364
Validation loss: 1.7470617653221212

Epoch: 6| Step: 4
Training loss: 1.1093153953552246
Validation loss: 1.7352385392753027

Epoch: 6| Step: 5
Training loss: 0.8503143787384033
Validation loss: 1.751411239306132

Epoch: 6| Step: 6
Training loss: 0.7850836515426636
Validation loss: 1.7881872461688133

Epoch: 6| Step: 7
Training loss: 1.7125297784805298
Validation loss: 1.7980216613379858

Epoch: 6| Step: 8
Training loss: 0.6087119579315186
Validation loss: 1.7763690704940467

Epoch: 6| Step: 9
Training loss: 1.003915786743164
Validation loss: 1.8588819631966211

Epoch: 6| Step: 10
Training loss: 1.172776222229004
Validation loss: 1.8263163835771623

Epoch: 6| Step: 11
Training loss: 0.8458042144775391
Validation loss: 1.7792685544618996

Epoch: 6| Step: 12
Training loss: 1.388749599456787
Validation loss: 1.736313250757033

Epoch: 6| Step: 13
Training loss: 1.0066038370132446
Validation loss: 1.730410768139747

Epoch: 591| Step: 0
Training loss: 0.7518999576568604
Validation loss: 1.7443668252678328

Epoch: 6| Step: 1
Training loss: 0.9455922842025757
Validation loss: 1.7809479454512238

Epoch: 6| Step: 2
Training loss: 0.609095573425293
Validation loss: 1.6859918332869006

Epoch: 6| Step: 3
Training loss: 0.9411865472793579
Validation loss: 1.7628008447667605

Epoch: 6| Step: 4
Training loss: 1.1255072355270386
Validation loss: 1.7157003930819932

Epoch: 6| Step: 5
Training loss: 0.9467645883560181
Validation loss: 1.7489732029617473

Epoch: 6| Step: 6
Training loss: 1.1794859170913696
Validation loss: 1.7687647983592043

Epoch: 6| Step: 7
Training loss: 0.47781431674957275
Validation loss: 1.793093656980863

Epoch: 6| Step: 8
Training loss: 1.3705053329467773
Validation loss: 1.74470518994075

Epoch: 6| Step: 9
Training loss: 0.7640484571456909
Validation loss: 1.7202492452436877

Epoch: 6| Step: 10
Training loss: 0.8657126426696777
Validation loss: 1.7745786264378538

Epoch: 6| Step: 11
Training loss: 0.8550113439559937
Validation loss: 1.7784443991158598

Epoch: 6| Step: 12
Training loss: 1.3352112770080566
Validation loss: 1.728713236829286

Epoch: 6| Step: 13
Training loss: 1.7779000997543335
Validation loss: 1.6945953574231876

Epoch: 592| Step: 0
Training loss: 0.8019905090332031
Validation loss: 1.7723715382237588

Epoch: 6| Step: 1
Training loss: 0.7674775123596191
Validation loss: 1.7585363157333866

Epoch: 6| Step: 2
Training loss: 0.9127703905105591
Validation loss: 1.7469189192659111

Epoch: 6| Step: 3
Training loss: 1.1319217681884766
Validation loss: 1.7658771032928138

Epoch: 6| Step: 4
Training loss: 1.777979850769043
Validation loss: 1.7239345658210017

Epoch: 6| Step: 5
Training loss: 0.7369385957717896
Validation loss: 1.6968281999711068

Epoch: 6| Step: 6
Training loss: 1.010590672492981
Validation loss: 1.8175754675301172

Epoch: 6| Step: 7
Training loss: 1.2728517055511475
Validation loss: 1.7913655888649724

Epoch: 6| Step: 8
Training loss: 0.8433288335800171
Validation loss: 1.7302843063108382

Epoch: 6| Step: 9
Training loss: 1.2121917009353638
Validation loss: 1.7471403652621853

Epoch: 6| Step: 10
Training loss: 0.7537474632263184
Validation loss: 1.7708553934610018

Epoch: 6| Step: 11
Training loss: 1.269850492477417
Validation loss: 1.7434836408143402

Epoch: 6| Step: 12
Training loss: 0.8012075424194336
Validation loss: 1.7725265077365342

Epoch: 6| Step: 13
Training loss: 0.736481785774231
Validation loss: 1.7879067544014222

Epoch: 593| Step: 0
Training loss: 1.148760199546814
Validation loss: 1.7138921009596957

Epoch: 6| Step: 1
Training loss: 1.2731599807739258
Validation loss: 1.7379822051653298

Epoch: 6| Step: 2
Training loss: 0.6892752647399902
Validation loss: 1.8164579394043132

Epoch: 6| Step: 3
Training loss: 1.1890912055969238
Validation loss: 1.8398424656160417

Epoch: 6| Step: 4
Training loss: 1.1967682838439941
Validation loss: 1.756498271419156

Epoch: 6| Step: 5
Training loss: 1.010343313217163
Validation loss: 1.7429146266752673

Epoch: 6| Step: 6
Training loss: 1.907173752784729
Validation loss: 1.7778358613291094

Epoch: 6| Step: 7
Training loss: 0.9594727754592896
Validation loss: 1.8190735898992068

Epoch: 6| Step: 8
Training loss: 0.5754814147949219
Validation loss: 1.8145782524539578

Epoch: 6| Step: 9
Training loss: 0.6795012950897217
Validation loss: 1.7807919261276082

Epoch: 6| Step: 10
Training loss: 0.9488133192062378
Validation loss: 1.7916948808136808

Epoch: 6| Step: 11
Training loss: 1.0358471870422363
Validation loss: 1.7731602627743956

Epoch: 6| Step: 12
Training loss: 0.5057068467140198
Validation loss: 1.7410867419294132

Epoch: 6| Step: 13
Training loss: 0.4497835338115692
Validation loss: 1.7914892934983777

Epoch: 594| Step: 0
Training loss: 0.5880160331726074
Validation loss: 1.7791633067592498

Epoch: 6| Step: 1
Training loss: 0.7988694906234741
Validation loss: 1.7812062732635006

Epoch: 6| Step: 2
Training loss: 1.7461143732070923
Validation loss: 1.7684549336792321

Epoch: 6| Step: 3
Training loss: 0.8541820645332336
Validation loss: 1.7142593758080595

Epoch: 6| Step: 4
Training loss: 0.81743985414505
Validation loss: 1.763349752272329

Epoch: 6| Step: 5
Training loss: 0.9483871459960938
Validation loss: 1.7210728506888113

Epoch: 6| Step: 6
Training loss: 1.1763274669647217
Validation loss: 1.7472083568572998

Epoch: 6| Step: 7
Training loss: 0.5267431735992432
Validation loss: 1.7600955129951559

Epoch: 6| Step: 8
Training loss: 0.3977620601654053
Validation loss: 1.7152885852321502

Epoch: 6| Step: 9
Training loss: 1.1730645895004272
Validation loss: 1.7604259829367361

Epoch: 6| Step: 10
Training loss: 0.8269748687744141
Validation loss: 1.7924940906545168

Epoch: 6| Step: 11
Training loss: 0.6136094331741333
Validation loss: 1.7571755942477976

Epoch: 6| Step: 12
Training loss: 1.6504689455032349
Validation loss: 1.696443591066586

Epoch: 6| Step: 13
Training loss: 1.6036691665649414
Validation loss: 1.7676086284781014

Epoch: 595| Step: 0
Training loss: 0.7027373313903809
Validation loss: 1.832276286617402

Epoch: 6| Step: 1
Training loss: 0.6978912353515625
Validation loss: 1.7670306672332108

Epoch: 6| Step: 2
Training loss: 1.0036845207214355
Validation loss: 1.7480112570588306

Epoch: 6| Step: 3
Training loss: 1.1229667663574219
Validation loss: 1.743649495545254

Epoch: 6| Step: 4
Training loss: 0.8694008588790894
Validation loss: 1.7729654491588633

Epoch: 6| Step: 5
Training loss: 0.9446478486061096
Validation loss: 1.7702963736749464

Epoch: 6| Step: 6
Training loss: 0.8686660528182983
Validation loss: 1.7379609589935632

Epoch: 6| Step: 7
Training loss: 0.8832441568374634
Validation loss: 1.776176352654734

Epoch: 6| Step: 8
Training loss: 0.9334431290626526
Validation loss: 1.7726029324275192

Epoch: 6| Step: 9
Training loss: 0.776978611946106
Validation loss: 1.8052290819024528

Epoch: 6| Step: 10
Training loss: 1.240570306777954
Validation loss: 1.774685686634433

Epoch: 6| Step: 11
Training loss: 1.1716034412384033
Validation loss: 1.7723037248016686

Epoch: 6| Step: 12
Training loss: 1.141404151916504
Validation loss: 1.7986342573678622

Epoch: 6| Step: 13
Training loss: 0.5978841185569763
Validation loss: 1.790019122503137

Epoch: 596| Step: 0
Training loss: 1.1642076969146729
Validation loss: 1.7545311027957546

Epoch: 6| Step: 1
Training loss: 1.3056700229644775
Validation loss: 1.7826631338365617

Epoch: 6| Step: 2
Training loss: 0.3186061978340149
Validation loss: 1.8501281763917656

Epoch: 6| Step: 3
Training loss: 0.9731900691986084
Validation loss: 1.7222294243433143

Epoch: 6| Step: 4
Training loss: 0.9762499928474426
Validation loss: 1.7567861233988116

Epoch: 6| Step: 5
Training loss: 1.3094978332519531
Validation loss: 1.7572974915145545

Epoch: 6| Step: 6
Training loss: 1.083322525024414
Validation loss: 1.7726098875845633

Epoch: 6| Step: 7
Training loss: 0.9726672172546387
Validation loss: 1.7334956815165858

Epoch: 6| Step: 8
Training loss: 0.8107380867004395
Validation loss: 1.7421298565403107

Epoch: 6| Step: 9
Training loss: 1.1824826002120972
Validation loss: 1.7226339206900647

Epoch: 6| Step: 10
Training loss: 0.8776477575302124
Validation loss: 1.7504758463110974

Epoch: 6| Step: 11
Training loss: 1.0459263324737549
Validation loss: 1.7753679560076805

Epoch: 6| Step: 12
Training loss: 0.8603053092956543
Validation loss: 1.731841342423552

Epoch: 6| Step: 13
Training loss: 0.8222344517707825
Validation loss: 1.8028033741058842

Epoch: 597| Step: 0
Training loss: 1.043359637260437
Validation loss: 1.8051955135919715

Epoch: 6| Step: 1
Training loss: 0.8878868222236633
Validation loss: 1.7072813959531887

Epoch: 6| Step: 2
Training loss: 0.8264814019203186
Validation loss: 1.7465779627523115

Epoch: 6| Step: 3
Training loss: 0.5259058475494385
Validation loss: 1.7331348952426706

Epoch: 6| Step: 4
Training loss: 1.4467966556549072
Validation loss: 1.7583451065965878

Epoch: 6| Step: 5
Training loss: 0.6272495985031128
Validation loss: 1.743927642863284

Epoch: 6| Step: 6
Training loss: 0.6649108529090881
Validation loss: 1.7090104369707004

Epoch: 6| Step: 7
Training loss: 0.9400637149810791
Validation loss: 1.7192730313988143

Epoch: 6| Step: 8
Training loss: 1.5801095962524414
Validation loss: 1.7403127147305397

Epoch: 6| Step: 9
Training loss: 1.1180241107940674
Validation loss: 1.7641201967834144

Epoch: 6| Step: 10
Training loss: 0.37103602290153503
Validation loss: 1.82974616301957

Epoch: 6| Step: 11
Training loss: 1.1176810264587402
Validation loss: 1.7359528964565647

Epoch: 6| Step: 12
Training loss: 1.0754179954528809
Validation loss: 1.7401403150250834

Epoch: 6| Step: 13
Training loss: 1.4072892665863037
Validation loss: 1.7768205237644974

Epoch: 598| Step: 0
Training loss: 0.6651716232299805
Validation loss: 1.7706661237183439

Epoch: 6| Step: 1
Training loss: 0.8780673146247864
Validation loss: 1.695112584739603

Epoch: 6| Step: 2
Training loss: 1.2562377452850342
Validation loss: 1.7547820268138763

Epoch: 6| Step: 3
Training loss: 0.9473192691802979
Validation loss: 1.7927089621943813

Epoch: 6| Step: 4
Training loss: 0.9648672342300415
Validation loss: 1.8133866889502412

Epoch: 6| Step: 5
Training loss: 0.6895975470542908
Validation loss: 1.7070585476454867

Epoch: 6| Step: 6
Training loss: 0.9715192317962646
Validation loss: 1.6663689638978691

Epoch: 6| Step: 7
Training loss: 1.0592005252838135
Validation loss: 1.738999746179068

Epoch: 6| Step: 8
Training loss: 0.8234255909919739
Validation loss: 1.7215543844366585

Epoch: 6| Step: 9
Training loss: 1.447029709815979
Validation loss: 1.7274092615291636

Epoch: 6| Step: 10
Training loss: 1.3560709953308105
Validation loss: 1.810294210269887

Epoch: 6| Step: 11
Training loss: 0.7204914093017578
Validation loss: 1.7518106404171194

Epoch: 6| Step: 12
Training loss: 0.9270431995391846
Validation loss: 1.7362202534111597

Epoch: 6| Step: 13
Training loss: 1.0109715461730957
Validation loss: 1.779179742259364

Epoch: 599| Step: 0
Training loss: 1.0355305671691895
Validation loss: 1.8593531782909105

Epoch: 6| Step: 1
Training loss: 0.565625011920929
Validation loss: 1.780998182553117

Epoch: 6| Step: 2
Training loss: 1.2478665113449097
Validation loss: 1.7332409915103708

Epoch: 6| Step: 3
Training loss: 1.7262144088745117
Validation loss: 1.744727151368254

Epoch: 6| Step: 4
Training loss: 0.5071417689323425
Validation loss: 1.7659760213667346

Epoch: 6| Step: 5
Training loss: 0.8565724492073059
Validation loss: 1.7756149115100983

Epoch: 6| Step: 6
Training loss: 0.9918766021728516
Validation loss: 1.814954121907552

Epoch: 6| Step: 7
Training loss: 1.5489416122436523
Validation loss: 1.7962473054086008

Epoch: 6| Step: 8
Training loss: 0.826145589351654
Validation loss: 1.806875100699804

Epoch: 6| Step: 9
Training loss: 0.8912627100944519
Validation loss: 1.7711395743072673

Epoch: 6| Step: 10
Training loss: 0.724443793296814
Validation loss: 1.791777685124387

Epoch: 6| Step: 11
Training loss: 0.9897477030754089
Validation loss: 1.739226936012186

Epoch: 6| Step: 12
Training loss: 0.592551589012146
Validation loss: 1.7513608881222305

Epoch: 6| Step: 13
Training loss: 0.5617956519126892
Validation loss: 1.704366773687383

Epoch: 600| Step: 0
Training loss: 0.7958565950393677
Validation loss: 1.7431610540677143

Epoch: 6| Step: 1
Training loss: 0.9881702661514282
Validation loss: 1.7513898367522864

Epoch: 6| Step: 2
Training loss: 0.9825438261032104
Validation loss: 1.7221924489544285

Epoch: 6| Step: 3
Training loss: 0.881924569606781
Validation loss: 1.6790790916771017

Epoch: 6| Step: 4
Training loss: 1.041951298713684
Validation loss: 1.7534774439309233

Epoch: 6| Step: 5
Training loss: 0.9020554423332214
Validation loss: 1.6880948255139012

Epoch: 6| Step: 6
Training loss: 1.050297737121582
Validation loss: 1.7671930456674227

Epoch: 6| Step: 7
Training loss: 0.6771285533905029
Validation loss: 1.7142002069821922

Epoch: 6| Step: 8
Training loss: 0.9948163628578186
Validation loss: 1.7598992214407971

Epoch: 6| Step: 9
Training loss: 0.9245323538780212
Validation loss: 1.7442010077097083

Epoch: 6| Step: 10
Training loss: 1.153524398803711
Validation loss: 1.7572741303392636

Epoch: 6| Step: 11
Training loss: 1.6083476543426514
Validation loss: 1.7644655268679383

Epoch: 6| Step: 12
Training loss: 0.9161444306373596
Validation loss: 1.7937429643446399

Epoch: 6| Step: 13
Training loss: 0.43512576818466187
Validation loss: 1.7795672826869513

Epoch: 601| Step: 0
Training loss: 1.04646635055542
Validation loss: 1.7879650297985281

Epoch: 6| Step: 1
Training loss: 1.0292302370071411
Validation loss: 1.7566530037951726

Epoch: 6| Step: 2
Training loss: 0.6908073425292969
Validation loss: 1.7381270880340247

Epoch: 6| Step: 3
Training loss: 0.8412837982177734
Validation loss: 1.8169881310514224

Epoch: 6| Step: 4
Training loss: 1.4946410655975342
Validation loss: 1.7614789201367287

Epoch: 6| Step: 5
Training loss: 0.6425427794456482
Validation loss: 1.6993943978381414

Epoch: 6| Step: 6
Training loss: 0.7103511095046997
Validation loss: 1.7582281097289054

Epoch: 6| Step: 7
Training loss: 0.9931665658950806
Validation loss: 1.7560046180602042

Epoch: 6| Step: 8
Training loss: 1.190873622894287
Validation loss: 1.7602732604549778

Epoch: 6| Step: 9
Training loss: 1.118809461593628
Validation loss: 1.707187101405154

Epoch: 6| Step: 10
Training loss: 0.9804027080535889
Validation loss: 1.7608626132370324

Epoch: 6| Step: 11
Training loss: 1.3947515487670898
Validation loss: 1.7547364875834475

Epoch: 6| Step: 12
Training loss: 1.145796298980713
Validation loss: 1.7643496580021356

Epoch: 6| Step: 13
Training loss: 0.6336275935173035
Validation loss: 1.7566487122607488

Epoch: 602| Step: 0
Training loss: 1.338524341583252
Validation loss: 1.703632717491478

Epoch: 6| Step: 1
Training loss: 1.461010217666626
Validation loss: 1.7688134037038332

Epoch: 6| Step: 2
Training loss: 0.9242396354675293
Validation loss: 1.7460028689394715

Epoch: 6| Step: 3
Training loss: 0.9668149352073669
Validation loss: 1.7938703439568962

Epoch: 6| Step: 4
Training loss: 0.8270400166511536
Validation loss: 1.6921068609401744

Epoch: 6| Step: 5
Training loss: 0.9785732626914978
Validation loss: 1.7308372515504078

Epoch: 6| Step: 6
Training loss: 0.6157974004745483
Validation loss: 1.7815262399693972

Epoch: 6| Step: 7
Training loss: 0.7529983520507812
Validation loss: 1.720543743461691

Epoch: 6| Step: 8
Training loss: 0.9052180051803589
Validation loss: 1.7498360308267737

Epoch: 6| Step: 9
Training loss: 0.5039217472076416
Validation loss: 1.7197416315796554

Epoch: 6| Step: 10
Training loss: 0.790802001953125
Validation loss: 1.6754148288439679

Epoch: 6| Step: 11
Training loss: 1.0873713493347168
Validation loss: 1.732769694379581

Epoch: 6| Step: 12
Training loss: 1.0141760110855103
Validation loss: 1.7518956302314677

Epoch: 6| Step: 13
Training loss: 1.5019290447235107
Validation loss: 1.7327293067850091

Epoch: 603| Step: 0
Training loss: 1.093839406967163
Validation loss: 1.7598392886500205

Epoch: 6| Step: 1
Training loss: 0.7389488220214844
Validation loss: 1.7631090071893507

Epoch: 6| Step: 2
Training loss: 1.3647196292877197
Validation loss: 1.714594207784181

Epoch: 6| Step: 3
Training loss: 1.0115505456924438
Validation loss: 1.7060313519611154

Epoch: 6| Step: 4
Training loss: 1.2816804647445679
Validation loss: 1.758483890564211

Epoch: 6| Step: 5
Training loss: 0.9968723058700562
Validation loss: 1.6860141702877578

Epoch: 6| Step: 6
Training loss: 1.4069623947143555
Validation loss: 1.796881833384114

Epoch: 6| Step: 7
Training loss: 0.5884233713150024
Validation loss: 1.7370999205497004

Epoch: 6| Step: 8
Training loss: 0.7313420176506042
Validation loss: 1.7918522409213486

Epoch: 6| Step: 9
Training loss: 0.7446534633636475
Validation loss: 1.8091576035304735

Epoch: 6| Step: 10
Training loss: 0.830791711807251
Validation loss: 1.7493363900851178

Epoch: 6| Step: 11
Training loss: 1.038157343864441
Validation loss: 1.7134750594374955

Epoch: 6| Step: 12
Training loss: 0.839073121547699
Validation loss: 1.7132946880914832

Epoch: 6| Step: 13
Training loss: 0.7529516816139221
Validation loss: 1.7594451148022887

Epoch: 604| Step: 0
Training loss: 0.547532320022583
Validation loss: 1.6867260086920954

Epoch: 6| Step: 1
Training loss: 0.763696551322937
Validation loss: 1.6940995044605707

Epoch: 6| Step: 2
Training loss: 1.5210871696472168
Validation loss: 1.7492803732554119

Epoch: 6| Step: 3
Training loss: 0.9939427375793457
Validation loss: 1.7536643628151185

Epoch: 6| Step: 4
Training loss: 0.561843991279602
Validation loss: 1.7530993851282264

Epoch: 6| Step: 5
Training loss: 1.4371451139450073
Validation loss: 1.7887220536508868

Epoch: 6| Step: 6
Training loss: 1.4449169635772705
Validation loss: 1.7281631833763533

Epoch: 6| Step: 7
Training loss: 0.6228264570236206
Validation loss: 1.7435955693644862

Epoch: 6| Step: 8
Training loss: 1.1257818937301636
Validation loss: 1.7717619756216645

Epoch: 6| Step: 9
Training loss: 0.867806613445282
Validation loss: 1.7803456565385223

Epoch: 6| Step: 10
Training loss: 0.7741991281509399
Validation loss: 1.7663146052309262

Epoch: 6| Step: 11
Training loss: 0.9661721587181091
Validation loss: 1.75456093588183

Epoch: 6| Step: 12
Training loss: 0.8840925693511963
Validation loss: 1.7460393777457617

Epoch: 6| Step: 13
Training loss: 1.2446961402893066
Validation loss: 1.6990002573177378

Epoch: 605| Step: 0
Training loss: 1.447685718536377
Validation loss: 1.7577746350278136

Epoch: 6| Step: 1
Training loss: 1.1025121212005615
Validation loss: 1.7221730742403256

Epoch: 6| Step: 2
Training loss: 0.8495336771011353
Validation loss: 1.7554206091870543

Epoch: 6| Step: 3
Training loss: 0.7016886472702026
Validation loss: 1.710743788749941

Epoch: 6| Step: 4
Training loss: 1.0422545671463013
Validation loss: 1.7881842377365276

Epoch: 6| Step: 5
Training loss: 1.0328844785690308
Validation loss: 1.8179359256580312

Epoch: 6| Step: 6
Training loss: 1.0325891971588135
Validation loss: 1.7255591897554294

Epoch: 6| Step: 7
Training loss: 1.1477997303009033
Validation loss: 1.7514659153517855

Epoch: 6| Step: 8
Training loss: 1.0821661949157715
Validation loss: 1.737283101645849

Epoch: 6| Step: 9
Training loss: 1.1092414855957031
Validation loss: 1.7094685787795691

Epoch: 6| Step: 10
Training loss: 1.0931038856506348
Validation loss: 1.7481264837326542

Epoch: 6| Step: 11
Training loss: 0.4421161413192749
Validation loss: 1.69524948827682

Epoch: 6| Step: 12
Training loss: 0.6942068934440613
Validation loss: 1.7168177340620308

Epoch: 6| Step: 13
Training loss: 0.6410098671913147
Validation loss: 1.7681281784529328

Epoch: 606| Step: 0
Training loss: 1.0195748805999756
Validation loss: 1.7854098696862497

Epoch: 6| Step: 1
Training loss: 1.1635925769805908
Validation loss: 1.809839387093821

Epoch: 6| Step: 2
Training loss: 0.711021900177002
Validation loss: 1.8177059388929797

Epoch: 6| Step: 3
Training loss: 0.7887659668922424
Validation loss: 1.90226835332891

Epoch: 6| Step: 4
Training loss: 1.5023739337921143
Validation loss: 1.78866954388157

Epoch: 6| Step: 5
Training loss: 1.003582239151001
Validation loss: 1.8882764013864661

Epoch: 6| Step: 6
Training loss: 0.7490702867507935
Validation loss: 1.8715252543008456

Epoch: 6| Step: 7
Training loss: 1.2962732315063477
Validation loss: 1.8340026281213249

Epoch: 6| Step: 8
Training loss: 1.1293278932571411
Validation loss: 1.8560885639600857

Epoch: 6| Step: 9
Training loss: 1.4455833435058594
Validation loss: 1.7692829383316862

Epoch: 6| Step: 10
Training loss: 0.6181387901306152
Validation loss: 1.775446279074556

Epoch: 6| Step: 11
Training loss: 0.5042140483856201
Validation loss: 1.7528828254310034

Epoch: 6| Step: 12
Training loss: 1.1572765111923218
Validation loss: 1.7679773197379163

Epoch: 6| Step: 13
Training loss: 0.5158833861351013
Validation loss: 1.7462997513432656

Epoch: 607| Step: 0
Training loss: 0.9329060316085815
Validation loss: 1.7172281152458602

Epoch: 6| Step: 1
Training loss: 1.2903156280517578
Validation loss: 1.7017991645361787

Epoch: 6| Step: 2
Training loss: 0.6126006245613098
Validation loss: 1.7693028270557363

Epoch: 6| Step: 3
Training loss: 0.7578150033950806
Validation loss: 1.7798556922584452

Epoch: 6| Step: 4
Training loss: 1.457785964012146
Validation loss: 1.7529219991417342

Epoch: 6| Step: 5
Training loss: 0.556160032749176
Validation loss: 1.7835388234866563

Epoch: 6| Step: 6
Training loss: 1.1810928583145142
Validation loss: 1.742042371021804

Epoch: 6| Step: 7
Training loss: 0.8644797801971436
Validation loss: 1.7752022089496735

Epoch: 6| Step: 8
Training loss: 0.8776220083236694
Validation loss: 1.7322751719464538

Epoch: 6| Step: 9
Training loss: 1.2920384407043457
Validation loss: 1.7353963262291365

Epoch: 6| Step: 10
Training loss: 1.0592260360717773
Validation loss: 1.767247643522037

Epoch: 6| Step: 11
Training loss: 0.7056848406791687
Validation loss: 1.7985995046554073

Epoch: 6| Step: 12
Training loss: 0.8285551071166992
Validation loss: 1.7508525899661485

Epoch: 6| Step: 13
Training loss: 1.0397167205810547
Validation loss: 1.7043360356361634

Epoch: 608| Step: 0
Training loss: 1.1474354267120361
Validation loss: 1.801724999181686

Epoch: 6| Step: 1
Training loss: 1.2990585565567017
Validation loss: 1.7801345753413376

Epoch: 6| Step: 2
Training loss: 0.9111916422843933
Validation loss: 1.8014448676058041

Epoch: 6| Step: 3
Training loss: 1.2886024713516235
Validation loss: 1.7479587254985687

Epoch: 6| Step: 4
Training loss: 0.5685124397277832
Validation loss: 1.8111521133812525

Epoch: 6| Step: 5
Training loss: 1.0025525093078613
Validation loss: 1.7112812149909236

Epoch: 6| Step: 6
Training loss: 1.296525478363037
Validation loss: 1.795969227308868

Epoch: 6| Step: 7
Training loss: 1.2960128784179688
Validation loss: 1.7559639523106236

Epoch: 6| Step: 8
Training loss: 0.7290643453598022
Validation loss: 1.7395005392771896

Epoch: 6| Step: 9
Training loss: 0.38031715154647827
Validation loss: 1.7533632657861198

Epoch: 6| Step: 10
Training loss: 1.0359208583831787
Validation loss: 1.7133498114924277

Epoch: 6| Step: 11
Training loss: 1.2317698001861572
Validation loss: 1.7236072453119422

Epoch: 6| Step: 12
Training loss: 0.5250272750854492
Validation loss: 1.728294482795141

Epoch: 6| Step: 13
Training loss: 0.8536538481712341
Validation loss: 1.7219021781798332

Epoch: 609| Step: 0
Training loss: 0.8202717304229736
Validation loss: 1.74990431211328

Epoch: 6| Step: 1
Training loss: 0.5765377283096313
Validation loss: 1.7941133783709617

Epoch: 6| Step: 2
Training loss: 0.5101903676986694
Validation loss: 1.7753735152623986

Epoch: 6| Step: 3
Training loss: 1.2300570011138916
Validation loss: 1.7693377746048795

Epoch: 6| Step: 4
Training loss: 0.9205496311187744
Validation loss: 1.7320866110504314

Epoch: 6| Step: 5
Training loss: 1.1217573881149292
Validation loss: 1.746102072859323

Epoch: 6| Step: 6
Training loss: 1.2680152654647827
Validation loss: 1.8197105494878625

Epoch: 6| Step: 7
Training loss: 1.4820815324783325
Validation loss: 1.823963633147619

Epoch: 6| Step: 8
Training loss: 0.8285086750984192
Validation loss: 1.8326973376735565

Epoch: 6| Step: 9
Training loss: 0.7471596002578735
Validation loss: 1.7990803641657676

Epoch: 6| Step: 10
Training loss: 1.483355164527893
Validation loss: 1.7126403047192482

Epoch: 6| Step: 11
Training loss: 0.6257533431053162
Validation loss: 1.7391781947946037

Epoch: 6| Step: 12
Training loss: 1.0990673303604126
Validation loss: 1.7367812049004339

Epoch: 6| Step: 13
Training loss: 0.5076239109039307
Validation loss: 1.6650161345799763

Epoch: 610| Step: 0
Training loss: 1.1812772750854492
Validation loss: 1.7162848377740512

Epoch: 6| Step: 1
Training loss: 0.8424807190895081
Validation loss: 1.764603748116442

Epoch: 6| Step: 2
Training loss: 1.4882779121398926
Validation loss: 1.7773554581467823

Epoch: 6| Step: 3
Training loss: 0.9271996021270752
Validation loss: 1.7362951591450682

Epoch: 6| Step: 4
Training loss: 0.6935283541679382
Validation loss: 1.7427569512398011

Epoch: 6| Step: 5
Training loss: 0.9266421794891357
Validation loss: 1.7524378453531573

Epoch: 6| Step: 6
Training loss: 0.8443392515182495
Validation loss: 1.7640740025428034

Epoch: 6| Step: 7
Training loss: 1.0149643421173096
Validation loss: 1.7013917815300725

Epoch: 6| Step: 8
Training loss: 0.9986156225204468
Validation loss: 1.7298809533478112

Epoch: 6| Step: 9
Training loss: 0.670455813407898
Validation loss: 1.7627280668545795

Epoch: 6| Step: 10
Training loss: 0.7643280625343323
Validation loss: 1.7014817550618162

Epoch: 6| Step: 11
Training loss: 0.9925587773323059
Validation loss: 1.8002881285964802

Epoch: 6| Step: 12
Training loss: 0.9461774230003357
Validation loss: 1.8057872890144266

Epoch: 6| Step: 13
Training loss: 1.7793023586273193
Validation loss: 1.777150320750411

Epoch: 611| Step: 0
Training loss: 1.6281869411468506
Validation loss: 1.756287900350427

Epoch: 6| Step: 1
Training loss: 0.7842347621917725
Validation loss: 1.7502936765711794

Epoch: 6| Step: 2
Training loss: 0.5769910216331482
Validation loss: 1.8233060324063866

Epoch: 6| Step: 3
Training loss: 0.7397507429122925
Validation loss: 1.7283520852365801

Epoch: 6| Step: 4
Training loss: 0.6995729207992554
Validation loss: 1.6872002367050416

Epoch: 6| Step: 5
Training loss: 1.5162999629974365
Validation loss: 1.6906771147122948

Epoch: 6| Step: 6
Training loss: 0.9761020541191101
Validation loss: 1.7047396872633247

Epoch: 6| Step: 7
Training loss: 1.1651906967163086
Validation loss: 1.7330429976986301

Epoch: 6| Step: 8
Training loss: 0.8607940673828125
Validation loss: 1.7462522624641337

Epoch: 6| Step: 9
Training loss: 0.6455249786376953
Validation loss: 1.7626998937258156

Epoch: 6| Step: 10
Training loss: 1.0344316959381104
Validation loss: 1.6730278602210424

Epoch: 6| Step: 11
Training loss: 0.9997172355651855
Validation loss: 1.7466817389252365

Epoch: 6| Step: 12
Training loss: 1.106374740600586
Validation loss: 1.7492750985648042

Epoch: 6| Step: 13
Training loss: 0.6859301924705505
Validation loss: 1.7256479096669022

Epoch: 612| Step: 0
Training loss: 0.7086626291275024
Validation loss: 1.7786028820981261

Epoch: 6| Step: 1
Training loss: 0.6275439262390137
Validation loss: 1.7228491921578684

Epoch: 6| Step: 2
Training loss: 1.1590111255645752
Validation loss: 1.7452665003397132

Epoch: 6| Step: 3
Training loss: 1.0091078281402588
Validation loss: 1.7478182649099698

Epoch: 6| Step: 4
Training loss: 0.7877072095870972
Validation loss: 1.7827810728421776

Epoch: 6| Step: 5
Training loss: 0.7414054870605469
Validation loss: 1.7998939432123655

Epoch: 6| Step: 6
Training loss: 1.1096006631851196
Validation loss: 1.7464075960138792

Epoch: 6| Step: 7
Training loss: 1.2459160089492798
Validation loss: 1.7620031436284382

Epoch: 6| Step: 8
Training loss: 0.5375998020172119
Validation loss: 1.69774261084936

Epoch: 6| Step: 9
Training loss: 1.0027010440826416
Validation loss: 1.8352267819066201

Epoch: 6| Step: 10
Training loss: 1.3571834564208984
Validation loss: 1.7320578252115557

Epoch: 6| Step: 11
Training loss: 1.1818432807922363
Validation loss: 1.7204824416868147

Epoch: 6| Step: 12
Training loss: 0.7628262042999268
Validation loss: 1.7418990929921467

Epoch: 6| Step: 13
Training loss: 1.0154370069503784
Validation loss: 1.7326115459524176

Epoch: 613| Step: 0
Training loss: 1.1194732189178467
Validation loss: 1.6828741796555058

Epoch: 6| Step: 1
Training loss: 0.7134361267089844
Validation loss: 1.7350726717261857

Epoch: 6| Step: 2
Training loss: 1.0998973846435547
Validation loss: 1.7237846889803488

Epoch: 6| Step: 3
Training loss: 0.8713080883026123
Validation loss: 1.7491162682092318

Epoch: 6| Step: 4
Training loss: 0.6248431205749512
Validation loss: 1.7513721271227765

Epoch: 6| Step: 5
Training loss: 1.1172038316726685
Validation loss: 1.7415773881378995

Epoch: 6| Step: 6
Training loss: 0.8348926901817322
Validation loss: 1.7365095666659776

Epoch: 6| Step: 7
Training loss: 1.1357972621917725
Validation loss: 1.7163448410649453

Epoch: 6| Step: 8
Training loss: 0.7978495359420776
Validation loss: 1.7872695051213747

Epoch: 6| Step: 9
Training loss: 1.3073084354400635
Validation loss: 1.8119574977505593

Epoch: 6| Step: 10
Training loss: 1.0959473848342896
Validation loss: 1.7505519377287997

Epoch: 6| Step: 11
Training loss: 0.592072606086731
Validation loss: 1.7659655745311449

Epoch: 6| Step: 12
Training loss: 0.8255816698074341
Validation loss: 1.7503723226567751

Epoch: 6| Step: 13
Training loss: 0.6449772715568542
Validation loss: 1.7910405051323675

Epoch: 614| Step: 0
Training loss: 0.6754370927810669
Validation loss: 1.7167896506606892

Epoch: 6| Step: 1
Training loss: 1.173307180404663
Validation loss: 1.7772141810386413

Epoch: 6| Step: 2
Training loss: 0.8980550765991211
Validation loss: 1.7657997185184109

Epoch: 6| Step: 3
Training loss: 1.028907060623169
Validation loss: 1.7098115131419191

Epoch: 6| Step: 4
Training loss: 0.5344657301902771
Validation loss: 1.7391166584466093

Epoch: 6| Step: 5
Training loss: 1.1110923290252686
Validation loss: 1.7349925771836312

Epoch: 6| Step: 6
Training loss: 0.8954975605010986
Validation loss: 1.7396195678300754

Epoch: 6| Step: 7
Training loss: 0.7196749448776245
Validation loss: 1.8148440878878358

Epoch: 6| Step: 8
Training loss: 0.8265690207481384
Validation loss: 1.7004056797232678

Epoch: 6| Step: 9
Training loss: 0.6976903080940247
Validation loss: 1.7963520352558424

Epoch: 6| Step: 10
Training loss: 1.545009732246399
Validation loss: 1.7930152634138703

Epoch: 6| Step: 11
Training loss: 1.104612112045288
Validation loss: 1.756070110105699

Epoch: 6| Step: 12
Training loss: 0.6700744032859802
Validation loss: 1.736748476182261

Epoch: 6| Step: 13
Training loss: 1.0911916494369507
Validation loss: 1.724392661484339

Epoch: 615| Step: 0
Training loss: 0.7328011989593506
Validation loss: 1.706429567388309

Epoch: 6| Step: 1
Training loss: 0.9099527597427368
Validation loss: 1.74334349683536

Epoch: 6| Step: 2
Training loss: 0.9451899528503418
Validation loss: 1.7841127264884211

Epoch: 6| Step: 3
Training loss: 1.1210272312164307
Validation loss: 1.8017023558257728

Epoch: 6| Step: 4
Training loss: 1.3537003993988037
Validation loss: 1.7145207697345364

Epoch: 6| Step: 5
Training loss: 0.7463561296463013
Validation loss: 1.7442384958267212

Epoch: 6| Step: 6
Training loss: 0.5379928946495056
Validation loss: 1.7731237911408948

Epoch: 6| Step: 7
Training loss: 0.933707058429718
Validation loss: 1.739842640456333

Epoch: 6| Step: 8
Training loss: 1.4037353992462158
Validation loss: 1.7869772987980996

Epoch: 6| Step: 9
Training loss: 1.5504004955291748
Validation loss: 1.7711738078824935

Epoch: 6| Step: 10
Training loss: 0.47240328788757324
Validation loss: 1.7572453688549738

Epoch: 6| Step: 11
Training loss: 1.0864152908325195
Validation loss: 1.754600804339173

Epoch: 6| Step: 12
Training loss: 1.0087056159973145
Validation loss: 1.734256734130203

Epoch: 6| Step: 13
Training loss: 1.007066249847412
Validation loss: 1.7613071972324001

Epoch: 616| Step: 0
Training loss: 1.2709391117095947
Validation loss: 1.7434379772473407

Epoch: 6| Step: 1
Training loss: 1.2601661682128906
Validation loss: 1.7069173064283145

Epoch: 6| Step: 2
Training loss: 1.2260125875473022
Validation loss: 1.734998187711162

Epoch: 6| Step: 3
Training loss: 0.721417248249054
Validation loss: 1.731017651096467

Epoch: 6| Step: 4
Training loss: 0.9382399320602417
Validation loss: 1.8019935597655594

Epoch: 6| Step: 5
Training loss: 1.2766633033752441
Validation loss: 1.7425247943529518

Epoch: 6| Step: 6
Training loss: 0.5867732763290405
Validation loss: 1.7611136833826702

Epoch: 6| Step: 7
Training loss: 0.6393777132034302
Validation loss: 1.7497127222758468

Epoch: 6| Step: 8
Training loss: 0.8188002109527588
Validation loss: 1.6761970443110312

Epoch: 6| Step: 9
Training loss: 0.4767569899559021
Validation loss: 1.8035687349175895

Epoch: 6| Step: 10
Training loss: 0.8269191980361938
Validation loss: 1.772445619747203

Epoch: 6| Step: 11
Training loss: 1.2122586965560913
Validation loss: 1.753560725078788

Epoch: 6| Step: 12
Training loss: 1.13558030128479
Validation loss: 1.786254805903281

Epoch: 6| Step: 13
Training loss: 0.9923229217529297
Validation loss: 1.816667611880969

Epoch: 617| Step: 0
Training loss: 0.5133363008499146
Validation loss: 1.7614476450027958

Epoch: 6| Step: 1
Training loss: 1.0290035009384155
Validation loss: 1.7141647902868127

Epoch: 6| Step: 2
Training loss: 0.7830634117126465
Validation loss: 1.7575136077019475

Epoch: 6| Step: 3
Training loss: 1.1585273742675781
Validation loss: 1.7486118680687361

Epoch: 6| Step: 4
Training loss: 0.5805666446685791
Validation loss: 1.7849928896914247

Epoch: 6| Step: 5
Training loss: 1.291853427886963
Validation loss: 1.750051203594413

Epoch: 6| Step: 6
Training loss: 0.8898272514343262
Validation loss: 1.7600648941532258

Epoch: 6| Step: 7
Training loss: 0.8907385468482971
Validation loss: 1.8064533933516471

Epoch: 6| Step: 8
Training loss: 0.8031406402587891
Validation loss: 1.7557530069863925

Epoch: 6| Step: 9
Training loss: 1.1154906749725342
Validation loss: 1.7568893022434686

Epoch: 6| Step: 10
Training loss: 1.035942554473877
Validation loss: 1.7802926942866335

Epoch: 6| Step: 11
Training loss: 1.407308578491211
Validation loss: 1.7176547204294512

Epoch: 6| Step: 12
Training loss: 0.4831531047821045
Validation loss: 1.7257162358171196

Epoch: 6| Step: 13
Training loss: 1.0758557319641113
Validation loss: 1.735255213193996

Epoch: 618| Step: 0
Training loss: 0.7957796454429626
Validation loss: 1.7731578170612294

Epoch: 6| Step: 1
Training loss: 0.8023996353149414
Validation loss: 1.7767802284609886

Epoch: 6| Step: 2
Training loss: 1.4056320190429688
Validation loss: 1.7964879325641099

Epoch: 6| Step: 3
Training loss: 0.8043059706687927
Validation loss: 1.7802697817484539

Epoch: 6| Step: 4
Training loss: 0.6798050403594971
Validation loss: 1.7824019206467496

Epoch: 6| Step: 5
Training loss: 0.8550645112991333
Validation loss: 1.7467524889976747

Epoch: 6| Step: 6
Training loss: 1.1085155010223389
Validation loss: 1.8033850103296258

Epoch: 6| Step: 7
Training loss: 1.1136844158172607
Validation loss: 1.765710715324648

Epoch: 6| Step: 8
Training loss: 0.8687395453453064
Validation loss: 1.746622121462258

Epoch: 6| Step: 9
Training loss: 0.5911740064620972
Validation loss: 1.6599932037374026

Epoch: 6| Step: 10
Training loss: 0.7770252823829651
Validation loss: 1.7423449421441684

Epoch: 6| Step: 11
Training loss: 1.1213929653167725
Validation loss: 1.7614696256576046

Epoch: 6| Step: 12
Training loss: 1.2514724731445312
Validation loss: 1.7545469589130853

Epoch: 6| Step: 13
Training loss: 0.7265373468399048
Validation loss: 1.7073506161730776

Epoch: 619| Step: 0
Training loss: 1.131101131439209
Validation loss: 1.7317046324412029

Epoch: 6| Step: 1
Training loss: 0.9390506744384766
Validation loss: 1.7387982901706491

Epoch: 6| Step: 2
Training loss: 1.0287877321243286
Validation loss: 1.7286333537870837

Epoch: 6| Step: 3
Training loss: 1.0313043594360352
Validation loss: 1.7284153994693552

Epoch: 6| Step: 4
Training loss: 1.0212105512619019
Validation loss: 1.7398478882287138

Epoch: 6| Step: 5
Training loss: 0.5912876129150391
Validation loss: 1.7189211307033416

Epoch: 6| Step: 6
Training loss: 0.7249319553375244
Validation loss: 1.6917624050571072

Epoch: 6| Step: 7
Training loss: 1.0372421741485596
Validation loss: 1.7631408373514812

Epoch: 6| Step: 8
Training loss: 0.5130326747894287
Validation loss: 1.7396677104375695

Epoch: 6| Step: 9
Training loss: 0.8520677089691162
Validation loss: 1.746893068795563

Epoch: 6| Step: 10
Training loss: 0.8687726259231567
Validation loss: 1.8040824756827405

Epoch: 6| Step: 11
Training loss: 1.248734474182129
Validation loss: 1.75809435946967

Epoch: 6| Step: 12
Training loss: 1.0008535385131836
Validation loss: 1.8472953714350218

Epoch: 6| Step: 13
Training loss: 1.7642244100570679
Validation loss: 1.8132924597750428

Epoch: 620| Step: 0
Training loss: 1.1582473516464233
Validation loss: 1.7793938062524284

Epoch: 6| Step: 1
Training loss: 0.9457465410232544
Validation loss: 1.7878454962084371

Epoch: 6| Step: 2
Training loss: 0.8665574193000793
Validation loss: 1.7311899341562742

Epoch: 6| Step: 3
Training loss: 1.0458369255065918
Validation loss: 1.7295234408429874

Epoch: 6| Step: 4
Training loss: 1.2888624668121338
Validation loss: 1.7393745260853921

Epoch: 6| Step: 5
Training loss: 1.2678163051605225
Validation loss: 1.7001448369795276

Epoch: 6| Step: 6
Training loss: 0.7949137091636658
Validation loss: 1.7943416872332174

Epoch: 6| Step: 7
Training loss: 0.8684157133102417
Validation loss: 1.7367884894852996

Epoch: 6| Step: 8
Training loss: 0.7020671367645264
Validation loss: 1.766797693826819

Epoch: 6| Step: 9
Training loss: 1.2466661930084229
Validation loss: 1.7856036565637077

Epoch: 6| Step: 10
Training loss: 0.667427659034729
Validation loss: 1.736692564461821

Epoch: 6| Step: 11
Training loss: 0.6657586693763733
Validation loss: 1.6954500675201416

Epoch: 6| Step: 12
Training loss: 0.8449079990386963
Validation loss: 1.7360719275730911

Epoch: 6| Step: 13
Training loss: 0.8725720047950745
Validation loss: 1.7971826637944868

Epoch: 621| Step: 0
Training loss: 0.9282958507537842
Validation loss: 1.6778221130371094

Epoch: 6| Step: 1
Training loss: 0.8541920185089111
Validation loss: 1.7435585068118187

Epoch: 6| Step: 2
Training loss: 0.9223286509513855
Validation loss: 1.7651259501775105

Epoch: 6| Step: 3
Training loss: 1.3713890314102173
Validation loss: 1.7342359276228054

Epoch: 6| Step: 4
Training loss: 0.9998757839202881
Validation loss: 1.7785332433639034

Epoch: 6| Step: 5
Training loss: 0.8481135368347168
Validation loss: 1.75354859136766

Epoch: 6| Step: 6
Training loss: 1.07130765914917
Validation loss: 1.731524593086653

Epoch: 6| Step: 7
Training loss: 0.8458417057991028
Validation loss: 1.7045783970945625

Epoch: 6| Step: 8
Training loss: 1.03560471534729
Validation loss: 1.7391141768424743

Epoch: 6| Step: 9
Training loss: 0.7640430927276611
Validation loss: 1.7095127259531329

Epoch: 6| Step: 10
Training loss: 1.0005569458007812
Validation loss: 1.7177916034575431

Epoch: 6| Step: 11
Training loss: 0.6637212038040161
Validation loss: 1.7409603698279268

Epoch: 6| Step: 12
Training loss: 0.7267481088638306
Validation loss: 1.7869008177070207

Epoch: 6| Step: 13
Training loss: 0.40590429306030273
Validation loss: 1.7807880191392795

Epoch: 622| Step: 0
Training loss: 0.9343448281288147
Validation loss: 1.7529147196841497

Epoch: 6| Step: 1
Training loss: 0.653874397277832
Validation loss: 1.753088967774504

Epoch: 6| Step: 2
Training loss: 1.1494903564453125
Validation loss: 1.7540143574437788

Epoch: 6| Step: 3
Training loss: 1.0113263130187988
Validation loss: 1.7635932019961778

Epoch: 6| Step: 4
Training loss: 1.2459636926651
Validation loss: 1.738058978511441

Epoch: 6| Step: 5
Training loss: 0.812992513179779
Validation loss: 1.7922563616947462

Epoch: 6| Step: 6
Training loss: 0.9095973968505859
Validation loss: 1.7878125534262708

Epoch: 6| Step: 7
Training loss: 0.693483829498291
Validation loss: 1.7620273482414983

Epoch: 6| Step: 8
Training loss: 0.44227758049964905
Validation loss: 1.7480809252749208

Epoch: 6| Step: 9
Training loss: 1.3815889358520508
Validation loss: 1.771232255043522

Epoch: 6| Step: 10
Training loss: 0.7718316912651062
Validation loss: 1.7596725058811966

Epoch: 6| Step: 11
Training loss: 0.3764192759990692
Validation loss: 1.747726785239353

Epoch: 6| Step: 12
Training loss: 0.7800713777542114
Validation loss: 1.7912556971273115

Epoch: 6| Step: 13
Training loss: 2.564296007156372
Validation loss: 1.8327640436028922

Epoch: 623| Step: 0
Training loss: 0.6982607245445251
Validation loss: 1.7416509748787008

Epoch: 6| Step: 1
Training loss: 0.8840373754501343
Validation loss: 1.7891353637941423

Epoch: 6| Step: 2
Training loss: 0.8513595461845398
Validation loss: 1.664828214594113

Epoch: 6| Step: 3
Training loss: 0.8203519582748413
Validation loss: 1.7328143004448182

Epoch: 6| Step: 4
Training loss: 0.5323927402496338
Validation loss: 1.730549648884804

Epoch: 6| Step: 5
Training loss: 0.8122470378875732
Validation loss: 1.7886702578554872

Epoch: 6| Step: 6
Training loss: 0.9135797023773193
Validation loss: 1.7615001701539563

Epoch: 6| Step: 7
Training loss: 0.9231380224227905
Validation loss: 1.7737573539057085

Epoch: 6| Step: 8
Training loss: 1.745483636856079
Validation loss: 1.7442076154934463

Epoch: 6| Step: 9
Training loss: 1.0971786975860596
Validation loss: 1.723931686852568

Epoch: 6| Step: 10
Training loss: 1.1448395252227783
Validation loss: 1.704307758679954

Epoch: 6| Step: 11
Training loss: 0.9959495067596436
Validation loss: 1.8073070562014015

Epoch: 6| Step: 12
Training loss: 0.9400050044059753
Validation loss: 1.789120312659971

Epoch: 6| Step: 13
Training loss: 0.8868972659111023
Validation loss: 1.718766063772222

Epoch: 624| Step: 0
Training loss: 0.9670224189758301
Validation loss: 1.7495998131331576

Epoch: 6| Step: 1
Training loss: 0.6455023288726807
Validation loss: 1.7014814628067838

Epoch: 6| Step: 2
Training loss: 1.0233163833618164
Validation loss: 1.6848179960763583

Epoch: 6| Step: 3
Training loss: 0.912203311920166
Validation loss: 1.7701415259351012

Epoch: 6| Step: 4
Training loss: 0.9721088409423828
Validation loss: 1.772548311500139

Epoch: 6| Step: 5
Training loss: 1.02012038230896
Validation loss: 1.7082521761617353

Epoch: 6| Step: 6
Training loss: 1.1169925928115845
Validation loss: 1.7343582414811658

Epoch: 6| Step: 7
Training loss: 0.6405735015869141
Validation loss: 1.7870686643867082

Epoch: 6| Step: 8
Training loss: 0.7063897252082825
Validation loss: 1.7686490166571833

Epoch: 6| Step: 9
Training loss: 0.7536945343017578
Validation loss: 1.73208039294007

Epoch: 6| Step: 10
Training loss: 0.9418269395828247
Validation loss: 1.7413839383791851

Epoch: 6| Step: 11
Training loss: 1.7295689582824707
Validation loss: 1.772089627481276

Epoch: 6| Step: 12
Training loss: 0.8329134583473206
Validation loss: 1.7729105628946775

Epoch: 6| Step: 13
Training loss: 0.8359636068344116
Validation loss: 1.7348958651224773

Epoch: 625| Step: 0
Training loss: 0.6841689348220825
Validation loss: 1.71576125391068

Epoch: 6| Step: 1
Training loss: 0.6352077126502991
Validation loss: 1.8123467404355285

Epoch: 6| Step: 2
Training loss: 0.5839020013809204
Validation loss: 1.7687304276292042

Epoch: 6| Step: 3
Training loss: 1.429499626159668
Validation loss: 1.8077224057207826

Epoch: 6| Step: 4
Training loss: 0.9946123361587524
Validation loss: 1.7454566955566406

Epoch: 6| Step: 5
Training loss: 0.881920576095581
Validation loss: 1.7471050203487437

Epoch: 6| Step: 6
Training loss: 1.425957202911377
Validation loss: 1.746596404301223

Epoch: 6| Step: 7
Training loss: 0.9814612865447998
Validation loss: 1.7610583292540682

Epoch: 6| Step: 8
Training loss: 1.6985280513763428
Validation loss: 1.7422227346768944

Epoch: 6| Step: 9
Training loss: 0.8630179166793823
Validation loss: 1.7267843510514946

Epoch: 6| Step: 10
Training loss: 0.5288910865783691
Validation loss: 1.751459534450244

Epoch: 6| Step: 11
Training loss: 0.8570965528488159
Validation loss: 1.760243720905755

Epoch: 6| Step: 12
Training loss: 0.6341765522956848
Validation loss: 1.7335550092881726

Epoch: 6| Step: 13
Training loss: 0.7042467594146729
Validation loss: 1.792532765737144

Epoch: 626| Step: 0
Training loss: 0.844336986541748
Validation loss: 1.6905941604286112

Epoch: 6| Step: 1
Training loss: 1.0838208198547363
Validation loss: 1.7169110403266004

Epoch: 6| Step: 2
Training loss: 0.8530880808830261
Validation loss: 1.7738286987427743

Epoch: 6| Step: 3
Training loss: 0.9028375148773193
Validation loss: 1.7421379666174612

Epoch: 6| Step: 4
Training loss: 0.832302451133728
Validation loss: 1.764393501384284

Epoch: 6| Step: 5
Training loss: 0.6409130096435547
Validation loss: 1.7167254045445433

Epoch: 6| Step: 6
Training loss: 1.2657877206802368
Validation loss: 1.6725551466788016

Epoch: 6| Step: 7
Training loss: 0.9722800254821777
Validation loss: 1.7321043283708635

Epoch: 6| Step: 8
Training loss: 0.7987948656082153
Validation loss: 1.7548689380768807

Epoch: 6| Step: 9
Training loss: 1.2099943161010742
Validation loss: 1.7810258711538007

Epoch: 6| Step: 10
Training loss: 1.045468807220459
Validation loss: 1.7721125336103543

Epoch: 6| Step: 11
Training loss: 1.048862338066101
Validation loss: 1.775204994345224

Epoch: 6| Step: 12
Training loss: 0.7596889734268188
Validation loss: 1.7973896957212878

Epoch: 6| Step: 13
Training loss: 1.3137412071228027
Validation loss: 1.8316259666155743

Epoch: 627| Step: 0
Training loss: 0.902307391166687
Validation loss: 1.7370527880166167

Epoch: 6| Step: 1
Training loss: 1.034509301185608
Validation loss: 1.7795095110452304

Epoch: 6| Step: 2
Training loss: 0.766813337802887
Validation loss: 1.7476695250439387

Epoch: 6| Step: 3
Training loss: 0.6908147931098938
Validation loss: 1.8130790469467

Epoch: 6| Step: 4
Training loss: 0.8841665983200073
Validation loss: 1.7511399240903958

Epoch: 6| Step: 5
Training loss: 0.8837628364562988
Validation loss: 1.7326656310789046

Epoch: 6| Step: 6
Training loss: 0.9992777109146118
Validation loss: 1.7577343269061017

Epoch: 6| Step: 7
Training loss: 0.8252599835395813
Validation loss: 1.7487189641562841

Epoch: 6| Step: 8
Training loss: 0.8124704360961914
Validation loss: 1.6940820191496162

Epoch: 6| Step: 9
Training loss: 1.175072431564331
Validation loss: 1.710888962591848

Epoch: 6| Step: 10
Training loss: 0.7961187958717346
Validation loss: 1.6797047533014768

Epoch: 6| Step: 11
Training loss: 1.5532591342926025
Validation loss: 1.7867300830861574

Epoch: 6| Step: 12
Training loss: 0.8234055042266846
Validation loss: 1.7467071317857312

Epoch: 6| Step: 13
Training loss: 1.352947473526001
Validation loss: 1.694036602973938

Epoch: 628| Step: 0
Training loss: 1.0834041833877563
Validation loss: 1.6842274858105568

Epoch: 6| Step: 1
Training loss: 0.6121899485588074
Validation loss: 1.7525665067857312

Epoch: 6| Step: 2
Training loss: 0.5541104078292847
Validation loss: 1.7339836987116004

Epoch: 6| Step: 3
Training loss: 1.150050163269043
Validation loss: 1.7435795107195455

Epoch: 6| Step: 4
Training loss: 1.2451810836791992
Validation loss: 1.7735415607370355

Epoch: 6| Step: 5
Training loss: 1.1646708250045776
Validation loss: 1.7349833442318825

Epoch: 6| Step: 6
Training loss: 1.0539305210113525
Validation loss: 1.7645133810658609

Epoch: 6| Step: 7
Training loss: 0.7889584302902222
Validation loss: 1.792140148019278

Epoch: 6| Step: 8
Training loss: 1.0959677696228027
Validation loss: 1.730946627996301

Epoch: 6| Step: 9
Training loss: 0.5575161576271057
Validation loss: 1.7478577847121863

Epoch: 6| Step: 10
Training loss: 1.0926796197891235
Validation loss: 1.772672414779663

Epoch: 6| Step: 11
Training loss: 1.0441291332244873
Validation loss: 1.717057663907287

Epoch: 6| Step: 12
Training loss: 0.5637099146842957
Validation loss: 1.7531158693375126

Epoch: 6| Step: 13
Training loss: 1.0207387208938599
Validation loss: 1.7074147885845554

Epoch: 629| Step: 0
Training loss: 0.8533278107643127
Validation loss: 1.7549265917911325

Epoch: 6| Step: 1
Training loss: 0.8871053457260132
Validation loss: 1.7818272447073331

Epoch: 6| Step: 2
Training loss: 1.0280929803848267
Validation loss: 1.8531092084864134

Epoch: 6| Step: 3
Training loss: 0.7841865420341492
Validation loss: 1.736072181373514

Epoch: 6| Step: 4
Training loss: 0.6722118854522705
Validation loss: 1.774113662781254

Epoch: 6| Step: 5
Training loss: 0.905707061290741
Validation loss: 1.7605366681211738

Epoch: 6| Step: 6
Training loss: 1.2378754615783691
Validation loss: 1.7971764559386878

Epoch: 6| Step: 7
Training loss: 1.3308727741241455
Validation loss: 1.7593264349045292

Epoch: 6| Step: 8
Training loss: 0.8575695157051086
Validation loss: 1.729290699446073

Epoch: 6| Step: 9
Training loss: 0.6652957797050476
Validation loss: 1.768728179316367

Epoch: 6| Step: 10
Training loss: 0.8106308579444885
Validation loss: 1.754866382127167

Epoch: 6| Step: 11
Training loss: 0.887993574142456
Validation loss: 1.8056579110442952

Epoch: 6| Step: 12
Training loss: 0.9165382385253906
Validation loss: 1.747118096197805

Epoch: 6| Step: 13
Training loss: 1.3446913957595825
Validation loss: 1.835274515613433

Epoch: 630| Step: 0
Training loss: 0.3247513473033905
Validation loss: 1.7108975764243834

Epoch: 6| Step: 1
Training loss: 0.7055737376213074
Validation loss: 1.6910112852691321

Epoch: 6| Step: 2
Training loss: 1.0946216583251953
Validation loss: 1.7278516895027571

Epoch: 6| Step: 3
Training loss: 1.025564432144165
Validation loss: 1.7721537159335228

Epoch: 6| Step: 4
Training loss: 0.6388260126113892
Validation loss: 1.7594514123855098

Epoch: 6| Step: 5
Training loss: 1.0961627960205078
Validation loss: 1.7350355130369945

Epoch: 6| Step: 6
Training loss: 1.3551498651504517
Validation loss: 1.7465429229121054

Epoch: 6| Step: 7
Training loss: 0.9702303409576416
Validation loss: 1.8383647754628172

Epoch: 6| Step: 8
Training loss: 1.0556113719940186
Validation loss: 1.7594183362940305

Epoch: 6| Step: 9
Training loss: 0.932741641998291
Validation loss: 1.7627211257975588

Epoch: 6| Step: 10
Training loss: 0.8025208115577698
Validation loss: 1.7886668943589734

Epoch: 6| Step: 11
Training loss: 1.1417510509490967
Validation loss: 1.783987670816401

Epoch: 6| Step: 12
Training loss: 1.0030136108398438
Validation loss: 1.8005921007484518

Epoch: 6| Step: 13
Training loss: 0.8144744634628296
Validation loss: 1.717191978167462

Epoch: 631| Step: 0
Training loss: 1.0646620988845825
Validation loss: 1.6966047607442385

Epoch: 6| Step: 1
Training loss: 1.2762664556503296
Validation loss: 1.7597489869722756

Epoch: 6| Step: 2
Training loss: 0.8907120823860168
Validation loss: 1.658069295267905

Epoch: 6| Step: 3
Training loss: 1.177628517150879
Validation loss: 1.7012977548824844

Epoch: 6| Step: 4
Training loss: 1.0825326442718506
Validation loss: 1.7066258512517458

Epoch: 6| Step: 5
Training loss: 0.5570105910301208
Validation loss: 1.77785934171369

Epoch: 6| Step: 6
Training loss: 0.4772941470146179
Validation loss: 1.7731242128597793

Epoch: 6| Step: 7
Training loss: 0.8052331805229187
Validation loss: 1.7668273436125888

Epoch: 6| Step: 8
Training loss: 1.2876783609390259
Validation loss: 1.7587498618710427

Epoch: 6| Step: 9
Training loss: 0.7355791330337524
Validation loss: 1.6719398485716952

Epoch: 6| Step: 10
Training loss: 0.8019618391990662
Validation loss: 1.7296156485875447

Epoch: 6| Step: 11
Training loss: 1.089699387550354
Validation loss: 1.7671133895074167

Epoch: 6| Step: 12
Training loss: 0.8567267656326294
Validation loss: 1.7983315529361847

Epoch: 6| Step: 13
Training loss: 0.5813099145889282
Validation loss: 1.722780716034674

Epoch: 632| Step: 0
Training loss: 0.8746411800384521
Validation loss: 1.7679356733957927

Epoch: 6| Step: 1
Training loss: 1.437950611114502
Validation loss: 1.748890846006332

Epoch: 6| Step: 2
Training loss: 0.737363338470459
Validation loss: 1.7750689573185419

Epoch: 6| Step: 3
Training loss: 0.9713872075080872
Validation loss: 1.8036132345917404

Epoch: 6| Step: 4
Training loss: 0.9918375015258789
Validation loss: 1.7880733705336047

Epoch: 6| Step: 5
Training loss: 0.5000417232513428
Validation loss: 1.7540992101033528

Epoch: 6| Step: 6
Training loss: 1.3265459537506104
Validation loss: 1.7827460099292058

Epoch: 6| Step: 7
Training loss: 0.7960116863250732
Validation loss: 1.7103344099496

Epoch: 6| Step: 8
Training loss: 1.3873529434204102
Validation loss: 1.6877405233280633

Epoch: 6| Step: 9
Training loss: 0.813025951385498
Validation loss: 1.7680529176547963

Epoch: 6| Step: 10
Training loss: 0.7134582996368408
Validation loss: 1.7151496807734172

Epoch: 6| Step: 11
Training loss: 0.9361436367034912
Validation loss: 1.7300422191619873

Epoch: 6| Step: 12
Training loss: 0.8190932273864746
Validation loss: 1.7670674606036114

Epoch: 6| Step: 13
Training loss: 0.8613947033882141
Validation loss: 1.7174452812440935

Epoch: 633| Step: 0
Training loss: 1.499194860458374
Validation loss: 1.7202320547514065

Epoch: 6| Step: 1
Training loss: 0.5029140710830688
Validation loss: 1.7634714752115228

Epoch: 6| Step: 2
Training loss: 0.7851107120513916
Validation loss: 1.6967222088126725

Epoch: 6| Step: 3
Training loss: 1.0676771402359009
Validation loss: 1.7452589504180416

Epoch: 6| Step: 4
Training loss: 1.0135217905044556
Validation loss: 1.7802811643128753

Epoch: 6| Step: 5
Training loss: 1.0002996921539307
Validation loss: 1.7516554619676323

Epoch: 6| Step: 6
Training loss: 0.9586840867996216
Validation loss: 1.7793067001527356

Epoch: 6| Step: 7
Training loss: 1.1995981931686401
Validation loss: 1.7836174670086111

Epoch: 6| Step: 8
Training loss: 0.522380530834198
Validation loss: 1.6933333643021122

Epoch: 6| Step: 9
Training loss: 1.0046231746673584
Validation loss: 1.7344783095903293

Epoch: 6| Step: 10
Training loss: 0.7435731291770935
Validation loss: 1.7813437664380638

Epoch: 6| Step: 11
Training loss: 0.6754424571990967
Validation loss: 1.7914307553281066

Epoch: 6| Step: 12
Training loss: 1.2208658456802368
Validation loss: 1.8143426064522035

Epoch: 6| Step: 13
Training loss: 0.4934195876121521
Validation loss: 1.770675500233968

Epoch: 634| Step: 0
Training loss: 1.3506243228912354
Validation loss: 1.8756445633467806

Epoch: 6| Step: 1
Training loss: 0.640060305595398
Validation loss: 1.7306678654045187

Epoch: 6| Step: 2
Training loss: 0.9488769769668579
Validation loss: 1.7717518152729157

Epoch: 6| Step: 3
Training loss: 0.8911766409873962
Validation loss: 1.7191078919236378

Epoch: 6| Step: 4
Training loss: 0.7306050062179565
Validation loss: 1.7874912715727282

Epoch: 6| Step: 5
Training loss: 1.2748866081237793
Validation loss: 1.7592527750999696

Epoch: 6| Step: 6
Training loss: 0.7862839698791504
Validation loss: 1.7406341465570594

Epoch: 6| Step: 7
Training loss: 0.9558919668197632
Validation loss: 1.729792623109715

Epoch: 6| Step: 8
Training loss: 0.9880390763282776
Validation loss: 1.7523363149294289

Epoch: 6| Step: 9
Training loss: 0.547476589679718
Validation loss: 1.7610703194013206

Epoch: 6| Step: 10
Training loss: 0.6227208375930786
Validation loss: 1.7279643525359452

Epoch: 6| Step: 11
Training loss: 0.848646342754364
Validation loss: 1.7455375412459015

Epoch: 6| Step: 12
Training loss: 0.8552693128585815
Validation loss: 1.7310305744089105

Epoch: 6| Step: 13
Training loss: 1.0969971418380737
Validation loss: 1.7004593521036127

Epoch: 635| Step: 0
Training loss: 0.8816978931427002
Validation loss: 1.7410824337313253

Epoch: 6| Step: 1
Training loss: 1.0117003917694092
Validation loss: 1.74956581541287

Epoch: 6| Step: 2
Training loss: 0.7715315818786621
Validation loss: 1.732151864677347

Epoch: 6| Step: 3
Training loss: 0.9600272178649902
Validation loss: 1.695765506836676

Epoch: 6| Step: 4
Training loss: 1.247212529182434
Validation loss: 1.749241550763448

Epoch: 6| Step: 5
Training loss: 0.8871560096740723
Validation loss: 1.7279909631257415

Epoch: 6| Step: 6
Training loss: 1.2438602447509766
Validation loss: 1.671623094107515

Epoch: 6| Step: 7
Training loss: 0.5609096884727478
Validation loss: 1.7581949567282071

Epoch: 6| Step: 8
Training loss: 0.8711848855018616
Validation loss: 1.7095539082763016

Epoch: 6| Step: 9
Training loss: 0.797109067440033
Validation loss: 1.785712057544339

Epoch: 6| Step: 10
Training loss: 1.2009669542312622
Validation loss: 1.7031250410182501

Epoch: 6| Step: 11
Training loss: 0.7503578662872314
Validation loss: 1.7675004441251037

Epoch: 6| Step: 12
Training loss: 0.629662036895752
Validation loss: 1.794667173457402

Epoch: 6| Step: 13
Training loss: 0.864691972732544
Validation loss: 1.775465223097032

Epoch: 636| Step: 0
Training loss: 1.4305669069290161
Validation loss: 1.7869755888497958

Epoch: 6| Step: 1
Training loss: 0.8590791821479797
Validation loss: 1.8424373172944593

Epoch: 6| Step: 2
Training loss: 0.5493091940879822
Validation loss: 1.7577235519245107

Epoch: 6| Step: 3
Training loss: 0.48687928915023804
Validation loss: 1.8297232081813197

Epoch: 6| Step: 4
Training loss: 0.8638854026794434
Validation loss: 1.796929669636552

Epoch: 6| Step: 5
Training loss: 1.0844804048538208
Validation loss: 1.8439768181052258

Epoch: 6| Step: 6
Training loss: 0.8863658308982849
Validation loss: 1.7133932139283867

Epoch: 6| Step: 7
Training loss: 0.9972962737083435
Validation loss: 1.722661272172005

Epoch: 6| Step: 8
Training loss: 1.1369738578796387
Validation loss: 1.7526618075627152

Epoch: 6| Step: 9
Training loss: 0.9308826923370361
Validation loss: 1.7945718226894256

Epoch: 6| Step: 10
Training loss: 1.0013306140899658
Validation loss: 1.804121986512215

Epoch: 6| Step: 11
Training loss: 0.6022239923477173
Validation loss: 1.7375782792286207

Epoch: 6| Step: 12
Training loss: 0.6424010992050171
Validation loss: 1.7382990570478543

Epoch: 6| Step: 13
Training loss: 1.3332791328430176
Validation loss: 1.7488601438460811

Epoch: 637| Step: 0
Training loss: 0.7010052800178528
Validation loss: 1.8212279273617653

Epoch: 6| Step: 1
Training loss: 1.0039188861846924
Validation loss: 1.7200706364006124

Epoch: 6| Step: 2
Training loss: 0.9558062553405762
Validation loss: 1.7376682258421374

Epoch: 6| Step: 3
Training loss: 0.6396532654762268
Validation loss: 1.739543112375403

Epoch: 6| Step: 4
Training loss: 0.8286259770393372
Validation loss: 1.7975710258688977

Epoch: 6| Step: 5
Training loss: 1.186470866203308
Validation loss: 1.7170990141489173

Epoch: 6| Step: 6
Training loss: 0.8907232880592346
Validation loss: 1.7038640911861131

Epoch: 6| Step: 7
Training loss: 1.0533589124679565
Validation loss: 1.780317876928596

Epoch: 6| Step: 8
Training loss: 0.7572041153907776
Validation loss: 1.770395653222197

Epoch: 6| Step: 9
Training loss: 1.3142788410186768
Validation loss: 1.785903533299764

Epoch: 6| Step: 10
Training loss: 0.6793689131736755
Validation loss: 1.7864367186382253

Epoch: 6| Step: 11
Training loss: 1.0049413442611694
Validation loss: 1.7799982114504742

Epoch: 6| Step: 12
Training loss: 0.7026448249816895
Validation loss: 1.7333385918730049

Epoch: 6| Step: 13
Training loss: 0.6883546113967896
Validation loss: 1.8304007130284463

Epoch: 638| Step: 0
Training loss: 1.562453269958496
Validation loss: 1.755283268549109

Epoch: 6| Step: 1
Training loss: 0.8268746733665466
Validation loss: 1.7168478786304433

Epoch: 6| Step: 2
Training loss: 0.3063774108886719
Validation loss: 1.8398786052580802

Epoch: 6| Step: 3
Training loss: 0.8375847339630127
Validation loss: 1.7659384947951122

Epoch: 6| Step: 4
Training loss: 1.183802604675293
Validation loss: 1.7379494367107269

Epoch: 6| Step: 5
Training loss: 1.4716519117355347
Validation loss: 1.7820401537802912

Epoch: 6| Step: 6
Training loss: 0.8325373530387878
Validation loss: 1.8250231871040918

Epoch: 6| Step: 7
Training loss: 0.6269652843475342
Validation loss: 1.8049921604894823

Epoch: 6| Step: 8
Training loss: 0.7343980669975281
Validation loss: 1.699356339311087

Epoch: 6| Step: 9
Training loss: 1.0226926803588867
Validation loss: 1.7597016775479881

Epoch: 6| Step: 10
Training loss: 0.5472292304039001
Validation loss: 1.75239993551726

Epoch: 6| Step: 11
Training loss: 0.7366888523101807
Validation loss: 1.7617402820176975

Epoch: 6| Step: 12
Training loss: 1.281957983970642
Validation loss: 1.6932707204613635

Epoch: 6| Step: 13
Training loss: 0.6564521193504333
Validation loss: 1.8065318933097265

Epoch: 639| Step: 0
Training loss: 0.9778520464897156
Validation loss: 1.7400883538748628

Epoch: 6| Step: 1
Training loss: 1.089105486869812
Validation loss: 1.6903865081007763

Epoch: 6| Step: 2
Training loss: 0.5670063495635986
Validation loss: 1.793848136419891

Epoch: 6| Step: 3
Training loss: 0.7871185541152954
Validation loss: 1.751647663372819

Epoch: 6| Step: 4
Training loss: 0.6348268389701843
Validation loss: 1.7489313771647792

Epoch: 6| Step: 5
Training loss: 1.0580651760101318
Validation loss: 1.7391840950135262

Epoch: 6| Step: 6
Training loss: 1.0793405771255493
Validation loss: 1.7355441419027184

Epoch: 6| Step: 7
Training loss: 1.6984214782714844
Validation loss: 1.7181144042681622

Epoch: 6| Step: 8
Training loss: 0.8582289218902588
Validation loss: 1.734413585355205

Epoch: 6| Step: 9
Training loss: 0.7465747594833374
Validation loss: 1.7814706217858098

Epoch: 6| Step: 10
Training loss: 0.6738595962524414
Validation loss: 1.7924740929757395

Epoch: 6| Step: 11
Training loss: 0.9796270728111267
Validation loss: 1.7866120479440177

Epoch: 6| Step: 12
Training loss: 0.6225451231002808
Validation loss: 1.7677445764182715

Epoch: 6| Step: 13
Training loss: 0.4159197211265564
Validation loss: 1.7173547360204882

Epoch: 640| Step: 0
Training loss: 0.7367205619812012
Validation loss: 1.768910454165551

Epoch: 6| Step: 1
Training loss: 1.1282575130462646
Validation loss: 1.7471343266066683

Epoch: 6| Step: 2
Training loss: 0.6966734528541565
Validation loss: 1.7801535949912122

Epoch: 6| Step: 3
Training loss: 1.0577354431152344
Validation loss: 1.747826486505488

Epoch: 6| Step: 4
Training loss: 0.7491046190261841
Validation loss: 1.755000683569139

Epoch: 6| Step: 5
Training loss: 0.8430365324020386
Validation loss: 1.77053540496416

Epoch: 6| Step: 6
Training loss: 1.2374231815338135
Validation loss: 1.8043255011240642

Epoch: 6| Step: 7
Training loss: 0.40175551176071167
Validation loss: 1.7348665780918573

Epoch: 6| Step: 8
Training loss: 0.8694181442260742
Validation loss: 1.751845359802246

Epoch: 6| Step: 9
Training loss: 1.6233175992965698
Validation loss: 1.8280438684648084

Epoch: 6| Step: 10
Training loss: 1.2291738986968994
Validation loss: 1.6796150220337736

Epoch: 6| Step: 11
Training loss: 0.6573504209518433
Validation loss: 1.699420173962911

Epoch: 6| Step: 12
Training loss: 0.6673765778541565
Validation loss: 1.7654527925675916

Epoch: 6| Step: 13
Training loss: 0.7745331525802612
Validation loss: 1.7505095863855014

Epoch: 641| Step: 0
Training loss: 1.3274015188217163
Validation loss: 1.7576699461988223

Epoch: 6| Step: 1
Training loss: 0.6706408858299255
Validation loss: 1.7886658458299534

Epoch: 6| Step: 2
Training loss: 0.3321177065372467
Validation loss: 1.7789008784037765

Epoch: 6| Step: 3
Training loss: 0.8626880645751953
Validation loss: 1.7502582086029874

Epoch: 6| Step: 4
Training loss: 0.981803297996521
Validation loss: 1.7373689707889353

Epoch: 6| Step: 5
Training loss: 1.0926772356033325
Validation loss: 1.7207906951186478

Epoch: 6| Step: 6
Training loss: 0.6313357353210449
Validation loss: 1.7432504161711662

Epoch: 6| Step: 7
Training loss: 1.4560718536376953
Validation loss: 1.74119020277454

Epoch: 6| Step: 8
Training loss: 0.84951251745224
Validation loss: 1.7203136349237094

Epoch: 6| Step: 9
Training loss: 0.6459600925445557
Validation loss: 1.764353931591075

Epoch: 6| Step: 10
Training loss: 0.4497218132019043
Validation loss: 1.6860699422897831

Epoch: 6| Step: 11
Training loss: 1.179915428161621
Validation loss: 1.7123876297345726

Epoch: 6| Step: 12
Training loss: 0.6997860670089722
Validation loss: 1.7355103569646035

Epoch: 6| Step: 13
Training loss: 1.0469000339508057
Validation loss: 1.7982379736438874

Epoch: 642| Step: 0
Training loss: 0.8601096868515015
Validation loss: 1.7609979773080477

Epoch: 6| Step: 1
Training loss: 0.9724520444869995
Validation loss: 1.759633876944101

Epoch: 6| Step: 2
Training loss: 1.1368314027786255
Validation loss: 1.7986271458287393

Epoch: 6| Step: 3
Training loss: 1.1010444164276123
Validation loss: 1.7266586390874719

Epoch: 6| Step: 4
Training loss: 0.8746600151062012
Validation loss: 1.7216166770586403

Epoch: 6| Step: 5
Training loss: 0.5795233249664307
Validation loss: 1.7040050894983354

Epoch: 6| Step: 6
Training loss: 0.9320342540740967
Validation loss: 1.7844026550169914

Epoch: 6| Step: 7
Training loss: 0.8490017056465149
Validation loss: 1.7340259423819921

Epoch: 6| Step: 8
Training loss: 0.6486133337020874
Validation loss: 1.8089635461889289

Epoch: 6| Step: 9
Training loss: 0.6154687404632568
Validation loss: 1.7972480020215433

Epoch: 6| Step: 10
Training loss: 0.8489645719528198
Validation loss: 1.714270523799363

Epoch: 6| Step: 11
Training loss: 0.8094979524612427
Validation loss: 1.710361091039514

Epoch: 6| Step: 12
Training loss: 0.8957130312919617
Validation loss: 1.7301431663574711

Epoch: 6| Step: 13
Training loss: 1.2242000102996826
Validation loss: 1.755295871406473

Epoch: 643| Step: 0
Training loss: 1.0099174976348877
Validation loss: 1.7557503523365143

Epoch: 6| Step: 1
Training loss: 0.9350740909576416
Validation loss: 1.8003038411499352

Epoch: 6| Step: 2
Training loss: 0.9493288993835449
Validation loss: 1.795860569964173

Epoch: 6| Step: 3
Training loss: 1.064666509628296
Validation loss: 1.7433340677651026

Epoch: 6| Step: 4
Training loss: 0.7789337635040283
Validation loss: 1.7733002503712971

Epoch: 6| Step: 5
Training loss: 0.7234428524971008
Validation loss: 1.8445770496963172

Epoch: 6| Step: 6
Training loss: 0.9851856231689453
Validation loss: 1.8402063679951493

Epoch: 6| Step: 7
Training loss: 0.6147681474685669
Validation loss: 1.7211023684470885

Epoch: 6| Step: 8
Training loss: 0.8886773586273193
Validation loss: 1.7570455612674836

Epoch: 6| Step: 9
Training loss: 0.7130794525146484
Validation loss: 1.7655474729435419

Epoch: 6| Step: 10
Training loss: 0.6252008080482483
Validation loss: 1.693849773817165

Epoch: 6| Step: 11
Training loss: 0.9726199507713318
Validation loss: 1.7713429107460925

Epoch: 6| Step: 12
Training loss: 1.369837999343872
Validation loss: 1.747303114142469

Epoch: 6| Step: 13
Training loss: 0.8731393814086914
Validation loss: 1.771351242578158

Epoch: 644| Step: 0
Training loss: 0.959743857383728
Validation loss: 1.735589655496741

Epoch: 6| Step: 1
Training loss: 1.0381255149841309
Validation loss: 1.6609612587959535

Epoch: 6| Step: 2
Training loss: 0.9067507982254028
Validation loss: 1.7314445998079033

Epoch: 6| Step: 3
Training loss: 0.7186709046363831
Validation loss: 1.7459615122887395

Epoch: 6| Step: 4
Training loss: 0.645243763923645
Validation loss: 1.7356080944820116

Epoch: 6| Step: 5
Training loss: 1.5267736911773682
Validation loss: 1.7267526657350603

Epoch: 6| Step: 6
Training loss: 1.4108471870422363
Validation loss: 1.707330862681071

Epoch: 6| Step: 7
Training loss: 0.696765661239624
Validation loss: 1.7819131317959036

Epoch: 6| Step: 8
Training loss: 0.6620068550109863
Validation loss: 1.7115734405415033

Epoch: 6| Step: 9
Training loss: 0.8047813773155212
Validation loss: 1.7722522584340905

Epoch: 6| Step: 10
Training loss: 0.8290128707885742
Validation loss: 1.7318455006486626

Epoch: 6| Step: 11
Training loss: 0.9253586530685425
Validation loss: 1.7495306461088118

Epoch: 6| Step: 12
Training loss: 0.9880496859550476
Validation loss: 1.7115548823469429

Epoch: 6| Step: 13
Training loss: 0.4502251446247101
Validation loss: 1.7520694809575235

Epoch: 645| Step: 0
Training loss: 0.4003885090351105
Validation loss: 1.7169488117259035

Epoch: 6| Step: 1
Training loss: 1.314499855041504
Validation loss: 1.7404294142159082

Epoch: 6| Step: 2
Training loss: 1.0687586069107056
Validation loss: 1.7417467845383512

Epoch: 6| Step: 3
Training loss: 0.6706968545913696
Validation loss: 1.7827136888298938

Epoch: 6| Step: 4
Training loss: 1.3690370321273804
Validation loss: 1.7643696185081237

Epoch: 6| Step: 5
Training loss: 0.8086929321289062
Validation loss: 1.780025319386554

Epoch: 6| Step: 6
Training loss: 0.33496585488319397
Validation loss: 1.730791832811089

Epoch: 6| Step: 7
Training loss: 1.5678647756576538
Validation loss: 1.7169903029677689

Epoch: 6| Step: 8
Training loss: 0.5931228995323181
Validation loss: 1.7307440183495963

Epoch: 6| Step: 9
Training loss: 1.0145431756973267
Validation loss: 1.7087270534166725

Epoch: 6| Step: 10
Training loss: 0.6429265141487122
Validation loss: 1.7777354166071901

Epoch: 6| Step: 11
Training loss: 0.9151943922042847
Validation loss: 1.749837524147444

Epoch: 6| Step: 12
Training loss: 0.7668625116348267
Validation loss: 1.7893481408396075

Epoch: 6| Step: 13
Training loss: 0.5347528457641602
Validation loss: 1.727667406041135

Epoch: 646| Step: 0
Training loss: 0.6071372032165527
Validation loss: 1.7693843290369997

Epoch: 6| Step: 1
Training loss: 1.1404961347579956
Validation loss: 1.751821914026814

Epoch: 6| Step: 2
Training loss: 0.7840588688850403
Validation loss: 1.6714430932075746

Epoch: 6| Step: 3
Training loss: 0.778164803981781
Validation loss: 1.7493357478931386

Epoch: 6| Step: 4
Training loss: 1.0958445072174072
Validation loss: 1.7259212463132796

Epoch: 6| Step: 5
Training loss: 0.9100179672241211
Validation loss: 1.7359947722445253

Epoch: 6| Step: 6
Training loss: 1.3469574451446533
Validation loss: 1.7252331420939455

Epoch: 6| Step: 7
Training loss: 1.2346014976501465
Validation loss: 1.7572493540343417

Epoch: 6| Step: 8
Training loss: 0.7222355604171753
Validation loss: 1.7640770455842376

Epoch: 6| Step: 9
Training loss: 0.5791161060333252
Validation loss: 1.7535053978684128

Epoch: 6| Step: 10
Training loss: 0.5426672101020813
Validation loss: 1.6982063862585253

Epoch: 6| Step: 11
Training loss: 0.7330498695373535
Validation loss: 1.7129351144195886

Epoch: 6| Step: 12
Training loss: 0.6027622222900391
Validation loss: 1.7332125761175667

Epoch: 6| Step: 13
Training loss: 1.2808839082717896
Validation loss: 1.7738929922862718

Epoch: 647| Step: 0
Training loss: 0.5251127481460571
Validation loss: 1.7507576198988064

Epoch: 6| Step: 1
Training loss: 0.5041456818580627
Validation loss: 1.7434800504356303

Epoch: 6| Step: 2
Training loss: 0.818185567855835
Validation loss: 1.6864918842110583

Epoch: 6| Step: 3
Training loss: 0.6710572838783264
Validation loss: 1.7971754445824573

Epoch: 6| Step: 4
Training loss: 0.8568387031555176
Validation loss: 1.7270834945863294

Epoch: 6| Step: 5
Training loss: 0.6740235686302185
Validation loss: 1.7051101166714904

Epoch: 6| Step: 6
Training loss: 0.7250756025314331
Validation loss: 1.8542178420610325

Epoch: 6| Step: 7
Training loss: 0.6809113621711731
Validation loss: 1.7697965842421337

Epoch: 6| Step: 8
Training loss: 1.0887038707733154
Validation loss: 1.799844798221383

Epoch: 6| Step: 9
Training loss: 1.4377214908599854
Validation loss: 1.7482371073897167

Epoch: 6| Step: 10
Training loss: 1.0698821544647217
Validation loss: 1.810528757751629

Epoch: 6| Step: 11
Training loss: 1.385676622390747
Validation loss: 1.7591953123769453

Epoch: 6| Step: 12
Training loss: 1.578534722328186
Validation loss: 1.7434846919070008

Epoch: 6| Step: 13
Training loss: 0.46795526146888733
Validation loss: 1.769694891027225

Epoch: 648| Step: 0
Training loss: 1.4449632167816162
Validation loss: 1.7998128693590882

Epoch: 6| Step: 1
Training loss: 0.6065033674240112
Validation loss: 1.7647271284493067

Epoch: 6| Step: 2
Training loss: 0.8030250072479248
Validation loss: 1.7523012648346603

Epoch: 6| Step: 3
Training loss: 0.7913178205490112
Validation loss: 1.7955898033675326

Epoch: 6| Step: 4
Training loss: 0.6723198890686035
Validation loss: 1.750035462840911

Epoch: 6| Step: 5
Training loss: 1.015883207321167
Validation loss: 1.7594740403595792

Epoch: 6| Step: 6
Training loss: 0.34237468242645264
Validation loss: 1.7493527666214974

Epoch: 6| Step: 7
Training loss: 1.1152262687683105
Validation loss: 1.669923872076055

Epoch: 6| Step: 8
Training loss: 1.0303593873977661
Validation loss: 1.747560590826055

Epoch: 6| Step: 9
Training loss: 1.1842654943466187
Validation loss: 1.7075760531169113

Epoch: 6| Step: 10
Training loss: 0.7274964451789856
Validation loss: 1.7267283752400389

Epoch: 6| Step: 11
Training loss: 1.010810375213623
Validation loss: 1.7628405952966342

Epoch: 6| Step: 12
Training loss: 0.7698606252670288
Validation loss: 1.7144575401019024

Epoch: 6| Step: 13
Training loss: 0.7912659049034119
Validation loss: 1.7581512364008094

Epoch: 649| Step: 0
Training loss: 1.1431553363800049
Validation loss: 1.7566022052559802

Epoch: 6| Step: 1
Training loss: 0.6752862334251404
Validation loss: 1.6642102938826366

Epoch: 6| Step: 2
Training loss: 0.8845168352127075
Validation loss: 1.6725063862339142

Epoch: 6| Step: 3
Training loss: 1.1077888011932373
Validation loss: 1.7635606411964662

Epoch: 6| Step: 4
Training loss: 0.6756189465522766
Validation loss: 1.7528638083447692

Epoch: 6| Step: 5
Training loss: 0.6581987142562866
Validation loss: 1.6630784324420396

Epoch: 6| Step: 6
Training loss: 0.8702760934829712
Validation loss: 1.7367636221711353

Epoch: 6| Step: 7
Training loss: 1.2028816938400269
Validation loss: 1.7617173489703928

Epoch: 6| Step: 8
Training loss: 1.0599007606506348
Validation loss: 1.7227099569894935

Epoch: 6| Step: 9
Training loss: 0.9695637226104736
Validation loss: 1.669419478344661

Epoch: 6| Step: 10
Training loss: 0.9597492218017578
Validation loss: 1.7097265771640244

Epoch: 6| Step: 11
Training loss: 0.9328956007957458
Validation loss: 1.7413213022293583

Epoch: 6| Step: 12
Training loss: 0.7386044263839722
Validation loss: 1.720364773145286

Epoch: 6| Step: 13
Training loss: 0.9127563834190369
Validation loss: 1.7523158647680794

Epoch: 650| Step: 0
Training loss: 0.8471164107322693
Validation loss: 1.7017397893372403

Epoch: 6| Step: 1
Training loss: 0.7263290882110596
Validation loss: 1.7753238447250859

Epoch: 6| Step: 2
Training loss: 0.9107730388641357
Validation loss: 1.7092066964795511

Epoch: 6| Step: 3
Training loss: 0.9416177868843079
Validation loss: 1.6898284048162482

Epoch: 6| Step: 4
Training loss: 0.8519536256790161
Validation loss: 1.734920947782455

Epoch: 6| Step: 5
Training loss: 0.43062570691108704
Validation loss: 1.7804376168917584

Epoch: 6| Step: 6
Training loss: 0.9664678573608398
Validation loss: 1.7246394234318887

Epoch: 6| Step: 7
Training loss: 1.0883464813232422
Validation loss: 1.7564015491034395

Epoch: 6| Step: 8
Training loss: 1.0245578289031982
Validation loss: 1.7207832054425312

Epoch: 6| Step: 9
Training loss: 0.9161465764045715
Validation loss: 1.7451008699273551

Epoch: 6| Step: 10
Training loss: 1.0196080207824707
Validation loss: 1.791576918735299

Epoch: 6| Step: 11
Training loss: 0.5877372026443481
Validation loss: 1.752649946879315

Epoch: 6| Step: 12
Training loss: 0.8244837522506714
Validation loss: 1.6867805168192873

Epoch: 6| Step: 13
Training loss: 1.1041499376296997
Validation loss: 1.7155095838731336

Epoch: 651| Step: 0
Training loss: 0.5695275068283081
Validation loss: 1.7715421056234708

Epoch: 6| Step: 1
Training loss: 1.190062403678894
Validation loss: 1.7328534151918145

Epoch: 6| Step: 2
Training loss: 0.6687557697296143
Validation loss: 1.7365681637999832

Epoch: 6| Step: 3
Training loss: 0.886914849281311
Validation loss: 1.681147212623268

Epoch: 6| Step: 4
Training loss: 0.8550899028778076
Validation loss: 1.6988449660680627

Epoch: 6| Step: 5
Training loss: 1.0535409450531006
Validation loss: 1.6908351580301921

Epoch: 6| Step: 6
Training loss: 0.8252668976783752
Validation loss: 1.7514753636493479

Epoch: 6| Step: 7
Training loss: 1.1328543424606323
Validation loss: 1.7607285720045849

Epoch: 6| Step: 8
Training loss: 0.9811614751815796
Validation loss: 1.7343305221167944

Epoch: 6| Step: 9
Training loss: 0.8304589986801147
Validation loss: 1.7318328747185328

Epoch: 6| Step: 10
Training loss: 0.479915589094162
Validation loss: 1.7078821351451259

Epoch: 6| Step: 11
Training loss: 0.9224395751953125
Validation loss: 1.7320974514048586

Epoch: 6| Step: 12
Training loss: 0.908088207244873
Validation loss: 1.7321010507563108

Epoch: 6| Step: 13
Training loss: 0.6904418468475342
Validation loss: 1.691631362002383

Epoch: 652| Step: 0
Training loss: 0.7590773105621338
Validation loss: 1.7233919251349665

Epoch: 6| Step: 1
Training loss: 0.6273426413536072
Validation loss: 1.7038675123645413

Epoch: 6| Step: 2
Training loss: 1.3634202480316162
Validation loss: 1.7028869916034002

Epoch: 6| Step: 3
Training loss: 0.75118088722229
Validation loss: 1.6813673562900995

Epoch: 6| Step: 4
Training loss: 0.9746853709220886
Validation loss: 1.745898332647098

Epoch: 6| Step: 5
Training loss: 1.0287436246871948
Validation loss: 1.7749414995152464

Epoch: 6| Step: 6
Training loss: 1.2387689352035522
Validation loss: 1.7399000506247244

Epoch: 6| Step: 7
Training loss: 0.8329296112060547
Validation loss: 1.7259750955848283

Epoch: 6| Step: 8
Training loss: 0.906067967414856
Validation loss: 1.737761325733636

Epoch: 6| Step: 9
Training loss: 0.752713143825531
Validation loss: 1.740139554905635

Epoch: 6| Step: 10
Training loss: 0.66025310754776
Validation loss: 1.7937489042999923

Epoch: 6| Step: 11
Training loss: 1.1097893714904785
Validation loss: 1.7020934320265246

Epoch: 6| Step: 12
Training loss: 0.4601592421531677
Validation loss: 1.7287558535093903

Epoch: 6| Step: 13
Training loss: 1.1086182594299316
Validation loss: 1.78938244106949

Epoch: 653| Step: 0
Training loss: 1.0421576499938965
Validation loss: 1.802905313430294

Epoch: 6| Step: 1
Training loss: 1.1830905675888062
Validation loss: 1.7904125528950845

Epoch: 6| Step: 2
Training loss: 0.8568671941757202
Validation loss: 1.7060274077999977

Epoch: 6| Step: 3
Training loss: 0.4995928108692169
Validation loss: 1.7707075726601385

Epoch: 6| Step: 4
Training loss: 0.8248915672302246
Validation loss: 1.7459111752048615

Epoch: 6| Step: 5
Training loss: 0.9507668614387512
Validation loss: 1.7792097163456742

Epoch: 6| Step: 6
Training loss: 0.9879017472267151
Validation loss: 1.7991920594246156

Epoch: 6| Step: 7
Training loss: 0.7282323837280273
Validation loss: 1.7390110800343175

Epoch: 6| Step: 8
Training loss: 0.5121051669120789
Validation loss: 1.7501365100183794

Epoch: 6| Step: 9
Training loss: 1.135025978088379
Validation loss: 1.7582689459605882

Epoch: 6| Step: 10
Training loss: 0.6554455757141113
Validation loss: 1.7118563728947793

Epoch: 6| Step: 11
Training loss: 1.4109623432159424
Validation loss: 1.7313076885797645

Epoch: 6| Step: 12
Training loss: 0.5344380140304565
Validation loss: 1.7043007266136907

Epoch: 6| Step: 13
Training loss: 0.622546911239624
Validation loss: 1.7539194771038589

Epoch: 654| Step: 0
Training loss: 0.5968112349510193
Validation loss: 1.7071390228886758

Epoch: 6| Step: 1
Training loss: 1.3892649412155151
Validation loss: 1.6894510548601869

Epoch: 6| Step: 2
Training loss: 0.735781192779541
Validation loss: 1.740570226023274

Epoch: 6| Step: 3
Training loss: 0.7317151427268982
Validation loss: 1.648537717839723

Epoch: 6| Step: 4
Training loss: 0.7746789455413818
Validation loss: 1.740767853234404

Epoch: 6| Step: 5
Training loss: 0.9047396779060364
Validation loss: 1.728151059919788

Epoch: 6| Step: 6
Training loss: 1.0332391262054443
Validation loss: 1.7588471827968475

Epoch: 6| Step: 7
Training loss: 0.7190804481506348
Validation loss: 1.7912672463283743

Epoch: 6| Step: 8
Training loss: 0.6467612385749817
Validation loss: 1.7167194709982923

Epoch: 6| Step: 9
Training loss: 0.9211327433586121
Validation loss: 1.733361937666452

Epoch: 6| Step: 10
Training loss: 1.0438778400421143
Validation loss: 1.7537150741905294

Epoch: 6| Step: 11
Training loss: 0.6187819242477417
Validation loss: 1.7304053896216935

Epoch: 6| Step: 12
Training loss: 0.653337836265564
Validation loss: 1.6395295871201383

Epoch: 6| Step: 13
Training loss: 1.0451005697250366
Validation loss: 1.7430533132245463

Epoch: 655| Step: 0
Training loss: 0.5322731137275696
Validation loss: 1.7372778538734681

Epoch: 6| Step: 1
Training loss: 0.9643745422363281
Validation loss: 1.7030105385729062

Epoch: 6| Step: 2
Training loss: 0.6405887603759766
Validation loss: 1.694462432656237

Epoch: 6| Step: 3
Training loss: 0.9076845049858093
Validation loss: 1.7448758104796052

Epoch: 6| Step: 4
Training loss: 1.089460849761963
Validation loss: 1.6917840485931726

Epoch: 6| Step: 5
Training loss: 0.6305553913116455
Validation loss: 1.716898246478009

Epoch: 6| Step: 6
Training loss: 0.7437556982040405
Validation loss: 1.7266720097552064

Epoch: 6| Step: 7
Training loss: 0.7140035629272461
Validation loss: 1.6989276665513233

Epoch: 6| Step: 8
Training loss: 0.8617051243782043
Validation loss: 1.7256021755997852

Epoch: 6| Step: 9
Training loss: 0.7121557593345642
Validation loss: 1.7028963514553603

Epoch: 6| Step: 10
Training loss: 1.2406800985336304
Validation loss: 1.7083268883407756

Epoch: 6| Step: 11
Training loss: 1.4855091571807861
Validation loss: 1.7434542050925634

Epoch: 6| Step: 12
Training loss: 1.05800461769104
Validation loss: 1.7424359321594238

Epoch: 6| Step: 13
Training loss: 0.5888760089874268
Validation loss: 1.7838191293901013

Epoch: 656| Step: 0
Training loss: 1.0322058200836182
Validation loss: 1.7187423859873125

Epoch: 6| Step: 1
Training loss: 1.1135412454605103
Validation loss: 1.7175806850515387

Epoch: 6| Step: 2
Training loss: 0.5658085346221924
Validation loss: 1.7107564826165476

Epoch: 6| Step: 3
Training loss: 1.197798252105713
Validation loss: 1.7355022276601484

Epoch: 6| Step: 4
Training loss: 1.0549030303955078
Validation loss: 1.6923214979069208

Epoch: 6| Step: 5
Training loss: 0.7585088610649109
Validation loss: 1.727192937686879

Epoch: 6| Step: 6
Training loss: 0.9785231351852417
Validation loss: 1.7237423145642845

Epoch: 6| Step: 7
Training loss: 1.0614168643951416
Validation loss: 1.7388251494335871

Epoch: 6| Step: 8
Training loss: 0.8807485103607178
Validation loss: 1.717061593968381

Epoch: 6| Step: 9
Training loss: 0.6897872090339661
Validation loss: 1.7070191970435522

Epoch: 6| Step: 10
Training loss: 0.8665772676467896
Validation loss: 1.7456917314119236

Epoch: 6| Step: 11
Training loss: 0.8473631739616394
Validation loss: 1.688720646724906

Epoch: 6| Step: 12
Training loss: 0.4212874174118042
Validation loss: 1.8065506117318266

Epoch: 6| Step: 13
Training loss: 0.7480606436729431
Validation loss: 1.7260495052542737

Epoch: 657| Step: 0
Training loss: 0.8861739635467529
Validation loss: 1.7359034784378544

Epoch: 6| Step: 1
Training loss: 0.6470966935157776
Validation loss: 1.7579840024312336

Epoch: 6| Step: 2
Training loss: 1.3193860054016113
Validation loss: 1.7506099554800219

Epoch: 6| Step: 3
Training loss: 1.0214976072311401
Validation loss: 1.7498225806861796

Epoch: 6| Step: 4
Training loss: 0.8253113031387329
Validation loss: 1.8378305127543788

Epoch: 6| Step: 5
Training loss: 0.6572067737579346
Validation loss: 1.746379961249649

Epoch: 6| Step: 6
Training loss: 0.9361217617988586
Validation loss: 1.710196057955424

Epoch: 6| Step: 7
Training loss: 0.4345194101333618
Validation loss: 1.729888346887404

Epoch: 6| Step: 8
Training loss: 0.9954285621643066
Validation loss: 1.7408634103754514

Epoch: 6| Step: 9
Training loss: 0.5761727094650269
Validation loss: 1.725797317361319

Epoch: 6| Step: 10
Training loss: 0.9426262378692627
Validation loss: 1.6730115388029365

Epoch: 6| Step: 11
Training loss: 0.9855471849441528
Validation loss: 1.705340112409284

Epoch: 6| Step: 12
Training loss: 1.3378605842590332
Validation loss: 1.7171015649713495

Epoch: 6| Step: 13
Training loss: 1.2332350015640259
Validation loss: 1.7281597096432921

Epoch: 658| Step: 0
Training loss: 0.9988511800765991
Validation loss: 1.6774132572194582

Epoch: 6| Step: 1
Training loss: 0.8474909663200378
Validation loss: 1.7501940355505994

Epoch: 6| Step: 2
Training loss: 0.38684535026550293
Validation loss: 1.6857968222710393

Epoch: 6| Step: 3
Training loss: 0.896626353263855
Validation loss: 1.7104697150568808

Epoch: 6| Step: 4
Training loss: 0.7278048992156982
Validation loss: 1.7066587440429195

Epoch: 6| Step: 5
Training loss: 0.8369584083557129
Validation loss: 1.728264049817157

Epoch: 6| Step: 6
Training loss: 0.9814000129699707
Validation loss: 1.7614540130861345

Epoch: 6| Step: 7
Training loss: 0.729780912399292
Validation loss: 1.7477444397505892

Epoch: 6| Step: 8
Training loss: 1.1173158884048462
Validation loss: 1.8116833202300533

Epoch: 6| Step: 9
Training loss: 0.751118004322052
Validation loss: 1.7422542572021484

Epoch: 6| Step: 10
Training loss: 0.7623014450073242
Validation loss: 1.7872071009810253

Epoch: 6| Step: 11
Training loss: 1.1930873394012451
Validation loss: 1.7524068714469991

Epoch: 6| Step: 12
Training loss: 0.8139539957046509
Validation loss: 1.7646891096586823

Epoch: 6| Step: 13
Training loss: 0.9669749140739441
Validation loss: 1.7130126530124294

Epoch: 659| Step: 0
Training loss: 1.0886890888214111
Validation loss: 1.788456125925946

Epoch: 6| Step: 1
Training loss: 0.7932385206222534
Validation loss: 1.689978204747682

Epoch: 6| Step: 2
Training loss: 1.1090550422668457
Validation loss: 1.6914529313323319

Epoch: 6| Step: 3
Training loss: 0.6430099606513977
Validation loss: 1.6793283185651224

Epoch: 6| Step: 4
Training loss: 0.7797941565513611
Validation loss: 1.7617602873873968

Epoch: 6| Step: 5
Training loss: 0.4633145332336426
Validation loss: 1.6734431430857668

Epoch: 6| Step: 6
Training loss: 0.6686465740203857
Validation loss: 1.698078304208735

Epoch: 6| Step: 7
Training loss: 1.1720280647277832
Validation loss: 1.7013682908909296

Epoch: 6| Step: 8
Training loss: 1.0110706090927124
Validation loss: 1.7126146913856588

Epoch: 6| Step: 9
Training loss: 1.4233570098876953
Validation loss: 1.7690817271509478

Epoch: 6| Step: 10
Training loss: 0.5654821991920471
Validation loss: 1.7920989644142888

Epoch: 6| Step: 11
Training loss: 0.93036949634552
Validation loss: 1.8150293429692586

Epoch: 6| Step: 12
Training loss: 0.8892085552215576
Validation loss: 1.8468542970636839

Epoch: 6| Step: 13
Training loss: 1.0799593925476074
Validation loss: 1.8629429045543875

Epoch: 660| Step: 0
Training loss: 0.7985495924949646
Validation loss: 1.7965922586379512

Epoch: 6| Step: 1
Training loss: 0.8751816749572754
Validation loss: 1.828789254670502

Epoch: 6| Step: 2
Training loss: 1.1772085428237915
Validation loss: 1.7390959647393995

Epoch: 6| Step: 3
Training loss: 0.7871927618980408
Validation loss: 1.7993518626818092

Epoch: 6| Step: 4
Training loss: 1.0415136814117432
Validation loss: 1.7869151612763763

Epoch: 6| Step: 5
Training loss: 0.6864210963249207
Validation loss: 1.7691628420224754

Epoch: 6| Step: 6
Training loss: 0.9177987575531006
Validation loss: 1.8046404802671043

Epoch: 6| Step: 7
Training loss: 0.7584767937660217
Validation loss: 1.7481377932333177

Epoch: 6| Step: 8
Training loss: 0.8509398102760315
Validation loss: 1.7909007521085842

Epoch: 6| Step: 9
Training loss: 0.9418760538101196
Validation loss: 1.7611924512411958

Epoch: 6| Step: 10
Training loss: 0.803896427154541
Validation loss: 1.7089211376764442

Epoch: 6| Step: 11
Training loss: 0.5681257247924805
Validation loss: 1.8061885295375701

Epoch: 6| Step: 12
Training loss: 1.0252022743225098
Validation loss: 1.752677458588795

Epoch: 6| Step: 13
Training loss: 1.1593228578567505
Validation loss: 1.753794994405521

Epoch: 661| Step: 0
Training loss: 0.8858205676078796
Validation loss: 1.6970133063613728

Epoch: 6| Step: 1
Training loss: 0.7231298089027405
Validation loss: 1.7147353182556808

Epoch: 6| Step: 2
Training loss: 0.45749032497406006
Validation loss: 1.7106954115693287

Epoch: 6| Step: 3
Training loss: 0.6900620460510254
Validation loss: 1.7281077318294074

Epoch: 6| Step: 4
Training loss: 0.5475254058837891
Validation loss: 1.7652079007958854

Epoch: 6| Step: 5
Training loss: 0.4702503979206085
Validation loss: 1.76668684200574

Epoch: 6| Step: 6
Training loss: 1.6434179544448853
Validation loss: 1.729918933683826

Epoch: 6| Step: 7
Training loss: 1.1032602787017822
Validation loss: 1.7534021126326693

Epoch: 6| Step: 8
Training loss: 1.1128863096237183
Validation loss: 1.733166028094548

Epoch: 6| Step: 9
Training loss: 0.8186945915222168
Validation loss: 1.7387867307150235

Epoch: 6| Step: 10
Training loss: 0.7940478324890137
Validation loss: 1.775015104201532

Epoch: 6| Step: 11
Training loss: 0.6334507465362549
Validation loss: 1.752415067406111

Epoch: 6| Step: 12
Training loss: 0.9875375628471375
Validation loss: 1.705366938344894

Epoch: 6| Step: 13
Training loss: 1.1212990283966064
Validation loss: 1.741421986651677

Epoch: 662| Step: 0
Training loss: 0.934589147567749
Validation loss: 1.754364094426555

Epoch: 6| Step: 1
Training loss: 0.9003595113754272
Validation loss: 1.7584277519615747

Epoch: 6| Step: 2
Training loss: 0.8860489726066589
Validation loss: 1.7749563699127526

Epoch: 6| Step: 3
Training loss: 0.7003925442695618
Validation loss: 1.7997918090512675

Epoch: 6| Step: 4
Training loss: 0.768868088722229
Validation loss: 1.792266873903172

Epoch: 6| Step: 5
Training loss: 0.6279202103614807
Validation loss: 1.8067016614380704

Epoch: 6| Step: 6
Training loss: 0.8814902901649475
Validation loss: 1.770562461627427

Epoch: 6| Step: 7
Training loss: 0.8428019881248474
Validation loss: 1.7180844109545472

Epoch: 6| Step: 8
Training loss: 0.8141114711761475
Validation loss: 1.7305334691078431

Epoch: 6| Step: 9
Training loss: 0.7563813328742981
Validation loss: 1.7872916767674107

Epoch: 6| Step: 10
Training loss: 0.8902643322944641
Validation loss: 1.7420535395222325

Epoch: 6| Step: 11
Training loss: 0.7615142464637756
Validation loss: 1.7750194252178233

Epoch: 6| Step: 12
Training loss: 1.1317862272262573
Validation loss: 1.7439612252737886

Epoch: 6| Step: 13
Training loss: 1.3714032173156738
Validation loss: 1.7054972904984669

Epoch: 663| Step: 0
Training loss: 0.5816755890846252
Validation loss: 1.7289265522392847

Epoch: 6| Step: 1
Training loss: 1.060474157333374
Validation loss: 1.6367592811584473

Epoch: 6| Step: 2
Training loss: 1.1805325746536255
Validation loss: 1.7269100873701033

Epoch: 6| Step: 3
Training loss: 1.0662422180175781
Validation loss: 1.7077825607792023

Epoch: 6| Step: 4
Training loss: 1.4002796411514282
Validation loss: 1.6825352932817192

Epoch: 6| Step: 5
Training loss: 0.7413256168365479
Validation loss: 1.7130085755419988

Epoch: 6| Step: 6
Training loss: 0.821086049079895
Validation loss: 1.7534651166649275

Epoch: 6| Step: 7
Training loss: 0.48850157856941223
Validation loss: 1.6951073062035344

Epoch: 6| Step: 8
Training loss: 0.8954488039016724
Validation loss: 1.6942084912330873

Epoch: 6| Step: 9
Training loss: 0.7953237295150757
Validation loss: 1.7653707227399271

Epoch: 6| Step: 10
Training loss: 0.3729884624481201
Validation loss: 1.7758936920473654

Epoch: 6| Step: 11
Training loss: 0.7739182710647583
Validation loss: 1.805350629232263

Epoch: 6| Step: 12
Training loss: 0.8202970027923584
Validation loss: 1.7585677972403906

Epoch: 6| Step: 13
Training loss: 0.922532320022583
Validation loss: 1.770604484824724

Epoch: 664| Step: 0
Training loss: 0.5847535133361816
Validation loss: 1.7407307291543612

Epoch: 6| Step: 1
Training loss: 1.4471044540405273
Validation loss: 1.7323115371888684

Epoch: 6| Step: 2
Training loss: 1.295098066329956
Validation loss: 1.6990789854398338

Epoch: 6| Step: 3
Training loss: 0.8818355798721313
Validation loss: 1.7106204135443575

Epoch: 6| Step: 4
Training loss: 0.3699304163455963
Validation loss: 1.7322616269511562

Epoch: 6| Step: 5
Training loss: 0.8518878817558289
Validation loss: 1.6543735111913374

Epoch: 6| Step: 6
Training loss: 1.0193641185760498
Validation loss: 1.7595951826341691

Epoch: 6| Step: 7
Training loss: 0.5560269951820374
Validation loss: 1.7286411985274284

Epoch: 6| Step: 8
Training loss: 0.7501243948936462
Validation loss: 1.7527442478364514

Epoch: 6| Step: 9
Training loss: 0.9017869830131531
Validation loss: 1.7209304250696653

Epoch: 6| Step: 10
Training loss: 0.9076200723648071
Validation loss: 1.7396979331970215

Epoch: 6| Step: 11
Training loss: 0.8579859733581543
Validation loss: 1.7221281554109307

Epoch: 6| Step: 12
Training loss: 0.6270928382873535
Validation loss: 1.7076661586761475

Epoch: 6| Step: 13
Training loss: 0.8057393431663513
Validation loss: 1.7112862948448426

Epoch: 665| Step: 0
Training loss: 0.9469701051712036
Validation loss: 1.703557841239437

Epoch: 6| Step: 1
Training loss: 0.7149990797042847
Validation loss: 1.807294572553327

Epoch: 6| Step: 2
Training loss: 1.0991407632827759
Validation loss: 1.75261946903762

Epoch: 6| Step: 3
Training loss: 0.5385233163833618
Validation loss: 1.745775415051368

Epoch: 6| Step: 4
Training loss: 0.6105070114135742
Validation loss: 1.8061600782537972

Epoch: 6| Step: 5
Training loss: 0.6745721101760864
Validation loss: 1.8078823551054923

Epoch: 6| Step: 6
Training loss: 0.7081475853919983
Validation loss: 1.7038296884106052

Epoch: 6| Step: 7
Training loss: 0.5232772827148438
Validation loss: 1.7286111103591097

Epoch: 6| Step: 8
Training loss: 1.7222884893417358
Validation loss: 1.7579029067870109

Epoch: 6| Step: 9
Training loss: 0.8411054015159607
Validation loss: 1.6534481253675235

Epoch: 6| Step: 10
Training loss: 0.6158344745635986
Validation loss: 1.7307270470485892

Epoch: 6| Step: 11
Training loss: 1.3496603965759277
Validation loss: 1.7548474118273745

Epoch: 6| Step: 12
Training loss: 0.6758652925491333
Validation loss: 1.741254163044755

Epoch: 6| Step: 13
Training loss: 1.8452374935150146
Validation loss: 1.7617438800873295

Epoch: 666| Step: 0
Training loss: 1.630711555480957
Validation loss: 1.7014973522514425

Epoch: 6| Step: 1
Training loss: 0.8432139158248901
Validation loss: 1.6949160611757668

Epoch: 6| Step: 2
Training loss: 1.1654483079910278
Validation loss: 1.7018172087207917

Epoch: 6| Step: 3
Training loss: 1.1096465587615967
Validation loss: 1.71973144431268

Epoch: 6| Step: 4
Training loss: 1.1082912683486938
Validation loss: 1.746835038226138

Epoch: 6| Step: 5
Training loss: 0.9337731599807739
Validation loss: 1.7423911004938104

Epoch: 6| Step: 6
Training loss: 0.81184321641922
Validation loss: 1.6973748155819472

Epoch: 6| Step: 7
Training loss: 0.7885746359825134
Validation loss: 1.7100718880212435

Epoch: 6| Step: 8
Training loss: 0.5766121745109558
Validation loss: 1.751633721013223

Epoch: 6| Step: 9
Training loss: 0.7859254479408264
Validation loss: 1.722494814985542

Epoch: 6| Step: 10
Training loss: 0.6483024954795837
Validation loss: 1.698065976942739

Epoch: 6| Step: 11
Training loss: 0.7183724045753479
Validation loss: 1.7103599476557907

Epoch: 6| Step: 12
Training loss: 0.5368940234184265
Validation loss: 1.7002016100832211

Epoch: 6| Step: 13
Training loss: 0.6349239349365234
Validation loss: 1.665859459548868

Epoch: 667| Step: 0
Training loss: 1.1012400388717651
Validation loss: 1.7818030324033511

Epoch: 6| Step: 1
Training loss: 0.9855681657791138
Validation loss: 1.7827572284206268

Epoch: 6| Step: 2
Training loss: 0.47618991136550903
Validation loss: 1.7977765067931144

Epoch: 6| Step: 3
Training loss: 0.8533565998077393
Validation loss: 1.747687138536925

Epoch: 6| Step: 4
Training loss: 0.6023527383804321
Validation loss: 1.7522686860894645

Epoch: 6| Step: 5
Training loss: 0.8198111057281494
Validation loss: 1.747610249826985

Epoch: 6| Step: 6
Training loss: 1.1831037998199463
Validation loss: 1.718561239140008

Epoch: 6| Step: 7
Training loss: 0.7838828563690186
Validation loss: 1.725188498855919

Epoch: 6| Step: 8
Training loss: 0.8863022923469543
Validation loss: 1.722149174700501

Epoch: 6| Step: 9
Training loss: 0.7377231121063232
Validation loss: 1.7409288088480632

Epoch: 6| Step: 10
Training loss: 1.116302251815796
Validation loss: 1.770171606412498

Epoch: 6| Step: 11
Training loss: 0.47989505529403687
Validation loss: 1.7198563442435315

Epoch: 6| Step: 12
Training loss: 0.9114198684692383
Validation loss: 1.7374532197111396

Epoch: 6| Step: 13
Training loss: 1.1273189783096313
Validation loss: 1.7552297025598504

Epoch: 668| Step: 0
Training loss: 0.9115886688232422
Validation loss: 1.7479826622111823

Epoch: 6| Step: 1
Training loss: 0.7515934109687805
Validation loss: 1.7691603437546761

Epoch: 6| Step: 2
Training loss: 0.5130771398544312
Validation loss: 1.744327777175493

Epoch: 6| Step: 3
Training loss: 0.9955781102180481
Validation loss: 1.7347065646161315

Epoch: 6| Step: 4
Training loss: 0.5764317512512207
Validation loss: 1.7515874396088302

Epoch: 6| Step: 5
Training loss: 0.9116198420524597
Validation loss: 1.7236887190931587

Epoch: 6| Step: 6
Training loss: 0.49962127208709717
Validation loss: 1.6559313369053665

Epoch: 6| Step: 7
Training loss: 0.836580753326416
Validation loss: 1.6907158038949455

Epoch: 6| Step: 8
Training loss: 0.7791025638580322
Validation loss: 1.7260086139043171

Epoch: 6| Step: 9
Training loss: 1.374898910522461
Validation loss: 1.7435602411147086

Epoch: 6| Step: 10
Training loss: 1.0072767734527588
Validation loss: 1.7140258255825247

Epoch: 6| Step: 11
Training loss: 1.0474199056625366
Validation loss: 1.7000364013897475

Epoch: 6| Step: 12
Training loss: 0.6480615139007568
Validation loss: 1.711810205572395

Epoch: 6| Step: 13
Training loss: 0.7003297209739685
Validation loss: 1.7446729047324068

Epoch: 669| Step: 0
Training loss: 0.90690016746521
Validation loss: 1.768431762213348

Epoch: 6| Step: 1
Training loss: 0.6292868852615356
Validation loss: 1.7352253801079207

Epoch: 6| Step: 2
Training loss: 1.3468406200408936
Validation loss: 1.7311221835433797

Epoch: 6| Step: 3
Training loss: 0.992373526096344
Validation loss: 1.7396841203012774

Epoch: 6| Step: 4
Training loss: 0.5623615980148315
Validation loss: 1.749237759138948

Epoch: 6| Step: 5
Training loss: 0.6390089988708496
Validation loss: 1.7188397261404222

Epoch: 6| Step: 6
Training loss: 0.5713863372802734
Validation loss: 1.7884304228649344

Epoch: 6| Step: 7
Training loss: 0.7894484996795654
Validation loss: 1.7467311146438762

Epoch: 6| Step: 8
Training loss: 0.7066954970359802
Validation loss: 1.746902879848275

Epoch: 6| Step: 9
Training loss: 0.6160486340522766
Validation loss: 1.75131356716156

Epoch: 6| Step: 10
Training loss: 0.8793587684631348
Validation loss: 1.793559399984216

Epoch: 6| Step: 11
Training loss: 1.2499001026153564
Validation loss: 1.7805696943754792

Epoch: 6| Step: 12
Training loss: 0.8515570759773254
Validation loss: 1.7559946262708275

Epoch: 6| Step: 13
Training loss: 1.335166335105896
Validation loss: 1.7382648298817296

Epoch: 670| Step: 0
Training loss: 0.6876822710037231
Validation loss: 1.7588241087493075

Epoch: 6| Step: 1
Training loss: 1.279745101928711
Validation loss: 1.6944490453248382

Epoch: 6| Step: 2
Training loss: 0.8095159530639648
Validation loss: 1.7039938293477541

Epoch: 6| Step: 3
Training loss: 0.5625545978546143
Validation loss: 1.7114670840642785

Epoch: 6| Step: 4
Training loss: 0.789474368095398
Validation loss: 1.740859136786512

Epoch: 6| Step: 5
Training loss: 0.5784218311309814
Validation loss: 1.7212278983926261

Epoch: 6| Step: 6
Training loss: 0.8067028522491455
Validation loss: 1.7742970515322942

Epoch: 6| Step: 7
Training loss: 1.1077477931976318
Validation loss: 1.729784842460386

Epoch: 6| Step: 8
Training loss: 1.0618128776550293
Validation loss: 1.7408537249411307

Epoch: 6| Step: 9
Training loss: 0.977792501449585
Validation loss: 1.6960253779606154

Epoch: 6| Step: 10
Training loss: 0.7390094995498657
Validation loss: 1.7707835499958327

Epoch: 6| Step: 11
Training loss: 0.6799969673156738
Validation loss: 1.7393179632002307

Epoch: 6| Step: 12
Training loss: 0.9737213850021362
Validation loss: 1.7368773132242181

Epoch: 6| Step: 13
Training loss: 0.8277275562286377
Validation loss: 1.729201578324841

Epoch: 671| Step: 0
Training loss: 0.7538252472877502
Validation loss: 1.7724165211441696

Epoch: 6| Step: 1
Training loss: 1.197957992553711
Validation loss: 1.7283971591662335

Epoch: 6| Step: 2
Training loss: 0.5859763026237488
Validation loss: 1.6862905781756166

Epoch: 6| Step: 3
Training loss: 0.65525221824646
Validation loss: 1.721586383799071

Epoch: 6| Step: 4
Training loss: 0.7474296689033508
Validation loss: 1.7383941540154078

Epoch: 6| Step: 5
Training loss: 1.0427677631378174
Validation loss: 1.718321761777324

Epoch: 6| Step: 6
Training loss: 0.9378597736358643
Validation loss: 1.6448597113291423

Epoch: 6| Step: 7
Training loss: 1.1094956398010254
Validation loss: 1.6889836429267802

Epoch: 6| Step: 8
Training loss: 0.7595322728157043
Validation loss: 1.7613345781962078

Epoch: 6| Step: 9
Training loss: 1.1418523788452148
Validation loss: 1.7456183677078576

Epoch: 6| Step: 10
Training loss: 1.026029109954834
Validation loss: 1.7641580438101163

Epoch: 6| Step: 11
Training loss: 0.9694435596466064
Validation loss: 1.7163319280070644

Epoch: 6| Step: 12
Training loss: 0.9197213649749756
Validation loss: 1.7556060501324233

Epoch: 6| Step: 13
Training loss: 0.29852327704429626
Validation loss: 1.7098656110866095

Epoch: 672| Step: 0
Training loss: 0.6327857971191406
Validation loss: 1.7014083580304218

Epoch: 6| Step: 1
Training loss: 1.114355444908142
Validation loss: 1.7968547139116513

Epoch: 6| Step: 2
Training loss: 0.5112931728363037
Validation loss: 1.78600444844974

Epoch: 6| Step: 3
Training loss: 0.5622992515563965
Validation loss: 1.7055396110780778

Epoch: 6| Step: 4
Training loss: 1.008194923400879
Validation loss: 1.7527313001694218

Epoch: 6| Step: 5
Training loss: 0.8819750547409058
Validation loss: 1.74017337958018

Epoch: 6| Step: 6
Training loss: 0.9771853089332581
Validation loss: 1.6963110290547854

Epoch: 6| Step: 7
Training loss: 1.1125462055206299
Validation loss: 1.7167939639860583

Epoch: 6| Step: 8
Training loss: 0.6406025886535645
Validation loss: 1.6919286456159366

Epoch: 6| Step: 9
Training loss: 0.9301191568374634
Validation loss: 1.7275394547370173

Epoch: 6| Step: 10
Training loss: 0.5798735618591309
Validation loss: 1.709029648893623

Epoch: 6| Step: 11
Training loss: 0.9553073644638062
Validation loss: 1.7108328227073915

Epoch: 6| Step: 12
Training loss: 0.9356171488761902
Validation loss: 1.673151111090055

Epoch: 6| Step: 13
Training loss: 1.2698146104812622
Validation loss: 1.7275067567825317

Epoch: 673| Step: 0
Training loss: 0.7886687517166138
Validation loss: 1.7305516145562614

Epoch: 6| Step: 1
Training loss: 0.8820309042930603
Validation loss: 1.7420043701766639

Epoch: 6| Step: 2
Training loss: 0.8557166457176208
Validation loss: 1.7503923139264506

Epoch: 6| Step: 3
Training loss: 0.767438530921936
Validation loss: 1.6369650799741027

Epoch: 6| Step: 4
Training loss: 0.6401231288909912
Validation loss: 1.7792402057237522

Epoch: 6| Step: 5
Training loss: 0.7227480411529541
Validation loss: 1.7179229772219093

Epoch: 6| Step: 6
Training loss: 1.0819247961044312
Validation loss: 1.6933921370455014

Epoch: 6| Step: 7
Training loss: 0.828129768371582
Validation loss: 1.6821500575670632

Epoch: 6| Step: 8
Training loss: 0.8919175863265991
Validation loss: 1.798353474627259

Epoch: 6| Step: 9
Training loss: 0.47941070795059204
Validation loss: 1.7538353179090767

Epoch: 6| Step: 10
Training loss: 1.1484113931655884
Validation loss: 1.6987303662043747

Epoch: 6| Step: 11
Training loss: 1.0394792556762695
Validation loss: 1.716691984925219

Epoch: 6| Step: 12
Training loss: 0.6676220297813416
Validation loss: 1.732055635862453

Epoch: 6| Step: 13
Training loss: 0.9839537739753723
Validation loss: 1.668590214944655

Epoch: 674| Step: 0
Training loss: 1.190063238143921
Validation loss: 1.6911768349268104

Epoch: 6| Step: 1
Training loss: 0.67558354139328
Validation loss: 1.7431044386279198

Epoch: 6| Step: 2
Training loss: 1.1106505393981934
Validation loss: 1.7192751130750101

Epoch: 6| Step: 3
Training loss: 0.8564296960830688
Validation loss: 1.6963204991432927

Epoch: 6| Step: 4
Training loss: 0.553716778755188
Validation loss: 1.723864149021846

Epoch: 6| Step: 5
Training loss: 0.9118644595146179
Validation loss: 1.7202431655699206

Epoch: 6| Step: 6
Training loss: 0.5302634835243225
Validation loss: 1.7382147312164307

Epoch: 6| Step: 7
Training loss: 0.32635509967803955
Validation loss: 1.695178758713507

Epoch: 6| Step: 8
Training loss: 0.8454796075820923
Validation loss: 1.7291937989573325

Epoch: 6| Step: 9
Training loss: 0.9078026413917542
Validation loss: 1.6934844780993719

Epoch: 6| Step: 10
Training loss: 1.2922067642211914
Validation loss: 1.6957372388532084

Epoch: 6| Step: 11
Training loss: 0.6991806626319885
Validation loss: 1.6874751621677029

Epoch: 6| Step: 12
Training loss: 0.803041934967041
Validation loss: 1.7170947264599543

Epoch: 6| Step: 13
Training loss: 0.8282526135444641
Validation loss: 1.7466245723027054

Epoch: 675| Step: 0
Training loss: 1.0174962282180786
Validation loss: 1.7256699967127975

Epoch: 6| Step: 1
Training loss: 0.7052209973335266
Validation loss: 1.7002232946375364

Epoch: 6| Step: 2
Training loss: 0.6931592226028442
Validation loss: 1.7353670699622041

Epoch: 6| Step: 3
Training loss: 0.4749876856803894
Validation loss: 1.7581129548370198

Epoch: 6| Step: 4
Training loss: 1.282262921333313
Validation loss: 1.735140037792985

Epoch: 6| Step: 5
Training loss: 0.9344097375869751
Validation loss: 1.725634636417512

Epoch: 6| Step: 6
Training loss: 1.0733671188354492
Validation loss: 1.809609825893115

Epoch: 6| Step: 7
Training loss: 1.0983750820159912
Validation loss: 1.7248693512332054

Epoch: 6| Step: 8
Training loss: 0.6038148403167725
Validation loss: 1.7716886535767586

Epoch: 6| Step: 9
Training loss: 0.80907142162323
Validation loss: 1.6875907990240282

Epoch: 6| Step: 10
Training loss: 0.5695600509643555
Validation loss: 1.7472443529354629

Epoch: 6| Step: 11
Training loss: 1.4798914194107056
Validation loss: 1.689544798225485

Epoch: 6| Step: 12
Training loss: 0.863489031791687
Validation loss: 1.7207548028679305

Epoch: 6| Step: 13
Training loss: 0.5940937399864197
Validation loss: 1.6795757906411284

Epoch: 676| Step: 0
Training loss: 1.9619998931884766
Validation loss: 1.7076611929042365

Epoch: 6| Step: 1
Training loss: 0.9191256761550903
Validation loss: 1.6778713964646863

Epoch: 6| Step: 2
Training loss: 0.7918152213096619
Validation loss: 1.7049924917118524

Epoch: 6| Step: 3
Training loss: 0.7570011615753174
Validation loss: 1.6914239673204319

Epoch: 6| Step: 4
Training loss: 0.723284125328064
Validation loss: 1.7599928840514152

Epoch: 6| Step: 5
Training loss: 0.8269674777984619
Validation loss: 1.650007095388187

Epoch: 6| Step: 6
Training loss: 0.656636118888855
Validation loss: 1.7794729176387991

Epoch: 6| Step: 7
Training loss: 1.0429637432098389
Validation loss: 1.6932319107876028

Epoch: 6| Step: 8
Training loss: 0.8575085401535034
Validation loss: 1.7647872586404123

Epoch: 6| Step: 9
Training loss: 0.8744248747825623
Validation loss: 1.713043866618987

Epoch: 6| Step: 10
Training loss: 0.8408781290054321
Validation loss: 1.7575059065254786

Epoch: 6| Step: 11
Training loss: 0.6177136301994324
Validation loss: 1.742164461843429

Epoch: 6| Step: 12
Training loss: 0.3922417461872101
Validation loss: 1.7626518664821502

Epoch: 6| Step: 13
Training loss: 0.6946263909339905
Validation loss: 1.7445561834560928

Epoch: 677| Step: 0
Training loss: 1.1949012279510498
Validation loss: 1.6973498418766966

Epoch: 6| Step: 1
Training loss: 0.6154102087020874
Validation loss: 1.6916343319800593

Epoch: 6| Step: 2
Training loss: 0.6093232035636902
Validation loss: 1.731442375849652

Epoch: 6| Step: 3
Training loss: 1.115795373916626
Validation loss: 1.7326652414055281

Epoch: 6| Step: 4
Training loss: 0.7556313276290894
Validation loss: 1.7145271044905468

Epoch: 6| Step: 5
Training loss: 0.7766100764274597
Validation loss: 1.714739453408026

Epoch: 6| Step: 6
Training loss: 1.1561051607131958
Validation loss: 1.7514277209517777

Epoch: 6| Step: 7
Training loss: 0.7262324690818787
Validation loss: 1.7736964764133576

Epoch: 6| Step: 8
Training loss: 1.0126806497573853
Validation loss: 1.75780919162176

Epoch: 6| Step: 9
Training loss: 1.1098588705062866
Validation loss: 1.7757433396513744

Epoch: 6| Step: 10
Training loss: 0.9164208769798279
Validation loss: 1.6792012222351567

Epoch: 6| Step: 11
Training loss: 0.4675130546092987
Validation loss: 1.69852795972619

Epoch: 6| Step: 12
Training loss: 0.6782492995262146
Validation loss: 1.7435534051669541

Epoch: 6| Step: 13
Training loss: 0.6994521617889404
Validation loss: 1.6725055953507781

Epoch: 678| Step: 0
Training loss: 1.0014541149139404
Validation loss: 1.7208283280813566

Epoch: 6| Step: 1
Training loss: 0.9087175130844116
Validation loss: 1.7382983046193277

Epoch: 6| Step: 2
Training loss: 0.6894323229789734
Validation loss: 1.7634701857002832

Epoch: 6| Step: 3
Training loss: 0.8823329210281372
Validation loss: 1.7331768402489283

Epoch: 6| Step: 4
Training loss: 0.6634865999221802
Validation loss: 1.764824285302111

Epoch: 6| Step: 5
Training loss: 0.4142221212387085
Validation loss: 1.7374083842000654

Epoch: 6| Step: 6
Training loss: 0.8681901693344116
Validation loss: 1.719145304413252

Epoch: 6| Step: 7
Training loss: 1.0893926620483398
Validation loss: 1.6936497431929394

Epoch: 6| Step: 8
Training loss: 0.9579977989196777
Validation loss: 1.711387688113797

Epoch: 6| Step: 9
Training loss: 0.5651491284370422
Validation loss: 1.8017795649907922

Epoch: 6| Step: 10
Training loss: 0.5649780035018921
Validation loss: 1.6936676925228489

Epoch: 6| Step: 11
Training loss: 0.706222414970398
Validation loss: 1.6930111979925504

Epoch: 6| Step: 12
Training loss: 1.1511939764022827
Validation loss: 1.7424216014082714

Epoch: 6| Step: 13
Training loss: 1.3209644556045532
Validation loss: 1.8560629198628087

Epoch: 679| Step: 0
Training loss: 0.9620040655136108
Validation loss: 1.7293207542870634

Epoch: 6| Step: 1
Training loss: 1.1299620866775513
Validation loss: 1.6959399331000544

Epoch: 6| Step: 2
Training loss: 0.4724772572517395
Validation loss: 1.7724293739564958

Epoch: 6| Step: 3
Training loss: 1.0044236183166504
Validation loss: 1.714514970779419

Epoch: 6| Step: 4
Training loss: 0.6197719573974609
Validation loss: 1.7535943279984176

Epoch: 6| Step: 5
Training loss: 0.6920719146728516
Validation loss: 1.7151232060565744

Epoch: 6| Step: 6
Training loss: 0.9718524813652039
Validation loss: 1.7732122969883743

Epoch: 6| Step: 7
Training loss: 0.663694441318512
Validation loss: 1.690997581328115

Epoch: 6| Step: 8
Training loss: 1.0336174964904785
Validation loss: 1.7434054779750046

Epoch: 6| Step: 9
Training loss: 1.1132433414459229
Validation loss: 1.7249547281572897

Epoch: 6| Step: 10
Training loss: 0.8740687966346741
Validation loss: 1.6889597113414476

Epoch: 6| Step: 11
Training loss: 0.45143938064575195
Validation loss: 1.7362886654433383

Epoch: 6| Step: 12
Training loss: 0.5315667390823364
Validation loss: 1.7686664019861529

Epoch: 6| Step: 13
Training loss: 1.1702089309692383
Validation loss: 1.7488510160035984

Epoch: 680| Step: 0
Training loss: 0.6618281602859497
Validation loss: 1.6751202896077146

Epoch: 6| Step: 1
Training loss: 1.0283204317092896
Validation loss: 1.7037745291186916

Epoch: 6| Step: 2
Training loss: 0.6885061860084534
Validation loss: 1.733551376609392

Epoch: 6| Step: 3
Training loss: 0.6562486290931702
Validation loss: 1.6522553607981691

Epoch: 6| Step: 4
Training loss: 0.7070037126541138
Validation loss: 1.734003278516954

Epoch: 6| Step: 5
Training loss: 0.8490830659866333
Validation loss: 1.6930488476189234

Epoch: 6| Step: 6
Training loss: 1.181969165802002
Validation loss: 1.6576257572379163

Epoch: 6| Step: 7
Training loss: 0.47078388929367065
Validation loss: 1.7577912653646162

Epoch: 6| Step: 8
Training loss: 1.503504991531372
Validation loss: 1.7277838619806434

Epoch: 6| Step: 9
Training loss: 0.42925867438316345
Validation loss: 1.740134358406067

Epoch: 6| Step: 10
Training loss: 1.0966784954071045
Validation loss: 1.7812281334271995

Epoch: 6| Step: 11
Training loss: 0.7602792978286743
Validation loss: 1.7774258903277818

Epoch: 6| Step: 12
Training loss: 0.8910526037216187
Validation loss: 1.8104247508510467

Epoch: 6| Step: 13
Training loss: 0.674626886844635
Validation loss: 1.7479005629016506

Epoch: 681| Step: 0
Training loss: 1.0722990036010742
Validation loss: 1.7761766538825086

Epoch: 6| Step: 1
Training loss: 0.6685953736305237
Validation loss: 1.761170518013739

Epoch: 6| Step: 2
Training loss: 0.7101542353630066
Validation loss: 1.7316071692333426

Epoch: 6| Step: 3
Training loss: 0.6503309011459351
Validation loss: 1.7452160068737563

Epoch: 6| Step: 4
Training loss: 0.9632285833358765
Validation loss: 1.700130816428892

Epoch: 6| Step: 5
Training loss: 0.8006424307823181
Validation loss: 1.7203485440182429

Epoch: 6| Step: 6
Training loss: 0.784940779209137
Validation loss: 1.7245472156873314

Epoch: 6| Step: 7
Training loss: 1.3814748525619507
Validation loss: 1.7425947561058948

Epoch: 6| Step: 8
Training loss: 0.6775240302085876
Validation loss: 1.7903196747585008

Epoch: 6| Step: 9
Training loss: 0.45596569776535034
Validation loss: 1.6986033583200106

Epoch: 6| Step: 10
Training loss: 0.896912157535553
Validation loss: 1.6999168613905549

Epoch: 6| Step: 11
Training loss: 0.9412295818328857
Validation loss: 1.7320292483093918

Epoch: 6| Step: 12
Training loss: 0.9461544156074524
Validation loss: 1.696393068118762

Epoch: 6| Step: 13
Training loss: 1.5072542428970337
Validation loss: 1.663694663714337

Epoch: 682| Step: 0
Training loss: 0.7367924451828003
Validation loss: 1.701709606314218

Epoch: 6| Step: 1
Training loss: 1.2983438968658447
Validation loss: 1.7621998248561737

Epoch: 6| Step: 2
Training loss: 0.4362277388572693
Validation loss: 1.760201322135105

Epoch: 6| Step: 3
Training loss: 0.725559651851654
Validation loss: 1.7556057642864924

Epoch: 6| Step: 4
Training loss: 0.754849910736084
Validation loss: 1.666778487543906

Epoch: 6| Step: 5
Training loss: 0.7905412912368774
Validation loss: 1.710077005047952

Epoch: 6| Step: 6
Training loss: 1.1403450965881348
Validation loss: 1.7439841134573824

Epoch: 6| Step: 7
Training loss: 0.7263169288635254
Validation loss: 1.7397699240715272

Epoch: 6| Step: 8
Training loss: 0.6990340352058411
Validation loss: 1.724439932454017

Epoch: 6| Step: 9
Training loss: 0.7015515565872192
Validation loss: 1.6983630221377137

Epoch: 6| Step: 10
Training loss: 1.1398845911026
Validation loss: 1.7326147171758837

Epoch: 6| Step: 11
Training loss: 0.9542828798294067
Validation loss: 1.7274105164312548

Epoch: 6| Step: 12
Training loss: 0.8676684498786926
Validation loss: 1.7506264742984567

Epoch: 6| Step: 13
Training loss: 0.47803741693496704
Validation loss: 1.7417268432596678

Epoch: 683| Step: 0
Training loss: 0.5918294191360474
Validation loss: 1.7421157013985418

Epoch: 6| Step: 1
Training loss: 0.9008198976516724
Validation loss: 1.7346868771378712

Epoch: 6| Step: 2
Training loss: 1.3111789226531982
Validation loss: 1.7337848153165591

Epoch: 6| Step: 3
Training loss: 1.1545355319976807
Validation loss: 1.7603592462437128

Epoch: 6| Step: 4
Training loss: 0.7531752586364746
Validation loss: 1.6955692063095749

Epoch: 6| Step: 5
Training loss: 0.5595937967300415
Validation loss: 1.7663891238550986

Epoch: 6| Step: 6
Training loss: 0.9471927881240845
Validation loss: 1.6653703233247161

Epoch: 6| Step: 7
Training loss: 0.8296398520469666
Validation loss: 1.7566622931470153

Epoch: 6| Step: 8
Training loss: 0.36754798889160156
Validation loss: 1.6929173084997362

Epoch: 6| Step: 9
Training loss: 1.005573034286499
Validation loss: 1.7364199481984621

Epoch: 6| Step: 10
Training loss: 0.8982325792312622
Validation loss: 1.6598213962329331

Epoch: 6| Step: 11
Training loss: 0.6080008745193481
Validation loss: 1.6400467657273816

Epoch: 6| Step: 12
Training loss: 0.7148398160934448
Validation loss: 1.6729087752680625

Epoch: 6| Step: 13
Training loss: 0.32970404624938965
Validation loss: 1.6970135473435926

Epoch: 684| Step: 0
Training loss: 0.607914924621582
Validation loss: 1.697335723907717

Epoch: 6| Step: 1
Training loss: 0.6957109570503235
Validation loss: 1.7700214078349452

Epoch: 6| Step: 2
Training loss: 0.550378143787384
Validation loss: 1.7082874915933097

Epoch: 6| Step: 3
Training loss: 1.192945957183838
Validation loss: 1.7499890058271346

Epoch: 6| Step: 4
Training loss: 0.8529671430587769
Validation loss: 1.754521152024628

Epoch: 6| Step: 5
Training loss: 0.5793660283088684
Validation loss: 1.6730645548912786

Epoch: 6| Step: 6
Training loss: 1.7289831638336182
Validation loss: 1.7610342758958057

Epoch: 6| Step: 7
Training loss: 0.8616155385971069
Validation loss: 1.6666047521816787

Epoch: 6| Step: 8
Training loss: 0.6843644380569458
Validation loss: 1.7343870555200884

Epoch: 6| Step: 9
Training loss: 0.6298027038574219
Validation loss: 1.65363976904141

Epoch: 6| Step: 10
Training loss: 0.5119328498840332
Validation loss: 1.7583787941163587

Epoch: 6| Step: 11
Training loss: 0.9067728519439697
Validation loss: 1.6511940751024472

Epoch: 6| Step: 12
Training loss: 1.0632785558700562
Validation loss: 1.7310060557498728

Epoch: 6| Step: 13
Training loss: 0.5699094533920288
Validation loss: 1.7277243637269544

Epoch: 685| Step: 0
Training loss: 0.7003275752067566
Validation loss: 1.7767436440272997

Epoch: 6| Step: 1
Training loss: 0.9177059531211853
Validation loss: 1.7062978795779649

Epoch: 6| Step: 2
Training loss: 0.7645269632339478
Validation loss: 1.687763496111798

Epoch: 6| Step: 3
Training loss: 0.8424890637397766
Validation loss: 1.7336169205686098

Epoch: 6| Step: 4
Training loss: 1.121983289718628
Validation loss: 1.6829602410716396

Epoch: 6| Step: 5
Training loss: 0.6058996915817261
Validation loss: 1.6672360461245301

Epoch: 6| Step: 6
Training loss: 0.3869183659553528
Validation loss: 1.749605022450929

Epoch: 6| Step: 7
Training loss: 1.0977771282196045
Validation loss: 1.8235524046805598

Epoch: 6| Step: 8
Training loss: 1.5342357158660889
Validation loss: 1.6999000592898297

Epoch: 6| Step: 9
Training loss: 0.9725304841995239
Validation loss: 1.716796882690922

Epoch: 6| Step: 10
Training loss: 0.7873610258102417
Validation loss: 1.7357278780270649

Epoch: 6| Step: 11
Training loss: 0.5573907494544983
Validation loss: 1.7382735366462378

Epoch: 6| Step: 12
Training loss: 0.8558953404426575
Validation loss: 1.708849581339026

Epoch: 6| Step: 13
Training loss: 0.508249819278717
Validation loss: 1.7299026417475876

Epoch: 686| Step: 0
Training loss: 1.0451490879058838
Validation loss: 1.6779788899165329

Epoch: 6| Step: 1
Training loss: 0.8039506673812866
Validation loss: 1.7267584070082633

Epoch: 6| Step: 2
Training loss: 1.334765911102295
Validation loss: 1.7299623591925508

Epoch: 6| Step: 3
Training loss: 0.9731099605560303
Validation loss: 1.7372725676464778

Epoch: 6| Step: 4
Training loss: 1.1252176761627197
Validation loss: 1.7682604020641697

Epoch: 6| Step: 5
Training loss: 0.6627270579338074
Validation loss: 1.7663017229367328

Epoch: 6| Step: 6
Training loss: 1.0991902351379395
Validation loss: 1.731843001099043

Epoch: 6| Step: 7
Training loss: 0.6885833740234375
Validation loss: 1.7557762527978549

Epoch: 6| Step: 8
Training loss: 0.6013785600662231
Validation loss: 1.7519448034224971

Epoch: 6| Step: 9
Training loss: 0.5310009121894836
Validation loss: 1.7262041222664617

Epoch: 6| Step: 10
Training loss: 0.6832264065742493
Validation loss: 1.7313929706491449

Epoch: 6| Step: 11
Training loss: 0.525260329246521
Validation loss: 1.7341486138682212

Epoch: 6| Step: 12
Training loss: 0.7954165935516357
Validation loss: 1.7157008141599677

Epoch: 6| Step: 13
Training loss: 1.434781789779663
Validation loss: 1.763436444344059

Epoch: 687| Step: 0
Training loss: 0.9663746953010559
Validation loss: 1.7106572171693206

Epoch: 6| Step: 1
Training loss: 0.7756339907646179
Validation loss: 1.752982339551372

Epoch: 6| Step: 2
Training loss: 0.619586706161499
Validation loss: 1.745317111092229

Epoch: 6| Step: 3
Training loss: 0.7155466675758362
Validation loss: 1.7612750696879562

Epoch: 6| Step: 4
Training loss: 0.49297115206718445
Validation loss: 1.7082661210849721

Epoch: 6| Step: 5
Training loss: 0.9695329666137695
Validation loss: 1.7515180226295226

Epoch: 6| Step: 6
Training loss: 1.0355899333953857
Validation loss: 1.6911741097768147

Epoch: 6| Step: 7
Training loss: 0.909016489982605
Validation loss: 1.7518737418677217

Epoch: 6| Step: 8
Training loss: 0.563992977142334
Validation loss: 1.7105704930520826

Epoch: 6| Step: 9
Training loss: 1.3018062114715576
Validation loss: 1.7465140563185497

Epoch: 6| Step: 10
Training loss: 0.7438417673110962
Validation loss: 1.725080354239351

Epoch: 6| Step: 11
Training loss: 0.7064744234085083
Validation loss: 1.774328084402187

Epoch: 6| Step: 12
Training loss: 1.299018144607544
Validation loss: 1.7375546040073517

Epoch: 6| Step: 13
Training loss: 0.8677882552146912
Validation loss: 1.7887721279615998

Epoch: 688| Step: 0
Training loss: 0.7720752954483032
Validation loss: 1.6935990189993253

Epoch: 6| Step: 1
Training loss: 0.5635409951210022
Validation loss: 1.6927199004798807

Epoch: 6| Step: 2
Training loss: 0.7790927886962891
Validation loss: 1.7475216183611142

Epoch: 6| Step: 3
Training loss: 1.497690200805664
Validation loss: 1.7181027794397006

Epoch: 6| Step: 4
Training loss: 0.32613223791122437
Validation loss: 1.730526694687464

Epoch: 6| Step: 5
Training loss: 1.2911217212677002
Validation loss: 1.6853733472926642

Epoch: 6| Step: 6
Training loss: 0.9147765040397644
Validation loss: 1.7564219300464918

Epoch: 6| Step: 7
Training loss: 0.9294964671134949
Validation loss: 1.7793429718222669

Epoch: 6| Step: 8
Training loss: 1.389857530593872
Validation loss: 1.7799803057024557

Epoch: 6| Step: 9
Training loss: 0.4638110399246216
Validation loss: 1.8007600243373583

Epoch: 6| Step: 10
Training loss: 0.9366264939308167
Validation loss: 1.834717450603362

Epoch: 6| Step: 11
Training loss: 0.8575094938278198
Validation loss: 1.7910741567611694

Epoch: 6| Step: 12
Training loss: 0.7015023827552795
Validation loss: 1.7246189854478324

Epoch: 6| Step: 13
Training loss: 0.754875123500824
Validation loss: 1.8042944477450462

Epoch: 689| Step: 0
Training loss: 0.6810934543609619
Validation loss: 1.705275817583966

Epoch: 6| Step: 1
Training loss: 1.338174819946289
Validation loss: 1.725588043530782

Epoch: 6| Step: 2
Training loss: 0.7717618346214294
Validation loss: 1.7422093037636048

Epoch: 6| Step: 3
Training loss: 0.5326567888259888
Validation loss: 1.748455826954175

Epoch: 6| Step: 4
Training loss: 0.7206750512123108
Validation loss: 1.7518036519327471

Epoch: 6| Step: 5
Training loss: 1.6386644840240479
Validation loss: 1.7282798482525734

Epoch: 6| Step: 6
Training loss: 0.5935383439064026
Validation loss: 1.7034451474425614

Epoch: 6| Step: 7
Training loss: 0.5563076734542847
Validation loss: 1.738867607167972

Epoch: 6| Step: 8
Training loss: 0.6869284510612488
Validation loss: 1.7439549481996925

Epoch: 6| Step: 9
Training loss: 1.1899160146713257
Validation loss: 1.7323633842570807

Epoch: 6| Step: 10
Training loss: 0.6905049085617065
Validation loss: 1.6895868419319071

Epoch: 6| Step: 11
Training loss: 1.1355361938476562
Validation loss: 1.746916982435411

Epoch: 6| Step: 12
Training loss: 0.7542359828948975
Validation loss: 1.6934819477860645

Epoch: 6| Step: 13
Training loss: 0.6164005994796753
Validation loss: 1.7932408291806456

Epoch: 690| Step: 0
Training loss: 0.378506064414978
Validation loss: 1.74442768737834

Epoch: 6| Step: 1
Training loss: 1.1210194826126099
Validation loss: 1.7191129166592833

Epoch: 6| Step: 2
Training loss: 0.64699387550354
Validation loss: 1.652855723134933

Epoch: 6| Step: 3
Training loss: 0.6860902309417725
Validation loss: 1.7096746865139212

Epoch: 6| Step: 4
Training loss: 0.591192901134491
Validation loss: 1.7193216559707478

Epoch: 6| Step: 5
Training loss: 0.6775998473167419
Validation loss: 1.675954209860935

Epoch: 6| Step: 6
Training loss: 1.2123444080352783
Validation loss: 1.6908288937742992

Epoch: 6| Step: 7
Training loss: 0.6296680569648743
Validation loss: 1.7440635965716453

Epoch: 6| Step: 8
Training loss: 0.8466001749038696
Validation loss: 1.681321906787093

Epoch: 6| Step: 9
Training loss: 0.9536544680595398
Validation loss: 1.7719483721640803

Epoch: 6| Step: 10
Training loss: 0.845283567905426
Validation loss: 1.7333390148737098

Epoch: 6| Step: 11
Training loss: 1.033900260925293
Validation loss: 1.7438267969316052

Epoch: 6| Step: 12
Training loss: 0.8516983985900879
Validation loss: 1.651664633904734

Epoch: 6| Step: 13
Training loss: 1.0508954524993896
Validation loss: 1.7724529248411938

Epoch: 691| Step: 0
Training loss: 0.9735268950462341
Validation loss: 1.6807990368976389

Epoch: 6| Step: 1
Training loss: 0.9661238193511963
Validation loss: 1.7217269212968889

Epoch: 6| Step: 2
Training loss: 0.38492780923843384
Validation loss: 1.710569820096416

Epoch: 6| Step: 3
Training loss: 0.9536664485931396
Validation loss: 1.7397006647561186

Epoch: 6| Step: 4
Training loss: 0.9160385727882385
Validation loss: 1.6534738784195275

Epoch: 6| Step: 5
Training loss: 0.6940101385116577
Validation loss: 1.7003939420946184

Epoch: 6| Step: 6
Training loss: 0.6959484815597534
Validation loss: 1.7606707196081839

Epoch: 6| Step: 7
Training loss: 0.8737070560455322
Validation loss: 1.692393954082202

Epoch: 6| Step: 8
Training loss: 1.129414677619934
Validation loss: 1.7462986605141753

Epoch: 6| Step: 9
Training loss: 0.8106158971786499
Validation loss: 1.6951927920823455

Epoch: 6| Step: 10
Training loss: 0.9556278586387634
Validation loss: 1.7218975072265954

Epoch: 6| Step: 11
Training loss: 0.7510096430778503
Validation loss: 1.7440592883735575

Epoch: 6| Step: 12
Training loss: 0.7619192004203796
Validation loss: 1.653985450344701

Epoch: 6| Step: 13
Training loss: 0.4341343343257904
Validation loss: 1.738341272518199

Epoch: 692| Step: 0
Training loss: 1.0094993114471436
Validation loss: 1.7119910088918542

Epoch: 6| Step: 1
Training loss: 1.2407197952270508
Validation loss: 1.708924728055154

Epoch: 6| Step: 2
Training loss: 0.8602032661437988
Validation loss: 1.7047022465736634

Epoch: 6| Step: 3
Training loss: 0.9420006275177002
Validation loss: 1.6922330574322773

Epoch: 6| Step: 4
Training loss: 0.9062908887863159
Validation loss: 1.756478750577537

Epoch: 6| Step: 5
Training loss: 0.7865960597991943
Validation loss: 1.7239582102785829

Epoch: 6| Step: 6
Training loss: 0.5042728781700134
Validation loss: 1.7059999383905882

Epoch: 6| Step: 7
Training loss: 0.8769046068191528
Validation loss: 1.7684535711042342

Epoch: 6| Step: 8
Training loss: 0.9660934209823608
Validation loss: 1.7541297776724702

Epoch: 6| Step: 9
Training loss: 1.171617865562439
Validation loss: 1.7317442022344118

Epoch: 6| Step: 10
Training loss: 0.4544104039669037
Validation loss: 1.7072128236934703

Epoch: 6| Step: 11
Training loss: 0.2659272253513336
Validation loss: 1.7411798636118572

Epoch: 6| Step: 12
Training loss: 0.4793095588684082
Validation loss: 1.7919018883858957

Epoch: 6| Step: 13
Training loss: 1.215220332145691
Validation loss: 1.7332770683432137

Epoch: 693| Step: 0
Training loss: 0.7202268242835999
Validation loss: 1.767406713578009

Epoch: 6| Step: 1
Training loss: 1.5548961162567139
Validation loss: 1.776783356102564

Epoch: 6| Step: 2
Training loss: 0.4326065182685852
Validation loss: 1.7631389582028953

Epoch: 6| Step: 3
Training loss: 0.9016826152801514
Validation loss: 1.7546463807423909

Epoch: 6| Step: 4
Training loss: 0.7146924734115601
Validation loss: 1.7448715522725096

Epoch: 6| Step: 5
Training loss: 0.8651026487350464
Validation loss: 1.704136194721345

Epoch: 6| Step: 6
Training loss: 1.1496860980987549
Validation loss: 1.7084224634273077

Epoch: 6| Step: 7
Training loss: 0.9044931530952454
Validation loss: 1.7467792405877063

Epoch: 6| Step: 8
Training loss: 0.9043110609054565
Validation loss: 1.7373727534406929

Epoch: 6| Step: 9
Training loss: 0.6827555298805237
Validation loss: 1.741827908382621

Epoch: 6| Step: 10
Training loss: 0.6891531944274902
Validation loss: 1.7005979373890867

Epoch: 6| Step: 11
Training loss: 0.5431251525878906
Validation loss: 1.7231382567395446

Epoch: 6| Step: 12
Training loss: 0.9778969883918762
Validation loss: 1.7055889534693893

Epoch: 6| Step: 13
Training loss: 0.3653464615345001
Validation loss: 1.7213417740278347

Epoch: 694| Step: 0
Training loss: 0.9913405179977417
Validation loss: 1.7659622879438504

Epoch: 6| Step: 1
Training loss: 0.818649411201477
Validation loss: 1.7097335387301702

Epoch: 6| Step: 2
Training loss: 1.1157879829406738
Validation loss: 1.7548424364418111

Epoch: 6| Step: 3
Training loss: 0.5691275000572205
Validation loss: 1.6825270704043809

Epoch: 6| Step: 4
Training loss: 0.8320117592811584
Validation loss: 1.7402598909152451

Epoch: 6| Step: 5
Training loss: 1.0283218622207642
Validation loss: 1.7061132871976463

Epoch: 6| Step: 6
Training loss: 0.8787194490432739
Validation loss: 1.7189429113941808

Epoch: 6| Step: 7
Training loss: 0.9055604934692383
Validation loss: 1.7171331887604089

Epoch: 6| Step: 8
Training loss: 1.0163253545761108
Validation loss: 1.732763817233424

Epoch: 6| Step: 9
Training loss: 0.41158974170684814
Validation loss: 1.6924734910329182

Epoch: 6| Step: 10
Training loss: 0.9418419599533081
Validation loss: 1.7288537038269864

Epoch: 6| Step: 11
Training loss: 0.6297963857650757
Validation loss: 1.6917131754659838

Epoch: 6| Step: 12
Training loss: 0.38111287355422974
Validation loss: 1.7515220616453437

Epoch: 6| Step: 13
Training loss: 1.0002402067184448
Validation loss: 1.7544043320481495

Epoch: 695| Step: 0
Training loss: 0.8479247689247131
Validation loss: 1.7132609403261574

Epoch: 6| Step: 1
Training loss: 0.7894189357757568
Validation loss: 1.7431888003503122

Epoch: 6| Step: 2
Training loss: 0.8061252236366272
Validation loss: 1.7356143061832716

Epoch: 6| Step: 3
Training loss: 0.545136570930481
Validation loss: 1.7834148535164454

Epoch: 6| Step: 4
Training loss: 1.20480477809906
Validation loss: 1.7478746162947787

Epoch: 6| Step: 5
Training loss: 0.8176337480545044
Validation loss: 1.7217881987171788

Epoch: 6| Step: 6
Training loss: 0.9886349439620972
Validation loss: 1.7366620494473366

Epoch: 6| Step: 7
Training loss: 0.6778593063354492
Validation loss: 1.7567062788112189

Epoch: 6| Step: 8
Training loss: 0.7290607690811157
Validation loss: 1.7108573682846562

Epoch: 6| Step: 9
Training loss: 0.8395301103591919
Validation loss: 1.7262169686696862

Epoch: 6| Step: 10
Training loss: 1.040277361869812
Validation loss: 1.6775320294082805

Epoch: 6| Step: 11
Training loss: 0.8005340099334717
Validation loss: 1.6784857306429135

Epoch: 6| Step: 12
Training loss: 1.319657564163208
Validation loss: 1.6769355061233684

Epoch: 6| Step: 13
Training loss: 0.651208221912384
Validation loss: 1.7128221040130944

Epoch: 696| Step: 0
Training loss: 0.6651740074157715
Validation loss: 1.6961757765021375

Epoch: 6| Step: 1
Training loss: 0.7403404712677002
Validation loss: 1.7355800379988968

Epoch: 6| Step: 2
Training loss: 0.5737195611000061
Validation loss: 1.698026898086712

Epoch: 6| Step: 3
Training loss: 0.5817853212356567
Validation loss: 1.7031582094007922

Epoch: 6| Step: 4
Training loss: 0.7096553444862366
Validation loss: 1.7283865815849715

Epoch: 6| Step: 5
Training loss: 0.7056015729904175
Validation loss: 1.7155969091641006

Epoch: 6| Step: 6
Training loss: 0.8974975943565369
Validation loss: 1.773536325782858

Epoch: 6| Step: 7
Training loss: 0.7703121900558472
Validation loss: 1.7165114738607918

Epoch: 6| Step: 8
Training loss: 1.4586668014526367
Validation loss: 1.7497493169640983

Epoch: 6| Step: 9
Training loss: 1.0785506963729858
Validation loss: 1.722911177142974

Epoch: 6| Step: 10
Training loss: 0.8540538549423218
Validation loss: 1.7798290637231642

Epoch: 6| Step: 11
Training loss: 0.5569022297859192
Validation loss: 1.738223063048496

Epoch: 6| Step: 12
Training loss: 0.7710087895393372
Validation loss: 1.727633769794177

Epoch: 6| Step: 13
Training loss: 0.47282150387763977
Validation loss: 1.7422759148382372

Epoch: 697| Step: 0
Training loss: 1.2909958362579346
Validation loss: 1.7545735759119834

Epoch: 6| Step: 1
Training loss: 0.6215238571166992
Validation loss: 1.7248418561873897

Epoch: 6| Step: 2
Training loss: 0.7929667234420776
Validation loss: 1.7615321361890404

Epoch: 6| Step: 3
Training loss: 0.3890608549118042
Validation loss: 1.6995636596474597

Epoch: 6| Step: 4
Training loss: 0.6698015332221985
Validation loss: 1.6911781603290188

Epoch: 6| Step: 5
Training loss: 1.2090210914611816
Validation loss: 1.7207984744861562

Epoch: 6| Step: 6
Training loss: 0.8012205958366394
Validation loss: 1.7406683967959495

Epoch: 6| Step: 7
Training loss: 0.5262449979782104
Validation loss: 1.7664689171698786

Epoch: 6| Step: 8
Training loss: 1.264652967453003
Validation loss: 1.7160564007297638

Epoch: 6| Step: 9
Training loss: 1.0112489461898804
Validation loss: 1.640479245493489

Epoch: 6| Step: 10
Training loss: 0.7496457099914551
Validation loss: 1.704760834734927

Epoch: 6| Step: 11
Training loss: 0.6489095687866211
Validation loss: 1.7053523294387325

Epoch: 6| Step: 12
Training loss: 1.0725455284118652
Validation loss: 1.727138303941296

Epoch: 6| Step: 13
Training loss: 0.3895062804222107
Validation loss: 1.751488083793271

Epoch: 698| Step: 0
Training loss: 0.5534024834632874
Validation loss: 1.7196826165722263

Epoch: 6| Step: 1
Training loss: 1.2659127712249756
Validation loss: 1.6948340708209622

Epoch: 6| Step: 2
Training loss: 0.7003995180130005
Validation loss: 1.7127350376498314

Epoch: 6| Step: 3
Training loss: 0.6172678470611572
Validation loss: 1.7079101967555221

Epoch: 6| Step: 4
Training loss: 0.5178284049034119
Validation loss: 1.6817308882231354

Epoch: 6| Step: 5
Training loss: 0.6853170394897461
Validation loss: 1.7330811228803409

Epoch: 6| Step: 6
Training loss: 1.1806304454803467
Validation loss: 1.7255181779143631

Epoch: 6| Step: 7
Training loss: 0.8781751394271851
Validation loss: 1.661238174284658

Epoch: 6| Step: 8
Training loss: 1.1207174062728882
Validation loss: 1.6848705314820813

Epoch: 6| Step: 9
Training loss: 0.7265602946281433
Validation loss: 1.7237730487700431

Epoch: 6| Step: 10
Training loss: 0.7213776707649231
Validation loss: 1.7331188673614173

Epoch: 6| Step: 11
Training loss: 0.9065365195274353
Validation loss: 1.7212986459014237

Epoch: 6| Step: 12
Training loss: 0.5347837805747986
Validation loss: 1.7121676860317108

Epoch: 6| Step: 13
Training loss: 0.9452706575393677
Validation loss: 1.7487629639205111

Epoch: 699| Step: 0
Training loss: 1.0619398355484009
Validation loss: 1.7055712053852696

Epoch: 6| Step: 1
Training loss: 0.9788951873779297
Validation loss: 1.765586563335952

Epoch: 6| Step: 2
Training loss: 1.1236045360565186
Validation loss: 1.7769114996797295

Epoch: 6| Step: 3
Training loss: 0.6660577058792114
Validation loss: 1.7702721293254564

Epoch: 6| Step: 4
Training loss: 1.0861735343933105
Validation loss: 1.7157991073464836

Epoch: 6| Step: 5
Training loss: 0.8118133544921875
Validation loss: 1.7389080960263488

Epoch: 6| Step: 6
Training loss: 0.45985090732574463
Validation loss: 1.7268717570971417

Epoch: 6| Step: 7
Training loss: 1.4842066764831543
Validation loss: 1.6608491674546273

Epoch: 6| Step: 8
Training loss: 0.3735119104385376
Validation loss: 1.7451025926938621

Epoch: 6| Step: 9
Training loss: 0.6923692226409912
Validation loss: 1.7648213499335832

Epoch: 6| Step: 10
Training loss: 1.1515460014343262
Validation loss: 1.69543336027412

Epoch: 6| Step: 11
Training loss: 0.7093459963798523
Validation loss: 1.734857616886016

Epoch: 6| Step: 12
Training loss: 0.40007221698760986
Validation loss: 1.7372234021463702

Epoch: 6| Step: 13
Training loss: 0.5019206404685974
Validation loss: 1.7038924450515418

Epoch: 700| Step: 0
Training loss: 0.9219691753387451
Validation loss: 1.7021393775939941

Epoch: 6| Step: 1
Training loss: 0.920128583908081
Validation loss: 1.703213163601455

Epoch: 6| Step: 2
Training loss: 0.9626477360725403
Validation loss: 1.749927964261783

Epoch: 6| Step: 3
Training loss: 0.4707641303539276
Validation loss: 1.6943514193257978

Epoch: 6| Step: 4
Training loss: 0.9285452961921692
Validation loss: 1.731202451131677

Epoch: 6| Step: 5
Training loss: 0.48726463317871094
Validation loss: 1.7041840322556034

Epoch: 6| Step: 6
Training loss: 0.6538697481155396
Validation loss: 1.7374727315800165

Epoch: 6| Step: 7
Training loss: 1.0398081541061401
Validation loss: 1.7261338919721625

Epoch: 6| Step: 8
Training loss: 0.7753391265869141
Validation loss: 1.6489093060134559

Epoch: 6| Step: 9
Training loss: 0.7836189270019531
Validation loss: 1.6893985143271826

Epoch: 6| Step: 10
Training loss: 1.5632516145706177
Validation loss: 1.7560179361733057

Epoch: 6| Step: 11
Training loss: 0.47756990790367126
Validation loss: 1.6865871978062454

Epoch: 6| Step: 12
Training loss: 0.6899194717407227
Validation loss: 1.6990207484973374

Epoch: 6| Step: 13
Training loss: 0.9172384738922119
Validation loss: 1.6820664969823693

Epoch: 701| Step: 0
Training loss: 0.6978945732116699
Validation loss: 1.7275533535147225

Epoch: 6| Step: 1
Training loss: 0.7440013885498047
Validation loss: 1.6666245460510254

Epoch: 6| Step: 2
Training loss: 1.0044137239456177
Validation loss: 1.6871532188948763

Epoch: 6| Step: 3
Training loss: 1.1299711465835571
Validation loss: 1.725855778622371

Epoch: 6| Step: 4
Training loss: 0.8029377460479736
Validation loss: 1.7326352827010616

Epoch: 6| Step: 5
Training loss: 0.3055630326271057
Validation loss: 1.7214414599121257

Epoch: 6| Step: 6
Training loss: 1.0741115808486938
Validation loss: 1.8044674088878017

Epoch: 6| Step: 7
Training loss: 1.1147805452346802
Validation loss: 1.7551926207798783

Epoch: 6| Step: 8
Training loss: 1.0995615720748901
Validation loss: 1.7725370096903976

Epoch: 6| Step: 9
Training loss: 0.5709577798843384
Validation loss: 1.712737787154413

Epoch: 6| Step: 10
Training loss: 0.7922171950340271
Validation loss: 1.7470209957450948

Epoch: 6| Step: 11
Training loss: 0.7974626421928406
Validation loss: 1.731545812340193

Epoch: 6| Step: 12
Training loss: 0.601557731628418
Validation loss: 1.6804568344546902

Epoch: 6| Step: 13
Training loss: 0.3038548231124878
Validation loss: 1.7565670859429143

Epoch: 702| Step: 0
Training loss: 1.5922373533248901
Validation loss: 1.671006384716239

Epoch: 6| Step: 1
Training loss: 0.5611881017684937
Validation loss: 1.7314727896003312

Epoch: 6| Step: 2
Training loss: 0.9195057153701782
Validation loss: 1.7251501442283712

Epoch: 6| Step: 3
Training loss: 0.9675127267837524
Validation loss: 1.7004382776957687

Epoch: 6| Step: 4
Training loss: 0.6460788249969482
Validation loss: 1.7309431311904744

Epoch: 6| Step: 5
Training loss: 0.9866739511489868
Validation loss: 1.7450305838738718

Epoch: 6| Step: 6
Training loss: 0.7456027269363403
Validation loss: 1.646828705264676

Epoch: 6| Step: 7
Training loss: 0.7792884111404419
Validation loss: 1.7436162451262116

Epoch: 6| Step: 8
Training loss: 0.5822150111198425
Validation loss: 1.6929229638909782

Epoch: 6| Step: 9
Training loss: 0.5616709589958191
Validation loss: 1.7082937673855854

Epoch: 6| Step: 10
Training loss: 0.6596235036849976
Validation loss: 1.7325522463808778

Epoch: 6| Step: 11
Training loss: 0.9466208219528198
Validation loss: 1.7071336764161305

Epoch: 6| Step: 12
Training loss: 1.0658676624298096
Validation loss: 1.7498685288172897

Epoch: 6| Step: 13
Training loss: 0.4183740019798279
Validation loss: 1.7672795352115427

Epoch: 703| Step: 0
Training loss: 0.7691428661346436
Validation loss: 1.734876235326131

Epoch: 6| Step: 1
Training loss: 0.6764849424362183
Validation loss: 1.7582592348898611

Epoch: 6| Step: 2
Training loss: 0.414210706949234
Validation loss: 1.7608670701262772

Epoch: 6| Step: 3
Training loss: 0.9722483158111572
Validation loss: 1.7195610461696502

Epoch: 6| Step: 4
Training loss: 0.8629934787750244
Validation loss: 1.7300093212435323

Epoch: 6| Step: 5
Training loss: 0.9790046811103821
Validation loss: 1.7734738613969536

Epoch: 6| Step: 6
Training loss: 0.7402448058128357
Validation loss: 1.7498200811365598

Epoch: 6| Step: 7
Training loss: 0.5931422710418701
Validation loss: 1.7045291572488763

Epoch: 6| Step: 8
Training loss: 1.1155592203140259
Validation loss: 1.7602295183366345

Epoch: 6| Step: 9
Training loss: 0.8147891163825989
Validation loss: 1.690892159297902

Epoch: 6| Step: 10
Training loss: 0.8132368922233582
Validation loss: 1.7426215064141057

Epoch: 6| Step: 11
Training loss: 0.6189389228820801
Validation loss: 1.686540085782287

Epoch: 6| Step: 12
Training loss: 1.0562338829040527
Validation loss: 1.6889467893108245

Epoch: 6| Step: 13
Training loss: 0.4554452896118164
Validation loss: 1.679642108178908

Epoch: 704| Step: 0
Training loss: 0.7232058644294739
Validation loss: 1.7304932148225847

Epoch: 6| Step: 1
Training loss: 0.4225708246231079
Validation loss: 1.7027037989708684

Epoch: 6| Step: 2
Training loss: 0.7723519802093506
Validation loss: 1.6935651443337882

Epoch: 6| Step: 3
Training loss: 0.7474058866500854
Validation loss: 1.715293619581448

Epoch: 6| Step: 4
Training loss: 0.8225518465042114
Validation loss: 1.7040263696383404

Epoch: 6| Step: 5
Training loss: 1.2095699310302734
Validation loss: 1.7119451389517835

Epoch: 6| Step: 6
Training loss: 0.9994816780090332
Validation loss: 1.6710833016262259

Epoch: 6| Step: 7
Training loss: 0.9711212515830994
Validation loss: 1.7146702645927347

Epoch: 6| Step: 8
Training loss: 0.4905439019203186
Validation loss: 1.7308634558031637

Epoch: 6| Step: 9
Training loss: 0.6832784414291382
Validation loss: 1.700113659263939

Epoch: 6| Step: 10
Training loss: 0.728814959526062
Validation loss: 1.7403776466205556

Epoch: 6| Step: 11
Training loss: 0.6894805431365967
Validation loss: 1.714748392822922

Epoch: 6| Step: 12
Training loss: 1.142240047454834
Validation loss: 1.6909018652413481

Epoch: 6| Step: 13
Training loss: 1.0629260540008545
Validation loss: 1.7565103782120572

Epoch: 705| Step: 0
Training loss: 0.7003968954086304
Validation loss: 1.7426680441825622

Epoch: 6| Step: 1
Training loss: 1.1965036392211914
Validation loss: 1.6994268535285868

Epoch: 6| Step: 2
Training loss: 0.5323243141174316
Validation loss: 1.6852042764745734

Epoch: 6| Step: 3
Training loss: 0.7179669141769409
Validation loss: 1.675543010875743

Epoch: 6| Step: 4
Training loss: 0.5588585138320923
Validation loss: 1.7314765914793937

Epoch: 6| Step: 5
Training loss: 1.0014357566833496
Validation loss: 1.6682541293482627

Epoch: 6| Step: 6
Training loss: 0.6969394087791443
Validation loss: 1.7460814701613558

Epoch: 6| Step: 7
Training loss: 1.3567490577697754
Validation loss: 1.673943123509807

Epoch: 6| Step: 8
Training loss: 0.7179909944534302
Validation loss: 1.670988682777651

Epoch: 6| Step: 9
Training loss: 0.6136119365692139
Validation loss: 1.6871131600872162

Epoch: 6| Step: 10
Training loss: 0.9328634738922119
Validation loss: 1.7134774731051536

Epoch: 6| Step: 11
Training loss: 0.6253730058670044
Validation loss: 1.7218781209761096

Epoch: 6| Step: 12
Training loss: 0.5631284713745117
Validation loss: 1.7479281630567325

Epoch: 6| Step: 13
Training loss: 0.6572958827018738
Validation loss: 1.6869361503149873

Epoch: 706| Step: 0
Training loss: 0.6064014434814453
Validation loss: 1.7425150602094588

Epoch: 6| Step: 1
Training loss: 0.3649716377258301
Validation loss: 1.7040593675387803

Epoch: 6| Step: 2
Training loss: 1.2930526733398438
Validation loss: 1.718801349721929

Epoch: 6| Step: 3
Training loss: 0.7489086389541626
Validation loss: 1.7061907783631356

Epoch: 6| Step: 4
Training loss: 1.0139615535736084
Validation loss: 1.7610303548074537

Epoch: 6| Step: 5
Training loss: 0.8104896545410156
Validation loss: 1.6812638236630348

Epoch: 6| Step: 6
Training loss: 0.4045022428035736
Validation loss: 1.7157987369004117

Epoch: 6| Step: 7
Training loss: 1.017953634262085
Validation loss: 1.6995562481623825

Epoch: 6| Step: 8
Training loss: 0.7160331606864929
Validation loss: 1.7801775265765447

Epoch: 6| Step: 9
Training loss: 0.8133314847946167
Validation loss: 1.740454851940114

Epoch: 6| Step: 10
Training loss: 0.5606651902198792
Validation loss: 1.6749800546194917

Epoch: 6| Step: 11
Training loss: 1.0257313251495361
Validation loss: 1.7194533258356073

Epoch: 6| Step: 12
Training loss: 1.1346726417541504
Validation loss: 1.7591601764002154

Epoch: 6| Step: 13
Training loss: 0.7230318188667297
Validation loss: 1.7117527941221833

Epoch: 707| Step: 0
Training loss: 0.9277005791664124
Validation loss: 1.6498174692994805

Epoch: 6| Step: 1
Training loss: 0.7278498411178589
Validation loss: 1.6732534657242477

Epoch: 6| Step: 2
Training loss: 0.563363790512085
Validation loss: 1.7062709600694719

Epoch: 6| Step: 3
Training loss: 0.9693966507911682
Validation loss: 1.6637630129373202

Epoch: 6| Step: 4
Training loss: 0.4568256139755249
Validation loss: 1.7101974128394999

Epoch: 6| Step: 5
Training loss: 0.8462958931922913
Validation loss: 1.678987979888916

Epoch: 6| Step: 6
Training loss: 0.8457973003387451
Validation loss: 1.6862557549630441

Epoch: 6| Step: 7
Training loss: 0.5443634390830994
Validation loss: 1.6676754079839236

Epoch: 6| Step: 8
Training loss: 1.150601863861084
Validation loss: 1.7088817037561888

Epoch: 6| Step: 9
Training loss: 0.9931304454803467
Validation loss: 1.7473591450721986

Epoch: 6| Step: 10
Training loss: 0.8686275482177734
Validation loss: 1.7573659689195695

Epoch: 6| Step: 11
Training loss: 0.5480170249938965
Validation loss: 1.707162400727631

Epoch: 6| Step: 12
Training loss: 0.7440533638000488
Validation loss: 1.7632178080979215

Epoch: 6| Step: 13
Training loss: 1.413511872291565
Validation loss: 1.7267478633952398

Epoch: 708| Step: 0
Training loss: 1.0386496782302856
Validation loss: 1.793737934481713

Epoch: 6| Step: 1
Training loss: 0.9805700778961182
Validation loss: 1.7115754632539646

Epoch: 6| Step: 2
Training loss: 0.25091955065727234
Validation loss: 1.7265531670662664

Epoch: 6| Step: 3
Training loss: 0.8290497064590454
Validation loss: 1.704795152910294

Epoch: 6| Step: 4
Training loss: 0.7435988187789917
Validation loss: 1.6961933182131859

Epoch: 6| Step: 5
Training loss: 0.7759742736816406
Validation loss: 1.6927120800941222

Epoch: 6| Step: 6
Training loss: 1.2137565612792969
Validation loss: 1.7074407249368646

Epoch: 6| Step: 7
Training loss: 0.6542458534240723
Validation loss: 1.7685359062687043

Epoch: 6| Step: 8
Training loss: 0.904815673828125
Validation loss: 1.7049707930575135

Epoch: 6| Step: 9
Training loss: 0.54645836353302
Validation loss: 1.7072834763475644

Epoch: 6| Step: 10
Training loss: 0.8616183996200562
Validation loss: 1.7314077987465808

Epoch: 6| Step: 11
Training loss: 0.9343163371086121
Validation loss: 1.6754497892113143

Epoch: 6| Step: 12
Training loss: 0.9486081004142761
Validation loss: 1.6798698427856609

Epoch: 6| Step: 13
Training loss: 0.9086047410964966
Validation loss: 1.7418828215650333

Epoch: 709| Step: 0
Training loss: 1.7874380350112915
Validation loss: 1.698406514301095

Epoch: 6| Step: 1
Training loss: 0.7495343685150146
Validation loss: 1.6788086160536735

Epoch: 6| Step: 2
Training loss: 0.4179214835166931
Validation loss: 1.773421541337044

Epoch: 6| Step: 3
Training loss: 0.9667449593544006
Validation loss: 1.8059309208264915

Epoch: 6| Step: 4
Training loss: 0.6290233135223389
Validation loss: 1.8091991229723858

Epoch: 6| Step: 5
Training loss: 0.48812150955200195
Validation loss: 1.7757235009183165

Epoch: 6| Step: 6
Training loss: 0.8200975656509399
Validation loss: 1.7918293117195048

Epoch: 6| Step: 7
Training loss: 0.8142368793487549
Validation loss: 1.6988570523518387

Epoch: 6| Step: 8
Training loss: 1.491530179977417
Validation loss: 1.7382887114760697

Epoch: 6| Step: 9
Training loss: 0.6900209784507751
Validation loss: 1.7410179684239049

Epoch: 6| Step: 10
Training loss: 0.6608312726020813
Validation loss: 1.764155949315717

Epoch: 6| Step: 11
Training loss: 0.7276031970977783
Validation loss: 1.719148035972349

Epoch: 6| Step: 12
Training loss: 0.5818275213241577
Validation loss: 1.7245410808952906

Epoch: 6| Step: 13
Training loss: 0.41821515560150146
Validation loss: 1.7063416588690974

Epoch: 710| Step: 0
Training loss: 0.7171075344085693
Validation loss: 1.7529207737215105

Epoch: 6| Step: 1
Training loss: 0.7435731291770935
Validation loss: 1.727869737532831

Epoch: 6| Step: 2
Training loss: 0.6869726181030273
Validation loss: 1.7172124924198273

Epoch: 6| Step: 3
Training loss: 0.9775327444076538
Validation loss: 1.7008330040080573

Epoch: 6| Step: 4
Training loss: 1.09267258644104
Validation loss: 1.721711358716411

Epoch: 6| Step: 5
Training loss: 0.9278527498245239
Validation loss: 1.7903108084073631

Epoch: 6| Step: 6
Training loss: 0.8941178917884827
Validation loss: 1.7176379067923433

Epoch: 6| Step: 7
Training loss: 0.623031735420227
Validation loss: 1.7132725125999861

Epoch: 6| Step: 8
Training loss: 0.9825034141540527
Validation loss: 1.6933801263891242

Epoch: 6| Step: 9
Training loss: 0.6665550470352173
Validation loss: 1.7344528398206156

Epoch: 6| Step: 10
Training loss: 0.7983049154281616
Validation loss: 1.731686370347136

Epoch: 6| Step: 11
Training loss: 0.48256319761276245
Validation loss: 1.7373031916156891

Epoch: 6| Step: 12
Training loss: 0.9057532548904419
Validation loss: 1.6900066021950013

Epoch: 6| Step: 13
Training loss: 0.8898162841796875
Validation loss: 1.7044262193864392

Epoch: 711| Step: 0
Training loss: 0.701309084892273
Validation loss: 1.7148493105365383

Epoch: 6| Step: 1
Training loss: 0.4613844156265259
Validation loss: 1.6600264221109369

Epoch: 6| Step: 2
Training loss: 0.6936396360397339
Validation loss: 1.6797479955098962

Epoch: 6| Step: 3
Training loss: 1.0840272903442383
Validation loss: 1.7118165685284523

Epoch: 6| Step: 4
Training loss: 0.7286054491996765
Validation loss: 1.6950001203885643

Epoch: 6| Step: 5
Training loss: 0.8975294232368469
Validation loss: 1.6528893401545863

Epoch: 6| Step: 6
Training loss: 0.6342454552650452
Validation loss: 1.6700106372115433

Epoch: 6| Step: 7
Training loss: 0.7081358432769775
Validation loss: 1.76221759985852

Epoch: 6| Step: 8
Training loss: 0.9755681753158569
Validation loss: 1.690729328381118

Epoch: 6| Step: 9
Training loss: 0.7915353178977966
Validation loss: 1.6960212492173719

Epoch: 6| Step: 10
Training loss: 1.161710262298584
Validation loss: 1.7533316317424978

Epoch: 6| Step: 11
Training loss: 0.5724794268608093
Validation loss: 1.6847790633478472

Epoch: 6| Step: 12
Training loss: 1.0477464199066162
Validation loss: 1.7291207313537598

Epoch: 6| Step: 13
Training loss: 0.3449552059173584
Validation loss: 1.716500114369136

Epoch: 712| Step: 0
Training loss: 0.8183877468109131
Validation loss: 1.6908264544702345

Epoch: 6| Step: 1
Training loss: 0.6506743431091309
Validation loss: 1.7845097357226956

Epoch: 6| Step: 2
Training loss: 0.8540000915527344
Validation loss: 1.7677577272538216

Epoch: 6| Step: 3
Training loss: 0.8350257873535156
Validation loss: 1.708516287547286

Epoch: 6| Step: 4
Training loss: 0.7876938581466675
Validation loss: 1.7699490593325706

Epoch: 6| Step: 5
Training loss: 0.8243262767791748
Validation loss: 1.708763648104924

Epoch: 6| Step: 6
Training loss: 0.7805055379867554
Validation loss: 1.6960350005857405

Epoch: 6| Step: 7
Training loss: 0.9787096977233887
Validation loss: 1.7304409934628395

Epoch: 6| Step: 8
Training loss: 0.7943987250328064
Validation loss: 1.6571153953511228

Epoch: 6| Step: 9
Training loss: 0.46413376927375793
Validation loss: 1.7350476275208175

Epoch: 6| Step: 10
Training loss: 0.8259204626083374
Validation loss: 1.724026095482611

Epoch: 6| Step: 11
Training loss: 1.098768949508667
Validation loss: 1.625466355713465

Epoch: 6| Step: 12
Training loss: 0.3103526830673218
Validation loss: 1.6741168806629796

Epoch: 6| Step: 13
Training loss: 0.598931610584259
Validation loss: 1.6924041253264233

Epoch: 713| Step: 0
Training loss: 0.6942129731178284
Validation loss: 1.7216335804231706

Epoch: 6| Step: 1
Training loss: 0.7751696109771729
Validation loss: 1.7504112848671534

Epoch: 6| Step: 2
Training loss: 0.8868299126625061
Validation loss: 1.7118943301580285

Epoch: 6| Step: 3
Training loss: 0.4606500566005707
Validation loss: 1.6806723866411435

Epoch: 6| Step: 4
Training loss: 1.2433278560638428
Validation loss: 1.6980032138927008

Epoch: 6| Step: 5
Training loss: 0.8230392336845398
Validation loss: 1.6703883832500828

Epoch: 6| Step: 6
Training loss: 0.7362217903137207
Validation loss: 1.7782583954513713

Epoch: 6| Step: 7
Training loss: 0.5568464994430542
Validation loss: 1.68646228185264

Epoch: 6| Step: 8
Training loss: 0.9792343378067017
Validation loss: 1.753613487366707

Epoch: 6| Step: 9
Training loss: 0.6221552491188049
Validation loss: 1.7402891112912087

Epoch: 6| Step: 10
Training loss: 1.3271729946136475
Validation loss: 1.711272208921371

Epoch: 6| Step: 11
Training loss: 0.6039255857467651
Validation loss: 1.698853861901068

Epoch: 6| Step: 12
Training loss: 0.5238442420959473
Validation loss: 1.7353513022904754

Epoch: 6| Step: 13
Training loss: 0.9875776767730713
Validation loss: 1.7443733317877657

Epoch: 714| Step: 0
Training loss: 1.0620512962341309
Validation loss: 1.7386142105184577

Epoch: 6| Step: 1
Training loss: 0.6998982429504395
Validation loss: 1.7115586432077552

Epoch: 6| Step: 2
Training loss: 0.6836053133010864
Validation loss: 1.7493645914139286

Epoch: 6| Step: 3
Training loss: 0.9228032827377319
Validation loss: 1.681375257430538

Epoch: 6| Step: 4
Training loss: 0.832430362701416
Validation loss: 1.7162431311863724

Epoch: 6| Step: 5
Training loss: 1.186455249786377
Validation loss: 1.6970199718270251

Epoch: 6| Step: 6
Training loss: 0.8762215375900269
Validation loss: 1.7391559231665827

Epoch: 6| Step: 7
Training loss: 0.8165647387504578
Validation loss: 1.700939211794125

Epoch: 6| Step: 8
Training loss: 0.5964099764823914
Validation loss: 1.7590171931892313

Epoch: 6| Step: 9
Training loss: 0.4384247958660126
Validation loss: 1.6649552981058757

Epoch: 6| Step: 10
Training loss: 0.8523737788200378
Validation loss: 1.6655722279702463

Epoch: 6| Step: 11
Training loss: 0.556506872177124
Validation loss: 1.6673017996613697

Epoch: 6| Step: 12
Training loss: 0.7949733734130859
Validation loss: 1.6837154037208968

Epoch: 6| Step: 13
Training loss: 0.3196552097797394
Validation loss: 1.719163901062422

Epoch: 715| Step: 0
Training loss: 0.8339802026748657
Validation loss: 1.7608038981755574

Epoch: 6| Step: 1
Training loss: 0.6167670488357544
Validation loss: 1.701140147383495

Epoch: 6| Step: 2
Training loss: 0.6057969927787781
Validation loss: 1.6729502665099276

Epoch: 6| Step: 3
Training loss: 0.7497854828834534
Validation loss: 1.624814324481513

Epoch: 6| Step: 4
Training loss: 0.9083104133605957
Validation loss: 1.6818555503763177

Epoch: 6| Step: 5
Training loss: 0.8062172532081604
Validation loss: 1.6811792696675947

Epoch: 6| Step: 6
Training loss: 0.6113787889480591
Validation loss: 1.686495005443532

Epoch: 6| Step: 7
Training loss: 0.9058287739753723
Validation loss: 1.6823590673426145

Epoch: 6| Step: 8
Training loss: 1.0018846988677979
Validation loss: 1.7381807181142992

Epoch: 6| Step: 9
Training loss: 0.8525707721710205
Validation loss: 1.736916990690334

Epoch: 6| Step: 10
Training loss: 0.8163242936134338
Validation loss: 1.732556144396464

Epoch: 6| Step: 11
Training loss: 0.6290706396102905
Validation loss: 1.718629455053678

Epoch: 6| Step: 12
Training loss: 0.7778240442276001
Validation loss: 1.7138968744585592

Epoch: 6| Step: 13
Training loss: 0.7355307936668396
Validation loss: 1.7047626972198486

Epoch: 716| Step: 0
Training loss: 0.6862798929214478
Validation loss: 1.7831829094117688

Epoch: 6| Step: 1
Training loss: 0.5111004114151001
Validation loss: 1.7954316075130174

Epoch: 6| Step: 2
Training loss: 0.44044405221939087
Validation loss: 1.7232185948279597

Epoch: 6| Step: 3
Training loss: 1.0572242736816406
Validation loss: 1.7332543788417694

Epoch: 6| Step: 4
Training loss: 0.7407536506652832
Validation loss: 1.7659512732618599

Epoch: 6| Step: 5
Training loss: 0.8520578145980835
Validation loss: 1.7103849046973771

Epoch: 6| Step: 6
Training loss: 0.6698376536369324
Validation loss: 1.7074271382824067

Epoch: 6| Step: 7
Training loss: 0.45417851209640503
Validation loss: 1.7021621786138064

Epoch: 6| Step: 8
Training loss: 0.7099338173866272
Validation loss: 1.7555597956462572

Epoch: 6| Step: 9
Training loss: 0.7917031049728394
Validation loss: 1.6885912905457199

Epoch: 6| Step: 10
Training loss: 1.234581470489502
Validation loss: 1.693762440835276

Epoch: 6| Step: 11
Training loss: 0.8491311073303223
Validation loss: 1.726799508576752

Epoch: 6| Step: 12
Training loss: 1.3878962993621826
Validation loss: 1.6580130105377526

Epoch: 6| Step: 13
Training loss: 0.5337322950363159
Validation loss: 1.6741192238305205

Epoch: 717| Step: 0
Training loss: 1.0581436157226562
Validation loss: 1.6890314932792418

Epoch: 6| Step: 1
Training loss: 0.9840021133422852
Validation loss: 1.6602627115864907

Epoch: 6| Step: 2
Training loss: 1.061448097229004
Validation loss: 1.7314922796782626

Epoch: 6| Step: 3
Training loss: 0.7510846853256226
Validation loss: 1.700066581849129

Epoch: 6| Step: 4
Training loss: 0.4351203441619873
Validation loss: 1.7157071431477864

Epoch: 6| Step: 5
Training loss: 0.6173437833786011
Validation loss: 1.698433377409494

Epoch: 6| Step: 6
Training loss: 0.5562694668769836
Validation loss: 1.7554811213606147

Epoch: 6| Step: 7
Training loss: 0.4509804844856262
Validation loss: 1.7402699301319737

Epoch: 6| Step: 8
Training loss: 0.943034827709198
Validation loss: 1.686453712883816

Epoch: 6| Step: 9
Training loss: 1.27069890499115
Validation loss: 1.6662699445601432

Epoch: 6| Step: 10
Training loss: 0.5611464977264404
Validation loss: 1.7101942493069557

Epoch: 6| Step: 11
Training loss: 0.4847879111766815
Validation loss: 1.6705285477381882

Epoch: 6| Step: 12
Training loss: 0.6201629638671875
Validation loss: 1.739296938783379

Epoch: 6| Step: 13
Training loss: 1.1306102275848389
Validation loss: 1.717994910414501

Epoch: 718| Step: 0
Training loss: 0.9529737234115601
Validation loss: 1.6614422170064782

Epoch: 6| Step: 1
Training loss: 0.6240710616111755
Validation loss: 1.7478783951010755

Epoch: 6| Step: 2
Training loss: 0.9463444948196411
Validation loss: 1.7382404791411532

Epoch: 6| Step: 3
Training loss: 0.7058898210525513
Validation loss: 1.7177988136968305

Epoch: 6| Step: 4
Training loss: 0.7190682888031006
Validation loss: 1.7657974778964955

Epoch: 6| Step: 5
Training loss: 0.6627655029296875
Validation loss: 1.709850029278827

Epoch: 6| Step: 6
Training loss: 1.0561649799346924
Validation loss: 1.7629532288479548

Epoch: 6| Step: 7
Training loss: 1.1825292110443115
Validation loss: 1.7649030634151992

Epoch: 6| Step: 8
Training loss: 0.6002497673034668
Validation loss: 1.7664875586827595

Epoch: 6| Step: 9
Training loss: 0.3678498864173889
Validation loss: 1.7178665937915925

Epoch: 6| Step: 10
Training loss: 0.6589360237121582
Validation loss: 1.7276672381226734

Epoch: 6| Step: 11
Training loss: 0.9598442912101746
Validation loss: 1.7262827632247761

Epoch: 6| Step: 12
Training loss: 0.47949594259262085
Validation loss: 1.7074316470853743

Epoch: 6| Step: 13
Training loss: 0.5301995873451233
Validation loss: 1.666845501110118

Epoch: 719| Step: 0
Training loss: 0.5547173619270325
Validation loss: 1.7064526593813332

Epoch: 6| Step: 1
Training loss: 0.580265998840332
Validation loss: 1.716304527815952

Epoch: 6| Step: 2
Training loss: 1.3742554187774658
Validation loss: 1.7037961995729836

Epoch: 6| Step: 3
Training loss: 0.8091611266136169
Validation loss: 1.7507207291100615

Epoch: 6| Step: 4
Training loss: 0.7298484444618225
Validation loss: 1.680002902143745

Epoch: 6| Step: 5
Training loss: 0.374702125787735
Validation loss: 1.7068535307402253

Epoch: 6| Step: 6
Training loss: 0.785738468170166
Validation loss: 1.6474560140281596

Epoch: 6| Step: 7
Training loss: 1.1063873767852783
Validation loss: 1.789610719168058

Epoch: 6| Step: 8
Training loss: 1.1369495391845703
Validation loss: 1.673520484278279

Epoch: 6| Step: 9
Training loss: 0.6096560955047607
Validation loss: 1.739703401442497

Epoch: 6| Step: 10
Training loss: 1.2101998329162598
Validation loss: 1.7796865855493853

Epoch: 6| Step: 11
Training loss: 0.4283055067062378
Validation loss: 1.7362678012540262

Epoch: 6| Step: 12
Training loss: 0.9942217469215393
Validation loss: 1.7332095100033669

Epoch: 6| Step: 13
Training loss: 0.7355958819389343
Validation loss: 1.6898974000766713

Epoch: 720| Step: 0
Training loss: 1.0285251140594482
Validation loss: 1.7084785353752874

Epoch: 6| Step: 1
Training loss: 0.6293987035751343
Validation loss: 1.757747051536396

Epoch: 6| Step: 2
Training loss: 0.7563493251800537
Validation loss: 1.7346703916467645

Epoch: 6| Step: 3
Training loss: 0.9860478043556213
Validation loss: 1.7574621413343696

Epoch: 6| Step: 4
Training loss: 1.1432826519012451
Validation loss: 1.7469420702226701

Epoch: 6| Step: 5
Training loss: 0.6507259607315063
Validation loss: 1.6816039969844203

Epoch: 6| Step: 6
Training loss: 0.5084041357040405
Validation loss: 1.716653472633772

Epoch: 6| Step: 7
Training loss: 0.8301435708999634
Validation loss: 1.7386655307585193

Epoch: 6| Step: 8
Training loss: 0.9407052397727966
Validation loss: 1.6750025313387635

Epoch: 6| Step: 9
Training loss: 0.5576687455177307
Validation loss: 1.722263277217906

Epoch: 6| Step: 10
Training loss: 1.0948257446289062
Validation loss: 1.7125750754469184

Epoch: 6| Step: 11
Training loss: 0.7605514526367188
Validation loss: 1.6810867722316454

Epoch: 6| Step: 12
Training loss: 0.6042967438697815
Validation loss: 1.7010472564287082

Epoch: 6| Step: 13
Training loss: 1.0120519399642944
Validation loss: 1.6586073560099448

Epoch: 721| Step: 0
Training loss: 0.4478090703487396
Validation loss: 1.7361678487511092

Epoch: 6| Step: 1
Training loss: 0.8262327909469604
Validation loss: 1.6556487826890842

Epoch: 6| Step: 2
Training loss: 0.4700273871421814
Validation loss: 1.6564445495605469

Epoch: 6| Step: 3
Training loss: 1.386134386062622
Validation loss: 1.7526076109178605

Epoch: 6| Step: 4
Training loss: 1.2931790351867676
Validation loss: 1.7326856838759555

Epoch: 6| Step: 5
Training loss: 0.5834150314331055
Validation loss: 1.6707763915420861

Epoch: 6| Step: 6
Training loss: 0.9377597570419312
Validation loss: 1.6704096101945447

Epoch: 6| Step: 7
Training loss: 0.9175225496292114
Validation loss: 1.6980357900742562

Epoch: 6| Step: 8
Training loss: 0.9604694843292236
Validation loss: 1.7716119750853507

Epoch: 6| Step: 9
Training loss: 0.38366565108299255
Validation loss: 1.7515031368501726

Epoch: 6| Step: 10
Training loss: 0.39900296926498413
Validation loss: 1.7340669888322071

Epoch: 6| Step: 11
Training loss: 0.403903603553772
Validation loss: 1.717030511107496

Epoch: 6| Step: 12
Training loss: 1.2115557193756104
Validation loss: 1.6936106886914981

Epoch: 6| Step: 13
Training loss: 1.0560380220413208
Validation loss: 1.7075795473590973

Epoch: 722| Step: 0
Training loss: 0.9179510474205017
Validation loss: 1.7274534958665089

Epoch: 6| Step: 1
Training loss: 0.6906964182853699
Validation loss: 1.7145573759591708

Epoch: 6| Step: 2
Training loss: 0.7032740116119385
Validation loss: 1.7306472268155826

Epoch: 6| Step: 3
Training loss: 1.4394246339797974
Validation loss: 1.7020560438914965

Epoch: 6| Step: 4
Training loss: 0.7977225184440613
Validation loss: 1.7109759546095324

Epoch: 6| Step: 5
Training loss: 0.5432220697402954
Validation loss: 1.8014156754298876

Epoch: 6| Step: 6
Training loss: 0.7623302936553955
Validation loss: 1.676748364202438

Epoch: 6| Step: 7
Training loss: 0.71592116355896
Validation loss: 1.698723090592251

Epoch: 6| Step: 8
Training loss: 0.683780312538147
Validation loss: 1.6608286147476525

Epoch: 6| Step: 9
Training loss: 0.8327037692070007
Validation loss: 1.6681767074010705

Epoch: 6| Step: 10
Training loss: 0.393831729888916
Validation loss: 1.7171161854138939

Epoch: 6| Step: 11
Training loss: 0.598261833190918
Validation loss: 1.6396139257697648

Epoch: 6| Step: 12
Training loss: 0.7968811392784119
Validation loss: 1.7563110346435218

Epoch: 6| Step: 13
Training loss: 1.3390507698059082
Validation loss: 1.7547929427957023

Epoch: 723| Step: 0
Training loss: 1.0229682922363281
Validation loss: 1.6860830706934775

Epoch: 6| Step: 1
Training loss: 0.6553958058357239
Validation loss: 1.696782495385857

Epoch: 6| Step: 2
Training loss: 0.8931043148040771
Validation loss: 1.68091417384404

Epoch: 6| Step: 3
Training loss: 0.8207560777664185
Validation loss: 1.7350993028251074

Epoch: 6| Step: 4
Training loss: 0.9667161107063293
Validation loss: 1.703936867816474

Epoch: 6| Step: 5
Training loss: 0.7887805104255676
Validation loss: 1.7691176053016417

Epoch: 6| Step: 6
Training loss: 0.924157977104187
Validation loss: 1.7380534807840984

Epoch: 6| Step: 7
Training loss: 0.799391508102417
Validation loss: 1.779238982867169

Epoch: 6| Step: 8
Training loss: 0.7548848390579224
Validation loss: 1.7190866303700272

Epoch: 6| Step: 9
Training loss: 0.605488657951355
Validation loss: 1.7336819799997474

Epoch: 6| Step: 10
Training loss: 0.7335659265518188
Validation loss: 1.7550503310336862

Epoch: 6| Step: 11
Training loss: 1.0209531784057617
Validation loss: 1.7043787894710418

Epoch: 6| Step: 12
Training loss: 0.417682021856308
Validation loss: 1.7152984642213391

Epoch: 6| Step: 13
Training loss: 0.7116842865943909
Validation loss: 1.690118787109211

Epoch: 724| Step: 0
Training loss: 0.6096796989440918
Validation loss: 1.7059864408226424

Epoch: 6| Step: 1
Training loss: 0.6688706874847412
Validation loss: 1.6890920951802244

Epoch: 6| Step: 2
Training loss: 0.47592926025390625
Validation loss: 1.6663018298405472

Epoch: 6| Step: 3
Training loss: 0.6646215915679932
Validation loss: 1.7312182418761715

Epoch: 6| Step: 4
Training loss: 1.0501329898834229
Validation loss: 1.7163712529725925

Epoch: 6| Step: 5
Training loss: 1.1548242568969727
Validation loss: 1.728632709031464

Epoch: 6| Step: 6
Training loss: 0.553264319896698
Validation loss: 1.6824422600448772

Epoch: 6| Step: 7
Training loss: 0.9524272084236145
Validation loss: 1.7246936636586343

Epoch: 6| Step: 8
Training loss: 0.47375160455703735
Validation loss: 1.6719744128565635

Epoch: 6| Step: 9
Training loss: 0.9617681503295898
Validation loss: 1.6828549100506691

Epoch: 6| Step: 10
Training loss: 1.0473133325576782
Validation loss: 1.6646163079046434

Epoch: 6| Step: 11
Training loss: 1.2456778287887573
Validation loss: 1.6934431906669372

Epoch: 6| Step: 12
Training loss: 0.35358354449272156
Validation loss: 1.7106138531879713

Epoch: 6| Step: 13
Training loss: 0.6231583952903748
Validation loss: 1.6850179523550055

Epoch: 725| Step: 0
Training loss: 0.7612113952636719
Validation loss: 1.7125042587198236

Epoch: 6| Step: 1
Training loss: 0.7258180379867554
Validation loss: 1.7144862580043014

Epoch: 6| Step: 2
Training loss: 0.7485032081604004
Validation loss: 1.705837941938831

Epoch: 6| Step: 3
Training loss: 1.0088160037994385
Validation loss: 1.739456517722017

Epoch: 6| Step: 4
Training loss: 0.8607884049415588
Validation loss: 1.7157195255320559

Epoch: 6| Step: 5
Training loss: 0.8062041997909546
Validation loss: 1.7188905772342478

Epoch: 6| Step: 6
Training loss: 0.5795800685882568
Validation loss: 1.6879767378171284

Epoch: 6| Step: 7
Training loss: 0.8197112083435059
Validation loss: 1.6430979505661996

Epoch: 6| Step: 8
Training loss: 0.6714696884155273
Validation loss: 1.7592596674478183

Epoch: 6| Step: 9
Training loss: 0.9932407736778259
Validation loss: 1.778539410201452

Epoch: 6| Step: 10
Training loss: 0.6451342701911926
Validation loss: 1.7246865534013318

Epoch: 6| Step: 11
Training loss: 0.4976152777671814
Validation loss: 1.6943235089701991

Epoch: 6| Step: 12
Training loss: 1.2632664442062378
Validation loss: 1.683897775988425

Epoch: 6| Step: 13
Training loss: 0.6818752288818359
Validation loss: 1.710831912614966

Epoch: 726| Step: 0
Training loss: 0.7094579935073853
Validation loss: 1.7205338990816506

Epoch: 6| Step: 1
Training loss: 0.6308466196060181
Validation loss: 1.66522309600666

Epoch: 6| Step: 2
Training loss: 0.8588060140609741
Validation loss: 1.7185063695394864

Epoch: 6| Step: 3
Training loss: 0.4894309639930725
Validation loss: 1.7079361741260817

Epoch: 6| Step: 4
Training loss: 0.5541782379150391
Validation loss: 1.6875969466342722

Epoch: 6| Step: 5
Training loss: 0.3027224540710449
Validation loss: 1.720911290055962

Epoch: 6| Step: 6
Training loss: 0.9851400256156921
Validation loss: 1.6874463096741708

Epoch: 6| Step: 7
Training loss: 0.7306878566741943
Validation loss: 1.725831002317449

Epoch: 6| Step: 8
Training loss: 0.7839738130569458
Validation loss: 1.6593710427643151

Epoch: 6| Step: 9
Training loss: 0.9623019695281982
Validation loss: 1.7085843445152364

Epoch: 6| Step: 10
Training loss: 1.3329191207885742
Validation loss: 1.7128979313758113

Epoch: 6| Step: 11
Training loss: 0.5101933479309082
Validation loss: 1.7390902657662668

Epoch: 6| Step: 12
Training loss: 0.3040895462036133
Validation loss: 1.7784148377756919

Epoch: 6| Step: 13
Training loss: 1.8076519966125488
Validation loss: 1.7252325268201931

Epoch: 727| Step: 0
Training loss: 0.7548187971115112
Validation loss: 1.7184180854469218

Epoch: 6| Step: 1
Training loss: 0.6365469694137573
Validation loss: 1.8090930215774044

Epoch: 6| Step: 2
Training loss: 0.7261701822280884
Validation loss: 1.7797423921605593

Epoch: 6| Step: 3
Training loss: 0.5184177160263062
Validation loss: 1.7314513370554934

Epoch: 6| Step: 4
Training loss: 1.2814624309539795
Validation loss: 1.7510712044213408

Epoch: 6| Step: 5
Training loss: 0.4477333128452301
Validation loss: 1.77283178734523

Epoch: 6| Step: 6
Training loss: 0.7810783982276917
Validation loss: 1.7157319694437005

Epoch: 6| Step: 7
Training loss: 1.142290472984314
Validation loss: 1.7289938311423025

Epoch: 6| Step: 8
Training loss: 0.5405561327934265
Validation loss: 1.7252355044887913

Epoch: 6| Step: 9
Training loss: 1.2961080074310303
Validation loss: 1.69134356129554

Epoch: 6| Step: 10
Training loss: 0.619726836681366
Validation loss: 1.679664340070499

Epoch: 6| Step: 11
Training loss: 0.609102725982666
Validation loss: 1.7076291256053473

Epoch: 6| Step: 12
Training loss: 0.6860659122467041
Validation loss: 1.7622513796693535

Epoch: 6| Step: 13
Training loss: 1.37702476978302
Validation loss: 1.6775331881738478

Epoch: 728| Step: 0
Training loss: 0.4677285850048065
Validation loss: 1.7059237149453932

Epoch: 6| Step: 1
Training loss: 1.1848405599594116
Validation loss: 1.7145844762043287

Epoch: 6| Step: 2
Training loss: 0.7257298827171326
Validation loss: 1.7202063901450044

Epoch: 6| Step: 3
Training loss: 0.7408263683319092
Validation loss: 1.7058630079351447

Epoch: 6| Step: 4
Training loss: 0.5098015069961548
Validation loss: 1.7442870357985139

Epoch: 6| Step: 5
Training loss: 0.7342933416366577
Validation loss: 1.690385494180905

Epoch: 6| Step: 6
Training loss: 0.6031023859977722
Validation loss: 1.6830885435945244

Epoch: 6| Step: 7
Training loss: 0.6810095310211182
Validation loss: 1.730511393598331

Epoch: 6| Step: 8
Training loss: 1.31607186794281
Validation loss: 1.694550060456799

Epoch: 6| Step: 9
Training loss: 1.3114019632339478
Validation loss: 1.7668100364746586

Epoch: 6| Step: 10
Training loss: 0.6961839199066162
Validation loss: 1.7308256959402433

Epoch: 6| Step: 11
Training loss: 0.596833348274231
Validation loss: 1.6917604169537943

Epoch: 6| Step: 12
Training loss: 0.679662823677063
Validation loss: 1.7437655284840574

Epoch: 6| Step: 13
Training loss: 0.6254866123199463
Validation loss: 1.7026743901673185

Epoch: 729| Step: 0
Training loss: 0.6671484708786011
Validation loss: 1.7444309931929394

Epoch: 6| Step: 1
Training loss: 0.8206238150596619
Validation loss: 1.6605207535528368

Epoch: 6| Step: 2
Training loss: 0.699317455291748
Validation loss: 1.6739811794732207

Epoch: 6| Step: 3
Training loss: 0.7332186698913574
Validation loss: 1.7099067049641763

Epoch: 6| Step: 4
Training loss: 0.7194790840148926
Validation loss: 1.7569823598348966

Epoch: 6| Step: 5
Training loss: 0.5513978004455566
Validation loss: 1.7437957871344782

Epoch: 6| Step: 6
Training loss: 0.91681969165802
Validation loss: 1.7104367466383084

Epoch: 6| Step: 7
Training loss: 0.6897947788238525
Validation loss: 1.676158530737764

Epoch: 6| Step: 8
Training loss: 0.7270312905311584
Validation loss: 1.7532519307187808

Epoch: 6| Step: 9
Training loss: 0.6656132936477661
Validation loss: 1.7038778387090212

Epoch: 6| Step: 10
Training loss: 0.876461386680603
Validation loss: 1.7221633721423406

Epoch: 6| Step: 11
Training loss: 0.8495330810546875
Validation loss: 1.7562484074664373

Epoch: 6| Step: 12
Training loss: 0.8916335105895996
Validation loss: 1.6933834475855674

Epoch: 6| Step: 13
Training loss: 0.8423084020614624
Validation loss: 1.7024579278884395

Epoch: 730| Step: 0
Training loss: 1.004216194152832
Validation loss: 1.7174486549951697

Epoch: 6| Step: 1
Training loss: 0.7350494265556335
Validation loss: 1.7194083006151262

Epoch: 6| Step: 2
Training loss: 0.3894272744655609
Validation loss: 1.6971573329740954

Epoch: 6| Step: 3
Training loss: 0.7455090880393982
Validation loss: 1.6979474329179334

Epoch: 6| Step: 4
Training loss: 1.1558799743652344
Validation loss: 1.7289481214297715

Epoch: 6| Step: 5
Training loss: 0.8588687181472778
Validation loss: 1.697339242504489

Epoch: 6| Step: 6
Training loss: 0.9310777187347412
Validation loss: 1.724877530528653

Epoch: 6| Step: 7
Training loss: 0.6670140027999878
Validation loss: 1.6894316993733889

Epoch: 6| Step: 8
Training loss: 0.41343748569488525
Validation loss: 1.6982897507247103

Epoch: 6| Step: 9
Training loss: 0.6468541622161865
Validation loss: 1.6788653660846014

Epoch: 6| Step: 10
Training loss: 0.8907230496406555
Validation loss: 1.7102969769508607

Epoch: 6| Step: 11
Training loss: 0.6630003452301025
Validation loss: 1.7206933242018505

Epoch: 6| Step: 12
Training loss: 0.9677226543426514
Validation loss: 1.6887617572661369

Epoch: 6| Step: 13
Training loss: 0.8162176609039307
Validation loss: 1.6856487181878859

Epoch: 731| Step: 0
Training loss: 1.1075900793075562
Validation loss: 1.708579815844054

Epoch: 6| Step: 1
Training loss: 1.1608349084854126
Validation loss: 1.7114046722330072

Epoch: 6| Step: 2
Training loss: 0.9456046223640442
Validation loss: 1.708008712337863

Epoch: 6| Step: 3
Training loss: 0.3744865357875824
Validation loss: 1.7363677793933499

Epoch: 6| Step: 4
Training loss: 0.4437646269798279
Validation loss: 1.7316715127678328

Epoch: 6| Step: 5
Training loss: 0.760057806968689
Validation loss: 1.691943314767653

Epoch: 6| Step: 6
Training loss: 0.7774513959884644
Validation loss: 1.7229713880887596

Epoch: 6| Step: 7
Training loss: 0.5981725454330444
Validation loss: 1.7102859712416125

Epoch: 6| Step: 8
Training loss: 0.9753390550613403
Validation loss: 1.712369441986084

Epoch: 6| Step: 9
Training loss: 0.5106761455535889
Validation loss: 1.6645721966220486

Epoch: 6| Step: 10
Training loss: 0.6717209815979004
Validation loss: 1.7048384899734168

Epoch: 6| Step: 11
Training loss: 0.6420190334320068
Validation loss: 1.7531172434488933

Epoch: 6| Step: 12
Training loss: 0.8981164693832397
Validation loss: 1.7434790749703684

Epoch: 6| Step: 13
Training loss: 0.780019998550415
Validation loss: 1.6885293965698571

Epoch: 732| Step: 0
Training loss: 1.0107362270355225
Validation loss: 1.670859754726451

Epoch: 6| Step: 1
Training loss: 0.8924839496612549
Validation loss: 1.6272481667098178

Epoch: 6| Step: 2
Training loss: 0.4113311469554901
Validation loss: 1.6913482245578562

Epoch: 6| Step: 3
Training loss: 0.9976105690002441
Validation loss: 1.6766812045087096

Epoch: 6| Step: 4
Training loss: 0.7058025002479553
Validation loss: 1.664326516530847

Epoch: 6| Step: 5
Training loss: 1.294250726699829
Validation loss: 1.6802561308747979

Epoch: 6| Step: 6
Training loss: 0.6265016794204712
Validation loss: 1.70308300500275

Epoch: 6| Step: 7
Training loss: 0.9616367220878601
Validation loss: 1.7577225521046629

Epoch: 6| Step: 8
Training loss: 0.8107599020004272
Validation loss: 1.7362958692735242

Epoch: 6| Step: 9
Training loss: 0.7417155504226685
Validation loss: 1.7359439076915864

Epoch: 6| Step: 10
Training loss: 0.8466641902923584
Validation loss: 1.751982165921119

Epoch: 6| Step: 11
Training loss: 0.8961613178253174
Validation loss: 1.7678235205270911

Epoch: 6| Step: 12
Training loss: 0.5453352332115173
Validation loss: 1.7291525025521555

Epoch: 6| Step: 13
Training loss: 0.8589470982551575
Validation loss: 1.741002486598107

Epoch: 733| Step: 0
Training loss: 1.3951764106750488
Validation loss: 1.7346288593866492

Epoch: 6| Step: 1
Training loss: 0.71502685546875
Validation loss: 1.693523794092158

Epoch: 6| Step: 2
Training loss: 0.823101818561554
Validation loss: 1.6847582529949885

Epoch: 6| Step: 3
Training loss: 0.6991198062896729
Validation loss: 1.7423454023176623

Epoch: 6| Step: 4
Training loss: 0.5481542348861694
Validation loss: 1.6805563383204962

Epoch: 6| Step: 5
Training loss: 0.6003805994987488
Validation loss: 1.641119203259868

Epoch: 6| Step: 6
Training loss: 1.2269518375396729
Validation loss: 1.6848023399229972

Epoch: 6| Step: 7
Training loss: 0.9915748834609985
Validation loss: 1.666764291383887

Epoch: 6| Step: 8
Training loss: 1.2765873670578003
Validation loss: 1.7049990482227777

Epoch: 6| Step: 9
Training loss: 0.6773656606674194
Validation loss: 1.6590699303534724

Epoch: 6| Step: 10
Training loss: 0.4234578013420105
Validation loss: 1.6779627300077868

Epoch: 6| Step: 11
Training loss: 0.7912265658378601
Validation loss: 1.6861779587243193

Epoch: 6| Step: 12
Training loss: 0.6314720511436462
Validation loss: 1.7366203902870097

Epoch: 6| Step: 13
Training loss: 0.2099819779396057
Validation loss: 1.7362757716127621

Epoch: 734| Step: 0
Training loss: 0.5372437238693237
Validation loss: 1.7000820585476455

Epoch: 6| Step: 1
Training loss: 1.06223726272583
Validation loss: 1.7680301217622654

Epoch: 6| Step: 2
Training loss: 0.9996915459632874
Validation loss: 1.7594396709113993

Epoch: 6| Step: 3
Training loss: 1.118943452835083
Validation loss: 1.7841975304388231

Epoch: 6| Step: 4
Training loss: 1.0870722532272339
Validation loss: 1.8023281315321564

Epoch: 6| Step: 5
Training loss: 0.5906623601913452
Validation loss: 1.719202189035313

Epoch: 6| Step: 6
Training loss: 1.1447689533233643
Validation loss: 1.769127002326391

Epoch: 6| Step: 7
Training loss: 0.9758071899414062
Validation loss: 1.668721551536232

Epoch: 6| Step: 8
Training loss: 0.6996501088142395
Validation loss: 1.7007283805519022

Epoch: 6| Step: 9
Training loss: 0.48211967945098877
Validation loss: 1.7286131253806494

Epoch: 6| Step: 10
Training loss: 0.6616261601448059
Validation loss: 1.7541245055455033

Epoch: 6| Step: 11
Training loss: 0.6415742635726929
Validation loss: 1.728093530542107

Epoch: 6| Step: 12
Training loss: 0.8484588861465454
Validation loss: 1.7312148540250716

Epoch: 6| Step: 13
Training loss: 0.4489802122116089
Validation loss: 1.6456663057368288

Epoch: 735| Step: 0
Training loss: 0.9299014806747437
Validation loss: 1.7168398954535042

Epoch: 6| Step: 1
Training loss: 0.5282739996910095
Validation loss: 1.7257970609972555

Epoch: 6| Step: 2
Training loss: 0.49605682492256165
Validation loss: 1.7467647893454439

Epoch: 6| Step: 3
Training loss: 0.9066975116729736
Validation loss: 1.6348937967772126

Epoch: 6| Step: 4
Training loss: 1.05269193649292
Validation loss: 1.6712617989509337

Epoch: 6| Step: 5
Training loss: 0.8157410621643066
Validation loss: 1.7294156205269597

Epoch: 6| Step: 6
Training loss: 0.7817967534065247
Validation loss: 1.7601828523861465

Epoch: 6| Step: 7
Training loss: 0.6626452803611755
Validation loss: 1.66348893924426

Epoch: 6| Step: 8
Training loss: 0.5258373618125916
Validation loss: 1.710030750561786

Epoch: 6| Step: 9
Training loss: 0.5537269115447998
Validation loss: 1.7245075459121375

Epoch: 6| Step: 10
Training loss: 0.6665244102478027
Validation loss: 1.7425564514693392

Epoch: 6| Step: 11
Training loss: 0.6314383745193481
Validation loss: 1.6983613019348474

Epoch: 6| Step: 12
Training loss: 1.0101630687713623
Validation loss: 1.6473872007862214

Epoch: 6| Step: 13
Training loss: 1.0932193994522095
Validation loss: 1.6896022340302825

Epoch: 736| Step: 0
Training loss: 0.6390342712402344
Validation loss: 1.655722269447901

Epoch: 6| Step: 1
Training loss: 0.7269750237464905
Validation loss: 1.6520777742067974

Epoch: 6| Step: 2
Training loss: 1.0274434089660645
Validation loss: 1.6766529749798518

Epoch: 6| Step: 3
Training loss: 0.45118817687034607
Validation loss: 1.714570628699436

Epoch: 6| Step: 4
Training loss: 0.7200930118560791
Validation loss: 1.6829597655163016

Epoch: 6| Step: 5
Training loss: 1.058381199836731
Validation loss: 1.7400485559176373

Epoch: 6| Step: 6
Training loss: 0.5935375690460205
Validation loss: 1.657777496563491

Epoch: 6| Step: 7
Training loss: 0.7991228103637695
Validation loss: 1.6637522994831044

Epoch: 6| Step: 8
Training loss: 1.1578903198242188
Validation loss: 1.7337150625003281

Epoch: 6| Step: 9
Training loss: 1.1341325044631958
Validation loss: 1.7167453432595858

Epoch: 6| Step: 10
Training loss: 0.9102261662483215
Validation loss: 1.7024050374184885

Epoch: 6| Step: 11
Training loss: 0.3266030251979828
Validation loss: 1.685460611056256

Epoch: 6| Step: 12
Training loss: 0.48104235529899597
Validation loss: 1.7485698000077279

Epoch: 6| Step: 13
Training loss: 0.7214405536651611
Validation loss: 1.696764697310745

Epoch: 737| Step: 0
Training loss: 0.7333825826644897
Validation loss: 1.7280117901422645

Epoch: 6| Step: 1
Training loss: 0.7619363069534302
Validation loss: 1.663995909434493

Epoch: 6| Step: 2
Training loss: 0.6817996501922607
Validation loss: 1.7441656115234538

Epoch: 6| Step: 3
Training loss: 0.8786005973815918
Validation loss: 1.7098073190258396

Epoch: 6| Step: 4
Training loss: 0.7605165839195251
Validation loss: 1.7193875453805412

Epoch: 6| Step: 5
Training loss: 0.5724798440933228
Validation loss: 1.7370612185488465

Epoch: 6| Step: 6
Training loss: 0.49593091011047363
Validation loss: 1.6566452698041034

Epoch: 6| Step: 7
Training loss: 0.6100775003433228
Validation loss: 1.6896625577762563

Epoch: 6| Step: 8
Training loss: 0.6407821774482727
Validation loss: 1.710350158394024

Epoch: 6| Step: 9
Training loss: 0.8992940783500671
Validation loss: 1.70655987211453

Epoch: 6| Step: 10
Training loss: 1.4471919536590576
Validation loss: 1.759636873840004

Epoch: 6| Step: 11
Training loss: 0.7866910696029663
Validation loss: 1.7037239074707031

Epoch: 6| Step: 12
Training loss: 0.7018357515335083
Validation loss: 1.6773335754230458

Epoch: 6| Step: 13
Training loss: 0.7716422080993652
Validation loss: 1.7333261761614072

Epoch: 738| Step: 0
Training loss: 0.842819094657898
Validation loss: 1.6851557070209133

Epoch: 6| Step: 1
Training loss: 0.88731449842453
Validation loss: 1.7009833423040246

Epoch: 6| Step: 2
Training loss: 1.1665654182434082
Validation loss: 1.7476765878738896

Epoch: 6| Step: 3
Training loss: 0.9895665645599365
Validation loss: 1.7511005683611798

Epoch: 6| Step: 4
Training loss: 0.4859362840652466
Validation loss: 1.7175616320743357

Epoch: 6| Step: 5
Training loss: 0.7615540027618408
Validation loss: 1.7593726855452343

Epoch: 6| Step: 6
Training loss: 0.7012135982513428
Validation loss: 1.7625254072168821

Epoch: 6| Step: 7
Training loss: 0.7668644189834595
Validation loss: 1.807485698371805

Epoch: 6| Step: 8
Training loss: 0.559036910533905
Validation loss: 1.7706181990203036

Epoch: 6| Step: 9
Training loss: 0.6486667394638062
Validation loss: 1.7272650759707215

Epoch: 6| Step: 10
Training loss: 1.152576208114624
Validation loss: 1.728825746044036

Epoch: 6| Step: 11
Training loss: 0.897882878780365
Validation loss: 1.7125563044701853

Epoch: 6| Step: 12
Training loss: 0.8598721027374268
Validation loss: 1.7081391273006317

Epoch: 6| Step: 13
Training loss: 0.7883462905883789
Validation loss: 1.7399655567702426

Epoch: 739| Step: 0
Training loss: 0.8434764742851257
Validation loss: 1.7100092005986038

Epoch: 6| Step: 1
Training loss: 0.6760810017585754
Validation loss: 1.6801208206402358

Epoch: 6| Step: 2
Training loss: 0.44482746720314026
Validation loss: 1.707608235779629

Epoch: 6| Step: 3
Training loss: 0.9274975061416626
Validation loss: 1.6953411563750236

Epoch: 6| Step: 4
Training loss: 0.9283555746078491
Validation loss: 1.6697235927786878

Epoch: 6| Step: 5
Training loss: 0.6162893772125244
Validation loss: 1.6640267372131348

Epoch: 6| Step: 6
Training loss: 1.024147391319275
Validation loss: 1.7108735999753397

Epoch: 6| Step: 7
Training loss: 0.6795240640640259
Validation loss: 1.705984031000445

Epoch: 6| Step: 8
Training loss: 1.2734124660491943
Validation loss: 1.6903351199242376

Epoch: 6| Step: 9
Training loss: 0.8864680528640747
Validation loss: 1.6911948752659622

Epoch: 6| Step: 10
Training loss: 0.6534192562103271
Validation loss: 1.725166420782766

Epoch: 6| Step: 11
Training loss: 0.533251166343689
Validation loss: 1.7657583503312961

Epoch: 6| Step: 12
Training loss: 0.6338207721710205
Validation loss: 1.7442141489316059

Epoch: 6| Step: 13
Training loss: 0.665661096572876
Validation loss: 1.6710660816520773

Epoch: 740| Step: 0
Training loss: 0.8185778856277466
Validation loss: 1.7026319093601678

Epoch: 6| Step: 1
Training loss: 1.0120413303375244
Validation loss: 1.7507361109538744

Epoch: 6| Step: 2
Training loss: 0.8468352556228638
Validation loss: 1.6871977621509182

Epoch: 6| Step: 3
Training loss: 0.5780785083770752
Validation loss: 1.747679195096416

Epoch: 6| Step: 4
Training loss: 0.9070925712585449
Validation loss: 1.6619371970494587

Epoch: 6| Step: 5
Training loss: 1.0403263568878174
Validation loss: 1.6972487677810013

Epoch: 6| Step: 6
Training loss: 0.3617763817310333
Validation loss: 1.6854253840702835

Epoch: 6| Step: 7
Training loss: 0.6820804476737976
Validation loss: 1.7234545856393793

Epoch: 6| Step: 8
Training loss: 0.6891413927078247
Validation loss: 1.7443089010894939

Epoch: 6| Step: 9
Training loss: 0.7626888751983643
Validation loss: 1.7548907828587357

Epoch: 6| Step: 10
Training loss: 0.9138177633285522
Validation loss: 1.7414093504669845

Epoch: 6| Step: 11
Training loss: 0.6696853637695312
Validation loss: 1.7043502433325655

Epoch: 6| Step: 12
Training loss: 0.9860748052597046
Validation loss: 1.7280298702178463

Epoch: 6| Step: 13
Training loss: 0.46392568945884705
Validation loss: 1.6856637026674004

Epoch: 741| Step: 0
Training loss: 0.79915452003479
Validation loss: 1.6722669139985116

Epoch: 6| Step: 1
Training loss: 0.6798487901687622
Validation loss: 1.7051003940643803

Epoch: 6| Step: 2
Training loss: 0.68702632188797
Validation loss: 1.6814100203975555

Epoch: 6| Step: 3
Training loss: 0.6540007591247559
Validation loss: 1.658484802451185

Epoch: 6| Step: 4
Training loss: 0.4508831799030304
Validation loss: 1.7355677338056668

Epoch: 6| Step: 5
Training loss: 1.1880892515182495
Validation loss: 1.7367991734576482

Epoch: 6| Step: 6
Training loss: 0.8931412100791931
Validation loss: 1.6490251530883133

Epoch: 6| Step: 7
Training loss: 0.5751952528953552
Validation loss: 1.690636186189549

Epoch: 6| Step: 8
Training loss: 1.2989660501480103
Validation loss: 1.6666086412245227

Epoch: 6| Step: 9
Training loss: 0.6306182146072388
Validation loss: 1.6307173300814886

Epoch: 6| Step: 10
Training loss: 0.8358246088027954
Validation loss: 1.6422643212861912

Epoch: 6| Step: 11
Training loss: 0.5132738351821899
Validation loss: 1.790871638123707

Epoch: 6| Step: 12
Training loss: 0.8392861485481262
Validation loss: 1.701244335020742

Epoch: 6| Step: 13
Training loss: 0.7743030786514282
Validation loss: 1.6873808291650587

Epoch: 742| Step: 0
Training loss: 0.49388277530670166
Validation loss: 1.739578127861023

Epoch: 6| Step: 1
Training loss: 0.7798593640327454
Validation loss: 1.721616848822563

Epoch: 6| Step: 2
Training loss: 1.3913304805755615
Validation loss: 1.7101394386701687

Epoch: 6| Step: 3
Training loss: 0.6524364948272705
Validation loss: 1.6945676918952697

Epoch: 6| Step: 4
Training loss: 0.6670037508010864
Validation loss: 1.7379683474058747

Epoch: 6| Step: 5
Training loss: 0.5237687826156616
Validation loss: 1.7267247066702893

Epoch: 6| Step: 6
Training loss: 0.7096147537231445
Validation loss: 1.7519776705772645

Epoch: 6| Step: 7
Training loss: 0.5106722116470337
Validation loss: 1.7277272696136146

Epoch: 6| Step: 8
Training loss: 0.8031831979751587
Validation loss: 1.7817449108246834

Epoch: 6| Step: 9
Training loss: 1.267802357673645
Validation loss: 1.6768062178806593

Epoch: 6| Step: 10
Training loss: 1.1824541091918945
Validation loss: 1.750803792348472

Epoch: 6| Step: 11
Training loss: 0.5669093728065491
Validation loss: 1.6914740403493245

Epoch: 6| Step: 12
Training loss: 0.6744067668914795
Validation loss: 1.7381755600693405

Epoch: 6| Step: 13
Training loss: 0.3724899888038635
Validation loss: 1.6887481776616906

Epoch: 743| Step: 0
Training loss: 0.6485211849212646
Validation loss: 1.7367554326211252

Epoch: 6| Step: 1
Training loss: 1.2683337926864624
Validation loss: 1.712117684784756

Epoch: 6| Step: 2
Training loss: 1.128658652305603
Validation loss: 1.6813925491866244

Epoch: 6| Step: 3
Training loss: 0.5924183130264282
Validation loss: 1.6700615139417752

Epoch: 6| Step: 4
Training loss: 0.907059371471405
Validation loss: 1.6625596656594226

Epoch: 6| Step: 5
Training loss: 0.8749105930328369
Validation loss: 1.6873830396641967

Epoch: 6| Step: 6
Training loss: 0.7484490275382996
Validation loss: 1.7369921104882353

Epoch: 6| Step: 7
Training loss: 0.6069025993347168
Validation loss: 1.6756154132145706

Epoch: 6| Step: 8
Training loss: 0.6719030141830444
Validation loss: 1.7037117878595989

Epoch: 6| Step: 9
Training loss: 0.5725087523460388
Validation loss: 1.7218519436415805

Epoch: 6| Step: 10
Training loss: 0.47384050488471985
Validation loss: 1.716825423702117

Epoch: 6| Step: 11
Training loss: 0.6662527918815613
Validation loss: 1.7551210388060539

Epoch: 6| Step: 12
Training loss: 1.030616283416748
Validation loss: 1.7059116286616172

Epoch: 6| Step: 13
Training loss: 0.7396914958953857
Validation loss: 1.6897270371837

Epoch: 744| Step: 0
Training loss: 0.5229998826980591
Validation loss: 1.744811431054146

Epoch: 6| Step: 1
Training loss: 0.7410256862640381
Validation loss: 1.7099545213483995

Epoch: 6| Step: 2
Training loss: 0.5610976219177246
Validation loss: 1.6772279252288163

Epoch: 6| Step: 3
Training loss: 0.48426806926727295
Validation loss: 1.7068978394231489

Epoch: 6| Step: 4
Training loss: 0.9562183618545532
Validation loss: 1.6992135951595921

Epoch: 6| Step: 5
Training loss: 1.2626793384552002
Validation loss: 1.667439870295986

Epoch: 6| Step: 6
Training loss: 0.4340290427207947
Validation loss: 1.7673095804388805

Epoch: 6| Step: 7
Training loss: 0.9497601985931396
Validation loss: 1.7064169068490305

Epoch: 6| Step: 8
Training loss: 0.6577585935592651
Validation loss: 1.7350846285461097

Epoch: 6| Step: 9
Training loss: 0.4779736399650574
Validation loss: 1.7153886389988724

Epoch: 6| Step: 10
Training loss: 1.0766675472259521
Validation loss: 1.7203831595759238

Epoch: 6| Step: 11
Training loss: 0.8146560192108154
Validation loss: 1.7375305391127063

Epoch: 6| Step: 12
Training loss: 0.5828319787979126
Validation loss: 1.7540550674161604

Epoch: 6| Step: 13
Training loss: 1.0562548637390137
Validation loss: 1.703781433002923

Epoch: 745| Step: 0
Training loss: 0.7092999219894409
Validation loss: 1.79809114497195

Epoch: 6| Step: 1
Training loss: 0.729262113571167
Validation loss: 1.6308319619906846

Epoch: 6| Step: 2
Training loss: 0.8395662307739258
Validation loss: 1.6912747172899143

Epoch: 6| Step: 3
Training loss: 0.6068946123123169
Validation loss: 1.6604158878326416

Epoch: 6| Step: 4
Training loss: 0.7786271572113037
Validation loss: 1.7087277109904955

Epoch: 6| Step: 5
Training loss: 1.0788614749908447
Validation loss: 1.7377315951931862

Epoch: 6| Step: 6
Training loss: 0.5666645765304565
Validation loss: 1.6417102365083591

Epoch: 6| Step: 7
Training loss: 0.8249974250793457
Validation loss: 1.7392613208422096

Epoch: 6| Step: 8
Training loss: 0.491180419921875
Validation loss: 1.7059731073276971

Epoch: 6| Step: 9
Training loss: 0.9926032423973083
Validation loss: 1.7297291653130644

Epoch: 6| Step: 10
Training loss: 0.8264210224151611
Validation loss: 1.7164659320667226

Epoch: 6| Step: 11
Training loss: 0.48130184412002563
Validation loss: 1.6919976113944926

Epoch: 6| Step: 12
Training loss: 0.6673504710197449
Validation loss: 1.719335183020561

Epoch: 6| Step: 13
Training loss: 0.6114017963409424
Validation loss: 1.7246307249992125

Epoch: 746| Step: 0
Training loss: 0.6571173071861267
Validation loss: 1.7309262047531784

Epoch: 6| Step: 1
Training loss: 0.8964878916740417
Validation loss: 1.7001804280024704

Epoch: 6| Step: 2
Training loss: 0.864733099937439
Validation loss: 1.728108129193706

Epoch: 6| Step: 3
Training loss: 0.5298640727996826
Validation loss: 1.6346238249091691

Epoch: 6| Step: 4
Training loss: 0.43651026487350464
Validation loss: 1.7347659859606015

Epoch: 6| Step: 5
Training loss: 0.3884243965148926
Validation loss: 1.7513741447079567

Epoch: 6| Step: 6
Training loss: 0.989996612071991
Validation loss: 1.7156163518146803

Epoch: 6| Step: 7
Training loss: 0.5814527869224548
Validation loss: 1.734494173398582

Epoch: 6| Step: 8
Training loss: 0.9404860138893127
Validation loss: 1.7295233639337684

Epoch: 6| Step: 9
Training loss: 0.46712803840637207
Validation loss: 1.690765893587502

Epoch: 6| Step: 10
Training loss: 0.714502215385437
Validation loss: 1.6727964749900244

Epoch: 6| Step: 11
Training loss: 0.6971142292022705
Validation loss: 1.6994025143243934

Epoch: 6| Step: 12
Training loss: 1.3932945728302002
Validation loss: 1.7170846257158505

Epoch: 6| Step: 13
Training loss: 0.590687096118927
Validation loss: 1.7107911020196893

Epoch: 747| Step: 0
Training loss: 0.9238447546958923
Validation loss: 1.7036702402176396

Epoch: 6| Step: 1
Training loss: 0.5008429884910583
Validation loss: 1.6956773932262132

Epoch: 6| Step: 2
Training loss: 0.48084592819213867
Validation loss: 1.7213340677240843

Epoch: 6| Step: 3
Training loss: 0.7836490869522095
Validation loss: 1.6675103582361692

Epoch: 6| Step: 4
Training loss: 0.5542985200881958
Validation loss: 1.6528970618401804

Epoch: 6| Step: 5
Training loss: 1.2627875804901123
Validation loss: 1.675396793632097

Epoch: 6| Step: 6
Training loss: 0.5925506353378296
Validation loss: 1.6402318131539129

Epoch: 6| Step: 7
Training loss: 0.9769281148910522
Validation loss: 1.6719307232928533

Epoch: 6| Step: 8
Training loss: 0.7495602965354919
Validation loss: 1.6832989966997536

Epoch: 6| Step: 9
Training loss: 0.7563443183898926
Validation loss: 1.7532228167339037

Epoch: 6| Step: 10
Training loss: 0.7933970093727112
Validation loss: 1.724843644326733

Epoch: 6| Step: 11
Training loss: 0.5418664813041687
Validation loss: 1.71932824068172

Epoch: 6| Step: 12
Training loss: 0.7691755294799805
Validation loss: 1.6462923967710106

Epoch: 6| Step: 13
Training loss: 0.938109278678894
Validation loss: 1.7170441278847315

Epoch: 748| Step: 0
Training loss: 0.7962476015090942
Validation loss: 1.7268246450731832

Epoch: 6| Step: 1
Training loss: 0.7090591192245483
Validation loss: 1.7068396255534182

Epoch: 6| Step: 2
Training loss: 0.7511115074157715
Validation loss: 1.704834367639275

Epoch: 6| Step: 3
Training loss: 1.0852633714675903
Validation loss: 1.7343766048390379

Epoch: 6| Step: 4
Training loss: 0.7250729203224182
Validation loss: 1.6318308896915887

Epoch: 6| Step: 5
Training loss: 1.122007131576538
Validation loss: 1.6887428286255046

Epoch: 6| Step: 6
Training loss: 0.6421934366226196
Validation loss: 1.6089417370416785

Epoch: 6| Step: 7
Training loss: 0.5593947768211365
Validation loss: 1.679164436555678

Epoch: 6| Step: 8
Training loss: 0.6041901707649231
Validation loss: 1.6551434032378658

Epoch: 6| Step: 9
Training loss: 0.5101335048675537
Validation loss: 1.6253865700896069

Epoch: 6| Step: 10
Training loss: 0.7077666521072388
Validation loss: 1.6620342885294268

Epoch: 6| Step: 11
Training loss: 1.0657927989959717
Validation loss: 1.721333061495135

Epoch: 6| Step: 12
Training loss: 0.7337307929992676
Validation loss: 1.7374553693238126

Epoch: 6| Step: 13
Training loss: 1.1585427522659302
Validation loss: 1.7559336436692106

Epoch: 749| Step: 0
Training loss: 0.519363284111023
Validation loss: 1.7074109405599616

Epoch: 6| Step: 1
Training loss: 0.9563762545585632
Validation loss: 1.7556864087299635

Epoch: 6| Step: 2
Training loss: 0.5747838020324707
Validation loss: 1.7007625179906045

Epoch: 6| Step: 3
Training loss: 0.9253532290458679
Validation loss: 1.7717427643396522

Epoch: 6| Step: 4
Training loss: 0.5336295962333679
Validation loss: 1.6782547536716665

Epoch: 6| Step: 5
Training loss: 1.1866847276687622
Validation loss: 1.7673975600991199

Epoch: 6| Step: 6
Training loss: 1.2359263896942139
Validation loss: 1.736601039927493

Epoch: 6| Step: 7
Training loss: 0.3397512435913086
Validation loss: 1.7235750741856073

Epoch: 6| Step: 8
Training loss: 1.0747042894363403
Validation loss: 1.6813693687479982

Epoch: 6| Step: 9
Training loss: 0.5530025959014893
Validation loss: 1.7016754214481642

Epoch: 6| Step: 10
Training loss: 0.7074775695800781
Validation loss: 1.6837569667446999

Epoch: 6| Step: 11
Training loss: 0.808882474899292
Validation loss: 1.6705730358759563

Epoch: 6| Step: 12
Training loss: 0.7271450757980347
Validation loss: 1.6959658361250354

Epoch: 6| Step: 13
Training loss: 0.14763623476028442
Validation loss: 1.7199108062251922

Epoch: 750| Step: 0
Training loss: 0.43452849984169006
Validation loss: 1.6785319005289385

Epoch: 6| Step: 1
Training loss: 0.9544119238853455
Validation loss: 1.696531057357788

Epoch: 6| Step: 2
Training loss: 0.6400743722915649
Validation loss: 1.6658206139841387

Epoch: 6| Step: 3
Training loss: 0.9802874326705933
Validation loss: 1.747449556986491

Epoch: 6| Step: 4
Training loss: 0.8164225816726685
Validation loss: 1.682396235004548

Epoch: 6| Step: 5
Training loss: 1.3781640529632568
Validation loss: 1.672822916379539

Epoch: 6| Step: 6
Training loss: 0.6502106189727783
Validation loss: 1.7055743355904855

Epoch: 6| Step: 7
Training loss: 0.817106306552887
Validation loss: 1.7004670237982145

Epoch: 6| Step: 8
Training loss: 0.7705426812171936
Validation loss: 1.716044351618777

Epoch: 6| Step: 9
Training loss: 0.38111257553100586
Validation loss: 1.6959973881321568

Epoch: 6| Step: 10
Training loss: 0.8739743828773499
Validation loss: 1.667750661091138

Epoch: 6| Step: 11
Training loss: 0.239525705575943
Validation loss: 1.6908649565071188

Epoch: 6| Step: 12
Training loss: 0.7150520086288452
Validation loss: 1.7384065658815446

Epoch: 6| Step: 13
Training loss: 0.6237582564353943
Validation loss: 1.6867056098035587

Epoch: 751| Step: 0
Training loss: 0.5788155794143677
Validation loss: 1.6730523019708612

Epoch: 6| Step: 1
Training loss: 0.9058697819709778
Validation loss: 1.6925562068980227

Epoch: 6| Step: 2
Training loss: 0.5990170240402222
Validation loss: 1.7028936237417243

Epoch: 6| Step: 3
Training loss: 1.1262576580047607
Validation loss: 1.6902801093234812

Epoch: 6| Step: 4
Training loss: 0.6942384243011475
Validation loss: 1.7213502801874632

Epoch: 6| Step: 5
Training loss: 0.5433009266853333
Validation loss: 1.7570140131058232

Epoch: 6| Step: 6
Training loss: 0.8281779289245605
Validation loss: 1.746593556096477

Epoch: 6| Step: 7
Training loss: 0.6622466444969177
Validation loss: 1.7273905789980324

Epoch: 6| Step: 8
Training loss: 0.694213330745697
Validation loss: 1.6959189061195619

Epoch: 6| Step: 9
Training loss: 0.6155091524124146
Validation loss: 1.729921624224673

Epoch: 6| Step: 10
Training loss: 0.6181496381759644
Validation loss: 1.7371983271773144

Epoch: 6| Step: 11
Training loss: 1.3748536109924316
Validation loss: 1.6785924601298507

Epoch: 6| Step: 12
Training loss: 0.6207273006439209
Validation loss: 1.745669008583151

Epoch: 6| Step: 13
Training loss: 0.7941043376922607
Validation loss: 1.7395331872406827

Epoch: 752| Step: 0
Training loss: 0.7771039605140686
Validation loss: 1.6786581816211823

Epoch: 6| Step: 1
Training loss: 0.5854195952415466
Validation loss: 1.6425531115583194

Epoch: 6| Step: 2
Training loss: 0.7748348712921143
Validation loss: 1.694885951857413

Epoch: 6| Step: 3
Training loss: 1.424739956855774
Validation loss: 1.6984840054665842

Epoch: 6| Step: 4
Training loss: 0.7763925194740295
Validation loss: 1.7143889268239338

Epoch: 6| Step: 5
Training loss: 0.5658644437789917
Validation loss: 1.7363844148574337

Epoch: 6| Step: 6
Training loss: 0.5689351558685303
Validation loss: 1.6538618303114367

Epoch: 6| Step: 7
Training loss: 0.8132482171058655
Validation loss: 1.715587656985047

Epoch: 6| Step: 8
Training loss: 0.5922096967697144
Validation loss: 1.6907642285029094

Epoch: 6| Step: 9
Training loss: 0.9465979933738708
Validation loss: 1.7211234274730887

Epoch: 6| Step: 10
Training loss: 0.5952932834625244
Validation loss: 1.697770413532052

Epoch: 6| Step: 11
Training loss: 0.4415600597858429
Validation loss: 1.7648995960912397

Epoch: 6| Step: 12
Training loss: 1.2234439849853516
Validation loss: 1.7391402106131277

Epoch: 6| Step: 13
Training loss: 0.3803750276565552
Validation loss: 1.726155440012614

Epoch: 753| Step: 0
Training loss: 0.5480999946594238
Validation loss: 1.7236762098086778

Epoch: 6| Step: 1
Training loss: 0.32586339116096497
Validation loss: 1.7513539022014988

Epoch: 6| Step: 2
Training loss: 0.6221964359283447
Validation loss: 1.6511689450151177

Epoch: 6| Step: 3
Training loss: 0.6355295777320862
Validation loss: 1.6810194318012526

Epoch: 6| Step: 4
Training loss: 0.794517993927002
Validation loss: 1.7553149423291605

Epoch: 6| Step: 5
Training loss: 1.0367242097854614
Validation loss: 1.6737698342210503

Epoch: 6| Step: 6
Training loss: 1.3206582069396973
Validation loss: 1.7205863204053653

Epoch: 6| Step: 7
Training loss: 0.9019098281860352
Validation loss: 1.7023620246559061

Epoch: 6| Step: 8
Training loss: 0.902031660079956
Validation loss: 1.6869554852926603

Epoch: 6| Step: 9
Training loss: 1.0540220737457275
Validation loss: 1.7371525508101269

Epoch: 6| Step: 10
Training loss: 0.8689294457435608
Validation loss: 1.644281828275291

Epoch: 6| Step: 11
Training loss: 0.7387746572494507
Validation loss: 1.7333539608986146

Epoch: 6| Step: 12
Training loss: 0.4106152057647705
Validation loss: 1.6456659872044799

Epoch: 6| Step: 13
Training loss: 0.5622060298919678
Validation loss: 1.7111943293643255

Epoch: 754| Step: 0
Training loss: 0.7821005582809448
Validation loss: 1.731883797594296

Epoch: 6| Step: 1
Training loss: 0.8973737955093384
Validation loss: 1.7365422556477208

Epoch: 6| Step: 2
Training loss: 0.7107191681861877
Validation loss: 1.6997061224393948

Epoch: 6| Step: 3
Training loss: 0.7948708534240723
Validation loss: 1.7280681543452765

Epoch: 6| Step: 4
Training loss: 1.382142424583435
Validation loss: 1.7725440821340006

Epoch: 6| Step: 5
Training loss: 0.7460659742355347
Validation loss: 1.7224573384049118

Epoch: 6| Step: 6
Training loss: 0.5206891298294067
Validation loss: 1.7501087060538671

Epoch: 6| Step: 7
Training loss: 0.6239824295043945
Validation loss: 1.7251215878353323

Epoch: 6| Step: 8
Training loss: 0.39188504219055176
Validation loss: 1.7211694358497538

Epoch: 6| Step: 9
Training loss: 0.555557131767273
Validation loss: 1.7498592445927281

Epoch: 6| Step: 10
Training loss: 0.9240611791610718
Validation loss: 1.7044361073483703

Epoch: 6| Step: 11
Training loss: 0.42677420377731323
Validation loss: 1.727323269331327

Epoch: 6| Step: 12
Training loss: 1.08897066116333
Validation loss: 1.7275413467038063

Epoch: 6| Step: 13
Training loss: 0.3482653796672821
Validation loss: 1.6616195068564465

Epoch: 755| Step: 0
Training loss: 1.20747971534729
Validation loss: 1.7366252945315452

Epoch: 6| Step: 1
Training loss: 0.5106316804885864
Validation loss: 1.6761085064180437

Epoch: 6| Step: 2
Training loss: 0.849622368812561
Validation loss: 1.6804119066525531

Epoch: 6| Step: 3
Training loss: 0.6709325909614563
Validation loss: 1.7418440285549368

Epoch: 6| Step: 4
Training loss: 0.42828744649887085
Validation loss: 1.6772432711816603

Epoch: 6| Step: 5
Training loss: 0.7515773773193359
Validation loss: 1.7369376843975437

Epoch: 6| Step: 6
Training loss: 0.796891450881958
Validation loss: 1.686462265188976

Epoch: 6| Step: 7
Training loss: 0.7241675853729248
Validation loss: 1.6637524238196753

Epoch: 6| Step: 8
Training loss: 0.6860808730125427
Validation loss: 1.6846346342435448

Epoch: 6| Step: 9
Training loss: 0.7600569128990173
Validation loss: 1.661573669602794

Epoch: 6| Step: 10
Training loss: 0.8000770211219788
Validation loss: 1.6792273188150058

Epoch: 6| Step: 11
Training loss: 0.9111888408660889
Validation loss: 1.7659893894708285

Epoch: 6| Step: 12
Training loss: 0.8969674706459045
Validation loss: 1.6331738246384488

Epoch: 6| Step: 13
Training loss: 0.6587994694709778
Validation loss: 1.7388259492894655

Epoch: 756| Step: 0
Training loss: 0.5222741365432739
Validation loss: 1.7952805231976252

Epoch: 6| Step: 1
Training loss: 0.5080028176307678
Validation loss: 1.8053645549281951

Epoch: 6| Step: 2
Training loss: 0.9751235842704773
Validation loss: 1.7789176228225871

Epoch: 6| Step: 3
Training loss: 0.629369854927063
Validation loss: 1.8038990638589347

Epoch: 6| Step: 4
Training loss: 0.5973097681999207
Validation loss: 1.7757298972017022

Epoch: 6| Step: 5
Training loss: 0.7941352725028992
Validation loss: 1.73034970478345

Epoch: 6| Step: 6
Training loss: 0.8645889759063721
Validation loss: 1.7428977758653703

Epoch: 6| Step: 7
Training loss: 0.4441664218902588
Validation loss: 1.6519120072805753

Epoch: 6| Step: 8
Training loss: 0.581993818283081
Validation loss: 1.7037475198827765

Epoch: 6| Step: 9
Training loss: 0.6268295049667358
Validation loss: 1.623958642764758

Epoch: 6| Step: 10
Training loss: 1.0884958505630493
Validation loss: 1.6730618066685174

Epoch: 6| Step: 11
Training loss: 0.3888389766216278
Validation loss: 1.726265234331931

Epoch: 6| Step: 12
Training loss: 0.9069815874099731
Validation loss: 1.7915532781231789

Epoch: 6| Step: 13
Training loss: 1.1625628471374512
Validation loss: 1.7136867879539408

Epoch: 757| Step: 0
Training loss: 0.532484233379364
Validation loss: 1.6580332056168587

Epoch: 6| Step: 1
Training loss: 0.6014614105224609
Validation loss: 1.6672958609878377

Epoch: 6| Step: 2
Training loss: 0.8667877912521362
Validation loss: 1.6798050147230907

Epoch: 6| Step: 3
Training loss: 0.9573829770088196
Validation loss: 1.7289880700008844

Epoch: 6| Step: 4
Training loss: 0.5035181045532227
Validation loss: 1.6916738953641666

Epoch: 6| Step: 5
Training loss: 0.845552384853363
Validation loss: 1.668272864434027

Epoch: 6| Step: 6
Training loss: 0.5915025472640991
Validation loss: 1.6754428635361374

Epoch: 6| Step: 7
Training loss: 0.6320258378982544
Validation loss: 1.6914467132219704

Epoch: 6| Step: 8
Training loss: 0.7206341624259949
Validation loss: 1.6645356865339382

Epoch: 6| Step: 9
Training loss: 0.9376963376998901
Validation loss: 1.6851570439595047

Epoch: 6| Step: 10
Training loss: 0.5342938899993896
Validation loss: 1.6984189159126692

Epoch: 6| Step: 11
Training loss: 0.7224084138870239
Validation loss: 1.7018019178862214

Epoch: 6| Step: 12
Training loss: 0.8563635349273682
Validation loss: 1.6995927005685785

Epoch: 6| Step: 13
Training loss: 0.9308580756187439
Validation loss: 1.6839652458826702

Epoch: 758| Step: 0
Training loss: 0.3711376488208771
Validation loss: 1.6913448085067093

Epoch: 6| Step: 1
Training loss: 0.6928278803825378
Validation loss: 1.6682971574926888

Epoch: 6| Step: 2
Training loss: 1.1548269987106323
Validation loss: 1.7099802699140323

Epoch: 6| Step: 3
Training loss: 0.38726726174354553
Validation loss: 1.6611827047922278

Epoch: 6| Step: 4
Training loss: 0.9271337985992432
Validation loss: 1.7218692879523

Epoch: 6| Step: 5
Training loss: 0.7974659204483032
Validation loss: 1.6962962137755526

Epoch: 6| Step: 6
Training loss: 0.7266169786453247
Validation loss: 1.6775040357343611

Epoch: 6| Step: 7
Training loss: 0.5891580581665039
Validation loss: 1.738644616578215

Epoch: 6| Step: 8
Training loss: 0.47820255160331726
Validation loss: 1.6913632269828551

Epoch: 6| Step: 9
Training loss: 0.5412104725837708
Validation loss: 1.657584023732011

Epoch: 6| Step: 10
Training loss: 0.975522518157959
Validation loss: 1.6259603641366447

Epoch: 6| Step: 11
Training loss: 0.9651553630828857
Validation loss: 1.7184231486371768

Epoch: 6| Step: 12
Training loss: 0.8039944171905518
Validation loss: 1.6586422497226345

Epoch: 6| Step: 13
Training loss: 1.1172550916671753
Validation loss: 1.713438887749949

Epoch: 759| Step: 0
Training loss: 0.8423572778701782
Validation loss: 1.646975947964576

Epoch: 6| Step: 1
Training loss: 1.0469833612442017
Validation loss: 1.7242641718156877

Epoch: 6| Step: 2
Training loss: 0.7169355154037476
Validation loss: 1.721699606987738

Epoch: 6| Step: 3
Training loss: 0.40829890966415405
Validation loss: 1.6696839960672523

Epoch: 6| Step: 4
Training loss: 0.4685332477092743
Validation loss: 1.7002936255547307

Epoch: 6| Step: 5
Training loss: 0.9111480712890625
Validation loss: 1.6566170505298081

Epoch: 6| Step: 6
Training loss: 1.2168877124786377
Validation loss: 1.7150981862057921

Epoch: 6| Step: 7
Training loss: 0.9479278326034546
Validation loss: 1.756591667411148

Epoch: 6| Step: 8
Training loss: 0.6836308240890503
Validation loss: 1.7054335763377528

Epoch: 6| Step: 9
Training loss: 0.8623252511024475
Validation loss: 1.7374755567119968

Epoch: 6| Step: 10
Training loss: 0.336383581161499
Validation loss: 1.670829975476829

Epoch: 6| Step: 11
Training loss: 0.6929199695587158
Validation loss: 1.7378913664048719

Epoch: 6| Step: 12
Training loss: 0.4892346262931824
Validation loss: 1.6632159089529386

Epoch: 6| Step: 13
Training loss: 0.7381864786148071
Validation loss: 1.7640405957416823

Epoch: 760| Step: 0
Training loss: 0.45513370633125305
Validation loss: 1.7249115436307845

Epoch: 6| Step: 1
Training loss: 0.5333012938499451
Validation loss: 1.723127753503861

Epoch: 6| Step: 2
Training loss: 0.836437463760376
Validation loss: 1.7091375576552523

Epoch: 6| Step: 3
Training loss: 0.5000481009483337
Validation loss: 1.7341658966515654

Epoch: 6| Step: 4
Training loss: 0.652242124080658
Validation loss: 1.755445864892775

Epoch: 6| Step: 5
Training loss: 0.7372034788131714
Validation loss: 1.7379299825237644

Epoch: 6| Step: 6
Training loss: 1.0522010326385498
Validation loss: 1.7599144558752737

Epoch: 6| Step: 7
Training loss: 0.7014379501342773
Validation loss: 1.755878879177955

Epoch: 6| Step: 8
Training loss: 1.233076810836792
Validation loss: 1.6839893517955657

Epoch: 6| Step: 9
Training loss: 0.859065055847168
Validation loss: 1.6977050509504092

Epoch: 6| Step: 10
Training loss: 0.5676629543304443
Validation loss: 1.7615713316907164

Epoch: 6| Step: 11
Training loss: 1.0391550064086914
Validation loss: 1.6135821957742014

Epoch: 6| Step: 12
Training loss: 0.5266793370246887
Validation loss: 1.7126073247642928

Epoch: 6| Step: 13
Training loss: 0.26138564944267273
Validation loss: 1.7002798318862915

Epoch: 761| Step: 0
Training loss: 0.476724773645401
Validation loss: 1.6934380005764704

Epoch: 6| Step: 1
Training loss: 0.5876721143722534
Validation loss: 1.6747235816012147

Epoch: 6| Step: 2
Training loss: 0.7779998779296875
Validation loss: 1.6843724045702206

Epoch: 6| Step: 3
Training loss: 0.7730388641357422
Validation loss: 1.7123441016802223

Epoch: 6| Step: 4
Training loss: 0.3208423852920532
Validation loss: 1.7554950060382966

Epoch: 6| Step: 5
Training loss: 1.2656340599060059
Validation loss: 1.6957246898322977

Epoch: 6| Step: 6
Training loss: 0.8269792199134827
Validation loss: 1.7560696332685408

Epoch: 6| Step: 7
Training loss: 0.6952828168869019
Validation loss: 1.7244327709239016

Epoch: 6| Step: 8
Training loss: 0.367873877286911
Validation loss: 1.7237177753961215

Epoch: 6| Step: 9
Training loss: 0.36582624912261963
Validation loss: 1.6862959759209746

Epoch: 6| Step: 10
Training loss: 0.9835577011108398
Validation loss: 1.6994731298056982

Epoch: 6| Step: 11
Training loss: 0.6534076929092407
Validation loss: 1.7147094511216687

Epoch: 6| Step: 12
Training loss: 1.0431839227676392
Validation loss: 1.7476313908894856

Epoch: 6| Step: 13
Training loss: 1.0273735523223877
Validation loss: 1.6569630535699988

Epoch: 762| Step: 0
Training loss: 0.648950457572937
Validation loss: 1.7054636811697355

Epoch: 6| Step: 1
Training loss: 0.5834927558898926
Validation loss: 1.669358253479004

Epoch: 6| Step: 2
Training loss: 0.41057103872299194
Validation loss: 1.6824255438261135

Epoch: 6| Step: 3
Training loss: 0.7598038911819458
Validation loss: 1.6410954754839662

Epoch: 6| Step: 4
Training loss: 0.49693381786346436
Validation loss: 1.6913150068252318

Epoch: 6| Step: 5
Training loss: 0.5569072961807251
Validation loss: 1.7156675861727806

Epoch: 6| Step: 6
Training loss: 0.7404568195343018
Validation loss: 1.63936052783843

Epoch: 6| Step: 7
Training loss: 0.6880275011062622
Validation loss: 1.7133843052771784

Epoch: 6| Step: 8
Training loss: 1.1297607421875
Validation loss: 1.6938677269925353

Epoch: 6| Step: 9
Training loss: 0.7363626956939697
Validation loss: 1.7364681984788628

Epoch: 6| Step: 10
Training loss: 0.5979307889938354
Validation loss: 1.7323290955635808

Epoch: 6| Step: 11
Training loss: 1.1653555631637573
Validation loss: 1.7571269850577078

Epoch: 6| Step: 12
Training loss: 0.793921947479248
Validation loss: 1.7813865651366532

Epoch: 6| Step: 13
Training loss: 1.1924591064453125
Validation loss: 1.709882752869719

Epoch: 763| Step: 0
Training loss: 0.6243209838867188
Validation loss: 1.8278336999236897

Epoch: 6| Step: 1
Training loss: 1.1152948141098022
Validation loss: 1.7287650896656899

Epoch: 6| Step: 2
Training loss: 0.7779128551483154
Validation loss: 1.7497691544153358

Epoch: 6| Step: 3
Training loss: 0.6962227821350098
Validation loss: 1.6767190284626459

Epoch: 6| Step: 4
Training loss: 0.75105881690979
Validation loss: 1.7007591698759346

Epoch: 6| Step: 5
Training loss: 0.3181666135787964
Validation loss: 1.701351245244344

Epoch: 6| Step: 6
Training loss: 0.5557755827903748
Validation loss: 1.6847919379511187

Epoch: 6| Step: 7
Training loss: 0.6950514316558838
Validation loss: 1.6758900252721642

Epoch: 6| Step: 8
Training loss: 0.61269611120224
Validation loss: 1.7152070140325895

Epoch: 6| Step: 9
Training loss: 0.5030230283737183
Validation loss: 1.7194004642066134

Epoch: 6| Step: 10
Training loss: 0.5561615228652954
Validation loss: 1.7099642151145524

Epoch: 6| Step: 11
Training loss: 0.8259701132774353
Validation loss: 1.7025717253326087

Epoch: 6| Step: 12
Training loss: 0.8958727121353149
Validation loss: 1.7102111001168527

Epoch: 6| Step: 13
Training loss: 1.4246234893798828
Validation loss: 1.709120128744392

Epoch: 764| Step: 0
Training loss: 0.4978475868701935
Validation loss: 1.717251782776207

Epoch: 6| Step: 1
Training loss: 0.6846762895584106
Validation loss: 1.6908401122657202

Epoch: 6| Step: 2
Training loss: 0.9181016087532043
Validation loss: 1.73570817260332

Epoch: 6| Step: 3
Training loss: 0.5942661166191101
Validation loss: 1.692237461766889

Epoch: 6| Step: 4
Training loss: 0.5641549229621887
Validation loss: 1.6642438557840162

Epoch: 6| Step: 5
Training loss: 0.8222032785415649
Validation loss: 1.6819347822537987

Epoch: 6| Step: 6
Training loss: 0.983433187007904
Validation loss: 1.655609207768594

Epoch: 6| Step: 7
Training loss: 0.414414644241333
Validation loss: 1.7066110577634586

Epoch: 6| Step: 8
Training loss: 1.2010538578033447
Validation loss: 1.7141115409071728

Epoch: 6| Step: 9
Training loss: 0.5786437392234802
Validation loss: 1.6533307798447148

Epoch: 6| Step: 10
Training loss: 0.9556939601898193
Validation loss: 1.6991775035858154

Epoch: 6| Step: 11
Training loss: 0.9964432120323181
Validation loss: 1.7155038079907816

Epoch: 6| Step: 12
Training loss: 0.6433531641960144
Validation loss: 1.721951348807222

Epoch: 6| Step: 13
Training loss: 0.5214426517486572
Validation loss: 1.7353900773550874

Epoch: 765| Step: 0
Training loss: 0.6452791094779968
Validation loss: 1.7728879720933977

Epoch: 6| Step: 1
Training loss: 0.6423461437225342
Validation loss: 1.6372780530683455

Epoch: 6| Step: 2
Training loss: 0.7693644762039185
Validation loss: 1.7851042811588576

Epoch: 6| Step: 3
Training loss: 1.0155892372131348
Validation loss: 1.7197111011833273

Epoch: 6| Step: 4
Training loss: 0.9942371845245361
Validation loss: 1.698433704273675

Epoch: 6| Step: 5
Training loss: 0.319915771484375
Validation loss: 1.7005484655339231

Epoch: 6| Step: 6
Training loss: 0.6008222699165344
Validation loss: 1.6918555972396687

Epoch: 6| Step: 7
Training loss: 0.7842860817909241
Validation loss: 1.6925943436161164

Epoch: 6| Step: 8
Training loss: 0.5913041830062866
Validation loss: 1.6927692531257548

Epoch: 6| Step: 9
Training loss: 0.8209667205810547
Validation loss: 1.7133808776896486

Epoch: 6| Step: 10
Training loss: 0.8543776273727417
Validation loss: 1.6755553765963482

Epoch: 6| Step: 11
Training loss: 0.8931882977485657
Validation loss: 1.7431042245639268

Epoch: 6| Step: 12
Training loss: 0.3824620842933655
Validation loss: 1.6817200811960364

Epoch: 6| Step: 13
Training loss: 0.8419849872589111
Validation loss: 1.7072009617282498

Epoch: 766| Step: 0
Training loss: 0.6366660594940186
Validation loss: 1.636471366369596

Epoch: 6| Step: 1
Training loss: 0.4410718083381653
Validation loss: 1.692384272493342

Epoch: 6| Step: 2
Training loss: 0.5352863669395447
Validation loss: 1.7302422978544747

Epoch: 6| Step: 3
Training loss: 1.1598193645477295
Validation loss: 1.6774417969488329

Epoch: 6| Step: 4
Training loss: 0.5216865539550781
Validation loss: 1.7502144587937223

Epoch: 6| Step: 5
Training loss: 0.751579999923706
Validation loss: 1.7139958156052457

Epoch: 6| Step: 6
Training loss: 0.7052772045135498
Validation loss: 1.7028288456701464

Epoch: 6| Step: 7
Training loss: 0.7886228561401367
Validation loss: 1.6905214273801414

Epoch: 6| Step: 8
Training loss: 0.8740668296813965
Validation loss: 1.6967116799405826

Epoch: 6| Step: 9
Training loss: 0.5319381952285767
Validation loss: 1.6797147361181115

Epoch: 6| Step: 10
Training loss: 0.7753676176071167
Validation loss: 1.6615452894600489

Epoch: 6| Step: 11
Training loss: 0.6612324714660645
Validation loss: 1.668419361114502

Epoch: 6| Step: 12
Training loss: 0.8366323709487915
Validation loss: 1.7278599354528612

Epoch: 6| Step: 13
Training loss: 1.1547753810882568
Validation loss: 1.6975979317900955

Epoch: 767| Step: 0
Training loss: 0.7680349349975586
Validation loss: 1.6952106734757781

Epoch: 6| Step: 1
Training loss: 1.2514958381652832
Validation loss: 1.704831571989162

Epoch: 6| Step: 2
Training loss: 0.6502629518508911
Validation loss: 1.7234929505214895

Epoch: 6| Step: 3
Training loss: 0.6002488136291504
Validation loss: 1.6949486258209392

Epoch: 6| Step: 4
Training loss: 0.4191419184207916
Validation loss: 1.7001342414527811

Epoch: 6| Step: 5
Training loss: 0.8139435052871704
Validation loss: 1.7244676402820054

Epoch: 6| Step: 6
Training loss: 0.9500404596328735
Validation loss: 1.7454713224082865

Epoch: 6| Step: 7
Training loss: 0.6511001586914062
Validation loss: 1.6795716234432754

Epoch: 6| Step: 8
Training loss: 0.9958342909812927
Validation loss: 1.7254618008931477

Epoch: 6| Step: 9
Training loss: 0.6809777021408081
Validation loss: 1.7534439179205126

Epoch: 6| Step: 10
Training loss: 0.6292246580123901
Validation loss: 1.788539501928514

Epoch: 6| Step: 11
Training loss: 0.5501265525817871
Validation loss: 1.7103151941812167

Epoch: 6| Step: 12
Training loss: 0.42722025513648987
Validation loss: 1.657280957827004

Epoch: 6| Step: 13
Training loss: 0.6992290019989014
Validation loss: 1.7156954439737464

Epoch: 768| Step: 0
Training loss: 0.6256635785102844
Validation loss: 1.6855382970584336

Epoch: 6| Step: 1
Training loss: 0.5596404671669006
Validation loss: 1.7020282463360858

Epoch: 6| Step: 2
Training loss: 0.5254164934158325
Validation loss: 1.6712287754140875

Epoch: 6| Step: 3
Training loss: 0.8037819862365723
Validation loss: 1.7317627386380268

Epoch: 6| Step: 4
Training loss: 0.74950110912323
Validation loss: 1.6735924918164489

Epoch: 6| Step: 5
Training loss: 0.927618145942688
Validation loss: 1.7644913927201302

Epoch: 6| Step: 6
Training loss: 0.5554376244544983
Validation loss: 1.6980232513079079

Epoch: 6| Step: 7
Training loss: 1.1300355195999146
Validation loss: 1.777806794771584

Epoch: 6| Step: 8
Training loss: 0.7557356357574463
Validation loss: 1.6981922887986707

Epoch: 6| Step: 9
Training loss: 1.2457221746444702
Validation loss: 1.7460295500293854

Epoch: 6| Step: 10
Training loss: 0.8926326036453247
Validation loss: 1.716890956765862

Epoch: 6| Step: 11
Training loss: 0.463650107383728
Validation loss: 1.7046694588917557

Epoch: 6| Step: 12
Training loss: 0.7394027709960938
Validation loss: 1.6729232611194733

Epoch: 6| Step: 13
Training loss: 0.48964935541152954
Validation loss: 1.8087708091223111

Epoch: 769| Step: 0
Training loss: 0.6642859578132629
Validation loss: 1.7481287512727963

Epoch: 6| Step: 1
Training loss: 0.40969109535217285
Validation loss: 1.6967801740092616

Epoch: 6| Step: 2
Training loss: 0.7465344667434692
Validation loss: 1.6853894264467302

Epoch: 6| Step: 3
Training loss: 0.5027008056640625
Validation loss: 1.71460469179256

Epoch: 6| Step: 4
Training loss: 0.7310905456542969
Validation loss: 1.7147172356164584

Epoch: 6| Step: 5
Training loss: 0.3738635182380676
Validation loss: 1.7351185506389988

Epoch: 6| Step: 6
Training loss: 0.5761038661003113
Validation loss: 1.6644109141442083

Epoch: 6| Step: 7
Training loss: 0.49378299713134766
Validation loss: 1.6494215829398042

Epoch: 6| Step: 8
Training loss: 0.6651747822761536
Validation loss: 1.7290509285465363

Epoch: 6| Step: 9
Training loss: 0.8840211629867554
Validation loss: 1.7056884432351718

Epoch: 6| Step: 10
Training loss: 0.9713714122772217
Validation loss: 1.7430992780193206

Epoch: 6| Step: 11
Training loss: 0.7516332864761353
Validation loss: 1.7447997139346214

Epoch: 6| Step: 12
Training loss: 1.6118627786636353
Validation loss: 1.6869092154246506

Epoch: 6| Step: 13
Training loss: 0.6741873025894165
Validation loss: 1.6694255182819981

Epoch: 770| Step: 0
Training loss: 0.8415288925170898
Validation loss: 1.6611250728689215

Epoch: 6| Step: 1
Training loss: 0.6439348459243774
Validation loss: 1.7175355688218148

Epoch: 6| Step: 2
Training loss: 0.682975709438324
Validation loss: 1.693065321573647

Epoch: 6| Step: 3
Training loss: 0.6818441152572632
Validation loss: 1.7049881283954909

Epoch: 6| Step: 4
Training loss: 0.9682552814483643
Validation loss: 1.6599024579089174

Epoch: 6| Step: 5
Training loss: 0.5244566202163696
Validation loss: 1.710282543654083

Epoch: 6| Step: 6
Training loss: 0.36906924843788147
Validation loss: 1.775507552649385

Epoch: 6| Step: 7
Training loss: 0.7609659433364868
Validation loss: 1.6703078105885496

Epoch: 6| Step: 8
Training loss: 0.4158872067928314
Validation loss: 1.662402404251919

Epoch: 6| Step: 9
Training loss: 1.0193850994110107
Validation loss: 1.676092484945892

Epoch: 6| Step: 10
Training loss: 0.8406099677085876
Validation loss: 1.7493321921235772

Epoch: 6| Step: 11
Training loss: 0.5416711568832397
Validation loss: 1.6602558205204625

Epoch: 6| Step: 12
Training loss: 0.7310397624969482
Validation loss: 1.668994148572286

Epoch: 6| Step: 13
Training loss: 1.0325734615325928
Validation loss: 1.774172375279088

Epoch: 771| Step: 0
Training loss: 0.8728252053260803
Validation loss: 1.7112404018320062

Epoch: 6| Step: 1
Training loss: 1.0253889560699463
Validation loss: 1.787037532816651

Epoch: 6| Step: 2
Training loss: 0.5480706095695496
Validation loss: 1.707285652878464

Epoch: 6| Step: 3
Training loss: 0.6211647391319275
Validation loss: 1.7741906501913582

Epoch: 6| Step: 4
Training loss: 0.9354661107063293
Validation loss: 1.7094221038203086

Epoch: 6| Step: 5
Training loss: 0.3398941159248352
Validation loss: 1.7085569789332729

Epoch: 6| Step: 6
Training loss: 0.766930103302002
Validation loss: 1.746797416799812

Epoch: 6| Step: 7
Training loss: 0.9090410470962524
Validation loss: 1.7460519959849696

Epoch: 6| Step: 8
Training loss: 0.7727265357971191
Validation loss: 1.6941469241214056

Epoch: 6| Step: 9
Training loss: 0.3040696382522583
Validation loss: 1.6478101745728524

Epoch: 6| Step: 10
Training loss: 0.667045533657074
Validation loss: 1.700740788572578

Epoch: 6| Step: 11
Training loss: 1.3507040739059448
Validation loss: 1.6311350971139886

Epoch: 6| Step: 12
Training loss: 0.5485957860946655
Validation loss: 1.6963306268056233

Epoch: 6| Step: 13
Training loss: 1.1608548164367676
Validation loss: 1.68342432027222

Epoch: 772| Step: 0
Training loss: 0.8316181898117065
Validation loss: 1.648927951371798

Epoch: 6| Step: 1
Training loss: 0.7985008955001831
Validation loss: 1.636614393162471

Epoch: 6| Step: 2
Training loss: 0.5632870197296143
Validation loss: 1.6958359774722849

Epoch: 6| Step: 3
Training loss: 0.6333552598953247
Validation loss: 1.7158524861899755

Epoch: 6| Step: 4
Training loss: 0.5557408332824707
Validation loss: 1.697541465041458

Epoch: 6| Step: 5
Training loss: 0.6669517159461975
Validation loss: 1.714315286246679

Epoch: 6| Step: 6
Training loss: 0.479043185710907
Validation loss: 1.7344911220253154

Epoch: 6| Step: 7
Training loss: 0.8185209631919861
Validation loss: 1.7328597858387937

Epoch: 6| Step: 8
Training loss: 0.8041824102401733
Validation loss: 1.7280117427149126

Epoch: 6| Step: 9
Training loss: 0.8880891799926758
Validation loss: 1.6805897611443714

Epoch: 6| Step: 10
Training loss: 1.0022093057632446
Validation loss: 1.6569292949092003

Epoch: 6| Step: 11
Training loss: 0.7322990894317627
Validation loss: 1.6918784136413245

Epoch: 6| Step: 12
Training loss: 0.6291956901550293
Validation loss: 1.6831661937057332

Epoch: 6| Step: 13
Training loss: 0.49626022577285767
Validation loss: 1.7511884012529928

Epoch: 773| Step: 0
Training loss: 0.7804713845252991
Validation loss: 1.6976707891751361

Epoch: 6| Step: 1
Training loss: 0.674219012260437
Validation loss: 1.5992913528155255

Epoch: 6| Step: 2
Training loss: 0.8338596820831299
Validation loss: 1.6907371731214627

Epoch: 6| Step: 3
Training loss: 0.8014845252037048
Validation loss: 1.6974182795452815

Epoch: 6| Step: 4
Training loss: 0.2741851508617401
Validation loss: 1.7060097302159956

Epoch: 6| Step: 5
Training loss: 0.6704597473144531
Validation loss: 1.6618959621716571

Epoch: 6| Step: 6
Training loss: 0.5655211210250854
Validation loss: 1.7513110829937844

Epoch: 6| Step: 7
Training loss: 1.1596529483795166
Validation loss: 1.6570873478407502

Epoch: 6| Step: 8
Training loss: 0.9506903886795044
Validation loss: 1.6706257545819847

Epoch: 6| Step: 9
Training loss: 0.5564460754394531
Validation loss: 1.663229650066745

Epoch: 6| Step: 10
Training loss: 0.7809641361236572
Validation loss: 1.6863235594123922

Epoch: 6| Step: 11
Training loss: 0.9345853328704834
Validation loss: 1.689735843289283

Epoch: 6| Step: 12
Training loss: 0.7355746626853943
Validation loss: 1.6947152435138662

Epoch: 6| Step: 13
Training loss: 0.26110658049583435
Validation loss: 1.666483239461017

Epoch: 774| Step: 0
Training loss: 0.7142559885978699
Validation loss: 1.7498441985858384

Epoch: 6| Step: 1
Training loss: 0.8225244879722595
Validation loss: 1.6746543735586188

Epoch: 6| Step: 2
Training loss: 0.3365243077278137
Validation loss: 1.7065456362180813

Epoch: 6| Step: 3
Training loss: 0.48913079500198364
Validation loss: 1.744746010790589

Epoch: 6| Step: 4
Training loss: 0.7736163139343262
Validation loss: 1.6870111086035287

Epoch: 6| Step: 5
Training loss: 1.4507098197937012
Validation loss: 1.6465012950281943

Epoch: 6| Step: 6
Training loss: 0.4790303409099579
Validation loss: 1.7125958550360896

Epoch: 6| Step: 7
Training loss: 0.6401921510696411
Validation loss: 1.6807599811143772

Epoch: 6| Step: 8
Training loss: 0.7901986837387085
Validation loss: 1.7344864952948786

Epoch: 6| Step: 9
Training loss: 0.7993899583816528
Validation loss: 1.7581891962276992

Epoch: 6| Step: 10
Training loss: 0.3894128203392029
Validation loss: 1.7323902307018157

Epoch: 6| Step: 11
Training loss: 0.8530646562576294
Validation loss: 1.7054959727871803

Epoch: 6| Step: 12
Training loss: 0.9546504020690918
Validation loss: 1.6737304502917874

Epoch: 6| Step: 13
Training loss: 0.37889984250068665
Validation loss: 1.7030305400971444

Epoch: 775| Step: 0
Training loss: 0.7339099645614624
Validation loss: 1.6877161264419556

Epoch: 6| Step: 1
Training loss: 0.5619303584098816
Validation loss: 1.6911423129420127

Epoch: 6| Step: 2
Training loss: 1.1648125648498535
Validation loss: 1.7029245207386632

Epoch: 6| Step: 3
Training loss: 0.7594306468963623
Validation loss: 1.6465636786594187

Epoch: 6| Step: 4
Training loss: 1.2875721454620361
Validation loss: 1.660619467817327

Epoch: 6| Step: 5
Training loss: 0.8285592794418335
Validation loss: 1.6665221670622468

Epoch: 6| Step: 6
Training loss: 0.49311262369155884
Validation loss: 1.701525229279713

Epoch: 6| Step: 7
Training loss: 0.9956834316253662
Validation loss: 1.683784992464127

Epoch: 6| Step: 8
Training loss: 0.5557281970977783
Validation loss: 1.7164568798516386

Epoch: 6| Step: 9
Training loss: 0.772840678691864
Validation loss: 1.7027387093472224

Epoch: 6| Step: 10
Training loss: 0.7435413002967834
Validation loss: 1.6379769886693647

Epoch: 6| Step: 11
Training loss: 0.9302675724029541
Validation loss: 1.689332986390719

Epoch: 6| Step: 12
Training loss: 0.37781310081481934
Validation loss: 1.689155024866904

Epoch: 6| Step: 13
Training loss: 0.25982776284217834
Validation loss: 1.7063396823021673

Epoch: 776| Step: 0
Training loss: 1.2399007081985474
Validation loss: 1.6869487339450466

Epoch: 6| Step: 1
Training loss: 0.6816426515579224
Validation loss: 1.7177361852379256

Epoch: 6| Step: 2
Training loss: 0.3273605704307556
Validation loss: 1.6669690814069522

Epoch: 6| Step: 3
Training loss: 0.40069273114204407
Validation loss: 1.6920248282852994

Epoch: 6| Step: 4
Training loss: 1.0276029109954834
Validation loss: 1.6364292188357281

Epoch: 6| Step: 5
Training loss: 0.9224904775619507
Validation loss: 1.694219655888055

Epoch: 6| Step: 6
Training loss: 0.9041292667388916
Validation loss: 1.7100362213709022

Epoch: 6| Step: 7
Training loss: 0.8850668668746948
Validation loss: 1.617543105156191

Epoch: 6| Step: 8
Training loss: 0.8336822986602783
Validation loss: 1.6687877690920265

Epoch: 6| Step: 9
Training loss: 1.0697412490844727
Validation loss: 1.6360953777067122

Epoch: 6| Step: 10
Training loss: 0.3374236226081848
Validation loss: 1.6598218230790989

Epoch: 6| Step: 11
Training loss: 0.5391756892204285
Validation loss: 1.6219878414625764

Epoch: 6| Step: 12
Training loss: 0.41731691360473633
Validation loss: 1.6741704069158083

Epoch: 6| Step: 13
Training loss: 0.8574045300483704
Validation loss: 1.6956571917380057

Epoch: 777| Step: 0
Training loss: 0.42302340269088745
Validation loss: 1.6864407024075907

Epoch: 6| Step: 1
Training loss: 0.588662326335907
Validation loss: 1.6951877083829654

Epoch: 6| Step: 2
Training loss: 0.5544306635856628
Validation loss: 1.697442986631906

Epoch: 6| Step: 3
Training loss: 0.7435521483421326
Validation loss: 1.7646767798290457

Epoch: 6| Step: 4
Training loss: 0.8209416270256042
Validation loss: 1.7227406578679239

Epoch: 6| Step: 5
Training loss: 0.6619990468025208
Validation loss: 1.7220283016081779

Epoch: 6| Step: 6
Training loss: 0.784388542175293
Validation loss: 1.657779433393991

Epoch: 6| Step: 7
Training loss: 0.6279020309448242
Validation loss: 1.6967409221074914

Epoch: 6| Step: 8
Training loss: 0.9951275587081909
Validation loss: 1.7053741255114157

Epoch: 6| Step: 9
Training loss: 0.5652458071708679
Validation loss: 1.6782753070195515

Epoch: 6| Step: 10
Training loss: 1.178954839706421
Validation loss: 1.6755408804903749

Epoch: 6| Step: 11
Training loss: 0.9294800758361816
Validation loss: 1.6950721971450313

Epoch: 6| Step: 12
Training loss: 0.5471082329750061
Validation loss: 1.6231452559912076

Epoch: 6| Step: 13
Training loss: 0.5021994113922119
Validation loss: 1.6694421076005506

Epoch: 778| Step: 0
Training loss: 0.3893001079559326
Validation loss: 1.6767872584763395

Epoch: 6| Step: 1
Training loss: 0.898484468460083
Validation loss: 1.7159353853553854

Epoch: 6| Step: 2
Training loss: 0.9617922306060791
Validation loss: 1.7502585329035276

Epoch: 6| Step: 3
Training loss: 0.5226833820343018
Validation loss: 1.6561293717353576

Epoch: 6| Step: 4
Training loss: 0.7177802920341492
Validation loss: 1.8043713505550096

Epoch: 6| Step: 5
Training loss: 1.3719251155853271
Validation loss: 1.7376261462447464

Epoch: 6| Step: 6
Training loss: 1.0373563766479492
Validation loss: 1.7145518449044996

Epoch: 6| Step: 7
Training loss: 0.7328709959983826
Validation loss: 1.7495353170620498

Epoch: 6| Step: 8
Training loss: 0.5944207906723022
Validation loss: 1.7304415138818885

Epoch: 6| Step: 9
Training loss: 0.7024944424629211
Validation loss: 1.7162146517025527

Epoch: 6| Step: 10
Training loss: 0.6512723565101624
Validation loss: 1.6978301348224762

Epoch: 6| Step: 11
Training loss: 0.5814402103424072
Validation loss: 1.6981282106009863

Epoch: 6| Step: 12
Training loss: 0.35928648710250854
Validation loss: 1.6692301983474402

Epoch: 6| Step: 13
Training loss: 0.6225354671478271
Validation loss: 1.685046793312155

Epoch: 779| Step: 0
Training loss: 0.8798317313194275
Validation loss: 1.6695418255303496

Epoch: 6| Step: 1
Training loss: 1.0595862865447998
Validation loss: 1.734570740371622

Epoch: 6| Step: 2
Training loss: 0.5614778995513916
Validation loss: 1.6773378861847745

Epoch: 6| Step: 3
Training loss: 0.7257083654403687
Validation loss: 1.637502739506383

Epoch: 6| Step: 4
Training loss: 0.8397656679153442
Validation loss: 1.6650069900738296

Epoch: 6| Step: 5
Training loss: 1.0303740501403809
Validation loss: 1.6822801482292913

Epoch: 6| Step: 6
Training loss: 0.7785691618919373
Validation loss: 1.654273006223863

Epoch: 6| Step: 7
Training loss: 1.097501516342163
Validation loss: 1.7026760360246063

Epoch: 6| Step: 8
Training loss: 0.46295931935310364
Validation loss: 1.631544433614259

Epoch: 6| Step: 9
Training loss: 0.4075677990913391
Validation loss: 1.6790951785220896

Epoch: 6| Step: 10
Training loss: 0.853996753692627
Validation loss: 1.6952540977026826

Epoch: 6| Step: 11
Training loss: 0.7956129312515259
Validation loss: 1.686956021093553

Epoch: 6| Step: 12
Training loss: 1.005253791809082
Validation loss: 1.7340064843495686

Epoch: 6| Step: 13
Training loss: 0.26177242398262024
Validation loss: 1.6359660804912608

Epoch: 780| Step: 0
Training loss: 0.34406572580337524
Validation loss: 1.6962138106746059

Epoch: 6| Step: 1
Training loss: 0.5230332612991333
Validation loss: 1.7564471921613138

Epoch: 6| Step: 2
Training loss: 0.8282681703567505
Validation loss: 1.6884814616172545

Epoch: 6| Step: 3
Training loss: 1.270033836364746
Validation loss: 1.7202414902307654

Epoch: 6| Step: 4
Training loss: 0.5784714818000793
Validation loss: 1.7223664137624926

Epoch: 6| Step: 5
Training loss: 0.7979468107223511
Validation loss: 1.6607402934822986

Epoch: 6| Step: 6
Training loss: 0.22798827290534973
Validation loss: 1.6887566370348777

Epoch: 6| Step: 7
Training loss: 0.6617032885551453
Validation loss: 1.6924671716587518

Epoch: 6| Step: 8
Training loss: 0.8006879091262817
Validation loss: 1.6790913984339724

Epoch: 6| Step: 9
Training loss: 0.6179167628288269
Validation loss: 1.704127311706543

Epoch: 6| Step: 10
Training loss: 0.8670746684074402
Validation loss: 1.6935929354800974

Epoch: 6| Step: 11
Training loss: 0.6909387111663818
Validation loss: 1.6383069567782904

Epoch: 6| Step: 12
Training loss: 1.137131690979004
Validation loss: 1.6836100534726215

Epoch: 6| Step: 13
Training loss: 0.5440488457679749
Validation loss: 1.6999452447378507

Epoch: 781| Step: 0
Training loss: 0.7199141979217529
Validation loss: 1.687643269056915

Epoch: 6| Step: 1
Training loss: 0.5841662883758545
Validation loss: 1.6691387596950735

Epoch: 6| Step: 2
Training loss: 0.733295738697052
Validation loss: 1.6594324663121214

Epoch: 6| Step: 3
Training loss: 0.9752308130264282
Validation loss: 1.6890569925308228

Epoch: 6| Step: 4
Training loss: 1.2899901866912842
Validation loss: 1.6915482962003319

Epoch: 6| Step: 5
Training loss: 0.40561386942863464
Validation loss: 1.7238756482319166

Epoch: 6| Step: 6
Training loss: 0.7265993356704712
Validation loss: 1.713843636615302

Epoch: 6| Step: 7
Training loss: 0.6198288798332214
Validation loss: 1.7130176251934421

Epoch: 6| Step: 8
Training loss: 0.6140740513801575
Validation loss: 1.7462287679795296

Epoch: 6| Step: 9
Training loss: 0.7573715448379517
Validation loss: 1.7111205272777106

Epoch: 6| Step: 10
Training loss: 0.5993510484695435
Validation loss: 1.696253333040463

Epoch: 6| Step: 11
Training loss: 0.8155051469802856
Validation loss: 1.6346344358177596

Epoch: 6| Step: 12
Training loss: 0.6992219090461731
Validation loss: 1.667945315760951

Epoch: 6| Step: 13
Training loss: 0.6095969080924988
Validation loss: 1.6621346371148222

Epoch: 782| Step: 0
Training loss: 0.7676497101783752
Validation loss: 1.6418641818467008

Epoch: 6| Step: 1
Training loss: 0.7341616153717041
Validation loss: 1.6677663082717566

Epoch: 6| Step: 2
Training loss: 0.7234396934509277
Validation loss: 1.642670771127106

Epoch: 6| Step: 3
Training loss: 0.7580718398094177
Validation loss: 1.6749413680004817

Epoch: 6| Step: 4
Training loss: 0.5139302611351013
Validation loss: 1.7435661156972249

Epoch: 6| Step: 5
Training loss: 0.5817499160766602
Validation loss: 1.7401278121497041

Epoch: 6| Step: 6
Training loss: 0.6377339363098145
Validation loss: 1.6838619529560048

Epoch: 6| Step: 7
Training loss: 0.7288092970848083
Validation loss: 1.705233455986105

Epoch: 6| Step: 8
Training loss: 0.9919581413269043
Validation loss: 1.7006616143770115

Epoch: 6| Step: 9
Training loss: 0.9617102146148682
Validation loss: 1.7124348148222892

Epoch: 6| Step: 10
Training loss: 0.7847821116447449
Validation loss: 1.7209332091833955

Epoch: 6| Step: 11
Training loss: 0.8587659001350403
Validation loss: 1.7177486573496172

Epoch: 6| Step: 12
Training loss: 0.45221641659736633
Validation loss: 1.6583756426329255

Epoch: 6| Step: 13
Training loss: 0.6913478374481201
Validation loss: 1.710466407960461

Epoch: 783| Step: 0
Training loss: 1.1103434562683105
Validation loss: 1.7152587342005905

Epoch: 6| Step: 1
Training loss: 1.0952304601669312
Validation loss: 1.6769541489180697

Epoch: 6| Step: 2
Training loss: 0.5108405947685242
Validation loss: 1.7201830981880106

Epoch: 6| Step: 3
Training loss: 0.8331851959228516
Validation loss: 1.717814515995723

Epoch: 6| Step: 4
Training loss: 0.5676629543304443
Validation loss: 1.7248558152106501

Epoch: 6| Step: 5
Training loss: 0.7226889133453369
Validation loss: 1.6512173286048315

Epoch: 6| Step: 6
Training loss: 0.5350346565246582
Validation loss: 1.7114003960804274

Epoch: 6| Step: 7
Training loss: 0.6438421010971069
Validation loss: 1.6453814916713263

Epoch: 6| Step: 8
Training loss: 0.5698214769363403
Validation loss: 1.6822185221538748

Epoch: 6| Step: 9
Training loss: 0.5142151713371277
Validation loss: 1.7370436832468996

Epoch: 6| Step: 10
Training loss: 0.7449921369552612
Validation loss: 1.666523479646252

Epoch: 6| Step: 11
Training loss: 0.35738152265548706
Validation loss: 1.719026865497712

Epoch: 6| Step: 12
Training loss: 1.137117624282837
Validation loss: 1.6755908458463606

Epoch: 6| Step: 13
Training loss: 0.6273084282875061
Validation loss: 1.695651509428537

Epoch: 784| Step: 0
Training loss: 0.6565247178077698
Validation loss: 1.7025695731562953

Epoch: 6| Step: 1
Training loss: 0.7558890581130981
Validation loss: 1.6747795099853187

Epoch: 6| Step: 2
Training loss: 0.4563978612422943
Validation loss: 1.6889975955409389

Epoch: 6| Step: 3
Training loss: 0.8344869613647461
Validation loss: 1.7244667404441423

Epoch: 6| Step: 4
Training loss: 0.45230135321617126
Validation loss: 1.7012141494340793

Epoch: 6| Step: 5
Training loss: 0.7577698826789856
Validation loss: 1.7001778361617879

Epoch: 6| Step: 6
Training loss: 0.7515449523925781
Validation loss: 1.69404806757486

Epoch: 6| Step: 7
Training loss: 0.5762557983398438
Validation loss: 1.6836417439163371

Epoch: 6| Step: 8
Training loss: 1.3217414617538452
Validation loss: 1.693020429982934

Epoch: 6| Step: 9
Training loss: 0.9988235235214233
Validation loss: 1.6735430930250434

Epoch: 6| Step: 10
Training loss: 0.5951947569847107
Validation loss: 1.718099437734132

Epoch: 6| Step: 11
Training loss: 0.5079566240310669
Validation loss: 1.678329647228282

Epoch: 6| Step: 12
Training loss: 0.697939395904541
Validation loss: 1.728476232097995

Epoch: 6| Step: 13
Training loss: 0.6902183890342712
Validation loss: 1.6584907090792091

Epoch: 785| Step: 0
Training loss: 0.7466641664505005
Validation loss: 1.7156203023848995

Epoch: 6| Step: 1
Training loss: 0.5536746978759766
Validation loss: 1.7041305418937438

Epoch: 6| Step: 2
Training loss: 0.6042438745498657
Validation loss: 1.7021580665342269

Epoch: 6| Step: 3
Training loss: 0.6484830379486084
Validation loss: 1.6792078172006915

Epoch: 6| Step: 4
Training loss: 0.9873217344284058
Validation loss: 1.7214043050683954

Epoch: 6| Step: 5
Training loss: 0.5172514915466309
Validation loss: 1.7046823501586914

Epoch: 6| Step: 6
Training loss: 0.4726185202598572
Validation loss: 1.6668882036721835

Epoch: 6| Step: 7
Training loss: 0.5017518997192383
Validation loss: 1.6615322956474878

Epoch: 6| Step: 8
Training loss: 0.6225062608718872
Validation loss: 1.627676345968759

Epoch: 6| Step: 9
Training loss: 0.9536561965942383
Validation loss: 1.7008679246389737

Epoch: 6| Step: 10
Training loss: 0.8729169368743896
Validation loss: 1.6695574765564294

Epoch: 6| Step: 11
Training loss: 0.7108708024024963
Validation loss: 1.703070172699549

Epoch: 6| Step: 12
Training loss: 0.5017086267471313
Validation loss: 1.6859997587819253

Epoch: 6| Step: 13
Training loss: 0.844748854637146
Validation loss: 1.6565132192386094

Epoch: 786| Step: 0
Training loss: 0.5528233051300049
Validation loss: 1.6646054406319895

Epoch: 6| Step: 1
Training loss: 0.9251829981803894
Validation loss: 1.692991595114431

Epoch: 6| Step: 2
Training loss: 0.7015557885169983
Validation loss: 1.7034427953022782

Epoch: 6| Step: 3
Training loss: 0.5417758226394653
Validation loss: 1.6790080749860374

Epoch: 6| Step: 4
Training loss: 0.44984543323516846
Validation loss: 1.6884554207965892

Epoch: 6| Step: 5
Training loss: 0.8258767127990723
Validation loss: 1.7196699509056665

Epoch: 6| Step: 6
Training loss: 0.8948066234588623
Validation loss: 1.715828368740697

Epoch: 6| Step: 7
Training loss: 0.7093907594680786
Validation loss: 1.6712055629299534

Epoch: 6| Step: 8
Training loss: 0.7772549390792847
Validation loss: 1.692352480785821

Epoch: 6| Step: 9
Training loss: 0.45887401700019836
Validation loss: 1.6789742605660551

Epoch: 6| Step: 10
Training loss: 0.8997490406036377
Validation loss: 1.6456759821984075

Epoch: 6| Step: 11
Training loss: 0.8879218101501465
Validation loss: 1.6924840199050082

Epoch: 6| Step: 12
Training loss: 0.48517999053001404
Validation loss: 1.6930576652608893

Epoch: 6| Step: 13
Training loss: 0.901398241519928
Validation loss: 1.7029191088932816

Epoch: 787| Step: 0
Training loss: 0.5785374641418457
Validation loss: 1.7000451216133692

Epoch: 6| Step: 1
Training loss: 0.9817009568214417
Validation loss: 1.6632937641553982

Epoch: 6| Step: 2
Training loss: 0.6208850145339966
Validation loss: 1.7195389257964266

Epoch: 6| Step: 3
Training loss: 0.9112472534179688
Validation loss: 1.6936239234862789

Epoch: 6| Step: 4
Training loss: 0.6071297526359558
Validation loss: 1.6892492091783913

Epoch: 6| Step: 5
Training loss: 0.9477933645248413
Validation loss: 1.7196769111899919

Epoch: 6| Step: 6
Training loss: 0.596563458442688
Validation loss: 1.7051208852439799

Epoch: 6| Step: 7
Training loss: 0.4334949851036072
Validation loss: 1.6477429777063348

Epoch: 6| Step: 8
Training loss: 0.6062870621681213
Validation loss: 1.7032040960045272

Epoch: 6| Step: 9
Training loss: 0.8765274286270142
Validation loss: 1.7618039282419349

Epoch: 6| Step: 10
Training loss: 0.5753298997879028
Validation loss: 1.635465629639164

Epoch: 6| Step: 11
Training loss: 0.6399769186973572
Validation loss: 1.689248078612871

Epoch: 6| Step: 12
Training loss: 1.120790958404541
Validation loss: 1.687404308267819

Epoch: 6| Step: 13
Training loss: 0.8963737487792969
Validation loss: 1.66396160792279

Epoch: 788| Step: 0
Training loss: 0.669827401638031
Validation loss: 1.6382625410633702

Epoch: 6| Step: 1
Training loss: 0.3395416736602783
Validation loss: 1.6560342619496007

Epoch: 6| Step: 2
Training loss: 0.3810412585735321
Validation loss: 1.5776436751888645

Epoch: 6| Step: 3
Training loss: 0.8277115821838379
Validation loss: 1.7242002166727537

Epoch: 6| Step: 4
Training loss: 0.5256451368331909
Validation loss: 1.7116752747566468

Epoch: 6| Step: 5
Training loss: 0.797491192817688
Validation loss: 1.7407222229947326

Epoch: 6| Step: 6
Training loss: 0.6188826560974121
Validation loss: 1.659594835773591

Epoch: 6| Step: 7
Training loss: 1.0303566455841064
Validation loss: 1.7417744808299567

Epoch: 6| Step: 8
Training loss: 0.49950405955314636
Validation loss: 1.7534723512588009

Epoch: 6| Step: 9
Training loss: 0.7690713405609131
Validation loss: 1.6883486957960232

Epoch: 6| Step: 10
Training loss: 0.7967567443847656
Validation loss: 1.7197579286431754

Epoch: 6| Step: 11
Training loss: 0.7119382619857788
Validation loss: 1.7583121484325779

Epoch: 6| Step: 12
Training loss: 1.2211570739746094
Validation loss: 1.6782975427566036

Epoch: 6| Step: 13
Training loss: 0.6741392016410828
Validation loss: 1.6933372700086204

Epoch: 789| Step: 0
Training loss: 0.7598440647125244
Validation loss: 1.6586021761740408

Epoch: 6| Step: 1
Training loss: 0.6581217646598816
Validation loss: 1.6283685058675788

Epoch: 6| Step: 2
Training loss: 0.7316790223121643
Validation loss: 1.7010184821262155

Epoch: 6| Step: 3
Training loss: 0.6345454454421997
Validation loss: 1.667896043869757

Epoch: 6| Step: 4
Training loss: 0.9341590404510498
Validation loss: 1.716800074423513

Epoch: 6| Step: 5
Training loss: 1.2292695045471191
Validation loss: 1.7142427134257492

Epoch: 6| Step: 6
Training loss: 0.9947494864463806
Validation loss: 1.7356425382757699

Epoch: 6| Step: 7
Training loss: 0.4999507665634155
Validation loss: 1.7194227480119275

Epoch: 6| Step: 8
Training loss: 0.5947871208190918
Validation loss: 1.7217926671428065

Epoch: 6| Step: 9
Training loss: 0.4730372428894043
Validation loss: 1.688739594592843

Epoch: 6| Step: 10
Training loss: 0.7390750646591187
Validation loss: 1.7376297404689174

Epoch: 6| Step: 11
Training loss: 0.5962620973587036
Validation loss: 1.678867006814608

Epoch: 6| Step: 12
Training loss: 0.48461103439331055
Validation loss: 1.635924288021621

Epoch: 6| Step: 13
Training loss: 0.625863790512085
Validation loss: 1.7202794346758115

Epoch: 790| Step: 0
Training loss: 0.70427405834198
Validation loss: 1.6982720295588176

Epoch: 6| Step: 1
Training loss: 0.9343898296356201
Validation loss: 1.669536227821022

Epoch: 6| Step: 2
Training loss: 1.0693961381912231
Validation loss: 1.6592161193970711

Epoch: 6| Step: 3
Training loss: 0.7622816562652588
Validation loss: 1.6730827157215407

Epoch: 6| Step: 4
Training loss: 0.7452142238616943
Validation loss: 1.6327074381612963

Epoch: 6| Step: 5
Training loss: 0.5023428201675415
Validation loss: 1.699167804051471

Epoch: 6| Step: 6
Training loss: 1.1502101421356201
Validation loss: 1.6630191264613983

Epoch: 6| Step: 7
Training loss: 0.4630824327468872
Validation loss: 1.6446989505521712

Epoch: 6| Step: 8
Training loss: 0.5939008593559265
Validation loss: 1.7087062084546654

Epoch: 6| Step: 9
Training loss: 0.5567591786384583
Validation loss: 1.63250022421601

Epoch: 6| Step: 10
Training loss: 0.7450168132781982
Validation loss: 1.7179786107873405

Epoch: 6| Step: 11
Training loss: 0.5513161420822144
Validation loss: 1.7250324449231547

Epoch: 6| Step: 12
Training loss: 0.5200735330581665
Validation loss: 1.6878085008231543

Epoch: 6| Step: 13
Training loss: 0.42944204807281494
Validation loss: 1.7744982216947822

Epoch: 791| Step: 0
Training loss: 0.5512593984603882
Validation loss: 1.699582920279554

Epoch: 6| Step: 1
Training loss: 0.5602560043334961
Validation loss: 1.6592114202437862

Epoch: 6| Step: 2
Training loss: 1.6492894887924194
Validation loss: 1.7050250217478762

Epoch: 6| Step: 3
Training loss: 0.6334345936775208
Validation loss: 1.7372503075548398

Epoch: 6| Step: 4
Training loss: 0.7452360391616821
Validation loss: 1.6884870259992537

Epoch: 6| Step: 5
Training loss: 0.41169843077659607
Validation loss: 1.6966525495693248

Epoch: 6| Step: 6
Training loss: 0.40317535400390625
Validation loss: 1.7445693323689122

Epoch: 6| Step: 7
Training loss: 0.5586113333702087
Validation loss: 1.6944896739016297

Epoch: 6| Step: 8
Training loss: 0.5672984719276428
Validation loss: 1.6949930549949728

Epoch: 6| Step: 9
Training loss: 0.719717800617218
Validation loss: 1.6660766242652811

Epoch: 6| Step: 10
Training loss: 0.46831589937210083
Validation loss: 1.6482215632674515

Epoch: 6| Step: 11
Training loss: 0.7357567548751831
Validation loss: 1.6625999955720798

Epoch: 6| Step: 12
Training loss: 0.735264003276825
Validation loss: 1.6700396717235606

Epoch: 6| Step: 13
Training loss: 0.7467483878135681
Validation loss: 1.6376355719822708

Epoch: 792| Step: 0
Training loss: 0.6096363067626953
Validation loss: 1.6681972293443577

Epoch: 6| Step: 1
Training loss: 0.5826182961463928
Validation loss: 1.6814452127743793

Epoch: 6| Step: 2
Training loss: 0.9122023582458496
Validation loss: 1.7139552357376262

Epoch: 6| Step: 3
Training loss: 0.5783476829528809
Validation loss: 1.7171125488896524

Epoch: 6| Step: 4
Training loss: 0.502336323261261
Validation loss: 1.6605946325486707

Epoch: 6| Step: 5
Training loss: 0.374483585357666
Validation loss: 1.6490134423778904

Epoch: 6| Step: 6
Training loss: 1.0328505039215088
Validation loss: 1.6781573064865605

Epoch: 6| Step: 7
Training loss: 0.8599284887313843
Validation loss: 1.7054170190647084

Epoch: 6| Step: 8
Training loss: 0.5982913970947266
Validation loss: 1.6859704448330788

Epoch: 6| Step: 9
Training loss: 0.8081531524658203
Validation loss: 1.6530529068362327

Epoch: 6| Step: 10
Training loss: 0.7275727391242981
Validation loss: 1.7280308444012877

Epoch: 6| Step: 11
Training loss: 0.6450604796409607
Validation loss: 1.6821874444202711

Epoch: 6| Step: 12
Training loss: 0.6587673425674438
Validation loss: 1.6322750429953299

Epoch: 6| Step: 13
Training loss: 0.6765171885490417
Validation loss: 1.7133971529622232

Epoch: 793| Step: 0
Training loss: 0.9885056018829346
Validation loss: 1.6617651472809494

Epoch: 6| Step: 1
Training loss: 0.5512227416038513
Validation loss: 1.6586080289656115

Epoch: 6| Step: 2
Training loss: 1.1715879440307617
Validation loss: 1.6603759578479234

Epoch: 6| Step: 3
Training loss: 0.6858810186386108
Validation loss: 1.6716557587346723

Epoch: 6| Step: 4
Training loss: 0.8069849014282227
Validation loss: 1.6326113631648402

Epoch: 6| Step: 5
Training loss: 1.017928957939148
Validation loss: 1.6681272381095475

Epoch: 6| Step: 6
Training loss: 0.4858531951904297
Validation loss: 1.6357702491103963

Epoch: 6| Step: 7
Training loss: 0.5746523141860962
Validation loss: 1.722623404636178

Epoch: 6| Step: 8
Training loss: 0.710692286491394
Validation loss: 1.6844505930459628

Epoch: 6| Step: 9
Training loss: 0.5413469076156616
Validation loss: 1.670622319303533

Epoch: 6| Step: 10
Training loss: 0.4542032480239868
Validation loss: 1.6789923560234807

Epoch: 6| Step: 11
Training loss: 0.6923294067382812
Validation loss: 1.6570691139467302

Epoch: 6| Step: 12
Training loss: 0.6733104586601257
Validation loss: 1.6595956933113836

Epoch: 6| Step: 13
Training loss: 0.31517934799194336
Validation loss: 1.6394729345075545

Epoch: 794| Step: 0
Training loss: 0.8119051456451416
Validation loss: 1.7169581869597077

Epoch: 6| Step: 1
Training loss: 0.6316753029823303
Validation loss: 1.7192602439593243

Epoch: 6| Step: 2
Training loss: 0.45705926418304443
Validation loss: 1.7421390189919421

Epoch: 6| Step: 3
Training loss: 0.7201760411262512
Validation loss: 1.7046349625433646

Epoch: 6| Step: 4
Training loss: 0.6650883555412292
Validation loss: 1.671182741401016

Epoch: 6| Step: 5
Training loss: 0.41598862409591675
Validation loss: 1.7160089695325462

Epoch: 6| Step: 6
Training loss: 0.5838772058486938
Validation loss: 1.696047434242823

Epoch: 6| Step: 7
Training loss: 0.546688437461853
Validation loss: 1.7236346390939528

Epoch: 6| Step: 8
Training loss: 1.0074055194854736
Validation loss: 1.6890062362917009

Epoch: 6| Step: 9
Training loss: 0.5432721972465515
Validation loss: 1.727737606212657

Epoch: 6| Step: 10
Training loss: 1.4461601972579956
Validation loss: 1.6916227853426369

Epoch: 6| Step: 11
Training loss: 0.5135120749473572
Validation loss: 1.6824558178583782

Epoch: 6| Step: 12
Training loss: 1.0114799737930298
Validation loss: 1.709231424075301

Epoch: 6| Step: 13
Training loss: 0.4390820264816284
Validation loss: 1.6827675232323267

Epoch: 795| Step: 0
Training loss: 0.3284182548522949
Validation loss: 1.6886201366301505

Epoch: 6| Step: 1
Training loss: 0.6439656615257263
Validation loss: 1.6974425097947479

Epoch: 6| Step: 2
Training loss: 0.8033770322799683
Validation loss: 1.6655008331421883

Epoch: 6| Step: 3
Training loss: 0.5836482048034668
Validation loss: 1.6411885215390114

Epoch: 6| Step: 4
Training loss: 0.9669218063354492
Validation loss: 1.722064664286952

Epoch: 6| Step: 5
Training loss: 0.568884551525116
Validation loss: 1.664204183445182

Epoch: 6| Step: 6
Training loss: 0.6812905073165894
Validation loss: 1.70340903728239

Epoch: 6| Step: 7
Training loss: 0.5840504765510559
Validation loss: 1.670698445330384

Epoch: 6| Step: 8
Training loss: 1.3918185234069824
Validation loss: 1.7129444140259937

Epoch: 6| Step: 9
Training loss: 0.6534819006919861
Validation loss: 1.7096688106495848

Epoch: 6| Step: 10
Training loss: 0.5823514461517334
Validation loss: 1.6960016745392994

Epoch: 6| Step: 11
Training loss: 0.6914201378822327
Validation loss: 1.7338044105037567

Epoch: 6| Step: 12
Training loss: 0.7037791609764099
Validation loss: 1.689272875426918

Epoch: 6| Step: 13
Training loss: 1.0956670045852661
Validation loss: 1.7103751038992276

Epoch: 796| Step: 0
Training loss: 1.1507220268249512
Validation loss: 1.6923826407360774

Epoch: 6| Step: 1
Training loss: 0.35027098655700684
Validation loss: 1.6798600221192965

Epoch: 6| Step: 2
Training loss: 0.6001932621002197
Validation loss: 1.677404090922366

Epoch: 6| Step: 3
Training loss: 0.5080752968788147
Validation loss: 1.7146158551657071

Epoch: 6| Step: 4
Training loss: 0.2363014966249466
Validation loss: 1.656490320800453

Epoch: 6| Step: 5
Training loss: 0.6318570375442505
Validation loss: 1.7002110763262677

Epoch: 6| Step: 6
Training loss: 0.9190127849578857
Validation loss: 1.6978108408630534

Epoch: 6| Step: 7
Training loss: 0.4569670855998993
Validation loss: 1.6540160063774354

Epoch: 6| Step: 8
Training loss: 0.6452743411064148
Validation loss: 1.6633102304192

Epoch: 6| Step: 9
Training loss: 0.7695835828781128
Validation loss: 1.7139981946637552

Epoch: 6| Step: 10
Training loss: 0.8141136169433594
Validation loss: 1.6308587725444506

Epoch: 6| Step: 11
Training loss: 1.067376732826233
Validation loss: 1.670996609554496

Epoch: 6| Step: 12
Training loss: 0.8266907334327698
Validation loss: 1.6860922254541868

Epoch: 6| Step: 13
Training loss: 0.8813967108726501
Validation loss: 1.7475738179299138

Epoch: 797| Step: 0
Training loss: 1.455511450767517
Validation loss: 1.6983923296774588

Epoch: 6| Step: 1
Training loss: 0.7954534292221069
Validation loss: 1.6170749997579923

Epoch: 6| Step: 2
Training loss: 0.3749627470970154
Validation loss: 1.705557482216948

Epoch: 6| Step: 3
Training loss: 0.33849093317985535
Validation loss: 1.7009885567490772

Epoch: 6| Step: 4
Training loss: 0.6685280799865723
Validation loss: 1.7161215454019525

Epoch: 6| Step: 5
Training loss: 0.7176641225814819
Validation loss: 1.6696892258941487

Epoch: 6| Step: 6
Training loss: 0.6543514132499695
Validation loss: 1.6734810260034376

Epoch: 6| Step: 7
Training loss: 0.8802393078804016
Validation loss: 1.6873786987796906

Epoch: 6| Step: 8
Training loss: 0.5225627422332764
Validation loss: 1.6951953903321297

Epoch: 6| Step: 9
Training loss: 0.7350680232048035
Validation loss: 1.699821069676389

Epoch: 6| Step: 10
Training loss: 0.9681007862091064
Validation loss: 1.6780774849717335

Epoch: 6| Step: 11
Training loss: 0.7285934686660767
Validation loss: 1.7097362959256737

Epoch: 6| Step: 12
Training loss: 0.3939932584762573
Validation loss: 1.7470015800127419

Epoch: 6| Step: 13
Training loss: 0.29915162920951843
Validation loss: 1.685074229394236

Epoch: 798| Step: 0
Training loss: 0.44000864028930664
Validation loss: 1.6734580570651638

Epoch: 6| Step: 1
Training loss: 0.8796346187591553
Validation loss: 1.6982649346833587

Epoch: 6| Step: 2
Training loss: 1.2541661262512207
Validation loss: 1.6474514635660316

Epoch: 6| Step: 3
Training loss: 0.7921741008758545
Validation loss: 1.7003566052324028

Epoch: 6| Step: 4
Training loss: 0.803125262260437
Validation loss: 1.659847814549682

Epoch: 6| Step: 5
Training loss: 1.0595102310180664
Validation loss: 1.7336607851007932

Epoch: 6| Step: 6
Training loss: 0.6800611019134521
Validation loss: 1.7568582796281385

Epoch: 6| Step: 7
Training loss: 0.5870234966278076
Validation loss: 1.6665923544155654

Epoch: 6| Step: 8
Training loss: 0.4949599504470825
Validation loss: 1.6996070018378637

Epoch: 6| Step: 9
Training loss: 0.4009741544723511
Validation loss: 1.674773617457318

Epoch: 6| Step: 10
Training loss: 0.9937688112258911
Validation loss: 1.7117064486267746

Epoch: 6| Step: 11
Training loss: 0.49576660990715027
Validation loss: 1.69211797688597

Epoch: 6| Step: 12
Training loss: 0.635249137878418
Validation loss: 1.7217583566583612

Epoch: 6| Step: 13
Training loss: 0.5480628609657288
Validation loss: 1.7383463767267042

Epoch: 799| Step: 0
Training loss: 0.6540375351905823
Validation loss: 1.7419689214357765

Epoch: 6| Step: 1
Training loss: 0.3799798786640167
Validation loss: 1.7111870165794127

Epoch: 6| Step: 2
Training loss: 0.669876217842102
Validation loss: 1.6572008427753244

Epoch: 6| Step: 3
Training loss: 0.7414073348045349
Validation loss: 1.653265041689719

Epoch: 6| Step: 4
Training loss: 1.3203469514846802
Validation loss: 1.688174161859738

Epoch: 6| Step: 5
Training loss: 0.42227256298065186
Validation loss: 1.6958778340329406

Epoch: 6| Step: 6
Training loss: 0.586382269859314
Validation loss: 1.7204184250165058

Epoch: 6| Step: 7
Training loss: 1.1062090396881104
Validation loss: 1.6867545779033373

Epoch: 6| Step: 8
Training loss: 0.7856160402297974
Validation loss: 1.6696201114244358

Epoch: 6| Step: 9
Training loss: 0.48632386326789856
Validation loss: 1.6659972731785109

Epoch: 6| Step: 10
Training loss: 0.7464181184768677
Validation loss: 1.679047703742981

Epoch: 6| Step: 11
Training loss: 0.6724652647972107
Validation loss: 1.684304214292957

Epoch: 6| Step: 12
Training loss: 0.4455724358558655
Validation loss: 1.6612643272646013

Epoch: 6| Step: 13
Training loss: 0.6406269669532776
Validation loss: 1.6843169568687357

Epoch: 800| Step: 0
Training loss: 0.5818009376525879
Validation loss: 1.6772801414612801

Epoch: 6| Step: 1
Training loss: 0.6658473610877991
Validation loss: 1.7061504702414236

Epoch: 6| Step: 2
Training loss: 0.5833300352096558
Validation loss: 1.6951722957754647

Epoch: 6| Step: 3
Training loss: 0.7617716789245605
Validation loss: 1.6688133093618578

Epoch: 6| Step: 4
Training loss: 0.9883213043212891
Validation loss: 1.6973930020486154

Epoch: 6| Step: 5
Training loss: 0.671509861946106
Validation loss: 1.7063883684014762

Epoch: 6| Step: 6
Training loss: 0.6293174028396606
Validation loss: 1.6545468620074693

Epoch: 6| Step: 7
Training loss: 1.0937275886535645
Validation loss: 1.7079192258978402

Epoch: 6| Step: 8
Training loss: 0.6559938192367554
Validation loss: 1.6704315549583846

Epoch: 6| Step: 9
Training loss: 0.6400221586227417
Validation loss: 1.7401244435259091

Epoch: 6| Step: 10
Training loss: 0.9244787693023682
Validation loss: 1.658798502337548

Epoch: 6| Step: 11
Training loss: 0.3976384997367859
Validation loss: 1.6857253838610906

Epoch: 6| Step: 12
Training loss: 0.5252878069877625
Validation loss: 1.7302442173804007

Epoch: 6| Step: 13
Training loss: 0.4605478048324585
Validation loss: 1.7784863562994107

Testing loss: 2.5342361609141033
