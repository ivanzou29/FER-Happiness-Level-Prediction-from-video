Epoch: 1| Step: 0
Training loss: 4.13625431060791
Validation loss: 4.199742037762878

Epoch: 5| Step: 1
Training loss: 4.296856880187988
Validation loss: 4.194958327918925

Epoch: 5| Step: 2
Training loss: 3.5975964069366455
Validation loss: 4.188147360278714

Epoch: 5| Step: 3
Training loss: 4.59420108795166
Validation loss: 4.182418038768153

Epoch: 5| Step: 4
Training loss: 3.7678215503692627
Validation loss: 4.177237131262339

Epoch: 5| Step: 5
Training loss: 3.621863842010498
Validation loss: 4.1686716489894415

Epoch: 5| Step: 6
Training loss: 4.1349382400512695
Validation loss: 4.166037503109183

Epoch: 5| Step: 7
Training loss: 4.002148628234863
Validation loss: 4.160356572879258

Epoch: 5| Step: 8
Training loss: 3.3714003562927246
Validation loss: 4.155384422630392

Epoch: 5| Step: 9
Training loss: 4.93203067779541
Validation loss: 4.1506566078432146

Epoch: 5| Step: 10
Training loss: 3.4856324195861816
Validation loss: 4.142858238630398

Epoch: 2| Step: 0
Training loss: 3.4933929443359375
Validation loss: 4.136853238587738

Epoch: 5| Step: 1
Training loss: 4.525116920471191
Validation loss: 4.132855748617521

Epoch: 5| Step: 2
Training loss: 4.204016208648682
Validation loss: 4.126235879877562

Epoch: 5| Step: 3
Training loss: 4.879256248474121
Validation loss: 4.120254493528797

Epoch: 5| Step: 4
Training loss: 3.69377064704895
Validation loss: 4.11517810308805

Epoch: 5| Step: 5
Training loss: 3.608898162841797
Validation loss: 4.111752458797988

Epoch: 5| Step: 6
Training loss: 3.8930611610412598
Validation loss: 4.10576868057251

Epoch: 5| Step: 7
Training loss: 4.212141513824463
Validation loss: 4.103024149453768

Epoch: 5| Step: 8
Training loss: 3.147247552871704
Validation loss: 4.095885458812918

Epoch: 5| Step: 9
Training loss: 4.221439361572266
Validation loss: 4.089369358554963

Epoch: 5| Step: 10
Training loss: 3.468287229537964
Validation loss: 4.0836521271736395

Epoch: 3| Step: 0
Training loss: 4.475029945373535
Validation loss: 4.081166082812894

Epoch: 5| Step: 1
Training loss: 3.402592897415161
Validation loss: 4.073770087252381

Epoch: 5| Step: 2
Training loss: 3.7765698432922363
Validation loss: 4.069991983393187

Epoch: 5| Step: 3
Training loss: 4.166386604309082
Validation loss: 4.061003279942338

Epoch: 5| Step: 4
Training loss: 3.2680916786193848
Validation loss: 4.057341626895371

Epoch: 5| Step: 5
Training loss: 4.23427152633667
Validation loss: 4.054126213955623

Epoch: 5| Step: 6
Training loss: 3.623250961303711
Validation loss: 4.046481004325292

Epoch: 5| Step: 7
Training loss: 4.592848777770996
Validation loss: 4.04131785515816

Epoch: 5| Step: 8
Training loss: 3.6582131385803223
Validation loss: 4.035844913092992

Epoch: 5| Step: 9
Training loss: 3.4918437004089355
Validation loss: 4.029793149681502

Epoch: 5| Step: 10
Training loss: 4.209739685058594
Validation loss: 4.024805576570572

Epoch: 4| Step: 0
Training loss: 4.700122356414795
Validation loss: 4.0202808995400705

Epoch: 5| Step: 1
Training loss: 4.88766622543335
Validation loss: 4.014677660439604

Epoch: 5| Step: 2
Training loss: 4.760776996612549
Validation loss: 4.007653672208068

Epoch: 5| Step: 3
Training loss: 3.4800426959991455
Validation loss: 3.998741139647781

Epoch: 5| Step: 4
Training loss: 3.2759087085723877
Validation loss: 3.9948534145150134

Epoch: 5| Step: 5
Training loss: 3.023592710494995
Validation loss: 3.989166044419812

Epoch: 5| Step: 6
Training loss: 3.901535749435425
Validation loss: 3.9831402481243177

Epoch: 5| Step: 7
Training loss: 3.7094223499298096
Validation loss: 3.975780648569907

Epoch: 5| Step: 8
Training loss: 3.8810715675354004
Validation loss: 3.969891091828705

Epoch: 5| Step: 9
Training loss: 2.9070968627929688
Validation loss: 3.964390770081551

Epoch: 5| Step: 10
Training loss: 3.705810070037842
Validation loss: 3.9574314291759203

Epoch: 5| Step: 0
Training loss: 3.307089328765869
Validation loss: 3.9514658553625948

Epoch: 5| Step: 1
Training loss: 4.618475914001465
Validation loss: 3.945171840729252

Epoch: 5| Step: 2
Training loss: 3.5345358848571777
Validation loss: 3.9409723743315666

Epoch: 5| Step: 3
Training loss: 3.1437182426452637
Validation loss: 3.9346177706154446

Epoch: 5| Step: 4
Training loss: 3.1585142612457275
Validation loss: 3.9270463348716818

Epoch: 5| Step: 5
Training loss: 3.858574390411377
Validation loss: 3.9217706008624007

Epoch: 5| Step: 6
Training loss: 3.5861611366271973
Validation loss: 3.913201721765662

Epoch: 5| Step: 7
Training loss: 3.3935630321502686
Validation loss: 3.907812205694055

Epoch: 5| Step: 8
Training loss: 4.0433244705200195
Validation loss: 3.901256248515139

Epoch: 5| Step: 9
Training loss: 4.346797943115234
Validation loss: 3.89416641061024

Epoch: 5| Step: 10
Training loss: 4.751296043395996
Validation loss: 3.8892857387501705

Epoch: 6| Step: 0
Training loss: 3.268104076385498
Validation loss: 3.8814963730432654

Epoch: 5| Step: 1
Training loss: 4.005076885223389
Validation loss: 3.874044164534538

Epoch: 5| Step: 2
Training loss: 4.536752223968506
Validation loss: 3.8701177463736585

Epoch: 5| Step: 3
Training loss: 4.645953178405762
Validation loss: 3.862430485345984

Epoch: 5| Step: 4
Training loss: 3.8241353034973145
Validation loss: 3.856163199229907

Epoch: 5| Step: 5
Training loss: 3.3313324451446533
Validation loss: 3.8474814968724407

Epoch: 5| Step: 6
Training loss: 4.046882629394531
Validation loss: 3.8421892196901384

Epoch: 5| Step: 7
Training loss: 3.6194839477539062
Validation loss: 3.835028591976371

Epoch: 5| Step: 8
Training loss: 3.5987210273742676
Validation loss: 3.8277205241623746

Epoch: 5| Step: 9
Training loss: 3.503671169281006
Validation loss: 3.82074260968034

Epoch: 5| Step: 10
Training loss: 2.35664963722229
Validation loss: 3.8153179512229016

Epoch: 7| Step: 0
Training loss: 3.982140064239502
Validation loss: 3.8058695870061077

Epoch: 5| Step: 1
Training loss: 3.503314256668091
Validation loss: 3.8015493577526462

Epoch: 5| Step: 2
Training loss: 4.02475643157959
Validation loss: 3.794545717136834

Epoch: 5| Step: 3
Training loss: 4.8837103843688965
Validation loss: 3.7877409278705554

Epoch: 5| Step: 4
Training loss: 4.2462897300720215
Validation loss: 3.781035651442825

Epoch: 5| Step: 5
Training loss: 3.908161163330078
Validation loss: 3.7743860316532913

Epoch: 5| Step: 6
Training loss: 4.189260482788086
Validation loss: 3.765272973686136

Epoch: 5| Step: 7
Training loss: 2.6135551929473877
Validation loss: 3.7578161121696554

Epoch: 5| Step: 8
Training loss: 2.8131113052368164
Validation loss: 3.749068534502419

Epoch: 5| Step: 9
Training loss: 3.128972291946411
Validation loss: 3.743775498482489

Epoch: 5| Step: 10
Training loss: 2.8006622791290283
Validation loss: 3.739127092463996

Epoch: 8| Step: 0
Training loss: 3.147167682647705
Validation loss: 3.7315426282985236

Epoch: 5| Step: 1
Training loss: 3.4579689502716064
Validation loss: 3.724356766669981

Epoch: 5| Step: 2
Training loss: 3.799487352371216
Validation loss: 3.717343138110253

Epoch: 5| Step: 3
Training loss: 3.309476375579834
Validation loss: 3.7106324959826726

Epoch: 5| Step: 4
Training loss: 4.5363450050354
Validation loss: 3.703042768662976

Epoch: 5| Step: 5
Training loss: 3.1780829429626465
Validation loss: 3.6980414108563493

Epoch: 5| Step: 6
Training loss: 3.5202388763427734
Validation loss: 3.6882175937775643

Epoch: 5| Step: 7
Training loss: 3.2728965282440186
Validation loss: 3.6819407811728855

Epoch: 5| Step: 8
Training loss: 3.7029755115509033
Validation loss: 3.6741226770544566

Epoch: 5| Step: 9
Training loss: 3.2926013469696045
Validation loss: 3.6667968944836686

Epoch: 5| Step: 10
Training loss: 4.400078296661377
Validation loss: 3.6590873144006215

Epoch: 9| Step: 0
Training loss: 3.1605420112609863
Validation loss: 3.6526854884239937

Epoch: 5| Step: 1
Training loss: 3.7936980724334717
Validation loss: 3.645141391343968

Epoch: 5| Step: 2
Training loss: 2.6886305809020996
Validation loss: 3.638805620131954

Epoch: 5| Step: 3
Training loss: 4.188343048095703
Validation loss: 3.63132881861861

Epoch: 5| Step: 4
Training loss: 4.2480621337890625
Validation loss: 3.6269860806003695

Epoch: 5| Step: 5
Training loss: 3.7415618896484375
Validation loss: 3.6163724058417865

Epoch: 5| Step: 6
Training loss: 3.1314778327941895
Validation loss: 3.608831000584428

Epoch: 5| Step: 7
Training loss: 3.2543861865997314
Validation loss: 3.5964626137928297

Epoch: 5| Step: 8
Training loss: 4.239233016967773
Validation loss: 3.5945739284638436

Epoch: 5| Step: 9
Training loss: 2.9340434074401855
Validation loss: 3.5846653497347267

Epoch: 5| Step: 10
Training loss: 3.262157678604126
Validation loss: 3.5744176423677834

Epoch: 10| Step: 0
Training loss: 2.612715005874634
Validation loss: 3.5658607406000935

Epoch: 5| Step: 1
Training loss: 3.5679333209991455
Validation loss: 3.5611393528599895

Epoch: 5| Step: 2
Training loss: 3.938999891281128
Validation loss: 3.5531176777296167

Epoch: 5| Step: 3
Training loss: 3.5993666648864746
Validation loss: 3.546067991564351

Epoch: 5| Step: 4
Training loss: 3.8661880493164062
Validation loss: 3.533975101286365

Epoch: 5| Step: 5
Training loss: 3.405468702316284
Validation loss: 3.524285239558066

Epoch: 5| Step: 6
Training loss: 3.7950897216796875
Validation loss: 3.5141004695687243

Epoch: 5| Step: 7
Training loss: 3.825990676879883
Validation loss: 3.5088836505848873

Epoch: 5| Step: 8
Training loss: 3.695803165435791
Validation loss: 3.500427774203721

Epoch: 5| Step: 9
Training loss: 3.3031158447265625
Validation loss: 3.4888241957592707

Epoch: 5| Step: 10
Training loss: 2.020890712738037
Validation loss: 3.478609879811605

Epoch: 11| Step: 0
Training loss: 2.915097236633301
Validation loss: 3.4705063912176315

Epoch: 5| Step: 1
Training loss: 2.9101805686950684
Validation loss: 3.4607268200125745

Epoch: 5| Step: 2
Training loss: 3.029660701751709
Validation loss: 3.4530266587452223

Epoch: 5| Step: 3
Training loss: 3.2029242515563965
Validation loss: 3.4415110516291794

Epoch: 5| Step: 4
Training loss: 3.5173468589782715
Validation loss: 3.4371943422543105

Epoch: 5| Step: 5
Training loss: 3.7154552936553955
Validation loss: 3.4235659542904107

Epoch: 5| Step: 6
Training loss: 3.2279231548309326
Validation loss: 3.4130547610662316

Epoch: 5| Step: 7
Training loss: 3.4964828491210938
Validation loss: 3.402204167458319

Epoch: 5| Step: 8
Training loss: 3.8232452869415283
Validation loss: 3.39476445669769

Epoch: 5| Step: 9
Training loss: 3.6308655738830566
Validation loss: 3.380405205552296

Epoch: 5| Step: 10
Training loss: 3.362499475479126
Validation loss: 3.373102900802448

Epoch: 12| Step: 0
Training loss: 3.679701328277588
Validation loss: 3.359851780758109

Epoch: 5| Step: 1
Training loss: 3.6611411571502686
Validation loss: 3.349677008967246

Epoch: 5| Step: 2
Training loss: 3.5149803161621094
Validation loss: 3.334138672838929

Epoch: 5| Step: 3
Training loss: 3.3394951820373535
Validation loss: 3.325909906818021

Epoch: 5| Step: 4
Training loss: 3.4380722045898438
Validation loss: 3.3110190822232153

Epoch: 5| Step: 5
Training loss: 2.9683516025543213
Validation loss: 3.299879830370667

Epoch: 5| Step: 6
Training loss: 2.9169490337371826
Validation loss: 3.2850372868199504

Epoch: 5| Step: 7
Training loss: 3.20863676071167
Validation loss: 3.2769717811256327

Epoch: 5| Step: 8
Training loss: 3.2895431518554688
Validation loss: 3.26515688947452

Epoch: 5| Step: 9
Training loss: 2.6994130611419678
Validation loss: 3.2539332118085635

Epoch: 5| Step: 10
Training loss: 3.0517807006835938
Validation loss: 3.2435127099355063

Epoch: 13| Step: 0
Training loss: 2.673187255859375
Validation loss: 3.2338026313371557

Epoch: 5| Step: 1
Training loss: 2.828582763671875
Validation loss: 3.216273610309888

Epoch: 5| Step: 2
Training loss: 3.1892850399017334
Validation loss: 3.207033316294352

Epoch: 5| Step: 3
Training loss: 3.5646443367004395
Validation loss: 3.1980136568828295

Epoch: 5| Step: 4
Training loss: 3.4485573768615723
Validation loss: 3.1816408480367353

Epoch: 5| Step: 5
Training loss: 3.751020908355713
Validation loss: 3.168803486772763

Epoch: 5| Step: 6
Training loss: 2.786252498626709
Validation loss: 3.161817766004993

Epoch: 5| Step: 7
Training loss: 3.4024136066436768
Validation loss: 3.1485480339296403

Epoch: 5| Step: 8
Training loss: 3.0656352043151855
Validation loss: 3.135342969689318

Epoch: 5| Step: 9
Training loss: 2.8331093788146973
Validation loss: 3.1259786826308056

Epoch: 5| Step: 10
Training loss: 3.0358686447143555
Validation loss: 3.111136567208075

Epoch: 14| Step: 0
Training loss: 3.222904920578003
Validation loss: 3.10141077861991

Epoch: 5| Step: 1
Training loss: 2.6437175273895264
Validation loss: 3.087786243807885

Epoch: 5| Step: 2
Training loss: 2.429546356201172
Validation loss: 3.0735858127635014

Epoch: 5| Step: 3
Training loss: 3.4101319313049316
Validation loss: 3.0660656857234176

Epoch: 5| Step: 4
Training loss: 3.997281551361084
Validation loss: 3.051146609808809

Epoch: 5| Step: 5
Training loss: 3.211064100265503
Validation loss: 3.0450615062508533

Epoch: 5| Step: 6
Training loss: 3.0313591957092285
Validation loss: 3.0325339532667592

Epoch: 5| Step: 7
Training loss: 2.6745381355285645
Validation loss: 3.0186832668960735

Epoch: 5| Step: 8
Training loss: 3.0173404216766357
Validation loss: 3.0086227540046937

Epoch: 5| Step: 9
Training loss: 3.2799675464630127
Validation loss: 2.9957561569829143

Epoch: 5| Step: 10
Training loss: 2.442640542984009
Validation loss: 2.9827378180719193

Epoch: 15| Step: 0
Training loss: 2.965822696685791
Validation loss: 2.970783269533547

Epoch: 5| Step: 1
Training loss: 2.859213352203369
Validation loss: 2.9521934319567937

Epoch: 5| Step: 2
Training loss: 3.3688831329345703
Validation loss: 2.9445279516199583

Epoch: 5| Step: 3
Training loss: 2.9795093536376953
Validation loss: 2.93496209831648

Epoch: 5| Step: 4
Training loss: 2.847611665725708
Validation loss: 2.911016382196898

Epoch: 5| Step: 5
Training loss: 2.6665916442871094
Validation loss: 2.906801313482305

Epoch: 5| Step: 6
Training loss: 3.0473999977111816
Validation loss: 2.8872624648514615

Epoch: 5| Step: 7
Training loss: 3.6247870922088623
Validation loss: 2.8748553260680167

Epoch: 5| Step: 8
Training loss: 3.5511956214904785
Validation loss: 2.864498407610001

Epoch: 5| Step: 9
Training loss: 1.8411788940429688
Validation loss: 2.847984534437938

Epoch: 5| Step: 10
Training loss: 2.665879487991333
Validation loss: 2.836345995626142

Epoch: 16| Step: 0
Training loss: 3.200207233428955
Validation loss: 2.8309683363924742

Epoch: 5| Step: 1
Training loss: 3.709918975830078
Validation loss: 2.8172976201580417

Epoch: 5| Step: 2
Training loss: 2.361288547515869
Validation loss: 2.8023266997388614

Epoch: 5| Step: 3
Training loss: 2.333627223968506
Validation loss: 2.7795241827605874

Epoch: 5| Step: 4
Training loss: 3.346633195877075
Validation loss: 2.768799456216956

Epoch: 5| Step: 5
Training loss: 2.2124359607696533
Validation loss: 2.7612495883818595

Epoch: 5| Step: 6
Training loss: 2.8117918968200684
Validation loss: 2.747919190314508

Epoch: 5| Step: 7
Training loss: 3.116211414337158
Validation loss: 2.7354842411574496

Epoch: 5| Step: 8
Training loss: 2.8565592765808105
Validation loss: 2.7193934763631513

Epoch: 5| Step: 9
Training loss: 2.4967117309570312
Validation loss: 2.7058154947014263

Epoch: 5| Step: 10
Training loss: 3.129424571990967
Validation loss: 2.692055212554111

Epoch: 17| Step: 0
Training loss: 2.823714017868042
Validation loss: 2.6795510707363004

Epoch: 5| Step: 1
Training loss: 2.9676198959350586
Validation loss: 2.663925609280986

Epoch: 5| Step: 2
Training loss: 2.3096327781677246
Validation loss: 2.6682903587177234

Epoch: 5| Step: 3
Training loss: 2.8121402263641357
Validation loss: 2.6512643957650788

Epoch: 5| Step: 4
Training loss: 3.2659924030303955
Validation loss: 2.6388664630151566

Epoch: 5| Step: 5
Training loss: 2.5966734886169434
Validation loss: 2.6283537636521044

Epoch: 5| Step: 6
Training loss: 3.007678508758545
Validation loss: 2.6121274835319928

Epoch: 5| Step: 7
Training loss: 3.182706356048584
Validation loss: 2.594563502137379

Epoch: 5| Step: 8
Training loss: 2.1630425453186035
Validation loss: 2.585169494792979

Epoch: 5| Step: 9
Training loss: 2.835693120956421
Validation loss: 2.5642276681879514

Epoch: 5| Step: 10
Training loss: 2.5628297328948975
Validation loss: 2.558369513480894

Epoch: 18| Step: 0
Training loss: 2.8949661254882812
Validation loss: 2.5472866283949984

Epoch: 5| Step: 1
Training loss: 3.005650043487549
Validation loss: 2.5370712587910313

Epoch: 5| Step: 2
Training loss: 2.3579466342926025
Validation loss: 2.522271151183754

Epoch: 5| Step: 3
Training loss: 2.526695966720581
Validation loss: 2.518437408631848

Epoch: 5| Step: 4
Training loss: 3.5554041862487793
Validation loss: 2.505889518286592

Epoch: 5| Step: 5
Training loss: 2.9435155391693115
Validation loss: 2.491489630873485

Epoch: 5| Step: 6
Training loss: 2.7681360244750977
Validation loss: 2.480974092278429

Epoch: 5| Step: 7
Training loss: 2.640699863433838
Validation loss: 2.472537338092763

Epoch: 5| Step: 8
Training loss: 2.3056368827819824
Validation loss: 2.4537369743470223

Epoch: 5| Step: 9
Training loss: 2.486083984375
Validation loss: 2.4419919880487586

Epoch: 5| Step: 10
Training loss: 2.127504825592041
Validation loss: 2.434124336447767

Epoch: 19| Step: 0
Training loss: 2.3274502754211426
Validation loss: 2.4275111690644295

Epoch: 5| Step: 1
Training loss: 2.2548251152038574
Validation loss: 2.414120299841768

Epoch: 5| Step: 2
Training loss: 2.286963701248169
Validation loss: 2.4073809141753824

Epoch: 5| Step: 3
Training loss: 1.7484476566314697
Validation loss: 2.3943460167095227

Epoch: 5| Step: 4
Training loss: 2.716697931289673
Validation loss: 2.388360515717537

Epoch: 5| Step: 5
Training loss: 2.644227981567383
Validation loss: 2.3870611498432774

Epoch: 5| Step: 6
Training loss: 3.3497633934020996
Validation loss: 2.3799439950655867

Epoch: 5| Step: 7
Training loss: 2.803269624710083
Validation loss: 2.3669179562599427

Epoch: 5| Step: 8
Training loss: 2.3385071754455566
Validation loss: 2.3569830950870307

Epoch: 5| Step: 9
Training loss: 3.667504072189331
Validation loss: 2.346049826632264

Epoch: 5| Step: 10
Training loss: 2.8404593467712402
Validation loss: 2.3426833037407166

Epoch: 20| Step: 0
Training loss: 2.577984571456909
Validation loss: 2.331042943462249

Epoch: 5| Step: 1
Training loss: 2.743952989578247
Validation loss: 2.3276715740080802

Epoch: 5| Step: 2
Training loss: 2.2034759521484375
Validation loss: 2.312207924422397

Epoch: 5| Step: 3
Training loss: 2.1167194843292236
Validation loss: 2.3075739106824322

Epoch: 5| Step: 4
Training loss: 2.5796802043914795
Validation loss: 2.2970028769585396

Epoch: 5| Step: 5
Training loss: 2.740551710128784
Validation loss: 2.2863492529879332

Epoch: 5| Step: 6
Training loss: 2.8523426055908203
Validation loss: 2.273800657641503

Epoch: 5| Step: 7
Training loss: 2.571364641189575
Validation loss: 2.273859788012761

Epoch: 5| Step: 8
Training loss: 2.791837692260742
Validation loss: 2.2673864492806057

Epoch: 5| Step: 9
Training loss: 2.476250171661377
Validation loss: 2.242547212108489

Epoch: 5| Step: 10
Training loss: 2.7605130672454834
Validation loss: 2.242150859166217

Epoch: 21| Step: 0
Training loss: 2.60370135307312
Validation loss: 2.2480886931060464

Epoch: 5| Step: 1
Training loss: 2.5114526748657227
Validation loss: 2.226995145120928

Epoch: 5| Step: 2
Training loss: 2.331892490386963
Validation loss: 2.2223097508953464

Epoch: 5| Step: 3
Training loss: 2.539855480194092
Validation loss: 2.216265527150964

Epoch: 5| Step: 4
Training loss: 2.498844623565674
Validation loss: 2.2100376416278142

Epoch: 5| Step: 5
Training loss: 2.303309917449951
Validation loss: 2.216102853898079

Epoch: 5| Step: 6
Training loss: 2.289867401123047
Validation loss: 2.2064926137206373

Epoch: 5| Step: 7
Training loss: 2.890498638153076
Validation loss: 2.2089521500372116

Epoch: 5| Step: 8
Training loss: 2.7625739574432373
Validation loss: 2.2044123398360385

Epoch: 5| Step: 9
Training loss: 2.3040473461151123
Validation loss: 2.1994602141841764

Epoch: 5| Step: 10
Training loss: 2.809507131576538
Validation loss: 2.189159349728656

Epoch: 22| Step: 0
Training loss: 2.2030177116394043
Validation loss: 2.183877937255367

Epoch: 5| Step: 1
Training loss: 2.457704544067383
Validation loss: 2.171372321344191

Epoch: 5| Step: 2
Training loss: 2.4246785640716553
Validation loss: 2.166900803965907

Epoch: 5| Step: 3
Training loss: 2.241746187210083
Validation loss: 2.167029444889356

Epoch: 5| Step: 4
Training loss: 2.3719921112060547
Validation loss: 2.1635444369367374

Epoch: 5| Step: 5
Training loss: 2.4634346961975098
Validation loss: 2.1592275506706646

Epoch: 5| Step: 6
Training loss: 2.3957009315490723
Validation loss: 2.1609968216188493

Epoch: 5| Step: 7
Training loss: 2.492785692214966
Validation loss: 2.1601743531483475

Epoch: 5| Step: 8
Training loss: 3.034830093383789
Validation loss: 2.1534960654474076

Epoch: 5| Step: 9
Training loss: 3.340372085571289
Validation loss: 2.1608009748561408

Epoch: 5| Step: 10
Training loss: 1.9623171091079712
Validation loss: 2.1440819873604724

Epoch: 23| Step: 0
Training loss: 1.81037175655365
Validation loss: 2.138947973969162

Epoch: 5| Step: 1
Training loss: 2.928025484085083
Validation loss: 2.1448581769902217

Epoch: 5| Step: 2
Training loss: 2.3842129707336426
Validation loss: 2.1333346418155137

Epoch: 5| Step: 3
Training loss: 2.750216007232666
Validation loss: 2.137874713508032

Epoch: 5| Step: 4
Training loss: 2.587306261062622
Validation loss: 2.1410521922572965

Epoch: 5| Step: 5
Training loss: 2.575169563293457
Validation loss: 2.1286735560304377

Epoch: 5| Step: 6
Training loss: 2.344744920730591
Validation loss: 2.1223217338644047

Epoch: 5| Step: 7
Training loss: 2.7609047889709473
Validation loss: 2.1298224297902917

Epoch: 5| Step: 8
Training loss: 2.184019088745117
Validation loss: 2.127036674048311

Epoch: 5| Step: 9
Training loss: 2.5400550365448
Validation loss: 2.124619335256597

Epoch: 5| Step: 10
Training loss: 2.459352493286133
Validation loss: 2.1227127800705614

Epoch: 24| Step: 0
Training loss: 2.440896511077881
Validation loss: 2.1220067444668023

Epoch: 5| Step: 1
Training loss: 2.2128703594207764
Validation loss: 2.121773309605096

Epoch: 5| Step: 2
Training loss: 2.4099338054656982
Validation loss: 2.111601739801386

Epoch: 5| Step: 3
Training loss: 2.0945072174072266
Validation loss: 2.123514416397259

Epoch: 5| Step: 4
Training loss: 2.468688488006592
Validation loss: 2.113508742342713

Epoch: 5| Step: 5
Training loss: 2.2501235008239746
Validation loss: 2.1206330586505193

Epoch: 5| Step: 6
Training loss: 3.2425060272216797
Validation loss: 2.1175645397555445

Epoch: 5| Step: 7
Training loss: 2.584908962249756
Validation loss: 2.114590019308111

Epoch: 5| Step: 8
Training loss: 2.4827895164489746
Validation loss: 2.1057371119017243

Epoch: 5| Step: 9
Training loss: 2.782597064971924
Validation loss: 2.1012809661126908

Epoch: 5| Step: 10
Training loss: 2.2656667232513428
Validation loss: 2.099258645888298

Epoch: 25| Step: 0
Training loss: 2.960278034210205
Validation loss: 2.107770694199429

Epoch: 5| Step: 1
Training loss: 2.0611608028411865
Validation loss: 2.106535424468338

Epoch: 5| Step: 2
Training loss: 2.4203901290893555
Validation loss: 2.089263126414309

Epoch: 5| Step: 3
Training loss: 2.539501667022705
Validation loss: 2.0865902362331266

Epoch: 5| Step: 4
Training loss: 2.286713123321533
Validation loss: 2.0862899877691783

Epoch: 5| Step: 5
Training loss: 2.77445125579834
Validation loss: 2.089088609141688

Epoch: 5| Step: 6
Training loss: 2.0633718967437744
Validation loss: 2.0837775609826528

Epoch: 5| Step: 7
Training loss: 2.4339489936828613
Validation loss: 2.0889329602641444

Epoch: 5| Step: 8
Training loss: 2.254486560821533
Validation loss: 2.090270547456639

Epoch: 5| Step: 9
Training loss: 2.9743852615356445
Validation loss: 2.0864061206899662

Epoch: 5| Step: 10
Training loss: 2.4555325508117676
Validation loss: 2.0691040677409016

Epoch: 26| Step: 0
Training loss: 1.9804155826568604
Validation loss: 2.080081949951828

Epoch: 5| Step: 1
Training loss: 2.641939878463745
Validation loss: 2.0823467777621363

Epoch: 5| Step: 2
Training loss: 2.8538105487823486
Validation loss: 2.085238474671559

Epoch: 5| Step: 3
Training loss: 2.2186827659606934
Validation loss: 2.0838952256787207

Epoch: 5| Step: 4
Training loss: 2.5206425189971924
Validation loss: 2.075597437479163

Epoch: 5| Step: 5
Training loss: 2.2592520713806152
Validation loss: 2.08957592902645

Epoch: 5| Step: 6
Training loss: 2.7593672275543213
Validation loss: 2.082621861529607

Epoch: 5| Step: 7
Training loss: 2.2696900367736816
Validation loss: 2.082781050794868

Epoch: 5| Step: 8
Training loss: 2.554932117462158
Validation loss: 2.0889944107301774

Epoch: 5| Step: 9
Training loss: 2.71170973777771
Validation loss: 2.08779054046959

Epoch: 5| Step: 10
Training loss: 2.3099663257598877
Validation loss: 2.0962894398679017

Epoch: 27| Step: 0
Training loss: 2.012972354888916
Validation loss: 2.083564144308849

Epoch: 5| Step: 1
Training loss: 2.581556797027588
Validation loss: 2.0791103993692706

Epoch: 5| Step: 2
Training loss: 2.4916210174560547
Validation loss: 2.0739991511068037

Epoch: 5| Step: 3
Training loss: 2.757869243621826
Validation loss: 2.085300527593141

Epoch: 5| Step: 4
Training loss: 2.6086127758026123
Validation loss: 2.074560608915103

Epoch: 5| Step: 5
Training loss: 2.580204963684082
Validation loss: 2.0754995140978085

Epoch: 5| Step: 6
Training loss: 2.428372859954834
Validation loss: 2.072243618708785

Epoch: 5| Step: 7
Training loss: 2.730595827102661
Validation loss: 2.073625067228912

Epoch: 5| Step: 8
Training loss: 1.9705734252929688
Validation loss: 2.070077860227195

Epoch: 5| Step: 9
Training loss: 2.49839448928833
Validation loss: 2.0698715217651857

Epoch: 5| Step: 10
Training loss: 2.248039484024048
Validation loss: 2.0578500301607194

Epoch: 28| Step: 0
Training loss: 2.127518892288208
Validation loss: 2.0679488925523657

Epoch: 5| Step: 1
Training loss: 2.848045825958252
Validation loss: 2.0593836102434384

Epoch: 5| Step: 2
Training loss: 2.01070499420166
Validation loss: 2.059638418177123

Epoch: 5| Step: 3
Training loss: 2.7916133403778076
Validation loss: 2.0553206756550777

Epoch: 5| Step: 4
Training loss: 2.633635997772217
Validation loss: 2.041793502787108

Epoch: 5| Step: 5
Training loss: 2.344223737716675
Validation loss: 2.0549014435019544

Epoch: 5| Step: 6
Training loss: 2.793713331222534
Validation loss: 2.0513291153856503

Epoch: 5| Step: 7
Training loss: 2.6617443561553955
Validation loss: 2.0581110292865383

Epoch: 5| Step: 8
Training loss: 2.5549533367156982
Validation loss: 2.063269402391167

Epoch: 5| Step: 9
Training loss: 2.2519593238830566
Validation loss: 2.056071786470311

Epoch: 5| Step: 10
Training loss: 1.7753181457519531
Validation loss: 2.047170349346694

Epoch: 29| Step: 0
Training loss: 2.159848213195801
Validation loss: 2.0419852156792917

Epoch: 5| Step: 1
Training loss: 2.4898438453674316
Validation loss: 2.0445915088858655

Epoch: 5| Step: 2
Training loss: 2.929415702819824
Validation loss: 2.0574933162299534

Epoch: 5| Step: 3
Training loss: 2.44903564453125
Validation loss: 2.0442281743531585

Epoch: 5| Step: 4
Training loss: 2.4026095867156982
Validation loss: 2.0540948631942912

Epoch: 5| Step: 5
Training loss: 1.9290062189102173
Validation loss: 2.046111196599981

Epoch: 5| Step: 6
Training loss: 2.2849085330963135
Validation loss: 2.0416125507764917

Epoch: 5| Step: 7
Training loss: 1.9924991130828857
Validation loss: 2.0479351423119985

Epoch: 5| Step: 8
Training loss: 2.98683500289917
Validation loss: 2.0466806350215787

Epoch: 5| Step: 9
Training loss: 2.9921135902404785
Validation loss: 2.0445575432110856

Epoch: 5| Step: 10
Training loss: 2.2102413177490234
Validation loss: 2.0484315323573288

Epoch: 30| Step: 0
Training loss: 2.4848904609680176
Validation loss: 2.044712312759892

Epoch: 5| Step: 1
Training loss: 1.9865195751190186
Validation loss: 2.056556858042235

Epoch: 5| Step: 2
Training loss: 2.6128318309783936
Validation loss: 2.0476401159840245

Epoch: 5| Step: 3
Training loss: 2.0933837890625
Validation loss: 2.0494233433918287

Epoch: 5| Step: 4
Training loss: 2.2205350399017334
Validation loss: 2.0474596203014417

Epoch: 5| Step: 5
Training loss: 2.503262519836426
Validation loss: 2.0390312876752628

Epoch: 5| Step: 6
Training loss: 2.677794933319092
Validation loss: 2.049822158710931

Epoch: 5| Step: 7
Training loss: 2.5801339149475098
Validation loss: 2.0488422301507767

Epoch: 5| Step: 8
Training loss: 2.2068891525268555
Validation loss: 2.035827661073336

Epoch: 5| Step: 9
Training loss: 2.8829891681671143
Validation loss: 2.047873963591873

Epoch: 5| Step: 10
Training loss: 2.610811233520508
Validation loss: 2.042036461573775

Epoch: 31| Step: 0
Training loss: 2.252855062484741
Validation loss: 2.0333713587894233

Epoch: 5| Step: 1
Training loss: 2.1684045791625977
Validation loss: 2.053313757783623

Epoch: 5| Step: 2
Training loss: 2.699301242828369
Validation loss: 2.0404404132596907

Epoch: 5| Step: 3
Training loss: 2.1649329662323
Validation loss: 2.0331350603411273

Epoch: 5| Step: 4
Training loss: 2.1597704887390137
Validation loss: 2.0328826955569688

Epoch: 5| Step: 5
Training loss: 2.4607081413269043
Validation loss: 2.0321479638417563

Epoch: 5| Step: 6
Training loss: 2.387404441833496
Validation loss: 2.0252650822362592

Epoch: 5| Step: 7
Training loss: 2.966977596282959
Validation loss: 2.022892475128174

Epoch: 5| Step: 8
Training loss: 2.242567777633667
Validation loss: 2.019675003584995

Epoch: 5| Step: 9
Training loss: 2.5027925968170166
Validation loss: 2.0316414781796035

Epoch: 5| Step: 10
Training loss: 2.6737520694732666
Validation loss: 2.0269192405926284

Epoch: 32| Step: 0
Training loss: 2.3841800689697266
Validation loss: 2.0371278819217475

Epoch: 5| Step: 1
Training loss: 1.9882456064224243
Validation loss: 2.027979204731603

Epoch: 5| Step: 2
Training loss: 2.360328197479248
Validation loss: 2.027843454832672

Epoch: 5| Step: 3
Training loss: 2.564539670944214
Validation loss: 2.027021531135805

Epoch: 5| Step: 4
Training loss: 2.351356029510498
Validation loss: 2.0277843039522887

Epoch: 5| Step: 5
Training loss: 2.3669166564941406
Validation loss: 2.027429649906774

Epoch: 5| Step: 6
Training loss: 3.066795825958252
Validation loss: 2.023781088090712

Epoch: 5| Step: 7
Training loss: 2.179145097732544
Validation loss: 2.0336550692076325

Epoch: 5| Step: 8
Training loss: 2.2069201469421387
Validation loss: 2.0171579776271695

Epoch: 5| Step: 9
Training loss: 2.4522647857666016
Validation loss: 2.0388229585463002

Epoch: 5| Step: 10
Training loss: 2.780910015106201
Validation loss: 2.0276666533562446

Epoch: 33| Step: 0
Training loss: 2.9638895988464355
Validation loss: 2.033935146947061

Epoch: 5| Step: 1
Training loss: 1.8310697078704834
Validation loss: 2.039790790568116

Epoch: 5| Step: 2
Training loss: 2.0911316871643066
Validation loss: 2.034814111648067

Epoch: 5| Step: 3
Training loss: 2.7528834342956543
Validation loss: 2.0396991839972873

Epoch: 5| Step: 4
Training loss: 2.405137538909912
Validation loss: 2.0456564490513136

Epoch: 5| Step: 5
Training loss: 2.6078364849090576
Validation loss: 2.0400410262487267

Epoch: 5| Step: 6
Training loss: 2.338526964187622
Validation loss: 2.034858601067656

Epoch: 5| Step: 7
Training loss: 2.534653425216675
Validation loss: 2.0364401443030244

Epoch: 5| Step: 8
Training loss: 2.6460394859313965
Validation loss: 2.0471871604201612

Epoch: 5| Step: 9
Training loss: 2.5007545948028564
Validation loss: 2.0414280006962437

Epoch: 5| Step: 10
Training loss: 1.8623722791671753
Validation loss: 2.0315962247951056

Epoch: 34| Step: 0
Training loss: 2.4472694396972656
Validation loss: 2.038800311344926

Epoch: 5| Step: 1
Training loss: 2.2378931045532227
Validation loss: 2.040870511403648

Epoch: 5| Step: 2
Training loss: 2.8471336364746094
Validation loss: 2.0315420883958057

Epoch: 5| Step: 3
Training loss: 2.577213764190674
Validation loss: 2.022185266658824

Epoch: 5| Step: 4
Training loss: 2.702230930328369
Validation loss: 2.0289378499472015

Epoch: 5| Step: 5
Training loss: 2.3153164386749268
Validation loss: 2.033169174707064

Epoch: 5| Step: 6
Training loss: 2.2095794677734375
Validation loss: 2.0301133355786725

Epoch: 5| Step: 7
Training loss: 2.1363818645477295
Validation loss: 2.03403200129027

Epoch: 5| Step: 8
Training loss: 2.580655336380005
Validation loss: 2.0284548087786605

Epoch: 5| Step: 9
Training loss: 2.1088309288024902
Validation loss: 2.007596000548332

Epoch: 5| Step: 10
Training loss: 2.41186261177063
Validation loss: 2.025028354378157

Epoch: 35| Step: 0
Training loss: 2.667750835418701
Validation loss: 2.028250878857028

Epoch: 5| Step: 1
Training loss: 2.0970215797424316
Validation loss: 2.03103393636724

Epoch: 5| Step: 2
Training loss: 2.2977869510650635
Validation loss: 2.0331443099565405

Epoch: 5| Step: 3
Training loss: 1.9688745737075806
Validation loss: 2.0283071815326648

Epoch: 5| Step: 4
Training loss: 2.3457446098327637
Validation loss: 2.015989253597875

Epoch: 5| Step: 5
Training loss: 2.04498028755188
Validation loss: 2.0285341342290244

Epoch: 5| Step: 6
Training loss: 2.8572394847869873
Validation loss: 2.022031286711334

Epoch: 5| Step: 7
Training loss: 2.7692453861236572
Validation loss: 2.021510530543584

Epoch: 5| Step: 8
Training loss: 2.8147006034851074
Validation loss: 2.021070054782334

Epoch: 5| Step: 9
Training loss: 2.03132963180542
Validation loss: 2.025778152609384

Epoch: 5| Step: 10
Training loss: 2.5689220428466797
Validation loss: 2.0201922706378403

Epoch: 36| Step: 0
Training loss: 2.2428181171417236
Validation loss: 2.0206318324612034

Epoch: 5| Step: 1
Training loss: 2.6612749099731445
Validation loss: 2.010247486893849

Epoch: 5| Step: 2
Training loss: 2.3307390213012695
Validation loss: 2.008323061850763

Epoch: 5| Step: 3
Training loss: 2.1401591300964355
Validation loss: 2.025518818568158

Epoch: 5| Step: 4
Training loss: 2.6733250617980957
Validation loss: 2.024671972438853

Epoch: 5| Step: 5
Training loss: 2.055633783340454
Validation loss: 2.0146024457869993

Epoch: 5| Step: 6
Training loss: 2.448497772216797
Validation loss: 2.024761223023938

Epoch: 5| Step: 7
Training loss: 2.5927846431732178
Validation loss: 2.0105667114257812

Epoch: 5| Step: 8
Training loss: 2.113473653793335
Validation loss: 2.020285338483831

Epoch: 5| Step: 9
Training loss: 2.275583028793335
Validation loss: 2.0110497987398537

Epoch: 5| Step: 10
Training loss: 2.9214541912078857
Validation loss: 2.013051889275992

Epoch: 37| Step: 0
Training loss: 3.3698890209198
Validation loss: 2.0215076733660955

Epoch: 5| Step: 1
Training loss: 2.3499367237091064
Validation loss: 2.0114815568411224

Epoch: 5| Step: 2
Training loss: 2.316802501678467
Validation loss: 2.008915655074581

Epoch: 5| Step: 3
Training loss: 1.8002955913543701
Validation loss: 2.0128367767539075

Epoch: 5| Step: 4
Training loss: 2.6769495010375977
Validation loss: 2.012518290550478

Epoch: 5| Step: 5
Training loss: 3.1003201007843018
Validation loss: 2.0094229790472213

Epoch: 5| Step: 6
Training loss: 2.410457134246826
Validation loss: 2.013099431991577

Epoch: 5| Step: 7
Training loss: 1.926129937171936
Validation loss: 2.007806275480537

Epoch: 5| Step: 8
Training loss: 1.8812614679336548
Validation loss: 2.008431960177678

Epoch: 5| Step: 9
Training loss: 2.1414742469787598
Validation loss: 2.0176245704773934

Epoch: 5| Step: 10
Training loss: 2.3851687908172607
Validation loss: 2.018354321038851

Epoch: 38| Step: 0
Training loss: 2.8035850524902344
Validation loss: 2.012837779137396

Epoch: 5| Step: 1
Training loss: 2.1904537677764893
Validation loss: 2.0223713792780393

Epoch: 5| Step: 2
Training loss: 1.8373485803604126
Validation loss: 2.019835328543058

Epoch: 5| Step: 3
Training loss: 2.0188262462615967
Validation loss: 2.002867708923996

Epoch: 5| Step: 4
Training loss: 2.432325839996338
Validation loss: 2.00904724162112

Epoch: 5| Step: 5
Training loss: 1.9249684810638428
Validation loss: 2.0108634989748717

Epoch: 5| Step: 6
Training loss: 2.7827000617980957
Validation loss: 2.0132564985623924

Epoch: 5| Step: 7
Training loss: 2.832043170928955
Validation loss: 2.0086521076899704

Epoch: 5| Step: 8
Training loss: 2.651784896850586
Validation loss: 2.020349371817804

Epoch: 5| Step: 9
Training loss: 2.2778944969177246
Validation loss: 2.0167904823057112

Epoch: 5| Step: 10
Training loss: 2.5339863300323486
Validation loss: 2.0035155678308136

Epoch: 39| Step: 0
Training loss: 2.6976325511932373
Validation loss: 2.006822605286875

Epoch: 5| Step: 1
Training loss: 2.4571168422698975
Validation loss: 2.006760717720114

Epoch: 5| Step: 2
Training loss: 2.807361125946045
Validation loss: 2.01482641953294

Epoch: 5| Step: 3
Training loss: 2.2705211639404297
Validation loss: 2.01055807452048

Epoch: 5| Step: 4
Training loss: 1.945723533630371
Validation loss: 2.025700056424705

Epoch: 5| Step: 5
Training loss: 2.3857648372650146
Validation loss: 2.015236234152189

Epoch: 5| Step: 6
Training loss: 1.8218141794204712
Validation loss: 2.000292924142653

Epoch: 5| Step: 7
Training loss: 2.757593870162964
Validation loss: 2.005459891852512

Epoch: 5| Step: 8
Training loss: 2.3802285194396973
Validation loss: 2.003013182711858

Epoch: 5| Step: 9
Training loss: 2.5126614570617676
Validation loss: 2.0053848476820093

Epoch: 5| Step: 10
Training loss: 2.008802652359009
Validation loss: 2.0112719125645135

Epoch: 40| Step: 0
Training loss: 2.00498628616333
Validation loss: 2.011073035578574

Epoch: 5| Step: 1
Training loss: 2.562316656112671
Validation loss: 2.018653182573216

Epoch: 5| Step: 2
Training loss: 2.2800090312957764
Validation loss: 2.0043460643419655

Epoch: 5| Step: 3
Training loss: 2.7277774810791016
Validation loss: 2.005207323258923

Epoch: 5| Step: 4
Training loss: 2.3418967723846436
Validation loss: 2.0024599682900215

Epoch: 5| Step: 5
Training loss: 2.178870677947998
Validation loss: 2.014120868457261

Epoch: 5| Step: 6
Training loss: 2.345888137817383
Validation loss: 2.0155008890295543

Epoch: 5| Step: 7
Training loss: 2.152540683746338
Validation loss: 2.0277790177252983

Epoch: 5| Step: 8
Training loss: 2.8239173889160156
Validation loss: 2.0150619168435373

Epoch: 5| Step: 9
Training loss: 2.242966413497925
Validation loss: 2.010464004291001

Epoch: 5| Step: 10
Training loss: 2.5546391010284424
Validation loss: 2.0167217357184297

Epoch: 41| Step: 0
Training loss: 1.7736152410507202
Validation loss: 2.014839414627321

Epoch: 5| Step: 1
Training loss: 2.6259875297546387
Validation loss: 2.008001809479088

Epoch: 5| Step: 2
Training loss: 1.6210708618164062
Validation loss: 2.011755371606478

Epoch: 5| Step: 3
Training loss: 2.705970048904419
Validation loss: 1.9977200415826613

Epoch: 5| Step: 4
Training loss: 2.527148723602295
Validation loss: 2.018763542175293

Epoch: 5| Step: 5
Training loss: 2.736717700958252
Validation loss: 2.018858310996845

Epoch: 5| Step: 6
Training loss: 2.199528217315674
Validation loss: 2.015008267535958

Epoch: 5| Step: 7
Training loss: 2.595698833465576
Validation loss: 2.0038473503563994

Epoch: 5| Step: 8
Training loss: 2.1933705806732178
Validation loss: 2.0208661992062806

Epoch: 5| Step: 9
Training loss: 2.3625712394714355
Validation loss: 2.015301178860408

Epoch: 5| Step: 10
Training loss: 2.7820210456848145
Validation loss: 2.0045202137321554

Epoch: 42| Step: 0
Training loss: 2.3554537296295166
Validation loss: 2.0038781589077366

Epoch: 5| Step: 1
Training loss: 1.63511061668396
Validation loss: 2.0005099747770574

Epoch: 5| Step: 2
Training loss: 2.147319793701172
Validation loss: 2.0196526819659817

Epoch: 5| Step: 3
Training loss: 2.6515982151031494
Validation loss: 2.0076360728151057

Epoch: 5| Step: 4
Training loss: 1.9451833963394165
Validation loss: 2.004236936569214

Epoch: 5| Step: 5
Training loss: 1.9029918909072876
Validation loss: 2.0172583390307683

Epoch: 5| Step: 6
Training loss: 2.3946681022644043
Validation loss: 2.0137163810832526

Epoch: 5| Step: 7
Training loss: 3.3457329273223877
Validation loss: 2.0098241529157086

Epoch: 5| Step: 8
Training loss: 2.9168806076049805
Validation loss: 1.9985854779520342

Epoch: 5| Step: 9
Training loss: 2.670337200164795
Validation loss: 1.9994084924779914

Epoch: 5| Step: 10
Training loss: 2.090440511703491
Validation loss: 2.008881515072238

Epoch: 43| Step: 0
Training loss: 2.66211199760437
Validation loss: 2.004249352280812

Epoch: 5| Step: 1
Training loss: 2.205331563949585
Validation loss: 2.005872836676977

Epoch: 5| Step: 2
Training loss: 2.8142144680023193
Validation loss: 2.0210376785647486

Epoch: 5| Step: 3
Training loss: 2.3869054317474365
Validation loss: 2.0080930340674614

Epoch: 5| Step: 4
Training loss: 2.248837947845459
Validation loss: 2.015109823596093

Epoch: 5| Step: 5
Training loss: 2.4597671031951904
Validation loss: 2.0025877209119898

Epoch: 5| Step: 6
Training loss: 1.8533544540405273
Validation loss: 2.000303896524573

Epoch: 5| Step: 7
Training loss: 2.6760342121124268
Validation loss: 2.0102961550476732

Epoch: 5| Step: 8
Training loss: 2.266663074493408
Validation loss: 2.0035147718203965

Epoch: 5| Step: 9
Training loss: 2.3174965381622314
Validation loss: 2.0100008492828696

Epoch: 5| Step: 10
Training loss: 1.961187481880188
Validation loss: 2.013463959899

Epoch: 44| Step: 0
Training loss: 2.369816541671753
Validation loss: 2.002589709015303

Epoch: 5| Step: 1
Training loss: 2.741183042526245
Validation loss: 2.0069110983161518

Epoch: 5| Step: 2
Training loss: 2.9504361152648926
Validation loss: 2.008037615847844

Epoch: 5| Step: 3
Training loss: 2.212258815765381
Validation loss: 2.0044966308019494

Epoch: 5| Step: 4
Training loss: 2.4202442169189453
Validation loss: 1.9971622356804468

Epoch: 5| Step: 5
Training loss: 2.467127799987793
Validation loss: 2.002444585164388

Epoch: 5| Step: 6
Training loss: 1.9899619817733765
Validation loss: 2.0074480554108978

Epoch: 5| Step: 7
Training loss: 1.7524631023406982
Validation loss: 1.9946549643752396

Epoch: 5| Step: 8
Training loss: 2.546814441680908
Validation loss: 1.9962544556586974

Epoch: 5| Step: 9
Training loss: 2.313601016998291
Validation loss: 2.0042900680213847

Epoch: 5| Step: 10
Training loss: 2.10847806930542
Validation loss: 2.0031121520585913

Epoch: 45| Step: 0
Training loss: 2.4617209434509277
Validation loss: 2.0060021902925227

Epoch: 5| Step: 1
Training loss: 2.7310540676116943
Validation loss: 1.9937115407759143

Epoch: 5| Step: 2
Training loss: 2.6872620582580566
Validation loss: 2.002663102201236

Epoch: 5| Step: 3
Training loss: 2.18424391746521
Validation loss: 2.0076304866421606

Epoch: 5| Step: 4
Training loss: 2.39501690864563
Validation loss: 1.9965019866984377

Epoch: 5| Step: 5
Training loss: 2.3365767002105713
Validation loss: 2.006491043234384

Epoch: 5| Step: 6
Training loss: 2.0661697387695312
Validation loss: 2.0049831969763643

Epoch: 5| Step: 7
Training loss: 2.3377461433410645
Validation loss: 2.0026381900233607

Epoch: 5| Step: 8
Training loss: 2.2521536350250244
Validation loss: 2.0086476315734205

Epoch: 5| Step: 9
Training loss: 2.181349277496338
Validation loss: 1.9940278299393193

Epoch: 5| Step: 10
Training loss: 2.140434980392456
Validation loss: 1.9999343079905356

Epoch: 46| Step: 0
Training loss: 1.7669109106063843
Validation loss: 1.9964999921860234

Epoch: 5| Step: 1
Training loss: 2.4929230213165283
Validation loss: 1.9881640198410198

Epoch: 5| Step: 2
Training loss: 2.046865701675415
Validation loss: 1.994358742108909

Epoch: 5| Step: 3
Training loss: 2.122598886489868
Validation loss: 1.9906469263056272

Epoch: 5| Step: 4
Training loss: 2.782500743865967
Validation loss: 1.9972686498395857

Epoch: 5| Step: 5
Training loss: 2.804450511932373
Validation loss: 1.9907031853993733

Epoch: 5| Step: 6
Training loss: 2.174185276031494
Validation loss: 1.9841825410883913

Epoch: 5| Step: 7
Training loss: 2.3393054008483887
Validation loss: 1.98390579992725

Epoch: 5| Step: 8
Training loss: 2.3372085094451904
Validation loss: 1.9920564466907131

Epoch: 5| Step: 9
Training loss: 3.0370945930480957
Validation loss: 1.9882926928099764

Epoch: 5| Step: 10
Training loss: 1.7356910705566406
Validation loss: 1.9891726868126982

Epoch: 47| Step: 0
Training loss: 2.230807304382324
Validation loss: 1.974023868960719

Epoch: 5| Step: 1
Training loss: 1.9357173442840576
Validation loss: 1.989904680559712

Epoch: 5| Step: 2
Training loss: 2.6369032859802246
Validation loss: 1.9694536962816793

Epoch: 5| Step: 3
Training loss: 2.281454563140869
Validation loss: 1.9882365554891608

Epoch: 5| Step: 4
Training loss: 2.256373167037964
Validation loss: 1.9745213985443115

Epoch: 5| Step: 5
Training loss: 2.6278786659240723
Validation loss: 1.9908643102133146

Epoch: 5| Step: 6
Training loss: 2.3582026958465576
Validation loss: 1.9800793355511082

Epoch: 5| Step: 7
Training loss: 2.2342121601104736
Validation loss: 1.9744651484233078

Epoch: 5| Step: 8
Training loss: 2.1069908142089844
Validation loss: 1.976564262502937

Epoch: 5| Step: 9
Training loss: 2.736298084259033
Validation loss: 1.9821350677039034

Epoch: 5| Step: 10
Training loss: 2.3126471042633057
Validation loss: 1.9779350167961531

Epoch: 48| Step: 0
Training loss: 2.7161178588867188
Validation loss: 1.9980272477672947

Epoch: 5| Step: 1
Training loss: 2.2186431884765625
Validation loss: 1.988262878951206

Epoch: 5| Step: 2
Training loss: 2.620948314666748
Validation loss: 1.9901490596032911

Epoch: 5| Step: 3
Training loss: 2.2708983421325684
Validation loss: 1.9838426023401239

Epoch: 5| Step: 4
Training loss: 2.193134307861328
Validation loss: 1.9943804779360372

Epoch: 5| Step: 5
Training loss: 2.2006187438964844
Validation loss: 1.9872869355704195

Epoch: 5| Step: 6
Training loss: 2.251105785369873
Validation loss: 1.9892564768432288

Epoch: 5| Step: 7
Training loss: 1.9032478332519531
Validation loss: 1.986196369253179

Epoch: 5| Step: 8
Training loss: 2.5137195587158203
Validation loss: 1.9858097260998142

Epoch: 5| Step: 9
Training loss: 1.9420335292816162
Validation loss: 1.9728515250708467

Epoch: 5| Step: 10
Training loss: 2.860126256942749
Validation loss: 1.9955639646899315

Epoch: 49| Step: 0
Training loss: 2.265834331512451
Validation loss: 1.9859854034198228

Epoch: 5| Step: 1
Training loss: 2.6391215324401855
Validation loss: 1.9970719506663661

Epoch: 5| Step: 2
Training loss: 2.0065996646881104
Validation loss: 2.0081742117481847

Epoch: 5| Step: 3
Training loss: 2.6536078453063965
Validation loss: 1.984468722856173

Epoch: 5| Step: 4
Training loss: 2.183560848236084
Validation loss: 1.9792362208007483

Epoch: 5| Step: 5
Training loss: 2.420238971710205
Validation loss: 1.9870856641441264

Epoch: 5| Step: 6
Training loss: 2.410050868988037
Validation loss: 2.002305680705655

Epoch: 5| Step: 7
Training loss: 2.225362539291382
Validation loss: 1.9794402148133965

Epoch: 5| Step: 8
Training loss: 2.2523396015167236
Validation loss: 1.984073074915076

Epoch: 5| Step: 9
Training loss: 2.3146450519561768
Validation loss: 1.991136961085822

Epoch: 5| Step: 10
Training loss: 2.4288814067840576
Validation loss: 1.9908604378341346

Epoch: 50| Step: 0
Training loss: 2.355959892272949
Validation loss: 1.9862362851378739

Epoch: 5| Step: 1
Training loss: 2.350564479827881
Validation loss: 1.9966082611391622

Epoch: 5| Step: 2
Training loss: 2.2693846225738525
Validation loss: 1.9918882154649304

Epoch: 5| Step: 3
Training loss: 2.30243182182312
Validation loss: 1.9958798372617332

Epoch: 5| Step: 4
Training loss: 1.8219465017318726
Validation loss: 1.9937474240538895

Epoch: 5| Step: 5
Training loss: 2.6811134815216064
Validation loss: 1.9839437059176865

Epoch: 5| Step: 6
Training loss: 2.601378917694092
Validation loss: 1.994384677179398

Epoch: 5| Step: 7
Training loss: 2.5930607318878174
Validation loss: 1.9956818472954534

Epoch: 5| Step: 8
Training loss: 1.951205849647522
Validation loss: 1.99477933555521

Epoch: 5| Step: 9
Training loss: 2.0888161659240723
Validation loss: 1.9966214882430209

Epoch: 5| Step: 10
Training loss: 2.5054397583007812
Validation loss: 1.9916512786701162

Epoch: 51| Step: 0
Training loss: 2.797834873199463
Validation loss: 1.9900011811205136

Epoch: 5| Step: 1
Training loss: 1.8536598682403564
Validation loss: 1.9852934960396058

Epoch: 5| Step: 2
Training loss: 2.355438470840454
Validation loss: 1.9881172513449064

Epoch: 5| Step: 3
Training loss: 2.4153242111206055
Validation loss: 1.9948212767160067

Epoch: 5| Step: 4
Training loss: 2.119063377380371
Validation loss: 1.980495463135422

Epoch: 5| Step: 5
Training loss: 2.485508680343628
Validation loss: 1.9814918054047452

Epoch: 5| Step: 6
Training loss: 2.6543140411376953
Validation loss: 1.9936194881316154

Epoch: 5| Step: 7
Training loss: 2.503345012664795
Validation loss: 1.9886895507894538

Epoch: 5| Step: 8
Training loss: 2.098151922225952
Validation loss: 1.9840318772100634

Epoch: 5| Step: 9
Training loss: 2.250720262527466
Validation loss: 1.992134992794324

Epoch: 5| Step: 10
Training loss: 1.9321964979171753
Validation loss: 1.9830520614500968

Epoch: 52| Step: 0
Training loss: 2.3475863933563232
Validation loss: 1.9881901869209864

Epoch: 5| Step: 1
Training loss: 2.343432903289795
Validation loss: 1.9767084724159651

Epoch: 5| Step: 2
Training loss: 2.1947944164276123
Validation loss: 1.9784595581793016

Epoch: 5| Step: 3
Training loss: 2.8294196128845215
Validation loss: 1.9837436099206247

Epoch: 5| Step: 4
Training loss: 1.9557253122329712
Validation loss: 1.9686390058968657

Epoch: 5| Step: 5
Training loss: 2.2597055435180664
Validation loss: 1.9874297367629183

Epoch: 5| Step: 6
Training loss: 2.568614959716797
Validation loss: 1.9828042932735976

Epoch: 5| Step: 7
Training loss: 2.500002384185791
Validation loss: 1.9798573242720736

Epoch: 5| Step: 8
Training loss: 2.1301913261413574
Validation loss: 1.9670086573528986

Epoch: 5| Step: 9
Training loss: 2.2454516887664795
Validation loss: 1.969784967360958

Epoch: 5| Step: 10
Training loss: 2.023881435394287
Validation loss: 1.9669853423231392

Epoch: 53| Step: 0
Training loss: 2.136413097381592
Validation loss: 1.9830970789796563

Epoch: 5| Step: 1
Training loss: 2.2559924125671387
Validation loss: 1.9712040603801768

Epoch: 5| Step: 2
Training loss: 2.121605634689331
Validation loss: 1.9710284099783948

Epoch: 5| Step: 3
Training loss: 2.5110859870910645
Validation loss: 1.9698053944495417

Epoch: 5| Step: 4
Training loss: 2.642411470413208
Validation loss: 1.972195049767853

Epoch: 5| Step: 5
Training loss: 2.7246100902557373
Validation loss: 1.9792748317923596

Epoch: 5| Step: 6
Training loss: 1.9818195104599
Validation loss: 1.9768671258803336

Epoch: 5| Step: 7
Training loss: 1.9045369625091553
Validation loss: 1.962774880470768

Epoch: 5| Step: 8
Training loss: 2.984891414642334
Validation loss: 1.9697466627244027

Epoch: 5| Step: 9
Training loss: 2.195617198944092
Validation loss: 1.9731869466843144

Epoch: 5| Step: 10
Training loss: 1.927607536315918
Validation loss: 1.9692116347692346

Epoch: 54| Step: 0
Training loss: 2.424398899078369
Validation loss: 1.965547025844615

Epoch: 5| Step: 1
Training loss: 2.0874075889587402
Validation loss: 1.9796308086764427

Epoch: 5| Step: 2
Training loss: 1.6918790340423584
Validation loss: 1.9741827441800026

Epoch: 5| Step: 3
Training loss: 2.17276668548584
Validation loss: 1.9709678606320453

Epoch: 5| Step: 4
Training loss: 2.138138771057129
Validation loss: 1.9752556072768344

Epoch: 5| Step: 5
Training loss: 2.489489793777466
Validation loss: 1.9592500502063381

Epoch: 5| Step: 6
Training loss: 2.3593974113464355
Validation loss: 1.9599824272176272

Epoch: 5| Step: 7
Training loss: 2.762425661087036
Validation loss: 1.960827506998534

Epoch: 5| Step: 8
Training loss: 2.851916790008545
Validation loss: 1.9697399818769066

Epoch: 5| Step: 9
Training loss: 2.2695841789245605
Validation loss: 1.9722955008988738

Epoch: 5| Step: 10
Training loss: 1.9532511234283447
Validation loss: 1.9677547126687982

Epoch: 55| Step: 0
Training loss: 2.1039156913757324
Validation loss: 1.9634155586201658

Epoch: 5| Step: 1
Training loss: 2.3618130683898926
Validation loss: 1.9773445642122658

Epoch: 5| Step: 2
Training loss: 1.7536064386367798
Validation loss: 1.968280582017796

Epoch: 5| Step: 3
Training loss: 1.9146339893341064
Validation loss: 1.96969505663841

Epoch: 5| Step: 4
Training loss: 1.8060652017593384
Validation loss: 1.9708724688458186

Epoch: 5| Step: 5
Training loss: 2.9164791107177734
Validation loss: 1.973552442366077

Epoch: 5| Step: 6
Training loss: 2.857288360595703
Validation loss: 1.973714820800289

Epoch: 5| Step: 7
Training loss: 1.9544601440429688
Validation loss: 1.9741575282107118

Epoch: 5| Step: 8
Training loss: 3.1388609409332275
Validation loss: 1.9846432414106143

Epoch: 5| Step: 9
Training loss: 1.9671564102172852
Validation loss: 1.9587725657288746

Epoch: 5| Step: 10
Training loss: 2.599388599395752
Validation loss: 1.975964471858035

Epoch: 56| Step: 0
Training loss: 2.526125192642212
Validation loss: 1.9787887911642752

Epoch: 5| Step: 1
Training loss: 2.450009346008301
Validation loss: 1.975681645895845

Epoch: 5| Step: 2
Training loss: 2.263075351715088
Validation loss: 1.9807612639601513

Epoch: 5| Step: 3
Training loss: 2.4314517974853516
Validation loss: 1.9836351499762586

Epoch: 5| Step: 4
Training loss: 2.7794017791748047
Validation loss: 1.982132798881941

Epoch: 5| Step: 5
Training loss: 2.3915891647338867
Validation loss: 1.9818374738898328

Epoch: 5| Step: 6
Training loss: 1.6814334392547607
Validation loss: 1.981146263819869

Epoch: 5| Step: 7
Training loss: 2.4333972930908203
Validation loss: 1.9710634575095227

Epoch: 5| Step: 8
Training loss: 1.8352222442626953
Validation loss: 1.9796112493802143

Epoch: 5| Step: 9
Training loss: 1.9878032207489014
Validation loss: 1.9690160802615586

Epoch: 5| Step: 10
Training loss: 2.4737563133239746
Validation loss: 1.9828914365460795

Epoch: 57| Step: 0
Training loss: 2.694756269454956
Validation loss: 1.9670189349882063

Epoch: 5| Step: 1
Training loss: 2.2452921867370605
Validation loss: 1.9830832558293496

Epoch: 5| Step: 2
Training loss: 2.5427157878875732
Validation loss: 1.976430933962586

Epoch: 5| Step: 3
Training loss: 2.2628087997436523
Validation loss: 1.9827690355239376

Epoch: 5| Step: 4
Training loss: 1.723207712173462
Validation loss: 1.9813914247738418

Epoch: 5| Step: 5
Training loss: 2.1048641204833984
Validation loss: 1.9721756660810081

Epoch: 5| Step: 6
Training loss: 2.0455050468444824
Validation loss: 1.9749118269130748

Epoch: 5| Step: 7
Training loss: 2.3659353256225586
Validation loss: 1.9842290827023086

Epoch: 5| Step: 8
Training loss: 2.475276470184326
Validation loss: 1.9703647500725203

Epoch: 5| Step: 9
Training loss: 2.507035493850708
Validation loss: 1.9767829397673249

Epoch: 5| Step: 10
Training loss: 2.299956798553467
Validation loss: 1.9724855397337226

Epoch: 58| Step: 0
Training loss: 2.20369291305542
Validation loss: 1.9838892644451511

Epoch: 5| Step: 1
Training loss: 2.268442153930664
Validation loss: 1.9751188857581026

Epoch: 5| Step: 2
Training loss: 1.9632927179336548
Validation loss: 1.9718313409436135

Epoch: 5| Step: 3
Training loss: 2.1675796508789062
Validation loss: 1.9840974461647771

Epoch: 5| Step: 4
Training loss: 2.411404848098755
Validation loss: 1.9750121998530563

Epoch: 5| Step: 5
Training loss: 2.9922842979431152
Validation loss: 1.9824181423392346

Epoch: 5| Step: 6
Training loss: 2.3065273761749268
Validation loss: 1.9706590278174287

Epoch: 5| Step: 7
Training loss: 2.233621120452881
Validation loss: 1.9739007975465508

Epoch: 5| Step: 8
Training loss: 2.287121295928955
Validation loss: 1.9751782750570646

Epoch: 5| Step: 9
Training loss: 2.1142756938934326
Validation loss: 1.9737171883224158

Epoch: 5| Step: 10
Training loss: 2.2832164764404297
Validation loss: 1.977141623855919

Epoch: 59| Step: 0
Training loss: 1.745043158531189
Validation loss: 1.972219705581665

Epoch: 5| Step: 1
Training loss: 2.6509523391723633
Validation loss: 1.9910190105438232

Epoch: 5| Step: 2
Training loss: 2.236374616622925
Validation loss: 1.9712141765061246

Epoch: 5| Step: 3
Training loss: 2.681562662124634
Validation loss: 1.9713099695021106

Epoch: 5| Step: 4
Training loss: 2.2269530296325684
Validation loss: 1.9541793818114905

Epoch: 5| Step: 5
Training loss: 2.2642388343811035
Validation loss: 1.9679260997362034

Epoch: 5| Step: 6
Training loss: 2.052708864212036
Validation loss: 1.9645239973580966

Epoch: 5| Step: 7
Training loss: 2.5031371116638184
Validation loss: 1.945559911830451

Epoch: 5| Step: 8
Training loss: 2.917135715484619
Validation loss: 1.9691288317403486

Epoch: 5| Step: 9
Training loss: 2.101466178894043
Validation loss: 1.9683295924176452

Epoch: 5| Step: 10
Training loss: 1.7096452713012695
Validation loss: 1.9762458339814217

Epoch: 60| Step: 0
Training loss: 2.6607487201690674
Validation loss: 1.9794899032961937

Epoch: 5| Step: 1
Training loss: 1.7259315252304077
Validation loss: 1.9506930971658358

Epoch: 5| Step: 2
Training loss: 2.2126567363739014
Validation loss: 1.9656296237822501

Epoch: 5| Step: 3
Training loss: 1.8416674137115479
Validation loss: 1.9750539666862899

Epoch: 5| Step: 4
Training loss: 2.212834119796753
Validation loss: 1.9699581233404015

Epoch: 5| Step: 5
Training loss: 2.2410824298858643
Validation loss: 1.9703217155189925

Epoch: 5| Step: 6
Training loss: 2.252495527267456
Validation loss: 1.977735084872092

Epoch: 5| Step: 7
Training loss: 2.1108057498931885
Validation loss: 1.975760623972903

Epoch: 5| Step: 8
Training loss: 2.789853572845459
Validation loss: 1.9744108441055461

Epoch: 5| Step: 9
Training loss: 2.1424758434295654
Validation loss: 1.9787752346325946

Epoch: 5| Step: 10
Training loss: 2.9980108737945557
Validation loss: 1.973365492718194

Epoch: 61| Step: 0
Training loss: 1.5801994800567627
Validation loss: 1.980708674717975

Epoch: 5| Step: 1
Training loss: 2.590388059616089
Validation loss: 1.9707404580167545

Epoch: 5| Step: 2
Training loss: 2.616299629211426
Validation loss: 1.96898171594066

Epoch: 5| Step: 3
Training loss: 1.7612005472183228
Validation loss: 1.9687387174175632

Epoch: 5| Step: 4
Training loss: 2.1204066276550293
Validation loss: 1.9575684814042942

Epoch: 5| Step: 5
Training loss: 1.9053913354873657
Validation loss: 1.9644219747153662

Epoch: 5| Step: 6
Training loss: 2.6778626441955566
Validation loss: 1.9806258986073155

Epoch: 5| Step: 7
Training loss: 2.517277717590332
Validation loss: 1.9619805992290538

Epoch: 5| Step: 8
Training loss: 2.9798543453216553
Validation loss: 1.9585195023526427

Epoch: 5| Step: 9
Training loss: 2.3668372631073
Validation loss: 1.9496325049349057

Epoch: 5| Step: 10
Training loss: 1.9615278244018555
Validation loss: 1.9608882345179075

Epoch: 62| Step: 0
Training loss: 2.2415120601654053
Validation loss: 1.9700564376769527

Epoch: 5| Step: 1
Training loss: 2.334902763366699
Validation loss: 1.9596995294734996

Epoch: 5| Step: 2
Training loss: 2.933739185333252
Validation loss: 1.9619507943430254

Epoch: 5| Step: 3
Training loss: 2.3251302242279053
Validation loss: 1.939503659484207

Epoch: 5| Step: 4
Training loss: 1.9281179904937744
Validation loss: 1.946931141679005

Epoch: 5| Step: 5
Training loss: 2.6482207775115967
Validation loss: 1.9609525383159678

Epoch: 5| Step: 6
Training loss: 1.855180025100708
Validation loss: 1.9620474384677025

Epoch: 5| Step: 7
Training loss: 2.2069783210754395
Validation loss: 1.9572575707589426

Epoch: 5| Step: 8
Training loss: 2.4290084838867188
Validation loss: 1.9531631828636251

Epoch: 5| Step: 9
Training loss: 2.2437312602996826
Validation loss: 1.9560268796900266

Epoch: 5| Step: 10
Training loss: 1.8591734170913696
Validation loss: 1.9590786567298315

Epoch: 63| Step: 0
Training loss: 2.0608110427856445
Validation loss: 1.9602659979174215

Epoch: 5| Step: 1
Training loss: 2.508206605911255
Validation loss: 1.9586415726651427

Epoch: 5| Step: 2
Training loss: 2.376105785369873
Validation loss: 1.9538236433459866

Epoch: 5| Step: 3
Training loss: 1.8065248727798462
Validation loss: 1.950187034504388

Epoch: 5| Step: 4
Training loss: 2.4565486907958984
Validation loss: 1.955747749215813

Epoch: 5| Step: 5
Training loss: 1.9958479404449463
Validation loss: 1.9593340248189948

Epoch: 5| Step: 6
Training loss: 1.8629646301269531
Validation loss: 1.9509386144658571

Epoch: 5| Step: 7
Training loss: 1.7975772619247437
Validation loss: 1.9533560814396027

Epoch: 5| Step: 8
Training loss: 2.9758801460266113
Validation loss: 1.9546316541651243

Epoch: 5| Step: 9
Training loss: 2.777615785598755
Validation loss: 1.9399806786608953

Epoch: 5| Step: 10
Training loss: 2.395416736602783
Validation loss: 1.950581225015784

Epoch: 64| Step: 0
Training loss: 2.2884371280670166
Validation loss: 1.9471782548453218

Epoch: 5| Step: 1
Training loss: 2.143451452255249
Validation loss: 1.9554861578890073

Epoch: 5| Step: 2
Training loss: 2.5574538707733154
Validation loss: 1.9549226196863319

Epoch: 5| Step: 3
Training loss: 2.3921236991882324
Validation loss: 1.96646652683135

Epoch: 5| Step: 4
Training loss: 1.8734939098358154
Validation loss: 1.957106113433838

Epoch: 5| Step: 5
Training loss: 2.2459311485290527
Validation loss: 1.9380016480722735

Epoch: 5| Step: 6
Training loss: 1.7894623279571533
Validation loss: 1.9566924354081512

Epoch: 5| Step: 7
Training loss: 3.072875499725342
Validation loss: 1.9558511062334942

Epoch: 5| Step: 8
Training loss: 2.0134410858154297
Validation loss: 1.9484319917617305

Epoch: 5| Step: 9
Training loss: 2.421907901763916
Validation loss: 1.9647924643690868

Epoch: 5| Step: 10
Training loss: 2.1563897132873535
Validation loss: 1.9534350941258092

Epoch: 65| Step: 0
Training loss: 2.412475824356079
Validation loss: 1.9576904196893015

Epoch: 5| Step: 1
Training loss: 2.1883225440979004
Validation loss: 1.9547044974501415

Epoch: 5| Step: 2
Training loss: 2.2522778511047363
Validation loss: 1.959848601330993

Epoch: 5| Step: 3
Training loss: 2.111151695251465
Validation loss: 1.9617855933404738

Epoch: 5| Step: 4
Training loss: 2.617858409881592
Validation loss: 1.9482649244287962

Epoch: 5| Step: 5
Training loss: 2.6532232761383057
Validation loss: 1.9556435205603158

Epoch: 5| Step: 6
Training loss: 2.2445003986358643
Validation loss: 1.9514438042076685

Epoch: 5| Step: 7
Training loss: 2.0441336631774902
Validation loss: 1.954579286677863

Epoch: 5| Step: 8
Training loss: 1.8292341232299805
Validation loss: 1.9552059635039298

Epoch: 5| Step: 9
Training loss: 2.3452117443084717
Validation loss: 1.9614397659096667

Epoch: 5| Step: 10
Training loss: 2.2769858837127686
Validation loss: 1.9549053689484954

Epoch: 66| Step: 0
Training loss: 2.2157232761383057
Validation loss: 1.9463393816383936

Epoch: 5| Step: 1
Training loss: 2.5326437950134277
Validation loss: 1.9542968247526435

Epoch: 5| Step: 2
Training loss: 1.8257787227630615
Validation loss: 1.953479407936014

Epoch: 5| Step: 3
Training loss: 2.0174150466918945
Validation loss: 1.94189118313533

Epoch: 5| Step: 4
Training loss: 2.4490036964416504
Validation loss: 1.95188779728387

Epoch: 5| Step: 5
Training loss: 2.3556511402130127
Validation loss: 1.948274730354227

Epoch: 5| Step: 6
Training loss: 2.49409818649292
Validation loss: 1.9577804444938578

Epoch: 5| Step: 7
Training loss: 2.693390369415283
Validation loss: 1.9506690194529872

Epoch: 5| Step: 8
Training loss: 2.378864288330078
Validation loss: 1.9552803039550781

Epoch: 5| Step: 9
Training loss: 1.7518508434295654
Validation loss: 1.946641993779008

Epoch: 5| Step: 10
Training loss: 2.1001644134521484
Validation loss: 1.931294620677989

Epoch: 67| Step: 0
Training loss: 2.4675021171569824
Validation loss: 1.94776883176578

Epoch: 5| Step: 1
Training loss: 2.519775390625
Validation loss: 1.9406281440488753

Epoch: 5| Step: 2
Training loss: 2.156897783279419
Validation loss: 1.9532107947975077

Epoch: 5| Step: 3
Training loss: 2.1751515865325928
Validation loss: 1.942869451738173

Epoch: 5| Step: 4
Training loss: 1.8832015991210938
Validation loss: 1.9515846160150343

Epoch: 5| Step: 5
Training loss: 1.871914267539978
Validation loss: 1.9524036492070844

Epoch: 5| Step: 6
Training loss: 2.2231955528259277
Validation loss: 1.9587588041059432

Epoch: 5| Step: 7
Training loss: 2.4364991188049316
Validation loss: 1.953353476780717

Epoch: 5| Step: 8
Training loss: 2.7021028995513916
Validation loss: 1.964510279317056

Epoch: 5| Step: 9
Training loss: 2.2473652362823486
Validation loss: 1.9624598257003292

Epoch: 5| Step: 10
Training loss: 2.1457622051239014
Validation loss: 1.9712745604976531

Epoch: 68| Step: 0
Training loss: 1.9317821264266968
Validation loss: 1.967293377845518

Epoch: 5| Step: 1
Training loss: 1.9037879705429077
Validation loss: 1.9568398062900831

Epoch: 5| Step: 2
Training loss: 2.24454402923584
Validation loss: 1.961339436551576

Epoch: 5| Step: 3
Training loss: 2.703127384185791
Validation loss: 1.9564887439050982

Epoch: 5| Step: 4
Training loss: 1.7160590887069702
Validation loss: 1.960286633942717

Epoch: 5| Step: 5
Training loss: 3.0520126819610596
Validation loss: 1.960966056393039

Epoch: 5| Step: 6
Training loss: 2.4903578758239746
Validation loss: 1.9626587872864099

Epoch: 5| Step: 7
Training loss: 2.204346179962158
Validation loss: 1.9586282058428692

Epoch: 5| Step: 8
Training loss: 1.9303677082061768
Validation loss: 1.9533222516377766

Epoch: 5| Step: 9
Training loss: 2.223569631576538
Validation loss: 1.947946181861303

Epoch: 5| Step: 10
Training loss: 2.5480434894561768
Validation loss: 1.951613982518514

Epoch: 69| Step: 0
Training loss: 2.46653413772583
Validation loss: 1.9392216128687705

Epoch: 5| Step: 1
Training loss: 2.1241493225097656
Validation loss: 1.9580951929092407

Epoch: 5| Step: 2
Training loss: 3.150812864303589
Validation loss: 1.9407972930580057

Epoch: 5| Step: 3
Training loss: 1.743669867515564
Validation loss: 1.9548493059732581

Epoch: 5| Step: 4
Training loss: 2.720588207244873
Validation loss: 1.9457122100296842

Epoch: 5| Step: 5
Training loss: 2.000649929046631
Validation loss: 1.9431761874947497

Epoch: 5| Step: 6
Training loss: 2.323729991912842
Validation loss: 1.9551495300826205

Epoch: 5| Step: 7
Training loss: 2.3877270221710205
Validation loss: 1.9497296271785614

Epoch: 5| Step: 8
Training loss: 1.489764928817749
Validation loss: 1.9614618785919682

Epoch: 5| Step: 9
Training loss: 2.110196828842163
Validation loss: 1.935786957381874

Epoch: 5| Step: 10
Training loss: 2.2268760204315186
Validation loss: 1.940701194988784

Epoch: 70| Step: 0
Training loss: 2.485651969909668
Validation loss: 1.9466700553894043

Epoch: 5| Step: 1
Training loss: 2.4917798042297363
Validation loss: 1.952317891582366

Epoch: 5| Step: 2
Training loss: 2.0972137451171875
Validation loss: 1.9533726733217958

Epoch: 5| Step: 3
Training loss: 2.033902645111084
Validation loss: 1.9583804312572684

Epoch: 5| Step: 4
Training loss: 2.5736875534057617
Validation loss: 1.9463948178034958

Epoch: 5| Step: 5
Training loss: 2.3860602378845215
Validation loss: 1.9561410642439319

Epoch: 5| Step: 6
Training loss: 1.9281437397003174
Validation loss: 1.9504550938965173

Epoch: 5| Step: 7
Training loss: 2.2180237770080566
Validation loss: 1.9425160948948195

Epoch: 5| Step: 8
Training loss: 2.003662347793579
Validation loss: 1.9564907576448174

Epoch: 5| Step: 9
Training loss: 2.288740396499634
Validation loss: 1.9504306162557294

Epoch: 5| Step: 10
Training loss: 2.2728095054626465
Validation loss: 1.9513526501194123

Epoch: 71| Step: 0
Training loss: 2.2626428604125977
Validation loss: 1.9409099842912407

Epoch: 5| Step: 1
Training loss: 2.3299593925476074
Validation loss: 1.9697745884618452

Epoch: 5| Step: 2
Training loss: 2.5747053623199463
Validation loss: 1.950108858846849

Epoch: 5| Step: 3
Training loss: 1.5041425228118896
Validation loss: 1.957538443226968

Epoch: 5| Step: 4
Training loss: 2.0218868255615234
Validation loss: 1.9491449863679948

Epoch: 5| Step: 5
Training loss: 1.924329400062561
Validation loss: 1.9436767921652844

Epoch: 5| Step: 6
Training loss: 2.0404703617095947
Validation loss: 1.9571749766667683

Epoch: 5| Step: 7
Training loss: 2.750131607055664
Validation loss: 1.9482001617390623

Epoch: 5| Step: 8
Training loss: 2.2667930126190186
Validation loss: 1.934882471638341

Epoch: 5| Step: 9
Training loss: 2.4844894409179688
Validation loss: 1.9450711896342616

Epoch: 5| Step: 10
Training loss: 2.643374443054199
Validation loss: 1.9459460550738918

Epoch: 72| Step: 0
Training loss: 2.311906099319458
Validation loss: 1.9516726411798948

Epoch: 5| Step: 1
Training loss: 2.915304183959961
Validation loss: 1.944618071279218

Epoch: 5| Step: 2
Training loss: 2.3083128929138184
Validation loss: 1.940060487357519

Epoch: 5| Step: 3
Training loss: 2.244218111038208
Validation loss: 1.9284568666129984

Epoch: 5| Step: 4
Training loss: 2.2378017902374268
Validation loss: 1.92971694853998

Epoch: 5| Step: 5
Training loss: 2.299672842025757
Validation loss: 1.942778161776963

Epoch: 5| Step: 6
Training loss: 1.7838901281356812
Validation loss: 1.9253206035142303

Epoch: 5| Step: 7
Training loss: 2.407585620880127
Validation loss: 1.9264016766701975

Epoch: 5| Step: 8
Training loss: 2.2428059577941895
Validation loss: 1.936652865461124

Epoch: 5| Step: 9
Training loss: 2.0127298831939697
Validation loss: 1.9223097165425618

Epoch: 5| Step: 10
Training loss: 1.9338442087173462
Validation loss: 1.9402823986545685

Epoch: 73| Step: 0
Training loss: 2.3124425411224365
Validation loss: 1.9357560873031616

Epoch: 5| Step: 1
Training loss: 2.2001523971557617
Validation loss: 1.9288569265796291

Epoch: 5| Step: 2
Training loss: 2.8097379207611084
Validation loss: 1.9300570462339668

Epoch: 5| Step: 3
Training loss: 2.2534942626953125
Validation loss: 1.9246147319834719

Epoch: 5| Step: 4
Training loss: 2.8572945594787598
Validation loss: 1.9405927978536135

Epoch: 5| Step: 5
Training loss: 1.9224271774291992
Validation loss: 1.9326764614351335

Epoch: 5| Step: 6
Training loss: 2.8903393745422363
Validation loss: 1.942660891881553

Epoch: 5| Step: 7
Training loss: 2.034615993499756
Validation loss: 1.9419581954197218

Epoch: 5| Step: 8
Training loss: 1.9665400981903076
Validation loss: 1.945033234934653

Epoch: 5| Step: 9
Training loss: 1.3121448755264282
Validation loss: 1.947787514296911

Epoch: 5| Step: 10
Training loss: 2.0936782360076904
Validation loss: 1.9491575148797804

Epoch: 74| Step: 0
Training loss: 2.2676210403442383
Validation loss: 1.9517634709676106

Epoch: 5| Step: 1
Training loss: 2.0330586433410645
Validation loss: 1.9510561343162292

Epoch: 5| Step: 2
Training loss: 2.7652907371520996
Validation loss: 1.9436422432622602

Epoch: 5| Step: 3
Training loss: 2.2984137535095215
Validation loss: 1.9295744549843572

Epoch: 5| Step: 4
Training loss: 2.1934690475463867
Validation loss: 1.9479699493736349

Epoch: 5| Step: 5
Training loss: 1.9241405725479126
Validation loss: 1.9296257508698331

Epoch: 5| Step: 6
Training loss: 2.5253262519836426
Validation loss: 1.9490941878288024

Epoch: 5| Step: 7
Training loss: 2.5214405059814453
Validation loss: 1.937931364582431

Epoch: 5| Step: 8
Training loss: 1.7471774816513062
Validation loss: 1.9418602605019846

Epoch: 5| Step: 9
Training loss: 2.0846059322357178
Validation loss: 1.9275423429345573

Epoch: 5| Step: 10
Training loss: 2.333427667617798
Validation loss: 1.9302553412734822

Epoch: 75| Step: 0
Training loss: 2.3796424865722656
Validation loss: 1.941938514350563

Epoch: 5| Step: 1
Training loss: 1.7797057628631592
Validation loss: 1.9407056813598962

Epoch: 5| Step: 2
Training loss: 2.3422749042510986
Validation loss: 1.9362149238586426

Epoch: 5| Step: 3
Training loss: 2.463170051574707
Validation loss: 1.9176555487417406

Epoch: 5| Step: 4
Training loss: 2.38403058052063
Validation loss: 1.931719272367416

Epoch: 5| Step: 5
Training loss: 2.4211087226867676
Validation loss: 1.9318966365629626

Epoch: 5| Step: 6
Training loss: 1.836243987083435
Validation loss: 1.9375899171316495

Epoch: 5| Step: 7
Training loss: 1.6470634937286377
Validation loss: 1.9397470669079853

Epoch: 5| Step: 8
Training loss: 2.3887016773223877
Validation loss: 1.943074700652912

Epoch: 5| Step: 9
Training loss: 2.341529130935669
Validation loss: 1.9317407326031757

Epoch: 5| Step: 10
Training loss: 2.7325119972229004
Validation loss: 1.9369391690018356

Epoch: 76| Step: 0
Training loss: 1.9616079330444336
Validation loss: 1.9336671803587226

Epoch: 5| Step: 1
Training loss: 2.7618095874786377
Validation loss: 1.9353223872441117

Epoch: 5| Step: 2
Training loss: 1.984877347946167
Validation loss: 1.9330622688416512

Epoch: 5| Step: 3
Training loss: 2.459808349609375
Validation loss: 1.9170995553334553

Epoch: 5| Step: 4
Training loss: 1.9631760120391846
Validation loss: 1.9283369882132417

Epoch: 5| Step: 5
Training loss: 2.3312079906463623
Validation loss: 1.9349943027701428

Epoch: 5| Step: 6
Training loss: 2.621671199798584
Validation loss: 1.9259800167493923

Epoch: 5| Step: 7
Training loss: 2.156510829925537
Validation loss: 1.9345543230733564

Epoch: 5| Step: 8
Training loss: 1.9186723232269287
Validation loss: 1.9408233755378312

Epoch: 5| Step: 9
Training loss: 2.422527313232422
Validation loss: 1.9383263523860643

Epoch: 5| Step: 10
Training loss: 1.8741360902786255
Validation loss: 1.9259874436163134

Epoch: 77| Step: 0
Training loss: 2.318856716156006
Validation loss: 1.9281461700316398

Epoch: 5| Step: 1
Training loss: 2.2227420806884766
Validation loss: 1.9385452167962187

Epoch: 5| Step: 2
Training loss: 2.3510384559631348
Validation loss: 1.9228659932331373

Epoch: 5| Step: 3
Training loss: 1.9139957427978516
Validation loss: 1.9375532827069681

Epoch: 5| Step: 4
Training loss: 2.3985886573791504
Validation loss: 1.9275169449467813

Epoch: 5| Step: 5
Training loss: 2.402522087097168
Validation loss: 1.9431981143131052

Epoch: 5| Step: 6
Training loss: 1.7973018884658813
Validation loss: 1.9352862014565417

Epoch: 5| Step: 7
Training loss: 2.5879249572753906
Validation loss: 1.9137310751022831

Epoch: 5| Step: 8
Training loss: 1.9597702026367188
Validation loss: 1.9227528161900018

Epoch: 5| Step: 9
Training loss: 2.0490498542785645
Validation loss: 1.9279156602838987

Epoch: 5| Step: 10
Training loss: 2.6285312175750732
Validation loss: 1.9149692673836984

Epoch: 78| Step: 0
Training loss: 2.2680327892303467
Validation loss: 1.9347092438769597

Epoch: 5| Step: 1
Training loss: 2.131108045578003
Validation loss: 1.936399131692866

Epoch: 5| Step: 2
Training loss: 2.1053786277770996
Validation loss: 1.9210878290155882

Epoch: 5| Step: 3
Training loss: 2.299029588699341
Validation loss: 1.9482808459189631

Epoch: 5| Step: 4
Training loss: 2.220754623413086
Validation loss: 1.9192544311605475

Epoch: 5| Step: 5
Training loss: 1.9859269857406616
Validation loss: 1.9397225533762286

Epoch: 5| Step: 6
Training loss: 2.2815937995910645
Validation loss: 1.9504966351293749

Epoch: 5| Step: 7
Training loss: 2.3518097400665283
Validation loss: 1.956367027375006

Epoch: 5| Step: 8
Training loss: 2.1650092601776123
Validation loss: 1.9406130006236415

Epoch: 5| Step: 9
Training loss: 2.0901923179626465
Validation loss: 1.9375466915868944

Epoch: 5| Step: 10
Training loss: 2.713275909423828
Validation loss: 1.9513063020603632

Epoch: 79| Step: 0
Training loss: 2.386340379714966
Validation loss: 1.9360276037646877

Epoch: 5| Step: 1
Training loss: 2.2841577529907227
Validation loss: 1.9338146076407483

Epoch: 5| Step: 2
Training loss: 2.2264580726623535
Validation loss: 1.9384293146030878

Epoch: 5| Step: 3
Training loss: 2.2692275047302246
Validation loss: 1.9305613540833997

Epoch: 5| Step: 4
Training loss: 2.2175536155700684
Validation loss: 1.941650826443908

Epoch: 5| Step: 5
Training loss: 2.596527576446533
Validation loss: 1.9292032558430907

Epoch: 5| Step: 6
Training loss: 2.2931675910949707
Validation loss: 1.9325416882832844

Epoch: 5| Step: 7
Training loss: 2.78493070602417
Validation loss: 1.9230687900256085

Epoch: 5| Step: 8
Training loss: 1.1818046569824219
Validation loss: 1.9132014051560433

Epoch: 5| Step: 9
Training loss: 2.5021891593933105
Validation loss: 1.9286014879903486

Epoch: 5| Step: 10
Training loss: 1.6203185319900513
Validation loss: 1.9302004524456557

Epoch: 80| Step: 0
Training loss: 2.715578079223633
Validation loss: 1.9220730848209833

Epoch: 5| Step: 1
Training loss: 2.450446605682373
Validation loss: 1.9128685459013908

Epoch: 5| Step: 2
Training loss: 2.556572198867798
Validation loss: 1.9217689498778312

Epoch: 5| Step: 3
Training loss: 2.0367541313171387
Validation loss: 1.931301111816078

Epoch: 5| Step: 4
Training loss: 2.2086000442504883
Validation loss: 1.9368873065517795

Epoch: 5| Step: 5
Training loss: 1.6677720546722412
Validation loss: 1.9360406116772724

Epoch: 5| Step: 6
Training loss: 2.4067959785461426
Validation loss: 1.9107320923959055

Epoch: 5| Step: 7
Training loss: 2.206369638442993
Validation loss: 1.9288782509424354

Epoch: 5| Step: 8
Training loss: 1.8184016942977905
Validation loss: 1.917248579763597

Epoch: 5| Step: 9
Training loss: 2.2468693256378174
Validation loss: 1.9403432825560212

Epoch: 5| Step: 10
Training loss: 2.1278843879699707
Validation loss: 1.9199067572111725

Epoch: 81| Step: 0
Training loss: 2.1525704860687256
Validation loss: 1.9409601701203214

Epoch: 5| Step: 1
Training loss: 2.4671363830566406
Validation loss: 1.9366268060540641

Epoch: 5| Step: 2
Training loss: 2.4590518474578857
Validation loss: 1.9225861795486943

Epoch: 5| Step: 3
Training loss: 2.341609001159668
Validation loss: 1.917145545764636

Epoch: 5| Step: 4
Training loss: 2.766558885574341
Validation loss: 1.9274053445426367

Epoch: 5| Step: 5
Training loss: 1.7191489934921265
Validation loss: 1.9325044001302412

Epoch: 5| Step: 6
Training loss: 1.39091157913208
Validation loss: 1.9431190054903749

Epoch: 5| Step: 7
Training loss: 1.7227433919906616
Validation loss: 1.9201020322820193

Epoch: 5| Step: 8
Training loss: 2.2372822761535645
Validation loss: 1.9416024492632957

Epoch: 5| Step: 9
Training loss: 2.581231117248535
Validation loss: 1.9411400889837613

Epoch: 5| Step: 10
Training loss: 2.6365435123443604
Validation loss: 1.9455689999365038

Epoch: 82| Step: 0
Training loss: 1.9455989599227905
Validation loss: 1.930957148152013

Epoch: 5| Step: 1
Training loss: 2.251295566558838
Validation loss: 1.9214238171936364

Epoch: 5| Step: 2
Training loss: 3.0817151069641113
Validation loss: 1.9455262935289772

Epoch: 5| Step: 3
Training loss: 1.8340803384780884
Validation loss: 1.934122468835564

Epoch: 5| Step: 4
Training loss: 2.539926767349243
Validation loss: 1.93236635064566

Epoch: 5| Step: 5
Training loss: 2.3867712020874023
Validation loss: 1.9279129928158176

Epoch: 5| Step: 6
Training loss: 2.0843613147735596
Validation loss: 1.9299299165766726

Epoch: 5| Step: 7
Training loss: 2.0956990718841553
Validation loss: 1.915900989245343

Epoch: 5| Step: 8
Training loss: 2.3074047565460205
Validation loss: 1.9361385504404705

Epoch: 5| Step: 9
Training loss: 1.7537683248519897
Validation loss: 1.9470308365360383

Epoch: 5| Step: 10
Training loss: 2.127354383468628
Validation loss: 1.9252108732859294

Epoch: 83| Step: 0
Training loss: 1.8475589752197266
Validation loss: 1.922617902037918

Epoch: 5| Step: 1
Training loss: 2.4823365211486816
Validation loss: 1.9269366930889826

Epoch: 5| Step: 2
Training loss: 1.889879822731018
Validation loss: 1.9241221156171573

Epoch: 5| Step: 3
Training loss: 2.1791279315948486
Validation loss: 1.9268774729903027

Epoch: 5| Step: 4
Training loss: 1.6168248653411865
Validation loss: 1.9410678827634422

Epoch: 5| Step: 5
Training loss: 2.414140462875366
Validation loss: 1.9317828686006608

Epoch: 5| Step: 6
Training loss: 2.26438045501709
Validation loss: 1.927824648477698

Epoch: 5| Step: 7
Training loss: 2.525824785232544
Validation loss: 1.9306096082092614

Epoch: 5| Step: 8
Training loss: 2.4828543663024902
Validation loss: 1.9197358392900037

Epoch: 5| Step: 9
Training loss: 2.337561845779419
Validation loss: 1.9225376831587924

Epoch: 5| Step: 10
Training loss: 2.3122806549072266
Validation loss: 1.9333779632404287

Epoch: 84| Step: 0
Training loss: 2.4810338020324707
Validation loss: 1.9250462452570598

Epoch: 5| Step: 1
Training loss: 2.492953300476074
Validation loss: 1.919761121913951

Epoch: 5| Step: 2
Training loss: 2.0127711296081543
Validation loss: 1.9263728203312043

Epoch: 5| Step: 3
Training loss: 2.3658268451690674
Validation loss: 1.9366442644467918

Epoch: 5| Step: 4
Training loss: 2.0341477394104004
Validation loss: 1.9203116534858622

Epoch: 5| Step: 5
Training loss: 2.078183174133301
Validation loss: 1.9248313698717343

Epoch: 5| Step: 6
Training loss: 2.117964744567871
Validation loss: 1.9345189038143362

Epoch: 5| Step: 7
Training loss: 2.2453837394714355
Validation loss: 1.9355848527723742

Epoch: 5| Step: 8
Training loss: 2.5456130504608154
Validation loss: 1.9383713045427877

Epoch: 5| Step: 9
Training loss: 1.6595361232757568
Validation loss: 1.9453198063758113

Epoch: 5| Step: 10
Training loss: 2.3268330097198486
Validation loss: 1.9286186874553721

Epoch: 85| Step: 0
Training loss: 2.39615797996521
Validation loss: 1.9133496335757676

Epoch: 5| Step: 1
Training loss: 2.4627509117126465
Validation loss: 1.9179347279251262

Epoch: 5| Step: 2
Training loss: 2.193847179412842
Validation loss: 1.924988046769173

Epoch: 5| Step: 3
Training loss: 1.9555652141571045
Validation loss: 1.9238244410484069

Epoch: 5| Step: 4
Training loss: 2.7068374156951904
Validation loss: 1.923531912988232

Epoch: 5| Step: 5
Training loss: 2.244361400604248
Validation loss: 1.9077843414839877

Epoch: 5| Step: 6
Training loss: 1.6697721481323242
Validation loss: 1.9254089709251159

Epoch: 5| Step: 7
Training loss: 1.6334221363067627
Validation loss: 1.9082662187596804

Epoch: 5| Step: 8
Training loss: 2.117509365081787
Validation loss: 1.9134628131825437

Epoch: 5| Step: 9
Training loss: 2.503000497817993
Validation loss: 1.9102945404668008

Epoch: 5| Step: 10
Training loss: 2.2971370220184326
Validation loss: 1.9090961756244782

Epoch: 86| Step: 0
Training loss: 2.2064738273620605
Validation loss: 1.912433652467625

Epoch: 5| Step: 1
Training loss: 1.7741655111312866
Validation loss: 1.9330862760543823

Epoch: 5| Step: 2
Training loss: 2.381984233856201
Validation loss: 1.9270465681629796

Epoch: 5| Step: 3
Training loss: 2.2540860176086426
Validation loss: 1.9114045404618787

Epoch: 5| Step: 4
Training loss: 2.449714183807373
Validation loss: 1.910246620896042

Epoch: 5| Step: 5
Training loss: 2.2220945358276367
Validation loss: 1.8956589109154158

Epoch: 5| Step: 6
Training loss: 1.403379201889038
Validation loss: 1.9005256532340922

Epoch: 5| Step: 7
Training loss: 2.4943270683288574
Validation loss: 1.9128526180021224

Epoch: 5| Step: 8
Training loss: 2.06854248046875
Validation loss: 1.901670846887814

Epoch: 5| Step: 9
Training loss: 2.305729389190674
Validation loss: 1.912286767395594

Epoch: 5| Step: 10
Training loss: 2.860320568084717
Validation loss: 1.9189393263991161

Epoch: 87| Step: 0
Training loss: 2.50640869140625
Validation loss: 1.9003222347587667

Epoch: 5| Step: 1
Training loss: 2.0341458320617676
Validation loss: 1.9143299748820644

Epoch: 5| Step: 2
Training loss: 2.6171822547912598
Validation loss: 1.9124955169616207

Epoch: 5| Step: 3
Training loss: 1.8306182622909546
Validation loss: 1.9202151657432638

Epoch: 5| Step: 4
Training loss: 2.104447841644287
Validation loss: 1.9089788647108181

Epoch: 5| Step: 5
Training loss: 2.287778615951538
Validation loss: 1.9163909624981623

Epoch: 5| Step: 6
Training loss: 2.3160910606384277
Validation loss: 1.9157680260237826

Epoch: 5| Step: 7
Training loss: 2.0653774738311768
Validation loss: 1.922234255780456

Epoch: 5| Step: 8
Training loss: 2.223558187484741
Validation loss: 1.9289152404313445

Epoch: 5| Step: 9
Training loss: 1.780638337135315
Validation loss: 1.9206711656303816

Epoch: 5| Step: 10
Training loss: 2.509420394897461
Validation loss: 1.91380016521741

Epoch: 88| Step: 0
Training loss: 2.701577663421631
Validation loss: 1.9226258749602942

Epoch: 5| Step: 1
Training loss: 1.4134620428085327
Validation loss: 1.9114674739940192

Epoch: 5| Step: 2
Training loss: 1.8685646057128906
Validation loss: 1.9296046469801216

Epoch: 5| Step: 3
Training loss: 2.3515028953552246
Validation loss: 1.9244878650993429

Epoch: 5| Step: 4
Training loss: 2.278970241546631
Validation loss: 1.9231146240747103

Epoch: 5| Step: 5
Training loss: 2.474778652191162
Validation loss: 1.9219324101683914

Epoch: 5| Step: 6
Training loss: 2.3734142780303955
Validation loss: 1.9170908876644668

Epoch: 5| Step: 7
Training loss: 2.7284865379333496
Validation loss: 1.9120671723478584

Epoch: 5| Step: 8
Training loss: 2.23734188079834
Validation loss: 1.9281341683480047

Epoch: 5| Step: 9
Training loss: 2.0319712162017822
Validation loss: 1.9255804502835838

Epoch: 5| Step: 10
Training loss: 1.6423128843307495
Validation loss: 1.9256150440503192

Epoch: 89| Step: 0
Training loss: 2.2882254123687744
Validation loss: 1.9116736919649187

Epoch: 5| Step: 1
Training loss: 2.4235973358154297
Validation loss: 1.9337200772377752

Epoch: 5| Step: 2
Training loss: 1.8766810894012451
Validation loss: 1.9295678792461273

Epoch: 5| Step: 3
Training loss: 2.691962718963623
Validation loss: 1.9152322174400411

Epoch: 5| Step: 4
Training loss: 2.414189577102661
Validation loss: 1.9178445928840226

Epoch: 5| Step: 5
Training loss: 2.0933194160461426
Validation loss: 1.9257552610930575

Epoch: 5| Step: 6
Training loss: 1.4929780960083008
Validation loss: 1.9278097934620355

Epoch: 5| Step: 7
Training loss: 2.10239577293396
Validation loss: 1.9123901064677904

Epoch: 5| Step: 8
Training loss: 2.205878496170044
Validation loss: 1.9192346334457397

Epoch: 5| Step: 9
Training loss: 2.1140053272247314
Validation loss: 1.9321528660353793

Epoch: 5| Step: 10
Training loss: 2.3226332664489746
Validation loss: 1.9181467307511197

Epoch: 90| Step: 0
Training loss: 2.0018811225891113
Validation loss: 1.9174289626459922

Epoch: 5| Step: 1
Training loss: 2.36415433883667
Validation loss: 1.91693909962972

Epoch: 5| Step: 2
Training loss: 2.1532766819000244
Validation loss: 1.9008259260526268

Epoch: 5| Step: 3
Training loss: 2.5507185459136963
Validation loss: 1.9102238916581677

Epoch: 5| Step: 4
Training loss: 2.3540008068084717
Validation loss: 1.9134294012541413

Epoch: 5| Step: 5
Training loss: 1.905003309249878
Validation loss: 1.9103040079916678

Epoch: 5| Step: 6
Training loss: 2.0220260620117188
Validation loss: 1.905026153851581

Epoch: 5| Step: 7
Training loss: 2.115288257598877
Validation loss: 1.9201527616029144

Epoch: 5| Step: 8
Training loss: 2.5299277305603027
Validation loss: 1.905837094911965

Epoch: 5| Step: 9
Training loss: 1.815468192100525
Validation loss: 1.9130218182840655

Epoch: 5| Step: 10
Training loss: 2.3535654544830322
Validation loss: 1.9117119491741221

Epoch: 91| Step: 0
Training loss: 2.2997374534606934
Validation loss: 1.905729857824182

Epoch: 5| Step: 1
Training loss: 2.4519481658935547
Validation loss: 1.9154569769418368

Epoch: 5| Step: 2
Training loss: 1.943922758102417
Validation loss: 1.9200828870137532

Epoch: 5| Step: 3
Training loss: 2.1988396644592285
Validation loss: 1.904425290323073

Epoch: 5| Step: 4
Training loss: 2.3470940589904785
Validation loss: 1.919596295202932

Epoch: 5| Step: 5
Training loss: 2.241706132888794
Validation loss: 1.9181131880770448

Epoch: 5| Step: 6
Training loss: 2.1836535930633545
Validation loss: 1.9067845216361425

Epoch: 5| Step: 7
Training loss: 2.08365535736084
Validation loss: 1.915261632652693

Epoch: 5| Step: 8
Training loss: 2.3523566722869873
Validation loss: 1.9178007828292025

Epoch: 5| Step: 9
Training loss: 1.9034305810928345
Validation loss: 1.9164991314693163

Epoch: 5| Step: 10
Training loss: 2.053600788116455
Validation loss: 1.926516035551666

Epoch: 92| Step: 0
Training loss: 2.7992043495178223
Validation loss: 1.9166750754079511

Epoch: 5| Step: 1
Training loss: 2.3719723224639893
Validation loss: 1.9189158972873483

Epoch: 5| Step: 2
Training loss: 2.362365484237671
Validation loss: 1.9386085951200096

Epoch: 5| Step: 3
Training loss: 2.151826858520508
Validation loss: 1.9285524532359133

Epoch: 5| Step: 4
Training loss: 2.02323579788208
Validation loss: 1.9242925387556835

Epoch: 5| Step: 5
Training loss: 1.5813257694244385
Validation loss: 1.926265444806827

Epoch: 5| Step: 6
Training loss: 2.0692574977874756
Validation loss: 1.919125146763299

Epoch: 5| Step: 7
Training loss: 2.29715895652771
Validation loss: 1.9201057649427844

Epoch: 5| Step: 8
Training loss: 2.2227532863616943
Validation loss: 1.9232883914824455

Epoch: 5| Step: 9
Training loss: 2.208407402038574
Validation loss: 1.9070415830099454

Epoch: 5| Step: 10
Training loss: 1.964862585067749
Validation loss: 1.9233159031919254

Epoch: 93| Step: 0
Training loss: 2.524578809738159
Validation loss: 1.9129367720696233

Epoch: 5| Step: 1
Training loss: 1.6993083953857422
Validation loss: 1.9259671036915114

Epoch: 5| Step: 2
Training loss: 1.7167400121688843
Validation loss: 1.924399350279121

Epoch: 5| Step: 3
Training loss: 1.8836085796356201
Validation loss: 1.9131002067237772

Epoch: 5| Step: 4
Training loss: 2.6875720024108887
Validation loss: 1.9009849768812939

Epoch: 5| Step: 5
Training loss: 2.27760648727417
Validation loss: 1.900994457224364

Epoch: 5| Step: 6
Training loss: 1.9685875177383423
Validation loss: 1.918413628814041

Epoch: 5| Step: 7
Training loss: 2.1898536682128906
Validation loss: 1.899810396214967

Epoch: 5| Step: 8
Training loss: 2.133479356765747
Validation loss: 1.9144745603684457

Epoch: 5| Step: 9
Training loss: 2.3874001502990723
Validation loss: 1.9279432283934725

Epoch: 5| Step: 10
Training loss: 2.5649077892303467
Validation loss: 1.9189776323174919

Epoch: 94| Step: 0
Training loss: 1.6508671045303345
Validation loss: 1.9102976937447824

Epoch: 5| Step: 1
Training loss: 2.597032070159912
Validation loss: 1.924231562563168

Epoch: 5| Step: 2
Training loss: 2.726992130279541
Validation loss: 1.9130890177142235

Epoch: 5| Step: 3
Training loss: 1.8938820362091064
Validation loss: 1.917976769067908

Epoch: 5| Step: 4
Training loss: 2.5208587646484375
Validation loss: 1.9120801994877477

Epoch: 5| Step: 5
Training loss: 1.9179611206054688
Validation loss: 1.9102410962504726

Epoch: 5| Step: 6
Training loss: 2.462040662765503
Validation loss: 1.9252267242759786

Epoch: 5| Step: 7
Training loss: 2.1308348178863525
Validation loss: 1.9054873322927823

Epoch: 5| Step: 8
Training loss: 1.9299602508544922
Validation loss: 1.9059245137758152

Epoch: 5| Step: 9
Training loss: 1.9174997806549072
Validation loss: 1.9181452335849885

Epoch: 5| Step: 10
Training loss: 2.4301726818084717
Validation loss: 1.9092205544953704

Epoch: 95| Step: 0
Training loss: 2.0840816497802734
Validation loss: 1.8933118030589113

Epoch: 5| Step: 1
Training loss: 2.4270615577697754
Validation loss: 1.9091065493963097

Epoch: 5| Step: 2
Training loss: 2.382842779159546
Validation loss: 1.9039402443875548

Epoch: 5| Step: 3
Training loss: 1.869259238243103
Validation loss: 1.8913682904294742

Epoch: 5| Step: 4
Training loss: 2.5959291458129883
Validation loss: 1.8961101937037643

Epoch: 5| Step: 5
Training loss: 2.0406105518341064
Validation loss: 1.914339901298605

Epoch: 5| Step: 6
Training loss: 1.9908735752105713
Validation loss: 1.8961686652193788

Epoch: 5| Step: 7
Training loss: 2.3045969009399414
Validation loss: 1.9089939927542081

Epoch: 5| Step: 8
Training loss: 1.9758331775665283
Validation loss: 1.9074509964194348

Epoch: 5| Step: 9
Training loss: 2.4502313137054443
Validation loss: 1.9030436520935388

Epoch: 5| Step: 10
Training loss: 1.8353441953659058
Validation loss: 1.9005405531134656

Epoch: 96| Step: 0
Training loss: 2.270573139190674
Validation loss: 1.912907333784206

Epoch: 5| Step: 1
Training loss: 2.380880832672119
Validation loss: 1.9121557897137058

Epoch: 5| Step: 2
Training loss: 1.753847360610962
Validation loss: 1.8997941568333616

Epoch: 5| Step: 3
Training loss: 2.228886842727661
Validation loss: 1.9030054641026322

Epoch: 5| Step: 4
Training loss: 2.3989017009735107
Validation loss: 1.9158831270792152

Epoch: 5| Step: 5
Training loss: 1.987260103225708
Validation loss: 1.9157049758459932

Epoch: 5| Step: 6
Training loss: 2.6980719566345215
Validation loss: 1.9046512085904357

Epoch: 5| Step: 7
Training loss: 1.9893356561660767
Validation loss: 1.9197678604433615

Epoch: 5| Step: 8
Training loss: 1.6757440567016602
Validation loss: 1.9154350270507157

Epoch: 5| Step: 9
Training loss: 2.2949788570404053
Validation loss: 1.905810784268123

Epoch: 5| Step: 10
Training loss: 2.213547706604004
Validation loss: 1.9190647063716766

Epoch: 97| Step: 0
Training loss: 2.732264280319214
Validation loss: 1.909259509014827

Epoch: 5| Step: 1
Training loss: 2.126716136932373
Validation loss: 1.9189834376817108

Epoch: 5| Step: 2
Training loss: 2.388911724090576
Validation loss: 1.8985180239523611

Epoch: 5| Step: 3
Training loss: 2.5634591579437256
Validation loss: 1.9120198347235238

Epoch: 5| Step: 4
Training loss: 1.6030590534210205
Validation loss: 1.9148640837720645

Epoch: 5| Step: 5
Training loss: 1.9335848093032837
Validation loss: 1.9106138829262025

Epoch: 5| Step: 6
Training loss: 2.2387967109680176
Validation loss: 1.9020740511596843

Epoch: 5| Step: 7
Training loss: 2.2227463722229004
Validation loss: 1.8964824394513202

Epoch: 5| Step: 8
Training loss: 1.7825767993927002
Validation loss: 1.9114074450667187

Epoch: 5| Step: 9
Training loss: 2.216158628463745
Validation loss: 1.896452844783824

Epoch: 5| Step: 10
Training loss: 2.067659616470337
Validation loss: 1.9065799995135235

Epoch: 98| Step: 0
Training loss: 1.9876320362091064
Validation loss: 1.8904269459427043

Epoch: 5| Step: 1
Training loss: 2.0756735801696777
Validation loss: 1.8995770164715347

Epoch: 5| Step: 2
Training loss: 2.032271146774292
Validation loss: 1.8988104148577618

Epoch: 5| Step: 3
Training loss: 1.9294841289520264
Validation loss: 1.920992209065345

Epoch: 5| Step: 4
Training loss: 1.9487396478652954
Validation loss: 1.9123802056876562

Epoch: 5| Step: 5
Training loss: 2.2295145988464355
Validation loss: 1.9088420150100545

Epoch: 5| Step: 6
Training loss: 2.381899356842041
Validation loss: 1.9107690600938694

Epoch: 5| Step: 7
Training loss: 2.5512187480926514
Validation loss: 1.9068666581184632

Epoch: 5| Step: 8
Training loss: 2.094257354736328
Validation loss: 1.9025436139875842

Epoch: 5| Step: 9
Training loss: 2.429309844970703
Validation loss: 1.897123763638158

Epoch: 5| Step: 10
Training loss: 2.225780725479126
Validation loss: 1.8989073512374715

Epoch: 99| Step: 0
Training loss: 2.907994270324707
Validation loss: 1.888458909526948

Epoch: 5| Step: 1
Training loss: 1.4231021404266357
Validation loss: 1.9041540866257043

Epoch: 5| Step: 2
Training loss: 2.3674144744873047
Validation loss: 1.9163183384044196

Epoch: 5| Step: 3
Training loss: 1.910251259803772
Validation loss: 1.90087926900515

Epoch: 5| Step: 4
Training loss: 2.6179916858673096
Validation loss: 1.903393317294377

Epoch: 5| Step: 5
Training loss: 1.9048454761505127
Validation loss: 1.8815938990603212

Epoch: 5| Step: 6
Training loss: 1.480893850326538
Validation loss: 1.8959151083423245

Epoch: 5| Step: 7
Training loss: 1.5871504545211792
Validation loss: 1.8876764146230554

Epoch: 5| Step: 8
Training loss: 2.4239871501922607
Validation loss: 1.897782180898933

Epoch: 5| Step: 9
Training loss: 2.4626102447509766
Validation loss: 1.895570070512833

Epoch: 5| Step: 10
Training loss: 2.7917864322662354
Validation loss: 1.8975416332162836

Epoch: 100| Step: 0
Training loss: 2.338326930999756
Validation loss: 1.8778499890399236

Epoch: 5| Step: 1
Training loss: 1.8033431768417358
Validation loss: 1.887628545043289

Epoch: 5| Step: 2
Training loss: 2.2741150856018066
Validation loss: 1.873051211398135

Epoch: 5| Step: 3
Training loss: 1.9299198389053345
Validation loss: 1.8876480671667284

Epoch: 5| Step: 4
Training loss: 2.4974820613861084
Validation loss: 1.8953250069772043

Epoch: 5| Step: 5
Training loss: 2.0070278644561768
Validation loss: 1.8837021794370425

Epoch: 5| Step: 6
Training loss: 2.2906265258789062
Validation loss: 1.8942518952072307

Epoch: 5| Step: 7
Training loss: 2.0177865028381348
Validation loss: 1.9082974746663084

Epoch: 5| Step: 8
Training loss: 1.9429107904434204
Validation loss: 1.8998154927325506

Epoch: 5| Step: 9
Training loss: 1.982879638671875
Validation loss: 1.8688060122151529

Epoch: 5| Step: 10
Training loss: 2.6239092350006104
Validation loss: 1.9023292846577142

Epoch: 101| Step: 0
Training loss: 2.0142385959625244
Validation loss: 1.912515619749664

Epoch: 5| Step: 1
Training loss: 1.8438085317611694
Validation loss: 1.896308034978887

Epoch: 5| Step: 2
Training loss: 2.2782280445098877
Validation loss: 1.898897752966932

Epoch: 5| Step: 3
Training loss: 2.3426706790924072
Validation loss: 1.9070269830765263

Epoch: 5| Step: 4
Training loss: 2.4602622985839844
Validation loss: 1.8947466650316793

Epoch: 5| Step: 5
Training loss: 2.1651206016540527
Validation loss: 1.8996307811429423

Epoch: 5| Step: 6
Training loss: 2.258230686187744
Validation loss: 1.8944621970576625

Epoch: 5| Step: 7
Training loss: 1.9500255584716797
Validation loss: 1.899239496518207

Epoch: 5| Step: 8
Training loss: 1.9437211751937866
Validation loss: 1.8967516999090872

Epoch: 5| Step: 9
Training loss: 2.507035732269287
Validation loss: 1.9088821975133752

Epoch: 5| Step: 10
Training loss: 1.9625816345214844
Validation loss: 1.9041773555099324

Epoch: 102| Step: 0
Training loss: 2.127720355987549
Validation loss: 1.891147885271298

Epoch: 5| Step: 1
Training loss: 2.432835340499878
Validation loss: 1.9143486240858674

Epoch: 5| Step: 2
Training loss: 2.28851580619812
Validation loss: 1.9082137705177389

Epoch: 5| Step: 3
Training loss: 2.6380743980407715
Validation loss: 1.9169282490207302

Epoch: 5| Step: 4
Training loss: 1.920772910118103
Validation loss: 1.9160630215880692

Epoch: 5| Step: 5
Training loss: 1.6747846603393555
Validation loss: 1.907830850411487

Epoch: 5| Step: 6
Training loss: 1.8969061374664307
Validation loss: 1.9140872545139764

Epoch: 5| Step: 7
Training loss: 2.2225868701934814
Validation loss: 1.9067993958791096

Epoch: 5| Step: 8
Training loss: 2.3023009300231934
Validation loss: 1.9145795324797272

Epoch: 5| Step: 9
Training loss: 2.0113677978515625
Validation loss: 1.9007311290310276

Epoch: 5| Step: 10
Training loss: 2.160306930541992
Validation loss: 1.9096386150647235

Epoch: 103| Step: 0
Training loss: 1.6846317052841187
Validation loss: 1.92043601441127

Epoch: 5| Step: 1
Training loss: 1.9137985706329346
Validation loss: 1.9128927556417321

Epoch: 5| Step: 2
Training loss: 2.2700283527374268
Validation loss: 1.9147417955501105

Epoch: 5| Step: 3
Training loss: 2.0891473293304443
Validation loss: 1.905274018164604

Epoch: 5| Step: 4
Training loss: 1.8581247329711914
Validation loss: 1.908394495646159

Epoch: 5| Step: 5
Training loss: 2.619943380355835
Validation loss: 1.918719328859801

Epoch: 5| Step: 6
Training loss: 2.3016107082366943
Validation loss: 1.9166431234728905

Epoch: 5| Step: 7
Training loss: 2.143083095550537
Validation loss: 1.9134807279033046

Epoch: 5| Step: 8
Training loss: 2.63439679145813
Validation loss: 1.8922802825127878

Epoch: 5| Step: 9
Training loss: 1.9007667303085327
Validation loss: 1.8873539124765704

Epoch: 5| Step: 10
Training loss: 2.3021962642669678
Validation loss: 1.9128956846011582

Epoch: 104| Step: 0
Training loss: 2.2743630409240723
Validation loss: 1.9010949032281035

Epoch: 5| Step: 1
Training loss: 2.570962429046631
Validation loss: 1.9081590701174993

Epoch: 5| Step: 2
Training loss: 1.6980009078979492
Validation loss: 1.903376030665572

Epoch: 5| Step: 3
Training loss: 1.9353729486465454
Validation loss: 1.9120381327085598

Epoch: 5| Step: 4
Training loss: 2.320565700531006
Validation loss: 1.9183592373324978

Epoch: 5| Step: 5
Training loss: 2.2227697372436523
Validation loss: 1.909727998959121

Epoch: 5| Step: 6
Training loss: 1.9367907047271729
Validation loss: 1.9131655846872637

Epoch: 5| Step: 7
Training loss: 2.2643423080444336
Validation loss: 1.9049525260925293

Epoch: 5| Step: 8
Training loss: 2.059136390686035
Validation loss: 1.8992951839200911

Epoch: 5| Step: 9
Training loss: 2.1587915420532227
Validation loss: 1.9146036947927167

Epoch: 5| Step: 10
Training loss: 2.24489426612854
Validation loss: 1.8887461411055697

Epoch: 105| Step: 0
Training loss: 2.168579578399658
Validation loss: 1.9061572218454013

Epoch: 5| Step: 1
Training loss: 2.6518619060516357
Validation loss: 1.91012389685518

Epoch: 5| Step: 2
Training loss: 1.8792699575424194
Validation loss: 1.8926142813057028

Epoch: 5| Step: 3
Training loss: 1.6680002212524414
Validation loss: 1.8950280169005036

Epoch: 5| Step: 4
Training loss: 2.3172008991241455
Validation loss: 1.9086428534600042

Epoch: 5| Step: 5
Training loss: 1.8144285678863525
Validation loss: 1.9237528231836134

Epoch: 5| Step: 6
Training loss: 1.9323657751083374
Validation loss: 1.9279658025310886

Epoch: 5| Step: 7
Training loss: 2.532477378845215
Validation loss: 1.919554098959892

Epoch: 5| Step: 8
Training loss: 2.5967798233032227
Validation loss: 1.9088865864661433

Epoch: 5| Step: 9
Training loss: 2.036989212036133
Validation loss: 1.9080327005796536

Epoch: 5| Step: 10
Training loss: 2.0750958919525146
Validation loss: 1.906494794353362

Epoch: 106| Step: 0
Training loss: 1.5509881973266602
Validation loss: 1.917472667591546

Epoch: 5| Step: 1
Training loss: 2.20343017578125
Validation loss: 1.9259279620262884

Epoch: 5| Step: 2
Training loss: 2.4659714698791504
Validation loss: 1.902334923385292

Epoch: 5| Step: 3
Training loss: 1.8890479803085327
Validation loss: 1.9082022610531058

Epoch: 5| Step: 4
Training loss: 2.046692371368408
Validation loss: 1.9144279905544814

Epoch: 5| Step: 5
Training loss: 2.7611937522888184
Validation loss: 1.9086978653425812

Epoch: 5| Step: 6
Training loss: 1.7320257425308228
Validation loss: 1.9052447785613358

Epoch: 5| Step: 7
Training loss: 2.1377511024475098
Validation loss: 1.8866965322084324

Epoch: 5| Step: 8
Training loss: 2.1685783863067627
Validation loss: 1.9056321984978133

Epoch: 5| Step: 9
Training loss: 1.9588441848754883
Validation loss: 1.9109083888351277

Epoch: 5| Step: 10
Training loss: 2.7819042205810547
Validation loss: 1.9082149997834237

Epoch: 107| Step: 0
Training loss: 1.9741013050079346
Validation loss: 1.8968419900504492

Epoch: 5| Step: 1
Training loss: 1.7393327951431274
Validation loss: 1.901285784218901

Epoch: 5| Step: 2
Training loss: 2.3015201091766357
Validation loss: 1.9146292824898996

Epoch: 5| Step: 3
Training loss: 1.6294549703598022
Validation loss: 1.909149819804776

Epoch: 5| Step: 4
Training loss: 2.5174813270568848
Validation loss: 1.9062265785791541

Epoch: 5| Step: 5
Training loss: 2.0912938117980957
Validation loss: 1.8978243611192191

Epoch: 5| Step: 6
Training loss: 1.71062433719635
Validation loss: 1.9097987259587934

Epoch: 5| Step: 7
Training loss: 2.3683314323425293
Validation loss: 1.8967440807691185

Epoch: 5| Step: 8
Training loss: 2.8587334156036377
Validation loss: 1.9057893214687225

Epoch: 5| Step: 9
Training loss: 2.2800488471984863
Validation loss: 1.9208265735257057

Epoch: 5| Step: 10
Training loss: 2.0241150856018066
Validation loss: 1.9084798136065084

Epoch: 108| Step: 0
Training loss: 2.5814175605773926
Validation loss: 1.9218374977829635

Epoch: 5| Step: 1
Training loss: 1.9837405681610107
Validation loss: 1.9194890773424538

Epoch: 5| Step: 2
Training loss: 1.6957120895385742
Validation loss: 1.9107962141754806

Epoch: 5| Step: 3
Training loss: 1.853945016860962
Validation loss: 1.9290284469563475

Epoch: 5| Step: 4
Training loss: 1.680719017982483
Validation loss: 1.903075473282927

Epoch: 5| Step: 5
Training loss: 2.5676076412200928
Validation loss: 1.9274819922703568

Epoch: 5| Step: 6
Training loss: 2.2575602531433105
Validation loss: 1.9010009329806092

Epoch: 5| Step: 7
Training loss: 2.878567695617676
Validation loss: 1.9194562114695066

Epoch: 5| Step: 8
Training loss: 1.9513763189315796
Validation loss: 1.9275469010876072

Epoch: 5| Step: 9
Training loss: 1.7992761135101318
Validation loss: 1.9196574329048075

Epoch: 5| Step: 10
Training loss: 2.15486741065979
Validation loss: 1.9266318018718431

Epoch: 109| Step: 0
Training loss: 2.3828132152557373
Validation loss: 1.896263255867907

Epoch: 5| Step: 1
Training loss: 1.9280389547348022
Validation loss: 1.9176380852217316

Epoch: 5| Step: 2
Training loss: 2.1459949016571045
Validation loss: 1.9342868148639638

Epoch: 5| Step: 3
Training loss: 2.6620826721191406
Validation loss: 1.9026656202090684

Epoch: 5| Step: 4
Training loss: 2.071240186691284
Validation loss: 1.9085878210683023

Epoch: 5| Step: 5
Training loss: 1.9029916524887085
Validation loss: 1.922232207431588

Epoch: 5| Step: 6
Training loss: 1.692222237586975
Validation loss: 1.927380261882659

Epoch: 5| Step: 7
Training loss: 2.019376277923584
Validation loss: 1.9146218017865253

Epoch: 5| Step: 8
Training loss: 2.1036500930786133
Validation loss: 1.908064701223886

Epoch: 5| Step: 9
Training loss: 2.1407084465026855
Validation loss: 1.9077115904900335

Epoch: 5| Step: 10
Training loss: 2.416966676712036
Validation loss: 1.918244509286778

Epoch: 110| Step: 0
Training loss: 1.794824242591858
Validation loss: 1.9212067178500596

Epoch: 5| Step: 1
Training loss: 2.1420764923095703
Validation loss: 1.9013471731575586

Epoch: 5| Step: 2
Training loss: 2.1526248455047607
Validation loss: 1.9208759979535175

Epoch: 5| Step: 3
Training loss: 1.8155618906021118
Validation loss: 1.8979255691651375

Epoch: 5| Step: 4
Training loss: 2.1373190879821777
Validation loss: 1.9008773501201341

Epoch: 5| Step: 5
Training loss: 2.7597029209136963
Validation loss: 1.9087152686170352

Epoch: 5| Step: 6
Training loss: 2.0025668144226074
Validation loss: 1.8982871911859

Epoch: 5| Step: 7
Training loss: 2.125500202178955
Validation loss: 1.9086831949090446

Epoch: 5| Step: 8
Training loss: 2.4422454833984375
Validation loss: 1.8946774749345676

Epoch: 5| Step: 9
Training loss: 2.40329647064209
Validation loss: 1.9006174623325307

Epoch: 5| Step: 10
Training loss: 1.528302788734436
Validation loss: 1.9174364946221794

Epoch: 111| Step: 0
Training loss: 2.270939350128174
Validation loss: 1.9041535123702018

Epoch: 5| Step: 1
Training loss: 1.6862903833389282
Validation loss: 1.8910040599043652

Epoch: 5| Step: 2
Training loss: 2.215745687484741
Validation loss: 1.9166306449520973

Epoch: 5| Step: 3
Training loss: 2.390982151031494
Validation loss: 1.8821213809392785

Epoch: 5| Step: 4
Training loss: 2.330357074737549
Validation loss: 1.9019675921368342

Epoch: 5| Step: 5
Training loss: 1.9972158670425415
Validation loss: 1.9118005857672742

Epoch: 5| Step: 6
Training loss: 2.339754104614258
Validation loss: 1.9141181848382438

Epoch: 5| Step: 7
Training loss: 1.8327147960662842
Validation loss: 1.9365081428199686

Epoch: 5| Step: 8
Training loss: 2.302311897277832
Validation loss: 1.9457456091398835

Epoch: 5| Step: 9
Training loss: 2.1932640075683594
Validation loss: 1.9134269465682328

Epoch: 5| Step: 10
Training loss: 1.957879662513733
Validation loss: 1.9095811972054102

Epoch: 112| Step: 0
Training loss: 2.5196380615234375
Validation loss: 1.8979758934308124

Epoch: 5| Step: 1
Training loss: 2.953610420227051
Validation loss: 1.9235848457582536

Epoch: 5| Step: 2
Training loss: 2.708686351776123
Validation loss: 1.90774275923288

Epoch: 5| Step: 3
Training loss: 2.06447172164917
Validation loss: 1.9201110947516657

Epoch: 5| Step: 4
Training loss: 1.9619452953338623
Validation loss: 1.9268170838714929

Epoch: 5| Step: 5
Training loss: 1.5168819427490234
Validation loss: 1.9471414909567883

Epoch: 5| Step: 6
Training loss: 1.7379461526870728
Validation loss: 1.944128236462993

Epoch: 5| Step: 7
Training loss: 2.357805013656616
Validation loss: 1.9331327202499553

Epoch: 5| Step: 8
Training loss: 1.6227824687957764
Validation loss: 1.9304737224373767

Epoch: 5| Step: 9
Training loss: 1.7819019556045532
Validation loss: 1.9330798336254653

Epoch: 5| Step: 10
Training loss: 2.16676926612854
Validation loss: 1.9246875765503093

Epoch: 113| Step: 0
Training loss: 1.8797767162322998
Validation loss: 1.9183775250629713

Epoch: 5| Step: 1
Training loss: 2.2803823947906494
Validation loss: 1.9251569189051145

Epoch: 5| Step: 2
Training loss: 1.7993402481079102
Validation loss: 1.9198009942167549

Epoch: 5| Step: 3
Training loss: 2.2486579418182373
Validation loss: 1.908953829478192

Epoch: 5| Step: 4
Training loss: 2.1339428424835205
Validation loss: 1.9051904896254181

Epoch: 5| Step: 5
Training loss: 1.8280029296875
Validation loss: 1.904297395419049

Epoch: 5| Step: 6
Training loss: 2.2664763927459717
Validation loss: 1.9069145828165033

Epoch: 5| Step: 7
Training loss: 1.4044231176376343
Validation loss: 1.8970744661105576

Epoch: 5| Step: 8
Training loss: 2.7116012573242188
Validation loss: 1.8830354957170383

Epoch: 5| Step: 9
Training loss: 2.448617458343506
Validation loss: 1.893522101063882

Epoch: 5| Step: 10
Training loss: 2.4232892990112305
Validation loss: 1.890472335200156

Epoch: 114| Step: 0
Training loss: 2.227853775024414
Validation loss: 1.8874176138190812

Epoch: 5| Step: 1
Training loss: 2.2801225185394287
Validation loss: 1.8972930882566719

Epoch: 5| Step: 2
Training loss: 1.9002805948257446
Validation loss: 1.902185183699413

Epoch: 5| Step: 3
Training loss: 2.5059664249420166
Validation loss: 1.888535681591239

Epoch: 5| Step: 4
Training loss: 2.633910655975342
Validation loss: 1.8967234908893544

Epoch: 5| Step: 5
Training loss: 1.622427225112915
Validation loss: 1.89423543278889

Epoch: 5| Step: 6
Training loss: 2.1437952518463135
Validation loss: 1.90141059378142

Epoch: 5| Step: 7
Training loss: 2.2393851280212402
Validation loss: 1.8896329044013895

Epoch: 5| Step: 8
Training loss: 1.865830659866333
Validation loss: 1.912910230698124

Epoch: 5| Step: 9
Training loss: 1.8253120183944702
Validation loss: 1.9004076398828977

Epoch: 5| Step: 10
Training loss: 2.0550949573516846
Validation loss: 1.9203021757064327

Epoch: 115| Step: 0
Training loss: 2.041259288787842
Validation loss: 1.9134528431841122

Epoch: 5| Step: 1
Training loss: 2.5845961570739746
Validation loss: 1.8973475502383323

Epoch: 5| Step: 2
Training loss: 1.9572290182113647
Validation loss: 1.9144615768104472

Epoch: 5| Step: 3
Training loss: 2.2223339080810547
Validation loss: 1.9239013297583467

Epoch: 5| Step: 4
Training loss: 2.081435441970825
Validation loss: 1.905324714158171

Epoch: 5| Step: 5
Training loss: 2.0653510093688965
Validation loss: 1.9070072891891643

Epoch: 5| Step: 6
Training loss: 2.9215407371520996
Validation loss: 1.9038534946339105

Epoch: 5| Step: 7
Training loss: 1.292648196220398
Validation loss: 1.9190315328618532

Epoch: 5| Step: 8
Training loss: 1.9286315441131592
Validation loss: 1.9219278238152946

Epoch: 5| Step: 9
Training loss: 2.494018077850342
Validation loss: 1.9056483519974576

Epoch: 5| Step: 10
Training loss: 1.5584315061569214
Validation loss: 1.9208494386365336

Epoch: 116| Step: 0
Training loss: 2.140270948410034
Validation loss: 1.925645689810476

Epoch: 5| Step: 1
Training loss: 2.1565749645233154
Validation loss: 1.9130597294017833

Epoch: 5| Step: 2
Training loss: 2.078557014465332
Validation loss: 1.9055427287214546

Epoch: 5| Step: 3
Training loss: 1.5903334617614746
Validation loss: 1.9051821680479153

Epoch: 5| Step: 4
Training loss: 1.9932581186294556
Validation loss: 1.923652151579498

Epoch: 5| Step: 5
Training loss: 2.0252020359039307
Validation loss: 1.9068015057553527

Epoch: 5| Step: 6
Training loss: 2.65203857421875
Validation loss: 1.9078185122500184

Epoch: 5| Step: 7
Training loss: 2.226555347442627
Validation loss: 1.9188630965448195

Epoch: 5| Step: 8
Training loss: 2.1289114952087402
Validation loss: 1.9208486349351945

Epoch: 5| Step: 9
Training loss: 1.6066038608551025
Validation loss: 1.9231000907959477

Epoch: 5| Step: 10
Training loss: 2.7429206371307373
Validation loss: 1.9129851300229308

Epoch: 117| Step: 0
Training loss: 1.7438163757324219
Validation loss: 1.907881716246246

Epoch: 5| Step: 1
Training loss: 3.108095645904541
Validation loss: 1.8984820894015733

Epoch: 5| Step: 2
Training loss: 1.7372900247573853
Validation loss: 1.9177089198943107

Epoch: 5| Step: 3
Training loss: 2.088838577270508
Validation loss: 1.9008516252681773

Epoch: 5| Step: 4
Training loss: 2.37947154045105
Validation loss: 1.90716492232456

Epoch: 5| Step: 5
Training loss: 1.5869300365447998
Validation loss: 1.908863757246284

Epoch: 5| Step: 6
Training loss: 1.9735727310180664
Validation loss: 1.8948408006339945

Epoch: 5| Step: 7
Training loss: 1.9510180950164795
Validation loss: 1.9195471284210042

Epoch: 5| Step: 8
Training loss: 2.3422610759735107
Validation loss: 1.9093868091542234

Epoch: 5| Step: 9
Training loss: 2.2260401248931885
Validation loss: 1.9105630408051193

Epoch: 5| Step: 10
Training loss: 2.0573902130126953
Validation loss: 1.8906406446169781

Epoch: 118| Step: 0
Training loss: 2.2535862922668457
Validation loss: 1.9057435720197615

Epoch: 5| Step: 1
Training loss: 1.4873392581939697
Validation loss: 1.9040798256474156

Epoch: 5| Step: 2
Training loss: 1.8568748235702515
Validation loss: 1.9232908307865102

Epoch: 5| Step: 3
Training loss: 2.221980571746826
Validation loss: 1.9225518754733506

Epoch: 5| Step: 4
Training loss: 1.5346170663833618
Validation loss: 1.908201894452495

Epoch: 5| Step: 5
Training loss: 2.690250873565674
Validation loss: 1.927153036158572

Epoch: 5| Step: 6
Training loss: 1.9927465915679932
Validation loss: 1.903132664260044

Epoch: 5| Step: 7
Training loss: 2.374284505844116
Validation loss: 1.9275484341447071

Epoch: 5| Step: 8
Training loss: 1.9220597743988037
Validation loss: 1.902513123327686

Epoch: 5| Step: 9
Training loss: 2.872795820236206
Validation loss: 1.9008903926418674

Epoch: 5| Step: 10
Training loss: 2.0118887424468994
Validation loss: 1.9110173179257302

Epoch: 119| Step: 0
Training loss: 2.2677178382873535
Validation loss: 1.9048109349384104

Epoch: 5| Step: 1
Training loss: 1.8239109516143799
Validation loss: 1.8949920644042313

Epoch: 5| Step: 2
Training loss: 1.7894432544708252
Validation loss: 1.9021366975640739

Epoch: 5| Step: 3
Training loss: 2.1398849487304688
Validation loss: 1.9135247199766097

Epoch: 5| Step: 4
Training loss: 2.022801637649536
Validation loss: 1.8831245386472313

Epoch: 5| Step: 5
Training loss: 2.031013011932373
Validation loss: 1.90954166330317

Epoch: 5| Step: 6
Training loss: 2.0703513622283936
Validation loss: 1.8906673923615487

Epoch: 5| Step: 7
Training loss: 2.4251983165740967
Validation loss: 1.9019368861311226

Epoch: 5| Step: 8
Training loss: 2.62024188041687
Validation loss: 1.9046475374570457

Epoch: 5| Step: 9
Training loss: 2.6246471405029297
Validation loss: 1.8887960077613912

Epoch: 5| Step: 10
Training loss: 1.332437515258789
Validation loss: 1.8876442716967674

Epoch: 120| Step: 0
Training loss: 2.7469229698181152
Validation loss: 1.8747824289465462

Epoch: 5| Step: 1
Training loss: 2.178192615509033
Validation loss: 1.880415048650516

Epoch: 5| Step: 2
Training loss: 1.9373321533203125
Validation loss: 1.9001676139011179

Epoch: 5| Step: 3
Training loss: 2.4790761470794678
Validation loss: 1.8903180719703756

Epoch: 5| Step: 4
Training loss: 1.9465748071670532
Validation loss: 1.89650095534581

Epoch: 5| Step: 5
Training loss: 1.6171760559082031
Validation loss: 1.8965201634232716

Epoch: 5| Step: 6
Training loss: 1.8100898265838623
Validation loss: 1.8991426011567474

Epoch: 5| Step: 7
Training loss: 2.3120357990264893
Validation loss: 1.8852985494880266

Epoch: 5| Step: 8
Training loss: 1.525342345237732
Validation loss: 1.900231356261879

Epoch: 5| Step: 9
Training loss: 2.5478131771087646
Validation loss: 1.8885870441313712

Epoch: 5| Step: 10
Training loss: 2.028726577758789
Validation loss: 1.9066774896396104

Epoch: 121| Step: 0
Training loss: 2.332430601119995
Validation loss: 1.9003440410860124

Epoch: 5| Step: 1
Training loss: 1.8089702129364014
Validation loss: 1.8974570587117185

Epoch: 5| Step: 2
Training loss: 2.1716315746307373
Validation loss: 1.9035302195497739

Epoch: 5| Step: 3
Training loss: 1.2713428735733032
Validation loss: 1.9015798696907618

Epoch: 5| Step: 4
Training loss: 1.7176660299301147
Validation loss: 1.8932065117743708

Epoch: 5| Step: 5
Training loss: 2.2917070388793945
Validation loss: 1.8959476922148017

Epoch: 5| Step: 6
Training loss: 2.2306880950927734
Validation loss: 1.904570500055949

Epoch: 5| Step: 7
Training loss: 1.690630316734314
Validation loss: 1.8927307462179532

Epoch: 5| Step: 8
Training loss: 2.3024065494537354
Validation loss: 1.9082342334972915

Epoch: 5| Step: 9
Training loss: 2.470930814743042
Validation loss: 1.9056605074995308

Epoch: 5| Step: 10
Training loss: 2.9265780448913574
Validation loss: 1.9029700717618387

Epoch: 122| Step: 0
Training loss: 2.514159679412842
Validation loss: 1.9055003901963592

Epoch: 5| Step: 1
Training loss: 1.6615180969238281
Validation loss: 1.9178580904519686

Epoch: 5| Step: 2
Training loss: 2.2884819507598877
Validation loss: 1.919840379427838

Epoch: 5| Step: 3
Training loss: 2.2544984817504883
Validation loss: 1.9084951082865398

Epoch: 5| Step: 4
Training loss: 1.8644241094589233
Validation loss: 1.9027577292534612

Epoch: 5| Step: 5
Training loss: 1.966413140296936
Validation loss: 1.910742732786363

Epoch: 5| Step: 6
Training loss: 1.499603033065796
Validation loss: 1.9098441293162685

Epoch: 5| Step: 7
Training loss: 1.97048819065094
Validation loss: 1.8998221556345622

Epoch: 5| Step: 8
Training loss: 2.5968780517578125
Validation loss: 1.9059751892602572

Epoch: 5| Step: 9
Training loss: 1.9408317804336548
Validation loss: 1.9008719472474949

Epoch: 5| Step: 10
Training loss: 2.6583516597747803
Validation loss: 1.9144344252924765

Epoch: 123| Step: 0
Training loss: 2.5045101642608643
Validation loss: 1.8930537700653076

Epoch: 5| Step: 1
Training loss: 2.037886142730713
Validation loss: 1.9169572540508804

Epoch: 5| Step: 2
Training loss: 1.7595231533050537
Validation loss: 1.8976121974247757

Epoch: 5| Step: 3
Training loss: 2.2028491497039795
Validation loss: 1.9140539861494494

Epoch: 5| Step: 4
Training loss: 1.5386741161346436
Validation loss: 1.9299367089425363

Epoch: 5| Step: 5
Training loss: 1.6242605447769165
Validation loss: 1.901009436576597

Epoch: 5| Step: 6
Training loss: 2.4672820568084717
Validation loss: 1.900030533472697

Epoch: 5| Step: 7
Training loss: 2.0013070106506348
Validation loss: 1.9093969265619914

Epoch: 5| Step: 8
Training loss: 2.012169361114502
Validation loss: 1.9138240480935702

Epoch: 5| Step: 9
Training loss: 2.972726821899414
Validation loss: 1.9001276390526884

Epoch: 5| Step: 10
Training loss: 1.8360732793807983
Validation loss: 1.9152142617010302

Epoch: 124| Step: 0
Training loss: 2.4418370723724365
Validation loss: 1.9172660766109344

Epoch: 5| Step: 1
Training loss: 2.1923015117645264
Validation loss: 1.9072228606029222

Epoch: 5| Step: 2
Training loss: 2.0593042373657227
Validation loss: 1.922503500856379

Epoch: 5| Step: 3
Training loss: 2.547384262084961
Validation loss: 1.9204799077844108

Epoch: 5| Step: 4
Training loss: 2.030306339263916
Validation loss: 1.9049545436777093

Epoch: 5| Step: 5
Training loss: 2.3458797931671143
Validation loss: 1.9091407227259811

Epoch: 5| Step: 6
Training loss: 1.5928980112075806
Validation loss: 1.9116095445489372

Epoch: 5| Step: 7
Training loss: 1.1868869066238403
Validation loss: 1.9016554637621808

Epoch: 5| Step: 8
Training loss: 1.9061005115509033
Validation loss: 1.907597190590315

Epoch: 5| Step: 9
Training loss: 2.58522367477417
Validation loss: 1.9101558808357484

Epoch: 5| Step: 10
Training loss: 1.9751901626586914
Validation loss: 1.9246359614915745

Epoch: 125| Step: 0
Training loss: 2.2481637001037598
Validation loss: 1.91058393960358

Epoch: 5| Step: 1
Training loss: 1.9381099939346313
Validation loss: 1.9116819366332023

Epoch: 5| Step: 2
Training loss: 2.013671636581421
Validation loss: 1.9201219940698275

Epoch: 5| Step: 3
Training loss: 1.408873200416565
Validation loss: 1.9236209572002452

Epoch: 5| Step: 4
Training loss: 2.2288477420806885
Validation loss: 1.9108077915765906

Epoch: 5| Step: 5
Training loss: 2.671278476715088
Validation loss: 1.9241709170802948

Epoch: 5| Step: 6
Training loss: 1.9823417663574219
Validation loss: 1.9245951649963216

Epoch: 5| Step: 7
Training loss: 2.6489481925964355
Validation loss: 1.9163330934380973

Epoch: 5| Step: 8
Training loss: 1.7746837139129639
Validation loss: 1.9187538418718564

Epoch: 5| Step: 9
Training loss: 1.9921916723251343
Validation loss: 1.9277918492594073

Epoch: 5| Step: 10
Training loss: 2.1681644916534424
Validation loss: 1.9189076936373146

Epoch: 126| Step: 0
Training loss: 2.097632884979248
Validation loss: 1.9241430054428756

Epoch: 5| Step: 1
Training loss: 2.188598394393921
Validation loss: 1.9200639647822226

Epoch: 5| Step: 2
Training loss: 2.5462145805358887
Validation loss: 1.9233988267119213

Epoch: 5| Step: 3
Training loss: 1.9455339908599854
Validation loss: 1.9187702773719706

Epoch: 5| Step: 4
Training loss: 1.5493885278701782
Validation loss: 1.9269544411731023

Epoch: 5| Step: 5
Training loss: 2.1366727352142334
Validation loss: 1.934470970143554

Epoch: 5| Step: 6
Training loss: 2.3049283027648926
Validation loss: 1.901952685848359

Epoch: 5| Step: 7
Training loss: 2.0651063919067383
Validation loss: 1.913422643497426

Epoch: 5| Step: 8
Training loss: 2.024686098098755
Validation loss: 1.9180453631185717

Epoch: 5| Step: 9
Training loss: 1.894506812095642
Validation loss: 1.9087001021190355

Epoch: 5| Step: 10
Training loss: 2.2605767250061035
Validation loss: 1.9116692094392673

Epoch: 127| Step: 0
Training loss: 2.511772394180298
Validation loss: 1.9042248238799393

Epoch: 5| Step: 1
Training loss: 1.669878363609314
Validation loss: 1.9182861902380501

Epoch: 5| Step: 2
Training loss: 2.2256622314453125
Validation loss: 1.9283287063721688

Epoch: 5| Step: 3
Training loss: 1.9370982646942139
Validation loss: 1.9262604803167365

Epoch: 5| Step: 4
Training loss: 2.4571421146392822
Validation loss: 1.9438925802066762

Epoch: 5| Step: 5
Training loss: 1.9318681955337524
Validation loss: 1.9222775787435553

Epoch: 5| Step: 6
Training loss: 2.032536268234253
Validation loss: 1.9179045987385575

Epoch: 5| Step: 7
Training loss: 1.4172743558883667
Validation loss: 1.9326152083694295

Epoch: 5| Step: 8
Training loss: 1.9466034173965454
Validation loss: 1.922434256922814

Epoch: 5| Step: 9
Training loss: 2.688530206680298
Validation loss: 1.9481101741072953

Epoch: 5| Step: 10
Training loss: 2.0685160160064697
Validation loss: 1.9256070634370208

Epoch: 128| Step: 0
Training loss: 2.0247128009796143
Validation loss: 1.9368840750827585

Epoch: 5| Step: 1
Training loss: 2.015005350112915
Validation loss: 1.9069021799231087

Epoch: 5| Step: 2
Training loss: 1.682638168334961
Validation loss: 1.9015160376025784

Epoch: 5| Step: 3
Training loss: 1.8635547161102295
Validation loss: 1.9040447999072332

Epoch: 5| Step: 4
Training loss: 2.1220128536224365
Validation loss: 1.9134816354320896

Epoch: 5| Step: 5
Training loss: 2.668741464614868
Validation loss: 1.8995203074588571

Epoch: 5| Step: 6
Training loss: 1.8704001903533936
Validation loss: 1.9036443259126397

Epoch: 5| Step: 7
Training loss: 1.9848123788833618
Validation loss: 1.9131685315921743

Epoch: 5| Step: 8
Training loss: 1.9114296436309814
Validation loss: 1.9014044525802776

Epoch: 5| Step: 9
Training loss: 2.035546064376831
Validation loss: 1.9107049357506536

Epoch: 5| Step: 10
Training loss: 2.7847728729248047
Validation loss: 1.8996126241581415

Epoch: 129| Step: 0
Training loss: 1.7186152935028076
Validation loss: 1.9016552176526798

Epoch: 5| Step: 1
Training loss: 1.9193271398544312
Validation loss: 1.905773017996101

Epoch: 5| Step: 2
Training loss: 1.9322773218154907
Validation loss: 1.906965119864351

Epoch: 5| Step: 3
Training loss: 2.208900213241577
Validation loss: 1.911433982592757

Epoch: 5| Step: 4
Training loss: 2.010789632797241
Validation loss: 1.9106117884318035

Epoch: 5| Step: 5
Training loss: 2.0288665294647217
Validation loss: 1.910535180440513

Epoch: 5| Step: 6
Training loss: 2.2833409309387207
Validation loss: 1.901022323998072

Epoch: 5| Step: 7
Training loss: 2.366004705429077
Validation loss: 1.906960533511254

Epoch: 5| Step: 8
Training loss: 2.0955705642700195
Validation loss: 1.915495140578157

Epoch: 5| Step: 9
Training loss: 2.173867702484131
Validation loss: 1.9043356526282527

Epoch: 5| Step: 10
Training loss: 2.255070209503174
Validation loss: 1.9152959931281306

Epoch: 130| Step: 0
Training loss: 2.976998805999756
Validation loss: 1.9102880006195397

Epoch: 5| Step: 1
Training loss: 1.9311683177947998
Validation loss: 1.8940339216621973

Epoch: 5| Step: 2
Training loss: 2.396395206451416
Validation loss: 1.9213920383043186

Epoch: 5| Step: 3
Training loss: 1.6934137344360352
Validation loss: 1.9234381593683714

Epoch: 5| Step: 4
Training loss: 1.934289574623108
Validation loss: 1.9052282789702057

Epoch: 5| Step: 5
Training loss: 1.9343570470809937
Validation loss: 1.9199653030723653

Epoch: 5| Step: 6
Training loss: 1.7603809833526611
Validation loss: 1.9086395463635843

Epoch: 5| Step: 7
Training loss: 1.9888784885406494
Validation loss: 1.907014508401194

Epoch: 5| Step: 8
Training loss: 2.369616985321045
Validation loss: 1.9093369501893238

Epoch: 5| Step: 9
Training loss: 1.896466851234436
Validation loss: 1.9088416471276233

Epoch: 5| Step: 10
Training loss: 1.8551231622695923
Validation loss: 1.905843695004781

Epoch: 131| Step: 0
Training loss: 1.297196626663208
Validation loss: 1.9093505720938406

Epoch: 5| Step: 1
Training loss: 1.9182571172714233
Validation loss: 1.9092265777690436

Epoch: 5| Step: 2
Training loss: 2.507112979888916
Validation loss: 1.9005493066644157

Epoch: 5| Step: 3
Training loss: 2.508023500442505
Validation loss: 1.9019986455158522

Epoch: 5| Step: 4
Training loss: 2.289263963699341
Validation loss: 1.9015253551544682

Epoch: 5| Step: 5
Training loss: 2.102403163909912
Validation loss: 1.8915444586866645

Epoch: 5| Step: 6
Training loss: 2.178196907043457
Validation loss: 1.8967906582740046

Epoch: 5| Step: 7
Training loss: 2.011788845062256
Validation loss: 1.8990512496681624

Epoch: 5| Step: 8
Training loss: 2.258413553237915
Validation loss: 1.900695159871091

Epoch: 5| Step: 9
Training loss: 2.195225477218628
Validation loss: 1.9193311147792365

Epoch: 5| Step: 10
Training loss: 1.535247564315796
Validation loss: 1.8935335297738352

Epoch: 132| Step: 0
Training loss: 1.6668779850006104
Validation loss: 1.908784653550835

Epoch: 5| Step: 1
Training loss: 2.678173780441284
Validation loss: 1.8964268789496472

Epoch: 5| Step: 2
Training loss: 1.896490454673767
Validation loss: 1.9173827248234903

Epoch: 5| Step: 3
Training loss: 2.040968894958496
Validation loss: 1.9042066579223962

Epoch: 5| Step: 4
Training loss: 2.0629372596740723
Validation loss: 1.9035319359071794

Epoch: 5| Step: 5
Training loss: 1.7494456768035889
Validation loss: 1.8959207124607538

Epoch: 5| Step: 6
Training loss: 2.0438525676727295
Validation loss: 1.8913678353832615

Epoch: 5| Step: 7
Training loss: 2.1813387870788574
Validation loss: 1.9057446352897152

Epoch: 5| Step: 8
Training loss: 2.440207004547119
Validation loss: 1.9075061441749654

Epoch: 5| Step: 9
Training loss: 2.386852264404297
Validation loss: 1.8954262836005098

Epoch: 5| Step: 10
Training loss: 1.5024480819702148
Validation loss: 1.917299473157493

Epoch: 133| Step: 0
Training loss: 2.125699520111084
Validation loss: 1.9063610838305565

Epoch: 5| Step: 1
Training loss: 2.380746364593506
Validation loss: 1.8991237173798263

Epoch: 5| Step: 2
Training loss: 2.294856548309326
Validation loss: 1.8893429489545925

Epoch: 5| Step: 3
Training loss: 1.6769402027130127
Validation loss: 1.9183547701886905

Epoch: 5| Step: 4
Training loss: 1.702136754989624
Validation loss: 1.9353293885466873

Epoch: 5| Step: 5
Training loss: 2.4479689598083496
Validation loss: 1.9209028059436428

Epoch: 5| Step: 6
Training loss: 1.558012843132019
Validation loss: 1.8987377894821988

Epoch: 5| Step: 7
Training loss: 1.6592328548431396
Validation loss: 1.8912681712899158

Epoch: 5| Step: 8
Training loss: 2.419947862625122
Validation loss: 1.9157521673428115

Epoch: 5| Step: 9
Training loss: 1.9670217037200928
Validation loss: 1.9065809224241523

Epoch: 5| Step: 10
Training loss: 2.562256336212158
Validation loss: 1.9170505218608405

Epoch: 134| Step: 0
Training loss: 2.162609577178955
Validation loss: 1.8920647610900223

Epoch: 5| Step: 1
Training loss: 1.7184035778045654
Validation loss: 1.9164592501937703

Epoch: 5| Step: 2
Training loss: 2.459489583969116
Validation loss: 1.8856300782131892

Epoch: 5| Step: 3
Training loss: 2.366537094116211
Validation loss: 1.9009693002188077

Epoch: 5| Step: 4
Training loss: 2.0625643730163574
Validation loss: 1.9149127801259358

Epoch: 5| Step: 5
Training loss: 1.6242992877960205
Validation loss: 1.902152922845656

Epoch: 5| Step: 6
Training loss: 1.5626215934753418
Validation loss: 1.9350217580795288

Epoch: 5| Step: 7
Training loss: 2.093217372894287
Validation loss: 1.9005199119608889

Epoch: 5| Step: 8
Training loss: 2.3111605644226074
Validation loss: 1.8790134909332439

Epoch: 5| Step: 9
Training loss: 2.1327967643737793
Validation loss: 1.9137877828331404

Epoch: 5| Step: 10
Training loss: 2.125269889831543
Validation loss: 1.8988447881514026

Epoch: 135| Step: 0
Training loss: 2.315391778945923
Validation loss: 1.8969730292597125

Epoch: 5| Step: 1
Training loss: 1.614871621131897
Validation loss: 1.9209801778998425

Epoch: 5| Step: 2
Training loss: 2.3426408767700195
Validation loss: 1.9047650739710817

Epoch: 5| Step: 3
Training loss: 2.2121987342834473
Validation loss: 1.9055790273092126

Epoch: 5| Step: 4
Training loss: 1.6194206476211548
Validation loss: 1.8942661669946486

Epoch: 5| Step: 5
Training loss: 1.7943538427352905
Validation loss: 1.8926410264866327

Epoch: 5| Step: 6
Training loss: 1.9474328756332397
Validation loss: 1.8919831129812426

Epoch: 5| Step: 7
Training loss: 2.3128137588500977
Validation loss: 1.9104078790192962

Epoch: 5| Step: 8
Training loss: 2.506894588470459
Validation loss: 1.8983505233641593

Epoch: 5| Step: 9
Training loss: 1.6245040893554688
Validation loss: 1.8996354059506488

Epoch: 5| Step: 10
Training loss: 2.275806188583374
Validation loss: 1.8855885882531442

Epoch: 136| Step: 0
Training loss: 1.4790866374969482
Validation loss: 1.8988514113169845

Epoch: 5| Step: 1
Training loss: 2.115525722503662
Validation loss: 1.8956485627799906

Epoch: 5| Step: 2
Training loss: 2.503370761871338
Validation loss: 1.8948815202200284

Epoch: 5| Step: 3
Training loss: 1.5678997039794922
Validation loss: 1.8779279916517195

Epoch: 5| Step: 4
Training loss: 1.8467897176742554
Validation loss: 1.9132375050616521

Epoch: 5| Step: 5
Training loss: 1.9350526332855225
Validation loss: 1.9032929866544661

Epoch: 5| Step: 6
Training loss: 2.442161798477173
Validation loss: 1.8831939440901562

Epoch: 5| Step: 7
Training loss: 2.2411694526672363
Validation loss: 1.8863994459952078

Epoch: 5| Step: 8
Training loss: 2.4059648513793945
Validation loss: 1.8916705218694543

Epoch: 5| Step: 9
Training loss: 2.0751914978027344
Validation loss: 1.893127082496561

Epoch: 5| Step: 10
Training loss: 1.871741771697998
Validation loss: 1.8809071458796018

Epoch: 137| Step: 0
Training loss: 2.230635166168213
Validation loss: 1.9049546205869285

Epoch: 5| Step: 1
Training loss: 1.778072714805603
Validation loss: 1.8926706314086914

Epoch: 5| Step: 2
Training loss: 2.3822898864746094
Validation loss: 1.9098516818015807

Epoch: 5| Step: 3
Training loss: 1.834573745727539
Validation loss: 1.9033741117805563

Epoch: 5| Step: 4
Training loss: 1.9414522647857666
Validation loss: 1.8825011612266622

Epoch: 5| Step: 5
Training loss: 2.01039719581604
Validation loss: 1.8930811087290447

Epoch: 5| Step: 6
Training loss: 2.1707475185394287
Validation loss: 1.8771391478917931

Epoch: 5| Step: 7
Training loss: 2.1267459392547607
Validation loss: 1.8913504462088309

Epoch: 5| Step: 8
Training loss: 1.7256643772125244
Validation loss: 1.8921098350196757

Epoch: 5| Step: 9
Training loss: 1.809827446937561
Validation loss: 1.8943346290178196

Epoch: 5| Step: 10
Training loss: 2.874760389328003
Validation loss: 1.8845272525664298

Epoch: 138| Step: 0
Training loss: 1.8850170373916626
Validation loss: 1.895255260570075

Epoch: 5| Step: 1
Training loss: 2.604034900665283
Validation loss: 1.8774489048988587

Epoch: 5| Step: 2
Training loss: 2.312623977661133
Validation loss: 1.8999509644764725

Epoch: 5| Step: 3
Training loss: 1.9485546350479126
Validation loss: 1.9032460156307425

Epoch: 5| Step: 4
Training loss: 1.7808425426483154
Validation loss: 1.8829200139609716

Epoch: 5| Step: 5
Training loss: 2.0023434162139893
Validation loss: 1.9019066595262097

Epoch: 5| Step: 6
Training loss: 2.285522937774658
Validation loss: 1.8906805233288837

Epoch: 5| Step: 7
Training loss: 1.2823494672775269
Validation loss: 1.9096375255174534

Epoch: 5| Step: 8
Training loss: 2.297760486602783
Validation loss: 1.90747735961791

Epoch: 5| Step: 9
Training loss: 2.0662214756011963
Validation loss: 1.914919464818893

Epoch: 5| Step: 10
Training loss: 1.9398696422576904
Validation loss: 1.9100730778068624

Epoch: 139| Step: 0
Training loss: 2.0657131671905518
Validation loss: 1.9222261239123601

Epoch: 5| Step: 1
Training loss: 1.6984260082244873
Validation loss: 1.917403640285615

Epoch: 5| Step: 2
Training loss: 2.586956739425659
Validation loss: 1.9139890106775428

Epoch: 5| Step: 3
Training loss: 2.363067626953125
Validation loss: 1.9165052649795369

Epoch: 5| Step: 4
Training loss: 1.4862110614776611
Validation loss: 1.9190353449954782

Epoch: 5| Step: 5
Training loss: 2.07708740234375
Validation loss: 1.9129800335053475

Epoch: 5| Step: 6
Training loss: 2.204207181930542
Validation loss: 1.940527601908612

Epoch: 5| Step: 7
Training loss: 1.797846794128418
Validation loss: 1.9148318408637919

Epoch: 5| Step: 8
Training loss: 2.613471508026123
Validation loss: 1.932856903281263

Epoch: 5| Step: 9
Training loss: 1.8468878269195557
Validation loss: 1.9192989846711517

Epoch: 5| Step: 10
Training loss: 1.5246648788452148
Validation loss: 1.9145014593678136

Epoch: 140| Step: 0
Training loss: 2.1255385875701904
Validation loss: 1.8998108461338987

Epoch: 5| Step: 1
Training loss: 1.9226652383804321
Validation loss: 1.9259203659590853

Epoch: 5| Step: 2
Training loss: 1.4747986793518066
Validation loss: 1.9361387170771116

Epoch: 5| Step: 3
Training loss: 2.623195171356201
Validation loss: 1.8942048767561555

Epoch: 5| Step: 4
Training loss: 2.058354377746582
Validation loss: 1.8941502391651113

Epoch: 5| Step: 5
Training loss: 1.3435884714126587
Validation loss: 1.9040906890746085

Epoch: 5| Step: 6
Training loss: 1.7438313961029053
Validation loss: 1.8936252414539296

Epoch: 5| Step: 7
Training loss: 2.22340726852417
Validation loss: 1.8830606437498523

Epoch: 5| Step: 8
Training loss: 2.244732141494751
Validation loss: 1.8928597537420129

Epoch: 5| Step: 9
Training loss: 2.493964433670044
Validation loss: 1.9034216147597118

Epoch: 5| Step: 10
Training loss: 2.127743721008301
Validation loss: 1.9082916346929406

Epoch: 141| Step: 0
Training loss: 1.8463115692138672
Validation loss: 1.8972080779331986

Epoch: 5| Step: 1
Training loss: 2.0261459350585938
Validation loss: 1.8910230923724431

Epoch: 5| Step: 2
Training loss: 2.413191556930542
Validation loss: 1.8987988951385661

Epoch: 5| Step: 3
Training loss: 2.186527729034424
Validation loss: 1.8975294123413742

Epoch: 5| Step: 4
Training loss: 2.1574833393096924
Validation loss: 1.9091611882691741

Epoch: 5| Step: 5
Training loss: 1.6255371570587158
Validation loss: 1.8827092032278738

Epoch: 5| Step: 6
Training loss: 2.001303195953369
Validation loss: 1.8965738883582495

Epoch: 5| Step: 7
Training loss: 1.8477106094360352
Validation loss: 1.8861328414691392

Epoch: 5| Step: 8
Training loss: 1.617916464805603
Validation loss: 1.9168048891969907

Epoch: 5| Step: 9
Training loss: 2.176358699798584
Validation loss: 1.9041614340197655

Epoch: 5| Step: 10
Training loss: 2.6801953315734863
Validation loss: 1.9110214787144815

Epoch: 142| Step: 0
Training loss: 2.4568278789520264
Validation loss: 1.9186479699227117

Epoch: 5| Step: 1
Training loss: 2.0124664306640625
Validation loss: 1.899871632617007

Epoch: 5| Step: 2
Training loss: 2.4020230770111084
Validation loss: 1.887913091208345

Epoch: 5| Step: 3
Training loss: 2.6640353202819824
Validation loss: 1.8983940360366658

Epoch: 5| Step: 4
Training loss: 2.029996156692505
Validation loss: 1.887831667418121

Epoch: 5| Step: 5
Training loss: 1.5147950649261475
Validation loss: 1.8917895863133092

Epoch: 5| Step: 6
Training loss: 1.9040085077285767
Validation loss: 1.8925306450936101

Epoch: 5| Step: 7
Training loss: 1.7265608310699463
Validation loss: 1.871206606588056

Epoch: 5| Step: 8
Training loss: 1.6384029388427734
Validation loss: 1.8957364533537178

Epoch: 5| Step: 9
Training loss: 1.874455213546753
Validation loss: 1.8766476031272643

Epoch: 5| Step: 10
Training loss: 2.2134909629821777
Validation loss: 1.8946839622271958

Epoch: 143| Step: 0
Training loss: 2.034210681915283
Validation loss: 1.886829532602782

Epoch: 5| Step: 1
Training loss: 1.6496250629425049
Validation loss: 1.8891181920164375

Epoch: 5| Step: 2
Training loss: 2.587686061859131
Validation loss: 1.8843950417733961

Epoch: 5| Step: 3
Training loss: 2.3809869289398193
Validation loss: 1.877476966509255

Epoch: 5| Step: 4
Training loss: 2.2300446033477783
Validation loss: 1.8703990162059825

Epoch: 5| Step: 5
Training loss: 1.5653817653656006
Validation loss: 1.8822165958343013

Epoch: 5| Step: 6
Training loss: 2.6893150806427
Validation loss: 1.9042042391274565

Epoch: 5| Step: 7
Training loss: 1.5457193851470947
Validation loss: 1.885854281404967

Epoch: 5| Step: 8
Training loss: 2.101048707962036
Validation loss: 1.8781252791804652

Epoch: 5| Step: 9
Training loss: 1.6960111856460571
Validation loss: 1.9237006466875795

Epoch: 5| Step: 10
Training loss: 1.789544939994812
Validation loss: 1.8941174155922347

Epoch: 144| Step: 0
Training loss: 1.915717363357544
Validation loss: 1.8858413516834218

Epoch: 5| Step: 1
Training loss: 2.637075424194336
Validation loss: 1.8984788925417009

Epoch: 5| Step: 2
Training loss: 1.6159976720809937
Validation loss: 1.9052125766713133

Epoch: 5| Step: 3
Training loss: 2.356722354888916
Validation loss: 1.8917663507564093

Epoch: 5| Step: 4
Training loss: 2.1401963233947754
Validation loss: 1.8931896532735517

Epoch: 5| Step: 5
Training loss: 1.9344732761383057
Validation loss: 1.8978895384778258

Epoch: 5| Step: 6
Training loss: 1.754611611366272
Validation loss: 1.9037194059741112

Epoch: 5| Step: 7
Training loss: 2.4463508129119873
Validation loss: 1.8799299924604354

Epoch: 5| Step: 8
Training loss: 2.0165491104125977
Validation loss: 1.8958413318921161

Epoch: 5| Step: 9
Training loss: 1.919159173965454
Validation loss: 1.905485878708542

Epoch: 5| Step: 10
Training loss: 1.2621270418167114
Validation loss: 1.9139336950035506

Epoch: 145| Step: 0
Training loss: 2.8080849647521973
Validation loss: 1.891266075513696

Epoch: 5| Step: 1
Training loss: 2.175208330154419
Validation loss: 1.9147744191590177

Epoch: 5| Step: 2
Training loss: 2.793499231338501
Validation loss: 1.915904478360248

Epoch: 5| Step: 3
Training loss: 1.481789231300354
Validation loss: 1.911881245592589

Epoch: 5| Step: 4
Training loss: 2.483219861984253
Validation loss: 1.9124537693556918

Epoch: 5| Step: 5
Training loss: 2.0457234382629395
Validation loss: 1.9072845251329484

Epoch: 5| Step: 6
Training loss: 1.7856369018554688
Validation loss: 1.914496128277112

Epoch: 5| Step: 7
Training loss: 1.2881568670272827
Validation loss: 1.898537120511455

Epoch: 5| Step: 8
Training loss: 2.142662525177002
Validation loss: 1.9052988072877288

Epoch: 5| Step: 9
Training loss: 1.6152513027191162
Validation loss: 1.9212092763634139

Epoch: 5| Step: 10
Training loss: 1.5725899934768677
Validation loss: 1.9231125795713035

Epoch: 146| Step: 0
Training loss: 1.6158168315887451
Validation loss: 1.9026352564493816

Epoch: 5| Step: 1
Training loss: 1.7470653057098389
Validation loss: 1.9211554655464746

Epoch: 5| Step: 2
Training loss: 1.734440565109253
Validation loss: 1.913739542807302

Epoch: 5| Step: 3
Training loss: 1.3118362426757812
Validation loss: 1.8983650668974845

Epoch: 5| Step: 4
Training loss: 2.473816394805908
Validation loss: 1.8932299242224744

Epoch: 5| Step: 5
Training loss: 2.533817768096924
Validation loss: 1.9023999347481677

Epoch: 5| Step: 6
Training loss: 2.5018019676208496
Validation loss: 1.903978318296453

Epoch: 5| Step: 7
Training loss: 1.9677842855453491
Validation loss: 1.9069234350676179

Epoch: 5| Step: 8
Training loss: 2.320810317993164
Validation loss: 1.9078537725633191

Epoch: 5| Step: 9
Training loss: 2.4345600605010986
Validation loss: 1.916679210560296

Epoch: 5| Step: 10
Training loss: 1.543569564819336
Validation loss: 1.9218254448265157

Epoch: 147| Step: 0
Training loss: 1.3692052364349365
Validation loss: 1.9048229802039363

Epoch: 5| Step: 1
Training loss: 2.4760921001434326
Validation loss: 1.9237739347642469

Epoch: 5| Step: 2
Training loss: 1.9672679901123047
Validation loss: 1.9009852973363732

Epoch: 5| Step: 3
Training loss: 2.3359341621398926
Validation loss: 1.8999316256533387

Epoch: 5| Step: 4
Training loss: 1.5995848178863525
Validation loss: 1.9124660709852814

Epoch: 5| Step: 5
Training loss: 2.2383079528808594
Validation loss: 1.9090904548604002

Epoch: 5| Step: 6
Training loss: 1.9821306467056274
Validation loss: 1.920730403674546

Epoch: 5| Step: 7
Training loss: 1.704140067100525
Validation loss: 1.9361096864105554

Epoch: 5| Step: 8
Training loss: 1.8490827083587646
Validation loss: 1.907023843898568

Epoch: 5| Step: 9
Training loss: 2.3027031421661377
Validation loss: 1.9198400179545085

Epoch: 5| Step: 10
Training loss: 2.4782657623291016
Validation loss: 1.9210992679801038

Epoch: 148| Step: 0
Training loss: 1.6966674327850342
Validation loss: 1.9191339426143195

Epoch: 5| Step: 1
Training loss: 2.234133720397949
Validation loss: 1.8903178361154371

Epoch: 5| Step: 2
Training loss: 2.0204527378082275
Validation loss: 1.8869078697696808

Epoch: 5| Step: 3
Training loss: 2.4107069969177246
Validation loss: 1.8922855930943643

Epoch: 5| Step: 4
Training loss: 2.1935696601867676
Validation loss: 1.8940620935091408

Epoch: 5| Step: 5
Training loss: 2.6232826709747314
Validation loss: 1.8852707275780298

Epoch: 5| Step: 6
Training loss: 1.977423906326294
Validation loss: 1.894974648311574

Epoch: 5| Step: 7
Training loss: 2.1173830032348633
Validation loss: 1.8963888473408197

Epoch: 5| Step: 8
Training loss: 1.3879187107086182
Validation loss: 1.8781703569555794

Epoch: 5| Step: 9
Training loss: 1.914560317993164
Validation loss: 1.8781927888111403

Epoch: 5| Step: 10
Training loss: 1.5672897100448608
Validation loss: 1.8933314405461794

Epoch: 149| Step: 0
Training loss: 1.5422351360321045
Validation loss: 1.8807013111729776

Epoch: 5| Step: 1
Training loss: 1.9387187957763672
Validation loss: 1.8865703921164236

Epoch: 5| Step: 2
Training loss: 2.471566915512085
Validation loss: 1.8924602270126343

Epoch: 5| Step: 3
Training loss: 1.8899953365325928
Validation loss: 1.8885152724481398

Epoch: 5| Step: 4
Training loss: 2.3764872550964355
Validation loss: 1.8733396171241679

Epoch: 5| Step: 5
Training loss: 1.8995258808135986
Validation loss: 1.8968629196125975

Epoch: 5| Step: 6
Training loss: 1.6621463298797607
Validation loss: 1.8729406979776198

Epoch: 5| Step: 7
Training loss: 1.5638152360916138
Validation loss: 1.8954029211433985

Epoch: 5| Step: 8
Training loss: 1.9659783840179443
Validation loss: 1.883835732295949

Epoch: 5| Step: 9
Training loss: 2.2503840923309326
Validation loss: 1.8898683722301195

Epoch: 5| Step: 10
Training loss: 2.6454405784606934
Validation loss: 1.8856220809362267

Epoch: 150| Step: 0
Training loss: 1.7074470520019531
Validation loss: 1.8916649382601503

Epoch: 5| Step: 1
Training loss: 1.985852599143982
Validation loss: 1.8975671722042946

Epoch: 5| Step: 2
Training loss: 2.22890043258667
Validation loss: 1.88779434850139

Epoch: 5| Step: 3
Training loss: 2.287576675415039
Validation loss: 1.9000328522856518

Epoch: 5| Step: 4
Training loss: 1.6901702880859375
Validation loss: 1.9048361252712946

Epoch: 5| Step: 5
Training loss: 2.0099799633026123
Validation loss: 1.8876290475168536

Epoch: 5| Step: 6
Training loss: 1.9467853307724
Validation loss: 1.8821341171059558

Epoch: 5| Step: 7
Training loss: 1.9802621603012085
Validation loss: 1.8984491440557665

Epoch: 5| Step: 8
Training loss: 2.169938325881958
Validation loss: 1.8987374318543302

Epoch: 5| Step: 9
Training loss: 2.0739550590515137
Validation loss: 1.9016612780991422

Epoch: 5| Step: 10
Training loss: 1.931672215461731
Validation loss: 1.9027544260025024

Epoch: 151| Step: 0
Training loss: 2.421243667602539
Validation loss: 1.904424343057858

Epoch: 5| Step: 1
Training loss: 2.053950071334839
Validation loss: 1.9061490733136413

Epoch: 5| Step: 2
Training loss: 1.6617555618286133
Validation loss: 1.9070111654138053

Epoch: 5| Step: 3
Training loss: 2.065788507461548
Validation loss: 1.9140302058189147

Epoch: 5| Step: 4
Training loss: 1.5518783330917358
Validation loss: 1.9222036651385728

Epoch: 5| Step: 5
Training loss: 1.8761367797851562
Validation loss: 1.8982072478981429

Epoch: 5| Step: 6
Training loss: 2.5734894275665283
Validation loss: 1.9133647539282357

Epoch: 5| Step: 7
Training loss: 1.7566134929656982
Validation loss: 1.882351884277918

Epoch: 5| Step: 8
Training loss: 1.8988916873931885
Validation loss: 1.9180161696608349

Epoch: 5| Step: 9
Training loss: 1.8686548471450806
Validation loss: 1.8991168070864934

Epoch: 5| Step: 10
Training loss: 2.3849356174468994
Validation loss: 1.9067807710298927

Epoch: 152| Step: 0
Training loss: 1.9356029033660889
Validation loss: 1.9066021596231768

Epoch: 5| Step: 1
Training loss: 1.9389854669570923
Validation loss: 1.9100859626646964

Epoch: 5| Step: 2
Training loss: 1.613344430923462
Validation loss: 1.9066795482430408

Epoch: 5| Step: 3
Training loss: 1.9971946477890015
Validation loss: 1.9046529775024743

Epoch: 5| Step: 4
Training loss: 1.8819267749786377
Validation loss: 1.9307273587872904

Epoch: 5| Step: 5
Training loss: 1.9239332675933838
Validation loss: 1.9053983380717616

Epoch: 5| Step: 6
Training loss: 2.197812557220459
Validation loss: 1.92869621323001

Epoch: 5| Step: 7
Training loss: 1.6158335208892822
Validation loss: 1.9158854253830448

Epoch: 5| Step: 8
Training loss: 1.705089807510376
Validation loss: 1.9061593176216207

Epoch: 5| Step: 9
Training loss: 2.5880963802337646
Validation loss: 1.9089003865436842

Epoch: 5| Step: 10
Training loss: 2.6139848232269287
Validation loss: 1.9059795179674703

Epoch: 153| Step: 0
Training loss: 1.7787420749664307
Validation loss: 1.8957748272085702

Epoch: 5| Step: 1
Training loss: 2.3227150440216064
Validation loss: 1.9088218942765267

Epoch: 5| Step: 2
Training loss: 1.5357866287231445
Validation loss: 1.8986477031502673

Epoch: 5| Step: 3
Training loss: 1.8161096572875977
Validation loss: 1.9136554502671765

Epoch: 5| Step: 4
Training loss: 2.083576202392578
Validation loss: 1.8988063232873076

Epoch: 5| Step: 5
Training loss: 2.1038355827331543
Validation loss: 1.8964379167044034

Epoch: 5| Step: 6
Training loss: 2.2309863567352295
Validation loss: 1.884916559342415

Epoch: 5| Step: 7
Training loss: 2.098576068878174
Validation loss: 1.9032369993066276

Epoch: 5| Step: 8
Training loss: 2.014106035232544
Validation loss: 1.8762121239016134

Epoch: 5| Step: 9
Training loss: 1.8936392068862915
Validation loss: 1.8921160877391856

Epoch: 5| Step: 10
Training loss: 2.0595579147338867
Validation loss: 1.8955326977596487

Epoch: 154| Step: 0
Training loss: 2.1812312602996826
Validation loss: 1.8787910117897937

Epoch: 5| Step: 1
Training loss: 1.6409215927124023
Validation loss: 1.904671901015825

Epoch: 5| Step: 2
Training loss: 1.1814138889312744
Validation loss: 1.900263697870316

Epoch: 5| Step: 3
Training loss: 1.8167804479599
Validation loss: 1.9060647103094286

Epoch: 5| Step: 4
Training loss: 2.1538548469543457
Validation loss: 1.893010107419824

Epoch: 5| Step: 5
Training loss: 1.8872432708740234
Validation loss: 1.8839431296112716

Epoch: 5| Step: 6
Training loss: 2.466015577316284
Validation loss: 1.892648648190242

Epoch: 5| Step: 7
Training loss: 2.262498378753662
Validation loss: 1.8967712104961436

Epoch: 5| Step: 8
Training loss: 2.2518417835235596
Validation loss: 1.9088057689769293

Epoch: 5| Step: 9
Training loss: 2.2639122009277344
Validation loss: 1.8907238860284128

Epoch: 5| Step: 10
Training loss: 1.6852712631225586
Validation loss: 1.8833029013808056

Epoch: 155| Step: 0
Training loss: 2.1430938243865967
Validation loss: 1.8947857067149172

Epoch: 5| Step: 1
Training loss: 1.965354323387146
Validation loss: 1.8753126154663742

Epoch: 5| Step: 2
Training loss: 2.2358193397521973
Validation loss: 1.8803978094490625

Epoch: 5| Step: 3
Training loss: 1.3821650743484497
Validation loss: 1.8853972650343371

Epoch: 5| Step: 4
Training loss: 1.901548147201538
Validation loss: 1.919458527718821

Epoch: 5| Step: 5
Training loss: 2.1530203819274902
Validation loss: 1.908432193981704

Epoch: 5| Step: 6
Training loss: 2.082165241241455
Validation loss: 1.909718910853068

Epoch: 5| Step: 7
Training loss: 2.518761396408081
Validation loss: 1.9370357682628017

Epoch: 5| Step: 8
Training loss: 1.8272708654403687
Validation loss: 1.9023866961079259

Epoch: 5| Step: 9
Training loss: 1.7436273097991943
Validation loss: 1.9212086931351693

Epoch: 5| Step: 10
Training loss: 1.9720245599746704
Validation loss: 1.9061323083857054

Epoch: 156| Step: 0
Training loss: 1.4552255868911743
Validation loss: 1.9295768404519686

Epoch: 5| Step: 1
Training loss: 1.7078157663345337
Validation loss: 1.9119790613010366

Epoch: 5| Step: 2
Training loss: 2.3292653560638428
Validation loss: 1.9055667910524594

Epoch: 5| Step: 3
Training loss: 2.257964611053467
Validation loss: 1.912991431451613

Epoch: 5| Step: 4
Training loss: 2.190037488937378
Validation loss: 1.9128459768910562

Epoch: 5| Step: 5
Training loss: 2.0733132362365723
Validation loss: 1.9120894157758324

Epoch: 5| Step: 6
Training loss: 1.3471486568450928
Validation loss: 1.8962096155330699

Epoch: 5| Step: 7
Training loss: 1.7904040813446045
Validation loss: 1.9104921343506023

Epoch: 5| Step: 8
Training loss: 2.116227626800537
Validation loss: 1.9096666766751198

Epoch: 5| Step: 9
Training loss: 2.1202101707458496
Validation loss: 1.8992688604580459

Epoch: 5| Step: 10
Training loss: 2.388460397720337
Validation loss: 1.898098321371181

Epoch: 157| Step: 0
Training loss: 2.0056426525115967
Validation loss: 1.9103569522980721

Epoch: 5| Step: 1
Training loss: 1.609210729598999
Validation loss: 1.8941762472993584

Epoch: 5| Step: 2
Training loss: 1.9909775257110596
Validation loss: 1.8959574955765919

Epoch: 5| Step: 3
Training loss: 2.037886381149292
Validation loss: 1.88386756502172

Epoch: 5| Step: 4
Training loss: 2.349912405014038
Validation loss: 1.8638481581082909

Epoch: 5| Step: 5
Training loss: 1.6597671508789062
Validation loss: 1.88133652235872

Epoch: 5| Step: 6
Training loss: 2.265084981918335
Validation loss: 1.8913152884411555

Epoch: 5| Step: 7
Training loss: 1.4057303667068481
Validation loss: 1.883953579010502

Epoch: 5| Step: 8
Training loss: 2.0202815532684326
Validation loss: 1.8656136579411005

Epoch: 5| Step: 9
Training loss: 2.1016855239868164
Validation loss: 1.8934886724718156

Epoch: 5| Step: 10
Training loss: 2.3082942962646484
Validation loss: 1.872081789919125

Epoch: 158| Step: 0
Training loss: 2.1659836769104004
Validation loss: 1.874401141238469

Epoch: 5| Step: 1
Training loss: 1.6518585681915283
Validation loss: 1.8785801151747346

Epoch: 5| Step: 2
Training loss: 1.331568956375122
Validation loss: 1.868390299940622

Epoch: 5| Step: 3
Training loss: 2.2042770385742188
Validation loss: 1.8753131281945012

Epoch: 5| Step: 4
Training loss: 2.1120705604553223
Validation loss: 1.8813189383476012

Epoch: 5| Step: 5
Training loss: 0.9968544244766235
Validation loss: 1.8875334698666808

Epoch: 5| Step: 6
Training loss: 2.369654417037964
Validation loss: 1.8740486444965485

Epoch: 5| Step: 7
Training loss: 2.3523988723754883
Validation loss: 1.8922059741071475

Epoch: 5| Step: 8
Training loss: 1.8572196960449219
Validation loss: 1.9083651842609528

Epoch: 5| Step: 9
Training loss: 2.569762706756592
Validation loss: 1.9146713210690407

Epoch: 5| Step: 10
Training loss: 2.188751459121704
Validation loss: 1.8826745825429116

Epoch: 159| Step: 0
Training loss: 1.8062217235565186
Validation loss: 1.878947324650262

Epoch: 5| Step: 1
Training loss: 2.2101998329162598
Validation loss: 1.873608345626503

Epoch: 5| Step: 2
Training loss: 2.3454742431640625
Validation loss: 1.8924731977524296

Epoch: 5| Step: 3
Training loss: 2.143988847732544
Validation loss: 1.8923784353399788

Epoch: 5| Step: 4
Training loss: 1.7144815921783447
Validation loss: 1.8933268798294889

Epoch: 5| Step: 5
Training loss: 1.422547459602356
Validation loss: 1.9143761306680658

Epoch: 5| Step: 6
Training loss: 1.9282770156860352
Validation loss: 1.8724026846629318

Epoch: 5| Step: 7
Training loss: 2.341721773147583
Validation loss: 1.8824297023075882

Epoch: 5| Step: 8
Training loss: 1.2649476528167725
Validation loss: 1.8839746482910649

Epoch: 5| Step: 9
Training loss: 2.238521099090576
Validation loss: 1.8923841138039865

Epoch: 5| Step: 10
Training loss: 2.2856202125549316
Validation loss: 1.9199561406207342

Epoch: 160| Step: 0
Training loss: 2.2313475608825684
Validation loss: 1.919898017760246

Epoch: 5| Step: 1
Training loss: 2.2479147911071777
Validation loss: 1.90970290348094

Epoch: 5| Step: 2
Training loss: 1.8216403722763062
Validation loss: 1.9124789161066855

Epoch: 5| Step: 3
Training loss: 1.4421724081039429
Validation loss: 1.90946320051788

Epoch: 5| Step: 4
Training loss: 1.8421118259429932
Validation loss: 1.9348335676295783

Epoch: 5| Step: 5
Training loss: 1.9584156274795532
Validation loss: 1.9336847720607635

Epoch: 5| Step: 6
Training loss: 2.1486499309539795
Validation loss: 1.9165347032649542

Epoch: 5| Step: 7
Training loss: 1.9769614934921265
Validation loss: 1.9057912262537147

Epoch: 5| Step: 8
Training loss: 2.20684814453125
Validation loss: 1.9167790130902362

Epoch: 5| Step: 9
Training loss: 1.8139867782592773
Validation loss: 1.9080556900270524

Epoch: 5| Step: 10
Training loss: 2.023283004760742
Validation loss: 1.9142187808149604

Epoch: 161| Step: 0
Training loss: 1.930444359779358
Validation loss: 1.9120775756015573

Epoch: 5| Step: 1
Training loss: 2.245673179626465
Validation loss: 1.909125727991904

Epoch: 5| Step: 2
Training loss: 1.5887067317962646
Validation loss: 1.9059757788976033

Epoch: 5| Step: 3
Training loss: 2.0019500255584717
Validation loss: 1.899923328430422

Epoch: 5| Step: 4
Training loss: 1.3654733896255493
Validation loss: 1.8924190536622079

Epoch: 5| Step: 5
Training loss: 2.309978485107422
Validation loss: 1.8970303253460956

Epoch: 5| Step: 6
Training loss: 2.2505204677581787
Validation loss: 1.9133943152684036

Epoch: 5| Step: 7
Training loss: 2.1378962993621826
Validation loss: 1.8831504878177439

Epoch: 5| Step: 8
Training loss: 1.580183506011963
Validation loss: 1.906051952351806

Epoch: 5| Step: 9
Training loss: 2.2442386150360107
Validation loss: 1.9015911163822297

Epoch: 5| Step: 10
Training loss: 1.9344419240951538
Validation loss: 1.892168152716852

Epoch: 162| Step: 0
Training loss: 1.3201513290405273
Validation loss: 1.8802388406568957

Epoch: 5| Step: 1
Training loss: 2.342071056365967
Validation loss: 1.8786576729948803

Epoch: 5| Step: 2
Training loss: 2.0202250480651855
Validation loss: 1.8641225330291256

Epoch: 5| Step: 3
Training loss: 1.5146952867507935
Validation loss: 1.9131043418761222

Epoch: 5| Step: 4
Training loss: 2.6443874835968018
Validation loss: 1.9059632042402863

Epoch: 5| Step: 5
Training loss: 2.0008864402770996
Validation loss: 1.9134895570816532

Epoch: 5| Step: 6
Training loss: 2.1300692558288574
Validation loss: 1.9110267239232217

Epoch: 5| Step: 7
Training loss: 1.7461973428726196
Validation loss: 1.9145889666772657

Epoch: 5| Step: 8
Training loss: 1.8206707239151
Validation loss: 1.925411747347924

Epoch: 5| Step: 9
Training loss: 2.4210214614868164
Validation loss: 1.897132392852537

Epoch: 5| Step: 10
Training loss: 1.5599814653396606
Validation loss: 1.9091593450115574

Epoch: 163| Step: 0
Training loss: 2.352731704711914
Validation loss: 1.875625874406548

Epoch: 5| Step: 1
Training loss: 2.5943219661712646
Validation loss: 1.8724685792000062

Epoch: 5| Step: 2
Training loss: 1.8622286319732666
Validation loss: 1.8936259028732136

Epoch: 5| Step: 3
Training loss: 1.6427419185638428
Validation loss: 1.88141006295399

Epoch: 5| Step: 4
Training loss: 2.451292037963867
Validation loss: 1.8750452392844743

Epoch: 5| Step: 5
Training loss: 2.071157932281494
Validation loss: 1.8717728968589538

Epoch: 5| Step: 6
Training loss: 1.8546226024627686
Validation loss: 1.8936465619712748

Epoch: 5| Step: 7
Training loss: 1.6779518127441406
Validation loss: 1.8904096029138053

Epoch: 5| Step: 8
Training loss: 1.574436902999878
Validation loss: 1.854198367364945

Epoch: 5| Step: 9
Training loss: 1.6937757730484009
Validation loss: 1.8552030542845368

Epoch: 5| Step: 10
Training loss: 1.8628740310668945
Validation loss: 1.8832341060843518

Epoch: 164| Step: 0
Training loss: 1.738878607749939
Validation loss: 1.8675132143882014

Epoch: 5| Step: 1
Training loss: 2.324596405029297
Validation loss: 1.8938038310697

Epoch: 5| Step: 2
Training loss: 1.8060890436172485
Validation loss: 1.872409806456617

Epoch: 5| Step: 3
Training loss: 2.341548442840576
Validation loss: 1.8958163030685917

Epoch: 5| Step: 4
Training loss: 1.7477076053619385
Validation loss: 1.8742632365995837

Epoch: 5| Step: 5
Training loss: 1.2968003749847412
Validation loss: 1.9052070956076346

Epoch: 5| Step: 6
Training loss: 2.1273255348205566
Validation loss: 1.8738370941531273

Epoch: 5| Step: 7
Training loss: 2.57853102684021
Validation loss: 1.8814094143529092

Epoch: 5| Step: 8
Training loss: 1.718309760093689
Validation loss: 1.8985285989699825

Epoch: 5| Step: 9
Training loss: 1.9048492908477783
Validation loss: 1.8813629752846175

Epoch: 5| Step: 10
Training loss: 2.0244827270507812
Validation loss: 1.8849446388982958

Epoch: 165| Step: 0
Training loss: 2.0258963108062744
Validation loss: 1.9099958942782493

Epoch: 5| Step: 1
Training loss: 1.6694514751434326
Validation loss: 1.908394080336376

Epoch: 5| Step: 2
Training loss: 2.2164864540100098
Validation loss: 1.8978637200529858

Epoch: 5| Step: 3
Training loss: 1.7512813806533813
Validation loss: 1.8946383409602667

Epoch: 5| Step: 4
Training loss: 1.5955390930175781
Validation loss: 1.9060872498378958

Epoch: 5| Step: 5
Training loss: 2.368711471557617
Validation loss: 1.9062068770008702

Epoch: 5| Step: 6
Training loss: 1.7156422138214111
Validation loss: 1.9092475252766763

Epoch: 5| Step: 7
Training loss: 1.6842918395996094
Validation loss: 1.9075277261836554

Epoch: 5| Step: 8
Training loss: 2.232221841812134
Validation loss: 1.893449729488742

Epoch: 5| Step: 9
Training loss: 2.3542044162750244
Validation loss: 1.8884612808945358

Epoch: 5| Step: 10
Training loss: 1.8963338136672974
Validation loss: 1.8820993131206882

Epoch: 166| Step: 0
Training loss: 2.1942224502563477
Validation loss: 1.8930536277832524

Epoch: 5| Step: 1
Training loss: 1.8133857250213623
Validation loss: 1.9044212166981032

Epoch: 5| Step: 2
Training loss: 1.9711942672729492
Validation loss: 1.9050835204380814

Epoch: 5| Step: 3
Training loss: 1.7966070175170898
Validation loss: 1.8905380631005892

Epoch: 5| Step: 4
Training loss: 2.341764450073242
Validation loss: 1.88214171830044

Epoch: 5| Step: 5
Training loss: 2.322727680206299
Validation loss: 1.8932265466259373

Epoch: 5| Step: 6
Training loss: 2.154538631439209
Validation loss: 1.906431213501961

Epoch: 5| Step: 7
Training loss: 1.5813249349594116
Validation loss: 1.9123424278792513

Epoch: 5| Step: 8
Training loss: 1.696209192276001
Validation loss: 1.8976157301215715

Epoch: 5| Step: 9
Training loss: 1.8690179586410522
Validation loss: 1.8930549031944686

Epoch: 5| Step: 10
Training loss: 1.6677556037902832
Validation loss: 1.8769979220564648

Epoch: 167| Step: 0
Training loss: 2.2004661560058594
Validation loss: 1.8933827389952957

Epoch: 5| Step: 1
Training loss: 2.5265355110168457
Validation loss: 1.894968448146697

Epoch: 5| Step: 2
Training loss: 1.7784690856933594
Validation loss: 1.9024506935509302

Epoch: 5| Step: 3
Training loss: 1.6387211084365845
Validation loss: 1.8997892615615681

Epoch: 5| Step: 4
Training loss: 1.5526301860809326
Validation loss: 1.926609335407134

Epoch: 5| Step: 5
Training loss: 2.0597617626190186
Validation loss: 1.9178608053474016

Epoch: 5| Step: 6
Training loss: 1.8527218103408813
Validation loss: 1.9157545233285556

Epoch: 5| Step: 7
Training loss: 1.8868080377578735
Validation loss: 1.9260365142617175

Epoch: 5| Step: 8
Training loss: 1.352416753768921
Validation loss: 1.911215647574394

Epoch: 5| Step: 9
Training loss: 2.222661256790161
Validation loss: 1.9189249495024323

Epoch: 5| Step: 10
Training loss: 2.4687139987945557
Validation loss: 1.8973941033886326

Epoch: 168| Step: 0
Training loss: 1.6718034744262695
Validation loss: 1.8925100475229242

Epoch: 5| Step: 1
Training loss: 1.8477070331573486
Validation loss: 1.877120510224373

Epoch: 5| Step: 2
Training loss: 1.5899351835250854
Validation loss: 1.89388289759236

Epoch: 5| Step: 3
Training loss: 1.7319633960723877
Validation loss: 1.913394010195168

Epoch: 5| Step: 4
Training loss: 2.1505162715911865
Validation loss: 1.8550962530156618

Epoch: 5| Step: 5
Training loss: 2.139017105102539
Validation loss: 1.8795627470939391

Epoch: 5| Step: 6
Training loss: 2.2444119453430176
Validation loss: 1.8926486751084686

Epoch: 5| Step: 7
Training loss: 2.0402438640594482
Validation loss: 1.8808205178988877

Epoch: 5| Step: 8
Training loss: 2.1360509395599365
Validation loss: 1.8859655959631807

Epoch: 5| Step: 9
Training loss: 1.9742587804794312
Validation loss: 1.8904280098535682

Epoch: 5| Step: 10
Training loss: 1.863693356513977
Validation loss: 1.874533696841168

Epoch: 169| Step: 0
Training loss: 1.8390754461288452
Validation loss: 1.8719311721863285

Epoch: 5| Step: 1
Training loss: 1.4270243644714355
Validation loss: 1.9009281255865609

Epoch: 5| Step: 2
Training loss: 2.291395425796509
Validation loss: 1.878452024152202

Epoch: 5| Step: 3
Training loss: 1.8641589879989624
Validation loss: 1.8933498180040749

Epoch: 5| Step: 4
Training loss: 1.5766252279281616
Validation loss: 1.8990274014011506

Epoch: 5| Step: 5
Training loss: 2.131669282913208
Validation loss: 1.8776506352168258

Epoch: 5| Step: 6
Training loss: 1.7702686786651611
Validation loss: 1.8894783681438816

Epoch: 5| Step: 7
Training loss: 2.1076126098632812
Validation loss: 1.916168652554994

Epoch: 5| Step: 8
Training loss: 1.9294513463974
Validation loss: 1.8979972434300247

Epoch: 5| Step: 9
Training loss: 1.7459379434585571
Validation loss: 1.8952994731164747

Epoch: 5| Step: 10
Training loss: 2.728663682937622
Validation loss: 1.9200653594027284

Epoch: 170| Step: 0
Training loss: 1.7411060333251953
Validation loss: 1.9061919668669343

Epoch: 5| Step: 1
Training loss: 2.0691702365875244
Validation loss: 1.8971833208555817

Epoch: 5| Step: 2
Training loss: 1.4813579320907593
Validation loss: 1.886601391658988

Epoch: 5| Step: 3
Training loss: 2.234861373901367
Validation loss: 1.8972344654862598

Epoch: 5| Step: 4
Training loss: 1.6603977680206299
Validation loss: 1.9031796083655408

Epoch: 5| Step: 5
Training loss: 2.3403267860412598
Validation loss: 1.9024990066405265

Epoch: 5| Step: 6
Training loss: 1.956190824508667
Validation loss: 1.8965202223870061

Epoch: 5| Step: 7
Training loss: 1.7963634729385376
Validation loss: 1.8853949987760155

Epoch: 5| Step: 8
Training loss: 2.3417787551879883
Validation loss: 1.9008111415370819

Epoch: 5| Step: 9
Training loss: 1.6997921466827393
Validation loss: 1.8810602029164631

Epoch: 5| Step: 10
Training loss: 1.948473334312439
Validation loss: 1.8615166307777486

Epoch: 171| Step: 0
Training loss: 1.4872252941131592
Validation loss: 1.868633459973079

Epoch: 5| Step: 1
Training loss: 1.9763768911361694
Validation loss: 1.8772647444919874

Epoch: 5| Step: 2
Training loss: 1.484750509262085
Validation loss: 1.8893697274628507

Epoch: 5| Step: 3
Training loss: 2.09989857673645
Validation loss: 1.8688519411189581

Epoch: 5| Step: 4
Training loss: 1.866642951965332
Validation loss: 1.8895234369462537

Epoch: 5| Step: 5
Training loss: 2.0362586975097656
Validation loss: 1.8858586357485863

Epoch: 5| Step: 6
Training loss: 1.4960353374481201
Validation loss: 1.8911295885680823

Epoch: 5| Step: 7
Training loss: 2.1351113319396973
Validation loss: 1.8902533323534074

Epoch: 5| Step: 8
Training loss: 2.0090103149414062
Validation loss: 1.8955801610023744

Epoch: 5| Step: 9
Training loss: 2.564110279083252
Validation loss: 1.8716316171871719

Epoch: 5| Step: 10
Training loss: 2.1643121242523193
Validation loss: 1.8780288209197342

Epoch: 172| Step: 0
Training loss: 1.8966366052627563
Validation loss: 1.8779854518111034

Epoch: 5| Step: 1
Training loss: 1.6619231700897217
Validation loss: 1.8865700742249847

Epoch: 5| Step: 2
Training loss: 2.0643560886383057
Validation loss: 1.911896018571751

Epoch: 5| Step: 3
Training loss: 1.946062445640564
Validation loss: 1.8759396281293643

Epoch: 5| Step: 4
Training loss: 2.342268466949463
Validation loss: 1.9029704088805823

Epoch: 5| Step: 5
Training loss: 1.973118543624878
Validation loss: 1.8910739524390108

Epoch: 5| Step: 6
Training loss: 1.6967519521713257
Validation loss: 1.897579877607284

Epoch: 5| Step: 7
Training loss: 2.0649611949920654
Validation loss: 1.899987848856116

Epoch: 5| Step: 8
Training loss: 2.1294398307800293
Validation loss: 1.9050254462867655

Epoch: 5| Step: 9
Training loss: 1.6538429260253906
Validation loss: 1.8948307165535547

Epoch: 5| Step: 10
Training loss: 1.7958765029907227
Validation loss: 1.9002025409411358

Epoch: 173| Step: 0
Training loss: 2.069133996963501
Validation loss: 1.9072441849657285

Epoch: 5| Step: 1
Training loss: 2.163050413131714
Validation loss: 1.9168395098819528

Epoch: 5| Step: 2
Training loss: 1.9417855739593506
Validation loss: 1.8865465835858417

Epoch: 5| Step: 3
Training loss: 1.8780958652496338
Validation loss: 1.891975151595249

Epoch: 5| Step: 4
Training loss: 1.7667566537857056
Validation loss: 1.8803813713853077

Epoch: 5| Step: 5
Training loss: 2.040034055709839
Validation loss: 1.8869657657479728

Epoch: 5| Step: 6
Training loss: 1.8926042318344116
Validation loss: 1.8777076967300907

Epoch: 5| Step: 7
Training loss: 2.0397322177886963
Validation loss: 1.8905114384107693

Epoch: 5| Step: 8
Training loss: 1.6062781810760498
Validation loss: 1.8866143111259706

Epoch: 5| Step: 9
Training loss: 2.1916651725769043
Validation loss: 1.8837580475755917

Epoch: 5| Step: 10
Training loss: 1.3786346912384033
Validation loss: 1.88764642002762

Epoch: 174| Step: 0
Training loss: 1.9032022953033447
Validation loss: 1.8993187155774844

Epoch: 5| Step: 1
Training loss: 1.8596184253692627
Validation loss: 1.8883007034178703

Epoch: 5| Step: 2
Training loss: 2.3494739532470703
Validation loss: 1.8952708628869825

Epoch: 5| Step: 3
Training loss: 2.1333703994750977
Validation loss: 1.8846228814894153

Epoch: 5| Step: 4
Training loss: 2.131605625152588
Validation loss: 1.9084859022530176

Epoch: 5| Step: 5
Training loss: 1.4875240325927734
Validation loss: 1.8999294747588455

Epoch: 5| Step: 6
Training loss: 2.2465767860412598
Validation loss: 1.908298482177078

Epoch: 5| Step: 7
Training loss: 1.4123374223709106
Validation loss: 1.897643768659202

Epoch: 5| Step: 8
Training loss: 1.6103856563568115
Validation loss: 1.9463783874306628

Epoch: 5| Step: 9
Training loss: 1.3909552097320557
Validation loss: 1.9117791627043037

Epoch: 5| Step: 10
Training loss: 2.6635379791259766
Validation loss: 1.9105507455846316

Epoch: 175| Step: 0
Training loss: 1.8834171295166016
Validation loss: 1.8923983702095606

Epoch: 5| Step: 1
Training loss: 2.3098061084747314
Validation loss: 1.8957533439000447

Epoch: 5| Step: 2
Training loss: 1.6869947910308838
Validation loss: 1.8939309812361194

Epoch: 5| Step: 3
Training loss: 2.1266825199127197
Validation loss: 1.8835094641613703

Epoch: 5| Step: 4
Training loss: 2.050140142440796
Validation loss: 1.8782026665185088

Epoch: 5| Step: 5
Training loss: 2.1948459148406982
Validation loss: 1.8829436891822404

Epoch: 5| Step: 6
Training loss: 1.5524179935455322
Validation loss: 1.8822460584743048

Epoch: 5| Step: 7
Training loss: 1.629225492477417
Validation loss: 1.8858165817876016

Epoch: 5| Step: 8
Training loss: 1.7288936376571655
Validation loss: 1.8674578000140447

Epoch: 5| Step: 9
Training loss: 2.1324095726013184
Validation loss: 1.8766656203936505

Epoch: 5| Step: 10
Training loss: 1.7285932302474976
Validation loss: 1.8775650147468812

Epoch: 176| Step: 0
Training loss: 1.8298743963241577
Validation loss: 1.8720098413446897

Epoch: 5| Step: 1
Training loss: 1.9144033193588257
Validation loss: 1.880861125966554

Epoch: 5| Step: 2
Training loss: 2.0212502479553223
Validation loss: 1.8756941351839291

Epoch: 5| Step: 3
Training loss: 1.0362021923065186
Validation loss: 1.8699921792553318

Epoch: 5| Step: 4
Training loss: 2.0468404293060303
Validation loss: 1.859639395949661

Epoch: 5| Step: 5
Training loss: 2.4454073905944824
Validation loss: 1.855641512460606

Epoch: 5| Step: 6
Training loss: 1.8227447271347046
Validation loss: 1.883685088926746

Epoch: 5| Step: 7
Training loss: 1.6598209142684937
Validation loss: 1.8796386821295625

Epoch: 5| Step: 8
Training loss: 1.9998729228973389
Validation loss: 1.8802149013806415

Epoch: 5| Step: 9
Training loss: 2.659008264541626
Validation loss: 1.8751380648664249

Epoch: 5| Step: 10
Training loss: 1.6400665044784546
Validation loss: 1.864841180462991

Epoch: 177| Step: 0
Training loss: 1.3244527578353882
Validation loss: 1.8917569114315895

Epoch: 5| Step: 1
Training loss: 1.7559009790420532
Validation loss: 1.8775698036275885

Epoch: 5| Step: 2
Training loss: 1.8956782817840576
Validation loss: 1.8750050862630208

Epoch: 5| Step: 3
Training loss: 2.3901937007904053
Validation loss: 1.9027504203140095

Epoch: 5| Step: 4
Training loss: 2.3143057823181152
Validation loss: 1.8563393021142611

Epoch: 5| Step: 5
Training loss: 1.8700100183486938
Validation loss: 1.878665801017515

Epoch: 5| Step: 6
Training loss: 1.5835846662521362
Validation loss: 1.8695443189272316

Epoch: 5| Step: 7
Training loss: 1.864952802658081
Validation loss: 1.8701919676155172

Epoch: 5| Step: 8
Training loss: 1.6464534997940063
Validation loss: 1.8693395942770026

Epoch: 5| Step: 9
Training loss: 1.8435360193252563
Validation loss: 1.8948565362602152

Epoch: 5| Step: 10
Training loss: 2.6379764080047607
Validation loss: 1.8788330785689815

Epoch: 178| Step: 0
Training loss: 1.9231418371200562
Validation loss: 1.88462536052991

Epoch: 5| Step: 1
Training loss: 2.0556912422180176
Validation loss: 1.8866554742218347

Epoch: 5| Step: 2
Training loss: 2.149148464202881
Validation loss: 1.8818158744483866

Epoch: 5| Step: 3
Training loss: 1.8101648092269897
Validation loss: 1.9136131322512062

Epoch: 5| Step: 4
Training loss: 2.046736478805542
Validation loss: 1.9200379592116161

Epoch: 5| Step: 5
Training loss: 1.6776940822601318
Validation loss: 1.9000867694936774

Epoch: 5| Step: 6
Training loss: 2.0374109745025635
Validation loss: 1.9297275030484764

Epoch: 5| Step: 7
Training loss: 1.6076847314834595
Validation loss: 1.9017167732279787

Epoch: 5| Step: 8
Training loss: 2.087218999862671
Validation loss: 1.8971473914320751

Epoch: 5| Step: 9
Training loss: 1.94025456905365
Validation loss: 1.8991352242808188

Epoch: 5| Step: 10
Training loss: 1.8616786003112793
Validation loss: 1.910078840871011

Epoch: 179| Step: 0
Training loss: 1.916629433631897
Validation loss: 1.8974051860070997

Epoch: 5| Step: 1
Training loss: 1.8364083766937256
Validation loss: 1.8991494153135566

Epoch: 5| Step: 2
Training loss: 2.133979320526123
Validation loss: 1.893065656385114

Epoch: 5| Step: 3
Training loss: 1.6819345951080322
Validation loss: 1.9047052988442041

Epoch: 5| Step: 4
Training loss: 2.023242712020874
Validation loss: 1.8877290500107633

Epoch: 5| Step: 5
Training loss: 1.6440273523330688
Validation loss: 1.9227794306252592

Epoch: 5| Step: 6
Training loss: 1.8379557132720947
Validation loss: 1.8876246226731168

Epoch: 5| Step: 7
Training loss: 1.5868918895721436
Validation loss: 1.886392140901217

Epoch: 5| Step: 8
Training loss: 2.2261271476745605
Validation loss: 1.8753561794116933

Epoch: 5| Step: 9
Training loss: 2.1426985263824463
Validation loss: 1.8724054751857635

Epoch: 5| Step: 10
Training loss: 2.0861105918884277
Validation loss: 1.8683479806428314

Epoch: 180| Step: 0
Training loss: 2.448885679244995
Validation loss: 1.874106204637917

Epoch: 5| Step: 1
Training loss: 1.4148284196853638
Validation loss: 1.8864068318438787

Epoch: 5| Step: 2
Training loss: 2.531583309173584
Validation loss: 1.8838820790731778

Epoch: 5| Step: 3
Training loss: 2.519052505493164
Validation loss: 1.8743770507074171

Epoch: 5| Step: 4
Training loss: 1.4147982597351074
Validation loss: 1.8747330416915238

Epoch: 5| Step: 5
Training loss: 1.468967318534851
Validation loss: 1.9320434421621344

Epoch: 5| Step: 6
Training loss: 1.7561047077178955
Validation loss: 1.9003573656082153

Epoch: 5| Step: 7
Training loss: 1.685530662536621
Validation loss: 1.9139659699573313

Epoch: 5| Step: 8
Training loss: 2.0559959411621094
Validation loss: 1.898985625595175

Epoch: 5| Step: 9
Training loss: 1.417440414428711
Validation loss: 1.8980066519911571

Epoch: 5| Step: 10
Training loss: 2.5567824840545654
Validation loss: 1.8958673759173321

Epoch: 181| Step: 0
Training loss: 1.6184085607528687
Validation loss: 1.888376194943664

Epoch: 5| Step: 1
Training loss: 1.8814928531646729
Validation loss: 1.8896796882793467

Epoch: 5| Step: 2
Training loss: 1.5334577560424805
Validation loss: 1.8696967017266057

Epoch: 5| Step: 3
Training loss: 2.0463461875915527
Validation loss: 1.865505080069265

Epoch: 5| Step: 4
Training loss: 2.0290918350219727
Validation loss: 1.8758610140892766

Epoch: 5| Step: 5
Training loss: 1.3853528499603271
Validation loss: 1.8991475374467912

Epoch: 5| Step: 6
Training loss: 1.7851879596710205
Validation loss: 1.881619043247674

Epoch: 5| Step: 7
Training loss: 1.9193798303604126
Validation loss: 1.869265135898385

Epoch: 5| Step: 8
Training loss: 2.4882633686065674
Validation loss: 1.8775883438766643

Epoch: 5| Step: 9
Training loss: 2.4632349014282227
Validation loss: 1.8996770625473351

Epoch: 5| Step: 10
Training loss: 1.8238372802734375
Validation loss: 1.8825714229255595

Epoch: 182| Step: 0
Training loss: 2.742624044418335
Validation loss: 1.8576771027298384

Epoch: 5| Step: 1
Training loss: 2.152935028076172
Validation loss: 1.8796574146516862

Epoch: 5| Step: 2
Training loss: 1.1541149616241455
Validation loss: 1.8796795914250035

Epoch: 5| Step: 3
Training loss: 1.8168598413467407
Validation loss: 1.8854692879543509

Epoch: 5| Step: 4
Training loss: 2.8826801776885986
Validation loss: 1.893321737166374

Epoch: 5| Step: 5
Training loss: 2.0047521591186523
Validation loss: 1.895423480259475

Epoch: 5| Step: 6
Training loss: 2.08428692817688
Validation loss: 1.880329515344353

Epoch: 5| Step: 7
Training loss: 1.7262256145477295
Validation loss: 1.8992546437889017

Epoch: 5| Step: 8
Training loss: 1.2644150257110596
Validation loss: 1.8902098953082997

Epoch: 5| Step: 9
Training loss: 1.4873120784759521
Validation loss: 1.8954225714488695

Epoch: 5| Step: 10
Training loss: 1.5720902681350708
Validation loss: 1.874704618607798

Epoch: 183| Step: 0
Training loss: 1.9128497838974
Validation loss: 1.886984799497871

Epoch: 5| Step: 1
Training loss: 1.9233099222183228
Validation loss: 1.8807545169707267

Epoch: 5| Step: 2
Training loss: 2.0965240001678467
Validation loss: 1.8791246785912463

Epoch: 5| Step: 3
Training loss: 1.8595548868179321
Validation loss: 1.8758720672258766

Epoch: 5| Step: 4
Training loss: 1.5377310514450073
Validation loss: 1.8913911850221696

Epoch: 5| Step: 5
Training loss: 2.0945940017700195
Validation loss: 1.8475692541368547

Epoch: 5| Step: 6
Training loss: 1.9198331832885742
Validation loss: 1.863407987420277

Epoch: 5| Step: 7
Training loss: 2.166560411453247
Validation loss: 1.8861289588353967

Epoch: 5| Step: 8
Training loss: 1.3101778030395508
Validation loss: 1.8901343089278027

Epoch: 5| Step: 9
Training loss: 2.004812240600586
Validation loss: 1.8758441478975358

Epoch: 5| Step: 10
Training loss: 2.1295437812805176
Validation loss: 1.8679165865785332

Epoch: 184| Step: 0
Training loss: 1.6239397525787354
Validation loss: 1.8651617111698273

Epoch: 5| Step: 1
Training loss: 1.4748296737670898
Validation loss: 1.879364344381517

Epoch: 5| Step: 2
Training loss: 2.0566353797912598
Validation loss: 1.9022523523658834

Epoch: 5| Step: 3
Training loss: 2.3564305305480957
Validation loss: 1.8837344723363076

Epoch: 5| Step: 4
Training loss: 1.9198625087738037
Validation loss: 1.8775943543321343

Epoch: 5| Step: 5
Training loss: 2.1265406608581543
Validation loss: 1.8721912907015892

Epoch: 5| Step: 6
Training loss: 2.0861475467681885
Validation loss: 1.8490133875159807

Epoch: 5| Step: 7
Training loss: 2.1226539611816406
Validation loss: 1.8850704213624359

Epoch: 5| Step: 8
Training loss: 1.189892053604126
Validation loss: 1.8765403070757467

Epoch: 5| Step: 9
Training loss: 1.9294006824493408
Validation loss: 1.9002031639058103

Epoch: 5| Step: 10
Training loss: 1.9691855907440186
Validation loss: 1.8923433275632962

Epoch: 185| Step: 0
Training loss: 1.258028507232666
Validation loss: 1.8899564243132068

Epoch: 5| Step: 1
Training loss: 2.1231276988983154
Validation loss: 1.8838829737837597

Epoch: 5| Step: 2
Training loss: 1.5148184299468994
Validation loss: 1.8837661884164298

Epoch: 5| Step: 3
Training loss: 1.9721720218658447
Validation loss: 1.8963650913648709

Epoch: 5| Step: 4
Training loss: 1.9648898839950562
Validation loss: 1.9076077732988583

Epoch: 5| Step: 5
Training loss: 2.1554179191589355
Validation loss: 1.886840594712124

Epoch: 5| Step: 6
Training loss: 1.9684860706329346
Validation loss: 1.8818695032468407

Epoch: 5| Step: 7
Training loss: 1.5089576244354248
Validation loss: 1.8932859897613525

Epoch: 5| Step: 8
Training loss: 1.692631483078003
Validation loss: 1.861811883987919

Epoch: 5| Step: 9
Training loss: 2.5820393562316895
Validation loss: 1.884818346269669

Epoch: 5| Step: 10
Training loss: 1.9292633533477783
Validation loss: 1.8807204436230403

Epoch: 186| Step: 0
Training loss: 1.4576842784881592
Validation loss: 1.8961701162399784

Epoch: 5| Step: 1
Training loss: 1.5746252536773682
Validation loss: 1.891748594981368

Epoch: 5| Step: 2
Training loss: 2.1337430477142334
Validation loss: 1.9074858696229997

Epoch: 5| Step: 3
Training loss: 1.6967535018920898
Validation loss: 1.8892270877797117

Epoch: 5| Step: 4
Training loss: 1.5779964923858643
Validation loss: 1.9014042782527145

Epoch: 5| Step: 5
Training loss: 2.2452194690704346
Validation loss: 1.9175313211256457

Epoch: 5| Step: 6
Training loss: 2.359471082687378
Validation loss: 1.8954451096955167

Epoch: 5| Step: 7
Training loss: 2.366427183151245
Validation loss: 1.8907879462806128

Epoch: 5| Step: 8
Training loss: 1.5911993980407715
Validation loss: 1.8746701466139926

Epoch: 5| Step: 9
Training loss: 2.076277494430542
Validation loss: 1.8839615365510345

Epoch: 5| Step: 10
Training loss: 1.595508098602295
Validation loss: 1.879907113249584

Epoch: 187| Step: 0
Training loss: 1.3533952236175537
Validation loss: 1.8894796179186912

Epoch: 5| Step: 1
Training loss: 1.5597891807556152
Validation loss: 1.878006076300016

Epoch: 5| Step: 2
Training loss: 1.9472320079803467
Validation loss: 1.8709007693875221

Epoch: 5| Step: 3
Training loss: 1.4306566715240479
Validation loss: 1.895907719930013

Epoch: 5| Step: 4
Training loss: 2.658228635787964
Validation loss: 1.9013510211821525

Epoch: 5| Step: 5
Training loss: 2.3862464427948
Validation loss: 1.8812939069604362

Epoch: 5| Step: 6
Training loss: 1.6146831512451172
Validation loss: 1.9068981370618265

Epoch: 5| Step: 7
Training loss: 2.1009249687194824
Validation loss: 1.9019598704512402

Epoch: 5| Step: 8
Training loss: 1.837994933128357
Validation loss: 1.8992487294699556

Epoch: 5| Step: 9
Training loss: 1.8018776178359985
Validation loss: 1.9144358045311385

Epoch: 5| Step: 10
Training loss: 2.0102713108062744
Validation loss: 1.8699105439647552

Epoch: 188| Step: 0
Training loss: 1.7948249578475952
Validation loss: 1.8974590442513908

Epoch: 5| Step: 1
Training loss: 1.908129096031189
Validation loss: 1.9118107377841909

Epoch: 5| Step: 2
Training loss: 2.087120532989502
Validation loss: 1.9003617122609129

Epoch: 5| Step: 3
Training loss: 1.8425514698028564
Validation loss: 1.9027624591704337

Epoch: 5| Step: 4
Training loss: 2.4757118225097656
Validation loss: 1.8737104836330618

Epoch: 5| Step: 5
Training loss: 1.9608004093170166
Validation loss: 1.8912219039855465

Epoch: 5| Step: 6
Training loss: 1.7579162120819092
Validation loss: 1.8942612345500658

Epoch: 5| Step: 7
Training loss: 1.4285303354263306
Validation loss: 1.8742878501133253

Epoch: 5| Step: 8
Training loss: 1.942755103111267
Validation loss: 1.8962805309603292

Epoch: 5| Step: 9
Training loss: 1.4110532999038696
Validation loss: 1.8952196977471794

Epoch: 5| Step: 10
Training loss: 2.072902202606201
Validation loss: 1.8510495078179143

Epoch: 189| Step: 0
Training loss: 1.7488809823989868
Validation loss: 1.8662689373057375

Epoch: 5| Step: 1
Training loss: 1.3238701820373535
Validation loss: 1.869775051711708

Epoch: 5| Step: 2
Training loss: 2.221714496612549
Validation loss: 1.8721274842498123

Epoch: 5| Step: 3
Training loss: 1.9216448068618774
Validation loss: 1.8751094392550889

Epoch: 5| Step: 4
Training loss: 1.68021559715271
Validation loss: 1.8808941982125724

Epoch: 5| Step: 5
Training loss: 1.365632176399231
Validation loss: 1.8656717423469789

Epoch: 5| Step: 6
Training loss: 2.103325366973877
Validation loss: 1.8671884113742458

Epoch: 5| Step: 7
Training loss: 1.62239670753479
Validation loss: 1.8599164819204679

Epoch: 5| Step: 8
Training loss: 2.6435883045196533
Validation loss: 1.8734484052145353

Epoch: 5| Step: 9
Training loss: 1.9257640838623047
Validation loss: 1.8753135088951356

Epoch: 5| Step: 10
Training loss: 1.9954028129577637
Validation loss: 1.8552051462152952

Epoch: 190| Step: 0
Training loss: 2.006072521209717
Validation loss: 1.8938499125101234

Epoch: 5| Step: 1
Training loss: 1.9994001388549805
Validation loss: 1.8762601972908102

Epoch: 5| Step: 2
Training loss: 1.7323410511016846
Validation loss: 1.8752844333648682

Epoch: 5| Step: 3
Training loss: 1.79006826877594
Validation loss: 1.8742068262510403

Epoch: 5| Step: 4
Training loss: 1.2145817279815674
Validation loss: 1.8636667587423836

Epoch: 5| Step: 5
Training loss: 1.4167929887771606
Validation loss: 1.8998786787832938

Epoch: 5| Step: 6
Training loss: 1.726511001586914
Validation loss: 1.8847567599306825

Epoch: 5| Step: 7
Training loss: 1.621971845626831
Validation loss: 1.904838490229781

Epoch: 5| Step: 8
Training loss: 2.7643561363220215
Validation loss: 1.9117045069253573

Epoch: 5| Step: 9
Training loss: 2.040322780609131
Validation loss: 1.8972675338868172

Epoch: 5| Step: 10
Training loss: 2.160001754760742
Validation loss: 1.9116137284104542

Epoch: 191| Step: 0
Training loss: 2.2330198287963867
Validation loss: 1.8710907172131281

Epoch: 5| Step: 1
Training loss: 2.4343771934509277
Validation loss: 1.887405180161999

Epoch: 5| Step: 2
Training loss: 1.1644294261932373
Validation loss: 1.8829296558134017

Epoch: 5| Step: 3
Training loss: 1.790541410446167
Validation loss: 1.888364209923693

Epoch: 5| Step: 4
Training loss: 1.8679611682891846
Validation loss: 1.8870512593177058

Epoch: 5| Step: 5
Training loss: 2.233534336090088
Validation loss: 1.8963293926690215

Epoch: 5| Step: 6
Training loss: 1.8056989908218384
Validation loss: 1.9061336978789298

Epoch: 5| Step: 7
Training loss: 1.0821142196655273
Validation loss: 1.8972312570900045

Epoch: 5| Step: 8
Training loss: 1.4285880327224731
Validation loss: 1.8884987561933455

Epoch: 5| Step: 9
Training loss: 2.75970721244812
Validation loss: 1.8758998737540296

Epoch: 5| Step: 10
Training loss: 1.6340168714523315
Validation loss: 1.8964197058831491

Epoch: 192| Step: 0
Training loss: 2.2315568923950195
Validation loss: 1.9040647501586585

Epoch: 5| Step: 1
Training loss: 1.7488988637924194
Validation loss: 1.8785165509869974

Epoch: 5| Step: 2
Training loss: 1.7848091125488281
Validation loss: 1.9084416640702115

Epoch: 5| Step: 3
Training loss: 1.8131377696990967
Validation loss: 1.8853171012734855

Epoch: 5| Step: 4
Training loss: 2.0031991004943848
Validation loss: 1.8913543711426437

Epoch: 5| Step: 5
Training loss: 1.7285324335098267
Validation loss: 1.8781077810513076

Epoch: 5| Step: 6
Training loss: 2.3605198860168457
Validation loss: 1.9043420617298414

Epoch: 5| Step: 7
Training loss: 2.3045096397399902
Validation loss: 1.8818843313442764

Epoch: 5| Step: 8
Training loss: 2.016632556915283
Validation loss: 1.8769264631373908

Epoch: 5| Step: 9
Training loss: 1.3811705112457275
Validation loss: 1.892397101207446

Epoch: 5| Step: 10
Training loss: 1.1826934814453125
Validation loss: 1.8681397361140097

Epoch: 193| Step: 0
Training loss: 1.8144283294677734
Validation loss: 1.897083750335119

Epoch: 5| Step: 1
Training loss: 1.443084955215454
Validation loss: 1.874074984622258

Epoch: 5| Step: 2
Training loss: 1.8394842147827148
Validation loss: 1.8653176574296848

Epoch: 5| Step: 3
Training loss: 1.8282006978988647
Validation loss: 1.8857288975869455

Epoch: 5| Step: 4
Training loss: 2.147491931915283
Validation loss: 1.8829970641802716

Epoch: 5| Step: 5
Training loss: 1.811989426612854
Validation loss: 1.8943000531965686

Epoch: 5| Step: 6
Training loss: 2.475168466567993
Validation loss: 1.8624310724196895

Epoch: 5| Step: 7
Training loss: 1.757569670677185
Validation loss: 1.8951866344739032

Epoch: 5| Step: 8
Training loss: 1.8230106830596924
Validation loss: 1.8489583269242318

Epoch: 5| Step: 9
Training loss: 1.997758150100708
Validation loss: 1.888212121942992

Epoch: 5| Step: 10
Training loss: 1.4999839067459106
Validation loss: 1.8636236062613867

Epoch: 194| Step: 0
Training loss: 1.8490793704986572
Validation loss: 1.8502602167026971

Epoch: 5| Step: 1
Training loss: 1.9096367359161377
Validation loss: 1.8595292247751707

Epoch: 5| Step: 2
Training loss: 2.3501689434051514
Validation loss: 1.87966953298097

Epoch: 5| Step: 3
Training loss: 1.5859700441360474
Validation loss: 1.9035027257857784

Epoch: 5| Step: 4
Training loss: 1.8737983703613281
Validation loss: 1.8653421235340897

Epoch: 5| Step: 5
Training loss: 1.8981431722640991
Validation loss: 1.9053193971674929

Epoch: 5| Step: 6
Training loss: 1.5376259088516235
Validation loss: 1.8818995555241902

Epoch: 5| Step: 7
Training loss: 2.1253998279571533
Validation loss: 1.8603662918972712

Epoch: 5| Step: 8
Training loss: 1.9110393524169922
Validation loss: 1.8548035211460565

Epoch: 5| Step: 9
Training loss: 1.3032640218734741
Validation loss: 1.8821991002687843

Epoch: 5| Step: 10
Training loss: 2.108440399169922
Validation loss: 1.861222949079288

Epoch: 195| Step: 0
Training loss: 1.290171504020691
Validation loss: 1.8693233830954439

Epoch: 5| Step: 1
Training loss: 1.7002846002578735
Validation loss: 1.8936451647871284

Epoch: 5| Step: 2
Training loss: 1.6251943111419678
Validation loss: 1.891444993275468

Epoch: 5| Step: 3
Training loss: 2.3909714221954346
Validation loss: 1.8733439471132012

Epoch: 5| Step: 4
Training loss: 1.6379215717315674
Validation loss: 1.8959962770503054

Epoch: 5| Step: 5
Training loss: 2.264859676361084
Validation loss: 1.9129111484814716

Epoch: 5| Step: 6
Training loss: 2.0507240295410156
Validation loss: 1.9087022786499352

Epoch: 5| Step: 7
Training loss: 1.8439176082611084
Validation loss: 1.9067721828337638

Epoch: 5| Step: 8
Training loss: 1.674756407737732
Validation loss: 1.9310846046734882

Epoch: 5| Step: 9
Training loss: 2.053840398788452
Validation loss: 1.889527992535663

Epoch: 5| Step: 10
Training loss: 1.9338926076889038
Validation loss: 1.8844338078652658

Epoch: 196| Step: 0
Training loss: 2.444643974304199
Validation loss: 1.9284809071530578

Epoch: 5| Step: 1
Training loss: 2.1686737537384033
Validation loss: 1.9273275239493257

Epoch: 5| Step: 2
Training loss: 2.3712973594665527
Validation loss: 1.8953072140293736

Epoch: 5| Step: 3
Training loss: 1.9042389392852783
Validation loss: 1.9034978599958523

Epoch: 5| Step: 4
Training loss: 1.6941182613372803
Validation loss: 1.8733649228208809

Epoch: 5| Step: 5
Training loss: 1.6329641342163086
Validation loss: 1.8816338931360552

Epoch: 5| Step: 6
Training loss: 1.5151033401489258
Validation loss: 1.8610379054982176

Epoch: 5| Step: 7
Training loss: 1.3342876434326172
Validation loss: 1.8801960265764626

Epoch: 5| Step: 8
Training loss: 1.732969880104065
Validation loss: 1.9086016429367887

Epoch: 5| Step: 9
Training loss: 1.7271219491958618
Validation loss: 1.8838415145874023

Epoch: 5| Step: 10
Training loss: 1.7215328216552734
Validation loss: 1.8630932146503079

Epoch: 197| Step: 0
Training loss: 1.685158371925354
Validation loss: 1.8617331212566746

Epoch: 5| Step: 1
Training loss: 2.35256290435791
Validation loss: 1.893545586575744

Epoch: 5| Step: 2
Training loss: 1.9525467157363892
Validation loss: 1.8831153787592405

Epoch: 5| Step: 3
Training loss: 1.3448987007141113
Validation loss: 1.8924709212395452

Epoch: 5| Step: 4
Training loss: 2.229872465133667
Validation loss: 1.884058508821713

Epoch: 5| Step: 5
Training loss: 1.4573445320129395
Validation loss: 1.873947351209579

Epoch: 5| Step: 6
Training loss: 2.120065450668335
Validation loss: 1.8672294642335625

Epoch: 5| Step: 7
Training loss: 1.862636923789978
Validation loss: 1.8525603086717668

Epoch: 5| Step: 8
Training loss: 1.6866075992584229
Validation loss: 1.8658156394958496

Epoch: 5| Step: 9
Training loss: 2.1395926475524902
Validation loss: 1.8749403671551776

Epoch: 5| Step: 10
Training loss: 1.3913339376449585
Validation loss: 1.8687984161479498

Epoch: 198| Step: 0
Training loss: 1.8031055927276611
Validation loss: 1.87790132850729

Epoch: 5| Step: 1
Training loss: 2.3135721683502197
Validation loss: 1.8822372677505657

Epoch: 5| Step: 2
Training loss: 1.7349355220794678
Validation loss: 1.9009963927730438

Epoch: 5| Step: 3
Training loss: 1.730700135231018
Validation loss: 1.8575792774077384

Epoch: 5| Step: 4
Training loss: 1.162024736404419
Validation loss: 1.8760320960834462

Epoch: 5| Step: 5
Training loss: 2.6703028678894043
Validation loss: 1.8656560836299774

Epoch: 5| Step: 6
Training loss: 1.3193901777267456
Validation loss: 1.8782989466062157

Epoch: 5| Step: 7
Training loss: 1.689113974571228
Validation loss: 1.8890129314955844

Epoch: 5| Step: 8
Training loss: 1.8515428304672241
Validation loss: 1.9066112182473625

Epoch: 5| Step: 9
Training loss: 1.9060001373291016
Validation loss: 1.8836413301447386

Epoch: 5| Step: 10
Training loss: 2.0130913257598877
Validation loss: 1.8845428215560092

Epoch: 199| Step: 0
Training loss: 1.695296287536621
Validation loss: 1.8938975808440999

Epoch: 5| Step: 1
Training loss: 2.0630815029144287
Validation loss: 1.8789232648828977

Epoch: 5| Step: 2
Training loss: 2.015270709991455
Validation loss: 1.8704113575720018

Epoch: 5| Step: 3
Training loss: 1.6945480108261108
Validation loss: 1.8588550295881046

Epoch: 5| Step: 4
Training loss: 2.189180850982666
Validation loss: 1.8819239460011965

Epoch: 5| Step: 5
Training loss: 1.4593489170074463
Validation loss: 1.86846915752657

Epoch: 5| Step: 6
Training loss: 2.1078944206237793
Validation loss: 1.8625824169446064

Epoch: 5| Step: 7
Training loss: 1.1485636234283447
Validation loss: 1.8779338393160092

Epoch: 5| Step: 8
Training loss: 1.6744884252548218
Validation loss: 1.870710269097359

Epoch: 5| Step: 9
Training loss: 2.194474697113037
Validation loss: 1.867867970979342

Epoch: 5| Step: 10
Training loss: 1.988971471786499
Validation loss: 1.8611129714596657

Epoch: 200| Step: 0
Training loss: 1.8356536626815796
Validation loss: 1.8487892381606563

Epoch: 5| Step: 1
Training loss: 1.7137229442596436
Validation loss: 1.8775082390795472

Epoch: 5| Step: 2
Training loss: 2.507289409637451
Validation loss: 1.86400011790696

Epoch: 5| Step: 3
Training loss: 1.6428035497665405
Validation loss: 1.8705726977317565

Epoch: 5| Step: 4
Training loss: 1.9446719884872437
Validation loss: 1.8652643490863103

Epoch: 5| Step: 5
Training loss: 1.9429209232330322
Validation loss: 1.872631844653878

Epoch: 5| Step: 6
Training loss: 2.0489680767059326
Validation loss: 1.88401884161016

Epoch: 5| Step: 7
Training loss: 1.6801353693008423
Validation loss: 1.873369380991946

Epoch: 5| Step: 8
Training loss: 1.4959089756011963
Validation loss: 1.870588820467713

Epoch: 5| Step: 9
Training loss: 1.5118744373321533
Validation loss: 1.8542456524346465

Epoch: 5| Step: 10
Training loss: 1.888323187828064
Validation loss: 1.8670372783496816

Epoch: 201| Step: 0
Training loss: 1.8280588388442993
Validation loss: 1.8756155262711227

Epoch: 5| Step: 1
Training loss: 1.8499481678009033
Validation loss: 1.8594087785290134

Epoch: 5| Step: 2
Training loss: 1.8460029363632202
Validation loss: 1.873296845343805

Epoch: 5| Step: 3
Training loss: 1.6444066762924194
Validation loss: 1.8669270405205347

Epoch: 5| Step: 4
Training loss: 1.6620620489120483
Validation loss: 1.8783300820217337

Epoch: 5| Step: 5
Training loss: 2.121929883956909
Validation loss: 1.8881148125535698

Epoch: 5| Step: 6
Training loss: 1.4970296621322632
Validation loss: 1.8739242963893439

Epoch: 5| Step: 7
Training loss: 1.9082672595977783
Validation loss: 1.8682849855833157

Epoch: 5| Step: 8
Training loss: 1.962866187095642
Validation loss: 1.888352858122959

Epoch: 5| Step: 9
Training loss: 1.8869407176971436
Validation loss: 1.8761287209808186

Epoch: 5| Step: 10
Training loss: 1.7932783365249634
Validation loss: 1.8730822327316448

Epoch: 202| Step: 0
Training loss: 2.215209484100342
Validation loss: 1.8781795668345627

Epoch: 5| Step: 1
Training loss: 1.7794862985610962
Validation loss: 1.8800197327008812

Epoch: 5| Step: 2
Training loss: 1.8658746480941772
Validation loss: 1.880701623937135

Epoch: 5| Step: 3
Training loss: 1.6326801776885986
Validation loss: 1.9023317021708335

Epoch: 5| Step: 4
Training loss: 2.0095086097717285
Validation loss: 1.892168430871861

Epoch: 5| Step: 5
Training loss: 1.5009753704071045
Validation loss: 1.8812765940543144

Epoch: 5| Step: 6
Training loss: 1.7965351343154907
Validation loss: 1.892036316215351

Epoch: 5| Step: 7
Training loss: 2.0407938957214355
Validation loss: 1.877021558823124

Epoch: 5| Step: 8
Training loss: 1.5041608810424805
Validation loss: 1.8749592547775598

Epoch: 5| Step: 9
Training loss: 2.3152620792388916
Validation loss: 1.880252245933779

Epoch: 5| Step: 10
Training loss: 1.5145214796066284
Validation loss: 1.8935475221244238

Epoch: 203| Step: 0
Training loss: 1.673174500465393
Validation loss: 1.9046555603704145

Epoch: 5| Step: 1
Training loss: 2.0213775634765625
Validation loss: 1.8996342805124098

Epoch: 5| Step: 2
Training loss: 1.4601960182189941
Validation loss: 1.8775759627742152

Epoch: 5| Step: 3
Training loss: 2.026045322418213
Validation loss: 1.9159210856242845

Epoch: 5| Step: 4
Training loss: 1.3087118864059448
Validation loss: 1.9079769285776282

Epoch: 5| Step: 5
Training loss: 2.5436739921569824
Validation loss: 1.8755516006100563

Epoch: 5| Step: 6
Training loss: 1.6351311206817627
Validation loss: 1.8832060675467215

Epoch: 5| Step: 7
Training loss: 2.105076551437378
Validation loss: 1.904154130207595

Epoch: 5| Step: 8
Training loss: 1.6738207340240479
Validation loss: 1.9016381450878677

Epoch: 5| Step: 9
Training loss: 1.8516638278961182
Validation loss: 1.8783057274356965

Epoch: 5| Step: 10
Training loss: 1.9455093145370483
Validation loss: 1.8794834357435986

Epoch: 204| Step: 0
Training loss: 2.3346190452575684
Validation loss: 1.872330520742683

Epoch: 5| Step: 1
Training loss: 1.7403361797332764
Validation loss: 1.9040457420451666

Epoch: 5| Step: 2
Training loss: 2.1016108989715576
Validation loss: 1.8920020518764373

Epoch: 5| Step: 3
Training loss: 1.607885718345642
Validation loss: 1.878329735930248

Epoch: 5| Step: 4
Training loss: 1.7316913604736328
Validation loss: 1.894644021987915

Epoch: 5| Step: 5
Training loss: 1.7808809280395508
Validation loss: 1.9115251469355758

Epoch: 5| Step: 6
Training loss: 1.3492488861083984
Validation loss: 1.9021396739508516

Epoch: 5| Step: 7
Training loss: 2.197587728500366
Validation loss: 1.8897460737536032

Epoch: 5| Step: 8
Training loss: 1.7999413013458252
Validation loss: 1.8656105790086972

Epoch: 5| Step: 9
Training loss: 1.433552861213684
Validation loss: 1.8831571161106069

Epoch: 5| Step: 10
Training loss: 2.0818734169006348
Validation loss: 1.8927855363456152

Epoch: 205| Step: 0
Training loss: 1.7281595468521118
Validation loss: 1.8615642516843733

Epoch: 5| Step: 1
Training loss: 1.7775611877441406
Validation loss: 1.8907827574719664

Epoch: 5| Step: 2
Training loss: 2.217472553253174
Validation loss: 1.8463406152622674

Epoch: 5| Step: 3
Training loss: 2.0931336879730225
Validation loss: 1.8905390001112414

Epoch: 5| Step: 4
Training loss: 2.6192615032196045
Validation loss: 1.8918364919641966

Epoch: 5| Step: 5
Training loss: 1.8172857761383057
Validation loss: 1.8807825234628492

Epoch: 5| Step: 6
Training loss: 1.314012050628662
Validation loss: 1.859280756724778

Epoch: 5| Step: 7
Training loss: 1.706632375717163
Validation loss: 1.8657281873046712

Epoch: 5| Step: 8
Training loss: 1.49741792678833
Validation loss: 1.8698305109495759

Epoch: 5| Step: 9
Training loss: 1.6231253147125244
Validation loss: 1.850531784437036

Epoch: 5| Step: 10
Training loss: 1.674529790878296
Validation loss: 1.8737385708798644

Epoch: 206| Step: 0
Training loss: 2.0024096965789795
Validation loss: 1.8897965851650442

Epoch: 5| Step: 1
Training loss: 1.8395885229110718
Validation loss: 1.8577657745730491

Epoch: 5| Step: 2
Training loss: 1.8124396800994873
Validation loss: 1.8678258631819038

Epoch: 5| Step: 3
Training loss: 1.9832226037979126
Validation loss: 1.8396995759779406

Epoch: 5| Step: 4
Training loss: 1.253507375717163
Validation loss: 1.880931015937559

Epoch: 5| Step: 5
Training loss: 1.9208905696868896
Validation loss: 1.8950579525322042

Epoch: 5| Step: 6
Training loss: 1.627403974533081
Validation loss: 1.8696421243811165

Epoch: 5| Step: 7
Training loss: 2.449122190475464
Validation loss: 1.892397048652813

Epoch: 5| Step: 8
Training loss: 1.6474624872207642
Validation loss: 1.8756981383087814

Epoch: 5| Step: 9
Training loss: 2.045267105102539
Validation loss: 1.8825920570281245

Epoch: 5| Step: 10
Training loss: 1.3721444606781006
Validation loss: 1.8754824951130857

Epoch: 207| Step: 0
Training loss: 1.371643304824829
Validation loss: 1.8981600756286292

Epoch: 5| Step: 1
Training loss: 2.132305145263672
Validation loss: 1.892468624217536

Epoch: 5| Step: 2
Training loss: 1.8743261098861694
Validation loss: 1.900760478870843

Epoch: 5| Step: 3
Training loss: 1.858515739440918
Validation loss: 1.911667626391175

Epoch: 5| Step: 4
Training loss: 2.130934238433838
Validation loss: 1.900721953761193

Epoch: 5| Step: 5
Training loss: 2.0076231956481934
Validation loss: 1.8981399920678907

Epoch: 5| Step: 6
Training loss: 1.4635896682739258
Validation loss: 1.906588057036041

Epoch: 5| Step: 7
Training loss: 1.3676652908325195
Validation loss: 1.9078443870749524

Epoch: 5| Step: 8
Training loss: 1.8405777215957642
Validation loss: 1.927783368736185

Epoch: 5| Step: 9
Training loss: 1.9952703714370728
Validation loss: 1.9209638590453773

Epoch: 5| Step: 10
Training loss: 2.1164865493774414
Validation loss: 1.891775910572339

Epoch: 208| Step: 0
Training loss: 1.7646383047103882
Validation loss: 1.8917607158742926

Epoch: 5| Step: 1
Training loss: 1.5872746706008911
Validation loss: 1.8706357709823116

Epoch: 5| Step: 2
Training loss: 1.899047613143921
Validation loss: 1.867542084827218

Epoch: 5| Step: 3
Training loss: 1.9354766607284546
Validation loss: 1.8875222257388535

Epoch: 5| Step: 4
Training loss: 1.7795394659042358
Validation loss: 1.8689052956078642

Epoch: 5| Step: 5
Training loss: 2.402088165283203
Validation loss: 1.8777204444331508

Epoch: 5| Step: 6
Training loss: 1.7671186923980713
Validation loss: 1.8731153703504992

Epoch: 5| Step: 7
Training loss: 1.3239176273345947
Validation loss: 1.867670323259087

Epoch: 5| Step: 8
Training loss: 1.9805641174316406
Validation loss: 1.8463675911708544

Epoch: 5| Step: 9
Training loss: 2.0878682136535645
Validation loss: 1.868198844694322

Epoch: 5| Step: 10
Training loss: 1.4102646112442017
Validation loss: 1.857870396747384

Epoch: 209| Step: 0
Training loss: 2.208655834197998
Validation loss: 1.862523514737365

Epoch: 5| Step: 1
Training loss: 2.0059452056884766
Validation loss: 1.8574738028228923

Epoch: 5| Step: 2
Training loss: 1.5082356929779053
Validation loss: 1.8657373202744352

Epoch: 5| Step: 3
Training loss: 1.3376796245574951
Validation loss: 1.8905388078381937

Epoch: 5| Step: 4
Training loss: 1.3126671314239502
Validation loss: 1.8914281258019068

Epoch: 5| Step: 5
Training loss: 2.157311201095581
Validation loss: 1.8311019610333186

Epoch: 5| Step: 6
Training loss: 1.5911140441894531
Validation loss: 1.8616675292291949

Epoch: 5| Step: 7
Training loss: 2.4443044662475586
Validation loss: 1.8689804538603751

Epoch: 5| Step: 8
Training loss: 1.2791903018951416
Validation loss: 1.8758427635315926

Epoch: 5| Step: 9
Training loss: 2.052825450897217
Validation loss: 1.869360593057448

Epoch: 5| Step: 10
Training loss: 1.9520940780639648
Validation loss: 1.8817218657462829

Epoch: 210| Step: 0
Training loss: 1.5977287292480469
Validation loss: 1.862699347157632

Epoch: 5| Step: 1
Training loss: 1.9477993249893188
Validation loss: 1.8860152947005404

Epoch: 5| Step: 2
Training loss: 1.7791343927383423
Validation loss: 1.8670449949079944

Epoch: 5| Step: 3
Training loss: 1.8944435119628906
Validation loss: 1.8860833157775223

Epoch: 5| Step: 4
Training loss: 1.7464265823364258
Validation loss: 1.88888382398954

Epoch: 5| Step: 5
Training loss: 1.63058340549469
Validation loss: 1.9053797593680761

Epoch: 5| Step: 6
Training loss: 1.9045393466949463
Validation loss: 1.9059072258651897

Epoch: 5| Step: 7
Training loss: 1.5426819324493408
Validation loss: 1.9411588971332838

Epoch: 5| Step: 8
Training loss: 1.9964860677719116
Validation loss: 1.9077053236705002

Epoch: 5| Step: 9
Training loss: 2.0444488525390625
Validation loss: 1.8920228763293194

Epoch: 5| Step: 10
Training loss: 1.8012293577194214
Validation loss: 1.8805279449750019

Epoch: 211| Step: 0
Training loss: 1.4333378076553345
Validation loss: 1.8904954682114303

Epoch: 5| Step: 1
Training loss: 2.284377336502075
Validation loss: 1.889048243081698

Epoch: 5| Step: 2
Training loss: 1.733881950378418
Validation loss: 1.8714447072757188

Epoch: 5| Step: 3
Training loss: 1.6999351978302002
Validation loss: 1.8666201906819497

Epoch: 5| Step: 4
Training loss: 2.4194116592407227
Validation loss: 1.872310584591281

Epoch: 5| Step: 5
Training loss: 1.9022340774536133
Validation loss: 1.8793410498608825

Epoch: 5| Step: 6
Training loss: 1.7525291442871094
Validation loss: 1.8555684602388771

Epoch: 5| Step: 7
Training loss: 1.693459153175354
Validation loss: 1.871190788925335

Epoch: 5| Step: 8
Training loss: 1.8791840076446533
Validation loss: 1.8551168877591369

Epoch: 5| Step: 9
Training loss: 1.590612530708313
Validation loss: 1.8489974826894782

Epoch: 5| Step: 10
Training loss: 1.387679100036621
Validation loss: 1.8467710095067178

Epoch: 212| Step: 0
Training loss: 1.8037126064300537
Validation loss: 1.840207326796747

Epoch: 5| Step: 1
Training loss: 1.5416555404663086
Validation loss: 1.8569391709502026

Epoch: 5| Step: 2
Training loss: 1.1081104278564453
Validation loss: 1.8636159486668085

Epoch: 5| Step: 3
Training loss: 2.249898910522461
Validation loss: 1.8412426543492142

Epoch: 5| Step: 4
Training loss: 1.4411404132843018
Validation loss: 1.8760680921616093

Epoch: 5| Step: 5
Training loss: 1.871896505355835
Validation loss: 1.8474273527822187

Epoch: 5| Step: 6
Training loss: 2.2588272094726562
Validation loss: 1.869016117947076

Epoch: 5| Step: 7
Training loss: 1.0952001810073853
Validation loss: 1.8612990199878652

Epoch: 5| Step: 8
Training loss: 2.546806573867798
Validation loss: 1.8716124488461403

Epoch: 5| Step: 9
Training loss: 1.3919481039047241
Validation loss: 1.8673927014873875

Epoch: 5| Step: 10
Training loss: 2.5185556411743164
Validation loss: 1.8752609606712096

Epoch: 213| Step: 0
Training loss: 1.9132554531097412
Validation loss: 1.8639281898416498

Epoch: 5| Step: 1
Training loss: 1.839159607887268
Validation loss: 1.8552631614028767

Epoch: 5| Step: 2
Training loss: 1.7154662609100342
Validation loss: 1.871158238380186

Epoch: 5| Step: 3
Training loss: 1.7893768548965454
Validation loss: 1.861890305754959

Epoch: 5| Step: 4
Training loss: 2.1433632373809814
Validation loss: 1.8682614154713129

Epoch: 5| Step: 5
Training loss: 1.928297758102417
Validation loss: 1.9023986965097406

Epoch: 5| Step: 6
Training loss: 1.3727340698242188
Validation loss: 1.8807616964463265

Epoch: 5| Step: 7
Training loss: 1.7585357427597046
Validation loss: 1.849046596916773

Epoch: 5| Step: 8
Training loss: 2.209116220474243
Validation loss: 1.8789994101370535

Epoch: 5| Step: 9
Training loss: 1.469145655632019
Validation loss: 1.8750647729442966

Epoch: 5| Step: 10
Training loss: 1.6198725700378418
Validation loss: 1.874342441558838

Epoch: 214| Step: 0
Training loss: 2.458137273788452
Validation loss: 1.8594130751907185

Epoch: 5| Step: 1
Training loss: 1.3988215923309326
Validation loss: 1.8921378056208293

Epoch: 5| Step: 2
Training loss: 1.8346424102783203
Validation loss: 1.8789696821602442

Epoch: 5| Step: 3
Training loss: 2.200613498687744
Validation loss: 1.8792506789648404

Epoch: 5| Step: 4
Training loss: 1.2693462371826172
Validation loss: 1.9031092889847294

Epoch: 5| Step: 5
Training loss: 1.6418087482452393
Validation loss: 1.9163551766385314

Epoch: 5| Step: 6
Training loss: 1.7767913341522217
Validation loss: 1.8904989227171867

Epoch: 5| Step: 7
Training loss: 1.4749886989593506
Validation loss: 1.907199639146046

Epoch: 5| Step: 8
Training loss: 1.9829200506210327
Validation loss: 1.9014444889560822

Epoch: 5| Step: 9
Training loss: 1.9083728790283203
Validation loss: 1.8846071112540461

Epoch: 5| Step: 10
Training loss: 1.8369940519332886
Validation loss: 1.8874381472987514

Epoch: 215| Step: 0
Training loss: 1.5633354187011719
Validation loss: 1.8687505722045898

Epoch: 5| Step: 1
Training loss: 1.5340484380722046
Validation loss: 1.8921001367671515

Epoch: 5| Step: 2
Training loss: 1.4661785364151
Validation loss: 1.877848163727791

Epoch: 5| Step: 3
Training loss: 2.228759288787842
Validation loss: 1.903900598966947

Epoch: 5| Step: 4
Training loss: 1.6692578792572021
Validation loss: 1.8714297509962512

Epoch: 5| Step: 5
Training loss: 1.9417476654052734
Validation loss: 1.8693190441336682

Epoch: 5| Step: 6
Training loss: 2.210282564163208
Validation loss: 1.9049655083687074

Epoch: 5| Step: 7
Training loss: 1.8310291767120361
Validation loss: 1.8615217016589256

Epoch: 5| Step: 8
Training loss: 1.7954612970352173
Validation loss: 1.841182816413141

Epoch: 5| Step: 9
Training loss: 1.7813069820404053
Validation loss: 1.8767465647830759

Epoch: 5| Step: 10
Training loss: 1.7523432970046997
Validation loss: 1.8659500075924782

Epoch: 216| Step: 0
Training loss: 1.767511010169983
Validation loss: 1.8739797658817743

Epoch: 5| Step: 1
Training loss: 1.6883809566497803
Validation loss: 1.8659040376704226

Epoch: 5| Step: 2
Training loss: 1.6280605792999268
Validation loss: 1.8272420462741648

Epoch: 5| Step: 3
Training loss: 1.3311835527420044
Validation loss: 1.8812664439601283

Epoch: 5| Step: 4
Training loss: 1.6039698123931885
Validation loss: 1.8768271720537575

Epoch: 5| Step: 5
Training loss: 2.35711932182312
Validation loss: 1.860976788305467

Epoch: 5| Step: 6
Training loss: 1.9166584014892578
Validation loss: 1.8780658411723312

Epoch: 5| Step: 7
Training loss: 2.0256454944610596
Validation loss: 1.8488018769089893

Epoch: 5| Step: 8
Training loss: 1.353142499923706
Validation loss: 1.858855632043654

Epoch: 5| Step: 9
Training loss: 2.0438437461853027
Validation loss: 1.8955290150898758

Epoch: 5| Step: 10
Training loss: 1.879226803779602
Validation loss: 1.8846742260840632

Epoch: 217| Step: 0
Training loss: 1.3293571472167969
Validation loss: 1.8677970440157

Epoch: 5| Step: 1
Training loss: 1.8198213577270508
Validation loss: 1.8874809344609578

Epoch: 5| Step: 2
Training loss: 1.3279852867126465
Validation loss: 1.8673731768003075

Epoch: 5| Step: 3
Training loss: 1.9498398303985596
Validation loss: 1.8877738163035402

Epoch: 5| Step: 4
Training loss: 1.5941413640975952
Validation loss: 1.875861663972178

Epoch: 5| Step: 5
Training loss: 2.377945899963379
Validation loss: 1.887583355749807

Epoch: 5| Step: 6
Training loss: 1.7675880193710327
Validation loss: 1.8993416806702972

Epoch: 5| Step: 7
Training loss: 1.9670794010162354
Validation loss: 1.8748737599260064

Epoch: 5| Step: 8
Training loss: 1.8638029098510742
Validation loss: 1.8852467703562912

Epoch: 5| Step: 9
Training loss: 2.0817902088165283
Validation loss: 1.8957159467922744

Epoch: 5| Step: 10
Training loss: 1.6725103855133057
Validation loss: 1.8676864459950437

Epoch: 218| Step: 0
Training loss: 1.837592363357544
Validation loss: 1.8603143179288475

Epoch: 5| Step: 1
Training loss: 1.9616222381591797
Validation loss: 1.8669481726102932

Epoch: 5| Step: 2
Training loss: 1.2394441366195679
Validation loss: 1.8674018549662765

Epoch: 5| Step: 3
Training loss: 1.5094144344329834
Validation loss: 1.8595094450058476

Epoch: 5| Step: 4
Training loss: 2.2558536529541016
Validation loss: 1.8598198634321972

Epoch: 5| Step: 5
Training loss: 1.8783775568008423
Validation loss: 1.84563797520053

Epoch: 5| Step: 6
Training loss: 1.6144098043441772
Validation loss: 1.842761585789342

Epoch: 5| Step: 7
Training loss: 1.8762388229370117
Validation loss: 1.844366551727377

Epoch: 5| Step: 8
Training loss: 1.518445611000061
Validation loss: 1.865690819678768

Epoch: 5| Step: 9
Training loss: 2.4721012115478516
Validation loss: 1.8667029065470542

Epoch: 5| Step: 10
Training loss: 1.643574595451355
Validation loss: 1.874993872898881

Epoch: 219| Step: 0
Training loss: 2.4646689891815186
Validation loss: 1.868644199063701

Epoch: 5| Step: 1
Training loss: 0.8373602628707886
Validation loss: 1.8999852647063553

Epoch: 5| Step: 2
Training loss: 1.5175206661224365
Validation loss: 1.8996027772144606

Epoch: 5| Step: 3
Training loss: 2.628244638442993
Validation loss: 1.8903630805271927

Epoch: 5| Step: 4
Training loss: 2.218937397003174
Validation loss: 1.9035505658836775

Epoch: 5| Step: 5
Training loss: 1.6457545757293701
Validation loss: 1.9073215556401077

Epoch: 5| Step: 6
Training loss: 1.8994277715682983
Validation loss: 1.9168085423848962

Epoch: 5| Step: 7
Training loss: 1.6357448101043701
Validation loss: 1.894057555865216

Epoch: 5| Step: 8
Training loss: 1.8155200481414795
Validation loss: 1.940306976277341

Epoch: 5| Step: 9
Training loss: 1.5292174816131592
Validation loss: 1.923532170634116

Epoch: 5| Step: 10
Training loss: 1.4250130653381348
Validation loss: 1.8963385115387619

Epoch: 220| Step: 0
Training loss: 2.063246250152588
Validation loss: 1.9106741105356524

Epoch: 5| Step: 1
Training loss: 1.945211410522461
Validation loss: 1.8743118547624158

Epoch: 5| Step: 2
Training loss: 1.433037281036377
Validation loss: 1.8935234649207002

Epoch: 5| Step: 3
Training loss: 1.447281837463379
Validation loss: 1.8943009338071268

Epoch: 5| Step: 4
Training loss: 1.2783563137054443
Validation loss: 1.881381880852484

Epoch: 5| Step: 5
Training loss: 1.4446483850479126
Validation loss: 1.87998120246395

Epoch: 5| Step: 6
Training loss: 1.7591629028320312
Validation loss: 1.833421068806802

Epoch: 5| Step: 7
Training loss: 2.3347561359405518
Validation loss: 1.8788349910448956

Epoch: 5| Step: 8
Training loss: 2.151034355163574
Validation loss: 1.8638221371558406

Epoch: 5| Step: 9
Training loss: 2.057795524597168
Validation loss: 1.8606978847134499

Epoch: 5| Step: 10
Training loss: 1.892803430557251
Validation loss: 1.883869601834205

Epoch: 221| Step: 0
Training loss: 1.7175096273422241
Validation loss: 1.8703382399774366

Epoch: 5| Step: 1
Training loss: 1.274964451789856
Validation loss: 1.8590426906462638

Epoch: 5| Step: 2
Training loss: 2.1997148990631104
Validation loss: 1.8803698093660417

Epoch: 5| Step: 3
Training loss: 2.336854934692383
Validation loss: 1.840954852360551

Epoch: 5| Step: 4
Training loss: 1.4329736232757568
Validation loss: 1.8682269255320232

Epoch: 5| Step: 5
Training loss: 1.1819067001342773
Validation loss: 1.877040470800092

Epoch: 5| Step: 6
Training loss: 1.7766611576080322
Validation loss: 1.8708883024031115

Epoch: 5| Step: 7
Training loss: 1.7372465133666992
Validation loss: 1.901645314308905

Epoch: 5| Step: 8
Training loss: 1.3239750862121582
Validation loss: 1.8723810385632258

Epoch: 5| Step: 9
Training loss: 2.290651321411133
Validation loss: 1.853741608640199

Epoch: 5| Step: 10
Training loss: 2.178436756134033
Validation loss: 1.8907025450019426

Epoch: 222| Step: 0
Training loss: 1.9342079162597656
Validation loss: 1.8743548893159436

Epoch: 5| Step: 1
Training loss: 1.543733835220337
Validation loss: 1.8817206742942973

Epoch: 5| Step: 2
Training loss: 1.3563793897628784
Validation loss: 1.8759641519156836

Epoch: 5| Step: 3
Training loss: 1.4747718572616577
Validation loss: 1.8585588662855086

Epoch: 5| Step: 4
Training loss: 1.7171211242675781
Validation loss: 1.8626285060759513

Epoch: 5| Step: 5
Training loss: 1.7810941934585571
Validation loss: 1.8619723755826232

Epoch: 5| Step: 6
Training loss: 1.9823977947235107
Validation loss: 1.871333969536648

Epoch: 5| Step: 7
Training loss: 2.018079996109009
Validation loss: 1.8794266267489361

Epoch: 5| Step: 8
Training loss: 2.108847141265869
Validation loss: 1.8738629523143973

Epoch: 5| Step: 9
Training loss: 1.62531316280365
Validation loss: 1.8601526419321697

Epoch: 5| Step: 10
Training loss: 1.9697929620742798
Validation loss: 1.8663858008641068

Epoch: 223| Step: 0
Training loss: 1.6351925134658813
Validation loss: 1.8451991491420294

Epoch: 5| Step: 1
Training loss: 1.8821666240692139
Validation loss: 1.8843310558667747

Epoch: 5| Step: 2
Training loss: 1.121626615524292
Validation loss: 1.8640767066709456

Epoch: 5| Step: 3
Training loss: 2.1483750343322754
Validation loss: 1.853022934288107

Epoch: 5| Step: 4
Training loss: 1.8950754404067993
Validation loss: 1.8400135053101407

Epoch: 5| Step: 5
Training loss: 2.03145170211792
Validation loss: 1.885077835411154

Epoch: 5| Step: 6
Training loss: 2.549471139907837
Validation loss: 1.886900495457393

Epoch: 5| Step: 7
Training loss: 1.4981170892715454
Validation loss: 1.8831712186977427

Epoch: 5| Step: 8
Training loss: 1.2851285934448242
Validation loss: 1.8726383178464827

Epoch: 5| Step: 9
Training loss: 1.6366561651229858
Validation loss: 1.8720570379687893

Epoch: 5| Step: 10
Training loss: 1.7184571027755737
Validation loss: 1.8176709169982581

Epoch: 224| Step: 0
Training loss: 1.324438452720642
Validation loss: 1.8601605994727022

Epoch: 5| Step: 1
Training loss: 2.0163156986236572
Validation loss: 1.8740272880882345

Epoch: 5| Step: 2
Training loss: 1.5663557052612305
Validation loss: 1.8740657055249779

Epoch: 5| Step: 3
Training loss: 1.893416166305542
Validation loss: 1.8744984826733988

Epoch: 5| Step: 4
Training loss: 1.839250922203064
Validation loss: 1.8515139369554416

Epoch: 5| Step: 5
Training loss: 1.8428758382797241
Validation loss: 1.8699951633330314

Epoch: 5| Step: 6
Training loss: 2.1419777870178223
Validation loss: 1.8415105265955771

Epoch: 5| Step: 7
Training loss: 1.7554562091827393
Validation loss: 1.865951499631328

Epoch: 5| Step: 8
Training loss: 1.981954574584961
Validation loss: 1.866794643863555

Epoch: 5| Step: 9
Training loss: 1.3070625066757202
Validation loss: 1.8593361211079422

Epoch: 5| Step: 10
Training loss: 1.7655836343765259
Validation loss: 1.8439987500508626

Epoch: 225| Step: 0
Training loss: 1.7443383932113647
Validation loss: 1.8798118688726937

Epoch: 5| Step: 1
Training loss: 1.7190383672714233
Validation loss: 1.8608287598497124

Epoch: 5| Step: 2
Training loss: 2.2126107215881348
Validation loss: 1.8768173392101

Epoch: 5| Step: 3
Training loss: 2.476038694381714
Validation loss: 1.907695020398786

Epoch: 5| Step: 4
Training loss: 1.7071720361709595
Validation loss: 1.8637963905129382

Epoch: 5| Step: 5
Training loss: 1.604177474975586
Validation loss: 1.8824508408064484

Epoch: 5| Step: 6
Training loss: 1.648651123046875
Validation loss: 1.9242686776704685

Epoch: 5| Step: 7
Training loss: 1.6115868091583252
Validation loss: 1.9058325777771652

Epoch: 5| Step: 8
Training loss: 1.5023932456970215
Validation loss: 1.8968710412261307

Epoch: 5| Step: 9
Training loss: 1.8279752731323242
Validation loss: 1.8743108087970364

Epoch: 5| Step: 10
Training loss: 1.5668039321899414
Validation loss: 1.901150982867005

Epoch: 226| Step: 0
Training loss: 1.5961437225341797
Validation loss: 1.8628515979295135

Epoch: 5| Step: 1
Training loss: 2.1891086101531982
Validation loss: 1.8767755877587102

Epoch: 5| Step: 2
Training loss: 1.4081281423568726
Validation loss: 1.9216006532792123

Epoch: 5| Step: 3
Training loss: 2.119804859161377
Validation loss: 1.8870521540282874

Epoch: 5| Step: 4
Training loss: 1.6283133029937744
Validation loss: 1.8673846080739012

Epoch: 5| Step: 5
Training loss: 2.0788745880126953
Validation loss: 1.8653917902259416

Epoch: 5| Step: 6
Training loss: 1.4189889430999756
Validation loss: 1.8832202162793887

Epoch: 5| Step: 7
Training loss: 2.0918917655944824
Validation loss: 1.899992166026946

Epoch: 5| Step: 8
Training loss: 1.4822529554367065
Validation loss: 1.8641433363319726

Epoch: 5| Step: 9
Training loss: 1.666752576828003
Validation loss: 1.8522996928102227

Epoch: 5| Step: 10
Training loss: 1.5111256837844849
Validation loss: 1.8603466146735734

Epoch: 227| Step: 0
Training loss: 1.5270534753799438
Validation loss: 1.8556685896329983

Epoch: 5| Step: 1
Training loss: 1.6262223720550537
Validation loss: 1.886873532367009

Epoch: 5| Step: 2
Training loss: 1.7760928869247437
Validation loss: 1.8542090000644806

Epoch: 5| Step: 3
Training loss: 2.144436836242676
Validation loss: 1.88700561113255

Epoch: 5| Step: 4
Training loss: 2.2713215351104736
Validation loss: 1.845582046816426

Epoch: 5| Step: 5
Training loss: 1.269335150718689
Validation loss: 1.849616257093286

Epoch: 5| Step: 6
Training loss: 1.6453529596328735
Validation loss: 1.859774124237799

Epoch: 5| Step: 7
Training loss: 1.7266286611557007
Validation loss: 1.873213755187168

Epoch: 5| Step: 8
Training loss: 2.1496713161468506
Validation loss: 1.858604693925509

Epoch: 5| Step: 9
Training loss: 1.4344720840454102
Validation loss: 1.8770506728080012

Epoch: 5| Step: 10
Training loss: 1.7239749431610107
Validation loss: 1.8851892050876413

Epoch: 228| Step: 0
Training loss: 1.9377654790878296
Validation loss: 1.855529377537389

Epoch: 5| Step: 1
Training loss: 1.5814937353134155
Validation loss: 1.8612666091611307

Epoch: 5| Step: 2
Training loss: 1.6850770711898804
Validation loss: 1.8814257165437103

Epoch: 5| Step: 3
Training loss: 2.282331943511963
Validation loss: 1.8600778477166289

Epoch: 5| Step: 4
Training loss: 1.2925474643707275
Validation loss: 1.8538259280625211

Epoch: 5| Step: 5
Training loss: 1.6438747644424438
Validation loss: 1.8632416135521346

Epoch: 5| Step: 6
Training loss: 1.6719520092010498
Validation loss: 1.8456673596494941

Epoch: 5| Step: 7
Training loss: 1.4922583103179932
Validation loss: 1.8766787769973918

Epoch: 5| Step: 8
Training loss: 2.384127378463745
Validation loss: 1.8607829770734232

Epoch: 5| Step: 9
Training loss: 1.4539884328842163
Validation loss: 1.872116078612625

Epoch: 5| Step: 10
Training loss: 2.0530056953430176
Validation loss: 1.8705306796617405

Epoch: 229| Step: 0
Training loss: 1.374133825302124
Validation loss: 1.8664678758190525

Epoch: 5| Step: 1
Training loss: 1.8133751153945923
Validation loss: 1.8701292635292135

Epoch: 5| Step: 2
Training loss: 2.021681070327759
Validation loss: 1.8956567138753913

Epoch: 5| Step: 3
Training loss: 1.9561735391616821
Validation loss: 1.8668894998488887

Epoch: 5| Step: 4
Training loss: 1.624772310256958
Validation loss: 1.8660327747303953

Epoch: 5| Step: 5
Training loss: 1.2620972394943237
Validation loss: 1.8714721023395497

Epoch: 5| Step: 6
Training loss: 1.4357290267944336
Validation loss: 1.861870406776346

Epoch: 5| Step: 7
Training loss: 2.0464730262756348
Validation loss: 1.8696650100010697

Epoch: 5| Step: 8
Training loss: 2.0900678634643555
Validation loss: 1.8679551565518944

Epoch: 5| Step: 9
Training loss: 1.5210250616073608
Validation loss: 1.9150369667237805

Epoch: 5| Step: 10
Training loss: 2.121816635131836
Validation loss: 1.8671733858764812

Epoch: 230| Step: 0
Training loss: 2.1289117336273193
Validation loss: 1.8527861269571448

Epoch: 5| Step: 1
Training loss: 1.4945719242095947
Validation loss: 1.90714317880651

Epoch: 5| Step: 2
Training loss: 1.4042251110076904
Validation loss: 1.8497322015864874

Epoch: 5| Step: 3
Training loss: 1.8559890985488892
Validation loss: 1.8897490898768108

Epoch: 5| Step: 4
Training loss: 1.6848071813583374
Validation loss: 1.861053906461244

Epoch: 5| Step: 5
Training loss: 2.065904140472412
Validation loss: 1.8779282172520955

Epoch: 5| Step: 6
Training loss: 1.8881444931030273
Validation loss: 1.843327691478114

Epoch: 5| Step: 7
Training loss: 1.5235271453857422
Validation loss: 1.8508444268216369

Epoch: 5| Step: 8
Training loss: 1.9876428842544556
Validation loss: 1.882148479902616

Epoch: 5| Step: 9
Training loss: 1.1611449718475342
Validation loss: 1.8777047536706413

Epoch: 5| Step: 10
Training loss: 2.0971171855926514
Validation loss: 1.8592497174457838

Epoch: 231| Step: 0
Training loss: 1.6246439218521118
Validation loss: 1.8547307778430242

Epoch: 5| Step: 1
Training loss: 2.122131824493408
Validation loss: 1.8730690171641688

Epoch: 5| Step: 2
Training loss: 1.5254511833190918
Validation loss: 1.8659711832641273

Epoch: 5| Step: 3
Training loss: 1.4323228597640991
Validation loss: 1.8343617031651158

Epoch: 5| Step: 4
Training loss: 1.9395500421524048
Validation loss: 1.858870546023051

Epoch: 5| Step: 5
Training loss: 2.2617249488830566
Validation loss: 1.8579043688312653

Epoch: 5| Step: 6
Training loss: 1.6989942789077759
Validation loss: 1.8708146490076536

Epoch: 5| Step: 7
Training loss: 1.9618393182754517
Validation loss: 1.8576600820787492

Epoch: 5| Step: 8
Training loss: 1.6117744445800781
Validation loss: 1.8867920816585582

Epoch: 5| Step: 9
Training loss: 1.4327915906906128
Validation loss: 1.8642926792944632

Epoch: 5| Step: 10
Training loss: 1.284112572669983
Validation loss: 1.8473965519218034

Epoch: 232| Step: 0
Training loss: 2.373370885848999
Validation loss: 1.858960759255194

Epoch: 5| Step: 1
Training loss: 1.9046885967254639
Validation loss: 1.8784727832322479

Epoch: 5| Step: 2
Training loss: 1.9845645427703857
Validation loss: 1.8864911961299118

Epoch: 5| Step: 3
Training loss: 2.251978874206543
Validation loss: 1.8818726334520566

Epoch: 5| Step: 4
Training loss: 1.7440866231918335
Validation loss: 1.8653160115723968

Epoch: 5| Step: 5
Training loss: 1.897093415260315
Validation loss: 1.861652402467625

Epoch: 5| Step: 6
Training loss: 1.6080386638641357
Validation loss: 1.8874872115350538

Epoch: 5| Step: 7
Training loss: 1.5324316024780273
Validation loss: 1.883309066936534

Epoch: 5| Step: 8
Training loss: 1.3649260997772217
Validation loss: 1.8586695553154073

Epoch: 5| Step: 9
Training loss: 1.428520917892456
Validation loss: 1.8680024557216193

Epoch: 5| Step: 10
Training loss: 1.1745271682739258
Validation loss: 1.8810044129689534

Epoch: 233| Step: 0
Training loss: 1.8632690906524658
Validation loss: 1.8858517780098865

Epoch: 5| Step: 1
Training loss: 1.716091513633728
Validation loss: 1.862739300215116

Epoch: 5| Step: 2
Training loss: 2.224605083465576
Validation loss: 1.8611504275311705

Epoch: 5| Step: 3
Training loss: 1.8587799072265625
Validation loss: 1.837875703329681

Epoch: 5| Step: 4
Training loss: 1.7548472881317139
Validation loss: 1.8347772616212086

Epoch: 5| Step: 5
Training loss: 1.8511974811553955
Validation loss: 1.8323112546756704

Epoch: 5| Step: 6
Training loss: 1.0691735744476318
Validation loss: 1.8561301615930372

Epoch: 5| Step: 7
Training loss: 1.60653555393219
Validation loss: 1.8637522087302258

Epoch: 5| Step: 8
Training loss: 1.7258485555648804
Validation loss: 1.8350810081728044

Epoch: 5| Step: 9
Training loss: 2.103684663772583
Validation loss: 1.871686218887247

Epoch: 5| Step: 10
Training loss: 1.325716257095337
Validation loss: 1.861222082568753

Epoch: 234| Step: 0
Training loss: 1.0562851428985596
Validation loss: 1.8822923450059788

Epoch: 5| Step: 1
Training loss: 1.6416633129119873
Validation loss: 1.8483078992494972

Epoch: 5| Step: 2
Training loss: 2.398629665374756
Validation loss: 1.8851604794943204

Epoch: 5| Step: 3
Training loss: 1.9440562725067139
Validation loss: 1.8542429298482916

Epoch: 5| Step: 4
Training loss: 1.6204774379730225
Validation loss: 1.8944885500015751

Epoch: 5| Step: 5
Training loss: 1.8453603982925415
Validation loss: 1.8536517568813857

Epoch: 5| Step: 6
Training loss: 1.3859950304031372
Validation loss: 1.8669831124685143

Epoch: 5| Step: 7
Training loss: 2.0690407752990723
Validation loss: 1.8805293062681794

Epoch: 5| Step: 8
Training loss: 1.304909348487854
Validation loss: 1.9201426275314823

Epoch: 5| Step: 9
Training loss: 1.9082447290420532
Validation loss: 1.8786553964819959

Epoch: 5| Step: 10
Training loss: 2.2350127696990967
Validation loss: 1.8896885148940548

Epoch: 235| Step: 0
Training loss: 2.1504995822906494
Validation loss: 1.8701658966720744

Epoch: 5| Step: 1
Training loss: 2.198476791381836
Validation loss: 1.862262801457477

Epoch: 5| Step: 2
Training loss: 2.3697094917297363
Validation loss: 1.8917882596292803

Epoch: 5| Step: 3
Training loss: 1.6514266729354858
Validation loss: 1.879940967405996

Epoch: 5| Step: 4
Training loss: 1.7060282230377197
Validation loss: 1.8707684009305892

Epoch: 5| Step: 5
Training loss: 1.4345006942749023
Validation loss: 1.8661863880772744

Epoch: 5| Step: 6
Training loss: 1.6818246841430664
Validation loss: 1.880156486265121

Epoch: 5| Step: 7
Training loss: 1.4853192567825317
Validation loss: 1.8564530905856882

Epoch: 5| Step: 8
Training loss: 1.5966501235961914
Validation loss: 1.885112649650984

Epoch: 5| Step: 9
Training loss: 1.4922484159469604
Validation loss: 1.9041459201484598

Epoch: 5| Step: 10
Training loss: 1.2961313724517822
Validation loss: 1.8543780170461184

Epoch: 236| Step: 0
Training loss: 1.2935324907302856
Validation loss: 1.8622844539662844

Epoch: 5| Step: 1
Training loss: 1.433611512184143
Validation loss: 1.8276357599484023

Epoch: 5| Step: 2
Training loss: 2.1298556327819824
Validation loss: 1.833397388458252

Epoch: 5| Step: 3
Training loss: 1.692549467086792
Validation loss: 1.8318344675084597

Epoch: 5| Step: 4
Training loss: 1.6400543451309204
Validation loss: 1.8666887731962307

Epoch: 5| Step: 5
Training loss: 1.6900804042816162
Validation loss: 1.8621180980436263

Epoch: 5| Step: 6
Training loss: 1.782625436782837
Validation loss: 1.8710041123051797

Epoch: 5| Step: 7
Training loss: 2.0259366035461426
Validation loss: 1.8504591782887776

Epoch: 5| Step: 8
Training loss: 1.6137588024139404
Validation loss: 1.8567217806334138

Epoch: 5| Step: 9
Training loss: 1.9076032638549805
Validation loss: 1.8794843971088369

Epoch: 5| Step: 10
Training loss: 2.0503292083740234
Validation loss: 1.8416719693009571

Epoch: 237| Step: 0
Training loss: 1.9347718954086304
Validation loss: 1.8799474047076317

Epoch: 5| Step: 1
Training loss: 1.9385669231414795
Validation loss: 1.8392333535737888

Epoch: 5| Step: 2
Training loss: 1.6274150609970093
Validation loss: 1.8711564720317881

Epoch: 5| Step: 3
Training loss: 1.4993715286254883
Validation loss: 1.851778330341462

Epoch: 5| Step: 4
Training loss: 1.7224937677383423
Validation loss: 1.853750390391196

Epoch: 5| Step: 5
Training loss: 1.4053174257278442
Validation loss: 1.86712868367472

Epoch: 5| Step: 6
Training loss: 1.6329848766326904
Validation loss: 1.8831403857918196

Epoch: 5| Step: 7
Training loss: 1.676567792892456
Validation loss: 1.8862503856740973

Epoch: 5| Step: 8
Training loss: 1.5787607431411743
Validation loss: 1.8664976480186626

Epoch: 5| Step: 9
Training loss: 1.9401404857635498
Validation loss: 1.8672690737632014

Epoch: 5| Step: 10
Training loss: 2.0791122913360596
Validation loss: 1.8440288984647362

Epoch: 238| Step: 0
Training loss: 2.12349796295166
Validation loss: 1.8563450844057146

Epoch: 5| Step: 1
Training loss: 2.319591999053955
Validation loss: 1.853437562142649

Epoch: 5| Step: 2
Training loss: 1.9693920612335205
Validation loss: 1.8677159432441957

Epoch: 5| Step: 3
Training loss: 1.4320071935653687
Validation loss: 1.8785829531249179

Epoch: 5| Step: 4
Training loss: 2.153872013092041
Validation loss: 1.8870817666412683

Epoch: 5| Step: 5
Training loss: 1.117577075958252
Validation loss: 1.8391907984210598

Epoch: 5| Step: 6
Training loss: 1.879948377609253
Validation loss: 1.8345250147645191

Epoch: 5| Step: 7
Training loss: 1.3458950519561768
Validation loss: 1.8643186310286164

Epoch: 5| Step: 8
Training loss: 1.7507606744766235
Validation loss: 1.8768711038815078

Epoch: 5| Step: 9
Training loss: 1.4164131879806519
Validation loss: 1.8311562127964471

Epoch: 5| Step: 10
Training loss: 1.5196298360824585
Validation loss: 1.8542196314821962

Epoch: 239| Step: 0
Training loss: 1.6693614721298218
Validation loss: 1.8607059678723734

Epoch: 5| Step: 1
Training loss: 2.1472315788269043
Validation loss: 1.846307853216766

Epoch: 5| Step: 2
Training loss: 2.267777442932129
Validation loss: 1.8426661081211542

Epoch: 5| Step: 3
Training loss: 1.495733380317688
Validation loss: 1.869491531002906

Epoch: 5| Step: 4
Training loss: 1.4140751361846924
Validation loss: 1.8805195644337644

Epoch: 5| Step: 5
Training loss: 1.5708222389221191
Validation loss: 1.830984720619776

Epoch: 5| Step: 6
Training loss: 1.5341650247573853
Validation loss: 1.8530509292438466

Epoch: 5| Step: 7
Training loss: 1.7254688739776611
Validation loss: 1.8387656993763422

Epoch: 5| Step: 8
Training loss: 1.4051780700683594
Validation loss: 1.8347265976731495

Epoch: 5| Step: 9
Training loss: 2.170217990875244
Validation loss: 1.846994330806117

Epoch: 5| Step: 10
Training loss: 1.6201589107513428
Validation loss: 1.83872131634784

Epoch: 240| Step: 0
Training loss: 1.8361291885375977
Validation loss: 1.8473238355369979

Epoch: 5| Step: 1
Training loss: 1.6930968761444092
Validation loss: 1.8473199182941067

Epoch: 5| Step: 2
Training loss: 1.2280738353729248
Validation loss: 1.8697545605321084

Epoch: 5| Step: 3
Training loss: 2.1548166275024414
Validation loss: 1.8446880181630452

Epoch: 5| Step: 4
Training loss: 1.8767125606536865
Validation loss: 1.88082343211738

Epoch: 5| Step: 5
Training loss: 1.4448063373565674
Validation loss: 1.8832631457236506

Epoch: 5| Step: 6
Training loss: 1.9182014465332031
Validation loss: 1.8581408954435779

Epoch: 5| Step: 7
Training loss: 1.3472321033477783
Validation loss: 1.8889012823822677

Epoch: 5| Step: 8
Training loss: 1.7213776111602783
Validation loss: 1.8569580252452562

Epoch: 5| Step: 9
Training loss: 1.7733561992645264
Validation loss: 1.8914266696540258

Epoch: 5| Step: 10
Training loss: 1.8885818719863892
Validation loss: 1.8867594862496981

Epoch: 241| Step: 0
Training loss: 1.3605350255966187
Validation loss: 1.8753977360263947

Epoch: 5| Step: 1
Training loss: 1.8959766626358032
Validation loss: 1.8816216145792315

Epoch: 5| Step: 2
Training loss: 2.5335376262664795
Validation loss: 1.9162658491442282

Epoch: 5| Step: 3
Training loss: 2.029338836669922
Validation loss: 1.9071037025861843

Epoch: 5| Step: 4
Training loss: 1.370288610458374
Validation loss: 1.9366791145775908

Epoch: 5| Step: 5
Training loss: 1.526958703994751
Validation loss: 1.8745209658017723

Epoch: 5| Step: 6
Training loss: 1.767394781112671
Validation loss: 1.8877630515765118

Epoch: 5| Step: 7
Training loss: 1.9851715564727783
Validation loss: 1.897931114319832

Epoch: 5| Step: 8
Training loss: 1.6617931127548218
Validation loss: 1.9172996090304466

Epoch: 5| Step: 9
Training loss: 1.7425634860992432
Validation loss: 1.8580816176629835

Epoch: 5| Step: 10
Training loss: 1.2128452062606812
Validation loss: 1.8810120692817114

Epoch: 242| Step: 0
Training loss: 1.359702229499817
Validation loss: 1.8512619964538082

Epoch: 5| Step: 1
Training loss: 1.8540489673614502
Validation loss: 1.8449863144146499

Epoch: 5| Step: 2
Training loss: 0.9997847676277161
Validation loss: 1.8309491065240675

Epoch: 5| Step: 3
Training loss: 1.5930442810058594
Validation loss: 1.8569391299319524

Epoch: 5| Step: 4
Training loss: 1.9890785217285156
Validation loss: 1.8566494321310392

Epoch: 5| Step: 5
Training loss: 1.9404065608978271
Validation loss: 1.8379260724590671

Epoch: 5| Step: 6
Training loss: 2.5183708667755127
Validation loss: 1.8366589110384706

Epoch: 5| Step: 7
Training loss: 1.354081153869629
Validation loss: 1.838196434000487

Epoch: 5| Step: 8
Training loss: 1.6754662990570068
Validation loss: 1.851244217606001

Epoch: 5| Step: 9
Training loss: 1.7265236377716064
Validation loss: 1.8593626368430354

Epoch: 5| Step: 10
Training loss: 1.891539216041565
Validation loss: 1.8539827741602415

Epoch: 243| Step: 0
Training loss: 1.3900766372680664
Validation loss: 1.8481313297825475

Epoch: 5| Step: 1
Training loss: 2.301637887954712
Validation loss: 1.8795145301408664

Epoch: 5| Step: 2
Training loss: 1.8204290866851807
Validation loss: 1.8673173906982585

Epoch: 5| Step: 3
Training loss: 2.029646396636963
Validation loss: 1.8553874697736514

Epoch: 5| Step: 4
Training loss: 1.4162909984588623
Validation loss: 1.8690760225378058

Epoch: 5| Step: 5
Training loss: 1.7219778299331665
Validation loss: 1.8806263503207956

Epoch: 5| Step: 6
Training loss: 1.3904011249542236
Validation loss: 1.8813597245882916

Epoch: 5| Step: 7
Training loss: 1.9024053812026978
Validation loss: 1.8952074512358634

Epoch: 5| Step: 8
Training loss: 1.2251697778701782
Validation loss: 1.8666819064847884

Epoch: 5| Step: 9
Training loss: 1.4736878871917725
Validation loss: 1.8611554022758239

Epoch: 5| Step: 10
Training loss: 1.9186203479766846
Validation loss: 1.8570650290417414

Epoch: 244| Step: 0
Training loss: 1.9564584493637085
Validation loss: 1.8858950881547825

Epoch: 5| Step: 1
Training loss: 2.222738027572632
Validation loss: 1.8778758587375763

Epoch: 5| Step: 2
Training loss: 1.4715807437896729
Validation loss: 1.8839473121909684

Epoch: 5| Step: 3
Training loss: 1.1204936504364014
Validation loss: 1.8714537620544434

Epoch: 5| Step: 4
Training loss: 2.2050700187683105
Validation loss: 1.8659857755066247

Epoch: 5| Step: 5
Training loss: 1.9543946981430054
Validation loss: 1.8580810075165124

Epoch: 5| Step: 6
Training loss: 1.77022385597229
Validation loss: 1.8633265700391544

Epoch: 5| Step: 7
Training loss: 1.547724962234497
Validation loss: 1.8538086234882314

Epoch: 5| Step: 8
Training loss: 1.4360034465789795
Validation loss: 1.8474637154609925

Epoch: 5| Step: 9
Training loss: 1.4864263534545898
Validation loss: 1.868918215074847

Epoch: 5| Step: 10
Training loss: 1.7192035913467407
Validation loss: 1.8680035080961002

Epoch: 245| Step: 0
Training loss: 1.7354812622070312
Validation loss: 1.8634318510691326

Epoch: 5| Step: 1
Training loss: 1.8679107427597046
Validation loss: 1.8519582492049023

Epoch: 5| Step: 2
Training loss: 1.9953744411468506
Validation loss: 1.8609884246703117

Epoch: 5| Step: 3
Training loss: 1.2930562496185303
Validation loss: 1.840638268378473

Epoch: 5| Step: 4
Training loss: 2.0193991661071777
Validation loss: 1.8479055768700057

Epoch: 5| Step: 5
Training loss: 1.1487914323806763
Validation loss: 1.8538963897253877

Epoch: 5| Step: 6
Training loss: 2.1938297748565674
Validation loss: 1.8688558634891306

Epoch: 5| Step: 7
Training loss: 1.1056506633758545
Validation loss: 1.8598012437102616

Epoch: 5| Step: 8
Training loss: 1.9542810916900635
Validation loss: 1.8426846227338236

Epoch: 5| Step: 9
Training loss: 1.7540994882583618
Validation loss: 1.8764359181927097

Epoch: 5| Step: 10
Training loss: 1.556964635848999
Validation loss: 1.8951367690999021

Epoch: 246| Step: 0
Training loss: 1.988736867904663
Validation loss: 1.8423121308767667

Epoch: 5| Step: 1
Training loss: 2.006596803665161
Validation loss: 1.871314912713984

Epoch: 5| Step: 2
Training loss: 1.4862196445465088
Validation loss: 1.8403938021711124

Epoch: 5| Step: 3
Training loss: 2.1959445476531982
Validation loss: 1.860556920369466

Epoch: 5| Step: 4
Training loss: 1.8302921056747437
Validation loss: 1.8638972620810232

Epoch: 5| Step: 5
Training loss: 1.2514914274215698
Validation loss: 1.8466594103843934

Epoch: 5| Step: 6
Training loss: 1.8746349811553955
Validation loss: 1.861342614696872

Epoch: 5| Step: 7
Training loss: 1.5769550800323486
Validation loss: 1.8849251526658253

Epoch: 5| Step: 8
Training loss: 1.8847293853759766
Validation loss: 1.8548148396194621

Epoch: 5| Step: 9
Training loss: 1.5368869304656982
Validation loss: 1.8762448436470442

Epoch: 5| Step: 10
Training loss: 1.158700704574585
Validation loss: 1.8673455766452256

Epoch: 247| Step: 0
Training loss: 1.9031349420547485
Validation loss: 1.850197684380316

Epoch: 5| Step: 1
Training loss: 1.9298546314239502
Validation loss: 1.8341410672792824

Epoch: 5| Step: 2
Training loss: 2.1210930347442627
Validation loss: 1.8627870364855694

Epoch: 5| Step: 3
Training loss: 1.8373512029647827
Validation loss: 1.8394687175750732

Epoch: 5| Step: 4
Training loss: 1.6223418712615967
Validation loss: 1.867912132252929

Epoch: 5| Step: 5
Training loss: 2.0785059928894043
Validation loss: 1.8628669015822872

Epoch: 5| Step: 6
Training loss: 0.9916020631790161
Validation loss: 1.841060325663577

Epoch: 5| Step: 7
Training loss: 1.4984464645385742
Validation loss: 1.845908413651169

Epoch: 5| Step: 8
Training loss: 1.5229218006134033
Validation loss: 1.8535760756461852

Epoch: 5| Step: 9
Training loss: 1.2894744873046875
Validation loss: 1.8563157243113364

Epoch: 5| Step: 10
Training loss: 2.009363889694214
Validation loss: 1.8468054430459135

Epoch: 248| Step: 0
Training loss: 2.083519458770752
Validation loss: 1.8764507232173797

Epoch: 5| Step: 1
Training loss: 1.6064536571502686
Validation loss: 1.8598073054385442

Epoch: 5| Step: 2
Training loss: 1.8241539001464844
Validation loss: 1.879514407086116

Epoch: 5| Step: 3
Training loss: 1.8304431438446045
Validation loss: 1.861824482999822

Epoch: 5| Step: 4
Training loss: 1.7094409465789795
Validation loss: 1.8429644953820012

Epoch: 5| Step: 5
Training loss: 1.9211890697479248
Validation loss: 1.8593576159528507

Epoch: 5| Step: 6
Training loss: 1.4359122514724731
Validation loss: 1.8522490365530855

Epoch: 5| Step: 7
Training loss: 1.4758479595184326
Validation loss: 1.8828770563166628

Epoch: 5| Step: 8
Training loss: 1.5387545824050903
Validation loss: 1.9053889756561608

Epoch: 5| Step: 9
Training loss: 1.3933398723602295
Validation loss: 1.8683015890018915

Epoch: 5| Step: 10
Training loss: 1.756367564201355
Validation loss: 1.8629602475832867

Epoch: 249| Step: 0
Training loss: 1.7864032983779907
Validation loss: 1.8694694144751436

Epoch: 5| Step: 1
Training loss: 1.2192649841308594
Validation loss: 1.873886731363112

Epoch: 5| Step: 2
Training loss: 1.2547597885131836
Validation loss: 1.860507353659599

Epoch: 5| Step: 3
Training loss: 1.4658668041229248
Validation loss: 1.8669584156364523

Epoch: 5| Step: 4
Training loss: 1.9167054891586304
Validation loss: 1.874149707055861

Epoch: 5| Step: 5
Training loss: 1.630353569984436
Validation loss: 1.8703058868326166

Epoch: 5| Step: 6
Training loss: 2.0066092014312744
Validation loss: 1.8833946733064548

Epoch: 5| Step: 7
Training loss: 1.57707941532135
Validation loss: 1.8630427237479918

Epoch: 5| Step: 8
Training loss: 1.9511823654174805
Validation loss: 1.8675414516079811

Epoch: 5| Step: 9
Training loss: 1.6807434558868408
Validation loss: 1.856248850463539

Epoch: 5| Step: 10
Training loss: 2.0194928646087646
Validation loss: 1.8543800038676108

Epoch: 250| Step: 0
Training loss: 2.0436172485351562
Validation loss: 1.842615803082784

Epoch: 5| Step: 1
Training loss: 1.3343086242675781
Validation loss: 1.8536279457871632

Epoch: 5| Step: 2
Training loss: 1.685119867324829
Validation loss: 1.835916675547118

Epoch: 5| Step: 3
Training loss: 1.360088586807251
Validation loss: 1.8424197781470515

Epoch: 5| Step: 4
Training loss: 1.7272546291351318
Validation loss: 1.8313442045642483

Epoch: 5| Step: 5
Training loss: 1.9822301864624023
Validation loss: 1.8200013906724992

Epoch: 5| Step: 6
Training loss: 1.1372333765029907
Validation loss: 1.8354647518486105

Epoch: 5| Step: 7
Training loss: 1.6403955221176147
Validation loss: 1.8363734816992154

Epoch: 5| Step: 8
Training loss: 2.2879514694213867
Validation loss: 1.8325740983409267

Epoch: 5| Step: 9
Training loss: 1.7017810344696045
Validation loss: 1.8550725393397833

Epoch: 5| Step: 10
Training loss: 2.0410518646240234
Validation loss: 1.8418574615191388

Epoch: 251| Step: 0
Training loss: 1.522552728652954
Validation loss: 1.8395345198210848

Epoch: 5| Step: 1
Training loss: 1.5662113428115845
Validation loss: 1.8729316803716844

Epoch: 5| Step: 2
Training loss: 1.1665199995040894
Validation loss: 1.849776985824749

Epoch: 5| Step: 3
Training loss: 2.0164499282836914
Validation loss: 1.876025911300413

Epoch: 5| Step: 4
Training loss: 2.1204357147216797
Validation loss: 1.8500604680789414

Epoch: 5| Step: 5
Training loss: 1.5019004344940186
Validation loss: 1.8892189072024437

Epoch: 5| Step: 6
Training loss: 1.9028819799423218
Validation loss: 1.9021184572609522

Epoch: 5| Step: 7
Training loss: 1.7014858722686768
Validation loss: 1.8853841020214943

Epoch: 5| Step: 8
Training loss: 1.8916488885879517
Validation loss: 1.9101909565669235

Epoch: 5| Step: 9
Training loss: 1.5577671527862549
Validation loss: 1.9116654575511973

Epoch: 5| Step: 10
Training loss: 1.9081039428710938
Validation loss: 1.9121468144078408

Epoch: 252| Step: 0
Training loss: 1.855522871017456
Validation loss: 1.9138998421289588

Epoch: 5| Step: 1
Training loss: 2.1021578311920166
Validation loss: 1.8588197077474287

Epoch: 5| Step: 2
Training loss: 1.5308730602264404
Validation loss: 1.9002606894380303

Epoch: 5| Step: 3
Training loss: 1.8370182514190674
Validation loss: 1.8894259622020106

Epoch: 5| Step: 4
Training loss: 1.30880606174469
Validation loss: 1.8552424125773932

Epoch: 5| Step: 5
Training loss: 2.0986130237579346
Validation loss: 1.857806101922066

Epoch: 5| Step: 6
Training loss: 1.6340210437774658
Validation loss: 1.8615254304742301

Epoch: 5| Step: 7
Training loss: 1.5537458658218384
Validation loss: 1.8530937394788187

Epoch: 5| Step: 8
Training loss: 1.3091552257537842
Validation loss: 1.8435850617706135

Epoch: 5| Step: 9
Training loss: 2.431018114089966
Validation loss: 1.8553397963123937

Epoch: 5| Step: 10
Training loss: 1.1394339799880981
Validation loss: 1.8182020571924025

Epoch: 253| Step: 0
Training loss: 1.4508397579193115
Validation loss: 1.8277599747462938

Epoch: 5| Step: 1
Training loss: 1.6285136938095093
Validation loss: 1.8141097702005857

Epoch: 5| Step: 2
Training loss: 1.8600683212280273
Validation loss: 1.817241758428594

Epoch: 5| Step: 3
Training loss: 1.8336366415023804
Validation loss: 1.865042991535638

Epoch: 5| Step: 4
Training loss: 1.4132320880889893
Validation loss: 1.8491199272935108

Epoch: 5| Step: 5
Training loss: 1.8172237873077393
Validation loss: 1.850081915496498

Epoch: 5| Step: 6
Training loss: 1.7147077322006226
Validation loss: 1.838884626665423

Epoch: 5| Step: 7
Training loss: 1.6197850704193115
Validation loss: 1.8430659001873386

Epoch: 5| Step: 8
Training loss: 1.2138087749481201
Validation loss: 1.8244177731134559

Epoch: 5| Step: 9
Training loss: 1.8694959878921509
Validation loss: 1.8595230271739345

Epoch: 5| Step: 10
Training loss: 2.22772479057312
Validation loss: 1.8522244057347697

Epoch: 254| Step: 0
Training loss: 1.303099274635315
Validation loss: 1.8668956577136953

Epoch: 5| Step: 1
Training loss: 1.3606687784194946
Validation loss: 1.86585965207828

Epoch: 5| Step: 2
Training loss: 0.9214538335800171
Validation loss: 1.8682533669215378

Epoch: 5| Step: 3
Training loss: 1.7631279230117798
Validation loss: 1.8845369482553134

Epoch: 5| Step: 4
Training loss: 1.5544182062149048
Validation loss: 1.858160525239924

Epoch: 5| Step: 5
Training loss: 2.7984774112701416
Validation loss: 1.8736787585801975

Epoch: 5| Step: 6
Training loss: 1.6197471618652344
Validation loss: 1.8977902884124427

Epoch: 5| Step: 7
Training loss: 1.079849362373352
Validation loss: 1.852361657286203

Epoch: 5| Step: 8
Training loss: 1.5799107551574707
Validation loss: 1.874613308137463

Epoch: 5| Step: 9
Training loss: 2.273113965988159
Validation loss: 1.871938887462821

Epoch: 5| Step: 10
Training loss: 2.41473388671875
Validation loss: 1.8742226221228158

Epoch: 255| Step: 0
Training loss: 1.9478530883789062
Validation loss: 1.8741425891076364

Epoch: 5| Step: 1
Training loss: 1.967291235923767
Validation loss: 1.876279697623304

Epoch: 5| Step: 2
Training loss: 1.316293478012085
Validation loss: 1.8314755975559194

Epoch: 5| Step: 3
Training loss: 2.2032923698425293
Validation loss: 1.8710508064557148

Epoch: 5| Step: 4
Training loss: 1.42079758644104
Validation loss: 1.8460839448436615

Epoch: 5| Step: 5
Training loss: 1.5398626327514648
Validation loss: 1.8598205248514812

Epoch: 5| Step: 6
Training loss: 1.2416112422943115
Validation loss: 1.8627006315415906

Epoch: 5| Step: 7
Training loss: 1.4698938131332397
Validation loss: 1.8599429156190606

Epoch: 5| Step: 8
Training loss: 1.7942510843276978
Validation loss: 1.8526525817891604

Epoch: 5| Step: 9
Training loss: 1.6969130039215088
Validation loss: 1.8611428891458819

Epoch: 5| Step: 10
Training loss: 1.9345868825912476
Validation loss: 1.830108965596845

Epoch: 256| Step: 0
Training loss: 1.4838875532150269
Validation loss: 1.8605505843316354

Epoch: 5| Step: 1
Training loss: 1.494179368019104
Validation loss: 1.8465433633455666

Epoch: 5| Step: 2
Training loss: 2.031756639480591
Validation loss: 1.8588915909490278

Epoch: 5| Step: 3
Training loss: 0.9319513440132141
Validation loss: 1.8582003552426574

Epoch: 5| Step: 4
Training loss: 2.1542820930480957
Validation loss: 1.8319756830892255

Epoch: 5| Step: 5
Training loss: 1.4628512859344482
Validation loss: 1.8668575620138517

Epoch: 5| Step: 6
Training loss: 2.048379898071289
Validation loss: 1.8783206196241482

Epoch: 5| Step: 7
Training loss: 1.4027798175811768
Validation loss: 1.88505373718918

Epoch: 5| Step: 8
Training loss: 1.3568246364593506
Validation loss: 1.8587229841498918

Epoch: 5| Step: 9
Training loss: 2.22387433052063
Validation loss: 1.8573900474015104

Epoch: 5| Step: 10
Training loss: 2.1454288959503174
Validation loss: 1.865106721078196

Epoch: 257| Step: 0
Training loss: 1.4734967947006226
Validation loss: 1.841626492879724

Epoch: 5| Step: 1
Training loss: 1.3510547876358032
Validation loss: 1.849796841221471

Epoch: 5| Step: 2
Training loss: 1.8734099864959717
Validation loss: 1.8457631218817927

Epoch: 5| Step: 3
Training loss: 1.6967589855194092
Validation loss: 1.8794738990004345

Epoch: 5| Step: 4
Training loss: 1.6421476602554321
Validation loss: 1.854273126971337

Epoch: 5| Step: 5
Training loss: 1.804561972618103
Validation loss: 1.8331454492384387

Epoch: 5| Step: 6
Training loss: 1.4401614665985107
Validation loss: 1.8464311066494192

Epoch: 5| Step: 7
Training loss: 2.0106663703918457
Validation loss: 1.8418811931405017

Epoch: 5| Step: 8
Training loss: 2.005821466445923
Validation loss: 1.8308283846865419

Epoch: 5| Step: 9
Training loss: 1.7133888006210327
Validation loss: 1.8423134229516471

Epoch: 5| Step: 10
Training loss: 1.3158029317855835
Validation loss: 1.848728451677548

Epoch: 258| Step: 0
Training loss: 1.2991888523101807
Validation loss: 1.8510708642262284

Epoch: 5| Step: 1
Training loss: 1.9374659061431885
Validation loss: 1.8564153204682052

Epoch: 5| Step: 2
Training loss: 2.2401785850524902
Validation loss: 1.8518084172279603

Epoch: 5| Step: 3
Training loss: 1.984429955482483
Validation loss: 1.8484343521056636

Epoch: 5| Step: 4
Training loss: 2.073516845703125
Validation loss: 1.8276480333779448

Epoch: 5| Step: 5
Training loss: 1.296987771987915
Validation loss: 1.855397637172412

Epoch: 5| Step: 6
Training loss: 1.9218336343765259
Validation loss: 1.8670026775329345

Epoch: 5| Step: 7
Training loss: 1.1815674304962158
Validation loss: 1.8665345586756223

Epoch: 5| Step: 8
Training loss: 1.5006022453308105
Validation loss: 1.8475134000983289

Epoch: 5| Step: 9
Training loss: 1.570417046546936
Validation loss: 1.8737541347421625

Epoch: 5| Step: 10
Training loss: 1.4857254028320312
Validation loss: 1.8758734349281556

Epoch: 259| Step: 0
Training loss: 1.3849008083343506
Validation loss: 1.880822822611819

Epoch: 5| Step: 1
Training loss: 0.9761373400688171
Validation loss: 1.8704904433219665

Epoch: 5| Step: 2
Training loss: 1.608646035194397
Validation loss: 1.8782896969908027

Epoch: 5| Step: 3
Training loss: 2.014280319213867
Validation loss: 1.8746465636837868

Epoch: 5| Step: 4
Training loss: 1.4956519603729248
Validation loss: 1.846944897405563

Epoch: 5| Step: 5
Training loss: 1.351610541343689
Validation loss: 1.8318359800564346

Epoch: 5| Step: 6
Training loss: 1.829646110534668
Validation loss: 1.864221522884984

Epoch: 5| Step: 7
Training loss: 2.3129210472106934
Validation loss: 1.8396608239860945

Epoch: 5| Step: 8
Training loss: 1.712303876876831
Validation loss: 1.8526460868056103

Epoch: 5| Step: 9
Training loss: 1.8969557285308838
Validation loss: 1.8345251378192697

Epoch: 5| Step: 10
Training loss: 1.826945185661316
Validation loss: 1.8416481325703282

Epoch: 260| Step: 0
Training loss: 1.2027405500411987
Validation loss: 1.8409073686087003

Epoch: 5| Step: 1
Training loss: 1.8159822225570679
Validation loss: 1.8105245956810572

Epoch: 5| Step: 2
Training loss: 1.9968430995941162
Validation loss: 1.8393849057535971

Epoch: 5| Step: 3
Training loss: 1.31576406955719
Validation loss: 1.8154324177772767

Epoch: 5| Step: 4
Training loss: 1.6622333526611328
Validation loss: 1.844986178541696

Epoch: 5| Step: 5
Training loss: 1.8658866882324219
Validation loss: 1.7941917040014779

Epoch: 5| Step: 6
Training loss: 1.4048399925231934
Validation loss: 1.8425448376645324

Epoch: 5| Step: 7
Training loss: 2.1309468746185303
Validation loss: 1.835289998721051

Epoch: 5| Step: 8
Training loss: 1.494922161102295
Validation loss: 1.8400301177014586

Epoch: 5| Step: 9
Training loss: 2.2668490409851074
Validation loss: 1.864283512997371

Epoch: 5| Step: 10
Training loss: 1.4298269748687744
Validation loss: 1.8678117503402054

Epoch: 261| Step: 0
Training loss: 1.3336269855499268
Validation loss: 1.861670458188621

Epoch: 5| Step: 1
Training loss: 2.215344190597534
Validation loss: 1.8631774610088718

Epoch: 5| Step: 2
Training loss: 1.5743473768234253
Validation loss: 1.8705763124650525

Epoch: 5| Step: 3
Training loss: 1.591627597808838
Validation loss: 1.8596111907753894

Epoch: 5| Step: 4
Training loss: 1.2325220108032227
Validation loss: 1.912954673972181

Epoch: 5| Step: 5
Training loss: 2.209817886352539
Validation loss: 1.8900705781034244

Epoch: 5| Step: 6
Training loss: 1.6154178380966187
Validation loss: 1.8315151224854171

Epoch: 5| Step: 7
Training loss: 1.4228541851043701
Validation loss: 1.874212275269211

Epoch: 5| Step: 8
Training loss: 2.028672695159912
Validation loss: 1.8508331416755595

Epoch: 5| Step: 9
Training loss: 1.476963758468628
Validation loss: 1.8622903477761052

Epoch: 5| Step: 10
Training loss: 1.4277372360229492
Validation loss: 1.8901909346221595

Epoch: 262| Step: 0
Training loss: 1.742395043373108
Validation loss: 1.8856905429593978

Epoch: 5| Step: 1
Training loss: 1.9078766107559204
Validation loss: 1.900344139786177

Epoch: 5| Step: 2
Training loss: 1.7384283542633057
Validation loss: 1.890892291581759

Epoch: 5| Step: 3
Training loss: 1.1750133037567139
Validation loss: 1.839472798890965

Epoch: 5| Step: 4
Training loss: 1.9085590839385986
Validation loss: 1.8843028173651746

Epoch: 5| Step: 5
Training loss: 1.786085844039917
Validation loss: 1.864597915321268

Epoch: 5| Step: 6
Training loss: 1.9106066226959229
Validation loss: 1.8351655416591193

Epoch: 5| Step: 7
Training loss: 1.4161831140518188
Validation loss: 1.868570771268619

Epoch: 5| Step: 8
Training loss: 1.4724812507629395
Validation loss: 1.8501855686146726

Epoch: 5| Step: 9
Training loss: 1.5538477897644043
Validation loss: 1.8560441258133098

Epoch: 5| Step: 10
Training loss: 2.002535343170166
Validation loss: 1.8569011060140466

Epoch: 263| Step: 0
Training loss: 1.4107158184051514
Validation loss: 1.8462878914289578

Epoch: 5| Step: 1
Training loss: 1.7634903192520142
Validation loss: 1.8831916983409593

Epoch: 5| Step: 2
Training loss: 1.4924466609954834
Validation loss: 1.8523833213313934

Epoch: 5| Step: 3
Training loss: 1.4564095735549927
Validation loss: 1.8547061207473918

Epoch: 5| Step: 4
Training loss: 1.3155542612075806
Validation loss: 1.858360372563844

Epoch: 5| Step: 5
Training loss: 1.8049169778823853
Validation loss: 1.8448117958602084

Epoch: 5| Step: 6
Training loss: 1.8530670404434204
Validation loss: 1.8624826861966042

Epoch: 5| Step: 7
Training loss: 2.179159641265869
Validation loss: 1.913099294067711

Epoch: 5| Step: 8
Training loss: 1.928577184677124
Validation loss: 1.876133841852988

Epoch: 5| Step: 9
Training loss: 1.6179739236831665
Validation loss: 1.864402017285747

Epoch: 5| Step: 10
Training loss: 1.4877769947052002
Validation loss: 1.8759014978203723

Epoch: 264| Step: 0
Training loss: 1.5188573598861694
Validation loss: 1.8674930475091422

Epoch: 5| Step: 1
Training loss: 1.4960752725601196
Validation loss: 1.8821659677772111

Epoch: 5| Step: 2
Training loss: 1.7439550161361694
Validation loss: 1.8667618818180536

Epoch: 5| Step: 3
Training loss: 1.7101809978485107
Validation loss: 1.891211473813621

Epoch: 5| Step: 4
Training loss: 2.31990647315979
Validation loss: 1.8526104419462142

Epoch: 5| Step: 5
Training loss: 1.2688939571380615
Validation loss: 1.849253478870597

Epoch: 5| Step: 6
Training loss: 1.8978807926177979
Validation loss: 1.8424222110420145

Epoch: 5| Step: 7
Training loss: 1.825850486755371
Validation loss: 1.836740985993416

Epoch: 5| Step: 8
Training loss: 1.7436081171035767
Validation loss: 1.8650493429553123

Epoch: 5| Step: 9
Training loss: 1.1331831216812134
Validation loss: 1.8594923557773713

Epoch: 5| Step: 10
Training loss: 1.506584882736206
Validation loss: 1.8540706198702577

Epoch: 265| Step: 0
Training loss: 1.4396311044692993
Validation loss: 1.848218128245364

Epoch: 5| Step: 1
Training loss: 1.5536489486694336
Validation loss: 1.8313741043049803

Epoch: 5| Step: 2
Training loss: 2.0065810680389404
Validation loss: 1.8656069617117605

Epoch: 5| Step: 3
Training loss: 1.9137532711029053
Validation loss: 1.822636624818207

Epoch: 5| Step: 4
Training loss: 1.5335023403167725
Validation loss: 1.8207446503382858

Epoch: 5| Step: 5
Training loss: 1.524746060371399
Validation loss: 1.8523493351474885

Epoch: 5| Step: 6
Training loss: 1.646797776222229
Validation loss: 1.8533221701140046

Epoch: 5| Step: 7
Training loss: 1.484201192855835
Validation loss: 1.8615245819091797

Epoch: 5| Step: 8
Training loss: 1.7167446613311768
Validation loss: 1.8507567964574343

Epoch: 5| Step: 9
Training loss: 1.4776581525802612
Validation loss: 1.8491217731147684

Epoch: 5| Step: 10
Training loss: 2.303020477294922
Validation loss: 1.8301075761036207

Epoch: 266| Step: 0
Training loss: 1.1437143087387085
Validation loss: 1.849748271767811

Epoch: 5| Step: 1
Training loss: 1.5700960159301758
Validation loss: 1.8850203047516525

Epoch: 5| Step: 2
Training loss: 1.7746293544769287
Validation loss: 1.8602013613588066

Epoch: 5| Step: 3
Training loss: 1.3444359302520752
Validation loss: 1.8393250062901487

Epoch: 5| Step: 4
Training loss: 1.6849489212036133
Validation loss: 1.8258296148751372

Epoch: 5| Step: 5
Training loss: 1.792754888534546
Validation loss: 1.850300629933675

Epoch: 5| Step: 6
Training loss: 1.1159286499023438
Validation loss: 1.833038245477984

Epoch: 5| Step: 7
Training loss: 1.9806253910064697
Validation loss: 1.8790297380057714

Epoch: 5| Step: 8
Training loss: 2.017796039581299
Validation loss: 1.8535784803411013

Epoch: 5| Step: 9
Training loss: 2.1509289741516113
Validation loss: 1.8600537751310615

Epoch: 5| Step: 10
Training loss: 1.6202318668365479
Validation loss: 1.8495302520772463

Epoch: 267| Step: 0
Training loss: 1.9278112649917603
Validation loss: 1.8626589621267011

Epoch: 5| Step: 1
Training loss: 0.8487294912338257
Validation loss: 1.8631913905502648

Epoch: 5| Step: 2
Training loss: 1.6284523010253906
Validation loss: 1.8282859927864485

Epoch: 5| Step: 3
Training loss: 1.780413269996643
Validation loss: 1.8557965883644678

Epoch: 5| Step: 4
Training loss: 1.9585155248641968
Validation loss: 1.8439596801675775

Epoch: 5| Step: 5
Training loss: 1.8177621364593506
Validation loss: 1.854833141449959

Epoch: 5| Step: 6
Training loss: 1.723186731338501
Validation loss: 1.851767739941997

Epoch: 5| Step: 7
Training loss: 1.6330640316009521
Validation loss: 1.838680418588782

Epoch: 5| Step: 8
Training loss: 1.4432271718978882
Validation loss: 1.8910954972749114

Epoch: 5| Step: 9
Training loss: 1.5417439937591553
Validation loss: 1.8455441280077862

Epoch: 5| Step: 10
Training loss: 1.5586713552474976
Validation loss: 1.8562794923782349

Epoch: 268| Step: 0
Training loss: 1.556203842163086
Validation loss: 1.8357291529255528

Epoch: 5| Step: 1
Training loss: 1.465975046157837
Validation loss: 1.8859608481007237

Epoch: 5| Step: 2
Training loss: 1.502137541770935
Validation loss: 1.8327954417915755

Epoch: 5| Step: 3
Training loss: 1.4626133441925049
Validation loss: 1.8235491603933356

Epoch: 5| Step: 4
Training loss: 1.7052853107452393
Validation loss: 1.8362792986695484

Epoch: 5| Step: 5
Training loss: 1.863012671470642
Validation loss: 1.8554525221547773

Epoch: 5| Step: 6
Training loss: 1.7833662033081055
Validation loss: 1.8414191199887184

Epoch: 5| Step: 7
Training loss: 1.1726652383804321
Validation loss: 1.8276354420569636

Epoch: 5| Step: 8
Training loss: 1.8475643396377563
Validation loss: 1.8413663884644866

Epoch: 5| Step: 9
Training loss: 1.6176748275756836
Validation loss: 1.8539495788594729

Epoch: 5| Step: 10
Training loss: 2.203023672103882
Validation loss: 1.8192104831818612

Epoch: 269| Step: 0
Training loss: 1.5570271015167236
Validation loss: 1.832795673801053

Epoch: 5| Step: 1
Training loss: 1.4927324056625366
Validation loss: 1.8733851525091356

Epoch: 5| Step: 2
Training loss: 1.8097045421600342
Validation loss: 1.8271640244350638

Epoch: 5| Step: 3
Training loss: 2.0940394401550293
Validation loss: 1.8420395146134079

Epoch: 5| Step: 4
Training loss: 1.1026437282562256
Validation loss: 1.8430767636145315

Epoch: 5| Step: 5
Training loss: 2.2829127311706543
Validation loss: 1.858484011824413

Epoch: 5| Step: 6
Training loss: 1.4069675207138062
Validation loss: 1.8428183306929886

Epoch: 5| Step: 7
Training loss: 1.653540849685669
Validation loss: 1.8699917588182675

Epoch: 5| Step: 8
Training loss: 1.5439497232437134
Validation loss: 1.8734587123317104

Epoch: 5| Step: 9
Training loss: 1.4583476781845093
Validation loss: 1.8415870666503906

Epoch: 5| Step: 10
Training loss: 1.8459371328353882
Validation loss: 1.796067269899512

Epoch: 270| Step: 0
Training loss: 1.407923936843872
Validation loss: 1.8299303593174103

Epoch: 5| Step: 1
Training loss: 1.6802459955215454
Validation loss: 1.8789323760617165

Epoch: 5| Step: 2
Training loss: 1.8721710443496704
Validation loss: 1.8737910947492045

Epoch: 5| Step: 3
Training loss: 1.736562728881836
Validation loss: 1.8788221702780774

Epoch: 5| Step: 4
Training loss: 1.7037503719329834
Validation loss: 1.863479128447912

Epoch: 5| Step: 5
Training loss: 1.540027141571045
Validation loss: 1.885918769785153

Epoch: 5| Step: 6
Training loss: 2.092191219329834
Validation loss: 1.8829630421053978

Epoch: 5| Step: 7
Training loss: 2.0420031547546387
Validation loss: 1.8648677397799749

Epoch: 5| Step: 8
Training loss: 1.0675609111785889
Validation loss: 1.9047164968265

Epoch: 5| Step: 9
Training loss: 1.2636404037475586
Validation loss: 1.8778592232734925

Epoch: 5| Step: 10
Training loss: 1.9017374515533447
Validation loss: 1.8831014838269962

Epoch: 271| Step: 0
Training loss: 1.3007822036743164
Validation loss: 1.8879437728594708

Epoch: 5| Step: 1
Training loss: 1.481788992881775
Validation loss: 1.8481661632496824

Epoch: 5| Step: 2
Training loss: 1.430994987487793
Validation loss: 1.863162999512047

Epoch: 5| Step: 3
Training loss: 2.3723912239074707
Validation loss: 1.850208004315694

Epoch: 5| Step: 4
Training loss: 1.2463419437408447
Validation loss: 1.839648603111185

Epoch: 5| Step: 5
Training loss: 2.0410850048065186
Validation loss: 1.844975056186799

Epoch: 5| Step: 6
Training loss: 1.5636084079742432
Validation loss: 1.8332589698094193

Epoch: 5| Step: 7
Training loss: 1.4207345247268677
Validation loss: 1.8259332333841631

Epoch: 5| Step: 8
Training loss: 1.7199252843856812
Validation loss: 1.818987145218798

Epoch: 5| Step: 9
Training loss: 2.355458974838257
Validation loss: 1.8244739732434672

Epoch: 5| Step: 10
Training loss: 1.3451262712478638
Validation loss: 1.8281917777112735

Epoch: 272| Step: 0
Training loss: 1.674231767654419
Validation loss: 1.8492023509035829

Epoch: 5| Step: 1
Training loss: 1.2475956678390503
Validation loss: 1.8822403056647188

Epoch: 5| Step: 2
Training loss: 1.7800356149673462
Validation loss: 1.876112393153611

Epoch: 5| Step: 3
Training loss: 1.7559913396835327
Validation loss: 1.851504886022178

Epoch: 5| Step: 4
Training loss: 1.3319189548492432
Validation loss: 1.8620108904377106

Epoch: 5| Step: 5
Training loss: 2.1903719902038574
Validation loss: 1.8326330031118085

Epoch: 5| Step: 6
Training loss: 1.901515245437622
Validation loss: 1.8472891853701683

Epoch: 5| Step: 7
Training loss: 1.3840792179107666
Validation loss: 1.8525066016822733

Epoch: 5| Step: 8
Training loss: 1.2302920818328857
Validation loss: 1.8507569682213567

Epoch: 5| Step: 9
Training loss: 1.746069312095642
Validation loss: 1.8659536569349227

Epoch: 5| Step: 10
Training loss: 1.5747358798980713
Validation loss: 1.8485988006796887

Epoch: 273| Step: 0
Training loss: 1.6750818490982056
Validation loss: 1.8654067029235184

Epoch: 5| Step: 1
Training loss: 1.717513084411621
Validation loss: 1.857332834633448

Epoch: 5| Step: 2
Training loss: 1.8217769861221313
Validation loss: 1.8497467874198832

Epoch: 5| Step: 3
Training loss: 2.4219048023223877
Validation loss: 1.8583279245643205

Epoch: 5| Step: 4
Training loss: 1.6075435876846313
Validation loss: 1.8527224550965011

Epoch: 5| Step: 5
Training loss: 1.890825629234314
Validation loss: 1.86096316511913

Epoch: 5| Step: 6
Training loss: 1.5811883211135864
Validation loss: 1.8721510761527604

Epoch: 5| Step: 7
Training loss: 1.4218755960464478
Validation loss: 1.8775556638676634

Epoch: 5| Step: 8
Training loss: 1.13002610206604
Validation loss: 1.8724054751857635

Epoch: 5| Step: 9
Training loss: 1.572223424911499
Validation loss: 1.8444733786326584

Epoch: 5| Step: 10
Training loss: 1.2922126054763794
Validation loss: 1.8451313857109315

Epoch: 274| Step: 0
Training loss: 2.125244140625
Validation loss: 1.862922606929656

Epoch: 5| Step: 1
Training loss: 1.600274682044983
Validation loss: 1.848024469549938

Epoch: 5| Step: 2
Training loss: 1.4408496618270874
Validation loss: 1.8668003530912503

Epoch: 5| Step: 3
Training loss: 2.3848376274108887
Validation loss: 1.827618150300877

Epoch: 5| Step: 4
Training loss: 1.484315037727356
Validation loss: 1.8492074025574552

Epoch: 5| Step: 5
Training loss: 2.1481831073760986
Validation loss: 1.8391342393813594

Epoch: 5| Step: 6
Training loss: 1.3209096193313599
Validation loss: 1.825694639195678

Epoch: 5| Step: 7
Training loss: 1.1993257999420166
Validation loss: 1.8064742254954513

Epoch: 5| Step: 8
Training loss: 1.5965207815170288
Validation loss: 1.8369551448411838

Epoch: 5| Step: 9
Training loss: 1.1701682806015015
Validation loss: 1.8833424429739676

Epoch: 5| Step: 10
Training loss: 1.6441929340362549
Validation loss: 1.8335180820957306

Epoch: 275| Step: 0
Training loss: 0.9612250328063965
Validation loss: 1.8217256505002257

Epoch: 5| Step: 1
Training loss: 2.2644104957580566
Validation loss: 1.829537428835387

Epoch: 5| Step: 2
Training loss: 1.5175158977508545
Validation loss: 1.8480775010201238

Epoch: 5| Step: 3
Training loss: 1.5194354057312012
Validation loss: 1.8975012110125633

Epoch: 5| Step: 4
Training loss: 1.653689980506897
Validation loss: 1.8537955745573966

Epoch: 5| Step: 5
Training loss: 2.1526410579681396
Validation loss: 1.8596514630061325

Epoch: 5| Step: 6
Training loss: 1.762571930885315
Validation loss: 1.8699766589749245

Epoch: 5| Step: 7
Training loss: 0.9127044677734375
Validation loss: 1.8447591079178678

Epoch: 5| Step: 8
Training loss: 1.4656009674072266
Validation loss: 1.9052312797115696

Epoch: 5| Step: 9
Training loss: 1.879804015159607
Validation loss: 1.8954825196214902

Epoch: 5| Step: 10
Training loss: 1.95974862575531
Validation loss: 1.8942344239962998

Epoch: 276| Step: 0
Training loss: 1.6613925695419312
Validation loss: 1.8389142790148336

Epoch: 5| Step: 1
Training loss: 1.7038122415542603
Validation loss: 1.8688073414628223

Epoch: 5| Step: 2
Training loss: 1.6072782278060913
Validation loss: 1.8751925037753197

Epoch: 5| Step: 3
Training loss: 1.4877113103866577
Validation loss: 1.8397513871551843

Epoch: 5| Step: 4
Training loss: 1.8935871124267578
Validation loss: 1.8718657250045447

Epoch: 5| Step: 5
Training loss: 2.091547727584839
Validation loss: 1.8750016996937413

Epoch: 5| Step: 6
Training loss: 1.4530696868896484
Validation loss: 1.8322564043024534

Epoch: 5| Step: 7
Training loss: 1.677594780921936
Validation loss: 1.8804927948982484

Epoch: 5| Step: 8
Training loss: 1.659165382385254
Validation loss: 1.8182141998762726

Epoch: 5| Step: 9
Training loss: 1.500004529953003
Validation loss: 1.8131232030930058

Epoch: 5| Step: 10
Training loss: 1.356972575187683
Validation loss: 1.8518719134792205

Epoch: 277| Step: 0
Training loss: 1.9830299615859985
Validation loss: 1.8081673473440192

Epoch: 5| Step: 1
Training loss: 1.921331763267517
Validation loss: 1.8214324071843138

Epoch: 5| Step: 2
Training loss: 1.4784576892852783
Validation loss: 1.8306418042029104

Epoch: 5| Step: 3
Training loss: 1.244351863861084
Validation loss: 1.819981328902706

Epoch: 5| Step: 4
Training loss: 1.1918013095855713
Validation loss: 1.820084325728878

Epoch: 5| Step: 5
Training loss: 2.0537219047546387
Validation loss: 1.8500716352975497

Epoch: 5| Step: 6
Training loss: 1.4975097179412842
Validation loss: 1.8365461864779073

Epoch: 5| Step: 7
Training loss: 1.382882833480835
Validation loss: 1.8141363589994368

Epoch: 5| Step: 8
Training loss: 1.9788659811019897
Validation loss: 1.8298707879999632

Epoch: 5| Step: 9
Training loss: 1.2502888441085815
Validation loss: 1.8201271334002096

Epoch: 5| Step: 10
Training loss: 2.1928043365478516
Validation loss: 1.8491150768854285

Epoch: 278| Step: 0
Training loss: 1.5033012628555298
Validation loss: 1.8347067179218415

Epoch: 5| Step: 1
Training loss: 2.0316274166107178
Validation loss: 1.834531578325456

Epoch: 5| Step: 2
Training loss: 1.7546405792236328
Validation loss: 1.8722349597561745

Epoch: 5| Step: 3
Training loss: 1.4350969791412354
Validation loss: 1.861707188749826

Epoch: 5| Step: 4
Training loss: 1.4066048860549927
Validation loss: 1.8286590294171405

Epoch: 5| Step: 5
Training loss: 1.5933966636657715
Validation loss: 1.8146118938281972

Epoch: 5| Step: 6
Training loss: 1.4314638376235962
Validation loss: 1.8335229876220867

Epoch: 5| Step: 7
Training loss: 1.4343388080596924
Validation loss: 1.8300444797802997

Epoch: 5| Step: 8
Training loss: 2.0771965980529785
Validation loss: 1.8522220888445455

Epoch: 5| Step: 9
Training loss: 1.698768973350525
Validation loss: 1.8840764748152865

Epoch: 5| Step: 10
Training loss: 1.413386344909668
Validation loss: 1.864636190475956

Epoch: 279| Step: 0
Training loss: 1.3943126201629639
Validation loss: 1.8420543286108202

Epoch: 5| Step: 1
Training loss: 1.7386674880981445
Validation loss: 1.8286440398103447

Epoch: 5| Step: 2
Training loss: 1.3704172372817993
Validation loss: 1.8649547215430968

Epoch: 5| Step: 3
Training loss: 1.7274144887924194
Validation loss: 1.856654336375575

Epoch: 5| Step: 4
Training loss: 1.8257625102996826
Validation loss: 1.8207484265809417

Epoch: 5| Step: 5
Training loss: 1.5857489109039307
Validation loss: 1.8354297376448108

Epoch: 5| Step: 6
Training loss: 1.9488502740859985
Validation loss: 1.852970282236735

Epoch: 5| Step: 7
Training loss: 1.5546389818191528
Validation loss: 1.8595935926642468

Epoch: 5| Step: 8
Training loss: 1.5276610851287842
Validation loss: 1.8345156818307855

Epoch: 5| Step: 9
Training loss: 2.1086232662200928
Validation loss: 1.8417008012853644

Epoch: 5| Step: 10
Training loss: 1.1181564331054688
Validation loss: 1.8523524294617355

Epoch: 280| Step: 0
Training loss: 1.7073978185653687
Validation loss: 1.8631767508804158

Epoch: 5| Step: 1
Training loss: 1.3655561208724976
Validation loss: 1.8461401206190868

Epoch: 5| Step: 2
Training loss: 2.231717824935913
Validation loss: 1.870582043483693

Epoch: 5| Step: 3
Training loss: 1.334721326828003
Validation loss: 1.856706832044868

Epoch: 5| Step: 4
Training loss: 1.2827657461166382
Validation loss: 1.8374772546111897

Epoch: 5| Step: 5
Training loss: 1.6258713006973267
Validation loss: 1.862770535612619

Epoch: 5| Step: 6
Training loss: 1.5572597980499268
Validation loss: 1.8397545942696192

Epoch: 5| Step: 7
Training loss: 1.866782784461975
Validation loss: 1.8407317899888562

Epoch: 5| Step: 8
Training loss: 1.3426247835159302
Validation loss: 1.8273092495497836

Epoch: 5| Step: 9
Training loss: 1.5792582035064697
Validation loss: 1.8315268024321525

Epoch: 5| Step: 10
Training loss: 1.9423532485961914
Validation loss: 1.8109810583053096

Epoch: 281| Step: 0
Training loss: 1.9219343662261963
Validation loss: 1.8295123346390263

Epoch: 5| Step: 1
Training loss: 1.9958595037460327
Validation loss: 1.840361859208794

Epoch: 5| Step: 2
Training loss: 1.7959051132202148
Validation loss: 1.821187493621662

Epoch: 5| Step: 3
Training loss: 1.1812829971313477
Validation loss: 1.820143820137106

Epoch: 5| Step: 4
Training loss: 1.818777084350586
Validation loss: 1.802925193181602

Epoch: 5| Step: 5
Training loss: 1.8692400455474854
Validation loss: 1.8228693777515041

Epoch: 5| Step: 6
Training loss: 0.9021114110946655
Validation loss: 1.8124885277081562

Epoch: 5| Step: 7
Training loss: 1.2798811197280884
Validation loss: 1.830535751517101

Epoch: 5| Step: 8
Training loss: 1.9931350946426392
Validation loss: 1.8469965611734698

Epoch: 5| Step: 9
Training loss: 1.3466522693634033
Validation loss: 1.8731317584232619

Epoch: 5| Step: 10
Training loss: 1.6402772665023804
Validation loss: 1.8398916080433836

Epoch: 282| Step: 0
Training loss: 1.181100606918335
Validation loss: 1.8441383466925672

Epoch: 5| Step: 1
Training loss: 1.982034683227539
Validation loss: 1.884827011375017

Epoch: 5| Step: 2
Training loss: 1.447067141532898
Validation loss: 1.8831443517438826

Epoch: 5| Step: 3
Training loss: 1.366669774055481
Validation loss: 1.8455383149526452

Epoch: 5| Step: 4
Training loss: 2.1604647636413574
Validation loss: 1.8451384741772887

Epoch: 5| Step: 5
Training loss: 1.232969880104065
Validation loss: 1.841362194348407

Epoch: 5| Step: 6
Training loss: 1.4377689361572266
Validation loss: 1.8602463942702099

Epoch: 5| Step: 7
Training loss: 2.0275864601135254
Validation loss: 1.8612515900724678

Epoch: 5| Step: 8
Training loss: 1.8391268253326416
Validation loss: 1.8651135377986456

Epoch: 5| Step: 9
Training loss: 1.8479045629501343
Validation loss: 1.8292994319751699

Epoch: 5| Step: 10
Training loss: 1.2380526065826416
Validation loss: 1.8271333402202976

Epoch: 283| Step: 0
Training loss: 1.493774175643921
Validation loss: 1.8595932658000658

Epoch: 5| Step: 1
Training loss: 1.6504369974136353
Validation loss: 1.8166180400438205

Epoch: 5| Step: 2
Training loss: 1.8832420110702515
Validation loss: 1.8297188897286691

Epoch: 5| Step: 3
Training loss: 1.7655689716339111
Validation loss: 1.8456067500575897

Epoch: 5| Step: 4
Training loss: 1.2302765846252441
Validation loss: 1.8552427984053088

Epoch: 5| Step: 5
Training loss: 1.7300161123275757
Validation loss: 1.8323208926826395

Epoch: 5| Step: 6
Training loss: 1.2086845636367798
Validation loss: 1.8226070096415858

Epoch: 5| Step: 7
Training loss: 1.724722146987915
Validation loss: 1.8326711885390743

Epoch: 5| Step: 8
Training loss: 1.38676118850708
Validation loss: 1.8436701925851966

Epoch: 5| Step: 9
Training loss: 1.6861613988876343
Validation loss: 1.8253208539819206

Epoch: 5| Step: 10
Training loss: 2.095684051513672
Validation loss: 1.81807207035762

Epoch: 284| Step: 0
Training loss: 1.7078616619110107
Validation loss: 1.8166731480629212

Epoch: 5| Step: 1
Training loss: 1.7117633819580078
Validation loss: 1.83771925844172

Epoch: 5| Step: 2
Training loss: 1.458857536315918
Validation loss: 1.8463905498545656

Epoch: 5| Step: 3
Training loss: 1.4613332748413086
Validation loss: 1.8094350573837117

Epoch: 5| Step: 4
Training loss: 1.425731897354126
Validation loss: 1.8642833976335422

Epoch: 5| Step: 5
Training loss: 1.399717092514038
Validation loss: 1.8566687722359934

Epoch: 5| Step: 6
Training loss: 1.5483057498931885
Validation loss: 1.8590536937918714

Epoch: 5| Step: 7
Training loss: 1.9283660650253296
Validation loss: 1.8234785167119836

Epoch: 5| Step: 8
Training loss: 2.098646640777588
Validation loss: 1.8399799126450733

Epoch: 5| Step: 9
Training loss: 1.4608314037322998
Validation loss: 1.8687565544600129

Epoch: 5| Step: 10
Training loss: 1.4563374519348145
Validation loss: 1.8295454696942401

Epoch: 285| Step: 0
Training loss: 1.3570095300674438
Validation loss: 1.8482842958101662

Epoch: 5| Step: 1
Training loss: 1.6427509784698486
Validation loss: 1.8544068541578067

Epoch: 5| Step: 2
Training loss: 2.112102746963501
Validation loss: 1.825110427794918

Epoch: 5| Step: 3
Training loss: 1.3549362421035767
Validation loss: 1.796703093795366

Epoch: 5| Step: 4
Training loss: 1.9983222484588623
Validation loss: 1.8666288827055244

Epoch: 5| Step: 5
Training loss: 1.5601781606674194
Validation loss: 1.8321163654327393

Epoch: 5| Step: 6
Training loss: 1.250704050064087
Validation loss: 1.8591689781476093

Epoch: 5| Step: 7
Training loss: 1.562643051147461
Validation loss: 1.8357038549197617

Epoch: 5| Step: 8
Training loss: 1.0921175479888916
Validation loss: 1.852096635808227

Epoch: 5| Step: 9
Training loss: 1.4390562772750854
Validation loss: 1.851941849595757

Epoch: 5| Step: 10
Training loss: 2.3062033653259277
Validation loss: 1.8630555342602473

Epoch: 286| Step: 0
Training loss: 1.441159963607788
Validation loss: 1.8307743598056097

Epoch: 5| Step: 1
Training loss: 1.4198271036148071
Validation loss: 1.8457827388599355

Epoch: 5| Step: 2
Training loss: 1.033696174621582
Validation loss: 1.8467888216818533

Epoch: 5| Step: 3
Training loss: 1.6509201526641846
Validation loss: 1.8505580681626514

Epoch: 5| Step: 4
Training loss: 2.2293190956115723
Validation loss: 1.877598149802095

Epoch: 5| Step: 5
Training loss: 1.7627331018447876
Validation loss: 1.8684152941549979

Epoch: 5| Step: 6
Training loss: 1.6147739887237549
Validation loss: 1.879240745498288

Epoch: 5| Step: 7
Training loss: 1.5303504467010498
Validation loss: 1.8626125384402532

Epoch: 5| Step: 8
Training loss: 2.070719003677368
Validation loss: 1.8396538444744643

Epoch: 5| Step: 9
Training loss: 1.3073294162750244
Validation loss: 1.862026717073174

Epoch: 5| Step: 10
Training loss: 1.823012351989746
Validation loss: 1.8584326749206872

Epoch: 287| Step: 0
Training loss: 1.7216886281967163
Validation loss: 1.8364069295185868

Epoch: 5| Step: 1
Training loss: 1.686000108718872
Validation loss: 1.8429670282589492

Epoch: 5| Step: 2
Training loss: 1.436124324798584
Validation loss: 1.8243578300681165

Epoch: 5| Step: 3
Training loss: 1.660414695739746
Validation loss: 1.8045062249706638

Epoch: 5| Step: 4
Training loss: 1.5093765258789062
Validation loss: 1.7959634129719069

Epoch: 5| Step: 5
Training loss: 1.992929220199585
Validation loss: 1.8142115364792526

Epoch: 5| Step: 6
Training loss: 1.254927635192871
Validation loss: 1.8078836907622635

Epoch: 5| Step: 7
Training loss: 1.16121506690979
Validation loss: 1.8509777130619172

Epoch: 5| Step: 8
Training loss: 2.0988402366638184
Validation loss: 1.8361925258431384

Epoch: 5| Step: 9
Training loss: 1.434775471687317
Validation loss: 1.845129902644824

Epoch: 5| Step: 10
Training loss: 1.7965327501296997
Validation loss: 1.8540161066157843

Epoch: 288| Step: 0
Training loss: 1.6334091424942017
Validation loss: 1.8225844201221262

Epoch: 5| Step: 1
Training loss: 1.4151660203933716
Validation loss: 1.8189761113095027

Epoch: 5| Step: 2
Training loss: 1.8850816488265991
Validation loss: 1.8559418519337971

Epoch: 5| Step: 3
Training loss: 1.7734050750732422
Validation loss: 1.835174286237327

Epoch: 5| Step: 4
Training loss: 1.8706939220428467
Validation loss: 1.8350629498881679

Epoch: 5| Step: 5
Training loss: 1.7230818271636963
Validation loss: 1.8116677268858878

Epoch: 5| Step: 6
Training loss: 1.6007919311523438
Validation loss: 1.8156006695121847

Epoch: 5| Step: 7
Training loss: 1.266762375831604
Validation loss: 1.8079139365944812

Epoch: 5| Step: 8
Training loss: 1.442070484161377
Validation loss: 1.8302489339664418

Epoch: 5| Step: 9
Training loss: 1.740281105041504
Validation loss: 1.8366296547715382

Epoch: 5| Step: 10
Training loss: 1.4048055410385132
Validation loss: 1.8008253228279851

Epoch: 289| Step: 0
Training loss: 1.7302500009536743
Validation loss: 1.7852323555177259

Epoch: 5| Step: 1
Training loss: 1.1237047910690308
Validation loss: 1.8124074089911677

Epoch: 5| Step: 2
Training loss: 1.8119481801986694
Validation loss: 1.816769572996324

Epoch: 5| Step: 3
Training loss: 1.6582788228988647
Validation loss: 1.8042859236399333

Epoch: 5| Step: 4
Training loss: 1.2097923755645752
Validation loss: 1.8214178546782462

Epoch: 5| Step: 5
Training loss: 1.8638582229614258
Validation loss: 1.829059745675774

Epoch: 5| Step: 6
Training loss: 2.6977486610412598
Validation loss: 1.8481691242546163

Epoch: 5| Step: 7
Training loss: 1.2782847881317139
Validation loss: 1.838025540433904

Epoch: 5| Step: 8
Training loss: 1.164361596107483
Validation loss: 1.85402972467484

Epoch: 5| Step: 9
Training loss: 1.46405029296875
Validation loss: 1.8879063770335207

Epoch: 5| Step: 10
Training loss: 1.6958483457565308
Validation loss: 1.860061043052263

Epoch: 290| Step: 0
Training loss: 1.7633934020996094
Validation loss: 1.877082908025352

Epoch: 5| Step: 1
Training loss: 1.9824978113174438
Validation loss: 1.8784803575085056

Epoch: 5| Step: 2
Training loss: 1.4908230304718018
Validation loss: 1.884414908706501

Epoch: 5| Step: 3
Training loss: 1.8208671808242798
Validation loss: 1.8683738016313123

Epoch: 5| Step: 4
Training loss: 0.8639557957649231
Validation loss: 1.8272726933161418

Epoch: 5| Step: 5
Training loss: 1.86797297000885
Validation loss: 1.849971520003452

Epoch: 5| Step: 6
Training loss: 1.7892324924468994
Validation loss: 1.8123917938560568

Epoch: 5| Step: 7
Training loss: 1.805019736289978
Validation loss: 1.8515008188063098

Epoch: 5| Step: 8
Training loss: 1.1541627645492554
Validation loss: 1.835308903007097

Epoch: 5| Step: 9
Training loss: 1.5711342096328735
Validation loss: 1.833159879971576

Epoch: 5| Step: 10
Training loss: 1.5447934865951538
Validation loss: 1.830208634817472

Epoch: 291| Step: 0
Training loss: 2.182465076446533
Validation loss: 1.8434656307261477

Epoch: 5| Step: 1
Training loss: 1.650061011314392
Validation loss: 1.826435718485104

Epoch: 5| Step: 2
Training loss: 1.133317232131958
Validation loss: 1.8316557010014851

Epoch: 5| Step: 3
Training loss: 1.1581776142120361
Validation loss: 1.8341944063863447

Epoch: 5| Step: 4
Training loss: 2.1318211555480957
Validation loss: 1.819140311210386

Epoch: 5| Step: 5
Training loss: 1.4516243934631348
Validation loss: 1.8379572424837338

Epoch: 5| Step: 6
Training loss: 1.5579650402069092
Validation loss: 1.8554249783997894

Epoch: 5| Step: 7
Training loss: 1.3494021892547607
Validation loss: 1.862066977767534

Epoch: 5| Step: 8
Training loss: 1.677351713180542
Validation loss: 1.8487621020245295

Epoch: 5| Step: 9
Training loss: 1.5088894367218018
Validation loss: 1.856170774787985

Epoch: 5| Step: 10
Training loss: 1.9637951850891113
Validation loss: 1.827119742670367

Epoch: 292| Step: 0
Training loss: 1.682814359664917
Validation loss: 1.844304182196176

Epoch: 5| Step: 1
Training loss: 1.9574558734893799
Validation loss: 1.821779639490189

Epoch: 5| Step: 2
Training loss: 1.323585867881775
Validation loss: 1.8439170878420594

Epoch: 5| Step: 3
Training loss: 1.8580589294433594
Validation loss: 1.840379213774076

Epoch: 5| Step: 4
Training loss: 1.550092339515686
Validation loss: 1.8317149634002357

Epoch: 5| Step: 5
Training loss: 1.4088268280029297
Validation loss: 1.822752337301931

Epoch: 5| Step: 6
Training loss: 1.7604119777679443
Validation loss: 1.83664119884532

Epoch: 5| Step: 7
Training loss: 1.5122194290161133
Validation loss: 1.799057238845415

Epoch: 5| Step: 8
Training loss: 1.354774832725525
Validation loss: 1.8072512559993292

Epoch: 5| Step: 9
Training loss: 1.8338454961776733
Validation loss: 1.8383661521378385

Epoch: 5| Step: 10
Training loss: 1.4031217098236084
Validation loss: 1.8285647258963635

Epoch: 293| Step: 0
Training loss: 1.6435123682022095
Validation loss: 1.820162365513463

Epoch: 5| Step: 1
Training loss: 1.4298232793807983
Validation loss: 1.8439387685509139

Epoch: 5| Step: 2
Training loss: 1.5705691576004028
Validation loss: 1.8340901418398785

Epoch: 5| Step: 3
Training loss: 1.302911639213562
Validation loss: 1.8627364020193777

Epoch: 5| Step: 4
Training loss: 2.208604335784912
Validation loss: 1.8615699929575766

Epoch: 5| Step: 5
Training loss: 1.5505489110946655
Validation loss: 1.8534183976470784

Epoch: 5| Step: 6
Training loss: 1.8405243158340454
Validation loss: 1.894328612153248

Epoch: 5| Step: 7
Training loss: 1.5107471942901611
Validation loss: 1.8817587385895431

Epoch: 5| Step: 8
Training loss: 1.4527555704116821
Validation loss: 1.8625571958480343

Epoch: 5| Step: 9
Training loss: 1.5399576425552368
Validation loss: 1.8476387890436317

Epoch: 5| Step: 10
Training loss: 1.3041467666625977
Validation loss: 1.8681899462976763

Epoch: 294| Step: 0
Training loss: 1.0954067707061768
Validation loss: 1.8278826436688822

Epoch: 5| Step: 1
Training loss: 2.1665098667144775
Validation loss: 1.8386600966094642

Epoch: 5| Step: 2
Training loss: 1.4389660358428955
Validation loss: 1.81104988051999

Epoch: 5| Step: 3
Training loss: 1.0051183700561523
Validation loss: 1.808109893593737

Epoch: 5| Step: 4
Training loss: 1.404719352722168
Validation loss: 1.8489416094236477

Epoch: 5| Step: 5
Training loss: 1.3390792608261108
Validation loss: 1.7853586366099696

Epoch: 5| Step: 6
Training loss: 1.532812237739563
Validation loss: 1.8078463487727667

Epoch: 5| Step: 7
Training loss: 0.9781400561332703
Validation loss: 1.8137350306716016

Epoch: 5| Step: 8
Training loss: 2.2832329273223877
Validation loss: 1.8214310189729095

Epoch: 5| Step: 9
Training loss: 1.839625597000122
Validation loss: 1.8252855500867289

Epoch: 5| Step: 10
Training loss: 2.5707316398620605
Validation loss: 1.797211270178518

Epoch: 295| Step: 0
Training loss: 1.0171597003936768
Validation loss: 1.8423531209268877

Epoch: 5| Step: 1
Training loss: 1.7354724407196045
Validation loss: 1.8304054916545909

Epoch: 5| Step: 2
Training loss: 1.8988717794418335
Validation loss: 1.8301728835669897

Epoch: 5| Step: 3
Training loss: 1.3919405937194824
Validation loss: 1.837460692210864

Epoch: 5| Step: 4
Training loss: 1.2244689464569092
Validation loss: 1.8309430358230427

Epoch: 5| Step: 5
Training loss: 1.933677315711975
Validation loss: 1.8006644223325996

Epoch: 5| Step: 6
Training loss: 1.9393924474716187
Validation loss: 1.8472578666543449

Epoch: 5| Step: 7
Training loss: 1.6961711645126343
Validation loss: 1.8736235492972917

Epoch: 5| Step: 8
Training loss: 1.3315069675445557
Validation loss: 1.839819597941573

Epoch: 5| Step: 9
Training loss: 1.9306743144989014
Validation loss: 1.8396135530164164

Epoch: 5| Step: 10
Training loss: 1.3478606939315796
Validation loss: 1.8607115873726465

Epoch: 296| Step: 0
Training loss: 1.7251923084259033
Validation loss: 1.8445532424475557

Epoch: 5| Step: 1
Training loss: 1.1614115238189697
Validation loss: 1.8214546749668736

Epoch: 5| Step: 2
Training loss: 1.3921165466308594
Validation loss: 1.8179153985874628

Epoch: 5| Step: 3
Training loss: 1.6137186288833618
Validation loss: 1.8498639201605191

Epoch: 5| Step: 4
Training loss: 1.2399141788482666
Validation loss: 1.8411944514961653

Epoch: 5| Step: 5
Training loss: 1.708387017250061
Validation loss: 1.841124898643904

Epoch: 5| Step: 6
Training loss: 1.7773975133895874
Validation loss: 1.837764565662671

Epoch: 5| Step: 7
Training loss: 1.3225290775299072
Validation loss: 1.8111722751330304

Epoch: 5| Step: 8
Training loss: 1.601889967918396
Validation loss: 1.8321016616718744

Epoch: 5| Step: 9
Training loss: 1.4527833461761475
Validation loss: 1.794999982721062

Epoch: 5| Step: 10
Training loss: 2.3812849521636963
Validation loss: 1.86057908304276

Epoch: 297| Step: 0
Training loss: 2.0007927417755127
Validation loss: 1.8256372521000523

Epoch: 5| Step: 1
Training loss: 1.5529954433441162
Validation loss: 1.8301447694019606

Epoch: 5| Step: 2
Training loss: 1.60085928440094
Validation loss: 1.8343979876528504

Epoch: 5| Step: 3
Training loss: 1.8436485528945923
Validation loss: 1.848361590857147

Epoch: 5| Step: 4
Training loss: 1.3276560306549072
Validation loss: 1.8320033780990108

Epoch: 5| Step: 5
Training loss: 1.4295032024383545
Validation loss: 1.864285720291958

Epoch: 5| Step: 6
Training loss: 1.862525224685669
Validation loss: 1.8233733613003966

Epoch: 5| Step: 7
Training loss: 0.937436580657959
Validation loss: 1.842380205790202

Epoch: 5| Step: 8
Training loss: 1.717312216758728
Validation loss: 1.8468958088146743

Epoch: 5| Step: 9
Training loss: 1.6488929986953735
Validation loss: 1.8533358215003886

Epoch: 5| Step: 10
Training loss: 1.297614574432373
Validation loss: 1.8777628201310352

Epoch: 298| Step: 0
Training loss: 1.7750194072723389
Validation loss: 1.861083330646638

Epoch: 5| Step: 1
Training loss: 1.5312867164611816
Validation loss: 1.8721413330365253

Epoch: 5| Step: 2
Training loss: 1.67349112033844
Validation loss: 1.865373537104617

Epoch: 5| Step: 3
Training loss: 1.8323020935058594
Validation loss: 1.895285967857607

Epoch: 5| Step: 4
Training loss: 1.7430444955825806
Validation loss: 1.869422710070046

Epoch: 5| Step: 5
Training loss: 1.521722435951233
Validation loss: 1.8634228398722987

Epoch: 5| Step: 6
Training loss: 1.572535753250122
Validation loss: 1.8434485081703431

Epoch: 5| Step: 7
Training loss: 1.7369693517684937
Validation loss: 1.8250366141719203

Epoch: 5| Step: 8
Training loss: 1.8586269617080688
Validation loss: 1.8066298128456197

Epoch: 5| Step: 9
Training loss: 1.0080583095550537
Validation loss: 1.8482718749712872

Epoch: 5| Step: 10
Training loss: 0.9617380499839783
Validation loss: 1.8231276081454368

Epoch: 299| Step: 0
Training loss: 2.420041084289551
Validation loss: 1.8263678550720215

Epoch: 5| Step: 1
Training loss: 1.239377498626709
Validation loss: 1.8141301280708724

Epoch: 5| Step: 2
Training loss: 1.2418278455734253
Validation loss: 1.8280272099279589

Epoch: 5| Step: 3
Training loss: 1.832794189453125
Validation loss: 1.8550850524697253

Epoch: 5| Step: 4
Training loss: 2.1009857654571533
Validation loss: 1.7701557028678157

Epoch: 5| Step: 5
Training loss: 0.9262544512748718
Validation loss: 1.8103327661432245

Epoch: 5| Step: 6
Training loss: 1.4905544519424438
Validation loss: 1.805892357262232

Epoch: 5| Step: 7
Training loss: 1.5011857748031616
Validation loss: 1.830164828608113

Epoch: 5| Step: 8
Training loss: 1.3331876993179321
Validation loss: 1.8160237266171364

Epoch: 5| Step: 9
Training loss: 1.8083276748657227
Validation loss: 1.825501315055355

Epoch: 5| Step: 10
Training loss: 1.4120373725891113
Validation loss: 1.8437496615994362

Epoch: 300| Step: 0
Training loss: 2.2001736164093018
Validation loss: 1.8093980294401928

Epoch: 5| Step: 1
Training loss: 1.6372772455215454
Validation loss: 1.8095719224663191

Epoch: 5| Step: 2
Training loss: 1.6685912609100342
Validation loss: 1.8285741498393397

Epoch: 5| Step: 3
Training loss: 1.5687856674194336
Validation loss: 1.8173669051098567

Epoch: 5| Step: 4
Training loss: 1.0004804134368896
Validation loss: 1.855016746828633

Epoch: 5| Step: 5
Training loss: 1.3459837436676025
Validation loss: 1.8392986302734704

Epoch: 5| Step: 6
Training loss: 1.5983645915985107
Validation loss: 1.874063471312164

Epoch: 5| Step: 7
Training loss: 1.6678812503814697
Validation loss: 1.8424123717892555

Epoch: 5| Step: 8
Training loss: 1.571619987487793
Validation loss: 1.811433853641633

Epoch: 5| Step: 9
Training loss: 1.3837354183197021
Validation loss: 1.8479002086065148

Epoch: 5| Step: 10
Training loss: 1.5622327327728271
Validation loss: 1.8793164196834768

Epoch: 301| Step: 0
Training loss: 1.2520087957382202
Validation loss: 1.8486207415980678

Epoch: 5| Step: 1
Training loss: 1.5064704418182373
Validation loss: 1.803657675302157

Epoch: 5| Step: 2
Training loss: 1.346069097518921
Validation loss: 1.8341139593432028

Epoch: 5| Step: 3
Training loss: 1.3124784231185913
Validation loss: 1.876761713335591

Epoch: 5| Step: 4
Training loss: 1.3072437047958374
Validation loss: 1.8558546420066588

Epoch: 5| Step: 5
Training loss: 1.6431804895401
Validation loss: 1.882140128843246

Epoch: 5| Step: 6
Training loss: 1.2008588314056396
Validation loss: 1.869511991418818

Epoch: 5| Step: 7
Training loss: 2.418567657470703
Validation loss: 1.8425935904184978

Epoch: 5| Step: 8
Training loss: 1.022814154624939
Validation loss: 1.882684180813451

Epoch: 5| Step: 9
Training loss: 2.7902159690856934
Validation loss: 1.833237846692403

Epoch: 5| Step: 10
Training loss: 1.3182438611984253
Validation loss: 1.8314224289309593

Epoch: 302| Step: 0
Training loss: 1.7405338287353516
Validation loss: 1.8155344968201013

Epoch: 5| Step: 1
Training loss: 1.2456821203231812
Validation loss: 1.8576087541477655

Epoch: 5| Step: 2
Training loss: 1.6906388998031616
Validation loss: 1.8136769122974847

Epoch: 5| Step: 3
Training loss: 1.418552041053772
Validation loss: 1.822894298902122

Epoch: 5| Step: 4
Training loss: 1.737534761428833
Validation loss: 1.8810542257883216

Epoch: 5| Step: 5
Training loss: 1.61627197265625
Validation loss: 1.814119900426557

Epoch: 5| Step: 6
Training loss: 0.9303054809570312
Validation loss: 1.8423487486377839

Epoch: 5| Step: 7
Training loss: 1.8128368854522705
Validation loss: 1.8710970391509354

Epoch: 5| Step: 8
Training loss: 2.1793861389160156
Validation loss: 1.852581775316628

Epoch: 5| Step: 9
Training loss: 1.302790880203247
Validation loss: 1.8708353837331135

Epoch: 5| Step: 10
Training loss: 1.501636028289795
Validation loss: 1.9047585341238207

Epoch: 303| Step: 0
Training loss: 1.274251937866211
Validation loss: 1.8677357781317927

Epoch: 5| Step: 1
Training loss: 1.7179577350616455
Validation loss: 1.8650829638204267

Epoch: 5| Step: 2
Training loss: 1.4339044094085693
Validation loss: 1.8344140232250254

Epoch: 5| Step: 3
Training loss: 2.2382378578186035
Validation loss: 1.8267360938492643

Epoch: 5| Step: 4
Training loss: 1.2713123559951782
Validation loss: 1.841283618762929

Epoch: 5| Step: 5
Training loss: 1.9377985000610352
Validation loss: 1.8501138469224334

Epoch: 5| Step: 6
Training loss: 1.4313243627548218
Validation loss: 1.8686602897541498

Epoch: 5| Step: 7
Training loss: 1.5328131914138794
Validation loss: 1.8244167668845064

Epoch: 5| Step: 8
Training loss: 1.094449758529663
Validation loss: 1.823990370637627

Epoch: 5| Step: 9
Training loss: 2.0457139015197754
Validation loss: 1.808904432481335

Epoch: 5| Step: 10
Training loss: 1.4956036806106567
Validation loss: 1.8094920624968827

Epoch: 304| Step: 0
Training loss: 1.4157888889312744
Validation loss: 1.8389628779503606

Epoch: 5| Step: 1
Training loss: 1.3861773014068604
Validation loss: 1.8084811805396952

Epoch: 5| Step: 2
Training loss: 1.1230108737945557
Validation loss: 1.8161684313128073

Epoch: 5| Step: 3
Training loss: 1.6494382619857788
Validation loss: 1.8201612734025525

Epoch: 5| Step: 4
Training loss: 1.6038519144058228
Validation loss: 1.825533643845589

Epoch: 5| Step: 5
Training loss: 1.3427972793579102
Validation loss: 1.8233093818028767

Epoch: 5| Step: 6
Training loss: 2.1470513343811035
Validation loss: 1.8035237571244598

Epoch: 5| Step: 7
Training loss: 1.5365760326385498
Validation loss: 1.8342432783495994

Epoch: 5| Step: 8
Training loss: 1.9868437051773071
Validation loss: 1.809947491973959

Epoch: 5| Step: 9
Training loss: 1.3308864831924438
Validation loss: 1.8484913738824988

Epoch: 5| Step: 10
Training loss: 1.5150527954101562
Validation loss: 1.8042680614738054

Epoch: 305| Step: 0
Training loss: 2.1785032749176025
Validation loss: 1.8407601118087769

Epoch: 5| Step: 1
Training loss: 1.5725276470184326
Validation loss: 1.8136716017159082

Epoch: 5| Step: 2
Training loss: 1.8368241786956787
Validation loss: 1.8451921247666883

Epoch: 5| Step: 3
Training loss: 1.533673644065857
Validation loss: 1.8097443208899548

Epoch: 5| Step: 4
Training loss: 2.2106308937072754
Validation loss: 1.828964183407445

Epoch: 5| Step: 5
Training loss: 1.5505883693695068
Validation loss: 1.8211811165655813

Epoch: 5| Step: 6
Training loss: 0.8974378705024719
Validation loss: 1.8756689243419196

Epoch: 5| Step: 7
Training loss: 1.6390962600708008
Validation loss: 1.8456680390142626

Epoch: 5| Step: 8
Training loss: 1.2701119184494019
Validation loss: 1.8398451189840994

Epoch: 5| Step: 9
Training loss: 1.2896065711975098
Validation loss: 1.863532159918098

Epoch: 5| Step: 10
Training loss: 1.16861093044281
Validation loss: 1.8541258381259056

Epoch: 306| Step: 0
Training loss: 1.3859496116638184
Validation loss: 1.8218398222359278

Epoch: 5| Step: 1
Training loss: 1.6887296438217163
Validation loss: 1.868397073079181

Epoch: 5| Step: 2
Training loss: 1.2985928058624268
Validation loss: 1.8511094047177223

Epoch: 5| Step: 3
Training loss: 1.5329952239990234
Validation loss: 1.8543684803029543

Epoch: 5| Step: 4
Training loss: 1.474663496017456
Validation loss: 1.8429949142599618

Epoch: 5| Step: 5
Training loss: 1.6089318990707397
Validation loss: 1.8079130905930714

Epoch: 5| Step: 6
Training loss: 1.451889991760254
Validation loss: 1.8354113127595635

Epoch: 5| Step: 7
Training loss: 1.4927316904067993
Validation loss: 1.8221324002870949

Epoch: 5| Step: 8
Training loss: 1.6786140203475952
Validation loss: 1.8283106024547289

Epoch: 5| Step: 9
Training loss: 1.6075594425201416
Validation loss: 1.8626354407238703

Epoch: 5| Step: 10
Training loss: 1.9536888599395752
Validation loss: 1.8247643722000944

Epoch: 307| Step: 0
Training loss: 1.4815573692321777
Validation loss: 1.8387810350746236

Epoch: 5| Step: 1
Training loss: 1.6181085109710693
Validation loss: 1.798289151601894

Epoch: 5| Step: 2
Training loss: 1.5406146049499512
Validation loss: 1.8531109889348347

Epoch: 5| Step: 3
Training loss: 1.835017442703247
Validation loss: 1.8395161295449862

Epoch: 5| Step: 4
Training loss: 1.8531196117401123
Validation loss: 1.8272610300330705

Epoch: 5| Step: 5
Training loss: 1.296251893043518
Validation loss: 1.8304335763377528

Epoch: 5| Step: 6
Training loss: 1.4711592197418213
Validation loss: 1.8161910426232122

Epoch: 5| Step: 7
Training loss: 1.0224297046661377
Validation loss: 1.8208822742585213

Epoch: 5| Step: 8
Training loss: 1.3303192853927612
Validation loss: 1.8373977868787703

Epoch: 5| Step: 9
Training loss: 1.9818779230117798
Validation loss: 1.8001287130899326

Epoch: 5| Step: 10
Training loss: 1.7485957145690918
Validation loss: 1.8029660358223865

Epoch: 308| Step: 0
Training loss: 2.0179412364959717
Validation loss: 1.8026172807139735

Epoch: 5| Step: 1
Training loss: 1.2540639638900757
Validation loss: 1.8353851290159329

Epoch: 5| Step: 2
Training loss: 1.9307143688201904
Validation loss: 1.8447508747859667

Epoch: 5| Step: 3
Training loss: 1.8684320449829102
Validation loss: 1.8173678921115013

Epoch: 5| Step: 4
Training loss: 1.2582095861434937
Validation loss: 1.836750671427737

Epoch: 5| Step: 5
Training loss: 1.8606189489364624
Validation loss: 1.8343494912629486

Epoch: 5| Step: 6
Training loss: 1.1768287420272827
Validation loss: 1.8149453722020632

Epoch: 5| Step: 7
Training loss: 1.2497066259384155
Validation loss: 1.8510112531723515

Epoch: 5| Step: 8
Training loss: 1.3076894283294678
Validation loss: 1.8664513762279222

Epoch: 5| Step: 9
Training loss: 1.6477596759796143
Validation loss: 1.8266272185951151

Epoch: 5| Step: 10
Training loss: 1.5328834056854248
Validation loss: 1.857163724078927

Epoch: 309| Step: 0
Training loss: 1.495367407798767
Validation loss: 1.831606782892699

Epoch: 5| Step: 1
Training loss: 1.27206289768219
Validation loss: 1.8549098712141796

Epoch: 5| Step: 2
Training loss: 1.656690239906311
Validation loss: 1.8310139012593094

Epoch: 5| Step: 3
Training loss: 1.5606769323349
Validation loss: 1.8757729581607285

Epoch: 5| Step: 4
Training loss: 2.0957260131835938
Validation loss: 1.8590882542312785

Epoch: 5| Step: 5
Training loss: 1.2550725936889648
Validation loss: 1.8264038844775128

Epoch: 5| Step: 6
Training loss: 1.4536598920822144
Validation loss: 1.8638145282704344

Epoch: 5| Step: 7
Training loss: 1.424637794494629
Validation loss: 1.8512441573604461

Epoch: 5| Step: 8
Training loss: 1.4770050048828125
Validation loss: 1.845725368427974

Epoch: 5| Step: 9
Training loss: 1.8239864110946655
Validation loss: 1.840516100647629

Epoch: 5| Step: 10
Training loss: 1.4555368423461914
Validation loss: 1.8692162831624348

Epoch: 310| Step: 0
Training loss: 1.4439128637313843
Validation loss: 1.831821350641148

Epoch: 5| Step: 1
Training loss: 1.8337799310684204
Validation loss: 1.8394924466327955

Epoch: 5| Step: 2
Training loss: 1.5991389751434326
Validation loss: 1.8159805856725222

Epoch: 5| Step: 3
Training loss: 1.5314527750015259
Validation loss: 1.8260905896463702

Epoch: 5| Step: 4
Training loss: 1.9511686563491821
Validation loss: 1.8294855651035105

Epoch: 5| Step: 5
Training loss: 1.4311085939407349
Validation loss: 1.8324133734549246

Epoch: 5| Step: 6
Training loss: 1.2849527597427368
Validation loss: 1.8539174474695677

Epoch: 5| Step: 7
Training loss: 1.018475890159607
Validation loss: 1.792396778701454

Epoch: 5| Step: 8
Training loss: 1.4470248222351074
Validation loss: 1.825896014449417

Epoch: 5| Step: 9
Training loss: 1.5436080694198608
Validation loss: 1.8496544104750439

Epoch: 5| Step: 10
Training loss: 1.7387207746505737
Validation loss: 1.8396948793882966

Epoch: 311| Step: 0
Training loss: 1.5526096820831299
Validation loss: 1.8008886178334553

Epoch: 5| Step: 1
Training loss: 1.410921573638916
Validation loss: 1.8198848078327794

Epoch: 5| Step: 2
Training loss: 1.8738267421722412
Validation loss: 1.8208442708497405

Epoch: 5| Step: 3
Training loss: 1.8659645318984985
Validation loss: 1.8256005189752067

Epoch: 5| Step: 4
Training loss: 2.098477363586426
Validation loss: 1.8303667422263854

Epoch: 5| Step: 5
Training loss: 0.9302077293395996
Validation loss: 1.8217152498101676

Epoch: 5| Step: 6
Training loss: 1.006604790687561
Validation loss: 1.82300365355707

Epoch: 5| Step: 7
Training loss: 1.3100394010543823
Validation loss: 1.839662589052672

Epoch: 5| Step: 8
Training loss: 1.5929936170578003
Validation loss: 1.8437315815238542

Epoch: 5| Step: 9
Training loss: 1.4827687740325928
Validation loss: 1.837862414698447

Epoch: 5| Step: 10
Training loss: 1.8050658702850342
Validation loss: 1.8410185639576246

Epoch: 312| Step: 0
Training loss: 1.356374979019165
Validation loss: 1.8369635971643592

Epoch: 5| Step: 1
Training loss: 2.0743517875671387
Validation loss: 1.8353612102488035

Epoch: 5| Step: 2
Training loss: 1.4482178688049316
Validation loss: 1.8413054571356824

Epoch: 5| Step: 3
Training loss: 1.421902060508728
Validation loss: 1.8309374983592699

Epoch: 5| Step: 4
Training loss: 0.9799286723136902
Validation loss: 1.841241576338327

Epoch: 5| Step: 5
Training loss: 1.591982126235962
Validation loss: 1.8296372467471707

Epoch: 5| Step: 6
Training loss: 2.1733734607696533
Validation loss: 1.8439446495425316

Epoch: 5| Step: 7
Training loss: 1.289510726928711
Validation loss: 1.8241350727696573

Epoch: 5| Step: 8
Training loss: 1.741464376449585
Validation loss: 1.8611385514659267

Epoch: 5| Step: 9
Training loss: 1.5564610958099365
Validation loss: 1.8156705530740882

Epoch: 5| Step: 10
Training loss: 1.2372031211853027
Validation loss: 1.8418695567756571

Epoch: 313| Step: 0
Training loss: 1.7796236276626587
Validation loss: 1.8299178987421014

Epoch: 5| Step: 1
Training loss: 1.3860410451889038
Validation loss: 1.8340704851253058

Epoch: 5| Step: 2
Training loss: 1.2029836177825928
Validation loss: 1.8471169061558221

Epoch: 5| Step: 3
Training loss: 1.6312795877456665
Validation loss: 1.8624088943645518

Epoch: 5| Step: 4
Training loss: 1.5512561798095703
Validation loss: 1.820101249602533

Epoch: 5| Step: 5
Training loss: 1.2606227397918701
Validation loss: 1.788549582163493

Epoch: 5| Step: 6
Training loss: 1.8415682315826416
Validation loss: 1.8158546955354753

Epoch: 5| Step: 7
Training loss: 1.2300729751586914
Validation loss: 1.8362822789017872

Epoch: 5| Step: 8
Training loss: 1.7429202795028687
Validation loss: 1.814519610456241

Epoch: 5| Step: 9
Training loss: 1.4184367656707764
Validation loss: 1.8252228460004252

Epoch: 5| Step: 10
Training loss: 2.0503876209259033
Validation loss: 1.8221735428738337

Epoch: 314| Step: 0
Training loss: 1.1868536472320557
Validation loss: 1.826451386174848

Epoch: 5| Step: 1
Training loss: 1.7223190069198608
Validation loss: 1.8440285036640782

Epoch: 5| Step: 2
Training loss: 1.7473284006118774
Validation loss: 1.8605889569046676

Epoch: 5| Step: 3
Training loss: 1.801556944847107
Validation loss: 1.8476813890600716

Epoch: 5| Step: 4
Training loss: 1.1017366647720337
Validation loss: 1.8565564655488538

Epoch: 5| Step: 5
Training loss: 1.0488755702972412
Validation loss: 1.8315324783325195

Epoch: 5| Step: 6
Training loss: 1.398604393005371
Validation loss: 1.8005515119080902

Epoch: 5| Step: 7
Training loss: 1.9591825008392334
Validation loss: 1.8260305568736086

Epoch: 5| Step: 8
Training loss: 1.5866398811340332
Validation loss: 1.8299241514616116

Epoch: 5| Step: 9
Training loss: 1.6493949890136719
Validation loss: 1.8212906365753503

Epoch: 5| Step: 10
Training loss: 1.4689130783081055
Validation loss: 1.8079974318063388

Epoch: 315| Step: 0
Training loss: 1.3836495876312256
Validation loss: 1.8323220270936207

Epoch: 5| Step: 1
Training loss: 1.6664209365844727
Validation loss: 1.816822382711595

Epoch: 5| Step: 2
Training loss: 1.5905123949050903
Validation loss: 1.8216630566504695

Epoch: 5| Step: 3
Training loss: 2.115661144256592
Validation loss: 1.8028166396643526

Epoch: 5| Step: 4
Training loss: 1.5862491130828857
Validation loss: 1.8518653326137091

Epoch: 5| Step: 5
Training loss: 1.093498945236206
Validation loss: 1.8675743226082093

Epoch: 5| Step: 6
Training loss: 1.7178733348846436
Validation loss: 1.8338204365904613

Epoch: 5| Step: 7
Training loss: 1.6402946710586548
Validation loss: 1.8780676498207995

Epoch: 5| Step: 8
Training loss: 1.2870094776153564
Validation loss: 1.8537424379779446

Epoch: 5| Step: 9
Training loss: 1.156700611114502
Validation loss: 1.8516945659473378

Epoch: 5| Step: 10
Training loss: 2.023827075958252
Validation loss: 1.836701504645809

Epoch: 316| Step: 0
Training loss: 1.053092360496521
Validation loss: 1.8554319015113256

Epoch: 5| Step: 1
Training loss: 1.14011812210083
Validation loss: 1.8289374074628275

Epoch: 5| Step: 2
Training loss: 2.0526809692382812
Validation loss: 1.821515824205132

Epoch: 5| Step: 3
Training loss: 1.2906734943389893
Validation loss: 1.7912692857044998

Epoch: 5| Step: 4
Training loss: 1.4711211919784546
Validation loss: 1.8007964959708593

Epoch: 5| Step: 5
Training loss: 1.6551930904388428
Validation loss: 1.8113584403068788

Epoch: 5| Step: 6
Training loss: 1.498720407485962
Validation loss: 1.8139306319657194

Epoch: 5| Step: 7
Training loss: 1.959671974182129
Validation loss: 1.8135149376366728

Epoch: 5| Step: 8
Training loss: 1.510573148727417
Validation loss: 1.8127062070754267

Epoch: 5| Step: 9
Training loss: 1.9752905368804932
Validation loss: 1.8159624094604163

Epoch: 5| Step: 10
Training loss: 1.2016562223434448
Validation loss: 1.7958771592827254

Epoch: 317| Step: 0
Training loss: 1.2389005422592163
Validation loss: 1.8426994469857985

Epoch: 5| Step: 1
Training loss: 1.2928509712219238
Validation loss: 1.8583424270793956

Epoch: 5| Step: 2
Training loss: 0.9516423940658569
Validation loss: 1.8455283975088468

Epoch: 5| Step: 3
Training loss: 1.379632592201233
Validation loss: 1.8787336298214492

Epoch: 5| Step: 4
Training loss: 1.5441232919692993
Validation loss: 1.83653397457574

Epoch: 5| Step: 5
Training loss: 1.5127424001693726
Validation loss: 1.8678751709640666

Epoch: 5| Step: 6
Training loss: 2.3937859535217285
Validation loss: 1.8285473469764955

Epoch: 5| Step: 7
Training loss: 1.6773446798324585
Validation loss: 1.8577818485998339

Epoch: 5| Step: 8
Training loss: 1.4692572355270386
Validation loss: 1.81570448670336

Epoch: 5| Step: 9
Training loss: 1.6351025104522705
Validation loss: 1.8099066775332215

Epoch: 5| Step: 10
Training loss: 1.8933687210083008
Validation loss: 1.834421637237713

Epoch: 318| Step: 0
Training loss: 2.06591534614563
Validation loss: 1.8255665891913957

Epoch: 5| Step: 1
Training loss: 1.2132387161254883
Validation loss: 1.8174036343892415

Epoch: 5| Step: 2
Training loss: 1.0362409353256226
Validation loss: 1.7882392585918467

Epoch: 5| Step: 3
Training loss: 1.520779013633728
Validation loss: 1.809325946274624

Epoch: 5| Step: 4
Training loss: 1.6838712692260742
Validation loss: 1.820549685467956

Epoch: 5| Step: 5
Training loss: 1.6290819644927979
Validation loss: 1.7993834582708215

Epoch: 5| Step: 6
Training loss: 1.3531006574630737
Validation loss: 1.8116102564719416

Epoch: 5| Step: 7
Training loss: 1.3691402673721313
Validation loss: 1.8285278709985877

Epoch: 5| Step: 8
Training loss: 1.6157853603363037
Validation loss: 1.7702703091406053

Epoch: 5| Step: 9
Training loss: 1.876516342163086
Validation loss: 1.8089050093004782

Epoch: 5| Step: 10
Training loss: 1.3416231870651245
Validation loss: 1.8351577610097907

Epoch: 319| Step: 0
Training loss: 0.9892715215682983
Validation loss: 1.8421984180327384

Epoch: 5| Step: 1
Training loss: 1.628424048423767
Validation loss: 1.8288984760161369

Epoch: 5| Step: 2
Training loss: 1.5855329036712646
Validation loss: 1.8262243655420118

Epoch: 5| Step: 3
Training loss: 1.394395112991333
Validation loss: 1.846918672643682

Epoch: 5| Step: 4
Training loss: 1.099350094795227
Validation loss: 1.852108661205538

Epoch: 5| Step: 5
Training loss: 1.7340717315673828
Validation loss: 1.8181915078111874

Epoch: 5| Step: 6
Training loss: 1.567490816116333
Validation loss: 1.8444261922631213

Epoch: 5| Step: 7
Training loss: 1.8183519840240479
Validation loss: 1.8410856416148524

Epoch: 5| Step: 8
Training loss: 1.2571852207183838
Validation loss: 1.854616927844222

Epoch: 5| Step: 9
Training loss: 1.9771848917007446
Validation loss: 1.846299930285382

Epoch: 5| Step: 10
Training loss: 1.3719806671142578
Validation loss: 1.833973224445056

Epoch: 320| Step: 0
Training loss: 1.27308988571167
Validation loss: 1.8709762250223467

Epoch: 5| Step: 1
Training loss: 1.9705772399902344
Validation loss: 1.850686198921614

Epoch: 5| Step: 2
Training loss: 1.1969090700149536
Validation loss: 1.876612558159777

Epoch: 5| Step: 3
Training loss: 1.9294102191925049
Validation loss: 1.8528765978351716

Epoch: 5| Step: 4
Training loss: 1.1441326141357422
Validation loss: 1.83925344738909

Epoch: 5| Step: 5
Training loss: 2.010352373123169
Validation loss: 1.839226274080174

Epoch: 5| Step: 6
Training loss: 1.2177822589874268
Validation loss: 1.829880299106721

Epoch: 5| Step: 7
Training loss: 1.3058961629867554
Validation loss: 1.8260616179435485

Epoch: 5| Step: 8
Training loss: 1.0492374897003174
Validation loss: 1.8301637826427337

Epoch: 5| Step: 9
Training loss: 1.6289126873016357
Validation loss: 1.8225948656758955

Epoch: 5| Step: 10
Training loss: 2.202460765838623
Validation loss: 1.843147438059571

Epoch: 321| Step: 0
Training loss: 1.1439175605773926
Validation loss: 1.8048299692010368

Epoch: 5| Step: 1
Training loss: 1.8715293407440186
Validation loss: 1.7706606913638372

Epoch: 5| Step: 2
Training loss: 1.8551247119903564
Validation loss: 1.8196768645317323

Epoch: 5| Step: 3
Training loss: 1.857264757156372
Validation loss: 1.7950813437020907

Epoch: 5| Step: 4
Training loss: 1.4555326700210571
Validation loss: 1.8219154855256439

Epoch: 5| Step: 5
Training loss: 1.549891710281372
Validation loss: 1.7941122952327933

Epoch: 5| Step: 6
Training loss: 1.602643370628357
Validation loss: 1.8218155881410003

Epoch: 5| Step: 7
Training loss: 1.4876054525375366
Validation loss: 1.7840194215056717

Epoch: 5| Step: 8
Training loss: 1.1296190023422241
Validation loss: 1.8197669598364061

Epoch: 5| Step: 9
Training loss: 1.3882216215133667
Validation loss: 1.7725434277647285

Epoch: 5| Step: 10
Training loss: 1.2030935287475586
Validation loss: 1.8093745811011201

Epoch: 322| Step: 0
Training loss: 1.8062598705291748
Validation loss: 1.844130709607114

Epoch: 5| Step: 1
Training loss: 1.62985098361969
Validation loss: 1.8384084522083242

Epoch: 5| Step: 2
Training loss: 1.297463059425354
Validation loss: 1.8384998190787532

Epoch: 5| Step: 3
Training loss: 1.9069591760635376
Validation loss: 1.83259210407093

Epoch: 5| Step: 4
Training loss: 1.5348819494247437
Validation loss: 1.81204483842337

Epoch: 5| Step: 5
Training loss: 0.9537978172302246
Validation loss: 1.8876167830600534

Epoch: 5| Step: 6
Training loss: 1.7220840454101562
Validation loss: 1.8252634425317087

Epoch: 5| Step: 7
Training loss: 1.225207805633545
Validation loss: 1.8496918716738302

Epoch: 5| Step: 8
Training loss: 2.0592830181121826
Validation loss: 1.8193003541679793

Epoch: 5| Step: 9
Training loss: 1.3537890911102295
Validation loss: 1.8137059609095256

Epoch: 5| Step: 10
Training loss: 1.0541316270828247
Validation loss: 1.8415400340992918

Epoch: 323| Step: 0
Training loss: 1.905099630355835
Validation loss: 1.8217312969187254

Epoch: 5| Step: 1
Training loss: 1.111081600189209
Validation loss: 1.7884955739462247

Epoch: 5| Step: 2
Training loss: 1.8994954824447632
Validation loss: 1.8092510264406922

Epoch: 5| Step: 3
Training loss: 1.7778279781341553
Validation loss: 1.815201849065801

Epoch: 5| Step: 4
Training loss: 1.4661346673965454
Validation loss: 1.7920866794483636

Epoch: 5| Step: 5
Training loss: 1.2102633714675903
Validation loss: 1.7958132451580417

Epoch: 5| Step: 6
Training loss: 1.6260019540786743
Validation loss: 1.8120908173181678

Epoch: 5| Step: 7
Training loss: 1.4944469928741455
Validation loss: 1.8139994913531887

Epoch: 5| Step: 8
Training loss: 1.4059092998504639
Validation loss: 1.7826987748504968

Epoch: 5| Step: 9
Training loss: 0.982781708240509
Validation loss: 1.8362293935591174

Epoch: 5| Step: 10
Training loss: 2.0836503505706787
Validation loss: 1.7965620615149056

Epoch: 324| Step: 0
Training loss: 1.8711971044540405
Validation loss: 1.823463209213749

Epoch: 5| Step: 1
Training loss: 1.5884716510772705
Validation loss: 1.8093513288805563

Epoch: 5| Step: 2
Training loss: 1.4814494848251343
Validation loss: 1.8440514046658751

Epoch: 5| Step: 3
Training loss: 1.2931780815124512
Validation loss: 1.8414027819069483

Epoch: 5| Step: 4
Training loss: 1.3860256671905518
Validation loss: 1.85507236501222

Epoch: 5| Step: 5
Training loss: 1.6207361221313477
Validation loss: 1.864105095145523

Epoch: 5| Step: 6
Training loss: 1.4410488605499268
Validation loss: 1.880747264431369

Epoch: 5| Step: 7
Training loss: 1.574690580368042
Validation loss: 1.8396492209485782

Epoch: 5| Step: 8
Training loss: 1.448284387588501
Validation loss: 1.8446999647284066

Epoch: 5| Step: 9
Training loss: 1.2157084941864014
Validation loss: 1.8566937728594708

Epoch: 5| Step: 10
Training loss: 1.7440311908721924
Validation loss: 1.8212314216039514

Epoch: 325| Step: 0
Training loss: 2.069221019744873
Validation loss: 1.8590260231366722

Epoch: 5| Step: 1
Training loss: 1.7103198766708374
Validation loss: 1.8182772603086246

Epoch: 5| Step: 2
Training loss: 1.7258456945419312
Validation loss: 1.8060480087034163

Epoch: 5| Step: 3
Training loss: 0.9689551591873169
Validation loss: 1.8519265497884443

Epoch: 5| Step: 4
Training loss: 1.0092843770980835
Validation loss: 1.7954829777440717

Epoch: 5| Step: 5
Training loss: 1.1432329416275024
Validation loss: 1.860245148340861

Epoch: 5| Step: 6
Training loss: 1.5552732944488525
Validation loss: 1.7889203615086053

Epoch: 5| Step: 7
Training loss: 1.9149948358535767
Validation loss: 1.8386651777452039

Epoch: 5| Step: 8
Training loss: 1.4075310230255127
Validation loss: 1.8314491600118659

Epoch: 5| Step: 9
Training loss: 1.4480037689208984
Validation loss: 1.8251771516697382

Epoch: 5| Step: 10
Training loss: 1.853119969367981
Validation loss: 1.824379878659402

Epoch: 326| Step: 0
Training loss: 1.4305278062820435
Validation loss: 1.8404121565562424

Epoch: 5| Step: 1
Training loss: 2.177119493484497
Validation loss: 1.8062350480787215

Epoch: 5| Step: 2
Training loss: 1.4152204990386963
Validation loss: 1.7963726533356534

Epoch: 5| Step: 3
Training loss: 1.896219253540039
Validation loss: 1.8414803051179456

Epoch: 5| Step: 4
Training loss: 1.6177356243133545
Validation loss: 1.8158519857673234

Epoch: 5| Step: 5
Training loss: 1.4181066751480103
Validation loss: 1.841376394353887

Epoch: 5| Step: 6
Training loss: 1.0171159505844116
Validation loss: 1.8578565325788272

Epoch: 5| Step: 7
Training loss: 1.4340678453445435
Validation loss: 1.8141174688134143

Epoch: 5| Step: 8
Training loss: 1.5874855518341064
Validation loss: 1.8003666016363329

Epoch: 5| Step: 9
Training loss: 1.2812883853912354
Validation loss: 1.79998230677779

Epoch: 5| Step: 10
Training loss: 1.0906211137771606
Validation loss: 1.8102678534805134

Epoch: 327| Step: 0
Training loss: 1.7570005655288696
Validation loss: 1.812661660614834

Epoch: 5| Step: 1
Training loss: 1.898637056350708
Validation loss: 1.8283622034134404

Epoch: 5| Step: 2
Training loss: 1.7572885751724243
Validation loss: 1.8103546801433767

Epoch: 5| Step: 3
Training loss: 1.9167343378067017
Validation loss: 1.821903629969525

Epoch: 5| Step: 4
Training loss: 0.8911696672439575
Validation loss: 1.8432586398175967

Epoch: 5| Step: 5
Training loss: 1.0552974939346313
Validation loss: 1.8369069227608301

Epoch: 5| Step: 6
Training loss: 1.2911245822906494
Validation loss: 1.8493527955906366

Epoch: 5| Step: 7
Training loss: 1.3706930875778198
Validation loss: 1.8713444714905114

Epoch: 5| Step: 8
Training loss: 1.6622135639190674
Validation loss: 1.8297142239027127

Epoch: 5| Step: 9
Training loss: 1.6624809503555298
Validation loss: 1.836833752611632

Epoch: 5| Step: 10
Training loss: 1.119973063468933
Validation loss: 1.8184909628283592

Epoch: 328| Step: 0
Training loss: 1.2705549001693726
Validation loss: 1.8267870205704884

Epoch: 5| Step: 1
Training loss: 1.659618616104126
Validation loss: 1.8311745018087409

Epoch: 5| Step: 2
Training loss: 1.3930476903915405
Validation loss: 1.8275991485964866

Epoch: 5| Step: 3
Training loss: 2.048065185546875
Validation loss: 1.8065650040103542

Epoch: 5| Step: 4
Training loss: 1.8772475719451904
Validation loss: 1.8513736455671248

Epoch: 5| Step: 5
Training loss: 1.1338733434677124
Validation loss: 1.8194291066097956

Epoch: 5| Step: 6
Training loss: 1.6760305166244507
Validation loss: 1.8500097426035071

Epoch: 5| Step: 7
Training loss: 1.4380905628204346
Validation loss: 1.8296205036101802

Epoch: 5| Step: 8
Training loss: 0.8955450057983398
Validation loss: 1.790158692226615

Epoch: 5| Step: 9
Training loss: 1.317630410194397
Validation loss: 1.822783262498917

Epoch: 5| Step: 10
Training loss: 1.693507194519043
Validation loss: 1.835941409551969

Epoch: 329| Step: 0
Training loss: 1.5282484292984009
Validation loss: 1.8149205600061724

Epoch: 5| Step: 1
Training loss: 1.0801223516464233
Validation loss: 1.8007289196855278

Epoch: 5| Step: 2
Training loss: 1.4235931634902954
Validation loss: 1.806058508093639

Epoch: 5| Step: 3
Training loss: 1.3697471618652344
Validation loss: 1.808030532252404

Epoch: 5| Step: 4
Training loss: 1.2710932493209839
Validation loss: 1.8078502916520642

Epoch: 5| Step: 5
Training loss: 1.384883165359497
Validation loss: 1.8259044436998264

Epoch: 5| Step: 6
Training loss: 1.4328886270523071
Validation loss: 1.801170975931229

Epoch: 5| Step: 7
Training loss: 1.377410888671875
Validation loss: 1.8037305852418304

Epoch: 5| Step: 8
Training loss: 1.5636489391326904
Validation loss: 1.8158607085545857

Epoch: 5| Step: 9
Training loss: 2.3300387859344482
Validation loss: 1.8342257186930666

Epoch: 5| Step: 10
Training loss: 1.705344319343567
Validation loss: 1.7877661361489245

Epoch: 330| Step: 0
Training loss: 1.7023283243179321
Validation loss: 1.8366799239189393

Epoch: 5| Step: 1
Training loss: 1.441028356552124
Validation loss: 1.8345984464050622

Epoch: 5| Step: 2
Training loss: 1.674232840538025
Validation loss: 1.8524664243062336

Epoch: 5| Step: 3
Training loss: 1.6185709238052368
Validation loss: 1.8307264876622025

Epoch: 5| Step: 4
Training loss: 0.9064884185791016
Validation loss: 1.7931323717999201

Epoch: 5| Step: 5
Training loss: 1.1750268936157227
Validation loss: 1.828899122053577

Epoch: 5| Step: 6
Training loss: 1.5418109893798828
Validation loss: 1.8152513657846758

Epoch: 5| Step: 7
Training loss: 1.5762076377868652
Validation loss: 1.8465168271013486

Epoch: 5| Step: 8
Training loss: 1.3120322227478027
Validation loss: 1.866876381699757

Epoch: 5| Step: 9
Training loss: 1.5842596292495728
Validation loss: 1.8051866113498647

Epoch: 5| Step: 10
Training loss: 1.7737222909927368
Validation loss: 1.8345979323951147

Epoch: 331| Step: 0
Training loss: 1.9344228506088257
Validation loss: 1.8188340587000693

Epoch: 5| Step: 1
Training loss: 1.5656406879425049
Validation loss: 1.8482750641402377

Epoch: 5| Step: 2
Training loss: 1.6947904825210571
Validation loss: 1.8091999882011003

Epoch: 5| Step: 3
Training loss: 1.821354866027832
Validation loss: 1.810284415880839

Epoch: 5| Step: 4
Training loss: 0.6977323889732361
Validation loss: 1.8430735526546356

Epoch: 5| Step: 5
Training loss: 1.789104700088501
Validation loss: 1.8356969074536396

Epoch: 5| Step: 6
Training loss: 1.8353683948516846
Validation loss: 1.8182464927755377

Epoch: 5| Step: 7
Training loss: 1.0568820238113403
Validation loss: 1.8454096137836415

Epoch: 5| Step: 8
Training loss: 1.1334269046783447
Validation loss: 1.7974694262268722

Epoch: 5| Step: 9
Training loss: 1.6819645166397095
Validation loss: 1.8645003002177003

Epoch: 5| Step: 10
Training loss: 1.0658729076385498
Validation loss: 1.8661339206080283

Epoch: 332| Step: 0
Training loss: 1.3861780166625977
Validation loss: 1.8047855823270735

Epoch: 5| Step: 1
Training loss: 1.8274953365325928
Validation loss: 1.8134206571886617

Epoch: 5| Step: 2
Training loss: 1.4837312698364258
Validation loss: 1.8480097350253855

Epoch: 5| Step: 3
Training loss: 1.3139317035675049
Validation loss: 1.8154695585209837

Epoch: 5| Step: 4
Training loss: 1.4528144598007202
Validation loss: 1.8259945402863205

Epoch: 5| Step: 5
Training loss: 1.5092262029647827
Validation loss: 1.8352210355061356

Epoch: 5| Step: 6
Training loss: 1.4044381380081177
Validation loss: 1.8352025298662082

Epoch: 5| Step: 7
Training loss: 1.5709701776504517
Validation loss: 1.8456328838102278

Epoch: 5| Step: 8
Training loss: 0.8786638379096985
Validation loss: 1.8048108803328646

Epoch: 5| Step: 9
Training loss: 1.7940765619277954
Validation loss: 1.828514575958252

Epoch: 5| Step: 10
Training loss: 1.8914822340011597
Validation loss: 1.8540202622772546

Epoch: 333| Step: 0
Training loss: 1.349063754081726
Validation loss: 1.80871908767249

Epoch: 5| Step: 1
Training loss: 1.8012657165527344
Validation loss: 1.846510737173019

Epoch: 5| Step: 2
Training loss: 1.6344249248504639
Validation loss: 1.8086702208365164

Epoch: 5| Step: 3
Training loss: 1.9197843074798584
Validation loss: 1.78923931173099

Epoch: 5| Step: 4
Training loss: 1.418415904045105
Validation loss: 1.8371998571580457

Epoch: 5| Step: 5
Training loss: 1.7466771602630615
Validation loss: 1.8270411901576544

Epoch: 5| Step: 6
Training loss: 1.375622034072876
Validation loss: 1.8071566589416996

Epoch: 5| Step: 7
Training loss: 0.7777469754219055
Validation loss: 1.8078272637500559

Epoch: 5| Step: 8
Training loss: 1.3374613523483276
Validation loss: 1.8310271078540432

Epoch: 5| Step: 9
Training loss: 1.641531229019165
Validation loss: 1.848518563855079

Epoch: 5| Step: 10
Training loss: 1.2245392799377441
Validation loss: 1.8375861619108467

Epoch: 334| Step: 0
Training loss: 1.4276845455169678
Validation loss: 1.8522417724773448

Epoch: 5| Step: 1
Training loss: 1.562735915184021
Validation loss: 1.809469953660042

Epoch: 5| Step: 2
Training loss: 1.4440606832504272
Validation loss: 1.8117442156678887

Epoch: 5| Step: 3
Training loss: 1.0354716777801514
Validation loss: 1.8042609217346355

Epoch: 5| Step: 4
Training loss: 1.848864197731018
Validation loss: 1.7999654046950802

Epoch: 5| Step: 5
Training loss: 2.0706653594970703
Validation loss: 1.8196092920918618

Epoch: 5| Step: 6
Training loss: 0.9222575426101685
Validation loss: 1.8275458863986436

Epoch: 5| Step: 7
Training loss: 0.9666098356246948
Validation loss: 1.8250212413008495

Epoch: 5| Step: 8
Training loss: 1.5015424489974976
Validation loss: 1.8493844219433364

Epoch: 5| Step: 9
Training loss: 2.0042521953582764
Validation loss: 1.8359419568892448

Epoch: 5| Step: 10
Training loss: 1.1456007957458496
Validation loss: 1.8356634275887602

Epoch: 335| Step: 0
Training loss: 0.99195796251297
Validation loss: 1.8127079035646172

Epoch: 5| Step: 1
Training loss: 1.7614948749542236
Validation loss: 1.803148933636245

Epoch: 5| Step: 2
Training loss: 1.4536712169647217
Validation loss: 1.867026893041467

Epoch: 5| Step: 3
Training loss: 1.412327766418457
Validation loss: 1.814056557993735

Epoch: 5| Step: 4
Training loss: 1.6990407705307007
Validation loss: 1.8300255511396675

Epoch: 5| Step: 5
Training loss: 1.663903832435608
Validation loss: 1.8333294417268486

Epoch: 5| Step: 6
Training loss: 1.8084617853164673
Validation loss: 1.8268588012264622

Epoch: 5| Step: 7
Training loss: 1.3744478225708008
Validation loss: 1.8055378057623421

Epoch: 5| Step: 8
Training loss: 1.62820565700531
Validation loss: 1.8261587055780555

Epoch: 5| Step: 9
Training loss: 1.2377411127090454
Validation loss: 1.7977845348337644

Epoch: 5| Step: 10
Training loss: 1.1443372964859009
Validation loss: 1.8353486317460255

Epoch: 336| Step: 0
Training loss: 1.3876609802246094
Validation loss: 1.8544179457490162

Epoch: 5| Step: 1
Training loss: 1.2163832187652588
Validation loss: 1.8673138323650564

Epoch: 5| Step: 2
Training loss: 1.8038257360458374
Validation loss: 1.8679876353151055

Epoch: 5| Step: 3
Training loss: 1.2004016637802124
Validation loss: 1.8479960349298292

Epoch: 5| Step: 4
Training loss: 1.7709659337997437
Validation loss: 1.8490325071478402

Epoch: 5| Step: 5
Training loss: 1.4481714963912964
Validation loss: 1.8025386692375265

Epoch: 5| Step: 6
Training loss: 1.5287050008773804
Validation loss: 1.8880653573620705

Epoch: 5| Step: 7
Training loss: 1.6980870962142944
Validation loss: 1.7958667406471827

Epoch: 5| Step: 8
Training loss: 1.397392988204956
Validation loss: 1.8155851876863869

Epoch: 5| Step: 9
Training loss: 1.5262869596481323
Validation loss: 1.8088558002184796

Epoch: 5| Step: 10
Training loss: 1.2750605344772339
Validation loss: 1.828931946908274

Epoch: 337| Step: 0
Training loss: 1.3769031763076782
Validation loss: 1.7855946902305848

Epoch: 5| Step: 1
Training loss: 1.7774375677108765
Validation loss: 1.8088993731365408

Epoch: 5| Step: 2
Training loss: 1.638899803161621
Validation loss: 1.8018134691381966

Epoch: 5| Step: 3
Training loss: 1.1333484649658203
Validation loss: 1.8460871763126825

Epoch: 5| Step: 4
Training loss: 1.450585126876831
Validation loss: 1.838731099200505

Epoch: 5| Step: 5
Training loss: 1.6886926889419556
Validation loss: 1.7828077911048807

Epoch: 5| Step: 6
Training loss: 1.4160728454589844
Validation loss: 1.8412231072302787

Epoch: 5| Step: 7
Training loss: 1.2519580125808716
Validation loss: 1.8294191578383088

Epoch: 5| Step: 8
Training loss: 1.2026914358139038
Validation loss: 1.8564491720609768

Epoch: 5| Step: 9
Training loss: 1.516796350479126
Validation loss: 1.809817212884144

Epoch: 5| Step: 10
Training loss: 1.6527308225631714
Validation loss: 1.8023049562208113

Epoch: 338| Step: 0
Training loss: 1.709376573562622
Validation loss: 1.8424406795091526

Epoch: 5| Step: 1
Training loss: 1.1527175903320312
Validation loss: 1.813628665862545

Epoch: 5| Step: 2
Training loss: 1.2621371746063232
Validation loss: 1.8149999495475524

Epoch: 5| Step: 3
Training loss: 2.0954155921936035
Validation loss: 1.818502003146756

Epoch: 5| Step: 4
Training loss: 1.5664409399032593
Validation loss: 1.8535980396373297

Epoch: 5| Step: 5
Training loss: 1.0841434001922607
Validation loss: 1.829439837445495

Epoch: 5| Step: 6
Training loss: 1.2575757503509521
Validation loss: 1.8161441690178328

Epoch: 5| Step: 7
Training loss: 1.326722502708435
Validation loss: 1.837875852020838

Epoch: 5| Step: 8
Training loss: 1.8584766387939453
Validation loss: 1.7997208936240083

Epoch: 5| Step: 9
Training loss: 1.1047626733779907
Validation loss: 1.798696348744054

Epoch: 5| Step: 10
Training loss: 1.827275037765503
Validation loss: 1.806903285364951

Epoch: 339| Step: 0
Training loss: 1.126899242401123
Validation loss: 1.8117194919175998

Epoch: 5| Step: 1
Training loss: 1.6414158344268799
Validation loss: 1.83672708465207

Epoch: 5| Step: 2
Training loss: 1.467248797416687
Validation loss: 1.823091656930985

Epoch: 5| Step: 3
Training loss: 1.4505800008773804
Validation loss: 1.8302373988654024

Epoch: 5| Step: 4
Training loss: 1.0721503496170044
Validation loss: 1.8539230490243563

Epoch: 5| Step: 5
Training loss: 2.073044538497925
Validation loss: 1.8239307685564923

Epoch: 5| Step: 6
Training loss: 1.7197787761688232
Validation loss: 1.8305185046247257

Epoch: 5| Step: 7
Training loss: 1.1978665590286255
Validation loss: 1.873527738355821

Epoch: 5| Step: 8
Training loss: 1.7136322259902954
Validation loss: 1.8422395503649147

Epoch: 5| Step: 9
Training loss: 1.2401472330093384
Validation loss: 1.823414578232714

Epoch: 5| Step: 10
Training loss: 1.5551958084106445
Validation loss: 1.8703143776104014

Epoch: 340| Step: 0
Training loss: 1.5038782358169556
Validation loss: 1.8395551481554586

Epoch: 5| Step: 1
Training loss: 1.6536996364593506
Validation loss: 1.8371826705112253

Epoch: 5| Step: 2
Training loss: 1.1018058061599731
Validation loss: 1.8030014179086173

Epoch: 5| Step: 3
Training loss: 2.089447259902954
Validation loss: 1.8321504592895508

Epoch: 5| Step: 4
Training loss: 1.8562657833099365
Validation loss: 1.818359827482572

Epoch: 5| Step: 5
Training loss: 1.359392762184143
Validation loss: 1.8160196901649557

Epoch: 5| Step: 6
Training loss: 1.681478500366211
Validation loss: 1.8038088967723231

Epoch: 5| Step: 7
Training loss: 1.0871798992156982
Validation loss: 1.8019574483235676

Epoch: 5| Step: 8
Training loss: 0.7963364124298096
Validation loss: 1.8348453685801516

Epoch: 5| Step: 9
Training loss: 1.3619624376296997
Validation loss: 1.8486782812303113

Epoch: 5| Step: 10
Training loss: 1.667790412902832
Validation loss: 1.8135897831250263

Epoch: 341| Step: 0
Training loss: 1.7600208520889282
Validation loss: 1.8138138953075613

Epoch: 5| Step: 1
Training loss: 1.8724620342254639
Validation loss: 1.8289314764802174

Epoch: 5| Step: 2
Training loss: 1.6672627925872803
Validation loss: 1.8358598575797132

Epoch: 5| Step: 3
Training loss: 1.3555870056152344
Validation loss: 1.8472043570651804

Epoch: 5| Step: 4
Training loss: 1.5161489248275757
Validation loss: 1.832102314118416

Epoch: 5| Step: 5
Training loss: 1.2247252464294434
Validation loss: 1.8424619218354583

Epoch: 5| Step: 6
Training loss: 1.5819851160049438
Validation loss: 1.8505090346900366

Epoch: 5| Step: 7
Training loss: 0.5743156671524048
Validation loss: 1.839430929512106

Epoch: 5| Step: 8
Training loss: 1.7759240865707397
Validation loss: 1.848082302719034

Epoch: 5| Step: 9
Training loss: 1.152732253074646
Validation loss: 1.8371446273660148

Epoch: 5| Step: 10
Training loss: 1.8099356889724731
Validation loss: 1.8386303635053738

Epoch: 342| Step: 0
Training loss: 1.3915826082229614
Validation loss: 1.819144666835826

Epoch: 5| Step: 1
Training loss: 1.1251198053359985
Validation loss: 1.8365804251804148

Epoch: 5| Step: 2
Training loss: 1.4824178218841553
Validation loss: 1.857295261916294

Epoch: 5| Step: 3
Training loss: 1.1606446504592896
Validation loss: 1.866747962531223

Epoch: 5| Step: 4
Training loss: 1.2710916996002197
Validation loss: 1.8586526980964087

Epoch: 5| Step: 5
Training loss: 1.1364439725875854
Validation loss: 1.8438736213150846

Epoch: 5| Step: 6
Training loss: 1.503455638885498
Validation loss: 1.868196648936118

Epoch: 5| Step: 7
Training loss: 2.1102993488311768
Validation loss: 1.8538399268222112

Epoch: 5| Step: 8
Training loss: 1.542457938194275
Validation loss: 1.8268526625889603

Epoch: 5| Step: 9
Training loss: 2.1067287921905518
Validation loss: 1.8250329007384598

Epoch: 5| Step: 10
Training loss: 1.3885375261306763
Validation loss: 1.8306212514959357

Epoch: 343| Step: 0
Training loss: 1.676717758178711
Validation loss: 1.7792958726165116

Epoch: 5| Step: 1
Training loss: 1.3678796291351318
Validation loss: 1.8288694248404553

Epoch: 5| Step: 2
Training loss: 1.4275718927383423
Validation loss: 1.8210960677874986

Epoch: 5| Step: 3
Training loss: 1.3350452184677124
Validation loss: 1.8438672609226678

Epoch: 5| Step: 4
Training loss: 1.149339199066162
Validation loss: 1.8476356857566423

Epoch: 5| Step: 5
Training loss: 1.907020926475525
Validation loss: 1.837562584107922

Epoch: 5| Step: 6
Training loss: 1.71880304813385
Validation loss: 1.8142553221794866

Epoch: 5| Step: 7
Training loss: 1.488175630569458
Validation loss: 1.7773384073729157

Epoch: 5| Step: 8
Training loss: 0.963668704032898
Validation loss: 1.821315235989068

Epoch: 5| Step: 9
Training loss: 1.6660999059677124
Validation loss: 1.8465746077158118

Epoch: 5| Step: 10
Training loss: 1.60463285446167
Validation loss: 1.854711918420689

Epoch: 344| Step: 0
Training loss: 1.44722580909729
Validation loss: 1.8153799733807963

Epoch: 5| Step: 1
Training loss: 1.3760786056518555
Validation loss: 1.8474586497070968

Epoch: 5| Step: 2
Training loss: 1.7999731302261353
Validation loss: 1.863042018746817

Epoch: 5| Step: 3
Training loss: 1.6762893199920654
Validation loss: 1.8515184899812103

Epoch: 5| Step: 4
Training loss: 1.089660406112671
Validation loss: 1.82067705738929

Epoch: 5| Step: 5
Training loss: 1.8895843029022217
Validation loss: 1.8516476256873018

Epoch: 5| Step: 6
Training loss: 1.4568352699279785
Validation loss: 1.823583261941069

Epoch: 5| Step: 7
Training loss: 1.6874204874038696
Validation loss: 1.8623957890336231

Epoch: 5| Step: 8
Training loss: 1.3057305812835693
Validation loss: 1.8189981688735306

Epoch: 5| Step: 9
Training loss: 0.9004193544387817
Validation loss: 1.8376075055009575

Epoch: 5| Step: 10
Training loss: 1.5372583866119385
Validation loss: 1.9059229281640822

Epoch: 345| Step: 0
Training loss: 1.3854072093963623
Validation loss: 1.8460976846756474

Epoch: 5| Step: 1
Training loss: 1.0824216604232788
Validation loss: 1.8052305303594118

Epoch: 5| Step: 2
Training loss: 1.5630080699920654
Validation loss: 1.8667289005812777

Epoch: 5| Step: 3
Training loss: 0.8685671091079712
Validation loss: 1.8193449717695995

Epoch: 5| Step: 4
Training loss: 1.8256175518035889
Validation loss: 1.8335959180708854

Epoch: 5| Step: 5
Training loss: 1.7289507389068604
Validation loss: 1.85786989683746

Epoch: 5| Step: 6
Training loss: 1.6466315984725952
Validation loss: 1.8388707368604598

Epoch: 5| Step: 7
Training loss: 1.1257880926132202
Validation loss: 1.8098760881731588

Epoch: 5| Step: 8
Training loss: 1.9656140804290771
Validation loss: 1.818023266330842

Epoch: 5| Step: 9
Training loss: 1.034469485282898
Validation loss: 1.8526150526538971

Epoch: 5| Step: 10
Training loss: 1.9499105215072632
Validation loss: 1.8205024760256532

Epoch: 346| Step: 0
Training loss: 1.63153076171875
Validation loss: 1.8233218628873107

Epoch: 5| Step: 1
Training loss: 1.2051751613616943
Validation loss: 1.8521025642271964

Epoch: 5| Step: 2
Training loss: 0.9929192662239075
Validation loss: 1.8278476820197156

Epoch: 5| Step: 3
Training loss: 1.573131799697876
Validation loss: 1.8343061234361382

Epoch: 5| Step: 4
Training loss: 1.7503547668457031
Validation loss: 1.817613181247506

Epoch: 5| Step: 5
Training loss: 1.027133584022522
Validation loss: 1.8191231386635893

Epoch: 5| Step: 6
Training loss: 1.4541670083999634
Validation loss: 1.8489900378770725

Epoch: 5| Step: 7
Training loss: 1.6651594638824463
Validation loss: 1.8146317415339972

Epoch: 5| Step: 8
Training loss: 1.3893043994903564
Validation loss: 1.8159651653740996

Epoch: 5| Step: 9
Training loss: 1.3788411617279053
Validation loss: 1.8047164986210484

Epoch: 5| Step: 10
Training loss: 1.546074628829956
Validation loss: 1.805045380387255

Epoch: 347| Step: 0
Training loss: 1.9213603734970093
Validation loss: 1.8153552727032733

Epoch: 5| Step: 1
Training loss: 1.5706404447555542
Validation loss: 1.8659058117097425

Epoch: 5| Step: 2
Training loss: 0.9084189534187317
Validation loss: 1.8135651632021832

Epoch: 5| Step: 3
Training loss: 1.1266592741012573
Validation loss: 1.8242145289656937

Epoch: 5| Step: 4
Training loss: 1.0847291946411133
Validation loss: 1.8482512876551638

Epoch: 5| Step: 5
Training loss: 2.084852457046509
Validation loss: 1.8123360013449064

Epoch: 5| Step: 6
Training loss: 1.4612681865692139
Validation loss: 1.8288501436992357

Epoch: 5| Step: 7
Training loss: 1.4818799495697021
Validation loss: 1.8312236916634343

Epoch: 5| Step: 8
Training loss: 1.6241792440414429
Validation loss: 1.811776630340084

Epoch: 5| Step: 9
Training loss: 1.3691819906234741
Validation loss: 1.8505709081567743

Epoch: 5| Step: 10
Training loss: 1.2756913900375366
Validation loss: 1.8342284566612654

Epoch: 348| Step: 0
Training loss: 1.62503981590271
Validation loss: 1.8292036466701056

Epoch: 5| Step: 1
Training loss: 2.1812334060668945
Validation loss: 1.8006371182780112

Epoch: 5| Step: 2
Training loss: 1.6093199253082275
Validation loss: 1.8490945011056878

Epoch: 5| Step: 3
Training loss: 1.9100425243377686
Validation loss: 1.8571973987804946

Epoch: 5| Step: 4
Training loss: 1.3694833517074585
Validation loss: 1.8382942163816063

Epoch: 5| Step: 5
Training loss: 1.3836784362792969
Validation loss: 1.8478637844003656

Epoch: 5| Step: 6
Training loss: 1.068615436553955
Validation loss: 1.7989516988877328

Epoch: 5| Step: 7
Training loss: 1.4640288352966309
Validation loss: 1.819311882859917

Epoch: 5| Step: 8
Training loss: 1.0886987447738647
Validation loss: 1.8572683949624338

Epoch: 5| Step: 9
Training loss: 0.8160907030105591
Validation loss: 1.8399506063871487

Epoch: 5| Step: 10
Training loss: 1.192670464515686
Validation loss: 1.8291526199668966

Epoch: 349| Step: 0
Training loss: 1.6486704349517822
Validation loss: 1.8586234226021716

Epoch: 5| Step: 1
Training loss: 1.4136825799942017
Validation loss: 1.8682813516227148

Epoch: 5| Step: 2
Training loss: 1.6553866863250732
Validation loss: 1.8305255052863911

Epoch: 5| Step: 3
Training loss: 1.483052372932434
Validation loss: 1.8447605063838344

Epoch: 5| Step: 4
Training loss: 1.795635461807251
Validation loss: 1.8665047178986252

Epoch: 5| Step: 5
Training loss: 0.9572283625602722
Validation loss: 1.8556951040862708

Epoch: 5| Step: 6
Training loss: 1.2666494846343994
Validation loss: 1.8384519046352756

Epoch: 5| Step: 7
Training loss: 1.399893045425415
Validation loss: 1.7959021573425622

Epoch: 5| Step: 8
Training loss: 1.488588571548462
Validation loss: 1.8316758371168567

Epoch: 5| Step: 9
Training loss: 1.3725707530975342
Validation loss: 1.824655673837149

Epoch: 5| Step: 10
Training loss: 1.5980936288833618
Validation loss: 1.840446977205174

Epoch: 350| Step: 0
Training loss: 1.185928225517273
Validation loss: 1.806904624867183

Epoch: 5| Step: 1
Training loss: 1.218969464302063
Validation loss: 1.8469704581845192

Epoch: 5| Step: 2
Training loss: 0.9881604313850403
Validation loss: 1.8523055968746063

Epoch: 5| Step: 3
Training loss: 1.4829025268554688
Validation loss: 1.8072829925885765

Epoch: 5| Step: 4
Training loss: 1.4855690002441406
Validation loss: 1.8468803795435096

Epoch: 5| Step: 5
Training loss: 1.3045752048492432
Validation loss: 1.8377516295320244

Epoch: 5| Step: 6
Training loss: 1.8601421117782593
Validation loss: 1.8689980865806661

Epoch: 5| Step: 7
Training loss: 1.1346503496170044
Validation loss: 1.809776230524945

Epoch: 5| Step: 8
Training loss: 1.716925859451294
Validation loss: 1.8721251449277323

Epoch: 5| Step: 9
Training loss: 1.5580766201019287
Validation loss: 1.8500700881404262

Epoch: 5| Step: 10
Training loss: 1.8952387571334839
Validation loss: 1.8500276791152133

Testing loss: 2.2784378793504505
