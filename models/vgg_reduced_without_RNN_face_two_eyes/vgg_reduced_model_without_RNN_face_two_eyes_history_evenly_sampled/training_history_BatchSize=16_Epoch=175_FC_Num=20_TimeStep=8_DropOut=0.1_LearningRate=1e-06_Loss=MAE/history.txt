Epoch: 1| Step: 0
Training loss: 5.727607727050781
Validation loss: 6.276859391120173

Epoch: 6| Step: 1
Training loss: 4.928964614868164
Validation loss: 6.272182567145235

Epoch: 6| Step: 2
Training loss: 5.406640529632568
Validation loss: 6.266411750547348

Epoch: 6| Step: 3
Training loss: 5.8579559326171875
Validation loss: 6.2597359482960035

Epoch: 6| Step: 4
Training loss: 8.140192031860352
Validation loss: 6.253628971756146

Epoch: 6| Step: 5
Training loss: 6.349112033843994
Validation loss: 6.245654270213137

Epoch: 6| Step: 6
Training loss: 5.191472053527832
Validation loss: 6.238937680439283

Epoch: 6| Step: 7
Training loss: 7.7335662841796875
Validation loss: 6.2347542393592095

Epoch: 6| Step: 8
Training loss: 6.328621864318848
Validation loss: 6.229671021943451

Epoch: 6| Step: 9
Training loss: 5.948390007019043
Validation loss: 6.221378203361265

Epoch: 6| Step: 10
Training loss: 6.362090110778809
Validation loss: 6.217298584599649

Epoch: 6| Step: 11
Training loss: 6.658283233642578
Validation loss: 6.21007171241186

Epoch: 6| Step: 12
Training loss: 4.941429138183594
Validation loss: 6.202457812524611

Epoch: 6| Step: 13
Training loss: 4.047091007232666
Validation loss: 6.200092300291984

Epoch: 2| Step: 0
Training loss: 5.117469310760498
Validation loss: 6.193987415682885

Epoch: 6| Step: 1
Training loss: 7.085660934448242
Validation loss: 6.187403960894513

Epoch: 6| Step: 2
Training loss: 6.205033302307129
Validation loss: 6.183169523874919

Epoch: 6| Step: 3
Training loss: 6.177663803100586
Validation loss: 6.175604112686649

Epoch: 6| Step: 4
Training loss: 3.6355953216552734
Validation loss: 6.169362601413522

Epoch: 6| Step: 5
Training loss: 6.650214195251465
Validation loss: 6.164267821978497

Epoch: 6| Step: 6
Training loss: 5.936962127685547
Validation loss: 6.158042179640903

Epoch: 6| Step: 7
Training loss: 6.201178550720215
Validation loss: 6.151647680549211

Epoch: 6| Step: 8
Training loss: 6.587028503417969
Validation loss: 6.146766247287873

Epoch: 6| Step: 9
Training loss: 7.15726375579834
Validation loss: 6.142727287866736

Epoch: 6| Step: 10
Training loss: 5.248149871826172
Validation loss: 6.1386109372620945

Epoch: 6| Step: 11
Training loss: 6.5950608253479
Validation loss: 6.133134682973226

Epoch: 6| Step: 12
Training loss: 5.501891136169434
Validation loss: 6.125071756301388

Epoch: 6| Step: 13
Training loss: 4.614436626434326
Validation loss: 6.121089945557297

Epoch: 3| Step: 0
Training loss: 5.437089443206787
Validation loss: 6.114610159268943

Epoch: 6| Step: 1
Training loss: 5.124192714691162
Validation loss: 6.108505561787595

Epoch: 6| Step: 2
Training loss: 4.93343448638916
Validation loss: 6.102220976224509

Epoch: 6| Step: 3
Training loss: 6.2871551513671875
Validation loss: 6.098528036507227

Epoch: 6| Step: 4
Training loss: 4.814016342163086
Validation loss: 6.092964500509282

Epoch: 6| Step: 5
Training loss: 6.617031097412109
Validation loss: 6.086476659262052

Epoch: 6| Step: 6
Training loss: 6.5323381423950195
Validation loss: 6.0824368282030985

Epoch: 6| Step: 7
Training loss: 5.909328460693359
Validation loss: 6.076469041967905

Epoch: 6| Step: 8
Training loss: 7.733959197998047
Validation loss: 6.071982737510435

Epoch: 6| Step: 9
Training loss: 6.434569835662842
Validation loss: 6.066074309810515

Epoch: 6| Step: 10
Training loss: 4.517354965209961
Validation loss: 6.06102381983111

Epoch: 6| Step: 11
Training loss: 5.793222427368164
Validation loss: 6.053054496806155

Epoch: 6| Step: 12
Training loss: 5.710458755493164
Validation loss: 6.047902276439052

Epoch: 6| Step: 13
Training loss: 6.733057022094727
Validation loss: 6.043005194715274

Epoch: 4| Step: 0
Training loss: 6.684503555297852
Validation loss: 6.0344971892654256

Epoch: 6| Step: 1
Training loss: 5.610625267028809
Validation loss: 6.0302369363846315

Epoch: 6| Step: 2
Training loss: 3.983720541000366
Validation loss: 6.027758459891042

Epoch: 6| Step: 3
Training loss: 5.100152015686035
Validation loss: 6.016795830060077

Epoch: 6| Step: 4
Training loss: 5.541577339172363
Validation loss: 6.013131639008881

Epoch: 6| Step: 5
Training loss: 6.778629302978516
Validation loss: 6.0066638454314205

Epoch: 6| Step: 6
Training loss: 4.406033992767334
Validation loss: 5.999180480998049

Epoch: 6| Step: 7
Training loss: 6.665224552154541
Validation loss: 5.993495264360981

Epoch: 6| Step: 8
Training loss: 5.942147731781006
Validation loss: 5.986574260137415

Epoch: 6| Step: 9
Training loss: 6.332523822784424
Validation loss: 5.982089893792265

Epoch: 6| Step: 10
Training loss: 6.311101913452148
Validation loss: 5.972237858721005

Epoch: 6| Step: 11
Training loss: 5.5776166915893555
Validation loss: 5.969252791455997

Epoch: 6| Step: 12
Training loss: 6.025754451751709
Validation loss: 5.960561706173804

Epoch: 6| Step: 13
Training loss: 6.252161026000977
Validation loss: 5.956090880978492

Epoch: 5| Step: 0
Training loss: 5.102876663208008
Validation loss: 5.9480568157729286

Epoch: 6| Step: 1
Training loss: 5.6335344314575195
Validation loss: 5.941983387034426

Epoch: 6| Step: 2
Training loss: 6.810824871063232
Validation loss: 5.9355968301014235

Epoch: 6| Step: 3
Training loss: 5.1441969871521
Validation loss: 5.926753249219669

Epoch: 6| Step: 4
Training loss: 5.914525032043457
Validation loss: 5.923292918871808

Epoch: 6| Step: 5
Training loss: 6.086691856384277
Validation loss: 5.917159788070187

Epoch: 6| Step: 6
Training loss: 6.064119338989258
Validation loss: 5.9086893399556475

Epoch: 6| Step: 7
Training loss: 6.227025985717773
Validation loss: 5.902834517981416

Epoch: 6| Step: 8
Training loss: 5.129223823547363
Validation loss: 5.893793336806759

Epoch: 6| Step: 9
Training loss: 6.768756866455078
Validation loss: 5.887663656665433

Epoch: 6| Step: 10
Training loss: 6.0702033042907715
Validation loss: 5.881770785136889

Epoch: 6| Step: 11
Training loss: 4.913690567016602
Validation loss: 5.871177032429685

Epoch: 6| Step: 12
Training loss: 4.0750837326049805
Validation loss: 5.864560998896117

Epoch: 6| Step: 13
Training loss: 5.78114128112793
Validation loss: 5.855053214616673

Epoch: 6| Step: 0
Training loss: 5.076009750366211
Validation loss: 5.848476676530735

Epoch: 6| Step: 1
Training loss: 6.241003036499023
Validation loss: 5.839714137456751

Epoch: 6| Step: 2
Training loss: 6.414996147155762
Validation loss: 5.831072489420573

Epoch: 6| Step: 3
Training loss: 4.018802642822266
Validation loss: 5.8265575234607985

Epoch: 6| Step: 4
Training loss: 7.364269256591797
Validation loss: 5.818274041657807

Epoch: 6| Step: 5
Training loss: 4.7340898513793945
Validation loss: 5.808771630769135

Epoch: 6| Step: 6
Training loss: 5.5009026527404785
Validation loss: 5.8000818734527915

Epoch: 6| Step: 7
Training loss: 6.257918357849121
Validation loss: 5.793119615124118

Epoch: 6| Step: 8
Training loss: 5.6263508796691895
Validation loss: 5.781897324387745

Epoch: 6| Step: 9
Training loss: 6.476716041564941
Validation loss: 5.7754225525804745

Epoch: 6| Step: 10
Training loss: 5.871837615966797
Validation loss: 5.7653964463100635

Epoch: 6| Step: 11
Training loss: 5.1116156578063965
Validation loss: 5.756084898466705

Epoch: 6| Step: 12
Training loss: 4.708197593688965
Validation loss: 5.746849193367907

Epoch: 6| Step: 13
Training loss: 4.088348388671875
Validation loss: 5.7391490321005545

Epoch: 7| Step: 0
Training loss: 5.697595596313477
Validation loss: 5.728986094074864

Epoch: 6| Step: 1
Training loss: 5.671792507171631
Validation loss: 5.718036605465796

Epoch: 6| Step: 2
Training loss: 5.331242084503174
Validation loss: 5.712889794380434

Epoch: 6| Step: 3
Training loss: 4.82843542098999
Validation loss: 5.699365328716976

Epoch: 6| Step: 4
Training loss: 6.346976280212402
Validation loss: 5.693451994208879

Epoch: 6| Step: 5
Training loss: 5.165149688720703
Validation loss: 5.683944640621062

Epoch: 6| Step: 6
Training loss: 5.861928939819336
Validation loss: 5.673412589616673

Epoch: 6| Step: 7
Training loss: 4.7773003578186035
Validation loss: 5.664876471283615

Epoch: 6| Step: 8
Training loss: 7.064189910888672
Validation loss: 5.654677196215558

Epoch: 6| Step: 9
Training loss: 4.656217098236084
Validation loss: 5.641871816368513

Epoch: 6| Step: 10
Training loss: 6.424142837524414
Validation loss: 5.633585017214539

Epoch: 6| Step: 11
Training loss: 4.1813154220581055
Validation loss: 5.6207549700173

Epoch: 6| Step: 12
Training loss: 5.388754844665527
Validation loss: 5.609672218240718

Epoch: 6| Step: 13
Training loss: 4.43029260635376
Validation loss: 5.60216619635141

Epoch: 8| Step: 0
Training loss: 5.670040130615234
Validation loss: 5.590300370288151

Epoch: 6| Step: 1
Training loss: 4.162815093994141
Validation loss: 5.5748229436976935

Epoch: 6| Step: 2
Training loss: 6.619032859802246
Validation loss: 5.569275163835095

Epoch: 6| Step: 3
Training loss: 5.2210235595703125
Validation loss: 5.556302121890488

Epoch: 6| Step: 4
Training loss: 5.00675630569458
Validation loss: 5.543507888752927

Epoch: 6| Step: 5
Training loss: 4.961077690124512
Validation loss: 5.529934206316548

Epoch: 6| Step: 6
Training loss: 5.165412902832031
Validation loss: 5.520931202878234

Epoch: 6| Step: 7
Training loss: 4.1059112548828125
Validation loss: 5.511001663823282

Epoch: 6| Step: 8
Training loss: 6.29210901260376
Validation loss: 5.496915345550866

Epoch: 6| Step: 9
Training loss: 5.6483564376831055
Validation loss: 5.482729255512196

Epoch: 6| Step: 10
Training loss: 4.922619342803955
Validation loss: 5.474993146875853

Epoch: 6| Step: 11
Training loss: 5.305398941040039
Validation loss: 5.460208739003828

Epoch: 6| Step: 12
Training loss: 5.715789794921875
Validation loss: 5.45138382655318

Epoch: 6| Step: 13
Training loss: 5.242546081542969
Validation loss: 5.440205161289502

Epoch: 9| Step: 0
Training loss: 5.551866054534912
Validation loss: 5.4214958939501035

Epoch: 6| Step: 1
Training loss: 4.307140827178955
Validation loss: 5.403932868793446

Epoch: 6| Step: 2
Training loss: 4.380878925323486
Validation loss: 5.394513171206238

Epoch: 6| Step: 3
Training loss: 5.195722579956055
Validation loss: 5.382239608354466

Epoch: 6| Step: 4
Training loss: 5.4171977043151855
Validation loss: 5.368659583471155

Epoch: 6| Step: 5
Training loss: 5.380492687225342
Validation loss: 5.352763622037826

Epoch: 6| Step: 6
Training loss: 5.132709503173828
Validation loss: 5.338535165274015

Epoch: 6| Step: 7
Training loss: 4.275241851806641
Validation loss: 5.319339803470078

Epoch: 6| Step: 8
Training loss: 5.477326393127441
Validation loss: 5.307558695475261

Epoch: 6| Step: 9
Training loss: 4.853775501251221
Validation loss: 5.293849011903168

Epoch: 6| Step: 10
Training loss: 5.88864803314209
Validation loss: 5.276802221934001

Epoch: 6| Step: 11
Training loss: 6.0128631591796875
Validation loss: 5.262323784571822

Epoch: 6| Step: 12
Training loss: 4.836621284484863
Validation loss: 5.246480936645179

Epoch: 6| Step: 13
Training loss: 4.3907470703125
Validation loss: 5.226667419556649

Epoch: 10| Step: 0
Training loss: 4.738946914672852
Validation loss: 5.21616587074854

Epoch: 6| Step: 1
Training loss: 3.7607133388519287
Validation loss: 5.194234781367804

Epoch: 6| Step: 2
Training loss: 4.583824634552002
Validation loss: 5.178003782867103

Epoch: 6| Step: 3
Training loss: 4.055502414703369
Validation loss: 5.165124652206257

Epoch: 6| Step: 4
Training loss: 5.6508636474609375
Validation loss: 5.149062720678186

Epoch: 6| Step: 5
Training loss: 5.919452667236328
Validation loss: 5.1281484839736775

Epoch: 6| Step: 6
Training loss: 4.792695045471191
Validation loss: 5.111195625797395

Epoch: 6| Step: 7
Training loss: 5.32692813873291
Validation loss: 5.091227213541667

Epoch: 6| Step: 8
Training loss: 5.029996871948242
Validation loss: 5.070510484838999

Epoch: 6| Step: 9
Training loss: 5.157193660736084
Validation loss: 5.053801152013963

Epoch: 6| Step: 10
Training loss: 4.552811145782471
Validation loss: 5.037753423055013

Epoch: 6| Step: 11
Training loss: 5.254280090332031
Validation loss: 5.0154814156152865

Epoch: 6| Step: 12
Training loss: 4.581953048706055
Validation loss: 4.999994006208194

Epoch: 6| Step: 13
Training loss: 4.612568378448486
Validation loss: 4.975797496816163

Epoch: 11| Step: 0
Training loss: 4.584007740020752
Validation loss: 4.9535829072357505

Epoch: 6| Step: 1
Training loss: 4.348896026611328
Validation loss: 4.938453592279906

Epoch: 6| Step: 2
Training loss: 5.370556831359863
Validation loss: 4.9189542698603805

Epoch: 6| Step: 3
Training loss: 4.795929908752441
Validation loss: 4.897873437532815

Epoch: 6| Step: 4
Training loss: 5.9868974685668945
Validation loss: 4.873404077304307

Epoch: 6| Step: 5
Training loss: 6.143941879272461
Validation loss: 4.848839026625439

Epoch: 6| Step: 6
Training loss: 4.099725723266602
Validation loss: 4.835380420889906

Epoch: 6| Step: 7
Training loss: 5.175678253173828
Validation loss: 4.8086410337878815

Epoch: 6| Step: 8
Training loss: 4.128330230712891
Validation loss: 4.78181637999832

Epoch: 6| Step: 9
Training loss: 4.0963592529296875
Validation loss: 4.764142108219926

Epoch: 6| Step: 10
Training loss: 3.3262760639190674
Validation loss: 4.745731876742456

Epoch: 6| Step: 11
Training loss: 3.9998254776000977
Validation loss: 4.719936078594577

Epoch: 6| Step: 12
Training loss: 4.156213760375977
Validation loss: 4.692071078926005

Epoch: 6| Step: 13
Training loss: 3.5902721881866455
Validation loss: 4.67197185947049

Epoch: 12| Step: 0
Training loss: 4.708531856536865
Validation loss: 4.65222881942667

Epoch: 6| Step: 1
Training loss: 4.573686599731445
Validation loss: 4.620651081044187

Epoch: 6| Step: 2
Training loss: 5.094304084777832
Validation loss: 4.605322730156683

Epoch: 6| Step: 3
Training loss: 3.2168359756469727
Validation loss: 4.57939290487638

Epoch: 6| Step: 4
Training loss: 5.003514289855957
Validation loss: 4.556681566340949

Epoch: 6| Step: 5
Training loss: 4.499358177185059
Validation loss: 4.524421507312406

Epoch: 6| Step: 6
Training loss: 3.439765453338623
Validation loss: 4.497370237945228

Epoch: 6| Step: 7
Training loss: 4.9139533042907715
Validation loss: 4.469092758752966

Epoch: 6| Step: 8
Training loss: 3.9053664207458496
Validation loss: 4.4492926802686465

Epoch: 6| Step: 9
Training loss: 3.440511703491211
Validation loss: 4.417816551782751

Epoch: 6| Step: 10
Training loss: 4.176633358001709
Validation loss: 4.383365169648202

Epoch: 6| Step: 11
Training loss: 4.515086650848389
Validation loss: 4.355068683624268

Epoch: 6| Step: 12
Training loss: 4.419369697570801
Validation loss: 4.324253994931457

Epoch: 6| Step: 13
Training loss: 3.041822671890259
Validation loss: 4.3042681191557195

Epoch: 13| Step: 0
Training loss: 4.736030578613281
Validation loss: 4.276029827774212

Epoch: 6| Step: 1
Training loss: 3.829056978225708
Validation loss: 4.2403101664717475

Epoch: 6| Step: 2
Training loss: 3.3541672229766846
Validation loss: 4.202788091474964

Epoch: 6| Step: 3
Training loss: 5.266939640045166
Validation loss: 4.185924094210389

Epoch: 6| Step: 4
Training loss: 3.598658561706543
Validation loss: 4.152833123360911

Epoch: 6| Step: 5
Training loss: 4.274845600128174
Validation loss: 4.122606364629602

Epoch: 6| Step: 6
Training loss: 4.389115810394287
Validation loss: 4.096003552918793

Epoch: 6| Step: 7
Training loss: 4.125739097595215
Validation loss: 4.060937830196914

Epoch: 6| Step: 8
Training loss: 3.333667755126953
Validation loss: 4.025855874502531

Epoch: 6| Step: 9
Training loss: 2.9070627689361572
Validation loss: 3.991900941377045

Epoch: 6| Step: 10
Training loss: 4.306458473205566
Validation loss: 3.9681410533125683

Epoch: 6| Step: 11
Training loss: 3.3826756477355957
Validation loss: 3.9378132820129395

Epoch: 6| Step: 12
Training loss: 3.354379653930664
Validation loss: 3.9026786255580124

Epoch: 6| Step: 13
Training loss: 3.0664782524108887
Validation loss: 3.875005160608599

Epoch: 14| Step: 0
Training loss: 4.228221893310547
Validation loss: 3.8499685000347834

Epoch: 6| Step: 1
Training loss: 2.656655788421631
Validation loss: 3.813431498824909

Epoch: 6| Step: 2
Training loss: 4.38138484954834
Validation loss: 3.7803199316865657

Epoch: 6| Step: 3
Training loss: 4.293280124664307
Validation loss: 3.7528681985793577

Epoch: 6| Step: 4
Training loss: 3.288384437561035
Validation loss: 3.725059429804484

Epoch: 6| Step: 5
Training loss: 3.1618552207946777
Validation loss: 3.69946744877805

Epoch: 6| Step: 6
Training loss: 3.3791797161102295
Validation loss: 3.6645017490592053

Epoch: 6| Step: 7
Training loss: 2.395911455154419
Validation loss: 3.627307512426889

Epoch: 6| Step: 8
Training loss: 3.736541986465454
Validation loss: 3.607926353331535

Epoch: 6| Step: 9
Training loss: 3.3479347229003906
Validation loss: 3.561167865671137

Epoch: 6| Step: 10
Training loss: 3.232947587966919
Validation loss: 3.5354235197908137

Epoch: 6| Step: 11
Training loss: 4.236173152923584
Validation loss: 3.513784964879354

Epoch: 6| Step: 12
Training loss: 2.8798840045928955
Validation loss: 3.470589214755643

Epoch: 6| Step: 13
Training loss: 3.9398701190948486
Validation loss: 3.448579398534631

Epoch: 15| Step: 0
Training loss: 2.5377840995788574
Validation loss: 3.417417203226397

Epoch: 6| Step: 1
Training loss: 3.4093871116638184
Validation loss: 3.389823067572809

Epoch: 6| Step: 2
Training loss: 2.555403470993042
Validation loss: 3.3408418188812914

Epoch: 6| Step: 3
Training loss: 3.5749900341033936
Validation loss: 3.323424388003606

Epoch: 6| Step: 4
Training loss: 2.2336325645446777
Validation loss: 3.2941662752500145

Epoch: 6| Step: 5
Training loss: 2.2276415824890137
Validation loss: 3.249862470934468

Epoch: 6| Step: 6
Training loss: 3.0747878551483154
Validation loss: 3.230527049751692

Epoch: 6| Step: 7
Training loss: 3.811251401901245
Validation loss: 3.1944690545399985

Epoch: 6| Step: 8
Training loss: 2.7342190742492676
Validation loss: 3.1608100860349593

Epoch: 6| Step: 9
Training loss: 3.544889450073242
Validation loss: 3.1401153149143344

Epoch: 6| Step: 10
Training loss: 3.2739133834838867
Validation loss: 3.1075325858208442

Epoch: 6| Step: 11
Training loss: 3.1229565143585205
Validation loss: 3.084483115903793

Epoch: 6| Step: 12
Training loss: 3.9316892623901367
Validation loss: 3.0534508074483564

Epoch: 6| Step: 13
Training loss: 4.175412178039551
Validation loss: 3.019340420282015

Epoch: 16| Step: 0
Training loss: 3.860960006713867
Validation loss: 2.994233541591193

Epoch: 6| Step: 1
Training loss: 2.3212051391601562
Validation loss: 2.9407541162224224

Epoch: 6| Step: 2
Training loss: 3.48976993560791
Validation loss: 2.908344094471265

Epoch: 6| Step: 3
Training loss: 3.1580281257629395
Validation loss: 2.872902242086267

Epoch: 6| Step: 4
Training loss: 2.6798343658447266
Validation loss: 2.8493464121254544

Epoch: 6| Step: 5
Training loss: 2.4844765663146973
Validation loss: 2.8178665971243255

Epoch: 6| Step: 6
Training loss: 2.743107557296753
Validation loss: 2.779988940044116

Epoch: 6| Step: 7
Training loss: 3.468285322189331
Validation loss: 2.746718855314357

Epoch: 6| Step: 8
Training loss: 2.806072235107422
Validation loss: 2.7232774431987474

Epoch: 6| Step: 9
Training loss: 2.545724868774414
Validation loss: 2.7130977953633955

Epoch: 6| Step: 10
Training loss: 2.5960488319396973
Validation loss: 2.676358953599007

Epoch: 6| Step: 11
Training loss: 2.483405590057373
Validation loss: 2.6596337749112036

Epoch: 6| Step: 12
Training loss: 2.461498260498047
Validation loss: 2.6306283243240847

Epoch: 6| Step: 13
Training loss: 2.6446239948272705
Validation loss: 2.6190894701147593

Epoch: 17| Step: 0
Training loss: 2.863553524017334
Validation loss: 2.5868698063717095

Epoch: 6| Step: 1
Training loss: 3.0535500049591064
Validation loss: 2.589784235082647

Epoch: 6| Step: 2
Training loss: 2.5357885360717773
Validation loss: 2.5695450357211533

Epoch: 6| Step: 3
Training loss: 2.5820865631103516
Validation loss: 2.5469111780966482

Epoch: 6| Step: 4
Training loss: 2.3962199687957764
Validation loss: 2.5298561562774

Epoch: 6| Step: 5
Training loss: 2.2961807250976562
Validation loss: 2.5238296383170673

Epoch: 6| Step: 6
Training loss: 2.5967745780944824
Validation loss: 2.493122769940284

Epoch: 6| Step: 7
Training loss: 3.2499492168426514
Validation loss: 2.4898778725695867

Epoch: 6| Step: 8
Training loss: 2.37119460105896
Validation loss: 2.444682691686897

Epoch: 6| Step: 9
Training loss: 2.990096092224121
Validation loss: 2.447758977131177

Epoch: 6| Step: 10
Training loss: 1.56734299659729
Validation loss: 2.426880000739969

Epoch: 6| Step: 11
Training loss: 3.026369333267212
Validation loss: 2.4063019214137906

Epoch: 6| Step: 12
Training loss: 2.0922865867614746
Validation loss: 2.4142179976227465

Epoch: 6| Step: 13
Training loss: 2.634497880935669
Validation loss: 2.400688409805298

Epoch: 18| Step: 0
Training loss: 2.3700387477874756
Validation loss: 2.378825315865137

Epoch: 6| Step: 1
Training loss: 2.764035224914551
Validation loss: 2.3866358880073792

Epoch: 6| Step: 2
Training loss: 1.9800944328308105
Validation loss: 2.3781135966700893

Epoch: 6| Step: 3
Training loss: 2.791877269744873
Validation loss: 2.3697685580099783

Epoch: 6| Step: 4
Training loss: 2.8188281059265137
Validation loss: 2.3388209240410918

Epoch: 6| Step: 5
Training loss: 3.4659457206726074
Validation loss: 2.3645912088373655

Epoch: 6| Step: 6
Training loss: 1.7990559339523315
Validation loss: 2.329649726549784

Epoch: 6| Step: 7
Training loss: 2.529916286468506
Validation loss: 2.3249019012656262

Epoch: 6| Step: 8
Training loss: 2.086643695831299
Validation loss: 2.3236394800165647

Epoch: 6| Step: 9
Training loss: 2.57061767578125
Validation loss: 2.3032574833080335

Epoch: 6| Step: 10
Training loss: 2.254033088684082
Validation loss: 2.30596391359965

Epoch: 6| Step: 11
Training loss: 3.259737014770508
Validation loss: 2.318334476922148

Epoch: 6| Step: 12
Training loss: 1.7559480667114258
Validation loss: 2.286096149875272

Epoch: 6| Step: 13
Training loss: 2.0283801555633545
Validation loss: 2.313323417017537

Epoch: 19| Step: 0
Training loss: 2.4613137245178223
Validation loss: 2.3031815123814408

Epoch: 6| Step: 1
Training loss: 1.9712469577789307
Validation loss: 2.3179306061037126

Epoch: 6| Step: 2
Training loss: 2.750497579574585
Validation loss: 2.3029163499032297

Epoch: 6| Step: 3
Training loss: 2.3443374633789062
Validation loss: 2.3087666675608647

Epoch: 6| Step: 4
Training loss: 2.9971907138824463
Validation loss: 2.2857898358375794

Epoch: 6| Step: 5
Training loss: 2.2223682403564453
Validation loss: 2.2984247464005665

Epoch: 6| Step: 6
Training loss: 2.3939716815948486
Validation loss: 2.3093732838989585

Epoch: 6| Step: 7
Training loss: 3.456555128097534
Validation loss: 2.2937421414159958

Epoch: 6| Step: 8
Training loss: 1.4588828086853027
Validation loss: 2.292668357972176

Epoch: 6| Step: 9
Training loss: 2.4776957035064697
Validation loss: 2.293894257596744

Epoch: 6| Step: 10
Training loss: 2.3044943809509277
Validation loss: 2.332678569260464

Epoch: 6| Step: 11
Training loss: 2.2729721069335938
Validation loss: 2.303239812133133

Epoch: 6| Step: 12
Training loss: 2.890796184539795
Validation loss: 2.2821989905449653

Epoch: 6| Step: 13
Training loss: 1.9839587211608887
Validation loss: 2.284249900489725

Epoch: 20| Step: 0
Training loss: 2.1340959072113037
Validation loss: 2.323476086380661

Epoch: 6| Step: 1
Training loss: 2.0564041137695312
Validation loss: 2.304114992900561

Epoch: 6| Step: 2
Training loss: 2.253718852996826
Validation loss: 2.2820405293536443

Epoch: 6| Step: 3
Training loss: 2.319965362548828
Validation loss: 2.2972103447042485

Epoch: 6| Step: 4
Training loss: 2.5977463722229004
Validation loss: 2.3017261259017454

Epoch: 6| Step: 5
Training loss: 2.255126476287842
Validation loss: 2.290578406344178

Epoch: 6| Step: 6
Training loss: 2.5861716270446777
Validation loss: 2.291348975191834

Epoch: 6| Step: 7
Training loss: 2.2303647994995117
Validation loss: 2.3125958545233614

Epoch: 6| Step: 8
Training loss: 3.0730605125427246
Validation loss: 2.308677955340314

Epoch: 6| Step: 9
Training loss: 2.01794171333313
Validation loss: 2.288171716915664

Epoch: 6| Step: 10
Training loss: 2.669309139251709
Validation loss: 2.3130814375415927

Epoch: 6| Step: 11
Training loss: 2.954906940460205
Validation loss: 2.2937202761250157

Epoch: 6| Step: 12
Training loss: 2.0877397060394287
Validation loss: 2.2983953260606333

Epoch: 6| Step: 13
Training loss: 3.038820743560791
Validation loss: 2.273272019560619

Epoch: 21| Step: 0
Training loss: 2.336508274078369
Validation loss: 2.2846476262615574

Epoch: 6| Step: 1
Training loss: 2.5343244075775146
Validation loss: 2.283986355668755

Epoch: 6| Step: 2
Training loss: 1.5407384634017944
Validation loss: 2.263841099636529

Epoch: 6| Step: 3
Training loss: 2.4099984169006348
Validation loss: 2.260734029995498

Epoch: 6| Step: 4
Training loss: 2.8798651695251465
Validation loss: 2.2781042565581617

Epoch: 6| Step: 5
Training loss: 1.9631686210632324
Validation loss: 2.3090269001581336

Epoch: 6| Step: 6
Training loss: 2.8340229988098145
Validation loss: 2.2886303983708864

Epoch: 6| Step: 7
Training loss: 2.0086112022399902
Validation loss: 2.2949399807119883

Epoch: 6| Step: 8
Training loss: 2.8681349754333496
Validation loss: 2.2995306804615963

Epoch: 6| Step: 9
Training loss: 2.317016363143921
Validation loss: 2.287128440795406

Epoch: 6| Step: 10
Training loss: 2.5787065029144287
Validation loss: 2.2815090328134517

Epoch: 6| Step: 11
Training loss: 2.506270170211792
Validation loss: 2.2752055942371325

Epoch: 6| Step: 12
Training loss: 2.821235418319702
Validation loss: 2.2712203430873092

Epoch: 6| Step: 13
Training loss: 2.252814769744873
Validation loss: 2.2802045947761944

Epoch: 22| Step: 0
Training loss: 2.4065213203430176
Validation loss: 2.278997480228383

Epoch: 6| Step: 1
Training loss: 2.9938416481018066
Validation loss: 2.2728792787880026

Epoch: 6| Step: 2
Training loss: 1.8140960931777954
Validation loss: 2.298969832799768

Epoch: 6| Step: 3
Training loss: 2.733656644821167
Validation loss: 2.290876401368008

Epoch: 6| Step: 4
Training loss: 2.2187459468841553
Validation loss: 2.266885006299583

Epoch: 6| Step: 5
Training loss: 1.9379327297210693
Validation loss: 2.2712679575848322

Epoch: 6| Step: 6
Training loss: 2.2224717140197754
Validation loss: 2.2908170043781237

Epoch: 6| Step: 7
Training loss: 2.730163097381592
Validation loss: 2.295184623810553

Epoch: 6| Step: 8
Training loss: 2.166583776473999
Validation loss: 2.26380455493927

Epoch: 6| Step: 9
Training loss: 2.646812915802002
Validation loss: 2.2809997374011624

Epoch: 6| Step: 10
Training loss: 3.01188325881958
Validation loss: 2.274111311922791

Epoch: 6| Step: 11
Training loss: 2.628986358642578
Validation loss: 2.2824218401344876

Epoch: 6| Step: 12
Training loss: 2.5903496742248535
Validation loss: 2.264057969534269

Epoch: 6| Step: 13
Training loss: 1.2151997089385986
Validation loss: 2.2713755176913355

Epoch: 23| Step: 0
Training loss: 1.923152208328247
Validation loss: 2.2752390638474496

Epoch: 6| Step: 1
Training loss: 2.412466526031494
Validation loss: 2.2618404024390766

Epoch: 6| Step: 2
Training loss: 2.4686689376831055
Validation loss: 2.2881264968584945

Epoch: 6| Step: 3
Training loss: 2.263418436050415
Validation loss: 2.2702005934971634

Epoch: 6| Step: 4
Training loss: 2.3110058307647705
Validation loss: 2.264008322069722

Epoch: 6| Step: 5
Training loss: 3.1070990562438965
Validation loss: 2.288927760175479

Epoch: 6| Step: 6
Training loss: 1.9810371398925781
Validation loss: 2.279382659542945

Epoch: 6| Step: 7
Training loss: 1.8644498586654663
Validation loss: 2.273573947209184

Epoch: 6| Step: 8
Training loss: 3.4796059131622314
Validation loss: 2.269862799234288

Epoch: 6| Step: 9
Training loss: 2.714648485183716
Validation loss: 2.2573969184711413

Epoch: 6| Step: 10
Training loss: 2.7706100940704346
Validation loss: 2.293478253067181

Epoch: 6| Step: 11
Training loss: 2.399951934814453
Validation loss: 2.268545307138915

Epoch: 6| Step: 12
Training loss: 2.215646266937256
Validation loss: 2.270755490949077

Epoch: 6| Step: 13
Training loss: 1.6503044366836548
Validation loss: 2.2776603570548435

Epoch: 24| Step: 0
Training loss: 3.2177047729492188
Validation loss: 2.2817417870285692

Epoch: 6| Step: 1
Training loss: 2.970599412918091
Validation loss: 2.2980150714997323

Epoch: 6| Step: 2
Training loss: 2.4560203552246094
Validation loss: 2.2628508280682307

Epoch: 6| Step: 3
Training loss: 2.166072368621826
Validation loss: 2.2606289309840046

Epoch: 6| Step: 4
Training loss: 1.628267765045166
Validation loss: 2.2914638852560394

Epoch: 6| Step: 5
Training loss: 2.6156692504882812
Validation loss: 2.270991579178841

Epoch: 6| Step: 6
Training loss: 2.510096549987793
Validation loss: 2.2754537597779305

Epoch: 6| Step: 7
Training loss: 1.8875269889831543
Validation loss: 2.2742479783232494

Epoch: 6| Step: 8
Training loss: 2.7755913734436035
Validation loss: 2.285606545786704

Epoch: 6| Step: 9
Training loss: 2.8846817016601562
Validation loss: 2.2861948449124574

Epoch: 6| Step: 10
Training loss: 2.461385726928711
Validation loss: 2.26673964787555

Epoch: 6| Step: 11
Training loss: 2.5231592655181885
Validation loss: 2.269809874155188

Epoch: 6| Step: 12
Training loss: 1.6671388149261475
Validation loss: 2.2797644445973058

Epoch: 6| Step: 13
Training loss: 1.6883271932601929
Validation loss: 2.2580605117223596

Epoch: 25| Step: 0
Training loss: 2.1736085414886475
Validation loss: 2.2620959461376233

Epoch: 6| Step: 1
Training loss: 1.8233672380447388
Validation loss: 2.248743357196931

Epoch: 6| Step: 2
Training loss: 2.504683017730713
Validation loss: 2.29155852717738

Epoch: 6| Step: 3
Training loss: 3.384965419769287
Validation loss: 2.272342510120843

Epoch: 6| Step: 4
Training loss: 2.9089035987854004
Validation loss: 2.2640793964427006

Epoch: 6| Step: 5
Training loss: 2.545781373977661
Validation loss: 2.2730040396413496

Epoch: 6| Step: 6
Training loss: 1.6296019554138184
Validation loss: 2.2676898253861295

Epoch: 6| Step: 7
Training loss: 2.3837146759033203
Validation loss: 2.255817828639861

Epoch: 6| Step: 8
Training loss: 2.1415982246398926
Validation loss: 2.2667662097561743

Epoch: 6| Step: 9
Training loss: 3.021426200866699
Validation loss: 2.2853052846847044

Epoch: 6| Step: 10
Training loss: 1.6454088687896729
Validation loss: 2.275049594140822

Epoch: 6| Step: 11
Training loss: 2.559821844100952
Validation loss: 2.257269533731604

Epoch: 6| Step: 12
Training loss: 2.7726364135742188
Validation loss: 2.2526452695169756

Epoch: 6| Step: 13
Training loss: 1.9558234214782715
Validation loss: 2.2763437199336227

Epoch: 26| Step: 0
Training loss: 2.478301525115967
Validation loss: 2.2442083833038167

Epoch: 6| Step: 1
Training loss: 2.7081077098846436
Validation loss: 2.280729696314822

Epoch: 6| Step: 2
Training loss: 1.7911059856414795
Validation loss: 2.263060963282021

Epoch: 6| Step: 3
Training loss: 2.3839454650878906
Validation loss: 2.268234473402782

Epoch: 6| Step: 4
Training loss: 2.2784018516540527
Validation loss: 2.2789744305354294

Epoch: 6| Step: 5
Training loss: 2.208380699157715
Validation loss: 2.270294863690612

Epoch: 6| Step: 6
Training loss: 2.6883885860443115
Validation loss: 2.2574346937159055

Epoch: 6| Step: 7
Training loss: 2.386340618133545
Validation loss: 2.257162268443774

Epoch: 6| Step: 8
Training loss: 2.2031965255737305
Validation loss: 2.260163435371973

Epoch: 6| Step: 9
Training loss: 2.867368698120117
Validation loss: 2.26448199184992

Epoch: 6| Step: 10
Training loss: 2.6368255615234375
Validation loss: 2.256956866992417

Epoch: 6| Step: 11
Training loss: 1.9578747749328613
Validation loss: 2.273032631925357

Epoch: 6| Step: 12
Training loss: 2.019784450531006
Validation loss: 2.2691995764291413

Epoch: 6| Step: 13
Training loss: 2.813807725906372
Validation loss: 2.2639128315833306

Epoch: 27| Step: 0
Training loss: 2.689894676208496
Validation loss: 2.2598643969464045

Epoch: 6| Step: 1
Training loss: 2.4113388061523438
Validation loss: 2.255835005032119

Epoch: 6| Step: 2
Training loss: 2.391164779663086
Validation loss: 2.2490246411292785

Epoch: 6| Step: 3
Training loss: 2.7247872352600098
Validation loss: 2.250056257811926

Epoch: 6| Step: 4
Training loss: 2.4051170349121094
Validation loss: 2.252127271826549

Epoch: 6| Step: 5
Training loss: 2.70035457611084
Validation loss: 2.258349972386514

Epoch: 6| Step: 6
Training loss: 3.2968084812164307
Validation loss: 2.262307233707879

Epoch: 6| Step: 7
Training loss: 2.247745990753174
Validation loss: 2.258071376431373

Epoch: 6| Step: 8
Training loss: 2.1572303771972656
Validation loss: 2.2534265351551834

Epoch: 6| Step: 9
Training loss: 1.895320177078247
Validation loss: 2.243118493787704

Epoch: 6| Step: 10
Training loss: 1.9806406497955322
Validation loss: 2.2641070119796263

Epoch: 6| Step: 11
Training loss: 2.1875290870666504
Validation loss: 2.2526753064124816

Epoch: 6| Step: 12
Training loss: 1.8650662899017334
Validation loss: 2.2642653142252276

Epoch: 6| Step: 13
Training loss: 2.8405392169952393
Validation loss: 2.2539649035341

Epoch: 28| Step: 0
Training loss: 2.396420955657959
Validation loss: 2.2462866639578216

Epoch: 6| Step: 1
Training loss: 2.807271718978882
Validation loss: 2.258718813619306

Epoch: 6| Step: 2
Training loss: 1.9719964265823364
Validation loss: 2.242035440219346

Epoch: 6| Step: 3
Training loss: 2.298546314239502
Validation loss: 2.23593226299491

Epoch: 6| Step: 4
Training loss: 2.5084033012390137
Validation loss: 2.261411706606547

Epoch: 6| Step: 5
Training loss: 2.9869625568389893
Validation loss: 2.2568537740297216

Epoch: 6| Step: 6
Training loss: 2.8043978214263916
Validation loss: 2.2342608385188605

Epoch: 6| Step: 7
Training loss: 1.9232103824615479
Validation loss: 2.273271429923273

Epoch: 6| Step: 8
Training loss: 2.2416396141052246
Validation loss: 2.2463572230390323

Epoch: 6| Step: 9
Training loss: 2.554767370223999
Validation loss: 2.2542102413792766

Epoch: 6| Step: 10
Training loss: 2.3306632041931152
Validation loss: 2.240516890761673

Epoch: 6| Step: 11
Training loss: 2.1092233657836914
Validation loss: 2.2482291447219027

Epoch: 6| Step: 12
Training loss: 2.100667715072632
Validation loss: 2.256397303714547

Epoch: 6| Step: 13
Training loss: 2.2946224212646484
Validation loss: 2.2394052115819787

Epoch: 29| Step: 0
Training loss: 1.9980902671813965
Validation loss: 2.249071882617089

Epoch: 6| Step: 1
Training loss: 2.2141075134277344
Validation loss: 2.251094469460108

Epoch: 6| Step: 2
Training loss: 2.920196533203125
Validation loss: 2.25211218736505

Epoch: 6| Step: 3
Training loss: 2.7132787704467773
Validation loss: 2.2623588731212

Epoch: 6| Step: 4
Training loss: 2.9114444255828857
Validation loss: 2.273038552653405

Epoch: 6| Step: 5
Training loss: 2.44197940826416
Validation loss: 2.264763439855268

Epoch: 6| Step: 6
Training loss: 1.8019146919250488
Validation loss: 2.241863368659891

Epoch: 6| Step: 7
Training loss: 2.610103130340576
Validation loss: 2.236024538675944

Epoch: 6| Step: 8
Training loss: 2.371993064880371
Validation loss: 2.242453994289521

Epoch: 6| Step: 9
Training loss: 2.1393489837646484
Validation loss: 2.2563200637858403

Epoch: 6| Step: 10
Training loss: 2.391948938369751
Validation loss: 2.2284656224712247

Epoch: 6| Step: 11
Training loss: 2.625394344329834
Validation loss: 2.2432412229558474

Epoch: 6| Step: 12
Training loss: 2.0889010429382324
Validation loss: 2.2575152048500637

Epoch: 6| Step: 13
Training loss: 2.061220645904541
Validation loss: 2.2693506927900415

Epoch: 30| Step: 0
Training loss: 2.599546194076538
Validation loss: 2.2561876517470165

Epoch: 6| Step: 1
Training loss: 2.9178152084350586
Validation loss: 2.2607676367605887

Epoch: 6| Step: 2
Training loss: 1.7178654670715332
Validation loss: 2.2425010178678777

Epoch: 6| Step: 3
Training loss: 2.4868273735046387
Validation loss: 2.264026811045985

Epoch: 6| Step: 4
Training loss: 2.2090003490448
Validation loss: 2.2221976608358402

Epoch: 6| Step: 5
Training loss: 2.521336078643799
Validation loss: 2.244260213708365

Epoch: 6| Step: 6
Training loss: 2.2217724323272705
Validation loss: 2.262102932058355

Epoch: 6| Step: 7
Training loss: 1.5711886882781982
Validation loss: 2.2545458911567606

Epoch: 6| Step: 8
Training loss: 2.457524061203003
Validation loss: 2.2339506803020353

Epoch: 6| Step: 9
Training loss: 2.0125715732574463
Validation loss: 2.2655444068293416

Epoch: 6| Step: 10
Training loss: 2.6207339763641357
Validation loss: 2.260272820790609

Epoch: 6| Step: 11
Training loss: 2.601285696029663
Validation loss: 2.2597292828303512

Epoch: 6| Step: 12
Training loss: 2.717866897583008
Validation loss: 2.2560834679552304

Epoch: 6| Step: 13
Training loss: 2.7086946964263916
Validation loss: 2.2490448003174155

Epoch: 31| Step: 0
Training loss: 2.222109794616699
Validation loss: 2.2505197960843324

Epoch: 6| Step: 1
Training loss: 2.9406075477600098
Validation loss: 2.24851946292385

Epoch: 6| Step: 2
Training loss: 2.1798548698425293
Validation loss: 2.2462369729113836

Epoch: 6| Step: 3
Training loss: 3.081078052520752
Validation loss: 2.245833966039842

Epoch: 6| Step: 4
Training loss: 2.693203926086426
Validation loss: 2.2638527757378033

Epoch: 6| Step: 5
Training loss: 2.127473831176758
Validation loss: 2.22528866798647

Epoch: 6| Step: 6
Training loss: 2.59486722946167
Validation loss: 2.2568942269971295

Epoch: 6| Step: 7
Training loss: 2.2931642532348633
Validation loss: 2.2487504148996003

Epoch: 6| Step: 8
Training loss: 2.0540263652801514
Validation loss: 2.243795259024507

Epoch: 6| Step: 9
Training loss: 2.50075101852417
Validation loss: 2.249307185090998

Epoch: 6| Step: 10
Training loss: 2.472334623336792
Validation loss: 2.2662530022282756

Epoch: 6| Step: 11
Training loss: 2.109309196472168
Validation loss: 2.22165076322453

Epoch: 6| Step: 12
Training loss: 1.7102625370025635
Validation loss: 2.2489359301905476

Epoch: 6| Step: 13
Training loss: 1.769946575164795
Validation loss: 2.2396420022492767

Epoch: 32| Step: 0
Training loss: 2.59452486038208
Validation loss: 2.244324113733025

Epoch: 6| Step: 1
Training loss: 1.8291401863098145
Validation loss: 2.2573145422884213

Epoch: 6| Step: 2
Training loss: 2.189664602279663
Validation loss: 2.2164998016049786

Epoch: 6| Step: 3
Training loss: 2.295485019683838
Validation loss: 2.251715906204716

Epoch: 6| Step: 4
Training loss: 2.514894723892212
Validation loss: 2.253947483595981

Epoch: 6| Step: 5
Training loss: 2.2766287326812744
Validation loss: 2.2455535447725685

Epoch: 6| Step: 6
Training loss: 1.6191078424453735
Validation loss: 2.2423031304472234

Epoch: 6| Step: 7
Training loss: 1.8535834550857544
Validation loss: 2.237409596802086

Epoch: 6| Step: 8
Training loss: 3.269728660583496
Validation loss: 2.2506395078474477

Epoch: 6| Step: 9
Training loss: 2.556110382080078
Validation loss: 2.25863024111717

Epoch: 6| Step: 10
Training loss: 2.3408191204071045
Validation loss: 2.2414482716591126

Epoch: 6| Step: 11
Training loss: 2.801790714263916
Validation loss: 2.2588503976022043

Epoch: 6| Step: 12
Training loss: 2.8122291564941406
Validation loss: 2.2279813212733113

Epoch: 6| Step: 13
Training loss: 1.7840911149978638
Validation loss: 2.252210796520274

Epoch: 33| Step: 0
Training loss: 2.169776678085327
Validation loss: 2.2371886007247435

Epoch: 6| Step: 1
Training loss: 2.707542896270752
Validation loss: 2.2375816965615876

Epoch: 6| Step: 2
Training loss: 1.9962283372879028
Validation loss: 2.243012887175365

Epoch: 6| Step: 3
Training loss: 2.4708750247955322
Validation loss: 2.241051199615643

Epoch: 6| Step: 4
Training loss: 2.5334959030151367
Validation loss: 2.248189369837443

Epoch: 6| Step: 5
Training loss: 2.171790599822998
Validation loss: 2.222645431436518

Epoch: 6| Step: 6
Training loss: 2.1974129676818848
Validation loss: 2.2432800108386624

Epoch: 6| Step: 7
Training loss: 2.3447508811950684
Validation loss: 2.2502040670764063

Epoch: 6| Step: 8
Training loss: 2.4621973037719727
Validation loss: 2.2349880587670112

Epoch: 6| Step: 9
Training loss: 2.7008187770843506
Validation loss: 2.240277951763522

Epoch: 6| Step: 10
Training loss: 2.1964566707611084
Validation loss: 2.2253103333134807

Epoch: 6| Step: 11
Training loss: 2.3601267337799072
Validation loss: 2.2253359748471166

Epoch: 6| Step: 12
Training loss: 2.553010940551758
Validation loss: 2.220162894136162

Epoch: 6| Step: 13
Training loss: 2.170201301574707
Validation loss: 2.2113411964908725

Epoch: 34| Step: 0
Training loss: 1.8590317964553833
Validation loss: 2.247173211907828

Epoch: 6| Step: 1
Training loss: 1.4045474529266357
Validation loss: 2.232557858190229

Epoch: 6| Step: 2
Training loss: 2.7691659927368164
Validation loss: 2.239905454779184

Epoch: 6| Step: 3
Training loss: 2.203962802886963
Validation loss: 2.223672607893585

Epoch: 6| Step: 4
Training loss: 2.699079990386963
Validation loss: 2.2376398142947944

Epoch: 6| Step: 5
Training loss: 2.6300106048583984
Validation loss: 2.2363056726353143

Epoch: 6| Step: 6
Training loss: 3.140575885772705
Validation loss: 2.2414099119042836

Epoch: 6| Step: 7
Training loss: 2.5514402389526367
Validation loss: 2.2525346881599835

Epoch: 6| Step: 8
Training loss: 2.103919506072998
Validation loss: 2.235055274860833

Epoch: 6| Step: 9
Training loss: 2.5272068977355957
Validation loss: 2.246753636226859

Epoch: 6| Step: 10
Training loss: 2.228835344314575
Validation loss: 2.2371678788174867

Epoch: 6| Step: 11
Training loss: 2.0087456703186035
Validation loss: 2.2344113088423208

Epoch: 6| Step: 12
Training loss: 2.083364486694336
Validation loss: 2.2310781748064104

Epoch: 6| Step: 13
Training loss: 2.93353009223938
Validation loss: 2.2304756103023404

Epoch: 35| Step: 0
Training loss: 2.5567686557769775
Validation loss: 2.2395308786822903

Epoch: 6| Step: 1
Training loss: 1.9529139995574951
Validation loss: 2.230331369625625

Epoch: 6| Step: 2
Training loss: 2.239307403564453
Validation loss: 2.2202513243562434

Epoch: 6| Step: 3
Training loss: 2.3648524284362793
Validation loss: 2.2275958727764826

Epoch: 6| Step: 4
Training loss: 2.5800907611846924
Validation loss: 2.221905464767128

Epoch: 6| Step: 5
Training loss: 2.603100299835205
Validation loss: 2.2319884941142094

Epoch: 6| Step: 6
Training loss: 1.5985537767410278
Validation loss: 2.2361306964710193

Epoch: 6| Step: 7
Training loss: 2.3133749961853027
Validation loss: 2.2218980404638473

Epoch: 6| Step: 8
Training loss: 2.0810046195983887
Validation loss: 2.228861311430572

Epoch: 6| Step: 9
Training loss: 2.6418166160583496
Validation loss: 2.220935813842281

Epoch: 6| Step: 10
Training loss: 2.7075159549713135
Validation loss: 2.2390208436596777

Epoch: 6| Step: 11
Training loss: 2.209479331970215
Validation loss: 2.2338707729052474

Epoch: 6| Step: 12
Training loss: 2.6799564361572266
Validation loss: 2.251946617198247

Epoch: 6| Step: 13
Training loss: 2.460282802581787
Validation loss: 2.23747161639634

Epoch: 36| Step: 0
Training loss: 2.0124142169952393
Validation loss: 2.2252340932046213

Epoch: 6| Step: 1
Training loss: 2.9460694789886475
Validation loss: 2.2398801926643617

Epoch: 6| Step: 2
Training loss: 2.3639702796936035
Validation loss: 2.23655471750485

Epoch: 6| Step: 3
Training loss: 3.0271825790405273
Validation loss: 2.2267821552932903

Epoch: 6| Step: 4
Training loss: 2.110379219055176
Validation loss: 2.236832941732099

Epoch: 6| Step: 5
Training loss: 1.8121297359466553
Validation loss: 2.224184259291618

Epoch: 6| Step: 6
Training loss: 2.445981979370117
Validation loss: 2.224895022248709

Epoch: 6| Step: 7
Training loss: 2.617248058319092
Validation loss: 2.215780049241999

Epoch: 6| Step: 8
Training loss: 2.0043375492095947
Validation loss: 2.2225405913527294

Epoch: 6| Step: 9
Training loss: 2.3229875564575195
Validation loss: 2.2364740499886135

Epoch: 6| Step: 10
Training loss: 2.522804021835327
Validation loss: 2.2181271814530894

Epoch: 6| Step: 11
Training loss: 2.2156877517700195
Validation loss: 2.2111399712101107

Epoch: 6| Step: 12
Training loss: 1.8680940866470337
Validation loss: 2.2150959443020564

Epoch: 6| Step: 13
Training loss: 2.777299165725708
Validation loss: 2.223743369502406

Epoch: 37| Step: 0
Training loss: 2.320542335510254
Validation loss: 2.212257064798827

Epoch: 6| Step: 1
Training loss: 1.7971265316009521
Validation loss: 2.2204140514455815

Epoch: 6| Step: 2
Training loss: 2.6969075202941895
Validation loss: 2.2088102217643493

Epoch: 6| Step: 3
Training loss: 1.8994858264923096
Validation loss: 2.210959901091873

Epoch: 6| Step: 4
Training loss: 2.0448241233825684
Validation loss: 2.2356929497052263

Epoch: 6| Step: 5
Training loss: 2.595947265625
Validation loss: 2.198870776801981

Epoch: 6| Step: 6
Training loss: 1.9682855606079102
Validation loss: 2.2279257517988964

Epoch: 6| Step: 7
Training loss: 2.213299512863159
Validation loss: 2.1995383565143873

Epoch: 6| Step: 8
Training loss: 1.8413429260253906
Validation loss: 2.215007253872451

Epoch: 6| Step: 9
Training loss: 2.3106400966644287
Validation loss: 2.224077158076789

Epoch: 6| Step: 10
Training loss: 2.8784022331237793
Validation loss: 2.2032723734455724

Epoch: 6| Step: 11
Training loss: 2.890664577484131
Validation loss: 2.198502679024973

Epoch: 6| Step: 12
Training loss: 3.006559133529663
Validation loss: 2.220866216126309

Epoch: 6| Step: 13
Training loss: 2.2729415893554688
Validation loss: 2.2003123350040887

Epoch: 38| Step: 0
Training loss: 2.0016303062438965
Validation loss: 2.213252677712389

Epoch: 6| Step: 1
Training loss: 2.60127592086792
Validation loss: 2.2246344832963842

Epoch: 6| Step: 2
Training loss: 2.8243401050567627
Validation loss: 2.2191941379218973

Epoch: 6| Step: 3
Training loss: 2.4755494594573975
Validation loss: 2.2037899827444427

Epoch: 6| Step: 4
Training loss: 2.318490982055664
Validation loss: 2.1999332956088486

Epoch: 6| Step: 5
Training loss: 2.469521999359131
Validation loss: 2.2053724796541276

Epoch: 6| Step: 6
Training loss: 2.228105306625366
Validation loss: 2.2095917463302612

Epoch: 6| Step: 7
Training loss: 2.35911226272583
Validation loss: 2.2253563942447787

Epoch: 6| Step: 8
Training loss: 2.4246230125427246
Validation loss: 2.204091243846442

Epoch: 6| Step: 9
Training loss: 1.7333056926727295
Validation loss: 2.212647581613192

Epoch: 6| Step: 10
Training loss: 1.7344512939453125
Validation loss: 2.2032600654068815

Epoch: 6| Step: 11
Training loss: 2.3440260887145996
Validation loss: 2.2160281494099605

Epoch: 6| Step: 12
Training loss: 2.9107561111450195
Validation loss: 2.211275913382089

Epoch: 6| Step: 13
Training loss: 2.0528602600097656
Validation loss: 2.2092965956657165

Epoch: 39| Step: 0
Training loss: 3.2342114448547363
Validation loss: 2.212444108019593

Epoch: 6| Step: 1
Training loss: 2.0343475341796875
Validation loss: 2.213070595136253

Epoch: 6| Step: 2
Training loss: 1.634082555770874
Validation loss: 2.2112534251264346

Epoch: 6| Step: 3
Training loss: 1.6332875490188599
Validation loss: 2.2071413327288885

Epoch: 6| Step: 4
Training loss: 2.554156541824341
Validation loss: 2.2080384454419537

Epoch: 6| Step: 5
Training loss: 2.4195961952209473
Validation loss: 2.206624669413413

Epoch: 6| Step: 6
Training loss: 1.9830751419067383
Validation loss: 2.2025187451352357

Epoch: 6| Step: 7
Training loss: 2.2661428451538086
Validation loss: 2.197374336181148

Epoch: 6| Step: 8
Training loss: 2.7436506748199463
Validation loss: 2.236098409980856

Epoch: 6| Step: 9
Training loss: 2.733536720275879
Validation loss: 2.201626895576395

Epoch: 6| Step: 10
Training loss: 2.3753018379211426
Validation loss: 2.1924925299100977

Epoch: 6| Step: 11
Training loss: 2.041602611541748
Validation loss: 2.2009540501461236

Epoch: 6| Step: 12
Training loss: 2.368746042251587
Validation loss: 2.2125089142912175

Epoch: 6| Step: 13
Training loss: 2.5702061653137207
Validation loss: 2.208995665273359

Epoch: 40| Step: 0
Training loss: 2.293687343597412
Validation loss: 2.193998021464194

Epoch: 6| Step: 1
Training loss: 2.0883965492248535
Validation loss: 2.187648022046653

Epoch: 6| Step: 2
Training loss: 2.5911028385162354
Validation loss: 2.229441991416357

Epoch: 6| Step: 3
Training loss: 2.4173147678375244
Validation loss: 2.2130100624535674

Epoch: 6| Step: 4
Training loss: 2.616992950439453
Validation loss: 2.2169835849474837

Epoch: 6| Step: 5
Training loss: 2.6430773735046387
Validation loss: 2.217649576484516

Epoch: 6| Step: 6
Training loss: 2.389927387237549
Validation loss: 2.2096145845228627

Epoch: 6| Step: 7
Training loss: 2.226715564727783
Validation loss: 2.195682612798547

Epoch: 6| Step: 8
Training loss: 2.8086447715759277
Validation loss: 2.2025446353420133

Epoch: 6| Step: 9
Training loss: 1.2140452861785889
Validation loss: 2.1848411970241095

Epoch: 6| Step: 10
Training loss: 2.0677573680877686
Validation loss: 2.189082896837624

Epoch: 6| Step: 11
Training loss: 2.5424890518188477
Validation loss: 2.198467477675407

Epoch: 6| Step: 12
Training loss: 2.6520168781280518
Validation loss: 2.2064546256937008

Epoch: 6| Step: 13
Training loss: 1.6992170810699463
Validation loss: 2.202514692019391

Epoch: 41| Step: 0
Training loss: 2.499018907546997
Validation loss: 2.187243987155217

Epoch: 6| Step: 1
Training loss: 2.839597702026367
Validation loss: 2.189224804601362

Epoch: 6| Step: 2
Training loss: 2.6610851287841797
Validation loss: 2.2045990882381314

Epoch: 6| Step: 3
Training loss: 1.9414700269699097
Validation loss: 2.204028234686903

Epoch: 6| Step: 4
Training loss: 3.043668746948242
Validation loss: 2.208323191570979

Epoch: 6| Step: 5
Training loss: 2.4564151763916016
Validation loss: 2.205977039952432

Epoch: 6| Step: 6
Training loss: 2.2292721271514893
Validation loss: 2.2084815681621595

Epoch: 6| Step: 7
Training loss: 2.017395257949829
Validation loss: 2.200792799713791

Epoch: 6| Step: 8
Training loss: 2.1323304176330566
Validation loss: 2.2032090540855163

Epoch: 6| Step: 9
Training loss: 1.262019157409668
Validation loss: 2.2042798098697456

Epoch: 6| Step: 10
Training loss: 2.6417644023895264
Validation loss: 2.2050225529619443

Epoch: 6| Step: 11
Training loss: 2.510451316833496
Validation loss: 2.1991174490221086

Epoch: 6| Step: 12
Training loss: 1.716475248336792
Validation loss: 2.2052749690189155

Epoch: 6| Step: 13
Training loss: 2.3924806118011475
Validation loss: 2.1987701257069907

Epoch: 42| Step: 0
Training loss: 2.4484734535217285
Validation loss: 2.1956793505658387

Epoch: 6| Step: 1
Training loss: 2.0187370777130127
Validation loss: 2.223171405894782

Epoch: 6| Step: 2
Training loss: 1.742018699645996
Validation loss: 2.1987814646895214

Epoch: 6| Step: 3
Training loss: 2.629422903060913
Validation loss: 2.209638605835617

Epoch: 6| Step: 4
Training loss: 2.385380268096924
Validation loss: 2.2062612682260494

Epoch: 6| Step: 5
Training loss: 1.7591915130615234
Validation loss: 2.1911748455416773

Epoch: 6| Step: 6
Training loss: 2.8115735054016113
Validation loss: 2.1776684996902302

Epoch: 6| Step: 7
Training loss: 3.6553215980529785
Validation loss: 2.1868906790210354

Epoch: 6| Step: 8
Training loss: 2.57499361038208
Validation loss: 2.197334402350969

Epoch: 6| Step: 9
Training loss: 2.13983416557312
Validation loss: 2.2081727545748473

Epoch: 6| Step: 10
Training loss: 2.3305139541625977
Validation loss: 2.1953432406148603

Epoch: 6| Step: 11
Training loss: 2.0315771102905273
Validation loss: 2.217091957728068

Epoch: 6| Step: 12
Training loss: 1.5255175828933716
Validation loss: 2.200124695736875

Epoch: 6| Step: 13
Training loss: 2.459336519241333
Validation loss: 2.1893322903622865

Epoch: 43| Step: 0
Training loss: 2.025176525115967
Validation loss: 2.186222771162628

Epoch: 6| Step: 1
Training loss: 2.5428621768951416
Validation loss: 2.193122128004669

Epoch: 6| Step: 2
Training loss: 3.1307692527770996
Validation loss: 2.1951913192708004

Epoch: 6| Step: 3
Training loss: 1.8445532321929932
Validation loss: 2.2014497095538723

Epoch: 6| Step: 4
Training loss: 1.802763819694519
Validation loss: 2.2029223442077637

Epoch: 6| Step: 5
Training loss: 2.646484375
Validation loss: 2.2004830016884753

Epoch: 6| Step: 6
Training loss: 2.5039050579071045
Validation loss: 2.1770834230607554

Epoch: 6| Step: 7
Training loss: 2.708184242248535
Validation loss: 2.1890571771129483

Epoch: 6| Step: 8
Training loss: 1.9518243074417114
Validation loss: 2.1906206838546263

Epoch: 6| Step: 9
Training loss: 2.30126953125
Validation loss: 2.1967161009388585

Epoch: 6| Step: 10
Training loss: 1.9099844694137573
Validation loss: 2.220439916015953

Epoch: 6| Step: 11
Training loss: 2.2302675247192383
Validation loss: 2.1999602420355684

Epoch: 6| Step: 12
Training loss: 1.898854374885559
Validation loss: 2.193945595013198

Epoch: 6| Step: 13
Training loss: 3.1974077224731445
Validation loss: 2.189352693096284

Epoch: 44| Step: 0
Training loss: 1.8330893516540527
Validation loss: 2.204496519539946

Epoch: 6| Step: 1
Training loss: 2.1034927368164062
Validation loss: 2.1848018400130735

Epoch: 6| Step: 2
Training loss: 1.8054935932159424
Validation loss: 2.1971920818410893

Epoch: 6| Step: 3
Training loss: 3.0018465518951416
Validation loss: 2.1979146413905646

Epoch: 6| Step: 4
Training loss: 2.1435675621032715
Validation loss: 2.1976222299760386

Epoch: 6| Step: 5
Training loss: 3.251070022583008
Validation loss: 2.1826870954164894

Epoch: 6| Step: 6
Training loss: 1.8004546165466309
Validation loss: 2.1887912416970856

Epoch: 6| Step: 7
Training loss: 2.7197189331054688
Validation loss: 2.1789656890335904

Epoch: 6| Step: 8
Training loss: 1.5569853782653809
Validation loss: 2.178094046090239

Epoch: 6| Step: 9
Training loss: 2.6552560329437256
Validation loss: 2.175547012718775

Epoch: 6| Step: 10
Training loss: 2.132251024246216
Validation loss: 2.200706087132936

Epoch: 6| Step: 11
Training loss: 2.4970312118530273
Validation loss: 2.191879874916487

Epoch: 6| Step: 12
Training loss: 2.2937793731689453
Validation loss: 2.1903926557110203

Epoch: 6| Step: 13
Training loss: 2.325523853302002
Validation loss: 2.196107901552672

Epoch: 45| Step: 0
Training loss: 3.0455548763275146
Validation loss: 2.195991304612929

Epoch: 6| Step: 1
Training loss: 2.5240285396575928
Validation loss: 2.187986366210445

Epoch: 6| Step: 2
Training loss: 1.8720992803573608
Validation loss: 2.1824368763995428

Epoch: 6| Step: 3
Training loss: 2.1183552742004395
Validation loss: 2.178608791802519

Epoch: 6| Step: 4
Training loss: 1.8927996158599854
Validation loss: 2.1988921960194907

Epoch: 6| Step: 5
Training loss: 2.263549327850342
Validation loss: 2.1870172600592337

Epoch: 6| Step: 6
Training loss: 2.7246296405792236
Validation loss: 2.202788696494154

Epoch: 6| Step: 7
Training loss: 2.3773043155670166
Validation loss: 2.18256518917699

Epoch: 6| Step: 8
Training loss: 2.0998029708862305
Validation loss: 2.1973963757996917

Epoch: 6| Step: 9
Training loss: 2.8242383003234863
Validation loss: 2.182026868225426

Epoch: 6| Step: 10
Training loss: 1.8242346048355103
Validation loss: 2.1960016014755412

Epoch: 6| Step: 11
Training loss: 1.854447603225708
Validation loss: 2.1662968973959646

Epoch: 6| Step: 12
Training loss: 2.1346027851104736
Validation loss: 2.176652750661296

Epoch: 6| Step: 13
Training loss: 2.847324848175049
Validation loss: 2.1728034903926234

Epoch: 46| Step: 0
Training loss: 2.735024929046631
Validation loss: 2.19128982738782

Epoch: 6| Step: 1
Training loss: 2.277838945388794
Validation loss: 2.186153478519891

Epoch: 6| Step: 2
Training loss: 1.4360544681549072
Validation loss: 2.1801410413557485

Epoch: 6| Step: 3
Training loss: 1.652139663696289
Validation loss: 2.2033593513632335

Epoch: 6| Step: 4
Training loss: 2.8931894302368164
Validation loss: 2.2028786546440533

Epoch: 6| Step: 5
Training loss: 2.6221234798431396
Validation loss: 2.1774036486943564

Epoch: 6| Step: 6
Training loss: 2.639610767364502
Validation loss: 2.197890317568215

Epoch: 6| Step: 7
Training loss: 1.874575138092041
Validation loss: 2.192694128200572

Epoch: 6| Step: 8
Training loss: 3.6060984134674072
Validation loss: 2.189259349658925

Epoch: 6| Step: 9
Training loss: 2.1747303009033203
Validation loss: 2.1849700930298015

Epoch: 6| Step: 10
Training loss: 1.7189844846725464
Validation loss: 2.2114178852368425

Epoch: 6| Step: 11
Training loss: 2.0583455562591553
Validation loss: 2.187567799322067

Epoch: 6| Step: 12
Training loss: 2.3047738075256348
Validation loss: 2.2011302158396733

Epoch: 6| Step: 13
Training loss: 2.1159045696258545
Validation loss: 2.171779586422828

Epoch: 47| Step: 0
Training loss: 2.203995704650879
Validation loss: 2.1909410543339227

Epoch: 6| Step: 1
Training loss: 2.6695897579193115
Validation loss: 2.183741100372807

Epoch: 6| Step: 2
Training loss: 1.5383892059326172
Validation loss: 2.206774414226573

Epoch: 6| Step: 3
Training loss: 1.7691314220428467
Validation loss: 2.183852537985771

Epoch: 6| Step: 4
Training loss: 2.9507999420166016
Validation loss: 2.2000976544554516

Epoch: 6| Step: 5
Training loss: 2.6060285568237305
Validation loss: 2.177462747020106

Epoch: 6| Step: 6
Training loss: 2.1498453617095947
Validation loss: 2.2196035180040585

Epoch: 6| Step: 7
Training loss: 1.943198323249817
Validation loss: 2.181452610159433

Epoch: 6| Step: 8
Training loss: 2.8027896881103516
Validation loss: 2.193275752887931

Epoch: 6| Step: 9
Training loss: 2.3433051109313965
Validation loss: 2.2007013085067912

Epoch: 6| Step: 10
Training loss: 2.091057300567627
Validation loss: 2.1741568375659246

Epoch: 6| Step: 11
Training loss: 1.8691520690917969
Validation loss: 2.1729173403914257

Epoch: 6| Step: 12
Training loss: 2.4623122215270996
Validation loss: 2.191010057285268

Epoch: 6| Step: 13
Training loss: 2.5963187217712402
Validation loss: 2.1990503841830837

Epoch: 48| Step: 0
Training loss: 2.466264247894287
Validation loss: 2.185884993563416

Epoch: 6| Step: 1
Training loss: 2.6028993129730225
Validation loss: 2.176438764859271

Epoch: 6| Step: 2
Training loss: 2.763664722442627
Validation loss: 2.1890874754997993

Epoch: 6| Step: 3
Training loss: 2.2661964893341064
Validation loss: 2.186666016937584

Epoch: 6| Step: 4
Training loss: 2.6304726600646973
Validation loss: 2.206911245981852

Epoch: 6| Step: 5
Training loss: 2.807954788208008
Validation loss: 2.1771302248841975

Epoch: 6| Step: 6
Training loss: 1.4399795532226562
Validation loss: 2.2076077973970802

Epoch: 6| Step: 7
Training loss: 2.780073404312134
Validation loss: 2.19103987755314

Epoch: 6| Step: 8
Training loss: 1.9344298839569092
Validation loss: 2.1915938661944483

Epoch: 6| Step: 9
Training loss: 2.2312262058258057
Validation loss: 2.178135456577424

Epoch: 6| Step: 10
Training loss: 2.304492950439453
Validation loss: 2.1957716916197088

Epoch: 6| Step: 11
Training loss: 1.7328592538833618
Validation loss: 2.2120542910791214

Epoch: 6| Step: 12
Training loss: 1.872469186782837
Validation loss: 2.205547401981969

Epoch: 6| Step: 13
Training loss: 1.92221200466156
Validation loss: 2.1838323839249147

Epoch: 49| Step: 0
Training loss: 1.906301498413086
Validation loss: 2.1685837750793784

Epoch: 6| Step: 1
Training loss: 2.351992607116699
Validation loss: 2.1453340745741323

Epoch: 6| Step: 2
Training loss: 2.2506179809570312
Validation loss: 2.1800582357632217

Epoch: 6| Step: 3
Training loss: 1.515052318572998
Validation loss: 2.1989930598966536

Epoch: 6| Step: 4
Training loss: 2.2815704345703125
Validation loss: 2.1640177080708165

Epoch: 6| Step: 5
Training loss: 2.2198915481567383
Validation loss: 2.191852725962157

Epoch: 6| Step: 6
Training loss: 2.090664863586426
Validation loss: 2.2149680699071577

Epoch: 6| Step: 7
Training loss: 1.988468050956726
Validation loss: 2.163583452983569

Epoch: 6| Step: 8
Training loss: 2.978058338165283
Validation loss: 2.188755214855235

Epoch: 6| Step: 9
Training loss: 2.6351356506347656
Validation loss: 2.1734331448872886

Epoch: 6| Step: 10
Training loss: 2.1673855781555176
Validation loss: 2.191434975593321

Epoch: 6| Step: 11
Training loss: 2.532987356185913
Validation loss: 2.186038427455451

Epoch: 6| Step: 12
Training loss: 1.8877408504486084
Validation loss: 2.1747661816176547

Epoch: 6| Step: 13
Training loss: 3.264773368835449
Validation loss: 2.182282065832487

Epoch: 50| Step: 0
Training loss: 1.5674633979797363
Validation loss: 2.200319743925525

Epoch: 6| Step: 1
Training loss: 1.8254809379577637
Validation loss: 2.16585402078526

Epoch: 6| Step: 2
Training loss: 2.044023036956787
Validation loss: 2.17388133336139

Epoch: 6| Step: 3
Training loss: 1.5216865539550781
Validation loss: 2.1713397964354484

Epoch: 6| Step: 4
Training loss: 2.8634397983551025
Validation loss: 2.1910370139665503

Epoch: 6| Step: 5
Training loss: 1.943568468093872
Validation loss: 2.1772804234617498

Epoch: 6| Step: 6
Training loss: 2.4978251457214355
Validation loss: 2.168346530647688

Epoch: 6| Step: 7
Training loss: 2.752635955810547
Validation loss: 2.1759503554272395

Epoch: 6| Step: 8
Training loss: 2.6938750743865967
Validation loss: 2.1899659633636475

Epoch: 6| Step: 9
Training loss: 2.8413798809051514
Validation loss: 2.161492256708043

Epoch: 6| Step: 10
Training loss: 2.061345100402832
Validation loss: 2.180036053862623

Epoch: 6| Step: 11
Training loss: 2.745927572250366
Validation loss: 2.1884495930005143

Epoch: 6| Step: 12
Training loss: 2.4619362354278564
Validation loss: 2.1681024541137037

Epoch: 6| Step: 13
Training loss: 1.9219565391540527
Validation loss: 2.2030727171128794

Epoch: 51| Step: 0
Training loss: 2.052490472793579
Validation loss: 2.185778038476103

Epoch: 6| Step: 1
Training loss: 2.0006821155548096
Validation loss: 2.1612338391683434

Epoch: 6| Step: 2
Training loss: 1.7116047143936157
Validation loss: 2.1760597408458753

Epoch: 6| Step: 3
Training loss: 1.6346995830535889
Validation loss: 2.1599059515101935

Epoch: 6| Step: 4
Training loss: 1.9089571237564087
Validation loss: 2.1597763902397564

Epoch: 6| Step: 5
Training loss: 2.0944271087646484
Validation loss: 2.185231436965286

Epoch: 6| Step: 6
Training loss: 2.655691623687744
Validation loss: 2.1684035742154686

Epoch: 6| Step: 7
Training loss: 2.67496395111084
Validation loss: 2.179019446014076

Epoch: 6| Step: 8
Training loss: 2.359889030456543
Validation loss: 2.187998620412683

Epoch: 6| Step: 9
Training loss: 1.868625521659851
Validation loss: 2.17990747703019

Epoch: 6| Step: 10
Training loss: 3.265399932861328
Validation loss: 2.2214130945103143

Epoch: 6| Step: 11
Training loss: 2.678440570831299
Validation loss: 2.185127863319971

Epoch: 6| Step: 12
Training loss: 2.508514881134033
Validation loss: 2.202530344327291

Epoch: 6| Step: 13
Training loss: 2.5528972148895264
Validation loss: 2.1828770111965876

Epoch: 52| Step: 0
Training loss: 2.2435808181762695
Validation loss: 2.198197898044381

Epoch: 6| Step: 1
Training loss: 3.3482189178466797
Validation loss: 2.208446885949822

Epoch: 6| Step: 2
Training loss: 2.003429889678955
Validation loss: 2.2058118363862396

Epoch: 6| Step: 3
Training loss: 2.0101804733276367
Validation loss: 2.179480684700833

Epoch: 6| Step: 4
Training loss: 2.325657844543457
Validation loss: 2.183155261060243

Epoch: 6| Step: 5
Training loss: 2.1647377014160156
Validation loss: 2.186856936382991

Epoch: 6| Step: 6
Training loss: 1.8758608102798462
Validation loss: 2.1630629506162418

Epoch: 6| Step: 7
Training loss: 2.5102503299713135
Validation loss: 2.1788342845055366

Epoch: 6| Step: 8
Training loss: 2.350050926208496
Validation loss: 2.1923167808081514

Epoch: 6| Step: 9
Training loss: 2.518324375152588
Validation loss: 2.16748918256452

Epoch: 6| Step: 10
Training loss: 1.4842143058776855
Validation loss: 2.1818035648715113

Epoch: 6| Step: 11
Training loss: 2.5842225551605225
Validation loss: 2.153833794337447

Epoch: 6| Step: 12
Training loss: 2.2112388610839844
Validation loss: 2.1694470374814925

Epoch: 6| Step: 13
Training loss: 1.9963717460632324
Validation loss: 2.1899494535179547

Epoch: 53| Step: 0
Training loss: 2.1125245094299316
Validation loss: 2.160043203702537

Epoch: 6| Step: 1
Training loss: 2.353393077850342
Validation loss: 2.1745480709178473

Epoch: 6| Step: 2
Training loss: 1.7027332782745361
Validation loss: 2.1755078684899116

Epoch: 6| Step: 3
Training loss: 2.256686210632324
Validation loss: 2.1691910605276785

Epoch: 6| Step: 4
Training loss: 2.3151090145111084
Validation loss: 2.1955381836942447

Epoch: 6| Step: 5
Training loss: 1.9465596675872803
Validation loss: 2.177033478213895

Epoch: 6| Step: 6
Training loss: 2.6541035175323486
Validation loss: 2.203378974750478

Epoch: 6| Step: 7
Training loss: 2.4163694381713867
Validation loss: 2.1904944604442966

Epoch: 6| Step: 8
Training loss: 2.4086928367614746
Validation loss: 2.189017249691871

Epoch: 6| Step: 9
Training loss: 1.8797800540924072
Validation loss: 2.1702905572870725

Epoch: 6| Step: 10
Training loss: 2.756077766418457
Validation loss: 2.1697170760041926

Epoch: 6| Step: 11
Training loss: 1.4851362705230713
Validation loss: 2.145056237456619

Epoch: 6| Step: 12
Training loss: 3.0317091941833496
Validation loss: 2.198151929404146

Epoch: 6| Step: 13
Training loss: 2.1168975830078125
Validation loss: 2.188168335986394

Epoch: 54| Step: 0
Training loss: 1.995551347732544
Validation loss: 2.191570440928141

Epoch: 6| Step: 1
Training loss: 2.091938018798828
Validation loss: 2.182739573140298

Epoch: 6| Step: 2
Training loss: 1.6721826791763306
Validation loss: 2.1774461769288584

Epoch: 6| Step: 3
Training loss: 2.7605059146881104
Validation loss: 2.173710448767549

Epoch: 6| Step: 4
Training loss: 2.3587427139282227
Validation loss: 2.1765351628744476

Epoch: 6| Step: 5
Training loss: 2.3795487880706787
Validation loss: 2.1737306553830384

Epoch: 6| Step: 6
Training loss: 2.7585880756378174
Validation loss: 2.154914822629703

Epoch: 6| Step: 7
Training loss: 1.964829444885254
Validation loss: 2.1690081370774137

Epoch: 6| Step: 8
Training loss: 1.7595698833465576
Validation loss: 2.2031341278424827

Epoch: 6| Step: 9
Training loss: 2.412656307220459
Validation loss: 2.177229704395417

Epoch: 6| Step: 10
Training loss: 2.35056734085083
Validation loss: 2.200593010071785

Epoch: 6| Step: 11
Training loss: 2.161390781402588
Validation loss: 2.1871194583113476

Epoch: 6| Step: 12
Training loss: 2.2726407051086426
Validation loss: 2.1614718321830995

Epoch: 6| Step: 13
Training loss: 2.566579580307007
Validation loss: 2.168144183774148

Epoch: 55| Step: 0
Training loss: 2.6836256980895996
Validation loss: 2.157114403222197

Epoch: 6| Step: 1
Training loss: 1.9516022205352783
Validation loss: 2.1762254520129134

Epoch: 6| Step: 2
Training loss: 1.9592745304107666
Validation loss: 2.158381697952106

Epoch: 6| Step: 3
Training loss: 1.9653502702713013
Validation loss: 2.166712407142885

Epoch: 6| Step: 4
Training loss: 2.1012845039367676
Validation loss: 2.1561959456372004

Epoch: 6| Step: 5
Training loss: 1.7724835872650146
Validation loss: 2.1695405385827504

Epoch: 6| Step: 6
Training loss: 2.5175440311431885
Validation loss: 2.1720725413291686

Epoch: 6| Step: 7
Training loss: 2.4502947330474854
Validation loss: 2.1455622770453013

Epoch: 6| Step: 8
Training loss: 1.82291579246521
Validation loss: 2.183685697535033

Epoch: 6| Step: 9
Training loss: 1.6898670196533203
Validation loss: 2.1816728832901164

Epoch: 6| Step: 10
Training loss: 2.698422908782959
Validation loss: 2.184272935313563

Epoch: 6| Step: 11
Training loss: 2.6884753704071045
Validation loss: 2.191452258376665

Epoch: 6| Step: 12
Training loss: 2.286259651184082
Validation loss: 2.1572466191425117

Epoch: 6| Step: 13
Training loss: 2.8491930961608887
Validation loss: 2.172034007246776

Epoch: 56| Step: 0
Training loss: 1.735205054283142
Validation loss: 2.178830623626709

Epoch: 6| Step: 1
Training loss: 2.6103410720825195
Validation loss: 2.175086654642577

Epoch: 6| Step: 2
Training loss: 1.879870891571045
Validation loss: 2.1485830391606977

Epoch: 6| Step: 3
Training loss: 2.166898727416992
Validation loss: 2.1707792769196215

Epoch: 6| Step: 4
Training loss: 2.2671759128570557
Validation loss: 2.1733463246335267

Epoch: 6| Step: 5
Training loss: 1.9336365461349487
Validation loss: 2.156716118576706

Epoch: 6| Step: 6
Training loss: 1.855403184890747
Validation loss: 2.169611871883433

Epoch: 6| Step: 7
Training loss: 2.7053725719451904
Validation loss: 2.165212572261851

Epoch: 6| Step: 8
Training loss: 2.1278862953186035
Validation loss: 2.180606965095766

Epoch: 6| Step: 9
Training loss: 2.4263722896575928
Validation loss: 2.173640010177448

Epoch: 6| Step: 10
Training loss: 2.978764533996582
Validation loss: 2.151360119542768

Epoch: 6| Step: 11
Training loss: 2.5583295822143555
Validation loss: 2.171003698020853

Epoch: 6| Step: 12
Training loss: 2.0315682888031006
Validation loss: 2.2035595422149985

Epoch: 6| Step: 13
Training loss: 2.1959445476531982
Validation loss: 2.167291009297935

Epoch: 57| Step: 0
Training loss: 2.0752182006835938
Validation loss: 2.1645080402333248

Epoch: 6| Step: 1
Training loss: 2.5758581161499023
Validation loss: 2.155371594172652

Epoch: 6| Step: 2
Training loss: 2.5699069499969482
Validation loss: 2.1836196017521683

Epoch: 6| Step: 3
Training loss: 2.048246145248413
Validation loss: 2.1341345528120637

Epoch: 6| Step: 4
Training loss: 2.055396795272827
Validation loss: 2.198086646295363

Epoch: 6| Step: 5
Training loss: 2.0438103675842285
Validation loss: 2.1706812676563056

Epoch: 6| Step: 6
Training loss: 1.0955466032028198
Validation loss: 2.17865926219571

Epoch: 6| Step: 7
Training loss: 2.3682949542999268
Validation loss: 2.1607370427859727

Epoch: 6| Step: 8
Training loss: 2.78895902633667
Validation loss: 2.1556522436039423

Epoch: 6| Step: 9
Training loss: 2.277413845062256
Validation loss: 2.16760391061024

Epoch: 6| Step: 10
Training loss: 2.5782086849212646
Validation loss: 2.155431596181726

Epoch: 6| Step: 11
Training loss: 2.242151975631714
Validation loss: 2.1871979044329737

Epoch: 6| Step: 12
Training loss: 2.240039348602295
Validation loss: 2.1569253026798205

Epoch: 6| Step: 13
Training loss: 2.028458833694458
Validation loss: 2.203291477695588

Epoch: 58| Step: 0
Training loss: 2.207721710205078
Validation loss: 2.1567819913228354

Epoch: 6| Step: 1
Training loss: 2.9043118953704834
Validation loss: 2.1548999509503766

Epoch: 6| Step: 2
Training loss: 1.880168080329895
Validation loss: 2.167788633736231

Epoch: 6| Step: 3
Training loss: 2.404555559158325
Validation loss: 2.1767573100264355

Epoch: 6| Step: 4
Training loss: 1.811206579208374
Validation loss: 2.1531370352673274

Epoch: 6| Step: 5
Training loss: 2.013470411300659
Validation loss: 2.1616994924442743

Epoch: 6| Step: 6
Training loss: 2.0930354595184326
Validation loss: 2.1904674114719516

Epoch: 6| Step: 7
Training loss: 2.1765942573547363
Validation loss: 2.1773435377305552

Epoch: 6| Step: 8
Training loss: 2.389346122741699
Validation loss: 2.195570989321637

Epoch: 6| Step: 9
Training loss: 2.8981666564941406
Validation loss: 2.184543719855688

Epoch: 6| Step: 10
Training loss: 2.2548911571502686
Validation loss: 2.166377221384356

Epoch: 6| Step: 11
Training loss: 1.4424504041671753
Validation loss: 2.1533596964292627

Epoch: 6| Step: 12
Training loss: 1.878516674041748
Validation loss: 2.163497599222327

Epoch: 6| Step: 13
Training loss: 3.283024787902832
Validation loss: 2.13748199196272

Epoch: 59| Step: 0
Training loss: 2.4800515174865723
Validation loss: 2.1739759188826366

Epoch: 6| Step: 1
Training loss: 2.2939138412475586
Validation loss: 2.156070819465063

Epoch: 6| Step: 2
Training loss: 2.313579797744751
Validation loss: 2.1759819856254

Epoch: 6| Step: 3
Training loss: 2.0136570930480957
Validation loss: 2.1607587722039994

Epoch: 6| Step: 4
Training loss: 2.631992816925049
Validation loss: 2.1786749106581493

Epoch: 6| Step: 5
Training loss: 1.473739504814148
Validation loss: 2.1739284902490597

Epoch: 6| Step: 6
Training loss: 1.9920374155044556
Validation loss: 2.1774236694458993

Epoch: 6| Step: 7
Training loss: 1.8381831645965576
Validation loss: 2.162718606251542

Epoch: 6| Step: 8
Training loss: 2.389443874359131
Validation loss: 2.153132300223074

Epoch: 6| Step: 9
Training loss: 2.255866527557373
Validation loss: 2.185133857111777

Epoch: 6| Step: 10
Training loss: 2.047701597213745
Validation loss: 2.1761294680257

Epoch: 6| Step: 11
Training loss: 2.0867316722869873
Validation loss: 2.169531867068301

Epoch: 6| Step: 12
Training loss: 2.4131367206573486
Validation loss: 2.1610481610862156

Epoch: 6| Step: 13
Training loss: 3.0708954334259033
Validation loss: 2.184165580298311

Epoch: 60| Step: 0
Training loss: 2.940443992614746
Validation loss: 2.172449440084478

Epoch: 6| Step: 1
Training loss: 1.9753189086914062
Validation loss: 2.1780870858059136

Epoch: 6| Step: 2
Training loss: 2.976564884185791
Validation loss: 2.170968194161692

Epoch: 6| Step: 3
Training loss: 1.5661817789077759
Validation loss: 2.1683548752979567

Epoch: 6| Step: 4
Training loss: 2.6827778816223145
Validation loss: 2.1532096375701246

Epoch: 6| Step: 5
Training loss: 1.7560796737670898
Validation loss: 2.1728138705735565

Epoch: 6| Step: 6
Training loss: 1.9051134586334229
Validation loss: 2.178535794699064

Epoch: 6| Step: 7
Training loss: 1.9506906270980835
Validation loss: 2.157671715623589

Epoch: 6| Step: 8
Training loss: 2.278921604156494
Validation loss: 2.1601157406324982

Epoch: 6| Step: 9
Training loss: 1.9698008298873901
Validation loss: 2.158964987724058

Epoch: 6| Step: 10
Training loss: 1.998106837272644
Validation loss: 2.169974906470186

Epoch: 6| Step: 11
Training loss: 2.4500350952148438
Validation loss: 2.1669574681148736

Epoch: 6| Step: 12
Training loss: 2.146266222000122
Validation loss: 2.157713940066676

Epoch: 6| Step: 13
Training loss: 2.578604221343994
Validation loss: 2.163572975384292

Epoch: 61| Step: 0
Training loss: 3.1451854705810547
Validation loss: 2.183240500829553

Epoch: 6| Step: 1
Training loss: 1.9016399383544922
Validation loss: 2.1649773428517003

Epoch: 6| Step: 2
Training loss: 1.0704851150512695
Validation loss: 2.1415075948161464

Epoch: 6| Step: 3
Training loss: 1.998902440071106
Validation loss: 2.1888838814150904

Epoch: 6| Step: 4
Training loss: 2.769430160522461
Validation loss: 2.1625644250582625

Epoch: 6| Step: 5
Training loss: 3.3168764114379883
Validation loss: 2.166513814721056

Epoch: 6| Step: 6
Training loss: 1.6339192390441895
Validation loss: 2.170308025934363

Epoch: 6| Step: 7
Training loss: 2.2178473472595215
Validation loss: 2.156204277469266

Epoch: 6| Step: 8
Training loss: 2.178514242172241
Validation loss: 2.1703482802196215

Epoch: 6| Step: 9
Training loss: 1.8274242877960205
Validation loss: 2.154003793193448

Epoch: 6| Step: 10
Training loss: 2.2525582313537598
Validation loss: 2.1638349089571225

Epoch: 6| Step: 11
Training loss: 2.0578866004943848
Validation loss: 2.168436973325668

Epoch: 6| Step: 12
Training loss: 2.1113009452819824
Validation loss: 2.151564860856661

Epoch: 6| Step: 13
Training loss: 2.646132230758667
Validation loss: 2.1770075905707573

Epoch: 62| Step: 0
Training loss: 3.1510748863220215
Validation loss: 2.18423798776442

Epoch: 6| Step: 1
Training loss: 1.715817928314209
Validation loss: 2.1681981958368772

Epoch: 6| Step: 2
Training loss: 2.046422004699707
Validation loss: 2.1709712064394386

Epoch: 6| Step: 3
Training loss: 2.539792537689209
Validation loss: 2.1888619084512033

Epoch: 6| Step: 4
Training loss: 2.358853340148926
Validation loss: 2.1489399017826205

Epoch: 6| Step: 5
Training loss: 2.2304024696350098
Validation loss: 2.1818502590220463

Epoch: 6| Step: 6
Training loss: 2.4044246673583984
Validation loss: 2.1790701189348773

Epoch: 6| Step: 7
Training loss: 2.5133237838745117
Validation loss: 2.1716825218610865

Epoch: 6| Step: 8
Training loss: 1.713557481765747
Validation loss: 2.1778331110554356

Epoch: 6| Step: 9
Training loss: 1.632425308227539
Validation loss: 2.163803219795227

Epoch: 6| Step: 10
Training loss: 2.343320369720459
Validation loss: 2.1617603558366016

Epoch: 6| Step: 11
Training loss: 1.962606430053711
Validation loss: 2.1585955594175603

Epoch: 6| Step: 12
Training loss: 1.998645305633545
Validation loss: 2.170113173864221

Epoch: 6| Step: 13
Training loss: 2.0076510906219482
Validation loss: 2.1687817650456584

Epoch: 63| Step: 0
Training loss: 1.6794356107711792
Validation loss: 2.1761121442241054

Epoch: 6| Step: 1
Training loss: 2.5796427726745605
Validation loss: 2.157570524882245

Epoch: 6| Step: 2
Training loss: 2.1981618404388428
Validation loss: 2.1684284517841954

Epoch: 6| Step: 3
Training loss: 3.432110071182251
Validation loss: 2.177988936824183

Epoch: 6| Step: 4
Training loss: 2.2906455993652344
Validation loss: 2.1530822169396187

Epoch: 6| Step: 5
Training loss: 1.6442511081695557
Validation loss: 2.1614202325062086

Epoch: 6| Step: 6
Training loss: 2.5201518535614014
Validation loss: 2.1363350370878815

Epoch: 6| Step: 7
Training loss: 1.7576377391815186
Validation loss: 2.155350274937127

Epoch: 6| Step: 8
Training loss: 1.9050564765930176
Validation loss: 2.162903108904439

Epoch: 6| Step: 9
Training loss: 2.201052665710449
Validation loss: 2.1504765069612892

Epoch: 6| Step: 10
Training loss: 2.257880687713623
Validation loss: 2.1707803792850946

Epoch: 6| Step: 11
Training loss: 2.6185145378112793
Validation loss: 2.164930884556104

Epoch: 6| Step: 12
Training loss: 1.8978424072265625
Validation loss: 2.1694826208135134

Epoch: 6| Step: 13
Training loss: 1.7289282083511353
Validation loss: 2.154224511115782

Epoch: 64| Step: 0
Training loss: 2.932880401611328
Validation loss: 2.1363810326463435

Epoch: 6| Step: 1
Training loss: 2.248138904571533
Validation loss: 2.1655638653744935

Epoch: 6| Step: 2
Training loss: 2.4949216842651367
Validation loss: 2.160978704370478

Epoch: 6| Step: 3
Training loss: 2.566847801208496
Validation loss: 2.1491939342150124

Epoch: 6| Step: 4
Training loss: 2.242736339569092
Validation loss: 2.177108003247169

Epoch: 6| Step: 5
Training loss: 1.7625925540924072
Validation loss: 2.1587768613651233

Epoch: 6| Step: 6
Training loss: 1.7689310312271118
Validation loss: 2.1498140109482633

Epoch: 6| Step: 7
Training loss: 2.725661277770996
Validation loss: 2.1691604750130766

Epoch: 6| Step: 8
Training loss: 2.311429500579834
Validation loss: 2.1637419282749133

Epoch: 6| Step: 9
Training loss: 1.7040404081344604
Validation loss: 2.1638318800157115

Epoch: 6| Step: 10
Training loss: 2.2162089347839355
Validation loss: 2.148380676905314

Epoch: 6| Step: 11
Training loss: 2.166994333267212
Validation loss: 2.1603970809649398

Epoch: 6| Step: 12
Training loss: 1.7575666904449463
Validation loss: 2.152294425554173

Epoch: 6| Step: 13
Training loss: 1.4792654514312744
Validation loss: 2.1696124820299048

Epoch: 65| Step: 0
Training loss: 1.518484354019165
Validation loss: 2.1632879562275384

Epoch: 6| Step: 1
Training loss: 2.416378974914551
Validation loss: 2.1477122409369356

Epoch: 6| Step: 2
Training loss: 1.8457481861114502
Validation loss: 2.127559410628452

Epoch: 6| Step: 3
Training loss: 2.7809433937072754
Validation loss: 2.1643679757272043

Epoch: 6| Step: 4
Training loss: 2.7174510955810547
Validation loss: 2.1378412797886837

Epoch: 6| Step: 5
Training loss: 1.6359331607818604
Validation loss: 2.1612129749790316

Epoch: 6| Step: 6
Training loss: 2.621824264526367
Validation loss: 2.160238842810354

Epoch: 6| Step: 7
Training loss: 1.766008734703064
Validation loss: 2.134575992502192

Epoch: 6| Step: 8
Training loss: 2.235316276550293
Validation loss: 2.160327862667781

Epoch: 6| Step: 9
Training loss: 2.6189651489257812
Validation loss: 2.134890878072349

Epoch: 6| Step: 10
Training loss: 2.277543544769287
Validation loss: 2.1562254275045087

Epoch: 6| Step: 11
Training loss: 1.3817224502563477
Validation loss: 2.154966313351867

Epoch: 6| Step: 12
Training loss: 2.174290657043457
Validation loss: 2.167208674133465

Epoch: 6| Step: 13
Training loss: 2.914443016052246
Validation loss: 2.1323627387323687

Epoch: 66| Step: 0
Training loss: 2.112048625946045
Validation loss: 2.1548644201729887

Epoch: 6| Step: 1
Training loss: 2.289468765258789
Validation loss: 2.1576452819249963

Epoch: 6| Step: 2
Training loss: 2.065934658050537
Validation loss: 2.1532553139553277

Epoch: 6| Step: 3
Training loss: 1.84499192237854
Validation loss: 2.1441535052432807

Epoch: 6| Step: 4
Training loss: 2.280088424682617
Validation loss: 2.1583970592867945

Epoch: 6| Step: 5
Training loss: 2.052182197570801
Validation loss: 2.1210122005913847

Epoch: 6| Step: 6
Training loss: 2.101522922515869
Validation loss: 2.1604895450735606

Epoch: 6| Step: 7
Training loss: 2.354785203933716
Validation loss: 2.1470606826966807

Epoch: 6| Step: 8
Training loss: 2.405209541320801
Validation loss: 2.1517392537927114

Epoch: 6| Step: 9
Training loss: 3.2383956909179688
Validation loss: 2.1721768302302205

Epoch: 6| Step: 10
Training loss: 1.7841864824295044
Validation loss: 2.161378845091789

Epoch: 6| Step: 11
Training loss: 1.8026561737060547
Validation loss: 2.1385032259007937

Epoch: 6| Step: 12
Training loss: 1.630523443222046
Validation loss: 2.132105550458354

Epoch: 6| Step: 13
Training loss: 2.708362102508545
Validation loss: 2.1509710204216743

Epoch: 67| Step: 0
Training loss: 1.9911441802978516
Validation loss: 2.1352163104600805

Epoch: 6| Step: 1
Training loss: 1.6935102939605713
Validation loss: 2.1383175260277203

Epoch: 6| Step: 2
Training loss: 1.9465601444244385
Validation loss: 2.15236153910237

Epoch: 6| Step: 3
Training loss: 2.1074275970458984
Validation loss: 2.144390518947314

Epoch: 6| Step: 4
Training loss: 3.1425352096557617
Validation loss: 2.1295515055297525

Epoch: 6| Step: 5
Training loss: 2.442439317703247
Validation loss: 2.1194121376160653

Epoch: 6| Step: 6
Training loss: 2.047088146209717
Validation loss: 2.134868368025749

Epoch: 6| Step: 7
Training loss: 2.6243441104888916
Validation loss: 2.126005939258042

Epoch: 6| Step: 8
Training loss: 2.1977505683898926
Validation loss: 2.1533754487191477

Epoch: 6| Step: 9
Training loss: 1.9760887622833252
Validation loss: 2.1200046667488675

Epoch: 6| Step: 10
Training loss: 2.13694429397583
Validation loss: 2.1688421477553663

Epoch: 6| Step: 11
Training loss: 2.07635498046875
Validation loss: 2.1269906079897316

Epoch: 6| Step: 12
Training loss: 1.951630711555481
Validation loss: 2.148925209558138

Epoch: 6| Step: 13
Training loss: 2.320586681365967
Validation loss: 2.17268047794219

Epoch: 68| Step: 0
Training loss: 3.0297675132751465
Validation loss: 2.143274081650601

Epoch: 6| Step: 1
Training loss: 2.1587939262390137
Validation loss: 2.167833007791991

Epoch: 6| Step: 2
Training loss: 1.6992688179016113
Validation loss: 2.1249246546017226

Epoch: 6| Step: 3
Training loss: 2.0189597606658936
Validation loss: 2.1315930530589116

Epoch: 6| Step: 4
Training loss: 2.467935562133789
Validation loss: 2.167375094147139

Epoch: 6| Step: 5
Training loss: 2.874978542327881
Validation loss: 2.1557234256498274

Epoch: 6| Step: 6
Training loss: 2.163119077682495
Validation loss: 2.137947295301704

Epoch: 6| Step: 7
Training loss: 1.8659944534301758
Validation loss: 2.175330021048105

Epoch: 6| Step: 8
Training loss: 1.8726773262023926
Validation loss: 2.135289639554998

Epoch: 6| Step: 9
Training loss: 2.3648312091827393
Validation loss: 2.1632029253949403

Epoch: 6| Step: 10
Training loss: 1.6840696334838867
Validation loss: 2.1406081312446186

Epoch: 6| Step: 11
Training loss: 2.634979724884033
Validation loss: 2.132182762187014

Epoch: 6| Step: 12
Training loss: 1.6647247076034546
Validation loss: 2.165358022976947

Epoch: 6| Step: 13
Training loss: 1.221975326538086
Validation loss: 2.156813559993621

Epoch: 69| Step: 0
Training loss: 2.389676809310913
Validation loss: 2.13920997804211

Epoch: 6| Step: 1
Training loss: 2.584606647491455
Validation loss: 2.148203665210355

Epoch: 6| Step: 2
Training loss: 1.5427452325820923
Validation loss: 2.1315668603425384

Epoch: 6| Step: 3
Training loss: 1.470604658126831
Validation loss: 2.146198352177938

Epoch: 6| Step: 4
Training loss: 2.294355630874634
Validation loss: 2.143798412815217

Epoch: 6| Step: 5
Training loss: 2.8805317878723145
Validation loss: 2.155734900505312

Epoch: 6| Step: 6
Training loss: 2.0850844383239746
Validation loss: 2.1481739372335453

Epoch: 6| Step: 7
Training loss: 2.21127986907959
Validation loss: 2.11445511797423

Epoch: 6| Step: 8
Training loss: 2.6248245239257812
Validation loss: 2.132570875588284

Epoch: 6| Step: 9
Training loss: 1.9540342092514038
Validation loss: 2.1656799265133437

Epoch: 6| Step: 10
Training loss: 1.7060673236846924
Validation loss: 2.138531760502887

Epoch: 6| Step: 11
Training loss: 2.6140379905700684
Validation loss: 2.0692673934403287

Epoch: 6| Step: 12
Training loss: 2.0299549102783203
Validation loss: 2.155622528445336

Epoch: 6| Step: 13
Training loss: 1.9418288469314575
Validation loss: 2.1427111061670447

Epoch: 70| Step: 0
Training loss: 2.216712713241577
Validation loss: 2.140836554188882

Epoch: 6| Step: 1
Training loss: 1.9803237915039062
Validation loss: 2.1519089424481956

Epoch: 6| Step: 2
Training loss: 2.154045581817627
Validation loss: 2.1711808712251726

Epoch: 6| Step: 3
Training loss: 2.6311635971069336
Validation loss: 2.1503491042762675

Epoch: 6| Step: 4
Training loss: 2.3286139965057373
Validation loss: 2.1436769295764226

Epoch: 6| Step: 5
Training loss: 1.8406238555908203
Validation loss: 2.1294785263717815

Epoch: 6| Step: 6
Training loss: 2.3586292266845703
Validation loss: 2.1452431640317364

Epoch: 6| Step: 7
Training loss: 1.7507898807525635
Validation loss: 2.1437045092223794

Epoch: 6| Step: 8
Training loss: 1.524399995803833
Validation loss: 2.1408435554914576

Epoch: 6| Step: 9
Training loss: 1.5827655792236328
Validation loss: 2.1706129735515964

Epoch: 6| Step: 10
Training loss: 2.8026206493377686
Validation loss: 2.1373101357490785

Epoch: 6| Step: 11
Training loss: 2.429269313812256
Validation loss: 2.1656413924309517

Epoch: 6| Step: 12
Training loss: 2.41886043548584
Validation loss: 2.1333769752133276

Epoch: 6| Step: 13
Training loss: 2.1219096183776855
Validation loss: 2.141502208607171

Epoch: 71| Step: 0
Training loss: 1.7517056465148926
Validation loss: 2.1407707916793

Epoch: 6| Step: 1
Training loss: 2.0869340896606445
Validation loss: 2.1310284035180205

Epoch: 6| Step: 2
Training loss: 1.9267282485961914
Validation loss: 2.142891210894431

Epoch: 6| Step: 3
Training loss: 2.640035629272461
Validation loss: 2.124095360438029

Epoch: 6| Step: 4
Training loss: 2.235414981842041
Validation loss: 2.1553265356248423

Epoch: 6| Step: 5
Training loss: 2.4668731689453125
Validation loss: 2.1320701799085064

Epoch: 6| Step: 6
Training loss: 2.7263383865356445
Validation loss: 2.1172888971144155

Epoch: 6| Step: 7
Training loss: 2.790747880935669
Validation loss: 2.136985014843684

Epoch: 6| Step: 8
Training loss: 1.623523235321045
Validation loss: 2.126048867420484

Epoch: 6| Step: 9
Training loss: 2.029297351837158
Validation loss: 2.1200264884579565

Epoch: 6| Step: 10
Training loss: 1.424744963645935
Validation loss: 2.1567010751334568

Epoch: 6| Step: 11
Training loss: 2.1486752033233643
Validation loss: 2.124586702674948

Epoch: 6| Step: 12
Training loss: 2.087631940841675
Validation loss: 2.150575250707647

Epoch: 6| Step: 13
Training loss: 2.516417980194092
Validation loss: 2.1425315949224655

Epoch: 72| Step: 0
Training loss: 2.5653061866760254
Validation loss: 2.146924106023645

Epoch: 6| Step: 1
Training loss: 1.7770425081253052
Validation loss: 2.1616130029001543

Epoch: 6| Step: 2
Training loss: 2.163999319076538
Validation loss: 2.1344297650039836

Epoch: 6| Step: 3
Training loss: 2.8082375526428223
Validation loss: 2.145771522675791

Epoch: 6| Step: 4
Training loss: 1.825916051864624
Validation loss: 2.1031514008839927

Epoch: 6| Step: 5
Training loss: 2.485657215118408
Validation loss: 2.1375368448995773

Epoch: 6| Step: 6
Training loss: 2.0926835536956787
Validation loss: 2.1333256857369536

Epoch: 6| Step: 7
Training loss: 1.7886462211608887
Validation loss: 2.1445954691979194

Epoch: 6| Step: 8
Training loss: 1.8716024160385132
Validation loss: 2.158484028231713

Epoch: 6| Step: 9
Training loss: 1.6597918272018433
Validation loss: 2.1393046763635453

Epoch: 6| Step: 10
Training loss: 2.6118311882019043
Validation loss: 2.138566642679194

Epoch: 6| Step: 11
Training loss: 2.4600582122802734
Validation loss: 2.1140534621413036

Epoch: 6| Step: 12
Training loss: 1.9613933563232422
Validation loss: 2.1452880021064513

Epoch: 6| Step: 13
Training loss: 2.268977165222168
Validation loss: 2.141583599070067

Epoch: 73| Step: 0
Training loss: 1.810004711151123
Validation loss: 2.1373834379257692

Epoch: 6| Step: 1
Training loss: 2.156710147857666
Validation loss: 2.1166714545219176

Epoch: 6| Step: 2
Training loss: 2.069816827774048
Validation loss: 2.1430524702995055

Epoch: 6| Step: 3
Training loss: 2.5487797260284424
Validation loss: 2.1184078339607484

Epoch: 6| Step: 4
Training loss: 2.155435562133789
Validation loss: 2.1258590054768387

Epoch: 6| Step: 5
Training loss: 2.673851490020752
Validation loss: 2.147232676065096

Epoch: 6| Step: 6
Training loss: 2.543145179748535
Validation loss: 2.1311233517944173

Epoch: 6| Step: 7
Training loss: 1.4551005363464355
Validation loss: 2.116763138001965

Epoch: 6| Step: 8
Training loss: 2.660834312438965
Validation loss: 2.148048911043393

Epoch: 6| Step: 9
Training loss: 2.308971405029297
Validation loss: 2.1486304831761185

Epoch: 6| Step: 10
Training loss: 2.055459976196289
Validation loss: 2.1493123577487085

Epoch: 6| Step: 11
Training loss: 1.8910185098648071
Validation loss: 2.121155155602322

Epoch: 6| Step: 12
Training loss: 1.826499342918396
Validation loss: 2.129707487680579

Epoch: 6| Step: 13
Training loss: 2.162036895751953
Validation loss: 2.104855047759189

Epoch: 74| Step: 0
Training loss: 1.7247289419174194
Validation loss: 2.1177165328815417

Epoch: 6| Step: 1
Training loss: 2.647759199142456
Validation loss: 2.100986942168205

Epoch: 6| Step: 2
Training loss: 2.2303733825683594
Validation loss: 2.127561035976615

Epoch: 6| Step: 3
Training loss: 2.2311277389526367
Validation loss: 2.1066859588828137

Epoch: 6| Step: 4
Training loss: 2.1020348072052
Validation loss: 2.106433217243482

Epoch: 6| Step: 5
Training loss: 2.1157567501068115
Validation loss: 2.096680215609971

Epoch: 6| Step: 6
Training loss: 1.9042013883590698
Validation loss: 2.1318227475689304

Epoch: 6| Step: 7
Training loss: 1.6510810852050781
Validation loss: 2.1043255957224036

Epoch: 6| Step: 8
Training loss: 2.4823434352874756
Validation loss: 2.1184035654990905

Epoch: 6| Step: 9
Training loss: 1.8131929636001587
Validation loss: 2.138829272280457

Epoch: 6| Step: 10
Training loss: 1.9954479932785034
Validation loss: 2.154642992122199

Epoch: 6| Step: 11
Training loss: 1.43096923828125
Validation loss: 2.115957337041055

Epoch: 6| Step: 12
Training loss: 2.8645191192626953
Validation loss: 2.1260555431406987

Epoch: 6| Step: 13
Training loss: 3.452364921569824
Validation loss: 2.136463171692305

Epoch: 75| Step: 0
Training loss: 2.2731919288635254
Validation loss: 2.095021222227363

Epoch: 6| Step: 1
Training loss: 2.4702858924865723
Validation loss: 2.128950536891978

Epoch: 6| Step: 2
Training loss: 2.287720203399658
Validation loss: 2.1114099205181165

Epoch: 6| Step: 3
Training loss: 2.026327133178711
Validation loss: 2.1198786074115383

Epoch: 6| Step: 4
Training loss: 1.8672213554382324
Validation loss: 2.1040655759073075

Epoch: 6| Step: 5
Training loss: 1.8111186027526855
Validation loss: 2.1252856434032483

Epoch: 6| Step: 6
Training loss: 2.1650705337524414
Validation loss: 2.1050587802804928

Epoch: 6| Step: 7
Training loss: 2.4630627632141113
Validation loss: 2.1398943188369914

Epoch: 6| Step: 8
Training loss: 2.1439208984375
Validation loss: 2.1500955243264475

Epoch: 6| Step: 9
Training loss: 2.38446044921875
Validation loss: 2.126422925661969

Epoch: 6| Step: 10
Training loss: 1.7236500978469849
Validation loss: 2.1514326423727055

Epoch: 6| Step: 11
Training loss: 1.570726752281189
Validation loss: 2.106602890517122

Epoch: 6| Step: 12
Training loss: 2.583569049835205
Validation loss: 2.107886257991996

Epoch: 6| Step: 13
Training loss: 2.3292019367218018
Validation loss: 2.1105314223997054

Epoch: 76| Step: 0
Training loss: 1.6104533672332764
Validation loss: 2.097923360845094

Epoch: 6| Step: 1
Training loss: 1.961948275566101
Validation loss: 2.1178946956511466

Epoch: 6| Step: 2
Training loss: 2.3664417266845703
Validation loss: 2.100407260720448

Epoch: 6| Step: 3
Training loss: 2.643730878829956
Validation loss: 2.1352807296219694

Epoch: 6| Step: 4
Training loss: 3.1465535163879395
Validation loss: 2.143889452821465

Epoch: 6| Step: 5
Training loss: 2.7748525142669678
Validation loss: 2.145790884571691

Epoch: 6| Step: 6
Training loss: 1.6838090419769287
Validation loss: 2.128965438053172

Epoch: 6| Step: 7
Training loss: 1.792914867401123
Validation loss: 2.158042400113998

Epoch: 6| Step: 8
Training loss: 2.3719427585601807
Validation loss: 2.1321486273119525

Epoch: 6| Step: 9
Training loss: 1.8518576622009277
Validation loss: 2.1325336322989514

Epoch: 6| Step: 10
Training loss: 2.1348814964294434
Validation loss: 2.134262038815406

Epoch: 6| Step: 11
Training loss: 1.5626170635223389
Validation loss: 2.145165010165143

Epoch: 6| Step: 12
Training loss: 2.1966614723205566
Validation loss: 2.120818099667949

Epoch: 6| Step: 13
Training loss: 1.88923180103302
Validation loss: 2.1120664483757428

Epoch: 77| Step: 0
Training loss: 1.9372539520263672
Validation loss: 2.11515797081814

Epoch: 6| Step: 1
Training loss: 1.8770519495010376
Validation loss: 2.1097857285571355

Epoch: 6| Step: 2
Training loss: 1.8318182229995728
Validation loss: 2.1228565221191733

Epoch: 6| Step: 3
Training loss: 2.5816259384155273
Validation loss: 2.1161592263047413

Epoch: 6| Step: 4
Training loss: 1.6357295513153076
Validation loss: 2.1111270932741064

Epoch: 6| Step: 5
Training loss: 1.871053695678711
Validation loss: 2.1095978418986

Epoch: 6| Step: 6
Training loss: 1.8119324445724487
Validation loss: 2.087496570361558

Epoch: 6| Step: 7
Training loss: 2.4316039085388184
Validation loss: 2.0831791611127954

Epoch: 6| Step: 8
Training loss: 2.647695541381836
Validation loss: 2.0919037916327037

Epoch: 6| Step: 9
Training loss: 2.861799716949463
Validation loss: 2.100924135536276

Epoch: 6| Step: 10
Training loss: 2.1960813999176025
Validation loss: 2.1033412500094344

Epoch: 6| Step: 11
Training loss: 1.9620227813720703
Validation loss: 2.1349525400387344

Epoch: 6| Step: 12
Training loss: 1.9124541282653809
Validation loss: 2.1040826612903225

Epoch: 6| Step: 13
Training loss: 2.267467498779297
Validation loss: 2.0900931255791777

Epoch: 78| Step: 0
Training loss: 2.582056760787964
Validation loss: 2.113130277202975

Epoch: 6| Step: 1
Training loss: 1.511780023574829
Validation loss: 2.0993796740808794

Epoch: 6| Step: 2
Training loss: 2.07098388671875
Validation loss: 2.1117667203308432

Epoch: 6| Step: 3
Training loss: 2.1999545097351074
Validation loss: 2.13439598391133

Epoch: 6| Step: 4
Training loss: 2.333094835281372
Validation loss: 2.0976832406495207

Epoch: 6| Step: 5
Training loss: 2.2256827354431152
Validation loss: 2.1114939028216946

Epoch: 6| Step: 6
Training loss: 2.658954620361328
Validation loss: 2.105445208088044

Epoch: 6| Step: 7
Training loss: 1.876993179321289
Validation loss: 2.1339612981324554

Epoch: 6| Step: 8
Training loss: 2.557206869125366
Validation loss: 2.109958096217084

Epoch: 6| Step: 9
Training loss: 1.8448593616485596
Validation loss: 2.1184152454458256

Epoch: 6| Step: 10
Training loss: 1.4160263538360596
Validation loss: 2.096299348338958

Epoch: 6| Step: 11
Training loss: 2.4078636169433594
Validation loss: 2.1283999181562856

Epoch: 6| Step: 12
Training loss: 2.3008432388305664
Validation loss: 2.138733720266691

Epoch: 6| Step: 13
Training loss: 2.157259225845337
Validation loss: 2.0982573647652902

Epoch: 79| Step: 0
Training loss: 2.2381582260131836
Validation loss: 2.113715094904746

Epoch: 6| Step: 1
Training loss: 1.6913397312164307
Validation loss: 2.1218918600390033

Epoch: 6| Step: 2
Training loss: 2.3719778060913086
Validation loss: 2.0839578208102973

Epoch: 6| Step: 3
Training loss: 1.6303623914718628
Validation loss: 2.115416965176982

Epoch: 6| Step: 4
Training loss: 2.194819450378418
Validation loss: 2.0880889443941015

Epoch: 6| Step: 5
Training loss: 2.3216841220855713
Validation loss: 2.119388629031438

Epoch: 6| Step: 6
Training loss: 2.1446988582611084
Validation loss: 2.0911034166171985

Epoch: 6| Step: 7
Training loss: 1.678454875946045
Validation loss: 2.110384492463963

Epoch: 6| Step: 8
Training loss: 2.17258882522583
Validation loss: 2.0833427136944187

Epoch: 6| Step: 9
Training loss: 2.4337878227233887
Validation loss: 2.0812293893547467

Epoch: 6| Step: 10
Training loss: 2.865757465362549
Validation loss: 2.1275371531004548

Epoch: 6| Step: 11
Training loss: 1.459460973739624
Validation loss: 2.1324244199260587

Epoch: 6| Step: 12
Training loss: 1.9871859550476074
Validation loss: 2.1204078415388703

Epoch: 6| Step: 13
Training loss: 2.328134298324585
Validation loss: 2.0744913085814445

Epoch: 80| Step: 0
Training loss: 1.8162860870361328
Validation loss: 2.117176212290282

Epoch: 6| Step: 1
Training loss: 1.7028405666351318
Validation loss: 2.1019355379125124

Epoch: 6| Step: 2
Training loss: 2.0714597702026367
Validation loss: 2.1009835786716913

Epoch: 6| Step: 3
Training loss: 2.348552703857422
Validation loss: 2.1024031946735997

Epoch: 6| Step: 4
Training loss: 2.3050272464752197
Validation loss: 2.0809304380929596

Epoch: 6| Step: 5
Training loss: 2.5947012901306152
Validation loss: 2.1387079249146166

Epoch: 6| Step: 6
Training loss: 2.0890955924987793
Validation loss: 2.1109743528468634

Epoch: 6| Step: 7
Training loss: 1.621556043624878
Validation loss: 2.1203343752891786

Epoch: 6| Step: 8
Training loss: 2.0305683612823486
Validation loss: 2.0828426832793863

Epoch: 6| Step: 9
Training loss: 2.252148151397705
Validation loss: 2.1033356035909345

Epoch: 6| Step: 10
Training loss: 1.9894609451293945
Validation loss: 2.074659352661461

Epoch: 6| Step: 11
Training loss: 2.263874053955078
Validation loss: 2.1135427772357898

Epoch: 6| Step: 12
Training loss: 2.097456932067871
Validation loss: 2.109209606724401

Epoch: 6| Step: 13
Training loss: 2.803277015686035
Validation loss: 2.1086508663751746

Epoch: 81| Step: 0
Training loss: 2.003573417663574
Validation loss: 2.0593933213141655

Epoch: 6| Step: 1
Training loss: 1.795586109161377
Validation loss: 2.100143596690188

Epoch: 6| Step: 2
Training loss: 3.318302869796753
Validation loss: 2.1428400572910102

Epoch: 6| Step: 3
Training loss: 2.4571540355682373
Validation loss: 2.1059851518241306

Epoch: 6| Step: 4
Training loss: 1.801161289215088
Validation loss: 2.068876874062323

Epoch: 6| Step: 5
Training loss: 1.788912057876587
Validation loss: 2.106940079760808

Epoch: 6| Step: 6
Training loss: 1.8008065223693848
Validation loss: 2.1135059325925765

Epoch: 6| Step: 7
Training loss: 1.96095609664917
Validation loss: 2.078227055970059

Epoch: 6| Step: 8
Training loss: 2.458308458328247
Validation loss: 2.0857616752706547

Epoch: 6| Step: 9
Training loss: 2.2108333110809326
Validation loss: 2.1189210132886003

Epoch: 6| Step: 10
Training loss: 3.023237466812134
Validation loss: 2.103160289026076

Epoch: 6| Step: 11
Training loss: 2.3168766498565674
Validation loss: 2.100411791955271

Epoch: 6| Step: 12
Training loss: 0.8654173612594604
Validation loss: 2.102461535443542

Epoch: 6| Step: 13
Training loss: 1.8171299695968628
Validation loss: 2.070315249504582

Epoch: 82| Step: 0
Training loss: 1.5268447399139404
Validation loss: 2.1055001738250896

Epoch: 6| Step: 1
Training loss: 1.5808169841766357
Validation loss: 2.076500637556917

Epoch: 6| Step: 2
Training loss: 1.8545007705688477
Validation loss: 2.118008916096021

Epoch: 6| Step: 3
Training loss: 1.6940419673919678
Validation loss: 2.082983483550369

Epoch: 6| Step: 4
Training loss: 2.08840012550354
Validation loss: 2.096780546249882

Epoch: 6| Step: 5
Training loss: 1.9078850746154785
Validation loss: 2.0717904157536005

Epoch: 6| Step: 6
Training loss: 1.6730656623840332
Validation loss: 2.1164033566751788

Epoch: 6| Step: 7
Training loss: 1.900510549545288
Validation loss: 2.072066645468435

Epoch: 6| Step: 8
Training loss: 2.348268985748291
Validation loss: 2.0528003374735513

Epoch: 6| Step: 9
Training loss: 2.4168357849121094
Validation loss: 2.100761411010578

Epoch: 6| Step: 10
Training loss: 2.91414737701416
Validation loss: 2.1056308848883516

Epoch: 6| Step: 11
Training loss: 2.517369031906128
Validation loss: 2.095083882731776

Epoch: 6| Step: 12
Training loss: 2.473724365234375
Validation loss: 2.1037876272714264

Epoch: 6| Step: 13
Training loss: 2.9086568355560303
Validation loss: 2.0953516780689196

Epoch: 83| Step: 0
Training loss: 1.6959288120269775
Validation loss: 2.090816552921008

Epoch: 6| Step: 1
Training loss: 1.2835456132888794
Validation loss: 2.0574214214919717

Epoch: 6| Step: 2
Training loss: 2.923112392425537
Validation loss: 2.093656051543451

Epoch: 6| Step: 3
Training loss: 2.419389009475708
Validation loss: 2.0735101353737617

Epoch: 6| Step: 4
Training loss: 2.175661087036133
Validation loss: 2.0936523740009596

Epoch: 6| Step: 5
Training loss: 2.0460152626037598
Validation loss: 2.070052800639983

Epoch: 6| Step: 6
Training loss: 1.7275490760803223
Validation loss: 2.0941112938747612

Epoch: 6| Step: 7
Training loss: 1.693382740020752
Validation loss: 2.0665519750246437

Epoch: 6| Step: 8
Training loss: 2.48421573638916
Validation loss: 2.117239922605535

Epoch: 6| Step: 9
Training loss: 2.2463393211364746
Validation loss: 2.0799946708063923

Epoch: 6| Step: 10
Training loss: 1.7803311347961426
Validation loss: 2.1019897409664687

Epoch: 6| Step: 11
Training loss: 2.492800235748291
Validation loss: 2.1012470312015985

Epoch: 6| Step: 12
Training loss: 2.671876907348633
Validation loss: 2.0813423971976004

Epoch: 6| Step: 13
Training loss: 2.590813398361206
Validation loss: 2.136912589432091

Epoch: 84| Step: 0
Training loss: 2.0157980918884277
Validation loss: 2.106238306209605

Epoch: 6| Step: 1
Training loss: 2.229403495788574
Validation loss: 2.0761296236386864

Epoch: 6| Step: 2
Training loss: 2.5744543075561523
Validation loss: 2.127720220114595

Epoch: 6| Step: 3
Training loss: 2.414278984069824
Validation loss: 2.096875495808099

Epoch: 6| Step: 4
Training loss: 2.162559986114502
Validation loss: 2.0916695133332284

Epoch: 6| Step: 5
Training loss: 2.6000638008117676
Validation loss: 2.070216040457449

Epoch: 6| Step: 6
Training loss: 2.2992358207702637
Validation loss: 2.1132332714655067

Epoch: 6| Step: 7
Training loss: 1.5685489177703857
Validation loss: 2.072992483774821

Epoch: 6| Step: 8
Training loss: 1.6799359321594238
Validation loss: 2.095369536389587

Epoch: 6| Step: 9
Training loss: 1.522871971130371
Validation loss: 2.071969574497592

Epoch: 6| Step: 10
Training loss: 2.310856580734253
Validation loss: 2.0724510633817284

Epoch: 6| Step: 11
Training loss: 1.8304904699325562
Validation loss: 2.0905120757318314

Epoch: 6| Step: 12
Training loss: 2.1284399032592773
Validation loss: 2.100838058738298

Epoch: 6| Step: 13
Training loss: 2.00329852104187
Validation loss: 2.095208514121271

Epoch: 85| Step: 0
Training loss: 2.244661331176758
Validation loss: 2.0837409778307845

Epoch: 6| Step: 1
Training loss: 2.0593338012695312
Validation loss: 2.080535909181

Epoch: 6| Step: 2
Training loss: 1.705580711364746
Validation loss: 2.114298969186762

Epoch: 6| Step: 3
Training loss: 2.3160688877105713
Validation loss: 2.0826548094390542

Epoch: 6| Step: 4
Training loss: 2.3211307525634766
Validation loss: 2.075467683935678

Epoch: 6| Step: 5
Training loss: 2.163681983947754
Validation loss: 2.0941562268041793

Epoch: 6| Step: 6
Training loss: 1.4665205478668213
Validation loss: 2.0829087303530787

Epoch: 6| Step: 7
Training loss: 2.513767719268799
Validation loss: 2.0890329063579602

Epoch: 6| Step: 8
Training loss: 2.4689807891845703
Validation loss: 2.088592811297345

Epoch: 6| Step: 9
Training loss: 2.845132827758789
Validation loss: 2.080039096134965

Epoch: 6| Step: 10
Training loss: 1.1980016231536865
Validation loss: 2.0984286723598355

Epoch: 6| Step: 11
Training loss: 1.644818663597107
Validation loss: 2.09705037583587

Epoch: 6| Step: 12
Training loss: 2.1344127655029297
Validation loss: 2.0943698190873667

Epoch: 6| Step: 13
Training loss: 2.184596061706543
Validation loss: 2.0438551415679274

Epoch: 86| Step: 0
Training loss: 2.88260817527771
Validation loss: 2.076896518789312

Epoch: 6| Step: 1
Training loss: 2.719998359680176
Validation loss: 2.0724327974422003

Epoch: 6| Step: 2
Training loss: 1.6870362758636475
Validation loss: 2.0752059387904342

Epoch: 6| Step: 3
Training loss: 1.878730297088623
Validation loss: 2.0957103403665687

Epoch: 6| Step: 4
Training loss: 2.3555455207824707
Validation loss: 2.093361635361948

Epoch: 6| Step: 5
Training loss: 2.225640296936035
Validation loss: 2.0930002453506633

Epoch: 6| Step: 6
Training loss: 2.361057758331299
Validation loss: 2.0873975574329333

Epoch: 6| Step: 7
Training loss: 2.008749485015869
Validation loss: 2.0796031900631484

Epoch: 6| Step: 8
Training loss: 1.805821180343628
Validation loss: 2.0837591194337413

Epoch: 6| Step: 9
Training loss: 1.0945547819137573
Validation loss: 2.0688021336832354

Epoch: 6| Step: 10
Training loss: 2.258504867553711
Validation loss: 2.086054586595105

Epoch: 6| Step: 11
Training loss: 2.360261917114258
Validation loss: 2.1041104793548584

Epoch: 6| Step: 12
Training loss: 1.5522615909576416
Validation loss: 2.0804361886875604

Epoch: 6| Step: 13
Training loss: 2.2516610622406006
Validation loss: 2.064766235249017

Epoch: 87| Step: 0
Training loss: 2.0194385051727295
Validation loss: 2.050501000496649

Epoch: 6| Step: 1
Training loss: 1.6872639656066895
Validation loss: 2.069140221482964

Epoch: 6| Step: 2
Training loss: 1.5212808847427368
Validation loss: 2.07371868882128

Epoch: 6| Step: 3
Training loss: 1.8970104455947876
Validation loss: 2.0649384221723004

Epoch: 6| Step: 4
Training loss: 2.008756637573242
Validation loss: 2.0843102675612255

Epoch: 6| Step: 5
Training loss: 2.619812250137329
Validation loss: 2.0966007273684264

Epoch: 6| Step: 6
Training loss: 2.887251377105713
Validation loss: 2.0829323414833314

Epoch: 6| Step: 7
Training loss: 2.34895396232605
Validation loss: 2.0967707557062947

Epoch: 6| Step: 8
Training loss: 1.835707187652588
Validation loss: 2.1138888917943484

Epoch: 6| Step: 9
Training loss: 1.9882469177246094
Validation loss: 2.102869189554645

Epoch: 6| Step: 10
Training loss: 2.350254535675049
Validation loss: 2.06112576043734

Epoch: 6| Step: 11
Training loss: 2.5430350303649902
Validation loss: 2.083467560429727

Epoch: 6| Step: 12
Training loss: 1.8728628158569336
Validation loss: 2.1035600990377445

Epoch: 6| Step: 13
Training loss: 1.3566899299621582
Validation loss: 2.0799232644419514

Epoch: 88| Step: 0
Training loss: 2.571676254272461
Validation loss: 2.1192916823971655

Epoch: 6| Step: 1
Training loss: 2.293318271636963
Validation loss: 2.075444991870593

Epoch: 6| Step: 2
Training loss: 2.0820577144622803
Validation loss: 2.0986878025916313

Epoch: 6| Step: 3
Training loss: 2.013091564178467
Validation loss: 2.099651026469405

Epoch: 6| Step: 4
Training loss: 1.6005749702453613
Validation loss: 2.0852604527627268

Epoch: 6| Step: 5
Training loss: 2.1410372257232666
Validation loss: 2.074533752215806

Epoch: 6| Step: 6
Training loss: 2.5500950813293457
Validation loss: 2.075562959076256

Epoch: 6| Step: 7
Training loss: 1.8761016130447388
Validation loss: 2.0866749748106925

Epoch: 6| Step: 8
Training loss: 1.7224347591400146
Validation loss: 2.0843549287447365

Epoch: 6| Step: 9
Training loss: 2.656212329864502
Validation loss: 2.076444269508444

Epoch: 6| Step: 10
Training loss: 2.290681838989258
Validation loss: 2.0491742446858394

Epoch: 6| Step: 11
Training loss: 2.3679094314575195
Validation loss: 2.0919612402557046

Epoch: 6| Step: 12
Training loss: 1.5528242588043213
Validation loss: 2.0795702524082635

Epoch: 6| Step: 13
Training loss: 1.6622627973556519
Validation loss: 2.0782025039836927

Epoch: 89| Step: 0
Training loss: 2.365612506866455
Validation loss: 2.1024637376108477

Epoch: 6| Step: 1
Training loss: 2.056121826171875
Validation loss: 2.0907448978834253

Epoch: 6| Step: 2
Training loss: 1.6182985305786133
Validation loss: 2.092562888258247

Epoch: 6| Step: 3
Training loss: 2.8640310764312744
Validation loss: 2.088073859932602

Epoch: 6| Step: 4
Training loss: 1.6858394145965576
Validation loss: 2.075817577300533

Epoch: 6| Step: 5
Training loss: 2.1636831760406494
Validation loss: 2.0739824592426257

Epoch: 6| Step: 6
Training loss: 1.8474594354629517
Validation loss: 2.0656512219418763

Epoch: 6| Step: 7
Training loss: 2.4147815704345703
Validation loss: 2.106921519002607

Epoch: 6| Step: 8
Training loss: 1.9004251956939697
Validation loss: 2.042127616943852

Epoch: 6| Step: 9
Training loss: 2.51185941696167
Validation loss: 2.0801867361991637

Epoch: 6| Step: 10
Training loss: 2.2431118488311768
Validation loss: 2.104815334402105

Epoch: 6| Step: 11
Training loss: 1.977980613708496
Validation loss: 2.0897399712634344

Epoch: 6| Step: 12
Training loss: 1.7421002388000488
Validation loss: 2.090966752780381

Epoch: 6| Step: 13
Training loss: 2.2648637294769287
Validation loss: 2.0619892151125017

Epoch: 90| Step: 0
Training loss: 1.8120975494384766
Validation loss: 2.0840741101131646

Epoch: 6| Step: 1
Training loss: 2.3138136863708496
Validation loss: 2.065291138105495

Epoch: 6| Step: 2
Training loss: 2.169996500015259
Validation loss: 2.067062977821596

Epoch: 6| Step: 3
Training loss: 2.6588006019592285
Validation loss: 2.1028122094369706

Epoch: 6| Step: 4
Training loss: 2.2395339012145996
Validation loss: 2.0833597131954726

Epoch: 6| Step: 5
Training loss: 1.7160627841949463
Validation loss: 2.086987013457924

Epoch: 6| Step: 6
Training loss: 1.9148224592208862
Validation loss: 2.069539782821491

Epoch: 6| Step: 7
Training loss: 1.815084457397461
Validation loss: 2.0644419321449856

Epoch: 6| Step: 8
Training loss: 2.6168696880340576
Validation loss: 2.0878480608745287

Epoch: 6| Step: 9
Training loss: 2.836336135864258
Validation loss: 2.085660244828911

Epoch: 6| Step: 10
Training loss: 2.440840721130371
Validation loss: 2.0617986750859085

Epoch: 6| Step: 11
Training loss: 1.5232579708099365
Validation loss: 2.081007748521784

Epoch: 6| Step: 12
Training loss: 1.3759136199951172
Validation loss: 2.1032108337648454

Epoch: 6| Step: 13
Training loss: 2.0730082988739014
Validation loss: 2.0742887784075994

Epoch: 91| Step: 0
Training loss: 2.052284002304077
Validation loss: 2.108937422434489

Epoch: 6| Step: 1
Training loss: 2.345658779144287
Validation loss: 2.098395324522449

Epoch: 6| Step: 2
Training loss: 2.0695977210998535
Validation loss: 2.077159153517856

Epoch: 6| Step: 3
Training loss: 1.736325740814209
Validation loss: 2.085540433083811

Epoch: 6| Step: 4
Training loss: 1.924241542816162
Validation loss: 2.086933051386187

Epoch: 6| Step: 5
Training loss: 1.7932047843933105
Validation loss: 2.0725778020838255

Epoch: 6| Step: 6
Training loss: 2.3727827072143555
Validation loss: 2.090839316768031

Epoch: 6| Step: 7
Training loss: 2.73714017868042
Validation loss: 2.088552581366672

Epoch: 6| Step: 8
Training loss: 2.5086207389831543
Validation loss: 2.088387471373363

Epoch: 6| Step: 9
Training loss: 2.18918514251709
Validation loss: 2.0724297313280005

Epoch: 6| Step: 10
Training loss: 1.6709840297698975
Validation loss: 2.079153166022352

Epoch: 6| Step: 11
Training loss: 1.9226388931274414
Validation loss: 2.1033848306184173

Epoch: 6| Step: 12
Training loss: 1.784493088722229
Validation loss: 2.068695837451566

Epoch: 6| Step: 13
Training loss: 2.379025459289551
Validation loss: 2.0640726550932853

Epoch: 92| Step: 0
Training loss: 2.2395308017730713
Validation loss: 2.1096164282932075

Epoch: 6| Step: 1
Training loss: 2.6651415824890137
Validation loss: 2.088795315834784

Epoch: 6| Step: 2
Training loss: 1.78151273727417
Validation loss: 2.0783967189891364

Epoch: 6| Step: 3
Training loss: 2.2839953899383545
Validation loss: 2.0656181586686

Epoch: 6| Step: 4
Training loss: 2.2263827323913574
Validation loss: 2.0770789372023715

Epoch: 6| Step: 5
Training loss: 2.3227591514587402
Validation loss: 2.0845082421456613

Epoch: 6| Step: 6
Training loss: 1.4476374387741089
Validation loss: 2.0773201398952033

Epoch: 6| Step: 7
Training loss: 2.002730369567871
Validation loss: 2.0799454053243003

Epoch: 6| Step: 8
Training loss: 1.8086817264556885
Validation loss: 2.080172274702339

Epoch: 6| Step: 9
Training loss: 1.7601375579833984
Validation loss: 2.0895792720138386

Epoch: 6| Step: 10
Training loss: 2.710449457168579
Validation loss: 2.0790277501588226

Epoch: 6| Step: 11
Training loss: 1.9020441770553589
Validation loss: 2.0837186741572555

Epoch: 6| Step: 12
Training loss: 2.0628538131713867
Validation loss: 2.0632838946516796

Epoch: 6| Step: 13
Training loss: 1.5683561563491821
Validation loss: 2.0997806313217326

Epoch: 93| Step: 0
Training loss: 2.349052906036377
Validation loss: 2.057634554883485

Epoch: 6| Step: 1
Training loss: 1.778559684753418
Validation loss: 2.052381564212102

Epoch: 6| Step: 2
Training loss: 2.310260772705078
Validation loss: 2.074116435102237

Epoch: 6| Step: 3
Training loss: 1.352635383605957
Validation loss: 2.0863846168723157

Epoch: 6| Step: 4
Training loss: 2.537848949432373
Validation loss: 2.0906515018914336

Epoch: 6| Step: 5
Training loss: 2.0481204986572266
Validation loss: 2.038808144548888

Epoch: 6| Step: 6
Training loss: 2.0266592502593994
Validation loss: 2.090978301981444

Epoch: 6| Step: 7
Training loss: 1.443399429321289
Validation loss: 2.0551269592777377

Epoch: 6| Step: 8
Training loss: 2.4913249015808105
Validation loss: 2.0749723206284227

Epoch: 6| Step: 9
Training loss: 2.1700937747955322
Validation loss: 2.0775310608648483

Epoch: 6| Step: 10
Training loss: 1.7425869703292847
Validation loss: 2.0879326328154533

Epoch: 6| Step: 11
Training loss: 1.863313913345337
Validation loss: 2.073821080628262

Epoch: 6| Step: 12
Training loss: 2.2303566932678223
Validation loss: 2.0589975093000676

Epoch: 6| Step: 13
Training loss: 2.643754482269287
Validation loss: 2.070724166849608

Epoch: 94| Step: 0
Training loss: 2.886662006378174
Validation loss: 2.076967179134328

Epoch: 6| Step: 1
Training loss: 2.1153202056884766
Validation loss: 2.05803862438407

Epoch: 6| Step: 2
Training loss: 1.7422727346420288
Validation loss: 2.0721766282153387

Epoch: 6| Step: 3
Training loss: 1.5776458978652954
Validation loss: 2.062386566592801

Epoch: 6| Step: 4
Training loss: 1.7698291540145874
Validation loss: 2.1030327889227096

Epoch: 6| Step: 5
Training loss: 1.735572338104248
Validation loss: 2.0831226469368063

Epoch: 6| Step: 6
Training loss: 2.340024709701538
Validation loss: 2.077493862439227

Epoch: 6| Step: 7
Training loss: 2.4884567260742188
Validation loss: 2.0811794419442453

Epoch: 6| Step: 8
Training loss: 2.0231590270996094
Validation loss: 2.0879714463346746

Epoch: 6| Step: 9
Training loss: 2.139923095703125
Validation loss: 2.104527355522238

Epoch: 6| Step: 10
Training loss: 2.246023416519165
Validation loss: 2.0621913094674387

Epoch: 6| Step: 11
Training loss: 1.860390067100525
Validation loss: 2.076671605469078

Epoch: 6| Step: 12
Training loss: 1.8264474868774414
Validation loss: 2.0803289874907462

Epoch: 6| Step: 13
Training loss: 2.557816505432129
Validation loss: 2.091296867657733

Epoch: 95| Step: 0
Training loss: 1.9549427032470703
Validation loss: 2.0803254676121536

Epoch: 6| Step: 1
Training loss: 2.0319111347198486
Validation loss: 2.0975470953090216

Epoch: 6| Step: 2
Training loss: 2.2946672439575195
Validation loss: 2.043479965579125

Epoch: 6| Step: 3
Training loss: 2.098634958267212
Validation loss: 2.0805307203723538

Epoch: 6| Step: 4
Training loss: 2.2538416385650635
Validation loss: 2.1025693480686476

Epoch: 6| Step: 5
Training loss: 2.296621799468994
Validation loss: 2.069904806793377

Epoch: 6| Step: 6
Training loss: 1.8841575384140015
Validation loss: 2.077760834847727

Epoch: 6| Step: 7
Training loss: 2.4962778091430664
Validation loss: 2.0744805182180097

Epoch: 6| Step: 8
Training loss: 2.374262809753418
Validation loss: 2.0911848660438292

Epoch: 6| Step: 9
Training loss: 1.929100751876831
Validation loss: 2.0739318427219184

Epoch: 6| Step: 10
Training loss: 2.0142197608947754
Validation loss: 2.0880767991465907

Epoch: 6| Step: 11
Training loss: 1.7011005878448486
Validation loss: 2.119774446692518

Epoch: 6| Step: 12
Training loss: 1.661466360092163
Validation loss: 2.0523665233324935

Epoch: 6| Step: 13
Training loss: 2.0282676219940186
Validation loss: 2.0551559040623326

Epoch: 96| Step: 0
Training loss: 2.877350330352783
Validation loss: 2.0932261636180263

Epoch: 6| Step: 1
Training loss: 2.0851058959960938
Validation loss: 2.08828688949667

Epoch: 6| Step: 2
Training loss: 2.673847198486328
Validation loss: 2.075025375171374

Epoch: 6| Step: 3
Training loss: 1.4143092632293701
Validation loss: 2.040967751574773

Epoch: 6| Step: 4
Training loss: 3.1212210655212402
Validation loss: 2.072041524353848

Epoch: 6| Step: 5
Training loss: 1.674082636833191
Validation loss: 2.049466133117676

Epoch: 6| Step: 6
Training loss: 2.1684231758117676
Validation loss: 2.066405462962325

Epoch: 6| Step: 7
Training loss: 2.254481792449951
Validation loss: 2.0874757048904256

Epoch: 6| Step: 8
Training loss: 1.9860501289367676
Validation loss: 2.0625043222981114

Epoch: 6| Step: 9
Training loss: 1.7042832374572754
Validation loss: 2.074069553805936

Epoch: 6| Step: 10
Training loss: 1.8134360313415527
Validation loss: 2.0574688783255954

Epoch: 6| Step: 11
Training loss: 1.773060917854309
Validation loss: 2.0888356508747226

Epoch: 6| Step: 12
Training loss: 1.6645539999008179
Validation loss: 2.0786887599575903

Epoch: 6| Step: 13
Training loss: 1.586698055267334
Validation loss: 2.0419928514829246

Epoch: 97| Step: 0
Training loss: 1.6938395500183105
Validation loss: 2.0520040296739146

Epoch: 6| Step: 1
Training loss: 2.379979372024536
Validation loss: 2.0582416544678392

Epoch: 6| Step: 2
Training loss: 2.391909599304199
Validation loss: 2.0817796402080084

Epoch: 6| Step: 3
Training loss: 2.0621016025543213
Validation loss: 2.0304448066219205

Epoch: 6| Step: 4
Training loss: 2.2099952697753906
Validation loss: 2.0774364650890393

Epoch: 6| Step: 5
Training loss: 2.284976005554199
Validation loss: 2.0167953711684032

Epoch: 6| Step: 6
Training loss: 1.8574204444885254
Validation loss: 2.054109657964399

Epoch: 6| Step: 7
Training loss: 1.9445831775665283
Validation loss: 2.0696116544867076

Epoch: 6| Step: 8
Training loss: 2.330591917037964
Validation loss: 2.0723058639034146

Epoch: 6| Step: 9
Training loss: 1.8397750854492188
Validation loss: 2.060805692467638

Epoch: 6| Step: 10
Training loss: 1.782507300376892
Validation loss: 2.0226837768349597

Epoch: 6| Step: 11
Training loss: 2.045602560043335
Validation loss: 2.0725916393341555

Epoch: 6| Step: 12
Training loss: 1.8994669914245605
Validation loss: 2.044366672474851

Epoch: 6| Step: 13
Training loss: 2.316011428833008
Validation loss: 2.0524439247705604

Epoch: 98| Step: 0
Training loss: 2.1971449851989746
Validation loss: 2.070056838373984

Epoch: 6| Step: 1
Training loss: 2.223973512649536
Validation loss: 2.072737616877402

Epoch: 6| Step: 2
Training loss: 1.7228703498840332
Validation loss: 2.0574795276887956

Epoch: 6| Step: 3
Training loss: 2.340653896331787
Validation loss: 2.0603105996244695

Epoch: 6| Step: 4
Training loss: 1.7763055562973022
Validation loss: 2.0804597280358754

Epoch: 6| Step: 5
Training loss: 2.310119867324829
Validation loss: 2.0724426930950535

Epoch: 6| Step: 6
Training loss: 2.4456238746643066
Validation loss: 2.1144837692219722

Epoch: 6| Step: 7
Training loss: 2.0383107662200928
Validation loss: 2.0923424420818204

Epoch: 6| Step: 8
Training loss: 1.8509771823883057
Validation loss: 2.0949776364910986

Epoch: 6| Step: 9
Training loss: 1.8347042798995972
Validation loss: 2.0703254079306

Epoch: 6| Step: 10
Training loss: 2.634068012237549
Validation loss: 2.0841703709735664

Epoch: 6| Step: 11
Training loss: 1.6944023370742798
Validation loss: 2.116261793721107

Epoch: 6| Step: 12
Training loss: 1.3267199993133545
Validation loss: 2.0860180047250565

Epoch: 6| Step: 13
Training loss: 3.3191287517547607
Validation loss: 2.087894544806532

Epoch: 99| Step: 0
Training loss: 1.769547939300537
Validation loss: 2.0901609287467053

Epoch: 6| Step: 1
Training loss: 2.947390079498291
Validation loss: 2.0843505308192265

Epoch: 6| Step: 2
Training loss: 2.2452809810638428
Validation loss: 2.056639708498473

Epoch: 6| Step: 3
Training loss: 2.427313804626465
Validation loss: 2.073091296739476

Epoch: 6| Step: 4
Training loss: 2.1022677421569824
Validation loss: 2.058501176936652

Epoch: 6| Step: 5
Training loss: 1.478580355644226
Validation loss: 2.064957736640848

Epoch: 6| Step: 6
Training loss: 1.948111653327942
Validation loss: 2.059792798052552

Epoch: 6| Step: 7
Training loss: 1.5693399906158447
Validation loss: 2.0559358660892775

Epoch: 6| Step: 8
Training loss: 2.3847713470458984
Validation loss: 2.063593038948633

Epoch: 6| Step: 9
Training loss: 1.6472408771514893
Validation loss: 2.072989571479059

Epoch: 6| Step: 10
Training loss: 1.6677732467651367
Validation loss: 2.071512140253539

Epoch: 6| Step: 11
Training loss: 2.7867836952209473
Validation loss: 2.0494564053832844

Epoch: 6| Step: 12
Training loss: 2.0673158168792725
Validation loss: 2.0552880020551783

Epoch: 6| Step: 13
Training loss: 1.3142670392990112
Validation loss: 2.0770784039651193

Epoch: 100| Step: 0
Training loss: 1.9764623641967773
Validation loss: 2.038033631540114

Epoch: 6| Step: 1
Training loss: 2.758770227432251
Validation loss: 2.0792709909459597

Epoch: 6| Step: 2
Training loss: 1.6194188594818115
Validation loss: 2.064267332835864

Epoch: 6| Step: 3
Training loss: 2.1698412895202637
Validation loss: 2.082768770956224

Epoch: 6| Step: 4
Training loss: 1.6964921951293945
Validation loss: 2.09356423347227

Epoch: 6| Step: 5
Training loss: 2.4127535820007324
Validation loss: 2.0401516550330707

Epoch: 6| Step: 6
Training loss: 1.5147756338119507
Validation loss: 2.0452064955106346

Epoch: 6| Step: 7
Training loss: 2.189519166946411
Validation loss: 2.0674757047366072

Epoch: 6| Step: 8
Training loss: 2.1461217403411865
Validation loss: 2.088803122120519

Epoch: 6| Step: 9
Training loss: 1.913008213043213
Validation loss: 2.043979835766618

Epoch: 6| Step: 10
Training loss: 1.6630661487579346
Validation loss: 2.0833841946817215

Epoch: 6| Step: 11
Training loss: 2.980181932449341
Validation loss: 2.0669598284588067

Epoch: 6| Step: 12
Training loss: 1.7114293575286865
Validation loss: 2.0521329038886615

Epoch: 6| Step: 13
Training loss: 2.280855894088745
Validation loss: 2.080740322348892

Epoch: 101| Step: 0
Training loss: 2.554269313812256
Validation loss: 2.099043171892884

Epoch: 6| Step: 1
Training loss: 2.2447333335876465
Validation loss: 2.0799074378064883

Epoch: 6| Step: 2
Training loss: 2.228738784790039
Validation loss: 2.0665265155094925

Epoch: 6| Step: 3
Training loss: 1.3647863864898682
Validation loss: 2.0448059625523065

Epoch: 6| Step: 4
Training loss: 2.3223676681518555
Validation loss: 2.0518158276875815

Epoch: 6| Step: 5
Training loss: 2.2705349922180176
Validation loss: 2.061506338016961

Epoch: 6| Step: 6
Training loss: 2.6210403442382812
Validation loss: 2.068417595278832

Epoch: 6| Step: 7
Training loss: 1.8920326232910156
Validation loss: 2.065285869823989

Epoch: 6| Step: 8
Training loss: 1.4680027961730957
Validation loss: 2.045443736096864

Epoch: 6| Step: 9
Training loss: 1.9074634313583374
Validation loss: 2.0623875817944928

Epoch: 6| Step: 10
Training loss: 2.251922369003296
Validation loss: 2.0594104489972516

Epoch: 6| Step: 11
Training loss: 1.811569333076477
Validation loss: 2.059894259257983

Epoch: 6| Step: 12
Training loss: 1.736493706703186
Validation loss: 2.03563202581098

Epoch: 6| Step: 13
Training loss: 2.0706207752227783
Validation loss: 2.0537196051689888

Epoch: 102| Step: 0
Training loss: 1.9480030536651611
Validation loss: 2.058389126613576

Epoch: 6| Step: 1
Training loss: 2.4330928325653076
Validation loss: 2.054090505005211

Epoch: 6| Step: 2
Training loss: 2.676210403442383
Validation loss: 2.0479736866489535

Epoch: 6| Step: 3
Training loss: 1.7210299968719482
Validation loss: 2.0337126972854778

Epoch: 6| Step: 4
Training loss: 1.4072166681289673
Validation loss: 2.0641699452554025

Epoch: 6| Step: 5
Training loss: 1.3556993007659912
Validation loss: 2.0509859233774166

Epoch: 6| Step: 6
Training loss: 1.5253596305847168
Validation loss: 2.0529487338117374

Epoch: 6| Step: 7
Training loss: 2.4976425170898438
Validation loss: 2.061882206188735

Epoch: 6| Step: 8
Training loss: 2.2885327339172363
Validation loss: 2.049247275116623

Epoch: 6| Step: 9
Training loss: 2.6462180614471436
Validation loss: 2.0787119532144196

Epoch: 6| Step: 10
Training loss: 2.5755767822265625
Validation loss: 2.036708093458606

Epoch: 6| Step: 11
Training loss: 1.6257907152175903
Validation loss: 2.0736392723616732

Epoch: 6| Step: 12
Training loss: 1.4031753540039062
Validation loss: 2.0624198580300934

Epoch: 6| Step: 13
Training loss: 2.6649327278137207
Validation loss: 2.037169034763049

Epoch: 103| Step: 0
Training loss: 2.076472520828247
Validation loss: 2.0412306990674747

Epoch: 6| Step: 1
Training loss: 1.459592342376709
Validation loss: 2.0651783955994474

Epoch: 6| Step: 2
Training loss: 1.8805270195007324
Validation loss: 2.0657959112557034

Epoch: 6| Step: 3
Training loss: 2.270358085632324
Validation loss: 2.0379481405340214

Epoch: 6| Step: 4
Training loss: 2.3483309745788574
Validation loss: 2.0210265369825464

Epoch: 6| Step: 5
Training loss: 2.3916175365448
Validation loss: 2.0713612571839364

Epoch: 6| Step: 6
Training loss: 1.9905362129211426
Validation loss: 2.0577983625473513

Epoch: 6| Step: 7
Training loss: 2.3186845779418945
Validation loss: 2.0652482714704288

Epoch: 6| Step: 8
Training loss: 2.2364792823791504
Validation loss: 2.021466765352475

Epoch: 6| Step: 9
Training loss: 1.7761327028274536
Validation loss: 2.0324690354767667

Epoch: 6| Step: 10
Training loss: 2.1312692165374756
Validation loss: 2.0557720404799267

Epoch: 6| Step: 11
Training loss: 1.2642018795013428
Validation loss: 2.0063660170442317

Epoch: 6| Step: 12
Training loss: 2.718472480773926
Validation loss: 2.0445911525398173

Epoch: 6| Step: 13
Training loss: 1.4332427978515625
Validation loss: 2.0369905425656225

Epoch: 104| Step: 0
Training loss: 2.45503568649292
Validation loss: 2.0418721347726803

Epoch: 6| Step: 1
Training loss: 1.671999216079712
Validation loss: 2.0182406671585573

Epoch: 6| Step: 2
Training loss: 2.201212167739868
Validation loss: 2.0194157656802925

Epoch: 6| Step: 3
Training loss: 1.7033500671386719
Validation loss: 2.057504864149196

Epoch: 6| Step: 4
Training loss: 2.2917771339416504
Validation loss: 2.043017131026073

Epoch: 6| Step: 5
Training loss: 1.9613171815872192
Validation loss: 2.0365542340022262

Epoch: 6| Step: 6
Training loss: 2.0983266830444336
Validation loss: 2.0428915433986212

Epoch: 6| Step: 7
Training loss: 1.928908109664917
Validation loss: 2.0840545213350685

Epoch: 6| Step: 8
Training loss: 1.8205540180206299
Validation loss: 2.0450257742276756

Epoch: 6| Step: 9
Training loss: 2.045485019683838
Validation loss: 1.9933164376084522

Epoch: 6| Step: 10
Training loss: 1.9465397596359253
Validation loss: 2.0669374081396286

Epoch: 6| Step: 11
Training loss: 2.0399961471557617
Validation loss: 2.0471116624852663

Epoch: 6| Step: 12
Training loss: 2.26938533782959
Validation loss: 2.07657051855518

Epoch: 6| Step: 13
Training loss: 1.9806588888168335
Validation loss: 2.047141505825904

Epoch: 105| Step: 0
Training loss: 2.9282500743865967
Validation loss: 2.030606251890941

Epoch: 6| Step: 1
Training loss: 3.0399820804595947
Validation loss: 2.056156526329697

Epoch: 6| Step: 2
Training loss: 1.5771833658218384
Validation loss: 2.0329387598140265

Epoch: 6| Step: 3
Training loss: 2.238124370574951
Validation loss: 2.0255349502768567

Epoch: 6| Step: 4
Training loss: 1.8474920988082886
Validation loss: 2.0468341894047235

Epoch: 6| Step: 5
Training loss: 1.948840618133545
Validation loss: 2.058875619724233

Epoch: 6| Step: 6
Training loss: 1.7776689529418945
Validation loss: 2.0398368937994844

Epoch: 6| Step: 7
Training loss: 2.012643814086914
Validation loss: 2.033613463883759

Epoch: 6| Step: 8
Training loss: 1.9407384395599365
Validation loss: 2.07954934207342

Epoch: 6| Step: 9
Training loss: 1.6227115392684937
Validation loss: 2.0727442874703357

Epoch: 6| Step: 10
Training loss: 2.4935569763183594
Validation loss: 2.0645732956547893

Epoch: 6| Step: 11
Training loss: 1.7017500400543213
Validation loss: 2.0313667430672595

Epoch: 6| Step: 12
Training loss: 1.740619421005249
Validation loss: 2.0380070235139582

Epoch: 6| Step: 13
Training loss: 1.4857038259506226
Validation loss: 2.0363899969285533

Epoch: 106| Step: 0
Training loss: 2.5436770915985107
Validation loss: 2.0374625164975404

Epoch: 6| Step: 1
Training loss: 2.958817720413208
Validation loss: 2.0404347963230585

Epoch: 6| Step: 2
Training loss: 2.4189858436584473
Validation loss: 2.0296045605854323

Epoch: 6| Step: 3
Training loss: 2.3109641075134277
Validation loss: 2.0254523831029094

Epoch: 6| Step: 4
Training loss: 1.5983408689498901
Validation loss: 2.047502995819174

Epoch: 6| Step: 5
Training loss: 1.7485997676849365
Validation loss: 2.0603425682231946

Epoch: 6| Step: 6
Training loss: 1.5355300903320312
Validation loss: 2.0447426073012815

Epoch: 6| Step: 7
Training loss: 1.3529760837554932
Validation loss: 2.014146947091626

Epoch: 6| Step: 8
Training loss: 2.3927483558654785
Validation loss: 2.0607800829795098

Epoch: 6| Step: 9
Training loss: 2.0627527236938477
Validation loss: 2.052251587631882

Epoch: 6| Step: 10
Training loss: 1.7210105657577515
Validation loss: 2.065088564349759

Epoch: 6| Step: 11
Training loss: 1.7803107500076294
Validation loss: 2.0623222448492564

Epoch: 6| Step: 12
Training loss: 2.098054885864258
Validation loss: 2.0500082879938106

Epoch: 6| Step: 13
Training loss: 1.8395758867263794
Validation loss: 2.042594502049108

Epoch: 107| Step: 0
Training loss: 2.684075355529785
Validation loss: 2.0236673662739415

Epoch: 6| Step: 1
Training loss: 1.6619954109191895
Validation loss: 2.058699616821863

Epoch: 6| Step: 2
Training loss: 2.2133374214172363
Validation loss: 2.0443576356416107

Epoch: 6| Step: 3
Training loss: 2.2608819007873535
Validation loss: 2.07046647866567

Epoch: 6| Step: 4
Training loss: 1.7602263689041138
Validation loss: 2.0332802341830347

Epoch: 6| Step: 5
Training loss: 1.862595558166504
Validation loss: 2.0272457368912233

Epoch: 6| Step: 6
Training loss: 1.6690069437026978
Validation loss: 2.055624920834777

Epoch: 6| Step: 7
Training loss: 1.7019832134246826
Validation loss: 2.055751232690709

Epoch: 6| Step: 8
Training loss: 1.7075307369232178
Validation loss: 2.032050936452804

Epoch: 6| Step: 9
Training loss: 2.2721152305603027
Validation loss: 2.010608244967717

Epoch: 6| Step: 10
Training loss: 1.9784619808197021
Validation loss: 2.0813396682021437

Epoch: 6| Step: 11
Training loss: 2.1641061305999756
Validation loss: 2.0358810783714376

Epoch: 6| Step: 12
Training loss: 1.966672420501709
Validation loss: 2.066904297439001

Epoch: 6| Step: 13
Training loss: 3.0723984241485596
Validation loss: 2.0170409294866745

Epoch: 108| Step: 0
Training loss: 2.3744325637817383
Validation loss: 2.0593508084615073

Epoch: 6| Step: 1
Training loss: 2.062330722808838
Validation loss: 2.0579281212181173

Epoch: 6| Step: 2
Training loss: 1.9595366716384888
Validation loss: 2.0473516807761243

Epoch: 6| Step: 3
Training loss: 2.2701447010040283
Validation loss: 2.0292598406473794

Epoch: 6| Step: 4
Training loss: 2.2088990211486816
Validation loss: 2.0106613379652782

Epoch: 6| Step: 5
Training loss: 1.9193565845489502
Validation loss: 2.0781750486743067

Epoch: 6| Step: 6
Training loss: 1.5126986503601074
Validation loss: 2.031914581534683

Epoch: 6| Step: 7
Training loss: 2.4421329498291016
Validation loss: 2.0205271372231106

Epoch: 6| Step: 8
Training loss: 1.8413817882537842
Validation loss: 2.0129579677376697

Epoch: 6| Step: 9
Training loss: 1.7957673072814941
Validation loss: 2.0341665949872745

Epoch: 6| Step: 10
Training loss: 1.819950819015503
Validation loss: 2.0202527776841195

Epoch: 6| Step: 11
Training loss: 2.15615177154541
Validation loss: 2.041212006281781

Epoch: 6| Step: 12
Training loss: 2.061276435852051
Validation loss: 2.0988876178700435

Epoch: 6| Step: 13
Training loss: 2.13089919090271
Validation loss: 2.039475743488599

Epoch: 109| Step: 0
Training loss: 2.184889078140259
Validation loss: 2.0584370346479517

Epoch: 6| Step: 1
Training loss: 1.480417013168335
Validation loss: 2.04287975834262

Epoch: 6| Step: 2
Training loss: 3.0541539192199707
Validation loss: 2.0543882641741025

Epoch: 6| Step: 3
Training loss: 1.4796831607818604
Validation loss: 2.0287982417691137

Epoch: 6| Step: 4
Training loss: 2.3777337074279785
Validation loss: 2.0656351761151384

Epoch: 6| Step: 5
Training loss: 1.456288456916809
Validation loss: 2.0528862194348405

Epoch: 6| Step: 6
Training loss: 1.4095613956451416
Validation loss: 2.052825299642419

Epoch: 6| Step: 7
Training loss: 2.225930690765381
Validation loss: 2.0359344251694216

Epoch: 6| Step: 8
Training loss: 1.871335506439209
Validation loss: 2.025533788947649

Epoch: 6| Step: 9
Training loss: 2.049567222595215
Validation loss: 2.032040698553926

Epoch: 6| Step: 10
Training loss: 2.3141045570373535
Validation loss: 2.0357979241237847

Epoch: 6| Step: 11
Training loss: 2.0898611545562744
Validation loss: 2.056970597595297

Epoch: 6| Step: 12
Training loss: 2.949892282485962
Validation loss: 2.0445979872057514

Epoch: 6| Step: 13
Training loss: 1.1821445226669312
Validation loss: 2.0962942197758663

Epoch: 110| Step: 0
Training loss: 1.1465628147125244
Validation loss: 2.0091227651924215

Epoch: 6| Step: 1
Training loss: 2.006720781326294
Validation loss: 2.051353209762163

Epoch: 6| Step: 2
Training loss: 2.126214027404785
Validation loss: 2.0447206176737303

Epoch: 6| Step: 3
Training loss: 1.9409728050231934
Validation loss: 2.0528688251331286

Epoch: 6| Step: 4
Training loss: 2.5189223289489746
Validation loss: 2.0276578959598335

Epoch: 6| Step: 5
Training loss: 2.4721288681030273
Validation loss: 2.045863646332936

Epoch: 6| Step: 6
Training loss: 2.4495716094970703
Validation loss: 2.0413034244250228

Epoch: 6| Step: 7
Training loss: 2.6619715690612793
Validation loss: 2.0414156759938886

Epoch: 6| Step: 8
Training loss: 1.6456462144851685
Validation loss: 2.005085878474738

Epoch: 6| Step: 9
Training loss: 1.9185845851898193
Validation loss: 2.0437769684740292

Epoch: 6| Step: 10
Training loss: 2.0282883644104004
Validation loss: 2.067067195010442

Epoch: 6| Step: 11
Training loss: 1.799467921257019
Validation loss: 2.027292764315041

Epoch: 6| Step: 12
Training loss: 1.2922478914260864
Validation loss: 2.0496576088731007

Epoch: 6| Step: 13
Training loss: 2.4492223262786865
Validation loss: 2.04437058202682

Epoch: 111| Step: 0
Training loss: 1.5458087921142578
Validation loss: 1.9974917673295545

Epoch: 6| Step: 1
Training loss: 1.498300552368164
Validation loss: 2.0706242079375894

Epoch: 6| Step: 2
Training loss: 2.233035087585449
Validation loss: 2.017389230830695

Epoch: 6| Step: 3
Training loss: 2.508999824523926
Validation loss: 2.017038535046321

Epoch: 6| Step: 4
Training loss: 2.419870615005493
Validation loss: 2.060767323740067

Epoch: 6| Step: 5
Training loss: 1.7727131843566895
Validation loss: 2.0668334089299685

Epoch: 6| Step: 6
Training loss: 1.6309723854064941
Validation loss: 2.0260496934254966

Epoch: 6| Step: 7
Training loss: 2.104339599609375
Validation loss: 2.023052474503876

Epoch: 6| Step: 8
Training loss: 1.7374144792556763
Validation loss: 2.0388025596577632

Epoch: 6| Step: 9
Training loss: 2.141488790512085
Validation loss: 2.0741321643193564

Epoch: 6| Step: 10
Training loss: 2.3177592754364014
Validation loss: 2.088650626520957

Epoch: 6| Step: 11
Training loss: 1.695711612701416
Validation loss: 2.06459072584747

Epoch: 6| Step: 12
Training loss: 2.4431562423706055
Validation loss: 2.0529509129062777

Epoch: 6| Step: 13
Training loss: 2.635094404220581
Validation loss: 2.052814059360053

Epoch: 112| Step: 0
Training loss: 2.469172954559326
Validation loss: 2.028339123213163

Epoch: 6| Step: 1
Training loss: 1.7849116325378418
Validation loss: 2.0557831820621284

Epoch: 6| Step: 2
Training loss: 2.472069501876831
Validation loss: 2.0479302893402758

Epoch: 6| Step: 3
Training loss: 2.3137054443359375
Validation loss: 2.04665950036818

Epoch: 6| Step: 4
Training loss: 1.9636411666870117
Validation loss: 2.0204960428258425

Epoch: 6| Step: 5
Training loss: 1.3820774555206299
Validation loss: 2.022478593293057

Epoch: 6| Step: 6
Training loss: 1.4979548454284668
Validation loss: 2.0668448555854058

Epoch: 6| Step: 7
Training loss: 1.1591943502426147
Validation loss: 2.0245584185405443

Epoch: 6| Step: 8
Training loss: 2.4603562355041504
Validation loss: 2.0353238351883425

Epoch: 6| Step: 9
Training loss: 1.9205379486083984
Validation loss: 1.9896878401438396

Epoch: 6| Step: 10
Training loss: 2.3715052604675293
Validation loss: 2.0255392623204056

Epoch: 6| Step: 11
Training loss: 2.334221363067627
Validation loss: 2.0272230819989274

Epoch: 6| Step: 12
Training loss: 2.412339687347412
Validation loss: 2.021925159679946

Epoch: 6| Step: 13
Training loss: 1.3907591104507446
Validation loss: 2.0820339187499015

Epoch: 113| Step: 0
Training loss: 2.2332687377929688
Validation loss: 2.015127812662432

Epoch: 6| Step: 1
Training loss: 1.9415637254714966
Validation loss: 2.020751073796262

Epoch: 6| Step: 2
Training loss: 2.264423131942749
Validation loss: 2.0423533544745496

Epoch: 6| Step: 3
Training loss: 1.344468116760254
Validation loss: 2.0430404575922156

Epoch: 6| Step: 4
Training loss: 2.380220413208008
Validation loss: 2.017291445885935

Epoch: 6| Step: 5
Training loss: 1.938955307006836
Validation loss: 2.038715244621359

Epoch: 6| Step: 6
Training loss: 2.1133265495300293
Validation loss: 2.0439349605191137

Epoch: 6| Step: 7
Training loss: 1.784263014793396
Validation loss: 2.017972166820239

Epoch: 6| Step: 8
Training loss: 1.9873104095458984
Validation loss: 2.01869955114139

Epoch: 6| Step: 9
Training loss: 2.157255172729492
Validation loss: 2.0106091704419864

Epoch: 6| Step: 10
Training loss: 2.512511730194092
Validation loss: 2.0501951197142243

Epoch: 6| Step: 11
Training loss: 1.7178155183792114
Validation loss: 2.0169338410900486

Epoch: 6| Step: 12
Training loss: 1.9764888286590576
Validation loss: 2.059361714188771

Epoch: 6| Step: 13
Training loss: 1.8539347648620605
Validation loss: 2.0264240208492486

Epoch: 114| Step: 0
Training loss: 1.8811366558074951
Validation loss: 2.0335983704495173

Epoch: 6| Step: 1
Training loss: 2.3155910968780518
Validation loss: 2.0066868989698348

Epoch: 6| Step: 2
Training loss: 2.3412699699401855
Validation loss: 2.0314188464995353

Epoch: 6| Step: 3
Training loss: 2.742663621902466
Validation loss: 2.047157613180017

Epoch: 6| Step: 4
Training loss: 2.0173940658569336
Validation loss: 2.0724899538101687

Epoch: 6| Step: 5
Training loss: 1.7775583267211914
Validation loss: 2.025801558648386

Epoch: 6| Step: 6
Training loss: 1.7756190299987793
Validation loss: 2.0374304274077057

Epoch: 6| Step: 7
Training loss: 1.9153082370758057
Validation loss: 2.002567287414305

Epoch: 6| Step: 8
Training loss: 1.6422568559646606
Validation loss: 2.0357933005978985

Epoch: 6| Step: 9
Training loss: 2.180375814437866
Validation loss: 2.008883630075762

Epoch: 6| Step: 10
Training loss: 1.663970947265625
Validation loss: 2.0336486395969184

Epoch: 6| Step: 11
Training loss: 2.2237820625305176
Validation loss: 2.0789043723895984

Epoch: 6| Step: 12
Training loss: 1.054695963859558
Validation loss: 2.0158667743846936

Epoch: 6| Step: 13
Training loss: 3.3612396717071533
Validation loss: 2.049014279919286

Epoch: 115| Step: 0
Training loss: 1.66729736328125
Validation loss: 2.051203845649637

Epoch: 6| Step: 1
Training loss: 2.0390830039978027
Validation loss: 2.04024479978828

Epoch: 6| Step: 2
Training loss: 2.1061506271362305
Validation loss: 2.0276296856582805

Epoch: 6| Step: 3
Training loss: 1.7604701519012451
Validation loss: 2.0402240496809765

Epoch: 6| Step: 4
Training loss: 2.645479202270508
Validation loss: 2.0503680244568856

Epoch: 6| Step: 5
Training loss: 2.165534019470215
Validation loss: 2.046951993819206

Epoch: 6| Step: 6
Training loss: 1.3881051540374756
Validation loss: 2.0174767445492487

Epoch: 6| Step: 7
Training loss: 2.311964511871338
Validation loss: 2.006077430581534

Epoch: 6| Step: 8
Training loss: 2.177696466445923
Validation loss: 2.038594866311678

Epoch: 6| Step: 9
Training loss: 1.9225468635559082
Validation loss: 2.0431901690780476

Epoch: 6| Step: 10
Training loss: 1.7720690965652466
Validation loss: 2.028057059934062

Epoch: 6| Step: 11
Training loss: 2.4324159622192383
Validation loss: 2.037783661196309

Epoch: 6| Step: 12
Training loss: 1.3318531513214111
Validation loss: 2.0154959822213776

Epoch: 6| Step: 13
Training loss: 2.589195966720581
Validation loss: 2.043556212097086

Epoch: 116| Step: 0
Training loss: 2.4294307231903076
Validation loss: 2.0447318771834015

Epoch: 6| Step: 1
Training loss: 1.9564651250839233
Validation loss: 2.0100796120141142

Epoch: 6| Step: 2
Training loss: 1.9340687990188599
Validation loss: 2.0281372941950315

Epoch: 6| Step: 3
Training loss: 2.013484001159668
Validation loss: 2.0338798671640377

Epoch: 6| Step: 4
Training loss: 2.302722454071045
Validation loss: 2.0518604247800765

Epoch: 6| Step: 5
Training loss: 1.43894624710083
Validation loss: 2.0224288009828135

Epoch: 6| Step: 6
Training loss: 2.766123056411743
Validation loss: 2.052290112741532

Epoch: 6| Step: 7
Training loss: 1.4779759645462036
Validation loss: 2.0020583022025322

Epoch: 6| Step: 8
Training loss: 1.870389461517334
Validation loss: 2.0763001083045878

Epoch: 6| Step: 9
Training loss: 1.7006067037582397
Validation loss: 2.060685811504241

Epoch: 6| Step: 10
Training loss: 1.5360405445098877
Validation loss: 2.038499436070842

Epoch: 6| Step: 11
Training loss: 2.476532459259033
Validation loss: 2.065575643252301

Epoch: 6| Step: 12
Training loss: 1.9238510131835938
Validation loss: 2.051364967899938

Epoch: 6| Step: 13
Training loss: 2.755807399749756
Validation loss: 2.0427107452064432

Epoch: 117| Step: 0
Training loss: 2.190753221511841
Validation loss: 1.9972713198713077

Epoch: 6| Step: 1
Training loss: 2.50461483001709
Validation loss: 2.039822188756799

Epoch: 6| Step: 2
Training loss: 1.9912583827972412
Validation loss: 2.0343220067280594

Epoch: 6| Step: 3
Training loss: 1.963299036026001
Validation loss: 2.0230523514491257

Epoch: 6| Step: 4
Training loss: 2.220625400543213
Validation loss: 2.0254481274594545

Epoch: 6| Step: 5
Training loss: 1.6937509775161743
Validation loss: 2.0632867979746994

Epoch: 6| Step: 6
Training loss: 1.5235424041748047
Validation loss: 2.048705936760031

Epoch: 6| Step: 7
Training loss: 2.6008377075195312
Validation loss: 2.022913322653822

Epoch: 6| Step: 8
Training loss: 2.0738799571990967
Validation loss: 2.010835878310665

Epoch: 6| Step: 9
Training loss: 1.3946467638015747
Validation loss: 2.0362967957732496

Epoch: 6| Step: 10
Training loss: 2.1288726329803467
Validation loss: 2.06009671508625

Epoch: 6| Step: 11
Training loss: 2.44126033782959
Validation loss: 2.047939231318812

Epoch: 6| Step: 12
Training loss: 1.4668076038360596
Validation loss: 2.0353041810374104

Epoch: 6| Step: 13
Training loss: 1.451837420463562
Validation loss: 2.052787793579922

Epoch: 118| Step: 0
Training loss: 1.4348058700561523
Validation loss: 2.023456928550556

Epoch: 6| Step: 1
Training loss: 2.148245334625244
Validation loss: 2.0382558453467583

Epoch: 6| Step: 2
Training loss: 1.925873875617981
Validation loss: 2.0148196258852558

Epoch: 6| Step: 3
Training loss: 2.5165348052978516
Validation loss: 2.0668712533930296

Epoch: 6| Step: 4
Training loss: 1.5738519430160522
Validation loss: 2.0372896937913794

Epoch: 6| Step: 5
Training loss: 1.6283676624298096
Validation loss: 2.04900848737327

Epoch: 6| Step: 6
Training loss: 1.8343137502670288
Validation loss: 2.027253209903676

Epoch: 6| Step: 7
Training loss: 2.0044426918029785
Validation loss: 2.0424505382455806

Epoch: 6| Step: 8
Training loss: 2.0654759407043457
Validation loss: 2.0422402992043445

Epoch: 6| Step: 9
Training loss: 2.6278958320617676
Validation loss: 2.044721841812134

Epoch: 6| Step: 10
Training loss: 1.6242499351501465
Validation loss: 2.0277182235512683

Epoch: 6| Step: 11
Training loss: 2.9557316303253174
Validation loss: 2.0421734715020783

Epoch: 6| Step: 12
Training loss: 2.082735776901245
Validation loss: 2.054292742924024

Epoch: 6| Step: 13
Training loss: 1.4184108972549438
Validation loss: 2.0077761552667104

Epoch: 119| Step: 0
Training loss: 1.7467297315597534
Validation loss: 2.0073307765427457

Epoch: 6| Step: 1
Training loss: 2.7206244468688965
Validation loss: 2.057757739097841

Epoch: 6| Step: 2
Training loss: 1.5026733875274658
Validation loss: 2.0344256380552888

Epoch: 6| Step: 3
Training loss: 1.9202020168304443
Validation loss: 2.0110774834950766

Epoch: 6| Step: 4
Training loss: 2.7411293983459473
Validation loss: 2.0333832822820193

Epoch: 6| Step: 5
Training loss: 1.526484727859497
Validation loss: 2.0290862834581764

Epoch: 6| Step: 6
Training loss: 2.321542978286743
Validation loss: 2.0234370270083026

Epoch: 6| Step: 7
Training loss: 2.4962148666381836
Validation loss: 2.024936729861844

Epoch: 6| Step: 8
Training loss: 1.97178053855896
Validation loss: 2.020801474971156

Epoch: 6| Step: 9
Training loss: 1.7377405166625977
Validation loss: 2.0416343442855345

Epoch: 6| Step: 10
Training loss: 1.724938154220581
Validation loss: 1.9994259213888517

Epoch: 6| Step: 11
Training loss: 1.6621558666229248
Validation loss: 2.0162495336224957

Epoch: 6| Step: 12
Training loss: 2.105410099029541
Validation loss: 2.037577470143636

Epoch: 6| Step: 13
Training loss: 1.7582416534423828
Validation loss: 1.9996407852377942

Epoch: 120| Step: 0
Training loss: 2.007171630859375
Validation loss: 2.0027482612158662

Epoch: 6| Step: 1
Training loss: 2.489529848098755
Validation loss: 2.0517383954858266

Epoch: 6| Step: 2
Training loss: 1.9847652912139893
Validation loss: 2.027414808991135

Epoch: 6| Step: 3
Training loss: 2.282460927963257
Validation loss: 2.002300995652394

Epoch: 6| Step: 4
Training loss: 1.6589632034301758
Validation loss: 2.024789689689554

Epoch: 6| Step: 5
Training loss: 1.823797583580017
Validation loss: 1.9845977893439672

Epoch: 6| Step: 6
Training loss: 1.6613388061523438
Validation loss: 2.0255315995985463

Epoch: 6| Step: 7
Training loss: 2.281623363494873
Validation loss: 2.0396462281545005

Epoch: 6| Step: 8
Training loss: 1.9823942184448242
Validation loss: 2.012031611575875

Epoch: 6| Step: 9
Training loss: 1.9234726428985596
Validation loss: 1.9982597058819187

Epoch: 6| Step: 10
Training loss: 1.858964443206787
Validation loss: 2.0329956880179783

Epoch: 6| Step: 11
Training loss: 2.0432825088500977
Validation loss: 2.027776020829396

Epoch: 6| Step: 12
Training loss: 1.6673377752304077
Validation loss: 2.028444059433476

Epoch: 6| Step: 13
Training loss: 2.482593297958374
Validation loss: 2.025076021430313

Epoch: 121| Step: 0
Training loss: 2.313164710998535
Validation loss: 2.040023091018841

Epoch: 6| Step: 1
Training loss: 2.1764116287231445
Validation loss: 2.015680618183587

Epoch: 6| Step: 2
Training loss: 1.741774559020996
Validation loss: 2.0304062597213255

Epoch: 6| Step: 3
Training loss: 1.8862353563308716
Validation loss: 2.0334718227386475

Epoch: 6| Step: 4
Training loss: 1.889175295829773
Validation loss: 2.0496476068291614

Epoch: 6| Step: 5
Training loss: 2.25009822845459
Validation loss: 2.0268164142485587

Epoch: 6| Step: 6
Training loss: 2.0739293098449707
Validation loss: 1.9866612034459268

Epoch: 6| Step: 7
Training loss: 2.33262300491333
Validation loss: 2.0573604952904487

Epoch: 6| Step: 8
Training loss: 1.7491201162338257
Validation loss: 2.0505509555980725

Epoch: 6| Step: 9
Training loss: 2.484241008758545
Validation loss: 2.022970099602976

Epoch: 6| Step: 10
Training loss: 1.6889307498931885
Validation loss: 2.0275776975898334

Epoch: 6| Step: 11
Training loss: 1.9218008518218994
Validation loss: 2.00660297178453

Epoch: 6| Step: 12
Training loss: 1.3819396495819092
Validation loss: 1.9995036753275062

Epoch: 6| Step: 13
Training loss: 2.1207339763641357
Validation loss: 2.072028729223436

Epoch: 122| Step: 0
Training loss: 1.6798820495605469
Validation loss: 2.0564703736253964

Epoch: 6| Step: 1
Training loss: 2.649019956588745
Validation loss: 2.0075277307982087

Epoch: 6| Step: 2
Training loss: 1.6485025882720947
Validation loss: 2.0414160913036716

Epoch: 6| Step: 3
Training loss: 2.1739444732666016
Validation loss: 2.0407351960418043

Epoch: 6| Step: 4
Training loss: 2.378371238708496
Validation loss: 2.0395865517277874

Epoch: 6| Step: 5
Training loss: 2.1938059329986572
Validation loss: 2.022067073852785

Epoch: 6| Step: 6
Training loss: 2.093370199203491
Validation loss: 2.037875542076685

Epoch: 6| Step: 7
Training loss: 1.961546778678894
Validation loss: 2.015102396729172

Epoch: 6| Step: 8
Training loss: 1.5556659698486328
Validation loss: 1.9907543992483487

Epoch: 6| Step: 9
Training loss: 2.1068880558013916
Validation loss: 2.0298004509300314

Epoch: 6| Step: 10
Training loss: 1.64601731300354
Validation loss: 2.0469052483958583

Epoch: 6| Step: 11
Training loss: 1.7481765747070312
Validation loss: 2.0529556402596096

Epoch: 6| Step: 12
Training loss: 2.623703956604004
Validation loss: 2.0030664961825133

Epoch: 6| Step: 13
Training loss: 0.876239538192749
Validation loss: 2.035957485116938

Epoch: 123| Step: 0
Training loss: 2.663468837738037
Validation loss: 2.0205752593214794

Epoch: 6| Step: 1
Training loss: 1.519172191619873
Validation loss: 2.043355098334692

Epoch: 6| Step: 2
Training loss: 1.6408613920211792
Validation loss: 2.030897835249542

Epoch: 6| Step: 3
Training loss: 2.15863037109375
Validation loss: 2.0142776837912937

Epoch: 6| Step: 4
Training loss: 1.545102834701538
Validation loss: 2.0127539698795607

Epoch: 6| Step: 5
Training loss: 1.857515573501587
Validation loss: 2.0373384952545166

Epoch: 6| Step: 6
Training loss: 2.6960861682891846
Validation loss: 2.040002264002318

Epoch: 6| Step: 7
Training loss: 2.586005210876465
Validation loss: 2.0245732517652613

Epoch: 6| Step: 8
Training loss: 1.8215023279190063
Validation loss: 2.028783280362365

Epoch: 6| Step: 9
Training loss: 1.6207489967346191
Validation loss: 1.9988701087172314

Epoch: 6| Step: 10
Training loss: 1.9715235233306885
Validation loss: 2.0538973372469664

Epoch: 6| Step: 11
Training loss: 1.668531894683838
Validation loss: 2.0242628910208262

Epoch: 6| Step: 12
Training loss: 1.741254448890686
Validation loss: 2.0430008903626473

Epoch: 6| Step: 13
Training loss: 2.2467637062072754
Validation loss: 2.0237140450426327

Epoch: 124| Step: 0
Training loss: 1.3823249340057373
Validation loss: 2.0783296041591193

Epoch: 6| Step: 1
Training loss: 1.9317536354064941
Validation loss: 2.008056899552704

Epoch: 6| Step: 2
Training loss: 2.4384708404541016
Validation loss: 2.0300720045643468

Epoch: 6| Step: 3
Training loss: 2.176828384399414
Validation loss: 2.031569762896466

Epoch: 6| Step: 4
Training loss: 1.7747840881347656
Validation loss: 2.0263341011539584

Epoch: 6| Step: 5
Training loss: 1.3729352951049805
Validation loss: 2.0764687292037474

Epoch: 6| Step: 6
Training loss: 2.446747303009033
Validation loss: 2.0036670366923013

Epoch: 6| Step: 7
Training loss: 1.6649092435836792
Validation loss: 2.0255314355255454

Epoch: 6| Step: 8
Training loss: 1.5508002042770386
Validation loss: 1.9928609786495086

Epoch: 6| Step: 9
Training loss: 1.5767738819122314
Validation loss: 2.0536545156150736

Epoch: 6| Step: 10
Training loss: 2.621699810028076
Validation loss: 1.9951707932256884

Epoch: 6| Step: 11
Training loss: 2.8047409057617188
Validation loss: 2.0242148727499027

Epoch: 6| Step: 12
Training loss: 2.051523208618164
Validation loss: 2.0486507646499144

Epoch: 6| Step: 13
Training loss: 1.637364387512207
Validation loss: 2.03720925956644

Epoch: 125| Step: 0
Training loss: 1.3760137557983398
Validation loss: 2.024946739596705

Epoch: 6| Step: 1
Training loss: 2.4692368507385254
Validation loss: 2.0297451173105547

Epoch: 6| Step: 2
Training loss: 1.9166127443313599
Validation loss: 2.001355935168523

Epoch: 6| Step: 3
Training loss: 2.2295594215393066
Validation loss: 2.041421272421396

Epoch: 6| Step: 4
Training loss: 1.9474544525146484
Validation loss: 2.0558572302582445

Epoch: 6| Step: 5
Training loss: 2.4988315105438232
Validation loss: 2.0222563000135523

Epoch: 6| Step: 6
Training loss: 1.645654559135437
Validation loss: 2.0630425048130814

Epoch: 6| Step: 7
Training loss: 1.4753694534301758
Validation loss: 2.0514854026097122

Epoch: 6| Step: 8
Training loss: 1.986829161643982
Validation loss: 2.012092121185795

Epoch: 6| Step: 9
Training loss: 1.940018653869629
Validation loss: 2.042634869134554

Epoch: 6| Step: 10
Training loss: 1.5399807691574097
Validation loss: 2.025287748664938

Epoch: 6| Step: 11
Training loss: 2.186173439025879
Validation loss: 2.0077339756873345

Epoch: 6| Step: 12
Training loss: 2.6534018516540527
Validation loss: 2.0163404569830945

Epoch: 6| Step: 13
Training loss: 1.9738962650299072
Validation loss: 2.004244542890979

Epoch: 126| Step: 0
Training loss: 2.1557228565216064
Validation loss: 2.0151482756419847

Epoch: 6| Step: 1
Training loss: 1.7753952741622925
Validation loss: 2.0454093358849965

Epoch: 6| Step: 2
Training loss: 2.060608386993408
Validation loss: 1.99628060735682

Epoch: 6| Step: 3
Training loss: 2.2692489624023438
Validation loss: 2.020638709427208

Epoch: 6| Step: 4
Training loss: 2.403383493423462
Validation loss: 2.0087853657302035

Epoch: 6| Step: 5
Training loss: 1.374656081199646
Validation loss: 2.0434971958078365

Epoch: 6| Step: 6
Training loss: 1.5124480724334717
Validation loss: 2.0117385002874557

Epoch: 6| Step: 7
Training loss: 1.7652405500411987
Validation loss: 2.029709977488364

Epoch: 6| Step: 8
Training loss: 2.420596122741699
Validation loss: 2.0223874904776133

Epoch: 6| Step: 9
Training loss: 2.300018548965454
Validation loss: 2.029583773305339

Epoch: 6| Step: 10
Training loss: 2.4820473194122314
Validation loss: 2.0662549605933567

Epoch: 6| Step: 11
Training loss: 1.940612554550171
Validation loss: 2.022620634366107

Epoch: 6| Step: 12
Training loss: 1.5184624195098877
Validation loss: 2.0171149738373293

Epoch: 6| Step: 13
Training loss: 1.7777037620544434
Validation loss: 2.061269701168101

Epoch: 127| Step: 0
Training loss: 2.5359601974487305
Validation loss: 2.036842594864548

Epoch: 6| Step: 1
Training loss: 2.0172667503356934
Validation loss: 1.9868684789185882

Epoch: 6| Step: 2
Training loss: 2.5207595825195312
Validation loss: 2.0078360073028074

Epoch: 6| Step: 3
Training loss: 2.309077501296997
Validation loss: 2.0129300625093522

Epoch: 6| Step: 4
Training loss: 1.3432185649871826
Validation loss: 1.9691154174907233

Epoch: 6| Step: 5
Training loss: 2.2216267585754395
Validation loss: 2.0004338551593084

Epoch: 6| Step: 6
Training loss: 2.4944698810577393
Validation loss: 2.04255796247913

Epoch: 6| Step: 7
Training loss: 1.456112265586853
Validation loss: 2.014982432447454

Epoch: 6| Step: 8
Training loss: 1.4598904848098755
Validation loss: 2.003653203287432

Epoch: 6| Step: 9
Training loss: 2.3429338932037354
Validation loss: 2.0125266967281217

Epoch: 6| Step: 10
Training loss: 1.4777765274047852
Validation loss: 2.015173041692344

Epoch: 6| Step: 11
Training loss: 1.8238489627838135
Validation loss: 2.0321627534845823

Epoch: 6| Step: 12
Training loss: 1.5671964883804321
Validation loss: 2.019308344010384

Epoch: 6| Step: 13
Training loss: 2.1590359210968018
Validation loss: 2.0208397167985157

Epoch: 128| Step: 0
Training loss: 1.9654269218444824
Validation loss: 2.0232057250956053

Epoch: 6| Step: 1
Training loss: 1.8872655630111694
Validation loss: 1.961321089857368

Epoch: 6| Step: 2
Training loss: 1.9580659866333008
Validation loss: 1.994860477344964

Epoch: 6| Step: 3
Training loss: 1.7213857173919678
Validation loss: 2.0038940855251846

Epoch: 6| Step: 4
Training loss: 1.8036377429962158
Validation loss: 2.0365285988776916

Epoch: 6| Step: 5
Training loss: 2.3246307373046875
Validation loss: 2.037433705022258

Epoch: 6| Step: 6
Training loss: 2.3644046783447266
Validation loss: 2.002066699407434

Epoch: 6| Step: 7
Training loss: 1.8522186279296875
Validation loss: 2.006610603742702

Epoch: 6| Step: 8
Training loss: 2.0793237686157227
Validation loss: 2.077051306283602

Epoch: 6| Step: 9
Training loss: 2.0037970542907715
Validation loss: 2.030564702967162

Epoch: 6| Step: 10
Training loss: 2.1117191314697266
Validation loss: 2.0540935275375203

Epoch: 6| Step: 11
Training loss: 1.9459964036941528
Validation loss: 2.024797352411414

Epoch: 6| Step: 12
Training loss: 1.8580178022384644
Validation loss: 2.051198495331631

Epoch: 6| Step: 13
Training loss: 1.230360984802246
Validation loss: 2.0555599120355423

Epoch: 129| Step: 0
Training loss: 2.152616024017334
Validation loss: 2.006941021129649

Epoch: 6| Step: 1
Training loss: 1.5431034564971924
Validation loss: 2.009553281209802

Epoch: 6| Step: 2
Training loss: 1.779412031173706
Validation loss: 2.004680279762514

Epoch: 6| Step: 3
Training loss: 1.864365577697754
Validation loss: 2.040185561744116

Epoch: 6| Step: 4
Training loss: 1.5246994495391846
Validation loss: 2.007350342248076

Epoch: 6| Step: 5
Training loss: 2.472548246383667
Validation loss: 1.9965293279258154

Epoch: 6| Step: 6
Training loss: 1.6239469051361084
Validation loss: 1.9682168793934647

Epoch: 6| Step: 7
Training loss: 2.32326078414917
Validation loss: 1.9833085639502412

Epoch: 6| Step: 8
Training loss: 2.7850708961486816
Validation loss: 2.0415761573340303

Epoch: 6| Step: 9
Training loss: 1.8874821662902832
Validation loss: 1.991554976791464

Epoch: 6| Step: 10
Training loss: 2.4788849353790283
Validation loss: 2.030458322135351

Epoch: 6| Step: 11
Training loss: 2.0404882431030273
Validation loss: 1.9918078863492577

Epoch: 6| Step: 12
Training loss: 1.6626282930374146
Validation loss: 2.011181906987262

Epoch: 6| Step: 13
Training loss: 0.7410895228385925
Validation loss: 2.0083598142029135

Epoch: 130| Step: 0
Training loss: 2.051769256591797
Validation loss: 1.9719146861824939

Epoch: 6| Step: 1
Training loss: 1.385870337486267
Validation loss: 1.977173484781737

Epoch: 6| Step: 2
Training loss: 1.5461722612380981
Validation loss: 1.9735829971169914

Epoch: 6| Step: 3
Training loss: 1.8555548191070557
Validation loss: 2.0078821771888324

Epoch: 6| Step: 4
Training loss: 1.2333602905273438
Validation loss: 2.015917976697286

Epoch: 6| Step: 5
Training loss: 2.0204925537109375
Validation loss: 2.0457691249027046

Epoch: 6| Step: 6
Training loss: 2.002368450164795
Validation loss: 2.024441901073661

Epoch: 6| Step: 7
Training loss: 1.5643959045410156
Validation loss: 2.0154833973094983

Epoch: 6| Step: 8
Training loss: 2.0943174362182617
Validation loss: 2.020393911228385

Epoch: 6| Step: 9
Training loss: 2.0056915283203125
Validation loss: 2.034713060625138

Epoch: 6| Step: 10
Training loss: 2.0922107696533203
Validation loss: 1.985532203028279

Epoch: 6| Step: 11
Training loss: 2.499215602874756
Validation loss: 2.0164731087223178

Epoch: 6| Step: 12
Training loss: 2.9700632095336914
Validation loss: 2.007288322653822

Epoch: 6| Step: 13
Training loss: 2.2608444690704346
Validation loss: 1.9990901870112265

Epoch: 131| Step: 0
Training loss: 1.8434160947799683
Validation loss: 2.0416163911101637

Epoch: 6| Step: 1
Training loss: 1.4675776958465576
Validation loss: 2.046588187576622

Epoch: 6| Step: 2
Training loss: 1.8093407154083252
Validation loss: 1.9960688185948197

Epoch: 6| Step: 3
Training loss: 2.4151906967163086
Validation loss: 2.013146312006058

Epoch: 6| Step: 4
Training loss: 3.021711587905884
Validation loss: 1.9755639991452616

Epoch: 6| Step: 5
Training loss: 1.843230962753296
Validation loss: 2.00313425320451

Epoch: 6| Step: 6
Training loss: 1.5267224311828613
Validation loss: 1.9695655210043794

Epoch: 6| Step: 7
Training loss: 1.1400583982467651
Validation loss: 2.0164488989819764

Epoch: 6| Step: 8
Training loss: 2.660691738128662
Validation loss: 1.9966438175529562

Epoch: 6| Step: 9
Training loss: 2.143733263015747
Validation loss: 2.0569428423399567

Epoch: 6| Step: 10
Training loss: 1.362955093383789
Validation loss: 1.9900912366887575

Epoch: 6| Step: 11
Training loss: 2.0939278602600098
Validation loss: 2.0420099458386822

Epoch: 6| Step: 12
Training loss: 1.8148326873779297
Validation loss: 2.00329089677462

Epoch: 6| Step: 13
Training loss: 2.330827236175537
Validation loss: 2.0180257699822866

Epoch: 132| Step: 0
Training loss: 2.460606098175049
Validation loss: 2.0213698956274215

Epoch: 6| Step: 1
Training loss: 1.5903319120407104
Validation loss: 2.013870698149486

Epoch: 6| Step: 2
Training loss: 2.18098783493042
Validation loss: 1.9846320357373965

Epoch: 6| Step: 3
Training loss: 1.811282992362976
Validation loss: 1.9845579619048743

Epoch: 6| Step: 4
Training loss: 1.3317029476165771
Validation loss: 1.9991031692874046

Epoch: 6| Step: 5
Training loss: 2.1383233070373535
Validation loss: 2.011405981997008

Epoch: 6| Step: 6
Training loss: 2.2943623065948486
Validation loss: 2.0065174948784614

Epoch: 6| Step: 7
Training loss: 1.7454845905303955
Validation loss: 1.9812803934979182

Epoch: 6| Step: 8
Training loss: 1.9897440671920776
Validation loss: 1.9822403705248268

Epoch: 6| Step: 9
Training loss: 1.5480331182479858
Validation loss: 1.9751485701530211

Epoch: 6| Step: 10
Training loss: 2.124387502670288
Validation loss: 2.024576853680354

Epoch: 6| Step: 11
Training loss: 2.0306379795074463
Validation loss: 2.0309021498567317

Epoch: 6| Step: 12
Training loss: 2.1312801837921143
Validation loss: 2.0132322426765197

Epoch: 6| Step: 13
Training loss: 1.748186707496643
Validation loss: 2.0244562805339856

Epoch: 133| Step: 0
Training loss: 2.7219653129577637
Validation loss: 2.0034929039657756

Epoch: 6| Step: 1
Training loss: 1.8382655382156372
Validation loss: 2.0132091468380344

Epoch: 6| Step: 2
Training loss: 1.8071863651275635
Validation loss: 2.0405061642328897

Epoch: 6| Step: 3
Training loss: 1.159653663635254
Validation loss: 2.0075045913778324

Epoch: 6| Step: 4
Training loss: 2.194234848022461
Validation loss: 2.0299085109464583

Epoch: 6| Step: 5
Training loss: 1.9459779262542725
Validation loss: 1.9901673524610457

Epoch: 6| Step: 6
Training loss: 2.2099227905273438
Validation loss: 2.0074906541455175

Epoch: 6| Step: 7
Training loss: 1.5000057220458984
Validation loss: 2.0151838064193726

Epoch: 6| Step: 8
Training loss: 2.433750867843628
Validation loss: 1.9750673219721804

Epoch: 6| Step: 9
Training loss: 2.276837110519409
Validation loss: 1.9951814118252005

Epoch: 6| Step: 10
Training loss: 1.7606362104415894
Validation loss: 2.0455262635343816

Epoch: 6| Step: 11
Training loss: 1.6693388223648071
Validation loss: 1.9865429247579267

Epoch: 6| Step: 12
Training loss: 1.619357705116272
Validation loss: 2.025502989369054

Epoch: 6| Step: 13
Training loss: 2.1312458515167236
Validation loss: 2.03444742643705

Epoch: 134| Step: 0
Training loss: 1.6470246315002441
Validation loss: 1.9880160567581013

Epoch: 6| Step: 1
Training loss: 2.107146978378296
Validation loss: 2.048677188093944

Epoch: 6| Step: 2
Training loss: 1.9211583137512207
Validation loss: 2.023860057195028

Epoch: 6| Step: 3
Training loss: 1.7725505828857422
Validation loss: 1.999742046479256

Epoch: 6| Step: 4
Training loss: 1.7298781871795654
Validation loss: 2.008626578956522

Epoch: 6| Step: 5
Training loss: 1.8010225296020508
Validation loss: 2.009446495322771

Epoch: 6| Step: 6
Training loss: 1.8303086757659912
Validation loss: 1.9924945369843514

Epoch: 6| Step: 7
Training loss: 2.1023483276367188
Validation loss: 2.059011241441132

Epoch: 6| Step: 8
Training loss: 1.5867440700531006
Validation loss: 2.0551218589146933

Epoch: 6| Step: 9
Training loss: 2.348109006881714
Validation loss: 2.010107783861058

Epoch: 6| Step: 10
Training loss: 2.1613454818725586
Validation loss: 1.9811507040454495

Epoch: 6| Step: 11
Training loss: 1.8701049089431763
Validation loss: 2.007724077470841

Epoch: 6| Step: 12
Training loss: 2.2944438457489014
Validation loss: 2.019705372471963

Epoch: 6| Step: 13
Training loss: 2.2604005336761475
Validation loss: 2.025392167029842

Epoch: 135| Step: 0
Training loss: 2.306309700012207
Validation loss: 2.008180142730795

Epoch: 6| Step: 1
Training loss: 1.9473563432693481
Validation loss: 1.9815859781798495

Epoch: 6| Step: 2
Training loss: 1.4741967916488647
Validation loss: 2.0133793520671066

Epoch: 6| Step: 3
Training loss: 1.387208342552185
Validation loss: 2.0295610991857385

Epoch: 6| Step: 4
Training loss: 1.307684063911438
Validation loss: 2.022507034322267

Epoch: 6| Step: 5
Training loss: 1.5845947265625
Validation loss: 1.9599882313000259

Epoch: 6| Step: 6
Training loss: 2.481020450592041
Validation loss: 2.0225715970480316

Epoch: 6| Step: 7
Training loss: 2.5810415744781494
Validation loss: 2.0008651774416686

Epoch: 6| Step: 8
Training loss: 2.8066530227661133
Validation loss: 1.9781523084127774

Epoch: 6| Step: 9
Training loss: 1.8535706996917725
Validation loss: 2.023188944785826

Epoch: 6| Step: 10
Training loss: 1.721961259841919
Validation loss: 1.9697891191769672

Epoch: 6| Step: 11
Training loss: 1.8915677070617676
Validation loss: 1.968727037470828

Epoch: 6| Step: 12
Training loss: 2.301206588745117
Validation loss: 1.9578135475035636

Epoch: 6| Step: 13
Training loss: 1.6987892389297485
Validation loss: 1.972442982017353

Epoch: 136| Step: 0
Training loss: 1.4250710010528564
Validation loss: 1.9840991343221357

Epoch: 6| Step: 1
Training loss: 1.643784999847412
Validation loss: 1.9949619590595205

Epoch: 6| Step: 2
Training loss: 2.0232391357421875
Validation loss: 1.9944294524449173

Epoch: 6| Step: 3
Training loss: 2.894381284713745
Validation loss: 2.024769308746502

Epoch: 6| Step: 4
Training loss: 1.2009880542755127
Validation loss: 2.0283338741589616

Epoch: 6| Step: 5
Training loss: 1.7941564321517944
Validation loss: 1.976754915329718

Epoch: 6| Step: 6
Training loss: 1.837978482246399
Validation loss: 2.0495678917054208

Epoch: 6| Step: 7
Training loss: 1.4410946369171143
Validation loss: 2.0448746347940094

Epoch: 6| Step: 8
Training loss: 1.8205138444900513
Validation loss: 2.034212689245901

Epoch: 6| Step: 9
Training loss: 2.811901569366455
Validation loss: 2.0051948742199968

Epoch: 6| Step: 10
Training loss: 1.6208815574645996
Validation loss: 2.011061324868151

Epoch: 6| Step: 11
Training loss: 1.7641451358795166
Validation loss: 1.9694736106421358

Epoch: 6| Step: 12
Training loss: 2.3405776023864746
Validation loss: 2.013841975119806

Epoch: 6| Step: 13
Training loss: 2.1627817153930664
Validation loss: 1.9954840303749166

Epoch: 137| Step: 0
Training loss: 1.9984089136123657
Validation loss: 2.015229627650271

Epoch: 6| Step: 1
Training loss: 2.0731282234191895
Validation loss: 2.018813815168155

Epoch: 6| Step: 2
Training loss: 1.8748713731765747
Validation loss: 1.9998336363864202

Epoch: 6| Step: 3
Training loss: 1.4148443937301636
Validation loss: 2.0100929775545673

Epoch: 6| Step: 4
Training loss: 1.6232872009277344
Validation loss: 1.9835058258425804

Epoch: 6| Step: 5
Training loss: 1.7254881858825684
Validation loss: 2.0309943409376245

Epoch: 6| Step: 6
Training loss: 2.3235116004943848
Validation loss: 1.997648169917445

Epoch: 6| Step: 7
Training loss: 2.2419118881225586
Validation loss: 1.9417630780127741

Epoch: 6| Step: 8
Training loss: 2.505645275115967
Validation loss: 2.019496294759935

Epoch: 6| Step: 9
Training loss: 1.8082900047302246
Validation loss: 1.9761562424321328

Epoch: 6| Step: 10
Training loss: 1.9447423219680786
Validation loss: 1.982253159246137

Epoch: 6| Step: 11
Training loss: 1.6064229011535645
Validation loss: 2.0262575290536367

Epoch: 6| Step: 12
Training loss: 1.8350845575332642
Validation loss: 1.9606287684491885

Epoch: 6| Step: 13
Training loss: 2.177568197250366
Validation loss: 2.028120002438945

Epoch: 138| Step: 0
Training loss: 3.214390754699707
Validation loss: 1.9983952891442083

Epoch: 6| Step: 1
Training loss: 1.4868402481079102
Validation loss: 1.989246270989859

Epoch: 6| Step: 2
Training loss: 2.062260627746582
Validation loss: 1.9936379078895814

Epoch: 6| Step: 3
Training loss: 1.7507063150405884
Validation loss: 1.9712841510772705

Epoch: 6| Step: 4
Training loss: 1.8077759742736816
Validation loss: 2.0003691181059806

Epoch: 6| Step: 5
Training loss: 2.031309127807617
Validation loss: 1.9894100824991863

Epoch: 6| Step: 6
Training loss: 1.701717495918274
Validation loss: 2.02121994315937

Epoch: 6| Step: 7
Training loss: 1.996834397315979
Validation loss: 1.9876249477427492

Epoch: 6| Step: 8
Training loss: 2.295146942138672
Validation loss: 1.9631574499991633

Epoch: 6| Step: 9
Training loss: 1.6701469421386719
Validation loss: 2.0167875546281055

Epoch: 6| Step: 10
Training loss: 1.267995834350586
Validation loss: 2.0061288623399633

Epoch: 6| Step: 11
Training loss: 1.549322247505188
Validation loss: 2.0110491732115388

Epoch: 6| Step: 12
Training loss: 2.1443657875061035
Validation loss: 1.998025514746225

Epoch: 6| Step: 13
Training loss: 1.6756845712661743
Validation loss: 1.9653798816024617

Epoch: 139| Step: 0
Training loss: 2.1358790397644043
Validation loss: 1.9929048374135008

Epoch: 6| Step: 1
Training loss: 1.6900908946990967
Validation loss: 1.957971917685642

Epoch: 6| Step: 2
Training loss: 2.285421371459961
Validation loss: 1.9963131194473596

Epoch: 6| Step: 3
Training loss: 1.594834327697754
Validation loss: 1.9866048712884226

Epoch: 6| Step: 4
Training loss: 1.6927461624145508
Validation loss: 2.0207227635127243

Epoch: 6| Step: 5
Training loss: 1.7434275150299072
Validation loss: 1.9883405367533367

Epoch: 6| Step: 6
Training loss: 2.2635703086853027
Validation loss: 1.9660608614644697

Epoch: 6| Step: 7
Training loss: 1.9661962985992432
Validation loss: 2.0342522141753987

Epoch: 6| Step: 8
Training loss: 2.250412702560425
Validation loss: 2.0006826475102413

Epoch: 6| Step: 9
Training loss: 1.53789222240448
Validation loss: 1.9867018422772806

Epoch: 6| Step: 10
Training loss: 1.6339824199676514
Validation loss: 2.013154855338476

Epoch: 6| Step: 11
Training loss: 1.14762544631958
Validation loss: 2.0067328124917965

Epoch: 6| Step: 12
Training loss: 2.658280372619629
Validation loss: 1.9932385260058987

Epoch: 6| Step: 13
Training loss: 2.7439231872558594
Validation loss: 1.9961864345817155

Epoch: 140| Step: 0
Training loss: 1.8782622814178467
Validation loss: 2.006252642600767

Epoch: 6| Step: 1
Training loss: 1.856898546218872
Validation loss: 2.0062196216275616

Epoch: 6| Step: 2
Training loss: 1.6028549671173096
Validation loss: 2.003081924171858

Epoch: 6| Step: 3
Training loss: 2.3682830333709717
Validation loss: 1.989360427343717

Epoch: 6| Step: 4
Training loss: 2.467276096343994
Validation loss: 1.9985660442741968

Epoch: 6| Step: 5
Training loss: 1.7175712585449219
Validation loss: 1.9836237481845322

Epoch: 6| Step: 6
Training loss: 2.2931206226348877
Validation loss: 1.9773097730452014

Epoch: 6| Step: 7
Training loss: 2.050992012023926
Validation loss: 1.9910108556029618

Epoch: 6| Step: 8
Training loss: 2.183504343032837
Validation loss: 2.020869170465777

Epoch: 6| Step: 9
Training loss: 1.6515982151031494
Validation loss: 1.958420665033402

Epoch: 6| Step: 10
Training loss: 2.3923592567443848
Validation loss: 2.0004571958254744

Epoch: 6| Step: 11
Training loss: 1.6872243881225586
Validation loss: 1.9989023849528322

Epoch: 6| Step: 12
Training loss: 1.3641259670257568
Validation loss: 1.9548712545825588

Epoch: 6| Step: 13
Training loss: 1.32389497756958
Validation loss: 1.97382475227438

Epoch: 141| Step: 0
Training loss: 2.3154525756835938
Validation loss: 1.9681677715752715

Epoch: 6| Step: 1
Training loss: 1.3904050588607788
Validation loss: 1.9892500344143118

Epoch: 6| Step: 2
Training loss: 1.4776244163513184
Validation loss: 2.008270009871452

Epoch: 6| Step: 3
Training loss: 2.9143459796905518
Validation loss: 2.0176727643577

Epoch: 6| Step: 4
Training loss: 2.009798049926758
Validation loss: 1.9856203948297808

Epoch: 6| Step: 5
Training loss: 2.143934965133667
Validation loss: 1.977161956089799

Epoch: 6| Step: 6
Training loss: 2.2419559955596924
Validation loss: 1.9913922099656955

Epoch: 6| Step: 7
Training loss: 1.846656084060669
Validation loss: 1.9846741819894442

Epoch: 6| Step: 8
Training loss: 2.6291708946228027
Validation loss: 2.0049445526574248

Epoch: 6| Step: 9
Training loss: 2.240882635116577
Validation loss: 1.9920354056101974

Epoch: 6| Step: 10
Training loss: 0.9210419654846191
Validation loss: 1.9633518957322644

Epoch: 6| Step: 11
Training loss: 1.0731158256530762
Validation loss: 1.9860215597255255

Epoch: 6| Step: 12
Training loss: 1.6169791221618652
Validation loss: 1.9833210501619565

Epoch: 6| Step: 13
Training loss: 1.8880159854888916
Validation loss: 1.9910481335014425

Epoch: 142| Step: 0
Training loss: 2.3864457607269287
Validation loss: 1.9812600561367568

Epoch: 6| Step: 1
Training loss: 1.93691086769104
Validation loss: 1.998603077344997

Epoch: 6| Step: 2
Training loss: 2.089777946472168
Validation loss: 2.0248809194052093

Epoch: 6| Step: 3
Training loss: 1.3152964115142822
Validation loss: 2.0331635552067913

Epoch: 6| Step: 4
Training loss: 1.2915375232696533
Validation loss: 2.03139603266152

Epoch: 6| Step: 5
Training loss: 2.355375289916992
Validation loss: 2.0094147933426725

Epoch: 6| Step: 6
Training loss: 1.3372095823287964
Validation loss: 1.9846959139711113

Epoch: 6| Step: 7
Training loss: 2.116774559020996
Validation loss: 1.9872939753276047

Epoch: 6| Step: 8
Training loss: 2.3901138305664062
Validation loss: 1.985474064785947

Epoch: 6| Step: 9
Training loss: 1.7196857929229736
Validation loss: 1.9686718269061017

Epoch: 6| Step: 10
Training loss: 2.374154567718506
Validation loss: 1.9803408627868981

Epoch: 6| Step: 11
Training loss: 1.4173686504364014
Validation loss: 1.964213312313121

Epoch: 6| Step: 12
Training loss: 1.862410068511963
Validation loss: 1.9889323019212293

Epoch: 6| Step: 13
Training loss: 3.168531894683838
Validation loss: 1.991869439360916

Epoch: 143| Step: 0
Training loss: 1.9497432708740234
Validation loss: 2.0179884344018917

Epoch: 6| Step: 1
Training loss: 1.8441566228866577
Validation loss: 1.9729230788446241

Epoch: 6| Step: 2
Training loss: 1.9091434478759766
Validation loss: 1.9857607656909573

Epoch: 6| Step: 3
Training loss: 1.7268297672271729
Validation loss: 1.9747330040060065

Epoch: 6| Step: 4
Training loss: 2.034554958343506
Validation loss: 1.9624310129432267

Epoch: 6| Step: 5
Training loss: 2.612027645111084
Validation loss: 2.019861349495508

Epoch: 6| Step: 6
Training loss: 1.325939655303955
Validation loss: 1.963193162795036

Epoch: 6| Step: 7
Training loss: 1.268791913986206
Validation loss: 2.005243488537368

Epoch: 6| Step: 8
Training loss: 1.987297773361206
Validation loss: 1.973732530429799

Epoch: 6| Step: 9
Training loss: 2.1902050971984863
Validation loss: 1.9695504634611067

Epoch: 6| Step: 10
Training loss: 2.2830612659454346
Validation loss: 2.004320111325992

Epoch: 6| Step: 11
Training loss: 2.354933738708496
Validation loss: 2.0186021097244753

Epoch: 6| Step: 12
Training loss: 1.8090693950653076
Validation loss: 1.9872998755465272

Epoch: 6| Step: 13
Training loss: 1.2846213579177856
Validation loss: 1.9910836168514785

Epoch: 144| Step: 0
Training loss: 1.7762160301208496
Validation loss: 1.9621204471075406

Epoch: 6| Step: 1
Training loss: 2.4862053394317627
Validation loss: 1.9910220766580233

Epoch: 6| Step: 2
Training loss: 1.8610708713531494
Validation loss: 2.0011923774596183

Epoch: 6| Step: 3
Training loss: 2.2120580673217773
Validation loss: 1.9842303722135481

Epoch: 6| Step: 4
Training loss: 1.6420927047729492
Validation loss: 2.0356640892644084

Epoch: 6| Step: 5
Training loss: 2.2635135650634766
Validation loss: 1.9724001192277478

Epoch: 6| Step: 6
Training loss: 1.6089813709259033
Validation loss: 1.95265834177694

Epoch: 6| Step: 7
Training loss: 1.5601491928100586
Validation loss: 1.9476872753071528

Epoch: 6| Step: 8
Training loss: 2.5348968505859375
Validation loss: 2.008714642575992

Epoch: 6| Step: 9
Training loss: 1.734165072441101
Validation loss: 1.9826161169236707

Epoch: 6| Step: 10
Training loss: 1.3881862163543701
Validation loss: 2.01214611658486

Epoch: 6| Step: 11
Training loss: 1.651798129081726
Validation loss: 1.9756796385652275

Epoch: 6| Step: 12
Training loss: 2.17344331741333
Validation loss: 2.0046167809476136

Epoch: 6| Step: 13
Training loss: 1.7237372398376465
Validation loss: 1.9768396244254163

Epoch: 145| Step: 0
Training loss: 1.9559061527252197
Validation loss: 2.002520925255232

Epoch: 6| Step: 1
Training loss: 1.5068410634994507
Validation loss: 2.0061464309692383

Epoch: 6| Step: 2
Training loss: 1.485610008239746
Validation loss: 1.969149024255814

Epoch: 6| Step: 3
Training loss: 1.668035864830017
Validation loss: 1.9695675167986142

Epoch: 6| Step: 4
Training loss: 1.5883938074111938
Validation loss: 1.9952186948509627

Epoch: 6| Step: 5
Training loss: 2.2830429077148438
Validation loss: 1.9839032657684819

Epoch: 6| Step: 6
Training loss: 1.895371913909912
Validation loss: 1.9521880534387404

Epoch: 6| Step: 7
Training loss: 1.7064316272735596
Validation loss: 2.005512119621359

Epoch: 6| Step: 8
Training loss: 1.960630178451538
Validation loss: 1.9857871481167373

Epoch: 6| Step: 9
Training loss: 1.7811466455459595
Validation loss: 2.010465455311601

Epoch: 6| Step: 10
Training loss: 1.643476963043213
Validation loss: 1.9931005918851463

Epoch: 6| Step: 11
Training loss: 2.8687338829040527
Validation loss: 2.015494300473121

Epoch: 6| Step: 12
Training loss: 2.023129940032959
Validation loss: 1.9913509097150577

Epoch: 6| Step: 13
Training loss: 2.5119378566741943
Validation loss: 2.006746445932696

Epoch: 146| Step: 0
Training loss: 1.4886786937713623
Validation loss: 1.998992585366772

Epoch: 6| Step: 1
Training loss: 1.915635347366333
Validation loss: 1.9818882967836113

Epoch: 6| Step: 2
Training loss: 2.7832603454589844
Validation loss: 2.0004108054663545

Epoch: 6| Step: 3
Training loss: 2.098661422729492
Validation loss: 1.970183152024464

Epoch: 6| Step: 4
Training loss: 1.3420827388763428
Validation loss: 1.9711284573360155

Epoch: 6| Step: 5
Training loss: 2.0215959548950195
Validation loss: 1.9684143117679063

Epoch: 6| Step: 6
Training loss: 1.9205119609832764
Validation loss: 2.00759978448191

Epoch: 6| Step: 7
Training loss: 2.3563313484191895
Validation loss: 2.0111408156733357

Epoch: 6| Step: 8
Training loss: 1.8221487998962402
Validation loss: 1.9539763991550734

Epoch: 6| Step: 9
Training loss: 1.3674050569534302
Validation loss: 1.9686516151633313

Epoch: 6| Step: 10
Training loss: 1.775951862335205
Validation loss: 1.9669412951315604

Epoch: 6| Step: 11
Training loss: 1.4131697416305542
Validation loss: 2.0023962605384087

Epoch: 6| Step: 12
Training loss: 2.0027594566345215
Validation loss: 1.9937546381386377

Epoch: 6| Step: 13
Training loss: 2.7365200519561768
Validation loss: 1.9687842835662186

Epoch: 147| Step: 0
Training loss: 2.0358963012695312
Validation loss: 1.9557266696806876

Epoch: 6| Step: 1
Training loss: 2.2179222106933594
Validation loss: 1.9677153223304338

Epoch: 6| Step: 2
Training loss: 1.6549875736236572
Validation loss: 2.0193034525840514

Epoch: 6| Step: 3
Training loss: 1.539419412612915
Validation loss: 2.010193245385283

Epoch: 6| Step: 4
Training loss: 2.2349019050598145
Validation loss: 1.9868468930644374

Epoch: 6| Step: 5
Training loss: 1.761781096458435
Validation loss: 1.9710994433331233

Epoch: 6| Step: 6
Training loss: 1.7971149682998657
Validation loss: 1.9699742153126707

Epoch: 6| Step: 7
Training loss: 2.0883677005767822
Validation loss: 1.9719815331120645

Epoch: 6| Step: 8
Training loss: 2.3514788150787354
Validation loss: 1.9843247103434738

Epoch: 6| Step: 9
Training loss: 1.5073425769805908
Validation loss: 1.9617158392424225

Epoch: 6| Step: 10
Training loss: 1.897384762763977
Validation loss: 1.9628834339880175

Epoch: 6| Step: 11
Training loss: 2.449735164642334
Validation loss: 2.0094984359638666

Epoch: 6| Step: 12
Training loss: 1.6592226028442383
Validation loss: 1.9880690369554745

Epoch: 6| Step: 13
Training loss: 0.9600571393966675
Validation loss: 1.9652173211497646

Epoch: 148| Step: 0
Training loss: 1.9140758514404297
Validation loss: 1.9800205384531329

Epoch: 6| Step: 1
Training loss: 1.852225661277771
Validation loss: 1.9747555332799112

Epoch: 6| Step: 2
Training loss: 1.4359619617462158
Validation loss: 1.9992049099296652

Epoch: 6| Step: 3
Training loss: 2.236903190612793
Validation loss: 1.961122012907459

Epoch: 6| Step: 4
Training loss: 1.7737200260162354
Validation loss: 1.9634359139268116

Epoch: 6| Step: 5
Training loss: 1.959977149963379
Validation loss: 1.9917831279898202

Epoch: 6| Step: 6
Training loss: 1.724470615386963
Validation loss: 2.0160304115664576

Epoch: 6| Step: 7
Training loss: 2.4393997192382812
Validation loss: 1.9757656153812204

Epoch: 6| Step: 8
Training loss: 1.858292818069458
Validation loss: 2.0084613394993607

Epoch: 6| Step: 9
Training loss: 2.192344903945923
Validation loss: 1.9812365719067153

Epoch: 6| Step: 10
Training loss: 2.111668586730957
Validation loss: 1.9952624305602042

Epoch: 6| Step: 11
Training loss: 2.3723082542419434
Validation loss: 1.953233334325975

Epoch: 6| Step: 12
Training loss: 1.2621045112609863
Validation loss: 2.023842809020832

Epoch: 6| Step: 13
Training loss: 1.5622169971466064
Validation loss: 2.0185233444295902

Epoch: 149| Step: 0
Training loss: 2.6706478595733643
Validation loss: 1.983708058634112

Epoch: 6| Step: 1
Training loss: 1.349330186843872
Validation loss: 1.989951737465397

Epoch: 6| Step: 2
Training loss: 2.0069706439971924
Validation loss: 1.9895935507230862

Epoch: 6| Step: 3
Training loss: 1.0830957889556885
Validation loss: 1.9986762821033437

Epoch: 6| Step: 4
Training loss: 1.8360668420791626
Validation loss: 1.9790286479457733

Epoch: 6| Step: 5
Training loss: 2.4204347133636475
Validation loss: 1.9442007003291961

Epoch: 6| Step: 6
Training loss: 1.916365385055542
Validation loss: 1.973891322330762

Epoch: 6| Step: 7
Training loss: 2.1141021251678467
Validation loss: 1.969833166368546

Epoch: 6| Step: 8
Training loss: 2.417685031890869
Validation loss: 1.9687021791294057

Epoch: 6| Step: 9
Training loss: 1.4233523607254028
Validation loss: 1.9943763209927468

Epoch: 6| Step: 10
Training loss: 1.274444818496704
Validation loss: 1.9995608624591623

Epoch: 6| Step: 11
Training loss: 1.4127260446548462
Validation loss: 2.0042503918370893

Epoch: 6| Step: 12
Training loss: 2.691434621810913
Validation loss: 1.984552268059023

Epoch: 6| Step: 13
Training loss: 1.6196696758270264
Validation loss: 1.9814501552171604

Epoch: 150| Step: 0
Training loss: 1.8613786697387695
Validation loss: 2.00101133572158

Epoch: 6| Step: 1
Training loss: 2.526947021484375
Validation loss: 2.010085575042232

Epoch: 6| Step: 2
Training loss: 1.9399027824401855
Validation loss: 2.0066886076363186

Epoch: 6| Step: 3
Training loss: 1.1716773509979248
Validation loss: 1.992615403667573

Epoch: 6| Step: 4
Training loss: 2.0698022842407227
Validation loss: 1.9759794999194402

Epoch: 6| Step: 5
Training loss: 2.1269149780273438
Validation loss: 1.9937269764561807

Epoch: 6| Step: 6
Training loss: 1.646472692489624
Validation loss: 2.018155497889365

Epoch: 6| Step: 7
Training loss: 2.375547409057617
Validation loss: 1.9812717463380547

Epoch: 6| Step: 8
Training loss: 1.8261789083480835
Validation loss: 1.9913726493876467

Epoch: 6| Step: 9
Training loss: 1.8233885765075684
Validation loss: 1.9854879481818086

Epoch: 6| Step: 10
Training loss: 1.323073387145996
Validation loss: 1.98473358667025

Epoch: 6| Step: 11
Training loss: 1.7808117866516113
Validation loss: 1.9675540667708202

Epoch: 6| Step: 12
Training loss: 2.117672920227051
Validation loss: 1.9535058775255758

Epoch: 6| Step: 13
Training loss: 1.9321588277816772
Validation loss: 1.9497925440470378

Epoch: 151| Step: 0
Training loss: 2.6100211143493652
Validation loss: 1.9670672673051075

Epoch: 6| Step: 1
Training loss: 1.591338872909546
Validation loss: 1.9689115772965133

Epoch: 6| Step: 2
Training loss: 1.6746306419372559
Validation loss: 1.9246970402297152

Epoch: 6| Step: 3
Training loss: 1.9496649503707886
Validation loss: 1.954833326801177

Epoch: 6| Step: 4
Training loss: 2.310321807861328
Validation loss: 1.93299312104461

Epoch: 6| Step: 5
Training loss: 1.5026202201843262
Validation loss: 1.9317517434397051

Epoch: 6| Step: 6
Training loss: 2.4713284969329834
Validation loss: 1.9684182751563288

Epoch: 6| Step: 7
Training loss: 1.9602347612380981
Validation loss: 1.9630885457479825

Epoch: 6| Step: 8
Training loss: 1.6868325471878052
Validation loss: 1.9752904727894773

Epoch: 6| Step: 9
Training loss: 1.727190375328064
Validation loss: 1.9564257616637855

Epoch: 6| Step: 10
Training loss: 1.6847329139709473
Validation loss: 1.9844541447136992

Epoch: 6| Step: 11
Training loss: 1.887263298034668
Validation loss: 1.9834819378391388

Epoch: 6| Step: 12
Training loss: 1.573072910308838
Validation loss: 2.0196799462841404

Epoch: 6| Step: 13
Training loss: 1.6044126749038696
Validation loss: 1.9531373182932537

Epoch: 152| Step: 0
Training loss: 1.4086066484451294
Validation loss: 2.010220509703441

Epoch: 6| Step: 1
Training loss: 1.6556841135025024
Validation loss: 2.0040407078240507

Epoch: 6| Step: 2
Training loss: 2.3361189365386963
Validation loss: 1.9846071504777478

Epoch: 6| Step: 3
Training loss: 1.6706492900848389
Validation loss: 1.9874669454431022

Epoch: 6| Step: 4
Training loss: 2.0925822257995605
Validation loss: 2.03921401885248

Epoch: 6| Step: 5
Training loss: 2.266627311706543
Validation loss: 2.008782896944272

Epoch: 6| Step: 6
Training loss: 2.066993474960327
Validation loss: 1.9849298487427414

Epoch: 6| Step: 7
Training loss: 1.561838150024414
Validation loss: 2.0071874267311505

Epoch: 6| Step: 8
Training loss: 1.8096396923065186
Validation loss: 1.9544795379843762

Epoch: 6| Step: 9
Training loss: 2.2093162536621094
Validation loss: 2.0301875017022573

Epoch: 6| Step: 10
Training loss: 2.2156577110290527
Validation loss: 2.0364890534390687

Epoch: 6| Step: 11
Training loss: 1.9174680709838867
Validation loss: 1.9919298771888978

Epoch: 6| Step: 12
Training loss: 1.3815587759017944
Validation loss: 2.0052587268173054

Epoch: 6| Step: 13
Training loss: 1.7695804834365845
Validation loss: 2.0147326056675245

Epoch: 153| Step: 0
Training loss: 1.1216834783554077
Validation loss: 1.973374862824717

Epoch: 6| Step: 1
Training loss: 1.9687156677246094
Validation loss: 1.957695230360954

Epoch: 6| Step: 2
Training loss: 2.262284278869629
Validation loss: 1.9864206262814101

Epoch: 6| Step: 3
Training loss: 1.2016522884368896
Validation loss: 1.9622006326593378

Epoch: 6| Step: 4
Training loss: 1.8067189455032349
Validation loss: 1.9542277910376107

Epoch: 6| Step: 5
Training loss: 1.8593971729278564
Validation loss: 1.967206742173882

Epoch: 6| Step: 6
Training loss: 1.6698668003082275
Validation loss: 1.9423995838370374

Epoch: 6| Step: 7
Training loss: 1.906969428062439
Validation loss: 1.9518801294347292

Epoch: 6| Step: 8
Training loss: 2.8723602294921875
Validation loss: 1.9896625293198453

Epoch: 6| Step: 9
Training loss: 1.8361090421676636
Validation loss: 1.944424642029629

Epoch: 6| Step: 10
Training loss: 2.126676082611084
Validation loss: 1.9672435586170485

Epoch: 6| Step: 11
Training loss: 1.278507947921753
Validation loss: 1.98534958593307

Epoch: 6| Step: 12
Training loss: 2.904036521911621
Validation loss: 1.9819076971341205

Epoch: 6| Step: 13
Training loss: 1.8175188302993774
Validation loss: 1.9438049575333953

Epoch: 154| Step: 0
Training loss: 2.1505393981933594
Validation loss: 1.9331978341584564

Epoch: 6| Step: 1
Training loss: 1.828953742980957
Validation loss: 1.9955196021705546

Epoch: 6| Step: 2
Training loss: 1.747243881225586
Validation loss: 1.9965166097046227

Epoch: 6| Step: 3
Training loss: 2.052947521209717
Validation loss: 1.9670871239836498

Epoch: 6| Step: 4
Training loss: 2.302971839904785
Validation loss: 1.9759418874658563

Epoch: 6| Step: 5
Training loss: 1.5215328931808472
Validation loss: 1.9711121833452614

Epoch: 6| Step: 6
Training loss: 1.8885259628295898
Validation loss: 1.9642691740425684

Epoch: 6| Step: 7
Training loss: 1.8373923301696777
Validation loss: 1.9683087666829426

Epoch: 6| Step: 8
Training loss: 2.1306488513946533
Validation loss: 1.9573712925757132

Epoch: 6| Step: 9
Training loss: 1.776450276374817
Validation loss: 1.9703889303309943

Epoch: 6| Step: 10
Training loss: 1.6700260639190674
Validation loss: 1.9778319276789182

Epoch: 6| Step: 11
Training loss: 1.6526975631713867
Validation loss: 1.9941517973458895

Epoch: 6| Step: 12
Training loss: 1.8879010677337646
Validation loss: 1.9537066080236947

Epoch: 6| Step: 13
Training loss: 1.5582777261734009
Validation loss: 1.9295998132357033

Epoch: 155| Step: 0
Training loss: 2.3062705993652344
Validation loss: 1.9759811560312908

Epoch: 6| Step: 1
Training loss: 1.4060933589935303
Validation loss: 1.9935436671780002

Epoch: 6| Step: 2
Training loss: 1.4619159698486328
Validation loss: 2.0212442874908447

Epoch: 6| Step: 3
Training loss: 1.8291534185409546
Validation loss: 2.030603519050024

Epoch: 6| Step: 4
Training loss: 1.5785846710205078
Validation loss: 2.0275876265700146

Epoch: 6| Step: 5
Training loss: 1.9393157958984375
Validation loss: 1.9973060802746845

Epoch: 6| Step: 6
Training loss: 1.854045033454895
Validation loss: 2.0021915358881794

Epoch: 6| Step: 7
Training loss: 2.0525269508361816
Validation loss: 1.9606130417957102

Epoch: 6| Step: 8
Training loss: 1.4717068672180176
Validation loss: 1.9531665335419357

Epoch: 6| Step: 9
Training loss: 1.7942047119140625
Validation loss: 1.9879327563829319

Epoch: 6| Step: 10
Training loss: 1.7734404802322388
Validation loss: 1.9764134448061708

Epoch: 6| Step: 11
Training loss: 2.6520347595214844
Validation loss: 2.0602185495438112

Epoch: 6| Step: 12
Training loss: 1.999503254890442
Validation loss: 2.0051388407266266

Epoch: 6| Step: 13
Training loss: 2.640756845474243
Validation loss: 1.961310399475918

Epoch: 156| Step: 0
Training loss: 2.1484735012054443
Validation loss: 1.9794872627463391

Epoch: 6| Step: 1
Training loss: 1.4275264739990234
Validation loss: 1.9760933896546722

Epoch: 6| Step: 2
Training loss: 3.128264904022217
Validation loss: 1.9758405916152462

Epoch: 6| Step: 3
Training loss: 2.6795296669006348
Validation loss: 1.9635290945729902

Epoch: 6| Step: 4
Training loss: 1.8420203924179077
Validation loss: 1.997430041272153

Epoch: 6| Step: 5
Training loss: 1.9161417484283447
Validation loss: 1.917738773489511

Epoch: 6| Step: 6
Training loss: 1.3926172256469727
Validation loss: 1.9213938084981774

Epoch: 6| Step: 7
Training loss: 1.3537144660949707
Validation loss: 1.9791482981815134

Epoch: 6| Step: 8
Training loss: 1.3034261465072632
Validation loss: 1.9595786448447936

Epoch: 6| Step: 9
Training loss: 1.8240573406219482
Validation loss: 1.9797531609894128

Epoch: 6| Step: 10
Training loss: 2.008513927459717
Validation loss: 1.9841359276925363

Epoch: 6| Step: 11
Training loss: 1.7794151306152344
Validation loss: 1.9268720303812334

Epoch: 6| Step: 12
Training loss: 1.0102378129959106
Validation loss: 1.9242518589060793

Epoch: 6| Step: 13
Training loss: 2.5429935455322266
Validation loss: 1.9750569584549114

Epoch: 157| Step: 0
Training loss: 1.4311892986297607
Validation loss: 1.9265963441582137

Epoch: 6| Step: 1
Training loss: 1.781997799873352
Validation loss: 1.9791488186005624

Epoch: 6| Step: 2
Training loss: 1.1543151140213013
Validation loss: 1.9240877295053134

Epoch: 6| Step: 3
Training loss: 1.6602044105529785
Validation loss: 1.944333791732788

Epoch: 6| Step: 4
Training loss: 2.0609264373779297
Validation loss: 1.9569546843087802

Epoch: 6| Step: 5
Training loss: 1.6188161373138428
Validation loss: 1.9789381322040354

Epoch: 6| Step: 6
Training loss: 1.6242212057113647
Validation loss: 1.9753084695467384

Epoch: 6| Step: 7
Training loss: 1.4150464534759521
Validation loss: 1.9160480653086016

Epoch: 6| Step: 8
Training loss: 2.036158323287964
Validation loss: 1.9250985486533052

Epoch: 6| Step: 9
Training loss: 1.8577455282211304
Validation loss: 1.9665919350039573

Epoch: 6| Step: 10
Training loss: 3.4057490825653076
Validation loss: 1.9424830149578791

Epoch: 6| Step: 11
Training loss: 1.8206757307052612
Validation loss: 1.9737283337500788

Epoch: 6| Step: 12
Training loss: 1.8536460399627686
Validation loss: 1.9420499660635506

Epoch: 6| Step: 13
Training loss: 2.1250016689300537
Validation loss: 1.9659623522912302

Epoch: 158| Step: 0
Training loss: 2.631293773651123
Validation loss: 1.9486024251548193

Epoch: 6| Step: 1
Training loss: 2.4535155296325684
Validation loss: 2.0090799921302387

Epoch: 6| Step: 2
Training loss: 2.092933177947998
Validation loss: 1.9644857196397678

Epoch: 6| Step: 3
Training loss: 2.278134346008301
Validation loss: 1.9992616791878977

Epoch: 6| Step: 4
Training loss: 1.5860477685928345
Validation loss: 2.0047605217144056

Epoch: 6| Step: 5
Training loss: 1.5814268589019775
Validation loss: 2.0109981900902203

Epoch: 6| Step: 6
Training loss: 1.6418414115905762
Validation loss: 1.9889985489588913

Epoch: 6| Step: 7
Training loss: 2.0161328315734863
Validation loss: 1.981115960305737

Epoch: 6| Step: 8
Training loss: 1.917015790939331
Validation loss: 1.9755059134575628

Epoch: 6| Step: 9
Training loss: 0.9202667474746704
Validation loss: 1.988434660819269

Epoch: 6| Step: 10
Training loss: 1.6415257453918457
Validation loss: 1.967727614987281

Epoch: 6| Step: 11
Training loss: 1.557560682296753
Validation loss: 1.9370920158201648

Epoch: 6| Step: 12
Training loss: 2.0707931518554688
Validation loss: 1.9673617655231106

Epoch: 6| Step: 13
Training loss: 1.9109606742858887
Validation loss: 1.9851988028454524

Epoch: 159| Step: 0
Training loss: 0.9317388534545898
Validation loss: 1.9912330706914265

Epoch: 6| Step: 1
Training loss: 2.348361015319824
Validation loss: 2.0256461225530153

Epoch: 6| Step: 2
Training loss: 2.3976891040802
Validation loss: 1.9357539479450514

Epoch: 6| Step: 3
Training loss: 2.34625244140625
Validation loss: 1.963178357770366

Epoch: 6| Step: 4
Training loss: 1.3014671802520752
Validation loss: 1.9681552353725638

Epoch: 6| Step: 5
Training loss: 1.999157428741455
Validation loss: 1.9642379360814248

Epoch: 6| Step: 6
Training loss: 2.1337616443634033
Validation loss: 1.9589739486735354

Epoch: 6| Step: 7
Training loss: 1.9356913566589355
Validation loss: 1.9495729066992318

Epoch: 6| Step: 8
Training loss: 1.78076171875
Validation loss: 1.9900493237280077

Epoch: 6| Step: 9
Training loss: 2.1674039363861084
Validation loss: 1.9790407098749632

Epoch: 6| Step: 10
Training loss: 1.8219237327575684
Validation loss: 1.9298721192985453

Epoch: 6| Step: 11
Training loss: 1.0347027778625488
Validation loss: 1.9607509618164392

Epoch: 6| Step: 12
Training loss: 1.9384026527404785
Validation loss: 1.9506088200435843

Epoch: 6| Step: 13
Training loss: 1.8211767673492432
Validation loss: 1.970574127730503

Epoch: 160| Step: 0
Training loss: 2.2540674209594727
Validation loss: 1.9514789658208047

Epoch: 6| Step: 1
Training loss: 1.8212647438049316
Validation loss: 1.9794712925470004

Epoch: 6| Step: 2
Training loss: 2.1556971073150635
Validation loss: 1.9554857259155602

Epoch: 6| Step: 3
Training loss: 1.9396628141403198
Validation loss: 1.9697964960528958

Epoch: 6| Step: 4
Training loss: 1.2209416627883911
Validation loss: 1.9397586289272513

Epoch: 6| Step: 5
Training loss: 1.9453628063201904
Validation loss: 1.9554084680413688

Epoch: 6| Step: 6
Training loss: 2.026956081390381
Validation loss: 1.9609951934506815

Epoch: 6| Step: 7
Training loss: 1.740500807762146
Validation loss: 1.9231169454513057

Epoch: 6| Step: 8
Training loss: 2.473705768585205
Validation loss: 1.93369504456879

Epoch: 6| Step: 9
Training loss: 2.0381808280944824
Validation loss: 1.9376024097524664

Epoch: 6| Step: 10
Training loss: 1.556278109550476
Validation loss: 1.924772144645773

Epoch: 6| Step: 11
Training loss: 1.3971256017684937
Validation loss: 1.9718301552598194

Epoch: 6| Step: 12
Training loss: 1.8082969188690186
Validation loss: 1.9469799687785487

Epoch: 6| Step: 13
Training loss: 2.190626382827759
Validation loss: 1.9591697018633607

Epoch: 161| Step: 0
Training loss: 1.493800163269043
Validation loss: 1.9989129599704538

Epoch: 6| Step: 1
Training loss: 1.0940210819244385
Validation loss: 2.0024727083021596

Epoch: 6| Step: 2
Training loss: 2.4526333808898926
Validation loss: 1.978053705666655

Epoch: 6| Step: 3
Training loss: 1.8367091417312622
Validation loss: 1.9474121973078737

Epoch: 6| Step: 4
Training loss: 2.3908863067626953
Validation loss: 1.953632330381742

Epoch: 6| Step: 5
Training loss: 1.8349796533584595
Validation loss: 1.9875306980584257

Epoch: 6| Step: 6
Training loss: 1.8526020050048828
Validation loss: 1.9800837424493605

Epoch: 6| Step: 7
Training loss: 1.8690646886825562
Validation loss: 1.9833373382527342

Epoch: 6| Step: 8
Training loss: 2.019798755645752
Validation loss: 1.9878631984033892

Epoch: 6| Step: 9
Training loss: 2.87074613571167
Validation loss: 1.9898885296237083

Epoch: 6| Step: 10
Training loss: 1.2584788799285889
Validation loss: 2.0034775554492907

Epoch: 6| Step: 11
Training loss: 1.6506041288375854
Validation loss: 1.9693553627178233

Epoch: 6| Step: 12
Training loss: 1.4212052822113037
Validation loss: 1.9510526836559337

Epoch: 6| Step: 13
Training loss: 1.2730580568313599
Validation loss: 2.001379778308253

Epoch: 162| Step: 0
Training loss: 2.3142266273498535
Validation loss: 2.012933679806289

Epoch: 6| Step: 1
Training loss: 2.2379848957061768
Validation loss: 1.9788053792010072

Epoch: 6| Step: 2
Training loss: 1.473991870880127
Validation loss: 1.977762476090462

Epoch: 6| Step: 3
Training loss: 1.8189926147460938
Validation loss: 1.9534325151033298

Epoch: 6| Step: 4
Training loss: 2.0642526149749756
Validation loss: 1.95183805752826

Epoch: 6| Step: 5
Training loss: 1.7445554733276367
Validation loss: 1.9997510474215272

Epoch: 6| Step: 6
Training loss: 1.9842467308044434
Validation loss: 1.9502407504666237

Epoch: 6| Step: 7
Training loss: 1.7604188919067383
Validation loss: 1.9607289145069737

Epoch: 6| Step: 8
Training loss: 1.6037999391555786
Validation loss: 1.9518886086761311

Epoch: 6| Step: 9
Training loss: 1.6632781028747559
Validation loss: 1.9850247752281927

Epoch: 6| Step: 10
Training loss: 1.8286817073822021
Validation loss: 1.996217543079007

Epoch: 6| Step: 11
Training loss: 2.3980040550231934
Validation loss: 2.0307870013739473

Epoch: 6| Step: 12
Training loss: 1.631723403930664
Validation loss: 1.9504349987993959

Epoch: 6| Step: 13
Training loss: 1.367782473564148
Validation loss: 1.918127582919213

Epoch: 163| Step: 0
Training loss: 1.7801780700683594
Validation loss: 1.9628138516538887

Epoch: 6| Step: 1
Training loss: 1.7966246604919434
Validation loss: 1.9786314118293025

Epoch: 6| Step: 2
Training loss: 2.220134735107422
Validation loss: 1.9886307703551425

Epoch: 6| Step: 3
Training loss: 1.3325986862182617
Validation loss: 1.9601461912996025

Epoch: 6| Step: 4
Training loss: 1.9896684885025024
Validation loss: 1.959399987292546

Epoch: 6| Step: 5
Training loss: 1.767237901687622
Validation loss: 1.9746753336280904

Epoch: 6| Step: 6
Training loss: 1.2786091566085815
Validation loss: 1.975940614618281

Epoch: 6| Step: 7
Training loss: 1.7438478469848633
Validation loss: 1.9867203466353878

Epoch: 6| Step: 8
Training loss: 2.139347791671753
Validation loss: 1.9324724405042586

Epoch: 6| Step: 9
Training loss: 1.8833506107330322
Validation loss: 1.9643236898606824

Epoch: 6| Step: 10
Training loss: 2.0949766635894775
Validation loss: 2.010117934596154

Epoch: 6| Step: 11
Training loss: 2.349882125854492
Validation loss: 1.9561321107290124

Epoch: 6| Step: 12
Training loss: 1.6457982063293457
Validation loss: 1.9639292506761448

Epoch: 6| Step: 13
Training loss: 1.977112889289856
Validation loss: 2.022845552813622

Epoch: 164| Step: 0
Training loss: 1.992775797843933
Validation loss: 1.9644034472844933

Epoch: 6| Step: 1
Training loss: 1.7759846448898315
Validation loss: 1.9775793372943837

Epoch: 6| Step: 2
Training loss: 1.9180221557617188
Validation loss: 1.92670956478324

Epoch: 6| Step: 3
Training loss: 1.2779589891433716
Validation loss: 1.9511060894176524

Epoch: 6| Step: 4
Training loss: 1.9908664226531982
Validation loss: 1.952447578471194

Epoch: 6| Step: 5
Training loss: 1.698312759399414
Validation loss: 1.9738651373053109

Epoch: 6| Step: 6
Training loss: 2.2324366569519043
Validation loss: 1.9852618786596483

Epoch: 6| Step: 7
Training loss: 1.484761118888855
Validation loss: 1.9619163390128844

Epoch: 6| Step: 8
Training loss: 1.4717365503311157
Validation loss: 1.9719869116301179

Epoch: 6| Step: 9
Training loss: 1.9582059383392334
Validation loss: 1.9782664006756199

Epoch: 6| Step: 10
Training loss: 0.9614473581314087
Validation loss: 1.9263975389542118

Epoch: 6| Step: 11
Training loss: 2.8010244369506836
Validation loss: 1.968067281989641

Epoch: 6| Step: 12
Training loss: 1.6622394323349
Validation loss: 1.9346604603593067

Epoch: 6| Step: 13
Training loss: 2.8930728435516357
Validation loss: 1.9578500742553382

Epoch: 165| Step: 0
Training loss: 1.4688081741333008
Validation loss: 1.9604878835780646

Epoch: 6| Step: 1
Training loss: 1.9201087951660156
Validation loss: 1.9542462505320066

Epoch: 6| Step: 2
Training loss: 1.6254568099975586
Validation loss: 1.9438889923916067

Epoch: 6| Step: 3
Training loss: 2.23815655708313
Validation loss: 1.9703431411456036

Epoch: 6| Step: 4
Training loss: 1.6329238414764404
Validation loss: 1.9665937269887617

Epoch: 6| Step: 5
Training loss: 1.1536831855773926
Validation loss: 1.9618402168314943

Epoch: 6| Step: 6
Training loss: 2.246288299560547
Validation loss: 1.9745083034679454

Epoch: 6| Step: 7
Training loss: 2.7468276023864746
Validation loss: 1.9419268126128821

Epoch: 6| Step: 8
Training loss: 1.986933708190918
Validation loss: 1.9326392348094652

Epoch: 6| Step: 9
Training loss: 1.769527554512024
Validation loss: 1.9461032331630748

Epoch: 6| Step: 10
Training loss: 2.002899408340454
Validation loss: 1.9523556693907707

Epoch: 6| Step: 11
Training loss: 1.5532159805297852
Validation loss: 1.9223833173833869

Epoch: 6| Step: 12
Training loss: 1.639803171157837
Validation loss: 1.9827993633926555

Epoch: 6| Step: 13
Training loss: 1.4889408349990845
Validation loss: 1.9141177387647732

Epoch: 166| Step: 0
Training loss: 1.5618999004364014
Validation loss: 1.987054794065414

Epoch: 6| Step: 1
Training loss: 2.5173628330230713
Validation loss: 1.967097556719216

Epoch: 6| Step: 2
Training loss: 1.7412195205688477
Validation loss: 1.9801700833023235

Epoch: 6| Step: 3
Training loss: 1.6039539575576782
Validation loss: 1.941170295079549

Epoch: 6| Step: 4
Training loss: 2.3995120525360107
Validation loss: 1.9955630571611467

Epoch: 6| Step: 5
Training loss: 1.8558735847473145
Validation loss: 1.973451732307352

Epoch: 6| Step: 6
Training loss: 1.510196566581726
Validation loss: 1.942359705125132

Epoch: 6| Step: 7
Training loss: 1.3640835285186768
Validation loss: 1.9599963144589496

Epoch: 6| Step: 8
Training loss: 2.5987024307250977
Validation loss: 1.9835797330384612

Epoch: 6| Step: 9
Training loss: 1.8249914646148682
Validation loss: 1.9929679721914313

Epoch: 6| Step: 10
Training loss: 1.2178391218185425
Validation loss: 1.9689900413636239

Epoch: 6| Step: 11
Training loss: 1.9301031827926636
Validation loss: 1.9331682920455933

Epoch: 6| Step: 12
Training loss: 1.5491724014282227
Validation loss: 1.9114047788804578

Epoch: 6| Step: 13
Training loss: 1.8747859001159668
Validation loss: 1.9449768297133907

Epoch: 167| Step: 0
Training loss: 1.201841115951538
Validation loss: 1.9327988419481503

Epoch: 6| Step: 1
Training loss: 2.6594533920288086
Validation loss: 1.961886477726762

Epoch: 6| Step: 2
Training loss: 1.5688440799713135
Validation loss: 1.9361250990180559

Epoch: 6| Step: 3
Training loss: 1.398242473602295
Validation loss: 1.9828546226665538

Epoch: 6| Step: 4
Training loss: 1.4436031579971313
Validation loss: 1.9317380330895866

Epoch: 6| Step: 5
Training loss: 1.7396106719970703
Validation loss: 1.949443850466

Epoch: 6| Step: 6
Training loss: 1.4319822788238525
Validation loss: 1.9371671317726054

Epoch: 6| Step: 7
Training loss: 2.131300926208496
Validation loss: 1.9493725697199504

Epoch: 6| Step: 8
Training loss: 1.2047008275985718
Validation loss: 1.9260336622115104

Epoch: 6| Step: 9
Training loss: 1.9016112089157104
Validation loss: 1.9613655267223236

Epoch: 6| Step: 10
Training loss: 2.501249074935913
Validation loss: 1.9618246414328133

Epoch: 6| Step: 11
Training loss: 1.8952531814575195
Validation loss: 1.9445310510614866

Epoch: 6| Step: 12
Training loss: 2.5641236305236816
Validation loss: 1.9731257577096262

Epoch: 6| Step: 13
Training loss: 2.0562963485717773
Validation loss: 1.9511562085920764

Epoch: 168| Step: 0
Training loss: 2.616250991821289
Validation loss: 1.9747020454816921

Epoch: 6| Step: 1
Training loss: 1.4676977396011353
Validation loss: 1.983228729617211

Epoch: 6| Step: 2
Training loss: 2.728808879852295
Validation loss: 1.9996962649847871

Epoch: 6| Step: 3
Training loss: 1.89424729347229
Validation loss: 2.0363895329095985

Epoch: 6| Step: 4
Training loss: 1.3439772129058838
Validation loss: 1.9613947650437713

Epoch: 6| Step: 5
Training loss: 1.3778294324874878
Validation loss: 1.9989032155723983

Epoch: 6| Step: 6
Training loss: 1.8791700601577759
Validation loss: 2.006898862059398

Epoch: 6| Step: 7
Training loss: 2.058450222015381
Validation loss: 1.9900330061553626

Epoch: 6| Step: 8
Training loss: 1.4567058086395264
Validation loss: 2.031256442428917

Epoch: 6| Step: 9
Training loss: 1.6900312900543213
Validation loss: 2.0057747107680126

Epoch: 6| Step: 10
Training loss: 1.9889158010482788
Validation loss: 2.017421301975045

Epoch: 6| Step: 11
Training loss: 1.853493571281433
Validation loss: 1.934016898114194

Epoch: 6| Step: 12
Training loss: 2.0881943702697754
Validation loss: 1.932341396167714

Epoch: 6| Step: 13
Training loss: 1.7330262660980225
Validation loss: 1.9287235019027547

Epoch: 169| Step: 0
Training loss: 1.6431050300598145
Validation loss: 1.9252455747255715

Epoch: 6| Step: 1
Training loss: 1.762769103050232
Validation loss: 1.9325488998043923

Epoch: 6| Step: 2
Training loss: 1.395721197128296
Validation loss: 1.906538873590449

Epoch: 6| Step: 3
Training loss: 1.5161738395690918
Validation loss: 1.9649085754989295

Epoch: 6| Step: 4
Training loss: 1.8608835935592651
Validation loss: 1.9423178395917338

Epoch: 6| Step: 5
Training loss: 1.7334988117218018
Validation loss: 1.9341172800269177

Epoch: 6| Step: 6
Training loss: 1.7910621166229248
Validation loss: 1.9249469567370672

Epoch: 6| Step: 7
Training loss: 2.328512668609619
Validation loss: 1.8845506842418382

Epoch: 6| Step: 8
Training loss: 1.8200507164001465
Validation loss: 1.9322477591935026

Epoch: 6| Step: 9
Training loss: 2.0784289836883545
Validation loss: 1.9572680470763997

Epoch: 6| Step: 10
Training loss: 2.085808753967285
Validation loss: 1.9386619290997904

Epoch: 6| Step: 11
Training loss: 2.206300735473633
Validation loss: 1.9364337049504763

Epoch: 6| Step: 12
Training loss: 1.8056010007858276
Validation loss: 1.9770129547324231

Epoch: 6| Step: 13
Training loss: 1.7740126848220825
Validation loss: 1.9424178177310574

Epoch: 170| Step: 0
Training loss: 1.3246408700942993
Validation loss: 1.932601660810491

Epoch: 6| Step: 1
Training loss: 1.7817909717559814
Validation loss: 1.9449645883293563

Epoch: 6| Step: 2
Training loss: 2.2274835109710693
Validation loss: 1.9464154153741815

Epoch: 6| Step: 3
Training loss: 1.6395816802978516
Validation loss: 1.9160056293651622

Epoch: 6| Step: 4
Training loss: 1.9415127038955688
Validation loss: 1.9664319099918488

Epoch: 6| Step: 5
Training loss: 1.9779047966003418
Validation loss: 1.954428784308895

Epoch: 6| Step: 6
Training loss: 1.8730918169021606
Validation loss: 1.9230618271776425

Epoch: 6| Step: 7
Training loss: 1.418814778327942
Validation loss: 1.9395499895977717

Epoch: 6| Step: 8
Training loss: 1.6966354846954346
Validation loss: 1.929981880290534

Epoch: 6| Step: 9
Training loss: 2.3791868686676025
Validation loss: 1.9433094993714364

Epoch: 6| Step: 10
Training loss: 2.151731491088867
Validation loss: 1.922352158895103

Epoch: 6| Step: 11
Training loss: 1.5806580781936646
Validation loss: 1.9431001473498601

Epoch: 6| Step: 12
Training loss: 1.2851516008377075
Validation loss: 1.9427833223855624

Epoch: 6| Step: 13
Training loss: 2.251878023147583
Validation loss: 1.9437953438810123

Epoch: 171| Step: 0
Training loss: 2.087096929550171
Validation loss: 1.933254954635456

Epoch: 6| Step: 1
Training loss: 2.3181793689727783
Validation loss: 1.9575409171401814

Epoch: 6| Step: 2
Training loss: 1.46323823928833
Validation loss: 1.9862013222068868

Epoch: 6| Step: 3
Training loss: 1.7294816970825195
Validation loss: 2.0049211030365317

Epoch: 6| Step: 4
Training loss: 1.7311859130859375
Validation loss: 1.962413308440998

Epoch: 6| Step: 5
Training loss: 1.6529160737991333
Validation loss: 1.9462793898838822

Epoch: 6| Step: 6
Training loss: 1.2930024862289429
Validation loss: 1.9311666527102072

Epoch: 6| Step: 7
Training loss: 2.6403543949127197
Validation loss: 1.9495432223043134

Epoch: 6| Step: 8
Training loss: 1.4084995985031128
Validation loss: 1.9462557197898946

Epoch: 6| Step: 9
Training loss: 1.4814287424087524
Validation loss: 1.9382741912718742

Epoch: 6| Step: 10
Training loss: 1.8151034116744995
Validation loss: 1.8972717459483812

Epoch: 6| Step: 11
Training loss: 1.8550395965576172
Validation loss: 1.9410150256208194

Epoch: 6| Step: 12
Training loss: 2.1710407733917236
Validation loss: 1.9251952261053107

Epoch: 6| Step: 13
Training loss: 1.900390863418579
Validation loss: 1.9187123570390927

Epoch: 172| Step: 0
Training loss: 2.069434404373169
Validation loss: 1.923053797855172

Epoch: 6| Step: 1
Training loss: 3.0293877124786377
Validation loss: 1.9309973011734665

Epoch: 6| Step: 2
Training loss: 1.767218828201294
Validation loss: 1.8936690309996247

Epoch: 6| Step: 3
Training loss: 1.4130929708480835
Validation loss: 1.9170903390453709

Epoch: 6| Step: 4
Training loss: 1.4739668369293213
Validation loss: 1.9107206585586711

Epoch: 6| Step: 5
Training loss: 1.7858819961547852
Validation loss: 1.9103743799271122

Epoch: 6| Step: 6
Training loss: 1.6122474670410156
Validation loss: 1.90923176785951

Epoch: 6| Step: 7
Training loss: 2.0411016941070557
Validation loss: 1.9216712456877514

Epoch: 6| Step: 8
Training loss: 1.6177773475646973
Validation loss: 1.8982940181609123

Epoch: 6| Step: 9
Training loss: 1.6450140476226807
Validation loss: 1.928431394279644

Epoch: 6| Step: 10
Training loss: 1.760403037071228
Validation loss: 1.9027537017740228

Epoch: 6| Step: 11
Training loss: 1.8949984312057495
Validation loss: 1.908849814886688

Epoch: 6| Step: 12
Training loss: 2.022855281829834
Validation loss: 1.944397985294301

Epoch: 6| Step: 13
Training loss: 1.267789602279663
Validation loss: 1.9875450749551096

Epoch: 173| Step: 0
Training loss: 2.0017662048339844
Validation loss: 1.905831257502238

Epoch: 6| Step: 1
Training loss: 1.4109673500061035
Validation loss: 1.977712074915568

Epoch: 6| Step: 2
Training loss: 1.6519464254379272
Validation loss: 1.9743515752976941

Epoch: 6| Step: 3
Training loss: 1.8671875
Validation loss: 1.9931512237876974

Epoch: 6| Step: 4
Training loss: 1.4097342491149902
Validation loss: 1.9626050072331582

Epoch: 6| Step: 5
Training loss: 2.241013526916504
Validation loss: 1.9584394667738227

Epoch: 6| Step: 6
Training loss: 2.529366970062256
Validation loss: 1.9916772457861132

Epoch: 6| Step: 7
Training loss: 2.3366575241088867
Validation loss: 1.9953859877842728

Epoch: 6| Step: 8
Training loss: 1.2609515190124512
Validation loss: 1.9970784917954476

Epoch: 6| Step: 9
Training loss: 2.14064884185791
Validation loss: 2.0060684962939193

Epoch: 6| Step: 10
Training loss: 1.396226167678833
Validation loss: 1.9689880353148266

Epoch: 6| Step: 11
Training loss: 1.9764347076416016
Validation loss: 1.9647031522566272

Epoch: 6| Step: 12
Training loss: 1.371018409729004
Validation loss: 1.9787790185661727

Epoch: 6| Step: 13
Training loss: 1.4647117853164673
Validation loss: 1.928924076018795

Epoch: 174| Step: 0
Training loss: 1.6845066547393799
Validation loss: 1.9210714870883572

Epoch: 6| Step: 1
Training loss: 1.9619696140289307
Validation loss: 1.9070575416729014

Epoch: 6| Step: 2
Training loss: 1.0594851970672607
Validation loss: 1.8905530668074084

Epoch: 6| Step: 3
Training loss: 2.0976476669311523
Validation loss: 1.9169459035319667

Epoch: 6| Step: 4
Training loss: 1.7431392669677734
Validation loss: 1.9402133162303636

Epoch: 6| Step: 5
Training loss: 1.3823585510253906
Validation loss: 1.9062408055028608

Epoch: 6| Step: 6
Training loss: 1.5946054458618164
Validation loss: 1.8919767436160837

Epoch: 6| Step: 7
Training loss: 2.434857130050659
Validation loss: 1.9306569150699082

Epoch: 6| Step: 8
Training loss: 2.4703073501586914
Validation loss: 1.9394432114016624

Epoch: 6| Step: 9
Training loss: 1.3916126489639282
Validation loss: 1.9397667479771439

Epoch: 6| Step: 10
Training loss: 1.9637725353240967
Validation loss: 1.928382344143365

Epoch: 6| Step: 11
Training loss: 1.789260745048523
Validation loss: 1.9019787798645675

Epoch: 6| Step: 12
Training loss: 1.974989414215088
Validation loss: 1.9352880831687682

Epoch: 6| Step: 13
Training loss: 1.8318792581558228
Validation loss: 1.9319773399701683

Epoch: 175| Step: 0
Training loss: 2.1501235961914062
Validation loss: 1.8806783178801179

Epoch: 6| Step: 1
Training loss: 2.3891804218292236
Validation loss: 1.9351813562454716

Epoch: 6| Step: 2
Training loss: 2.396010637283325
Validation loss: 1.9831906633992349

Epoch: 6| Step: 3
Training loss: 1.7137802839279175
Validation loss: 1.93779702724949

Epoch: 6| Step: 4
Training loss: 1.6821014881134033
Validation loss: 1.9791301668331187

Epoch: 6| Step: 5
Training loss: 1.400830864906311
Validation loss: 1.9926834503809612

Epoch: 6| Step: 6
Training loss: 1.6653227806091309
Validation loss: 1.9814995168357767

Epoch: 6| Step: 7
Training loss: 2.1510019302368164
Validation loss: 2.0059299456175936

Epoch: 6| Step: 8
Training loss: 1.5607078075408936
Validation loss: 1.971539056429299

Epoch: 6| Step: 9
Training loss: 1.7497819662094116
Validation loss: 1.8842055643758466

Epoch: 6| Step: 10
Training loss: 1.772093653678894
Validation loss: 1.9352785002800725

Epoch: 6| Step: 11
Training loss: 1.2405874729156494
Validation loss: 1.9199125510390087

Epoch: 6| Step: 12
Training loss: 2.255765438079834
Validation loss: 1.9643943963512298

Epoch: 6| Step: 13
Training loss: 1.3573143482208252
Validation loss: 1.9123781099114368

Testing loss: 2.2759708404541015
