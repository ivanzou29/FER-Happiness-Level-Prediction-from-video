Epoch: 1| Step: 0
Training loss: 8.853412628173828
Validation loss: 9.503114320898568

Epoch: 6| Step: 1
Training loss: 8.567230224609375
Validation loss: 9.495014457292454

Epoch: 6| Step: 2
Training loss: 9.823594093322754
Validation loss: 9.486417226893927

Epoch: 6| Step: 3
Training loss: 9.153321266174316
Validation loss: 9.480104784811697

Epoch: 6| Step: 4
Training loss: 9.135375022888184
Validation loss: 9.474705460251018

Epoch: 6| Step: 5
Training loss: 9.005176544189453
Validation loss: 9.47001083948279

Epoch: 6| Step: 6
Training loss: 8.669443130493164
Validation loss: 9.461405764343919

Epoch: 6| Step: 7
Training loss: 10.459589004516602
Validation loss: 9.451986692285026

Epoch: 6| Step: 8
Training loss: 9.804008483886719
Validation loss: 9.44808570287561

Epoch: 6| Step: 9
Training loss: 8.725142478942871
Validation loss: 9.439497906674621

Epoch: 6| Step: 10
Training loss: 10.04487133026123
Validation loss: 9.433563437513126

Epoch: 6| Step: 11
Training loss: 8.874414443969727
Validation loss: 9.425367027200679

Epoch: 6| Step: 12
Training loss: 9.39997673034668
Validation loss: 9.418470997964182

Epoch: 6| Step: 13
Training loss: 8.896939277648926
Validation loss: 9.411437598607874

Epoch: 2| Step: 0
Training loss: 9.063436508178711
Validation loss: 9.401177057655909

Epoch: 6| Step: 1
Training loss: 9.457109451293945
Validation loss: 9.399194061115224

Epoch: 6| Step: 2
Training loss: 8.77132511138916
Validation loss: 9.386609046689925

Epoch: 6| Step: 3
Training loss: 8.66596794128418
Validation loss: 9.38319024732036

Epoch: 6| Step: 4
Training loss: 9.15792465209961
Validation loss: 9.373696870701288

Epoch: 6| Step: 5
Training loss: 8.922290802001953
Validation loss: 9.365062108603857

Epoch: 6| Step: 6
Training loss: 9.106765747070312
Validation loss: 9.358106346540554

Epoch: 6| Step: 7
Training loss: 8.704788208007812
Validation loss: 9.355042929290443

Epoch: 6| Step: 8
Training loss: 7.836557388305664
Validation loss: 9.344739452485115

Epoch: 6| Step: 9
Training loss: 9.56295108795166
Validation loss: 9.335966551175682

Epoch: 6| Step: 10
Training loss: 10.195481300354004
Validation loss: 9.328841506793935

Epoch: 6| Step: 11
Training loss: 8.68704605102539
Validation loss: 9.320095964657362

Epoch: 6| Step: 12
Training loss: 10.155491828918457
Validation loss: 9.314926434588688

Epoch: 6| Step: 13
Training loss: 10.32177734375
Validation loss: 9.303858305818292

Epoch: 3| Step: 0
Training loss: 8.559427261352539
Validation loss: 9.294674432405861

Epoch: 6| Step: 1
Training loss: 9.182836532592773
Validation loss: 9.285963960873183

Epoch: 6| Step: 2
Training loss: 8.375032424926758
Validation loss: 9.278261297492572

Epoch: 6| Step: 3
Training loss: 9.647407531738281
Validation loss: 9.272028471833917

Epoch: 6| Step: 4
Training loss: 8.429073333740234
Validation loss: 9.260799643813924

Epoch: 6| Step: 5
Training loss: 9.862353324890137
Validation loss: 9.254601006866784

Epoch: 6| Step: 6
Training loss: 8.808541297912598
Validation loss: 9.244242862988544

Epoch: 6| Step: 7
Training loss: 7.871001243591309
Validation loss: 9.237265658634966

Epoch: 6| Step: 8
Training loss: 9.647663116455078
Validation loss: 9.22981805698846

Epoch: 6| Step: 9
Training loss: 9.136146545410156
Validation loss: 9.217848695734496

Epoch: 6| Step: 10
Training loss: 8.027350425720215
Validation loss: 9.210022649457377

Epoch: 6| Step: 11
Training loss: 10.403223037719727
Validation loss: 9.202394403437133

Epoch: 6| Step: 12
Training loss: 10.309982299804688
Validation loss: 9.19312524282804

Epoch: 6| Step: 13
Training loss: 7.598637104034424
Validation loss: 9.184016278994982

Epoch: 4| Step: 0
Training loss: 8.741299629211426
Validation loss: 9.174330854928622

Epoch: 6| Step: 1
Training loss: 9.288349151611328
Validation loss: 9.165610395452028

Epoch: 6| Step: 2
Training loss: 8.573360443115234
Validation loss: 9.155200568578577

Epoch: 6| Step: 3
Training loss: 8.558058738708496
Validation loss: 9.145737422409878

Epoch: 6| Step: 4
Training loss: 8.568464279174805
Validation loss: 9.137885268016529

Epoch: 6| Step: 5
Training loss: 9.153623580932617
Validation loss: 9.129832821507607

Epoch: 6| Step: 6
Training loss: 8.777448654174805
Validation loss: 9.12176993585402

Epoch: 6| Step: 7
Training loss: 8.642513275146484
Validation loss: 9.109844484636861

Epoch: 6| Step: 8
Training loss: 8.426909446716309
Validation loss: 9.09670630834436

Epoch: 6| Step: 9
Training loss: 10.1400785446167
Validation loss: 9.088067229076099

Epoch: 6| Step: 10
Training loss: 9.502801895141602
Validation loss: 9.078856745073873

Epoch: 6| Step: 11
Training loss: 9.3395414352417
Validation loss: 9.071178754170736

Epoch: 6| Step: 12
Training loss: 8.308610916137695
Validation loss: 9.057637327460833

Epoch: 6| Step: 13
Training loss: 8.405831336975098
Validation loss: 9.051523782873666

Epoch: 5| Step: 0
Training loss: 9.270524978637695
Validation loss: 9.039362558754542

Epoch: 6| Step: 1
Training loss: 8.866094589233398
Validation loss: 9.030207428880917

Epoch: 6| Step: 2
Training loss: 8.597208976745605
Validation loss: 9.015488501518004

Epoch: 6| Step: 3
Training loss: 7.87790060043335
Validation loss: 9.005481812261767

Epoch: 6| Step: 4
Training loss: 8.932220458984375
Validation loss: 8.996454495255666

Epoch: 6| Step: 5
Training loss: 10.20889949798584
Validation loss: 8.985010106076476

Epoch: 6| Step: 6
Training loss: 7.874462127685547
Validation loss: 8.974060079102875

Epoch: 6| Step: 7
Training loss: 7.918008804321289
Validation loss: 8.964100294215704

Epoch: 6| Step: 8
Training loss: 9.57660961151123
Validation loss: 8.954515846826697

Epoch: 6| Step: 9
Training loss: 8.568313598632812
Validation loss: 8.943531497832268

Epoch: 6| Step: 10
Training loss: 8.360481262207031
Validation loss: 8.933755659287975

Epoch: 6| Step: 11
Training loss: 9.285539627075195
Validation loss: 8.916849238898164

Epoch: 6| Step: 12
Training loss: 9.085587501525879
Validation loss: 8.908652582476217

Epoch: 6| Step: 13
Training loss: 7.708728313446045
Validation loss: 8.900135778611705

Epoch: 6| Step: 0
Training loss: 9.332627296447754
Validation loss: 8.889900668974846

Epoch: 6| Step: 1
Training loss: 8.012648582458496
Validation loss: 8.877367799000073

Epoch: 6| Step: 2
Training loss: 8.275327682495117
Validation loss: 8.864422008555422

Epoch: 6| Step: 3
Training loss: 9.490213394165039
Validation loss: 8.853562724205755

Epoch: 6| Step: 4
Training loss: 8.399848937988281
Validation loss: 8.842605406238187

Epoch: 6| Step: 5
Training loss: 8.602108001708984
Validation loss: 8.830238096175655

Epoch: 6| Step: 6
Training loss: 9.657121658325195
Validation loss: 8.81825783432171

Epoch: 6| Step: 7
Training loss: 7.279560565948486
Validation loss: 8.80731177586381

Epoch: 6| Step: 8
Training loss: 7.863107681274414
Validation loss: 8.795564671998383

Epoch: 6| Step: 9
Training loss: 8.348718643188477
Validation loss: 8.782702189619823

Epoch: 6| Step: 10
Training loss: 8.811138153076172
Validation loss: 8.76994256050356

Epoch: 6| Step: 11
Training loss: 8.710612297058105
Validation loss: 8.757519701475738

Epoch: 6| Step: 12
Training loss: 7.781749248504639
Validation loss: 8.75199132324547

Epoch: 6| Step: 13
Training loss: 10.75475788116455
Validation loss: 8.73551856830556

Epoch: 7| Step: 0
Training loss: 7.991499423980713
Validation loss: 8.719828400560605

Epoch: 6| Step: 1
Training loss: 9.08597183227539
Validation loss: 8.710735751736548

Epoch: 6| Step: 2
Training loss: 8.398303985595703
Validation loss: 8.699777756967853

Epoch: 6| Step: 3
Training loss: 9.269227981567383
Validation loss: 8.68536788673811

Epoch: 6| Step: 4
Training loss: 7.95754861831665
Validation loss: 8.673973688515284

Epoch: 6| Step: 5
Training loss: 8.672443389892578
Validation loss: 8.659186445256715

Epoch: 6| Step: 6
Training loss: 9.409000396728516
Validation loss: 8.648178900441815

Epoch: 6| Step: 7
Training loss: 7.252565383911133
Validation loss: 8.632809495413175

Epoch: 6| Step: 8
Training loss: 7.153443336486816
Validation loss: 8.621289335271364

Epoch: 6| Step: 9
Training loss: 7.625218391418457
Validation loss: 8.602848340106267

Epoch: 6| Step: 10
Training loss: 8.021202087402344
Validation loss: 8.596391636838195

Epoch: 6| Step: 11
Training loss: 8.687058448791504
Validation loss: 8.58249573041034

Epoch: 6| Step: 12
Training loss: 8.572554588317871
Validation loss: 8.562536680570213

Epoch: 6| Step: 13
Training loss: 10.924384117126465
Validation loss: 8.554361353638352

Epoch: 8| Step: 0
Training loss: 7.613551616668701
Validation loss: 8.540025557241131

Epoch: 6| Step: 1
Training loss: 8.641274452209473
Validation loss: 8.522268500379337

Epoch: 6| Step: 2
Training loss: 8.921248435974121
Validation loss: 8.510575027876003

Epoch: 6| Step: 3
Training loss: 7.832991600036621
Validation loss: 8.495156206110472

Epoch: 6| Step: 4
Training loss: 8.759088516235352
Validation loss: 8.478043956141319

Epoch: 6| Step: 5
Training loss: 8.459836959838867
Validation loss: 8.467219403994982

Epoch: 6| Step: 6
Training loss: 8.514717102050781
Validation loss: 8.45394173488822

Epoch: 6| Step: 7
Training loss: 9.140007972717285
Validation loss: 8.44012346575337

Epoch: 6| Step: 8
Training loss: 8.272032737731934
Validation loss: 8.418208599090576

Epoch: 6| Step: 9
Training loss: 6.723687171936035
Validation loss: 8.405269520257109

Epoch: 6| Step: 10
Training loss: 8.497920989990234
Validation loss: 8.392656756985572

Epoch: 6| Step: 11
Training loss: 7.63704252243042
Validation loss: 8.375638284990865

Epoch: 6| Step: 12
Training loss: 7.152005195617676
Validation loss: 8.360017909798572

Epoch: 6| Step: 13
Training loss: 9.520647048950195
Validation loss: 8.3436066309611

Epoch: 9| Step: 0
Training loss: 6.792548656463623
Validation loss: 8.32648660803354

Epoch: 6| Step: 1
Training loss: 7.998526573181152
Validation loss: 8.308364498999811

Epoch: 6| Step: 2
Training loss: 8.793397903442383
Validation loss: 8.297117756259057

Epoch: 6| Step: 3
Training loss: 7.7147321701049805
Validation loss: 8.275566085692375

Epoch: 6| Step: 4
Training loss: 8.808721542358398
Validation loss: 8.25811492755849

Epoch: 6| Step: 5
Training loss: 8.02914810180664
Validation loss: 8.24225196018014

Epoch: 6| Step: 6
Training loss: 7.622067451477051
Validation loss: 8.226575000311739

Epoch: 6| Step: 7
Training loss: 8.300477027893066
Validation loss: 8.205689860928443

Epoch: 6| Step: 8
Training loss: 9.027332305908203
Validation loss: 8.192504554666499

Epoch: 6| Step: 9
Training loss: 8.922574996948242
Validation loss: 8.166521769697948

Epoch: 6| Step: 10
Training loss: 7.0123114585876465
Validation loss: 8.1486297627931

Epoch: 6| Step: 11
Training loss: 7.355356216430664
Validation loss: 8.132193247477213

Epoch: 6| Step: 12
Training loss: 8.012218475341797
Validation loss: 8.112876415252686

Epoch: 6| Step: 13
Training loss: 7.122900009155273
Validation loss: 8.09542102198447

Epoch: 10| Step: 0
Training loss: 8.260643005371094
Validation loss: 8.076111173117033

Epoch: 6| Step: 1
Training loss: 6.999148845672607
Validation loss: 8.05975079792802

Epoch: 6| Step: 2
Training loss: 7.449353218078613
Validation loss: 8.034189634425665

Epoch: 6| Step: 3
Training loss: 7.292806625366211
Validation loss: 8.015407049527733

Epoch: 6| Step: 4
Training loss: 6.422673225402832
Validation loss: 7.994558334350586

Epoch: 6| Step: 5
Training loss: 7.708902835845947
Validation loss: 7.969795145014281

Epoch: 6| Step: 6
Training loss: 6.647430419921875
Validation loss: 7.949850405416181

Epoch: 6| Step: 7
Training loss: 8.501077651977539
Validation loss: 7.933233496963337

Epoch: 6| Step: 8
Training loss: 8.953563690185547
Validation loss: 7.908551759617303

Epoch: 6| Step: 9
Training loss: 8.594585418701172
Validation loss: 7.883064690456595

Epoch: 6| Step: 10
Training loss: 7.954964637756348
Validation loss: 7.861414868344543

Epoch: 6| Step: 11
Training loss: 8.0419340133667
Validation loss: 7.846736733631421

Epoch: 6| Step: 12
Training loss: 7.40077543258667
Validation loss: 7.818488490196966

Epoch: 6| Step: 13
Training loss: 7.61411190032959
Validation loss: 7.798394254458848

Epoch: 11| Step: 0
Training loss: 7.113520622253418
Validation loss: 7.774147633583315

Epoch: 6| Step: 1
Training loss: 9.004091262817383
Validation loss: 7.748941242053944

Epoch: 6| Step: 2
Training loss: 7.937018394470215
Validation loss: 7.725212850878315

Epoch: 6| Step: 3
Training loss: 7.344180583953857
Validation loss: 7.697766293761551

Epoch: 6| Step: 4
Training loss: 5.633294105529785
Validation loss: 7.673562977903632

Epoch: 6| Step: 5
Training loss: 7.161564826965332
Validation loss: 7.652239250880416

Epoch: 6| Step: 6
Training loss: 6.873993396759033
Validation loss: 7.6204251525222615

Epoch: 6| Step: 7
Training loss: 6.987213134765625
Validation loss: 7.600177159873388

Epoch: 6| Step: 8
Training loss: 8.044748306274414
Validation loss: 7.574701227167601

Epoch: 6| Step: 9
Training loss: 7.836694717407227
Validation loss: 7.552426261286581

Epoch: 6| Step: 10
Training loss: 7.360663414001465
Validation loss: 7.5250907764639905

Epoch: 6| Step: 11
Training loss: 7.881711006164551
Validation loss: 7.49844677217545

Epoch: 6| Step: 12
Training loss: 6.667006492614746
Validation loss: 7.476405907702702

Epoch: 6| Step: 13
Training loss: 7.4523468017578125
Validation loss: 7.441850057212255

Epoch: 12| Step: 0
Training loss: 8.853105545043945
Validation loss: 7.417810429808914

Epoch: 6| Step: 1
Training loss: 6.21306848526001
Validation loss: 7.390051000861711

Epoch: 6| Step: 2
Training loss: 7.791273593902588
Validation loss: 7.364565869813324

Epoch: 6| Step: 3
Training loss: 6.638376712799072
Validation loss: 7.336967719498501

Epoch: 6| Step: 4
Training loss: 6.299853324890137
Validation loss: 7.313645680745442

Epoch: 6| Step: 5
Training loss: 6.901610374450684
Validation loss: 7.286281134492608

Epoch: 6| Step: 6
Training loss: 6.998987197875977
Validation loss: 7.257902801677745

Epoch: 6| Step: 7
Training loss: 8.27161979675293
Validation loss: 7.223088879739085

Epoch: 6| Step: 8
Training loss: 6.879339218139648
Validation loss: 7.192662587729833

Epoch: 6| Step: 9
Training loss: 6.492354393005371
Validation loss: 7.163697929792507

Epoch: 6| Step: 10
Training loss: 5.948962211608887
Validation loss: 7.140195564557147

Epoch: 6| Step: 11
Training loss: 5.8638691902160645
Validation loss: 7.107301958145634

Epoch: 6| Step: 12
Training loss: 7.630722522735596
Validation loss: 7.080455441628733

Epoch: 6| Step: 13
Training loss: 7.227518081665039
Validation loss: 7.042649166558379

Epoch: 13| Step: 0
Training loss: 5.98101806640625
Validation loss: 7.012255248203073

Epoch: 6| Step: 1
Training loss: 7.466703414916992
Validation loss: 6.975124395021829

Epoch: 6| Step: 2
Training loss: 6.421391010284424
Validation loss: 6.950924094005297

Epoch: 6| Step: 3
Training loss: 6.486181259155273
Validation loss: 6.9191230907235095

Epoch: 6| Step: 4
Training loss: 7.462509632110596
Validation loss: 6.885374023068335

Epoch: 6| Step: 5
Training loss: 6.500490188598633
Validation loss: 6.8464208572141585

Epoch: 6| Step: 6
Training loss: 6.3561553955078125
Validation loss: 6.8210743575967765

Epoch: 6| Step: 7
Training loss: 7.403411865234375
Validation loss: 6.7836990305172495

Epoch: 6| Step: 8
Training loss: 7.149507522583008
Validation loss: 6.751820046414611

Epoch: 6| Step: 9
Training loss: 6.142621040344238
Validation loss: 6.717690190961284

Epoch: 6| Step: 10
Training loss: 6.743680000305176
Validation loss: 6.68416844132126

Epoch: 6| Step: 11
Training loss: 5.123647689819336
Validation loss: 6.6469287410859135

Epoch: 6| Step: 12
Training loss: 6.4220781326293945
Validation loss: 6.612971536574825

Epoch: 6| Step: 13
Training loss: 5.637418746948242
Validation loss: 6.583031387739284

Epoch: 14| Step: 0
Training loss: 6.943564414978027
Validation loss: 6.5530420118762605

Epoch: 6| Step: 1
Training loss: 5.370482444763184
Validation loss: 6.500171558831328

Epoch: 6| Step: 2
Training loss: 6.478761672973633
Validation loss: 6.466115541355585

Epoch: 6| Step: 3
Training loss: 5.740520477294922
Validation loss: 6.434889701104933

Epoch: 6| Step: 4
Training loss: 5.430816650390625
Validation loss: 6.3965906635407475

Epoch: 6| Step: 5
Training loss: 5.47282075881958
Validation loss: 6.359813223602951

Epoch: 6| Step: 6
Training loss: 6.254671573638916
Validation loss: 6.319685495027932

Epoch: 6| Step: 7
Training loss: 6.707965850830078
Validation loss: 6.282755472326792

Epoch: 6| Step: 8
Training loss: 7.034140586853027
Validation loss: 6.2422860412187475

Epoch: 6| Step: 9
Training loss: 6.0689287185668945
Validation loss: 6.203376631582937

Epoch: 6| Step: 10
Training loss: 6.238772869110107
Validation loss: 6.16577345837829

Epoch: 6| Step: 11
Training loss: 5.101511478424072
Validation loss: 6.123124317456317

Epoch: 6| Step: 12
Training loss: 6.321146488189697
Validation loss: 6.0854239207442085

Epoch: 6| Step: 13
Training loss: 4.920435428619385
Validation loss: 6.047086572134367

Epoch: 15| Step: 0
Training loss: 5.459151268005371
Validation loss: 6.006017956682431

Epoch: 6| Step: 1
Training loss: 4.712362766265869
Validation loss: 5.9630143104061

Epoch: 6| Step: 2
Training loss: 6.4438958168029785
Validation loss: 5.918739252192999

Epoch: 6| Step: 3
Training loss: 4.984348773956299
Validation loss: 5.871798058991791

Epoch: 6| Step: 4
Training loss: 5.121764659881592
Validation loss: 5.829193663853471

Epoch: 6| Step: 5
Training loss: 6.320799350738525
Validation loss: 5.783232273594026

Epoch: 6| Step: 6
Training loss: 5.995912551879883
Validation loss: 5.734582234454411

Epoch: 6| Step: 7
Training loss: 6.091673851013184
Validation loss: 5.7001250123464935

Epoch: 6| Step: 8
Training loss: 5.942086696624756
Validation loss: 5.650547776170956

Epoch: 6| Step: 9
Training loss: 5.345958232879639
Validation loss: 5.607091375576553

Epoch: 6| Step: 10
Training loss: 5.8856425285339355
Validation loss: 5.564459011118899

Epoch: 6| Step: 11
Training loss: 5.4511942863464355
Validation loss: 5.512540453223772

Epoch: 6| Step: 12
Training loss: 4.151379108428955
Validation loss: 5.4705300946389475

Epoch: 6| Step: 13
Training loss: 3.8534746170043945
Validation loss: 5.417674146672731

Epoch: 16| Step: 0
Training loss: 5.159580230712891
Validation loss: 5.375684897104899

Epoch: 6| Step: 1
Training loss: 4.702902793884277
Validation loss: 5.335197115457186

Epoch: 6| Step: 2
Training loss: 5.411495208740234
Validation loss: 5.278956003086542

Epoch: 6| Step: 3
Training loss: 5.363223075866699
Validation loss: 5.224668020843177

Epoch: 6| Step: 4
Training loss: 5.5092363357543945
Validation loss: 5.182706499612459

Epoch: 6| Step: 5
Training loss: 5.330721855163574
Validation loss: 5.120709178268268

Epoch: 6| Step: 6
Training loss: 5.183201313018799
Validation loss: 5.080663763066774

Epoch: 6| Step: 7
Training loss: 5.684693336486816
Validation loss: 5.023233623914821

Epoch: 6| Step: 8
Training loss: 5.493873596191406
Validation loss: 4.971295751551146

Epoch: 6| Step: 9
Training loss: 4.206727027893066
Validation loss: 4.920709681767289

Epoch: 6| Step: 10
Training loss: 3.5197463035583496
Validation loss: 4.884431536479663

Epoch: 6| Step: 11
Training loss: 4.106512069702148
Validation loss: 4.8204086570329565

Epoch: 6| Step: 12
Training loss: 3.2899041175842285
Validation loss: 4.775022247786163

Epoch: 6| Step: 13
Training loss: 3.7041876316070557
Validation loss: 4.719323835065288

Epoch: 17| Step: 0
Training loss: 4.5722222328186035
Validation loss: 4.691303442883235

Epoch: 6| Step: 1
Training loss: 4.650012493133545
Validation loss: 4.625785494363436

Epoch: 6| Step: 2
Training loss: 4.229150295257568
Validation loss: 4.5788982965612925

Epoch: 6| Step: 3
Training loss: 3.9715728759765625
Validation loss: 4.5230666181092625

Epoch: 6| Step: 4
Training loss: 3.4206602573394775
Validation loss: 4.474309013735864

Epoch: 6| Step: 5
Training loss: 2.32454514503479
Validation loss: 4.433647417253064

Epoch: 6| Step: 6
Training loss: 5.391378402709961
Validation loss: 4.401023111035747

Epoch: 6| Step: 7
Training loss: 4.128518104553223
Validation loss: 4.334859181475895

Epoch: 6| Step: 8
Training loss: 4.404513359069824
Validation loss: 4.292880637671358

Epoch: 6| Step: 9
Training loss: 4.836895942687988
Validation loss: 4.24165174012543

Epoch: 6| Step: 10
Training loss: 4.733709335327148
Validation loss: 4.199175321927634

Epoch: 6| Step: 11
Training loss: 4.198866367340088
Validation loss: 4.138660830836142

Epoch: 6| Step: 12
Training loss: 3.5218558311462402
Validation loss: 4.089646006143221

Epoch: 6| Step: 13
Training loss: 3.0350751876831055
Validation loss: 4.042001837043352

Epoch: 18| Step: 0
Training loss: 4.024113178253174
Validation loss: 3.9963262260601087

Epoch: 6| Step: 1
Training loss: 4.661999702453613
Validation loss: 3.9375190581044843

Epoch: 6| Step: 2
Training loss: 3.4487133026123047
Validation loss: 3.910945466769639

Epoch: 6| Step: 3
Training loss: 2.752401828765869
Validation loss: 3.8528972851332797

Epoch: 6| Step: 4
Training loss: 4.035871505737305
Validation loss: 3.806767955903084

Epoch: 6| Step: 5
Training loss: 3.5394845008850098
Validation loss: 3.749747286560715

Epoch: 6| Step: 6
Training loss: 3.7474522590637207
Validation loss: 3.713367267321515

Epoch: 6| Step: 7
Training loss: 2.5228612422943115
Validation loss: 3.6584953672142437

Epoch: 6| Step: 8
Training loss: 3.428438186645508
Validation loss: 3.5919775245010213

Epoch: 6| Step: 9
Training loss: 2.577089786529541
Validation loss: 3.5756011137398342

Epoch: 6| Step: 10
Training loss: 4.314568519592285
Validation loss: 3.519024920719926

Epoch: 6| Step: 11
Training loss: 2.90933895111084
Validation loss: 3.493696140986617

Epoch: 6| Step: 12
Training loss: 3.0579147338867188
Validation loss: 3.424896950362831

Epoch: 6| Step: 13
Training loss: 4.650643348693848
Validation loss: 3.415829973836099

Epoch: 19| Step: 0
Training loss: 3.7235584259033203
Validation loss: 3.361664979688583

Epoch: 6| Step: 1
Training loss: 3.1271581649780273
Validation loss: 3.3360311523560555

Epoch: 6| Step: 2
Training loss: 4.245787620544434
Validation loss: 3.268758471294116

Epoch: 6| Step: 3
Training loss: 2.913801670074463
Validation loss: 3.2370441011203233

Epoch: 6| Step: 4
Training loss: 3.606473207473755
Validation loss: 3.187818670785555

Epoch: 6| Step: 5
Training loss: 3.3504233360290527
Validation loss: 3.169042984644572

Epoch: 6| Step: 6
Training loss: 1.9541889429092407
Validation loss: 3.138648468960998

Epoch: 6| Step: 7
Training loss: 3.7210121154785156
Validation loss: 3.1042030575454875

Epoch: 6| Step: 8
Training loss: 2.5908126831054688
Validation loss: 3.0514284513329946

Epoch: 6| Step: 9
Training loss: 2.37192964553833
Validation loss: 3.0357226684529293

Epoch: 6| Step: 10
Training loss: 3.3213133811950684
Validation loss: 2.995324993646273

Epoch: 6| Step: 11
Training loss: 2.1446685791015625
Validation loss: 2.997220262404411

Epoch: 6| Step: 12
Training loss: 2.921056032180786
Validation loss: 2.952602263419859

Epoch: 6| Step: 13
Training loss: 2.5384302139282227
Validation loss: 2.950086578246086

Epoch: 20| Step: 0
Training loss: 2.7205207347869873
Validation loss: 2.906000442402337

Epoch: 6| Step: 1
Training loss: 2.729823589324951
Validation loss: 2.8875524459346646

Epoch: 6| Step: 2
Training loss: 2.6166162490844727
Validation loss: 2.8553642688259

Epoch: 6| Step: 3
Training loss: 3.2131025791168213
Validation loss: 2.8438854140620076

Epoch: 6| Step: 4
Training loss: 2.1969499588012695
Validation loss: 2.823888627431726

Epoch: 6| Step: 5
Training loss: 2.857354164123535
Validation loss: 2.818353186371506

Epoch: 6| Step: 6
Training loss: 2.5722408294677734
Validation loss: 2.8115605256890737

Epoch: 6| Step: 7
Training loss: 2.7120003700256348
Validation loss: 2.7674113755585044

Epoch: 6| Step: 8
Training loss: 2.8879709243774414
Validation loss: 2.7639946732469785

Epoch: 6| Step: 9
Training loss: 3.202852725982666
Validation loss: 2.75953903249515

Epoch: 6| Step: 10
Training loss: 3.186856269836426
Validation loss: 2.729957006310904

Epoch: 6| Step: 11
Training loss: 2.5205962657928467
Validation loss: 2.7342017799295406

Epoch: 6| Step: 12
Training loss: 3.2775473594665527
Validation loss: 2.7387786296106156

Epoch: 6| Step: 13
Training loss: 1.6691633462905884
Validation loss: 2.676039336830057

Epoch: 21| Step: 0
Training loss: 2.4098381996154785
Validation loss: 2.6844651545247724

Epoch: 6| Step: 1
Training loss: 2.584247589111328
Validation loss: 2.6836100906454106

Epoch: 6| Step: 2
Training loss: 3.1798229217529297
Validation loss: 2.630397983776626

Epoch: 6| Step: 3
Training loss: 2.6147754192352295
Validation loss: 2.64067857239836

Epoch: 6| Step: 4
Training loss: 2.6415467262268066
Validation loss: 2.6456340692376576

Epoch: 6| Step: 5
Training loss: 1.5065823793411255
Validation loss: 2.6222948002558883

Epoch: 6| Step: 6
Training loss: 2.3141438961029053
Validation loss: 2.601827811169368

Epoch: 6| Step: 7
Training loss: 2.4189529418945312
Validation loss: 2.6140018176007014

Epoch: 6| Step: 8
Training loss: 3.4075424671173096
Validation loss: 2.5960403667983187

Epoch: 6| Step: 9
Training loss: 3.260162830352783
Validation loss: 2.6042642298565117

Epoch: 6| Step: 10
Training loss: 2.6727559566497803
Validation loss: 2.5924802518660024

Epoch: 6| Step: 11
Training loss: 2.734023094177246
Validation loss: 2.568127034812845

Epoch: 6| Step: 12
Training loss: 2.935532569885254
Validation loss: 2.579766886208647

Epoch: 6| Step: 13
Training loss: 2.569697856903076
Validation loss: 2.555856676511867

Epoch: 22| Step: 0
Training loss: 2.667973756790161
Validation loss: 2.5623628862442507

Epoch: 6| Step: 1
Training loss: 1.9933462142944336
Validation loss: 2.588570010277533

Epoch: 6| Step: 2
Training loss: 2.858340263366699
Validation loss: 2.5454364925302486

Epoch: 6| Step: 3
Training loss: 2.1621527671813965
Validation loss: 2.5498164084649857

Epoch: 6| Step: 4
Training loss: 2.5927014350891113
Validation loss: 2.532920370819748

Epoch: 6| Step: 5
Training loss: 2.454197406768799
Validation loss: 2.532730507594283

Epoch: 6| Step: 6
Training loss: 2.539163112640381
Validation loss: 2.540085167013189

Epoch: 6| Step: 7
Training loss: 3.0097477436065674
Validation loss: 2.54281194748417

Epoch: 6| Step: 8
Training loss: 3.1549081802368164
Validation loss: 2.535711798616635

Epoch: 6| Step: 9
Training loss: 2.1274027824401855
Validation loss: 2.535594842767203

Epoch: 6| Step: 10
Training loss: 2.9859776496887207
Validation loss: 2.535397198892409

Epoch: 6| Step: 11
Training loss: 2.4360640048980713
Validation loss: 2.5339100258324736

Epoch: 6| Step: 12
Training loss: 2.9531924724578857
Validation loss: 2.5332253056187786

Epoch: 6| Step: 13
Training loss: 2.993290901184082
Validation loss: 2.519497074106688

Epoch: 23| Step: 0
Training loss: 2.505039930343628
Validation loss: 2.5228897474145375

Epoch: 6| Step: 1
Training loss: 2.2192959785461426
Validation loss: 2.528101054571008

Epoch: 6| Step: 2
Training loss: 2.2837038040161133
Validation loss: 2.5187195372837845

Epoch: 6| Step: 3
Training loss: 2.111076831817627
Validation loss: 2.5037916783363587

Epoch: 6| Step: 4
Training loss: 3.3127126693725586
Validation loss: 2.4997396956207933

Epoch: 6| Step: 5
Training loss: 3.2593464851379395
Validation loss: 2.5194262740432576

Epoch: 6| Step: 6
Training loss: 2.0501348972320557
Validation loss: 2.5163579448576896

Epoch: 6| Step: 7
Training loss: 2.2922961711883545
Validation loss: 2.540058551296111

Epoch: 6| Step: 8
Training loss: 2.7500898838043213
Validation loss: 2.5581383807684785

Epoch: 6| Step: 9
Training loss: 3.697744369506836
Validation loss: 2.513714118670392

Epoch: 6| Step: 10
Training loss: 2.912471294403076
Validation loss: 2.53144944355052

Epoch: 6| Step: 11
Training loss: 1.8330812454223633
Validation loss: 2.525130048874886

Epoch: 6| Step: 12
Training loss: 2.751204490661621
Validation loss: 2.5271756700290147

Epoch: 6| Step: 13
Training loss: 2.5213563442230225
Validation loss: 2.5239689837219896

Epoch: 24| Step: 0
Training loss: 1.6127692461013794
Validation loss: 2.56110785084386

Epoch: 6| Step: 1
Training loss: 2.2702019214630127
Validation loss: 2.5154569507927023

Epoch: 6| Step: 2
Training loss: 2.950892925262451
Validation loss: 2.5027336587188063

Epoch: 6| Step: 3
Training loss: 2.182953357696533
Validation loss: 2.538545713629774

Epoch: 6| Step: 4
Training loss: 2.660156488418579
Validation loss: 2.5123501285429923

Epoch: 6| Step: 5
Training loss: 2.0235488414764404
Validation loss: 2.5110986822394916

Epoch: 6| Step: 6
Training loss: 1.9934945106506348
Validation loss: 2.495981313849008

Epoch: 6| Step: 7
Training loss: 2.5158069133758545
Validation loss: 2.5072101393053607

Epoch: 6| Step: 8
Training loss: 3.128899574279785
Validation loss: 2.4968597119854343

Epoch: 6| Step: 9
Training loss: 3.721544027328491
Validation loss: 2.4990707110333186

Epoch: 6| Step: 10
Training loss: 2.581643581390381
Validation loss: 2.486473819260956

Epoch: 6| Step: 11
Training loss: 2.5873632431030273
Validation loss: 2.5335285586695515

Epoch: 6| Step: 12
Training loss: 3.1989831924438477
Validation loss: 2.545307674715596

Epoch: 6| Step: 13
Training loss: 3.4001755714416504
Validation loss: 2.5034567335600495

Epoch: 25| Step: 0
Training loss: 2.602750301361084
Validation loss: 2.507854543706422

Epoch: 6| Step: 1
Training loss: 2.4298672676086426
Validation loss: 2.488411477817002

Epoch: 6| Step: 2
Training loss: 3.6207828521728516
Validation loss: 2.496441682179769

Epoch: 6| Step: 3
Training loss: 2.3913497924804688
Validation loss: 2.525487699816304

Epoch: 6| Step: 4
Training loss: 2.3202850818634033
Validation loss: 2.5179105522812053

Epoch: 6| Step: 5
Training loss: 2.323173761367798
Validation loss: 2.5464771242551905

Epoch: 6| Step: 6
Training loss: 2.4131829738616943
Validation loss: 2.481475330168201

Epoch: 6| Step: 7
Training loss: 3.1074728965759277
Validation loss: 2.4836276218455327

Epoch: 6| Step: 8
Training loss: 2.2198803424835205
Validation loss: 2.4797167137104976

Epoch: 6| Step: 9
Training loss: 1.9316489696502686
Validation loss: 2.4987701421142905

Epoch: 6| Step: 10
Training loss: 2.6471762657165527
Validation loss: 2.486757757843182

Epoch: 6| Step: 11
Training loss: 3.182652711868286
Validation loss: 2.509325945249168

Epoch: 6| Step: 12
Training loss: 2.3620784282684326
Validation loss: 2.477065696511217

Epoch: 6| Step: 13
Training loss: 2.6370303630828857
Validation loss: 2.491454324414653

Epoch: 26| Step: 0
Training loss: 2.38265323638916
Validation loss: 2.4945162444986324

Epoch: 6| Step: 1
Training loss: 2.340989112854004
Validation loss: 2.490428134959231

Epoch: 6| Step: 2
Training loss: 2.5368266105651855
Validation loss: 2.4757634388503207

Epoch: 6| Step: 3
Training loss: 2.6670522689819336
Validation loss: 2.4835352872007634

Epoch: 6| Step: 4
Training loss: 2.64652156829834
Validation loss: 2.4922369987733903

Epoch: 6| Step: 5
Training loss: 3.1297380924224854
Validation loss: 2.495838713902299

Epoch: 6| Step: 6
Training loss: 2.407083034515381
Validation loss: 2.471736531103811

Epoch: 6| Step: 7
Training loss: 1.770869493484497
Validation loss: 2.4709398464490007

Epoch: 6| Step: 8
Training loss: 2.0986223220825195
Validation loss: 2.4952717750303206

Epoch: 6| Step: 9
Training loss: 2.092846155166626
Validation loss: 2.4723300010927263

Epoch: 6| Step: 10
Training loss: 2.711606979370117
Validation loss: 2.502524011878557

Epoch: 6| Step: 11
Training loss: 3.3585293292999268
Validation loss: 2.4787877439170756

Epoch: 6| Step: 12
Training loss: 3.2558133602142334
Validation loss: 2.4571741498926634

Epoch: 6| Step: 13
Training loss: 2.2494969367980957
Validation loss: 2.491176010459982

Epoch: 27| Step: 0
Training loss: 2.091581344604492
Validation loss: 2.5030418390868814

Epoch: 6| Step: 1
Training loss: 2.5111496448516846
Validation loss: 2.4881998903007916

Epoch: 6| Step: 2
Training loss: 2.0842947959899902
Validation loss: 2.469042785706059

Epoch: 6| Step: 3
Training loss: 3.3650240898132324
Validation loss: 2.4789763368586057

Epoch: 6| Step: 4
Training loss: 2.4156293869018555
Validation loss: 2.4953214994040867

Epoch: 6| Step: 5
Training loss: 2.227937698364258
Validation loss: 2.4926278334791943

Epoch: 6| Step: 6
Training loss: 2.612868309020996
Validation loss: 2.4838565293178765

Epoch: 6| Step: 7
Training loss: 2.3854737281799316
Validation loss: 2.481312367223924

Epoch: 6| Step: 8
Training loss: 3.1654303073883057
Validation loss: 2.5081137457201557

Epoch: 6| Step: 9
Training loss: 2.69189453125
Validation loss: 2.500928622420116

Epoch: 6| Step: 10
Training loss: 1.8161325454711914
Validation loss: 2.4989479331560034

Epoch: 6| Step: 11
Training loss: 3.396937847137451
Validation loss: 2.4959238344623196

Epoch: 6| Step: 12
Training loss: 2.0645861625671387
Validation loss: 2.4754852325685563

Epoch: 6| Step: 13
Training loss: 3.243760347366333
Validation loss: 2.5219504141038462

Epoch: 28| Step: 0
Training loss: 2.482973575592041
Validation loss: 2.5130807071603756

Epoch: 6| Step: 1
Training loss: 1.8566057682037354
Validation loss: 2.4598222701780257

Epoch: 6| Step: 2
Training loss: 4.154513359069824
Validation loss: 2.5029160591863815

Epoch: 6| Step: 3
Training loss: 2.3016152381896973
Validation loss: 2.483982588655205

Epoch: 6| Step: 4
Training loss: 1.7559657096862793
Validation loss: 2.4962138117000623

Epoch: 6| Step: 5
Training loss: 3.2464661598205566
Validation loss: 2.484988481767716

Epoch: 6| Step: 6
Training loss: 2.7642674446105957
Validation loss: 2.4944477440208517

Epoch: 6| Step: 7
Training loss: 2.3407740592956543
Validation loss: 2.47909955311847

Epoch: 6| Step: 8
Training loss: 1.8997386693954468
Validation loss: 2.4591284695491997

Epoch: 6| Step: 9
Training loss: 3.434624671936035
Validation loss: 2.4634281153319986

Epoch: 6| Step: 10
Training loss: 3.169908046722412
Validation loss: 2.4642848019958823

Epoch: 6| Step: 11
Training loss: 2.073824167251587
Validation loss: 2.4620576661120177

Epoch: 6| Step: 12
Training loss: 1.8102809190750122
Validation loss: 2.446132888076126

Epoch: 6| Step: 13
Training loss: 1.796562671661377
Validation loss: 2.46976718594951

Epoch: 29| Step: 0
Training loss: 2.604806900024414
Validation loss: 2.4653630359198457

Epoch: 6| Step: 1
Training loss: 2.5703916549682617
Validation loss: 2.4482086858441754

Epoch: 6| Step: 2
Training loss: 2.34462833404541
Validation loss: 2.4521680980600338

Epoch: 6| Step: 3
Training loss: 2.795497417449951
Validation loss: 2.469083093827771

Epoch: 6| Step: 4
Training loss: 3.4394028186798096
Validation loss: 2.4309391795947985

Epoch: 6| Step: 5
Training loss: 2.1481449604034424
Validation loss: 2.4528253373279365

Epoch: 6| Step: 6
Training loss: 2.5942764282226562
Validation loss: 2.458502577197167

Epoch: 6| Step: 7
Training loss: 1.9199765920639038
Validation loss: 2.424149743972286

Epoch: 6| Step: 8
Training loss: 2.1329915523529053
Validation loss: 2.435278956608106

Epoch: 6| Step: 9
Training loss: 2.8865997791290283
Validation loss: 2.451781157524355

Epoch: 6| Step: 10
Training loss: 3.2318015098571777
Validation loss: 2.438965053968532

Epoch: 6| Step: 11
Training loss: 2.0768017768859863
Validation loss: 2.4209504178775254

Epoch: 6| Step: 12
Training loss: 1.5217540264129639
Validation loss: 2.4064869162856892

Epoch: 6| Step: 13
Training loss: 2.842419385910034
Validation loss: 2.4161073494982976

Epoch: 30| Step: 0
Training loss: 3.136111259460449
Validation loss: 2.4219064943252073

Epoch: 6| Step: 1
Training loss: 2.878617763519287
Validation loss: 2.423434772799092

Epoch: 6| Step: 2
Training loss: 2.5141983032226562
Validation loss: 2.415107783450875

Epoch: 6| Step: 3
Training loss: 2.9190914630889893
Validation loss: 2.3853312205242854

Epoch: 6| Step: 4
Training loss: 2.079058885574341
Validation loss: 2.442174801262476

Epoch: 6| Step: 5
Training loss: 1.8269075155258179
Validation loss: 2.403141439601939

Epoch: 6| Step: 6
Training loss: 3.1063427925109863
Validation loss: 2.4247061514085337

Epoch: 6| Step: 7
Training loss: 2.2372708320617676
Validation loss: 2.4207540250593618

Epoch: 6| Step: 8
Training loss: 2.585020065307617
Validation loss: 2.4062599571802283

Epoch: 6| Step: 9
Training loss: 1.9250658750534058
Validation loss: 2.3787064565125333

Epoch: 6| Step: 10
Training loss: 2.3288686275482178
Validation loss: 2.4055042882119455

Epoch: 6| Step: 11
Training loss: 1.5532331466674805
Validation loss: 2.4006029764811196

Epoch: 6| Step: 12
Training loss: 2.856137752532959
Validation loss: 2.4004251956939697

Epoch: 6| Step: 13
Training loss: 3.6899685859680176
Validation loss: 2.4035375143892024

Epoch: 31| Step: 0
Training loss: 2.509315252304077
Validation loss: 2.3848271344297673

Epoch: 6| Step: 1
Training loss: 2.007732391357422
Validation loss: 2.4180654402702086

Epoch: 6| Step: 2
Training loss: 2.000077247619629
Validation loss: 2.4054177807223414

Epoch: 6| Step: 3
Training loss: 4.003021240234375
Validation loss: 2.423187263550297

Epoch: 6| Step: 4
Training loss: 1.8956995010375977
Validation loss: 2.40435040638011

Epoch: 6| Step: 5
Training loss: 2.491633892059326
Validation loss: 2.413479269191783

Epoch: 6| Step: 6
Training loss: 2.7255704402923584
Validation loss: 2.4101107838333293

Epoch: 6| Step: 7
Training loss: 2.391144275665283
Validation loss: 2.4014641290069907

Epoch: 6| Step: 8
Training loss: 2.6320297718048096
Validation loss: 2.405817900934527

Epoch: 6| Step: 9
Training loss: 2.542910575866699
Validation loss: 2.377590689607846

Epoch: 6| Step: 10
Training loss: 1.6810433864593506
Validation loss: 2.4130640747726604

Epoch: 6| Step: 11
Training loss: 2.3848795890808105
Validation loss: 2.3885282085787867

Epoch: 6| Step: 12
Training loss: 2.3448987007141113
Validation loss: 2.4029454620935584

Epoch: 6| Step: 13
Training loss: 3.39401912689209
Validation loss: 2.3973254183287263

Epoch: 32| Step: 0
Training loss: 2.043727397918701
Validation loss: 2.3916915719227125

Epoch: 6| Step: 1
Training loss: 1.9677517414093018
Validation loss: 2.3813330152983307

Epoch: 6| Step: 2
Training loss: 2.012153148651123
Validation loss: 2.4065687015492427

Epoch: 6| Step: 3
Training loss: 2.854341983795166
Validation loss: 2.391120385098201

Epoch: 6| Step: 4
Training loss: 2.1875486373901367
Validation loss: 2.390117129971904

Epoch: 6| Step: 5
Training loss: 3.476511001586914
Validation loss: 2.3619987259628954

Epoch: 6| Step: 6
Training loss: 1.5904837846755981
Validation loss: 2.3868465500493206

Epoch: 6| Step: 7
Training loss: 1.8950669765472412
Validation loss: 2.3862090623506935

Epoch: 6| Step: 8
Training loss: 2.5596563816070557
Validation loss: 2.3970887430252565

Epoch: 6| Step: 9
Training loss: 2.6887941360473633
Validation loss: 2.403857792577436

Epoch: 6| Step: 10
Training loss: 2.6488728523254395
Validation loss: 2.3961984316507974

Epoch: 6| Step: 11
Training loss: 3.418055534362793
Validation loss: 2.384886962111278

Epoch: 6| Step: 12
Training loss: 2.295480728149414
Validation loss: 2.3862815172441545

Epoch: 6| Step: 13
Training loss: 3.490959644317627
Validation loss: 2.392272577490858

Epoch: 33| Step: 0
Training loss: 2.308098554611206
Validation loss: 2.3533541528127526

Epoch: 6| Step: 1
Training loss: 3.0074219703674316
Validation loss: 2.3525792552578833

Epoch: 6| Step: 2
Training loss: 3.079822540283203
Validation loss: 2.3722250615396807

Epoch: 6| Step: 3
Training loss: 1.9173800945281982
Validation loss: 2.3703508582166446

Epoch: 6| Step: 4
Training loss: 1.9112441539764404
Validation loss: 2.388652786131828

Epoch: 6| Step: 5
Training loss: 3.173398017883301
Validation loss: 2.3952864780220935

Epoch: 6| Step: 6
Training loss: 2.0053324699401855
Validation loss: 2.3776304747468684

Epoch: 6| Step: 7
Training loss: 2.596898317337036
Validation loss: 2.3892011693728867

Epoch: 6| Step: 8
Training loss: 2.230617046356201
Validation loss: 2.3348568408719954

Epoch: 6| Step: 9
Training loss: 2.295886516571045
Validation loss: 2.3690667972769788

Epoch: 6| Step: 10
Training loss: 1.9856891632080078
Validation loss: 2.387775813379595

Epoch: 6| Step: 11
Training loss: 2.048999786376953
Validation loss: 2.3703330588597122

Epoch: 6| Step: 12
Training loss: 3.024305820465088
Validation loss: 2.3909178574879966

Epoch: 6| Step: 13
Training loss: 2.6582627296447754
Validation loss: 2.3477626462136545

Epoch: 34| Step: 0
Training loss: 2.3008551597595215
Validation loss: 2.397281810801516

Epoch: 6| Step: 1
Training loss: 2.736732006072998
Validation loss: 2.3907315256775066

Epoch: 6| Step: 2
Training loss: 3.0983691215515137
Validation loss: 2.3620135963604016

Epoch: 6| Step: 3
Training loss: 2.8742270469665527
Validation loss: 2.371018963475381

Epoch: 6| Step: 4
Training loss: 1.703794002532959
Validation loss: 2.400937969966601

Epoch: 6| Step: 5
Training loss: 1.9362447261810303
Validation loss: 2.3842527866363525

Epoch: 6| Step: 6
Training loss: 2.55425763130188
Validation loss: 2.3722952219747726

Epoch: 6| Step: 7
Training loss: 1.9423348903656006
Validation loss: 2.381888181932511

Epoch: 6| Step: 8
Training loss: 2.592249870300293
Validation loss: 2.388785890353623

Epoch: 6| Step: 9
Training loss: 2.476825714111328
Validation loss: 2.355044500802153

Epoch: 6| Step: 10
Training loss: 2.693891763687134
Validation loss: 2.3602916694456533

Epoch: 6| Step: 11
Training loss: 2.323655843734741
Validation loss: 2.3703360019191617

Epoch: 6| Step: 12
Training loss: 2.5136349201202393
Validation loss: 2.3824620426342054

Epoch: 6| Step: 13
Training loss: 1.83376944065094
Validation loss: 2.3957992830584125

Epoch: 35| Step: 0
Training loss: 2.6061465740203857
Validation loss: 2.37604082527981

Epoch: 6| Step: 1
Training loss: 2.9891340732574463
Validation loss: 2.3688943578350927

Epoch: 6| Step: 2
Training loss: 1.8450894355773926
Validation loss: 2.369452461119621

Epoch: 6| Step: 3
Training loss: 2.3963050842285156
Validation loss: 2.3513775128190235

Epoch: 6| Step: 4
Training loss: 1.977380633354187
Validation loss: 2.373395155834895

Epoch: 6| Step: 5
Training loss: 2.4434001445770264
Validation loss: 2.3784286898951374

Epoch: 6| Step: 6
Training loss: 2.1948418617248535
Validation loss: 2.365406108158891

Epoch: 6| Step: 7
Training loss: 2.516843795776367
Validation loss: 2.3781115521666822

Epoch: 6| Step: 8
Training loss: 2.164614677429199
Validation loss: 2.353891982827135

Epoch: 6| Step: 9
Training loss: 3.407406806945801
Validation loss: 2.374265178557365

Epoch: 6| Step: 10
Training loss: 1.8302148580551147
Validation loss: 2.3726859182439823

Epoch: 6| Step: 11
Training loss: 2.655728340148926
Validation loss: 2.3519607179908344

Epoch: 6| Step: 12
Training loss: 2.2940785884857178
Validation loss: 2.342291807615629

Epoch: 6| Step: 13
Training loss: 2.544750690460205
Validation loss: 2.333664140393657

Epoch: 36| Step: 0
Training loss: 3.157196521759033
Validation loss: 2.367177999147805

Epoch: 6| Step: 1
Training loss: 2.8446879386901855
Validation loss: 2.3504242474032986

Epoch: 6| Step: 2
Training loss: 1.940718412399292
Validation loss: 2.366589420585222

Epoch: 6| Step: 3
Training loss: 1.6554973125457764
Validation loss: 2.3643759194240777

Epoch: 6| Step: 4
Training loss: 2.304107904434204
Validation loss: 2.338622272655528

Epoch: 6| Step: 5
Training loss: 3.0145061016082764
Validation loss: 2.352629392377792

Epoch: 6| Step: 6
Training loss: 2.491089344024658
Validation loss: 2.361796691853513

Epoch: 6| Step: 7
Training loss: 2.1715025901794434
Validation loss: 2.3376209812779583

Epoch: 6| Step: 8
Training loss: 2.5120480060577393
Validation loss: 2.363553882927023

Epoch: 6| Step: 9
Training loss: 1.6774182319641113
Validation loss: 2.368011771991689

Epoch: 6| Step: 10
Training loss: 2.7868123054504395
Validation loss: 2.3578109459210466

Epoch: 6| Step: 11
Training loss: 1.6850451231002808
Validation loss: 2.3779905739650933

Epoch: 6| Step: 12
Training loss: 2.6396102905273438
Validation loss: 2.3332567061147382

Epoch: 6| Step: 13
Training loss: 3.253922700881958
Validation loss: 2.3649292940734536

Epoch: 37| Step: 0
Training loss: 2.4433798789978027
Validation loss: 2.3604410386854604

Epoch: 6| Step: 1
Training loss: 2.849595069885254
Validation loss: 2.357505506084811

Epoch: 6| Step: 2
Training loss: 2.696101427078247
Validation loss: 2.351515636649183

Epoch: 6| Step: 3
Training loss: 2.0932536125183105
Validation loss: 2.3756511647214174

Epoch: 6| Step: 4
Training loss: 2.640763759613037
Validation loss: 2.3396901263985583

Epoch: 6| Step: 5
Training loss: 1.8057968616485596
Validation loss: 2.3369259654834704

Epoch: 6| Step: 6
Training loss: 2.2447080612182617
Validation loss: 2.3363628464360393

Epoch: 6| Step: 7
Training loss: 2.6119768619537354
Validation loss: 2.343875474827264

Epoch: 6| Step: 8
Training loss: 1.9169062376022339
Validation loss: 2.3757876375670075

Epoch: 6| Step: 9
Training loss: 1.9702404737472534
Validation loss: 2.3528794575763006

Epoch: 6| Step: 10
Training loss: 2.497920513153076
Validation loss: 2.3401177942111926

Epoch: 6| Step: 11
Training loss: 2.9025588035583496
Validation loss: 2.353041651428387

Epoch: 6| Step: 12
Training loss: 2.1827797889709473
Validation loss: 2.3416331660362983

Epoch: 6| Step: 13
Training loss: 2.821352958679199
Validation loss: 2.3567298202104467

Epoch: 38| Step: 0
Training loss: 2.4153904914855957
Validation loss: 2.3542550507412163

Epoch: 6| Step: 1
Training loss: 1.790860652923584
Validation loss: 2.321358819161692

Epoch: 6| Step: 2
Training loss: 1.726553201675415
Validation loss: 2.367453744334559

Epoch: 6| Step: 3
Training loss: 2.065425395965576
Validation loss: 2.3292649958723333

Epoch: 6| Step: 4
Training loss: 2.2263026237487793
Validation loss: 2.355131072382773

Epoch: 6| Step: 5
Training loss: 2.062080144882202
Validation loss: 2.364401771176246

Epoch: 6| Step: 6
Training loss: 2.5606789588928223
Validation loss: 2.332239020255304

Epoch: 6| Step: 7
Training loss: 3.4686033725738525
Validation loss: 2.3046278876643025

Epoch: 6| Step: 8
Training loss: 2.259282350540161
Validation loss: 2.329917948733094

Epoch: 6| Step: 9
Training loss: 2.6848044395446777
Validation loss: 2.320540738362138

Epoch: 6| Step: 10
Training loss: 2.65535044670105
Validation loss: 2.3442452261524815

Epoch: 6| Step: 11
Training loss: 2.2525553703308105
Validation loss: 2.37674024797255

Epoch: 6| Step: 12
Training loss: 3.2464418411254883
Validation loss: 2.3393079978163525

Epoch: 6| Step: 13
Training loss: 2.42002534866333
Validation loss: 2.3286881267383532

Epoch: 39| Step: 0
Training loss: 3.047046422958374
Validation loss: 2.3315140919018815

Epoch: 6| Step: 1
Training loss: 2.7954390048980713
Validation loss: 2.299510561009889

Epoch: 6| Step: 2
Training loss: 2.603281021118164
Validation loss: 2.324465456829276

Epoch: 6| Step: 3
Training loss: 2.328176736831665
Validation loss: 2.3644882837931314

Epoch: 6| Step: 4
Training loss: 3.0087084770202637
Validation loss: 2.3460025864262737

Epoch: 6| Step: 5
Training loss: 2.168362617492676
Validation loss: 2.339765743542743

Epoch: 6| Step: 6
Training loss: 1.8172087669372559
Validation loss: 2.330759304825978

Epoch: 6| Step: 7
Training loss: 2.185985565185547
Validation loss: 2.305643250865321

Epoch: 6| Step: 8
Training loss: 3.030006170272827
Validation loss: 2.3689240550482147

Epoch: 6| Step: 9
Training loss: 2.2756426334381104
Validation loss: 2.3097080082021733

Epoch: 6| Step: 10
Training loss: 1.9810726642608643
Validation loss: 2.331849149478379

Epoch: 6| Step: 11
Training loss: 1.655946969985962
Validation loss: 2.329109985341308

Epoch: 6| Step: 12
Training loss: 2.235624074935913
Validation loss: 2.3350160737191477

Epoch: 6| Step: 13
Training loss: 1.707895040512085
Validation loss: 2.309956499325332

Epoch: 40| Step: 0
Training loss: 2.151475429534912
Validation loss: 2.316988733506972

Epoch: 6| Step: 1
Training loss: 1.9034639596939087
Validation loss: 2.3377132467044297

Epoch: 6| Step: 2
Training loss: 2.1433587074279785
Validation loss: 2.318339373475762

Epoch: 6| Step: 3
Training loss: 2.5575923919677734
Validation loss: 2.34061328570048

Epoch: 6| Step: 4
Training loss: 3.187939405441284
Validation loss: 2.3735082380233274

Epoch: 6| Step: 5
Training loss: 2.5010104179382324
Validation loss: 2.3227972779222714

Epoch: 6| Step: 6
Training loss: 0.9993376135826111
Validation loss: 2.3650501774203394

Epoch: 6| Step: 7
Training loss: 1.967719554901123
Validation loss: 2.3494321325773835

Epoch: 6| Step: 8
Training loss: 2.8907647132873535
Validation loss: 2.346270945764357

Epoch: 6| Step: 9
Training loss: 2.4183311462402344
Validation loss: 2.2877764163478727

Epoch: 6| Step: 10
Training loss: 2.495285987854004
Validation loss: 2.3061322191710114

Epoch: 6| Step: 11
Training loss: 2.8119566440582275
Validation loss: 2.3321379282141246

Epoch: 6| Step: 12
Training loss: 2.804872989654541
Validation loss: 2.3631319281875447

Epoch: 6| Step: 13
Training loss: 2.720597743988037
Validation loss: 2.352939223730436

Epoch: 41| Step: 0
Training loss: 2.5684454441070557
Validation loss: 2.3370591017507736

Epoch: 6| Step: 1
Training loss: 1.7734503746032715
Validation loss: 2.3307671021389704

Epoch: 6| Step: 2
Training loss: 2.4755005836486816
Validation loss: 2.3321378077230146

Epoch: 6| Step: 3
Training loss: 2.9357357025146484
Validation loss: 2.322147274530062

Epoch: 6| Step: 4
Training loss: 2.5153207778930664
Validation loss: 2.3176890393739105

Epoch: 6| Step: 5
Training loss: 3.2464137077331543
Validation loss: 2.331260270969842

Epoch: 6| Step: 6
Training loss: 2.068695306777954
Validation loss: 2.3100408379749586

Epoch: 6| Step: 7
Training loss: 2.3609883785247803
Validation loss: 2.3608404846601587

Epoch: 6| Step: 8
Training loss: 2.561316967010498
Validation loss: 2.34527212701818

Epoch: 6| Step: 9
Training loss: 1.9667961597442627
Validation loss: 2.3260966577837543

Epoch: 6| Step: 10
Training loss: 2.4585068225860596
Validation loss: 2.3037343409753617

Epoch: 6| Step: 11
Training loss: 2.3666672706604004
Validation loss: 2.328245767983057

Epoch: 6| Step: 12
Training loss: 2.02288818359375
Validation loss: 2.3026371361106954

Epoch: 6| Step: 13
Training loss: 1.318981647491455
Validation loss: 2.3311576997080157

Epoch: 42| Step: 0
Training loss: 2.3311495780944824
Validation loss: 2.31327800596914

Epoch: 6| Step: 1
Training loss: 2.9178380966186523
Validation loss: 2.305823269710746

Epoch: 6| Step: 2
Training loss: 2.758612871170044
Validation loss: 2.297966721237347

Epoch: 6| Step: 3
Training loss: 2.129927635192871
Validation loss: 2.312334311905728

Epoch: 6| Step: 4
Training loss: 1.9968904256820679
Validation loss: 2.3541526845706406

Epoch: 6| Step: 5
Training loss: 2.2445833683013916
Validation loss: 2.350875896792258

Epoch: 6| Step: 6
Training loss: 1.8698208332061768
Validation loss: 2.322555136936967

Epoch: 6| Step: 7
Training loss: 3.296037197113037
Validation loss: 2.3147799212445497

Epoch: 6| Step: 8
Training loss: 1.9433460235595703
Validation loss: 2.32438459063089

Epoch: 6| Step: 9
Training loss: 2.23641300201416
Validation loss: 2.3065873294748287

Epoch: 6| Step: 10
Training loss: 2.258178234100342
Validation loss: 2.3314939442501275

Epoch: 6| Step: 11
Training loss: 2.7804675102233887
Validation loss: 2.295870345125916

Epoch: 6| Step: 12
Training loss: 2.4266910552978516
Validation loss: 2.311275392450312

Epoch: 6| Step: 13
Training loss: 1.7615368366241455
Validation loss: 2.3076022389114543

Epoch: 43| Step: 0
Training loss: 2.098660945892334
Validation loss: 2.2836317375142086

Epoch: 6| Step: 1
Training loss: 2.1762688159942627
Validation loss: 2.3144918013644475

Epoch: 6| Step: 2
Training loss: 2.0713884830474854
Validation loss: 2.2960512894456104

Epoch: 6| Step: 3
Training loss: 2.591923475265503
Validation loss: 2.3247663051851335

Epoch: 6| Step: 4
Training loss: 2.812683582305908
Validation loss: 2.3415916888944563

Epoch: 6| Step: 5
Training loss: 2.36366868019104
Validation loss: 2.319860622447024

Epoch: 6| Step: 6
Training loss: 2.8864967823028564
Validation loss: 2.32181691867049

Epoch: 6| Step: 7
Training loss: 2.118337392807007
Validation loss: 2.299729315183496

Epoch: 6| Step: 8
Training loss: 3.186366558074951
Validation loss: 2.351735189396848

Epoch: 6| Step: 9
Training loss: 2.5897817611694336
Validation loss: 2.3117060968952794

Epoch: 6| Step: 10
Training loss: 1.3657901287078857
Validation loss: 2.3077646493911743

Epoch: 6| Step: 11
Training loss: 2.59604811668396
Validation loss: 2.3270880227447837

Epoch: 6| Step: 12
Training loss: 1.8000551462173462
Validation loss: 2.298894184891896

Epoch: 6| Step: 13
Training loss: 1.9415736198425293
Validation loss: 2.3132268536475395

Epoch: 44| Step: 0
Training loss: 2.17584228515625
Validation loss: 2.343213371051255

Epoch: 6| Step: 1
Training loss: 1.893673062324524
Validation loss: 2.308992132063835

Epoch: 6| Step: 2
Training loss: 2.9612619876861572
Validation loss: 2.312460381497619

Epoch: 6| Step: 3
Training loss: 2.4064316749572754
Validation loss: 2.2949287058204733

Epoch: 6| Step: 4
Training loss: 2.4445645809173584
Validation loss: 2.3076821860446723

Epoch: 6| Step: 5
Training loss: 2.892118453979492
Validation loss: 2.302851535940683

Epoch: 6| Step: 6
Training loss: 2.303718090057373
Validation loss: 2.3008898201809136

Epoch: 6| Step: 7
Training loss: 1.7044914960861206
Validation loss: 2.3265465151879097

Epoch: 6| Step: 8
Training loss: 2.786853313446045
Validation loss: 2.3170815398616176

Epoch: 6| Step: 9
Training loss: 2.3298864364624023
Validation loss: 2.3227849980836273

Epoch: 6| Step: 10
Training loss: 2.5433578491210938
Validation loss: 2.28076006520179

Epoch: 6| Step: 11
Training loss: 1.8475754261016846
Validation loss: 2.3174277223566526

Epoch: 6| Step: 12
Training loss: 2.04695463180542
Validation loss: 2.320531169573466

Epoch: 6| Step: 13
Training loss: 2.8225581645965576
Validation loss: 2.3109135884110645

Epoch: 45| Step: 0
Training loss: 3.0178489685058594
Validation loss: 2.3204338935113724

Epoch: 6| Step: 1
Training loss: 2.1375107765197754
Validation loss: 2.3143542197442826

Epoch: 6| Step: 2
Training loss: 2.3640823364257812
Validation loss: 2.332499668162356

Epoch: 6| Step: 3
Training loss: 1.493125081062317
Validation loss: 2.2960844168099026

Epoch: 6| Step: 4
Training loss: 2.0999937057495117
Validation loss: 2.290500181977467

Epoch: 6| Step: 5
Training loss: 2.3326311111450195
Validation loss: 2.3326249455892913

Epoch: 6| Step: 6
Training loss: 2.1645281314849854
Validation loss: 2.312196527757952

Epoch: 6| Step: 7
Training loss: 3.1433284282684326
Validation loss: 2.3148260296031995

Epoch: 6| Step: 8
Training loss: 2.1110496520996094
Validation loss: 2.3013696901259886

Epoch: 6| Step: 9
Training loss: 1.7823699712753296
Validation loss: 2.2617310913660194

Epoch: 6| Step: 10
Training loss: 2.5190300941467285
Validation loss: 2.3470529638310915

Epoch: 6| Step: 11
Training loss: 2.382798671722412
Validation loss: 2.3103328622797483

Epoch: 6| Step: 12
Training loss: 2.342268228530884
Validation loss: 2.3071611517219135

Epoch: 6| Step: 13
Training loss: 2.8846278190612793
Validation loss: 2.2786227221130044

Epoch: 46| Step: 0
Training loss: 3.195209503173828
Validation loss: 2.331547483321159

Epoch: 6| Step: 1
Training loss: 2.0447587966918945
Validation loss: 2.353671173895559

Epoch: 6| Step: 2
Training loss: 2.232008457183838
Validation loss: 2.3025660719922794

Epoch: 6| Step: 3
Training loss: 2.600475311279297
Validation loss: 2.3017075574526222

Epoch: 6| Step: 4
Training loss: 2.031543254852295
Validation loss: 2.3596980546110418

Epoch: 6| Step: 5
Training loss: 2.0186960697174072
Validation loss: 2.2858238502215316

Epoch: 6| Step: 6
Training loss: 2.261735439300537
Validation loss: 2.3390075288793093

Epoch: 6| Step: 7
Training loss: 1.5644649267196655
Validation loss: 2.2843037600158365

Epoch: 6| Step: 8
Training loss: 2.5686681270599365
Validation loss: 2.3159885534676175

Epoch: 6| Step: 9
Training loss: 2.108198404312134
Validation loss: 2.2873730710757676

Epoch: 6| Step: 10
Training loss: 2.833444595336914
Validation loss: 2.3110707139456146

Epoch: 6| Step: 11
Training loss: 2.716052532196045
Validation loss: 2.2990885165429886

Epoch: 6| Step: 12
Training loss: 2.435624122619629
Validation loss: 2.276529973553073

Epoch: 6| Step: 13
Training loss: 1.8661324977874756
Validation loss: 2.3078563751712924

Epoch: 47| Step: 0
Training loss: 1.9378855228424072
Validation loss: 2.3080666872762863

Epoch: 6| Step: 1
Training loss: 3.329686164855957
Validation loss: 2.2746840420589653

Epoch: 6| Step: 2
Training loss: 2.1439828872680664
Validation loss: 2.2855151827617357

Epoch: 6| Step: 3
Training loss: 2.577104330062866
Validation loss: 2.2959140346896265

Epoch: 6| Step: 4
Training loss: 2.66249942779541
Validation loss: 2.329075187765142

Epoch: 6| Step: 5
Training loss: 2.5280649662017822
Validation loss: 2.272750445591506

Epoch: 6| Step: 6
Training loss: 2.2570581436157227
Validation loss: 2.2866484875320108

Epoch: 6| Step: 7
Training loss: 2.01298451423645
Validation loss: 2.2916443219748874

Epoch: 6| Step: 8
Training loss: 2.3837761878967285
Validation loss: 2.292820438261955

Epoch: 6| Step: 9
Training loss: 1.4091758728027344
Validation loss: 2.279061241816449

Epoch: 6| Step: 10
Training loss: 2.2038722038269043
Validation loss: 2.313510035955778

Epoch: 6| Step: 11
Training loss: 2.454559087753296
Validation loss: 2.2878806424397293

Epoch: 6| Step: 12
Training loss: 2.2503130435943604
Validation loss: 2.325995114541823

Epoch: 6| Step: 13
Training loss: 2.894900321960449
Validation loss: 2.3361266018241964

Epoch: 48| Step: 0
Training loss: 2.2583470344543457
Validation loss: 2.312605240011728

Epoch: 6| Step: 1
Training loss: 1.925262689590454
Validation loss: 2.3028683059959003

Epoch: 6| Step: 2
Training loss: 1.7250771522521973
Validation loss: 2.2581620139460408

Epoch: 6| Step: 3
Training loss: 2.8022727966308594
Validation loss: 2.298342921400583

Epoch: 6| Step: 4
Training loss: 2.758481025695801
Validation loss: 2.3154686086921283

Epoch: 6| Step: 5
Training loss: 2.4063613414764404
Validation loss: 2.3080167180748394

Epoch: 6| Step: 6
Training loss: 2.8254618644714355
Validation loss: 2.3334259076785018

Epoch: 6| Step: 7
Training loss: 2.421757459640503
Validation loss: 2.2529043433486775

Epoch: 6| Step: 8
Training loss: 2.7532033920288086
Validation loss: 2.2840214954909457

Epoch: 6| Step: 9
Training loss: 1.9008009433746338
Validation loss: 2.292799436917869

Epoch: 6| Step: 10
Training loss: 2.860668182373047
Validation loss: 2.321210333096084

Epoch: 6| Step: 11
Training loss: 1.6785104274749756
Validation loss: 2.3100734321019982

Epoch: 6| Step: 12
Training loss: 2.3558530807495117
Validation loss: 2.296452045440674

Epoch: 6| Step: 13
Training loss: 1.7714028358459473
Validation loss: 2.3179357013394757

Epoch: 49| Step: 0
Training loss: 1.5856928825378418
Validation loss: 2.2743715342654975

Epoch: 6| Step: 1
Training loss: 2.499267578125
Validation loss: 2.2846556581476682

Epoch: 6| Step: 2
Training loss: 1.6142438650131226
Validation loss: 2.281159767540552

Epoch: 6| Step: 3
Training loss: 1.6264115571975708
Validation loss: 2.306441532668247

Epoch: 6| Step: 4
Training loss: 2.9346566200256348
Validation loss: 2.3043567006305983

Epoch: 6| Step: 5
Training loss: 2.236506700515747
Validation loss: 2.3122272363273044

Epoch: 6| Step: 6
Training loss: 2.20809268951416
Validation loss: 2.3154415699743454

Epoch: 6| Step: 7
Training loss: 2.283024311065674
Validation loss: 2.3128721688383367

Epoch: 6| Step: 8
Training loss: 2.8805062770843506
Validation loss: 2.3125869715085594

Epoch: 6| Step: 9
Training loss: 2.5764501094818115
Validation loss: 2.289163327986194

Epoch: 6| Step: 10
Training loss: 3.108628749847412
Validation loss: 2.3118402906643447

Epoch: 6| Step: 11
Training loss: 2.3546652793884277
Validation loss: 2.2951153503951205

Epoch: 6| Step: 12
Training loss: 2.561311721801758
Validation loss: 2.3068560041407102

Epoch: 6| Step: 13
Training loss: 2.0584685802459717
Validation loss: 2.265935315880724

Epoch: 50| Step: 0
Training loss: 2.4447646141052246
Validation loss: 2.3017780498791764

Epoch: 6| Step: 1
Training loss: 1.9215576648712158
Validation loss: 2.287407354641986

Epoch: 6| Step: 2
Training loss: 2.090245246887207
Validation loss: 2.287730989917632

Epoch: 6| Step: 3
Training loss: 2.969113826751709
Validation loss: 2.291814018321294

Epoch: 6| Step: 4
Training loss: 3.1454453468322754
Validation loss: 2.245644023341517

Epoch: 6| Step: 5
Training loss: 3.082613229751587
Validation loss: 2.294604029706729

Epoch: 6| Step: 6
Training loss: 1.9808995723724365
Validation loss: 2.2627243585484003

Epoch: 6| Step: 7
Training loss: 1.847680926322937
Validation loss: 2.302103416894072

Epoch: 6| Step: 8
Training loss: 2.2336959838867188
Validation loss: 2.3325111225087154

Epoch: 6| Step: 9
Training loss: 2.0596885681152344
Validation loss: 2.3064932233543805

Epoch: 6| Step: 10
Training loss: 1.9230448007583618
Validation loss: 2.297782623639671

Epoch: 6| Step: 11
Training loss: 2.455843210220337
Validation loss: 2.238350268333189

Epoch: 6| Step: 12
Training loss: 1.4593842029571533
Validation loss: 2.295754717242333

Epoch: 6| Step: 13
Training loss: 3.2176461219787598
Validation loss: 2.298933941830871

Epoch: 51| Step: 0
Training loss: 2.4672746658325195
Validation loss: 2.3377508194215837

Epoch: 6| Step: 1
Training loss: 1.8149020671844482
Validation loss: 2.2987306528193976

Epoch: 6| Step: 2
Training loss: 2.2199792861938477
Validation loss: 2.3031573500684512

Epoch: 6| Step: 3
Training loss: 2.554795265197754
Validation loss: 2.3368787073319957

Epoch: 6| Step: 4
Training loss: 1.9349443912506104
Validation loss: 2.2888568216754543

Epoch: 6| Step: 5
Training loss: 2.384420394897461
Validation loss: 2.301836666240487

Epoch: 6| Step: 6
Training loss: 3.117161750793457
Validation loss: 2.324822700151833

Epoch: 6| Step: 7
Training loss: 1.5774730443954468
Validation loss: 2.2972904200194986

Epoch: 6| Step: 8
Training loss: 2.1351404190063477
Validation loss: 2.323035596519388

Epoch: 6| Step: 9
Training loss: 3.118138074874878
Validation loss: 2.3452045430419264

Epoch: 6| Step: 10
Training loss: 2.9338529109954834
Validation loss: 2.3305476993642826

Epoch: 6| Step: 11
Training loss: 2.4321484565734863
Validation loss: 2.3374485636270173

Epoch: 6| Step: 12
Training loss: 1.8915190696716309
Validation loss: 2.3271626554509646

Epoch: 6| Step: 13
Training loss: 2.184652090072632
Validation loss: 2.2919391047570015

Epoch: 52| Step: 0
Training loss: 2.627427577972412
Validation loss: 2.330542072173088

Epoch: 6| Step: 1
Training loss: 2.4000277519226074
Validation loss: 2.3283634621609925

Epoch: 6| Step: 2
Training loss: 2.597188711166382
Validation loss: 2.335959449891121

Epoch: 6| Step: 3
Training loss: 2.0918521881103516
Validation loss: 2.298421134230911

Epoch: 6| Step: 4
Training loss: 2.224677801132202
Validation loss: 2.3086810650364047

Epoch: 6| Step: 5
Training loss: 2.8125720024108887
Validation loss: 2.325781158221665

Epoch: 6| Step: 6
Training loss: 1.9428026676177979
Validation loss: 2.3098374925633913

Epoch: 6| Step: 7
Training loss: 2.3620827198028564
Validation loss: 2.334913302493352

Epoch: 6| Step: 8
Training loss: 1.9846001863479614
Validation loss: 2.3170446567637946

Epoch: 6| Step: 9
Training loss: 2.749476671218872
Validation loss: 2.3045430619229554

Epoch: 6| Step: 10
Training loss: 2.4148354530334473
Validation loss: 2.292733492389802

Epoch: 6| Step: 11
Training loss: 1.6230084896087646
Validation loss: 2.310262216034756

Epoch: 6| Step: 12
Training loss: 2.384826183319092
Validation loss: 2.279377063115438

Epoch: 6| Step: 13
Training loss: 1.5839166641235352
Validation loss: 2.2674438671399186

Epoch: 53| Step: 0
Training loss: 2.7411673069000244
Validation loss: 2.2782131677032798

Epoch: 6| Step: 1
Training loss: 2.134204387664795
Validation loss: 2.2704578035621235

Epoch: 6| Step: 2
Training loss: 1.7274247407913208
Validation loss: 2.2582323910087667

Epoch: 6| Step: 3
Training loss: 2.008293628692627
Validation loss: 2.2964831552197857

Epoch: 6| Step: 4
Training loss: 1.8494303226470947
Validation loss: 2.271850780774188

Epoch: 6| Step: 5
Training loss: 2.7575862407684326
Validation loss: 2.2934614663482993

Epoch: 6| Step: 6
Training loss: 2.439620018005371
Validation loss: 2.2904854359165316

Epoch: 6| Step: 7
Training loss: 2.4191062450408936
Validation loss: 2.2874451016867035

Epoch: 6| Step: 8
Training loss: 2.8098607063293457
Validation loss: 2.279059076821932

Epoch: 6| Step: 9
Training loss: 1.7260628938674927
Validation loss: 2.2883575911163003

Epoch: 6| Step: 10
Training loss: 2.5119476318359375
Validation loss: 2.2554553977904783

Epoch: 6| Step: 11
Training loss: 3.115875720977783
Validation loss: 2.2915028474664174

Epoch: 6| Step: 12
Training loss: 1.693655252456665
Validation loss: 2.2616981255110873

Epoch: 6| Step: 13
Training loss: 1.9986035823822021
Validation loss: 2.2378111475257465

Epoch: 54| Step: 0
Training loss: 1.364497423171997
Validation loss: 2.2943548028187086

Epoch: 6| Step: 1
Training loss: 1.9063658714294434
Validation loss: 2.2844687815635436

Epoch: 6| Step: 2
Training loss: 3.028458595275879
Validation loss: 2.2896212454765075

Epoch: 6| Step: 3
Training loss: 2.0880813598632812
Validation loss: 2.292641541009308

Epoch: 6| Step: 4
Training loss: 2.2846786975860596
Validation loss: 2.290896523383356

Epoch: 6| Step: 5
Training loss: 2.245171070098877
Validation loss: 2.289198884399988

Epoch: 6| Step: 6
Training loss: 4.193420886993408
Validation loss: 2.2868242468885196

Epoch: 6| Step: 7
Training loss: 1.487324595451355
Validation loss: 2.2858340599203624

Epoch: 6| Step: 8
Training loss: 2.179003953933716
Validation loss: 2.2837820232555432

Epoch: 6| Step: 9
Training loss: 3.0040242671966553
Validation loss: 2.275332135538901

Epoch: 6| Step: 10
Training loss: 2.5722107887268066
Validation loss: 2.2663514332104753

Epoch: 6| Step: 11
Training loss: 1.386950969696045
Validation loss: 2.2743573701509865

Epoch: 6| Step: 12
Training loss: 2.100986957550049
Validation loss: 2.2693066609803068

Epoch: 6| Step: 13
Training loss: 2.311399221420288
Validation loss: 2.266666161116733

Epoch: 55| Step: 0
Training loss: 2.0436758995056152
Validation loss: 2.2970471869232836

Epoch: 6| Step: 1
Training loss: 1.8727662563323975
Validation loss: 2.28898847487665

Epoch: 6| Step: 2
Training loss: 1.8509502410888672
Validation loss: 2.254041406416124

Epoch: 6| Step: 3
Training loss: 2.269240379333496
Validation loss: 2.299926024611278

Epoch: 6| Step: 4
Training loss: 1.8912638425827026
Validation loss: 2.2624921708978634

Epoch: 6| Step: 5
Training loss: 2.3857531547546387
Validation loss: 2.2949972050164336

Epoch: 6| Step: 6
Training loss: 2.522343158721924
Validation loss: 2.328291521277479

Epoch: 6| Step: 7
Training loss: 2.1872780323028564
Validation loss: 2.28159212809737

Epoch: 6| Step: 8
Training loss: 2.0970897674560547
Validation loss: 2.331991018787507

Epoch: 6| Step: 9
Training loss: 2.884331226348877
Validation loss: 2.267162679344095

Epoch: 6| Step: 10
Training loss: 3.363539457321167
Validation loss: 2.311769829001478

Epoch: 6| Step: 11
Training loss: 1.9982422590255737
Validation loss: 2.2911963001374276

Epoch: 6| Step: 12
Training loss: 2.8271684646606445
Validation loss: 2.276535775071831

Epoch: 6| Step: 13
Training loss: 1.8987261056900024
Validation loss: 2.2595422831914758

Epoch: 56| Step: 0
Training loss: 2.148411273956299
Validation loss: 2.3244892269052486

Epoch: 6| Step: 1
Training loss: 2.2250852584838867
Validation loss: 2.245832171491397

Epoch: 6| Step: 2
Training loss: 2.731431007385254
Validation loss: 2.3294860829589186

Epoch: 6| Step: 3
Training loss: 1.589709758758545
Validation loss: 2.2567082656327115

Epoch: 6| Step: 4
Training loss: 3.0461015701293945
Validation loss: 2.2608491682237193

Epoch: 6| Step: 5
Training loss: 2.788238048553467
Validation loss: 2.2605936757979856

Epoch: 6| Step: 6
Training loss: 2.003856658935547
Validation loss: 2.261860934636926

Epoch: 6| Step: 7
Training loss: 2.851632595062256
Validation loss: 2.263894925835312

Epoch: 6| Step: 8
Training loss: 1.6561551094055176
Validation loss: 2.2578496061345583

Epoch: 6| Step: 9
Training loss: 2.141922950744629
Validation loss: 2.266152012732721

Epoch: 6| Step: 10
Training loss: 2.3077187538146973
Validation loss: 2.2588746483607958

Epoch: 6| Step: 11
Training loss: 2.2359564304351807
Validation loss: 2.2321388695829656

Epoch: 6| Step: 12
Training loss: 2.2418816089630127
Validation loss: 2.2673725633211035

Epoch: 6| Step: 13
Training loss: 1.700520634651184
Validation loss: 2.2999006599508305

Epoch: 57| Step: 0
Training loss: 2.6184332370758057
Validation loss: 2.2758702924174647

Epoch: 6| Step: 1
Training loss: 2.192491054534912
Validation loss: 2.2773974275076263

Epoch: 6| Step: 2
Training loss: 3.6277623176574707
Validation loss: 2.298380696645347

Epoch: 6| Step: 3
Training loss: 1.7647578716278076
Validation loss: 2.2525461514790854

Epoch: 6| Step: 4
Training loss: 2.6477465629577637
Validation loss: 2.2571506782244612

Epoch: 6| Step: 5
Training loss: 2.631589412689209
Validation loss: 2.2838013723332393

Epoch: 6| Step: 6
Training loss: 2.9405484199523926
Validation loss: 2.243635416030884

Epoch: 6| Step: 7
Training loss: 1.4870283603668213
Validation loss: 2.3071932382481073

Epoch: 6| Step: 8
Training loss: 1.2640221118927002
Validation loss: 2.261694090340727

Epoch: 6| Step: 9
Training loss: 2.5431129932403564
Validation loss: 2.2490339509902464

Epoch: 6| Step: 10
Training loss: 1.8970402479171753
Validation loss: 2.233010594562818

Epoch: 6| Step: 11
Training loss: 2.2983510494232178
Validation loss: 2.2918569964747273

Epoch: 6| Step: 12
Training loss: 1.8180136680603027
Validation loss: 2.258204351189316

Epoch: 6| Step: 13
Training loss: 1.9901351928710938
Validation loss: 2.2869568409458285

Epoch: 58| Step: 0
Training loss: 2.649282932281494
Validation loss: 2.257498380958393

Epoch: 6| Step: 1
Training loss: 3.0374350547790527
Validation loss: 2.279868274606684

Epoch: 6| Step: 2
Training loss: 1.8449777364730835
Validation loss: 2.2209611720936273

Epoch: 6| Step: 3
Training loss: 1.6553270816802979
Validation loss: 2.253187443620415

Epoch: 6| Step: 4
Training loss: 1.7697786092758179
Validation loss: 2.237147303037746

Epoch: 6| Step: 5
Training loss: 1.841576337814331
Validation loss: 2.2455203968991517

Epoch: 6| Step: 6
Training loss: 2.3950252532958984
Validation loss: 2.2775140731565413

Epoch: 6| Step: 7
Training loss: 1.4362986087799072
Validation loss: 2.242769214414781

Epoch: 6| Step: 8
Training loss: 2.699617385864258
Validation loss: 2.2679643861709105

Epoch: 6| Step: 9
Training loss: 3.050413131713867
Validation loss: 2.263527318995486

Epoch: 6| Step: 10
Training loss: 3.161613941192627
Validation loss: 2.27427738840862

Epoch: 6| Step: 11
Training loss: 1.802024245262146
Validation loss: 2.2743491895737185

Epoch: 6| Step: 12
Training loss: 2.5923943519592285
Validation loss: 2.253990396376579

Epoch: 6| Step: 13
Training loss: 1.6808016300201416
Validation loss: 2.2748916072230183

Epoch: 59| Step: 0
Training loss: 1.9822279214859009
Validation loss: 2.2673316309528966

Epoch: 6| Step: 1
Training loss: 3.308262586593628
Validation loss: 2.2927280164534047

Epoch: 6| Step: 2
Training loss: 2.111158609390259
Validation loss: 2.2466253798495055

Epoch: 6| Step: 3
Training loss: 1.9756619930267334
Validation loss: 2.2447539785856843

Epoch: 6| Step: 4
Training loss: 1.6998769044876099
Validation loss: 2.2907592506818872

Epoch: 6| Step: 5
Training loss: 2.278921604156494
Validation loss: 2.2770048725989556

Epoch: 6| Step: 6
Training loss: 2.417982816696167
Validation loss: 2.245889917496712

Epoch: 6| Step: 7
Training loss: 2.691984176635742
Validation loss: 2.2813834951769922

Epoch: 6| Step: 8
Training loss: 1.6904833316802979
Validation loss: 2.206681038743706

Epoch: 6| Step: 9
Training loss: 1.8039023876190186
Validation loss: 2.248497877069699

Epoch: 6| Step: 10
Training loss: 2.3312368392944336
Validation loss: 2.27783300030616

Epoch: 6| Step: 11
Training loss: 2.683994770050049
Validation loss: 2.2660007733170704

Epoch: 6| Step: 12
Training loss: 2.4678962230682373
Validation loss: 2.277389452021609

Epoch: 6| Step: 13
Training loss: 2.4913876056671143
Validation loss: 2.249434514712262

Epoch: 60| Step: 0
Training loss: 2.2663846015930176
Validation loss: 2.277471391103601

Epoch: 6| Step: 1
Training loss: 1.9252374172210693
Validation loss: 2.206030535441573

Epoch: 6| Step: 2
Training loss: 1.8490347862243652
Validation loss: 2.2710591926369617

Epoch: 6| Step: 3
Training loss: 2.497856855392456
Validation loss: 2.2441403609450146

Epoch: 6| Step: 4
Training loss: 2.315028190612793
Validation loss: 2.203869850404801

Epoch: 6| Step: 5
Training loss: 2.9405994415283203
Validation loss: 2.265494672201013

Epoch: 6| Step: 6
Training loss: 2.0644614696502686
Validation loss: 2.2971950218241703

Epoch: 6| Step: 7
Training loss: 2.706763744354248
Validation loss: 2.239745710485725

Epoch: 6| Step: 8
Training loss: 2.4100263118743896
Validation loss: 2.267281342578191

Epoch: 6| Step: 9
Training loss: 2.2396702766418457
Validation loss: 2.2887457160539526

Epoch: 6| Step: 10
Training loss: 2.587294578552246
Validation loss: 2.2317760785420737

Epoch: 6| Step: 11
Training loss: 2.3029050827026367
Validation loss: 2.2563002545346498

Epoch: 6| Step: 12
Training loss: 1.7888832092285156
Validation loss: 2.2410663840591267

Epoch: 6| Step: 13
Training loss: 1.688822627067566
Validation loss: 2.2736208772146576

Epoch: 61| Step: 0
Training loss: 3.8494157791137695
Validation loss: 2.233367343102732

Epoch: 6| Step: 1
Training loss: 2.0194103717803955
Validation loss: 2.270018544248355

Epoch: 6| Step: 2
Training loss: 2.258793592453003
Validation loss: 2.2619980740290817

Epoch: 6| Step: 3
Training loss: 2.1471142768859863
Validation loss: 2.2913282968664683

Epoch: 6| Step: 4
Training loss: 2.291527032852173
Validation loss: 2.2315395160387923

Epoch: 6| Step: 5
Training loss: 2.0222606658935547
Validation loss: 2.258077816296649

Epoch: 6| Step: 6
Training loss: 2.7661259174346924
Validation loss: 2.245683091942982

Epoch: 6| Step: 7
Training loss: 1.8079547882080078
Validation loss: 2.2391607710110244

Epoch: 6| Step: 8
Training loss: 1.743911623954773
Validation loss: 2.2304243118532243

Epoch: 6| Step: 9
Training loss: 2.0857155323028564
Validation loss: 2.290755602621263

Epoch: 6| Step: 10
Training loss: 2.9559850692749023
Validation loss: 2.2729890731073197

Epoch: 6| Step: 11
Training loss: 1.4175843000411987
Validation loss: 2.241014024262787

Epoch: 6| Step: 12
Training loss: 1.3806884288787842
Validation loss: 2.280083207673924

Epoch: 6| Step: 13
Training loss: 3.7218501567840576
Validation loss: 2.2410706320116596

Epoch: 62| Step: 0
Training loss: 1.8824028968811035
Validation loss: 2.234344314503413

Epoch: 6| Step: 1
Training loss: 2.343200445175171
Validation loss: 2.278300013593448

Epoch: 6| Step: 2
Training loss: 2.1660470962524414
Validation loss: 2.2598506981326687

Epoch: 6| Step: 3
Training loss: 1.637778639793396
Validation loss: 2.252811103738764

Epoch: 6| Step: 4
Training loss: 2.737511396408081
Validation loss: 2.2352096060270905

Epoch: 6| Step: 5
Training loss: 2.3378939628601074
Validation loss: 2.241778063517745

Epoch: 6| Step: 6
Training loss: 2.0658059120178223
Validation loss: 2.2351377343618744

Epoch: 6| Step: 7
Training loss: 1.8367807865142822
Validation loss: 2.223246307783229

Epoch: 6| Step: 8
Training loss: 1.9086902141571045
Validation loss: 2.2589982171212473

Epoch: 6| Step: 9
Training loss: 2.9640936851501465
Validation loss: 2.2317163969880793

Epoch: 6| Step: 10
Training loss: 3.177853584289551
Validation loss: 2.2411390889075493

Epoch: 6| Step: 11
Training loss: 1.685834527015686
Validation loss: 2.253974804314234

Epoch: 6| Step: 12
Training loss: 3.0029304027557373
Validation loss: 2.2462935114419587

Epoch: 6| Step: 13
Training loss: 1.7870523929595947
Validation loss: 2.2514709811056814

Epoch: 63| Step: 0
Training loss: 1.775179147720337
Validation loss: 2.2403682444685247

Epoch: 6| Step: 1
Training loss: 2.201795816421509
Validation loss: 2.248574305606145

Epoch: 6| Step: 2
Training loss: 2.658416271209717
Validation loss: 2.304605225081085

Epoch: 6| Step: 3
Training loss: 2.2163338661193848
Validation loss: 2.2880331829030025

Epoch: 6| Step: 4
Training loss: 2.1590170860290527
Validation loss: 2.250249416597428

Epoch: 6| Step: 5
Training loss: 1.7529332637786865
Validation loss: 2.267431764192479

Epoch: 6| Step: 6
Training loss: 2.2153024673461914
Validation loss: 2.256011985963391

Epoch: 6| Step: 7
Training loss: 2.1451754570007324
Validation loss: 2.303305169587494

Epoch: 6| Step: 8
Training loss: 1.9906097650527954
Validation loss: 2.24703989618568

Epoch: 6| Step: 9
Training loss: 2.564286947250366
Validation loss: 2.268826933317287

Epoch: 6| Step: 10
Training loss: 2.2267682552337646
Validation loss: 2.264362931251526

Epoch: 6| Step: 11
Training loss: 2.5432636737823486
Validation loss: 2.286948775732389

Epoch: 6| Step: 12
Training loss: 3.0186595916748047
Validation loss: 2.2720707257588706

Epoch: 6| Step: 13
Training loss: 2.7072041034698486
Validation loss: 2.2613876045391126

Epoch: 64| Step: 0
Training loss: 2.120378017425537
Validation loss: 2.236531415293294

Epoch: 6| Step: 1
Training loss: 2.348566770553589
Validation loss: 2.2729540691580823

Epoch: 6| Step: 2
Training loss: 2.7893567085266113
Validation loss: 2.2505407769192933

Epoch: 6| Step: 3
Training loss: 2.428899049758911
Validation loss: 2.260980298442225

Epoch: 6| Step: 4
Training loss: 1.2579092979431152
Validation loss: 2.2938335839138237

Epoch: 6| Step: 5
Training loss: 1.974792242050171
Validation loss: 2.2391015714214695

Epoch: 6| Step: 6
Training loss: 2.3882334232330322
Validation loss: 2.300836855365384

Epoch: 6| Step: 7
Training loss: 1.708900809288025
Validation loss: 2.250618432157783

Epoch: 6| Step: 8
Training loss: 2.1197288036346436
Validation loss: 2.212626644360122

Epoch: 6| Step: 9
Training loss: 2.6024587154388428
Validation loss: 2.265889040885433

Epoch: 6| Step: 10
Training loss: 1.9805097579956055
Validation loss: 2.255054845604845

Epoch: 6| Step: 11
Training loss: 3.312521457672119
Validation loss: 2.247035650796788

Epoch: 6| Step: 12
Training loss: 2.4663589000701904
Validation loss: 2.2620005940878265

Epoch: 6| Step: 13
Training loss: 2.576218843460083
Validation loss: 2.260750045058548

Epoch: 65| Step: 0
Training loss: 2.3169643878936768
Validation loss: 2.245556628832253

Epoch: 6| Step: 1
Training loss: 2.1652822494506836
Validation loss: 2.214021239229428

Epoch: 6| Step: 2
Training loss: 1.8826334476470947
Validation loss: 2.2512053956267652

Epoch: 6| Step: 3
Training loss: 2.4949417114257812
Validation loss: 2.228751515829435

Epoch: 6| Step: 4
Training loss: 2.031890869140625
Validation loss: 2.2465397927068893

Epoch: 6| Step: 5
Training loss: 2.0488343238830566
Validation loss: 2.253010549852925

Epoch: 6| Step: 6
Training loss: 2.7436933517456055
Validation loss: 2.2209371059171614

Epoch: 6| Step: 7
Training loss: 2.0589678287506104
Validation loss: 2.269226271619079

Epoch: 6| Step: 8
Training loss: 2.6053719520568848
Validation loss: 2.279995576027901

Epoch: 6| Step: 9
Training loss: 2.6120357513427734
Validation loss: 2.2530229296735538

Epoch: 6| Step: 10
Training loss: 1.87876296043396
Validation loss: 2.2335990475070093

Epoch: 6| Step: 11
Training loss: 2.443424701690674
Validation loss: 2.2404257315461353

Epoch: 6| Step: 12
Training loss: 2.301604986190796
Validation loss: 2.27531534882002

Epoch: 6| Step: 13
Training loss: 1.5839694738388062
Validation loss: 2.234670828747493

Epoch: 66| Step: 0
Training loss: 2.0324435234069824
Validation loss: 2.2315694388522895

Epoch: 6| Step: 1
Training loss: 1.4427099227905273
Validation loss: 2.2333688300143004

Epoch: 6| Step: 2
Training loss: 2.6044583320617676
Validation loss: 2.225025914048636

Epoch: 6| Step: 3
Training loss: 1.9805006980895996
Validation loss: 2.1642152519636255

Epoch: 6| Step: 4
Training loss: 2.946956157684326
Validation loss: 2.2067906266899517

Epoch: 6| Step: 5
Training loss: 2.7954869270324707
Validation loss: 2.244616316210839

Epoch: 6| Step: 6
Training loss: 2.137497901916504
Validation loss: 2.225130593904885

Epoch: 6| Step: 7
Training loss: 3.013986110687256
Validation loss: 2.171956846790929

Epoch: 6| Step: 8
Training loss: 1.984094500541687
Validation loss: 2.2241016767358266

Epoch: 6| Step: 9
Training loss: 2.682224750518799
Validation loss: 2.218460388081048

Epoch: 6| Step: 10
Training loss: 2.629544734954834
Validation loss: 2.217011959322037

Epoch: 6| Step: 11
Training loss: 1.7370381355285645
Validation loss: 2.2620555508521294

Epoch: 6| Step: 12
Training loss: 1.8399155139923096
Validation loss: 2.2253137711555726

Epoch: 6| Step: 13
Training loss: 1.9096429347991943
Validation loss: 2.212559582084738

Epoch: 67| Step: 0
Training loss: 1.8793301582336426
Validation loss: 2.2454297952754523

Epoch: 6| Step: 1
Training loss: 2.834838390350342
Validation loss: 2.2133950776951288

Epoch: 6| Step: 2
Training loss: 3.253269910812378
Validation loss: 2.2165092293934157

Epoch: 6| Step: 3
Training loss: 1.8996762037277222
Validation loss: 2.216085567269274

Epoch: 6| Step: 4
Training loss: 2.76918363571167
Validation loss: 2.234975863528508

Epoch: 6| Step: 5
Training loss: 2.2177727222442627
Validation loss: 2.228802957842427

Epoch: 6| Step: 6
Training loss: 2.1765823364257812
Validation loss: 2.189131111227056

Epoch: 6| Step: 7
Training loss: 2.2086143493652344
Validation loss: 2.2404746163275933

Epoch: 6| Step: 8
Training loss: 1.5940513610839844
Validation loss: 2.2158460668338242

Epoch: 6| Step: 9
Training loss: 2.241321086883545
Validation loss: 2.233865932751727

Epoch: 6| Step: 10
Training loss: 1.5263407230377197
Validation loss: 2.2481598110609156

Epoch: 6| Step: 11
Training loss: 2.2525782585144043
Validation loss: 2.243159446665036

Epoch: 6| Step: 12
Training loss: 2.750215768814087
Validation loss: 2.1984555849464993

Epoch: 6| Step: 13
Training loss: 2.375626802444458
Validation loss: 2.220275702015046

Epoch: 68| Step: 0
Training loss: 2.842383861541748
Validation loss: 2.2469718943360033

Epoch: 6| Step: 1
Training loss: 1.5549476146697998
Validation loss: 2.240843285796463

Epoch: 6| Step: 2
Training loss: 1.786173701286316
Validation loss: 2.260679632104853

Epoch: 6| Step: 3
Training loss: 2.594646453857422
Validation loss: 2.2376975064636557

Epoch: 6| Step: 4
Training loss: 2.9130454063415527
Validation loss: 2.2480989681777133

Epoch: 6| Step: 5
Training loss: 2.169956684112549
Validation loss: 2.2336229778105214

Epoch: 6| Step: 6
Training loss: 2.894017457962036
Validation loss: 2.21143848921663

Epoch: 6| Step: 7
Training loss: 2.2239935398101807
Validation loss: 2.2267282303943428

Epoch: 6| Step: 8
Training loss: 2.232215404510498
Validation loss: 2.230480096673453

Epoch: 6| Step: 9
Training loss: 2.251617908477783
Validation loss: 2.2153335745616625

Epoch: 6| Step: 10
Training loss: 2.0900635719299316
Validation loss: 2.210512427873509

Epoch: 6| Step: 11
Training loss: 1.895369529724121
Validation loss: 2.2322273331303752

Epoch: 6| Step: 12
Training loss: 1.8145767450332642
Validation loss: 2.229158268179945

Epoch: 6| Step: 13
Training loss: 2.351959228515625
Validation loss: 2.2007068369978215

Epoch: 69| Step: 0
Training loss: 1.9077563285827637
Validation loss: 2.2128116725593485

Epoch: 6| Step: 1
Training loss: 2.178966522216797
Validation loss: 2.2209876891105407

Epoch: 6| Step: 2
Training loss: 2.503594398498535
Validation loss: 2.204706286871305

Epoch: 6| Step: 3
Training loss: 2.172321319580078
Validation loss: 2.235597336164085

Epoch: 6| Step: 4
Training loss: 2.043717384338379
Validation loss: 2.2113129272255847

Epoch: 6| Step: 5
Training loss: 1.566196322441101
Validation loss: 2.193634171639719

Epoch: 6| Step: 6
Training loss: 2.186384677886963
Validation loss: 2.228044230450866

Epoch: 6| Step: 7
Training loss: 2.4101574420928955
Validation loss: 2.197699317368128

Epoch: 6| Step: 8
Training loss: 1.9793645143508911
Validation loss: 2.1911570282392603

Epoch: 6| Step: 9
Training loss: 2.603006601333618
Validation loss: 2.2240161126659763

Epoch: 6| Step: 10
Training loss: 2.6080055236816406
Validation loss: 2.2325574249349613

Epoch: 6| Step: 11
Training loss: 2.576572895050049
Validation loss: 2.2147758519777687

Epoch: 6| Step: 12
Training loss: 2.4794728755950928
Validation loss: 2.256390287030128

Epoch: 6| Step: 13
Training loss: 1.2056788206100464
Validation loss: 2.2127734012501215

Epoch: 70| Step: 0
Training loss: 2.202733039855957
Validation loss: 2.216074679487495

Epoch: 6| Step: 1
Training loss: 2.0489110946655273
Validation loss: 2.174428896237445

Epoch: 6| Step: 2
Training loss: 1.9101024866104126
Validation loss: 2.215842305973012

Epoch: 6| Step: 3
Training loss: 2.5972490310668945
Validation loss: 2.195198914056183

Epoch: 6| Step: 4
Training loss: 1.870252251625061
Validation loss: 2.235777303736697

Epoch: 6| Step: 5
Training loss: 2.6206183433532715
Validation loss: 2.2545515555207447

Epoch: 6| Step: 6
Training loss: 1.9318910837173462
Validation loss: 2.2504889862511748

Epoch: 6| Step: 7
Training loss: 2.476073741912842
Validation loss: 2.2410860728192072

Epoch: 6| Step: 8
Training loss: 2.1006057262420654
Validation loss: 2.239028330772154

Epoch: 6| Step: 9
Training loss: 1.5189733505249023
Validation loss: 2.2271518399638515

Epoch: 6| Step: 10
Training loss: 2.908982038497925
Validation loss: 2.170661582741686

Epoch: 6| Step: 11
Training loss: 2.646933078765869
Validation loss: 2.2137124640967256

Epoch: 6| Step: 12
Training loss: 1.8992924690246582
Validation loss: 2.245862612160303

Epoch: 6| Step: 13
Training loss: 2.1563186645507812
Validation loss: 2.2046115975226126

Epoch: 71| Step: 0
Training loss: 2.71449875831604
Validation loss: 2.2581980228424072

Epoch: 6| Step: 1
Training loss: 2.4653916358947754
Validation loss: 2.2207031301272813

Epoch: 6| Step: 2
Training loss: 2.2428250312805176
Validation loss: 2.1831895394991805

Epoch: 6| Step: 3
Training loss: 1.70401930809021
Validation loss: 2.2053373295773744

Epoch: 6| Step: 4
Training loss: 2.0882458686828613
Validation loss: 2.179484699362068

Epoch: 6| Step: 5
Training loss: 1.9715272188186646
Validation loss: 2.2282056347016366

Epoch: 6| Step: 6
Training loss: 2.6297590732574463
Validation loss: 2.2174783957901822

Epoch: 6| Step: 7
Training loss: 2.776127338409424
Validation loss: 2.210394526040682

Epoch: 6| Step: 8
Training loss: 1.3593428134918213
Validation loss: 2.2258644104003906

Epoch: 6| Step: 9
Training loss: 1.9419658184051514
Validation loss: 2.225825978863624

Epoch: 6| Step: 10
Training loss: 2.0691633224487305
Validation loss: 2.213931523343568

Epoch: 6| Step: 11
Training loss: 2.597132444381714
Validation loss: 2.2059535159859607

Epoch: 6| Step: 12
Training loss: 2.0849404335021973
Validation loss: 2.234422799079649

Epoch: 6| Step: 13
Training loss: 2.53914213180542
Validation loss: 2.197093020203293

Epoch: 72| Step: 0
Training loss: 2.1449952125549316
Validation loss: 2.2264153957366943

Epoch: 6| Step: 1
Training loss: 2.3776397705078125
Validation loss: 2.201835340069186

Epoch: 6| Step: 2
Training loss: 2.9340744018554688
Validation loss: 2.194068395963279

Epoch: 6| Step: 3
Training loss: 2.0469517707824707
Validation loss: 2.130943534194782

Epoch: 6| Step: 4
Training loss: 1.9035354852676392
Validation loss: 2.192362121356431

Epoch: 6| Step: 5
Training loss: 1.5252989530563354
Validation loss: 2.211460189152789

Epoch: 6| Step: 6
Training loss: 2.5765864849090576
Validation loss: 2.2314675879734818

Epoch: 6| Step: 7
Training loss: 1.7381879091262817
Validation loss: 2.17983849458797

Epoch: 6| Step: 8
Training loss: 2.5763559341430664
Validation loss: 2.1719475100117345

Epoch: 6| Step: 9
Training loss: 3.0135092735290527
Validation loss: 2.2259035777020197

Epoch: 6| Step: 10
Training loss: 2.335590362548828
Validation loss: 2.1991622576149563

Epoch: 6| Step: 11
Training loss: 1.803560733795166
Validation loss: 2.2107040805201374

Epoch: 6| Step: 12
Training loss: 2.5423994064331055
Validation loss: 2.1565642536327405

Epoch: 6| Step: 13
Training loss: 1.244748592376709
Validation loss: 2.1613119174075384

Epoch: 73| Step: 0
Training loss: 1.7078933715820312
Validation loss: 2.225798181308213

Epoch: 6| Step: 1
Training loss: 1.2702014446258545
Validation loss: 2.1671897557473954

Epoch: 6| Step: 2
Training loss: 2.8898634910583496
Validation loss: 2.1978859311790875

Epoch: 6| Step: 3
Training loss: 2.628870964050293
Validation loss: 2.1908368654148553

Epoch: 6| Step: 4
Training loss: 2.1738264560699463
Validation loss: 2.189092707890336

Epoch: 6| Step: 5
Training loss: 3.1363682746887207
Validation loss: 2.17364320447368

Epoch: 6| Step: 6
Training loss: 1.4290666580200195
Validation loss: 2.2077244174095894

Epoch: 6| Step: 7
Training loss: 2.0324764251708984
Validation loss: 2.1880894053366875

Epoch: 6| Step: 8
Training loss: 2.2560646533966064
Validation loss: 2.1937610974875827

Epoch: 6| Step: 9
Training loss: 1.825059175491333
Validation loss: 2.1997721105493526

Epoch: 6| Step: 10
Training loss: 2.0680041313171387
Validation loss: 2.225702202448281

Epoch: 6| Step: 11
Training loss: 2.28558611869812
Validation loss: 2.1991941762226883

Epoch: 6| Step: 12
Training loss: 3.0966944694519043
Validation loss: 2.1592366695404053

Epoch: 6| Step: 13
Training loss: 2.366128444671631
Validation loss: 2.1762088165488294

Epoch: 74| Step: 0
Training loss: 1.2174582481384277
Validation loss: 2.243468657616646

Epoch: 6| Step: 1
Training loss: 2.4750568866729736
Validation loss: 2.206549161223955

Epoch: 6| Step: 2
Training loss: 2.9076709747314453
Validation loss: 2.1544473914689917

Epoch: 6| Step: 3
Training loss: 1.8785426616668701
Validation loss: 2.2037726243336997

Epoch: 6| Step: 4
Training loss: 2.6543195247650146
Validation loss: 2.2386958470908542

Epoch: 6| Step: 5
Training loss: 2.148313522338867
Validation loss: 2.180578067738523

Epoch: 6| Step: 6
Training loss: 2.3566784858703613
Validation loss: 2.200996078470702

Epoch: 6| Step: 7
Training loss: 1.6287891864776611
Validation loss: 2.244309353572066

Epoch: 6| Step: 8
Training loss: 2.0482449531555176
Validation loss: 2.2077968312847998

Epoch: 6| Step: 9
Training loss: 2.667637586593628
Validation loss: 2.206207436899985

Epoch: 6| Step: 10
Training loss: 1.9368306398391724
Validation loss: 2.220117647160766

Epoch: 6| Step: 11
Training loss: 2.275407314300537
Validation loss: 2.24158751580023

Epoch: 6| Step: 12
Training loss: 2.471766948699951
Validation loss: 2.2540718099122405

Epoch: 6| Step: 13
Training loss: 2.197115182876587
Validation loss: 2.227268490740048

Epoch: 75| Step: 0
Training loss: 2.3547494411468506
Validation loss: 2.2106015182310537

Epoch: 6| Step: 1
Training loss: 2.8045952320098877
Validation loss: 2.2058022047883723

Epoch: 6| Step: 2
Training loss: 2.4077608585357666
Validation loss: 2.183452365218952

Epoch: 6| Step: 3
Training loss: 2.3787765502929688
Validation loss: 2.2154962196145007

Epoch: 6| Step: 4
Training loss: 1.8074954748153687
Validation loss: 2.21364777575257

Epoch: 6| Step: 5
Training loss: 2.69382905960083
Validation loss: 2.237270716697939

Epoch: 6| Step: 6
Training loss: 1.770540475845337
Validation loss: 2.1728776372889036

Epoch: 6| Step: 7
Training loss: 1.4361425638198853
Validation loss: 2.208447171795753

Epoch: 6| Step: 8
Training loss: 1.6700228452682495
Validation loss: 2.195986504195839

Epoch: 6| Step: 9
Training loss: 2.81187105178833
Validation loss: 2.1489050196063135

Epoch: 6| Step: 10
Training loss: 1.9745569229125977
Validation loss: 2.2095742661465883

Epoch: 6| Step: 11
Training loss: 1.7736659049987793
Validation loss: 2.1420463515866186

Epoch: 6| Step: 12
Training loss: 2.828495502471924
Validation loss: 2.175263394591629

Epoch: 6| Step: 13
Training loss: 2.3161282539367676
Validation loss: 2.218870419327931

Epoch: 76| Step: 0
Training loss: 2.001701831817627
Validation loss: 2.133730547402495

Epoch: 6| Step: 1
Training loss: 2.0093796253204346
Validation loss: 2.2011890872832267

Epoch: 6| Step: 2
Training loss: 2.6871891021728516
Validation loss: 2.1963174394381944

Epoch: 6| Step: 3
Training loss: 2.560450553894043
Validation loss: 2.1624198934083343

Epoch: 6| Step: 4
Training loss: 1.6060047149658203
Validation loss: 2.147124103320542

Epoch: 6| Step: 5
Training loss: 2.2305409908294678
Validation loss: 2.12224930332553

Epoch: 6| Step: 6
Training loss: 1.728885531425476
Validation loss: 2.1637452187076693

Epoch: 6| Step: 7
Training loss: 2.823981523513794
Validation loss: 2.1545844872792563

Epoch: 6| Step: 8
Training loss: 2.0813159942626953
Validation loss: 2.160041811645672

Epoch: 6| Step: 9
Training loss: 2.167520046234131
Validation loss: 2.156980561953719

Epoch: 6| Step: 10
Training loss: 1.8750965595245361
Validation loss: 2.1980819420147966

Epoch: 6| Step: 11
Training loss: 2.749401330947876
Validation loss: 2.1818888828318608

Epoch: 6| Step: 12
Training loss: 1.8696321249008179
Validation loss: 2.192828119442027

Epoch: 6| Step: 13
Training loss: 2.2467565536499023
Validation loss: 2.1719264497039137

Epoch: 77| Step: 0
Training loss: 2.674314498901367
Validation loss: 2.1642625460060696

Epoch: 6| Step: 1
Training loss: 2.2809693813323975
Validation loss: 2.196742485928279

Epoch: 6| Step: 2
Training loss: 2.2682104110717773
Validation loss: 2.144082320633755

Epoch: 6| Step: 3
Training loss: 1.9562551975250244
Validation loss: 2.210926954464246

Epoch: 6| Step: 4
Training loss: 1.7101185321807861
Validation loss: 2.2356553103334162

Epoch: 6| Step: 5
Training loss: 2.31681489944458
Validation loss: 2.208661848498929

Epoch: 6| Step: 6
Training loss: 1.9700241088867188
Validation loss: 2.2322824590949604

Epoch: 6| Step: 7
Training loss: 2.4879016876220703
Validation loss: 2.2010627767091155

Epoch: 6| Step: 8
Training loss: 1.9739482402801514
Validation loss: 2.206834490581225

Epoch: 6| Step: 9
Training loss: 2.2361698150634766
Validation loss: 2.2573052465274768

Epoch: 6| Step: 10
Training loss: 2.1701133251190186
Validation loss: 2.172222891161519

Epoch: 6| Step: 11
Training loss: 2.282313585281372
Validation loss: 2.1706065362499607

Epoch: 6| Step: 12
Training loss: 2.384782314300537
Validation loss: 2.1754485086728166

Epoch: 6| Step: 13
Training loss: 2.280374050140381
Validation loss: 2.206536077683972

Epoch: 78| Step: 0
Training loss: 2.133193016052246
Validation loss: 2.2126054276702223

Epoch: 6| Step: 1
Training loss: 2.4437153339385986
Validation loss: 2.2198039741926294

Epoch: 6| Step: 2
Training loss: 2.15836238861084
Validation loss: 2.1696302685686337

Epoch: 6| Step: 3
Training loss: 3.143519401550293
Validation loss: 2.1676093968012

Epoch: 6| Step: 4
Training loss: 1.9510732889175415
Validation loss: 2.1876505087780695

Epoch: 6| Step: 5
Training loss: 2.1571919918060303
Validation loss: 2.1813003068329184

Epoch: 6| Step: 6
Training loss: 2.1917061805725098
Validation loss: 2.1894366484816357

Epoch: 6| Step: 7
Training loss: 2.1374192237854004
Validation loss: 2.190714761775027

Epoch: 6| Step: 8
Training loss: 1.9939762353897095
Validation loss: 2.1676217920036724

Epoch: 6| Step: 9
Training loss: 1.7392246723175049
Validation loss: 2.160719351101947

Epoch: 6| Step: 10
Training loss: 2.0385899543762207
Validation loss: 2.194820437380063

Epoch: 6| Step: 11
Training loss: 2.160048246383667
Validation loss: 2.17728635444436

Epoch: 6| Step: 12
Training loss: 2.023827314376831
Validation loss: 2.1513465066109934

Epoch: 6| Step: 13
Training loss: 2.00026798248291
Validation loss: 2.1402832667032876

Epoch: 79| Step: 0
Training loss: 2.2688145637512207
Validation loss: 2.202221157730267

Epoch: 6| Step: 1
Training loss: 2.485902786254883
Validation loss: 2.181900155159735

Epoch: 6| Step: 2
Training loss: 2.271059036254883
Validation loss: 2.1999374512703187

Epoch: 6| Step: 3
Training loss: 1.749693512916565
Validation loss: 2.185747315806727

Epoch: 6| Step: 4
Training loss: 2.6126747131347656
Validation loss: 2.158125041633524

Epoch: 6| Step: 5
Training loss: 1.5118966102600098
Validation loss: 2.1197561064074115

Epoch: 6| Step: 6
Training loss: 2.2058167457580566
Validation loss: 2.187706753771792

Epoch: 6| Step: 7
Training loss: 2.3208484649658203
Validation loss: 2.199464887701055

Epoch: 6| Step: 8
Training loss: 2.8208436965942383
Validation loss: 2.1821606928302395

Epoch: 6| Step: 9
Training loss: 1.5634750127792358
Validation loss: 2.1209602253411406

Epoch: 6| Step: 10
Training loss: 2.1087329387664795
Validation loss: 2.175186280281313

Epoch: 6| Step: 11
Training loss: 2.2273428440093994
Validation loss: 2.161545732969879

Epoch: 6| Step: 12
Training loss: 2.4686965942382812
Validation loss: 2.151621000741118

Epoch: 6| Step: 13
Training loss: 2.359273910522461
Validation loss: 2.183309664008438

Epoch: 80| Step: 0
Training loss: 2.978910446166992
Validation loss: 2.207141868529781

Epoch: 6| Step: 1
Training loss: 1.6778438091278076
Validation loss: 2.134048610605219

Epoch: 6| Step: 2
Training loss: 1.5766170024871826
Validation loss: 2.156664791927543

Epoch: 6| Step: 3
Training loss: 2.276869297027588
Validation loss: 2.1866375835992957

Epoch: 6| Step: 4
Training loss: 2.024024486541748
Validation loss: 2.1942788708594536

Epoch: 6| Step: 5
Training loss: 1.967937707901001
Validation loss: 2.158313492292999

Epoch: 6| Step: 6
Training loss: 2.174170732498169
Validation loss: 2.208105105225758

Epoch: 6| Step: 7
Training loss: 2.059441566467285
Validation loss: 2.1471202040231354

Epoch: 6| Step: 8
Training loss: 2.2014107704162598
Validation loss: 2.1569402115319365

Epoch: 6| Step: 9
Training loss: 2.487788677215576
Validation loss: 2.1473810980396886

Epoch: 6| Step: 10
Training loss: 2.6194679737091064
Validation loss: 2.1301604047898324

Epoch: 6| Step: 11
Training loss: 1.8694701194763184
Validation loss: 2.1539223629941224

Epoch: 6| Step: 12
Training loss: 2.019972324371338
Validation loss: 2.1248911914005073

Epoch: 6| Step: 13
Training loss: 2.609598398208618
Validation loss: 2.2463801009680635

Epoch: 81| Step: 0
Training loss: 1.7850555181503296
Validation loss: 2.1609131315703034

Epoch: 6| Step: 1
Training loss: 2.334144115447998
Validation loss: 2.173208648158658

Epoch: 6| Step: 2
Training loss: 1.702775001525879
Validation loss: 2.1901246693826493

Epoch: 6| Step: 3
Training loss: 2.2576308250427246
Validation loss: 2.1814139248222433

Epoch: 6| Step: 4
Training loss: 2.000980854034424
Validation loss: 2.144043637860206

Epoch: 6| Step: 5
Training loss: 2.21121883392334
Validation loss: 2.1380304149402085

Epoch: 6| Step: 6
Training loss: 2.4716744422912598
Validation loss: 2.181516365338397

Epoch: 6| Step: 7
Training loss: 1.3959755897521973
Validation loss: 2.175012112945639

Epoch: 6| Step: 8
Training loss: 2.072413921356201
Validation loss: 2.1686106638241838

Epoch: 6| Step: 9
Training loss: 2.8299357891082764
Validation loss: 2.1596348644584737

Epoch: 6| Step: 10
Training loss: 2.1434860229492188
Validation loss: 2.158363055157405

Epoch: 6| Step: 11
Training loss: 2.144028663635254
Validation loss: 2.148528857897687

Epoch: 6| Step: 12
Training loss: 2.7836105823516846
Validation loss: 2.1931395351245837

Epoch: 6| Step: 13
Training loss: 2.3843586444854736
Validation loss: 2.12553927206224

Epoch: 82| Step: 0
Training loss: 1.8643991947174072
Validation loss: 2.13527726357983

Epoch: 6| Step: 1
Training loss: 2.5780787467956543
Validation loss: 2.193142569193276

Epoch: 6| Step: 2
Training loss: 2.001105308532715
Validation loss: 2.181853735318748

Epoch: 6| Step: 3
Training loss: 1.9259824752807617
Validation loss: 2.1693560538753385

Epoch: 6| Step: 4
Training loss: 1.685915470123291
Validation loss: 2.1537065223980973

Epoch: 6| Step: 5
Training loss: 1.8857654333114624
Validation loss: 2.170538858700824

Epoch: 6| Step: 6
Training loss: 2.128661632537842
Validation loss: 2.2060845974952943

Epoch: 6| Step: 7
Training loss: 1.988674521446228
Validation loss: 2.1376008141425347

Epoch: 6| Step: 8
Training loss: 2.6976027488708496
Validation loss: 2.1643806247301

Epoch: 6| Step: 9
Training loss: 2.241288661956787
Validation loss: 2.211184278611214

Epoch: 6| Step: 10
Training loss: 2.54105281829834
Validation loss: 2.114766700293428

Epoch: 6| Step: 11
Training loss: 2.458495616912842
Validation loss: 2.11432296229947

Epoch: 6| Step: 12
Training loss: 2.183178424835205
Validation loss: 2.1743839556171047

Epoch: 6| Step: 13
Training loss: 2.2443974018096924
Validation loss: 2.142225488539665

Epoch: 83| Step: 0
Training loss: 1.9094336032867432
Validation loss: 2.1791328281484623

Epoch: 6| Step: 1
Training loss: 2.0048069953918457
Validation loss: 2.209715066417571

Epoch: 6| Step: 2
Training loss: 2.291790246963501
Validation loss: 2.199851405236029

Epoch: 6| Step: 3
Training loss: 2.2485342025756836
Validation loss: 2.1031696334961922

Epoch: 6| Step: 4
Training loss: 1.621504306793213
Validation loss: 2.1546025083911036

Epoch: 6| Step: 5
Training loss: 2.307358980178833
Validation loss: 2.1346134947192286

Epoch: 6| Step: 6
Training loss: 2.1277289390563965
Validation loss: 2.1635338196190457

Epoch: 6| Step: 7
Training loss: 2.1615352630615234
Validation loss: 2.1619763784511115

Epoch: 6| Step: 8
Training loss: 2.1067543029785156
Validation loss: 2.113391517311014

Epoch: 6| Step: 9
Training loss: 2.1570639610290527
Validation loss: 2.162577900835263

Epoch: 6| Step: 10
Training loss: 1.7843708992004395
Validation loss: 2.1398671545008177

Epoch: 6| Step: 11
Training loss: 3.5033786296844482
Validation loss: 2.163302316460558

Epoch: 6| Step: 12
Training loss: 2.212794780731201
Validation loss: 2.1362027532310894

Epoch: 6| Step: 13
Training loss: 1.603884220123291
Validation loss: 2.1436694501548685

Epoch: 84| Step: 0
Training loss: 1.8946597576141357
Validation loss: 2.146017925713652

Epoch: 6| Step: 1
Training loss: 2.3928027153015137
Validation loss: 2.164188197863999

Epoch: 6| Step: 2
Training loss: 1.5522620677947998
Validation loss: 2.141443069263171

Epoch: 6| Step: 3
Training loss: 2.1292507648468018
Validation loss: 2.144428257019289

Epoch: 6| Step: 4
Training loss: 2.0488784313201904
Validation loss: 2.133533816183767

Epoch: 6| Step: 5
Training loss: 2.173128604888916
Validation loss: 2.1636257799722816

Epoch: 6| Step: 6
Training loss: 2.5354034900665283
Validation loss: 2.1267714000517324

Epoch: 6| Step: 7
Training loss: 2.2281341552734375
Validation loss: 2.186798946831816

Epoch: 6| Step: 8
Training loss: 2.4999659061431885
Validation loss: 2.1568526683315152

Epoch: 6| Step: 9
Training loss: 2.6743924617767334
Validation loss: 2.145901233919205

Epoch: 6| Step: 10
Training loss: 2.005897045135498
Validation loss: 2.1887899701313307

Epoch: 6| Step: 11
Training loss: 1.611401081085205
Validation loss: 2.148229939963228

Epoch: 6| Step: 12
Training loss: 2.3088455200195312
Validation loss: 2.190829876930483

Epoch: 6| Step: 13
Training loss: 1.9683952331542969
Validation loss: 2.1637658047419723

Epoch: 85| Step: 0
Training loss: 1.7647731304168701
Validation loss: 2.1977442310702417

Epoch: 6| Step: 1
Training loss: 2.507422924041748
Validation loss: 2.140922100313248

Epoch: 6| Step: 2
Training loss: 2.2565646171569824
Validation loss: 2.1960357337869625

Epoch: 6| Step: 3
Training loss: 2.515023708343506
Validation loss: 2.1726762120441725

Epoch: 6| Step: 4
Training loss: 2.2373247146606445
Validation loss: 2.1289265463429112

Epoch: 6| Step: 5
Training loss: 3.4730424880981445
Validation loss: 2.217731498902844

Epoch: 6| Step: 6
Training loss: 1.5773711204528809
Validation loss: 2.187677655168759

Epoch: 6| Step: 7
Training loss: 1.9772019386291504
Validation loss: 2.1720536293522006

Epoch: 6| Step: 8
Training loss: 1.3994194269180298
Validation loss: 2.2083918920127292

Epoch: 6| Step: 9
Training loss: 3.025636672973633
Validation loss: 2.117473038293982

Epoch: 6| Step: 10
Training loss: 2.2405846118927
Validation loss: 2.1905516629577964

Epoch: 6| Step: 11
Training loss: 1.4705145359039307
Validation loss: 2.156839870637463

Epoch: 6| Step: 12
Training loss: 1.559561014175415
Validation loss: 2.1405206111169632

Epoch: 6| Step: 13
Training loss: 2.523472785949707
Validation loss: 2.1609016323602326

Epoch: 86| Step: 0
Training loss: 2.3076171875
Validation loss: 2.2041110120793825

Epoch: 6| Step: 1
Training loss: 2.0938591957092285
Validation loss: 2.146657161815192

Epoch: 6| Step: 2
Training loss: 1.9932782649993896
Validation loss: 2.1514823334191435

Epoch: 6| Step: 3
Training loss: 1.565986156463623
Validation loss: 2.1262074952484458

Epoch: 6| Step: 4
Training loss: 1.9601244926452637
Validation loss: 2.1265731370577248

Epoch: 6| Step: 5
Training loss: 2.247291326522827
Validation loss: 2.133162885583857

Epoch: 6| Step: 6
Training loss: 1.8284640312194824
Validation loss: 2.187425031456896

Epoch: 6| Step: 7
Training loss: 1.7079668045043945
Validation loss: 2.2110660076141357

Epoch: 6| Step: 8
Training loss: 3.1442391872406006
Validation loss: 2.1688974108747257

Epoch: 6| Step: 9
Training loss: 2.494349241256714
Validation loss: 2.1379444060787076

Epoch: 6| Step: 10
Training loss: 2.064521551132202
Validation loss: 2.1974696805400233

Epoch: 6| Step: 11
Training loss: 2.4001431465148926
Validation loss: 2.193471498386834

Epoch: 6| Step: 12
Training loss: 2.5781822204589844
Validation loss: 2.1733757808644283

Epoch: 6| Step: 13
Training loss: 2.173513412475586
Validation loss: 2.1162547731912262

Epoch: 87| Step: 0
Training loss: 2.262051820755005
Validation loss: 2.082337938329225

Epoch: 6| Step: 1
Training loss: 3.479278087615967
Validation loss: 2.0994559808443953

Epoch: 6| Step: 2
Training loss: 2.09800386428833
Validation loss: 2.1421010686505224

Epoch: 6| Step: 3
Training loss: 1.752900242805481
Validation loss: 2.1338970840618177

Epoch: 6| Step: 4
Training loss: 2.216604232788086
Validation loss: 2.1292539335066274

Epoch: 6| Step: 5
Training loss: 2.564253807067871
Validation loss: 2.1366187718606766

Epoch: 6| Step: 6
Training loss: 2.662781238555908
Validation loss: 2.13612267919766

Epoch: 6| Step: 7
Training loss: 2.079214334487915
Validation loss: 2.18098004915381

Epoch: 6| Step: 8
Training loss: 1.49900484085083
Validation loss: 2.1306276000956053

Epoch: 6| Step: 9
Training loss: 1.9672788381576538
Validation loss: 2.172547391665879

Epoch: 6| Step: 10
Training loss: 2.0334506034851074
Validation loss: 2.140691585438226

Epoch: 6| Step: 11
Training loss: 2.0978879928588867
Validation loss: 2.1863727518307265

Epoch: 6| Step: 12
Training loss: 1.5187196731567383
Validation loss: 2.160873620740829

Epoch: 6| Step: 13
Training loss: 2.0454719066619873
Validation loss: 2.1493404860137613

Epoch: 88| Step: 0
Training loss: 1.7285093069076538
Validation loss: 2.100643955251222

Epoch: 6| Step: 1
Training loss: 3.5110764503479004
Validation loss: 2.1669410710693686

Epoch: 6| Step: 2
Training loss: 2.1154541969299316
Validation loss: 2.1267021240726596

Epoch: 6| Step: 3
Training loss: 1.4705935716629028
Validation loss: 2.1501998439911874

Epoch: 6| Step: 4
Training loss: 2.3455147743225098
Validation loss: 2.1556875756991807

Epoch: 6| Step: 5
Training loss: 1.5244030952453613
Validation loss: 2.1826808760243077

Epoch: 6| Step: 6
Training loss: 2.786586284637451
Validation loss: 2.108651286812239

Epoch: 6| Step: 7
Training loss: 1.6229560375213623
Validation loss: 2.07200393625485

Epoch: 6| Step: 8
Training loss: 2.6189513206481934
Validation loss: 2.1402765256102367

Epoch: 6| Step: 9
Training loss: 3.7729315757751465
Validation loss: 2.085772292588347

Epoch: 6| Step: 10
Training loss: 1.667527198791504
Validation loss: 2.149877799454556

Epoch: 6| Step: 11
Training loss: 1.7257527112960815
Validation loss: 2.1032171839026996

Epoch: 6| Step: 12
Training loss: 1.7428398132324219
Validation loss: 2.1547979513804116

Epoch: 6| Step: 13
Training loss: 1.1435582637786865
Validation loss: 2.1282969777302077

Epoch: 89| Step: 0
Training loss: 1.6233755350112915
Validation loss: 2.1206083554093555

Epoch: 6| Step: 1
Training loss: 2.5378165245056152
Validation loss: 2.120090630746657

Epoch: 6| Step: 2
Training loss: 2.0340211391448975
Validation loss: 2.1704573644104825

Epoch: 6| Step: 3
Training loss: 1.960985779762268
Validation loss: 2.1561096701570737

Epoch: 6| Step: 4
Training loss: 2.236901044845581
Validation loss: 2.0397435516439457

Epoch: 6| Step: 5
Training loss: 2.905834674835205
Validation loss: 2.142426303637925

Epoch: 6| Step: 6
Training loss: 2.234891414642334
Validation loss: 2.1297467831642396

Epoch: 6| Step: 7
Training loss: 2.067385196685791
Validation loss: 2.1176925115687872

Epoch: 6| Step: 8
Training loss: 1.712500810623169
Validation loss: 2.106302071643132

Epoch: 6| Step: 9
Training loss: 3.00405216217041
Validation loss: 2.1596557478750906

Epoch: 6| Step: 10
Training loss: 2.1092374324798584
Validation loss: 2.07892781688321

Epoch: 6| Step: 11
Training loss: 1.7521235942840576
Validation loss: 2.143825154150686

Epoch: 6| Step: 12
Training loss: 2.304810047149658
Validation loss: 2.1486000899345643

Epoch: 6| Step: 13
Training loss: 1.6024940013885498
Validation loss: 2.132884407556185

Epoch: 90| Step: 0
Training loss: 1.7270753383636475
Validation loss: 2.1295376657157816

Epoch: 6| Step: 1
Training loss: 1.4536354541778564
Validation loss: 2.1180257207603863

Epoch: 6| Step: 2
Training loss: 2.9263076782226562
Validation loss: 2.1458694011934343

Epoch: 6| Step: 3
Training loss: 1.2164068222045898
Validation loss: 2.155608974477296

Epoch: 6| Step: 4
Training loss: 1.7802551984786987
Validation loss: 2.102806064390367

Epoch: 6| Step: 5
Training loss: 2.747089147567749
Validation loss: 2.1172276530214535

Epoch: 6| Step: 6
Training loss: 2.4995594024658203
Validation loss: 2.166781361385058

Epoch: 6| Step: 7
Training loss: 2.303330421447754
Validation loss: 2.1174544941994453

Epoch: 6| Step: 8
Training loss: 2.5821304321289062
Validation loss: 2.077526702675768

Epoch: 6| Step: 9
Training loss: 1.7062785625457764
Validation loss: 2.1331836715821297

Epoch: 6| Step: 10
Training loss: 2.1185824871063232
Validation loss: 2.1024967598658737

Epoch: 6| Step: 11
Training loss: 2.238450527191162
Validation loss: 2.15116052217381

Epoch: 6| Step: 12
Training loss: 2.5758254528045654
Validation loss: 2.1275851829077608

Epoch: 6| Step: 13
Training loss: 1.9739842414855957
Validation loss: 2.1492304519940446

Epoch: 91| Step: 0
Training loss: 3.0115768909454346
Validation loss: 2.129466760543085

Epoch: 6| Step: 1
Training loss: 1.7727012634277344
Validation loss: 2.1314012465938443

Epoch: 6| Step: 2
Training loss: 1.2933862209320068
Validation loss: 2.1088853702750257

Epoch: 6| Step: 3
Training loss: 2.6125144958496094
Validation loss: 2.185809635346936

Epoch: 6| Step: 4
Training loss: 1.7406704425811768
Validation loss: 2.1342883622774513

Epoch: 6| Step: 5
Training loss: 1.7437348365783691
Validation loss: 2.1235549449920654

Epoch: 6| Step: 6
Training loss: 1.508000373840332
Validation loss: 2.135361994466474

Epoch: 6| Step: 7
Training loss: 1.9938108921051025
Validation loss: 2.1024901969458467

Epoch: 6| Step: 8
Training loss: 2.3140549659729004
Validation loss: 2.100166218255156

Epoch: 6| Step: 9
Training loss: 2.754833698272705
Validation loss: 2.1315372913114485

Epoch: 6| Step: 10
Training loss: 2.829028606414795
Validation loss: 2.103029789463166

Epoch: 6| Step: 11
Training loss: 1.7805551290512085
Validation loss: 2.1199801083533996

Epoch: 6| Step: 12
Training loss: 1.9849238395690918
Validation loss: 2.1727285910678167

Epoch: 6| Step: 13
Training loss: 2.105391502380371
Validation loss: 2.100009020938668

Epoch: 92| Step: 0
Training loss: 1.5245990753173828
Validation loss: 2.104457075877856

Epoch: 6| Step: 1
Training loss: 2.647932529449463
Validation loss: 2.120375342266534

Epoch: 6| Step: 2
Training loss: 2.177539587020874
Validation loss: 2.1234752631956533

Epoch: 6| Step: 3
Training loss: 2.178743839263916
Validation loss: 2.1328461400924192

Epoch: 6| Step: 4
Training loss: 1.8487544059753418
Validation loss: 2.1592809205414145

Epoch: 6| Step: 5
Training loss: 1.907637596130371
Validation loss: 2.1654402184230026

Epoch: 6| Step: 6
Training loss: 2.4426560401916504
Validation loss: 2.141972957118865

Epoch: 6| Step: 7
Training loss: 2.3128271102905273
Validation loss: 2.10666060960421

Epoch: 6| Step: 8
Training loss: 2.11087703704834
Validation loss: 2.108886491867804

Epoch: 6| Step: 9
Training loss: 1.808884620666504
Validation loss: 2.1193334056485083

Epoch: 6| Step: 10
Training loss: 2.6794376373291016
Validation loss: 2.0878292334977018

Epoch: 6| Step: 11
Training loss: 2.3525540828704834
Validation loss: 2.167280327889227

Epoch: 6| Step: 12
Training loss: 1.4435198307037354
Validation loss: 2.135712068567994

Epoch: 6| Step: 13
Training loss: 2.2612342834472656
Validation loss: 2.125310246662427

Epoch: 93| Step: 0
Training loss: 1.881145715713501
Validation loss: 2.091614994951474

Epoch: 6| Step: 1
Training loss: 2.6970367431640625
Validation loss: 2.076384695627356

Epoch: 6| Step: 2
Training loss: 1.7444082498550415
Validation loss: 2.1705167267912175

Epoch: 6| Step: 3
Training loss: 1.9604111909866333
Validation loss: 2.1595279401348484

Epoch: 6| Step: 4
Training loss: 1.7833962440490723
Validation loss: 2.1538620302754063

Epoch: 6| Step: 5
Training loss: 2.338785171508789
Validation loss: 2.146511957209597

Epoch: 6| Step: 6
Training loss: 2.0860626697540283
Validation loss: 2.096050145805523

Epoch: 6| Step: 7
Training loss: 2.5812792778015137
Validation loss: 2.2047494765250915

Epoch: 6| Step: 8
Training loss: 2.3178248405456543
Validation loss: 2.2013507299525763

Epoch: 6| Step: 9
Training loss: 1.6975351572036743
Validation loss: 2.154245909824166

Epoch: 6| Step: 10
Training loss: 2.4960274696350098
Validation loss: 2.186439355214437

Epoch: 6| Step: 11
Training loss: 2.4432249069213867
Validation loss: 2.1451934665761967

Epoch: 6| Step: 12
Training loss: 2.2244489192962646
Validation loss: 2.121121621900989

Epoch: 6| Step: 13
Training loss: 2.1151177883148193
Validation loss: 2.177565379809308

Epoch: 94| Step: 0
Training loss: 1.4695030450820923
Validation loss: 2.1057886154420915

Epoch: 6| Step: 1
Training loss: 2.247344970703125
Validation loss: 2.1312945735070015

Epoch: 6| Step: 2
Training loss: 2.250976324081421
Validation loss: 2.158415521344831

Epoch: 6| Step: 3
Training loss: 2.3456692695617676
Validation loss: 2.0996599787025043

Epoch: 6| Step: 4
Training loss: 2.184657096862793
Validation loss: 2.0890664349320116

Epoch: 6| Step: 5
Training loss: 1.4486315250396729
Validation loss: 2.099507539503036

Epoch: 6| Step: 6
Training loss: 2.5729076862335205
Validation loss: 2.092817942301432

Epoch: 6| Step: 7
Training loss: 1.9831807613372803
Validation loss: 2.1015572970913303

Epoch: 6| Step: 8
Training loss: 2.097977638244629
Validation loss: 2.1549331065147155

Epoch: 6| Step: 9
Training loss: 2.737353801727295
Validation loss: 2.101431963264301

Epoch: 6| Step: 10
Training loss: 1.7292630672454834
Validation loss: 2.1100146616658857

Epoch: 6| Step: 11
Training loss: 1.9903709888458252
Validation loss: 2.119902108305244

Epoch: 6| Step: 12
Training loss: 2.6338558197021484
Validation loss: 2.103034641153069

Epoch: 6| Step: 13
Training loss: 2.3333792686462402
Validation loss: 2.0800229323807584

Epoch: 95| Step: 0
Training loss: 1.3510124683380127
Validation loss: 2.0696757147389073

Epoch: 6| Step: 1
Training loss: 1.6970525979995728
Validation loss: 2.100848226137059

Epoch: 6| Step: 2
Training loss: 2.093578815460205
Validation loss: 2.1327280280410603

Epoch: 6| Step: 3
Training loss: 2.1572117805480957
Validation loss: 2.1547087443772184

Epoch: 6| Step: 4
Training loss: 2.1659717559814453
Validation loss: 2.0851062587512437

Epoch: 6| Step: 5
Training loss: 1.8871715068817139
Validation loss: 2.14893610759448

Epoch: 6| Step: 6
Training loss: 2.378692388534546
Validation loss: 2.080645371508855

Epoch: 6| Step: 7
Training loss: 1.8129832744598389
Validation loss: 2.132672163747972

Epoch: 6| Step: 8
Training loss: 2.316145658493042
Validation loss: 2.118523528498988

Epoch: 6| Step: 9
Training loss: 1.7321127653121948
Validation loss: 2.094038713362909

Epoch: 6| Step: 10
Training loss: 2.81205677986145
Validation loss: 2.1017696344724266

Epoch: 6| Step: 11
Training loss: 2.7123360633850098
Validation loss: 2.127666299061109

Epoch: 6| Step: 12
Training loss: 1.6219663619995117
Validation loss: 2.0986886011656893

Epoch: 6| Step: 13
Training loss: 2.5141751766204834
Validation loss: 2.1656499575543147

Epoch: 96| Step: 0
Training loss: 2.459469795227051
Validation loss: 2.127279343143586

Epoch: 6| Step: 1
Training loss: 1.9536774158477783
Validation loss: 2.1144433765001196

Epoch: 6| Step: 2
Training loss: 1.866098403930664
Validation loss: 2.0992062553282707

Epoch: 6| Step: 3
Training loss: 1.9405159950256348
Validation loss: 2.12905091111378

Epoch: 6| Step: 4
Training loss: 1.8918101787567139
Validation loss: 2.145475897737729

Epoch: 6| Step: 5
Training loss: 2.1999526023864746
Validation loss: 2.0634641826793714

Epoch: 6| Step: 6
Training loss: 2.2378458976745605
Validation loss: 2.113178176264609

Epoch: 6| Step: 7
Training loss: 1.2511992454528809
Validation loss: 2.0793836783337336

Epoch: 6| Step: 8
Training loss: 2.543489694595337
Validation loss: 2.0751092049383346

Epoch: 6| Step: 9
Training loss: 2.0965230464935303
Validation loss: 2.093208602679673

Epoch: 6| Step: 10
Training loss: 2.0145506858825684
Validation loss: 2.150123493645781

Epoch: 6| Step: 11
Training loss: 2.452357292175293
Validation loss: 2.057814005882509

Epoch: 6| Step: 12
Training loss: 2.3621349334716797
Validation loss: 2.1584646189084618

Epoch: 6| Step: 13
Training loss: 2.4271419048309326
Validation loss: 2.1506240137161745

Epoch: 97| Step: 0
Training loss: 2.1683859825134277
Validation loss: 2.102127528959705

Epoch: 6| Step: 1
Training loss: 1.885270357131958
Validation loss: 2.1370650901589343

Epoch: 6| Step: 2
Training loss: 2.0148587226867676
Validation loss: 2.0630166466518114

Epoch: 6| Step: 3
Training loss: 2.3601326942443848
Validation loss: 2.0903192938015027

Epoch: 6| Step: 4
Training loss: 2.1386332511901855
Validation loss: 2.087032844943385

Epoch: 6| Step: 5
Training loss: 2.563044548034668
Validation loss: 2.1051950864894415

Epoch: 6| Step: 6
Training loss: 2.47493052482605
Validation loss: 2.084264321993756

Epoch: 6| Step: 7
Training loss: 2.0225343704223633
Validation loss: 2.085428278933289

Epoch: 6| Step: 8
Training loss: 1.3164665699005127
Validation loss: 2.0616683831778904

Epoch: 6| Step: 9
Training loss: 3.0195746421813965
Validation loss: 2.0834135163214897

Epoch: 6| Step: 10
Training loss: 1.9119383096694946
Validation loss: 2.1355275466877925

Epoch: 6| Step: 11
Training loss: 1.9140205383300781
Validation loss: 2.0700821363797752

Epoch: 6| Step: 12
Training loss: 1.6197509765625
Validation loss: 2.1195046478702175

Epoch: 6| Step: 13
Training loss: 1.7371553182601929
Validation loss: 2.076948473530431

Epoch: 98| Step: 0
Training loss: 2.528998374938965
Validation loss: 2.070785419915312

Epoch: 6| Step: 1
Training loss: 1.8528876304626465
Validation loss: 2.135818773700345

Epoch: 6| Step: 2
Training loss: 1.8028297424316406
Validation loss: 2.1420783099307807

Epoch: 6| Step: 3
Training loss: 2.447293758392334
Validation loss: 2.078106657151253

Epoch: 6| Step: 4
Training loss: 2.00956392288208
Validation loss: 2.059720677714194

Epoch: 6| Step: 5
Training loss: 2.111990451812744
Validation loss: 2.1702169820826542

Epoch: 6| Step: 6
Training loss: 2.4065370559692383
Validation loss: 2.075825265658799

Epoch: 6| Step: 7
Training loss: 2.5295424461364746
Validation loss: 2.0538396989145586

Epoch: 6| Step: 8
Training loss: 2.3141918182373047
Validation loss: 2.1406180679157214

Epoch: 6| Step: 9
Training loss: 2.142092227935791
Validation loss: 2.0857859273110666

Epoch: 6| Step: 10
Training loss: 1.6490933895111084
Validation loss: 2.136282049199586

Epoch: 6| Step: 11
Training loss: 1.4463796615600586
Validation loss: 2.10634115434462

Epoch: 6| Step: 12
Training loss: 1.869309902191162
Validation loss: 2.100454520153743

Epoch: 6| Step: 13
Training loss: 2.274739980697632
Validation loss: 2.0680845975875854

Epoch: 99| Step: 0
Training loss: 2.049030303955078
Validation loss: 2.0851310863289783

Epoch: 6| Step: 1
Training loss: 2.3976423740386963
Validation loss: 2.100070463713779

Epoch: 6| Step: 2
Training loss: 1.5919337272644043
Validation loss: 2.1360083959435903

Epoch: 6| Step: 3
Training loss: 2.2253217697143555
Validation loss: 2.1705946832574825

Epoch: 6| Step: 4
Training loss: 1.9738885164260864
Validation loss: 2.1265357514863372

Epoch: 6| Step: 5
Training loss: 2.0472006797790527
Validation loss: 2.1371750113784627

Epoch: 6| Step: 6
Training loss: 1.6764589548110962
Validation loss: 2.1232317570717103

Epoch: 6| Step: 7
Training loss: 1.7124048471450806
Validation loss: 2.174358801175189

Epoch: 6| Step: 8
Training loss: 2.186500310897827
Validation loss: 2.1475902218972482

Epoch: 6| Step: 9
Training loss: 2.02364444732666
Validation loss: 2.109863531204962

Epoch: 6| Step: 10
Training loss: 2.646246910095215
Validation loss: 2.09104097530406

Epoch: 6| Step: 11
Training loss: 2.3929336071014404
Validation loss: 2.091899157852255

Epoch: 6| Step: 12
Training loss: 1.5697054862976074
Validation loss: 2.088086335889755

Epoch: 6| Step: 13
Training loss: 3.1256983280181885
Validation loss: 2.1089727506842664

Epoch: 100| Step: 0
Training loss: 1.350259780883789
Validation loss: 2.1211351938145135

Epoch: 6| Step: 1
Training loss: 1.8540172576904297
Validation loss: 2.1087741480078748

Epoch: 6| Step: 2
Training loss: 2.6350812911987305
Validation loss: 2.0993682697255123

Epoch: 6| Step: 3
Training loss: 2.4263691902160645
Validation loss: 2.090093994653353

Epoch: 6| Step: 4
Training loss: 1.696372151374817
Validation loss: 2.044414822773267

Epoch: 6| Step: 5
Training loss: 2.3260390758514404
Validation loss: 2.072412210126077

Epoch: 6| Step: 6
Training loss: 2.6762208938598633
Validation loss: 2.07145736294408

Epoch: 6| Step: 7
Training loss: 1.7179286479949951
Validation loss: 2.1198338744460896

Epoch: 6| Step: 8
Training loss: 2.08308744430542
Validation loss: 2.1073836588090464

Epoch: 6| Step: 9
Training loss: 2.3807601928710938
Validation loss: 2.0692011464026665

Epoch: 6| Step: 10
Training loss: 1.8256609439849854
Validation loss: 2.1058320499235585

Epoch: 6| Step: 11
Training loss: 2.0061097145080566
Validation loss: 2.061836491348923

Epoch: 6| Step: 12
Training loss: 1.6863069534301758
Validation loss: 2.0856270585008847

Epoch: 6| Step: 13
Training loss: 3.048093795776367
Validation loss: 2.1221932083047848

Epoch: 101| Step: 0
Training loss: 2.0761990547180176
Validation loss: 2.078792300275577

Epoch: 6| Step: 1
Training loss: 2.409292221069336
Validation loss: 2.076519291888001

Epoch: 6| Step: 2
Training loss: 2.1812753677368164
Validation loss: 2.105639721757622

Epoch: 6| Step: 3
Training loss: 2.2515339851379395
Validation loss: 2.110146668649489

Epoch: 6| Step: 4
Training loss: 2.1919946670532227
Validation loss: 2.105632541000202

Epoch: 6| Step: 5
Training loss: 2.0065817832946777
Validation loss: 2.0892217825817805

Epoch: 6| Step: 6
Training loss: 2.212099313735962
Validation loss: 2.1237161031333347

Epoch: 6| Step: 7
Training loss: 1.9722260236740112
Validation loss: 2.043099623854442

Epoch: 6| Step: 8
Training loss: 1.505798578262329
Validation loss: 2.104184421159888

Epoch: 6| Step: 9
Training loss: 2.291560173034668
Validation loss: 2.069137047695857

Epoch: 6| Step: 10
Training loss: 1.702797293663025
Validation loss: 2.114551405752859

Epoch: 6| Step: 11
Training loss: 1.7009426355361938
Validation loss: 2.146851811357724

Epoch: 6| Step: 12
Training loss: 2.015547037124634
Validation loss: 2.0749347761113155

Epoch: 6| Step: 13
Training loss: 2.581559419631958
Validation loss: 2.0627966952580277

Epoch: 102| Step: 0
Training loss: 2.456613540649414
Validation loss: 2.1031956262485956

Epoch: 6| Step: 1
Training loss: 2.926678419113159
Validation loss: 2.12392807391382

Epoch: 6| Step: 2
Training loss: 1.6991677284240723
Validation loss: 2.0835048460191294

Epoch: 6| Step: 3
Training loss: 2.448914051055908
Validation loss: 2.096169876795943

Epoch: 6| Step: 4
Training loss: 2.226253032684326
Validation loss: 2.157626744239561

Epoch: 6| Step: 5
Training loss: 1.8659169673919678
Validation loss: 2.1757619919315463

Epoch: 6| Step: 6
Training loss: 1.9581153392791748
Validation loss: 2.1069695231735066

Epoch: 6| Step: 7
Training loss: 1.967657208442688
Validation loss: 2.138647366595525

Epoch: 6| Step: 8
Training loss: 1.812756061553955
Validation loss: 2.1385166798868487

Epoch: 6| Step: 9
Training loss: 2.8688220977783203
Validation loss: 2.1697310863002652

Epoch: 6| Step: 10
Training loss: 2.016545057296753
Validation loss: 2.119292284852715

Epoch: 6| Step: 11
Training loss: 1.6857993602752686
Validation loss: 2.093857366551635

Epoch: 6| Step: 12
Training loss: 1.5394881963729858
Validation loss: 2.109620089172035

Epoch: 6| Step: 13
Training loss: 1.4659236669540405
Validation loss: 2.055951996516156

Epoch: 103| Step: 0
Training loss: 2.6362948417663574
Validation loss: 2.0922026339397637

Epoch: 6| Step: 1
Training loss: 2.1191835403442383
Validation loss: 2.08673083654014

Epoch: 6| Step: 2
Training loss: 2.1289565563201904
Validation loss: 2.101981064324738

Epoch: 6| Step: 3
Training loss: 1.9769939184188843
Validation loss: 2.036672524226609

Epoch: 6| Step: 4
Training loss: 2.22904109954834
Validation loss: 2.117642705158521

Epoch: 6| Step: 5
Training loss: 1.9291406869888306
Validation loss: 2.069258830880606

Epoch: 6| Step: 6
Training loss: 1.8952385187149048
Validation loss: 2.0818664130344184

Epoch: 6| Step: 7
Training loss: 1.5514743328094482
Validation loss: 2.0906096196943715

Epoch: 6| Step: 8
Training loss: 1.9209392070770264
Validation loss: 2.0321943965009464

Epoch: 6| Step: 9
Training loss: 1.704555630683899
Validation loss: 2.1101288987744238

Epoch: 6| Step: 10
Training loss: 2.8530819416046143
Validation loss: 2.0679946740468345

Epoch: 6| Step: 11
Training loss: 1.5125089883804321
Validation loss: 2.0534002704005085

Epoch: 6| Step: 12
Training loss: 2.1902859210968018
Validation loss: 2.0800986674524125

Epoch: 6| Step: 13
Training loss: 2.3939483165740967
Validation loss: 2.0660002769962436

Epoch: 104| Step: 0
Training loss: 1.964514970779419
Validation loss: 2.0708850378631265

Epoch: 6| Step: 1
Training loss: 2.3912734985351562
Validation loss: 2.0577855751078618

Epoch: 6| Step: 2
Training loss: 1.9142016172409058
Validation loss: 2.048150339434224

Epoch: 6| Step: 3
Training loss: 2.410325050354004
Validation loss: 2.0993711102393364

Epoch: 6| Step: 4
Training loss: 2.1154394149780273
Validation loss: 2.0553231546955724

Epoch: 6| Step: 5
Training loss: 1.8980486392974854
Validation loss: 2.1163024517797653

Epoch: 6| Step: 6
Training loss: 2.1630282402038574
Validation loss: 2.1389978162703978

Epoch: 6| Step: 7
Training loss: 2.2061891555786133
Validation loss: 2.065914252752899

Epoch: 6| Step: 8
Training loss: 2.3719780445098877
Validation loss: 2.0612529080401183

Epoch: 6| Step: 9
Training loss: 2.310861587524414
Validation loss: 2.093293461748349

Epoch: 6| Step: 10
Training loss: 1.9473326206207275
Validation loss: 2.088177393841487

Epoch: 6| Step: 11
Training loss: 2.5128111839294434
Validation loss: 2.1238867595631588

Epoch: 6| Step: 12
Training loss: 1.3475806713104248
Validation loss: 2.1228549980348155

Epoch: 6| Step: 13
Training loss: 1.569252848625183
Validation loss: 2.1388065340698406

Epoch: 105| Step: 0
Training loss: 1.9343904256820679
Validation loss: 2.102767582862608

Epoch: 6| Step: 1
Training loss: 1.5374608039855957
Validation loss: 2.0473512846936464

Epoch: 6| Step: 2
Training loss: 2.8298001289367676
Validation loss: 2.0617718491502988

Epoch: 6| Step: 3
Training loss: 1.6321864128112793
Validation loss: 2.052658006709109

Epoch: 6| Step: 4
Training loss: 1.6391453742980957
Validation loss: 2.0573282985277075

Epoch: 6| Step: 5
Training loss: 1.7742844820022583
Validation loss: 2.076914064345821

Epoch: 6| Step: 6
Training loss: 1.7771493196487427
Validation loss: 2.0585952035842405

Epoch: 6| Step: 7
Training loss: 2.8420262336730957
Validation loss: 2.0921178838258148

Epoch: 6| Step: 8
Training loss: 2.509936809539795
Validation loss: 2.0814866686380036

Epoch: 6| Step: 9
Training loss: 2.0702109336853027
Validation loss: 2.080452234514298

Epoch: 6| Step: 10
Training loss: 2.8818416595458984
Validation loss: 2.046961958690356

Epoch: 6| Step: 11
Training loss: 1.6430437564849854
Validation loss: 2.06212011332153

Epoch: 6| Step: 12
Training loss: 2.113142251968384
Validation loss: 2.081923407893027

Epoch: 6| Step: 13
Training loss: 1.6065406799316406
Validation loss: 2.1050768411287697

Epoch: 106| Step: 0
Training loss: 2.409790515899658
Validation loss: 2.0963646263204594

Epoch: 6| Step: 1
Training loss: 1.804315447807312
Validation loss: 2.0276645921891734

Epoch: 6| Step: 2
Training loss: 2.2130370140075684
Validation loss: 2.080799059201312

Epoch: 6| Step: 3
Training loss: 2.772190809249878
Validation loss: 2.0791449187904276

Epoch: 6| Step: 4
Training loss: 1.2767740488052368
Validation loss: 2.1230953137079873

Epoch: 6| Step: 5
Training loss: 2.087360143661499
Validation loss: 2.0771318904815184

Epoch: 6| Step: 6
Training loss: 1.8796230554580688
Validation loss: 2.099464762595392

Epoch: 6| Step: 7
Training loss: 2.1194989681243896
Validation loss: 2.0647977936652397

Epoch: 6| Step: 8
Training loss: 1.8466559648513794
Validation loss: 2.0715714936615317

Epoch: 6| Step: 9
Training loss: 2.134460210800171
Validation loss: 2.0736205654759563

Epoch: 6| Step: 10
Training loss: 2.0302183628082275
Validation loss: 2.0823019012328117

Epoch: 6| Step: 11
Training loss: 1.8356144428253174
Validation loss: 2.134352967303286

Epoch: 6| Step: 12
Training loss: 2.7672176361083984
Validation loss: 2.1125354741209295

Epoch: 6| Step: 13
Training loss: 1.6573606729507446
Validation loss: 2.081992587735576

Epoch: 107| Step: 0
Training loss: 2.002467632293701
Validation loss: 2.0735516573793147

Epoch: 6| Step: 1
Training loss: 1.7241158485412598
Validation loss: 2.022751292874736

Epoch: 6| Step: 2
Training loss: 1.674692153930664
Validation loss: 2.081933775255757

Epoch: 6| Step: 3
Training loss: 2.5352296829223633
Validation loss: 2.1409911212100776

Epoch: 6| Step: 4
Training loss: 1.8176262378692627
Validation loss: 2.0367243546311573

Epoch: 6| Step: 5
Training loss: 1.997870922088623
Validation loss: 2.0926982574565436

Epoch: 6| Step: 6
Training loss: 2.0184226036071777
Validation loss: 2.097125094424012

Epoch: 6| Step: 7
Training loss: 2.8666458129882812
Validation loss: 2.1091049742955033

Epoch: 6| Step: 8
Training loss: 1.762710690498352
Validation loss: 2.065951778042701

Epoch: 6| Step: 9
Training loss: 1.4987468719482422
Validation loss: 2.105334840795045

Epoch: 6| Step: 10
Training loss: 2.685615062713623
Validation loss: 2.1012284114796627

Epoch: 6| Step: 11
Training loss: 2.018970489501953
Validation loss: 2.1109416536105576

Epoch: 6| Step: 12
Training loss: 1.9162966012954712
Validation loss: 2.068077592439549

Epoch: 6| Step: 13
Training loss: 2.7024965286254883
Validation loss: 2.0561319448614634

Epoch: 108| Step: 0
Training loss: 1.8616622686386108
Validation loss: 2.0504060535020727

Epoch: 6| Step: 1
Training loss: 1.6523061990737915
Validation loss: 2.0255608276654313

Epoch: 6| Step: 2
Training loss: 2.047968626022339
Validation loss: 2.011511460427315

Epoch: 6| Step: 3
Training loss: 1.7163106203079224
Validation loss: 1.9673080418699531

Epoch: 6| Step: 4
Training loss: 1.697278380393982
Validation loss: 2.084938649208315

Epoch: 6| Step: 5
Training loss: 2.6371922492980957
Validation loss: 2.049550748640491

Epoch: 6| Step: 6
Training loss: 2.5382771492004395
Validation loss: 2.0938664854213758

Epoch: 6| Step: 7
Training loss: 2.427741527557373
Validation loss: 2.0684227558874313

Epoch: 6| Step: 8
Training loss: 2.048370838165283
Validation loss: 2.077153264835317

Epoch: 6| Step: 9
Training loss: 1.7494115829467773
Validation loss: 1.9933167093543596

Epoch: 6| Step: 10
Training loss: 1.7251884937286377
Validation loss: 2.0427946429098807

Epoch: 6| Step: 11
Training loss: 2.2995152473449707
Validation loss: 2.001844016454553

Epoch: 6| Step: 12
Training loss: 1.835259199142456
Validation loss: 2.01235209485536

Epoch: 6| Step: 13
Training loss: 2.6077799797058105
Validation loss: 2.050690899613083

Epoch: 109| Step: 0
Training loss: 1.282468557357788
Validation loss: 2.0751322866767965

Epoch: 6| Step: 1
Training loss: 1.8848869800567627
Validation loss: 2.065404169021114

Epoch: 6| Step: 2
Training loss: 2.3528854846954346
Validation loss: 2.094927842899035

Epoch: 6| Step: 3
Training loss: 2.0055556297302246
Validation loss: 2.0435105728846725

Epoch: 6| Step: 4
Training loss: 1.7177999019622803
Validation loss: 2.019028309852846

Epoch: 6| Step: 5
Training loss: 2.6755003929138184
Validation loss: 2.0616758459357807

Epoch: 6| Step: 6
Training loss: 2.5230889320373535
Validation loss: 2.0551520675741215

Epoch: 6| Step: 7
Training loss: 2.294239044189453
Validation loss: 2.0907901243496965

Epoch: 6| Step: 8
Training loss: 3.0546979904174805
Validation loss: 2.058093253002372

Epoch: 6| Step: 9
Training loss: 1.7686225175857544
Validation loss: 2.0525276378918718

Epoch: 6| Step: 10
Training loss: 1.5510921478271484
Validation loss: 2.0296563102353002

Epoch: 6| Step: 11
Training loss: 2.0381462574005127
Validation loss: 2.035968226771201

Epoch: 6| Step: 12
Training loss: 1.4592137336730957
Validation loss: 2.0582188201206986

Epoch: 6| Step: 13
Training loss: 2.1783275604248047
Validation loss: 2.046827200920351

Epoch: 110| Step: 0
Training loss: 2.1640853881835938
Validation loss: 2.1025343607830744

Epoch: 6| Step: 1
Training loss: 2.0723788738250732
Validation loss: 2.0805608328952583

Epoch: 6| Step: 2
Training loss: 1.934112548828125
Validation loss: 2.115235495310958

Epoch: 6| Step: 3
Training loss: 1.7507474422454834
Validation loss: 2.081483285914185

Epoch: 6| Step: 4
Training loss: 1.7594835758209229
Validation loss: 2.068494173788255

Epoch: 6| Step: 5
Training loss: 2.620638608932495
Validation loss: 2.040587950778264

Epoch: 6| Step: 6
Training loss: 1.8612327575683594
Validation loss: 2.112507503519776

Epoch: 6| Step: 7
Training loss: 1.7135359048843384
Validation loss: 2.0661470915681575

Epoch: 6| Step: 8
Training loss: 2.054532051086426
Validation loss: 2.157104589605844

Epoch: 6| Step: 9
Training loss: 2.095881938934326
Validation loss: 2.107099543335617

Epoch: 6| Step: 10
Training loss: 2.197390079498291
Validation loss: 2.090183045274468

Epoch: 6| Step: 11
Training loss: 2.116091728210449
Validation loss: 2.102445422962148

Epoch: 6| Step: 12
Training loss: 2.4784460067749023
Validation loss: 2.0599971125202794

Epoch: 6| Step: 13
Training loss: 2.3288705348968506
Validation loss: 2.09131444397793

Epoch: 111| Step: 0
Training loss: 2.1000022888183594
Validation loss: 2.0659361039438555

Epoch: 6| Step: 1
Training loss: 1.8525352478027344
Validation loss: 2.036589766061434

Epoch: 6| Step: 2
Training loss: 1.1091175079345703
Validation loss: 2.1333783134337394

Epoch: 6| Step: 3
Training loss: 2.286287784576416
Validation loss: 2.065992937293104

Epoch: 6| Step: 4
Training loss: 1.519851565361023
Validation loss: 2.0456541302383586

Epoch: 6| Step: 5
Training loss: 1.6055337190628052
Validation loss: 2.0664386492903515

Epoch: 6| Step: 6
Training loss: 2.205817222595215
Validation loss: 2.035645232405714

Epoch: 6| Step: 7
Training loss: 1.9920499324798584
Validation loss: 2.0810236033572944

Epoch: 6| Step: 8
Training loss: 1.9641860723495483
Validation loss: 2.1248560259419103

Epoch: 6| Step: 9
Training loss: 1.73379385471344
Validation loss: 2.0675017577345653

Epoch: 6| Step: 10
Training loss: 2.218885898590088
Validation loss: 2.0504949759411555

Epoch: 6| Step: 11
Training loss: 2.7203805446624756
Validation loss: 2.0579661271905385

Epoch: 6| Step: 12
Training loss: 2.1848936080932617
Validation loss: 2.0476981491170902

Epoch: 6| Step: 13
Training loss: 2.8042354583740234
Validation loss: 2.0455004528004634

Epoch: 112| Step: 0
Training loss: 1.7885055541992188
Validation loss: 2.0690864427115327

Epoch: 6| Step: 1
Training loss: 1.711624264717102
Validation loss: 2.089593868101797

Epoch: 6| Step: 2
Training loss: 1.542647361755371
Validation loss: 2.1113950065387193

Epoch: 6| Step: 3
Training loss: 1.9731173515319824
Validation loss: 2.0948316640751337

Epoch: 6| Step: 4
Training loss: 1.9583725929260254
Validation loss: 2.02319053552484

Epoch: 6| Step: 5
Training loss: 1.8200573921203613
Validation loss: 1.9944748058114001

Epoch: 6| Step: 6
Training loss: 2.5423290729522705
Validation loss: 2.0987652399206675

Epoch: 6| Step: 7
Training loss: 1.956294059753418
Validation loss: 2.0448981433786373

Epoch: 6| Step: 8
Training loss: 2.0241994857788086
Validation loss: 2.003035964504365

Epoch: 6| Step: 9
Training loss: 2.431260108947754
Validation loss: 2.048104150320894

Epoch: 6| Step: 10
Training loss: 1.6990315914154053
Validation loss: 2.0188692897878666

Epoch: 6| Step: 11
Training loss: 3.093280792236328
Validation loss: 2.08456939266574

Epoch: 6| Step: 12
Training loss: 1.5307127237319946
Validation loss: 2.093541693943803

Epoch: 6| Step: 13
Training loss: 2.4187536239624023
Validation loss: 2.0856234668403544

Epoch: 113| Step: 0
Training loss: 1.2797939777374268
Validation loss: 2.002924583291495

Epoch: 6| Step: 1
Training loss: 2.904672622680664
Validation loss: 2.074258430029756

Epoch: 6| Step: 2
Training loss: 2.5978124141693115
Validation loss: 2.072903302408034

Epoch: 6| Step: 3
Training loss: 1.433875560760498
Validation loss: 2.08347475400535

Epoch: 6| Step: 4
Training loss: 1.9015806913375854
Validation loss: 2.097418719722379

Epoch: 6| Step: 5
Training loss: 2.0818285942077637
Validation loss: 1.9930768602637834

Epoch: 6| Step: 6
Training loss: 2.014037609100342
Validation loss: 2.0403979362980014

Epoch: 6| Step: 7
Training loss: 2.073117733001709
Validation loss: 2.099327410421064

Epoch: 6| Step: 8
Training loss: 1.1594221591949463
Validation loss: 2.0289349863606114

Epoch: 6| Step: 9
Training loss: 2.4445929527282715
Validation loss: 1.995148112696986

Epoch: 6| Step: 10
Training loss: 2.1599068641662598
Validation loss: 2.0498956172697005

Epoch: 6| Step: 11
Training loss: 1.8508855104446411
Validation loss: 2.019196166787096

Epoch: 6| Step: 12
Training loss: 2.3852100372314453
Validation loss: 2.0671648415186072

Epoch: 6| Step: 13
Training loss: 2.182300090789795
Validation loss: 2.002935033972545

Epoch: 114| Step: 0
Training loss: 2.4991133213043213
Validation loss: 2.031215536978937

Epoch: 6| Step: 1
Training loss: 2.6996982097625732
Validation loss: 2.037701911823724

Epoch: 6| Step: 2
Training loss: 1.69688880443573
Validation loss: 2.126511691718973

Epoch: 6| Step: 3
Training loss: 1.3677690029144287
Validation loss: 2.0897517793922016

Epoch: 6| Step: 4
Training loss: 1.9256033897399902
Validation loss: 1.9991171026742587

Epoch: 6| Step: 5
Training loss: 1.8931913375854492
Validation loss: 2.038022671976397

Epoch: 6| Step: 6
Training loss: 2.7844367027282715
Validation loss: 2.0626998819330686

Epoch: 6| Step: 7
Training loss: 1.8671170473098755
Validation loss: 2.0447598131754066

Epoch: 6| Step: 8
Training loss: 1.686513900756836
Validation loss: 2.0177331278401036

Epoch: 6| Step: 9
Training loss: 2.04067325592041
Validation loss: 2.0153494265771683

Epoch: 6| Step: 10
Training loss: 2.6117334365844727
Validation loss: 2.0214728027261715

Epoch: 6| Step: 11
Training loss: 1.9044690132141113
Validation loss: 2.0379794169497747

Epoch: 6| Step: 12
Training loss: 1.530210256576538
Validation loss: 2.057729765933047

Epoch: 6| Step: 13
Training loss: 1.766463279724121
Validation loss: 1.996772663567656

Epoch: 115| Step: 0
Training loss: 2.1987054347991943
Validation loss: 2.1153755726352816

Epoch: 6| Step: 1
Training loss: 2.0313186645507812
Validation loss: 2.0307586667358235

Epoch: 6| Step: 2
Training loss: 2.4434444904327393
Validation loss: 2.0560079056729554

Epoch: 6| Step: 3
Training loss: 2.195477247238159
Validation loss: 2.0668196690979825

Epoch: 6| Step: 4
Training loss: 1.0975475311279297
Validation loss: 2.0994058680790726

Epoch: 6| Step: 5
Training loss: 1.490178108215332
Validation loss: 2.2078491026355374

Epoch: 6| Step: 6
Training loss: 2.376974105834961
Validation loss: 2.1396138027150142

Epoch: 6| Step: 7
Training loss: 2.203115940093994
Validation loss: 2.0983258344793834

Epoch: 6| Step: 8
Training loss: 1.3627499341964722
Validation loss: 2.1181059729668403

Epoch: 6| Step: 9
Training loss: 1.6564714908599854
Validation loss: 2.159405086630134

Epoch: 6| Step: 10
Training loss: 2.805172920227051
Validation loss: 2.107784476331485

Epoch: 6| Step: 11
Training loss: 1.81821608543396
Validation loss: 2.1569823757294686

Epoch: 6| Step: 12
Training loss: 2.4332239627838135
Validation loss: 2.133927799040271

Epoch: 6| Step: 13
Training loss: 3.12575626373291
Validation loss: 2.1192772003912155

Epoch: 116| Step: 0
Training loss: 2.407353639602661
Validation loss: 2.057381603025621

Epoch: 6| Step: 1
Training loss: 1.976265549659729
Validation loss: 2.085056310058922

Epoch: 6| Step: 2
Training loss: 2.1379168033599854
Validation loss: 2.047470878529292

Epoch: 6| Step: 3
Training loss: 2.6823065280914307
Validation loss: 2.0414685459547144

Epoch: 6| Step: 4
Training loss: 2.182692050933838
Validation loss: 2.045487492315231

Epoch: 6| Step: 5
Training loss: 1.6562550067901611
Validation loss: 1.998720871504917

Epoch: 6| Step: 6
Training loss: 2.3236942291259766
Validation loss: 2.0476195709679716

Epoch: 6| Step: 7
Training loss: 2.5325915813446045
Validation loss: 2.034868909466651

Epoch: 6| Step: 8
Training loss: 1.2654576301574707
Validation loss: 2.0787382830855665

Epoch: 6| Step: 9
Training loss: 1.657591462135315
Validation loss: 1.9881190279478669

Epoch: 6| Step: 10
Training loss: 2.1572115421295166
Validation loss: 1.9844703007769842

Epoch: 6| Step: 11
Training loss: 1.4051979780197144
Validation loss: 2.0176285313021753

Epoch: 6| Step: 12
Training loss: 2.0901951789855957
Validation loss: 2.0652298914488925

Epoch: 6| Step: 13
Training loss: 1.79060697555542
Validation loss: 1.9739428758621216

Epoch: 117| Step: 0
Training loss: 1.7800111770629883
Validation loss: 2.044377766629701

Epoch: 6| Step: 1
Training loss: 2.5535688400268555
Validation loss: 2.0009552176280687

Epoch: 6| Step: 2
Training loss: 1.7620112895965576
Validation loss: 2.04533367003164

Epoch: 6| Step: 3
Training loss: 1.5259008407592773
Validation loss: 2.0333696693502445

Epoch: 6| Step: 4
Training loss: 1.512735366821289
Validation loss: 2.0782452206457815

Epoch: 6| Step: 5
Training loss: 1.883936882019043
Validation loss: 2.003243359186316

Epoch: 6| Step: 6
Training loss: 1.9529420137405396
Validation loss: 1.944989340279692

Epoch: 6| Step: 7
Training loss: 2.300551414489746
Validation loss: 2.059007445971171

Epoch: 6| Step: 8
Training loss: 1.7465109825134277
Validation loss: 2.0918551286061606

Epoch: 6| Step: 9
Training loss: 1.8743817806243896
Validation loss: 1.972824683753393

Epoch: 6| Step: 10
Training loss: 2.166383743286133
Validation loss: 2.115860936462238

Epoch: 6| Step: 11
Training loss: 1.8330843448638916
Validation loss: 2.034725542991392

Epoch: 6| Step: 12
Training loss: 2.5693459510803223
Validation loss: 2.024369021897675

Epoch: 6| Step: 13
Training loss: 2.2021186351776123
Validation loss: 2.1205044869453675

Epoch: 118| Step: 0
Training loss: 2.032961368560791
Validation loss: 2.0163293551373225

Epoch: 6| Step: 1
Training loss: 2.0337228775024414
Validation loss: 2.057957277503065

Epoch: 6| Step: 2
Training loss: 3.419243812561035
Validation loss: 2.0390543412136775

Epoch: 6| Step: 3
Training loss: 1.61857008934021
Validation loss: 2.066119706758889

Epoch: 6| Step: 4
Training loss: 1.622863531112671
Validation loss: 1.9906440909190843

Epoch: 6| Step: 5
Training loss: 1.653200387954712
Validation loss: 2.0618572132561797

Epoch: 6| Step: 6
Training loss: 1.7212899923324585
Validation loss: 2.087492145517821

Epoch: 6| Step: 7
Training loss: 1.8700042963027954
Validation loss: 2.007118212279453

Epoch: 6| Step: 8
Training loss: 2.0091757774353027
Validation loss: 2.0185207192615797

Epoch: 6| Step: 9
Training loss: 2.125957489013672
Validation loss: 2.0698201656341553

Epoch: 6| Step: 10
Training loss: 1.5110350847244263
Validation loss: 2.010037914399178

Epoch: 6| Step: 11
Training loss: 1.9320148229599
Validation loss: 2.0396338803793794

Epoch: 6| Step: 12
Training loss: 2.8274083137512207
Validation loss: 2.007060206064614

Epoch: 6| Step: 13
Training loss: 1.7818894386291504
Validation loss: 2.0163866499418854

Epoch: 119| Step: 0
Training loss: 1.491405725479126
Validation loss: 2.086658772601876

Epoch: 6| Step: 1
Training loss: 2.2284319400787354
Validation loss: 2.072229999367909

Epoch: 6| Step: 2
Training loss: 2.4234390258789062
Validation loss: 2.055094806096887

Epoch: 6| Step: 3
Training loss: 2.2934751510620117
Validation loss: 1.9817989116073937

Epoch: 6| Step: 4
Training loss: 1.6010143756866455
Validation loss: 1.9940376281738281

Epoch: 6| Step: 5
Training loss: 2.5318245887756348
Validation loss: 2.0202394890528854

Epoch: 6| Step: 6
Training loss: 1.5468729734420776
Validation loss: 2.027927751182228

Epoch: 6| Step: 7
Training loss: 1.7208471298217773
Validation loss: 2.037610817981023

Epoch: 6| Step: 8
Training loss: 2.3837382793426514
Validation loss: 2.030000553336195

Epoch: 6| Step: 9
Training loss: 2.1719484329223633
Validation loss: 2.0193058418971237

Epoch: 6| Step: 10
Training loss: 2.026866912841797
Validation loss: 2.03085292923835

Epoch: 6| Step: 11
Training loss: 2.489145517349243
Validation loss: 2.0520434610305296

Epoch: 6| Step: 12
Training loss: 2.2659411430358887
Validation loss: 2.0366266030137257

Epoch: 6| Step: 13
Training loss: 1.552496075630188
Validation loss: 2.061848953206052

Epoch: 120| Step: 0
Training loss: 1.9928086996078491
Validation loss: 2.0684301391724618

Epoch: 6| Step: 1
Training loss: 1.9606797695159912
Validation loss: 1.9543571087621874

Epoch: 6| Step: 2
Training loss: 2.144603729248047
Validation loss: 2.010564088821411

Epoch: 6| Step: 3
Training loss: 2.2948555946350098
Validation loss: 2.0206415922411027

Epoch: 6| Step: 4
Training loss: 2.3618621826171875
Validation loss: 1.9844704289590158

Epoch: 6| Step: 5
Training loss: 1.8674434423446655
Validation loss: 2.0227474576683453

Epoch: 6| Step: 6
Training loss: 2.3213086128234863
Validation loss: 2.0584097857116372

Epoch: 6| Step: 7
Training loss: 1.9749699831008911
Validation loss: 2.0237743854522705

Epoch: 6| Step: 8
Training loss: 2.517805814743042
Validation loss: 2.0661025995849283

Epoch: 6| Step: 9
Training loss: 1.8140311241149902
Validation loss: 2.113266114265688

Epoch: 6| Step: 10
Training loss: 1.649117112159729
Validation loss: 2.0388591315156672

Epoch: 6| Step: 11
Training loss: 1.5183484554290771
Validation loss: 2.0203159842439877

Epoch: 6| Step: 12
Training loss: 2.147212028503418
Validation loss: 2.0597342214276715

Epoch: 6| Step: 13
Training loss: 1.7314491271972656
Validation loss: 1.971401442763626

Epoch: 121| Step: 0
Training loss: 2.0187110900878906
Validation loss: 2.0693131031528598

Epoch: 6| Step: 1
Training loss: 1.619767665863037
Validation loss: 2.004111316896254

Epoch: 6| Step: 2
Training loss: 1.9594452381134033
Validation loss: 2.0584427208028813

Epoch: 6| Step: 3
Training loss: 1.9625673294067383
Validation loss: 2.063127251081569

Epoch: 6| Step: 4
Training loss: 2.0304272174835205
Validation loss: 2.0843727845017628

Epoch: 6| Step: 5
Training loss: 2.008629560470581
Validation loss: 1.9977113200772194

Epoch: 6| Step: 6
Training loss: 1.7900654077529907
Validation loss: 1.955382186879394

Epoch: 6| Step: 7
Training loss: 2.6992759704589844
Validation loss: 2.0409505508279286

Epoch: 6| Step: 8
Training loss: 1.4928803443908691
Validation loss: 2.0569797049286547

Epoch: 6| Step: 9
Training loss: 2.315319061279297
Validation loss: 2.005516162482641

Epoch: 6| Step: 10
Training loss: 2.473580837249756
Validation loss: 2.034792835994433

Epoch: 6| Step: 11
Training loss: 2.0949268341064453
Validation loss: 2.009721165062279

Epoch: 6| Step: 12
Training loss: 2.0757219791412354
Validation loss: 2.0245605745623187

Epoch: 6| Step: 13
Training loss: 2.073082208633423
Validation loss: 2.0053220743774087

Epoch: 122| Step: 0
Training loss: 2.8434486389160156
Validation loss: 2.0331656035556587

Epoch: 6| Step: 1
Training loss: 2.183351993560791
Validation loss: 2.056128373710058

Epoch: 6| Step: 2
Training loss: 1.6482723951339722
Validation loss: 2.030371589045371

Epoch: 6| Step: 3
Training loss: 1.8647080659866333
Validation loss: 2.005267389359013

Epoch: 6| Step: 4
Training loss: 1.7391343116760254
Validation loss: 2.1084739046712078

Epoch: 6| Step: 5
Training loss: 1.751076102256775
Validation loss: 2.028401732444763

Epoch: 6| Step: 6
Training loss: 2.463132381439209
Validation loss: 2.016088742081837

Epoch: 6| Step: 7
Training loss: 1.8691284656524658
Validation loss: 2.0423736982448126

Epoch: 6| Step: 8
Training loss: 2.4773595333099365
Validation loss: 2.0032440449601863

Epoch: 6| Step: 9
Training loss: 1.5621665716171265
Validation loss: 2.0824916772944952

Epoch: 6| Step: 10
Training loss: 1.566807508468628
Validation loss: 2.1107397002558552

Epoch: 6| Step: 11
Training loss: 2.1506896018981934
Validation loss: 2.015541934197949

Epoch: 6| Step: 12
Training loss: 2.731649160385132
Validation loss: 2.0197685918500348

Epoch: 6| Step: 13
Training loss: 1.3362958431243896
Validation loss: 2.079506940739129

Epoch: 123| Step: 0
Training loss: 1.7140462398529053
Validation loss: 2.0529396264783797

Epoch: 6| Step: 1
Training loss: 2.111544132232666
Validation loss: 2.0376291762116137

Epoch: 6| Step: 2
Training loss: 2.203751802444458
Validation loss: 2.0801501017744823

Epoch: 6| Step: 3
Training loss: 1.932989239692688
Validation loss: 2.046239573468444

Epoch: 6| Step: 4
Training loss: 1.6146235466003418
Validation loss: 2.009086888323548

Epoch: 6| Step: 5
Training loss: 2.235003709793091
Validation loss: 2.0278832168989283

Epoch: 6| Step: 6
Training loss: 2.2738046646118164
Validation loss: 2.057386106060397

Epoch: 6| Step: 7
Training loss: 1.8437232971191406
Validation loss: 2.042611324658958

Epoch: 6| Step: 8
Training loss: 2.0583760738372803
Validation loss: 2.049212996677686

Epoch: 6| Step: 9
Training loss: 1.1188910007476807
Validation loss: 2.092285099849906

Epoch: 6| Step: 10
Training loss: 2.2635388374328613
Validation loss: 2.0335253182277886

Epoch: 6| Step: 11
Training loss: 1.7676267623901367
Validation loss: 2.097369824686358

Epoch: 6| Step: 12
Training loss: 2.5658059120178223
Validation loss: 2.1194248891645864

Epoch: 6| Step: 13
Training loss: 2.552387237548828
Validation loss: 2.031281817343927

Epoch: 124| Step: 0
Training loss: 1.5747156143188477
Validation loss: 2.031751722417852

Epoch: 6| Step: 1
Training loss: 1.8135733604431152
Validation loss: 2.012836821617619

Epoch: 6| Step: 2
Training loss: 2.338576555252075
Validation loss: 2.0583986364385134

Epoch: 6| Step: 3
Training loss: 2.071319103240967
Validation loss: 2.0942911486471854

Epoch: 6| Step: 4
Training loss: 3.172818183898926
Validation loss: 2.0885253644758657

Epoch: 6| Step: 5
Training loss: 1.5914547443389893
Validation loss: 2.0203027750856135

Epoch: 6| Step: 6
Training loss: 2.142939567565918
Validation loss: 2.1087877981124388

Epoch: 6| Step: 7
Training loss: 2.2120718955993652
Validation loss: 2.09919669038506

Epoch: 6| Step: 8
Training loss: 1.9855830669403076
Validation loss: 2.0092845988529984

Epoch: 6| Step: 9
Training loss: 1.9491289854049683
Validation loss: 2.011166795607536

Epoch: 6| Step: 10
Training loss: 1.3983943462371826
Validation loss: 2.086144317862808

Epoch: 6| Step: 11
Training loss: 2.1005916595458984
Validation loss: 2.0637478136247203

Epoch: 6| Step: 12
Training loss: 2.195547103881836
Validation loss: 2.032118438392557

Epoch: 6| Step: 13
Training loss: 1.738869071006775
Validation loss: 2.0244152776656614

Epoch: 125| Step: 0
Training loss: 1.8718523979187012
Validation loss: 2.0203328042901973

Epoch: 6| Step: 1
Training loss: 2.67204213142395
Validation loss: 2.0318634202403407

Epoch: 6| Step: 2
Training loss: 2.0693233013153076
Validation loss: 2.010122242794242

Epoch: 6| Step: 3
Training loss: 2.4765729904174805
Validation loss: 1.9685956149972894

Epoch: 6| Step: 4
Training loss: 1.718796968460083
Validation loss: 2.0354049462144093

Epoch: 6| Step: 5
Training loss: 1.780922293663025
Validation loss: 2.051197108402047

Epoch: 6| Step: 6
Training loss: 2.292670965194702
Validation loss: 1.9908200694668678

Epoch: 6| Step: 7
Training loss: 1.9411067962646484
Validation loss: 2.0274512114063388

Epoch: 6| Step: 8
Training loss: 1.4600677490234375
Validation loss: 2.0174050972025883

Epoch: 6| Step: 9
Training loss: 1.762550711631775
Validation loss: 2.0281760410595964

Epoch: 6| Step: 10
Training loss: 2.213320255279541
Validation loss: 1.9921699608525922

Epoch: 6| Step: 11
Training loss: 2.0084242820739746
Validation loss: 2.0355695434795913

Epoch: 6| Step: 12
Training loss: 2.0524466037750244
Validation loss: 2.036920048857248

Epoch: 6| Step: 13
Training loss: 1.5482728481292725
Validation loss: 2.0406049041337866

Epoch: 126| Step: 0
Training loss: 1.9578053951263428
Validation loss: 2.055752500411003

Epoch: 6| Step: 1
Training loss: 1.840022325515747
Validation loss: 1.9951154801153368

Epoch: 6| Step: 2
Training loss: 1.9770631790161133
Validation loss: 2.0162346234885593

Epoch: 6| Step: 3
Training loss: 1.766137719154358
Validation loss: 1.9912334488284202

Epoch: 6| Step: 4
Training loss: 2.0254018306732178
Validation loss: 2.0398823215115454

Epoch: 6| Step: 5
Training loss: 2.1845409870147705
Validation loss: 1.997297397223852

Epoch: 6| Step: 6
Training loss: 1.581591010093689
Validation loss: 2.00745734348092

Epoch: 6| Step: 7
Training loss: 2.57334566116333
Validation loss: 2.023752053578695

Epoch: 6| Step: 8
Training loss: 1.6185698509216309
Validation loss: 2.0625179403571674

Epoch: 6| Step: 9
Training loss: 2.178849458694458
Validation loss: 2.047942872970335

Epoch: 6| Step: 10
Training loss: 2.6734018325805664
Validation loss: 1.9977475981558523

Epoch: 6| Step: 11
Training loss: 1.9660851955413818
Validation loss: 2.060188170402281

Epoch: 6| Step: 12
Training loss: 1.6729744672775269
Validation loss: 2.034959654654226

Epoch: 6| Step: 13
Training loss: 2.036731481552124
Validation loss: 2.0306510463837655

Epoch: 127| Step: 0
Training loss: 2.1211962699890137
Validation loss: 2.028852069249717

Epoch: 6| Step: 1
Training loss: 1.8200900554656982
Validation loss: 2.0816275176181587

Epoch: 6| Step: 2
Training loss: 2.5084407329559326
Validation loss: 2.1420480435894382

Epoch: 6| Step: 3
Training loss: 2.569133758544922
Validation loss: 2.0333664417266846

Epoch: 6| Step: 4
Training loss: 1.4967865943908691
Validation loss: 2.121289933881452

Epoch: 6| Step: 5
Training loss: 2.150153636932373
Validation loss: 2.012136906705877

Epoch: 6| Step: 6
Training loss: 1.545910358428955
Validation loss: 2.0923503534768217

Epoch: 6| Step: 7
Training loss: 2.281968355178833
Validation loss: 2.0765210274727113

Epoch: 6| Step: 8
Training loss: 1.3549199104309082
Validation loss: 2.0539487946418022

Epoch: 6| Step: 9
Training loss: 2.606517791748047
Validation loss: 1.9754560327017179

Epoch: 6| Step: 10
Training loss: 2.2543587684631348
Validation loss: 1.9991457590492823

Epoch: 6| Step: 11
Training loss: 1.5830966234207153
Validation loss: 2.0538629178077943

Epoch: 6| Step: 12
Training loss: 1.875628113746643
Validation loss: 2.1105671108409925

Epoch: 6| Step: 13
Training loss: 2.6382718086242676
Validation loss: 2.0111362113747546

Epoch: 128| Step: 0
Training loss: 1.8938761949539185
Validation loss: 2.0321161259887037

Epoch: 6| Step: 1
Training loss: 1.748929738998413
Validation loss: 2.0357148019216393

Epoch: 6| Step: 2
Training loss: 2.35809063911438
Validation loss: 2.068766881060857

Epoch: 6| Step: 3
Training loss: 1.6785575151443481
Validation loss: 2.0546961830508326

Epoch: 6| Step: 4
Training loss: 2.4585742950439453
Validation loss: 1.945051823892901

Epoch: 6| Step: 5
Training loss: 2.1869139671325684
Validation loss: 2.081777782850368

Epoch: 6| Step: 6
Training loss: 2.5719571113586426
Validation loss: 2.03464925160972

Epoch: 6| Step: 7
Training loss: 1.9792280197143555
Validation loss: 2.007033981302733

Epoch: 6| Step: 8
Training loss: 1.3944884538650513
Validation loss: 1.9991375015627952

Epoch: 6| Step: 9
Training loss: 1.8704540729522705
Validation loss: 2.054404197200652

Epoch: 6| Step: 10
Training loss: 1.959984302520752
Validation loss: 2.0755036210501068

Epoch: 6| Step: 11
Training loss: 2.126081943511963
Validation loss: 2.0613994931661956

Epoch: 6| Step: 12
Training loss: 1.9380427598953247
Validation loss: 2.0257207501319145

Epoch: 6| Step: 13
Training loss: 1.8748433589935303
Validation loss: 2.003405499201949

Epoch: 129| Step: 0
Training loss: 1.395222783088684
Validation loss: 2.043990417193341

Epoch: 6| Step: 1
Training loss: 2.3468689918518066
Validation loss: 1.9811770787803076

Epoch: 6| Step: 2
Training loss: 2.9104418754577637
Validation loss: 2.006302856629895

Epoch: 6| Step: 3
Training loss: 1.7476942539215088
Validation loss: 2.0151439994894047

Epoch: 6| Step: 4
Training loss: 1.547753095626831
Validation loss: 2.14800956685056

Epoch: 6| Step: 5
Training loss: 1.85482656955719
Validation loss: 2.0566103202040478

Epoch: 6| Step: 6
Training loss: 2.004979133605957
Validation loss: 2.040283956835347

Epoch: 6| Step: 7
Training loss: 1.8030893802642822
Validation loss: 2.065001041658463

Epoch: 6| Step: 8
Training loss: 2.7161810398101807
Validation loss: 2.084158594890307

Epoch: 6| Step: 9
Training loss: 1.8302823305130005
Validation loss: 2.070130700706154

Epoch: 6| Step: 10
Training loss: 2.0312790870666504
Validation loss: 2.068674390034009

Epoch: 6| Step: 11
Training loss: 2.3677971363067627
Validation loss: 2.0239290806554977

Epoch: 6| Step: 12
Training loss: 2.267226219177246
Validation loss: 2.012432122743258

Epoch: 6| Step: 13
Training loss: 2.722024440765381
Validation loss: 2.018081554802515

Epoch: 130| Step: 0
Training loss: 2.0137856006622314
Validation loss: 2.041402277126107

Epoch: 6| Step: 1
Training loss: 2.109475612640381
Validation loss: 2.0158615176395704

Epoch: 6| Step: 2
Training loss: 1.72422456741333
Validation loss: 2.0352165263186217

Epoch: 6| Step: 3
Training loss: 2.1489877700805664
Validation loss: 1.958212007758438

Epoch: 6| Step: 4
Training loss: 1.7257287502288818
Validation loss: 1.992145513975492

Epoch: 6| Step: 5
Training loss: 2.303194046020508
Validation loss: 1.9973964357888827

Epoch: 6| Step: 6
Training loss: 2.1561524868011475
Validation loss: 1.9753455743994763

Epoch: 6| Step: 7
Training loss: 1.4797956943511963
Validation loss: 2.0175556277716034

Epoch: 6| Step: 8
Training loss: 2.38020658493042
Validation loss: 2.0297361932775027

Epoch: 6| Step: 9
Training loss: 1.7979736328125
Validation loss: 2.015350082869171

Epoch: 6| Step: 10
Training loss: 1.5706335306167603
Validation loss: 1.9862556944611252

Epoch: 6| Step: 11
Training loss: 2.28983736038208
Validation loss: 1.9557083229864798

Epoch: 6| Step: 12
Training loss: 1.9745793342590332
Validation loss: 2.034533058443377

Epoch: 6| Step: 13
Training loss: 1.86240816116333
Validation loss: 2.049906389687651

Epoch: 131| Step: 0
Training loss: 1.7353951930999756
Validation loss: 2.003772161340201

Epoch: 6| Step: 1
Training loss: 1.9066616296768188
Validation loss: 2.0399099344848306

Epoch: 6| Step: 2
Training loss: 1.3019382953643799
Validation loss: 2.00115192321039

Epoch: 6| Step: 3
Training loss: 2.5552749633789062
Validation loss: 2.057082695345725

Epoch: 6| Step: 4
Training loss: 2.1050615310668945
Validation loss: 2.021851626775598

Epoch: 6| Step: 5
Training loss: 1.5162830352783203
Validation loss: 2.0243744939886112

Epoch: 6| Step: 6
Training loss: 2.2119054794311523
Validation loss: 1.99351930105558

Epoch: 6| Step: 7
Training loss: 1.8188830614089966
Validation loss: 2.027144470522481

Epoch: 6| Step: 8
Training loss: 2.3451316356658936
Validation loss: 2.0263831077083463

Epoch: 6| Step: 9
Training loss: 1.8078866004943848
Validation loss: 2.0394103014340965

Epoch: 6| Step: 10
Training loss: 1.7975664138793945
Validation loss: 2.035987150284552

Epoch: 6| Step: 11
Training loss: 2.7330899238586426
Validation loss: 2.0598921647635837

Epoch: 6| Step: 12
Training loss: 1.7861814498901367
Validation loss: 2.0699991128777944

Epoch: 6| Step: 13
Training loss: 2.8350605964660645
Validation loss: 2.076530938507408

Epoch: 132| Step: 0
Training loss: 2.1644339561462402
Validation loss: 2.0631970205614643

Epoch: 6| Step: 1
Training loss: 1.9885550737380981
Validation loss: 1.9860686153493903

Epoch: 6| Step: 2
Training loss: 2.275294303894043
Validation loss: 2.024443527703644

Epoch: 6| Step: 3
Training loss: 1.4272079467773438
Validation loss: 2.051508847103324

Epoch: 6| Step: 4
Training loss: 1.4669491052627563
Validation loss: 2.0171572110986196

Epoch: 6| Step: 5
Training loss: 1.9083144664764404
Validation loss: 2.0591412334031958

Epoch: 6| Step: 6
Training loss: 0.8203806281089783
Validation loss: 1.9623229477995185

Epoch: 6| Step: 7
Training loss: 2.359098434448242
Validation loss: 2.047643699953633

Epoch: 6| Step: 8
Training loss: 2.443894863128662
Validation loss: 1.981690634963333

Epoch: 6| Step: 9
Training loss: 2.234328269958496
Validation loss: 2.032987394640523

Epoch: 6| Step: 10
Training loss: 2.328403949737549
Validation loss: 2.0385175084555023

Epoch: 6| Step: 11
Training loss: 2.024749517440796
Validation loss: 2.0271431707566783

Epoch: 6| Step: 12
Training loss: 1.8179048299789429
Validation loss: 2.0280132062973513

Epoch: 6| Step: 13
Training loss: 2.6356306076049805
Validation loss: 1.9806223351468322

Epoch: 133| Step: 0
Training loss: 1.9372873306274414
Validation loss: 2.0699354358898696

Epoch: 6| Step: 1
Training loss: 1.970051646232605
Validation loss: 2.023417765094388

Epoch: 6| Step: 2
Training loss: 1.8109691143035889
Validation loss: 2.085344515820985

Epoch: 6| Step: 3
Training loss: 2.3502254486083984
Validation loss: 1.9812621108947261

Epoch: 6| Step: 4
Training loss: 1.8090888261795044
Validation loss: 2.0653736206793014

Epoch: 6| Step: 5
Training loss: 2.505441665649414
Validation loss: 1.9785340550125285

Epoch: 6| Step: 6
Training loss: 2.8262522220611572
Validation loss: 2.0646877750273673

Epoch: 6| Step: 7
Training loss: 1.8498882055282593
Validation loss: 2.0217606316330614

Epoch: 6| Step: 8
Training loss: 2.816899299621582
Validation loss: 2.082714839648175

Epoch: 6| Step: 9
Training loss: 1.6455669403076172
Validation loss: 2.048020480781473

Epoch: 6| Step: 10
Training loss: 1.0155532360076904
Validation loss: 2.0243597569004184

Epoch: 6| Step: 11
Training loss: 1.3944205045700073
Validation loss: 2.011403992611875

Epoch: 6| Step: 12
Training loss: 1.5387451648712158
Validation loss: 2.00122102614372

Epoch: 6| Step: 13
Training loss: 2.6674015522003174
Validation loss: 2.065901041030884

Epoch: 134| Step: 0
Training loss: 2.459951400756836
Validation loss: 2.0479532954513386

Epoch: 6| Step: 1
Training loss: 1.3951228857040405
Validation loss: 1.9931536361735354

Epoch: 6| Step: 2
Training loss: 1.8879246711730957
Validation loss: 2.03458490679341

Epoch: 6| Step: 3
Training loss: 2.049022674560547
Validation loss: 2.04342972078631

Epoch: 6| Step: 4
Training loss: 1.8607255220413208
Validation loss: 2.0370668852201073

Epoch: 6| Step: 5
Training loss: 1.9576102495193481
Validation loss: 2.026802732098487

Epoch: 6| Step: 6
Training loss: 2.041506767272949
Validation loss: 2.0468565058964554

Epoch: 6| Step: 7
Training loss: 2.545194149017334
Validation loss: 2.0242129282284806

Epoch: 6| Step: 8
Training loss: 1.5779790878295898
Validation loss: 2.097851284088627

Epoch: 6| Step: 9
Training loss: 1.360131859779358
Validation loss: 2.0242472387129262

Epoch: 6| Step: 10
Training loss: 2.3784947395324707
Validation loss: 1.9953781481712096

Epoch: 6| Step: 11
Training loss: 1.620535135269165
Validation loss: 2.0183539890473887

Epoch: 6| Step: 12
Training loss: 2.623417854309082
Validation loss: 2.0631624703766196

Epoch: 6| Step: 13
Training loss: 1.862130880355835
Validation loss: 1.9972648812878517

Epoch: 135| Step: 0
Training loss: 1.2874491214752197
Validation loss: 2.018093534695205

Epoch: 6| Step: 1
Training loss: 2.058347225189209
Validation loss: 2.0165333081317205

Epoch: 6| Step: 2
Training loss: 1.485827922821045
Validation loss: 2.0631751783432497

Epoch: 6| Step: 3
Training loss: 2.109990119934082
Validation loss: 2.041888289554145

Epoch: 6| Step: 4
Training loss: 1.7899560928344727
Validation loss: 2.070320861313933

Epoch: 6| Step: 5
Training loss: 2.101005792617798
Validation loss: 2.0781163413037538

Epoch: 6| Step: 6
Training loss: 2.021139621734619
Validation loss: 2.0520112181222565

Epoch: 6| Step: 7
Training loss: 2.332606315612793
Validation loss: 2.1206650298128844

Epoch: 6| Step: 8
Training loss: 1.7532286643981934
Validation loss: 2.0563678459454606

Epoch: 6| Step: 9
Training loss: 2.1751928329467773
Validation loss: 2.065616242347225

Epoch: 6| Step: 10
Training loss: 2.2288894653320312
Validation loss: 2.039217687422229

Epoch: 6| Step: 11
Training loss: 2.149014711380005
Validation loss: 2.0421841939290366

Epoch: 6| Step: 12
Training loss: 1.9045891761779785
Validation loss: 2.1356120109558105

Epoch: 6| Step: 13
Training loss: 2.934528350830078
Validation loss: 2.007280827850424

Epoch: 136| Step: 0
Training loss: 1.994809865951538
Validation loss: 2.070715694017308

Epoch: 6| Step: 1
Training loss: 1.5166442394256592
Validation loss: 2.0453655232665358

Epoch: 6| Step: 2
Training loss: 1.9669207334518433
Validation loss: 2.0768447986213108

Epoch: 6| Step: 3
Training loss: 2.4243128299713135
Validation loss: 1.97648653932797

Epoch: 6| Step: 4
Training loss: 2.053650140762329
Validation loss: 2.024510333614965

Epoch: 6| Step: 5
Training loss: 2.0949954986572266
Validation loss: 2.043209240000735

Epoch: 6| Step: 6
Training loss: 1.872243881225586
Validation loss: 2.0170232724117976

Epoch: 6| Step: 7
Training loss: 1.9352688789367676
Validation loss: 1.9707466940726004

Epoch: 6| Step: 8
Training loss: 2.037548542022705
Validation loss: 1.959720503899359

Epoch: 6| Step: 9
Training loss: 2.227848768234253
Validation loss: 1.9920556775985225

Epoch: 6| Step: 10
Training loss: 1.2768123149871826
Validation loss: 2.007186492284139

Epoch: 6| Step: 11
Training loss: 2.136657476425171
Validation loss: 2.031803164430844

Epoch: 6| Step: 12
Training loss: 1.8592280149459839
Validation loss: 2.029353132811926

Epoch: 6| Step: 13
Training loss: 2.608121395111084
Validation loss: 1.9380713073156213

Epoch: 137| Step: 0
Training loss: 2.1213338375091553
Validation loss: 2.0344597088393344

Epoch: 6| Step: 1
Training loss: 2.3863110542297363
Validation loss: 2.0029712646238265

Epoch: 6| Step: 2
Training loss: 2.129570484161377
Validation loss: 2.0758337077274116

Epoch: 6| Step: 3
Training loss: 2.276615619659424
Validation loss: 1.9886282067145071

Epoch: 6| Step: 4
Training loss: 2.1137094497680664
Validation loss: 1.9720624146922943

Epoch: 6| Step: 5
Training loss: 1.5161980390548706
Validation loss: 1.9806289442123906

Epoch: 6| Step: 6
Training loss: 1.6447522640228271
Validation loss: 2.0363010924349547

Epoch: 6| Step: 7
Training loss: 1.4348855018615723
Validation loss: 2.0003410244500763

Epoch: 6| Step: 8
Training loss: 2.9036223888397217
Validation loss: 1.9768749513933737

Epoch: 6| Step: 9
Training loss: 2.473841667175293
Validation loss: 2.021049976348877

Epoch: 6| Step: 10
Training loss: 1.9333155155181885
Validation loss: 2.056610404804189

Epoch: 6| Step: 11
Training loss: 1.567791223526001
Validation loss: 2.041008867243285

Epoch: 6| Step: 12
Training loss: 1.7837975025177002
Validation loss: 2.04185256906735

Epoch: 6| Step: 13
Training loss: 1.6996099948883057
Validation loss: 2.0008672411723802

Epoch: 138| Step: 0
Training loss: 2.660245656967163
Validation loss: 2.0440457174854894

Epoch: 6| Step: 1
Training loss: 1.8206838369369507
Validation loss: 2.046876912475914

Epoch: 6| Step: 2
Training loss: 1.705298662185669
Validation loss: 1.9916616332146428

Epoch: 6| Step: 3
Training loss: 1.7668101787567139
Validation loss: 2.044328635738742

Epoch: 6| Step: 4
Training loss: 1.962113618850708
Validation loss: 2.0640120839559906

Epoch: 6| Step: 5
Training loss: 1.5922064781188965
Validation loss: 2.0597354724843013

Epoch: 6| Step: 6
Training loss: 1.982752799987793
Validation loss: 1.9731627305348713

Epoch: 6| Step: 7
Training loss: 2.158236503601074
Validation loss: 2.0554642574761504

Epoch: 6| Step: 8
Training loss: 1.3405358791351318
Validation loss: 2.0467504750015917

Epoch: 6| Step: 9
Training loss: 1.306769847869873
Validation loss: 2.020194593296256

Epoch: 6| Step: 10
Training loss: 1.925652265548706
Validation loss: 2.037138190320743

Epoch: 6| Step: 11
Training loss: 2.665130615234375
Validation loss: 1.9971906087731803

Epoch: 6| Step: 12
Training loss: 1.457301378250122
Validation loss: 2.037524897565124

Epoch: 6| Step: 13
Training loss: 3.4377689361572266
Validation loss: 2.013185695935321

Epoch: 139| Step: 0
Training loss: 1.9207260608673096
Validation loss: 2.0179015615934968

Epoch: 6| Step: 1
Training loss: 2.165034770965576
Validation loss: 1.9835134949735416

Epoch: 6| Step: 2
Training loss: 2.94498872756958
Validation loss: 1.9857189040030203

Epoch: 6| Step: 3
Training loss: 1.863905906677246
Validation loss: 2.074520718666815

Epoch: 6| Step: 4
Training loss: 2.333465814590454
Validation loss: 1.9671201372659335

Epoch: 6| Step: 5
Training loss: 2.228257179260254
Validation loss: 2.0331067295484644

Epoch: 6| Step: 6
Training loss: 1.063628911972046
Validation loss: 2.0590977053488455

Epoch: 6| Step: 7
Training loss: 1.511711597442627
Validation loss: 2.047447657072416

Epoch: 6| Step: 8
Training loss: 1.8629473447799683
Validation loss: 2.0031600870111936

Epoch: 6| Step: 9
Training loss: 2.857862949371338
Validation loss: 1.9527650110183223

Epoch: 6| Step: 10
Training loss: 1.1291297674179077
Validation loss: 2.0100198779054868

Epoch: 6| Step: 11
Training loss: 2.2847602367401123
Validation loss: 2.067278805599418

Epoch: 6| Step: 12
Training loss: 2.474721908569336
Validation loss: 1.9636780138938659

Epoch: 6| Step: 13
Training loss: 0.3115829527378082
Validation loss: 2.0082571121954147

Epoch: 140| Step: 0
Training loss: 2.3820693492889404
Validation loss: 1.9932289251717188

Epoch: 6| Step: 1
Training loss: 2.353641986846924
Validation loss: 2.0406737814667406

Epoch: 6| Step: 2
Training loss: 1.9787614345550537
Validation loss: 2.0340901869599537

Epoch: 6| Step: 3
Training loss: 1.94822096824646
Validation loss: 1.9806082735779464

Epoch: 6| Step: 4
Training loss: 2.232815742492676
Validation loss: 2.0385178622379097

Epoch: 6| Step: 5
Training loss: 1.7148950099945068
Validation loss: 2.0375071417900825

Epoch: 6| Step: 6
Training loss: 2.7144765853881836
Validation loss: 2.062000648949736

Epoch: 6| Step: 7
Training loss: 1.8505127429962158
Validation loss: 2.1075960102901665

Epoch: 6| Step: 8
Training loss: 1.7717463970184326
Validation loss: 2.0490423505024244

Epoch: 6| Step: 9
Training loss: 1.6496319770812988
Validation loss: 2.0579670552284486

Epoch: 6| Step: 10
Training loss: 1.7105121612548828
Validation loss: 2.0797644097317933

Epoch: 6| Step: 11
Training loss: 1.6039206981658936
Validation loss: 1.9694775509577926

Epoch: 6| Step: 12
Training loss: 2.300938606262207
Validation loss: 2.0657570592818724

Epoch: 6| Step: 13
Training loss: 1.0459542274475098
Validation loss: 2.0414740603457213

Epoch: 141| Step: 0
Training loss: 2.139742851257324
Validation loss: 2.0711085373355496

Epoch: 6| Step: 1
Training loss: 2.2409186363220215
Validation loss: 1.9790950564927952

Epoch: 6| Step: 2
Training loss: 2.144361972808838
Validation loss: 2.0418710529163318

Epoch: 6| Step: 3
Training loss: 2.639028310775757
Validation loss: 1.9851097676061815

Epoch: 6| Step: 4
Training loss: 2.111978530883789
Validation loss: 1.9538481927687121

Epoch: 6| Step: 5
Training loss: 2.121469736099243
Validation loss: 2.0240086509335424

Epoch: 6| Step: 6
Training loss: 1.400637149810791
Validation loss: 1.9920588565129105

Epoch: 6| Step: 7
Training loss: 1.9315900802612305
Validation loss: 2.0149096840171405

Epoch: 6| Step: 8
Training loss: 1.3792500495910645
Validation loss: 2.025454854452482

Epoch: 6| Step: 9
Training loss: 2.1041741371154785
Validation loss: 2.0251719400446904

Epoch: 6| Step: 10
Training loss: 1.9681484699249268
Validation loss: 1.9515285568852578

Epoch: 6| Step: 11
Training loss: 1.5318067073822021
Validation loss: 2.0623422386825725

Epoch: 6| Step: 12
Training loss: 2.1231346130371094
Validation loss: 2.0024452158199844

Epoch: 6| Step: 13
Training loss: 1.445528507232666
Validation loss: 1.9777132823903074

Epoch: 142| Step: 0
Training loss: 2.2692155838012695
Validation loss: 2.0358035102967293

Epoch: 6| Step: 1
Training loss: 1.7382363080978394
Validation loss: 2.062232650736327

Epoch: 6| Step: 2
Training loss: 2.338385581970215
Validation loss: 2.0505648941122074

Epoch: 6| Step: 3
Training loss: 1.0502307415008545
Validation loss: 2.0903457210909937

Epoch: 6| Step: 4
Training loss: 2.1422417163848877
Validation loss: 2.0058770256657756

Epoch: 6| Step: 5
Training loss: 2.1618685722351074
Validation loss: 2.112570548570284

Epoch: 6| Step: 6
Training loss: 2.431891441345215
Validation loss: 2.0557422637939453

Epoch: 6| Step: 7
Training loss: 1.914910078048706
Validation loss: 2.043253952457059

Epoch: 6| Step: 8
Training loss: 2.176302433013916
Validation loss: 2.0327126082553657

Epoch: 6| Step: 9
Training loss: 1.6979165077209473
Validation loss: 2.0592925497280654

Epoch: 6| Step: 10
Training loss: 1.1245609521865845
Validation loss: 2.043929308973333

Epoch: 6| Step: 11
Training loss: 2.0445399284362793
Validation loss: 1.99189894430099

Epoch: 6| Step: 12
Training loss: 2.1303577423095703
Validation loss: 1.9936796272954633

Epoch: 6| Step: 13
Training loss: 2.0468149185180664
Validation loss: 2.0360174448259416

Epoch: 143| Step: 0
Training loss: 2.040172576904297
Validation loss: 2.0268542843480266

Epoch: 6| Step: 1
Training loss: 1.2839140892028809
Validation loss: 2.011286048478978

Epoch: 6| Step: 2
Training loss: 1.8018399477005005
Validation loss: 2.0260181760275238

Epoch: 6| Step: 3
Training loss: 2.426281452178955
Validation loss: 1.9844857441481722

Epoch: 6| Step: 4
Training loss: 2.5033111572265625
Validation loss: 1.9623776584543207

Epoch: 6| Step: 5
Training loss: 1.7504332065582275
Validation loss: 1.9876416255069036

Epoch: 6| Step: 6
Training loss: 1.380782961845398
Validation loss: 1.9872306085401965

Epoch: 6| Step: 7
Training loss: 1.9991340637207031
Validation loss: 1.9897078801226873

Epoch: 6| Step: 8
Training loss: 1.3339042663574219
Validation loss: 1.968408405139882

Epoch: 6| Step: 9
Training loss: 1.7784761190414429
Validation loss: 2.060349614389481

Epoch: 6| Step: 10
Training loss: 2.598045587539673
Validation loss: 2.024051372722913

Epoch: 6| Step: 11
Training loss: 2.3185176849365234
Validation loss: 1.9785373890271751

Epoch: 6| Step: 12
Training loss: 1.984631061553955
Validation loss: 2.0109118735918434

Epoch: 6| Step: 13
Training loss: 2.225388526916504
Validation loss: 1.9590493325264222

Epoch: 144| Step: 0
Training loss: 1.938760757446289
Validation loss: 1.9660477868972286

Epoch: 6| Step: 1
Training loss: 1.71342933177948
Validation loss: 2.037189083714639

Epoch: 6| Step: 2
Training loss: 1.2051479816436768
Validation loss: 2.0339869760697886

Epoch: 6| Step: 3
Training loss: 2.0000758171081543
Validation loss: 1.9633782679034817

Epoch: 6| Step: 4
Training loss: 1.3584635257720947
Validation loss: 1.9979465174418625

Epoch: 6| Step: 5
Training loss: 1.2505333423614502
Validation loss: 1.981672861242807

Epoch: 6| Step: 6
Training loss: 2.414994239807129
Validation loss: 1.978716205525142

Epoch: 6| Step: 7
Training loss: 2.2712531089782715
Validation loss: 2.0239250224123717

Epoch: 6| Step: 8
Training loss: 2.018235445022583
Validation loss: 2.010716263965894

Epoch: 6| Step: 9
Training loss: 3.009460926055908
Validation loss: 2.0003623167673745

Epoch: 6| Step: 10
Training loss: 2.510565757751465
Validation loss: 2.0157874040706183

Epoch: 6| Step: 11
Training loss: 2.0732154846191406
Validation loss: 1.9898230721873622

Epoch: 6| Step: 12
Training loss: 2.1098742485046387
Validation loss: 2.018050847514983

Epoch: 6| Step: 13
Training loss: 1.6138410568237305
Validation loss: 2.0061959156426052

Epoch: 145| Step: 0
Training loss: 2.148563861846924
Validation loss: 1.9959667574974798

Epoch: 6| Step: 1
Training loss: 1.900512456893921
Validation loss: 2.000611618000974

Epoch: 6| Step: 2
Training loss: 2.432100534439087
Validation loss: 1.9944467134373163

Epoch: 6| Step: 3
Training loss: 2.2844512462615967
Validation loss: 2.000976485590781

Epoch: 6| Step: 4
Training loss: 1.2451226711273193
Validation loss: 2.011308903335243

Epoch: 6| Step: 5
Training loss: 2.08994460105896
Validation loss: 2.060913580720143

Epoch: 6| Step: 6
Training loss: 1.8055824041366577
Validation loss: 2.0694403648376465

Epoch: 6| Step: 7
Training loss: 1.6794507503509521
Validation loss: 2.0242985986894175

Epoch: 6| Step: 8
Training loss: 1.9312269687652588
Validation loss: 1.9900187971771404

Epoch: 6| Step: 9
Training loss: 1.3948698043823242
Validation loss: 2.051424503326416

Epoch: 6| Step: 10
Training loss: 2.4420011043548584
Validation loss: 2.0274096048006447

Epoch: 6| Step: 11
Training loss: 3.2956113815307617
Validation loss: 1.972813553707574

Epoch: 6| Step: 12
Training loss: 1.2543542385101318
Validation loss: 2.022654680795567

Epoch: 6| Step: 13
Training loss: 1.912433385848999
Validation loss: 1.9694908280526437

Epoch: 146| Step: 0
Training loss: 1.632842779159546
Validation loss: 2.0359897152070077

Epoch: 6| Step: 1
Training loss: 1.9469795227050781
Validation loss: 1.9280908569212882

Epoch: 6| Step: 2
Training loss: 2.020498037338257
Validation loss: 2.0380488108563166

Epoch: 6| Step: 3
Training loss: 1.5824689865112305
Validation loss: 1.9735133071099558

Epoch: 6| Step: 4
Training loss: 2.493210554122925
Validation loss: 1.9509931738658617

Epoch: 6| Step: 5
Training loss: 1.4802128076553345
Validation loss: 1.9897479267530545

Epoch: 6| Step: 6
Training loss: 1.8438407182693481
Validation loss: 2.034619664633146

Epoch: 6| Step: 7
Training loss: 2.3997249603271484
Validation loss: 1.9879977395457606

Epoch: 6| Step: 8
Training loss: 2.4396250247955322
Validation loss: 2.0122003337388397

Epoch: 6| Step: 9
Training loss: 1.8395795822143555
Validation loss: 2.0065452219337545

Epoch: 6| Step: 10
Training loss: 2.267448663711548
Validation loss: 2.009672204653422

Epoch: 6| Step: 11
Training loss: 1.842432975769043
Validation loss: 2.0022052359837357

Epoch: 6| Step: 12
Training loss: 1.4519531726837158
Validation loss: 1.9832803023758756

Epoch: 6| Step: 13
Training loss: 2.3976218700408936
Validation loss: 2.0115225199730165

Epoch: 147| Step: 0
Training loss: 2.089439630508423
Validation loss: 2.02564827857479

Epoch: 6| Step: 1
Training loss: 1.7303420305252075
Validation loss: 2.0077011380144345

Epoch: 6| Step: 2
Training loss: 1.6411994695663452
Validation loss: 2.0330628015661754

Epoch: 6| Step: 3
Training loss: 1.6725072860717773
Validation loss: 2.009704948753439

Epoch: 6| Step: 4
Training loss: 1.4555692672729492
Validation loss: 2.0308973148304927

Epoch: 6| Step: 5
Training loss: 1.7482893466949463
Validation loss: 2.050397297387482

Epoch: 6| Step: 6
Training loss: 2.1512343883514404
Validation loss: 2.014912336103378

Epoch: 6| Step: 7
Training loss: 2.251300573348999
Validation loss: 2.0210254987080893

Epoch: 6| Step: 8
Training loss: 1.4572675228118896
Validation loss: 2.0258913950253556

Epoch: 6| Step: 9
Training loss: 1.8344755172729492
Validation loss: 2.0540977267808813

Epoch: 6| Step: 10
Training loss: 2.3409035205841064
Validation loss: 2.054559278231795

Epoch: 6| Step: 11
Training loss: 2.1947684288024902
Validation loss: 2.0559349521513908

Epoch: 6| Step: 12
Training loss: 2.439659357070923
Validation loss: 2.037762386824495

Epoch: 6| Step: 13
Training loss: 2.0281288623809814
Validation loss: 2.0042223699631228

Epoch: 148| Step: 0
Training loss: 1.8000757694244385
Validation loss: 2.066283989978093

Epoch: 6| Step: 1
Training loss: 2.005652904510498
Validation loss: 1.918132644827648

Epoch: 6| Step: 2
Training loss: 2.3365209102630615
Validation loss: 2.0540037078242146

Epoch: 6| Step: 3
Training loss: 2.2196483612060547
Validation loss: 2.052810207489998

Epoch: 6| Step: 4
Training loss: 2.0781705379486084
Validation loss: 2.1049924858154787

Epoch: 6| Step: 5
Training loss: 1.959600806236267
Validation loss: 2.0298745375807568

Epoch: 6| Step: 6
Training loss: 1.7479157447814941
Validation loss: 2.045340379079183

Epoch: 6| Step: 7
Training loss: 1.9315857887268066
Validation loss: 2.0672627828454457

Epoch: 6| Step: 8
Training loss: 1.3991351127624512
Validation loss: 1.9811189507925382

Epoch: 6| Step: 9
Training loss: 2.1499104499816895
Validation loss: 2.022990829201155

Epoch: 6| Step: 10
Training loss: 1.6279470920562744
Validation loss: 1.9985204383891115

Epoch: 6| Step: 11
Training loss: 2.2631983757019043
Validation loss: 1.971307308443131

Epoch: 6| Step: 12
Training loss: 2.3422374725341797
Validation loss: 1.9628256982372654

Epoch: 6| Step: 13
Training loss: 1.0531107187271118
Validation loss: 1.9778400851834206

Epoch: 149| Step: 0
Training loss: 1.8771772384643555
Validation loss: 1.959174527916857

Epoch: 6| Step: 1
Training loss: 1.8024576902389526
Validation loss: 1.9542243326863935

Epoch: 6| Step: 2
Training loss: 2.030515432357788
Validation loss: 1.9936464832675072

Epoch: 6| Step: 3
Training loss: 2.222231864929199
Validation loss: 2.005904754002889

Epoch: 6| Step: 4
Training loss: 1.8510148525238037
Validation loss: 1.979598891350531

Epoch: 6| Step: 5
Training loss: 2.487186908721924
Validation loss: 2.0162399327883156

Epoch: 6| Step: 6
Training loss: 1.842793345451355
Validation loss: 2.0160306038395053

Epoch: 6| Step: 7
Training loss: 1.933427095413208
Validation loss: 2.0217533662755

Epoch: 6| Step: 8
Training loss: 1.8934508562088013
Validation loss: 1.9613889571159118

Epoch: 6| Step: 9
Training loss: 1.1221423149108887
Validation loss: 1.9329064405092629

Epoch: 6| Step: 10
Training loss: 1.9941211938858032
Validation loss: 1.95153352778445

Epoch: 6| Step: 11
Training loss: 1.4379780292510986
Validation loss: 1.987344621330179

Epoch: 6| Step: 12
Training loss: 2.139876365661621
Validation loss: 1.9608800616315616

Epoch: 6| Step: 13
Training loss: 2.5054831504821777
Validation loss: 1.960540040846794

Epoch: 150| Step: 0
Training loss: 1.7906557321548462
Validation loss: 1.9886087448366228

Epoch: 6| Step: 1
Training loss: 1.4768351316452026
Validation loss: 2.041085276552426

Epoch: 6| Step: 2
Training loss: 1.4392242431640625
Validation loss: 1.9866053827347294

Epoch: 6| Step: 3
Training loss: 2.2702560424804688
Validation loss: 2.0524409714565484

Epoch: 6| Step: 4
Training loss: 1.997994303703308
Validation loss: 1.982557463389571

Epoch: 6| Step: 5
Training loss: 2.0487523078918457
Validation loss: 2.030463026415917

Epoch: 6| Step: 6
Training loss: 2.3442306518554688
Validation loss: 2.1232457391677366

Epoch: 6| Step: 7
Training loss: 2.0004680156707764
Validation loss: 2.093324363872569

Epoch: 6| Step: 8
Training loss: 2.3750505447387695
Validation loss: 2.1016786867572415

Epoch: 6| Step: 9
Training loss: 2.588494300842285
Validation loss: 2.058041895589521

Epoch: 6| Step: 10
Training loss: 2.2413761615753174
Validation loss: 2.044173163752402

Epoch: 6| Step: 11
Training loss: 2.181051015853882
Validation loss: 1.9989980305394819

Epoch: 6| Step: 12
Training loss: 1.6490721702575684
Validation loss: 1.9775465073124054

Epoch: 6| Step: 13
Training loss: 0.9356251955032349
Validation loss: 2.0443285652386245

Epoch: 151| Step: 0
Training loss: 1.4925380945205688
Validation loss: 2.0124550545087425

Epoch: 6| Step: 1
Training loss: 2.06264328956604
Validation loss: 2.0313974990639636

Epoch: 6| Step: 2
Training loss: 2.75787615776062
Validation loss: 2.0341945899430143

Epoch: 6| Step: 3
Training loss: 1.517362356185913
Validation loss: 2.0217102650673158

Epoch: 6| Step: 4
Training loss: 1.9959362745285034
Validation loss: 1.977932228836962

Epoch: 6| Step: 5
Training loss: 2.548961877822876
Validation loss: 1.9692273883409397

Epoch: 6| Step: 6
Training loss: 1.6743090152740479
Validation loss: 1.9462324598784089

Epoch: 6| Step: 7
Training loss: 1.877219796180725
Validation loss: 1.956060271109304

Epoch: 6| Step: 8
Training loss: 1.871131420135498
Validation loss: 1.9882127456767584

Epoch: 6| Step: 9
Training loss: 1.6249066591262817
Validation loss: 1.9824280123556814

Epoch: 6| Step: 10
Training loss: 1.9926788806915283
Validation loss: 2.027288342034945

Epoch: 6| Step: 11
Training loss: 2.2668991088867188
Validation loss: 1.9432181773647186

Epoch: 6| Step: 12
Training loss: 1.3859491348266602
Validation loss: 2.009225583845569

Epoch: 6| Step: 13
Training loss: 1.8957358598709106
Validation loss: 1.9796985938984861

Epoch: 152| Step: 0
Training loss: 1.4895739555358887
Validation loss: 2.002697565222299

Epoch: 6| Step: 1
Training loss: 2.334690570831299
Validation loss: 1.9749235876144902

Epoch: 6| Step: 2
Training loss: 1.4355924129486084
Validation loss: 1.9804458977073751

Epoch: 6| Step: 3
Training loss: 1.4932053089141846
Validation loss: 1.98003985035804

Epoch: 6| Step: 4
Training loss: 2.0254006385803223
Validation loss: 1.9952309208531533

Epoch: 6| Step: 5
Training loss: 2.1785833835601807
Validation loss: 1.9893667954270557

Epoch: 6| Step: 6
Training loss: 2.6525590419769287
Validation loss: 2.0080570790075485

Epoch: 6| Step: 7
Training loss: 1.302796483039856
Validation loss: 1.9844655298417615

Epoch: 6| Step: 8
Training loss: 2.336139440536499
Validation loss: 1.9831938243681384

Epoch: 6| Step: 9
Training loss: 2.1414411067962646
Validation loss: 1.9443159513576056

Epoch: 6| Step: 10
Training loss: 1.507632851600647
Validation loss: 2.0254537572142897

Epoch: 6| Step: 11
Training loss: 1.2584490776062012
Validation loss: 1.946776338802871

Epoch: 6| Step: 12
Training loss: 2.154747724533081
Validation loss: 2.0413740757972962

Epoch: 6| Step: 13
Training loss: 2.6763079166412354
Validation loss: 2.0639404545548143

Epoch: 153| Step: 0
Training loss: 1.479097843170166
Validation loss: 1.9173273745403494

Epoch: 6| Step: 1
Training loss: 1.747751235961914
Validation loss: 2.042453226222787

Epoch: 6| Step: 2
Training loss: 1.9761507511138916
Validation loss: 1.9797244251415294

Epoch: 6| Step: 3
Training loss: 2.115100145339966
Validation loss: 2.0135761922405613

Epoch: 6| Step: 4
Training loss: 1.8124730587005615
Validation loss: 1.9526722251728017

Epoch: 6| Step: 5
Training loss: 1.9755395650863647
Validation loss: 2.032555595521004

Epoch: 6| Step: 6
Training loss: 1.3633426427841187
Validation loss: 2.045650197613624

Epoch: 6| Step: 7
Training loss: 2.9935131072998047
Validation loss: 2.037198173102512

Epoch: 6| Step: 8
Training loss: 2.115461826324463
Validation loss: 2.0008777277444

Epoch: 6| Step: 9
Training loss: 1.683375358581543
Validation loss: 2.010996926215387

Epoch: 6| Step: 10
Training loss: 1.677566647529602
Validation loss: 1.980783511233586

Epoch: 6| Step: 11
Training loss: 1.7795474529266357
Validation loss: 1.9730493701914305

Epoch: 6| Step: 12
Training loss: 2.9992387294769287
Validation loss: 1.9669626528216946

Epoch: 6| Step: 13
Training loss: 1.8209929466247559
Validation loss: 1.9580992665342105

Epoch: 154| Step: 0
Training loss: 2.371979236602783
Validation loss: 1.9801833642426359

Epoch: 6| Step: 1
Training loss: 2.4174413681030273
Validation loss: 2.0100558445017827

Epoch: 6| Step: 2
Training loss: 1.7296643257141113
Validation loss: 2.020344249663814

Epoch: 6| Step: 3
Training loss: 1.390520453453064
Validation loss: 2.001439566253334

Epoch: 6| Step: 4
Training loss: 2.131425380706787
Validation loss: 2.0145279592083347

Epoch: 6| Step: 5
Training loss: 1.8087931871414185
Validation loss: 2.0232905008459605

Epoch: 6| Step: 6
Training loss: 1.7993764877319336
Validation loss: 2.0589296305051414

Epoch: 6| Step: 7
Training loss: 2.0998082160949707
Validation loss: 2.0042184232383646

Epoch: 6| Step: 8
Training loss: 2.4248509407043457
Validation loss: 2.015353971912015

Epoch: 6| Step: 9
Training loss: 1.4463121891021729
Validation loss: 2.0076654239367415

Epoch: 6| Step: 10
Training loss: 1.9334499835968018
Validation loss: 2.036011985553208

Epoch: 6| Step: 11
Training loss: 1.4747124910354614
Validation loss: 2.054187185020857

Epoch: 6| Step: 12
Training loss: 2.06351375579834
Validation loss: 2.004350044394052

Epoch: 6| Step: 13
Training loss: 1.6736280918121338
Validation loss: 2.0864740802395727

Epoch: 155| Step: 0
Training loss: 1.9692283868789673
Validation loss: 2.0603393636724

Epoch: 6| Step: 1
Training loss: 1.514861822128296
Validation loss: 2.0690344738703903

Epoch: 6| Step: 2
Training loss: 2.038912773132324
Validation loss: 2.007185375818642

Epoch: 6| Step: 3
Training loss: 1.745074987411499
Validation loss: 2.0051981249163227

Epoch: 6| Step: 4
Training loss: 1.3889302015304565
Validation loss: 2.020389280011577

Epoch: 6| Step: 5
Training loss: 1.9589494466781616
Validation loss: 2.0196948500089746

Epoch: 6| Step: 6
Training loss: 1.9429094791412354
Validation loss: 1.962525556164403

Epoch: 6| Step: 7
Training loss: 2.4189610481262207
Validation loss: 2.006316690034764

Epoch: 6| Step: 8
Training loss: 2.2139811515808105
Validation loss: 1.9363202279613865

Epoch: 6| Step: 9
Training loss: 1.7123744487762451
Validation loss: 2.0350467146083875

Epoch: 6| Step: 10
Training loss: 2.0237348079681396
Validation loss: 2.088386510008125

Epoch: 6| Step: 11
Training loss: 2.500979423522949
Validation loss: 1.9502403428477626

Epoch: 6| Step: 12
Training loss: 1.8232699632644653
Validation loss: 2.0414268380852154

Epoch: 6| Step: 13
Training loss: 1.3999544382095337
Validation loss: 2.051946099086474

Epoch: 156| Step: 0
Training loss: 1.917320966720581
Validation loss: 2.0244006879868044

Epoch: 6| Step: 1
Training loss: 1.2244415283203125
Validation loss: 1.9582880068850774

Epoch: 6| Step: 2
Training loss: 2.4607315063476562
Validation loss: 1.964590662269182

Epoch: 6| Step: 3
Training loss: 2.3032007217407227
Validation loss: 1.9789116703053957

Epoch: 6| Step: 4
Training loss: 1.9545085430145264
Validation loss: 2.038377561876851

Epoch: 6| Step: 5
Training loss: 1.8318946361541748
Validation loss: 1.977199016078826

Epoch: 6| Step: 6
Training loss: 1.9548548460006714
Validation loss: 2.0109822916728195

Epoch: 6| Step: 7
Training loss: 1.764120101928711
Validation loss: 1.9715096771076162

Epoch: 6| Step: 8
Training loss: 1.3629783391952515
Validation loss: 1.9714120472631147

Epoch: 6| Step: 9
Training loss: 1.6793391704559326
Validation loss: 1.9917429595865228

Epoch: 6| Step: 10
Training loss: 1.858030080795288
Validation loss: 2.019457268458541

Epoch: 6| Step: 11
Training loss: 1.9382227659225464
Validation loss: 2.0052587524537118

Epoch: 6| Step: 12
Training loss: 2.4401659965515137
Validation loss: 2.0409781779012373

Epoch: 6| Step: 13
Training loss: 2.0808756351470947
Validation loss: 2.0473429708070654

Epoch: 157| Step: 0
Training loss: 1.6478540897369385
Validation loss: 2.0277032493263163

Epoch: 6| Step: 1
Training loss: 1.8611295223236084
Validation loss: 1.9975739576483285

Epoch: 6| Step: 2
Training loss: 2.2280991077423096
Validation loss: 1.9629027330747215

Epoch: 6| Step: 3
Training loss: 1.8010869026184082
Validation loss: 1.9999117723075293

Epoch: 6| Step: 4
Training loss: 3.115309238433838
Validation loss: 1.9976961356337353

Epoch: 6| Step: 5
Training loss: 1.953363060951233
Validation loss: 2.003740402960008

Epoch: 6| Step: 6
Training loss: 1.5586456060409546
Validation loss: 1.9504379354497439

Epoch: 6| Step: 7
Training loss: 1.332403302192688
Validation loss: 2.005722804736066

Epoch: 6| Step: 8
Training loss: 2.2472338676452637
Validation loss: 1.983669860388643

Epoch: 6| Step: 9
Training loss: 1.6319670677185059
Validation loss: 2.049056590244334

Epoch: 6| Step: 10
Training loss: 2.721104621887207
Validation loss: 2.016584070779944

Epoch: 6| Step: 11
Training loss: 1.5453895330429077
Validation loss: 2.0312296305933306

Epoch: 6| Step: 12
Training loss: 1.4026439189910889
Validation loss: 1.955092623669614

Epoch: 6| Step: 13
Training loss: 1.9069892168045044
Validation loss: 2.0147188991628666

Epoch: 158| Step: 0
Training loss: 2.425889492034912
Validation loss: 2.0087343800452446

Epoch: 6| Step: 1
Training loss: 2.8039488792419434
Validation loss: 2.001821247480249

Epoch: 6| Step: 2
Training loss: 1.8844914436340332
Validation loss: 1.9678722350828108

Epoch: 6| Step: 3
Training loss: 1.533137321472168
Validation loss: 2.0218805369510444

Epoch: 6| Step: 4
Training loss: 1.0832054615020752
Validation loss: 2.0143344492040653

Epoch: 6| Step: 5
Training loss: 1.5015145540237427
Validation loss: 2.0104784273332164

Epoch: 6| Step: 6
Training loss: 2.1452040672302246
Validation loss: 2.0472851478925316

Epoch: 6| Step: 7
Training loss: 1.708601474761963
Validation loss: 2.020388199437049

Epoch: 6| Step: 8
Training loss: 1.7672709226608276
Validation loss: 2.0013568670518938

Epoch: 6| Step: 9
Training loss: 2.004645824432373
Validation loss: 2.0502366468470585

Epoch: 6| Step: 10
Training loss: 2.0990896224975586
Validation loss: 2.046337999323363

Epoch: 6| Step: 11
Training loss: 2.219498634338379
Validation loss: 2.034780430537398

Epoch: 6| Step: 12
Training loss: 1.2864307165145874
Validation loss: 2.057546889910134

Epoch: 6| Step: 13
Training loss: 1.7535786628723145
Validation loss: 2.023192786401318

Epoch: 159| Step: 0
Training loss: 2.3873744010925293
Validation loss: 1.9598019174350205

Epoch: 6| Step: 1
Training loss: 1.771122694015503
Validation loss: 2.000729368579003

Epoch: 6| Step: 2
Training loss: 1.6958067417144775
Validation loss: 1.9560353217586395

Epoch: 6| Step: 3
Training loss: 1.9494630098342896
Validation loss: 1.9926513959002752

Epoch: 6| Step: 4
Training loss: 2.0257012844085693
Validation loss: 1.9273919713112615

Epoch: 6| Step: 5
Training loss: 2.6511833667755127
Validation loss: 2.003506818125325

Epoch: 6| Step: 6
Training loss: 2.204115390777588
Validation loss: 2.0316914486628708

Epoch: 6| Step: 7
Training loss: 1.2729742527008057
Validation loss: 1.9098693991220126

Epoch: 6| Step: 8
Training loss: 1.5441620349884033
Validation loss: 1.97030718352205

Epoch: 6| Step: 9
Training loss: 1.6291029453277588
Validation loss: 2.0211096066300587

Epoch: 6| Step: 10
Training loss: 2.1301541328430176
Validation loss: 2.0156318244113716

Epoch: 6| Step: 11
Training loss: 1.6910459995269775
Validation loss: 1.9781601198257939

Epoch: 6| Step: 12
Training loss: 1.755367398262024
Validation loss: 1.9891974541448778

Epoch: 6| Step: 13
Training loss: 1.5800080299377441
Validation loss: 1.9485592329373924

Epoch: 160| Step: 0
Training loss: 2.637779712677002
Validation loss: 2.0158831381028697

Epoch: 6| Step: 1
Training loss: 2.2410922050476074
Validation loss: 2.0675459113172305

Epoch: 6| Step: 2
Training loss: 1.4438663721084595
Validation loss: 2.0014583590210124

Epoch: 6| Step: 3
Training loss: 1.6219596862792969
Validation loss: 2.0294686030316096

Epoch: 6| Step: 4
Training loss: 1.0816926956176758
Validation loss: 2.004454461477136

Epoch: 6| Step: 5
Training loss: 2.407255172729492
Validation loss: 1.9768588568574639

Epoch: 6| Step: 6
Training loss: 1.846688985824585
Validation loss: 2.0574020006323375

Epoch: 6| Step: 7
Training loss: 2.2154829502105713
Validation loss: 1.9951193717218214

Epoch: 6| Step: 8
Training loss: 1.8548657894134521
Validation loss: 2.0779917240142822

Epoch: 6| Step: 9
Training loss: 1.8616018295288086
Validation loss: 2.015610084738783

Epoch: 6| Step: 10
Training loss: 1.8436684608459473
Validation loss: 2.0165569295165358

Epoch: 6| Step: 11
Training loss: 1.7436094284057617
Validation loss: 2.0079904922875027

Epoch: 6| Step: 12
Training loss: 1.9179060459136963
Validation loss: 1.9574588139851887

Epoch: 6| Step: 13
Training loss: 2.3742828369140625
Validation loss: 2.0173298146135066

Epoch: 161| Step: 0
Training loss: 1.6965843439102173
Validation loss: 2.026324510574341

Epoch: 6| Step: 1
Training loss: 2.1811394691467285
Validation loss: 1.980330809470146

Epoch: 6| Step: 2
Training loss: 2.418795108795166
Validation loss: 1.9935248000647432

Epoch: 6| Step: 3
Training loss: 2.194941997528076
Validation loss: 1.960535292984337

Epoch: 6| Step: 4
Training loss: 1.803837776184082
Validation loss: 1.977920292526163

Epoch: 6| Step: 5
Training loss: 1.7831957340240479
Validation loss: 1.9520176354274954

Epoch: 6| Step: 6
Training loss: 2.26017427444458
Validation loss: 2.004710910140827

Epoch: 6| Step: 7
Training loss: 2.0150272846221924
Validation loss: 2.055741443428942

Epoch: 6| Step: 8
Training loss: 1.9398226737976074
Validation loss: 2.025357727081545

Epoch: 6| Step: 9
Training loss: 0.8232988119125366
Validation loss: 1.9676227774671329

Epoch: 6| Step: 10
Training loss: 1.861263632774353
Validation loss: 1.9996366039399178

Epoch: 6| Step: 11
Training loss: 1.912764072418213
Validation loss: 2.042573759632726

Epoch: 6| Step: 12
Training loss: 2.534919500350952
Validation loss: 1.9697457308410316

Epoch: 6| Step: 13
Training loss: 1.7054251432418823
Validation loss: 2.0023266935861237

Epoch: 162| Step: 0
Training loss: 1.6042921543121338
Validation loss: 2.0109381188628492

Epoch: 6| Step: 1
Training loss: 2.509124755859375
Validation loss: 2.0064994955575592

Epoch: 6| Step: 2
Training loss: 1.4173705577850342
Validation loss: 2.0103120393650507

Epoch: 6| Step: 3
Training loss: 1.6793714761734009
Validation loss: 1.983392329626186

Epoch: 6| Step: 4
Training loss: 1.6610336303710938
Validation loss: 2.0149044195810952

Epoch: 6| Step: 5
Training loss: 1.2543193101882935
Validation loss: 1.9597319338911323

Epoch: 6| Step: 6
Training loss: 1.843576192855835
Validation loss: 1.970900374074136

Epoch: 6| Step: 7
Training loss: 3.2472589015960693
Validation loss: 1.9997316739892448

Epoch: 6| Step: 8
Training loss: 1.8350651264190674
Validation loss: 1.9560292138848254

Epoch: 6| Step: 9
Training loss: 2.0232343673706055
Validation loss: 1.9902832508087158

Epoch: 6| Step: 10
Training loss: 1.4154049158096313
Validation loss: 1.9728786330069266

Epoch: 6| Step: 11
Training loss: 2.4535140991210938
Validation loss: 2.017777991551225

Epoch: 6| Step: 12
Training loss: 1.1793324947357178
Validation loss: 2.0387907925472466

Epoch: 6| Step: 13
Training loss: 2.036868095397949
Validation loss: 2.011723049225346

Epoch: 163| Step: 0
Training loss: 1.4513938426971436
Validation loss: 2.0054735035024662

Epoch: 6| Step: 1
Training loss: 2.637136459350586
Validation loss: 2.0388945494928667

Epoch: 6| Step: 2
Training loss: 1.823415756225586
Validation loss: 2.0027582260870163

Epoch: 6| Step: 3
Training loss: 1.8234570026397705
Validation loss: 2.0414116779963174

Epoch: 6| Step: 4
Training loss: 2.5345187187194824
Validation loss: 2.0060529555043867

Epoch: 6| Step: 5
Training loss: 1.827552318572998
Validation loss: 2.0555778523927093

Epoch: 6| Step: 6
Training loss: 1.8909916877746582
Validation loss: 2.105318807786511

Epoch: 6| Step: 7
Training loss: 2.2521660327911377
Validation loss: 2.0746393613917853

Epoch: 6| Step: 8
Training loss: 1.5615043640136719
Validation loss: 2.1299284914488434

Epoch: 6| Step: 9
Training loss: 2.2173357009887695
Validation loss: 2.017656067366241

Epoch: 6| Step: 10
Training loss: 1.646092414855957
Validation loss: 1.992996117120148

Epoch: 6| Step: 11
Training loss: 1.8109617233276367
Validation loss: 2.050659132260148

Epoch: 6| Step: 12
Training loss: 1.7468531131744385
Validation loss: 2.016367015018258

Epoch: 6| Step: 13
Training loss: 1.6630709171295166
Validation loss: 2.0213904214161698

Epoch: 164| Step: 0
Training loss: 2.463388204574585
Validation loss: 1.9652681299435195

Epoch: 6| Step: 1
Training loss: 1.9864864349365234
Validation loss: 2.0190833025081183

Epoch: 6| Step: 2
Training loss: 1.6230213642120361
Validation loss: 1.9782408334875619

Epoch: 6| Step: 3
Training loss: 1.9820843935012817
Validation loss: 1.9925949214607157

Epoch: 6| Step: 4
Training loss: 1.9828228950500488
Validation loss: 1.9701496221685921

Epoch: 6| Step: 5
Training loss: 1.1716666221618652
Validation loss: 1.9521069283126502

Epoch: 6| Step: 6
Training loss: 1.5359141826629639
Validation loss: 2.0283817296387046

Epoch: 6| Step: 7
Training loss: 2.171419143676758
Validation loss: 1.9401961577835904

Epoch: 6| Step: 8
Training loss: 2.6222352981567383
Validation loss: 1.9516042458113803

Epoch: 6| Step: 9
Training loss: 1.6797397136688232
Validation loss: 2.0401862795634935

Epoch: 6| Step: 10
Training loss: 1.675252914428711
Validation loss: 1.9717052982699486

Epoch: 6| Step: 11
Training loss: 1.273329734802246
Validation loss: 1.9997873793366134

Epoch: 6| Step: 12
Training loss: 2.4611656665802
Validation loss: 1.934207836786906

Epoch: 6| Step: 13
Training loss: 1.931457281112671
Validation loss: 2.023345567846811

Epoch: 165| Step: 0
Training loss: 1.3316359519958496
Validation loss: 2.0599454731069584

Epoch: 6| Step: 1
Training loss: 2.0531582832336426
Validation loss: 2.0390790380457395

Epoch: 6| Step: 2
Training loss: 1.9287543296813965
Validation loss: 2.021284834031136

Epoch: 6| Step: 3
Training loss: 1.725243091583252
Validation loss: 2.003235904119348

Epoch: 6| Step: 4
Training loss: 2.1763882637023926
Validation loss: 2.0021491665993967

Epoch: 6| Step: 5
Training loss: 1.930229902267456
Validation loss: 2.0644537607828775

Epoch: 6| Step: 6
Training loss: 1.6673643589019775
Validation loss: 2.021473717945878

Epoch: 6| Step: 7
Training loss: 2.0819549560546875
Validation loss: 2.0769145181102138

Epoch: 6| Step: 8
Training loss: 2.0434131622314453
Validation loss: 1.9468333490433232

Epoch: 6| Step: 9
Training loss: 1.810973048210144
Validation loss: 2.044302967286879

Epoch: 6| Step: 10
Training loss: 1.9154963493347168
Validation loss: 1.9620913741409138

Epoch: 6| Step: 11
Training loss: 1.9727532863616943
Validation loss: 1.9901995889602169

Epoch: 6| Step: 12
Training loss: 1.7303258180618286
Validation loss: 2.0094536248073784

Epoch: 6| Step: 13
Training loss: 1.7412474155426025
Validation loss: 1.9893327310521116

Epoch: 166| Step: 0
Training loss: 1.798590064048767
Validation loss: 1.9804194204268917

Epoch: 6| Step: 1
Training loss: 1.2184559106826782
Validation loss: 1.9835896568913614

Epoch: 6| Step: 2
Training loss: 1.5073738098144531
Validation loss: 1.9624650555272256

Epoch: 6| Step: 3
Training loss: 1.9535138607025146
Validation loss: 2.054887531906046

Epoch: 6| Step: 4
Training loss: 1.9500395059585571
Validation loss: 2.0315411270305677

Epoch: 6| Step: 5
Training loss: 2.618931293487549
Validation loss: 1.9829711606425624

Epoch: 6| Step: 6
Training loss: 1.5914955139160156
Validation loss: 2.029567233977779

Epoch: 6| Step: 7
Training loss: 2.1907236576080322
Validation loss: 1.9370416389998568

Epoch: 6| Step: 8
Training loss: 2.0766162872314453
Validation loss: 1.9794236203675628

Epoch: 6| Step: 9
Training loss: 2.0320498943328857
Validation loss: 2.006879069471872

Epoch: 6| Step: 10
Training loss: 1.4349862337112427
Validation loss: 1.9565143687750703

Epoch: 6| Step: 11
Training loss: 2.140604019165039
Validation loss: 1.9907411977808962

Epoch: 6| Step: 12
Training loss: 2.2116994857788086
Validation loss: 1.9679471933713524

Epoch: 6| Step: 13
Training loss: 1.839844822883606
Validation loss: 1.9114721590472805

Epoch: 167| Step: 0
Training loss: 2.273031234741211
Validation loss: 1.9278496106465657

Epoch: 6| Step: 1
Training loss: 2.4834084510803223
Validation loss: 1.994432323722429

Epoch: 6| Step: 2
Training loss: 2.355501651763916
Validation loss: 1.9536838839131017

Epoch: 6| Step: 3
Training loss: 1.6090025901794434
Validation loss: 1.9998018241697741

Epoch: 6| Step: 4
Training loss: 1.5724490880966187
Validation loss: 1.9817195400114982

Epoch: 6| Step: 5
Training loss: 2.006643772125244
Validation loss: 1.990717630232534

Epoch: 6| Step: 6
Training loss: 1.624672532081604
Validation loss: 1.9966376545608684

Epoch: 6| Step: 7
Training loss: 1.9457720518112183
Validation loss: 1.996483072157829

Epoch: 6| Step: 8
Training loss: 1.9134697914123535
Validation loss: 1.9929136742827713

Epoch: 6| Step: 9
Training loss: 1.3099900484085083
Validation loss: 1.9825377618112872

Epoch: 6| Step: 10
Training loss: 1.9607497453689575
Validation loss: 2.0150089827916955

Epoch: 6| Step: 11
Training loss: 2.3932785987854004
Validation loss: 2.004165082849482

Epoch: 6| Step: 12
Training loss: 1.1124067306518555
Validation loss: 2.0315138845033545

Epoch: 6| Step: 13
Training loss: 1.87769615650177
Validation loss: 1.9936930146268619

Epoch: 168| Step: 0
Training loss: 2.4870450496673584
Validation loss: 2.0473261584517775

Epoch: 6| Step: 1
Training loss: 2.3208999633789062
Validation loss: 2.030742883682251

Epoch: 6| Step: 2
Training loss: 1.897119164466858
Validation loss: 2.0340701200628795

Epoch: 6| Step: 3
Training loss: 1.5234284400939941
Validation loss: 1.9370788476800407

Epoch: 6| Step: 4
Training loss: 1.9785730838775635
Validation loss: 2.05782820845163

Epoch: 6| Step: 5
Training loss: 2.7406184673309326
Validation loss: 1.9669440471997826

Epoch: 6| Step: 6
Training loss: 1.3958110809326172
Validation loss: 1.985415966280045

Epoch: 6| Step: 7
Training loss: 2.3341524600982666
Validation loss: 1.9943888623227355

Epoch: 6| Step: 8
Training loss: 2.0003185272216797
Validation loss: 1.997537725715227

Epoch: 6| Step: 9
Training loss: 1.965749740600586
Validation loss: 1.9367885179417108

Epoch: 6| Step: 10
Training loss: 1.3196707963943481
Validation loss: 2.0977629756414764

Epoch: 6| Step: 11
Training loss: 1.0818557739257812
Validation loss: 1.9832386791065175

Epoch: 6| Step: 12
Training loss: 1.7955498695373535
Validation loss: 2.054273896319892

Epoch: 6| Step: 13
Training loss: 2.1853883266448975
Validation loss: 1.9806101540083527

Epoch: 169| Step: 0
Training loss: 1.5028775930404663
Validation loss: 1.9795349067257297

Epoch: 6| Step: 1
Training loss: 2.04819393157959
Validation loss: 2.0132510662078857

Epoch: 6| Step: 2
Training loss: 2.6120007038116455
Validation loss: 1.9375582433515979

Epoch: 6| Step: 3
Training loss: 1.5136958360671997
Validation loss: 2.0251956729478735

Epoch: 6| Step: 4
Training loss: 2.0018138885498047
Validation loss: 2.012144401509275

Epoch: 6| Step: 5
Training loss: 1.7040411233901978
Validation loss: 1.964669354500309

Epoch: 6| Step: 6
Training loss: 1.032194972038269
Validation loss: 2.0088541161629463

Epoch: 6| Step: 7
Training loss: 1.359303593635559
Validation loss: 1.9753010657525831

Epoch: 6| Step: 8
Training loss: 2.605581760406494
Validation loss: 1.926853463213931

Epoch: 6| Step: 9
Training loss: 2.3926379680633545
Validation loss: 2.0287223887699906

Epoch: 6| Step: 10
Training loss: 2.5462284088134766
Validation loss: 2.0003190399498068

Epoch: 6| Step: 11
Training loss: 1.3033522367477417
Validation loss: 1.9333196378523303

Epoch: 6| Step: 12
Training loss: 1.6047805547714233
Validation loss: 1.9916074429788897

Epoch: 6| Step: 13
Training loss: 1.7389498949050903
Validation loss: 1.988871169346635

Epoch: 170| Step: 0
Training loss: 1.9476847648620605
Validation loss: 1.9632071987275155

Epoch: 6| Step: 1
Training loss: 1.4307944774627686
Validation loss: 2.011730130000781

Epoch: 6| Step: 2
Training loss: 1.858299732208252
Validation loss: 2.011413884419267

Epoch: 6| Step: 3
Training loss: 1.8712103366851807
Validation loss: 2.009546820835401

Epoch: 6| Step: 4
Training loss: 1.7304006814956665
Validation loss: 2.009038454742842

Epoch: 6| Step: 5
Training loss: 1.9789113998413086
Validation loss: 1.9680256920476114

Epoch: 6| Step: 6
Training loss: 1.5592464208602905
Validation loss: 2.003079498967817

Epoch: 6| Step: 7
Training loss: 2.2291760444641113
Validation loss: 1.9968124461430374

Epoch: 6| Step: 8
Training loss: 1.9386322498321533
Validation loss: 2.0144308754192886

Epoch: 6| Step: 9
Training loss: 1.7425618171691895
Validation loss: 1.9975423223228865

Epoch: 6| Step: 10
Training loss: 1.5707975625991821
Validation loss: 2.043151254295021

Epoch: 6| Step: 11
Training loss: 2.2257566452026367
Validation loss: 2.0596020260164813

Epoch: 6| Step: 12
Training loss: 2.044079303741455
Validation loss: 1.995241888107792

Epoch: 6| Step: 13
Training loss: 1.9790043830871582
Validation loss: 2.053936673748878

Epoch: 171| Step: 0
Training loss: 2.5734663009643555
Validation loss: 2.0199947639178206

Epoch: 6| Step: 1
Training loss: 1.8999371528625488
Validation loss: 1.9680674383717198

Epoch: 6| Step: 2
Training loss: 1.851032018661499
Validation loss: 1.9357839130586194

Epoch: 6| Step: 3
Training loss: 1.137204647064209
Validation loss: 2.030664236314835

Epoch: 6| Step: 4
Training loss: 1.7277203798294067
Validation loss: 2.0122606087756414

Epoch: 6| Step: 5
Training loss: 2.4998435974121094
Validation loss: 2.0295541055740847

Epoch: 6| Step: 6
Training loss: 1.9575265645980835
Validation loss: 2.071070694154309

Epoch: 6| Step: 7
Training loss: 2.0689868927001953
Validation loss: 2.001043833712096

Epoch: 6| Step: 8
Training loss: 1.5817865133285522
Validation loss: 1.976459950529119

Epoch: 6| Step: 9
Training loss: 1.28433358669281
Validation loss: 1.9233234543954172

Epoch: 6| Step: 10
Training loss: 2.097898483276367
Validation loss: 2.0232047291212183

Epoch: 6| Step: 11
Training loss: 1.7230594158172607
Validation loss: 1.9853668687164143

Epoch: 6| Step: 12
Training loss: 2.2324976921081543
Validation loss: 1.9690981475255822

Epoch: 6| Step: 13
Training loss: 1.7141321897506714
Validation loss: 1.950422280578203

Epoch: 172| Step: 0
Training loss: 1.7703795433044434
Validation loss: 1.9998999936606294

Epoch: 6| Step: 1
Training loss: 1.5192534923553467
Validation loss: 2.055004841537886

Epoch: 6| Step: 2
Training loss: 2.01436185836792
Validation loss: 1.9966386056715442

Epoch: 6| Step: 3
Training loss: 1.9259289503097534
Validation loss: 1.9420950771659933

Epoch: 6| Step: 4
Training loss: 2.0599122047424316
Validation loss: 1.9822846138349144

Epoch: 6| Step: 5
Training loss: 1.956262469291687
Validation loss: 1.9389716886704969

Epoch: 6| Step: 6
Training loss: 2.3403234481811523
Validation loss: 1.8944692521966913

Epoch: 6| Step: 7
Training loss: 1.9875863790512085
Validation loss: 1.97985210469974

Epoch: 6| Step: 8
Training loss: 2.1168084144592285
Validation loss: 1.951565291291924

Epoch: 6| Step: 9
Training loss: 2.291261672973633
Validation loss: 2.024545201691248

Epoch: 6| Step: 10
Training loss: 1.5841426849365234
Validation loss: 2.0112447700192853

Epoch: 6| Step: 11
Training loss: 1.4893710613250732
Validation loss: 2.035898047108804

Epoch: 6| Step: 12
Training loss: 2.0994067192077637
Validation loss: 2.018578347339425

Epoch: 6| Step: 13
Training loss: 1.4370238780975342
Validation loss: 1.9863470562042729

Epoch: 173| Step: 0
Training loss: 2.307919979095459
Validation loss: 2.009819858817644

Epoch: 6| Step: 1
Training loss: 2.4043631553649902
Validation loss: 2.0102074607726066

Epoch: 6| Step: 2
Training loss: 1.1890944242477417
Validation loss: 2.037788660295548

Epoch: 6| Step: 3
Training loss: 2.069148540496826
Validation loss: 1.9278639567795621

Epoch: 6| Step: 4
Training loss: 1.9163730144500732
Validation loss: 1.958276189783568

Epoch: 6| Step: 5
Training loss: 2.2227256298065186
Validation loss: 2.070246236298674

Epoch: 6| Step: 6
Training loss: 1.0727834701538086
Validation loss: 2.0032290348442654

Epoch: 6| Step: 7
Training loss: 2.060593605041504
Validation loss: 1.9762131039814284

Epoch: 6| Step: 8
Training loss: 1.5890147686004639
Validation loss: 1.9887569309562765

Epoch: 6| Step: 9
Training loss: 2.014761209487915
Validation loss: 1.9893076432648527

Epoch: 6| Step: 10
Training loss: 1.8054962158203125
Validation loss: 1.9946741493799354

Epoch: 6| Step: 11
Training loss: 1.835608720779419
Validation loss: 2.0148409156389135

Epoch: 6| Step: 12
Training loss: 1.6863884925842285
Validation loss: 2.0038536248668546

Epoch: 6| Step: 13
Training loss: 1.6474342346191406
Validation loss: 1.9770829395581317

Epoch: 174| Step: 0
Training loss: 2.2261266708374023
Validation loss: 2.0156046818661433

Epoch: 6| Step: 1
Training loss: 1.6835136413574219
Validation loss: 1.9508123167099491

Epoch: 6| Step: 2
Training loss: 1.6422460079193115
Validation loss: 1.9950909076198455

Epoch: 6| Step: 3
Training loss: 1.8354064226150513
Validation loss: 2.012763686077569

Epoch: 6| Step: 4
Training loss: 1.7628730535507202
Validation loss: 1.9441912494679934

Epoch: 6| Step: 5
Training loss: 1.7814831733703613
Validation loss: 1.9694979703554543

Epoch: 6| Step: 6
Training loss: 1.8123098611831665
Validation loss: 1.930286802271361

Epoch: 6| Step: 7
Training loss: 1.9784085750579834
Validation loss: 1.9688081279877694

Epoch: 6| Step: 8
Training loss: 1.7159264087677002
Validation loss: 1.9327841548509495

Epoch: 6| Step: 9
Training loss: 2.0550057888031006
Validation loss: 1.992660230205905

Epoch: 6| Step: 10
Training loss: 1.6590430736541748
Validation loss: 1.974552636505455

Epoch: 6| Step: 11
Training loss: 1.924761176109314
Validation loss: 2.0056139935729322

Epoch: 6| Step: 12
Training loss: 1.7746436595916748
Validation loss: 1.9285571203436902

Epoch: 6| Step: 13
Training loss: 1.2318681478500366
Validation loss: 2.010125198671895

Epoch: 175| Step: 0
Training loss: 2.2015182971954346
Validation loss: 1.9984317415504045

Epoch: 6| Step: 1
Training loss: 1.8625632524490356
Validation loss: 1.9679357223613287

Epoch: 6| Step: 2
Training loss: 1.7243049144744873
Validation loss: 1.9807366119918002

Epoch: 6| Step: 3
Training loss: 1.5845232009887695
Validation loss: 1.9325464566548665

Epoch: 6| Step: 4
Training loss: 1.548550009727478
Validation loss: 2.012179092694354

Epoch: 6| Step: 5
Training loss: 1.6422626972198486
Validation loss: 1.9732661477981075

Epoch: 6| Step: 6
Training loss: 1.7864902019500732
Validation loss: 2.0717581805362495

Epoch: 6| Step: 7
Training loss: 2.3520824909210205
Validation loss: 1.9616427959934357

Epoch: 6| Step: 8
Training loss: 1.9486362934112549
Validation loss: 2.017703237072114

Epoch: 6| Step: 9
Training loss: 1.9859527349472046
Validation loss: 1.9405416545047556

Epoch: 6| Step: 10
Training loss: 1.668154001235962
Validation loss: 2.075488398152013

Epoch: 6| Step: 11
Training loss: 1.5745561122894287
Validation loss: 2.0615955411746936

Epoch: 6| Step: 12
Training loss: 2.956624984741211
Validation loss: 2.0055898415145053

Epoch: 6| Step: 13
Training loss: 1.7935763597488403
Validation loss: 1.995257313533496

Epoch: 176| Step: 0
Training loss: 1.5595006942749023
Validation loss: 1.9503858294538272

Epoch: 6| Step: 1
Training loss: 2.429314613342285
Validation loss: 2.022048370812529

Epoch: 6| Step: 2
Training loss: 1.8482532501220703
Validation loss: 2.048345119722428

Epoch: 6| Step: 3
Training loss: 1.8341233730316162
Validation loss: 2.0022082841524513

Epoch: 6| Step: 4
Training loss: 2.147852659225464
Validation loss: 1.9629638643674954

Epoch: 6| Step: 5
Training loss: 1.3640575408935547
Validation loss: 1.9774584590747792

Epoch: 6| Step: 6
Training loss: 1.3109004497528076
Validation loss: 1.9871209500938334

Epoch: 6| Step: 7
Training loss: 1.8659651279449463
Validation loss: 2.0998602990181214

Epoch: 6| Step: 8
Training loss: 2.2075395584106445
Validation loss: 2.077261588906729

Epoch: 6| Step: 9
Training loss: 2.1173009872436523
Validation loss: 2.062976610276007

Epoch: 6| Step: 10
Training loss: 2.449462890625
Validation loss: 2.0385649819527902

Epoch: 6| Step: 11
Training loss: 1.9655494689941406
Validation loss: 2.0871928379099858

Epoch: 6| Step: 12
Training loss: 1.9902156591415405
Validation loss: 1.9700818984739241

Epoch: 6| Step: 13
Training loss: 1.956860065460205
Validation loss: 2.045962187551683

Epoch: 177| Step: 0
Training loss: 2.3698863983154297
Validation loss: 2.0164046620809906

Epoch: 6| Step: 1
Training loss: 2.6023168563842773
Validation loss: 2.0141269878674577

Epoch: 6| Step: 2
Training loss: 1.3964250087738037
Validation loss: 1.9870397775403914

Epoch: 6| Step: 3
Training loss: 1.6642897129058838
Validation loss: 2.0012806436066986

Epoch: 6| Step: 4
Training loss: 2.347670793533325
Validation loss: 1.9514411495577904

Epoch: 6| Step: 5
Training loss: 1.6448780298233032
Validation loss: 2.0500191078391126

Epoch: 6| Step: 6
Training loss: 2.565534830093384
Validation loss: 1.954928236622964

Epoch: 6| Step: 7
Training loss: 1.0658454895019531
Validation loss: 2.0180182892789125

Epoch: 6| Step: 8
Training loss: 1.893398642539978
Validation loss: 1.969638724480906

Epoch: 6| Step: 9
Training loss: 1.6583170890808105
Validation loss: 1.9166693277256464

Epoch: 6| Step: 10
Training loss: 2.1694273948669434
Validation loss: 1.9145807245726227

Epoch: 6| Step: 11
Training loss: 1.5091240406036377
Validation loss: 1.9631965416733936

Epoch: 6| Step: 12
Training loss: 1.7138257026672363
Validation loss: 2.003570438713156

Epoch: 6| Step: 13
Training loss: 1.8780394792556763
Validation loss: 1.9981397646729664

Epoch: 178| Step: 0
Training loss: 2.2146430015563965
Validation loss: 1.9779158535824026

Epoch: 6| Step: 1
Training loss: 1.880911111831665
Validation loss: 1.9537834710972284

Epoch: 6| Step: 2
Training loss: 1.4909313917160034
Validation loss: 2.010382789437489

Epoch: 6| Step: 3
Training loss: 1.7708303928375244
Validation loss: 1.9671105492499568

Epoch: 6| Step: 4
Training loss: 1.5627455711364746
Validation loss: 2.016288298432545

Epoch: 6| Step: 5
Training loss: 1.7378203868865967
Validation loss: 1.9415660596662951

Epoch: 6| Step: 6
Training loss: 1.4826109409332275
Validation loss: 1.9815561976484073

Epoch: 6| Step: 7
Training loss: 1.8867197036743164
Validation loss: 2.010213335355123

Epoch: 6| Step: 8
Training loss: 1.673541784286499
Validation loss: 1.9712745451158094

Epoch: 6| Step: 9
Training loss: 1.2801287174224854
Validation loss: 1.938814281135477

Epoch: 6| Step: 10
Training loss: 1.768627405166626
Validation loss: 2.0013398073052846

Epoch: 6| Step: 11
Training loss: 2.619410514831543
Validation loss: 2.003616311216867

Epoch: 6| Step: 12
Training loss: 2.137591600418091
Validation loss: 2.014783313197474

Epoch: 6| Step: 13
Training loss: 2.866668462753296
Validation loss: 2.013068755467733

Epoch: 179| Step: 0
Training loss: 1.9103479385375977
Validation loss: 2.065195378436837

Epoch: 6| Step: 1
Training loss: 1.9850949048995972
Validation loss: 1.9307329295783915

Epoch: 6| Step: 2
Training loss: 2.37674617767334
Validation loss: 1.9445980159185265

Epoch: 6| Step: 3
Training loss: 2.2032124996185303
Validation loss: 2.0442351282283826

Epoch: 6| Step: 4
Training loss: 1.044060230255127
Validation loss: 1.9450547310613817

Epoch: 6| Step: 5
Training loss: 1.3969100713729858
Validation loss: 1.9288105234023063

Epoch: 6| Step: 6
Training loss: 1.9189083576202393
Validation loss: 1.9852851590802592

Epoch: 6| Step: 7
Training loss: 1.623070478439331
Validation loss: 1.9881681652479275

Epoch: 6| Step: 8
Training loss: 1.4738478660583496
Validation loss: 1.9700731667139197

Epoch: 6| Step: 9
Training loss: 2.217560291290283
Validation loss: 2.020487913521387

Epoch: 6| Step: 10
Training loss: 1.976987600326538
Validation loss: 1.9291668066414454

Epoch: 6| Step: 11
Training loss: 2.1159589290618896
Validation loss: 1.9696400678285988

Epoch: 6| Step: 12
Training loss: 1.99446702003479
Validation loss: 1.9481543802445935

Epoch: 6| Step: 13
Training loss: 1.6421704292297363
Validation loss: 1.978450995619579

Epoch: 180| Step: 0
Training loss: 1.7781078815460205
Validation loss: 2.0745333522878666

Epoch: 6| Step: 1
Training loss: 2.3814196586608887
Validation loss: 2.040820526820357

Epoch: 6| Step: 2
Training loss: 1.996589183807373
Validation loss: 2.022573385187375

Epoch: 6| Step: 3
Training loss: 1.2238960266113281
Validation loss: 2.040240174980574

Epoch: 6| Step: 4
Training loss: 2.4420197010040283
Validation loss: 1.9976227462932628

Epoch: 6| Step: 5
Training loss: 1.6458947658538818
Validation loss: 2.071746790280906

Epoch: 6| Step: 6
Training loss: 2.080362319946289
Validation loss: 1.970611442801773

Epoch: 6| Step: 7
Training loss: 1.1858086585998535
Validation loss: 2.020359049561203

Epoch: 6| Step: 8
Training loss: 1.466637372970581
Validation loss: 1.99035216915992

Epoch: 6| Step: 9
Training loss: 2.7505125999450684
Validation loss: 1.9628583308189147

Epoch: 6| Step: 10
Training loss: 1.8810406923294067
Validation loss: 1.929560520315683

Epoch: 6| Step: 11
Training loss: 1.5926092863082886
Validation loss: 2.005600142222579

Epoch: 6| Step: 12
Training loss: 1.733614206314087
Validation loss: 1.995037091675625

Epoch: 6| Step: 13
Training loss: 2.3296947479248047
Validation loss: 1.9393985655999952

Epoch: 181| Step: 0
Training loss: 2.1951963901519775
Validation loss: 1.9963043094963155

Epoch: 6| Step: 1
Training loss: 1.4592474699020386
Validation loss: 1.9923887432262462

Epoch: 6| Step: 2
Training loss: 1.7762746810913086
Validation loss: 1.9793216361794421

Epoch: 6| Step: 3
Training loss: 2.0805654525756836
Validation loss: 2.0464891746479976

Epoch: 6| Step: 4
Training loss: 2.060983419418335
Validation loss: 2.096847777725548

Epoch: 6| Step: 5
Training loss: 2.5649657249450684
Validation loss: 2.0713377101446993

Epoch: 6| Step: 6
Training loss: 1.3558216094970703
Validation loss: 2.1397360986278904

Epoch: 6| Step: 7
Training loss: 2.23223876953125
Validation loss: 2.0647461632246613

Epoch: 6| Step: 8
Training loss: 1.827923059463501
Validation loss: 2.047935626840079

Epoch: 6| Step: 9
Training loss: 1.9917818307876587
Validation loss: 2.115963707688034

Epoch: 6| Step: 10
Training loss: 0.9929459691047668
Validation loss: 2.091048850808092

Epoch: 6| Step: 11
Training loss: 1.6788815259933472
Validation loss: 2.069895649469027

Epoch: 6| Step: 12
Training loss: 2.087636709213257
Validation loss: 2.0255857462524087

Epoch: 6| Step: 13
Training loss: 2.5117287635803223
Validation loss: 2.0124730269114175

Epoch: 182| Step: 0
Training loss: 1.497910499572754
Validation loss: 1.988222929739183

Epoch: 6| Step: 1
Training loss: 1.8720126152038574
Validation loss: 2.005642484593135

Epoch: 6| Step: 2
Training loss: 2.019899606704712
Validation loss: 1.9256607306900846

Epoch: 6| Step: 3
Training loss: 2.027348279953003
Validation loss: 2.0318092902501426

Epoch: 6| Step: 4
Training loss: 2.3816821575164795
Validation loss: 2.058802621338957

Epoch: 6| Step: 5
Training loss: 1.7497187852859497
Validation loss: 2.000294813545801

Epoch: 6| Step: 6
Training loss: 1.9888477325439453
Validation loss: 2.042510506927326

Epoch: 6| Step: 7
Training loss: 2.0949997901916504
Validation loss: 2.005394761280347

Epoch: 6| Step: 8
Training loss: 1.3768898248672485
Validation loss: 1.9870341247127903

Epoch: 6| Step: 9
Training loss: 2.099619150161743
Validation loss: 1.9302802483240764

Epoch: 6| Step: 10
Training loss: 1.9879906177520752
Validation loss: 2.0163086486119095

Epoch: 6| Step: 11
Training loss: 2.376654624938965
Validation loss: 1.9790861247688212

Epoch: 6| Step: 12
Training loss: 1.3220765590667725
Validation loss: 2.0310823596933836

Epoch: 6| Step: 13
Training loss: 1.8808708190917969
Validation loss: 1.9379079623888897

Epoch: 183| Step: 0
Training loss: 1.7444500923156738
Validation loss: 1.9463871602089173

Epoch: 6| Step: 1
Training loss: 1.4854272603988647
Validation loss: 2.018005730003439

Epoch: 6| Step: 2
Training loss: 2.213095188140869
Validation loss: 1.9402109756264636

Epoch: 6| Step: 3
Training loss: 1.647713541984558
Validation loss: 1.9546858110735494

Epoch: 6| Step: 4
Training loss: 1.875356912612915
Validation loss: 1.9907618056061447

Epoch: 6| Step: 5
Training loss: 2.0201621055603027
Validation loss: 1.981740874628867

Epoch: 6| Step: 6
Training loss: 1.915565848350525
Validation loss: 1.8934191350013978

Epoch: 6| Step: 7
Training loss: 1.4280210733413696
Validation loss: 1.9547693678127822

Epoch: 6| Step: 8
Training loss: 2.4356393814086914
Validation loss: 1.865579605102539

Epoch: 6| Step: 9
Training loss: 1.473327875137329
Validation loss: 1.9901031012176185

Epoch: 6| Step: 10
Training loss: 2.0232598781585693
Validation loss: 1.9831974109013875

Epoch: 6| Step: 11
Training loss: 1.5595850944519043
Validation loss: 1.952899597024405

Epoch: 6| Step: 12
Training loss: 2.492164373397827
Validation loss: 2.022389490117309

Epoch: 6| Step: 13
Training loss: 1.8477630615234375
Validation loss: 1.982412544629907

Epoch: 184| Step: 0
Training loss: 2.439892292022705
Validation loss: 1.9919681087616952

Epoch: 6| Step: 1
Training loss: 1.711076021194458
Validation loss: 1.986323812956451

Epoch: 6| Step: 2
Training loss: 1.9878323078155518
Validation loss: 2.0306389036998955

Epoch: 6| Step: 3
Training loss: 1.147575855255127
Validation loss: 2.0279274986636255

Epoch: 6| Step: 4
Training loss: 1.5140490531921387
Validation loss: 2.0224194295944704

Epoch: 6| Step: 5
Training loss: 1.9608447551727295
Validation loss: 2.0455076284306024

Epoch: 6| Step: 6
Training loss: 2.215440034866333
Validation loss: 1.9486276026695006

Epoch: 6| Step: 7
Training loss: 1.992915391921997
Validation loss: 2.044458371336742

Epoch: 6| Step: 8
Training loss: 1.907777190208435
Validation loss: 1.9854802008598083

Epoch: 6| Step: 9
Training loss: 1.477062463760376
Validation loss: 2.009765794200282

Epoch: 6| Step: 10
Training loss: 2.203667163848877
Validation loss: 1.9787622690200806

Epoch: 6| Step: 11
Training loss: 1.501965880393982
Validation loss: 2.0352360099874516

Epoch: 6| Step: 12
Training loss: 1.9471957683563232
Validation loss: 2.0697461712744927

Epoch: 6| Step: 13
Training loss: 1.6671042442321777
Validation loss: 2.025947091399982

Epoch: 185| Step: 0
Training loss: 2.479915142059326
Validation loss: 2.0117212123768304

Epoch: 6| Step: 1
Training loss: 2.646921396255493
Validation loss: 2.0154993892997823

Epoch: 6| Step: 2
Training loss: 1.488470196723938
Validation loss: 1.9842263985705633

Epoch: 6| Step: 3
Training loss: 1.8580187559127808
Validation loss: 1.9517940834004393

Epoch: 6| Step: 4
Training loss: 1.1072452068328857
Validation loss: 1.9985301879144484

Epoch: 6| Step: 5
Training loss: 2.005247116088867
Validation loss: 1.9858096350905716

Epoch: 6| Step: 6
Training loss: 1.6145856380462646
Validation loss: 1.962389834465519

Epoch: 6| Step: 7
Training loss: 1.5705137252807617
Validation loss: 1.972022101443301

Epoch: 6| Step: 8
Training loss: 2.2361345291137695
Validation loss: 2.015501691449073

Epoch: 6| Step: 9
Training loss: 2.015045642852783
Validation loss: 1.940695055069462

Epoch: 6| Step: 10
Training loss: 1.694068431854248
Validation loss: 1.977656013222151

Epoch: 6| Step: 11
Training loss: 2.09401798248291
Validation loss: 1.989785437942833

Epoch: 6| Step: 12
Training loss: 2.1868252754211426
Validation loss: 1.9575987772275043

Epoch: 6| Step: 13
Training loss: 1.04562246799469
Validation loss: 2.0287214479138775

Epoch: 186| Step: 0
Training loss: 2.5625739097595215
Validation loss: 2.0271434809571955

Epoch: 6| Step: 1
Training loss: 1.9946805238723755
Validation loss: 1.9331746024470176

Epoch: 6| Step: 2
Training loss: 2.315213680267334
Validation loss: 1.93086915375084

Epoch: 6| Step: 3
Training loss: 2.0625698566436768
Validation loss: 1.995367327044087

Epoch: 6| Step: 4
Training loss: 1.9939899444580078
Validation loss: 1.9217370005064114

Epoch: 6| Step: 5
Training loss: 2.527987003326416
Validation loss: 1.9290135342587706

Epoch: 6| Step: 6
Training loss: 1.0517652034759521
Validation loss: 1.9561500792862268

Epoch: 6| Step: 7
Training loss: 1.3575868606567383
Validation loss: 2.046218346523982

Epoch: 6| Step: 8
Training loss: 1.8844785690307617
Validation loss: 1.920595989432386

Epoch: 6| Step: 9
Training loss: 1.3218437433242798
Validation loss: 1.955765519090878

Epoch: 6| Step: 10
Training loss: 1.7458728551864624
Validation loss: 1.9317646257338985

Epoch: 6| Step: 11
Training loss: 1.6941382884979248
Validation loss: 1.9547123960269395

Epoch: 6| Step: 12
Training loss: 1.1715419292449951
Validation loss: 1.9900429479537471

Epoch: 6| Step: 13
Training loss: 2.391768217086792
Validation loss: 2.021870349043159

Epoch: 187| Step: 0
Training loss: 1.6360632181167603
Validation loss: 1.9587209929702103

Epoch: 6| Step: 1
Training loss: 1.5498179197311401
Validation loss: 1.985221315455693

Epoch: 6| Step: 2
Training loss: 1.9275460243225098
Validation loss: 1.9649049953747821

Epoch: 6| Step: 3
Training loss: 2.4983127117156982
Validation loss: 2.005385498846731

Epoch: 6| Step: 4
Training loss: 2.5247740745544434
Validation loss: 2.036210903557398

Epoch: 6| Step: 5
Training loss: 1.049744963645935
Validation loss: 2.0006072790391984

Epoch: 6| Step: 6
Training loss: 1.8890241384506226
Validation loss: 1.9762042504484936

Epoch: 6| Step: 7
Training loss: 2.252042293548584
Validation loss: 1.9270560831151984

Epoch: 6| Step: 8
Training loss: 1.8047012090682983
Validation loss: 1.9838992575163483

Epoch: 6| Step: 9
Training loss: 1.8725175857543945
Validation loss: 2.029427166908018

Epoch: 6| Step: 10
Training loss: 1.943270206451416
Validation loss: 1.9146637608928065

Epoch: 6| Step: 11
Training loss: 2.2076776027679443
Validation loss: 1.9162746244861233

Epoch: 6| Step: 12
Training loss: 1.2298938035964966
Validation loss: 2.0065403035891953

Epoch: 6| Step: 13
Training loss: 1.6355664730072021
Validation loss: 2.008834167193341

Epoch: 188| Step: 0
Training loss: 1.450626254081726
Validation loss: 1.9917964602029452

Epoch: 6| Step: 1
Training loss: 2.177004098892212
Validation loss: 1.9433515507687804

Epoch: 6| Step: 2
Training loss: 1.5388026237487793
Validation loss: 1.951183908729143

Epoch: 6| Step: 3
Training loss: 1.490220069885254
Validation loss: 1.9508303544854606

Epoch: 6| Step: 4
Training loss: 1.5454108715057373
Validation loss: 2.0439994078810497

Epoch: 6| Step: 5
Training loss: 2.5915865898132324
Validation loss: 2.0095276422398065

Epoch: 6| Step: 6
Training loss: 1.9611443281173706
Validation loss: 2.0004148021821053

Epoch: 6| Step: 7
Training loss: 1.4802255630493164
Validation loss: 1.9742527354148127

Epoch: 6| Step: 8
Training loss: 2.073237657546997
Validation loss: 1.992149435063844

Epoch: 6| Step: 9
Training loss: 2.038382053375244
Validation loss: 1.9780853243284329

Epoch: 6| Step: 10
Training loss: 2.0835585594177246
Validation loss: 1.9957016943603434

Epoch: 6| Step: 11
Training loss: 1.677947759628296
Validation loss: 1.9356065347630491

Epoch: 6| Step: 12
Training loss: 1.7644418478012085
Validation loss: 1.9606619406771917

Epoch: 6| Step: 13
Training loss: 2.0309762954711914
Validation loss: 1.9713342984517415

Epoch: 189| Step: 0
Training loss: 1.8967087268829346
Validation loss: 1.9663678164123206

Epoch: 6| Step: 1
Training loss: 1.6088056564331055
Validation loss: 1.9773119470124603

Epoch: 6| Step: 2
Training loss: 1.6635119915008545
Validation loss: 2.015627755913683

Epoch: 6| Step: 3
Training loss: 2.4906973838806152
Validation loss: 1.9455799595002206

Epoch: 6| Step: 4
Training loss: 2.1934189796447754
Validation loss: 1.998561587384952

Epoch: 6| Step: 5
Training loss: 1.2466307878494263
Validation loss: 2.005732144078901

Epoch: 6| Step: 6
Training loss: 2.139071464538574
Validation loss: 1.975911771097491

Epoch: 6| Step: 7
Training loss: 2.59151029586792
Validation loss: 2.0070449921392624

Epoch: 6| Step: 8
Training loss: 1.1532379388809204
Validation loss: 1.9629951420650686

Epoch: 6| Step: 9
Training loss: 1.7039047479629517
Validation loss: 1.9544160212239912

Epoch: 6| Step: 10
Training loss: 2.0512375831604004
Validation loss: 1.935314965504472

Epoch: 6| Step: 11
Training loss: 2.2667949199676514
Validation loss: 1.9599412769399664

Epoch: 6| Step: 12
Training loss: 1.2192506790161133
Validation loss: 1.9764789355698453

Epoch: 6| Step: 13
Training loss: 1.6107568740844727
Validation loss: 2.0153628651813795

Epoch: 190| Step: 0
Training loss: 2.269278049468994
Validation loss: 2.0059855138101885

Epoch: 6| Step: 1
Training loss: 2.356476306915283
Validation loss: 1.9349695495379868

Epoch: 6| Step: 2
Training loss: 2.0895650386810303
Validation loss: 1.9330950962599887

Epoch: 6| Step: 3
Training loss: 0.9299766421318054
Validation loss: 1.9571917467219855

Epoch: 6| Step: 4
Training loss: 2.013104200363159
Validation loss: 1.944509301134335

Epoch: 6| Step: 5
Training loss: 1.3405494689941406
Validation loss: 1.9770607871394004

Epoch: 6| Step: 6
Training loss: 1.455075740814209
Validation loss: 1.9179361648457025

Epoch: 6| Step: 7
Training loss: 1.9122653007507324
Validation loss: 1.937565775327785

Epoch: 6| Step: 8
Training loss: 2.020110607147217
Validation loss: 1.9312030346162858

Epoch: 6| Step: 9
Training loss: 1.6466938257217407
Validation loss: 2.0135831730340117

Epoch: 6| Step: 10
Training loss: 1.864065170288086
Validation loss: 1.9548735926228185

Epoch: 6| Step: 11
Training loss: 2.1911511421203613
Validation loss: 1.9974348519438057

Epoch: 6| Step: 12
Training loss: 1.5950071811676025
Validation loss: 2.011818137220157

Epoch: 6| Step: 13
Training loss: 1.0268653631210327
Validation loss: 1.9661639557089856

Epoch: 191| Step: 0
Training loss: 2.1060872077941895
Validation loss: 2.0194780967568837

Epoch: 6| Step: 1
Training loss: 1.3716871738433838
Validation loss: 1.9859089774470176

Epoch: 6| Step: 2
Training loss: 1.7355873584747314
Validation loss: 1.993041851187265

Epoch: 6| Step: 3
Training loss: 1.800136923789978
Validation loss: 2.044303286460138

Epoch: 6| Step: 4
Training loss: 2.1234335899353027
Validation loss: 2.0747392485218663

Epoch: 6| Step: 5
Training loss: 1.5177001953125
Validation loss: 1.9920434208326443

Epoch: 6| Step: 6
Training loss: 1.4995731115341187
Validation loss: 2.0563539112767866

Epoch: 6| Step: 7
Training loss: 2.754905939102173
Validation loss: 2.0406721433003745

Epoch: 6| Step: 8
Training loss: 1.5901758670806885
Validation loss: 2.0604390072566208

Epoch: 6| Step: 9
Training loss: 1.2084993124008179
Validation loss: 2.068320906290444

Epoch: 6| Step: 10
Training loss: 2.243803024291992
Validation loss: 1.9711711278525732

Epoch: 6| Step: 11
Training loss: 2.1322150230407715
Validation loss: 1.9659019670178812

Epoch: 6| Step: 12
Training loss: 2.1639254093170166
Validation loss: 2.0073542466727634

Epoch: 6| Step: 13
Training loss: 1.6348990201950073
Validation loss: 1.983803395302065

Epoch: 192| Step: 0
Training loss: 2.7204678058624268
Validation loss: 1.9758426438095749

Epoch: 6| Step: 1
Training loss: 1.7968599796295166
Validation loss: 1.979366066635296

Epoch: 6| Step: 2
Training loss: 1.3983440399169922
Validation loss: 1.994629152359501

Epoch: 6| Step: 3
Training loss: 1.7967668771743774
Validation loss: 1.8992596569881643

Epoch: 6| Step: 4
Training loss: 1.5460346937179565
Validation loss: 1.9486806674670147

Epoch: 6| Step: 5
Training loss: 2.1612234115600586
Validation loss: 1.9659924584050332

Epoch: 6| Step: 6
Training loss: 1.7225053310394287
Validation loss: 1.9954332202993414

Epoch: 6| Step: 7
Training loss: 1.814776062965393
Validation loss: 1.911560712322112

Epoch: 6| Step: 8
Training loss: 1.6358282566070557
Validation loss: 1.90657389292153

Epoch: 6| Step: 9
Training loss: 1.6384403705596924
Validation loss: 1.9594555170305314

Epoch: 6| Step: 10
Training loss: 1.4444537162780762
Validation loss: 1.9522902324635496

Epoch: 6| Step: 11
Training loss: 2.1189968585968018
Validation loss: 1.933625913435413

Epoch: 6| Step: 12
Training loss: 2.0533556938171387
Validation loss: 1.9412643319817

Epoch: 6| Step: 13
Training loss: 1.2427209615707397
Validation loss: 1.9247442701811432

Epoch: 193| Step: 0
Training loss: 0.9963526725769043
Validation loss: 1.9264425462292087

Epoch: 6| Step: 1
Training loss: 1.6486217975616455
Validation loss: 1.9610366846925469

Epoch: 6| Step: 2
Training loss: 1.520009994506836
Validation loss: 1.9789134558810983

Epoch: 6| Step: 3
Training loss: 2.003129482269287
Validation loss: 1.9789934107052383

Epoch: 6| Step: 4
Training loss: 1.9822217226028442
Validation loss: 1.9514982713166105

Epoch: 6| Step: 5
Training loss: 1.5159094333648682
Validation loss: 1.9338146153316702

Epoch: 6| Step: 6
Training loss: 2.002922534942627
Validation loss: 1.9087803620164112

Epoch: 6| Step: 7
Training loss: 1.635526418685913
Validation loss: 1.8783273325171521

Epoch: 6| Step: 8
Training loss: 2.523922920227051
Validation loss: 1.9198974870866345

Epoch: 6| Step: 9
Training loss: 2.041104793548584
Validation loss: 1.9735592231955579

Epoch: 6| Step: 10
Training loss: 1.4056274890899658
Validation loss: 1.959802968527681

Epoch: 6| Step: 11
Training loss: 2.546475887298584
Validation loss: 1.9850820520872712

Epoch: 6| Step: 12
Training loss: 1.8537288904190063
Validation loss: 1.9515687137521722

Epoch: 6| Step: 13
Training loss: 1.97982919216156
Validation loss: 1.937705812915679

Epoch: 194| Step: 0
Training loss: 2.0575103759765625
Validation loss: 1.9317275965085594

Epoch: 6| Step: 1
Training loss: 1.6171586513519287
Validation loss: 2.0556617116415374

Epoch: 6| Step: 2
Training loss: 2.1600570678710938
Validation loss: 1.9961174918759255

Epoch: 6| Step: 3
Training loss: 1.8138946294784546
Validation loss: 1.8759672513572119

Epoch: 6| Step: 4
Training loss: 1.7485620975494385
Validation loss: 1.9237350340812438

Epoch: 6| Step: 5
Training loss: 1.9362449645996094
Validation loss: 1.9957949141020417

Epoch: 6| Step: 6
Training loss: 1.8843753337860107
Validation loss: 1.9787133547567552

Epoch: 6| Step: 7
Training loss: 1.6725764274597168
Validation loss: 1.9806606743925361

Epoch: 6| Step: 8
Training loss: 1.6701711416244507
Validation loss: 2.0025079711791007

Epoch: 6| Step: 9
Training loss: 1.3960256576538086
Validation loss: 1.9671353768276911

Epoch: 6| Step: 10
Training loss: 2.042849540710449
Validation loss: 1.879238768290448

Epoch: 6| Step: 11
Training loss: 1.490506887435913
Validation loss: 1.9567341009775798

Epoch: 6| Step: 12
Training loss: 1.6803042888641357
Validation loss: 1.9615523058881041

Epoch: 6| Step: 13
Training loss: 2.0584399700164795
Validation loss: 2.026891618646601

Epoch: 195| Step: 0
Training loss: 1.4562228918075562
Validation loss: 1.981825449133432

Epoch: 6| Step: 1
Training loss: 1.993464708328247
Validation loss: 1.9094196750271706

Epoch: 6| Step: 2
Training loss: 2.117279052734375
Validation loss: 2.016477405384023

Epoch: 6| Step: 3
Training loss: 1.531769871711731
Validation loss: 1.9646946691697644

Epoch: 6| Step: 4
Training loss: 1.635428547859192
Validation loss: 1.982490849751298

Epoch: 6| Step: 5
Training loss: 1.7510545253753662
Validation loss: 1.9393688542868501

Epoch: 6| Step: 6
Training loss: 1.8768484592437744
Validation loss: 1.9821777728296095

Epoch: 6| Step: 7
Training loss: 2.130650043487549
Validation loss: 2.0224371264057774

Epoch: 6| Step: 8
Training loss: 1.6640257835388184
Validation loss: 1.9449511228069183

Epoch: 6| Step: 9
Training loss: 2.2746739387512207
Validation loss: 1.9591995387948968

Epoch: 6| Step: 10
Training loss: 1.8555853366851807
Validation loss: 1.9530560201214207

Epoch: 6| Step: 11
Training loss: 1.975407600402832
Validation loss: 2.024090823306832

Epoch: 6| Step: 12
Training loss: 1.32937753200531
Validation loss: 1.9392007807249665

Epoch: 6| Step: 13
Training loss: 1.7792693376541138
Validation loss: 1.9352319817389212

Epoch: 196| Step: 0
Training loss: 1.64091157913208
Validation loss: 1.990134604515568

Epoch: 6| Step: 1
Training loss: 1.9498271942138672
Validation loss: 1.9484069065381122

Epoch: 6| Step: 2
Training loss: 2.0960428714752197
Validation loss: 1.9451149817435973

Epoch: 6| Step: 3
Training loss: 1.7095227241516113
Validation loss: 1.9749787110154347

Epoch: 6| Step: 4
Training loss: 1.9290111064910889
Validation loss: 1.944492514415454

Epoch: 6| Step: 5
Training loss: 1.8191496133804321
Validation loss: 1.9702512243742585

Epoch: 6| Step: 6
Training loss: 1.7011831998825073
Validation loss: 1.9024511280880179

Epoch: 6| Step: 7
Training loss: 2.169370412826538
Validation loss: 1.9396701987071703

Epoch: 6| Step: 8
Training loss: 1.7391328811645508
Validation loss: 1.8903244592810189

Epoch: 6| Step: 9
Training loss: 1.541182518005371
Validation loss: 1.9497147183264456

Epoch: 6| Step: 10
Training loss: 1.4921222925186157
Validation loss: 1.9380605938614055

Epoch: 6| Step: 11
Training loss: 1.6123437881469727
Validation loss: 1.962153293753183

Epoch: 6| Step: 12
Training loss: 2.618010997772217
Validation loss: 1.9611787872929727

Epoch: 6| Step: 13
Training loss: 1.8799796104431152
Validation loss: 1.945550205887005

Epoch: 197| Step: 0
Training loss: 2.305802345275879
Validation loss: 1.9784224879357122

Epoch: 6| Step: 1
Training loss: 1.3732531070709229
Validation loss: 1.891843262539115

Epoch: 6| Step: 2
Training loss: 1.3931989669799805
Validation loss: 1.916115168602236

Epoch: 6| Step: 3
Training loss: 2.1336288452148438
Validation loss: 1.999447948189192

Epoch: 6| Step: 4
Training loss: 1.6207337379455566
Validation loss: 1.9888430846634733

Epoch: 6| Step: 5
Training loss: 1.3946822881698608
Validation loss: 1.9913055307121688

Epoch: 6| Step: 6
Training loss: 1.789932131767273
Validation loss: 2.0095260656008156

Epoch: 6| Step: 7
Training loss: 2.18119478225708
Validation loss: 2.041953589326592

Epoch: 6| Step: 8
Training loss: 1.9723641872406006
Validation loss: 2.068446933582265

Epoch: 6| Step: 9
Training loss: 1.6472190618515015
Validation loss: 1.9474174899439658

Epoch: 6| Step: 10
Training loss: 1.9421641826629639
Validation loss: 2.028185572675479

Epoch: 6| Step: 11
Training loss: 1.6083875894546509
Validation loss: 1.9432655226799749

Epoch: 6| Step: 12
Training loss: 2.048438549041748
Validation loss: 1.930656781760595

Epoch: 6| Step: 13
Training loss: 2.0167720317840576
Validation loss: 1.9169407890688988

Epoch: 198| Step: 0
Training loss: 2.044461727142334
Validation loss: 1.9416859739570207

Epoch: 6| Step: 1
Training loss: 2.02708101272583
Validation loss: 2.032314900429018

Epoch: 6| Step: 2
Training loss: 1.4789537191390991
Validation loss: 2.016466515038603

Epoch: 6| Step: 3
Training loss: 1.7438223361968994
Validation loss: 1.9597015585950626

Epoch: 6| Step: 4
Training loss: 2.120884895324707
Validation loss: 2.0479490821079542

Epoch: 6| Step: 5
Training loss: 1.7141185998916626
Validation loss: 1.978718726865707

Epoch: 6| Step: 6
Training loss: 1.5587725639343262
Validation loss: 1.9896688922759025

Epoch: 6| Step: 7
Training loss: 1.544975996017456
Validation loss: 1.9777851335463985

Epoch: 6| Step: 8
Training loss: 2.3406076431274414
Validation loss: 1.957561533938172

Epoch: 6| Step: 9
Training loss: 1.9321637153625488
Validation loss: 1.9888764248099378

Epoch: 6| Step: 10
Training loss: 1.5234683752059937
Validation loss: 1.9508543604163713

Epoch: 6| Step: 11
Training loss: 1.2867729663848877
Validation loss: 1.9618261168079991

Epoch: 6| Step: 12
Training loss: 2.152358055114746
Validation loss: 1.9645285298747401

Epoch: 6| Step: 13
Training loss: 2.534636974334717
Validation loss: 1.9226904364042385

Epoch: 199| Step: 0
Training loss: 1.633200764656067
Validation loss: 1.976542644603278

Epoch: 6| Step: 1
Training loss: 1.2818711996078491
Validation loss: 1.961381612285491

Epoch: 6| Step: 2
Training loss: 1.7091014385223389
Validation loss: 1.9137002473236413

Epoch: 6| Step: 3
Training loss: 1.641900897026062
Validation loss: 1.9903866706355926

Epoch: 6| Step: 4
Training loss: 1.698140025138855
Validation loss: 1.9710487409304547

Epoch: 6| Step: 5
Training loss: 2.435575485229492
Validation loss: 2.020282688961234

Epoch: 6| Step: 6
Training loss: 1.7288844585418701
Validation loss: 1.994441299028294

Epoch: 6| Step: 7
Training loss: 2.191164970397949
Validation loss: 1.8946696699306529

Epoch: 6| Step: 8
Training loss: 1.9782065153121948
Validation loss: 1.8782230013160295

Epoch: 6| Step: 9
Training loss: 2.417940139770508
Validation loss: 1.9505747274685932

Epoch: 6| Step: 10
Training loss: 1.0896488428115845
Validation loss: 1.9646628466985558

Epoch: 6| Step: 11
Training loss: 1.4881548881530762
Validation loss: 1.9966590814693

Epoch: 6| Step: 12
Training loss: 2.0670316219329834
Validation loss: 1.95242109862707

Epoch: 6| Step: 13
Training loss: 2.2318484783172607
Validation loss: 2.0664075754022084

Epoch: 200| Step: 0
Training loss: 1.765653133392334
Validation loss: 1.983256527172622

Epoch: 6| Step: 1
Training loss: 1.4279125928878784
Validation loss: 2.0565805204453005

Epoch: 6| Step: 2
Training loss: 2.700024127960205
Validation loss: 2.037419219170847

Epoch: 6| Step: 3
Training loss: 2.474376678466797
Validation loss: 1.9247518611210648

Epoch: 6| Step: 4
Training loss: 1.6233432292938232
Validation loss: 2.064108725517027

Epoch: 6| Step: 5
Training loss: 1.6390447616577148
Validation loss: 2.0456978992749284

Epoch: 6| Step: 6
Training loss: 2.3418402671813965
Validation loss: 2.1224702660755446

Epoch: 6| Step: 7
Training loss: 1.872072458267212
Validation loss: 2.045841222168297

Epoch: 6| Step: 8
Training loss: 2.0675344467163086
Validation loss: 2.0875122136967157

Epoch: 6| Step: 9
Training loss: 2.308310031890869
Validation loss: 2.0638344774964037

Epoch: 6| Step: 10
Training loss: 1.4345163106918335
Validation loss: 2.0221703603703487

Epoch: 6| Step: 11
Training loss: 1.374725103378296
Validation loss: 2.031641576879768

Epoch: 6| Step: 12
Training loss: 1.64346444606781
Validation loss: 1.9646303269170946

Epoch: 6| Step: 13
Training loss: 1.6189719438552856
Validation loss: 2.0328024202777493

Epoch: 201| Step: 0
Training loss: 1.7198946475982666
Validation loss: 1.9553864463683097

Epoch: 6| Step: 1
Training loss: 2.529567003250122
Validation loss: 1.9624566672950663

Epoch: 6| Step: 2
Training loss: 1.9247291088104248
Validation loss: 1.9831108047116188

Epoch: 6| Step: 3
Training loss: 1.5371320247650146
Validation loss: 1.9576109981024137

Epoch: 6| Step: 4
Training loss: 3.0659236907958984
Validation loss: 1.9863116202815887

Epoch: 6| Step: 5
Training loss: 1.0426557064056396
Validation loss: 1.9850158947770313

Epoch: 6| Step: 6
Training loss: 1.877633810043335
Validation loss: 1.991533028182163

Epoch: 6| Step: 7
Training loss: 1.2735671997070312
Validation loss: 1.9364210482566588

Epoch: 6| Step: 8
Training loss: 2.1797289848327637
Validation loss: 2.011575846261876

Epoch: 6| Step: 9
Training loss: 0.9756115078926086
Validation loss: 1.9437057331044187

Epoch: 6| Step: 10
Training loss: 2.1430020332336426
Validation loss: 1.938048893405545

Epoch: 6| Step: 11
Training loss: 1.5869965553283691
Validation loss: 1.9718330444828156

Epoch: 6| Step: 12
Training loss: 2.1161694526672363
Validation loss: 1.9750349521636963

Epoch: 6| Step: 13
Training loss: 1.298865556716919
Validation loss: 1.9045240071512037

Epoch: 202| Step: 0
Training loss: 1.1171433925628662
Validation loss: 1.92854308056575

Epoch: 6| Step: 1
Training loss: 1.8988869190216064
Validation loss: 1.9771672692350162

Epoch: 6| Step: 2
Training loss: 1.8947135210037231
Validation loss: 1.9341894811199558

Epoch: 6| Step: 3
Training loss: 2.1466240882873535
Validation loss: 1.9438979625701904

Epoch: 6| Step: 4
Training loss: 1.1960997581481934
Validation loss: 2.0363735332283923

Epoch: 6| Step: 5
Training loss: 1.9520018100738525
Validation loss: 2.0191806811158375

Epoch: 6| Step: 6
Training loss: 2.2767763137817383
Validation loss: 1.9953045191303376

Epoch: 6| Step: 7
Training loss: 1.5359960794448853
Validation loss: 1.9963724331189228

Epoch: 6| Step: 8
Training loss: 1.9216556549072266
Validation loss: 1.9657442979915167

Epoch: 6| Step: 9
Training loss: 2.150508403778076
Validation loss: 1.9104103888234785

Epoch: 6| Step: 10
Training loss: 2.0761051177978516
Validation loss: 1.9901764444125596

Epoch: 6| Step: 11
Training loss: 1.7724134922027588
Validation loss: 2.0074945944611744

Epoch: 6| Step: 12
Training loss: 1.3535144329071045
Validation loss: 1.9636366841613606

Epoch: 6| Step: 13
Training loss: 1.3670616149902344
Validation loss: 1.984455362443001

Epoch: 203| Step: 0
Training loss: 1.583864450454712
Validation loss: 1.9415897271966422

Epoch: 6| Step: 1
Training loss: 1.260504126548767
Validation loss: 1.9698588925023233

Epoch: 6| Step: 2
Training loss: 2.132026195526123
Validation loss: 1.9216644661400908

Epoch: 6| Step: 3
Training loss: 2.134133815765381
Validation loss: 1.9965855331831082

Epoch: 6| Step: 4
Training loss: 1.3776689767837524
Validation loss: 1.939802094172406

Epoch: 6| Step: 5
Training loss: 1.724701166152954
Validation loss: 2.0384968365392377

Epoch: 6| Step: 6
Training loss: 1.3146333694458008
Validation loss: 2.0072432218059415

Epoch: 6| Step: 7
Training loss: 1.4597280025482178
Validation loss: 2.0039273333805863

Epoch: 6| Step: 8
Training loss: 1.371040940284729
Validation loss: 1.9351688892610612

Epoch: 6| Step: 9
Training loss: 2.2941508293151855
Validation loss: 1.9914734876284035

Epoch: 6| Step: 10
Training loss: 2.432948112487793
Validation loss: 1.9106952131435435

Epoch: 6| Step: 11
Training loss: 2.3032655715942383
Validation loss: 1.9347860787504463

Epoch: 6| Step: 12
Training loss: 2.1866159439086914
Validation loss: 1.9871745750468264

Epoch: 6| Step: 13
Training loss: 1.0202044248580933
Validation loss: 1.9086678604925833

Epoch: 204| Step: 0
Training loss: 2.8838019371032715
Validation loss: 1.9441356851208595

Epoch: 6| Step: 1
Training loss: 1.406386137008667
Validation loss: 1.9445379126456477

Epoch: 6| Step: 2
Training loss: 1.9634650945663452
Validation loss: 1.9157369534174602

Epoch: 6| Step: 3
Training loss: 2.3265340328216553
Validation loss: 1.9160054691376225

Epoch: 6| Step: 4
Training loss: 1.7209739685058594
Validation loss: 1.9613656766953007

Epoch: 6| Step: 5
Training loss: 1.5048447847366333
Validation loss: 1.952942330350158

Epoch: 6| Step: 6
Training loss: 1.7128747701644897
Validation loss: 1.9538694043313303

Epoch: 6| Step: 7
Training loss: 1.9805707931518555
Validation loss: 2.0058970579537014

Epoch: 6| Step: 8
Training loss: 1.5297791957855225
Validation loss: 1.956167705597416

Epoch: 6| Step: 9
Training loss: 1.8590149879455566
Validation loss: 1.987070281018493

Epoch: 6| Step: 10
Training loss: 1.9524614810943604
Validation loss: 1.9789547497226345

Epoch: 6| Step: 11
Training loss: 2.268984317779541
Validation loss: 1.9451424255166003

Epoch: 6| Step: 12
Training loss: 1.4008342027664185
Validation loss: 1.9668835132352767

Epoch: 6| Step: 13
Training loss: 1.5961843729019165
Validation loss: 2.033176911774502

Epoch: 205| Step: 0
Training loss: 1.5280580520629883
Validation loss: 2.0394954707032893

Epoch: 6| Step: 1
Training loss: 2.0492162704467773
Validation loss: 1.9465970352131834

Epoch: 6| Step: 2
Training loss: 1.3653349876403809
Validation loss: 1.9818621848219184

Epoch: 6| Step: 3
Training loss: 1.7425273656845093
Validation loss: 1.9381031810596425

Epoch: 6| Step: 4
Training loss: 2.7682597637176514
Validation loss: 1.943452594100788

Epoch: 6| Step: 5
Training loss: 1.6806316375732422
Validation loss: 1.9609259187534291

Epoch: 6| Step: 6
Training loss: 2.3292391300201416
Validation loss: 1.9549894153430898

Epoch: 6| Step: 7
Training loss: 2.273050308227539
Validation loss: 2.016090175156952

Epoch: 6| Step: 8
Training loss: 1.8423466682434082
Validation loss: 2.0075692540855816

Epoch: 6| Step: 9
Training loss: 1.5314135551452637
Validation loss: 1.995723698728828

Epoch: 6| Step: 10
Training loss: 1.7142815589904785
Validation loss: 1.9591513795237387

Epoch: 6| Step: 11
Training loss: 1.6024541854858398
Validation loss: 1.914712195755333

Epoch: 6| Step: 12
Training loss: 1.4818613529205322
Validation loss: 2.014976350210046

Epoch: 6| Step: 13
Training loss: 1.3301632404327393
Validation loss: 1.9948508201106903

Epoch: 206| Step: 0
Training loss: 1.7691556215286255
Validation loss: 2.0148235405645063

Epoch: 6| Step: 1
Training loss: 1.7369297742843628
Validation loss: 2.062943871303271

Epoch: 6| Step: 2
Training loss: 2.095734119415283
Validation loss: 1.9036903535166094

Epoch: 6| Step: 3
Training loss: 1.6539275646209717
Validation loss: 2.0099708880147626

Epoch: 6| Step: 4
Training loss: 2.057433605194092
Validation loss: 2.0427110746342647

Epoch: 6| Step: 5
Training loss: 2.061915397644043
Validation loss: 1.9621228620570192

Epoch: 6| Step: 6
Training loss: 1.533602237701416
Validation loss: 1.987175513339299

Epoch: 6| Step: 7
Training loss: 2.16609263420105
Validation loss: 1.9924869947536017

Epoch: 6| Step: 8
Training loss: 1.8366979360580444
Validation loss: 2.0095815684205744

Epoch: 6| Step: 9
Training loss: 1.5242326259613037
Validation loss: 1.9893189873746646

Epoch: 6| Step: 10
Training loss: 1.3717998266220093
Validation loss: 2.0346076770495345

Epoch: 6| Step: 11
Training loss: 1.89544677734375
Validation loss: 2.005445731583462

Epoch: 6| Step: 12
Training loss: 2.1750833988189697
Validation loss: 1.9591800038532545

Epoch: 6| Step: 13
Training loss: 2.23958420753479
Validation loss: 1.9625000620401034

Epoch: 207| Step: 0
Training loss: 1.6152825355529785
Validation loss: 1.9477958730472031

Epoch: 6| Step: 1
Training loss: 2.3063337802886963
Validation loss: 1.9611648359606344

Epoch: 6| Step: 2
Training loss: 2.0666439533233643
Validation loss: 1.9771692419564852

Epoch: 6| Step: 3
Training loss: 1.9163326025009155
Validation loss: 1.9530676346953197

Epoch: 6| Step: 4
Training loss: 1.6749367713928223
Validation loss: 1.909463792718867

Epoch: 6| Step: 5
Training loss: 2.0820462703704834
Validation loss: 1.9266448905391078

Epoch: 6| Step: 6
Training loss: 1.805495262145996
Validation loss: 1.9423674280925463

Epoch: 6| Step: 7
Training loss: 2.3029932975769043
Validation loss: 1.990139868951613

Epoch: 6| Step: 8
Training loss: 1.5733418464660645
Validation loss: 1.9398870493776055

Epoch: 6| Step: 9
Training loss: 2.2310051918029785
Validation loss: 1.937092455484534

Epoch: 6| Step: 10
Training loss: 1.6929116249084473
Validation loss: 1.9811837352732176

Epoch: 6| Step: 11
Training loss: 1.560793161392212
Validation loss: 1.9523748941318964

Epoch: 6| Step: 12
Training loss: 1.4388318061828613
Validation loss: 1.8985538880030315

Epoch: 6| Step: 13
Training loss: 1.3105032444000244
Validation loss: 1.9634408502168552

Epoch: 208| Step: 0
Training loss: 1.7173160314559937
Validation loss: 1.9156964568681614

Epoch: 6| Step: 1
Training loss: 2.285043716430664
Validation loss: 1.9603337446848552

Epoch: 6| Step: 2
Training loss: 2.1825456619262695
Validation loss: 1.9528934724869267

Epoch: 6| Step: 3
Training loss: 1.7661362886428833
Validation loss: 1.9772799502136886

Epoch: 6| Step: 4
Training loss: 1.9013667106628418
Validation loss: 2.036252962645664

Epoch: 6| Step: 5
Training loss: 1.615436315536499
Validation loss: 1.9688375496095227

Epoch: 6| Step: 6
Training loss: 2.0994322299957275
Validation loss: 2.015207573931704

Epoch: 6| Step: 7
Training loss: 1.8555817604064941
Validation loss: 1.927513022576609

Epoch: 6| Step: 8
Training loss: 1.8331152200698853
Validation loss: 1.9263299588234193

Epoch: 6| Step: 9
Training loss: 1.9501466751098633
Validation loss: 1.9648637130696287

Epoch: 6| Step: 10
Training loss: 0.9113460183143616
Validation loss: 2.02869055860786

Epoch: 6| Step: 11
Training loss: 1.9048489332199097
Validation loss: 1.9676575942706036

Epoch: 6| Step: 12
Training loss: 1.7792683839797974
Validation loss: 1.9614011459453131

Epoch: 6| Step: 13
Training loss: 1.3124258518218994
Validation loss: 1.9709949288316952

Epoch: 209| Step: 0
Training loss: 1.323439359664917
Validation loss: 1.991076773212802

Epoch: 6| Step: 1
Training loss: 1.4252207279205322
Validation loss: 2.029806847213417

Epoch: 6| Step: 2
Training loss: 1.9799792766571045
Validation loss: 1.9606132725233674

Epoch: 6| Step: 3
Training loss: 1.6127490997314453
Validation loss: 1.9633317634623537

Epoch: 6| Step: 4
Training loss: 2.1973419189453125
Validation loss: 1.960237495360836

Epoch: 6| Step: 5
Training loss: 1.9455841779708862
Validation loss: 1.928086284668215

Epoch: 6| Step: 6
Training loss: 2.188694477081299
Validation loss: 1.906525142731205

Epoch: 6| Step: 7
Training loss: 1.797005534172058
Validation loss: 1.9480970649309055

Epoch: 6| Step: 8
Training loss: 1.7149760723114014
Validation loss: 1.951430546340122

Epoch: 6| Step: 9
Training loss: 1.7362632751464844
Validation loss: 1.976942600742463

Epoch: 6| Step: 10
Training loss: 1.3216601610183716
Validation loss: 1.9988276061191355

Epoch: 6| Step: 11
Training loss: 2.2014970779418945
Validation loss: 1.9690952147206953

Epoch: 6| Step: 12
Training loss: 2.041729211807251
Validation loss: 1.9025158638595252

Epoch: 6| Step: 13
Training loss: 1.842947244644165
Validation loss: 1.9829693148213048

Epoch: 210| Step: 0
Training loss: 1.567825436592102
Validation loss: 1.9942173099005094

Epoch: 6| Step: 1
Training loss: 1.1056667566299438
Validation loss: 1.9757127697749803

Epoch: 6| Step: 2
Training loss: 1.41170334815979
Validation loss: 1.9323684605219031

Epoch: 6| Step: 3
Training loss: 2.4666290283203125
Validation loss: 1.9825171565496793

Epoch: 6| Step: 4
Training loss: 1.5935901403427124
Validation loss: 1.951087797841718

Epoch: 6| Step: 5
Training loss: 1.6419074535369873
Validation loss: 1.9986969399195846

Epoch: 6| Step: 6
Training loss: 2.2088682651519775
Validation loss: 1.9476446784952635

Epoch: 6| Step: 7
Training loss: 1.8104710578918457
Validation loss: 1.9600798711981824

Epoch: 6| Step: 8
Training loss: 1.6408841609954834
Validation loss: 1.9888519407600485

Epoch: 6| Step: 9
Training loss: 1.9309160709381104
Validation loss: 1.9777273362682712

Epoch: 6| Step: 10
Training loss: 2.537367343902588
Validation loss: 2.0002979616965018

Epoch: 6| Step: 11
Training loss: 1.4951024055480957
Validation loss: 1.925576550986177

Epoch: 6| Step: 12
Training loss: 1.7138296365737915
Validation loss: 1.9828322984838997

Epoch: 6| Step: 13
Training loss: 1.3404004573822021
Validation loss: 2.0013425247643584

Epoch: 211| Step: 0
Training loss: 1.296979308128357
Validation loss: 2.00122239769146

Epoch: 6| Step: 1
Training loss: 2.2622952461242676
Validation loss: 2.0006489343540643

Epoch: 6| Step: 2
Training loss: 1.6234731674194336
Validation loss: 2.052663316008865

Epoch: 6| Step: 3
Training loss: 1.7641719579696655
Validation loss: 1.9658074045694003

Epoch: 6| Step: 4
Training loss: 1.3531285524368286
Validation loss: 1.9672217522898028

Epoch: 6| Step: 5
Training loss: 2.492685317993164
Validation loss: 1.9242016038587015

Epoch: 6| Step: 6
Training loss: 1.6434645652770996
Validation loss: 2.0397986506903045

Epoch: 6| Step: 7
Training loss: 1.7348103523254395
Validation loss: 1.903695047542613

Epoch: 6| Step: 8
Training loss: 2.1944618225097656
Validation loss: 1.9674924214680989

Epoch: 6| Step: 9
Training loss: 1.2716220617294312
Validation loss: 1.942197174154302

Epoch: 6| Step: 10
Training loss: 1.7141953706741333
Validation loss: 1.9182015452333676

Epoch: 6| Step: 11
Training loss: 1.9706662893295288
Validation loss: 1.9924873011086577

Epoch: 6| Step: 12
Training loss: 2.4742727279663086
Validation loss: 1.9721518742140902

Epoch: 6| Step: 13
Training loss: 1.5197213888168335
Validation loss: 1.9672979270258257

Epoch: 212| Step: 0
Training loss: 1.3330729007720947
Validation loss: 1.9733418341605895

Epoch: 6| Step: 1
Training loss: 2.002546787261963
Validation loss: 1.9641739142838346

Epoch: 6| Step: 2
Training loss: 1.5511983633041382
Validation loss: 2.124249073766893

Epoch: 6| Step: 3
Training loss: 2.0100953578948975
Validation loss: 2.0414397101248465

Epoch: 6| Step: 4
Training loss: 1.8773560523986816
Validation loss: 2.064456557714811

Epoch: 6| Step: 5
Training loss: 1.4902381896972656
Validation loss: 2.060347321212933

Epoch: 6| Step: 6
Training loss: 1.8047888278961182
Validation loss: 2.056612173716227

Epoch: 6| Step: 7
Training loss: 1.8844285011291504
Validation loss: 2.1150475522523284

Epoch: 6| Step: 8
Training loss: 1.6801860332489014
Validation loss: 2.123986492874802

Epoch: 6| Step: 9
Training loss: 2.7450335025787354
Validation loss: 2.0654945322262344

Epoch: 6| Step: 10
Training loss: 1.857058048248291
Validation loss: 2.0775116976871284

Epoch: 6| Step: 11
Training loss: 1.6171915531158447
Validation loss: 2.019384338009742

Epoch: 6| Step: 12
Training loss: 2.324517250061035
Validation loss: 2.0152112796742427

Epoch: 6| Step: 13
Training loss: 1.7865564823150635
Validation loss: 2.0002561897359867

Epoch: 213| Step: 0
Training loss: 1.702315330505371
Validation loss: 1.9796258377772507

Epoch: 6| Step: 1
Training loss: 1.8354192972183228
Validation loss: 1.9567814245018909

Epoch: 6| Step: 2
Training loss: 1.586409568786621
Validation loss: 2.0185348500487623

Epoch: 6| Step: 3
Training loss: 1.7619186639785767
Validation loss: 1.9210308841479722

Epoch: 6| Step: 4
Training loss: 2.693800687789917
Validation loss: 1.8795051305524764

Epoch: 6| Step: 5
Training loss: 1.724685788154602
Validation loss: 2.0008144519662343

Epoch: 6| Step: 6
Training loss: 1.660541296005249
Validation loss: 1.9550149953493507

Epoch: 6| Step: 7
Training loss: 2.6653857231140137
Validation loss: 1.9676465065248552

Epoch: 6| Step: 8
Training loss: 1.7008700370788574
Validation loss: 1.9486371419763053

Epoch: 6| Step: 9
Training loss: 1.3398540019989014
Validation loss: 1.9441672230279574

Epoch: 6| Step: 10
Training loss: 1.7941365242004395
Validation loss: 1.9558492463122132

Epoch: 6| Step: 11
Training loss: 1.8466488122940063
Validation loss: 2.0198219207025345

Epoch: 6| Step: 12
Training loss: 1.811575174331665
Validation loss: 1.9098988040801017

Epoch: 6| Step: 13
Training loss: 1.2570338249206543
Validation loss: 1.9623963679036787

Epoch: 214| Step: 0
Training loss: 2.0725255012512207
Validation loss: 1.9342173889119139

Epoch: 6| Step: 1
Training loss: 1.5800837278366089
Validation loss: 2.012178779930197

Epoch: 6| Step: 2
Training loss: 1.1828794479370117
Validation loss: 1.9569718273737098

Epoch: 6| Step: 3
Training loss: 1.3577337265014648
Validation loss: 1.9555988824495705

Epoch: 6| Step: 4
Training loss: 1.8261284828186035
Validation loss: 1.9716071441609373

Epoch: 6| Step: 5
Training loss: 2.140753746032715
Validation loss: 1.9793380037430794

Epoch: 6| Step: 6
Training loss: 1.468764305114746
Validation loss: 1.8976039578837733

Epoch: 6| Step: 7
Training loss: 2.100928783416748
Validation loss: 1.9522943342885664

Epoch: 6| Step: 8
Training loss: 1.5600266456604004
Validation loss: 2.0530709066698627

Epoch: 6| Step: 9
Training loss: 1.8534371852874756
Validation loss: 2.0732812830196914

Epoch: 6| Step: 10
Training loss: 2.195697784423828
Validation loss: 1.9794940717758671

Epoch: 6| Step: 11
Training loss: 2.224158763885498
Validation loss: 1.9960056709986862

Epoch: 6| Step: 12
Training loss: 1.586982011795044
Validation loss: 1.9931041361183248

Epoch: 6| Step: 13
Training loss: 1.4323724508285522
Validation loss: 2.031277802682692

Epoch: 215| Step: 0
Training loss: 1.5116207599639893
Validation loss: 2.0019992115677043

Epoch: 6| Step: 1
Training loss: 1.4111850261688232
Validation loss: 1.9715196368514851

Epoch: 6| Step: 2
Training loss: 0.8874437808990479
Validation loss: 1.9161126613616943

Epoch: 6| Step: 3
Training loss: 1.6463044881820679
Validation loss: 1.9311812975073372

Epoch: 6| Step: 4
Training loss: 2.0649795532226562
Validation loss: 1.9417700177879744

Epoch: 6| Step: 5
Training loss: 3.1902523040771484
Validation loss: 1.97766621523006

Epoch: 6| Step: 6
Training loss: 1.6039530038833618
Validation loss: 1.9469092507516184

Epoch: 6| Step: 7
Training loss: 1.748375415802002
Validation loss: 1.9360621424131497

Epoch: 6| Step: 8
Training loss: 2.335505723953247
Validation loss: 2.0131946212501934

Epoch: 6| Step: 9
Training loss: 1.5192365646362305
Validation loss: 1.974981466929118

Epoch: 6| Step: 10
Training loss: 1.009621500968933
Validation loss: 1.9572062620552637

Epoch: 6| Step: 11
Training loss: 2.5191211700439453
Validation loss: 1.9220276673634846

Epoch: 6| Step: 12
Training loss: 1.6986608505249023
Validation loss: 2.004642862145619

Epoch: 6| Step: 13
Training loss: 1.507272720336914
Validation loss: 1.9804047076932845

Epoch: 216| Step: 0
Training loss: 1.088958740234375
Validation loss: 1.9748451402110438

Epoch: 6| Step: 1
Training loss: 1.7801963090896606
Validation loss: 1.9971309208100843

Epoch: 6| Step: 2
Training loss: 1.9346740245819092
Validation loss: 2.030211197432651

Epoch: 6| Step: 3
Training loss: 2.5062415599823
Validation loss: 2.045672760214857

Epoch: 6| Step: 4
Training loss: 1.7253859043121338
Validation loss: 1.9627571003411406

Epoch: 6| Step: 5
Training loss: 2.2846999168395996
Validation loss: 1.978089718408482

Epoch: 6| Step: 6
Training loss: 1.5800223350524902
Validation loss: 1.974810549007949

Epoch: 6| Step: 7
Training loss: 1.867567777633667
Validation loss: 2.028979843662631

Epoch: 6| Step: 8
Training loss: 1.9194053411483765
Validation loss: 2.0023173696251324

Epoch: 6| Step: 9
Training loss: 1.9005732536315918
Validation loss: 1.9512750089809459

Epoch: 6| Step: 10
Training loss: 1.5922907590866089
Validation loss: 2.0431841778498825

Epoch: 6| Step: 11
Training loss: 1.5267866849899292
Validation loss: 2.026555292067989

Epoch: 6| Step: 12
Training loss: 2.21705961227417
Validation loss: 2.0114301917373494

Epoch: 6| Step: 13
Training loss: 1.1330453157424927
Validation loss: 1.9729175721445391

Epoch: 217| Step: 0
Training loss: 2.2764434814453125
Validation loss: 1.9878964808679396

Epoch: 6| Step: 1
Training loss: 2.0397789478302
Validation loss: 1.9979149961984286

Epoch: 6| Step: 2
Training loss: 1.3331212997436523
Validation loss: 1.9493192280492475

Epoch: 6| Step: 3
Training loss: 1.621093511581421
Validation loss: 1.9610007065598682

Epoch: 6| Step: 4
Training loss: 2.5716676712036133
Validation loss: 1.9344873864163634

Epoch: 6| Step: 5
Training loss: 1.7050561904907227
Validation loss: 1.9681083476671608

Epoch: 6| Step: 6
Training loss: 2.0388426780700684
Validation loss: 1.955391428803885

Epoch: 6| Step: 7
Training loss: 1.9329098463058472
Validation loss: 1.938401101737894

Epoch: 6| Step: 8
Training loss: 1.3868167400360107
Validation loss: 1.9161075238258607

Epoch: 6| Step: 9
Training loss: 1.503122091293335
Validation loss: 1.9269653661276704

Epoch: 6| Step: 10
Training loss: 1.6427037715911865
Validation loss: 1.9219192074191185

Epoch: 6| Step: 11
Training loss: 1.9737403392791748
Validation loss: 1.9644488288510231

Epoch: 6| Step: 12
Training loss: 1.4505722522735596
Validation loss: 1.9225897507000995

Epoch: 6| Step: 13
Training loss: 1.2611929178237915
Validation loss: 1.9738026998376335

Epoch: 218| Step: 0
Training loss: 1.8679358959197998
Validation loss: 1.9819045092469902

Epoch: 6| Step: 1
Training loss: 0.9205389022827148
Validation loss: 1.9382306324538363

Epoch: 6| Step: 2
Training loss: 1.9100011587142944
Validation loss: 1.9173848795634445

Epoch: 6| Step: 3
Training loss: 1.6740245819091797
Validation loss: 1.9345064932300198

Epoch: 6| Step: 4
Training loss: 1.560549020767212
Validation loss: 1.9476500531678558

Epoch: 6| Step: 5
Training loss: 2.467477560043335
Validation loss: 1.9352107342853342

Epoch: 6| Step: 6
Training loss: 1.7935001850128174
Validation loss: 1.9840446588813618

Epoch: 6| Step: 7
Training loss: 2.1800968647003174
Validation loss: 1.9376801393365348

Epoch: 6| Step: 8
Training loss: 1.4704092741012573
Validation loss: 1.9166205698443997

Epoch: 6| Step: 9
Training loss: 1.8873746395111084
Validation loss: 2.019933407024671

Epoch: 6| Step: 10
Training loss: 2.5395915508270264
Validation loss: 1.9756370821306783

Epoch: 6| Step: 11
Training loss: 1.061414361000061
Validation loss: 1.9810791438625706

Epoch: 6| Step: 12
Training loss: 1.8661080598831177
Validation loss: 1.9851940383193314

Epoch: 6| Step: 13
Training loss: 1.258630633354187
Validation loss: 1.9343533682566818

Epoch: 219| Step: 0
Training loss: 1.4900519847869873
Validation loss: 1.9472096940522552

Epoch: 6| Step: 1
Training loss: 1.746995449066162
Validation loss: 2.0061084916514735

Epoch: 6| Step: 2
Training loss: 2.404879093170166
Validation loss: 1.9179899346443914

Epoch: 6| Step: 3
Training loss: 1.6960035562515259
Validation loss: 1.9296217990177933

Epoch: 6| Step: 4
Training loss: 1.2533903121948242
Validation loss: 1.9810559262511551

Epoch: 6| Step: 5
Training loss: 1.5357712507247925
Validation loss: 1.9289110450334446

Epoch: 6| Step: 6
Training loss: 1.8853733539581299
Validation loss: 1.946445276660304

Epoch: 6| Step: 7
Training loss: 1.3474026918411255
Validation loss: 1.9662681395007717

Epoch: 6| Step: 8
Training loss: 1.965448260307312
Validation loss: 1.9238196752404655

Epoch: 6| Step: 9
Training loss: 2.044215679168701
Validation loss: 1.945721810863864

Epoch: 6| Step: 10
Training loss: 2.3416717052459717
Validation loss: 1.9002581719429261

Epoch: 6| Step: 11
Training loss: 1.7611944675445557
Validation loss: 1.9235277227176133

Epoch: 6| Step: 12
Training loss: 2.0726418495178223
Validation loss: 1.957646337888574

Epoch: 6| Step: 13
Training loss: 1.5776628255844116
Validation loss: 1.9618742722336964

Epoch: 220| Step: 0
Training loss: 1.8372907638549805
Validation loss: 1.9445381831097346

Epoch: 6| Step: 1
Training loss: 1.3202853202819824
Validation loss: 1.926107378416164

Epoch: 6| Step: 2
Training loss: 1.2390058040618896
Validation loss: 1.9555600868758334

Epoch: 6| Step: 3
Training loss: 2.0987045764923096
Validation loss: 2.0328886444850633

Epoch: 6| Step: 4
Training loss: 1.49281907081604
Validation loss: 2.0057914539050032

Epoch: 6| Step: 5
Training loss: 1.7914297580718994
Validation loss: 1.9751341599290089

Epoch: 6| Step: 6
Training loss: 2.3563942909240723
Validation loss: 1.941394063734239

Epoch: 6| Step: 7
Training loss: 1.7251745462417603
Validation loss: 1.9569812897712953

Epoch: 6| Step: 8
Training loss: 2.158438205718994
Validation loss: 2.0157974061145576

Epoch: 6| Step: 9
Training loss: 1.7136610746383667
Validation loss: 1.9701834699159027

Epoch: 6| Step: 10
Training loss: 2.031912088394165
Validation loss: 1.974555000182121

Epoch: 6| Step: 11
Training loss: 1.1257944107055664
Validation loss: 1.960796574110626

Epoch: 6| Step: 12
Training loss: 2.2004642486572266
Validation loss: 1.9445714604470037

Epoch: 6| Step: 13
Training loss: 1.3418550491333008
Validation loss: 2.017059956827471

Epoch: 221| Step: 0
Training loss: 1.6334964036941528
Validation loss: 1.9452678029255202

Epoch: 6| Step: 1
Training loss: 2.343653678894043
Validation loss: 2.0375649134318032

Epoch: 6| Step: 2
Training loss: 2.3033604621887207
Validation loss: 2.007465695822111

Epoch: 6| Step: 3
Training loss: 1.3660494089126587
Validation loss: 1.959038003798454

Epoch: 6| Step: 4
Training loss: 1.488029956817627
Validation loss: 2.0026159940227384

Epoch: 6| Step: 5
Training loss: 1.123659372329712
Validation loss: 2.0102979636961416

Epoch: 6| Step: 6
Training loss: 1.7044557332992554
Validation loss: 1.9740225935495028

Epoch: 6| Step: 7
Training loss: 2.150759220123291
Validation loss: 1.9408906070134972

Epoch: 6| Step: 8
Training loss: 1.5136083364486694
Validation loss: 2.0083716454044467

Epoch: 6| Step: 9
Training loss: 1.2640717029571533
Validation loss: 1.929798949149347

Epoch: 6| Step: 10
Training loss: 1.8743536472320557
Validation loss: 1.957313096651467

Epoch: 6| Step: 11
Training loss: 1.9263676404953003
Validation loss: 1.914298988157703

Epoch: 6| Step: 12
Training loss: 2.0301949977874756
Validation loss: 1.9716840021071895

Epoch: 6| Step: 13
Training loss: 1.7504229545593262
Validation loss: 1.9628552698319959

Epoch: 222| Step: 0
Training loss: 1.7416019439697266
Validation loss: 1.8779016553714711

Epoch: 6| Step: 1
Training loss: 2.517098903656006
Validation loss: 2.0060095069228963

Epoch: 6| Step: 2
Training loss: 1.6804728507995605
Validation loss: 2.005520846254082

Epoch: 6| Step: 3
Training loss: 1.0541833639144897
Validation loss: 1.9450869124422792

Epoch: 6| Step: 4
Training loss: 2.3167037963867188
Validation loss: 2.0203105377894577

Epoch: 6| Step: 5
Training loss: 1.717515230178833
Validation loss: 1.9450250633301274

Epoch: 6| Step: 6
Training loss: 1.7766950130462646
Validation loss: 1.9363218225458616

Epoch: 6| Step: 7
Training loss: 1.8870325088500977
Validation loss: 1.9725393659325057

Epoch: 6| Step: 8
Training loss: 1.3301844596862793
Validation loss: 2.0110471312717726

Epoch: 6| Step: 9
Training loss: 1.8120874166488647
Validation loss: 2.0128678301329255

Epoch: 6| Step: 10
Training loss: 1.5661834478378296
Validation loss: 1.979258478328746

Epoch: 6| Step: 11
Training loss: 1.5350697040557861
Validation loss: 1.9748361623415382

Epoch: 6| Step: 12
Training loss: 2.4189488887786865
Validation loss: 2.0068569311531643

Epoch: 6| Step: 13
Training loss: 1.1618952751159668
Validation loss: 1.955697508268459

Epoch: 223| Step: 0
Training loss: 1.8405522108078003
Validation loss: 1.9582036233717395

Epoch: 6| Step: 1
Training loss: 1.9017194509506226
Validation loss: 1.912590390892439

Epoch: 6| Step: 2
Training loss: 1.997200608253479
Validation loss: 1.9545963438608314

Epoch: 6| Step: 3
Training loss: 1.427657961845398
Validation loss: 1.9634712767857376

Epoch: 6| Step: 4
Training loss: 1.3798829317092896
Validation loss: 2.0528006374195056

Epoch: 6| Step: 5
Training loss: 1.3854681253433228
Validation loss: 1.961128060535718

Epoch: 6| Step: 6
Training loss: 2.4191808700561523
Validation loss: 1.998545754340387

Epoch: 6| Step: 7
Training loss: 1.827152132987976
Validation loss: 1.9931154302371445

Epoch: 6| Step: 8
Training loss: 1.4664647579193115
Validation loss: 1.9918633891690163

Epoch: 6| Step: 9
Training loss: 2.107821464538574
Validation loss: 1.9808636019306798

Epoch: 6| Step: 10
Training loss: 1.8549317121505737
Validation loss: 2.0367537160073557

Epoch: 6| Step: 11
Training loss: 1.6794430017471313
Validation loss: 2.0781766201860163

Epoch: 6| Step: 12
Training loss: 1.9576749801635742
Validation loss: 2.0356130599975586

Epoch: 6| Step: 13
Training loss: 1.6194871664047241
Validation loss: 1.9615399504220614

Epoch: 224| Step: 0
Training loss: 1.3537664413452148
Validation loss: 1.970596408331266

Epoch: 6| Step: 1
Training loss: 1.4156948328018188
Validation loss: 1.9255481176478888

Epoch: 6| Step: 2
Training loss: 2.0879673957824707
Validation loss: 2.035902443752494

Epoch: 6| Step: 3
Training loss: 2.141038179397583
Validation loss: 1.9424262610814904

Epoch: 6| Step: 4
Training loss: 1.988702416419983
Validation loss: 1.9753475432754846

Epoch: 6| Step: 5
Training loss: 2.2458481788635254
Validation loss: 1.9483080371733634

Epoch: 6| Step: 6
Training loss: 1.4281847476959229
Validation loss: 1.978012869434972

Epoch: 6| Step: 7
Training loss: 2.031278610229492
Validation loss: 1.9327675450232722

Epoch: 6| Step: 8
Training loss: 1.6819684505462646
Validation loss: 1.9091636788460515

Epoch: 6| Step: 9
Training loss: 1.324565052986145
Validation loss: 1.9164899497903802

Epoch: 6| Step: 10
Training loss: 1.4397363662719727
Validation loss: 1.9527708458644089

Epoch: 6| Step: 11
Training loss: 1.8033342361450195
Validation loss: 1.9448467339238813

Epoch: 6| Step: 12
Training loss: 2.195596694946289
Validation loss: 1.918459297508322

Epoch: 6| Step: 13
Training loss: 1.4994722604751587
Validation loss: 2.010677819610924

Epoch: 225| Step: 0
Training loss: 2.2570624351501465
Validation loss: 2.02550983172591

Epoch: 6| Step: 1
Training loss: 2.177299976348877
Validation loss: 1.9692562677526986

Epoch: 6| Step: 2
Training loss: 1.8269050121307373
Validation loss: 1.9552904944266043

Epoch: 6| Step: 3
Training loss: 1.381453275680542
Validation loss: 1.9672564024566321

Epoch: 6| Step: 4
Training loss: 1.7072582244873047
Validation loss: 2.038024845943656

Epoch: 6| Step: 5
Training loss: 1.4799617528915405
Validation loss: 2.025517484193207

Epoch: 6| Step: 6
Training loss: 1.9189311265945435
Validation loss: 2.072045749233615

Epoch: 6| Step: 7
Training loss: 1.7845500707626343
Validation loss: 2.036217183195135

Epoch: 6| Step: 8
Training loss: 2.117421865463257
Validation loss: 2.15949765072074

Epoch: 6| Step: 9
Training loss: 1.7053340673446655
Validation loss: 2.115218218936715

Epoch: 6| Step: 10
Training loss: 1.7187331914901733
Validation loss: 2.0876927247611423

Epoch: 6| Step: 11
Training loss: 1.8984521627426147
Validation loss: 2.0240612055665705

Epoch: 6| Step: 12
Training loss: 1.485435962677002
Validation loss: 2.0234831071669057

Epoch: 6| Step: 13
Training loss: 1.889321208000183
Validation loss: 1.9838703896409722

Epoch: 226| Step: 0
Training loss: 1.5700565576553345
Validation loss: 1.976686607124985

Epoch: 6| Step: 1
Training loss: 1.6309844255447388
Validation loss: 1.9787182154194

Epoch: 6| Step: 2
Training loss: 1.8739951848983765
Validation loss: 1.941971876287973

Epoch: 6| Step: 3
Training loss: 1.667672038078308
Validation loss: 1.963809077457715

Epoch: 6| Step: 4
Training loss: 1.6955642700195312
Validation loss: 1.965228025631238

Epoch: 6| Step: 5
Training loss: 1.6132240295410156
Validation loss: 1.960020396017259

Epoch: 6| Step: 6
Training loss: 2.166316032409668
Validation loss: 1.9424688739161338

Epoch: 6| Step: 7
Training loss: 1.830186367034912
Validation loss: 1.9162251731400848

Epoch: 6| Step: 8
Training loss: 1.6310482025146484
Validation loss: 1.9453676516009915

Epoch: 6| Step: 9
Training loss: 1.8328797817230225
Validation loss: 1.9725694220553163

Epoch: 6| Step: 10
Training loss: 1.851940393447876
Validation loss: 1.971838822928808

Epoch: 6| Step: 11
Training loss: 1.5763440132141113
Validation loss: 2.020731561927385

Epoch: 6| Step: 12
Training loss: 2.050962448120117
Validation loss: 1.9240814178220687

Epoch: 6| Step: 13
Training loss: 1.4945563077926636
Validation loss: 1.9815200759518532

Epoch: 227| Step: 0
Training loss: 1.7914358377456665
Validation loss: 1.988201432330634

Epoch: 6| Step: 1
Training loss: 1.683058500289917
Validation loss: 1.912520750876396

Epoch: 6| Step: 2
Training loss: 2.4032201766967773
Validation loss: 1.953876264633671

Epoch: 6| Step: 3
Training loss: 1.1552700996398926
Validation loss: 1.9002065389387068

Epoch: 6| Step: 4
Training loss: 1.5427368879318237
Validation loss: 2.0493460957722

Epoch: 6| Step: 5
Training loss: 2.538713216781616
Validation loss: 1.9857688155225528

Epoch: 6| Step: 6
Training loss: 2.0372121334075928
Validation loss: 1.9979838530222576

Epoch: 6| Step: 7
Training loss: 2.0943775177001953
Validation loss: 1.9502825775454122

Epoch: 6| Step: 8
Training loss: 1.7641113996505737
Validation loss: 1.9986755745385283

Epoch: 6| Step: 9
Training loss: 1.0287041664123535
Validation loss: 2.012035549327891

Epoch: 6| Step: 10
Training loss: 1.9344183206558228
Validation loss: 1.9716049778846003

Epoch: 6| Step: 11
Training loss: 1.7079319953918457
Validation loss: 2.026875780474755

Epoch: 6| Step: 12
Training loss: 2.164030075073242
Validation loss: 1.9977275299769577

Epoch: 6| Step: 13
Training loss: 1.3002183437347412
Validation loss: 2.0355042052525345

Epoch: 228| Step: 0
Training loss: 1.9638348817825317
Validation loss: 2.0111801906298568

Epoch: 6| Step: 1
Training loss: 2.345525026321411
Validation loss: 1.908396702940746

Epoch: 6| Step: 2
Training loss: 2.0106120109558105
Validation loss: 2.007761196423602

Epoch: 6| Step: 3
Training loss: 1.7091832160949707
Validation loss: 1.9698114395141602

Epoch: 6| Step: 4
Training loss: 2.023184299468994
Validation loss: 1.971166936300134

Epoch: 6| Step: 5
Training loss: 1.3670144081115723
Validation loss: 1.907015795348793

Epoch: 6| Step: 6
Training loss: 1.9520188570022583
Validation loss: 2.0648028722373386

Epoch: 6| Step: 7
Training loss: 1.8136460781097412
Validation loss: 1.9944882495428926

Epoch: 6| Step: 8
Training loss: 1.3477187156677246
Validation loss: 1.9453724007452688

Epoch: 6| Step: 9
Training loss: 2.0299274921417236
Validation loss: 2.0274424886190765

Epoch: 6| Step: 10
Training loss: 1.7386928796768188
Validation loss: 1.932997416424495

Epoch: 6| Step: 11
Training loss: 1.196213960647583
Validation loss: 1.9110941553628573

Epoch: 6| Step: 12
Training loss: 1.1262290477752686
Validation loss: 1.9989212943661598

Epoch: 6| Step: 13
Training loss: 2.4460723400115967
Validation loss: 2.0304242923695552

Epoch: 229| Step: 0
Training loss: 1.3810539245605469
Validation loss: 1.9033930558030323

Epoch: 6| Step: 1
Training loss: 1.7708258628845215
Validation loss: 1.9657966449696531

Epoch: 6| Step: 2
Training loss: 1.2821898460388184
Validation loss: 1.9666872332173009

Epoch: 6| Step: 3
Training loss: 1.4870717525482178
Validation loss: 1.9668743001517428

Epoch: 6| Step: 4
Training loss: 2.7324790954589844
Validation loss: 2.02526778815895

Epoch: 6| Step: 5
Training loss: 1.6279723644256592
Validation loss: 2.000821018731722

Epoch: 6| Step: 6
Training loss: 2.1849658489227295
Validation loss: 1.865002893632458

Epoch: 6| Step: 7
Training loss: 1.7792012691497803
Validation loss: 1.9623387372621925

Epoch: 6| Step: 8
Training loss: 1.4578649997711182
Validation loss: 2.051814256175872

Epoch: 6| Step: 9
Training loss: 1.5956385135650635
Validation loss: 1.9658044845827165

Epoch: 6| Step: 10
Training loss: 2.051276922225952
Validation loss: 1.9964703334275113

Epoch: 6| Step: 11
Training loss: 1.5116629600524902
Validation loss: 1.9821769934828564

Epoch: 6| Step: 12
Training loss: 1.9740431308746338
Validation loss: 1.9407823854877102

Epoch: 6| Step: 13
Training loss: 1.4287962913513184
Validation loss: 2.0180136747257684

Epoch: 230| Step: 0
Training loss: 1.4864060878753662
Validation loss: 1.95587573769272

Epoch: 6| Step: 1
Training loss: 1.56785249710083
Validation loss: 1.9462970072223293

Epoch: 6| Step: 2
Training loss: 1.400386095046997
Validation loss: 1.9302023610761088

Epoch: 6| Step: 3
Training loss: 1.3720430135726929
Validation loss: 1.929094071029335

Epoch: 6| Step: 4
Training loss: 1.785305142402649
Validation loss: 1.9224598535927393

Epoch: 6| Step: 5
Training loss: 0.8065935373306274
Validation loss: 1.8868668258831065

Epoch: 6| Step: 6
Training loss: 2.0658881664276123
Validation loss: 1.9962252288736322

Epoch: 6| Step: 7
Training loss: 1.6762763261795044
Validation loss: 1.9917396178809545

Epoch: 6| Step: 8
Training loss: 2.0640478134155273
Validation loss: 1.933687025500882

Epoch: 6| Step: 9
Training loss: 1.7728464603424072
Validation loss: 1.9202287722659368

Epoch: 6| Step: 10
Training loss: 1.771362066268921
Validation loss: 1.9572131685031358

Epoch: 6| Step: 11
Training loss: 2.1217100620269775
Validation loss: 2.0535498985680203

Epoch: 6| Step: 12
Training loss: 1.9718265533447266
Validation loss: 1.964918674961213

Epoch: 6| Step: 13
Training loss: 2.5865044593811035
Validation loss: 1.9427924284370996

Epoch: 231| Step: 0
Training loss: 1.754446268081665
Validation loss: 1.9661078427427559

Epoch: 6| Step: 1
Training loss: 1.7938565015792847
Validation loss: 1.9544862957410916

Epoch: 6| Step: 2
Training loss: 1.6288480758666992
Validation loss: 1.984328439158778

Epoch: 6| Step: 3
Training loss: 1.183381199836731
Validation loss: 1.8878822147205312

Epoch: 6| Step: 4
Training loss: 1.9072750806808472
Validation loss: 2.029719785977435

Epoch: 6| Step: 5
Training loss: 1.576014518737793
Validation loss: 1.9203861554463704

Epoch: 6| Step: 6
Training loss: 2.0535247325897217
Validation loss: 1.9413124976619598

Epoch: 6| Step: 7
Training loss: 1.4983036518096924
Validation loss: 2.0218619838837655

Epoch: 6| Step: 8
Training loss: 1.959418773651123
Validation loss: 1.929298004796428

Epoch: 6| Step: 9
Training loss: 1.470515489578247
Validation loss: 1.8611098297180668

Epoch: 6| Step: 10
Training loss: 2.2240700721740723
Validation loss: 1.965901896517764

Epoch: 6| Step: 11
Training loss: 1.581589937210083
Validation loss: 1.9857294405660322

Epoch: 6| Step: 12
Training loss: 1.7784206867218018
Validation loss: 1.97057088857056

Epoch: 6| Step: 13
Training loss: 2.083296060562134
Validation loss: 1.9658623741519066

Epoch: 232| Step: 0
Training loss: 1.2767363786697388
Validation loss: 1.9486747313571233

Epoch: 6| Step: 1
Training loss: 1.9013930559158325
Validation loss: 2.04082945341705

Epoch: 6| Step: 2
Training loss: 2.5650644302368164
Validation loss: 1.960378203340756

Epoch: 6| Step: 3
Training loss: 2.0424644947052
Validation loss: 1.8936204243731756

Epoch: 6| Step: 4
Training loss: 1.9769729375839233
Validation loss: 1.9357946944493118

Epoch: 6| Step: 5
Training loss: 1.1090147495269775
Validation loss: 1.9613361435551797

Epoch: 6| Step: 6
Training loss: 1.7845370769500732
Validation loss: 2.0610101953629525

Epoch: 6| Step: 7
Training loss: 1.68862783908844
Validation loss: 1.9081367241438998

Epoch: 6| Step: 8
Training loss: 1.601940393447876
Validation loss: 1.9764918447822653

Epoch: 6| Step: 9
Training loss: 1.182011604309082
Validation loss: 1.943556490764823

Epoch: 6| Step: 10
Training loss: 1.3603671789169312
Validation loss: 1.9348808565447408

Epoch: 6| Step: 11
Training loss: 2.204859972000122
Validation loss: 1.9757904570589784

Epoch: 6| Step: 12
Training loss: 1.740814447402954
Validation loss: 1.9075195122790594

Epoch: 6| Step: 13
Training loss: 2.0755186080932617
Validation loss: 1.9234296083450317

Epoch: 233| Step: 0
Training loss: 1.528658151626587
Validation loss: 1.962377323899218

Epoch: 6| Step: 1
Training loss: 2.0382604598999023
Validation loss: 1.965251926452883

Epoch: 6| Step: 2
Training loss: 1.6704609394073486
Validation loss: 1.9196607169284616

Epoch: 6| Step: 3
Training loss: 1.6637723445892334
Validation loss: 1.9800249209967993

Epoch: 6| Step: 4
Training loss: 2.6863036155700684
Validation loss: 2.029461117200954

Epoch: 6| Step: 5
Training loss: 1.4323171377182007
Validation loss: 1.9537509718248922

Epoch: 6| Step: 6
Training loss: 1.665604829788208
Validation loss: 2.0430666938904793

Epoch: 6| Step: 7
Training loss: 1.8076231479644775
Validation loss: 1.918614408021332

Epoch: 6| Step: 8
Training loss: 1.6699018478393555
Validation loss: 2.089992401420429

Epoch: 6| Step: 9
Training loss: 2.175536632537842
Validation loss: 1.9605717876906037

Epoch: 6| Step: 10
Training loss: 1.904036045074463
Validation loss: 2.0060184450559717

Epoch: 6| Step: 11
Training loss: 2.219038248062134
Validation loss: 1.9355364384189728

Epoch: 6| Step: 12
Training loss: 1.459127426147461
Validation loss: 1.963298149006341

Epoch: 6| Step: 13
Training loss: 1.0146499872207642
Validation loss: 1.9024404607793337

Epoch: 234| Step: 0
Training loss: 1.623351812362671
Validation loss: 1.9042616351958244

Epoch: 6| Step: 1
Training loss: 1.6726018190383911
Validation loss: 1.9936451732471425

Epoch: 6| Step: 2
Training loss: 1.354823350906372
Validation loss: 1.963766421041181

Epoch: 6| Step: 3
Training loss: 1.6247694492340088
Validation loss: 1.877850854268638

Epoch: 6| Step: 4
Training loss: 1.4391155242919922
Validation loss: 1.911917108361439

Epoch: 6| Step: 5
Training loss: 1.8425763845443726
Validation loss: 1.9711737760933496

Epoch: 6| Step: 6
Training loss: 1.7479735612869263
Validation loss: 1.9318073898233392

Epoch: 6| Step: 7
Training loss: 1.5290026664733887
Validation loss: 1.9833208450707056

Epoch: 6| Step: 8
Training loss: 1.566115140914917
Validation loss: 1.9942875062265704

Epoch: 6| Step: 9
Training loss: 1.6425772905349731
Validation loss: 1.9359824862531436

Epoch: 6| Step: 10
Training loss: 1.8081399202346802
Validation loss: 1.9300096291367725

Epoch: 6| Step: 11
Training loss: 2.098085880279541
Validation loss: 2.002395140227451

Epoch: 6| Step: 12
Training loss: 2.294178009033203
Validation loss: 1.9868587499023767

Epoch: 6| Step: 13
Training loss: 1.7055944204330444
Validation loss: 2.0172490522425663

Epoch: 235| Step: 0
Training loss: 1.9076505899429321
Validation loss: 2.0153523093910626

Epoch: 6| Step: 1
Training loss: 2.456557035446167
Validation loss: 1.9796872164613457

Epoch: 6| Step: 2
Training loss: 1.372711420059204
Validation loss: 1.9602862019692697

Epoch: 6| Step: 3
Training loss: 2.0327539443969727
Validation loss: 1.956900078763244

Epoch: 6| Step: 4
Training loss: 2.4449453353881836
Validation loss: 2.012140727812244

Epoch: 6| Step: 5
Training loss: 1.9707744121551514
Validation loss: 1.920394169386997

Epoch: 6| Step: 6
Training loss: 2.025696277618408
Validation loss: 1.9823226467255624

Epoch: 6| Step: 7
Training loss: 1.484950065612793
Validation loss: 1.9274226773169734

Epoch: 6| Step: 8
Training loss: 1.1975491046905518
Validation loss: 1.969684075283748

Epoch: 6| Step: 9
Training loss: 1.5061838626861572
Validation loss: 1.988998971959596

Epoch: 6| Step: 10
Training loss: 1.4139093160629272
Validation loss: 2.022430266103437

Epoch: 6| Step: 11
Training loss: 1.5397815704345703
Validation loss: 2.0097551192006757

Epoch: 6| Step: 12
Training loss: 1.3943121433258057
Validation loss: 1.9448685261511034

Epoch: 6| Step: 13
Training loss: 1.3900268077850342
Validation loss: 1.9566288186657814

Epoch: 236| Step: 0
Training loss: 1.029613971710205
Validation loss: 1.9913294751157042

Epoch: 6| Step: 1
Training loss: 2.6313955783843994
Validation loss: 1.9360239531404229

Epoch: 6| Step: 2
Training loss: 2.0099964141845703
Validation loss: 1.957465846051452

Epoch: 6| Step: 3
Training loss: 1.7173885107040405
Validation loss: 2.002239675932033

Epoch: 6| Step: 4
Training loss: 2.1802477836608887
Validation loss: 2.0397724387466267

Epoch: 6| Step: 5
Training loss: 1.3871536254882812
Validation loss: 1.9738170626342937

Epoch: 6| Step: 6
Training loss: 1.5797526836395264
Validation loss: 1.967468637292103

Epoch: 6| Step: 7
Training loss: 2.182908058166504
Validation loss: 1.9110508170179141

Epoch: 6| Step: 8
Training loss: 0.9747121334075928
Validation loss: 1.9618189181050947

Epoch: 6| Step: 9
Training loss: 1.6558140516281128
Validation loss: 1.9750097003034366

Epoch: 6| Step: 10
Training loss: 1.577113151550293
Validation loss: 1.9950009366517425

Epoch: 6| Step: 11
Training loss: 2.191469192504883
Validation loss: 2.01761689237369

Epoch: 6| Step: 12
Training loss: 1.0695056915283203
Validation loss: 1.9766763179532942

Epoch: 6| Step: 13
Training loss: 1.9193261861801147
Validation loss: 2.0066787389016922

Epoch: 237| Step: 0
Training loss: 1.5365490913391113
Validation loss: 1.969491445890037

Epoch: 6| Step: 1
Training loss: 2.1166443824768066
Validation loss: 1.9193380237907491

Epoch: 6| Step: 2
Training loss: 1.6203254461288452
Validation loss: 1.9646626364800237

Epoch: 6| Step: 3
Training loss: 2.315783977508545
Validation loss: 1.982656035372006

Epoch: 6| Step: 4
Training loss: 1.4925097227096558
Validation loss: 2.0072129182918097

Epoch: 6| Step: 5
Training loss: 1.5125187635421753
Validation loss: 1.9552274545033772

Epoch: 6| Step: 6
Training loss: 1.6988911628723145
Validation loss: 1.9731252680542648

Epoch: 6| Step: 7
Training loss: 1.1818115711212158
Validation loss: 1.9392595944866058

Epoch: 6| Step: 8
Training loss: 1.2439230680465698
Validation loss: 1.9505160277889622

Epoch: 6| Step: 9
Training loss: 1.572758674621582
Validation loss: 1.946051404040347

Epoch: 6| Step: 10
Training loss: 1.6800265312194824
Validation loss: 1.9917461282463484

Epoch: 6| Step: 11
Training loss: 2.2394542694091797
Validation loss: 1.9884425696506296

Epoch: 6| Step: 12
Training loss: 1.6757619380950928
Validation loss: 1.8824395389967068

Epoch: 6| Step: 13
Training loss: 3.039728879928589
Validation loss: 2.0082254666154102

Epoch: 238| Step: 0
Training loss: 1.1051936149597168
Validation loss: 1.9650412387745355

Epoch: 6| Step: 1
Training loss: 1.7481815814971924
Validation loss: 1.9972468281304965

Epoch: 6| Step: 2
Training loss: 1.8669284582138062
Validation loss: 2.020400849721765

Epoch: 6| Step: 3
Training loss: 1.9456830024719238
Validation loss: 1.9398889336534726

Epoch: 6| Step: 4
Training loss: 1.4354009628295898
Validation loss: 2.026018729773901

Epoch: 6| Step: 5
Training loss: 1.5199090242385864
Validation loss: 1.9702575616939093

Epoch: 6| Step: 6
Training loss: 2.040597915649414
Validation loss: 1.9347766355801654

Epoch: 6| Step: 7
Training loss: 1.5094501972198486
Validation loss: 2.026732547308809

Epoch: 6| Step: 8
Training loss: 2.3702356815338135
Validation loss: 1.9646799179815477

Epoch: 6| Step: 9
Training loss: 1.6757310628890991
Validation loss: 1.9644435515967749

Epoch: 6| Step: 10
Training loss: 1.9411380290985107
Validation loss: 1.9451719278930335

Epoch: 6| Step: 11
Training loss: 2.036641836166382
Validation loss: 1.9538588344409902

Epoch: 6| Step: 12
Training loss: 1.4515342712402344
Validation loss: 1.9703702747180898

Epoch: 6| Step: 13
Training loss: 1.586660623550415
Validation loss: 1.9266427306718723

Epoch: 239| Step: 0
Training loss: 2.132986307144165
Validation loss: 1.952095026611

Epoch: 6| Step: 1
Training loss: 1.6735012531280518
Validation loss: 1.9885372372083767

Epoch: 6| Step: 2
Training loss: 2.146162271499634
Validation loss: 1.9906339465930898

Epoch: 6| Step: 3
Training loss: 1.6998209953308105
Validation loss: 1.8941270202718756

Epoch: 6| Step: 4
Training loss: 1.9461591243743896
Validation loss: 1.9757966533783944

Epoch: 6| Step: 5
Training loss: 1.2848246097564697
Validation loss: 1.9722985336857457

Epoch: 6| Step: 6
Training loss: 1.8494963645935059
Validation loss: 1.9630093113068612

Epoch: 6| Step: 7
Training loss: 1.1619787216186523
Validation loss: 1.9397095634091286

Epoch: 6| Step: 8
Training loss: 2.1352953910827637
Validation loss: 1.9730639291065994

Epoch: 6| Step: 9
Training loss: 1.5014848709106445
Validation loss: 1.97364088027708

Epoch: 6| Step: 10
Training loss: 1.5991274118423462
Validation loss: 1.9745162738266813

Epoch: 6| Step: 11
Training loss: 2.369744300842285
Validation loss: 2.0042314478146133

Epoch: 6| Step: 12
Training loss: 1.5783742666244507
Validation loss: 1.977983529849719

Epoch: 6| Step: 13
Training loss: 0.7830708026885986
Validation loss: 2.0016482901829544

Epoch: 240| Step: 0
Training loss: 2.1102116107940674
Validation loss: 1.9750563790721278

Epoch: 6| Step: 1
Training loss: 1.640021562576294
Validation loss: 1.9427277298383816

Epoch: 6| Step: 2
Training loss: 1.142944574356079
Validation loss: 1.93961347815811

Epoch: 6| Step: 3
Training loss: 1.497597575187683
Validation loss: 1.9068596363067627

Epoch: 6| Step: 4
Training loss: 2.1027023792266846
Validation loss: 1.960561934337821

Epoch: 6| Step: 5
Training loss: 1.7882081270217896
Validation loss: 1.9937163873385357

Epoch: 6| Step: 6
Training loss: 2.224571704864502
Validation loss: 1.9418836127045334

Epoch: 6| Step: 7
Training loss: 1.0575755834579468
Validation loss: 1.9809009439201766

Epoch: 6| Step: 8
Training loss: 1.6763373613357544
Validation loss: 1.9705590637781287

Epoch: 6| Step: 9
Training loss: 2.389132499694824
Validation loss: 2.0006688589690835

Epoch: 6| Step: 10
Training loss: 1.4734928607940674
Validation loss: 1.9962436563225203

Epoch: 6| Step: 11
Training loss: 1.720211386680603
Validation loss: 1.9937422557543683

Epoch: 6| Step: 12
Training loss: 1.7959010601043701
Validation loss: 1.996421249963904

Epoch: 6| Step: 13
Training loss: 0.753070592880249
Validation loss: 1.9569756138709284

Epoch: 241| Step: 0
Training loss: 1.7939419746398926
Validation loss: 1.9487128616661153

Epoch: 6| Step: 1
Training loss: 2.1695971488952637
Validation loss: 1.9315413890346405

Epoch: 6| Step: 2
Training loss: 1.763757586479187
Validation loss: 1.9276763469942155

Epoch: 6| Step: 3
Training loss: 1.8162052631378174
Validation loss: 1.9563838051211448

Epoch: 6| Step: 4
Training loss: 1.7807683944702148
Validation loss: 1.9699473534860918

Epoch: 6| Step: 5
Training loss: 1.7297067642211914
Validation loss: 1.9831432078474311

Epoch: 6| Step: 6
Training loss: 1.4205310344696045
Validation loss: 1.9385932222489388

Epoch: 6| Step: 7
Training loss: 2.1074023246765137
Validation loss: 1.9391629618983115

Epoch: 6| Step: 8
Training loss: 1.243322730064392
Validation loss: 1.9067438392228977

Epoch: 6| Step: 9
Training loss: 1.744364857673645
Validation loss: 1.9529001853799308

Epoch: 6| Step: 10
Training loss: 1.490646243095398
Validation loss: 1.9267106363850255

Epoch: 6| Step: 11
Training loss: 1.3025188446044922
Validation loss: 1.9349145043280818

Epoch: 6| Step: 12
Training loss: 1.797982096672058
Validation loss: 1.9201367619217082

Epoch: 6| Step: 13
Training loss: 1.5881296396255493
Validation loss: 1.934633239623039

Epoch: 242| Step: 0
Training loss: 2.130887031555176
Validation loss: 1.9143762973047072

Epoch: 6| Step: 1
Training loss: 1.435806393623352
Validation loss: 1.9151733203600811

Epoch: 6| Step: 2
Training loss: 1.6659806966781616
Validation loss: 1.9166320831544938

Epoch: 6| Step: 3
Training loss: 2.1189944744110107
Validation loss: 2.011448391022221

Epoch: 6| Step: 4
Training loss: 1.5207712650299072
Validation loss: 1.98171583555078

Epoch: 6| Step: 5
Training loss: 2.048826217651367
Validation loss: 1.9109831766415668

Epoch: 6| Step: 6
Training loss: 1.3813352584838867
Validation loss: 1.9340505343611523

Epoch: 6| Step: 7
Training loss: 2.066390037536621
Validation loss: 1.9941497797607093

Epoch: 6| Step: 8
Training loss: 1.298649549484253
Validation loss: 1.915943125242828

Epoch: 6| Step: 9
Training loss: 1.583784818649292
Validation loss: 1.937707454927506

Epoch: 6| Step: 10
Training loss: 1.4152767658233643
Validation loss: 1.9319470159469112

Epoch: 6| Step: 11
Training loss: 1.9392127990722656
Validation loss: 1.9604819872046029

Epoch: 6| Step: 12
Training loss: 2.1077518463134766
Validation loss: 1.9874038132288123

Epoch: 6| Step: 13
Training loss: 1.6664891242980957
Validation loss: 1.9416781548530824

Epoch: 243| Step: 0
Training loss: 1.5582395792007446
Validation loss: 2.005204854472991

Epoch: 6| Step: 1
Training loss: 2.231051206588745
Validation loss: 1.9367142185088126

Epoch: 6| Step: 2
Training loss: 0.9320068955421448
Validation loss: 1.9804844676807363

Epoch: 6| Step: 3
Training loss: 2.108943223953247
Validation loss: 1.9239202558353383

Epoch: 6| Step: 4
Training loss: 2.002748489379883
Validation loss: 1.9601157378124934

Epoch: 6| Step: 5
Training loss: 1.315916895866394
Validation loss: 1.9778958597490865

Epoch: 6| Step: 6
Training loss: 1.842557668685913
Validation loss: 1.972966032643472

Epoch: 6| Step: 7
Training loss: 1.4669108390808105
Validation loss: 1.9902824753074235

Epoch: 6| Step: 8
Training loss: 1.705797791481018
Validation loss: 2.0358277520825787

Epoch: 6| Step: 9
Training loss: 1.4817160367965698
Validation loss: 1.9607778390248616

Epoch: 6| Step: 10
Training loss: 2.234853744506836
Validation loss: 1.967625125761955

Epoch: 6| Step: 11
Training loss: 1.8132930994033813
Validation loss: 1.9455015723423292

Epoch: 6| Step: 12
Training loss: 1.1244175434112549
Validation loss: 1.9708557795452815

Epoch: 6| Step: 13
Training loss: 2.0223827362060547
Validation loss: 1.9291496789583595

Epoch: 244| Step: 0
Training loss: 1.502767562866211
Validation loss: 1.9585425238455496

Epoch: 6| Step: 1
Training loss: 2.07003116607666
Validation loss: 1.962737682045147

Epoch: 6| Step: 2
Training loss: 1.1147903203964233
Validation loss: 1.8757163760482625

Epoch: 6| Step: 3
Training loss: 2.0005080699920654
Validation loss: 1.8795219211168186

Epoch: 6| Step: 4
Training loss: 1.6030502319335938
Validation loss: 1.8563268748662805

Epoch: 6| Step: 5
Training loss: 2.102487087249756
Validation loss: 1.9700958972336144

Epoch: 6| Step: 6
Training loss: 1.2517120838165283
Validation loss: 1.9235694510962373

Epoch: 6| Step: 7
Training loss: 1.5864012241363525
Validation loss: 1.8811974333178612

Epoch: 6| Step: 8
Training loss: 2.159273624420166
Validation loss: 1.9713610526054137

Epoch: 6| Step: 9
Training loss: 2.283046007156372
Validation loss: 1.959078981030372

Epoch: 6| Step: 10
Training loss: 1.380649209022522
Validation loss: 1.9833895519215574

Epoch: 6| Step: 11
Training loss: 1.6497302055358887
Validation loss: 1.928395337955926

Epoch: 6| Step: 12
Training loss: 1.3059964179992676
Validation loss: 1.9673249336981005

Epoch: 6| Step: 13
Training loss: 1.6146897077560425
Validation loss: 2.011439081161253

Epoch: 245| Step: 0
Training loss: 1.593841791152954
Validation loss: 2.031767224752775

Epoch: 6| Step: 1
Training loss: 1.7931644916534424
Validation loss: 1.973762366079515

Epoch: 6| Step: 2
Training loss: 1.5042598247528076
Validation loss: 1.9206056902485509

Epoch: 6| Step: 3
Training loss: 1.3933095932006836
Validation loss: 2.0006771908011487

Epoch: 6| Step: 4
Training loss: 2.071922779083252
Validation loss: 1.9570416199263705

Epoch: 6| Step: 5
Training loss: 1.3877397775650024
Validation loss: 2.0145207502508677

Epoch: 6| Step: 6
Training loss: 1.4518554210662842
Validation loss: 1.9767328949384793

Epoch: 6| Step: 7
Training loss: 1.6823501586914062
Validation loss: 1.9929787266638972

Epoch: 6| Step: 8
Training loss: 2.453599452972412
Validation loss: 1.9495989199607604

Epoch: 6| Step: 9
Training loss: 1.9890244007110596
Validation loss: 1.9405114317453036

Epoch: 6| Step: 10
Training loss: 1.6603178977966309
Validation loss: 1.9551554982380202

Epoch: 6| Step: 11
Training loss: 2.4608614444732666
Validation loss: 1.8862089316050212

Epoch: 6| Step: 12
Training loss: 1.7277297973632812
Validation loss: 1.9425492863501272

Epoch: 6| Step: 13
Training loss: 1.4819347858428955
Validation loss: 1.8901211971877723

Epoch: 246| Step: 0
Training loss: 2.386662006378174
Validation loss: 1.9507911230928154

Epoch: 6| Step: 1
Training loss: 1.794846534729004
Validation loss: 1.9136492372840963

Epoch: 6| Step: 2
Training loss: 2.0212924480438232
Validation loss: 1.9237600321410804

Epoch: 6| Step: 3
Training loss: 1.6306052207946777
Validation loss: 1.9460503824295536

Epoch: 6| Step: 4
Training loss: 1.2425304651260376
Validation loss: 1.8507388548184467

Epoch: 6| Step: 5
Training loss: 1.5982424020767212
Validation loss: 2.0205562755625737

Epoch: 6| Step: 6
Training loss: 1.8087024688720703
Validation loss: 1.9830460420218847

Epoch: 6| Step: 7
Training loss: 2.1216747760772705
Validation loss: 2.031967504050142

Epoch: 6| Step: 8
Training loss: 1.5271100997924805
Validation loss: 1.9334373935576408

Epoch: 6| Step: 9
Training loss: 1.4983644485473633
Validation loss: 1.9591300308063466

Epoch: 6| Step: 10
Training loss: 1.8405258655548096
Validation loss: 1.9394338105314521

Epoch: 6| Step: 11
Training loss: 0.9991968870162964
Validation loss: 1.8830231684510426

Epoch: 6| Step: 12
Training loss: 1.6171505451202393
Validation loss: 1.9430579741795857

Epoch: 6| Step: 13
Training loss: 1.863791584968567
Validation loss: 1.9259610663178146

Epoch: 247| Step: 0
Training loss: 1.9693212509155273
Validation loss: 1.9739704875535862

Epoch: 6| Step: 1
Training loss: 1.7796231508255005
Validation loss: 1.941710743852841

Epoch: 6| Step: 2
Training loss: 1.5436372756958008
Validation loss: 1.9500903852524296

Epoch: 6| Step: 3
Training loss: 2.0409085750579834
Validation loss: 1.9139630961161789

Epoch: 6| Step: 4
Training loss: 1.4393014907836914
Validation loss: 1.979805528476674

Epoch: 6| Step: 5
Training loss: 2.1010942459106445
Validation loss: 1.9633950251404957

Epoch: 6| Step: 6
Training loss: 1.5717597007751465
Validation loss: 1.9790188817567722

Epoch: 6| Step: 7
Training loss: 2.069362163543701
Validation loss: 1.9229930062447824

Epoch: 6| Step: 8
Training loss: 1.2716940641403198
Validation loss: 1.9166507349219373

Epoch: 6| Step: 9
Training loss: 1.2233573198318481
Validation loss: 1.9626612906814904

Epoch: 6| Step: 10
Training loss: 1.867637038230896
Validation loss: 1.9089281712808917

Epoch: 6| Step: 11
Training loss: 1.6092517375946045
Validation loss: 1.9169258097166657

Epoch: 6| Step: 12
Training loss: 1.476878046989441
Validation loss: 1.9563843319492955

Epoch: 6| Step: 13
Training loss: 1.2769185304641724
Validation loss: 1.9776401468502578

Epoch: 248| Step: 0
Training loss: 1.660301685333252
Validation loss: 1.889871084561912

Epoch: 6| Step: 1
Training loss: 1.7310340404510498
Validation loss: 1.9004278054801367

Epoch: 6| Step: 2
Training loss: 2.2017807960510254
Validation loss: 2.005625976029263

Epoch: 6| Step: 3
Training loss: 1.5820090770721436
Validation loss: 1.9305334847460511

Epoch: 6| Step: 4
Training loss: 2.6157050132751465
Validation loss: 1.927852071741576

Epoch: 6| Step: 5
Training loss: 1.9694000482559204
Validation loss: 1.9349497338776946

Epoch: 6| Step: 6
Training loss: 1.6367371082305908
Validation loss: 1.92964211715165

Epoch: 6| Step: 7
Training loss: 1.682307481765747
Validation loss: 1.9781628885576803

Epoch: 6| Step: 8
Training loss: 1.3997559547424316
Validation loss: 1.9516667627519177

Epoch: 6| Step: 9
Training loss: 1.512526512145996
Validation loss: 1.9878426136509064

Epoch: 6| Step: 10
Training loss: 1.8932461738586426
Validation loss: 1.9887860193047473

Epoch: 6| Step: 11
Training loss: 1.656131386756897
Validation loss: 1.9038294130756008

Epoch: 6| Step: 12
Training loss: 1.5536470413208008
Validation loss: 1.9321433113467308

Epoch: 6| Step: 13
Training loss: 1.3645367622375488
Validation loss: 1.952577426869382

Epoch: 249| Step: 0
Training loss: 1.7282787561416626
Validation loss: 1.947377538168302

Epoch: 6| Step: 1
Training loss: 1.9173948764801025
Validation loss: 1.9078753173992198

Epoch: 6| Step: 2
Training loss: 1.5494204759597778
Validation loss: 1.9621434365549395

Epoch: 6| Step: 3
Training loss: 1.79695725440979
Validation loss: 1.9554549545370123

Epoch: 6| Step: 4
Training loss: 1.3143103122711182
Validation loss: 1.9191468018357472

Epoch: 6| Step: 5
Training loss: 2.0607903003692627
Validation loss: 1.9346340612698627

Epoch: 6| Step: 6
Training loss: 1.4533759355545044
Validation loss: 1.9990526232668149

Epoch: 6| Step: 7
Training loss: 1.1565824747085571
Validation loss: 1.9147656361262004

Epoch: 6| Step: 8
Training loss: 1.346034049987793
Validation loss: 2.0179603984279018

Epoch: 6| Step: 9
Training loss: 1.8523883819580078
Validation loss: 1.9502498898454892

Epoch: 6| Step: 10
Training loss: 1.3608269691467285
Validation loss: 1.924083327734342

Epoch: 6| Step: 11
Training loss: 2.138347625732422
Validation loss: 1.9531304336363269

Epoch: 6| Step: 12
Training loss: 1.8778804540634155
Validation loss: 1.9190649268447713

Epoch: 6| Step: 13
Training loss: 2.1678149700164795
Validation loss: 1.9172381816371795

Epoch: 250| Step: 0
Training loss: 2.0027432441711426
Validation loss: 1.9671353858004335

Epoch: 6| Step: 1
Training loss: 1.4778411388397217
Validation loss: 1.9590531369691253

Epoch: 6| Step: 2
Training loss: 1.6344588994979858
Validation loss: 1.9413115337330809

Epoch: 6| Step: 3
Training loss: 1.6560190916061401
Validation loss: 2.0084597936240574

Epoch: 6| Step: 4
Training loss: 1.0844473838806152
Validation loss: 1.94735122752446

Epoch: 6| Step: 5
Training loss: 1.3109411001205444
Validation loss: 1.9556294154095393

Epoch: 6| Step: 6
Training loss: 1.0580849647521973
Validation loss: 1.9773175588218115

Epoch: 6| Step: 7
Training loss: 1.9191923141479492
Validation loss: 1.9138927562262422

Epoch: 6| Step: 8
Training loss: 2.3844428062438965
Validation loss: 1.9791346352587464

Epoch: 6| Step: 9
Training loss: 1.7384129762649536
Validation loss: 1.9289498021525722

Epoch: 6| Step: 10
Training loss: 1.8935296535491943
Validation loss: 1.971825094633205

Epoch: 6| Step: 11
Training loss: 1.970031976699829
Validation loss: 1.9605061084993425

Epoch: 6| Step: 12
Training loss: 1.9632987976074219
Validation loss: 1.964674917600488

Epoch: 6| Step: 13
Training loss: 1.3863582611083984
Validation loss: 2.0406430818701304

Epoch: 251| Step: 0
Training loss: 1.9583061933517456
Validation loss: 1.971160937381047

Epoch: 6| Step: 1
Training loss: 2.298116683959961
Validation loss: 1.9317214130073466

Epoch: 6| Step: 2
Training loss: 1.390244722366333
Validation loss: 2.0190696690672185

Epoch: 6| Step: 3
Training loss: 2.101438283920288
Validation loss: 1.9695392603515296

Epoch: 6| Step: 4
Training loss: 1.4631602764129639
Validation loss: 1.9464395097506944

Epoch: 6| Step: 5
Training loss: 1.8794214725494385
Validation loss: 2.005490444039786

Epoch: 6| Step: 6
Training loss: 1.5671939849853516
Validation loss: 1.985352244428409

Epoch: 6| Step: 7
Training loss: 2.0592172145843506
Validation loss: 1.9450043260410268

Epoch: 6| Step: 8
Training loss: 1.1774615049362183
Validation loss: 1.917619264254006

Epoch: 6| Step: 9
Training loss: 1.6108055114746094
Validation loss: 1.9437544230491883

Epoch: 6| Step: 10
Training loss: 0.9352854490280151
Validation loss: 1.939722845631261

Epoch: 6| Step: 11
Training loss: 1.6298760175704956
Validation loss: 1.9345406345141831

Epoch: 6| Step: 12
Training loss: 2.1664068698883057
Validation loss: 1.9577639923300794

Epoch: 6| Step: 13
Training loss: 2.0740768909454346
Validation loss: 1.9730897026677285

Epoch: 252| Step: 0
Training loss: 1.3595845699310303
Validation loss: 1.98212855990215

Epoch: 6| Step: 1
Training loss: 1.18101167678833
Validation loss: 1.9668236906810472

Epoch: 6| Step: 2
Training loss: 1.798394799232483
Validation loss: 1.9654860317066152

Epoch: 6| Step: 3
Training loss: 2.338776111602783
Validation loss: 1.8899774653937227

Epoch: 6| Step: 4
Training loss: 2.6893935203552246
Validation loss: 1.914919880128676

Epoch: 6| Step: 5
Training loss: 1.4979636669158936
Validation loss: 1.9185322202661985

Epoch: 6| Step: 6
Training loss: 1.3213523626327515
Validation loss: 1.913915447009507

Epoch: 6| Step: 7
Training loss: 2.2582414150238037
Validation loss: 1.893095495880291

Epoch: 6| Step: 8
Training loss: 1.3931012153625488
Validation loss: 1.9795962559279574

Epoch: 6| Step: 9
Training loss: 1.5100504159927368
Validation loss: 1.892217154143959

Epoch: 6| Step: 10
Training loss: 1.6988344192504883
Validation loss: 1.9410331556873937

Epoch: 6| Step: 11
Training loss: 1.795823335647583
Validation loss: 1.9145334894939134

Epoch: 6| Step: 12
Training loss: 1.5418754816055298
Validation loss: 1.9567798094082904

Epoch: 6| Step: 13
Training loss: 2.320512533187866
Validation loss: 1.9661874732663553

Epoch: 253| Step: 0
Training loss: 1.8809876441955566
Validation loss: 1.9822179066237582

Epoch: 6| Step: 1
Training loss: 1.6134300231933594
Validation loss: 1.9982913065982122

Epoch: 6| Step: 2
Training loss: 2.2412021160125732
Validation loss: 1.9652195207534298

Epoch: 6| Step: 3
Training loss: 1.660290241241455
Validation loss: 1.9780439087139663

Epoch: 6| Step: 4
Training loss: 2.550891876220703
Validation loss: 1.976820735521214

Epoch: 6| Step: 5
Training loss: 1.4849872589111328
Validation loss: 1.983022766728555

Epoch: 6| Step: 6
Training loss: 0.9579035043716431
Validation loss: 1.9844427775311213

Epoch: 6| Step: 7
Training loss: 1.3055577278137207
Validation loss: 1.9755456627056163

Epoch: 6| Step: 8
Training loss: 1.5699000358581543
Validation loss: 1.929351217003279

Epoch: 6| Step: 9
Training loss: 1.172710657119751
Validation loss: 1.9413535184757684

Epoch: 6| Step: 10
Training loss: 2.2714481353759766
Validation loss: 2.024300814956747

Epoch: 6| Step: 11
Training loss: 1.6102619171142578
Validation loss: 1.9308923893077399

Epoch: 6| Step: 12
Training loss: 1.4800240993499756
Validation loss: 1.9759100021854523

Epoch: 6| Step: 13
Training loss: 1.8423470258712769
Validation loss: 1.9712595965272637

Epoch: 254| Step: 0
Training loss: 2.0683469772338867
Validation loss: 1.9634752363286994

Epoch: 6| Step: 1
Training loss: 2.070716381072998
Validation loss: 2.004721300576323

Epoch: 6| Step: 2
Training loss: 2.021523952484131
Validation loss: 1.9637159916662401

Epoch: 6| Step: 3
Training loss: 1.632651448249817
Validation loss: 1.9776637118349794

Epoch: 6| Step: 4
Training loss: 1.988059639930725
Validation loss: 1.9529916035231722

Epoch: 6| Step: 5
Training loss: 1.9830747842788696
Validation loss: 1.9429840951837518

Epoch: 6| Step: 6
Training loss: 1.8501495122909546
Validation loss: 1.9701287951520694

Epoch: 6| Step: 7
Training loss: 0.6519969701766968
Validation loss: 1.9579101967555221

Epoch: 6| Step: 8
Training loss: 1.2130792140960693
Validation loss: 1.9565168349973616

Epoch: 6| Step: 9
Training loss: 2.03497052192688
Validation loss: 1.9581643432699225

Epoch: 6| Step: 10
Training loss: 1.3350167274475098
Validation loss: 2.040005730044457

Epoch: 6| Step: 11
Training loss: 1.4247857332229614
Validation loss: 1.9822418561545752

Epoch: 6| Step: 12
Training loss: 1.800112247467041
Validation loss: 2.003044800091815

Epoch: 6| Step: 13
Training loss: 1.4575254917144775
Validation loss: 1.9675158557071482

Epoch: 255| Step: 0
Training loss: 1.9951802492141724
Validation loss: 1.9428998129342192

Epoch: 6| Step: 1
Training loss: 1.8192230463027954
Validation loss: 1.9211410553224626

Epoch: 6| Step: 2
Training loss: 1.666135549545288
Validation loss: 1.9189710693974649

Epoch: 6| Step: 3
Training loss: 1.7231019735336304
Validation loss: 1.950341672025701

Epoch: 6| Step: 4
Training loss: 1.7240275144577026
Validation loss: 1.9179083121720182

Epoch: 6| Step: 5
Training loss: 1.2104766368865967
Validation loss: 1.9096818611186037

Epoch: 6| Step: 6
Training loss: 2.177737236022949
Validation loss: 1.8642985423405964

Epoch: 6| Step: 7
Training loss: 1.5743310451507568
Validation loss: 1.930894354338287

Epoch: 6| Step: 8
Training loss: 1.4250023365020752
Validation loss: 1.923233816700597

Epoch: 6| Step: 9
Training loss: 1.2118117809295654
Validation loss: 1.9346979484763196

Epoch: 6| Step: 10
Training loss: 1.5969160795211792
Validation loss: 1.9370154937108357

Epoch: 6| Step: 11
Training loss: 2.2122323513031006
Validation loss: 1.9725000243033133

Epoch: 6| Step: 12
Training loss: 1.3876876831054688
Validation loss: 1.973085662370087

Epoch: 6| Step: 13
Training loss: 2.0207810401916504
Validation loss: 1.93624892029711

Epoch: 256| Step: 0
Training loss: 1.2678194046020508
Validation loss: 1.9210854191933908

Epoch: 6| Step: 1
Training loss: 0.9276105165481567
Validation loss: 1.9489975847223753

Epoch: 6| Step: 2
Training loss: 1.432673454284668
Validation loss: 1.977116988551232

Epoch: 6| Step: 3
Training loss: 2.54530930519104
Validation loss: 1.9677199676472654

Epoch: 6| Step: 4
Training loss: 1.3143576383590698
Validation loss: 2.004353318163144

Epoch: 6| Step: 5
Training loss: 1.9893839359283447
Validation loss: 1.9869783104106944

Epoch: 6| Step: 6
Training loss: 1.927382230758667
Validation loss: 1.9823422252490956

Epoch: 6| Step: 7
Training loss: 2.18074893951416
Validation loss: 1.967899299437

Epoch: 6| Step: 8
Training loss: 2.0400094985961914
Validation loss: 1.9422313269748483

Epoch: 6| Step: 9
Training loss: 1.5463265180587769
Validation loss: 1.9656093902485345

Epoch: 6| Step: 10
Training loss: 2.407106637954712
Validation loss: 1.9495065724977882

Epoch: 6| Step: 11
Training loss: 1.3805410861968994
Validation loss: 1.9496232027648597

Epoch: 6| Step: 12
Training loss: 1.521194577217102
Validation loss: 2.0006935211919967

Epoch: 6| Step: 13
Training loss: 1.4219948053359985
Validation loss: 1.8883867289430352

Epoch: 257| Step: 0
Training loss: 1.5491814613342285
Validation loss: 1.9296312767972228

Epoch: 6| Step: 1
Training loss: 1.3479366302490234
Validation loss: 1.9691688706797938

Epoch: 6| Step: 2
Training loss: 1.6161720752716064
Validation loss: 1.8824627617354035

Epoch: 6| Step: 3
Training loss: 1.6984825134277344
Validation loss: 1.9533241282227218

Epoch: 6| Step: 4
Training loss: 1.7870125770568848
Validation loss: 1.946731782728626

Epoch: 6| Step: 5
Training loss: 1.7209982872009277
Validation loss: 1.984741327583149

Epoch: 6| Step: 6
Training loss: 1.185072660446167
Validation loss: 1.965243185720136

Epoch: 6| Step: 7
Training loss: 1.7397003173828125
Validation loss: 1.8356445809846282

Epoch: 6| Step: 8
Training loss: 2.170600175857544
Validation loss: 1.93536094568109

Epoch: 6| Step: 9
Training loss: 1.289454460144043
Validation loss: 1.8789687195131857

Epoch: 6| Step: 10
Training loss: 1.7536269426345825
Validation loss: 1.974487086778046

Epoch: 6| Step: 11
Training loss: 1.9998457431793213
Validation loss: 1.8985356694908553

Epoch: 6| Step: 12
Training loss: 1.9257311820983887
Validation loss: 1.890467023336759

Epoch: 6| Step: 13
Training loss: 2.4796154499053955
Validation loss: 1.9402134726124425

Epoch: 258| Step: 0
Training loss: 1.4698030948638916
Validation loss: 1.988905991277387

Epoch: 6| Step: 1
Training loss: 2.0901336669921875
Validation loss: 1.9987685757298623

Epoch: 6| Step: 2
Training loss: 1.9399704933166504
Validation loss: 1.9873579676433275

Epoch: 6| Step: 3
Training loss: 1.5718903541564941
Validation loss: 2.0105068183714345

Epoch: 6| Step: 4
Training loss: 1.4285622835159302
Validation loss: 2.016200115603785

Epoch: 6| Step: 5
Training loss: 1.695145845413208
Validation loss: 2.029619191282539

Epoch: 6| Step: 6
Training loss: 1.846935749053955
Validation loss: 2.0282633689142044

Epoch: 6| Step: 7
Training loss: 1.1944013833999634
Validation loss: 1.9531690125824304

Epoch: 6| Step: 8
Training loss: 1.6108458042144775
Validation loss: 1.9764855292535597

Epoch: 6| Step: 9
Training loss: 1.6810908317565918
Validation loss: 1.9356711731162122

Epoch: 6| Step: 10
Training loss: 2.6129720211029053
Validation loss: 1.8996679475230556

Epoch: 6| Step: 11
Training loss: 1.6518049240112305
Validation loss: 2.008519962269773

Epoch: 6| Step: 12
Training loss: 1.435701847076416
Validation loss: 1.9612413619154243

Epoch: 6| Step: 13
Training loss: 1.546547770500183
Validation loss: 1.9479997388778194

Epoch: 259| Step: 0
Training loss: 2.233515501022339
Validation loss: 1.921497965371737

Epoch: 6| Step: 1
Training loss: 1.6042101383209229
Validation loss: 1.976057424340197

Epoch: 6| Step: 2
Training loss: 1.7834014892578125
Validation loss: 1.9307502238981185

Epoch: 6| Step: 3
Training loss: 1.7283539772033691
Validation loss: 1.9532112870165097

Epoch: 6| Step: 4
Training loss: 1.2855137586593628
Validation loss: 1.9194932035220567

Epoch: 6| Step: 5
Training loss: 1.529505729675293
Validation loss: 1.9519130311986452

Epoch: 6| Step: 6
Training loss: 1.6070163249969482
Validation loss: 1.9458767880675614

Epoch: 6| Step: 7
Training loss: 1.5450193881988525
Validation loss: 1.9796334338444534

Epoch: 6| Step: 8
Training loss: 2.2800180912017822
Validation loss: 1.9900947065763577

Epoch: 6| Step: 9
Training loss: 1.5783202648162842
Validation loss: 1.9389524921294181

Epoch: 6| Step: 10
Training loss: 2.1093626022338867
Validation loss: 2.0062408934357348

Epoch: 6| Step: 11
Training loss: 1.1797261238098145
Validation loss: 1.9585430109372703

Epoch: 6| Step: 12
Training loss: 1.5322434902191162
Validation loss: 1.960267343828755

Epoch: 6| Step: 13
Training loss: 1.250866174697876
Validation loss: 1.9732160286236835

Epoch: 260| Step: 0
Training loss: 2.3121962547302246
Validation loss: 1.9411986694541028

Epoch: 6| Step: 1
Training loss: 1.4008539915084839
Validation loss: 2.027856869082297

Epoch: 6| Step: 2
Training loss: 1.2498149871826172
Validation loss: 1.9128191932555167

Epoch: 6| Step: 3
Training loss: 1.6679140329360962
Validation loss: 1.9282965314003728

Epoch: 6| Step: 4
Training loss: 1.7798422574996948
Validation loss: 1.9578134500852196

Epoch: 6| Step: 5
Training loss: 1.9918071031570435
Validation loss: 1.9244578935766732

Epoch: 6| Step: 6
Training loss: 1.7102665901184082
Validation loss: 1.9090056675736622

Epoch: 6| Step: 7
Training loss: 1.51680326461792
Validation loss: 1.84528515672171

Epoch: 6| Step: 8
Training loss: 1.82844877243042
Validation loss: 1.925903752285947

Epoch: 6| Step: 9
Training loss: 1.629765272140503
Validation loss: 1.959708018969464

Epoch: 6| Step: 10
Training loss: 1.409208059310913
Validation loss: 1.918909949641074

Epoch: 6| Step: 11
Training loss: 1.9696083068847656
Validation loss: 1.9040687763562767

Epoch: 6| Step: 12
Training loss: 1.226707100868225
Validation loss: 1.9324822682206348

Epoch: 6| Step: 13
Training loss: 2.120252847671509
Validation loss: 1.9184116701925955

Epoch: 261| Step: 0
Training loss: 1.6479097604751587
Validation loss: 1.9849510641508206

Epoch: 6| Step: 1
Training loss: 1.4590256214141846
Validation loss: 1.9556734010737429

Epoch: 6| Step: 2
Training loss: 1.8039616346359253
Validation loss: 1.9159420933774722

Epoch: 6| Step: 3
Training loss: 1.9276944398880005
Validation loss: 1.9500994464402557

Epoch: 6| Step: 4
Training loss: 1.33174729347229
Validation loss: 1.8657403710067912

Epoch: 6| Step: 5
Training loss: 1.4161462783813477
Validation loss: 1.898200087649848

Epoch: 6| Step: 6
Training loss: 1.9400383234024048
Validation loss: 1.967586523743086

Epoch: 6| Step: 7
Training loss: 1.5149798393249512
Validation loss: 2.0406962876678794

Epoch: 6| Step: 8
Training loss: 2.1126251220703125
Validation loss: 1.9207193441288446

Epoch: 6| Step: 9
Training loss: 1.8098303079605103
Validation loss: 1.9812207145075644

Epoch: 6| Step: 10
Training loss: 1.2415916919708252
Validation loss: 2.0127687390132616

Epoch: 6| Step: 11
Training loss: 2.294081211090088
Validation loss: 1.9060730882870254

Epoch: 6| Step: 12
Training loss: 1.8080739974975586
Validation loss: 1.9968395156245078

Epoch: 6| Step: 13
Training loss: 1.305988073348999
Validation loss: 2.0635180306690994

Epoch: 262| Step: 0
Training loss: 1.701215147972107
Validation loss: 2.006511466477507

Epoch: 6| Step: 1
Training loss: 1.3007800579071045
Validation loss: 1.9805569956379552

Epoch: 6| Step: 2
Training loss: 1.8684415817260742
Validation loss: 2.034146208916941

Epoch: 6| Step: 3
Training loss: 1.4648888111114502
Validation loss: 2.0597383565800165

Epoch: 6| Step: 4
Training loss: 2.183896064758301
Validation loss: 2.0058702243271695

Epoch: 6| Step: 5
Training loss: 1.966683268547058
Validation loss: 1.989873060616114

Epoch: 6| Step: 6
Training loss: 1.8958078622817993
Validation loss: 1.9229903733858498

Epoch: 6| Step: 7
Training loss: 2.1759538650512695
Validation loss: 1.9719263148564163

Epoch: 6| Step: 8
Training loss: 1.7316033840179443
Validation loss: 1.953376571337382

Epoch: 6| Step: 9
Training loss: 1.4616810083389282
Validation loss: 1.9804418010096396

Epoch: 6| Step: 10
Training loss: 2.5171642303466797
Validation loss: 2.0090910824396278

Epoch: 6| Step: 11
Training loss: 1.9346258640289307
Validation loss: 1.9353184033465642

Epoch: 6| Step: 12
Training loss: 0.8914927244186401
Validation loss: 1.9265225574534426

Epoch: 6| Step: 13
Training loss: 1.5820388793945312
Validation loss: 1.8934329812244703

Epoch: 263| Step: 0
Training loss: 1.6102323532104492
Validation loss: 1.9281906363784627

Epoch: 6| Step: 1
Training loss: 1.1103392839431763
Validation loss: 1.9546243042074225

Epoch: 6| Step: 2
Training loss: 1.7052714824676514
Validation loss: 1.9249371379934332

Epoch: 6| Step: 3
Training loss: 1.8753528594970703
Validation loss: 1.8773083302282518

Epoch: 6| Step: 4
Training loss: 1.5823304653167725
Validation loss: 1.9381976153260918

Epoch: 6| Step: 5
Training loss: 2.450608253479004
Validation loss: 1.997098122873614

Epoch: 6| Step: 6
Training loss: 1.715305209159851
Validation loss: 1.9782250978613412

Epoch: 6| Step: 7
Training loss: 1.956490159034729
Validation loss: 1.884630339120024

Epoch: 6| Step: 8
Training loss: 1.6298699378967285
Validation loss: 1.8841674635487218

Epoch: 6| Step: 9
Training loss: 1.03465735912323
Validation loss: 1.9486908143566501

Epoch: 6| Step: 10
Training loss: 1.6141142845153809
Validation loss: 1.9371454613183134

Epoch: 6| Step: 11
Training loss: 1.4940185546875
Validation loss: 1.9870046979637557

Epoch: 6| Step: 12
Training loss: 1.3453376293182373
Validation loss: 1.9751382925177132

Epoch: 6| Step: 13
Training loss: 2.066629648208618
Validation loss: 1.9322755029124599

Epoch: 264| Step: 0
Training loss: 2.122279167175293
Validation loss: 1.9753879449700797

Epoch: 6| Step: 1
Training loss: 1.8799368143081665
Validation loss: 1.9627614687847834

Epoch: 6| Step: 2
Training loss: 1.242920160293579
Validation loss: 1.9974826702507593

Epoch: 6| Step: 3
Training loss: 1.6283495426177979
Validation loss: 1.9898731708526611

Epoch: 6| Step: 4
Training loss: 1.5512723922729492
Validation loss: 1.925877606996926

Epoch: 6| Step: 5
Training loss: 2.1890833377838135
Validation loss: 1.966885894857427

Epoch: 6| Step: 6
Training loss: 1.5678062438964844
Validation loss: 1.9350322446515482

Epoch: 6| Step: 7
Training loss: 1.3410303592681885
Validation loss: 1.9298781041176087

Epoch: 6| Step: 8
Training loss: 1.403540849685669
Validation loss: 1.9784430265426636

Epoch: 6| Step: 9
Training loss: 1.839551329612732
Validation loss: 1.9189250956299484

Epoch: 6| Step: 10
Training loss: 2.2764668464660645
Validation loss: 1.9120423909156554

Epoch: 6| Step: 11
Training loss: 1.0567623376846313
Validation loss: 1.9244808535422049

Epoch: 6| Step: 12
Training loss: 1.609690546989441
Validation loss: 1.9631700131200975

Epoch: 6| Step: 13
Training loss: 1.337802767753601
Validation loss: 1.9615847051784556

Epoch: 265| Step: 0
Training loss: 1.3138058185577393
Validation loss: 1.9752112729575044

Epoch: 6| Step: 1
Training loss: 1.740282654762268
Validation loss: 1.9173189363171976

Epoch: 6| Step: 2
Training loss: 1.4330661296844482
Validation loss: 1.9674418190474152

Epoch: 6| Step: 3
Training loss: 1.4822356700897217
Validation loss: 1.963093796084004

Epoch: 6| Step: 4
Training loss: 1.8906099796295166
Validation loss: 1.9021593550200104

Epoch: 6| Step: 5
Training loss: 1.6685025691986084
Validation loss: 1.943835098256347

Epoch: 6| Step: 6
Training loss: 2.3717198371887207
Validation loss: 2.0044807772482596

Epoch: 6| Step: 7
Training loss: 2.3331704139709473
Validation loss: 1.9343525530189596

Epoch: 6| Step: 8
Training loss: 1.7964125871658325
Validation loss: 2.024168634927401

Epoch: 6| Step: 9
Training loss: 1.4871361255645752
Validation loss: 1.9361578572180964

Epoch: 6| Step: 10
Training loss: 1.58425772190094
Validation loss: 1.91667511129892

Epoch: 6| Step: 11
Training loss: 1.6202880144119263
Validation loss: 1.9282085395628406

Epoch: 6| Step: 12
Training loss: 0.9805237054824829
Validation loss: 1.937868901478347

Epoch: 6| Step: 13
Training loss: 1.7178696393966675
Validation loss: 1.9376515239797614

Epoch: 266| Step: 0
Training loss: 1.7604951858520508
Validation loss: 1.9160606258658952

Epoch: 6| Step: 1
Training loss: 1.6296314001083374
Validation loss: 1.9576243098064134

Epoch: 6| Step: 2
Training loss: 1.2619154453277588
Validation loss: 1.9733842931767946

Epoch: 6| Step: 3
Training loss: 1.8580272197723389
Validation loss: 1.9568498801159602

Epoch: 6| Step: 4
Training loss: 1.692474603652954
Validation loss: 2.005166797227757

Epoch: 6| Step: 5
Training loss: 1.6765151023864746
Validation loss: 1.950664322863343

Epoch: 6| Step: 6
Training loss: 1.1846449375152588
Validation loss: 1.9395831554166731

Epoch: 6| Step: 7
Training loss: 1.6874651908874512
Validation loss: 1.938877595368252

Epoch: 6| Step: 8
Training loss: 1.5866724252700806
Validation loss: 1.9641471114209903

Epoch: 6| Step: 9
Training loss: 0.9784420728683472
Validation loss: 1.8989588060686666

Epoch: 6| Step: 10
Training loss: 3.387751340866089
Validation loss: 1.9693568573203137

Epoch: 6| Step: 11
Training loss: 1.5560870170593262
Validation loss: 1.9292256832122803

Epoch: 6| Step: 12
Training loss: 1.7633490562438965
Validation loss: 1.9396392004464262

Epoch: 6| Step: 13
Training loss: 0.5159028768539429
Validation loss: 1.9335903916307675

Epoch: 267| Step: 0
Training loss: 1.3750637769699097
Validation loss: 1.9666382266629128

Epoch: 6| Step: 1
Training loss: 1.372214674949646
Validation loss: 1.928785321533039

Epoch: 6| Step: 2
Training loss: 1.7175884246826172
Validation loss: 1.9813177124146493

Epoch: 6| Step: 3
Training loss: 1.9033946990966797
Validation loss: 2.0124704683980634

Epoch: 6| Step: 4
Training loss: 1.3317596912384033
Validation loss: 1.9695232132429719

Epoch: 6| Step: 5
Training loss: 1.6356985569000244
Validation loss: 1.9664713080211351

Epoch: 6| Step: 6
Training loss: 1.3856048583984375
Validation loss: 1.9643090155816847

Epoch: 6| Step: 7
Training loss: 1.8522367477416992
Validation loss: 2.0147949880169285

Epoch: 6| Step: 8
Training loss: 1.532357096672058
Validation loss: 2.0018212820893977

Epoch: 6| Step: 9
Training loss: 2.2557196617126465
Validation loss: 2.005207318131642

Epoch: 6| Step: 10
Training loss: 1.405475378036499
Validation loss: 1.9167439899136942

Epoch: 6| Step: 11
Training loss: 2.4289755821228027
Validation loss: 2.0286446194494925

Epoch: 6| Step: 12
Training loss: 1.5836114883422852
Validation loss: 1.9224630325071272

Epoch: 6| Step: 13
Training loss: 1.1985713243484497
Validation loss: 1.9366133546316495

Epoch: 268| Step: 0
Training loss: 2.20104718208313
Validation loss: 1.9104305633934595

Epoch: 6| Step: 1
Training loss: 1.6900274753570557
Validation loss: 1.9706289691309775

Epoch: 6| Step: 2
Training loss: 1.3811875581741333
Validation loss: 1.9225432013952604

Epoch: 6| Step: 3
Training loss: 1.6258904933929443
Validation loss: 1.9891667648028302

Epoch: 6| Step: 4
Training loss: 1.4413703680038452
Validation loss: 1.9723317597502021

Epoch: 6| Step: 5
Training loss: 1.8567363023757935
Validation loss: 1.8868519003673265

Epoch: 6| Step: 6
Training loss: 1.0423226356506348
Validation loss: 1.9419196203190794

Epoch: 6| Step: 7
Training loss: 1.604860782623291
Validation loss: 2.0676348824654855

Epoch: 6| Step: 8
Training loss: 1.5172430276870728
Validation loss: 2.0011547829515193

Epoch: 6| Step: 9
Training loss: 1.8771135807037354
Validation loss: 1.9687313879689863

Epoch: 6| Step: 10
Training loss: 1.2280173301696777
Validation loss: 1.9721938653658795

Epoch: 6| Step: 11
Training loss: 1.7077088356018066
Validation loss: 2.056980889330628

Epoch: 6| Step: 12
Training loss: 2.075331926345825
Validation loss: 1.8949275221875919

Epoch: 6| Step: 13
Training loss: 2.2328498363494873
Validation loss: 1.975236738881757

Epoch: 269| Step: 0
Training loss: 1.420658826828003
Validation loss: 1.9640150044554023

Epoch: 6| Step: 1
Training loss: 1.9931379556655884
Validation loss: 2.0427091557492494

Epoch: 6| Step: 2
Training loss: 1.8155689239501953
Validation loss: 2.0024537860706286

Epoch: 6| Step: 3
Training loss: 1.67872953414917
Validation loss: 2.0135178771070255

Epoch: 6| Step: 4
Training loss: 1.2263603210449219
Validation loss: 2.0294736098217707

Epoch: 6| Step: 5
Training loss: 1.86221182346344
Validation loss: 2.0133707523345947

Epoch: 6| Step: 6
Training loss: 1.9104286432266235
Validation loss: 1.9762292292810255

Epoch: 6| Step: 7
Training loss: 2.8091368675231934
Validation loss: 2.0235985658502065

Epoch: 6| Step: 8
Training loss: 1.3873822689056396
Validation loss: 1.9537956150629188

Epoch: 6| Step: 9
Training loss: 1.0773019790649414
Validation loss: 1.9186225091257403

Epoch: 6| Step: 10
Training loss: 1.3979945182800293
Validation loss: 1.9331776583066551

Epoch: 6| Step: 11
Training loss: 1.323101282119751
Validation loss: 1.9683186687448972

Epoch: 6| Step: 12
Training loss: 1.423520803451538
Validation loss: 1.9723067950176936

Epoch: 6| Step: 13
Training loss: 1.6477398872375488
Validation loss: 1.9832368230306974

Epoch: 270| Step: 0
Training loss: 1.0003808736801147
Validation loss: 2.0293754941673687

Epoch: 6| Step: 1
Training loss: 1.5718400478363037
Validation loss: 1.99575819764086

Epoch: 6| Step: 2
Training loss: 1.431666612625122
Validation loss: 1.981328619423733

Epoch: 6| Step: 3
Training loss: 1.209942102432251
Validation loss: 2.0147830875970985

Epoch: 6| Step: 4
Training loss: 1.9760746955871582
Validation loss: 1.948874036471049

Epoch: 6| Step: 5
Training loss: 1.1442316770553589
Validation loss: 1.8995331487348002

Epoch: 6| Step: 6
Training loss: 1.5749397277832031
Validation loss: 1.9291904831445346

Epoch: 6| Step: 7
Training loss: 2.244560480117798
Validation loss: 2.010835564264687

Epoch: 6| Step: 8
Training loss: 1.6419241428375244
Validation loss: 1.9139637998355332

Epoch: 6| Step: 9
Training loss: 1.821624755859375
Validation loss: 1.955777939929757

Epoch: 6| Step: 10
Training loss: 1.638188362121582
Validation loss: 1.9816163419395365

Epoch: 6| Step: 11
Training loss: 1.942046046257019
Validation loss: 1.950512719410722

Epoch: 6| Step: 12
Training loss: 1.73250412940979
Validation loss: 1.9918959666323919

Epoch: 6| Step: 13
Training loss: 2.2645788192749023
Validation loss: 1.9568403279909523

Epoch: 271| Step: 0
Training loss: 1.2173274755477905
Validation loss: 1.8674042442793488

Epoch: 6| Step: 1
Training loss: 1.9416272640228271
Validation loss: 1.908938543770903

Epoch: 6| Step: 2
Training loss: 1.1636803150177002
Validation loss: 1.9463916414527482

Epoch: 6| Step: 3
Training loss: 1.9879204034805298
Validation loss: 1.919750718660252

Epoch: 6| Step: 4
Training loss: 1.2104806900024414
Validation loss: 1.8970101187306065

Epoch: 6| Step: 5
Training loss: 1.4060237407684326
Validation loss: 1.8840628926471998

Epoch: 6| Step: 6
Training loss: 1.8394901752471924
Validation loss: 1.903668543343903

Epoch: 6| Step: 7
Training loss: 1.368104100227356
Validation loss: 1.9298621634001374

Epoch: 6| Step: 8
Training loss: 1.8239946365356445
Validation loss: 1.9073007991237025

Epoch: 6| Step: 9
Training loss: 1.646167516708374
Validation loss: 1.9360655725643199

Epoch: 6| Step: 10
Training loss: 1.8196450471878052
Validation loss: 1.9254213789457917

Epoch: 6| Step: 11
Training loss: 1.5308237075805664
Validation loss: 1.8878927320562384

Epoch: 6| Step: 12
Training loss: 2.019162654876709
Validation loss: 1.9764777819315593

Epoch: 6| Step: 13
Training loss: 2.0492584705352783
Validation loss: 2.008466805181196

Epoch: 272| Step: 0
Training loss: 1.7538410425186157
Validation loss: 1.8304805601796796

Epoch: 6| Step: 1
Training loss: 1.5949591398239136
Validation loss: 1.9727865111443303

Epoch: 6| Step: 2
Training loss: 1.7479870319366455
Validation loss: 1.9845862542429278

Epoch: 6| Step: 3
Training loss: 1.458894968032837
Validation loss: 1.9318510396506197

Epoch: 6| Step: 4
Training loss: 1.9926013946533203
Validation loss: 1.9823548306701004

Epoch: 6| Step: 5
Training loss: 1.4476162195205688
Validation loss: 1.9539714090285762

Epoch: 6| Step: 6
Training loss: 1.3916295766830444
Validation loss: 2.032960763541601

Epoch: 6| Step: 7
Training loss: 1.6786329746246338
Validation loss: 1.9380194166655182

Epoch: 6| Step: 8
Training loss: 1.4862908124923706
Validation loss: 1.9854966799418132

Epoch: 6| Step: 9
Training loss: 1.684753656387329
Validation loss: 2.0527116816530944

Epoch: 6| Step: 10
Training loss: 1.8920798301696777
Validation loss: 2.028614103153188

Epoch: 6| Step: 11
Training loss: 1.2364729642868042
Validation loss: 1.968141487849656

Epoch: 6| Step: 12
Training loss: 2.021589756011963
Validation loss: 1.9390012013014926

Epoch: 6| Step: 13
Training loss: 1.9788153171539307
Validation loss: 1.933637063990357

Epoch: 273| Step: 0
Training loss: 1.6834577322006226
Validation loss: 1.9305196782594085

Epoch: 6| Step: 1
Training loss: 1.754028081893921
Validation loss: 1.9459501568989088

Epoch: 6| Step: 2
Training loss: 2.0951967239379883
Validation loss: 1.9484308688871321

Epoch: 6| Step: 3
Training loss: 2.040032148361206
Validation loss: 1.96396138206605

Epoch: 6| Step: 4
Training loss: 2.008485794067383
Validation loss: 1.9220046638160624

Epoch: 6| Step: 5
Training loss: 1.426063060760498
Validation loss: 1.9249541631308935

Epoch: 6| Step: 6
Training loss: 1.8135111331939697
Validation loss: 1.9879992123573058

Epoch: 6| Step: 7
Training loss: 1.393357515335083
Validation loss: 1.9144186589025682

Epoch: 6| Step: 8
Training loss: 1.4240105152130127
Validation loss: 1.861970273397302

Epoch: 6| Step: 9
Training loss: 1.589111089706421
Validation loss: 1.9498869270406745

Epoch: 6| Step: 10
Training loss: 1.9680944681167603
Validation loss: 1.8691776362798547

Epoch: 6| Step: 11
Training loss: 1.1351608037948608
Validation loss: 1.9750063265523603

Epoch: 6| Step: 12
Training loss: 1.3996667861938477
Validation loss: 1.9497743050257366

Epoch: 6| Step: 13
Training loss: 1.6904650926589966
Validation loss: 2.009025812149048

Epoch: 274| Step: 0
Training loss: 1.4549732208251953
Validation loss: 2.007328587193643

Epoch: 6| Step: 1
Training loss: 1.3862899541854858
Validation loss: 1.8984777158306492

Epoch: 6| Step: 2
Training loss: 1.498465895652771
Validation loss: 1.9419640392385504

Epoch: 6| Step: 3
Training loss: 1.7299374341964722
Validation loss: 1.9323211485339749

Epoch: 6| Step: 4
Training loss: 1.1831355094909668
Validation loss: 1.983182539222061

Epoch: 6| Step: 5
Training loss: 1.383550763130188
Validation loss: 2.02997528224863

Epoch: 6| Step: 6
Training loss: 1.6227645874023438
Validation loss: 1.9229497883909492

Epoch: 6| Step: 7
Training loss: 1.9112310409545898
Validation loss: 1.9568930056787306

Epoch: 6| Step: 8
Training loss: 1.9787570238113403
Validation loss: 1.9894035785428938

Epoch: 6| Step: 9
Training loss: 1.3991358280181885
Validation loss: 1.9549040820008965

Epoch: 6| Step: 10
Training loss: 1.9469454288482666
Validation loss: 1.9117761965720885

Epoch: 6| Step: 11
Training loss: 2.354668617248535
Validation loss: 1.9417592069154144

Epoch: 6| Step: 12
Training loss: 1.0013540983200073
Validation loss: 1.8995071380369124

Epoch: 6| Step: 13
Training loss: 2.2899560928344727
Validation loss: 1.9422852441828737

Epoch: 275| Step: 0
Training loss: 1.5542123317718506
Validation loss: 1.9626730257464993

Epoch: 6| Step: 1
Training loss: 1.0300666093826294
Validation loss: 1.935881172457049

Epoch: 6| Step: 2
Training loss: 1.7195082902908325
Validation loss: 1.917209271461733

Epoch: 6| Step: 3
Training loss: 2.0083022117614746
Validation loss: 2.00149114670292

Epoch: 6| Step: 4
Training loss: 1.7880572080612183
Validation loss: 1.8918885877055507

Epoch: 6| Step: 5
Training loss: 1.9320480823516846
Validation loss: 2.012379865492544

Epoch: 6| Step: 6
Training loss: 1.5760082006454468
Validation loss: 1.9616319851208759

Epoch: 6| Step: 7
Training loss: 1.4706201553344727
Validation loss: 1.9184519219142135

Epoch: 6| Step: 8
Training loss: 1.371063470840454
Validation loss: 1.8746749906129734

Epoch: 6| Step: 9
Training loss: 1.271024227142334
Validation loss: 1.943006060456717

Epoch: 6| Step: 10
Training loss: 1.937333583831787
Validation loss: 1.960788175623904

Epoch: 6| Step: 11
Training loss: 1.7729947566986084
Validation loss: 2.0225725173950195

Epoch: 6| Step: 12
Training loss: 1.5795481204986572
Validation loss: 1.9261633529457995

Epoch: 6| Step: 13
Training loss: 1.6350661516189575
Validation loss: 1.9125968922850907

Epoch: 276| Step: 0
Training loss: 1.4597856998443604
Validation loss: 1.951603328028033

Epoch: 6| Step: 1
Training loss: 1.5876438617706299
Validation loss: 1.886473555718699

Epoch: 6| Step: 2
Training loss: 1.309743046760559
Validation loss: 1.9421302477518718

Epoch: 6| Step: 3
Training loss: 1.4604493379592896
Validation loss: 1.8893265108908377

Epoch: 6| Step: 4
Training loss: 1.960042953491211
Validation loss: 1.9767568906148274

Epoch: 6| Step: 5
Training loss: 1.954239010810852
Validation loss: 1.9077050749973585

Epoch: 6| Step: 6
Training loss: 1.5464515686035156
Validation loss: 1.9560397594205794

Epoch: 6| Step: 7
Training loss: 2.193179130554199
Validation loss: 1.889634855331913

Epoch: 6| Step: 8
Training loss: 0.9863076210021973
Validation loss: 1.9820673978456886

Epoch: 6| Step: 9
Training loss: 1.9883546829223633
Validation loss: 1.9487284562921012

Epoch: 6| Step: 10
Training loss: 1.6517282724380493
Validation loss: 2.011936564599314

Epoch: 6| Step: 11
Training loss: 0.9717553853988647
Validation loss: 1.9221104588559879

Epoch: 6| Step: 12
Training loss: 2.0306448936462402
Validation loss: 1.9031329180604668

Epoch: 6| Step: 13
Training loss: 2.388235330581665
Validation loss: 1.8879137564730901

Epoch: 277| Step: 0
Training loss: 1.3933179378509521
Validation loss: 1.9384918148799608

Epoch: 6| Step: 1
Training loss: 1.7521196603775024
Validation loss: 1.8778998621048466

Epoch: 6| Step: 2
Training loss: 1.0613471269607544
Validation loss: 1.913006833804551

Epoch: 6| Step: 3
Training loss: 1.4475476741790771
Validation loss: 1.909829956229015

Epoch: 6| Step: 4
Training loss: 1.1914376020431519
Validation loss: 1.8933271925936463

Epoch: 6| Step: 5
Training loss: 1.3755079507827759
Validation loss: 1.9861487175828667

Epoch: 6| Step: 6
Training loss: 1.6509065628051758
Validation loss: 1.9414889069013699

Epoch: 6| Step: 7
Training loss: 1.4608465433120728
Validation loss: 1.9511740041035477

Epoch: 6| Step: 8
Training loss: 2.563748359680176
Validation loss: 1.928559939066569

Epoch: 6| Step: 9
Training loss: 1.9026345014572144
Validation loss: 1.924847512475906

Epoch: 6| Step: 10
Training loss: 1.2405552864074707
Validation loss: 1.9294683164165867

Epoch: 6| Step: 11
Training loss: 1.791045069694519
Validation loss: 1.9234250258373957

Epoch: 6| Step: 12
Training loss: 2.301889657974243
Validation loss: 1.9580152637215071

Epoch: 6| Step: 13
Training loss: 1.3565998077392578
Validation loss: 1.8871843097030476

Epoch: 278| Step: 0
Training loss: 2.6720571517944336
Validation loss: 1.968867301940918

Epoch: 6| Step: 1
Training loss: 1.0703563690185547
Validation loss: 1.9026489924359065

Epoch: 6| Step: 2
Training loss: 1.5894086360931396
Validation loss: 1.9634103531478553

Epoch: 6| Step: 3
Training loss: 2.2838590145111084
Validation loss: 1.9420104283158497

Epoch: 6| Step: 4
Training loss: 1.197134017944336
Validation loss: 1.8767418425570253

Epoch: 6| Step: 5
Training loss: 1.8088868856430054
Validation loss: 1.9957076400838873

Epoch: 6| Step: 6
Training loss: 1.5029692649841309
Validation loss: 1.9712027106233823

Epoch: 6| Step: 7
Training loss: 1.8350205421447754
Validation loss: 1.9322008035516227

Epoch: 6| Step: 8
Training loss: 1.241722822189331
Validation loss: 1.9238444925636373

Epoch: 6| Step: 9
Training loss: 1.328561544418335
Validation loss: 1.9342057166561004

Epoch: 6| Step: 10
Training loss: 1.6130526065826416
Validation loss: 1.9707163790220856

Epoch: 6| Step: 11
Training loss: 1.7152156829833984
Validation loss: 1.9198301710108274

Epoch: 6| Step: 12
Training loss: 1.3541300296783447
Validation loss: 1.9532223593804143

Epoch: 6| Step: 13
Training loss: 1.851401448249817
Validation loss: 1.9908962762483986

Epoch: 279| Step: 0
Training loss: 1.05232834815979
Validation loss: 1.9174943277912755

Epoch: 6| Step: 1
Training loss: 1.882943034172058
Validation loss: 1.9775364091319423

Epoch: 6| Step: 2
Training loss: 1.7946922779083252
Validation loss: 1.95791043004682

Epoch: 6| Step: 3
Training loss: 1.3330789804458618
Validation loss: 2.006160984757126

Epoch: 6| Step: 4
Training loss: 1.6199965476989746
Validation loss: 1.9805896653923938

Epoch: 6| Step: 5
Training loss: 2.222425937652588
Validation loss: 1.9119950135548909

Epoch: 6| Step: 6
Training loss: 1.5819485187530518
Validation loss: 1.9383282661437988

Epoch: 6| Step: 7
Training loss: 1.461203932762146
Validation loss: 1.8950434935990201

Epoch: 6| Step: 8
Training loss: 1.4270639419555664
Validation loss: 1.9498702902947702

Epoch: 6| Step: 9
Training loss: 1.7474687099456787
Validation loss: 1.95086032600813

Epoch: 6| Step: 10
Training loss: 1.236069917678833
Validation loss: 1.9177867930422547

Epoch: 6| Step: 11
Training loss: 2.2080743312835693
Validation loss: 1.9606243205326859

Epoch: 6| Step: 12
Training loss: 1.9457025527954102
Validation loss: 1.9069463027420865

Epoch: 6| Step: 13
Training loss: 1.292757272720337
Validation loss: 1.9896500777172785

Epoch: 280| Step: 0
Training loss: 1.13100004196167
Validation loss: 1.983683083647041

Epoch: 6| Step: 1
Training loss: 1.7614288330078125
Validation loss: 1.9928305661806496

Epoch: 6| Step: 2
Training loss: 2.1101980209350586
Validation loss: 1.9546808978562713

Epoch: 6| Step: 3
Training loss: 1.890510082244873
Validation loss: 2.011129626663782

Epoch: 6| Step: 4
Training loss: 1.6817209720611572
Validation loss: 1.9350523307759275

Epoch: 6| Step: 5
Training loss: 1.1230356693267822
Validation loss: 1.9757267775074128

Epoch: 6| Step: 6
Training loss: 1.3522124290466309
Validation loss: 1.9932113949970534

Epoch: 6| Step: 7
Training loss: 2.0450117588043213
Validation loss: 2.021465192558945

Epoch: 6| Step: 8
Training loss: 1.357229232788086
Validation loss: 1.9487271795990646

Epoch: 6| Step: 9
Training loss: 1.6946675777435303
Validation loss: 1.931637284576252

Epoch: 6| Step: 10
Training loss: 1.4410841464996338
Validation loss: 1.9927639961242676

Epoch: 6| Step: 11
Training loss: 1.5046443939208984
Validation loss: 1.9807653721942697

Epoch: 6| Step: 12
Training loss: 1.6991480588912964
Validation loss: 1.8919327182154502

Epoch: 6| Step: 13
Training loss: 1.2829241752624512
Validation loss: 1.916370427736672

Epoch: 281| Step: 0
Training loss: 1.61106276512146
Validation loss: 1.8687581157171598

Epoch: 6| Step: 1
Training loss: 2.68044114112854
Validation loss: 1.9149309050652288

Epoch: 6| Step: 2
Training loss: 1.1970100402832031
Validation loss: 1.9448550567832044

Epoch: 6| Step: 3
Training loss: 1.613572597503662
Validation loss: 1.928716000690255

Epoch: 6| Step: 4
Training loss: 1.8172597885131836
Validation loss: 1.9157362663617699

Epoch: 6| Step: 5
Training loss: 1.7426753044128418
Validation loss: 1.873815223734866

Epoch: 6| Step: 6
Training loss: 1.5761809349060059
Validation loss: 1.9978967417952835

Epoch: 6| Step: 7
Training loss: 1.8691937923431396
Validation loss: 1.8918334848137313

Epoch: 6| Step: 8
Training loss: 1.4783310890197754
Validation loss: 2.0151667979455765

Epoch: 6| Step: 9
Training loss: 1.2367122173309326
Validation loss: 1.987499031969296

Epoch: 6| Step: 10
Training loss: 1.655099630355835
Validation loss: 1.9386505375626266

Epoch: 6| Step: 11
Training loss: 1.386479139328003
Validation loss: 1.9508919869699786

Epoch: 6| Step: 12
Training loss: 1.6901772022247314
Validation loss: 1.9860774381186372

Epoch: 6| Step: 13
Training loss: 1.7313679456710815
Validation loss: 1.9724405042586788

Epoch: 282| Step: 0
Training loss: 1.2504374980926514
Validation loss: 1.9458201034094698

Epoch: 6| Step: 1
Training loss: 1.9209895133972168
Validation loss: 1.9978356861299085

Epoch: 6| Step: 2
Training loss: 1.727332353591919
Validation loss: 1.9047078150574879

Epoch: 6| Step: 3
Training loss: 1.384547233581543
Validation loss: 1.8791211164125832

Epoch: 6| Step: 4
Training loss: 1.9627320766448975
Validation loss: 1.9556967981400029

Epoch: 6| Step: 5
Training loss: 1.834585189819336
Validation loss: 1.9279074104883338

Epoch: 6| Step: 6
Training loss: 1.7237567901611328
Validation loss: 1.916236594159116

Epoch: 6| Step: 7
Training loss: 1.8874263763427734
Validation loss: 1.9938607510700022

Epoch: 6| Step: 8
Training loss: 1.2649660110473633
Validation loss: 1.9584689371047481

Epoch: 6| Step: 9
Training loss: 1.7044780254364014
Validation loss: 1.960938681838333

Epoch: 6| Step: 10
Training loss: 1.8050246238708496
Validation loss: 1.9336116929208078

Epoch: 6| Step: 11
Training loss: 1.1061584949493408
Validation loss: 1.919109445746227

Epoch: 6| Step: 12
Training loss: 1.454056739807129
Validation loss: 2.035512057683801

Epoch: 6| Step: 13
Training loss: 1.43190598487854
Validation loss: 1.960743155530704

Epoch: 283| Step: 0
Training loss: 1.3980097770690918
Validation loss: 1.9198063112074328

Epoch: 6| Step: 1
Training loss: 1.9146490097045898
Validation loss: 1.8999953885232248

Epoch: 6| Step: 2
Training loss: 1.8528831005096436
Validation loss: 2.012295328160768

Epoch: 6| Step: 3
Training loss: 1.2890907526016235
Validation loss: 1.9006211552568661

Epoch: 6| Step: 4
Training loss: 2.0621864795684814
Validation loss: 1.934387066031015

Epoch: 6| Step: 5
Training loss: 2.4649710655212402
Validation loss: 1.8583022035578245

Epoch: 6| Step: 6
Training loss: 1.724400520324707
Validation loss: 1.961890774388467

Epoch: 6| Step: 7
Training loss: 1.2870861291885376
Validation loss: 1.9779855038530083

Epoch: 6| Step: 8
Training loss: 1.064292550086975
Validation loss: 1.9686810034577564

Epoch: 6| Step: 9
Training loss: 1.7587471008300781
Validation loss: 1.9617137934571953

Epoch: 6| Step: 10
Training loss: 1.5543123483657837
Validation loss: 2.0649438929814163

Epoch: 6| Step: 11
Training loss: 1.7122504711151123
Validation loss: 1.9318167022479478

Epoch: 6| Step: 12
Training loss: 1.379657506942749
Validation loss: 1.9367737898262598

Epoch: 6| Step: 13
Training loss: 1.425740122795105
Validation loss: 1.8933687248537618

Epoch: 284| Step: 0
Training loss: 1.6844074726104736
Validation loss: 1.933019458606679

Epoch: 6| Step: 1
Training loss: 1.7635152339935303
Validation loss: 1.9252758705487816

Epoch: 6| Step: 2
Training loss: 1.7315449714660645
Validation loss: 2.0215134441211657

Epoch: 6| Step: 3
Training loss: 1.2444349527359009
Validation loss: 1.9227916220183014

Epoch: 6| Step: 4
Training loss: 1.4830987453460693
Validation loss: 1.9213369738671087

Epoch: 6| Step: 5
Training loss: 1.8901617527008057
Validation loss: 1.9573128569510676

Epoch: 6| Step: 6
Training loss: 0.9436128735542297
Validation loss: 1.937050542523784

Epoch: 6| Step: 7
Training loss: 2.0798134803771973
Validation loss: 1.9665484761679044

Epoch: 6| Step: 8
Training loss: 1.7026277780532837
Validation loss: 1.9484791832585489

Epoch: 6| Step: 9
Training loss: 1.6154098510742188
Validation loss: 1.9535493735344178

Epoch: 6| Step: 10
Training loss: 1.2837672233581543
Validation loss: 1.9635514187556442

Epoch: 6| Step: 11
Training loss: 2.5845577716827393
Validation loss: 1.9589454563715125

Epoch: 6| Step: 12
Training loss: 1.5163295269012451
Validation loss: 1.9908746852669665

Epoch: 6| Step: 13
Training loss: 0.9211386442184448
Validation loss: 1.9654613130836076

Epoch: 285| Step: 0
Training loss: 2.0442113876342773
Validation loss: 1.9352001259403844

Epoch: 6| Step: 1
Training loss: 1.3625624179840088
Validation loss: 1.9902149297857796

Epoch: 6| Step: 2
Training loss: 2.268075704574585
Validation loss: 1.9651113710095804

Epoch: 6| Step: 3
Training loss: 1.9226454496383667
Validation loss: 1.943952287397077

Epoch: 6| Step: 4
Training loss: 0.8545138239860535
Validation loss: 1.9053728785566104

Epoch: 6| Step: 5
Training loss: 1.318930745124817
Validation loss: 1.934043445894795

Epoch: 6| Step: 6
Training loss: 1.237603783607483
Validation loss: 1.9087699754263765

Epoch: 6| Step: 7
Training loss: 1.611236572265625
Validation loss: 1.9434027594904746

Epoch: 6| Step: 8
Training loss: 2.236060619354248
Validation loss: 1.9253891373193392

Epoch: 6| Step: 9
Training loss: 1.0056774616241455
Validation loss: 1.9577853961657452

Epoch: 6| Step: 10
Training loss: 1.299518346786499
Validation loss: 1.9397316466095627

Epoch: 6| Step: 11
Training loss: 1.9271845817565918
Validation loss: 1.9681480610242454

Epoch: 6| Step: 12
Training loss: 1.8924528360366821
Validation loss: 1.9368970727407804

Epoch: 6| Step: 13
Training loss: 1.6603516340255737
Validation loss: 1.8776436544233752

Epoch: 286| Step: 0
Training loss: 1.793691635131836
Validation loss: 1.9845905893592424

Epoch: 6| Step: 1
Training loss: 1.439371943473816
Validation loss: 1.9597675620868642

Epoch: 6| Step: 2
Training loss: 1.8650901317596436
Validation loss: 1.9159129768289545

Epoch: 6| Step: 3
Training loss: 1.2685730457305908
Validation loss: 1.8987126734948927

Epoch: 6| Step: 4
Training loss: 1.230412483215332
Validation loss: 1.9259795604213592

Epoch: 6| Step: 5
Training loss: 2.0414843559265137
Validation loss: 1.9019375808777348

Epoch: 6| Step: 6
Training loss: 2.3417022228240967
Validation loss: 1.9291493969578897

Epoch: 6| Step: 7
Training loss: 1.6947641372680664
Validation loss: 2.003027380153697

Epoch: 6| Step: 8
Training loss: 1.3691189289093018
Validation loss: 1.9454399667760378

Epoch: 6| Step: 9
Training loss: 1.718604564666748
Validation loss: 1.9849259545726161

Epoch: 6| Step: 10
Training loss: 1.4603538513183594
Validation loss: 1.990469903074285

Epoch: 6| Step: 11
Training loss: 1.6551716327667236
Validation loss: 1.9122154123039656

Epoch: 6| Step: 12
Training loss: 1.366801381111145
Validation loss: 2.0019108223658737

Epoch: 6| Step: 13
Training loss: 2.242117166519165
Validation loss: 1.9295548059607064

Epoch: 287| Step: 0
Training loss: 1.7850608825683594
Validation loss: 1.9408898122849003

Epoch: 6| Step: 1
Training loss: 1.5617222785949707
Validation loss: 2.0246839266951366

Epoch: 6| Step: 2
Training loss: 1.7019214630126953
Validation loss: 1.9774480327483146

Epoch: 6| Step: 3
Training loss: 1.6449918746948242
Validation loss: 1.9173136398356447

Epoch: 6| Step: 4
Training loss: 1.2897729873657227
Validation loss: 1.9194998459149433

Epoch: 6| Step: 5
Training loss: 1.6413724422454834
Validation loss: 1.9639333307102163

Epoch: 6| Step: 6
Training loss: 1.4532060623168945
Validation loss: 2.003135273533483

Epoch: 6| Step: 7
Training loss: 1.7664201259613037
Validation loss: 1.9454903320599628

Epoch: 6| Step: 8
Training loss: 1.6391782760620117
Validation loss: 1.9662572055734613

Epoch: 6| Step: 9
Training loss: 1.823896884918213
Validation loss: 1.979754404355121

Epoch: 6| Step: 10
Training loss: 2.004652976989746
Validation loss: 1.900865388172929

Epoch: 6| Step: 11
Training loss: 1.6770389080047607
Validation loss: 1.907337829630862

Epoch: 6| Step: 12
Training loss: 2.1412124633789062
Validation loss: 1.8976049461672384

Epoch: 6| Step: 13
Training loss: 0.7080613374710083
Validation loss: 1.8994198050550235

Epoch: 288| Step: 0
Training loss: 1.9196258783340454
Validation loss: 1.9866028934396722

Epoch: 6| Step: 1
Training loss: 1.510290265083313
Validation loss: 1.9252180027705368

Epoch: 6| Step: 2
Training loss: 1.8339269161224365
Validation loss: 1.9008335746744627

Epoch: 6| Step: 3
Training loss: 1.2922191619873047
Validation loss: 1.8787760849921935

Epoch: 6| Step: 4
Training loss: 1.2369744777679443
Validation loss: 1.9085615014517179

Epoch: 6| Step: 5
Training loss: 1.0132761001586914
Validation loss: 1.9767865698824647

Epoch: 6| Step: 6
Training loss: 1.2526030540466309
Validation loss: 1.9175728136493313

Epoch: 6| Step: 7
Training loss: 2.006301164627075
Validation loss: 1.9501684224733742

Epoch: 6| Step: 8
Training loss: 1.6825098991394043
Validation loss: 1.9777396366160402

Epoch: 6| Step: 9
Training loss: 1.4480326175689697
Validation loss: 1.984114122647111

Epoch: 6| Step: 10
Training loss: 1.453896403312683
Validation loss: 1.9383535756859729

Epoch: 6| Step: 11
Training loss: 2.3762998580932617
Validation loss: 1.9928140230076288

Epoch: 6| Step: 12
Training loss: 1.751461148262024
Validation loss: 1.9490272844991376

Epoch: 6| Step: 13
Training loss: 1.9145804643630981
Validation loss: 2.0047751831752

Epoch: 289| Step: 0
Training loss: 1.092990756034851
Validation loss: 1.9294768969217937

Epoch: 6| Step: 1
Training loss: 1.7797843217849731
Validation loss: 1.9431631565093994

Epoch: 6| Step: 2
Training loss: 1.3099048137664795
Validation loss: 1.9992309885640298

Epoch: 6| Step: 3
Training loss: 1.9740521907806396
Validation loss: 1.91054121909603

Epoch: 6| Step: 4
Training loss: 2.3308658599853516
Validation loss: 1.9278438719370032

Epoch: 6| Step: 5
Training loss: 1.1000670194625854
Validation loss: 1.9515563646952312

Epoch: 6| Step: 6
Training loss: 1.4272620677947998
Validation loss: 1.9871362998921385

Epoch: 6| Step: 7
Training loss: 1.599743366241455
Validation loss: 2.0531849476598922

Epoch: 6| Step: 8
Training loss: 1.2220406532287598
Validation loss: 1.9242628030879523

Epoch: 6| Step: 9
Training loss: 1.4041547775268555
Validation loss: 2.061575253804525

Epoch: 6| Step: 10
Training loss: 2.1839513778686523
Validation loss: 1.9802457978648524

Epoch: 6| Step: 11
Training loss: 1.7701365947723389
Validation loss: 1.9752892140419251

Epoch: 6| Step: 12
Training loss: 1.9290848970413208
Validation loss: 1.8849021721911687

Epoch: 6| Step: 13
Training loss: 1.5683245658874512
Validation loss: 1.959277415788302

Epoch: 290| Step: 0
Training loss: 1.9365265369415283
Validation loss: 1.9255621561440088

Epoch: 6| Step: 1
Training loss: 1.7902743816375732
Validation loss: 1.958399979017114

Epoch: 6| Step: 2
Training loss: 1.6674914360046387
Validation loss: 1.9703099573812177

Epoch: 6| Step: 3
Training loss: 1.8668467998504639
Validation loss: 1.93698924843983

Epoch: 6| Step: 4
Training loss: 1.1828522682189941
Validation loss: 1.9626190559838408

Epoch: 6| Step: 5
Training loss: 1.472215175628662
Validation loss: 1.9040206991216189

Epoch: 6| Step: 6
Training loss: 1.0084755420684814
Validation loss: 1.9271562419911867

Epoch: 6| Step: 7
Training loss: 2.091715097427368
Validation loss: 1.910472841673

Epoch: 6| Step: 8
Training loss: 1.7179479598999023
Validation loss: 1.9452902552902058

Epoch: 6| Step: 9
Training loss: 1.7051573991775513
Validation loss: 1.9725233739422214

Epoch: 6| Step: 10
Training loss: 1.0972602367401123
Validation loss: 1.9260530971711682

Epoch: 6| Step: 11
Training loss: 1.4379196166992188
Validation loss: 1.9229189003667524

Epoch: 6| Step: 12
Training loss: 1.7796440124511719
Validation loss: 1.9016764266516573

Epoch: 6| Step: 13
Training loss: 1.3179032802581787
Validation loss: 1.899004481172049

Epoch: 291| Step: 0
Training loss: 2.318357467651367
Validation loss: 1.9160492061286845

Epoch: 6| Step: 1
Training loss: 1.2845045328140259
Validation loss: 1.9569714236003097

Epoch: 6| Step: 2
Training loss: 1.3218897581100464
Validation loss: 2.0059769204867783

Epoch: 6| Step: 3
Training loss: 1.1434184312820435
Validation loss: 1.9762827375883698

Epoch: 6| Step: 4
Training loss: 1.8963963985443115
Validation loss: 1.9406732205421693

Epoch: 6| Step: 5
Training loss: 1.0347682237625122
Validation loss: 1.9846158053285332

Epoch: 6| Step: 6
Training loss: 2.118680953979492
Validation loss: 1.9991227683200632

Epoch: 6| Step: 7
Training loss: 1.6571786403656006
Validation loss: 1.948036729648549

Epoch: 6| Step: 8
Training loss: 1.254495620727539
Validation loss: 2.0169729673734276

Epoch: 6| Step: 9
Training loss: 1.3617364168167114
Validation loss: 1.9625501760872461

Epoch: 6| Step: 10
Training loss: 1.956918478012085
Validation loss: 1.9696815680432063

Epoch: 6| Step: 11
Training loss: 1.3285105228424072
Validation loss: 1.9394051746655536

Epoch: 6| Step: 12
Training loss: 1.2938997745513916
Validation loss: 1.9346256384285547

Epoch: 6| Step: 13
Training loss: 2.3076343536376953
Validation loss: 1.9339651112915368

Epoch: 292| Step: 0
Training loss: 1.3123462200164795
Validation loss: 1.9399173823736047

Epoch: 6| Step: 1
Training loss: 1.3377447128295898
Validation loss: 1.8608472372895928

Epoch: 6| Step: 2
Training loss: 1.623023271560669
Validation loss: 1.8764249881108601

Epoch: 6| Step: 3
Training loss: 0.9998070597648621
Validation loss: 1.9302251890141477

Epoch: 6| Step: 4
Training loss: 1.8944857120513916
Validation loss: 1.97720508421621

Epoch: 6| Step: 5
Training loss: 1.133132815361023
Validation loss: 1.9076054301313174

Epoch: 6| Step: 6
Training loss: 1.6838462352752686
Validation loss: 1.9234244490182528

Epoch: 6| Step: 7
Training loss: 1.8522274494171143
Validation loss: 1.94906226922107

Epoch: 6| Step: 8
Training loss: 1.4881396293640137
Validation loss: 1.8755489754420456

Epoch: 6| Step: 9
Training loss: 1.3842310905456543
Validation loss: 1.9202268200535928

Epoch: 6| Step: 10
Training loss: 2.2764596939086914
Validation loss: 1.9914767357610887

Epoch: 6| Step: 11
Training loss: 1.9477996826171875
Validation loss: 1.9220637198417418

Epoch: 6| Step: 12
Training loss: 1.1423285007476807
Validation loss: 1.9428337248422767

Epoch: 6| Step: 13
Training loss: 1.8713785409927368
Validation loss: 2.0341162784125215

Epoch: 293| Step: 0
Training loss: 2.1290488243103027
Validation loss: 1.946217051116369

Epoch: 6| Step: 1
Training loss: 1.1303478479385376
Validation loss: 1.9323522442130632

Epoch: 6| Step: 2
Training loss: 1.3148435354232788
Validation loss: 1.992759837899157

Epoch: 6| Step: 3
Training loss: 1.6328986883163452
Validation loss: 1.9950625614453388

Epoch: 6| Step: 4
Training loss: 2.143754243850708
Validation loss: 1.977074751289942

Epoch: 6| Step: 5
Training loss: 1.5416138172149658
Validation loss: 1.9606359722793743

Epoch: 6| Step: 6
Training loss: 1.503112554550171
Validation loss: 1.94612927334283

Epoch: 6| Step: 7
Training loss: 1.3645182847976685
Validation loss: 1.9573802986452657

Epoch: 6| Step: 8
Training loss: 1.7170848846435547
Validation loss: 2.000881113031859

Epoch: 6| Step: 9
Training loss: 1.7783657312393188
Validation loss: 1.9782536465634581

Epoch: 6| Step: 10
Training loss: 1.6390421390533447
Validation loss: 1.9912908410513273

Epoch: 6| Step: 11
Training loss: 1.490451693534851
Validation loss: 1.899125688819475

Epoch: 6| Step: 12
Training loss: 1.8154661655426025
Validation loss: 1.9934850264621038

Epoch: 6| Step: 13
Training loss: 1.1736891269683838
Validation loss: 1.8710949869566067

Epoch: 294| Step: 0
Training loss: 2.008078098297119
Validation loss: 1.9639777919297576

Epoch: 6| Step: 1
Training loss: 1.4138610363006592
Validation loss: 1.9030839999516804

Epoch: 6| Step: 2
Training loss: 1.527159333229065
Validation loss: 1.9202543022812053

Epoch: 6| Step: 3
Training loss: 1.4906976222991943
Validation loss: 1.9132791667856195

Epoch: 6| Step: 4
Training loss: 1.6187115907669067
Validation loss: 1.9444158987332416

Epoch: 6| Step: 5
Training loss: 1.9699959754943848
Validation loss: 1.9280285566083846

Epoch: 6| Step: 6
Training loss: 0.8852826952934265
Validation loss: 1.9697484213818786

Epoch: 6| Step: 7
Training loss: 0.8764222860336304
Validation loss: 1.9164846225451397

Epoch: 6| Step: 8
Training loss: 1.6081146001815796
Validation loss: 1.9405194149222424

Epoch: 6| Step: 9
Training loss: 2.1370155811309814
Validation loss: 1.9057657411021571

Epoch: 6| Step: 10
Training loss: 1.9421837329864502
Validation loss: 1.8934170276887956

Epoch: 6| Step: 11
Training loss: 1.6480239629745483
Validation loss: 1.9627552429835002

Epoch: 6| Step: 12
Training loss: 1.2352491617202759
Validation loss: 1.9287381172180176

Epoch: 6| Step: 13
Training loss: 2.1423628330230713
Validation loss: 1.8858078602821595

Epoch: 295| Step: 0
Training loss: 1.2960484027862549
Validation loss: 1.962504938084592

Epoch: 6| Step: 1
Training loss: 1.5477625131607056
Validation loss: 1.9113199172481414

Epoch: 6| Step: 2
Training loss: 1.2223248481750488
Validation loss: 1.9510941672068771

Epoch: 6| Step: 3
Training loss: 1.5804274082183838
Validation loss: 1.9539214385453092

Epoch: 6| Step: 4
Training loss: 1.7130084037780762
Validation loss: 1.9303964863541305

Epoch: 6| Step: 5
Training loss: 2.1332743167877197
Validation loss: 1.9265161265609085

Epoch: 6| Step: 6
Training loss: 1.753748893737793
Validation loss: 1.9984832655998968

Epoch: 6| Step: 7
Training loss: 1.8939661979675293
Validation loss: 2.0519232134665213

Epoch: 6| Step: 8
Training loss: 1.698305606842041
Validation loss: 1.9534730180617301

Epoch: 6| Step: 9
Training loss: 1.0478262901306152
Validation loss: 2.0007207534646474

Epoch: 6| Step: 10
Training loss: 1.4998207092285156
Validation loss: 1.996382640254113

Epoch: 6| Step: 11
Training loss: 1.7212376594543457
Validation loss: 1.9131149822665798

Epoch: 6| Step: 12
Training loss: 1.5756210088729858
Validation loss: 1.9606420352894773

Epoch: 6| Step: 13
Training loss: 1.1950536966323853
Validation loss: 1.9835550297972977

Epoch: 296| Step: 0
Training loss: 1.4372212886810303
Validation loss: 1.9857221649539085

Epoch: 6| Step: 1
Training loss: 1.9000208377838135
Validation loss: 1.9766316618970645

Epoch: 6| Step: 2
Training loss: 1.177057147026062
Validation loss: 2.008342199428107

Epoch: 6| Step: 3
Training loss: 1.5776455402374268
Validation loss: 1.925036730304841

Epoch: 6| Step: 4
Training loss: 1.4173256158828735
Validation loss: 1.8968549261810959

Epoch: 6| Step: 5
Training loss: 1.8244898319244385
Validation loss: 1.983760984995032

Epoch: 6| Step: 6
Training loss: 1.520345687866211
Validation loss: 1.975172012082992

Epoch: 6| Step: 7
Training loss: 1.8339016437530518
Validation loss: 1.9567136943981212

Epoch: 6| Step: 8
Training loss: 1.301229476928711
Validation loss: 1.9840200742085774

Epoch: 6| Step: 9
Training loss: 1.6963951587677002
Validation loss: 1.9793388279535438

Epoch: 6| Step: 10
Training loss: 1.63480806350708
Validation loss: 1.9272529386704969

Epoch: 6| Step: 11
Training loss: 1.7973730564117432
Validation loss: 2.0668127408591648

Epoch: 6| Step: 12
Training loss: 1.5183894634246826
Validation loss: 1.9574175201436526

Epoch: 6| Step: 13
Training loss: 1.2749074697494507
Validation loss: 2.0520256437281126

Epoch: 297| Step: 0
Training loss: 2.050579786300659
Validation loss: 1.9224401353507914

Epoch: 6| Step: 1
Training loss: 1.8997790813446045
Validation loss: 1.9418149712265178

Epoch: 6| Step: 2
Training loss: 1.441527009010315
Validation loss: 1.9114251252143615

Epoch: 6| Step: 3
Training loss: 1.241628646850586
Validation loss: 1.9866422273779427

Epoch: 6| Step: 4
Training loss: 1.1117498874664307
Validation loss: 1.8738556702931721

Epoch: 6| Step: 5
Training loss: 1.728520154953003
Validation loss: 1.9119784601273075

Epoch: 6| Step: 6
Training loss: 1.7824649810791016
Validation loss: 1.9208341542110647

Epoch: 6| Step: 7
Training loss: 1.4393277168273926
Validation loss: 1.9680024808452976

Epoch: 6| Step: 8
Training loss: 1.278993844985962
Validation loss: 1.9825259588098014

Epoch: 6| Step: 9
Training loss: 1.336458683013916
Validation loss: 2.0014796462110294

Epoch: 6| Step: 10
Training loss: 1.7588388919830322
Validation loss: 1.887834474604617

Epoch: 6| Step: 11
Training loss: 1.3010958433151245
Validation loss: 1.9478885819835048

Epoch: 6| Step: 12
Training loss: 2.6464664936065674
Validation loss: 1.8657306483996812

Epoch: 6| Step: 13
Training loss: 1.0372440814971924
Validation loss: 2.005259060090588

Epoch: 298| Step: 0
Training loss: 1.1205775737762451
Validation loss: 1.9798942432608655

Epoch: 6| Step: 1
Training loss: 1.6570570468902588
Validation loss: 1.9011081264865013

Epoch: 6| Step: 2
Training loss: 1.435297966003418
Validation loss: 1.937773968583794

Epoch: 6| Step: 3
Training loss: 1.2408196926116943
Validation loss: 2.013341834468226

Epoch: 6| Step: 4
Training loss: 1.132614254951477
Validation loss: 1.9363842369407736

Epoch: 6| Step: 5
Training loss: 1.6713358163833618
Validation loss: 1.9669097341516966

Epoch: 6| Step: 6
Training loss: 1.7095435857772827
Validation loss: 1.9475165900363718

Epoch: 6| Step: 7
Training loss: 1.7298641204833984
Validation loss: 1.9163427481087305

Epoch: 6| Step: 8
Training loss: 1.8675410747528076
Validation loss: 1.923615106972315

Epoch: 6| Step: 9
Training loss: 1.5822196006774902
Validation loss: 1.8932132682492655

Epoch: 6| Step: 10
Training loss: 1.2598607540130615
Validation loss: 1.8875051672740648

Epoch: 6| Step: 11
Training loss: 1.7727625370025635
Validation loss: 1.9151092460078578

Epoch: 6| Step: 12
Training loss: 1.9548168182373047
Validation loss: 2.023479530888219

Epoch: 6| Step: 13
Training loss: 1.5884737968444824
Validation loss: 1.9476109166299143

Epoch: 299| Step: 0
Training loss: 1.6809043884277344
Validation loss: 1.9044667136284612

Epoch: 6| Step: 1
Training loss: 1.5799469947814941
Validation loss: 1.94255349328441

Epoch: 6| Step: 2
Training loss: 1.4578580856323242
Validation loss: 1.9829111752971527

Epoch: 6| Step: 3
Training loss: 1.2351272106170654
Validation loss: 1.9162541615065707

Epoch: 6| Step: 4
Training loss: 2.053579807281494
Validation loss: 1.8605636909443846

Epoch: 6| Step: 5
Training loss: 2.371166706085205
Validation loss: 1.8845261578918786

Epoch: 6| Step: 6
Training loss: 1.6223986148834229
Validation loss: 1.8610209111244447

Epoch: 6| Step: 7
Training loss: 1.4464653730392456
Validation loss: 1.8923188717134538

Epoch: 6| Step: 8
Training loss: 1.623579502105713
Validation loss: 1.9646230589958928

Epoch: 6| Step: 9
Training loss: 1.857418417930603
Validation loss: 1.9885216656551565

Epoch: 6| Step: 10
Training loss: 0.8557151556015015
Validation loss: 1.9781397581100464

Epoch: 6| Step: 11
Training loss: 1.0462677478790283
Validation loss: 1.9497357594069613

Epoch: 6| Step: 12
Training loss: 1.6074492931365967
Validation loss: 1.8552647713691957

Epoch: 6| Step: 13
Training loss: 1.5750808715820312
Validation loss: 2.0047615189706125

Epoch: 300| Step: 0
Training loss: 2.1266744136810303
Validation loss: 1.9314199032322052

Epoch: 6| Step: 1
Training loss: 1.5466389656066895
Validation loss: 1.9173787614350677

Epoch: 6| Step: 2
Training loss: 1.6427528858184814
Validation loss: 1.946636789588518

Epoch: 6| Step: 3
Training loss: 1.512009620666504
Validation loss: 1.8900151355292207

Epoch: 6| Step: 4
Training loss: 1.4309027194976807
Validation loss: 1.9957600588439612

Epoch: 6| Step: 5
Training loss: 1.8821524381637573
Validation loss: 1.8191264188417824

Epoch: 6| Step: 6
Training loss: 1.304282784461975
Validation loss: 1.972247996637898

Epoch: 6| Step: 7
Training loss: 1.778015375137329
Validation loss: 1.9654047501984464

Epoch: 6| Step: 8
Training loss: 1.7860933542251587
Validation loss: 1.9468315480857767

Epoch: 6| Step: 9
Training loss: 1.231960415840149
Validation loss: 1.9678033039134035

Epoch: 6| Step: 10
Training loss: 1.3653420209884644
Validation loss: 1.9977670074791036

Epoch: 6| Step: 11
Training loss: 1.4319697618484497
Validation loss: 1.9571444808795888

Epoch: 6| Step: 12
Training loss: 1.720047950744629
Validation loss: 1.9425142106189524

Epoch: 6| Step: 13
Training loss: 2.0083436965942383
Validation loss: 1.987752446564295

Epoch: 301| Step: 0
Training loss: 1.3565678596496582
Validation loss: 2.029357393582662

Epoch: 6| Step: 1
Training loss: 1.6510498523712158
Validation loss: 1.9493094336601995

Epoch: 6| Step: 2
Training loss: 1.438413381576538
Validation loss: 2.016067551028344

Epoch: 6| Step: 3
Training loss: 1.5919907093048096
Validation loss: 1.9666884509466027

Epoch: 6| Step: 4
Training loss: 2.6782500743865967
Validation loss: 1.958990135500508

Epoch: 6| Step: 5
Training loss: 1.6168181896209717
Validation loss: 1.9788746590255408

Epoch: 6| Step: 6
Training loss: 1.6583266258239746
Validation loss: 1.9903799846608152

Epoch: 6| Step: 7
Training loss: 1.5880032777786255
Validation loss: 1.928619300165484

Epoch: 6| Step: 8
Training loss: 1.815525770187378
Validation loss: 1.9953030232460267

Epoch: 6| Step: 9
Training loss: 1.0219788551330566
Validation loss: 1.9400413856711438

Epoch: 6| Step: 10
Training loss: 2.0213749408721924
Validation loss: 1.900316894695323

Epoch: 6| Step: 11
Training loss: 1.2834949493408203
Validation loss: 2.001436951339886

Epoch: 6| Step: 12
Training loss: 0.951988935470581
Validation loss: 2.028039252886208

Epoch: 6| Step: 13
Training loss: 1.1151270866394043
Validation loss: 1.9635654957063737

Epoch: 302| Step: 0
Training loss: 1.6381940841674805
Validation loss: 1.9549812745022517

Epoch: 6| Step: 1
Training loss: 1.5575323104858398
Validation loss: 1.9077208862509778

Epoch: 6| Step: 2
Training loss: 1.7221856117248535
Validation loss: 1.9913633754176479

Epoch: 6| Step: 3
Training loss: 1.5022871494293213
Validation loss: 1.9411258287327264

Epoch: 6| Step: 4
Training loss: 2.276331663131714
Validation loss: 1.9464559888326993

Epoch: 6| Step: 5
Training loss: 1.7592403888702393
Validation loss: 1.9855610375763268

Epoch: 6| Step: 6
Training loss: 1.5151126384735107
Validation loss: 1.8956243812396962

Epoch: 6| Step: 7
Training loss: 0.9151531457901001
Validation loss: 1.8562370090074436

Epoch: 6| Step: 8
Training loss: 1.534603476524353
Validation loss: 1.9462418633122598

Epoch: 6| Step: 9
Training loss: 1.4934296607971191
Validation loss: 1.9110291670727473

Epoch: 6| Step: 10
Training loss: 1.688211441040039
Validation loss: 1.9571327778600878

Epoch: 6| Step: 11
Training loss: 1.5858938694000244
Validation loss: 1.9692209292483587

Epoch: 6| Step: 12
Training loss: 1.444990873336792
Validation loss: 1.9359077740741033

Epoch: 6| Step: 13
Training loss: 1.6729377508163452
Validation loss: 1.982633726571196

Epoch: 303| Step: 0
Training loss: 1.4069576263427734
Validation loss: 1.9452701409657795

Epoch: 6| Step: 1
Training loss: 1.8187649250030518
Validation loss: 2.0222286665311424

Epoch: 6| Step: 2
Training loss: 2.012061595916748
Validation loss: 2.028948950511153

Epoch: 6| Step: 3
Training loss: 1.6019721031188965
Validation loss: 1.9418185090505948

Epoch: 6| Step: 4
Training loss: 1.445600986480713
Validation loss: 1.9876622435867146

Epoch: 6| Step: 5
Training loss: 1.0982747077941895
Validation loss: 1.987953612881322

Epoch: 6| Step: 6
Training loss: 2.423213243484497
Validation loss: 2.0393281880245415

Epoch: 6| Step: 7
Training loss: 1.6050546169281006
Validation loss: 1.9675419715143019

Epoch: 6| Step: 8
Training loss: 1.5731723308563232
Validation loss: 1.9992684561719176

Epoch: 6| Step: 9
Training loss: 0.9014268517494202
Validation loss: 1.9065539195973387

Epoch: 6| Step: 10
Training loss: 1.6689560413360596
Validation loss: 1.9039882267675092

Epoch: 6| Step: 11
Training loss: 1.451891541481018
Validation loss: 1.9565147417847828

Epoch: 6| Step: 12
Training loss: 1.3735102415084839
Validation loss: 1.9437499020689277

Epoch: 6| Step: 13
Training loss: 2.0049142837524414
Validation loss: 1.8677020367755686

Epoch: 304| Step: 0
Training loss: 1.2363317012786865
Validation loss: 1.9059724468056873

Epoch: 6| Step: 1
Training loss: 1.389904499053955
Validation loss: 1.9308653262353712

Epoch: 6| Step: 2
Training loss: 1.6781500577926636
Validation loss: 2.0045795299673594

Epoch: 6| Step: 3
Training loss: 1.5362193584442139
Validation loss: 1.9275912584797028

Epoch: 6| Step: 4
Training loss: 1.7925245761871338
Validation loss: 1.9315067222041469

Epoch: 6| Step: 5
Training loss: 1.1098674535751343
Validation loss: 1.9034047460043302

Epoch: 6| Step: 6
Training loss: 2.165001392364502
Validation loss: 1.8819272338703115

Epoch: 6| Step: 7
Training loss: 1.4890042543411255
Validation loss: 1.8991705961124872

Epoch: 6| Step: 8
Training loss: 1.673805594444275
Validation loss: 1.933413795245591

Epoch: 6| Step: 9
Training loss: 1.538640022277832
Validation loss: 1.927537420744537

Epoch: 6| Step: 10
Training loss: 1.649836540222168
Validation loss: 1.925300987817908

Epoch: 6| Step: 11
Training loss: 1.297896146774292
Validation loss: 1.9130708274020944

Epoch: 6| Step: 12
Training loss: 1.6949607133865356
Validation loss: 1.9726977015054354

Epoch: 6| Step: 13
Training loss: 1.4297975301742554
Validation loss: 1.9829086244747203

Epoch: 305| Step: 0
Training loss: 1.6675262451171875
Validation loss: 1.8881681439697102

Epoch: 6| Step: 1
Training loss: 1.3716645240783691
Validation loss: 1.9597874918291647

Epoch: 6| Step: 2
Training loss: 1.5061314105987549
Validation loss: 1.9599697000236922

Epoch: 6| Step: 3
Training loss: 1.5558838844299316
Validation loss: 2.038272255210466

Epoch: 6| Step: 4
Training loss: 1.4159302711486816
Validation loss: 2.0213993403219406

Epoch: 6| Step: 5
Training loss: 1.413356065750122
Validation loss: 1.962776586573611

Epoch: 6| Step: 6
Training loss: 1.601264476776123
Validation loss: 1.9628722565148466

Epoch: 6| Step: 7
Training loss: 1.3099944591522217
Validation loss: 1.9482391521494875

Epoch: 6| Step: 8
Training loss: 2.471043109893799
Validation loss: 1.9867202171715357

Epoch: 6| Step: 9
Training loss: 1.7712619304656982
Validation loss: 2.028367022032379

Epoch: 6| Step: 10
Training loss: 1.606504201889038
Validation loss: 1.9248103890367734

Epoch: 6| Step: 11
Training loss: 1.3657944202423096
Validation loss: 1.969697859979445

Epoch: 6| Step: 12
Training loss: 1.5045950412750244
Validation loss: 1.8967747803657287

Epoch: 6| Step: 13
Training loss: 1.6230790615081787
Validation loss: 1.8806556040240872

Epoch: 306| Step: 0
Training loss: 0.8356688022613525
Validation loss: 1.9175263194627659

Epoch: 6| Step: 1
Training loss: 1.796147346496582
Validation loss: 1.8739297902712257

Epoch: 6| Step: 2
Training loss: 1.6508111953735352
Validation loss: 1.9754830265557894

Epoch: 6| Step: 3
Training loss: 1.6204581260681152
Validation loss: 1.9577444112429054

Epoch: 6| Step: 4
Training loss: 1.1727346181869507
Validation loss: 1.9074242256020988

Epoch: 6| Step: 5
Training loss: 2.5227575302124023
Validation loss: 1.8621421731928343

Epoch: 6| Step: 6
Training loss: 1.5535147190093994
Validation loss: 1.955363094165761

Epoch: 6| Step: 7
Training loss: 1.3340922594070435
Validation loss: 1.9263710091190953

Epoch: 6| Step: 8
Training loss: 1.3217589855194092
Validation loss: 1.9248089610889394

Epoch: 6| Step: 9
Training loss: 1.6679484844207764
Validation loss: 1.9912357150867421

Epoch: 6| Step: 10
Training loss: 1.750967264175415
Validation loss: 1.922437774237766

Epoch: 6| Step: 11
Training loss: 1.549952745437622
Validation loss: 1.948000072151102

Epoch: 6| Step: 12
Training loss: 1.5035556554794312
Validation loss: 1.9687015241192234

Epoch: 6| Step: 13
Training loss: 1.1420706510543823
Validation loss: 1.8570069625813475

Epoch: 307| Step: 0
Training loss: 1.4114701747894287
Validation loss: 1.827803171450092

Epoch: 6| Step: 1
Training loss: 1.2032238245010376
Validation loss: 1.8999457731041858

Epoch: 6| Step: 2
Training loss: 1.0503934621810913
Validation loss: 2.0122906341347644

Epoch: 6| Step: 3
Training loss: 1.831137776374817
Validation loss: 1.915313886057946

Epoch: 6| Step: 4
Training loss: 1.41140878200531
Validation loss: 2.0054167611624605

Epoch: 6| Step: 5
Training loss: 1.1027719974517822
Validation loss: 1.967516915772551

Epoch: 6| Step: 6
Training loss: 1.339491367340088
Validation loss: 2.003690235076412

Epoch: 6| Step: 7
Training loss: 1.667756199836731
Validation loss: 1.8897130194530691

Epoch: 6| Step: 8
Training loss: 1.7608144283294678
Validation loss: 1.942241354655194

Epoch: 6| Step: 9
Training loss: 2.0372772216796875
Validation loss: 1.9038082835494832

Epoch: 6| Step: 10
Training loss: 1.9194172620773315
Validation loss: 1.9244503180185955

Epoch: 6| Step: 11
Training loss: 1.8006842136383057
Validation loss: 1.9287358099414456

Epoch: 6| Step: 12
Training loss: 1.0909991264343262
Validation loss: 1.9238305066221504

Epoch: 6| Step: 13
Training loss: 2.02899432182312
Validation loss: 1.9525980462310135

Epoch: 308| Step: 0
Training loss: 1.6734689474105835
Validation loss: 1.9415704043962623

Epoch: 6| Step: 1
Training loss: 2.039330005645752
Validation loss: 1.9000710172037925

Epoch: 6| Step: 2
Training loss: 1.6963304281234741
Validation loss: 1.9608182830195273

Epoch: 6| Step: 3
Training loss: 1.413796067237854
Validation loss: 1.966692279743892

Epoch: 6| Step: 4
Training loss: 1.3556220531463623
Validation loss: 2.100857562916253

Epoch: 6| Step: 5
Training loss: 1.2722827196121216
Validation loss: 1.985068327637129

Epoch: 6| Step: 6
Training loss: 2.2451155185699463
Validation loss: 2.0161172049019926

Epoch: 6| Step: 7
Training loss: 1.1970903873443604
Validation loss: 2.0323403496896066

Epoch: 6| Step: 8
Training loss: 2.035426616668701
Validation loss: 1.9943806279090144

Epoch: 6| Step: 9
Training loss: 1.2958558797836304
Validation loss: 1.9936301054493073

Epoch: 6| Step: 10
Training loss: 1.3690059185028076
Validation loss: 1.8751967978733841

Epoch: 6| Step: 11
Training loss: 1.0001686811447144
Validation loss: 1.914692207049298

Epoch: 6| Step: 12
Training loss: 1.9926046133041382
Validation loss: 1.910315764847622

Epoch: 6| Step: 13
Training loss: 1.1794193983078003
Validation loss: 1.9391407030884937

Epoch: 309| Step: 0
Training loss: 1.179151177406311
Validation loss: 1.8922230748720066

Epoch: 6| Step: 1
Training loss: 1.386689305305481
Validation loss: 2.017605468791018

Epoch: 6| Step: 2
Training loss: 1.3448575735092163
Validation loss: 1.9779678237053655

Epoch: 6| Step: 3
Training loss: 1.6865887641906738
Validation loss: 1.929059108098348

Epoch: 6| Step: 4
Training loss: 1.4928148984909058
Validation loss: 2.004254764126193

Epoch: 6| Step: 5
Training loss: 1.25921630859375
Validation loss: 1.9146490673865042

Epoch: 6| Step: 6
Training loss: 1.8954179286956787
Validation loss: 1.889723729061824

Epoch: 6| Step: 7
Training loss: 1.19293212890625
Validation loss: 2.0243573522055023

Epoch: 6| Step: 8
Training loss: 1.44260835647583
Validation loss: 1.9396665352647022

Epoch: 6| Step: 9
Training loss: 1.7818001508712769
Validation loss: 1.998569296252343

Epoch: 6| Step: 10
Training loss: 2.266223430633545
Validation loss: 1.9000995107876357

Epoch: 6| Step: 11
Training loss: 1.0775195360183716
Validation loss: 1.9293148632972472

Epoch: 6| Step: 12
Training loss: 1.8242459297180176
Validation loss: 1.9398697845397457

Epoch: 6| Step: 13
Training loss: 2.503145456314087
Validation loss: 1.9178423804621543

Epoch: 310| Step: 0
Training loss: 1.737199306488037
Validation loss: 1.9109340124232794

Epoch: 6| Step: 1
Training loss: 1.6263972520828247
Validation loss: 1.9252017569798294

Epoch: 6| Step: 2
Training loss: 1.3333128690719604
Validation loss: 1.9509360956889328

Epoch: 6| Step: 3
Training loss: 1.605161190032959
Validation loss: 1.8670411212469942

Epoch: 6| Step: 4
Training loss: 1.1839686632156372
Validation loss: 1.9937278916758876

Epoch: 6| Step: 5
Training loss: 2.0574772357940674
Validation loss: 1.9528099798387097

Epoch: 6| Step: 6
Training loss: 1.5573794841766357
Validation loss: 1.9031769075701315

Epoch: 6| Step: 7
Training loss: 1.5527054071426392
Validation loss: 1.9599578944585656

Epoch: 6| Step: 8
Training loss: 1.775818109512329
Validation loss: 1.9602693255229662

Epoch: 6| Step: 9
Training loss: 1.4498980045318604
Validation loss: 1.9438466051573395

Epoch: 6| Step: 10
Training loss: 1.4475948810577393
Validation loss: 1.9058597472406202

Epoch: 6| Step: 11
Training loss: 1.8221774101257324
Validation loss: 1.9046055911689677

Epoch: 6| Step: 12
Training loss: 1.704195499420166
Validation loss: 1.9408261596515615

Epoch: 6| Step: 13
Training loss: 0.8480284810066223
Validation loss: 2.0467577929137857

Epoch: 311| Step: 0
Training loss: 1.4672534465789795
Validation loss: 1.9271038257947533

Epoch: 6| Step: 1
Training loss: 1.3134268522262573
Validation loss: 1.946602213767267

Epoch: 6| Step: 2
Training loss: 1.0963826179504395
Validation loss: 1.877875098618128

Epoch: 6| Step: 3
Training loss: 1.156156063079834
Validation loss: 1.92538785037174

Epoch: 6| Step: 4
Training loss: 1.5718283653259277
Validation loss: 1.8775197536714616

Epoch: 6| Step: 5
Training loss: 1.7851004600524902
Validation loss: 1.92420611586622

Epoch: 6| Step: 6
Training loss: 0.9165612459182739
Validation loss: 1.986741312088505

Epoch: 6| Step: 7
Training loss: 2.028001070022583
Validation loss: 1.938798839046109

Epoch: 6| Step: 8
Training loss: 2.1846933364868164
Validation loss: 1.8663580199723602

Epoch: 6| Step: 9
Training loss: 1.5747654438018799
Validation loss: 1.9038734923126877

Epoch: 6| Step: 10
Training loss: 2.3768045902252197
Validation loss: 1.978938251413325

Epoch: 6| Step: 11
Training loss: 1.182331919670105
Validation loss: 1.9290487432992587

Epoch: 6| Step: 12
Training loss: 1.5944558382034302
Validation loss: 2.011154053031757

Epoch: 6| Step: 13
Training loss: 1.0140089988708496
Validation loss: 1.904357543555639

Epoch: 312| Step: 0
Training loss: 1.3623099327087402
Validation loss: 1.9242393342397546

Epoch: 6| Step: 1
Training loss: 1.2985107898712158
Validation loss: 1.877601824780946

Epoch: 6| Step: 2
Training loss: 1.8516182899475098
Validation loss: 1.896666693431075

Epoch: 6| Step: 3
Training loss: 1.5702893733978271
Validation loss: 1.9583716007970995

Epoch: 6| Step: 4
Training loss: 1.3679512739181519
Validation loss: 1.9362552383894562

Epoch: 6| Step: 5
Training loss: 2.107821464538574
Validation loss: 1.9599945558014737

Epoch: 6| Step: 6
Training loss: 2.1021580696105957
Validation loss: 2.0588402209743375

Epoch: 6| Step: 7
Training loss: 1.1897172927856445
Validation loss: 1.9432588495234007

Epoch: 6| Step: 8
Training loss: 1.5718588829040527
Validation loss: 1.8710615070917274

Epoch: 6| Step: 9
Training loss: 1.1337692737579346
Validation loss: 1.896256439147457

Epoch: 6| Step: 10
Training loss: 1.2871651649475098
Validation loss: 1.930813891913301

Epoch: 6| Step: 11
Training loss: 1.9641392230987549
Validation loss: 1.9568611921802643

Epoch: 6| Step: 12
Training loss: 1.5711772441864014
Validation loss: 1.9254292698316677

Epoch: 6| Step: 13
Training loss: 1.2102198600769043
Validation loss: 1.898802213771369

Epoch: 313| Step: 0
Training loss: 1.3990564346313477
Validation loss: 1.979717534075501

Epoch: 6| Step: 1
Training loss: 1.5376451015472412
Validation loss: 1.9999486912963211

Epoch: 6| Step: 2
Training loss: 1.4623842239379883
Validation loss: 1.9143794223826418

Epoch: 6| Step: 3
Training loss: 1.4096903800964355
Validation loss: 1.8912794256723056

Epoch: 6| Step: 4
Training loss: 1.352353811264038
Validation loss: 1.8567977259235997

Epoch: 6| Step: 5
Training loss: 1.6341757774353027
Validation loss: 1.8964303155099191

Epoch: 6| Step: 6
Training loss: 1.2522200345993042
Validation loss: 1.93168189320513

Epoch: 6| Step: 7
Training loss: 1.0439268350601196
Validation loss: 1.8814250628153484

Epoch: 6| Step: 8
Training loss: 1.0988539457321167
Validation loss: 1.9108934351193008

Epoch: 6| Step: 9
Training loss: 1.9495985507965088
Validation loss: 1.9602701484516103

Epoch: 6| Step: 10
Training loss: 1.4675517082214355
Validation loss: 1.9102968759434198

Epoch: 6| Step: 11
Training loss: 2.4127583503723145
Validation loss: 1.9602055113802674

Epoch: 6| Step: 12
Training loss: 1.7834210395812988
Validation loss: 1.848534095671869

Epoch: 6| Step: 13
Training loss: 1.2694411277770996
Validation loss: 1.8657028662261141

Epoch: 314| Step: 0
Training loss: 1.917961835861206
Validation loss: 1.9155930075594174

Epoch: 6| Step: 1
Training loss: 1.8964688777923584
Validation loss: 1.8830179193968415

Epoch: 6| Step: 2
Training loss: 1.7419672012329102
Validation loss: 1.9541261478136944

Epoch: 6| Step: 3
Training loss: 1.3797680139541626
Validation loss: 1.8759452476296374

Epoch: 6| Step: 4
Training loss: 1.9260374307632446
Validation loss: 1.9239023936692106

Epoch: 6| Step: 5
Training loss: 1.7181894779205322
Validation loss: 2.021798813214866

Epoch: 6| Step: 6
Training loss: 1.898104190826416
Validation loss: 1.8590572469977922

Epoch: 6| Step: 7
Training loss: 1.1095154285430908
Validation loss: 1.9491011340131041

Epoch: 6| Step: 8
Training loss: 1.9053173065185547
Validation loss: 1.983369396578881

Epoch: 6| Step: 9
Training loss: 1.649320125579834
Validation loss: 1.9170256532648557

Epoch: 6| Step: 10
Training loss: 1.6024470329284668
Validation loss: 1.9090085132147676

Epoch: 6| Step: 11
Training loss: 1.0665605068206787
Validation loss: 1.939117629040954

Epoch: 6| Step: 12
Training loss: 0.9364205598831177
Validation loss: 1.9504528635291642

Epoch: 6| Step: 13
Training loss: 1.1425122022628784
Validation loss: 1.9037363144659227

Epoch: 315| Step: 0
Training loss: 1.8880555629730225
Validation loss: 1.9464105226660287

Epoch: 6| Step: 1
Training loss: 1.1325997114181519
Validation loss: 1.9714635700307868

Epoch: 6| Step: 2
Training loss: 1.83076810836792
Validation loss: 1.9139325464925458

Epoch: 6| Step: 3
Training loss: 0.8429296612739563
Validation loss: 1.9514751716326642

Epoch: 6| Step: 4
Training loss: 1.297013759613037
Validation loss: 1.96693846999958

Epoch: 6| Step: 5
Training loss: 1.7588610649108887
Validation loss: 1.9735791183287097

Epoch: 6| Step: 6
Training loss: 1.8051573038101196
Validation loss: 1.848022263537171

Epoch: 6| Step: 7
Training loss: 1.8293970823287964
Validation loss: 1.8906587759653728

Epoch: 6| Step: 8
Training loss: 1.303354024887085
Validation loss: 1.9955180255315637

Epoch: 6| Step: 9
Training loss: 1.7166929244995117
Validation loss: 1.9284737366502003

Epoch: 6| Step: 10
Training loss: 1.4472728967666626
Validation loss: 1.9844945233355287

Epoch: 6| Step: 11
Training loss: 1.1579385995864868
Validation loss: 1.9779331197020829

Epoch: 6| Step: 12
Training loss: 1.9192023277282715
Validation loss: 1.921483124456098

Epoch: 6| Step: 13
Training loss: 1.4333456754684448
Validation loss: 1.9230986666935745

Epoch: 316| Step: 0
Training loss: 2.289896249771118
Validation loss: 1.9809402829857283

Epoch: 6| Step: 1
Training loss: 1.5098421573638916
Validation loss: 1.9729183373912689

Epoch: 6| Step: 2
Training loss: 1.2221218347549438
Validation loss: 1.9787707726160686

Epoch: 6| Step: 3
Training loss: 1.7226974964141846
Validation loss: 1.9605698149691346

Epoch: 6| Step: 4
Training loss: 1.4801931381225586
Validation loss: 1.9334163460680234

Epoch: 6| Step: 5
Training loss: 1.7579951286315918
Validation loss: 1.9269673670491865

Epoch: 6| Step: 6
Training loss: 1.5140129327774048
Validation loss: 1.9792816715855752

Epoch: 6| Step: 7
Training loss: 0.9633061289787292
Validation loss: 1.9519125492342058

Epoch: 6| Step: 8
Training loss: 1.5261738300323486
Validation loss: 1.9509072021771503

Epoch: 6| Step: 9
Training loss: 1.6307930946350098
Validation loss: 1.9142992317035634

Epoch: 6| Step: 10
Training loss: 1.6464905738830566
Validation loss: 2.029764131833148

Epoch: 6| Step: 11
Training loss: 1.0455491542816162
Validation loss: 1.9203025243615592

Epoch: 6| Step: 12
Training loss: 1.7949597835540771
Validation loss: 1.9201000813514955

Epoch: 6| Step: 13
Training loss: 1.1499284505844116
Validation loss: 2.037182701531277

Epoch: 317| Step: 0
Training loss: 1.700865387916565
Validation loss: 1.9754670204654816

Epoch: 6| Step: 1
Training loss: 1.381706953048706
Validation loss: 1.9519659960141746

Epoch: 6| Step: 2
Training loss: 1.8399817943572998
Validation loss: 1.8846192847016037

Epoch: 6| Step: 3
Training loss: 1.4894472360610962
Validation loss: 1.9234590645759337

Epoch: 6| Step: 4
Training loss: 1.386612057685852
Validation loss: 1.8759731708034393

Epoch: 6| Step: 5
Training loss: 1.527468204498291
Validation loss: 1.970362191559166

Epoch: 6| Step: 6
Training loss: 1.4560511112213135
Validation loss: 1.9807149364102272

Epoch: 6| Step: 7
Training loss: 1.143868088722229
Validation loss: 1.9134007320609143

Epoch: 6| Step: 8
Training loss: 1.5920166969299316
Validation loss: 1.9980422373740905

Epoch: 6| Step: 9
Training loss: 1.3724855184555054
Validation loss: 1.860428270473275

Epoch: 6| Step: 10
Training loss: 1.757559061050415
Validation loss: 1.9421763958469513

Epoch: 6| Step: 11
Training loss: 1.5851709842681885
Validation loss: 1.9454954901049215

Epoch: 6| Step: 12
Training loss: 1.6564509868621826
Validation loss: 1.8956342256197365

Epoch: 6| Step: 13
Training loss: 1.9686821699142456
Validation loss: 1.9933627356765091

Epoch: 318| Step: 0
Training loss: 1.102769374847412
Validation loss: 1.908476439855432

Epoch: 6| Step: 1
Training loss: 1.8172731399536133
Validation loss: 1.9156759323612336

Epoch: 6| Step: 2
Training loss: 1.9584581851959229
Validation loss: 1.9260365437435847

Epoch: 6| Step: 3
Training loss: 1.9751582145690918
Validation loss: 1.8953155625251032

Epoch: 6| Step: 4
Training loss: 1.6749833822250366
Validation loss: 1.9240705249130086

Epoch: 6| Step: 5
Training loss: 1.396613359451294
Validation loss: 1.9766044180880311

Epoch: 6| Step: 6
Training loss: 1.7360786199569702
Validation loss: 1.885851513954901

Epoch: 6| Step: 7
Training loss: 0.8984432220458984
Validation loss: 1.9682894957962858

Epoch: 6| Step: 8
Training loss: 1.1656882762908936
Validation loss: 1.9841800210296467

Epoch: 6| Step: 9
Training loss: 1.7480618953704834
Validation loss: 1.8718167428047425

Epoch: 6| Step: 10
Training loss: 1.390595555305481
Validation loss: 1.899318015703591

Epoch: 6| Step: 11
Training loss: 1.2151556015014648
Validation loss: 1.943681022172333

Epoch: 6| Step: 12
Training loss: 1.963266134262085
Validation loss: 1.9082421282286286

Epoch: 6| Step: 13
Training loss: 1.2967325448989868
Validation loss: 1.9349572773902648

Epoch: 319| Step: 0
Training loss: 1.1859748363494873
Validation loss: 1.8996813835636261

Epoch: 6| Step: 1
Training loss: 1.6968674659729004
Validation loss: 1.9363492817007086

Epoch: 6| Step: 2
Training loss: 1.322170376777649
Validation loss: 1.9082977387212938

Epoch: 6| Step: 3
Training loss: 1.5788308382034302
Validation loss: 1.8540426402963617

Epoch: 6| Step: 4
Training loss: 1.3334423303604126
Validation loss: 1.9673158866102978

Epoch: 6| Step: 5
Training loss: 1.704535722732544
Validation loss: 1.9199247411502305

Epoch: 6| Step: 6
Training loss: 1.4407576322555542
Validation loss: 1.9623426006686302

Epoch: 6| Step: 7
Training loss: 1.7475199699401855
Validation loss: 1.9016350956373318

Epoch: 6| Step: 8
Training loss: 1.9442986249923706
Validation loss: 1.9576168252575783

Epoch: 6| Step: 9
Training loss: 1.5521161556243896
Validation loss: 1.9226979952986523

Epoch: 6| Step: 10
Training loss: 1.9034124612808228
Validation loss: 1.849302040633335

Epoch: 6| Step: 11
Training loss: 1.1577372550964355
Validation loss: 1.9704624427262174

Epoch: 6| Step: 12
Training loss: 1.7738394737243652
Validation loss: 2.008491280258343

Epoch: 6| Step: 13
Training loss: 1.5068678855895996
Validation loss: 1.9499599279895905

Epoch: 320| Step: 0
Training loss: 1.2197102308273315
Validation loss: 1.9140554756246588

Epoch: 6| Step: 1
Training loss: 1.4834849834442139
Validation loss: 1.9237254896471578

Epoch: 6| Step: 2
Training loss: 1.9417698383331299
Validation loss: 1.9997589306164814

Epoch: 6| Step: 3
Training loss: 1.6414833068847656
Validation loss: 2.0228382041377406

Epoch: 6| Step: 4
Training loss: 1.1986260414123535
Validation loss: 1.915079778240573

Epoch: 6| Step: 5
Training loss: 1.4098763465881348
Validation loss: 1.8840806586768037

Epoch: 6| Step: 6
Training loss: 1.7847118377685547
Validation loss: 1.962970249114498

Epoch: 6| Step: 7
Training loss: 1.7447535991668701
Validation loss: 1.933038539783929

Epoch: 6| Step: 8
Training loss: 1.7306480407714844
Validation loss: 1.9461035228544665

Epoch: 6| Step: 9
Training loss: 1.6363855600357056
Validation loss: 1.9169770107474378

Epoch: 6| Step: 10
Training loss: 1.6211249828338623
Validation loss: 1.9521822442290604

Epoch: 6| Step: 11
Training loss: 1.4033766984939575
Validation loss: 1.9313539074313255

Epoch: 6| Step: 12
Training loss: 1.3047270774841309
Validation loss: 1.927478741574031

Epoch: 6| Step: 13
Training loss: 1.2175147533416748
Validation loss: 1.9355672969613025

Epoch: 321| Step: 0
Training loss: 1.7040727138519287
Validation loss: 1.9237719171790666

Epoch: 6| Step: 1
Training loss: 1.7286205291748047
Validation loss: 1.9334958663550756

Epoch: 6| Step: 2
Training loss: 1.476705551147461
Validation loss: 1.9068830295275616

Epoch: 6| Step: 3
Training loss: 1.397741436958313
Validation loss: 1.951637234739078

Epoch: 6| Step: 4
Training loss: 1.0541012287139893
Validation loss: 1.9378715022917716

Epoch: 6| Step: 5
Training loss: 1.7058323621749878
Validation loss: 1.9272242771681918

Epoch: 6| Step: 6
Training loss: 1.414229393005371
Validation loss: 1.8155306616137106

Epoch: 6| Step: 7
Training loss: 1.2091526985168457
Validation loss: 1.8702591798638786

Epoch: 6| Step: 8
Training loss: 1.296710729598999
Validation loss: 2.044265524033577

Epoch: 6| Step: 9
Training loss: 1.9465171098709106
Validation loss: 1.983455555413359

Epoch: 6| Step: 10
Training loss: 1.372328519821167
Validation loss: 2.019142420061173

Epoch: 6| Step: 11
Training loss: 1.9363887310028076
Validation loss: 2.0323582964558757

Epoch: 6| Step: 12
Training loss: 1.2311639785766602
Validation loss: 2.019834315905007

Epoch: 6| Step: 13
Training loss: 1.1519941091537476
Validation loss: 1.988164735096757

Epoch: 322| Step: 0
Training loss: 1.674098014831543
Validation loss: 1.917782522016956

Epoch: 6| Step: 1
Training loss: 1.02594792842865
Validation loss: 1.965992186659126

Epoch: 6| Step: 2
Training loss: 1.9144495725631714
Validation loss: 2.006941217248158

Epoch: 6| Step: 3
Training loss: 1.2985203266143799
Validation loss: 1.9047580175502326

Epoch: 6| Step: 4
Training loss: 1.7612193822860718
Validation loss: 1.857814238917443

Epoch: 6| Step: 5
Training loss: 1.133617639541626
Validation loss: 1.9838798674204017

Epoch: 6| Step: 6
Training loss: 1.6549286842346191
Validation loss: 1.9101942995543122

Epoch: 6| Step: 7
Training loss: 1.4633700847625732
Validation loss: 1.9971569866262457

Epoch: 6| Step: 8
Training loss: 1.6239733695983887
Validation loss: 1.901675513995591

Epoch: 6| Step: 9
Training loss: 1.966625452041626
Validation loss: 1.8869832202952395

Epoch: 6| Step: 10
Training loss: 1.42987060546875
Validation loss: 1.963113211816357

Epoch: 6| Step: 11
Training loss: 1.540099024772644
Validation loss: 1.915655364272415

Epoch: 6| Step: 12
Training loss: 1.5857453346252441
Validation loss: 1.9162686819671302

Epoch: 6| Step: 13
Training loss: 1.3184632062911987
Validation loss: 1.95435590897837

Epoch: 323| Step: 0
Training loss: 1.3484876155853271
Validation loss: 1.9263004872106737

Epoch: 6| Step: 1
Training loss: 1.5531139373779297
Validation loss: 2.0154581326310352

Epoch: 6| Step: 2
Training loss: 1.2755261659622192
Validation loss: 1.940011029602379

Epoch: 6| Step: 3
Training loss: 1.9084291458129883
Validation loss: 1.9109009965773551

Epoch: 6| Step: 4
Training loss: 1.4800212383270264
Validation loss: 1.9330391640304236

Epoch: 6| Step: 5
Training loss: 1.1040940284729004
Validation loss: 1.952180867554039

Epoch: 6| Step: 6
Training loss: 1.9648973941802979
Validation loss: 1.9562128577181088

Epoch: 6| Step: 7
Training loss: 1.9541785717010498
Validation loss: 1.9206583243544384

Epoch: 6| Step: 8
Training loss: 1.8484433889389038
Validation loss: 1.9351621827771586

Epoch: 6| Step: 9
Training loss: 0.9711971282958984
Validation loss: 1.8936793727259482

Epoch: 6| Step: 10
Training loss: 2.0107569694519043
Validation loss: 1.8911307986064623

Epoch: 6| Step: 11
Training loss: 1.1848440170288086
Validation loss: 1.9302715191277124

Epoch: 6| Step: 12
Training loss: 1.3914082050323486
Validation loss: 1.9651942791477326

Epoch: 6| Step: 13
Training loss: 1.083397388458252
Validation loss: 1.9699048688334804

Epoch: 324| Step: 0
Training loss: 1.168836236000061
Validation loss: 1.8745340288326304

Epoch: 6| Step: 1
Training loss: 1.5136847496032715
Validation loss: 1.9802226071716638

Epoch: 6| Step: 2
Training loss: 1.4654968976974487
Validation loss: 2.0017294217181463

Epoch: 6| Step: 3
Training loss: 2.328075647354126
Validation loss: 1.9759596932318904

Epoch: 6| Step: 4
Training loss: 1.8226196765899658
Validation loss: 1.891788242965616

Epoch: 6| Step: 5
Training loss: 1.659602165222168
Validation loss: 1.8605839270417408

Epoch: 6| Step: 6
Training loss: 1.4176762104034424
Validation loss: 1.9368376565235916

Epoch: 6| Step: 7
Training loss: 1.0422898530960083
Validation loss: 1.9910479117465276

Epoch: 6| Step: 8
Training loss: 0.9821216464042664
Validation loss: 1.935019839194513

Epoch: 6| Step: 9
Training loss: 1.558091640472412
Validation loss: 2.005053444575238

Epoch: 6| Step: 10
Training loss: 0.8832972049713135
Validation loss: 1.978265130391685

Epoch: 6| Step: 11
Training loss: 1.617008924484253
Validation loss: 1.96168133776675

Epoch: 6| Step: 12
Training loss: 1.6649606227874756
Validation loss: 1.9693534015327372

Epoch: 6| Step: 13
Training loss: 1.3919429779052734
Validation loss: 1.874508173235001

Epoch: 325| Step: 0
Training loss: 1.2900241613388062
Validation loss: 1.8767317648856872

Epoch: 6| Step: 1
Training loss: 1.7469534873962402
Validation loss: 1.9619805492380613

Epoch: 6| Step: 2
Training loss: 1.8814334869384766
Validation loss: 1.9029575752955612

Epoch: 6| Step: 3
Training loss: 1.8405842781066895
Validation loss: 1.9282402094974314

Epoch: 6| Step: 4
Training loss: 1.6186870336532593
Validation loss: 1.903503102640952

Epoch: 6| Step: 5
Training loss: 1.1692548990249634
Validation loss: 1.9890337644084808

Epoch: 6| Step: 6
Training loss: 1.2233755588531494
Validation loss: 1.8002725352523148

Epoch: 6| Step: 7
Training loss: 1.776698112487793
Validation loss: 1.9765614053254486

Epoch: 6| Step: 8
Training loss: 1.2474560737609863
Validation loss: 1.9154001000106975

Epoch: 6| Step: 9
Training loss: 1.0559144020080566
Validation loss: 1.9317306459590953

Epoch: 6| Step: 10
Training loss: 1.7433242797851562
Validation loss: 1.9777138976640598

Epoch: 6| Step: 11
Training loss: 1.394405722618103
Validation loss: 1.906843259770383

Epoch: 6| Step: 12
Training loss: 1.7043083906173706
Validation loss: 1.9534984634768577

Epoch: 6| Step: 13
Training loss: 1.29169762134552
Validation loss: 1.875066699520234

Epoch: 326| Step: 0
Training loss: 1.2378028631210327
Validation loss: 1.9690025980754564

Epoch: 6| Step: 1
Training loss: 1.464348554611206
Validation loss: 1.9639502417656682

Epoch: 6| Step: 2
Training loss: 1.1076548099517822
Validation loss: 1.8564830454446937

Epoch: 6| Step: 3
Training loss: 1.6521817445755005
Validation loss: 1.9379688488539828

Epoch: 6| Step: 4
Training loss: 1.0121501684188843
Validation loss: 1.9246643743207377

Epoch: 6| Step: 5
Training loss: 1.7619824409484863
Validation loss: 1.973700092684838

Epoch: 6| Step: 6
Training loss: 1.570023775100708
Validation loss: 1.9052067443888674

Epoch: 6| Step: 7
Training loss: 1.549504041671753
Validation loss: 1.9669809674703946

Epoch: 6| Step: 8
Training loss: 1.6646687984466553
Validation loss: 1.9963025546843005

Epoch: 6| Step: 9
Training loss: 1.2431786060333252
Validation loss: 1.9911718445439492

Epoch: 6| Step: 10
Training loss: 2.039966583251953
Validation loss: 1.9915536411346928

Epoch: 6| Step: 11
Training loss: 1.786725640296936
Validation loss: 1.8275426100659113

Epoch: 6| Step: 12
Training loss: 1.5058188438415527
Validation loss: 1.9207697811947073

Epoch: 6| Step: 13
Training loss: 1.5215017795562744
Validation loss: 1.9140912499479068

Epoch: 327| Step: 0
Training loss: 1.2163828611373901
Validation loss: 1.9288101503925938

Epoch: 6| Step: 1
Training loss: 1.5856674909591675
Validation loss: 1.9359610093537198

Epoch: 6| Step: 2
Training loss: 1.0358154773712158
Validation loss: 1.9006680147622221

Epoch: 6| Step: 3
Training loss: 1.2093966007232666
Validation loss: 1.9176387427955546

Epoch: 6| Step: 4
Training loss: 2.313293933868408
Validation loss: 1.8658826133256317

Epoch: 6| Step: 5
Training loss: 1.4842891693115234
Validation loss: 1.9374015741450812

Epoch: 6| Step: 6
Training loss: 1.7528119087219238
Validation loss: 1.8505418826174993

Epoch: 6| Step: 7
Training loss: 1.881014347076416
Validation loss: 1.9724122696025397

Epoch: 6| Step: 8
Training loss: 2.1142725944519043
Validation loss: 1.8628569469656995

Epoch: 6| Step: 9
Training loss: 1.292535424232483
Validation loss: 1.9412017996593187

Epoch: 6| Step: 10
Training loss: 1.0285166501998901
Validation loss: 1.9195373276228547

Epoch: 6| Step: 11
Training loss: 1.3846173286437988
Validation loss: 1.9385933004399782

Epoch: 6| Step: 12
Training loss: 1.4538235664367676
Validation loss: 1.9607147080923921

Epoch: 6| Step: 13
Training loss: 1.7188867330551147
Validation loss: 1.967175970795334

Epoch: 328| Step: 0
Training loss: 1.1687623262405396
Validation loss: 1.983669521988079

Epoch: 6| Step: 1
Training loss: 1.3483275175094604
Validation loss: 1.992372384635351

Epoch: 6| Step: 2
Training loss: 1.6605316400527954
Validation loss: 2.0013218977118052

Epoch: 6| Step: 3
Training loss: 1.4938297271728516
Validation loss: 1.9965588482477332

Epoch: 6| Step: 4
Training loss: 1.3353785276412964
Validation loss: 2.0452670384478826

Epoch: 6| Step: 5
Training loss: 1.5846532583236694
Validation loss: 2.0435051354028846

Epoch: 6| Step: 6
Training loss: 1.8837612867355347
Validation loss: 1.964933156967163

Epoch: 6| Step: 7
Training loss: 1.4866671562194824
Validation loss: 1.9745203192516039

Epoch: 6| Step: 8
Training loss: 1.0683202743530273
Validation loss: 1.852852600877003

Epoch: 6| Step: 9
Training loss: 1.4188172817230225
Validation loss: 1.9446518562173332

Epoch: 6| Step: 10
Training loss: 1.4198920726776123
Validation loss: 1.921970896823432

Epoch: 6| Step: 11
Training loss: 1.347899079322815
Validation loss: 1.9812685674236667

Epoch: 6| Step: 12
Training loss: 2.2661261558532715
Validation loss: 1.946478266869822

Epoch: 6| Step: 13
Training loss: 2.7479782104492188
Validation loss: 1.966180896246305

Epoch: 329| Step: 0
Training loss: 2.1647839546203613
Validation loss: 1.9354355924872941

Epoch: 6| Step: 1
Training loss: 1.4329065084457397
Validation loss: 1.9480065555982693

Epoch: 6| Step: 2
Training loss: 1.4278521537780762
Validation loss: 1.9149156898580573

Epoch: 6| Step: 3
Training loss: 1.3992869853973389
Validation loss: 1.9839937148555633

Epoch: 6| Step: 4
Training loss: 1.5963568687438965
Validation loss: 1.9799090636673795

Epoch: 6| Step: 5
Training loss: 1.949742078781128
Validation loss: 1.9161635355282856

Epoch: 6| Step: 6
Training loss: 1.4155025482177734
Validation loss: 1.9316427118034774

Epoch: 6| Step: 7
Training loss: 0.813993513584137
Validation loss: 1.9285265220108854

Epoch: 6| Step: 8
Training loss: 1.266106367111206
Validation loss: 2.006834494170322

Epoch: 6| Step: 9
Training loss: 1.4259074926376343
Validation loss: 1.8791077290811846

Epoch: 6| Step: 10
Training loss: 1.6431384086608887
Validation loss: 2.0142116174902966

Epoch: 6| Step: 11
Training loss: 1.4987208843231201
Validation loss: 1.8808620796408704

Epoch: 6| Step: 12
Training loss: 1.1067074537277222
Validation loss: 1.9674960708105436

Epoch: 6| Step: 13
Training loss: 1.7664084434509277
Validation loss: 1.9023054402361634

Epoch: 330| Step: 0
Training loss: 1.683304786682129
Validation loss: 1.8999465075872277

Epoch: 6| Step: 1
Training loss: 1.1166239976882935
Validation loss: 1.8958685833920714

Epoch: 6| Step: 2
Training loss: 1.9904718399047852
Validation loss: 1.8929892816851217

Epoch: 6| Step: 3
Training loss: 1.7455569505691528
Validation loss: 1.8570997189450007

Epoch: 6| Step: 4
Training loss: 1.8165502548217773
Validation loss: 1.8991516328627063

Epoch: 6| Step: 5
Training loss: 1.3035318851470947
Validation loss: 1.9668900761553036

Epoch: 6| Step: 6
Training loss: 0.8176435232162476
Validation loss: 1.965583973033454

Epoch: 6| Step: 7
Training loss: 1.8233528137207031
Validation loss: 1.9480270108868998

Epoch: 6| Step: 8
Training loss: 1.6534966230392456
Validation loss: 1.9228967415389193

Epoch: 6| Step: 9
Training loss: 1.4247050285339355
Validation loss: 1.9209155036557106

Epoch: 6| Step: 10
Training loss: 1.0488779544830322
Validation loss: 1.9970241477412563

Epoch: 6| Step: 11
Training loss: 1.4431663751602173
Validation loss: 2.0222394415127334

Epoch: 6| Step: 12
Training loss: 2.108872652053833
Validation loss: 1.9277936617533367

Epoch: 6| Step: 13
Training loss: 1.753312587738037
Validation loss: 1.9804186705620057

Epoch: 331| Step: 0
Training loss: 1.1965041160583496
Validation loss: 1.8872824638120589

Epoch: 6| Step: 1
Training loss: 1.3485262393951416
Validation loss: 1.9268635742125972

Epoch: 6| Step: 2
Training loss: 2.3152384757995605
Validation loss: 1.8814732733593191

Epoch: 6| Step: 3
Training loss: 1.3203339576721191
Validation loss: 1.9338621785563808

Epoch: 6| Step: 4
Training loss: 1.1640828847885132
Validation loss: 1.8276275588620094

Epoch: 6| Step: 5
Training loss: 2.0402672290802
Validation loss: 1.9226810137430828

Epoch: 6| Step: 6
Training loss: 1.0736510753631592
Validation loss: 2.01586793058662

Epoch: 6| Step: 7
Training loss: 1.6958507299423218
Validation loss: 1.9132430386799637

Epoch: 6| Step: 8
Training loss: 1.23023521900177
Validation loss: 1.9231771371697868

Epoch: 6| Step: 9
Training loss: 1.8857874870300293
Validation loss: 1.9374199964666878

Epoch: 6| Step: 10
Training loss: 1.6598830223083496
Validation loss: 1.878679060166882

Epoch: 6| Step: 11
Training loss: 1.4218268394470215
Validation loss: 1.955787843273532

Epoch: 6| Step: 12
Training loss: 1.0340628623962402
Validation loss: 1.9103222444493284

Epoch: 6| Step: 13
Training loss: 1.4771559238433838
Validation loss: 1.918271885123304

Epoch: 332| Step: 0
Training loss: 1.6512253284454346
Validation loss: 1.9076046828300721

Epoch: 6| Step: 1
Training loss: 1.2947731018066406
Validation loss: 1.9572184239664385

Epoch: 6| Step: 2
Training loss: 1.979261875152588
Validation loss: 1.9101433395057597

Epoch: 6| Step: 3
Training loss: 1.4904011487960815
Validation loss: 1.8558455974824968

Epoch: 6| Step: 4
Training loss: 1.7814218997955322
Validation loss: 1.892381529654226

Epoch: 6| Step: 5
Training loss: 1.6442546844482422
Validation loss: 1.913900339475242

Epoch: 6| Step: 6
Training loss: 1.562683343887329
Validation loss: 1.9294794823533745

Epoch: 6| Step: 7
Training loss: 1.5840942859649658
Validation loss: 1.9275218184276293

Epoch: 6| Step: 8
Training loss: 1.1398706436157227
Validation loss: 1.8564699375501243

Epoch: 6| Step: 9
Training loss: 1.2005727291107178
Validation loss: 1.959859937749883

Epoch: 6| Step: 10
Training loss: 1.4774852991104126
Validation loss: 2.009181237989856

Epoch: 6| Step: 11
Training loss: 1.6583545207977295
Validation loss: 1.9696380476797781

Epoch: 6| Step: 12
Training loss: 1.3147716522216797
Validation loss: 1.9965787267172208

Epoch: 6| Step: 13
Training loss: 1.6908764839172363
Validation loss: 1.9730507225118659

Epoch: 333| Step: 0
Training loss: 1.7875490188598633
Validation loss: 2.023814196227699

Epoch: 6| Step: 1
Training loss: 2.1071977615356445
Validation loss: 2.0042500252364785

Epoch: 6| Step: 2
Training loss: 1.6306324005126953
Validation loss: 1.9846454358869983

Epoch: 6| Step: 3
Training loss: 1.754826545715332
Validation loss: 1.9721946549671951

Epoch: 6| Step: 4
Training loss: 1.0935144424438477
Validation loss: 1.8807497550082464

Epoch: 6| Step: 5
Training loss: 1.4271141290664673
Validation loss: 1.8652986480343727

Epoch: 6| Step: 6
Training loss: 1.2082250118255615
Validation loss: 1.9046952134819441

Epoch: 6| Step: 7
Training loss: 1.185309886932373
Validation loss: 1.9387242050581082

Epoch: 6| Step: 8
Training loss: 1.5990574359893799
Validation loss: 1.8532998690041163

Epoch: 6| Step: 9
Training loss: 1.48890221118927
Validation loss: 1.9717740422935897

Epoch: 6| Step: 10
Training loss: 1.518436312675476
Validation loss: 1.8945869335564234

Epoch: 6| Step: 11
Training loss: 1.1469173431396484
Validation loss: 1.8155538599978212

Epoch: 6| Step: 12
Training loss: 1.616002082824707
Validation loss: 1.9558439434215587

Epoch: 6| Step: 13
Training loss: 1.5308887958526611
Validation loss: 1.9411494834448701

Epoch: 334| Step: 0
Training loss: 1.828227162361145
Validation loss: 1.9237799439378964

Epoch: 6| Step: 1
Training loss: 1.3169074058532715
Validation loss: 1.8997237874615578

Epoch: 6| Step: 2
Training loss: 1.6766934394836426
Validation loss: 1.978449624071839

Epoch: 6| Step: 3
Training loss: 1.3447232246398926
Validation loss: 1.8790981513197704

Epoch: 6| Step: 4
Training loss: 1.5923006534576416
Validation loss: 1.9878342574642551

Epoch: 6| Step: 5
Training loss: 1.4725236892700195
Validation loss: 1.958590099888463

Epoch: 6| Step: 6
Training loss: 1.2607033252716064
Validation loss: 1.921167089093116

Epoch: 6| Step: 7
Training loss: 1.0484542846679688
Validation loss: 1.955384894083905

Epoch: 6| Step: 8
Training loss: 1.4348516464233398
Validation loss: 1.977003348770962

Epoch: 6| Step: 9
Training loss: 2.0820326805114746
Validation loss: 1.9591577975980696

Epoch: 6| Step: 10
Training loss: 1.6518242359161377
Validation loss: 1.951630623109879

Epoch: 6| Step: 11
Training loss: 1.1475017070770264
Validation loss: 1.9631922193752822

Epoch: 6| Step: 12
Training loss: 1.63836669921875
Validation loss: 1.9429249032851188

Epoch: 6| Step: 13
Training loss: 1.2351144552230835
Validation loss: 1.9860982253987303

Epoch: 335| Step: 0
Training loss: 1.800337791442871
Validation loss: 2.004223862001973

Epoch: 6| Step: 1
Training loss: 1.138495683670044
Validation loss: 1.8529087881888113

Epoch: 6| Step: 2
Training loss: 1.9278128147125244
Validation loss: 1.9543804712192987

Epoch: 6| Step: 3
Training loss: 1.6178971529006958
Validation loss: 2.0025905063075404

Epoch: 6| Step: 4
Training loss: 1.5047519207000732
Validation loss: 1.9227389340759606

Epoch: 6| Step: 5
Training loss: 1.5141645669937134
Validation loss: 1.9648848297775432

Epoch: 6| Step: 6
Training loss: 1.1728487014770508
Validation loss: 1.954076865667938

Epoch: 6| Step: 7
Training loss: 1.6029945611953735
Validation loss: 1.984262079320928

Epoch: 6| Step: 8
Training loss: 1.580672264099121
Validation loss: 1.9687857140776932

Epoch: 6| Step: 9
Training loss: 1.7664560079574585
Validation loss: 1.9488128410872592

Epoch: 6| Step: 10
Training loss: 2.162175178527832
Validation loss: 1.8935190605860885

Epoch: 6| Step: 11
Training loss: 0.814245343208313
Validation loss: 1.999698890152798

Epoch: 6| Step: 12
Training loss: 1.1700007915496826
Validation loss: 1.960915211708315

Epoch: 6| Step: 13
Training loss: 1.667925477027893
Validation loss: 1.9617703178877473

Epoch: 336| Step: 0
Training loss: 1.5383427143096924
Validation loss: 1.9640620011155323

Epoch: 6| Step: 1
Training loss: 1.3385365009307861
Validation loss: 1.9073569569536435

Epoch: 6| Step: 2
Training loss: 2.410738229751587
Validation loss: 1.9503279616755824

Epoch: 6| Step: 3
Training loss: 1.6127439737319946
Validation loss: 1.8924457206520984

Epoch: 6| Step: 4
Training loss: 1.2800750732421875
Validation loss: 1.9441037306221582

Epoch: 6| Step: 5
Training loss: 1.3225681781768799
Validation loss: 1.9601334320601596

Epoch: 6| Step: 6
Training loss: 0.9791615605354309
Validation loss: 1.9047966375145862

Epoch: 6| Step: 7
Training loss: 1.4974462985992432
Validation loss: 1.9548012107931159

Epoch: 6| Step: 8
Training loss: 1.5666152238845825
Validation loss: 1.9254077301230481

Epoch: 6| Step: 9
Training loss: 1.4877642393112183
Validation loss: 1.9563224059279247

Epoch: 6| Step: 10
Training loss: 1.1533503532409668
Validation loss: 1.8465891627855198

Epoch: 6| Step: 11
Training loss: 1.5839890241622925
Validation loss: 1.9399778022561023

Epoch: 6| Step: 12
Training loss: 1.640898585319519
Validation loss: 1.9306861354458718

Epoch: 6| Step: 13
Training loss: 0.6104576587677002
Validation loss: 1.9672403450935119

Epoch: 337| Step: 0
Training loss: 1.4407234191894531
Validation loss: 1.959861163170107

Epoch: 6| Step: 1
Training loss: 0.8533025979995728
Validation loss: 2.016706589729555

Epoch: 6| Step: 2
Training loss: 1.361295223236084
Validation loss: 1.9497037126171974

Epoch: 6| Step: 3
Training loss: 1.5311033725738525
Validation loss: 1.8743304629479685

Epoch: 6| Step: 4
Training loss: 1.9027334451675415
Validation loss: 1.9120415692688317

Epoch: 6| Step: 5
Training loss: 1.9120452404022217
Validation loss: 1.9643608959772254

Epoch: 6| Step: 6
Training loss: 1.9873980283737183
Validation loss: 1.8999636634703605

Epoch: 6| Step: 7
Training loss: 1.9475936889648438
Validation loss: 1.9167204480017386

Epoch: 6| Step: 8
Training loss: 1.303035020828247
Validation loss: 1.9025505691446283

Epoch: 6| Step: 9
Training loss: 0.880191445350647
Validation loss: 1.8686354916582826

Epoch: 6| Step: 10
Training loss: 1.5733108520507812
Validation loss: 1.918761517411919

Epoch: 6| Step: 11
Training loss: 1.2002735137939453
Validation loss: 1.9287895092400171

Epoch: 6| Step: 12
Training loss: 1.4106239080429077
Validation loss: 1.9298282695072952

Epoch: 6| Step: 13
Training loss: 1.472360610961914
Validation loss: 1.8818145298188733

Epoch: 338| Step: 0
Training loss: 1.3908510208129883
Validation loss: 1.9365066302719938

Epoch: 6| Step: 1
Training loss: 1.4095555543899536
Validation loss: 1.9231014431163829

Epoch: 6| Step: 2
Training loss: 1.742811679840088
Validation loss: 1.8708554314028831

Epoch: 6| Step: 3
Training loss: 1.2912201881408691
Validation loss: 1.9281278451283772

Epoch: 6| Step: 4
Training loss: 1.2548682689666748
Validation loss: 1.9658882143676921

Epoch: 6| Step: 5
Training loss: 1.7579681873321533
Validation loss: 1.9960285309822328

Epoch: 6| Step: 6
Training loss: 1.4271867275238037
Validation loss: 1.9629278567529493

Epoch: 6| Step: 7
Training loss: 1.371021032333374
Validation loss: 1.8735638972251647

Epoch: 6| Step: 8
Training loss: 1.8984023332595825
Validation loss: 1.9264557374420987

Epoch: 6| Step: 9
Training loss: 0.7172237634658813
Validation loss: 1.9663148157058223

Epoch: 6| Step: 10
Training loss: 1.5998085737228394
Validation loss: 2.032668414936271

Epoch: 6| Step: 11
Training loss: 1.487725019454956
Validation loss: 1.9302276654910016

Epoch: 6| Step: 12
Training loss: 1.8421984910964966
Validation loss: 1.9132595933893675

Epoch: 6| Step: 13
Training loss: 1.8659223318099976
Validation loss: 1.876106644189486

Epoch: 339| Step: 0
Training loss: 1.182900071144104
Validation loss: 1.9441452590368127

Epoch: 6| Step: 1
Training loss: 1.7098802328109741
Validation loss: 1.9695676244715208

Epoch: 6| Step: 2
Training loss: 1.4416193962097168
Validation loss: 1.9154209552272674

Epoch: 6| Step: 3
Training loss: 1.4434337615966797
Validation loss: 1.9400535988551315

Epoch: 6| Step: 4
Training loss: 1.643179178237915
Validation loss: 1.9389810677497619

Epoch: 6| Step: 5
Training loss: 1.0565546751022339
Validation loss: 1.9547000572245607

Epoch: 6| Step: 6
Training loss: 1.4269332885742188
Validation loss: 2.00345415325575

Epoch: 6| Step: 7
Training loss: 2.132711172103882
Validation loss: 1.8826214882635302

Epoch: 6| Step: 8
Training loss: 1.319873332977295
Validation loss: 1.9020103293080484

Epoch: 6| Step: 9
Training loss: 1.0853557586669922
Validation loss: 1.8851661041218748

Epoch: 6| Step: 10
Training loss: 1.557595133781433
Validation loss: 1.847442957662767

Epoch: 6| Step: 11
Training loss: 1.234706163406372
Validation loss: 1.9103819401033464

Epoch: 6| Step: 12
Training loss: 2.145491123199463
Validation loss: 1.92777015701417

Epoch: 6| Step: 13
Training loss: 1.3332583904266357
Validation loss: 1.9021085064898255

Epoch: 340| Step: 0
Training loss: 1.54886794090271
Validation loss: 1.9298657012242142

Epoch: 6| Step: 1
Training loss: 1.7867716550827026
Validation loss: 1.9357895748589629

Epoch: 6| Step: 2
Training loss: 1.310990810394287
Validation loss: 1.9423328317621702

Epoch: 6| Step: 3
Training loss: 1.4971349239349365
Validation loss: 2.0295973785461916

Epoch: 6| Step: 4
Training loss: 1.8385882377624512
Validation loss: 1.9393259530426354

Epoch: 6| Step: 5
Training loss: 1.7164795398712158
Validation loss: 1.8494291907997542

Epoch: 6| Step: 6
Training loss: 1.4394134283065796
Validation loss: 1.9896663388898295

Epoch: 6| Step: 7
Training loss: 1.2269275188446045
Validation loss: 1.943673817060327

Epoch: 6| Step: 8
Training loss: 1.4662322998046875
Validation loss: 1.8843072306725286

Epoch: 6| Step: 9
Training loss: 1.2317068576812744
Validation loss: 1.932112443831659

Epoch: 6| Step: 10
Training loss: 1.5097572803497314
Validation loss: 1.891997701378279

Epoch: 6| Step: 11
Training loss: 1.7694916725158691
Validation loss: 1.9353012013179

Epoch: 6| Step: 12
Training loss: 1.1749415397644043
Validation loss: 1.9553311217215754

Epoch: 6| Step: 13
Training loss: 1.2228988409042358
Validation loss: 1.9368595487327986

Epoch: 341| Step: 0
Training loss: 1.4482331275939941
Validation loss: 1.9606391306846374

Epoch: 6| Step: 1
Training loss: 2.0605833530426025
Validation loss: 2.0294459430120324

Epoch: 6| Step: 2
Training loss: 2.43241286277771
Validation loss: 1.9937675460692375

Epoch: 6| Step: 3
Training loss: 1.6976253986358643
Validation loss: 1.9511750410961848

Epoch: 6| Step: 4
Training loss: 1.0242674350738525
Validation loss: 1.995008325064054

Epoch: 6| Step: 5
Training loss: 1.2755968570709229
Validation loss: 1.916092034309141

Epoch: 6| Step: 6
Training loss: 1.2788150310516357
Validation loss: 1.891946779784336

Epoch: 6| Step: 7
Training loss: 1.0284762382507324
Validation loss: 1.9256762458432106

Epoch: 6| Step: 8
Training loss: 1.2903759479522705
Validation loss: 1.8911867821088402

Epoch: 6| Step: 9
Training loss: 1.6292438507080078
Validation loss: 1.9361223123406852

Epoch: 6| Step: 10
Training loss: 1.935251235961914
Validation loss: 1.9026092970243065

Epoch: 6| Step: 11
Training loss: 1.2061305046081543
Validation loss: 1.9359120040811517

Epoch: 6| Step: 12
Training loss: 1.241855263710022
Validation loss: 1.8739615691605436

Epoch: 6| Step: 13
Training loss: 1.614030361175537
Validation loss: 1.8924012414870723

Epoch: 342| Step: 0
Training loss: 1.2987375259399414
Validation loss: 1.9639201228336622

Epoch: 6| Step: 1
Training loss: 1.0426867008209229
Validation loss: 1.9810299975897676

Epoch: 6| Step: 2
Training loss: 1.07136869430542
Validation loss: 1.9518296000778035

Epoch: 6| Step: 3
Training loss: 1.6407320499420166
Validation loss: 1.8974779805829447

Epoch: 6| Step: 4
Training loss: 1.0851916074752808
Validation loss: 1.9145957128975981

Epoch: 6| Step: 5
Training loss: 0.7988581657409668
Validation loss: 1.8917124309847433

Epoch: 6| Step: 6
Training loss: 1.9209998846054077
Validation loss: 1.9849782502779396

Epoch: 6| Step: 7
Training loss: 1.6757128238677979
Validation loss: 1.9221972932097733

Epoch: 6| Step: 8
Training loss: 1.5060451030731201
Validation loss: 1.850193364645845

Epoch: 6| Step: 9
Training loss: 1.6419861316680908
Validation loss: 1.9796855039494012

Epoch: 6| Step: 10
Training loss: 1.8704942464828491
Validation loss: 1.9375917565438054

Epoch: 6| Step: 11
Training loss: 1.2607691287994385
Validation loss: 1.9692606105599353

Epoch: 6| Step: 12
Training loss: 1.3478245735168457
Validation loss: 1.945179041995797

Epoch: 6| Step: 13
Training loss: 1.757738709449768
Validation loss: 1.9828044496556765

Epoch: 343| Step: 0
Training loss: 1.0544967651367188
Validation loss: 1.9106984651216896

Epoch: 6| Step: 1
Training loss: 1.3520498275756836
Validation loss: 1.889044152793064

Epoch: 6| Step: 2
Training loss: 2.0381970405578613
Validation loss: 1.9781649522883917

Epoch: 6| Step: 3
Training loss: 1.5895838737487793
Validation loss: 2.0060657762712046

Epoch: 6| Step: 4
Training loss: 2.0958504676818848
Validation loss: 1.9165025167567755

Epoch: 6| Step: 5
Training loss: 1.1637907028198242
Validation loss: 1.9528158685212493

Epoch: 6| Step: 6
Training loss: 1.2909890413284302
Validation loss: 1.9141068740557599

Epoch: 6| Step: 7
Training loss: 0.8739668130874634
Validation loss: 1.9552876308400144

Epoch: 6| Step: 8
Training loss: 1.6966359615325928
Validation loss: 2.045667036887138

Epoch: 6| Step: 9
Training loss: 1.355315923690796
Validation loss: 2.012153672915633

Epoch: 6| Step: 10
Training loss: 1.5491044521331787
Validation loss: 1.901853181982553

Epoch: 6| Step: 11
Training loss: 1.145043134689331
Validation loss: 1.876017080840244

Epoch: 6| Step: 12
Training loss: 1.9606057405471802
Validation loss: 1.915330784295195

Epoch: 6| Step: 13
Training loss: 0.9285635352134705
Validation loss: 2.0026731234724804

Epoch: 344| Step: 0
Training loss: 1.4002645015716553
Validation loss: 1.9480463394554712

Epoch: 6| Step: 1
Training loss: 1.1643543243408203
Validation loss: 1.9441107831975466

Epoch: 6| Step: 2
Training loss: 1.4394108057022095
Validation loss: 2.013342620224081

Epoch: 6| Step: 3
Training loss: 1.6583893299102783
Validation loss: 1.9617553244354904

Epoch: 6| Step: 4
Training loss: 1.375411033630371
Validation loss: 1.9922402392151535

Epoch: 6| Step: 5
Training loss: 1.344527006149292
Validation loss: 1.9549738155898226

Epoch: 6| Step: 6
Training loss: 1.579986572265625
Validation loss: 2.028337667065282

Epoch: 6| Step: 7
Training loss: 1.030885934829712
Validation loss: 1.9518054300738918

Epoch: 6| Step: 8
Training loss: 2.1537604331970215
Validation loss: 1.9346288327247865

Epoch: 6| Step: 9
Training loss: 1.5220041275024414
Validation loss: 1.9353940281816708

Epoch: 6| Step: 10
Training loss: 1.165406346321106
Validation loss: 1.9970689960705337

Epoch: 6| Step: 11
Training loss: 1.5220377445220947
Validation loss: 1.936009846707826

Epoch: 6| Step: 12
Training loss: 1.2286229133605957
Validation loss: 1.9364138623719573

Epoch: 6| Step: 13
Training loss: 1.2913192510604858
Validation loss: 1.951458227249884

Epoch: 345| Step: 0
Training loss: 1.3248904943466187
Validation loss: 1.987673981215364

Epoch: 6| Step: 1
Training loss: 1.6438789367675781
Validation loss: 1.9318076070918833

Epoch: 6| Step: 2
Training loss: 1.3169180154800415
Validation loss: 1.8676590099129626

Epoch: 6| Step: 3
Training loss: 2.15973162651062
Validation loss: 1.9573496067395775

Epoch: 6| Step: 4
Training loss: 1.4333217144012451
Validation loss: 1.9722738509537072

Epoch: 6| Step: 5
Training loss: 1.9018213748931885
Validation loss: 1.9754119137282014

Epoch: 6| Step: 6
Training loss: 1.2349045276641846
Validation loss: 1.976446331188243

Epoch: 6| Step: 7
Training loss: 0.84888756275177
Validation loss: 1.8798415635221748

Epoch: 6| Step: 8
Training loss: 1.4823975563049316
Validation loss: 1.8511232458135134

Epoch: 6| Step: 9
Training loss: 1.2809442281723022
Validation loss: 1.9085870788943382

Epoch: 6| Step: 10
Training loss: 1.3066561222076416
Validation loss: 1.940924144560291

Epoch: 6| Step: 11
Training loss: 1.499717116355896
Validation loss: 1.8525031587128997

Epoch: 6| Step: 12
Training loss: 1.8981783390045166
Validation loss: 1.9822980203936178

Epoch: 6| Step: 13
Training loss: 1.8327547311782837
Validation loss: 1.9001576862027567

Epoch: 346| Step: 0
Training loss: 1.6388883590698242
Validation loss: 1.9708679414564563

Epoch: 6| Step: 1
Training loss: 1.2934824228286743
Validation loss: 1.9434497433324014

Epoch: 6| Step: 2
Training loss: 1.9942529201507568
Validation loss: 1.9399154775886125

Epoch: 6| Step: 3
Training loss: 1.610252857208252
Validation loss: 1.8468504054571993

Epoch: 6| Step: 4
Training loss: 1.5649535655975342
Validation loss: 1.9337327890498663

Epoch: 6| Step: 5
Training loss: 1.7508189678192139
Validation loss: 2.0091077909674695

Epoch: 6| Step: 6
Training loss: 1.3282743692398071
Validation loss: 1.882990267968947

Epoch: 6| Step: 7
Training loss: 1.6327232122421265
Validation loss: 1.9415847191246607

Epoch: 6| Step: 8
Training loss: 1.2567963600158691
Validation loss: 1.9529263973236084

Epoch: 6| Step: 9
Training loss: 1.3672362565994263
Validation loss: 1.9417456362837104

Epoch: 6| Step: 10
Training loss: 0.8859895467758179
Validation loss: 1.9398100529947588

Epoch: 6| Step: 11
Training loss: 1.2633671760559082
Validation loss: 1.9790736859844578

Epoch: 6| Step: 12
Training loss: 1.4382911920547485
Validation loss: 1.9262117365355134

Epoch: 6| Step: 13
Training loss: 2.276128053665161
Validation loss: 1.9229352320394208

Epoch: 347| Step: 0
Training loss: 1.1781542301177979
Validation loss: 1.9252306671552761

Epoch: 6| Step: 1
Training loss: 1.5113723278045654
Validation loss: 1.897578723968998

Epoch: 6| Step: 2
Training loss: 1.2788968086242676
Validation loss: 1.9505154035424674

Epoch: 6| Step: 3
Training loss: 1.8523736000061035
Validation loss: 1.9279904006629862

Epoch: 6| Step: 4
Training loss: 1.237180471420288
Validation loss: 1.9239274096745316

Epoch: 6| Step: 5
Training loss: 1.3350729942321777
Validation loss: 1.9131252381109423

Epoch: 6| Step: 6
Training loss: 1.5667372941970825
Validation loss: 1.8884801454441522

Epoch: 6| Step: 7
Training loss: 1.5697988271713257
Validation loss: 1.8460612284239901

Epoch: 6| Step: 8
Training loss: 1.179430365562439
Validation loss: 1.9758363577627367

Epoch: 6| Step: 9
Training loss: 2.599123954772949
Validation loss: 1.9428473518740745

Epoch: 6| Step: 10
Training loss: 1.4718546867370605
Validation loss: 2.0179825175193047

Epoch: 6| Step: 11
Training loss: 1.698058009147644
Validation loss: 1.898183713677109

Epoch: 6| Step: 12
Training loss: 0.8925857543945312
Validation loss: 1.909104916357225

Epoch: 6| Step: 13
Training loss: 1.475660800933838
Validation loss: 1.918928784708823

Epoch: 348| Step: 0
Training loss: 1.6304891109466553
Validation loss: 1.8764538816226426

Epoch: 6| Step: 1
Training loss: 1.2928705215454102
Validation loss: 1.952155674657514

Epoch: 6| Step: 2
Training loss: 1.1047868728637695
Validation loss: 1.8391129893641318

Epoch: 6| Step: 3
Training loss: 1.5401148796081543
Validation loss: 1.8847016621661443

Epoch: 6| Step: 4
Training loss: 1.1416699886322021
Validation loss: 1.9468904490111976

Epoch: 6| Step: 5
Training loss: 1.657996654510498
Validation loss: 1.9327561342588035

Epoch: 6| Step: 6
Training loss: 1.2941343784332275
Validation loss: 1.9924676341395224

Epoch: 6| Step: 7
Training loss: 1.1851649284362793
Validation loss: 1.9295102460410005

Epoch: 6| Step: 8
Training loss: 1.4688801765441895
Validation loss: 1.867634565599503

Epoch: 6| Step: 9
Training loss: 1.5197241306304932
Validation loss: 1.9481106317171486

Epoch: 6| Step: 10
Training loss: 2.1015613079071045
Validation loss: 1.8937073471725627

Epoch: 6| Step: 11
Training loss: 2.387782335281372
Validation loss: 1.9504536710759646

Epoch: 6| Step: 12
Training loss: 1.7311146259307861
Validation loss: 1.89507810531124

Epoch: 6| Step: 13
Training loss: 1.026069164276123
Validation loss: 1.9492452349714053

Epoch: 349| Step: 0
Training loss: 2.1014580726623535
Validation loss: 1.9518082244421846

Epoch: 6| Step: 1
Training loss: 1.2094855308532715
Validation loss: 1.846907187533635

Epoch: 6| Step: 2
Training loss: 1.856343150138855
Validation loss: 1.8494921589410434

Epoch: 6| Step: 3
Training loss: 1.480696439743042
Validation loss: 2.041881840716126

Epoch: 6| Step: 4
Training loss: 1.355261206626892
Validation loss: 1.92678649451143

Epoch: 6| Step: 5
Training loss: 1.1602493524551392
Validation loss: 2.009272949669951

Epoch: 6| Step: 6
Training loss: 1.4267964363098145
Validation loss: 1.9645491851273404

Epoch: 6| Step: 7
Training loss: 1.8065822124481201
Validation loss: 2.0253188494713075

Epoch: 6| Step: 8
Training loss: 1.8723251819610596
Validation loss: 1.9425485903216946

Epoch: 6| Step: 9
Training loss: 1.7350980043411255
Validation loss: 1.9117990924466042

Epoch: 6| Step: 10
Training loss: 1.1108407974243164
Validation loss: 1.9146323806496077

Epoch: 6| Step: 11
Training loss: 1.2111396789550781
Validation loss: 1.9334206568297518

Epoch: 6| Step: 12
Training loss: 1.3518924713134766
Validation loss: 1.9377326196239841

Epoch: 6| Step: 13
Training loss: 0.9333865642547607
Validation loss: 1.925085485622447

Epoch: 350| Step: 0
Training loss: 1.1369154453277588
Validation loss: 2.0262383132852535

Epoch: 6| Step: 1
Training loss: 1.5750362873077393
Validation loss: 1.9316744983837169

Epoch: 6| Step: 2
Training loss: 1.5584304332733154
Validation loss: 1.8579830418350876

Epoch: 6| Step: 3
Training loss: 1.253587007522583
Validation loss: 1.8643656930615824

Epoch: 6| Step: 4
Training loss: 1.5361894369125366
Validation loss: 1.8808468477700346

Epoch: 6| Step: 5
Training loss: 1.5588887929916382
Validation loss: 1.9690477591688915

Epoch: 6| Step: 6
Training loss: 1.2363591194152832
Validation loss: 1.9206043648463424

Epoch: 6| Step: 7
Training loss: 1.475982427597046
Validation loss: 1.9029558576563352

Epoch: 6| Step: 8
Training loss: 1.4927489757537842
Validation loss: 1.988567602249884

Epoch: 6| Step: 9
Training loss: 2.011834144592285
Validation loss: 1.9123556408830868

Epoch: 6| Step: 10
Training loss: 1.1826393604278564
Validation loss: 1.9394410425616848

Epoch: 6| Step: 11
Training loss: 1.8064980506896973
Validation loss: 1.8980742449401526

Epoch: 6| Step: 12
Training loss: 1.0156688690185547
Validation loss: 1.9787529694136752

Epoch: 6| Step: 13
Training loss: 2.249903678894043
Validation loss: 1.924992649785934

Epoch: 351| Step: 0
Training loss: 1.2069759368896484
Validation loss: 1.9422911033835462

Epoch: 6| Step: 1
Training loss: 1.5052409172058105
Validation loss: 1.9098850745026783

Epoch: 6| Step: 2
Training loss: 1.5169247388839722
Validation loss: 1.9641980535240584

Epoch: 6| Step: 3
Training loss: 1.3836545944213867
Validation loss: 1.9686251660828948

Epoch: 6| Step: 4
Training loss: 1.980918526649475
Validation loss: 1.910717947508699

Epoch: 6| Step: 5
Training loss: 1.5176434516906738
Validation loss: 1.859095545225246

Epoch: 6| Step: 6
Training loss: 1.329119086265564
Validation loss: 1.915334306737428

Epoch: 6| Step: 7
Training loss: 1.3530772924423218
Validation loss: 1.8801399277102562

Epoch: 6| Step: 8
Training loss: 1.3992303609848022
Validation loss: 1.9198561906814575

Epoch: 6| Step: 9
Training loss: 1.8709216117858887
Validation loss: 1.862748630585209

Epoch: 6| Step: 10
Training loss: 1.964733600616455
Validation loss: 1.8464501775721067

Epoch: 6| Step: 11
Training loss: 1.4001433849334717
Validation loss: 1.9926557502438944

Epoch: 6| Step: 12
Training loss: 1.368354082107544
Validation loss: 1.9169833942126202

Epoch: 6| Step: 13
Training loss: 1.9383209943771362
Validation loss: 1.8772769397304905

Epoch: 352| Step: 0
Training loss: 1.8058135509490967
Validation loss: 1.9866977507068264

Epoch: 6| Step: 1
Training loss: 1.6073896884918213
Validation loss: 1.9751906074503416

Epoch: 6| Step: 2
Training loss: 1.2652521133422852
Validation loss: 2.0062688768550916

Epoch: 6| Step: 3
Training loss: 1.3111498355865479
Validation loss: 1.86449739497195

Epoch: 6| Step: 4
Training loss: 1.3960797786712646
Validation loss: 1.8974428458880352

Epoch: 6| Step: 5
Training loss: 1.0262824296951294
Validation loss: 1.872563854340584

Epoch: 6| Step: 6
Training loss: 1.6503543853759766
Validation loss: 1.9067059357961018

Epoch: 6| Step: 7
Training loss: 0.7802990078926086
Validation loss: 1.929157792880971

Epoch: 6| Step: 8
Training loss: 1.44308602809906
Validation loss: 2.024809414340604

Epoch: 6| Step: 9
Training loss: 1.2367372512817383
Validation loss: 1.975579680935029

Epoch: 6| Step: 10
Training loss: 1.6088939905166626
Validation loss: 1.9347992520178519

Epoch: 6| Step: 11
Training loss: 1.9698820114135742
Validation loss: 1.882589736292439

Epoch: 6| Step: 12
Training loss: 1.1954554319381714
Validation loss: 1.9271301018294467

Epoch: 6| Step: 13
Training loss: 2.4014883041381836
Validation loss: 1.9809139428600189

Epoch: 353| Step: 0
Training loss: 1.7331666946411133
Validation loss: 2.0199821687513784

Epoch: 6| Step: 1
Training loss: 1.6925606727600098
Validation loss: 1.9570845288615073

Epoch: 6| Step: 2
Training loss: 1.3097904920578003
Validation loss: 1.9614037416314567

Epoch: 6| Step: 3
Training loss: 1.353432536125183
Validation loss: 2.0199552095064552

Epoch: 6| Step: 4
Training loss: 1.0810141563415527
Validation loss: 2.0138090451558432

Epoch: 6| Step: 5
Training loss: 1.406164526939392
Validation loss: 2.020454106792327

Epoch: 6| Step: 6
Training loss: 1.5494887828826904
Validation loss: 1.9583416728563205

Epoch: 6| Step: 7
Training loss: 0.8175345659255981
Validation loss: 1.9425999605527489

Epoch: 6| Step: 8
Training loss: 1.7797294855117798
Validation loss: 1.9424603293018956

Epoch: 6| Step: 9
Training loss: 2.0807113647460938
Validation loss: 1.8705540164824455

Epoch: 6| Step: 10
Training loss: 1.3086292743682861
Validation loss: 1.8658234829543738

Epoch: 6| Step: 11
Training loss: 1.514998435974121
Validation loss: 1.9286453441907

Epoch: 6| Step: 12
Training loss: 0.8543219566345215
Validation loss: 1.9450114055346417

Epoch: 6| Step: 13
Training loss: 1.1416480541229248
Validation loss: 1.9112121392321844

Epoch: 354| Step: 0
Training loss: 1.4385075569152832
Validation loss: 1.934882015310308

Epoch: 6| Step: 1
Training loss: 1.4564838409423828
Validation loss: 1.8951459315515333

Epoch: 6| Step: 2
Training loss: 1.6765971183776855
Validation loss: 1.9535013706453386

Epoch: 6| Step: 3
Training loss: 1.5447555780410767
Validation loss: 1.9095207850138347

Epoch: 6| Step: 4
Training loss: 0.985360860824585
Validation loss: 1.9340704512852493

Epoch: 6| Step: 5
Training loss: 1.7285938262939453
Validation loss: 1.9240665384518203

Epoch: 6| Step: 6
Training loss: 1.1667814254760742
Validation loss: 1.9518465675333494

Epoch: 6| Step: 7
Training loss: 0.954401433467865
Validation loss: 1.9536466983056837

Epoch: 6| Step: 8
Training loss: 1.275416374206543
Validation loss: 1.9805809310687486

Epoch: 6| Step: 9
Training loss: 1.5851285457611084
Validation loss: 1.9757408506126815

Epoch: 6| Step: 10
Training loss: 1.4569427967071533
Validation loss: 1.8477139960053146

Epoch: 6| Step: 11
Training loss: 1.315596342086792
Validation loss: 1.8696871919016684

Epoch: 6| Step: 12
Training loss: 1.389604091644287
Validation loss: 1.99941695890119

Epoch: 6| Step: 13
Training loss: 1.3395752906799316
Validation loss: 1.9500726922865836

Epoch: 355| Step: 0
Training loss: 1.4530526399612427
Validation loss: 1.9434485563667871

Epoch: 6| Step: 1
Training loss: 1.4448472261428833
Validation loss: 1.8637095869228404

Epoch: 6| Step: 2
Training loss: 1.4612265825271606
Validation loss: 1.8601602123629661

Epoch: 6| Step: 3
Training loss: 0.9146636724472046
Validation loss: 1.9030629101619925

Epoch: 6| Step: 4
Training loss: 2.0201287269592285
Validation loss: 1.837966852290656

Epoch: 6| Step: 5
Training loss: 1.349714756011963
Validation loss: 1.9497275429387246

Epoch: 6| Step: 6
Training loss: 1.7858119010925293
Validation loss: 1.9251597376279934

Epoch: 6| Step: 7
Training loss: 1.483795404434204
Validation loss: 1.93058983613086

Epoch: 6| Step: 8
Training loss: 1.1401774883270264
Validation loss: 1.941344532915341

Epoch: 6| Step: 9
Training loss: 1.904383659362793
Validation loss: 1.967409462057134

Epoch: 6| Step: 10
Training loss: 1.2496833801269531
Validation loss: 1.8962414315951768

Epoch: 6| Step: 11
Training loss: 1.3115930557250977
Validation loss: 1.9359402579645957

Epoch: 6| Step: 12
Training loss: 1.2029460668563843
Validation loss: 1.8660957838899346

Epoch: 6| Step: 13
Training loss: 1.779869556427002
Validation loss: 1.8980896434476298

Epoch: 356| Step: 0
Training loss: 2.026827573776245
Validation loss: 1.9068989189722205

Epoch: 6| Step: 1
Training loss: 1.30827796459198
Validation loss: 1.883443509378741

Epoch: 6| Step: 2
Training loss: 1.2671465873718262
Validation loss: 1.9350720349178518

Epoch: 6| Step: 3
Training loss: 1.804368019104004
Validation loss: 1.9232785317205614

Epoch: 6| Step: 4
Training loss: 0.9911971688270569
Validation loss: 1.8924503313597811

Epoch: 6| Step: 5
Training loss: 0.6575185060501099
Validation loss: 1.8479107925968785

Epoch: 6| Step: 6
Training loss: 1.617410659790039
Validation loss: 1.88615511309716

Epoch: 6| Step: 7
Training loss: 1.8894453048706055
Validation loss: 1.9182278597226707

Epoch: 6| Step: 8
Training loss: 1.3870974779129028
Validation loss: 1.9054534422454013

Epoch: 6| Step: 9
Training loss: 1.4805598258972168
Validation loss: 1.952588406942224

Epoch: 6| Step: 10
Training loss: 1.3002448081970215
Validation loss: 1.9484200631418536

Epoch: 6| Step: 11
Training loss: 1.3514208793640137
Validation loss: 1.9277279697438723

Epoch: 6| Step: 12
Training loss: 1.8875062465667725
Validation loss: 1.8975463298059279

Epoch: 6| Step: 13
Training loss: 1.5223617553710938
Validation loss: 1.8907698418504448

Epoch: 357| Step: 0
Training loss: 1.4776582717895508
Validation loss: 1.9147281287818827

Epoch: 6| Step: 1
Training loss: 0.9123505353927612
Validation loss: 1.9770542472921393

Epoch: 6| Step: 2
Training loss: 1.917449951171875
Validation loss: 1.9596401324836157

Epoch: 6| Step: 3
Training loss: 1.3437799215316772
Validation loss: 1.932549072850135

Epoch: 6| Step: 4
Training loss: 1.4299015998840332
Validation loss: 1.9441326113157376

Epoch: 6| Step: 5
Training loss: 1.2185931205749512
Validation loss: 1.968416238343844

Epoch: 6| Step: 6
Training loss: 1.5319761037826538
Validation loss: 2.007866399903451

Epoch: 6| Step: 7
Training loss: 1.6842323541641235
Validation loss: 1.9557361218237108

Epoch: 6| Step: 8
Training loss: 1.193946123123169
Validation loss: 1.9069187013051843

Epoch: 6| Step: 9
Training loss: 1.850420355796814
Validation loss: 1.8509290551626554

Epoch: 6| Step: 10
Training loss: 0.9589748382568359
Validation loss: 1.9636997638210174

Epoch: 6| Step: 11
Training loss: 1.6778384447097778
Validation loss: 1.9439475485073623

Epoch: 6| Step: 12
Training loss: 1.2449798583984375
Validation loss: 1.8976061023691648

Epoch: 6| Step: 13
Training loss: 2.1635122299194336
Validation loss: 1.933232940653319

Epoch: 358| Step: 0
Training loss: 1.3147599697113037
Validation loss: 1.9624549470922

Epoch: 6| Step: 1
Training loss: 1.472771406173706
Validation loss: 1.8114431981117494

Epoch: 6| Step: 2
Training loss: 1.904548168182373
Validation loss: 1.9380496855705016

Epoch: 6| Step: 3
Training loss: 1.5162466764450073
Validation loss: 1.9511841394568001

Epoch: 6| Step: 4
Training loss: 1.4128155708312988
Validation loss: 1.9636121757568852

Epoch: 6| Step: 5
Training loss: 1.9121389389038086
Validation loss: 1.9628973378930041

Epoch: 6| Step: 6
Training loss: 0.7638652324676514
Validation loss: 1.9419075712080924

Epoch: 6| Step: 7
Training loss: 1.4966695308685303
Validation loss: 1.8765484966257566

Epoch: 6| Step: 8
Training loss: 1.2671842575073242
Validation loss: 1.8767232305260115

Epoch: 6| Step: 9
Training loss: 1.5355408191680908
Validation loss: 1.9485653664476128

Epoch: 6| Step: 10
Training loss: 1.6285145282745361
Validation loss: 1.8801555761726954

Epoch: 6| Step: 11
Training loss: 0.8527787327766418
Validation loss: 1.9529628574207265

Epoch: 6| Step: 12
Training loss: 1.3807328939437866
Validation loss: 1.962793775784072

Epoch: 6| Step: 13
Training loss: 1.4257187843322754
Validation loss: 1.9109398344511628

Epoch: 359| Step: 0
Training loss: 1.6044949293136597
Validation loss: 1.9609516743690736

Epoch: 6| Step: 1
Training loss: 1.6538749933242798
Validation loss: 1.8517806376180341

Epoch: 6| Step: 2
Training loss: 1.2875392436981201
Validation loss: 1.9387550943641252

Epoch: 6| Step: 3
Training loss: 1.589530348777771
Validation loss: 1.8983927657527309

Epoch: 6| Step: 4
Training loss: 1.7320270538330078
Validation loss: 1.8605290882049068

Epoch: 6| Step: 5
Training loss: 1.7675561904907227
Validation loss: 1.8747836543667702

Epoch: 6| Step: 6
Training loss: 0.7120774984359741
Validation loss: 1.8463889321973246

Epoch: 6| Step: 7
Training loss: 1.6215310096740723
Validation loss: 1.9107499686620568

Epoch: 6| Step: 8
Training loss: 1.6848721504211426
Validation loss: 1.8547150678532098

Epoch: 6| Step: 9
Training loss: 1.3118029832839966
Validation loss: 1.9201713838884908

Epoch: 6| Step: 10
Training loss: 1.2478519678115845
Validation loss: 1.928548155292388

Epoch: 6| Step: 11
Training loss: 1.20835542678833
Validation loss: 1.955086459395706

Epoch: 6| Step: 12
Training loss: 1.4841349124908447
Validation loss: 1.9532353788293817

Epoch: 6| Step: 13
Training loss: 1.2295349836349487
Validation loss: 1.9895141381089405

Epoch: 360| Step: 0
Training loss: 1.9937655925750732
Validation loss: 1.8908794003148233

Epoch: 6| Step: 1
Training loss: 1.0669069290161133
Validation loss: 1.948808588007445

Epoch: 6| Step: 2
Training loss: 0.7272043228149414
Validation loss: 1.910792222587011

Epoch: 6| Step: 3
Training loss: 1.4716260433197021
Validation loss: 1.8908504529665875

Epoch: 6| Step: 4
Training loss: 1.472129225730896
Validation loss: 1.945699691772461

Epoch: 6| Step: 5
Training loss: 1.824354887008667
Validation loss: 1.92138449991903

Epoch: 6| Step: 6
Training loss: 0.7953993082046509
Validation loss: 1.8890267572095316

Epoch: 6| Step: 7
Training loss: 1.4123022556304932
Validation loss: 1.970333109619797

Epoch: 6| Step: 8
Training loss: 0.8195891380310059
Validation loss: 1.9341262437963997

Epoch: 6| Step: 9
Training loss: 1.0705091953277588
Validation loss: 1.9142049845828806

Epoch: 6| Step: 10
Training loss: 1.811946153640747
Validation loss: 1.9476233220869494

Epoch: 6| Step: 11
Training loss: 1.6004983186721802
Validation loss: 1.9114427181982225

Epoch: 6| Step: 12
Training loss: 2.089813709259033
Validation loss: 1.9342200012617214

Epoch: 6| Step: 13
Training loss: 1.4529598951339722
Validation loss: 1.8724978828942904

Epoch: 361| Step: 0
Training loss: 1.5644162893295288
Validation loss: 1.8542569004079348

Epoch: 6| Step: 1
Training loss: 0.993882954120636
Validation loss: 1.8573776432262954

Epoch: 6| Step: 2
Training loss: 1.0843327045440674
Validation loss: 1.9309781020687473

Epoch: 6| Step: 3
Training loss: 2.0675318241119385
Validation loss: 1.9397552231306672

Epoch: 6| Step: 4
Training loss: 1.3612767457962036
Validation loss: 1.8516623358572684

Epoch: 6| Step: 5
Training loss: 1.4466822147369385
Validation loss: 1.9410550786602883

Epoch: 6| Step: 6
Training loss: 1.3821630477905273
Validation loss: 1.9531407676717287

Epoch: 6| Step: 7
Training loss: 1.330755352973938
Validation loss: 1.937260755928614

Epoch: 6| Step: 8
Training loss: 1.4934742450714111
Validation loss: 1.892820257012562

Epoch: 6| Step: 9
Training loss: 1.6351919174194336
Validation loss: 1.9527125896946076

Epoch: 6| Step: 10
Training loss: 1.1436200141906738
Validation loss: 1.841303853578465

Epoch: 6| Step: 11
Training loss: 1.727409839630127
Validation loss: 1.8993417127158052

Epoch: 6| Step: 12
Training loss: 0.8376799821853638
Validation loss: 1.9442319305994178

Epoch: 6| Step: 13
Training loss: 1.5798933506011963
Validation loss: 1.9499428990066692

Epoch: 362| Step: 0
Training loss: 1.549239158630371
Validation loss: 1.8902325925006662

Epoch: 6| Step: 1
Training loss: 1.843820571899414
Validation loss: 1.991089609361464

Epoch: 6| Step: 2
Training loss: 1.0880461931228638
Validation loss: 1.8777127676112677

Epoch: 6| Step: 3
Training loss: 1.2395460605621338
Validation loss: 1.9133122941499114

Epoch: 6| Step: 4
Training loss: 0.9249056577682495
Validation loss: 1.8844610055287678

Epoch: 6| Step: 5
Training loss: 1.3642864227294922
Validation loss: 1.9257158476819274

Epoch: 6| Step: 6
Training loss: 1.802030086517334
Validation loss: 1.9021497618767522

Epoch: 6| Step: 7
Training loss: 1.7979907989501953
Validation loss: 1.931534041640579

Epoch: 6| Step: 8
Training loss: 1.6649688482284546
Validation loss: 1.9085029658450876

Epoch: 6| Step: 9
Training loss: 1.6169006824493408
Validation loss: 1.8667287929083711

Epoch: 6| Step: 10
Training loss: 1.10810387134552
Validation loss: 1.862311734948107

Epoch: 6| Step: 11
Training loss: 1.0927433967590332
Validation loss: 1.8248741024283952

Epoch: 6| Step: 12
Training loss: 1.811584711074829
Validation loss: 1.9589680625546364

Epoch: 6| Step: 13
Training loss: 1.2382699251174927
Validation loss: 1.9095952600561164

Epoch: 363| Step: 0
Training loss: 1.2855656147003174
Validation loss: 1.8804590138055945

Epoch: 6| Step: 1
Training loss: 1.1302764415740967
Validation loss: 1.910329416234006

Epoch: 6| Step: 2
Training loss: 1.3367408514022827
Validation loss: 1.8692280528365925

Epoch: 6| Step: 3
Training loss: 1.3035064935684204
Validation loss: 1.8608349856509958

Epoch: 6| Step: 4
Training loss: 1.7173290252685547
Validation loss: 1.963156178433408

Epoch: 6| Step: 5
Training loss: 1.829466700553894
Validation loss: 2.006551704099101

Epoch: 6| Step: 6
Training loss: 1.6091821193695068
Validation loss: 1.8954236007505847

Epoch: 6| Step: 7
Training loss: 1.3332006931304932
Validation loss: 1.9726492358792214

Epoch: 6| Step: 8
Training loss: 1.4274420738220215
Validation loss: 1.9572070875475485

Epoch: 6| Step: 9
Training loss: 1.354081630706787
Validation loss: 1.9210350423730829

Epoch: 6| Step: 10
Training loss: 1.6732404232025146
Validation loss: 1.9486694784574612

Epoch: 6| Step: 11
Training loss: 1.4965898990631104
Validation loss: 1.9484417015506375

Epoch: 6| Step: 12
Training loss: 1.3957269191741943
Validation loss: 1.915553085265621

Epoch: 6| Step: 13
Training loss: 1.7527996301651
Validation loss: 1.951533240656699

Epoch: 364| Step: 0
Training loss: 1.1870490312576294
Validation loss: 2.0021119297191663

Epoch: 6| Step: 1
Training loss: 1.5755784511566162
Validation loss: 1.891896108145355

Epoch: 6| Step: 2
Training loss: 1.2415499687194824
Validation loss: 1.8624674017711351

Epoch: 6| Step: 3
Training loss: 1.7256731986999512
Validation loss: 1.9442923889365247

Epoch: 6| Step: 4
Training loss: 0.9668181538581848
Validation loss: 1.87863661396888

Epoch: 6| Step: 5
Training loss: 1.511991024017334
Validation loss: 1.9150606188722836

Epoch: 6| Step: 6
Training loss: 1.2588165998458862
Validation loss: 1.9006944523062757

Epoch: 6| Step: 7
Training loss: 1.5119574069976807
Validation loss: 1.9370592653110463

Epoch: 6| Step: 8
Training loss: 1.4368007183074951
Validation loss: 1.9137943098621983

Epoch: 6| Step: 9
Training loss: 1.5193123817443848
Validation loss: 1.8490218975210702

Epoch: 6| Step: 10
Training loss: 2.0542359352111816
Validation loss: 1.9326421253142818

Epoch: 6| Step: 11
Training loss: 1.628309726715088
Validation loss: 1.9136685094525736

Epoch: 6| Step: 12
Training loss: 1.4666893482208252
Validation loss: 1.8568495550463278

Epoch: 6| Step: 13
Training loss: 1.144981861114502
Validation loss: 1.935704308171426

Epoch: 365| Step: 0
Training loss: 1.5290796756744385
Validation loss: 1.9625329279130506

Epoch: 6| Step: 1
Training loss: 1.4707531929016113
Validation loss: 1.9398915767669678

Epoch: 6| Step: 2
Training loss: 1.0140858888626099
Validation loss: 1.9229844590669036

Epoch: 6| Step: 3
Training loss: 1.4533686637878418
Validation loss: 1.8939125460963095

Epoch: 6| Step: 4
Training loss: 1.5701234340667725
Validation loss: 1.9221219260205504

Epoch: 6| Step: 5
Training loss: 1.8646475076675415
Validation loss: 1.9743278462399718

Epoch: 6| Step: 6
Training loss: 1.4774901866912842
Validation loss: 1.9925511139695362

Epoch: 6| Step: 7
Training loss: 1.1416873931884766
Validation loss: 1.9037363093386415

Epoch: 6| Step: 8
Training loss: 1.3023276329040527
Validation loss: 1.8786507075832737

Epoch: 6| Step: 9
Training loss: 1.3685078620910645
Validation loss: 1.8716276217532415

Epoch: 6| Step: 10
Training loss: 1.8498499393463135
Validation loss: 1.9050104976982198

Epoch: 6| Step: 11
Training loss: 2.018368721008301
Validation loss: 2.013019013148482

Epoch: 6| Step: 12
Training loss: 0.7529491186141968
Validation loss: 1.9367005491769442

Epoch: 6| Step: 13
Training loss: 1.6096844673156738
Validation loss: 1.9210241597185853

Epoch: 366| Step: 0
Training loss: 2.1459054946899414
Validation loss: 1.9506935304211033

Epoch: 6| Step: 1
Training loss: 1.1884448528289795
Validation loss: 1.9580977527044152

Epoch: 6| Step: 2
Training loss: 1.7236666679382324
Validation loss: 1.8996489868369153

Epoch: 6| Step: 3
Training loss: 1.4520018100738525
Validation loss: 1.9367426864562496

Epoch: 6| Step: 4
Training loss: 0.8510180711746216
Validation loss: 1.956222488034156

Epoch: 6| Step: 5
Training loss: 1.1823596954345703
Validation loss: 1.9586412419555008

Epoch: 6| Step: 6
Training loss: 1.6641968488693237
Validation loss: 1.9625818537127586

Epoch: 6| Step: 7
Training loss: 1.477051019668579
Validation loss: 1.8632766944105907

Epoch: 6| Step: 8
Training loss: 2.225029945373535
Validation loss: 1.8734069921637093

Epoch: 6| Step: 9
Training loss: 1.586702823638916
Validation loss: 1.8741853108970068

Epoch: 6| Step: 10
Training loss: 1.1840810775756836
Validation loss: 1.8180037724074496

Epoch: 6| Step: 11
Training loss: 1.0813382863998413
Validation loss: 1.9212317876918341

Epoch: 6| Step: 12
Training loss: 0.7910031080245972
Validation loss: 1.895850250797887

Epoch: 6| Step: 13
Training loss: 1.9440773725509644
Validation loss: 1.8721511030709872

Epoch: 367| Step: 0
Training loss: 1.971022605895996
Validation loss: 1.8878902773703299

Epoch: 6| Step: 1
Training loss: 1.326601505279541
Validation loss: 1.8400463545194237

Epoch: 6| Step: 2
Training loss: 0.6730340719223022
Validation loss: 1.921483370565599

Epoch: 6| Step: 3
Training loss: 1.4191312789916992
Validation loss: 1.8707438156168947

Epoch: 6| Step: 4
Training loss: 1.0992639064788818
Validation loss: 1.9012307031180269

Epoch: 6| Step: 5
Training loss: 1.5438783168792725
Validation loss: 1.9114642040703886

Epoch: 6| Step: 6
Training loss: 1.2333602905273438
Validation loss: 1.8659514752767419

Epoch: 6| Step: 7
Training loss: 1.1904230117797852
Validation loss: 1.8625294534108972

Epoch: 6| Step: 8
Training loss: 0.8919135332107544
Validation loss: 1.8891507156433598

Epoch: 6| Step: 9
Training loss: 1.8672326803207397
Validation loss: 2.0281707497053247

Epoch: 6| Step: 10
Training loss: 1.5013526678085327
Validation loss: 1.9740830672684537

Epoch: 6| Step: 11
Training loss: 2.0732452869415283
Validation loss: 1.9838547296421503

Epoch: 6| Step: 12
Training loss: 1.111727237701416
Validation loss: 2.042260221255723

Epoch: 6| Step: 13
Training loss: 1.7365398406982422
Validation loss: 1.9894279818381033

Epoch: 368| Step: 0
Training loss: 1.7807552814483643
Validation loss: 2.020938563090499

Epoch: 6| Step: 1
Training loss: 1.5933927297592163
Validation loss: 2.0148582586678128

Epoch: 6| Step: 2
Training loss: 0.8665784597396851
Validation loss: 1.9064842398448656

Epoch: 6| Step: 3
Training loss: 1.124483346939087
Validation loss: 2.008139838454544

Epoch: 6| Step: 4
Training loss: 0.7203378677368164
Validation loss: 1.9732955873653453

Epoch: 6| Step: 5
Training loss: 1.6833308935165405
Validation loss: 1.9107726645726029

Epoch: 6| Step: 6
Training loss: 1.5786153078079224
Validation loss: 1.9931538028101767

Epoch: 6| Step: 7
Training loss: 0.9932354688644409
Validation loss: 1.8377995478209628

Epoch: 6| Step: 8
Training loss: 1.5768744945526123
Validation loss: 1.9333822599021337

Epoch: 6| Step: 9
Training loss: 1.8414194583892822
Validation loss: 1.9507046566214612

Epoch: 6| Step: 10
Training loss: 1.4228798151016235
Validation loss: 1.9203993094864713

Epoch: 6| Step: 11
Training loss: 1.3070876598358154
Validation loss: 1.9551049573447115

Epoch: 6| Step: 12
Training loss: 1.6519036293029785
Validation loss: 1.9335224628448486

Epoch: 6| Step: 13
Training loss: 1.9102532863616943
Validation loss: 1.9230503625767206

Epoch: 369| Step: 0
Training loss: 1.3314968347549438
Validation loss: 1.9005306484878703

Epoch: 6| Step: 1
Training loss: 1.4316902160644531
Validation loss: 1.9064937406970608

Epoch: 6| Step: 2
Training loss: 1.4126414060592651
Validation loss: 1.8962227157367173

Epoch: 6| Step: 3
Training loss: 1.1589869260787964
Validation loss: 1.853948368821093

Epoch: 6| Step: 4
Training loss: 0.7715550661087036
Validation loss: 1.9111157309624456

Epoch: 6| Step: 5
Training loss: 1.8590717315673828
Validation loss: 1.871573491763043

Epoch: 6| Step: 6
Training loss: 1.6637468338012695
Validation loss: 1.921876004947129

Epoch: 6| Step: 7
Training loss: 1.2707163095474243
Validation loss: 1.9371321201324463

Epoch: 6| Step: 8
Training loss: 1.407394528388977
Validation loss: 1.9498968380753712

Epoch: 6| Step: 9
Training loss: 1.5231784582138062
Validation loss: 1.8924788275072653

Epoch: 6| Step: 10
Training loss: 1.7527333498001099
Validation loss: 1.903353045063634

Epoch: 6| Step: 11
Training loss: 1.763732671737671
Validation loss: 2.0140831726853565

Epoch: 6| Step: 12
Training loss: 1.2937355041503906
Validation loss: 1.9480929349058418

Epoch: 6| Step: 13
Training loss: 1.4552626609802246
Validation loss: 1.87312485325721

Epoch: 370| Step: 0
Training loss: 1.2996928691864014
Validation loss: 1.9089813706695393

Epoch: 6| Step: 1
Training loss: 1.7355127334594727
Validation loss: 1.9993234001180178

Epoch: 6| Step: 2
Training loss: 1.731518030166626
Validation loss: 1.9120968093154251

Epoch: 6| Step: 3
Training loss: 1.2861003875732422
Validation loss: 1.9661073941056446

Epoch: 6| Step: 4
Training loss: 0.8540366888046265
Validation loss: 1.9364999199426303

Epoch: 6| Step: 5
Training loss: 1.5594565868377686
Validation loss: 1.8853477175517748

Epoch: 6| Step: 6
Training loss: 1.3669805526733398
Validation loss: 1.9090068237755888

Epoch: 6| Step: 7
Training loss: 1.3422894477844238
Validation loss: 1.9580649945043749

Epoch: 6| Step: 8
Training loss: 1.5957221984863281
Validation loss: 1.9593697619694534

Epoch: 6| Step: 9
Training loss: 1.4508154392242432
Validation loss: 1.9085373288841658

Epoch: 6| Step: 10
Training loss: 1.0923672914505005
Validation loss: 1.9605708096617012

Epoch: 6| Step: 11
Training loss: 0.9695109724998474
Validation loss: 1.894755858246998

Epoch: 6| Step: 12
Training loss: 1.6198090314865112
Validation loss: 1.9109205712554276

Epoch: 6| Step: 13
Training loss: 1.6175867319107056
Validation loss: 1.9807476766647831

Epoch: 371| Step: 0
Training loss: 1.5086696147918701
Validation loss: 1.865524007428077

Epoch: 6| Step: 1
Training loss: 0.9453015327453613
Validation loss: 1.874913251528176

Epoch: 6| Step: 2
Training loss: 1.303880214691162
Validation loss: 1.9622534757019372

Epoch: 6| Step: 3
Training loss: 1.1124927997589111
Validation loss: 1.849407426772579

Epoch: 6| Step: 4
Training loss: 1.8835008144378662
Validation loss: 1.896688622813071

Epoch: 6| Step: 5
Training loss: 1.652580738067627
Validation loss: 1.9072516118326495

Epoch: 6| Step: 6
Training loss: 1.6155624389648438
Validation loss: 1.8936215626296176

Epoch: 6| Step: 7
Training loss: 1.4000787734985352
Validation loss: 1.9302797676414571

Epoch: 6| Step: 8
Training loss: 1.1252927780151367
Validation loss: 2.0162119480871383

Epoch: 6| Step: 9
Training loss: 1.1970692873001099
Validation loss: 2.042550881703695

Epoch: 6| Step: 10
Training loss: 1.502846121788025
Validation loss: 1.9723879162983229

Epoch: 6| Step: 11
Training loss: 1.3982778787612915
Validation loss: 1.9575083178858603

Epoch: 6| Step: 12
Training loss: 0.859980583190918
Validation loss: 1.9447133425743348

Epoch: 6| Step: 13
Training loss: 1.9930254220962524
Validation loss: 1.9506511406231952

Epoch: 372| Step: 0
Training loss: 1.1265016794204712
Validation loss: 1.9295537881953742

Epoch: 6| Step: 1
Training loss: 1.547343134880066
Validation loss: 1.9445378882910616

Epoch: 6| Step: 2
Training loss: 0.8201526999473572
Validation loss: 1.931924267481732

Epoch: 6| Step: 3
Training loss: 1.2261807918548584
Validation loss: 1.9044114364090787

Epoch: 6| Step: 4
Training loss: 1.857286810874939
Validation loss: 1.910937334901543

Epoch: 6| Step: 5
Training loss: 1.9962413311004639
Validation loss: 1.9105169644919775

Epoch: 6| Step: 6
Training loss: 1.0532317161560059
Validation loss: 1.9050337165914557

Epoch: 6| Step: 7
Training loss: 1.2511053085327148
Validation loss: 1.9240326650681034

Epoch: 6| Step: 8
Training loss: 1.7740216255187988
Validation loss: 1.955015267095258

Epoch: 6| Step: 9
Training loss: 1.3590099811553955
Validation loss: 2.0039846333124305

Epoch: 6| Step: 10
Training loss: 0.9746091365814209
Validation loss: 1.8758761639236121

Epoch: 6| Step: 11
Training loss: 2.2979793548583984
Validation loss: 1.874481229371922

Epoch: 6| Step: 12
Training loss: 0.9158222079277039
Validation loss: 1.9459253370120961

Epoch: 6| Step: 13
Training loss: 1.3544387817382812
Validation loss: 1.9295320715955508

Epoch: 373| Step: 0
Training loss: 1.8078460693359375
Validation loss: 1.8683210854889245

Epoch: 6| Step: 1
Training loss: 1.8637412786483765
Validation loss: 1.9681351389936221

Epoch: 6| Step: 2
Training loss: 1.0683850049972534
Validation loss: 1.9288184822246592

Epoch: 6| Step: 3
Training loss: 1.3715721368789673
Validation loss: 1.961499712800467

Epoch: 6| Step: 4
Training loss: 1.290698766708374
Validation loss: 1.8595906252502112

Epoch: 6| Step: 5
Training loss: 1.1232612133026123
Validation loss: 1.9466407375950967

Epoch: 6| Step: 6
Training loss: 1.4924894571304321
Validation loss: 1.921600116196499

Epoch: 6| Step: 7
Training loss: 1.9956943988800049
Validation loss: 1.935908939248772

Epoch: 6| Step: 8
Training loss: 1.3397725820541382
Validation loss: 1.8801890688557779

Epoch: 6| Step: 9
Training loss: 1.1697725057601929
Validation loss: 1.9220065634737733

Epoch: 6| Step: 10
Training loss: 1.1546666622161865
Validation loss: 1.949210041312761

Epoch: 6| Step: 11
Training loss: 1.7120776176452637
Validation loss: 1.7933871528153777

Epoch: 6| Step: 12
Training loss: 1.2545703649520874
Validation loss: 1.9043789743095316

Epoch: 6| Step: 13
Training loss: 1.4252545833587646
Validation loss: 1.9526044604598836

Epoch: 374| Step: 0
Training loss: 1.3719820976257324
Validation loss: 1.9352768851864723

Epoch: 6| Step: 1
Training loss: 0.9340130090713501
Validation loss: 1.9058251252738379

Epoch: 6| Step: 2
Training loss: 1.6665375232696533
Validation loss: 1.9001189816382624

Epoch: 6| Step: 3
Training loss: 1.3939778804779053
Validation loss: 1.9241894445111674

Epoch: 6| Step: 4
Training loss: 1.802085041999817
Validation loss: 1.7876296658669748

Epoch: 6| Step: 5
Training loss: 1.1253178119659424
Validation loss: 1.9391639053180654

Epoch: 6| Step: 6
Training loss: 0.5718371272087097
Validation loss: 1.9050656698083366

Epoch: 6| Step: 7
Training loss: 1.9477887153625488
Validation loss: 1.9569715402459587

Epoch: 6| Step: 8
Training loss: 2.2467057704925537
Validation loss: 1.8686803669057868

Epoch: 6| Step: 9
Training loss: 1.4800028800964355
Validation loss: 1.8938967848336825

Epoch: 6| Step: 10
Training loss: 1.1592079401016235
Validation loss: 1.9227010024491178

Epoch: 6| Step: 11
Training loss: 0.9396020174026489
Validation loss: 1.9468077331460931

Epoch: 6| Step: 12
Training loss: 1.6109724044799805
Validation loss: 1.8572588454010666

Epoch: 6| Step: 13
Training loss: 1.4368163347244263
Validation loss: 1.927745396091092

Epoch: 375| Step: 0
Training loss: 0.8389583230018616
Validation loss: 1.9610893751985283

Epoch: 6| Step: 1
Training loss: 1.4039671421051025
Validation loss: 1.9397916640004804

Epoch: 6| Step: 2
Training loss: 0.6150722503662109
Validation loss: 1.9073314794930079

Epoch: 6| Step: 3
Training loss: 1.5631954669952393
Validation loss: 1.951680201356129

Epoch: 6| Step: 4
Training loss: 1.5582656860351562
Validation loss: 1.9184201635340208

Epoch: 6| Step: 5
Training loss: 1.74940824508667
Validation loss: 1.9507280344604163

Epoch: 6| Step: 6
Training loss: 1.0980409383773804
Validation loss: 1.980959564126948

Epoch: 6| Step: 7
Training loss: 2.0833559036254883
Validation loss: 2.001142512085617

Epoch: 6| Step: 8
Training loss: 1.9328564405441284
Validation loss: 1.9739191685953448

Epoch: 6| Step: 9
Training loss: 0.6488596796989441
Validation loss: 1.8997631470362346

Epoch: 6| Step: 10
Training loss: 1.8368858098983765
Validation loss: 1.8868840202208488

Epoch: 6| Step: 11
Training loss: 1.621614933013916
Validation loss: 1.9130364502629926

Epoch: 6| Step: 12
Training loss: 1.6886720657348633
Validation loss: 1.938942660567581

Epoch: 6| Step: 13
Training loss: 0.9808424711227417
Validation loss: 1.9069786148686563

Epoch: 376| Step: 0
Training loss: 1.0601484775543213
Validation loss: 1.950174795683994

Epoch: 6| Step: 1
Training loss: 1.3257609605789185
Validation loss: 1.8471098228167462

Epoch: 6| Step: 2
Training loss: 1.821357011795044
Validation loss: 1.9056266905159078

Epoch: 6| Step: 3
Training loss: 1.180358648300171
Validation loss: 1.8745227859866234

Epoch: 6| Step: 4
Training loss: 1.0318341255187988
Validation loss: 1.9202313705157208

Epoch: 6| Step: 5
Training loss: 0.9071741104125977
Validation loss: 1.9263544249278244

Epoch: 6| Step: 6
Training loss: 1.5056180953979492
Validation loss: 1.965800472485122

Epoch: 6| Step: 7
Training loss: 0.9891688823699951
Validation loss: 1.8489913684065624

Epoch: 6| Step: 8
Training loss: 1.6557435989379883
Validation loss: 1.9376747069820281

Epoch: 6| Step: 9
Training loss: 1.7951619625091553
Validation loss: 1.8976972231300928

Epoch: 6| Step: 10
Training loss: 1.5826431512832642
Validation loss: 1.933263212121943

Epoch: 6| Step: 11
Training loss: 1.6629496812820435
Validation loss: 1.9586874695234402

Epoch: 6| Step: 12
Training loss: 1.1837918758392334
Validation loss: 1.9944882162155644

Epoch: 6| Step: 13
Training loss: 1.10684072971344
Validation loss: 1.8860768323303552

Epoch: 377| Step: 0
Training loss: 1.57438063621521
Validation loss: 1.9512812681095575

Epoch: 6| Step: 1
Training loss: 1.4847030639648438
Validation loss: 1.8866222443119172

Epoch: 6| Step: 2
Training loss: 1.1924519538879395
Validation loss: 1.9904134683711554

Epoch: 6| Step: 3
Training loss: 1.5891081094741821
Validation loss: 1.994132452113654

Epoch: 6| Step: 4
Training loss: 1.6923003196716309
Validation loss: 1.9670615619228733

Epoch: 6| Step: 5
Training loss: 0.9861634969711304
Validation loss: 1.960508224784687

Epoch: 6| Step: 6
Training loss: 0.9815689325332642
Validation loss: 1.9383914342490576

Epoch: 6| Step: 7
Training loss: 1.6662123203277588
Validation loss: 1.992808767544326

Epoch: 6| Step: 8
Training loss: 1.6347098350524902
Validation loss: 1.929081210526087

Epoch: 6| Step: 9
Training loss: 1.5847338438034058
Validation loss: 1.869138063923005

Epoch: 6| Step: 10
Training loss: 1.0988805294036865
Validation loss: 1.9386741089564499

Epoch: 6| Step: 11
Training loss: 1.2977211475372314
Validation loss: 1.9377253850301106

Epoch: 6| Step: 12
Training loss: 1.7422455549240112
Validation loss: 1.993029107329666

Epoch: 6| Step: 13
Training loss: 1.7151786088943481
Validation loss: 1.9282646935473207

Epoch: 378| Step: 0
Training loss: 0.7740485072135925
Validation loss: 1.9984750414407382

Epoch: 6| Step: 1
Training loss: 1.4511946439743042
Validation loss: 1.8871353800578783

Epoch: 6| Step: 2
Training loss: 1.7669202089309692
Validation loss: 2.016139171456778

Epoch: 6| Step: 3
Training loss: 1.0273085832595825
Validation loss: 1.9069973448271393

Epoch: 6| Step: 4
Training loss: 1.0403708219528198
Validation loss: 1.8834432889056463

Epoch: 6| Step: 5
Training loss: 0.9080267548561096
Validation loss: 1.9012545385668356

Epoch: 6| Step: 6
Training loss: 1.6947605609893799
Validation loss: 1.842624875806993

Epoch: 6| Step: 7
Training loss: 2.0818374156951904
Validation loss: 1.9028071767540389

Epoch: 6| Step: 8
Training loss: 1.6682989597320557
Validation loss: 1.9107368966584564

Epoch: 6| Step: 9
Training loss: 1.3475944995880127
Validation loss: 1.8882183374897126

Epoch: 6| Step: 10
Training loss: 1.1190361976623535
Validation loss: 1.8784866089461951

Epoch: 6| Step: 11
Training loss: 1.5058741569519043
Validation loss: 1.9085815183577999

Epoch: 6| Step: 12
Training loss: 1.4173038005828857
Validation loss: 1.9766673054746402

Epoch: 6| Step: 13
Training loss: 1.129844069480896
Validation loss: 1.9212270116293302

Epoch: 379| Step: 0
Training loss: 1.6326751708984375
Validation loss: 1.8638113955015778

Epoch: 6| Step: 1
Training loss: 1.231661319732666
Validation loss: 1.9116157665047595

Epoch: 6| Step: 2
Training loss: 1.641073226928711
Validation loss: 1.9435465194845711

Epoch: 6| Step: 3
Training loss: 1.2157516479492188
Validation loss: 1.8227180101538216

Epoch: 6| Step: 4
Training loss: 1.2622151374816895
Validation loss: 1.9937662616852792

Epoch: 6| Step: 5
Training loss: 1.3045334815979004
Validation loss: 1.8335569045876945

Epoch: 6| Step: 6
Training loss: 1.363637924194336
Validation loss: 2.037334580575266

Epoch: 6| Step: 7
Training loss: 1.430527925491333
Validation loss: 1.9002261495077482

Epoch: 6| Step: 8
Training loss: 1.296892762184143
Validation loss: 1.9358832887423936

Epoch: 6| Step: 9
Training loss: 1.3888163566589355
Validation loss: 1.9338836926285938

Epoch: 6| Step: 10
Training loss: 1.8513742685317993
Validation loss: 1.9163356506696312

Epoch: 6| Step: 11
Training loss: 1.4814856052398682
Validation loss: 1.9362533169407998

Epoch: 6| Step: 12
Training loss: 1.174447774887085
Validation loss: 1.9075851440429688

Epoch: 6| Step: 13
Training loss: 1.180916428565979
Validation loss: 1.8824868202209473

Epoch: 380| Step: 0
Training loss: 1.0035521984100342
Validation loss: 1.8820611879389773

Epoch: 6| Step: 1
Training loss: 2.268242120742798
Validation loss: 1.917302954581476

Epoch: 6| Step: 2
Training loss: 1.182268738746643
Validation loss: 1.9071906176946496

Epoch: 6| Step: 3
Training loss: 1.4789153337478638
Validation loss: 1.8566101571565032

Epoch: 6| Step: 4
Training loss: 1.2728543281555176
Validation loss: 1.960346524433423

Epoch: 6| Step: 5
Training loss: 1.594494342803955
Validation loss: 1.9633456789037234

Epoch: 6| Step: 6
Training loss: 1.456179141998291
Validation loss: 1.9986322849027571

Epoch: 6| Step: 7
Training loss: 1.0768022537231445
Validation loss: 1.9564131177881712

Epoch: 6| Step: 8
Training loss: 1.0317940711975098
Validation loss: 2.008731702322601

Epoch: 6| Step: 9
Training loss: 1.1089274883270264
Validation loss: 2.014493760242257

Epoch: 6| Step: 10
Training loss: 2.0614476203918457
Validation loss: 2.0437782041488157

Epoch: 6| Step: 11
Training loss: 1.1959174871444702
Validation loss: 1.9202825843646962

Epoch: 6| Step: 12
Training loss: 2.1391825675964355
Validation loss: 1.9871463006542576

Epoch: 6| Step: 13
Training loss: 1.4087966680526733
Validation loss: 1.963767784897999

Epoch: 381| Step: 0
Training loss: 1.6868529319763184
Validation loss: 2.0346827583928264

Epoch: 6| Step: 1
Training loss: 1.6455250978469849
Validation loss: 2.010960109772221

Epoch: 6| Step: 2
Training loss: 1.58432936668396
Validation loss: 1.9036791375888291

Epoch: 6| Step: 3
Training loss: 0.9555124044418335
Validation loss: 1.9267933266137236

Epoch: 6| Step: 4
Training loss: 1.0630370378494263
Validation loss: 1.9839797583959435

Epoch: 6| Step: 5
Training loss: 0.8672889471054077
Validation loss: 1.8401712345820602

Epoch: 6| Step: 6
Training loss: 1.452759027481079
Validation loss: 1.8843545593241209

Epoch: 6| Step: 7
Training loss: 1.7277991771697998
Validation loss: 1.9402407779488513

Epoch: 6| Step: 8
Training loss: 1.3611774444580078
Validation loss: 1.9234724403709493

Epoch: 6| Step: 9
Training loss: 1.9634400606155396
Validation loss: 1.9267754631657754

Epoch: 6| Step: 10
Training loss: 1.20377779006958
Validation loss: 1.9040305409380185

Epoch: 6| Step: 11
Training loss: 1.7170841693878174
Validation loss: 1.8921187539254465

Epoch: 6| Step: 12
Training loss: 1.8497164249420166
Validation loss: 2.0025816502109652

Epoch: 6| Step: 13
Training loss: 1.5201008319854736
Validation loss: 1.9398080187459146

Epoch: 382| Step: 0
Training loss: 1.3389358520507812
Validation loss: 1.8832409010138562

Epoch: 6| Step: 1
Training loss: 0.9686482548713684
Validation loss: 1.9507554167060441

Epoch: 6| Step: 2
Training loss: 0.9583985805511475
Validation loss: 1.8719194319940382

Epoch: 6| Step: 3
Training loss: 1.5350708961486816
Validation loss: 1.9925683647073724

Epoch: 6| Step: 4
Training loss: 2.0723459720611572
Validation loss: 1.9932457221451627

Epoch: 6| Step: 5
Training loss: 1.6335147619247437
Validation loss: 1.9500888009225168

Epoch: 6| Step: 6
Training loss: 1.3592689037322998
Validation loss: 2.0326700902754262

Epoch: 6| Step: 7
Training loss: 0.9334394335746765
Validation loss: 2.0947819166286017

Epoch: 6| Step: 8
Training loss: 1.1091910600662231
Validation loss: 1.9409692287445068

Epoch: 6| Step: 9
Training loss: 1.2039241790771484
Validation loss: 1.9646949306611092

Epoch: 6| Step: 10
Training loss: 1.3731815814971924
Validation loss: 1.9959884484608967

Epoch: 6| Step: 11
Training loss: 1.1303315162658691
Validation loss: 1.9710421536558418

Epoch: 6| Step: 12
Training loss: 2.0915470123291016
Validation loss: 1.9989141494997087

Epoch: 6| Step: 13
Training loss: 2.340378522872925
Validation loss: 1.978476450007449

Epoch: 383| Step: 0
Training loss: 1.7934648990631104
Validation loss: 1.922502407463648

Epoch: 6| Step: 1
Training loss: 1.349642038345337
Validation loss: 1.9258916083202566

Epoch: 6| Step: 2
Training loss: 1.4931098222732544
Validation loss: 1.9357510074492423

Epoch: 6| Step: 3
Training loss: 1.0391170978546143
Validation loss: 1.9004410518113004

Epoch: 6| Step: 4
Training loss: 1.3949941396713257
Validation loss: 1.9251700498724496

Epoch: 6| Step: 5
Training loss: 1.3117663860321045
Validation loss: 2.0061046923360517

Epoch: 6| Step: 6
Training loss: 2.209639072418213
Validation loss: 1.911128419701771

Epoch: 6| Step: 7
Training loss: 1.206176519393921
Validation loss: 1.9322747479202926

Epoch: 6| Step: 8
Training loss: 0.8186588287353516
Validation loss: 1.9578124143744027

Epoch: 6| Step: 9
Training loss: 1.8281080722808838
Validation loss: 1.8882828348426408

Epoch: 6| Step: 10
Training loss: 1.702343225479126
Validation loss: 1.9633785640039751

Epoch: 6| Step: 11
Training loss: 1.0313241481781006
Validation loss: 1.914381932186824

Epoch: 6| Step: 12
Training loss: 0.9156339168548584
Validation loss: 1.9391090036720358

Epoch: 6| Step: 13
Training loss: 1.5076947212219238
Validation loss: 1.9773381140924269

Epoch: 384| Step: 0
Training loss: 1.3184130191802979
Validation loss: 1.9274999390366256

Epoch: 6| Step: 1
Training loss: 1.171677589416504
Validation loss: 1.8749878829525364

Epoch: 6| Step: 2
Training loss: 1.2417869567871094
Validation loss: 2.0211974715673797

Epoch: 6| Step: 3
Training loss: 1.9176195859909058
Validation loss: 2.0002577253567275

Epoch: 6| Step: 4
Training loss: 1.6796729564666748
Validation loss: 1.9684784604657082

Epoch: 6| Step: 5
Training loss: 2.0209054946899414
Validation loss: 1.953983026166116

Epoch: 6| Step: 6
Training loss: 1.06351637840271
Validation loss: 1.872936838416643

Epoch: 6| Step: 7
Training loss: 1.6398112773895264
Validation loss: 1.8449246319391395

Epoch: 6| Step: 8
Training loss: 1.0407369136810303
Validation loss: 1.900033902096492

Epoch: 6| Step: 9
Training loss: 1.619492530822754
Validation loss: 1.9066832962856497

Epoch: 6| Step: 10
Training loss: 1.6395392417907715
Validation loss: 1.8428901882581814

Epoch: 6| Step: 11
Training loss: 1.0227367877960205
Validation loss: 1.9307467360650339

Epoch: 6| Step: 12
Training loss: 1.4006531238555908
Validation loss: 1.9457561598029187

Epoch: 6| Step: 13
Training loss: 0.5672919750213623
Validation loss: 1.9389672689540411

Epoch: 385| Step: 0
Training loss: 1.2083511352539062
Validation loss: 1.9562048501865839

Epoch: 6| Step: 1
Training loss: 1.3788989782333374
Validation loss: 1.9105502149110198

Epoch: 6| Step: 2
Training loss: 1.107035756111145
Validation loss: 1.9514097962328183

Epoch: 6| Step: 3
Training loss: 1.0977835655212402
Validation loss: 1.8670484327500867

Epoch: 6| Step: 4
Training loss: 1.6035034656524658
Validation loss: 1.9779630540519633

Epoch: 6| Step: 5
Training loss: 1.1636834144592285
Validation loss: 1.9384571275403422

Epoch: 6| Step: 6
Training loss: 1.078948736190796
Validation loss: 1.9291379785024991

Epoch: 6| Step: 7
Training loss: 1.4338221549987793
Validation loss: 1.9768255192746398

Epoch: 6| Step: 8
Training loss: 1.7831413745880127
Validation loss: 1.9343851612460228

Epoch: 6| Step: 9
Training loss: 1.6163628101348877
Validation loss: 1.898614550149569

Epoch: 6| Step: 10
Training loss: 1.6048486232757568
Validation loss: 1.9218882309493197

Epoch: 6| Step: 11
Training loss: 1.6405134201049805
Validation loss: 1.9910666775959793

Epoch: 6| Step: 12
Training loss: 1.2737061977386475
Validation loss: 1.981972687987871

Epoch: 6| Step: 13
Training loss: 0.9623549580574036
Validation loss: 1.9111420467335691

Epoch: 386| Step: 0
Training loss: 1.2907451391220093
Validation loss: 1.8894230601608113

Epoch: 6| Step: 1
Training loss: 1.4134130477905273
Validation loss: 1.9272410869598389

Epoch: 6| Step: 2
Training loss: 1.6923611164093018
Validation loss: 1.8899754247357767

Epoch: 6| Step: 3
Training loss: 1.2108098268508911
Validation loss: 1.911624800774359

Epoch: 6| Step: 4
Training loss: 1.4678908586502075
Validation loss: 1.9329237297017088

Epoch: 6| Step: 5
Training loss: 0.8963952660560608
Validation loss: 1.9052446478156633

Epoch: 6| Step: 6
Training loss: 1.293444037437439
Validation loss: 1.944945050824073

Epoch: 6| Step: 7
Training loss: 1.0803937911987305
Validation loss: 1.917549394792126

Epoch: 6| Step: 8
Training loss: 1.2776354551315308
Validation loss: 1.893634368014592

Epoch: 6| Step: 9
Training loss: 1.6157548427581787
Validation loss: 1.8867727633445495

Epoch: 6| Step: 10
Training loss: 1.6260440349578857
Validation loss: 1.8885611462336716

Epoch: 6| Step: 11
Training loss: 1.522080898284912
Validation loss: 1.9440699546567854

Epoch: 6| Step: 12
Training loss: 1.388934850692749
Validation loss: 1.9363713443920176

Epoch: 6| Step: 13
Training loss: 2.288468599319458
Validation loss: 1.8613312090596845

Epoch: 387| Step: 0
Training loss: 1.6383659839630127
Validation loss: 1.9604489252131472

Epoch: 6| Step: 1
Training loss: 1.2433422803878784
Validation loss: 1.9160932981839744

Epoch: 6| Step: 2
Training loss: 1.530968189239502
Validation loss: 1.9323654815714846

Epoch: 6| Step: 3
Training loss: 1.514791488647461
Validation loss: 1.9075630967335035

Epoch: 6| Step: 4
Training loss: 1.3318910598754883
Validation loss: 1.9146302957688608

Epoch: 6| Step: 5
Training loss: 0.9872470498085022
Validation loss: 1.930487891679169

Epoch: 6| Step: 6
Training loss: 1.4568722248077393
Validation loss: 1.872016409391998

Epoch: 6| Step: 7
Training loss: 0.9466367363929749
Validation loss: 1.9334990234785183

Epoch: 6| Step: 8
Training loss: 1.2654645442962646
Validation loss: 1.9458930697492374

Epoch: 6| Step: 9
Training loss: 1.456971526145935
Validation loss: 1.8373160541698497

Epoch: 6| Step: 10
Training loss: 1.2573868036270142
Validation loss: 1.9060892828049198

Epoch: 6| Step: 11
Training loss: 1.4610209465026855
Validation loss: 1.9133766299934798

Epoch: 6| Step: 12
Training loss: 1.5766167640686035
Validation loss: 1.9561581701360724

Epoch: 6| Step: 13
Training loss: 0.6163403987884521
Validation loss: 1.9325694012385544

Epoch: 388| Step: 0
Training loss: 1.278764009475708
Validation loss: 1.9269550641377766

Epoch: 6| Step: 1
Training loss: 0.8277971148490906
Validation loss: 1.8925001762246574

Epoch: 6| Step: 2
Training loss: 1.11045503616333
Validation loss: 1.959547863211683

Epoch: 6| Step: 3
Training loss: 1.2470636367797852
Validation loss: 2.0053928885408627

Epoch: 6| Step: 4
Training loss: 1.4186031818389893
Validation loss: 1.9511065303638417

Epoch: 6| Step: 5
Training loss: 1.8901011943817139
Validation loss: 1.9057320023095736

Epoch: 6| Step: 6
Training loss: 1.1476716995239258
Validation loss: 1.8645025722442135

Epoch: 6| Step: 7
Training loss: 1.5889455080032349
Validation loss: 1.9035398485840007

Epoch: 6| Step: 8
Training loss: 1.6273307800292969
Validation loss: 2.0057266117424093

Epoch: 6| Step: 9
Training loss: 1.3442182540893555
Validation loss: 1.9173000653584797

Epoch: 6| Step: 10
Training loss: 1.1854619979858398
Validation loss: 1.9416877531236219

Epoch: 6| Step: 11
Training loss: 1.9595832824707031
Validation loss: 1.9147878231540802

Epoch: 6| Step: 12
Training loss: 1.0946680307388306
Validation loss: 1.8418252198926863

Epoch: 6| Step: 13
Training loss: 1.575843334197998
Validation loss: 1.9583461989638626

Epoch: 389| Step: 0
Training loss: 1.1798818111419678
Validation loss: 1.918536240054715

Epoch: 6| Step: 1
Training loss: 1.5189263820648193
Validation loss: 1.89254472332616

Epoch: 6| Step: 2
Training loss: 1.445483684539795
Validation loss: 1.858173180651921

Epoch: 6| Step: 3
Training loss: 1.2891805171966553
Validation loss: 1.8471467341146162

Epoch: 6| Step: 4
Training loss: 1.0323495864868164
Validation loss: 1.9640864633744763

Epoch: 6| Step: 5
Training loss: 1.3011654615402222
Validation loss: 1.904868000297136

Epoch: 6| Step: 6
Training loss: 1.7938928604125977
Validation loss: 1.9214535015885548

Epoch: 6| Step: 7
Training loss: 1.392486333847046
Validation loss: 1.9518891944680163

Epoch: 6| Step: 8
Training loss: 1.4446964263916016
Validation loss: 1.8590368083728257

Epoch: 6| Step: 9
Training loss: 1.6265588998794556
Validation loss: 1.9339394543760566

Epoch: 6| Step: 10
Training loss: 1.4974799156188965
Validation loss: 1.9219036435568204

Epoch: 6| Step: 11
Training loss: 0.968514084815979
Validation loss: 1.8842585445732198

Epoch: 6| Step: 12
Training loss: 1.8532366752624512
Validation loss: 1.9250600530255226

Epoch: 6| Step: 13
Training loss: 0.7888054251670837
Validation loss: 1.9217732721759426

Epoch: 390| Step: 0
Training loss: 0.9412659406661987
Validation loss: 1.8487884793230283

Epoch: 6| Step: 1
Training loss: 0.5924379825592041
Validation loss: 1.9937723990409606

Epoch: 6| Step: 2
Training loss: 1.2868181467056274
Validation loss: 1.903552742414577

Epoch: 6| Step: 3
Training loss: 1.4596598148345947
Validation loss: 1.9156277641173332

Epoch: 6| Step: 4
Training loss: 1.752120018005371
Validation loss: 1.9248805379354825

Epoch: 6| Step: 5
Training loss: 0.8939666152000427
Validation loss: 1.9074594013152584

Epoch: 6| Step: 6
Training loss: 1.604438066482544
Validation loss: 1.9273919187566286

Epoch: 6| Step: 7
Training loss: 1.7718961238861084
Validation loss: 1.9190501218201013

Epoch: 6| Step: 8
Training loss: 1.3949072360992432
Validation loss: 1.9546550294404388

Epoch: 6| Step: 9
Training loss: 2.263070583343506
Validation loss: 1.8631546548617783

Epoch: 6| Step: 10
Training loss: 0.5690439343452454
Validation loss: 1.9893736441930134

Epoch: 6| Step: 11
Training loss: 1.5123523473739624
Validation loss: 1.9451683695598314

Epoch: 6| Step: 12
Training loss: 1.5965148210525513
Validation loss: 1.9257232399397

Epoch: 6| Step: 13
Training loss: 1.0120000839233398
Validation loss: 2.017307840367799

Epoch: 391| Step: 0
Training loss: 2.2701797485351562
Validation loss: 1.862108128045195

Epoch: 6| Step: 1
Training loss: 1.021833062171936
Validation loss: 1.920140794528428

Epoch: 6| Step: 2
Training loss: 1.1965956687927246
Validation loss: 1.9571661641520839

Epoch: 6| Step: 3
Training loss: 1.2080457210540771
Validation loss: 1.9454276664282686

Epoch: 6| Step: 4
Training loss: 1.5290727615356445
Validation loss: 1.9456498302439207

Epoch: 6| Step: 5
Training loss: 1.369696855545044
Validation loss: 1.8881186182780931

Epoch: 6| Step: 6
Training loss: 1.4460543394088745
Validation loss: 1.9272495815830846

Epoch: 6| Step: 7
Training loss: 1.291820764541626
Validation loss: 1.9422722144793438

Epoch: 6| Step: 8
Training loss: 1.0518556833267212
Validation loss: 1.920963453990157

Epoch: 6| Step: 9
Training loss: 1.0717817544937134
Validation loss: 2.063060352879186

Epoch: 6| Step: 10
Training loss: 1.6316392421722412
Validation loss: 1.9834612108046008

Epoch: 6| Step: 11
Training loss: 1.5785984992980957
Validation loss: 1.8770379430504256

Epoch: 6| Step: 12
Training loss: 1.009011149406433
Validation loss: 1.9507905898555633

Epoch: 6| Step: 13
Training loss: 1.3822288513183594
Validation loss: 1.9610223462504726

Epoch: 392| Step: 0
Training loss: 1.3385543823242188
Validation loss: 1.8801595857066493

Epoch: 6| Step: 1
Training loss: 1.4473590850830078
Validation loss: 1.9967770217567362

Epoch: 6| Step: 2
Training loss: 1.525028109550476
Validation loss: 1.9128728425630959

Epoch: 6| Step: 3
Training loss: 1.9688273668289185
Validation loss: 1.8974026890211209

Epoch: 6| Step: 4
Training loss: 1.2238227128982544
Validation loss: 1.909196965156063

Epoch: 6| Step: 5
Training loss: 2.1146814823150635
Validation loss: 1.8856233153291928

Epoch: 6| Step: 6
Training loss: 1.7151379585266113
Validation loss: 1.8882024185631865

Epoch: 6| Step: 7
Training loss: 0.8824543356895447
Validation loss: 1.9277840634827972

Epoch: 6| Step: 8
Training loss: 0.8649195432662964
Validation loss: 1.8081517168270644

Epoch: 6| Step: 9
Training loss: 1.0258129835128784
Validation loss: 1.848658730906825

Epoch: 6| Step: 10
Training loss: 1.4700108766555786
Validation loss: 1.9691099210452008

Epoch: 6| Step: 11
Training loss: 1.791885256767273
Validation loss: 2.012846480133713

Epoch: 6| Step: 12
Training loss: 0.9925214648246765
Validation loss: 1.8525388625360304

Epoch: 6| Step: 13
Training loss: 1.1680291891098022
Validation loss: 1.9438874311344598

Epoch: 393| Step: 0
Training loss: 1.759384036064148
Validation loss: 1.9339653215100687

Epoch: 6| Step: 1
Training loss: 1.5584802627563477
Validation loss: 1.9478113446184384

Epoch: 6| Step: 2
Training loss: 1.1641154289245605
Validation loss: 1.8889199995225476

Epoch: 6| Step: 3
Training loss: 1.9892239570617676
Validation loss: 1.9382733971841875

Epoch: 6| Step: 4
Training loss: 1.2775285243988037
Validation loss: 1.936185891910266

Epoch: 6| Step: 5
Training loss: 0.8184328079223633
Validation loss: 1.947767489699907

Epoch: 6| Step: 6
Training loss: 1.0429960489273071
Validation loss: 1.9591126108682284

Epoch: 6| Step: 7
Training loss: 1.0541410446166992
Validation loss: 1.9677195292647167

Epoch: 6| Step: 8
Training loss: 1.7420015335083008
Validation loss: 1.943291720523629

Epoch: 6| Step: 9
Training loss: 0.7732197046279907
Validation loss: 1.9872343629919074

Epoch: 6| Step: 10
Training loss: 1.4392695426940918
Validation loss: 1.9223107266169723

Epoch: 6| Step: 11
Training loss: 1.661904215812683
Validation loss: 1.872663474852039

Epoch: 6| Step: 12
Training loss: 1.866530179977417
Validation loss: 1.9289410345015987

Epoch: 6| Step: 13
Training loss: 0.9667768478393555
Validation loss: 1.9121756771559357

Epoch: 394| Step: 0
Training loss: 1.1774578094482422
Validation loss: 1.929914677014915

Epoch: 6| Step: 1
Training loss: 1.0810790061950684
Validation loss: 1.9712157941633655

Epoch: 6| Step: 2
Training loss: 1.4510407447814941
Validation loss: 1.9160063715391262

Epoch: 6| Step: 3
Training loss: 1.506758451461792
Validation loss: 1.9657192948043987

Epoch: 6| Step: 4
Training loss: 1.1493901014328003
Validation loss: 1.8853490544903664

Epoch: 6| Step: 5
Training loss: 1.6742541790008545
Validation loss: 1.935668594093733

Epoch: 6| Step: 6
Training loss: 1.3567776679992676
Validation loss: 1.8689818048989901

Epoch: 6| Step: 7
Training loss: 1.2451043128967285
Validation loss: 1.9201146569303287

Epoch: 6| Step: 8
Training loss: 1.1629583835601807
Validation loss: 1.8766297294247536

Epoch: 6| Step: 9
Training loss: 1.2097249031066895
Validation loss: 1.9161286738611036

Epoch: 6| Step: 10
Training loss: 1.669555902481079
Validation loss: 1.8481111116306757

Epoch: 6| Step: 11
Training loss: 1.3734562397003174
Validation loss: 1.886907696723938

Epoch: 6| Step: 12
Training loss: 1.6348481178283691
Validation loss: 1.9584459489391697

Epoch: 6| Step: 13
Training loss: 1.214298963546753
Validation loss: 1.9524456249770297

Epoch: 395| Step: 0
Training loss: 1.2302860021591187
Validation loss: 1.913218113683885

Epoch: 6| Step: 1
Training loss: 1.5289438962936401
Validation loss: 1.9469788036038798

Epoch: 6| Step: 2
Training loss: 1.4405349493026733
Validation loss: 1.9584787084210304

Epoch: 6| Step: 3
Training loss: 1.6606796979904175
Validation loss: 1.8925022335462673

Epoch: 6| Step: 4
Training loss: 1.7206707000732422
Validation loss: 1.938325894776211

Epoch: 6| Step: 5
Training loss: 1.2662768363952637
Validation loss: 1.9690096660326886

Epoch: 6| Step: 6
Training loss: 1.2164828777313232
Validation loss: 1.9231524749468731

Epoch: 6| Step: 7
Training loss: 1.223902702331543
Validation loss: 1.9818361010602725

Epoch: 6| Step: 8
Training loss: 1.1838927268981934
Validation loss: 1.904280572809199

Epoch: 6| Step: 9
Training loss: 0.9849266409873962
Validation loss: 1.8975647905821442

Epoch: 6| Step: 10
Training loss: 1.1428260803222656
Validation loss: 1.8867092568387267

Epoch: 6| Step: 11
Training loss: 1.3096997737884521
Validation loss: 1.8366761617763068

Epoch: 6| Step: 12
Training loss: 1.59258234500885
Validation loss: 1.939939033600592

Epoch: 6| Step: 13
Training loss: 1.9851542711257935
Validation loss: 1.9058833276071856

Epoch: 396| Step: 0
Training loss: 1.2760190963745117
Validation loss: 1.873953846193129

Epoch: 6| Step: 1
Training loss: 1.567297101020813
Validation loss: 1.920382051057713

Epoch: 6| Step: 2
Training loss: 1.6819707155227661
Validation loss: 1.9770885103492326

Epoch: 6| Step: 3
Training loss: 1.236032247543335
Validation loss: 1.8471467187327724

Epoch: 6| Step: 4
Training loss: 1.3326752185821533
Validation loss: 1.9404702122493456

Epoch: 6| Step: 5
Training loss: 1.57040274143219
Validation loss: 1.8989895864199566

Epoch: 6| Step: 6
Training loss: 1.029097080230713
Validation loss: 1.8623422409898491

Epoch: 6| Step: 7
Training loss: 0.8796461820602417
Validation loss: 1.9071868709338609

Epoch: 6| Step: 8
Training loss: 1.1817017793655396
Validation loss: 1.8844047643805062

Epoch: 6| Step: 9
Training loss: 1.3957583904266357
Validation loss: 1.9303573754525953

Epoch: 6| Step: 10
Training loss: 1.3862942457199097
Validation loss: 1.9455589658470565

Epoch: 6| Step: 11
Training loss: 0.9422171115875244
Validation loss: 1.9185367015100294

Epoch: 6| Step: 12
Training loss: 2.205751419067383
Validation loss: 1.8599924092651696

Epoch: 6| Step: 13
Training loss: 0.9839346408843994
Validation loss: 1.9206468110443444

Epoch: 397| Step: 0
Training loss: 1.7605520486831665
Validation loss: 1.9015121088233045

Epoch: 6| Step: 1
Training loss: 1.5364890098571777
Validation loss: 1.9230694796449395

Epoch: 6| Step: 2
Training loss: 1.271204948425293
Validation loss: 1.9149815279950377

Epoch: 6| Step: 3
Training loss: 0.9108301401138306
Validation loss: 1.8914157831540672

Epoch: 6| Step: 4
Training loss: 1.0188300609588623
Validation loss: 1.9479209915284188

Epoch: 6| Step: 5
Training loss: 1.8340418338775635
Validation loss: 1.927573238649676

Epoch: 6| Step: 6
Training loss: 1.1437739133834839
Validation loss: 1.8562870371726252

Epoch: 6| Step: 7
Training loss: 1.2695209980010986
Validation loss: 1.898933046607561

Epoch: 6| Step: 8
Training loss: 1.4944970607757568
Validation loss: 1.8550440906196513

Epoch: 6| Step: 9
Training loss: 1.3514962196350098
Validation loss: 1.9740477800369263

Epoch: 6| Step: 10
Training loss: 1.182117223739624
Validation loss: 1.9180476742406045

Epoch: 6| Step: 11
Training loss: 1.4353466033935547
Validation loss: 1.9177556986449866

Epoch: 6| Step: 12
Training loss: 1.4881212711334229
Validation loss: 1.9453502367901545

Epoch: 6| Step: 13
Training loss: 0.6850622892379761
Validation loss: 1.9566155043981408

Epoch: 398| Step: 0
Training loss: 1.3728718757629395
Validation loss: 1.9573863885735954

Epoch: 6| Step: 1
Training loss: 1.2508196830749512
Validation loss: 1.875657622532178

Epoch: 6| Step: 2
Training loss: 1.0884625911712646
Validation loss: 1.9765919139308314

Epoch: 6| Step: 3
Training loss: 1.2051022052764893
Validation loss: 1.90234709811467

Epoch: 6| Step: 4
Training loss: 0.7052352428436279
Validation loss: 1.945010531333185

Epoch: 6| Step: 5
Training loss: 1.3096363544464111
Validation loss: 1.9443925824216617

Epoch: 6| Step: 6
Training loss: 2.1300270557403564
Validation loss: 1.974158848485639

Epoch: 6| Step: 7
Training loss: 1.3743116855621338
Validation loss: 1.9107035001118977

Epoch: 6| Step: 8
Training loss: 1.0930898189544678
Validation loss: 1.8377043213895572

Epoch: 6| Step: 9
Training loss: 1.4835431575775146
Validation loss: 1.9761218883657967

Epoch: 6| Step: 10
Training loss: 1.6495308876037598
Validation loss: 1.8994179541064846

Epoch: 6| Step: 11
Training loss: 1.1732776165008545
Validation loss: 1.9034522656471498

Epoch: 6| Step: 12
Training loss: 1.242868423461914
Validation loss: 1.9157140203701553

Epoch: 6| Step: 13
Training loss: 1.1131837368011475
Validation loss: 1.8757525618358324

Epoch: 399| Step: 0
Training loss: 1.619588851928711
Validation loss: 1.893216844527952

Epoch: 6| Step: 1
Training loss: 1.2686305046081543
Validation loss: 1.930084454116001

Epoch: 6| Step: 2
Training loss: 1.4095062017440796
Validation loss: 1.8982616214342014

Epoch: 6| Step: 3
Training loss: 1.7093647718429565
Validation loss: 1.9114351913493166

Epoch: 6| Step: 4
Training loss: 1.1932544708251953
Validation loss: 2.0618901188655565

Epoch: 6| Step: 5
Training loss: 1.067089319229126
Validation loss: 1.9317961585137151

Epoch: 6| Step: 6
Training loss: 1.8930072784423828
Validation loss: 1.9228691080565095

Epoch: 6| Step: 7
Training loss: 0.8640860319137573
Validation loss: 1.9668123145257272

Epoch: 6| Step: 8
Training loss: 1.8377842903137207
Validation loss: 1.788208092412641

Epoch: 6| Step: 9
Training loss: 1.1796115636825562
Validation loss: 1.90227896295568

Epoch: 6| Step: 10
Training loss: 0.8998847007751465
Validation loss: 1.9332538266335764

Epoch: 6| Step: 11
Training loss: 1.0460398197174072
Validation loss: 1.9552289632058912

Epoch: 6| Step: 12
Training loss: 1.3055455684661865
Validation loss: 1.9243226153876192

Epoch: 6| Step: 13
Training loss: 1.7016698122024536
Validation loss: 1.9431310738286665

Epoch: 400| Step: 0
Training loss: 1.6971848011016846
Validation loss: 1.9188829391233382

Epoch: 6| Step: 1
Training loss: 1.560895323753357
Validation loss: 1.9443047802935365

Epoch: 6| Step: 2
Training loss: 1.9249383211135864
Validation loss: 1.9248905053702734

Epoch: 6| Step: 3
Training loss: 0.7803316116333008
Validation loss: 1.9471661954797723

Epoch: 6| Step: 4
Training loss: 1.6844435930252075
Validation loss: 1.9738348171275149

Epoch: 6| Step: 5
Training loss: 1.3707963228225708
Validation loss: 1.8582851425293954

Epoch: 6| Step: 6
Training loss: 1.219660997390747
Validation loss: 1.8526234754952051

Epoch: 6| Step: 7
Training loss: 1.3695602416992188
Validation loss: 1.9870916617813932

Epoch: 6| Step: 8
Training loss: 1.2282861471176147
Validation loss: 1.978860855102539

Epoch: 6| Step: 9
Training loss: 1.0402146577835083
Validation loss: 1.9451376007449241

Epoch: 6| Step: 10
Training loss: 1.1929529905319214
Validation loss: 1.8905260883351809

Epoch: 6| Step: 11
Training loss: 0.9742076396942139
Validation loss: 1.9440893985891854

Epoch: 6| Step: 12
Training loss: 0.910446047782898
Validation loss: 1.922699031009469

Epoch: 6| Step: 13
Training loss: 1.4108489751815796
Validation loss: 1.896007030240951

Epoch: 401| Step: 0
Training loss: 1.412029504776001
Validation loss: 1.965048651541433

Epoch: 6| Step: 1
Training loss: 1.428998351097107
Validation loss: 1.8837890650636406

Epoch: 6| Step: 2
Training loss: 1.2886570692062378
Validation loss: 1.8298409369684034

Epoch: 6| Step: 3
Training loss: 1.9286879301071167
Validation loss: 1.9021120891776135

Epoch: 6| Step: 4
Training loss: 1.3601878881454468
Validation loss: 1.9116582985847228

Epoch: 6| Step: 5
Training loss: 1.1344292163848877
Validation loss: 1.883357769699507

Epoch: 6| Step: 6
Training loss: 1.5166864395141602
Validation loss: 1.937705063050793

Epoch: 6| Step: 7
Training loss: 1.283799409866333
Validation loss: 1.8403208050676572

Epoch: 6| Step: 8
Training loss: 0.8789339065551758
Validation loss: 1.8549986385530042

Epoch: 6| Step: 9
Training loss: 1.5834101438522339
Validation loss: 1.9148660026570803

Epoch: 6| Step: 10
Training loss: 1.4865493774414062
Validation loss: 1.8847416498327767

Epoch: 6| Step: 11
Training loss: 1.0379362106323242
Validation loss: 1.938261244886665

Epoch: 6| Step: 12
Training loss: 1.4083433151245117
Validation loss: 1.9266282166204145

Epoch: 6| Step: 13
Training loss: 1.0200012922286987
Validation loss: 1.8757644904557096

Epoch: 402| Step: 0
Training loss: 1.325430154800415
Validation loss: 1.8776673488719489

Epoch: 6| Step: 1
Training loss: 1.1320879459381104
Validation loss: 1.9145096566087456

Epoch: 6| Step: 2
Training loss: 1.5128586292266846
Validation loss: 1.9009484103930894

Epoch: 6| Step: 3
Training loss: 1.2962071895599365
Validation loss: 1.8814894076316588

Epoch: 6| Step: 4
Training loss: 1.4017529487609863
Validation loss: 1.9706909079705515

Epoch: 6| Step: 5
Training loss: 1.7182408571243286
Validation loss: 1.9524972079902567

Epoch: 6| Step: 6
Training loss: 1.0375874042510986
Validation loss: 1.9548483125625118

Epoch: 6| Step: 7
Training loss: 1.0914121866226196
Validation loss: 1.959996135004105

Epoch: 6| Step: 8
Training loss: 1.0052907466888428
Validation loss: 1.9000338879964684

Epoch: 6| Step: 9
Training loss: 1.321934461593628
Validation loss: 1.9278341826572214

Epoch: 6| Step: 10
Training loss: 1.143593192100525
Validation loss: 1.87979160329347

Epoch: 6| Step: 11
Training loss: 1.5226919651031494
Validation loss: 1.9276072671336513

Epoch: 6| Step: 12
Training loss: 1.5024642944335938
Validation loss: 1.8241084647435013

Epoch: 6| Step: 13
Training loss: 1.547505259513855
Validation loss: 1.8956759616892824

Epoch: 403| Step: 0
Training loss: 1.4639523029327393
Validation loss: 1.9389475801939606

Epoch: 6| Step: 1
Training loss: 0.9291971325874329
Validation loss: 1.930039011022096

Epoch: 6| Step: 2
Training loss: 0.7569454312324524
Validation loss: 1.9288139240716093

Epoch: 6| Step: 3
Training loss: 1.4536559581756592
Validation loss: 1.8708013514036774

Epoch: 6| Step: 4
Training loss: 1.3536651134490967
Validation loss: 1.9175339591118596

Epoch: 6| Step: 5
Training loss: 1.1795705556869507
Validation loss: 1.9243814945220947

Epoch: 6| Step: 6
Training loss: 1.48488450050354
Validation loss: 2.013458175043906

Epoch: 6| Step: 7
Training loss: 1.1019107103347778
Validation loss: 1.9908141372024373

Epoch: 6| Step: 8
Training loss: 1.4940952062606812
Validation loss: 1.9899639211675173

Epoch: 6| Step: 9
Training loss: 1.210461139678955
Validation loss: 2.052140943465694

Epoch: 6| Step: 10
Training loss: 1.369219183921814
Validation loss: 2.00636879346704

Epoch: 6| Step: 11
Training loss: 2.23911714553833
Validation loss: 1.9600300481242519

Epoch: 6| Step: 12
Training loss: 1.3107612133026123
Validation loss: 1.8858693056209113

Epoch: 6| Step: 13
Training loss: 2.101353406906128
Validation loss: 1.9244360795585058

Epoch: 404| Step: 0
Training loss: 1.2003133296966553
Validation loss: 1.9902084630022767

Epoch: 6| Step: 1
Training loss: 1.1054044961929321
Validation loss: 2.0168331951223393

Epoch: 6| Step: 2
Training loss: 1.8641215562820435
Validation loss: 1.9560646908257597

Epoch: 6| Step: 3
Training loss: 1.404147744178772
Validation loss: 1.9225696261211107

Epoch: 6| Step: 4
Training loss: 1.6129380464553833
Validation loss: 1.910481914397209

Epoch: 6| Step: 5
Training loss: 1.478060245513916
Validation loss: 1.9925919886558288

Epoch: 6| Step: 6
Training loss: 0.9696915149688721
Validation loss: 1.893389363442698

Epoch: 6| Step: 7
Training loss: 1.9064143896102905
Validation loss: 1.925183948650155

Epoch: 6| Step: 8
Training loss: 0.9741346836090088
Validation loss: 1.8988851270368021

Epoch: 6| Step: 9
Training loss: 1.4718093872070312
Validation loss: 1.96094092886935

Epoch: 6| Step: 10
Training loss: 0.7905490398406982
Validation loss: 1.8508881061307845

Epoch: 6| Step: 11
Training loss: 1.3384040594100952
Validation loss: 1.9258195443819928

Epoch: 6| Step: 12
Training loss: 0.7737839221954346
Validation loss: 1.972722181709864

Epoch: 6| Step: 13
Training loss: 1.2826186418533325
Validation loss: 1.961448642515367

Epoch: 405| Step: 0
Training loss: 1.0366796255111694
Validation loss: 1.9600229147941834

Epoch: 6| Step: 1
Training loss: 1.6881613731384277
Validation loss: 1.9309809848826418

Epoch: 6| Step: 2
Training loss: 1.4033429622650146
Validation loss: 1.8988775924969745

Epoch: 6| Step: 3
Training loss: 2.0115835666656494
Validation loss: 1.9780512625171291

Epoch: 6| Step: 4
Training loss: 1.750009536743164
Validation loss: 1.8832513209312194

Epoch: 6| Step: 5
Training loss: 0.9319105744361877
Validation loss: 1.8917954096230127

Epoch: 6| Step: 6
Training loss: 1.478438377380371
Validation loss: 1.9965582842467933

Epoch: 6| Step: 7
Training loss: 0.8591488599777222
Validation loss: 1.906966906721874

Epoch: 6| Step: 8
Training loss: 0.8355981111526489
Validation loss: 1.9652189670070526

Epoch: 6| Step: 9
Training loss: 1.4586783647537231
Validation loss: 1.8971935472180765

Epoch: 6| Step: 10
Training loss: 1.3439210653305054
Validation loss: 1.9607942270976242

Epoch: 6| Step: 11
Training loss: 1.7242767810821533
Validation loss: 2.0200010653465026

Epoch: 6| Step: 12
Training loss: 1.0342005491256714
Validation loss: 2.0218531700872604

Epoch: 6| Step: 13
Training loss: 1.2373261451721191
Validation loss: 1.96121137116545

Epoch: 406| Step: 0
Training loss: 1.0622572898864746
Validation loss: 1.8490994079138643

Epoch: 6| Step: 1
Training loss: 1.4477498531341553
Validation loss: 1.9159237441196237

Epoch: 6| Step: 2
Training loss: 1.5442452430725098
Validation loss: 1.9372173675926783

Epoch: 6| Step: 3
Training loss: 1.1484603881835938
Validation loss: 1.9230703077008646

Epoch: 6| Step: 4
Training loss: 0.9891141653060913
Validation loss: 1.8737573495475195

Epoch: 6| Step: 5
Training loss: 1.5569024085998535
Validation loss: 1.9892238673343454

Epoch: 6| Step: 6
Training loss: 1.2707421779632568
Validation loss: 1.8470323213966944

Epoch: 6| Step: 7
Training loss: 1.9717737436294556
Validation loss: 1.9574591190584245

Epoch: 6| Step: 8
Training loss: 1.2471466064453125
Validation loss: 1.9230721342948176

Epoch: 6| Step: 9
Training loss: 1.2223190069198608
Validation loss: 1.9789908855192122

Epoch: 6| Step: 10
Training loss: 1.8414831161499023
Validation loss: 1.8524089936287171

Epoch: 6| Step: 11
Training loss: 0.839592695236206
Validation loss: 1.8963271648653093

Epoch: 6| Step: 12
Training loss: 1.3087751865386963
Validation loss: 1.9989684717629546

Epoch: 6| Step: 13
Training loss: 1.2518346309661865
Validation loss: 1.96460432903741

Epoch: 407| Step: 0
Training loss: 1.2926825284957886
Validation loss: 1.9382707585570633

Epoch: 6| Step: 1
Training loss: 1.459080457687378
Validation loss: 1.9760261145971154

Epoch: 6| Step: 2
Training loss: 1.3338803052902222
Validation loss: 1.9344957285029913

Epoch: 6| Step: 3
Training loss: 1.1627689599990845
Validation loss: 1.9839130755393737

Epoch: 6| Step: 4
Training loss: 1.389023780822754
Validation loss: 2.064357579395335

Epoch: 6| Step: 5
Training loss: 1.1599496603012085
Validation loss: 1.9431638031877496

Epoch: 6| Step: 6
Training loss: 1.1664427518844604
Validation loss: 2.003208932056222

Epoch: 6| Step: 7
Training loss: 1.3054702281951904
Validation loss: 1.8578528793909217

Epoch: 6| Step: 8
Training loss: 1.2362812757492065
Validation loss: 1.9480328316329627

Epoch: 6| Step: 9
Training loss: 1.5147066116333008
Validation loss: 1.9158685079184912

Epoch: 6| Step: 10
Training loss: 1.0440177917480469
Validation loss: 1.954637308274546

Epoch: 6| Step: 11
Training loss: 2.146031379699707
Validation loss: 1.8888824344963155

Epoch: 6| Step: 12
Training loss: 1.8608989715576172
Validation loss: 1.8981036396436795

Epoch: 6| Step: 13
Training loss: 1.0450189113616943
Validation loss: 1.8709922631581624

Epoch: 408| Step: 0
Training loss: 1.2984142303466797
Validation loss: 1.9722063900322042

Epoch: 6| Step: 1
Training loss: 1.1876050233840942
Validation loss: 1.9361534900562738

Epoch: 6| Step: 2
Training loss: 1.9370167255401611
Validation loss: 1.8739832242329915

Epoch: 6| Step: 3
Training loss: 1.2288455963134766
Validation loss: 1.8619348182473132

Epoch: 6| Step: 4
Training loss: 0.8973831534385681
Validation loss: 1.9572534432975195

Epoch: 6| Step: 5
Training loss: 1.2013211250305176
Validation loss: 1.9291372324830742

Epoch: 6| Step: 6
Training loss: 1.314469575881958
Validation loss: 1.8508494771936888

Epoch: 6| Step: 7
Training loss: 0.8373110294342041
Validation loss: 1.8724271289763912

Epoch: 6| Step: 8
Training loss: 1.8456939458847046
Validation loss: 1.9608163628526913

Epoch: 6| Step: 9
Training loss: 1.2501816749572754
Validation loss: 1.8797397549434374

Epoch: 6| Step: 10
Training loss: 1.2303848266601562
Validation loss: 1.9019044573589037

Epoch: 6| Step: 11
Training loss: 1.4727362394332886
Validation loss: 1.890134584519171

Epoch: 6| Step: 12
Training loss: 1.586409091949463
Validation loss: 1.907776192952228

Epoch: 6| Step: 13
Training loss: 1.0949116945266724
Validation loss: 1.8996478819078015

Epoch: 409| Step: 0
Training loss: 1.6718780994415283
Validation loss: 1.9856257746296544

Epoch: 6| Step: 1
Training loss: 0.9174840450286865
Validation loss: 1.9660830933560607

Epoch: 6| Step: 2
Training loss: 1.3224939107894897
Validation loss: 1.9555940166596444

Epoch: 6| Step: 3
Training loss: 1.4999597072601318
Validation loss: 2.003923027746139

Epoch: 6| Step: 4
Training loss: 0.7937369346618652
Validation loss: 1.9434031017364994

Epoch: 6| Step: 5
Training loss: 1.8215709924697876
Validation loss: 1.9741749084124

Epoch: 6| Step: 6
Training loss: 1.7862164974212646
Validation loss: 1.9823450760174823

Epoch: 6| Step: 7
Training loss: 1.5532751083374023
Validation loss: 1.9382107744934738

Epoch: 6| Step: 8
Training loss: 1.4682594537734985
Validation loss: 1.8841274733184485

Epoch: 6| Step: 9
Training loss: 1.4406318664550781
Validation loss: 1.9662207018944524

Epoch: 6| Step: 10
Training loss: 1.0717806816101074
Validation loss: 1.8773551294880528

Epoch: 6| Step: 11
Training loss: 0.7471767067909241
Validation loss: 1.8944725144294001

Epoch: 6| Step: 12
Training loss: 0.8859506845474243
Validation loss: 1.8901011431089012

Epoch: 6| Step: 13
Training loss: 1.2394654750823975
Validation loss: 1.9989884566235285

Epoch: 410| Step: 0
Training loss: 0.8187650442123413
Validation loss: 1.8775612551678893

Epoch: 6| Step: 1
Training loss: 1.9091806411743164
Validation loss: 1.9220793170313681

Epoch: 6| Step: 2
Training loss: 1.5097618103027344
Validation loss: 1.9725315686195128

Epoch: 6| Step: 3
Training loss: 1.7153570652008057
Validation loss: 1.8750929717094666

Epoch: 6| Step: 4
Training loss: 1.313189148902893
Validation loss: 1.941882138611168

Epoch: 6| Step: 5
Training loss: 1.8653854131698608
Validation loss: 1.8600850387286114

Epoch: 6| Step: 6
Training loss: 1.3447484970092773
Validation loss: 1.8314085365623556

Epoch: 6| Step: 7
Training loss: 1.3340073823928833
Validation loss: 1.9005394263934063

Epoch: 6| Step: 8
Training loss: 1.5613224506378174
Validation loss: 1.9124039475635817

Epoch: 6| Step: 9
Training loss: 0.8179899454116821
Validation loss: 1.9069255680166266

Epoch: 6| Step: 10
Training loss: 0.9601423740386963
Validation loss: 1.8546064105085147

Epoch: 6| Step: 11
Training loss: 1.1434379816055298
Validation loss: 1.9319005371421896

Epoch: 6| Step: 12
Training loss: 1.5498716831207275
Validation loss: 1.8764598267052763

Epoch: 6| Step: 13
Training loss: 0.7780377864837646
Validation loss: 1.8593479241094282

Epoch: 411| Step: 0
Training loss: 1.417724370956421
Validation loss: 1.9388029677893526

Epoch: 6| Step: 1
Training loss: 1.073468565940857
Validation loss: 1.9137119605977049

Epoch: 6| Step: 2
Training loss: 1.277151107788086
Validation loss: 1.8647228082021077

Epoch: 6| Step: 3
Training loss: 1.457430362701416
Validation loss: 1.8878519650428527

Epoch: 6| Step: 4
Training loss: 1.1427109241485596
Validation loss: 1.9052330396508659

Epoch: 6| Step: 5
Training loss: 0.9797226190567017
Validation loss: 1.9147992095639628

Epoch: 6| Step: 6
Training loss: 1.3282862901687622
Validation loss: 1.9359959325482767

Epoch: 6| Step: 7
Training loss: 1.384751319885254
Validation loss: 1.894180573442931

Epoch: 6| Step: 8
Training loss: 1.273275375366211
Validation loss: 1.939142829628401

Epoch: 6| Step: 9
Training loss: 1.3980987071990967
Validation loss: 1.9532775045723043

Epoch: 6| Step: 10
Training loss: 1.2321356534957886
Validation loss: 1.8966602625385407

Epoch: 6| Step: 11
Training loss: 1.809588074684143
Validation loss: 1.9372512191854498

Epoch: 6| Step: 12
Training loss: 1.7853622436523438
Validation loss: 1.9270701792932325

Epoch: 6| Step: 13
Training loss: 0.7527309656143188
Validation loss: 2.031022266675067

Epoch: 412| Step: 0
Training loss: 1.1820060014724731
Validation loss: 1.9619785380619827

Epoch: 6| Step: 1
Training loss: 0.8973482251167297
Validation loss: 1.8535170580751152

Epoch: 6| Step: 2
Training loss: 1.0162286758422852
Validation loss: 1.9542822735283965

Epoch: 6| Step: 3
Training loss: 1.5483194589614868
Validation loss: 1.9833027162859518

Epoch: 6| Step: 4
Training loss: 1.3097362518310547
Validation loss: 1.9345896987504856

Epoch: 6| Step: 5
Training loss: 1.2220878601074219
Validation loss: 1.8968146603594545

Epoch: 6| Step: 6
Training loss: 1.1202285289764404
Validation loss: 1.8938772601466025

Epoch: 6| Step: 7
Training loss: 1.09523344039917
Validation loss: 1.8580765672909316

Epoch: 6| Step: 8
Training loss: 2.3135528564453125
Validation loss: 1.8925092925307572

Epoch: 6| Step: 9
Training loss: 1.086210012435913
Validation loss: 1.8969412772886214

Epoch: 6| Step: 10
Training loss: 1.4947669506072998
Validation loss: 1.944926074756089

Epoch: 6| Step: 11
Training loss: 1.486104965209961
Validation loss: 1.9745869316080564

Epoch: 6| Step: 12
Training loss: 1.639322280883789
Validation loss: 1.8748195914811985

Epoch: 6| Step: 13
Training loss: 1.4863054752349854
Validation loss: 1.8625136216481526

Epoch: 413| Step: 0
Training loss: 2.275815010070801
Validation loss: 1.9414106171618226

Epoch: 6| Step: 1
Training loss: 1.5337941646575928
Validation loss: 1.9504188517088532

Epoch: 6| Step: 2
Training loss: 1.3644644021987915
Validation loss: 1.878212167370704

Epoch: 6| Step: 3
Training loss: 1.467200517654419
Validation loss: 1.866046655562616

Epoch: 6| Step: 4
Training loss: 1.0814491510391235
Validation loss: 1.9085364444281465

Epoch: 6| Step: 5
Training loss: 0.9470390677452087
Validation loss: 1.9112938091319094

Epoch: 6| Step: 6
Training loss: 1.5341055393218994
Validation loss: 1.9888185544680523

Epoch: 6| Step: 7
Training loss: 1.2727924585342407
Validation loss: 1.9494365235810638

Epoch: 6| Step: 8
Training loss: 1.1610453128814697
Validation loss: 1.8983923722338933

Epoch: 6| Step: 9
Training loss: 0.9186140298843384
Validation loss: 1.9714545844703593

Epoch: 6| Step: 10
Training loss: 1.1583290100097656
Validation loss: 1.9221078144606722

Epoch: 6| Step: 11
Training loss: 1.161521315574646
Validation loss: 2.0354003483249294

Epoch: 6| Step: 12
Training loss: 1.6043899059295654
Validation loss: 1.910965552894018

Epoch: 6| Step: 13
Training loss: 1.2987229824066162
Validation loss: 1.8942314963186941

Epoch: 414| Step: 0
Training loss: 1.7124313116073608
Validation loss: 1.9228609069701164

Epoch: 6| Step: 1
Training loss: 1.896554946899414
Validation loss: 2.000983435620544

Epoch: 6| Step: 2
Training loss: 1.3092248439788818
Validation loss: 1.9036614330866004

Epoch: 6| Step: 3
Training loss: 1.6094849109649658
Validation loss: 1.916511720226657

Epoch: 6| Step: 4
Training loss: 0.9558265209197998
Validation loss: 1.90513244751961

Epoch: 6| Step: 5
Training loss: 1.1633858680725098
Validation loss: 1.937137424304921

Epoch: 6| Step: 6
Training loss: 1.270729422569275
Validation loss: 1.8995160133607927

Epoch: 6| Step: 7
Training loss: 1.6330608129501343
Validation loss: 1.9658199907631002

Epoch: 6| Step: 8
Training loss: 1.2826951742172241
Validation loss: 1.9136301599523073

Epoch: 6| Step: 9
Training loss: 0.873086154460907
Validation loss: 1.9506181670773415

Epoch: 6| Step: 10
Training loss: 1.1784656047821045
Validation loss: 1.9889315405199606

Epoch: 6| Step: 11
Training loss: 1.1767327785491943
Validation loss: 1.948282281557719

Epoch: 6| Step: 12
Training loss: 1.367692470550537
Validation loss: 1.8567265361867926

Epoch: 6| Step: 13
Training loss: 0.9108855128288269
Validation loss: 1.9634000255215553

Epoch: 415| Step: 0
Training loss: 1.7213488817214966
Validation loss: 1.8805810918090164

Epoch: 6| Step: 1
Training loss: 1.030798077583313
Validation loss: 1.964593482273881

Epoch: 6| Step: 2
Training loss: 1.1439028978347778
Validation loss: 2.0054232356368855

Epoch: 6| Step: 3
Training loss: 1.8408284187316895
Validation loss: 1.9445893238949519

Epoch: 6| Step: 4
Training loss: 1.986810326576233
Validation loss: 1.8984443974751297

Epoch: 6| Step: 5
Training loss: 1.5746313333511353
Validation loss: 1.9083021866377963

Epoch: 6| Step: 6
Training loss: 1.8997228145599365
Validation loss: 1.8689315959971438

Epoch: 6| Step: 7
Training loss: 0.8047516345977783
Validation loss: 1.9523689362310594

Epoch: 6| Step: 8
Training loss: 1.6422455310821533
Validation loss: 1.9501274542141986

Epoch: 6| Step: 9
Training loss: 1.208000898361206
Validation loss: 1.9064362215739425

Epoch: 6| Step: 10
Training loss: 1.0109186172485352
Validation loss: 1.9132816586443173

Epoch: 6| Step: 11
Training loss: 0.9731638431549072
Validation loss: 1.9718384973464473

Epoch: 6| Step: 12
Training loss: 1.2840237617492676
Validation loss: 1.9321734777060888

Epoch: 6| Step: 13
Training loss: 0.4129291772842407
Validation loss: 1.990575821168961

Epoch: 416| Step: 0
Training loss: 1.2956891059875488
Validation loss: 1.9986804275102512

Epoch: 6| Step: 1
Training loss: 1.799675464630127
Validation loss: 2.0528256752157725

Epoch: 6| Step: 2
Training loss: 1.1713106632232666
Validation loss: 2.0955362037945817

Epoch: 6| Step: 3
Training loss: 1.3510106801986694
Validation loss: 2.045263886451721

Epoch: 6| Step: 4
Training loss: 1.5181208848953247
Validation loss: 1.9476784839425036

Epoch: 6| Step: 5
Training loss: 1.0468876361846924
Validation loss: 1.979192655573609

Epoch: 6| Step: 6
Training loss: 1.2856191396713257
Validation loss: 1.9597747915534562

Epoch: 6| Step: 7
Training loss: 1.8000378608703613
Validation loss: 1.9577061604428034

Epoch: 6| Step: 8
Training loss: 1.522362232208252
Validation loss: 1.9311378361076437

Epoch: 6| Step: 9
Training loss: 0.9992930889129639
Validation loss: 1.9013228326715448

Epoch: 6| Step: 10
Training loss: 1.030189871788025
Validation loss: 1.890855569993296

Epoch: 6| Step: 11
Training loss: 0.9907248616218567
Validation loss: 1.9400534514457948

Epoch: 6| Step: 12
Training loss: 1.742969274520874
Validation loss: 1.9102413269781298

Epoch: 6| Step: 13
Training loss: 1.5050326585769653
Validation loss: 1.9930578790685183

Epoch: 417| Step: 0
Training loss: 1.4197769165039062
Validation loss: 1.8983319908060052

Epoch: 6| Step: 1
Training loss: 1.432724952697754
Validation loss: 1.9919038152181974

Epoch: 6| Step: 2
Training loss: 1.207309365272522
Validation loss: 1.9231639408296155

Epoch: 6| Step: 3
Training loss: 0.9845564365386963
Validation loss: 1.9004071194638488

Epoch: 6| Step: 4
Training loss: 0.9347072839736938
Validation loss: 1.913136064365346

Epoch: 6| Step: 5
Training loss: 1.1832091808319092
Validation loss: 1.9332758239520493

Epoch: 6| Step: 6
Training loss: 1.467913269996643
Validation loss: 1.9737825752586446

Epoch: 6| Step: 7
Training loss: 1.3286468982696533
Validation loss: 1.9219076095088836

Epoch: 6| Step: 8
Training loss: 0.9458597898483276
Validation loss: 1.9235613269190635

Epoch: 6| Step: 9
Training loss: 1.2158255577087402
Validation loss: 1.9353305191122077

Epoch: 6| Step: 10
Training loss: 1.3173176050186157
Validation loss: 1.9943349181964833

Epoch: 6| Step: 11
Training loss: 1.837282419204712
Validation loss: 2.0094617054026616

Epoch: 6| Step: 12
Training loss: 1.539367914199829
Validation loss: 2.0856536178178686

Epoch: 6| Step: 13
Training loss: 1.9310122728347778
Validation loss: 1.9215903506484082

Epoch: 418| Step: 0
Training loss: 1.0312649011611938
Validation loss: 1.9989829653052873

Epoch: 6| Step: 1
Training loss: 1.219130039215088
Validation loss: 1.8973646253667853

Epoch: 6| Step: 2
Training loss: 1.3716208934783936
Validation loss: 1.9400147430358394

Epoch: 6| Step: 3
Training loss: 1.3853991031646729
Validation loss: 1.8804584286546195

Epoch: 6| Step: 4
Training loss: 1.2749994993209839
Validation loss: 1.9012068420328119

Epoch: 6| Step: 5
Training loss: 1.3469680547714233
Validation loss: 1.8889728297469437

Epoch: 6| Step: 6
Training loss: 1.583403468132019
Validation loss: 1.9347933466716478

Epoch: 6| Step: 7
Training loss: 1.0015218257904053
Validation loss: 1.8741736078775058

Epoch: 6| Step: 8
Training loss: 1.3591946363449097
Validation loss: 1.996537305975473

Epoch: 6| Step: 9
Training loss: 1.4183942079544067
Validation loss: 1.956471179121284

Epoch: 6| Step: 10
Training loss: 1.0758311748504639
Validation loss: 1.9147943258285522

Epoch: 6| Step: 11
Training loss: 1.260329008102417
Validation loss: 1.927877692766087

Epoch: 6| Step: 12
Training loss: 1.3318674564361572
Validation loss: 1.9933460963669645

Epoch: 6| Step: 13
Training loss: 1.1159453392028809
Validation loss: 1.9392944241082797

Epoch: 419| Step: 0
Training loss: 1.2565605640411377
Validation loss: 1.956555727989443

Epoch: 6| Step: 1
Training loss: 1.0863035917282104
Validation loss: 2.063086235395042

Epoch: 6| Step: 2
Training loss: 1.4247426986694336
Validation loss: 1.9556908992029005

Epoch: 6| Step: 3
Training loss: 1.2961068153381348
Validation loss: 2.0228656312470794

Epoch: 6| Step: 4
Training loss: 1.1603739261627197
Validation loss: 2.0215479455968386

Epoch: 6| Step: 5
Training loss: 1.2540223598480225
Validation loss: 1.9753922800863943

Epoch: 6| Step: 6
Training loss: 1.199951171875
Validation loss: 2.03821978774122

Epoch: 6| Step: 7
Training loss: 2.0017032623291016
Validation loss: 1.9550892153093893

Epoch: 6| Step: 8
Training loss: 1.2603837251663208
Validation loss: 2.0111569307183705

Epoch: 6| Step: 9
Training loss: 1.3915419578552246
Validation loss: 1.8924582466002433

Epoch: 6| Step: 10
Training loss: 1.238406777381897
Validation loss: 1.9094134197440198

Epoch: 6| Step: 11
Training loss: 1.5099530220031738
Validation loss: 1.962861527678787

Epoch: 6| Step: 12
Training loss: 1.1776022911071777
Validation loss: 1.9709297239139516

Epoch: 6| Step: 13
Training loss: 0.9961222410202026
Validation loss: 1.8955362868565384

Epoch: 420| Step: 0
Training loss: 0.7332595586776733
Validation loss: 1.9716245230808054

Epoch: 6| Step: 1
Training loss: 0.9244292974472046
Validation loss: 1.885065923454941

Epoch: 6| Step: 2
Training loss: 1.2762842178344727
Validation loss: 1.9422263214665074

Epoch: 6| Step: 3
Training loss: 1.5592314004898071
Validation loss: 1.8850589798342796

Epoch: 6| Step: 4
Training loss: 2.1101512908935547
Validation loss: 1.9720533765772337

Epoch: 6| Step: 5
Training loss: 1.1854735612869263
Validation loss: 1.9515648836730628

Epoch: 6| Step: 6
Training loss: 1.480762243270874
Validation loss: 1.9158817042586624

Epoch: 6| Step: 7
Training loss: 1.3960294723510742
Validation loss: 1.8685262908217728

Epoch: 6| Step: 8
Training loss: 1.7810136079788208
Validation loss: 1.9665829417526082

Epoch: 6| Step: 9
Training loss: 1.0198030471801758
Validation loss: 1.9029614566474833

Epoch: 6| Step: 10
Training loss: 1.19148588180542
Validation loss: 1.8624905770824802

Epoch: 6| Step: 11
Training loss: 1.33469820022583
Validation loss: 1.9123522722592918

Epoch: 6| Step: 12
Training loss: 1.5123093128204346
Validation loss: 1.8968930769992132

Epoch: 6| Step: 13
Training loss: 0.6994168758392334
Validation loss: 1.9054952359968615

Epoch: 421| Step: 0
Training loss: 1.31648850440979
Validation loss: 1.927566735975204

Epoch: 6| Step: 1
Training loss: 1.5580838918685913
Validation loss: 1.922410495819584

Epoch: 6| Step: 2
Training loss: 1.2787315845489502
Validation loss: 2.0021508406567317

Epoch: 6| Step: 3
Training loss: 1.2628777027130127
Validation loss: 1.943207683101777

Epoch: 6| Step: 4
Training loss: 1.236769676208496
Validation loss: 1.990347041878649

Epoch: 6| Step: 5
Training loss: 1.072791337966919
Validation loss: 1.9552427068833382

Epoch: 6| Step: 6
Training loss: 1.0868701934814453
Validation loss: 2.0152499752659954

Epoch: 6| Step: 7
Training loss: 1.171508550643921
Validation loss: 1.9012351061708184

Epoch: 6| Step: 8
Training loss: 1.0900462865829468
Validation loss: 1.915169091634853

Epoch: 6| Step: 9
Training loss: 1.5998852252960205
Validation loss: 1.9490502278010051

Epoch: 6| Step: 10
Training loss: 1.2826988697052002
Validation loss: 1.9152997847526305

Epoch: 6| Step: 11
Training loss: 1.1800003051757812
Validation loss: 1.990510340659849

Epoch: 6| Step: 12
Training loss: 1.5723576545715332
Validation loss: 1.972579720199749

Epoch: 6| Step: 13
Training loss: 1.6384854316711426
Validation loss: 1.8870758087404313

Epoch: 422| Step: 0
Training loss: 1.007051706314087
Validation loss: 1.9188540392024542

Epoch: 6| Step: 1
Training loss: 1.413254976272583
Validation loss: 1.9295011463985647

Epoch: 6| Step: 2
Training loss: 1.3456507921218872
Validation loss: 1.9349664180509505

Epoch: 6| Step: 3
Training loss: 0.8623065948486328
Validation loss: 1.9398497278972338

Epoch: 6| Step: 4
Training loss: 1.1865947246551514
Validation loss: 1.9479865271558043

Epoch: 6| Step: 5
Training loss: 1.1822068691253662
Validation loss: 1.929892748914739

Epoch: 6| Step: 6
Training loss: 1.2083301544189453
Validation loss: 1.8164939034369685

Epoch: 6| Step: 7
Training loss: 0.8700698018074036
Validation loss: 1.9210395184896325

Epoch: 6| Step: 8
Training loss: 1.647017002105713
Validation loss: 1.9479549725850422

Epoch: 6| Step: 9
Training loss: 1.4831068515777588
Validation loss: 1.9159026786845217

Epoch: 6| Step: 10
Training loss: 2.195094585418701
Validation loss: 1.8948991849858274

Epoch: 6| Step: 11
Training loss: 1.3955758810043335
Validation loss: 1.932697529433876

Epoch: 6| Step: 12
Training loss: 1.3416919708251953
Validation loss: 1.9104677938645886

Epoch: 6| Step: 13
Training loss: 1.614970326423645
Validation loss: 1.9271439121615501

Epoch: 423| Step: 0
Training loss: 1.0524661540985107
Validation loss: 1.8771389710005892

Epoch: 6| Step: 1
Training loss: 0.8411434888839722
Validation loss: 1.9765116117333854

Epoch: 6| Step: 2
Training loss: 0.8800536394119263
Validation loss: 1.9485656984390751

Epoch: 6| Step: 3
Training loss: 1.4414246082305908
Validation loss: 1.9513357198366554

Epoch: 6| Step: 4
Training loss: 2.349975109100342
Validation loss: 2.0217398161529214

Epoch: 6| Step: 5
Training loss: 1.123051643371582
Validation loss: 1.9461920133201025

Epoch: 6| Step: 6
Training loss: 1.5267771482467651
Validation loss: 1.9968150200382355

Epoch: 6| Step: 7
Training loss: 0.8350487351417542
Validation loss: 2.0047680177996234

Epoch: 6| Step: 8
Training loss: 1.7677884101867676
Validation loss: 1.8361355643118582

Epoch: 6| Step: 9
Training loss: 1.7910537719726562
Validation loss: 1.8968289667560208

Epoch: 6| Step: 10
Training loss: 1.1726804971694946
Validation loss: 1.8376332354801956

Epoch: 6| Step: 11
Training loss: 1.067016839981079
Validation loss: 1.9748459528851252

Epoch: 6| Step: 12
Training loss: 1.0331852436065674
Validation loss: 1.952612300072947

Epoch: 6| Step: 13
Training loss: 1.0873980522155762
Validation loss: 1.9720810382596907

Epoch: 424| Step: 0
Training loss: 2.463792324066162
Validation loss: 1.9923123339171052

Epoch: 6| Step: 1
Training loss: 1.1211806535720825
Validation loss: 1.898136987481066

Epoch: 6| Step: 2
Training loss: 1.4159349203109741
Validation loss: 1.8766943100960023

Epoch: 6| Step: 3
Training loss: 1.389762043952942
Validation loss: 1.9231624000815934

Epoch: 6| Step: 4
Training loss: 1.5085700750350952
Validation loss: 2.0265758140112764

Epoch: 6| Step: 5
Training loss: 1.193560004234314
Validation loss: 1.9411356449127197

Epoch: 6| Step: 6
Training loss: 0.9985119104385376
Validation loss: 1.988140877857003

Epoch: 6| Step: 7
Training loss: 1.0065300464630127
Validation loss: 1.889843499788674

Epoch: 6| Step: 8
Training loss: 1.151038646697998
Validation loss: 1.8768879059822328

Epoch: 6| Step: 9
Training loss: 1.2733840942382812
Validation loss: 1.9097851271270423

Epoch: 6| Step: 10
Training loss: 1.2893445491790771
Validation loss: 1.9228365331567743

Epoch: 6| Step: 11
Training loss: 0.9564305543899536
Validation loss: 1.9366298542227796

Epoch: 6| Step: 12
Training loss: 0.8030840158462524
Validation loss: 1.9294023026702225

Epoch: 6| Step: 13
Training loss: 1.3853839635849
Validation loss: 1.94009139204538

Epoch: 425| Step: 0
Training loss: 1.334672212600708
Validation loss: 1.9357844168140041

Epoch: 6| Step: 1
Training loss: 1.0599483251571655
Validation loss: 1.9155286973522556

Epoch: 6| Step: 2
Training loss: 1.3070036172866821
Validation loss: 1.9059145758228917

Epoch: 6| Step: 3
Training loss: 1.1824617385864258
Validation loss: 1.9216350842547674

Epoch: 6| Step: 4
Training loss: 1.5181018114089966
Validation loss: 1.975657206709667

Epoch: 6| Step: 5
Training loss: 1.6624703407287598
Validation loss: 2.019102192694141

Epoch: 6| Step: 6
Training loss: 1.105425238609314
Validation loss: 1.9667413721802414

Epoch: 6| Step: 7
Training loss: 1.0225021839141846
Validation loss: 1.9807280276411323

Epoch: 6| Step: 8
Training loss: 1.4909207820892334
Validation loss: 2.013454362910281

Epoch: 6| Step: 9
Training loss: 1.4882333278656006
Validation loss: 1.9236046742367487

Epoch: 6| Step: 10
Training loss: 1.369997501373291
Validation loss: 1.960200596881169

Epoch: 6| Step: 11
Training loss: 1.07484769821167
Validation loss: 1.9078831454759002

Epoch: 6| Step: 12
Training loss: 1.0167834758758545
Validation loss: 1.950395381578835

Epoch: 6| Step: 13
Training loss: 1.4226690530776978
Validation loss: 1.9193508214848016

Epoch: 426| Step: 0
Training loss: 2.038327217102051
Validation loss: 1.9632308149850497

Epoch: 6| Step: 1
Training loss: 1.56201171875
Validation loss: 1.8751879648495746

Epoch: 6| Step: 2
Training loss: 1.1856639385223389
Validation loss: 1.9629614494180168

Epoch: 6| Step: 3
Training loss: 1.1852294206619263
Validation loss: 1.8797750857568556

Epoch: 6| Step: 4
Training loss: 1.07512629032135
Validation loss: 1.8969452996407785

Epoch: 6| Step: 5
Training loss: 1.252043604850769
Validation loss: 1.9714979458880681

Epoch: 6| Step: 6
Training loss: 1.2862107753753662
Validation loss: 1.8940205445853613

Epoch: 6| Step: 7
Training loss: 1.3063892126083374
Validation loss: 1.8865435969445012

Epoch: 6| Step: 8
Training loss: 1.2383099794387817
Validation loss: 1.892513914774823

Epoch: 6| Step: 9
Training loss: 1.4313384294509888
Validation loss: 1.9208789794675765

Epoch: 6| Step: 10
Training loss: 1.156414270401001
Validation loss: 1.8916493026159142

Epoch: 6| Step: 11
Training loss: 1.3482818603515625
Validation loss: 1.9642627200772684

Epoch: 6| Step: 12
Training loss: 0.7399024963378906
Validation loss: 1.9126773931646859

Epoch: 6| Step: 13
Training loss: 1.3701444864273071
Validation loss: 2.006993232234832

Epoch: 427| Step: 0
Training loss: 1.316295862197876
Validation loss: 2.0332041966017855

Epoch: 6| Step: 1
Training loss: 0.9980607032775879
Validation loss: 1.9790331189350416

Epoch: 6| Step: 2
Training loss: 1.061310052871704
Validation loss: 1.9593748764325214

Epoch: 6| Step: 3
Training loss: 1.115073800086975
Validation loss: 1.968754691462363

Epoch: 6| Step: 4
Training loss: 1.0069472789764404
Validation loss: 1.9893150932045394

Epoch: 6| Step: 5
Training loss: 0.9165188074111938
Validation loss: 1.9992761842666134

Epoch: 6| Step: 6
Training loss: 1.5832277536392212
Validation loss: 1.9157662404480802

Epoch: 6| Step: 7
Training loss: 0.8662101626396179
Validation loss: 1.9103692731549662

Epoch: 6| Step: 8
Training loss: 1.5039713382720947
Validation loss: 1.9725110223216396

Epoch: 6| Step: 9
Training loss: 1.0932672023773193
Validation loss: 1.9075700890633367

Epoch: 6| Step: 10
Training loss: 1.4872708320617676
Validation loss: 1.9169610918209117

Epoch: 6| Step: 11
Training loss: 1.8555216789245605
Validation loss: 1.8489177444929719

Epoch: 6| Step: 12
Training loss: 1.2923170328140259
Validation loss: 1.9182382411854242

Epoch: 6| Step: 13
Training loss: 2.755199909210205
Validation loss: 1.8697980283409037

Epoch: 428| Step: 0
Training loss: 1.4390363693237305
Validation loss: 1.8950055888904038

Epoch: 6| Step: 1
Training loss: 0.7855476140975952
Validation loss: 1.9349976098665627

Epoch: 6| Step: 2
Training loss: 1.1208686828613281
Validation loss: 1.8070780833562214

Epoch: 6| Step: 3
Training loss: 1.9912151098251343
Validation loss: 1.8992630281756002

Epoch: 6| Step: 4
Training loss: 1.0278518199920654
Validation loss: 1.8318283878346926

Epoch: 6| Step: 5
Training loss: 1.3714011907577515
Validation loss: 1.974570494826122

Epoch: 6| Step: 6
Training loss: 1.1265666484832764
Validation loss: 1.949626894407375

Epoch: 6| Step: 7
Training loss: 1.118480920791626
Validation loss: 1.9242842005145164

Epoch: 6| Step: 8
Training loss: 1.7608833312988281
Validation loss: 1.9263716397746917

Epoch: 6| Step: 9
Training loss: 1.0190271139144897
Validation loss: 1.958118446411625

Epoch: 6| Step: 10
Training loss: 1.4146363735198975
Validation loss: 2.045742022093906

Epoch: 6| Step: 11
Training loss: 0.9433599710464478
Validation loss: 1.9860129869112404

Epoch: 6| Step: 12
Training loss: 1.4630001783370972
Validation loss: 1.9782815748645413

Epoch: 6| Step: 13
Training loss: 1.366795301437378
Validation loss: 1.9440083657541583

Epoch: 429| Step: 0
Training loss: 1.4535466432571411
Validation loss: 1.952560656814165

Epoch: 6| Step: 1
Training loss: 1.1588261127471924
Validation loss: 1.9342930752743956

Epoch: 6| Step: 2
Training loss: 1.2034447193145752
Validation loss: 1.9219140621923632

Epoch: 6| Step: 3
Training loss: 0.7797186374664307
Validation loss: 1.9815830851113925

Epoch: 6| Step: 4
Training loss: 1.0891616344451904
Validation loss: 1.9924628990952686

Epoch: 6| Step: 5
Training loss: 1.2991993427276611
Validation loss: 1.893061343059745

Epoch: 6| Step: 6
Training loss: 0.9685269594192505
Validation loss: 1.9371944704363424

Epoch: 6| Step: 7
Training loss: 2.1601035594940186
Validation loss: 1.9566020952757968

Epoch: 6| Step: 8
Training loss: 1.2200782299041748
Validation loss: 1.9329940580552625

Epoch: 6| Step: 9
Training loss: 1.625578761100769
Validation loss: 1.921338132632676

Epoch: 6| Step: 10
Training loss: 0.721227765083313
Validation loss: 1.9589551136057863

Epoch: 6| Step: 11
Training loss: 1.9439380168914795
Validation loss: 1.8486061096191406

Epoch: 6| Step: 12
Training loss: 1.2295033931732178
Validation loss: 1.8808675786500335

Epoch: 6| Step: 13
Training loss: 1.3499507904052734
Validation loss: 1.8501404152121594

Epoch: 430| Step: 0
Training loss: 1.3433409929275513
Validation loss: 1.9514558699823195

Epoch: 6| Step: 1
Training loss: 0.9569897651672363
Validation loss: 1.9151097933451335

Epoch: 6| Step: 2
Training loss: 1.0752724409103394
Validation loss: 1.9114548660093738

Epoch: 6| Step: 3
Training loss: 1.2028007507324219
Validation loss: 1.9522381290312736

Epoch: 6| Step: 4
Training loss: 1.233004093170166
Validation loss: 1.8944364440056585

Epoch: 6| Step: 5
Training loss: 1.2814831733703613
Validation loss: 1.9440269277941795

Epoch: 6| Step: 6
Training loss: 1.277089238166809
Validation loss: 1.912843591423445

Epoch: 6| Step: 7
Training loss: 0.6109365820884705
Validation loss: 1.9026343258478309

Epoch: 6| Step: 8
Training loss: 1.2862924337387085
Validation loss: 1.906058830599631

Epoch: 6| Step: 9
Training loss: 1.4458690881729126
Validation loss: 2.0529984940764723

Epoch: 6| Step: 10
Training loss: 1.7102586030960083
Validation loss: 2.003813447490815

Epoch: 6| Step: 11
Training loss: 1.2353312969207764
Validation loss: 1.9953423469297347

Epoch: 6| Step: 12
Training loss: 1.6823675632476807
Validation loss: 1.970520511750252

Epoch: 6| Step: 13
Training loss: 1.644927740097046
Validation loss: 2.000799834087331

Epoch: 431| Step: 0
Training loss: 1.8591302633285522
Validation loss: 2.035889894731583

Epoch: 6| Step: 1
Training loss: 0.9036805033683777
Validation loss: 2.043118594795145

Epoch: 6| Step: 2
Training loss: 1.21964430809021
Validation loss: 1.9950402834082162

Epoch: 6| Step: 3
Training loss: 0.9378881454467773
Validation loss: 1.912284621628382

Epoch: 6| Step: 4
Training loss: 1.1232569217681885
Validation loss: 1.9944128682536464

Epoch: 6| Step: 5
Training loss: 1.3639001846313477
Validation loss: 1.9790633199035481

Epoch: 6| Step: 6
Training loss: 1.0448698997497559
Validation loss: 1.9153539583247194

Epoch: 6| Step: 7
Training loss: 1.4974212646484375
Validation loss: 1.9439047280178274

Epoch: 6| Step: 8
Training loss: 1.253328561782837
Validation loss: 1.951462794375676

Epoch: 6| Step: 9
Training loss: 1.7648653984069824
Validation loss: 1.877499880329255

Epoch: 6| Step: 10
Training loss: 1.1347445249557495
Validation loss: 1.9422918737575572

Epoch: 6| Step: 11
Training loss: 1.5163904428482056
Validation loss: 1.9024825019221152

Epoch: 6| Step: 12
Training loss: 1.2614023685455322
Validation loss: 1.9600385363383959

Epoch: 6| Step: 13
Training loss: 1.0607717037200928
Validation loss: 1.9346147634649788

Epoch: 432| Step: 0
Training loss: 1.0583765506744385
Validation loss: 1.951450014627108

Epoch: 6| Step: 1
Training loss: 1.0920606851577759
Validation loss: 2.030459398864418

Epoch: 6| Step: 2
Training loss: 1.0243232250213623
Validation loss: 1.880987201967547

Epoch: 6| Step: 3
Training loss: 2.0032761096954346
Validation loss: 1.9849942140681769

Epoch: 6| Step: 4
Training loss: 1.4303337335586548
Validation loss: 1.9352377614667338

Epoch: 6| Step: 5
Training loss: 0.8508458733558655
Validation loss: 1.9360068728846889

Epoch: 6| Step: 6
Training loss: 1.2321480512619019
Validation loss: 1.9128241103182557

Epoch: 6| Step: 7
Training loss: 1.1812396049499512
Validation loss: 1.9879639289712394

Epoch: 6| Step: 8
Training loss: 1.0534703731536865
Validation loss: 1.924704877279138

Epoch: 6| Step: 9
Training loss: 1.22212815284729
Validation loss: 1.9199639533155708

Epoch: 6| Step: 10
Training loss: 1.1512258052825928
Validation loss: 2.0067091500887306

Epoch: 6| Step: 11
Training loss: 1.1700310707092285
Validation loss: 1.9961268312187606

Epoch: 6| Step: 12
Training loss: 2.1202759742736816
Validation loss: 1.9159971840919987

Epoch: 6| Step: 13
Training loss: 1.0306777954101562
Validation loss: 2.028447153747723

Epoch: 433| Step: 0
Training loss: 1.166821002960205
Validation loss: 1.9644200160939207

Epoch: 6| Step: 1
Training loss: 1.6627429723739624
Validation loss: 2.006048342233063

Epoch: 6| Step: 2
Training loss: 1.3739149570465088
Validation loss: 1.9238789978847708

Epoch: 6| Step: 3
Training loss: 1.3262505531311035
Validation loss: 2.0114982794689875

Epoch: 6| Step: 4
Training loss: 0.693771481513977
Validation loss: 1.9272595810633835

Epoch: 6| Step: 5
Training loss: 1.321305513381958
Validation loss: 1.9287865200350363

Epoch: 6| Step: 6
Training loss: 1.546402931213379
Validation loss: 1.8123856039457424

Epoch: 6| Step: 7
Training loss: 0.8219424486160278
Validation loss: 1.925940546938168

Epoch: 6| Step: 8
Training loss: 1.2636252641677856
Validation loss: 1.9335655255984234

Epoch: 6| Step: 9
Training loss: 1.1118072271347046
Validation loss: 1.926022748793325

Epoch: 6| Step: 10
Training loss: 1.525287389755249
Validation loss: 1.9203042650735507

Epoch: 6| Step: 11
Training loss: 1.2844452857971191
Validation loss: 1.885910100834344

Epoch: 6| Step: 12
Training loss: 1.4963867664337158
Validation loss: 1.8922559227994693

Epoch: 6| Step: 13
Training loss: 1.5296576023101807
Validation loss: 1.8989906041852889

Epoch: 434| Step: 0
Training loss: 1.739166498184204
Validation loss: 1.969856721098705

Epoch: 6| Step: 1
Training loss: 0.7651429772377014
Validation loss: 1.9131950204090407

Epoch: 6| Step: 2
Training loss: 1.670159101486206
Validation loss: 1.9978511436011201

Epoch: 6| Step: 3
Training loss: 1.1525191068649292
Validation loss: 1.9125433814141057

Epoch: 6| Step: 4
Training loss: 1.4542168378829956
Validation loss: 2.065610880492836

Epoch: 6| Step: 5
Training loss: 1.1373226642608643
Validation loss: 1.9980985861952587

Epoch: 6| Step: 6
Training loss: 0.9760554432868958
Validation loss: 1.9001134493017708

Epoch: 6| Step: 7
Training loss: 1.292770504951477
Validation loss: 1.9724534570529897

Epoch: 6| Step: 8
Training loss: 1.523349642753601
Validation loss: 1.9224724487591816

Epoch: 6| Step: 9
Training loss: 1.0497257709503174
Validation loss: 1.9750637290298299

Epoch: 6| Step: 10
Training loss: 0.8978408575057983
Validation loss: 1.9870529392714142

Epoch: 6| Step: 11
Training loss: 1.2897220849990845
Validation loss: 1.8580882177557996

Epoch: 6| Step: 12
Training loss: 1.1336185932159424
Validation loss: 1.9213404655456543

Epoch: 6| Step: 13
Training loss: 1.33307683467865
Validation loss: 1.924711714508713

Epoch: 435| Step: 0
Training loss: 1.3090758323669434
Validation loss: 1.9215250681805354

Epoch: 6| Step: 1
Training loss: 0.9817186594009399
Validation loss: 2.002159289134446

Epoch: 6| Step: 2
Training loss: 1.9357104301452637
Validation loss: 1.940186559513051

Epoch: 6| Step: 3
Training loss: 0.9264031648635864
Validation loss: 1.9064668006794427

Epoch: 6| Step: 4
Training loss: 1.148475170135498
Validation loss: 1.892863917094405

Epoch: 6| Step: 5
Training loss: 0.7822239398956299
Validation loss: 1.954839265474709

Epoch: 6| Step: 6
Training loss: 1.3666350841522217
Validation loss: 1.976665678844657

Epoch: 6| Step: 7
Training loss: 1.0101196765899658
Validation loss: 1.9429797767311014

Epoch: 6| Step: 8
Training loss: 1.5007295608520508
Validation loss: 1.908613435683712

Epoch: 6| Step: 9
Training loss: 1.5273611545562744
Validation loss: 2.0296879288970784

Epoch: 6| Step: 10
Training loss: 1.1835978031158447
Validation loss: 1.9232955389125372

Epoch: 6| Step: 11
Training loss: 1.4810293912887573
Validation loss: 1.810322089861798

Epoch: 6| Step: 12
Training loss: 1.1371874809265137
Validation loss: 1.863885812861945

Epoch: 6| Step: 13
Training loss: 1.3394181728363037
Validation loss: 1.9185425273833736

Epoch: 436| Step: 0
Training loss: 1.1855449676513672
Validation loss: 1.8208102513385076

Epoch: 6| Step: 1
Training loss: 1.5265690088272095
Validation loss: 1.909916494482307

Epoch: 6| Step: 2
Training loss: 0.9218385219573975
Validation loss: 1.942524976627801

Epoch: 6| Step: 3
Training loss: 0.866788387298584
Validation loss: 1.9632286935724237

Epoch: 6| Step: 4
Training loss: 1.5809866189956665
Validation loss: 1.9264533853018155

Epoch: 6| Step: 5
Training loss: 0.6997930407524109
Validation loss: 1.9205917914708455

Epoch: 6| Step: 6
Training loss: 0.9360519647598267
Validation loss: 1.8907546433069373

Epoch: 6| Step: 7
Training loss: 1.2900476455688477
Validation loss: 1.9419805516478836

Epoch: 6| Step: 8
Training loss: 1.7513484954833984
Validation loss: 1.989461257893552

Epoch: 6| Step: 9
Training loss: 0.9763062000274658
Validation loss: 1.9389510013723885

Epoch: 6| Step: 10
Training loss: 1.739505648612976
Validation loss: 1.8904205317138343

Epoch: 6| Step: 11
Training loss: 1.4995403289794922
Validation loss: 1.9747712804425148

Epoch: 6| Step: 12
Training loss: 1.4489370584487915
Validation loss: 1.9132991554916545

Epoch: 6| Step: 13
Training loss: 1.3467540740966797
Validation loss: 1.9104120680080947

Epoch: 437| Step: 0
Training loss: 1.3573112487792969
Validation loss: 1.9159923304793656

Epoch: 6| Step: 1
Training loss: 0.9116261005401611
Validation loss: 1.9466165368274977

Epoch: 6| Step: 2
Training loss: 1.2414264678955078
Validation loss: 1.9779204835173905

Epoch: 6| Step: 3
Training loss: 1.105186939239502
Validation loss: 1.9544305775755195

Epoch: 6| Step: 4
Training loss: 1.3565113544464111
Validation loss: 1.9471989447070706

Epoch: 6| Step: 5
Training loss: 1.0717480182647705
Validation loss: 1.9644612266171364

Epoch: 6| Step: 6
Training loss: 1.0367560386657715
Validation loss: 1.9582013237860896

Epoch: 6| Step: 7
Training loss: 0.9583578109741211
Validation loss: 1.9888704489636164

Epoch: 6| Step: 8
Training loss: 1.1707050800323486
Validation loss: 1.897036075592041

Epoch: 6| Step: 9
Training loss: 1.2791121006011963
Validation loss: 1.8457909784009379

Epoch: 6| Step: 10
Training loss: 1.3205361366271973
Validation loss: 1.935279546245452

Epoch: 6| Step: 11
Training loss: 0.9042913913726807
Validation loss: 1.90217500604609

Epoch: 6| Step: 12
Training loss: 2.125969171524048
Validation loss: 1.9210322339047667

Epoch: 6| Step: 13
Training loss: 1.7557979822158813
Validation loss: 1.9603674821956183

Epoch: 438| Step: 0
Training loss: 1.4972724914550781
Validation loss: 1.9383706879872147

Epoch: 6| Step: 1
Training loss: 1.207848310470581
Validation loss: 1.9603304952703497

Epoch: 6| Step: 2
Training loss: 1.1578128337860107
Validation loss: 1.8847119487741941

Epoch: 6| Step: 3
Training loss: 1.6692628860473633
Validation loss: 1.9084264155357116

Epoch: 6| Step: 4
Training loss: 1.7888511419296265
Validation loss: 1.9351276236195718

Epoch: 6| Step: 5
Training loss: 1.7366065979003906
Validation loss: 1.9317408543761059

Epoch: 6| Step: 6
Training loss: 0.7912360429763794
Validation loss: 1.9860345599471882

Epoch: 6| Step: 7
Training loss: 0.8671225309371948
Validation loss: 1.9649694940095306

Epoch: 6| Step: 8
Training loss: 1.511173963546753
Validation loss: 1.997672204048403

Epoch: 6| Step: 9
Training loss: 1.0519130229949951
Validation loss: 1.8556878643651162

Epoch: 6| Step: 10
Training loss: 1.5337269306182861
Validation loss: 1.900458025675948

Epoch: 6| Step: 11
Training loss: 1.2552497386932373
Validation loss: 1.9362005059437086

Epoch: 6| Step: 12
Training loss: 0.7875728607177734
Validation loss: 1.940926351854878

Epoch: 6| Step: 13
Training loss: 0.6815025806427002
Validation loss: 1.977969790017733

Epoch: 439| Step: 0
Training loss: 1.4100865125656128
Validation loss: 1.9602958002398092

Epoch: 6| Step: 1
Training loss: 0.9579557776451111
Validation loss: 1.900293016946444

Epoch: 6| Step: 2
Training loss: 1.4659597873687744
Validation loss: 1.8802873934468916

Epoch: 6| Step: 3
Training loss: 1.0712134838104248
Validation loss: 1.9179850675726449

Epoch: 6| Step: 4
Training loss: 2.1099109649658203
Validation loss: 2.020053413606459

Epoch: 6| Step: 5
Training loss: 0.6949101686477661
Validation loss: 1.9391628644799674

Epoch: 6| Step: 6
Training loss: 1.1609221696853638
Validation loss: 2.012522969194638

Epoch: 6| Step: 7
Training loss: 1.114492654800415
Validation loss: 2.0721386786430114

Epoch: 6| Step: 8
Training loss: 1.193650722503662
Validation loss: 2.0144972006479898

Epoch: 6| Step: 9
Training loss: 1.5986626148223877
Validation loss: 2.0216023819420927

Epoch: 6| Step: 10
Training loss: 1.195831060409546
Validation loss: 1.9443453665702575

Epoch: 6| Step: 11
Training loss: 2.071258544921875
Validation loss: 1.972938383779218

Epoch: 6| Step: 12
Training loss: 1.050765037536621
Validation loss: 1.9221450180135748

Epoch: 6| Step: 13
Training loss: 1.595160961151123
Validation loss: 1.9514430543427825

Epoch: 440| Step: 0
Training loss: 0.6738681793212891
Validation loss: 1.8882834578073153

Epoch: 6| Step: 1
Training loss: 1.2439111471176147
Validation loss: 1.9379919934016403

Epoch: 6| Step: 2
Training loss: 1.2893762588500977
Validation loss: 1.9681027038123018

Epoch: 6| Step: 3
Training loss: 1.6917386054992676
Validation loss: 1.9211057027180989

Epoch: 6| Step: 4
Training loss: 1.4928439855575562
Validation loss: 1.8487297283705844

Epoch: 6| Step: 5
Training loss: 1.3940845727920532
Validation loss: 1.9147415622588126

Epoch: 6| Step: 6
Training loss: 2.3284833431243896
Validation loss: 1.9291501263136506

Epoch: 6| Step: 7
Training loss: 0.9231276512145996
Validation loss: 1.943773413217196

Epoch: 6| Step: 8
Training loss: 0.6244612336158752
Validation loss: 1.9046076395178353

Epoch: 6| Step: 9
Training loss: 1.1397920846939087
Validation loss: 1.948517345613049

Epoch: 6| Step: 10
Training loss: 1.5301313400268555
Validation loss: 1.9036633045442644

Epoch: 6| Step: 11
Training loss: 1.3919105529785156
Validation loss: 1.8919821323886994

Epoch: 6| Step: 12
Training loss: 1.1093032360076904
Validation loss: 1.9472728108847013

Epoch: 6| Step: 13
Training loss: 1.0163145065307617
Validation loss: 1.9366212724357523

Epoch: 441| Step: 0
Training loss: 1.107338309288025
Validation loss: 1.968311099595921

Epoch: 6| Step: 1
Training loss: 1.5718481540679932
Validation loss: 1.9106381836757864

Epoch: 6| Step: 2
Training loss: 1.1906464099884033
Validation loss: 1.930918683287918

Epoch: 6| Step: 3
Training loss: 0.8705575466156006
Validation loss: 1.9111803116336945

Epoch: 6| Step: 4
Training loss: 1.5213040113449097
Validation loss: 1.967644295384807

Epoch: 6| Step: 5
Training loss: 1.1388514041900635
Validation loss: 1.9997281797470585

Epoch: 6| Step: 6
Training loss: 1.8296926021575928
Validation loss: 1.902941975542294

Epoch: 6| Step: 7
Training loss: 1.0443800687789917
Validation loss: 1.9350708300067532

Epoch: 6| Step: 8
Training loss: 1.446790337562561
Validation loss: 1.900518525031305

Epoch: 6| Step: 9
Training loss: 1.0511982440948486
Validation loss: 1.948831122408631

Epoch: 6| Step: 10
Training loss: 1.2633252143859863
Validation loss: 1.8672803781365837

Epoch: 6| Step: 11
Training loss: 1.910274863243103
Validation loss: 1.9347003326621106

Epoch: 6| Step: 12
Training loss: 0.9503278136253357
Validation loss: 1.9197602528397755

Epoch: 6| Step: 13
Training loss: 1.3845793008804321
Validation loss: 1.9266941085938485

Epoch: 442| Step: 0
Training loss: 1.149123191833496
Validation loss: 1.9568997736900084

Epoch: 6| Step: 1
Training loss: 1.2944806814193726
Validation loss: 1.9356591573325537

Epoch: 6| Step: 2
Training loss: 1.2998952865600586
Validation loss: 1.915835234426683

Epoch: 6| Step: 3
Training loss: 1.243048906326294
Validation loss: 1.9874911487743419

Epoch: 6| Step: 4
Training loss: 1.0581278800964355
Validation loss: 1.883194149181407

Epoch: 6| Step: 5
Training loss: 1.4512693881988525
Validation loss: 1.90011380821146

Epoch: 6| Step: 6
Training loss: 1.3269402980804443
Validation loss: 1.9322883711066297

Epoch: 6| Step: 7
Training loss: 1.5870628356933594
Validation loss: 1.97239669933114

Epoch: 6| Step: 8
Training loss: 1.412475824356079
Validation loss: 1.9232182925747288

Epoch: 6| Step: 9
Training loss: 1.1747461557388306
Validation loss: 1.9018740935992169

Epoch: 6| Step: 10
Training loss: 1.0985116958618164
Validation loss: 1.9790359479124828

Epoch: 6| Step: 11
Training loss: 1.3987877368927002
Validation loss: 2.0117948849995932

Epoch: 6| Step: 12
Training loss: 1.188364028930664
Validation loss: 1.9665278414244294

Epoch: 6| Step: 13
Training loss: 2.315509796142578
Validation loss: 1.9726081022652246

Epoch: 443| Step: 0
Training loss: 1.4679733514785767
Validation loss: 1.978944537460163

Epoch: 6| Step: 1
Training loss: 1.7616028785705566
Validation loss: 1.9717761649880359

Epoch: 6| Step: 2
Training loss: 1.5340673923492432
Validation loss: 1.8770043439762567

Epoch: 6| Step: 3
Training loss: 0.9659118056297302
Validation loss: 1.9095494747161865

Epoch: 6| Step: 4
Training loss: 1.2048155069351196
Validation loss: 1.9223608150277087

Epoch: 6| Step: 5
Training loss: 0.754283607006073
Validation loss: 1.9199079018767162

Epoch: 6| Step: 6
Training loss: 0.9457343816757202
Validation loss: 1.8664056844608758

Epoch: 6| Step: 7
Training loss: 1.2892773151397705
Validation loss: 1.9270404256800169

Epoch: 6| Step: 8
Training loss: 1.4556410312652588
Validation loss: 1.894884801680042

Epoch: 6| Step: 9
Training loss: 1.363081455230713
Validation loss: 1.924405751689788

Epoch: 6| Step: 10
Training loss: 1.474305272102356
Validation loss: 1.8881670774952057

Epoch: 6| Step: 11
Training loss: 1.5045263767242432
Validation loss: 1.9379922138747347

Epoch: 6| Step: 12
Training loss: 1.250894546508789
Validation loss: 1.957213803004193

Epoch: 6| Step: 13
Training loss: 1.4277442693710327
Validation loss: 2.0343388049833235

Epoch: 444| Step: 0
Training loss: 0.9001166224479675
Validation loss: 1.9841558241075086

Epoch: 6| Step: 1
Training loss: 0.7897639870643616
Validation loss: 1.9225563003170876

Epoch: 6| Step: 2
Training loss: 1.9925827980041504
Validation loss: 1.9265525212851904

Epoch: 6| Step: 3
Training loss: 2.015094757080078
Validation loss: 2.015185789395404

Epoch: 6| Step: 4
Training loss: 0.9069370031356812
Validation loss: 1.9781159790613319

Epoch: 6| Step: 5
Training loss: 1.2622699737548828
Validation loss: 1.9509591024409059

Epoch: 6| Step: 6
Training loss: 1.7642124891281128
Validation loss: 2.011154502950689

Epoch: 6| Step: 7
Training loss: 1.2438559532165527
Validation loss: 1.9752439555301462

Epoch: 6| Step: 8
Training loss: 1.2535996437072754
Validation loss: 1.9637068074236634

Epoch: 6| Step: 9
Training loss: 1.3991738557815552
Validation loss: 1.9329211429883075

Epoch: 6| Step: 10
Training loss: 1.4335527420043945
Validation loss: 1.9014076238037438

Epoch: 6| Step: 11
Training loss: 1.0793187618255615
Validation loss: 1.9959619070893975

Epoch: 6| Step: 12
Training loss: 0.8586889505386353
Validation loss: 1.9033592721467376

Epoch: 6| Step: 13
Training loss: 0.8550851345062256
Validation loss: 1.9068323309703539

Epoch: 445| Step: 0
Training loss: 0.9630032777786255
Validation loss: 1.8995997675003544

Epoch: 6| Step: 1
Training loss: 1.037831425666809
Validation loss: 1.8761187497005667

Epoch: 6| Step: 2
Training loss: 1.2048957347869873
Validation loss: 1.921517510567942

Epoch: 6| Step: 3
Training loss: 1.2337461709976196
Validation loss: 1.9595789063361384

Epoch: 6| Step: 4
Training loss: 1.0365585088729858
Validation loss: 1.8500036962570683

Epoch: 6| Step: 5
Training loss: 1.9099891185760498
Validation loss: 1.9162653056524133

Epoch: 6| Step: 6
Training loss: 1.109562635421753
Validation loss: 1.8909040574104554

Epoch: 6| Step: 7
Training loss: 1.3918861150741577
Validation loss: 1.791925589243571

Epoch: 6| Step: 8
Training loss: 0.8911418318748474
Validation loss: 1.9137187004089355

Epoch: 6| Step: 9
Training loss: 1.210859775543213
Validation loss: 1.9684152769786056

Epoch: 6| Step: 10
Training loss: 2.0167601108551025
Validation loss: 1.8668372297799716

Epoch: 6| Step: 11
Training loss: 1.1650876998901367
Validation loss: 1.9596996384282266

Epoch: 6| Step: 12
Training loss: 1.144568681716919
Validation loss: 2.044763400990476

Epoch: 6| Step: 13
Training loss: 0.9990177154541016
Validation loss: 1.9419200824153038

Epoch: 446| Step: 0
Training loss: 1.1695820093154907
Validation loss: 1.9449547567675192

Epoch: 6| Step: 1
Training loss: 1.1760008335113525
Validation loss: 1.9194428484926942

Epoch: 6| Step: 2
Training loss: 1.322340965270996
Validation loss: 1.930525190086775

Epoch: 6| Step: 3
Training loss: 1.0291228294372559
Validation loss: 1.9298863026403612

Epoch: 6| Step: 4
Training loss: 1.3696753978729248
Validation loss: 1.871028402800201

Epoch: 6| Step: 5
Training loss: 1.280053734779358
Validation loss: 1.9109804758461573

Epoch: 6| Step: 6
Training loss: 1.4614591598510742
Validation loss: 1.93226457154879

Epoch: 6| Step: 7
Training loss: 0.8833931684494019
Validation loss: 1.9273577044087071

Epoch: 6| Step: 8
Training loss: 0.8613602519035339
Validation loss: 1.8535352483872445

Epoch: 6| Step: 9
Training loss: 1.857504963874817
Validation loss: 1.883766120479953

Epoch: 6| Step: 10
Training loss: 1.8103498220443726
Validation loss: 1.9258573696177492

Epoch: 6| Step: 11
Training loss: 1.2908613681793213
Validation loss: 1.9390916875613633

Epoch: 6| Step: 12
Training loss: 0.8669899106025696
Validation loss: 1.9311673820659678

Epoch: 6| Step: 13
Training loss: 0.5527029037475586
Validation loss: 1.919343440763412

Epoch: 447| Step: 0
Training loss: 1.5911400318145752
Validation loss: 1.9331069095160371

Epoch: 6| Step: 1
Training loss: 1.4814707040786743
Validation loss: 1.887676372322985

Epoch: 6| Step: 2
Training loss: 0.6904137134552002
Validation loss: 1.9557835312299832

Epoch: 6| Step: 3
Training loss: 1.9730113744735718
Validation loss: 1.972959190286616

Epoch: 6| Step: 4
Training loss: 0.9824002981185913
Validation loss: 1.944148172614395

Epoch: 6| Step: 5
Training loss: 1.002800464630127
Validation loss: 1.9023563144027547

Epoch: 6| Step: 6
Training loss: 0.5988824367523193
Validation loss: 1.9414848871128534

Epoch: 6| Step: 7
Training loss: 1.625183343887329
Validation loss: 1.9020682739955124

Epoch: 6| Step: 8
Training loss: 1.719465970993042
Validation loss: 1.9033374401830858

Epoch: 6| Step: 9
Training loss: 0.7148923873901367
Validation loss: 1.8925604333159745

Epoch: 6| Step: 10
Training loss: 0.8527352213859558
Validation loss: 1.917095027944093

Epoch: 6| Step: 11
Training loss: 1.5388933420181274
Validation loss: 1.9432335463903283

Epoch: 6| Step: 12
Training loss: 1.1265794038772583
Validation loss: 1.88486006183009

Epoch: 6| Step: 13
Training loss: 1.565472960472107
Validation loss: 1.879798855832828

Epoch: 448| Step: 0
Training loss: 0.8928614854812622
Validation loss: 1.9864227823031846

Epoch: 6| Step: 1
Training loss: 0.9512436985969543
Validation loss: 1.9114142348689418

Epoch: 6| Step: 2
Training loss: 1.9103343486785889
Validation loss: 1.9329408522575133

Epoch: 6| Step: 3
Training loss: 2.253415822982788
Validation loss: 1.8565055196003248

Epoch: 6| Step: 4
Training loss: 1.473071813583374
Validation loss: 1.8888431543944983

Epoch: 6| Step: 5
Training loss: 0.9941656589508057
Validation loss: 2.058802561093402

Epoch: 6| Step: 6
Training loss: 1.2382431030273438
Validation loss: 1.8557247577175018

Epoch: 6| Step: 7
Training loss: 1.1885762214660645
Validation loss: 1.8956154982248943

Epoch: 6| Step: 8
Training loss: 0.7885867953300476
Validation loss: 1.982388824544927

Epoch: 6| Step: 9
Training loss: 1.1719146966934204
Validation loss: 1.9625678011166152

Epoch: 6| Step: 10
Training loss: 1.2991232872009277
Validation loss: 2.018097613447456

Epoch: 6| Step: 11
Training loss: 0.7117106914520264
Validation loss: 1.8873875320598643

Epoch: 6| Step: 12
Training loss: 0.9074475169181824
Validation loss: 1.8732834990306566

Epoch: 6| Step: 13
Training loss: 0.9216942191123962
Validation loss: 1.9142008263577697

Epoch: 449| Step: 0
Training loss: 1.1625573635101318
Validation loss: 1.9069241169960267

Epoch: 6| Step: 1
Training loss: 1.3256158828735352
Validation loss: 1.9294878077763382

Epoch: 6| Step: 2
Training loss: 0.7434770464897156
Validation loss: 1.9488959312438965

Epoch: 6| Step: 3
Training loss: 0.8542125225067139
Validation loss: 1.9574717488340152

Epoch: 6| Step: 4
Training loss: 1.538478970527649
Validation loss: 1.889560527698968

Epoch: 6| Step: 5
Training loss: 0.869361162185669
Validation loss: 1.9095247714750228

Epoch: 6| Step: 6
Training loss: 1.4133057594299316
Validation loss: 1.9091956820539249

Epoch: 6| Step: 7
Training loss: 1.8641419410705566
Validation loss: 1.8162818185744747

Epoch: 6| Step: 8
Training loss: 1.0713961124420166
Validation loss: 1.9927806520974765

Epoch: 6| Step: 9
Training loss: 1.2484937906265259
Validation loss: 1.916821716934122

Epoch: 6| Step: 10
Training loss: 1.8673999309539795
Validation loss: 1.8958177592164727

Epoch: 6| Step: 11
Training loss: 1.2996788024902344
Validation loss: 1.918965244805941

Epoch: 6| Step: 12
Training loss: 0.6288948059082031
Validation loss: 1.9532087938759917

Epoch: 6| Step: 13
Training loss: 1.634697437286377
Validation loss: 2.015098237222241

Epoch: 450| Step: 0
Training loss: 1.4385182857513428
Validation loss: 1.9380749989581365

Epoch: 6| Step: 1
Training loss: 1.7224817276000977
Validation loss: 1.9390580602871474

Epoch: 6| Step: 2
Training loss: 1.1789534091949463
Validation loss: 1.9075965035346247

Epoch: 6| Step: 3
Training loss: 0.9904104471206665
Validation loss: 1.9671384801146805

Epoch: 6| Step: 4
Training loss: 1.3864680528640747
Validation loss: 1.8782825828880392

Epoch: 6| Step: 5
Training loss: 1.4934762716293335
Validation loss: 1.9161133676446893

Epoch: 6| Step: 6
Training loss: 1.328457236289978
Validation loss: 1.894660521579045

Epoch: 6| Step: 7
Training loss: 1.1748685836791992
Validation loss: 1.892979896196755

Epoch: 6| Step: 8
Training loss: 0.8732551336288452
Validation loss: 1.8691812894677604

Epoch: 6| Step: 9
Training loss: 0.9399987459182739
Validation loss: 1.9274976304782334

Epoch: 6| Step: 10
Training loss: 1.3293089866638184
Validation loss: 1.9100810020200667

Epoch: 6| Step: 11
Training loss: 1.3349250555038452
Validation loss: 1.9006190543533654

Epoch: 6| Step: 12
Training loss: 1.0819995403289795
Validation loss: 1.9312244679338189

Epoch: 6| Step: 13
Training loss: 1.148526668548584
Validation loss: 1.956259278840916

Epoch: 451| Step: 0
Training loss: 1.1973762512207031
Validation loss: 1.8917863881716164

Epoch: 6| Step: 1
Training loss: 1.8963452577590942
Validation loss: 1.8727852362458424

Epoch: 6| Step: 2
Training loss: 1.3811395168304443
Validation loss: 1.895928418764504

Epoch: 6| Step: 3
Training loss: 1.5858092308044434
Validation loss: 1.9708648612422328

Epoch: 6| Step: 4
Training loss: 1.170606255531311
Validation loss: 1.9068080763663016

Epoch: 6| Step: 5
Training loss: 1.2789591550827026
Validation loss: 1.9640180795423445

Epoch: 6| Step: 6
Training loss: 1.061980962753296
Validation loss: 1.9466617415028233

Epoch: 6| Step: 7
Training loss: 1.3881207704544067
Validation loss: 1.9130190444248978

Epoch: 6| Step: 8
Training loss: 1.195624828338623
Validation loss: 1.9854276141812723

Epoch: 6| Step: 9
Training loss: 1.074385166168213
Validation loss: 1.9732160542600898

Epoch: 6| Step: 10
Training loss: 1.0517301559448242
Validation loss: 1.912675093579036

Epoch: 6| Step: 11
Training loss: 1.0718506574630737
Validation loss: 1.9177470335396387

Epoch: 6| Step: 12
Training loss: 1.3556692600250244
Validation loss: 2.0037991064851

Epoch: 6| Step: 13
Training loss: 1.2620737552642822
Validation loss: 1.90658781092654

Epoch: 452| Step: 0
Training loss: 1.296507716178894
Validation loss: 1.8968571027119954

Epoch: 6| Step: 1
Training loss: 1.386783480644226
Validation loss: 1.9185258778192664

Epoch: 6| Step: 2
Training loss: 1.3754953145980835
Validation loss: 1.8860028725798412

Epoch: 6| Step: 3
Training loss: 1.448171615600586
Validation loss: 1.8764341620988743

Epoch: 6| Step: 4
Training loss: 1.3281149864196777
Validation loss: 1.9149224937603038

Epoch: 6| Step: 5
Training loss: 1.4284946918487549
Validation loss: 1.9129478111062

Epoch: 6| Step: 6
Training loss: 1.1076340675354004
Validation loss: 1.8649240245101273

Epoch: 6| Step: 7
Training loss: 1.7009215354919434
Validation loss: 1.885600011835816

Epoch: 6| Step: 8
Training loss: 1.3293235301971436
Validation loss: 1.9171894237559328

Epoch: 6| Step: 9
Training loss: 1.1550254821777344
Validation loss: 1.8907408304111932

Epoch: 6| Step: 10
Training loss: 0.637768566608429
Validation loss: 1.8942802362544562

Epoch: 6| Step: 11
Training loss: 1.3589560985565186
Validation loss: 1.8100242589109687

Epoch: 6| Step: 12
Training loss: 1.1456010341644287
Validation loss: 1.9199541486719602

Epoch: 6| Step: 13
Training loss: 1.1503987312316895
Validation loss: 1.9483395571349769

Epoch: 453| Step: 0
Training loss: 1.1079446077346802
Validation loss: 1.9700356632150628

Epoch: 6| Step: 1
Training loss: 1.381757140159607
Validation loss: 1.9007002474159322

Epoch: 6| Step: 2
Training loss: 1.6202291250228882
Validation loss: 1.9251194974427581

Epoch: 6| Step: 3
Training loss: 1.1084988117218018
Validation loss: 2.006886721939169

Epoch: 6| Step: 4
Training loss: 1.0632624626159668
Validation loss: 1.9754089027322748

Epoch: 6| Step: 5
Training loss: 1.3731313943862915
Validation loss: 1.9310528873115458

Epoch: 6| Step: 6
Training loss: 1.330099105834961
Validation loss: 1.916108105772285

Epoch: 6| Step: 7
Training loss: 0.9684322476387024
Validation loss: 1.992841725708336

Epoch: 6| Step: 8
Training loss: 1.6808650493621826
Validation loss: 1.9169340184939805

Epoch: 6| Step: 9
Training loss: 1.2081259489059448
Validation loss: 1.9438930096164826

Epoch: 6| Step: 10
Training loss: 0.7327705025672913
Validation loss: 1.9848072451929892

Epoch: 6| Step: 11
Training loss: 1.0521323680877686
Validation loss: 1.86362325632444

Epoch: 6| Step: 12
Training loss: 1.567047357559204
Validation loss: 1.9628999771610383

Epoch: 6| Step: 13
Training loss: 1.0126683712005615
Validation loss: 1.953815822960228

Epoch: 454| Step: 0
Training loss: 1.3773906230926514
Validation loss: 1.8572378440569806

Epoch: 6| Step: 1
Training loss: 1.3951237201690674
Validation loss: 1.9276513104797692

Epoch: 6| Step: 2
Training loss: 0.8928020000457764
Validation loss: 1.9138120797372633

Epoch: 6| Step: 3
Training loss: 1.2089730501174927
Validation loss: 1.9024822724762784

Epoch: 6| Step: 4
Training loss: 1.2685773372650146
Validation loss: 1.9105241375584756

Epoch: 6| Step: 5
Training loss: 1.053675889968872
Validation loss: 1.9835385891699022

Epoch: 6| Step: 6
Training loss: 1.1320022344589233
Validation loss: 1.9913913908825125

Epoch: 6| Step: 7
Training loss: 0.8495715260505676
Validation loss: 1.929359145061944

Epoch: 6| Step: 8
Training loss: 1.4113209247589111
Validation loss: 1.9331068813159902

Epoch: 6| Step: 9
Training loss: 1.9562129974365234
Validation loss: 1.8959759614800895

Epoch: 6| Step: 10
Training loss: 1.1388789415359497
Validation loss: 1.9195859368129442

Epoch: 6| Step: 11
Training loss: 0.985970139503479
Validation loss: 1.9751150326062274

Epoch: 6| Step: 12
Training loss: 1.9083936214447021
Validation loss: 1.8823809854445919

Epoch: 6| Step: 13
Training loss: 0.8363268375396729
Validation loss: 1.967976708565989

Epoch: 455| Step: 0
Training loss: 0.7154816389083862
Validation loss: 1.980631733453402

Epoch: 6| Step: 1
Training loss: 0.996964693069458
Validation loss: 1.9861369825178576

Epoch: 6| Step: 2
Training loss: 0.7640952467918396
Validation loss: 1.987002782924201

Epoch: 6| Step: 3
Training loss: 1.2894343137741089
Validation loss: 1.9954257780505764

Epoch: 6| Step: 4
Training loss: 1.0079340934753418
Validation loss: 2.0318426291147866

Epoch: 6| Step: 5
Training loss: 1.5521636009216309
Validation loss: 1.9984954031564857

Epoch: 6| Step: 6
Training loss: 0.8596017360687256
Validation loss: 1.9777501834336149

Epoch: 6| Step: 7
Training loss: 1.7168601751327515
Validation loss: 1.9355168650227208

Epoch: 6| Step: 8
Training loss: 1.3237905502319336
Validation loss: 1.909418939262308

Epoch: 6| Step: 9
Training loss: 1.1677563190460205
Validation loss: 1.9041475634421072

Epoch: 6| Step: 10
Training loss: 1.315199851989746
Validation loss: 1.9030422933640019

Epoch: 6| Step: 11
Training loss: 1.2409820556640625
Validation loss: 1.901758106805945

Epoch: 6| Step: 12
Training loss: 1.5788993835449219
Validation loss: 1.8917059078011462

Epoch: 6| Step: 13
Training loss: 0.9783837795257568
Validation loss: 1.8946236461721442

Epoch: 456| Step: 0
Training loss: 1.7096469402313232
Validation loss: 1.8911337596113964

Epoch: 6| Step: 1
Training loss: 1.2545130252838135
Validation loss: 1.9708642434048396

Epoch: 6| Step: 2
Training loss: 1.2450751066207886
Validation loss: 1.8955831425164336

Epoch: 6| Step: 3
Training loss: 1.1316109895706177
Validation loss: 1.9235324013617732

Epoch: 6| Step: 4
Training loss: 1.5536386966705322
Validation loss: 1.9325007174604683

Epoch: 6| Step: 5
Training loss: 0.9488258361816406
Validation loss: 1.9731697292738064

Epoch: 6| Step: 6
Training loss: 1.4848079681396484
Validation loss: 1.9269106029182352

Epoch: 6| Step: 7
Training loss: 1.4925734996795654
Validation loss: 1.9182653593760666

Epoch: 6| Step: 8
Training loss: 1.3686604499816895
Validation loss: 1.8897201553467782

Epoch: 6| Step: 9
Training loss: 0.574837327003479
Validation loss: 1.955943166568715

Epoch: 6| Step: 10
Training loss: 1.091841220855713
Validation loss: 1.9153559259189072

Epoch: 6| Step: 11
Training loss: 1.2506394386291504
Validation loss: 1.9139254336716027

Epoch: 6| Step: 12
Training loss: 1.010477066040039
Validation loss: 1.8613770033723565

Epoch: 6| Step: 13
Training loss: 1.370644211769104
Validation loss: 1.972292838558074

Epoch: 457| Step: 0
Training loss: 0.6574166417121887
Validation loss: 1.9155893197623632

Epoch: 6| Step: 1
Training loss: 0.8544976115226746
Validation loss: 1.9687691388591644

Epoch: 6| Step: 2
Training loss: 1.3055408000946045
Validation loss: 1.9749161915112567

Epoch: 6| Step: 3
Training loss: 1.3628284931182861
Validation loss: 1.9087903755967335

Epoch: 6| Step: 4
Training loss: 1.1018439531326294
Validation loss: 1.9034171360795216

Epoch: 6| Step: 5
Training loss: 1.1966733932495117
Validation loss: 1.9182969857287664

Epoch: 6| Step: 6
Training loss: 1.2876203060150146
Validation loss: 1.9422261817480928

Epoch: 6| Step: 7
Training loss: 1.3310052156448364
Validation loss: 1.8532495780657696

Epoch: 6| Step: 8
Training loss: 1.4256172180175781
Validation loss: 1.898047516422887

Epoch: 6| Step: 9
Training loss: 1.4475922584533691
Validation loss: 1.8512853422472555

Epoch: 6| Step: 10
Training loss: 1.5225211381912231
Validation loss: 2.004342685463608

Epoch: 6| Step: 11
Training loss: 0.9110615253448486
Validation loss: 1.9629079449561335

Epoch: 6| Step: 12
Training loss: 1.3859236240386963
Validation loss: 1.9522009818784651

Epoch: 6| Step: 13
Training loss: 1.6443818807601929
Validation loss: 1.8703285788977018

Epoch: 458| Step: 0
Training loss: 1.0280884504318237
Validation loss: 1.9235219583716443

Epoch: 6| Step: 1
Training loss: 0.9500614404678345
Validation loss: 1.9330468998160413

Epoch: 6| Step: 2
Training loss: 1.1470057964324951
Validation loss: 2.025280975526379

Epoch: 6| Step: 3
Training loss: 1.2812743186950684
Validation loss: 1.8998224299441102

Epoch: 6| Step: 4
Training loss: 0.7531870603561401
Validation loss: 1.9159100722241145

Epoch: 6| Step: 5
Training loss: 1.221733808517456
Validation loss: 1.8773202665390507

Epoch: 6| Step: 6
Training loss: 1.1689552068710327
Validation loss: 1.9130988633760841

Epoch: 6| Step: 7
Training loss: 1.3094276189804077
Validation loss: 1.907971946142053

Epoch: 6| Step: 8
Training loss: 1.1870474815368652
Validation loss: 1.935480543362197

Epoch: 6| Step: 9
Training loss: 1.240726113319397
Validation loss: 1.8782720950341993

Epoch: 6| Step: 10
Training loss: 1.5126819610595703
Validation loss: 1.8505632262076102

Epoch: 6| Step: 11
Training loss: 1.382462501525879
Validation loss: 1.8850761434083343

Epoch: 6| Step: 12
Training loss: 1.274179220199585
Validation loss: 1.9622576557179934

Epoch: 6| Step: 13
Training loss: 0.9519282579421997
Validation loss: 2.0019362921355874

Epoch: 459| Step: 0
Training loss: 1.501349925994873
Validation loss: 1.8847454363299954

Epoch: 6| Step: 1
Training loss: 1.2953548431396484
Validation loss: 1.8781881063215193

Epoch: 6| Step: 2
Training loss: 1.376285433769226
Validation loss: 1.907942101519595

Epoch: 6| Step: 3
Training loss: 1.0212242603302002
Validation loss: 1.8786591778519333

Epoch: 6| Step: 4
Training loss: 0.8129415512084961
Validation loss: 1.9049290482715895

Epoch: 6| Step: 5
Training loss: 1.6020607948303223
Validation loss: 1.9866293207291634

Epoch: 6| Step: 6
Training loss: 1.1735203266143799
Validation loss: 1.9206854604905652

Epoch: 6| Step: 7
Training loss: 1.717424988746643
Validation loss: 1.9429465493848246

Epoch: 6| Step: 8
Training loss: 1.434046745300293
Validation loss: 1.9602515133478309

Epoch: 6| Step: 9
Training loss: 1.013150691986084
Validation loss: 1.9289270703510573

Epoch: 6| Step: 10
Training loss: 1.038020133972168
Validation loss: 1.9289263025406869

Epoch: 6| Step: 11
Training loss: 1.1762690544128418
Validation loss: 1.894577391685978

Epoch: 6| Step: 12
Training loss: 1.4504601955413818
Validation loss: 1.958088057015532

Epoch: 6| Step: 13
Training loss: 0.8172155022621155
Validation loss: 1.8726925311550018

Epoch: 460| Step: 0
Training loss: 1.1098699569702148
Validation loss: 1.8999500748931721

Epoch: 6| Step: 1
Training loss: 1.2156113386154175
Validation loss: 1.869007670751182

Epoch: 6| Step: 2
Training loss: 1.0684442520141602
Validation loss: 1.9667881560581986

Epoch: 6| Step: 3
Training loss: 1.1255853176116943
Validation loss: 1.8126292741426857

Epoch: 6| Step: 4
Training loss: 1.190307855606079
Validation loss: 1.9100230560507825

Epoch: 6| Step: 5
Training loss: 1.423243761062622
Validation loss: 1.901454274372388

Epoch: 6| Step: 6
Training loss: 1.3712806701660156
Validation loss: 1.874421129944504

Epoch: 6| Step: 7
Training loss: 1.6532992124557495
Validation loss: 1.8536963591011621

Epoch: 6| Step: 8
Training loss: 0.8552244305610657
Validation loss: 1.8543534227596816

Epoch: 6| Step: 9
Training loss: 1.1783065795898438
Validation loss: 1.9444343428457938

Epoch: 6| Step: 10
Training loss: 1.2636600732803345
Validation loss: 1.9639738336686166

Epoch: 6| Step: 11
Training loss: 1.1219273805618286
Validation loss: 1.9390474352785336

Epoch: 6| Step: 12
Training loss: 1.0581445693969727
Validation loss: 1.9454421984252108

Epoch: 6| Step: 13
Training loss: 0.93907630443573
Validation loss: 1.890615354302109

Epoch: 461| Step: 0
Training loss: 1.3445870876312256
Validation loss: 1.9188906172270417

Epoch: 6| Step: 1
Training loss: 1.4210797548294067
Validation loss: 1.9539779283667122

Epoch: 6| Step: 2
Training loss: 1.094691514968872
Validation loss: 1.9309865505464616

Epoch: 6| Step: 3
Training loss: 1.5054295063018799
Validation loss: 1.8971942817011187

Epoch: 6| Step: 4
Training loss: 1.1867960691452026
Validation loss: 1.8903142508640085

Epoch: 6| Step: 5
Training loss: 0.8503488898277283
Validation loss: 1.929959379216676

Epoch: 6| Step: 6
Training loss: 0.986011266708374
Validation loss: 1.9314456524387482

Epoch: 6| Step: 7
Training loss: 1.204275369644165
Validation loss: 1.9150610431548087

Epoch: 6| Step: 8
Training loss: 1.2359431982040405
Validation loss: 1.9114567131124518

Epoch: 6| Step: 9
Training loss: 1.0303692817687988
Validation loss: 1.9521808598631172

Epoch: 6| Step: 10
Training loss: 1.2111871242523193
Validation loss: 1.8098638698618899

Epoch: 6| Step: 11
Training loss: 1.6857680082321167
Validation loss: 1.9028471131478586

Epoch: 6| Step: 12
Training loss: 0.9112944602966309
Validation loss: 1.8592233709109727

Epoch: 6| Step: 13
Training loss: 1.6389880180358887
Validation loss: 1.8970441510600429

Epoch: 462| Step: 0
Training loss: 0.7374995946884155
Validation loss: 1.98332413037618

Epoch: 6| Step: 1
Training loss: 1.0678021907806396
Validation loss: 1.859424803846626

Epoch: 6| Step: 2
Training loss: 0.7895218133926392
Validation loss: 1.8796489443830264

Epoch: 6| Step: 3
Training loss: 1.143069863319397
Validation loss: 1.9292375733775478

Epoch: 6| Step: 4
Training loss: 1.2564527988433838
Validation loss: 1.9228394057161065

Epoch: 6| Step: 5
Training loss: 1.174194097518921
Validation loss: 1.910327821649531

Epoch: 6| Step: 6
Training loss: 1.4506299495697021
Validation loss: 1.9164824960052327

Epoch: 6| Step: 7
Training loss: 1.0996265411376953
Validation loss: 1.915066942091911

Epoch: 6| Step: 8
Training loss: 1.6089301109313965
Validation loss: 1.9060550018023419

Epoch: 6| Step: 9
Training loss: 1.8683552742004395
Validation loss: 1.8724105435032998

Epoch: 6| Step: 10
Training loss: 1.0279287099838257
Validation loss: 1.912708346561719

Epoch: 6| Step: 11
Training loss: 1.3298285007476807
Validation loss: 1.9001226976353636

Epoch: 6| Step: 12
Training loss: 0.7763952016830444
Validation loss: 1.8957233646864533

Epoch: 6| Step: 13
Training loss: 2.0942249298095703
Validation loss: 1.9465417708120039

Epoch: 463| Step: 0
Training loss: 1.4956003427505493
Validation loss: 1.917115311468801

Epoch: 6| Step: 1
Training loss: 1.4477248191833496
Validation loss: 1.856466659935572

Epoch: 6| Step: 2
Training loss: 0.7825279235839844
Validation loss: 1.8947832917654386

Epoch: 6| Step: 3
Training loss: 1.5308727025985718
Validation loss: 1.8682954375461867

Epoch: 6| Step: 4
Training loss: 1.1590392589569092
Validation loss: 1.9175467516786309

Epoch: 6| Step: 5
Training loss: 1.1613905429840088
Validation loss: 1.8574899114588255

Epoch: 6| Step: 6
Training loss: 1.3324687480926514
Validation loss: 1.9699790439298075

Epoch: 6| Step: 7
Training loss: 1.727371335029602
Validation loss: 1.9547634073483047

Epoch: 6| Step: 8
Training loss: 1.444121241569519
Validation loss: 1.9165937182723836

Epoch: 6| Step: 9
Training loss: 1.766183614730835
Validation loss: 2.002816314338356

Epoch: 6| Step: 10
Training loss: 1.179785966873169
Validation loss: 1.88277268409729

Epoch: 6| Step: 11
Training loss: 0.9157224297523499
Validation loss: 1.9680362016923967

Epoch: 6| Step: 12
Training loss: 0.8198292255401611
Validation loss: 1.9406832661679996

Epoch: 6| Step: 13
Training loss: 0.5273633599281311
Validation loss: 1.863496962413993

Epoch: 464| Step: 0
Training loss: 1.1858384609222412
Validation loss: 1.861837052529858

Epoch: 6| Step: 1
Training loss: 1.5141639709472656
Validation loss: 1.9294777275413595

Epoch: 6| Step: 2
Training loss: 1.258361577987671
Validation loss: 1.9487874097721551

Epoch: 6| Step: 3
Training loss: 1.3095654249191284
Validation loss: 1.9337933191689112

Epoch: 6| Step: 4
Training loss: 1.5230287313461304
Validation loss: 1.8726871500733078

Epoch: 6| Step: 5
Training loss: 1.1820824146270752
Validation loss: 1.9132096062424362

Epoch: 6| Step: 6
Training loss: 1.0189332962036133
Validation loss: 1.898054661289338

Epoch: 6| Step: 7
Training loss: 0.7861489653587341
Validation loss: 1.9150132222842144

Epoch: 6| Step: 8
Training loss: 0.9390532970428467
Validation loss: 1.9055690509016796

Epoch: 6| Step: 9
Training loss: 1.2215733528137207
Validation loss: 1.936575687059792

Epoch: 6| Step: 10
Training loss: 0.9266863465309143
Validation loss: 1.9684662536908222

Epoch: 6| Step: 11
Training loss: 1.2093968391418457
Validation loss: 1.9032257679970033

Epoch: 6| Step: 12
Training loss: 1.5626354217529297
Validation loss: 1.9621141738789056

Epoch: 6| Step: 13
Training loss: 0.9287405014038086
Validation loss: 1.9495903779101629

Epoch: 465| Step: 0
Training loss: 0.9832566380500793
Validation loss: 1.962692831152229

Epoch: 6| Step: 1
Training loss: 1.5120359659194946
Validation loss: 1.886575980853009

Epoch: 6| Step: 2
Training loss: 1.8136184215545654
Validation loss: 1.940420199466008

Epoch: 6| Step: 3
Training loss: 1.1348447799682617
Validation loss: 1.9502563502198906

Epoch: 6| Step: 4
Training loss: 1.3864681720733643
Validation loss: 1.9199164541818763

Epoch: 6| Step: 5
Training loss: 0.9139596819877625
Validation loss: 1.9149961497194024

Epoch: 6| Step: 6
Training loss: 1.6064732074737549
Validation loss: 1.9196776215748121

Epoch: 6| Step: 7
Training loss: 0.6949312686920166
Validation loss: 1.885175435773788

Epoch: 6| Step: 8
Training loss: 1.7764276266098022
Validation loss: 1.9312975381010322

Epoch: 6| Step: 9
Training loss: 0.7703200578689575
Validation loss: 1.8793758397461267

Epoch: 6| Step: 10
Training loss: 1.081672191619873
Validation loss: 1.9617726520825458

Epoch: 6| Step: 11
Training loss: 1.1150076389312744
Validation loss: 1.9020361951602403

Epoch: 6| Step: 12
Training loss: 1.2751920223236084
Validation loss: 2.0300130459570114

Epoch: 6| Step: 13
Training loss: 2.0694873332977295
Validation loss: 1.902711340176162

Epoch: 466| Step: 0
Training loss: 1.1202538013458252
Validation loss: 1.8990204872623566

Epoch: 6| Step: 1
Training loss: 1.825208067893982
Validation loss: 1.9287945250029206

Epoch: 6| Step: 2
Training loss: 1.2186336517333984
Validation loss: 1.9597194117884482

Epoch: 6| Step: 3
Training loss: 1.0372438430786133
Validation loss: 1.956854340850666

Epoch: 6| Step: 4
Training loss: 1.887732982635498
Validation loss: 1.946130270599037

Epoch: 6| Step: 5
Training loss: 1.196321964263916
Validation loss: 2.009201254895938

Epoch: 6| Step: 6
Training loss: 0.9622058868408203
Validation loss: 1.9650044928314865

Epoch: 6| Step: 7
Training loss: 1.2467063665390015
Validation loss: 2.0061693499165196

Epoch: 6| Step: 8
Training loss: 0.8875582218170166
Validation loss: 1.9209815456021218

Epoch: 6| Step: 9
Training loss: 0.9016228318214417
Validation loss: 1.9459251896027596

Epoch: 6| Step: 10
Training loss: 1.1240055561065674
Validation loss: 1.973196493682041

Epoch: 6| Step: 11
Training loss: 1.2138328552246094
Validation loss: 1.9763654624262164

Epoch: 6| Step: 12
Training loss: 1.2695472240447998
Validation loss: 1.9267274513039538

Epoch: 6| Step: 13
Training loss: 1.2586580514907837
Validation loss: 1.8920101888718144

Epoch: 467| Step: 0
Training loss: 1.283829927444458
Validation loss: 1.883669150772915

Epoch: 6| Step: 1
Training loss: 1.1697635650634766
Validation loss: 1.8517262269091863

Epoch: 6| Step: 2
Training loss: 0.8028011322021484
Validation loss: 1.8510162445806688

Epoch: 6| Step: 3
Training loss: 1.3399806022644043
Validation loss: 1.9125839112907328

Epoch: 6| Step: 4
Training loss: 0.996705174446106
Validation loss: 1.8768337362556047

Epoch: 6| Step: 5
Training loss: 1.0632715225219727
Validation loss: 1.8976318246574813

Epoch: 6| Step: 6
Training loss: 1.3060767650604248
Validation loss: 1.9409391854398994

Epoch: 6| Step: 7
Training loss: 1.1654683351516724
Validation loss: 1.895219474710444

Epoch: 6| Step: 8
Training loss: 1.8584277629852295
Validation loss: 1.958850593977077

Epoch: 6| Step: 9
Training loss: 1.0938866138458252
Validation loss: 1.973137576092956

Epoch: 6| Step: 10
Training loss: 1.4930377006530762
Validation loss: 1.913912292449705

Epoch: 6| Step: 11
Training loss: 1.295375108718872
Validation loss: 1.9157203910171345

Epoch: 6| Step: 12
Training loss: 1.193145990371704
Validation loss: 1.9230347602598128

Epoch: 6| Step: 13
Training loss: 0.8390586376190186
Validation loss: 1.915658043276879

Epoch: 468| Step: 0
Training loss: 1.2849878072738647
Validation loss: 1.9059001732898015

Epoch: 6| Step: 1
Training loss: 1.0775349140167236
Validation loss: 2.02186978632404

Epoch: 6| Step: 2
Training loss: 0.8198696374893188
Validation loss: 1.9313984122327579

Epoch: 6| Step: 3
Training loss: 1.378867745399475
Validation loss: 1.9550750845222062

Epoch: 6| Step: 4
Training loss: 1.19590163230896
Validation loss: 1.9286818222333026

Epoch: 6| Step: 5
Training loss: 0.7383952736854553
Validation loss: 1.997081361791139

Epoch: 6| Step: 6
Training loss: 1.7044053077697754
Validation loss: 1.9160380132736698

Epoch: 6| Step: 7
Training loss: 0.7668411135673523
Validation loss: 1.945705666336962

Epoch: 6| Step: 8
Training loss: 2.013838291168213
Validation loss: 1.8666644339920373

Epoch: 6| Step: 9
Training loss: 1.2891566753387451
Validation loss: 1.9914670298176427

Epoch: 6| Step: 10
Training loss: 1.1597073078155518
Validation loss: 1.9173484515118342

Epoch: 6| Step: 11
Training loss: 1.2910914421081543
Validation loss: 1.9045205103453768

Epoch: 6| Step: 12
Training loss: 1.298162579536438
Validation loss: 1.9321332926391273

Epoch: 6| Step: 13
Training loss: 1.6164886951446533
Validation loss: 1.8417460072425105

Epoch: 469| Step: 0
Training loss: 1.2549850940704346
Validation loss: 1.964601271895952

Epoch: 6| Step: 1
Training loss: 1.4852876663208008
Validation loss: 1.8571948659035467

Epoch: 6| Step: 2
Training loss: 1.3967727422714233
Validation loss: 1.8806580702463787

Epoch: 6| Step: 3
Training loss: 0.940977156162262
Validation loss: 1.9085206036926599

Epoch: 6| Step: 4
Training loss: 1.1645476818084717
Validation loss: 1.874819746581457

Epoch: 6| Step: 5
Training loss: 1.2775431871414185
Validation loss: 1.8643388254668123

Epoch: 6| Step: 6
Training loss: 1.2025525569915771
Validation loss: 1.9405155104975547

Epoch: 6| Step: 7
Training loss: 0.7563558220863342
Validation loss: 1.856143154123778

Epoch: 6| Step: 8
Training loss: 1.239861011505127
Validation loss: 1.9041799742688414

Epoch: 6| Step: 9
Training loss: 1.0094847679138184
Validation loss: 1.9436108835281865

Epoch: 6| Step: 10
Training loss: 0.622689962387085
Validation loss: 1.9441917762961438

Epoch: 6| Step: 11
Training loss: 1.3943002223968506
Validation loss: 1.9645825445011098

Epoch: 6| Step: 12
Training loss: 1.6307976245880127
Validation loss: 1.9073597641401394

Epoch: 6| Step: 13
Training loss: 1.8963394165039062
Validation loss: 1.9374743379572386

Epoch: 470| Step: 0
Training loss: 0.8233345746994019
Validation loss: 2.0082382707185644

Epoch: 6| Step: 1
Training loss: 0.8864141702651978
Validation loss: 1.8475572806532665

Epoch: 6| Step: 2
Training loss: 0.9294037222862244
Validation loss: 1.9785616064584384

Epoch: 6| Step: 3
Training loss: 1.4741567373275757
Validation loss: 1.9288005591720663

Epoch: 6| Step: 4
Training loss: 0.780850350856781
Validation loss: 1.9239549021567068

Epoch: 6| Step: 5
Training loss: 1.2115107774734497
Validation loss: 1.955714830788233

Epoch: 6| Step: 6
Training loss: 1.0696001052856445
Validation loss: 1.9578043722337293

Epoch: 6| Step: 7
Training loss: 1.2654612064361572
Validation loss: 1.9159088109129219

Epoch: 6| Step: 8
Training loss: 0.8131555318832397
Validation loss: 1.8947089449051888

Epoch: 6| Step: 9
Training loss: 1.7128806114196777
Validation loss: 1.8883665172002648

Epoch: 6| Step: 10
Training loss: 1.035191297531128
Validation loss: 1.9656650148412234

Epoch: 6| Step: 11
Training loss: 1.2404571771621704
Validation loss: 1.9898451169331868

Epoch: 6| Step: 12
Training loss: 1.9254581928253174
Validation loss: 1.877704413988257

Epoch: 6| Step: 13
Training loss: 0.5930402278900146
Validation loss: 1.9426494183078888

Epoch: 471| Step: 0
Training loss: 1.477020263671875
Validation loss: 1.9618103722090363

Epoch: 6| Step: 1
Training loss: 0.7846275568008423
Validation loss: 1.87263794355495

Epoch: 6| Step: 2
Training loss: 1.1098062992095947
Validation loss: 1.8630370863022343

Epoch: 6| Step: 3
Training loss: 1.74518883228302
Validation loss: 1.9440377835304505

Epoch: 6| Step: 4
Training loss: 0.8982990980148315
Validation loss: 1.8843493384699668

Epoch: 6| Step: 5
Training loss: 1.2441766262054443
Validation loss: 1.9349534396202333

Epoch: 6| Step: 6
Training loss: 0.6987959146499634
Validation loss: 1.9667900916068786

Epoch: 6| Step: 7
Training loss: 1.5658257007598877
Validation loss: 1.9393213333622101

Epoch: 6| Step: 8
Training loss: 1.1129276752471924
Validation loss: 1.9333784682776338

Epoch: 6| Step: 9
Training loss: 1.175349473953247
Validation loss: 1.8620656792835524

Epoch: 6| Step: 10
Training loss: 1.1067780256271362
Validation loss: 1.9308287379562215

Epoch: 6| Step: 11
Training loss: 1.144102931022644
Validation loss: 1.9196539284080587

Epoch: 6| Step: 12
Training loss: 1.2140743732452393
Validation loss: 1.8771521634952997

Epoch: 6| Step: 13
Training loss: 1.7408932447433472
Validation loss: 1.8874526152046778

Epoch: 472| Step: 0
Training loss: 1.3536005020141602
Validation loss: 1.8387952594346897

Epoch: 6| Step: 1
Training loss: 0.9659956097602844
Validation loss: 1.8813202201679189

Epoch: 6| Step: 2
Training loss: 1.2529863119125366
Validation loss: 1.9064907899466894

Epoch: 6| Step: 3
Training loss: 1.0921404361724854
Validation loss: 1.9247155599696661

Epoch: 6| Step: 4
Training loss: 1.4245507717132568
Validation loss: 1.7634104310825307

Epoch: 6| Step: 5
Training loss: 0.738673746585846
Validation loss: 1.9648792436045985

Epoch: 6| Step: 6
Training loss: 1.0068590641021729
Validation loss: 1.9236347457414031

Epoch: 6| Step: 7
Training loss: 1.1582783460617065
Validation loss: 1.918814960346427

Epoch: 6| Step: 8
Training loss: 1.2107561826705933
Validation loss: 1.9754820023813555

Epoch: 6| Step: 9
Training loss: 1.9403371810913086
Validation loss: 1.951646630482007

Epoch: 6| Step: 10
Training loss: 0.8021200895309448
Validation loss: 1.9637008149136779

Epoch: 6| Step: 11
Training loss: 1.542637586593628
Validation loss: 1.9424392561758719

Epoch: 6| Step: 12
Training loss: 1.1710665225982666
Validation loss: 2.0162551608136905

Epoch: 6| Step: 13
Training loss: 1.3570780754089355
Validation loss: 1.900453007349404

Epoch: 473| Step: 0
Training loss: 0.9072418212890625
Validation loss: 1.940059204255381

Epoch: 6| Step: 1
Training loss: 0.9184085130691528
Validation loss: 1.854354053415278

Epoch: 6| Step: 2
Training loss: 1.1791541576385498
Validation loss: 1.8701599413348782

Epoch: 6| Step: 3
Training loss: 1.1197946071624756
Validation loss: 1.8860124900776853

Epoch: 6| Step: 4
Training loss: 1.5227246284484863
Validation loss: 1.9120634576325775

Epoch: 6| Step: 5
Training loss: 1.396235704421997
Validation loss: 1.905947011004212

Epoch: 6| Step: 6
Training loss: 0.763285756111145
Validation loss: 1.9201238898820774

Epoch: 6| Step: 7
Training loss: 1.1570380926132202
Validation loss: 1.9475450438837851

Epoch: 6| Step: 8
Training loss: 0.9838215112686157
Validation loss: 1.9449550797862392

Epoch: 6| Step: 9
Training loss: 1.182551622390747
Validation loss: 1.9774327713956115

Epoch: 6| Step: 10
Training loss: 1.6252574920654297
Validation loss: 1.9257234168309036

Epoch: 6| Step: 11
Training loss: 0.976459801197052
Validation loss: 1.9056312730235438

Epoch: 6| Step: 12
Training loss: 1.2516915798187256
Validation loss: 1.8521278827421126

Epoch: 6| Step: 13
Training loss: 1.610284447669983
Validation loss: 1.8701252809134863

Epoch: 474| Step: 0
Training loss: 1.1813945770263672
Validation loss: 1.9244565092107302

Epoch: 6| Step: 1
Training loss: 1.2013040781021118
Validation loss: 1.8784474352354645

Epoch: 6| Step: 2
Training loss: 1.6408207416534424
Validation loss: 1.9244856244774275

Epoch: 6| Step: 3
Training loss: 1.2747066020965576
Validation loss: 1.8482911868761944

Epoch: 6| Step: 4
Training loss: 0.9142258167266846
Validation loss: 1.8759443067735242

Epoch: 6| Step: 5
Training loss: 1.3431141376495361
Validation loss: 1.909025167906156

Epoch: 6| Step: 6
Training loss: 1.2494643926620483
Validation loss: 1.8901715432443926

Epoch: 6| Step: 7
Training loss: 1.717611312866211
Validation loss: 1.947873169376004

Epoch: 6| Step: 8
Training loss: 1.2377873659133911
Validation loss: 1.9763966850055161

Epoch: 6| Step: 9
Training loss: 1.38529634475708
Validation loss: 1.8858158152590516

Epoch: 6| Step: 10
Training loss: 0.9755932092666626
Validation loss: 1.9118399132964432

Epoch: 6| Step: 11
Training loss: 0.9977344870567322
Validation loss: 1.8461748682042605

Epoch: 6| Step: 12
Training loss: 1.249351978302002
Validation loss: 1.864082944008612

Epoch: 6| Step: 13
Training loss: 0.7135556936264038
Validation loss: 1.9192727676001928

Epoch: 475| Step: 0
Training loss: 1.2540630102157593
Validation loss: 1.9058459163993917

Epoch: 6| Step: 1
Training loss: 1.8818447589874268
Validation loss: 1.8820684507328977

Epoch: 6| Step: 2
Training loss: 1.2044963836669922
Validation loss: 1.9139473451081144

Epoch: 6| Step: 3
Training loss: 1.5228617191314697
Validation loss: 1.9620588415412492

Epoch: 6| Step: 4
Training loss: 1.388001799583435
Validation loss: 1.8589382735631799

Epoch: 6| Step: 5
Training loss: 0.8257271647453308
Validation loss: 1.8880851217495498

Epoch: 6| Step: 6
Training loss: 0.5895223617553711
Validation loss: 1.8475722087326871

Epoch: 6| Step: 7
Training loss: 1.0246233940124512
Validation loss: 1.9661586412819483

Epoch: 6| Step: 8
Training loss: 1.5757989883422852
Validation loss: 1.8922062843076644

Epoch: 6| Step: 9
Training loss: 0.6992723941802979
Validation loss: 1.8926213531083957

Epoch: 6| Step: 10
Training loss: 1.1563167572021484
Validation loss: 1.892250112307969

Epoch: 6| Step: 11
Training loss: 1.267458438873291
Validation loss: 1.9399417600324076

Epoch: 6| Step: 12
Training loss: 0.9529320001602173
Validation loss: 1.8661598249148297

Epoch: 6| Step: 13
Training loss: 0.7593433856964111
Validation loss: 1.962838936877507

Epoch: 476| Step: 0
Training loss: 1.4385919570922852
Validation loss: 1.9119938855530114

Epoch: 6| Step: 1
Training loss: 1.0830148458480835
Validation loss: 1.8789292099655315

Epoch: 6| Step: 2
Training loss: 0.8962708711624146
Validation loss: 1.9170127632797405

Epoch: 6| Step: 3
Training loss: 1.3444321155548096
Validation loss: 1.8881671069770731

Epoch: 6| Step: 4
Training loss: 1.2960035800933838
Validation loss: 1.8926341302933232

Epoch: 6| Step: 5
Training loss: 0.9701732397079468
Validation loss: 1.8965319433519918

Epoch: 6| Step: 6
Training loss: 1.0031352043151855
Validation loss: 1.8697920781309887

Epoch: 6| Step: 7
Training loss: 1.0911318063735962
Validation loss: 1.8889375348244943

Epoch: 6| Step: 8
Training loss: 1.0271929502487183
Validation loss: 1.911664024476082

Epoch: 6| Step: 9
Training loss: 1.1386123895645142
Validation loss: 1.8577109126634495

Epoch: 6| Step: 10
Training loss: 1.5988725423812866
Validation loss: 1.984244890110467

Epoch: 6| Step: 11
Training loss: 1.305248737335205
Validation loss: 1.8622763695255402

Epoch: 6| Step: 12
Training loss: 1.2057777643203735
Validation loss: 1.933668972343527

Epoch: 6| Step: 13
Training loss: 0.6284096240997314
Validation loss: 1.9088643955928024

Epoch: 477| Step: 0
Training loss: 1.0249240398406982
Validation loss: 1.9409180930865708

Epoch: 6| Step: 1
Training loss: 1.0423071384429932
Validation loss: 1.9752810206464542

Epoch: 6| Step: 2
Training loss: 1.1841599941253662
Validation loss: 1.8717224854294972

Epoch: 6| Step: 3
Training loss: 1.1044024229049683
Validation loss: 1.8647075314675607

Epoch: 6| Step: 4
Training loss: 1.4766275882720947
Validation loss: 1.9642779070843932

Epoch: 6| Step: 5
Training loss: 0.895506739616394
Validation loss: 1.8819512654376287

Epoch: 6| Step: 6
Training loss: 0.941910445690155
Validation loss: 1.9173234944702477

Epoch: 6| Step: 7
Training loss: 1.8327306509017944
Validation loss: 1.9484220781633932

Epoch: 6| Step: 8
Training loss: 1.3039411306381226
Validation loss: 1.9223328098174064

Epoch: 6| Step: 9
Training loss: 1.0929365158081055
Validation loss: 1.92971848159708

Epoch: 6| Step: 10
Training loss: 1.2989919185638428
Validation loss: 1.932054642708071

Epoch: 6| Step: 11
Training loss: 0.6651175022125244
Validation loss: 2.0040390696576846

Epoch: 6| Step: 12
Training loss: 0.8745641708374023
Validation loss: 1.882036933334925

Epoch: 6| Step: 13
Training loss: 2.050015926361084
Validation loss: 1.8512504792982531

Epoch: 478| Step: 0
Training loss: 0.8233014345169067
Validation loss: 1.935235518922088

Epoch: 6| Step: 1
Training loss: 0.9201958179473877
Validation loss: 1.8968235420924362

Epoch: 6| Step: 2
Training loss: 1.5038552284240723
Validation loss: 1.904218783942602

Epoch: 6| Step: 3
Training loss: 1.3150898218154907
Validation loss: 1.9205329136181903

Epoch: 6| Step: 4
Training loss: 0.9561327695846558
Validation loss: 1.9404250985832625

Epoch: 6| Step: 5
Training loss: 1.6138184070587158
Validation loss: 1.9301224203519924

Epoch: 6| Step: 6
Training loss: 1.7758300304412842
Validation loss: 1.9660229042012205

Epoch: 6| Step: 7
Training loss: 0.8240995407104492
Validation loss: 1.9316363565383419

Epoch: 6| Step: 8
Training loss: 1.127908706665039
Validation loss: 1.8891177049247168

Epoch: 6| Step: 9
Training loss: 1.3390922546386719
Validation loss: 1.9484415720867854

Epoch: 6| Step: 10
Training loss: 1.0501539707183838
Validation loss: 1.9890837848827403

Epoch: 6| Step: 11
Training loss: 0.7787020802497864
Validation loss: 1.9709526287612094

Epoch: 6| Step: 12
Training loss: 0.9786056280136108
Validation loss: 1.9033302491711033

Epoch: 6| Step: 13
Training loss: 1.0556128025054932
Validation loss: 1.915103466280045

Epoch: 479| Step: 0
Training loss: 1.3057560920715332
Validation loss: 1.9003874114764634

Epoch: 6| Step: 1
Training loss: 0.6701697111129761
Validation loss: 1.9433098608447659

Epoch: 6| Step: 2
Training loss: 1.1567455530166626
Validation loss: 2.0212003223357664

Epoch: 6| Step: 3
Training loss: 0.9518693685531616
Validation loss: 2.026921001813745

Epoch: 6| Step: 4
Training loss: 1.2527804374694824
Validation loss: 1.8929407058223602

Epoch: 6| Step: 5
Training loss: 1.0999876260757446
Validation loss: 1.9522921808304325

Epoch: 6| Step: 6
Training loss: 0.9253420829772949
Validation loss: 1.9363293365765644

Epoch: 6| Step: 7
Training loss: 1.8227604627609253
Validation loss: 2.012751531857316

Epoch: 6| Step: 8
Training loss: 1.3974348306655884
Validation loss: 1.9921494914639382

Epoch: 6| Step: 9
Training loss: 1.7534730434417725
Validation loss: 1.8905391500842186

Epoch: 6| Step: 10
Training loss: 0.9399588108062744
Validation loss: 1.8981785697321738

Epoch: 6| Step: 11
Training loss: 0.9505667686462402
Validation loss: 1.9272038013704362

Epoch: 6| Step: 12
Training loss: 0.7658686637878418
Validation loss: 1.9363486356632684

Epoch: 6| Step: 13
Training loss: 1.7374094724655151
Validation loss: 1.8906929236586376

Epoch: 480| Step: 0
Training loss: 1.2103264331817627
Validation loss: 1.8421639780844412

Epoch: 6| Step: 1
Training loss: 2.0092947483062744
Validation loss: 1.9407743151469896

Epoch: 6| Step: 2
Training loss: 1.26018226146698
Validation loss: 1.9378809723802792

Epoch: 6| Step: 3
Training loss: 0.7159773111343384
Validation loss: 1.8753154969984485

Epoch: 6| Step: 4
Training loss: 1.0298206806182861
Validation loss: 1.910007530643094

Epoch: 6| Step: 5
Training loss: 0.9032804369926453
Validation loss: 1.900745775109978

Epoch: 6| Step: 6
Training loss: 1.0238441228866577
Validation loss: 1.845859355823968

Epoch: 6| Step: 7
Training loss: 1.2784616947174072
Validation loss: 1.8871270507894538

Epoch: 6| Step: 8
Training loss: 0.7790625095367432
Validation loss: 1.8668733437856038

Epoch: 6| Step: 9
Training loss: 0.8750694394111633
Validation loss: 1.9201480957769579

Epoch: 6| Step: 10
Training loss: 1.0643017292022705
Validation loss: 1.9551414725601033

Epoch: 6| Step: 11
Training loss: 1.3075190782546997
Validation loss: 1.9542786998133506

Epoch: 6| Step: 12
Training loss: 1.1475739479064941
Validation loss: 1.914452245158534

Epoch: 6| Step: 13
Training loss: 1.5222816467285156
Validation loss: 1.915030865259068

Epoch: 481| Step: 0
Training loss: 1.3083248138427734
Validation loss: 1.9429779386007657

Epoch: 6| Step: 1
Training loss: 1.1641192436218262
Validation loss: 1.8643463465475267

Epoch: 6| Step: 2
Training loss: 1.2709711790084839
Validation loss: 1.9077173638087448

Epoch: 6| Step: 3
Training loss: 1.4769682884216309
Validation loss: 1.8972715998208651

Epoch: 6| Step: 4
Training loss: 0.844995379447937
Validation loss: 1.8503598910506054

Epoch: 6| Step: 5
Training loss: 1.2585302591323853
Validation loss: 1.9254264011177966

Epoch: 6| Step: 6
Training loss: 1.0259490013122559
Validation loss: 1.9238767572628555

Epoch: 6| Step: 7
Training loss: 1.0822418928146362
Validation loss: 1.8084757892034387

Epoch: 6| Step: 8
Training loss: 1.4305922985076904
Validation loss: 1.857910704869096

Epoch: 6| Step: 9
Training loss: 0.9645012617111206
Validation loss: 1.912321008661742

Epoch: 6| Step: 10
Training loss: 1.6603296995162964
Validation loss: 1.8676822480335031

Epoch: 6| Step: 11
Training loss: 1.0448307991027832
Validation loss: 1.8902194794788156

Epoch: 6| Step: 12
Training loss: 1.2976120710372925
Validation loss: 1.9345930955743278

Epoch: 6| Step: 13
Training loss: 0.7560881972312927
Validation loss: 1.9180316232865857

Epoch: 482| Step: 0
Training loss: 1.017876148223877
Validation loss: 1.8716354857208908

Epoch: 6| Step: 1
Training loss: 1.7915327548980713
Validation loss: 1.9360427087353123

Epoch: 6| Step: 2
Training loss: 1.068277359008789
Validation loss: 1.946031597352797

Epoch: 6| Step: 3
Training loss: 0.6249715685844421
Validation loss: 1.95355212560264

Epoch: 6| Step: 4
Training loss: 0.9214841723442078
Validation loss: 1.927169733150031

Epoch: 6| Step: 5
Training loss: 1.4175196886062622
Validation loss: 1.9630723563573693

Epoch: 6| Step: 6
Training loss: 1.2118442058563232
Validation loss: 1.9307600836600027

Epoch: 6| Step: 7
Training loss: 1.1530359983444214
Validation loss: 1.8828117514169345

Epoch: 6| Step: 8
Training loss: 1.0797598361968994
Validation loss: 1.9023490349451702

Epoch: 6| Step: 9
Training loss: 1.0480109453201294
Validation loss: 1.879797625285323

Epoch: 6| Step: 10
Training loss: 1.0445672273635864
Validation loss: 1.9487223689274122

Epoch: 6| Step: 11
Training loss: 1.2589542865753174
Validation loss: 1.9170621428438412

Epoch: 6| Step: 12
Training loss: 1.1733334064483643
Validation loss: 1.916166990034042

Epoch: 6| Step: 13
Training loss: 1.5707266330718994
Validation loss: 1.9334903071003575

Epoch: 483| Step: 0
Training loss: 0.8047175407409668
Validation loss: 1.901655412489368

Epoch: 6| Step: 1
Training loss: 1.7879786491394043
Validation loss: 1.8926108524363527

Epoch: 6| Step: 2
Training loss: 1.0386147499084473
Validation loss: 1.8972845180060274

Epoch: 6| Step: 3
Training loss: 1.0639567375183105
Validation loss: 1.958823452713669

Epoch: 6| Step: 4
Training loss: 1.332761287689209
Validation loss: 1.869462061953801

Epoch: 6| Step: 5
Training loss: 0.895889401435852
Validation loss: 1.9289033105296474

Epoch: 6| Step: 6
Training loss: 0.8271119594573975
Validation loss: 1.936053369634895

Epoch: 6| Step: 7
Training loss: 1.2353870868682861
Validation loss: 1.9734695649916125

Epoch: 6| Step: 8
Training loss: 1.8254036903381348
Validation loss: 1.9563437584907777

Epoch: 6| Step: 9
Training loss: 1.2693158388137817
Validation loss: 1.9779444945755826

Epoch: 6| Step: 10
Training loss: 0.6856926083564758
Validation loss: 1.9740531777822843

Epoch: 6| Step: 11
Training loss: 0.9299037456512451
Validation loss: 1.9724736623866583

Epoch: 6| Step: 12
Training loss: 1.2687313556671143
Validation loss: 1.971381784767233

Epoch: 6| Step: 13
Training loss: 1.9137662649154663
Validation loss: 1.8800586500475485

Epoch: 484| Step: 0
Training loss: 0.9949275255203247
Validation loss: 1.960714276118945

Epoch: 6| Step: 1
Training loss: 0.6519501209259033
Validation loss: 1.8803451676522531

Epoch: 6| Step: 2
Training loss: 1.0483410358428955
Validation loss: 1.9173155946116294

Epoch: 6| Step: 3
Training loss: 1.0315865278244019
Validation loss: 1.9251794276698944

Epoch: 6| Step: 4
Training loss: 0.9370142221450806
Validation loss: 1.9151338761852634

Epoch: 6| Step: 5
Training loss: 1.21211838722229
Validation loss: 1.8602727279868176

Epoch: 6| Step: 6
Training loss: 1.0669151544570923
Validation loss: 1.8545955957904938

Epoch: 6| Step: 7
Training loss: 1.6826159954071045
Validation loss: 1.8786821852448166

Epoch: 6| Step: 8
Training loss: 1.441986322402954
Validation loss: 1.9111053251451062

Epoch: 6| Step: 9
Training loss: 1.1455494165420532
Validation loss: 1.9111263187982703

Epoch: 6| Step: 10
Training loss: 2.018096446990967
Validation loss: 1.978238941520773

Epoch: 6| Step: 11
Training loss: 0.9398894906044006
Validation loss: 1.9555080757346204

Epoch: 6| Step: 12
Training loss: 1.4749462604522705
Validation loss: 1.9387549379820466

Epoch: 6| Step: 13
Training loss: 1.1905790567398071
Validation loss: 1.9779842809964252

Epoch: 485| Step: 0
Training loss: 1.2524046897888184
Validation loss: 1.9591477429994972

Epoch: 6| Step: 1
Training loss: 0.7278420925140381
Validation loss: 1.939362056793705

Epoch: 6| Step: 2
Training loss: 1.1394755840301514
Validation loss: 1.908773688859837

Epoch: 6| Step: 3
Training loss: 1.0565540790557861
Validation loss: 1.9042004949303084

Epoch: 6| Step: 4
Training loss: 1.0864534378051758
Validation loss: 1.949410633374286

Epoch: 6| Step: 5
Training loss: 0.9939354658126831
Validation loss: 1.9156356396213654

Epoch: 6| Step: 6
Training loss: 1.1749272346496582
Validation loss: 1.9024126337420555

Epoch: 6| Step: 7
Training loss: 1.2103326320648193
Validation loss: 1.8645489549124112

Epoch: 6| Step: 8
Training loss: 1.4875879287719727
Validation loss: 1.9017632776691067

Epoch: 6| Step: 9
Training loss: 1.1661853790283203
Validation loss: 1.9090531808073803

Epoch: 6| Step: 10
Training loss: 1.3207483291625977
Validation loss: 1.921188618547173

Epoch: 6| Step: 11
Training loss: 1.2906794548034668
Validation loss: 1.8633606715868878

Epoch: 6| Step: 12
Training loss: 1.1765522956848145
Validation loss: 1.9171360346578783

Epoch: 6| Step: 13
Training loss: 1.5742993354797363
Validation loss: 1.9071657785805323

Epoch: 486| Step: 0
Training loss: 1.221175193786621
Validation loss: 1.9187421119341286

Epoch: 6| Step: 1
Training loss: 0.7661932706832886
Validation loss: 1.8713666892820788

Epoch: 6| Step: 2
Training loss: 1.5702000856399536
Validation loss: 1.9218519080069758

Epoch: 6| Step: 3
Training loss: 0.9825499057769775
Validation loss: 1.9380698204040527

Epoch: 6| Step: 4
Training loss: 1.0748441219329834
Validation loss: 1.8332440801846084

Epoch: 6| Step: 5
Training loss: 0.7747185230255127
Validation loss: 1.9633731483131327

Epoch: 6| Step: 6
Training loss: 1.0540351867675781
Validation loss: 1.9672182324112102

Epoch: 6| Step: 7
Training loss: 1.0791531801223755
Validation loss: 1.886544213500074

Epoch: 6| Step: 8
Training loss: 1.456002950668335
Validation loss: 1.9643501607320641

Epoch: 6| Step: 9
Training loss: 1.3950951099395752
Validation loss: 1.9846785606876496

Epoch: 6| Step: 10
Training loss: 0.6849851012229919
Validation loss: 1.890845585894841

Epoch: 6| Step: 11
Training loss: 1.3968416452407837
Validation loss: 1.9246540133671095

Epoch: 6| Step: 12
Training loss: 1.0191818475723267
Validation loss: 1.9169888701490176

Epoch: 6| Step: 13
Training loss: 2.401695489883423
Validation loss: 1.9675784828842326

Epoch: 487| Step: 0
Training loss: 1.3668168783187866
Validation loss: 1.9454278792104414

Epoch: 6| Step: 1
Training loss: 1.1070671081542969
Validation loss: 1.8772718214219617

Epoch: 6| Step: 2
Training loss: 0.8993812799453735
Validation loss: 1.9587995236919773

Epoch: 6| Step: 3
Training loss: 1.4528429508209229
Validation loss: 1.8986235562191214

Epoch: 6| Step: 4
Training loss: 1.156346321105957
Validation loss: 1.95704068932482

Epoch: 6| Step: 5
Training loss: 1.3716310262680054
Validation loss: 1.9080981990342498

Epoch: 6| Step: 6
Training loss: 0.8138983249664307
Validation loss: 1.9335374498880038

Epoch: 6| Step: 7
Training loss: 0.5890369415283203
Validation loss: 1.8828748208220287

Epoch: 6| Step: 8
Training loss: 1.164844274520874
Validation loss: 1.9700907379068353

Epoch: 6| Step: 9
Training loss: 1.3947237730026245
Validation loss: 1.9750565380178473

Epoch: 6| Step: 10
Training loss: 1.5736041069030762
Validation loss: 1.9467024572433964

Epoch: 6| Step: 11
Training loss: 1.5071780681610107
Validation loss: 1.8935416103691183

Epoch: 6| Step: 12
Training loss: 0.8863564133644104
Validation loss: 1.8375576337178547

Epoch: 6| Step: 13
Training loss: 1.5418096780776978
Validation loss: 1.9382853828450686

Epoch: 488| Step: 0
Training loss: 0.7996336817741394
Validation loss: 1.929615725753128

Epoch: 6| Step: 1
Training loss: 0.932725191116333
Validation loss: 1.9110035037481656

Epoch: 6| Step: 2
Training loss: 0.6636786460876465
Validation loss: 1.8745094730008034

Epoch: 6| Step: 3
Training loss: 1.7146668434143066
Validation loss: 1.8585924435687322

Epoch: 6| Step: 4
Training loss: 1.294419527053833
Validation loss: 1.9517512295835762

Epoch: 6| Step: 5
Training loss: 1.5627425909042358
Validation loss: 1.854194252721725

Epoch: 6| Step: 6
Training loss: 1.3324780464172363
Validation loss: 1.9325884183247883

Epoch: 6| Step: 7
Training loss: 0.561398983001709
Validation loss: 1.864434370430567

Epoch: 6| Step: 8
Training loss: 1.757360816001892
Validation loss: 1.9750278867701048

Epoch: 6| Step: 9
Training loss: 1.309501051902771
Validation loss: 1.90904874186362

Epoch: 6| Step: 10
Training loss: 1.0790648460388184
Validation loss: 1.8913660075074883

Epoch: 6| Step: 11
Training loss: 0.9477638006210327
Validation loss: 1.8578253458904963

Epoch: 6| Step: 12
Training loss: 1.0702629089355469
Validation loss: 1.9410957521007908

Epoch: 6| Step: 13
Training loss: 1.2764232158660889
Validation loss: 1.9198977216597526

Epoch: 489| Step: 0
Training loss: 1.21437406539917
Validation loss: 1.8809388632415442

Epoch: 6| Step: 1
Training loss: 0.6438486576080322
Validation loss: 1.952359796852194

Epoch: 6| Step: 2
Training loss: 0.9489238262176514
Validation loss: 1.8997233759972356

Epoch: 6| Step: 3
Training loss: 1.060148000717163
Validation loss: 1.9436634035520657

Epoch: 6| Step: 4
Training loss: 1.2276240587234497
Validation loss: 1.9294846826984036

Epoch: 6| Step: 5
Training loss: 0.9992354512214661
Validation loss: 1.909759626593641

Epoch: 6| Step: 6
Training loss: 0.9978193640708923
Validation loss: 1.8714087214521182

Epoch: 6| Step: 7
Training loss: 1.4740209579467773
Validation loss: 1.9568488110778153

Epoch: 6| Step: 8
Training loss: 1.4461265802383423
Validation loss: 1.8540757266424035

Epoch: 6| Step: 9
Training loss: 1.4725478887557983
Validation loss: 1.9319957443462905

Epoch: 6| Step: 10
Training loss: 0.9565309286117554
Validation loss: 1.9133942178500596

Epoch: 6| Step: 11
Training loss: 1.4421586990356445
Validation loss: 1.8532523391067341

Epoch: 6| Step: 12
Training loss: 1.2950093746185303
Validation loss: 2.0099134957918556

Epoch: 6| Step: 13
Training loss: 1.17416250705719
Validation loss: 1.9754083156585693

Epoch: 490| Step: 0
Training loss: 1.2224878072738647
Validation loss: 1.897803665489279

Epoch: 6| Step: 1
Training loss: 1.4218401908874512
Validation loss: 1.9160233851402038

Epoch: 6| Step: 2
Training loss: 1.494046926498413
Validation loss: 1.891691146358367

Epoch: 6| Step: 3
Training loss: 1.2054508924484253
Validation loss: 1.9762202296205746

Epoch: 6| Step: 4
Training loss: 0.7091350555419922
Validation loss: 1.8899314403533936

Epoch: 6| Step: 5
Training loss: 0.7070518732070923
Validation loss: 1.8764379921779837

Epoch: 6| Step: 6
Training loss: 1.527485966682434
Validation loss: 1.883427159760588

Epoch: 6| Step: 7
Training loss: 1.2067831754684448
Validation loss: 1.8941305388686478

Epoch: 6| Step: 8
Training loss: 0.9210429191589355
Validation loss: 1.87186687479737

Epoch: 6| Step: 9
Training loss: 0.9653717279434204
Validation loss: 1.936248702387656

Epoch: 6| Step: 10
Training loss: 1.2092788219451904
Validation loss: 1.9342188809507637

Epoch: 6| Step: 11
Training loss: 0.974379301071167
Validation loss: 1.8168860353449339

Epoch: 6| Step: 12
Training loss: 1.8032832145690918
Validation loss: 1.8880715690633303

Epoch: 6| Step: 13
Training loss: 0.920766294002533
Validation loss: 1.8430502696703839

Epoch: 491| Step: 0
Training loss: 1.5302647352218628
Validation loss: 1.942292805640928

Epoch: 6| Step: 1
Training loss: 1.298152208328247
Validation loss: 1.9214157417256346

Epoch: 6| Step: 2
Training loss: 0.8305480480194092
Validation loss: 1.9369730513582948

Epoch: 6| Step: 3
Training loss: 1.3467192649841309
Validation loss: 1.981653126337195

Epoch: 6| Step: 4
Training loss: 0.8425167798995972
Validation loss: 1.9131103241315452

Epoch: 6| Step: 5
Training loss: 2.094186544418335
Validation loss: 1.9117096765066988

Epoch: 6| Step: 6
Training loss: 1.089147925376892
Validation loss: 1.9034266061680292

Epoch: 6| Step: 7
Training loss: 0.7496485114097595
Validation loss: 1.9598475810020202

Epoch: 6| Step: 8
Training loss: 0.7929223775863647
Validation loss: 1.8740150249132546

Epoch: 6| Step: 9
Training loss: 1.097438931465149
Validation loss: 1.8801447012091195

Epoch: 6| Step: 10
Training loss: 1.0450267791748047
Validation loss: 1.9670167405118224

Epoch: 6| Step: 11
Training loss: 1.1015321016311646
Validation loss: 1.9067416550010763

Epoch: 6| Step: 12
Training loss: 1.0466945171356201
Validation loss: 1.9560124643387333

Epoch: 6| Step: 13
Training loss: 0.8564417362213135
Validation loss: 1.9284089957514117

Epoch: 492| Step: 0
Training loss: 1.2123157978057861
Validation loss: 1.9371180213907713

Epoch: 6| Step: 1
Training loss: 0.7539137601852417
Validation loss: 1.9172007204383932

Epoch: 6| Step: 2
Training loss: 0.8224709630012512
Validation loss: 1.9343776049152497

Epoch: 6| Step: 3
Training loss: 0.45946621894836426
Validation loss: 1.8456969799533967

Epoch: 6| Step: 4
Training loss: 1.1475269794464111
Validation loss: 1.9723113300979778

Epoch: 6| Step: 5
Training loss: 1.0060210227966309
Validation loss: 1.7957795358473254

Epoch: 6| Step: 6
Training loss: 1.372440218925476
Validation loss: 1.8679787971640145

Epoch: 6| Step: 7
Training loss: 1.7737534046173096
Validation loss: 1.8903834242974558

Epoch: 6| Step: 8
Training loss: 1.5960662364959717
Validation loss: 1.882412895079582

Epoch: 6| Step: 9
Training loss: 1.168443202972412
Validation loss: 1.9051515030604538

Epoch: 6| Step: 10
Training loss: 1.341158390045166
Validation loss: 1.8620352847601778

Epoch: 6| Step: 11
Training loss: 1.1913723945617676
Validation loss: 1.9192568102190573

Epoch: 6| Step: 12
Training loss: 1.2357947826385498
Validation loss: 1.911970607696041

Epoch: 6| Step: 13
Training loss: 0.933338463306427
Validation loss: 1.955424694604771

Epoch: 493| Step: 0
Training loss: 1.1878330707550049
Validation loss: 1.9485400889509468

Epoch: 6| Step: 1
Training loss: 1.5085549354553223
Validation loss: 1.9677840560995123

Epoch: 6| Step: 2
Training loss: 0.8077230453491211
Validation loss: 1.9196559075386292

Epoch: 6| Step: 3
Training loss: 1.3334412574768066
Validation loss: 1.932229293290005

Epoch: 6| Step: 4
Training loss: 0.6480389833450317
Validation loss: 1.9615475413619832

Epoch: 6| Step: 5
Training loss: 1.1094152927398682
Validation loss: 1.9343873813588133

Epoch: 6| Step: 6
Training loss: 0.746864914894104
Validation loss: 2.0025201971812914

Epoch: 6| Step: 7
Training loss: 1.1435521841049194
Validation loss: 1.8447313462534258

Epoch: 6| Step: 8
Training loss: 0.7932350635528564
Validation loss: 1.9533536229082333

Epoch: 6| Step: 9
Training loss: 1.1987178325653076
Validation loss: 1.90794922203146

Epoch: 6| Step: 10
Training loss: 0.8974633812904358
Validation loss: 1.826662068725914

Epoch: 6| Step: 11
Training loss: 1.6057088375091553
Validation loss: 1.8551499689778974

Epoch: 6| Step: 12
Training loss: 1.3396719694137573
Validation loss: 2.007765075211884

Epoch: 6| Step: 13
Training loss: 2.219444990158081
Validation loss: 1.9128303092013124

Epoch: 494| Step: 0
Training loss: 1.431159257888794
Validation loss: 1.9332112881445116

Epoch: 6| Step: 1
Training loss: 1.3723132610321045
Validation loss: 1.9291647813653434

Epoch: 6| Step: 2
Training loss: 1.0485368967056274
Validation loss: 1.909573455010691

Epoch: 6| Step: 3
Training loss: 1.0500059127807617
Validation loss: 1.906144174196387

Epoch: 6| Step: 4
Training loss: 0.8532686829566956
Validation loss: 1.8844670941752772

Epoch: 6| Step: 5
Training loss: 1.1314812898635864
Validation loss: 1.9496022834572742

Epoch: 6| Step: 6
Training loss: 1.8560279607772827
Validation loss: 1.9105673759214339

Epoch: 6| Step: 7
Training loss: 1.0718376636505127
Validation loss: 1.9227205014997912

Epoch: 6| Step: 8
Training loss: 0.5541629195213318
Validation loss: 1.8905124869397891

Epoch: 6| Step: 9
Training loss: 1.3342475891113281
Validation loss: 1.935080559022965

Epoch: 6| Step: 10
Training loss: 0.7049431204795837
Validation loss: 2.0103350275306293

Epoch: 6| Step: 11
Training loss: 1.4932509660720825
Validation loss: 1.9190189812773017

Epoch: 6| Step: 12
Training loss: 1.3477678298950195
Validation loss: 1.8901668543456702

Epoch: 6| Step: 13
Training loss: 0.5937931537628174
Validation loss: 1.9806835023305749

Epoch: 495| Step: 0
Training loss: 1.1167454719543457
Validation loss: 1.8990562974765737

Epoch: 6| Step: 1
Training loss: 1.2378381490707397
Validation loss: 1.9442937438206007

Epoch: 6| Step: 2
Training loss: 1.2809464931488037
Validation loss: 1.8464177757181146

Epoch: 6| Step: 3
Training loss: 1.2800188064575195
Validation loss: 1.8679844935735066

Epoch: 6| Step: 4
Training loss: 1.360295057296753
Validation loss: 1.901019597566256

Epoch: 6| Step: 5
Training loss: 1.0892812013626099
Validation loss: 1.9264452252336728

Epoch: 6| Step: 6
Training loss: 0.9231359958648682
Validation loss: 1.9075488377642889

Epoch: 6| Step: 7
Training loss: 1.0327882766723633
Validation loss: 1.8857933013669905

Epoch: 6| Step: 8
Training loss: 1.5395007133483887
Validation loss: 1.9219744846385012

Epoch: 6| Step: 9
Training loss: 1.3877148628234863
Validation loss: 1.928154528781932

Epoch: 6| Step: 10
Training loss: 0.8784177303314209
Validation loss: 1.9595622759993359

Epoch: 6| Step: 11
Training loss: 1.8731133937835693
Validation loss: 1.9647934026615594

Epoch: 6| Step: 12
Training loss: 1.2463363409042358
Validation loss: 1.924191439023582

Epoch: 6| Step: 13
Training loss: 0.8847302198410034
Validation loss: 1.8836305295267413

Epoch: 496| Step: 0
Training loss: 1.0211899280548096
Validation loss: 1.9178670324305052

Epoch: 6| Step: 1
Training loss: 1.135416030883789
Validation loss: 1.8753139575322468

Epoch: 6| Step: 2
Training loss: 1.701744794845581
Validation loss: 1.9191396518420147

Epoch: 6| Step: 3
Training loss: 0.8668044209480286
Validation loss: 1.928965155796338

Epoch: 6| Step: 4
Training loss: 1.0062347650527954
Validation loss: 1.915921175351707

Epoch: 6| Step: 5
Training loss: 0.9838460087776184
Validation loss: 1.929892119540963

Epoch: 6| Step: 6
Training loss: 1.4689350128173828
Validation loss: 1.9440477458379601

Epoch: 6| Step: 7
Training loss: 0.7359156012535095
Validation loss: 1.9207867114774642

Epoch: 6| Step: 8
Training loss: 1.258411169052124
Validation loss: 1.952962572856616

Epoch: 6| Step: 9
Training loss: 1.9313380718231201
Validation loss: 1.9495824024241457

Epoch: 6| Step: 10
Training loss: 0.8153952956199646
Validation loss: 1.9829908147934945

Epoch: 6| Step: 11
Training loss: 1.4028990268707275
Validation loss: 1.9071572826754661

Epoch: 6| Step: 12
Training loss: 0.919929027557373
Validation loss: 1.9296327598633305

Epoch: 6| Step: 13
Training loss: 0.7977920174598694
Validation loss: 1.8525221629809308

Epoch: 497| Step: 0
Training loss: 2.199779748916626
Validation loss: 1.8864213446135163

Epoch: 6| Step: 1
Training loss: 0.9082534313201904
Validation loss: 1.8672085141622892

Epoch: 6| Step: 2
Training loss: 1.140869379043579
Validation loss: 1.890450014862963

Epoch: 6| Step: 3
Training loss: 0.5465470552444458
Validation loss: 1.7468985357592184

Epoch: 6| Step: 4
Training loss: 1.299220085144043
Validation loss: 1.883275721662788

Epoch: 6| Step: 5
Training loss: 1.4516096115112305
Validation loss: 1.9344938954999369

Epoch: 6| Step: 6
Training loss: 1.0677707195281982
Validation loss: 1.8796522335339618

Epoch: 6| Step: 7
Training loss: 0.9435170888900757
Validation loss: 1.9087105169091174

Epoch: 6| Step: 8
Training loss: 0.8235489726066589
Validation loss: 2.0114840768998667

Epoch: 6| Step: 9
Training loss: 0.9414617419242859
Validation loss: 1.8926357159050562

Epoch: 6| Step: 10
Training loss: 1.5439411401748657
Validation loss: 1.8333228582976966

Epoch: 6| Step: 11
Training loss: 1.2997956275939941
Validation loss: 1.8526397828132875

Epoch: 6| Step: 12
Training loss: 1.2138975858688354
Validation loss: 1.8900856266739547

Epoch: 6| Step: 13
Training loss: 0.8423454761505127
Validation loss: 1.927048812630356

Epoch: 498| Step: 0
Training loss: 1.0753302574157715
Validation loss: 1.9085721546603787

Epoch: 6| Step: 1
Training loss: 1.2005490064620972
Validation loss: 1.8094322886518253

Epoch: 6| Step: 2
Training loss: 0.7970342636108398
Validation loss: 1.9484101956890476

Epoch: 6| Step: 3
Training loss: 1.1919633150100708
Validation loss: 1.9800775743299914

Epoch: 6| Step: 4
Training loss: 1.2763149738311768
Validation loss: 1.947139638085519

Epoch: 6| Step: 5
Training loss: 0.9734933972358704
Validation loss: 1.9086102952239334

Epoch: 6| Step: 6
Training loss: 1.370938777923584
Validation loss: 2.003225349610852

Epoch: 6| Step: 7
Training loss: 1.353883981704712
Validation loss: 1.8790562780954505

Epoch: 6| Step: 8
Training loss: 0.8250335454940796
Validation loss: 1.8904280957355295

Epoch: 6| Step: 9
Training loss: 0.7256282567977905
Validation loss: 1.9133286911954162

Epoch: 6| Step: 10
Training loss: 1.3923152685165405
Validation loss: 1.8574820795366842

Epoch: 6| Step: 11
Training loss: 1.3941237926483154
Validation loss: 1.8925945746001376

Epoch: 6| Step: 12
Training loss: 1.317399024963379
Validation loss: 1.9160997098492039

Epoch: 6| Step: 13
Training loss: 0.6434411406517029
Validation loss: 1.9040462329823484

Epoch: 499| Step: 0
Training loss: 1.2670546770095825
Validation loss: 1.8833131354342225

Epoch: 6| Step: 1
Training loss: 1.066300392150879
Validation loss: 1.8471847580325218

Epoch: 6| Step: 2
Training loss: 1.3072092533111572
Validation loss: 1.910387013548164

Epoch: 6| Step: 3
Training loss: 1.1283247470855713
Validation loss: 1.8967807882575578

Epoch: 6| Step: 4
Training loss: 0.9730364680290222
Validation loss: 1.885627765809336

Epoch: 6| Step: 5
Training loss: 1.069985032081604
Validation loss: 1.909382584274456

Epoch: 6| Step: 6
Training loss: 1.1153810024261475
Validation loss: 1.941398411668757

Epoch: 6| Step: 7
Training loss: 1.0659875869750977
Validation loss: 1.948263354198907

Epoch: 6| Step: 8
Training loss: 1.1886248588562012
Validation loss: 2.0092544991482972

Epoch: 6| Step: 9
Training loss: 1.4833898544311523
Validation loss: 1.8924860659465994

Epoch: 6| Step: 10
Training loss: 1.1580909490585327
Validation loss: 2.0247747487919305

Epoch: 6| Step: 11
Training loss: 0.6505184173583984
Validation loss: 1.9842505070470995

Epoch: 6| Step: 12
Training loss: 1.0342721939086914
Validation loss: 1.9275198418606994

Epoch: 6| Step: 13
Training loss: 1.360005259513855
Validation loss: 1.9163984201287712

Epoch: 500| Step: 0
Training loss: 0.9592675566673279
Validation loss: 1.8714838348409182

Epoch: 6| Step: 1
Training loss: 1.0077269077301025
Validation loss: 1.9247034185676164

Epoch: 6| Step: 2
Training loss: 0.8008553981781006
Validation loss: 1.8923187204586562

Epoch: 6| Step: 3
Training loss: 1.3647708892822266
Validation loss: 1.9444388048623198

Epoch: 6| Step: 4
Training loss: 1.1300506591796875
Validation loss: 2.0016241099244807

Epoch: 6| Step: 5
Training loss: 1.4632518291473389
Validation loss: 1.939448102827995

Epoch: 6| Step: 6
Training loss: 1.1677597761154175
Validation loss: 1.9315767326662618

Epoch: 6| Step: 7
Training loss: 0.6068711280822754
Validation loss: 1.816658991639332

Epoch: 6| Step: 8
Training loss: 1.5321123600006104
Validation loss: 1.9731293288610314

Epoch: 6| Step: 9
Training loss: 1.2434816360473633
Validation loss: 1.8363084459817538

Epoch: 6| Step: 10
Training loss: 1.8775429725646973
Validation loss: 1.8689254663323844

Epoch: 6| Step: 11
Training loss: 0.9257066249847412
Validation loss: 1.8508849913074124

Epoch: 6| Step: 12
Training loss: 0.6761316061019897
Validation loss: 1.7721106672799716

Epoch: 6| Step: 13
Training loss: 1.3619225025177002
Validation loss: 1.827572125260548

Epoch: 501| Step: 0
Training loss: 1.3871791362762451
Validation loss: 1.869453917267502

Epoch: 6| Step: 1
Training loss: 1.1628613471984863
Validation loss: 1.837225257709462

Epoch: 6| Step: 2
Training loss: 1.247253656387329
Validation loss: 1.8995637598858084

Epoch: 6| Step: 3
Training loss: 1.2506592273712158
Validation loss: 1.9122675567544916

Epoch: 6| Step: 4
Training loss: 1.1913583278656006
Validation loss: 1.9469637255514822

Epoch: 6| Step: 5
Training loss: 1.2688877582550049
Validation loss: 1.9000234129608318

Epoch: 6| Step: 6
Training loss: 1.1466659307479858
Validation loss: 1.910024308389233

Epoch: 6| Step: 7
Training loss: 0.7604444026947021
Validation loss: 1.8835012810204619

Epoch: 6| Step: 8
Training loss: 1.3126487731933594
Validation loss: 1.8996951618502218

Epoch: 6| Step: 9
Training loss: 0.8538249135017395
Validation loss: 1.8941983920271679

Epoch: 6| Step: 10
Training loss: 1.0789484977722168
Validation loss: 1.9148748536263742

Epoch: 6| Step: 11
Training loss: 1.4859442710876465
Validation loss: 1.9045284832677534

Epoch: 6| Step: 12
Training loss: 0.9373161792755127
Validation loss: 1.8194701440872685

Epoch: 6| Step: 13
Training loss: 1.3394657373428345
Validation loss: 1.9447436012247556

Epoch: 502| Step: 0
Training loss: 0.8012700080871582
Validation loss: 1.916527468671081

Epoch: 6| Step: 1
Training loss: 1.088582158088684
Validation loss: 1.9452121552600656

Epoch: 6| Step: 2
Training loss: 1.422250747680664
Validation loss: 1.9158947660077004

Epoch: 6| Step: 3
Training loss: 0.48688754439353943
Validation loss: 1.8679116490066692

Epoch: 6| Step: 4
Training loss: 1.2812137603759766
Validation loss: 1.9019670024994881

Epoch: 6| Step: 5
Training loss: 1.422662377357483
Validation loss: 1.8670466869108138

Epoch: 6| Step: 6
Training loss: 0.7694846391677856
Validation loss: 1.8422816850805794

Epoch: 6| Step: 7
Training loss: 1.1295413970947266
Validation loss: 1.908613899702667

Epoch: 6| Step: 8
Training loss: 1.0002152919769287
Validation loss: 1.8052755767299282

Epoch: 6| Step: 9
Training loss: 1.2727025747299194
Validation loss: 1.8637290949462562

Epoch: 6| Step: 10
Training loss: 1.250192642211914
Validation loss: 1.8337692881143222

Epoch: 6| Step: 11
Training loss: 1.171979546546936
Validation loss: 1.9008228112292547

Epoch: 6| Step: 12
Training loss: 0.7800543904304504
Validation loss: 1.9108245116408153

Epoch: 6| Step: 13
Training loss: 1.8366761207580566
Validation loss: 1.9026742263506817

Epoch: 503| Step: 0
Training loss: 1.112288475036621
Validation loss: 1.890995171762282

Epoch: 6| Step: 1
Training loss: 1.9571937322616577
Validation loss: 1.8985418965739589

Epoch: 6| Step: 2
Training loss: 1.325693130493164
Validation loss: 1.978292155009444

Epoch: 6| Step: 3
Training loss: 0.8736861944198608
Validation loss: 1.8282222927257579

Epoch: 6| Step: 4
Training loss: 1.3234007358551025
Validation loss: 1.9108891615303614

Epoch: 6| Step: 5
Training loss: 0.9465453624725342
Validation loss: 1.9387482263708626

Epoch: 6| Step: 6
Training loss: 1.256437063217163
Validation loss: 1.8684242476699173

Epoch: 6| Step: 7
Training loss: 1.2612197399139404
Validation loss: 1.8672002720576462

Epoch: 6| Step: 8
Training loss: 1.4120502471923828
Validation loss: 1.8941274830090102

Epoch: 6| Step: 9
Training loss: 0.6368889808654785
Validation loss: 1.930252705850909

Epoch: 6| Step: 10
Training loss: 0.8134430646896362
Validation loss: 1.9824882079196233

Epoch: 6| Step: 11
Training loss: 0.8897679448127747
Validation loss: 1.9124103771742953

Epoch: 6| Step: 12
Training loss: 1.1074241399765015
Validation loss: 1.935812392542439

Epoch: 6| Step: 13
Training loss: 1.1201872825622559
Validation loss: 1.8326471467171945

Epoch: 504| Step: 0
Training loss: 1.3036690950393677
Validation loss: 1.9478138774953864

Epoch: 6| Step: 1
Training loss: 0.8307288885116577
Validation loss: 1.8469301436537056

Epoch: 6| Step: 2
Training loss: 1.416737675666809
Validation loss: 1.8020360354454286

Epoch: 6| Step: 3
Training loss: 1.0319621562957764
Validation loss: 1.878983587347051

Epoch: 6| Step: 4
Training loss: 1.3334369659423828
Validation loss: 1.9417257616596837

Epoch: 6| Step: 5
Training loss: 1.1632845401763916
Validation loss: 1.8818224258320306

Epoch: 6| Step: 6
Training loss: 1.534659743309021
Validation loss: 1.8950407043580086

Epoch: 6| Step: 7
Training loss: 1.548523187637329
Validation loss: 1.9298888239809262

Epoch: 6| Step: 8
Training loss: 1.1474720239639282
Validation loss: 1.930408513674172

Epoch: 6| Step: 9
Training loss: 1.3748117685317993
Validation loss: 1.918050589100007

Epoch: 6| Step: 10
Training loss: 1.0412894487380981
Validation loss: 1.8802120121576453

Epoch: 6| Step: 11
Training loss: 1.1429224014282227
Validation loss: 1.8430641440935032

Epoch: 6| Step: 12
Training loss: 0.5302039384841919
Validation loss: 1.8639833645154071

Epoch: 6| Step: 13
Training loss: 0.8080531358718872
Validation loss: 1.8530340297247774

Epoch: 505| Step: 0
Training loss: 0.6377713084220886
Validation loss: 1.9171813662334154

Epoch: 6| Step: 1
Training loss: 0.8846352100372314
Validation loss: 1.9055757266218945

Epoch: 6| Step: 2
Training loss: 1.026024341583252
Validation loss: 1.8448028897726407

Epoch: 6| Step: 3
Training loss: 1.5442633628845215
Validation loss: 1.9251785611593595

Epoch: 6| Step: 4
Training loss: 1.6299840211868286
Validation loss: 1.8809559678518644

Epoch: 6| Step: 5
Training loss: 1.4902446269989014
Validation loss: 1.8543442936353787

Epoch: 6| Step: 6
Training loss: 0.8266076445579529
Validation loss: 1.875594287790278

Epoch: 6| Step: 7
Training loss: 1.1677650213241577
Validation loss: 1.8856780657204248

Epoch: 6| Step: 8
Training loss: 1.1430673599243164
Validation loss: 1.9378338475381174

Epoch: 6| Step: 9
Training loss: 1.0088374614715576
Validation loss: 1.9137115247787968

Epoch: 6| Step: 10
Training loss: 0.9629913568496704
Validation loss: 1.8708024383873068

Epoch: 6| Step: 11
Training loss: 1.3846631050109863
Validation loss: 1.875704523055784

Epoch: 6| Step: 12
Training loss: 1.2402361631393433
Validation loss: 1.9445195403150333

Epoch: 6| Step: 13
Training loss: 0.889741063117981
Validation loss: 1.884086142304123

Epoch: 506| Step: 0
Training loss: 0.6021556854248047
Validation loss: 1.8952503332527735

Epoch: 6| Step: 1
Training loss: 1.221461534500122
Validation loss: 1.8817360067880282

Epoch: 6| Step: 2
Training loss: 0.7515966296195984
Validation loss: 1.879696043588782

Epoch: 6| Step: 3
Training loss: 2.0141241550445557
Validation loss: 1.9101222945797829

Epoch: 6| Step: 4
Training loss: 1.3959341049194336
Validation loss: 1.9809197841152069

Epoch: 6| Step: 5
Training loss: 1.034430742263794
Validation loss: 1.854292062021071

Epoch: 6| Step: 6
Training loss: 0.9256744384765625
Validation loss: 1.9182818910127044

Epoch: 6| Step: 7
Training loss: 0.9007483720779419
Validation loss: 1.871086311596696

Epoch: 6| Step: 8
Training loss: 0.9249656796455383
Validation loss: 1.9753890486173733

Epoch: 6| Step: 9
Training loss: 1.0800949335098267
Validation loss: 1.9540279706319172

Epoch: 6| Step: 10
Training loss: 1.3556914329528809
Validation loss: 1.9268976949876355

Epoch: 6| Step: 11
Training loss: 1.032393455505371
Validation loss: 1.9000183420796548

Epoch: 6| Step: 12
Training loss: 1.1521093845367432
Validation loss: 1.9219018182446879

Epoch: 6| Step: 13
Training loss: 1.0054937601089478
Validation loss: 1.918581771594222

Epoch: 507| Step: 0
Training loss: 1.036766767501831
Validation loss: 1.8674859218699957

Epoch: 6| Step: 1
Training loss: 1.1952605247497559
Validation loss: 1.9256546933163878

Epoch: 6| Step: 2
Training loss: 0.8915890455245972
Validation loss: 1.8187503353241952

Epoch: 6| Step: 3
Training loss: 1.0624117851257324
Validation loss: 1.8752346590001097

Epoch: 6| Step: 4
Training loss: 0.890397310256958
Validation loss: 1.8698087635860647

Epoch: 6| Step: 5
Training loss: 1.8110767602920532
Validation loss: 1.9844510632176553

Epoch: 6| Step: 6
Training loss: 1.1769338846206665
Validation loss: 1.8868694882239065

Epoch: 6| Step: 7
Training loss: 0.5809094309806824
Validation loss: 1.929999602738247

Epoch: 6| Step: 8
Training loss: 2.0255494117736816
Validation loss: 1.888221384376608

Epoch: 6| Step: 9
Training loss: 0.9981520771980286
Validation loss: 1.8724890434613792

Epoch: 6| Step: 10
Training loss: 0.907618522644043
Validation loss: 1.8513562525472333

Epoch: 6| Step: 11
Training loss: 1.2278568744659424
Validation loss: 1.979811535086683

Epoch: 6| Step: 12
Training loss: 1.0977298021316528
Validation loss: 1.9001862592594598

Epoch: 6| Step: 13
Training loss: 1.167534351348877
Validation loss: 1.990656005438938

Epoch: 508| Step: 0
Training loss: 1.0287702083587646
Validation loss: 1.9238323652616112

Epoch: 6| Step: 1
Training loss: 1.0813169479370117
Validation loss: 1.9731889142785022

Epoch: 6| Step: 2
Training loss: 1.9718050956726074
Validation loss: 2.024109196919267

Epoch: 6| Step: 3
Training loss: 1.3283946514129639
Validation loss: 2.011351787915794

Epoch: 6| Step: 4
Training loss: 1.2216408252716064
Validation loss: 2.0336616654549875

Epoch: 6| Step: 5
Training loss: 1.1857260465621948
Validation loss: 1.9835493885060793

Epoch: 6| Step: 6
Training loss: 1.032299280166626
Validation loss: 2.023200886223906

Epoch: 6| Step: 7
Training loss: 1.0384784936904907
Validation loss: 1.9764811556826356

Epoch: 6| Step: 8
Training loss: 1.5715826749801636
Validation loss: 1.9279364911458825

Epoch: 6| Step: 9
Training loss: 1.3095519542694092
Validation loss: 1.9225135695549749

Epoch: 6| Step: 10
Training loss: 0.966963529586792
Validation loss: 1.868657595367842

Epoch: 6| Step: 11
Training loss: 0.8800160884857178
Validation loss: 1.880044283405427

Epoch: 6| Step: 12
Training loss: 0.8832482099533081
Validation loss: 1.8460467015543292

Epoch: 6| Step: 13
Training loss: 1.5150752067565918
Validation loss: 1.875358259806069

Epoch: 509| Step: 0
Training loss: 0.8991761207580566
Validation loss: 1.8510373305248957

Epoch: 6| Step: 1
Training loss: 1.1138076782226562
Validation loss: 1.8802985260563512

Epoch: 6| Step: 2
Training loss: 1.0373585224151611
Validation loss: 1.8374331458922355

Epoch: 6| Step: 3
Training loss: 0.6197056174278259
Validation loss: 1.8813471191672868

Epoch: 6| Step: 4
Training loss: 0.8456493616104126
Validation loss: 1.8590554293765817

Epoch: 6| Step: 5
Training loss: 1.1198869943618774
Validation loss: 1.8644290880490375

Epoch: 6| Step: 6
Training loss: 1.0818442106246948
Validation loss: 1.9454473487792476

Epoch: 6| Step: 7
Training loss: 1.289036750793457
Validation loss: 1.8927097064192577

Epoch: 6| Step: 8
Training loss: 1.695553183555603
Validation loss: 1.9183581593216106

Epoch: 6| Step: 9
Training loss: 1.3043508529663086
Validation loss: 1.9653474643666258

Epoch: 6| Step: 10
Training loss: 0.9356168508529663
Validation loss: 1.925966226926414

Epoch: 6| Step: 11
Training loss: 1.6506197452545166
Validation loss: 1.8670523858839465

Epoch: 6| Step: 12
Training loss: 1.2231897115707397
Validation loss: 1.860160425145139

Epoch: 6| Step: 13
Training loss: 1.4626373052597046
Validation loss: 1.9692471540102394

Epoch: 510| Step: 0
Training loss: 0.9745229482650757
Validation loss: 1.8326690504627843

Epoch: 6| Step: 1
Training loss: 1.4571912288665771
Validation loss: 2.0325554365752847

Epoch: 6| Step: 2
Training loss: 0.9244160056114197
Validation loss: 1.8659900003863918

Epoch: 6| Step: 3
Training loss: 0.8592239618301392
Validation loss: 2.0010578017080984

Epoch: 6| Step: 4
Training loss: 1.1602869033813477
Validation loss: 1.8582709963603685

Epoch: 6| Step: 5
Training loss: 1.3487190008163452
Validation loss: 1.9189499475622689

Epoch: 6| Step: 6
Training loss: 0.8425436019897461
Validation loss: 1.8874623916482414

Epoch: 6| Step: 7
Training loss: 1.0979373455047607
Validation loss: 1.8442860854569303

Epoch: 6| Step: 8
Training loss: 0.7859035730361938
Validation loss: 1.884937391486219

Epoch: 6| Step: 9
Training loss: 1.1020524501800537
Validation loss: 1.8793938826489192

Epoch: 6| Step: 10
Training loss: 1.5594383478164673
Validation loss: 1.8632212813182543

Epoch: 6| Step: 11
Training loss: 1.2395684719085693
Validation loss: 1.9823187538372573

Epoch: 6| Step: 12
Training loss: 1.1777838468551636
Validation loss: 1.9511285430641585

Epoch: 6| Step: 13
Training loss: 0.972265899181366
Validation loss: 1.9198847483563166

Epoch: 511| Step: 0
Training loss: 1.2395700216293335
Validation loss: 1.9557429898169734

Epoch: 6| Step: 1
Training loss: 1.006524920463562
Validation loss: 1.9036525654536423

Epoch: 6| Step: 2
Training loss: 2.0233652591705322
Validation loss: 1.9374476325127385

Epoch: 6| Step: 3
Training loss: 1.189862608909607
Validation loss: 1.940060269448065

Epoch: 6| Step: 4
Training loss: 0.7380548715591431
Validation loss: 1.860665641805177

Epoch: 6| Step: 5
Training loss: 1.3760335445404053
Validation loss: 1.9051765447021813

Epoch: 6| Step: 6
Training loss: 1.4658564329147339
Validation loss: 1.9205189738222348

Epoch: 6| Step: 7
Training loss: 0.958293080329895
Validation loss: 1.923954225355579

Epoch: 6| Step: 8
Training loss: 1.2394335269927979
Validation loss: 1.9233024581786125

Epoch: 6| Step: 9
Training loss: 0.7341049909591675
Validation loss: 1.89884263982055

Epoch: 6| Step: 10
Training loss: 0.9708128571510315
Validation loss: 1.977379342561127

Epoch: 6| Step: 11
Training loss: 1.0625191926956177
Validation loss: 1.8689865418659743

Epoch: 6| Step: 12
Training loss: 0.9843440055847168
Validation loss: 1.931338648642263

Epoch: 6| Step: 13
Training loss: 1.1489264965057373
Validation loss: 1.8430017194440287

Epoch: 512| Step: 0
Training loss: 0.8997097015380859
Validation loss: 1.8746777388357347

Epoch: 6| Step: 1
Training loss: 1.669372320175171
Validation loss: 1.8939383363211026

Epoch: 6| Step: 2
Training loss: 1.4019436836242676
Validation loss: 1.9172472569250292

Epoch: 6| Step: 3
Training loss: 0.8845666646957397
Validation loss: 2.0163081833111343

Epoch: 6| Step: 4
Training loss: 1.2476938962936401
Validation loss: 1.96504468558937

Epoch: 6| Step: 5
Training loss: 1.1813901662826538
Validation loss: 1.9884559915911766

Epoch: 6| Step: 6
Training loss: 1.3566242456436157
Validation loss: 1.9507886030340706

Epoch: 6| Step: 7
Training loss: 1.3256253004074097
Validation loss: 1.9340050323035127

Epoch: 6| Step: 8
Training loss: 1.1653876304626465
Validation loss: 1.9154472504892657

Epoch: 6| Step: 9
Training loss: 1.3568166494369507
Validation loss: 1.9689804059202953

Epoch: 6| Step: 10
Training loss: 0.6661084294319153
Validation loss: 1.9273978997302312

Epoch: 6| Step: 11
Training loss: 0.7261603474617004
Validation loss: 1.9304367970394831

Epoch: 6| Step: 12
Training loss: 0.8764424324035645
Validation loss: 1.978785728895536

Epoch: 6| Step: 13
Training loss: 1.2983213663101196
Validation loss: 1.9185327958035212

Epoch: 513| Step: 0
Training loss: 0.6708919405937195
Validation loss: 1.9010777986177834

Epoch: 6| Step: 1
Training loss: 1.6369681358337402
Validation loss: 1.8933352988253358

Epoch: 6| Step: 2
Training loss: 1.1364798545837402
Validation loss: 1.8783810318157237

Epoch: 6| Step: 3
Training loss: 1.4402565956115723
Validation loss: 1.9131540739408104

Epoch: 6| Step: 4
Training loss: 0.813768744468689
Validation loss: 1.911581245801782

Epoch: 6| Step: 5
Training loss: 1.2163197994232178
Validation loss: 1.8817385729923044

Epoch: 6| Step: 6
Training loss: 1.0632424354553223
Validation loss: 1.9221751959093156

Epoch: 6| Step: 7
Training loss: 1.3760404586791992
Validation loss: 1.857878122278439

Epoch: 6| Step: 8
Training loss: 1.1278951168060303
Validation loss: 1.9033923559291388

Epoch: 6| Step: 9
Training loss: 0.9083414077758789
Validation loss: 1.910718887082992

Epoch: 6| Step: 10
Training loss: 1.174959421157837
Validation loss: 1.9070182692620061

Epoch: 6| Step: 11
Training loss: 1.0203602313995361
Validation loss: 1.9628207965563702

Epoch: 6| Step: 12
Training loss: 0.9359991550445557
Validation loss: 1.8873572964822092

Epoch: 6| Step: 13
Training loss: 1.1192221641540527
Validation loss: 1.8929703466353878

Epoch: 514| Step: 0
Training loss: 1.530526876449585
Validation loss: 1.9190484016172347

Epoch: 6| Step: 1
Training loss: 1.3108285665512085
Validation loss: 1.895357640840674

Epoch: 6| Step: 2
Training loss: 0.9576913714408875
Validation loss: 2.0066421070406513

Epoch: 6| Step: 3
Training loss: 1.1448628902435303
Validation loss: 1.9970070264672721

Epoch: 6| Step: 4
Training loss: 0.9348410964012146
Validation loss: 1.9562051039870068

Epoch: 6| Step: 5
Training loss: 0.7742576599121094
Validation loss: 1.9162460373293968

Epoch: 6| Step: 6
Training loss: 1.1056716442108154
Validation loss: 1.8688889729079379

Epoch: 6| Step: 7
Training loss: 1.229103684425354
Validation loss: 1.9052574198733094

Epoch: 6| Step: 8
Training loss: 1.514107584953308
Validation loss: 1.9449049426663307

Epoch: 6| Step: 9
Training loss: 0.817855954170227
Validation loss: 1.8608748784629248

Epoch: 6| Step: 10
Training loss: 1.4062514305114746
Validation loss: 1.8249329238809564

Epoch: 6| Step: 11
Training loss: 0.7688360214233398
Validation loss: 1.857331988632038

Epoch: 6| Step: 12
Training loss: 1.2625651359558105
Validation loss: 1.9117103263895998

Epoch: 6| Step: 13
Training loss: 0.6613041758537292
Validation loss: 1.8748595970933155

Epoch: 515| Step: 0
Training loss: 1.0138299465179443
Validation loss: 1.9286975732413671

Epoch: 6| Step: 1
Training loss: 1.2290351390838623
Validation loss: 1.88649720017628

Epoch: 6| Step: 2
Training loss: 1.6610090732574463
Validation loss: 1.8879340592251028

Epoch: 6| Step: 3
Training loss: 0.930749773979187
Validation loss: 1.9096119711475987

Epoch: 6| Step: 4
Training loss: 1.2067720890045166
Validation loss: 1.8375175986238705

Epoch: 6| Step: 5
Training loss: 0.8490505218505859
Validation loss: 1.8743873052699591

Epoch: 6| Step: 6
Training loss: 1.4034311771392822
Validation loss: 1.8731872855976064

Epoch: 6| Step: 7
Training loss: 1.2840368747711182
Validation loss: 1.8980762112525202

Epoch: 6| Step: 8
Training loss: 0.7560148239135742
Validation loss: 1.93510438037175

Epoch: 6| Step: 9
Training loss: 1.4230655431747437
Validation loss: 1.8785011883704894

Epoch: 6| Step: 10
Training loss: 1.0922507047653198
Validation loss: 1.9277967906767322

Epoch: 6| Step: 11
Training loss: 0.8930368423461914
Validation loss: 1.9551564249941098

Epoch: 6| Step: 12
Training loss: 1.0880513191223145
Validation loss: 1.9762977784679783

Epoch: 6| Step: 13
Training loss: 0.6202366948127747
Validation loss: 1.9566513812670143

Epoch: 516| Step: 0
Training loss: 1.5510001182556152
Validation loss: 1.8232776067590202

Epoch: 6| Step: 1
Training loss: 1.141861915588379
Validation loss: 1.8707415442312918

Epoch: 6| Step: 2
Training loss: 0.900881826877594
Validation loss: 1.8723660130654611

Epoch: 6| Step: 3
Training loss: 1.4595134258270264
Validation loss: 1.832417538089137

Epoch: 6| Step: 4
Training loss: 1.140852689743042
Validation loss: 1.8179555554543771

Epoch: 6| Step: 5
Training loss: 1.3018980026245117
Validation loss: 1.8728963578900983

Epoch: 6| Step: 6
Training loss: 0.8494076728820801
Validation loss: 1.9046181645444644

Epoch: 6| Step: 7
Training loss: 1.220150351524353
Validation loss: 1.8971492372533327

Epoch: 6| Step: 8
Training loss: 0.809685230255127
Validation loss: 1.86194489079137

Epoch: 6| Step: 9
Training loss: 0.7917342185974121
Validation loss: 1.930281469898839

Epoch: 6| Step: 10
Training loss: 1.268680453300476
Validation loss: 1.784979804869621

Epoch: 6| Step: 11
Training loss: 1.5910582542419434
Validation loss: 1.8751694951006161

Epoch: 6| Step: 12
Training loss: 0.7194075584411621
Validation loss: 1.9075871616281488

Epoch: 6| Step: 13
Training loss: 0.9237557649612427
Validation loss: 1.899087982793008

Epoch: 517| Step: 0
Training loss: 1.2033138275146484
Validation loss: 1.8597733923183974

Epoch: 6| Step: 1
Training loss: 1.0409302711486816
Validation loss: 1.843901749580137

Epoch: 6| Step: 2
Training loss: 1.1820969581604004
Validation loss: 1.9331261316935222

Epoch: 6| Step: 3
Training loss: 1.7155873775482178
Validation loss: 1.8900531466289232

Epoch: 6| Step: 4
Training loss: 0.9339590668678284
Validation loss: 1.8805147435075493

Epoch: 6| Step: 5
Training loss: 1.0139451026916504
Validation loss: 1.896166504070323

Epoch: 6| Step: 6
Training loss: 0.8456592559814453
Validation loss: 1.941179988204792

Epoch: 6| Step: 7
Training loss: 1.143273115158081
Validation loss: 1.9215514941882061

Epoch: 6| Step: 8
Training loss: 0.5914045572280884
Validation loss: 1.8875584474173925

Epoch: 6| Step: 9
Training loss: 0.8068983554840088
Validation loss: 1.901038400588497

Epoch: 6| Step: 10
Training loss: 1.6168900728225708
Validation loss: 1.8889477996415989

Epoch: 6| Step: 11
Training loss: 1.2458058595657349
Validation loss: 1.884986674913796

Epoch: 6| Step: 12
Training loss: 0.9118224382400513
Validation loss: 1.899384779314841

Epoch: 6| Step: 13
Training loss: 0.6492547988891602
Validation loss: 1.962363020066292

Epoch: 518| Step: 0
Training loss: 1.0496344566345215
Validation loss: 1.9451906898970246

Epoch: 6| Step: 1
Training loss: 1.0329792499542236
Validation loss: 1.828289920283902

Epoch: 6| Step: 2
Training loss: 0.9137985110282898
Validation loss: 1.8693456342143397

Epoch: 6| Step: 3
Training loss: 0.8376712203025818
Validation loss: 1.8629352508052703

Epoch: 6| Step: 4
Training loss: 1.3694013357162476
Validation loss: 1.8569672838334115

Epoch: 6| Step: 5
Training loss: 1.2053906917572021
Validation loss: 1.910707676282493

Epoch: 6| Step: 6
Training loss: 1.7827279567718506
Validation loss: 1.848033728138093

Epoch: 6| Step: 7
Training loss: 0.7461658716201782
Validation loss: 1.8984040367987849

Epoch: 6| Step: 8
Training loss: 0.9772707223892212
Validation loss: 1.9187860822164884

Epoch: 6| Step: 9
Training loss: 1.0163867473602295
Validation loss: 1.8828997611999512

Epoch: 6| Step: 10
Training loss: 1.3591067790985107
Validation loss: 1.8638982721554336

Epoch: 6| Step: 11
Training loss: 1.0334645509719849
Validation loss: 1.926365871583262

Epoch: 6| Step: 12
Training loss: 1.171151876449585
Validation loss: 2.0161439013737503

Epoch: 6| Step: 13
Training loss: 1.1203534603118896
Validation loss: 1.863350211933095

Epoch: 519| Step: 0
Training loss: 0.8475369215011597
Validation loss: 1.8732286076391897

Epoch: 6| Step: 1
Training loss: 0.8300288319587708
Validation loss: 1.8657142423814344

Epoch: 6| Step: 2
Training loss: 1.5710527896881104
Validation loss: 1.9793693122043405

Epoch: 6| Step: 3
Training loss: 1.2517726421356201
Validation loss: 1.9297233473870061

Epoch: 6| Step: 4
Training loss: 1.0113540887832642
Validation loss: 1.9809825843380344

Epoch: 6| Step: 5
Training loss: 0.8727142214775085
Validation loss: 1.8786024406392088

Epoch: 6| Step: 6
Training loss: 1.412637710571289
Validation loss: 1.9215297109337264

Epoch: 6| Step: 7
Training loss: 1.0510681867599487
Validation loss: 1.8966861412089357

Epoch: 6| Step: 8
Training loss: 1.456300973892212
Validation loss: 1.8725379513156029

Epoch: 6| Step: 9
Training loss: 0.8908389806747437
Validation loss: 1.9479439309848252

Epoch: 6| Step: 10
Training loss: 0.8422628045082092
Validation loss: 1.890416447834302

Epoch: 6| Step: 11
Training loss: 1.1977994441986084
Validation loss: 1.9031494740516908

Epoch: 6| Step: 12
Training loss: 0.9719587564468384
Validation loss: 1.9934019824509979

Epoch: 6| Step: 13
Training loss: 0.5285369157791138
Validation loss: 1.9141367379055227

Epoch: 520| Step: 0
Training loss: 1.0477381944656372
Validation loss: 1.9181674321492512

Epoch: 6| Step: 1
Training loss: 1.1481187343597412
Validation loss: 1.8913947946281844

Epoch: 6| Step: 2
Training loss: 1.845439076423645
Validation loss: 1.907274350043266

Epoch: 6| Step: 3
Training loss: 1.2568295001983643
Validation loss: 1.8852858851032872

Epoch: 6| Step: 4
Training loss: 1.1330596208572388
Validation loss: 1.879244671073011

Epoch: 6| Step: 5
Training loss: 1.059382438659668
Validation loss: 1.91569257807988

Epoch: 6| Step: 6
Training loss: 0.9799089431762695
Validation loss: 1.85126313342843

Epoch: 6| Step: 7
Training loss: 1.1840310096740723
Validation loss: 1.8852170180248957

Epoch: 6| Step: 8
Training loss: 0.5396394729614258
Validation loss: 2.03328791997766

Epoch: 6| Step: 9
Training loss: 1.1117792129516602
Validation loss: 1.9147459922298309

Epoch: 6| Step: 10
Training loss: 1.1384716033935547
Validation loss: 1.971088501714891

Epoch: 6| Step: 11
Training loss: 1.1555659770965576
Validation loss: 1.9311073262204406

Epoch: 6| Step: 12
Training loss: 1.134002685546875
Validation loss: 2.011702569582129

Epoch: 6| Step: 13
Training loss: 1.0468721389770508
Validation loss: 1.950047985199959

Epoch: 521| Step: 0
Training loss: 1.196673035621643
Validation loss: 1.9970549127107025

Epoch: 6| Step: 1
Training loss: 0.9312830567359924
Validation loss: 1.9686381214408464

Epoch: 6| Step: 2
Training loss: 0.966792106628418
Validation loss: 1.9126787467669415

Epoch: 6| Step: 3
Training loss: 0.8450353145599365
Validation loss: 1.8657308445181897

Epoch: 6| Step: 4
Training loss: 0.9591755867004395
Validation loss: 1.8557559802968016

Epoch: 6| Step: 5
Training loss: 1.360440969467163
Validation loss: 2.0332326094309487

Epoch: 6| Step: 6
Training loss: 1.055431604385376
Validation loss: 1.871033921036669

Epoch: 6| Step: 7
Training loss: 1.12503182888031
Validation loss: 1.9180495418528074

Epoch: 6| Step: 8
Training loss: 1.7780851125717163
Validation loss: 1.8964035639198877

Epoch: 6| Step: 9
Training loss: 0.9859367609024048
Validation loss: 1.9037320460042646

Epoch: 6| Step: 10
Training loss: 1.040722131729126
Validation loss: 1.9199729042668496

Epoch: 6| Step: 11
Training loss: 1.192500114440918
Validation loss: 1.9059952484664096

Epoch: 6| Step: 12
Training loss: 1.1654887199401855
Validation loss: 1.8754935674769904

Epoch: 6| Step: 13
Training loss: 1.0799816846847534
Validation loss: 1.9180275009524437

Epoch: 522| Step: 0
Training loss: 1.5460630655288696
Validation loss: 1.8669314205005605

Epoch: 6| Step: 1
Training loss: 1.5963425636291504
Validation loss: 1.9423454500013781

Epoch: 6| Step: 2
Training loss: 1.1339011192321777
Validation loss: 1.821065528418428

Epoch: 6| Step: 3
Training loss: 0.9209067821502686
Validation loss: 1.8764562478629492

Epoch: 6| Step: 4
Training loss: 0.8626543879508972
Validation loss: 1.8744925222089213

Epoch: 6| Step: 5
Training loss: 1.0087783336639404
Validation loss: 1.9907081075893935

Epoch: 6| Step: 6
Training loss: 0.912441611289978
Validation loss: 1.982288622087048

Epoch: 6| Step: 7
Training loss: 1.4895261526107788
Validation loss: 1.9359614797817764

Epoch: 6| Step: 8
Training loss: 1.2040996551513672
Validation loss: 1.9335401442743116

Epoch: 6| Step: 9
Training loss: 1.021465539932251
Validation loss: 1.9383751371855378

Epoch: 6| Step: 10
Training loss: 0.7917993664741516
Validation loss: 1.918358079848751

Epoch: 6| Step: 11
Training loss: 1.2913591861724854
Validation loss: 1.8589885311741983

Epoch: 6| Step: 12
Training loss: 1.016474723815918
Validation loss: 1.8199407067350162

Epoch: 6| Step: 13
Training loss: 1.0959464311599731
Validation loss: 1.8577427261619157

Epoch: 523| Step: 0
Training loss: 1.646894097328186
Validation loss: 1.8892822573261876

Epoch: 6| Step: 1
Training loss: 0.7566632032394409
Validation loss: 1.8282915007683538

Epoch: 6| Step: 2
Training loss: 0.883587121963501
Validation loss: 1.8656474903065672

Epoch: 6| Step: 3
Training loss: 0.9970300197601318
Validation loss: 1.8657882008501279

Epoch: 6| Step: 4
Training loss: 1.1464078426361084
Validation loss: 1.9218349610605547

Epoch: 6| Step: 5
Training loss: 1.4432713985443115
Validation loss: 1.8779855697385726

Epoch: 6| Step: 6
Training loss: 1.3649910688400269
Validation loss: 1.8469839160160353

Epoch: 6| Step: 7
Training loss: 0.8571990728378296
Validation loss: 1.9474839369455974

Epoch: 6| Step: 8
Training loss: 1.4678174257278442
Validation loss: 1.8839371345376457

Epoch: 6| Step: 9
Training loss: 1.0011787414550781
Validation loss: 1.836241118369564

Epoch: 6| Step: 10
Training loss: 1.0108586549758911
Validation loss: 1.8743278172708326

Epoch: 6| Step: 11
Training loss: 1.1338047981262207
Validation loss: 1.8569605581222042

Epoch: 6| Step: 12
Training loss: 1.4109498262405396
Validation loss: 1.8976971257117488

Epoch: 6| Step: 13
Training loss: 0.9942218065261841
Validation loss: 2.025056662098054

Epoch: 524| Step: 0
Training loss: 1.3058630228042603
Validation loss: 2.006315033922913

Epoch: 6| Step: 1
Training loss: 0.8390308618545532
Validation loss: 1.9922166716667913

Epoch: 6| Step: 2
Training loss: 0.7373403906822205
Validation loss: 1.9363296890771517

Epoch: 6| Step: 3
Training loss: 1.2445626258850098
Validation loss: 1.956785257144641

Epoch: 6| Step: 4
Training loss: 1.3109039068222046
Validation loss: 1.9150629274306759

Epoch: 6| Step: 5
Training loss: 1.5675568580627441
Validation loss: 1.9482363552175543

Epoch: 6| Step: 6
Training loss: 1.413190245628357
Validation loss: 1.8740839650554042

Epoch: 6| Step: 7
Training loss: 0.8095811605453491
Validation loss: 1.8813517157749464

Epoch: 6| Step: 8
Training loss: 1.0770485401153564
Validation loss: 1.8164032556677376

Epoch: 6| Step: 9
Training loss: 1.2371976375579834
Validation loss: 1.872162877872426

Epoch: 6| Step: 10
Training loss: 1.1027872562408447
Validation loss: 1.9266631475058935

Epoch: 6| Step: 11
Training loss: 1.07351553440094
Validation loss: 1.8689532818332795

Epoch: 6| Step: 12
Training loss: 0.8850235939025879
Validation loss: 1.8618859373113161

Epoch: 6| Step: 13
Training loss: 0.6070274114608765
Validation loss: 1.8681931931485412

Epoch: 525| Step: 0
Training loss: 0.8409427404403687
Validation loss: 1.8873489736228861

Epoch: 6| Step: 1
Training loss: 0.7941766977310181
Validation loss: 1.8514503279039938

Epoch: 6| Step: 2
Training loss: 0.9980315566062927
Validation loss: 1.9072422442897674

Epoch: 6| Step: 3
Training loss: 1.201256513595581
Validation loss: 1.836145313837195

Epoch: 6| Step: 4
Training loss: 1.3379440307617188
Validation loss: 1.927596494715701

Epoch: 6| Step: 5
Training loss: 0.9480072259902954
Validation loss: 1.8745946473972772

Epoch: 6| Step: 6
Training loss: 1.106461763381958
Validation loss: 1.912270930505568

Epoch: 6| Step: 7
Training loss: 1.0830899477005005
Validation loss: 1.8732589701170563

Epoch: 6| Step: 8
Training loss: 0.8667632341384888
Validation loss: 1.9546823937405822

Epoch: 6| Step: 9
Training loss: 1.2426708936691284
Validation loss: 1.8589723481926868

Epoch: 6| Step: 10
Training loss: 1.3942753076553345
Validation loss: 1.9303425537642611

Epoch: 6| Step: 11
Training loss: 1.0721555948257446
Validation loss: 1.946545958518982

Epoch: 6| Step: 12
Training loss: 1.1307175159454346
Validation loss: 2.0117412703011626

Epoch: 6| Step: 13
Training loss: 1.5401978492736816
Validation loss: 1.9702577155123475

Epoch: 526| Step: 0
Training loss: 1.1536366939544678
Validation loss: 1.9310998711534726

Epoch: 6| Step: 1
Training loss: 1.0016112327575684
Validation loss: 1.9701621417076356

Epoch: 6| Step: 2
Training loss: 0.8372992873191833
Validation loss: 1.9560575139138006

Epoch: 6| Step: 3
Training loss: 0.7370277643203735
Validation loss: 1.8874328444080968

Epoch: 6| Step: 4
Training loss: 1.1688517332077026
Validation loss: 1.942171868457589

Epoch: 6| Step: 5
Training loss: 1.3493900299072266
Validation loss: 1.8878295639509797

Epoch: 6| Step: 6
Training loss: 1.3626960515975952
Validation loss: 1.8959850880407518

Epoch: 6| Step: 7
Training loss: 1.1774466037750244
Validation loss: 1.8032428154381372

Epoch: 6| Step: 8
Training loss: 1.279567003250122
Validation loss: 1.8901259745320966

Epoch: 6| Step: 9
Training loss: 0.4220980405807495
Validation loss: 1.8873179753621419

Epoch: 6| Step: 10
Training loss: 1.2103614807128906
Validation loss: 1.9292543959873978

Epoch: 6| Step: 11
Training loss: 0.7681218981742859
Validation loss: 1.8797611100699312

Epoch: 6| Step: 12
Training loss: 1.4709460735321045
Validation loss: 1.8868790262488908

Epoch: 6| Step: 13
Training loss: 0.7791761755943298
Validation loss: 1.8914899954231836

Epoch: 527| Step: 0
Training loss: 1.0004112720489502
Validation loss: 1.8867979780320199

Epoch: 6| Step: 1
Training loss: 1.094225287437439
Validation loss: 1.9186801269490232

Epoch: 6| Step: 2
Training loss: 1.1329665184020996
Validation loss: 1.9150038637140745

Epoch: 6| Step: 3
Training loss: 0.890299379825592
Validation loss: 1.9620847368753085

Epoch: 6| Step: 4
Training loss: 1.4846941232681274
Validation loss: 1.9354400891129688

Epoch: 6| Step: 5
Training loss: 0.843064546585083
Validation loss: 1.9373124440511067

Epoch: 6| Step: 6
Training loss: 1.2903169393539429
Validation loss: 1.8794616294163529

Epoch: 6| Step: 7
Training loss: 1.5768346786499023
Validation loss: 1.863891258034655

Epoch: 6| Step: 8
Training loss: 1.4875946044921875
Validation loss: 1.8507336096097065

Epoch: 6| Step: 9
Training loss: 0.953874945640564
Validation loss: 1.8633673908889934

Epoch: 6| Step: 10
Training loss: 0.9404637217521667
Validation loss: 1.886599915001982

Epoch: 6| Step: 11
Training loss: 0.8959484100341797
Validation loss: 1.8849884989441081

Epoch: 6| Step: 12
Training loss: 1.0991328954696655
Validation loss: 1.8261883092182938

Epoch: 6| Step: 13
Training loss: 0.7740268111228943
Validation loss: 1.8543748150589645

Epoch: 528| Step: 0
Training loss: 0.8895062208175659
Validation loss: 1.9101464056199597

Epoch: 6| Step: 1
Training loss: 1.2042310237884521
Validation loss: 1.9090611703934208

Epoch: 6| Step: 2
Training loss: 1.03670072555542
Validation loss: 1.9597884929308327

Epoch: 6| Step: 3
Training loss: 1.1992424726486206
Validation loss: 1.9200478497371878

Epoch: 6| Step: 4
Training loss: 1.011080265045166
Validation loss: 1.8497046539860387

Epoch: 6| Step: 5
Training loss: 1.3464568853378296
Validation loss: 1.8534236223466936

Epoch: 6| Step: 6
Training loss: 0.9884586334228516
Validation loss: 1.9126955398949244

Epoch: 6| Step: 7
Training loss: 1.0841134786605835
Validation loss: 1.870383413889075

Epoch: 6| Step: 8
Training loss: 1.1836037635803223
Validation loss: 1.896193314624089

Epoch: 6| Step: 9
Training loss: 0.9038618803024292
Validation loss: 1.9397353818339687

Epoch: 6| Step: 10
Training loss: 0.7361530661582947
Validation loss: 1.8694679737091064

Epoch: 6| Step: 11
Training loss: 1.514805555343628
Validation loss: 1.948678408899615

Epoch: 6| Step: 12
Training loss: 1.0657671689987183
Validation loss: 1.838054746709844

Epoch: 6| Step: 13
Training loss: 0.7415023446083069
Validation loss: 1.9448633142696914

Epoch: 529| Step: 0
Training loss: 1.072920322418213
Validation loss: 1.9238470062132804

Epoch: 6| Step: 1
Training loss: 1.0803618431091309
Validation loss: 1.8953352051396524

Epoch: 6| Step: 2
Training loss: 0.9825726747512817
Validation loss: 1.8963483969370525

Epoch: 6| Step: 3
Training loss: 0.904568076133728
Validation loss: 1.9009450033146849

Epoch: 6| Step: 4
Training loss: 0.8165159821510315
Validation loss: 1.9034121574894074

Epoch: 6| Step: 5
Training loss: 0.8095049262046814
Validation loss: 1.8017715228501188

Epoch: 6| Step: 6
Training loss: 1.3077198266983032
Validation loss: 1.958348492140411

Epoch: 6| Step: 7
Training loss: 0.8202197551727295
Validation loss: 1.8747938204837102

Epoch: 6| Step: 8
Training loss: 0.8421868085861206
Validation loss: 1.8891824919690368

Epoch: 6| Step: 9
Training loss: 0.9141805171966553
Validation loss: 1.9100380174575313

Epoch: 6| Step: 10
Training loss: 1.437504529953003
Validation loss: 1.917748092323221

Epoch: 6| Step: 11
Training loss: 1.2832105159759521
Validation loss: 1.932669533196316

Epoch: 6| Step: 12
Training loss: 1.775036334991455
Validation loss: 1.9081158868728145

Epoch: 6| Step: 13
Training loss: 0.6253653168678284
Validation loss: 1.9166977969549035

Epoch: 530| Step: 0
Training loss: 1.2975221872329712
Validation loss: 1.8292985257282053

Epoch: 6| Step: 1
Training loss: 1.0686599016189575
Validation loss: 1.885740601888267

Epoch: 6| Step: 2
Training loss: 1.2215611934661865
Validation loss: 1.8455676109560075

Epoch: 6| Step: 3
Training loss: 1.1985098123550415
Validation loss: 1.9018336444772699

Epoch: 6| Step: 4
Training loss: 0.9254986643791199
Validation loss: 1.9599307173041887

Epoch: 6| Step: 5
Training loss: 0.7349034547805786
Validation loss: 1.9306535925916446

Epoch: 6| Step: 6
Training loss: 1.0653291940689087
Validation loss: 1.825448001584699

Epoch: 6| Step: 7
Training loss: 0.9142965078353882
Validation loss: 1.994637676464614

Epoch: 6| Step: 8
Training loss: 1.384204626083374
Validation loss: 1.8933836901059715

Epoch: 6| Step: 9
Training loss: 1.1447933912277222
Validation loss: 1.9055983417777604

Epoch: 6| Step: 10
Training loss: 1.2808582782745361
Validation loss: 1.9321633756801646

Epoch: 6| Step: 11
Training loss: 0.6204862594604492
Validation loss: 1.872712876207085

Epoch: 6| Step: 12
Training loss: 0.8271034955978394
Validation loss: 1.8991907181278351

Epoch: 6| Step: 13
Training loss: 1.4060646295547485
Validation loss: 1.9531807194473922

Epoch: 531| Step: 0
Training loss: 0.5770037174224854
Validation loss: 1.9517067529821908

Epoch: 6| Step: 1
Training loss: 1.7168281078338623
Validation loss: 1.8616930900081512

Epoch: 6| Step: 2
Training loss: 0.8159313201904297
Validation loss: 1.8794114435872724

Epoch: 6| Step: 3
Training loss: 0.8798744678497314
Validation loss: 1.829412365472445

Epoch: 6| Step: 4
Training loss: 1.0699326992034912
Validation loss: 1.8947466611862183

Epoch: 6| Step: 5
Training loss: 0.5988321900367737
Validation loss: 1.8799753458269182

Epoch: 6| Step: 6
Training loss: 0.8144572973251343
Validation loss: 1.8632803373439337

Epoch: 6| Step: 7
Training loss: 1.0437339544296265
Validation loss: 1.876010392301826

Epoch: 6| Step: 8
Training loss: 0.9946584105491638
Validation loss: 1.8454458508440243

Epoch: 6| Step: 9
Training loss: 0.8837266564369202
Validation loss: 1.9522893351893271

Epoch: 6| Step: 10
Training loss: 1.77101731300354
Validation loss: 1.9172206104442637

Epoch: 6| Step: 11
Training loss: 1.2726913690567017
Validation loss: 1.8860697541185605

Epoch: 6| Step: 12
Training loss: 1.521333932876587
Validation loss: 1.8827750785376436

Epoch: 6| Step: 13
Training loss: 0.8471806049346924
Validation loss: 1.913319879962552

Epoch: 532| Step: 0
Training loss: 1.0301859378814697
Validation loss: 1.8765604637002433

Epoch: 6| Step: 1
Training loss: 1.0961341857910156
Validation loss: 1.9204647592318955

Epoch: 6| Step: 2
Training loss: 0.8796383142471313
Validation loss: 1.8386898489408596

Epoch: 6| Step: 3
Training loss: 1.1043193340301514
Validation loss: 1.9484276989454865

Epoch: 6| Step: 4
Training loss: 1.3879015445709229
Validation loss: 1.867439088001046

Epoch: 6| Step: 5
Training loss: 0.8814752101898193
Validation loss: 1.9464913709189302

Epoch: 6| Step: 6
Training loss: 0.9406331777572632
Validation loss: 1.9174955583387805

Epoch: 6| Step: 7
Training loss: 1.1411876678466797
Validation loss: 1.9314584039872693

Epoch: 6| Step: 8
Training loss: 0.6372350454330444
Validation loss: 1.9235985945629817

Epoch: 6| Step: 9
Training loss: 0.8098419308662415
Validation loss: 1.9256800823314215

Epoch: 6| Step: 10
Training loss: 1.1003416776657104
Validation loss: 1.8976014429523098

Epoch: 6| Step: 11
Training loss: 1.067573070526123
Validation loss: 1.9081872817008727

Epoch: 6| Step: 12
Training loss: 1.3137807846069336
Validation loss: 1.962871031094623

Epoch: 6| Step: 13
Training loss: 2.03291654586792
Validation loss: 1.8416988670185048

Epoch: 533| Step: 0
Training loss: 1.181183934211731
Validation loss: 1.8167589505513508

Epoch: 6| Step: 1
Training loss: 1.1906647682189941
Validation loss: 1.9109245436165923

Epoch: 6| Step: 2
Training loss: 1.0708796977996826
Validation loss: 1.8627056280771892

Epoch: 6| Step: 3
Training loss: 1.0181922912597656
Validation loss: 1.836028322096794

Epoch: 6| Step: 4
Training loss: 0.7850781679153442
Validation loss: 1.8341512263462108

Epoch: 6| Step: 5
Training loss: 1.1764612197875977
Validation loss: 1.882115533274989

Epoch: 6| Step: 6
Training loss: 0.868781328201294
Validation loss: 1.8462211111540436

Epoch: 6| Step: 7
Training loss: 1.3031208515167236
Validation loss: 1.9804091556097871

Epoch: 6| Step: 8
Training loss: 1.0370362997055054
Validation loss: 1.8573762768058366

Epoch: 6| Step: 9
Training loss: 1.0986530780792236
Validation loss: 1.8709225667420255

Epoch: 6| Step: 10
Training loss: 1.1834089756011963
Validation loss: 1.8656259595706899

Epoch: 6| Step: 11
Training loss: 1.0766065120697021
Validation loss: 1.8352896808296122

Epoch: 6| Step: 12
Training loss: 0.9624426960945129
Validation loss: 1.8826901976780226

Epoch: 6| Step: 13
Training loss: 0.5031231641769409
Validation loss: 1.9282507024785525

Epoch: 534| Step: 0
Training loss: 1.7384634017944336
Validation loss: 1.896261215209961

Epoch: 6| Step: 1
Training loss: 0.43913403153419495
Validation loss: 1.887500968030704

Epoch: 6| Step: 2
Training loss: 0.8974652290344238
Validation loss: 1.8968341222373388

Epoch: 6| Step: 3
Training loss: 1.3877239227294922
Validation loss: 1.8843762310602332

Epoch: 6| Step: 4
Training loss: 0.7412217855453491
Validation loss: 1.9079127311706543

Epoch: 6| Step: 5
Training loss: 0.7291455864906311
Validation loss: 1.9248254273527412

Epoch: 6| Step: 6
Training loss: 1.3480048179626465
Validation loss: 2.0025452080593316

Epoch: 6| Step: 7
Training loss: 0.8651644587516785
Validation loss: 1.9405717324185114

Epoch: 6| Step: 8
Training loss: 0.8797930479049683
Validation loss: 1.9170347785436979

Epoch: 6| Step: 9
Training loss: 1.728820562362671
Validation loss: 1.8594870977504279

Epoch: 6| Step: 10
Training loss: 1.948394536972046
Validation loss: 1.9228778385346936

Epoch: 6| Step: 11
Training loss: 0.6904524564743042
Validation loss: 1.9264510267524309

Epoch: 6| Step: 12
Training loss: 1.0370371341705322
Validation loss: 1.899343986665049

Epoch: 6| Step: 13
Training loss: 0.32641759514808655
Validation loss: 1.8708939065215409

Epoch: 535| Step: 0
Training loss: 1.3131362199783325
Validation loss: 1.877540760142829

Epoch: 6| Step: 1
Training loss: 1.6858296394348145
Validation loss: 1.8775669464501001

Epoch: 6| Step: 2
Training loss: 1.5528204441070557
Validation loss: 1.8839616455057615

Epoch: 6| Step: 3
Training loss: 0.7844580411911011
Validation loss: 1.9222685931831278

Epoch: 6| Step: 4
Training loss: 0.8597479462623596
Validation loss: 1.868447478099536

Epoch: 6| Step: 5
Training loss: 0.94716477394104
Validation loss: 1.9112500913681523

Epoch: 6| Step: 6
Training loss: 0.9619739651679993
Validation loss: 1.8868907959230485

Epoch: 6| Step: 7
Training loss: 0.9840223789215088
Validation loss: 1.8031403633856005

Epoch: 6| Step: 8
Training loss: 0.7567558288574219
Validation loss: 1.9207516562554143

Epoch: 6| Step: 9
Training loss: 1.1526718139648438
Validation loss: 1.87005369124874

Epoch: 6| Step: 10
Training loss: 0.9460896253585815
Validation loss: 1.8935788844221382

Epoch: 6| Step: 11
Training loss: 1.4931201934814453
Validation loss: 1.979402131931756

Epoch: 6| Step: 12
Training loss: 0.8023924231529236
Validation loss: 1.86821319723642

Epoch: 6| Step: 13
Training loss: 0.721710205078125
Validation loss: 1.9476356378165625

Epoch: 536| Step: 0
Training loss: 1.605273723602295
Validation loss: 1.9379954491892168

Epoch: 6| Step: 1
Training loss: 1.0894403457641602
Validation loss: 1.84882604306744

Epoch: 6| Step: 2
Training loss: 1.1200616359710693
Validation loss: 1.8307901813137917

Epoch: 6| Step: 3
Training loss: 0.870254635810852
Validation loss: 1.8417301331796954

Epoch: 6| Step: 4
Training loss: 1.2017382383346558
Validation loss: 1.7736150410867506

Epoch: 6| Step: 5
Training loss: 0.703162431716919
Validation loss: 1.894200292966699

Epoch: 6| Step: 6
Training loss: 0.7333550453186035
Validation loss: 1.8509708514777563

Epoch: 6| Step: 7
Training loss: 1.4237282276153564
Validation loss: 1.902702098251671

Epoch: 6| Step: 8
Training loss: 0.6713212728500366
Validation loss: 1.940282980600993

Epoch: 6| Step: 9
Training loss: 1.1125203371047974
Validation loss: 1.9287547693457654

Epoch: 6| Step: 10
Training loss: 1.4511725902557373
Validation loss: 1.9473712918578938

Epoch: 6| Step: 11
Training loss: 0.9809338450431824
Validation loss: 1.8769507818324591

Epoch: 6| Step: 12
Training loss: 1.1189974546432495
Validation loss: 1.880545275185698

Epoch: 6| Step: 13
Training loss: 0.9463293552398682
Validation loss: 2.0107810061465026

Epoch: 537| Step: 0
Training loss: 0.7800846695899963
Validation loss: 1.9326638201231598

Epoch: 6| Step: 1
Training loss: 1.3221391439437866
Validation loss: 1.9980815226031887

Epoch: 6| Step: 2
Training loss: 0.8548768758773804
Validation loss: 1.9330361658527004

Epoch: 6| Step: 3
Training loss: 1.006364107131958
Validation loss: 1.9382051524295603

Epoch: 6| Step: 4
Training loss: 0.6829909086227417
Validation loss: 1.9339785422048261

Epoch: 6| Step: 5
Training loss: 1.3209047317504883
Validation loss: 1.8845228854046072

Epoch: 6| Step: 6
Training loss: 1.1733136177062988
Validation loss: 1.8449574209028674

Epoch: 6| Step: 7
Training loss: 1.0470889806747437
Validation loss: 1.8725764905252764

Epoch: 6| Step: 8
Training loss: 0.858173131942749
Validation loss: 1.8832763497547438

Epoch: 6| Step: 9
Training loss: 1.2193557024002075
Validation loss: 1.8765367410516227

Epoch: 6| Step: 10
Training loss: 0.9912843108177185
Validation loss: 1.8750340592476629

Epoch: 6| Step: 11
Training loss: 1.1491775512695312
Validation loss: 1.8241424893820157

Epoch: 6| Step: 12
Training loss: 1.3263418674468994
Validation loss: 1.887874601989664

Epoch: 6| Step: 13
Training loss: 0.5233128666877747
Validation loss: 1.841361294510544

Epoch: 538| Step: 0
Training loss: 0.6700429916381836
Validation loss: 1.8566793998082478

Epoch: 6| Step: 1
Training loss: 0.9157518744468689
Validation loss: 1.8322549276454474

Epoch: 6| Step: 2
Training loss: 0.9661974310874939
Validation loss: 1.9226676571753718

Epoch: 6| Step: 3
Training loss: 1.2626023292541504
Validation loss: 1.9221959344802364

Epoch: 6| Step: 4
Training loss: 0.9878662824630737
Validation loss: 1.9569519771042692

Epoch: 6| Step: 5
Training loss: 0.9556781053543091
Validation loss: 1.9261566208254906

Epoch: 6| Step: 6
Training loss: 1.0984433889389038
Validation loss: 1.897542825309179

Epoch: 6| Step: 7
Training loss: 0.98256516456604
Validation loss: 1.9476173731588549

Epoch: 6| Step: 8
Training loss: 0.8038297295570374
Validation loss: 1.9979383407100555

Epoch: 6| Step: 9
Training loss: 1.1207704544067383
Validation loss: 1.981713520583286

Epoch: 6| Step: 10
Training loss: 1.766655683517456
Validation loss: 1.9750093926665604

Epoch: 6| Step: 11
Training loss: 1.23074471950531
Validation loss: 1.9027165956394647

Epoch: 6| Step: 12
Training loss: 1.015028715133667
Validation loss: 1.9610233255611953

Epoch: 6| Step: 13
Training loss: 1.831412672996521
Validation loss: 1.9132466957133303

Epoch: 539| Step: 0
Training loss: 0.788795530796051
Validation loss: 1.8557641121648973

Epoch: 6| Step: 1
Training loss: 1.0584582090377808
Validation loss: 1.8929522601507043

Epoch: 6| Step: 2
Training loss: 0.6534123420715332
Validation loss: 1.8844102710805914

Epoch: 6| Step: 3
Training loss: 1.31048583984375
Validation loss: 1.9122445634616319

Epoch: 6| Step: 4
Training loss: 0.8610118627548218
Validation loss: 1.9593916259786135

Epoch: 6| Step: 5
Training loss: 1.0168304443359375
Validation loss: 1.8684855058629026

Epoch: 6| Step: 6
Training loss: 1.4918286800384521
Validation loss: 1.8730391251143588

Epoch: 6| Step: 7
Training loss: 1.1250083446502686
Validation loss: 1.9233965027716853

Epoch: 6| Step: 8
Training loss: 1.1369023323059082
Validation loss: 1.9334043008024975

Epoch: 6| Step: 9
Training loss: 1.2729361057281494
Validation loss: 1.8473888763817408

Epoch: 6| Step: 10
Training loss: 1.1734001636505127
Validation loss: 1.9179753103563864

Epoch: 6| Step: 11
Training loss: 0.9694357514381409
Validation loss: 1.9217026592582784

Epoch: 6| Step: 12
Training loss: 1.369877815246582
Validation loss: 1.8487621468882407

Epoch: 6| Step: 13
Training loss: 0.31501561403274536
Validation loss: 1.966283614917468

Epoch: 540| Step: 0
Training loss: 0.7238866090774536
Validation loss: 1.9269991638839885

Epoch: 6| Step: 1
Training loss: 1.0825929641723633
Validation loss: 1.8861834304307097

Epoch: 6| Step: 2
Training loss: 0.7763172388076782
Validation loss: 1.891382501971337

Epoch: 6| Step: 3
Training loss: 1.1251035928726196
Validation loss: 1.929065533863601

Epoch: 6| Step: 4
Training loss: 1.5044710636138916
Validation loss: 1.904615371457992

Epoch: 6| Step: 5
Training loss: 1.2430840730667114
Validation loss: 1.9213901386466077

Epoch: 6| Step: 6
Training loss: 0.790239691734314
Validation loss: 1.892610534544914

Epoch: 6| Step: 7
Training loss: 1.1832624673843384
Validation loss: 1.9199744129693637

Epoch: 6| Step: 8
Training loss: 1.0792323350906372
Validation loss: 1.8901292585557508

Epoch: 6| Step: 9
Training loss: 1.728933572769165
Validation loss: 1.7685830311108661

Epoch: 6| Step: 10
Training loss: 0.6426522731781006
Validation loss: 1.876569256987623

Epoch: 6| Step: 11
Training loss: 1.5436534881591797
Validation loss: 1.9102548040369505

Epoch: 6| Step: 12
Training loss: 0.8968974351882935
Validation loss: 1.8167104464705273

Epoch: 6| Step: 13
Training loss: 0.41998016834259033
Validation loss: 1.9809736923504901

Epoch: 541| Step: 0
Training loss: 2.0216028690338135
Validation loss: 1.856759600741889

Epoch: 6| Step: 1
Training loss: 1.1035406589508057
Validation loss: 1.9834724600597093

Epoch: 6| Step: 2
Training loss: 1.0090662240982056
Validation loss: 1.8924465205079766

Epoch: 6| Step: 3
Training loss: 0.8516395092010498
Validation loss: 1.9465364768940916

Epoch: 6| Step: 4
Training loss: 0.6786965131759644
Validation loss: 2.017819050819643

Epoch: 6| Step: 5
Training loss: 1.1125473976135254
Validation loss: 1.9233814900921238

Epoch: 6| Step: 6
Training loss: 1.0493779182434082
Validation loss: 1.870023746644297

Epoch: 6| Step: 7
Training loss: 1.147873878479004
Validation loss: 1.9063334695754512

Epoch: 6| Step: 8
Training loss: 1.1461631059646606
Validation loss: 1.9867799897347727

Epoch: 6| Step: 9
Training loss: 0.7956146597862244
Validation loss: 1.884143985727782

Epoch: 6| Step: 10
Training loss: 1.039790391921997
Validation loss: 1.9377114054977254

Epoch: 6| Step: 11
Training loss: 1.4542288780212402
Validation loss: 1.9002062633473387

Epoch: 6| Step: 12
Training loss: 1.2086018323898315
Validation loss: 1.9247877341444775

Epoch: 6| Step: 13
Training loss: 0.7298227548599243
Validation loss: 1.8979335369602326

Epoch: 542| Step: 0
Training loss: 0.9312379360198975
Validation loss: 2.000898991861651

Epoch: 6| Step: 1
Training loss: 1.3861147165298462
Validation loss: 1.9342585327804729

Epoch: 6| Step: 2
Training loss: 1.0473661422729492
Validation loss: 1.9778056016532324

Epoch: 6| Step: 3
Training loss: 0.9792675375938416
Validation loss: 1.8912216322396391

Epoch: 6| Step: 4
Training loss: 0.6610438823699951
Validation loss: 1.9554936450014833

Epoch: 6| Step: 5
Training loss: 1.2563236951828003
Validation loss: 1.821527478515461

Epoch: 6| Step: 6
Training loss: 1.1579816341400146
Validation loss: 1.8141967019727152

Epoch: 6| Step: 7
Training loss: 1.041571021080017
Validation loss: 1.9519380523312477

Epoch: 6| Step: 8
Training loss: 1.2097172737121582
Validation loss: 1.8471468405057025

Epoch: 6| Step: 9
Training loss: 0.8912626504898071
Validation loss: 1.984742372266708

Epoch: 6| Step: 10
Training loss: 0.745496392250061
Validation loss: 1.8549537786873438

Epoch: 6| Step: 11
Training loss: 1.3108775615692139
Validation loss: 1.9841540628863918

Epoch: 6| Step: 12
Training loss: 1.2188485860824585
Validation loss: 1.8545695017742854

Epoch: 6| Step: 13
Training loss: 1.49486243724823
Validation loss: 1.9775444551180767

Epoch: 543| Step: 0
Training loss: 1.1679649353027344
Validation loss: 1.9238106486617879

Epoch: 6| Step: 1
Training loss: 1.6384645700454712
Validation loss: 1.9156201219045987

Epoch: 6| Step: 2
Training loss: 1.0363906621932983
Validation loss: 1.97035559146635

Epoch: 6| Step: 3
Training loss: 1.107168436050415
Validation loss: 1.953388524311845

Epoch: 6| Step: 4
Training loss: 1.004833698272705
Validation loss: 1.9650657946063625

Epoch: 6| Step: 5
Training loss: 1.3076252937316895
Validation loss: 1.875847399875682

Epoch: 6| Step: 6
Training loss: 1.085998296737671
Validation loss: 1.885670736271848

Epoch: 6| Step: 7
Training loss: 0.5759623646736145
Validation loss: 1.9265208475051387

Epoch: 6| Step: 8
Training loss: 0.7655702829360962
Validation loss: 1.935167089585335

Epoch: 6| Step: 9
Training loss: 1.1612358093261719
Validation loss: 1.8972041850448937

Epoch: 6| Step: 10
Training loss: 0.9937493205070496
Validation loss: 1.912792395519954

Epoch: 6| Step: 11
Training loss: 1.0998995304107666
Validation loss: 1.9169955586874357

Epoch: 6| Step: 12
Training loss: 0.6923865079879761
Validation loss: 1.9211724522293254

Epoch: 6| Step: 13
Training loss: 1.445945143699646
Validation loss: 1.9446266684480893

Epoch: 544| Step: 0
Training loss: 1.2570252418518066
Validation loss: 1.8568846865366864

Epoch: 6| Step: 1
Training loss: 0.9215584993362427
Validation loss: 1.9631357141720351

Epoch: 6| Step: 2
Training loss: 1.6046812534332275
Validation loss: 1.8638660523199266

Epoch: 6| Step: 3
Training loss: 0.9628301858901978
Validation loss: 1.9025964839484102

Epoch: 6| Step: 4
Training loss: 1.6128039360046387
Validation loss: 1.9425041855022471

Epoch: 6| Step: 5
Training loss: 0.8555096983909607
Validation loss: 1.9401938312797136

Epoch: 6| Step: 6
Training loss: 0.5401440858840942
Validation loss: 1.9362202562311643

Epoch: 6| Step: 7
Training loss: 0.75770103931427
Validation loss: 1.9173923538577171

Epoch: 6| Step: 8
Training loss: 1.0335466861724854
Validation loss: 1.8998000621795654

Epoch: 6| Step: 9
Training loss: 0.6854163408279419
Validation loss: 1.9235105578617384

Epoch: 6| Step: 10
Training loss: 0.8764562010765076
Validation loss: 1.9292613357625983

Epoch: 6| Step: 11
Training loss: 1.6735097169876099
Validation loss: 1.9199461834405058

Epoch: 6| Step: 12
Training loss: 0.992347002029419
Validation loss: 1.8588599338326404

Epoch: 6| Step: 13
Training loss: 1.0896403789520264
Validation loss: 1.879698912302653

Epoch: 545| Step: 0
Training loss: 1.0309275388717651
Validation loss: 1.9732022811007757

Epoch: 6| Step: 1
Training loss: 0.9846837520599365
Validation loss: 1.8611012479310394

Epoch: 6| Step: 2
Training loss: 0.9031333327293396
Validation loss: 1.9434874288497432

Epoch: 6| Step: 3
Training loss: 0.853249728679657
Validation loss: 1.8815848212088309

Epoch: 6| Step: 4
Training loss: 1.1481411457061768
Validation loss: 1.9704020779619935

Epoch: 6| Step: 5
Training loss: 0.8861013650894165
Validation loss: 1.9461120995142127

Epoch: 6| Step: 6
Training loss: 0.7016072273254395
Validation loss: 1.8834775750355055

Epoch: 6| Step: 7
Training loss: 1.2881309986114502
Validation loss: 1.8835083605140768

Epoch: 6| Step: 8
Training loss: 1.1613669395446777
Validation loss: 1.9818098237437587

Epoch: 6| Step: 9
Training loss: 1.1881299018859863
Validation loss: 1.8974110669987176

Epoch: 6| Step: 10
Training loss: 0.918892502784729
Validation loss: 1.8783145989141157

Epoch: 6| Step: 11
Training loss: 1.1601628065109253
Validation loss: 1.8785115262513519

Epoch: 6| Step: 12
Training loss: 1.1747748851776123
Validation loss: 1.943073857215143

Epoch: 6| Step: 13
Training loss: 1.4781718254089355
Validation loss: 1.9230708793927265

Epoch: 546| Step: 0
Training loss: 0.875921368598938
Validation loss: 1.914924249854139

Epoch: 6| Step: 1
Training loss: 0.8144393563270569
Validation loss: 1.8889486610248525

Epoch: 6| Step: 2
Training loss: 1.1395490169525146
Validation loss: 1.812129016845457

Epoch: 6| Step: 3
Training loss: 0.9928298592567444
Validation loss: 1.9420311489412863

Epoch: 6| Step: 4
Training loss: 1.4632428884506226
Validation loss: 1.9265703129512008

Epoch: 6| Step: 5
Training loss: 1.6107150316238403
Validation loss: 1.90748917928306

Epoch: 6| Step: 6
Training loss: 1.1421153545379639
Validation loss: 1.8563663895412157

Epoch: 6| Step: 7
Training loss: 0.7888689041137695
Validation loss: 1.947029790570659

Epoch: 6| Step: 8
Training loss: 0.7942945957183838
Validation loss: 1.8769173724676973

Epoch: 6| Step: 9
Training loss: 1.005402684211731
Validation loss: 1.883898711973621

Epoch: 6| Step: 10
Training loss: 0.9048858880996704
Validation loss: 1.9348242821231965

Epoch: 6| Step: 11
Training loss: 1.2587708234786987
Validation loss: 1.897048714340374

Epoch: 6| Step: 12
Training loss: 0.9400570392608643
Validation loss: 1.8722595296880251

Epoch: 6| Step: 13
Training loss: 0.5424864292144775
Validation loss: 1.963962007594365

Epoch: 547| Step: 0
Training loss: 0.8749768733978271
Validation loss: 1.917950202060002

Epoch: 6| Step: 1
Training loss: 0.9723086953163147
Validation loss: 1.9465766183791622

Epoch: 6| Step: 2
Training loss: 0.833069384098053
Validation loss: 1.9088452375063332

Epoch: 6| Step: 3
Training loss: 1.0264447927474976
Validation loss: 1.9608434848887946

Epoch: 6| Step: 4
Training loss: 0.9109966158866882
Validation loss: 1.929133810022826

Epoch: 6| Step: 5
Training loss: 1.1819188594818115
Validation loss: 1.975761644301876

Epoch: 6| Step: 6
Training loss: 1.1141918897628784
Validation loss: 1.9038527716872513

Epoch: 6| Step: 7
Training loss: 1.1310954093933105
Validation loss: 1.8193776902332102

Epoch: 6| Step: 8
Training loss: 1.3694217205047607
Validation loss: 1.9393515189488728

Epoch: 6| Step: 9
Training loss: 1.1311874389648438
Validation loss: 1.910509596588791

Epoch: 6| Step: 10
Training loss: 1.0906797647476196
Validation loss: 1.845548814342868

Epoch: 6| Step: 11
Training loss: 0.8066521883010864
Validation loss: 1.8321007387612456

Epoch: 6| Step: 12
Training loss: 1.2301664352416992
Validation loss: 1.9090759369634813

Epoch: 6| Step: 13
Training loss: 1.906524419784546
Validation loss: 1.9246625464449647

Epoch: 548| Step: 0
Training loss: 0.7125939130783081
Validation loss: 1.8509603277329476

Epoch: 6| Step: 1
Training loss: 0.8911986351013184
Validation loss: 1.849125546793784

Epoch: 6| Step: 2
Training loss: 1.0128015279769897
Validation loss: 1.846524437268575

Epoch: 6| Step: 3
Training loss: 1.3522357940673828
Validation loss: 1.8894165049317062

Epoch: 6| Step: 4
Training loss: 1.399743914604187
Validation loss: 1.9475130868214432

Epoch: 6| Step: 5
Training loss: 0.6962584853172302
Validation loss: 1.8275983820679367

Epoch: 6| Step: 6
Training loss: 1.3563668727874756
Validation loss: 1.880682772205722

Epoch: 6| Step: 7
Training loss: 1.2653886079788208
Validation loss: 1.915203817429081

Epoch: 6| Step: 8
Training loss: 0.7458012104034424
Validation loss: 1.9681101101700977

Epoch: 6| Step: 9
Training loss: 0.7511646747589111
Validation loss: 1.918839721269505

Epoch: 6| Step: 10
Training loss: 1.3488349914550781
Validation loss: 1.9425171652147848

Epoch: 6| Step: 11
Training loss: 0.7962287068367004
Validation loss: 1.8707775685095018

Epoch: 6| Step: 12
Training loss: 1.1308255195617676
Validation loss: 2.0478484784403155

Epoch: 6| Step: 13
Training loss: 1.078993797302246
Validation loss: 1.9731467026536182

Epoch: 549| Step: 0
Training loss: 0.9539728760719299
Validation loss: 1.919395557013891

Epoch: 6| Step: 1
Training loss: 1.2954996824264526
Validation loss: 1.9745493678636448

Epoch: 6| Step: 2
Training loss: 1.4529671669006348
Validation loss: 1.9704359321184055

Epoch: 6| Step: 3
Training loss: 1.1433597803115845
Validation loss: 1.8976224045599661

Epoch: 6| Step: 4
Training loss: 1.012763500213623
Validation loss: 1.971873491041122

Epoch: 6| Step: 5
Training loss: 0.9574421644210815
Validation loss: 1.961195461211666

Epoch: 6| Step: 6
Training loss: 0.645521879196167
Validation loss: 1.9032782111116635

Epoch: 6| Step: 7
Training loss: 1.007135033607483
Validation loss: 1.8706907174920524

Epoch: 6| Step: 8
Training loss: 1.7566733360290527
Validation loss: 1.917335238507999

Epoch: 6| Step: 9
Training loss: 0.8066062927246094
Validation loss: 1.9147750267418482

Epoch: 6| Step: 10
Training loss: 1.1856716871261597
Validation loss: 1.861615224551129

Epoch: 6| Step: 11
Training loss: 1.2394415140151978
Validation loss: 1.7780946377784974

Epoch: 6| Step: 12
Training loss: 0.7628085613250732
Validation loss: 1.843147736723705

Epoch: 6| Step: 13
Training loss: 0.857017993927002
Validation loss: 1.8534951568931661

Epoch: 550| Step: 0
Training loss: 0.9730316400527954
Validation loss: 1.852163096909882

Epoch: 6| Step: 1
Training loss: 1.040426254272461
Validation loss: 1.8805532275989492

Epoch: 6| Step: 2
Training loss: 0.7026859521865845
Validation loss: 1.8498691205055482

Epoch: 6| Step: 3
Training loss: 1.0762842893600464
Validation loss: 1.8431713299084735

Epoch: 6| Step: 4
Training loss: 1.333324670791626
Validation loss: 1.8666271253298687

Epoch: 6| Step: 5
Training loss: 0.8302838802337646
Validation loss: 1.8530171878876225

Epoch: 6| Step: 6
Training loss: 1.8365164995193481
Validation loss: 1.864100617747153

Epoch: 6| Step: 7
Training loss: 1.0334620475769043
Validation loss: 1.9215233351594658

Epoch: 6| Step: 8
Training loss: 0.7480138540267944
Validation loss: 1.8863501241130214

Epoch: 6| Step: 9
Training loss: 0.7504538297653198
Validation loss: 1.8055956799496886

Epoch: 6| Step: 10
Training loss: 1.4778943061828613
Validation loss: 1.9707522699909825

Epoch: 6| Step: 11
Training loss: 0.6064856052398682
Validation loss: 1.845237881906571

Epoch: 6| Step: 12
Training loss: 1.038231611251831
Validation loss: 1.9252703394941104

Epoch: 6| Step: 13
Training loss: 1.3313885927200317
Validation loss: 1.8918979475575108

Epoch: 551| Step: 0
Training loss: 1.441546082496643
Validation loss: 1.8965762751076811

Epoch: 6| Step: 1
Training loss: 1.7326586246490479
Validation loss: 1.9224078988516202

Epoch: 6| Step: 2
Training loss: 0.8635269403457642
Validation loss: 1.966471505421464

Epoch: 6| Step: 3
Training loss: 0.8257386684417725
Validation loss: 1.876200588800574

Epoch: 6| Step: 4
Training loss: 0.6530255079269409
Validation loss: 1.9396055411267024

Epoch: 6| Step: 5
Training loss: 1.043643593788147
Validation loss: 1.8480777458478046

Epoch: 6| Step: 6
Training loss: 0.9666728973388672
Validation loss: 1.8754755514924244

Epoch: 6| Step: 7
Training loss: 0.6776138544082642
Validation loss: 1.8378432181573683

Epoch: 6| Step: 8
Training loss: 1.3605096340179443
Validation loss: 1.8581049801200948

Epoch: 6| Step: 9
Training loss: 1.5228992700576782
Validation loss: 1.8241437955569195

Epoch: 6| Step: 10
Training loss: 0.8693879246711731
Validation loss: 1.869816639090097

Epoch: 6| Step: 11
Training loss: 0.866689145565033
Validation loss: 1.8801118404634538

Epoch: 6| Step: 12
Training loss: 1.0047616958618164
Validation loss: 1.8395079617859216

Epoch: 6| Step: 13
Training loss: 1.0844931602478027
Validation loss: 1.8657176084415887

Epoch: 552| Step: 0
Training loss: 0.6998741626739502
Validation loss: 1.8551768384953982

Epoch: 6| Step: 1
Training loss: 1.02083420753479
Validation loss: 1.8669276224669589

Epoch: 6| Step: 2
Training loss: 0.8890427350997925
Validation loss: 1.8759342624295143

Epoch: 6| Step: 3
Training loss: 1.2557882070541382
Validation loss: 1.9486726394263647

Epoch: 6| Step: 4
Training loss: 1.1157430410385132
Validation loss: 1.930483756526824

Epoch: 6| Step: 5
Training loss: 1.1080522537231445
Validation loss: 1.8834552700801561

Epoch: 6| Step: 6
Training loss: 0.962073564529419
Validation loss: 1.8916539351145427

Epoch: 6| Step: 7
Training loss: 0.9890938401222229
Validation loss: 1.9212545271842711

Epoch: 6| Step: 8
Training loss: 0.5858384966850281
Validation loss: 1.8517142047164261

Epoch: 6| Step: 9
Training loss: 1.0389988422393799
Validation loss: 1.8286330341010966

Epoch: 6| Step: 10
Training loss: 1.810943603515625
Validation loss: 1.8873102280401415

Epoch: 6| Step: 11
Training loss: 1.1085820198059082
Validation loss: 1.8832929288187334

Epoch: 6| Step: 12
Training loss: 1.315180778503418
Validation loss: 1.8733675966980636

Epoch: 6| Step: 13
Training loss: 1.5989201068878174
Validation loss: 1.8888152081479308

Epoch: 553| Step: 0
Training loss: 1.0190906524658203
Validation loss: 1.77558982628648

Epoch: 6| Step: 1
Training loss: 0.9764221906661987
Validation loss: 1.9179576122632591

Epoch: 6| Step: 2
Training loss: 0.9308212995529175
Validation loss: 1.9206393534137356

Epoch: 6| Step: 3
Training loss: 1.176971673965454
Validation loss: 1.890342862375321

Epoch: 6| Step: 4
Training loss: 1.613521695137024
Validation loss: 1.904139623847059

Epoch: 6| Step: 5
Training loss: 1.1111688613891602
Validation loss: 1.91731813902496

Epoch: 6| Step: 6
Training loss: 0.6656761765480042
Validation loss: 1.9783251259916572

Epoch: 6| Step: 7
Training loss: 1.0045139789581299
Validation loss: 1.9169186058864798

Epoch: 6| Step: 8
Training loss: 0.9638084769248962
Validation loss: 1.8254186908404033

Epoch: 6| Step: 9
Training loss: 0.99632728099823
Validation loss: 1.9443751176198323

Epoch: 6| Step: 10
Training loss: 0.5837319493293762
Validation loss: 1.9764117797215779

Epoch: 6| Step: 11
Training loss: 1.3055834770202637
Validation loss: 1.943748071629514

Epoch: 6| Step: 12
Training loss: 0.8711698055267334
Validation loss: 1.9094440552496141

Epoch: 6| Step: 13
Training loss: 0.9950053691864014
Validation loss: 1.8909993697238225

Epoch: 554| Step: 0
Training loss: 1.3808720111846924
Validation loss: 1.865669681179908

Epoch: 6| Step: 1
Training loss: 1.1130993366241455
Validation loss: 1.891206201686654

Epoch: 6| Step: 2
Training loss: 1.1492230892181396
Validation loss: 1.8692984709175684

Epoch: 6| Step: 3
Training loss: 0.8461481332778931
Validation loss: 1.91871093421854

Epoch: 6| Step: 4
Training loss: 1.1992173194885254
Validation loss: 1.8176273940711893

Epoch: 6| Step: 5
Training loss: 0.8505123853683472
Validation loss: 1.8694137847551735

Epoch: 6| Step: 6
Training loss: 0.948184609413147
Validation loss: 1.8626150725990214

Epoch: 6| Step: 7
Training loss: 1.0032637119293213
Validation loss: 1.8294145291851414

Epoch: 6| Step: 8
Training loss: 0.9789862632751465
Validation loss: 1.8903237542798441

Epoch: 6| Step: 9
Training loss: 0.8445922136306763
Validation loss: 1.9288122948779856

Epoch: 6| Step: 10
Training loss: 1.0676465034484863
Validation loss: 1.9499585474691083

Epoch: 6| Step: 11
Training loss: 0.8672927618026733
Validation loss: 1.9447805881500244

Epoch: 6| Step: 12
Training loss: 0.8675433397293091
Validation loss: 1.8938173324831071

Epoch: 6| Step: 13
Training loss: 1.156965732574463
Validation loss: 1.866221575326817

Epoch: 555| Step: 0
Training loss: 0.8955147862434387
Validation loss: 1.890844257928992

Epoch: 6| Step: 1
Training loss: 0.9772595167160034
Validation loss: 1.9478755509981545

Epoch: 6| Step: 2
Training loss: 1.665271520614624
Validation loss: 1.893146155982889

Epoch: 6| Step: 3
Training loss: 0.8153901100158691
Validation loss: 1.91989771140519

Epoch: 6| Step: 4
Training loss: 1.6156561374664307
Validation loss: 1.8586393299923147

Epoch: 6| Step: 5
Training loss: 0.7997803688049316
Validation loss: 1.8570792841654953

Epoch: 6| Step: 6
Training loss: 1.0408458709716797
Validation loss: 1.9066727751044816

Epoch: 6| Step: 7
Training loss: 0.9884674549102783
Validation loss: 1.9353244599475656

Epoch: 6| Step: 8
Training loss: 0.8746012449264526
Validation loss: 1.9316721423979728

Epoch: 6| Step: 9
Training loss: 1.0419905185699463
Validation loss: 1.8771547963542323

Epoch: 6| Step: 10
Training loss: 1.282906174659729
Validation loss: 1.8894233524158437

Epoch: 6| Step: 11
Training loss: 0.6002788543701172
Validation loss: 1.8609129549354635

Epoch: 6| Step: 12
Training loss: 1.5593745708465576
Validation loss: 1.9008392787748767

Epoch: 6| Step: 13
Training loss: 0.6536476612091064
Validation loss: 1.7908106926948792

Epoch: 556| Step: 0
Training loss: 0.8854449987411499
Validation loss: 1.9223151527425295

Epoch: 6| Step: 1
Training loss: 0.9699670672416687
Validation loss: 1.9239043779270624

Epoch: 6| Step: 2
Training loss: 1.1187618970870972
Validation loss: 1.9291388206584479

Epoch: 6| Step: 3
Training loss: 0.9325497150421143
Validation loss: 1.9675957528493737

Epoch: 6| Step: 4
Training loss: 0.8654547929763794
Validation loss: 1.958433835737167

Epoch: 6| Step: 5
Training loss: 1.3464994430541992
Validation loss: 1.9929895247182539

Epoch: 6| Step: 6
Training loss: 1.3693547248840332
Validation loss: 1.955953372422085

Epoch: 6| Step: 7
Training loss: 0.47876548767089844
Validation loss: 1.986232425576897

Epoch: 6| Step: 8
Training loss: 1.0381580591201782
Validation loss: 1.9629725615183513

Epoch: 6| Step: 9
Training loss: 1.6246931552886963
Validation loss: 1.9626348069919053

Epoch: 6| Step: 10
Training loss: 0.9396836757659912
Validation loss: 2.004654306237416

Epoch: 6| Step: 11
Training loss: 1.35261869430542
Validation loss: 1.9392989655976653

Epoch: 6| Step: 12
Training loss: 0.9142143726348877
Validation loss: 1.9125878400700067

Epoch: 6| Step: 13
Training loss: 0.997990608215332
Validation loss: 1.864414684234127

Epoch: 557| Step: 0
Training loss: 1.107567310333252
Validation loss: 1.945492890573317

Epoch: 6| Step: 1
Training loss: 1.0108617544174194
Validation loss: 1.8377897636864775

Epoch: 6| Step: 2
Training loss: 1.0617728233337402
Validation loss: 1.8401254787239978

Epoch: 6| Step: 3
Training loss: 1.2943778038024902
Validation loss: 1.892650301738452

Epoch: 6| Step: 4
Training loss: 1.3031902313232422
Validation loss: 1.8842228458773704

Epoch: 6| Step: 5
Training loss: 1.6093093156814575
Validation loss: 1.8148239697179487

Epoch: 6| Step: 6
Training loss: 0.9658308625221252
Validation loss: 1.9231901091914023

Epoch: 6| Step: 7
Training loss: 0.8004682660102844
Validation loss: 1.891368721121101

Epoch: 6| Step: 8
Training loss: 0.9042233228683472
Validation loss: 1.8865897501668623

Epoch: 6| Step: 9
Training loss: 0.6550546884536743
Validation loss: 1.8112366455857472

Epoch: 6| Step: 10
Training loss: 1.1515957117080688
Validation loss: 1.908767443831249

Epoch: 6| Step: 11
Training loss: 0.9190163016319275
Validation loss: 1.8811041924261278

Epoch: 6| Step: 12
Training loss: 1.3048937320709229
Validation loss: 1.927995381816741

Epoch: 6| Step: 13
Training loss: 0.5314148664474487
Validation loss: 1.9190173341381935

Epoch: 558| Step: 0
Training loss: 0.7259387969970703
Validation loss: 1.9697185690684984

Epoch: 6| Step: 1
Training loss: 1.2172880172729492
Validation loss: 1.9496513348753735

Epoch: 6| Step: 2
Training loss: 0.8581352233886719
Validation loss: 1.933965798347227

Epoch: 6| Step: 3
Training loss: 1.4585254192352295
Validation loss: 1.9946699347547305

Epoch: 6| Step: 4
Training loss: 0.6943008303642273
Validation loss: 1.9124198818719516

Epoch: 6| Step: 5
Training loss: 0.9342825412750244
Validation loss: 2.0098110629666235

Epoch: 6| Step: 6
Training loss: 1.0187734365463257
Validation loss: 1.9431790113449097

Epoch: 6| Step: 7
Training loss: 0.9821721315383911
Validation loss: 1.9087493317101591

Epoch: 6| Step: 8
Training loss: 0.6175937652587891
Validation loss: 1.8608178515588083

Epoch: 6| Step: 9
Training loss: 1.086995244026184
Validation loss: 1.8627155647482923

Epoch: 6| Step: 10
Training loss: 1.2233057022094727
Validation loss: 1.8657052516937256

Epoch: 6| Step: 11
Training loss: 0.9743108749389648
Validation loss: 1.8553709189097087

Epoch: 6| Step: 12
Training loss: 1.066892385482788
Validation loss: 1.834706155202722

Epoch: 6| Step: 13
Training loss: 1.2803921699523926
Validation loss: 1.8822511908828572

Epoch: 559| Step: 0
Training loss: 1.3079702854156494
Validation loss: 1.9252157800941057

Epoch: 6| Step: 1
Training loss: 1.0935670137405396
Validation loss: 1.843992397349368

Epoch: 6| Step: 2
Training loss: 1.1305325031280518
Validation loss: 1.9141467860949937

Epoch: 6| Step: 3
Training loss: 1.0875670909881592
Validation loss: 1.8688478751849102

Epoch: 6| Step: 4
Training loss: 0.685234546661377
Validation loss: 1.836437584251486

Epoch: 6| Step: 5
Training loss: 1.690960168838501
Validation loss: 1.928785624042634

Epoch: 6| Step: 6
Training loss: 0.7051534056663513
Validation loss: 1.9190214346813899

Epoch: 6| Step: 7
Training loss: 0.8908206224441528
Validation loss: 1.9106348919612106

Epoch: 6| Step: 8
Training loss: 0.7885463237762451
Validation loss: 1.9457136482320807

Epoch: 6| Step: 9
Training loss: 1.356245994567871
Validation loss: 1.829468560475175

Epoch: 6| Step: 10
Training loss: 1.1973717212677002
Validation loss: 1.9052063220290727

Epoch: 6| Step: 11
Training loss: 0.6568800210952759
Validation loss: 1.9217464911040438

Epoch: 6| Step: 12
Training loss: 1.260383129119873
Validation loss: 1.8700085134916409

Epoch: 6| Step: 13
Training loss: 0.8483653664588928
Validation loss: 1.860673810846062

Epoch: 560| Step: 0
Training loss: 0.7493757009506226
Validation loss: 1.8999554957112958

Epoch: 6| Step: 1
Training loss: 1.0702965259552002
Validation loss: 1.9869196273947274

Epoch: 6| Step: 2
Training loss: 0.953700602054596
Validation loss: 1.95529205055647

Epoch: 6| Step: 3
Training loss: 1.0367413759231567
Validation loss: 2.005509579053489

Epoch: 6| Step: 4
Training loss: 1.1329295635223389
Validation loss: 1.9125314451033069

Epoch: 6| Step: 5
Training loss: 1.0465490818023682
Validation loss: 1.8661262207133795

Epoch: 6| Step: 6
Training loss: 1.2643064260482788
Validation loss: 1.9699794964123798

Epoch: 6| Step: 7
Training loss: 0.43562746047973633
Validation loss: 1.9404051150045087

Epoch: 6| Step: 8
Training loss: 1.2248053550720215
Validation loss: 1.9245801792349866

Epoch: 6| Step: 9
Training loss: 1.1930100917816162
Validation loss: 1.8841672866575179

Epoch: 6| Step: 10
Training loss: 1.133518934249878
Validation loss: 1.8881816300012733

Epoch: 6| Step: 11
Training loss: 0.9116230010986328
Validation loss: 1.874876186411868

Epoch: 6| Step: 12
Training loss: 1.4150049686431885
Validation loss: 1.8223441416217434

Epoch: 6| Step: 13
Training loss: 0.4394340217113495
Validation loss: 1.8952253428838586

Epoch: 561| Step: 0
Training loss: 1.1156939268112183
Validation loss: 1.798885340331703

Epoch: 6| Step: 1
Training loss: 0.647243857383728
Validation loss: 1.904298549057335

Epoch: 6| Step: 2
Training loss: 1.5508637428283691
Validation loss: 1.9576824685578704

Epoch: 6| Step: 3
Training loss: 0.9154216051101685
Validation loss: 1.8580752598342074

Epoch: 6| Step: 4
Training loss: 1.1459226608276367
Validation loss: 1.8988210796028056

Epoch: 6| Step: 5
Training loss: 1.2152295112609863
Validation loss: 1.9033426879554667

Epoch: 6| Step: 6
Training loss: 1.2107013463974
Validation loss: 1.9361271473669237

Epoch: 6| Step: 7
Training loss: 0.9466103315353394
Validation loss: 1.9287302032593758

Epoch: 6| Step: 8
Training loss: 0.6831026077270508
Validation loss: 1.9719937514233332

Epoch: 6| Step: 9
Training loss: 1.1362520456314087
Validation loss: 1.925315822324445

Epoch: 6| Step: 10
Training loss: 0.9969772100448608
Validation loss: 1.9471061178432998

Epoch: 6| Step: 11
Training loss: 0.6206644177436829
Validation loss: 1.8171862991907264

Epoch: 6| Step: 12
Training loss: 0.8092700242996216
Validation loss: 1.9668745943295058

Epoch: 6| Step: 13
Training loss: 1.154542088508606
Validation loss: 1.9032742925869521

Epoch: 562| Step: 0
Training loss: 1.215261459350586
Validation loss: 1.9840583057813748

Epoch: 6| Step: 1
Training loss: 0.8904085159301758
Validation loss: 1.8708961291979718

Epoch: 6| Step: 2
Training loss: 0.6883076429367065
Validation loss: 1.885185198117328

Epoch: 6| Step: 3
Training loss: 1.1275840997695923
Validation loss: 1.8887127689135972

Epoch: 6| Step: 4
Training loss: 0.9301397204399109
Validation loss: 1.904874255580287

Epoch: 6| Step: 5
Training loss: 0.9410592317581177
Validation loss: 1.8543675907196537

Epoch: 6| Step: 6
Training loss: 0.7990275025367737
Validation loss: 1.8325551363729662

Epoch: 6| Step: 7
Training loss: 1.1395164728164673
Validation loss: 1.9353200620220554

Epoch: 6| Step: 8
Training loss: 1.146775484085083
Validation loss: 1.887626818431321

Epoch: 6| Step: 9
Training loss: 1.0553481578826904
Validation loss: 1.9191956084261659

Epoch: 6| Step: 10
Training loss: 1.212645411491394
Validation loss: 1.839976461984778

Epoch: 6| Step: 11
Training loss: 1.2728214263916016
Validation loss: 1.8891980853132022

Epoch: 6| Step: 12
Training loss: 1.0255985260009766
Validation loss: 1.9495105666498984

Epoch: 6| Step: 13
Training loss: 0.9995436072349548
Validation loss: 1.9333440872930712

Epoch: 563| Step: 0
Training loss: 0.9093466997146606
Validation loss: 1.9047403245843866

Epoch: 6| Step: 1
Training loss: 1.2677873373031616
Validation loss: 1.8934678082825036

Epoch: 6| Step: 2
Training loss: 0.5569753646850586
Validation loss: 1.9464263864742812

Epoch: 6| Step: 3
Training loss: 1.1255438327789307
Validation loss: 1.8535988023204188

Epoch: 6| Step: 4
Training loss: 0.9031776189804077
Validation loss: 1.9254311156529251

Epoch: 6| Step: 5
Training loss: 1.1206992864608765
Validation loss: 1.8968275375263666

Epoch: 6| Step: 6
Training loss: 1.0825411081314087
Validation loss: 1.8863236250415925

Epoch: 6| Step: 7
Training loss: 0.9125232696533203
Validation loss: 1.8415479954852854

Epoch: 6| Step: 8
Training loss: 1.2001478672027588
Validation loss: 1.9145255063169746

Epoch: 6| Step: 9
Training loss: 1.1866981983184814
Validation loss: 1.8408977793109031

Epoch: 6| Step: 10
Training loss: 1.2362967729568481
Validation loss: 1.8476224060981505

Epoch: 6| Step: 11
Training loss: 0.9975506663322449
Validation loss: 1.9683995028977752

Epoch: 6| Step: 12
Training loss: 0.9989311695098877
Validation loss: 1.874049396925075

Epoch: 6| Step: 13
Training loss: 1.3026210069656372
Validation loss: 1.9231141690284974

Epoch: 564| Step: 0
Training loss: 0.9890854358673096
Validation loss: 1.850477748019721

Epoch: 6| Step: 1
Training loss: 0.9855141639709473
Validation loss: 1.9441975701239802

Epoch: 6| Step: 2
Training loss: 0.9272550344467163
Validation loss: 1.8848960937992219

Epoch: 6| Step: 3
Training loss: 0.8284323215484619
Validation loss: 1.8456341720396472

Epoch: 6| Step: 4
Training loss: 1.8233380317687988
Validation loss: 1.8932788910404328

Epoch: 6| Step: 5
Training loss: 0.9488382339477539
Validation loss: 1.9600624615146267

Epoch: 6| Step: 6
Training loss: 1.4055249691009521
Validation loss: 1.8643537964872134

Epoch: 6| Step: 7
Training loss: 1.1414567232131958
Validation loss: 1.926533010698134

Epoch: 6| Step: 8
Training loss: 1.0294773578643799
Validation loss: 1.9502969941785258

Epoch: 6| Step: 9
Training loss: 0.7444795370101929
Validation loss: 1.9603676642141035

Epoch: 6| Step: 10
Training loss: 0.4842681288719177
Validation loss: 1.8849631278745589

Epoch: 6| Step: 11
Training loss: 1.2147750854492188
Validation loss: 1.8356308411526423

Epoch: 6| Step: 12
Training loss: 0.8377379775047302
Validation loss: 1.8903768152318976

Epoch: 6| Step: 13
Training loss: 0.9788157343864441
Validation loss: 1.8755511955548358

Epoch: 565| Step: 0
Training loss: 1.0891172885894775
Validation loss: 1.8772226610491354

Epoch: 6| Step: 1
Training loss: 1.0332626104354858
Validation loss: 1.8703353148634716

Epoch: 6| Step: 2
Training loss: 0.8406538963317871
Validation loss: 1.7806107920985068

Epoch: 6| Step: 3
Training loss: 0.7512304186820984
Validation loss: 1.9591258430993685

Epoch: 6| Step: 4
Training loss: 1.2566802501678467
Validation loss: 1.8990161188187138

Epoch: 6| Step: 5
Training loss: 0.6536180377006531
Validation loss: 1.9084765424010575

Epoch: 6| Step: 6
Training loss: 0.9804068207740784
Validation loss: 1.9078046224450553

Epoch: 6| Step: 7
Training loss: 0.8508424758911133
Validation loss: 1.937207321966848

Epoch: 6| Step: 8
Training loss: 1.2319048643112183
Validation loss: 1.8979482753302461

Epoch: 6| Step: 9
Training loss: 0.9306774735450745
Validation loss: 1.8990145716615903

Epoch: 6| Step: 10
Training loss: 1.1808133125305176
Validation loss: 1.8999383347008818

Epoch: 6| Step: 11
Training loss: 1.0303330421447754
Validation loss: 1.8649836970913796

Epoch: 6| Step: 12
Training loss: 1.138904094696045
Validation loss: 1.8950225589095906

Epoch: 6| Step: 13
Training loss: 0.7833863496780396
Validation loss: 1.8788175441885506

Epoch: 566| Step: 0
Training loss: 0.6663755774497986
Validation loss: 1.8612119202972741

Epoch: 6| Step: 1
Training loss: 0.7863103151321411
Validation loss: 1.9342444763388684

Epoch: 6| Step: 2
Training loss: 1.1738834381103516
Validation loss: 1.8819268723969818

Epoch: 6| Step: 3
Training loss: 1.3469197750091553
Validation loss: 1.8700172362789031

Epoch: 6| Step: 4
Training loss: 0.8737860321998596
Validation loss: 1.8601105187528877

Epoch: 6| Step: 5
Training loss: 1.2809683084487915
Validation loss: 1.9550307719938216

Epoch: 6| Step: 6
Training loss: 0.9880175590515137
Validation loss: 1.9124772125674832

Epoch: 6| Step: 7
Training loss: 0.7396913766860962
Validation loss: 1.9148579707709692

Epoch: 6| Step: 8
Training loss: 0.6482158899307251
Validation loss: 1.9081214986821657

Epoch: 6| Step: 9
Training loss: 1.0543491840362549
Validation loss: 1.9081586740350212

Epoch: 6| Step: 10
Training loss: 0.9135133028030396
Validation loss: 1.8186455029313282

Epoch: 6| Step: 11
Training loss: 1.4498016834259033
Validation loss: 1.832033859786167

Epoch: 6| Step: 12
Training loss: 1.2653639316558838
Validation loss: 1.8231272953812794

Epoch: 6| Step: 13
Training loss: 1.200294017791748
Validation loss: 1.84342868866459

Epoch: 567| Step: 0
Training loss: 0.8659465312957764
Validation loss: 1.8504491134356427

Epoch: 6| Step: 1
Training loss: 1.0352908372879028
Validation loss: 1.8639980452035063

Epoch: 6| Step: 2
Training loss: 0.7959924936294556
Validation loss: 1.8513773897642731

Epoch: 6| Step: 3
Training loss: 0.8486034274101257
Validation loss: 1.882654316963688

Epoch: 6| Step: 4
Training loss: 0.9340235590934753
Validation loss: 1.8521774122791905

Epoch: 6| Step: 5
Training loss: 1.276770830154419
Validation loss: 1.841412805741833

Epoch: 6| Step: 6
Training loss: 1.149244785308838
Validation loss: 1.9001381333156298

Epoch: 6| Step: 7
Training loss: 1.0448839664459229
Validation loss: 1.9075246882695023

Epoch: 6| Step: 8
Training loss: 1.088632345199585
Validation loss: 1.826655166123503

Epoch: 6| Step: 9
Training loss: 1.5349106788635254
Validation loss: 1.8947372846705939

Epoch: 6| Step: 10
Training loss: 0.9093029499053955
Validation loss: 1.9303034492718276

Epoch: 6| Step: 11
Training loss: 0.9467946290969849
Validation loss: 1.8067973018974386

Epoch: 6| Step: 12
Training loss: 0.7654910087585449
Validation loss: 1.9112937988773469

Epoch: 6| Step: 13
Training loss: 0.932873010635376
Validation loss: 1.8345716589240617

Epoch: 568| Step: 0
Training loss: 0.6776678562164307
Validation loss: 1.8992002394891554

Epoch: 6| Step: 1
Training loss: 1.0471746921539307
Validation loss: 1.9756795385832429

Epoch: 6| Step: 2
Training loss: 1.0886064767837524
Validation loss: 1.8983522153669787

Epoch: 6| Step: 3
Training loss: 0.6204352974891663
Validation loss: 1.9592783630535167

Epoch: 6| Step: 4
Training loss: 0.8082007169723511
Validation loss: 1.9180587607045327

Epoch: 6| Step: 5
Training loss: 1.0548487901687622
Validation loss: 1.907299921076785

Epoch: 6| Step: 6
Training loss: 1.0118558406829834
Validation loss: 1.9407557364433043

Epoch: 6| Step: 7
Training loss: 1.2951382398605347
Validation loss: 1.7906422640687676

Epoch: 6| Step: 8
Training loss: 0.9252008199691772
Validation loss: 1.9519879279598114

Epoch: 6| Step: 9
Training loss: 0.830380916595459
Validation loss: 1.9399710137356994

Epoch: 6| Step: 10
Training loss: 0.9537320137023926
Validation loss: 1.8937691104027532

Epoch: 6| Step: 11
Training loss: 1.0987377166748047
Validation loss: 1.9140108477684759

Epoch: 6| Step: 12
Training loss: 1.4306925535202026
Validation loss: 1.8707060326812088

Epoch: 6| Step: 13
Training loss: 1.3350473642349243
Validation loss: 1.8743209761957969

Epoch: 569| Step: 0
Training loss: 0.5180650353431702
Validation loss: 1.8705034563618321

Epoch: 6| Step: 1
Training loss: 0.6639655232429504
Validation loss: 1.908130298378647

Epoch: 6| Step: 2
Training loss: 0.9884178042411804
Validation loss: 1.8922243682287072

Epoch: 6| Step: 3
Training loss: 1.5984457731246948
Validation loss: 1.8972453122497888

Epoch: 6| Step: 4
Training loss: 0.9221388101577759
Validation loss: 1.8357084374273978

Epoch: 6| Step: 5
Training loss: 0.8037823438644409
Validation loss: 1.8886619050015685

Epoch: 6| Step: 6
Training loss: 1.1626977920532227
Validation loss: 1.7955540892898396

Epoch: 6| Step: 7
Training loss: 1.1313503980636597
Validation loss: 1.8650186087495537

Epoch: 6| Step: 8
Training loss: 1.0053924322128296
Validation loss: 1.9246552657055598

Epoch: 6| Step: 9
Training loss: 0.7022327184677124
Validation loss: 1.8321755381040676

Epoch: 6| Step: 10
Training loss: 1.2948274612426758
Validation loss: 1.8230515308277582

Epoch: 6| Step: 11
Training loss: 1.013520359992981
Validation loss: 1.9038274980360461

Epoch: 6| Step: 12
Training loss: 1.240262746810913
Validation loss: 1.91749192566

Epoch: 6| Step: 13
Training loss: 0.377437561750412
Validation loss: 1.9463174599473194

Epoch: 570| Step: 0
Training loss: 0.7817909717559814
Validation loss: 1.8213885650839856

Epoch: 6| Step: 1
Training loss: 0.9851639270782471
Validation loss: 1.9301269913232455

Epoch: 6| Step: 2
Training loss: 1.5323753356933594
Validation loss: 1.8327855615205662

Epoch: 6| Step: 3
Training loss: 1.0384635925292969
Validation loss: 1.851199883286671

Epoch: 6| Step: 4
Training loss: 0.8962869644165039
Validation loss: 1.7906566114835842

Epoch: 6| Step: 5
Training loss: 1.0738286972045898
Validation loss: 1.874719532587195

Epoch: 6| Step: 6
Training loss: 1.056532382965088
Validation loss: 1.815009073544574

Epoch: 6| Step: 7
Training loss: 1.1114587783813477
Validation loss: 1.9251353689419326

Epoch: 6| Step: 8
Training loss: 0.9793825745582581
Validation loss: 1.8111421139009538

Epoch: 6| Step: 9
Training loss: 0.5988219976425171
Validation loss: 1.8837107304603822

Epoch: 6| Step: 10
Training loss: 1.3171274662017822
Validation loss: 1.8810687552216232

Epoch: 6| Step: 11
Training loss: 1.145098328590393
Validation loss: 1.8397590908952939

Epoch: 6| Step: 12
Training loss: 0.5907054543495178
Validation loss: 1.8254944278347878

Epoch: 6| Step: 13
Training loss: 0.7315157055854797
Validation loss: 1.8292949943132297

Epoch: 571| Step: 0
Training loss: 1.3319860696792603
Validation loss: 1.8942464115799114

Epoch: 6| Step: 1
Training loss: 0.7795038819313049
Validation loss: 1.9556349195459837

Epoch: 6| Step: 2
Training loss: 0.9396181702613831
Validation loss: 1.88676316507401

Epoch: 6| Step: 3
Training loss: 0.6691696643829346
Validation loss: 1.8754922651475476

Epoch: 6| Step: 4
Training loss: 0.9801028370857239
Validation loss: 1.8840190774650984

Epoch: 6| Step: 5
Training loss: 1.0946383476257324
Validation loss: 1.9318333889848442

Epoch: 6| Step: 6
Training loss: 1.2187563180923462
Validation loss: 1.8870348263812322

Epoch: 6| Step: 7
Training loss: 1.361616849899292
Validation loss: 1.9053453412107242

Epoch: 6| Step: 8
Training loss: 1.3794995546340942
Validation loss: 1.8722808155962216

Epoch: 6| Step: 9
Training loss: 1.0034563541412354
Validation loss: 1.8952534403852237

Epoch: 6| Step: 10
Training loss: 0.7058277130126953
Validation loss: 1.8315078635369577

Epoch: 6| Step: 11
Training loss: 0.8561242818832397
Validation loss: 1.8697440854964718

Epoch: 6| Step: 12
Training loss: 0.8690589070320129
Validation loss: 1.7778825118977537

Epoch: 6| Step: 13
Training loss: 0.7673194408416748
Validation loss: 1.8969056734474756

Epoch: 572| Step: 0
Training loss: 0.9872483015060425
Validation loss: 1.8063867374133038

Epoch: 6| Step: 1
Training loss: 1.0972871780395508
Validation loss: 1.8562037547429402

Epoch: 6| Step: 2
Training loss: 0.892401933670044
Validation loss: 1.947373733725599

Epoch: 6| Step: 3
Training loss: 1.2578272819519043
Validation loss: 1.86761377831941

Epoch: 6| Step: 4
Training loss: 1.1415433883666992
Validation loss: 1.9238254959865282

Epoch: 6| Step: 5
Training loss: 1.2094676494598389
Validation loss: 1.954348453911402

Epoch: 6| Step: 6
Training loss: 0.6200748682022095
Validation loss: 1.9018108332028953

Epoch: 6| Step: 7
Training loss: 1.1858279705047607
Validation loss: 1.9505564141017135

Epoch: 6| Step: 8
Training loss: 1.1659820079803467
Validation loss: 1.916497758639756

Epoch: 6| Step: 9
Training loss: 1.5545223951339722
Validation loss: 1.9608942078005882

Epoch: 6| Step: 10
Training loss: 0.8442225456237793
Validation loss: 1.948694541890134

Epoch: 6| Step: 11
Training loss: 0.7033480405807495
Validation loss: 1.9356183493009178

Epoch: 6| Step: 12
Training loss: 0.9532708525657654
Validation loss: 1.9271042398227158

Epoch: 6| Step: 13
Training loss: 1.1630128622055054
Validation loss: 1.934774124494163

Epoch: 573| Step: 0
Training loss: 0.9834234714508057
Validation loss: 1.8979749525746992

Epoch: 6| Step: 1
Training loss: 1.141932725906372
Validation loss: 1.838116858595161

Epoch: 6| Step: 2
Training loss: 0.6029800772666931
Validation loss: 1.8966786963965303

Epoch: 6| Step: 3
Training loss: 0.8185806274414062
Validation loss: 1.8896670604264865

Epoch: 6| Step: 4
Training loss: 0.9720865488052368
Validation loss: 1.8733423217650382

Epoch: 6| Step: 5
Training loss: 1.1873753070831299
Validation loss: 1.8707545316347511

Epoch: 6| Step: 6
Training loss: 0.9662959575653076
Validation loss: 1.8633259457926596

Epoch: 6| Step: 7
Training loss: 1.1922779083251953
Validation loss: 1.9184003427464476

Epoch: 6| Step: 8
Training loss: 1.4302701950073242
Validation loss: 1.8921212637296287

Epoch: 6| Step: 9
Training loss: 1.158266305923462
Validation loss: 1.7674384270944903

Epoch: 6| Step: 10
Training loss: 1.040062427520752
Validation loss: 1.7749622509043703

Epoch: 6| Step: 11
Training loss: 0.9385582208633423
Validation loss: 1.8590545462023826

Epoch: 6| Step: 12
Training loss: 0.7371715307235718
Validation loss: 1.896788013878689

Epoch: 6| Step: 13
Training loss: 1.0953645706176758
Validation loss: 1.8641962069337086

Epoch: 574| Step: 0
Training loss: 0.8533527851104736
Validation loss: 1.8492695336700768

Epoch: 6| Step: 1
Training loss: 0.8186151385307312
Validation loss: 1.8921951837437128

Epoch: 6| Step: 2
Training loss: 1.0572774410247803
Validation loss: 1.8027279582074893

Epoch: 6| Step: 3
Training loss: 0.6573639512062073
Validation loss: 1.8849902460652013

Epoch: 6| Step: 4
Training loss: 0.9835045337677002
Validation loss: 1.9478710300178939

Epoch: 6| Step: 5
Training loss: 0.9821387529373169
Validation loss: 1.99772491762715

Epoch: 6| Step: 6
Training loss: 1.23152494430542
Validation loss: 1.8982594038850518

Epoch: 6| Step: 7
Training loss: 1.0171217918395996
Validation loss: 1.965779104540425

Epoch: 6| Step: 8
Training loss: 1.0728816986083984
Validation loss: 1.8388505853632444

Epoch: 6| Step: 9
Training loss: 0.8717706203460693
Validation loss: 1.7841598577396844

Epoch: 6| Step: 10
Training loss: 1.7317314147949219
Validation loss: 1.8198410541780534

Epoch: 6| Step: 11
Training loss: 0.863203763961792
Validation loss: 1.8473393045445925

Epoch: 6| Step: 12
Training loss: 0.7547957897186279
Validation loss: 1.8258427573788552

Epoch: 6| Step: 13
Training loss: 1.1785054206848145
Validation loss: 1.8631855210950297

Epoch: 575| Step: 0
Training loss: 0.798008143901825
Validation loss: 1.8161762401621828

Epoch: 6| Step: 1
Training loss: 1.1292293071746826
Validation loss: 1.8863353934339298

Epoch: 6| Step: 2
Training loss: 1.8147724866867065
Validation loss: 1.8137923312443558

Epoch: 6| Step: 3
Training loss: 1.2231109142303467
Validation loss: 1.8680848306225193

Epoch: 6| Step: 4
Training loss: 0.4467329680919647
Validation loss: 1.8179876330078288

Epoch: 6| Step: 5
Training loss: 0.8369295001029968
Validation loss: 1.9396601094994494

Epoch: 6| Step: 6
Training loss: 0.7959128618240356
Validation loss: 1.8993938225571827

Epoch: 6| Step: 7
Training loss: 0.7967205047607422
Validation loss: 1.8759208110070997

Epoch: 6| Step: 8
Training loss: 0.8896216750144958
Validation loss: 1.918823411387782

Epoch: 6| Step: 9
Training loss: 0.819310188293457
Validation loss: 1.8911531484255226

Epoch: 6| Step: 10
Training loss: 1.0846257209777832
Validation loss: 1.8982544945132347

Epoch: 6| Step: 11
Training loss: 0.49224549531936646
Validation loss: 1.9260751149987663

Epoch: 6| Step: 12
Training loss: 1.2412571907043457
Validation loss: 1.8138977763473347

Epoch: 6| Step: 13
Training loss: 1.210585117340088
Validation loss: 1.8140883317557714

Epoch: 576| Step: 0
Training loss: 0.9045476317405701
Validation loss: 1.9207738086741457

Epoch: 6| Step: 1
Training loss: 0.6673702001571655
Validation loss: 1.869893507290912

Epoch: 6| Step: 2
Training loss: 1.1929694414138794
Validation loss: 1.9531302913542716

Epoch: 6| Step: 3
Training loss: 1.204369306564331
Validation loss: 1.91277785711391

Epoch: 6| Step: 4
Training loss: 0.6691302061080933
Validation loss: 1.9086313811681603

Epoch: 6| Step: 5
Training loss: 1.1661691665649414
Validation loss: 1.8904708559795091

Epoch: 6| Step: 6
Training loss: 1.132908582687378
Validation loss: 1.8399689453904347

Epoch: 6| Step: 7
Training loss: 0.7238057851791382
Validation loss: 1.9056728552746516

Epoch: 6| Step: 8
Training loss: 0.9796623587608337
Validation loss: 1.905625375368262

Epoch: 6| Step: 9
Training loss: 1.2629140615463257
Validation loss: 1.931993757524798

Epoch: 6| Step: 10
Training loss: 0.5073921084403992
Validation loss: 1.8523115650300057

Epoch: 6| Step: 11
Training loss: 1.294950246810913
Validation loss: 1.9427571668419787

Epoch: 6| Step: 12
Training loss: 0.8761411905288696
Validation loss: 1.908343558670372

Epoch: 6| Step: 13
Training loss: 1.051371693611145
Validation loss: 1.8190451463063557

Epoch: 577| Step: 0
Training loss: 0.8860292434692383
Validation loss: 1.9029529607424172

Epoch: 6| Step: 1
Training loss: 0.7664506435394287
Validation loss: 1.878912773183597

Epoch: 6| Step: 2
Training loss: 0.7284998893737793
Validation loss: 1.8160387956967918

Epoch: 6| Step: 3
Training loss: 1.1844100952148438
Validation loss: 1.8891923837764288

Epoch: 6| Step: 4
Training loss: 0.8207975625991821
Validation loss: 1.931187932209302

Epoch: 6| Step: 5
Training loss: 1.4617279767990112
Validation loss: 1.8084350978174517

Epoch: 6| Step: 6
Training loss: 1.6917306184768677
Validation loss: 1.9035205917973672

Epoch: 6| Step: 7
Training loss: 0.9649852514266968
Validation loss: 1.8743639146128008

Epoch: 6| Step: 8
Training loss: 0.7633726596832275
Validation loss: 1.9411786243479738

Epoch: 6| Step: 9
Training loss: 1.1817224025726318
Validation loss: 1.8649490443609094

Epoch: 6| Step: 10
Training loss: 0.634201169013977
Validation loss: 1.918508247662616

Epoch: 6| Step: 11
Training loss: 0.725246012210846
Validation loss: 1.8793242234055714

Epoch: 6| Step: 12
Training loss: 0.775467038154602
Validation loss: 1.9162775008909163

Epoch: 6| Step: 13
Training loss: 0.7618729472160339
Validation loss: 1.9396316056610436

Epoch: 578| Step: 0
Training loss: 1.4270498752593994
Validation loss: 1.964791423530989

Epoch: 6| Step: 1
Training loss: 1.458854079246521
Validation loss: 1.917498759044114

Epoch: 6| Step: 2
Training loss: 1.300462007522583
Validation loss: 1.9621064432205693

Epoch: 6| Step: 3
Training loss: 1.0312047004699707
Validation loss: 1.877484453621731

Epoch: 6| Step: 4
Training loss: 0.9464844465255737
Validation loss: 1.792294627876692

Epoch: 6| Step: 5
Training loss: 0.8571932315826416
Validation loss: 1.8772189591520576

Epoch: 6| Step: 6
Training loss: 1.0850021839141846
Validation loss: 1.8523654553198046

Epoch: 6| Step: 7
Training loss: 0.7560884356498718
Validation loss: 1.9253492688619962

Epoch: 6| Step: 8
Training loss: 0.729745090007782
Validation loss: 1.844306715073124

Epoch: 6| Step: 9
Training loss: 1.0643118619918823
Validation loss: 1.8243640622785013

Epoch: 6| Step: 10
Training loss: 1.0049595832824707
Validation loss: 1.837893129676901

Epoch: 6| Step: 11
Training loss: 0.9649711847305298
Validation loss: 1.8359085231698968

Epoch: 6| Step: 12
Training loss: 0.8505473732948303
Validation loss: 1.8766443152581491

Epoch: 6| Step: 13
Training loss: 0.4966844320297241
Validation loss: 1.879647595908052

Epoch: 579| Step: 0
Training loss: 0.9808443188667297
Validation loss: 1.8758383104878087

Epoch: 6| Step: 1
Training loss: 1.9565600156784058
Validation loss: 1.8358802949228594

Epoch: 6| Step: 2
Training loss: 1.213759422302246
Validation loss: 1.8259867032368977

Epoch: 6| Step: 3
Training loss: 1.072131633758545
Validation loss: 1.8526930091201619

Epoch: 6| Step: 4
Training loss: 0.6286818385124207
Validation loss: 1.9920747510848507

Epoch: 6| Step: 5
Training loss: 1.0722179412841797
Validation loss: 1.919288996727236

Epoch: 6| Step: 6
Training loss: 0.7935337424278259
Validation loss: 1.8949911440572431

Epoch: 6| Step: 7
Training loss: 1.1637399196624756
Validation loss: 1.852510485597836

Epoch: 6| Step: 8
Training loss: 0.6013052463531494
Validation loss: 1.8859352347671345

Epoch: 6| Step: 9
Training loss: 1.250922679901123
Validation loss: 1.8933420130001601

Epoch: 6| Step: 10
Training loss: 0.9285875558853149
Validation loss: 1.940951060223323

Epoch: 6| Step: 11
Training loss: 0.8414672613143921
Validation loss: 1.8985195031730078

Epoch: 6| Step: 12
Training loss: 0.7353624105453491
Validation loss: 1.889560394389655

Epoch: 6| Step: 13
Training loss: 0.7102532386779785
Validation loss: 1.8993808889901767

Epoch: 580| Step: 0
Training loss: 1.3660253286361694
Validation loss: 1.8671056737181961

Epoch: 6| Step: 1
Training loss: 1.336225986480713
Validation loss: 1.8372492790222168

Epoch: 6| Step: 2
Training loss: 0.816197395324707
Validation loss: 1.8789926075166272

Epoch: 6| Step: 3
Training loss: 1.1851160526275635
Validation loss: 1.8714499794026858

Epoch: 6| Step: 4
Training loss: 0.7794954180717468
Validation loss: 1.8643200243673017

Epoch: 6| Step: 5
Training loss: 0.6339277029037476
Validation loss: 1.8719585634046985

Epoch: 6| Step: 6
Training loss: 1.0979268550872803
Validation loss: 1.8202612015508837

Epoch: 6| Step: 7
Training loss: 0.9115664958953857
Validation loss: 1.8219445405467865

Epoch: 6| Step: 8
Training loss: 1.3319897651672363
Validation loss: 1.8629624612869755

Epoch: 6| Step: 9
Training loss: 1.1882109642028809
Validation loss: 1.9160562612677132

Epoch: 6| Step: 10
Training loss: 0.9533053636550903
Validation loss: 1.9414624757664178

Epoch: 6| Step: 11
Training loss: 1.0821216106414795
Validation loss: 1.8562566695674774

Epoch: 6| Step: 12
Training loss: 0.8682631254196167
Validation loss: 1.925413323986915

Epoch: 6| Step: 13
Training loss: 1.014154076576233
Validation loss: 1.8893375883820236

Epoch: 581| Step: 0
Training loss: 0.9477061033248901
Validation loss: 1.8252978965800295

Epoch: 6| Step: 1
Training loss: 1.2568186521530151
Validation loss: 1.953917778948302

Epoch: 6| Step: 2
Training loss: 0.7357045412063599
Validation loss: 1.8943994224712413

Epoch: 6| Step: 3
Training loss: 1.0543638467788696
Validation loss: 1.8568930523369902

Epoch: 6| Step: 4
Training loss: 0.9967886805534363
Validation loss: 1.8344605520207395

Epoch: 6| Step: 5
Training loss: 0.9445761442184448
Validation loss: 1.828164787702663

Epoch: 6| Step: 6
Training loss: 1.1247220039367676
Validation loss: 1.8149751655517086

Epoch: 6| Step: 7
Training loss: 0.9149465560913086
Validation loss: 1.9003919529658493

Epoch: 6| Step: 8
Training loss: 1.4273936748504639
Validation loss: 1.9320474029869161

Epoch: 6| Step: 9
Training loss: 0.94368577003479
Validation loss: 1.903109952967654

Epoch: 6| Step: 10
Training loss: 1.0785452127456665
Validation loss: 1.9123101811255179

Epoch: 6| Step: 11
Training loss: 0.8165961503982544
Validation loss: 1.8787227176850843

Epoch: 6| Step: 12
Training loss: 0.46575266122817993
Validation loss: 1.8562406955226776

Epoch: 6| Step: 13
Training loss: 0.770605742931366
Validation loss: 1.8632317973721413

Epoch: 582| Step: 0
Training loss: 0.9936027526855469
Validation loss: 1.886398269284156

Epoch: 6| Step: 1
Training loss: 0.7178974747657776
Validation loss: 1.9409250597799979

Epoch: 6| Step: 2
Training loss: 1.1611589193344116
Validation loss: 1.8861442073698966

Epoch: 6| Step: 3
Training loss: 0.7887208461761475
Validation loss: 1.8608244849789528

Epoch: 6| Step: 4
Training loss: 0.4675304889678955
Validation loss: 1.9160286034307172

Epoch: 6| Step: 5
Training loss: 1.5668528079986572
Validation loss: 1.830387109069414

Epoch: 6| Step: 6
Training loss: 1.024535894393921
Validation loss: 1.9510806029842747

Epoch: 6| Step: 7
Training loss: 1.0024925470352173
Validation loss: 1.9019139876929663

Epoch: 6| Step: 8
Training loss: 1.1946959495544434
Validation loss: 1.906753163183889

Epoch: 6| Step: 9
Training loss: 0.8937301635742188
Validation loss: 1.8549087432123

Epoch: 6| Step: 10
Training loss: 0.7589385509490967
Validation loss: 1.884027183696788

Epoch: 6| Step: 11
Training loss: 1.2802119255065918
Validation loss: 1.8893006399113645

Epoch: 6| Step: 12
Training loss: 0.9274842739105225
Validation loss: 1.9194445071681854

Epoch: 6| Step: 13
Training loss: 0.9002365469932556
Validation loss: 1.8355489533434632

Epoch: 583| Step: 0
Training loss: 0.7768725156784058
Validation loss: 1.789395929664694

Epoch: 6| Step: 1
Training loss: 0.8844170570373535
Validation loss: 1.866104902759675

Epoch: 6| Step: 2
Training loss: 0.9533786773681641
Validation loss: 1.906489520944575

Epoch: 6| Step: 3
Training loss: 0.9430698156356812
Validation loss: 1.8780490634261922

Epoch: 6| Step: 4
Training loss: 0.46906578540802
Validation loss: 1.8017824465228665

Epoch: 6| Step: 5
Training loss: 1.2162781953811646
Validation loss: 1.971946495835499

Epoch: 6| Step: 6
Training loss: 1.0578711032867432
Validation loss: 1.9703167587198236

Epoch: 6| Step: 7
Training loss: 0.951651394367218
Validation loss: 1.8061061572003108

Epoch: 6| Step: 8
Training loss: 0.6091053485870361
Validation loss: 1.8708548020291071

Epoch: 6| Step: 9
Training loss: 0.7803189754486084
Validation loss: 1.9109294773429952

Epoch: 6| Step: 10
Training loss: 0.9626216888427734
Validation loss: 1.8902486524274271

Epoch: 6| Step: 11
Training loss: 0.8548010587692261
Validation loss: 1.816848862555719

Epoch: 6| Step: 12
Training loss: 1.0301170349121094
Validation loss: 1.9153717461452688

Epoch: 6| Step: 13
Training loss: 1.967267394065857
Validation loss: 1.8024515182741228

Epoch: 584| Step: 0
Training loss: 0.6377519369125366
Validation loss: 1.859098598521243

Epoch: 6| Step: 1
Training loss: 0.9809181094169617
Validation loss: 1.8514783677234445

Epoch: 6| Step: 2
Training loss: 0.5793430805206299
Validation loss: 1.8131858379610124

Epoch: 6| Step: 3
Training loss: 0.571341335773468
Validation loss: 1.8622734098024265

Epoch: 6| Step: 4
Training loss: 1.1832531690597534
Validation loss: 1.8389335370832873

Epoch: 6| Step: 5
Training loss: 0.9496314525604248
Validation loss: 1.843654227513139

Epoch: 6| Step: 6
Training loss: 1.1161494255065918
Validation loss: 1.9742755864256172

Epoch: 6| Step: 7
Training loss: 0.8652066588401794
Validation loss: 1.8211337712503248

Epoch: 6| Step: 8
Training loss: 1.3643076419830322
Validation loss: 1.8461187475471086

Epoch: 6| Step: 9
Training loss: 0.9536179304122925
Validation loss: 1.8859050658441359

Epoch: 6| Step: 10
Training loss: 1.3774044513702393
Validation loss: 1.9434954325358074

Epoch: 6| Step: 11
Training loss: 0.7536884546279907
Validation loss: 1.8931097420313026

Epoch: 6| Step: 12
Training loss: 0.9585962295532227
Validation loss: 1.869150612943916

Epoch: 6| Step: 13
Training loss: 1.158341884613037
Validation loss: 1.861276549677695

Epoch: 585| Step: 0
Training loss: 0.7551517486572266
Validation loss: 1.9719958612995763

Epoch: 6| Step: 1
Training loss: 1.2644479274749756
Validation loss: 1.890015709784723

Epoch: 6| Step: 2
Training loss: 0.9010093212127686
Validation loss: 1.9749722237228065

Epoch: 6| Step: 3
Training loss: 0.8385512828826904
Validation loss: 1.823060404869818

Epoch: 6| Step: 4
Training loss: 1.475119948387146
Validation loss: 1.8615017270529142

Epoch: 6| Step: 5
Training loss: 0.6170451641082764
Validation loss: 1.8723937055116058

Epoch: 6| Step: 6
Training loss: 0.7399630546569824
Validation loss: 1.94174365843496

Epoch: 6| Step: 7
Training loss: 0.8523015379905701
Validation loss: 1.8417340760589929

Epoch: 6| Step: 8
Training loss: 0.8193047046661377
Validation loss: 1.8178419772014822

Epoch: 6| Step: 9
Training loss: 0.850665807723999
Validation loss: 1.8334894475116525

Epoch: 6| Step: 10
Training loss: 1.0242469310760498
Validation loss: 1.8709478814114806

Epoch: 6| Step: 11
Training loss: 1.0173814296722412
Validation loss: 1.7936082527201662

Epoch: 6| Step: 12
Training loss: 1.2283763885498047
Validation loss: 1.9091282557415705

Epoch: 6| Step: 13
Training loss: 1.7343769073486328
Validation loss: 1.828037554217923

Epoch: 586| Step: 0
Training loss: 0.916593611240387
Validation loss: 1.8212258585037724

Epoch: 6| Step: 1
Training loss: 0.8399045467376709
Validation loss: 1.7671124204512565

Epoch: 6| Step: 2
Training loss: 1.1846568584442139
Validation loss: 1.8311459877157723

Epoch: 6| Step: 3
Training loss: 1.2158669233322144
Validation loss: 1.884571486903775

Epoch: 6| Step: 4
Training loss: 1.0291308164596558
Validation loss: 1.8972328529563

Epoch: 6| Step: 5
Training loss: 1.0329079627990723
Validation loss: 1.9335290616558445

Epoch: 6| Step: 6
Training loss: 0.9593743085861206
Validation loss: 1.8426808862275974

Epoch: 6| Step: 7
Training loss: 1.1502368450164795
Validation loss: 1.9748149552652914

Epoch: 6| Step: 8
Training loss: 0.6408421993255615
Validation loss: 1.7678093782035254

Epoch: 6| Step: 9
Training loss: 0.8067097663879395
Validation loss: 1.8201316428440872

Epoch: 6| Step: 10
Training loss: 0.8778045773506165
Validation loss: 1.8709019255894486

Epoch: 6| Step: 11
Training loss: 0.7619519233703613
Validation loss: 1.833905541768638

Epoch: 6| Step: 12
Training loss: 1.2088227272033691
Validation loss: 1.8574330473458895

Epoch: 6| Step: 13
Training loss: 0.789539635181427
Validation loss: 1.8661719663168794

Epoch: 587| Step: 0
Training loss: 0.9707905650138855
Validation loss: 1.8689890958929574

Epoch: 6| Step: 1
Training loss: 1.505553126335144
Validation loss: 1.808044292593515

Epoch: 6| Step: 2
Training loss: 0.9642715454101562
Validation loss: 1.9081578485427364

Epoch: 6| Step: 3
Training loss: 1.0787990093231201
Validation loss: 1.8373279584351407

Epoch: 6| Step: 4
Training loss: 1.1185600757598877
Validation loss: 1.9288078508069437

Epoch: 6| Step: 5
Training loss: 0.857396125793457
Validation loss: 1.8757881208132672

Epoch: 6| Step: 6
Training loss: 1.039351224899292
Validation loss: 1.9108025796951786

Epoch: 6| Step: 7
Training loss: 0.8297390341758728
Validation loss: 1.9510894308808029

Epoch: 6| Step: 8
Training loss: 0.6063215732574463
Validation loss: 1.9168062466447071

Epoch: 6| Step: 9
Training loss: 0.798364520072937
Validation loss: 1.8412295977274578

Epoch: 6| Step: 10
Training loss: 0.8875947594642639
Validation loss: 1.8744660487738989

Epoch: 6| Step: 11
Training loss: 1.1656628847122192
Validation loss: 1.8605194348160938

Epoch: 6| Step: 12
Training loss: 0.8532398343086243
Validation loss: 1.8250601419838526

Epoch: 6| Step: 13
Training loss: 0.7420321106910706
Validation loss: 1.8660714369948193

Epoch: 588| Step: 0
Training loss: 1.0498700141906738
Validation loss: 1.8990243506687943

Epoch: 6| Step: 1
Training loss: 0.8860543370246887
Validation loss: 1.8556271381275629

Epoch: 6| Step: 2
Training loss: 1.1113836765289307
Validation loss: 1.8093532272564468

Epoch: 6| Step: 3
Training loss: 0.8960345983505249
Validation loss: 1.863448840315624

Epoch: 6| Step: 4
Training loss: 0.9571357369422913
Validation loss: 1.8640899632566719

Epoch: 6| Step: 5
Training loss: 1.4935240745544434
Validation loss: 1.887757816622334

Epoch: 6| Step: 6
Training loss: 1.193198800086975
Validation loss: 1.8271032225701116

Epoch: 6| Step: 7
Training loss: 0.740215003490448
Validation loss: 1.9054434568651262

Epoch: 6| Step: 8
Training loss: 1.0446728467941284
Validation loss: 1.8189983624283985

Epoch: 6| Step: 9
Training loss: 0.5010724067687988
Validation loss: 1.8810113950442242

Epoch: 6| Step: 10
Training loss: 0.8089824914932251
Validation loss: 1.9011666159476004

Epoch: 6| Step: 11
Training loss: 0.6317322850227356
Validation loss: 1.864792134172173

Epoch: 6| Step: 12
Training loss: 0.7762624025344849
Validation loss: 1.905706703021962

Epoch: 6| Step: 13
Training loss: 0.9974899291992188
Validation loss: 1.892462961135372

Epoch: 589| Step: 0
Training loss: 0.8771393299102783
Validation loss: 1.9837901464072607

Epoch: 6| Step: 1
Training loss: 1.170275092124939
Validation loss: 1.8487739947534376

Epoch: 6| Step: 2
Training loss: 1.2394498586654663
Validation loss: 1.8797202776837092

Epoch: 6| Step: 3
Training loss: 1.0115641355514526
Validation loss: 1.8918080419622443

Epoch: 6| Step: 4
Training loss: 0.7866919040679932
Validation loss: 1.8788637602201073

Epoch: 6| Step: 5
Training loss: 0.8216944336891174
Validation loss: 1.847513759008018

Epoch: 6| Step: 6
Training loss: 0.9266870021820068
Validation loss: 1.8275370931112638

Epoch: 6| Step: 7
Training loss: 0.7776878476142883
Validation loss: 1.8304712516005321

Epoch: 6| Step: 8
Training loss: 1.0362036228179932
Validation loss: 1.8742666949508011

Epoch: 6| Step: 9
Training loss: 0.945882260799408
Validation loss: 1.8176718463179886

Epoch: 6| Step: 10
Training loss: 0.630670428276062
Validation loss: 1.8602627964429959

Epoch: 6| Step: 11
Training loss: 0.8677319884300232
Validation loss: 1.8916672019548313

Epoch: 6| Step: 12
Training loss: 0.8962875604629517
Validation loss: 1.840887435020939

Epoch: 6| Step: 13
Training loss: 2.0323235988616943
Validation loss: 1.8383420641704271

Epoch: 590| Step: 0
Training loss: 0.8711170554161072
Validation loss: 1.8172646466121878

Epoch: 6| Step: 1
Training loss: 0.879027247428894
Validation loss: 1.8419914296878281

Epoch: 6| Step: 2
Training loss: 1.0942606925964355
Validation loss: 1.823469792642901

Epoch: 6| Step: 3
Training loss: 1.9964663982391357
Validation loss: 1.8415662870612195

Epoch: 6| Step: 4
Training loss: 1.2038345336914062
Validation loss: 1.8802156192000195

Epoch: 6| Step: 5
Training loss: 0.7353200912475586
Validation loss: 1.8207884321930587

Epoch: 6| Step: 6
Training loss: 0.8163616061210632
Validation loss: 1.831696952542951

Epoch: 6| Step: 7
Training loss: 1.0472993850708008
Validation loss: 1.9115868422292894

Epoch: 6| Step: 8
Training loss: 0.6151487231254578
Validation loss: 1.9806998391305246

Epoch: 6| Step: 9
Training loss: 0.5626908540725708
Validation loss: 1.925896308755362

Epoch: 6| Step: 10
Training loss: 0.8583887815475464
Validation loss: 1.870801951295586

Epoch: 6| Step: 11
Training loss: 1.2052249908447266
Validation loss: 1.9579647920464958

Epoch: 6| Step: 12
Training loss: 1.0261090993881226
Validation loss: 1.9242606086115683

Epoch: 6| Step: 13
Training loss: 0.890326201915741
Validation loss: 1.9308713648908882

Epoch: 591| Step: 0
Training loss: 1.269078016281128
Validation loss: 1.8994370481019378

Epoch: 6| Step: 1
Training loss: 1.3922271728515625
Validation loss: 1.8968383483989264

Epoch: 6| Step: 2
Training loss: 0.8819046020507812
Validation loss: 1.861211533187538

Epoch: 6| Step: 3
Training loss: 0.7195385098457336
Validation loss: 1.924937266175465

Epoch: 6| Step: 4
Training loss: 1.143540382385254
Validation loss: 1.8364047606786091

Epoch: 6| Step: 5
Training loss: 0.8476051688194275
Validation loss: 1.8927836623243106

Epoch: 6| Step: 6
Training loss: 0.8245112895965576
Validation loss: 1.9229205013603292

Epoch: 6| Step: 7
Training loss: 0.889879584312439
Validation loss: 1.8628590145418722

Epoch: 6| Step: 8
Training loss: 0.6946883201599121
Validation loss: 1.8683138585859729

Epoch: 6| Step: 9
Training loss: 1.0682520866394043
Validation loss: 1.929963627169209

Epoch: 6| Step: 10
Training loss: 1.3310245275497437
Validation loss: 1.8988508383433025

Epoch: 6| Step: 11
Training loss: 0.9851893782615662
Validation loss: 1.824769612281553

Epoch: 6| Step: 12
Training loss: 0.9079640507698059
Validation loss: 1.9089900203930434

Epoch: 6| Step: 13
Training loss: 0.9480412602424622
Validation loss: 1.8887480048723118

Epoch: 592| Step: 0
Training loss: 1.2628017663955688
Validation loss: 1.94173942201881

Epoch: 6| Step: 1
Training loss: 0.9419223666191101
Validation loss: 1.9704626016719367

Epoch: 6| Step: 2
Training loss: 1.0044348239898682
Validation loss: 1.9270699075473252

Epoch: 6| Step: 3
Training loss: 0.8122256994247437
Validation loss: 1.8085736433664958

Epoch: 6| Step: 4
Training loss: 0.577437698841095
Validation loss: 1.8266627070724324

Epoch: 6| Step: 5
Training loss: 1.1315112113952637
Validation loss: 1.8972413270704207

Epoch: 6| Step: 6
Training loss: 1.2927823066711426
Validation loss: 1.9032086762048865

Epoch: 6| Step: 7
Training loss: 1.0805954933166504
Validation loss: 1.8752982706151984

Epoch: 6| Step: 8
Training loss: 0.5970688462257385
Validation loss: 1.9054759702374857

Epoch: 6| Step: 9
Training loss: 0.7087043523788452
Validation loss: 1.8788040171387375

Epoch: 6| Step: 10
Training loss: 0.9185472726821899
Validation loss: 1.9670743583351054

Epoch: 6| Step: 11
Training loss: 0.8603707551956177
Validation loss: 1.8802593882365892

Epoch: 6| Step: 12
Training loss: 1.255253791809082
Validation loss: 1.9368278852073095

Epoch: 6| Step: 13
Training loss: 1.1745648384094238
Validation loss: 1.8677518803586242

Epoch: 593| Step: 0
Training loss: 0.8211467266082764
Validation loss: 1.8380474275158298

Epoch: 6| Step: 1
Training loss: 0.7000373601913452
Validation loss: 1.821527006805584

Epoch: 6| Step: 2
Training loss: 1.2953801155090332
Validation loss: 1.8565500782382103

Epoch: 6| Step: 3
Training loss: 1.131900429725647
Validation loss: 1.8541458191410187

Epoch: 6| Step: 4
Training loss: 0.9197685122489929
Validation loss: 1.796222085593849

Epoch: 6| Step: 5
Training loss: 1.3521668910980225
Validation loss: 1.8724678306169407

Epoch: 6| Step: 6
Training loss: 0.7463735342025757
Validation loss: 1.8580647963349537

Epoch: 6| Step: 7
Training loss: 1.060071587562561
Validation loss: 1.8920786842223136

Epoch: 6| Step: 8
Training loss: 1.1292170286178589
Validation loss: 1.8134404395216255

Epoch: 6| Step: 9
Training loss: 1.1882569789886475
Validation loss: 1.874984001600614

Epoch: 6| Step: 10
Training loss: 0.8045787811279297
Validation loss: 1.852769874757336

Epoch: 6| Step: 11
Training loss: 1.2969136238098145
Validation loss: 1.7909260751098715

Epoch: 6| Step: 12
Training loss: 1.1809258460998535
Validation loss: 1.8533912627927718

Epoch: 6| Step: 13
Training loss: 0.8949096202850342
Validation loss: 1.7842883063900856

Epoch: 594| Step: 0
Training loss: 0.7010350823402405
Validation loss: 1.8102277709591774

Epoch: 6| Step: 1
Training loss: 1.113882064819336
Validation loss: 1.785786195467877

Epoch: 6| Step: 2
Training loss: 1.2531243562698364
Validation loss: 1.8349465939306444

Epoch: 6| Step: 3
Training loss: 0.8412481546401978
Validation loss: 1.8811675310134888

Epoch: 6| Step: 4
Training loss: 1.0459280014038086
Validation loss: 1.8552574470479002

Epoch: 6| Step: 5
Training loss: 0.8682864904403687
Validation loss: 1.825992344528116

Epoch: 6| Step: 6
Training loss: 0.8904584646224976
Validation loss: 1.8449806077505952

Epoch: 6| Step: 7
Training loss: 1.0573084354400635
Validation loss: 1.9078351938596336

Epoch: 6| Step: 8
Training loss: 1.2600748538970947
Validation loss: 1.8423677670058383

Epoch: 6| Step: 9
Training loss: 1.1771166324615479
Validation loss: 1.8701764588714929

Epoch: 6| Step: 10
Training loss: 1.009809970855713
Validation loss: 1.8934118209346649

Epoch: 6| Step: 11
Training loss: 0.5362333655357361
Validation loss: 1.8868490842080885

Epoch: 6| Step: 12
Training loss: 0.940574586391449
Validation loss: 1.8368770768565517

Epoch: 6| Step: 13
Training loss: 1.0893359184265137
Validation loss: 1.8795968742780789

Epoch: 595| Step: 0
Training loss: 0.8060346841812134
Validation loss: 1.884167831431153

Epoch: 6| Step: 1
Training loss: 0.9765357375144958
Validation loss: 1.8631184947106145

Epoch: 6| Step: 2
Training loss: 0.749394953250885
Validation loss: 1.8789515008208573

Epoch: 6| Step: 3
Training loss: 0.9783416986465454
Validation loss: 1.844186713618617

Epoch: 6| Step: 4
Training loss: 0.6528297662734985
Validation loss: 1.8046270121810257

Epoch: 6| Step: 5
Training loss: 2.0715091228485107
Validation loss: 1.7777769937310168

Epoch: 6| Step: 6
Training loss: 0.9266232252120972
Validation loss: 1.8711083396788566

Epoch: 6| Step: 7
Training loss: 0.8599943518638611
Validation loss: 1.8066359566104027

Epoch: 6| Step: 8
Training loss: 0.6080251932144165
Validation loss: 1.845013613341957

Epoch: 6| Step: 9
Training loss: 1.1742868423461914
Validation loss: 1.7956373153194305

Epoch: 6| Step: 10
Training loss: 0.7975828647613525
Validation loss: 1.8721134829264816

Epoch: 6| Step: 11
Training loss: 1.0549092292785645
Validation loss: 1.8525820303988714

Epoch: 6| Step: 12
Training loss: 0.4810428023338318
Validation loss: 1.8452616173733947

Epoch: 6| Step: 13
Training loss: 1.088218092918396
Validation loss: 1.8331139420950284

Epoch: 596| Step: 0
Training loss: 1.1718528270721436
Validation loss: 1.9644931003611574

Epoch: 6| Step: 1
Training loss: 1.0425372123718262
Validation loss: 1.9102460774042274

Epoch: 6| Step: 2
Training loss: 0.6373887062072754
Validation loss: 1.8828890426184541

Epoch: 6| Step: 3
Training loss: 0.9247995018959045
Validation loss: 1.856562509331652

Epoch: 6| Step: 4
Training loss: 1.3091130256652832
Validation loss: 1.8775177976136566

Epoch: 6| Step: 5
Training loss: 0.7021675109863281
Validation loss: 1.9066206819267684

Epoch: 6| Step: 6
Training loss: 0.9287768006324768
Validation loss: 1.8405677169881842

Epoch: 6| Step: 7
Training loss: 1.0727860927581787
Validation loss: 1.9348079171231998

Epoch: 6| Step: 8
Training loss: 0.6583888530731201
Validation loss: 1.8671565978757796

Epoch: 6| Step: 9
Training loss: 1.0703015327453613
Validation loss: 1.8064786772574148

Epoch: 6| Step: 10
Training loss: 0.7400722503662109
Validation loss: 1.7955575681501819

Epoch: 6| Step: 11
Training loss: 0.8627162575721741
Validation loss: 1.870111532108758

Epoch: 6| Step: 12
Training loss: 0.7957768440246582
Validation loss: 1.8696422089812577

Epoch: 6| Step: 13
Training loss: 0.9298155903816223
Validation loss: 1.8188503096180577

Epoch: 597| Step: 0
Training loss: 1.4535353183746338
Validation loss: 1.8287088742820166

Epoch: 6| Step: 1
Training loss: 0.902984619140625
Validation loss: 1.8300861389406267

Epoch: 6| Step: 2
Training loss: 1.1897327899932861
Validation loss: 1.9384995481019378

Epoch: 6| Step: 3
Training loss: 0.6348428726196289
Validation loss: 1.938472335056592

Epoch: 6| Step: 4
Training loss: 0.5766675472259521
Validation loss: 1.8532018353862147

Epoch: 6| Step: 5
Training loss: 1.2392594814300537
Validation loss: 1.8557565737796087

Epoch: 6| Step: 6
Training loss: 1.0005708932876587
Validation loss: 1.873007002697196

Epoch: 6| Step: 7
Training loss: 0.7750049829483032
Validation loss: 1.8256461440875966

Epoch: 6| Step: 8
Training loss: 0.907935380935669
Validation loss: 1.868239818080779

Epoch: 6| Step: 9
Training loss: 1.1355069875717163
Validation loss: 1.9600065805578744

Epoch: 6| Step: 10
Training loss: 0.5690727829933167
Validation loss: 1.910742272612869

Epoch: 6| Step: 11
Training loss: 1.1339707374572754
Validation loss: 1.8676776911622734

Epoch: 6| Step: 12
Training loss: 0.7498959302902222
Validation loss: 1.8296015493331417

Epoch: 6| Step: 13
Training loss: 0.5907520651817322
Validation loss: 1.8821364102825042

Epoch: 598| Step: 0
Training loss: 1.1830189228057861
Validation loss: 1.7942334939074773

Epoch: 6| Step: 1
Training loss: 1.1677093505859375
Validation loss: 1.9110518834924186

Epoch: 6| Step: 2
Training loss: 1.2760814428329468
Validation loss: 1.844614383994892

Epoch: 6| Step: 3
Training loss: 0.7453718185424805
Validation loss: 1.912735326315767

Epoch: 6| Step: 4
Training loss: 0.7808927297592163
Validation loss: 1.8393504901598858

Epoch: 6| Step: 5
Training loss: 0.796046793460846
Validation loss: 1.8698046886792747

Epoch: 6| Step: 6
Training loss: 0.7713653445243835
Validation loss: 1.887733704300337

Epoch: 6| Step: 7
Training loss: 1.0387951135635376
Validation loss: 1.8673381215782576

Epoch: 6| Step: 8
Training loss: 0.9625332951545715
Validation loss: 1.9049135177366194

Epoch: 6| Step: 9
Training loss: 0.7382327914237976
Validation loss: 1.9129633442048104

Epoch: 6| Step: 10
Training loss: 1.1022001504898071
Validation loss: 1.9166919582633561

Epoch: 6| Step: 11
Training loss: 0.6600438952445984
Validation loss: 1.915600219080525

Epoch: 6| Step: 12
Training loss: 0.898042619228363
Validation loss: 1.9201903625201153

Epoch: 6| Step: 13
Training loss: 1.0781664848327637
Validation loss: 1.921962438091155

Epoch: 599| Step: 0
Training loss: 0.579948365688324
Validation loss: 1.8657349213477104

Epoch: 6| Step: 1
Training loss: 0.46231603622436523
Validation loss: 1.852904091599167

Epoch: 6| Step: 2
Training loss: 0.5883975028991699
Validation loss: 1.9593625812120334

Epoch: 6| Step: 3
Training loss: 1.6755645275115967
Validation loss: 1.834655733518703

Epoch: 6| Step: 4
Training loss: 1.09421968460083
Validation loss: 1.914060777233493

Epoch: 6| Step: 5
Training loss: 1.6713403463363647
Validation loss: 1.9405260829515354

Epoch: 6| Step: 6
Training loss: 0.9438612461090088
Validation loss: 1.8478482641199583

Epoch: 6| Step: 7
Training loss: 0.48353004455566406
Validation loss: 1.9185983545036727

Epoch: 6| Step: 8
Training loss: 0.7802892923355103
Validation loss: 1.9180334178350305

Epoch: 6| Step: 9
Training loss: 0.9128779172897339
Validation loss: 1.8087004512868903

Epoch: 6| Step: 10
Training loss: 1.239311695098877
Validation loss: 1.9391250738533594

Epoch: 6| Step: 11
Training loss: 0.7127834558486938
Validation loss: 1.8032868498115129

Epoch: 6| Step: 12
Training loss: 0.9777394533157349
Validation loss: 1.8629846213966288

Epoch: 6| Step: 13
Training loss: 0.8275833129882812
Validation loss: 1.8244352955971994

Epoch: 600| Step: 0
Training loss: 0.8294376134872437
Validation loss: 1.9354391303113712

Epoch: 6| Step: 1
Training loss: 0.9789283275604248
Validation loss: 1.826630873064841

Epoch: 6| Step: 2
Training loss: 1.0643301010131836
Validation loss: 1.867240200760544

Epoch: 6| Step: 3
Training loss: 0.7340484261512756
Validation loss: 1.8599938961767382

Epoch: 6| Step: 4
Training loss: 0.7965700626373291
Validation loss: 1.8421253363291423

Epoch: 6| Step: 5
Training loss: 0.9024046063423157
Validation loss: 1.8861419885389266

Epoch: 6| Step: 6
Training loss: 0.8840527534484863
Validation loss: 1.9365026720108525

Epoch: 6| Step: 7
Training loss: 0.7530351281166077
Validation loss: 1.8789581509046658

Epoch: 6| Step: 8
Training loss: 1.3193202018737793
Validation loss: 1.807206371779083

Epoch: 6| Step: 9
Training loss: 1.11622154712677
Validation loss: 1.8317792287436865

Epoch: 6| Step: 10
Training loss: 0.8765242099761963
Validation loss: 1.8025069980211155

Epoch: 6| Step: 11
Training loss: 1.25873601436615
Validation loss: 1.9161899269268077

Epoch: 6| Step: 12
Training loss: 0.8688087463378906
Validation loss: 1.8555778598272672

Epoch: 6| Step: 13
Training loss: 0.7826572060585022
Validation loss: 1.939154827466575

Epoch: 601| Step: 0
Training loss: 0.5617190599441528
Validation loss: 1.8346812507157684

Epoch: 6| Step: 1
Training loss: 1.0584450960159302
Validation loss: 1.8851830138955066

Epoch: 6| Step: 2
Training loss: 0.9708894491195679
Validation loss: 1.9230163276836436

Epoch: 6| Step: 3
Training loss: 0.7605631351470947
Validation loss: 2.010069416415307

Epoch: 6| Step: 4
Training loss: 0.6468641757965088
Validation loss: 1.886348073200513

Epoch: 6| Step: 5
Training loss: 1.0847088098526
Validation loss: 1.9333407366147606

Epoch: 6| Step: 6
Training loss: 1.4753782749176025
Validation loss: 1.9694236593861734

Epoch: 6| Step: 7
Training loss: 0.5388814210891724
Validation loss: 1.8801753918329875

Epoch: 6| Step: 8
Training loss: 0.765278160572052
Validation loss: 1.847313787347527

Epoch: 6| Step: 9
Training loss: 1.192921757698059
Validation loss: 1.8717204075987621

Epoch: 6| Step: 10
Training loss: 0.7512742280960083
Validation loss: 1.8472921989297355

Epoch: 6| Step: 11
Training loss: 1.400167465209961
Validation loss: 1.8631978547701271

Epoch: 6| Step: 12
Training loss: 0.7008661031723022
Validation loss: 1.959612782283496

Epoch: 6| Step: 13
Training loss: 1.62136709690094
Validation loss: 1.8646713713163972

Epoch: 602| Step: 0
Training loss: 0.5943590402603149
Validation loss: 1.889432483462877

Epoch: 6| Step: 1
Training loss: 0.5535463094711304
Validation loss: 1.8435478594995314

Epoch: 6| Step: 2
Training loss: 0.8550758361816406
Validation loss: 1.8766525355718469

Epoch: 6| Step: 3
Training loss: 0.9878751039505005
Validation loss: 1.8996462091322868

Epoch: 6| Step: 4
Training loss: 1.1668741703033447
Validation loss: 1.8833374284928845

Epoch: 6| Step: 5
Training loss: 0.9900527000427246
Validation loss: 1.8397729012273973

Epoch: 6| Step: 6
Training loss: 0.8246665000915527
Validation loss: 1.8897544619857625

Epoch: 6| Step: 7
Training loss: 1.2145700454711914
Validation loss: 1.8438415104343044

Epoch: 6| Step: 8
Training loss: 1.1646480560302734
Validation loss: 1.9088848175541047

Epoch: 6| Step: 9
Training loss: 0.6527928113937378
Validation loss: 1.7671283983415174

Epoch: 6| Step: 10
Training loss: 1.3705811500549316
Validation loss: 1.9036402035784978

Epoch: 6| Step: 11
Training loss: 1.0708410739898682
Validation loss: 1.8619508563831288

Epoch: 6| Step: 12
Training loss: 0.7517762780189514
Validation loss: 1.8823712807829662

Epoch: 6| Step: 13
Training loss: 0.7528897523880005
Validation loss: 1.9257408418963033

Epoch: 603| Step: 0
Training loss: 1.4773659706115723
Validation loss: 1.9098974043323147

Epoch: 6| Step: 1
Training loss: 0.7471417188644409
Validation loss: 1.8930677034521615

Epoch: 6| Step: 2
Training loss: 1.096855640411377
Validation loss: 1.9529412036300988

Epoch: 6| Step: 3
Training loss: 0.9992661476135254
Validation loss: 1.880021551603912

Epoch: 6| Step: 4
Training loss: 1.3060238361358643
Validation loss: 1.9488246479342062

Epoch: 6| Step: 5
Training loss: 0.7486264705657959
Validation loss: 1.8203948569554154

Epoch: 6| Step: 6
Training loss: 0.7500077486038208
Validation loss: 1.876603667454053

Epoch: 6| Step: 7
Training loss: 0.6728780269622803
Validation loss: 1.8552091942038587

Epoch: 6| Step: 8
Training loss: 1.1432033777236938
Validation loss: 1.8283543612367363

Epoch: 6| Step: 9
Training loss: 0.8996893167495728
Validation loss: 1.8510462391761042

Epoch: 6| Step: 10
Training loss: 0.9440994262695312
Validation loss: 1.8878492373292164

Epoch: 6| Step: 11
Training loss: 0.9451919794082642
Validation loss: 1.8487215067750664

Epoch: 6| Step: 12
Training loss: 0.9748262166976929
Validation loss: 1.8298888975574124

Epoch: 6| Step: 13
Training loss: 1.1939913034439087
Validation loss: 1.7716109919291672

Epoch: 604| Step: 0
Training loss: 1.070253610610962
Validation loss: 1.9247872291072723

Epoch: 6| Step: 1
Training loss: 0.8862730264663696
Validation loss: 1.7523562036534792

Epoch: 6| Step: 2
Training loss: 0.9957407116889954
Validation loss: 1.8897549413865613

Epoch: 6| Step: 3
Training loss: 1.2553611993789673
Validation loss: 1.817283195834006

Epoch: 6| Step: 4
Training loss: 0.8942644596099854
Validation loss: 1.8811885259484733

Epoch: 6| Step: 5
Training loss: 1.1242612600326538
Validation loss: 1.9326413100765598

Epoch: 6| Step: 6
Training loss: 0.8198174238204956
Validation loss: 1.8407711675090175

Epoch: 6| Step: 7
Training loss: 1.0686774253845215
Validation loss: 1.8983053673980057

Epoch: 6| Step: 8
Training loss: 1.7605950832366943
Validation loss: 1.9117653805722472

Epoch: 6| Step: 9
Training loss: 0.6791960000991821
Validation loss: 1.8271856666893087

Epoch: 6| Step: 10
Training loss: 0.7183667421340942
Validation loss: 1.8669945116966002

Epoch: 6| Step: 11
Training loss: 1.053868055343628
Validation loss: 1.857397258922618

Epoch: 6| Step: 12
Training loss: 0.7593368291854858
Validation loss: 1.8809014751065163

Epoch: 6| Step: 13
Training loss: 0.21760858595371246
Validation loss: 1.7958787493808295

Epoch: 605| Step: 0
Training loss: 0.622125506401062
Validation loss: 1.908869046036915

Epoch: 6| Step: 1
Training loss: 0.7471066117286682
Validation loss: 1.8634268301789478

Epoch: 6| Step: 2
Training loss: 0.9897722005844116
Validation loss: 1.878911873345734

Epoch: 6| Step: 3
Training loss: 0.9843226671218872
Validation loss: 1.8098042805989583

Epoch: 6| Step: 4
Training loss: 1.5149279832839966
Validation loss: 1.886793605742916

Epoch: 6| Step: 5
Training loss: 1.0781540870666504
Validation loss: 1.8225607090098883

Epoch: 6| Step: 6
Training loss: 0.834290087223053
Validation loss: 1.8818747740919872

Epoch: 6| Step: 7
Training loss: 0.7991258502006531
Validation loss: 1.86344362074329

Epoch: 6| Step: 8
Training loss: 1.0104395151138306
Validation loss: 1.8368520326511835

Epoch: 6| Step: 9
Training loss: 1.270643949508667
Validation loss: 1.8252267273523475

Epoch: 6| Step: 10
Training loss: 0.9144219756126404
Validation loss: 1.827066393308742

Epoch: 6| Step: 11
Training loss: 0.7275267243385315
Validation loss: 1.8752689118026404

Epoch: 6| Step: 12
Training loss: 0.6443997621536255
Validation loss: 1.9170109302766862

Epoch: 6| Step: 13
Training loss: 1.3104852437973022
Validation loss: 1.8781408340700212

Epoch: 606| Step: 0
Training loss: 0.5875194072723389
Validation loss: 1.9599624244115685

Epoch: 6| Step: 1
Training loss: 1.1027355194091797
Validation loss: 1.9270580635275891

Epoch: 6| Step: 2
Training loss: 1.0972554683685303
Validation loss: 1.912434975306193

Epoch: 6| Step: 3
Training loss: 0.7420913577079773
Validation loss: 1.8645442493500248

Epoch: 6| Step: 4
Training loss: 0.8847098350524902
Validation loss: 1.8372758908938336

Epoch: 6| Step: 5
Training loss: 1.2502105236053467
Validation loss: 1.8566545491577477

Epoch: 6| Step: 6
Training loss: 1.0596237182617188
Validation loss: 1.8287593280115435

Epoch: 6| Step: 7
Training loss: 0.9280558824539185
Validation loss: 1.9168649232515724

Epoch: 6| Step: 8
Training loss: 1.4078247547149658
Validation loss: 1.8409203278121127

Epoch: 6| Step: 9
Training loss: 0.5477496385574341
Validation loss: 1.8611967537992744

Epoch: 6| Step: 10
Training loss: 0.528519868850708
Validation loss: 1.7863909864938388

Epoch: 6| Step: 11
Training loss: 1.0881669521331787
Validation loss: 1.843254396992345

Epoch: 6| Step: 12
Training loss: 1.1359528303146362
Validation loss: 1.8519071097015052

Epoch: 6| Step: 13
Training loss: 1.2102664709091187
Validation loss: 1.8486989313556301

Epoch: 607| Step: 0
Training loss: 1.5098292827606201
Validation loss: 1.838289790256049

Epoch: 6| Step: 1
Training loss: 1.2230318784713745
Validation loss: 1.908450024102324

Epoch: 6| Step: 2
Training loss: 1.2108619213104248
Validation loss: 1.807391910142796

Epoch: 6| Step: 3
Training loss: 1.013150691986084
Validation loss: 1.7191337103484778

Epoch: 6| Step: 4
Training loss: 0.621497392654419
Validation loss: 1.896534812065863

Epoch: 6| Step: 5
Training loss: 1.2885310649871826
Validation loss: 1.8502892999238865

Epoch: 6| Step: 6
Training loss: 0.6680175065994263
Validation loss: 1.8413393805103917

Epoch: 6| Step: 7
Training loss: 1.0206997394561768
Validation loss: 1.881701700149044

Epoch: 6| Step: 8
Training loss: 0.6659584045410156
Validation loss: 1.8945491390843545

Epoch: 6| Step: 9
Training loss: 0.742409348487854
Validation loss: 1.8018053039427726

Epoch: 6| Step: 10
Training loss: 0.8026745915412903
Validation loss: 1.857493818447154

Epoch: 6| Step: 11
Training loss: 0.8037411570549011
Validation loss: 1.9712336653022355

Epoch: 6| Step: 12
Training loss: 0.8636311292648315
Validation loss: 1.9212889825144122

Epoch: 6| Step: 13
Training loss: 0.9858775734901428
Validation loss: 1.8875965354263142

Epoch: 608| Step: 0
Training loss: 1.3665648698806763
Validation loss: 1.8415937077614568

Epoch: 6| Step: 1
Training loss: 0.5044060945510864
Validation loss: 1.8251164805504583

Epoch: 6| Step: 2
Training loss: 0.7717502117156982
Validation loss: 1.8783719385823896

Epoch: 6| Step: 3
Training loss: 0.7161599397659302
Validation loss: 1.818566305662996

Epoch: 6| Step: 4
Training loss: 0.6197003126144409
Validation loss: 1.8573375965959282

Epoch: 6| Step: 5
Training loss: 0.8461896181106567
Validation loss: 1.8802929757743754

Epoch: 6| Step: 6
Training loss: 0.8630708456039429
Validation loss: 1.8359510014134068

Epoch: 6| Step: 7
Training loss: 1.5228062868118286
Validation loss: 1.9182058329223304

Epoch: 6| Step: 8
Training loss: 0.8240649700164795
Validation loss: 1.8426044782002766

Epoch: 6| Step: 9
Training loss: 1.1895015239715576
Validation loss: 1.8885893514079433

Epoch: 6| Step: 10
Training loss: 0.8110226392745972
Validation loss: 1.7946260872707571

Epoch: 6| Step: 11
Training loss: 1.1211439371109009
Validation loss: 1.8013990438112648

Epoch: 6| Step: 12
Training loss: 0.9170026183128357
Validation loss: 1.885184023969917

Epoch: 6| Step: 13
Training loss: 0.6066540479660034
Validation loss: 1.8936865996288996

Epoch: 609| Step: 0
Training loss: 0.8815779089927673
Validation loss: 1.8793919547911613

Epoch: 6| Step: 1
Training loss: 0.3081275224685669
Validation loss: 1.8794509928713563

Epoch: 6| Step: 2
Training loss: 1.0342342853546143
Validation loss: 1.8570983512427217

Epoch: 6| Step: 3
Training loss: 1.0284388065338135
Validation loss: 1.8903215251943117

Epoch: 6| Step: 4
Training loss: 0.9506143927574158
Validation loss: 1.9056434836438907

Epoch: 6| Step: 5
Training loss: 0.9166561961174011
Validation loss: 1.9533306167971702

Epoch: 6| Step: 6
Training loss: 1.1134194135665894
Validation loss: 1.9147819934352752

Epoch: 6| Step: 7
Training loss: 0.9239519834518433
Validation loss: 1.9088283687509515

Epoch: 6| Step: 8
Training loss: 1.0516847372055054
Validation loss: 1.8311794624533704

Epoch: 6| Step: 9
Training loss: 0.7281256914138794
Validation loss: 1.8974815658343736

Epoch: 6| Step: 10
Training loss: 1.5144402980804443
Validation loss: 1.829822696665282

Epoch: 6| Step: 11
Training loss: 1.2418960332870483
Validation loss: 1.8662835654392038

Epoch: 6| Step: 12
Training loss: 0.8461823463439941
Validation loss: 1.8581235562601397

Epoch: 6| Step: 13
Training loss: 0.7148287296295166
Validation loss: 1.852736835838646

Epoch: 610| Step: 0
Training loss: 0.945610761642456
Validation loss: 1.9164031090274933

Epoch: 6| Step: 1
Training loss: 0.8588075637817383
Validation loss: 1.8296463822805753

Epoch: 6| Step: 2
Training loss: 0.600909948348999
Validation loss: 1.8764405122367285

Epoch: 6| Step: 3
Training loss: 1.0371367931365967
Validation loss: 1.7669732660375617

Epoch: 6| Step: 4
Training loss: 0.5976580381393433
Validation loss: 1.8537136418845064

Epoch: 6| Step: 5
Training loss: 1.203084111213684
Validation loss: 1.8877315469967422

Epoch: 6| Step: 6
Training loss: 1.228703498840332
Validation loss: 1.8574642109614548

Epoch: 6| Step: 7
Training loss: 0.5587322115898132
Validation loss: 1.8225461872675086

Epoch: 6| Step: 8
Training loss: 0.5706493854522705
Validation loss: 1.8701821219536565

Epoch: 6| Step: 9
Training loss: 1.4826164245605469
Validation loss: 1.7522055096523736

Epoch: 6| Step: 10
Training loss: 1.0094516277313232
Validation loss: 1.7678441860342538

Epoch: 6| Step: 11
Training loss: 0.9663015007972717
Validation loss: 1.9221760547289284

Epoch: 6| Step: 12
Training loss: 0.7972913384437561
Validation loss: 1.8677494487454813

Epoch: 6| Step: 13
Training loss: 0.4753657877445221
Validation loss: 1.90511703747575

Epoch: 611| Step: 0
Training loss: 1.1207762956619263
Validation loss: 1.9181467692057292

Epoch: 6| Step: 1
Training loss: 0.7479285001754761
Validation loss: 1.869629967597223

Epoch: 6| Step: 2
Training loss: 0.8017523884773254
Validation loss: 1.8860546017205844

Epoch: 6| Step: 3
Training loss: 0.9010124206542969
Validation loss: 1.8906434530852942

Epoch: 6| Step: 4
Training loss: 0.6949025988578796
Validation loss: 1.9324282792306715

Epoch: 6| Step: 5
Training loss: 0.8968000411987305
Validation loss: 1.8579220182152205

Epoch: 6| Step: 6
Training loss: 0.9902991056442261
Validation loss: 1.8672349478608818

Epoch: 6| Step: 7
Training loss: 0.8422932624816895
Validation loss: 1.8065455523870324

Epoch: 6| Step: 8
Training loss: 1.0020525455474854
Validation loss: 1.7939940370539182

Epoch: 6| Step: 9
Training loss: 1.0104269981384277
Validation loss: 1.8278623037440802

Epoch: 6| Step: 10
Training loss: 1.0900923013687134
Validation loss: 1.9016286160356255

Epoch: 6| Step: 11
Training loss: 1.505190134048462
Validation loss: 1.8123081191893546

Epoch: 6| Step: 12
Training loss: 0.7426498532295227
Validation loss: 1.8207904959237704

Epoch: 6| Step: 13
Training loss: 0.41842350363731384
Validation loss: 1.8124518727743497

Epoch: 612| Step: 0
Training loss: 0.8682264089584351
Validation loss: 1.7964466335952922

Epoch: 6| Step: 1
Training loss: 0.9050382375717163
Validation loss: 1.8552884106994958

Epoch: 6| Step: 2
Training loss: 1.0192056894302368
Validation loss: 1.8272106673127861

Epoch: 6| Step: 3
Training loss: 0.9702911376953125
Validation loss: 1.8313292585393435

Epoch: 6| Step: 4
Training loss: 1.2223279476165771
Validation loss: 1.8390404152613815

Epoch: 6| Step: 5
Training loss: 0.8552486896514893
Validation loss: 1.9086573444386965

Epoch: 6| Step: 6
Training loss: 1.7736601829528809
Validation loss: 1.8549453340550905

Epoch: 6| Step: 7
Training loss: 0.7438918352127075
Validation loss: 1.8490910004544001

Epoch: 6| Step: 8
Training loss: 1.0238598585128784
Validation loss: 1.8543924503428961

Epoch: 6| Step: 9
Training loss: 0.8380276560783386
Validation loss: 1.8405024043975338

Epoch: 6| Step: 10
Training loss: 1.1191054582595825
Validation loss: 1.9006385239221717

Epoch: 6| Step: 11
Training loss: 0.7494540214538574
Validation loss: 1.916671194056029

Epoch: 6| Step: 12
Training loss: 0.6457870006561279
Validation loss: 1.8661441085159138

Epoch: 6| Step: 13
Training loss: 0.8179014325141907
Validation loss: 1.8693548402478617

Epoch: 613| Step: 0
Training loss: 0.9184359312057495
Validation loss: 1.8545853040551628

Epoch: 6| Step: 1
Training loss: 1.1488382816314697
Validation loss: 1.8737441698710124

Epoch: 6| Step: 2
Training loss: 0.8762545585632324
Validation loss: 1.889579511457874

Epoch: 6| Step: 3
Training loss: 0.994914174079895
Validation loss: 1.7589361097223015

Epoch: 6| Step: 4
Training loss: 1.099540114402771
Validation loss: 1.8565142898149387

Epoch: 6| Step: 5
Training loss: 1.4225165843963623
Validation loss: 1.827734306294431

Epoch: 6| Step: 6
Training loss: 1.0812993049621582
Validation loss: 1.860020560602988

Epoch: 6| Step: 7
Training loss: 0.6265993118286133
Validation loss: 1.789527782829859

Epoch: 6| Step: 8
Training loss: 0.6912474632263184
Validation loss: 1.848792750348327

Epoch: 6| Step: 9
Training loss: 0.522804856300354
Validation loss: 1.9128611292890323

Epoch: 6| Step: 10
Training loss: 1.2939872741699219
Validation loss: 1.847860672140634

Epoch: 6| Step: 11
Training loss: 1.0398412942886353
Validation loss: 1.9143352226544452

Epoch: 6| Step: 12
Training loss: 0.9020048379898071
Validation loss: 1.758612476369386

Epoch: 6| Step: 13
Training loss: 0.7918064594268799
Validation loss: 1.8403903579199186

Epoch: 614| Step: 0
Training loss: 0.7783657908439636
Validation loss: 1.876498906843124

Epoch: 6| Step: 1
Training loss: 1.3215272426605225
Validation loss: 1.8845826348950785

Epoch: 6| Step: 2
Training loss: 0.8110744953155518
Validation loss: 1.90716177545568

Epoch: 6| Step: 3
Training loss: 1.0991413593292236
Validation loss: 1.9113349401822655

Epoch: 6| Step: 4
Training loss: 1.1764535903930664
Validation loss: 1.8270476210501887

Epoch: 6| Step: 5
Training loss: 0.6678255796432495
Validation loss: 1.8981833240037322

Epoch: 6| Step: 6
Training loss: 1.0453102588653564
Validation loss: 1.8829761679454515

Epoch: 6| Step: 7
Training loss: 0.9969943165779114
Validation loss: 1.9489813440589494

Epoch: 6| Step: 8
Training loss: 0.6141920685768127
Validation loss: 1.9200544690573087

Epoch: 6| Step: 9
Training loss: 0.8361368179321289
Validation loss: 1.8620426180542156

Epoch: 6| Step: 10
Training loss: 0.9021002054214478
Validation loss: 1.9044186363938034

Epoch: 6| Step: 11
Training loss: 0.8749355673789978
Validation loss: 1.82625211182461

Epoch: 6| Step: 12
Training loss: 1.2009761333465576
Validation loss: 1.8702416804529005

Epoch: 6| Step: 13
Training loss: 0.8483911156654358
Validation loss: 1.8555546434976722

Epoch: 615| Step: 0
Training loss: 1.2814993858337402
Validation loss: 1.8530487091310563

Epoch: 6| Step: 1
Training loss: 0.7234088182449341
Validation loss: 1.91861375429297

Epoch: 6| Step: 2
Training loss: 1.5364502668380737
Validation loss: 1.8722971203506633

Epoch: 6| Step: 3
Training loss: 1.1914968490600586
Validation loss: 1.8373133187652917

Epoch: 6| Step: 4
Training loss: 0.9824832081794739
Validation loss: 1.8082108882165724

Epoch: 6| Step: 5
Training loss: 0.6168884634971619
Validation loss: 1.8381267414298108

Epoch: 6| Step: 6
Training loss: 0.5680586099624634
Validation loss: 1.9140484717584425

Epoch: 6| Step: 7
Training loss: 1.0927116870880127
Validation loss: 1.8958157121494252

Epoch: 6| Step: 8
Training loss: 1.0466511249542236
Validation loss: 1.8876885726887693

Epoch: 6| Step: 9
Training loss: 0.7754842042922974
Validation loss: 1.9338658894262006

Epoch: 6| Step: 10
Training loss: 0.7705219984054565
Validation loss: 1.9151868371553318

Epoch: 6| Step: 11
Training loss: 1.0630024671554565
Validation loss: 1.8024674833461802

Epoch: 6| Step: 12
Training loss: 0.7678260207176208
Validation loss: 1.8235301304888982

Epoch: 6| Step: 13
Training loss: 0.5027579665184021
Validation loss: 1.8963966959266252

Epoch: 616| Step: 0
Training loss: 0.9382214546203613
Validation loss: 1.8575853314450992

Epoch: 6| Step: 1
Training loss: 1.3402307033538818
Validation loss: 1.911931316057841

Epoch: 6| Step: 2
Training loss: 0.5994466543197632
Validation loss: 1.7907617393360342

Epoch: 6| Step: 3
Training loss: 1.2971973419189453
Validation loss: 1.8445989713873914

Epoch: 6| Step: 4
Training loss: 0.6766729354858398
Validation loss: 1.8764512231273036

Epoch: 6| Step: 5
Training loss: 0.9794050455093384
Validation loss: 1.9168025960204422

Epoch: 6| Step: 6
Training loss: 0.6848745346069336
Validation loss: 1.8392165501912434

Epoch: 6| Step: 7
Training loss: 1.1585605144500732
Validation loss: 1.874021666024321

Epoch: 6| Step: 8
Training loss: 1.3488306999206543
Validation loss: 1.8175806999206543

Epoch: 6| Step: 9
Training loss: 0.7412796020507812
Validation loss: 1.9039386292939544

Epoch: 6| Step: 10
Training loss: 0.8589355945587158
Validation loss: 1.8609203446295954

Epoch: 6| Step: 11
Training loss: 0.7995469570159912
Validation loss: 1.9666623530849334

Epoch: 6| Step: 12
Training loss: 1.0381799936294556
Validation loss: 1.8547714974290581

Epoch: 6| Step: 13
Training loss: 0.8377437591552734
Validation loss: 1.8627369339748094

Epoch: 617| Step: 0
Training loss: 0.8077145218849182
Validation loss: 1.8529902247972385

Epoch: 6| Step: 1
Training loss: 0.5652326345443726
Validation loss: 1.8102537092342172

Epoch: 6| Step: 2
Training loss: 1.0661879777908325
Validation loss: 1.8293125424333798

Epoch: 6| Step: 3
Training loss: 1.818136215209961
Validation loss: 1.8511610415674025

Epoch: 6| Step: 4
Training loss: 1.0657496452331543
Validation loss: 1.8791577662191083

Epoch: 6| Step: 5
Training loss: 1.0169942378997803
Validation loss: 1.852154501022831

Epoch: 6| Step: 6
Training loss: 0.8117411136627197
Validation loss: 1.8571585506521247

Epoch: 6| Step: 7
Training loss: 0.6154993772506714
Validation loss: 1.9029269346626856

Epoch: 6| Step: 8
Training loss: 0.8568961024284363
Validation loss: 1.898397288014812

Epoch: 6| Step: 9
Training loss: 0.8944206237792969
Validation loss: 1.8376396573999876

Epoch: 6| Step: 10
Training loss: 0.8452439308166504
Validation loss: 1.8249339185735232

Epoch: 6| Step: 11
Training loss: 0.9179974794387817
Validation loss: 1.8412973214221258

Epoch: 6| Step: 12
Training loss: 0.9478214383125305
Validation loss: 1.9400580724080403

Epoch: 6| Step: 13
Training loss: 0.5659551620483398
Validation loss: 1.8757689127358057

Epoch: 618| Step: 0
Training loss: 1.0128397941589355
Validation loss: 1.8919645458139398

Epoch: 6| Step: 1
Training loss: 0.9302098155021667
Validation loss: 1.8509902197827575

Epoch: 6| Step: 2
Training loss: 0.9228639602661133
Validation loss: 1.7924315083411433

Epoch: 6| Step: 3
Training loss: 1.2103286981582642
Validation loss: 1.8273018380647064

Epoch: 6| Step: 4
Training loss: 0.9056181907653809
Validation loss: 1.8906134533625778

Epoch: 6| Step: 5
Training loss: 1.2174873352050781
Validation loss: 1.8216333068827146

Epoch: 6| Step: 6
Training loss: 0.45739758014678955
Validation loss: 1.8110978603363037

Epoch: 6| Step: 7
Training loss: 0.6014233827590942
Validation loss: 1.8788907848378664

Epoch: 6| Step: 8
Training loss: 1.2287373542785645
Validation loss: 1.8945866887287428

Epoch: 6| Step: 9
Training loss: 1.089456558227539
Validation loss: 1.862634253758256

Epoch: 6| Step: 10
Training loss: 1.7516841888427734
Validation loss: 1.9468806097584386

Epoch: 6| Step: 11
Training loss: 0.5973379015922546
Validation loss: 1.8388888438542683

Epoch: 6| Step: 12
Training loss: 0.7377818822860718
Validation loss: 1.8773457298996628

Epoch: 6| Step: 13
Training loss: 0.7480852603912354
Validation loss: 1.9564465835530271

Epoch: 619| Step: 0
Training loss: 0.6993029117584229
Validation loss: 1.8970869266858665

Epoch: 6| Step: 1
Training loss: 0.7616540789604187
Validation loss: 1.9118270181840467

Epoch: 6| Step: 2
Training loss: 0.6558781266212463
Validation loss: 1.8887010607668149

Epoch: 6| Step: 3
Training loss: 0.6241002082824707
Validation loss: 1.922533295487845

Epoch: 6| Step: 4
Training loss: 1.312991738319397
Validation loss: 1.8185394329409446

Epoch: 6| Step: 5
Training loss: 0.8355247378349304
Validation loss: 1.7992837531592256

Epoch: 6| Step: 6
Training loss: 0.7867574095726013
Validation loss: 1.9216350278546732

Epoch: 6| Step: 7
Training loss: 0.7838258743286133
Validation loss: 1.9354757442269275

Epoch: 6| Step: 8
Training loss: 1.0304150581359863
Validation loss: 1.8289200593066472

Epoch: 6| Step: 9
Training loss: 0.7903954982757568
Validation loss: 1.8343876420810659

Epoch: 6| Step: 10
Training loss: 1.1788685321807861
Validation loss: 1.8707447475002659

Epoch: 6| Step: 11
Training loss: 1.0768458843231201
Validation loss: 1.9114719001195764

Epoch: 6| Step: 12
Training loss: 1.1901108026504517
Validation loss: 1.829216468718744

Epoch: 6| Step: 13
Training loss: 0.9936614632606506
Validation loss: 1.8653834481393137

Epoch: 620| Step: 0
Training loss: 0.7532163262367249
Validation loss: 1.9232008047001337

Epoch: 6| Step: 1
Training loss: 0.37553369998931885
Validation loss: 1.8676654523418796

Epoch: 6| Step: 2
Training loss: 0.9720699787139893
Validation loss: 1.9148148144445112

Epoch: 6| Step: 3
Training loss: 0.6192617416381836
Validation loss: 1.9087483857267646

Epoch: 6| Step: 4
Training loss: 0.8334221243858337
Validation loss: 1.9176817811945432

Epoch: 6| Step: 5
Training loss: 1.521283507347107
Validation loss: 1.9385021296880578

Epoch: 6| Step: 6
Training loss: 1.0549663305282593
Validation loss: 1.840567542660621

Epoch: 6| Step: 7
Training loss: 0.8861335515975952
Validation loss: 1.8623803879625054

Epoch: 6| Step: 8
Training loss: 0.8923198580741882
Validation loss: 1.880896173497682

Epoch: 6| Step: 9
Training loss: 1.0673770904541016
Validation loss: 1.8685222646241546

Epoch: 6| Step: 10
Training loss: 0.8887361288070679
Validation loss: 1.8960139905252764

Epoch: 6| Step: 11
Training loss: 1.2366013526916504
Validation loss: 1.8036646701956307

Epoch: 6| Step: 12
Training loss: 1.0479698181152344
Validation loss: 1.8671052917357414

Epoch: 6| Step: 13
Training loss: 0.7606990933418274
Validation loss: 1.8616041009144118

Epoch: 621| Step: 0
Training loss: 0.9530737996101379
Validation loss: 1.8790492062927575

Epoch: 6| Step: 1
Training loss: 0.6985357999801636
Validation loss: 1.8892515090204054

Epoch: 6| Step: 2
Training loss: 0.8426961898803711
Validation loss: 1.8518060689331384

Epoch: 6| Step: 3
Training loss: 1.14907705783844
Validation loss: 1.9259925734612249

Epoch: 6| Step: 4
Training loss: 0.7974398136138916
Validation loss: 1.9143146814838532

Epoch: 6| Step: 5
Training loss: 1.034752607345581
Validation loss: 1.792420066812987

Epoch: 6| Step: 6
Training loss: 0.7239251732826233
Validation loss: 1.865956010357026

Epoch: 6| Step: 7
Training loss: 1.0130033493041992
Validation loss: 1.87225220793037

Epoch: 6| Step: 8
Training loss: 1.0514168739318848
Validation loss: 1.911183416202504

Epoch: 6| Step: 9
Training loss: 0.7604490518569946
Validation loss: 1.8617010680578088

Epoch: 6| Step: 10
Training loss: 0.749887228012085
Validation loss: 1.9199614819659983

Epoch: 6| Step: 11
Training loss: 0.9139649868011475
Validation loss: 1.8591492047873877

Epoch: 6| Step: 12
Training loss: 1.1115272045135498
Validation loss: 1.844718970278258

Epoch: 6| Step: 13
Training loss: 1.1524816751480103
Validation loss: 1.860875657809678

Epoch: 622| Step: 0
Training loss: 1.4096757173538208
Validation loss: 1.8351878145689606

Epoch: 6| Step: 1
Training loss: 1.0845086574554443
Validation loss: 1.821651630504157

Epoch: 6| Step: 2
Training loss: 1.0626020431518555
Validation loss: 1.8022497059196554

Epoch: 6| Step: 3
Training loss: 0.7716273665428162
Validation loss: 1.8476217190424602

Epoch: 6| Step: 4
Training loss: 0.5269595980644226
Validation loss: 1.8101849466241815

Epoch: 6| Step: 5
Training loss: 1.0202516317367554
Validation loss: 1.824320282987369

Epoch: 6| Step: 6
Training loss: 1.2008438110351562
Validation loss: 1.8282818332795174

Epoch: 6| Step: 7
Training loss: 0.6040265560150146
Validation loss: 1.8938370417523127

Epoch: 6| Step: 8
Training loss: 0.7636095285415649
Validation loss: 1.9251566676683323

Epoch: 6| Step: 9
Training loss: 0.9866153001785278
Validation loss: 1.8466311680373324

Epoch: 6| Step: 10
Training loss: 1.3534843921661377
Validation loss: 1.9207255276300574

Epoch: 6| Step: 11
Training loss: 0.7382168769836426
Validation loss: 1.975729295002517

Epoch: 6| Step: 12
Training loss: 0.772091269493103
Validation loss: 1.9523512983834872

Epoch: 6| Step: 13
Training loss: 0.5499785542488098
Validation loss: 1.954851342785743

Epoch: 623| Step: 0
Training loss: 0.8154820203781128
Validation loss: 1.9125606629156298

Epoch: 6| Step: 1
Training loss: 0.39263850450515747
Validation loss: 1.8967839043627504

Epoch: 6| Step: 2
Training loss: 0.9746067523956299
Validation loss: 1.9576420104631813

Epoch: 6| Step: 3
Training loss: 1.2370035648345947
Validation loss: 1.9094817856306672

Epoch: 6| Step: 4
Training loss: 0.7687535285949707
Validation loss: 1.8621310854470858

Epoch: 6| Step: 5
Training loss: 0.6152132749557495
Validation loss: 1.8469621865980086

Epoch: 6| Step: 6
Training loss: 1.1872844696044922
Validation loss: 1.818070544991442

Epoch: 6| Step: 7
Training loss: 1.0040475130081177
Validation loss: 1.837651450146911

Epoch: 6| Step: 8
Training loss: 1.1621108055114746
Validation loss: 1.8212441616160895

Epoch: 6| Step: 9
Training loss: 0.961801290512085
Validation loss: 1.8555743258486512

Epoch: 6| Step: 10
Training loss: 0.6766936779022217
Validation loss: 1.9098963070941228

Epoch: 6| Step: 11
Training loss: 1.4093624353408813
Validation loss: 1.9236454566319783

Epoch: 6| Step: 12
Training loss: 0.7093527317047119
Validation loss: 1.8989541761336788

Epoch: 6| Step: 13
Training loss: 1.3521018028259277
Validation loss: 1.8859500910646172

Epoch: 624| Step: 0
Training loss: 0.7884326577186584
Validation loss: 1.8776885617163874

Epoch: 6| Step: 1
Training loss: 0.8140544295310974
Validation loss: 1.8936829067045642

Epoch: 6| Step: 2
Training loss: 0.8537321090698242
Validation loss: 1.8583936319556287

Epoch: 6| Step: 3
Training loss: 0.9579602479934692
Validation loss: 1.870909410138284

Epoch: 6| Step: 4
Training loss: 0.6874739527702332
Validation loss: 1.8701903448309949

Epoch: 6| Step: 5
Training loss: 0.950878381729126
Validation loss: 1.930972388995591

Epoch: 6| Step: 6
Training loss: 0.6678106784820557
Validation loss: 1.8365933010655064

Epoch: 6| Step: 7
Training loss: 0.659480094909668
Validation loss: 1.8200753452957317

Epoch: 6| Step: 8
Training loss: 1.2041423320770264
Validation loss: 1.9215749745727868

Epoch: 6| Step: 9
Training loss: 0.9229207038879395
Validation loss: 1.8635378627366916

Epoch: 6| Step: 10
Training loss: 0.6852706670761108
Validation loss: 1.8094261346324798

Epoch: 6| Step: 11
Training loss: 1.4341459274291992
Validation loss: 1.8840860423221384

Epoch: 6| Step: 12
Training loss: 0.6396476030349731
Validation loss: 1.7610534468004782

Epoch: 6| Step: 13
Training loss: 0.8861329555511475
Validation loss: 1.814197999174877

Epoch: 625| Step: 0
Training loss: 1.1035889387130737
Validation loss: 1.9037045740312146

Epoch: 6| Step: 1
Training loss: 0.8521535396575928
Validation loss: 1.9221628968433668

Epoch: 6| Step: 2
Training loss: 0.759291410446167
Validation loss: 1.853440966657413

Epoch: 6| Step: 3
Training loss: 0.7233709692955017
Validation loss: 1.8189102757361628

Epoch: 6| Step: 4
Training loss: 0.5396180748939514
Validation loss: 1.8335249398344307

Epoch: 6| Step: 5
Training loss: 0.7564781904220581
Validation loss: 1.8683058779726747

Epoch: 6| Step: 6
Training loss: 1.357424259185791
Validation loss: 1.8524058916235482

Epoch: 6| Step: 7
Training loss: 1.1241142749786377
Validation loss: 1.9040982364326395

Epoch: 6| Step: 8
Training loss: 0.5938856601715088
Validation loss: 1.9007932460436257

Epoch: 6| Step: 9
Training loss: 0.9484167695045471
Validation loss: 1.9043528174841275

Epoch: 6| Step: 10
Training loss: 0.6882584691047668
Validation loss: 1.911720811679799

Epoch: 6| Step: 11
Training loss: 0.7020514011383057
Validation loss: 1.879270980435033

Epoch: 6| Step: 12
Training loss: 0.7287214398384094
Validation loss: 1.9171030444483603

Epoch: 6| Step: 13
Training loss: 2.3585309982299805
Validation loss: 1.9453728391278176

Epoch: 626| Step: 0
Training loss: 1.1124982833862305
Validation loss: 1.904850488067955

Epoch: 6| Step: 1
Training loss: 1.2683918476104736
Validation loss: 1.8607612143280685

Epoch: 6| Step: 2
Training loss: 0.9177657961845398
Validation loss: 1.9207665151165378

Epoch: 6| Step: 3
Training loss: 0.6725320816040039
Validation loss: 1.8336466332917571

Epoch: 6| Step: 4
Training loss: 1.071915626525879
Validation loss: 1.7912375029697214

Epoch: 6| Step: 5
Training loss: 0.81843101978302
Validation loss: 1.8383625233045189

Epoch: 6| Step: 6
Training loss: 0.821172297000885
Validation loss: 1.873782257879934

Epoch: 6| Step: 7
Training loss: 1.0523481369018555
Validation loss: 1.9142043821273311

Epoch: 6| Step: 8
Training loss: 0.7458615303039551
Validation loss: 1.8768798894779657

Epoch: 6| Step: 9
Training loss: 0.7173945903778076
Validation loss: 1.8358622340745823

Epoch: 6| Step: 10
Training loss: 0.7972355484962463
Validation loss: 1.913758429147864

Epoch: 6| Step: 11
Training loss: 0.6762388944625854
Validation loss: 1.917290154323783

Epoch: 6| Step: 12
Training loss: 1.1126046180725098
Validation loss: 1.8664460444963107

Epoch: 6| Step: 13
Training loss: 0.8030266165733337
Validation loss: 1.9278831687024844

Epoch: 627| Step: 0
Training loss: 0.9053027629852295
Validation loss: 1.8339314691482052

Epoch: 6| Step: 1
Training loss: 0.601409912109375
Validation loss: 1.89016310117578

Epoch: 6| Step: 2
Training loss: 0.8537567853927612
Validation loss: 1.8599126928596086

Epoch: 6| Step: 3
Training loss: 1.337455153465271
Validation loss: 1.9216223685972151

Epoch: 6| Step: 4
Training loss: 1.4167287349700928
Validation loss: 1.892323152993315

Epoch: 6| Step: 5
Training loss: 0.7422617077827454
Validation loss: 1.9175248889512913

Epoch: 6| Step: 6
Training loss: 1.104804277420044
Validation loss: 1.9088098836201493

Epoch: 6| Step: 7
Training loss: 0.6217001676559448
Validation loss: 1.836572672731133

Epoch: 6| Step: 8
Training loss: 0.6608154773712158
Validation loss: 1.7752438834918443

Epoch: 6| Step: 9
Training loss: 1.1551098823547363
Validation loss: 1.8657528738821707

Epoch: 6| Step: 10
Training loss: 0.5528452396392822
Validation loss: 1.7989846070607503

Epoch: 6| Step: 11
Training loss: 1.0603866577148438
Validation loss: 1.909770901485156

Epoch: 6| Step: 12
Training loss: 0.41129738092422485
Validation loss: 1.9107393731353104

Epoch: 6| Step: 13
Training loss: 1.5004029273986816
Validation loss: 1.8112469770575081

Epoch: 628| Step: 0
Training loss: 0.7689352631568909
Validation loss: 1.8837865142412082

Epoch: 6| Step: 1
Training loss: 0.9528403282165527
Validation loss: 1.8605266232644357

Epoch: 6| Step: 2
Training loss: 0.7856237888336182
Validation loss: 1.8261253808134346

Epoch: 6| Step: 3
Training loss: 0.7872933149337769
Validation loss: 1.878165570638513

Epoch: 6| Step: 4
Training loss: 0.670465350151062
Validation loss: 1.850908894692698

Epoch: 6| Step: 5
Training loss: 1.272659420967102
Validation loss: 1.905353347460429

Epoch: 6| Step: 6
Training loss: 0.8987010717391968
Validation loss: 1.9083978463244695

Epoch: 6| Step: 7
Training loss: 1.7871065139770508
Validation loss: 1.8318150966398177

Epoch: 6| Step: 8
Training loss: 0.7045488357543945
Validation loss: 1.8595264727069485

Epoch: 6| Step: 9
Training loss: 0.8339521884918213
Validation loss: 1.8419985463542323

Epoch: 6| Step: 10
Training loss: 0.9833150506019592
Validation loss: 1.8863315364365936

Epoch: 6| Step: 11
Training loss: 0.7403695583343506
Validation loss: 1.9041807677156182

Epoch: 6| Step: 12
Training loss: 0.534900426864624
Validation loss: 1.8174663807756157

Epoch: 6| Step: 13
Training loss: 1.018332600593567
Validation loss: 1.8573218648151686

Epoch: 629| Step: 0
Training loss: 0.5029207468032837
Validation loss: 1.9105059241735807

Epoch: 6| Step: 1
Training loss: 0.5118757486343384
Validation loss: 1.8698281267637848

Epoch: 6| Step: 2
Training loss: 0.8707308769226074
Validation loss: 1.9423780056738085

Epoch: 6| Step: 3
Training loss: 0.9471578598022461
Validation loss: 1.8756604374095958

Epoch: 6| Step: 4
Training loss: 0.9457908272743225
Validation loss: 1.9008800137427546

Epoch: 6| Step: 5
Training loss: 0.7781081199645996
Validation loss: 1.9092258804587907

Epoch: 6| Step: 6
Training loss: 0.782781720161438
Validation loss: 1.847804198982895

Epoch: 6| Step: 7
Training loss: 1.1500554084777832
Validation loss: 1.8339379038862003

Epoch: 6| Step: 8
Training loss: 1.359838843345642
Validation loss: 1.8335056369022658

Epoch: 6| Step: 9
Training loss: 1.4476826190948486
Validation loss: 1.770339305682849

Epoch: 6| Step: 10
Training loss: 1.0328024625778198
Validation loss: 1.9183977457784838

Epoch: 6| Step: 11
Training loss: 0.9862959980964661
Validation loss: 1.8571770498829503

Epoch: 6| Step: 12
Training loss: 0.41816824674606323
Validation loss: 1.8970903273551696

Epoch: 6| Step: 13
Training loss: 0.4651769995689392
Validation loss: 1.8607326733168734

Epoch: 630| Step: 0
Training loss: 1.200128197669983
Validation loss: 1.906721507349322

Epoch: 6| Step: 1
Training loss: 0.7747600674629211
Validation loss: 1.839109379758117

Epoch: 6| Step: 2
Training loss: 0.5586825013160706
Validation loss: 1.8475532634283907

Epoch: 6| Step: 3
Training loss: 0.8089766502380371
Validation loss: 1.845802786529705

Epoch: 6| Step: 4
Training loss: 1.3269789218902588
Validation loss: 1.7994675046654158

Epoch: 6| Step: 5
Training loss: 0.6601548194885254
Validation loss: 1.8647879682561403

Epoch: 6| Step: 6
Training loss: 0.7333433628082275
Validation loss: 1.731939414496063

Epoch: 6| Step: 7
Training loss: 0.9861291646957397
Validation loss: 1.9047902207220755

Epoch: 6| Step: 8
Training loss: 1.0919429063796997
Validation loss: 1.9191476427098757

Epoch: 6| Step: 9
Training loss: 0.8098790645599365
Validation loss: 1.8939145662451302

Epoch: 6| Step: 10
Training loss: 1.1504247188568115
Validation loss: 1.9070432339945147

Epoch: 6| Step: 11
Training loss: 0.9467280507087708
Validation loss: 1.9921217708177463

Epoch: 6| Step: 12
Training loss: 0.8141933679580688
Validation loss: 1.871301858655868

Epoch: 6| Step: 13
Training loss: 1.6446489095687866
Validation loss: 1.8973372264574933

Epoch: 631| Step: 0
Training loss: 1.0748801231384277
Validation loss: 1.8939274062392533

Epoch: 6| Step: 1
Training loss: 0.9735094308853149
Validation loss: 1.8969177802403767

Epoch: 6| Step: 2
Training loss: 0.6390820145606995
Validation loss: 1.8885086608189408

Epoch: 6| Step: 3
Training loss: 0.6559861898422241
Validation loss: 1.8648729555068477

Epoch: 6| Step: 4
Training loss: 0.8244204521179199
Validation loss: 1.8829316682713007

Epoch: 6| Step: 5
Training loss: 1.1436653137207031
Validation loss: 1.889186760430695

Epoch: 6| Step: 6
Training loss: 1.6185266971588135
Validation loss: 1.8279455829692144

Epoch: 6| Step: 7
Training loss: 0.7888729572296143
Validation loss: 1.8730744110640658

Epoch: 6| Step: 8
Training loss: 0.7410405874252319
Validation loss: 1.8232813381379651

Epoch: 6| Step: 9
Training loss: 0.9348731637001038
Validation loss: 1.844521399467222

Epoch: 6| Step: 10
Training loss: 0.8102568984031677
Validation loss: 1.8405225597402102

Epoch: 6| Step: 11
Training loss: 0.7228013277053833
Validation loss: 1.7973202325964486

Epoch: 6| Step: 12
Training loss: 1.232337474822998
Validation loss: 1.8677690208599131

Epoch: 6| Step: 13
Training loss: 0.8643772602081299
Validation loss: 1.8841826813195341

Epoch: 632| Step: 0
Training loss: 0.8458020091056824
Validation loss: 1.8326354565158967

Epoch: 6| Step: 1
Training loss: 0.8706690073013306
Validation loss: 1.8555561778365925

Epoch: 6| Step: 2
Training loss: 0.90947425365448
Validation loss: 1.8812053972674954

Epoch: 6| Step: 3
Training loss: 0.7971909046173096
Validation loss: 1.8614159322554065

Epoch: 6| Step: 4
Training loss: 0.7771662473678589
Validation loss: 1.8476743172573786

Epoch: 6| Step: 5
Training loss: 1.0498052835464478
Validation loss: 1.9072359428610852

Epoch: 6| Step: 6
Training loss: 1.149125337600708
Validation loss: 1.9084520839875745

Epoch: 6| Step: 7
Training loss: 0.8055096864700317
Validation loss: 1.922237289849148

Epoch: 6| Step: 8
Training loss: 0.9552984237670898
Validation loss: 1.9057401700686383

Epoch: 6| Step: 9
Training loss: 1.0450823307037354
Validation loss: 1.8579344954541934

Epoch: 6| Step: 10
Training loss: 0.9821838140487671
Validation loss: 1.849780773603788

Epoch: 6| Step: 11
Training loss: 0.6321004033088684
Validation loss: 1.9032126203660042

Epoch: 6| Step: 12
Training loss: 0.46929481625556946
Validation loss: 1.7753315741016018

Epoch: 6| Step: 13
Training loss: 1.0427896976470947
Validation loss: 1.9133395084770777

Epoch: 633| Step: 0
Training loss: 0.976859986782074
Validation loss: 1.8593106064745175

Epoch: 6| Step: 1
Training loss: 0.8086681365966797
Validation loss: 1.8073433906801286

Epoch: 6| Step: 2
Training loss: 0.6979105472564697
Validation loss: 1.8711239958322177

Epoch: 6| Step: 3
Training loss: 0.6618719100952148
Validation loss: 1.8869021605419856

Epoch: 6| Step: 4
Training loss: 0.9812062978744507
Validation loss: 1.8119950115039785

Epoch: 6| Step: 5
Training loss: 0.7776735424995422
Validation loss: 1.8589447672649095

Epoch: 6| Step: 6
Training loss: 0.5299712419509888
Validation loss: 1.9439376990000408

Epoch: 6| Step: 7
Training loss: 1.19325852394104
Validation loss: 1.876414724575576

Epoch: 6| Step: 8
Training loss: 1.2034354209899902
Validation loss: 1.8401924679356236

Epoch: 6| Step: 9
Training loss: 1.1490195989608765
Validation loss: 1.9008736841140255

Epoch: 6| Step: 10
Training loss: 0.562559962272644
Validation loss: 1.8630227542692614

Epoch: 6| Step: 11
Training loss: 0.8381893634796143
Validation loss: 1.9163691074617448

Epoch: 6| Step: 12
Training loss: 0.7295194864273071
Validation loss: 1.8919717329804615

Epoch: 6| Step: 13
Training loss: 1.4627025127410889
Validation loss: 1.8826286292845202

Epoch: 634| Step: 0
Training loss: 0.8337952494621277
Validation loss: 1.8712024099083358

Epoch: 6| Step: 1
Training loss: 1.0605605840682983
Validation loss: 1.8086502167486376

Epoch: 6| Step: 2
Training loss: 0.6885164976119995
Validation loss: 1.845593407589902

Epoch: 6| Step: 3
Training loss: 1.2252202033996582
Validation loss: 1.896393701594363

Epoch: 6| Step: 4
Training loss: 0.9104171991348267
Validation loss: 1.8435590600454679

Epoch: 6| Step: 5
Training loss: 0.8156411647796631
Validation loss: 1.8183309801163212

Epoch: 6| Step: 6
Training loss: 0.951155424118042
Validation loss: 1.9086399950006956

Epoch: 6| Step: 7
Training loss: 0.935265302658081
Validation loss: 1.8315056985424412

Epoch: 6| Step: 8
Training loss: 0.9825392961502075
Validation loss: 1.9312622329240203

Epoch: 6| Step: 9
Training loss: 0.6835612654685974
Validation loss: 1.8754235557330552

Epoch: 6| Step: 10
Training loss: 1.5540302991867065
Validation loss: 1.856949995922786

Epoch: 6| Step: 11
Training loss: 0.5727065801620483
Validation loss: 1.9077114648716424

Epoch: 6| Step: 12
Training loss: 0.895529568195343
Validation loss: 1.9148456768323017

Epoch: 6| Step: 13
Training loss: 0.627758800983429
Validation loss: 1.8365120298119002

Epoch: 635| Step: 0
Training loss: 0.5556113719940186
Validation loss: 1.7643805678172777

Epoch: 6| Step: 1
Training loss: 0.7099275588989258
Validation loss: 1.782956346388786

Epoch: 6| Step: 2
Training loss: 1.0051963329315186
Validation loss: 1.8605655906020955

Epoch: 6| Step: 3
Training loss: 0.7347029447555542
Validation loss: 1.859170429168209

Epoch: 6| Step: 4
Training loss: 0.7618286609649658
Validation loss: 1.8431153092333066

Epoch: 6| Step: 5
Training loss: 0.9910553097724915
Validation loss: 1.8661811441503546

Epoch: 6| Step: 6
Training loss: 0.9709962606430054
Validation loss: 1.8002318707845544

Epoch: 6| Step: 7
Training loss: 0.8874945640563965
Validation loss: 1.8026369130739601

Epoch: 6| Step: 8
Training loss: 0.52852863073349
Validation loss: 1.865637243434947

Epoch: 6| Step: 9
Training loss: 1.0439937114715576
Validation loss: 1.9072267547730477

Epoch: 6| Step: 10
Training loss: 0.9740327000617981
Validation loss: 1.9338051003794516

Epoch: 6| Step: 11
Training loss: 1.449951410293579
Validation loss: 1.8056886965228665

Epoch: 6| Step: 12
Training loss: 1.1093387603759766
Validation loss: 1.8528299241937616

Epoch: 6| Step: 13
Training loss: 0.6271188259124756
Validation loss: 1.8428634905046033

Epoch: 636| Step: 0
Training loss: 0.6593061089515686
Validation loss: 1.813939329116575

Epoch: 6| Step: 1
Training loss: 1.0379197597503662
Validation loss: 1.8406861289854972

Epoch: 6| Step: 2
Training loss: 1.0406103134155273
Validation loss: 1.87784150338942

Epoch: 6| Step: 3
Training loss: 0.7935653924942017
Validation loss: 1.830908401038057

Epoch: 6| Step: 4
Training loss: 0.8499399423599243
Validation loss: 1.9346503583333825

Epoch: 6| Step: 5
Training loss: 0.7492343187332153
Validation loss: 1.8653404751131613

Epoch: 6| Step: 6
Training loss: 1.1566977500915527
Validation loss: 1.8597222681968444

Epoch: 6| Step: 7
Training loss: 0.6915532350540161
Validation loss: 1.8815615215609152

Epoch: 6| Step: 8
Training loss: 0.9481766819953918
Validation loss: 1.8859631271772488

Epoch: 6| Step: 9
Training loss: 0.8256334066390991
Validation loss: 1.8460526338187597

Epoch: 6| Step: 10
Training loss: 1.15726637840271
Validation loss: 1.9092211556690994

Epoch: 6| Step: 11
Training loss: 0.6901825070381165
Validation loss: 1.8475789229075115

Epoch: 6| Step: 12
Training loss: 0.7385820746421814
Validation loss: 1.8874114738997592

Epoch: 6| Step: 13
Training loss: 1.5211399793624878
Validation loss: 1.8592696433426232

Epoch: 637| Step: 0
Training loss: 1.388978123664856
Validation loss: 1.8352081147573327

Epoch: 6| Step: 1
Training loss: 0.6387407779693604
Validation loss: 1.8430892703353718

Epoch: 6| Step: 2
Training loss: 0.6111292839050293
Validation loss: 1.8375535088200723

Epoch: 6| Step: 3
Training loss: 0.5844722986221313
Validation loss: 1.8661874186608098

Epoch: 6| Step: 4
Training loss: 0.8479529619216919
Validation loss: 1.842528627764794

Epoch: 6| Step: 5
Training loss: 1.2789056301116943
Validation loss: 1.7431386901486305

Epoch: 6| Step: 6
Training loss: 1.180107831954956
Validation loss: 1.8828072753003848

Epoch: 6| Step: 7
Training loss: 1.0011876821517944
Validation loss: 1.8527799370468303

Epoch: 6| Step: 8
Training loss: 0.7415938973426819
Validation loss: 1.8943467883653538

Epoch: 6| Step: 9
Training loss: 0.7609996199607849
Validation loss: 1.8307818802454139

Epoch: 6| Step: 10
Training loss: 0.96320641040802
Validation loss: 1.888993916972991

Epoch: 6| Step: 11
Training loss: 0.9344823360443115
Validation loss: 1.817627852962863

Epoch: 6| Step: 12
Training loss: 0.6314981579780579
Validation loss: 1.8786503730281707

Epoch: 6| Step: 13
Training loss: 0.9344639182090759
Validation loss: 1.7869613247532998

Epoch: 638| Step: 0
Training loss: 0.738728404045105
Validation loss: 1.793726231462212

Epoch: 6| Step: 1
Training loss: 0.9618228673934937
Validation loss: 1.8960772355397542

Epoch: 6| Step: 2
Training loss: 1.2394165992736816
Validation loss: 1.7849146525065105

Epoch: 6| Step: 3
Training loss: 0.6753883361816406
Validation loss: 1.8509934576608802

Epoch: 6| Step: 4
Training loss: 0.569766640663147
Validation loss: 1.889841066893711

Epoch: 6| Step: 5
Training loss: 0.963909924030304
Validation loss: 1.901818222897027

Epoch: 6| Step: 6
Training loss: 1.0316482782363892
Validation loss: 1.8397314035764305

Epoch: 6| Step: 7
Training loss: 0.8661779761314392
Validation loss: 1.94380622653551

Epoch: 6| Step: 8
Training loss: 1.0690200328826904
Validation loss: 1.9089891359370241

Epoch: 6| Step: 9
Training loss: 0.5076532363891602
Validation loss: 1.8734716779442244

Epoch: 6| Step: 10
Training loss: 0.8437002301216125
Validation loss: 1.8788079574543943

Epoch: 6| Step: 11
Training loss: 0.9319474697113037
Validation loss: 1.8273170301991124

Epoch: 6| Step: 12
Training loss: 0.8332878351211548
Validation loss: 1.8046825931918236

Epoch: 6| Step: 13
Training loss: 0.9607622623443604
Validation loss: 1.796615997950236

Epoch: 639| Step: 0
Training loss: 0.9330631494522095
Validation loss: 1.8711105315916

Epoch: 6| Step: 1
Training loss: 0.6918338537216187
Validation loss: 1.8470434796425603

Epoch: 6| Step: 2
Training loss: 0.5045369863510132
Validation loss: 1.7890033055377264

Epoch: 6| Step: 3
Training loss: 0.8672031760215759
Validation loss: 1.8676970338308683

Epoch: 6| Step: 4
Training loss: 0.7896610498428345
Validation loss: 1.8318593155953191

Epoch: 6| Step: 5
Training loss: 0.8958768248558044
Validation loss: 1.8397502040350309

Epoch: 6| Step: 6
Training loss: 1.2669031620025635
Validation loss: 1.8361492156982422

Epoch: 6| Step: 7
Training loss: 1.3273954391479492
Validation loss: 1.8285218592612975

Epoch: 6| Step: 8
Training loss: 0.8420019745826721
Validation loss: 1.8360199492464784

Epoch: 6| Step: 9
Training loss: 0.8471092581748962
Validation loss: 1.8981979534190188

Epoch: 6| Step: 10
Training loss: 0.9017796516418457
Validation loss: 1.8702427341092018

Epoch: 6| Step: 11
Training loss: 0.5378154516220093
Validation loss: 1.8820472609612249

Epoch: 6| Step: 12
Training loss: 1.0687475204467773
Validation loss: 1.8783294141933482

Epoch: 6| Step: 13
Training loss: 1.073525309562683
Validation loss: 1.8869966537721696

Epoch: 640| Step: 0
Training loss: 1.0772180557250977
Validation loss: 1.8943977484139063

Epoch: 6| Step: 1
Training loss: 0.6324373483657837
Validation loss: 1.912869159893323

Epoch: 6| Step: 2
Training loss: 0.8436481952667236
Validation loss: 1.8598466457859162

Epoch: 6| Step: 3
Training loss: 1.2291767597198486
Validation loss: 1.8286282785477177

Epoch: 6| Step: 4
Training loss: 1.4430663585662842
Validation loss: 1.8340962343318488

Epoch: 6| Step: 5
Training loss: 0.8571792840957642
Validation loss: 1.8231131812577606

Epoch: 6| Step: 6
Training loss: 0.4931343197822571
Validation loss: 1.8705277507023146

Epoch: 6| Step: 7
Training loss: 0.7671900987625122
Validation loss: 1.8725567030650314

Epoch: 6| Step: 8
Training loss: 0.5339155197143555
Validation loss: 1.8625607516175957

Epoch: 6| Step: 9
Training loss: 0.7544577121734619
Validation loss: 1.8999355211052844

Epoch: 6| Step: 10
Training loss: 1.2020264863967896
Validation loss: 1.813796357441974

Epoch: 6| Step: 11
Training loss: 0.6865609884262085
Validation loss: 1.9363379350272558

Epoch: 6| Step: 12
Training loss: 1.0480502843856812
Validation loss: 1.8968763851350354

Epoch: 6| Step: 13
Training loss: 1.5551756620407104
Validation loss: 1.8288931846618652

Epoch: 641| Step: 0
Training loss: 0.5153526663780212
Validation loss: 1.8473678814467562

Epoch: 6| Step: 1
Training loss: 1.2136168479919434
Validation loss: 1.9209795203260196

Epoch: 6| Step: 2
Training loss: 0.8155614137649536
Validation loss: 1.9150598484982726

Epoch: 6| Step: 3
Training loss: 0.5861961841583252
Validation loss: 1.907212488112911

Epoch: 6| Step: 4
Training loss: 1.459681510925293
Validation loss: 1.9117491488815637

Epoch: 6| Step: 5
Training loss: 0.47992241382598877
Validation loss: 1.9511973204151276

Epoch: 6| Step: 6
Training loss: 0.9828585386276245
Validation loss: 1.8775393270677136

Epoch: 6| Step: 7
Training loss: 0.5335615873336792
Validation loss: 1.8486626173860283

Epoch: 6| Step: 8
Training loss: 0.7378924489021301
Validation loss: 1.9062330543353994

Epoch: 6| Step: 9
Training loss: 0.7540145516395569
Validation loss: 1.8710533418963033

Epoch: 6| Step: 10
Training loss: 0.9732446670532227
Validation loss: 1.7765937966685141

Epoch: 6| Step: 11
Training loss: 0.7967987060546875
Validation loss: 1.8391728490911505

Epoch: 6| Step: 12
Training loss: 1.0540156364440918
Validation loss: 1.8868290634565457

Epoch: 6| Step: 13
Training loss: 0.7350707650184631
Validation loss: 1.830248830138996

Epoch: 642| Step: 0
Training loss: 0.9646219611167908
Validation loss: 1.930335142279184

Epoch: 6| Step: 1
Training loss: 0.6154096722602844
Validation loss: 1.8368453902582969

Epoch: 6| Step: 2
Training loss: 0.8646962642669678
Validation loss: 1.8198382111005886

Epoch: 6| Step: 3
Training loss: 1.0481503009796143
Validation loss: 1.897713029256431

Epoch: 6| Step: 4
Training loss: 0.7654677629470825
Validation loss: 1.9179330795041976

Epoch: 6| Step: 5
Training loss: 0.5734779834747314
Validation loss: 1.847443760082286

Epoch: 6| Step: 6
Training loss: 1.4347766637802124
Validation loss: 1.8270995052911903

Epoch: 6| Step: 7
Training loss: 1.1836633682250977
Validation loss: 1.8187224134322135

Epoch: 6| Step: 8
Training loss: 0.9183006882667542
Validation loss: 1.8928315511313818

Epoch: 6| Step: 9
Training loss: 0.7614704966545105
Validation loss: 1.9123813798350673

Epoch: 6| Step: 10
Training loss: 0.7415235042572021
Validation loss: 1.8548036211280412

Epoch: 6| Step: 11
Training loss: 1.0044543743133545
Validation loss: 1.9387525768690212

Epoch: 6| Step: 12
Training loss: 0.6857947111129761
Validation loss: 1.8746745150576356

Epoch: 6| Step: 13
Training loss: 0.7485805153846741
Validation loss: 1.8545016293884606

Epoch: 643| Step: 0
Training loss: 0.9585620164871216
Validation loss: 1.889491791366249

Epoch: 6| Step: 1
Training loss: 0.6276724338531494
Validation loss: 1.8633761213671776

Epoch: 6| Step: 2
Training loss: 1.2023571729660034
Validation loss: 1.9030590826465237

Epoch: 6| Step: 3
Training loss: 1.073044776916504
Validation loss: 1.9372190121681458

Epoch: 6| Step: 4
Training loss: 0.8664811253547668
Validation loss: 1.878967946575534

Epoch: 6| Step: 5
Training loss: 0.7794759273529053
Validation loss: 1.9570932157578007

Epoch: 6| Step: 6
Training loss: 0.8302608728408813
Validation loss: 1.9103034773180563

Epoch: 6| Step: 7
Training loss: 0.7175648212432861
Validation loss: 1.9105955503320182

Epoch: 6| Step: 8
Training loss: 0.845897912979126
Validation loss: 1.832713234809137

Epoch: 6| Step: 9
Training loss: 1.222731113433838
Validation loss: 1.9243815086221183

Epoch: 6| Step: 10
Training loss: 0.8580589294433594
Validation loss: 1.875722582622241

Epoch: 6| Step: 11
Training loss: 0.9191738367080688
Validation loss: 1.9933469474956553

Epoch: 6| Step: 12
Training loss: 0.5117483139038086
Validation loss: 1.8311003600397417

Epoch: 6| Step: 13
Training loss: 1.1460140943527222
Validation loss: 1.8755156045318933

Epoch: 644| Step: 0
Training loss: 0.6861850023269653
Validation loss: 1.8822117749080862

Epoch: 6| Step: 1
Training loss: 0.8560638427734375
Validation loss: 1.790837610921552

Epoch: 6| Step: 2
Training loss: 0.9545212984085083
Validation loss: 1.9490523222954041

Epoch: 6| Step: 3
Training loss: 0.7793475389480591
Validation loss: 1.8590209458463935

Epoch: 6| Step: 4
Training loss: 1.4613502025604248
Validation loss: 1.877075126094203

Epoch: 6| Step: 5
Training loss: 1.0120835304260254
Validation loss: 1.9393606775550432

Epoch: 6| Step: 6
Training loss: 0.9820652008056641
Validation loss: 1.8921396591330086

Epoch: 6| Step: 7
Training loss: 0.5367797613143921
Validation loss: 1.9367799810183945

Epoch: 6| Step: 8
Training loss: 0.7028586268424988
Validation loss: 1.9023645411255539

Epoch: 6| Step: 9
Training loss: 0.7026575803756714
Validation loss: 1.945605690761279

Epoch: 6| Step: 10
Training loss: 0.8835844993591309
Validation loss: 1.8797294503899031

Epoch: 6| Step: 11
Training loss: 0.8482872843742371
Validation loss: 1.8983584039954728

Epoch: 6| Step: 12
Training loss: 1.4359275102615356
Validation loss: 1.8760498762130737

Epoch: 6| Step: 13
Training loss: 0.42374399304389954
Validation loss: 1.7952429914987216

Epoch: 645| Step: 0
Training loss: 0.9335184097290039
Validation loss: 1.8801842761296097

Epoch: 6| Step: 1
Training loss: 0.6619915962219238
Validation loss: 1.8462852278063375

Epoch: 6| Step: 2
Training loss: 0.8863351345062256
Validation loss: 1.8414386280121342

Epoch: 6| Step: 3
Training loss: 1.0692412853240967
Validation loss: 1.8048200466299569

Epoch: 6| Step: 4
Training loss: 0.6453048586845398
Validation loss: 1.8338680139151953

Epoch: 6| Step: 5
Training loss: 0.6444447040557861
Validation loss: 1.8457667366150887

Epoch: 6| Step: 6
Training loss: 1.2049410343170166
Validation loss: 1.812977542159378

Epoch: 6| Step: 7
Training loss: 1.0972874164581299
Validation loss: 1.8732823453923708

Epoch: 6| Step: 8
Training loss: 1.1576292514801025
Validation loss: 1.867331604803762

Epoch: 6| Step: 9
Training loss: 0.6285738348960876
Validation loss: 1.9394254966448712

Epoch: 6| Step: 10
Training loss: 1.1930067539215088
Validation loss: 1.8464996891637002

Epoch: 6| Step: 11
Training loss: 0.588823676109314
Validation loss: 1.8707972970060123

Epoch: 6| Step: 12
Training loss: 0.9940386414527893
Validation loss: 1.8692443870729016

Epoch: 6| Step: 13
Training loss: 0.3305004835128784
Validation loss: 1.835049170319752

Epoch: 646| Step: 0
Training loss: 0.6891398429870605
Validation loss: 1.8701615551466584

Epoch: 6| Step: 1
Training loss: 0.5995566844940186
Validation loss: 1.91195390301366

Epoch: 6| Step: 2
Training loss: 0.912805438041687
Validation loss: 1.8965705876709313

Epoch: 6| Step: 3
Training loss: 1.3498895168304443
Validation loss: 1.9040909390295706

Epoch: 6| Step: 4
Training loss: 1.274799108505249
Validation loss: 1.8196525355821014

Epoch: 6| Step: 5
Training loss: 0.6946461200714111
Validation loss: 1.8714617824041715

Epoch: 6| Step: 6
Training loss: 1.0616741180419922
Validation loss: 1.8622011330819899

Epoch: 6| Step: 7
Training loss: 0.7179778218269348
Validation loss: 1.8531518341392599

Epoch: 6| Step: 8
Training loss: 1.1830459833145142
Validation loss: 1.7773396251022175

Epoch: 6| Step: 9
Training loss: 1.0164415836334229
Validation loss: 1.831430119852866

Epoch: 6| Step: 10
Training loss: 1.1008950471878052
Validation loss: 1.8797168834235078

Epoch: 6| Step: 11
Training loss: 0.6765984892845154
Validation loss: 1.8861287614350677

Epoch: 6| Step: 12
Training loss: 0.8400918245315552
Validation loss: 1.8616966361640601

Epoch: 6| Step: 13
Training loss: 0.15192127227783203
Validation loss: 1.9384705969082412

Epoch: 647| Step: 0
Training loss: 1.0287184715270996
Validation loss: 1.8550814390182495

Epoch: 6| Step: 1
Training loss: 0.8380903601646423
Validation loss: 1.881617017971572

Epoch: 6| Step: 2
Training loss: 0.8253146409988403
Validation loss: 1.8823427948900449

Epoch: 6| Step: 3
Training loss: 0.6237955689430237
Validation loss: 1.9445563234308714

Epoch: 6| Step: 4
Training loss: 0.945173442363739
Validation loss: 1.8015795497484104

Epoch: 6| Step: 5
Training loss: 0.7772970199584961
Validation loss: 1.8317092554543608

Epoch: 6| Step: 6
Training loss: 0.6329270005226135
Validation loss: 1.8623446418393044

Epoch: 6| Step: 7
Training loss: 0.5272057056427002
Validation loss: 1.7977962263168827

Epoch: 6| Step: 8
Training loss: 1.378157138824463
Validation loss: 1.8802767094745432

Epoch: 6| Step: 9
Training loss: 0.8845664858818054
Validation loss: 1.906068717279742

Epoch: 6| Step: 10
Training loss: 1.0870747566223145
Validation loss: 1.8848643431099512

Epoch: 6| Step: 11
Training loss: 0.8764058351516724
Validation loss: 1.837453556317155

Epoch: 6| Step: 12
Training loss: 0.9853820204734802
Validation loss: 1.8757628138347338

Epoch: 6| Step: 13
Training loss: 1.6142336130142212
Validation loss: 1.8794264101213025

Epoch: 648| Step: 0
Training loss: 0.5761774182319641
Validation loss: 1.8648767702041134

Epoch: 6| Step: 1
Training loss: 1.349759578704834
Validation loss: 1.853380839029948

Epoch: 6| Step: 2
Training loss: 0.7126047611236572
Validation loss: 1.8284012579148816

Epoch: 6| Step: 3
Training loss: 1.0550541877746582
Validation loss: 1.9145936607032694

Epoch: 6| Step: 4
Training loss: 0.9326474070549011
Validation loss: 1.9111017693755448

Epoch: 6| Step: 5
Training loss: 1.3050404787063599
Validation loss: 1.8979238745986775

Epoch: 6| Step: 6
Training loss: 1.013237476348877
Validation loss: 1.9025164496514104

Epoch: 6| Step: 7
Training loss: 0.6442742943763733
Validation loss: 1.9086969949865853

Epoch: 6| Step: 8
Training loss: 0.6892783641815186
Validation loss: 1.8432213491009128

Epoch: 6| Step: 9
Training loss: 0.5906394720077515
Validation loss: 1.900851652186404

Epoch: 6| Step: 10
Training loss: 0.6949009299278259
Validation loss: 1.8185251092398038

Epoch: 6| Step: 11
Training loss: 0.928470253944397
Validation loss: 1.8436321263672204

Epoch: 6| Step: 12
Training loss: 0.814665675163269
Validation loss: 1.880469532423122

Epoch: 6| Step: 13
Training loss: 0.5215370655059814
Validation loss: 1.8689084604222288

Epoch: 649| Step: 0
Training loss: 0.4473901093006134
Validation loss: 1.817134363676912

Epoch: 6| Step: 1
Training loss: 0.7289485335350037
Validation loss: 1.8386878698102889

Epoch: 6| Step: 2
Training loss: 0.6952422857284546
Validation loss: 1.8897716204325359

Epoch: 6| Step: 3
Training loss: 0.7953699827194214
Validation loss: 1.8418185108451433

Epoch: 6| Step: 4
Training loss: 0.5964143872261047
Validation loss: 1.8388504469266502

Epoch: 6| Step: 5
Training loss: 0.9280794858932495
Validation loss: 1.9354646641721007

Epoch: 6| Step: 6
Training loss: 0.9796230792999268
Validation loss: 1.900467077891032

Epoch: 6| Step: 7
Training loss: 1.2084088325500488
Validation loss: 1.8730012832149383

Epoch: 6| Step: 8
Training loss: 1.1517796516418457
Validation loss: 1.7893823667239117

Epoch: 6| Step: 9
Training loss: 1.1641497611999512
Validation loss: 1.8537848687941028

Epoch: 6| Step: 10
Training loss: 1.0528242588043213
Validation loss: 1.9101246223654798

Epoch: 6| Step: 11
Training loss: 1.1274569034576416
Validation loss: 1.879554594716718

Epoch: 6| Step: 12
Training loss: 0.7167036533355713
Validation loss: 1.8660336386772893

Epoch: 6| Step: 13
Training loss: 1.1132545471191406
Validation loss: 1.8829217277547365

Epoch: 650| Step: 0
Training loss: 1.406598448753357
Validation loss: 1.844169186007592

Epoch: 6| Step: 1
Training loss: 1.0703965425491333
Validation loss: 1.857237865847926

Epoch: 6| Step: 2
Training loss: 0.38556531071662903
Validation loss: 1.8987922091637888

Epoch: 6| Step: 3
Training loss: 0.7481183409690857
Validation loss: 1.8823260043257026

Epoch: 6| Step: 4
Training loss: 0.4364173710346222
Validation loss: 1.794974753933568

Epoch: 6| Step: 5
Training loss: 1.0146993398666382
Validation loss: 1.8736888964970906

Epoch: 6| Step: 6
Training loss: 0.7154169082641602
Validation loss: 1.9049186706542969

Epoch: 6| Step: 7
Training loss: 1.110874891281128
Validation loss: 1.998677404977942

Epoch: 6| Step: 8
Training loss: 1.3098540306091309
Validation loss: 1.827498787192888

Epoch: 6| Step: 9
Training loss: 0.894572377204895
Validation loss: 1.8612724734890846

Epoch: 6| Step: 10
Training loss: 0.7922084331512451
Validation loss: 1.8617792539699103

Epoch: 6| Step: 11
Training loss: 0.7076734304428101
Validation loss: 1.8716577996489823

Epoch: 6| Step: 12
Training loss: 0.7584860324859619
Validation loss: 1.9436285905940558

Epoch: 6| Step: 13
Training loss: 0.550197958946228
Validation loss: 1.904455343882243

Epoch: 651| Step: 0
Training loss: 0.9789260029792786
Validation loss: 1.8810072791191839

Epoch: 6| Step: 1
Training loss: 0.5389173030853271
Validation loss: 1.867062178991174

Epoch: 6| Step: 2
Training loss: 1.719212293624878
Validation loss: 1.8434682251304708

Epoch: 6| Step: 3
Training loss: 0.6763707399368286
Validation loss: 1.8282291504644579

Epoch: 6| Step: 4
Training loss: 0.5426119565963745
Validation loss: 1.8247323818104242

Epoch: 6| Step: 5
Training loss: 0.9265817999839783
Validation loss: 1.881874426718681

Epoch: 6| Step: 6
Training loss: 0.9011551737785339
Validation loss: 1.8035892196880874

Epoch: 6| Step: 7
Training loss: 0.5886421203613281
Validation loss: 1.8706341328159455

Epoch: 6| Step: 8
Training loss: 1.3375881910324097
Validation loss: 1.8750682466773576

Epoch: 6| Step: 9
Training loss: 0.7392452955245972
Validation loss: 1.8057024517366964

Epoch: 6| Step: 10
Training loss: 0.7226820588111877
Validation loss: 1.8557074416068293

Epoch: 6| Step: 11
Training loss: 0.8505597710609436
Validation loss: 1.8097452963552167

Epoch: 6| Step: 12
Training loss: 0.8508719205856323
Validation loss: 1.8484162310118317

Epoch: 6| Step: 13
Training loss: 0.9603737592697144
Validation loss: 1.8773711906966342

Epoch: 652| Step: 0
Training loss: 0.9142618179321289
Validation loss: 1.860070110649191

Epoch: 6| Step: 1
Training loss: 0.8248283863067627
Validation loss: 1.845840859156783

Epoch: 6| Step: 2
Training loss: 0.6431117057800293
Validation loss: 1.8390875939399964

Epoch: 6| Step: 3
Training loss: 1.3089277744293213
Validation loss: 1.8526936295211955

Epoch: 6| Step: 4
Training loss: 0.9349814653396606
Validation loss: 1.9012863841108096

Epoch: 6| Step: 5
Training loss: 0.6026423573493958
Validation loss: 1.8408959193896222

Epoch: 6| Step: 6
Training loss: 0.7577115893363953
Validation loss: 1.845993100955922

Epoch: 6| Step: 7
Training loss: 1.0670537948608398
Validation loss: 1.8614477918994041

Epoch: 6| Step: 8
Training loss: 0.7740787267684937
Validation loss: 1.7925877724924395

Epoch: 6| Step: 9
Training loss: 0.6500977277755737
Validation loss: 1.7841777416967577

Epoch: 6| Step: 10
Training loss: 0.8341418504714966
Validation loss: 1.8519433159982004

Epoch: 6| Step: 11
Training loss: 0.7953201532363892
Validation loss: 1.8658510561912292

Epoch: 6| Step: 12
Training loss: 0.8475962281227112
Validation loss: 1.8060708417687366

Epoch: 6| Step: 13
Training loss: 1.0305334329605103
Validation loss: 1.8164097083512174

Epoch: 653| Step: 0
Training loss: 1.1636601686477661
Validation loss: 1.8450306666794645

Epoch: 6| Step: 1
Training loss: 1.2887609004974365
Validation loss: 1.8364925461430703

Epoch: 6| Step: 2
Training loss: 0.8124950528144836
Validation loss: 1.8447075454137658

Epoch: 6| Step: 3
Training loss: 0.5672266483306885
Validation loss: 1.8348557103064753

Epoch: 6| Step: 4
Training loss: 0.7727478742599487
Validation loss: 1.9216899769280547

Epoch: 6| Step: 5
Training loss: 0.9238929748535156
Validation loss: 1.937557863932784

Epoch: 6| Step: 6
Training loss: 0.9446383118629456
Validation loss: 1.8985198723372592

Epoch: 6| Step: 7
Training loss: 1.1745188236236572
Validation loss: 1.9078109764283704

Epoch: 6| Step: 8
Training loss: 0.7034647464752197
Validation loss: 1.791937199972009

Epoch: 6| Step: 9
Training loss: 1.1751186847686768
Validation loss: 1.8276570061201691

Epoch: 6| Step: 10
Training loss: 0.701266884803772
Validation loss: 1.745558815617715

Epoch: 6| Step: 11
Training loss: 0.8385474681854248
Validation loss: 1.8617259943357078

Epoch: 6| Step: 12
Training loss: 0.6645426750183105
Validation loss: 1.8431223028449601

Epoch: 6| Step: 13
Training loss: 1.0123416185379028
Validation loss: 1.8449213274063603

Epoch: 654| Step: 0
Training loss: 1.2493864297866821
Validation loss: 1.8171631033702562

Epoch: 6| Step: 1
Training loss: 1.0302672386169434
Validation loss: 1.8257410205820555

Epoch: 6| Step: 2
Training loss: 0.9478501081466675
Validation loss: 1.8147207690823464

Epoch: 6| Step: 3
Training loss: 0.45253053307533264
Validation loss: 1.7916139101469388

Epoch: 6| Step: 4
Training loss: 0.8243728876113892
Validation loss: 1.835132416858468

Epoch: 6| Step: 5
Training loss: 0.6237308979034424
Validation loss: 1.8789738198762298

Epoch: 6| Step: 6
Training loss: 0.9329707622528076
Validation loss: 1.8926637711063508

Epoch: 6| Step: 7
Training loss: 0.8424935340881348
Validation loss: 1.8981710082741194

Epoch: 6| Step: 8
Training loss: 0.8063840866088867
Validation loss: 1.8839388662768948

Epoch: 6| Step: 9
Training loss: 1.101389765739441
Validation loss: 1.8790021481052521

Epoch: 6| Step: 10
Training loss: 1.0894207954406738
Validation loss: 1.9197015172691756

Epoch: 6| Step: 11
Training loss: 0.8266791701316833
Validation loss: 1.8821628119355889

Epoch: 6| Step: 12
Training loss: 0.7339096069335938
Validation loss: 1.9392676545727638

Epoch: 6| Step: 13
Training loss: 1.623437762260437
Validation loss: 1.8327267836498957

Epoch: 655| Step: 0
Training loss: 0.7449346780776978
Validation loss: 1.890450946746334

Epoch: 6| Step: 1
Training loss: 1.0881247520446777
Validation loss: 1.8182439829713555

Epoch: 6| Step: 2
Training loss: 0.6689658164978027
Validation loss: 1.762186606725057

Epoch: 6| Step: 3
Training loss: 1.3257049322128296
Validation loss: 1.85313428601911

Epoch: 6| Step: 4
Training loss: 1.1850175857543945
Validation loss: 1.8324750546486146

Epoch: 6| Step: 5
Training loss: 0.9334482550621033
Validation loss: 1.8223609437224686

Epoch: 6| Step: 6
Training loss: 0.8657956123352051
Validation loss: 1.8523371732363136

Epoch: 6| Step: 7
Training loss: 0.9947754144668579
Validation loss: 1.8305640733370216

Epoch: 6| Step: 8
Training loss: 0.7469871044158936
Validation loss: 1.8096255794648202

Epoch: 6| Step: 9
Training loss: 0.7771393060684204
Validation loss: 1.8367605683624104

Epoch: 6| Step: 10
Training loss: 0.749589204788208
Validation loss: 1.8401287422385266

Epoch: 6| Step: 11
Training loss: 0.7405585050582886
Validation loss: 1.8632232130214732

Epoch: 6| Step: 12
Training loss: 0.8728435039520264
Validation loss: 1.8223889130418018

Epoch: 6| Step: 13
Training loss: 0.5514796376228333
Validation loss: 1.8576477868582613

Epoch: 656| Step: 0
Training loss: 0.6107556223869324
Validation loss: 1.8911307063153995

Epoch: 6| Step: 1
Training loss: 0.882361114025116
Validation loss: 1.8576894434549476

Epoch: 6| Step: 2
Training loss: 1.032565951347351
Validation loss: 1.865564969278151

Epoch: 6| Step: 3
Training loss: 0.7061340808868408
Validation loss: 1.8556820449008737

Epoch: 6| Step: 4
Training loss: 0.5636341571807861
Validation loss: 1.85400785938386

Epoch: 6| Step: 5
Training loss: 0.8496677279472351
Validation loss: 1.9503654818381033

Epoch: 6| Step: 6
Training loss: 0.8224812746047974
Validation loss: 1.8629911586802492

Epoch: 6| Step: 7
Training loss: 0.6224881410598755
Validation loss: 1.8263961269009499

Epoch: 6| Step: 8
Training loss: 0.8980359435081482
Validation loss: 1.8526142566434798

Epoch: 6| Step: 9
Training loss: 1.013176441192627
Validation loss: 1.8555551575076195

Epoch: 6| Step: 10
Training loss: 0.9716125726699829
Validation loss: 1.8998488687699842

Epoch: 6| Step: 11
Training loss: 1.029658555984497
Validation loss: 1.8792036887138122

Epoch: 6| Step: 12
Training loss: 0.6380431652069092
Validation loss: 1.827935129083613

Epoch: 6| Step: 13
Training loss: 2.120861768722534
Validation loss: 1.8640331209346812

Epoch: 657| Step: 0
Training loss: 0.838410496711731
Validation loss: 1.8706871924861785

Epoch: 6| Step: 1
Training loss: 0.6421148777008057
Validation loss: 1.8714137948969358

Epoch: 6| Step: 2
Training loss: 1.2498383522033691
Validation loss: 1.7802756576127903

Epoch: 6| Step: 3
Training loss: 0.7664388418197632
Validation loss: 1.9019267712869952

Epoch: 6| Step: 4
Training loss: 1.0510073900222778
Validation loss: 1.8889085221034225

Epoch: 6| Step: 5
Training loss: 0.9089775085449219
Validation loss: 1.8007082951966153

Epoch: 6| Step: 6
Training loss: 0.8994453549385071
Validation loss: 1.8833087669905795

Epoch: 6| Step: 7
Training loss: 1.0652827024459839
Validation loss: 1.8267699441602152

Epoch: 6| Step: 8
Training loss: 0.8722610473632812
Validation loss: 1.8219970926161735

Epoch: 6| Step: 9
Training loss: 0.5416133403778076
Validation loss: 1.8973059551690215

Epoch: 6| Step: 10
Training loss: 0.8211649060249329
Validation loss: 1.8808417127978416

Epoch: 6| Step: 11
Training loss: 0.6519112586975098
Validation loss: 1.8562677265495382

Epoch: 6| Step: 12
Training loss: 1.0337835550308228
Validation loss: 1.7935062070046701

Epoch: 6| Step: 13
Training loss: 0.5121703743934631
Validation loss: 1.7692829678135533

Epoch: 658| Step: 0
Training loss: 0.75517737865448
Validation loss: 1.8665471461511427

Epoch: 6| Step: 1
Training loss: 1.0572164058685303
Validation loss: 1.8016109620371172

Epoch: 6| Step: 2
Training loss: 1.059473991394043
Validation loss: 1.8689782773294756

Epoch: 6| Step: 3
Training loss: 1.0805304050445557
Validation loss: 1.8466625892987816

Epoch: 6| Step: 4
Training loss: 0.6335042715072632
Validation loss: 1.854986011341054

Epoch: 6| Step: 5
Training loss: 0.8840847015380859
Validation loss: 1.9098024855377853

Epoch: 6| Step: 6
Training loss: 0.6716752052307129
Validation loss: 1.807808283836611

Epoch: 6| Step: 7
Training loss: 0.7522443532943726
Validation loss: 1.9180840215375345

Epoch: 6| Step: 8
Training loss: 0.7188434600830078
Validation loss: 1.8576462422647784

Epoch: 6| Step: 9
Training loss: 0.9750655293464661
Validation loss: 1.8816454564371417

Epoch: 6| Step: 10
Training loss: 0.729970395565033
Validation loss: 1.9257166898378761

Epoch: 6| Step: 11
Training loss: 1.1574766635894775
Validation loss: 1.8784072065866122

Epoch: 6| Step: 12
Training loss: 0.7542322874069214
Validation loss: 1.8476789113013976

Epoch: 6| Step: 13
Training loss: 0.5788482427597046
Validation loss: 1.8407149161061933

Epoch: 659| Step: 0
Training loss: 0.8846477270126343
Validation loss: 1.815577612128309

Epoch: 6| Step: 1
Training loss: 0.8936138153076172
Validation loss: 1.8554832140604656

Epoch: 6| Step: 2
Training loss: 0.734653651714325
Validation loss: 1.8598429925980107

Epoch: 6| Step: 3
Training loss: 1.0951045751571655
Validation loss: 1.7735256943651425

Epoch: 6| Step: 4
Training loss: 0.9697935581207275
Validation loss: 1.8955978949864705

Epoch: 6| Step: 5
Training loss: 0.5972390174865723
Validation loss: 1.8008572286175144

Epoch: 6| Step: 6
Training loss: 1.2046822309494019
Validation loss: 1.884463470469239

Epoch: 6| Step: 7
Training loss: 0.5246134400367737
Validation loss: 1.8722860351685555

Epoch: 6| Step: 8
Training loss: 0.6320062279701233
Validation loss: 1.8988481413933538

Epoch: 6| Step: 9
Training loss: 0.46395257115364075
Validation loss: 1.9592160794042772

Epoch: 6| Step: 10
Training loss: 0.9839953184127808
Validation loss: 1.9725317724289433

Epoch: 6| Step: 11
Training loss: 1.4310133457183838
Validation loss: 1.8949366987392466

Epoch: 6| Step: 12
Training loss: 0.8274429440498352
Validation loss: 1.950390346588627

Epoch: 6| Step: 13
Training loss: 1.6719920635223389
Validation loss: 1.8855696185942619

Epoch: 660| Step: 0
Training loss: 0.8594081401824951
Validation loss: 1.8898275718894055

Epoch: 6| Step: 1
Training loss: 0.9737957715988159
Validation loss: 1.8230819112511092

Epoch: 6| Step: 2
Training loss: 0.4658961296081543
Validation loss: 1.8662196923327703

Epoch: 6| Step: 3
Training loss: 1.0071024894714355
Validation loss: 1.7903821378625848

Epoch: 6| Step: 4
Training loss: 1.186137318611145
Validation loss: 1.8116049458903651

Epoch: 6| Step: 5
Training loss: 1.0887237787246704
Validation loss: 1.8343519215942712

Epoch: 6| Step: 6
Training loss: 1.060057282447815
Validation loss: 1.808928346121183

Epoch: 6| Step: 7
Training loss: 0.7800840139389038
Validation loss: 1.83191886127636

Epoch: 6| Step: 8
Training loss: 0.7456064820289612
Validation loss: 1.805723262089555

Epoch: 6| Step: 9
Training loss: 1.0201737880706787
Validation loss: 1.9119807994493874

Epoch: 6| Step: 10
Training loss: 0.7631047368049622
Validation loss: 1.8241014224226757

Epoch: 6| Step: 11
Training loss: 0.9578547477722168
Validation loss: 1.8478715214678036

Epoch: 6| Step: 12
Training loss: 0.8091723322868347
Validation loss: 1.9005067079297957

Epoch: 6| Step: 13
Training loss: 0.6306756734848022
Validation loss: 1.8894785347805227

Epoch: 661| Step: 0
Training loss: 1.0827476978302002
Validation loss: 1.8403911975122267

Epoch: 6| Step: 1
Training loss: 1.0121866464614868
Validation loss: 1.8326697785367247

Epoch: 6| Step: 2
Training loss: 0.5985594987869263
Validation loss: 1.854936288249108

Epoch: 6| Step: 3
Training loss: 0.8379840850830078
Validation loss: 1.9057521922613985

Epoch: 6| Step: 4
Training loss: 1.1716686487197876
Validation loss: 1.832097335528302

Epoch: 6| Step: 5
Training loss: 0.6960063576698303
Validation loss: 1.8738756871992541

Epoch: 6| Step: 6
Training loss: 0.4256904721260071
Validation loss: 1.9095633645211496

Epoch: 6| Step: 7
Training loss: 0.767015814781189
Validation loss: 1.9023090434330765

Epoch: 6| Step: 8
Training loss: 0.7574583888053894
Validation loss: 1.8187479280656385

Epoch: 6| Step: 9
Training loss: 0.7222892045974731
Validation loss: 1.8619196850766417

Epoch: 6| Step: 10
Training loss: 0.5551192164421082
Validation loss: 1.8169732644993772

Epoch: 6| Step: 11
Training loss: 1.1887891292572021
Validation loss: 1.9069880849571639

Epoch: 6| Step: 12
Training loss: 0.8236621618270874
Validation loss: 1.8675762132931781

Epoch: 6| Step: 13
Training loss: 1.1985887289047241
Validation loss: 1.8838723705660911

Epoch: 662| Step: 0
Training loss: 1.0967998504638672
Validation loss: 1.825412452861827

Epoch: 6| Step: 1
Training loss: 0.528967022895813
Validation loss: 1.8022922879906111

Epoch: 6| Step: 2
Training loss: 0.8569546937942505
Validation loss: 1.817390271412429

Epoch: 6| Step: 3
Training loss: 0.6903796195983887
Validation loss: 1.8527098676209808

Epoch: 6| Step: 4
Training loss: 0.7060933113098145
Validation loss: 1.7787424787398307

Epoch: 6| Step: 5
Training loss: 0.7468935251235962
Validation loss: 1.8375608972323838

Epoch: 6| Step: 6
Training loss: 0.8477494716644287
Validation loss: 1.7963820349785589

Epoch: 6| Step: 7
Training loss: 1.196272373199463
Validation loss: 1.8139362155750234

Epoch: 6| Step: 8
Training loss: 0.8487327098846436
Validation loss: 1.8915044376927037

Epoch: 6| Step: 9
Training loss: 0.8149275779724121
Validation loss: 1.8278010506783762

Epoch: 6| Step: 10
Training loss: 1.0228930711746216
Validation loss: 1.7562455169616207

Epoch: 6| Step: 11
Training loss: 1.6094379425048828
Validation loss: 1.805760532297114

Epoch: 6| Step: 12
Training loss: 0.6252620816230774
Validation loss: 1.8209193893658218

Epoch: 6| Step: 13
Training loss: 0.3335495591163635
Validation loss: 1.9260697954444475

Epoch: 663| Step: 0
Training loss: 0.7657095193862915
Validation loss: 1.8690754521277644

Epoch: 6| Step: 1
Training loss: 0.9465519189834595
Validation loss: 1.8742864747201242

Epoch: 6| Step: 2
Training loss: 0.8618689775466919
Validation loss: 1.8784279195211266

Epoch: 6| Step: 3
Training loss: 0.7248326539993286
Validation loss: 1.9803210919903171

Epoch: 6| Step: 4
Training loss: 1.0005590915679932
Validation loss: 1.9350374462783977

Epoch: 6| Step: 5
Training loss: 1.0826292037963867
Validation loss: 1.8691519947462185

Epoch: 6| Step: 6
Training loss: 0.8822360038757324
Validation loss: 1.8382318635140695

Epoch: 6| Step: 7
Training loss: 0.9837155938148499
Validation loss: 1.8311521750624462

Epoch: 6| Step: 8
Training loss: 0.5602875351905823
Validation loss: 1.843278492650678

Epoch: 6| Step: 9
Training loss: 0.9260429739952087
Validation loss: 1.7790942858624201

Epoch: 6| Step: 10
Training loss: 1.0920584201812744
Validation loss: 1.7776978477354972

Epoch: 6| Step: 11
Training loss: 0.8024426102638245
Validation loss: 1.8519140597312682

Epoch: 6| Step: 12
Training loss: 0.6911243796348572
Validation loss: 1.7783781738691433

Epoch: 6| Step: 13
Training loss: 1.3011231422424316
Validation loss: 1.813331587340242

Epoch: 664| Step: 0
Training loss: 0.6207829117774963
Validation loss: 1.78799569606781

Epoch: 6| Step: 1
Training loss: 1.2562072277069092
Validation loss: 1.7988479509148547

Epoch: 6| Step: 2
Training loss: 1.0519181489944458
Validation loss: 1.7981478296300417

Epoch: 6| Step: 3
Training loss: 1.1080245971679688
Validation loss: 1.9096526035698511

Epoch: 6| Step: 4
Training loss: 0.8047078251838684
Validation loss: 1.7934475047613985

Epoch: 6| Step: 5
Training loss: 0.6111993789672852
Validation loss: 1.9358080599897651

Epoch: 6| Step: 6
Training loss: 0.674286961555481
Validation loss: 1.9172341233940535

Epoch: 6| Step: 7
Training loss: 1.0706779956817627
Validation loss: 1.8784976274736467

Epoch: 6| Step: 8
Training loss: 0.6127098798751831
Validation loss: 1.945474455433507

Epoch: 6| Step: 9
Training loss: 1.017703652381897
Validation loss: 1.8851125958145305

Epoch: 6| Step: 10
Training loss: 0.8118605017662048
Validation loss: 1.930201433038199

Epoch: 6| Step: 11
Training loss: 0.965247631072998
Validation loss: 1.8709293219351

Epoch: 6| Step: 12
Training loss: 1.350632905960083
Validation loss: 1.8579871885238155

Epoch: 6| Step: 13
Training loss: 0.7081995606422424
Validation loss: 1.8378022178526847

Epoch: 665| Step: 0
Training loss: 0.4602614939212799
Validation loss: 1.8285215170152727

Epoch: 6| Step: 1
Training loss: 1.0064984560012817
Validation loss: 1.887022154305571

Epoch: 6| Step: 2
Training loss: 0.6325293183326721
Validation loss: 1.8931867089322818

Epoch: 6| Step: 3
Training loss: 0.917034387588501
Validation loss: 1.7998786998051468

Epoch: 6| Step: 4
Training loss: 0.6594786047935486
Validation loss: 1.8871181177836593

Epoch: 6| Step: 5
Training loss: 0.6776745915412903
Validation loss: 1.8827874301582255

Epoch: 6| Step: 6
Training loss: 1.1518363952636719
Validation loss: 1.8746817957970403

Epoch: 6| Step: 7
Training loss: 0.8374390602111816
Validation loss: 1.8242925956685057

Epoch: 6| Step: 8
Training loss: 1.1191661357879639
Validation loss: 1.8039256808578328

Epoch: 6| Step: 9
Training loss: 1.0685051679611206
Validation loss: 1.831654901145607

Epoch: 6| Step: 10
Training loss: 1.1163506507873535
Validation loss: 1.9075262687539543

Epoch: 6| Step: 11
Training loss: 0.9199315309524536
Validation loss: 1.8569932676130725

Epoch: 6| Step: 12
Training loss: 0.5959301590919495
Validation loss: 1.9213834577991116

Epoch: 6| Step: 13
Training loss: 0.6797820329666138
Validation loss: 1.895783350031863

Epoch: 666| Step: 0
Training loss: 1.0349243879318237
Validation loss: 1.8785781501441874

Epoch: 6| Step: 1
Training loss: 1.2235281467437744
Validation loss: 1.9259074811012513

Epoch: 6| Step: 2
Training loss: 0.8124065399169922
Validation loss: 1.8155322561981857

Epoch: 6| Step: 3
Training loss: 0.7648093700408936
Validation loss: 1.8907728707918556

Epoch: 6| Step: 4
Training loss: 0.7286069989204407
Validation loss: 1.8795681743211643

Epoch: 6| Step: 5
Training loss: 0.45124953985214233
Validation loss: 1.8855242498459355

Epoch: 6| Step: 6
Training loss: 0.5430905222892761
Validation loss: 1.8204082224958686

Epoch: 6| Step: 7
Training loss: 0.7305389642715454
Validation loss: 1.872082782048051

Epoch: 6| Step: 8
Training loss: 0.5150056481361389
Validation loss: 1.8475358511811943

Epoch: 6| Step: 9
Training loss: 0.8216120004653931
Validation loss: 1.8090528595832087

Epoch: 6| Step: 10
Training loss: 1.1774821281433105
Validation loss: 1.8305579718723093

Epoch: 6| Step: 11
Training loss: 0.8560478687286377
Validation loss: 1.8142422097985462

Epoch: 6| Step: 12
Training loss: 0.7764459848403931
Validation loss: 1.8480937378380888

Epoch: 6| Step: 13
Training loss: 0.6684311628341675
Validation loss: 1.7598540770110263

Epoch: 667| Step: 0
Training loss: 0.6306923627853394
Validation loss: 1.8608594222735333

Epoch: 6| Step: 1
Training loss: 0.7506312131881714
Validation loss: 1.8453451459125807

Epoch: 6| Step: 2
Training loss: 0.8360989093780518
Validation loss: 1.8589991574646325

Epoch: 6| Step: 3
Training loss: 0.6195328831672668
Validation loss: 1.8826814710452993

Epoch: 6| Step: 4
Training loss: 0.8466609716415405
Validation loss: 1.8604186657936341

Epoch: 6| Step: 5
Training loss: 0.7599104046821594
Validation loss: 1.876902731516028

Epoch: 6| Step: 6
Training loss: 0.9897228479385376
Validation loss: 1.78778076171875

Epoch: 6| Step: 7
Training loss: 1.1107192039489746
Validation loss: 1.82426695669851

Epoch: 6| Step: 8
Training loss: 0.9207210540771484
Validation loss: 1.8593742462896532

Epoch: 6| Step: 9
Training loss: 0.5695645213127136
Validation loss: 1.8217668789689259

Epoch: 6| Step: 10
Training loss: 0.9935046434402466
Validation loss: 1.8021113898164483

Epoch: 6| Step: 11
Training loss: 0.8460150957107544
Validation loss: 1.8445643904388591

Epoch: 6| Step: 12
Training loss: 0.697908878326416
Validation loss: 1.8298830075930523

Epoch: 6| Step: 13
Training loss: 1.207891821861267
Validation loss: 1.8253340541675527

Epoch: 668| Step: 0
Training loss: 0.6702275276184082
Validation loss: 1.8751657419307257

Epoch: 6| Step: 1
Training loss: 1.1522808074951172
Validation loss: 1.8088003550806353

Epoch: 6| Step: 2
Training loss: 1.0893057584762573
Validation loss: 1.8769498602036507

Epoch: 6| Step: 3
Training loss: 0.8687806725502014
Validation loss: 1.8659733956859959

Epoch: 6| Step: 4
Training loss: 0.9090762138366699
Validation loss: 1.8561925580424647

Epoch: 6| Step: 5
Training loss: 1.0951175689697266
Validation loss: 1.8394429017138738

Epoch: 6| Step: 6
Training loss: 0.8059287071228027
Validation loss: 1.842850128809611

Epoch: 6| Step: 7
Training loss: 0.8237742185592651
Validation loss: 1.8858854463023524

Epoch: 6| Step: 8
Training loss: 0.8906714916229248
Validation loss: 1.8616213362704042

Epoch: 6| Step: 9
Training loss: 1.0518759489059448
Validation loss: 1.8741716261832946

Epoch: 6| Step: 10
Training loss: 0.7618119716644287
Validation loss: 1.860058553757206

Epoch: 6| Step: 11
Training loss: 0.7400462627410889
Validation loss: 1.8616514334114649

Epoch: 6| Step: 12
Training loss: 0.7662534713745117
Validation loss: 1.8208646274382068

Epoch: 6| Step: 13
Training loss: 0.5635377764701843
Validation loss: 1.8824291421521095

Epoch: 669| Step: 0
Training loss: 1.192252516746521
Validation loss: 1.8796066750762284

Epoch: 6| Step: 1
Training loss: 0.8793088793754578
Validation loss: 1.8671375628440612

Epoch: 6| Step: 2
Training loss: 0.9126588106155396
Validation loss: 1.8547317994538175

Epoch: 6| Step: 3
Training loss: 0.8920580148696899
Validation loss: 1.8480400103394703

Epoch: 6| Step: 4
Training loss: 1.00701904296875
Validation loss: 1.8274772795297767

Epoch: 6| Step: 5
Training loss: 0.7856687307357788
Validation loss: 1.9055480341757498

Epoch: 6| Step: 6
Training loss: 0.7838525772094727
Validation loss: 1.8155002260720858

Epoch: 6| Step: 7
Training loss: 0.6180511713027954
Validation loss: 1.8274300713692941

Epoch: 6| Step: 8
Training loss: 0.9617211222648621
Validation loss: 1.8046280466100222

Epoch: 6| Step: 9
Training loss: 0.8526041507720947
Validation loss: 1.8388830564355338

Epoch: 6| Step: 10
Training loss: 0.3185265064239502
Validation loss: 1.8938341653475197

Epoch: 6| Step: 11
Training loss: 0.9698588252067566
Validation loss: 1.862209354677508

Epoch: 6| Step: 12
Training loss: 1.1712371110916138
Validation loss: 1.943525686058947

Epoch: 6| Step: 13
Training loss: 0.7905892133712769
Validation loss: 1.8576358800293298

Epoch: 670| Step: 0
Training loss: 1.5945535898208618
Validation loss: 1.8717383594923123

Epoch: 6| Step: 1
Training loss: 1.2324497699737549
Validation loss: 1.8051235701448174

Epoch: 6| Step: 2
Training loss: 0.8241612315177917
Validation loss: 1.8466489039441591

Epoch: 6| Step: 3
Training loss: 0.33273816108703613
Validation loss: 1.8256936355303692

Epoch: 6| Step: 4
Training loss: 0.7459128499031067
Validation loss: 1.7936566414371613

Epoch: 6| Step: 5
Training loss: 0.5363245606422424
Validation loss: 1.8040337818925098

Epoch: 6| Step: 6
Training loss: 0.8277707695960999
Validation loss: 1.833845607696041

Epoch: 6| Step: 7
Training loss: 0.7885442972183228
Validation loss: 1.81099332276211

Epoch: 6| Step: 8
Training loss: 0.586090087890625
Validation loss: 1.8398990477285078

Epoch: 6| Step: 9
Training loss: 0.8240202069282532
Validation loss: 1.8359110457922823

Epoch: 6| Step: 10
Training loss: 1.071618914604187
Validation loss: 1.7642349222654938

Epoch: 6| Step: 11
Training loss: 0.91425621509552
Validation loss: 1.814428223076687

Epoch: 6| Step: 12
Training loss: 0.5634306073188782
Validation loss: 1.8367677132288616

Epoch: 6| Step: 13
Training loss: 0.8607627153396606
Validation loss: 1.8584079486067577

Epoch: 671| Step: 0
Training loss: 0.7576538920402527
Validation loss: 1.8481775893959949

Epoch: 6| Step: 1
Training loss: 0.7874107360839844
Validation loss: 1.9487993794102823

Epoch: 6| Step: 2
Training loss: 0.6934481263160706
Validation loss: 1.8063012528163132

Epoch: 6| Step: 3
Training loss: 0.8446246385574341
Validation loss: 1.9188683173989738

Epoch: 6| Step: 4
Training loss: 0.9295769333839417
Validation loss: 1.7665022650072653

Epoch: 6| Step: 5
Training loss: 0.6070774793624878
Validation loss: 1.8940634599295996

Epoch: 6| Step: 6
Training loss: 1.2829694747924805
Validation loss: 1.8783770376636135

Epoch: 6| Step: 7
Training loss: 1.3484396934509277
Validation loss: 1.8901021249832646

Epoch: 6| Step: 8
Training loss: 0.6042524576187134
Validation loss: 1.8822840490648824

Epoch: 6| Step: 9
Training loss: 0.5598458647727966
Validation loss: 1.8761084220742668

Epoch: 6| Step: 10
Training loss: 1.1730399131774902
Validation loss: 1.8120341070236698

Epoch: 6| Step: 11
Training loss: 0.820939302444458
Validation loss: 1.9013097901498117

Epoch: 6| Step: 12
Training loss: 0.4464552104473114
Validation loss: 1.8409437550011503

Epoch: 6| Step: 13
Training loss: 1.2240006923675537
Validation loss: 1.8009600664979668

Epoch: 672| Step: 0
Training loss: 0.7088550925254822
Validation loss: 1.8729909696886617

Epoch: 6| Step: 1
Training loss: 0.8108527660369873
Validation loss: 1.815489492108745

Epoch: 6| Step: 2
Training loss: 0.8443599939346313
Validation loss: 1.8063114150877921

Epoch: 6| Step: 3
Training loss: 0.8704593181610107
Validation loss: 1.8567306636482157

Epoch: 6| Step: 4
Training loss: 0.6101248264312744
Validation loss: 1.77996188850813

Epoch: 6| Step: 5
Training loss: 1.3500280380249023
Validation loss: 1.8164919640428276

Epoch: 6| Step: 6
Training loss: 0.7780101299285889
Validation loss: 1.7945153790135537

Epoch: 6| Step: 7
Training loss: 1.1011019945144653
Validation loss: 1.7890555320247528

Epoch: 6| Step: 8
Training loss: 0.6975840330123901
Validation loss: 1.8592837292660949

Epoch: 6| Step: 9
Training loss: 0.9162917137145996
Validation loss: 1.81198218945534

Epoch: 6| Step: 10
Training loss: 0.7895005941390991
Validation loss: 1.8303964214940225

Epoch: 6| Step: 11
Training loss: 0.7277215719223022
Validation loss: 1.8081614868615263

Epoch: 6| Step: 12
Training loss: 0.8703233003616333
Validation loss: 1.8462848458238827

Epoch: 6| Step: 13
Training loss: 1.0282280445098877
Validation loss: 1.8719248258939354

Epoch: 673| Step: 0
Training loss: 0.693284809589386
Validation loss: 1.9147948206111949

Epoch: 6| Step: 1
Training loss: 1.1534595489501953
Validation loss: 1.9409638271536878

Epoch: 6| Step: 2
Training loss: 0.7387737035751343
Validation loss: 1.8189792581783828

Epoch: 6| Step: 3
Training loss: 0.9741848707199097
Validation loss: 1.9005628619142758

Epoch: 6| Step: 4
Training loss: 0.6898493766784668
Validation loss: 1.8840002859792402

Epoch: 6| Step: 5
Training loss: 1.0626541376113892
Validation loss: 1.8652221938615203

Epoch: 6| Step: 6
Training loss: 0.7418286800384521
Validation loss: 1.8398314650340746

Epoch: 6| Step: 7
Training loss: 0.7260198593139648
Validation loss: 1.8464334626351633

Epoch: 6| Step: 8
Training loss: 0.625991702079773
Validation loss: 1.8201257157069382

Epoch: 6| Step: 9
Training loss: 0.909423828125
Validation loss: 1.7740752684172763

Epoch: 6| Step: 10
Training loss: 0.6731307506561279
Validation loss: 1.8057753809036747

Epoch: 6| Step: 11
Training loss: 1.28993558883667
Validation loss: 1.8368823592380812

Epoch: 6| Step: 12
Training loss: 0.7483925819396973
Validation loss: 1.7901283335942093

Epoch: 6| Step: 13
Training loss: 0.7714977860450745
Validation loss: 1.7711132149542532

Epoch: 674| Step: 0
Training loss: 0.8321646451950073
Validation loss: 1.8281156657844462

Epoch: 6| Step: 1
Training loss: 1.217142105102539
Validation loss: 1.8741187972407187

Epoch: 6| Step: 2
Training loss: 0.7625454664230347
Validation loss: 1.91148458116798

Epoch: 6| Step: 3
Training loss: 0.9619385004043579
Validation loss: 1.8731330671618063

Epoch: 6| Step: 4
Training loss: 1.06935715675354
Validation loss: 1.8125242033312399

Epoch: 6| Step: 5
Training loss: 0.6570911407470703
Validation loss: 1.9307964348023938

Epoch: 6| Step: 6
Training loss: 0.5945321917533875
Validation loss: 1.9126676974758026

Epoch: 6| Step: 7
Training loss: 1.3144909143447876
Validation loss: 1.9168834045369139

Epoch: 6| Step: 8
Training loss: 0.5420576333999634
Validation loss: 1.8901245106932938

Epoch: 6| Step: 9
Training loss: 0.8654686212539673
Validation loss: 1.8255611209459202

Epoch: 6| Step: 10
Training loss: 0.745842695236206
Validation loss: 1.8603380110956007

Epoch: 6| Step: 11
Training loss: 0.9707988500595093
Validation loss: 1.8412885422347693

Epoch: 6| Step: 12
Training loss: 0.6886802911758423
Validation loss: 1.8423173184035926

Epoch: 6| Step: 13
Training loss: 1.08980131149292
Validation loss: 1.8603483579492057

Epoch: 675| Step: 0
Training loss: 0.8440201282501221
Validation loss: 1.7956707022523368

Epoch: 6| Step: 1
Training loss: 0.6706923842430115
Validation loss: 1.8050652819295083

Epoch: 6| Step: 2
Training loss: 0.8963260054588318
Validation loss: 1.831613914940947

Epoch: 6| Step: 3
Training loss: 0.6860675811767578
Validation loss: 1.8213149834704656

Epoch: 6| Step: 4
Training loss: 1.1131354570388794
Validation loss: 1.901679446620326

Epoch: 6| Step: 5
Training loss: 1.226698398590088
Validation loss: 1.8764118955981346

Epoch: 6| Step: 6
Training loss: 0.7457453012466431
Validation loss: 1.810918874638055

Epoch: 6| Step: 7
Training loss: 0.9851537346839905
Validation loss: 1.833918466362902

Epoch: 6| Step: 8
Training loss: 0.5678805708885193
Validation loss: 1.8227504350805794

Epoch: 6| Step: 9
Training loss: 1.0483529567718506
Validation loss: 1.8458934765990063

Epoch: 6| Step: 10
Training loss: 0.8071905374526978
Validation loss: 1.9062873881350282

Epoch: 6| Step: 11
Training loss: 0.3746579885482788
Validation loss: 1.9221617175686745

Epoch: 6| Step: 12
Training loss: 0.7669317126274109
Validation loss: 1.8442922587035804

Epoch: 6| Step: 13
Training loss: 0.799483060836792
Validation loss: 1.9320555489550355

Epoch: 676| Step: 0
Training loss: 0.45465201139450073
Validation loss: 1.9417072611470376

Epoch: 6| Step: 1
Training loss: 0.9198216795921326
Validation loss: 1.899513586874931

Epoch: 6| Step: 2
Training loss: 0.9386717081069946
Validation loss: 1.852428154278827

Epoch: 6| Step: 3
Training loss: 0.6901454329490662
Validation loss: 1.8202670543424544

Epoch: 6| Step: 4
Training loss: 1.533266305923462
Validation loss: 1.8461111899345153

Epoch: 6| Step: 5
Training loss: 0.8700835704803467
Validation loss: 1.8884712406384048

Epoch: 6| Step: 6
Training loss: 1.070927381515503
Validation loss: 1.9028706230143064

Epoch: 6| Step: 7
Training loss: 1.0630121231079102
Validation loss: 1.8619126683922225

Epoch: 6| Step: 8
Training loss: 0.7889204621315002
Validation loss: 1.8131648084168792

Epoch: 6| Step: 9
Training loss: 0.8997597694396973
Validation loss: 1.8862164853721537

Epoch: 6| Step: 10
Training loss: 0.5671161413192749
Validation loss: 1.7917283914422477

Epoch: 6| Step: 11
Training loss: 0.5726897716522217
Validation loss: 1.8533208908573273

Epoch: 6| Step: 12
Training loss: 0.8348431587219238
Validation loss: 1.8028855003336424

Epoch: 6| Step: 13
Training loss: 0.9928134083747864
Validation loss: 1.914901142479271

Epoch: 677| Step: 0
Training loss: 0.9258850812911987
Validation loss: 1.802911768677414

Epoch: 6| Step: 1
Training loss: 0.4598272442817688
Validation loss: 1.8722792633118168

Epoch: 6| Step: 2
Training loss: 0.5226774215698242
Validation loss: 1.923570663698258

Epoch: 6| Step: 3
Training loss: 1.0602147579193115
Validation loss: 1.9261948382982643

Epoch: 6| Step: 4
Training loss: 1.0703110694885254
Validation loss: 1.982013206328115

Epoch: 6| Step: 5
Training loss: 0.9813872575759888
Validation loss: 1.9424776415671072

Epoch: 6| Step: 6
Training loss: 1.1893765926361084
Validation loss: 2.0030608561731156

Epoch: 6| Step: 7
Training loss: 1.3363516330718994
Validation loss: 1.927947849355718

Epoch: 6| Step: 8
Training loss: 1.206458330154419
Validation loss: 1.8606498190151748

Epoch: 6| Step: 9
Training loss: 0.7059810161590576
Validation loss: 1.8306616480632494

Epoch: 6| Step: 10
Training loss: 0.5134483575820923
Validation loss: 1.9121904437259962

Epoch: 6| Step: 11
Training loss: 0.8133993148803711
Validation loss: 1.8456305150062806

Epoch: 6| Step: 12
Training loss: 0.6646378040313721
Validation loss: 1.8873015014074181

Epoch: 6| Step: 13
Training loss: 0.730722188949585
Validation loss: 1.9056070081649288

Epoch: 678| Step: 0
Training loss: 1.3480380773544312
Validation loss: 1.8461635522944952

Epoch: 6| Step: 1
Training loss: 0.5599894523620605
Validation loss: 1.8089237354135002

Epoch: 6| Step: 2
Training loss: 0.9704865217208862
Validation loss: 1.84916942093962

Epoch: 6| Step: 3
Training loss: 0.763984739780426
Validation loss: 1.8074452466862176

Epoch: 6| Step: 4
Training loss: 1.1553330421447754
Validation loss: 1.832774987784765

Epoch: 6| Step: 5
Training loss: 0.7965291738510132
Validation loss: 1.7054041816342262

Epoch: 6| Step: 6
Training loss: 0.730348527431488
Validation loss: 1.8501126445749754

Epoch: 6| Step: 7
Training loss: 0.654558539390564
Validation loss: 1.8878450150130897

Epoch: 6| Step: 8
Training loss: 0.8459532260894775
Validation loss: 1.9376377213385798

Epoch: 6| Step: 9
Training loss: 1.1779531240463257
Validation loss: 1.893709933885964

Epoch: 6| Step: 10
Training loss: 1.7052762508392334
Validation loss: 1.894665495041878

Epoch: 6| Step: 11
Training loss: 0.5075961947441101
Validation loss: 1.8434461573118806

Epoch: 6| Step: 12
Training loss: 0.7398408651351929
Validation loss: 1.9554040124339442

Epoch: 6| Step: 13
Training loss: 0.6884498596191406
Validation loss: 1.875371362573357

Epoch: 679| Step: 0
Training loss: 0.9560017585754395
Validation loss: 1.8203957529478176

Epoch: 6| Step: 1
Training loss: 0.5124607086181641
Validation loss: 1.9268458171557354

Epoch: 6| Step: 2
Training loss: 0.7678974866867065
Validation loss: 1.8455578357942644

Epoch: 6| Step: 3
Training loss: 0.9919133186340332
Validation loss: 1.846738189779302

Epoch: 6| Step: 4
Training loss: 0.6308501362800598
Validation loss: 1.8602549978481826

Epoch: 6| Step: 5
Training loss: 0.5463119745254517
Validation loss: 1.8085480428511096

Epoch: 6| Step: 6
Training loss: 0.6695632934570312
Validation loss: 1.8261388604358961

Epoch: 6| Step: 7
Training loss: 0.7460618019104004
Validation loss: 1.7995492924926102

Epoch: 6| Step: 8
Training loss: 0.9966641664505005
Validation loss: 1.8671078169217674

Epoch: 6| Step: 9
Training loss: 0.9852721095085144
Validation loss: 1.8585468569109518

Epoch: 6| Step: 10
Training loss: 0.9507471323013306
Validation loss: 1.8159706105468094

Epoch: 6| Step: 11
Training loss: 0.9137358069419861
Validation loss: 1.9212591955738683

Epoch: 6| Step: 12
Training loss: 0.7938269376754761
Validation loss: 1.9377759630962084

Epoch: 6| Step: 13
Training loss: 0.7236981391906738
Validation loss: 1.8808706511733353

Epoch: 680| Step: 0
Training loss: 0.5619773864746094
Validation loss: 1.8652462895198534

Epoch: 6| Step: 1
Training loss: 1.3711017370224
Validation loss: 1.83752457557186

Epoch: 6| Step: 2
Training loss: 0.7853962779045105
Validation loss: 1.8493870522386284

Epoch: 6| Step: 3
Training loss: 1.4597439765930176
Validation loss: 1.853411473253722

Epoch: 6| Step: 4
Training loss: 0.7635417580604553
Validation loss: 1.851115995837796

Epoch: 6| Step: 5
Training loss: 0.8601810336112976
Validation loss: 1.8239956901919456

Epoch: 6| Step: 6
Training loss: 0.7790361642837524
Validation loss: 1.8783773811914588

Epoch: 6| Step: 7
Training loss: 0.5073657035827637
Validation loss: 1.891324007382957

Epoch: 6| Step: 8
Training loss: 0.7598462104797363
Validation loss: 1.853690871628382

Epoch: 6| Step: 9
Training loss: 0.9888728260993958
Validation loss: 1.8105598636852798

Epoch: 6| Step: 10
Training loss: 0.6428447961807251
Validation loss: 1.7791751610335482

Epoch: 6| Step: 11
Training loss: 0.5713478922843933
Validation loss: 1.8236961198109451

Epoch: 6| Step: 12
Training loss: 1.1620367765426636
Validation loss: 1.785099793505925

Epoch: 6| Step: 13
Training loss: 0.9962602257728577
Validation loss: 1.8292679812318535

Epoch: 681| Step: 0
Training loss: 0.9119319319725037
Validation loss: 1.8179423821869718

Epoch: 6| Step: 1
Training loss: 0.8959227800369263
Validation loss: 1.8896847232695548

Epoch: 6| Step: 2
Training loss: 0.8976801633834839
Validation loss: 1.8182965811862741

Epoch: 6| Step: 3
Training loss: 0.6802483797073364
Validation loss: 1.8174743844616799

Epoch: 6| Step: 4
Training loss: 0.7745182514190674
Validation loss: 1.8339494210417553

Epoch: 6| Step: 5
Training loss: 1.1645082235336304
Validation loss: 1.8579096371127712

Epoch: 6| Step: 6
Training loss: 0.7165887355804443
Validation loss: 1.898373556393449

Epoch: 6| Step: 7
Training loss: 0.7491661906242371
Validation loss: 1.873112432418331

Epoch: 6| Step: 8
Training loss: 0.6586019396781921
Validation loss: 1.8126155150833951

Epoch: 6| Step: 9
Training loss: 0.8163666725158691
Validation loss: 1.8448870797311105

Epoch: 6| Step: 10
Training loss: 0.6032314300537109
Validation loss: 1.7698593908740627

Epoch: 6| Step: 11
Training loss: 0.8340811729431152
Validation loss: 1.8698150624511063

Epoch: 6| Step: 12
Training loss: 0.7820079326629639
Validation loss: 1.821664838380711

Epoch: 6| Step: 13
Training loss: 0.694869875907898
Validation loss: 1.763178462623268

Epoch: 682| Step: 0
Training loss: 1.1927201747894287
Validation loss: 1.8508636643809657

Epoch: 6| Step: 1
Training loss: 0.8917133808135986
Validation loss: 1.8815680101353636

Epoch: 6| Step: 2
Training loss: 1.2999483346939087
Validation loss: 1.8101140119696175

Epoch: 6| Step: 3
Training loss: 0.7139304280281067
Validation loss: 1.8097506146277151

Epoch: 6| Step: 4
Training loss: 0.800621509552002
Validation loss: 1.8501184255846086

Epoch: 6| Step: 5
Training loss: 0.8978047370910645
Validation loss: 1.8225344932207497

Epoch: 6| Step: 6
Training loss: 0.7431305050849915
Validation loss: 1.8260320899307088

Epoch: 6| Step: 7
Training loss: 1.2465261220932007
Validation loss: 1.8872797540439072

Epoch: 6| Step: 8
Training loss: 0.6803368330001831
Validation loss: 1.8533952505357805

Epoch: 6| Step: 9
Training loss: 0.6009364128112793
Validation loss: 1.8150271331110308

Epoch: 6| Step: 10
Training loss: 1.3139728307724
Validation loss: 1.823640336272537

Epoch: 6| Step: 11
Training loss: 0.7371335029602051
Validation loss: 1.8434324469617618

Epoch: 6| Step: 12
Training loss: 0.698715329170227
Validation loss: 1.8544704914093018

Epoch: 6| Step: 13
Training loss: 0.5250681638717651
Validation loss: 1.8022762396002328

Epoch: 683| Step: 0
Training loss: 0.7879816293716431
Validation loss: 1.8683436942356888

Epoch: 6| Step: 1
Training loss: 0.5310525894165039
Validation loss: 1.9229350077208651

Epoch: 6| Step: 2
Training loss: 1.0046095848083496
Validation loss: 1.8810702036785822

Epoch: 6| Step: 3
Training loss: 0.6023581027984619
Validation loss: 1.8559902021961827

Epoch: 6| Step: 4
Training loss: 0.6118191480636597
Validation loss: 1.8999092437887704

Epoch: 6| Step: 5
Training loss: 0.9914490580558777
Validation loss: 1.9549163003121652

Epoch: 6| Step: 6
Training loss: 0.6878388524055481
Validation loss: 1.8586196745595625

Epoch: 6| Step: 7
Training loss: 0.8421041965484619
Validation loss: 1.9020865988987747

Epoch: 6| Step: 8
Training loss: 0.9080532789230347
Validation loss: 1.8423650239103584

Epoch: 6| Step: 9
Training loss: 0.8870851993560791
Validation loss: 1.8515638151476461

Epoch: 6| Step: 10
Training loss: 0.7804921269416809
Validation loss: 1.8367989261945088

Epoch: 6| Step: 11
Training loss: 0.41074496507644653
Validation loss: 1.9024351181522492

Epoch: 6| Step: 12
Training loss: 1.2282593250274658
Validation loss: 1.8591947042813866

Epoch: 6| Step: 13
Training loss: 0.741970419883728
Validation loss: 1.8373592950964486

Epoch: 684| Step: 0
Training loss: 0.7762410044670105
Validation loss: 1.7753965290643836

Epoch: 6| Step: 1
Training loss: 0.6019124984741211
Validation loss: 1.8570062985984228

Epoch: 6| Step: 2
Training loss: 1.001152515411377
Validation loss: 1.7957505820899882

Epoch: 6| Step: 3
Training loss: 0.7706930637359619
Validation loss: 1.8823808482898179

Epoch: 6| Step: 4
Training loss: 1.0284056663513184
Validation loss: 1.7763350343191495

Epoch: 6| Step: 5
Training loss: 0.7839478254318237
Validation loss: 1.8557992673689319

Epoch: 6| Step: 6
Training loss: 0.7182111144065857
Validation loss: 1.877569180662914

Epoch: 6| Step: 7
Training loss: 1.067496418952942
Validation loss: 1.8874221322357014

Epoch: 6| Step: 8
Training loss: 1.1714715957641602
Validation loss: 1.8378052429486347

Epoch: 6| Step: 9
Training loss: 0.6534397602081299
Validation loss: 1.8051867869592482

Epoch: 6| Step: 10
Training loss: 0.4068438708782196
Validation loss: 1.8207262536530853

Epoch: 6| Step: 11
Training loss: 1.02601158618927
Validation loss: 1.8053290818327217

Epoch: 6| Step: 12
Training loss: 0.8506055474281311
Validation loss: 1.8524634274103309

Epoch: 6| Step: 13
Training loss: 0.7555636167526245
Validation loss: 1.803724786286713

Epoch: 685| Step: 0
Training loss: 1.2072217464447021
Validation loss: 1.8576606806888376

Epoch: 6| Step: 1
Training loss: 0.8278623819351196
Validation loss: 1.8231075527847453

Epoch: 6| Step: 2
Training loss: 0.5110058784484863
Validation loss: 1.8103369102683118

Epoch: 6| Step: 3
Training loss: 1.2106738090515137
Validation loss: 1.8026350749436246

Epoch: 6| Step: 4
Training loss: 0.5606816411018372
Validation loss: 1.8518613653798257

Epoch: 6| Step: 5
Training loss: 0.9405922889709473
Validation loss: 1.8375516847897602

Epoch: 6| Step: 6
Training loss: 0.9158228635787964
Validation loss: 1.8115848905296736

Epoch: 6| Step: 7
Training loss: 0.5703260898590088
Validation loss: 1.7810507359043244

Epoch: 6| Step: 8
Training loss: 0.9543281197547913
Validation loss: 1.8209629430565784

Epoch: 6| Step: 9
Training loss: 1.2690858840942383
Validation loss: 1.8693954457518875

Epoch: 6| Step: 10
Training loss: 0.6276235580444336
Validation loss: 1.8106027700567757

Epoch: 6| Step: 11
Training loss: 0.8467929363250732
Validation loss: 1.8505785131967196

Epoch: 6| Step: 12
Training loss: 0.7895409464836121
Validation loss: 1.8660173569956133

Epoch: 6| Step: 13
Training loss: 0.6152823567390442
Validation loss: 1.8349402258473058

Epoch: 686| Step: 0
Training loss: 0.7688503265380859
Validation loss: 1.8714971426994569

Epoch: 6| Step: 1
Training loss: 0.6133241653442383
Validation loss: 1.8422333784000848

Epoch: 6| Step: 2
Training loss: 1.107692837715149
Validation loss: 1.7882894162208802

Epoch: 6| Step: 3
Training loss: 0.9905352592468262
Validation loss: 1.8895115519082675

Epoch: 6| Step: 4
Training loss: 1.042014718055725
Validation loss: 1.8377929605463499

Epoch: 6| Step: 5
Training loss: 0.9069147109985352
Validation loss: 1.7669344794365667

Epoch: 6| Step: 6
Training loss: 0.9019598960876465
Validation loss: 1.9154786166324411

Epoch: 6| Step: 7
Training loss: 0.5870546698570251
Validation loss: 1.833360439987593

Epoch: 6| Step: 8
Training loss: 1.0812207460403442
Validation loss: 1.8996516978868874

Epoch: 6| Step: 9
Training loss: 0.7818460464477539
Validation loss: 1.7454841239477998

Epoch: 6| Step: 10
Training loss: 0.37822335958480835
Validation loss: 1.9517790579026746

Epoch: 6| Step: 11
Training loss: 0.7717489004135132
Validation loss: 1.8066853797563942

Epoch: 6| Step: 12
Training loss: 0.7238686084747314
Validation loss: 1.833214359898721

Epoch: 6| Step: 13
Training loss: 0.9442359209060669
Validation loss: 1.8941672181570401

Epoch: 687| Step: 0
Training loss: 0.939598798751831
Validation loss: 1.8758090247390091

Epoch: 6| Step: 1
Training loss: 0.9273923635482788
Validation loss: 1.8440913923325077

Epoch: 6| Step: 2
Training loss: 0.7871713638305664
Validation loss: 1.7903115915995773

Epoch: 6| Step: 3
Training loss: 0.53573077917099
Validation loss: 1.7764351803769347

Epoch: 6| Step: 4
Training loss: 1.0195446014404297
Validation loss: 1.8475380277120939

Epoch: 6| Step: 5
Training loss: 0.5418505072593689
Validation loss: 1.7796532902666318

Epoch: 6| Step: 6
Training loss: 0.7620605230331421
Validation loss: 1.9044845078581123

Epoch: 6| Step: 7
Training loss: 0.8292770385742188
Validation loss: 1.8667668962991366

Epoch: 6| Step: 8
Training loss: 1.1222137212753296
Validation loss: 1.8356142146613008

Epoch: 6| Step: 9
Training loss: 0.8138258457183838
Validation loss: 1.8229918454283027

Epoch: 6| Step: 10
Training loss: 0.6204655170440674
Validation loss: 1.872760836796094

Epoch: 6| Step: 11
Training loss: 0.5931618809700012
Validation loss: 1.8813531526955225

Epoch: 6| Step: 12
Training loss: 1.0040388107299805
Validation loss: 1.8495563358388922

Epoch: 6| Step: 13
Training loss: 0.8349707722663879
Validation loss: 1.7852489345817155

Epoch: 688| Step: 0
Training loss: 0.8772127628326416
Validation loss: 1.9030654866208312

Epoch: 6| Step: 1
Training loss: 1.1287379264831543
Validation loss: 1.9227763888656453

Epoch: 6| Step: 2
Training loss: 0.9551461935043335
Validation loss: 1.9103448852416007

Epoch: 6| Step: 3
Training loss: 0.7922583222389221
Validation loss: 1.9699951974294518

Epoch: 6| Step: 4
Training loss: 0.7143923044204712
Validation loss: 1.8230725629355318

Epoch: 6| Step: 5
Training loss: 0.6378965377807617
Validation loss: 1.8396275786943332

Epoch: 6| Step: 6
Training loss: 0.4329397678375244
Validation loss: 1.8696538735461492

Epoch: 6| Step: 7
Training loss: 0.942332923412323
Validation loss: 1.8196807753655218

Epoch: 6| Step: 8
Training loss: 0.47366857528686523
Validation loss: 1.9362920150961926

Epoch: 6| Step: 9
Training loss: 1.0408334732055664
Validation loss: 1.7666606832576055

Epoch: 6| Step: 10
Training loss: 0.4892002046108246
Validation loss: 1.8699968848177182

Epoch: 6| Step: 11
Training loss: 0.9765242338180542
Validation loss: 1.8593613614318192

Epoch: 6| Step: 12
Training loss: 1.8108571767807007
Validation loss: 1.801248832415509

Epoch: 6| Step: 13
Training loss: 0.2751496136188507
Validation loss: 1.780125230871221

Epoch: 689| Step: 0
Training loss: 0.6732813715934753
Validation loss: 1.8815396703699583

Epoch: 6| Step: 1
Training loss: 1.0574232339859009
Validation loss: 1.8741437440277429

Epoch: 6| Step: 2
Training loss: 0.574026346206665
Validation loss: 1.8544054210826915

Epoch: 6| Step: 3
Training loss: 1.1213418245315552
Validation loss: 1.8372898050533828

Epoch: 6| Step: 4
Training loss: 0.8956276178359985
Validation loss: 1.8577395421202465

Epoch: 6| Step: 5
Training loss: 0.6749866604804993
Validation loss: 1.8707350992387342

Epoch: 6| Step: 6
Training loss: 1.1908961534500122
Validation loss: 1.7926005740319528

Epoch: 6| Step: 7
Training loss: 0.8172375559806824
Validation loss: 1.8338315871454054

Epoch: 6| Step: 8
Training loss: 0.9238200187683105
Validation loss: 1.7826587038655435

Epoch: 6| Step: 9
Training loss: 0.8244672417640686
Validation loss: 1.8460361931913642

Epoch: 6| Step: 10
Training loss: 0.9347484707832336
Validation loss: 1.8189831933667582

Epoch: 6| Step: 11
Training loss: 0.9028072357177734
Validation loss: 1.8685560534077306

Epoch: 6| Step: 12
Training loss: 0.8106971979141235
Validation loss: 1.8495651124626078

Epoch: 6| Step: 13
Training loss: 0.8534945845603943
Validation loss: 1.8037376890900314

Epoch: 690| Step: 0
Training loss: 0.9276730418205261
Validation loss: 1.8000235044828026

Epoch: 6| Step: 1
Training loss: 0.5218806266784668
Validation loss: 1.7840490789823635

Epoch: 6| Step: 2
Training loss: 1.4043185710906982
Validation loss: 1.8019857637343868

Epoch: 6| Step: 3
Training loss: 0.8355759978294373
Validation loss: 1.8197367575860792

Epoch: 6| Step: 4
Training loss: 0.9227352142333984
Validation loss: 1.9316037572840208

Epoch: 6| Step: 5
Training loss: 0.8092142343521118
Validation loss: 1.8710548595715595

Epoch: 6| Step: 6
Training loss: 0.7075321078300476
Validation loss: 1.8367562781098068

Epoch: 6| Step: 7
Training loss: 0.7396014332771301
Validation loss: 1.815398145747441

Epoch: 6| Step: 8
Training loss: 0.8798153400421143
Validation loss: 1.814545859572708

Epoch: 6| Step: 9
Training loss: 0.8358165621757507
Validation loss: 1.7330628800135788

Epoch: 6| Step: 10
Training loss: 1.136826515197754
Validation loss: 1.795958920191693

Epoch: 6| Step: 11
Training loss: 0.6325331330299377
Validation loss: 1.8314835948328818

Epoch: 6| Step: 12
Training loss: 0.945759654045105
Validation loss: 1.8344345567046956

Epoch: 6| Step: 13
Training loss: 0.30121761560440063
Validation loss: 1.8276686309486307

Epoch: 691| Step: 0
Training loss: 0.7325483560562134
Validation loss: 1.84002471739246

Epoch: 6| Step: 1
Training loss: 0.9011040329933167
Validation loss: 1.754991139135053

Epoch: 6| Step: 2
Training loss: 0.6239897012710571
Validation loss: 1.848457537671571

Epoch: 6| Step: 3
Training loss: 1.1319350004196167
Validation loss: 1.8580200697786065

Epoch: 6| Step: 4
Training loss: 1.2278468608856201
Validation loss: 1.8972593046003772

Epoch: 6| Step: 5
Training loss: 1.0348186492919922
Validation loss: 1.7468723148427985

Epoch: 6| Step: 6
Training loss: 0.7995836138725281
Validation loss: 1.865492638721261

Epoch: 6| Step: 7
Training loss: 0.5475063323974609
Validation loss: 1.8468736499868414

Epoch: 6| Step: 8
Training loss: 0.5253724455833435
Validation loss: 1.795203605005818

Epoch: 6| Step: 9
Training loss: 1.104312777519226
Validation loss: 1.8238486910379061

Epoch: 6| Step: 10
Training loss: 0.5283583402633667
Validation loss: 1.8481229787231774

Epoch: 6| Step: 11
Training loss: 0.8167544603347778
Validation loss: 1.817175216572259

Epoch: 6| Step: 12
Training loss: 0.7369443774223328
Validation loss: 1.801987858228786

Epoch: 6| Step: 13
Training loss: 0.8521504402160645
Validation loss: 1.8465911534524733

Epoch: 692| Step: 0
Training loss: 0.8427615165710449
Validation loss: 1.8049538071437548

Epoch: 6| Step: 1
Training loss: 0.943831205368042
Validation loss: 1.8213732332311652

Epoch: 6| Step: 2
Training loss: 1.4076205492019653
Validation loss: 1.8229631544441305

Epoch: 6| Step: 3
Training loss: 0.347167432308197
Validation loss: 1.8660401387881207

Epoch: 6| Step: 4
Training loss: 0.804854154586792
Validation loss: 1.8251914619117655

Epoch: 6| Step: 5
Training loss: 0.39217525720596313
Validation loss: 1.8885266832126084

Epoch: 6| Step: 6
Training loss: 0.6805267333984375
Validation loss: 1.8919836359639322

Epoch: 6| Step: 7
Training loss: 0.6100044250488281
Validation loss: 1.8397868628142982

Epoch: 6| Step: 8
Training loss: 0.9583374261856079
Validation loss: 1.8135189471706268

Epoch: 6| Step: 9
Training loss: 0.8583014607429504
Validation loss: 1.8131111245001517

Epoch: 6| Step: 10
Training loss: 1.0957908630371094
Validation loss: 1.8379445229807208

Epoch: 6| Step: 11
Training loss: 0.7328885793685913
Validation loss: 1.8359517115418629

Epoch: 6| Step: 12
Training loss: 0.8396411538124084
Validation loss: 1.7779181734208138

Epoch: 6| Step: 13
Training loss: 0.6087477207183838
Validation loss: 1.8234044428794616

Epoch: 693| Step: 0
Training loss: 0.7677599191665649
Validation loss: 1.8567085048203826

Epoch: 6| Step: 1
Training loss: 1.3269237279891968
Validation loss: 1.8132152634282266

Epoch: 6| Step: 2
Training loss: 0.6084007024765015
Validation loss: 1.8137218785542313

Epoch: 6| Step: 3
Training loss: 0.863004207611084
Validation loss: 1.85433183434189

Epoch: 6| Step: 4
Training loss: 0.5039424300193787
Validation loss: 1.8549852025124334

Epoch: 6| Step: 5
Training loss: 1.4001579284667969
Validation loss: 1.8829283765567246

Epoch: 6| Step: 6
Training loss: 0.5449426770210266
Validation loss: 1.9244873639075988

Epoch: 6| Step: 7
Training loss: 0.7393315434455872
Validation loss: 1.843179206694326

Epoch: 6| Step: 8
Training loss: 1.1045713424682617
Validation loss: 1.9266721484481648

Epoch: 6| Step: 9
Training loss: 1.0009092092514038
Validation loss: 1.9405663231367707

Epoch: 6| Step: 10
Training loss: 0.569185197353363
Validation loss: 1.923393382821032

Epoch: 6| Step: 11
Training loss: 0.6943007707595825
Validation loss: 1.8945715145398212

Epoch: 6| Step: 12
Training loss: 0.5997257232666016
Validation loss: 1.7855547448640228

Epoch: 6| Step: 13
Training loss: 1.110255241394043
Validation loss: 1.8940359584746822

Epoch: 694| Step: 0
Training loss: 0.8350769877433777
Validation loss: 1.8263622970991238

Epoch: 6| Step: 1
Training loss: 0.8812892436981201
Validation loss: 1.766968648920777

Epoch: 6| Step: 2
Training loss: 0.7953853011131287
Validation loss: 1.8545887290790517

Epoch: 6| Step: 3
Training loss: 0.8461459279060364
Validation loss: 1.818767588625672

Epoch: 6| Step: 4
Training loss: 0.6347594857215881
Validation loss: 1.855194168706094

Epoch: 6| Step: 5
Training loss: 0.6777836084365845
Validation loss: 1.8418126093444003

Epoch: 6| Step: 6
Training loss: 0.9025362133979797
Validation loss: 1.7310858093282229

Epoch: 6| Step: 7
Training loss: 0.5434517860412598
Validation loss: 1.8354258306564823

Epoch: 6| Step: 8
Training loss: 0.6445146799087524
Validation loss: 1.8421099544853292

Epoch: 6| Step: 9
Training loss: 1.081122875213623
Validation loss: 1.8785860218027586

Epoch: 6| Step: 10
Training loss: 1.4822311401367188
Validation loss: 1.8664788815283007

Epoch: 6| Step: 11
Training loss: 0.4692665934562683
Validation loss: 1.803703382451047

Epoch: 6| Step: 12
Training loss: 0.9819508194923401
Validation loss: 1.8788691079744728

Epoch: 6| Step: 13
Training loss: 0.8099600076675415
Validation loss: 1.9161993534334245

Epoch: 695| Step: 0
Training loss: 0.8115681409835815
Validation loss: 1.8422470067137031

Epoch: 6| Step: 1
Training loss: 0.8715415596961975
Validation loss: 1.850400831109734

Epoch: 6| Step: 2
Training loss: 0.908839225769043
Validation loss: 1.9203009118315995

Epoch: 6| Step: 3
Training loss: 0.7829656004905701
Validation loss: 1.8624108055586457

Epoch: 6| Step: 4
Training loss: 0.6321762800216675
Validation loss: 1.7472944131461523

Epoch: 6| Step: 5
Training loss: 0.6597665548324585
Validation loss: 1.8085209733696395

Epoch: 6| Step: 6
Training loss: 1.3521960973739624
Validation loss: 1.8169921341762747

Epoch: 6| Step: 7
Training loss: 0.8675456643104553
Validation loss: 1.8881593968278618

Epoch: 6| Step: 8
Training loss: 0.8846700191497803
Validation loss: 1.7899830879703644

Epoch: 6| Step: 9
Training loss: 0.8634684085845947
Validation loss: 1.867434122229135

Epoch: 6| Step: 10
Training loss: 1.0777547359466553
Validation loss: 1.8030160832148727

Epoch: 6| Step: 11
Training loss: 0.3840335011482239
Validation loss: 1.7860743435480262

Epoch: 6| Step: 12
Training loss: 0.6119900941848755
Validation loss: 1.8554577122452438

Epoch: 6| Step: 13
Training loss: 0.9172713160514832
Validation loss: 1.8099788978535643

Epoch: 696| Step: 0
Training loss: 0.6302752494812012
Validation loss: 1.9037460063093452

Epoch: 6| Step: 1
Training loss: 0.8585070967674255
Validation loss: 1.90376603475181

Epoch: 6| Step: 2
Training loss: 0.9686398506164551
Validation loss: 1.8897295818533948

Epoch: 6| Step: 3
Training loss: 1.0331119298934937
Validation loss: 1.9339768989111787

Epoch: 6| Step: 4
Training loss: 0.9574309587478638
Validation loss: 1.9323497549180062

Epoch: 6| Step: 5
Training loss: 1.421475887298584
Validation loss: 1.8864086263923234

Epoch: 6| Step: 6
Training loss: 0.6532144546508789
Validation loss: 1.848444410549697

Epoch: 6| Step: 7
Training loss: 0.784150242805481
Validation loss: 1.8251371640031055

Epoch: 6| Step: 8
Training loss: 1.3395925760269165
Validation loss: 1.8331006714092788

Epoch: 6| Step: 9
Training loss: 0.6238277554512024
Validation loss: 1.8381240239707373

Epoch: 6| Step: 10
Training loss: 1.2412819862365723
Validation loss: 1.7963850793018137

Epoch: 6| Step: 11
Training loss: 0.5981999635696411
Validation loss: 1.7916083387149278

Epoch: 6| Step: 12
Training loss: 0.5215638279914856
Validation loss: 1.84141573854672

Epoch: 6| Step: 13
Training loss: 0.8788632750511169
Validation loss: 1.7854170696709746

Epoch: 697| Step: 0
Training loss: 0.7354065179824829
Validation loss: 1.8997570981261551

Epoch: 6| Step: 1
Training loss: 0.59761643409729
Validation loss: 1.8168266793733001

Epoch: 6| Step: 2
Training loss: 0.7443060874938965
Validation loss: 1.8614018809410833

Epoch: 6| Step: 3
Training loss: 0.7695837616920471
Validation loss: 1.8380074731765255

Epoch: 6| Step: 4
Training loss: 0.8802076578140259
Validation loss: 1.881787274473457

Epoch: 6| Step: 5
Training loss: 0.7665836215019226
Validation loss: 1.7876246436949699

Epoch: 6| Step: 6
Training loss: 1.0788114070892334
Validation loss: 1.898857191044797

Epoch: 6| Step: 7
Training loss: 0.47010987997055054
Validation loss: 1.7717945921805598

Epoch: 6| Step: 8
Training loss: 1.4397754669189453
Validation loss: 1.8782760122770905

Epoch: 6| Step: 9
Training loss: 0.7768746614456177
Validation loss: 1.8075821912416847

Epoch: 6| Step: 10
Training loss: 0.7106629014015198
Validation loss: 1.820469202533845

Epoch: 6| Step: 11
Training loss: 0.654979944229126
Validation loss: 1.8385849870661253

Epoch: 6| Step: 12
Training loss: 0.6030102968215942
Validation loss: 1.8318027796283844

Epoch: 6| Step: 13
Training loss: 0.8000455498695374
Validation loss: 1.8304004835826095

Epoch: 698| Step: 0
Training loss: 0.8092740178108215
Validation loss: 1.8069480490940872

Epoch: 6| Step: 1
Training loss: 0.9610655307769775
Validation loss: 1.869043129746632

Epoch: 6| Step: 2
Training loss: 1.2911651134490967
Validation loss: 1.8273388980537333

Epoch: 6| Step: 3
Training loss: 0.8959172964096069
Validation loss: 1.8658044017771238

Epoch: 6| Step: 4
Training loss: 0.9246087670326233
Validation loss: 1.9122575931651618

Epoch: 6| Step: 5
Training loss: 0.8674128651618958
Validation loss: 1.7499700733410415

Epoch: 6| Step: 6
Training loss: 0.46824711561203003
Validation loss: 1.832234255729183

Epoch: 6| Step: 7
Training loss: 1.246281385421753
Validation loss: 1.916169612638412

Epoch: 6| Step: 8
Training loss: 0.7593387365341187
Validation loss: 1.8918360663998512

Epoch: 6| Step: 9
Training loss: 0.7234705686569214
Validation loss: 1.7837300710780646

Epoch: 6| Step: 10
Training loss: 0.666733980178833
Validation loss: 1.8324317803946875

Epoch: 6| Step: 11
Training loss: 0.46642836928367615
Validation loss: 1.810636881859072

Epoch: 6| Step: 12
Training loss: 0.5342337489128113
Validation loss: 1.82785621125211

Epoch: 6| Step: 13
Training loss: 1.049807071685791
Validation loss: 1.8481257179731965

Epoch: 699| Step: 0
Training loss: 1.2240204811096191
Validation loss: 1.8192370014805948

Epoch: 6| Step: 1
Training loss: 0.656908392906189
Validation loss: 1.7465326247676727

Epoch: 6| Step: 2
Training loss: 0.6656657457351685
Validation loss: 1.8159957060249903

Epoch: 6| Step: 3
Training loss: 0.7815600037574768
Validation loss: 1.7534764351383332

Epoch: 6| Step: 4
Training loss: 0.5331690311431885
Validation loss: 1.8229690649176156

Epoch: 6| Step: 5
Training loss: 0.6647953391075134
Validation loss: 1.810643962634507

Epoch: 6| Step: 6
Training loss: 0.8246579170227051
Validation loss: 1.81697174297866

Epoch: 6| Step: 7
Training loss: 0.7785677909851074
Validation loss: 1.850165556835872

Epoch: 6| Step: 8
Training loss: 1.2491406202316284
Validation loss: 1.8049706951264413

Epoch: 6| Step: 9
Training loss: 1.105778694152832
Validation loss: 1.861590362364246

Epoch: 6| Step: 10
Training loss: 0.5868915319442749
Validation loss: 1.828155710492083

Epoch: 6| Step: 11
Training loss: 0.8777788877487183
Validation loss: 1.813693082460793

Epoch: 6| Step: 12
Training loss: 0.742192804813385
Validation loss: 1.7928463694869832

Epoch: 6| Step: 13
Training loss: 1.1264853477478027
Validation loss: 1.8838930501732776

Epoch: 700| Step: 0
Training loss: 1.0284414291381836
Validation loss: 1.8857576923985635

Epoch: 6| Step: 1
Training loss: 0.8697750568389893
Validation loss: 1.8475580907637073

Epoch: 6| Step: 2
Training loss: 0.6283220052719116
Validation loss: 1.7725175734489196

Epoch: 6| Step: 3
Training loss: 0.9950976371765137
Validation loss: 1.8374614920667423

Epoch: 6| Step: 4
Training loss: 0.4764111638069153
Validation loss: 1.8921718020592966

Epoch: 6| Step: 5
Training loss: 1.3000664710998535
Validation loss: 1.7941090214637019

Epoch: 6| Step: 6
Training loss: 0.5582065582275391
Validation loss: 1.7604669614504742

Epoch: 6| Step: 7
Training loss: 0.6525579690933228
Validation loss: 1.7646469377702283

Epoch: 6| Step: 8
Training loss: 1.0368931293487549
Validation loss: 1.8011548570407334

Epoch: 6| Step: 9
Training loss: 0.903924822807312
Validation loss: 1.8274669595943984

Epoch: 6| Step: 10
Training loss: 0.49602529406547546
Validation loss: 1.861460872875747

Epoch: 6| Step: 11
Training loss: 0.937805712223053
Validation loss: 1.7525312490360712

Epoch: 6| Step: 12
Training loss: 0.8834986090660095
Validation loss: 1.825920848436253

Epoch: 6| Step: 13
Training loss: 0.45687928795814514
Validation loss: 1.8180592585635442

Testing loss: 2.3577287117640178
