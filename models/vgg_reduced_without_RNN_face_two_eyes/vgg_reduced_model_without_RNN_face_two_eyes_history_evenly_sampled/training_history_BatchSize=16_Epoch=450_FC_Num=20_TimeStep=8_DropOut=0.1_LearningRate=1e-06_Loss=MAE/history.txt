Epoch: 1| Step: 0
Training loss: 3.4358935356140137
Validation loss: 3.826821260554816

Epoch: 6| Step: 1
Training loss: 3.035019874572754
Validation loss: 3.821895489128687

Epoch: 6| Step: 2
Training loss: 4.695000648498535
Validation loss: 3.819913746208273

Epoch: 6| Step: 3
Training loss: 4.556525230407715
Validation loss: 3.814642337060744

Epoch: 6| Step: 4
Training loss: 3.6962084770202637
Validation loss: 3.8111911178917013

Epoch: 6| Step: 5
Training loss: 2.881333351135254
Validation loss: 3.8054174146344586

Epoch: 6| Step: 6
Training loss: 4.020826816558838
Validation loss: 3.80222886864857

Epoch: 6| Step: 7
Training loss: 3.664447069168091
Validation loss: 3.7947663235408005

Epoch: 6| Step: 8
Training loss: 4.052233695983887
Validation loss: 3.788861136282644

Epoch: 6| Step: 9
Training loss: 3.395580768585205
Validation loss: 3.7863562927451184

Epoch: 6| Step: 10
Training loss: 3.865901470184326
Validation loss: 3.782005069076374

Epoch: 6| Step: 11
Training loss: 4.105625629425049
Validation loss: 3.7768567198066303

Epoch: 6| Step: 12
Training loss: 3.170149326324463
Validation loss: 3.772246524851809

Epoch: 6| Step: 13
Training loss: 2.4582598209381104
Validation loss: 3.768194342172274

Epoch: 2| Step: 0
Training loss: 2.6989428997039795
Validation loss: 3.762687211395592

Epoch: 6| Step: 1
Training loss: 3.6766138076782227
Validation loss: 3.759496368387694

Epoch: 6| Step: 2
Training loss: 3.133718252182007
Validation loss: 3.7544901550457044

Epoch: 6| Step: 3
Training loss: 3.727388381958008
Validation loss: 3.749106325129027

Epoch: 6| Step: 4
Training loss: 4.112893104553223
Validation loss: 3.7459926066860074

Epoch: 6| Step: 5
Training loss: 3.5906782150268555
Validation loss: 3.738885889771164

Epoch: 6| Step: 6
Training loss: 4.286050796508789
Validation loss: 3.7355067806859172

Epoch: 6| Step: 7
Training loss: 2.4862756729125977
Validation loss: 3.7322143252177904

Epoch: 6| Step: 8
Training loss: 4.468382835388184
Validation loss: 3.7258007295670046

Epoch: 6| Step: 9
Training loss: 3.8971357345581055
Validation loss: 3.72355515726151

Epoch: 6| Step: 10
Training loss: 4.562424182891846
Validation loss: 3.7174932828513523

Epoch: 6| Step: 11
Training loss: 3.514122247695923
Validation loss: 3.7133119131929133

Epoch: 6| Step: 12
Training loss: 3.6016170978546143
Validation loss: 3.7092451126344743

Epoch: 6| Step: 13
Training loss: 2.6227211952209473
Validation loss: 3.703090598506312

Epoch: 3| Step: 0
Training loss: 3.4499709606170654
Validation loss: 3.701255588121312

Epoch: 6| Step: 1
Training loss: 4.407330513000488
Validation loss: 3.697196191357028

Epoch: 6| Step: 2
Training loss: 3.6470448970794678
Validation loss: 3.6912011484945975

Epoch: 6| Step: 3
Training loss: 4.342264175415039
Validation loss: 3.6847184165831535

Epoch: 6| Step: 4
Training loss: 4.465554714202881
Validation loss: 3.683232917580553

Epoch: 6| Step: 5
Training loss: 2.1587114334106445
Validation loss: 3.678495950596307

Epoch: 6| Step: 6
Training loss: 3.378260612487793
Validation loss: 3.6742044392452446

Epoch: 6| Step: 7
Training loss: 3.0879831314086914
Validation loss: 3.667958995347382

Epoch: 6| Step: 8
Training loss: 4.271899223327637
Validation loss: 3.6659671696283485

Epoch: 6| Step: 9
Training loss: 3.730623722076416
Validation loss: 3.661382629025367

Epoch: 6| Step: 10
Training loss: 3.100846767425537
Validation loss: 3.6556475290688137

Epoch: 6| Step: 11
Training loss: 3.2584521770477295
Validation loss: 3.651534867543046

Epoch: 6| Step: 12
Training loss: 3.2646982669830322
Validation loss: 3.6496139059784594

Epoch: 6| Step: 13
Training loss: 3.432680130004883
Validation loss: 3.64279261455741

Epoch: 4| Step: 0
Training loss: 2.758298397064209
Validation loss: 3.638775497354487

Epoch: 6| Step: 1
Training loss: 3.2536892890930176
Validation loss: 3.635324449949367

Epoch: 6| Step: 2
Training loss: 4.488854885101318
Validation loss: 3.629955137929609

Epoch: 6| Step: 3
Training loss: 2.1789984703063965
Validation loss: 3.625566244125366

Epoch: 6| Step: 4
Training loss: 3.0526576042175293
Validation loss: 3.6217267590184368

Epoch: 6| Step: 5
Training loss: 4.315413475036621
Validation loss: 3.6155695863949355

Epoch: 6| Step: 6
Training loss: 3.948396682739258
Validation loss: 3.615393974447763

Epoch: 6| Step: 7
Training loss: 3.9989306926727295
Validation loss: 3.6073067700991066

Epoch: 6| Step: 8
Training loss: 3.6097359657287598
Validation loss: 3.6034330270623647

Epoch: 6| Step: 9
Training loss: 3.878864288330078
Validation loss: 3.600339017888551

Epoch: 6| Step: 10
Training loss: 3.16552734375
Validation loss: 3.5942765128227974

Epoch: 6| Step: 11
Training loss: 3.7764878273010254
Validation loss: 3.5906305364383164

Epoch: 6| Step: 12
Training loss: 3.3511126041412354
Validation loss: 3.5858454858103106

Epoch: 6| Step: 13
Training loss: 3.5699102878570557
Validation loss: 3.578838397097844

Epoch: 5| Step: 0
Training loss: 3.6128480434417725
Validation loss: 3.573044264188377

Epoch: 6| Step: 1
Training loss: 2.8177762031555176
Validation loss: 3.5699093828919115

Epoch: 6| Step: 2
Training loss: 2.577897548675537
Validation loss: 3.565205402271722

Epoch: 6| Step: 3
Training loss: 3.881153106689453
Validation loss: 3.5603211720784507

Epoch: 6| Step: 4
Training loss: 2.870746374130249
Validation loss: 3.5594380132613646

Epoch: 6| Step: 5
Training loss: 3.5563087463378906
Validation loss: 3.5508341173971854

Epoch: 6| Step: 6
Training loss: 4.228934288024902
Validation loss: 3.5493151295569634

Epoch: 6| Step: 7
Training loss: 3.7897868156433105
Validation loss: 3.5425633615063084

Epoch: 6| Step: 8
Training loss: 2.735304594039917
Validation loss: 3.5378552200973674

Epoch: 6| Step: 9
Training loss: 3.6920549869537354
Validation loss: 3.5327409057207007

Epoch: 6| Step: 10
Training loss: 3.5222067832946777
Validation loss: 3.5283176822047078

Epoch: 6| Step: 11
Training loss: 3.990018129348755
Validation loss: 3.521650150258054

Epoch: 6| Step: 12
Training loss: 3.1601200103759766
Validation loss: 3.518429881782942

Epoch: 6| Step: 13
Training loss: 4.574779987335205
Validation loss: 3.510414397844704

Epoch: 6| Step: 0
Training loss: 3.1280195713043213
Validation loss: 3.5023469822381132

Epoch: 6| Step: 1
Training loss: 3.9163830280303955
Validation loss: 3.50336278382168

Epoch: 6| Step: 2
Training loss: 3.2996983528137207
Validation loss: 3.4941066644525014

Epoch: 6| Step: 3
Training loss: 4.356863021850586
Validation loss: 3.4903108381455943

Epoch: 6| Step: 4
Training loss: 3.6201059818267822
Validation loss: 3.4822008353407665

Epoch: 6| Step: 5
Training loss: 4.291067123413086
Validation loss: 3.4763528275233444

Epoch: 6| Step: 6
Training loss: 3.6933653354644775
Validation loss: 3.4755860861911567

Epoch: 6| Step: 7
Training loss: 3.1430468559265137
Validation loss: 3.4700665653392835

Epoch: 6| Step: 8
Training loss: 3.4951038360595703
Validation loss: 3.459819475809733

Epoch: 6| Step: 9
Training loss: 2.2325210571289062
Validation loss: 3.4541682556111324

Epoch: 6| Step: 10
Training loss: 3.7235116958618164
Validation loss: 3.4491048884648148

Epoch: 6| Step: 11
Training loss: 1.813596487045288
Validation loss: 3.4467623874705327

Epoch: 6| Step: 12
Training loss: 3.70121693611145
Validation loss: 3.4350371104414745

Epoch: 6| Step: 13
Training loss: 3.0663037300109863
Validation loss: 3.4306343370868313

Epoch: 7| Step: 0
Training loss: 3.592681884765625
Validation loss: 3.4291463308436896

Epoch: 6| Step: 1
Training loss: 3.5823235511779785
Validation loss: 3.420161775363389

Epoch: 6| Step: 2
Training loss: 3.3109583854675293
Validation loss: 3.41426851928875

Epoch: 6| Step: 3
Training loss: 3.603219985961914
Validation loss: 3.407508311733123

Epoch: 6| Step: 4
Training loss: 4.217205047607422
Validation loss: 3.396802848385226

Epoch: 6| Step: 5
Training loss: 3.8833365440368652
Validation loss: 3.3935773731559835

Epoch: 6| Step: 6
Training loss: 4.029279708862305
Validation loss: 3.388771923639441

Epoch: 6| Step: 7
Training loss: 2.7233452796936035
Validation loss: 3.378395898367769

Epoch: 6| Step: 8
Training loss: 2.520163059234619
Validation loss: 3.375055933511385

Epoch: 6| Step: 9
Training loss: 3.277501106262207
Validation loss: 3.3650402458765174

Epoch: 6| Step: 10
Training loss: 3.547903537750244
Validation loss: 3.3623031646974626

Epoch: 6| Step: 11
Training loss: 2.1299071311950684
Validation loss: 3.35352599236273

Epoch: 6| Step: 12
Training loss: 2.8775343894958496
Validation loss: 3.345593662672145

Epoch: 6| Step: 13
Training loss: 3.366668224334717
Validation loss: 3.34206142733174

Epoch: 8| Step: 0
Training loss: 3.0598206520080566
Validation loss: 3.332996609390423

Epoch: 6| Step: 1
Training loss: 3.8303074836730957
Validation loss: 3.326661007378691

Epoch: 6| Step: 2
Training loss: 3.474358081817627
Validation loss: 3.324860349778206

Epoch: 6| Step: 3
Training loss: 3.1965882778167725
Validation loss: 3.3168065522306707

Epoch: 6| Step: 4
Training loss: 2.5648555755615234
Validation loss: 3.309491665132584

Epoch: 6| Step: 5
Training loss: 3.134092330932617
Validation loss: 3.3018595454513386

Epoch: 6| Step: 6
Training loss: 3.9328441619873047
Validation loss: 3.2966369916034

Epoch: 6| Step: 7
Training loss: 2.7983555793762207
Validation loss: 3.290066190945205

Epoch: 6| Step: 8
Training loss: 2.5407214164733887
Validation loss: 3.2809551044176986

Epoch: 6| Step: 9
Training loss: 2.9179611206054688
Validation loss: 3.276734088056831

Epoch: 6| Step: 10
Training loss: 3.6556575298309326
Validation loss: 3.27152051976932

Epoch: 6| Step: 11
Training loss: 2.9213221073150635
Validation loss: 3.261146455682734

Epoch: 6| Step: 12
Training loss: 4.104629993438721
Validation loss: 3.252721284025459

Epoch: 6| Step: 13
Training loss: 3.3850038051605225
Validation loss: 3.248539488802674

Epoch: 9| Step: 0
Training loss: 4.300561904907227
Validation loss: 3.237646246469149

Epoch: 6| Step: 1
Training loss: 3.23574161529541
Validation loss: 3.2317941470812728

Epoch: 6| Step: 2
Training loss: 2.532825469970703
Validation loss: 3.220951564850346

Epoch: 6| Step: 3
Training loss: 3.0452117919921875
Validation loss: 3.2137849510356946

Epoch: 6| Step: 4
Training loss: 3.798248767852783
Validation loss: 3.2036038367978987

Epoch: 6| Step: 5
Training loss: 3.2661361694335938
Validation loss: 3.198367195744668

Epoch: 6| Step: 6
Training loss: 2.7738564014434814
Validation loss: 3.1884538409530476

Epoch: 6| Step: 7
Training loss: 3.4324073791503906
Validation loss: 3.1761501014873548

Epoch: 6| Step: 8
Training loss: 1.7792716026306152
Validation loss: 3.1652833671980005

Epoch: 6| Step: 9
Training loss: 3.9236419200897217
Validation loss: 3.1588353392898396

Epoch: 6| Step: 10
Training loss: 3.2044334411621094
Validation loss: 3.152536956212854

Epoch: 6| Step: 11
Training loss: 3.5272622108459473
Validation loss: 3.1444879219096196

Epoch: 6| Step: 12
Training loss: 2.6963765621185303
Validation loss: 3.1332003685735885

Epoch: 6| Step: 13
Training loss: 2.519284963607788
Validation loss: 3.1232206154895086

Epoch: 10| Step: 0
Training loss: 2.2753710746765137
Validation loss: 3.114222329149964

Epoch: 6| Step: 1
Training loss: 3.6015379428863525
Validation loss: 3.107862759661931

Epoch: 6| Step: 2
Training loss: 3.7285056114196777
Validation loss: 3.1016221020811345

Epoch: 6| Step: 3
Training loss: 3.5465660095214844
Validation loss: 3.089944137040005

Epoch: 6| Step: 4
Training loss: 2.7733139991760254
Validation loss: 3.0842190045182423

Epoch: 6| Step: 5
Training loss: 3.28817081451416
Validation loss: 3.0766755919302664

Epoch: 6| Step: 6
Training loss: 2.5714337825775146
Validation loss: 3.063484855877456

Epoch: 6| Step: 7
Training loss: 2.78410005569458
Validation loss: 3.0549365192331295

Epoch: 6| Step: 8
Training loss: 3.4121809005737305
Validation loss: 3.0439256596308883

Epoch: 6| Step: 9
Training loss: 3.431973457336426
Validation loss: 3.039807868260209

Epoch: 6| Step: 10
Training loss: 2.977710008621216
Validation loss: 3.026065121414841

Epoch: 6| Step: 11
Training loss: 3.6022064685821533
Validation loss: 3.014502938075732

Epoch: 6| Step: 12
Training loss: 1.875910758972168
Validation loss: 3.0080865070384037

Epoch: 6| Step: 13
Training loss: 3.080753803253174
Validation loss: 2.998102254765008

Epoch: 11| Step: 0
Training loss: 2.7099101543426514
Validation loss: 2.989915173540833

Epoch: 6| Step: 1
Training loss: 2.738842010498047
Validation loss: 2.974669030917588

Epoch: 6| Step: 2
Training loss: 3.161545991897583
Validation loss: 2.9660781147659465

Epoch: 6| Step: 3
Training loss: 3.349308490753174
Validation loss: 2.9529039116315943

Epoch: 6| Step: 4
Training loss: 2.935296058654785
Validation loss: 2.9417980524801437

Epoch: 6| Step: 5
Training loss: 2.358825445175171
Validation loss: 2.9318912054902766

Epoch: 6| Step: 6
Training loss: 2.418947458267212
Validation loss: 2.920317603695777

Epoch: 6| Step: 7
Training loss: 3.197800636291504
Validation loss: 2.911543207783853

Epoch: 6| Step: 8
Training loss: 3.4393625259399414
Validation loss: 2.9002166255827873

Epoch: 6| Step: 9
Training loss: 3.117394208908081
Validation loss: 2.893058840946485

Epoch: 6| Step: 10
Training loss: 2.9563136100769043
Validation loss: 2.881980001285512

Epoch: 6| Step: 11
Training loss: 2.694780111312866
Validation loss: 2.8680700153432865

Epoch: 6| Step: 12
Training loss: 3.725714683532715
Validation loss: 2.8637613199090444

Epoch: 6| Step: 13
Training loss: 2.555344820022583
Validation loss: 2.8520408676516626

Epoch: 12| Step: 0
Training loss: 3.627890110015869
Validation loss: 2.8403207819948912

Epoch: 6| Step: 1
Training loss: 3.361504077911377
Validation loss: 2.827021514215777

Epoch: 6| Step: 2
Training loss: 2.209221839904785
Validation loss: 2.816958181319698

Epoch: 6| Step: 3
Training loss: 2.6048245429992676
Validation loss: 2.8056633498079036

Epoch: 6| Step: 4
Training loss: 2.7569093704223633
Validation loss: 2.796318043944656

Epoch: 6| Step: 5
Training loss: 3.4185738563537598
Validation loss: 2.777553968532111

Epoch: 6| Step: 6
Training loss: 3.08622670173645
Validation loss: 2.7671627459987516

Epoch: 6| Step: 7
Training loss: 2.9371485710144043
Validation loss: 2.7561980883280435

Epoch: 6| Step: 8
Training loss: 3.3491902351379395
Validation loss: 2.752246977180563

Epoch: 6| Step: 9
Training loss: 2.385617971420288
Validation loss: 2.7424165997453915

Epoch: 6| Step: 10
Training loss: 2.40423583984375
Validation loss: 2.721600842732255

Epoch: 6| Step: 11
Training loss: 3.057612895965576
Validation loss: 2.7148104790718324

Epoch: 6| Step: 12
Training loss: 2.0885696411132812
Validation loss: 2.7050780532180623

Epoch: 6| Step: 13
Training loss: 2.8610002994537354
Validation loss: 2.69966709485618

Epoch: 13| Step: 0
Training loss: 3.029505729675293
Validation loss: 2.6856672738188054

Epoch: 6| Step: 1
Training loss: 2.2256264686584473
Validation loss: 2.6772659183830343

Epoch: 6| Step: 2
Training loss: 3.102497100830078
Validation loss: 2.660267465858049

Epoch: 6| Step: 3
Training loss: 2.422786235809326
Validation loss: 2.644758109123476

Epoch: 6| Step: 4
Training loss: 2.5706112384796143
Validation loss: 2.63404478052611

Epoch: 6| Step: 5
Training loss: 3.1550612449645996
Validation loss: 2.623029847298899

Epoch: 6| Step: 6
Training loss: 2.9162540435791016
Validation loss: 2.616606778995965

Epoch: 6| Step: 7
Training loss: 2.9496145248413086
Validation loss: 2.595873801938949

Epoch: 6| Step: 8
Training loss: 2.8527936935424805
Validation loss: 2.5837708186077815

Epoch: 6| Step: 9
Training loss: 2.302309513092041
Validation loss: 2.57859464358258

Epoch: 6| Step: 10
Training loss: 2.662533760070801
Validation loss: 2.56473627398091

Epoch: 6| Step: 11
Training loss: 2.40028977394104
Validation loss: 2.5492732935054327

Epoch: 6| Step: 12
Training loss: 3.1791415214538574
Validation loss: 2.5390077226905414

Epoch: 6| Step: 13
Training loss: 3.3250529766082764
Validation loss: 2.52775147140667

Epoch: 14| Step: 0
Training loss: 2.745476007461548
Validation loss: 2.5200123940744708

Epoch: 6| Step: 1
Training loss: 2.4454641342163086
Validation loss: 2.5077033119816936

Epoch: 6| Step: 2
Training loss: 2.2020606994628906
Validation loss: 2.498290131168981

Epoch: 6| Step: 3
Training loss: 2.4119882583618164
Validation loss: 2.481816355900098

Epoch: 6| Step: 4
Training loss: 2.1160292625427246
Validation loss: 2.4710877480045443

Epoch: 6| Step: 5
Training loss: 3.3985371589660645
Validation loss: 2.4657728825846026

Epoch: 6| Step: 6
Training loss: 2.637632131576538
Validation loss: 2.466024165512413

Epoch: 6| Step: 7
Training loss: 3.5318665504455566
Validation loss: 2.449235377773162

Epoch: 6| Step: 8
Training loss: 3.293490171432495
Validation loss: 2.434225531034572

Epoch: 6| Step: 9
Training loss: 2.972494125366211
Validation loss: 2.420295262849459

Epoch: 6| Step: 10
Training loss: 2.6171762943267822
Validation loss: 2.410416564633769

Epoch: 6| Step: 11
Training loss: 2.6421937942504883
Validation loss: 2.3980653901253977

Epoch: 6| Step: 12
Training loss: 2.262507915496826
Validation loss: 2.3851623278792187

Epoch: 6| Step: 13
Training loss: 1.9488604068756104
Validation loss: 2.382267775074128

Epoch: 15| Step: 0
Training loss: 2.620917320251465
Validation loss: 2.3722133123746483

Epoch: 6| Step: 1
Training loss: 2.9436652660369873
Validation loss: 2.356478178372947

Epoch: 6| Step: 2
Training loss: 1.7792946100234985
Validation loss: 2.35201169085759

Epoch: 6| Step: 3
Training loss: 2.734271287918091
Validation loss: 2.3470280298622708

Epoch: 6| Step: 4
Training loss: 2.89569091796875
Validation loss: 2.345208732030725

Epoch: 6| Step: 5
Training loss: 2.5226407051086426
Validation loss: 2.3439489538951586

Epoch: 6| Step: 6
Training loss: 2.154130458831787
Validation loss: 2.3339542547861734

Epoch: 6| Step: 7
Training loss: 3.060516834259033
Validation loss: 2.3131379747903473

Epoch: 6| Step: 8
Training loss: 2.2609050273895264
Validation loss: 2.3064549712724585

Epoch: 6| Step: 9
Training loss: 3.0683341026306152
Validation loss: 2.309378498344011

Epoch: 6| Step: 10
Training loss: 2.2402288913726807
Validation loss: 2.30904697602795

Epoch: 6| Step: 11
Training loss: 2.1946563720703125
Validation loss: 2.282663845246838

Epoch: 6| Step: 12
Training loss: 2.6990227699279785
Validation loss: 2.2837855636432605

Epoch: 6| Step: 13
Training loss: 3.3493337631225586
Validation loss: 2.274710532157652

Epoch: 16| Step: 0
Training loss: 2.799895763397217
Validation loss: 2.2611596456138034

Epoch: 6| Step: 1
Training loss: 2.4403016567230225
Validation loss: 2.255950450897217

Epoch: 6| Step: 2
Training loss: 2.6701791286468506
Validation loss: 2.2407325339573685

Epoch: 6| Step: 3
Training loss: 2.964229106903076
Validation loss: 2.22472349674471

Epoch: 6| Step: 4
Training loss: 2.199312448501587
Validation loss: 2.223995262576688

Epoch: 6| Step: 5
Training loss: 3.0327093601226807
Validation loss: 2.218038494868945

Epoch: 6| Step: 6
Training loss: 2.105684995651245
Validation loss: 2.2088311641447005

Epoch: 6| Step: 7
Training loss: 3.0353012084960938
Validation loss: 2.2069370285157235

Epoch: 6| Step: 8
Training loss: 2.7835161685943604
Validation loss: 2.195329794319727

Epoch: 6| Step: 9
Training loss: 2.4444658756256104
Validation loss: 2.1986220113692747

Epoch: 6| Step: 10
Training loss: 2.1859211921691895
Validation loss: 2.190117798825746

Epoch: 6| Step: 11
Training loss: 2.128602981567383
Validation loss: 2.1832984749988844

Epoch: 6| Step: 12
Training loss: 2.4111177921295166
Validation loss: 2.177076321776195

Epoch: 6| Step: 13
Training loss: 2.0728611946105957
Validation loss: 2.179406540368193

Epoch: 17| Step: 0
Training loss: 2.5595784187316895
Validation loss: 2.172965275344028

Epoch: 6| Step: 1
Training loss: 2.9613778591156006
Validation loss: 2.16674772385628

Epoch: 6| Step: 2
Training loss: 2.4642505645751953
Validation loss: 2.1566654264286

Epoch: 6| Step: 3
Training loss: 2.7078046798706055
Validation loss: 2.14766114757907

Epoch: 6| Step: 4
Training loss: 2.5680172443389893
Validation loss: 2.1527649741018973

Epoch: 6| Step: 5
Training loss: 2.943113327026367
Validation loss: 2.1433155613560833

Epoch: 6| Step: 6
Training loss: 2.3364875316619873
Validation loss: 2.139313551687425

Epoch: 6| Step: 7
Training loss: 2.3108417987823486
Validation loss: 2.144416252772013

Epoch: 6| Step: 8
Training loss: 2.5774734020233154
Validation loss: 2.1360388699398247

Epoch: 6| Step: 9
Training loss: 2.1682333946228027
Validation loss: 2.137012731644415

Epoch: 6| Step: 10
Training loss: 2.4594154357910156
Validation loss: 2.128039780483451

Epoch: 6| Step: 11
Training loss: 2.4134697914123535
Validation loss: 2.1283908249229513

Epoch: 6| Step: 12
Training loss: 2.4700212478637695
Validation loss: 2.1351901779892626

Epoch: 6| Step: 13
Training loss: 1.486088514328003
Validation loss: 2.129467292498517

Epoch: 18| Step: 0
Training loss: 2.311032295227051
Validation loss: 2.1273023390000865

Epoch: 6| Step: 1
Training loss: 2.8911232948303223
Validation loss: 2.1165303799413864

Epoch: 6| Step: 2
Training loss: 2.074342727661133
Validation loss: 2.1156498693650767

Epoch: 6| Step: 3
Training loss: 2.8055903911590576
Validation loss: 2.1151751241376324

Epoch: 6| Step: 4
Training loss: 1.9922552108764648
Validation loss: 2.1191083308189147

Epoch: 6| Step: 5
Training loss: 2.258084297180176
Validation loss: 2.108404342846204

Epoch: 6| Step: 6
Training loss: 2.7573013305664062
Validation loss: 2.116628472523023

Epoch: 6| Step: 7
Training loss: 2.1232380867004395
Validation loss: 2.113760150888915

Epoch: 6| Step: 8
Training loss: 2.8340003490448
Validation loss: 2.1173551518429994

Epoch: 6| Step: 9
Training loss: 3.1461517810821533
Validation loss: 2.1110802824779222

Epoch: 6| Step: 10
Training loss: 2.556403160095215
Validation loss: 2.117837254719068

Epoch: 6| Step: 11
Training loss: 2.0744214057922363
Validation loss: 2.101246346709549

Epoch: 6| Step: 12
Training loss: 2.5407962799072266
Validation loss: 2.1011394018767984

Epoch: 6| Step: 13
Training loss: 2.1164450645446777
Validation loss: 2.1072470013813307

Epoch: 19| Step: 0
Training loss: 2.2596702575683594
Validation loss: 2.1068540132173927

Epoch: 6| Step: 1
Training loss: 1.962026834487915
Validation loss: 2.100452673050665

Epoch: 6| Step: 2
Training loss: 2.139841318130493
Validation loss: 2.0939040748021935

Epoch: 6| Step: 3
Training loss: 2.6883914470672607
Validation loss: 2.0945845650088404

Epoch: 6| Step: 4
Training loss: 2.825751304626465
Validation loss: 2.087768462396437

Epoch: 6| Step: 5
Training loss: 2.4077773094177246
Validation loss: 2.0953549518380115

Epoch: 6| Step: 6
Training loss: 2.3788809776306152
Validation loss: 2.0842609559336016

Epoch: 6| Step: 7
Training loss: 2.477519989013672
Validation loss: 2.073938472296602

Epoch: 6| Step: 8
Training loss: 2.6045761108398438
Validation loss: 2.0725734221037997

Epoch: 6| Step: 9
Training loss: 2.296471118927002
Validation loss: 2.0612253104486773

Epoch: 6| Step: 10
Training loss: 2.7485055923461914
Validation loss: 2.0753403273961877

Epoch: 6| Step: 11
Training loss: 2.6577751636505127
Validation loss: 2.0623052504754837

Epoch: 6| Step: 12
Training loss: 2.6872305870056152
Validation loss: 2.0650003943392026

Epoch: 6| Step: 13
Training loss: 1.9872575998306274
Validation loss: 2.0523786134617303

Epoch: 20| Step: 0
Training loss: 3.0488240718841553
Validation loss: 2.064736714927099

Epoch: 6| Step: 1
Training loss: 2.2603938579559326
Validation loss: 2.054819090392

Epoch: 6| Step: 2
Training loss: 3.16481351852417
Validation loss: 2.0599528269101213

Epoch: 6| Step: 3
Training loss: 2.3805441856384277
Validation loss: 2.068386559845299

Epoch: 6| Step: 4
Training loss: 2.753624677658081
Validation loss: 2.0497247096030944

Epoch: 6| Step: 5
Training loss: 2.735414505004883
Validation loss: 2.056707848784744

Epoch: 6| Step: 6
Training loss: 1.6797317266464233
Validation loss: 2.0572099608759724

Epoch: 6| Step: 7
Training loss: 3.019705057144165
Validation loss: 2.0481624154634375

Epoch: 6| Step: 8
Training loss: 2.061561107635498
Validation loss: 2.0558237004023727

Epoch: 6| Step: 9
Training loss: 2.894275665283203
Validation loss: 2.0523651594756753

Epoch: 6| Step: 10
Training loss: 1.6531320810317993
Validation loss: 2.0494451625372774

Epoch: 6| Step: 11
Training loss: 1.602702260017395
Validation loss: 2.047756096368195

Epoch: 6| Step: 12
Training loss: 2.5682926177978516
Validation loss: 2.04029704037533

Epoch: 6| Step: 13
Training loss: 2.3122870922088623
Validation loss: 2.0484645007759013

Epoch: 21| Step: 0
Training loss: 2.2518913745880127
Validation loss: 2.044652267168927

Epoch: 6| Step: 1
Training loss: 2.2795443534851074
Validation loss: 2.041071581584151

Epoch: 6| Step: 2
Training loss: 2.569697856903076
Validation loss: 2.0319365865440777

Epoch: 6| Step: 3
Training loss: 3.032498359680176
Validation loss: 2.0284601744785102

Epoch: 6| Step: 4
Training loss: 2.9322128295898438
Validation loss: 2.0260057321158786

Epoch: 6| Step: 5
Training loss: 2.474440813064575
Validation loss: 2.0315402502654702

Epoch: 6| Step: 6
Training loss: 2.5930304527282715
Validation loss: 2.026504232037452

Epoch: 6| Step: 7
Training loss: 2.603196620941162
Validation loss: 2.024901641312466

Epoch: 6| Step: 8
Training loss: 2.2390055656433105
Validation loss: 2.0279565562484083

Epoch: 6| Step: 9
Training loss: 2.1418681144714355
Validation loss: 2.034534590218657

Epoch: 6| Step: 10
Training loss: 1.8822910785675049
Validation loss: 2.02141341599085

Epoch: 6| Step: 11
Training loss: 2.7709193229675293
Validation loss: 2.0086322574205298

Epoch: 6| Step: 12
Training loss: 2.125617742538452
Validation loss: 2.027651051039337

Epoch: 6| Step: 13
Training loss: 1.960593342781067
Validation loss: 2.0190358674654396

Epoch: 22| Step: 0
Training loss: 2.893773078918457
Validation loss: 2.0134302608428465

Epoch: 6| Step: 1
Training loss: 2.2272746562957764
Validation loss: 2.0194319268708587

Epoch: 6| Step: 2
Training loss: 1.8102848529815674
Validation loss: 2.015661875406901

Epoch: 6| Step: 3
Training loss: 2.721958875656128
Validation loss: 2.019940632645802

Epoch: 6| Step: 4
Training loss: 2.2488393783569336
Validation loss: 2.0195341776776057

Epoch: 6| Step: 5
Training loss: 2.112128734588623
Validation loss: 2.0240900939510715

Epoch: 6| Step: 6
Training loss: 2.9424781799316406
Validation loss: 2.016252451045539

Epoch: 6| Step: 7
Training loss: 2.807140350341797
Validation loss: 2.027361598066104

Epoch: 6| Step: 8
Training loss: 2.2554616928100586
Validation loss: 2.0245391399629655

Epoch: 6| Step: 9
Training loss: 2.6235785484313965
Validation loss: 2.0343097153530327

Epoch: 6| Step: 10
Training loss: 2.5441842079162598
Validation loss: 2.031611522038778

Epoch: 6| Step: 11
Training loss: 2.3654870986938477
Validation loss: 2.022320894784825

Epoch: 6| Step: 12
Training loss: 2.154078483581543
Validation loss: 2.031146408409201

Epoch: 6| Step: 13
Training loss: 2.295437812805176
Validation loss: 2.016508530544978

Epoch: 23| Step: 0
Training loss: 1.8167041540145874
Validation loss: 2.0205279563062932

Epoch: 6| Step: 1
Training loss: 1.8420565128326416
Validation loss: 2.0253256892645233

Epoch: 6| Step: 2
Training loss: 2.706947088241577
Validation loss: 2.0259617784971833

Epoch: 6| Step: 3
Training loss: 2.4299895763397217
Validation loss: 2.022848508691275

Epoch: 6| Step: 4
Training loss: 2.394322156906128
Validation loss: 2.0008804413580124

Epoch: 6| Step: 5
Training loss: 2.2666914463043213
Validation loss: 2.0120931812511977

Epoch: 6| Step: 6
Training loss: 2.577849864959717
Validation loss: 2.0126906428285825

Epoch: 6| Step: 7
Training loss: 3.0374579429626465
Validation loss: 2.0022276575847338

Epoch: 6| Step: 8
Training loss: 2.413602828979492
Validation loss: 2.0005546000696

Epoch: 6| Step: 9
Training loss: 3.3280415534973145
Validation loss: 2.000808410747077

Epoch: 6| Step: 10
Training loss: 2.7219078540802
Validation loss: 2.0086380589392876

Epoch: 6| Step: 11
Training loss: 2.0324466228485107
Validation loss: 2.0079869480543238

Epoch: 6| Step: 12
Training loss: 1.781942367553711
Validation loss: 2.006394547800864

Epoch: 6| Step: 13
Training loss: 2.908047914505005
Validation loss: 2.007762465425717

Epoch: 24| Step: 0
Training loss: 2.963999032974243
Validation loss: 2.0127067630008986

Epoch: 6| Step: 1
Training loss: 2.574199676513672
Validation loss: 2.0149030890516055

Epoch: 6| Step: 2
Training loss: 2.135435104370117
Validation loss: 2.018828225392167

Epoch: 6| Step: 3
Training loss: 2.7023773193359375
Validation loss: 2.028950983478177

Epoch: 6| Step: 4
Training loss: 3.2524943351745605
Validation loss: 2.021643248937463

Epoch: 6| Step: 5
Training loss: 2.2607457637786865
Validation loss: 2.0221584150868077

Epoch: 6| Step: 6
Training loss: 2.6115071773529053
Validation loss: 2.018926276955553

Epoch: 6| Step: 7
Training loss: 2.3336822986602783
Validation loss: 2.0147609890148206

Epoch: 6| Step: 8
Training loss: 2.1334176063537598
Validation loss: 2.016129518067965

Epoch: 6| Step: 9
Training loss: 2.561890125274658
Validation loss: 2.0232619649620465

Epoch: 6| Step: 10
Training loss: 2.304098129272461
Validation loss: 2.022391535902536

Epoch: 6| Step: 11
Training loss: 1.9345815181732178
Validation loss: 2.0256829466871036

Epoch: 6| Step: 12
Training loss: 2.038053512573242
Validation loss: 2.0246000982099965

Epoch: 6| Step: 13
Training loss: 1.5809979438781738
Validation loss: 2.0160654924249135

Epoch: 25| Step: 0
Training loss: 1.9530812501907349
Validation loss: 2.01994276431299

Epoch: 6| Step: 1
Training loss: 2.3598663806915283
Validation loss: 2.0303298273394184

Epoch: 6| Step: 2
Training loss: 2.133232593536377
Validation loss: 2.0279724380021453

Epoch: 6| Step: 3
Training loss: 2.7953972816467285
Validation loss: 2.0301295121510825

Epoch: 6| Step: 4
Training loss: 2.2466487884521484
Validation loss: 2.0274992245499805

Epoch: 6| Step: 5
Training loss: 2.961940288543701
Validation loss: 2.0202137193372174

Epoch: 6| Step: 6
Training loss: 1.9573540687561035
Validation loss: 2.0360449539717806

Epoch: 6| Step: 7
Training loss: 1.7843291759490967
Validation loss: 2.020679771259267

Epoch: 6| Step: 8
Training loss: 3.0631635189056396
Validation loss: 2.0236796256034606

Epoch: 6| Step: 9
Training loss: 2.281216859817505
Validation loss: 2.0283489329840547

Epoch: 6| Step: 10
Training loss: 2.927802085876465
Validation loss: 2.0283456476785804

Epoch: 6| Step: 11
Training loss: 2.272800922393799
Validation loss: 2.0252907763245287

Epoch: 6| Step: 12
Training loss: 2.1510062217712402
Validation loss: 2.0206390337277482

Epoch: 6| Step: 13
Training loss: 3.1373791694641113
Validation loss: 2.0152427201629965

Epoch: 26| Step: 0
Training loss: 2.31441330909729
Validation loss: 2.018321294938364

Epoch: 6| Step: 1
Training loss: 3.0149006843566895
Validation loss: 2.0176648273262927

Epoch: 6| Step: 2
Training loss: 2.5694549083709717
Validation loss: 2.029303471247355

Epoch: 6| Step: 3
Training loss: 2.7542338371276855
Validation loss: 2.017194251860342

Epoch: 6| Step: 4
Training loss: 2.2477798461914062
Validation loss: 2.0214017437350367

Epoch: 6| Step: 5
Training loss: 2.3247666358947754
Validation loss: 2.028882570164178

Epoch: 6| Step: 6
Training loss: 2.80391788482666
Validation loss: 2.029441105422153

Epoch: 6| Step: 7
Training loss: 1.9011754989624023
Validation loss: 2.0171585659826956

Epoch: 6| Step: 8
Training loss: 1.7045986652374268
Validation loss: 2.0132603747870332

Epoch: 6| Step: 9
Training loss: 2.646263360977173
Validation loss: 2.0216910249443463

Epoch: 6| Step: 10
Training loss: 2.118638515472412
Validation loss: 2.00947989443297

Epoch: 6| Step: 11
Training loss: 2.2270593643188477
Validation loss: 2.0109089882143083

Epoch: 6| Step: 12
Training loss: 2.579594373703003
Validation loss: 2.0144030112092213

Epoch: 6| Step: 13
Training loss: 2.4106972217559814
Validation loss: 2.0035975338310323

Epoch: 27| Step: 0
Training loss: 2.8504984378814697
Validation loss: 2.0085110818186114

Epoch: 6| Step: 1
Training loss: 2.318247079849243
Validation loss: 2.0020553296612156

Epoch: 6| Step: 2
Training loss: 2.378742218017578
Validation loss: 2.0066878129077215

Epoch: 6| Step: 3
Training loss: 2.2535009384155273
Validation loss: 2.003512147934206

Epoch: 6| Step: 4
Training loss: 2.7506790161132812
Validation loss: 1.9995019230791318

Epoch: 6| Step: 5
Training loss: 1.5415900945663452
Validation loss: 2.0132951762086604

Epoch: 6| Step: 6
Training loss: 2.427461862564087
Validation loss: 2.0104063313494445

Epoch: 6| Step: 7
Training loss: 2.2423532009124756
Validation loss: 1.9968177759519188

Epoch: 6| Step: 8
Training loss: 2.800060749053955
Validation loss: 1.988623611388668

Epoch: 6| Step: 9
Training loss: 2.1971817016601562
Validation loss: 1.998881536145364

Epoch: 6| Step: 10
Training loss: 2.619755268096924
Validation loss: 1.9955563186317362

Epoch: 6| Step: 11
Training loss: 2.4818506240844727
Validation loss: 1.9975534280141194

Epoch: 6| Step: 12
Training loss: 1.9133630990982056
Validation loss: 1.9925110724664503

Epoch: 6| Step: 13
Training loss: 2.8378498554229736
Validation loss: 1.9987057062887377

Epoch: 28| Step: 0
Training loss: 2.7249715328216553
Validation loss: 1.9951304492130075

Epoch: 6| Step: 1
Training loss: 2.2678327560424805
Validation loss: 1.9932857585209671

Epoch: 6| Step: 2
Training loss: 2.403367042541504
Validation loss: 1.9968855598921418

Epoch: 6| Step: 3
Training loss: 2.9628682136535645
Validation loss: 1.9880047895575081

Epoch: 6| Step: 4
Training loss: 2.4014811515808105
Validation loss: 1.999428851630098

Epoch: 6| Step: 5
Training loss: 2.4171595573425293
Validation loss: 1.9932487164774249

Epoch: 6| Step: 6
Training loss: 2.3838729858398438
Validation loss: 1.9903580437424362

Epoch: 6| Step: 7
Training loss: 2.066885471343994
Validation loss: 1.9836813339623072

Epoch: 6| Step: 8
Training loss: 2.385516405105591
Validation loss: 1.9947928408140778

Epoch: 6| Step: 9
Training loss: 2.5051705837249756
Validation loss: 1.9875378570249003

Epoch: 6| Step: 10
Training loss: 2.6013424396514893
Validation loss: 2.0005012289170296

Epoch: 6| Step: 11
Training loss: 2.5775508880615234
Validation loss: 1.9986659711407078

Epoch: 6| Step: 12
Training loss: 1.7194454669952393
Validation loss: 1.986300983736592

Epoch: 6| Step: 13
Training loss: 1.749513030052185
Validation loss: 1.988603340682163

Epoch: 29| Step: 0
Training loss: 2.7868995666503906
Validation loss: 1.9903724296118623

Epoch: 6| Step: 1
Training loss: 2.2992639541625977
Validation loss: 2.0003354369953112

Epoch: 6| Step: 2
Training loss: 2.312007427215576
Validation loss: 2.008658173263714

Epoch: 6| Step: 3
Training loss: 2.0063812732696533
Validation loss: 1.9892668954787716

Epoch: 6| Step: 4
Training loss: 2.416170597076416
Validation loss: 1.9953689600831719

Epoch: 6| Step: 5
Training loss: 2.22668719291687
Validation loss: 1.982056079372283

Epoch: 6| Step: 6
Training loss: 2.801219940185547
Validation loss: 1.9914412113928026

Epoch: 6| Step: 7
Training loss: 1.9313547611236572
Validation loss: 1.9925339337318175

Epoch: 6| Step: 8
Training loss: 2.1830179691314697
Validation loss: 1.9959753482572493

Epoch: 6| Step: 9
Training loss: 2.337376356124878
Validation loss: 1.9946155919823596

Epoch: 6| Step: 10
Training loss: 2.3318028450012207
Validation loss: 1.9836473311147382

Epoch: 6| Step: 11
Training loss: 2.5477447509765625
Validation loss: 1.9958362707527735

Epoch: 6| Step: 12
Training loss: 2.580016613006592
Validation loss: 1.9820234596088369

Epoch: 6| Step: 13
Training loss: 2.8414502143859863
Validation loss: 1.9901267879752702

Epoch: 30| Step: 0
Training loss: 2.9404914379119873
Validation loss: 1.996036958950822

Epoch: 6| Step: 1
Training loss: 2.1072161197662354
Validation loss: 2.0066251242032616

Epoch: 6| Step: 2
Training loss: 2.092170238494873
Validation loss: 1.9863014503191876

Epoch: 6| Step: 3
Training loss: 1.902644395828247
Validation loss: 1.9960537225969377

Epoch: 6| Step: 4
Training loss: 2.578439712524414
Validation loss: 1.9976640747439476

Epoch: 6| Step: 5
Training loss: 2.28920316696167
Validation loss: 1.9920865540863366

Epoch: 6| Step: 6
Training loss: 2.9425065517425537
Validation loss: 1.9986317696109894

Epoch: 6| Step: 7
Training loss: 2.7686734199523926
Validation loss: 1.9940175369221678

Epoch: 6| Step: 8
Training loss: 1.7379353046417236
Validation loss: 1.9968241401897964

Epoch: 6| Step: 9
Training loss: 2.1791162490844727
Validation loss: 1.9981743571578816

Epoch: 6| Step: 10
Training loss: 2.6938164234161377
Validation loss: 2.0031186944694928

Epoch: 6| Step: 11
Training loss: 3.2017629146575928
Validation loss: 2.0071638348282024

Epoch: 6| Step: 12
Training loss: 1.9198848009109497
Validation loss: 2.000203292856934

Epoch: 6| Step: 13
Training loss: 1.6803487539291382
Validation loss: 1.999400556728404

Epoch: 31| Step: 0
Training loss: 2.538020133972168
Validation loss: 1.9973840636591758

Epoch: 6| Step: 1
Training loss: 2.682028293609619
Validation loss: 1.9903844748773882

Epoch: 6| Step: 2
Training loss: 1.8302232027053833
Validation loss: 1.9989956937810427

Epoch: 6| Step: 3
Training loss: 2.873322010040283
Validation loss: 2.0062761460581133

Epoch: 6| Step: 4
Training loss: 2.1363282203674316
Validation loss: 2.001104081830671

Epoch: 6| Step: 5
Training loss: 2.0268497467041016
Validation loss: 2.0046314449720484

Epoch: 6| Step: 6
Training loss: 2.461848735809326
Validation loss: 1.9986182528157388

Epoch: 6| Step: 7
Training loss: 1.7297673225402832
Validation loss: 2.014676906729257

Epoch: 6| Step: 8
Training loss: 2.075129508972168
Validation loss: 2.0134802095351683

Epoch: 6| Step: 9
Training loss: 2.2551698684692383
Validation loss: 2.003854000440208

Epoch: 6| Step: 10
Training loss: 2.5844154357910156
Validation loss: 2.00316709087741

Epoch: 6| Step: 11
Training loss: 3.1506497859954834
Validation loss: 2.0117047550857707

Epoch: 6| Step: 12
Training loss: 2.561020851135254
Validation loss: 2.0011665756984423

Epoch: 6| Step: 13
Training loss: 2.4069366455078125
Validation loss: 2.01161418807122

Epoch: 32| Step: 0
Training loss: 2.0085678100585938
Validation loss: 2.0055157497364986

Epoch: 6| Step: 1
Training loss: 2.6184282302856445
Validation loss: 2.009534579451366

Epoch: 6| Step: 2
Training loss: 3.1380786895751953
Validation loss: 2.0019088406716623

Epoch: 6| Step: 3
Training loss: 2.4228196144104004
Validation loss: 1.997679138696322

Epoch: 6| Step: 4
Training loss: 2.1801724433898926
Validation loss: 2.0076591084080357

Epoch: 6| Step: 5
Training loss: 1.3336803913116455
Validation loss: 2.010789038032614

Epoch: 6| Step: 6
Training loss: 2.006995916366577
Validation loss: 2.016265182084935

Epoch: 6| Step: 7
Training loss: 1.944460391998291
Validation loss: 2.0016544659932456

Epoch: 6| Step: 8
Training loss: 1.463558316230774
Validation loss: 1.9993225887257566

Epoch: 6| Step: 9
Training loss: 2.3971781730651855
Validation loss: 2.0025003917755617

Epoch: 6| Step: 10
Training loss: 2.9777283668518066
Validation loss: 1.9949078111238376

Epoch: 6| Step: 11
Training loss: 2.9754979610443115
Validation loss: 1.999598116003057

Epoch: 6| Step: 12
Training loss: 3.1827640533447266
Validation loss: 1.991707521100198

Epoch: 6| Step: 13
Training loss: 2.435032844543457
Validation loss: 2.0036130002749863

Epoch: 33| Step: 0
Training loss: 2.7042458057403564
Validation loss: 2.0048316576147593

Epoch: 6| Step: 1
Training loss: 2.168073892593384
Validation loss: 2.0109693516967115

Epoch: 6| Step: 2
Training loss: 1.5087193250656128
Validation loss: 2.0082842842225106

Epoch: 6| Step: 3
Training loss: 2.1483683586120605
Validation loss: 2.00882883738446

Epoch: 6| Step: 4
Training loss: 2.626312732696533
Validation loss: 2.0069487787062124

Epoch: 6| Step: 5
Training loss: 2.634462833404541
Validation loss: 2.012730654849801

Epoch: 6| Step: 6
Training loss: 2.5045931339263916
Validation loss: 2.002598642021097

Epoch: 6| Step: 7
Training loss: 2.376277446746826
Validation loss: 2.0031970085636264

Epoch: 6| Step: 8
Training loss: 2.253265857696533
Validation loss: 2.021593027217414

Epoch: 6| Step: 9
Training loss: 2.0419063568115234
Validation loss: 1.9981792742206204

Epoch: 6| Step: 10
Training loss: 2.8661534786224365
Validation loss: 2.014019913570855

Epoch: 6| Step: 11
Training loss: 2.299865245819092
Validation loss: 1.996091179950263

Epoch: 6| Step: 12
Training loss: 2.582188606262207
Validation loss: 2.0123378179406606

Epoch: 6| Step: 13
Training loss: 2.3797097206115723
Validation loss: 2.0026208546853836

Epoch: 34| Step: 0
Training loss: 3.054363489151001
Validation loss: 2.005763256421653

Epoch: 6| Step: 1
Training loss: 2.875119686126709
Validation loss: 2.004447878047984

Epoch: 6| Step: 2
Training loss: 1.426023244857788
Validation loss: 1.9959509654711651

Epoch: 6| Step: 3
Training loss: 1.9286377429962158
Validation loss: 1.980256365191552

Epoch: 6| Step: 4
Training loss: 2.413365602493286
Validation loss: 2.000437540392722

Epoch: 6| Step: 5
Training loss: 1.9317182302474976
Validation loss: 1.990638658564578

Epoch: 6| Step: 6
Training loss: 3.0133235454559326
Validation loss: 1.9878267306153492

Epoch: 6| Step: 7
Training loss: 2.327115774154663
Validation loss: 1.9849208375459075

Epoch: 6| Step: 8
Training loss: 2.2226932048797607
Validation loss: 1.9847933451334636

Epoch: 6| Step: 9
Training loss: 2.742055892944336
Validation loss: 1.9906533687345442

Epoch: 6| Step: 10
Training loss: 2.4437289237976074
Validation loss: 1.9907038288731729

Epoch: 6| Step: 11
Training loss: 2.005146026611328
Validation loss: 1.986189301295947

Epoch: 6| Step: 12
Training loss: 2.559007167816162
Validation loss: 1.992437119125038

Epoch: 6| Step: 13
Training loss: 1.969951868057251
Validation loss: 1.972581059701981

Epoch: 35| Step: 0
Training loss: 2.0246615409851074
Validation loss: 1.9852481606186076

Epoch: 6| Step: 1
Training loss: 2.479218006134033
Validation loss: 1.9819805468282392

Epoch: 6| Step: 2
Training loss: 2.0340375900268555
Validation loss: 1.986979357657894

Epoch: 6| Step: 3
Training loss: 3.054025650024414
Validation loss: 1.9816363101364465

Epoch: 6| Step: 4
Training loss: 2.393486976623535
Validation loss: 1.9833687941233318

Epoch: 6| Step: 5
Training loss: 2.031977653503418
Validation loss: 1.9887325174065047

Epoch: 6| Step: 6
Training loss: 2.240342140197754
Validation loss: 1.988357190162905

Epoch: 6| Step: 7
Training loss: 1.8672294616699219
Validation loss: 1.9896698254410938

Epoch: 6| Step: 8
Training loss: 2.3913755416870117
Validation loss: 1.9889392904056016

Epoch: 6| Step: 9
Training loss: 3.11940336227417
Validation loss: 1.9921281645374913

Epoch: 6| Step: 10
Training loss: 1.7353030443191528
Validation loss: 1.9891964415068268

Epoch: 6| Step: 11
Training loss: 2.6429479122161865
Validation loss: 1.9934826973945863

Epoch: 6| Step: 12
Training loss: 2.1856842041015625
Validation loss: 1.9815623990951046

Epoch: 6| Step: 13
Training loss: 3.2338550090789795
Validation loss: 1.9888278053652855

Epoch: 36| Step: 0
Training loss: 2.0052268505096436
Validation loss: 1.9945461186029578

Epoch: 6| Step: 1
Training loss: 2.1445066928863525
Validation loss: 1.9857622500388854

Epoch: 6| Step: 2
Training loss: 2.7334494590759277
Validation loss: 1.9916198561268468

Epoch: 6| Step: 3
Training loss: 2.290161609649658
Validation loss: 1.9928786677698935

Epoch: 6| Step: 4
Training loss: 1.8846633434295654
Validation loss: 1.9981708065156014

Epoch: 6| Step: 5
Training loss: 1.9313429594039917
Validation loss: 1.9952039013626754

Epoch: 6| Step: 6
Training loss: 3.0111443996429443
Validation loss: 1.9872148806048977

Epoch: 6| Step: 7
Training loss: 3.1269307136535645
Validation loss: 1.9873267963368406

Epoch: 6| Step: 8
Training loss: 2.0780277252197266
Validation loss: 2.0030854273867864

Epoch: 6| Step: 9
Training loss: 2.119429349899292
Validation loss: 1.9944430038493166

Epoch: 6| Step: 10
Training loss: 2.652595281600952
Validation loss: 1.9892675363889305

Epoch: 6| Step: 11
Training loss: 2.418621301651001
Validation loss: 1.993202611964236

Epoch: 6| Step: 12
Training loss: 2.325732707977295
Validation loss: 1.9747822079607236

Epoch: 6| Step: 13
Training loss: 1.9852668046951294
Validation loss: 1.977963424498035

Epoch: 37| Step: 0
Training loss: 2.8640851974487305
Validation loss: 1.9714968114770868

Epoch: 6| Step: 1
Training loss: 2.013526678085327
Validation loss: 1.983666012364049

Epoch: 6| Step: 2
Training loss: 2.4603772163391113
Validation loss: 1.988903804491925

Epoch: 6| Step: 3
Training loss: 1.829911708831787
Validation loss: 1.9852882264762797

Epoch: 6| Step: 4
Training loss: 3.7208566665649414
Validation loss: 1.9909284012292021

Epoch: 6| Step: 5
Training loss: 2.6029555797576904
Validation loss: 1.993149390784643

Epoch: 6| Step: 6
Training loss: 1.6063135862350464
Validation loss: 1.9904389714681974

Epoch: 6| Step: 7
Training loss: 2.1972837448120117
Validation loss: 1.9812445922564434

Epoch: 6| Step: 8
Training loss: 2.7621073722839355
Validation loss: 1.9867833122130363

Epoch: 6| Step: 9
Training loss: 2.1969499588012695
Validation loss: 1.9876359483247161

Epoch: 6| Step: 10
Training loss: 2.0694351196289062
Validation loss: 1.993265732642143

Epoch: 6| Step: 11
Training loss: 1.9007400274276733
Validation loss: 1.991568560241371

Epoch: 6| Step: 12
Training loss: 2.2190496921539307
Validation loss: 1.9771102923218922

Epoch: 6| Step: 13
Training loss: 2.48612380027771
Validation loss: 1.995805521165171

Epoch: 38| Step: 0
Training loss: 2.435421943664551
Validation loss: 1.9845049112073836

Epoch: 6| Step: 1
Training loss: 2.8575479984283447
Validation loss: 1.9801777114150345

Epoch: 6| Step: 2
Training loss: 2.661302089691162
Validation loss: 1.9811062953805412

Epoch: 6| Step: 3
Training loss: 2.28309965133667
Validation loss: 1.9914512326640468

Epoch: 6| Step: 4
Training loss: 2.2743310928344727
Validation loss: 1.9889931242953065

Epoch: 6| Step: 5
Training loss: 2.250148296356201
Validation loss: 1.9911664775622788

Epoch: 6| Step: 6
Training loss: 2.0847091674804688
Validation loss: 1.9873734110145158

Epoch: 6| Step: 7
Training loss: 2.554208278656006
Validation loss: 1.9974094103741389

Epoch: 6| Step: 8
Training loss: 2.1029117107391357
Validation loss: 1.9900868951633413

Epoch: 6| Step: 9
Training loss: 2.2666573524475098
Validation loss: 1.9860742463860461

Epoch: 6| Step: 10
Training loss: 2.2778160572052
Validation loss: 1.996940499992781

Epoch: 6| Step: 11
Training loss: 2.2484633922576904
Validation loss: 1.9966315466870543

Epoch: 6| Step: 12
Training loss: 2.144714832305908
Validation loss: 1.9956410636184037

Epoch: 6| Step: 13
Training loss: 2.1729791164398193
Validation loss: 1.9868435705861738

Epoch: 39| Step: 0
Training loss: 2.1869258880615234
Validation loss: 1.99581092275599

Epoch: 6| Step: 1
Training loss: 1.9302300214767456
Validation loss: 1.9899823050345145

Epoch: 6| Step: 2
Training loss: 2.0197651386260986
Validation loss: 1.9788039166440246

Epoch: 6| Step: 3
Training loss: 2.489335775375366
Validation loss: 1.9915612487382786

Epoch: 6| Step: 4
Training loss: 2.7204442024230957
Validation loss: 1.9735544625148977

Epoch: 6| Step: 5
Training loss: 2.123725175857544
Validation loss: 1.9842105193804669

Epoch: 6| Step: 6
Training loss: 2.978472948074341
Validation loss: 1.9835721215894144

Epoch: 6| Step: 7
Training loss: 1.96109139919281
Validation loss: 1.9914687705296341

Epoch: 6| Step: 8
Training loss: 3.0979771614074707
Validation loss: 1.9886948370164441

Epoch: 6| Step: 9
Training loss: 2.4279117584228516
Validation loss: 1.9857846280579925

Epoch: 6| Step: 10
Training loss: 2.310779571533203
Validation loss: 1.9900118997020106

Epoch: 6| Step: 11
Training loss: 2.452197313308716
Validation loss: 1.9747282215344009

Epoch: 6| Step: 12
Training loss: 1.6045511960983276
Validation loss: 1.9818055501548193

Epoch: 6| Step: 13
Training loss: 2.510211944580078
Validation loss: 1.9818921499354865

Epoch: 40| Step: 0
Training loss: 2.200716972351074
Validation loss: 1.9933609629190097

Epoch: 6| Step: 1
Training loss: 2.1277248859405518
Validation loss: 1.9895420535918205

Epoch: 6| Step: 2
Training loss: 1.3505040407180786
Validation loss: 1.9811944487274333

Epoch: 6| Step: 3
Training loss: 2.1737618446350098
Validation loss: 1.9771534704392957

Epoch: 6| Step: 4
Training loss: 2.5760443210601807
Validation loss: 1.9784666261365336

Epoch: 6| Step: 5
Training loss: 2.112577438354492
Validation loss: 1.9823057895065637

Epoch: 6| Step: 6
Training loss: 2.0288171768188477
Validation loss: 1.9827515668766473

Epoch: 6| Step: 7
Training loss: 2.122342348098755
Validation loss: 1.9803165389645485

Epoch: 6| Step: 8
Training loss: 2.8288486003875732
Validation loss: 1.9794181277675014

Epoch: 6| Step: 9
Training loss: 2.953352689743042
Validation loss: 1.9801000907856932

Epoch: 6| Step: 10
Training loss: 2.3952014446258545
Validation loss: 1.9754309397871777

Epoch: 6| Step: 11
Training loss: 2.933238983154297
Validation loss: 1.9737253560814807

Epoch: 6| Step: 12
Training loss: 2.493021011352539
Validation loss: 1.9793486620790215

Epoch: 6| Step: 13
Training loss: 2.3434362411499023
Validation loss: 1.9851089369866155

Epoch: 41| Step: 0
Training loss: 1.8499095439910889
Validation loss: 1.9815704386721376

Epoch: 6| Step: 1
Training loss: 2.0171494483947754
Validation loss: 1.9817242160920174

Epoch: 6| Step: 2
Training loss: 2.8056962490081787
Validation loss: 1.9826324344963155

Epoch: 6| Step: 3
Training loss: 2.22990345954895
Validation loss: 1.9710430919483144

Epoch: 6| Step: 4
Training loss: 2.040437698364258
Validation loss: 1.9841232158804452

Epoch: 6| Step: 5
Training loss: 1.1832504272460938
Validation loss: 1.9758512384148055

Epoch: 6| Step: 6
Training loss: 2.809122085571289
Validation loss: 1.9798313110105452

Epoch: 6| Step: 7
Training loss: 2.635092258453369
Validation loss: 1.978119300257775

Epoch: 6| Step: 8
Training loss: 2.588207244873047
Validation loss: 1.980719509945121

Epoch: 6| Step: 9
Training loss: 3.0416572093963623
Validation loss: 1.9693470667767268

Epoch: 6| Step: 10
Training loss: 1.9033421277999878
Validation loss: 1.9707949494802823

Epoch: 6| Step: 11
Training loss: 2.5396485328674316
Validation loss: 1.9840211227375975

Epoch: 6| Step: 12
Training loss: 2.70613431930542
Validation loss: 1.9773786631963586

Epoch: 6| Step: 13
Training loss: 2.1457440853118896
Validation loss: 1.9779168816022976

Epoch: 42| Step: 0
Training loss: 1.8696036338806152
Validation loss: 1.9720055467338973

Epoch: 6| Step: 1
Training loss: 2.6349692344665527
Validation loss: 1.9675436917171683

Epoch: 6| Step: 2
Training loss: 2.0454862117767334
Validation loss: 1.9756651873229651

Epoch: 6| Step: 3
Training loss: 2.5587828159332275
Validation loss: 1.983749794703658

Epoch: 6| Step: 4
Training loss: 2.1560683250427246
Validation loss: 1.9820179118905017

Epoch: 6| Step: 5
Training loss: 2.7833969593048096
Validation loss: 1.9684991862184258

Epoch: 6| Step: 6
Training loss: 2.528808832168579
Validation loss: 1.99126862454158

Epoch: 6| Step: 7
Training loss: 2.0752511024475098
Validation loss: 1.9696592861606228

Epoch: 6| Step: 8
Training loss: 2.0282750129699707
Validation loss: 1.9728507611059374

Epoch: 6| Step: 9
Training loss: 2.3327012062072754
Validation loss: 1.979339438100015

Epoch: 6| Step: 10
Training loss: 3.1689767837524414
Validation loss: 1.9672816902078607

Epoch: 6| Step: 11
Training loss: 1.9724135398864746
Validation loss: 1.9640254782092186

Epoch: 6| Step: 12
Training loss: 2.1360208988189697
Validation loss: 1.9650034263569822

Epoch: 6| Step: 13
Training loss: 2.317356586456299
Validation loss: 1.9782918101997786

Epoch: 43| Step: 0
Training loss: 2.4276649951934814
Validation loss: 1.979264272156582

Epoch: 6| Step: 1
Training loss: 2.408691883087158
Validation loss: 1.9721437026095647

Epoch: 6| Step: 2
Training loss: 2.461038589477539
Validation loss: 1.9702705003881966

Epoch: 6| Step: 3
Training loss: 2.2962968349456787
Validation loss: 1.976042175805697

Epoch: 6| Step: 4
Training loss: 2.206975221633911
Validation loss: 1.98056153328188

Epoch: 6| Step: 5
Training loss: 2.285597085952759
Validation loss: 1.9822974666472404

Epoch: 6| Step: 6
Training loss: 1.98690664768219
Validation loss: 1.9690795842037405

Epoch: 6| Step: 7
Training loss: 1.961220383644104
Validation loss: 1.9820043886861494

Epoch: 6| Step: 8
Training loss: 2.495349884033203
Validation loss: 1.9836153855887793

Epoch: 6| Step: 9
Training loss: 2.27414608001709
Validation loss: 1.9828005144673009

Epoch: 6| Step: 10
Training loss: 2.3922646045684814
Validation loss: 1.9892781344793176

Epoch: 6| Step: 11
Training loss: 1.8848469257354736
Validation loss: 1.983964381679412

Epoch: 6| Step: 12
Training loss: 2.614616870880127
Validation loss: 1.9817278269798524

Epoch: 6| Step: 13
Training loss: 3.238764524459839
Validation loss: 1.98239525031018

Epoch: 44| Step: 0
Training loss: 2.1699936389923096
Validation loss: 1.9739545186360676

Epoch: 6| Step: 1
Training loss: 2.832119941711426
Validation loss: 1.991177466607863

Epoch: 6| Step: 2
Training loss: 2.2073493003845215
Validation loss: 1.9859789956000544

Epoch: 6| Step: 3
Training loss: 2.1697354316711426
Validation loss: 1.9866139427308114

Epoch: 6| Step: 4
Training loss: 1.6500492095947266
Validation loss: 1.9904171446318268

Epoch: 6| Step: 5
Training loss: 1.8255289793014526
Validation loss: 1.9858213291373303

Epoch: 6| Step: 6
Training loss: 2.651898145675659
Validation loss: 1.9852629682069183

Epoch: 6| Step: 7
Training loss: 2.3556156158447266
Validation loss: 1.981452699630491

Epoch: 6| Step: 8
Training loss: 2.6105265617370605
Validation loss: 1.9932390464249479

Epoch: 6| Step: 9
Training loss: 2.0286102294921875
Validation loss: 1.9847921556042087

Epoch: 6| Step: 10
Training loss: 2.675015926361084
Validation loss: 1.9888335953476608

Epoch: 6| Step: 11
Training loss: 2.4891464710235596
Validation loss: 1.983585003883608

Epoch: 6| Step: 12
Training loss: 2.0320749282836914
Validation loss: 1.994487775269375

Epoch: 6| Step: 13
Training loss: 2.9365346431732178
Validation loss: 1.9729856932035057

Epoch: 45| Step: 0
Training loss: 2.2295610904693604
Validation loss: 1.9731702984020274

Epoch: 6| Step: 1
Training loss: 2.3189125061035156
Validation loss: 1.9839635946417367

Epoch: 6| Step: 2
Training loss: 2.2273807525634766
Validation loss: 1.9863558866644417

Epoch: 6| Step: 3
Training loss: 3.3166959285736084
Validation loss: 1.974351308679068

Epoch: 6| Step: 4
Training loss: 2.21752667427063
Validation loss: 1.9766100401519446

Epoch: 6| Step: 5
Training loss: 1.8828010559082031
Validation loss: 1.9879256217710433

Epoch: 6| Step: 6
Training loss: 2.057107925415039
Validation loss: 1.977090980416985

Epoch: 6| Step: 7
Training loss: 1.9046039581298828
Validation loss: 1.9710283305055352

Epoch: 6| Step: 8
Training loss: 2.6210556030273438
Validation loss: 1.9678815513528802

Epoch: 6| Step: 9
Training loss: 2.2261850833892822
Validation loss: 1.9680327766685075

Epoch: 6| Step: 10
Training loss: 2.0591559410095215
Validation loss: 1.9545139189689391

Epoch: 6| Step: 11
Training loss: 2.474944829940796
Validation loss: 1.9688667405036189

Epoch: 6| Step: 12
Training loss: 2.6739134788513184
Validation loss: 1.9720185649010442

Epoch: 6| Step: 13
Training loss: 2.1692914962768555
Validation loss: 1.9630130311494232

Epoch: 46| Step: 0
Training loss: 1.4843671321868896
Validation loss: 1.9738219322696808

Epoch: 6| Step: 1
Training loss: 2.355933666229248
Validation loss: 1.9704075013437579

Epoch: 6| Step: 2
Training loss: 2.7669711112976074
Validation loss: 1.974528315246746

Epoch: 6| Step: 3
Training loss: 2.899940013885498
Validation loss: 1.9818759118357012

Epoch: 6| Step: 4
Training loss: 2.4519214630126953
Validation loss: 1.9818153227529218

Epoch: 6| Step: 5
Training loss: 2.834892988204956
Validation loss: 1.9700273262557162

Epoch: 6| Step: 6
Training loss: 2.5311028957366943
Validation loss: 1.9941219232415641

Epoch: 6| Step: 7
Training loss: 2.483104944229126
Validation loss: 1.9998626350074686

Epoch: 6| Step: 8
Training loss: 1.781661033630371
Validation loss: 1.992679315228616

Epoch: 6| Step: 9
Training loss: 2.529402256011963
Validation loss: 1.996492693501134

Epoch: 6| Step: 10
Training loss: 1.7796566486358643
Validation loss: 1.9945199963867024

Epoch: 6| Step: 11
Training loss: 2.736002206802368
Validation loss: 1.9895159544483307

Epoch: 6| Step: 12
Training loss: 1.962500810623169
Validation loss: 1.9829477699854041

Epoch: 6| Step: 13
Training loss: 1.6684283018112183
Validation loss: 1.9971206470202374

Epoch: 47| Step: 0
Training loss: 3.2039570808410645
Validation loss: 1.9811259136405042

Epoch: 6| Step: 1
Training loss: 2.877635955810547
Validation loss: 1.9860156018246886

Epoch: 6| Step: 2
Training loss: 2.427490711212158
Validation loss: 1.9952675732233192

Epoch: 6| Step: 3
Training loss: 2.245227575302124
Validation loss: 1.975908439646485

Epoch: 6| Step: 4
Training loss: 1.3415727615356445
Validation loss: 1.9875911179409231

Epoch: 6| Step: 5
Training loss: 2.1679606437683105
Validation loss: 1.9790798643583893

Epoch: 6| Step: 6
Training loss: 2.1936655044555664
Validation loss: 1.9809694213251914

Epoch: 6| Step: 7
Training loss: 2.302114486694336
Validation loss: 1.974863798387589

Epoch: 6| Step: 8
Training loss: 2.4142184257507324
Validation loss: 1.9810616841880224

Epoch: 6| Step: 9
Training loss: 2.1756112575531006
Validation loss: 1.9765452031166322

Epoch: 6| Step: 10
Training loss: 2.678708791732788
Validation loss: 1.9706946701131842

Epoch: 6| Step: 11
Training loss: 2.2554726600646973
Validation loss: 1.9748058421637422

Epoch: 6| Step: 12
Training loss: 1.6301028728485107
Validation loss: 1.9702147847862654

Epoch: 6| Step: 13
Training loss: 2.228989839553833
Validation loss: 1.9777706387222453

Epoch: 48| Step: 0
Training loss: 2.961246967315674
Validation loss: 1.9690101967063

Epoch: 6| Step: 1
Training loss: 2.0981884002685547
Validation loss: 1.9592330122506747

Epoch: 6| Step: 2
Training loss: 2.100914239883423
Validation loss: 1.9646525126631542

Epoch: 6| Step: 3
Training loss: 2.862478733062744
Validation loss: 1.9652723984051776

Epoch: 6| Step: 4
Training loss: 2.6068673133850098
Validation loss: 1.9762585727117394

Epoch: 6| Step: 5
Training loss: 2.208096504211426
Validation loss: 1.9723425398590744

Epoch: 6| Step: 6
Training loss: 1.9547606706619263
Validation loss: 1.9645362400239514

Epoch: 6| Step: 7
Training loss: 1.7027308940887451
Validation loss: 1.9666274221994544

Epoch: 6| Step: 8
Training loss: 2.409029245376587
Validation loss: 1.9771042331572501

Epoch: 6| Step: 9
Training loss: 2.078416347503662
Validation loss: 1.9533591911356936

Epoch: 6| Step: 10
Training loss: 2.2766096591949463
Validation loss: 1.9698188522810578

Epoch: 6| Step: 11
Training loss: 1.9238855838775635
Validation loss: 1.967917779440521

Epoch: 6| Step: 12
Training loss: 2.1006064414978027
Validation loss: 1.9549738617353543

Epoch: 6| Step: 13
Training loss: 3.243323802947998
Validation loss: 1.9615438099830382

Epoch: 49| Step: 0
Training loss: 2.790121078491211
Validation loss: 1.9707106300579604

Epoch: 6| Step: 1
Training loss: 2.651865005493164
Validation loss: 1.949948126269925

Epoch: 6| Step: 2
Training loss: 2.0739383697509766
Validation loss: 1.9605440721716931

Epoch: 6| Step: 3
Training loss: 2.2364084720611572
Validation loss: 1.964960882740636

Epoch: 6| Step: 4
Training loss: 1.8574415445327759
Validation loss: 1.9569243359309372

Epoch: 6| Step: 5
Training loss: 2.427887439727783
Validation loss: 1.9684389098998039

Epoch: 6| Step: 6
Training loss: 2.1923840045928955
Validation loss: 1.9718154835444626

Epoch: 6| Step: 7
Training loss: 1.4901959896087646
Validation loss: 1.9774788002814017

Epoch: 6| Step: 8
Training loss: 2.400607109069824
Validation loss: 1.9661144415537517

Epoch: 6| Step: 9
Training loss: 2.030564785003662
Validation loss: 1.9723661561166086

Epoch: 6| Step: 10
Training loss: 2.2841567993164062
Validation loss: 1.9591197685528827

Epoch: 6| Step: 11
Training loss: 2.40350341796875
Validation loss: 1.9534922825392855

Epoch: 6| Step: 12
Training loss: 2.367908000946045
Validation loss: 1.9745115926188808

Epoch: 6| Step: 13
Training loss: 3.3625617027282715
Validation loss: 1.9631852462727537

Epoch: 50| Step: 0
Training loss: 2.572736978530884
Validation loss: 1.9594864665821035

Epoch: 6| Step: 1
Training loss: 1.8368966579437256
Validation loss: 1.9596581600045646

Epoch: 6| Step: 2
Training loss: 2.6820931434631348
Validation loss: 1.9603002353381085

Epoch: 6| Step: 3
Training loss: 2.033358097076416
Validation loss: 1.9501280297515213

Epoch: 6| Step: 4
Training loss: 1.3767110109329224
Validation loss: 1.9636275511915966

Epoch: 6| Step: 5
Training loss: 2.2930808067321777
Validation loss: 1.9554706440177014

Epoch: 6| Step: 6
Training loss: 2.3892977237701416
Validation loss: 1.9752111319572694

Epoch: 6| Step: 7
Training loss: 2.251275062561035
Validation loss: 1.9589068787072295

Epoch: 6| Step: 8
Training loss: 2.115341901779175
Validation loss: 1.959614904977942

Epoch: 6| Step: 9
Training loss: 1.9704978466033936
Validation loss: 1.9622109936129661

Epoch: 6| Step: 10
Training loss: 2.6699371337890625
Validation loss: 1.9515436567286009

Epoch: 6| Step: 11
Training loss: 2.856590747833252
Validation loss: 1.9625378988122428

Epoch: 6| Step: 12
Training loss: 2.2895054817199707
Validation loss: 1.9573214874472669

Epoch: 6| Step: 13
Training loss: 2.8746838569641113
Validation loss: 1.9586812116766488

Epoch: 51| Step: 0
Training loss: 3.1781387329101562
Validation loss: 1.9607150631566201

Epoch: 6| Step: 1
Training loss: 2.090702533721924
Validation loss: 1.964496099820701

Epoch: 6| Step: 2
Training loss: 1.8325377702713013
Validation loss: 1.9508690218771658

Epoch: 6| Step: 3
Training loss: 2.5090208053588867
Validation loss: 1.9570413302349787

Epoch: 6| Step: 4
Training loss: 1.8460335731506348
Validation loss: 1.9505928331805813

Epoch: 6| Step: 5
Training loss: 2.5910260677337646
Validation loss: 1.966606152954922

Epoch: 6| Step: 6
Training loss: 2.2802071571350098
Validation loss: 1.9543992075868832

Epoch: 6| Step: 7
Training loss: 1.8958821296691895
Validation loss: 1.9545446839383853

Epoch: 6| Step: 8
Training loss: 2.6123392581939697
Validation loss: 1.9614159676336473

Epoch: 6| Step: 9
Training loss: 1.9109177589416504
Validation loss: 1.9693739568033526

Epoch: 6| Step: 10
Training loss: 2.0241026878356934
Validation loss: 1.9525300777086647

Epoch: 6| Step: 11
Training loss: 2.320755958557129
Validation loss: 1.9591998451499528

Epoch: 6| Step: 12
Training loss: 2.204699754714966
Validation loss: 1.9541931101070937

Epoch: 6| Step: 13
Training loss: 3.1033215522766113
Validation loss: 1.955980639303884

Epoch: 52| Step: 0
Training loss: 1.9929990768432617
Validation loss: 1.9678563302563084

Epoch: 6| Step: 1
Training loss: 2.4949796199798584
Validation loss: 1.9617120835088915

Epoch: 6| Step: 2
Training loss: 2.333772897720337
Validation loss: 1.9493110154264717

Epoch: 6| Step: 3
Training loss: 2.0102295875549316
Validation loss: 1.9611286271002986

Epoch: 6| Step: 4
Training loss: 2.1025567054748535
Validation loss: 1.9574362590748777

Epoch: 6| Step: 5
Training loss: 2.683070182800293
Validation loss: 1.9536305986424929

Epoch: 6| Step: 6
Training loss: 1.9325200319290161
Validation loss: 1.949745721714471

Epoch: 6| Step: 7
Training loss: 2.201846122741699
Validation loss: 1.9542823260830295

Epoch: 6| Step: 8
Training loss: 2.245847702026367
Validation loss: 1.9604638366289036

Epoch: 6| Step: 9
Training loss: 2.5173914432525635
Validation loss: 1.9502909619321105

Epoch: 6| Step: 10
Training loss: 2.6789186000823975
Validation loss: 1.9382267613564768

Epoch: 6| Step: 11
Training loss: 2.0932891368865967
Validation loss: 1.952392638370555

Epoch: 6| Step: 12
Training loss: 2.573531150817871
Validation loss: 1.9648740855596398

Epoch: 6| Step: 13
Training loss: 2.0885868072509766
Validation loss: 1.9591678547602829

Epoch: 53| Step: 0
Training loss: 1.9878871440887451
Validation loss: 1.9772283569458993

Epoch: 6| Step: 1
Training loss: 1.8756427764892578
Validation loss: 1.9563390836920789

Epoch: 6| Step: 2
Training loss: 2.3287172317504883
Validation loss: 1.9560192220954484

Epoch: 6| Step: 3
Training loss: 2.7408313751220703
Validation loss: 1.9616136294539257

Epoch: 6| Step: 4
Training loss: 2.850961208343506
Validation loss: 1.9646214669750584

Epoch: 6| Step: 5
Training loss: 2.3769257068634033
Validation loss: 1.9643947770518642

Epoch: 6| Step: 6
Training loss: 1.7400877475738525
Validation loss: 1.9606915827720397

Epoch: 6| Step: 7
Training loss: 2.648867130279541
Validation loss: 1.9654037708877234

Epoch: 6| Step: 8
Training loss: 2.1804721355438232
Validation loss: 1.9676111462295696

Epoch: 6| Step: 9
Training loss: 2.4908876419067383
Validation loss: 1.966772456322947

Epoch: 6| Step: 10
Training loss: 1.767639398574829
Validation loss: 1.959642591014985

Epoch: 6| Step: 11
Training loss: 2.3729910850524902
Validation loss: 1.9623954308930265

Epoch: 6| Step: 12
Training loss: 2.3614840507507324
Validation loss: 1.9761724651500743

Epoch: 6| Step: 13
Training loss: 2.2035279273986816
Validation loss: 1.9709550924198602

Epoch: 54| Step: 0
Training loss: 1.9489898681640625
Validation loss: 1.9619192730995916

Epoch: 6| Step: 1
Training loss: 2.483842372894287
Validation loss: 1.9757116148548741

Epoch: 6| Step: 2
Training loss: 2.4525747299194336
Validation loss: 1.9556714988523913

Epoch: 6| Step: 3
Training loss: 1.9254460334777832
Validation loss: 1.956101312432238

Epoch: 6| Step: 4
Training loss: 2.6472039222717285
Validation loss: 1.9571176062348068

Epoch: 6| Step: 5
Training loss: 2.1648364067077637
Validation loss: 1.9592343197073987

Epoch: 6| Step: 6
Training loss: 2.1290078163146973
Validation loss: 1.9509124960950626

Epoch: 6| Step: 7
Training loss: 2.4265451431274414
Validation loss: 1.964517488274523

Epoch: 6| Step: 8
Training loss: 2.182983160018921
Validation loss: 1.9473824219037128

Epoch: 6| Step: 9
Training loss: 1.8674722909927368
Validation loss: 1.950667614577919

Epoch: 6| Step: 10
Training loss: 2.8886914253234863
Validation loss: 1.9428602931320027

Epoch: 6| Step: 11
Training loss: 1.9199399948120117
Validation loss: 1.9544769986983268

Epoch: 6| Step: 12
Training loss: 2.2167274951934814
Validation loss: 1.9680155707943825

Epoch: 6| Step: 13
Training loss: 2.8296399116516113
Validation loss: 1.952459296872539

Epoch: 55| Step: 0
Training loss: 2.542814016342163
Validation loss: 1.9677442607059275

Epoch: 6| Step: 1
Training loss: 2.1352379322052
Validation loss: 1.965505430775304

Epoch: 6| Step: 2
Training loss: 2.5811643600463867
Validation loss: 1.948697514431451

Epoch: 6| Step: 3
Training loss: 2.883837938308716
Validation loss: 1.967529817294049

Epoch: 6| Step: 4
Training loss: 2.367696762084961
Validation loss: 1.9651120170470207

Epoch: 6| Step: 5
Training loss: 2.1140689849853516
Validation loss: 1.953079874797534

Epoch: 6| Step: 6
Training loss: 2.1138696670532227
Validation loss: 1.9555689301542056

Epoch: 6| Step: 7
Training loss: 2.285231351852417
Validation loss: 1.9531118023780085

Epoch: 6| Step: 8
Training loss: 1.9195573329925537
Validation loss: 1.9721946472762732

Epoch: 6| Step: 9
Training loss: 1.8320850133895874
Validation loss: 1.947536963288502

Epoch: 6| Step: 10
Training loss: 1.999700665473938
Validation loss: 1.9557103431353005

Epoch: 6| Step: 11
Training loss: 2.403398036956787
Validation loss: 1.9621719724388533

Epoch: 6| Step: 12
Training loss: 2.5765552520751953
Validation loss: 1.9535582116855088

Epoch: 6| Step: 13
Training loss: 1.716233730316162
Validation loss: 1.9463523575054702

Epoch: 56| Step: 0
Training loss: 2.5638961791992188
Validation loss: 1.956087855882542

Epoch: 6| Step: 1
Training loss: 1.6150273084640503
Validation loss: 1.9551408162681005

Epoch: 6| Step: 2
Training loss: 2.2422235012054443
Validation loss: 1.9561134922888972

Epoch: 6| Step: 3
Training loss: 2.176548957824707
Validation loss: 1.9398675964724632

Epoch: 6| Step: 4
Training loss: 2.362105369567871
Validation loss: 1.9506460761511197

Epoch: 6| Step: 5
Training loss: 3.093005657196045
Validation loss: 1.9357348565132386

Epoch: 6| Step: 6
Training loss: 2.7003350257873535
Validation loss: 1.952586704684842

Epoch: 6| Step: 7
Training loss: 2.546722888946533
Validation loss: 1.9569791568222867

Epoch: 6| Step: 8
Training loss: 1.867363691329956
Validation loss: 1.9435866084150089

Epoch: 6| Step: 9
Training loss: 2.425332546234131
Validation loss: 1.9557355039863176

Epoch: 6| Step: 10
Training loss: 2.4281129837036133
Validation loss: 1.947123699290778

Epoch: 6| Step: 11
Training loss: 1.6350152492523193
Validation loss: 1.9497132442330802

Epoch: 6| Step: 12
Training loss: 2.036715269088745
Validation loss: 1.9596776885371054

Epoch: 6| Step: 13
Training loss: 2.003156900405884
Validation loss: 1.9565501482255998

Epoch: 57| Step: 0
Training loss: 2.560847759246826
Validation loss: 1.9449571870988416

Epoch: 6| Step: 1
Training loss: 2.2717669010162354
Validation loss: 1.9492162401958177

Epoch: 6| Step: 2
Training loss: 1.7032395601272583
Validation loss: 1.9635235084000455

Epoch: 6| Step: 3
Training loss: 3.2776904106140137
Validation loss: 1.9413588931483607

Epoch: 6| Step: 4
Training loss: 2.54178524017334
Validation loss: 1.9541625194652106

Epoch: 6| Step: 5
Training loss: 1.9589312076568604
Validation loss: 1.950690156670027

Epoch: 6| Step: 6
Training loss: 2.1909658908843994
Validation loss: 1.9539928910552815

Epoch: 6| Step: 7
Training loss: 1.7343851327896118
Validation loss: 1.9588397292680637

Epoch: 6| Step: 8
Training loss: 2.4796619415283203
Validation loss: 1.950994958159744

Epoch: 6| Step: 9
Training loss: 2.29445219039917
Validation loss: 1.9557223179007088

Epoch: 6| Step: 10
Training loss: 2.032914638519287
Validation loss: 1.971242404753162

Epoch: 6| Step: 11
Training loss: 1.7462201118469238
Validation loss: 1.959939629800858

Epoch: 6| Step: 12
Training loss: 2.409808397293091
Validation loss: 1.9585343201955159

Epoch: 6| Step: 13
Training loss: 2.6831564903259277
Validation loss: 1.962857005416706

Epoch: 58| Step: 0
Training loss: 2.3689565658569336
Validation loss: 1.9548068661843576

Epoch: 6| Step: 1
Training loss: 1.937740683555603
Validation loss: 1.948275068754791

Epoch: 6| Step: 2
Training loss: 1.7747195959091187
Validation loss: 1.9610151103747788

Epoch: 6| Step: 3
Training loss: 3.242702007293701
Validation loss: 1.9562147560939993

Epoch: 6| Step: 4
Training loss: 2.065782308578491
Validation loss: 1.9566313605154715

Epoch: 6| Step: 5
Training loss: 2.776338577270508
Validation loss: 1.9627221733011224

Epoch: 6| Step: 6
Training loss: 2.0026984214782715
Validation loss: 1.9572549494363929

Epoch: 6| Step: 7
Training loss: 2.638317346572876
Validation loss: 1.9684950087660102

Epoch: 6| Step: 8
Training loss: 2.1898348331451416
Validation loss: 1.95569747237749

Epoch: 6| Step: 9
Training loss: 2.2705016136169434
Validation loss: 1.9514568749294485

Epoch: 6| Step: 10
Training loss: 2.3967580795288086
Validation loss: 1.961186412842043

Epoch: 6| Step: 11
Training loss: 1.8631527423858643
Validation loss: 1.955073425846715

Epoch: 6| Step: 12
Training loss: 1.7826967239379883
Validation loss: 1.963399633284538

Epoch: 6| Step: 13
Training loss: 2.548825979232788
Validation loss: 1.966719449207347

Epoch: 59| Step: 0
Training loss: 1.8872835636138916
Validation loss: 1.9522154869571808

Epoch: 6| Step: 1
Training loss: 2.3926846981048584
Validation loss: 1.9493021324116697

Epoch: 6| Step: 2
Training loss: 1.8469879627227783
Validation loss: 1.9574027446008497

Epoch: 6| Step: 3
Training loss: 2.097193479537964
Validation loss: 1.9449501242688907

Epoch: 6| Step: 4
Training loss: 1.715358853340149
Validation loss: 1.9579160239106865

Epoch: 6| Step: 5
Training loss: 2.547576904296875
Validation loss: 1.9365537320413897

Epoch: 6| Step: 6
Training loss: 2.192610502243042
Validation loss: 1.9420877874538462

Epoch: 6| Step: 7
Training loss: 2.462995767593384
Validation loss: 1.9442224733291134

Epoch: 6| Step: 8
Training loss: 1.8173877000808716
Validation loss: 1.946010584472328

Epoch: 6| Step: 9
Training loss: 2.8815560340881348
Validation loss: 1.940846509830926

Epoch: 6| Step: 10
Training loss: 2.6219115257263184
Validation loss: 1.9489645381127634

Epoch: 6| Step: 11
Training loss: 2.1146974563598633
Validation loss: 1.9397811761466406

Epoch: 6| Step: 12
Training loss: 3.0241994857788086
Validation loss: 1.9371132440464471

Epoch: 6| Step: 13
Training loss: 1.830759048461914
Validation loss: 1.9529664593358194

Epoch: 60| Step: 0
Training loss: 2.0426998138427734
Validation loss: 1.9381684462229412

Epoch: 6| Step: 1
Training loss: 2.241293430328369
Validation loss: 1.9559398517813733

Epoch: 6| Step: 2
Training loss: 2.9304146766662598
Validation loss: 1.9396828977010583

Epoch: 6| Step: 3
Training loss: 1.5529539585113525
Validation loss: 1.9498113970602713

Epoch: 6| Step: 4
Training loss: 2.576873302459717
Validation loss: 1.9407399213442238

Epoch: 6| Step: 5
Training loss: 1.8992571830749512
Validation loss: 1.9426865295697284

Epoch: 6| Step: 6
Training loss: 3.076158285140991
Validation loss: 1.9546350843162947

Epoch: 6| Step: 7
Training loss: 1.6266415119171143
Validation loss: 1.9455924457119358

Epoch: 6| Step: 8
Training loss: 2.1789426803588867
Validation loss: 1.9545358893691853

Epoch: 6| Step: 9
Training loss: 2.493873119354248
Validation loss: 1.9473004136034238

Epoch: 6| Step: 10
Training loss: 1.6779743432998657
Validation loss: 1.969535853273125

Epoch: 6| Step: 11
Training loss: 2.9252829551696777
Validation loss: 1.9592588742574055

Epoch: 6| Step: 12
Training loss: 1.6154264211654663
Validation loss: 1.9538662356715049

Epoch: 6| Step: 13
Training loss: 3.1944241523742676
Validation loss: 1.9581919357340822

Epoch: 61| Step: 0
Training loss: 2.6601381301879883
Validation loss: 1.9589720746522308

Epoch: 6| Step: 1
Training loss: 2.3108718395233154
Validation loss: 1.961606994751961

Epoch: 6| Step: 2
Training loss: 2.294013023376465
Validation loss: 1.9597345629046041

Epoch: 6| Step: 3
Training loss: 1.5370912551879883
Validation loss: 1.9636801096700853

Epoch: 6| Step: 4
Training loss: 1.8341050148010254
Validation loss: 1.9560424973887782

Epoch: 6| Step: 5
Training loss: 2.7006959915161133
Validation loss: 1.9578617285656672

Epoch: 6| Step: 6
Training loss: 2.4716920852661133
Validation loss: 1.9611659908807406

Epoch: 6| Step: 7
Training loss: 1.9496047496795654
Validation loss: 1.9514546881439865

Epoch: 6| Step: 8
Training loss: 2.379748821258545
Validation loss: 1.9479487890838294

Epoch: 6| Step: 9
Training loss: 2.5919082164764404
Validation loss: 1.9584649326980754

Epoch: 6| Step: 10
Training loss: 2.0701396465301514
Validation loss: 1.9551819985912693

Epoch: 6| Step: 11
Training loss: 1.569544792175293
Validation loss: 1.9547117576804212

Epoch: 6| Step: 12
Training loss: 2.6375129222869873
Validation loss: 1.9555553492679392

Epoch: 6| Step: 13
Training loss: 2.658848524093628
Validation loss: 1.9467826427951935

Epoch: 62| Step: 0
Training loss: 2.357341766357422
Validation loss: 1.9429349412200272

Epoch: 6| Step: 1
Training loss: 2.3256306648254395
Validation loss: 1.933362977479094

Epoch: 6| Step: 2
Training loss: 2.298258066177368
Validation loss: 1.9459662206711308

Epoch: 6| Step: 3
Training loss: 2.9640305042266846
Validation loss: 1.9409253494713896

Epoch: 6| Step: 4
Training loss: 2.222731113433838
Validation loss: 1.9438370338050268

Epoch: 6| Step: 5
Training loss: 2.166013717651367
Validation loss: 1.9356004730347665

Epoch: 6| Step: 6
Training loss: 2.7818450927734375
Validation loss: 1.946156124914846

Epoch: 6| Step: 7
Training loss: 1.9705036878585815
Validation loss: 1.937638145621105

Epoch: 6| Step: 8
Training loss: 2.102107524871826
Validation loss: 1.9429858525594075

Epoch: 6| Step: 9
Training loss: 1.7532422542572021
Validation loss: 1.93895883329453

Epoch: 6| Step: 10
Training loss: 2.062004566192627
Validation loss: 1.942895976446008

Epoch: 6| Step: 11
Training loss: 2.2098329067230225
Validation loss: 1.9392785333818006

Epoch: 6| Step: 12
Training loss: 2.272818088531494
Validation loss: 1.9375617952756985

Epoch: 6| Step: 13
Training loss: 1.7559152841567993
Validation loss: 1.9495366901479743

Epoch: 63| Step: 0
Training loss: 2.6792681217193604
Validation loss: 1.9293128675030125

Epoch: 6| Step: 1
Training loss: 1.9983725547790527
Validation loss: 1.928130026786558

Epoch: 6| Step: 2
Training loss: 2.591028928756714
Validation loss: 1.943716153662692

Epoch: 6| Step: 3
Training loss: 1.8686027526855469
Validation loss: 1.937538271309227

Epoch: 6| Step: 4
Training loss: 2.2005221843719482
Validation loss: 1.9356723511090843

Epoch: 6| Step: 5
Training loss: 2.490067958831787
Validation loss: 1.9433717830206758

Epoch: 6| Step: 6
Training loss: 2.056208372116089
Validation loss: 1.9366357582871632

Epoch: 6| Step: 7
Training loss: 2.1523184776306152
Validation loss: 1.954183993800994

Epoch: 6| Step: 8
Training loss: 2.1511788368225098
Validation loss: 1.9308337562827653

Epoch: 6| Step: 9
Training loss: 2.10752534866333
Validation loss: 1.933323044930735

Epoch: 6| Step: 10
Training loss: 2.7982959747314453
Validation loss: 1.9379726058693343

Epoch: 6| Step: 11
Training loss: 2.116232395172119
Validation loss: 1.933211475290278

Epoch: 6| Step: 12
Training loss: 2.5354080200195312
Validation loss: 1.9415175299490652

Epoch: 6| Step: 13
Training loss: 1.354474663734436
Validation loss: 1.935006977409445

Epoch: 64| Step: 0
Training loss: 2.906841516494751
Validation loss: 1.9484536493978193

Epoch: 6| Step: 1
Training loss: 1.9539058208465576
Validation loss: 1.9227351783424296

Epoch: 6| Step: 2
Training loss: 2.5406970977783203
Validation loss: 1.9430991962391844

Epoch: 6| Step: 3
Training loss: 1.5203566551208496
Validation loss: 1.9513487200583182

Epoch: 6| Step: 4
Training loss: 2.245138168334961
Validation loss: 1.9197825501042027

Epoch: 6| Step: 5
Training loss: 2.8897242546081543
Validation loss: 1.9454679309680898

Epoch: 6| Step: 6
Training loss: 2.3781986236572266
Validation loss: 1.939207439781517

Epoch: 6| Step: 7
Training loss: 2.1667778491973877
Validation loss: 1.9380561869631532

Epoch: 6| Step: 8
Training loss: 2.3189213275909424
Validation loss: 1.9641936658531107

Epoch: 6| Step: 9
Training loss: 1.9571638107299805
Validation loss: 1.9532000762160107

Epoch: 6| Step: 10
Training loss: 2.3575563430786133
Validation loss: 1.9425239998807189

Epoch: 6| Step: 11
Training loss: 2.004774570465088
Validation loss: 1.956462820370992

Epoch: 6| Step: 12
Training loss: 2.458111524581909
Validation loss: 1.954201586784855

Epoch: 6| Step: 13
Training loss: 1.2473572492599487
Validation loss: 1.9539811995721632

Epoch: 65| Step: 0
Training loss: 2.2569327354431152
Validation loss: 1.969268363009217

Epoch: 6| Step: 1
Training loss: 2.1020827293395996
Validation loss: 1.9412265554551156

Epoch: 6| Step: 2
Training loss: 2.011404037475586
Validation loss: 1.9341786984474427

Epoch: 6| Step: 3
Training loss: 2.3064684867858887
Validation loss: 1.9412121131855955

Epoch: 6| Step: 4
Training loss: 2.096895933151245
Validation loss: 1.939493397230743

Epoch: 6| Step: 5
Training loss: 1.8071826696395874
Validation loss: 1.9331920544306438

Epoch: 6| Step: 6
Training loss: 1.7874785661697388
Validation loss: 1.9415740479705155

Epoch: 6| Step: 7
Training loss: 2.845047950744629
Validation loss: 1.9446685878179406

Epoch: 6| Step: 8
Training loss: 2.7247514724731445
Validation loss: 1.951725657268237

Epoch: 6| Step: 9
Training loss: 1.946696162223816
Validation loss: 1.9598868393128919

Epoch: 6| Step: 10
Training loss: 2.560671091079712
Validation loss: 1.9507172210242159

Epoch: 6| Step: 11
Training loss: 2.183835029602051
Validation loss: 1.9557626042314755

Epoch: 6| Step: 12
Training loss: 2.006643772125244
Validation loss: 1.9509031849522744

Epoch: 6| Step: 13
Training loss: 2.863654613494873
Validation loss: 1.95267024091495

Epoch: 66| Step: 0
Training loss: 1.8472685813903809
Validation loss: 1.9494465653614332

Epoch: 6| Step: 1
Training loss: 2.681177854537964
Validation loss: 1.9391147718634656

Epoch: 6| Step: 2
Training loss: 2.0111260414123535
Validation loss: 1.9391060208761564

Epoch: 6| Step: 3
Training loss: 2.3295392990112305
Validation loss: 1.9394110043843586

Epoch: 6| Step: 4
Training loss: 2.249342679977417
Validation loss: 1.941131886615548

Epoch: 6| Step: 5
Training loss: 1.9449944496154785
Validation loss: 1.9331340110430153

Epoch: 6| Step: 6
Training loss: 2.1791391372680664
Validation loss: 1.9434493562226653

Epoch: 6| Step: 7
Training loss: 3.1566109657287598
Validation loss: 1.9367312180098666

Epoch: 6| Step: 8
Training loss: 2.0920236110687256
Validation loss: 1.9315849606708815

Epoch: 6| Step: 9
Training loss: 2.311288356781006
Validation loss: 1.9366162079636768

Epoch: 6| Step: 10
Training loss: 2.8163533210754395
Validation loss: 1.936700040294278

Epoch: 6| Step: 11
Training loss: 1.9304289817810059
Validation loss: 1.9435901000935545

Epoch: 6| Step: 12
Training loss: 1.7793238162994385
Validation loss: 1.941711453981297

Epoch: 6| Step: 13
Training loss: 1.675750732421875
Validation loss: 1.954823613166809

Epoch: 67| Step: 0
Training loss: 2.0920724868774414
Validation loss: 1.9388497183399815

Epoch: 6| Step: 1
Training loss: 1.6794785261154175
Validation loss: 1.9467357230442826

Epoch: 6| Step: 2
Training loss: 2.215238571166992
Validation loss: 1.9308151762972596

Epoch: 6| Step: 3
Training loss: 1.8932218551635742
Validation loss: 1.9466281180740685

Epoch: 6| Step: 4
Training loss: 2.627007007598877
Validation loss: 1.917473461679233

Epoch: 6| Step: 5
Training loss: 2.5057475566864014
Validation loss: 1.9416835051710888

Epoch: 6| Step: 6
Training loss: 2.848850727081299
Validation loss: 1.9456199599850563

Epoch: 6| Step: 7
Training loss: 2.365565061569214
Validation loss: 1.9430344066312235

Epoch: 6| Step: 8
Training loss: 1.7375974655151367
Validation loss: 1.9230912628994192

Epoch: 6| Step: 9
Training loss: 2.4248228073120117
Validation loss: 1.9411685953858078

Epoch: 6| Step: 10
Training loss: 1.8764758110046387
Validation loss: 1.9354324187001875

Epoch: 6| Step: 11
Training loss: 2.6446971893310547
Validation loss: 1.9307139996559388

Epoch: 6| Step: 12
Training loss: 1.9153565168380737
Validation loss: 1.9396766603633921

Epoch: 6| Step: 13
Training loss: 2.5265164375305176
Validation loss: 1.9327743617437219

Epoch: 68| Step: 0
Training loss: 2.349473476409912
Validation loss: 1.9555642322827411

Epoch: 6| Step: 1
Training loss: 1.8802440166473389
Validation loss: 1.9423512976656678

Epoch: 6| Step: 2
Training loss: 2.202068328857422
Validation loss: 1.9258848159543929

Epoch: 6| Step: 3
Training loss: 2.9851722717285156
Validation loss: 1.9315733704515683

Epoch: 6| Step: 4
Training loss: 2.0346107482910156
Validation loss: 1.9346522028728197

Epoch: 6| Step: 5
Training loss: 1.8621835708618164
Validation loss: 1.938242926392504

Epoch: 6| Step: 6
Training loss: 2.1250436305999756
Validation loss: 1.9358770949866182

Epoch: 6| Step: 7
Training loss: 2.5584158897399902
Validation loss: 1.9359557846541047

Epoch: 6| Step: 8
Training loss: 2.073821544647217
Validation loss: 1.9531202700830275

Epoch: 6| Step: 9
Training loss: 2.088980197906494
Validation loss: 1.9226154845247987

Epoch: 6| Step: 10
Training loss: 2.631922721862793
Validation loss: 1.9340549899685768

Epoch: 6| Step: 11
Training loss: 1.6589417457580566
Validation loss: 1.9325556549974667

Epoch: 6| Step: 12
Training loss: 2.0251898765563965
Validation loss: 1.9294298489888508

Epoch: 6| Step: 13
Training loss: 3.0411007404327393
Validation loss: 1.9315611931585497

Epoch: 69| Step: 0
Training loss: 2.6372058391571045
Validation loss: 1.9274833125452842

Epoch: 6| Step: 1
Training loss: 1.8947833776474
Validation loss: 1.9376955621985978

Epoch: 6| Step: 2
Training loss: 2.571316719055176
Validation loss: 1.93482094810855

Epoch: 6| Step: 3
Training loss: 1.4483540058135986
Validation loss: 1.9483992361253308

Epoch: 6| Step: 4
Training loss: 2.109812021255493
Validation loss: 1.9293963396421043

Epoch: 6| Step: 5
Training loss: 1.888689398765564
Validation loss: 1.9498788836181804

Epoch: 6| Step: 6
Training loss: 2.1723814010620117
Validation loss: 1.9425855785287836

Epoch: 6| Step: 7
Training loss: 2.0686535835266113
Validation loss: 1.9325051499951271

Epoch: 6| Step: 8
Training loss: 2.9992737770080566
Validation loss: 1.94559524648933

Epoch: 6| Step: 9
Training loss: 1.8773000240325928
Validation loss: 1.932065543308053

Epoch: 6| Step: 10
Training loss: 2.536374568939209
Validation loss: 1.9391724217322566

Epoch: 6| Step: 11
Training loss: 1.7455857992172241
Validation loss: 1.958602254108716

Epoch: 6| Step: 12
Training loss: 2.3771469593048096
Validation loss: 1.9441537203327302

Epoch: 6| Step: 13
Training loss: 3.3310747146606445
Validation loss: 1.9402046049794843

Epoch: 70| Step: 0
Training loss: 2.455982208251953
Validation loss: 1.9347809540328158

Epoch: 6| Step: 1
Training loss: 1.4854624271392822
Validation loss: 1.9450434382243822

Epoch: 6| Step: 2
Training loss: 2.7744526863098145
Validation loss: 1.9443176805332143

Epoch: 6| Step: 3
Training loss: 2.2166361808776855
Validation loss: 1.939998452381421

Epoch: 6| Step: 4
Training loss: 1.7287068367004395
Validation loss: 1.931653038147957

Epoch: 6| Step: 5
Training loss: 1.369441032409668
Validation loss: 1.9342296482414327

Epoch: 6| Step: 6
Training loss: 2.5027225017547607
Validation loss: 1.9323572907396542

Epoch: 6| Step: 7
Training loss: 2.839848518371582
Validation loss: 1.9364453131152737

Epoch: 6| Step: 8
Training loss: 3.068859100341797
Validation loss: 1.927302340025543

Epoch: 6| Step: 9
Training loss: 2.6518163681030273
Validation loss: 1.9201772956437961

Epoch: 6| Step: 10
Training loss: 1.8261325359344482
Validation loss: 1.9266440919650498

Epoch: 6| Step: 11
Training loss: 2.0524957180023193
Validation loss: 1.945038499370698

Epoch: 6| Step: 12
Training loss: 1.9109234809875488
Validation loss: 1.9363867044448853

Epoch: 6| Step: 13
Training loss: 1.9532347917556763
Validation loss: 1.9264023534713253

Epoch: 71| Step: 0
Training loss: 2.172454833984375
Validation loss: 1.9382114859037503

Epoch: 6| Step: 1
Training loss: 2.6173577308654785
Validation loss: 1.9397098428459578

Epoch: 6| Step: 2
Training loss: 2.6602060794830322
Validation loss: 1.9279269351754138

Epoch: 6| Step: 3
Training loss: 2.414764881134033
Validation loss: 1.9471670196902366

Epoch: 6| Step: 4
Training loss: 2.557781219482422
Validation loss: 1.9322238468354749

Epoch: 6| Step: 5
Training loss: 2.6744089126586914
Validation loss: 1.9374063912258352

Epoch: 6| Step: 6
Training loss: 1.7910261154174805
Validation loss: 1.9238878719268306

Epoch: 6| Step: 7
Training loss: 1.4893940687179565
Validation loss: 1.9392100559767855

Epoch: 6| Step: 8
Training loss: 1.7403411865234375
Validation loss: 1.932434643468549

Epoch: 6| Step: 9
Training loss: 2.5027260780334473
Validation loss: 1.9280680212923276

Epoch: 6| Step: 10
Training loss: 2.19974684715271
Validation loss: 1.9413614606344571

Epoch: 6| Step: 11
Training loss: 1.80146062374115
Validation loss: 1.9265034839671145

Epoch: 6| Step: 12
Training loss: 2.2256298065185547
Validation loss: 1.927625302345522

Epoch: 6| Step: 13
Training loss: 2.0241003036499023
Validation loss: 1.936511634498514

Epoch: 72| Step: 0
Training loss: 2.211613178253174
Validation loss: 1.937426786268911

Epoch: 6| Step: 1
Training loss: 2.668144702911377
Validation loss: 1.9271862250502392

Epoch: 6| Step: 2
Training loss: 2.3083291053771973
Validation loss: 1.9345023375685497

Epoch: 6| Step: 3
Training loss: 2.050361156463623
Validation loss: 1.9218161747019777

Epoch: 6| Step: 4
Training loss: 2.0139248371124268
Validation loss: 1.9400542846290014

Epoch: 6| Step: 5
Training loss: 2.247833728790283
Validation loss: 1.9361268346027662

Epoch: 6| Step: 6
Training loss: 2.0780467987060547
Validation loss: 1.9455056805764475

Epoch: 6| Step: 7
Training loss: 1.46043062210083
Validation loss: 1.9551158746083577

Epoch: 6| Step: 8
Training loss: 2.192070484161377
Validation loss: 1.9381672669482488

Epoch: 6| Step: 9
Training loss: 2.978273868560791
Validation loss: 1.9341628589937765

Epoch: 6| Step: 10
Training loss: 2.349107265472412
Validation loss: 1.9384245693042714

Epoch: 6| Step: 11
Training loss: 1.8477137088775635
Validation loss: 1.933974301943215

Epoch: 6| Step: 12
Training loss: 2.308108329772949
Validation loss: 1.9534029473540604

Epoch: 6| Step: 13
Training loss: 2.1658506393432617
Validation loss: 1.931167451284265

Epoch: 73| Step: 0
Training loss: 2.1778249740600586
Validation loss: 1.9325728185715214

Epoch: 6| Step: 1
Training loss: 2.1274306774139404
Validation loss: 1.9249349665898148

Epoch: 6| Step: 2
Training loss: 2.49654221534729
Validation loss: 1.9448390955566077

Epoch: 6| Step: 3
Training loss: 1.6899640560150146
Validation loss: 1.9365223505163704

Epoch: 6| Step: 4
Training loss: 2.1747827529907227
Validation loss: 1.9381900346407326

Epoch: 6| Step: 5
Training loss: 2.3339667320251465
Validation loss: 1.9236481958819973

Epoch: 6| Step: 6
Training loss: 2.491360664367676
Validation loss: 1.9442633557063278

Epoch: 6| Step: 7
Training loss: 1.8301258087158203
Validation loss: 1.9418705624918784

Epoch: 6| Step: 8
Training loss: 2.339601516723633
Validation loss: 1.9399201152145222

Epoch: 6| Step: 9
Training loss: 2.4164726734161377
Validation loss: 1.9269550769559798

Epoch: 6| Step: 10
Training loss: 2.0514445304870605
Validation loss: 1.9311557110919748

Epoch: 6| Step: 11
Training loss: 2.3959569931030273
Validation loss: 1.946073047576412

Epoch: 6| Step: 12
Training loss: 2.4006762504577637
Validation loss: 1.9545721943660448

Epoch: 6| Step: 13
Training loss: 1.7880616188049316
Validation loss: 1.9240541381220664

Epoch: 74| Step: 0
Training loss: 2.3981518745422363
Validation loss: 1.9320832132011332

Epoch: 6| Step: 1
Training loss: 2.2060060501098633
Validation loss: 1.921937019594254

Epoch: 6| Step: 2
Training loss: 2.494680643081665
Validation loss: 1.9301062912069342

Epoch: 6| Step: 3
Training loss: 1.81540846824646
Validation loss: 1.9431740442911785

Epoch: 6| Step: 4
Training loss: 2.6035356521606445
Validation loss: 1.9317786873027842

Epoch: 6| Step: 5
Training loss: 2.7738161087036133
Validation loss: 1.9428107430857997

Epoch: 6| Step: 6
Training loss: 1.811628818511963
Validation loss: 1.9399914844061739

Epoch: 6| Step: 7
Training loss: 2.442321300506592
Validation loss: 1.9361670991425872

Epoch: 6| Step: 8
Training loss: 2.5532078742980957
Validation loss: 1.9428305895097795

Epoch: 6| Step: 9
Training loss: 2.6137356758117676
Validation loss: 1.931190433040742

Epoch: 6| Step: 10
Training loss: 1.6739377975463867
Validation loss: 1.9262875779982536

Epoch: 6| Step: 11
Training loss: 2.161118984222412
Validation loss: 1.928644367443618

Epoch: 6| Step: 12
Training loss: 1.5557756423950195
Validation loss: 1.9339196963976788

Epoch: 6| Step: 13
Training loss: 1.4745407104492188
Validation loss: 1.929261387035411

Epoch: 75| Step: 0
Training loss: 2.5084009170532227
Validation loss: 1.9296697801159275

Epoch: 6| Step: 1
Training loss: 1.7205060720443726
Validation loss: 1.940006242003492

Epoch: 6| Step: 2
Training loss: 1.966140627861023
Validation loss: 1.9297123083504297

Epoch: 6| Step: 3
Training loss: 3.3217453956604004
Validation loss: 1.9315300128793205

Epoch: 6| Step: 4
Training loss: 2.704103469848633
Validation loss: 1.9227105058649534

Epoch: 6| Step: 5
Training loss: 1.4328815937042236
Validation loss: 1.9287791354681856

Epoch: 6| Step: 6
Training loss: 2.4709253311157227
Validation loss: 1.9282451906511862

Epoch: 6| Step: 7
Training loss: 2.413114547729492
Validation loss: 1.938133765292424

Epoch: 6| Step: 8
Training loss: 1.8033595085144043
Validation loss: 1.9152554388969176

Epoch: 6| Step: 9
Training loss: 2.1937131881713867
Validation loss: 1.9201042088129188

Epoch: 6| Step: 10
Training loss: 2.5163607597351074
Validation loss: 1.9383705662142845

Epoch: 6| Step: 11
Training loss: 2.125990390777588
Validation loss: 1.9342679310870428

Epoch: 6| Step: 12
Training loss: 1.4903126955032349
Validation loss: 1.9305086815229027

Epoch: 6| Step: 13
Training loss: 1.962207555770874
Validation loss: 1.9382069367234425

Epoch: 76| Step: 0
Training loss: 1.9531571865081787
Validation loss: 1.9261501463510657

Epoch: 6| Step: 1
Training loss: 2.446636438369751
Validation loss: 1.9233451517679359

Epoch: 6| Step: 2
Training loss: 2.0078349113464355
Validation loss: 1.9215763794478549

Epoch: 6| Step: 3
Training loss: 1.7103184461593628
Validation loss: 1.9209576511895785

Epoch: 6| Step: 4
Training loss: 1.556673288345337
Validation loss: 1.9265686017210766

Epoch: 6| Step: 5
Training loss: 2.079237699508667
Validation loss: 1.9182951988712433

Epoch: 6| Step: 6
Training loss: 2.0089151859283447
Validation loss: 1.9262629747390747

Epoch: 6| Step: 7
Training loss: 2.0852863788604736
Validation loss: 1.9182640762739285

Epoch: 6| Step: 8
Training loss: 2.8809814453125
Validation loss: 1.9191563770335207

Epoch: 6| Step: 9
Training loss: 2.1214675903320312
Validation loss: 1.927562084249271

Epoch: 6| Step: 10
Training loss: 3.0390632152557373
Validation loss: 1.9310770419336134

Epoch: 6| Step: 11
Training loss: 2.070314407348633
Validation loss: 1.932036115277198

Epoch: 6| Step: 12
Training loss: 2.3948781490325928
Validation loss: 1.9055403483811246

Epoch: 6| Step: 13
Training loss: 2.393413782119751
Validation loss: 1.9194568869888142

Epoch: 77| Step: 0
Training loss: 2.4793601036071777
Validation loss: 1.9120247825499503

Epoch: 6| Step: 1
Training loss: 2.1129860877990723
Validation loss: 1.9198507211541618

Epoch: 6| Step: 2
Training loss: 1.8224871158599854
Validation loss: 1.9245158113459104

Epoch: 6| Step: 3
Training loss: 1.9189975261688232
Validation loss: 1.9122869917141494

Epoch: 6| Step: 4
Training loss: 2.2584877014160156
Validation loss: 1.9191315366375832

Epoch: 6| Step: 5
Training loss: 2.1595818996429443
Validation loss: 1.9356218486703851

Epoch: 6| Step: 6
Training loss: 2.3982105255126953
Validation loss: 1.9138817146260252

Epoch: 6| Step: 7
Training loss: 2.3127243518829346
Validation loss: 1.9085453530793548

Epoch: 6| Step: 8
Training loss: 1.9828681945800781
Validation loss: 1.9155515342630365

Epoch: 6| Step: 9
Training loss: 2.3158035278320312
Validation loss: 1.9140627358549385

Epoch: 6| Step: 10
Training loss: 2.2751550674438477
Validation loss: 1.9346768522775302

Epoch: 6| Step: 11
Training loss: 2.2806849479675293
Validation loss: 1.9282465032351914

Epoch: 6| Step: 12
Training loss: 2.318638801574707
Validation loss: 1.9293173513104838

Epoch: 6| Step: 13
Training loss: 2.1755354404449463
Validation loss: 1.9030806287642448

Epoch: 78| Step: 0
Training loss: 2.5720999240875244
Validation loss: 1.9250220867895311

Epoch: 6| Step: 1
Training loss: 2.8438527584075928
Validation loss: 1.91494107502763

Epoch: 6| Step: 2
Training loss: 2.0574729442596436
Validation loss: 1.9158060614780714

Epoch: 6| Step: 3
Training loss: 2.2883107662200928
Validation loss: 1.9048376198737853

Epoch: 6| Step: 4
Training loss: 1.8417937755584717
Validation loss: 1.9298709746330016

Epoch: 6| Step: 5
Training loss: 2.134538412094116
Validation loss: 1.919863994403552

Epoch: 6| Step: 6
Training loss: 2.6043448448181152
Validation loss: 1.920488078107116

Epoch: 6| Step: 7
Training loss: 2.0515971183776855
Validation loss: 1.9262982299250941

Epoch: 6| Step: 8
Training loss: 2.503262996673584
Validation loss: 1.9341445456268966

Epoch: 6| Step: 9
Training loss: 1.7141162157058716
Validation loss: 1.920974193080779

Epoch: 6| Step: 10
Training loss: 1.9574741125106812
Validation loss: 1.910199466572013

Epoch: 6| Step: 11
Training loss: 1.8458442687988281
Validation loss: 1.9140345511897918

Epoch: 6| Step: 12
Training loss: 2.243760108947754
Validation loss: 1.9125311054209226

Epoch: 6| Step: 13
Training loss: 1.9719085693359375
Validation loss: 1.9243733370175926

Epoch: 79| Step: 0
Training loss: 2.387481689453125
Validation loss: 1.9203007862132082

Epoch: 6| Step: 1
Training loss: 1.8408572673797607
Validation loss: 1.9136748108812558

Epoch: 6| Step: 2
Training loss: 2.210871934890747
Validation loss: 1.915917710591388

Epoch: 6| Step: 3
Training loss: 2.515078067779541
Validation loss: 1.9268779318819764

Epoch: 6| Step: 4
Training loss: 1.691261887550354
Validation loss: 1.927119739593998

Epoch: 6| Step: 5
Training loss: 2.270253896713257
Validation loss: 1.9229035351866035

Epoch: 6| Step: 6
Training loss: 2.462728977203369
Validation loss: 1.9089307554306523

Epoch: 6| Step: 7
Training loss: 1.8155136108398438
Validation loss: 1.9320403914297781

Epoch: 6| Step: 8
Training loss: 2.3979411125183105
Validation loss: 1.922805747678203

Epoch: 6| Step: 9
Training loss: 1.9965620040893555
Validation loss: 1.9175674133403326

Epoch: 6| Step: 10
Training loss: 1.6127171516418457
Validation loss: 1.9309639392360565

Epoch: 6| Step: 11
Training loss: 2.504096269607544
Validation loss: 1.9310394640891784

Epoch: 6| Step: 12
Training loss: 2.2393622398376465
Validation loss: 1.9290433211993145

Epoch: 6| Step: 13
Training loss: 2.8989498615264893
Validation loss: 1.9196469604328115

Epoch: 80| Step: 0
Training loss: 2.097785472869873
Validation loss: 1.926228327135886

Epoch: 6| Step: 1
Training loss: 2.060116767883301
Validation loss: 1.9279670035967262

Epoch: 6| Step: 2
Training loss: 2.1205499172210693
Validation loss: 1.9232717393546976

Epoch: 6| Step: 3
Training loss: 2.376211166381836
Validation loss: 1.9240937015061736

Epoch: 6| Step: 4
Training loss: 2.057352304458618
Validation loss: 1.930253492888584

Epoch: 6| Step: 5
Training loss: 1.9269119501113892
Validation loss: 1.9119129347544845

Epoch: 6| Step: 6
Training loss: 1.9502025842666626
Validation loss: 1.9211453442932458

Epoch: 6| Step: 7
Training loss: 2.3221170902252197
Validation loss: 1.9358633154182023

Epoch: 6| Step: 8
Training loss: 2.1843738555908203
Validation loss: 1.9259750881502706

Epoch: 6| Step: 9
Training loss: 2.0950136184692383
Validation loss: 1.9125738118284492

Epoch: 6| Step: 10
Training loss: 2.997610092163086
Validation loss: 1.9070925686949043

Epoch: 6| Step: 11
Training loss: 2.149954319000244
Validation loss: 1.9212917435553767

Epoch: 6| Step: 12
Training loss: 2.16831636428833
Validation loss: 1.9190675417582195

Epoch: 6| Step: 13
Training loss: 1.7458252906799316
Validation loss: 1.9126102001436296

Epoch: 81| Step: 0
Training loss: 1.7327710390090942
Validation loss: 1.912526060176152

Epoch: 6| Step: 1
Training loss: 2.4712209701538086
Validation loss: 1.9223076938301005

Epoch: 6| Step: 2
Training loss: 2.4963736534118652
Validation loss: 1.9233831872222245

Epoch: 6| Step: 3
Training loss: 2.6972098350524902
Validation loss: 1.916512252182089

Epoch: 6| Step: 4
Training loss: 1.8510396480560303
Validation loss: 1.9292773687711327

Epoch: 6| Step: 5
Training loss: 1.7896581888198853
Validation loss: 1.9238751062782862

Epoch: 6| Step: 6
Training loss: 2.140000343322754
Validation loss: 1.9071299696481356

Epoch: 6| Step: 7
Training loss: 2.61015248298645
Validation loss: 1.9157000382741292

Epoch: 6| Step: 8
Training loss: 2.0566277503967285
Validation loss: 1.903751620682337

Epoch: 6| Step: 9
Training loss: 1.9294520616531372
Validation loss: 1.9126856647511965

Epoch: 6| Step: 10
Training loss: 2.2071030139923096
Validation loss: 1.8987540993639218

Epoch: 6| Step: 11
Training loss: 2.142171859741211
Validation loss: 1.9139935560123895

Epoch: 6| Step: 12
Training loss: 2.3949711322784424
Validation loss: 1.907521294009301

Epoch: 6| Step: 13
Training loss: 1.842620849609375
Validation loss: 1.9103020621884255

Epoch: 82| Step: 0
Training loss: 2.366380214691162
Validation loss: 1.9170853322552097

Epoch: 6| Step: 1
Training loss: 1.8031537532806396
Validation loss: 1.9105356072866788

Epoch: 6| Step: 2
Training loss: 2.689711093902588
Validation loss: 1.9122478808126142

Epoch: 6| Step: 3
Training loss: 1.8959273099899292
Validation loss: 1.902378701394604

Epoch: 6| Step: 4
Training loss: 2.25221586227417
Validation loss: 1.9181040833073277

Epoch: 6| Step: 5
Training loss: 2.5274579524993896
Validation loss: 1.915731333917187

Epoch: 6| Step: 6
Training loss: 2.138335704803467
Validation loss: 1.9033860852641444

Epoch: 6| Step: 7
Training loss: 2.079746723175049
Validation loss: 1.9121446430042226

Epoch: 6| Step: 8
Training loss: 2.73840594291687
Validation loss: 1.9113700377043856

Epoch: 6| Step: 9
Training loss: 1.2076468467712402
Validation loss: 1.9083461633292578

Epoch: 6| Step: 10
Training loss: 1.8490993976593018
Validation loss: 1.8995757115784513

Epoch: 6| Step: 11
Training loss: 1.4214510917663574
Validation loss: 1.9146691355653989

Epoch: 6| Step: 12
Training loss: 3.454927682876587
Validation loss: 1.9045815954926193

Epoch: 6| Step: 13
Training loss: 1.9880036115646362
Validation loss: 1.9216314669578307

Epoch: 83| Step: 0
Training loss: 2.3467140197753906
Validation loss: 1.9065552116722189

Epoch: 6| Step: 1
Training loss: 2.047074556350708
Validation loss: 1.9229159893528107

Epoch: 6| Step: 2
Training loss: 2.305302619934082
Validation loss: 1.9158068254429808

Epoch: 6| Step: 3
Training loss: 1.0904909372329712
Validation loss: 1.9178157057813419

Epoch: 6| Step: 4
Training loss: 1.8988637924194336
Validation loss: 1.9386837687543643

Epoch: 6| Step: 5
Training loss: 3.4490184783935547
Validation loss: 1.9286739954384424

Epoch: 6| Step: 6
Training loss: 1.9920319318771362
Validation loss: 1.9284515867951095

Epoch: 6| Step: 7
Training loss: 2.2796268463134766
Validation loss: 1.9158646406665925

Epoch: 6| Step: 8
Training loss: 1.4384853839874268
Validation loss: 1.9172363511977657

Epoch: 6| Step: 9
Training loss: 2.2536873817443848
Validation loss: 1.9110355377197266

Epoch: 6| Step: 10
Training loss: 2.2807350158691406
Validation loss: 1.9112563851059123

Epoch: 6| Step: 11
Training loss: 1.7516160011291504
Validation loss: 1.908040746565788

Epoch: 6| Step: 12
Training loss: 3.384047269821167
Validation loss: 1.9106194972991943

Epoch: 6| Step: 13
Training loss: 1.7633174657821655
Validation loss: 1.9149018756804927

Epoch: 84| Step: 0
Training loss: 2.9872474670410156
Validation loss: 1.9231932983603528

Epoch: 6| Step: 1
Training loss: 2.5206923484802246
Validation loss: 1.9197080442982335

Epoch: 6| Step: 2
Training loss: 2.192410945892334
Validation loss: 1.9116431026048557

Epoch: 6| Step: 3
Training loss: 2.419384241104126
Validation loss: 1.9187860309436757

Epoch: 6| Step: 4
Training loss: 1.7936068773269653
Validation loss: 1.9260543854005876

Epoch: 6| Step: 5
Training loss: 2.270425796508789
Validation loss: 1.9169880190203268

Epoch: 6| Step: 6
Training loss: 1.8389337062835693
Validation loss: 1.9273550715497745

Epoch: 6| Step: 7
Training loss: 2.24369478225708
Validation loss: 1.9235519234852125

Epoch: 6| Step: 8
Training loss: 2.200136661529541
Validation loss: 1.9306201627177577

Epoch: 6| Step: 9
Training loss: 1.3432183265686035
Validation loss: 1.9282303599901096

Epoch: 6| Step: 10
Training loss: 2.6521875858306885
Validation loss: 1.931637934459153

Epoch: 6| Step: 11
Training loss: 2.05892014503479
Validation loss: 1.9248595455641389

Epoch: 6| Step: 12
Training loss: 1.9029467105865479
Validation loss: 1.9323448083734

Epoch: 6| Step: 13
Training loss: 1.820143222808838
Validation loss: 1.9173641973926174

Epoch: 85| Step: 0
Training loss: 2.236060380935669
Validation loss: 1.9196663941106489

Epoch: 6| Step: 1
Training loss: 1.4971778392791748
Validation loss: 1.919053857044507

Epoch: 6| Step: 2
Training loss: 2.248084306716919
Validation loss: 1.923671317356889

Epoch: 6| Step: 3
Training loss: 1.9466766119003296
Validation loss: 1.9236038910445346

Epoch: 6| Step: 4
Training loss: 2.004251718521118
Validation loss: 1.9047030889859764

Epoch: 6| Step: 5
Training loss: 1.494917631149292
Validation loss: 1.9261979697853007

Epoch: 6| Step: 6
Training loss: 2.7065324783325195
Validation loss: 1.922841082337082

Epoch: 6| Step: 7
Training loss: 1.8878270387649536
Validation loss: 1.910557605886972

Epoch: 6| Step: 8
Training loss: 2.2598915100097656
Validation loss: 1.9349682895086144

Epoch: 6| Step: 9
Training loss: 2.3605639934539795
Validation loss: 1.9203163218754593

Epoch: 6| Step: 10
Training loss: 2.7202553749084473
Validation loss: 1.9191664162502493

Epoch: 6| Step: 11
Training loss: 2.0069093704223633
Validation loss: 1.9223054942264353

Epoch: 6| Step: 12
Training loss: 2.1570496559143066
Validation loss: 1.908958940095799

Epoch: 6| Step: 13
Training loss: 2.875033378601074
Validation loss: 1.9244099124785392

Epoch: 86| Step: 0
Training loss: 2.3689136505126953
Validation loss: 1.914933527669599

Epoch: 6| Step: 1
Training loss: 2.593179225921631
Validation loss: 1.933285955459841

Epoch: 6| Step: 2
Training loss: 1.7284115552902222
Validation loss: 1.936661506211886

Epoch: 6| Step: 3
Training loss: 1.6682568788528442
Validation loss: 1.9079884354786207

Epoch: 6| Step: 4
Training loss: 2.356128692626953
Validation loss: 1.9299663241191576

Epoch: 6| Step: 5
Training loss: 2.388356924057007
Validation loss: 1.9283967351400724

Epoch: 6| Step: 6
Training loss: 2.3671553134918213
Validation loss: 1.9332918210696148

Epoch: 6| Step: 7
Training loss: 1.5912210941314697
Validation loss: 1.9156406810206752

Epoch: 6| Step: 8
Training loss: 2.2272746562957764
Validation loss: 1.9140578508377075

Epoch: 6| Step: 9
Training loss: 2.3622729778289795
Validation loss: 1.9100141448359336

Epoch: 6| Step: 10
Training loss: 2.4563241004943848
Validation loss: 1.9170991477145944

Epoch: 6| Step: 11
Training loss: 2.6159651279449463
Validation loss: 1.9199973690894343

Epoch: 6| Step: 12
Training loss: 1.4620829820632935
Validation loss: 1.8992864265236804

Epoch: 6| Step: 13
Training loss: 1.8784645795822144
Validation loss: 1.9126289659930813

Epoch: 87| Step: 0
Training loss: 2.248584270477295
Validation loss: 1.9210615273444884

Epoch: 6| Step: 1
Training loss: 2.419654369354248
Validation loss: 1.9152101009122786

Epoch: 6| Step: 2
Training loss: 1.652491807937622
Validation loss: 1.9275403381675802

Epoch: 6| Step: 3
Training loss: 2.2371456623077393
Validation loss: 1.9086915857048445

Epoch: 6| Step: 4
Training loss: 2.403226613998413
Validation loss: 1.924729908666303

Epoch: 6| Step: 5
Training loss: 2.087620735168457
Validation loss: 1.9091059520680418

Epoch: 6| Step: 6
Training loss: 2.6574418544769287
Validation loss: 1.9229592687340193

Epoch: 6| Step: 7
Training loss: 1.26204252243042
Validation loss: 1.9076763711949831

Epoch: 6| Step: 8
Training loss: 1.9745267629623413
Validation loss: 1.9123188987854989

Epoch: 6| Step: 9
Training loss: 1.759078025817871
Validation loss: 1.9144308925956808

Epoch: 6| Step: 10
Training loss: 2.8847124576568604
Validation loss: 1.9256444772084553

Epoch: 6| Step: 11
Training loss: 2.469757080078125
Validation loss: 1.9097060285588747

Epoch: 6| Step: 12
Training loss: 1.8510770797729492
Validation loss: 1.9203787183248868

Epoch: 6| Step: 13
Training loss: 2.306121587753296
Validation loss: 1.9103556884232389

Epoch: 88| Step: 0
Training loss: 2.0836098194122314
Validation loss: 1.9114987183642644

Epoch: 6| Step: 1
Training loss: 2.4522385597229004
Validation loss: 1.9187968661708217

Epoch: 6| Step: 2
Training loss: 1.5349756479263306
Validation loss: 1.9218280699945265

Epoch: 6| Step: 3
Training loss: 2.1827070713043213
Validation loss: 1.918592360711867

Epoch: 6| Step: 4
Training loss: 2.1978330612182617
Validation loss: 1.9291758768020137

Epoch: 6| Step: 5
Training loss: 2.7179648876190186
Validation loss: 1.9381565714395175

Epoch: 6| Step: 6
Training loss: 2.0211801528930664
Validation loss: 1.9287120091017855

Epoch: 6| Step: 7
Training loss: 1.8044359683990479
Validation loss: 1.9178461464502479

Epoch: 6| Step: 8
Training loss: 2.622810125350952
Validation loss: 1.9185755893748293

Epoch: 6| Step: 9
Training loss: 1.8433890342712402
Validation loss: 1.9248062897753972

Epoch: 6| Step: 10
Training loss: 2.144789934158325
Validation loss: 1.9246905670371106

Epoch: 6| Step: 11
Training loss: 2.3203415870666504
Validation loss: 1.9285663789318455

Epoch: 6| Step: 12
Training loss: 2.1134653091430664
Validation loss: 1.928969471685348

Epoch: 6| Step: 13
Training loss: 1.8006659746170044
Validation loss: 1.921741859887236

Epoch: 89| Step: 0
Training loss: 2.1813573837280273
Validation loss: 1.9155582920197518

Epoch: 6| Step: 1
Training loss: 1.8199447393417358
Validation loss: 1.9336949138231174

Epoch: 6| Step: 2
Training loss: 2.6734132766723633
Validation loss: 1.9401229171342746

Epoch: 6| Step: 3
Training loss: 1.5479214191436768
Validation loss: 1.921759657962348

Epoch: 6| Step: 4
Training loss: 1.6364021301269531
Validation loss: 1.9441939746179888

Epoch: 6| Step: 5
Training loss: 2.28344464302063
Validation loss: 1.9184660488559353

Epoch: 6| Step: 6
Training loss: 2.583528518676758
Validation loss: 1.9300884713408768

Epoch: 6| Step: 7
Training loss: 2.5406620502471924
Validation loss: 1.9308548640179377

Epoch: 6| Step: 8
Training loss: 2.012540817260742
Validation loss: 1.928396495439673

Epoch: 6| Step: 9
Training loss: 2.450927495956421
Validation loss: 1.9130365951086885

Epoch: 6| Step: 10
Training loss: 2.369752883911133
Validation loss: 1.9063038646533925

Epoch: 6| Step: 11
Training loss: 2.30257511138916
Validation loss: 1.9202410944046513

Epoch: 6| Step: 12
Training loss: 1.87070894241333
Validation loss: 1.9038565492117276

Epoch: 6| Step: 13
Training loss: 1.5030808448791504
Validation loss: 1.906603277370494

Epoch: 90| Step: 0
Training loss: 2.1485612392425537
Validation loss: 1.9142293840326288

Epoch: 6| Step: 1
Training loss: 2.2981467247009277
Validation loss: 1.9043410503736107

Epoch: 6| Step: 2
Training loss: 1.9627952575683594
Validation loss: 1.917134984847038

Epoch: 6| Step: 3
Training loss: 1.6044118404388428
Validation loss: 1.9130324163744528

Epoch: 6| Step: 4
Training loss: 1.7158193588256836
Validation loss: 1.9156157111608854

Epoch: 6| Step: 5
Training loss: 1.6405606269836426
Validation loss: 1.9119159072958014

Epoch: 6| Step: 6
Training loss: 2.1821722984313965
Validation loss: 1.9487176133740334

Epoch: 6| Step: 7
Training loss: 2.3874707221984863
Validation loss: 1.9150887689282816

Epoch: 6| Step: 8
Training loss: 2.0314130783081055
Validation loss: 1.9055325856772802

Epoch: 6| Step: 9
Training loss: 2.3070082664489746
Validation loss: 1.901254928240212

Epoch: 6| Step: 10
Training loss: 2.6658239364624023
Validation loss: 1.8949011115617649

Epoch: 6| Step: 11
Training loss: 2.0834712982177734
Validation loss: 1.911042236512707

Epoch: 6| Step: 12
Training loss: 2.546799659729004
Validation loss: 1.9096378767362205

Epoch: 6| Step: 13
Training loss: 2.3113787174224854
Validation loss: 1.919175955557054

Epoch: 91| Step: 0
Training loss: 2.641803741455078
Validation loss: 1.9158363098739295

Epoch: 6| Step: 1
Training loss: 1.408122181892395
Validation loss: 1.900118597092167

Epoch: 6| Step: 2
Training loss: 1.6025738716125488
Validation loss: 1.9150423003781227

Epoch: 6| Step: 3
Training loss: 2.953469753265381
Validation loss: 1.8828860893044421

Epoch: 6| Step: 4
Training loss: 2.4369266033172607
Validation loss: 1.9108897793677546

Epoch: 6| Step: 5
Training loss: 1.94694185256958
Validation loss: 1.906602580060241

Epoch: 6| Step: 6
Training loss: 1.8632707595825195
Validation loss: 1.8896622939776349

Epoch: 6| Step: 7
Training loss: 2.4275786876678467
Validation loss: 1.8907809065234276

Epoch: 6| Step: 8
Training loss: 2.151836395263672
Validation loss: 1.9055427479487594

Epoch: 6| Step: 9
Training loss: 1.9870250225067139
Validation loss: 1.9103686437811902

Epoch: 6| Step: 10
Training loss: 2.154758930206299
Validation loss: 1.9050022991754676

Epoch: 6| Step: 11
Training loss: 2.474529266357422
Validation loss: 1.894044150588333

Epoch: 6| Step: 12
Training loss: 1.7012237310409546
Validation loss: 1.9228848616282146

Epoch: 6| Step: 13
Training loss: 2.0233547687530518
Validation loss: 1.9215735991795857

Epoch: 92| Step: 0
Training loss: 2.042386531829834
Validation loss: 1.9188810599747526

Epoch: 6| Step: 1
Training loss: 1.988243818283081
Validation loss: 1.910674242563145

Epoch: 6| Step: 2
Training loss: 1.83174467086792
Validation loss: 1.909564741196171

Epoch: 6| Step: 3
Training loss: 2.526489734649658
Validation loss: 1.913065230974587

Epoch: 6| Step: 4
Training loss: 2.304365634918213
Validation loss: 1.9071312001956406

Epoch: 6| Step: 5
Training loss: 2.0226802825927734
Validation loss: 1.903585414732656

Epoch: 6| Step: 6
Training loss: 2.8190526962280273
Validation loss: 1.9141572495942474

Epoch: 6| Step: 7
Training loss: 2.0632762908935547
Validation loss: 1.908325029957679

Epoch: 6| Step: 8
Training loss: 1.9838826656341553
Validation loss: 1.928331555858735

Epoch: 6| Step: 9
Training loss: 2.483613967895508
Validation loss: 1.9093019000945552

Epoch: 6| Step: 10
Training loss: 1.353541374206543
Validation loss: 1.908652574785294

Epoch: 6| Step: 11
Training loss: 2.1789684295654297
Validation loss: 1.9124275753574986

Epoch: 6| Step: 12
Training loss: 1.6177040338516235
Validation loss: 1.9060945972319572

Epoch: 6| Step: 13
Training loss: 2.714590311050415
Validation loss: 1.9060852219981532

Epoch: 93| Step: 0
Training loss: 1.8632872104644775
Validation loss: 1.9104503508537047

Epoch: 6| Step: 1
Training loss: 2.4965224266052246
Validation loss: 1.9077082757026917

Epoch: 6| Step: 2
Training loss: 1.7129064798355103
Validation loss: 1.9094548135675409

Epoch: 6| Step: 3
Training loss: 1.8618807792663574
Validation loss: 1.9052091247291976

Epoch: 6| Step: 4
Training loss: 1.6832386255264282
Validation loss: 1.9056433323890931

Epoch: 6| Step: 5
Training loss: 2.59108567237854
Validation loss: 1.9095080603835404

Epoch: 6| Step: 6
Training loss: 1.9567756652832031
Validation loss: 1.9159612424911991

Epoch: 6| Step: 7
Training loss: 1.8577022552490234
Validation loss: 1.9247156445698073

Epoch: 6| Step: 8
Training loss: 2.386820077896118
Validation loss: 1.932651545411797

Epoch: 6| Step: 9
Training loss: 2.382758378982544
Validation loss: 1.9109813538930749

Epoch: 6| Step: 10
Training loss: 2.2173895835876465
Validation loss: 1.9181321103085753

Epoch: 6| Step: 11
Training loss: 2.0923266410827637
Validation loss: 1.9166218273101314

Epoch: 6| Step: 12
Training loss: 2.2628464698791504
Validation loss: 1.9083458403105378

Epoch: 6| Step: 13
Training loss: 2.280736207962036
Validation loss: 1.9081890762493174

Epoch: 94| Step: 0
Training loss: 1.9491617679595947
Validation loss: 1.9121840153971026

Epoch: 6| Step: 1
Training loss: 2.385714054107666
Validation loss: 1.8957504392952047

Epoch: 6| Step: 2
Training loss: 1.9293365478515625
Validation loss: 1.9124907908901092

Epoch: 6| Step: 3
Training loss: 1.7147202491760254
Validation loss: 1.9007897351377754

Epoch: 6| Step: 4
Training loss: 2.0929665565490723
Validation loss: 1.9256911405953028

Epoch: 6| Step: 5
Training loss: 1.9817816019058228
Validation loss: 1.8958264845673756

Epoch: 6| Step: 6
Training loss: 2.1022186279296875
Validation loss: 1.9173268297667145

Epoch: 6| Step: 7
Training loss: 2.366311550140381
Validation loss: 1.91463255113171

Epoch: 6| Step: 8
Training loss: 2.0486865043640137
Validation loss: 1.9338007921813636

Epoch: 6| Step: 9
Training loss: 2.2940545082092285
Validation loss: 1.92184535021423

Epoch: 6| Step: 10
Training loss: 2.394002914428711
Validation loss: 1.9083832156273626

Epoch: 6| Step: 11
Training loss: 1.5378906726837158
Validation loss: 1.9172104045908938

Epoch: 6| Step: 12
Training loss: 2.3621273040771484
Validation loss: 1.9115048018834924

Epoch: 6| Step: 13
Training loss: 2.4542741775512695
Validation loss: 1.9031194204925208

Epoch: 95| Step: 0
Training loss: 1.956488847732544
Validation loss: 1.9013248938386158

Epoch: 6| Step: 1
Training loss: 1.9237269163131714
Validation loss: 1.901997309859081

Epoch: 6| Step: 2
Training loss: 1.471843957901001
Validation loss: 1.9164963832465551

Epoch: 6| Step: 3
Training loss: 1.7397313117980957
Validation loss: 1.8986110584710234

Epoch: 6| Step: 4
Training loss: 1.9746109247207642
Validation loss: 1.915449671847846

Epoch: 6| Step: 5
Training loss: 2.308779239654541
Validation loss: 1.9282471505544518

Epoch: 6| Step: 6
Training loss: 2.576326847076416
Validation loss: 1.9020237384303924

Epoch: 6| Step: 7
Training loss: 2.630307912826538
Validation loss: 1.9012070932695944

Epoch: 6| Step: 8
Training loss: 1.7880241870880127
Validation loss: 1.9032366378332979

Epoch: 6| Step: 9
Training loss: 2.457247257232666
Validation loss: 1.9074893074650918

Epoch: 6| Step: 10
Training loss: 1.4037216901779175
Validation loss: 1.8882744350740988

Epoch: 6| Step: 11
Training loss: 2.885268211364746
Validation loss: 1.9113406763281873

Epoch: 6| Step: 12
Training loss: 2.3750083446502686
Validation loss: 1.904848821701542

Epoch: 6| Step: 13
Training loss: 2.06373929977417
Validation loss: 1.9140861342030187

Epoch: 96| Step: 0
Training loss: 2.5255048274993896
Validation loss: 1.9044518842492053

Epoch: 6| Step: 1
Training loss: 2.1948587894439697
Validation loss: 1.9052382746050436

Epoch: 6| Step: 2
Training loss: 2.241084575653076
Validation loss: 1.9283562462816957

Epoch: 6| Step: 3
Training loss: 2.030064582824707
Validation loss: 1.9122795776654316

Epoch: 6| Step: 4
Training loss: 2.290653705596924
Validation loss: 1.9197571944164973

Epoch: 6| Step: 5
Training loss: 1.8769407272338867
Validation loss: 1.9177817144701559

Epoch: 6| Step: 6
Training loss: 3.0009446144104004
Validation loss: 1.9224841953605734

Epoch: 6| Step: 7
Training loss: 2.0020358562469482
Validation loss: 1.9184230117387668

Epoch: 6| Step: 8
Training loss: 1.6873228549957275
Validation loss: 1.92593518892924

Epoch: 6| Step: 9
Training loss: 2.0581984519958496
Validation loss: 1.9305861457701652

Epoch: 6| Step: 10
Training loss: 1.8134946823120117
Validation loss: 1.923306626658286

Epoch: 6| Step: 11
Training loss: 1.8858287334442139
Validation loss: 1.9187002746007775

Epoch: 6| Step: 12
Training loss: 2.0795841217041016
Validation loss: 1.9272986509466683

Epoch: 6| Step: 13
Training loss: 1.7045879364013672
Validation loss: 1.9293726375026088

Epoch: 97| Step: 0
Training loss: 2.100787878036499
Validation loss: 1.9370776402053012

Epoch: 6| Step: 1
Training loss: 2.8234448432922363
Validation loss: 1.9059122916190856

Epoch: 6| Step: 2
Training loss: 3.0186023712158203
Validation loss: 1.9096675124219669

Epoch: 6| Step: 3
Training loss: 1.7494944334030151
Validation loss: 1.9291738335804274

Epoch: 6| Step: 4
Training loss: 2.1129555702209473
Validation loss: 1.9396473541054675

Epoch: 6| Step: 5
Training loss: 1.6608479022979736
Validation loss: 1.9403955628795009

Epoch: 6| Step: 6
Training loss: 2.1847949028015137
Validation loss: 1.9187242087497507

Epoch: 6| Step: 7
Training loss: 2.1155478954315186
Validation loss: 1.924428060490598

Epoch: 6| Step: 8
Training loss: 1.7689355611801147
Validation loss: 1.935019003447666

Epoch: 6| Step: 9
Training loss: 1.4903868436813354
Validation loss: 1.9259709004432923

Epoch: 6| Step: 10
Training loss: 2.6161651611328125
Validation loss: 1.923635826315931

Epoch: 6| Step: 11
Training loss: 1.6304693222045898
Validation loss: 1.9309263870280275

Epoch: 6| Step: 12
Training loss: 1.820000410079956
Validation loss: 1.9077506142277871

Epoch: 6| Step: 13
Training loss: 2.3783493041992188
Validation loss: 1.9217343279110488

Epoch: 98| Step: 0
Training loss: 1.3252480030059814
Validation loss: 1.9183755766960882

Epoch: 6| Step: 1
Training loss: 2.367856979370117
Validation loss: 1.9011368725889473

Epoch: 6| Step: 2
Training loss: 0.877717137336731
Validation loss: 1.9107586158219205

Epoch: 6| Step: 3
Training loss: 2.50353741645813
Validation loss: 1.92427901042405

Epoch: 6| Step: 4
Training loss: 2.2958664894104004
Validation loss: 1.9029318645436277

Epoch: 6| Step: 5
Training loss: 2.14900541305542
Validation loss: 1.8989321403605963

Epoch: 6| Step: 6
Training loss: 2.2503318786621094
Validation loss: 1.9184382923187748

Epoch: 6| Step: 7
Training loss: 2.754608154296875
Validation loss: 1.910977949378311

Epoch: 6| Step: 8
Training loss: 1.9075121879577637
Validation loss: 1.8979021503079323

Epoch: 6| Step: 9
Training loss: 2.163311243057251
Validation loss: 1.9114300461225613

Epoch: 6| Step: 10
Training loss: 1.9682731628417969
Validation loss: 1.909242763314196

Epoch: 6| Step: 11
Training loss: 2.177251100540161
Validation loss: 1.9178414101241736

Epoch: 6| Step: 12
Training loss: 2.4454727172851562
Validation loss: 1.899391576807986

Epoch: 6| Step: 13
Training loss: 2.2389025688171387
Validation loss: 1.909413940163069

Epoch: 99| Step: 0
Training loss: 2.1636619567871094
Validation loss: 1.90543072454391

Epoch: 6| Step: 1
Training loss: 2.1127707958221436
Validation loss: 1.9007324736605409

Epoch: 6| Step: 2
Training loss: 2.70109486579895
Validation loss: 1.8945766546392953

Epoch: 6| Step: 3
Training loss: 1.7770166397094727
Validation loss: 1.900082839432583

Epoch: 6| Step: 4
Training loss: 2.052657127380371
Validation loss: 1.9055077260540378

Epoch: 6| Step: 5
Training loss: 1.9307043552398682
Validation loss: 1.9170093997832267

Epoch: 6| Step: 6
Training loss: 2.215243101119995
Validation loss: 1.9225044917034846

Epoch: 6| Step: 7
Training loss: 2.3337697982788086
Validation loss: 1.8763388356854838

Epoch: 6| Step: 8
Training loss: 2.449090003967285
Validation loss: 1.8807245223752913

Epoch: 6| Step: 9
Training loss: 2.1485331058502197
Validation loss: 1.9094232102876068

Epoch: 6| Step: 10
Training loss: 2.68906831741333
Validation loss: 1.9130530946998185

Epoch: 6| Step: 11
Training loss: 1.3593499660491943
Validation loss: 1.9193706512451172

Epoch: 6| Step: 12
Training loss: 1.5942606925964355
Validation loss: 1.890157256075131

Epoch: 6| Step: 13
Training loss: 1.8122626543045044
Validation loss: 1.9227575550797165

Epoch: 100| Step: 0
Training loss: 2.1506307125091553
Validation loss: 1.8957526247988465

Epoch: 6| Step: 1
Training loss: 1.382828950881958
Validation loss: 1.9131784105813632

Epoch: 6| Step: 2
Training loss: 1.2205605506896973
Validation loss: 1.9135690376322756

Epoch: 6| Step: 3
Training loss: 2.2229998111724854
Validation loss: 1.9151253001664275

Epoch: 6| Step: 4
Training loss: 1.7439684867858887
Validation loss: 1.9115918080012004

Epoch: 6| Step: 5
Training loss: 2.437082529067993
Validation loss: 1.9260150822260047

Epoch: 6| Step: 6
Training loss: 2.1822216510772705
Validation loss: 1.9130026973703855

Epoch: 6| Step: 7
Training loss: 2.1878106594085693
Validation loss: 1.9230253542623212

Epoch: 6| Step: 8
Training loss: 2.2037158012390137
Validation loss: 1.9155118414150771

Epoch: 6| Step: 9
Training loss: 1.6569404602050781
Validation loss: 1.9129715094002344

Epoch: 6| Step: 10
Training loss: 2.190423011779785
Validation loss: 1.9083719586813321

Epoch: 6| Step: 11
Training loss: 2.139312267303467
Validation loss: 1.918668585438882

Epoch: 6| Step: 12
Training loss: 2.7252182960510254
Validation loss: 1.9227660420120403

Epoch: 6| Step: 13
Training loss: 3.5381269454956055
Validation loss: 1.9069131266686223

Epoch: 101| Step: 0
Training loss: 1.165198802947998
Validation loss: 1.899364274035218

Epoch: 6| Step: 1
Training loss: 1.8312666416168213
Validation loss: 1.9013068765722296

Epoch: 6| Step: 2
Training loss: 1.6292800903320312
Validation loss: 1.885916615045199

Epoch: 6| Step: 3
Training loss: 2.276883125305176
Validation loss: 1.8990321684909124

Epoch: 6| Step: 4
Training loss: 1.936835765838623
Validation loss: 1.9144051497982395

Epoch: 6| Step: 5
Training loss: 2.111729621887207
Validation loss: 1.9120841449306858

Epoch: 6| Step: 6
Training loss: 2.9794864654541016
Validation loss: 1.906794245525073

Epoch: 6| Step: 7
Training loss: 2.14103364944458
Validation loss: 1.8889094142503635

Epoch: 6| Step: 8
Training loss: 1.986095905303955
Validation loss: 1.907288465448605

Epoch: 6| Step: 9
Training loss: 2.2527084350585938
Validation loss: 1.9039895560151787

Epoch: 6| Step: 10
Training loss: 2.4725699424743652
Validation loss: 1.908008711312407

Epoch: 6| Step: 11
Training loss: 2.1664061546325684
Validation loss: 1.9156530723776868

Epoch: 6| Step: 12
Training loss: 2.9467315673828125
Validation loss: 1.9374554695621613

Epoch: 6| Step: 13
Training loss: 0.9389287233352661
Validation loss: 1.9026656689182404

Epoch: 102| Step: 0
Training loss: 1.8458499908447266
Validation loss: 1.9212368637002923

Epoch: 6| Step: 1
Training loss: 2.445645809173584
Validation loss: 1.9191950341706634

Epoch: 6| Step: 2
Training loss: 2.3593907356262207
Validation loss: 1.9150442718177714

Epoch: 6| Step: 3
Training loss: 1.3987653255462646
Validation loss: 1.9377552514435143

Epoch: 6| Step: 4
Training loss: 1.7373464107513428
Validation loss: 1.9298230191712737

Epoch: 6| Step: 5
Training loss: 2.530714273452759
Validation loss: 1.9459791926927463

Epoch: 6| Step: 6
Training loss: 2.2769298553466797
Validation loss: 1.9450998767729728

Epoch: 6| Step: 7
Training loss: 2.1662955284118652
Validation loss: 1.9362247144022295

Epoch: 6| Step: 8
Training loss: 1.691725492477417
Validation loss: 1.9185427081200384

Epoch: 6| Step: 9
Training loss: 1.8383430242538452
Validation loss: 1.9358319159476989

Epoch: 6| Step: 10
Training loss: 2.4181461334228516
Validation loss: 1.9360975116811774

Epoch: 6| Step: 11
Training loss: 1.7891383171081543
Validation loss: 1.9298586050669353

Epoch: 6| Step: 12
Training loss: 2.361931562423706
Validation loss: 1.9303756298557404

Epoch: 6| Step: 13
Training loss: 2.616950273513794
Validation loss: 1.9234893603991436

Epoch: 103| Step: 0
Training loss: 2.40913724899292
Validation loss: 1.9389277555609261

Epoch: 6| Step: 1
Training loss: 1.4342695474624634
Validation loss: 1.920919446535008

Epoch: 6| Step: 2
Training loss: 1.9825782775878906
Validation loss: 1.91652133259722

Epoch: 6| Step: 3
Training loss: 1.8942573070526123
Validation loss: 1.9318364730445288

Epoch: 6| Step: 4
Training loss: 1.9803954362869263
Validation loss: 1.9328526950651599

Epoch: 6| Step: 5
Training loss: 2.0930471420288086
Validation loss: 1.9225537020673034

Epoch: 6| Step: 6
Training loss: 2.3641371726989746
Validation loss: 1.925327604816806

Epoch: 6| Step: 7
Training loss: 2.796478509902954
Validation loss: 1.934080977593699

Epoch: 6| Step: 8
Training loss: 2.4173049926757812
Validation loss: 1.9299431629078363

Epoch: 6| Step: 9
Training loss: 2.3652663230895996
Validation loss: 1.9252672323616602

Epoch: 6| Step: 10
Training loss: 1.624313473701477
Validation loss: 1.9235623882662864

Epoch: 6| Step: 11
Training loss: 1.4557901620864868
Validation loss: 1.926830263548

Epoch: 6| Step: 12
Training loss: 2.208940029144287
Validation loss: 1.9038016885839484

Epoch: 6| Step: 13
Training loss: 1.9565495252609253
Validation loss: 1.9186438463067497

Epoch: 104| Step: 0
Training loss: 2.059239387512207
Validation loss: 1.9031855444754324

Epoch: 6| Step: 1
Training loss: 2.0390915870666504
Validation loss: 1.9134711501418904

Epoch: 6| Step: 2
Training loss: 2.418733596801758
Validation loss: 1.8946589987765077

Epoch: 6| Step: 3
Training loss: 3.065314769744873
Validation loss: 1.9089732221377793

Epoch: 6| Step: 4
Training loss: 2.09554386138916
Validation loss: 1.8935883263105988

Epoch: 6| Step: 5
Training loss: 1.8441436290740967
Validation loss: 1.8987439422197239

Epoch: 6| Step: 6
Training loss: 2.188462734222412
Validation loss: 1.8955451185985277

Epoch: 6| Step: 7
Training loss: 1.8072640895843506
Validation loss: 1.8856095857517694

Epoch: 6| Step: 8
Training loss: 2.5190303325653076
Validation loss: 1.914982767515285

Epoch: 6| Step: 9
Training loss: 1.337281346321106
Validation loss: 1.9206081564708422

Epoch: 6| Step: 10
Training loss: 2.0333666801452637
Validation loss: 1.9089954591566516

Epoch: 6| Step: 11
Training loss: 1.410505771636963
Validation loss: 1.9075651489278322

Epoch: 6| Step: 12
Training loss: 2.044389486312866
Validation loss: 1.9082816147035169

Epoch: 6| Step: 13
Training loss: 2.4256699085235596
Validation loss: 1.9160601016013854

Epoch: 105| Step: 0
Training loss: 2.3053438663482666
Validation loss: 1.8917645638988865

Epoch: 6| Step: 1
Training loss: 1.9854929447174072
Validation loss: 1.8999395755029493

Epoch: 6| Step: 2
Training loss: 1.9697297811508179
Validation loss: 1.91305709397921

Epoch: 6| Step: 3
Training loss: 2.2135009765625
Validation loss: 1.9255737489269626

Epoch: 6| Step: 4
Training loss: 1.949812412261963
Validation loss: 1.9059553659090431

Epoch: 6| Step: 5
Training loss: 1.9831042289733887
Validation loss: 1.89706592405996

Epoch: 6| Step: 6
Training loss: 2.7706267833709717
Validation loss: 1.9003725372334963

Epoch: 6| Step: 7
Training loss: 2.3386101722717285
Validation loss: 1.893939318195466

Epoch: 6| Step: 8
Training loss: 1.4398442506790161
Validation loss: 1.9084340936394149

Epoch: 6| Step: 9
Training loss: 2.480088233947754
Validation loss: 1.9112660795129754

Epoch: 6| Step: 10
Training loss: 1.5242396593093872
Validation loss: 1.918837002528611

Epoch: 6| Step: 11
Training loss: 2.4758963584899902
Validation loss: 1.9100866497203868

Epoch: 6| Step: 12
Training loss: 2.244175910949707
Validation loss: 1.9127704276833484

Epoch: 6| Step: 13
Training loss: 1.1212403774261475
Validation loss: 1.913020251899637

Epoch: 106| Step: 0
Training loss: 1.7673721313476562
Validation loss: 1.9083706025154359

Epoch: 6| Step: 1
Training loss: 2.209070920944214
Validation loss: 1.9041203247603549

Epoch: 6| Step: 2
Training loss: 1.588412880897522
Validation loss: 1.904204337827621

Epoch: 6| Step: 3
Training loss: 1.870242953300476
Validation loss: 1.9262573270387546

Epoch: 6| Step: 4
Training loss: 2.261052131652832
Validation loss: 1.9237533718027093

Epoch: 6| Step: 5
Training loss: 1.9482662677764893
Validation loss: 1.9150985107626965

Epoch: 6| Step: 6
Training loss: 1.6504676342010498
Validation loss: 1.9001461075198265

Epoch: 6| Step: 7
Training loss: 2.730370044708252
Validation loss: 1.9213785727818806

Epoch: 6| Step: 8
Training loss: 1.8872534036636353
Validation loss: 1.9262351579563592

Epoch: 6| Step: 9
Training loss: 2.1410605907440186
Validation loss: 1.9535703518057381

Epoch: 6| Step: 10
Training loss: 2.685317039489746
Validation loss: 1.9380928854788504

Epoch: 6| Step: 11
Training loss: 1.8444604873657227
Validation loss: 1.9162043922690934

Epoch: 6| Step: 12
Training loss: 2.127089500427246
Validation loss: 1.947114949585289

Epoch: 6| Step: 13
Training loss: 2.342433214187622
Validation loss: 1.9270343242153045

Epoch: 107| Step: 0
Training loss: 1.8471901416778564
Validation loss: 1.9248014021945257

Epoch: 6| Step: 1
Training loss: 1.671759843826294
Validation loss: 1.9263020356496174

Epoch: 6| Step: 2
Training loss: 2.2157185077667236
Validation loss: 1.9237103859583538

Epoch: 6| Step: 3
Training loss: 1.9386296272277832
Validation loss: 1.9387353235675442

Epoch: 6| Step: 4
Training loss: 1.6954944133758545
Validation loss: 1.9137647216038038

Epoch: 6| Step: 5
Training loss: 2.255960464477539
Validation loss: 1.9128863170582762

Epoch: 6| Step: 6
Training loss: 2.8972530364990234
Validation loss: 1.9113686289838565

Epoch: 6| Step: 7
Training loss: 1.7930853366851807
Validation loss: 1.9107576877840105

Epoch: 6| Step: 8
Training loss: 1.8278632164001465
Validation loss: 1.8969476120446318

Epoch: 6| Step: 9
Training loss: 2.307978630065918
Validation loss: 1.8894686775822793

Epoch: 6| Step: 10
Training loss: 2.6864023208618164
Validation loss: 1.912146314497917

Epoch: 6| Step: 11
Training loss: 2.0292906761169434
Validation loss: 1.9043791729916808

Epoch: 6| Step: 12
Training loss: 1.7149522304534912
Validation loss: 1.900768926066737

Epoch: 6| Step: 13
Training loss: 1.8096095323562622
Validation loss: 1.8981796567158034

Epoch: 108| Step: 0
Training loss: 1.89358651638031
Validation loss: 1.9104068279266357

Epoch: 6| Step: 1
Training loss: 2.426048517227173
Validation loss: 1.9032287341292187

Epoch: 6| Step: 2
Training loss: 1.4167873859405518
Validation loss: 1.893311333912675

Epoch: 6| Step: 3
Training loss: 1.2441636323928833
Validation loss: 1.9060560298222367

Epoch: 6| Step: 4
Training loss: 1.8105686902999878
Validation loss: 1.9093193354145173

Epoch: 6| Step: 5
Training loss: 2.644540786743164
Validation loss: 1.9326272536349554

Epoch: 6| Step: 6
Training loss: 2.7534916400909424
Validation loss: 1.9113053916603007

Epoch: 6| Step: 7
Training loss: 1.7225065231323242
Validation loss: 1.9086502252086517

Epoch: 6| Step: 8
Training loss: 2.074397563934326
Validation loss: 1.9155692464561873

Epoch: 6| Step: 9
Training loss: 1.9422476291656494
Validation loss: 1.9058129236262331

Epoch: 6| Step: 10
Training loss: 2.3070473670959473
Validation loss: 1.8931387867978824

Epoch: 6| Step: 11
Training loss: 2.188063144683838
Validation loss: 1.9124966052270704

Epoch: 6| Step: 12
Training loss: 2.0740036964416504
Validation loss: 1.909537011577237

Epoch: 6| Step: 13
Training loss: 2.7470037937164307
Validation loss: 1.9092855286854569

Epoch: 109| Step: 0
Training loss: 1.8640590906143188
Validation loss: 1.9234051781315957

Epoch: 6| Step: 1
Training loss: 2.0120890140533447
Validation loss: 1.9404487430408437

Epoch: 6| Step: 2
Training loss: 2.4950342178344727
Validation loss: 1.9060036302894674

Epoch: 6| Step: 3
Training loss: 2.207383155822754
Validation loss: 1.9328778418161536

Epoch: 6| Step: 4
Training loss: 1.4268357753753662
Validation loss: 1.936755382886497

Epoch: 6| Step: 5
Training loss: 1.8287878036499023
Validation loss: 1.9312490186383646

Epoch: 6| Step: 6
Training loss: 1.4220434427261353
Validation loss: 1.929356623721379

Epoch: 6| Step: 7
Training loss: 2.2166829109191895
Validation loss: 1.9322448584341234

Epoch: 6| Step: 8
Training loss: 1.9884942770004272
Validation loss: 1.9453204165222824

Epoch: 6| Step: 9
Training loss: 2.1940011978149414
Validation loss: 1.9375155459168136

Epoch: 6| Step: 10
Training loss: 2.405974864959717
Validation loss: 1.955798400345669

Epoch: 6| Step: 11
Training loss: 2.554250717163086
Validation loss: 1.9559009280256046

Epoch: 6| Step: 12
Training loss: 2.3917593955993652
Validation loss: 1.947816833373039

Epoch: 6| Step: 13
Training loss: 1.6616255044937134
Validation loss: 1.9402584145146031

Epoch: 110| Step: 0
Training loss: 2.1761727333068848
Validation loss: 1.936996062596639

Epoch: 6| Step: 1
Training loss: 2.1968750953674316
Validation loss: 1.9352777939970776

Epoch: 6| Step: 2
Training loss: 1.509451150894165
Validation loss: 1.9300722537502166

Epoch: 6| Step: 3
Training loss: 1.5661636590957642
Validation loss: 1.9220920249979982

Epoch: 6| Step: 4
Training loss: 2.0127859115600586
Validation loss: 1.929625008695869

Epoch: 6| Step: 5
Training loss: 2.1829323768615723
Validation loss: 1.9385581657450686

Epoch: 6| Step: 6
Training loss: 1.669302225112915
Validation loss: 1.9105837883487824

Epoch: 6| Step: 7
Training loss: 1.9776930809020996
Validation loss: 1.9061902312822239

Epoch: 6| Step: 8
Training loss: 2.364168643951416
Validation loss: 1.9181572865414362

Epoch: 6| Step: 9
Training loss: 2.5768847465515137
Validation loss: 1.9140751002937235

Epoch: 6| Step: 10
Training loss: 1.8596992492675781
Validation loss: 1.9227301266885573

Epoch: 6| Step: 11
Training loss: 2.501877784729004
Validation loss: 1.9096803703615743

Epoch: 6| Step: 12
Training loss: 1.902886152267456
Validation loss: 1.9207070514719973

Epoch: 6| Step: 13
Training loss: 2.35841703414917
Validation loss: 1.9130601498388475

Epoch: 111| Step: 0
Training loss: 2.597085475921631
Validation loss: 1.9034517567644837

Epoch: 6| Step: 1
Training loss: 1.543613314628601
Validation loss: 1.9148790926061652

Epoch: 6| Step: 2
Training loss: 2.082995891571045
Validation loss: 1.9276381872033561

Epoch: 6| Step: 3
Training loss: 2.769902229309082
Validation loss: 1.8935371778344596

Epoch: 6| Step: 4
Training loss: 2.190535068511963
Validation loss: 1.9279459535434682

Epoch: 6| Step: 5
Training loss: 1.1864957809448242
Validation loss: 1.9120951955036452

Epoch: 6| Step: 6
Training loss: 2.1399359703063965
Validation loss: 1.9192612581355597

Epoch: 6| Step: 7
Training loss: 1.6317243576049805
Validation loss: 1.904393401197208

Epoch: 6| Step: 8
Training loss: 1.6389074325561523
Validation loss: 1.9012857855007212

Epoch: 6| Step: 9
Training loss: 2.420619487762451
Validation loss: 1.9060345465137112

Epoch: 6| Step: 10
Training loss: 2.382596969604492
Validation loss: 1.9134988643789803

Epoch: 6| Step: 11
Training loss: 1.9554420709609985
Validation loss: 1.9301250955109954

Epoch: 6| Step: 12
Training loss: 2.123222589492798
Validation loss: 1.9381572815679735

Epoch: 6| Step: 13
Training loss: 1.861036777496338
Validation loss: 1.9294538703016055

Epoch: 112| Step: 0
Training loss: 1.3800718784332275
Validation loss: 1.9062998320466729

Epoch: 6| Step: 1
Training loss: 1.515247106552124
Validation loss: 1.9108952488950504

Epoch: 6| Step: 2
Training loss: 2.2297544479370117
Validation loss: 1.9269670658214118

Epoch: 6| Step: 3
Training loss: 1.7907652854919434
Validation loss: 1.9416757937400573

Epoch: 6| Step: 4
Training loss: 2.5391430854797363
Validation loss: 1.9266396812213364

Epoch: 6| Step: 5
Training loss: 2.301609754562378
Validation loss: 1.9127550471213557

Epoch: 6| Step: 6
Training loss: 2.5156197547912598
Validation loss: 1.9188614173602032

Epoch: 6| Step: 7
Training loss: 1.9760169982910156
Validation loss: 1.9259461369565738

Epoch: 6| Step: 8
Training loss: 2.5878334045410156
Validation loss: 1.922364660488662

Epoch: 6| Step: 9
Training loss: 1.9863207340240479
Validation loss: 1.9290728620303574

Epoch: 6| Step: 10
Training loss: 1.9058005809783936
Validation loss: 1.9375727715030793

Epoch: 6| Step: 11
Training loss: 1.9448060989379883
Validation loss: 1.919126103001256

Epoch: 6| Step: 12
Training loss: 2.0268633365631104
Validation loss: 1.9295174050074753

Epoch: 6| Step: 13
Training loss: 1.8873827457427979
Validation loss: 1.9550411893475441

Epoch: 113| Step: 0
Training loss: 2.5560479164123535
Validation loss: 1.9269884017206007

Epoch: 6| Step: 1
Training loss: 1.877166509628296
Validation loss: 1.938300230169809

Epoch: 6| Step: 2
Training loss: 2.653684139251709
Validation loss: 1.9458648850840907

Epoch: 6| Step: 3
Training loss: 1.7659900188446045
Validation loss: 1.9306278510760235

Epoch: 6| Step: 4
Training loss: 1.7217025756835938
Validation loss: 1.9498139478827035

Epoch: 6| Step: 5
Training loss: 1.9944496154785156
Validation loss: 1.9331579913375199

Epoch: 6| Step: 6
Training loss: 2.801328659057617
Validation loss: 1.928284591244113

Epoch: 6| Step: 7
Training loss: 1.6405143737792969
Validation loss: 1.9482778272321146

Epoch: 6| Step: 8
Training loss: 1.838233470916748
Validation loss: 1.9204054904240433

Epoch: 6| Step: 9
Training loss: 2.1255605220794678
Validation loss: 1.9160064087119153

Epoch: 6| Step: 10
Training loss: 1.9807319641113281
Validation loss: 1.9235041487601496

Epoch: 6| Step: 11
Training loss: 1.7219246625900269
Validation loss: 1.9382546665847942

Epoch: 6| Step: 12
Training loss: 1.8263126611709595
Validation loss: 1.931628498979794

Epoch: 6| Step: 13
Training loss: 1.9537503719329834
Validation loss: 1.932032359543667

Epoch: 114| Step: 0
Training loss: 1.8899664878845215
Validation loss: 1.9238031192492413

Epoch: 6| Step: 1
Training loss: 2.1488935947418213
Validation loss: 1.9145201072897962

Epoch: 6| Step: 2
Training loss: 1.718820333480835
Validation loss: 1.9080523342214606

Epoch: 6| Step: 3
Training loss: 1.9901641607284546
Validation loss: 1.9234133971634733

Epoch: 6| Step: 4
Training loss: 2.1733973026275635
Validation loss: 1.8957631536709365

Epoch: 6| Step: 5
Training loss: 1.7722508907318115
Validation loss: 1.9117817263449393

Epoch: 6| Step: 6
Training loss: 2.904559373855591
Validation loss: 1.915993321326471

Epoch: 6| Step: 7
Training loss: 1.290515422821045
Validation loss: 1.9123697101428945

Epoch: 6| Step: 8
Training loss: 2.5470666885375977
Validation loss: 1.914804809836931

Epoch: 6| Step: 9
Training loss: 1.9971195459365845
Validation loss: 1.9273446067687003

Epoch: 6| Step: 10
Training loss: 2.0473175048828125
Validation loss: 1.912064544616207

Epoch: 6| Step: 11
Training loss: 1.9868072271347046
Validation loss: 1.911994025271426

Epoch: 6| Step: 12
Training loss: 1.7894940376281738
Validation loss: 1.9098081178562616

Epoch: 6| Step: 13
Training loss: 2.4880080223083496
Validation loss: 1.9133162524110527

Epoch: 115| Step: 0
Training loss: 2.6324870586395264
Validation loss: 1.919130684227072

Epoch: 6| Step: 1
Training loss: 2.4498167037963867
Validation loss: 1.9366771662107078

Epoch: 6| Step: 2
Training loss: 1.915060043334961
Validation loss: 1.9212414462079284

Epoch: 6| Step: 3
Training loss: 1.7177505493164062
Validation loss: 1.9101778307268698

Epoch: 6| Step: 4
Training loss: 1.7184267044067383
Validation loss: 1.9266520136146135

Epoch: 6| Step: 5
Training loss: 1.982836127281189
Validation loss: 1.9223463714763682

Epoch: 6| Step: 6
Training loss: 1.699073314666748
Validation loss: 1.9271077468831053

Epoch: 6| Step: 7
Training loss: 2.3299379348754883
Validation loss: 1.9259923094062394

Epoch: 6| Step: 8
Training loss: 1.6338598728179932
Validation loss: 1.9044772399369108

Epoch: 6| Step: 9
Training loss: 2.030867099761963
Validation loss: 1.927739832990913

Epoch: 6| Step: 10
Training loss: 1.999925971031189
Validation loss: 1.9423042522963656

Epoch: 6| Step: 11
Training loss: 1.5726158618927002
Validation loss: 1.9577833208986508

Epoch: 6| Step: 12
Training loss: 2.3740596771240234
Validation loss: 1.9384276302911903

Epoch: 6| Step: 13
Training loss: 2.6603097915649414
Validation loss: 1.9310722094710155

Epoch: 116| Step: 0
Training loss: 1.7495155334472656
Validation loss: 1.9347056317073044

Epoch: 6| Step: 1
Training loss: 1.3436708450317383
Validation loss: 1.9385931312396962

Epoch: 6| Step: 2
Training loss: 2.0105667114257812
Validation loss: 1.9428569091263639

Epoch: 6| Step: 3
Training loss: 1.830453872680664
Validation loss: 1.9334324098402453

Epoch: 6| Step: 4
Training loss: 2.0322885513305664
Validation loss: 1.9524581714343

Epoch: 6| Step: 5
Training loss: 2.4764084815979004
Validation loss: 1.933401156497258

Epoch: 6| Step: 6
Training loss: 2.7856907844543457
Validation loss: 1.9404941143528107

Epoch: 6| Step: 7
Training loss: 1.8925200700759888
Validation loss: 1.9171408735295778

Epoch: 6| Step: 8
Training loss: 2.4104185104370117
Validation loss: 1.9323853933683006

Epoch: 6| Step: 9
Training loss: 3.0570337772369385
Validation loss: 1.9219135827915643

Epoch: 6| Step: 10
Training loss: 2.152951717376709
Validation loss: 1.9348160272003503

Epoch: 6| Step: 11
Training loss: 1.3261723518371582
Validation loss: 1.8967319303943264

Epoch: 6| Step: 12
Training loss: 1.565935492515564
Validation loss: 1.9111348864852742

Epoch: 6| Step: 13
Training loss: 1.5682724714279175
Validation loss: 1.9109127572787705

Epoch: 117| Step: 0
Training loss: 1.630178689956665
Validation loss: 1.9094772287594375

Epoch: 6| Step: 1
Training loss: 1.8916140794754028
Validation loss: 1.9259522191939815

Epoch: 6| Step: 2
Training loss: 2.287489414215088
Validation loss: 1.9215716251762964

Epoch: 6| Step: 3
Training loss: 1.6077499389648438
Validation loss: 1.9239201840534006

Epoch: 6| Step: 4
Training loss: 2.262944221496582
Validation loss: 1.9218745321355841

Epoch: 6| Step: 5
Training loss: 1.727178692817688
Validation loss: 1.9069077122596003

Epoch: 6| Step: 6
Training loss: 2.3848862648010254
Validation loss: 1.9239727963683426

Epoch: 6| Step: 7
Training loss: 2.4556233882904053
Validation loss: 1.9284423256433139

Epoch: 6| Step: 8
Training loss: 2.5754151344299316
Validation loss: 1.9300213808654456

Epoch: 6| Step: 9
Training loss: 2.0656027793884277
Validation loss: 1.9156580535314416

Epoch: 6| Step: 10
Training loss: 1.6342339515686035
Validation loss: 1.931804198090748

Epoch: 6| Step: 11
Training loss: 1.5554834604263306
Validation loss: 1.9128775160799745

Epoch: 6| Step: 12
Training loss: 2.596322774887085
Validation loss: 1.9237228055154123

Epoch: 6| Step: 13
Training loss: 1.4568324089050293
Validation loss: 1.9188951689709899

Epoch: 118| Step: 0
Training loss: 1.8159993886947632
Validation loss: 1.9123196063503143

Epoch: 6| Step: 1
Training loss: 1.7572811841964722
Validation loss: 1.915284820782241

Epoch: 6| Step: 2
Training loss: 1.5809569358825684
Validation loss: 1.8994602426405875

Epoch: 6| Step: 3
Training loss: 2.1684861183166504
Validation loss: 1.9094094653283396

Epoch: 6| Step: 4
Training loss: 2.2181572914123535
Validation loss: 1.9168619699375604

Epoch: 6| Step: 5
Training loss: 2.1007232666015625
Validation loss: 1.9195792457108856

Epoch: 6| Step: 6
Training loss: 1.640088438987732
Validation loss: 1.9169116994386077

Epoch: 6| Step: 7
Training loss: 2.1844916343688965
Validation loss: 1.9168594447515344

Epoch: 6| Step: 8
Training loss: 1.9395098686218262
Validation loss: 1.9338881456723778

Epoch: 6| Step: 9
Training loss: 2.2828993797302246
Validation loss: 1.939170245201357

Epoch: 6| Step: 10
Training loss: 2.099977493286133
Validation loss: 1.9418237388774913

Epoch: 6| Step: 11
Training loss: 2.024745225906372
Validation loss: 1.9306754258371168

Epoch: 6| Step: 12
Training loss: 2.4934816360473633
Validation loss: 1.9368431209236063

Epoch: 6| Step: 13
Training loss: 1.723066806793213
Validation loss: 1.9315032151437574

Epoch: 119| Step: 0
Training loss: 1.9063080549240112
Validation loss: 1.9560993730380971

Epoch: 6| Step: 1
Training loss: 2.101823329925537
Validation loss: 1.9299247572498937

Epoch: 6| Step: 2
Training loss: 2.3237264156341553
Validation loss: 1.9423594103064588

Epoch: 6| Step: 3
Training loss: 2.0895323753356934
Validation loss: 1.9659565520542923

Epoch: 6| Step: 4
Training loss: 1.9465534687042236
Validation loss: 1.97223174700173

Epoch: 6| Step: 5
Training loss: 1.6814961433410645
Validation loss: 1.95968412071146

Epoch: 6| Step: 6
Training loss: 1.6946147680282593
Validation loss: 1.9718697724803802

Epoch: 6| Step: 7
Training loss: 2.5914978981018066
Validation loss: 1.9836399952570598

Epoch: 6| Step: 8
Training loss: 2.056361675262451
Validation loss: 1.9711815695608816

Epoch: 6| Step: 9
Training loss: 2.466954231262207
Validation loss: 1.9753380783142582

Epoch: 6| Step: 10
Training loss: 1.1023802757263184
Validation loss: 1.954984039388677

Epoch: 6| Step: 11
Training loss: 1.8014085292816162
Validation loss: 1.9650449868171447

Epoch: 6| Step: 12
Training loss: 2.389462471008301
Validation loss: 1.954089085261027

Epoch: 6| Step: 13
Training loss: 2.1496825218200684
Validation loss: 1.9607999452980616

Epoch: 120| Step: 0
Training loss: 1.5655367374420166
Validation loss: 1.9680282121063561

Epoch: 6| Step: 1
Training loss: 2.1499364376068115
Validation loss: 1.9352621429709977

Epoch: 6| Step: 2
Training loss: 2.327343463897705
Validation loss: 1.9311660105182278

Epoch: 6| Step: 3
Training loss: 2.400750160217285
Validation loss: 1.9338673404468003

Epoch: 6| Step: 4
Training loss: 1.3347091674804688
Validation loss: 1.9111016206843878

Epoch: 6| Step: 5
Training loss: 2.26412296295166
Validation loss: 1.941230179161154

Epoch: 6| Step: 6
Training loss: 2.2361838817596436
Validation loss: 1.939550785608189

Epoch: 6| Step: 7
Training loss: 1.9891347885131836
Validation loss: 1.947162175691256

Epoch: 6| Step: 8
Training loss: 1.5302842855453491
Validation loss: 1.9124522952623264

Epoch: 6| Step: 9
Training loss: 2.222686767578125
Validation loss: 1.91102570872153

Epoch: 6| Step: 10
Training loss: 1.9035465717315674
Validation loss: 1.9205230218107983

Epoch: 6| Step: 11
Training loss: 2.243978977203369
Validation loss: 1.919472917433708

Epoch: 6| Step: 12
Training loss: 2.0811767578125
Validation loss: 1.9143762921774259

Epoch: 6| Step: 13
Training loss: 1.8052629232406616
Validation loss: 1.9110549188429309

Epoch: 121| Step: 0
Training loss: 1.6973589658737183
Validation loss: 1.9374234240542176

Epoch: 6| Step: 1
Training loss: 1.5160517692565918
Validation loss: 1.916421337794232

Epoch: 6| Step: 2
Training loss: 1.8498491048812866
Validation loss: 1.944124767857213

Epoch: 6| Step: 3
Training loss: 1.8659964799880981
Validation loss: 1.9373504320780437

Epoch: 6| Step: 4
Training loss: 2.3603739738464355
Validation loss: 1.9504787793723486

Epoch: 6| Step: 5
Training loss: 1.9306719303131104
Validation loss: 1.9299962930781867

Epoch: 6| Step: 6
Training loss: 2.29049015045166
Validation loss: 1.923218632257113

Epoch: 6| Step: 7
Training loss: 2.090667724609375
Validation loss: 1.9353929899072135

Epoch: 6| Step: 8
Training loss: 2.466752529144287
Validation loss: 1.9375222088188253

Epoch: 6| Step: 9
Training loss: 2.0976290702819824
Validation loss: 1.929860273996989

Epoch: 6| Step: 10
Training loss: 1.9739362001419067
Validation loss: 1.9551621149945002

Epoch: 6| Step: 11
Training loss: 2.2385852336883545
Validation loss: 1.9353750956955778

Epoch: 6| Step: 12
Training loss: 1.797441005706787
Validation loss: 1.9497021808419177

Epoch: 6| Step: 13
Training loss: 1.7300184965133667
Validation loss: 1.9375382892547115

Epoch: 122| Step: 0
Training loss: 2.6210474967956543
Validation loss: 1.9542422602253575

Epoch: 6| Step: 1
Training loss: 2.3910071849823
Validation loss: 1.9389449704077937

Epoch: 6| Step: 2
Training loss: 2.011176586151123
Validation loss: 1.9384252486690399

Epoch: 6| Step: 3
Training loss: 1.9439222812652588
Validation loss: 1.9239289940044444

Epoch: 6| Step: 4
Training loss: 2.4399518966674805
Validation loss: 1.9506040696174867

Epoch: 6| Step: 5
Training loss: 2.123716354370117
Validation loss: 1.9435930098256757

Epoch: 6| Step: 6
Training loss: 1.906034231185913
Validation loss: 1.9375280693013182

Epoch: 6| Step: 7
Training loss: 1.9454091787338257
Validation loss: 1.9494020682509228

Epoch: 6| Step: 8
Training loss: 1.7494221925735474
Validation loss: 1.9453084263750302

Epoch: 6| Step: 9
Training loss: 1.471259593963623
Validation loss: 1.963175194237822

Epoch: 6| Step: 10
Training loss: 2.320164918899536
Validation loss: 1.9360750939256401

Epoch: 6| Step: 11
Training loss: 1.8084113597869873
Validation loss: 1.9658994020954255

Epoch: 6| Step: 12
Training loss: 1.7264565229415894
Validation loss: 1.9307005520789855

Epoch: 6| Step: 13
Training loss: 1.3181899785995483
Validation loss: 1.9420384463443552

Epoch: 123| Step: 0
Training loss: 2.6341779232025146
Validation loss: 1.9333053045375372

Epoch: 6| Step: 1
Training loss: 2.212583303451538
Validation loss: 1.9477140749654462

Epoch: 6| Step: 2
Training loss: 2.29063081741333
Validation loss: 1.9470271090025544

Epoch: 6| Step: 3
Training loss: 2.2829079627990723
Validation loss: 1.9348008273750223

Epoch: 6| Step: 4
Training loss: 1.9498025178909302
Validation loss: 1.9443772877416303

Epoch: 6| Step: 5
Training loss: 1.3397504091262817
Validation loss: 1.9447732715196506

Epoch: 6| Step: 6
Training loss: 2.1062963008880615
Validation loss: 1.9175262117898593

Epoch: 6| Step: 7
Training loss: 1.6139973402023315
Validation loss: 1.9365605641436834

Epoch: 6| Step: 8
Training loss: 1.8367887735366821
Validation loss: 1.9495095104299567

Epoch: 6| Step: 9
Training loss: 2.121736526489258
Validation loss: 1.9157744402526526

Epoch: 6| Step: 10
Training loss: 1.3448429107666016
Validation loss: 1.930769435821041

Epoch: 6| Step: 11
Training loss: 1.8883838653564453
Validation loss: 1.9165515066474996

Epoch: 6| Step: 12
Training loss: 2.1525235176086426
Validation loss: 1.9353680713202364

Epoch: 6| Step: 13
Training loss: 2.6954047679901123
Validation loss: 1.9452664800869521

Epoch: 124| Step: 0
Training loss: 2.4482479095458984
Validation loss: 1.9163851148338729

Epoch: 6| Step: 1
Training loss: 2.2434353828430176
Validation loss: 1.9377422730127971

Epoch: 6| Step: 2
Training loss: 1.3940644264221191
Validation loss: 1.9266021008132606

Epoch: 6| Step: 3
Training loss: 1.396488070487976
Validation loss: 1.9254875606106174

Epoch: 6| Step: 4
Training loss: 1.9194636344909668
Validation loss: 1.9233390310759186

Epoch: 6| Step: 5
Training loss: 2.3872230052948
Validation loss: 1.9443233936063704

Epoch: 6| Step: 6
Training loss: 1.9463818073272705
Validation loss: 1.9303028814254268

Epoch: 6| Step: 7
Training loss: 2.373744010925293
Validation loss: 1.912842753112957

Epoch: 6| Step: 8
Training loss: 1.943002700805664
Validation loss: 1.913490476146821

Epoch: 6| Step: 9
Training loss: 1.756536841392517
Validation loss: 1.9076650937398274

Epoch: 6| Step: 10
Training loss: 1.5003467798233032
Validation loss: 1.9046140691285491

Epoch: 6| Step: 11
Training loss: 1.9395229816436768
Validation loss: 1.9166393844030236

Epoch: 6| Step: 12
Training loss: 1.9244804382324219
Validation loss: 1.9042099752733785

Epoch: 6| Step: 13
Training loss: 2.968198299407959
Validation loss: 1.926083528867332

Epoch: 125| Step: 0
Training loss: 1.942033052444458
Validation loss: 1.930716165932276

Epoch: 6| Step: 1
Training loss: 2.4701573848724365
Validation loss: 1.9219095104484147

Epoch: 6| Step: 2
Training loss: 2.060637950897217
Validation loss: 1.9253596913429998

Epoch: 6| Step: 3
Training loss: 1.7997878789901733
Validation loss: 1.910882032045754

Epoch: 6| Step: 4
Training loss: 2.551156520843506
Validation loss: 1.928601966109327

Epoch: 6| Step: 5
Training loss: 2.237285852432251
Validation loss: 1.917303369891259

Epoch: 6| Step: 6
Training loss: 1.7848219871520996
Validation loss: 1.92179625521424

Epoch: 6| Step: 7
Training loss: 2.040508270263672
Validation loss: 1.9276949833798152

Epoch: 6| Step: 8
Training loss: 1.7286298274993896
Validation loss: 1.94507477360387

Epoch: 6| Step: 9
Training loss: 2.4997291564941406
Validation loss: 1.9339712371108353

Epoch: 6| Step: 10
Training loss: 1.4959478378295898
Validation loss: 1.9274327037154988

Epoch: 6| Step: 11
Training loss: 1.340559482574463
Validation loss: 1.9332505990100164

Epoch: 6| Step: 12
Training loss: 1.7870458364486694
Validation loss: 1.9594487374828709

Epoch: 6| Step: 13
Training loss: 2.1076767444610596
Validation loss: 1.9519502783334384

Epoch: 126| Step: 0
Training loss: 2.1504852771759033
Validation loss: 1.9413046657398183

Epoch: 6| Step: 1
Training loss: 2.339378595352173
Validation loss: 1.9346267331031062

Epoch: 6| Step: 2
Training loss: 1.6585700511932373
Validation loss: 1.9236715506481867

Epoch: 6| Step: 3
Training loss: 1.7945921421051025
Validation loss: 1.9229707064167145

Epoch: 6| Step: 4
Training loss: 2.284402847290039
Validation loss: 1.912010472307923

Epoch: 6| Step: 5
Training loss: 2.389343738555908
Validation loss: 1.9225489324139011

Epoch: 6| Step: 6
Training loss: 1.493648648262024
Validation loss: 1.9154607198571647

Epoch: 6| Step: 7
Training loss: 2.2160234451293945
Validation loss: 1.9166947180225002

Epoch: 6| Step: 8
Training loss: 1.9990637302398682
Validation loss: 1.939374291768638

Epoch: 6| Step: 9
Training loss: 2.0303609371185303
Validation loss: 1.9031069535081104

Epoch: 6| Step: 10
Training loss: 2.0674870014190674
Validation loss: 1.8933463788801623

Epoch: 6| Step: 11
Training loss: 2.0949435234069824
Validation loss: 1.916647736744214

Epoch: 6| Step: 12
Training loss: 1.3583320379257202
Validation loss: 1.9162742373763875

Epoch: 6| Step: 13
Training loss: 1.90584397315979
Validation loss: 1.9310531013755388

Epoch: 127| Step: 0
Training loss: 2.3369812965393066
Validation loss: 1.9079505884519188

Epoch: 6| Step: 1
Training loss: 1.3821872472763062
Validation loss: 1.9005814201088362

Epoch: 6| Step: 2
Training loss: 1.3639600276947021
Validation loss: 1.9191908964546778

Epoch: 6| Step: 3
Training loss: 1.7825814485549927
Validation loss: 1.9271403820283952

Epoch: 6| Step: 4
Training loss: 1.374030351638794
Validation loss: 1.9237081620001024

Epoch: 6| Step: 5
Training loss: 2.043118476867676
Validation loss: 1.9222188329183927

Epoch: 6| Step: 6
Training loss: 2.166719913482666
Validation loss: 1.9079005487503544

Epoch: 6| Step: 7
Training loss: 2.4878265857696533
Validation loss: 1.9390225179733769

Epoch: 6| Step: 8
Training loss: 1.5829987525939941
Validation loss: 1.9351091718160978

Epoch: 6| Step: 9
Training loss: 2.4197092056274414
Validation loss: 1.9422331522869807

Epoch: 6| Step: 10
Training loss: 2.1159415245056152
Validation loss: 1.9253992303725211

Epoch: 6| Step: 11
Training loss: 2.039818525314331
Validation loss: 1.960347294807434

Epoch: 6| Step: 12
Training loss: 2.7268874645233154
Validation loss: 1.9672112875087286

Epoch: 6| Step: 13
Training loss: 1.9563554525375366
Validation loss: 1.936986865535859

Epoch: 128| Step: 0
Training loss: 1.730246663093567
Validation loss: 1.9329732310387395

Epoch: 6| Step: 1
Training loss: 1.671513557434082
Validation loss: 1.9590772967184744

Epoch: 6| Step: 2
Training loss: 2.030773639678955
Validation loss: 1.94213564677905

Epoch: 6| Step: 3
Training loss: 1.9985229969024658
Validation loss: 1.948955960171197

Epoch: 6| Step: 4
Training loss: 1.5496861934661865
Validation loss: 1.948223183231969

Epoch: 6| Step: 5
Training loss: 2.058969497680664
Validation loss: 1.9389808434312061

Epoch: 6| Step: 6
Training loss: 1.2672597169876099
Validation loss: 1.9241009271273048

Epoch: 6| Step: 7
Training loss: 2.1633951663970947
Validation loss: 1.918791255643291

Epoch: 6| Step: 8
Training loss: 2.091973304748535
Validation loss: 1.9214541514714558

Epoch: 6| Step: 9
Training loss: 2.021057605743408
Validation loss: 1.9069523106339157

Epoch: 6| Step: 10
Training loss: 2.5031561851501465
Validation loss: 1.9139596185376566

Epoch: 6| Step: 11
Training loss: 2.3298885822296143
Validation loss: 1.9292318846589775

Epoch: 6| Step: 12
Training loss: 1.9591779708862305
Validation loss: 1.9252007161417315

Epoch: 6| Step: 13
Training loss: 2.9695053100585938
Validation loss: 1.9075555365572694

Epoch: 129| Step: 0
Training loss: 1.3761744499206543
Validation loss: 1.9147880525999172

Epoch: 6| Step: 1
Training loss: 2.303542137145996
Validation loss: 1.918091074112923

Epoch: 6| Step: 2
Training loss: 1.8175387382507324
Validation loss: 1.9270872954399354

Epoch: 6| Step: 3
Training loss: 2.0951919555664062
Validation loss: 1.9103418652729323

Epoch: 6| Step: 4
Training loss: 2.173764705657959
Validation loss: 1.919649903492261

Epoch: 6| Step: 5
Training loss: 1.2968225479125977
Validation loss: 1.9324638279535438

Epoch: 6| Step: 6
Training loss: 1.6273078918457031
Validation loss: 1.9417510007017402

Epoch: 6| Step: 7
Training loss: 2.141087532043457
Validation loss: 1.9367668256964734

Epoch: 6| Step: 8
Training loss: 1.810469150543213
Validation loss: 1.9172030046421995

Epoch: 6| Step: 9
Training loss: 2.100327968597412
Validation loss: 1.9210987680701799

Epoch: 6| Step: 10
Training loss: 1.8334541320800781
Validation loss: 1.9577422847029984

Epoch: 6| Step: 11
Training loss: 2.827328681945801
Validation loss: 1.915534862907984

Epoch: 6| Step: 12
Training loss: 1.9954745769500732
Validation loss: 1.9272146994067776

Epoch: 6| Step: 13
Training loss: 2.5153372287750244
Validation loss: 1.9434756335391794

Epoch: 130| Step: 0
Training loss: 2.1519250869750977
Validation loss: 1.9292249974384104

Epoch: 6| Step: 1
Training loss: 1.4805819988250732
Validation loss: 1.9403667962679298

Epoch: 6| Step: 2
Training loss: 2.5666427612304688
Validation loss: 1.9247283461273357

Epoch: 6| Step: 3
Training loss: 1.7554692029953003
Validation loss: 1.9288639317276657

Epoch: 6| Step: 4
Training loss: 2.026685953140259
Validation loss: 1.9396770487549484

Epoch: 6| Step: 5
Training loss: 1.836944341659546
Validation loss: 1.9560961313145135

Epoch: 6| Step: 6
Training loss: 1.6951650381088257
Validation loss: 1.9413892492171256

Epoch: 6| Step: 7
Training loss: 1.5336620807647705
Validation loss: 1.9261222616318734

Epoch: 6| Step: 8
Training loss: 2.150151252746582
Validation loss: 1.9537733575349212

Epoch: 6| Step: 9
Training loss: 2.036125898361206
Validation loss: 1.9352839134072746

Epoch: 6| Step: 10
Training loss: 1.4766008853912354
Validation loss: 1.9424940411762526

Epoch: 6| Step: 11
Training loss: 2.558507204055786
Validation loss: 1.9408860334786036

Epoch: 6| Step: 12
Training loss: 2.4807770252227783
Validation loss: 1.9200384975761495

Epoch: 6| Step: 13
Training loss: 2.0929019451141357
Validation loss: 1.9295758893412929

Epoch: 131| Step: 0
Training loss: 2.508446216583252
Validation loss: 1.9011495497918898

Epoch: 6| Step: 1
Training loss: 1.5800659656524658
Validation loss: 1.9309978997835548

Epoch: 6| Step: 2
Training loss: 2.4073030948638916
Validation loss: 1.9140061588697537

Epoch: 6| Step: 3
Training loss: 1.664246916770935
Validation loss: 1.9167924093943771

Epoch: 6| Step: 4
Training loss: 2.4063467979431152
Validation loss: 1.9263879112018052

Epoch: 6| Step: 5
Training loss: 1.725818157196045
Validation loss: 1.914214546962451

Epoch: 6| Step: 6
Training loss: 2.3480851650238037
Validation loss: 1.9248105454188522

Epoch: 6| Step: 7
Training loss: 2.10507869720459
Validation loss: 1.9211021751485846

Epoch: 6| Step: 8
Training loss: 0.894895076751709
Validation loss: 1.9065198347132692

Epoch: 6| Step: 9
Training loss: 2.0044569969177246
Validation loss: 1.9173240328347811

Epoch: 6| Step: 10
Training loss: 1.7054386138916016
Validation loss: 1.9205657730820358

Epoch: 6| Step: 11
Training loss: 1.5712562799453735
Validation loss: 1.919882571825417

Epoch: 6| Step: 12
Training loss: 2.530470848083496
Validation loss: 1.923071567730237

Epoch: 6| Step: 13
Training loss: 2.003319501876831
Validation loss: 1.933599707900837

Epoch: 132| Step: 0
Training loss: 2.117706298828125
Validation loss: 1.9278224719467985

Epoch: 6| Step: 1
Training loss: 2.250943183898926
Validation loss: 1.9201701353955012

Epoch: 6| Step: 2
Training loss: 2.0256433486938477
Validation loss: 1.907072567170666

Epoch: 6| Step: 3
Training loss: 2.1586966514587402
Validation loss: 1.9080825851809593

Epoch: 6| Step: 4
Training loss: 1.355539321899414
Validation loss: 1.9142997572498937

Epoch: 6| Step: 5
Training loss: 1.929509162902832
Validation loss: 1.917747256576374

Epoch: 6| Step: 6
Training loss: 2.7244620323181152
Validation loss: 1.9085299173990886

Epoch: 6| Step: 7
Training loss: 1.4464020729064941
Validation loss: 1.923699326412652

Epoch: 6| Step: 8
Training loss: 1.9650639295578003
Validation loss: 1.9375938510382047

Epoch: 6| Step: 9
Training loss: 1.9382678270339966
Validation loss: 1.9501350489995812

Epoch: 6| Step: 10
Training loss: 1.902639389038086
Validation loss: 1.9139954774610457

Epoch: 6| Step: 11
Training loss: 2.1225314140319824
Validation loss: 1.9019052802875478

Epoch: 6| Step: 12
Training loss: 1.4138375520706177
Validation loss: 1.9485713128120667

Epoch: 6| Step: 13
Training loss: 2.1493165493011475
Validation loss: 1.9422053919043591

Epoch: 133| Step: 0
Training loss: 1.9319015741348267
Validation loss: 1.9366066058476765

Epoch: 6| Step: 1
Training loss: 2.064263343811035
Validation loss: 1.9390921669621621

Epoch: 6| Step: 2
Training loss: 1.611852765083313
Validation loss: 1.9415340462038595

Epoch: 6| Step: 3
Training loss: 1.9899646043777466
Validation loss: 1.9446907761276409

Epoch: 6| Step: 4
Training loss: 1.6133896112442017
Validation loss: 1.9428392866606354

Epoch: 6| Step: 5
Training loss: 1.7162017822265625
Validation loss: 1.9469505651022798

Epoch: 6| Step: 6
Training loss: 2.0737924575805664
Validation loss: 1.9326076058931247

Epoch: 6| Step: 7
Training loss: 2.667698383331299
Validation loss: 1.9377559461901266

Epoch: 6| Step: 8
Training loss: 1.5268065929412842
Validation loss: 1.946737161246679

Epoch: 6| Step: 9
Training loss: 2.2081856727600098
Validation loss: 1.9486516675641459

Epoch: 6| Step: 10
Training loss: 2.133039951324463
Validation loss: 1.92746215738276

Epoch: 6| Step: 11
Training loss: 2.640488624572754
Validation loss: 1.9573204132818407

Epoch: 6| Step: 12
Training loss: 2.033677577972412
Validation loss: 1.9408314458785518

Epoch: 6| Step: 13
Training loss: 0.9371005296707153
Validation loss: 1.9258387140048447

Epoch: 134| Step: 0
Training loss: 2.263373374938965
Validation loss: 1.9493933467454807

Epoch: 6| Step: 1
Training loss: 2.5382931232452393
Validation loss: 1.9297945422510947

Epoch: 6| Step: 2
Training loss: 2.19810152053833
Validation loss: 1.9507940507704211

Epoch: 6| Step: 3
Training loss: 1.5827209949493408
Validation loss: 1.958577004812097

Epoch: 6| Step: 4
Training loss: 1.6063969135284424
Validation loss: 1.9369707197271369

Epoch: 6| Step: 5
Training loss: 1.5568814277648926
Validation loss: 1.949408329943175

Epoch: 6| Step: 6
Training loss: 1.8663972616195679
Validation loss: 1.952949627753227

Epoch: 6| Step: 7
Training loss: 1.5325074195861816
Validation loss: 1.9631893634796143

Epoch: 6| Step: 8
Training loss: 2.281102180480957
Validation loss: 1.9763560218195761

Epoch: 6| Step: 9
Training loss: 2.1718363761901855
Validation loss: 1.9659972626675841

Epoch: 6| Step: 10
Training loss: 2.3265624046325684
Validation loss: 1.9363977819360711

Epoch: 6| Step: 11
Training loss: 1.9295134544372559
Validation loss: 1.942372304137035

Epoch: 6| Step: 12
Training loss: 2.0575075149536133
Validation loss: 1.945026865569494

Epoch: 6| Step: 13
Training loss: 1.1541576385498047
Validation loss: 1.9299896993944723

Epoch: 135| Step: 0
Training loss: 1.7767210006713867
Validation loss: 1.9432278217807892

Epoch: 6| Step: 1
Training loss: 2.091414451599121
Validation loss: 1.9310189126640238

Epoch: 6| Step: 2
Training loss: 1.4421732425689697
Validation loss: 1.939788923468641

Epoch: 6| Step: 3
Training loss: 2.097726821899414
Validation loss: 1.9371537828958163

Epoch: 6| Step: 4
Training loss: 2.3222222328186035
Validation loss: 1.924708208730144

Epoch: 6| Step: 5
Training loss: 2.096064329147339
Validation loss: 1.957795331555028

Epoch: 6| Step: 6
Training loss: 1.9499948024749756
Validation loss: 1.9413779743256108

Epoch: 6| Step: 7
Training loss: 2.1179163455963135
Validation loss: 1.944376532749463

Epoch: 6| Step: 8
Training loss: 1.6402652263641357
Validation loss: 1.921094948245633

Epoch: 6| Step: 9
Training loss: 1.8123090267181396
Validation loss: 1.9335627530210762

Epoch: 6| Step: 10
Training loss: 1.2482433319091797
Validation loss: 1.9333640247262933

Epoch: 6| Step: 11
Training loss: 2.4468774795532227
Validation loss: 1.9645783978123819

Epoch: 6| Step: 12
Training loss: 2.396712303161621
Validation loss: 1.9393394903470111

Epoch: 6| Step: 13
Training loss: 1.9514448642730713
Validation loss: 1.913822857282495

Epoch: 136| Step: 0
Training loss: 1.9949402809143066
Validation loss: 1.917341915510034

Epoch: 6| Step: 1
Training loss: 2.141352653503418
Validation loss: 1.9249411129182386

Epoch: 6| Step: 2
Training loss: 2.0400044918060303
Validation loss: 1.914184760021907

Epoch: 6| Step: 3
Training loss: 2.2930092811584473
Validation loss: 1.9122371647947578

Epoch: 6| Step: 4
Training loss: 1.55356764793396
Validation loss: 1.9455747110869295

Epoch: 6| Step: 5
Training loss: 2.4071044921875
Validation loss: 1.9128762983506726

Epoch: 6| Step: 6
Training loss: 2.208160400390625
Validation loss: 1.917293607547719

Epoch: 6| Step: 7
Training loss: 1.696948528289795
Validation loss: 1.9103503265688497

Epoch: 6| Step: 8
Training loss: 2.316141128540039
Validation loss: 1.9309813668650966

Epoch: 6| Step: 9
Training loss: 1.5318949222564697
Validation loss: 1.9264697874746015

Epoch: 6| Step: 10
Training loss: 1.4116151332855225
Validation loss: 1.930115246003674

Epoch: 6| Step: 11
Training loss: 2.027512550354004
Validation loss: 1.9508096787237352

Epoch: 6| Step: 12
Training loss: 1.857617974281311
Validation loss: 1.9303014073320615

Epoch: 6| Step: 13
Training loss: 1.775215983390808
Validation loss: 1.9351216041913597

Epoch: 137| Step: 0
Training loss: 2.0212783813476562
Validation loss: 1.9125884438073764

Epoch: 6| Step: 1
Training loss: 1.731933832168579
Validation loss: 1.9257629738059094

Epoch: 6| Step: 2
Training loss: 1.9985222816467285
Validation loss: 1.9125363288387176

Epoch: 6| Step: 3
Training loss: 2.2044968605041504
Validation loss: 1.9104602952157297

Epoch: 6| Step: 4
Training loss: 2.511867046356201
Validation loss: 1.911234176287087

Epoch: 6| Step: 5
Training loss: 1.8918712139129639
Validation loss: 1.9200030872898717

Epoch: 6| Step: 6
Training loss: 1.6602349281311035
Validation loss: 1.9222028563099522

Epoch: 6| Step: 7
Training loss: 1.935393214225769
Validation loss: 1.9192846539199993

Epoch: 6| Step: 8
Training loss: 2.6825928688049316
Validation loss: 1.9323737057306434

Epoch: 6| Step: 9
Training loss: 2.2825255393981934
Validation loss: 1.9218110986935195

Epoch: 6| Step: 10
Training loss: 1.3891648054122925
Validation loss: 1.9293554623921711

Epoch: 6| Step: 11
Training loss: 1.8599132299423218
Validation loss: 1.9383245052829865

Epoch: 6| Step: 12
Training loss: 1.2626252174377441
Validation loss: 1.9224889919322024

Epoch: 6| Step: 13
Training loss: 2.0622618198394775
Validation loss: 1.9205639413608018

Epoch: 138| Step: 0
Training loss: 2.0769381523132324
Validation loss: 1.9210950841185868

Epoch: 6| Step: 1
Training loss: 2.0852012634277344
Validation loss: 1.9077288694279169

Epoch: 6| Step: 2
Training loss: 1.6690874099731445
Validation loss: 1.9223880203821326

Epoch: 6| Step: 3
Training loss: 1.4917418956756592
Validation loss: 1.939939570683305

Epoch: 6| Step: 4
Training loss: 2.0892176628112793
Validation loss: 1.938316015787022

Epoch: 6| Step: 5
Training loss: 2.2728374004364014
Validation loss: 1.967641330534412

Epoch: 6| Step: 6
Training loss: 2.436854362487793
Validation loss: 1.9441839956468152

Epoch: 6| Step: 7
Training loss: 1.7316559553146362
Validation loss: 1.9276019039974417

Epoch: 6| Step: 8
Training loss: 2.208815813064575
Validation loss: 1.943069169598241

Epoch: 6| Step: 9
Training loss: 1.9345622062683105
Validation loss: 1.9679168578117125

Epoch: 6| Step: 10
Training loss: 1.4654269218444824
Validation loss: 1.9516807435661234

Epoch: 6| Step: 11
Training loss: 1.2208772897720337
Validation loss: 1.9739635464965657

Epoch: 6| Step: 12
Training loss: 2.459343194961548
Validation loss: 1.9613277681412236

Epoch: 6| Step: 13
Training loss: 2.168671131134033
Validation loss: 1.9788083901969336

Epoch: 139| Step: 0
Training loss: 1.4454814195632935
Validation loss: 1.9600843485965525

Epoch: 6| Step: 1
Training loss: 1.4389606714248657
Validation loss: 1.9575067309923069

Epoch: 6| Step: 2
Training loss: 1.6479787826538086
Validation loss: 1.9386654797420706

Epoch: 6| Step: 3
Training loss: 1.4142439365386963
Validation loss: 1.9325271485954203

Epoch: 6| Step: 4
Training loss: 1.655776858329773
Validation loss: 1.9453222982345089

Epoch: 6| Step: 5
Training loss: 2.095027446746826
Validation loss: 1.9393912156422932

Epoch: 6| Step: 6
Training loss: 2.434340000152588
Validation loss: 1.9209391058132212

Epoch: 6| Step: 7
Training loss: 1.764901876449585
Validation loss: 1.9271590812231905

Epoch: 6| Step: 8
Training loss: 2.2930197715759277
Validation loss: 1.9232033362952612

Epoch: 6| Step: 9
Training loss: 2.1831271648406982
Validation loss: 1.8840370306404688

Epoch: 6| Step: 10
Training loss: 2.536130428314209
Validation loss: 1.9067404526536182

Epoch: 6| Step: 11
Training loss: 2.0962815284729004
Validation loss: 1.9208675071757326

Epoch: 6| Step: 12
Training loss: 2.388103723526001
Validation loss: 1.9199652543631933

Epoch: 6| Step: 13
Training loss: 1.9889121055603027
Validation loss: 1.9214253976780882

Epoch: 140| Step: 0
Training loss: 1.5752067565917969
Validation loss: 1.9044425859246203

Epoch: 6| Step: 1
Training loss: 1.9470425844192505
Validation loss: 1.9057343570134972

Epoch: 6| Step: 2
Training loss: 1.4177991151809692
Validation loss: 1.9198964667576615

Epoch: 6| Step: 3
Training loss: 2.5678329467773438
Validation loss: 1.914216431238318

Epoch: 6| Step: 4
Training loss: 1.902953028678894
Validation loss: 1.9348825472657398

Epoch: 6| Step: 5
Training loss: 2.33734130859375
Validation loss: 1.9281072437122304

Epoch: 6| Step: 6
Training loss: 1.888589859008789
Validation loss: 1.953863315684821

Epoch: 6| Step: 7
Training loss: 1.6915323734283447
Validation loss: 1.9164278943051574

Epoch: 6| Step: 8
Training loss: 1.4800169467926025
Validation loss: 1.9292251845841766

Epoch: 6| Step: 9
Training loss: 2.3491599559783936
Validation loss: 1.9548300594411872

Epoch: 6| Step: 10
Training loss: 2.0420992374420166
Validation loss: 1.934127075697786

Epoch: 6| Step: 11
Training loss: 2.247735023498535
Validation loss: 1.9274523309482041

Epoch: 6| Step: 12
Training loss: 1.7283711433410645
Validation loss: 1.9335649731338664

Epoch: 6| Step: 13
Training loss: 2.2087368965148926
Validation loss: 1.9343763602677213

Epoch: 141| Step: 0
Training loss: 1.8773016929626465
Validation loss: 1.9599645894060853

Epoch: 6| Step: 1
Training loss: 2.211949348449707
Validation loss: 1.9359317761595531

Epoch: 6| Step: 2
Training loss: 2.0716986656188965
Validation loss: 1.9116512114001858

Epoch: 6| Step: 3
Training loss: 2.206062078475952
Validation loss: 1.9288111373942385

Epoch: 6| Step: 4
Training loss: 1.9875726699829102
Validation loss: 1.9174705141334123

Epoch: 6| Step: 5
Training loss: 1.893848180770874
Validation loss: 1.9247153061692432

Epoch: 6| Step: 6
Training loss: 2.2439370155334473
Validation loss: 1.9293015836387553

Epoch: 6| Step: 7
Training loss: 1.9947741031646729
Validation loss: 1.9238014528828282

Epoch: 6| Step: 8
Training loss: 1.8538094758987427
Validation loss: 1.9314563030837684

Epoch: 6| Step: 9
Training loss: 2.339299201965332
Validation loss: 1.9111299873680196

Epoch: 6| Step: 10
Training loss: 1.8909083604812622
Validation loss: 1.9393984745907527

Epoch: 6| Step: 11
Training loss: 1.2805793285369873
Validation loss: 1.917047833883634

Epoch: 6| Step: 12
Training loss: 1.3851282596588135
Validation loss: 1.9234608783516833

Epoch: 6| Step: 13
Training loss: 2.1794533729553223
Validation loss: 1.9434098838478007

Epoch: 142| Step: 0
Training loss: 1.7150981426239014
Validation loss: 1.9215587005820325

Epoch: 6| Step: 1
Training loss: 2.2291460037231445
Validation loss: 1.9556808510134298

Epoch: 6| Step: 2
Training loss: 2.7062299251556396
Validation loss: 1.9281931743826917

Epoch: 6| Step: 3
Training loss: 1.7668981552124023
Validation loss: 1.9052430378493441

Epoch: 6| Step: 4
Training loss: 1.8557381629943848
Validation loss: 1.9427433257461877

Epoch: 6| Step: 5
Training loss: 2.184353828430176
Validation loss: 1.9302427973798526

Epoch: 6| Step: 6
Training loss: 1.8553452491760254
Validation loss: 1.9422370156934183

Epoch: 6| Step: 7
Training loss: 2.3267390727996826
Validation loss: 1.9050976589161863

Epoch: 6| Step: 8
Training loss: 1.2737692594528198
Validation loss: 1.9476400318966116

Epoch: 6| Step: 9
Training loss: 1.942420482635498
Validation loss: 1.9469332054097166

Epoch: 6| Step: 10
Training loss: 1.375252604484558
Validation loss: 1.9307122384348223

Epoch: 6| Step: 11
Training loss: 1.8241273164749146
Validation loss: 1.938177526638072

Epoch: 6| Step: 12
Training loss: 1.8520724773406982
Validation loss: 1.9421292953593756

Epoch: 6| Step: 13
Training loss: 2.2107982635498047
Validation loss: 1.940495216718284

Epoch: 143| Step: 0
Training loss: 2.0094211101531982
Validation loss: 1.9498717566972137

Epoch: 6| Step: 1
Training loss: 2.5855226516723633
Validation loss: 1.9531530910922634

Epoch: 6| Step: 2
Training loss: 1.6837232112884521
Validation loss: 1.939949994446129

Epoch: 6| Step: 3
Training loss: 1.4364858865737915
Validation loss: 1.9640142033177037

Epoch: 6| Step: 4
Training loss: 1.9229884147644043
Validation loss: 1.9523367317773963

Epoch: 6| Step: 5
Training loss: 2.031017541885376
Validation loss: 1.9395767873333347

Epoch: 6| Step: 6
Training loss: 1.7942101955413818
Validation loss: 1.9470418858271774

Epoch: 6| Step: 7
Training loss: 1.8144854307174683
Validation loss: 1.9574931103696105

Epoch: 6| Step: 8
Training loss: 1.7536828517913818
Validation loss: 1.9343317016478507

Epoch: 6| Step: 9
Training loss: 1.9961670637130737
Validation loss: 1.94709748606528

Epoch: 6| Step: 10
Training loss: 2.2493205070495605
Validation loss: 1.9287914332523142

Epoch: 6| Step: 11
Training loss: 1.950592279434204
Validation loss: 1.935128968249085

Epoch: 6| Step: 12
Training loss: 1.9585860967636108
Validation loss: 1.923195041635985

Epoch: 6| Step: 13
Training loss: 1.7252908945083618
Validation loss: 1.947647653600221

Epoch: 144| Step: 0
Training loss: 2.0106029510498047
Validation loss: 1.9287236134211223

Epoch: 6| Step: 1
Training loss: 1.7100794315338135
Validation loss: 1.934407567465177

Epoch: 6| Step: 2
Training loss: 1.7776496410369873
Validation loss: 1.9549073967882382

Epoch: 6| Step: 3
Training loss: 1.5508267879486084
Validation loss: 1.9148915813815208

Epoch: 6| Step: 4
Training loss: 1.9099034070968628
Validation loss: 1.9413407771818099

Epoch: 6| Step: 5
Training loss: 1.0307408571243286
Validation loss: 1.9436141675518406

Epoch: 6| Step: 6
Training loss: 2.27034854888916
Validation loss: 1.9424128365773026

Epoch: 6| Step: 7
Training loss: 1.7628867626190186
Validation loss: 1.9453219547066638

Epoch: 6| Step: 8
Training loss: 2.044954299926758
Validation loss: 1.9377804648491643

Epoch: 6| Step: 9
Training loss: 1.9150997400283813
Validation loss: 1.9291055587030226

Epoch: 6| Step: 10
Training loss: 2.130136251449585
Validation loss: 1.9517443231357041

Epoch: 6| Step: 11
Training loss: 2.2174530029296875
Validation loss: 1.9501284655704294

Epoch: 6| Step: 12
Training loss: 1.8247699737548828
Validation loss: 1.9379295508066814

Epoch: 6| Step: 13
Training loss: 3.4305126667022705
Validation loss: 1.9270025927533385

Epoch: 145| Step: 0
Training loss: 1.683330774307251
Validation loss: 1.931415924461939

Epoch: 6| Step: 1
Training loss: 1.9101372957229614
Validation loss: 1.9521983567104544

Epoch: 6| Step: 2
Training loss: 1.3329052925109863
Validation loss: 1.9431762438948437

Epoch: 6| Step: 3
Training loss: 1.9904929399490356
Validation loss: 1.9289831371717556

Epoch: 6| Step: 4
Training loss: 2.6585936546325684
Validation loss: 1.914737578361265

Epoch: 6| Step: 5
Training loss: 2.2711308002471924
Validation loss: 1.9050897398302633

Epoch: 6| Step: 6
Training loss: 1.6643846035003662
Validation loss: 1.900483182681504

Epoch: 6| Step: 7
Training loss: 1.9466009140014648
Validation loss: 1.9276614906967326

Epoch: 6| Step: 8
Training loss: 2.0980916023254395
Validation loss: 1.9286151880859046

Epoch: 6| Step: 9
Training loss: 1.322784185409546
Validation loss: 1.91474227751455

Epoch: 6| Step: 10
Training loss: 2.126387119293213
Validation loss: 1.9120596506262337

Epoch: 6| Step: 11
Training loss: 1.9940944910049438
Validation loss: 1.9019665205350487

Epoch: 6| Step: 12
Training loss: 1.7999520301818848
Validation loss: 1.9196605477281796

Epoch: 6| Step: 13
Training loss: 2.1848669052124023
Validation loss: 1.918927138851535

Epoch: 146| Step: 0
Training loss: 2.3168129920959473
Validation loss: 1.9324079687877367

Epoch: 6| Step: 1
Training loss: 2.4781816005706787
Validation loss: 1.907269307362136

Epoch: 6| Step: 2
Training loss: 1.3048012256622314
Validation loss: 1.9328685229824436

Epoch: 6| Step: 3
Training loss: 1.3328795433044434
Validation loss: 1.951050642997988

Epoch: 6| Step: 4
Training loss: 1.8161067962646484
Validation loss: 1.9553133864556589

Epoch: 6| Step: 5
Training loss: 1.8828753232955933
Validation loss: 1.9530620805678829

Epoch: 6| Step: 6
Training loss: 2.0661966800689697
Validation loss: 1.9694101028544928

Epoch: 6| Step: 7
Training loss: 1.6231412887573242
Validation loss: 1.958666883489137

Epoch: 6| Step: 8
Training loss: 2.345388412475586
Validation loss: 1.9726285908811836

Epoch: 6| Step: 9
Training loss: 2.3799679279327393
Validation loss: 1.9820632703842656

Epoch: 6| Step: 10
Training loss: 1.7622408866882324
Validation loss: 1.9537819406037689

Epoch: 6| Step: 11
Training loss: 1.4491982460021973
Validation loss: 1.9900803617251817

Epoch: 6| Step: 12
Training loss: 2.293466567993164
Validation loss: 1.9570386294395692

Epoch: 6| Step: 13
Training loss: 1.7185213565826416
Validation loss: 1.958533525466919

Epoch: 147| Step: 0
Training loss: 1.8633546829223633
Validation loss: 1.9496678101119174

Epoch: 6| Step: 1
Training loss: 0.9711941480636597
Validation loss: 1.9537463072807557

Epoch: 6| Step: 2
Training loss: 2.247321128845215
Validation loss: 1.9335502322002123

Epoch: 6| Step: 3
Training loss: 1.8879971504211426
Validation loss: 1.935662741302162

Epoch: 6| Step: 4
Training loss: 1.7584598064422607
Validation loss: 1.9299124056293118

Epoch: 6| Step: 5
Training loss: 1.7514207363128662
Validation loss: 1.9170657678316998

Epoch: 6| Step: 6
Training loss: 1.1561501026153564
Validation loss: 1.9101652406877088

Epoch: 6| Step: 7
Training loss: 2.51052188873291
Validation loss: 1.9015060624768656

Epoch: 6| Step: 8
Training loss: 1.985937476158142
Validation loss: 1.938070712550994

Epoch: 6| Step: 9
Training loss: 2.2186620235443115
Validation loss: 1.927855432674449

Epoch: 6| Step: 10
Training loss: 2.1564574241638184
Validation loss: 1.9150967546688613

Epoch: 6| Step: 11
Training loss: 2.316969394683838
Validation loss: 1.9207223717884352

Epoch: 6| Step: 12
Training loss: 2.0927839279174805
Validation loss: 1.9220616061200377

Epoch: 6| Step: 13
Training loss: 1.9473700523376465
Validation loss: 1.9283005986162411

Epoch: 148| Step: 0
Training loss: 1.6094316244125366
Validation loss: 1.9074574785847818

Epoch: 6| Step: 1
Training loss: 1.7298015356063843
Validation loss: 1.9021812767110846

Epoch: 6| Step: 2
Training loss: 2.4841415882110596
Validation loss: 1.9192290818819435

Epoch: 6| Step: 3
Training loss: 1.7869007587432861
Validation loss: 1.9349211826119372

Epoch: 6| Step: 4
Training loss: 1.0717995166778564
Validation loss: 1.918741521014962

Epoch: 6| Step: 5
Training loss: 1.557682752609253
Validation loss: 1.9323492998717933

Epoch: 6| Step: 6
Training loss: 2.9797682762145996
Validation loss: 1.9181798068425988

Epoch: 6| Step: 7
Training loss: 1.5312552452087402
Validation loss: 1.9194876609310028

Epoch: 6| Step: 8
Training loss: 1.3601515293121338
Validation loss: 1.9219942246713946

Epoch: 6| Step: 9
Training loss: 1.7101829051971436
Validation loss: 1.9320724446286437

Epoch: 6| Step: 10
Training loss: 2.3431882858276367
Validation loss: 1.9308044807885283

Epoch: 6| Step: 11
Training loss: 2.4807655811309814
Validation loss: 1.9321456904052405

Epoch: 6| Step: 12
Training loss: 2.5450565814971924
Validation loss: 1.9255151364111132

Epoch: 6| Step: 13
Training loss: 1.4491437673568726
Validation loss: 1.9431745416374617

Epoch: 149| Step: 0
Training loss: 1.7793793678283691
Validation loss: 1.9384253358328214

Epoch: 6| Step: 1
Training loss: 2.276265859603882
Validation loss: 1.9162129253469489

Epoch: 6| Step: 2
Training loss: 1.6202952861785889
Validation loss: 1.9172537134539696

Epoch: 6| Step: 3
Training loss: 2.133173942565918
Validation loss: 1.9359331361709102

Epoch: 6| Step: 4
Training loss: 2.185210704803467
Validation loss: 1.932036792078326

Epoch: 6| Step: 5
Training loss: 2.3324999809265137
Validation loss: 1.9414742339041926

Epoch: 6| Step: 6
Training loss: 1.6113721132278442
Validation loss: 1.9151928476108018

Epoch: 6| Step: 7
Training loss: 1.4191240072250366
Validation loss: 1.9435068176638695

Epoch: 6| Step: 8
Training loss: 1.6013140678405762
Validation loss: 1.9423988262812297

Epoch: 6| Step: 9
Training loss: 1.9792265892028809
Validation loss: 1.9374452162814397

Epoch: 6| Step: 10
Training loss: 1.3857736587524414
Validation loss: 1.9296678599490915

Epoch: 6| Step: 11
Training loss: 1.6750460863113403
Validation loss: 1.9635057705704884

Epoch: 6| Step: 12
Training loss: 2.560924530029297
Validation loss: 1.933217874137304

Epoch: 6| Step: 13
Training loss: 2.0165510177612305
Validation loss: 1.9388694494001326

Epoch: 150| Step: 0
Training loss: 1.514831781387329
Validation loss: 1.9418915625541442

Epoch: 6| Step: 1
Training loss: 2.5911405086517334
Validation loss: 1.9454399462669127

Epoch: 6| Step: 2
Training loss: 2.0699596405029297
Validation loss: 1.9199345547665831

Epoch: 6| Step: 3
Training loss: 1.8981282711029053
Validation loss: 1.93196609199688

Epoch: 6| Step: 4
Training loss: 1.631967306137085
Validation loss: 1.9300812764834332

Epoch: 6| Step: 5
Training loss: 1.3612780570983887
Validation loss: 1.937078026033217

Epoch: 6| Step: 6
Training loss: 2.1423630714416504
Validation loss: 1.9171033674670803

Epoch: 6| Step: 7
Training loss: 1.993901014328003
Validation loss: 1.9197173977410922

Epoch: 6| Step: 8
Training loss: 2.1091508865356445
Validation loss: 1.9295054866421608

Epoch: 6| Step: 9
Training loss: 1.4904708862304688
Validation loss: 1.9308084916043025

Epoch: 6| Step: 10
Training loss: 1.3292217254638672
Validation loss: 1.9168227827677162

Epoch: 6| Step: 11
Training loss: 2.3205323219299316
Validation loss: 1.9163782827315792

Epoch: 6| Step: 12
Training loss: 2.2320773601531982
Validation loss: 1.927775816250873

Epoch: 6| Step: 13
Training loss: 1.574945092201233
Validation loss: 1.9192672775637718

Epoch: 151| Step: 0
Training loss: 1.3722631931304932
Validation loss: 1.8793069111403597

Epoch: 6| Step: 1
Training loss: 2.0355546474456787
Validation loss: 1.8976940954885175

Epoch: 6| Step: 2
Training loss: 2.108144760131836
Validation loss: 1.9066704139914563

Epoch: 6| Step: 3
Training loss: 1.7622781991958618
Validation loss: 1.892563070020368

Epoch: 6| Step: 4
Training loss: 1.5452933311462402
Validation loss: 1.9435637740678684

Epoch: 6| Step: 5
Training loss: 1.8035621643066406
Validation loss: 1.8984052212007585

Epoch: 6| Step: 6
Training loss: 1.9415311813354492
Validation loss: 1.9249281703784902

Epoch: 6| Step: 7
Training loss: 1.0389814376831055
Validation loss: 1.8978157184457267

Epoch: 6| Step: 8
Training loss: 2.496403217315674
Validation loss: 1.902681528881032

Epoch: 6| Step: 9
Training loss: 2.521242380142212
Validation loss: 1.913977874222622

Epoch: 6| Step: 10
Training loss: 2.2624542713165283
Validation loss: 1.9327115628027147

Epoch: 6| Step: 11
Training loss: 2.056687355041504
Validation loss: 1.914541103506601

Epoch: 6| Step: 12
Training loss: 1.6727244853973389
Validation loss: 1.9066838961775585

Epoch: 6| Step: 13
Training loss: 1.937885046005249
Validation loss: 1.9155440317687167

Epoch: 152| Step: 0
Training loss: 1.418793797492981
Validation loss: 1.9221735551793089

Epoch: 6| Step: 1
Training loss: 2.3162760734558105
Validation loss: 1.9183758330601517

Epoch: 6| Step: 2
Training loss: 1.7236320972442627
Validation loss: 1.9339196271793817

Epoch: 6| Step: 3
Training loss: 2.174999237060547
Validation loss: 1.9474677167912966

Epoch: 6| Step: 4
Training loss: 2.2364072799682617
Validation loss: 1.9431588175476238

Epoch: 6| Step: 5
Training loss: 2.063786745071411
Validation loss: 1.952839910343129

Epoch: 6| Step: 6
Training loss: 1.2038027048110962
Validation loss: 1.935781014862881

Epoch: 6| Step: 7
Training loss: 2.3924989700317383
Validation loss: 1.9468613029808126

Epoch: 6| Step: 8
Training loss: 1.5790767669677734
Validation loss: 1.9526273473616569

Epoch: 6| Step: 9
Training loss: 1.545379400253296
Validation loss: 1.9327626984606507

Epoch: 6| Step: 10
Training loss: 2.0563724040985107
Validation loss: 1.9288170388949815

Epoch: 6| Step: 11
Training loss: 1.3966387510299683
Validation loss: 1.9360926279457666

Epoch: 6| Step: 12
Training loss: 2.650155782699585
Validation loss: 1.9659413317198395

Epoch: 6| Step: 13
Training loss: 1.7105844020843506
Validation loss: 1.9534372052838724

Epoch: 153| Step: 0
Training loss: 1.9573010206222534
Validation loss: 1.9698861004203878

Epoch: 6| Step: 1
Training loss: 1.6801137924194336
Validation loss: 1.9484787756396877

Epoch: 6| Step: 2
Training loss: 2.1153831481933594
Validation loss: 1.9447795908938172

Epoch: 6| Step: 3
Training loss: 1.7446866035461426
Validation loss: 1.9455224032043128

Epoch: 6| Step: 4
Training loss: 2.835906505584717
Validation loss: 1.9158099582118373

Epoch: 6| Step: 5
Training loss: 1.1339170932769775
Validation loss: 1.9621041359439972

Epoch: 6| Step: 6
Training loss: 1.6820309162139893
Validation loss: 1.9592935833879697

Epoch: 6| Step: 7
Training loss: 1.5822134017944336
Validation loss: 1.9483564515267648

Epoch: 6| Step: 8
Training loss: 1.5930345058441162
Validation loss: 1.9452473450732488

Epoch: 6| Step: 9
Training loss: 2.23898983001709
Validation loss: 1.9224208785641579

Epoch: 6| Step: 10
Training loss: 2.136847734451294
Validation loss: 1.932266619897658

Epoch: 6| Step: 11
Training loss: 1.731096863746643
Validation loss: 1.9586813603678057

Epoch: 6| Step: 12
Training loss: 1.8222541809082031
Validation loss: 1.9026699053343905

Epoch: 6| Step: 13
Training loss: 1.8851149082183838
Validation loss: 1.948411585182272

Epoch: 154| Step: 0
Training loss: 2.0801820755004883
Validation loss: 1.926476663158786

Epoch: 6| Step: 1
Training loss: 1.9998446702957153
Validation loss: 1.9155989334147463

Epoch: 6| Step: 2
Training loss: 1.6355361938476562
Validation loss: 1.9057404379690848

Epoch: 6| Step: 3
Training loss: 2.1852002143859863
Validation loss: 1.9370126173060427

Epoch: 6| Step: 4
Training loss: 2.016633987426758
Validation loss: 1.9297757379470333

Epoch: 6| Step: 5
Training loss: 1.811145544052124
Validation loss: 1.9010971848682692

Epoch: 6| Step: 6
Training loss: 1.5079573392868042
Validation loss: 1.9307723493986233

Epoch: 6| Step: 7
Training loss: 1.986304521560669
Validation loss: 1.9156347718290103

Epoch: 6| Step: 8
Training loss: 2.4703409671783447
Validation loss: 1.9310103436951995

Epoch: 6| Step: 9
Training loss: 1.6348004341125488
Validation loss: 1.9114439936094387

Epoch: 6| Step: 10
Training loss: 1.7457880973815918
Validation loss: 1.9213136831919353

Epoch: 6| Step: 11
Training loss: 1.990837574005127
Validation loss: 1.908175483826668

Epoch: 6| Step: 12
Training loss: 1.9217880964279175
Validation loss: 1.9128080260369085

Epoch: 6| Step: 13
Training loss: 1.4934757947921753
Validation loss: 1.9268221944890997

Epoch: 155| Step: 0
Training loss: 1.7881741523742676
Validation loss: 1.9183580106304539

Epoch: 6| Step: 1
Training loss: 2.3946118354797363
Validation loss: 1.9160686897975143

Epoch: 6| Step: 2
Training loss: 1.6470420360565186
Validation loss: 1.9115021485154347

Epoch: 6| Step: 3
Training loss: 1.8226515054702759
Validation loss: 1.9152703567217755

Epoch: 6| Step: 4
Training loss: 1.5998506546020508
Validation loss: 1.9320685991676905

Epoch: 6| Step: 5
Training loss: 2.0237886905670166
Validation loss: 1.922275709849532

Epoch: 6| Step: 6
Training loss: 2.626066207885742
Validation loss: 1.9350233411276212

Epoch: 6| Step: 7
Training loss: 1.8035118579864502
Validation loss: 1.9506893721959924

Epoch: 6| Step: 8
Training loss: 1.8985419273376465
Validation loss: 1.926694857176914

Epoch: 6| Step: 9
Training loss: 1.6057178974151611
Validation loss: 1.9418967654628139

Epoch: 6| Step: 10
Training loss: 1.1018030643463135
Validation loss: 1.944498033933742

Epoch: 6| Step: 11
Training loss: 1.4949147701263428
Validation loss: 1.9408622685299124

Epoch: 6| Step: 12
Training loss: 2.1549525260925293
Validation loss: 1.9659782404540687

Epoch: 6| Step: 13
Training loss: 2.3296709060668945
Validation loss: 1.9308499815643474

Epoch: 156| Step: 0
Training loss: 1.6259019374847412
Validation loss: 1.9511393295821322

Epoch: 6| Step: 1
Training loss: 1.7760124206542969
Validation loss: 1.9307304492560766

Epoch: 6| Step: 2
Training loss: 1.7389366626739502
Validation loss: 1.9585643353000763

Epoch: 6| Step: 3
Training loss: 1.3268529176712036
Validation loss: 1.917486411268993

Epoch: 6| Step: 4
Training loss: 1.7389037609100342
Validation loss: 1.934046551745425

Epoch: 6| Step: 5
Training loss: 1.6852171421051025
Validation loss: 1.9099206744983632

Epoch: 6| Step: 6
Training loss: 1.7877296209335327
Validation loss: 1.9456850636389948

Epoch: 6| Step: 7
Training loss: 2.1358914375305176
Validation loss: 1.9090971344260759

Epoch: 6| Step: 8
Training loss: 2.431457042694092
Validation loss: 1.9371133978648851

Epoch: 6| Step: 9
Training loss: 1.4679380655288696
Validation loss: 1.9132108303808397

Epoch: 6| Step: 10
Training loss: 2.54386043548584
Validation loss: 1.9145523976254206

Epoch: 6| Step: 11
Training loss: 1.9796123504638672
Validation loss: 1.91182231262166

Epoch: 6| Step: 12
Training loss: 2.5579004287719727
Validation loss: 1.9109692086455643

Epoch: 6| Step: 13
Training loss: 1.5201669931411743
Validation loss: 1.921672260889443

Epoch: 157| Step: 0
Training loss: 1.8576741218566895
Validation loss: 1.8992475207133959

Epoch: 6| Step: 1
Training loss: 1.7032051086425781
Validation loss: 1.9232482653792187

Epoch: 6| Step: 2
Training loss: 1.648512363433838
Validation loss: 1.920092576293535

Epoch: 6| Step: 3
Training loss: 2.476206064224243
Validation loss: 1.9196977282083163

Epoch: 6| Step: 4
Training loss: 2.0260491371154785
Validation loss: 1.9124816489476029

Epoch: 6| Step: 5
Training loss: 1.8938109874725342
Validation loss: 1.9374325634330831

Epoch: 6| Step: 6
Training loss: 1.1899971961975098
Validation loss: 1.9265370509957755

Epoch: 6| Step: 7
Training loss: 1.1852868795394897
Validation loss: 1.9259603202983897

Epoch: 6| Step: 8
Training loss: 2.0952987670898438
Validation loss: 1.9336086703884987

Epoch: 6| Step: 9
Training loss: 2.455930709838867
Validation loss: 1.9014715007556382

Epoch: 6| Step: 10
Training loss: 2.065300464630127
Validation loss: 1.9167622737987067

Epoch: 6| Step: 11
Training loss: 1.9378981590270996
Validation loss: 1.9055227182244743

Epoch: 6| Step: 12
Training loss: 2.1041030883789062
Validation loss: 1.93419603378542

Epoch: 6| Step: 13
Training loss: 1.5664000511169434
Validation loss: 1.9328902357368059

Epoch: 158| Step: 0
Training loss: 1.9383116960525513
Validation loss: 1.9054293696598341

Epoch: 6| Step: 1
Training loss: 1.3643383979797363
Validation loss: 1.9072217851556756

Epoch: 6| Step: 2
Training loss: 2.798241138458252
Validation loss: 1.9244907850860267

Epoch: 6| Step: 3
Training loss: 1.4802982807159424
Validation loss: 1.9034284942893571

Epoch: 6| Step: 4
Training loss: 2.3512814044952393
Validation loss: 1.9343136331086517

Epoch: 6| Step: 5
Training loss: 2.500588893890381
Validation loss: 1.9197192602260138

Epoch: 6| Step: 6
Training loss: 1.9366928339004517
Validation loss: 1.9336589997814548

Epoch: 6| Step: 7
Training loss: 1.5634881258010864
Validation loss: 1.9224884907404582

Epoch: 6| Step: 8
Training loss: 1.0809404850006104
Validation loss: 1.909745164455906

Epoch: 6| Step: 9
Training loss: 2.100566864013672
Validation loss: 1.9239755343365412

Epoch: 6| Step: 10
Training loss: 1.5385115146636963
Validation loss: 1.9497619200778264

Epoch: 6| Step: 11
Training loss: 1.8336002826690674
Validation loss: 1.9224609918491815

Epoch: 6| Step: 12
Training loss: 1.834426999092102
Validation loss: 1.9411390378911009

Epoch: 6| Step: 13
Training loss: 2.1048216819763184
Validation loss: 1.9255279033414778

Epoch: 159| Step: 0
Training loss: 1.708789348602295
Validation loss: 1.927812325057163

Epoch: 6| Step: 1
Training loss: 1.90427565574646
Validation loss: 1.9130848505163704

Epoch: 6| Step: 2
Training loss: 1.6064682006835938
Validation loss: 1.9162853674222065

Epoch: 6| Step: 3
Training loss: 1.777130365371704
Validation loss: 1.9220159630621634

Epoch: 6| Step: 4
Training loss: 2.0617711544036865
Validation loss: 1.9080142077579294

Epoch: 6| Step: 5
Training loss: 2.149104118347168
Validation loss: 1.9012972539471042

Epoch: 6| Step: 6
Training loss: 1.837162733078003
Validation loss: 1.9017895960038709

Epoch: 6| Step: 7
Training loss: 2.0858073234558105
Validation loss: 1.9173175429785123

Epoch: 6| Step: 8
Training loss: 1.6047279834747314
Validation loss: 1.9367463063168269

Epoch: 6| Step: 9
Training loss: 2.4794931411743164
Validation loss: 1.9083683747117237

Epoch: 6| Step: 10
Training loss: 1.8089884519577026
Validation loss: 1.9238349289022467

Epoch: 6| Step: 11
Training loss: 1.526787281036377
Validation loss: 1.9248373534089775

Epoch: 6| Step: 12
Training loss: 1.668229579925537
Validation loss: 1.9095375999327628

Epoch: 6| Step: 13
Training loss: 2.0544116497039795
Validation loss: 1.9009587636557959

Epoch: 160| Step: 0
Training loss: 1.6168575286865234
Validation loss: 1.89442705082637

Epoch: 6| Step: 1
Training loss: 2.209613800048828
Validation loss: 1.9098774181899203

Epoch: 6| Step: 2
Training loss: 1.9361834526062012
Validation loss: 1.9051521837070424

Epoch: 6| Step: 3
Training loss: 1.6703450679779053
Validation loss: 1.901449066336437

Epoch: 6| Step: 4
Training loss: 1.479858160018921
Validation loss: 1.9193667596386326

Epoch: 6| Step: 5
Training loss: 1.92373526096344
Validation loss: 1.922204920040664

Epoch: 6| Step: 6
Training loss: 1.810809850692749
Validation loss: 1.9185485250206404

Epoch: 6| Step: 7
Training loss: 1.4693284034729004
Validation loss: 1.9223337955372308

Epoch: 6| Step: 8
Training loss: 2.2190558910369873
Validation loss: 1.9289790276558167

Epoch: 6| Step: 9
Training loss: 1.9791970252990723
Validation loss: 1.8905515798958399

Epoch: 6| Step: 10
Training loss: 0.9909185171127319
Validation loss: 1.942865881868588

Epoch: 6| Step: 11
Training loss: 2.2007129192352295
Validation loss: 1.942785188715945

Epoch: 6| Step: 12
Training loss: 2.167954921722412
Validation loss: 1.9295856555302937

Epoch: 6| Step: 13
Training loss: 2.57869815826416
Validation loss: 1.955018594700803

Epoch: 161| Step: 0
Training loss: 2.1153736114501953
Validation loss: 1.9479066248862975

Epoch: 6| Step: 1
Training loss: 2.5576415061950684
Validation loss: 1.9381939621381863

Epoch: 6| Step: 2
Training loss: 2.196726083755493
Validation loss: 1.9373357193444365

Epoch: 6| Step: 3
Training loss: 2.4486851692199707
Validation loss: 1.9522637192920973

Epoch: 6| Step: 4
Training loss: 1.7391347885131836
Validation loss: 1.9619925746353724

Epoch: 6| Step: 5
Training loss: 1.6457780599594116
Validation loss: 1.934946079407969

Epoch: 6| Step: 6
Training loss: 1.1481070518493652
Validation loss: 1.9497975867281678

Epoch: 6| Step: 7
Training loss: 1.4200019836425781
Validation loss: 1.9693270293615197

Epoch: 6| Step: 8
Training loss: 1.5440289974212646
Validation loss: 1.9267882634234685

Epoch: 6| Step: 9
Training loss: 2.221017599105835
Validation loss: 1.9272573455687492

Epoch: 6| Step: 10
Training loss: 1.9723678827285767
Validation loss: 1.9223685469678653

Epoch: 6| Step: 11
Training loss: 1.6684237718582153
Validation loss: 1.9105088608239287

Epoch: 6| Step: 12
Training loss: 1.4254359006881714
Validation loss: 1.906999062466365

Epoch: 6| Step: 13
Training loss: 2.204118013381958
Validation loss: 1.9190926423636816

Epoch: 162| Step: 0
Training loss: 0.994304895401001
Validation loss: 1.9128293542451755

Epoch: 6| Step: 1
Training loss: 1.9987163543701172
Validation loss: 1.9227264491460656

Epoch: 6| Step: 2
Training loss: 2.2152276039123535
Validation loss: 1.920055748313986

Epoch: 6| Step: 3
Training loss: 1.6285251379013062
Validation loss: 1.9150397546829716

Epoch: 6| Step: 4
Training loss: 1.69479238986969
Validation loss: 1.9176421191102715

Epoch: 6| Step: 5
Training loss: 1.6343257427215576
Validation loss: 1.9006255672823997

Epoch: 6| Step: 6
Training loss: 1.711596965789795
Validation loss: 1.9002631864240092

Epoch: 6| Step: 7
Training loss: 2.6979637145996094
Validation loss: 1.8956725059017059

Epoch: 6| Step: 8
Training loss: 1.584134817123413
Validation loss: 1.924992597231301

Epoch: 6| Step: 9
Training loss: 1.4990414381027222
Validation loss: 1.9158044976572837

Epoch: 6| Step: 10
Training loss: 2.1491334438323975
Validation loss: 1.9127935196763726

Epoch: 6| Step: 11
Training loss: 2.539236545562744
Validation loss: 1.925033910300142

Epoch: 6| Step: 12
Training loss: 1.2138094902038574
Validation loss: 1.9231882056882303

Epoch: 6| Step: 13
Training loss: 2.939239025115967
Validation loss: 1.9078060119382796

Epoch: 163| Step: 0
Training loss: 1.5349007844924927
Validation loss: 1.902688031555504

Epoch: 6| Step: 1
Training loss: 2.8200736045837402
Validation loss: 1.9257420814165505

Epoch: 6| Step: 2
Training loss: 1.822793960571289
Validation loss: 1.914206302294167

Epoch: 6| Step: 3
Training loss: 2.498363494873047
Validation loss: 1.9311059187817317

Epoch: 6| Step: 4
Training loss: 1.1201717853546143
Validation loss: 1.901929980965071

Epoch: 6| Step: 5
Training loss: 2.424424171447754
Validation loss: 1.9250873481073687

Epoch: 6| Step: 6
Training loss: 2.462954044342041
Validation loss: 1.924717587809409

Epoch: 6| Step: 7
Training loss: 1.789106011390686
Validation loss: 1.9381043500797723

Epoch: 6| Step: 8
Training loss: 1.6967973709106445
Validation loss: 1.953944642056701

Epoch: 6| Step: 9
Training loss: 1.4941751956939697
Validation loss: 1.9336739406790784

Epoch: 6| Step: 10
Training loss: 1.1636381149291992
Validation loss: 1.9377916397586945

Epoch: 6| Step: 11
Training loss: 1.289413332939148
Validation loss: 1.9281599842092043

Epoch: 6| Step: 12
Training loss: 1.475358247756958
Validation loss: 1.9215030657347811

Epoch: 6| Step: 13
Training loss: 2.4766714572906494
Validation loss: 1.9441808500597555

Epoch: 164| Step: 0
Training loss: 1.4086241722106934
Validation loss: 1.9152089267648675

Epoch: 6| Step: 1
Training loss: 1.7788952589035034
Validation loss: 1.9312642748637865

Epoch: 6| Step: 2
Training loss: 1.4987397193908691
Validation loss: 1.9153193837852889

Epoch: 6| Step: 3
Training loss: 1.981186032295227
Validation loss: 1.9430769694748746

Epoch: 6| Step: 4
Training loss: 2.1436333656311035
Validation loss: 1.9332575426306775

Epoch: 6| Step: 5
Training loss: 2.718021869659424
Validation loss: 1.9350984839982883

Epoch: 6| Step: 6
Training loss: 2.3153233528137207
Validation loss: 1.9166148862531107

Epoch: 6| Step: 7
Training loss: 1.8736650943756104
Validation loss: 1.9025212949322117

Epoch: 6| Step: 8
Training loss: 1.7876155376434326
Validation loss: 1.9204651976144442

Epoch: 6| Step: 9
Training loss: 1.2980625629425049
Validation loss: 1.935251393625813

Epoch: 6| Step: 10
Training loss: 2.351670503616333
Validation loss: 1.9261828199509652

Epoch: 6| Step: 11
Training loss: 1.3260111808776855
Validation loss: 1.9226540160435501

Epoch: 6| Step: 12
Training loss: 1.7047514915466309
Validation loss: 1.887591000526182

Epoch: 6| Step: 13
Training loss: 1.0926343202590942
Validation loss: 1.9129562160020233

Epoch: 165| Step: 0
Training loss: 1.5978944301605225
Validation loss: 1.895692120316208

Epoch: 6| Step: 1
Training loss: 1.4694700241088867
Validation loss: 1.91622293508181

Epoch: 6| Step: 2
Training loss: 1.8380906581878662
Validation loss: 1.9157061987025763

Epoch: 6| Step: 3
Training loss: 2.185713529586792
Validation loss: 1.8990409002509168

Epoch: 6| Step: 4
Training loss: 1.8347535133361816
Validation loss: 1.8910170870442544

Epoch: 6| Step: 5
Training loss: 1.6999441385269165
Validation loss: 1.917646905427338

Epoch: 6| Step: 6
Training loss: 2.1917991638183594
Validation loss: 1.9058880293241112

Epoch: 6| Step: 7
Training loss: 1.5671145915985107
Validation loss: 1.9158409128906906

Epoch: 6| Step: 8
Training loss: 2.0976967811584473
Validation loss: 1.9082183184162262

Epoch: 6| Step: 9
Training loss: 1.6684627532958984
Validation loss: 1.9027210589378112

Epoch: 6| Step: 10
Training loss: 1.8723112344741821
Validation loss: 1.9247279577357794

Epoch: 6| Step: 11
Training loss: 2.2088699340820312
Validation loss: 1.9289876273883286

Epoch: 6| Step: 12
Training loss: 2.079224109649658
Validation loss: 1.9441462614203011

Epoch: 6| Step: 13
Training loss: 1.7684094905853271
Validation loss: 1.930972518459443

Epoch: 166| Step: 0
Training loss: 2.2833950519561768
Validation loss: 1.9540560809514855

Epoch: 6| Step: 1
Training loss: 2.2610535621643066
Validation loss: 1.933053808827554

Epoch: 6| Step: 2
Training loss: 1.3592183589935303
Validation loss: 1.9558267247292302

Epoch: 6| Step: 3
Training loss: 1.7009135484695435
Validation loss: 1.9743952648614043

Epoch: 6| Step: 4
Training loss: 2.105160713195801
Validation loss: 1.9479023718064832

Epoch: 6| Step: 5
Training loss: 2.206226110458374
Validation loss: 1.9568293632999543

Epoch: 6| Step: 6
Training loss: 1.5025370121002197
Validation loss: 1.9374449368446105

Epoch: 6| Step: 7
Training loss: 1.4158227443695068
Validation loss: 1.9149701582488192

Epoch: 6| Step: 8
Training loss: 2.030665636062622
Validation loss: 1.9130424735366658

Epoch: 6| Step: 9
Training loss: 1.570894479751587
Validation loss: 1.9023613314474783

Epoch: 6| Step: 10
Training loss: 1.8935935497283936
Validation loss: 1.9312939848951114

Epoch: 6| Step: 11
Training loss: 2.205047130584717
Validation loss: 1.890283533321914

Epoch: 6| Step: 12
Training loss: 1.8490068912506104
Validation loss: 1.8951127657326319

Epoch: 6| Step: 13
Training loss: 1.161567211151123
Validation loss: 1.92355715843939

Epoch: 167| Step: 0
Training loss: 1.7431999444961548
Validation loss: 1.9198224461206825

Epoch: 6| Step: 1
Training loss: 1.4327129125595093
Validation loss: 1.9020606471646218

Epoch: 6| Step: 2
Training loss: 1.6329176425933838
Validation loss: 1.9043626234095583

Epoch: 6| Step: 3
Training loss: 1.6487833261489868
Validation loss: 1.928307843464677

Epoch: 6| Step: 4
Training loss: 2.340580940246582
Validation loss: 1.9065081483574324

Epoch: 6| Step: 5
Training loss: 2.141366481781006
Validation loss: 1.8934583535758398

Epoch: 6| Step: 6
Training loss: 1.3851096630096436
Validation loss: 1.9108418469787927

Epoch: 6| Step: 7
Training loss: 1.2603685855865479
Validation loss: 1.9154009844667168

Epoch: 6| Step: 8
Training loss: 1.6144754886627197
Validation loss: 1.9235848406309723

Epoch: 6| Step: 9
Training loss: 2.2987632751464844
Validation loss: 1.9066280959754862

Epoch: 6| Step: 10
Training loss: 1.8337128162384033
Validation loss: 1.910438205606194

Epoch: 6| Step: 11
Training loss: 2.113790988922119
Validation loss: 1.9191111556945308

Epoch: 6| Step: 12
Training loss: 2.242077350616455
Validation loss: 1.9150703043066046

Epoch: 6| Step: 13
Training loss: 2.018303871154785
Validation loss: 1.9182877848225255

Epoch: 168| Step: 0
Training loss: 1.7995624542236328
Validation loss: 1.9103086135720695

Epoch: 6| Step: 1
Training loss: 1.7012872695922852
Validation loss: 1.9266712973194737

Epoch: 6| Step: 2
Training loss: 1.9299674034118652
Validation loss: 1.9105056639640563

Epoch: 6| Step: 3
Training loss: 1.802626371383667
Validation loss: 1.9227214859377952

Epoch: 6| Step: 4
Training loss: 2.8063578605651855
Validation loss: 1.913209084541567

Epoch: 6| Step: 5
Training loss: 1.7904201745986938
Validation loss: 1.9016984162792083

Epoch: 6| Step: 6
Training loss: 2.150646924972534
Validation loss: 1.8938568625398862

Epoch: 6| Step: 7
Training loss: 2.089580535888672
Validation loss: 1.9177765551433767

Epoch: 6| Step: 8
Training loss: 1.6782299280166626
Validation loss: 1.9204254111936014

Epoch: 6| Step: 9
Training loss: 1.8058440685272217
Validation loss: 1.9110910918122979

Epoch: 6| Step: 10
Training loss: 1.3647773265838623
Validation loss: 1.9124250758078791

Epoch: 6| Step: 11
Training loss: 1.5071046352386475
Validation loss: 1.9224001130750101

Epoch: 6| Step: 12
Training loss: 1.6298696994781494
Validation loss: 1.8998476843680105

Epoch: 6| Step: 13
Training loss: 1.1669477224349976
Validation loss: 1.914563068779566

Epoch: 169| Step: 0
Training loss: 1.4581069946289062
Validation loss: 1.9208695747519051

Epoch: 6| Step: 1
Training loss: 2.542294502258301
Validation loss: 1.926689701695596

Epoch: 6| Step: 2
Training loss: 2.099681854248047
Validation loss: 1.897974443692033

Epoch: 6| Step: 3
Training loss: 1.1542236804962158
Validation loss: 1.905842810548762

Epoch: 6| Step: 4
Training loss: 2.0154972076416016
Validation loss: 1.9006386982497347

Epoch: 6| Step: 5
Training loss: 1.5995855331420898
Validation loss: 1.880162710784584

Epoch: 6| Step: 6
Training loss: 1.7038543224334717
Validation loss: 1.9133679020789363

Epoch: 6| Step: 7
Training loss: 2.1170101165771484
Validation loss: 1.9089829421812488

Epoch: 6| Step: 8
Training loss: 1.7504111528396606
Validation loss: 1.909423662770179

Epoch: 6| Step: 9
Training loss: 2.209963083267212
Validation loss: 1.9052106923954462

Epoch: 6| Step: 10
Training loss: 1.7689945697784424
Validation loss: 1.9134591382036927

Epoch: 6| Step: 11
Training loss: 1.2697210311889648
Validation loss: 1.9290559343112412

Epoch: 6| Step: 12
Training loss: 2.1766252517700195
Validation loss: 1.9365360403573642

Epoch: 6| Step: 13
Training loss: 1.9382531642913818
Validation loss: 1.9122944442174767

Epoch: 170| Step: 0
Training loss: 1.801300048828125
Validation loss: 1.9327099964182863

Epoch: 6| Step: 1
Training loss: 1.2834742069244385
Validation loss: 1.920674027935151

Epoch: 6| Step: 2
Training loss: 1.473571538925171
Validation loss: 1.910186763732664

Epoch: 6| Step: 3
Training loss: 2.437711477279663
Validation loss: 1.907071659641881

Epoch: 6| Step: 4
Training loss: 2.4420604705810547
Validation loss: 1.9117885571654125

Epoch: 6| Step: 5
Training loss: 1.766626238822937
Validation loss: 1.9106543192299463

Epoch: 6| Step: 6
Training loss: 1.803243637084961
Validation loss: 1.916935569496565

Epoch: 6| Step: 7
Training loss: 1.8269425630569458
Validation loss: 1.9120877007002473

Epoch: 6| Step: 8
Training loss: 1.6248244047164917
Validation loss: 1.9076299551994569

Epoch: 6| Step: 9
Training loss: 1.7345316410064697
Validation loss: 1.9000256253827004

Epoch: 6| Step: 10
Training loss: 1.7756770849227905
Validation loss: 1.8806535723388835

Epoch: 6| Step: 11
Training loss: 1.7082273960113525
Validation loss: 1.9000230245692755

Epoch: 6| Step: 12
Training loss: 2.264573574066162
Validation loss: 1.8693359692891438

Epoch: 6| Step: 13
Training loss: 1.5343742370605469
Validation loss: 1.8962477189238354

Epoch: 171| Step: 0
Training loss: 1.8599485158920288
Validation loss: 1.8974834975375925

Epoch: 6| Step: 1
Training loss: 1.4652677774429321
Validation loss: 1.9514661565903695

Epoch: 6| Step: 2
Training loss: 2.140399932861328
Validation loss: 1.9111434836541452

Epoch: 6| Step: 3
Training loss: 2.0986199378967285
Validation loss: 1.8982833534158685

Epoch: 6| Step: 4
Training loss: 2.283310651779175
Validation loss: 1.8863801494721444

Epoch: 6| Step: 5
Training loss: 2.067993402481079
Validation loss: 1.9255095399836057

Epoch: 6| Step: 6
Training loss: 2.2484679222106934
Validation loss: 1.9201689215116604

Epoch: 6| Step: 7
Training loss: 1.950677514076233
Validation loss: 1.925283601207118

Epoch: 6| Step: 8
Training loss: 1.68196439743042
Validation loss: 1.94773389703484

Epoch: 6| Step: 9
Training loss: 1.3967690467834473
Validation loss: 1.9284153881893362

Epoch: 6| Step: 10
Training loss: 1.569434404373169
Validation loss: 1.9342995087305705

Epoch: 6| Step: 11
Training loss: 1.624036431312561
Validation loss: 1.929625395805605

Epoch: 6| Step: 12
Training loss: 1.2830870151519775
Validation loss: 1.8923431993812643

Epoch: 6| Step: 13
Training loss: 1.5322734117507935
Validation loss: 1.9153972902605612

Epoch: 172| Step: 0
Training loss: 2.293483257293701
Validation loss: 1.913181774077877

Epoch: 6| Step: 1
Training loss: 1.9374923706054688
Validation loss: 1.9013961412573372

Epoch: 6| Step: 2
Training loss: 1.986852765083313
Validation loss: 1.9179806094015799

Epoch: 6| Step: 3
Training loss: 1.9300158023834229
Validation loss: 1.9342761514007405

Epoch: 6| Step: 4
Training loss: 1.7860287427902222
Validation loss: 1.916134967598864

Epoch: 6| Step: 5
Training loss: 1.5329101085662842
Validation loss: 1.8956730929754113

Epoch: 6| Step: 6
Training loss: 1.7102057933807373
Validation loss: 1.906311429956908

Epoch: 6| Step: 7
Training loss: 1.9134485721588135
Validation loss: 1.923016148228799

Epoch: 6| Step: 8
Training loss: 2.105020046234131
Validation loss: 1.9122433162504626

Epoch: 6| Step: 9
Training loss: 1.2188886404037476
Validation loss: 1.9248120079758346

Epoch: 6| Step: 10
Training loss: 1.5578398704528809
Validation loss: 1.9158346909348682

Epoch: 6| Step: 11
Training loss: 1.5703835487365723
Validation loss: 1.910649476512786

Epoch: 6| Step: 12
Training loss: 2.1603970527648926
Validation loss: 1.901388119625789

Epoch: 6| Step: 13
Training loss: 2.0397684574127197
Validation loss: 1.9092548790798392

Epoch: 173| Step: 0
Training loss: 1.6827679872512817
Validation loss: 1.9112209261104625

Epoch: 6| Step: 1
Training loss: 2.5328850746154785
Validation loss: 1.8898218600980696

Epoch: 6| Step: 2
Training loss: 2.3814642429351807
Validation loss: 1.9176005676228514

Epoch: 6| Step: 3
Training loss: 2.4823594093322754
Validation loss: 1.8835925978998984

Epoch: 6| Step: 4
Training loss: 1.0464482307434082
Validation loss: 1.9163012331531895

Epoch: 6| Step: 5
Training loss: 2.579204797744751
Validation loss: 1.903195709310552

Epoch: 6| Step: 6
Training loss: 1.2945692539215088
Validation loss: 1.9264205463470951

Epoch: 6| Step: 7
Training loss: 1.487174153327942
Validation loss: 1.88896648089091

Epoch: 6| Step: 8
Training loss: 1.1334285736083984
Validation loss: 1.9041685327406852

Epoch: 6| Step: 9
Training loss: 1.9040298461914062
Validation loss: 1.9120481450070617

Epoch: 6| Step: 10
Training loss: 1.7444132566452026
Validation loss: 1.909819435047847

Epoch: 6| Step: 11
Training loss: 2.0136475563049316
Validation loss: 1.9098518407473

Epoch: 6| Step: 12
Training loss: 1.7071199417114258
Validation loss: 1.915986240551036

Epoch: 6| Step: 13
Training loss: 1.2727007865905762
Validation loss: 1.910303941337011

Epoch: 174| Step: 0
Training loss: 1.541740894317627
Validation loss: 1.9035324076170563

Epoch: 6| Step: 1
Training loss: 1.9305559396743774
Validation loss: 1.9094132095254877

Epoch: 6| Step: 2
Training loss: 1.4011449813842773
Validation loss: 1.898044268290202

Epoch: 6| Step: 3
Training loss: 2.025794506072998
Validation loss: 1.8940061625613962

Epoch: 6| Step: 4
Training loss: 2.329282760620117
Validation loss: 1.9417780830014137

Epoch: 6| Step: 5
Training loss: 2.7709994316101074
Validation loss: 1.8912996015241068

Epoch: 6| Step: 6
Training loss: 1.666200876235962
Validation loss: 1.8942978048837313

Epoch: 6| Step: 7
Training loss: 1.605325698852539
Validation loss: 1.8993584827710224

Epoch: 6| Step: 8
Training loss: 2.0260870456695557
Validation loss: 1.9379151623736146

Epoch: 6| Step: 9
Training loss: 0.8760528564453125
Validation loss: 1.9027243750069731

Epoch: 6| Step: 10
Training loss: 2.324197769165039
Validation loss: 1.883672111777849

Epoch: 6| Step: 11
Training loss: 1.7660975456237793
Validation loss: 1.925927145506746

Epoch: 6| Step: 12
Training loss: 1.6979186534881592
Validation loss: 1.9042650935470418

Epoch: 6| Step: 13
Training loss: 1.1776556968688965
Validation loss: 1.911615797268447

Epoch: 175| Step: 0
Training loss: 1.3802311420440674
Validation loss: 1.906060213683754

Epoch: 6| Step: 1
Training loss: 1.9307042360305786
Validation loss: 1.8868564508294547

Epoch: 6| Step: 2
Training loss: 1.7038862705230713
Validation loss: 1.9071972241965673

Epoch: 6| Step: 3
Training loss: 2.48187518119812
Validation loss: 1.9086692166584793

Epoch: 6| Step: 4
Training loss: 1.1701985597610474
Validation loss: 1.889710105875487

Epoch: 6| Step: 5
Training loss: 2.041778802871704
Validation loss: 1.9165766867258216

Epoch: 6| Step: 6
Training loss: 1.6459250450134277
Validation loss: 1.888081382679683

Epoch: 6| Step: 7
Training loss: 2.672684669494629
Validation loss: 1.9510613743976881

Epoch: 6| Step: 8
Training loss: 1.555807113647461
Validation loss: 1.8983073157648886

Epoch: 6| Step: 9
Training loss: 1.0595322847366333
Validation loss: 1.9063298894513039

Epoch: 6| Step: 10
Training loss: 2.3231377601623535
Validation loss: 1.8921933520224787

Epoch: 6| Step: 11
Training loss: 1.454616665840149
Validation loss: 1.8985863065206876

Epoch: 6| Step: 12
Training loss: 1.8203418254852295
Validation loss: 1.8927219734396985

Epoch: 6| Step: 13
Training loss: 2.14136004447937
Validation loss: 1.890661253724047

Epoch: 176| Step: 0
Training loss: 1.9464232921600342
Validation loss: 1.8955442328606882

Epoch: 6| Step: 1
Training loss: 1.6698299646377563
Validation loss: 1.926922841738629

Epoch: 6| Step: 2
Training loss: 2.403773784637451
Validation loss: 1.9248380276464647

Epoch: 6| Step: 3
Training loss: 1.557060718536377
Validation loss: 1.9145757664916336

Epoch: 6| Step: 4
Training loss: 1.627518653869629
Validation loss: 1.927944863996198

Epoch: 6| Step: 5
Training loss: 2.0209097862243652
Validation loss: 1.9217890795841013

Epoch: 6| Step: 6
Training loss: 2.198531150817871
Validation loss: 1.9125444504522509

Epoch: 6| Step: 7
Training loss: 1.3900108337402344
Validation loss: 1.9144968909602011

Epoch: 6| Step: 8
Training loss: 1.278752326965332
Validation loss: 1.918159504090586

Epoch: 6| Step: 9
Training loss: 1.8119609355926514
Validation loss: 1.930832855163082

Epoch: 6| Step: 10
Training loss: 1.7240996360778809
Validation loss: 1.9184413853512015

Epoch: 6| Step: 11
Training loss: 1.8239084482192993
Validation loss: 1.9438938274178454

Epoch: 6| Step: 12
Training loss: 1.9421412944793701
Validation loss: 1.9548042769073157

Epoch: 6| Step: 13
Training loss: 2.0637762546539307
Validation loss: 1.9318886815860707

Epoch: 177| Step: 0
Training loss: 1.6815814971923828
Validation loss: 1.939813861282923

Epoch: 6| Step: 1
Training loss: 1.4906365871429443
Validation loss: 1.8900889324885544

Epoch: 6| Step: 2
Training loss: 1.2162073850631714
Validation loss: 1.905089024574526

Epoch: 6| Step: 3
Training loss: 1.4792587757110596
Validation loss: 1.892942907989666

Epoch: 6| Step: 4
Training loss: 1.5720367431640625
Validation loss: 1.8822695824407762

Epoch: 6| Step: 5
Training loss: 1.917925238609314
Validation loss: 1.8782801230748494

Epoch: 6| Step: 6
Training loss: 2.0452303886413574
Validation loss: 1.8872166372114612

Epoch: 6| Step: 7
Training loss: 2.510014772415161
Validation loss: 1.9046275987420032

Epoch: 6| Step: 8
Training loss: 1.5381619930267334
Validation loss: 1.9306007072489748

Epoch: 6| Step: 9
Training loss: 1.972228765487671
Validation loss: 1.8950326288900068

Epoch: 6| Step: 10
Training loss: 1.649519920349121
Validation loss: 1.9200882398954002

Epoch: 6| Step: 11
Training loss: 2.180138349533081
Validation loss: 1.8743503196265108

Epoch: 6| Step: 12
Training loss: 2.4699621200561523
Validation loss: 1.8928143247481315

Epoch: 6| Step: 13
Training loss: 1.5314818620681763
Validation loss: 1.8914012242388982

Epoch: 178| Step: 0
Training loss: 1.9446604251861572
Validation loss: 1.8653096281072146

Epoch: 6| Step: 1
Training loss: 1.8746808767318726
Validation loss: 1.8664164594424668

Epoch: 6| Step: 2
Training loss: 1.4542715549468994
Validation loss: 1.8819518986568655

Epoch: 6| Step: 3
Training loss: 1.6668484210968018
Validation loss: 1.8998433043879848

Epoch: 6| Step: 4
Training loss: 1.5016157627105713
Validation loss: 1.8977600066892562

Epoch: 6| Step: 5
Training loss: 1.6987862586975098
Validation loss: 1.9215065612587878

Epoch: 6| Step: 6
Training loss: 1.7933452129364014
Validation loss: 1.9323411654400569

Epoch: 6| Step: 7
Training loss: 2.1793572902679443
Validation loss: 1.901223510824224

Epoch: 6| Step: 8
Training loss: 1.545971155166626
Validation loss: 1.9262767658438733

Epoch: 6| Step: 9
Training loss: 2.381047248840332
Validation loss: 1.8918070908515685

Epoch: 6| Step: 10
Training loss: 2.1810169219970703
Validation loss: 1.9327571456150343

Epoch: 6| Step: 11
Training loss: 1.4724862575531006
Validation loss: 1.9340241942354428

Epoch: 6| Step: 12
Training loss: 1.7336621284484863
Validation loss: 1.9139739262160433

Epoch: 6| Step: 13
Training loss: 1.735095500946045
Validation loss: 1.9363692216975714

Epoch: 179| Step: 0
Training loss: 1.9612796306610107
Validation loss: 1.9092287683999667

Epoch: 6| Step: 1
Training loss: 2.0124473571777344
Validation loss: 1.926767106979124

Epoch: 6| Step: 2
Training loss: 2.2429935932159424
Validation loss: 1.9550843238830566

Epoch: 6| Step: 3
Training loss: 1.9933040142059326
Validation loss: 1.9308182283114361

Epoch: 6| Step: 4
Training loss: 1.6587424278259277
Validation loss: 1.929295789810919

Epoch: 6| Step: 5
Training loss: 1.1799311637878418
Validation loss: 1.9037416032565537

Epoch: 6| Step: 6
Training loss: 1.3479883670806885
Validation loss: 1.923630625970902

Epoch: 6| Step: 7
Training loss: 2.3233304023742676
Validation loss: 1.9152597253040602

Epoch: 6| Step: 8
Training loss: 1.3091425895690918
Validation loss: 1.900177571081346

Epoch: 6| Step: 9
Training loss: 1.3051478862762451
Validation loss: 1.9000266675026185

Epoch: 6| Step: 10
Training loss: 2.482586622238159
Validation loss: 1.914620021338104

Epoch: 6| Step: 11
Training loss: 1.5781188011169434
Validation loss: 1.9070043051114647

Epoch: 6| Step: 12
Training loss: 2.3201675415039062
Validation loss: 1.8892062876814155

Epoch: 6| Step: 13
Training loss: 1.2016702890396118
Validation loss: 1.8625818311527211

Epoch: 180| Step: 0
Training loss: 1.9922826290130615
Validation loss: 1.8878494642114128

Epoch: 6| Step: 1
Training loss: 1.5356338024139404
Validation loss: 1.889590504348919

Epoch: 6| Step: 2
Training loss: 1.811822533607483
Validation loss: 1.8917787408316007

Epoch: 6| Step: 3
Training loss: 1.9981460571289062
Validation loss: 1.888636912069013

Epoch: 6| Step: 4
Training loss: 1.6834962368011475
Validation loss: 1.8799036548983665

Epoch: 6| Step: 5
Training loss: 2.3302195072174072
Validation loss: 1.8921545628578431

Epoch: 6| Step: 6
Training loss: 1.5171260833740234
Validation loss: 1.898296812529205

Epoch: 6| Step: 7
Training loss: 1.627974510192871
Validation loss: 1.8936117054313741

Epoch: 6| Step: 8
Training loss: 1.511063814163208
Validation loss: 1.8982358799185803

Epoch: 6| Step: 9
Training loss: 1.478760004043579
Validation loss: 1.8863461620064192

Epoch: 6| Step: 10
Training loss: 2.2219929695129395
Validation loss: 1.8914551414469236

Epoch: 6| Step: 11
Training loss: 2.173840045928955
Validation loss: 1.869135195209134

Epoch: 6| Step: 12
Training loss: 1.5960451364517212
Validation loss: 1.8811152058262979

Epoch: 6| Step: 13
Training loss: 1.8967721462249756
Validation loss: 1.9275772610018331

Epoch: 181| Step: 0
Training loss: 1.888962984085083
Validation loss: 1.9141018672655987

Epoch: 6| Step: 1
Training loss: 1.3616671562194824
Validation loss: 1.924538904620755

Epoch: 6| Step: 2
Training loss: 1.6915202140808105
Validation loss: 1.891278564289052

Epoch: 6| Step: 3
Training loss: 2.2102270126342773
Validation loss: 1.9214473808965375

Epoch: 6| Step: 4
Training loss: 1.2897902727127075
Validation loss: 1.9080775194270636

Epoch: 6| Step: 5
Training loss: 1.6526308059692383
Validation loss: 1.9210238661817325

Epoch: 6| Step: 6
Training loss: 2.1097769737243652
Validation loss: 1.926217322708458

Epoch: 6| Step: 7
Training loss: 1.7215014696121216
Validation loss: 1.904533532357985

Epoch: 6| Step: 8
Training loss: 1.7500368356704712
Validation loss: 1.9139773563672138

Epoch: 6| Step: 9
Training loss: 2.6830105781555176
Validation loss: 1.940702372981656

Epoch: 6| Step: 10
Training loss: 1.1259338855743408
Validation loss: 1.9406512744965092

Epoch: 6| Step: 11
Training loss: 1.876523494720459
Validation loss: 1.8889478598871539

Epoch: 6| Step: 12
Training loss: 1.9925286769866943
Validation loss: 1.8936470452175345

Epoch: 6| Step: 13
Training loss: 1.4460539817810059
Validation loss: 1.924315401302871

Epoch: 182| Step: 0
Training loss: 1.8350647687911987
Validation loss: 1.8954851217167352

Epoch: 6| Step: 1
Training loss: 2.0286970138549805
Validation loss: 1.9002223476286857

Epoch: 6| Step: 2
Training loss: 1.6815650463104248
Validation loss: 1.8981352698418401

Epoch: 6| Step: 3
Training loss: 1.2244302034378052
Validation loss: 1.87038541096513

Epoch: 6| Step: 4
Training loss: 1.6510052680969238
Validation loss: 1.8885786892265402

Epoch: 6| Step: 5
Training loss: 2.441884756088257
Validation loss: 1.8928274057244743

Epoch: 6| Step: 6
Training loss: 2.0711913108825684
Validation loss: 1.915352484231354

Epoch: 6| Step: 7
Training loss: 1.9073305130004883
Validation loss: 1.9001743819123955

Epoch: 6| Step: 8
Training loss: 2.038729667663574
Validation loss: 1.9319551337149836

Epoch: 6| Step: 9
Training loss: 1.796602487564087
Validation loss: 1.911425971215771

Epoch: 6| Step: 10
Training loss: 1.4948863983154297
Validation loss: 1.8910577707393195

Epoch: 6| Step: 11
Training loss: 1.569859266281128
Validation loss: 1.9079969429200696

Epoch: 6| Step: 12
Training loss: 1.6021925210952759
Validation loss: 1.9043921680860623

Epoch: 6| Step: 13
Training loss: 1.6281702518463135
Validation loss: 1.8961718223428214

Epoch: 183| Step: 0
Training loss: 1.4096544981002808
Validation loss: 1.8936184452426048

Epoch: 6| Step: 1
Training loss: 2.5220794677734375
Validation loss: 1.883339935733426

Epoch: 6| Step: 2
Training loss: 2.0072948932647705
Validation loss: 1.8893043905176141

Epoch: 6| Step: 3
Training loss: 1.7668266296386719
Validation loss: 1.8897478093383133

Epoch: 6| Step: 4
Training loss: 1.5043072700500488
Validation loss: 1.8496332476215978

Epoch: 6| Step: 5
Training loss: 1.2046315670013428
Validation loss: 1.8848207253281788

Epoch: 6| Step: 6
Training loss: 1.7807862758636475
Validation loss: 1.9210818275328605

Epoch: 6| Step: 7
Training loss: 1.861187219619751
Validation loss: 1.9067227430241083

Epoch: 6| Step: 8
Training loss: 1.3486342430114746
Validation loss: 1.8603997717621505

Epoch: 6| Step: 9
Training loss: 1.70839524269104
Validation loss: 1.8962582247231596

Epoch: 6| Step: 10
Training loss: 1.8102748394012451
Validation loss: 1.9181930134373326

Epoch: 6| Step: 11
Training loss: 1.8393957614898682
Validation loss: 1.9118961967447752

Epoch: 6| Step: 12
Training loss: 2.2323498725891113
Validation loss: 1.8985921644395398

Epoch: 6| Step: 13
Training loss: 1.7951905727386475
Validation loss: 1.9059077219296527

Epoch: 184| Step: 0
Training loss: 1.4755563735961914
Validation loss: 1.8792281048272246

Epoch: 6| Step: 1
Training loss: 2.161268711090088
Validation loss: 1.8963123418951546

Epoch: 6| Step: 2
Training loss: 2.1547815799713135
Validation loss: 1.8994059716501543

Epoch: 6| Step: 3
Training loss: 2.839611530303955
Validation loss: 1.892990691687471

Epoch: 6| Step: 4
Training loss: 1.631523609161377
Validation loss: 1.8973492396775113

Epoch: 6| Step: 5
Training loss: 1.2860753536224365
Validation loss: 1.8819763480976064

Epoch: 6| Step: 6
Training loss: 1.9195327758789062
Validation loss: 1.9012955273351362

Epoch: 6| Step: 7
Training loss: 1.1553711891174316
Validation loss: 1.8721959129456551

Epoch: 6| Step: 8
Training loss: 1.7074816226959229
Validation loss: 1.8962378142982401

Epoch: 6| Step: 9
Training loss: 1.645538568496704
Validation loss: 1.8828995394450363

Epoch: 6| Step: 10
Training loss: 1.0926828384399414
Validation loss: 1.8998113934711744

Epoch: 6| Step: 11
Training loss: 1.9892743825912476
Validation loss: 1.8787536005819998

Epoch: 6| Step: 12
Training loss: 1.3879883289337158
Validation loss: 1.88096651979672

Epoch: 6| Step: 13
Training loss: 2.7756595611572266
Validation loss: 1.8851602987576557

Epoch: 185| Step: 0
Training loss: 1.5412628650665283
Validation loss: 1.8766401506239367

Epoch: 6| Step: 1
Training loss: 1.412116527557373
Validation loss: 1.8930585230550458

Epoch: 6| Step: 2
Training loss: 2.0280704498291016
Validation loss: 1.8650259997255059

Epoch: 6| Step: 3
Training loss: 1.3713419437408447
Validation loss: 1.8997157363481418

Epoch: 6| Step: 4
Training loss: 1.2353911399841309
Validation loss: 1.9084018315038374

Epoch: 6| Step: 5
Training loss: 1.9784480333328247
Validation loss: 1.9048719380491523

Epoch: 6| Step: 6
Training loss: 1.891237497329712
Validation loss: 1.902352133104878

Epoch: 6| Step: 7
Training loss: 1.7497504949569702
Validation loss: 1.9092990544534498

Epoch: 6| Step: 8
Training loss: 1.6231833696365356
Validation loss: 1.9149152450664069

Epoch: 6| Step: 9
Training loss: 1.6282639503479004
Validation loss: 1.9272303619692404

Epoch: 6| Step: 10
Training loss: 2.1110999584198
Validation loss: 1.9319323814043434

Epoch: 6| Step: 11
Training loss: 2.242905855178833
Validation loss: 1.897358609784034

Epoch: 6| Step: 12
Training loss: 2.1540589332580566
Validation loss: 1.942818214816432

Epoch: 6| Step: 13
Training loss: 2.079136848449707
Validation loss: 1.8953333375274495

Epoch: 186| Step: 0
Training loss: 2.1529626846313477
Validation loss: 1.9300574692346717

Epoch: 6| Step: 1
Training loss: 1.521347999572754
Validation loss: 1.9015320321565032

Epoch: 6| Step: 2
Training loss: 1.6141055822372437
Validation loss: 1.8865067292285222

Epoch: 6| Step: 3
Training loss: 1.5859217643737793
Validation loss: 1.8877041455238097

Epoch: 6| Step: 4
Training loss: 1.63066565990448
Validation loss: 1.8901052756976056

Epoch: 6| Step: 5
Training loss: 1.9087121486663818
Validation loss: 1.8990747761982743

Epoch: 6| Step: 6
Training loss: 1.542417049407959
Validation loss: 1.8714240827868063

Epoch: 6| Step: 7
Training loss: 2.267598867416382
Validation loss: 1.8901677529017131

Epoch: 6| Step: 8
Training loss: 1.6373778581619263
Validation loss: 1.9033218314570766

Epoch: 6| Step: 9
Training loss: 1.9880106449127197
Validation loss: 1.9025177571081346

Epoch: 6| Step: 10
Training loss: 2.123264789581299
Validation loss: 1.885904085892503

Epoch: 6| Step: 11
Training loss: 1.5362346172332764
Validation loss: 1.8774385131815428

Epoch: 6| Step: 12
Training loss: 2.1120877265930176
Validation loss: 1.8813965077041297

Epoch: 6| Step: 13
Training loss: 1.319778323173523
Validation loss: 1.8992631332848662

Epoch: 187| Step: 0
Training loss: 1.5068943500518799
Validation loss: 1.8515754681761547

Epoch: 6| Step: 1
Training loss: 1.5152696371078491
Validation loss: 1.8762588962431876

Epoch: 6| Step: 2
Training loss: 2.4157376289367676
Validation loss: 1.9011405873042282

Epoch: 6| Step: 3
Training loss: 2.7297558784484863
Validation loss: 1.9387581912420129

Epoch: 6| Step: 4
Training loss: 1.3247469663619995
Validation loss: 1.9237852737467775

Epoch: 6| Step: 5
Training loss: 2.0683302879333496
Validation loss: 1.9044653215715963

Epoch: 6| Step: 6
Training loss: 1.337737798690796
Validation loss: 1.9217054036355787

Epoch: 6| Step: 7
Training loss: 1.0342226028442383
Validation loss: 1.9104271550332346

Epoch: 6| Step: 8
Training loss: 1.8399066925048828
Validation loss: 1.9126533513428063

Epoch: 6| Step: 9
Training loss: 2.117617130279541
Validation loss: 1.949126338446012

Epoch: 6| Step: 10
Training loss: 2.133270502090454
Validation loss: 1.9279869064208

Epoch: 6| Step: 11
Training loss: 1.59381902217865
Validation loss: 1.9031997444809123

Epoch: 6| Step: 12
Training loss: 1.493844747543335
Validation loss: 1.9303714011305122

Epoch: 6| Step: 13
Training loss: 2.2632157802581787
Validation loss: 1.8944994070196663

Epoch: 188| Step: 0
Training loss: 1.932300329208374
Validation loss: 1.8833306630452473

Epoch: 6| Step: 1
Training loss: 1.6755614280700684
Validation loss: 1.884167222566502

Epoch: 6| Step: 2
Training loss: 2.1576790809631348
Validation loss: 1.903365103147363

Epoch: 6| Step: 3
Training loss: 0.8809245228767395
Validation loss: 1.906426445130379

Epoch: 6| Step: 4
Training loss: 1.603397011756897
Validation loss: 1.8936919114922965

Epoch: 6| Step: 5
Training loss: 2.459108591079712
Validation loss: 1.8959181988111107

Epoch: 6| Step: 6
Training loss: 2.1834897994995117
Validation loss: 1.846228463675386

Epoch: 6| Step: 7
Training loss: 1.7206826210021973
Validation loss: 1.8690790232791696

Epoch: 6| Step: 8
Training loss: 1.542433738708496
Validation loss: 1.8793624626692904

Epoch: 6| Step: 9
Training loss: 1.7626155614852905
Validation loss: 1.8670918505678895

Epoch: 6| Step: 10
Training loss: 1.178540587425232
Validation loss: 1.8823174763751287

Epoch: 6| Step: 11
Training loss: 1.8656895160675049
Validation loss: 1.8838779272571686

Epoch: 6| Step: 12
Training loss: 1.8547639846801758
Validation loss: 1.8695781615472609

Epoch: 6| Step: 13
Training loss: 2.316403388977051
Validation loss: 1.8908320806359733

Epoch: 189| Step: 0
Training loss: 2.1408562660217285
Validation loss: 1.9073545599496493

Epoch: 6| Step: 1
Training loss: 2.2267065048217773
Validation loss: 1.8957652174016482

Epoch: 6| Step: 2
Training loss: 1.6404269933700562
Validation loss: 1.8888239347806541

Epoch: 6| Step: 3
Training loss: 1.4427897930145264
Validation loss: 1.8706006824329335

Epoch: 6| Step: 4
Training loss: 1.3536094427108765
Validation loss: 1.9263172354749454

Epoch: 6| Step: 5
Training loss: 1.4853664636611938
Validation loss: 1.9174435446339269

Epoch: 6| Step: 6
Training loss: 1.6791915893554688
Validation loss: 1.9033146506996566

Epoch: 6| Step: 7
Training loss: 1.0431382656097412
Validation loss: 1.898325122812743

Epoch: 6| Step: 8
Training loss: 1.8442766666412354
Validation loss: 1.882311039073493

Epoch: 6| Step: 9
Training loss: 1.6774468421936035
Validation loss: 1.8839622876977409

Epoch: 6| Step: 10
Training loss: 1.948251485824585
Validation loss: 1.8872621751600696

Epoch: 6| Step: 11
Training loss: 2.2645206451416016
Validation loss: 1.928946892420451

Epoch: 6| Step: 12
Training loss: 2.1278762817382812
Validation loss: 1.9198571430739535

Epoch: 6| Step: 13
Training loss: 1.9296461343765259
Validation loss: 1.9067507700253559

Epoch: 190| Step: 0
Training loss: 1.7913153171539307
Validation loss: 1.8584278962945426

Epoch: 6| Step: 1
Training loss: 2.1082024574279785
Validation loss: 1.9285861176829184

Epoch: 6| Step: 2
Training loss: 1.726568341255188
Validation loss: 1.8989767669349589

Epoch: 6| Step: 3
Training loss: 1.3812544345855713
Validation loss: 1.8895840080835486

Epoch: 6| Step: 4
Training loss: 2.2025985717773438
Validation loss: 1.9014078763223463

Epoch: 6| Step: 5
Training loss: 1.8360767364501953
Validation loss: 1.8817850569243073

Epoch: 6| Step: 6
Training loss: 1.8097074031829834
Validation loss: 1.893933920450108

Epoch: 6| Step: 7
Training loss: 1.661575198173523
Validation loss: 1.9092981097518757

Epoch: 6| Step: 8
Training loss: 2.1365842819213867
Validation loss: 1.8958070239713114

Epoch: 6| Step: 9
Training loss: 1.8095884323120117
Validation loss: 1.9099817775910901

Epoch: 6| Step: 10
Training loss: 1.4783529043197632
Validation loss: 1.8766262723553566

Epoch: 6| Step: 11
Training loss: 1.1173032522201538
Validation loss: 1.891146566278191

Epoch: 6| Step: 12
Training loss: 1.5658128261566162
Validation loss: 1.8800885908065303

Epoch: 6| Step: 13
Training loss: 1.9908894300460815
Validation loss: 1.8908792593145882

Epoch: 191| Step: 0
Training loss: 1.2786670923233032
Validation loss: 1.8775316951095418

Epoch: 6| Step: 1
Training loss: 1.3446776866912842
Validation loss: 1.8990798714340373

Epoch: 6| Step: 2
Training loss: 1.5735609531402588
Validation loss: 1.9114714860916138

Epoch: 6| Step: 3
Training loss: 2.104208469390869
Validation loss: 1.8827767551586192

Epoch: 6| Step: 4
Training loss: 1.5997722148895264
Validation loss: 1.8818005874592771

Epoch: 6| Step: 5
Training loss: 1.9717543125152588
Validation loss: 1.8919008598532727

Epoch: 6| Step: 6
Training loss: 1.2027931213378906
Validation loss: 1.9202081054769538

Epoch: 6| Step: 7
Training loss: 1.54012131690979
Validation loss: 1.9119734251370994

Epoch: 6| Step: 8
Training loss: 2.168644905090332
Validation loss: 1.908720354880056

Epoch: 6| Step: 9
Training loss: 2.120070457458496
Validation loss: 1.9048050013921594

Epoch: 6| Step: 10
Training loss: 2.0358593463897705
Validation loss: 1.8961873900505803

Epoch: 6| Step: 11
Training loss: 1.9763414859771729
Validation loss: 1.8932660651463333

Epoch: 6| Step: 12
Training loss: 2.2032880783081055
Validation loss: 1.8823317596989293

Epoch: 6| Step: 13
Training loss: 1.25385582447052
Validation loss: 1.8957961451622747

Epoch: 192| Step: 0
Training loss: 1.384042501449585
Validation loss: 1.8790567587780695

Epoch: 6| Step: 1
Training loss: 1.781386137008667
Validation loss: 1.8910433938426356

Epoch: 6| Step: 2
Training loss: 2.128844976425171
Validation loss: 1.8987416272522302

Epoch: 6| Step: 3
Training loss: 1.0983612537384033
Validation loss: 1.876874889096906

Epoch: 6| Step: 4
Training loss: 1.8513386249542236
Validation loss: 1.8808581829071045

Epoch: 6| Step: 5
Training loss: 1.3904144763946533
Validation loss: 1.8854622738335722

Epoch: 6| Step: 6
Training loss: 1.6254132986068726
Validation loss: 1.9036207904097855

Epoch: 6| Step: 7
Training loss: 2.8447470664978027
Validation loss: 1.8928983262790147

Epoch: 6| Step: 8
Training loss: 1.2277841567993164
Validation loss: 1.8619614160189064

Epoch: 6| Step: 9
Training loss: 1.8653473854064941
Validation loss: 1.8758602885789768

Epoch: 6| Step: 10
Training loss: 2.46305513381958
Validation loss: 1.8707381499710904

Epoch: 6| Step: 11
Training loss: 2.036243438720703
Validation loss: 1.8718934853871663

Epoch: 6| Step: 12
Training loss: 1.2239859104156494
Validation loss: 1.8926239372581564

Epoch: 6| Step: 13
Training loss: 1.5191664695739746
Validation loss: 1.8692043250606907

Epoch: 193| Step: 0
Training loss: 1.4732353687286377
Validation loss: 1.877947122819962

Epoch: 6| Step: 1
Training loss: 1.9658414125442505
Validation loss: 1.9117570884766117

Epoch: 6| Step: 2
Training loss: 2.2558751106262207
Validation loss: 1.9048687642620457

Epoch: 6| Step: 3
Training loss: 2.056684732437134
Validation loss: 1.9038349915576238

Epoch: 6| Step: 4
Training loss: 1.3052823543548584
Validation loss: 1.8796243257420038

Epoch: 6| Step: 5
Training loss: 1.6419962644577026
Validation loss: 1.9450645728777813

Epoch: 6| Step: 6
Training loss: 1.8322982788085938
Validation loss: 1.8807130295743224

Epoch: 6| Step: 7
Training loss: 1.7667032480239868
Validation loss: 1.8861201424752512

Epoch: 6| Step: 8
Training loss: 1.622347354888916
Validation loss: 1.8990502088300643

Epoch: 6| Step: 9
Training loss: 1.885631799697876
Validation loss: 1.8787099546001804

Epoch: 6| Step: 10
Training loss: 1.666499137878418
Validation loss: 1.8916730598736835

Epoch: 6| Step: 11
Training loss: 1.3931565284729004
Validation loss: 1.9078115429929507

Epoch: 6| Step: 12
Training loss: 1.882394552230835
Validation loss: 1.9117163253086868

Epoch: 6| Step: 13
Training loss: 2.030951499938965
Validation loss: 1.8549148882589033

Epoch: 194| Step: 0
Training loss: 1.9471018314361572
Validation loss: 1.863845145830544

Epoch: 6| Step: 1
Training loss: 1.5138554573059082
Validation loss: 1.925331275950196

Epoch: 6| Step: 2
Training loss: 1.2735412120819092
Validation loss: 1.902904692516532

Epoch: 6| Step: 3
Training loss: 1.4414830207824707
Validation loss: 1.8779890460352744

Epoch: 6| Step: 4
Training loss: 1.9335585832595825
Validation loss: 1.902224640692434

Epoch: 6| Step: 5
Training loss: 2.2407281398773193
Validation loss: 1.8640443714716102

Epoch: 6| Step: 6
Training loss: 1.2337090969085693
Validation loss: 1.8942462116159418

Epoch: 6| Step: 7
Training loss: 1.582726001739502
Validation loss: 1.8930593075290802

Epoch: 6| Step: 8
Training loss: 1.8327522277832031
Validation loss: 1.8774902846223565

Epoch: 6| Step: 9
Training loss: 1.7899096012115479
Validation loss: 1.8676580370113414

Epoch: 6| Step: 10
Training loss: 2.2320194244384766
Validation loss: 1.8567894043460969

Epoch: 6| Step: 11
Training loss: 1.8308550119400024
Validation loss: 1.9218379541109967

Epoch: 6| Step: 12
Training loss: 1.5721933841705322
Validation loss: 1.881428603203066

Epoch: 6| Step: 13
Training loss: 1.4696663618087769
Validation loss: 1.845991955008558

Epoch: 195| Step: 0
Training loss: 1.3815712928771973
Validation loss: 1.853539110511862

Epoch: 6| Step: 1
Training loss: 1.6794123649597168
Validation loss: 1.8891137979363883

Epoch: 6| Step: 2
Training loss: 1.4764617681503296
Validation loss: 1.8727347312435028

Epoch: 6| Step: 3
Training loss: 1.7575349807739258
Validation loss: 1.8963063070850987

Epoch: 6| Step: 4
Training loss: 1.3017654418945312
Validation loss: 1.9100091636821788

Epoch: 6| Step: 5
Training loss: 2.510009288787842
Validation loss: 1.8808494524289203

Epoch: 6| Step: 6
Training loss: 1.1991400718688965
Validation loss: 1.918999175871572

Epoch: 6| Step: 7
Training loss: 1.4838314056396484
Validation loss: 1.8842617029784827

Epoch: 6| Step: 8
Training loss: 1.5074259042739868
Validation loss: 1.9263487528729182

Epoch: 6| Step: 9
Training loss: 1.5217663049697876
Validation loss: 1.8925496032161098

Epoch: 6| Step: 10
Training loss: 1.461997151374817
Validation loss: 1.8922199792759393

Epoch: 6| Step: 11
Training loss: 2.735753059387207
Validation loss: 1.881357148770363

Epoch: 6| Step: 12
Training loss: 2.3191819190979004
Validation loss: 1.9163148864623039

Epoch: 6| Step: 13
Training loss: 2.228776216506958
Validation loss: 1.8687922916104716

Epoch: 196| Step: 0
Training loss: 1.77195405960083
Validation loss: 1.8774663197096957

Epoch: 6| Step: 1
Training loss: 1.801880121231079
Validation loss: 1.8719254924405007

Epoch: 6| Step: 2
Training loss: 1.51724112033844
Validation loss: 1.9102010175745974

Epoch: 6| Step: 3
Training loss: 1.3658775091171265
Validation loss: 1.8701580673135736

Epoch: 6| Step: 4
Training loss: 1.9787722826004028
Validation loss: 1.8846825989343787

Epoch: 6| Step: 5
Training loss: 1.1279360055923462
Validation loss: 1.8637634477307718

Epoch: 6| Step: 6
Training loss: 1.6496355533599854
Validation loss: 1.86322356295842

Epoch: 6| Step: 7
Training loss: 1.9580168724060059
Validation loss: 1.8695667251463859

Epoch: 6| Step: 8
Training loss: 2.0726423263549805
Validation loss: 1.8807649112516833

Epoch: 6| Step: 9
Training loss: 2.2150704860687256
Validation loss: 1.8664349432914489

Epoch: 6| Step: 10
Training loss: 0.9604761004447937
Validation loss: 1.8667100193679973

Epoch: 6| Step: 11
Training loss: 2.678528070449829
Validation loss: 1.857807336315032

Epoch: 6| Step: 12
Training loss: 1.2037761211395264
Validation loss: 1.897094775271672

Epoch: 6| Step: 13
Training loss: 2.6836743354797363
Validation loss: 1.844249431804944

Epoch: 197| Step: 0
Training loss: 1.981547474861145
Validation loss: 1.8819398316003944

Epoch: 6| Step: 1
Training loss: 1.8757526874542236
Validation loss: 1.8852450129806355

Epoch: 6| Step: 2
Training loss: 2.1903204917907715
Validation loss: 1.8695610902642692

Epoch: 6| Step: 3
Training loss: 2.1119699478149414
Validation loss: 1.8923475178339149

Epoch: 6| Step: 4
Training loss: 0.8930853605270386
Validation loss: 1.884601975000033

Epoch: 6| Step: 5
Training loss: 2.1080212593078613
Validation loss: 1.8694970505211943

Epoch: 6| Step: 6
Training loss: 1.7283084392547607
Validation loss: 1.8937850703475296

Epoch: 6| Step: 7
Training loss: 2.0030293464660645
Validation loss: 1.8897082241632606

Epoch: 6| Step: 8
Training loss: 1.7223994731903076
Validation loss: 1.9148681189424248

Epoch: 6| Step: 9
Training loss: 2.5261783599853516
Validation loss: 1.8954654124475294

Epoch: 6| Step: 10
Training loss: 1.2879302501678467
Validation loss: 1.906917469475859

Epoch: 6| Step: 11
Training loss: 1.442056655883789
Validation loss: 1.8805241507868613

Epoch: 6| Step: 12
Training loss: 1.060286521911621
Validation loss: 1.8718196166458951

Epoch: 6| Step: 13
Training loss: 1.4678053855895996
Validation loss: 1.858549597442791

Epoch: 198| Step: 0
Training loss: 1.7541756629943848
Validation loss: 1.8800567375716342

Epoch: 6| Step: 1
Training loss: 1.8745994567871094
Validation loss: 1.8679584918483612

Epoch: 6| Step: 2
Training loss: 1.3385846614837646
Validation loss: 1.8732778654303601

Epoch: 6| Step: 3
Training loss: 1.6052242517471313
Validation loss: 1.8678066602317236

Epoch: 6| Step: 4
Training loss: 1.6650059223175049
Validation loss: 1.8803936178966234

Epoch: 6| Step: 5
Training loss: 0.8963159322738647
Validation loss: 1.8832068148479666

Epoch: 6| Step: 6
Training loss: 1.566901445388794
Validation loss: 1.8654372948472218

Epoch: 6| Step: 7
Training loss: 2.086308002471924
Validation loss: 1.8994406397624681

Epoch: 6| Step: 8
Training loss: 1.5108277797698975
Validation loss: 1.877715495324904

Epoch: 6| Step: 9
Training loss: 1.819709300994873
Validation loss: 1.8635283811118013

Epoch: 6| Step: 10
Training loss: 2.325662612915039
Validation loss: 1.8766744059901084

Epoch: 6| Step: 11
Training loss: 2.1945974826812744
Validation loss: 1.8749154178045129

Epoch: 6| Step: 12
Training loss: 2.166792631149292
Validation loss: 1.8953322364437966

Epoch: 6| Step: 13
Training loss: 1.6098475456237793
Validation loss: 1.8703452912710046

Epoch: 199| Step: 0
Training loss: 1.4514703750610352
Validation loss: 1.889219686549197

Epoch: 6| Step: 1
Training loss: 1.8248050212860107
Validation loss: 1.9261085064180437

Epoch: 6| Step: 2
Training loss: 1.0482277870178223
Validation loss: 1.8887248064882012

Epoch: 6| Step: 3
Training loss: 1.6375420093536377
Validation loss: 1.88404712113001

Epoch: 6| Step: 4
Training loss: 1.6646363735198975
Validation loss: 1.9064811045123684

Epoch: 6| Step: 5
Training loss: 1.3145250082015991
Validation loss: 1.8570252362117972

Epoch: 6| Step: 6
Training loss: 2.684661865234375
Validation loss: 1.8905586914349628

Epoch: 6| Step: 7
Training loss: 2.287050247192383
Validation loss: 1.8805095226533952

Epoch: 6| Step: 8
Training loss: 1.618116021156311
Validation loss: 1.8976246977365145

Epoch: 6| Step: 9
Training loss: 1.9699146747589111
Validation loss: 1.878422167993361

Epoch: 6| Step: 10
Training loss: 1.6592788696289062
Validation loss: 1.871715054717115

Epoch: 6| Step: 11
Training loss: 1.6235978603363037
Validation loss: 1.8636026741355978

Epoch: 6| Step: 12
Training loss: 2.106433868408203
Validation loss: 1.8790186118054133

Epoch: 6| Step: 13
Training loss: 1.216878890991211
Validation loss: 1.8838017794393724

Epoch: 200| Step: 0
Training loss: 1.9407424926757812
Validation loss: 1.88229957062711

Epoch: 6| Step: 1
Training loss: 1.7931644916534424
Validation loss: 1.8618637361834127

Epoch: 6| Step: 2
Training loss: 1.7371065616607666
Validation loss: 1.8744140273781233

Epoch: 6| Step: 3
Training loss: 1.8802621364593506
Validation loss: 1.868202982410308

Epoch: 6| Step: 4
Training loss: 2.0402700901031494
Validation loss: 1.8602413003162672

Epoch: 6| Step: 5
Training loss: 1.64185631275177
Validation loss: 1.88522385269083

Epoch: 6| Step: 6
Training loss: 1.4435275793075562
Validation loss: 1.8844375366805701

Epoch: 6| Step: 7
Training loss: 2.022568941116333
Validation loss: 1.8884857469989407

Epoch: 6| Step: 8
Training loss: 1.253523349761963
Validation loss: 1.8590021043695428

Epoch: 6| Step: 9
Training loss: 2.0189294815063477
Validation loss: 1.8977259397506714

Epoch: 6| Step: 10
Training loss: 1.5821874141693115
Validation loss: 1.8627260295293664

Epoch: 6| Step: 11
Training loss: 1.853633165359497
Validation loss: 1.9151514525054603

Epoch: 6| Step: 12
Training loss: 1.2082712650299072
Validation loss: 1.8853020129665252

Epoch: 6| Step: 13
Training loss: 2.0363388061523438
Validation loss: 1.883134759882445

Epoch: 201| Step: 0
Training loss: 1.1374082565307617
Validation loss: 1.88856755533526

Epoch: 6| Step: 1
Training loss: 1.6984444856643677
Validation loss: 1.8744850979056409

Epoch: 6| Step: 2
Training loss: 1.5703846216201782
Validation loss: 1.8734693911767775

Epoch: 6| Step: 3
Training loss: 1.5782115459442139
Validation loss: 1.8881069716586862

Epoch: 6| Step: 4
Training loss: 1.506206750869751
Validation loss: 1.8769350667153635

Epoch: 6| Step: 5
Training loss: 2.600296974182129
Validation loss: 1.874082742198821

Epoch: 6| Step: 6
Training loss: 2.106987953186035
Validation loss: 1.8774678553304365

Epoch: 6| Step: 7
Training loss: 1.6637682914733887
Validation loss: 1.8943256408937517

Epoch: 6| Step: 8
Training loss: 2.6001195907592773
Validation loss: 1.8563594215659684

Epoch: 6| Step: 9
Training loss: 1.5788013935089111
Validation loss: 1.8863286356772146

Epoch: 6| Step: 10
Training loss: 1.1389224529266357
Validation loss: 1.8768880867188977

Epoch: 6| Step: 11
Training loss: 1.2922887802124023
Validation loss: 1.900725640276427

Epoch: 6| Step: 12
Training loss: 2.1043403148651123
Validation loss: 1.8858052569050943

Epoch: 6| Step: 13
Training loss: 1.4910826683044434
Validation loss: 1.8726222117741902

Epoch: 202| Step: 0
Training loss: 1.4677592515945435
Validation loss: 1.882882728371569

Epoch: 6| Step: 1
Training loss: 1.957841157913208
Validation loss: 1.903007234296491

Epoch: 6| Step: 2
Training loss: 1.122110366821289
Validation loss: 1.876997624674151

Epoch: 6| Step: 3
Training loss: 2.0709879398345947
Validation loss: 1.8789698218786588

Epoch: 6| Step: 4
Training loss: 1.538954257965088
Validation loss: 1.8751427922197568

Epoch: 6| Step: 5
Training loss: 2.0696163177490234
Validation loss: 1.9234682308730258

Epoch: 6| Step: 6
Training loss: 1.5709044933319092
Validation loss: 1.902744605977048

Epoch: 6| Step: 7
Training loss: 1.8966047763824463
Validation loss: 1.8772937866949266

Epoch: 6| Step: 8
Training loss: 2.0592594146728516
Validation loss: 1.9020270621904762

Epoch: 6| Step: 9
Training loss: 2.2241413593292236
Validation loss: 1.9060503616127917

Epoch: 6| Step: 10
Training loss: 1.1186844110488892
Validation loss: 1.917918610316451

Epoch: 6| Step: 11
Training loss: 2.4234328269958496
Validation loss: 1.8857616891143143

Epoch: 6| Step: 12
Training loss: 1.1822690963745117
Validation loss: 1.9178105208181566

Epoch: 6| Step: 13
Training loss: 1.47823166847229
Validation loss: 1.8961048690221642

Epoch: 203| Step: 0
Training loss: 1.953902244567871
Validation loss: 1.8638887559213946

Epoch: 6| Step: 1
Training loss: 1.6175848245620728
Validation loss: 1.8970511651808215

Epoch: 6| Step: 2
Training loss: 1.4883049726486206
Validation loss: 1.8679024327185847

Epoch: 6| Step: 3
Training loss: 1.14303457736969
Validation loss: 1.8812587979019328

Epoch: 6| Step: 4
Training loss: 1.6122440099716187
Validation loss: 1.9002490966550765

Epoch: 6| Step: 5
Training loss: 1.8769209384918213
Validation loss: 1.886603061870862

Epoch: 6| Step: 6
Training loss: 2.0595827102661133
Validation loss: 1.8464180064457718

Epoch: 6| Step: 7
Training loss: 1.7501671314239502
Validation loss: 1.8696184671053322

Epoch: 6| Step: 8
Training loss: 1.7941715717315674
Validation loss: 1.867217130558465

Epoch: 6| Step: 9
Training loss: 1.9333068132400513
Validation loss: 1.8730182442613827

Epoch: 6| Step: 10
Training loss: 1.402529001235962
Validation loss: 1.8732465492781771

Epoch: 6| Step: 11
Training loss: 2.1228866577148438
Validation loss: 1.8861430896225797

Epoch: 6| Step: 12
Training loss: 1.6041895151138306
Validation loss: 1.8415691609023719

Epoch: 6| Step: 13
Training loss: 1.4918372631072998
Validation loss: 1.876280899970762

Epoch: 204| Step: 0
Training loss: 1.5927982330322266
Validation loss: 1.856414000193278

Epoch: 6| Step: 1
Training loss: 2.0354983806610107
Validation loss: 1.8902440660743303

Epoch: 6| Step: 2
Training loss: 2.2728490829467773
Validation loss: 1.8705238706322127

Epoch: 6| Step: 3
Training loss: 1.427964210510254
Validation loss: 1.8930760583569926

Epoch: 6| Step: 4
Training loss: 1.791975736618042
Validation loss: 1.893040418624878

Epoch: 6| Step: 5
Training loss: 1.4079669713974
Validation loss: 1.847990491056955

Epoch: 6| Step: 6
Training loss: 1.7903884649276733
Validation loss: 1.9100913117008824

Epoch: 6| Step: 7
Training loss: 1.6658611297607422
Validation loss: 1.8537766984713975

Epoch: 6| Step: 8
Training loss: 1.5963040590286255
Validation loss: 1.8869334907941921

Epoch: 6| Step: 9
Training loss: 1.5092369318008423
Validation loss: 1.9051267075282272

Epoch: 6| Step: 10
Training loss: 1.8130145072937012
Validation loss: 1.8574388116918585

Epoch: 6| Step: 11
Training loss: 1.9183374643325806
Validation loss: 1.8764053493417718

Epoch: 6| Step: 12
Training loss: 1.8006930351257324
Validation loss: 1.8919870750878447

Epoch: 6| Step: 13
Training loss: 1.2319564819335938
Validation loss: 1.887454899408484

Epoch: 205| Step: 0
Training loss: 1.768580436706543
Validation loss: 1.871331842996741

Epoch: 6| Step: 1
Training loss: 1.5664924383163452
Validation loss: 1.879956546650138

Epoch: 6| Step: 2
Training loss: 2.3393137454986572
Validation loss: 1.872985452734014

Epoch: 6| Step: 3
Training loss: 1.5671429634094238
Validation loss: 1.8675547287028322

Epoch: 6| Step: 4
Training loss: 1.7699379920959473
Validation loss: 1.859770546677292

Epoch: 6| Step: 5
Training loss: 1.6735010147094727
Validation loss: 1.8545299935084518

Epoch: 6| Step: 6
Training loss: 1.8906886577606201
Validation loss: 1.8609769075147566

Epoch: 6| Step: 7
Training loss: 2.064300537109375
Validation loss: 1.8690594370647142

Epoch: 6| Step: 8
Training loss: 1.5774405002593994
Validation loss: 1.8571477026067755

Epoch: 6| Step: 9
Training loss: 1.270492672920227
Validation loss: 1.875605062771869

Epoch: 6| Step: 10
Training loss: 1.7162538766860962
Validation loss: 1.8492747173514417

Epoch: 6| Step: 11
Training loss: 2.0949809551239014
Validation loss: 1.8719437776073333

Epoch: 6| Step: 12
Training loss: 1.4180729389190674
Validation loss: 1.8514746671081872

Epoch: 6| Step: 13
Training loss: 0.9215537309646606
Validation loss: 1.8751500473227551

Epoch: 206| Step: 0
Training loss: 2.203099489212036
Validation loss: 1.8939239260970906

Epoch: 6| Step: 1
Training loss: 1.1876776218414307
Validation loss: 1.9134695658119776

Epoch: 6| Step: 2
Training loss: 2.246720314025879
Validation loss: 1.8711631951793548

Epoch: 6| Step: 3
Training loss: 1.3474805355072021
Validation loss: 1.9012034285453059

Epoch: 6| Step: 4
Training loss: 2.04419207572937
Validation loss: 1.9149177664069719

Epoch: 6| Step: 5
Training loss: 1.6935429573059082
Validation loss: 1.857664531277072

Epoch: 6| Step: 6
Training loss: 1.3895847797393799
Validation loss: 1.9117397287840485

Epoch: 6| Step: 7
Training loss: 1.3323376178741455
Validation loss: 1.8909209710295483

Epoch: 6| Step: 8
Training loss: 2.4582481384277344
Validation loss: 1.8987436832920197

Epoch: 6| Step: 9
Training loss: 1.4302440881729126
Validation loss: 1.9157783997956144

Epoch: 6| Step: 10
Training loss: 1.463942527770996
Validation loss: 1.889698423365111

Epoch: 6| Step: 11
Training loss: 1.829713225364685
Validation loss: 1.8626432803369337

Epoch: 6| Step: 12
Training loss: 2.013087034225464
Validation loss: 1.8709842440902547

Epoch: 6| Step: 13
Training loss: 0.8465625047683716
Validation loss: 1.8960243732698503

Epoch: 207| Step: 0
Training loss: 1.7272909879684448
Validation loss: 1.8965031036766626

Epoch: 6| Step: 1
Training loss: 1.9477839469909668
Validation loss: 1.8687078055515085

Epoch: 6| Step: 2
Training loss: 1.7578388452529907
Validation loss: 1.8866245118520593

Epoch: 6| Step: 3
Training loss: 1.8552546501159668
Validation loss: 1.887710000879021

Epoch: 6| Step: 4
Training loss: 1.0237476825714111
Validation loss: 1.9130272685840566

Epoch: 6| Step: 5
Training loss: 1.2004170417785645
Validation loss: 1.8588020775907783

Epoch: 6| Step: 6
Training loss: 1.7783875465393066
Validation loss: 1.8751578728357952

Epoch: 6| Step: 7
Training loss: 1.8529549837112427
Validation loss: 1.8643090622399443

Epoch: 6| Step: 8
Training loss: 1.5019617080688477
Validation loss: 1.8838228282108103

Epoch: 6| Step: 9
Training loss: 1.4025723934173584
Validation loss: 1.8665221660367903

Epoch: 6| Step: 10
Training loss: 1.486504316329956
Validation loss: 1.8656034008149178

Epoch: 6| Step: 11
Training loss: 1.9197908639907837
Validation loss: 1.8871070210651686

Epoch: 6| Step: 12
Training loss: 2.2707533836364746
Validation loss: 1.881936998777492

Epoch: 6| Step: 13
Training loss: 2.5472288131713867
Validation loss: 1.8528891686470277

Epoch: 208| Step: 0
Training loss: 2.3374714851379395
Validation loss: 1.8633892382344892

Epoch: 6| Step: 1
Training loss: 1.6726901531219482
Validation loss: 1.8800550442869945

Epoch: 6| Step: 2
Training loss: 1.6585500240325928
Validation loss: 1.8772641804910475

Epoch: 6| Step: 3
Training loss: 0.8336496949195862
Validation loss: 1.8830042052012619

Epoch: 6| Step: 4
Training loss: 1.3151040077209473
Validation loss: 1.9142605694391395

Epoch: 6| Step: 5
Training loss: 1.3940174579620361
Validation loss: 1.9278411531961093

Epoch: 6| Step: 6
Training loss: 2.07388973236084
Validation loss: 1.8966976442644674

Epoch: 6| Step: 7
Training loss: 2.071638345718384
Validation loss: 1.8911222578376852

Epoch: 6| Step: 8
Training loss: 1.6750884056091309
Validation loss: 1.880136093785686

Epoch: 6| Step: 9
Training loss: 1.8492155075073242
Validation loss: 1.8927220093306674

Epoch: 6| Step: 10
Training loss: 1.7696460485458374
Validation loss: 1.918182549938079

Epoch: 6| Step: 11
Training loss: 2.12823748588562
Validation loss: 1.8697154714215187

Epoch: 6| Step: 12
Training loss: 1.561105489730835
Validation loss: 1.8915120747781569

Epoch: 6| Step: 13
Training loss: 1.956268072128296
Validation loss: 1.8888463256179646

Epoch: 209| Step: 0
Training loss: 1.3036479949951172
Validation loss: 1.8655089550120856

Epoch: 6| Step: 1
Training loss: 2.4090518951416016
Validation loss: 1.8933670046508952

Epoch: 6| Step: 2
Training loss: 1.6250981092453003
Validation loss: 1.8753921729262157

Epoch: 6| Step: 3
Training loss: 1.3450355529785156
Validation loss: 1.895885452147453

Epoch: 6| Step: 4
Training loss: 1.214313268661499
Validation loss: 1.881460218019383

Epoch: 6| Step: 5
Training loss: 1.704704999923706
Validation loss: 1.8596668102407967

Epoch: 6| Step: 6
Training loss: 1.0248336791992188
Validation loss: 1.8754698973830028

Epoch: 6| Step: 7
Training loss: 2.344341278076172
Validation loss: 1.8855370385672456

Epoch: 6| Step: 8
Training loss: 1.6732771396636963
Validation loss: 1.86566666377488

Epoch: 6| Step: 9
Training loss: 1.8403451442718506
Validation loss: 1.8877202900507117

Epoch: 6| Step: 10
Training loss: 2.7449862957000732
Validation loss: 1.861154851093087

Epoch: 6| Step: 11
Training loss: 1.7292609214782715
Validation loss: 1.8521845571456417

Epoch: 6| Step: 12
Training loss: 1.8258554935455322
Validation loss: 1.9284311891883932

Epoch: 6| Step: 13
Training loss: 0.7484028339385986
Validation loss: 1.845959557000027

Epoch: 210| Step: 0
Training loss: 1.6499931812286377
Validation loss: 1.8874501361641833

Epoch: 6| Step: 1
Training loss: 2.0935542583465576
Validation loss: 1.8759647902622019

Epoch: 6| Step: 2
Training loss: 1.2335748672485352
Validation loss: 1.877584731707009

Epoch: 6| Step: 3
Training loss: 1.414310336112976
Validation loss: 1.8796058765021704

Epoch: 6| Step: 4
Training loss: 1.274134635925293
Validation loss: 1.843475490488032

Epoch: 6| Step: 5
Training loss: 1.3170166015625
Validation loss: 1.8482926763514036

Epoch: 6| Step: 6
Training loss: 2.093282699584961
Validation loss: 1.8758695407580304

Epoch: 6| Step: 7
Training loss: 1.5148555040359497
Validation loss: 1.8793732197053972

Epoch: 6| Step: 8
Training loss: 1.132777452468872
Validation loss: 1.889083327785615

Epoch: 6| Step: 9
Training loss: 2.271549940109253
Validation loss: 1.8590459041698004

Epoch: 6| Step: 10
Training loss: 2.1177282333374023
Validation loss: 1.90366453765541

Epoch: 6| Step: 11
Training loss: 2.416536808013916
Validation loss: 1.8898004306259977

Epoch: 6| Step: 12
Training loss: 1.7695586681365967
Validation loss: 1.8850901460134855

Epoch: 6| Step: 13
Training loss: 1.7306073904037476
Validation loss: 1.8674022151577858

Epoch: 211| Step: 0
Training loss: 1.5313057899475098
Validation loss: 1.8516717521093224

Epoch: 6| Step: 1
Training loss: 1.552367091178894
Validation loss: 1.8459512161952194

Epoch: 6| Step: 2
Training loss: 1.9463179111480713
Validation loss: 1.8708923170643468

Epoch: 6| Step: 3
Training loss: 1.4728316068649292
Validation loss: 1.8427240720359228

Epoch: 6| Step: 4
Training loss: 1.4528894424438477
Validation loss: 1.8828519262293333

Epoch: 6| Step: 5
Training loss: 1.2805124521255493
Validation loss: 1.8843957172927035

Epoch: 6| Step: 6
Training loss: 2.2538394927978516
Validation loss: 1.876989769679244

Epoch: 6| Step: 7
Training loss: 1.7644660472869873
Validation loss: 1.8667873246695406

Epoch: 6| Step: 8
Training loss: 1.5677762031555176
Validation loss: 1.855805677752341

Epoch: 6| Step: 9
Training loss: 1.3978919982910156
Validation loss: 1.8601595893982918

Epoch: 6| Step: 10
Training loss: 1.2555049657821655
Validation loss: 1.8671291169299875

Epoch: 6| Step: 11
Training loss: 2.20583176612854
Validation loss: 1.8687558468951975

Epoch: 6| Step: 12
Training loss: 1.857443928718567
Validation loss: 1.8912781823065974

Epoch: 6| Step: 13
Training loss: 2.041980028152466
Validation loss: 1.8927986416765439

Epoch: 212| Step: 0
Training loss: 1.6032874584197998
Validation loss: 1.894194975976021

Epoch: 6| Step: 1
Training loss: 2.109229564666748
Validation loss: 1.8721425443567254

Epoch: 6| Step: 2
Training loss: 1.5853577852249146
Validation loss: 1.8774193538132535

Epoch: 6| Step: 3
Training loss: 1.339862585067749
Validation loss: 1.8720765190739785

Epoch: 6| Step: 4
Training loss: 1.0148942470550537
Validation loss: 1.8662034875603133

Epoch: 6| Step: 5
Training loss: 1.0135576725006104
Validation loss: 1.871122581984407

Epoch: 6| Step: 6
Training loss: 1.481860876083374
Validation loss: 1.8916110005429996

Epoch: 6| Step: 7
Training loss: 1.980872631072998
Validation loss: 1.8853651938899871

Epoch: 6| Step: 8
Training loss: 2.5017545223236084
Validation loss: 1.889600097492177

Epoch: 6| Step: 9
Training loss: 1.1902410984039307
Validation loss: 1.912626060106421

Epoch: 6| Step: 10
Training loss: 1.6978404521942139
Validation loss: 1.9077926502432874

Epoch: 6| Step: 11
Training loss: 2.2162723541259766
Validation loss: 1.8888264163847892

Epoch: 6| Step: 12
Training loss: 1.9249376058578491
Validation loss: 1.9055595782495314

Epoch: 6| Step: 13
Training loss: 2.358074188232422
Validation loss: 1.922108801462317

Epoch: 213| Step: 0
Training loss: 1.4512114524841309
Validation loss: 1.8652942872816516

Epoch: 6| Step: 1
Training loss: 1.498375654220581
Validation loss: 1.8945820664846769

Epoch: 6| Step: 2
Training loss: 2.060711145401001
Validation loss: 1.9038566338118685

Epoch: 6| Step: 3
Training loss: 1.4307169914245605
Validation loss: 1.8975202063078522

Epoch: 6| Step: 4
Training loss: 1.4362022876739502
Validation loss: 1.906123238225137

Epoch: 6| Step: 5
Training loss: 1.2973248958587646
Validation loss: 1.9032181847480036

Epoch: 6| Step: 6
Training loss: 2.2195630073547363
Validation loss: 1.9255320026028542

Epoch: 6| Step: 7
Training loss: 1.4976105690002441
Validation loss: 1.9019409789833972

Epoch: 6| Step: 8
Training loss: 1.4866632223129272
Validation loss: 1.9163568353140226

Epoch: 6| Step: 9
Training loss: 1.6573954820632935
Validation loss: 1.8490240317518993

Epoch: 6| Step: 10
Training loss: 1.5954011678695679
Validation loss: 1.8765154782161917

Epoch: 6| Step: 11
Training loss: 2.1171786785125732
Validation loss: 1.8549235559278918

Epoch: 6| Step: 12
Training loss: 2.0963199138641357
Validation loss: 1.8603364216384066

Epoch: 6| Step: 13
Training loss: 2.110142946243286
Validation loss: 1.840898923976447

Epoch: 214| Step: 0
Training loss: 1.376854419708252
Validation loss: 1.8536528477104761

Epoch: 6| Step: 1
Training loss: 0.9018394351005554
Validation loss: 1.8693963084169614

Epoch: 6| Step: 2
Training loss: 1.6202688217163086
Validation loss: 1.8767439498696277

Epoch: 6| Step: 3
Training loss: 1.5681785345077515
Validation loss: 1.8778754447096138

Epoch: 6| Step: 4
Training loss: 2.2197186946868896
Validation loss: 1.8472621671615108

Epoch: 6| Step: 5
Training loss: 1.6951780319213867
Validation loss: 1.8482884924898866

Epoch: 6| Step: 6
Training loss: 1.7454612255096436
Validation loss: 1.861973730466699

Epoch: 6| Step: 7
Training loss: 1.7097740173339844
Validation loss: 1.8171996057674449

Epoch: 6| Step: 8
Training loss: 2.000002384185791
Validation loss: 1.8581991913498088

Epoch: 6| Step: 9
Training loss: 1.7341980934143066
Validation loss: 1.8653166140279462

Epoch: 6| Step: 10
Training loss: 1.6544604301452637
Validation loss: 1.8357345878437001

Epoch: 6| Step: 11
Training loss: 1.2395633459091187
Validation loss: 1.8744806051254272

Epoch: 6| Step: 12
Training loss: 1.6911364793777466
Validation loss: 1.893722641852594

Epoch: 6| Step: 13
Training loss: 2.7515907287597656
Validation loss: 1.8558522885845554

Epoch: 215| Step: 0
Training loss: 1.8083491325378418
Validation loss: 1.8541433054913756

Epoch: 6| Step: 1
Training loss: 1.0523563623428345
Validation loss: 1.8959666362372778

Epoch: 6| Step: 2
Training loss: 1.4651397466659546
Validation loss: 1.8999216556549072

Epoch: 6| Step: 3
Training loss: 1.4553872346878052
Validation loss: 1.8912202145463677

Epoch: 6| Step: 4
Training loss: 2.1930646896362305
Validation loss: 1.8906698278201524

Epoch: 6| Step: 5
Training loss: 2.339334011077881
Validation loss: 1.8914198157607869

Epoch: 6| Step: 6
Training loss: 1.3504254817962646
Validation loss: 1.8856341582472607

Epoch: 6| Step: 7
Training loss: 1.7332730293273926
Validation loss: 1.8926499646197084

Epoch: 6| Step: 8
Training loss: 0.9195009469985962
Validation loss: 1.890428714854743

Epoch: 6| Step: 9
Training loss: 2.0389156341552734
Validation loss: 1.9289788828101209

Epoch: 6| Step: 10
Training loss: 2.0275754928588867
Validation loss: 1.8832081466592767

Epoch: 6| Step: 11
Training loss: 1.540993094444275
Validation loss: 1.8927935951499528

Epoch: 6| Step: 12
Training loss: 1.2799497842788696
Validation loss: 1.8979799568012197

Epoch: 6| Step: 13
Training loss: 2.5614402294158936
Validation loss: 1.853067462162305

Epoch: 216| Step: 0
Training loss: 1.5452702045440674
Validation loss: 1.8561281529805993

Epoch: 6| Step: 1
Training loss: 1.2131842374801636
Validation loss: 1.8433111175414054

Epoch: 6| Step: 2
Training loss: 1.5921282768249512
Validation loss: 1.8403246402740479

Epoch: 6| Step: 3
Training loss: 1.8045680522918701
Validation loss: 1.858246026500579

Epoch: 6| Step: 4
Training loss: 1.7559069395065308
Validation loss: 1.8390468820448844

Epoch: 6| Step: 5
Training loss: 2.5841116905212402
Validation loss: 1.8416832813652613

Epoch: 6| Step: 6
Training loss: 1.8279062509536743
Validation loss: 1.8634551564852397

Epoch: 6| Step: 7
Training loss: 0.7212387323379517
Validation loss: 1.8621608416239421

Epoch: 6| Step: 8
Training loss: 1.0802855491638184
Validation loss: 1.8562583372157107

Epoch: 6| Step: 9
Training loss: 1.9404146671295166
Validation loss: 1.856809562252414

Epoch: 6| Step: 10
Training loss: 2.1045496463775635
Validation loss: 1.864013664184078

Epoch: 6| Step: 11
Training loss: 1.7243520021438599
Validation loss: 1.8651733142073437

Epoch: 6| Step: 12
Training loss: 1.503233790397644
Validation loss: 1.8626214355550788

Epoch: 6| Step: 13
Training loss: 1.8879075050354004
Validation loss: 1.84257411572241

Epoch: 217| Step: 0
Training loss: 1.2686445713043213
Validation loss: 1.8425324706621067

Epoch: 6| Step: 1
Training loss: 1.75108003616333
Validation loss: 1.872369312470959

Epoch: 6| Step: 2
Training loss: 1.5016298294067383
Validation loss: 1.8517066406947311

Epoch: 6| Step: 3
Training loss: 1.524412989616394
Validation loss: 1.9066241313052434

Epoch: 6| Step: 4
Training loss: 1.6513381004333496
Validation loss: 1.8708987800023889

Epoch: 6| Step: 5
Training loss: 2.219515323638916
Validation loss: 1.9183224478075582

Epoch: 6| Step: 6
Training loss: 1.4672391414642334
Validation loss: 1.8485560660721154

Epoch: 6| Step: 7
Training loss: 1.461643934249878
Validation loss: 1.8750453482392013

Epoch: 6| Step: 8
Training loss: 2.3127384185791016
Validation loss: 1.890177639581824

Epoch: 6| Step: 9
Training loss: 1.988855242729187
Validation loss: 1.8902377223455777

Epoch: 6| Step: 10
Training loss: 1.074221134185791
Validation loss: 1.8859783744299283

Epoch: 6| Step: 11
Training loss: 2.0368871688842773
Validation loss: 1.8752922973325175

Epoch: 6| Step: 12
Training loss: 2.0106568336486816
Validation loss: 1.8688032127195788

Epoch: 6| Step: 13
Training loss: 0.7660327553749084
Validation loss: 1.8799163628649969

Epoch: 218| Step: 0
Training loss: 2.2197582721710205
Validation loss: 1.8632831445304296

Epoch: 6| Step: 1
Training loss: 2.079303503036499
Validation loss: 1.861487166855925

Epoch: 6| Step: 2
Training loss: 1.4283428192138672
Validation loss: 1.8763453037508073

Epoch: 6| Step: 3
Training loss: 1.451385259628296
Validation loss: 1.8376458665376068

Epoch: 6| Step: 4
Training loss: 1.686109185218811
Validation loss: 1.8786966544325634

Epoch: 6| Step: 5
Training loss: 1.3020868301391602
Validation loss: 1.8709810421031008

Epoch: 6| Step: 6
Training loss: 1.5284557342529297
Validation loss: 1.8543877729805567

Epoch: 6| Step: 7
Training loss: 1.2216947078704834
Validation loss: 1.8754396489871445

Epoch: 6| Step: 8
Training loss: 1.642411470413208
Validation loss: 1.8754882709954375

Epoch: 6| Step: 9
Training loss: 1.5177066326141357
Validation loss: 1.8415042700306061

Epoch: 6| Step: 10
Training loss: 1.51253342628479
Validation loss: 1.8758726401995587

Epoch: 6| Step: 11
Training loss: 2.4921562671661377
Validation loss: 1.8475270809665802

Epoch: 6| Step: 12
Training loss: 1.2434806823730469
Validation loss: 1.8593480548551005

Epoch: 6| Step: 13
Training loss: 1.83816659450531
Validation loss: 1.858792979230163

Epoch: 219| Step: 0
Training loss: 1.2710683345794678
Validation loss: 1.8562719232292586

Epoch: 6| Step: 1
Training loss: 1.7208664417266846
Validation loss: 1.8821230524329728

Epoch: 6| Step: 2
Training loss: 1.064056158065796
Validation loss: 1.8812804888653498

Epoch: 6| Step: 3
Training loss: 1.2960788011550903
Validation loss: 1.8618380741406513

Epoch: 6| Step: 4
Training loss: 1.5321764945983887
Validation loss: 1.8691310818477342

Epoch: 6| Step: 5
Training loss: 2.1139848232269287
Validation loss: 1.8785313688298708

Epoch: 6| Step: 6
Training loss: 1.9814424514770508
Validation loss: 1.8570186809826923

Epoch: 6| Step: 7
Training loss: 2.3331289291381836
Validation loss: 1.8709550531961585

Epoch: 6| Step: 8
Training loss: 1.6889755725860596
Validation loss: 1.8804469198308966

Epoch: 6| Step: 9
Training loss: 1.3396103382110596
Validation loss: 1.8990353845780896

Epoch: 6| Step: 10
Training loss: 2.0294947624206543
Validation loss: 1.8943631520835302

Epoch: 6| Step: 11
Training loss: 1.4528881311416626
Validation loss: 1.8771542823442848

Epoch: 6| Step: 12
Training loss: 1.8905351161956787
Validation loss: 1.8809712561227943

Epoch: 6| Step: 13
Training loss: 1.6281036138534546
Validation loss: 1.84865697609481

Epoch: 220| Step: 0
Training loss: 2.001335620880127
Validation loss: 1.8589792930951683

Epoch: 6| Step: 1
Training loss: 1.8219059705734253
Validation loss: 1.8485783120637298

Epoch: 6| Step: 2
Training loss: 1.8386338949203491
Validation loss: 1.8972129411594842

Epoch: 6| Step: 3
Training loss: 2.0073888301849365
Validation loss: 1.8589263385342014

Epoch: 6| Step: 4
Training loss: 1.0717271566390991
Validation loss: 1.8928885677809357

Epoch: 6| Step: 5
Training loss: 1.6024610996246338
Validation loss: 1.877354364241323

Epoch: 6| Step: 6
Training loss: 2.15842604637146
Validation loss: 1.8765831967835784

Epoch: 6| Step: 7
Training loss: 1.963059425354004
Validation loss: 1.8774204305423203

Epoch: 6| Step: 8
Training loss: 0.8130483627319336
Validation loss: 1.8655462239378242

Epoch: 6| Step: 9
Training loss: 1.6643489599227905
Validation loss: 1.9071269278885217

Epoch: 6| Step: 10
Training loss: 1.6963156461715698
Validation loss: 1.8792958362128145

Epoch: 6| Step: 11
Training loss: 1.2392910718917847
Validation loss: 1.8858608904705252

Epoch: 6| Step: 12
Training loss: 1.372406244277954
Validation loss: 1.8667619997455227

Epoch: 6| Step: 13
Training loss: 1.846387267112732
Validation loss: 1.877572380086427

Epoch: 221| Step: 0
Training loss: 1.202897071838379
Validation loss: 1.8678477746184154

Epoch: 6| Step: 1
Training loss: 1.4281061887741089
Validation loss: 1.8893543994554909

Epoch: 6| Step: 2
Training loss: 2.0389671325683594
Validation loss: 1.8812665913694648

Epoch: 6| Step: 3
Training loss: 1.6925302743911743
Validation loss: 1.8739021106432843

Epoch: 6| Step: 4
Training loss: 1.4521678686141968
Validation loss: 1.8806514047807263

Epoch: 6| Step: 5
Training loss: 1.5099103450775146
Validation loss: 1.8828865456324753

Epoch: 6| Step: 6
Training loss: 2.4226675033569336
Validation loss: 1.8605748607266335

Epoch: 6| Step: 7
Training loss: 1.0312719345092773
Validation loss: 1.893695859498875

Epoch: 6| Step: 8
Training loss: 1.7354331016540527
Validation loss: 1.8585346565451673

Epoch: 6| Step: 9
Training loss: 1.8559222221374512
Validation loss: 1.8759658029002528

Epoch: 6| Step: 10
Training loss: 1.4186369180679321
Validation loss: 1.8484739770171463

Epoch: 6| Step: 11
Training loss: 2.1553423404693604
Validation loss: 1.8871457743388351

Epoch: 6| Step: 12
Training loss: 1.6501868963241577
Validation loss: 1.839623644787778

Epoch: 6| Step: 13
Training loss: 1.8451110124588013
Validation loss: 1.8880619784837127

Epoch: 222| Step: 0
Training loss: 1.7224175930023193
Validation loss: 1.877962427754556

Epoch: 6| Step: 1
Training loss: 1.405099868774414
Validation loss: 1.8918869700483096

Epoch: 6| Step: 2
Training loss: 1.3196287155151367
Validation loss: 1.8456426474355883

Epoch: 6| Step: 3
Training loss: 1.2881380319595337
Validation loss: 1.8405685899078206

Epoch: 6| Step: 4
Training loss: 1.1814016103744507
Validation loss: 1.8590142906353038

Epoch: 6| Step: 5
Training loss: 2.4453842639923096
Validation loss: 1.8473657933614587

Epoch: 6| Step: 6
Training loss: 1.792221188545227
Validation loss: 1.8583154229707615

Epoch: 6| Step: 7
Training loss: 1.5721473693847656
Validation loss: 1.8438678274872482

Epoch: 6| Step: 8
Training loss: 1.7104709148406982
Validation loss: 1.877072367616879

Epoch: 6| Step: 9
Training loss: 2.4748215675354004
Validation loss: 1.8661979795784078

Epoch: 6| Step: 10
Training loss: 1.3114182949066162
Validation loss: 1.878279637264949

Epoch: 6| Step: 11
Training loss: 1.356130599975586
Validation loss: 1.8566278462768884

Epoch: 6| Step: 12
Training loss: 1.9245643615722656
Validation loss: 1.8818946256432483

Epoch: 6| Step: 13
Training loss: 1.5018976926803589
Validation loss: 1.857111115609446

Epoch: 223| Step: 0
Training loss: 1.4169731140136719
Validation loss: 1.8839670176147132

Epoch: 6| Step: 1
Training loss: 1.106366515159607
Validation loss: 1.8710723525734358

Epoch: 6| Step: 2
Training loss: 1.9854514598846436
Validation loss: 1.8745160948845647

Epoch: 6| Step: 3
Training loss: 1.3765122890472412
Validation loss: 1.8728804652408888

Epoch: 6| Step: 4
Training loss: 1.7362515926361084
Validation loss: 1.8733430011298067

Epoch: 6| Step: 5
Training loss: 2.114677906036377
Validation loss: 1.8821207118290726

Epoch: 6| Step: 6
Training loss: 1.697422742843628
Validation loss: 1.8837100549410748

Epoch: 6| Step: 7
Training loss: 1.447570562362671
Validation loss: 1.8850457258121942

Epoch: 6| Step: 8
Training loss: 1.3457587957382202
Validation loss: 1.8605764783838743

Epoch: 6| Step: 9
Training loss: 2.298034906387329
Validation loss: 1.9125164478055892

Epoch: 6| Step: 10
Training loss: 1.7524646520614624
Validation loss: 1.885215131185388

Epoch: 6| Step: 11
Training loss: 1.762108564376831
Validation loss: 1.8625356151211647

Epoch: 6| Step: 12
Training loss: 1.6467137336730957
Validation loss: 1.871672390609659

Epoch: 6| Step: 13
Training loss: 1.401648998260498
Validation loss: 1.8661781190544047

Epoch: 224| Step: 0
Training loss: 1.8140645027160645
Validation loss: 1.8537055523164812

Epoch: 6| Step: 1
Training loss: 1.318506121635437
Validation loss: 1.8466312372556297

Epoch: 6| Step: 2
Training loss: 2.1871285438537598
Validation loss: 1.8843562000541276

Epoch: 6| Step: 3
Training loss: 1.4397153854370117
Validation loss: 1.8517736747700682

Epoch: 6| Step: 4
Training loss: 2.4942712783813477
Validation loss: 1.8874205209875619

Epoch: 6| Step: 5
Training loss: 1.4437720775604248
Validation loss: 1.8874333558544036

Epoch: 6| Step: 6
Training loss: 1.9485499858856201
Validation loss: 1.8833866170657578

Epoch: 6| Step: 7
Training loss: 1.4526889324188232
Validation loss: 1.8805629925061298

Epoch: 6| Step: 8
Training loss: 1.4162046909332275
Validation loss: 1.8999239270405104

Epoch: 6| Step: 9
Training loss: 1.144412636756897
Validation loss: 1.8870142582924134

Epoch: 6| Step: 10
Training loss: 1.290615439414978
Validation loss: 1.8861369497032576

Epoch: 6| Step: 11
Training loss: 1.5081195831298828
Validation loss: 1.8816267187877367

Epoch: 6| Step: 12
Training loss: 2.104440450668335
Validation loss: 1.8735279831835019

Epoch: 6| Step: 13
Training loss: 1.0953035354614258
Validation loss: 1.8766461828703522

Epoch: 225| Step: 0
Training loss: 1.4562180042266846
Validation loss: 1.899322263656124

Epoch: 6| Step: 1
Training loss: 0.9090139865875244
Validation loss: 1.835305190855457

Epoch: 6| Step: 2
Training loss: 1.691478967666626
Validation loss: 1.8545058491409465

Epoch: 6| Step: 3
Training loss: 1.2351680994033813
Validation loss: 1.8648481574109805

Epoch: 6| Step: 4
Training loss: 1.6719619035720825
Validation loss: 1.8853791529132473

Epoch: 6| Step: 5
Training loss: 1.8193206787109375
Validation loss: 1.842414153519497

Epoch: 6| Step: 6
Training loss: 1.7044048309326172
Validation loss: 1.8648591810657131

Epoch: 6| Step: 7
Training loss: 1.785561442375183
Validation loss: 1.8759775418107227

Epoch: 6| Step: 8
Training loss: 2.3234121799468994
Validation loss: 1.849275218543186

Epoch: 6| Step: 9
Training loss: 1.7675012350082397
Validation loss: 1.8503124342169812

Epoch: 6| Step: 10
Training loss: 1.7258270978927612
Validation loss: 1.879704733048716

Epoch: 6| Step: 11
Training loss: 1.5977563858032227
Validation loss: 1.8621271323132258

Epoch: 6| Step: 12
Training loss: 1.8245160579681396
Validation loss: 1.8892616046372281

Epoch: 6| Step: 13
Training loss: 1.7329902648925781
Validation loss: 1.8436643564572899

Epoch: 226| Step: 0
Training loss: 1.6478748321533203
Validation loss: 1.8538652184189006

Epoch: 6| Step: 1
Training loss: 1.314093828201294
Validation loss: 1.8690192032885808

Epoch: 6| Step: 2
Training loss: 1.3582699298858643
Validation loss: 1.8674766581545594

Epoch: 6| Step: 3
Training loss: 1.7045258283615112
Validation loss: 1.8305534393556657

Epoch: 6| Step: 4
Training loss: 1.8437179327011108
Validation loss: 1.8347337169031943

Epoch: 6| Step: 5
Training loss: 2.6708903312683105
Validation loss: 1.8594956603101505

Epoch: 6| Step: 6
Training loss: 1.3092041015625
Validation loss: 1.8583416528599237

Epoch: 6| Step: 7
Training loss: 1.878476858139038
Validation loss: 1.871228902570663

Epoch: 6| Step: 8
Training loss: 1.3799939155578613
Validation loss: 1.8624232674157748

Epoch: 6| Step: 9
Training loss: 1.480583667755127
Validation loss: 1.9031271947327482

Epoch: 6| Step: 10
Training loss: 1.030097246170044
Validation loss: 1.8918961094271751

Epoch: 6| Step: 11
Training loss: 2.752302885055542
Validation loss: 1.8859972133431384

Epoch: 6| Step: 12
Training loss: 1.4138939380645752
Validation loss: 1.8790693757354573

Epoch: 6| Step: 13
Training loss: 1.2899538278579712
Validation loss: 1.898971765272079

Epoch: 227| Step: 0
Training loss: 1.9738481044769287
Validation loss: 1.8699932995662893

Epoch: 6| Step: 1
Training loss: 1.8091964721679688
Validation loss: 1.840933229333611

Epoch: 6| Step: 2
Training loss: 2.229579210281372
Validation loss: 1.8848183680606145

Epoch: 6| Step: 3
Training loss: 2.0644028186798096
Validation loss: 1.8494619656634588

Epoch: 6| Step: 4
Training loss: 1.1214169263839722
Validation loss: 1.8312299456647647

Epoch: 6| Step: 5
Training loss: 1.386547565460205
Validation loss: 1.8579742485477078

Epoch: 6| Step: 6
Training loss: 1.5979706048965454
Validation loss: 1.8374011311479794

Epoch: 6| Step: 7
Training loss: 1.391727328300476
Validation loss: 1.8302891215970438

Epoch: 6| Step: 8
Training loss: 1.5542904138565063
Validation loss: 1.8487974225833852

Epoch: 6| Step: 9
Training loss: 0.9870795011520386
Validation loss: 1.8453708989645845

Epoch: 6| Step: 10
Training loss: 1.3184115886688232
Validation loss: 1.856981441538821

Epoch: 6| Step: 11
Training loss: 2.177943229675293
Validation loss: 1.8844337899197814

Epoch: 6| Step: 12
Training loss: 2.2487292289733887
Validation loss: 1.8344374061912618

Epoch: 6| Step: 13
Training loss: 1.5932549238204956
Validation loss: 1.8237537312251266

Epoch: 228| Step: 0
Training loss: 1.9904847145080566
Validation loss: 1.8866631536073581

Epoch: 6| Step: 1
Training loss: 1.256261944770813
Validation loss: 1.8222596171081706

Epoch: 6| Step: 2
Training loss: 1.8444852828979492
Validation loss: 1.8336618959262807

Epoch: 6| Step: 3
Training loss: 2.1372017860412598
Validation loss: 1.8723110460465955

Epoch: 6| Step: 4
Training loss: 1.5102598667144775
Validation loss: 1.861322828518447

Epoch: 6| Step: 5
Training loss: 1.9264013767242432
Validation loss: 1.8859153921886156

Epoch: 6| Step: 6
Training loss: 1.7351126670837402
Validation loss: 1.8983798757676156

Epoch: 6| Step: 7
Training loss: 1.5281051397323608
Validation loss: 1.9428639206835019

Epoch: 6| Step: 8
Training loss: 1.8895487785339355
Validation loss: 1.9415959312069802

Epoch: 6| Step: 9
Training loss: 1.512037754058838
Validation loss: 1.9112127442513742

Epoch: 6| Step: 10
Training loss: 1.3008681535720825
Validation loss: 1.9173067513332571

Epoch: 6| Step: 11
Training loss: 1.5455224514007568
Validation loss: 1.9091402843434324

Epoch: 6| Step: 12
Training loss: 1.0120606422424316
Validation loss: 1.8968957688218804

Epoch: 6| Step: 13
Training loss: 2.10388445854187
Validation loss: 1.878331066459738

Epoch: 229| Step: 0
Training loss: 1.6774741411209106
Validation loss: 1.8524506861163723

Epoch: 6| Step: 1
Training loss: 1.8298799991607666
Validation loss: 1.8487917095102289

Epoch: 6| Step: 2
Training loss: 1.2484546899795532
Validation loss: 1.866091940992622

Epoch: 6| Step: 3
Training loss: 1.2250430583953857
Validation loss: 1.8721357225089945

Epoch: 6| Step: 4
Training loss: 1.4807417392730713
Validation loss: 1.8510902235584874

Epoch: 6| Step: 5
Training loss: 1.179166316986084
Validation loss: 1.846545442458122

Epoch: 6| Step: 6
Training loss: 1.9990276098251343
Validation loss: 1.8747810830352127

Epoch: 6| Step: 7
Training loss: 1.771963119506836
Validation loss: 1.8703559560160483

Epoch: 6| Step: 8
Training loss: 2.346482276916504
Validation loss: 1.8456141294971589

Epoch: 6| Step: 9
Training loss: 1.2733337879180908
Validation loss: 1.8138333853854929

Epoch: 6| Step: 10
Training loss: 1.651699185371399
Validation loss: 1.8534806748872161

Epoch: 6| Step: 11
Training loss: 1.4601995944976807
Validation loss: 1.86629198187141

Epoch: 6| Step: 12
Training loss: 2.0447356700897217
Validation loss: 1.884370219322943

Epoch: 6| Step: 13
Training loss: 1.4461368322372437
Validation loss: 1.836985291973237

Epoch: 230| Step: 0
Training loss: 2.470588445663452
Validation loss: 1.8510429282342233

Epoch: 6| Step: 1
Training loss: 2.0729308128356934
Validation loss: 1.863083638170714

Epoch: 6| Step: 2
Training loss: 1.196500539779663
Validation loss: 1.8504712991817023

Epoch: 6| Step: 3
Training loss: 1.7032593488693237
Validation loss: 1.8392223004371888

Epoch: 6| Step: 4
Training loss: 1.7379173040390015
Validation loss: 1.8751809981561476

Epoch: 6| Step: 5
Training loss: 1.4399362802505493
Validation loss: 1.8728320342238232

Epoch: 6| Step: 6
Training loss: 1.8728857040405273
Validation loss: 1.878326622388696

Epoch: 6| Step: 7
Training loss: 0.8006919622421265
Validation loss: 1.8433039624203917

Epoch: 6| Step: 8
Training loss: 2.007758140563965
Validation loss: 1.838852515784643

Epoch: 6| Step: 9
Training loss: 1.3144475221633911
Validation loss: 1.8654086269358152

Epoch: 6| Step: 10
Training loss: 1.4438879489898682
Validation loss: 1.8744538086716847

Epoch: 6| Step: 11
Training loss: 1.5764693021774292
Validation loss: 1.8618193159821212

Epoch: 6| Step: 12
Training loss: 1.768207311630249
Validation loss: 1.843817517321597

Epoch: 6| Step: 13
Training loss: 1.3196020126342773
Validation loss: 1.8626577751610869

Epoch: 231| Step: 0
Training loss: 1.325448989868164
Validation loss: 1.8612686434099752

Epoch: 6| Step: 1
Training loss: 1.212033987045288
Validation loss: 1.8372253692278298

Epoch: 6| Step: 2
Training loss: 2.683957099914551
Validation loss: 1.8743695302676129

Epoch: 6| Step: 3
Training loss: 2.3140017986297607
Validation loss: 1.8543985120711788

Epoch: 6| Step: 4
Training loss: 1.701984167098999
Validation loss: 1.8813888129367624

Epoch: 6| Step: 5
Training loss: 1.2712290287017822
Validation loss: 1.8356723426490702

Epoch: 6| Step: 6
Training loss: 1.4722081422805786
Validation loss: 1.8666231196413758

Epoch: 6| Step: 7
Training loss: 1.459096908569336
Validation loss: 1.8754283728138093

Epoch: 6| Step: 8
Training loss: 1.5031344890594482
Validation loss: 1.8966496067662393

Epoch: 6| Step: 9
Training loss: 2.115971565246582
Validation loss: 1.8507729820025864

Epoch: 6| Step: 10
Training loss: 1.270878553390503
Validation loss: 1.8602030943798762

Epoch: 6| Step: 11
Training loss: 1.9402730464935303
Validation loss: 1.832665430602207

Epoch: 6| Step: 12
Training loss: 0.8291328549385071
Validation loss: 1.8272154267116258

Epoch: 6| Step: 13
Training loss: 1.7541260719299316
Validation loss: 1.8530380751497002

Epoch: 232| Step: 0
Training loss: 1.862374186515808
Validation loss: 1.8559187996772029

Epoch: 6| Step: 1
Training loss: 1.999403715133667
Validation loss: 1.8456960596064085

Epoch: 6| Step: 2
Training loss: 1.6058824062347412
Validation loss: 1.846808220750542

Epoch: 6| Step: 3
Training loss: 2.0042858123779297
Validation loss: 1.8507602240449639

Epoch: 6| Step: 4
Training loss: 1.2292280197143555
Validation loss: 1.8266146311195948

Epoch: 6| Step: 5
Training loss: 1.484023094177246
Validation loss: 1.8353408536603373

Epoch: 6| Step: 6
Training loss: 1.608720302581787
Validation loss: 1.8501201932148268

Epoch: 6| Step: 7
Training loss: 1.3399567604064941
Validation loss: 1.8793005815116308

Epoch: 6| Step: 8
Training loss: 1.8147945404052734
Validation loss: 1.8456050516456686

Epoch: 6| Step: 9
Training loss: 1.374248743057251
Validation loss: 1.8309938561531804

Epoch: 6| Step: 10
Training loss: 2.2116575241088867
Validation loss: 1.8284991261779622

Epoch: 6| Step: 11
Training loss: 1.3479151725769043
Validation loss: 1.8619181186922136

Epoch: 6| Step: 12
Training loss: 1.6338087320327759
Validation loss: 1.860478437075051

Epoch: 6| Step: 13
Training loss: 1.3180928230285645
Validation loss: 1.8554010916781682

Epoch: 233| Step: 0
Training loss: 2.168696165084839
Validation loss: 1.8961678704907816

Epoch: 6| Step: 1
Training loss: 1.0419113636016846
Validation loss: 1.8890263777907177

Epoch: 6| Step: 2
Training loss: 1.8813848495483398
Validation loss: 1.8768366536786478

Epoch: 6| Step: 3
Training loss: 1.5787270069122314
Validation loss: 1.9072688702614076

Epoch: 6| Step: 4
Training loss: 2.5474820137023926
Validation loss: 1.9427181572042487

Epoch: 6| Step: 5
Training loss: 2.220508575439453
Validation loss: 1.9348066237664991

Epoch: 6| Step: 6
Training loss: 1.4179582595825195
Validation loss: 1.9433318350904731

Epoch: 6| Step: 7
Training loss: 1.0972034931182861
Validation loss: 1.947533046045611

Epoch: 6| Step: 8
Training loss: 1.663144588470459
Validation loss: 1.9189458970100648

Epoch: 6| Step: 9
Training loss: 2.2021799087524414
Validation loss: 1.926584420665618

Epoch: 6| Step: 10
Training loss: 1.0430548191070557
Validation loss: 1.9214830347286758

Epoch: 6| Step: 11
Training loss: 1.2358366250991821
Validation loss: 1.8932863179073538

Epoch: 6| Step: 12
Training loss: 1.4133117198944092
Validation loss: 1.8813589926688903

Epoch: 6| Step: 13
Training loss: 1.7385553121566772
Validation loss: 1.8934468915385585

Epoch: 234| Step: 0
Training loss: 2.1003692150115967
Validation loss: 1.8813584581498177

Epoch: 6| Step: 1
Training loss: 1.6466412544250488
Validation loss: 1.8800331302868423

Epoch: 6| Step: 2
Training loss: 1.6545770168304443
Validation loss: 1.8683401576934322

Epoch: 6| Step: 3
Training loss: 1.1596612930297852
Validation loss: 1.8578407943889659

Epoch: 6| Step: 4
Training loss: 1.6746704578399658
Validation loss: 1.8595160976532967

Epoch: 6| Step: 5
Training loss: 2.137716054916382
Validation loss: 1.845953208143993

Epoch: 6| Step: 6
Training loss: 1.5028181076049805
Validation loss: 1.8461560010910034

Epoch: 6| Step: 7
Training loss: 1.297916054725647
Validation loss: 1.8776490854960617

Epoch: 6| Step: 8
Training loss: 1.9854813814163208
Validation loss: 1.8506093730208695

Epoch: 6| Step: 9
Training loss: 1.568022608757019
Validation loss: 1.8458020123102332

Epoch: 6| Step: 10
Training loss: 1.1699494123458862
Validation loss: 1.8585964300299203

Epoch: 6| Step: 11
Training loss: 1.049938678741455
Validation loss: 1.8653582257609214

Epoch: 6| Step: 12
Training loss: 2.277390718460083
Validation loss: 1.8309382213059293

Epoch: 6| Step: 13
Training loss: 1.2237287759780884
Validation loss: 1.8825605505256242

Epoch: 235| Step: 0
Training loss: 1.6161205768585205
Validation loss: 1.8624662737692557

Epoch: 6| Step: 1
Training loss: 1.82916259765625
Validation loss: 1.8669033588901642

Epoch: 6| Step: 2
Training loss: 1.4396556615829468
Validation loss: 1.8446243937297533

Epoch: 6| Step: 3
Training loss: 1.2576098442077637
Validation loss: 1.853094406025384

Epoch: 6| Step: 4
Training loss: 2.043020725250244
Validation loss: 1.8502963922357047

Epoch: 6| Step: 5
Training loss: 1.8070377111434937
Validation loss: 1.84696013440368

Epoch: 6| Step: 6
Training loss: 2.109877347946167
Validation loss: 1.879896548486525

Epoch: 6| Step: 7
Training loss: 1.8848429918289185
Validation loss: 1.8636310331283077

Epoch: 6| Step: 8
Training loss: 1.5032167434692383
Validation loss: 1.858975855253076

Epoch: 6| Step: 9
Training loss: 1.1392714977264404
Validation loss: 1.902791589818975

Epoch: 6| Step: 10
Training loss: 1.466286540031433
Validation loss: 1.8506669741804882

Epoch: 6| Step: 11
Training loss: 1.1139910221099854
Validation loss: 1.8836690431000085

Epoch: 6| Step: 12
Training loss: 1.425438642501831
Validation loss: 1.8520383745111444

Epoch: 6| Step: 13
Training loss: 2.117248058319092
Validation loss: 1.8793199036711006

Epoch: 236| Step: 0
Training loss: 1.2008028030395508
Validation loss: 1.8450477097624092

Epoch: 6| Step: 1
Training loss: 1.6105504035949707
Validation loss: 1.8813885027362454

Epoch: 6| Step: 2
Training loss: 1.3018386363983154
Validation loss: 1.8683490971083283

Epoch: 6| Step: 3
Training loss: 1.668931245803833
Validation loss: 1.856302712553291

Epoch: 6| Step: 4
Training loss: 1.835532784461975
Validation loss: 1.8472275028946579

Epoch: 6| Step: 5
Training loss: 1.4811692237854004
Validation loss: 1.8706282466970465

Epoch: 6| Step: 6
Training loss: 1.789780616760254
Validation loss: 1.8649013555178078

Epoch: 6| Step: 7
Training loss: 1.6574573516845703
Validation loss: 1.8247243588970554

Epoch: 6| Step: 8
Training loss: 1.2281497716903687
Validation loss: 1.8927485507021669

Epoch: 6| Step: 9
Training loss: 1.901023268699646
Validation loss: 1.8949674624268726

Epoch: 6| Step: 10
Training loss: 1.5517858266830444
Validation loss: 1.884147226169545

Epoch: 6| Step: 11
Training loss: 2.077989101409912
Validation loss: 1.8651640953556183

Epoch: 6| Step: 12
Training loss: 1.5957823991775513
Validation loss: 1.878020986433952

Epoch: 6| Step: 13
Training loss: 1.378311276435852
Validation loss: 1.8503152580671414

Epoch: 237| Step: 0
Training loss: 2.060924768447876
Validation loss: 1.8732867561360842

Epoch: 6| Step: 1
Training loss: 1.7765917778015137
Validation loss: 1.8612101090851652

Epoch: 6| Step: 2
Training loss: 1.965123176574707
Validation loss: 1.846575319126088

Epoch: 6| Step: 3
Training loss: 2.2163286209106445
Validation loss: 1.8286471700155607

Epoch: 6| Step: 4
Training loss: 1.5928735733032227
Validation loss: 1.894319172828428

Epoch: 6| Step: 5
Training loss: 1.7169480323791504
Validation loss: 1.833162260311906

Epoch: 6| Step: 6
Training loss: 1.1031630039215088
Validation loss: 1.8769224818034838

Epoch: 6| Step: 7
Training loss: 1.4783735275268555
Validation loss: 1.850519774421569

Epoch: 6| Step: 8
Training loss: 1.320881724357605
Validation loss: 1.8352857033411663

Epoch: 6| Step: 9
Training loss: 1.4740629196166992
Validation loss: 1.8496166031847718

Epoch: 6| Step: 10
Training loss: 1.6870620250701904
Validation loss: 1.8471847375233967

Epoch: 6| Step: 11
Training loss: 1.7761794328689575
Validation loss: 1.8736854394276936

Epoch: 6| Step: 12
Training loss: 1.021005630493164
Validation loss: 1.8413953640127694

Epoch: 6| Step: 13
Training loss: 1.5706983804702759
Validation loss: 1.8444222724565895

Epoch: 238| Step: 0
Training loss: 1.3078480958938599
Validation loss: 1.8328493666905228

Epoch: 6| Step: 1
Training loss: 1.2896687984466553
Validation loss: 1.886679268652393

Epoch: 6| Step: 2
Training loss: 1.5657835006713867
Validation loss: 1.8362291269404913

Epoch: 6| Step: 3
Training loss: 1.0851839780807495
Validation loss: 1.8555484689692014

Epoch: 6| Step: 4
Training loss: 1.9832186698913574
Validation loss: 1.884073652246947

Epoch: 6| Step: 5
Training loss: 1.5804665088653564
Validation loss: 1.873525454152015

Epoch: 6| Step: 6
Training loss: 1.7341886758804321
Validation loss: 1.8552455248371247

Epoch: 6| Step: 7
Training loss: 2.0226216316223145
Validation loss: 1.863361116378538

Epoch: 6| Step: 8
Training loss: 1.5179641246795654
Validation loss: 1.8738260602438321

Epoch: 6| Step: 9
Training loss: 2.414304256439209
Validation loss: 1.846615429847471

Epoch: 6| Step: 10
Training loss: 1.8466377258300781
Validation loss: 1.8772495651757846

Epoch: 6| Step: 11
Training loss: 1.152184009552002
Validation loss: 1.861918007173846

Epoch: 6| Step: 12
Training loss: 1.4793795347213745
Validation loss: 1.8645779932698896

Epoch: 6| Step: 13
Training loss: 1.4456725120544434
Validation loss: 1.8667471075570712

Epoch: 239| Step: 0
Training loss: 1.7881693840026855
Validation loss: 1.896862623512104

Epoch: 6| Step: 1
Training loss: 1.5796719789505005
Validation loss: 1.8501819205540482

Epoch: 6| Step: 2
Training loss: 1.6018681526184082
Validation loss: 1.8592932352455713

Epoch: 6| Step: 3
Training loss: 2.386075258255005
Validation loss: 1.842980234853683

Epoch: 6| Step: 4
Training loss: 1.1697888374328613
Validation loss: 1.8392607627376434

Epoch: 6| Step: 5
Training loss: 2.255406618118286
Validation loss: 1.8231968866881503

Epoch: 6| Step: 6
Training loss: 1.605942726135254
Validation loss: 1.8536427533754738

Epoch: 6| Step: 7
Training loss: 1.5064704418182373
Validation loss: 1.8550964696432954

Epoch: 6| Step: 8
Training loss: 1.1449964046478271
Validation loss: 1.851328617783003

Epoch: 6| Step: 9
Training loss: 1.475770115852356
Validation loss: 1.849909338899838

Epoch: 6| Step: 10
Training loss: 1.617814302444458
Validation loss: 1.839675284201099

Epoch: 6| Step: 11
Training loss: 1.589089035987854
Validation loss: 1.843240531541968

Epoch: 6| Step: 12
Training loss: 0.9185851812362671
Validation loss: 1.869337494655322

Epoch: 6| Step: 13
Training loss: 1.7889336347579956
Validation loss: 1.8568646869351786

Epoch: 240| Step: 0
Training loss: 1.536383867263794
Validation loss: 1.8862070986019668

Epoch: 6| Step: 1
Training loss: 1.7833030223846436
Validation loss: 1.8782247997099353

Epoch: 6| Step: 2
Training loss: 1.7039339542388916
Validation loss: 1.861114473753078

Epoch: 6| Step: 3
Training loss: 1.6660236120224
Validation loss: 1.8591169759791384

Epoch: 6| Step: 4
Training loss: 0.9844841957092285
Validation loss: 1.9066904885794527

Epoch: 6| Step: 5
Training loss: 1.9153425693511963
Validation loss: 1.8524218246500979

Epoch: 6| Step: 6
Training loss: 0.9737668633460999
Validation loss: 1.9014266306354153

Epoch: 6| Step: 7
Training loss: 1.994551658630371
Validation loss: 1.8651462626713577

Epoch: 6| Step: 8
Training loss: 1.442633867263794
Validation loss: 1.8428438094354445

Epoch: 6| Step: 9
Training loss: 2.0109853744506836
Validation loss: 1.8361462598205895

Epoch: 6| Step: 10
Training loss: 1.0879623889923096
Validation loss: 1.8536327346678703

Epoch: 6| Step: 11
Training loss: 1.8208874464035034
Validation loss: 1.877509791363952

Epoch: 6| Step: 12
Training loss: 1.8055626153945923
Validation loss: 1.852447558474797

Epoch: 6| Step: 13
Training loss: 1.5494354963302612
Validation loss: 1.853994596389032

Epoch: 241| Step: 0
Training loss: 1.307593584060669
Validation loss: 1.8794033142828173

Epoch: 6| Step: 1
Training loss: 1.6476027965545654
Validation loss: 1.8739981753851778

Epoch: 6| Step: 2
Training loss: 1.8372111320495605
Validation loss: 1.8862259323878954

Epoch: 6| Step: 3
Training loss: 2.1997740268707275
Validation loss: 1.8677312186969224

Epoch: 6| Step: 4
Training loss: 2.454927444458008
Validation loss: 1.8740643198772142

Epoch: 6| Step: 5
Training loss: 1.4854986667633057
Validation loss: 1.8922042487769999

Epoch: 6| Step: 6
Training loss: 1.6768723726272583
Validation loss: 1.8856750598517797

Epoch: 6| Step: 7
Training loss: 2.033568859100342
Validation loss: 1.9429348617471673

Epoch: 6| Step: 8
Training loss: 1.7003875970840454
Validation loss: 1.891435182222756

Epoch: 6| Step: 9
Training loss: 1.2421379089355469
Validation loss: 1.8855267775956022

Epoch: 6| Step: 10
Training loss: 1.1431794166564941
Validation loss: 1.8706166180231238

Epoch: 6| Step: 11
Training loss: 0.8367093205451965
Validation loss: 1.8790211293005175

Epoch: 6| Step: 12
Training loss: 1.3272820711135864
Validation loss: 1.8823508011397494

Epoch: 6| Step: 13
Training loss: 2.2011497020721436
Validation loss: 1.8556260934440039

Epoch: 242| Step: 0
Training loss: 1.7135305404663086
Validation loss: 1.8554444338685723

Epoch: 6| Step: 1
Training loss: 1.7161717414855957
Validation loss: 1.852680794654354

Epoch: 6| Step: 2
Training loss: 1.5876383781433105
Validation loss: 1.8519408984850811

Epoch: 6| Step: 3
Training loss: 1.3635978698730469
Validation loss: 1.8242948337267804

Epoch: 6| Step: 4
Training loss: 1.1013519763946533
Validation loss: 1.876539372628735

Epoch: 6| Step: 5
Training loss: 1.2473154067993164
Validation loss: 1.8481824808223273

Epoch: 6| Step: 6
Training loss: 2.05062198638916
Validation loss: 1.852723454916349

Epoch: 6| Step: 7
Training loss: 2.0076637268066406
Validation loss: 1.8569375135565316

Epoch: 6| Step: 8
Training loss: 1.1589158773422241
Validation loss: 1.8337241334299887

Epoch: 6| Step: 9
Training loss: 1.716073751449585
Validation loss: 1.8339505400708926

Epoch: 6| Step: 10
Training loss: 1.2270607948303223
Validation loss: 1.8603984002144105

Epoch: 6| Step: 11
Training loss: 2.821377754211426
Validation loss: 1.84267710485766

Epoch: 6| Step: 12
Training loss: 1.2950234413146973
Validation loss: 1.8421637460749636

Epoch: 6| Step: 13
Training loss: 0.9386256337165833
Validation loss: 1.8580847914500902

Epoch: 243| Step: 0
Training loss: 1.0939834117889404
Validation loss: 1.8421668147528043

Epoch: 6| Step: 1
Training loss: 1.4952905178070068
Validation loss: 1.8573893526548981

Epoch: 6| Step: 2
Training loss: 1.5734832286834717
Validation loss: 1.8675057195848035

Epoch: 6| Step: 3
Training loss: 1.44728422164917
Validation loss: 1.8590201344541324

Epoch: 6| Step: 4
Training loss: 2.2919540405273438
Validation loss: 1.864608979994251

Epoch: 6| Step: 5
Training loss: 1.5988502502441406
Validation loss: 1.8384967055372012

Epoch: 6| Step: 6
Training loss: 1.3127448558807373
Validation loss: 1.833408360840172

Epoch: 6| Step: 7
Training loss: 1.167854905128479
Validation loss: 1.877476123071486

Epoch: 6| Step: 8
Training loss: 1.5623093843460083
Validation loss: 1.8775152429457633

Epoch: 6| Step: 9
Training loss: 2.1689062118530273
Validation loss: 1.845397295490388

Epoch: 6| Step: 10
Training loss: 1.810556173324585
Validation loss: 1.8602482336823658

Epoch: 6| Step: 11
Training loss: 1.2689399719238281
Validation loss: 1.8678131795698596

Epoch: 6| Step: 12
Training loss: 1.4120436906814575
Validation loss: 1.8145088559837752

Epoch: 6| Step: 13
Training loss: 2.3903703689575195
Validation loss: 1.8554252168183685

Epoch: 244| Step: 0
Training loss: 1.9218089580535889
Validation loss: 1.8191977841879732

Epoch: 6| Step: 1
Training loss: 1.6814906597137451
Validation loss: 1.8368723610396027

Epoch: 6| Step: 2
Training loss: 1.2281627655029297
Validation loss: 1.8702408216332878

Epoch: 6| Step: 3
Training loss: 1.0197374820709229
Validation loss: 1.83373543395791

Epoch: 6| Step: 4
Training loss: 1.2295665740966797
Validation loss: 1.8488870436145413

Epoch: 6| Step: 5
Training loss: 1.5564236640930176
Validation loss: 1.8075644521303074

Epoch: 6| Step: 6
Training loss: 2.6072869300842285
Validation loss: 1.8331000651082685

Epoch: 6| Step: 7
Training loss: 1.3913823366165161
Validation loss: 1.8242578121923632

Epoch: 6| Step: 8
Training loss: 1.6734554767608643
Validation loss: 1.8265814832461778

Epoch: 6| Step: 9
Training loss: 1.4617578983306885
Validation loss: 1.8447836355496479

Epoch: 6| Step: 10
Training loss: 1.6554474830627441
Validation loss: 1.869681930029264

Epoch: 6| Step: 11
Training loss: 2.0400919914245605
Validation loss: 1.8869905189801288

Epoch: 6| Step: 12
Training loss: 1.2583611011505127
Validation loss: 1.8283717965566983

Epoch: 6| Step: 13
Training loss: 1.5588512420654297
Validation loss: 1.8527425489118021

Epoch: 245| Step: 0
Training loss: 1.3815340995788574
Validation loss: 1.863880133116117

Epoch: 6| Step: 1
Training loss: 2.0994765758514404
Validation loss: 1.8433811997854581

Epoch: 6| Step: 2
Training loss: 1.470170497894287
Validation loss: 1.8455857076952535

Epoch: 6| Step: 3
Training loss: 1.7629824876785278
Validation loss: 1.8681338346132668

Epoch: 6| Step: 4
Training loss: 2.0011630058288574
Validation loss: 1.8293763309396722

Epoch: 6| Step: 5
Training loss: 1.3348543643951416
Validation loss: 1.8517466232340822

Epoch: 6| Step: 6
Training loss: 1.8274011611938477
Validation loss: 1.840852806645055

Epoch: 6| Step: 7
Training loss: 0.9746148586273193
Validation loss: 1.8374269098363898

Epoch: 6| Step: 8
Training loss: 1.9777703285217285
Validation loss: 1.8527357603913994

Epoch: 6| Step: 9
Training loss: 1.0457531213760376
Validation loss: 1.865627952801284

Epoch: 6| Step: 10
Training loss: 1.8258249759674072
Validation loss: 1.8344245790153422

Epoch: 6| Step: 11
Training loss: 1.0003602504730225
Validation loss: 1.8208259856829079

Epoch: 6| Step: 12
Training loss: 1.9749038219451904
Validation loss: 1.8340393253552016

Epoch: 6| Step: 13
Training loss: 1.6494451761245728
Validation loss: 1.8609480947576544

Epoch: 246| Step: 0
Training loss: 1.5289905071258545
Validation loss: 1.848445571878905

Epoch: 6| Step: 1
Training loss: 0.7994258999824524
Validation loss: 1.8828981358517882

Epoch: 6| Step: 2
Training loss: 2.0497984886169434
Validation loss: 1.8630944195614065

Epoch: 6| Step: 3
Training loss: 1.8249084949493408
Validation loss: 1.8566027200350197

Epoch: 6| Step: 4
Training loss: 1.8076984882354736
Validation loss: 1.826688761352211

Epoch: 6| Step: 5
Training loss: 1.5288861989974976
Validation loss: 1.8419425436245498

Epoch: 6| Step: 6
Training loss: 1.448968529701233
Validation loss: 1.8298574711686821

Epoch: 6| Step: 7
Training loss: 1.496274709701538
Validation loss: 1.8640143422670261

Epoch: 6| Step: 8
Training loss: 1.3714063167572021
Validation loss: 1.828308900197347

Epoch: 6| Step: 9
Training loss: 1.9251426458358765
Validation loss: 1.8209096475314068

Epoch: 6| Step: 10
Training loss: 1.9683005809783936
Validation loss: 1.8628373453694005

Epoch: 6| Step: 11
Training loss: 1.292471170425415
Validation loss: 1.8313944493570635

Epoch: 6| Step: 12
Training loss: 1.3286181688308716
Validation loss: 1.8525306614496375

Epoch: 6| Step: 13
Training loss: 1.3904880285263062
Validation loss: 1.8584804073456795

Epoch: 247| Step: 0
Training loss: 1.5495060682296753
Validation loss: 1.8487164794757802

Epoch: 6| Step: 1
Training loss: 1.433803677558899
Validation loss: 1.8556248090600456

Epoch: 6| Step: 2
Training loss: 1.4012881517410278
Validation loss: 1.830161492029826

Epoch: 6| Step: 3
Training loss: 1.3353722095489502
Validation loss: 1.8722047498149257

Epoch: 6| Step: 4
Training loss: 1.7039908170700073
Validation loss: 1.849862426839849

Epoch: 6| Step: 5
Training loss: 2.241143226623535
Validation loss: 1.8517256398354807

Epoch: 6| Step: 6
Training loss: 1.4901001453399658
Validation loss: 1.8747205990616993

Epoch: 6| Step: 7
Training loss: 1.806997537612915
Validation loss: 1.863476509689003

Epoch: 6| Step: 8
Training loss: 1.617537260055542
Validation loss: 1.857675886923267

Epoch: 6| Step: 9
Training loss: 1.1704304218292236
Validation loss: 1.8553925816730787

Epoch: 6| Step: 10
Training loss: 1.4983735084533691
Validation loss: 1.8517329026294012

Epoch: 6| Step: 11
Training loss: 1.5789859294891357
Validation loss: 1.8694972966306953

Epoch: 6| Step: 12
Training loss: 1.709478735923767
Validation loss: 1.8646212341964885

Epoch: 6| Step: 13
Training loss: 1.0574979782104492
Validation loss: 1.9190170431649813

Epoch: 248| Step: 0
Training loss: 1.7822561264038086
Validation loss: 1.818131769857099

Epoch: 6| Step: 1
Training loss: 1.7574717998504639
Validation loss: 1.867802276406237

Epoch: 6| Step: 2
Training loss: 1.9726742506027222
Validation loss: 1.8646807093774118

Epoch: 6| Step: 3
Training loss: 1.6854544878005981
Validation loss: 1.8636691211372294

Epoch: 6| Step: 4
Training loss: 1.3732657432556152
Validation loss: 1.8475791010805356

Epoch: 6| Step: 5
Training loss: 2.165635585784912
Validation loss: 1.8215797998571908

Epoch: 6| Step: 6
Training loss: 1.0399936437606812
Validation loss: 1.8217519944713962

Epoch: 6| Step: 7
Training loss: 1.321519136428833
Validation loss: 1.8454259211017239

Epoch: 6| Step: 8
Training loss: 1.6027586460113525
Validation loss: 1.8576189548738542

Epoch: 6| Step: 9
Training loss: 1.003949761390686
Validation loss: 1.8512206756940452

Epoch: 6| Step: 10
Training loss: 1.920843243598938
Validation loss: 1.8103493926345662

Epoch: 6| Step: 11
Training loss: 0.7907770872116089
Validation loss: 1.8535113514110606

Epoch: 6| Step: 12
Training loss: 2.277242660522461
Validation loss: 1.8402352973979006

Epoch: 6| Step: 13
Training loss: 1.6968929767608643
Validation loss: 1.8412351351912304

Epoch: 249| Step: 0
Training loss: 1.283048391342163
Validation loss: 1.8602622606421029

Epoch: 6| Step: 1
Training loss: 1.959730625152588
Validation loss: 1.8359544815555695

Epoch: 6| Step: 2
Training loss: 1.7585965394973755
Validation loss: 1.8300639455036452

Epoch: 6| Step: 3
Training loss: 1.5887244939804077
Validation loss: 1.8448386717868108

Epoch: 6| Step: 4
Training loss: 1.327939748764038
Validation loss: 1.8944135763311898

Epoch: 6| Step: 5
Training loss: 1.7381547689437866
Validation loss: 1.874134103457133

Epoch: 6| Step: 6
Training loss: 1.331529140472412
Validation loss: 1.8934614863446964

Epoch: 6| Step: 7
Training loss: 1.089693546295166
Validation loss: 1.8579964958211428

Epoch: 6| Step: 8
Training loss: 1.6972407102584839
Validation loss: 1.861881471449329

Epoch: 6| Step: 9
Training loss: 1.9153434038162231
Validation loss: 1.8647292416582826

Epoch: 6| Step: 10
Training loss: 2.3619585037231445
Validation loss: 1.8621588881297777

Epoch: 6| Step: 11
Training loss: 1.1324875354766846
Validation loss: 1.8734079214834398

Epoch: 6| Step: 12
Training loss: 1.8653299808502197
Validation loss: 1.8402471362903554

Epoch: 6| Step: 13
Training loss: 0.9742039442062378
Validation loss: 1.8580219271362468

Epoch: 250| Step: 0
Training loss: 1.476945400238037
Validation loss: 1.8570166159701604

Epoch: 6| Step: 1
Training loss: 1.83677339553833
Validation loss: 1.8149631331043858

Epoch: 6| Step: 2
Training loss: 1.9399821758270264
Validation loss: 1.8314018890421877

Epoch: 6| Step: 3
Training loss: 1.2486103773117065
Validation loss: 1.841978592257346

Epoch: 6| Step: 4
Training loss: 1.862208366394043
Validation loss: 1.825977135730046

Epoch: 6| Step: 5
Training loss: 1.5916929244995117
Validation loss: 1.8332961105531262

Epoch: 6| Step: 6
Training loss: 1.7273732423782349
Validation loss: 1.815173723364389

Epoch: 6| Step: 7
Training loss: 1.600338101387024
Validation loss: 1.8148871737141763

Epoch: 6| Step: 8
Training loss: 1.4754340648651123
Validation loss: 1.8447042536991898

Epoch: 6| Step: 9
Training loss: 1.4962916374206543
Validation loss: 1.854050354291034

Epoch: 6| Step: 10
Training loss: 0.8560576438903809
Validation loss: 1.8538005634020733

Epoch: 6| Step: 11
Training loss: 1.3134939670562744
Validation loss: 1.8660617720696233

Epoch: 6| Step: 12
Training loss: 1.6280831098556519
Validation loss: 1.8647480972351567

Epoch: 6| Step: 13
Training loss: 2.1650147438049316
Validation loss: 1.8297105437965804

Epoch: 251| Step: 0
Training loss: 1.5899420976638794
Validation loss: 1.825315793355306

Epoch: 6| Step: 1
Training loss: 1.580249547958374
Validation loss: 1.8626019877772177

Epoch: 6| Step: 2
Training loss: 1.2773981094360352
Validation loss: 1.850314833784616

Epoch: 6| Step: 3
Training loss: 1.2187869548797607
Validation loss: 1.8261182692743116

Epoch: 6| Step: 4
Training loss: 1.8219317197799683
Validation loss: 1.8515685335282357

Epoch: 6| Step: 5
Training loss: 2.020540714263916
Validation loss: 1.8760011119227256

Epoch: 6| Step: 6
Training loss: 1.822176456451416
Validation loss: 1.8431393356733425

Epoch: 6| Step: 7
Training loss: 1.0676164627075195
Validation loss: 1.8435310381715015

Epoch: 6| Step: 8
Training loss: 1.6272776126861572
Validation loss: 1.8708577925159084

Epoch: 6| Step: 9
Training loss: 1.4701566696166992
Validation loss: 1.8420823261302004

Epoch: 6| Step: 10
Training loss: 1.9432740211486816
Validation loss: 1.7941803278461579

Epoch: 6| Step: 11
Training loss: 1.8055719137191772
Validation loss: 1.8417600675295758

Epoch: 6| Step: 12
Training loss: 1.312842845916748
Validation loss: 1.8383454097214567

Epoch: 6| Step: 13
Training loss: 1.491042137145996
Validation loss: 1.8579548430699173

Epoch: 252| Step: 0
Training loss: 2.1946890354156494
Validation loss: 1.833552634844216

Epoch: 6| Step: 1
Training loss: 1.3477230072021484
Validation loss: 1.8491207117675452

Epoch: 6| Step: 2
Training loss: 1.6538877487182617
Validation loss: 1.8484299118800829

Epoch: 6| Step: 3
Training loss: 1.6061439514160156
Validation loss: 1.8199710602401404

Epoch: 6| Step: 4
Training loss: 1.2625484466552734
Validation loss: 1.8345495244508148

Epoch: 6| Step: 5
Training loss: 1.9791308641433716
Validation loss: 1.8021071995458295

Epoch: 6| Step: 6
Training loss: 1.3092191219329834
Validation loss: 1.8329866368283507

Epoch: 6| Step: 7
Training loss: 1.821445107460022
Validation loss: 1.8410804425516436

Epoch: 6| Step: 8
Training loss: 1.8356894254684448
Validation loss: 1.8309609979711554

Epoch: 6| Step: 9
Training loss: 0.8733760714530945
Validation loss: 1.8490466584441483

Epoch: 6| Step: 10
Training loss: 1.9458339214324951
Validation loss: 1.8128819863001506

Epoch: 6| Step: 11
Training loss: 1.394386887550354
Validation loss: 1.8404037183330906

Epoch: 6| Step: 12
Training loss: 0.9934032559394836
Validation loss: 1.9009014739785144

Epoch: 6| Step: 13
Training loss: 1.1570805311203003
Validation loss: 1.8450378500005251

Epoch: 253| Step: 0
Training loss: 1.6139979362487793
Validation loss: 1.8760010580862723

Epoch: 6| Step: 1
Training loss: 1.9338037967681885
Validation loss: 1.891896427318614

Epoch: 6| Step: 2
Training loss: 1.8315538167953491
Validation loss: 1.9212623180881623

Epoch: 6| Step: 3
Training loss: 1.6010490655899048
Validation loss: 1.9036856338541994

Epoch: 6| Step: 4
Training loss: 0.9350969791412354
Validation loss: 1.9241480750422324

Epoch: 6| Step: 5
Training loss: 1.668325424194336
Validation loss: 1.919492096029302

Epoch: 6| Step: 6
Training loss: 1.2663064002990723
Validation loss: 1.9226501218734249

Epoch: 6| Step: 7
Training loss: 1.7674087285995483
Validation loss: 1.8819233012455765

Epoch: 6| Step: 8
Training loss: 1.8045644760131836
Validation loss: 1.9034581581751506

Epoch: 6| Step: 9
Training loss: 0.9946340322494507
Validation loss: 1.9210902196104809

Epoch: 6| Step: 10
Training loss: 1.8199942111968994
Validation loss: 1.8773761449321624

Epoch: 6| Step: 11
Training loss: 1.7097485065460205
Validation loss: 1.8932643218707013

Epoch: 6| Step: 12
Training loss: 1.4734230041503906
Validation loss: 1.865733237676723

Epoch: 6| Step: 13
Training loss: 1.34150230884552
Validation loss: 1.8439580112375238

Epoch: 254| Step: 0
Training loss: 1.5939172506332397
Validation loss: 1.8304853990513792

Epoch: 6| Step: 1
Training loss: 1.4343748092651367
Validation loss: 1.8544495695380754

Epoch: 6| Step: 2
Training loss: 1.4660804271697998
Validation loss: 1.8600667356162943

Epoch: 6| Step: 3
Training loss: 1.036800742149353
Validation loss: 1.8315446504982569

Epoch: 6| Step: 4
Training loss: 1.7000237703323364
Validation loss: 1.8571644726619925

Epoch: 6| Step: 5
Training loss: 1.7119190692901611
Validation loss: 1.8528961981496503

Epoch: 6| Step: 6
Training loss: 1.1665420532226562
Validation loss: 1.8020843959623767

Epoch: 6| Step: 7
Training loss: 1.2969603538513184
Validation loss: 1.8131842215855916

Epoch: 6| Step: 8
Training loss: 1.3448023796081543
Validation loss: 1.8218606236160442

Epoch: 6| Step: 9
Training loss: 1.7635159492492676
Validation loss: 1.8465961128152826

Epoch: 6| Step: 10
Training loss: 1.5800397396087646
Validation loss: 1.8379897468833513

Epoch: 6| Step: 11
Training loss: 1.6198457479476929
Validation loss: 1.8367251426942888

Epoch: 6| Step: 12
Training loss: 2.106351852416992
Validation loss: 1.824941506949804

Epoch: 6| Step: 13
Training loss: 1.9617780447006226
Validation loss: 1.8415529651026572

Epoch: 255| Step: 0
Training loss: 1.393522024154663
Validation loss: 1.845572579291559

Epoch: 6| Step: 1
Training loss: 2.002593994140625
Validation loss: 1.8383569473861365

Epoch: 6| Step: 2
Training loss: 1.477757453918457
Validation loss: 1.8559157245902604

Epoch: 6| Step: 3
Training loss: 1.6818219423294067
Validation loss: 1.8768065296193606

Epoch: 6| Step: 4
Training loss: 1.7670313119888306
Validation loss: 1.897110833916613

Epoch: 6| Step: 5
Training loss: 1.742754340171814
Validation loss: 1.8440054142346947

Epoch: 6| Step: 6
Training loss: 1.9284796714782715
Validation loss: 1.853593259729365

Epoch: 6| Step: 7
Training loss: 1.031158685684204
Validation loss: 1.8614881500121085

Epoch: 6| Step: 8
Training loss: 1.2923738956451416
Validation loss: 1.8833019323246454

Epoch: 6| Step: 9
Training loss: 1.614680290222168
Validation loss: 1.8588509380176503

Epoch: 6| Step: 10
Training loss: 1.3206219673156738
Validation loss: 1.8478473258274857

Epoch: 6| Step: 11
Training loss: 1.5646233558654785
Validation loss: 1.8482755461046774

Epoch: 6| Step: 12
Training loss: 1.9566996097564697
Validation loss: 1.840476425745154

Epoch: 6| Step: 13
Training loss: 0.8066871166229248
Validation loss: 1.8093732018624582

Epoch: 256| Step: 0
Training loss: 0.9849162697792053
Validation loss: 1.8595091706962996

Epoch: 6| Step: 1
Training loss: 2.4088103771209717
Validation loss: 1.8259316618724535

Epoch: 6| Step: 2
Training loss: 1.5227110385894775
Validation loss: 1.8077784315232308

Epoch: 6| Step: 3
Training loss: 1.2468597888946533
Validation loss: 1.8486947359577302

Epoch: 6| Step: 4
Training loss: 1.391347885131836
Validation loss: 1.8435804510629306

Epoch: 6| Step: 5
Training loss: 1.378565788269043
Validation loss: 1.8239737531190277

Epoch: 6| Step: 6
Training loss: 2.0707974433898926
Validation loss: 1.8299934684589345

Epoch: 6| Step: 7
Training loss: 1.8878986835479736
Validation loss: 1.828609117897608

Epoch: 6| Step: 8
Training loss: 1.9015142917633057
Validation loss: 1.8202105709301528

Epoch: 6| Step: 9
Training loss: 1.775395154953003
Validation loss: 1.8520123074131627

Epoch: 6| Step: 10
Training loss: 1.0616084337234497
Validation loss: 1.8186512480499923

Epoch: 6| Step: 11
Training loss: 0.945525050163269
Validation loss: 1.8498135292401878

Epoch: 6| Step: 12
Training loss: 1.3538823127746582
Validation loss: 1.8047786835701234

Epoch: 6| Step: 13
Training loss: 1.1221833229064941
Validation loss: 1.8347308379347607

Epoch: 257| Step: 0
Training loss: 1.4554362297058105
Validation loss: 1.8528389905088691

Epoch: 6| Step: 1
Training loss: 1.796826958656311
Validation loss: 1.8260212418853596

Epoch: 6| Step: 2
Training loss: 1.245536208152771
Validation loss: 1.828768736572676

Epoch: 6| Step: 3
Training loss: 1.7323825359344482
Validation loss: 1.8543309486040505

Epoch: 6| Step: 4
Training loss: 1.8404905796051025
Validation loss: 1.878143282346828

Epoch: 6| Step: 5
Training loss: 1.7842538356781006
Validation loss: 1.8709493260229788

Epoch: 6| Step: 6
Training loss: 1.5647461414337158
Validation loss: 1.904203902008713

Epoch: 6| Step: 7
Training loss: 1.05159592628479
Validation loss: 1.8535502508122434

Epoch: 6| Step: 8
Training loss: 1.085323691368103
Validation loss: 1.824822570687981

Epoch: 6| Step: 9
Training loss: 1.8577349185943604
Validation loss: 1.8780058109632103

Epoch: 6| Step: 10
Training loss: 1.5047606229782104
Validation loss: 1.8236995422711937

Epoch: 6| Step: 11
Training loss: 1.4916847944259644
Validation loss: 1.8139373692133094

Epoch: 6| Step: 12
Training loss: 1.5948476791381836
Validation loss: 1.8172276122595674

Epoch: 6| Step: 13
Training loss: 1.399453043937683
Validation loss: 1.8259308940620833

Epoch: 258| Step: 0
Training loss: 2.1290040016174316
Validation loss: 1.8605334810031358

Epoch: 6| Step: 1
Training loss: 1.0011385679244995
Validation loss: 1.8564706822877288

Epoch: 6| Step: 2
Training loss: 1.5035326480865479
Validation loss: 1.8445882745968398

Epoch: 6| Step: 3
Training loss: 1.9670028686523438
Validation loss: 1.8335076250055784

Epoch: 6| Step: 4
Training loss: 1.8001973628997803
Validation loss: 1.8169152416208738

Epoch: 6| Step: 5
Training loss: 1.5585050582885742
Validation loss: 1.8208017515879806

Epoch: 6| Step: 6
Training loss: 1.0540251731872559
Validation loss: 1.8002385721411756

Epoch: 6| Step: 7
Training loss: 1.453615665435791
Validation loss: 1.8483477920614264

Epoch: 6| Step: 8
Training loss: 1.3889516592025757
Validation loss: 1.8182382340072303

Epoch: 6| Step: 9
Training loss: 1.2074873447418213
Validation loss: 1.846022928914716

Epoch: 6| Step: 10
Training loss: 1.3086822032928467
Validation loss: 1.8484123163325812

Epoch: 6| Step: 11
Training loss: 1.9352071285247803
Validation loss: 1.789836186234669

Epoch: 6| Step: 12
Training loss: 1.3951647281646729
Validation loss: 1.8330093032570296

Epoch: 6| Step: 13
Training loss: 1.726839542388916
Validation loss: 1.810506054150161

Epoch: 259| Step: 0
Training loss: 1.4993610382080078
Validation loss: 1.8384104672298636

Epoch: 6| Step: 1
Training loss: 0.8978145122528076
Validation loss: 1.818483789761861

Epoch: 6| Step: 2
Training loss: 1.474212884902954
Validation loss: 1.8005017490797146

Epoch: 6| Step: 3
Training loss: 1.4664201736450195
Validation loss: 1.8346563577651978

Epoch: 6| Step: 4
Training loss: 2.1194698810577393
Validation loss: 1.8589302057861

Epoch: 6| Step: 5
Training loss: 1.1232025623321533
Validation loss: 1.8361815534612185

Epoch: 6| Step: 6
Training loss: 1.6177706718444824
Validation loss: 1.8489423721067366

Epoch: 6| Step: 7
Training loss: 1.5561389923095703
Validation loss: 1.83219773538651

Epoch: 6| Step: 8
Training loss: 2.0917675495147705
Validation loss: 1.8986634157037223

Epoch: 6| Step: 9
Training loss: 1.927464485168457
Validation loss: 1.8717981948647449

Epoch: 6| Step: 10
Training loss: 1.106718897819519
Validation loss: 1.864846779454139

Epoch: 6| Step: 11
Training loss: 1.094571590423584
Validation loss: 1.8507631299316243

Epoch: 6| Step: 12
Training loss: 1.9075024127960205
Validation loss: 1.8657690107181508

Epoch: 6| Step: 13
Training loss: 1.0104212760925293
Validation loss: 1.8699603824205295

Epoch: 260| Step: 0
Training loss: 0.8644518852233887
Validation loss: 1.8565536839987642

Epoch: 6| Step: 1
Training loss: 1.299530267715454
Validation loss: 1.8361076975381503

Epoch: 6| Step: 2
Training loss: 2.134730815887451
Validation loss: 1.866990222725817

Epoch: 6| Step: 3
Training loss: 0.6721814870834351
Validation loss: 1.8007299310417586

Epoch: 6| Step: 4
Training loss: 1.4992647171020508
Validation loss: 1.8783045084245744

Epoch: 6| Step: 5
Training loss: 1.116294264793396
Validation loss: 1.8128905578326153

Epoch: 6| Step: 6
Training loss: 1.7707738876342773
Validation loss: 1.8591149789030834

Epoch: 6| Step: 7
Training loss: 1.8595337867736816
Validation loss: 1.8535698998358943

Epoch: 6| Step: 8
Training loss: 2.2178168296813965
Validation loss: 1.7962462889250888

Epoch: 6| Step: 9
Training loss: 1.612579345703125
Validation loss: 1.8296773959231634

Epoch: 6| Step: 10
Training loss: 1.6877843141555786
Validation loss: 1.8525889817104544

Epoch: 6| Step: 11
Training loss: 1.4621126651763916
Validation loss: 1.8266286093701598

Epoch: 6| Step: 12
Training loss: 1.6924699544906616
Validation loss: 1.8531451250917168

Epoch: 6| Step: 13
Training loss: 1.3127901554107666
Validation loss: 1.8392870682542042

Epoch: 261| Step: 0
Training loss: 1.2239753007888794
Validation loss: 1.8265960908705188

Epoch: 6| Step: 1
Training loss: 1.9359368085861206
Validation loss: 1.8319261009975145

Epoch: 6| Step: 2
Training loss: 1.4492981433868408
Validation loss: 1.868219078228038

Epoch: 6| Step: 3
Training loss: 1.9939854145050049
Validation loss: 1.8674537007526686

Epoch: 6| Step: 4
Training loss: 1.4791810512542725
Validation loss: 1.857004205385844

Epoch: 6| Step: 5
Training loss: 1.3546000719070435
Validation loss: 1.8326472159354918

Epoch: 6| Step: 6
Training loss: 2.006279706954956
Validation loss: 1.832792846105432

Epoch: 6| Step: 7
Training loss: 1.5693082809448242
Validation loss: 1.876843995945428

Epoch: 6| Step: 8
Training loss: 0.7677492499351501
Validation loss: 1.814860709251896

Epoch: 6| Step: 9
Training loss: 1.570338487625122
Validation loss: 1.836578284540484

Epoch: 6| Step: 10
Training loss: 1.4944441318511963
Validation loss: 1.7903686044036702

Epoch: 6| Step: 11
Training loss: 1.4202477931976318
Validation loss: 1.8388804748494139

Epoch: 6| Step: 12
Training loss: 1.2293065786361694
Validation loss: 1.7883600675931541

Epoch: 6| Step: 13
Training loss: 2.407918691635132
Validation loss: 1.8478264936836817

Epoch: 262| Step: 0
Training loss: 1.769078016281128
Validation loss: 1.846651336198212

Epoch: 6| Step: 1
Training loss: 1.0169053077697754
Validation loss: 1.8486746716242966

Epoch: 6| Step: 2
Training loss: 1.1342687606811523
Validation loss: 1.8073284843916535

Epoch: 6| Step: 3
Training loss: 1.434828281402588
Validation loss: 1.866425250166206

Epoch: 6| Step: 4
Training loss: 1.2707655429840088
Validation loss: 1.896314073634404

Epoch: 6| Step: 5
Training loss: 0.8577767610549927
Validation loss: 1.8577486263808383

Epoch: 6| Step: 6
Training loss: 1.562306523323059
Validation loss: 1.8589606374822638

Epoch: 6| Step: 7
Training loss: 2.040792226791382
Validation loss: 1.8874526818593342

Epoch: 6| Step: 8
Training loss: 1.9343647956848145
Validation loss: 1.8467972329867783

Epoch: 6| Step: 9
Training loss: 0.9172845482826233
Validation loss: 1.867427287563201

Epoch: 6| Step: 10
Training loss: 2.187380075454712
Validation loss: 1.829346582453738

Epoch: 6| Step: 11
Training loss: 1.8129714727401733
Validation loss: 1.8709618993984756

Epoch: 6| Step: 12
Training loss: 2.190561056137085
Validation loss: 1.8460584148283927

Epoch: 6| Step: 13
Training loss: 1.1539579629898071
Validation loss: 1.8878852680165281

Epoch: 263| Step: 0
Training loss: 1.286435604095459
Validation loss: 1.8641474336706183

Epoch: 6| Step: 1
Training loss: 1.3832601308822632
Validation loss: 1.8528681288483322

Epoch: 6| Step: 2
Training loss: 1.2518589496612549
Validation loss: 1.8285873448976906

Epoch: 6| Step: 3
Training loss: 1.5306487083435059
Validation loss: 1.8402597186385945

Epoch: 6| Step: 4
Training loss: 1.6568200588226318
Validation loss: 1.863260748565838

Epoch: 6| Step: 5
Training loss: 1.681583285331726
Validation loss: 1.8062007657943233

Epoch: 6| Step: 6
Training loss: 1.4222888946533203
Validation loss: 1.8245037409567064

Epoch: 6| Step: 7
Training loss: 1.523722767829895
Validation loss: 1.8132627151345695

Epoch: 6| Step: 8
Training loss: 1.618979811668396
Validation loss: 1.8718321810486496

Epoch: 6| Step: 9
Training loss: 1.8497323989868164
Validation loss: 1.8168868890372656

Epoch: 6| Step: 10
Training loss: 1.766533374786377
Validation loss: 1.7991872833621116

Epoch: 6| Step: 11
Training loss: 1.5387310981750488
Validation loss: 1.841837477940385

Epoch: 6| Step: 12
Training loss: 1.4750385284423828
Validation loss: 1.8373747256494337

Epoch: 6| Step: 13
Training loss: 0.7530966401100159
Validation loss: 1.8101370578171105

Epoch: 264| Step: 0
Training loss: 0.9213942289352417
Validation loss: 1.8053386775396203

Epoch: 6| Step: 1
Training loss: 1.6335153579711914
Validation loss: 1.8260326308588828

Epoch: 6| Step: 2
Training loss: 1.1504313945770264
Validation loss: 1.839947881237153

Epoch: 6| Step: 3
Training loss: 1.0989222526550293
Validation loss: 1.8592607564823602

Epoch: 6| Step: 4
Training loss: 1.3699572086334229
Validation loss: 1.891243693649128

Epoch: 6| Step: 5
Training loss: 1.8847997188568115
Validation loss: 1.8728218822069065

Epoch: 6| Step: 6
Training loss: 1.7444536685943604
Validation loss: 1.8770811096314461

Epoch: 6| Step: 7
Training loss: 2.099879026412964
Validation loss: 1.9009044760016984

Epoch: 6| Step: 8
Training loss: 1.3767831325531006
Validation loss: 1.8834941592267764

Epoch: 6| Step: 9
Training loss: 1.7853596210479736
Validation loss: 1.8995042795776038

Epoch: 6| Step: 10
Training loss: 1.8175550699234009
Validation loss: 1.8948261866005518

Epoch: 6| Step: 11
Training loss: 2.0181045532226562
Validation loss: 1.8658102737959994

Epoch: 6| Step: 12
Training loss: 0.7843824625015259
Validation loss: 1.8305359463537894

Epoch: 6| Step: 13
Training loss: 1.6612237691879272
Validation loss: 1.8395658141823226

Epoch: 265| Step: 0
Training loss: 1.6088809967041016
Validation loss: 1.8467010913356658

Epoch: 6| Step: 1
Training loss: 1.435335397720337
Validation loss: 1.8661743876754597

Epoch: 6| Step: 2
Training loss: 1.518441915512085
Validation loss: 1.864515341738219

Epoch: 6| Step: 3
Training loss: 2.0853824615478516
Validation loss: 1.8204768626920638

Epoch: 6| Step: 4
Training loss: 1.5861823558807373
Validation loss: 1.832973898098033

Epoch: 6| Step: 5
Training loss: 0.8639566898345947
Validation loss: 1.8417397032501877

Epoch: 6| Step: 6
Training loss: 0.9413639307022095
Validation loss: 1.8372617383157053

Epoch: 6| Step: 7
Training loss: 1.5987367630004883
Validation loss: 1.8432963176440167

Epoch: 6| Step: 8
Training loss: 1.6707167625427246
Validation loss: 1.8331902693676692

Epoch: 6| Step: 9
Training loss: 1.6061893701553345
Validation loss: 1.8045305257202477

Epoch: 6| Step: 10
Training loss: 2.1033694744110107
Validation loss: 1.792939926988335

Epoch: 6| Step: 11
Training loss: 1.3204236030578613
Validation loss: 1.8472331339313137

Epoch: 6| Step: 12
Training loss: 1.043657898902893
Validation loss: 1.8227704019956692

Epoch: 6| Step: 13
Training loss: 1.7837668657302856
Validation loss: 1.8279869248790126

Epoch: 266| Step: 0
Training loss: 1.7019174098968506
Validation loss: 1.841408125815853

Epoch: 6| Step: 1
Training loss: 1.6957333087921143
Validation loss: 1.8180013523306897

Epoch: 6| Step: 2
Training loss: 1.3606808185577393
Validation loss: 1.823972798162891

Epoch: 6| Step: 3
Training loss: 1.758183240890503
Validation loss: 1.8189366645710443

Epoch: 6| Step: 4
Training loss: 1.82734215259552
Validation loss: 1.844927486552987

Epoch: 6| Step: 5
Training loss: 1.8846502304077148
Validation loss: 1.8283955589417489

Epoch: 6| Step: 6
Training loss: 1.4429669380187988
Validation loss: 1.8361448395636775

Epoch: 6| Step: 7
Training loss: 0.9796438217163086
Validation loss: 1.8136192919105611

Epoch: 6| Step: 8
Training loss: 1.2050050497055054
Validation loss: 1.8207485214356454

Epoch: 6| Step: 9
Training loss: 1.2909413576126099
Validation loss: 1.8584968825822235

Epoch: 6| Step: 10
Training loss: 1.4767277240753174
Validation loss: 1.8182412373122347

Epoch: 6| Step: 11
Training loss: 1.320770502090454
Validation loss: 1.8314962489630586

Epoch: 6| Step: 12
Training loss: 1.6269478797912598
Validation loss: 1.85336011199541

Epoch: 6| Step: 13
Training loss: 1.3105508089065552
Validation loss: 1.8238772423036638

Epoch: 267| Step: 0
Training loss: 1.1906620264053345
Validation loss: 1.858305231217415

Epoch: 6| Step: 1
Training loss: 0.901904821395874
Validation loss: 1.843079372118878

Epoch: 6| Step: 2
Training loss: 1.1973388195037842
Validation loss: 1.8545295987077939

Epoch: 6| Step: 3
Training loss: 1.7562241554260254
Validation loss: 1.8507491439901373

Epoch: 6| Step: 4
Training loss: 1.446033000946045
Validation loss: 1.818352004533173

Epoch: 6| Step: 5
Training loss: 2.136646270751953
Validation loss: 1.8539677717352425

Epoch: 6| Step: 6
Training loss: 1.6339002847671509
Validation loss: 1.8520927198471562

Epoch: 6| Step: 7
Training loss: 2.0117857456207275
Validation loss: 1.8270791756209506

Epoch: 6| Step: 8
Training loss: 1.454793095588684
Validation loss: 1.8287695941104685

Epoch: 6| Step: 9
Training loss: 1.113694429397583
Validation loss: 1.7750179254880516

Epoch: 6| Step: 10
Training loss: 1.970673680305481
Validation loss: 1.8426093516811248

Epoch: 6| Step: 11
Training loss: 1.673775553703308
Validation loss: 1.8380346804536798

Epoch: 6| Step: 12
Training loss: 1.1882078647613525
Validation loss: 1.8362918746086858

Epoch: 6| Step: 13
Training loss: 1.7367299795150757
Validation loss: 1.8029276042856195

Epoch: 268| Step: 0
Training loss: 1.223893404006958
Validation loss: 1.841249273669335

Epoch: 6| Step: 1
Training loss: 1.9220683574676514
Validation loss: 1.8884210881366525

Epoch: 6| Step: 2
Training loss: 1.1937077045440674
Validation loss: 1.82150605417067

Epoch: 6| Step: 3
Training loss: 1.7796258926391602
Validation loss: 1.84088126690157

Epoch: 6| Step: 4
Training loss: 2.116861581802368
Validation loss: 1.8120659705131286

Epoch: 6| Step: 5
Training loss: 1.033860206604004
Validation loss: 1.8527368294295443

Epoch: 6| Step: 6
Training loss: 1.9197709560394287
Validation loss: 1.8521114280146938

Epoch: 6| Step: 7
Training loss: 0.8752723336219788
Validation loss: 1.8390445863046954

Epoch: 6| Step: 8
Training loss: 1.6178206205368042
Validation loss: 1.8786131553752448

Epoch: 6| Step: 9
Training loss: 1.5883339643478394
Validation loss: 1.8195159922363937

Epoch: 6| Step: 10
Training loss: 1.746120810508728
Validation loss: 1.839668535417126

Epoch: 6| Step: 11
Training loss: 1.454412579536438
Validation loss: 1.8809622564623434

Epoch: 6| Step: 12
Training loss: 0.9046614170074463
Validation loss: 1.8453502270483202

Epoch: 6| Step: 13
Training loss: 1.832194447517395
Validation loss: 1.8237535440793602

Epoch: 269| Step: 0
Training loss: 1.2171125411987305
Validation loss: 1.8358936284178047

Epoch: 6| Step: 1
Training loss: 1.8513948917388916
Validation loss: 1.8496335116765832

Epoch: 6| Step: 2
Training loss: 1.4427202939987183
Validation loss: 1.8461626242565852

Epoch: 6| Step: 3
Training loss: 0.724481999874115
Validation loss: 1.8229085694077194

Epoch: 6| Step: 4
Training loss: 2.440495014190674
Validation loss: 1.8489396559294833

Epoch: 6| Step: 5
Training loss: 1.7508056163787842
Validation loss: 1.8815130546528807

Epoch: 6| Step: 6
Training loss: 1.4445490837097168
Validation loss: 1.877550619904713

Epoch: 6| Step: 7
Training loss: 1.5657708644866943
Validation loss: 1.8851913188093452

Epoch: 6| Step: 8
Training loss: 1.003300428390503
Validation loss: 1.867303043283442

Epoch: 6| Step: 9
Training loss: 1.6714460849761963
Validation loss: 1.8767867357500139

Epoch: 6| Step: 10
Training loss: 1.891298532485962
Validation loss: 1.846228849503302

Epoch: 6| Step: 11
Training loss: 1.3188385963439941
Validation loss: 1.8606002125688779

Epoch: 6| Step: 12
Training loss: 1.3307483196258545
Validation loss: 1.850315038875867

Epoch: 6| Step: 13
Training loss: 1.1086277961730957
Validation loss: 1.8699492203292025

Epoch: 270| Step: 0
Training loss: 2.093134880065918
Validation loss: 1.8122679636042605

Epoch: 6| Step: 1
Training loss: 1.174894094467163
Validation loss: 1.8185374390694402

Epoch: 6| Step: 2
Training loss: 1.575239658355713
Validation loss: 1.8119592141079646

Epoch: 6| Step: 3
Training loss: 1.6302458047866821
Validation loss: 1.8285210773509035

Epoch: 6| Step: 4
Training loss: 0.9863211512565613
Validation loss: 1.8317756370831562

Epoch: 6| Step: 5
Training loss: 1.3502591848373413
Validation loss: 1.8084331443232875

Epoch: 6| Step: 6
Training loss: 1.4983971118927002
Validation loss: 1.8338344789320422

Epoch: 6| Step: 7
Training loss: 1.1646125316619873
Validation loss: 1.8485322870234007

Epoch: 6| Step: 8
Training loss: 1.5718657970428467
Validation loss: 1.8491405120459936

Epoch: 6| Step: 9
Training loss: 1.6084809303283691
Validation loss: 1.8447506594401535

Epoch: 6| Step: 10
Training loss: 2.1196770668029785
Validation loss: 1.839103869212571

Epoch: 6| Step: 11
Training loss: 1.3732798099517822
Validation loss: 1.8069443471970097

Epoch: 6| Step: 12
Training loss: 1.739163875579834
Validation loss: 1.9020674433759464

Epoch: 6| Step: 13
Training loss: 1.3707451820373535
Validation loss: 1.8704608345544467

Epoch: 271| Step: 0
Training loss: 1.8184025287628174
Validation loss: 1.9010248978932698

Epoch: 6| Step: 1
Training loss: 1.6138083934783936
Validation loss: 1.8502296901518298

Epoch: 6| Step: 2
Training loss: 1.1372628211975098
Validation loss: 1.8801418478770922

Epoch: 6| Step: 3
Training loss: 1.727051854133606
Validation loss: 1.8326314777456305

Epoch: 6| Step: 4
Training loss: 1.279044508934021
Validation loss: 1.869869165523078

Epoch: 6| Step: 5
Training loss: 1.3869266510009766
Validation loss: 1.838612525693832

Epoch: 6| Step: 6
Training loss: 1.3207793235778809
Validation loss: 1.8211847069442912

Epoch: 6| Step: 7
Training loss: 1.6251591444015503
Validation loss: 1.8438848603156306

Epoch: 6| Step: 8
Training loss: 1.673169493675232
Validation loss: 1.8271983323558685

Epoch: 6| Step: 9
Training loss: 1.383626937866211
Validation loss: 1.8493350257155716

Epoch: 6| Step: 10
Training loss: 1.3946207761764526
Validation loss: 1.8308752788010465

Epoch: 6| Step: 11
Training loss: 1.386321783065796
Validation loss: 1.8313804916156236

Epoch: 6| Step: 12
Training loss: 1.3895342350006104
Validation loss: 1.7783754807646557

Epoch: 6| Step: 13
Training loss: 1.46605384349823
Validation loss: 1.8341395829313545

Epoch: 272| Step: 0
Training loss: 1.334662675857544
Validation loss: 1.7978679057090514

Epoch: 6| Step: 1
Training loss: 1.8377177715301514
Validation loss: 1.8007216786825528

Epoch: 6| Step: 2
Training loss: 1.5179014205932617
Validation loss: 1.8244582683809343

Epoch: 6| Step: 3
Training loss: 1.563115119934082
Validation loss: 1.8504450334015714

Epoch: 6| Step: 4
Training loss: 1.3692729473114014
Validation loss: 1.8328864189886278

Epoch: 6| Step: 5
Training loss: 1.74354088306427
Validation loss: 1.8071965094535583

Epoch: 6| Step: 6
Training loss: 0.7013959884643555
Validation loss: 1.824690341949463

Epoch: 6| Step: 7
Training loss: 1.6252732276916504
Validation loss: 1.8210762008543937

Epoch: 6| Step: 8
Training loss: 1.1869909763336182
Validation loss: 1.7862216734117078

Epoch: 6| Step: 9
Training loss: 1.9911890029907227
Validation loss: 1.8278793391361032

Epoch: 6| Step: 10
Training loss: 0.9646323323249817
Validation loss: 1.8501788794353444

Epoch: 6| Step: 11
Training loss: 1.6688148975372314
Validation loss: 1.779727448699295

Epoch: 6| Step: 12
Training loss: 1.6978495121002197
Validation loss: 1.7946648405444237

Epoch: 6| Step: 13
Training loss: 1.273019552230835
Validation loss: 1.7871858099455475

Epoch: 273| Step: 0
Training loss: 1.7852482795715332
Validation loss: 1.851997765161658

Epoch: 6| Step: 1
Training loss: 1.6685518026351929
Validation loss: 1.8355973689786849

Epoch: 6| Step: 2
Training loss: 1.3365323543548584
Validation loss: 1.856844150891868

Epoch: 6| Step: 3
Training loss: 1.2772706747055054
Validation loss: 1.8518173617701377

Epoch: 6| Step: 4
Training loss: 1.8989198207855225
Validation loss: 1.868539414098186

Epoch: 6| Step: 5
Training loss: 1.9344956874847412
Validation loss: 1.848705216120648

Epoch: 6| Step: 6
Training loss: 1.0008149147033691
Validation loss: 1.8783415261135306

Epoch: 6| Step: 7
Training loss: 1.5682055950164795
Validation loss: 1.844055639800205

Epoch: 6| Step: 8
Training loss: 1.2902228832244873
Validation loss: 1.8501682140493905

Epoch: 6| Step: 9
Training loss: 1.1161918640136719
Validation loss: 1.849432732469292

Epoch: 6| Step: 10
Training loss: 1.0241508483886719
Validation loss: 1.855672110793411

Epoch: 6| Step: 11
Training loss: 1.7241209745407104
Validation loss: 1.8526617006589008

Epoch: 6| Step: 12
Training loss: 1.8366444110870361
Validation loss: 1.8208151568648636

Epoch: 6| Step: 13
Training loss: 1.2205065488815308
Validation loss: 1.825239009113722

Epoch: 274| Step: 0
Training loss: 1.8275090456008911
Validation loss: 1.8582728742271342

Epoch: 6| Step: 1
Training loss: 1.7537834644317627
Validation loss: 1.8101353440233456

Epoch: 6| Step: 2
Training loss: 1.4088900089263916
Validation loss: 1.8154609395611672

Epoch: 6| Step: 3
Training loss: 1.1914036273956299
Validation loss: 1.8613101128608949

Epoch: 6| Step: 4
Training loss: 1.7954134941101074
Validation loss: 1.8030751469314739

Epoch: 6| Step: 5
Training loss: 1.9958546161651611
Validation loss: 1.8122635502969064

Epoch: 6| Step: 6
Training loss: 1.2585535049438477
Validation loss: 1.80385410657493

Epoch: 6| Step: 7
Training loss: 1.374922513961792
Validation loss: 1.8264167898444719

Epoch: 6| Step: 8
Training loss: 1.0871739387512207
Validation loss: 1.7980929497749574

Epoch: 6| Step: 9
Training loss: 2.1118345260620117
Validation loss: 1.8447075889956566

Epoch: 6| Step: 10
Training loss: 0.9901878237724304
Validation loss: 1.8029764365124445

Epoch: 6| Step: 11
Training loss: 1.262473464012146
Validation loss: 1.7984777804343932

Epoch: 6| Step: 12
Training loss: 1.2467831373214722
Validation loss: 1.824769926327531

Epoch: 6| Step: 13
Training loss: 1.2290709018707275
Validation loss: 1.8053300983162337

Epoch: 275| Step: 0
Training loss: 1.7375316619873047
Validation loss: 1.8146721111830844

Epoch: 6| Step: 1
Training loss: 1.5836607217788696
Validation loss: 1.8353341984492477

Epoch: 6| Step: 2
Training loss: 0.82370924949646
Validation loss: 1.8235357986983431

Epoch: 6| Step: 3
Training loss: 1.6112314462661743
Validation loss: 1.799356291371007

Epoch: 6| Step: 4
Training loss: 2.181363821029663
Validation loss: 1.8291256735401769

Epoch: 6| Step: 5
Training loss: 1.3366904258728027
Validation loss: 1.8536065009332472

Epoch: 6| Step: 6
Training loss: 1.4598851203918457
Validation loss: 1.845680900799331

Epoch: 6| Step: 7
Training loss: 1.4473395347595215
Validation loss: 1.8442415268190446

Epoch: 6| Step: 8
Training loss: 1.7921738624572754
Validation loss: 1.8718553204690256

Epoch: 6| Step: 9
Training loss: 0.9005131721496582
Validation loss: 1.8102572605174074

Epoch: 6| Step: 10
Training loss: 1.1607543230056763
Validation loss: 1.847164213016469

Epoch: 6| Step: 11
Training loss: 1.40733802318573
Validation loss: 1.791718690626083

Epoch: 6| Step: 12
Training loss: 1.742737054824829
Validation loss: 1.828205531643283

Epoch: 6| Step: 13
Training loss: 1.9647390842437744
Validation loss: 1.8027631928843837

Epoch: 276| Step: 0
Training loss: 1.3946893215179443
Validation loss: 1.828215673405637

Epoch: 6| Step: 1
Training loss: 0.6268874406814575
Validation loss: 1.806915944622409

Epoch: 6| Step: 2
Training loss: 1.1311476230621338
Validation loss: 1.8283177319393362

Epoch: 6| Step: 3
Training loss: 1.2561287879943848
Validation loss: 1.8129421587913268

Epoch: 6| Step: 4
Training loss: 1.961160659790039
Validation loss: 1.8189877925380584

Epoch: 6| Step: 5
Training loss: 2.2706379890441895
Validation loss: 1.7991771505724998

Epoch: 6| Step: 6
Training loss: 1.5855515003204346
Validation loss: 1.8130682104377336

Epoch: 6| Step: 7
Training loss: 1.4842751026153564
Validation loss: 1.8006628764572965

Epoch: 6| Step: 8
Training loss: 1.5809533596038818
Validation loss: 1.8493683004892

Epoch: 6| Step: 9
Training loss: 1.311920166015625
Validation loss: 1.8633212658666796

Epoch: 6| Step: 10
Training loss: 1.8164267539978027
Validation loss: 1.8260223352780907

Epoch: 6| Step: 11
Training loss: 1.257582664489746
Validation loss: 1.8459490499188822

Epoch: 6| Step: 12
Training loss: 1.3676772117614746
Validation loss: 1.8363126772706226

Epoch: 6| Step: 13
Training loss: 1.979053020477295
Validation loss: 1.8164858894963418

Epoch: 277| Step: 0
Training loss: 1.445838451385498
Validation loss: 1.8281513760166783

Epoch: 6| Step: 1
Training loss: 1.9940396547317505
Validation loss: 1.8362132669776998

Epoch: 6| Step: 2
Training loss: 1.4922823905944824
Validation loss: 1.8693083306794525

Epoch: 6| Step: 3
Training loss: 1.524411916732788
Validation loss: 1.8710735228753859

Epoch: 6| Step: 4
Training loss: 1.147660493850708
Validation loss: 1.9240753291755595

Epoch: 6| Step: 5
Training loss: 2.319899082183838
Validation loss: 1.8781511373417352

Epoch: 6| Step: 6
Training loss: 1.858323335647583
Validation loss: 1.866581041325805

Epoch: 6| Step: 7
Training loss: 1.143803596496582
Validation loss: 1.8843334362071047

Epoch: 6| Step: 8
Training loss: 1.3457818031311035
Validation loss: 1.8589285714651949

Epoch: 6| Step: 9
Training loss: 1.1968111991882324
Validation loss: 1.907342359583865

Epoch: 6| Step: 10
Training loss: 0.9863125085830688
Validation loss: 1.8366281845236336

Epoch: 6| Step: 11
Training loss: 1.5261890888214111
Validation loss: 1.8708455062681628

Epoch: 6| Step: 12
Training loss: 1.5366216897964478
Validation loss: 1.8230013770441855

Epoch: 6| Step: 13
Training loss: 1.0135844945907593
Validation loss: 1.8509142885925949

Epoch: 278| Step: 0
Training loss: 0.9793031811714172
Validation loss: 1.8272878034140474

Epoch: 6| Step: 1
Training loss: 1.0044715404510498
Validation loss: 1.8028036086790022

Epoch: 6| Step: 2
Training loss: 1.5490562915802002
Validation loss: 1.804889589227656

Epoch: 6| Step: 3
Training loss: 1.3766469955444336
Validation loss: 1.8288002988343597

Epoch: 6| Step: 4
Training loss: 2.0267696380615234
Validation loss: 1.819703200811981

Epoch: 6| Step: 5
Training loss: 1.4291640520095825
Validation loss: 1.8336234477258497

Epoch: 6| Step: 6
Training loss: 1.9621028900146484
Validation loss: 1.83407546371542

Epoch: 6| Step: 7
Training loss: 1.2899494171142578
Validation loss: 1.7960569935460244

Epoch: 6| Step: 8
Training loss: 1.4664111137390137
Validation loss: 1.8482675731823008

Epoch: 6| Step: 9
Training loss: 1.5691494941711426
Validation loss: 1.8277581455887004

Epoch: 6| Step: 10
Training loss: 1.634089708328247
Validation loss: 1.8051970927946028

Epoch: 6| Step: 11
Training loss: 1.1557948589324951
Validation loss: 1.8065159910468644

Epoch: 6| Step: 12
Training loss: 1.803689956665039
Validation loss: 1.7977836824232531

Epoch: 6| Step: 13
Training loss: 1.4009971618652344
Validation loss: 1.8380437230551114

Epoch: 279| Step: 0
Training loss: 1.2782070636749268
Validation loss: 1.8507409531583068

Epoch: 6| Step: 1
Training loss: 2.1310367584228516
Validation loss: 1.8719923316791494

Epoch: 6| Step: 2
Training loss: 1.7655174732208252
Validation loss: 1.8419621247117237

Epoch: 6| Step: 3
Training loss: 1.6989774703979492
Validation loss: 1.7901244765968733

Epoch: 6| Step: 4
Training loss: 1.4091578722000122
Validation loss: 1.8155608125912246

Epoch: 6| Step: 5
Training loss: 1.2060158252716064
Validation loss: 1.8668077325308194

Epoch: 6| Step: 6
Training loss: 1.4727542400360107
Validation loss: 1.834523247134301

Epoch: 6| Step: 7
Training loss: 1.3839815855026245
Validation loss: 1.8119192995050901

Epoch: 6| Step: 8
Training loss: 1.0382113456726074
Validation loss: 1.8636253546643

Epoch: 6| Step: 9
Training loss: 0.6391168832778931
Validation loss: 1.8843777538627706

Epoch: 6| Step: 10
Training loss: 1.3152449131011963
Validation loss: 1.8777399037473945

Epoch: 6| Step: 11
Training loss: 1.9862329959869385
Validation loss: 1.8663593556291314

Epoch: 6| Step: 12
Training loss: 1.4341223239898682
Validation loss: 1.8763155219375447

Epoch: 6| Step: 13
Training loss: 1.2102290391921997
Validation loss: 1.8212442500616914

Epoch: 280| Step: 0
Training loss: 1.638472318649292
Validation loss: 1.8489109585362096

Epoch: 6| Step: 1
Training loss: 0.773743748664856
Validation loss: 1.8461766935163928

Epoch: 6| Step: 2
Training loss: 2.1909499168395996
Validation loss: 1.8577722990384666

Epoch: 6| Step: 3
Training loss: 0.800962507724762
Validation loss: 1.8145536479129587

Epoch: 6| Step: 4
Training loss: 1.8630092144012451
Validation loss: 1.850720259451097

Epoch: 6| Step: 5
Training loss: 1.0176528692245483
Validation loss: 1.854015193959718

Epoch: 6| Step: 6
Training loss: 1.8387184143066406
Validation loss: 1.8750830760566137

Epoch: 6| Step: 7
Training loss: 1.5478397607803345
Validation loss: 1.8355776186912292

Epoch: 6| Step: 8
Training loss: 1.5067205429077148
Validation loss: 1.845191131355942

Epoch: 6| Step: 9
Training loss: 1.2657558917999268
Validation loss: 1.8268060427840038

Epoch: 6| Step: 10
Training loss: 1.7585878372192383
Validation loss: 1.858564135848835

Epoch: 6| Step: 11
Training loss: 1.1885572671890259
Validation loss: 1.8204080699592509

Epoch: 6| Step: 12
Training loss: 1.2858434915542603
Validation loss: 1.8265244294238347

Epoch: 6| Step: 13
Training loss: 2.1058168411254883
Validation loss: 1.8168079109602078

Epoch: 281| Step: 0
Training loss: 1.4632185697555542
Validation loss: 1.8427671014621694

Epoch: 6| Step: 1
Training loss: 1.2714695930480957
Validation loss: 1.8679789291915072

Epoch: 6| Step: 2
Training loss: 1.798775315284729
Validation loss: 1.8476390300258514

Epoch: 6| Step: 3
Training loss: 1.5311357975006104
Validation loss: 1.8771853677688106

Epoch: 6| Step: 4
Training loss: 1.8585232496261597
Validation loss: 1.8233567553181802

Epoch: 6| Step: 5
Training loss: 1.391482949256897
Validation loss: 1.8688419711205266

Epoch: 6| Step: 6
Training loss: 1.1379269361495972
Validation loss: 1.7798548539479573

Epoch: 6| Step: 7
Training loss: 1.6745967864990234
Validation loss: 1.8063585501845165

Epoch: 6| Step: 8
Training loss: 1.0976389646530151
Validation loss: 1.8480529323700936

Epoch: 6| Step: 9
Training loss: 1.5765626430511475
Validation loss: 1.8290050798846829

Epoch: 6| Step: 10
Training loss: 1.2980345487594604
Validation loss: 1.8222716187918058

Epoch: 6| Step: 11
Training loss: 1.3049137592315674
Validation loss: 1.8197452406729422

Epoch: 6| Step: 12
Training loss: 1.3563752174377441
Validation loss: 1.855378230412801

Epoch: 6| Step: 13
Training loss: 1.9058717489242554
Validation loss: 1.811069474425367

Epoch: 282| Step: 0
Training loss: 0.9802494049072266
Validation loss: 1.8304482659985941

Epoch: 6| Step: 1
Training loss: 1.5825806856155396
Validation loss: 1.808257987422328

Epoch: 6| Step: 2
Training loss: 1.058833360671997
Validation loss: 1.7852301623231621

Epoch: 6| Step: 3
Training loss: 2.024319648742676
Validation loss: 1.8409767227788125

Epoch: 6| Step: 4
Training loss: 1.7029473781585693
Validation loss: 1.82339612642924

Epoch: 6| Step: 5
Training loss: 2.039090394973755
Validation loss: 1.8221661172887331

Epoch: 6| Step: 6
Training loss: 1.0217262506484985
Validation loss: 1.7970073876842376

Epoch: 6| Step: 7
Training loss: 1.482764482498169
Validation loss: 1.8260821809050858

Epoch: 6| Step: 8
Training loss: 1.223706841468811
Validation loss: 1.811930589778449

Epoch: 6| Step: 9
Training loss: 1.7520480155944824
Validation loss: 1.844233189859698

Epoch: 6| Step: 10
Training loss: 1.287614345550537
Validation loss: 1.832413697755465

Epoch: 6| Step: 11
Training loss: 1.9778087139129639
Validation loss: 1.8610802517142346

Epoch: 6| Step: 12
Training loss: 0.6892448663711548
Validation loss: 1.8420437177022297

Epoch: 6| Step: 13
Training loss: 1.46216881275177
Validation loss: 1.8395472675241449

Epoch: 283| Step: 0
Training loss: 1.351839303970337
Validation loss: 1.8732694682254587

Epoch: 6| Step: 1
Training loss: 1.3135778903961182
Validation loss: 1.9063043299541678

Epoch: 6| Step: 2
Training loss: 1.5055639743804932
Validation loss: 1.881852546045857

Epoch: 6| Step: 3
Training loss: 1.337777853012085
Validation loss: 1.9201157234048332

Epoch: 6| Step: 4
Training loss: 1.5101183652877808
Validation loss: 1.887659631749635

Epoch: 6| Step: 5
Training loss: 1.8624247312545776
Validation loss: 1.9072989750933904

Epoch: 6| Step: 6
Training loss: 1.9810495376586914
Validation loss: 1.8262214391462264

Epoch: 6| Step: 7
Training loss: 1.069873571395874
Validation loss: 1.8955278601697696

Epoch: 6| Step: 8
Training loss: 1.3956934213638306
Validation loss: 1.849712602553829

Epoch: 6| Step: 9
Training loss: 1.9471099376678467
Validation loss: 1.8189960589972876

Epoch: 6| Step: 10
Training loss: 1.48935866355896
Validation loss: 1.82095814904859

Epoch: 6| Step: 11
Training loss: 1.2530364990234375
Validation loss: 1.8918017264335387

Epoch: 6| Step: 12
Training loss: 1.7432892322540283
Validation loss: 1.824033510300421

Epoch: 6| Step: 13
Training loss: 0.7676927447319031
Validation loss: 1.8272573717178837

Epoch: 284| Step: 0
Training loss: 1.2310116291046143
Validation loss: 1.8237075113481092

Epoch: 6| Step: 1
Training loss: 1.527069091796875
Validation loss: 1.8364302689029324

Epoch: 6| Step: 2
Training loss: 1.0010392665863037
Validation loss: 1.782989954435697

Epoch: 6| Step: 3
Training loss: 1.1888256072998047
Validation loss: 1.819022576014201

Epoch: 6| Step: 4
Training loss: 1.67454195022583
Validation loss: 1.7956949869791667

Epoch: 6| Step: 5
Training loss: 2.19842791557312
Validation loss: 1.8225203534608245

Epoch: 6| Step: 6
Training loss: 1.7133159637451172
Validation loss: 1.8516707881804435

Epoch: 6| Step: 7
Training loss: 1.3967700004577637
Validation loss: 1.8209418917215

Epoch: 6| Step: 8
Training loss: 1.2408194541931152
Validation loss: 1.78021800902582

Epoch: 6| Step: 9
Training loss: 1.752309799194336
Validation loss: 1.846265628773679

Epoch: 6| Step: 10
Training loss: 1.1911096572875977
Validation loss: 1.8173004350354593

Epoch: 6| Step: 11
Training loss: 0.9563156962394714
Validation loss: 1.8352190986756356

Epoch: 6| Step: 12
Training loss: 1.670477032661438
Validation loss: 1.8274819549693857

Epoch: 6| Step: 13
Training loss: 2.04695463180542
Validation loss: 1.8122561221481652

Epoch: 285| Step: 0
Training loss: 1.1417312622070312
Validation loss: 1.837062398592631

Epoch: 6| Step: 1
Training loss: 1.0909514427185059
Validation loss: 1.8253475363536547

Epoch: 6| Step: 2
Training loss: 1.6471176147460938
Validation loss: 1.8301276083915465

Epoch: 6| Step: 3
Training loss: 1.7521637678146362
Validation loss: 1.8304365604154524

Epoch: 6| Step: 4
Training loss: 0.7439733743667603
Validation loss: 1.8434949485204553

Epoch: 6| Step: 5
Training loss: 1.1435205936431885
Validation loss: 1.863982868450944

Epoch: 6| Step: 6
Training loss: 1.6004385948181152
Validation loss: 1.8557455385884931

Epoch: 6| Step: 7
Training loss: 1.3282403945922852
Validation loss: 1.8768022175758117

Epoch: 6| Step: 8
Training loss: 1.6406285762786865
Validation loss: 1.8261881528362152

Epoch: 6| Step: 9
Training loss: 1.783831238746643
Validation loss: 1.826655053323315

Epoch: 6| Step: 10
Training loss: 2.200005054473877
Validation loss: 1.8347022353961904

Epoch: 6| Step: 11
Training loss: 1.3622918128967285
Validation loss: 1.850831034362957

Epoch: 6| Step: 12
Training loss: 1.9175350666046143
Validation loss: 1.8229817382750972

Epoch: 6| Step: 13
Training loss: 0.9041373133659363
Validation loss: 1.8744824163375362

Epoch: 286| Step: 0
Training loss: 1.6954455375671387
Validation loss: 1.8497508315629856

Epoch: 6| Step: 1
Training loss: 1.2734379768371582
Validation loss: 1.8198311508342784

Epoch: 6| Step: 2
Training loss: 1.1502482891082764
Validation loss: 1.8222520761592413

Epoch: 6| Step: 3
Training loss: 1.7091933488845825
Validation loss: 1.8753330694731845

Epoch: 6| Step: 4
Training loss: 1.793818712234497
Validation loss: 1.7957926232327697

Epoch: 6| Step: 5
Training loss: 1.4197657108306885
Validation loss: 1.8169616627436813

Epoch: 6| Step: 6
Training loss: 0.9951515197753906
Validation loss: 1.7980985564570273

Epoch: 6| Step: 7
Training loss: 1.2305560111999512
Validation loss: 1.8199258132647442

Epoch: 6| Step: 8
Training loss: 2.259298801422119
Validation loss: 1.8120049520205426

Epoch: 6| Step: 9
Training loss: 1.2019259929656982
Validation loss: 1.8206929135066208

Epoch: 6| Step: 10
Training loss: 2.012188196182251
Validation loss: 1.8664592696774391

Epoch: 6| Step: 11
Training loss: 1.3027615547180176
Validation loss: 1.7972130096086891

Epoch: 6| Step: 12
Training loss: 1.1827025413513184
Validation loss: 1.8451814677125664

Epoch: 6| Step: 13
Training loss: 1.0529704093933105
Validation loss: 1.862261882392309

Epoch: 287| Step: 0
Training loss: 1.6058367490768433
Validation loss: 1.8277970167898363

Epoch: 6| Step: 1
Training loss: 1.3419272899627686
Validation loss: 1.858568451737845

Epoch: 6| Step: 2
Training loss: 0.5687870383262634
Validation loss: 1.8913391738809564

Epoch: 6| Step: 3
Training loss: 1.415923833847046
Validation loss: 1.827964489177991

Epoch: 6| Step: 4
Training loss: 1.1265943050384521
Validation loss: 1.905879569310014

Epoch: 6| Step: 5
Training loss: 1.5162410736083984
Validation loss: 1.8353265575183335

Epoch: 6| Step: 6
Training loss: 1.804934024810791
Validation loss: 1.8447548984199442

Epoch: 6| Step: 7
Training loss: 1.4108672142028809
Validation loss: 1.8674065105376705

Epoch: 6| Step: 8
Training loss: 1.3548779487609863
Validation loss: 1.8543602087164437

Epoch: 6| Step: 9
Training loss: 2.0131123065948486
Validation loss: 1.88855944653993

Epoch: 6| Step: 10
Training loss: 1.257270097732544
Validation loss: 1.84270848894632

Epoch: 6| Step: 11
Training loss: 1.5689959526062012
Validation loss: 1.849681579938499

Epoch: 6| Step: 12
Training loss: 1.5714726448059082
Validation loss: 1.864313438374509

Epoch: 6| Step: 13
Training loss: 1.5190790891647339
Validation loss: 1.8375356197357178

Epoch: 288| Step: 0
Training loss: 1.0805420875549316
Validation loss: 1.8440840564748293

Epoch: 6| Step: 1
Training loss: 1.2473703622817993
Validation loss: 1.8269854117465276

Epoch: 6| Step: 2
Training loss: 1.686727523803711
Validation loss: 1.8373873669614074

Epoch: 6| Step: 3
Training loss: 1.723771572113037
Validation loss: 1.8466161899669196

Epoch: 6| Step: 4
Training loss: 1.630555272102356
Validation loss: 1.8023186960527975

Epoch: 6| Step: 5
Training loss: 1.1020301580429077
Validation loss: 1.8205951029254543

Epoch: 6| Step: 6
Training loss: 1.693387746810913
Validation loss: 1.8308659509945941

Epoch: 6| Step: 7
Training loss: 1.8023794889450073
Validation loss: 1.8166049859857047

Epoch: 6| Step: 8
Training loss: 0.9538174867630005
Validation loss: 1.7953891997696252

Epoch: 6| Step: 9
Training loss: 1.882673740386963
Validation loss: 1.859748089185325

Epoch: 6| Step: 10
Training loss: 1.3191676139831543
Validation loss: 1.820160197955306

Epoch: 6| Step: 11
Training loss: 1.4084889888763428
Validation loss: 1.8384111248036867

Epoch: 6| Step: 12
Training loss: 1.2426128387451172
Validation loss: 1.7884279733063073

Epoch: 6| Step: 13
Training loss: 1.5504636764526367
Validation loss: 1.8453025715325468

Epoch: 289| Step: 0
Training loss: 1.078370451927185
Validation loss: 1.8654031612539803

Epoch: 6| Step: 1
Training loss: 1.606781005859375
Validation loss: 1.8284540496846682

Epoch: 6| Step: 2
Training loss: 1.8394966125488281
Validation loss: 1.8458187375017392

Epoch: 6| Step: 3
Training loss: 1.6918772459030151
Validation loss: 1.848937919062953

Epoch: 6| Step: 4
Training loss: 1.5445917844772339
Validation loss: 1.8544703375908635

Epoch: 6| Step: 5
Training loss: 1.3276019096374512
Validation loss: 1.8294718906443606

Epoch: 6| Step: 6
Training loss: 1.513655662536621
Validation loss: 1.8556461808502034

Epoch: 6| Step: 7
Training loss: 1.313708782196045
Validation loss: 1.8444307427252493

Epoch: 6| Step: 8
Training loss: 1.4161491394042969
Validation loss: 1.8509911362842848

Epoch: 6| Step: 9
Training loss: 1.3192483186721802
Validation loss: 1.850384530200753

Epoch: 6| Step: 10
Training loss: 1.2911396026611328
Validation loss: 1.832646869844006

Epoch: 6| Step: 11
Training loss: 1.4215021133422852
Validation loss: 1.8567029558202273

Epoch: 6| Step: 12
Training loss: 1.2485439777374268
Validation loss: 1.8300929146428262

Epoch: 6| Step: 13
Training loss: 1.2480926513671875
Validation loss: 1.8399169009218934

Epoch: 290| Step: 0
Training loss: 1.228451132774353
Validation loss: 1.8017403758982176

Epoch: 6| Step: 1
Training loss: 0.8625457286834717
Validation loss: 1.820982922789871

Epoch: 6| Step: 2
Training loss: 1.1946253776550293
Validation loss: 1.8301045061439596

Epoch: 6| Step: 3
Training loss: 1.740722894668579
Validation loss: 1.8044576901261524

Epoch: 6| Step: 4
Training loss: 1.5661969184875488
Validation loss: 1.8004516696417203

Epoch: 6| Step: 5
Training loss: 1.7361419200897217
Validation loss: 1.838049832210746

Epoch: 6| Step: 6
Training loss: 1.2324318885803223
Validation loss: 1.8622667584367978

Epoch: 6| Step: 7
Training loss: 0.8278168439865112
Validation loss: 1.8260523760190575

Epoch: 6| Step: 8
Training loss: 1.8050830364227295
Validation loss: 1.7921910388495332

Epoch: 6| Step: 9
Training loss: 2.1213550567626953
Validation loss: 1.8162883379126107

Epoch: 6| Step: 10
Training loss: 1.4181487560272217
Validation loss: 1.8515393580159833

Epoch: 6| Step: 11
Training loss: 1.438218116760254
Validation loss: 1.8369314465471493

Epoch: 6| Step: 12
Training loss: 0.9742380380630493
Validation loss: 1.8365522981971822

Epoch: 6| Step: 13
Training loss: 2.0780887603759766
Validation loss: 1.826934370943295

Epoch: 291| Step: 0
Training loss: 0.9784969091415405
Validation loss: 1.8432283375852851

Epoch: 6| Step: 1
Training loss: 1.2151122093200684
Validation loss: 1.8418724524077548

Epoch: 6| Step: 2
Training loss: 1.0187733173370361
Validation loss: 1.8378269826212237

Epoch: 6| Step: 3
Training loss: 1.9356940984725952
Validation loss: 1.8527854232377903

Epoch: 6| Step: 4
Training loss: 0.950225830078125
Validation loss: 1.8322216349263345

Epoch: 6| Step: 5
Training loss: 1.7565693855285645
Validation loss: 1.8367282267539733

Epoch: 6| Step: 6
Training loss: 0.9599627256393433
Validation loss: 1.854492437454962

Epoch: 6| Step: 7
Training loss: 1.7779062986373901
Validation loss: 1.8805173571391771

Epoch: 6| Step: 8
Training loss: 2.1965394020080566
Validation loss: 1.8132772625133555

Epoch: 6| Step: 9
Training loss: 1.4161553382873535
Validation loss: 1.841811965870601

Epoch: 6| Step: 10
Training loss: 1.3361330032348633
Validation loss: 1.8508905544075915

Epoch: 6| Step: 11
Training loss: 1.6780521869659424
Validation loss: 1.828966547084111

Epoch: 6| Step: 12
Training loss: 0.7979065179824829
Validation loss: 1.8457784319436679

Epoch: 6| Step: 13
Training loss: 2.2233893871307373
Validation loss: 1.8165550398570236

Epoch: 292| Step: 0
Training loss: 1.7100290060043335
Validation loss: 1.8826720048022527

Epoch: 6| Step: 1
Training loss: 1.7307803630828857
Validation loss: 1.8633397497156614

Epoch: 6| Step: 2
Training loss: 1.9555002450942993
Validation loss: 1.8334769305362497

Epoch: 6| Step: 3
Training loss: 0.6263846158981323
Validation loss: 1.8070970158423147

Epoch: 6| Step: 4
Training loss: 1.8634223937988281
Validation loss: 1.8190903561089629

Epoch: 6| Step: 5
Training loss: 1.4959993362426758
Validation loss: 1.8311400631422639

Epoch: 6| Step: 6
Training loss: 1.3009272813796997
Validation loss: 1.798013057760013

Epoch: 6| Step: 7
Training loss: 1.0542583465576172
Validation loss: 1.8032776988962644

Epoch: 6| Step: 8
Training loss: 1.1333234310150146
Validation loss: 1.8195814599273026

Epoch: 6| Step: 9
Training loss: 0.9162533283233643
Validation loss: 1.8361681994571482

Epoch: 6| Step: 10
Training loss: 1.3734362125396729
Validation loss: 1.7894221441720122

Epoch: 6| Step: 11
Training loss: 1.8176984786987305
Validation loss: 1.7931451028393162

Epoch: 6| Step: 12
Training loss: 1.4812268018722534
Validation loss: 1.804641745423758

Epoch: 6| Step: 13
Training loss: 0.8332021236419678
Validation loss: 1.8495644779615505

Epoch: 293| Step: 0
Training loss: 1.0362513065338135
Validation loss: 1.8763207248462144

Epoch: 6| Step: 1
Training loss: 2.0227909088134766
Validation loss: 1.8508773080764278

Epoch: 6| Step: 2
Training loss: 1.0765457153320312
Validation loss: 1.8368311979437386

Epoch: 6| Step: 3
Training loss: 1.8238348960876465
Validation loss: 1.846214113696929

Epoch: 6| Step: 4
Training loss: 1.5339314937591553
Validation loss: 1.8258295674477854

Epoch: 6| Step: 5
Training loss: 1.1217693090438843
Validation loss: 1.8758144237661873

Epoch: 6| Step: 6
Training loss: 1.373714804649353
Validation loss: 1.8491856487848426

Epoch: 6| Step: 7
Training loss: 1.6223191022872925
Validation loss: 1.8708186816143733

Epoch: 6| Step: 8
Training loss: 1.6587507724761963
Validation loss: 1.8429183498505624

Epoch: 6| Step: 9
Training loss: 1.3765578269958496
Validation loss: 1.8044921685290594

Epoch: 6| Step: 10
Training loss: 1.7957491874694824
Validation loss: 1.7813056521518256

Epoch: 6| Step: 11
Training loss: 1.2753121852874756
Validation loss: 1.8393314077008156

Epoch: 6| Step: 12
Training loss: 1.115120530128479
Validation loss: 1.8103719936904086

Epoch: 6| Step: 13
Training loss: 1.416532278060913
Validation loss: 1.827095156074852

Epoch: 294| Step: 0
Training loss: 1.5390655994415283
Validation loss: 1.780364340351474

Epoch: 6| Step: 1
Training loss: 1.3301475048065186
Validation loss: 1.8263378271492579

Epoch: 6| Step: 2
Training loss: 1.2703807353973389
Validation loss: 1.7949465487592964

Epoch: 6| Step: 3
Training loss: 1.1485670804977417
Validation loss: 1.7972429119130617

Epoch: 6| Step: 4
Training loss: 2.17061185836792
Validation loss: 1.7887904131284325

Epoch: 6| Step: 5
Training loss: 1.1415306329727173
Validation loss: 1.790341579785911

Epoch: 6| Step: 6
Training loss: 2.08839750289917
Validation loss: 1.82834118412387

Epoch: 6| Step: 7
Training loss: 1.6682639122009277
Validation loss: 1.7954087231748848

Epoch: 6| Step: 8
Training loss: 1.1769511699676514
Validation loss: 1.8178831749064948

Epoch: 6| Step: 9
Training loss: 1.2369320392608643
Validation loss: 1.8156284196402437

Epoch: 6| Step: 10
Training loss: 1.0137498378753662
Validation loss: 1.8347887787767636

Epoch: 6| Step: 11
Training loss: 1.6263866424560547
Validation loss: 1.8490006334038191

Epoch: 6| Step: 12
Training loss: 0.7643810510635376
Validation loss: 1.866560628337245

Epoch: 6| Step: 13
Training loss: 1.82469642162323
Validation loss: 1.8413182291933285

Epoch: 295| Step: 0
Training loss: 2.1875832080841064
Validation loss: 1.8200081086927844

Epoch: 6| Step: 1
Training loss: 1.8182549476623535
Validation loss: 1.839666957496315

Epoch: 6| Step: 2
Training loss: 1.1146485805511475
Validation loss: 1.837170475272722

Epoch: 6| Step: 3
Training loss: 1.3855420351028442
Validation loss: 1.8237586072696153

Epoch: 6| Step: 4
Training loss: 1.5536822080612183
Validation loss: 1.796978066044469

Epoch: 6| Step: 5
Training loss: 1.2727540731430054
Validation loss: 1.85034324917742

Epoch: 6| Step: 6
Training loss: 0.9638172388076782
Validation loss: 1.83935514573128

Epoch: 6| Step: 7
Training loss: 0.9796891212463379
Validation loss: 1.8351450043339883

Epoch: 6| Step: 8
Training loss: 1.0359489917755127
Validation loss: 1.8751492705396426

Epoch: 6| Step: 9
Training loss: 1.0713114738464355
Validation loss: 1.8443344536648

Epoch: 6| Step: 10
Training loss: 2.375990390777588
Validation loss: 1.8257754310484855

Epoch: 6| Step: 11
Training loss: 1.0666570663452148
Validation loss: 1.8482435954514371

Epoch: 6| Step: 12
Training loss: 1.2850148677825928
Validation loss: 1.854862428480579

Epoch: 6| Step: 13
Training loss: 1.128895878791809
Validation loss: 1.804431430755123

Epoch: 296| Step: 0
Training loss: 1.6481612920761108
Validation loss: 1.8034434574906544

Epoch: 6| Step: 1
Training loss: 1.2184935808181763
Validation loss: 1.8500391898616668

Epoch: 6| Step: 2
Training loss: 1.1401185989379883
Validation loss: 1.8199563334065099

Epoch: 6| Step: 3
Training loss: 1.0688040256500244
Validation loss: 1.819957351171842

Epoch: 6| Step: 4
Training loss: 1.2683204412460327
Validation loss: 1.8435407274512834

Epoch: 6| Step: 5
Training loss: 1.3865244388580322
Validation loss: 1.8010582026614939

Epoch: 6| Step: 6
Training loss: 1.441237211227417
Validation loss: 1.7997576998126121

Epoch: 6| Step: 7
Training loss: 0.9722859859466553
Validation loss: 1.7997927358073573

Epoch: 6| Step: 8
Training loss: 1.3236889839172363
Validation loss: 1.800569280501335

Epoch: 6| Step: 9
Training loss: 2.329864025115967
Validation loss: 1.8001759103549424

Epoch: 6| Step: 10
Training loss: 1.8198540210723877
Validation loss: 1.802591468698235

Epoch: 6| Step: 11
Training loss: 1.9309489727020264
Validation loss: 1.8208807847833122

Epoch: 6| Step: 12
Training loss: 0.6420207023620605
Validation loss: 1.8426031874072166

Epoch: 6| Step: 13
Training loss: 1.2316663265228271
Validation loss: 1.8470157948873376

Epoch: 297| Step: 0
Training loss: 1.8173296451568604
Validation loss: 1.833862086778046

Epoch: 6| Step: 1
Training loss: 1.6346865892410278
Validation loss: 1.8180272579193115

Epoch: 6| Step: 2
Training loss: 1.0616739988327026
Validation loss: 1.8347973426183064

Epoch: 6| Step: 3
Training loss: 2.4153144359588623
Validation loss: 1.8373564904735935

Epoch: 6| Step: 4
Training loss: 0.8305720090866089
Validation loss: 1.8451350965807516

Epoch: 6| Step: 5
Training loss: 1.1679277420043945
Validation loss: 1.8367136140023508

Epoch: 6| Step: 6
Training loss: 1.3429110050201416
Validation loss: 1.8429059213207615

Epoch: 6| Step: 7
Training loss: 0.758605420589447
Validation loss: 1.800918976465861

Epoch: 6| Step: 8
Training loss: 2.0071370601654053
Validation loss: 1.8536676309442008

Epoch: 6| Step: 9
Training loss: 1.2319025993347168
Validation loss: 1.8500797325564968

Epoch: 6| Step: 10
Training loss: 1.5040428638458252
Validation loss: 1.797666911155947

Epoch: 6| Step: 11
Training loss: 1.2027122974395752
Validation loss: 1.8108947251432685

Epoch: 6| Step: 12
Training loss: 1.1055703163146973
Validation loss: 1.8620069565311554

Epoch: 6| Step: 13
Training loss: 1.3279441595077515
Validation loss: 1.8192811524996193

Epoch: 298| Step: 0
Training loss: 0.8504607677459717
Validation loss: 1.8272712307591592

Epoch: 6| Step: 1
Training loss: 1.4140830039978027
Validation loss: 1.7930922918422247

Epoch: 6| Step: 2
Training loss: 2.167379856109619
Validation loss: 1.809188735100531

Epoch: 6| Step: 3
Training loss: 1.6121768951416016
Validation loss: 1.802581178244724

Epoch: 6| Step: 4
Training loss: 2.014697551727295
Validation loss: 1.8309138436471262

Epoch: 6| Step: 5
Training loss: 1.446010708808899
Validation loss: 1.785089058260764

Epoch: 6| Step: 6
Training loss: 1.6466389894485474
Validation loss: 1.813027407533379

Epoch: 6| Step: 7
Training loss: 1.3260531425476074
Validation loss: 1.8681378544017833

Epoch: 6| Step: 8
Training loss: 1.028066873550415
Validation loss: 1.824814473429034

Epoch: 6| Step: 9
Training loss: 0.9593339562416077
Validation loss: 1.8011239843983804

Epoch: 6| Step: 10
Training loss: 1.6834900379180908
Validation loss: 1.776335080464681

Epoch: 6| Step: 11
Training loss: 1.0846244096755981
Validation loss: 1.8147763154839958

Epoch: 6| Step: 12
Training loss: 1.2415556907653809
Validation loss: 1.8002201869923582

Epoch: 6| Step: 13
Training loss: 1.2427703142166138
Validation loss: 1.8583175687379734

Epoch: 299| Step: 0
Training loss: 1.7694761753082275
Validation loss: 1.8348629756640362

Epoch: 6| Step: 1
Training loss: 1.4129765033721924
Validation loss: 1.8675858295092018

Epoch: 6| Step: 2
Training loss: 2.2439587116241455
Validation loss: 1.8142580934750137

Epoch: 6| Step: 3
Training loss: 1.6024727821350098
Validation loss: 1.882739169623262

Epoch: 6| Step: 4
Training loss: 0.9457443356513977
Validation loss: 1.9009100224382134

Epoch: 6| Step: 5
Training loss: 1.2438833713531494
Validation loss: 1.8834988737619052

Epoch: 6| Step: 6
Training loss: 1.5452213287353516
Validation loss: 1.8584066398682133

Epoch: 6| Step: 7
Training loss: 1.2381237745285034
Validation loss: 1.8989704308971282

Epoch: 6| Step: 8
Training loss: 1.224482536315918
Validation loss: 1.8933378445204867

Epoch: 6| Step: 9
Training loss: 0.6294929385185242
Validation loss: 1.8814295132954915

Epoch: 6| Step: 10
Training loss: 1.8869900703430176
Validation loss: 1.8348994819066857

Epoch: 6| Step: 11
Training loss: 1.243483304977417
Validation loss: 1.852663791307839

Epoch: 6| Step: 12
Training loss: 1.0957090854644775
Validation loss: 1.8218709191968363

Epoch: 6| Step: 13
Training loss: 1.6511811017990112
Validation loss: 1.7838718019505984

Epoch: 300| Step: 0
Training loss: 1.225895643234253
Validation loss: 1.8671108561177407

Epoch: 6| Step: 1
Training loss: 1.1356751918792725
Validation loss: 1.8067685980950632

Epoch: 6| Step: 2
Training loss: 1.2862818241119385
Validation loss: 1.8089349462139992

Epoch: 6| Step: 3
Training loss: 1.6185860633850098
Validation loss: 1.8229299693979242

Epoch: 6| Step: 4
Training loss: 1.4913603067398071
Validation loss: 1.8281758434029036

Epoch: 6| Step: 5
Training loss: 1.9459514617919922
Validation loss: 1.7799870890955771

Epoch: 6| Step: 6
Training loss: 1.3018585443496704
Validation loss: 1.8063900086187548

Epoch: 6| Step: 7
Training loss: 1.5207850933074951
Validation loss: 1.7915386358896892

Epoch: 6| Step: 8
Training loss: 1.152623176574707
Validation loss: 1.8112869916423675

Epoch: 6| Step: 9
Training loss: 1.343109369277954
Validation loss: 1.81466600202745

Epoch: 6| Step: 10
Training loss: 1.3513377904891968
Validation loss: 1.8219726380481516

Epoch: 6| Step: 11
Training loss: 1.4350755214691162
Validation loss: 1.8166526427832983

Epoch: 6| Step: 12
Training loss: 0.9178056716918945
Validation loss: 1.7936175753993373

Epoch: 6| Step: 13
Training loss: 1.8216005563735962
Validation loss: 1.821050279883928

Epoch: 301| Step: 0
Training loss: 1.8794671297073364
Validation loss: 1.8361861116142684

Epoch: 6| Step: 1
Training loss: 1.0605067014694214
Validation loss: 1.8285368424589916

Epoch: 6| Step: 2
Training loss: 1.6810129880905151
Validation loss: 1.8159628991157777

Epoch: 6| Step: 3
Training loss: 1.1481456756591797
Validation loss: 1.849670761375017

Epoch: 6| Step: 4
Training loss: 1.752336025238037
Validation loss: 1.8683094350240563

Epoch: 6| Step: 5
Training loss: 1.570481538772583
Validation loss: 1.799414086085494

Epoch: 6| Step: 6
Training loss: 1.0808757543563843
Validation loss: 1.8308530969004477

Epoch: 6| Step: 7
Training loss: 2.021061420440674
Validation loss: 1.8487005297855665

Epoch: 6| Step: 8
Training loss: 1.1195473670959473
Validation loss: 1.8061025258033507

Epoch: 6| Step: 9
Training loss: 1.6102392673492432
Validation loss: 1.8339083874097435

Epoch: 6| Step: 10
Training loss: 1.8365459442138672
Validation loss: 1.9231032966285624

Epoch: 6| Step: 11
Training loss: 0.749193012714386
Validation loss: 1.829718033472697

Epoch: 6| Step: 12
Training loss: 0.8039358854293823
Validation loss: 1.8341926682379939

Epoch: 6| Step: 13
Training loss: 1.1264798641204834
Validation loss: 1.8435198004527757

Epoch: 302| Step: 0
Training loss: 1.6374855041503906
Validation loss: 1.8608199088804183

Epoch: 6| Step: 1
Training loss: 1.416991114616394
Validation loss: 1.8491321443229594

Epoch: 6| Step: 2
Training loss: 1.2600328922271729
Validation loss: 1.7781414883111113

Epoch: 6| Step: 3
Training loss: 1.0754210948944092
Validation loss: 1.812766759626327

Epoch: 6| Step: 4
Training loss: 1.8737449645996094
Validation loss: 1.8535012096487067

Epoch: 6| Step: 5
Training loss: 1.447609782218933
Validation loss: 1.8000486576428978

Epoch: 6| Step: 6
Training loss: 1.2617287635803223
Validation loss: 1.8199091252460275

Epoch: 6| Step: 7
Training loss: 1.640047311782837
Validation loss: 1.8380935435654016

Epoch: 6| Step: 8
Training loss: 1.5540339946746826
Validation loss: 1.8143663867827384

Epoch: 6| Step: 9
Training loss: 1.1298513412475586
Validation loss: 1.7911197703371766

Epoch: 6| Step: 10
Training loss: 1.7090661525726318
Validation loss: 1.8247535100547216

Epoch: 6| Step: 11
Training loss: 1.417765736579895
Validation loss: 1.8417179379411923

Epoch: 6| Step: 12
Training loss: 1.1447184085845947
Validation loss: 1.7847279438408472

Epoch: 6| Step: 13
Training loss: 0.9323550462722778
Validation loss: 1.8441131999415736

Epoch: 303| Step: 0
Training loss: 1.0250890254974365
Validation loss: 1.809628636606278

Epoch: 6| Step: 1
Training loss: 1.8452773094177246
Validation loss: 1.8482834177632486

Epoch: 6| Step: 2
Training loss: 1.6087125539779663
Validation loss: 1.8625674760469826

Epoch: 6| Step: 3
Training loss: 0.9357056617736816
Validation loss: 1.8652259124222623

Epoch: 6| Step: 4
Training loss: 0.6525329351425171
Validation loss: 1.906981700210161

Epoch: 6| Step: 5
Training loss: 1.8618842363357544
Validation loss: 1.8657115736315328

Epoch: 6| Step: 6
Training loss: 1.8070545196533203
Validation loss: 1.8289729318311136

Epoch: 6| Step: 7
Training loss: 1.4874484539031982
Validation loss: 1.8626234531402588

Epoch: 6| Step: 8
Training loss: 1.368051528930664
Validation loss: 1.86484541175186

Epoch: 6| Step: 9
Training loss: 1.1842076778411865
Validation loss: 1.8461707958611109

Epoch: 6| Step: 10
Training loss: 1.4947680234909058
Validation loss: 1.8319458500031502

Epoch: 6| Step: 11
Training loss: 1.324603796005249
Validation loss: 1.8788303841826737

Epoch: 6| Step: 12
Training loss: 1.7532356977462769
Validation loss: 1.8311403195063274

Epoch: 6| Step: 13
Training loss: 1.1619466543197632
Validation loss: 1.776936097811627

Epoch: 304| Step: 0
Training loss: 2.098027467727661
Validation loss: 1.821243691188033

Epoch: 6| Step: 1
Training loss: 1.6551464796066284
Validation loss: 1.8243502006735852

Epoch: 6| Step: 2
Training loss: 1.340867519378662
Validation loss: 1.8049125504750076

Epoch: 6| Step: 3
Training loss: 0.9076800346374512
Validation loss: 1.829428772772512

Epoch: 6| Step: 4
Training loss: 0.7961307764053345
Validation loss: 1.8592480972249021

Epoch: 6| Step: 5
Training loss: 1.747107982635498
Validation loss: 1.862752850337695

Epoch: 6| Step: 6
Training loss: 1.3586757183074951
Validation loss: 1.7713853543804539

Epoch: 6| Step: 7
Training loss: 1.0378748178482056
Validation loss: 1.8550112632013136

Epoch: 6| Step: 8
Training loss: 1.6497188806533813
Validation loss: 1.8204508827578636

Epoch: 6| Step: 9
Training loss: 1.2356561422348022
Validation loss: 1.8069513895178353

Epoch: 6| Step: 10
Training loss: 1.8394731283187866
Validation loss: 1.769539507486487

Epoch: 6| Step: 11
Training loss: 0.9987573623657227
Validation loss: 1.848993347537133

Epoch: 6| Step: 12
Training loss: 1.0329668521881104
Validation loss: 1.8150438506116149

Epoch: 6| Step: 13
Training loss: 1.2326817512512207
Validation loss: 1.7596598543146604

Epoch: 305| Step: 0
Training loss: 0.8812060952186584
Validation loss: 1.8139903135197137

Epoch: 6| Step: 1
Training loss: 1.3267834186553955
Validation loss: 1.84323791791034

Epoch: 6| Step: 2
Training loss: 1.424285650253296
Validation loss: 1.8167196807040964

Epoch: 6| Step: 3
Training loss: 1.3494501113891602
Validation loss: 1.8406166235605876

Epoch: 6| Step: 4
Training loss: 0.7912774682044983
Validation loss: 1.790130264015608

Epoch: 6| Step: 5
Training loss: 1.1973042488098145
Validation loss: 1.8456811174269645

Epoch: 6| Step: 6
Training loss: 1.6172524690628052
Validation loss: 1.8337557674736105

Epoch: 6| Step: 7
Training loss: 1.4753053188323975
Validation loss: 1.8342739817916707

Epoch: 6| Step: 8
Training loss: 1.7062524557113647
Validation loss: 1.8072151407118766

Epoch: 6| Step: 9
Training loss: 1.8218207359313965
Validation loss: 1.8393138326624388

Epoch: 6| Step: 10
Training loss: 1.704233169555664
Validation loss: 1.8232623479699577

Epoch: 6| Step: 11
Training loss: 0.942255437374115
Validation loss: 1.8436676135627172

Epoch: 6| Step: 12
Training loss: 1.1028615236282349
Validation loss: 1.8204386388101885

Epoch: 6| Step: 13
Training loss: 2.132338523864746
Validation loss: 1.856059903739601

Epoch: 306| Step: 0
Training loss: 1.6833734512329102
Validation loss: 1.8348055001228087

Epoch: 6| Step: 1
Training loss: 1.296645164489746
Validation loss: 1.8212676932734828

Epoch: 6| Step: 2
Training loss: 1.0888899564743042
Validation loss: 1.8515843934910272

Epoch: 6| Step: 3
Training loss: 1.1836826801300049
Validation loss: 1.8023268843209872

Epoch: 6| Step: 4
Training loss: 1.529007077217102
Validation loss: 1.84057754342274

Epoch: 6| Step: 5
Training loss: 1.042640209197998
Validation loss: 1.785448501186986

Epoch: 6| Step: 6
Training loss: 1.565537691116333
Validation loss: 1.8213538738989061

Epoch: 6| Step: 7
Training loss: 0.9954748153686523
Validation loss: 1.8204238824946906

Epoch: 6| Step: 8
Training loss: 2.161644458770752
Validation loss: 1.8286942961395427

Epoch: 6| Step: 9
Training loss: 1.527266263961792
Validation loss: 1.7770679022676201

Epoch: 6| Step: 10
Training loss: 1.5041309595108032
Validation loss: 1.8189633738610052

Epoch: 6| Step: 11
Training loss: 1.2088160514831543
Validation loss: 1.8073057077264274

Epoch: 6| Step: 12
Training loss: 1.1789588928222656
Validation loss: 1.7899919838033698

Epoch: 6| Step: 13
Training loss: 1.0364298820495605
Validation loss: 1.80329381650494

Epoch: 307| Step: 0
Training loss: 1.7930598258972168
Validation loss: 1.7814958531369445

Epoch: 6| Step: 1
Training loss: 1.3814220428466797
Validation loss: 1.8222521607593825

Epoch: 6| Step: 2
Training loss: 1.2428736686706543
Validation loss: 1.8002005789869575

Epoch: 6| Step: 3
Training loss: 1.8534817695617676
Validation loss: 1.8290131938072942

Epoch: 6| Step: 4
Training loss: 1.5279505252838135
Validation loss: 1.8486849684869089

Epoch: 6| Step: 5
Training loss: 1.484649419784546
Validation loss: 1.8172505414614113

Epoch: 6| Step: 6
Training loss: 1.5533583164215088
Validation loss: 1.8367641984775502

Epoch: 6| Step: 7
Training loss: 0.7888768911361694
Validation loss: 1.8792009584365352

Epoch: 6| Step: 8
Training loss: 1.4386420249938965
Validation loss: 1.857399505953635

Epoch: 6| Step: 9
Training loss: 1.7362093925476074
Validation loss: 1.8057889822990663

Epoch: 6| Step: 10
Training loss: 0.9418423771858215
Validation loss: 1.8070898696940432

Epoch: 6| Step: 11
Training loss: 1.6088335514068604
Validation loss: 1.8494152535674393

Epoch: 6| Step: 12
Training loss: 0.43904298543930054
Validation loss: 1.824136484053827

Epoch: 6| Step: 13
Training loss: 1.2732248306274414
Validation loss: 1.8448823004640558

Epoch: 308| Step: 0
Training loss: 1.3377392292022705
Validation loss: 1.8418354988098145

Epoch: 6| Step: 1
Training loss: 1.3810505867004395
Validation loss: 1.8071678607694563

Epoch: 6| Step: 2
Training loss: 1.101276159286499
Validation loss: 1.8257506970436341

Epoch: 6| Step: 3
Training loss: 1.7496299743652344
Validation loss: 1.8253512831144436

Epoch: 6| Step: 4
Training loss: 0.8624764680862427
Validation loss: 1.814449059065952

Epoch: 6| Step: 5
Training loss: 0.9480463266372681
Validation loss: 1.789527702075179

Epoch: 6| Step: 6
Training loss: 1.6356022357940674
Validation loss: 1.8251639091840355

Epoch: 6| Step: 7
Training loss: 1.458282470703125
Validation loss: 1.8470956574204147

Epoch: 6| Step: 8
Training loss: 2.4304966926574707
Validation loss: 1.7727194691217074

Epoch: 6| Step: 9
Training loss: 1.0641248226165771
Validation loss: 1.7939300601200392

Epoch: 6| Step: 10
Training loss: 1.3537695407867432
Validation loss: 1.8307810791077153

Epoch: 6| Step: 11
Training loss: 1.7587217092514038
Validation loss: 1.7902864807395524

Epoch: 6| Step: 12
Training loss: 1.0121009349822998
Validation loss: 1.844037325151505

Epoch: 6| Step: 13
Training loss: 1.2837743759155273
Validation loss: 1.791187301758797

Epoch: 309| Step: 0
Training loss: 1.3856148719787598
Validation loss: 1.8291456007188367

Epoch: 6| Step: 1
Training loss: 1.2383203506469727
Validation loss: 1.82654562945007

Epoch: 6| Step: 2
Training loss: 1.8294435739517212
Validation loss: 1.8444766921381797

Epoch: 6| Step: 3
Training loss: 1.1384167671203613
Validation loss: 1.806066575870719

Epoch: 6| Step: 4
Training loss: 1.3156272172927856
Validation loss: 1.8126690400544034

Epoch: 6| Step: 5
Training loss: 1.389660358428955
Validation loss: 1.795370969721066

Epoch: 6| Step: 6
Training loss: 1.4589275121688843
Validation loss: 1.816670871550037

Epoch: 6| Step: 7
Training loss: 1.735607385635376
Validation loss: 1.7983302493249216

Epoch: 6| Step: 8
Training loss: 1.268695592880249
Validation loss: 1.8047129941242996

Epoch: 6| Step: 9
Training loss: 1.2852014303207397
Validation loss: 1.8058659876546552

Epoch: 6| Step: 10
Training loss: 0.8988634347915649
Validation loss: 1.7923459109439646

Epoch: 6| Step: 11
Training loss: 1.3931169509887695
Validation loss: 1.8171786518507107

Epoch: 6| Step: 12
Training loss: 1.19026517868042
Validation loss: 1.8346961698224467

Epoch: 6| Step: 13
Training loss: 1.782662272453308
Validation loss: 1.8297525503302132

Epoch: 310| Step: 0
Training loss: 1.5547537803649902
Validation loss: 1.8640838797374437

Epoch: 6| Step: 1
Training loss: 1.3968088626861572
Validation loss: 1.76926633363129

Epoch: 6| Step: 2
Training loss: 1.7854516506195068
Validation loss: 1.8101308012521395

Epoch: 6| Step: 3
Training loss: 0.9475579857826233
Validation loss: 1.797417708622512

Epoch: 6| Step: 4
Training loss: 1.5612876415252686
Validation loss: 1.8694944279168242

Epoch: 6| Step: 5
Training loss: 1.4711418151855469
Validation loss: 1.8391480676589473

Epoch: 6| Step: 6
Training loss: 0.986262321472168
Validation loss: 1.8274166071286766

Epoch: 6| Step: 7
Training loss: 0.7514649629592896
Validation loss: 1.880658903429585

Epoch: 6| Step: 8
Training loss: 1.6432411670684814
Validation loss: 1.8357121771381748

Epoch: 6| Step: 9
Training loss: 1.3228555917739868
Validation loss: 1.8789605325268162

Epoch: 6| Step: 10
Training loss: 1.188599944114685
Validation loss: 1.8203497984076058

Epoch: 6| Step: 11
Training loss: 2.2846665382385254
Validation loss: 1.854559745839847

Epoch: 6| Step: 12
Training loss: 1.092643141746521
Validation loss: 1.8498510115890092

Epoch: 6| Step: 13
Training loss: 1.5177741050720215
Validation loss: 1.8361153551327285

Epoch: 311| Step: 0
Training loss: 1.5347816944122314
Validation loss: 1.8308745609816683

Epoch: 6| Step: 1
Training loss: 1.3010450601577759
Validation loss: 1.873183040208714

Epoch: 6| Step: 2
Training loss: 1.7858208417892456
Validation loss: 1.8052510984482304

Epoch: 6| Step: 3
Training loss: 1.4737846851348877
Validation loss: 1.8458432625698786

Epoch: 6| Step: 4
Training loss: 0.95089191198349
Validation loss: 1.8662975295897453

Epoch: 6| Step: 5
Training loss: 0.9808524250984192
Validation loss: 1.8188794915394118

Epoch: 6| Step: 6
Training loss: 1.7656810283660889
Validation loss: 1.8263697906207013

Epoch: 6| Step: 7
Training loss: 1.3173755407333374
Validation loss: 1.7858827857561008

Epoch: 6| Step: 8
Training loss: 1.6334786415100098
Validation loss: 1.841955356700446

Epoch: 6| Step: 9
Training loss: 0.9888551831245422
Validation loss: 1.8233673751995128

Epoch: 6| Step: 10
Training loss: 1.3185763359069824
Validation loss: 1.8313915729522705

Epoch: 6| Step: 11
Training loss: 1.056309700012207
Validation loss: 1.8492433665901102

Epoch: 6| Step: 12
Training loss: 1.0454353094100952
Validation loss: 1.7992839710686797

Epoch: 6| Step: 13
Training loss: 1.5993834733963013
Validation loss: 1.821628983302783

Epoch: 312| Step: 0
Training loss: 1.3422636985778809
Validation loss: 1.828178769798689

Epoch: 6| Step: 1
Training loss: 0.8211459517478943
Validation loss: 1.8496912615273589

Epoch: 6| Step: 2
Training loss: 1.104241132736206
Validation loss: 1.8193795386181082

Epoch: 6| Step: 3
Training loss: 1.0932915210723877
Validation loss: 1.8287432809029855

Epoch: 6| Step: 4
Training loss: 1.481462001800537
Validation loss: 1.8023614973150275

Epoch: 6| Step: 5
Training loss: 1.3615490198135376
Validation loss: 1.868337187715756

Epoch: 6| Step: 6
Training loss: 1.0709694623947144
Validation loss: 1.8121296180191862

Epoch: 6| Step: 7
Training loss: 1.1813969612121582
Validation loss: 1.8471790039411156

Epoch: 6| Step: 8
Training loss: 1.1907001733779907
Validation loss: 1.8115753460955877

Epoch: 6| Step: 9
Training loss: 1.4969770908355713
Validation loss: 1.8211371385922996

Epoch: 6| Step: 10
Training loss: 1.298171043395996
Validation loss: 1.7884015947259881

Epoch: 6| Step: 11
Training loss: 1.4601802825927734
Validation loss: 1.8115542037512666

Epoch: 6| Step: 12
Training loss: 1.6000878810882568
Validation loss: 1.8525502822732414

Epoch: 6| Step: 13
Training loss: 2.638124704360962
Validation loss: 1.8573512441368514

Epoch: 313| Step: 0
Training loss: 0.7551610469818115
Validation loss: 1.8128014713205316

Epoch: 6| Step: 1
Training loss: 1.614298701286316
Validation loss: 1.8378727769338956

Epoch: 6| Step: 2
Training loss: 1.7268579006195068
Validation loss: 1.8854593935833182

Epoch: 6| Step: 3
Training loss: 1.5206334590911865
Validation loss: 1.8445729440258396

Epoch: 6| Step: 4
Training loss: 1.0018956661224365
Validation loss: 1.8574054830817766

Epoch: 6| Step: 5
Training loss: 1.2556617259979248
Validation loss: 1.8916366536130187

Epoch: 6| Step: 6
Training loss: 1.4192155599594116
Validation loss: 1.81357531650092

Epoch: 6| Step: 7
Training loss: 1.3305881023406982
Validation loss: 1.8802816252554617

Epoch: 6| Step: 8
Training loss: 1.3818669319152832
Validation loss: 1.8632282198116343

Epoch: 6| Step: 9
Training loss: 2.1190481185913086
Validation loss: 1.8276992369723577

Epoch: 6| Step: 10
Training loss: 1.6634936332702637
Validation loss: 1.8638385277922436

Epoch: 6| Step: 11
Training loss: 1.3707563877105713
Validation loss: 1.8214907953816075

Epoch: 6| Step: 12
Training loss: 1.0915718078613281
Validation loss: 1.8485032717386882

Epoch: 6| Step: 13
Training loss: 0.5258567333221436
Validation loss: 1.8652832866996847

Epoch: 314| Step: 0
Training loss: 1.3392298221588135
Validation loss: 1.8262765279380224

Epoch: 6| Step: 1
Training loss: 1.5217114686965942
Validation loss: 1.816906427824369

Epoch: 6| Step: 2
Training loss: 1.4168422222137451
Validation loss: 1.7968313822182276

Epoch: 6| Step: 3
Training loss: 1.4578955173492432
Validation loss: 1.8004572404328214

Epoch: 6| Step: 4
Training loss: 1.8975327014923096
Validation loss: 1.8066828379067041

Epoch: 6| Step: 5
Training loss: 1.394601583480835
Validation loss: 1.8718642009201871

Epoch: 6| Step: 6
Training loss: 1.611283302307129
Validation loss: 1.8346922807796027

Epoch: 6| Step: 7
Training loss: 1.227818489074707
Validation loss: 1.8218357998837706

Epoch: 6| Step: 8
Training loss: 0.7425268888473511
Validation loss: 1.812225657124673

Epoch: 6| Step: 9
Training loss: 0.837943434715271
Validation loss: 1.846510866636871

Epoch: 6| Step: 10
Training loss: 1.2712045907974243
Validation loss: 1.7572785039101877

Epoch: 6| Step: 11
Training loss: 0.9473979473114014
Validation loss: 1.8030165472338278

Epoch: 6| Step: 12
Training loss: 1.6418848037719727
Validation loss: 1.8393298502891295

Epoch: 6| Step: 13
Training loss: 1.4126529693603516
Validation loss: 1.801684416750426

Epoch: 315| Step: 0
Training loss: 1.3086196184158325
Validation loss: 1.8206990636805052

Epoch: 6| Step: 1
Training loss: 0.8861898183822632
Validation loss: 1.8310220446637882

Epoch: 6| Step: 2
Training loss: 0.9264709949493408
Validation loss: 1.8162975798371017

Epoch: 6| Step: 3
Training loss: 1.1978505849838257
Validation loss: 1.8365685478333504

Epoch: 6| Step: 4
Training loss: 1.2576526403427124
Validation loss: 1.8376157277373857

Epoch: 6| Step: 5
Training loss: 0.6948244571685791
Validation loss: 1.8588473130297918

Epoch: 6| Step: 6
Training loss: 1.7536375522613525
Validation loss: 1.8449122277639245

Epoch: 6| Step: 7
Training loss: 1.4721362590789795
Validation loss: 1.8158462086031515

Epoch: 6| Step: 8
Training loss: 1.3595110177993774
Validation loss: 1.8126727765606296

Epoch: 6| Step: 9
Training loss: 1.6118452548980713
Validation loss: 1.7999851216552079

Epoch: 6| Step: 10
Training loss: 2.1059987545013428
Validation loss: 1.8311049297291746

Epoch: 6| Step: 11
Training loss: 1.0614224672317505
Validation loss: 1.7720337260153987

Epoch: 6| Step: 12
Training loss: 1.5657261610031128
Validation loss: 1.794114496118279

Epoch: 6| Step: 13
Training loss: 1.7939796447753906
Validation loss: 1.8112074816098778

Epoch: 316| Step: 0
Training loss: 1.4882261753082275
Validation loss: 1.8047165550211424

Epoch: 6| Step: 1
Training loss: 1.2141274213790894
Validation loss: 1.795592156789636

Epoch: 6| Step: 2
Training loss: 1.8159301280975342
Validation loss: 1.8206487650512366

Epoch: 6| Step: 3
Training loss: 0.7561427354812622
Validation loss: 1.8144257850544427

Epoch: 6| Step: 4
Training loss: 0.8882262110710144
Validation loss: 1.857925461184594

Epoch: 6| Step: 5
Training loss: 1.6933420896530151
Validation loss: 1.886168533755887

Epoch: 6| Step: 6
Training loss: 1.5126936435699463
Validation loss: 1.806087763078751

Epoch: 6| Step: 7
Training loss: 1.101613998413086
Validation loss: 1.8109796726575462

Epoch: 6| Step: 8
Training loss: 1.2720158100128174
Validation loss: 1.7988564506653817

Epoch: 6| Step: 9
Training loss: 1.2637648582458496
Validation loss: 1.859494637417537

Epoch: 6| Step: 10
Training loss: 0.9353596568107605
Validation loss: 1.8241354585975729

Epoch: 6| Step: 11
Training loss: 1.613375186920166
Validation loss: 1.8647812412631126

Epoch: 6| Step: 12
Training loss: 1.7674527168273926
Validation loss: 1.8653120353657713

Epoch: 6| Step: 13
Training loss: 1.7588932514190674
Validation loss: 1.80082610858384

Epoch: 317| Step: 0
Training loss: 1.029871940612793
Validation loss: 1.8472047441749162

Epoch: 6| Step: 1
Training loss: 1.8287678956985474
Validation loss: 1.789531523181546

Epoch: 6| Step: 2
Training loss: 1.4476878643035889
Validation loss: 1.8067188878213205

Epoch: 6| Step: 3
Training loss: 1.1268336772918701
Validation loss: 1.8255678210207211

Epoch: 6| Step: 4
Training loss: 1.2928221225738525
Validation loss: 1.7860949616278372

Epoch: 6| Step: 5
Training loss: 1.393662691116333
Validation loss: 1.81545623143514

Epoch: 6| Step: 6
Training loss: 1.9062325954437256
Validation loss: 1.7986542063374673

Epoch: 6| Step: 7
Training loss: 1.4490891695022583
Validation loss: 1.8391797722026866

Epoch: 6| Step: 8
Training loss: 1.3260042667388916
Validation loss: 1.8177177944490988

Epoch: 6| Step: 9
Training loss: 0.8360198736190796
Validation loss: 1.8361186007017731

Epoch: 6| Step: 10
Training loss: 0.6757967472076416
Validation loss: 1.8275107568310154

Epoch: 6| Step: 11
Training loss: 1.7629127502441406
Validation loss: 1.8047957830531622

Epoch: 6| Step: 12
Training loss: 1.31836998462677
Validation loss: 1.838129061524586

Epoch: 6| Step: 13
Training loss: 1.1596957445144653
Validation loss: 1.8101675484770088

Epoch: 318| Step: 0
Training loss: 1.5556273460388184
Validation loss: 1.8486152515616467

Epoch: 6| Step: 1
Training loss: 1.1260929107666016
Validation loss: 1.8195554774294618

Epoch: 6| Step: 2
Training loss: 1.392082691192627
Validation loss: 1.8581365077726302

Epoch: 6| Step: 3
Training loss: 1.7800967693328857
Validation loss: 1.7927623538560764

Epoch: 6| Step: 4
Training loss: 1.5242719650268555
Validation loss: 1.7984504597161406

Epoch: 6| Step: 5
Training loss: 1.5369248390197754
Validation loss: 1.8488652026781471

Epoch: 6| Step: 6
Training loss: 1.0687508583068848
Validation loss: 1.8518073738262217

Epoch: 6| Step: 7
Training loss: 1.2328463792800903
Validation loss: 1.825499926843951

Epoch: 6| Step: 8
Training loss: 1.3737469911575317
Validation loss: 1.81896843576944

Epoch: 6| Step: 9
Training loss: 1.1492010354995728
Validation loss: 1.813185041950595

Epoch: 6| Step: 10
Training loss: 0.9931018352508545
Validation loss: 1.806931234175159

Epoch: 6| Step: 11
Training loss: 0.8630172610282898
Validation loss: 1.826284421387539

Epoch: 6| Step: 12
Training loss: 1.549608826637268
Validation loss: 1.8076228762185702

Epoch: 6| Step: 13
Training loss: 1.355090618133545
Validation loss: 1.8218263362043647

Epoch: 319| Step: 0
Training loss: 1.5916481018066406
Validation loss: 1.8556264215900051

Epoch: 6| Step: 1
Training loss: 1.062112808227539
Validation loss: 1.8711240278777255

Epoch: 6| Step: 2
Training loss: 1.516901969909668
Validation loss: 1.7537403004143828

Epoch: 6| Step: 3
Training loss: 1.0685588121414185
Validation loss: 1.8459419255615563

Epoch: 6| Step: 4
Training loss: 1.1272660493850708
Validation loss: 1.8281640032286286

Epoch: 6| Step: 5
Training loss: 1.4157564640045166
Validation loss: 1.7729175244608233

Epoch: 6| Step: 6
Training loss: 0.8947405815124512
Validation loss: 1.8106497692805466

Epoch: 6| Step: 7
Training loss: 1.1658129692077637
Validation loss: 1.7752906712152625

Epoch: 6| Step: 8
Training loss: 1.5200376510620117
Validation loss: 1.7819525432843033

Epoch: 6| Step: 9
Training loss: 1.1528961658477783
Validation loss: 1.8362168240290817

Epoch: 6| Step: 10
Training loss: 1.948998212814331
Validation loss: 1.8465960692333918

Epoch: 6| Step: 11
Training loss: 1.6759123802185059
Validation loss: 1.8116195073691748

Epoch: 6| Step: 12
Training loss: 1.0823874473571777
Validation loss: 1.8351489895133561

Epoch: 6| Step: 13
Training loss: 0.9001418352127075
Validation loss: 1.8057520543375323

Epoch: 320| Step: 0
Training loss: 1.4954757690429688
Validation loss: 1.8325532969608103

Epoch: 6| Step: 1
Training loss: 0.8447796106338501
Validation loss: 1.8026577952087566

Epoch: 6| Step: 2
Training loss: 1.3230522871017456
Validation loss: 1.7949321513534875

Epoch: 6| Step: 3
Training loss: 0.8036534786224365
Validation loss: 1.8165194424249793

Epoch: 6| Step: 4
Training loss: 1.6649231910705566
Validation loss: 1.785416251869612

Epoch: 6| Step: 5
Training loss: 1.828012228012085
Validation loss: 1.8266695443020071

Epoch: 6| Step: 6
Training loss: 0.9808075428009033
Validation loss: 1.8023114076224707

Epoch: 6| Step: 7
Training loss: 1.2616362571716309
Validation loss: 1.8599140464618642

Epoch: 6| Step: 8
Training loss: 1.391147494316101
Validation loss: 1.788559357325236

Epoch: 6| Step: 9
Training loss: 1.2960329055786133
Validation loss: 1.8399572859528244

Epoch: 6| Step: 10
Training loss: 1.2280277013778687
Validation loss: 1.8315660645884853

Epoch: 6| Step: 11
Training loss: 1.746727466583252
Validation loss: 1.8345491065773913

Epoch: 6| Step: 12
Training loss: 1.4696323871612549
Validation loss: 1.8019697960986887

Epoch: 6| Step: 13
Training loss: 1.0672937631607056
Validation loss: 1.8123181032878097

Epoch: 321| Step: 0
Training loss: 1.3551374673843384
Validation loss: 1.824178312414436

Epoch: 6| Step: 1
Training loss: 1.0328749418258667
Validation loss: 1.7967105527077951

Epoch: 6| Step: 2
Training loss: 1.1435022354125977
Validation loss: 1.801308157623455

Epoch: 6| Step: 3
Training loss: 1.476930022239685
Validation loss: 1.8390411510262439

Epoch: 6| Step: 4
Training loss: 1.4269521236419678
Validation loss: 1.7865836517785185

Epoch: 6| Step: 5
Training loss: 1.226567268371582
Validation loss: 1.8377842710864158

Epoch: 6| Step: 6
Training loss: 1.0310075283050537
Validation loss: 1.8420586701362365

Epoch: 6| Step: 7
Training loss: 1.3931188583374023
Validation loss: 1.819567632931535

Epoch: 6| Step: 8
Training loss: 1.3252969980239868
Validation loss: 1.8419202989147556

Epoch: 6| Step: 9
Training loss: 1.7182626724243164
Validation loss: 1.8099612420605076

Epoch: 6| Step: 10
Training loss: 1.216361403465271
Validation loss: 1.8508382945932367

Epoch: 6| Step: 11
Training loss: 1.3575727939605713
Validation loss: 1.819272756576538

Epoch: 6| Step: 12
Training loss: 1.3988615274429321
Validation loss: 1.8079655606259581

Epoch: 6| Step: 13
Training loss: 1.1340954303741455
Validation loss: 1.7955378281172885

Epoch: 322| Step: 0
Training loss: 0.5133798718452454
Validation loss: 1.8117879411225677

Epoch: 6| Step: 1
Training loss: 1.1702064275741577
Validation loss: 1.844465753083588

Epoch: 6| Step: 2
Training loss: 0.843837320804596
Validation loss: 1.8489472417421238

Epoch: 6| Step: 3
Training loss: 1.3435341119766235
Validation loss: 1.80579456462655

Epoch: 6| Step: 4
Training loss: 0.9969736337661743
Validation loss: 1.840564094563966

Epoch: 6| Step: 5
Training loss: 0.9654884338378906
Validation loss: 1.833112347510553

Epoch: 6| Step: 6
Training loss: 1.627164363861084
Validation loss: 1.8323545532841836

Epoch: 6| Step: 7
Training loss: 1.1557555198669434
Validation loss: 1.8270845874663322

Epoch: 6| Step: 8
Training loss: 1.4674248695373535
Validation loss: 1.7560422317956084

Epoch: 6| Step: 9
Training loss: 1.8885283470153809
Validation loss: 1.819833851629688

Epoch: 6| Step: 10
Training loss: 1.3624076843261719
Validation loss: 1.8056827706675376

Epoch: 6| Step: 11
Training loss: 1.7625818252563477
Validation loss: 1.8194146733130179

Epoch: 6| Step: 12
Training loss: 1.742476463317871
Validation loss: 1.846108591684731

Epoch: 6| Step: 13
Training loss: 1.8188514709472656
Validation loss: 1.8004984906924668

Epoch: 323| Step: 0
Training loss: 1.0175976753234863
Validation loss: 1.8355896229385047

Epoch: 6| Step: 1
Training loss: 1.2455971240997314
Validation loss: 1.797595711164577

Epoch: 6| Step: 2
Training loss: 1.6510300636291504
Validation loss: 1.7820440312867523

Epoch: 6| Step: 3
Training loss: 1.5946635007858276
Validation loss: 1.7865634169629825

Epoch: 6| Step: 4
Training loss: 1.2956254482269287
Validation loss: 1.8368179926308252

Epoch: 6| Step: 5
Training loss: 0.9737608432769775
Validation loss: 1.8434305306403869

Epoch: 6| Step: 6
Training loss: 1.1392247676849365
Validation loss: 1.8313334782918294

Epoch: 6| Step: 7
Training loss: 1.7085298299789429
Validation loss: 1.8233240240363664

Epoch: 6| Step: 8
Training loss: 1.3579623699188232
Validation loss: 1.8341872858744797

Epoch: 6| Step: 9
Training loss: 1.3323619365692139
Validation loss: 1.8529862921725038

Epoch: 6| Step: 10
Training loss: 1.087188720703125
Validation loss: 1.835042981691258

Epoch: 6| Step: 11
Training loss: 1.7784090042114258
Validation loss: 1.7812018663652482

Epoch: 6| Step: 12
Training loss: 1.4546962976455688
Validation loss: 1.7955421029880483

Epoch: 6| Step: 13
Training loss: 0.4836786985397339
Validation loss: 1.8185754719600882

Epoch: 324| Step: 0
Training loss: 1.7670230865478516
Validation loss: 1.821209034612102

Epoch: 6| Step: 1
Training loss: 2.029484748840332
Validation loss: 1.878439167494415

Epoch: 6| Step: 2
Training loss: 1.6790034770965576
Validation loss: 1.8637160742154686

Epoch: 6| Step: 3
Training loss: 1.373046636581421
Validation loss: 1.8276939648453907

Epoch: 6| Step: 4
Training loss: 1.1763153076171875
Validation loss: 1.8714848397880472

Epoch: 6| Step: 5
Training loss: 1.203815221786499
Validation loss: 1.8488925131418372

Epoch: 6| Step: 6
Training loss: 0.9982085227966309
Validation loss: 1.852609298562491

Epoch: 6| Step: 7
Training loss: 1.5182477235794067
Validation loss: 1.820250399651066

Epoch: 6| Step: 8
Training loss: 1.6809349060058594
Validation loss: 1.8283344776399675

Epoch: 6| Step: 9
Training loss: 0.7408648729324341
Validation loss: 1.8908553815657092

Epoch: 6| Step: 10
Training loss: 1.203390121459961
Validation loss: 1.8585556860893004

Epoch: 6| Step: 11
Training loss: 0.9430052042007446
Validation loss: 1.8710673086104854

Epoch: 6| Step: 12
Training loss: 1.2295336723327637
Validation loss: 1.803963686830254

Epoch: 6| Step: 13
Training loss: 0.5511337518692017
Validation loss: 1.7994762684709282

Epoch: 325| Step: 0
Training loss: 1.4149434566497803
Validation loss: 1.801061027793474

Epoch: 6| Step: 1
Training loss: 1.1242668628692627
Validation loss: 1.8256015303314372

Epoch: 6| Step: 2
Training loss: 1.5099612474441528
Validation loss: 1.7598654198390182

Epoch: 6| Step: 3
Training loss: 1.1773947477340698
Validation loss: 1.8379536982505553

Epoch: 6| Step: 4
Training loss: 0.9521596431732178
Validation loss: 1.8165588481451875

Epoch: 6| Step: 5
Training loss: 1.703765630722046
Validation loss: 1.8315646122860652

Epoch: 6| Step: 6
Training loss: 1.6433093547821045
Validation loss: 1.8322487595260784

Epoch: 6| Step: 7
Training loss: 1.4626201391220093
Validation loss: 1.785101439363213

Epoch: 6| Step: 8
Training loss: 1.2870028018951416
Validation loss: 1.7871066024226527

Epoch: 6| Step: 9
Training loss: 1.1060227155685425
Validation loss: 1.8092895477048812

Epoch: 6| Step: 10
Training loss: 0.7433147430419922
Validation loss: 1.8025858427888604

Epoch: 6| Step: 11
Training loss: 1.5523135662078857
Validation loss: 1.8435250584797194

Epoch: 6| Step: 12
Training loss: 1.3504594564437866
Validation loss: 1.8473536455503075

Epoch: 6| Step: 13
Training loss: 1.2463757991790771
Validation loss: 1.8293494614221717

Epoch: 326| Step: 0
Training loss: 1.3261609077453613
Validation loss: 1.8229345480600994

Epoch: 6| Step: 1
Training loss: 1.6715662479400635
Validation loss: 1.8353684922700286

Epoch: 6| Step: 2
Training loss: 1.4848871231079102
Validation loss: 1.8366791125266784

Epoch: 6| Step: 3
Training loss: 1.6886168718338013
Validation loss: 1.8607553923001854

Epoch: 6| Step: 4
Training loss: 1.7200766801834106
Validation loss: 1.856359117774553

Epoch: 6| Step: 5
Training loss: 0.8638936877250671
Validation loss: 1.8241556216311712

Epoch: 6| Step: 6
Training loss: 1.0975582599639893
Validation loss: 1.8640605608622234

Epoch: 6| Step: 7
Training loss: 1.3370773792266846
Validation loss: 1.8994392284782984

Epoch: 6| Step: 8
Training loss: 0.7973378896713257
Validation loss: 1.8512084663555186

Epoch: 6| Step: 9
Training loss: 0.9396680593490601
Validation loss: 1.8061535281519736

Epoch: 6| Step: 10
Training loss: 1.339669108390808
Validation loss: 1.841877257952126

Epoch: 6| Step: 11
Training loss: 0.9526157379150391
Validation loss: 1.8148227019976544

Epoch: 6| Step: 12
Training loss: 1.574468731880188
Validation loss: 1.8294959529753654

Epoch: 6| Step: 13
Training loss: 0.8797518014907837
Validation loss: 1.8674368499427714

Epoch: 327| Step: 0
Training loss: 1.413110613822937
Validation loss: 1.8477247017686085

Epoch: 6| Step: 1
Training loss: 1.1292213201522827
Validation loss: 1.869379469143447

Epoch: 6| Step: 2
Training loss: 1.9158363342285156
Validation loss: 1.8547253095975487

Epoch: 6| Step: 3
Training loss: 1.2914451360702515
Validation loss: 1.8329845589976157

Epoch: 6| Step: 4
Training loss: 1.1417367458343506
Validation loss: 1.85559473370993

Epoch: 6| Step: 5
Training loss: 1.021468162536621
Validation loss: 1.7660189520928167

Epoch: 6| Step: 6
Training loss: 1.0986676216125488
Validation loss: 1.8055525800233245

Epoch: 6| Step: 7
Training loss: 1.3621331453323364
Validation loss: 1.831111833613406

Epoch: 6| Step: 8
Training loss: 1.0721359252929688
Validation loss: 1.8522138185398553

Epoch: 6| Step: 9
Training loss: 1.3561838865280151
Validation loss: 1.8161677263116325

Epoch: 6| Step: 10
Training loss: 1.4546079635620117
Validation loss: 1.7789834596777474

Epoch: 6| Step: 11
Training loss: 1.0794130563735962
Validation loss: 1.8143192850133425

Epoch: 6| Step: 12
Training loss: 1.1038446426391602
Validation loss: 1.8613425813695437

Epoch: 6| Step: 13
Training loss: 2.0530683994293213
Validation loss: 1.833158311023507

Epoch: 328| Step: 0
Training loss: 1.5096280574798584
Validation loss: 1.8637542237517655

Epoch: 6| Step: 1
Training loss: 1.4510421752929688
Validation loss: 1.8196134387805898

Epoch: 6| Step: 2
Training loss: 0.90572190284729
Validation loss: 1.872040294831799

Epoch: 6| Step: 3
Training loss: 0.8169668316841125
Validation loss: 1.8756430866897746

Epoch: 6| Step: 4
Training loss: 1.3094669580459595
Validation loss: 1.8379436513429046

Epoch: 6| Step: 5
Training loss: 1.5848125219345093
Validation loss: 1.8496734890886533

Epoch: 6| Step: 6
Training loss: 1.4454619884490967
Validation loss: 1.8174996324764785

Epoch: 6| Step: 7
Training loss: 1.8044390678405762
Validation loss: 1.820240342488853

Epoch: 6| Step: 8
Training loss: 0.9908574223518372
Validation loss: 1.8274282422117007

Epoch: 6| Step: 9
Training loss: 0.746170699596405
Validation loss: 1.808528741200765

Epoch: 6| Step: 10
Training loss: 1.5975894927978516
Validation loss: 1.8048628145648586

Epoch: 6| Step: 11
Training loss: 1.3701550960540771
Validation loss: 1.8377324778546569

Epoch: 6| Step: 12
Training loss: 1.5265936851501465
Validation loss: 1.862506312708701

Epoch: 6| Step: 13
Training loss: 1.1202738285064697
Validation loss: 1.8087317315481042

Epoch: 329| Step: 0
Training loss: 0.9790387153625488
Validation loss: 1.8380856116612752

Epoch: 6| Step: 1
Training loss: 1.4895884990692139
Validation loss: 1.8466612754329559

Epoch: 6| Step: 2
Training loss: 1.6241827011108398
Validation loss: 1.8189937965844267

Epoch: 6| Step: 3
Training loss: 1.7216284275054932
Validation loss: 1.8326271157110892

Epoch: 6| Step: 4
Training loss: 1.2066917419433594
Validation loss: 1.8201720483841435

Epoch: 6| Step: 5
Training loss: 1.2892498970031738
Validation loss: 1.8296976358659807

Epoch: 6| Step: 6
Training loss: 1.4593980312347412
Validation loss: 1.8252085011492494

Epoch: 6| Step: 7
Training loss: 0.6686699390411377
Validation loss: 1.8565488887089554

Epoch: 6| Step: 8
Training loss: 2.0845696926116943
Validation loss: 1.7966589543127245

Epoch: 6| Step: 9
Training loss: 0.6856467723846436
Validation loss: 1.811926531535323

Epoch: 6| Step: 10
Training loss: 1.6999566555023193
Validation loss: 1.821793806168341

Epoch: 6| Step: 11
Training loss: 1.361400842666626
Validation loss: 1.849050974333158

Epoch: 6| Step: 12
Training loss: 0.9035932421684265
Validation loss: 1.8173910366591586

Epoch: 6| Step: 13
Training loss: 0.7205906510353088
Validation loss: 1.8564431193054363

Epoch: 330| Step: 0
Training loss: 0.5144749879837036
Validation loss: 1.8310216299949154

Epoch: 6| Step: 1
Training loss: 1.4284789562225342
Validation loss: 1.7761042553891417

Epoch: 6| Step: 2
Training loss: 1.3415541648864746
Validation loss: 1.7927091865129368

Epoch: 6| Step: 3
Training loss: 1.6114038228988647
Validation loss: 1.7963714932882657

Epoch: 6| Step: 4
Training loss: 0.9267948269844055
Validation loss: 1.8413770775641165

Epoch: 6| Step: 5
Training loss: 2.0381462574005127
Validation loss: 1.8371567931226505

Epoch: 6| Step: 6
Training loss: 0.8893086910247803
Validation loss: 1.8327043159033662

Epoch: 6| Step: 7
Training loss: 1.2430849075317383
Validation loss: 1.7871552231491252

Epoch: 6| Step: 8
Training loss: 1.1455762386322021
Validation loss: 1.8143767669636717

Epoch: 6| Step: 9
Training loss: 1.1800286769866943
Validation loss: 1.8339522859101653

Epoch: 6| Step: 10
Training loss: 1.4343030452728271
Validation loss: 1.8046853593600694

Epoch: 6| Step: 11
Training loss: 1.567474365234375
Validation loss: 1.8232887867958314

Epoch: 6| Step: 12
Training loss: 1.124199628829956
Validation loss: 1.8395402841670538

Epoch: 6| Step: 13
Training loss: 1.7358309030532837
Validation loss: 1.83492741533505

Epoch: 331| Step: 0
Training loss: 0.9694204330444336
Validation loss: 1.8531092379682808

Epoch: 6| Step: 1
Training loss: 1.3184306621551514
Validation loss: 1.8714420359621766

Epoch: 6| Step: 2
Training loss: 1.3897830247879028
Validation loss: 1.8662060089008783

Epoch: 6| Step: 3
Training loss: 1.0046741962432861
Validation loss: 1.8768909259509015

Epoch: 6| Step: 4
Training loss: 0.7932800650596619
Validation loss: 1.824918322665717

Epoch: 6| Step: 5
Training loss: 1.2636815309524536
Validation loss: 1.836325539055691

Epoch: 6| Step: 6
Training loss: 1.0886940956115723
Validation loss: 1.8658157279414516

Epoch: 6| Step: 7
Training loss: 1.611016035079956
Validation loss: 1.805259669980695

Epoch: 6| Step: 8
Training loss: 1.035390853881836
Validation loss: 1.860948931786322

Epoch: 6| Step: 9
Training loss: 1.354445457458496
Validation loss: 1.819822920266018

Epoch: 6| Step: 10
Training loss: 1.5074615478515625
Validation loss: 1.872082584647722

Epoch: 6| Step: 11
Training loss: 1.2997605800628662
Validation loss: 1.8403743902842205

Epoch: 6| Step: 12
Training loss: 1.842475175857544
Validation loss: 1.8185066061635171

Epoch: 6| Step: 13
Training loss: 1.4346177577972412
Validation loss: 1.805662191042336

Epoch: 332| Step: 0
Training loss: 1.4356727600097656
Validation loss: 1.8332465246159544

Epoch: 6| Step: 1
Training loss: 1.7948014736175537
Validation loss: 1.7790742638290569

Epoch: 6| Step: 2
Training loss: 1.0028388500213623
Validation loss: 1.872051146722609

Epoch: 6| Step: 3
Training loss: 1.358782410621643
Validation loss: 1.8181552540871404

Epoch: 6| Step: 4
Training loss: 1.3698493242263794
Validation loss: 1.7947079314980456

Epoch: 6| Step: 5
Training loss: 0.7259765863418579
Validation loss: 1.8543233153640584

Epoch: 6| Step: 6
Training loss: 1.4838643074035645
Validation loss: 1.814575110712359

Epoch: 6| Step: 7
Training loss: 1.5147751569747925
Validation loss: 1.8227160861415248

Epoch: 6| Step: 8
Training loss: 1.4892687797546387
Validation loss: 1.803000452697918

Epoch: 6| Step: 9
Training loss: 0.7984004020690918
Validation loss: 1.8380752250712404

Epoch: 6| Step: 10
Training loss: 1.1816074848175049
Validation loss: 1.856108412947706

Epoch: 6| Step: 11
Training loss: 1.3881900310516357
Validation loss: 1.870102023565641

Epoch: 6| Step: 12
Training loss: 1.1584941148757935
Validation loss: 1.8400421898852113

Epoch: 6| Step: 13
Training loss: 0.9215104579925537
Validation loss: 1.8330092135296072

Epoch: 333| Step: 0
Training loss: 1.5799553394317627
Validation loss: 1.8883354445939422

Epoch: 6| Step: 1
Training loss: 1.174106240272522
Validation loss: 1.8718628191178845

Epoch: 6| Step: 2
Training loss: 1.0865806341171265
Validation loss: 1.857205463993934

Epoch: 6| Step: 3
Training loss: 1.3167973756790161
Validation loss: 1.892076930692119

Epoch: 6| Step: 4
Training loss: 1.4382588863372803
Validation loss: 1.806647071274378

Epoch: 6| Step: 5
Training loss: 1.0078327655792236
Validation loss: 1.8760468549625848

Epoch: 6| Step: 6
Training loss: 1.399632453918457
Validation loss: 1.8097816257066623

Epoch: 6| Step: 7
Training loss: 1.4369564056396484
Validation loss: 1.83592935146824

Epoch: 6| Step: 8
Training loss: 0.9071084260940552
Validation loss: 1.8393064288682834

Epoch: 6| Step: 9
Training loss: 1.6660716533660889
Validation loss: 1.8253307098983436

Epoch: 6| Step: 10
Training loss: 1.1323862075805664
Validation loss: 1.8379088242848713

Epoch: 6| Step: 11
Training loss: 1.3024616241455078
Validation loss: 1.8207183935308968

Epoch: 6| Step: 12
Training loss: 1.5977344512939453
Validation loss: 1.8412227233250935

Epoch: 6| Step: 13
Training loss: 0.5669602155685425
Validation loss: 1.8303918633409726

Epoch: 334| Step: 0
Training loss: 1.7652184963226318
Validation loss: 1.87432780573445

Epoch: 6| Step: 1
Training loss: 1.6877570152282715
Validation loss: 1.787388414464971

Epoch: 6| Step: 2
Training loss: 1.0402553081512451
Validation loss: 1.844379017429967

Epoch: 6| Step: 3
Training loss: 1.1313198804855347
Validation loss: 1.8022564380399642

Epoch: 6| Step: 4
Training loss: 0.8534973859786987
Validation loss: 1.827609436486357

Epoch: 6| Step: 5
Training loss: 1.7666656970977783
Validation loss: 1.8320216055839293

Epoch: 6| Step: 6
Training loss: 1.1889891624450684
Validation loss: 1.8191542330608572

Epoch: 6| Step: 7
Training loss: 1.400665044784546
Validation loss: 1.766370605396968

Epoch: 6| Step: 8
Training loss: 0.8634390830993652
Validation loss: 1.8339462267455233

Epoch: 6| Step: 9
Training loss: 1.196561574935913
Validation loss: 1.810523489470123

Epoch: 6| Step: 10
Training loss: 1.1200892925262451
Validation loss: 1.819792055314587

Epoch: 6| Step: 11
Training loss: 1.084212064743042
Validation loss: 1.8073962414136497

Epoch: 6| Step: 12
Training loss: 1.459462285041809
Validation loss: 1.8275269334034254

Epoch: 6| Step: 13
Training loss: 1.4330155849456787
Validation loss: 1.8152106987532748

Epoch: 335| Step: 0
Training loss: 1.1345055103302002
Validation loss: 1.7640975598366029

Epoch: 6| Step: 1
Training loss: 1.750499963760376
Validation loss: 1.8852998466901882

Epoch: 6| Step: 2
Training loss: 1.4164079427719116
Validation loss: 1.895520794776178

Epoch: 6| Step: 3
Training loss: 0.919350266456604
Validation loss: 1.8016473452250164

Epoch: 6| Step: 4
Training loss: 1.121594786643982
Validation loss: 1.8176599087253693

Epoch: 6| Step: 5
Training loss: 1.0034359693527222
Validation loss: 1.8213750585432975

Epoch: 6| Step: 6
Training loss: 1.0477683544158936
Validation loss: 1.7937498605379494

Epoch: 6| Step: 7
Training loss: 0.9162033796310425
Validation loss: 1.875862907337886

Epoch: 6| Step: 8
Training loss: 1.7175195217132568
Validation loss: 1.8145619028358049

Epoch: 6| Step: 9
Training loss: 1.4113132953643799
Validation loss: 1.8133635879844747

Epoch: 6| Step: 10
Training loss: 1.4106590747833252
Validation loss: 1.7926552334139425

Epoch: 6| Step: 11
Training loss: 1.2405145168304443
Validation loss: 1.7947314811009232

Epoch: 6| Step: 12
Training loss: 1.365369439125061
Validation loss: 1.8210918570077548

Epoch: 6| Step: 13
Training loss: 1.0403727293014526
Validation loss: 1.8038310568819764

Epoch: 336| Step: 0
Training loss: 1.0854997634887695
Validation loss: 1.7927889388094667

Epoch: 6| Step: 1
Training loss: 1.4110374450683594
Validation loss: 1.8439466376458444

Epoch: 6| Step: 2
Training loss: 0.8836061358451843
Validation loss: 1.8089109723285963

Epoch: 6| Step: 3
Training loss: 1.3692700862884521
Validation loss: 1.850288374449617

Epoch: 6| Step: 4
Training loss: 0.8210104703903198
Validation loss: 1.7924643562686058

Epoch: 6| Step: 5
Training loss: 1.5487351417541504
Validation loss: 1.8234845387038363

Epoch: 6| Step: 6
Training loss: 1.4514830112457275
Validation loss: 1.8117876539948166

Epoch: 6| Step: 7
Training loss: 1.3338901996612549
Validation loss: 1.8121360284025951

Epoch: 6| Step: 8
Training loss: 0.8474254608154297
Validation loss: 1.8316200522966282

Epoch: 6| Step: 9
Training loss: 1.0875005722045898
Validation loss: 1.9050180117289226

Epoch: 6| Step: 10
Training loss: 1.0534089803695679
Validation loss: 1.8622221241715133

Epoch: 6| Step: 11
Training loss: 1.8782451152801514
Validation loss: 1.9241485787976174

Epoch: 6| Step: 12
Training loss: 1.5670478343963623
Validation loss: 1.8570260245312926

Epoch: 6| Step: 13
Training loss: 1.124830961227417
Validation loss: 1.8751322530931043

Epoch: 337| Step: 0
Training loss: 1.6831649541854858
Validation loss: 1.8545575705907678

Epoch: 6| Step: 1
Training loss: 1.1802575588226318
Validation loss: 1.8835742127510808

Epoch: 6| Step: 2
Training loss: 0.9377256035804749
Validation loss: 1.802051185279764

Epoch: 6| Step: 3
Training loss: 0.7203044891357422
Validation loss: 1.8665369428614134

Epoch: 6| Step: 4
Training loss: 1.4930837154388428
Validation loss: 1.8257023160175612

Epoch: 6| Step: 5
Training loss: 0.9629406332969666
Validation loss: 1.8418684941466137

Epoch: 6| Step: 6
Training loss: 0.9626362919807434
Validation loss: 1.8570686283931936

Epoch: 6| Step: 7
Training loss: 1.8163840770721436
Validation loss: 1.7905032839826358

Epoch: 6| Step: 8
Training loss: 0.9362459182739258
Validation loss: 1.8683965436873897

Epoch: 6| Step: 9
Training loss: 1.1757909059524536
Validation loss: 1.8506546994691253

Epoch: 6| Step: 10
Training loss: 1.4406275749206543
Validation loss: 1.8133291198361305

Epoch: 6| Step: 11
Training loss: 0.5894079804420471
Validation loss: 1.8250767005387174

Epoch: 6| Step: 12
Training loss: 2.1916556358337402
Validation loss: 1.8512537633219073

Epoch: 6| Step: 13
Training loss: 1.6920303106307983
Validation loss: 1.8281457001163113

Epoch: 338| Step: 0
Training loss: 1.5122816562652588
Validation loss: 1.8014070654428134

Epoch: 6| Step: 1
Training loss: 1.2588913440704346
Validation loss: 1.787469446018178

Epoch: 6| Step: 2
Training loss: 1.0302156209945679
Validation loss: 1.8189828113843036

Epoch: 6| Step: 3
Training loss: 1.5099198818206787
Validation loss: 1.8315060510430285

Epoch: 6| Step: 4
Training loss: 1.8717371225357056
Validation loss: 1.8388282329805437

Epoch: 6| Step: 5
Training loss: 1.1171886920928955
Validation loss: 1.8311188964433567

Epoch: 6| Step: 6
Training loss: 0.9792445302009583
Validation loss: 1.8473362115121656

Epoch: 6| Step: 7
Training loss: 1.2374072074890137
Validation loss: 1.8394255625304354

Epoch: 6| Step: 8
Training loss: 0.9237467050552368
Validation loss: 1.8492904516958422

Epoch: 6| Step: 9
Training loss: 1.2139358520507812
Validation loss: 1.8502922211923907

Epoch: 6| Step: 10
Training loss: 1.694242000579834
Validation loss: 1.8117061507317327

Epoch: 6| Step: 11
Training loss: 0.8299845457077026
Validation loss: 1.8348769782691874

Epoch: 6| Step: 12
Training loss: 1.4605977535247803
Validation loss: 1.8359046930907874

Epoch: 6| Step: 13
Training loss: 0.5474264621734619
Validation loss: 1.8254945431986163

Epoch: 339| Step: 0
Training loss: 1.5412631034851074
Validation loss: 1.8458877930077173

Epoch: 6| Step: 1
Training loss: 1.1790190935134888
Validation loss: 1.7826934463234358

Epoch: 6| Step: 2
Training loss: 1.3256138563156128
Validation loss: 1.820148524417672

Epoch: 6| Step: 3
Training loss: 1.9731345176696777
Validation loss: 1.7983253668713313

Epoch: 6| Step: 4
Training loss: 1.0900747776031494
Validation loss: 1.8057908165839411

Epoch: 6| Step: 5
Training loss: 0.7502833604812622
Validation loss: 1.8568510470851776

Epoch: 6| Step: 6
Training loss: 0.8759685158729553
Validation loss: 1.8257967913022606

Epoch: 6| Step: 7
Training loss: 1.3543543815612793
Validation loss: 1.8268189071327128

Epoch: 6| Step: 8
Training loss: 1.472050666809082
Validation loss: 1.831193345849232

Epoch: 6| Step: 9
Training loss: 0.9769626259803772
Validation loss: 1.8465539114449614

Epoch: 6| Step: 10
Training loss: 1.1805074214935303
Validation loss: 1.8194554569900676

Epoch: 6| Step: 11
Training loss: 0.6292041540145874
Validation loss: 1.8706680664452173

Epoch: 6| Step: 12
Training loss: 1.6944057941436768
Validation loss: 1.808961638840296

Epoch: 6| Step: 13
Training loss: 1.706133484840393
Validation loss: 1.8265888716584893

Epoch: 340| Step: 0
Training loss: 1.2382539510726929
Validation loss: 1.86920896140478

Epoch: 6| Step: 1
Training loss: 0.9114726185798645
Validation loss: 1.8620163240740377

Epoch: 6| Step: 2
Training loss: 0.5452264547348022
Validation loss: 1.8142245046554073

Epoch: 6| Step: 3
Training loss: 1.3405786752700806
Validation loss: 1.831311151545535

Epoch: 6| Step: 4
Training loss: 1.3972241878509521
Validation loss: 1.8487102126562467

Epoch: 6| Step: 5
Training loss: 0.8370504379272461
Validation loss: 1.869260972545993

Epoch: 6| Step: 6
Training loss: 1.3467202186584473
Validation loss: 1.848331694961876

Epoch: 6| Step: 7
Training loss: 1.680336356163025
Validation loss: 1.841595479237136

Epoch: 6| Step: 8
Training loss: 1.3230822086334229
Validation loss: 1.855698803419708

Epoch: 6| Step: 9
Training loss: 2.060141086578369
Validation loss: 1.8062905265438942

Epoch: 6| Step: 10
Training loss: 0.6881580948829651
Validation loss: 1.8274814454458093

Epoch: 6| Step: 11
Training loss: 1.1984056234359741
Validation loss: 1.8054507611900248

Epoch: 6| Step: 12
Training loss: 1.1883995532989502
Validation loss: 1.8303923196690057

Epoch: 6| Step: 13
Training loss: 2.109144926071167
Validation loss: 1.8329058744574105

Epoch: 341| Step: 0
Training loss: 1.3878169059753418
Validation loss: 1.8102399546612975

Epoch: 6| Step: 1
Training loss: 1.6081910133361816
Validation loss: 1.8146248107315393

Epoch: 6| Step: 2
Training loss: 1.4336731433868408
Validation loss: 1.7933823472710066

Epoch: 6| Step: 3
Training loss: 0.992834210395813
Validation loss: 1.8407606783733572

Epoch: 6| Step: 4
Training loss: 1.3698844909667969
Validation loss: 1.8101716656838693

Epoch: 6| Step: 5
Training loss: 1.010354995727539
Validation loss: 1.8411420417088333

Epoch: 6| Step: 6
Training loss: 0.8887487649917603
Validation loss: 1.8146887645926526

Epoch: 6| Step: 7
Training loss: 1.3015888929367065
Validation loss: 1.8284746523826354

Epoch: 6| Step: 8
Training loss: 0.8276535868644714
Validation loss: 1.82012471460527

Epoch: 6| Step: 9
Training loss: 1.25113046169281
Validation loss: 1.8034937535562823

Epoch: 6| Step: 10
Training loss: 1.6100661754608154
Validation loss: 1.83300926480242

Epoch: 6| Step: 11
Training loss: 1.2570295333862305
Validation loss: 1.8295788918772051

Epoch: 6| Step: 12
Training loss: 1.4356834888458252
Validation loss: 1.7987836137894662

Epoch: 6| Step: 13
Training loss: 0.9825806021690369
Validation loss: 1.8108399862884192

Epoch: 342| Step: 0
Training loss: 1.4448330402374268
Validation loss: 1.8307423694159395

Epoch: 6| Step: 1
Training loss: 1.0774879455566406
Validation loss: 1.8187130933166833

Epoch: 6| Step: 2
Training loss: 1.0016964673995972
Validation loss: 1.816405427071356

Epoch: 6| Step: 3
Training loss: 0.7609496712684631
Validation loss: 1.8597781273626512

Epoch: 6| Step: 4
Training loss: 1.5426511764526367
Validation loss: 1.8417447459313177

Epoch: 6| Step: 5
Training loss: 1.39460027217865
Validation loss: 1.8511767515572168

Epoch: 6| Step: 6
Training loss: 1.3614044189453125
Validation loss: 1.8191729437920354

Epoch: 6| Step: 7
Training loss: 1.2178363800048828
Validation loss: 1.8571843229314333

Epoch: 6| Step: 8
Training loss: 1.0831724405288696
Validation loss: 1.7838626856444983

Epoch: 6| Step: 9
Training loss: 1.170713186264038
Validation loss: 1.8274706294459682

Epoch: 6| Step: 10
Training loss: 1.4514102935791016
Validation loss: 1.8059922546468756

Epoch: 6| Step: 11
Training loss: 1.3931940793991089
Validation loss: 1.814953742488738

Epoch: 6| Step: 12
Training loss: 1.8770604133605957
Validation loss: 1.8014055503311979

Epoch: 6| Step: 13
Training loss: 1.3303581476211548
Validation loss: 1.8564671265181674

Epoch: 343| Step: 0
Training loss: 1.1772241592407227
Validation loss: 1.8254781000075802

Epoch: 6| Step: 1
Training loss: 0.9558085203170776
Validation loss: 1.8081942476252073

Epoch: 6| Step: 2
Training loss: 1.7018152475357056
Validation loss: 1.7700340670924033

Epoch: 6| Step: 3
Training loss: 1.4675085544586182
Validation loss: 1.7967091029690159

Epoch: 6| Step: 4
Training loss: 1.0776240825653076
Validation loss: 1.8170806810420046

Epoch: 6| Step: 5
Training loss: 1.2813720703125
Validation loss: 1.8169299120544105

Epoch: 6| Step: 6
Training loss: 1.8299864530563354
Validation loss: 1.8247179574863885

Epoch: 6| Step: 7
Training loss: 1.3440942764282227
Validation loss: 1.8241216239108835

Epoch: 6| Step: 8
Training loss: 0.8343471884727478
Validation loss: 1.8347136205242527

Epoch: 6| Step: 9
Training loss: 2.0828022956848145
Validation loss: 1.8435019626412341

Epoch: 6| Step: 10
Training loss: 1.053726315498352
Validation loss: 1.8495793342590332

Epoch: 6| Step: 11
Training loss: 1.022202491760254
Validation loss: 1.832556245147541

Epoch: 6| Step: 12
Training loss: 1.0802600383758545
Validation loss: 1.8060402588177753

Epoch: 6| Step: 13
Training loss: 0.3457002639770508
Validation loss: 1.8840401890457317

Epoch: 344| Step: 0
Training loss: 1.550832986831665
Validation loss: 1.7676443130739274

Epoch: 6| Step: 1
Training loss: 0.9905000329017639
Validation loss: 1.8536729671621834

Epoch: 6| Step: 2
Training loss: 1.027273178100586
Validation loss: 1.8076895257478118

Epoch: 6| Step: 3
Training loss: 0.70229172706604
Validation loss: 1.810697078704834

Epoch: 6| Step: 4
Training loss: 1.241010308265686
Validation loss: 1.8051336273070304

Epoch: 6| Step: 5
Training loss: 1.2364881038665771
Validation loss: 1.8156098793911677

Epoch: 6| Step: 6
Training loss: 1.3257169723510742
Validation loss: 1.818543339288363

Epoch: 6| Step: 7
Training loss: 1.4649416208267212
Validation loss: 1.8459273102462932

Epoch: 6| Step: 8
Training loss: 0.9186172485351562
Validation loss: 1.8321257534847464

Epoch: 6| Step: 9
Training loss: 1.5469251871109009
Validation loss: 1.7838600515037455

Epoch: 6| Step: 10
Training loss: 1.962516188621521
Validation loss: 1.7827526087402015

Epoch: 6| Step: 11
Training loss: 0.9412193298339844
Validation loss: 1.799397360893988

Epoch: 6| Step: 12
Training loss: 1.1697359085083008
Validation loss: 1.814155847795548

Epoch: 6| Step: 13
Training loss: 1.4116097688674927
Validation loss: 1.851461825832244

Epoch: 345| Step: 0
Training loss: 1.3330143690109253
Validation loss: 1.8377477033163911

Epoch: 6| Step: 1
Training loss: 1.1308091878890991
Validation loss: 1.854184667269389

Epoch: 6| Step: 2
Training loss: 1.1345511674880981
Validation loss: 1.8277168902017737

Epoch: 6| Step: 3
Training loss: 1.3565784692764282
Validation loss: 1.7986454784229238

Epoch: 6| Step: 4
Training loss: 1.2780758142471313
Validation loss: 1.81106238595901

Epoch: 6| Step: 5
Training loss: 1.5487432479858398
Validation loss: 1.826003780928991

Epoch: 6| Step: 6
Training loss: 1.0133802890777588
Validation loss: 1.827076852962535

Epoch: 6| Step: 7
Training loss: 1.3786022663116455
Validation loss: 1.834947968042025

Epoch: 6| Step: 8
Training loss: 1.4104171991348267
Validation loss: 1.8338953602698542

Epoch: 6| Step: 9
Training loss: 1.132366418838501
Validation loss: 1.7993764723500898

Epoch: 6| Step: 10
Training loss: 0.9678189158439636
Validation loss: 1.8312783010544316

Epoch: 6| Step: 11
Training loss: 1.5610218048095703
Validation loss: 1.8478359894085956

Epoch: 6| Step: 12
Training loss: 0.782494068145752
Validation loss: 1.8439566627625497

Epoch: 6| Step: 13
Training loss: 0.9294168949127197
Validation loss: 1.8030700657957344

Epoch: 346| Step: 0
Training loss: 1.040198564529419
Validation loss: 1.8326033481987574

Epoch: 6| Step: 1
Training loss: 1.0504660606384277
Validation loss: 1.8247305475255495

Epoch: 6| Step: 2
Training loss: 0.9694728851318359
Validation loss: 1.8444912382351455

Epoch: 6| Step: 3
Training loss: 1.2985920906066895
Validation loss: 1.7667621207493607

Epoch: 6| Step: 4
Training loss: 0.8394418358802795
Validation loss: 1.7778263515041721

Epoch: 6| Step: 5
Training loss: 1.8542253971099854
Validation loss: 1.8351995188702819

Epoch: 6| Step: 6
Training loss: 1.321956753730774
Validation loss: 1.788168687974253

Epoch: 6| Step: 7
Training loss: 0.7701781988143921
Validation loss: 1.8011478890654862

Epoch: 6| Step: 8
Training loss: 1.592926263809204
Validation loss: 1.8512588854758971

Epoch: 6| Step: 9
Training loss: 1.7094061374664307
Validation loss: 1.8008129955619894

Epoch: 6| Step: 10
Training loss: 1.175850510597229
Validation loss: 1.8452648270514704

Epoch: 6| Step: 11
Training loss: 1.1738461256027222
Validation loss: 1.8245238796357186

Epoch: 6| Step: 12
Training loss: 0.8977490663528442
Validation loss: 1.828466889678791

Epoch: 6| Step: 13
Training loss: 1.1736005544662476
Validation loss: 1.864965400388164

Epoch: 347| Step: 0
Training loss: 1.4635616540908813
Validation loss: 1.8439519815547492

Epoch: 6| Step: 1
Training loss: 1.055500864982605
Validation loss: 1.8073529017868863

Epoch: 6| Step: 2
Training loss: 1.166135549545288
Validation loss: 1.8459619296494352

Epoch: 6| Step: 3
Training loss: 1.0517539978027344
Validation loss: 1.812361931288114

Epoch: 6| Step: 4
Training loss: 1.215540885925293
Validation loss: 1.8307785654580722

Epoch: 6| Step: 5
Training loss: 1.065157175064087
Validation loss: 1.835014316343492

Epoch: 6| Step: 6
Training loss: 1.0623884201049805
Validation loss: 1.8007796220881964

Epoch: 6| Step: 7
Training loss: 1.8227105140686035
Validation loss: 1.8420882712128341

Epoch: 6| Step: 8
Training loss: 0.8822830319404602
Validation loss: 1.879855494345388

Epoch: 6| Step: 9
Training loss: 1.3872761726379395
Validation loss: 1.8167493753535773

Epoch: 6| Step: 10
Training loss: 0.9630123376846313
Validation loss: 1.8448084041636477

Epoch: 6| Step: 11
Training loss: 1.4969831705093384
Validation loss: 1.8275466093453028

Epoch: 6| Step: 12
Training loss: 1.6613552570343018
Validation loss: 1.7969044382854173

Epoch: 6| Step: 13
Training loss: 1.1444711685180664
Validation loss: 1.8002221379228818

Epoch: 348| Step: 0
Training loss: 1.1437550783157349
Validation loss: 1.8262238733230098

Epoch: 6| Step: 1
Training loss: 1.0121210813522339
Validation loss: 1.8178524945371894

Epoch: 6| Step: 2
Training loss: 1.2684918642044067
Validation loss: 1.8154343276895502

Epoch: 6| Step: 3
Training loss: 1.3903510570526123
Validation loss: 1.7866227780618975

Epoch: 6| Step: 4
Training loss: 1.1545188426971436
Validation loss: 1.7957530265213342

Epoch: 6| Step: 5
Training loss: 1.415283441543579
Validation loss: 1.8143901235313826

Epoch: 6| Step: 6
Training loss: 1.0429928302764893
Validation loss: 1.781196076382873

Epoch: 6| Step: 7
Training loss: 1.2762550115585327
Validation loss: 1.7896610190791469

Epoch: 6| Step: 8
Training loss: 1.149310827255249
Validation loss: 1.780568830428585

Epoch: 6| Step: 9
Training loss: 1.640649676322937
Validation loss: 1.8013402544042116

Epoch: 6| Step: 10
Training loss: 1.9274729490280151
Validation loss: 1.7920043571020967

Epoch: 6| Step: 11
Training loss: 1.029261827468872
Validation loss: 1.825413844918692

Epoch: 6| Step: 12
Training loss: 0.9567967653274536
Validation loss: 1.8302387499040174

Epoch: 6| Step: 13
Training loss: 1.0009433031082153
Validation loss: 1.7943999946758311

Epoch: 349| Step: 0
Training loss: 1.4495627880096436
Validation loss: 1.8037724841025569

Epoch: 6| Step: 1
Training loss: 1.2587883472442627
Validation loss: 1.8281063379779938

Epoch: 6| Step: 2
Training loss: 1.291577935218811
Validation loss: 1.8352064240363337

Epoch: 6| Step: 3
Training loss: 0.9773149490356445
Validation loss: 1.8805306303885676

Epoch: 6| Step: 4
Training loss: 1.1381793022155762
Validation loss: 1.8321879794520717

Epoch: 6| Step: 5
Training loss: 1.0645737648010254
Validation loss: 1.8720226851842736

Epoch: 6| Step: 6
Training loss: 0.9563980102539062
Validation loss: 1.8321196392018309

Epoch: 6| Step: 7
Training loss: 1.1952476501464844
Validation loss: 1.8090219215680194

Epoch: 6| Step: 8
Training loss: 0.9736890196800232
Validation loss: 1.858973394158066

Epoch: 6| Step: 9
Training loss: 1.1974856853485107
Validation loss: 1.8253708718925394

Epoch: 6| Step: 10
Training loss: 1.6316792964935303
Validation loss: 1.7990725489072903

Epoch: 6| Step: 11
Training loss: 1.5912580490112305
Validation loss: 1.855623907940362

Epoch: 6| Step: 12
Training loss: 1.1454451084136963
Validation loss: 1.8416107290534562

Epoch: 6| Step: 13
Training loss: 1.6229476928710938
Validation loss: 1.7980913269904353

Epoch: 350| Step: 0
Training loss: 1.978602647781372
Validation loss: 1.7862237012514504

Epoch: 6| Step: 1
Training loss: 1.2246508598327637
Validation loss: 1.8414881588310323

Epoch: 6| Step: 2
Training loss: 0.9720914959907532
Validation loss: 1.8241747963813044

Epoch: 6| Step: 3
Training loss: 1.3048726320266724
Validation loss: 1.8732135923959876

Epoch: 6| Step: 4
Training loss: 1.369345784187317
Validation loss: 1.8179148384319839

Epoch: 6| Step: 5
Training loss: 1.1555249691009521
Validation loss: 1.8211609663501862

Epoch: 6| Step: 6
Training loss: 0.748927116394043
Validation loss: 1.8502839816513883

Epoch: 6| Step: 7
Training loss: 1.7724902629852295
Validation loss: 1.8256577343069098

Epoch: 6| Step: 8
Training loss: 1.1607725620269775
Validation loss: 1.803910029831753

Epoch: 6| Step: 9
Training loss: 1.1423277854919434
Validation loss: 1.8448376450487363

Epoch: 6| Step: 10
Training loss: 1.3250250816345215
Validation loss: 1.8322542354624758

Epoch: 6| Step: 11
Training loss: 0.8421890735626221
Validation loss: 1.8754319478106756

Epoch: 6| Step: 12
Training loss: 1.2578372955322266
Validation loss: 1.8890066710851525

Epoch: 6| Step: 13
Training loss: 0.8270435333251953
Validation loss: 1.829998149666735

Epoch: 351| Step: 0
Training loss: 1.3409035205841064
Validation loss: 1.8380996873301845

Epoch: 6| Step: 1
Training loss: 1.4332456588745117
Validation loss: 1.8665373299711494

Epoch: 6| Step: 2
Training loss: 1.2577495574951172
Validation loss: 1.8242178129893478

Epoch: 6| Step: 3
Training loss: 1.862319827079773
Validation loss: 1.8382452328999836

Epoch: 6| Step: 4
Training loss: 0.9613157510757446
Validation loss: 1.8284791156809816

Epoch: 6| Step: 5
Training loss: 1.121222734451294
Validation loss: 1.8054874827784877

Epoch: 6| Step: 6
Training loss: 1.0247113704681396
Validation loss: 1.8456881841023762

Epoch: 6| Step: 7
Training loss: 1.1685885190963745
Validation loss: 1.862969772790068

Epoch: 6| Step: 8
Training loss: 1.636399269104004
Validation loss: 1.8063348826541696

Epoch: 6| Step: 9
Training loss: 0.9860178232192993
Validation loss: 1.7857467230930124

Epoch: 6| Step: 10
Training loss: 1.0465271472930908
Validation loss: 1.8460621628710019

Epoch: 6| Step: 11
Training loss: 0.8531768321990967
Validation loss: 1.8470809357140654

Epoch: 6| Step: 12
Training loss: 1.3794066905975342
Validation loss: 1.797400564275762

Epoch: 6| Step: 13
Training loss: 0.9848736524581909
Validation loss: 1.867241579999206

Epoch: 352| Step: 0
Training loss: 1.114379644393921
Validation loss: 1.824774569080722

Epoch: 6| Step: 1
Training loss: 1.6030511856079102
Validation loss: 1.8289148884434854

Epoch: 6| Step: 2
Training loss: 0.9633404612541199
Validation loss: 1.8752977719870947

Epoch: 6| Step: 3
Training loss: 1.5936965942382812
Validation loss: 1.8023730234433246

Epoch: 6| Step: 4
Training loss: 1.0744075775146484
Validation loss: 1.819650629515289

Epoch: 6| Step: 5
Training loss: 1.3945600986480713
Validation loss: 1.8371021183588172

Epoch: 6| Step: 6
Training loss: 1.1195738315582275
Validation loss: 1.7955557197652838

Epoch: 6| Step: 7
Training loss: 1.1647865772247314
Validation loss: 1.7936540752328851

Epoch: 6| Step: 8
Training loss: 1.5541627407073975
Validation loss: 1.8243273445354995

Epoch: 6| Step: 9
Training loss: 1.2232166528701782
Validation loss: 1.8333554883157053

Epoch: 6| Step: 10
Training loss: 0.6212469339370728
Validation loss: 1.837743793764422

Epoch: 6| Step: 11
Training loss: 1.295088768005371
Validation loss: 1.8091255054678967

Epoch: 6| Step: 12
Training loss: 0.9199656844139099
Validation loss: 1.8196765581766765

Epoch: 6| Step: 13
Training loss: 2.0383801460266113
Validation loss: 1.8713076563291653

Epoch: 353| Step: 0
Training loss: 1.1850757598876953
Validation loss: 1.8563909210184568

Epoch: 6| Step: 1
Training loss: 1.2573288679122925
Validation loss: 1.838142002782514

Epoch: 6| Step: 2
Training loss: 1.347273588180542
Validation loss: 1.8505598627110964

Epoch: 6| Step: 3
Training loss: 0.6333651542663574
Validation loss: 1.8877212539795907

Epoch: 6| Step: 4
Training loss: 1.2461669445037842
Validation loss: 1.8423693039083993

Epoch: 6| Step: 5
Training loss: 1.6719175577163696
Validation loss: 1.7950879719949537

Epoch: 6| Step: 6
Training loss: 1.055152416229248
Validation loss: 1.835123622289268

Epoch: 6| Step: 7
Training loss: 1.0837631225585938
Validation loss: 1.8287149090920725

Epoch: 6| Step: 8
Training loss: 1.7426342964172363
Validation loss: 1.8227633789021482

Epoch: 6| Step: 9
Training loss: 1.7601795196533203
Validation loss: 1.8478349998433103

Epoch: 6| Step: 10
Training loss: 1.0193283557891846
Validation loss: 1.818414867565196

Epoch: 6| Step: 11
Training loss: 1.4344921112060547
Validation loss: 1.8224806811219902

Epoch: 6| Step: 12
Training loss: 0.9323574900627136
Validation loss: 1.7826934296597716

Epoch: 6| Step: 13
Training loss: 0.6896048188209534
Validation loss: 1.7778319517771404

Epoch: 354| Step: 0
Training loss: 0.7613877058029175
Validation loss: 1.803297342792634

Epoch: 6| Step: 1
Training loss: 1.3115079402923584
Validation loss: 1.8510230036192044

Epoch: 6| Step: 2
Training loss: 1.0964192152023315
Validation loss: 1.8514056718477638

Epoch: 6| Step: 3
Training loss: 1.7840526103973389
Validation loss: 1.8242987919879217

Epoch: 6| Step: 4
Training loss: 1.4635717868804932
Validation loss: 1.8161019048383158

Epoch: 6| Step: 5
Training loss: 1.2435551881790161
Validation loss: 1.796673010754329

Epoch: 6| Step: 6
Training loss: 0.7260974645614624
Validation loss: 1.7977581357443204

Epoch: 6| Step: 7
Training loss: 0.935310959815979
Validation loss: 1.9084770756383096

Epoch: 6| Step: 8
Training loss: 1.1791036128997803
Validation loss: 1.8211982263031827

Epoch: 6| Step: 9
Training loss: 1.6932075023651123
Validation loss: 1.8313919651892878

Epoch: 6| Step: 10
Training loss: 1.2556520700454712
Validation loss: 1.8339154387033114

Epoch: 6| Step: 11
Training loss: 1.0523444414138794
Validation loss: 1.812966533886489

Epoch: 6| Step: 12
Training loss: 1.0544847249984741
Validation loss: 1.875483969206451

Epoch: 6| Step: 13
Training loss: 1.2568411827087402
Validation loss: 1.8453070156035885

Epoch: 355| Step: 0
Training loss: 1.4004911184310913
Validation loss: 1.8238083572797879

Epoch: 6| Step: 1
Training loss: 1.235698938369751
Validation loss: 1.8765978608080136

Epoch: 6| Step: 2
Training loss: 1.0305113792419434
Validation loss: 1.8910468919302827

Epoch: 6| Step: 3
Training loss: 1.1345086097717285
Validation loss: 1.8887232734311012

Epoch: 6| Step: 4
Training loss: 1.6582242250442505
Validation loss: 1.8733801047007244

Epoch: 6| Step: 5
Training loss: 0.8001028895378113
Validation loss: 1.8300632161478843

Epoch: 6| Step: 6
Training loss: 1.3050265312194824
Validation loss: 1.8640332119439238

Epoch: 6| Step: 7
Training loss: 1.5245834589004517
Validation loss: 1.8137914205110202

Epoch: 6| Step: 8
Training loss: 0.820952832698822
Validation loss: 1.810658388240363

Epoch: 6| Step: 9
Training loss: 2.048290729522705
Validation loss: 1.811873464174168

Epoch: 6| Step: 10
Training loss: 0.9067004323005676
Validation loss: 1.8439664686879804

Epoch: 6| Step: 11
Training loss: 0.7964677214622498
Validation loss: 1.8331278242090696

Epoch: 6| Step: 12
Training loss: 1.1543848514556885
Validation loss: 1.775326903148364

Epoch: 6| Step: 13
Training loss: 1.2058683633804321
Validation loss: 1.8448855287285262

Epoch: 356| Step: 0
Training loss: 1.2713003158569336
Validation loss: 1.8089929332015335

Epoch: 6| Step: 1
Training loss: 0.7552328705787659
Validation loss: 1.8055727853569934

Epoch: 6| Step: 2
Training loss: 0.9830666780471802
Validation loss: 1.8160082063367289

Epoch: 6| Step: 3
Training loss: 0.914190948009491
Validation loss: 1.8148720815617552

Epoch: 6| Step: 4
Training loss: 0.8016319274902344
Validation loss: 1.8614882038485618

Epoch: 6| Step: 5
Training loss: 1.4864227771759033
Validation loss: 1.8468813434723885

Epoch: 6| Step: 6
Training loss: 1.6714515686035156
Validation loss: 1.8336760382498465

Epoch: 6| Step: 7
Training loss: 1.1167585849761963
Validation loss: 1.8374464050416024

Epoch: 6| Step: 8
Training loss: 0.5633182525634766
Validation loss: 1.8806202027105516

Epoch: 6| Step: 9
Training loss: 1.5638831853866577
Validation loss: 1.8287397943517214

Epoch: 6| Step: 10
Training loss: 1.1741080284118652
Validation loss: 1.8978415894251999

Epoch: 6| Step: 11
Training loss: 1.444139003753662
Validation loss: 1.8223851598719114

Epoch: 6| Step: 12
Training loss: 0.9092181921005249
Validation loss: 1.8128628269318612

Epoch: 6| Step: 13
Training loss: 1.971724033355713
Validation loss: 1.818617279811572

Epoch: 357| Step: 0
Training loss: 0.9079047441482544
Validation loss: 1.8133922917868501

Epoch: 6| Step: 1
Training loss: 1.4205342531204224
Validation loss: 1.8124915912587156

Epoch: 6| Step: 2
Training loss: 1.231642484664917
Validation loss: 1.794933972820159

Epoch: 6| Step: 3
Training loss: 0.9863940477371216
Validation loss: 1.795079561971849

Epoch: 6| Step: 4
Training loss: 1.3999196290969849
Validation loss: 1.8439801918563021

Epoch: 6| Step: 5
Training loss: 0.9178727865219116
Validation loss: 1.8421382288778982

Epoch: 6| Step: 6
Training loss: 1.0240861177444458
Validation loss: 1.8402693271636963

Epoch: 6| Step: 7
Training loss: 1.1142362356185913
Validation loss: 1.8165153303454

Epoch: 6| Step: 8
Training loss: 1.5816971063613892
Validation loss: 1.8462509468037596

Epoch: 6| Step: 9
Training loss: 1.2570891380310059
Validation loss: 1.8120008155863772

Epoch: 6| Step: 10
Training loss: 0.5080386996269226
Validation loss: 1.7781843498188963

Epoch: 6| Step: 11
Training loss: 1.3985960483551025
Validation loss: 1.816905890741656

Epoch: 6| Step: 12
Training loss: 1.42093825340271
Validation loss: 1.8690856618265952

Epoch: 6| Step: 13
Training loss: 1.1257972717285156
Validation loss: 1.78778027719067

Epoch: 358| Step: 0
Training loss: 1.290029764175415
Validation loss: 1.8199625527986916

Epoch: 6| Step: 1
Training loss: 1.3335857391357422
Validation loss: 1.776350652017901

Epoch: 6| Step: 2
Training loss: 1.1643109321594238
Validation loss: 1.8199959467816096

Epoch: 6| Step: 3
Training loss: 1.1198424100875854
Validation loss: 1.851084413066987

Epoch: 6| Step: 4
Training loss: 1.365795612335205
Validation loss: 1.811299285581035

Epoch: 6| Step: 5
Training loss: 0.854537844657898
Validation loss: 1.8040033924964167

Epoch: 6| Step: 6
Training loss: 1.1242048740386963
Validation loss: 1.849145850827617

Epoch: 6| Step: 7
Training loss: 1.1730846166610718
Validation loss: 1.8401411746137886

Epoch: 6| Step: 8
Training loss: 1.2049896717071533
Validation loss: 1.8552573111749464

Epoch: 6| Step: 9
Training loss: 1.7089760303497314
Validation loss: 1.8333356303553427

Epoch: 6| Step: 10
Training loss: 1.142666220664978
Validation loss: 1.8424517480275964

Epoch: 6| Step: 11
Training loss: 0.8143669366836548
Validation loss: 1.8603833362620363

Epoch: 6| Step: 12
Training loss: 1.418914794921875
Validation loss: 1.9122189398734801

Epoch: 6| Step: 13
Training loss: 1.117819905281067
Validation loss: 1.8683181629385999

Epoch: 359| Step: 0
Training loss: 0.9257243871688843
Validation loss: 1.7786681011158934

Epoch: 6| Step: 1
Training loss: 0.843207597732544
Validation loss: 1.8328803880240327

Epoch: 6| Step: 2
Training loss: 1.1758942604064941
Validation loss: 1.8265060942660096

Epoch: 6| Step: 3
Training loss: 1.183229923248291
Validation loss: 1.8144751966640513

Epoch: 6| Step: 4
Training loss: 1.3217073678970337
Validation loss: 1.8173490403800883

Epoch: 6| Step: 5
Training loss: 1.1849594116210938
Validation loss: 1.8143952264580676

Epoch: 6| Step: 6
Training loss: 1.1899127960205078
Validation loss: 1.8230292156178465

Epoch: 6| Step: 7
Training loss: 1.9109275341033936
Validation loss: 1.8156783811507686

Epoch: 6| Step: 8
Training loss: 1.6369680166244507
Validation loss: 1.8368235685492074

Epoch: 6| Step: 9
Training loss: 0.9355617165565491
Validation loss: 1.8337049112525037

Epoch: 6| Step: 10
Training loss: 1.6518176794052124
Validation loss: 1.8196870101395475

Epoch: 6| Step: 11
Training loss: 0.6573242545127869
Validation loss: 1.806186395306741

Epoch: 6| Step: 12
Training loss: 1.1981236934661865
Validation loss: 1.844343969898839

Epoch: 6| Step: 13
Training loss: 0.9751780033111572
Validation loss: 1.8155677318572998

Epoch: 360| Step: 0
Training loss: 0.8075685501098633
Validation loss: 1.839162850892672

Epoch: 6| Step: 1
Training loss: 1.479857325553894
Validation loss: 1.822799482653218

Epoch: 6| Step: 2
Training loss: 1.1504836082458496
Validation loss: 1.815811490499845

Epoch: 6| Step: 3
Training loss: 1.0696992874145508
Validation loss: 1.8351422843112741

Epoch: 6| Step: 4
Training loss: 1.1373138427734375
Validation loss: 1.8094253232402187

Epoch: 6| Step: 5
Training loss: 1.4153456687927246
Validation loss: 1.825426265757571

Epoch: 6| Step: 6
Training loss: 0.824085533618927
Validation loss: 1.8555119370901456

Epoch: 6| Step: 7
Training loss: 1.2450320720672607
Validation loss: 1.8529555438667216

Epoch: 6| Step: 8
Training loss: 0.9818463921546936
Validation loss: 1.8755576636201592

Epoch: 6| Step: 9
Training loss: 1.348449945449829
Validation loss: 1.8719298096113308

Epoch: 6| Step: 10
Training loss: 1.145073413848877
Validation loss: 1.7969250230379001

Epoch: 6| Step: 11
Training loss: 1.2115716934204102
Validation loss: 1.8373243719018915

Epoch: 6| Step: 12
Training loss: 1.4361917972564697
Validation loss: 1.868273760682793

Epoch: 6| Step: 13
Training loss: 1.5640721321105957
Validation loss: 1.858184975962485

Epoch: 361| Step: 0
Training loss: 1.159469723701477
Validation loss: 1.8103095228954027

Epoch: 6| Step: 1
Training loss: 1.2472329139709473
Validation loss: 1.862550864937485

Epoch: 6| Step: 2
Training loss: 1.4989125728607178
Validation loss: 1.844245364589076

Epoch: 6| Step: 3
Training loss: 0.8549386858940125
Validation loss: 1.7789971213186941

Epoch: 6| Step: 4
Training loss: 1.3977335691452026
Validation loss: 1.79727864649988

Epoch: 6| Step: 5
Training loss: 1.3868533372879028
Validation loss: 1.8531792971395677

Epoch: 6| Step: 6
Training loss: 0.6985655426979065
Validation loss: 1.798328920077252

Epoch: 6| Step: 7
Training loss: 1.2306363582611084
Validation loss: 1.8494434343871249

Epoch: 6| Step: 8
Training loss: 1.1975923776626587
Validation loss: 1.7924911565678094

Epoch: 6| Step: 9
Training loss: 1.748253583908081
Validation loss: 1.8442920984760407

Epoch: 6| Step: 10
Training loss: 0.7942239046096802
Validation loss: 1.8301210044532694

Epoch: 6| Step: 11
Training loss: 1.3956117630004883
Validation loss: 1.8298731568039104

Epoch: 6| Step: 12
Training loss: 1.1927988529205322
Validation loss: 1.8325097227609286

Epoch: 6| Step: 13
Training loss: 0.9307318925857544
Validation loss: 1.8657169290768203

Epoch: 362| Step: 0
Training loss: 1.1634644269943237
Validation loss: 1.8389546717366865

Epoch: 6| Step: 1
Training loss: 1.4925507307052612
Validation loss: 1.8266650963855047

Epoch: 6| Step: 2
Training loss: 1.3407446146011353
Validation loss: 1.8870014529074393

Epoch: 6| Step: 3
Training loss: 0.859693706035614
Validation loss: 1.8239728917357743

Epoch: 6| Step: 4
Training loss: 1.4584518671035767
Validation loss: 1.8505948551239506

Epoch: 6| Step: 5
Training loss: 1.2047064304351807
Validation loss: 1.8356328343832364

Epoch: 6| Step: 6
Training loss: 1.3329789638519287
Validation loss: 1.8595588630245579

Epoch: 6| Step: 7
Training loss: 0.4656977653503418
Validation loss: 1.843733851627637

Epoch: 6| Step: 8
Training loss: 1.0172935724258423
Validation loss: 1.8344804881721415

Epoch: 6| Step: 9
Training loss: 1.577843189239502
Validation loss: 1.8076596170343378

Epoch: 6| Step: 10
Training loss: 1.4352846145629883
Validation loss: 1.8269382446042952

Epoch: 6| Step: 11
Training loss: 0.8647736310958862
Validation loss: 1.831141189862323

Epoch: 6| Step: 12
Training loss: 1.2311779260635376
Validation loss: 1.804573151373094

Epoch: 6| Step: 13
Training loss: 0.8958426713943481
Validation loss: 1.799195953594741

Epoch: 363| Step: 0
Training loss: 1.0869580507278442
Validation loss: 1.828998060636623

Epoch: 6| Step: 1
Training loss: 1.5014104843139648
Validation loss: 1.8479202716581282

Epoch: 6| Step: 2
Training loss: 0.8373856544494629
Validation loss: 1.8378994413601455

Epoch: 6| Step: 3
Training loss: 1.041595220565796
Validation loss: 1.8854775153180605

Epoch: 6| Step: 4
Training loss: 0.6763321757316589
Validation loss: 1.8042913559944398

Epoch: 6| Step: 5
Training loss: 1.525160312652588
Validation loss: 1.843976487395584

Epoch: 6| Step: 6
Training loss: 1.0968180894851685
Validation loss: 1.791750825861449

Epoch: 6| Step: 7
Training loss: 1.3124048709869385
Validation loss: 1.8758539640775291

Epoch: 6| Step: 8
Training loss: 1.0579924583435059
Validation loss: 1.8707378474614953

Epoch: 6| Step: 9
Training loss: 1.9951313734054565
Validation loss: 1.8030581371758574

Epoch: 6| Step: 10
Training loss: 1.1602181196212769
Validation loss: 1.8489416671055618

Epoch: 6| Step: 11
Training loss: 1.321885585784912
Validation loss: 1.822587428554412

Epoch: 6| Step: 12
Training loss: 0.7938607335090637
Validation loss: 1.81460541038103

Epoch: 6| Step: 13
Training loss: 1.3232208490371704
Validation loss: 1.8080200200439782

Epoch: 364| Step: 0
Training loss: 1.166532039642334
Validation loss: 1.820235021652714

Epoch: 6| Step: 1
Training loss: 0.8257745504379272
Validation loss: 1.7949186345582366

Epoch: 6| Step: 2
Training loss: 0.8132978081703186
Validation loss: 1.8446865799606487

Epoch: 6| Step: 3
Training loss: 1.0262258052825928
Validation loss: 1.8228735577675603

Epoch: 6| Step: 4
Training loss: 1.3231781721115112
Validation loss: 1.8239300430461924

Epoch: 6| Step: 5
Training loss: 1.2336313724517822
Validation loss: 1.835036067552464

Epoch: 6| Step: 6
Training loss: 1.3445641994476318
Validation loss: 1.8768823121183662

Epoch: 6| Step: 7
Training loss: 1.4689440727233887
Validation loss: 1.767068902651469

Epoch: 6| Step: 8
Training loss: 0.7766138315200806
Validation loss: 1.809415449378311

Epoch: 6| Step: 9
Training loss: 1.1729077100753784
Validation loss: 1.826486559324367

Epoch: 6| Step: 10
Training loss: 2.280762195587158
Validation loss: 1.8807103941517491

Epoch: 6| Step: 11
Training loss: 1.293365716934204
Validation loss: 1.8319817781448364

Epoch: 6| Step: 12
Training loss: 1.0198652744293213
Validation loss: 1.8663373480560959

Epoch: 6| Step: 13
Training loss: 0.6785640716552734
Validation loss: 1.8281069993972778

Epoch: 365| Step: 0
Training loss: 1.5181388854980469
Validation loss: 1.845926777009041

Epoch: 6| Step: 1
Training loss: 0.6528559923171997
Validation loss: 1.865794122859996

Epoch: 6| Step: 2
Training loss: 1.6871258020401
Validation loss: 1.8663864033196562

Epoch: 6| Step: 3
Training loss: 0.856099545955658
Validation loss: 1.874176606055229

Epoch: 6| Step: 4
Training loss: 1.7747740745544434
Validation loss: 1.8821141976182179

Epoch: 6| Step: 5
Training loss: 0.9530971646308899
Validation loss: 1.9026158368715675

Epoch: 6| Step: 6
Training loss: 0.9652021527290344
Validation loss: 1.859872857729594

Epoch: 6| Step: 7
Training loss: 1.4707897901535034
Validation loss: 1.844457519951687

Epoch: 6| Step: 8
Training loss: 1.0654101371765137
Validation loss: 1.8125212628354308

Epoch: 6| Step: 9
Training loss: 0.9281677007675171
Validation loss: 1.8230858220848987

Epoch: 6| Step: 10
Training loss: 1.421325922012329
Validation loss: 1.8413738371223531

Epoch: 6| Step: 11
Training loss: 1.2444411516189575
Validation loss: 1.8224279598523212

Epoch: 6| Step: 12
Training loss: 0.7817918658256531
Validation loss: 1.8518455015715731

Epoch: 6| Step: 13
Training loss: 1.0321438312530518
Validation loss: 1.8180422872625372

Epoch: 366| Step: 0
Training loss: 1.2264001369476318
Validation loss: 1.8262263651817077

Epoch: 6| Step: 1
Training loss: 1.5624825954437256
Validation loss: 1.8388532823131931

Epoch: 6| Step: 2
Training loss: 1.3290770053863525
Validation loss: 1.8870202097841489

Epoch: 6| Step: 3
Training loss: 1.3079490661621094
Validation loss: 1.812345564365387

Epoch: 6| Step: 4
Training loss: 0.7935708165168762
Validation loss: 1.8669643914827736

Epoch: 6| Step: 5
Training loss: 1.4581501483917236
Validation loss: 1.8622891749105146

Epoch: 6| Step: 6
Training loss: 0.8257415294647217
Validation loss: 1.8285239909284858

Epoch: 6| Step: 7
Training loss: 1.5284740924835205
Validation loss: 1.8254154997487222

Epoch: 6| Step: 8
Training loss: 0.6927357316017151
Validation loss: 1.8258457414565548

Epoch: 6| Step: 9
Training loss: 0.9907795190811157
Validation loss: 1.82823311257106

Epoch: 6| Step: 10
Training loss: 1.3237299919128418
Validation loss: 1.805624267106415

Epoch: 6| Step: 11
Training loss: 1.033635139465332
Validation loss: 1.8862325427352742

Epoch: 6| Step: 12
Training loss: 1.5075783729553223
Validation loss: 1.840405447508699

Epoch: 6| Step: 13
Training loss: 0.91089928150177
Validation loss: 1.8734843295107606

Epoch: 367| Step: 0
Training loss: 1.3557343482971191
Validation loss: 1.7822232323308145

Epoch: 6| Step: 1
Training loss: 1.9219989776611328
Validation loss: 1.8555701304507513

Epoch: 6| Step: 2
Training loss: 0.8395869731903076
Validation loss: 1.798768155036434

Epoch: 6| Step: 3
Training loss: 0.9282494187355042
Validation loss: 1.8251865807399954

Epoch: 6| Step: 4
Training loss: 0.8714393377304077
Validation loss: 1.8153452245138024

Epoch: 6| Step: 5
Training loss: 1.4607517719268799
Validation loss: 1.8620874651016728

Epoch: 6| Step: 6
Training loss: 1.312537431716919
Validation loss: 1.8221809069315593

Epoch: 6| Step: 7
Training loss: 0.6087351441383362
Validation loss: 1.837003557912765

Epoch: 6| Step: 8
Training loss: 1.0550789833068848
Validation loss: 1.7958280450554305

Epoch: 6| Step: 9
Training loss: 0.9987099170684814
Validation loss: 1.8886781020831036

Epoch: 6| Step: 10
Training loss: 1.0618088245391846
Validation loss: 1.813175033497554

Epoch: 6| Step: 11
Training loss: 1.185015082359314
Validation loss: 1.8080672794772732

Epoch: 6| Step: 12
Training loss: 1.745449423789978
Validation loss: 1.8435712770749164

Epoch: 6| Step: 13
Training loss: 0.7084053754806519
Validation loss: 1.784441283954087

Epoch: 368| Step: 0
Training loss: 1.000075340270996
Validation loss: 1.8802282502574306

Epoch: 6| Step: 1
Training loss: 1.1543991565704346
Validation loss: 1.8667634200024348

Epoch: 6| Step: 2
Training loss: 1.3041739463806152
Validation loss: 1.8708146272167083

Epoch: 6| Step: 3
Training loss: 1.3141083717346191
Validation loss: 1.8573514940918132

Epoch: 6| Step: 4
Training loss: 1.6348214149475098
Validation loss: 1.8561451652998566

Epoch: 6| Step: 5
Training loss: 1.266310691833496
Validation loss: 1.8650204725162958

Epoch: 6| Step: 6
Training loss: 1.5989019870758057
Validation loss: 1.8188364210949148

Epoch: 6| Step: 7
Training loss: 0.8493247032165527
Validation loss: 1.8182054975981354

Epoch: 6| Step: 8
Training loss: 1.1705201864242554
Validation loss: 1.8119848505143197

Epoch: 6| Step: 9
Training loss: 0.8778566718101501
Validation loss: 1.8292894517221758

Epoch: 6| Step: 10
Training loss: 1.0113694667816162
Validation loss: 1.8026970227559407

Epoch: 6| Step: 11
Training loss: 1.1217938661575317
Validation loss: 1.7864472814785537

Epoch: 6| Step: 12
Training loss: 0.8620153665542603
Validation loss: 1.8163885237068258

Epoch: 6| Step: 13
Training loss: 1.6667680740356445
Validation loss: 1.8016608479202434

Epoch: 369| Step: 0
Training loss: 1.1774797439575195
Validation loss: 1.7701979747382544

Epoch: 6| Step: 1
Training loss: 0.8912607431411743
Validation loss: 1.8400317417678012

Epoch: 6| Step: 2
Training loss: 1.4969687461853027
Validation loss: 1.8368983653283888

Epoch: 6| Step: 3
Training loss: 1.4033123254776
Validation loss: 1.848776851930926

Epoch: 6| Step: 4
Training loss: 1.1830615997314453
Validation loss: 1.8937043810403476

Epoch: 6| Step: 5
Training loss: 1.023805022239685
Validation loss: 1.8480020133397912

Epoch: 6| Step: 6
Training loss: 0.9851557016372681
Validation loss: 1.8497384850696852

Epoch: 6| Step: 7
Training loss: 1.0559470653533936
Validation loss: 1.8912698030471802

Epoch: 6| Step: 8
Training loss: 0.6670399308204651
Validation loss: 1.8402858190639044

Epoch: 6| Step: 9
Training loss: 1.047415852546692
Validation loss: 1.8057050192227928

Epoch: 6| Step: 10
Training loss: 0.8539314270019531
Validation loss: 1.8719008199630245

Epoch: 6| Step: 11
Training loss: 0.9973997473716736
Validation loss: 1.822145761982087

Epoch: 6| Step: 12
Training loss: 1.9774049520492554
Validation loss: 1.8251129657991472

Epoch: 6| Step: 13
Training loss: 1.4578986167907715
Validation loss: 1.7980765758022186

Epoch: 370| Step: 0
Training loss: 1.5167559385299683
Validation loss: 1.822346915480911

Epoch: 6| Step: 1
Training loss: 1.1719255447387695
Validation loss: 1.8302231642507738

Epoch: 6| Step: 2
Training loss: 1.3867290019989014
Validation loss: 1.8224911177030174

Epoch: 6| Step: 3
Training loss: 0.8500330448150635
Validation loss: 1.840454407917556

Epoch: 6| Step: 4
Training loss: 0.6329256296157837
Validation loss: 1.7714414596557617

Epoch: 6| Step: 5
Training loss: 1.4408818483352661
Validation loss: 1.8138909416814004

Epoch: 6| Step: 6
Training loss: 0.96502685546875
Validation loss: 1.7983174118944394

Epoch: 6| Step: 7
Training loss: 0.9815083146095276
Validation loss: 1.9064005831236481

Epoch: 6| Step: 8
Training loss: 1.409663438796997
Validation loss: 1.8579889958904636

Epoch: 6| Step: 9
Training loss: 1.4325740337371826
Validation loss: 1.8105829018418507

Epoch: 6| Step: 10
Training loss: 1.3711615800857544
Validation loss: 1.842839276918801

Epoch: 6| Step: 11
Training loss: 1.3119988441467285
Validation loss: 1.8351345292983516

Epoch: 6| Step: 12
Training loss: 0.8753248453140259
Validation loss: 1.8386348357764624

Epoch: 6| Step: 13
Training loss: 1.1118041276931763
Validation loss: 1.8493402119605773

Epoch: 371| Step: 0
Training loss: 1.3554928302764893
Validation loss: 1.8165586545903196

Epoch: 6| Step: 1
Training loss: 1.2620309591293335
Validation loss: 1.9032960079049552

Epoch: 6| Step: 2
Training loss: 1.520385503768921
Validation loss: 1.8388493548157394

Epoch: 6| Step: 3
Training loss: 1.3006638288497925
Validation loss: 1.8800055147499166

Epoch: 6| Step: 4
Training loss: 0.7333621978759766
Validation loss: 1.8151634072744718

Epoch: 6| Step: 5
Training loss: 0.8976486921310425
Validation loss: 1.8229724886596843

Epoch: 6| Step: 6
Training loss: 1.3908463716506958
Validation loss: 1.8608266102370394

Epoch: 6| Step: 7
Training loss: 0.9771120548248291
Validation loss: 1.8306818290423321

Epoch: 6| Step: 8
Training loss: 0.9973129034042358
Validation loss: 1.7837227595749723

Epoch: 6| Step: 9
Training loss: 1.7765332460403442
Validation loss: 1.8581845106617096

Epoch: 6| Step: 10
Training loss: 1.0036747455596924
Validation loss: 1.8342643937756937

Epoch: 6| Step: 11
Training loss: 1.0804107189178467
Validation loss: 1.8589036310872724

Epoch: 6| Step: 12
Training loss: 0.6213678121566772
Validation loss: 1.8724288312337731

Epoch: 6| Step: 13
Training loss: 1.309399127960205
Validation loss: 1.83534788316296

Epoch: 372| Step: 0
Training loss: 1.2844512462615967
Validation loss: 1.9199062342284827

Epoch: 6| Step: 1
Training loss: 1.507214903831482
Validation loss: 1.9029178927021642

Epoch: 6| Step: 2
Training loss: 0.8948386311531067
Validation loss: 1.8903140611546014

Epoch: 6| Step: 3
Training loss: 1.2305631637573242
Validation loss: 1.8831353264470254

Epoch: 6| Step: 4
Training loss: 1.2331370115280151
Validation loss: 1.8715539311849942

Epoch: 6| Step: 5
Training loss: 1.179648756980896
Validation loss: 1.9127261254095262

Epoch: 6| Step: 6
Training loss: 1.2880191802978516
Validation loss: 1.867718005693087

Epoch: 6| Step: 7
Training loss: 1.2938839197158813
Validation loss: 1.8340151822695168

Epoch: 6| Step: 8
Training loss: 1.375448226928711
Validation loss: 1.865863452675522

Epoch: 6| Step: 9
Training loss: 0.6795257329940796
Validation loss: 1.8540501773998301

Epoch: 6| Step: 10
Training loss: 1.1258177757263184
Validation loss: 1.8638417425976004

Epoch: 6| Step: 11
Training loss: 1.2270455360412598
Validation loss: 1.7879405226758731

Epoch: 6| Step: 12
Training loss: 0.9530398845672607
Validation loss: 1.8575935504769767

Epoch: 6| Step: 13
Training loss: 0.6887823939323425
Validation loss: 1.8412400881449382

Epoch: 373| Step: 0
Training loss: 0.8823577761650085
Validation loss: 1.8661278781070505

Epoch: 6| Step: 1
Training loss: 1.7039145231246948
Validation loss: 1.8148298519913868

Epoch: 6| Step: 2
Training loss: 1.200324296951294
Validation loss: 1.823752522468567

Epoch: 6| Step: 3
Training loss: 0.8150952458381653
Validation loss: 1.8163814595950547

Epoch: 6| Step: 4
Training loss: 1.0720869302749634
Validation loss: 1.8507059351090462

Epoch: 6| Step: 5
Training loss: 1.705456256866455
Validation loss: 1.7701264786463913

Epoch: 6| Step: 6
Training loss: 1.4224705696105957
Validation loss: 1.809588614330497

Epoch: 6| Step: 7
Training loss: 0.7517570853233337
Validation loss: 1.825394517631941

Epoch: 6| Step: 8
Training loss: 1.0926264524459839
Validation loss: 1.8713878969992361

Epoch: 6| Step: 9
Training loss: 0.9805492758750916
Validation loss: 1.8575184268336142

Epoch: 6| Step: 10
Training loss: 1.4342390298843384
Validation loss: 1.9131198185746388

Epoch: 6| Step: 11
Training loss: 0.8168147802352905
Validation loss: 1.8748368396553943

Epoch: 6| Step: 12
Training loss: 1.153721809387207
Validation loss: 1.8317366646182152

Epoch: 6| Step: 13
Training loss: 1.340308666229248
Validation loss: 1.837970010695919

Epoch: 374| Step: 0
Training loss: 1.0310721397399902
Validation loss: 1.8888787056810112

Epoch: 6| Step: 1
Training loss: 1.689937710762024
Validation loss: 1.8192531088347077

Epoch: 6| Step: 2
Training loss: 0.9303529262542725
Validation loss: 1.8942849123349754

Epoch: 6| Step: 3
Training loss: 1.3817174434661865
Validation loss: 1.8171914828720914

Epoch: 6| Step: 4
Training loss: 0.6200523972511292
Validation loss: 1.839895026658171

Epoch: 6| Step: 5
Training loss: 1.2165882587432861
Validation loss: 1.8643808941687308

Epoch: 6| Step: 6
Training loss: 1.2781612873077393
Validation loss: 1.828260338434609

Epoch: 6| Step: 7
Training loss: 0.7861667275428772
Validation loss: 1.833283447450207

Epoch: 6| Step: 8
Training loss: 1.4586868286132812
Validation loss: 1.8229630019075127

Epoch: 6| Step: 9
Training loss: 1.0332857370376587
Validation loss: 1.886360058220484

Epoch: 6| Step: 10
Training loss: 0.969164252281189
Validation loss: 1.8598890458383868

Epoch: 6| Step: 11
Training loss: 1.3862894773483276
Validation loss: 1.7984468193464382

Epoch: 6| Step: 12
Training loss: 1.4745466709136963
Validation loss: 1.9026597597265755

Epoch: 6| Step: 13
Training loss: 1.0118104219436646
Validation loss: 1.8195312202617686

Epoch: 375| Step: 0
Training loss: 0.684620201587677
Validation loss: 1.8619353207208778

Epoch: 6| Step: 1
Training loss: 1.109585165977478
Validation loss: 1.8180617888768513

Epoch: 6| Step: 2
Training loss: 1.1459985971450806
Validation loss: 1.8128130359034385

Epoch: 6| Step: 3
Training loss: 1.3093938827514648
Validation loss: 1.8103604931985178

Epoch: 6| Step: 4
Training loss: 1.158430814743042
Validation loss: 1.8305912056276876

Epoch: 6| Step: 5
Training loss: 1.1368160247802734
Validation loss: 1.7714233013891405

Epoch: 6| Step: 6
Training loss: 1.5558239221572876
Validation loss: 1.823011343197156

Epoch: 6| Step: 7
Training loss: 1.3038198947906494
Validation loss: 1.8976002021502423

Epoch: 6| Step: 8
Training loss: 1.2573490142822266
Validation loss: 1.7850511381703038

Epoch: 6| Step: 9
Training loss: 1.0952298641204834
Validation loss: 1.8564295409828104

Epoch: 6| Step: 10
Training loss: 0.48860451579093933
Validation loss: 1.8585848244287635

Epoch: 6| Step: 11
Training loss: 1.2577922344207764
Validation loss: 1.8328814916713263

Epoch: 6| Step: 12
Training loss: 0.8561919331550598
Validation loss: 1.845786303602239

Epoch: 6| Step: 13
Training loss: 2.056929588317871
Validation loss: 1.7851323671238397

Epoch: 376| Step: 0
Training loss: 1.2204430103302002
Validation loss: 1.811776767494858

Epoch: 6| Step: 1
Training loss: 1.5763036012649536
Validation loss: 1.860543417674239

Epoch: 6| Step: 2
Training loss: 0.7704038023948669
Validation loss: 1.879708759246334

Epoch: 6| Step: 3
Training loss: 0.6317316293716431
Validation loss: 1.8302919800563524

Epoch: 6| Step: 4
Training loss: 1.5687007904052734
Validation loss: 1.8079035871772355

Epoch: 6| Step: 5
Training loss: 1.3208428621292114
Validation loss: 1.8017374187387445

Epoch: 6| Step: 6
Training loss: 1.0185112953186035
Validation loss: 1.8369211496845368

Epoch: 6| Step: 7
Training loss: 1.0838549137115479
Validation loss: 1.8440119886911044

Epoch: 6| Step: 8
Training loss: 0.8471487164497375
Validation loss: 1.8363550798867339

Epoch: 6| Step: 9
Training loss: 0.7302761673927307
Validation loss: 1.776961459267524

Epoch: 6| Step: 10
Training loss: 1.2122334241867065
Validation loss: 1.8530392595516738

Epoch: 6| Step: 11
Training loss: 1.1962010860443115
Validation loss: 1.8318420661393033

Epoch: 6| Step: 12
Training loss: 1.3580634593963623
Validation loss: 1.7916371732629754

Epoch: 6| Step: 13
Training loss: 1.8884282112121582
Validation loss: 1.7935212478842786

Epoch: 377| Step: 0
Training loss: 1.1410408020019531
Validation loss: 1.8281788236351424

Epoch: 6| Step: 1
Training loss: 1.067728877067566
Validation loss: 1.841469410927065

Epoch: 6| Step: 2
Training loss: 1.1530613899230957
Validation loss: 1.8939383235028995

Epoch: 6| Step: 3
Training loss: 1.714807152748108
Validation loss: 1.8836892112608878

Epoch: 6| Step: 4
Training loss: 1.7380335330963135
Validation loss: 1.8775183462327527

Epoch: 6| Step: 5
Training loss: 0.7015944719314575
Validation loss: 1.8584657343485023

Epoch: 6| Step: 6
Training loss: 1.0035715103149414
Validation loss: 1.8911235691398702

Epoch: 6| Step: 7
Training loss: 0.8254777193069458
Validation loss: 1.8793969564540411

Epoch: 6| Step: 8
Training loss: 1.0667144060134888
Validation loss: 1.863130360521296

Epoch: 6| Step: 9
Training loss: 1.2387020587921143
Validation loss: 1.8330680298548874

Epoch: 6| Step: 10
Training loss: 1.0800137519836426
Validation loss: 1.804727065947748

Epoch: 6| Step: 11
Training loss: 1.16322922706604
Validation loss: 1.8362191261783722

Epoch: 6| Step: 12
Training loss: 1.2194769382476807
Validation loss: 1.8230048225771995

Epoch: 6| Step: 13
Training loss: 0.7627695798873901
Validation loss: 1.86692641627404

Epoch: 378| Step: 0
Training loss: 0.4765211343765259
Validation loss: 1.8786539390522947

Epoch: 6| Step: 1
Training loss: 0.5706408619880676
Validation loss: 1.836214175788305

Epoch: 6| Step: 2
Training loss: 1.2342430353164673
Validation loss: 1.8323275478937293

Epoch: 6| Step: 3
Training loss: 0.9390282034873962
Validation loss: 1.796782462827621

Epoch: 6| Step: 4
Training loss: 1.7669745683670044
Validation loss: 1.8571257616883965

Epoch: 6| Step: 5
Training loss: 1.7911832332611084
Validation loss: 1.875458150781611

Epoch: 6| Step: 6
Training loss: 1.2941341400146484
Validation loss: 1.8264664680727067

Epoch: 6| Step: 7
Training loss: 0.811622142791748
Validation loss: 1.8183697397990892

Epoch: 6| Step: 8
Training loss: 1.0370607376098633
Validation loss: 1.8099234821975871

Epoch: 6| Step: 9
Training loss: 1.0255873203277588
Validation loss: 1.8340538996522144

Epoch: 6| Step: 10
Training loss: 0.6695249080657959
Validation loss: 1.8119920222989974

Epoch: 6| Step: 11
Training loss: 1.3916736841201782
Validation loss: 1.890508799142735

Epoch: 6| Step: 12
Training loss: 0.8636358976364136
Validation loss: 1.8557743718547206

Epoch: 6| Step: 13
Training loss: 2.1546504497528076
Validation loss: 1.9074316998963714

Epoch: 379| Step: 0
Training loss: 1.1932332515716553
Validation loss: 1.8473624439649685

Epoch: 6| Step: 1
Training loss: 1.340836524963379
Validation loss: 1.845321475818593

Epoch: 6| Step: 2
Training loss: 0.9021798372268677
Validation loss: 1.8471459765588083

Epoch: 6| Step: 3
Training loss: 1.0400958061218262
Validation loss: 1.8208010119776572

Epoch: 6| Step: 4
Training loss: 1.2737300395965576
Validation loss: 1.8132001353848366

Epoch: 6| Step: 5
Training loss: 1.1373238563537598
Validation loss: 1.8440530787232101

Epoch: 6| Step: 6
Training loss: 1.0531907081604004
Validation loss: 1.8076270459800639

Epoch: 6| Step: 7
Training loss: 1.2221734523773193
Validation loss: 1.9260785605317803

Epoch: 6| Step: 8
Training loss: 1.0560986995697021
Validation loss: 1.788952919744676

Epoch: 6| Step: 9
Training loss: 1.2342668771743774
Validation loss: 1.8821614480787707

Epoch: 6| Step: 10
Training loss: 1.2186779975891113
Validation loss: 1.8407479127248128

Epoch: 6| Step: 11
Training loss: 1.1676344871520996
Validation loss: 1.8028511513945877

Epoch: 6| Step: 12
Training loss: 1.439978837966919
Validation loss: 1.8823801702068699

Epoch: 6| Step: 13
Training loss: 0.9327386021614075
Validation loss: 1.895390736159458

Epoch: 380| Step: 0
Training loss: 1.5919857025146484
Validation loss: 1.7754310869401502

Epoch: 6| Step: 1
Training loss: 0.9126556515693665
Validation loss: 1.851749179183796

Epoch: 6| Step: 2
Training loss: 1.0905691385269165
Validation loss: 1.86631908980749

Epoch: 6| Step: 3
Training loss: 1.3024760484695435
Validation loss: 1.8925959781933857

Epoch: 6| Step: 4
Training loss: 1.2016990184783936
Validation loss: 1.8867433827410462

Epoch: 6| Step: 5
Training loss: 1.0061872005462646
Validation loss: 1.8872534254545807

Epoch: 6| Step: 6
Training loss: 0.8557266592979431
Validation loss: 1.891013148010418

Epoch: 6| Step: 7
Training loss: 0.7868439555168152
Validation loss: 1.8836399175787484

Epoch: 6| Step: 8
Training loss: 0.7637162208557129
Validation loss: 1.9156430754610287

Epoch: 6| Step: 9
Training loss: 1.1711070537567139
Validation loss: 1.8099285710242488

Epoch: 6| Step: 10
Training loss: 0.9870445728302002
Validation loss: 1.8732277065195062

Epoch: 6| Step: 11
Training loss: 1.9364310503005981
Validation loss: 1.8081942809525358

Epoch: 6| Step: 12
Training loss: 1.240967035293579
Validation loss: 1.8322957049133957

Epoch: 6| Step: 13
Training loss: 0.9581072330474854
Validation loss: 1.8122482286986483

Epoch: 381| Step: 0
Training loss: 0.7702736854553223
Validation loss: 1.832460859770416

Epoch: 6| Step: 1
Training loss: 1.1870802640914917
Validation loss: 1.8567239956189228

Epoch: 6| Step: 2
Training loss: 1.5513014793395996
Validation loss: 1.851893885161287

Epoch: 6| Step: 3
Training loss: 0.9397350549697876
Validation loss: 1.8607361752499816

Epoch: 6| Step: 4
Training loss: 1.4339388608932495
Validation loss: 1.8250964649261967

Epoch: 6| Step: 5
Training loss: 1.239349365234375
Validation loss: 1.7907420755714498

Epoch: 6| Step: 6
Training loss: 0.773229718208313
Validation loss: 1.7956678892976494

Epoch: 6| Step: 7
Training loss: 0.7309163212776184
Validation loss: 1.8842838002789406

Epoch: 6| Step: 8
Training loss: 1.3909752368927002
Validation loss: 1.7864354887316305

Epoch: 6| Step: 9
Training loss: 1.006220817565918
Validation loss: 1.8499709406206686

Epoch: 6| Step: 10
Training loss: 1.183465600013733
Validation loss: 1.8994180412702664

Epoch: 6| Step: 11
Training loss: 1.1147236824035645
Validation loss: 1.8531655752530662

Epoch: 6| Step: 12
Training loss: 1.157904028892517
Validation loss: 1.8627652455401678

Epoch: 6| Step: 13
Training loss: 1.6259077787399292
Validation loss: 1.847728152428904

Epoch: 382| Step: 0
Training loss: 1.1375467777252197
Validation loss: 1.8858077782456593

Epoch: 6| Step: 1
Training loss: 0.9360916018486023
Validation loss: 1.8280058201923166

Epoch: 6| Step: 2
Training loss: 0.9915823936462402
Validation loss: 1.8506959689560758

Epoch: 6| Step: 3
Training loss: 1.1222022771835327
Validation loss: 1.816491585905834

Epoch: 6| Step: 4
Training loss: 0.6371033191680908
Validation loss: 1.8945112433484805

Epoch: 6| Step: 5
Training loss: 0.6086736917495728
Validation loss: 1.8460621910710489

Epoch: 6| Step: 6
Training loss: 1.0996283292770386
Validation loss: 1.7908369879568777

Epoch: 6| Step: 7
Training loss: 1.0912460088729858
Validation loss: 1.8634759674790085

Epoch: 6| Step: 8
Training loss: 1.749380350112915
Validation loss: 1.8223922009109168

Epoch: 6| Step: 9
Training loss: 1.8446723222732544
Validation loss: 1.810075589405593

Epoch: 6| Step: 10
Training loss: 1.0065524578094482
Validation loss: 1.8234754377795803

Epoch: 6| Step: 11
Training loss: 1.243341326713562
Validation loss: 1.8290560514696184

Epoch: 6| Step: 12
Training loss: 0.9576218724250793
Validation loss: 1.8270301690665625

Epoch: 6| Step: 13
Training loss: 1.6710941791534424
Validation loss: 1.8693623145421345

Epoch: 383| Step: 0
Training loss: 1.1596612930297852
Validation loss: 1.8367517955841557

Epoch: 6| Step: 1
Training loss: 1.0640132427215576
Validation loss: 1.7832267130574873

Epoch: 6| Step: 2
Training loss: 0.9907375574111938
Validation loss: 1.80829878007212

Epoch: 6| Step: 3
Training loss: 0.8546069860458374
Validation loss: 1.860832078482515

Epoch: 6| Step: 4
Training loss: 1.0259267091751099
Validation loss: 1.8489193813775175

Epoch: 6| Step: 5
Training loss: 1.3646860122680664
Validation loss: 1.8785784987993137

Epoch: 6| Step: 6
Training loss: 1.3495171070098877
Validation loss: 1.8102866629118561

Epoch: 6| Step: 7
Training loss: 1.3106682300567627
Validation loss: 1.879658442671581

Epoch: 6| Step: 8
Training loss: 1.4665852785110474
Validation loss: 1.811032743864162

Epoch: 6| Step: 9
Training loss: 0.7434068322181702
Validation loss: 1.830697646705053

Epoch: 6| Step: 10
Training loss: 0.8145781755447388
Validation loss: 1.8200331580254339

Epoch: 6| Step: 11
Training loss: 1.3161418437957764
Validation loss: 1.8567390339348906

Epoch: 6| Step: 12
Training loss: 0.6207201480865479
Validation loss: 1.7877030962256975

Epoch: 6| Step: 13
Training loss: 0.9773571491241455
Validation loss: 1.7684752018220964

Epoch: 384| Step: 0
Training loss: 0.8259982466697693
Validation loss: 1.8713649460064468

Epoch: 6| Step: 1
Training loss: 1.3769433498382568
Validation loss: 1.826715693678907

Epoch: 6| Step: 2
Training loss: 0.791920006275177
Validation loss: 1.8029967943827312

Epoch: 6| Step: 3
Training loss: 1.5486834049224854
Validation loss: 1.8093637163921068

Epoch: 6| Step: 4
Training loss: 0.842160165309906
Validation loss: 1.8644016968306674

Epoch: 6| Step: 5
Training loss: 0.6872087717056274
Validation loss: 1.8085897340569446

Epoch: 6| Step: 6
Training loss: 0.9274991154670715
Validation loss: 1.8664444172254173

Epoch: 6| Step: 7
Training loss: 1.0738184452056885
Validation loss: 1.8156059044663624

Epoch: 6| Step: 8
Training loss: 1.5009496212005615
Validation loss: 1.8052772527099938

Epoch: 6| Step: 9
Training loss: 0.8920084834098816
Validation loss: 1.8383702783174412

Epoch: 6| Step: 10
Training loss: 0.8729327321052551
Validation loss: 1.7981065832158571

Epoch: 6| Step: 11
Training loss: 1.1557636260986328
Validation loss: 1.8421128513992473

Epoch: 6| Step: 12
Training loss: 1.422876000404358
Validation loss: 1.8157983197960803

Epoch: 6| Step: 13
Training loss: 1.4466710090637207
Validation loss: 1.785808870869298

Epoch: 385| Step: 0
Training loss: 1.2531132698059082
Validation loss: 1.8689307628139373

Epoch: 6| Step: 1
Training loss: 1.4861741065979004
Validation loss: 1.8621978157310075

Epoch: 6| Step: 2
Training loss: 1.314176321029663
Validation loss: 1.8429211339642924

Epoch: 6| Step: 3
Training loss: 1.1649329662322998
Validation loss: 1.922173248824253

Epoch: 6| Step: 4
Training loss: 0.7505249381065369
Validation loss: 1.8649224555620583

Epoch: 6| Step: 5
Training loss: 1.1325823068618774
Validation loss: 1.8726682560418242

Epoch: 6| Step: 6
Training loss: 0.9527673721313477
Validation loss: 1.8294604362980011

Epoch: 6| Step: 7
Training loss: 0.9064567685127258
Validation loss: 1.8117835265333935

Epoch: 6| Step: 8
Training loss: 1.1574783325195312
Validation loss: 1.8582830813623243

Epoch: 6| Step: 9
Training loss: 0.9671787619590759
Validation loss: 1.8478731775796542

Epoch: 6| Step: 10
Training loss: 1.0549931526184082
Validation loss: 1.8358306038764216

Epoch: 6| Step: 11
Training loss: 1.5236543416976929
Validation loss: 1.8501919905344646

Epoch: 6| Step: 12
Training loss: 0.999187707901001
Validation loss: 1.8181414655459824

Epoch: 6| Step: 13
Training loss: 1.027625560760498
Validation loss: 1.7819527618346676

Epoch: 386| Step: 0
Training loss: 0.8768920302391052
Validation loss: 1.8359937014118317

Epoch: 6| Step: 1
Training loss: 1.135676622390747
Validation loss: 1.8324358232559697

Epoch: 6| Step: 2
Training loss: 0.6372706294059753
Validation loss: 1.8590059165031678

Epoch: 6| Step: 3
Training loss: 0.8070900440216064
Validation loss: 1.798911194647512

Epoch: 6| Step: 4
Training loss: 1.1600894927978516
Validation loss: 1.8695420231870425

Epoch: 6| Step: 5
Training loss: 1.2525138854980469
Validation loss: 1.8634274633981849

Epoch: 6| Step: 6
Training loss: 1.5096931457519531
Validation loss: 1.8299716416225638

Epoch: 6| Step: 7
Training loss: 1.5158228874206543
Validation loss: 1.8775271190110074

Epoch: 6| Step: 8
Training loss: 1.102332592010498
Validation loss: 1.84751049933895

Epoch: 6| Step: 9
Training loss: 1.2530759572982788
Validation loss: 1.8175143272646013

Epoch: 6| Step: 10
Training loss: 0.9346274137496948
Validation loss: 1.8299657503763835

Epoch: 6| Step: 11
Training loss: 1.4097950458526611
Validation loss: 1.838092787291414

Epoch: 6| Step: 12
Training loss: 0.8426855802536011
Validation loss: 1.8896461404779905

Epoch: 6| Step: 13
Training loss: 1.023388385772705
Validation loss: 1.863530792215819

Epoch: 387| Step: 0
Training loss: 1.0863231420516968
Validation loss: 1.85923175145221

Epoch: 6| Step: 1
Training loss: 1.0556221008300781
Validation loss: 1.8423865725917201

Epoch: 6| Step: 2
Training loss: 0.8934478759765625
Validation loss: 1.8490247803349649

Epoch: 6| Step: 3
Training loss: 0.8605285882949829
Validation loss: 1.862053854491121

Epoch: 6| Step: 4
Training loss: 1.145071268081665
Validation loss: 1.8371562188671482

Epoch: 6| Step: 5
Training loss: 1.2763067483901978
Validation loss: 1.813326625413792

Epoch: 6| Step: 6
Training loss: 1.5091699361801147
Validation loss: 1.8536317322843818

Epoch: 6| Step: 7
Training loss: 1.2562474012374878
Validation loss: 1.8146046541070426

Epoch: 6| Step: 8
Training loss: 1.1221293210983276
Validation loss: 1.8491390648708548

Epoch: 6| Step: 9
Training loss: 1.0387599468231201
Validation loss: 1.8087138975820234

Epoch: 6| Step: 10
Training loss: 1.145391583442688
Validation loss: 1.8317551625672208

Epoch: 6| Step: 11
Training loss: 1.0650866031646729
Validation loss: 1.8805549401108936

Epoch: 6| Step: 12
Training loss: 1.3092584609985352
Validation loss: 1.8288353284200032

Epoch: 6| Step: 13
Training loss: 1.1554224491119385
Validation loss: 1.8824826671231178

Epoch: 388| Step: 0
Training loss: 1.3342911005020142
Validation loss: 1.8664676271459109

Epoch: 6| Step: 1
Training loss: 0.6000669002532959
Validation loss: 1.848053857844363

Epoch: 6| Step: 2
Training loss: 1.9019112586975098
Validation loss: 1.8657673353789954

Epoch: 6| Step: 3
Training loss: 0.724687933921814
Validation loss: 1.9045368625271706

Epoch: 6| Step: 4
Training loss: 0.7262076139450073
Validation loss: 1.7779351408763597

Epoch: 6| Step: 5
Training loss: 0.8841719627380371
Validation loss: 1.777200206633537

Epoch: 6| Step: 6
Training loss: 1.5650005340576172
Validation loss: 1.8005127522253221

Epoch: 6| Step: 7
Training loss: 1.0523195266723633
Validation loss: 1.8481833819420106

Epoch: 6| Step: 8
Training loss: 0.8496843576431274
Validation loss: 1.8625772383905226

Epoch: 6| Step: 9
Training loss: 1.2571215629577637
Validation loss: 1.8638580537611438

Epoch: 6| Step: 10
Training loss: 0.7152209281921387
Validation loss: 1.762114514586746

Epoch: 6| Step: 11
Training loss: 1.4352457523345947
Validation loss: 1.8165588596815705

Epoch: 6| Step: 12
Training loss: 1.167531967163086
Validation loss: 1.8746792372836862

Epoch: 6| Step: 13
Training loss: 1.2905259132385254
Validation loss: 1.8080047279275873

Epoch: 389| Step: 0
Training loss: 0.8400264978408813
Validation loss: 1.8679853998204714

Epoch: 6| Step: 1
Training loss: 0.9597898721694946
Validation loss: 1.803289726216306

Epoch: 6| Step: 2
Training loss: 1.915074348449707
Validation loss: 1.8377884280297063

Epoch: 6| Step: 3
Training loss: 1.0576481819152832
Validation loss: 1.8335256127900974

Epoch: 6| Step: 4
Training loss: 0.5323507785797119
Validation loss: 1.818648402408887

Epoch: 6| Step: 5
Training loss: 1.024898648262024
Validation loss: 1.8959906331954464

Epoch: 6| Step: 6
Training loss: 0.9711971879005432
Validation loss: 1.8996489996551185

Epoch: 6| Step: 7
Training loss: 0.8715700507164001
Validation loss: 1.8502808437552503

Epoch: 6| Step: 8
Training loss: 1.098412036895752
Validation loss: 1.8646711482796618

Epoch: 6| Step: 9
Training loss: 1.139827847480774
Validation loss: 1.8515071638168827

Epoch: 6| Step: 10
Training loss: 1.2632039785385132
Validation loss: 1.866524778386598

Epoch: 6| Step: 11
Training loss: 1.0666908025741577
Validation loss: 1.941074073955577

Epoch: 6| Step: 12
Training loss: 0.9823400378227234
Validation loss: 1.8477588366436701

Epoch: 6| Step: 13
Training loss: 1.8392715454101562
Validation loss: 1.907395351317621

Epoch: 390| Step: 0
Training loss: 0.9479440450668335
Validation loss: 1.8174145478074268

Epoch: 6| Step: 1
Training loss: 1.2669479846954346
Validation loss: 1.8520749153629426

Epoch: 6| Step: 2
Training loss: 0.7623664140701294
Validation loss: 1.8444916253448815

Epoch: 6| Step: 3
Training loss: 0.7800813317298889
Validation loss: 1.8385650598874657

Epoch: 6| Step: 4
Training loss: 1.1891396045684814
Validation loss: 1.8329915115910191

Epoch: 6| Step: 5
Training loss: 0.6858581304550171
Validation loss: 1.8880130065384733

Epoch: 6| Step: 6
Training loss: 1.0836033821105957
Validation loss: 1.8555029464024368

Epoch: 6| Step: 7
Training loss: 1.7608094215393066
Validation loss: 1.8217632783356534

Epoch: 6| Step: 8
Training loss: 0.8649003505706787
Validation loss: 1.8086903646428099

Epoch: 6| Step: 9
Training loss: 1.1339492797851562
Validation loss: 1.8265431478459349

Epoch: 6| Step: 10
Training loss: 1.4759840965270996
Validation loss: 1.8282197649760912

Epoch: 6| Step: 11
Training loss: 1.454627275466919
Validation loss: 1.8669225144129928

Epoch: 6| Step: 12
Training loss: 1.187291145324707
Validation loss: 1.7721493423625987

Epoch: 6| Step: 13
Training loss: 0.3072596490383148
Validation loss: 1.8474495359646377

Epoch: 391| Step: 0
Training loss: 1.4383776187896729
Validation loss: 1.811603009059865

Epoch: 6| Step: 1
Training loss: 0.7950872182846069
Validation loss: 1.841995208494125

Epoch: 6| Step: 2
Training loss: 0.9430195093154907
Validation loss: 1.8237052053533576

Epoch: 6| Step: 3
Training loss: 0.883303701877594
Validation loss: 1.8146278627457157

Epoch: 6| Step: 4
Training loss: 0.8788461685180664
Validation loss: 1.8291385840344172

Epoch: 6| Step: 5
Training loss: 1.2587740421295166
Validation loss: 1.9026062950011222

Epoch: 6| Step: 6
Training loss: 0.5621814131736755
Validation loss: 1.8502380924840127

Epoch: 6| Step: 7
Training loss: 1.7272192239761353
Validation loss: 1.9129368643606863

Epoch: 6| Step: 8
Training loss: 1.260548710823059
Validation loss: 1.8870680588547901

Epoch: 6| Step: 9
Training loss: 0.8828858137130737
Validation loss: 1.846935095325593

Epoch: 6| Step: 10
Training loss: 0.6630287170410156
Validation loss: 1.8848844087252052

Epoch: 6| Step: 11
Training loss: 0.9269436597824097
Validation loss: 1.839935145070476

Epoch: 6| Step: 12
Training loss: 1.4066354036331177
Validation loss: 1.8287328558583413

Epoch: 6| Step: 13
Training loss: 2.102846622467041
Validation loss: 1.7823594552214428

Epoch: 392| Step: 0
Training loss: 0.8798229694366455
Validation loss: 1.8589892054116854

Epoch: 6| Step: 1
Training loss: 0.9701640605926514
Validation loss: 1.8201304751057779

Epoch: 6| Step: 2
Training loss: 1.3523876667022705
Validation loss: 1.8005534807840984

Epoch: 6| Step: 3
Training loss: 1.1270737648010254
Validation loss: 1.8277573482964629

Epoch: 6| Step: 4
Training loss: 1.1986924409866333
Validation loss: 1.817996758286671

Epoch: 6| Step: 5
Training loss: 1.3326927423477173
Validation loss: 1.872881934206973

Epoch: 6| Step: 6
Training loss: 1.4321801662445068
Validation loss: 1.7946638561064197

Epoch: 6| Step: 7
Training loss: 1.139033555984497
Validation loss: 1.8320407687976796

Epoch: 6| Step: 8
Training loss: 1.2658710479736328
Validation loss: 1.8090372175298712

Epoch: 6| Step: 9
Training loss: 0.7867894172668457
Validation loss: 1.7812176699279456

Epoch: 6| Step: 10
Training loss: 0.6523979306221008
Validation loss: 1.8418803702118576

Epoch: 6| Step: 11
Training loss: 0.9406161308288574
Validation loss: 1.785633562713541

Epoch: 6| Step: 12
Training loss: 1.3075640201568604
Validation loss: 1.8762008861828876

Epoch: 6| Step: 13
Training loss: 0.680136501789093
Validation loss: 1.842994431013702

Epoch: 393| Step: 0
Training loss: 0.7266913652420044
Validation loss: 1.8746144310120614

Epoch: 6| Step: 1
Training loss: 1.0707839727401733
Validation loss: 1.8206665528717862

Epoch: 6| Step: 2
Training loss: 1.3055505752563477
Validation loss: 1.8605075484962874

Epoch: 6| Step: 3
Training loss: 1.3292245864868164
Validation loss: 1.9019789734194357

Epoch: 6| Step: 4
Training loss: 0.9671903252601624
Validation loss: 1.7965729390421221

Epoch: 6| Step: 5
Training loss: 1.495615005493164
Validation loss: 1.826171951909219

Epoch: 6| Step: 6
Training loss: 1.3424063920974731
Validation loss: 1.84793379229884

Epoch: 6| Step: 7
Training loss: 1.21723473072052
Validation loss: 1.8270653947707145

Epoch: 6| Step: 8
Training loss: 0.9139993190765381
Validation loss: 1.8725087924670147

Epoch: 6| Step: 9
Training loss: 0.8516680002212524
Validation loss: 1.8148031619287306

Epoch: 6| Step: 10
Training loss: 0.9623498916625977
Validation loss: 1.8364071410189393

Epoch: 6| Step: 11
Training loss: 1.0844131708145142
Validation loss: 1.8891213478580597

Epoch: 6| Step: 12
Training loss: 1.1633635759353638
Validation loss: 1.8609707945136613

Epoch: 6| Step: 13
Training loss: 1.0163817405700684
Validation loss: 1.865325431669912

Epoch: 394| Step: 0
Training loss: 1.3839452266693115
Validation loss: 1.8190383911132812

Epoch: 6| Step: 1
Training loss: 1.0689761638641357
Validation loss: 1.8092261309264808

Epoch: 6| Step: 2
Training loss: 0.6322882175445557
Validation loss: 1.8225850725686679

Epoch: 6| Step: 3
Training loss: 0.7935352921485901
Validation loss: 1.8433935296150945

Epoch: 6| Step: 4
Training loss: 1.7000830173492432
Validation loss: 1.8742611690234112

Epoch: 6| Step: 5
Training loss: 1.1792110204696655
Validation loss: 1.842118924663913

Epoch: 6| Step: 6
Training loss: 0.8275628089904785
Validation loss: 1.8413076221301992

Epoch: 6| Step: 7
Training loss: 0.8522710204124451
Validation loss: 1.8387558626872238

Epoch: 6| Step: 8
Training loss: 1.2691712379455566
Validation loss: 1.796797453716237

Epoch: 6| Step: 9
Training loss: 1.9288450479507446
Validation loss: 1.829184034819244

Epoch: 6| Step: 10
Training loss: 1.482143521308899
Validation loss: 1.8436007589422247

Epoch: 6| Step: 11
Training loss: 0.6209197044372559
Validation loss: 1.8436314777661396

Epoch: 6| Step: 12
Training loss: 0.5096378326416016
Validation loss: 1.8672998976963822

Epoch: 6| Step: 13
Training loss: 0.5496777296066284
Validation loss: 1.8209710057063768

Epoch: 395| Step: 0
Training loss: 1.3237102031707764
Validation loss: 1.8630272573040378

Epoch: 6| Step: 1
Training loss: 1.2579667568206787
Validation loss: 1.880969516692623

Epoch: 6| Step: 2
Training loss: 1.1461416482925415
Validation loss: 1.8631461640839935

Epoch: 6| Step: 3
Training loss: 0.8882991075515747
Validation loss: 1.8388668875540457

Epoch: 6| Step: 4
Training loss: 0.9472202658653259
Validation loss: 1.841125738236212

Epoch: 6| Step: 5
Training loss: 0.960387110710144
Validation loss: 1.8054264373676752

Epoch: 6| Step: 6
Training loss: 1.0458288192749023
Validation loss: 1.8113238401310419

Epoch: 6| Step: 7
Training loss: 1.0495985746383667
Validation loss: 1.8469917607563797

Epoch: 6| Step: 8
Training loss: 1.244309425354004
Validation loss: 1.8463004596771733

Epoch: 6| Step: 9
Training loss: 0.853949785232544
Validation loss: 1.8790922485372072

Epoch: 6| Step: 10
Training loss: 1.2627272605895996
Validation loss: 1.8363701989573817

Epoch: 6| Step: 11
Training loss: 1.251919150352478
Validation loss: 1.830066354044022

Epoch: 6| Step: 12
Training loss: 0.8370858430862427
Validation loss: 1.8751333554585774

Epoch: 6| Step: 13
Training loss: 1.021474838256836
Validation loss: 1.828994345921342

Epoch: 396| Step: 0
Training loss: 0.912110447883606
Validation loss: 1.8517320463734288

Epoch: 6| Step: 1
Training loss: 1.1679998636245728
Validation loss: 1.8863389479216708

Epoch: 6| Step: 2
Training loss: 1.0750097036361694
Validation loss: 1.8742018207426994

Epoch: 6| Step: 3
Training loss: 1.5163135528564453
Validation loss: 1.8370131446469216

Epoch: 6| Step: 4
Training loss: 0.9048122763633728
Validation loss: 1.8326571987521263

Epoch: 6| Step: 5
Training loss: 1.0209953784942627
Validation loss: 1.8415571617823776

Epoch: 6| Step: 6
Training loss: 0.9305130243301392
Validation loss: 1.8577823677370626

Epoch: 6| Step: 7
Training loss: 1.429469108581543
Validation loss: 1.831580759376608

Epoch: 6| Step: 8
Training loss: 0.9306650161743164
Validation loss: 1.8518412292644542

Epoch: 6| Step: 9
Training loss: 0.9864563941955566
Validation loss: 1.8052438984635055

Epoch: 6| Step: 10
Training loss: 1.5665836334228516
Validation loss: 1.8865800442234162

Epoch: 6| Step: 11
Training loss: 0.6721394062042236
Validation loss: 1.8018377378422727

Epoch: 6| Step: 12
Training loss: 1.357207179069519
Validation loss: 1.8090198014372139

Epoch: 6| Step: 13
Training loss: 1.0663223266601562
Validation loss: 1.7976405825666202

Epoch: 397| Step: 0
Training loss: 0.8876787424087524
Validation loss: 1.8844159956901305

Epoch: 6| Step: 1
Training loss: 0.9628797769546509
Validation loss: 1.8665031553596578

Epoch: 6| Step: 2
Training loss: 1.3921819925308228
Validation loss: 1.8312220265788417

Epoch: 6| Step: 3
Training loss: 1.0402390956878662
Validation loss: 1.9130108510294268

Epoch: 6| Step: 4
Training loss: 1.1195751428604126
Validation loss: 1.8315702099953928

Epoch: 6| Step: 5
Training loss: 1.2473342418670654
Validation loss: 1.8877584113869617

Epoch: 6| Step: 6
Training loss: 0.6978671550750732
Validation loss: 1.8295387760285409

Epoch: 6| Step: 7
Training loss: 1.1605662107467651
Validation loss: 1.8563195941268757

Epoch: 6| Step: 8
Training loss: 1.1822794675827026
Validation loss: 1.8339383089414207

Epoch: 6| Step: 9
Training loss: 0.9913061857223511
Validation loss: 1.820323376245396

Epoch: 6| Step: 10
Training loss: 1.092879295349121
Validation loss: 1.832536297459756

Epoch: 6| Step: 11
Training loss: 1.6371749639511108
Validation loss: 1.835959021763135

Epoch: 6| Step: 12
Training loss: 0.8779224753379822
Validation loss: 1.8344262799909037

Epoch: 6| Step: 13
Training loss: 1.1719931364059448
Validation loss: 1.8657296011524815

Epoch: 398| Step: 0
Training loss: 1.5222687721252441
Validation loss: 1.8380150987255959

Epoch: 6| Step: 1
Training loss: 1.0281046628952026
Validation loss: 1.788211981455485

Epoch: 6| Step: 2
Training loss: 0.7073676586151123
Validation loss: 1.841139624195714

Epoch: 6| Step: 3
Training loss: 0.4493287205696106
Validation loss: 1.8213617737575243

Epoch: 6| Step: 4
Training loss: 1.1195098161697388
Validation loss: 1.8635330994923909

Epoch: 6| Step: 5
Training loss: 0.6876722574234009
Validation loss: 1.8126684401624946

Epoch: 6| Step: 6
Training loss: 1.0691094398498535
Validation loss: 1.8498395104562082

Epoch: 6| Step: 7
Training loss: 1.332696557044983
Validation loss: 1.9014290276394095

Epoch: 6| Step: 8
Training loss: 1.3898136615753174
Validation loss: 1.8860713128120667

Epoch: 6| Step: 9
Training loss: 1.6842008829116821
Validation loss: 1.90293074423267

Epoch: 6| Step: 10
Training loss: 0.8284643888473511
Validation loss: 1.8287107342032975

Epoch: 6| Step: 11
Training loss: 1.3290166854858398
Validation loss: 1.8715782908983127

Epoch: 6| Step: 12
Training loss: 1.3100943565368652
Validation loss: 1.821487534430719

Epoch: 6| Step: 13
Training loss: 0.9132063388824463
Validation loss: 1.8459853331247966

Epoch: 399| Step: 0
Training loss: 0.9739655256271362
Validation loss: 1.857938563951882

Epoch: 6| Step: 1
Training loss: 1.0620917081832886
Validation loss: 1.8372026412717757

Epoch: 6| Step: 2
Training loss: 0.7437570095062256
Validation loss: 1.8521297016451437

Epoch: 6| Step: 3
Training loss: 1.0902639627456665
Validation loss: 1.858816836469917

Epoch: 6| Step: 4
Training loss: 1.4067163467407227
Validation loss: 1.856590824742471

Epoch: 6| Step: 5
Training loss: 1.1013286113739014
Validation loss: 1.8175897777721446

Epoch: 6| Step: 6
Training loss: 1.4782167673110962
Validation loss: 1.824992190125168

Epoch: 6| Step: 7
Training loss: 1.067739725112915
Validation loss: 1.7664317097715152

Epoch: 6| Step: 8
Training loss: 1.5627552270889282
Validation loss: 1.833003346638013

Epoch: 6| Step: 9
Training loss: 0.8397268652915955
Validation loss: 1.8145960543745308

Epoch: 6| Step: 10
Training loss: 0.6863415241241455
Validation loss: 1.8201183580583142

Epoch: 6| Step: 11
Training loss: 1.637058973312378
Validation loss: 1.8047650732019895

Epoch: 6| Step: 12
Training loss: 0.7724218368530273
Validation loss: 1.843411332817488

Epoch: 6| Step: 13
Training loss: 0.7078554034233093
Validation loss: 1.8017496780682636

Epoch: 400| Step: 0
Training loss: 0.9211306571960449
Validation loss: 1.8540634237309939

Epoch: 6| Step: 1
Training loss: 1.0289549827575684
Validation loss: 1.8622953827663133

Epoch: 6| Step: 2
Training loss: 0.8491044044494629
Validation loss: 1.810925547794629

Epoch: 6| Step: 3
Training loss: 0.8833019733428955
Validation loss: 1.8413966881331576

Epoch: 6| Step: 4
Training loss: 0.5003982782363892
Validation loss: 1.7980094353357952

Epoch: 6| Step: 5
Training loss: 1.053040623664856
Validation loss: 1.8276543296793455

Epoch: 6| Step: 6
Training loss: 0.8462457656860352
Validation loss: 1.8533217778769873

Epoch: 6| Step: 7
Training loss: 1.159935474395752
Validation loss: 1.8060974382585095

Epoch: 6| Step: 8
Training loss: 1.4045689105987549
Validation loss: 1.8963731796510759

Epoch: 6| Step: 9
Training loss: 1.3045144081115723
Validation loss: 1.7877149915182462

Epoch: 6| Step: 10
Training loss: 1.2432713508605957
Validation loss: 1.8313689257508965

Epoch: 6| Step: 11
Training loss: 1.252561330795288
Validation loss: 1.8301983648730862

Epoch: 6| Step: 12
Training loss: 1.084716796875
Validation loss: 1.881363748222269

Epoch: 6| Step: 13
Training loss: 1.502195954322815
Validation loss: 1.8498432161987468

Epoch: 401| Step: 0
Training loss: 0.9317588210105896
Validation loss: 1.831659528516954

Epoch: 6| Step: 1
Training loss: 1.3563170433044434
Validation loss: 1.8194910915949012

Epoch: 6| Step: 2
Training loss: 1.2923731803894043
Validation loss: 1.792141815026601

Epoch: 6| Step: 3
Training loss: 1.2339568138122559
Validation loss: 1.8641451840759606

Epoch: 6| Step: 4
Training loss: 1.1164019107818604
Validation loss: 1.8422248119949012

Epoch: 6| Step: 5
Training loss: 1.2497618198394775
Validation loss: 1.8432786772328038

Epoch: 6| Step: 6
Training loss: 0.7133302092552185
Validation loss: 1.8179964698770994

Epoch: 6| Step: 7
Training loss: 0.7876744866371155
Validation loss: 1.8253773181669173

Epoch: 6| Step: 8
Training loss: 1.1100382804870605
Validation loss: 1.8402817774844427

Epoch: 6| Step: 9
Training loss: 0.669777512550354
Validation loss: 1.8511892403325727

Epoch: 6| Step: 10
Training loss: 0.8962023854255676
Validation loss: 1.8288462508109309

Epoch: 6| Step: 11
Training loss: 0.8890691995620728
Validation loss: 1.8203862533774426

Epoch: 6| Step: 12
Training loss: 1.756030559539795
Validation loss: 1.8149856892965173

Epoch: 6| Step: 13
Training loss: 0.7287015318870544
Validation loss: 1.8743481828320412

Epoch: 402| Step: 0
Training loss: 0.7386819124221802
Validation loss: 1.8147419678267611

Epoch: 6| Step: 1
Training loss: 1.1637946367263794
Validation loss: 1.8478880595135432

Epoch: 6| Step: 2
Training loss: 0.9740037322044373
Validation loss: 1.795873201021584

Epoch: 6| Step: 3
Training loss: 1.3555912971496582
Validation loss: 1.7674986290675339

Epoch: 6| Step: 4
Training loss: 1.3584212064743042
Validation loss: 1.8544583371890488

Epoch: 6| Step: 5
Training loss: 1.3838825225830078
Validation loss: 1.8626839909502255

Epoch: 6| Step: 6
Training loss: 0.9508985280990601
Validation loss: 1.8146078330214306

Epoch: 6| Step: 7
Training loss: 1.1547131538391113
Validation loss: 1.8211230385688044

Epoch: 6| Step: 8
Training loss: 1.085182785987854
Validation loss: 1.8462346561493412

Epoch: 6| Step: 9
Training loss: 0.8986477255821228
Validation loss: 1.814618892567132

Epoch: 6| Step: 10
Training loss: 0.7492273449897766
Validation loss: 1.851485154962027

Epoch: 6| Step: 11
Training loss: 1.105398416519165
Validation loss: 1.858646833768455

Epoch: 6| Step: 12
Training loss: 1.1738877296447754
Validation loss: 1.8375188894169305

Epoch: 6| Step: 13
Training loss: 0.9355303645133972
Validation loss: 1.8983146221407

Epoch: 403| Step: 0
Training loss: 1.1420918703079224
Validation loss: 1.829940490825202

Epoch: 6| Step: 1
Training loss: 1.3278967142105103
Validation loss: 1.8568348551309237

Epoch: 6| Step: 2
Training loss: 1.0056761503219604
Validation loss: 1.8523153848545526

Epoch: 6| Step: 3
Training loss: 0.7797010540962219
Validation loss: 1.8422102569251932

Epoch: 6| Step: 4
Training loss: 0.7017184495925903
Validation loss: 1.8635194865606164

Epoch: 6| Step: 5
Training loss: 0.8595966696739197
Validation loss: 1.8262003775565856

Epoch: 6| Step: 6
Training loss: 1.2404472827911377
Validation loss: 1.8921169798861268

Epoch: 6| Step: 7
Training loss: 0.7003228068351746
Validation loss: 1.850580056508382

Epoch: 6| Step: 8
Training loss: 1.437601923942566
Validation loss: 1.861942345096219

Epoch: 6| Step: 9
Training loss: 1.0254309177398682
Validation loss: 1.8557420597281507

Epoch: 6| Step: 10
Training loss: 1.0047945976257324
Validation loss: 1.8204758654358566

Epoch: 6| Step: 11
Training loss: 1.7757998704910278
Validation loss: 1.8140651128625358

Epoch: 6| Step: 12
Training loss: 0.7556638717651367
Validation loss: 1.8316589247795843

Epoch: 6| Step: 13
Training loss: 1.404958724975586
Validation loss: 1.8182965760589929

Epoch: 404| Step: 0
Training loss: 1.1246873140335083
Validation loss: 1.78500045499494

Epoch: 6| Step: 1
Training loss: 0.6672792434692383
Validation loss: 1.8383795061419088

Epoch: 6| Step: 2
Training loss: 1.691320776939392
Validation loss: 1.7927075829557193

Epoch: 6| Step: 3
Training loss: 0.8766928315162659
Validation loss: 1.821916082853912

Epoch: 6| Step: 4
Training loss: 0.9593044519424438
Validation loss: 1.7407618902062858

Epoch: 6| Step: 5
Training loss: 1.537283182144165
Validation loss: 1.8418013062528384

Epoch: 6| Step: 6
Training loss: 1.3381867408752441
Validation loss: 1.7805075863356232

Epoch: 6| Step: 7
Training loss: 1.1675190925598145
Validation loss: 1.8440696359962545

Epoch: 6| Step: 8
Training loss: 1.2634429931640625
Validation loss: 1.820526429401931

Epoch: 6| Step: 9
Training loss: 1.2846183776855469
Validation loss: 1.7637418188074583

Epoch: 6| Step: 10
Training loss: 0.5930976271629333
Validation loss: 1.835602436014401

Epoch: 6| Step: 11
Training loss: 1.1179158687591553
Validation loss: 1.848239621808452

Epoch: 6| Step: 12
Training loss: 0.521260142326355
Validation loss: 1.820325897585961

Epoch: 6| Step: 13
Training loss: 1.3054718971252441
Validation loss: 1.8074190949880948

Epoch: 405| Step: 0
Training loss: 0.8999944925308228
Validation loss: 1.8394467997294601

Epoch: 6| Step: 1
Training loss: 1.4698660373687744
Validation loss: 1.8664971384950864

Epoch: 6| Step: 2
Training loss: 1.0739072561264038
Validation loss: 1.8222295597035398

Epoch: 6| Step: 3
Training loss: 1.178840160369873
Validation loss: 1.8173540510157102

Epoch: 6| Step: 4
Training loss: 0.696625292301178
Validation loss: 1.8681403052422307

Epoch: 6| Step: 5
Training loss: 1.1489369869232178
Validation loss: 1.7929656377402685

Epoch: 6| Step: 6
Training loss: 1.1175158023834229
Validation loss: 1.8705068672856977

Epoch: 6| Step: 7
Training loss: 0.9090905785560608
Validation loss: 1.8808510764952628

Epoch: 6| Step: 8
Training loss: 1.4743189811706543
Validation loss: 1.8057126793810117

Epoch: 6| Step: 9
Training loss: 0.8042184114456177
Validation loss: 1.7910020838501632

Epoch: 6| Step: 10
Training loss: 1.3344612121582031
Validation loss: 1.810501883106847

Epoch: 6| Step: 11
Training loss: 1.0807640552520752
Validation loss: 1.8520695483812721

Epoch: 6| Step: 12
Training loss: 0.915968120098114
Validation loss: 1.8237862407520253

Epoch: 6| Step: 13
Training loss: 0.7586662769317627
Validation loss: 1.861126035772344

Epoch: 406| Step: 0
Training loss: 1.6392576694488525
Validation loss: 1.8152521348768664

Epoch: 6| Step: 1
Training loss: 1.0643060207366943
Validation loss: 1.813029081590714

Epoch: 6| Step: 2
Training loss: 0.9909085631370544
Validation loss: 1.8508686532256424

Epoch: 6| Step: 3
Training loss: 0.9776986837387085
Validation loss: 1.8339965471657373

Epoch: 6| Step: 4
Training loss: 1.1062090396881104
Validation loss: 1.822264648252918

Epoch: 6| Step: 5
Training loss: 0.9739305973052979
Validation loss: 1.8308970159099949

Epoch: 6| Step: 6
Training loss: 1.1861753463745117
Validation loss: 1.8035909796273837

Epoch: 6| Step: 7
Training loss: 0.6903210878372192
Validation loss: 1.8310454686482747

Epoch: 6| Step: 8
Training loss: 1.0513715744018555
Validation loss: 1.8278136637903029

Epoch: 6| Step: 9
Training loss: 1.4685109853744507
Validation loss: 1.8189251320336455

Epoch: 6| Step: 10
Training loss: 0.6424942016601562
Validation loss: 1.87235564057545

Epoch: 6| Step: 11
Training loss: 1.239725112915039
Validation loss: 1.810388703500071

Epoch: 6| Step: 12
Training loss: 1.3831008672714233
Validation loss: 1.8042754447588356

Epoch: 6| Step: 13
Training loss: 1.3430993556976318
Validation loss: 1.83279767856803

Epoch: 407| Step: 0
Training loss: 1.1460926532745361
Validation loss: 1.8818489325943815

Epoch: 6| Step: 1
Training loss: 0.7033867835998535
Validation loss: 1.8402458608791392

Epoch: 6| Step: 2
Training loss: 0.8134037256240845
Validation loss: 1.850949715542537

Epoch: 6| Step: 3
Training loss: 1.1090996265411377
Validation loss: 1.873903364263555

Epoch: 6| Step: 4
Training loss: 0.9129486680030823
Validation loss: 1.8315004879428494

Epoch: 6| Step: 5
Training loss: 1.2228572368621826
Validation loss: 1.9120741967231996

Epoch: 6| Step: 6
Training loss: 0.8967829346656799
Validation loss: 1.8557774584780458

Epoch: 6| Step: 7
Training loss: 1.4817677736282349
Validation loss: 1.78999533319986

Epoch: 6| Step: 8
Training loss: 0.8943453431129456
Validation loss: 1.8283374309539795

Epoch: 6| Step: 9
Training loss: 1.1122119426727295
Validation loss: 1.8134652491538756

Epoch: 6| Step: 10
Training loss: 1.1561466455459595
Validation loss: 1.838520315385634

Epoch: 6| Step: 11
Training loss: 0.878738522529602
Validation loss: 1.8084136760363014

Epoch: 6| Step: 12
Training loss: 1.3064287900924683
Validation loss: 1.8146337116918256

Epoch: 6| Step: 13
Training loss: 1.4557135105133057
Validation loss: 1.8318149210304342

Epoch: 408| Step: 0
Training loss: 1.1779870986938477
Validation loss: 1.8047453934146511

Epoch: 6| Step: 1
Training loss: 1.3290557861328125
Validation loss: 1.8538470768159436

Epoch: 6| Step: 2
Training loss: 0.819672703742981
Validation loss: 1.8534730275472004

Epoch: 6| Step: 3
Training loss: 1.0773746967315674
Validation loss: 1.745255087011604

Epoch: 6| Step: 4
Training loss: 1.3381381034851074
Validation loss: 1.8412025538823937

Epoch: 6| Step: 5
Training loss: 1.0488767623901367
Validation loss: 1.7646157639001006

Epoch: 6| Step: 6
Training loss: 0.6803019642829895
Validation loss: 1.8131833281568301

Epoch: 6| Step: 7
Training loss: 0.6759099960327148
Validation loss: 1.7857271778968073

Epoch: 6| Step: 8
Training loss: 1.3107399940490723
Validation loss: 1.878517553370486

Epoch: 6| Step: 9
Training loss: 0.7404347658157349
Validation loss: 1.8651415865908387

Epoch: 6| Step: 10
Training loss: 1.1798884868621826
Validation loss: 1.8153549240481468

Epoch: 6| Step: 11
Training loss: 1.6702500581741333
Validation loss: 1.8044627533164075

Epoch: 6| Step: 12
Training loss: 1.0252792835235596
Validation loss: 1.9041820790178032

Epoch: 6| Step: 13
Training loss: 0.6039069890975952
Validation loss: 1.8759371875434794

Epoch: 409| Step: 0
Training loss: 0.8741559982299805
Validation loss: 1.8711559029035671

Epoch: 6| Step: 1
Training loss: 1.2313264608383179
Validation loss: 1.8733580830276653

Epoch: 6| Step: 2
Training loss: 1.2360665798187256
Validation loss: 1.9348440170288086

Epoch: 6| Step: 3
Training loss: 1.119218111038208
Validation loss: 1.9107200817395282

Epoch: 6| Step: 4
Training loss: 0.9759607315063477
Validation loss: 1.839520990207631

Epoch: 6| Step: 5
Training loss: 0.9428549408912659
Validation loss: 1.884871006011963

Epoch: 6| Step: 6
Training loss: 1.6741664409637451
Validation loss: 1.831627300990525

Epoch: 6| Step: 7
Training loss: 1.1793327331542969
Validation loss: 1.8301993313656058

Epoch: 6| Step: 8
Training loss: 1.5878322124481201
Validation loss: 1.8444512492866927

Epoch: 6| Step: 9
Training loss: 0.941245436668396
Validation loss: 1.8571337384562339

Epoch: 6| Step: 10
Training loss: 0.9010709524154663
Validation loss: 1.8883099786696895

Epoch: 6| Step: 11
Training loss: 0.8493342995643616
Validation loss: 1.8276584545771282

Epoch: 6| Step: 12
Training loss: 0.6162479519844055
Validation loss: 1.8196040776468092

Epoch: 6| Step: 13
Training loss: 1.009542465209961
Validation loss: 1.866441176783654

Epoch: 410| Step: 0
Training loss: 1.4798334836959839
Validation loss: 1.837758861562257

Epoch: 6| Step: 1
Training loss: 1.3461734056472778
Validation loss: 1.8700590620758712

Epoch: 6| Step: 2
Training loss: 0.6714818477630615
Validation loss: 1.8484780083420456

Epoch: 6| Step: 3
Training loss: 1.0333516597747803
Validation loss: 1.8348924575313446

Epoch: 6| Step: 4
Training loss: 0.9191809892654419
Validation loss: 1.818988287320701

Epoch: 6| Step: 5
Training loss: 1.2241837978363037
Validation loss: 1.8036736326832925

Epoch: 6| Step: 6
Training loss: 1.4027998447418213
Validation loss: 1.8590398116778302

Epoch: 6| Step: 7
Training loss: 1.139512300491333
Validation loss: 1.83943627085737

Epoch: 6| Step: 8
Training loss: 0.74165940284729
Validation loss: 1.8731580972671509

Epoch: 6| Step: 9
Training loss: 1.024427890777588
Validation loss: 1.8480190820591424

Epoch: 6| Step: 10
Training loss: 0.554904043674469
Validation loss: 1.8554171439140075

Epoch: 6| Step: 11
Training loss: 1.1039042472839355
Validation loss: 1.8594050868864982

Epoch: 6| Step: 12
Training loss: 1.0694096088409424
Validation loss: 1.8496342512869066

Epoch: 6| Step: 13
Training loss: 1.1501977443695068
Validation loss: 1.7926887568607126

Epoch: 411| Step: 0
Training loss: 1.400803565979004
Validation loss: 1.8197632822939145

Epoch: 6| Step: 1
Training loss: 1.3688822984695435
Validation loss: 1.851423430186446

Epoch: 6| Step: 2
Training loss: 1.1037359237670898
Validation loss: 1.8307843490313458

Epoch: 6| Step: 3
Training loss: 1.5506303310394287
Validation loss: 1.7622449244222333

Epoch: 6| Step: 4
Training loss: 0.6572245955467224
Validation loss: 1.8464960680213025

Epoch: 6| Step: 5
Training loss: 0.7908051013946533
Validation loss: 1.7955770428462694

Epoch: 6| Step: 6
Training loss: 1.0077518224716187
Validation loss: 1.8102480134656351

Epoch: 6| Step: 7
Training loss: 0.9301683306694031
Validation loss: 1.8195097254168602

Epoch: 6| Step: 8
Training loss: 0.958388090133667
Validation loss: 1.8360833134702457

Epoch: 6| Step: 9
Training loss: 1.2134804725646973
Validation loss: 1.8451906301641976

Epoch: 6| Step: 10
Training loss: 1.0112828016281128
Validation loss: 1.834776060555571

Epoch: 6| Step: 11
Training loss: 1.0903682708740234
Validation loss: 1.8889854877225813

Epoch: 6| Step: 12
Training loss: 0.8189796209335327
Validation loss: 1.8038359803538169

Epoch: 6| Step: 13
Training loss: 0.6230127811431885
Validation loss: 1.8687986558483494

Epoch: 412| Step: 0
Training loss: 1.8043608665466309
Validation loss: 1.8903236748069845

Epoch: 6| Step: 1
Training loss: 0.6730931997299194
Validation loss: 1.848291189439835

Epoch: 6| Step: 2
Training loss: 0.5796427130699158
Validation loss: 1.7625135016697708

Epoch: 6| Step: 3
Training loss: 1.2860126495361328
Validation loss: 1.7981547271051714

Epoch: 6| Step: 4
Training loss: 1.0423920154571533
Validation loss: 1.8523506502951346

Epoch: 6| Step: 5
Training loss: 1.0477492809295654
Validation loss: 1.8306018729363718

Epoch: 6| Step: 6
Training loss: 0.8903098106384277
Validation loss: 1.8227488276779011

Epoch: 6| Step: 7
Training loss: 0.8350468277931213
Validation loss: 1.8561348633099628

Epoch: 6| Step: 8
Training loss: 0.8808600306510925
Validation loss: 1.8390727684062014

Epoch: 6| Step: 9
Training loss: 0.9867227673530579
Validation loss: 1.8178095253564979

Epoch: 6| Step: 10
Training loss: 0.8874204158782959
Validation loss: 1.8158733050028484

Epoch: 6| Step: 11
Training loss: 1.1254222393035889
Validation loss: 1.8695419296141593

Epoch: 6| Step: 12
Training loss: 1.1617876291275024
Validation loss: 1.849680785209902

Epoch: 6| Step: 13
Training loss: 1.1721371412277222
Validation loss: 1.7996863549755466

Epoch: 413| Step: 0
Training loss: 0.5786036252975464
Validation loss: 1.8540263663056076

Epoch: 6| Step: 1
Training loss: 1.190032720565796
Validation loss: 1.8806919410664549

Epoch: 6| Step: 2
Training loss: 0.9361828565597534
Validation loss: 1.8411385807939755

Epoch: 6| Step: 3
Training loss: 1.050187110900879
Validation loss: 1.7986753243272022

Epoch: 6| Step: 4
Training loss: 0.8000826835632324
Validation loss: 1.830530870345331

Epoch: 6| Step: 5
Training loss: 0.8555563688278198
Validation loss: 1.7865221179941648

Epoch: 6| Step: 6
Training loss: 1.3699228763580322
Validation loss: 1.7926839500345209

Epoch: 6| Step: 7
Training loss: 0.8081392049789429
Validation loss: 1.7956828596771404

Epoch: 6| Step: 8
Training loss: 1.1688430309295654
Validation loss: 1.8017571690262004

Epoch: 6| Step: 9
Training loss: 1.1450432538986206
Validation loss: 1.8023044857927548

Epoch: 6| Step: 10
Training loss: 1.4112495183944702
Validation loss: 1.8039703125594764

Epoch: 6| Step: 11
Training loss: 1.2959696054458618
Validation loss: 1.7663058375799527

Epoch: 6| Step: 12
Training loss: 0.9032721519470215
Validation loss: 1.7930487381514681

Epoch: 6| Step: 13
Training loss: 1.3446745872497559
Validation loss: 1.813663677502704

Epoch: 414| Step: 0
Training loss: 0.9256799817085266
Validation loss: 1.828906439965771

Epoch: 6| Step: 1
Training loss: 1.1585595607757568
Validation loss: 1.81442807438553

Epoch: 6| Step: 2
Training loss: 1.529845952987671
Validation loss: 1.7889408321790798

Epoch: 6| Step: 3
Training loss: 0.7406574487686157
Validation loss: 1.8590570124246741

Epoch: 6| Step: 4
Training loss: 0.8246380090713501
Validation loss: 1.8290605596316758

Epoch: 6| Step: 5
Training loss: 0.8601111173629761
Validation loss: 1.8444312105896652

Epoch: 6| Step: 6
Training loss: 1.0871105194091797
Validation loss: 1.8152439055904266

Epoch: 6| Step: 7
Training loss: 1.420424222946167
Validation loss: 1.807363611395641

Epoch: 6| Step: 8
Training loss: 0.7861933708190918
Validation loss: 1.8460544270853843

Epoch: 6| Step: 9
Training loss: 0.578732967376709
Validation loss: 1.8704626688393213

Epoch: 6| Step: 10
Training loss: 0.9949445128440857
Validation loss: 1.8502096706821072

Epoch: 6| Step: 11
Training loss: 1.6093525886535645
Validation loss: 1.8708964624712545

Epoch: 6| Step: 12
Training loss: 1.178144931793213
Validation loss: 1.7780886055320821

Epoch: 6| Step: 13
Training loss: 0.560520589351654
Validation loss: 1.8818039022466189

Epoch: 415| Step: 0
Training loss: 1.3541122674942017
Validation loss: 1.90004563331604

Epoch: 6| Step: 1
Training loss: 1.4096589088439941
Validation loss: 1.8632586694532824

Epoch: 6| Step: 2
Training loss: 0.7324538230895996
Validation loss: 1.867782308209327

Epoch: 6| Step: 3
Training loss: 0.8961337804794312
Validation loss: 1.821732105747346

Epoch: 6| Step: 4
Training loss: 1.3260185718536377
Validation loss: 1.8781815241741877

Epoch: 6| Step: 5
Training loss: 1.0360232591629028
Validation loss: 1.854358002703677

Epoch: 6| Step: 6
Training loss: 0.913935661315918
Validation loss: 1.8052414847958473

Epoch: 6| Step: 7
Training loss: 0.8501325249671936
Validation loss: 1.7802915086028397

Epoch: 6| Step: 8
Training loss: 1.2964787483215332
Validation loss: 1.891141273642099

Epoch: 6| Step: 9
Training loss: 0.6794317960739136
Validation loss: 1.8311781806330527

Epoch: 6| Step: 10
Training loss: 1.396272897720337
Validation loss: 1.8724933439685452

Epoch: 6| Step: 11
Training loss: 1.2893089056015015
Validation loss: 1.8017163776582288

Epoch: 6| Step: 12
Training loss: 0.5569338798522949
Validation loss: 1.837156754668041

Epoch: 6| Step: 13
Training loss: 0.7414664030075073
Validation loss: 1.8190771918142996

Epoch: 416| Step: 0
Training loss: 0.6100143790245056
Validation loss: 1.8501863095068163

Epoch: 6| Step: 1
Training loss: 0.8748117685317993
Validation loss: 1.8429321742826892

Epoch: 6| Step: 2
Training loss: 1.1710067987442017
Validation loss: 1.7684400402089602

Epoch: 6| Step: 3
Training loss: 1.4700798988342285
Validation loss: 1.8079229913732058

Epoch: 6| Step: 4
Training loss: 0.8224970102310181
Validation loss: 1.8202057333402737

Epoch: 6| Step: 5
Training loss: 1.3700815439224243
Validation loss: 1.821993717583277

Epoch: 6| Step: 6
Training loss: 0.9494837522506714
Validation loss: 1.8642435022579726

Epoch: 6| Step: 7
Training loss: 1.502638578414917
Validation loss: 1.763935556975744

Epoch: 6| Step: 8
Training loss: 1.0586329698562622
Validation loss: 1.8152452938018306

Epoch: 6| Step: 9
Training loss: 0.7670146822929382
Validation loss: 1.8340911070505779

Epoch: 6| Step: 10
Training loss: 1.1309014558792114
Validation loss: 1.8549970157684819

Epoch: 6| Step: 11
Training loss: 1.0189684629440308
Validation loss: 1.8058398128837667

Epoch: 6| Step: 12
Training loss: 0.7030770778656006
Validation loss: 1.8100158296605593

Epoch: 6| Step: 13
Training loss: 1.3419603109359741
Validation loss: 1.8645220571948635

Epoch: 417| Step: 0
Training loss: 0.9398646354675293
Validation loss: 1.801684207813714

Epoch: 6| Step: 1
Training loss: 0.952734649181366
Validation loss: 1.8892500964544152

Epoch: 6| Step: 2
Training loss: 1.538604736328125
Validation loss: 1.8199510189794725

Epoch: 6| Step: 3
Training loss: 0.9624260067939758
Validation loss: 1.8852429082316737

Epoch: 6| Step: 4
Training loss: 0.992408812046051
Validation loss: 1.8539481086115683

Epoch: 6| Step: 5
Training loss: 0.6462974548339844
Validation loss: 1.8141096561185774

Epoch: 6| Step: 6
Training loss: 1.771641731262207
Validation loss: 1.8918408270805114

Epoch: 6| Step: 7
Training loss: 1.2394946813583374
Validation loss: 1.7916096961626442

Epoch: 6| Step: 8
Training loss: 0.850197434425354
Validation loss: 1.8381318840929257

Epoch: 6| Step: 9
Training loss: 1.0031651258468628
Validation loss: 1.8763322343108475

Epoch: 6| Step: 10
Training loss: 0.8641500473022461
Validation loss: 1.9217119691192464

Epoch: 6| Step: 11
Training loss: 1.0957285165786743
Validation loss: 1.8422694808693343

Epoch: 6| Step: 12
Training loss: 0.6667460203170776
Validation loss: 1.928966700389821

Epoch: 6| Step: 13
Training loss: 1.280426025390625
Validation loss: 1.879678697996242

Epoch: 418| Step: 0
Training loss: 0.7232823371887207
Validation loss: 1.8049831210926015

Epoch: 6| Step: 1
Training loss: 0.7925669550895691
Validation loss: 1.8252304882131598

Epoch: 6| Step: 2
Training loss: 1.383109211921692
Validation loss: 1.8094660505171745

Epoch: 6| Step: 3
Training loss: 1.1692686080932617
Validation loss: 1.8482877105794928

Epoch: 6| Step: 4
Training loss: 1.0046619176864624
Validation loss: 1.823662063126923

Epoch: 6| Step: 5
Training loss: 1.1295945644378662
Validation loss: 1.8143799240871141

Epoch: 6| Step: 6
Training loss: 1.2404119968414307
Validation loss: 1.8444736003875732

Epoch: 6| Step: 7
Training loss: 1.2436648607254028
Validation loss: 1.839907048850931

Epoch: 6| Step: 8
Training loss: 0.7689124345779419
Validation loss: 1.8190291632888138

Epoch: 6| Step: 9
Training loss: 1.1923770904541016
Validation loss: 1.889027044337283

Epoch: 6| Step: 10
Training loss: 1.153512716293335
Validation loss: 1.8619295384294243

Epoch: 6| Step: 11
Training loss: 1.0437155961990356
Validation loss: 1.8199048734480334

Epoch: 6| Step: 12
Training loss: 0.9628409147262573
Validation loss: 1.8586635128144295

Epoch: 6| Step: 13
Training loss: 0.7050824761390686
Validation loss: 1.8443949850656653

Epoch: 419| Step: 0
Training loss: 0.8410831689834595
Validation loss: 1.7986703559916506

Epoch: 6| Step: 1
Training loss: 0.8528094291687012
Validation loss: 1.7622190739518853

Epoch: 6| Step: 2
Training loss: 1.3329638242721558
Validation loss: 1.7843520692599717

Epoch: 6| Step: 3
Training loss: 1.2829296588897705
Validation loss: 1.8295119680384153

Epoch: 6| Step: 4
Training loss: 1.0980224609375
Validation loss: 1.8887139622883131

Epoch: 6| Step: 5
Training loss: 1.0067577362060547
Validation loss: 1.846842244107236

Epoch: 6| Step: 6
Training loss: 1.2376575469970703
Validation loss: 1.8084499759058799

Epoch: 6| Step: 7
Training loss: 0.724669873714447
Validation loss: 1.8385498780076222

Epoch: 6| Step: 8
Training loss: 1.04789400100708
Validation loss: 1.7758771822016726

Epoch: 6| Step: 9
Training loss: 1.1133990287780762
Validation loss: 1.7965819092207058

Epoch: 6| Step: 10
Training loss: 1.169839859008789
Validation loss: 1.8418469762289396

Epoch: 6| Step: 11
Training loss: 1.0844120979309082
Validation loss: 1.8302548111125987

Epoch: 6| Step: 12
Training loss: 1.0996657609939575
Validation loss: 1.817960036698208

Epoch: 6| Step: 13
Training loss: 1.223273754119873
Validation loss: 1.8214018447424776

Epoch: 420| Step: 0
Training loss: 1.495875597000122
Validation loss: 1.8470035060759513

Epoch: 6| Step: 1
Training loss: 1.4057426452636719
Validation loss: 1.876554564763141

Epoch: 6| Step: 2
Training loss: 0.708369255065918
Validation loss: 1.7438007823882564

Epoch: 6| Step: 3
Training loss: 1.1620299816131592
Validation loss: 1.798912682840901

Epoch: 6| Step: 4
Training loss: 0.9510886073112488
Validation loss: 1.8043175564017346

Epoch: 6| Step: 5
Training loss: 0.591254472732544
Validation loss: 1.837522178567866

Epoch: 6| Step: 6
Training loss: 1.7555378675460815
Validation loss: 1.817757063014533

Epoch: 6| Step: 7
Training loss: 0.9017177820205688
Validation loss: 1.8079546023440618

Epoch: 6| Step: 8
Training loss: 1.307645559310913
Validation loss: 1.8150618012233446

Epoch: 6| Step: 9
Training loss: 0.729698657989502
Validation loss: 1.8140558414561774

Epoch: 6| Step: 10
Training loss: 1.092572808265686
Validation loss: 1.8539170065233785

Epoch: 6| Step: 11
Training loss: 0.5756526589393616
Validation loss: 1.8783646706611878

Epoch: 6| Step: 12
Training loss: 0.38746178150177
Validation loss: 1.8627615321067073

Epoch: 6| Step: 13
Training loss: 1.1779972314834595
Validation loss: 1.8330872699778566

Epoch: 421| Step: 0
Training loss: 1.485828161239624
Validation loss: 1.7901357617429507

Epoch: 6| Step: 1
Training loss: 1.2109185457229614
Validation loss: 1.85621944550545

Epoch: 6| Step: 2
Training loss: 1.0098272562026978
Validation loss: 1.8465358877694735

Epoch: 6| Step: 3
Training loss: 1.0367845296859741
Validation loss: 1.9101856575217298

Epoch: 6| Step: 4
Training loss: 0.9580560922622681
Validation loss: 1.8555097169773553

Epoch: 6| Step: 5
Training loss: 1.1528570652008057
Validation loss: 1.8607767525539602

Epoch: 6| Step: 6
Training loss: 1.3492246866226196
Validation loss: 1.8453238574407433

Epoch: 6| Step: 7
Training loss: 0.8514963388442993
Validation loss: 1.8244112999208513

Epoch: 6| Step: 8
Training loss: 0.7309560179710388
Validation loss: 1.8068756839280486

Epoch: 6| Step: 9
Training loss: 0.7560068964958191
Validation loss: 1.814715696919349

Epoch: 6| Step: 10
Training loss: 0.7278011441230774
Validation loss: 1.8125456597215386

Epoch: 6| Step: 11
Training loss: 1.4501543045043945
Validation loss: 1.8746111328883837

Epoch: 6| Step: 12
Training loss: 0.9380054473876953
Validation loss: 1.8321512642727102

Epoch: 6| Step: 13
Training loss: 1.0508053302764893
Validation loss: 1.8147504970591555

Epoch: 422| Step: 0
Training loss: 1.0965673923492432
Validation loss: 1.8301153080437773

Epoch: 6| Step: 1
Training loss: 2.076274871826172
Validation loss: 1.8562427361806233

Epoch: 6| Step: 2
Training loss: 0.6266849637031555
Validation loss: 1.8329924896199217

Epoch: 6| Step: 3
Training loss: 0.5239181518554688
Validation loss: 1.8659929652367868

Epoch: 6| Step: 4
Training loss: 0.8114330768585205
Validation loss: 1.8013643090442946

Epoch: 6| Step: 5
Training loss: 1.1341707706451416
Validation loss: 1.8280128791768064

Epoch: 6| Step: 6
Training loss: 0.9717979431152344
Validation loss: 1.8469919043202554

Epoch: 6| Step: 7
Training loss: 1.040157675743103
Validation loss: 1.8128183695577806

Epoch: 6| Step: 8
Training loss: 0.5848986506462097
Validation loss: 1.8108109786946287

Epoch: 6| Step: 9
Training loss: 0.8204556703567505
Validation loss: 1.8667984662517425

Epoch: 6| Step: 10
Training loss: 0.8246479034423828
Validation loss: 1.8057433020684026

Epoch: 6| Step: 11
Training loss: 1.425675868988037
Validation loss: 1.8305847619169502

Epoch: 6| Step: 12
Training loss: 1.1647274494171143
Validation loss: 1.8345512465764118

Epoch: 6| Step: 13
Training loss: 1.0584958791732788
Validation loss: 1.8337038781053276

Epoch: 423| Step: 0
Training loss: 0.7660936117172241
Validation loss: 1.829449471607003

Epoch: 6| Step: 1
Training loss: 1.3275741338729858
Validation loss: 1.8260678911721835

Epoch: 6| Step: 2
Training loss: 1.524366021156311
Validation loss: 1.824362257475494

Epoch: 6| Step: 3
Training loss: 1.1853750944137573
Validation loss: 1.799235697715513

Epoch: 6| Step: 4
Training loss: 0.9595749378204346
Validation loss: 1.8138252727447017

Epoch: 6| Step: 5
Training loss: 0.8922417163848877
Validation loss: 1.8059637700357745

Epoch: 6| Step: 6
Training loss: 0.9322530031204224
Validation loss: 1.8551615233062415

Epoch: 6| Step: 7
Training loss: 1.0040125846862793
Validation loss: 1.862657215005608

Epoch: 6| Step: 8
Training loss: 0.8599525094032288
Validation loss: 1.8697009881337483

Epoch: 6| Step: 9
Training loss: 1.1453014612197876
Validation loss: 1.850170007316015

Epoch: 6| Step: 10
Training loss: 1.1282141208648682
Validation loss: 1.868948189161157

Epoch: 6| Step: 11
Training loss: 0.9576143026351929
Validation loss: 1.8179703643245082

Epoch: 6| Step: 12
Training loss: 0.971534788608551
Validation loss: 1.8467275814343524

Epoch: 6| Step: 13
Training loss: 0.5539789199829102
Validation loss: 1.843977471833588

Epoch: 424| Step: 0
Training loss: 0.5500216484069824
Validation loss: 1.8488400033725205

Epoch: 6| Step: 1
Training loss: 1.19386887550354
Validation loss: 1.829644436477333

Epoch: 6| Step: 2
Training loss: 1.1573758125305176
Validation loss: 1.770705690947912

Epoch: 6| Step: 3
Training loss: 1.0973830223083496
Validation loss: 1.8454136745904082

Epoch: 6| Step: 4
Training loss: 0.8170375823974609
Validation loss: 1.8792334269451838

Epoch: 6| Step: 5
Training loss: 1.2527531385421753
Validation loss: 1.86084746801725

Epoch: 6| Step: 6
Training loss: 1.4559824466705322
Validation loss: 1.879025620798911

Epoch: 6| Step: 7
Training loss: 0.8141287565231323
Validation loss: 1.8802238843774284

Epoch: 6| Step: 8
Training loss: 1.557274580001831
Validation loss: 1.8411067403772825

Epoch: 6| Step: 9
Training loss: 1.3659336566925049
Validation loss: 1.8872156450825353

Epoch: 6| Step: 10
Training loss: 0.7021406292915344
Validation loss: 1.787039710629371

Epoch: 6| Step: 11
Training loss: 1.2052234411239624
Validation loss: 1.802470068777761

Epoch: 6| Step: 12
Training loss: 0.7567776441574097
Validation loss: 1.890822002964635

Epoch: 6| Step: 13
Training loss: 0.4315909743309021
Validation loss: 1.8237645087703582

Epoch: 425| Step: 0
Training loss: 1.1123030185699463
Validation loss: 1.8085540379247358

Epoch: 6| Step: 1
Training loss: 0.441283643245697
Validation loss: 1.7375385761260986

Epoch: 6| Step: 2
Training loss: 0.9241772294044495
Validation loss: 1.793945361209172

Epoch: 6| Step: 3
Training loss: 1.479899525642395
Validation loss: 1.8061257946875788

Epoch: 6| Step: 4
Training loss: 0.7708866000175476
Validation loss: 1.8552122615998792

Epoch: 6| Step: 5
Training loss: 1.214646577835083
Validation loss: 1.8428413368040515

Epoch: 6| Step: 6
Training loss: 1.208906650543213
Validation loss: 1.8434789501210695

Epoch: 6| Step: 7
Training loss: 0.9223555326461792
Validation loss: 1.8571382286728069

Epoch: 6| Step: 8
Training loss: 0.6384164094924927
Validation loss: 1.8775560907138291

Epoch: 6| Step: 9
Training loss: 1.1852552890777588
Validation loss: 1.8057043898490168

Epoch: 6| Step: 10
Training loss: 1.3111529350280762
Validation loss: 1.8507061004638672

Epoch: 6| Step: 11
Training loss: 1.4714584350585938
Validation loss: 1.8396515333524315

Epoch: 6| Step: 12
Training loss: 0.6584712862968445
Validation loss: 1.8468933054195937

Epoch: 6| Step: 13
Training loss: 1.0962828397750854
Validation loss: 1.885984428467289

Epoch: 426| Step: 0
Training loss: 1.1695151329040527
Validation loss: 1.8319380411537745

Epoch: 6| Step: 1
Training loss: 1.2094120979309082
Validation loss: 1.8634380794340564

Epoch: 6| Step: 2
Training loss: 0.6686288714408875
Validation loss: 1.8056290252234346

Epoch: 6| Step: 3
Training loss: 0.5648351907730103
Validation loss: 1.7950921802110569

Epoch: 6| Step: 4
Training loss: 0.96873939037323
Validation loss: 1.776531457901001

Epoch: 6| Step: 5
Training loss: 0.850382924079895
Validation loss: 1.8036317261316444

Epoch: 6| Step: 6
Training loss: 1.4719221591949463
Validation loss: 1.7862881845043552

Epoch: 6| Step: 7
Training loss: 0.7111259698867798
Validation loss: 1.8124437197562187

Epoch: 6| Step: 8
Training loss: 1.2382516860961914
Validation loss: 1.8338472356078446

Epoch: 6| Step: 9
Training loss: 1.000363826751709
Validation loss: 1.7989230643036545

Epoch: 6| Step: 10
Training loss: 1.0913829803466797
Validation loss: 1.77699799178749

Epoch: 6| Step: 11
Training loss: 0.8983819484710693
Validation loss: 1.8367616335550945

Epoch: 6| Step: 12
Training loss: 1.0989079475402832
Validation loss: 1.8328129911935458

Epoch: 6| Step: 13
Training loss: 0.9697231650352478
Validation loss: 1.827874623319154

Epoch: 427| Step: 0
Training loss: 1.157282829284668
Validation loss: 1.8479984037337764

Epoch: 6| Step: 1
Training loss: 1.011678695678711
Validation loss: 1.850342781313004

Epoch: 6| Step: 2
Training loss: 1.477734088897705
Validation loss: 1.8616849786491805

Epoch: 6| Step: 3
Training loss: 1.1952054500579834
Validation loss: 1.8275318684116486

Epoch: 6| Step: 4
Training loss: 0.8552302718162537
Validation loss: 1.8781029857614988

Epoch: 6| Step: 5
Training loss: 1.0706976652145386
Validation loss: 1.833817280748839

Epoch: 6| Step: 6
Training loss: 0.8798818588256836
Validation loss: 1.8142865434769662

Epoch: 6| Step: 7
Training loss: 1.1664648056030273
Validation loss: 1.8542920133118987

Epoch: 6| Step: 8
Training loss: 0.9368705153465271
Validation loss: 1.8241021517784364

Epoch: 6| Step: 9
Training loss: 0.872482180595398
Validation loss: 1.8346436895349973

Epoch: 6| Step: 10
Training loss: 0.8771748542785645
Validation loss: 1.8575215493479083

Epoch: 6| Step: 11
Training loss: 1.2321699857711792
Validation loss: 1.8274924908914874

Epoch: 6| Step: 12
Training loss: 1.1172977685928345
Validation loss: 1.8804320917334607

Epoch: 6| Step: 13
Training loss: 0.4130633771419525
Validation loss: 1.8944029577316777

Epoch: 428| Step: 0
Training loss: 1.2866829633712769
Validation loss: 1.8301781582575973

Epoch: 6| Step: 1
Training loss: 0.6590933799743652
Validation loss: 1.7959355756800661

Epoch: 6| Step: 2
Training loss: 1.3078207969665527
Validation loss: 1.8360246624997867

Epoch: 6| Step: 3
Training loss: 0.7025588750839233
Validation loss: 1.796490966632802

Epoch: 6| Step: 4
Training loss: 0.855144739151001
Validation loss: 1.84270610860599

Epoch: 6| Step: 5
Training loss: 0.626146137714386
Validation loss: 1.8555666451813073

Epoch: 6| Step: 6
Training loss: 0.6580563187599182
Validation loss: 1.8361765107800883

Epoch: 6| Step: 7
Training loss: 1.1745344400405884
Validation loss: 1.8521866875310098

Epoch: 6| Step: 8
Training loss: 1.346332311630249
Validation loss: 1.8229686367896296

Epoch: 6| Step: 9
Training loss: 1.0960203409194946
Validation loss: 1.7674679909982989

Epoch: 6| Step: 10
Training loss: 0.9310418367385864
Validation loss: 1.813285663563718

Epoch: 6| Step: 11
Training loss: 1.3798439502716064
Validation loss: 1.8389315899982248

Epoch: 6| Step: 12
Training loss: 1.2338690757751465
Validation loss: 1.816289165968536

Epoch: 6| Step: 13
Training loss: 1.087888240814209
Validation loss: 1.782033751087804

Epoch: 429| Step: 0
Training loss: 0.952833890914917
Validation loss: 1.8238381429385113

Epoch: 6| Step: 1
Training loss: 0.6709153056144714
Validation loss: 1.8579003554518505

Epoch: 6| Step: 2
Training loss: 1.4388465881347656
Validation loss: 1.808480042283253

Epoch: 6| Step: 3
Training loss: 1.1415003538131714
Validation loss: 1.8254071461257113

Epoch: 6| Step: 4
Training loss: 0.9508086442947388
Validation loss: 1.8522557891825193

Epoch: 6| Step: 5
Training loss: 0.8710793256759644
Validation loss: 1.8462787751228578

Epoch: 6| Step: 6
Training loss: 0.9506134390830994
Validation loss: 1.8239401002084055

Epoch: 6| Step: 7
Training loss: 0.8654828667640686
Validation loss: 1.834648145142422

Epoch: 6| Step: 8
Training loss: 1.1209163665771484
Validation loss: 1.7868652279658983

Epoch: 6| Step: 9
Training loss: 1.2974299192428589
Validation loss: 1.8235877906122515

Epoch: 6| Step: 10
Training loss: 0.891254186630249
Validation loss: 1.8386983320277224

Epoch: 6| Step: 11
Training loss: 1.351163625717163
Validation loss: 1.8618549608415174

Epoch: 6| Step: 12
Training loss: 0.8756769299507141
Validation loss: 1.8215987297796434

Epoch: 6| Step: 13
Training loss: 0.7020752429962158
Validation loss: 1.8641535505171745

Epoch: 430| Step: 0
Training loss: 0.9868540167808533
Validation loss: 1.8541543752916398

Epoch: 6| Step: 1
Training loss: 0.8062250018119812
Validation loss: 1.8867223954969836

Epoch: 6| Step: 2
Training loss: 0.8109855651855469
Validation loss: 1.8142129887816727

Epoch: 6| Step: 3
Training loss: 0.8989379405975342
Validation loss: 1.8352501764092395

Epoch: 6| Step: 4
Training loss: 1.0060168504714966
Validation loss: 1.8482837728274766

Epoch: 6| Step: 5
Training loss: 1.0236759185791016
Validation loss: 1.851969648432988

Epoch: 6| Step: 6
Training loss: 1.0601590871810913
Validation loss: 1.8143122632016417

Epoch: 6| Step: 7
Training loss: 1.334818720817566
Validation loss: 1.7984798185286983

Epoch: 6| Step: 8
Training loss: 0.808746337890625
Validation loss: 1.8405533439369612

Epoch: 6| Step: 9
Training loss: 0.8550878763198853
Validation loss: 1.8124226857257146

Epoch: 6| Step: 10
Training loss: 0.5233240127563477
Validation loss: 1.832300027211507

Epoch: 6| Step: 11
Training loss: 1.055577039718628
Validation loss: 1.819255631457093

Epoch: 6| Step: 12
Training loss: 1.7214860916137695
Validation loss: 1.8471183110308904

Epoch: 6| Step: 13
Training loss: 1.6132080554962158
Validation loss: 1.8183509380586687

Epoch: 431| Step: 0
Training loss: 0.8637218475341797
Validation loss: 1.824378441738826

Epoch: 6| Step: 1
Training loss: 0.6239942908287048
Validation loss: 1.8472256968098302

Epoch: 6| Step: 2
Training loss: 1.379276990890503
Validation loss: 1.8060543908867785

Epoch: 6| Step: 3
Training loss: 1.4122806787490845
Validation loss: 1.788662955325137

Epoch: 6| Step: 4
Training loss: 0.8429872989654541
Validation loss: 1.8061793491404543

Epoch: 6| Step: 5
Training loss: 0.9272476434707642
Validation loss: 1.813429368439541

Epoch: 6| Step: 6
Training loss: 1.0720977783203125
Validation loss: 1.8636488632489276

Epoch: 6| Step: 7
Training loss: 0.9642612338066101
Validation loss: 1.8045834443902458

Epoch: 6| Step: 8
Training loss: 1.2452092170715332
Validation loss: 1.8821882253052087

Epoch: 6| Step: 9
Training loss: 0.9899282455444336
Validation loss: 1.8331815888804774

Epoch: 6| Step: 10
Training loss: 0.9445884823799133
Validation loss: 1.878004582979346

Epoch: 6| Step: 11
Training loss: 0.9552637338638306
Validation loss: 1.8001612745305544

Epoch: 6| Step: 12
Training loss: 0.9701097011566162
Validation loss: 1.8676235714266378

Epoch: 6| Step: 13
Training loss: 0.537079930305481
Validation loss: 1.835237044160084

Epoch: 432| Step: 0
Training loss: 0.8211452960968018
Validation loss: 1.8079251602131834

Epoch: 6| Step: 1
Training loss: 1.2392258644104004
Validation loss: 1.8161871240985008

Epoch: 6| Step: 2
Training loss: 0.8127707839012146
Validation loss: 1.849354338902299

Epoch: 6| Step: 3
Training loss: 1.1166019439697266
Validation loss: 1.8537809182238836

Epoch: 6| Step: 4
Training loss: 0.8503289222717285
Validation loss: 1.8475795381812639

Epoch: 6| Step: 5
Training loss: 0.48619502782821655
Validation loss: 1.8351970770025765

Epoch: 6| Step: 6
Training loss: 0.8246983289718628
Validation loss: 1.8180906003521335

Epoch: 6| Step: 7
Training loss: 1.4238256216049194
Validation loss: 1.8415101702495287

Epoch: 6| Step: 8
Training loss: 1.0376534461975098
Validation loss: 1.8545682917359054

Epoch: 6| Step: 9
Training loss: 0.9513060450553894
Validation loss: 1.8701607975908505

Epoch: 6| Step: 10
Training loss: 1.593714714050293
Validation loss: 1.825342728245643

Epoch: 6| Step: 11
Training loss: 0.9622893929481506
Validation loss: 1.8153757510646698

Epoch: 6| Step: 12
Training loss: 1.153761386871338
Validation loss: 1.8300671180089314

Epoch: 6| Step: 13
Training loss: 0.9958572387695312
Validation loss: 1.798542079105172

Epoch: 433| Step: 0
Training loss: 0.6261017322540283
Validation loss: 1.850535226124589

Epoch: 6| Step: 1
Training loss: 0.9995737075805664
Validation loss: 1.8622744467950636

Epoch: 6| Step: 2
Training loss: 0.8218669891357422
Validation loss: 1.8802611571486278

Epoch: 6| Step: 3
Training loss: 1.1268130540847778
Validation loss: 1.8322647053708312

Epoch: 6| Step: 4
Training loss: 0.9805420637130737
Validation loss: 1.8239924830775107

Epoch: 6| Step: 5
Training loss: 0.8488158583641052
Validation loss: 1.8419333017000588

Epoch: 6| Step: 6
Training loss: 1.0558414459228516
Validation loss: 1.8465900023778279

Epoch: 6| Step: 7
Training loss: 1.2007219791412354
Validation loss: 1.8344740047249743

Epoch: 6| Step: 8
Training loss: 0.6564124822616577
Validation loss: 1.8105076436073548

Epoch: 6| Step: 9
Training loss: 1.2201191186904907
Validation loss: 1.7924624335381292

Epoch: 6| Step: 10
Training loss: 1.697566032409668
Validation loss: 1.8227851172929168

Epoch: 6| Step: 11
Training loss: 0.9743702411651611
Validation loss: 1.8907364799130348

Epoch: 6| Step: 12
Training loss: 0.911645770072937
Validation loss: 1.789667401262509

Epoch: 6| Step: 13
Training loss: 0.96462082862854
Validation loss: 1.7879397343563777

Epoch: 434| Step: 0
Training loss: 1.1522079706192017
Validation loss: 1.862428065269224

Epoch: 6| Step: 1
Training loss: 1.0514962673187256
Validation loss: 1.8008504721426195

Epoch: 6| Step: 2
Training loss: 1.0471082925796509
Validation loss: 1.842341887053623

Epoch: 6| Step: 3
Training loss: 1.2542760372161865
Validation loss: 1.864549118985412

Epoch: 6| Step: 4
Training loss: 1.065514326095581
Validation loss: 1.881369698432184

Epoch: 6| Step: 5
Training loss: 1.168529748916626
Validation loss: 1.8979287224431192

Epoch: 6| Step: 6
Training loss: 0.3899644613265991
Validation loss: 1.8453998155491327

Epoch: 6| Step: 7
Training loss: 1.3736627101898193
Validation loss: 1.8722303413575696

Epoch: 6| Step: 8
Training loss: 0.5988366603851318
Validation loss: 1.8642819312310988

Epoch: 6| Step: 9
Training loss: 0.8379113674163818
Validation loss: 1.8410690010234874

Epoch: 6| Step: 10
Training loss: 1.1460628509521484
Validation loss: 1.8228176857835503

Epoch: 6| Step: 11
Training loss: 0.9917542338371277
Validation loss: 1.8943216877598916

Epoch: 6| Step: 12
Training loss: 1.070603847503662
Validation loss: 1.8671936976012362

Epoch: 6| Step: 13
Training loss: 1.1383088827133179
Validation loss: 1.900870120653542

Epoch: 435| Step: 0
Training loss: 0.9747059345245361
Validation loss: 1.8071232085586877

Epoch: 6| Step: 1
Training loss: 0.841973066329956
Validation loss: 1.8147484512739285

Epoch: 6| Step: 2
Training loss: 0.4702015519142151
Validation loss: 1.8293551719316872

Epoch: 6| Step: 3
Training loss: 0.4953750967979431
Validation loss: 1.7908358086821854

Epoch: 6| Step: 4
Training loss: 1.3989942073822021
Validation loss: 1.819416367879478

Epoch: 6| Step: 5
Training loss: 0.9208393096923828
Validation loss: 1.8356316410085207

Epoch: 6| Step: 6
Training loss: 0.8649208545684814
Validation loss: 1.8105846707538893

Epoch: 6| Step: 7
Training loss: 1.030749797821045
Validation loss: 1.8295289560030865

Epoch: 6| Step: 8
Training loss: 1.1908912658691406
Validation loss: 1.8203472578397362

Epoch: 6| Step: 9
Training loss: 0.6986156105995178
Validation loss: 1.8452155692602998

Epoch: 6| Step: 10
Training loss: 0.9248471260070801
Validation loss: 1.8428491110442786

Epoch: 6| Step: 11
Training loss: 0.9610276222229004
Validation loss: 1.83190490353492

Epoch: 6| Step: 12
Training loss: 1.2759425640106201
Validation loss: 1.8210263841895646

Epoch: 6| Step: 13
Training loss: 1.580176830291748
Validation loss: 1.845461376251713

Epoch: 436| Step: 0
Training loss: 0.762999415397644
Validation loss: 1.852713369554089

Epoch: 6| Step: 1
Training loss: 0.5790854692459106
Validation loss: 1.8651851902725876

Epoch: 6| Step: 2
Training loss: 0.5438094139099121
Validation loss: 1.868231543930628

Epoch: 6| Step: 3
Training loss: 0.9138293862342834
Validation loss: 1.8409191190555532

Epoch: 6| Step: 4
Training loss: 1.9319885969161987
Validation loss: 1.8694027957095896

Epoch: 6| Step: 5
Training loss: 0.7511270046234131
Validation loss: 1.876644621613205

Epoch: 6| Step: 6
Training loss: 1.0127084255218506
Validation loss: 1.8656839773219118

Epoch: 6| Step: 7
Training loss: 1.6441330909729004
Validation loss: 1.8863282549765803

Epoch: 6| Step: 8
Training loss: 1.0395559072494507
Validation loss: 1.8383094636342858

Epoch: 6| Step: 9
Training loss: 0.8795748949050903
Validation loss: 1.8656052645816599

Epoch: 6| Step: 10
Training loss: 0.9679853916168213
Validation loss: 1.8831523900390954

Epoch: 6| Step: 11
Training loss: 0.6353825926780701
Validation loss: 1.8009391984631937

Epoch: 6| Step: 12
Training loss: 1.0660173892974854
Validation loss: 1.8830864044927782

Epoch: 6| Step: 13
Training loss: 1.0374616384506226
Validation loss: 1.8649795016934794

Epoch: 437| Step: 0
Training loss: 0.9300628304481506
Validation loss: 1.882413201434638

Epoch: 6| Step: 1
Training loss: 0.9476341009140015
Validation loss: 1.8281666412148425

Epoch: 6| Step: 2
Training loss: 0.4541776180267334
Validation loss: 1.8087185659716207

Epoch: 6| Step: 3
Training loss: 1.2435986995697021
Validation loss: 1.8230271236870879

Epoch: 6| Step: 4
Training loss: 1.192098617553711
Validation loss: 1.8230160128685735

Epoch: 6| Step: 5
Training loss: 0.7747606039047241
Validation loss: 1.8025554944110174

Epoch: 6| Step: 6
Training loss: 0.9697176218032837
Validation loss: 1.8413909148144465

Epoch: 6| Step: 7
Training loss: 0.8777320384979248
Validation loss: 1.801961547584944

Epoch: 6| Step: 8
Training loss: 0.7576987743377686
Validation loss: 1.810122061801213

Epoch: 6| Step: 9
Training loss: 0.7176120281219482
Validation loss: 1.8625914537778465

Epoch: 6| Step: 10
Training loss: 1.537829875946045
Validation loss: 1.7905633206008582

Epoch: 6| Step: 11
Training loss: 0.9619108438491821
Validation loss: 1.843766402172786

Epoch: 6| Step: 12
Training loss: 0.926071047782898
Validation loss: 1.8270697427052323

Epoch: 6| Step: 13
Training loss: 1.5158600807189941
Validation loss: 1.82812338618822

Epoch: 438| Step: 0
Training loss: 0.6691188216209412
Validation loss: 1.8180253697979836

Epoch: 6| Step: 1
Training loss: 1.4006321430206299
Validation loss: 1.827373521302336

Epoch: 6| Step: 2
Training loss: 1.3964166641235352
Validation loss: 1.8332220226205804

Epoch: 6| Step: 3
Training loss: 0.7593417167663574
Validation loss: 1.8352728671925043

Epoch: 6| Step: 4
Training loss: 0.8350585699081421
Validation loss: 1.8151604693423036

Epoch: 6| Step: 5
Training loss: 1.1357356309890747
Validation loss: 1.8438767258838942

Epoch: 6| Step: 6
Training loss: 1.1691397428512573
Validation loss: 1.8909815062758744

Epoch: 6| Step: 7
Training loss: 1.671441912651062
Validation loss: 1.8418060092515842

Epoch: 6| Step: 8
Training loss: 0.8589614629745483
Validation loss: 1.8509725037441458

Epoch: 6| Step: 9
Training loss: 0.8768035173416138
Validation loss: 1.836466021435235

Epoch: 6| Step: 10
Training loss: 0.7752212882041931
Validation loss: 1.876615342273507

Epoch: 6| Step: 11
Training loss: 0.5449652671813965
Validation loss: 1.8045784465728267

Epoch: 6| Step: 12
Training loss: 0.7136697173118591
Validation loss: 1.787362894704265

Epoch: 6| Step: 13
Training loss: 0.790367841720581
Validation loss: 1.8303915621131979

Epoch: 439| Step: 0
Training loss: 0.8092957139015198
Validation loss: 1.8093660467414445

Epoch: 6| Step: 1
Training loss: 0.9733667373657227
Validation loss: 1.7853156828111219

Epoch: 6| Step: 2
Training loss: 1.0154454708099365
Validation loss: 1.7687191745286346

Epoch: 6| Step: 3
Training loss: 1.1307252645492554
Validation loss: 1.7993061042601062

Epoch: 6| Step: 4
Training loss: 1.214491844177246
Validation loss: 1.8487394317503898

Epoch: 6| Step: 5
Training loss: 1.1355087757110596
Validation loss: 1.8138499926495295

Epoch: 6| Step: 6
Training loss: 0.745803952217102
Validation loss: 1.819610623903172

Epoch: 6| Step: 7
Training loss: 0.7923992872238159
Validation loss: 1.7905897119993806

Epoch: 6| Step: 8
Training loss: 0.8805456757545471
Validation loss: 1.812721078113843

Epoch: 6| Step: 9
Training loss: 1.0950840711593628
Validation loss: 1.799023053979361

Epoch: 6| Step: 10
Training loss: 1.2603118419647217
Validation loss: 1.821341477414613

Epoch: 6| Step: 11
Training loss: 1.1365978717803955
Validation loss: 1.7833165885299764

Epoch: 6| Step: 12
Training loss: 0.9804269075393677
Validation loss: 1.8127061179889146

Epoch: 6| Step: 13
Training loss: 0.8460283279418945
Validation loss: 1.8546185813924319

Epoch: 440| Step: 0
Training loss: 0.6465429067611694
Validation loss: 1.907657472036218

Epoch: 6| Step: 1
Training loss: 0.4905368685722351
Validation loss: 1.8170852648314608

Epoch: 6| Step: 2
Training loss: 1.1911593675613403
Validation loss: 1.7932398549972042

Epoch: 6| Step: 3
Training loss: 1.2879074811935425
Validation loss: 1.8733700372839486

Epoch: 6| Step: 4
Training loss: 1.0122795104980469
Validation loss: 1.879290831986294

Epoch: 6| Step: 5
Training loss: 1.048708200454712
Validation loss: 1.8517168004025695

Epoch: 6| Step: 6
Training loss: 0.8571422696113586
Validation loss: 1.8691813099768855

Epoch: 6| Step: 7
Training loss: 1.1110460758209229
Validation loss: 1.8378114777226602

Epoch: 6| Step: 8
Training loss: 0.8107404112815857
Validation loss: 1.829674715636879

Epoch: 6| Step: 9
Training loss: 1.0351754426956177
Validation loss: 1.848875746932081

Epoch: 6| Step: 10
Training loss: 0.7998937964439392
Validation loss: 1.8021790981292725

Epoch: 6| Step: 11
Training loss: 0.7655771970748901
Validation loss: 1.7850907912818335

Epoch: 6| Step: 12
Training loss: 1.4283134937286377
Validation loss: 1.8202732416891283

Epoch: 6| Step: 13
Training loss: 0.8863933086395264
Validation loss: 1.8031881047833351

Epoch: 441| Step: 0
Training loss: 1.3018238544464111
Validation loss: 1.8176772248360418

Epoch: 6| Step: 1
Training loss: 1.035618782043457
Validation loss: 1.80947845725603

Epoch: 6| Step: 2
Training loss: 1.0371373891830444
Validation loss: 1.802918573861481

Epoch: 6| Step: 3
Training loss: 1.1898306608200073
Validation loss: 1.7946199204332085

Epoch: 6| Step: 4
Training loss: 0.9446287751197815
Validation loss: 1.7356172095062912

Epoch: 6| Step: 5
Training loss: 0.7508050203323364
Validation loss: 1.7898087065706971

Epoch: 6| Step: 6
Training loss: 1.0205391645431519
Validation loss: 1.8119974469625821

Epoch: 6| Step: 7
Training loss: 0.9321155548095703
Validation loss: 1.8505274506025418

Epoch: 6| Step: 8
Training loss: 1.2631464004516602
Validation loss: 1.8058558689650668

Epoch: 6| Step: 9
Training loss: 0.9756538271903992
Validation loss: 1.830497371253147

Epoch: 6| Step: 10
Training loss: 0.6697419285774231
Validation loss: 1.7966907998566986

Epoch: 6| Step: 11
Training loss: 0.964298665523529
Validation loss: 1.877472021246469

Epoch: 6| Step: 12
Training loss: 0.5077700018882751
Validation loss: 1.8378182239429925

Epoch: 6| Step: 13
Training loss: 1.0686200857162476
Validation loss: 1.815514572205082

Epoch: 442| Step: 0
Training loss: 0.8117157816886902
Validation loss: 1.875388354383489

Epoch: 6| Step: 1
Training loss: 0.6391547322273254
Validation loss: 1.8424906846015685

Epoch: 6| Step: 2
Training loss: 0.8937549591064453
Validation loss: 1.8142197644838722

Epoch: 6| Step: 3
Training loss: 0.9951603412628174
Validation loss: 1.7931805528620237

Epoch: 6| Step: 4
Training loss: 1.4862136840820312
Validation loss: 1.8684000789478261

Epoch: 6| Step: 5
Training loss: 0.688219428062439
Validation loss: 1.8136747178211008

Epoch: 6| Step: 6
Training loss: 1.0863959789276123
Validation loss: 1.8076094709416872

Epoch: 6| Step: 7
Training loss: 0.769113302230835
Validation loss: 1.818119619482307

Epoch: 6| Step: 8
Training loss: 0.9728498458862305
Validation loss: 1.8687491468203965

Epoch: 6| Step: 9
Training loss: 1.505265235900879
Validation loss: 1.86267299677736

Epoch: 6| Step: 10
Training loss: 1.2366251945495605
Validation loss: 1.8635840313408965

Epoch: 6| Step: 11
Training loss: 1.0251600742340088
Validation loss: 1.845731250701412

Epoch: 6| Step: 12
Training loss: 0.628959059715271
Validation loss: 1.8022015325484737

Epoch: 6| Step: 13
Training loss: 0.7099102735519409
Validation loss: 1.8379205042316067

Epoch: 443| Step: 0
Training loss: 1.2600243091583252
Validation loss: 1.7792462020791986

Epoch: 6| Step: 1
Training loss: 0.7956204414367676
Validation loss: 1.7850644575652255

Epoch: 6| Step: 2
Training loss: 1.6049866676330566
Validation loss: 1.8205356777355235

Epoch: 6| Step: 3
Training loss: 0.6298344731330872
Validation loss: 1.7874977832199426

Epoch: 6| Step: 4
Training loss: 1.0144891738891602
Validation loss: 1.818371126728673

Epoch: 6| Step: 5
Training loss: 1.0571262836456299
Validation loss: 1.855569565167991

Epoch: 6| Step: 6
Training loss: 1.0794605016708374
Validation loss: 1.8712128266211479

Epoch: 6| Step: 7
Training loss: 1.0042192935943604
Validation loss: 1.7954773659347205

Epoch: 6| Step: 8
Training loss: 1.1353168487548828
Validation loss: 1.8434791705941642

Epoch: 6| Step: 9
Training loss: 1.0027860403060913
Validation loss: 1.820927014914892

Epoch: 6| Step: 10
Training loss: 0.7459161281585693
Validation loss: 1.8209958537932365

Epoch: 6| Step: 11
Training loss: 0.7174059152603149
Validation loss: 1.777700287039562

Epoch: 6| Step: 12
Training loss: 0.7079905271530151
Validation loss: 1.798125893838944

Epoch: 6| Step: 13
Training loss: 1.2016549110412598
Validation loss: 1.8326742238895868

Epoch: 444| Step: 0
Training loss: 1.0164363384246826
Validation loss: 1.8743292042004165

Epoch: 6| Step: 1
Training loss: 0.8311878442764282
Validation loss: 1.8368502816846293

Epoch: 6| Step: 2
Training loss: 0.9433626532554626
Validation loss: 1.8552359560484528

Epoch: 6| Step: 3
Training loss: 1.3484058380126953
Validation loss: 1.8291682991930234

Epoch: 6| Step: 4
Training loss: 0.9667500853538513
Validation loss: 1.872093915939331

Epoch: 6| Step: 5
Training loss: 1.0756431818008423
Validation loss: 1.8634464125479422

Epoch: 6| Step: 6
Training loss: 0.8370742797851562
Validation loss: 1.8661620424639793

Epoch: 6| Step: 7
Training loss: 0.7478702068328857
Validation loss: 1.8388308068757415

Epoch: 6| Step: 8
Training loss: 0.8075884580612183
Validation loss: 1.8564830031446231

Epoch: 6| Step: 9
Training loss: 0.9117082953453064
Validation loss: 1.8415564516539216

Epoch: 6| Step: 10
Training loss: 0.9988609552383423
Validation loss: 1.8880032813677223

Epoch: 6| Step: 11
Training loss: 1.2617894411087036
Validation loss: 1.849072084631971

Epoch: 6| Step: 12
Training loss: 1.0557061433792114
Validation loss: 1.8723958025696457

Epoch: 6| Step: 13
Training loss: 1.285972237586975
Validation loss: 1.855916343709474

Epoch: 445| Step: 0
Training loss: 1.1873352527618408
Validation loss: 1.838687563455233

Epoch: 6| Step: 1
Training loss: 1.1891980171203613
Validation loss: 1.8554819399310696

Epoch: 6| Step: 2
Training loss: 0.9552812576293945
Validation loss: 1.8690221399389289

Epoch: 6| Step: 3
Training loss: 0.7844422459602356
Validation loss: 1.8608238466324345

Epoch: 6| Step: 4
Training loss: 1.4390689134597778
Validation loss: 1.7968579492261332

Epoch: 6| Step: 5
Training loss: 0.990664005279541
Validation loss: 1.8844148984519384

Epoch: 6| Step: 6
Training loss: 1.1332216262817383
Validation loss: 1.8714214589006157

Epoch: 6| Step: 7
Training loss: 0.8657951354980469
Validation loss: 1.8067592010703137

Epoch: 6| Step: 8
Training loss: 0.8474729061126709
Validation loss: 1.8637579487216087

Epoch: 6| Step: 9
Training loss: 1.2316069602966309
Validation loss: 1.808266350018081

Epoch: 6| Step: 10
Training loss: 0.4813578128814697
Validation loss: 1.7746797607791038

Epoch: 6| Step: 11
Training loss: 1.0860174894332886
Validation loss: 1.8614601460836266

Epoch: 6| Step: 12
Training loss: 0.98531174659729
Validation loss: 1.8016629244691582

Epoch: 6| Step: 13
Training loss: 0.8441933393478394
Validation loss: 1.839656133805552

Epoch: 446| Step: 0
Training loss: 0.7640923261642456
Validation loss: 1.8160660177148797

Epoch: 6| Step: 1
Training loss: 1.2993645668029785
Validation loss: 1.8357178549612723

Epoch: 6| Step: 2
Training loss: 1.0177690982818604
Validation loss: 1.8573478652584938

Epoch: 6| Step: 3
Training loss: 0.8772066235542297
Validation loss: 1.8525616712467645

Epoch: 6| Step: 4
Training loss: 1.217109203338623
Validation loss: 1.8065056557296424

Epoch: 6| Step: 5
Training loss: 1.2230985164642334
Validation loss: 1.8384645459472493

Epoch: 6| Step: 6
Training loss: 1.256549596786499
Validation loss: 1.832804492724839

Epoch: 6| Step: 7
Training loss: 1.031876564025879
Validation loss: 1.8233238830361316

Epoch: 6| Step: 8
Training loss: 0.882731020450592
Validation loss: 1.829707202091012

Epoch: 6| Step: 9
Training loss: 1.1842753887176514
Validation loss: 1.8314401988060243

Epoch: 6| Step: 10
Training loss: 0.9499487280845642
Validation loss: 1.8401816852631108

Epoch: 6| Step: 11
Training loss: 0.9257436990737915
Validation loss: 1.8232794884712464

Epoch: 6| Step: 12
Training loss: 0.410087913274765
Validation loss: 1.8236583355934388

Epoch: 6| Step: 13
Training loss: 0.7823622226715088
Validation loss: 1.8569286100326046

Epoch: 447| Step: 0
Training loss: 0.5147829055786133
Validation loss: 1.8326620722329745

Epoch: 6| Step: 1
Training loss: 0.9893581867218018
Validation loss: 1.8790625346604215

Epoch: 6| Step: 2
Training loss: 1.0099159479141235
Validation loss: 1.8443215700887865

Epoch: 6| Step: 3
Training loss: 1.1122691631317139
Validation loss: 1.8252462533212477

Epoch: 6| Step: 4
Training loss: 1.518985629081726
Validation loss: 1.8499198036809121

Epoch: 6| Step: 5
Training loss: 0.5446784496307373
Validation loss: 1.7901169330843034

Epoch: 6| Step: 6
Training loss: 0.9899171590805054
Validation loss: 1.8045527524845575

Epoch: 6| Step: 7
Training loss: 0.9565491080284119
Validation loss: 1.8354355724908973

Epoch: 6| Step: 8
Training loss: 1.0594978332519531
Validation loss: 1.8946210979133524

Epoch: 6| Step: 9
Training loss: 1.1436359882354736
Validation loss: 1.8624699884845364

Epoch: 6| Step: 10
Training loss: 0.6752831935882568
Validation loss: 1.8744366515067317

Epoch: 6| Step: 11
Training loss: 1.1211395263671875
Validation loss: 1.8236222690151584

Epoch: 6| Step: 12
Training loss: 1.3804495334625244
Validation loss: 1.8395974815532725

Epoch: 6| Step: 13
Training loss: 0.3449925482273102
Validation loss: 1.8164965850050732

Epoch: 448| Step: 0
Training loss: 0.5823373794555664
Validation loss: 1.838004501917029

Epoch: 6| Step: 1
Training loss: 0.837559700012207
Validation loss: 1.859686537455487

Epoch: 6| Step: 2
Training loss: 1.0052069425582886
Validation loss: 1.8297535674546355

Epoch: 6| Step: 3
Training loss: 0.983679473400116
Validation loss: 1.8473329274885115

Epoch: 6| Step: 4
Training loss: 0.9850053787231445
Validation loss: 1.8176729525289228

Epoch: 6| Step: 5
Training loss: 0.8026009202003479
Validation loss: 1.8569328502942157

Epoch: 6| Step: 6
Training loss: 1.3638862371444702
Validation loss: 1.819782845435604

Epoch: 6| Step: 7
Training loss: 1.1668059825897217
Validation loss: 1.8272832478246381

Epoch: 6| Step: 8
Training loss: 0.9502691626548767
Validation loss: 1.8065154462732294

Epoch: 6| Step: 9
Training loss: 0.761420726776123
Validation loss: 1.729826227311165

Epoch: 6| Step: 10
Training loss: 0.8315874338150024
Validation loss: 1.8209214620692755

Epoch: 6| Step: 11
Training loss: 0.6321107149124146
Validation loss: 1.8678663981858121

Epoch: 6| Step: 12
Training loss: 0.9610164165496826
Validation loss: 1.8557756677750619

Epoch: 6| Step: 13
Training loss: 1.6795190572738647
Validation loss: 1.8259535797180668

Epoch: 449| Step: 0
Training loss: 0.31448519229888916
Validation loss: 1.802938651013118

Epoch: 6| Step: 1
Training loss: 1.1948336362838745
Validation loss: 1.7889122629678378

Epoch: 6| Step: 2
Training loss: 0.6488091349601746
Validation loss: 1.8112792097112185

Epoch: 6| Step: 3
Training loss: 0.7329103946685791
Validation loss: 1.7912409933664466

Epoch: 6| Step: 4
Training loss: 0.9505250453948975
Validation loss: 1.7646118082025999

Epoch: 6| Step: 5
Training loss: 0.7914267778396606
Validation loss: 1.8350335244209535

Epoch: 6| Step: 6
Training loss: 1.2312017679214478
Validation loss: 1.8538094028349845

Epoch: 6| Step: 7
Training loss: 1.855391502380371
Validation loss: 1.849020911801246

Epoch: 6| Step: 8
Training loss: 0.6511297225952148
Validation loss: 1.7916614829853017

Epoch: 6| Step: 9
Training loss: 1.4763154983520508
Validation loss: 1.8343414747586815

Epoch: 6| Step: 10
Training loss: 0.9515533447265625
Validation loss: 1.8231718809373918

Epoch: 6| Step: 11
Training loss: 0.7828664779663086
Validation loss: 1.86400544258856

Epoch: 6| Step: 12
Training loss: 0.8251105546951294
Validation loss: 1.850142584052137

Epoch: 6| Step: 13
Training loss: 0.8455345630645752
Validation loss: 1.8375028974266463

Epoch: 450| Step: 0
Training loss: 1.145524263381958
Validation loss: 1.8201295509133288

Epoch: 6| Step: 1
Training loss: 0.5881227850914001
Validation loss: 1.8431284440461027

Epoch: 6| Step: 2
Training loss: 1.1510244607925415
Validation loss: 1.8554811772479807

Epoch: 6| Step: 3
Training loss: 0.3987298607826233
Validation loss: 1.7985055856807257

Epoch: 6| Step: 4
Training loss: 0.967965841293335
Validation loss: 1.8100025359020437

Epoch: 6| Step: 5
Training loss: 0.9577783346176147
Validation loss: 1.8043156746895082

Epoch: 6| Step: 6
Training loss: 0.8462224006652832
Validation loss: 1.8611139225703415

Epoch: 6| Step: 7
Training loss: 0.9665815830230713
Validation loss: 1.7917482135116414

Epoch: 6| Step: 8
Training loss: 1.1051819324493408
Validation loss: 1.8514695718724241

Epoch: 6| Step: 9
Training loss: 0.837135910987854
Validation loss: 1.8361868550700526

Epoch: 6| Step: 10
Training loss: 1.4494574069976807
Validation loss: 1.8194009655265397

Epoch: 6| Step: 11
Training loss: 0.9264469146728516
Validation loss: 1.8058399115839312

Epoch: 6| Step: 12
Training loss: 1.2083598375320435
Validation loss: 1.8167723481373121

Epoch: 6| Step: 13
Training loss: 1.2525744438171387
Validation loss: 1.849422021578717

Testing loss: 2.3815294080310396
