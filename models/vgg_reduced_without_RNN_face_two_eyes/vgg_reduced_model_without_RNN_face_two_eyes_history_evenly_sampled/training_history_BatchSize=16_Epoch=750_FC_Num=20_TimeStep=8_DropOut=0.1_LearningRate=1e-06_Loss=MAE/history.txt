Epoch: 1| Step: 0
Training loss: 3.8719472885131836
Validation loss: 3.836407458910378

Epoch: 6| Step: 1
Training loss: 3.933755874633789
Validation loss: 3.8312436739603677

Epoch: 6| Step: 2
Training loss: 4.379682540893555
Validation loss: 3.8288700862597396

Epoch: 6| Step: 3
Training loss: 4.403471946716309
Validation loss: 3.824496620444841

Epoch: 6| Step: 4
Training loss: 2.6218841075897217
Validation loss: 3.8201789702138593

Epoch: 6| Step: 5
Training loss: 3.5593855381011963
Validation loss: 3.8164517289848736

Epoch: 6| Step: 6
Training loss: 3.4601566791534424
Validation loss: 3.8137875936364614

Epoch: 6| Step: 7
Training loss: 3.8537111282348633
Validation loss: 3.808123311688823

Epoch: 6| Step: 8
Training loss: 3.5211610794067383
Validation loss: 3.804606745319982

Epoch: 6| Step: 9
Training loss: 3.093886375427246
Validation loss: 3.7998504023398123

Epoch: 6| Step: 10
Training loss: 4.6584014892578125
Validation loss: 3.795587093599381

Epoch: 6| Step: 11
Training loss: 3.085275411605835
Validation loss: 3.792770824124736

Epoch: 6| Step: 12
Training loss: 3.017836570739746
Validation loss: 3.788040563624392

Epoch: 6| Step: 13
Training loss: 4.76065731048584
Validation loss: 3.7882751393061813

Epoch: 2| Step: 0
Training loss: 3.531893730163574
Validation loss: 3.7810944203407533

Epoch: 6| Step: 1
Training loss: 3.0210084915161133
Validation loss: 3.7775837093271236

Epoch: 6| Step: 2
Training loss: 3.8558762073516846
Validation loss: 3.771438747323969

Epoch: 6| Step: 3
Training loss: 4.0533223152160645
Validation loss: 3.7701753236914195

Epoch: 6| Step: 4
Training loss: 3.091719388961792
Validation loss: 3.7648029660665863

Epoch: 6| Step: 5
Training loss: 4.038941383361816
Validation loss: 3.762299512022285

Epoch: 6| Step: 6
Training loss: 3.6954100131988525
Validation loss: 3.758604972593246

Epoch: 6| Step: 7
Training loss: 3.048532009124756
Validation loss: 3.7543641239084224

Epoch: 6| Step: 8
Training loss: 2.4978997707366943
Validation loss: 3.7504060601675384

Epoch: 6| Step: 9
Training loss: 4.589517116546631
Validation loss: 3.746102415105348

Epoch: 6| Step: 10
Training loss: 3.244361639022827
Validation loss: 3.7429385518514984

Epoch: 6| Step: 11
Training loss: 3.7622005939483643
Validation loss: 3.738675614838959

Epoch: 6| Step: 12
Training loss: 4.664855480194092
Validation loss: 3.7356089161288355

Epoch: 6| Step: 13
Training loss: 4.2364935874938965
Validation loss: 3.7313552748772407

Epoch: 3| Step: 0
Training loss: 2.643240451812744
Validation loss: 3.7305103886512017

Epoch: 6| Step: 1
Training loss: 4.151042461395264
Validation loss: 3.725985991057529

Epoch: 6| Step: 2
Training loss: 3.7900447845458984
Validation loss: 3.720994703231319

Epoch: 6| Step: 3
Training loss: 4.236178398132324
Validation loss: 3.717366621058474

Epoch: 6| Step: 4
Training loss: 3.7877449989318848
Validation loss: 3.7133534262257237

Epoch: 6| Step: 5
Training loss: 3.854668617248535
Validation loss: 3.7101788110630487

Epoch: 6| Step: 6
Training loss: 3.3665664196014404
Validation loss: 3.705855377258793

Epoch: 6| Step: 7
Training loss: 3.353362798690796
Validation loss: 3.7022705385761876

Epoch: 6| Step: 8
Training loss: 3.722618579864502
Validation loss: 3.6981143464324293

Epoch: 6| Step: 9
Training loss: 4.115752220153809
Validation loss: 3.69545211843265

Epoch: 6| Step: 10
Training loss: 4.3406877517700195
Validation loss: 3.689601098337481

Epoch: 6| Step: 11
Training loss: 3.520902633666992
Validation loss: 3.685839770942606

Epoch: 6| Step: 12
Training loss: 1.3062896728515625
Validation loss: 3.6824741260979765

Epoch: 6| Step: 13
Training loss: 4.793666362762451
Validation loss: 3.6776770981409217

Epoch: 4| Step: 0
Training loss: 2.6506760120391846
Validation loss: 3.675553870457475

Epoch: 6| Step: 1
Training loss: 2.57076358795166
Validation loss: 3.6716326282870386

Epoch: 6| Step: 2
Training loss: 3.0889511108398438
Validation loss: 3.667004664738973

Epoch: 6| Step: 3
Training loss: 4.326213836669922
Validation loss: 3.663958000880416

Epoch: 6| Step: 4
Training loss: 5.008605003356934
Validation loss: 3.6605390630742556

Epoch: 6| Step: 5
Training loss: 3.5136425495147705
Validation loss: 3.6545285717133553

Epoch: 6| Step: 6
Training loss: 3.493497371673584
Validation loss: 3.649357126605126

Epoch: 6| Step: 7
Training loss: 4.612688064575195
Validation loss: 3.6458271036865892

Epoch: 6| Step: 8
Training loss: 3.098311185836792
Validation loss: 3.641731495498329

Epoch: 6| Step: 9
Training loss: 3.757097005844116
Validation loss: 3.6401779677278254

Epoch: 6| Step: 10
Training loss: 3.340482711791992
Validation loss: 3.6327088622636694

Epoch: 6| Step: 11
Training loss: 2.709779977798462
Validation loss: 3.6286601712626796

Epoch: 6| Step: 12
Training loss: 3.897010326385498
Validation loss: 3.6257244310071393

Epoch: 6| Step: 13
Training loss: 3.8527157306671143
Validation loss: 3.6205878052660214

Epoch: 5| Step: 0
Training loss: 4.079477787017822
Validation loss: 3.6198971117696455

Epoch: 6| Step: 1
Training loss: 2.4734060764312744
Validation loss: 3.613438370407269

Epoch: 6| Step: 2
Training loss: 3.203812599182129
Validation loss: 3.6103145281473794

Epoch: 6| Step: 3
Training loss: 4.444033622741699
Validation loss: 3.604630793294599

Epoch: 6| Step: 4
Training loss: 3.1223158836364746
Validation loss: 3.601115221618324

Epoch: 6| Step: 5
Training loss: 3.149477958679199
Validation loss: 3.5963012069784184

Epoch: 6| Step: 6
Training loss: 4.173786163330078
Validation loss: 3.592332340055896

Epoch: 6| Step: 7
Training loss: 2.6390228271484375
Validation loss: 3.5860315625385573

Epoch: 6| Step: 8
Training loss: 4.13031005859375
Validation loss: 3.5833925944502636

Epoch: 6| Step: 9
Training loss: 4.01965856552124
Validation loss: 3.580672840918264

Epoch: 6| Step: 10
Training loss: 3.0989813804626465
Validation loss: 3.57372703859883

Epoch: 6| Step: 11
Training loss: 3.332507610321045
Validation loss: 3.5710686740054878

Epoch: 6| Step: 12
Training loss: 3.4357411861419678
Validation loss: 3.5665944314772084

Epoch: 6| Step: 13
Training loss: 3.984097480773926
Validation loss: 3.561639796021164

Epoch: 6| Step: 0
Training loss: 3.282116174697876
Validation loss: 3.553371321770453

Epoch: 6| Step: 1
Training loss: 4.850841999053955
Validation loss: 3.5512839235285276

Epoch: 6| Step: 2
Training loss: 2.813476085662842
Validation loss: 3.5438123569693616

Epoch: 6| Step: 3
Training loss: 3.8061509132385254
Validation loss: 3.540338134252897

Epoch: 6| Step: 4
Training loss: 3.1932201385498047
Validation loss: 3.5369202449757564

Epoch: 6| Step: 5
Training loss: 3.108734130859375
Validation loss: 3.529875450236823

Epoch: 6| Step: 6
Training loss: 3.1476407051086426
Validation loss: 3.5255192120869956

Epoch: 6| Step: 7
Training loss: 3.4517664909362793
Validation loss: 3.5214737512732066

Epoch: 6| Step: 8
Training loss: 3.201091766357422
Validation loss: 3.51898834782262

Epoch: 6| Step: 9
Training loss: 3.6953983306884766
Validation loss: 3.5108851361018356

Epoch: 6| Step: 10
Training loss: 3.2930479049682617
Validation loss: 3.506970677324521

Epoch: 6| Step: 11
Training loss: 2.840639591217041
Validation loss: 3.4987727031912854

Epoch: 6| Step: 12
Training loss: 3.5580105781555176
Validation loss: 3.4948434240074566

Epoch: 6| Step: 13
Training loss: 4.47464656829834
Validation loss: 3.491379899363364

Epoch: 7| Step: 0
Training loss: 3.3340301513671875
Validation loss: 3.4815628426049345

Epoch: 6| Step: 1
Training loss: 3.606210708618164
Validation loss: 3.4762238481993317

Epoch: 6| Step: 2
Training loss: 2.3716933727264404
Validation loss: 3.4713962155003704

Epoch: 6| Step: 3
Training loss: 3.774533748626709
Validation loss: 3.4653973297406266

Epoch: 6| Step: 4
Training loss: 3.290811777114868
Validation loss: 3.459729956042382

Epoch: 6| Step: 5
Training loss: 3.0451841354370117
Validation loss: 3.454002498298563

Epoch: 6| Step: 6
Training loss: 3.5149974822998047
Validation loss: 3.447719443228937

Epoch: 6| Step: 7
Training loss: 3.984978675842285
Validation loss: 3.4421301323880433

Epoch: 6| Step: 8
Training loss: 4.193278789520264
Validation loss: 3.4356544684338313

Epoch: 6| Step: 9
Training loss: 3.8315296173095703
Validation loss: 3.4288410576440955

Epoch: 6| Step: 10
Training loss: 2.5996432304382324
Validation loss: 3.422616840690695

Epoch: 6| Step: 11
Training loss: 3.1524176597595215
Validation loss: 3.4153851847494803

Epoch: 6| Step: 12
Training loss: 3.283250331878662
Validation loss: 3.4071485304063365

Epoch: 6| Step: 13
Training loss: 3.2651309967041016
Validation loss: 3.4025328928424465

Epoch: 8| Step: 0
Training loss: 2.934704303741455
Validation loss: 3.3955617104807208

Epoch: 6| Step: 1
Training loss: 2.6534433364868164
Validation loss: 3.3887043511995705

Epoch: 6| Step: 2
Training loss: 4.223526954650879
Validation loss: 3.3795759447159304

Epoch: 6| Step: 3
Training loss: 3.247775077819824
Validation loss: 3.374374733176283

Epoch: 6| Step: 4
Training loss: 3.581137180328369
Validation loss: 3.3689337366370746

Epoch: 6| Step: 5
Training loss: 3.3839125633239746
Validation loss: 3.356357861590642

Epoch: 6| Step: 6
Training loss: 3.8165740966796875
Validation loss: 3.3504829278556247

Epoch: 6| Step: 7
Training loss: 3.3407349586486816
Validation loss: 3.3450031075426327

Epoch: 6| Step: 8
Training loss: 3.174821615219116
Validation loss: 3.3371891257583455

Epoch: 6| Step: 9
Training loss: 2.7968974113464355
Validation loss: 3.32854103272961

Epoch: 6| Step: 10
Training loss: 3.980837821960449
Validation loss: 3.321658375442669

Epoch: 6| Step: 11
Training loss: 3.1419951915740967
Validation loss: 3.315027683011947

Epoch: 6| Step: 12
Training loss: 2.5843894481658936
Validation loss: 3.308300989930348

Epoch: 6| Step: 13
Training loss: 3.3953053951263428
Validation loss: 3.299077364706224

Epoch: 9| Step: 0
Training loss: 3.2733850479125977
Validation loss: 3.2915842225474696

Epoch: 6| Step: 1
Training loss: 3.074892997741699
Validation loss: 3.2846186263586885

Epoch: 6| Step: 2
Training loss: 3.264937162399292
Validation loss: 3.2797008996368735

Epoch: 6| Step: 3
Training loss: 3.0200300216674805
Validation loss: 3.27232958937204

Epoch: 6| Step: 4
Training loss: 3.842458724975586
Validation loss: 3.2648407310567875

Epoch: 6| Step: 5
Training loss: 2.8456077575683594
Validation loss: 3.2542226314544678

Epoch: 6| Step: 6
Training loss: 3.442049026489258
Validation loss: 3.2442697248151227

Epoch: 6| Step: 7
Training loss: 2.4578189849853516
Validation loss: 3.241619474144392

Epoch: 6| Step: 8
Training loss: 3.0922327041625977
Validation loss: 3.23427092131748

Epoch: 6| Step: 9
Training loss: 2.3782260417938232
Validation loss: 3.2224456699945594

Epoch: 6| Step: 10
Training loss: 3.0268311500549316
Validation loss: 3.215769047378212

Epoch: 6| Step: 11
Training loss: 3.5953621864318848
Validation loss: 3.2086390295336322

Epoch: 6| Step: 12
Training loss: 4.074480056762695
Validation loss: 3.201450281245734

Epoch: 6| Step: 13
Training loss: 3.832432746887207
Validation loss: 3.1882666003319526

Epoch: 10| Step: 0
Training loss: 3.1531982421875
Validation loss: 3.182362848712552

Epoch: 6| Step: 1
Training loss: 3.280912399291992
Validation loss: 3.1730833053588867

Epoch: 6| Step: 2
Training loss: 2.8819990158081055
Validation loss: 3.1645405882148334

Epoch: 6| Step: 3
Training loss: 2.5660128593444824
Validation loss: 3.1534294236090874

Epoch: 6| Step: 4
Training loss: 2.2950496673583984
Validation loss: 3.1491748004831295

Epoch: 6| Step: 5
Training loss: 4.013137340545654
Validation loss: 3.1376923899496756

Epoch: 6| Step: 6
Training loss: 3.156773567199707
Validation loss: 3.1283064375641527

Epoch: 6| Step: 7
Training loss: 2.5717287063598633
Validation loss: 3.119575592779344

Epoch: 6| Step: 8
Training loss: 3.4026856422424316
Validation loss: 3.1113978919162544

Epoch: 6| Step: 9
Training loss: 3.2229270935058594
Validation loss: 3.1042293758802515

Epoch: 6| Step: 10
Training loss: 2.8781661987304688
Validation loss: 3.094696214122157

Epoch: 6| Step: 11
Training loss: 2.9522180557250977
Validation loss: 3.090038038069202

Epoch: 6| Step: 12
Training loss: 4.498259544372559
Validation loss: 3.076193622363511

Epoch: 6| Step: 13
Training loss: 2.5457539558410645
Validation loss: 3.0695617891127065

Epoch: 11| Step: 0
Training loss: 2.7717576026916504
Validation loss: 3.0610173568930676

Epoch: 6| Step: 1
Training loss: 3.071502685546875
Validation loss: 3.0508091116464264

Epoch: 6| Step: 2
Training loss: 3.6287717819213867
Validation loss: 3.0383975659647295

Epoch: 6| Step: 3
Training loss: 2.6741621494293213
Validation loss: 3.029913548500307

Epoch: 6| Step: 4
Training loss: 2.3545761108398438
Validation loss: 3.0212821473357496

Epoch: 6| Step: 5
Training loss: 3.009202003479004
Validation loss: 3.0125446191398044

Epoch: 6| Step: 6
Training loss: 2.5704028606414795
Validation loss: 3.002167965776177

Epoch: 6| Step: 7
Training loss: 4.328144550323486
Validation loss: 2.9917681447921263

Epoch: 6| Step: 8
Training loss: 3.184182643890381
Validation loss: 2.9815668572661695

Epoch: 6| Step: 9
Training loss: 2.890216827392578
Validation loss: 2.9748395745472243

Epoch: 6| Step: 10
Training loss: 2.6577696800231934
Validation loss: 2.966600330927039

Epoch: 6| Step: 11
Training loss: 3.6203103065490723
Validation loss: 2.9561181581148537

Epoch: 6| Step: 12
Training loss: 2.55881929397583
Validation loss: 2.9465383714245212

Epoch: 6| Step: 13
Training loss: 3.1892292499542236
Validation loss: 2.940595021811865

Epoch: 12| Step: 0
Training loss: 3.631603717803955
Validation loss: 2.9290244297314714

Epoch: 6| Step: 1
Training loss: 2.9878642559051514
Validation loss: 2.9192018124365036

Epoch: 6| Step: 2
Training loss: 3.153191566467285
Validation loss: 2.906522153526224

Epoch: 6| Step: 3
Training loss: 2.9420833587646484
Validation loss: 2.8954116708488873

Epoch: 6| Step: 4
Training loss: 3.4685230255126953
Validation loss: 2.887121254397977

Epoch: 6| Step: 5
Training loss: 2.661719799041748
Validation loss: 2.8754799622361378

Epoch: 6| Step: 6
Training loss: 3.4873015880584717
Validation loss: 2.8662382172000025

Epoch: 6| Step: 7
Training loss: 2.642282724380493
Validation loss: 2.8490001181120514

Epoch: 6| Step: 8
Training loss: 2.364643096923828
Validation loss: 2.839691928637925

Epoch: 6| Step: 9
Training loss: 2.293646812438965
Validation loss: 2.829420156376336

Epoch: 6| Step: 10
Training loss: 3.3428754806518555
Validation loss: 2.822850852884272

Epoch: 6| Step: 11
Training loss: 2.830550193786621
Validation loss: 2.81262864605073

Epoch: 6| Step: 12
Training loss: 2.3824920654296875
Validation loss: 2.8063615675895446

Epoch: 6| Step: 13
Training loss: 2.9877917766571045
Validation loss: 2.796262594961351

Epoch: 13| Step: 0
Training loss: 2.5077297687530518
Validation loss: 2.7859577081536733

Epoch: 6| Step: 1
Training loss: 3.71860933303833
Validation loss: 2.77450849933009

Epoch: 6| Step: 2
Training loss: 3.9230597019195557
Validation loss: 2.7660599190701722

Epoch: 6| Step: 3
Training loss: 2.6897454261779785
Validation loss: 2.7639574799486386

Epoch: 6| Step: 4
Training loss: 3.081695556640625
Validation loss: 2.7433032015318513

Epoch: 6| Step: 5
Training loss: 2.876591205596924
Validation loss: 2.7353865920856433

Epoch: 6| Step: 6
Training loss: 1.7503421306610107
Validation loss: 2.722837145610522

Epoch: 6| Step: 7
Training loss: 3.7704882621765137
Validation loss: 2.7137059806495585

Epoch: 6| Step: 8
Training loss: 3.210158348083496
Validation loss: 2.70546390164283

Epoch: 6| Step: 9
Training loss: 2.43829345703125
Validation loss: 2.6940924916216122

Epoch: 6| Step: 10
Training loss: 2.4979608058929443
Validation loss: 2.6761682623176166

Epoch: 6| Step: 11
Training loss: 2.422611951828003
Validation loss: 2.6695707844149683

Epoch: 6| Step: 12
Training loss: 2.5698766708374023
Validation loss: 2.65117988535153

Epoch: 6| Step: 13
Training loss: 2.28660249710083
Validation loss: 2.6482899035176923

Epoch: 14| Step: 0
Training loss: 2.2135720252990723
Validation loss: 2.6392402982199066

Epoch: 6| Step: 1
Training loss: 3.140011787414551
Validation loss: 2.630130242275935

Epoch: 6| Step: 2
Training loss: 2.4571735858917236
Validation loss: 2.62294186827957

Epoch: 6| Step: 3
Training loss: 2.8050761222839355
Validation loss: 2.6109032297647126

Epoch: 6| Step: 4
Training loss: 3.086916923522949
Validation loss: 2.6011108941929315

Epoch: 6| Step: 5
Training loss: 3.280626058578491
Validation loss: 2.5916033406411447

Epoch: 6| Step: 6
Training loss: 3.2829885482788086
Validation loss: 2.576573469305551

Epoch: 6| Step: 7
Training loss: 3.3132388591766357
Validation loss: 2.562670958939419

Epoch: 6| Step: 8
Training loss: 2.396825075149536
Validation loss: 2.551536557494953

Epoch: 6| Step: 9
Training loss: 2.573159694671631
Validation loss: 2.546619712665517

Epoch: 6| Step: 10
Training loss: 2.705685615539551
Validation loss: 2.5362604356581167

Epoch: 6| Step: 11
Training loss: 2.143054485321045
Validation loss: 2.5245896744471725

Epoch: 6| Step: 12
Training loss: 2.457237720489502
Validation loss: 2.517004648844401

Epoch: 6| Step: 13
Training loss: 2.893275022506714
Validation loss: 2.5060772690721738

Epoch: 15| Step: 0
Training loss: 3.152812957763672
Validation loss: 2.4991558982479956

Epoch: 6| Step: 1
Training loss: 1.1881744861602783
Validation loss: 2.490442019636913

Epoch: 6| Step: 2
Training loss: 2.67525315284729
Validation loss: 2.4755711299116894

Epoch: 6| Step: 3
Training loss: 3.4481043815612793
Validation loss: 2.4670582791810394

Epoch: 6| Step: 4
Training loss: 3.088247299194336
Validation loss: 2.462202510526103

Epoch: 6| Step: 5
Training loss: 2.7647435665130615
Validation loss: 2.4495805002027944

Epoch: 6| Step: 6
Training loss: 2.731335163116455
Validation loss: 2.442473952488233

Epoch: 6| Step: 7
Training loss: 2.815408229827881
Validation loss: 2.4365165900158625

Epoch: 6| Step: 8
Training loss: 2.6862189769744873
Validation loss: 2.427058830056139

Epoch: 6| Step: 9
Training loss: 2.28341007232666
Validation loss: 2.411478191293696

Epoch: 6| Step: 10
Training loss: 3.4419217109680176
Validation loss: 2.403861850820562

Epoch: 6| Step: 11
Training loss: 2.3352255821228027
Validation loss: 2.39495365465841

Epoch: 6| Step: 12
Training loss: 1.7202914953231812
Validation loss: 2.3897694900471675

Epoch: 6| Step: 13
Training loss: 3.2887754440307617
Validation loss: 2.371250339733657

Epoch: 16| Step: 0
Training loss: 2.6027989387512207
Validation loss: 2.371377193799583

Epoch: 6| Step: 1
Training loss: 2.716024160385132
Validation loss: 2.3502221004937285

Epoch: 6| Step: 2
Training loss: 2.1548657417297363
Validation loss: 2.348663135241437

Epoch: 6| Step: 3
Training loss: 2.501554489135742
Validation loss: 2.330667431636523

Epoch: 6| Step: 4
Training loss: 2.235236644744873
Validation loss: 2.316250951059403

Epoch: 6| Step: 5
Training loss: 3.0796256065368652
Validation loss: 2.3085605226537234

Epoch: 6| Step: 6
Training loss: 2.7030324935913086
Validation loss: 2.2993161857769056

Epoch: 6| Step: 7
Training loss: 2.2429754734039307
Validation loss: 2.2919310164707962

Epoch: 6| Step: 8
Training loss: 2.120929718017578
Validation loss: 2.2768292580881426

Epoch: 6| Step: 9
Training loss: 3.0424230098724365
Validation loss: 2.268676011793075

Epoch: 6| Step: 10
Training loss: 3.2217235565185547
Validation loss: 2.26507705514149

Epoch: 6| Step: 11
Training loss: 2.866940975189209
Validation loss: 2.2474500261327273

Epoch: 6| Step: 12
Training loss: 2.2137503623962402
Validation loss: 2.2461959290248092

Epoch: 6| Step: 13
Training loss: 2.4448728561401367
Validation loss: 2.2398845931535125

Epoch: 17| Step: 0
Training loss: 1.8354219198226929
Validation loss: 2.2356725123620804

Epoch: 6| Step: 1
Training loss: 2.148381233215332
Validation loss: 2.227299124963822

Epoch: 6| Step: 2
Training loss: 2.5341591835021973
Validation loss: 2.2118690821432296

Epoch: 6| Step: 3
Training loss: 2.3626890182495117
Validation loss: 2.210888680591378

Epoch: 6| Step: 4
Training loss: 2.5891306400299072
Validation loss: 2.197152699193647

Epoch: 6| Step: 5
Training loss: 2.1590828895568848
Validation loss: 2.2048363147243375

Epoch: 6| Step: 6
Training loss: 3.119417667388916
Validation loss: 2.191836744226435

Epoch: 6| Step: 7
Training loss: 1.8918999433517456
Validation loss: 2.1979034459719093

Epoch: 6| Step: 8
Training loss: 3.292560577392578
Validation loss: 2.181857652561639

Epoch: 6| Step: 9
Training loss: 2.2429356575012207
Validation loss: 2.187009475564444

Epoch: 6| Step: 10
Training loss: 3.721708059310913
Validation loss: 2.1818825173121628

Epoch: 6| Step: 11
Training loss: 2.6031689643859863
Validation loss: 2.1726936063458844

Epoch: 6| Step: 12
Training loss: 2.100767135620117
Validation loss: 2.1802142922596266

Epoch: 6| Step: 13
Training loss: 2.308835029602051
Validation loss: 2.1575622827776018

Epoch: 18| Step: 0
Training loss: 2.359328269958496
Validation loss: 2.1642643456817954

Epoch: 6| Step: 1
Training loss: 2.061115264892578
Validation loss: 2.1526189696404243

Epoch: 6| Step: 2
Training loss: 2.5353238582611084
Validation loss: 2.143642043554655

Epoch: 6| Step: 3
Training loss: 2.6674327850341797
Validation loss: 2.139829367719671

Epoch: 6| Step: 4
Training loss: 2.8966455459594727
Validation loss: 2.1312603976136897

Epoch: 6| Step: 5
Training loss: 2.913980484008789
Validation loss: 2.1272573355705506

Epoch: 6| Step: 6
Training loss: 2.4327073097229004
Validation loss: 2.1219502366999143

Epoch: 6| Step: 7
Training loss: 2.1428189277648926
Validation loss: 2.1275511057146135

Epoch: 6| Step: 8
Training loss: 2.2854113578796387
Validation loss: 2.104733177410659

Epoch: 6| Step: 9
Training loss: 2.170095443725586
Validation loss: 2.112350079321092

Epoch: 6| Step: 10
Training loss: 2.379415512084961
Validation loss: 2.109047105235438

Epoch: 6| Step: 11
Training loss: 2.7804789543151855
Validation loss: 2.089779007819391

Epoch: 6| Step: 12
Training loss: 2.2703030109405518
Validation loss: 2.1000083441375406

Epoch: 6| Step: 13
Training loss: 2.6034419536590576
Validation loss: 2.089322449058615

Epoch: 19| Step: 0
Training loss: 2.4035918712615967
Validation loss: 2.088078841086357

Epoch: 6| Step: 1
Training loss: 3.359389305114746
Validation loss: 2.090179649732446

Epoch: 6| Step: 2
Training loss: 2.3598835468292236
Validation loss: 2.0754939740703953

Epoch: 6| Step: 3
Training loss: 2.2146105766296387
Validation loss: 2.078529028482335

Epoch: 6| Step: 4
Training loss: 2.2804763317108154
Validation loss: 2.080255214885999

Epoch: 6| Step: 5
Training loss: 1.9841086864471436
Validation loss: 2.0698632283877303

Epoch: 6| Step: 6
Training loss: 2.4525325298309326
Validation loss: 2.0663316942030385

Epoch: 6| Step: 7
Training loss: 2.2518177032470703
Validation loss: 2.068975205062538

Epoch: 6| Step: 8
Training loss: 1.9566463232040405
Validation loss: 2.0632977024201424

Epoch: 6| Step: 9
Training loss: 2.9705803394317627
Validation loss: 2.065604889264671

Epoch: 6| Step: 10
Training loss: 3.0304598808288574
Validation loss: 2.068368375942271

Epoch: 6| Step: 11
Training loss: 2.1957342624664307
Validation loss: 2.0607327453551756

Epoch: 6| Step: 12
Training loss: 2.4710910320281982
Validation loss: 2.0510454588038947

Epoch: 6| Step: 13
Training loss: 1.9386190176010132
Validation loss: 2.057878727553993

Epoch: 20| Step: 0
Training loss: 2.4555816650390625
Validation loss: 2.051095701033069

Epoch: 6| Step: 1
Training loss: 2.642704725265503
Validation loss: 2.0435019411066526

Epoch: 6| Step: 2
Training loss: 2.0637354850769043
Validation loss: 2.0525791363049577

Epoch: 6| Step: 3
Training loss: 2.137885808944702
Validation loss: 2.0385308983505412

Epoch: 6| Step: 4
Training loss: 1.962667465209961
Validation loss: 2.04822346087425

Epoch: 6| Step: 5
Training loss: 2.843888521194458
Validation loss: 2.0449842791403494

Epoch: 6| Step: 6
Training loss: 2.808375358581543
Validation loss: 2.0385330082267843

Epoch: 6| Step: 7
Training loss: 2.311013698577881
Validation loss: 2.025626959339265

Epoch: 6| Step: 8
Training loss: 2.908665418624878
Validation loss: 2.0410217533829393

Epoch: 6| Step: 9
Training loss: 1.952651858329773
Validation loss: 2.0424595955879457

Epoch: 6| Step: 10
Training loss: 2.7224273681640625
Validation loss: 2.03001675041773

Epoch: 6| Step: 11
Training loss: 2.4129767417907715
Validation loss: 2.0317076380534838

Epoch: 6| Step: 12
Training loss: 2.278468608856201
Validation loss: 2.0309965431049304

Epoch: 6| Step: 13
Training loss: 2.034796714782715
Validation loss: 2.0272738625926356

Epoch: 21| Step: 0
Training loss: 2.4561703205108643
Validation loss: 2.015283489740023

Epoch: 6| Step: 1
Training loss: 2.6466681957244873
Validation loss: 2.0294539261889715

Epoch: 6| Step: 2
Training loss: 2.351118803024292
Validation loss: 2.0279253810964604

Epoch: 6| Step: 3
Training loss: 2.325808525085449
Validation loss: 2.0168878339952037

Epoch: 6| Step: 4
Training loss: 2.4145283699035645
Validation loss: 2.0216680111423617

Epoch: 6| Step: 5
Training loss: 2.825366973876953
Validation loss: 2.0146517035781697

Epoch: 6| Step: 6
Training loss: 1.959761142730713
Validation loss: 2.0256077063980924

Epoch: 6| Step: 7
Training loss: 2.6127865314483643
Validation loss: 2.0113314992638043

Epoch: 6| Step: 8
Training loss: 2.511481761932373
Validation loss: 2.019847734000093

Epoch: 6| Step: 9
Training loss: 2.316911220550537
Validation loss: 2.011928468622187

Epoch: 6| Step: 10
Training loss: 2.1566054821014404
Validation loss: 2.02167905786986

Epoch: 6| Step: 11
Training loss: 2.7367734909057617
Validation loss: 2.0220812866764684

Epoch: 6| Step: 12
Training loss: 1.729196548461914
Validation loss: 2.016786713753977

Epoch: 6| Step: 13
Training loss: 2.57637619972229
Validation loss: 2.008551443776777

Epoch: 22| Step: 0
Training loss: 2.4860761165618896
Validation loss: 2.0156605000137002

Epoch: 6| Step: 1
Training loss: 2.2224209308624268
Validation loss: 2.00918447971344

Epoch: 6| Step: 2
Training loss: 2.8565917015075684
Validation loss: 2.007914686715731

Epoch: 6| Step: 3
Training loss: 2.8475823402404785
Validation loss: 2.002367716963573

Epoch: 6| Step: 4
Training loss: 2.9215357303619385
Validation loss: 2.0040214125828077

Epoch: 6| Step: 5
Training loss: 1.8420424461364746
Validation loss: 2.010249199405793

Epoch: 6| Step: 6
Training loss: 2.222376823425293
Validation loss: 2.0051940410367903

Epoch: 6| Step: 7
Training loss: 2.7880544662475586
Validation loss: 2.005846897761027

Epoch: 6| Step: 8
Training loss: 2.1928133964538574
Validation loss: 2.0010473061633367

Epoch: 6| Step: 9
Training loss: 1.854200839996338
Validation loss: 1.9924538673893097

Epoch: 6| Step: 10
Training loss: 3.138848066329956
Validation loss: 2.0030150695513655

Epoch: 6| Step: 11
Training loss: 1.3801696300506592
Validation loss: 2.0065856390101935

Epoch: 6| Step: 12
Training loss: 2.265258312225342
Validation loss: 2.013644908064155

Epoch: 6| Step: 13
Training loss: 2.3055920600891113
Validation loss: 2.0100826409555252

Epoch: 23| Step: 0
Training loss: 2.394927501678467
Validation loss: 1.9959248189003236

Epoch: 6| Step: 1
Training loss: 2.1187353134155273
Validation loss: 1.9967659417019095

Epoch: 6| Step: 2
Training loss: 2.45042085647583
Validation loss: 1.995322262087176

Epoch: 6| Step: 3
Training loss: 2.507887363433838
Validation loss: 1.9977464240084413

Epoch: 6| Step: 4
Training loss: 2.870915174484253
Validation loss: 2.0035778437891314

Epoch: 6| Step: 5
Training loss: 2.4436349868774414
Validation loss: 2.0041479103026854

Epoch: 6| Step: 6
Training loss: 2.0780892372131348
Validation loss: 1.9998964507092711

Epoch: 6| Step: 7
Training loss: 1.9332865476608276
Validation loss: 2.001464528422202

Epoch: 6| Step: 8
Training loss: 2.955108404159546
Validation loss: 1.9974782338706396

Epoch: 6| Step: 9
Training loss: 1.9866619110107422
Validation loss: 2.0007488471205517

Epoch: 6| Step: 10
Training loss: 1.7520201206207275
Validation loss: 2.003834036088759

Epoch: 6| Step: 11
Training loss: 2.236119031906128
Validation loss: 2.0035673354261663

Epoch: 6| Step: 12
Training loss: 2.5132060050964355
Validation loss: 2.006463590488639

Epoch: 6| Step: 13
Training loss: 3.5086076259613037
Validation loss: 2.0026432352681316

Epoch: 24| Step: 0
Training loss: 2.365135908126831
Validation loss: 2.0114152739124913

Epoch: 6| Step: 1
Training loss: 2.180150032043457
Validation loss: 2.003152544780444

Epoch: 6| Step: 2
Training loss: 2.678973436355591
Validation loss: 2.0083268906480525

Epoch: 6| Step: 3
Training loss: 2.603389024734497
Validation loss: 1.9920063121344453

Epoch: 6| Step: 4
Training loss: 2.9036691188812256
Validation loss: 1.9906850027781662

Epoch: 6| Step: 5
Training loss: 1.6717407703399658
Validation loss: 1.9982748544344338

Epoch: 6| Step: 6
Training loss: 2.477783203125
Validation loss: 2.008402109146118

Epoch: 6| Step: 7
Training loss: 2.202702045440674
Validation loss: 2.001237054024973

Epoch: 6| Step: 8
Training loss: 2.770371437072754
Validation loss: 2.005815718763618

Epoch: 6| Step: 9
Training loss: 2.277050495147705
Validation loss: 1.9894987588287683

Epoch: 6| Step: 10
Training loss: 2.3009285926818848
Validation loss: 2.0037594533735708

Epoch: 6| Step: 11
Training loss: 2.244781494140625
Validation loss: 1.9948337462640577

Epoch: 6| Step: 12
Training loss: 2.3991012573242188
Validation loss: 2.0001696796827417

Epoch: 6| Step: 13
Training loss: 1.791990041732788
Validation loss: 2.002137707125756

Epoch: 25| Step: 0
Training loss: 2.4435911178588867
Validation loss: 1.9963062911905267

Epoch: 6| Step: 1
Training loss: 2.492461919784546
Validation loss: 2.013117362094182

Epoch: 6| Step: 2
Training loss: 2.352571964263916
Validation loss: 1.9928201808724353

Epoch: 6| Step: 3
Training loss: 2.7413864135742188
Validation loss: 1.994104778894814

Epoch: 6| Step: 4
Training loss: 1.876554012298584
Validation loss: 2.0074999473428212

Epoch: 6| Step: 5
Training loss: 2.214252471923828
Validation loss: 1.9984524044939267

Epoch: 6| Step: 6
Training loss: 2.6040070056915283
Validation loss: 1.9939521410131966

Epoch: 6| Step: 7
Training loss: 2.598598003387451
Validation loss: 1.9916355763712237

Epoch: 6| Step: 8
Training loss: 1.8376235961914062
Validation loss: 2.0075646779870473

Epoch: 6| Step: 9
Training loss: 2.209751605987549
Validation loss: 2.0044151301025064

Epoch: 6| Step: 10
Training loss: 2.5686588287353516
Validation loss: 2.0005912908943753

Epoch: 6| Step: 11
Training loss: 2.150592803955078
Validation loss: 1.995137894025413

Epoch: 6| Step: 12
Training loss: 2.217766284942627
Validation loss: 1.9955130956506217

Epoch: 6| Step: 13
Training loss: 3.0565714836120605
Validation loss: 1.9997267030900525

Epoch: 26| Step: 0
Training loss: 2.201608657836914
Validation loss: 1.9998100778108001

Epoch: 6| Step: 1
Training loss: 2.2087655067443848
Validation loss: 1.994189227780988

Epoch: 6| Step: 2
Training loss: 2.6262638568878174
Validation loss: 1.9971118947511077

Epoch: 6| Step: 3
Training loss: 2.5356009006500244
Validation loss: 1.9899752293863604

Epoch: 6| Step: 4
Training loss: 1.679630994796753
Validation loss: 1.9950495663509573

Epoch: 6| Step: 5
Training loss: 2.3844664096832275
Validation loss: 1.9796529764770179

Epoch: 6| Step: 6
Training loss: 2.199936628341675
Validation loss: 1.9937698302730438

Epoch: 6| Step: 7
Training loss: 3.0279171466827393
Validation loss: 1.993334647147886

Epoch: 6| Step: 8
Training loss: 2.2560172080993652
Validation loss: 1.9759721499617382

Epoch: 6| Step: 9
Training loss: 2.231672763824463
Validation loss: 1.9879305362701416

Epoch: 6| Step: 10
Training loss: 2.4663474559783936
Validation loss: 1.9883526961008708

Epoch: 6| Step: 11
Training loss: 1.8284120559692383
Validation loss: 2.007552040520535

Epoch: 6| Step: 12
Training loss: 2.668403148651123
Validation loss: 1.990341696687924

Epoch: 6| Step: 13
Training loss: 2.9603850841522217
Validation loss: 1.9944976914313532

Epoch: 27| Step: 0
Training loss: 2.1803269386291504
Validation loss: 1.9939212734981249

Epoch: 6| Step: 1
Training loss: 2.6240742206573486
Validation loss: 2.002512744677964

Epoch: 6| Step: 2
Training loss: 2.317343235015869
Validation loss: 1.9870634335343555

Epoch: 6| Step: 3
Training loss: 2.396329641342163
Validation loss: 1.991969839219124

Epoch: 6| Step: 4
Training loss: 1.7278199195861816
Validation loss: 1.996931004267867

Epoch: 6| Step: 5
Training loss: 1.8538167476654053
Validation loss: 1.9958695750082693

Epoch: 6| Step: 6
Training loss: 2.381377696990967
Validation loss: 1.9935259190938805

Epoch: 6| Step: 7
Training loss: 2.6632637977600098
Validation loss: 2.0088094319066694

Epoch: 6| Step: 8
Training loss: 2.757160186767578
Validation loss: 1.9963872740345616

Epoch: 6| Step: 9
Training loss: 2.4060258865356445
Validation loss: 2.0041563780077043

Epoch: 6| Step: 10
Training loss: 2.4681806564331055
Validation loss: 1.9927326966357488

Epoch: 6| Step: 11
Training loss: 2.504425048828125
Validation loss: 1.9870533648357596

Epoch: 6| Step: 12
Training loss: 2.1483964920043945
Validation loss: 1.9872724138280398

Epoch: 6| Step: 13
Training loss: 2.4468343257904053
Validation loss: 1.999027625206978

Epoch: 28| Step: 0
Training loss: 2.8254823684692383
Validation loss: 2.008273042658324

Epoch: 6| Step: 1
Training loss: 2.0826568603515625
Validation loss: 1.9980140475816623

Epoch: 6| Step: 2
Training loss: 2.685032844543457
Validation loss: 1.997254451115926

Epoch: 6| Step: 3
Training loss: 2.837883234024048
Validation loss: 1.998792694460961

Epoch: 6| Step: 4
Training loss: 2.1708507537841797
Validation loss: 2.013663257322004

Epoch: 6| Step: 5
Training loss: 2.555294990539551
Validation loss: 2.0055948970138386

Epoch: 6| Step: 6
Training loss: 1.9503555297851562
Validation loss: 2.0042548500081545

Epoch: 6| Step: 7
Training loss: 2.2100043296813965
Validation loss: 1.9966407847660843

Epoch: 6| Step: 8
Training loss: 1.722818374633789
Validation loss: 1.9968247208544003

Epoch: 6| Step: 9
Training loss: 2.317150115966797
Validation loss: 1.9864555892123972

Epoch: 6| Step: 10
Training loss: 1.9426960945129395
Validation loss: 1.9961826262935516

Epoch: 6| Step: 11
Training loss: 2.644286632537842
Validation loss: 2.009778586767053

Epoch: 6| Step: 12
Training loss: 2.203892946243286
Validation loss: 2.0001890813150713

Epoch: 6| Step: 13
Training loss: 2.951230049133301
Validation loss: 2.00967159066149

Epoch: 29| Step: 0
Training loss: 2.1716129779815674
Validation loss: 2.002514241844095

Epoch: 6| Step: 1
Training loss: 2.462733745574951
Validation loss: 1.9988931391828804

Epoch: 6| Step: 2
Training loss: 2.6481387615203857
Validation loss: 1.9960735126208233

Epoch: 6| Step: 3
Training loss: 2.47507381439209
Validation loss: 1.9898870952667729

Epoch: 6| Step: 4
Training loss: 2.2135190963745117
Validation loss: 1.996686566260553

Epoch: 6| Step: 5
Training loss: 2.3700156211853027
Validation loss: 1.9946040504722184

Epoch: 6| Step: 6
Training loss: 2.507668972015381
Validation loss: 2.003144535967099

Epoch: 6| Step: 7
Training loss: 1.8627514839172363
Validation loss: 1.9967797212703253

Epoch: 6| Step: 8
Training loss: 2.31178617477417
Validation loss: 2.014803468540151

Epoch: 6| Step: 9
Training loss: 2.334289073944092
Validation loss: 2.005624509626819

Epoch: 6| Step: 10
Training loss: 2.132344961166382
Validation loss: 1.999264827338598

Epoch: 6| Step: 11
Training loss: 2.298966407775879
Validation loss: 1.9926280577977498

Epoch: 6| Step: 12
Training loss: 2.6669394969940186
Validation loss: 2.008128371289981

Epoch: 6| Step: 13
Training loss: 2.199022054672241
Validation loss: 1.994653614618445

Epoch: 30| Step: 0
Training loss: 2.947807788848877
Validation loss: 2.0131441341933383

Epoch: 6| Step: 1
Training loss: 2.311659097671509
Validation loss: 2.0079566099310435

Epoch: 6| Step: 2
Training loss: 2.603992462158203
Validation loss: 2.0085179575027956

Epoch: 6| Step: 3
Training loss: 2.582533836364746
Validation loss: 2.008685053035777

Epoch: 6| Step: 4
Training loss: 1.9265459775924683
Validation loss: 1.9991415034058273

Epoch: 6| Step: 5
Training loss: 1.6321580410003662
Validation loss: 1.991986192682738

Epoch: 6| Step: 6
Training loss: 2.0817112922668457
Validation loss: 2.0066478585684173

Epoch: 6| Step: 7
Training loss: 2.487842559814453
Validation loss: 1.998747625658589

Epoch: 6| Step: 8
Training loss: 2.0595102310180664
Validation loss: 1.9927643550339567

Epoch: 6| Step: 9
Training loss: 2.197510242462158
Validation loss: 1.9916192946895477

Epoch: 6| Step: 10
Training loss: 1.7714803218841553
Validation loss: 2.000569946022444

Epoch: 6| Step: 11
Training loss: 2.3069732189178467
Validation loss: 1.997460619095833

Epoch: 6| Step: 12
Training loss: 2.7937161922454834
Validation loss: 1.9877539642395512

Epoch: 6| Step: 13
Training loss: 3.386854887008667
Validation loss: 2.0063438864164453

Epoch: 31| Step: 0
Training loss: 2.1543917655944824
Validation loss: 1.9952583774443595

Epoch: 6| Step: 1
Training loss: 2.4897756576538086
Validation loss: 2.000138880104147

Epoch: 6| Step: 2
Training loss: 2.023503541946411
Validation loss: 2.008538202572894

Epoch: 6| Step: 3
Training loss: 2.5823886394500732
Validation loss: 2.007913972741814

Epoch: 6| Step: 4
Training loss: 2.333482265472412
Validation loss: 1.997107175088698

Epoch: 6| Step: 5
Training loss: 1.7265613079071045
Validation loss: 2.0134471513891734

Epoch: 6| Step: 6
Training loss: 2.788602352142334
Validation loss: 2.0023138958920716

Epoch: 6| Step: 7
Training loss: 2.6361336708068848
Validation loss: 2.011319451434638

Epoch: 6| Step: 8
Training loss: 2.6640827655792236
Validation loss: 2.000875324331304

Epoch: 6| Step: 9
Training loss: 2.3524882793426514
Validation loss: 2.0080420278733775

Epoch: 6| Step: 10
Training loss: 1.9717707633972168
Validation loss: 1.996327341243785

Epoch: 6| Step: 11
Training loss: 2.547837734222412
Validation loss: 2.010132452493073

Epoch: 6| Step: 12
Training loss: 2.065056800842285
Validation loss: 2.0066979687700988

Epoch: 6| Step: 13
Training loss: 2.3221166133880615
Validation loss: 2.0087069503722654

Epoch: 32| Step: 0
Training loss: 2.173787832260132
Validation loss: 2.008663591518197

Epoch: 6| Step: 1
Training loss: 2.519710063934326
Validation loss: 2.0075760913151566

Epoch: 6| Step: 2
Training loss: 2.28328275680542
Validation loss: 2.021051652969853

Epoch: 6| Step: 3
Training loss: 2.044123649597168
Validation loss: 1.9939425312062746

Epoch: 6| Step: 4
Training loss: 2.816349506378174
Validation loss: 2.0041433867587837

Epoch: 6| Step: 5
Training loss: 2.468143939971924
Validation loss: 2.015578008467151

Epoch: 6| Step: 6
Training loss: 2.7152962684631348
Validation loss: 1.9998810855291222

Epoch: 6| Step: 7
Training loss: 1.986557960510254
Validation loss: 2.0115458247482136

Epoch: 6| Step: 8
Training loss: 1.9528863430023193
Validation loss: 2.0086355645169496

Epoch: 6| Step: 9
Training loss: 2.314350128173828
Validation loss: 2.0112683414131083

Epoch: 6| Step: 10
Training loss: 2.6330714225769043
Validation loss: 2.0002183811638945

Epoch: 6| Step: 11
Training loss: 2.1665124893188477
Validation loss: 2.007977403620238

Epoch: 6| Step: 12
Training loss: 2.384291648864746
Validation loss: 2.005786286887302

Epoch: 6| Step: 13
Training loss: 1.86366868019104
Validation loss: 1.9863337188638666

Epoch: 33| Step: 0
Training loss: 2.6959075927734375
Validation loss: 1.9990983060611192

Epoch: 6| Step: 1
Training loss: 2.577360153198242
Validation loss: 1.9912846062773017

Epoch: 6| Step: 2
Training loss: 2.0257158279418945
Validation loss: 2.0129009446790143

Epoch: 6| Step: 3
Training loss: 1.8656508922576904
Validation loss: 2.0016573052252493

Epoch: 6| Step: 4
Training loss: 2.5414881706237793
Validation loss: 1.9923884817349014

Epoch: 6| Step: 5
Training loss: 1.7740670442581177
Validation loss: 2.00753592675732

Epoch: 6| Step: 6
Training loss: 2.4961891174316406
Validation loss: 1.9935083722555509

Epoch: 6| Step: 7
Training loss: 2.1715097427368164
Validation loss: 2.0063533629140546

Epoch: 6| Step: 8
Training loss: 2.220559597015381
Validation loss: 1.9980811534389373

Epoch: 6| Step: 9
Training loss: 2.196901559829712
Validation loss: 2.0080272587396766

Epoch: 6| Step: 10
Training loss: 2.5088248252868652
Validation loss: 2.008131060549008

Epoch: 6| Step: 11
Training loss: 2.484816789627075
Validation loss: 1.9875780074827132

Epoch: 6| Step: 12
Training loss: 2.0404248237609863
Validation loss: 1.9841061599792973

Epoch: 6| Step: 13
Training loss: 3.3606419563293457
Validation loss: 1.9967989793387793

Epoch: 34| Step: 0
Training loss: 2.9093399047851562
Validation loss: 2.0045952181662283

Epoch: 6| Step: 1
Training loss: 2.3860177993774414
Validation loss: 2.0138081389088787

Epoch: 6| Step: 2
Training loss: 1.9614322185516357
Validation loss: 1.9965074869894213

Epoch: 6| Step: 3
Training loss: 2.0421648025512695
Validation loss: 1.9848338737282702

Epoch: 6| Step: 4
Training loss: 2.019772529602051
Validation loss: 2.0014410608558246

Epoch: 6| Step: 5
Training loss: 1.4604535102844238
Validation loss: 1.9980401326251287

Epoch: 6| Step: 6
Training loss: 2.4050800800323486
Validation loss: 2.0033211708068848

Epoch: 6| Step: 7
Training loss: 2.769808769226074
Validation loss: 1.999326927687532

Epoch: 6| Step: 8
Training loss: 2.020873546600342
Validation loss: 2.0189730121243383

Epoch: 6| Step: 9
Training loss: 2.233001470565796
Validation loss: 2.0067734320958457

Epoch: 6| Step: 10
Training loss: 2.358677387237549
Validation loss: 1.9986295379618162

Epoch: 6| Step: 11
Training loss: 2.7366180419921875
Validation loss: 1.9922782400602936

Epoch: 6| Step: 12
Training loss: 2.923820972442627
Validation loss: 2.007950773803137

Epoch: 6| Step: 13
Training loss: 2.089763641357422
Validation loss: 2.0080856398869584

Epoch: 35| Step: 0
Training loss: 2.412355422973633
Validation loss: 1.9921475379697737

Epoch: 6| Step: 1
Training loss: 1.976778268814087
Validation loss: 1.999360663916475

Epoch: 6| Step: 2
Training loss: 3.060950756072998
Validation loss: 1.9896739682843607

Epoch: 6| Step: 3
Training loss: 2.5564980506896973
Validation loss: 2.000805654833394

Epoch: 6| Step: 4
Training loss: 1.9858250617980957
Validation loss: 2.0126508999896306

Epoch: 6| Step: 5
Training loss: 2.439028024673462
Validation loss: 1.9904219001852057

Epoch: 6| Step: 6
Training loss: 2.2994542121887207
Validation loss: 2.0094537504257692

Epoch: 6| Step: 7
Training loss: 2.0626020431518555
Validation loss: 2.005252069042575

Epoch: 6| Step: 8
Training loss: 3.075981616973877
Validation loss: 2.006240023079739

Epoch: 6| Step: 9
Training loss: 1.4926241636276245
Validation loss: 2.0105691648298696

Epoch: 6| Step: 10
Training loss: 2.358863353729248
Validation loss: 2.011137085576211

Epoch: 6| Step: 11
Training loss: 1.8998984098434448
Validation loss: 2.005246667451756

Epoch: 6| Step: 12
Training loss: 2.2558188438415527
Validation loss: 2.017870669723839

Epoch: 6| Step: 13
Training loss: 2.4765124320983887
Validation loss: 2.0038214627132622

Epoch: 36| Step: 0
Training loss: 2.1970505714416504
Validation loss: 1.9939379589532011

Epoch: 6| Step: 1
Training loss: 3.1355526447296143
Validation loss: 2.0086727629425707

Epoch: 6| Step: 2
Training loss: 1.5622243881225586
Validation loss: 2.0112838732298983

Epoch: 6| Step: 3
Training loss: 2.561910629272461
Validation loss: 2.0094065858471777

Epoch: 6| Step: 4
Training loss: 2.4428672790527344
Validation loss: 2.002146465803987

Epoch: 6| Step: 5
Training loss: 2.1303205490112305
Validation loss: 2.0101719210224767

Epoch: 6| Step: 6
Training loss: 1.942891001701355
Validation loss: 2.0153350227622577

Epoch: 6| Step: 7
Training loss: 1.9963757991790771
Validation loss: 2.006270049720682

Epoch: 6| Step: 8
Training loss: 2.358368396759033
Validation loss: 2.013042575569563

Epoch: 6| Step: 9
Training loss: 2.5441927909851074
Validation loss: 2.0020290510628813

Epoch: 6| Step: 10
Training loss: 2.4527499675750732
Validation loss: 2.013080773815032

Epoch: 6| Step: 11
Training loss: 2.1445863246917725
Validation loss: 2.014394038466997

Epoch: 6| Step: 12
Training loss: 2.0487115383148193
Validation loss: 1.9888499090748448

Epoch: 6| Step: 13
Training loss: 2.9849512577056885
Validation loss: 2.0001332208674443

Epoch: 37| Step: 0
Training loss: 2.0888640880584717
Validation loss: 2.004891167404831

Epoch: 6| Step: 1
Training loss: 2.0603134632110596
Validation loss: 1.9911413884931994

Epoch: 6| Step: 2
Training loss: 2.181056499481201
Validation loss: 1.9999475363762147

Epoch: 6| Step: 3
Training loss: 2.2644877433776855
Validation loss: 2.008246810205521

Epoch: 6| Step: 4
Training loss: 2.5808849334716797
Validation loss: 2.001373315370211

Epoch: 6| Step: 5
Training loss: 1.8942391872406006
Validation loss: 2.010086146734094

Epoch: 6| Step: 6
Training loss: 2.8653862476348877
Validation loss: 1.9999292768457884

Epoch: 6| Step: 7
Training loss: 2.344207763671875
Validation loss: 2.004643622265067

Epoch: 6| Step: 8
Training loss: 2.1153483390808105
Validation loss: 1.995390269064134

Epoch: 6| Step: 9
Training loss: 2.486410140991211
Validation loss: 2.0179875794277398

Epoch: 6| Step: 10
Training loss: 2.4207663536071777
Validation loss: 1.9915935865012548

Epoch: 6| Step: 11
Training loss: 2.6213932037353516
Validation loss: 1.990666022864721

Epoch: 6| Step: 12
Training loss: 1.8661186695098877
Validation loss: 1.9918119163923367

Epoch: 6| Step: 13
Training loss: 2.5146546363830566
Validation loss: 2.0062744950735443

Epoch: 38| Step: 0
Training loss: 1.5014327764511108
Validation loss: 1.995863212052212

Epoch: 6| Step: 1
Training loss: 2.9248013496398926
Validation loss: 1.9960555056089997

Epoch: 6| Step: 2
Training loss: 1.6106016635894775
Validation loss: 2.008569109824396

Epoch: 6| Step: 3
Training loss: 2.7644224166870117
Validation loss: 2.0048190701392388

Epoch: 6| Step: 4
Training loss: 1.8271009922027588
Validation loss: 2.0093181902362454

Epoch: 6| Step: 5
Training loss: 2.362359046936035
Validation loss: 1.99923457894274

Epoch: 6| Step: 6
Training loss: 2.014108419418335
Validation loss: 2.0053287270248576

Epoch: 6| Step: 7
Training loss: 2.4448792934417725
Validation loss: 2.0006781983119186

Epoch: 6| Step: 8
Training loss: 2.1481308937072754
Validation loss: 1.9993817396061395

Epoch: 6| Step: 9
Training loss: 3.45876407623291
Validation loss: 1.9896579198939826

Epoch: 6| Step: 10
Training loss: 2.1051671504974365
Validation loss: 2.0137598668375323

Epoch: 6| Step: 11
Training loss: 2.4730074405670166
Validation loss: 2.0036063527548187

Epoch: 6| Step: 12
Training loss: 2.028580904006958
Validation loss: 2.0005331705975276

Epoch: 6| Step: 13
Training loss: 2.4428036212921143
Validation loss: 2.0189767511942054

Epoch: 39| Step: 0
Training loss: 2.6011605262756348
Validation loss: 1.9925680404068322

Epoch: 6| Step: 1
Training loss: 1.6826891899108887
Validation loss: 2.0078936828080045

Epoch: 6| Step: 2
Training loss: 2.3202996253967285
Validation loss: 1.988860305919442

Epoch: 6| Step: 3
Training loss: 2.0702617168426514
Validation loss: 1.9922399033782303

Epoch: 6| Step: 4
Training loss: 1.909971833229065
Validation loss: 2.004565869608233

Epoch: 6| Step: 5
Training loss: 2.1572041511535645
Validation loss: 1.9990721235993087

Epoch: 6| Step: 6
Training loss: 2.2479000091552734
Validation loss: 2.001696122589932

Epoch: 6| Step: 7
Training loss: 2.5609705448150635
Validation loss: 2.0009275033909786

Epoch: 6| Step: 8
Training loss: 2.4824819564819336
Validation loss: 2.0057358177759315

Epoch: 6| Step: 9
Training loss: 1.8007924556732178
Validation loss: 2.0121870130620976

Epoch: 6| Step: 10
Training loss: 2.237072467803955
Validation loss: 2.0094369419159426

Epoch: 6| Step: 11
Training loss: 2.879918098449707
Validation loss: 1.9993002953067902

Epoch: 6| Step: 12
Training loss: 2.875269889831543
Validation loss: 2.0060533272322787

Epoch: 6| Step: 13
Training loss: 1.9132148027420044
Validation loss: 2.0047674743078088

Epoch: 40| Step: 0
Training loss: 2.9794516563415527
Validation loss: 2.007607444640129

Epoch: 6| Step: 1
Training loss: 1.8395946025848389
Validation loss: 1.9985502535297024

Epoch: 6| Step: 2
Training loss: 2.7568230628967285
Validation loss: 1.995416420762257

Epoch: 6| Step: 3
Training loss: 2.0636792182922363
Validation loss: 2.0147575806545954

Epoch: 6| Step: 4
Training loss: 1.8435999155044556
Validation loss: 2.009826191010014

Epoch: 6| Step: 5
Training loss: 2.559544086456299
Validation loss: 2.0027733618213284

Epoch: 6| Step: 6
Training loss: 2.2225449085235596
Validation loss: 2.016519199135483

Epoch: 6| Step: 7
Training loss: 2.207916259765625
Validation loss: 1.9917014183536652

Epoch: 6| Step: 8
Training loss: 2.1549644470214844
Validation loss: 2.0047494288413756

Epoch: 6| Step: 9
Training loss: 1.8680479526519775
Validation loss: 2.0145925937160367

Epoch: 6| Step: 10
Training loss: 2.7833549976348877
Validation loss: 1.9979235472217682

Epoch: 6| Step: 11
Training loss: 2.2714154720306396
Validation loss: 1.9921005989915581

Epoch: 6| Step: 12
Training loss: 1.9607477188110352
Validation loss: 1.9998738906716789

Epoch: 6| Step: 13
Training loss: 2.1857569217681885
Validation loss: 1.9915918662983885

Epoch: 41| Step: 0
Training loss: 2.280076026916504
Validation loss: 2.0018966915786907

Epoch: 6| Step: 1
Training loss: 2.2015981674194336
Validation loss: 1.9941766941419212

Epoch: 6| Step: 2
Training loss: 2.6598381996154785
Validation loss: 2.005022928278933

Epoch: 6| Step: 3
Training loss: 1.7641384601593018
Validation loss: 2.0041043040572957

Epoch: 6| Step: 4
Training loss: 2.1031277179718018
Validation loss: 2.006064366268855

Epoch: 6| Step: 5
Training loss: 2.3145556449890137
Validation loss: 1.99180067482815

Epoch: 6| Step: 6
Training loss: 2.2988691329956055
Validation loss: 2.013168622088689

Epoch: 6| Step: 7
Training loss: 3.3347792625427246
Validation loss: 2.008008590308569

Epoch: 6| Step: 8
Training loss: 1.7093740701675415
Validation loss: 2.0047311372654413

Epoch: 6| Step: 9
Training loss: 2.260324716567993
Validation loss: 2.019568294607183

Epoch: 6| Step: 10
Training loss: 2.196901798248291
Validation loss: 2.0045241232841247

Epoch: 6| Step: 11
Training loss: 1.9906408786773682
Validation loss: 2.01151079516257

Epoch: 6| Step: 12
Training loss: 2.080899953842163
Validation loss: 2.0125969353542534

Epoch: 6| Step: 13
Training loss: 2.773134469985962
Validation loss: 2.0112718074552474

Epoch: 42| Step: 0
Training loss: 2.908478260040283
Validation loss: 1.9884128557738436

Epoch: 6| Step: 1
Training loss: 1.8749550580978394
Validation loss: 2.006720153234338

Epoch: 6| Step: 2
Training loss: 2.7546167373657227
Validation loss: 2.001080866782896

Epoch: 6| Step: 3
Training loss: 2.608590602874756
Validation loss: 2.0199523433562248

Epoch: 6| Step: 4
Training loss: 2.615324020385742
Validation loss: 2.0114954940734373

Epoch: 6| Step: 5
Training loss: 2.3955650329589844
Validation loss: 1.9993001312337897

Epoch: 6| Step: 6
Training loss: 1.8110836744308472
Validation loss: 2.0084507337180515

Epoch: 6| Step: 7
Training loss: 2.1039881706237793
Validation loss: 2.00176223375464

Epoch: 6| Step: 8
Training loss: 2.088862657546997
Validation loss: 2.0124786092389013

Epoch: 6| Step: 9
Training loss: 1.9951770305633545
Validation loss: 2.006351670911235

Epoch: 6| Step: 10
Training loss: 2.270059585571289
Validation loss: 2.0077545617216375

Epoch: 6| Step: 11
Training loss: 2.290822744369507
Validation loss: 2.0149790497236353

Epoch: 6| Step: 12
Training loss: 2.3587424755096436
Validation loss: 2.0259408104804253

Epoch: 6| Step: 13
Training loss: 1.1400446891784668
Validation loss: 2.0108339914711575

Epoch: 43| Step: 0
Training loss: 1.7474467754364014
Validation loss: 1.9996282477532663

Epoch: 6| Step: 1
Training loss: 2.06973934173584
Validation loss: 2.001326645574262

Epoch: 6| Step: 2
Training loss: 1.94638991355896
Validation loss: 2.014664890945599

Epoch: 6| Step: 3
Training loss: 2.14585542678833
Validation loss: 2.0078205024042437

Epoch: 6| Step: 4
Training loss: 1.9103672504425049
Validation loss: 1.9922854092813307

Epoch: 6| Step: 5
Training loss: 2.707371950149536
Validation loss: 2.0098012544775523

Epoch: 6| Step: 6
Training loss: 2.7781715393066406
Validation loss: 2.019065700551515

Epoch: 6| Step: 7
Training loss: 2.6808784008026123
Validation loss: 2.0142546956257155

Epoch: 6| Step: 8
Training loss: 2.0052649974823
Validation loss: 2.005599429530482

Epoch: 6| Step: 9
Training loss: 2.359778881072998
Validation loss: 2.0272979146690777

Epoch: 6| Step: 10
Training loss: 2.5512728691101074
Validation loss: 2.0172830268900883

Epoch: 6| Step: 11
Training loss: 2.008540153503418
Validation loss: 2.008405589288281

Epoch: 6| Step: 12
Training loss: 2.661325693130493
Validation loss: 2.0058482385450795

Epoch: 6| Step: 13
Training loss: 2.093916177749634
Validation loss: 2.019059850323585

Epoch: 44| Step: 0
Training loss: 1.9397523403167725
Validation loss: 2.008809854907374

Epoch: 6| Step: 1
Training loss: 2.5318267345428467
Validation loss: 1.9995986133493402

Epoch: 6| Step: 2
Training loss: 2.0290656089782715
Validation loss: 1.9918136455679452

Epoch: 6| Step: 3
Training loss: 2.0616302490234375
Validation loss: 2.0161649514270086

Epoch: 6| Step: 4
Training loss: 2.254103660583496
Validation loss: 2.0167485654995008

Epoch: 6| Step: 5
Training loss: 1.9878637790679932
Validation loss: 2.0088181662303146

Epoch: 6| Step: 6
Training loss: 2.9454445838928223
Validation loss: 2.0089261115238233

Epoch: 6| Step: 7
Training loss: 1.7576419115066528
Validation loss: 2.019390954766222

Epoch: 6| Step: 8
Training loss: 2.4310503005981445
Validation loss: 2.0025981677475797

Epoch: 6| Step: 9
Training loss: 2.2782487869262695
Validation loss: 2.0163879561167892

Epoch: 6| Step: 10
Training loss: 2.0093133449554443
Validation loss: 2.0057865650423112

Epoch: 6| Step: 11
Training loss: 2.8866145610809326
Validation loss: 1.9881867516425349

Epoch: 6| Step: 12
Training loss: 2.548525333404541
Validation loss: 2.0114796571834113

Epoch: 6| Step: 13
Training loss: 1.7053866386413574
Validation loss: 2.0026189819458993

Epoch: 45| Step: 0
Training loss: 2.3701159954071045
Validation loss: 2.0167794791601037

Epoch: 6| Step: 1
Training loss: 2.5963876247406006
Validation loss: 2.01232825556109

Epoch: 6| Step: 2
Training loss: 2.410983085632324
Validation loss: 2.0205138178281885

Epoch: 6| Step: 3
Training loss: 2.7880964279174805
Validation loss: 2.0050517692360827

Epoch: 6| Step: 4
Training loss: 2.220379114151001
Validation loss: 2.017101084032366

Epoch: 6| Step: 5
Training loss: 2.485499858856201
Validation loss: 2.010227559715189

Epoch: 6| Step: 6
Training loss: 1.6770973205566406
Validation loss: 2.0057918589602233

Epoch: 6| Step: 7
Training loss: 2.104083299636841
Validation loss: 2.020746370797516

Epoch: 6| Step: 8
Training loss: 2.103630781173706
Validation loss: 1.998665709649363

Epoch: 6| Step: 9
Training loss: 2.8080286979675293
Validation loss: 1.999296078117945

Epoch: 6| Step: 10
Training loss: 1.9220763444900513
Validation loss: 2.0108549928152435

Epoch: 6| Step: 11
Training loss: 2.1412222385406494
Validation loss: 2.005192018324329

Epoch: 6| Step: 12
Training loss: 1.9557528495788574
Validation loss: 2.006118410377092

Epoch: 6| Step: 13
Training loss: 1.6535420417785645
Validation loss: 2.0131338078488588

Epoch: 46| Step: 0
Training loss: 2.757038116455078
Validation loss: 2.001793355070135

Epoch: 6| Step: 1
Training loss: 2.228126049041748
Validation loss: 2.0061605643200617

Epoch: 6| Step: 2
Training loss: 1.5313258171081543
Validation loss: 2.0050160038855767

Epoch: 6| Step: 3
Training loss: 1.9327805042266846
Validation loss: 2.010695080603323

Epoch: 6| Step: 4
Training loss: 1.9286601543426514
Validation loss: 2.013955878955062

Epoch: 6| Step: 5
Training loss: 2.821558952331543
Validation loss: 2.0109010127282914

Epoch: 6| Step: 6
Training loss: 2.461121082305908
Validation loss: 2.00039186785298

Epoch: 6| Step: 7
Training loss: 1.9761452674865723
Validation loss: 2.0081022285646006

Epoch: 6| Step: 8
Training loss: 1.8286921977996826
Validation loss: 2.003831245565927

Epoch: 6| Step: 9
Training loss: 2.0658788681030273
Validation loss: 2.009515590565179

Epoch: 6| Step: 10
Training loss: 2.6028010845184326
Validation loss: 2.0115378005530244

Epoch: 6| Step: 11
Training loss: 2.3041229248046875
Validation loss: 2.0043864609092794

Epoch: 6| Step: 12
Training loss: 2.5293455123901367
Validation loss: 1.9987550858528382

Epoch: 6| Step: 13
Training loss: 2.760361671447754
Validation loss: 2.014623716313352

Epoch: 47| Step: 0
Training loss: 2.2895607948303223
Validation loss: 2.011520078105311

Epoch: 6| Step: 1
Training loss: 2.394331216812134
Validation loss: 2.026102560822682

Epoch: 6| Step: 2
Training loss: 2.3377456665039062
Validation loss: 2.008082705159341

Epoch: 6| Step: 3
Training loss: 2.3433423042297363
Validation loss: 2.004300428975013

Epoch: 6| Step: 4
Training loss: 2.213865280151367
Validation loss: 2.0177901047532276

Epoch: 6| Step: 5
Training loss: 1.5905635356903076
Validation loss: 2.00209479947244

Epoch: 6| Step: 6
Training loss: 2.425210952758789
Validation loss: 2.0085551508011354

Epoch: 6| Step: 7
Training loss: 1.9596357345581055
Validation loss: 1.997501132308796

Epoch: 6| Step: 8
Training loss: 2.1184439659118652
Validation loss: 2.0087521204384426

Epoch: 6| Step: 9
Training loss: 1.8450474739074707
Validation loss: 2.0128379791013655

Epoch: 6| Step: 10
Training loss: 2.752636432647705
Validation loss: 2.0045751217872865

Epoch: 6| Step: 11
Training loss: 2.46268367767334
Validation loss: 2.003197927628794

Epoch: 6| Step: 12
Training loss: 2.2432713508605957
Validation loss: 1.9960314830144246

Epoch: 6| Step: 13
Training loss: 2.664867877960205
Validation loss: 2.005186302687532

Epoch: 48| Step: 0
Training loss: 1.7222555875778198
Validation loss: 2.0066067518726474

Epoch: 6| Step: 1
Training loss: 2.4325766563415527
Validation loss: 1.995839706031225

Epoch: 6| Step: 2
Training loss: 2.2570321559906006
Validation loss: 2.006749109555316

Epoch: 6| Step: 3
Training loss: 2.088364839553833
Validation loss: 2.010393129881992

Epoch: 6| Step: 4
Training loss: 2.9973690509796143
Validation loss: 2.01414990937838

Epoch: 6| Step: 5
Training loss: 1.8697457313537598
Validation loss: 2.0007459091883835

Epoch: 6| Step: 6
Training loss: 2.017573833465576
Validation loss: 2.0108480145854335

Epoch: 6| Step: 7
Training loss: 1.858757734298706
Validation loss: 2.00517806442835

Epoch: 6| Step: 8
Training loss: 2.0751991271972656
Validation loss: 2.0035111775962253

Epoch: 6| Step: 9
Training loss: 1.990501880645752
Validation loss: 2.0083554483229116

Epoch: 6| Step: 10
Training loss: 2.256347417831421
Validation loss: 2.014591981005925

Epoch: 6| Step: 11
Training loss: 2.335977077484131
Validation loss: 2.005501462567237

Epoch: 6| Step: 12
Training loss: 3.1829841136932373
Validation loss: 2.0147142153914257

Epoch: 6| Step: 13
Training loss: 2.625155448913574
Validation loss: 2.0069620276010163

Epoch: 49| Step: 0
Training loss: 2.5679664611816406
Validation loss: 2.0169432086329304

Epoch: 6| Step: 1
Training loss: 2.4607505798339844
Validation loss: 2.002606773889193

Epoch: 6| Step: 2
Training loss: 1.7857338190078735
Validation loss: 2.0130876905174664

Epoch: 6| Step: 3
Training loss: 2.629746913909912
Validation loss: 2.007756604943224

Epoch: 6| Step: 4
Training loss: 2.154891014099121
Validation loss: 2.0142060582355787

Epoch: 6| Step: 5
Training loss: 2.4579226970672607
Validation loss: 2.0110469966806392

Epoch: 6| Step: 6
Training loss: 2.2522830963134766
Validation loss: 2.0090198952664613

Epoch: 6| Step: 7
Training loss: 2.171222686767578
Validation loss: 2.011174499347646

Epoch: 6| Step: 8
Training loss: 2.0367822647094727
Validation loss: 2.0095994446867254

Epoch: 6| Step: 9
Training loss: 1.737624168395996
Validation loss: 2.0153860661291305

Epoch: 6| Step: 10
Training loss: 2.0118765830993652
Validation loss: 2.0183424449736074

Epoch: 6| Step: 11
Training loss: 2.7520596981048584
Validation loss: 2.0137422392445226

Epoch: 6| Step: 12
Training loss: 2.5450587272644043
Validation loss: 2.0171732851254043

Epoch: 6| Step: 13
Training loss: 1.6189502477645874
Validation loss: 2.01556424684422

Epoch: 50| Step: 0
Training loss: 2.3348498344421387
Validation loss: 1.9979910004523493

Epoch: 6| Step: 1
Training loss: 2.7205452919006348
Validation loss: 1.9985920101083734

Epoch: 6| Step: 2
Training loss: 3.080409049987793
Validation loss: 1.9984115656986032

Epoch: 6| Step: 3
Training loss: 1.9204003810882568
Validation loss: 2.009696606666811

Epoch: 6| Step: 4
Training loss: 1.9067246913909912
Validation loss: 2.00894106588056

Epoch: 6| Step: 5
Training loss: 2.1131019592285156
Validation loss: 2.0039842256935696

Epoch: 6| Step: 6
Training loss: 2.3015499114990234
Validation loss: 2.0081474217035438

Epoch: 6| Step: 7
Training loss: 1.9332000017166138
Validation loss: 2.002396177220088

Epoch: 6| Step: 8
Training loss: 2.67879056930542
Validation loss: 2.0153882798328193

Epoch: 6| Step: 9
Training loss: 2.1243388652801514
Validation loss: 2.000430037898402

Epoch: 6| Step: 10
Training loss: 2.0010032653808594
Validation loss: 1.9972530539317797

Epoch: 6| Step: 11
Training loss: 1.785130500793457
Validation loss: 2.0014685969198904

Epoch: 6| Step: 12
Training loss: 2.2252633571624756
Validation loss: 2.005834038539599

Epoch: 6| Step: 13
Training loss: 2.3214404582977295
Validation loss: 2.018949052338959

Epoch: 51| Step: 0
Training loss: 1.993293046951294
Validation loss: 2.0109127567660425

Epoch: 6| Step: 1
Training loss: 2.3263778686523438
Validation loss: 2.0060111784165904

Epoch: 6| Step: 2
Training loss: 2.471334934234619
Validation loss: 2.0227156621153637

Epoch: 6| Step: 3
Training loss: 2.130089044570923
Validation loss: 2.001428090116029

Epoch: 6| Step: 4
Training loss: 2.3265116214752197
Validation loss: 2.0088995759205153

Epoch: 6| Step: 5
Training loss: 2.3777589797973633
Validation loss: 1.9953298132906678

Epoch: 6| Step: 6
Training loss: 2.487255096435547
Validation loss: 2.0178629749564716

Epoch: 6| Step: 7
Training loss: 1.3190667629241943
Validation loss: 2.0085825984195997

Epoch: 6| Step: 8
Training loss: 2.508962631225586
Validation loss: 2.004510453952256

Epoch: 6| Step: 9
Training loss: 2.4141054153442383
Validation loss: 2.001473198654831

Epoch: 6| Step: 10
Training loss: 2.4224228858947754
Validation loss: 2.011337419991852

Epoch: 6| Step: 11
Training loss: 2.5353918075561523
Validation loss: 2.0078270204605593

Epoch: 6| Step: 12
Training loss: 1.8726081848144531
Validation loss: 2.0193990122887397

Epoch: 6| Step: 13
Training loss: 2.1260695457458496
Validation loss: 2.0143180534403813

Epoch: 52| Step: 0
Training loss: 2.271317720413208
Validation loss: 2.0108603662060154

Epoch: 6| Step: 1
Training loss: 2.2788712978363037
Validation loss: 2.015148913988503

Epoch: 6| Step: 2
Training loss: 2.786759853363037
Validation loss: 2.0020054437780894

Epoch: 6| Step: 3
Training loss: 1.8776895999908447
Validation loss: 2.0183144769360943

Epoch: 6| Step: 4
Training loss: 1.424147367477417
Validation loss: 2.0234627057147283

Epoch: 6| Step: 5
Training loss: 2.5610368251800537
Validation loss: 2.01425814372237

Epoch: 6| Step: 6
Training loss: 2.102581024169922
Validation loss: 2.016712070793234

Epoch: 6| Step: 7
Training loss: 2.1869120597839355
Validation loss: 2.0074083074446647

Epoch: 6| Step: 8
Training loss: 2.507497787475586
Validation loss: 2.018232654499751

Epoch: 6| Step: 9
Training loss: 2.628108024597168
Validation loss: 2.0017339926893993

Epoch: 6| Step: 10
Training loss: 2.780028820037842
Validation loss: 2.000149649958457

Epoch: 6| Step: 11
Training loss: 1.5682170391082764
Validation loss: 2.0271145323271393

Epoch: 6| Step: 12
Training loss: 2.313349962234497
Validation loss: 1.9819012662415862

Epoch: 6| Step: 13
Training loss: 1.9452149868011475
Validation loss: 1.9978411069480322

Epoch: 53| Step: 0
Training loss: 1.4488186836242676
Validation loss: 1.9986817708579443

Epoch: 6| Step: 1
Training loss: 1.8373526334762573
Validation loss: 2.0067833674851285

Epoch: 6| Step: 2
Training loss: 2.394272804260254
Validation loss: 1.9915869620538527

Epoch: 6| Step: 3
Training loss: 2.687215805053711
Validation loss: 2.001021482611215

Epoch: 6| Step: 4
Training loss: 1.694785237312317
Validation loss: 2.0044202548201366

Epoch: 6| Step: 5
Training loss: 1.6619160175323486
Validation loss: 2.0172507968000186

Epoch: 6| Step: 6
Training loss: 1.7783939838409424
Validation loss: 2.001785136038257

Epoch: 6| Step: 7
Training loss: 3.1230573654174805
Validation loss: 2.010250201789282

Epoch: 6| Step: 8
Training loss: 2.1050734519958496
Validation loss: 1.9917984316425938

Epoch: 6| Step: 9
Training loss: 2.6782917976379395
Validation loss: 2.014265306534306

Epoch: 6| Step: 10
Training loss: 2.3730626106262207
Validation loss: 2.0040311749263475

Epoch: 6| Step: 11
Training loss: 2.469815731048584
Validation loss: 2.001210653653709

Epoch: 6| Step: 12
Training loss: 2.793989658355713
Validation loss: 2.0194199239054034

Epoch: 6| Step: 13
Training loss: 2.27351975440979
Validation loss: 2.00052071386768

Epoch: 54| Step: 0
Training loss: 1.3199317455291748
Validation loss: 2.0161910954342095

Epoch: 6| Step: 1
Training loss: 2.181636333465576
Validation loss: 2.010932469880709

Epoch: 6| Step: 2
Training loss: 2.383589267730713
Validation loss: 2.003671166717365

Epoch: 6| Step: 3
Training loss: 2.9350523948669434
Validation loss: 2.001280011669282

Epoch: 6| Step: 4
Training loss: 1.5917161703109741
Validation loss: 2.0212047997341362

Epoch: 6| Step: 5
Training loss: 2.4656410217285156
Validation loss: 2.0080241054616947

Epoch: 6| Step: 6
Training loss: 2.478259325027466
Validation loss: 2.0002382532242806

Epoch: 6| Step: 7
Training loss: 1.9329456090927124
Validation loss: 2.003957712522117

Epoch: 6| Step: 8
Training loss: 2.7046897411346436
Validation loss: 1.9980971095382527

Epoch: 6| Step: 9
Training loss: 2.7482876777648926
Validation loss: 2.004005291128671

Epoch: 6| Step: 10
Training loss: 1.6515562534332275
Validation loss: 2.0068503413149106

Epoch: 6| Step: 11
Training loss: 2.0602951049804688
Validation loss: 2.0052264762181107

Epoch: 6| Step: 12
Training loss: 2.7271218299865723
Validation loss: 2.025025639482724

Epoch: 6| Step: 13
Training loss: 1.8111237287521362
Validation loss: 2.0212297413938787

Epoch: 55| Step: 0
Training loss: 1.7359983921051025
Validation loss: 2.014708395927183

Epoch: 6| Step: 1
Training loss: 2.4765172004699707
Validation loss: 2.023657211693384

Epoch: 6| Step: 2
Training loss: 2.3524210453033447
Validation loss: 2.0269310243668093

Epoch: 6| Step: 3
Training loss: 2.725790023803711
Validation loss: 2.0071683724721274

Epoch: 6| Step: 4
Training loss: 1.5009362697601318
Validation loss: 2.0026669168985016

Epoch: 6| Step: 5
Training loss: 1.8434637784957886
Validation loss: 2.007221693633705

Epoch: 6| Step: 6
Training loss: 2.8686013221740723
Validation loss: 1.9989982997217486

Epoch: 6| Step: 7
Training loss: 2.0099072456359863
Validation loss: 2.018689670870381

Epoch: 6| Step: 8
Training loss: 2.51741886138916
Validation loss: 2.008754548206124

Epoch: 6| Step: 9
Training loss: 2.401637077331543
Validation loss: 2.0091809970076366

Epoch: 6| Step: 10
Training loss: 2.1934709548950195
Validation loss: 2.0220066244884203

Epoch: 6| Step: 11
Training loss: 1.9418840408325195
Validation loss: 2.0149361882158505

Epoch: 6| Step: 12
Training loss: 2.272975206375122
Validation loss: 2.0019453571688746

Epoch: 6| Step: 13
Training loss: 2.596604585647583
Validation loss: 1.9956377706220072

Epoch: 56| Step: 0
Training loss: 2.1582319736480713
Validation loss: 2.013438840066233

Epoch: 6| Step: 1
Training loss: 2.23720121383667
Validation loss: 1.9927869971080492

Epoch: 6| Step: 2
Training loss: 2.4442336559295654
Validation loss: 2.0154908651946695

Epoch: 6| Step: 3
Training loss: 1.8814723491668701
Validation loss: 2.0193891294540895

Epoch: 6| Step: 4
Training loss: 3.177178382873535
Validation loss: 2.0121762893533193

Epoch: 6| Step: 5
Training loss: 1.7048934698104858
Validation loss: 2.003463698971656

Epoch: 6| Step: 6
Training loss: 2.3931491374969482
Validation loss: 2.0139396062461277

Epoch: 6| Step: 7
Training loss: 1.79180908203125
Validation loss: 2.023130046424045

Epoch: 6| Step: 8
Training loss: 2.027205467224121
Validation loss: 2.002504305172992

Epoch: 6| Step: 9
Training loss: 2.0289347171783447
Validation loss: 2.002270035846259

Epoch: 6| Step: 10
Training loss: 1.589081048965454
Validation loss: 2.006920961923497

Epoch: 6| Step: 11
Training loss: 2.81710147857666
Validation loss: 2.006623819310178

Epoch: 6| Step: 12
Training loss: 2.041098117828369
Validation loss: 2.0067132993410994

Epoch: 6| Step: 13
Training loss: 3.151305913925171
Validation loss: 2.0061999623493483

Epoch: 57| Step: 0
Training loss: 2.076763153076172
Validation loss: 2.0126869383678643

Epoch: 6| Step: 1
Training loss: 2.6174516677856445
Validation loss: 2.0012320292893278

Epoch: 6| Step: 2
Training loss: 2.503269910812378
Validation loss: 2.0077272384397444

Epoch: 6| Step: 3
Training loss: 2.2695369720458984
Validation loss: 2.0188893272030737

Epoch: 6| Step: 4
Training loss: 2.20098876953125
Validation loss: 2.0206889555018437

Epoch: 6| Step: 5
Training loss: 2.237269878387451
Validation loss: 1.9902020359552035

Epoch: 6| Step: 6
Training loss: 1.7178757190704346
Validation loss: 2.0127884111096783

Epoch: 6| Step: 7
Training loss: 1.7565548419952393
Validation loss: 1.9991664758292578

Epoch: 6| Step: 8
Training loss: 2.605146884918213
Validation loss: 1.9867388535571355

Epoch: 6| Step: 9
Training loss: 1.9320170879364014
Validation loss: 2.015820562198598

Epoch: 6| Step: 10
Training loss: 2.112222909927368
Validation loss: 2.018936088008265

Epoch: 6| Step: 11
Training loss: 1.694465160369873
Validation loss: 2.025367243315584

Epoch: 6| Step: 12
Training loss: 3.2129406929016113
Validation loss: 2.0034781297047934

Epoch: 6| Step: 13
Training loss: 2.2181365489959717
Validation loss: 2.0111939291800223

Epoch: 58| Step: 0
Training loss: 1.6881709098815918
Validation loss: 2.001289261284695

Epoch: 6| Step: 1
Training loss: 1.51741361618042
Validation loss: 2.0152233569852767

Epoch: 6| Step: 2
Training loss: 2.2948813438415527
Validation loss: 2.0165986040587067

Epoch: 6| Step: 3
Training loss: 2.4626119136810303
Validation loss: 2.0081075083824897

Epoch: 6| Step: 4
Training loss: 2.782819986343384
Validation loss: 2.0177502362958846

Epoch: 6| Step: 5
Training loss: 2.5042238235473633
Validation loss: 1.9862961282012284

Epoch: 6| Step: 6
Training loss: 2.7012391090393066
Validation loss: 2.0169325131241993

Epoch: 6| Step: 7
Training loss: 2.6819119453430176
Validation loss: 2.008014061117685

Epoch: 6| Step: 8
Training loss: 2.174248456954956
Validation loss: 2.011902045178157

Epoch: 6| Step: 9
Training loss: 2.139206886291504
Validation loss: 2.0286337598677604

Epoch: 6| Step: 10
Training loss: 2.6922342777252197
Validation loss: 2.0157171321171585

Epoch: 6| Step: 11
Training loss: 1.5371655225753784
Validation loss: 2.0141189277813

Epoch: 6| Step: 12
Training loss: 1.7582576274871826
Validation loss: 2.023552558755362

Epoch: 6| Step: 13
Training loss: 2.288233757019043
Validation loss: 2.010068251240638

Epoch: 59| Step: 0
Training loss: 1.9278680086135864
Validation loss: 2.007055033919632

Epoch: 6| Step: 1
Training loss: 2.0201833248138428
Validation loss: 2.0057214767702165

Epoch: 6| Step: 2
Training loss: 2.5756349563598633
Validation loss: 2.0067112253558252

Epoch: 6| Step: 3
Training loss: 2.310906410217285
Validation loss: 2.0179853285512617

Epoch: 6| Step: 4
Training loss: 2.4910945892333984
Validation loss: 2.0161366565253145

Epoch: 6| Step: 5
Training loss: 2.4804296493530273
Validation loss: 2.015614781328427

Epoch: 6| Step: 6
Training loss: 1.6823132038116455
Validation loss: 2.009870967557353

Epoch: 6| Step: 7
Training loss: 2.0718300342559814
Validation loss: 2.013280996712305

Epoch: 6| Step: 8
Training loss: 1.9376287460327148
Validation loss: 2.014426850503491

Epoch: 6| Step: 9
Training loss: 2.446930170059204
Validation loss: 1.996743780310436

Epoch: 6| Step: 10
Training loss: 2.5758862495422363
Validation loss: 2.007514561376264

Epoch: 6| Step: 11
Training loss: 2.151275396347046
Validation loss: 2.010315905335129

Epoch: 6| Step: 12
Training loss: 1.574232816696167
Validation loss: 2.0253651103665753

Epoch: 6| Step: 13
Training loss: 3.191089391708374
Validation loss: 2.0155445093749673

Epoch: 60| Step: 0
Training loss: 2.145179271697998
Validation loss: 2.013015757324875

Epoch: 6| Step: 1
Training loss: 1.7384960651397705
Validation loss: 1.9964302560334564

Epoch: 6| Step: 2
Training loss: 2.2110745906829834
Validation loss: 2.015901886006837

Epoch: 6| Step: 3
Training loss: 2.1600546836853027
Validation loss: 2.003316743399507

Epoch: 6| Step: 4
Training loss: 2.7253501415252686
Validation loss: 1.9868043520117318

Epoch: 6| Step: 5
Training loss: 2.3788132667541504
Validation loss: 2.002792107161655

Epoch: 6| Step: 6
Training loss: 1.8212039470672607
Validation loss: 2.011405865351359

Epoch: 6| Step: 7
Training loss: 2.207965850830078
Validation loss: 2.0013261443825177

Epoch: 6| Step: 8
Training loss: 1.8490872383117676
Validation loss: 2.0106900943222867

Epoch: 6| Step: 9
Training loss: 2.599102020263672
Validation loss: 2.014214111912635

Epoch: 6| Step: 10
Training loss: 1.7534022331237793
Validation loss: 2.0107854873903337

Epoch: 6| Step: 11
Training loss: 3.306603193283081
Validation loss: 2.016710171135523

Epoch: 6| Step: 12
Training loss: 2.139511823654175
Validation loss: 2.004968984152681

Epoch: 6| Step: 13
Training loss: 1.747623085975647
Validation loss: 2.0197767724273024

Epoch: 61| Step: 0
Training loss: 1.988734483718872
Validation loss: 2.006242190637896

Epoch: 6| Step: 1
Training loss: 2.7769722938537598
Validation loss: 2.009796022087015

Epoch: 6| Step: 2
Training loss: 1.6955902576446533
Validation loss: 2.0334077573591665

Epoch: 6| Step: 3
Training loss: 1.5298309326171875
Validation loss: 1.9974987096683954

Epoch: 6| Step: 4
Training loss: 2.0063161849975586
Validation loss: 2.026373512001448

Epoch: 6| Step: 5
Training loss: 1.963325023651123
Validation loss: 2.0243771050565984

Epoch: 6| Step: 6
Training loss: 2.24766206741333
Validation loss: 2.0169313774313977

Epoch: 6| Step: 7
Training loss: 2.616586208343506
Validation loss: 2.0046882975486016

Epoch: 6| Step: 8
Training loss: 1.6459107398986816
Validation loss: 2.0255003488191994

Epoch: 6| Step: 9
Training loss: 2.2939705848693848
Validation loss: 1.9896263819868847

Epoch: 6| Step: 10
Training loss: 2.0519185066223145
Validation loss: 2.023868954309853

Epoch: 6| Step: 11
Training loss: 2.5700769424438477
Validation loss: 2.006084821557486

Epoch: 6| Step: 12
Training loss: 2.971365213394165
Validation loss: 2.015444532517464

Epoch: 6| Step: 13
Training loss: 2.856855869293213
Validation loss: 2.015476671598291

Epoch: 62| Step: 0
Training loss: 2.4339001178741455
Validation loss: 2.006851557762392

Epoch: 6| Step: 1
Training loss: 2.2089202404022217
Validation loss: 2.0093319492955364

Epoch: 6| Step: 2
Training loss: 1.9582551717758179
Validation loss: 2.02778184798456

Epoch: 6| Step: 3
Training loss: 1.8556971549987793
Validation loss: 2.013392404843402

Epoch: 6| Step: 4
Training loss: 2.4476003646850586
Validation loss: 2.0085038702975035

Epoch: 6| Step: 5
Training loss: 1.8881968259811401
Validation loss: 2.0183817750664166

Epoch: 6| Step: 6
Training loss: 2.726799964904785
Validation loss: 2.007857576493294

Epoch: 6| Step: 7
Training loss: 3.365572690963745
Validation loss: 2.007431871147566

Epoch: 6| Step: 8
Training loss: 1.7147932052612305
Validation loss: 2.0209975011887087

Epoch: 6| Step: 9
Training loss: 1.8895084857940674
Validation loss: 2.0354410397109164

Epoch: 6| Step: 10
Training loss: 2.547616481781006
Validation loss: 2.0086218964669014

Epoch: 6| Step: 11
Training loss: 2.0304484367370605
Validation loss: 2.0192943080779044

Epoch: 6| Step: 12
Training loss: 1.9908649921417236
Validation loss: 2.0097548730911745

Epoch: 6| Step: 13
Training loss: 1.494113564491272
Validation loss: 2.0279506227021575

Epoch: 63| Step: 0
Training loss: 2.346210241317749
Validation loss: 2.00892876296915

Epoch: 6| Step: 1
Training loss: 3.0486440658569336
Validation loss: 2.0089515639889624

Epoch: 6| Step: 2
Training loss: 1.739170789718628
Validation loss: 2.03025242077407

Epoch: 6| Step: 3
Training loss: 1.7604776620864868
Validation loss: 2.0207862495094218

Epoch: 6| Step: 4
Training loss: 2.051271915435791
Validation loss: 2.0306255561049267

Epoch: 6| Step: 5
Training loss: 2.0851337909698486
Validation loss: 2.0214768737875004

Epoch: 6| Step: 6
Training loss: 2.3046393394470215
Validation loss: 2.026084623029155

Epoch: 6| Step: 7
Training loss: 2.010484457015991
Validation loss: 2.0168955326080322

Epoch: 6| Step: 8
Training loss: 2.30787992477417
Validation loss: 2.0048585245686192

Epoch: 6| Step: 9
Training loss: 2.02758526802063
Validation loss: 2.022961055078814

Epoch: 6| Step: 10
Training loss: 1.8547857999801636
Validation loss: 2.017666902593387

Epoch: 6| Step: 11
Training loss: 2.7512316703796387
Validation loss: 2.016055332717075

Epoch: 6| Step: 12
Training loss: 2.3302016258239746
Validation loss: 2.011430351964889

Epoch: 6| Step: 13
Training loss: 2.1137795448303223
Validation loss: 2.0402126184073825

Epoch: 64| Step: 0
Training loss: 2.010519504547119
Validation loss: 1.992308150055588

Epoch: 6| Step: 1
Training loss: 2.0611259937286377
Validation loss: 2.028626116373206

Epoch: 6| Step: 2
Training loss: 2.426107883453369
Validation loss: 2.021122594033518

Epoch: 6| Step: 3
Training loss: 2.0443034172058105
Validation loss: 2.0183701925380255

Epoch: 6| Step: 4
Training loss: 2.333207130432129
Validation loss: 2.030472013258165

Epoch: 6| Step: 5
Training loss: 1.7585006952285767
Validation loss: 2.0156820794587493

Epoch: 6| Step: 6
Training loss: 1.9436991214752197
Validation loss: 2.010421411965483

Epoch: 6| Step: 7
Training loss: 1.9096615314483643
Validation loss: 2.023305308434271

Epoch: 6| Step: 8
Training loss: 2.011171340942383
Validation loss: 2.033770106172049

Epoch: 6| Step: 9
Training loss: 2.626229763031006
Validation loss: 2.000104065864317

Epoch: 6| Step: 10
Training loss: 2.2854442596435547
Validation loss: 2.0319159671824467

Epoch: 6| Step: 11
Training loss: 1.6314396858215332
Validation loss: 2.0134921778914747

Epoch: 6| Step: 12
Training loss: 2.7216081619262695
Validation loss: 2.0095278191310104

Epoch: 6| Step: 13
Training loss: 3.469219446182251
Validation loss: 2.0254524446302846

Epoch: 65| Step: 0
Training loss: 2.7367844581604004
Validation loss: 2.0151672542736097

Epoch: 6| Step: 1
Training loss: 2.237349033355713
Validation loss: 2.0231120150576354

Epoch: 6| Step: 2
Training loss: 2.222651958465576
Validation loss: 2.020122960049619

Epoch: 6| Step: 3
Training loss: 1.9061050415039062
Validation loss: 2.0078730890827794

Epoch: 6| Step: 4
Training loss: 2.0985889434814453
Validation loss: 2.0019714217032156

Epoch: 6| Step: 5
Training loss: 2.3529820442199707
Validation loss: 2.002262635897565

Epoch: 6| Step: 6
Training loss: 2.2736992835998535
Validation loss: 2.013405017955329

Epoch: 6| Step: 7
Training loss: 1.871297001838684
Validation loss: 2.0112859715697584

Epoch: 6| Step: 8
Training loss: 2.2356109619140625
Validation loss: 2.0060085801668066

Epoch: 6| Step: 9
Training loss: 2.4982666969299316
Validation loss: 2.0230857018501527

Epoch: 6| Step: 10
Training loss: 1.758460521697998
Validation loss: 2.011727520214614

Epoch: 6| Step: 11
Training loss: 2.58357572555542
Validation loss: 2.0226270742313837

Epoch: 6| Step: 12
Training loss: 1.829000473022461
Validation loss: 2.0263357111202773

Epoch: 6| Step: 13
Training loss: 2.3389058113098145
Validation loss: 2.0269780440997054

Epoch: 66| Step: 0
Training loss: 2.2634410858154297
Validation loss: 2.0169043053862867

Epoch: 6| Step: 1
Training loss: 2.0326809883117676
Validation loss: 2.03448280595964

Epoch: 6| Step: 2
Training loss: 2.5391674041748047
Validation loss: 2.015735110928935

Epoch: 6| Step: 3
Training loss: 1.7187212705612183
Validation loss: 2.0168893542341007

Epoch: 6| Step: 4
Training loss: 2.644545316696167
Validation loss: 2.009272192114143

Epoch: 6| Step: 5
Training loss: 2.2571699619293213
Validation loss: 2.0093066769261516

Epoch: 6| Step: 6
Training loss: 1.7442493438720703
Validation loss: 2.0106502912377797

Epoch: 6| Step: 7
Training loss: 2.150546073913574
Validation loss: 2.0205292317175094

Epoch: 6| Step: 8
Training loss: 1.9801113605499268
Validation loss: 2.0176346917306223

Epoch: 6| Step: 9
Training loss: 2.005671262741089
Validation loss: 2.0160153937596146

Epoch: 6| Step: 10
Training loss: 2.539994239807129
Validation loss: 2.0172006686528525

Epoch: 6| Step: 11
Training loss: 2.438117504119873
Validation loss: 2.0089339543414373

Epoch: 6| Step: 12
Training loss: 1.9066325426101685
Validation loss: 2.0190676796820854

Epoch: 6| Step: 13
Training loss: 2.57242488861084
Validation loss: 2.003722042165777

Epoch: 67| Step: 0
Training loss: 2.3019230365753174
Validation loss: 2.020785249689574

Epoch: 6| Step: 1
Training loss: 2.4748525619506836
Validation loss: 2.026138388982383

Epoch: 6| Step: 2
Training loss: 2.2487025260925293
Validation loss: 2.015796496022132

Epoch: 6| Step: 3
Training loss: 2.197819471359253
Validation loss: 1.9974399253886232

Epoch: 6| Step: 4
Training loss: 1.4100689888000488
Validation loss: 2.002623849017646

Epoch: 6| Step: 5
Training loss: 2.4809224605560303
Validation loss: 2.0141005310960995

Epoch: 6| Step: 6
Training loss: 2.238892078399658
Validation loss: 2.025048525102677

Epoch: 6| Step: 7
Training loss: 2.1978464126586914
Validation loss: 2.0242658533075804

Epoch: 6| Step: 8
Training loss: 2.817763090133667
Validation loss: 1.9993123367268553

Epoch: 6| Step: 9
Training loss: 1.7687846422195435
Validation loss: 2.0148074088558072

Epoch: 6| Step: 10
Training loss: 1.9435080289840698
Validation loss: 2.0059018186343613

Epoch: 6| Step: 11
Training loss: 2.1292519569396973
Validation loss: 2.0295063116217174

Epoch: 6| Step: 12
Training loss: 2.2506911754608154
Validation loss: 2.014078696568807

Epoch: 6| Step: 13
Training loss: 1.9440176486968994
Validation loss: 2.0136306247403546

Epoch: 68| Step: 0
Training loss: 2.338374614715576
Validation loss: 2.0272675483457503

Epoch: 6| Step: 1
Training loss: 2.119094133377075
Validation loss: 2.006978673319663

Epoch: 6| Step: 2
Training loss: 2.082815647125244
Validation loss: 2.0082515426861343

Epoch: 6| Step: 3
Training loss: 2.7304368019104004
Validation loss: 2.027806169243269

Epoch: 6| Step: 4
Training loss: 2.0492067337036133
Validation loss: 2.0251190098383094

Epoch: 6| Step: 5
Training loss: 2.1924872398376465
Validation loss: 2.028884321130732

Epoch: 6| Step: 6
Training loss: 1.8619883060455322
Validation loss: 2.0218222884721655

Epoch: 6| Step: 7
Training loss: 2.5019381046295166
Validation loss: 2.0172909305941675

Epoch: 6| Step: 8
Training loss: 2.4528656005859375
Validation loss: 2.0088581244150796

Epoch: 6| Step: 9
Training loss: 2.3433837890625
Validation loss: 2.0023313465938775

Epoch: 6| Step: 10
Training loss: 1.9780497550964355
Validation loss: 1.994639527413153

Epoch: 6| Step: 11
Training loss: 2.2424564361572266
Validation loss: 2.017572582408946

Epoch: 6| Step: 12
Training loss: 1.5057833194732666
Validation loss: 2.015700404362012

Epoch: 6| Step: 13
Training loss: 1.8782907724380493
Validation loss: 2.012997910540591

Epoch: 69| Step: 0
Training loss: 1.9068211317062378
Validation loss: 2.0376799234779934

Epoch: 6| Step: 1
Training loss: 2.409909725189209
Validation loss: 2.013271798369705

Epoch: 6| Step: 2
Training loss: 2.194179058074951
Validation loss: 2.017839070289366

Epoch: 6| Step: 3
Training loss: 1.691359281539917
Validation loss: 2.0112356703768492

Epoch: 6| Step: 4
Training loss: 2.5235323905944824
Validation loss: 2.013787443919848

Epoch: 6| Step: 5
Training loss: 1.761061429977417
Validation loss: 2.0169161058241323

Epoch: 6| Step: 6
Training loss: 2.246283531188965
Validation loss: 2.009616069896247

Epoch: 6| Step: 7
Training loss: 2.087136745452881
Validation loss: 1.9911656777064006

Epoch: 6| Step: 8
Training loss: 2.334566593170166
Validation loss: 2.0257089907123196

Epoch: 6| Step: 9
Training loss: 2.6104745864868164
Validation loss: 2.0307270198739986

Epoch: 6| Step: 10
Training loss: 2.265958070755005
Validation loss: 2.021628728476904

Epoch: 6| Step: 11
Training loss: 2.0175466537475586
Validation loss: 2.0210083517976987

Epoch: 6| Step: 12
Training loss: 2.174942970275879
Validation loss: 2.0125193416431384

Epoch: 6| Step: 13
Training loss: 2.293424606323242
Validation loss: 2.0312038506231

Epoch: 70| Step: 0
Training loss: 2.0828046798706055
Validation loss: 2.0247698189109884

Epoch: 6| Step: 1
Training loss: 2.076369285583496
Validation loss: 2.010236301729756

Epoch: 6| Step: 2
Training loss: 2.736243724822998
Validation loss: 2.017473114434109

Epoch: 6| Step: 3
Training loss: 2.690886974334717
Validation loss: 2.0151675260195168

Epoch: 6| Step: 4
Training loss: 1.9610705375671387
Validation loss: 2.0045305964767293

Epoch: 6| Step: 5
Training loss: 1.9794361591339111
Validation loss: 2.0251161180516726

Epoch: 6| Step: 6
Training loss: 2.71634578704834
Validation loss: 2.024193068986298

Epoch: 6| Step: 7
Training loss: 1.5510261058807373
Validation loss: 2.01620937291012

Epoch: 6| Step: 8
Training loss: 2.788625955581665
Validation loss: 2.0073356051598825

Epoch: 6| Step: 9
Training loss: 2.029327154159546
Validation loss: 2.0215941129192228

Epoch: 6| Step: 10
Training loss: 1.8168336153030396
Validation loss: 2.040029841084634

Epoch: 6| Step: 11
Training loss: 2.1476078033447266
Validation loss: 2.020617300464261

Epoch: 6| Step: 12
Training loss: 2.114564895629883
Validation loss: 2.024154705386008

Epoch: 6| Step: 13
Training loss: 1.2822041511535645
Validation loss: 2.0066066121542327

Epoch: 71| Step: 0
Training loss: 1.7898151874542236
Validation loss: 1.9973464319782872

Epoch: 6| Step: 1
Training loss: 2.386119842529297
Validation loss: 2.0261560627209243

Epoch: 6| Step: 2
Training loss: 2.6167101860046387
Validation loss: 2.0042510545381935

Epoch: 6| Step: 3
Training loss: 1.5487029552459717
Validation loss: 2.0088949908492384

Epoch: 6| Step: 4
Training loss: 2.2835888862609863
Validation loss: 2.0070920118721585

Epoch: 6| Step: 5
Training loss: 2.6045212745666504
Validation loss: 2.035000119158017

Epoch: 6| Step: 6
Training loss: 2.4479947090148926
Validation loss: 2.014487240904121

Epoch: 6| Step: 7
Training loss: 1.9234492778778076
Validation loss: 2.013923905229056

Epoch: 6| Step: 8
Training loss: 2.6683056354522705
Validation loss: 2.0056597045672837

Epoch: 6| Step: 9
Training loss: 2.306422710418701
Validation loss: 2.026390052610828

Epoch: 6| Step: 10
Training loss: 2.1117300987243652
Validation loss: 2.0259988128498034

Epoch: 6| Step: 11
Training loss: 1.9401010274887085
Validation loss: 2.0262433841664302

Epoch: 6| Step: 12
Training loss: 1.6239500045776367
Validation loss: 2.0145283757999377

Epoch: 6| Step: 13
Training loss: 2.29472279548645
Validation loss: 2.0057713575260614

Epoch: 72| Step: 0
Training loss: 2.1229515075683594
Validation loss: 2.0098573623165006

Epoch: 6| Step: 1
Training loss: 1.8602566719055176
Validation loss: 2.020042206651421

Epoch: 6| Step: 2
Training loss: 2.335231304168701
Validation loss: 2.0062612166968723

Epoch: 6| Step: 3
Training loss: 1.892137050628662
Validation loss: 2.024073680241903

Epoch: 6| Step: 4
Training loss: 2.4258551597595215
Validation loss: 2.0216554159759195

Epoch: 6| Step: 5
Training loss: 2.472353219985962
Validation loss: 2.0406822235353532

Epoch: 6| Step: 6
Training loss: 2.828474998474121
Validation loss: 2.0007748744821034

Epoch: 6| Step: 7
Training loss: 2.120600700378418
Validation loss: 2.010552124310565

Epoch: 6| Step: 8
Training loss: 2.8377695083618164
Validation loss: 2.0280146470633884

Epoch: 6| Step: 9
Training loss: 2.073286294937134
Validation loss: 2.0203403016572357

Epoch: 6| Step: 10
Training loss: 1.9454340934753418
Validation loss: 2.004659996237806

Epoch: 6| Step: 11
Training loss: 1.523409128189087
Validation loss: 2.0205603620057464

Epoch: 6| Step: 12
Training loss: 2.316622734069824
Validation loss: 2.0155660490835867

Epoch: 6| Step: 13
Training loss: 1.5788748264312744
Validation loss: 2.018906718941145

Epoch: 73| Step: 0
Training loss: 1.986366629600525
Validation loss: 2.0259502908234954

Epoch: 6| Step: 1
Training loss: 1.8288302421569824
Validation loss: 2.0203157522345103

Epoch: 6| Step: 2
Training loss: 2.159306526184082
Validation loss: 2.0013172729040987

Epoch: 6| Step: 3
Training loss: 2.0591301918029785
Validation loss: 2.022910496240021

Epoch: 6| Step: 4
Training loss: 2.3554961681365967
Validation loss: 1.9957016027101906

Epoch: 6| Step: 5
Training loss: 2.736380100250244
Validation loss: 2.0094441675370738

Epoch: 6| Step: 6
Training loss: 2.3576407432556152
Validation loss: 2.013281560713245

Epoch: 6| Step: 7
Training loss: 2.178607702255249
Validation loss: 2.000495710680562

Epoch: 6| Step: 8
Training loss: 1.6553261280059814
Validation loss: 2.013670172742618

Epoch: 6| Step: 9
Training loss: 1.9949641227722168
Validation loss: 2.0207524581622054

Epoch: 6| Step: 10
Training loss: 2.345574378967285
Validation loss: 1.999638762525333

Epoch: 6| Step: 11
Training loss: 2.4751601219177246
Validation loss: 2.0270483839896416

Epoch: 6| Step: 12
Training loss: 2.3493406772613525
Validation loss: 2.0213894485145487

Epoch: 6| Step: 13
Training loss: 1.8592000007629395
Validation loss: 2.019054610242126

Epoch: 74| Step: 0
Training loss: 2.031068801879883
Validation loss: 2.0199010859253588

Epoch: 6| Step: 1
Training loss: 2.7679319381713867
Validation loss: 2.000370276871548

Epoch: 6| Step: 2
Training loss: 2.158304214477539
Validation loss: 2.0277737443165114

Epoch: 6| Step: 3
Training loss: 1.5029802322387695
Validation loss: 2.0208265460947508

Epoch: 6| Step: 4
Training loss: 2.3238282203674316
Validation loss: 2.0049540612005416

Epoch: 6| Step: 5
Training loss: 1.727061152458191
Validation loss: 2.018313996253475

Epoch: 6| Step: 6
Training loss: 1.8161989450454712
Validation loss: 2.0315417410224996

Epoch: 6| Step: 7
Training loss: 1.9656457901000977
Validation loss: 2.004500650590466

Epoch: 6| Step: 8
Training loss: 2.1453323364257812
Validation loss: 2.018027071029909

Epoch: 6| Step: 9
Training loss: 1.7621184587478638
Validation loss: 2.012823507349978

Epoch: 6| Step: 10
Training loss: 2.828282594680786
Validation loss: 2.0036253621501308

Epoch: 6| Step: 11
Training loss: 1.7799609899520874
Validation loss: 2.0159399201793056

Epoch: 6| Step: 12
Training loss: 2.540527820587158
Validation loss: 2.0238302100089287

Epoch: 6| Step: 13
Training loss: 3.582451820373535
Validation loss: 2.0191495034002487

Epoch: 75| Step: 0
Training loss: 2.1059951782226562
Validation loss: 2.015330819673436

Epoch: 6| Step: 1
Training loss: 2.9195141792297363
Validation loss: 2.0098452747509046

Epoch: 6| Step: 2
Training loss: 2.4859681129455566
Validation loss: 2.0197123917200233

Epoch: 6| Step: 3
Training loss: 2.634192943572998
Validation loss: 2.005442726996637

Epoch: 6| Step: 4
Training loss: 2.383512258529663
Validation loss: 2.0248089810853362

Epoch: 6| Step: 5
Training loss: 1.6452813148498535
Validation loss: 2.0282348881485643

Epoch: 6| Step: 6
Training loss: 1.6440675258636475
Validation loss: 2.0122866348553727

Epoch: 6| Step: 7
Training loss: 2.2562475204467773
Validation loss: 2.023078990238969

Epoch: 6| Step: 8
Training loss: 1.7642736434936523
Validation loss: 1.9960038303047098

Epoch: 6| Step: 9
Training loss: 2.4789469242095947
Validation loss: 2.0024107809989684

Epoch: 6| Step: 10
Training loss: 2.144751787185669
Validation loss: 2.016879904654718

Epoch: 6| Step: 11
Training loss: 1.674431562423706
Validation loss: 2.020989937167014

Epoch: 6| Step: 12
Training loss: 2.0332343578338623
Validation loss: 2.0345113572253974

Epoch: 6| Step: 13
Training loss: 1.940305471420288
Validation loss: 2.0101146736452655

Epoch: 76| Step: 0
Training loss: 2.9606716632843018
Validation loss: 2.0290164921873357

Epoch: 6| Step: 1
Training loss: 1.7213411331176758
Validation loss: 2.0150309198646137

Epoch: 6| Step: 2
Training loss: 2.31901216506958
Validation loss: 2.029917219633697

Epoch: 6| Step: 3
Training loss: 1.557739019393921
Validation loss: 2.0448626766922655

Epoch: 6| Step: 4
Training loss: 1.6351902484893799
Validation loss: 2.0091776258202008

Epoch: 6| Step: 5
Training loss: 1.966343879699707
Validation loss: 2.0048931824263705

Epoch: 6| Step: 6
Training loss: 1.8672142028808594
Validation loss: 2.0228626830603487

Epoch: 6| Step: 7
Training loss: 1.8629015684127808
Validation loss: 2.0133684809489916

Epoch: 6| Step: 8
Training loss: 2.2013583183288574
Validation loss: 2.0257410823657946

Epoch: 6| Step: 9
Training loss: 2.3267734050750732
Validation loss: 2.019345892372952

Epoch: 6| Step: 10
Training loss: 2.3669745922088623
Validation loss: 2.033923036308699

Epoch: 6| Step: 11
Training loss: 2.3857293128967285
Validation loss: 2.0004733775251653

Epoch: 6| Step: 12
Training loss: 2.294912815093994
Validation loss: 2.017899372244394

Epoch: 6| Step: 13
Training loss: 3.755925416946411
Validation loss: 2.00387482489309

Epoch: 77| Step: 0
Training loss: 2.0306777954101562
Validation loss: 2.0125341030859176

Epoch: 6| Step: 1
Training loss: 1.8745431900024414
Validation loss: 2.014453080392653

Epoch: 6| Step: 2
Training loss: 1.9119051694869995
Validation loss: 2.017499816033148

Epoch: 6| Step: 3
Training loss: 2.130488395690918
Validation loss: 2.009874789945541

Epoch: 6| Step: 4
Training loss: 1.9330503940582275
Validation loss: 2.02634326616923

Epoch: 6| Step: 5
Training loss: 2.022988796234131
Validation loss: 2.0184413130565355

Epoch: 6| Step: 6
Training loss: 2.5735416412353516
Validation loss: 2.0014033625202794

Epoch: 6| Step: 7
Training loss: 2.074427843093872
Validation loss: 2.0237147910620576

Epoch: 6| Step: 8
Training loss: 2.1009130477905273
Validation loss: 2.0048532409052693

Epoch: 6| Step: 9
Training loss: 2.415536880493164
Validation loss: 2.0075263759141326

Epoch: 6| Step: 10
Training loss: 2.7320895195007324
Validation loss: 2.0196657629423242

Epoch: 6| Step: 11
Training loss: 1.8284575939178467
Validation loss: 2.0069009680901804

Epoch: 6| Step: 12
Training loss: 2.339799165725708
Validation loss: 2.0098873671664985

Epoch: 6| Step: 13
Training loss: 2.825932502746582
Validation loss: 2.039696949784474

Epoch: 78| Step: 0
Training loss: 2.5362539291381836
Validation loss: 1.9961213950187928

Epoch: 6| Step: 1
Training loss: 2.597808837890625
Validation loss: 2.024121815158475

Epoch: 6| Step: 2
Training loss: 2.5232644081115723
Validation loss: 2.0147131976260932

Epoch: 6| Step: 3
Training loss: 2.2315001487731934
Validation loss: 2.0309016794286747

Epoch: 6| Step: 4
Training loss: 1.865221619606018
Validation loss: 2.0111154266583022

Epoch: 6| Step: 5
Training loss: 2.0258824825286865
Validation loss: 2.02850006985408

Epoch: 6| Step: 6
Training loss: 2.39633846282959
Validation loss: 2.042243011536137

Epoch: 6| Step: 7
Training loss: 2.7499489784240723
Validation loss: 2.0088922580083213

Epoch: 6| Step: 8
Training loss: 1.8980520963668823
Validation loss: 2.0168762950487036

Epoch: 6| Step: 9
Training loss: 2.186616897583008
Validation loss: 2.0192747500634964

Epoch: 6| Step: 10
Training loss: 1.7311315536499023
Validation loss: 2.0252912993072183

Epoch: 6| Step: 11
Training loss: 1.862622618675232
Validation loss: 2.0108724576170727

Epoch: 6| Step: 12
Training loss: 1.7531027793884277
Validation loss: 2.0134016980407057

Epoch: 6| Step: 13
Training loss: 2.0357205867767334
Validation loss: 2.015973085998207

Epoch: 79| Step: 0
Training loss: 2.085190773010254
Validation loss: 2.038456873227191

Epoch: 6| Step: 1
Training loss: 2.3809657096862793
Validation loss: 2.015801336175652

Epoch: 6| Step: 2
Training loss: 2.1533443927764893
Validation loss: 2.034748543975174

Epoch: 6| Step: 3
Training loss: 2.4683070182800293
Validation loss: 2.021116136222757

Epoch: 6| Step: 4
Training loss: 2.409149646759033
Validation loss: 2.0153240426894157

Epoch: 6| Step: 5
Training loss: 1.5883426666259766
Validation loss: 2.00912570440641

Epoch: 6| Step: 6
Training loss: 1.6890602111816406
Validation loss: 2.0217384087142123

Epoch: 6| Step: 7
Training loss: 1.673060417175293
Validation loss: 2.028276592172602

Epoch: 6| Step: 8
Training loss: 2.4758920669555664
Validation loss: 2.022797138460221

Epoch: 6| Step: 9
Training loss: 1.8266098499298096
Validation loss: 2.016676925843762

Epoch: 6| Step: 10
Training loss: 2.6630139350891113
Validation loss: 2.024955969984813

Epoch: 6| Step: 11
Training loss: 2.282567024230957
Validation loss: 2.0142326816435783

Epoch: 6| Step: 12
Training loss: 2.0801968574523926
Validation loss: 2.0147417591464136

Epoch: 6| Step: 13
Training loss: 2.690356731414795
Validation loss: 2.0270155847713514

Epoch: 80| Step: 0
Training loss: 1.8958224058151245
Validation loss: 2.0257533416953137

Epoch: 6| Step: 1
Training loss: 2.047001838684082
Validation loss: 2.007151496025824

Epoch: 6| Step: 2
Training loss: 2.0738327503204346
Validation loss: 2.020945804093474

Epoch: 6| Step: 3
Training loss: 1.9872946739196777
Validation loss: 2.013932511370669

Epoch: 6| Step: 4
Training loss: 2.281785726547241
Validation loss: 2.0079562228213073

Epoch: 6| Step: 5
Training loss: 2.772717237472534
Validation loss: 2.0159322638665476

Epoch: 6| Step: 6
Training loss: 2.125284194946289
Validation loss: 1.9965178953704013

Epoch: 6| Step: 7
Training loss: 2.6314406394958496
Validation loss: 2.0235575758000857

Epoch: 6| Step: 8
Training loss: 2.1253933906555176
Validation loss: 2.018006440131895

Epoch: 6| Step: 9
Training loss: 2.1220972537994385
Validation loss: 2.0164515049226823

Epoch: 6| Step: 10
Training loss: 1.9439963102340698
Validation loss: 2.026638202769782

Epoch: 6| Step: 11
Training loss: 1.6209208965301514
Validation loss: 2.0209642353878228

Epoch: 6| Step: 12
Training loss: 1.8827813863754272
Validation loss: 2.0231452731676

Epoch: 6| Step: 13
Training loss: 3.0578131675720215
Validation loss: 2.0164881188382386

Epoch: 81| Step: 0
Training loss: 2.2704644203186035
Validation loss: 2.0182385239549863

Epoch: 6| Step: 1
Training loss: 2.7926647663116455
Validation loss: 2.023298792941596

Epoch: 6| Step: 2
Training loss: 2.8334121704101562
Validation loss: 2.0174412752992366

Epoch: 6| Step: 3
Training loss: 2.17708158493042
Validation loss: 2.0443066807203394

Epoch: 6| Step: 4
Training loss: 1.6999495029449463
Validation loss: 2.0277717780041438

Epoch: 6| Step: 5
Training loss: 1.998165249824524
Validation loss: 2.01098697416244

Epoch: 6| Step: 6
Training loss: 1.8962626457214355
Validation loss: 2.021036522362822

Epoch: 6| Step: 7
Training loss: 2.48539400100708
Validation loss: 2.0210590695822113

Epoch: 6| Step: 8
Training loss: 2.7412054538726807
Validation loss: 2.005214419416202

Epoch: 6| Step: 9
Training loss: 1.975365400314331
Validation loss: 2.0122333675302486

Epoch: 6| Step: 10
Training loss: 1.2627787590026855
Validation loss: 2.0118545998809156

Epoch: 6| Step: 11
Training loss: 1.766190528869629
Validation loss: 2.018417701926283

Epoch: 6| Step: 12
Training loss: 2.4409165382385254
Validation loss: 2.010054108917072

Epoch: 6| Step: 13
Training loss: 1.9786584377288818
Validation loss: 2.0251870283516507

Epoch: 82| Step: 0
Training loss: 1.962852954864502
Validation loss: 1.9994905328237882

Epoch: 6| Step: 1
Training loss: 2.0710015296936035
Validation loss: 2.025986780402481

Epoch: 6| Step: 2
Training loss: 2.0749940872192383
Validation loss: 2.0209293339842107

Epoch: 6| Step: 3
Training loss: 1.6156556606292725
Validation loss: 2.019047026993126

Epoch: 6| Step: 4
Training loss: 2.4253077507019043
Validation loss: 2.0290077860637377

Epoch: 6| Step: 5
Training loss: 1.982593059539795
Validation loss: 2.0087467150021623

Epoch: 6| Step: 6
Training loss: 2.5543341636657715
Validation loss: 2.0276880289918635

Epoch: 6| Step: 7
Training loss: 2.07547664642334
Validation loss: 1.9955910034077142

Epoch: 6| Step: 8
Training loss: 1.4743070602416992
Validation loss: 2.0075971490593365

Epoch: 6| Step: 9
Training loss: 2.2375404834747314
Validation loss: 2.0052043237993793

Epoch: 6| Step: 10
Training loss: 2.3348865509033203
Validation loss: 2.0152676413136144

Epoch: 6| Step: 11
Training loss: 3.112704277038574
Validation loss: 2.0165860819560226

Epoch: 6| Step: 12
Training loss: 2.239964485168457
Validation loss: 2.014220408214036

Epoch: 6| Step: 13
Training loss: 2.037019968032837
Validation loss: 1.9995203812917073

Epoch: 83| Step: 0
Training loss: 1.9043666124343872
Validation loss: 2.0047183023985995

Epoch: 6| Step: 1
Training loss: 1.7604848146438599
Validation loss: 2.0085100819987636

Epoch: 6| Step: 2
Training loss: 2.7917537689208984
Validation loss: 2.018948203773909

Epoch: 6| Step: 3
Training loss: 2.354982852935791
Validation loss: 2.0363925426237044

Epoch: 6| Step: 4
Training loss: 2.3221561908721924
Validation loss: 2.002273739025157

Epoch: 6| Step: 5
Training loss: 1.67362642288208
Validation loss: 1.9965103774942377

Epoch: 6| Step: 6
Training loss: 1.6716541051864624
Validation loss: 1.9996588025041806

Epoch: 6| Step: 7
Training loss: 2.1707754135131836
Validation loss: 2.0229931185322423

Epoch: 6| Step: 8
Training loss: 2.072030782699585
Validation loss: 2.0200158216620006

Epoch: 6| Step: 9
Training loss: 1.9565274715423584
Validation loss: 2.0265748218823503

Epoch: 6| Step: 10
Training loss: 2.0403072834014893
Validation loss: 2.001131811449605

Epoch: 6| Step: 11
Training loss: 2.565232753753662
Validation loss: 2.0090436986697617

Epoch: 6| Step: 12
Training loss: 2.292112350463867
Validation loss: 2.0338714776500577

Epoch: 6| Step: 13
Training loss: 2.324834108352661
Validation loss: 2.00757404809357

Epoch: 84| Step: 0
Training loss: 2.0294480323791504
Validation loss: 2.0415758266243884

Epoch: 6| Step: 1
Training loss: 2.53134822845459
Validation loss: 2.00860696454202

Epoch: 6| Step: 2
Training loss: 2.6915526390075684
Validation loss: 2.011145496881136

Epoch: 6| Step: 3
Training loss: 1.9580180644989014
Validation loss: 2.0276466569592877

Epoch: 6| Step: 4
Training loss: 2.033993721008301
Validation loss: 2.040995260720612

Epoch: 6| Step: 5
Training loss: 1.8424148559570312
Validation loss: 2.015756250709616

Epoch: 6| Step: 6
Training loss: 2.3164286613464355
Validation loss: 2.01934370686931

Epoch: 6| Step: 7
Training loss: 2.2155063152313232
Validation loss: 2.0032352273182203

Epoch: 6| Step: 8
Training loss: 1.8165442943572998
Validation loss: 2.0156418072280062

Epoch: 6| Step: 9
Training loss: 1.7376985549926758
Validation loss: 2.017429567152454

Epoch: 6| Step: 10
Training loss: 2.116647720336914
Validation loss: 2.012071628724375

Epoch: 6| Step: 11
Training loss: 2.244577407836914
Validation loss: 2.024041445024552

Epoch: 6| Step: 12
Training loss: 2.2573494911193848
Validation loss: 2.0185192015863236

Epoch: 6| Step: 13
Training loss: 2.349602699279785
Validation loss: 2.007303939070753

Epoch: 85| Step: 0
Training loss: 2.286686897277832
Validation loss: 2.0038225791787587

Epoch: 6| Step: 1
Training loss: 1.7640843391418457
Validation loss: 2.014365615383271

Epoch: 6| Step: 2
Training loss: 3.1727757453918457
Validation loss: 2.020044337036789

Epoch: 6| Step: 3
Training loss: 1.7923284769058228
Validation loss: 2.0071795883999077

Epoch: 6| Step: 4
Training loss: 2.109757900238037
Validation loss: 2.0233684111666936

Epoch: 6| Step: 5
Training loss: 2.605195999145508
Validation loss: 2.014077350657473

Epoch: 6| Step: 6
Training loss: 2.005464553833008
Validation loss: 2.013560301514082

Epoch: 6| Step: 7
Training loss: 2.351332187652588
Validation loss: 2.0233457549925773

Epoch: 6| Step: 8
Training loss: 3.167341947555542
Validation loss: 2.031956811105051

Epoch: 6| Step: 9
Training loss: 1.6669355630874634
Validation loss: 2.024063023187781

Epoch: 6| Step: 10
Training loss: 1.4866924285888672
Validation loss: 2.0444427215924827

Epoch: 6| Step: 11
Training loss: 1.8740168809890747
Validation loss: 2.0292118800583707

Epoch: 6| Step: 12
Training loss: 1.5282392501831055
Validation loss: 2.03979677795082

Epoch: 6| Step: 13
Training loss: 2.0343918800354004
Validation loss: 2.014080798754128

Epoch: 86| Step: 0
Training loss: 1.9718925952911377
Validation loss: 2.034290588030251

Epoch: 6| Step: 1
Training loss: 2.4699454307556152
Validation loss: 2.0157364465857066

Epoch: 6| Step: 2
Training loss: 2.119147300720215
Validation loss: 2.0049185842596073

Epoch: 6| Step: 3
Training loss: 1.6245827674865723
Validation loss: 2.036152785824191

Epoch: 6| Step: 4
Training loss: 1.9056310653686523
Validation loss: 2.0175420097125474

Epoch: 6| Step: 5
Training loss: 2.0166115760803223
Validation loss: 2.0367533570976666

Epoch: 6| Step: 6
Training loss: 1.7161544561386108
Validation loss: 2.015346965482158

Epoch: 6| Step: 7
Training loss: 2.277632236480713
Validation loss: 2.0182194107322284

Epoch: 6| Step: 8
Training loss: 2.179654598236084
Validation loss: 2.0215456178111415

Epoch: 6| Step: 9
Training loss: 1.9238770008087158
Validation loss: 2.0182518561681113

Epoch: 6| Step: 10
Training loss: 2.309891939163208
Validation loss: 2.022977957161524

Epoch: 6| Step: 11
Training loss: 2.6481986045837402
Validation loss: 2.017174349036268

Epoch: 6| Step: 12
Training loss: 2.18039608001709
Validation loss: 2.0238672494888306

Epoch: 6| Step: 13
Training loss: 2.531350612640381
Validation loss: 2.0081103206962667

Epoch: 87| Step: 0
Training loss: 2.0205881595611572
Validation loss: 2.005005148149306

Epoch: 6| Step: 1
Training loss: 2.453347682952881
Validation loss: 2.0035592586763444

Epoch: 6| Step: 2
Training loss: 2.2178194522857666
Validation loss: 2.022302989036806

Epoch: 6| Step: 3
Training loss: 2.219292402267456
Validation loss: 2.026155869166056

Epoch: 6| Step: 4
Training loss: 1.6901800632476807
Validation loss: 2.010895782901395

Epoch: 6| Step: 5
Training loss: 2.910294532775879
Validation loss: 2.0082811899082635

Epoch: 6| Step: 6
Training loss: 2.1339454650878906
Validation loss: 1.9921579309689101

Epoch: 6| Step: 7
Training loss: 2.3186464309692383
Validation loss: 2.009664721386407

Epoch: 6| Step: 8
Training loss: 2.1405694484710693
Validation loss: 1.9968837409891107

Epoch: 6| Step: 9
Training loss: 2.418933391571045
Validation loss: 2.0073649524360575

Epoch: 6| Step: 10
Training loss: 1.6572434902191162
Validation loss: 2.0284439261241625

Epoch: 6| Step: 11
Training loss: 1.9596939086914062
Validation loss: 2.0201410349979194

Epoch: 6| Step: 12
Training loss: 1.3077231645584106
Validation loss: 2.011401717380811

Epoch: 6| Step: 13
Training loss: 2.800055980682373
Validation loss: 2.0061357995515228

Epoch: 88| Step: 0
Training loss: 1.8958346843719482
Validation loss: 2.0075379174242736

Epoch: 6| Step: 1
Training loss: 2.614412784576416
Validation loss: 2.007407364024911

Epoch: 6| Step: 2
Training loss: 1.9169464111328125
Validation loss: 1.9910533043646044

Epoch: 6| Step: 3
Training loss: 1.6859447956085205
Validation loss: 2.0162778733879008

Epoch: 6| Step: 4
Training loss: 2.4684643745422363
Validation loss: 2.012662902955086

Epoch: 6| Step: 5
Training loss: 2.1543679237365723
Validation loss: 2.0206609874643306

Epoch: 6| Step: 6
Training loss: 2.6349682807922363
Validation loss: 2.0167404246586624

Epoch: 6| Step: 7
Training loss: 2.1398115158081055
Validation loss: 2.028546961404944

Epoch: 6| Step: 8
Training loss: 2.346123456954956
Validation loss: 2.011739371925272

Epoch: 6| Step: 9
Training loss: 2.0050206184387207
Validation loss: 2.0221934010905604

Epoch: 6| Step: 10
Training loss: 2.237992525100708
Validation loss: 2.018092873275921

Epoch: 6| Step: 11
Training loss: 2.1806840896606445
Validation loss: 2.019540822634133

Epoch: 6| Step: 12
Training loss: 1.6571307182312012
Validation loss: 2.0127911106232674

Epoch: 6| Step: 13
Training loss: 1.6179745197296143
Validation loss: 2.0213092424536265

Epoch: 89| Step: 0
Training loss: 2.152956485748291
Validation loss: 2.006047858986803

Epoch: 6| Step: 1
Training loss: 1.5900695323944092
Validation loss: 2.0085911468792985

Epoch: 6| Step: 2
Training loss: 2.211091995239258
Validation loss: 2.0216807883272887

Epoch: 6| Step: 3
Training loss: 2.5677764415740967
Validation loss: 2.01038029373333

Epoch: 6| Step: 4
Training loss: 1.6005825996398926
Validation loss: 2.0252492299643894

Epoch: 6| Step: 5
Training loss: 2.81365966796875
Validation loss: 2.004497584476266

Epoch: 6| Step: 6
Training loss: 2.686123847961426
Validation loss: 2.014156562025829

Epoch: 6| Step: 7
Training loss: 1.8841884136199951
Validation loss: 2.0313929139926867

Epoch: 6| Step: 8
Training loss: 2.4366888999938965
Validation loss: 2.047179821998842

Epoch: 6| Step: 9
Training loss: 2.0849571228027344
Validation loss: 1.9863429838611233

Epoch: 6| Step: 10
Training loss: 1.8043885231018066
Validation loss: 2.030187478629492

Epoch: 6| Step: 11
Training loss: 1.936492919921875
Validation loss: 1.9878799812768095

Epoch: 6| Step: 12
Training loss: 1.6232595443725586
Validation loss: 2.0092738930897047

Epoch: 6| Step: 13
Training loss: 2.8692307472229004
Validation loss: 2.025907042846885

Epoch: 90| Step: 0
Training loss: 2.0971689224243164
Validation loss: 2.0302329089051936

Epoch: 6| Step: 1
Training loss: 2.31782865524292
Validation loss: 2.02217960357666

Epoch: 6| Step: 2
Training loss: 3.0919480323791504
Validation loss: 2.020809406875282

Epoch: 6| Step: 3
Training loss: 1.11138916015625
Validation loss: 2.0195546342480566

Epoch: 6| Step: 4
Training loss: 1.9701752662658691
Validation loss: 2.0262110387125323

Epoch: 6| Step: 5
Training loss: 1.8959304094314575
Validation loss: 2.034698035127373

Epoch: 6| Step: 6
Training loss: 2.1577792167663574
Validation loss: 2.011748085739792

Epoch: 6| Step: 7
Training loss: 1.9177000522613525
Validation loss: 2.0328522010516097

Epoch: 6| Step: 8
Training loss: 1.547729253768921
Validation loss: 2.024708068499001

Epoch: 6| Step: 9
Training loss: 2.2308475971221924
Validation loss: 2.0263672362091723

Epoch: 6| Step: 10
Training loss: 2.5535635948181152
Validation loss: 2.026097338686707

Epoch: 6| Step: 11
Training loss: 2.194826126098633
Validation loss: 2.024471604695884

Epoch: 6| Step: 12
Training loss: 2.609506130218506
Validation loss: 2.033132800491907

Epoch: 6| Step: 13
Training loss: 2.2351534366607666
Validation loss: 2.0243395720758746

Epoch: 91| Step: 0
Training loss: 1.9323029518127441
Validation loss: 2.000345459548376

Epoch: 6| Step: 1
Training loss: 1.5947749614715576
Validation loss: 1.9998598483300978

Epoch: 6| Step: 2
Training loss: 1.6218478679656982
Validation loss: 2.022358194474251

Epoch: 6| Step: 3
Training loss: 2.2055070400238037
Validation loss: 2.0303682960489744

Epoch: 6| Step: 4
Training loss: 2.296938896179199
Validation loss: 1.9968099100615389

Epoch: 6| Step: 5
Training loss: 2.554889678955078
Validation loss: 1.9981510203371766

Epoch: 6| Step: 6
Training loss: 1.5129969120025635
Validation loss: 2.0037364523897887

Epoch: 6| Step: 7
Training loss: 1.839895248413086
Validation loss: 2.0235741279458486

Epoch: 6| Step: 8
Training loss: 2.326744556427002
Validation loss: 2.0221903195945163

Epoch: 6| Step: 9
Training loss: 2.577301263809204
Validation loss: 2.0423127630705475

Epoch: 6| Step: 10
Training loss: 3.3980712890625
Validation loss: 2.0191950221215524

Epoch: 6| Step: 11
Training loss: 2.1554033756256104
Validation loss: 2.0015333403823194

Epoch: 6| Step: 12
Training loss: 1.5573737621307373
Validation loss: 2.020340927185551

Epoch: 6| Step: 13
Training loss: 1.818543791770935
Validation loss: 2.006731640908026

Epoch: 92| Step: 0
Training loss: 2.5573666095733643
Validation loss: 2.000081895500101

Epoch: 6| Step: 1
Training loss: 1.535484790802002
Validation loss: 2.0292697363002326

Epoch: 6| Step: 2
Training loss: 2.0061776638031006
Validation loss: 1.9998533213010399

Epoch: 6| Step: 3
Training loss: 2.272770881652832
Validation loss: 2.0030262111335673

Epoch: 6| Step: 4
Training loss: 2.2246623039245605
Validation loss: 1.9999347476549045

Epoch: 6| Step: 5
Training loss: 1.774888038635254
Validation loss: 2.0217883099791822

Epoch: 6| Step: 6
Training loss: 2.2888970375061035
Validation loss: 2.041301042802872

Epoch: 6| Step: 7
Training loss: 2.466862678527832
Validation loss: 2.0155985214376964

Epoch: 6| Step: 8
Training loss: 1.9983279705047607
Validation loss: 1.9949248016521495

Epoch: 6| Step: 9
Training loss: 1.959657907485962
Validation loss: 2.00817100719739

Epoch: 6| Step: 10
Training loss: 2.4519710540771484
Validation loss: 2.01496026849234

Epoch: 6| Step: 11
Training loss: 2.112536907196045
Validation loss: 2.0362191956530333

Epoch: 6| Step: 12
Training loss: 2.0182361602783203
Validation loss: 2.0137565905048

Epoch: 6| Step: 13
Training loss: 1.970670461654663
Validation loss: 2.0212765534718833

Epoch: 93| Step: 0
Training loss: 2.072944164276123
Validation loss: 1.9972080774204706

Epoch: 6| Step: 1
Training loss: 1.9981721639633179
Validation loss: 2.0278419448483374

Epoch: 6| Step: 2
Training loss: 2.140012264251709
Validation loss: 2.0113508957688526

Epoch: 6| Step: 3
Training loss: 1.7332861423492432
Validation loss: 2.012631711139474

Epoch: 6| Step: 4
Training loss: 3.068082094192505
Validation loss: 2.0111600750236103

Epoch: 6| Step: 5
Training loss: 1.7896273136138916
Validation loss: 2.018260036745379

Epoch: 6| Step: 6
Training loss: 1.9760936498641968
Validation loss: 2.0311288115798787

Epoch: 6| Step: 7
Training loss: 1.43276047706604
Validation loss: 2.0090784154912478

Epoch: 6| Step: 8
Training loss: 2.543813467025757
Validation loss: 2.005502421368835

Epoch: 6| Step: 9
Training loss: 2.0108189582824707
Validation loss: 2.0031304359436035

Epoch: 6| Step: 10
Training loss: 2.107166290283203
Validation loss: 2.042300734468686

Epoch: 6| Step: 11
Training loss: 2.191920280456543
Validation loss: 2.0099137777923257

Epoch: 6| Step: 12
Training loss: 2.337113380432129
Validation loss: 2.021727356859433

Epoch: 6| Step: 13
Training loss: 1.8155043125152588
Validation loss: 2.039155278154599

Epoch: 94| Step: 0
Training loss: 1.5900077819824219
Validation loss: 2.008892907891222

Epoch: 6| Step: 1
Training loss: 2.5390677452087402
Validation loss: 2.0164277220285065

Epoch: 6| Step: 2
Training loss: 2.959080457687378
Validation loss: 2.0238163394312703

Epoch: 6| Step: 3
Training loss: 2.272979736328125
Validation loss: 2.0275483977410103

Epoch: 6| Step: 4
Training loss: 2.637907028198242
Validation loss: 2.003234524880686

Epoch: 6| Step: 5
Training loss: 2.3008065223693848
Validation loss: 2.0016183289148475

Epoch: 6| Step: 6
Training loss: 1.7612093687057495
Validation loss: 2.0349111800552695

Epoch: 6| Step: 7
Training loss: 2.5828917026519775
Validation loss: 2.0166930485797185

Epoch: 6| Step: 8
Training loss: 1.7009196281433105
Validation loss: 2.01029799830529

Epoch: 6| Step: 9
Training loss: 1.5572353601455688
Validation loss: 2.012336510483937

Epoch: 6| Step: 10
Training loss: 2.043896198272705
Validation loss: 2.0195555084495136

Epoch: 6| Step: 11
Training loss: 2.1371941566467285
Validation loss: 2.0056407477266047

Epoch: 6| Step: 12
Training loss: 1.686905860900879
Validation loss: 2.028590302313528

Epoch: 6| Step: 13
Training loss: 1.5909727811813354
Validation loss: 2.015284196023018

Epoch: 95| Step: 0
Training loss: 1.9966132640838623
Validation loss: 2.0010131764155563

Epoch: 6| Step: 1
Training loss: 2.005671977996826
Validation loss: 2.013107689478064

Epoch: 6| Step: 2
Training loss: 1.5745880603790283
Validation loss: 2.007208906194215

Epoch: 6| Step: 3
Training loss: 2.192389965057373
Validation loss: 2.004542777615209

Epoch: 6| Step: 4
Training loss: 2.4333157539367676
Validation loss: 2.0189152815008677

Epoch: 6| Step: 5
Training loss: 2.7549777030944824
Validation loss: 2.0271447448320288

Epoch: 6| Step: 6
Training loss: 3.273894786834717
Validation loss: 2.038413965573875

Epoch: 6| Step: 7
Training loss: 2.4377455711364746
Validation loss: 2.000501912127259

Epoch: 6| Step: 8
Training loss: 2.4639434814453125
Validation loss: 2.0062017543341524

Epoch: 6| Step: 9
Training loss: 2.035875082015991
Validation loss: 2.013403074715727

Epoch: 6| Step: 10
Training loss: 1.418576717376709
Validation loss: 2.0353225713135092

Epoch: 6| Step: 11
Training loss: 2.238598108291626
Validation loss: 2.025346823917922

Epoch: 6| Step: 12
Training loss: 0.8867440819740295
Validation loss: 2.0041017993803947

Epoch: 6| Step: 13
Training loss: 1.665519118309021
Validation loss: 2.026428322638235

Epoch: 96| Step: 0
Training loss: 2.396157741546631
Validation loss: 2.0262838345701977

Epoch: 6| Step: 1
Training loss: 1.7469482421875
Validation loss: 2.0292095727817987

Epoch: 6| Step: 2
Training loss: 1.5017645359039307
Validation loss: 1.99980067822241

Epoch: 6| Step: 3
Training loss: 2.536360502243042
Validation loss: 2.0232332137323197

Epoch: 6| Step: 4
Training loss: 1.4873427152633667
Validation loss: 2.005787105970485

Epoch: 6| Step: 5
Training loss: 2.186566114425659
Validation loss: 2.02048510120761

Epoch: 6| Step: 6
Training loss: 2.748608112335205
Validation loss: 2.0286998056596324

Epoch: 6| Step: 7
Training loss: 1.7923171520233154
Validation loss: 2.0101297388794603

Epoch: 6| Step: 8
Training loss: 1.626779556274414
Validation loss: 2.0259048874660204

Epoch: 6| Step: 9
Training loss: 2.1862173080444336
Validation loss: 2.024788425814721

Epoch: 6| Step: 10
Training loss: 2.5770263671875
Validation loss: 2.0195464728980936

Epoch: 6| Step: 11
Training loss: 2.647679567337036
Validation loss: 2.012772560119629

Epoch: 6| Step: 12
Training loss: 2.366969585418701
Validation loss: 2.0336023979289557

Epoch: 6| Step: 13
Training loss: 1.2779661417007446
Validation loss: 2.020653998979958

Epoch: 97| Step: 0
Training loss: 2.601489782333374
Validation loss: 2.0256647217658257

Epoch: 6| Step: 1
Training loss: 2.3918354511260986
Validation loss: 2.0111779397533787

Epoch: 6| Step: 2
Training loss: 1.4454190731048584
Validation loss: 2.014937241872152

Epoch: 6| Step: 3
Training loss: 2.2684950828552246
Validation loss: 2.0007926392298874

Epoch: 6| Step: 4
Training loss: 2.066096782684326
Validation loss: 2.0346208426260177

Epoch: 6| Step: 5
Training loss: 2.275413990020752
Validation loss: 2.028979685998732

Epoch: 6| Step: 6
Training loss: 2.3378214836120605
Validation loss: 2.0036347937840286

Epoch: 6| Step: 7
Training loss: 2.021613836288452
Validation loss: 2.0115148892966648

Epoch: 6| Step: 8
Training loss: 2.218780755996704
Validation loss: 2.0230316321055093

Epoch: 6| Step: 9
Training loss: 2.033174753189087
Validation loss: 2.011756855954406

Epoch: 6| Step: 10
Training loss: 1.9445245265960693
Validation loss: 1.9998668291235482

Epoch: 6| Step: 11
Training loss: 1.679635763168335
Validation loss: 2.019734562084239

Epoch: 6| Step: 12
Training loss: 1.930267572402954
Validation loss: 2.030760908639559

Epoch: 6| Step: 13
Training loss: 2.0052242279052734
Validation loss: 2.0154593811240247

Epoch: 98| Step: 0
Training loss: 1.5033472776412964
Validation loss: 2.0297849973042807

Epoch: 6| Step: 1
Training loss: 2.1902265548706055
Validation loss: 2.0111722382166053

Epoch: 6| Step: 2
Training loss: 1.9376662969589233
Validation loss: 2.0158583118069555

Epoch: 6| Step: 3
Training loss: 2.203286647796631
Validation loss: 2.0175316436316377

Epoch: 6| Step: 4
Training loss: 2.692605495452881
Validation loss: 2.024202487801993

Epoch: 6| Step: 5
Training loss: 1.8240673542022705
Validation loss: 2.0267261715345484

Epoch: 6| Step: 6
Training loss: 1.9130454063415527
Validation loss: 2.0083596962754444

Epoch: 6| Step: 7
Training loss: 2.067451238632202
Validation loss: 2.032883495412847

Epoch: 6| Step: 8
Training loss: 2.4543418884277344
Validation loss: 2.0214757765493085

Epoch: 6| Step: 9
Training loss: 2.542912244796753
Validation loss: 2.010748565837901

Epoch: 6| Step: 10
Training loss: 2.4479715824127197
Validation loss: 2.003443856393137

Epoch: 6| Step: 11
Training loss: 1.962801218032837
Validation loss: 2.0363860309764905

Epoch: 6| Step: 12
Training loss: 1.9871702194213867
Validation loss: 2.025784518129082

Epoch: 6| Step: 13
Training loss: 1.4333349466323853
Validation loss: 2.0209599310351956

Epoch: 99| Step: 0
Training loss: 1.6318492889404297
Validation loss: 2.0222660982480614

Epoch: 6| Step: 1
Training loss: 2.0074520111083984
Validation loss: 1.9931779138503536

Epoch: 6| Step: 2
Training loss: 1.691662311553955
Validation loss: 2.009824275970459

Epoch: 6| Step: 3
Training loss: 2.107757091522217
Validation loss: 2.0064346687768095

Epoch: 6| Step: 4
Training loss: 2.150965690612793
Validation loss: 2.018001566651047

Epoch: 6| Step: 5
Training loss: 1.8681204319000244
Validation loss: 2.02589851040994

Epoch: 6| Step: 6
Training loss: 2.4764623641967773
Validation loss: 2.0180913017642115

Epoch: 6| Step: 7
Training loss: 2.7814266681671143
Validation loss: 2.012275154872607

Epoch: 6| Step: 8
Training loss: 1.8038986921310425
Validation loss: 2.001732942878559

Epoch: 6| Step: 9
Training loss: 2.2330546379089355
Validation loss: 2.0179384344367572

Epoch: 6| Step: 10
Training loss: 2.3071095943450928
Validation loss: 1.9932592556040774

Epoch: 6| Step: 11
Training loss: 2.484524726867676
Validation loss: 1.9883319152298795

Epoch: 6| Step: 12
Training loss: 1.956803321838379
Validation loss: 2.020901290319299

Epoch: 6| Step: 13
Training loss: 1.9541988372802734
Validation loss: 2.0150204512380783

Epoch: 100| Step: 0
Training loss: 1.7781018018722534
Validation loss: 2.014717632724393

Epoch: 6| Step: 1
Training loss: 2.106147527694702
Validation loss: 2.025730566311908

Epoch: 6| Step: 2
Training loss: 1.9833636283874512
Validation loss: 2.0066367862045125

Epoch: 6| Step: 3
Training loss: 1.7947845458984375
Validation loss: 2.0103225836189846

Epoch: 6| Step: 4
Training loss: 2.333954334259033
Validation loss: 2.0187840000275643

Epoch: 6| Step: 5
Training loss: 1.9013817310333252
Validation loss: 2.013719904807306

Epoch: 6| Step: 6
Training loss: 2.858205795288086
Validation loss: 2.0052245022148214

Epoch: 6| Step: 7
Training loss: 2.53405499458313
Validation loss: 2.01885207750464

Epoch: 6| Step: 8
Training loss: 1.7068328857421875
Validation loss: 2.0267973971623245

Epoch: 6| Step: 9
Training loss: 2.2278714179992676
Validation loss: 2.01202517555606

Epoch: 6| Step: 10
Training loss: 1.7300076484680176
Validation loss: 2.0215043585787535

Epoch: 6| Step: 11
Training loss: 2.173245906829834
Validation loss: 2.0129343271255493

Epoch: 6| Step: 12
Training loss: 1.933518648147583
Validation loss: 2.005104071350508

Epoch: 6| Step: 13
Training loss: 2.378145694732666
Validation loss: 2.0128901543155795

Epoch: 101| Step: 0
Training loss: 1.8951175212860107
Validation loss: 2.0251111227978944

Epoch: 6| Step: 1
Training loss: 1.8993812799453735
Validation loss: 2.0239731598925847

Epoch: 6| Step: 2
Training loss: 1.8710432052612305
Validation loss: 2.0094782460120415

Epoch: 6| Step: 3
Training loss: 1.5930655002593994
Validation loss: 2.0063457694104923

Epoch: 6| Step: 4
Training loss: 2.0028300285339355
Validation loss: 2.030375954925373

Epoch: 6| Step: 5
Training loss: 2.7392826080322266
Validation loss: 2.0255361885152836

Epoch: 6| Step: 6
Training loss: 1.33444082736969
Validation loss: 2.0053258339564004

Epoch: 6| Step: 7
Training loss: 2.6047096252441406
Validation loss: 2.019687444932999

Epoch: 6| Step: 8
Training loss: 2.7201027870178223
Validation loss: 1.9997494951371224

Epoch: 6| Step: 9
Training loss: 1.8907660245895386
Validation loss: 2.0057539478425057

Epoch: 6| Step: 10
Training loss: 1.8075119256973267
Validation loss: 2.016399774500119

Epoch: 6| Step: 11
Training loss: 2.336620569229126
Validation loss: 2.0191783443573983

Epoch: 6| Step: 12
Training loss: 2.3953332901000977
Validation loss: 2.029106136291258

Epoch: 6| Step: 13
Training loss: 2.1005375385284424
Validation loss: 2.0123388703151415

Epoch: 102| Step: 0
Training loss: 1.2397156953811646
Validation loss: 2.00745500287702

Epoch: 6| Step: 1
Training loss: 2.7967896461486816
Validation loss: 2.034465152730224

Epoch: 6| Step: 2
Training loss: 3.0832629203796387
Validation loss: 2.0191229607469294

Epoch: 6| Step: 3
Training loss: 2.2951793670654297
Validation loss: 2.0102123380989156

Epoch: 6| Step: 4
Training loss: 1.4874393939971924
Validation loss: 2.0262802108641593

Epoch: 6| Step: 5
Training loss: 2.359793186187744
Validation loss: 2.0318455721742366

Epoch: 6| Step: 6
Training loss: 2.414409875869751
Validation loss: 2.0233750253595333

Epoch: 6| Step: 7
Training loss: 1.7148914337158203
Validation loss: 2.023884043898634

Epoch: 6| Step: 8
Training loss: 2.248626232147217
Validation loss: 2.0148768950534124

Epoch: 6| Step: 9
Training loss: 2.2188448905944824
Validation loss: 2.008092298302599

Epoch: 6| Step: 10
Training loss: 2.0277600288391113
Validation loss: 2.0010182537058347

Epoch: 6| Step: 11
Training loss: 1.5586810111999512
Validation loss: 2.0140757842730452

Epoch: 6| Step: 12
Training loss: 1.8968565464019775
Validation loss: 2.0161879729199153

Epoch: 6| Step: 13
Training loss: 1.436714768409729
Validation loss: 1.9912172645650885

Epoch: 103| Step: 0
Training loss: 1.7865725755691528
Validation loss: 2.009770690753896

Epoch: 6| Step: 1
Training loss: 1.8708252906799316
Validation loss: 2.0231944694313952

Epoch: 6| Step: 2
Training loss: 1.6568326950073242
Validation loss: 2.015292970083093

Epoch: 6| Step: 3
Training loss: 2.000786066055298
Validation loss: 2.019056252253953

Epoch: 6| Step: 4
Training loss: 2.239968776702881
Validation loss: 2.008245360466742

Epoch: 6| Step: 5
Training loss: 2.0196712017059326
Validation loss: 2.0145594240516744

Epoch: 6| Step: 6
Training loss: 2.3406434059143066
Validation loss: 2.014149106958861

Epoch: 6| Step: 7
Training loss: 1.4054992198944092
Validation loss: 2.005500275601623

Epoch: 6| Step: 8
Training loss: 1.5929921865463257
Validation loss: 2.0140791875059887

Epoch: 6| Step: 9
Training loss: 2.1714282035827637
Validation loss: 2.0161028318507697

Epoch: 6| Step: 10
Training loss: 2.52439284324646
Validation loss: 2.0250942014878794

Epoch: 6| Step: 11
Training loss: 2.6705031394958496
Validation loss: 2.0182293358669487

Epoch: 6| Step: 12
Training loss: 2.0082483291625977
Validation loss: 2.011670030573363

Epoch: 6| Step: 13
Training loss: 3.148203134536743
Validation loss: 2.0190240875367196

Epoch: 104| Step: 0
Training loss: 2.1584877967834473
Validation loss: 2.0320156902395268

Epoch: 6| Step: 1
Training loss: 1.8202884197235107
Validation loss: 2.0148450072093675

Epoch: 6| Step: 2
Training loss: 1.8900136947631836
Validation loss: 2.003331281805551

Epoch: 6| Step: 3
Training loss: 1.9839320182800293
Validation loss: 2.0168860984104935

Epoch: 6| Step: 4
Training loss: 1.8272820711135864
Validation loss: 2.002960366587485

Epoch: 6| Step: 5
Training loss: 1.080702543258667
Validation loss: 2.0250760432212584

Epoch: 6| Step: 6
Training loss: 2.7223963737487793
Validation loss: 2.0378770110427693

Epoch: 6| Step: 7
Training loss: 2.0563464164733887
Validation loss: 2.012100399181407

Epoch: 6| Step: 8
Training loss: 2.1958274841308594
Validation loss: 2.013887684832337

Epoch: 6| Step: 9
Training loss: 1.9956326484680176
Validation loss: 2.0322516682327434

Epoch: 6| Step: 10
Training loss: 3.080465078353882
Validation loss: 2.0133081302847913

Epoch: 6| Step: 11
Training loss: 2.6031124591827393
Validation loss: 2.0212933363453036

Epoch: 6| Step: 12
Training loss: 2.191822052001953
Validation loss: 2.007672511121278

Epoch: 6| Step: 13
Training loss: 1.3843638896942139
Validation loss: 2.033425243951941

Epoch: 105| Step: 0
Training loss: 1.452032446861267
Validation loss: 2.0323590373480194

Epoch: 6| Step: 1
Training loss: 1.6353297233581543
Validation loss: 2.0156664361235914

Epoch: 6| Step: 2
Training loss: 2.4590959548950195
Validation loss: 2.0207863084731565

Epoch: 6| Step: 3
Training loss: 2.483257532119751
Validation loss: 2.007348250317317

Epoch: 6| Step: 4
Training loss: 1.3896042108535767
Validation loss: 2.024381370954616

Epoch: 6| Step: 5
Training loss: 2.2584781646728516
Validation loss: 2.002524040078604

Epoch: 6| Step: 6
Training loss: 2.517406463623047
Validation loss: 2.0271486774567635

Epoch: 6| Step: 7
Training loss: 2.529733896255493
Validation loss: 2.0195017630054104

Epoch: 6| Step: 8
Training loss: 2.1699280738830566
Validation loss: 2.0126274862597064

Epoch: 6| Step: 9
Training loss: 2.041572332382202
Validation loss: 2.0148633090398644

Epoch: 6| Step: 10
Training loss: 1.918969750404358
Validation loss: 2.0478579177651355

Epoch: 6| Step: 11
Training loss: 1.973339557647705
Validation loss: 2.0179908301240657

Epoch: 6| Step: 12
Training loss: 1.777409315109253
Validation loss: 2.013323727474418

Epoch: 6| Step: 13
Training loss: 2.707082986831665
Validation loss: 2.0295460416424658

Epoch: 106| Step: 0
Training loss: 2.7959132194519043
Validation loss: 2.0191653966903687

Epoch: 6| Step: 1
Training loss: 2.4384853839874268
Validation loss: 2.004824356366229

Epoch: 6| Step: 2
Training loss: 1.605252981185913
Validation loss: 1.9988133984227334

Epoch: 6| Step: 3
Training loss: 2.8168208599090576
Validation loss: 1.9976055801555674

Epoch: 6| Step: 4
Training loss: 1.9703216552734375
Validation loss: 2.0093486924325266

Epoch: 6| Step: 5
Training loss: 1.6287648677825928
Validation loss: 2.027496968546221

Epoch: 6| Step: 6
Training loss: 1.912677526473999
Validation loss: 2.0194892485936484

Epoch: 6| Step: 7
Training loss: 1.4958274364471436
Validation loss: 2.0179930810005433

Epoch: 6| Step: 8
Training loss: 2.2928590774536133
Validation loss: 2.0190719378891813

Epoch: 6| Step: 9
Training loss: 1.4711413383483887
Validation loss: 2.023035018674789

Epoch: 6| Step: 10
Training loss: 2.621901512145996
Validation loss: 2.0284859339396157

Epoch: 6| Step: 11
Training loss: 2.3507883548736572
Validation loss: 2.034036292824694

Epoch: 6| Step: 12
Training loss: 1.8681960105895996
Validation loss: 2.012237480891648

Epoch: 6| Step: 13
Training loss: 1.530143141746521
Validation loss: 2.024008445842292

Epoch: 107| Step: 0
Training loss: 2.086793899536133
Validation loss: 2.016434697694676

Epoch: 6| Step: 1
Training loss: 1.9211275577545166
Validation loss: 2.010851842100902

Epoch: 6| Step: 2
Training loss: 2.8627970218658447
Validation loss: 2.0279510610847065

Epoch: 6| Step: 3
Training loss: 2.047165870666504
Validation loss: 2.028531183478653

Epoch: 6| Step: 4
Training loss: 1.8326020240783691
Validation loss: 2.0211912303842525

Epoch: 6| Step: 5
Training loss: 1.896343469619751
Validation loss: 2.020153348163892

Epoch: 6| Step: 6
Training loss: 2.2081260681152344
Validation loss: 2.0027055099446285

Epoch: 6| Step: 7
Training loss: 2.275197982788086
Validation loss: 2.024950517121182

Epoch: 6| Step: 8
Training loss: 1.9170923233032227
Validation loss: 2.001588818847492

Epoch: 6| Step: 9
Training loss: 1.5106022357940674
Validation loss: 2.0085610523018786

Epoch: 6| Step: 10
Training loss: 1.417661428451538
Validation loss: 2.0287283774345153

Epoch: 6| Step: 11
Training loss: 2.8011579513549805
Validation loss: 2.0030480815518286

Epoch: 6| Step: 12
Training loss: 2.016923427581787
Validation loss: 2.0015392329103205

Epoch: 6| Step: 13
Training loss: 2.1870243549346924
Validation loss: 2.0173641379161547

Epoch: 108| Step: 0
Training loss: 1.8187978267669678
Validation loss: 2.0219511793505762

Epoch: 6| Step: 1
Training loss: 2.1148948669433594
Validation loss: 2.014674481525216

Epoch: 6| Step: 2
Training loss: 2.817229986190796
Validation loss: 2.0292293153783327

Epoch: 6| Step: 3
Training loss: 1.6646186113357544
Validation loss: 1.991233092482372

Epoch: 6| Step: 4
Training loss: 2.124606132507324
Validation loss: 2.014565840844185

Epoch: 6| Step: 5
Training loss: 1.3524357080459595
Validation loss: 2.003291772257897

Epoch: 6| Step: 6
Training loss: 2.9712777137756348
Validation loss: 1.9931156481465986

Epoch: 6| Step: 7
Training loss: 2.334782600402832
Validation loss: 2.03018932701439

Epoch: 6| Step: 8
Training loss: 1.3725602626800537
Validation loss: 2.011105909142443

Epoch: 6| Step: 9
Training loss: 2.3102269172668457
Validation loss: 2.0047232912432764

Epoch: 6| Step: 10
Training loss: 2.621644973754883
Validation loss: 2.0284608217977707

Epoch: 6| Step: 11
Training loss: 1.8793835639953613
Validation loss: 2.0116459938787643

Epoch: 6| Step: 12
Training loss: 1.6553750038146973
Validation loss: 2.0244115885867866

Epoch: 6| Step: 13
Training loss: 1.5394052267074585
Validation loss: 2.0163488323970506

Epoch: 109| Step: 0
Training loss: 2.3466951847076416
Validation loss: 2.0208027798642396

Epoch: 6| Step: 1
Training loss: 1.8605884313583374
Validation loss: 1.992172469374954

Epoch: 6| Step: 2
Training loss: 1.329040288925171
Validation loss: 2.0243667838394

Epoch: 6| Step: 3
Training loss: 2.8062663078308105
Validation loss: 2.003798507875012

Epoch: 6| Step: 4
Training loss: 2.5735177993774414
Validation loss: 2.0046397024585354

Epoch: 6| Step: 5
Training loss: 2.2418713569641113
Validation loss: 2.000156182114796

Epoch: 6| Step: 6
Training loss: 1.6220061779022217
Validation loss: 2.0188152418341687

Epoch: 6| Step: 7
Training loss: 2.388664960861206
Validation loss: 2.0263285636901855

Epoch: 6| Step: 8
Training loss: 1.3062458038330078
Validation loss: 2.0168338770507486

Epoch: 6| Step: 9
Training loss: 2.1191203594207764
Validation loss: 2.0221478298146236

Epoch: 6| Step: 10
Training loss: 2.0328006744384766
Validation loss: 2.0106876575818626

Epoch: 6| Step: 11
Training loss: 2.0908265113830566
Validation loss: 2.0124958586949173

Epoch: 6| Step: 12
Training loss: 1.9825658798217773
Validation loss: 2.0145355950119677

Epoch: 6| Step: 13
Training loss: 2.218479871749878
Validation loss: 2.0253703389116513

Epoch: 110| Step: 0
Training loss: 2.7265334129333496
Validation loss: 2.0025195562711327

Epoch: 6| Step: 1
Training loss: 2.429147243499756
Validation loss: 2.0128136450244534

Epoch: 6| Step: 2
Training loss: 2.130549192428589
Validation loss: 2.0052732216414584

Epoch: 6| Step: 3
Training loss: 2.475382089614868
Validation loss: 2.021770459349437

Epoch: 6| Step: 4
Training loss: 1.2416329383850098
Validation loss: 1.9874883005695958

Epoch: 6| Step: 5
Training loss: 2.2001399993896484
Validation loss: 2.0286789094248125

Epoch: 6| Step: 6
Training loss: 1.749372959136963
Validation loss: 2.0136536064968316

Epoch: 6| Step: 7
Training loss: 1.5504169464111328
Validation loss: 2.0030401970750544

Epoch: 6| Step: 8
Training loss: 1.9286333322525024
Validation loss: 2.005532510818974

Epoch: 6| Step: 9
Training loss: 2.1579501628875732
Validation loss: 1.9998900864713935

Epoch: 6| Step: 10
Training loss: 1.7317315340042114
Validation loss: 2.0097342050203713

Epoch: 6| Step: 11
Training loss: 2.0860729217529297
Validation loss: 2.0133264090425227

Epoch: 6| Step: 12
Training loss: 2.6357064247131348
Validation loss: 2.0167819428187546

Epoch: 6| Step: 13
Training loss: 1.4882909059524536
Validation loss: 2.0189084801622617

Epoch: 111| Step: 0
Training loss: 1.1937508583068848
Validation loss: 2.011562216666437

Epoch: 6| Step: 1
Training loss: 2.499356746673584
Validation loss: 2.0140564236589658

Epoch: 6| Step: 2
Training loss: 2.1300504207611084
Validation loss: 2.02202659140351

Epoch: 6| Step: 3
Training loss: 1.3032877445220947
Validation loss: 2.040082408535865

Epoch: 6| Step: 4
Training loss: 2.5543529987335205
Validation loss: 2.0322156362636115

Epoch: 6| Step: 5
Training loss: 1.8083299398422241
Validation loss: 2.0287020565361105

Epoch: 6| Step: 6
Training loss: 2.4068408012390137
Validation loss: 2.005606657715254

Epoch: 6| Step: 7
Training loss: 1.743138313293457
Validation loss: 2.006895378071775

Epoch: 6| Step: 8
Training loss: 1.7213239669799805
Validation loss: 2.02299528865404

Epoch: 6| Step: 9
Training loss: 2.155649185180664
Validation loss: 2.004917621612549

Epoch: 6| Step: 10
Training loss: 1.9742823839187622
Validation loss: 2.017369426706786

Epoch: 6| Step: 11
Training loss: 2.2355709075927734
Validation loss: 2.0159482135567615

Epoch: 6| Step: 12
Training loss: 2.331851005554199
Validation loss: 2.0153356931542836

Epoch: 6| Step: 13
Training loss: 3.0703415870666504
Validation loss: 2.0114085623013076

Epoch: 112| Step: 0
Training loss: 1.7710185050964355
Validation loss: 1.995578770996422

Epoch: 6| Step: 1
Training loss: 2.286785364151001
Validation loss: 2.0102182203723538

Epoch: 6| Step: 2
Training loss: 2.4815027713775635
Validation loss: 2.008499541590291

Epoch: 6| Step: 3
Training loss: 1.9625234603881836
Validation loss: 1.9895177643786195

Epoch: 6| Step: 4
Training loss: 1.465665578842163
Validation loss: 2.0186112439760597

Epoch: 6| Step: 5
Training loss: 2.3879382610321045
Validation loss: 2.0114264103674118

Epoch: 6| Step: 6
Training loss: 2.241387367248535
Validation loss: 2.0168757618114515

Epoch: 6| Step: 7
Training loss: 2.0629444122314453
Validation loss: 2.0135642969480125

Epoch: 6| Step: 8
Training loss: 1.4403868913650513
Validation loss: 2.001021046792307

Epoch: 6| Step: 9
Training loss: 1.9671626091003418
Validation loss: 2.017407053260393

Epoch: 6| Step: 10
Training loss: 1.82352614402771
Validation loss: 1.9988693985887753

Epoch: 6| Step: 11
Training loss: 2.213146686553955
Validation loss: 1.9909321108172018

Epoch: 6| Step: 12
Training loss: 2.108274459838867
Validation loss: 2.0140920762092835

Epoch: 6| Step: 13
Training loss: 2.719735622406006
Validation loss: 1.9910223971131027

Epoch: 113| Step: 0
Training loss: 1.68292236328125
Validation loss: 1.989274654337155

Epoch: 6| Step: 1
Training loss: 2.2723000049591064
Validation loss: 1.996122496102446

Epoch: 6| Step: 2
Training loss: 2.1720170974731445
Validation loss: 1.994154740405339

Epoch: 6| Step: 3
Training loss: 2.405613899230957
Validation loss: 2.007620753780488

Epoch: 6| Step: 4
Training loss: 1.7137444019317627
Validation loss: 2.039613103353849

Epoch: 6| Step: 5
Training loss: 2.1791958808898926
Validation loss: 1.9886536354659705

Epoch: 6| Step: 6
Training loss: 2.4699158668518066
Validation loss: 2.0070275645102225

Epoch: 6| Step: 7
Training loss: 2.4603517055511475
Validation loss: 2.0047680101087018

Epoch: 6| Step: 8
Training loss: 2.1930487155914307
Validation loss: 2.0150092968376736

Epoch: 6| Step: 9
Training loss: 1.5630714893341064
Validation loss: 2.010615312924949

Epoch: 6| Step: 10
Training loss: 2.020362138748169
Validation loss: 2.0218296333025862

Epoch: 6| Step: 11
Training loss: 1.2188775539398193
Validation loss: 2.0293318533128306

Epoch: 6| Step: 12
Training loss: 1.7626949548721313
Validation loss: 2.009334405263265

Epoch: 6| Step: 13
Training loss: 2.967621088027954
Validation loss: 2.031820668969103

Epoch: 114| Step: 0
Training loss: 1.704572319984436
Validation loss: 1.987892677707057

Epoch: 6| Step: 1
Training loss: 1.856115698814392
Validation loss: 2.0089141040719967

Epoch: 6| Step: 2
Training loss: 1.4301725625991821
Validation loss: 2.0385419578962427

Epoch: 6| Step: 3
Training loss: 2.4722609519958496
Validation loss: 2.007204706950854

Epoch: 6| Step: 4
Training loss: 1.2768700122833252
Validation loss: 2.0202318212037444

Epoch: 6| Step: 5
Training loss: 1.9415595531463623
Validation loss: 2.0076870943910334

Epoch: 6| Step: 6
Training loss: 2.2710928916931152
Validation loss: 1.9857519185671242

Epoch: 6| Step: 7
Training loss: 2.3424928188323975
Validation loss: 1.9993056763884842

Epoch: 6| Step: 8
Training loss: 3.0002870559692383
Validation loss: 2.018112687654393

Epoch: 6| Step: 9
Training loss: 1.4276807308197021
Validation loss: 1.998256291112592

Epoch: 6| Step: 10
Training loss: 1.5478378534317017
Validation loss: 1.9986575547085013

Epoch: 6| Step: 11
Training loss: 2.422163486480713
Validation loss: 2.008245304066648

Epoch: 6| Step: 12
Training loss: 2.4713821411132812
Validation loss: 2.002467683566514

Epoch: 6| Step: 13
Training loss: 2.572047710418701
Validation loss: 2.0178121815445604

Epoch: 115| Step: 0
Training loss: 1.7106592655181885
Validation loss: 2.02143427120742

Epoch: 6| Step: 1
Training loss: 2.039776563644409
Validation loss: 1.994716816051032

Epoch: 6| Step: 2
Training loss: 2.465853691101074
Validation loss: 2.0256948996615667

Epoch: 6| Step: 3
Training loss: 1.953965425491333
Validation loss: 2.0034170330211682

Epoch: 6| Step: 4
Training loss: 2.3207125663757324
Validation loss: 2.0122904162253104

Epoch: 6| Step: 5
Training loss: 1.806916356086731
Validation loss: 2.0140811474092546

Epoch: 6| Step: 6
Training loss: 2.399536609649658
Validation loss: 2.0268884448594946

Epoch: 6| Step: 7
Training loss: 1.8443787097930908
Validation loss: 2.0090444651983117

Epoch: 6| Step: 8
Training loss: 1.9543015956878662
Validation loss: 2.011093803631362

Epoch: 6| Step: 9
Training loss: 2.2792582511901855
Validation loss: 1.9834057515667332

Epoch: 6| Step: 10
Training loss: 1.8047711849212646
Validation loss: 1.9982060809289255

Epoch: 6| Step: 11
Training loss: 1.795257806777954
Validation loss: 1.9710356163722214

Epoch: 6| Step: 12
Training loss: 1.8155442476272583
Validation loss: 1.9958136158604776

Epoch: 6| Step: 13
Training loss: 2.7811050415039062
Validation loss: 2.0060728262829524

Epoch: 116| Step: 0
Training loss: 2.125075578689575
Validation loss: 2.023129483704926

Epoch: 6| Step: 1
Training loss: 1.972935676574707
Validation loss: 2.0026621100723103

Epoch: 6| Step: 2
Training loss: 1.664365291595459
Validation loss: 2.005918102879678

Epoch: 6| Step: 3
Training loss: 2.840693950653076
Validation loss: 1.9849691365354805

Epoch: 6| Step: 4
Training loss: 2.1349897384643555
Validation loss: 2.00953407185052

Epoch: 6| Step: 5
Training loss: 1.2276437282562256
Validation loss: 1.9974099487386725

Epoch: 6| Step: 6
Training loss: 1.9357115030288696
Validation loss: 2.0112852537503807

Epoch: 6| Step: 7
Training loss: 2.861752510070801
Validation loss: 2.0083064520230858

Epoch: 6| Step: 8
Training loss: 2.2217016220092773
Validation loss: 2.0071556414327314

Epoch: 6| Step: 9
Training loss: 1.7487289905548096
Validation loss: 2.0173006506376367

Epoch: 6| Step: 10
Training loss: 2.2529618740081787
Validation loss: 2.000031598152653

Epoch: 6| Step: 11
Training loss: 1.3496785163879395
Validation loss: 2.025247525143367

Epoch: 6| Step: 12
Training loss: 2.1254358291625977
Validation loss: 2.0170089954970987

Epoch: 6| Step: 13
Training loss: 1.946465015411377
Validation loss: 2.010122552994759

Epoch: 117| Step: 0
Training loss: 2.202840805053711
Validation loss: 2.0114451710895827

Epoch: 6| Step: 1
Training loss: 1.8599425554275513
Validation loss: 1.9960324225887176

Epoch: 6| Step: 2
Training loss: 2.001950263977051
Validation loss: 2.007814371457664

Epoch: 6| Step: 3
Training loss: 2.537944793701172
Validation loss: 2.0151155712783977

Epoch: 6| Step: 4
Training loss: 2.019968032836914
Validation loss: 2.0088563170484317

Epoch: 6| Step: 5
Training loss: 2.685757875442505
Validation loss: 2.01057610460507

Epoch: 6| Step: 6
Training loss: 1.3703564405441284
Validation loss: 1.996703915698554

Epoch: 6| Step: 7
Training loss: 1.563812494277954
Validation loss: 2.0002792150743547

Epoch: 6| Step: 8
Training loss: 1.723880648612976
Validation loss: 1.9961750750900598

Epoch: 6| Step: 9
Training loss: 1.8771297931671143
Validation loss: 1.998958582519203

Epoch: 6| Step: 10
Training loss: 2.516979694366455
Validation loss: 2.016961864245835

Epoch: 6| Step: 11
Training loss: 2.4485201835632324
Validation loss: 2.014293138698865

Epoch: 6| Step: 12
Training loss: 1.8795216083526611
Validation loss: 2.00005212009594

Epoch: 6| Step: 13
Training loss: 1.6458642482757568
Validation loss: 2.001491654303766

Epoch: 118| Step: 0
Training loss: 2.415074348449707
Validation loss: 2.0045887770191317

Epoch: 6| Step: 1
Training loss: 1.6403136253356934
Validation loss: 1.9970397167308356

Epoch: 6| Step: 2
Training loss: 1.368212103843689
Validation loss: 2.023029996502784

Epoch: 6| Step: 3
Training loss: 2.330334424972534
Validation loss: 2.0100757152803483

Epoch: 6| Step: 4
Training loss: 2.2692205905914307
Validation loss: 1.9825913790733583

Epoch: 6| Step: 5
Training loss: 2.477738380432129
Validation loss: 2.0094501472288564

Epoch: 6| Step: 6
Training loss: 2.6221861839294434
Validation loss: 2.0093513675915298

Epoch: 6| Step: 7
Training loss: 1.7765718698501587
Validation loss: 2.001402493446104

Epoch: 6| Step: 8
Training loss: 1.5131816864013672
Validation loss: 1.9911603645611835

Epoch: 6| Step: 9
Training loss: 1.9914501905441284
Validation loss: 1.994404714594605

Epoch: 6| Step: 10
Training loss: 1.908808946609497
Validation loss: 2.0073920706267

Epoch: 6| Step: 11
Training loss: 2.5911879539489746
Validation loss: 2.013623220946199

Epoch: 6| Step: 12
Training loss: 1.9269143342971802
Validation loss: 1.9966963465495775

Epoch: 6| Step: 13
Training loss: 0.9395735263824463
Validation loss: 1.9909057681278517

Epoch: 119| Step: 0
Training loss: 2.6068615913391113
Validation loss: 2.007065496137065

Epoch: 6| Step: 1
Training loss: 2.306300163269043
Validation loss: 2.0116380530018962

Epoch: 6| Step: 2
Training loss: 2.606541872024536
Validation loss: 1.9875926817617109

Epoch: 6| Step: 3
Training loss: 1.44292414188385
Validation loss: 2.021178114798761

Epoch: 6| Step: 4
Training loss: 1.782284140586853
Validation loss: 2.0185722099837435

Epoch: 6| Step: 5
Training loss: 1.534985065460205
Validation loss: 2.002992473622804

Epoch: 6| Step: 6
Training loss: 1.276353120803833
Validation loss: 2.0202746980933735

Epoch: 6| Step: 7
Training loss: 1.3070123195648193
Validation loss: 2.0199753135763188

Epoch: 6| Step: 8
Training loss: 2.117175817489624
Validation loss: 2.0168702448568037

Epoch: 6| Step: 9
Training loss: 2.410212993621826
Validation loss: 2.0048082285029913

Epoch: 6| Step: 10
Training loss: 2.0148262977600098
Validation loss: 1.998526814163372

Epoch: 6| Step: 11
Training loss: 2.293938159942627
Validation loss: 2.01340159293144

Epoch: 6| Step: 12
Training loss: 2.3760437965393066
Validation loss: 2.008480379658361

Epoch: 6| Step: 13
Training loss: 2.7104592323303223
Validation loss: 2.0066820639435963

Epoch: 120| Step: 0
Training loss: 2.5766658782958984
Validation loss: 2.0018101494799376

Epoch: 6| Step: 1
Training loss: 1.3864402770996094
Validation loss: 2.000883568999588

Epoch: 6| Step: 2
Training loss: 1.779571294784546
Validation loss: 2.002322276433309

Epoch: 6| Step: 3
Training loss: 1.1743868589401245
Validation loss: 1.988841482388076

Epoch: 6| Step: 4
Training loss: 2.3350515365600586
Validation loss: 1.998824974542023

Epoch: 6| Step: 5
Training loss: 1.6301264762878418
Validation loss: 1.993602930858571

Epoch: 6| Step: 6
Training loss: 1.7256755828857422
Validation loss: 1.9818053104544198

Epoch: 6| Step: 7
Training loss: 3.0572586059570312
Validation loss: 1.9877555870240735

Epoch: 6| Step: 8
Training loss: 1.2673512697219849
Validation loss: 1.996504601611886

Epoch: 6| Step: 9
Training loss: 1.8256473541259766
Validation loss: 1.9904580449545255

Epoch: 6| Step: 10
Training loss: 2.231825113296509
Validation loss: 2.0062314733382194

Epoch: 6| Step: 11
Training loss: 2.1960721015930176
Validation loss: 2.005273436987272

Epoch: 6| Step: 12
Training loss: 2.465515375137329
Validation loss: 2.0002815326054892

Epoch: 6| Step: 13
Training loss: 2.8231825828552246
Validation loss: 2.0256267952662643

Epoch: 121| Step: 0
Training loss: 1.821065902709961
Validation loss: 1.9819456120972991

Epoch: 6| Step: 1
Training loss: 2.1296353340148926
Validation loss: 2.001758098602295

Epoch: 6| Step: 2
Training loss: 2.320664167404175
Validation loss: 1.9904034496635519

Epoch: 6| Step: 3
Training loss: 2.030811309814453
Validation loss: 2.0039131154296217

Epoch: 6| Step: 4
Training loss: 1.7498055696487427
Validation loss: 1.9881038537589453

Epoch: 6| Step: 5
Training loss: 1.7571593523025513
Validation loss: 1.9816373138017551

Epoch: 6| Step: 6
Training loss: 1.9719781875610352
Validation loss: 1.9953877490053895

Epoch: 6| Step: 7
Training loss: 2.497974157333374
Validation loss: 2.0203004921636274

Epoch: 6| Step: 8
Training loss: 1.6429665088653564
Validation loss: 1.9940932963484077

Epoch: 6| Step: 9
Training loss: 2.4388866424560547
Validation loss: 2.0008121075168734

Epoch: 6| Step: 10
Training loss: 2.305260419845581
Validation loss: 1.9750895218182636

Epoch: 6| Step: 11
Training loss: 1.5872892141342163
Validation loss: 1.9961442819205664

Epoch: 6| Step: 12
Training loss: 2.4201595783233643
Validation loss: 2.012400569454316

Epoch: 6| Step: 13
Training loss: 1.4470629692077637
Validation loss: 2.0157962153034825

Epoch: 122| Step: 0
Training loss: 2.0734031200408936
Validation loss: 1.990134431469825

Epoch: 6| Step: 1
Training loss: 2.0208263397216797
Validation loss: 2.0026503891073246

Epoch: 6| Step: 2
Training loss: 1.7017086744308472
Validation loss: 1.985673583963866

Epoch: 6| Step: 3
Training loss: 1.7459242343902588
Validation loss: 1.9962362461192633

Epoch: 6| Step: 4
Training loss: 1.8612473011016846
Validation loss: 1.9828561429054505

Epoch: 6| Step: 5
Training loss: 2.163867950439453
Validation loss: 1.9949950761692499

Epoch: 6| Step: 6
Training loss: 2.2404398918151855
Validation loss: 1.9948815402164255

Epoch: 6| Step: 7
Training loss: 1.450382947921753
Validation loss: 1.9834921642016339

Epoch: 6| Step: 8
Training loss: 2.550421714782715
Validation loss: 2.0147460429899153

Epoch: 6| Step: 9
Training loss: 1.8201624155044556
Validation loss: 2.0065566057799966

Epoch: 6| Step: 10
Training loss: 2.2324583530426025
Validation loss: 1.9953731618901736

Epoch: 6| Step: 11
Training loss: 2.3292458057403564
Validation loss: 1.9829338340349094

Epoch: 6| Step: 12
Training loss: 2.140519142150879
Validation loss: 1.9996045763774584

Epoch: 6| Step: 13
Training loss: 1.7190649509429932
Validation loss: 1.9923842273732668

Epoch: 123| Step: 0
Training loss: 1.4943081140518188
Validation loss: 2.002687305532476

Epoch: 6| Step: 1
Training loss: 1.5914900302886963
Validation loss: 1.9883851761459022

Epoch: 6| Step: 2
Training loss: 1.8609975576400757
Validation loss: 2.0081033565664805

Epoch: 6| Step: 3
Training loss: 1.6586986780166626
Validation loss: 1.978972174788034

Epoch: 6| Step: 4
Training loss: 2.484104871749878
Validation loss: 1.9781651778887677

Epoch: 6| Step: 5
Training loss: 1.5761529207229614
Validation loss: 2.010928225773637

Epoch: 6| Step: 6
Training loss: 2.3683278560638428
Validation loss: 1.996125223816082

Epoch: 6| Step: 7
Training loss: 2.197336435317993
Validation loss: 1.995684463490722

Epoch: 6| Step: 8
Training loss: 2.615983009338379
Validation loss: 1.9908261081223846

Epoch: 6| Step: 9
Training loss: 2.009577512741089
Validation loss: 1.9671648856132262

Epoch: 6| Step: 10
Training loss: 1.5989830493927002
Validation loss: 2.0154053805976786

Epoch: 6| Step: 11
Training loss: 2.5281972885131836
Validation loss: 1.989454371954805

Epoch: 6| Step: 12
Training loss: 2.2234363555908203
Validation loss: 1.9868528086652038

Epoch: 6| Step: 13
Training loss: 1.5605227947235107
Validation loss: 1.997754700722233

Epoch: 124| Step: 0
Training loss: 2.359388828277588
Validation loss: 1.9901227053775583

Epoch: 6| Step: 1
Training loss: 2.0321483612060547
Validation loss: 1.9890886455453851

Epoch: 6| Step: 2
Training loss: 1.464702844619751
Validation loss: 2.002198574363544

Epoch: 6| Step: 3
Training loss: 2.085825204849243
Validation loss: 1.9883010669421124

Epoch: 6| Step: 4
Training loss: 2.1996562480926514
Validation loss: 1.9881257664772771

Epoch: 6| Step: 5
Training loss: 1.6077663898468018
Validation loss: 1.9894047988358365

Epoch: 6| Step: 6
Training loss: 2.128368616104126
Validation loss: 1.9965539875850882

Epoch: 6| Step: 7
Training loss: 2.1870412826538086
Validation loss: 1.9970752205899966

Epoch: 6| Step: 8
Training loss: 1.9146482944488525
Validation loss: 2.003352572841029

Epoch: 6| Step: 9
Training loss: 2.1260604858398438
Validation loss: 2.0227785084837224

Epoch: 6| Step: 10
Training loss: 2.0475025177001953
Validation loss: 1.9975511707285398

Epoch: 6| Step: 11
Training loss: 2.4870188236236572
Validation loss: 1.99654374840439

Epoch: 6| Step: 12
Training loss: 1.9634720087051392
Validation loss: 1.9857521851857503

Epoch: 6| Step: 13
Training loss: 1.2264900207519531
Validation loss: 2.0036748596417007

Epoch: 125| Step: 0
Training loss: 1.6911687850952148
Validation loss: 1.977753185456799

Epoch: 6| Step: 1
Training loss: 1.8606185913085938
Validation loss: 1.9797490053279425

Epoch: 6| Step: 2
Training loss: 2.069542407989502
Validation loss: 2.007201680573084

Epoch: 6| Step: 3
Training loss: 2.6473727226257324
Validation loss: 1.9900034960880075

Epoch: 6| Step: 4
Training loss: 2.089653968811035
Validation loss: 1.9877276420593262

Epoch: 6| Step: 5
Training loss: 2.765017032623291
Validation loss: 1.9772210697973929

Epoch: 6| Step: 6
Training loss: 2.03826904296875
Validation loss: 1.980573631102039

Epoch: 6| Step: 7
Training loss: 1.2292225360870361
Validation loss: 1.9925704592017717

Epoch: 6| Step: 8
Training loss: 1.628652811050415
Validation loss: 1.9823225723799838

Epoch: 6| Step: 9
Training loss: 2.0098557472229004
Validation loss: 2.0142459715566328

Epoch: 6| Step: 10
Training loss: 1.9805076122283936
Validation loss: 1.9997588357617777

Epoch: 6| Step: 11
Training loss: 2.446013927459717
Validation loss: 1.9924557516651769

Epoch: 6| Step: 12
Training loss: 2.051853656768799
Validation loss: 2.0015041341063795

Epoch: 6| Step: 13
Training loss: 1.1296532154083252
Validation loss: 1.9970988945294452

Epoch: 126| Step: 0
Training loss: 1.8677029609680176
Validation loss: 1.991912099622911

Epoch: 6| Step: 1
Training loss: 1.8423597812652588
Validation loss: 1.9824325192359187

Epoch: 6| Step: 2
Training loss: 2.7332603931427
Validation loss: 2.0067426478990944

Epoch: 6| Step: 3
Training loss: 2.352771282196045
Validation loss: 2.005059516558083

Epoch: 6| Step: 4
Training loss: 2.142988443374634
Validation loss: 1.9933414215682654

Epoch: 6| Step: 5
Training loss: 1.6264207363128662
Validation loss: 2.018988929769044

Epoch: 6| Step: 6
Training loss: 2.904283046722412
Validation loss: 1.978287414837909

Epoch: 6| Step: 7
Training loss: 1.5384190082550049
Validation loss: 1.9955945143135645

Epoch: 6| Step: 8
Training loss: 1.6328758001327515
Validation loss: 1.9900949078221475

Epoch: 6| Step: 9
Training loss: 1.6497039794921875
Validation loss: 1.9887312945499216

Epoch: 6| Step: 10
Training loss: 2.0697379112243652
Validation loss: 1.9836187542125743

Epoch: 6| Step: 11
Training loss: 1.9793689250946045
Validation loss: 1.969285593237928

Epoch: 6| Step: 12
Training loss: 1.480769395828247
Validation loss: 1.979116755147134

Epoch: 6| Step: 13
Training loss: 1.9935221672058105
Validation loss: 2.008561697057498

Epoch: 127| Step: 0
Training loss: 1.877899169921875
Validation loss: 2.001039902369181

Epoch: 6| Step: 1
Training loss: 2.2126998901367188
Validation loss: 1.9853516048000706

Epoch: 6| Step: 2
Training loss: 1.512458324432373
Validation loss: 2.0027991110278713

Epoch: 6| Step: 3
Training loss: 2.231147289276123
Validation loss: 1.9907965429367558

Epoch: 6| Step: 4
Training loss: 1.9752631187438965
Validation loss: 1.9937928261295441

Epoch: 6| Step: 5
Training loss: 2.756309986114502
Validation loss: 1.9973988840656896

Epoch: 6| Step: 6
Training loss: 2.06278133392334
Validation loss: 1.9885257751710954

Epoch: 6| Step: 7
Training loss: 1.9290300607681274
Validation loss: 1.9986459234709382

Epoch: 6| Step: 8
Training loss: 1.916599154472351
Validation loss: 1.9836019726209744

Epoch: 6| Step: 9
Training loss: 1.6457698345184326
Validation loss: 1.9810798732183312

Epoch: 6| Step: 10
Training loss: 1.682669758796692
Validation loss: 1.9967739812789425

Epoch: 6| Step: 11
Training loss: 2.139503240585327
Validation loss: 1.9935708456141974

Epoch: 6| Step: 12
Training loss: 1.926955223083496
Validation loss: 1.9921997054930656

Epoch: 6| Step: 13
Training loss: 2.146214008331299
Validation loss: 2.007294310036526

Epoch: 128| Step: 0
Training loss: 1.5572514533996582
Validation loss: 1.9984532735681022

Epoch: 6| Step: 1
Training loss: 2.4470622539520264
Validation loss: 1.9947064358700988

Epoch: 6| Step: 2
Training loss: 1.6620599031448364
Validation loss: 1.9995134543347102

Epoch: 6| Step: 3
Training loss: 2.3986918926239014
Validation loss: 1.9870515779782367

Epoch: 6| Step: 4
Training loss: 1.8589160442352295
Validation loss: 1.9874949198897167

Epoch: 6| Step: 5
Training loss: 1.0889806747436523
Validation loss: 2.0115213650529102

Epoch: 6| Step: 6
Training loss: 2.4947757720947266
Validation loss: 1.9865266174398444

Epoch: 6| Step: 7
Training loss: 2.204400062561035
Validation loss: 1.9939376538799656

Epoch: 6| Step: 8
Training loss: 1.9955337047576904
Validation loss: 1.9914914561856178

Epoch: 6| Step: 9
Training loss: 2.220243453979492
Validation loss: 1.9989261960470548

Epoch: 6| Step: 10
Training loss: 1.7678698301315308
Validation loss: 1.9991193868780648

Epoch: 6| Step: 11
Training loss: 1.8310527801513672
Validation loss: 1.9730030080323577

Epoch: 6| Step: 12
Training loss: 2.229808807373047
Validation loss: 1.987857239220732

Epoch: 6| Step: 13
Training loss: 2.010023593902588
Validation loss: 1.9869999449740174

Epoch: 129| Step: 0
Training loss: 1.6921478509902954
Validation loss: 2.01518843507254

Epoch: 6| Step: 1
Training loss: 2.3216776847839355
Validation loss: 1.988455585254136

Epoch: 6| Step: 2
Training loss: 1.8896846771240234
Validation loss: 1.9693748745867001

Epoch: 6| Step: 3
Training loss: 1.3006391525268555
Validation loss: 1.968110902335054

Epoch: 6| Step: 4
Training loss: 2.0099105834960938
Validation loss: 1.9929224316791823

Epoch: 6| Step: 5
Training loss: 1.3889517784118652
Validation loss: 1.9889134873626053

Epoch: 6| Step: 6
Training loss: 3.2744503021240234
Validation loss: 1.9982366420889413

Epoch: 6| Step: 7
Training loss: 2.1712114810943604
Validation loss: 2.0038029686097176

Epoch: 6| Step: 8
Training loss: 1.784071445465088
Validation loss: 1.9898880245865032

Epoch: 6| Step: 9
Training loss: 1.8574035167694092
Validation loss: 2.0054110378347416

Epoch: 6| Step: 10
Training loss: 2.1526591777801514
Validation loss: 1.9845670910291775

Epoch: 6| Step: 11
Training loss: 2.1245102882385254
Validation loss: 1.9793609098721576

Epoch: 6| Step: 12
Training loss: 1.6010385751724243
Validation loss: 1.986710807328583

Epoch: 6| Step: 13
Training loss: 2.4193356037139893
Validation loss: 1.9725953109802739

Epoch: 130| Step: 0
Training loss: 2.0311734676361084
Validation loss: 1.9870872113012499

Epoch: 6| Step: 1
Training loss: 1.4831898212432861
Validation loss: 1.9797331633106354

Epoch: 6| Step: 2
Training loss: 2.2414984703063965
Validation loss: 1.9721226974200177

Epoch: 6| Step: 3
Training loss: 2.3599977493286133
Validation loss: 2.0176597654178576

Epoch: 6| Step: 4
Training loss: 2.275325298309326
Validation loss: 1.9840280009854225

Epoch: 6| Step: 5
Training loss: 1.944046139717102
Validation loss: 1.9866070849921114

Epoch: 6| Step: 6
Training loss: 2.325284957885742
Validation loss: 1.9867073515410065

Epoch: 6| Step: 7
Training loss: 1.7385183572769165
Validation loss: 1.9982425192350983

Epoch: 6| Step: 8
Training loss: 1.1666679382324219
Validation loss: 1.97921420169133

Epoch: 6| Step: 9
Training loss: 1.7611145973205566
Validation loss: 1.9915308311421385

Epoch: 6| Step: 10
Training loss: 2.5500760078430176
Validation loss: 2.0060620128467517

Epoch: 6| Step: 11
Training loss: 2.4937727451324463
Validation loss: 1.9985971745624338

Epoch: 6| Step: 12
Training loss: 1.6566325426101685
Validation loss: 1.9832917708222584

Epoch: 6| Step: 13
Training loss: 1.242180347442627
Validation loss: 1.995771554208571

Epoch: 131| Step: 0
Training loss: 1.9567807912826538
Validation loss: 1.9578382635629306

Epoch: 6| Step: 1
Training loss: 1.6386783123016357
Validation loss: 1.9875049975610548

Epoch: 6| Step: 2
Training loss: 1.8844358921051025
Validation loss: 1.975987716387677

Epoch: 6| Step: 3
Training loss: 2.555114984512329
Validation loss: 1.9998953060437274

Epoch: 6| Step: 4
Training loss: 1.987070083618164
Validation loss: 1.9818334553831367

Epoch: 6| Step: 5
Training loss: 1.8248424530029297
Validation loss: 1.9770681063334148

Epoch: 6| Step: 6
Training loss: 1.7235124111175537
Validation loss: 2.016627929543936

Epoch: 6| Step: 7
Training loss: 1.5166106224060059
Validation loss: 1.982620317448852

Epoch: 6| Step: 8
Training loss: 2.6788291931152344
Validation loss: 2.0008673642271306

Epoch: 6| Step: 9
Training loss: 2.055172920227051
Validation loss: 1.9752141814078055

Epoch: 6| Step: 10
Training loss: 1.6026402711868286
Validation loss: 2.0081860147496706

Epoch: 6| Step: 11
Training loss: 2.6032047271728516
Validation loss: 1.9876921356365245

Epoch: 6| Step: 12
Training loss: 1.8897223472595215
Validation loss: 1.9833691863603489

Epoch: 6| Step: 13
Training loss: 1.92660391330719
Validation loss: 1.9959692339743338

Epoch: 132| Step: 0
Training loss: 1.7966707944869995
Validation loss: 1.9828127994332263

Epoch: 6| Step: 1
Training loss: 2.4954190254211426
Validation loss: 1.9941357745919177

Epoch: 6| Step: 2
Training loss: 1.6194918155670166
Validation loss: 1.9702839582197127

Epoch: 6| Step: 3
Training loss: 2.40344500541687
Validation loss: 1.981337389638347

Epoch: 6| Step: 4
Training loss: 2.3000409603118896
Validation loss: 1.9613172392691336

Epoch: 6| Step: 5
Training loss: 2.4863123893737793
Validation loss: 1.967552335031571

Epoch: 6| Step: 6
Training loss: 1.88275146484375
Validation loss: 1.9620347869011663

Epoch: 6| Step: 7
Training loss: 2.193960666656494
Validation loss: 1.9791487878368748

Epoch: 6| Step: 8
Training loss: 1.2975842952728271
Validation loss: 2.0029583195204377

Epoch: 6| Step: 9
Training loss: 2.1313443183898926
Validation loss: 1.9740602303576726

Epoch: 6| Step: 10
Training loss: 1.391188621520996
Validation loss: 1.9685886393311203

Epoch: 6| Step: 11
Training loss: 1.5838499069213867
Validation loss: 1.9716037768189625

Epoch: 6| Step: 12
Training loss: 2.4486422538757324
Validation loss: 1.9777682545364543

Epoch: 6| Step: 13
Training loss: 1.314771056175232
Validation loss: 2.0025808606096493

Epoch: 133| Step: 0
Training loss: 1.7661917209625244
Validation loss: 1.9852472274534163

Epoch: 6| Step: 1
Training loss: 1.780745506286621
Validation loss: 1.9701978147670787

Epoch: 6| Step: 2
Training loss: 1.9086754322052002
Validation loss: 1.9654784010302635

Epoch: 6| Step: 3
Training loss: 1.3973338603973389
Validation loss: 1.978718642265566

Epoch: 6| Step: 4
Training loss: 1.5693249702453613
Validation loss: 2.0090827390711796

Epoch: 6| Step: 5
Training loss: 2.42049503326416
Validation loss: 1.9957958421399515

Epoch: 6| Step: 6
Training loss: 2.4924094676971436
Validation loss: 1.9765876659782984

Epoch: 6| Step: 7
Training loss: 1.8168174028396606
Validation loss: 1.976576005258868

Epoch: 6| Step: 8
Training loss: 2.055851697921753
Validation loss: 1.9965457685532109

Epoch: 6| Step: 9
Training loss: 1.7349780797958374
Validation loss: 1.9746083597983084

Epoch: 6| Step: 10
Training loss: 1.9586803913116455
Validation loss: 1.9824941504386164

Epoch: 6| Step: 11
Training loss: 2.39024019241333
Validation loss: 1.9599026364664878

Epoch: 6| Step: 12
Training loss: 1.7510491609573364
Validation loss: 1.9888583575525591

Epoch: 6| Step: 13
Training loss: 2.834808826446533
Validation loss: 1.983633227245782

Epoch: 134| Step: 0
Training loss: 1.864715814590454
Validation loss: 1.9967040643897107

Epoch: 6| Step: 1
Training loss: 2.1809163093566895
Validation loss: 1.9696942913916804

Epoch: 6| Step: 2
Training loss: 1.6125214099884033
Validation loss: 1.9906278938375495

Epoch: 6| Step: 3
Training loss: 2.6969807147979736
Validation loss: 1.9757973096703971

Epoch: 6| Step: 4
Training loss: 2.4178004264831543
Validation loss: 1.9743030712168703

Epoch: 6| Step: 5
Training loss: 1.8633142709732056
Validation loss: 1.969731753872287

Epoch: 6| Step: 6
Training loss: 1.9293612241744995
Validation loss: 1.9753477599031182

Epoch: 6| Step: 7
Training loss: 2.0395543575286865
Validation loss: 1.980722555550196

Epoch: 6| Step: 8
Training loss: 1.4965732097625732
Validation loss: 1.9561789061433525

Epoch: 6| Step: 9
Training loss: 1.2033092975616455
Validation loss: 1.9864765008290608

Epoch: 6| Step: 10
Training loss: 2.4880449771881104
Validation loss: 1.9976622904500654

Epoch: 6| Step: 11
Training loss: 1.9582107067108154
Validation loss: 1.9881212378060946

Epoch: 6| Step: 12
Training loss: 1.785975694656372
Validation loss: 1.9822074956791376

Epoch: 6| Step: 13
Training loss: 1.6883636713027954
Validation loss: 1.9871781090254426

Epoch: 135| Step: 0
Training loss: 2.9601244926452637
Validation loss: 1.9976024871231408

Epoch: 6| Step: 1
Training loss: 2.4258713722229004
Validation loss: 2.0022012520861883

Epoch: 6| Step: 2
Training loss: 1.7035865783691406
Validation loss: 1.9961403980050036

Epoch: 6| Step: 3
Training loss: 1.1594434976577759
Validation loss: 1.9804523016816826

Epoch: 6| Step: 4
Training loss: 1.3772082328796387
Validation loss: 1.9913293982064852

Epoch: 6| Step: 5
Training loss: 1.8972468376159668
Validation loss: 2.001261439374698

Epoch: 6| Step: 6
Training loss: 1.9715615510940552
Validation loss: 1.9732432673054356

Epoch: 6| Step: 7
Training loss: 1.6125288009643555
Validation loss: 1.9646667421505015

Epoch: 6| Step: 8
Training loss: 3.2531399726867676
Validation loss: 1.9828828637317946

Epoch: 6| Step: 9
Training loss: 1.6717592477798462
Validation loss: 1.969796670380459

Epoch: 6| Step: 10
Training loss: 1.4148080348968506
Validation loss: 1.9716866875207553

Epoch: 6| Step: 11
Training loss: 1.8497953414916992
Validation loss: 1.9910282140137048

Epoch: 6| Step: 12
Training loss: 1.5196664333343506
Validation loss: 1.998435526765803

Epoch: 6| Step: 13
Training loss: 3.082824230194092
Validation loss: 1.9809123880119734

Epoch: 136| Step: 0
Training loss: 1.7657299041748047
Validation loss: 1.9683774145700599

Epoch: 6| Step: 1
Training loss: 2.210519790649414
Validation loss: 1.9963190978573215

Epoch: 6| Step: 2
Training loss: 1.8501801490783691
Validation loss: 1.9826645210225096

Epoch: 6| Step: 3
Training loss: 2.8620617389678955
Validation loss: 2.006746683069455

Epoch: 6| Step: 4
Training loss: 2.0031685829162598
Validation loss: 1.9668304484377626

Epoch: 6| Step: 5
Training loss: 2.2087831497192383
Validation loss: 1.9623853647580711

Epoch: 6| Step: 6
Training loss: 1.6177451610565186
Validation loss: 1.9922868769655946

Epoch: 6| Step: 7
Training loss: 1.9464119672775269
Validation loss: 1.9740741022171513

Epoch: 6| Step: 8
Training loss: 2.466700792312622
Validation loss: 1.9720861399045555

Epoch: 6| Step: 9
Training loss: 1.364051103591919
Validation loss: 1.9795705297941804

Epoch: 6| Step: 10
Training loss: 1.665337324142456
Validation loss: 1.9762860011028986

Epoch: 6| Step: 11
Training loss: 1.469657063484192
Validation loss: 1.9619505354153213

Epoch: 6| Step: 12
Training loss: 1.9762606620788574
Validation loss: 1.9867487902282386

Epoch: 6| Step: 13
Training loss: 2.2737386226654053
Validation loss: 1.9886368654107536

Epoch: 137| Step: 0
Training loss: 2.393747329711914
Validation loss: 1.9618877390379548

Epoch: 6| Step: 1
Training loss: 1.258109211921692
Validation loss: 1.9732447016623713

Epoch: 6| Step: 2
Training loss: 1.4519679546356201
Validation loss: 1.968603910938386

Epoch: 6| Step: 3
Training loss: 2.742459297180176
Validation loss: 1.9599447173456992

Epoch: 6| Step: 4
Training loss: 2.3555245399475098
Validation loss: 1.9747074778361986

Epoch: 6| Step: 5
Training loss: 1.3996822834014893
Validation loss: 1.9593935192272227

Epoch: 6| Step: 6
Training loss: 2.7049880027770996
Validation loss: 1.9588743832803541

Epoch: 6| Step: 7
Training loss: 1.4575440883636475
Validation loss: 1.97422150129913

Epoch: 6| Step: 8
Training loss: 2.028940200805664
Validation loss: 1.970615880463713

Epoch: 6| Step: 9
Training loss: 2.030601978302002
Validation loss: 1.9758912850451726

Epoch: 6| Step: 10
Training loss: 2.042142391204834
Validation loss: 1.9794255764253679

Epoch: 6| Step: 11
Training loss: 1.9483927488327026
Validation loss: 1.9813718616321523

Epoch: 6| Step: 12
Training loss: 1.931657314300537
Validation loss: 2.0020179786989765

Epoch: 6| Step: 13
Training loss: 1.1837403774261475
Validation loss: 1.9710737941085652

Epoch: 138| Step: 0
Training loss: 2.059899091720581
Validation loss: 1.9642363261151057

Epoch: 6| Step: 1
Training loss: 1.8173954486846924
Validation loss: 1.9872325774162047

Epoch: 6| Step: 2
Training loss: 2.079686164855957
Validation loss: 1.9589995209888746

Epoch: 6| Step: 3
Training loss: 2.213798999786377
Validation loss: 1.9915719468106505

Epoch: 6| Step: 4
Training loss: 2.4065184593200684
Validation loss: 1.977380512863077

Epoch: 6| Step: 5
Training loss: 1.841365098953247
Validation loss: 2.000029294721542

Epoch: 6| Step: 6
Training loss: 2.0051872730255127
Validation loss: 1.9645782542485062

Epoch: 6| Step: 7
Training loss: 2.0941481590270996
Validation loss: 1.9804920765661425

Epoch: 6| Step: 8
Training loss: 2.020522356033325
Validation loss: 2.000937698989786

Epoch: 6| Step: 9
Training loss: 2.0190932750701904
Validation loss: 1.9891207371988604

Epoch: 6| Step: 10
Training loss: 1.0326266288757324
Validation loss: 1.9743061091310234

Epoch: 6| Step: 11
Training loss: 1.5833423137664795
Validation loss: 1.973097421789682

Epoch: 6| Step: 12
Training loss: 2.1344070434570312
Validation loss: 1.9457833074754285

Epoch: 6| Step: 13
Training loss: 1.79580819606781
Validation loss: 1.9662070594808108

Epoch: 139| Step: 0
Training loss: 1.3428953886032104
Validation loss: 1.9673116617305304

Epoch: 6| Step: 1
Training loss: 1.2740426063537598
Validation loss: 1.980930620624173

Epoch: 6| Step: 2
Training loss: 2.1520769596099854
Validation loss: 1.9779416380390045

Epoch: 6| Step: 3
Training loss: 2.020440101623535
Validation loss: 1.9684206221693306

Epoch: 6| Step: 4
Training loss: 2.3990578651428223
Validation loss: 1.966386825807633

Epoch: 6| Step: 5
Training loss: 1.7836639881134033
Validation loss: 1.9645745023604362

Epoch: 6| Step: 6
Training loss: 2.1005659103393555
Validation loss: 1.9677017119623

Epoch: 6| Step: 7
Training loss: 1.411085605621338
Validation loss: 1.9548497507649083

Epoch: 6| Step: 8
Training loss: 2.2819631099700928
Validation loss: 1.9616770244413806

Epoch: 6| Step: 9
Training loss: 1.8442250490188599
Validation loss: 1.9851855347233434

Epoch: 6| Step: 10
Training loss: 2.7042226791381836
Validation loss: 1.9639309490880659

Epoch: 6| Step: 11
Training loss: 2.2005727291107178
Validation loss: 1.9912061640011367

Epoch: 6| Step: 12
Training loss: 1.7123266458511353
Validation loss: 1.9957057160715903

Epoch: 6| Step: 13
Training loss: 2.189667224884033
Validation loss: 1.9900744320243917

Epoch: 140| Step: 0
Training loss: 1.6268045902252197
Validation loss: 1.990450588605737

Epoch: 6| Step: 1
Training loss: 2.2507503032684326
Validation loss: 1.9494766881389003

Epoch: 6| Step: 2
Training loss: 2.375393867492676
Validation loss: 1.993387883709323

Epoch: 6| Step: 3
Training loss: 1.831616759300232
Validation loss: 1.9560032352324455

Epoch: 6| Step: 4
Training loss: 2.630812644958496
Validation loss: 1.9588951769695486

Epoch: 6| Step: 5
Training loss: 1.7309356927871704
Validation loss: 1.9607632147368563

Epoch: 6| Step: 6
Training loss: 1.3206279277801514
Validation loss: 1.970181308766847

Epoch: 6| Step: 7
Training loss: 2.0738003253936768
Validation loss: 1.9705694055044523

Epoch: 6| Step: 8
Training loss: 1.6215322017669678
Validation loss: 1.9703118929298975

Epoch: 6| Step: 9
Training loss: 1.9010496139526367
Validation loss: 1.993353925725465

Epoch: 6| Step: 10
Training loss: 2.2061362266540527
Validation loss: 1.9630701452173211

Epoch: 6| Step: 11
Training loss: 1.6652405261993408
Validation loss: 1.9838995766896073

Epoch: 6| Step: 12
Training loss: 1.7847729921340942
Validation loss: 1.972447306879105

Epoch: 6| Step: 13
Training loss: 2.18666410446167
Validation loss: 1.9791389639659593

Epoch: 141| Step: 0
Training loss: 1.745811939239502
Validation loss: 1.9546463425441454

Epoch: 6| Step: 1
Training loss: 1.8359698057174683
Validation loss: 1.9716089976731168

Epoch: 6| Step: 2
Training loss: 2.3212082386016846
Validation loss: 1.9644110920608684

Epoch: 6| Step: 3
Training loss: 1.3489872217178345
Validation loss: 1.9525250850185272

Epoch: 6| Step: 4
Training loss: 1.5404222011566162
Validation loss: 1.9761129553600023

Epoch: 6| Step: 5
Training loss: 2.4570164680480957
Validation loss: 1.9750577288289224

Epoch: 6| Step: 6
Training loss: 1.8945270776748657
Validation loss: 1.966795176588079

Epoch: 6| Step: 7
Training loss: 2.0536398887634277
Validation loss: 1.9700040599351287

Epoch: 6| Step: 8
Training loss: 2.314570426940918
Validation loss: 1.9572600472357966

Epoch: 6| Step: 9
Training loss: 2.0182228088378906
Validation loss: 1.9564000996210242

Epoch: 6| Step: 10
Training loss: 1.2231347560882568
Validation loss: 1.9724633142512331

Epoch: 6| Step: 11
Training loss: 2.8068480491638184
Validation loss: 1.965140450385309

Epoch: 6| Step: 12
Training loss: 1.4981088638305664
Validation loss: 1.9626091167490969

Epoch: 6| Step: 13
Training loss: 1.8588061332702637
Validation loss: 1.9778782834288895

Epoch: 142| Step: 0
Training loss: 2.209834098815918
Validation loss: 1.9772951936209073

Epoch: 6| Step: 1
Training loss: 1.8620153665542603
Validation loss: 1.988580197416326

Epoch: 6| Step: 2
Training loss: 2.588472843170166
Validation loss: 1.9603758550459338

Epoch: 6| Step: 3
Training loss: 1.7863686084747314
Validation loss: 1.9645636325241418

Epoch: 6| Step: 4
Training loss: 2.0428466796875
Validation loss: 1.9800358997878207

Epoch: 6| Step: 5
Training loss: 1.5817193984985352
Validation loss: 1.9586270855319114

Epoch: 6| Step: 6
Training loss: 1.5898102521896362
Validation loss: 1.9743041761459843

Epoch: 6| Step: 7
Training loss: 2.6441967487335205
Validation loss: 1.9868269376857306

Epoch: 6| Step: 8
Training loss: 1.179640531539917
Validation loss: 1.9766387298542967

Epoch: 6| Step: 9
Training loss: 1.593840479850769
Validation loss: 1.990618348121643

Epoch: 6| Step: 10
Training loss: 1.5536301136016846
Validation loss: 1.9689250312825686

Epoch: 6| Step: 11
Training loss: 1.7076966762542725
Validation loss: 1.980340152658442

Epoch: 6| Step: 12
Training loss: 2.882566213607788
Validation loss: 1.99533857581436

Epoch: 6| Step: 13
Training loss: 2.086597204208374
Validation loss: 1.9597765168836039

Epoch: 143| Step: 0
Training loss: 1.897700548171997
Validation loss: 1.9739949549398115

Epoch: 6| Step: 1
Training loss: 2.2054882049560547
Validation loss: 2.000136747155138

Epoch: 6| Step: 2
Training loss: 2.267521381378174
Validation loss: 1.950357788352556

Epoch: 6| Step: 3
Training loss: 2.0141258239746094
Validation loss: 1.9694515210326

Epoch: 6| Step: 4
Training loss: 2.113884687423706
Validation loss: 1.964031070791265

Epoch: 6| Step: 5
Training loss: 1.70233952999115
Validation loss: 1.98048190147646

Epoch: 6| Step: 6
Training loss: 2.0743699073791504
Validation loss: 1.94057801974717

Epoch: 6| Step: 7
Training loss: 2.3278675079345703
Validation loss: 1.9831030214986494

Epoch: 6| Step: 8
Training loss: 1.6559109687805176
Validation loss: 1.9817736969199231

Epoch: 6| Step: 9
Training loss: 1.2845985889434814
Validation loss: 1.9983745134004982

Epoch: 6| Step: 10
Training loss: 1.9802907705307007
Validation loss: 1.971130722312517

Epoch: 6| Step: 11
Training loss: 2.075854778289795
Validation loss: 1.9849622480330928

Epoch: 6| Step: 12
Training loss: 2.1448991298675537
Validation loss: 1.970677762903193

Epoch: 6| Step: 13
Training loss: 0.775023341178894
Validation loss: 1.9783317453117781

Epoch: 144| Step: 0
Training loss: 1.7681388854980469
Validation loss: 1.9921824829552763

Epoch: 6| Step: 1
Training loss: 1.5269737243652344
Validation loss: 1.9534051623395694

Epoch: 6| Step: 2
Training loss: 2.158792495727539
Validation loss: 1.9825954770529142

Epoch: 6| Step: 3
Training loss: 1.6760531663894653
Validation loss: 1.9725974964839157

Epoch: 6| Step: 4
Training loss: 2.2220959663391113
Validation loss: 1.9781277371991066

Epoch: 6| Step: 5
Training loss: 2.2478036880493164
Validation loss: 1.972418826113465

Epoch: 6| Step: 6
Training loss: 1.5046008825302124
Validation loss: 1.9684708156893331

Epoch: 6| Step: 7
Training loss: 1.9656474590301514
Validation loss: 1.974053163682261

Epoch: 6| Step: 8
Training loss: 2.4952945709228516
Validation loss: 1.9718634415698308

Epoch: 6| Step: 9
Training loss: 2.4408769607543945
Validation loss: 1.9576711808481524

Epoch: 6| Step: 10
Training loss: 2.3256430625915527
Validation loss: 1.9835026879464426

Epoch: 6| Step: 11
Training loss: 1.3236472606658936
Validation loss: 1.9619373967570644

Epoch: 6| Step: 12
Training loss: 1.8731093406677246
Validation loss: 1.9619018249614264

Epoch: 6| Step: 13
Training loss: 1.0405757427215576
Validation loss: 1.9778022099566717

Epoch: 145| Step: 0
Training loss: 1.63164222240448
Validation loss: 1.997139956361504

Epoch: 6| Step: 1
Training loss: 1.8961894512176514
Validation loss: 1.9557293756033785

Epoch: 6| Step: 2
Training loss: 1.3924260139465332
Validation loss: 1.9793412967394757

Epoch: 6| Step: 3
Training loss: 1.874366283416748
Validation loss: 1.9605096674734546

Epoch: 6| Step: 4
Training loss: 1.5759356021881104
Validation loss: 1.9884546995162964

Epoch: 6| Step: 5
Training loss: 2.146923065185547
Validation loss: 1.9852916681638328

Epoch: 6| Step: 6
Training loss: 2.28076171875
Validation loss: 1.983049020972303

Epoch: 6| Step: 7
Training loss: 2.172518491744995
Validation loss: 1.9610574783817414

Epoch: 6| Step: 8
Training loss: 1.9683592319488525
Validation loss: 1.9452586045829199

Epoch: 6| Step: 9
Training loss: 2.058000087738037
Validation loss: 1.972370050286734

Epoch: 6| Step: 10
Training loss: 2.2460739612579346
Validation loss: 1.9771509529441915

Epoch: 6| Step: 11
Training loss: 2.486616373062134
Validation loss: 1.970499953915996

Epoch: 6| Step: 12
Training loss: 1.40671968460083
Validation loss: 1.9765181387624433

Epoch: 6| Step: 13
Training loss: 1.492353916168213
Validation loss: 1.969984523711666

Epoch: 146| Step: 0
Training loss: 1.3665680885314941
Validation loss: 1.9808834163091515

Epoch: 6| Step: 1
Training loss: 2.1920602321624756
Validation loss: 1.9656862199947398

Epoch: 6| Step: 2
Training loss: 2.381772518157959
Validation loss: 2.0087013962448284

Epoch: 6| Step: 3
Training loss: 2.133368492126465
Validation loss: 1.9784257027410692

Epoch: 6| Step: 4
Training loss: 1.6960418224334717
Validation loss: 1.9816905683086765

Epoch: 6| Step: 5
Training loss: 2.0129644870758057
Validation loss: 1.9875695590049989

Epoch: 6| Step: 6
Training loss: 1.4072484970092773
Validation loss: 1.953633108446675

Epoch: 6| Step: 7
Training loss: 2.0206360816955566
Validation loss: 1.97305937223537

Epoch: 6| Step: 8
Training loss: 1.6568653583526611
Validation loss: 1.9835323749050018

Epoch: 6| Step: 9
Training loss: 1.6771081686019897
Validation loss: 1.9634067396963797

Epoch: 6| Step: 10
Training loss: 2.121913433074951
Validation loss: 1.9748283137557328

Epoch: 6| Step: 11
Training loss: 2.1696789264678955
Validation loss: 1.9596097020692722

Epoch: 6| Step: 12
Training loss: 2.0018563270568848
Validation loss: 1.973124022124916

Epoch: 6| Step: 13
Training loss: 1.8305449485778809
Validation loss: 1.9610485594759706

Epoch: 147| Step: 0
Training loss: 1.5062371492385864
Validation loss: 1.9790104563518236

Epoch: 6| Step: 1
Training loss: 2.00290584564209
Validation loss: 1.9767098324273222

Epoch: 6| Step: 2
Training loss: 2.6082603931427
Validation loss: 1.970424247044389

Epoch: 6| Step: 3
Training loss: 1.7042794227600098
Validation loss: 1.9813611289506317

Epoch: 6| Step: 4
Training loss: 1.9176217317581177
Validation loss: 1.9558667995596444

Epoch: 6| Step: 5
Training loss: 1.3835954666137695
Validation loss: 1.9772608203272666

Epoch: 6| Step: 6
Training loss: 2.059373617172241
Validation loss: 1.92687899579284

Epoch: 6| Step: 7
Training loss: 2.545283317565918
Validation loss: 1.9780817352315432

Epoch: 6| Step: 8
Training loss: 2.061291217803955
Validation loss: 1.9645958638960315

Epoch: 6| Step: 9
Training loss: 1.7834609746932983
Validation loss: 1.9861152069542998

Epoch: 6| Step: 10
Training loss: 1.5419585704803467
Validation loss: 1.9729855265668643

Epoch: 6| Step: 11
Training loss: 2.58060359954834
Validation loss: 1.9572699903160014

Epoch: 6| Step: 12
Training loss: 1.4327805042266846
Validation loss: 1.9604192292818459

Epoch: 6| Step: 13
Training loss: 1.3244496583938599
Validation loss: 1.9842255166781846

Epoch: 148| Step: 0
Training loss: 1.5636433362960815
Validation loss: 1.9679011644855622

Epoch: 6| Step: 1
Training loss: 2.408388376235962
Validation loss: 2.010503750975414

Epoch: 6| Step: 2
Training loss: 1.616969347000122
Validation loss: 1.9688052759375623

Epoch: 6| Step: 3
Training loss: 1.8905584812164307
Validation loss: 1.9775853669771584

Epoch: 6| Step: 4
Training loss: 1.9401439428329468
Validation loss: 1.9826732386824906

Epoch: 6| Step: 5
Training loss: 1.6704082489013672
Validation loss: 1.958993616924491

Epoch: 6| Step: 6
Training loss: 2.7906665802001953
Validation loss: 1.9601619807622765

Epoch: 6| Step: 7
Training loss: 2.0593204498291016
Validation loss: 1.9506597352284256

Epoch: 6| Step: 8
Training loss: 2.243565559387207
Validation loss: 1.9519915901204592

Epoch: 6| Step: 9
Training loss: 1.2723109722137451
Validation loss: 1.9328347124079222

Epoch: 6| Step: 10
Training loss: 1.9278279542922974
Validation loss: 1.9626432195786507

Epoch: 6| Step: 11
Training loss: 1.5772756338119507
Validation loss: 1.9652917769647413

Epoch: 6| Step: 12
Training loss: 2.1052701473236084
Validation loss: 1.9742247712227605

Epoch: 6| Step: 13
Training loss: 1.5012784004211426
Validation loss: 1.9704724434883363

Epoch: 149| Step: 0
Training loss: 2.4197158813476562
Validation loss: 1.9535593409692087

Epoch: 6| Step: 1
Training loss: 1.60829758644104
Validation loss: 1.9584717096820954

Epoch: 6| Step: 2
Training loss: 1.7373102903366089
Validation loss: 1.9665771479247718

Epoch: 6| Step: 3
Training loss: 1.5853726863861084
Validation loss: 1.954576338491132

Epoch: 6| Step: 4
Training loss: 1.9433461427688599
Validation loss: 1.963576985943702

Epoch: 6| Step: 5
Training loss: 1.5686060190200806
Validation loss: 1.954572654539539

Epoch: 6| Step: 6
Training loss: 1.994410514831543
Validation loss: 1.9759400249809347

Epoch: 6| Step: 7
Training loss: 1.386242389678955
Validation loss: 1.9901817639668782

Epoch: 6| Step: 8
Training loss: 2.0739054679870605
Validation loss: 1.9601100542212044

Epoch: 6| Step: 9
Training loss: 2.279050588607788
Validation loss: 1.9677497622787312

Epoch: 6| Step: 10
Training loss: 2.360337018966675
Validation loss: 1.9782505573764924

Epoch: 6| Step: 11
Training loss: 1.5894359350204468
Validation loss: 1.9727811736445273

Epoch: 6| Step: 12
Training loss: 1.8136036396026611
Validation loss: 1.9819071754332511

Epoch: 6| Step: 13
Training loss: 2.2865939140319824
Validation loss: 1.9721063196018178

Epoch: 150| Step: 0
Training loss: 1.8549320697784424
Validation loss: 1.9773473816533242

Epoch: 6| Step: 1
Training loss: 1.7050654888153076
Validation loss: 1.978959115602637

Epoch: 6| Step: 2
Training loss: 1.5018930435180664
Validation loss: 1.9481559620108655

Epoch: 6| Step: 3
Training loss: 1.9629215002059937
Validation loss: 1.9720613802632978

Epoch: 6| Step: 4
Training loss: 1.8335177898406982
Validation loss: 1.9719887343786096

Epoch: 6| Step: 5
Training loss: 2.274515151977539
Validation loss: 1.950160462369201

Epoch: 6| Step: 6
Training loss: 1.3644850254058838
Validation loss: 1.9600716124298752

Epoch: 6| Step: 7
Training loss: 2.2716140747070312
Validation loss: 1.9724672455941477

Epoch: 6| Step: 8
Training loss: 1.8765017986297607
Validation loss: 1.959552941783782

Epoch: 6| Step: 9
Training loss: 1.6687657833099365
Validation loss: 1.9712169708744172

Epoch: 6| Step: 10
Training loss: 2.1031908988952637
Validation loss: 1.987984675233082

Epoch: 6| Step: 11
Training loss: 1.5594563484191895
Validation loss: 1.9623394230360627

Epoch: 6| Step: 12
Training loss: 2.2987358570098877
Validation loss: 1.9562988012067732

Epoch: 6| Step: 13
Training loss: 2.8332772254943848
Validation loss: 1.9550720786535611

Epoch: 151| Step: 0
Training loss: 2.4024577140808105
Validation loss: 1.9942263313519057

Epoch: 6| Step: 1
Training loss: 1.2736802101135254
Validation loss: 1.9867274094653387

Epoch: 6| Step: 2
Training loss: 1.8782169818878174
Validation loss: 1.951363689155989

Epoch: 6| Step: 3
Training loss: 0.9910340905189514
Validation loss: 1.9635101159413655

Epoch: 6| Step: 4
Training loss: 2.746488571166992
Validation loss: 1.9562255259483092

Epoch: 6| Step: 5
Training loss: 2.0137674808502197
Validation loss: 1.9669602224903722

Epoch: 6| Step: 6
Training loss: 1.8005094528198242
Validation loss: 1.9556473826849332

Epoch: 6| Step: 7
Training loss: 1.4908030033111572
Validation loss: 1.94211035261872

Epoch: 6| Step: 8
Training loss: 2.095932960510254
Validation loss: 1.9430553464479343

Epoch: 6| Step: 9
Training loss: 1.8618147373199463
Validation loss: 1.9437992008783485

Epoch: 6| Step: 10
Training loss: 1.8981132507324219
Validation loss: 1.954906750750798

Epoch: 6| Step: 11
Training loss: 1.737101674079895
Validation loss: 1.981311708368281

Epoch: 6| Step: 12
Training loss: 2.631711959838867
Validation loss: 1.9614710679618261

Epoch: 6| Step: 13
Training loss: 1.5797466039657593
Validation loss: 1.9756966329390002

Epoch: 152| Step: 0
Training loss: 2.0061583518981934
Validation loss: 1.9916008698043002

Epoch: 6| Step: 1
Training loss: 2.120558738708496
Validation loss: 1.9772930965628674

Epoch: 6| Step: 2
Training loss: 1.541290283203125
Validation loss: 1.9683287758981027

Epoch: 6| Step: 3
Training loss: 2.3635294437408447
Validation loss: 1.9634352166165587

Epoch: 6| Step: 4
Training loss: 1.7636648416519165
Validation loss: 1.9843771996036652

Epoch: 6| Step: 5
Training loss: 2.3354406356811523
Validation loss: 1.9747421139030046

Epoch: 6| Step: 6
Training loss: 1.705737829208374
Validation loss: 1.9299182545754217

Epoch: 6| Step: 7
Training loss: 1.506535530090332
Validation loss: 1.9524912206075524

Epoch: 6| Step: 8
Training loss: 2.0200014114379883
Validation loss: 1.975742147814843

Epoch: 6| Step: 9
Training loss: 1.4579054117202759
Validation loss: 1.9858478000087123

Epoch: 6| Step: 10
Training loss: 0.9303867220878601
Validation loss: 1.9751107436354443

Epoch: 6| Step: 11
Training loss: 2.2654361724853516
Validation loss: 1.9716549688769924

Epoch: 6| Step: 12
Training loss: 2.30948805809021
Validation loss: 1.9899716531076739

Epoch: 6| Step: 13
Training loss: 2.442318916320801
Validation loss: 1.9556523574295865

Epoch: 153| Step: 0
Training loss: 2.0819807052612305
Validation loss: 1.9525577816911923

Epoch: 6| Step: 1
Training loss: 2.112375497817993
Validation loss: 1.9511545319711008

Epoch: 6| Step: 2
Training loss: 2.109386682510376
Validation loss: 1.9426903827216035

Epoch: 6| Step: 3
Training loss: 1.6635661125183105
Validation loss: 1.9585232298861268

Epoch: 6| Step: 4
Training loss: 2.012068748474121
Validation loss: 1.9594419669079524

Epoch: 6| Step: 5
Training loss: 2.1509146690368652
Validation loss: 1.963496317145645

Epoch: 6| Step: 6
Training loss: 2.240734338760376
Validation loss: 1.967044570112741

Epoch: 6| Step: 7
Training loss: 1.1316149234771729
Validation loss: 1.9896730863919823

Epoch: 6| Step: 8
Training loss: 1.9097309112548828
Validation loss: 1.9661593039830525

Epoch: 6| Step: 9
Training loss: 1.6809816360473633
Validation loss: 1.9632957904569563

Epoch: 6| Step: 10
Training loss: 1.5779316425323486
Validation loss: 1.9672663711732434

Epoch: 6| Step: 11
Training loss: 1.8702411651611328
Validation loss: 1.9598167198960499

Epoch: 6| Step: 12
Training loss: 2.047610282897949
Validation loss: 1.9401835959444764

Epoch: 6| Step: 13
Training loss: 2.229693651199341
Validation loss: 1.9771896152086155

Epoch: 154| Step: 0
Training loss: 1.7319666147232056
Validation loss: 1.9792393407514017

Epoch: 6| Step: 1
Training loss: 1.9177359342575073
Validation loss: 1.9502286116282146

Epoch: 6| Step: 2
Training loss: 1.2639707326889038
Validation loss: 1.9509441878205986

Epoch: 6| Step: 3
Training loss: 1.761064887046814
Validation loss: 1.931151823330951

Epoch: 6| Step: 4
Training loss: 1.46718430519104
Validation loss: 1.9601469552645119

Epoch: 6| Step: 5
Training loss: 1.3098137378692627
Validation loss: 1.9617197846853605

Epoch: 6| Step: 6
Training loss: 1.9428300857543945
Validation loss: 1.9729742375753259

Epoch: 6| Step: 7
Training loss: 2.7955169677734375
Validation loss: 1.9527457580771497

Epoch: 6| Step: 8
Training loss: 2.642033100128174
Validation loss: 1.949788426840177

Epoch: 6| Step: 9
Training loss: 1.619913101196289
Validation loss: 1.9556971365405666

Epoch: 6| Step: 10
Training loss: 2.0779809951782227
Validation loss: 1.9460641812252741

Epoch: 6| Step: 11
Training loss: 2.2395706176757812
Validation loss: 1.9804597247031428

Epoch: 6| Step: 12
Training loss: 1.2753491401672363
Validation loss: 1.9589776877434022

Epoch: 6| Step: 13
Training loss: 2.0882465839385986
Validation loss: 1.9577779667351836

Epoch: 155| Step: 0
Training loss: 1.6549456119537354
Validation loss: 1.9478817357811877

Epoch: 6| Step: 1
Training loss: 1.3459980487823486
Validation loss: 1.9726571882924726

Epoch: 6| Step: 2
Training loss: 1.930462121963501
Validation loss: 1.918613609447274

Epoch: 6| Step: 3
Training loss: 1.4056274890899658
Validation loss: 1.9527362661976968

Epoch: 6| Step: 4
Training loss: 1.3843269348144531
Validation loss: 1.9441086156393892

Epoch: 6| Step: 5
Training loss: 1.6723661422729492
Validation loss: 1.9430590803905199

Epoch: 6| Step: 6
Training loss: 1.8119025230407715
Validation loss: 1.9730389579649894

Epoch: 6| Step: 7
Training loss: 1.745712399482727
Validation loss: 1.9413659726419756

Epoch: 6| Step: 8
Training loss: 1.5963504314422607
Validation loss: 1.9526466810575096

Epoch: 6| Step: 9
Training loss: 2.7002077102661133
Validation loss: 1.9452981487397225

Epoch: 6| Step: 10
Training loss: 2.8164634704589844
Validation loss: 1.9603817642375987

Epoch: 6| Step: 11
Training loss: 1.276793122291565
Validation loss: 1.9361289931881813

Epoch: 6| Step: 12
Training loss: 2.76869535446167
Validation loss: 1.9562977603686753

Epoch: 6| Step: 13
Training loss: 2.336702823638916
Validation loss: 1.9598737839729554

Epoch: 156| Step: 0
Training loss: 1.9205505847930908
Validation loss: 1.9626905995030557

Epoch: 6| Step: 1
Training loss: 2.0336060523986816
Validation loss: 1.963531131385475

Epoch: 6| Step: 2
Training loss: 1.5926625728607178
Validation loss: 1.9761074025143859

Epoch: 6| Step: 3
Training loss: 1.9742944240570068
Validation loss: 1.9401561649896766

Epoch: 6| Step: 4
Training loss: 2.4128012657165527
Validation loss: 1.9428751186657978

Epoch: 6| Step: 5
Training loss: 1.3833975791931152
Validation loss: 1.966276188050547

Epoch: 6| Step: 6
Training loss: 2.0585694313049316
Validation loss: 1.9440415238821378

Epoch: 6| Step: 7
Training loss: 1.2740492820739746
Validation loss: 1.9423757958155807

Epoch: 6| Step: 8
Training loss: 2.226728677749634
Validation loss: 1.9410139360735494

Epoch: 6| Step: 9
Training loss: 1.8096102476119995
Validation loss: 1.9560436587179861

Epoch: 6| Step: 10
Training loss: 1.8162184953689575
Validation loss: 1.9454414152329969

Epoch: 6| Step: 11
Training loss: 1.649153232574463
Validation loss: 1.9510500533606416

Epoch: 6| Step: 12
Training loss: 2.441465377807617
Validation loss: 1.9471717547344904

Epoch: 6| Step: 13
Training loss: 1.6897850036621094
Validation loss: 1.9650431832959574

Epoch: 157| Step: 0
Training loss: 1.9727410078048706
Validation loss: 1.9522486604670042

Epoch: 6| Step: 1
Training loss: 3.0174412727355957
Validation loss: 1.9663352325398435

Epoch: 6| Step: 2
Training loss: 1.5642080307006836
Validation loss: 1.9413288267709876

Epoch: 6| Step: 3
Training loss: 2.174844741821289
Validation loss: 1.942560608668994

Epoch: 6| Step: 4
Training loss: 1.540233850479126
Validation loss: 1.9780728765713271

Epoch: 6| Step: 5
Training loss: 1.5305089950561523
Validation loss: 1.9652148292910667

Epoch: 6| Step: 6
Training loss: 1.7509781122207642
Validation loss: 1.9582577597710393

Epoch: 6| Step: 7
Training loss: 2.080711841583252
Validation loss: 1.9713222519043954

Epoch: 6| Step: 8
Training loss: 1.6769410371780396
Validation loss: 1.9365399422184113

Epoch: 6| Step: 9
Training loss: 1.5833932161331177
Validation loss: 1.949941550531695

Epoch: 6| Step: 10
Training loss: 1.857328176498413
Validation loss: 1.9834997192505868

Epoch: 6| Step: 11
Training loss: 1.4392099380493164
Validation loss: 1.9426944845466203

Epoch: 6| Step: 12
Training loss: 1.653900146484375
Validation loss: 1.9662588950126403

Epoch: 6| Step: 13
Training loss: 2.617241144180298
Validation loss: 1.9448085241420294

Epoch: 158| Step: 0
Training loss: 2.2465577125549316
Validation loss: 1.9311665924646522

Epoch: 6| Step: 1
Training loss: 1.7091295719146729
Validation loss: 1.9434225610507432

Epoch: 6| Step: 2
Training loss: 2.031928539276123
Validation loss: 1.9552677446796047

Epoch: 6| Step: 3
Training loss: 1.3960497379302979
Validation loss: 1.953056468758532

Epoch: 6| Step: 4
Training loss: 2.355308771133423
Validation loss: 1.9448085766966625

Epoch: 6| Step: 5
Training loss: 2.0488529205322266
Validation loss: 1.9706439548923123

Epoch: 6| Step: 6
Training loss: 1.7067629098892212
Validation loss: 1.963962080658123

Epoch: 6| Step: 7
Training loss: 1.6293413639068604
Validation loss: 1.954361092659735

Epoch: 6| Step: 8
Training loss: 1.571959137916565
Validation loss: 1.9420843842209026

Epoch: 6| Step: 9
Training loss: 1.5404112339019775
Validation loss: 1.9397772101945774

Epoch: 6| Step: 10
Training loss: 2.0586302280426025
Validation loss: 1.968795955822032

Epoch: 6| Step: 11
Training loss: 2.359609365463257
Validation loss: 1.9504436985138924

Epoch: 6| Step: 12
Training loss: 1.5677576065063477
Validation loss: 1.9564813131927161

Epoch: 6| Step: 13
Training loss: 2.1187753677368164
Validation loss: 1.9694024285962504

Epoch: 159| Step: 0
Training loss: 2.11350154876709
Validation loss: 1.9591091063714796

Epoch: 6| Step: 1
Training loss: 2.055628776550293
Validation loss: 1.9916847316167687

Epoch: 6| Step: 2
Training loss: 1.364532232284546
Validation loss: 1.9694785943595312

Epoch: 6| Step: 3
Training loss: 1.749314308166504
Validation loss: 1.9543199718639415

Epoch: 6| Step: 4
Training loss: 1.9515941143035889
Validation loss: 1.9567134213703934

Epoch: 6| Step: 5
Training loss: 1.2204194068908691
Validation loss: 1.9662742807019142

Epoch: 6| Step: 6
Training loss: 1.8752667903900146
Validation loss: 1.95164857884889

Epoch: 6| Step: 7
Training loss: 2.1281304359436035
Validation loss: 1.9642316769528132

Epoch: 6| Step: 8
Training loss: 1.8593817949295044
Validation loss: 1.9432457403470111

Epoch: 6| Step: 9
Training loss: 1.7321367263793945
Validation loss: 1.9494898037243915

Epoch: 6| Step: 10
Training loss: 2.0653505325317383
Validation loss: 1.931096097474457

Epoch: 6| Step: 11
Training loss: 1.9426169395446777
Validation loss: 1.937606224449732

Epoch: 6| Step: 12
Training loss: 2.0369904041290283
Validation loss: 1.9572780645021828

Epoch: 6| Step: 13
Training loss: 2.612348794937134
Validation loss: 1.9083687220850298

Epoch: 160| Step: 0
Training loss: 1.8602555990219116
Validation loss: 1.9628871487032982

Epoch: 6| Step: 1
Training loss: 2.359333038330078
Validation loss: 1.957138466578658

Epoch: 6| Step: 2
Training loss: 2.619488000869751
Validation loss: 1.94902023448739

Epoch: 6| Step: 3
Training loss: 1.3347415924072266
Validation loss: 1.9273959795633953

Epoch: 6| Step: 4
Training loss: 1.4266273975372314
Validation loss: 1.9373272131848078

Epoch: 6| Step: 5
Training loss: 2.5690550804138184
Validation loss: 1.973717579277613

Epoch: 6| Step: 6
Training loss: 2.164060592651367
Validation loss: 1.9507867290127663

Epoch: 6| Step: 7
Training loss: 1.6976103782653809
Validation loss: 1.9555804973007531

Epoch: 6| Step: 8
Training loss: 1.500281572341919
Validation loss: 1.937474686612365

Epoch: 6| Step: 9
Training loss: 2.0428924560546875
Validation loss: 1.9505813288432297

Epoch: 6| Step: 10
Training loss: 0.8048250079154968
Validation loss: 1.9837459389881422

Epoch: 6| Step: 11
Training loss: 1.9033104181289673
Validation loss: 1.9442675934042981

Epoch: 6| Step: 12
Training loss: 1.8350670337677002
Validation loss: 1.9588978393103487

Epoch: 6| Step: 13
Training loss: 2.419320821762085
Validation loss: 1.9832749366760254

Epoch: 161| Step: 0
Training loss: 1.9613535404205322
Validation loss: 1.962737032162246

Epoch: 6| Step: 1
Training loss: 2.453925609588623
Validation loss: 1.959037398779264

Epoch: 6| Step: 2
Training loss: 1.8807005882263184
Validation loss: 1.967952069415841

Epoch: 6| Step: 3
Training loss: 2.5913777351379395
Validation loss: 1.9422771802512548

Epoch: 6| Step: 4
Training loss: 1.6481884717941284
Validation loss: 1.958765955381496

Epoch: 6| Step: 5
Training loss: 2.023247241973877
Validation loss: 1.9624541844091108

Epoch: 6| Step: 6
Training loss: 1.7326078414916992
Validation loss: 1.9319725446803595

Epoch: 6| Step: 7
Training loss: 1.2775155305862427
Validation loss: 1.942139466603597

Epoch: 6| Step: 8
Training loss: 2.173313856124878
Validation loss: 1.9391183904422227

Epoch: 6| Step: 9
Training loss: 1.4112401008605957
Validation loss: 1.9510342023705924

Epoch: 6| Step: 10
Training loss: 1.4693909883499146
Validation loss: 1.9558226959679716

Epoch: 6| Step: 11
Training loss: 1.6422021389007568
Validation loss: 1.9546850663359447

Epoch: 6| Step: 12
Training loss: 1.513095498085022
Validation loss: 1.9677781968988397

Epoch: 6| Step: 13
Training loss: 2.210034132003784
Validation loss: 1.9627572733868834

Epoch: 162| Step: 0
Training loss: 2.007009267807007
Validation loss: 1.9657130831031389

Epoch: 6| Step: 1
Training loss: 1.9274097681045532
Validation loss: 1.932391043632261

Epoch: 6| Step: 2
Training loss: 2.274752378463745
Validation loss: 1.9564449543594031

Epoch: 6| Step: 3
Training loss: 2.583486557006836
Validation loss: 1.941781747725702

Epoch: 6| Step: 4
Training loss: 1.7238433361053467
Validation loss: 1.9277156360687748

Epoch: 6| Step: 5
Training loss: 1.7427878379821777
Validation loss: 1.9366990943108835

Epoch: 6| Step: 6
Training loss: 2.086333751678467
Validation loss: 1.939813680546258

Epoch: 6| Step: 7
Training loss: 2.4934768676757812
Validation loss: 1.9272422828981954

Epoch: 6| Step: 8
Training loss: 1.9596260786056519
Validation loss: 1.926738526231499

Epoch: 6| Step: 9
Training loss: 1.6227494478225708
Validation loss: 1.9410457867448048

Epoch: 6| Step: 10
Training loss: 1.2562243938446045
Validation loss: 1.944307409307008

Epoch: 6| Step: 11
Training loss: 1.2188621759414673
Validation loss: 1.9450105415877474

Epoch: 6| Step: 12
Training loss: 1.4758241176605225
Validation loss: 1.9341171646630892

Epoch: 6| Step: 13
Training loss: 1.0264897346496582
Validation loss: 1.9673174504310853

Epoch: 163| Step: 0
Training loss: 1.4570558071136475
Validation loss: 1.9744414257746872

Epoch: 6| Step: 1
Training loss: 1.9318103790283203
Validation loss: 1.9333754457453245

Epoch: 6| Step: 2
Training loss: 1.7451488971710205
Validation loss: 1.9527539591635428

Epoch: 6| Step: 3
Training loss: 1.8798229694366455
Validation loss: 1.9435065971907748

Epoch: 6| Step: 4
Training loss: 1.1362227201461792
Validation loss: 1.9354697568442232

Epoch: 6| Step: 5
Training loss: 2.1013846397399902
Validation loss: 1.945722528683242

Epoch: 6| Step: 6
Training loss: 2.3513073921203613
Validation loss: 1.949717926722701

Epoch: 6| Step: 7
Training loss: 2.484827995300293
Validation loss: 1.9494767970936273

Epoch: 6| Step: 8
Training loss: 1.1423935890197754
Validation loss: 1.9294488327477568

Epoch: 6| Step: 9
Training loss: 1.7291760444641113
Validation loss: 1.9431998473341747

Epoch: 6| Step: 10
Training loss: 1.8632887601852417
Validation loss: 1.9338166559896162

Epoch: 6| Step: 11
Training loss: 2.6963353157043457
Validation loss: 1.940789779027303

Epoch: 6| Step: 12
Training loss: 1.9985462427139282
Validation loss: 1.9577733515411295

Epoch: 6| Step: 13
Training loss: 0.8311676383018494
Validation loss: 1.9139307852714293

Epoch: 164| Step: 0
Training loss: 1.8944077491760254
Validation loss: 1.9308405947941605

Epoch: 6| Step: 1
Training loss: 2.1105480194091797
Validation loss: 1.9377516085101711

Epoch: 6| Step: 2
Training loss: 1.3956987857818604
Validation loss: 1.9594470454800514

Epoch: 6| Step: 3
Training loss: 1.1887636184692383
Validation loss: 1.936116849222491

Epoch: 6| Step: 4
Training loss: 1.5248260498046875
Validation loss: 1.94567669335232

Epoch: 6| Step: 5
Training loss: 2.265843391418457
Validation loss: 1.9343780984160721

Epoch: 6| Step: 6
Training loss: 1.2384884357452393
Validation loss: 1.9369917774713168

Epoch: 6| Step: 7
Training loss: 2.2466273307800293
Validation loss: 1.9361433559848416

Epoch: 6| Step: 8
Training loss: 1.9643722772598267
Validation loss: 1.9546462899895125

Epoch: 6| Step: 9
Training loss: 2.4848995208740234
Validation loss: 1.9531230849604453

Epoch: 6| Step: 10
Training loss: 1.8722602128982544
Validation loss: 1.9185526050547117

Epoch: 6| Step: 11
Training loss: 1.829378604888916
Validation loss: 1.9259844723568167

Epoch: 6| Step: 12
Training loss: 1.882182240486145
Validation loss: 1.932282901579334

Epoch: 6| Step: 13
Training loss: 1.7816712856292725
Validation loss: 1.919274668539724

Epoch: 165| Step: 0
Training loss: 1.3018327951431274
Validation loss: 1.9498446884975638

Epoch: 6| Step: 1
Training loss: 1.7066011428833008
Validation loss: 1.9185906199998752

Epoch: 6| Step: 2
Training loss: 1.9485771656036377
Validation loss: 1.9759657613692745

Epoch: 6| Step: 3
Training loss: 1.5610508918762207
Validation loss: 1.9575666919831307

Epoch: 6| Step: 4
Training loss: 1.8140108585357666
Validation loss: 1.9453734941379999

Epoch: 6| Step: 5
Training loss: 1.3328077793121338
Validation loss: 1.9395506740898214

Epoch: 6| Step: 6
Training loss: 1.1804523468017578
Validation loss: 1.915906984318969

Epoch: 6| Step: 7
Training loss: 1.4109399318695068
Validation loss: 1.9702857309772122

Epoch: 6| Step: 8
Training loss: 2.5845584869384766
Validation loss: 1.9467977862204275

Epoch: 6| Step: 9
Training loss: 2.6077017784118652
Validation loss: 1.9468857165305846

Epoch: 6| Step: 10
Training loss: 1.8805599212646484
Validation loss: 1.937518835067749

Epoch: 6| Step: 11
Training loss: 2.1679248809814453
Validation loss: 1.9524196219700638

Epoch: 6| Step: 12
Training loss: 2.0985944271087646
Validation loss: 1.946102088497531

Epoch: 6| Step: 13
Training loss: 2.538705825805664
Validation loss: 1.9268677580741145

Epoch: 166| Step: 0
Training loss: 2.0491085052490234
Validation loss: 1.908218059488522

Epoch: 6| Step: 1
Training loss: 2.2721493244171143
Validation loss: 1.9191612248779626

Epoch: 6| Step: 2
Training loss: 1.798172116279602
Validation loss: 1.93513669249832

Epoch: 6| Step: 3
Training loss: 1.7582988739013672
Validation loss: 1.9146146415382304

Epoch: 6| Step: 4
Training loss: 1.2923245429992676
Validation loss: 1.9310528770569833

Epoch: 6| Step: 5
Training loss: 1.8998169898986816
Validation loss: 1.9250642920053134

Epoch: 6| Step: 6
Training loss: 1.5849307775497437
Validation loss: 1.9212760271564606

Epoch: 6| Step: 7
Training loss: 2.187776803970337
Validation loss: 1.948866262230822

Epoch: 6| Step: 8
Training loss: 1.6620664596557617
Validation loss: 1.9590167717267108

Epoch: 6| Step: 9
Training loss: 1.3108913898468018
Validation loss: 1.9380880325071272

Epoch: 6| Step: 10
Training loss: 2.660135269165039
Validation loss: 1.9426975416880783

Epoch: 6| Step: 11
Training loss: 1.759535312652588
Validation loss: 1.9543492845309678

Epoch: 6| Step: 12
Training loss: 1.7747478485107422
Validation loss: 1.9388364553451538

Epoch: 6| Step: 13
Training loss: 1.7606580257415771
Validation loss: 1.9397393631678757

Epoch: 167| Step: 0
Training loss: 1.5037182569503784
Validation loss: 1.9257874155557284

Epoch: 6| Step: 1
Training loss: 2.4086506366729736
Validation loss: 1.9467198579542098

Epoch: 6| Step: 2
Training loss: 1.4841783046722412
Validation loss: 1.919010216189969

Epoch: 6| Step: 3
Training loss: 1.6687769889831543
Validation loss: 1.9380101157772927

Epoch: 6| Step: 4
Training loss: 1.9222211837768555
Validation loss: 1.9319924231498473

Epoch: 6| Step: 5
Training loss: 1.556099534034729
Validation loss: 1.925422958148423

Epoch: 6| Step: 6
Training loss: 1.4509804248809814
Validation loss: 1.8894054005222936

Epoch: 6| Step: 7
Training loss: 2.3428735733032227
Validation loss: 1.9285906309722571

Epoch: 6| Step: 8
Training loss: 1.7358578443527222
Validation loss: 1.9385257997820455

Epoch: 6| Step: 9
Training loss: 1.7513275146484375
Validation loss: 1.9169956919967488

Epoch: 6| Step: 10
Training loss: 1.7205508947372437
Validation loss: 1.9363645276715677

Epoch: 6| Step: 11
Training loss: 2.0339932441711426
Validation loss: 1.9611515883476502

Epoch: 6| Step: 12
Training loss: 1.7392361164093018
Validation loss: 1.9025205732673727

Epoch: 6| Step: 13
Training loss: 2.507282018661499
Validation loss: 1.921644087760679

Epoch: 168| Step: 0
Training loss: 1.392680287361145
Validation loss: 1.948508265197918

Epoch: 6| Step: 1
Training loss: 2.6282036304473877
Validation loss: 1.90778725506157

Epoch: 6| Step: 2
Training loss: 1.8972947597503662
Validation loss: 1.8957790610610799

Epoch: 6| Step: 3
Training loss: 1.4798698425292969
Validation loss: 1.9030756488923104

Epoch: 6| Step: 4
Training loss: 1.3910183906555176
Validation loss: 1.9202737628772695

Epoch: 6| Step: 5
Training loss: 2.2052547931671143
Validation loss: 1.920995763553086

Epoch: 6| Step: 6
Training loss: 1.7221943140029907
Validation loss: 1.9186015462362638

Epoch: 6| Step: 7
Training loss: 1.2463738918304443
Validation loss: 1.9242366821535173

Epoch: 6| Step: 8
Training loss: 1.7956328392028809
Validation loss: 1.8914485849359983

Epoch: 6| Step: 9
Training loss: 1.5734505653381348
Validation loss: 1.9525348319802234

Epoch: 6| Step: 10
Training loss: 1.9851343631744385
Validation loss: 1.9441346224918161

Epoch: 6| Step: 11
Training loss: 2.5124497413635254
Validation loss: 1.925203869419713

Epoch: 6| Step: 12
Training loss: 2.1470866203308105
Validation loss: 1.938248925311591

Epoch: 6| Step: 13
Training loss: 1.196892499923706
Validation loss: 1.9272920546993133

Epoch: 169| Step: 0
Training loss: 2.0839059352874756
Validation loss: 1.9029880185281076

Epoch: 6| Step: 1
Training loss: 3.07722806930542
Validation loss: 1.9188519293262112

Epoch: 6| Step: 2
Training loss: 1.3609437942504883
Validation loss: 1.91514556125928

Epoch: 6| Step: 3
Training loss: 2.4162490367889404
Validation loss: 1.945644570935157

Epoch: 6| Step: 4
Training loss: 1.6390248537063599
Validation loss: 1.9603933160023024

Epoch: 6| Step: 5
Training loss: 2.0590739250183105
Validation loss: 1.929217512889575

Epoch: 6| Step: 6
Training loss: 1.753523349761963
Validation loss: 1.956264550967883

Epoch: 6| Step: 7
Training loss: 1.5426814556121826
Validation loss: 1.9467650972386843

Epoch: 6| Step: 8
Training loss: 1.866363286972046
Validation loss: 1.9302833951929563

Epoch: 6| Step: 9
Training loss: 1.3141058683395386
Validation loss: 1.9013912690583097

Epoch: 6| Step: 10
Training loss: 1.9459635019302368
Validation loss: 1.9262145770493375

Epoch: 6| Step: 11
Training loss: 1.6747491359710693
Validation loss: 1.9489878198151946

Epoch: 6| Step: 12
Training loss: 1.4080348014831543
Validation loss: 1.9256632225487822

Epoch: 6| Step: 13
Training loss: 1.2202706336975098
Validation loss: 1.956312233401883

Epoch: 170| Step: 0
Training loss: 1.8392988443374634
Validation loss: 1.9261231332696893

Epoch: 6| Step: 1
Training loss: 1.681786298751831
Validation loss: 1.9497352389879123

Epoch: 6| Step: 2
Training loss: 2.1191208362579346
Validation loss: 1.9248531338989094

Epoch: 6| Step: 3
Training loss: 2.087303400039673
Validation loss: 1.952794462121943

Epoch: 6| Step: 4
Training loss: 1.4203081130981445
Validation loss: 1.92776822018367

Epoch: 6| Step: 5
Training loss: 2.1303563117980957
Validation loss: 1.947452138828975

Epoch: 6| Step: 6
Training loss: 1.473306655883789
Validation loss: 1.9017392768654773

Epoch: 6| Step: 7
Training loss: 1.6028598546981812
Validation loss: 1.9215428495919833

Epoch: 6| Step: 8
Training loss: 1.3510701656341553
Validation loss: 1.9248010881485478

Epoch: 6| Step: 9
Training loss: 1.7553234100341797
Validation loss: 1.8981532230172107

Epoch: 6| Step: 10
Training loss: 2.700131416320801
Validation loss: 1.901985724767049

Epoch: 6| Step: 11
Training loss: 1.961240530014038
Validation loss: 1.9047019161203855

Epoch: 6| Step: 12
Training loss: 1.5789644718170166
Validation loss: 1.912177042294574

Epoch: 6| Step: 13
Training loss: 1.6559853553771973
Validation loss: 1.927123967037406

Epoch: 171| Step: 0
Training loss: 1.7384254932403564
Validation loss: 1.9189189890379548

Epoch: 6| Step: 1
Training loss: 2.261654853820801
Validation loss: 1.9100527148092947

Epoch: 6| Step: 2
Training loss: 1.8677756786346436
Validation loss: 1.9231153713759555

Epoch: 6| Step: 3
Training loss: 1.829122543334961
Validation loss: 1.9252042103839178

Epoch: 6| Step: 4
Training loss: 2.4984078407287598
Validation loss: 1.9156708563527753

Epoch: 6| Step: 5
Training loss: 1.9417078495025635
Validation loss: 1.9473274048938547

Epoch: 6| Step: 6
Training loss: 1.9116981029510498
Validation loss: 1.9136932460210656

Epoch: 6| Step: 7
Training loss: 1.7297899723052979
Validation loss: 1.9438456091829526

Epoch: 6| Step: 8
Training loss: 2.1046292781829834
Validation loss: 1.94106767254491

Epoch: 6| Step: 9
Training loss: 1.3628207445144653
Validation loss: 1.9276871706849785

Epoch: 6| Step: 10
Training loss: 1.521562099456787
Validation loss: 1.925977704345539

Epoch: 6| Step: 11
Training loss: 1.546778917312622
Validation loss: 1.92831927217463

Epoch: 6| Step: 12
Training loss: 1.0561238527297974
Validation loss: 1.9404655246324436

Epoch: 6| Step: 13
Training loss: 2.2618720531463623
Validation loss: 1.942735195159912

Epoch: 172| Step: 0
Training loss: 1.2840379476547241
Validation loss: 1.9290480485526464

Epoch: 6| Step: 1
Training loss: 1.836108684539795
Validation loss: 1.907598473692453

Epoch: 6| Step: 2
Training loss: 2.613330364227295
Validation loss: 1.9189783475732292

Epoch: 6| Step: 3
Training loss: 2.0935206413269043
Validation loss: 1.9092087476484236

Epoch: 6| Step: 4
Training loss: 1.500005841255188
Validation loss: 1.9413942739527712

Epoch: 6| Step: 5
Training loss: 1.1299653053283691
Validation loss: 1.9609781183222288

Epoch: 6| Step: 6
Training loss: 2.6253342628479004
Validation loss: 1.9327998488180098

Epoch: 6| Step: 7
Training loss: 1.6470303535461426
Validation loss: 1.961538701929072

Epoch: 6| Step: 8
Training loss: 1.8506323099136353
Validation loss: 1.9484733855852516

Epoch: 6| Step: 9
Training loss: 1.7426236867904663
Validation loss: 1.9417760731071554

Epoch: 6| Step: 10
Training loss: 1.3704006671905518
Validation loss: 1.9274993583720217

Epoch: 6| Step: 11
Training loss: 2.367032051086426
Validation loss: 1.9276623815618537

Epoch: 6| Step: 12
Training loss: 1.3668667078018188
Validation loss: 1.9498721066341604

Epoch: 6| Step: 13
Training loss: 2.661106586456299
Validation loss: 1.9030619487967542

Epoch: 173| Step: 0
Training loss: 1.6915987730026245
Validation loss: 1.9257825830931306

Epoch: 6| Step: 1
Training loss: 1.5330491065979004
Validation loss: 1.9032499662009619

Epoch: 6| Step: 2
Training loss: 2.191494941711426
Validation loss: 1.9074642632597236

Epoch: 6| Step: 3
Training loss: 1.5824859142303467
Validation loss: 1.925063435749341

Epoch: 6| Step: 4
Training loss: 1.4532122611999512
Validation loss: 1.9011834013846614

Epoch: 6| Step: 5
Training loss: 1.6879582405090332
Validation loss: 1.9281975953809676

Epoch: 6| Step: 6
Training loss: 1.9102461338043213
Validation loss: 1.935556024633428

Epoch: 6| Step: 7
Training loss: 1.8521958589553833
Validation loss: 1.9143108719138688

Epoch: 6| Step: 8
Training loss: 2.350424289703369
Validation loss: 1.9142370967454807

Epoch: 6| Step: 9
Training loss: 2.072944402694702
Validation loss: 1.9220165206540016

Epoch: 6| Step: 10
Training loss: 1.8357160091400146
Validation loss: 1.9493542909622192

Epoch: 6| Step: 11
Training loss: 1.5674785375595093
Validation loss: 1.9223480775792112

Epoch: 6| Step: 12
Training loss: 2.1334733963012695
Validation loss: 1.971062143643697

Epoch: 6| Step: 13
Training loss: 2.084557056427002
Validation loss: 1.9104870609057847

Epoch: 174| Step: 0
Training loss: 1.7019009590148926
Validation loss: 1.9215561920596707

Epoch: 6| Step: 1
Training loss: 1.4219117164611816
Validation loss: 1.911705010680742

Epoch: 6| Step: 2
Training loss: 1.9041147232055664
Validation loss: 1.9213669838443879

Epoch: 6| Step: 3
Training loss: 2.3976545333862305
Validation loss: 1.95428595876181

Epoch: 6| Step: 4
Training loss: 1.3210229873657227
Validation loss: 1.9066400643317931

Epoch: 6| Step: 5
Training loss: 2.5257790088653564
Validation loss: 1.912308931350708

Epoch: 6| Step: 6
Training loss: 1.1903862953186035
Validation loss: 1.9013869172783309

Epoch: 6| Step: 7
Training loss: 1.4272711277008057
Validation loss: 1.9413419397928382

Epoch: 6| Step: 8
Training loss: 2.8492989540100098
Validation loss: 1.921907982518596

Epoch: 6| Step: 9
Training loss: 1.2361469268798828
Validation loss: 1.9325083737732263

Epoch: 6| Step: 10
Training loss: 1.4659287929534912
Validation loss: 1.8982561044795538

Epoch: 6| Step: 11
Training loss: 2.138812780380249
Validation loss: 1.8945605908670733

Epoch: 6| Step: 12
Training loss: 2.078005790710449
Validation loss: 1.9266694899528258

Epoch: 6| Step: 13
Training loss: 1.488194465637207
Validation loss: 1.9341898143932383

Epoch: 175| Step: 0
Training loss: 1.0326670408248901
Validation loss: 1.903861980284414

Epoch: 6| Step: 1
Training loss: 1.6911638975143433
Validation loss: 1.8933482618742092

Epoch: 6| Step: 2
Training loss: 1.7935028076171875
Validation loss: 1.9062588445601925

Epoch: 6| Step: 3
Training loss: 2.414820671081543
Validation loss: 1.9325404859358264

Epoch: 6| Step: 4
Training loss: 2.3361735343933105
Validation loss: 1.9266528519251014

Epoch: 6| Step: 5
Training loss: 1.534062385559082
Validation loss: 1.9521703168910036

Epoch: 6| Step: 6
Training loss: 1.4552218914031982
Validation loss: 1.9282189402528989

Epoch: 6| Step: 7
Training loss: 2.1492063999176025
Validation loss: 1.9238402087201354

Epoch: 6| Step: 8
Training loss: 1.8320434093475342
Validation loss: 1.911091773740707

Epoch: 6| Step: 9
Training loss: 2.133150577545166
Validation loss: 1.9621226121020574

Epoch: 6| Step: 10
Training loss: 1.4705249071121216
Validation loss: 1.9155444009329683

Epoch: 6| Step: 11
Training loss: 2.0543980598449707
Validation loss: 1.9255596463398268

Epoch: 6| Step: 12
Training loss: 1.9209182262420654
Validation loss: 1.9695588516932663

Epoch: 6| Step: 13
Training loss: 1.7015094757080078
Validation loss: 1.9569558776834959

Epoch: 176| Step: 0
Training loss: 1.311112403869629
Validation loss: 1.9260395239758235

Epoch: 6| Step: 1
Training loss: 2.088404893875122
Validation loss: 1.9159800134679323

Epoch: 6| Step: 2
Training loss: 1.6928086280822754
Validation loss: 1.9187028914369562

Epoch: 6| Step: 3
Training loss: 1.9674553871154785
Validation loss: 1.9343014365883284

Epoch: 6| Step: 4
Training loss: 1.4510116577148438
Validation loss: 1.9321493128294587

Epoch: 6| Step: 5
Training loss: 2.6993892192840576
Validation loss: 1.9453118885717084

Epoch: 6| Step: 6
Training loss: 1.6595702171325684
Validation loss: 1.936804643241308

Epoch: 6| Step: 7
Training loss: 2.509387731552124
Validation loss: 1.9069795993066603

Epoch: 6| Step: 8
Training loss: 2.016068458557129
Validation loss: 1.895541226992043

Epoch: 6| Step: 9
Training loss: 2.2507266998291016
Validation loss: 1.9225517396003968

Epoch: 6| Step: 10
Training loss: 2.113832473754883
Validation loss: 1.9387726155660485

Epoch: 6| Step: 11
Training loss: 0.954554557800293
Validation loss: 1.944121330015121

Epoch: 6| Step: 12
Training loss: 1.2888615131378174
Validation loss: 1.9041093293056692

Epoch: 6| Step: 13
Training loss: 0.8644485473632812
Validation loss: 1.935225789264966

Epoch: 177| Step: 0
Training loss: 1.2236328125
Validation loss: 1.911457730877784

Epoch: 6| Step: 1
Training loss: 1.8402785062789917
Validation loss: 1.9367168731586908

Epoch: 6| Step: 2
Training loss: 1.830811619758606
Validation loss: 1.9123305595049294

Epoch: 6| Step: 3
Training loss: 1.8935511112213135
Validation loss: 1.9353740587029407

Epoch: 6| Step: 4
Training loss: 2.46968674659729
Validation loss: 1.9188642142921366

Epoch: 6| Step: 5
Training loss: 1.9344234466552734
Validation loss: 1.926768607990716

Epoch: 6| Step: 6
Training loss: 1.980932354927063
Validation loss: 1.8950614762562576

Epoch: 6| Step: 7
Training loss: 1.471935510635376
Validation loss: 1.916771601605159

Epoch: 6| Step: 8
Training loss: 2.148408889770508
Validation loss: 1.9186261071953723

Epoch: 6| Step: 9
Training loss: 1.1598058938980103
Validation loss: 1.8791145586198377

Epoch: 6| Step: 10
Training loss: 1.9890819787979126
Validation loss: 1.894940960791803

Epoch: 6| Step: 11
Training loss: 1.0539956092834473
Validation loss: 1.9153754685514717

Epoch: 6| Step: 12
Training loss: 1.927185297012329
Validation loss: 1.9010866982962495

Epoch: 6| Step: 13
Training loss: 2.3371975421905518
Validation loss: 1.8910195532665457

Epoch: 178| Step: 0
Training loss: 1.171727180480957
Validation loss: 1.9232673209200624

Epoch: 6| Step: 1
Training loss: 1.5843236446380615
Validation loss: 1.9033140418350056

Epoch: 6| Step: 2
Training loss: 1.9536000490188599
Validation loss: 1.96038124510037

Epoch: 6| Step: 3
Training loss: 1.8043708801269531
Validation loss: 1.9235061483998452

Epoch: 6| Step: 4
Training loss: 1.7653253078460693
Validation loss: 1.9385487892294442

Epoch: 6| Step: 5
Training loss: 2.4328956604003906
Validation loss: 1.9283647793595509

Epoch: 6| Step: 6
Training loss: 1.6665233373641968
Validation loss: 1.9469570293221423

Epoch: 6| Step: 7
Training loss: 2.334569215774536
Validation loss: 1.8796826575392036

Epoch: 6| Step: 8
Training loss: 1.6925228834152222
Validation loss: 1.9093556839932677

Epoch: 6| Step: 9
Training loss: 1.4464664459228516
Validation loss: 1.9352977839849328

Epoch: 6| Step: 10
Training loss: 1.413266897201538
Validation loss: 1.929101497896256

Epoch: 6| Step: 11
Training loss: 2.1081771850585938
Validation loss: 1.951627589041187

Epoch: 6| Step: 12
Training loss: 1.702278971672058
Validation loss: 1.9023104239535589

Epoch: 6| Step: 13
Training loss: 2.610877752304077
Validation loss: 1.9020537637895154

Epoch: 179| Step: 0
Training loss: 1.9547524452209473
Validation loss: 1.9348711018921227

Epoch: 6| Step: 1
Training loss: 1.075153112411499
Validation loss: 1.9356534070866083

Epoch: 6| Step: 2
Training loss: 2.424221992492676
Validation loss: 1.918223960425264

Epoch: 6| Step: 3
Training loss: 2.1472272872924805
Validation loss: 1.9478521488046134

Epoch: 6| Step: 4
Training loss: 2.30466365814209
Validation loss: 1.9139617322593607

Epoch: 6| Step: 5
Training loss: 1.4139233827590942
Validation loss: 1.9423260701599943

Epoch: 6| Step: 6
Training loss: 1.4212497472763062
Validation loss: 1.9318361013166365

Epoch: 6| Step: 7
Training loss: 1.826139211654663
Validation loss: 1.8899455198677637

Epoch: 6| Step: 8
Training loss: 2.2401514053344727
Validation loss: 1.8873697339847524

Epoch: 6| Step: 9
Training loss: 1.511073350906372
Validation loss: 1.9446179853972567

Epoch: 6| Step: 10
Training loss: 1.741180658340454
Validation loss: 1.9129753253793205

Epoch: 6| Step: 11
Training loss: 1.6780564785003662
Validation loss: 1.8978566264593473

Epoch: 6| Step: 12
Training loss: 1.7210969924926758
Validation loss: 1.9012908140818279

Epoch: 6| Step: 13
Training loss: 1.4305723905563354
Validation loss: 1.9017827972289054

Epoch: 180| Step: 0
Training loss: 2.5794522762298584
Validation loss: 1.9349102640664706

Epoch: 6| Step: 1
Training loss: 2.2599551677703857
Validation loss: 1.9427958175700197

Epoch: 6| Step: 2
Training loss: 2.0378923416137695
Validation loss: 1.9001339097176828

Epoch: 6| Step: 3
Training loss: 1.34084153175354
Validation loss: 1.9208010024921869

Epoch: 6| Step: 4
Training loss: 1.2576684951782227
Validation loss: 1.9086243875565068

Epoch: 6| Step: 5
Training loss: 1.9598498344421387
Validation loss: 1.904990715365256

Epoch: 6| Step: 6
Training loss: 1.1801469326019287
Validation loss: 1.91904192842463

Epoch: 6| Step: 7
Training loss: 1.8493056297302246
Validation loss: 1.9261178239699333

Epoch: 6| Step: 8
Training loss: 1.831667184829712
Validation loss: 1.9417897655117897

Epoch: 6| Step: 9
Training loss: 1.8673183917999268
Validation loss: 1.916612877640673

Epoch: 6| Step: 10
Training loss: 0.8166426420211792
Validation loss: 1.9268685015298987

Epoch: 6| Step: 11
Training loss: 1.6952440738677979
Validation loss: 1.9166736859147266

Epoch: 6| Step: 12
Training loss: 2.4670958518981934
Validation loss: 1.8755880427616898

Epoch: 6| Step: 13
Training loss: 2.1002676486968994
Validation loss: 1.8938549564730736

Epoch: 181| Step: 0
Training loss: 1.692445158958435
Validation loss: 1.8924189998257546

Epoch: 6| Step: 1
Training loss: 1.7597362995147705
Validation loss: 1.9000353531170917

Epoch: 6| Step: 2
Training loss: 1.172350525856018
Validation loss: 1.8975564869501258

Epoch: 6| Step: 3
Training loss: 2.4056591987609863
Validation loss: 1.8508343286411737

Epoch: 6| Step: 4
Training loss: 1.6546812057495117
Validation loss: 1.9039717002581524

Epoch: 6| Step: 5
Training loss: 1.8444234132766724
Validation loss: 1.912063995997111

Epoch: 6| Step: 6
Training loss: 1.8569774627685547
Validation loss: 1.9096457714675574

Epoch: 6| Step: 7
Training loss: 2.2933640480041504
Validation loss: 1.8890029589335124

Epoch: 6| Step: 8
Training loss: 2.3958616256713867
Validation loss: 1.8981140736610658

Epoch: 6| Step: 9
Training loss: 1.6440210342407227
Validation loss: 1.9095885445994716

Epoch: 6| Step: 10
Training loss: 1.0949071645736694
Validation loss: 1.9025148678851385

Epoch: 6| Step: 11
Training loss: 2.024524688720703
Validation loss: 1.9147016335559148

Epoch: 6| Step: 12
Training loss: 1.1969826221466064
Validation loss: 1.8915004499496952

Epoch: 6| Step: 13
Training loss: 2.252169370651245
Validation loss: 1.8694590548033356

Epoch: 182| Step: 0
Training loss: 1.601266860961914
Validation loss: 1.9109006735586351

Epoch: 6| Step: 1
Training loss: 1.8574198484420776
Validation loss: 1.9491050730469406

Epoch: 6| Step: 2
Training loss: 1.799452543258667
Validation loss: 1.8980003197987874

Epoch: 6| Step: 3
Training loss: 2.00018310546875
Validation loss: 1.9349634070550241

Epoch: 6| Step: 4
Training loss: 2.0988833904266357
Validation loss: 1.9315052032470703

Epoch: 6| Step: 5
Training loss: 1.864023208618164
Validation loss: 1.9175667083391579

Epoch: 6| Step: 6
Training loss: 1.7429381608963013
Validation loss: 1.9355031956908524

Epoch: 6| Step: 7
Training loss: 1.5087138414382935
Validation loss: 1.9322761181862123

Epoch: 6| Step: 8
Training loss: 2.358038902282715
Validation loss: 1.9306348716059039

Epoch: 6| Step: 9
Training loss: 1.8743536472320557
Validation loss: 1.950269745242211

Epoch: 6| Step: 10
Training loss: 2.079508066177368
Validation loss: 1.9204010143074939

Epoch: 6| Step: 11
Training loss: 1.6822865009307861
Validation loss: 1.9319918040306336

Epoch: 6| Step: 12
Training loss: 1.3569486141204834
Validation loss: 1.9151209272364134

Epoch: 6| Step: 13
Training loss: 1.35434091091156
Validation loss: 1.9052041038390128

Epoch: 183| Step: 0
Training loss: 2.1355082988739014
Validation loss: 1.8866110399205198

Epoch: 6| Step: 1
Training loss: 1.1402418613433838
Validation loss: 1.8702092785989084

Epoch: 6| Step: 2
Training loss: 2.081712245941162
Validation loss: 1.9267826593050392

Epoch: 6| Step: 3
Training loss: 1.432279109954834
Validation loss: 1.8912359822180964

Epoch: 6| Step: 4
Training loss: 1.574967384338379
Validation loss: 1.9131210234857374

Epoch: 6| Step: 5
Training loss: 1.9049745798110962
Validation loss: 1.895068399367794

Epoch: 6| Step: 6
Training loss: 1.9272395372390747
Validation loss: 1.9201784005729101

Epoch: 6| Step: 7
Training loss: 1.33719003200531
Validation loss: 1.8943403882365073

Epoch: 6| Step: 8
Training loss: 1.954826831817627
Validation loss: 1.8981954564330399

Epoch: 6| Step: 9
Training loss: 1.8630967140197754
Validation loss: 1.9077787732565274

Epoch: 6| Step: 10
Training loss: 2.1828036308288574
Validation loss: 1.9031125960811492

Epoch: 6| Step: 11
Training loss: 1.993668794631958
Validation loss: 1.886117322470552

Epoch: 6| Step: 12
Training loss: 1.5678666830062866
Validation loss: 1.9081090342613958

Epoch: 6| Step: 13
Training loss: 2.748002529144287
Validation loss: 1.879412498525394

Epoch: 184| Step: 0
Training loss: 1.3672133684158325
Validation loss: 1.905901410246408

Epoch: 6| Step: 1
Training loss: 1.6379263401031494
Validation loss: 1.8907700225871096

Epoch: 6| Step: 2
Training loss: 1.6615335941314697
Validation loss: 1.9118356550893476

Epoch: 6| Step: 3
Training loss: 1.9548382759094238
Validation loss: 1.89648727960484

Epoch: 6| Step: 4
Training loss: 1.083437204360962
Validation loss: 1.953125048709172

Epoch: 6| Step: 5
Training loss: 2.515580654144287
Validation loss: 1.92365441911964

Epoch: 6| Step: 6
Training loss: 1.841759443283081
Validation loss: 1.9071694189502346

Epoch: 6| Step: 7
Training loss: 2.187883138656616
Validation loss: 1.9098364576216666

Epoch: 6| Step: 8
Training loss: 2.3365161418914795
Validation loss: 1.941662270535705

Epoch: 6| Step: 9
Training loss: 1.6473922729492188
Validation loss: 1.9524276512925343

Epoch: 6| Step: 10
Training loss: 1.5859845876693726
Validation loss: 1.9305728481661888

Epoch: 6| Step: 11
Training loss: 1.8215099573135376
Validation loss: 1.9205803332790252

Epoch: 6| Step: 12
Training loss: 1.251708984375
Validation loss: 1.9345941825579571

Epoch: 6| Step: 13
Training loss: 2.2679598331451416
Validation loss: 1.9414714267176967

Epoch: 185| Step: 0
Training loss: 0.9491205215454102
Validation loss: 1.8629424084899247

Epoch: 6| Step: 1
Training loss: 2.221634864807129
Validation loss: 1.9509912613899476

Epoch: 6| Step: 2
Training loss: 2.359266519546509
Validation loss: 1.8881862176361905

Epoch: 6| Step: 3
Training loss: 2.040174961090088
Validation loss: 1.8638273567281745

Epoch: 6| Step: 4
Training loss: 1.7757213115692139
Validation loss: 1.8937950352186799

Epoch: 6| Step: 5
Training loss: 2.117128849029541
Validation loss: 1.913671249984413

Epoch: 6| Step: 6
Training loss: 1.4821643829345703
Validation loss: 1.9074441156079691

Epoch: 6| Step: 7
Training loss: 1.4527533054351807
Validation loss: 1.88878599802653

Epoch: 6| Step: 8
Training loss: 1.622560977935791
Validation loss: 1.885465145111084

Epoch: 6| Step: 9
Training loss: 1.6016442775726318
Validation loss: 1.8790052526740617

Epoch: 6| Step: 10
Training loss: 1.6653209924697876
Validation loss: 1.8917763079366376

Epoch: 6| Step: 11
Training loss: 1.716149926185608
Validation loss: 1.881147951208135

Epoch: 6| Step: 12
Training loss: 1.799247145652771
Validation loss: 1.8777934005183559

Epoch: 6| Step: 13
Training loss: 2.27055025100708
Validation loss: 1.8978709725923435

Epoch: 186| Step: 0
Training loss: 2.315734386444092
Validation loss: 1.9032908626781997

Epoch: 6| Step: 1
Training loss: 1.81888747215271
Validation loss: 1.883091244646298

Epoch: 6| Step: 2
Training loss: 1.1889160871505737
Validation loss: 1.895478702360584

Epoch: 6| Step: 3
Training loss: 1.764307975769043
Validation loss: 1.908930004283946

Epoch: 6| Step: 4
Training loss: 1.7937465906143188
Validation loss: 1.9327739207975325

Epoch: 6| Step: 5
Training loss: 1.8097715377807617
Validation loss: 1.9150443782088578

Epoch: 6| Step: 6
Training loss: 1.01741623878479
Validation loss: 1.9021123058052474

Epoch: 6| Step: 7
Training loss: 1.819130301475525
Validation loss: 1.9024499334314817

Epoch: 6| Step: 8
Training loss: 1.545798420906067
Validation loss: 1.9166517334599649

Epoch: 6| Step: 9
Training loss: 2.179234027862549
Validation loss: 1.9070766587411203

Epoch: 6| Step: 10
Training loss: 1.9737904071807861
Validation loss: 1.9019703442050564

Epoch: 6| Step: 11
Training loss: 2.1917104721069336
Validation loss: 1.9055720811249108

Epoch: 6| Step: 12
Training loss: 1.7501100301742554
Validation loss: 1.9215157788286927

Epoch: 6| Step: 13
Training loss: 1.6226032972335815
Validation loss: 1.9122203806395173

Epoch: 187| Step: 0
Training loss: 2.136598587036133
Validation loss: 1.91827912997174

Epoch: 6| Step: 1
Training loss: 2.2015671730041504
Validation loss: 1.923521823780511

Epoch: 6| Step: 2
Training loss: 1.7112693786621094
Validation loss: 1.8802969917174308

Epoch: 6| Step: 3
Training loss: 1.769879698753357
Validation loss: 1.9023835569299676

Epoch: 6| Step: 4
Training loss: 1.4058674573898315
Validation loss: 1.9210782743269397

Epoch: 6| Step: 5
Training loss: 1.624147653579712
Validation loss: 1.8946502721437843

Epoch: 6| Step: 6
Training loss: 2.0808424949645996
Validation loss: 1.903577450783022

Epoch: 6| Step: 7
Training loss: 2.1216585636138916
Validation loss: 1.9296926529176774

Epoch: 6| Step: 8
Training loss: 1.4601802825927734
Validation loss: 1.8769589329278598

Epoch: 6| Step: 9
Training loss: 2.007624864578247
Validation loss: 1.9121226495312107

Epoch: 6| Step: 10
Training loss: 1.4716814756393433
Validation loss: 1.916914996280465

Epoch: 6| Step: 11
Training loss: 2.033879041671753
Validation loss: 1.8910541252423358

Epoch: 6| Step: 12
Training loss: 1.4248660802841187
Validation loss: 1.8766003834303988

Epoch: 6| Step: 13
Training loss: 1.4744144678115845
Validation loss: 1.9109920429927048

Epoch: 188| Step: 0
Training loss: 1.6650527715682983
Validation loss: 1.879785785111048

Epoch: 6| Step: 1
Training loss: 1.8446849584579468
Validation loss: 1.9064447854154853

Epoch: 6| Step: 2
Training loss: 2.38846492767334
Validation loss: 1.9189059272889168

Epoch: 6| Step: 3
Training loss: 2.4475865364074707
Validation loss: 1.904622697061108

Epoch: 6| Step: 4
Training loss: 1.6042202711105347
Validation loss: 1.9377330054518997

Epoch: 6| Step: 5
Training loss: 1.0683255195617676
Validation loss: 1.9351665807026688

Epoch: 6| Step: 6
Training loss: 2.1420235633850098
Validation loss: 1.9304402630816224

Epoch: 6| Step: 7
Training loss: 2.03867769241333
Validation loss: 1.960566225872245

Epoch: 6| Step: 8
Training loss: 2.208686113357544
Validation loss: 1.9331496018235401

Epoch: 6| Step: 9
Training loss: 1.4508576393127441
Validation loss: 1.9137681773913804

Epoch: 6| Step: 10
Training loss: 1.6609139442443848
Validation loss: 1.8882906475374777

Epoch: 6| Step: 11
Training loss: 1.6906824111938477
Validation loss: 1.9047358907679075

Epoch: 6| Step: 12
Training loss: 1.3788490295410156
Validation loss: 1.9008394236205726

Epoch: 6| Step: 13
Training loss: 1.3958582878112793
Validation loss: 1.8802936487300421

Epoch: 189| Step: 0
Training loss: 1.272456169128418
Validation loss: 1.869829644439041

Epoch: 6| Step: 1
Training loss: 1.3222217559814453
Validation loss: 1.890583340839673

Epoch: 6| Step: 2
Training loss: 1.381101369857788
Validation loss: 1.8817945026582288

Epoch: 6| Step: 3
Training loss: 1.0894196033477783
Validation loss: 1.8908053675005514

Epoch: 6| Step: 4
Training loss: 1.9058399200439453
Validation loss: 1.8641658752195296

Epoch: 6| Step: 5
Training loss: 1.2041574716567993
Validation loss: 1.886798700978679

Epoch: 6| Step: 6
Training loss: 1.629596471786499
Validation loss: 1.8864057551148117

Epoch: 6| Step: 7
Training loss: 2.1830954551696777
Validation loss: 1.9149919914942917

Epoch: 6| Step: 8
Training loss: 2.0122034549713135
Validation loss: 1.90235863577935

Epoch: 6| Step: 9
Training loss: 2.5069351196289062
Validation loss: 1.8722166938166465

Epoch: 6| Step: 10
Training loss: 2.8802504539489746
Validation loss: 1.8782478237664828

Epoch: 6| Step: 11
Training loss: 1.3805404901504517
Validation loss: 1.8698073138472855

Epoch: 6| Step: 12
Training loss: 1.740814208984375
Validation loss: 1.8514173902491087

Epoch: 6| Step: 13
Training loss: 2.934220314025879
Validation loss: 1.8825420884675876

Epoch: 190| Step: 0
Training loss: 1.631443738937378
Validation loss: 1.903817230655301

Epoch: 6| Step: 1
Training loss: 1.695406436920166
Validation loss: 1.9273317962564447

Epoch: 6| Step: 2
Training loss: 2.2698559761047363
Validation loss: 1.9293376899534656

Epoch: 6| Step: 3
Training loss: 1.6393729448318481
Validation loss: 1.9334141349279752

Epoch: 6| Step: 4
Training loss: 2.3791046142578125
Validation loss: 1.9797286859122656

Epoch: 6| Step: 5
Training loss: 2.1612377166748047
Validation loss: 1.9050153557972243

Epoch: 6| Step: 6
Training loss: 1.1103496551513672
Validation loss: 1.947949770958193

Epoch: 6| Step: 7
Training loss: 2.2100136280059814
Validation loss: 1.9350625161201722

Epoch: 6| Step: 8
Training loss: 1.7477521896362305
Validation loss: 1.9491356342069563

Epoch: 6| Step: 9
Training loss: 1.8041205406188965
Validation loss: 1.8987597803915701

Epoch: 6| Step: 10
Training loss: 1.4322420358657837
Validation loss: 1.8979237079620361

Epoch: 6| Step: 11
Training loss: 1.6420364379882812
Validation loss: 1.8914403223222302

Epoch: 6| Step: 12
Training loss: 1.4128308296203613
Validation loss: 1.8910095973681378

Epoch: 6| Step: 13
Training loss: 1.799638271331787
Validation loss: 1.9254175424575806

Epoch: 191| Step: 0
Training loss: 1.4274142980575562
Validation loss: 1.885023311902118

Epoch: 6| Step: 1
Training loss: 1.4318647384643555
Validation loss: 1.9280649359508226

Epoch: 6| Step: 2
Training loss: 2.3315930366516113
Validation loss: 1.8654568797798567

Epoch: 6| Step: 3
Training loss: 1.7744486331939697
Validation loss: 1.8822697862502067

Epoch: 6| Step: 4
Training loss: 1.8244582414627075
Validation loss: 1.870844812803371

Epoch: 6| Step: 5
Training loss: 1.7290730476379395
Validation loss: 1.9003261571289392

Epoch: 6| Step: 6
Training loss: 2.0082027912139893
Validation loss: 1.8849849457381873

Epoch: 6| Step: 7
Training loss: 1.686750054359436
Validation loss: 1.8957814285832066

Epoch: 6| Step: 8
Training loss: 1.513288140296936
Validation loss: 1.8696049259554954

Epoch: 6| Step: 9
Training loss: 2.128260374069214
Validation loss: 1.8839147526730773

Epoch: 6| Step: 10
Training loss: 2.118361473083496
Validation loss: 1.8676321032226726

Epoch: 6| Step: 11
Training loss: 1.66681706905365
Validation loss: 1.8870956718280751

Epoch: 6| Step: 12
Training loss: 1.3161027431488037
Validation loss: 1.864955827754031

Epoch: 6| Step: 13
Training loss: 1.6617064476013184
Validation loss: 1.883830306350544

Epoch: 192| Step: 0
Training loss: 1.148979663848877
Validation loss: 1.9012386798858643

Epoch: 6| Step: 1
Training loss: 1.5748838186264038
Validation loss: 1.877229171414529

Epoch: 6| Step: 2
Training loss: 1.5961105823516846
Validation loss: 1.9147149491053757

Epoch: 6| Step: 3
Training loss: 2.2496337890625
Validation loss: 1.8878698220816992

Epoch: 6| Step: 4
Training loss: 1.5046933889389038
Validation loss: 1.8949913876031035

Epoch: 6| Step: 5
Training loss: 1.822677731513977
Validation loss: 1.863021017402731

Epoch: 6| Step: 6
Training loss: 1.7041187286376953
Validation loss: 1.9012696512283818

Epoch: 6| Step: 7
Training loss: 1.0922024250030518
Validation loss: 1.9006973876748035

Epoch: 6| Step: 8
Training loss: 2.038952589035034
Validation loss: 1.8751631308627386

Epoch: 6| Step: 9
Training loss: 1.6641672849655151
Validation loss: 1.872743570676414

Epoch: 6| Step: 10
Training loss: 2.1583168506622314
Validation loss: 1.901103711897327

Epoch: 6| Step: 11
Training loss: 2.0132484436035156
Validation loss: 1.8935380699814006

Epoch: 6| Step: 12
Training loss: 2.433748483657837
Validation loss: 1.893039475205124

Epoch: 6| Step: 13
Training loss: 1.5518258810043335
Validation loss: 1.856262573631861

Epoch: 193| Step: 0
Training loss: 1.6402543783187866
Validation loss: 1.915352544476909

Epoch: 6| Step: 1
Training loss: 1.8206039667129517
Validation loss: 1.87649796342337

Epoch: 6| Step: 2
Training loss: 1.694173812866211
Validation loss: 1.8903383183222946

Epoch: 6| Step: 3
Training loss: 1.1500639915466309
Validation loss: 1.8495034261416363

Epoch: 6| Step: 4
Training loss: 1.8719985485076904
Validation loss: 1.9041242830214962

Epoch: 6| Step: 5
Training loss: 2.0204503536224365
Validation loss: 1.8932705950993363

Epoch: 6| Step: 6
Training loss: 0.9176570177078247
Validation loss: 1.8671755329255135

Epoch: 6| Step: 7
Training loss: 2.00447678565979
Validation loss: 1.8780933580090922

Epoch: 6| Step: 8
Training loss: 1.9596941471099854
Validation loss: 1.8966606355482531

Epoch: 6| Step: 9
Training loss: 1.5493133068084717
Validation loss: 1.875716692657881

Epoch: 6| Step: 10
Training loss: 1.8905298709869385
Validation loss: 1.8853481238888157

Epoch: 6| Step: 11
Training loss: 2.229140281677246
Validation loss: 1.8974942289372927

Epoch: 6| Step: 12
Training loss: 1.5449542999267578
Validation loss: 1.871989546283599

Epoch: 6| Step: 13
Training loss: 2.197936773300171
Validation loss: 1.8837223411888204

Epoch: 194| Step: 0
Training loss: 1.2794318199157715
Validation loss: 1.9294153439101351

Epoch: 6| Step: 1
Training loss: 1.5144456624984741
Validation loss: 1.9069393386123001

Epoch: 6| Step: 2
Training loss: 1.830836296081543
Validation loss: 1.9074526602222073

Epoch: 6| Step: 3
Training loss: 2.540818691253662
Validation loss: 1.9294343507418068

Epoch: 6| Step: 4
Training loss: 2.054750919342041
Validation loss: 1.933182385659987

Epoch: 6| Step: 5
Training loss: 1.074284553527832
Validation loss: 1.917796004203058

Epoch: 6| Step: 6
Training loss: 1.627181053161621
Validation loss: 1.9244399480922247

Epoch: 6| Step: 7
Training loss: 1.5451831817626953
Validation loss: 1.9538510102097706

Epoch: 6| Step: 8
Training loss: 2.060053825378418
Validation loss: 1.8926108703818372

Epoch: 6| Step: 9
Training loss: 1.7750658988952637
Validation loss: 1.8762970303976407

Epoch: 6| Step: 10
Training loss: 1.7646113634109497
Validation loss: 1.8886924212978733

Epoch: 6| Step: 11
Training loss: 2.491102695465088
Validation loss: 1.893249761673712

Epoch: 6| Step: 12
Training loss: 1.4075264930725098
Validation loss: 1.8973034543375815

Epoch: 6| Step: 13
Training loss: 1.925484299659729
Validation loss: 1.892865442460583

Epoch: 195| Step: 0
Training loss: 1.2318658828735352
Validation loss: 1.862165456177086

Epoch: 6| Step: 1
Training loss: 2.012409210205078
Validation loss: 1.8805594495547715

Epoch: 6| Step: 2
Training loss: 1.8289611339569092
Validation loss: 1.9313967535572667

Epoch: 6| Step: 3
Training loss: 2.240569591522217
Validation loss: 1.8807222381714852

Epoch: 6| Step: 4
Training loss: 1.648789882659912
Validation loss: 1.8848202331091768

Epoch: 6| Step: 5
Training loss: 1.4479299783706665
Validation loss: 1.8768643127974642

Epoch: 6| Step: 6
Training loss: 2.613664150238037
Validation loss: 1.9184816293818976

Epoch: 6| Step: 7
Training loss: 1.3085651397705078
Validation loss: 1.867327715760918

Epoch: 6| Step: 8
Training loss: 1.8724045753479004
Validation loss: 1.9136791511248517

Epoch: 6| Step: 9
Training loss: 1.5600216388702393
Validation loss: 1.880379537100433

Epoch: 6| Step: 10
Training loss: 1.7482507228851318
Validation loss: 1.8898376803244314

Epoch: 6| Step: 11
Training loss: 1.3485140800476074
Validation loss: 1.8819313408226095

Epoch: 6| Step: 12
Training loss: 1.763617753982544
Validation loss: 1.8870336086519304

Epoch: 6| Step: 13
Training loss: 2.1553146839141846
Validation loss: 1.8521313231478456

Epoch: 196| Step: 0
Training loss: 1.8949954509735107
Validation loss: 1.877614495574787

Epoch: 6| Step: 1
Training loss: 1.7656469345092773
Validation loss: 1.8953770424730034

Epoch: 6| Step: 2
Training loss: 2.3931798934936523
Validation loss: 1.8690483159916376

Epoch: 6| Step: 3
Training loss: 1.451941967010498
Validation loss: 1.9109369349736038

Epoch: 6| Step: 4
Training loss: 2.0023910999298096
Validation loss: 1.85485900345669

Epoch: 6| Step: 5
Training loss: 1.4639999866485596
Validation loss: 1.905080864506383

Epoch: 6| Step: 6
Training loss: 0.944391131401062
Validation loss: 1.8735178747484762

Epoch: 6| Step: 7
Training loss: 1.5113528966903687
Validation loss: 1.8941868197533391

Epoch: 6| Step: 8
Training loss: 1.636120080947876
Validation loss: 1.8555807618684665

Epoch: 6| Step: 9
Training loss: 2.3287134170532227
Validation loss: 1.8270100470512145

Epoch: 6| Step: 10
Training loss: 1.4320895671844482
Validation loss: 1.8855352299187773

Epoch: 6| Step: 11
Training loss: 1.6938139200210571
Validation loss: 1.8936787420703518

Epoch: 6| Step: 12
Training loss: 1.721251368522644
Validation loss: 1.8458176748726958

Epoch: 6| Step: 13
Training loss: 1.953381061553955
Validation loss: 1.8839827506772933

Epoch: 197| Step: 0
Training loss: 1.9371669292449951
Validation loss: 1.9008030686327206

Epoch: 6| Step: 1
Training loss: 1.9262175559997559
Validation loss: 1.8848063740679013

Epoch: 6| Step: 2
Training loss: 2.0295157432556152
Validation loss: 1.8750668533386723

Epoch: 6| Step: 3
Training loss: 2.2173118591308594
Validation loss: 1.90044859404205

Epoch: 6| Step: 4
Training loss: 1.3674485683441162
Validation loss: 1.936663020041681

Epoch: 6| Step: 5
Training loss: 2.628199577331543
Validation loss: 1.9272468064420967

Epoch: 6| Step: 6
Training loss: 1.088538408279419
Validation loss: 1.8758360288476432

Epoch: 6| Step: 7
Training loss: 2.072584390640259
Validation loss: 1.9047342397833382

Epoch: 6| Step: 8
Training loss: 1.5960748195648193
Validation loss: 1.8862763938083444

Epoch: 6| Step: 9
Training loss: 1.5878076553344727
Validation loss: 1.8943424429944766

Epoch: 6| Step: 10
Training loss: 1.2197513580322266
Validation loss: 1.9019078016281128

Epoch: 6| Step: 11
Training loss: 1.1058772802352905
Validation loss: 1.9057758533826439

Epoch: 6| Step: 12
Training loss: 1.8636846542358398
Validation loss: 1.8719953375477945

Epoch: 6| Step: 13
Training loss: 1.8919495344161987
Validation loss: 1.9010195527025449

Epoch: 198| Step: 0
Training loss: 1.958704948425293
Validation loss: 1.9143542961407733

Epoch: 6| Step: 1
Training loss: 1.7519657611846924
Validation loss: 1.898076521453037

Epoch: 6| Step: 2
Training loss: 1.7373108863830566
Validation loss: 1.926067151049132

Epoch: 6| Step: 3
Training loss: 1.4274135828018188
Validation loss: 1.894541089252759

Epoch: 6| Step: 4
Training loss: 1.985215425491333
Validation loss: 1.9058625044361237

Epoch: 6| Step: 5
Training loss: 1.7453957796096802
Validation loss: 1.8610702381339124

Epoch: 6| Step: 6
Training loss: 1.6621513366699219
Validation loss: 1.9091987071498748

Epoch: 6| Step: 7
Training loss: 1.524425983428955
Validation loss: 1.8992972297053183

Epoch: 6| Step: 8
Training loss: 1.5147589445114136
Validation loss: 1.9047627679763302

Epoch: 6| Step: 9
Training loss: 2.068068027496338
Validation loss: 1.8863817953294324

Epoch: 6| Step: 10
Training loss: 1.989398717880249
Validation loss: 1.8668925351994012

Epoch: 6| Step: 11
Training loss: 1.534130573272705
Validation loss: 1.8866148020631524

Epoch: 6| Step: 12
Training loss: 1.4813766479492188
Validation loss: 1.8738218686913932

Epoch: 6| Step: 13
Training loss: 2.0392141342163086
Validation loss: 1.8910562299912976

Epoch: 199| Step: 0
Training loss: 0.9972246885299683
Validation loss: 1.9256697162505119

Epoch: 6| Step: 1
Training loss: 2.5693717002868652
Validation loss: 1.8649657528887513

Epoch: 6| Step: 2
Training loss: 1.6889673471450806
Validation loss: 1.8854848402802662

Epoch: 6| Step: 3
Training loss: 1.5796855688095093
Validation loss: 1.9035575236043623

Epoch: 6| Step: 4
Training loss: 2.17984676361084
Validation loss: 1.8799150656628352

Epoch: 6| Step: 5
Training loss: 0.9683904647827148
Validation loss: 1.9085081443991712

Epoch: 6| Step: 6
Training loss: 2.127937078475952
Validation loss: 1.8810131190925516

Epoch: 6| Step: 7
Training loss: 1.6681272983551025
Validation loss: 1.8661683144107941

Epoch: 6| Step: 8
Training loss: 1.82594633102417
Validation loss: 1.877408645486319

Epoch: 6| Step: 9
Training loss: 1.4864630699157715
Validation loss: 1.8676927435782649

Epoch: 6| Step: 10
Training loss: 1.5723230838775635
Validation loss: 1.8609360007829563

Epoch: 6| Step: 11
Training loss: 2.0730552673339844
Validation loss: 1.8842090214452436

Epoch: 6| Step: 12
Training loss: 1.9688724279403687
Validation loss: 1.8417855898539226

Epoch: 6| Step: 13
Training loss: 1.510037899017334
Validation loss: 1.8835716324467813

Epoch: 200| Step: 0
Training loss: 1.5132871866226196
Validation loss: 1.866577120237453

Epoch: 6| Step: 1
Training loss: 2.127795934677124
Validation loss: 1.8755811863048102

Epoch: 6| Step: 2
Training loss: 1.7271203994750977
Validation loss: 1.8859195222136795

Epoch: 6| Step: 3
Training loss: 1.6527788639068604
Validation loss: 1.8971995974099765

Epoch: 6| Step: 4
Training loss: 1.4662433862686157
Validation loss: 1.9027758029199415

Epoch: 6| Step: 5
Training loss: 1.9855393171310425
Validation loss: 1.8994235928340624

Epoch: 6| Step: 6
Training loss: 1.9447736740112305
Validation loss: 1.9369357926871187

Epoch: 6| Step: 7
Training loss: 1.2939504384994507
Validation loss: 1.9432483309058732

Epoch: 6| Step: 8
Training loss: 2.0428366661071777
Validation loss: 1.9177167287436865

Epoch: 6| Step: 9
Training loss: 1.5908567905426025
Validation loss: 1.8867072507899294

Epoch: 6| Step: 10
Training loss: 1.9266406297683716
Validation loss: 1.9237067545613935

Epoch: 6| Step: 11
Training loss: 2.0514161586761475
Validation loss: 1.9352680149898733

Epoch: 6| Step: 12
Training loss: 1.7771412134170532
Validation loss: 1.8942836869147517

Epoch: 6| Step: 13
Training loss: 1.0660426616668701
Validation loss: 1.8580829610106766

Epoch: 201| Step: 0
Training loss: 1.5992058515548706
Validation loss: 1.903485244320285

Epoch: 6| Step: 1
Training loss: 1.4559987783432007
Validation loss: 1.8900591429843698

Epoch: 6| Step: 2
Training loss: 1.8213741779327393
Validation loss: 1.8661940251627276

Epoch: 6| Step: 3
Training loss: 2.0642995834350586
Validation loss: 1.868839858680643

Epoch: 6| Step: 4
Training loss: 2.1636903285980225
Validation loss: 1.863174835840861

Epoch: 6| Step: 5
Training loss: 1.263103723526001
Validation loss: 1.8548540428120603

Epoch: 6| Step: 6
Training loss: 2.2737653255462646
Validation loss: 1.8814504736213273

Epoch: 6| Step: 7
Training loss: 1.5797293186187744
Validation loss: 1.8633396535791376

Epoch: 6| Step: 8
Training loss: 1.37790048122406
Validation loss: 1.9185262213471115

Epoch: 6| Step: 9
Training loss: 2.1076323986053467
Validation loss: 1.8744640734887892

Epoch: 6| Step: 10
Training loss: 1.4863580465316772
Validation loss: 1.8982743217099098

Epoch: 6| Step: 11
Training loss: 2.1546499729156494
Validation loss: 1.8288112507071546

Epoch: 6| Step: 12
Training loss: 1.5547906160354614
Validation loss: 1.880129514201995

Epoch: 6| Step: 13
Training loss: 0.885948121547699
Validation loss: 1.873569211652202

Epoch: 202| Step: 0
Training loss: 1.647451639175415
Validation loss: 1.8937542374416063

Epoch: 6| Step: 1
Training loss: 1.7714992761611938
Validation loss: 1.8973677568538214

Epoch: 6| Step: 2
Training loss: 1.6638007164001465
Validation loss: 1.8892276748534171

Epoch: 6| Step: 3
Training loss: 1.6041171550750732
Validation loss: 1.8795344957741358

Epoch: 6| Step: 4
Training loss: 1.2376022338867188
Validation loss: 1.8743750023585495

Epoch: 6| Step: 5
Training loss: 1.3409054279327393
Validation loss: 1.8600098753488192

Epoch: 6| Step: 6
Training loss: 2.1293749809265137
Validation loss: 1.850006870044175

Epoch: 6| Step: 7
Training loss: 1.2857027053833008
Validation loss: 1.857592373765925

Epoch: 6| Step: 8
Training loss: 2.1175074577331543
Validation loss: 1.8652048367325977

Epoch: 6| Step: 9
Training loss: 2.221771001815796
Validation loss: 1.9000736641627487

Epoch: 6| Step: 10
Training loss: 1.599071979522705
Validation loss: 1.8739139264629734

Epoch: 6| Step: 11
Training loss: 1.199540138244629
Validation loss: 1.8952221229512205

Epoch: 6| Step: 12
Training loss: 2.274517774581909
Validation loss: 1.9194195091083486

Epoch: 6| Step: 13
Training loss: 2.0122976303100586
Validation loss: 1.9100976733751194

Epoch: 203| Step: 0
Training loss: 1.58189857006073
Validation loss: 1.8769676787878877

Epoch: 6| Step: 1
Training loss: 1.1456518173217773
Validation loss: 1.8682558972348449

Epoch: 6| Step: 2
Training loss: 0.8711896538734436
Validation loss: 1.9233524414800829

Epoch: 6| Step: 3
Training loss: 1.7941553592681885
Validation loss: 1.9153971595148886

Epoch: 6| Step: 4
Training loss: 3.287794589996338
Validation loss: 1.870864422090592

Epoch: 6| Step: 5
Training loss: 1.420907974243164
Validation loss: 1.8762117009009085

Epoch: 6| Step: 6
Training loss: 1.4978079795837402
Validation loss: 1.8556021375040854

Epoch: 6| Step: 7
Training loss: 1.3687100410461426
Validation loss: 1.8774742452047204

Epoch: 6| Step: 8
Training loss: 1.660129189491272
Validation loss: 1.8150413446528937

Epoch: 6| Step: 9
Training loss: 1.355009913444519
Validation loss: 1.842740958736789

Epoch: 6| Step: 10
Training loss: 2.190321922302246
Validation loss: 1.8697768129328245

Epoch: 6| Step: 11
Training loss: 2.3186864852905273
Validation loss: 1.865370455608573

Epoch: 6| Step: 12
Training loss: 1.791581392288208
Validation loss: 1.8513528006051176

Epoch: 6| Step: 13
Training loss: 1.6093642711639404
Validation loss: 1.8570845947470715

Epoch: 204| Step: 0
Training loss: 1.7091255187988281
Validation loss: 1.870656164743567

Epoch: 6| Step: 1
Training loss: 2.1158578395843506
Validation loss: 1.8837899520833006

Epoch: 6| Step: 2
Training loss: 1.5607612133026123
Validation loss: 1.8765061337460753

Epoch: 6| Step: 3
Training loss: 1.414618730545044
Validation loss: 1.8568055270820536

Epoch: 6| Step: 4
Training loss: 2.2530174255371094
Validation loss: 1.8867036834839852

Epoch: 6| Step: 5
Training loss: 1.85320246219635
Validation loss: 1.8860088074079124

Epoch: 6| Step: 6
Training loss: 2.0246429443359375
Validation loss: 1.8922519222382577

Epoch: 6| Step: 7
Training loss: 2.039823293685913
Validation loss: 1.8881628256972118

Epoch: 6| Step: 8
Training loss: 1.757128357887268
Validation loss: 1.8697113349873533

Epoch: 6| Step: 9
Training loss: 0.9128082990646362
Validation loss: 1.8401301945409467

Epoch: 6| Step: 10
Training loss: 2.475431442260742
Validation loss: 1.8641456198948685

Epoch: 6| Step: 11
Training loss: 1.4609867334365845
Validation loss: 1.8693302113522765

Epoch: 6| Step: 12
Training loss: 1.1676961183547974
Validation loss: 1.8627704484488374

Epoch: 6| Step: 13
Training loss: 1.521027684211731
Validation loss: 1.8816732488652712

Epoch: 205| Step: 0
Training loss: 2.1506786346435547
Validation loss: 1.8766150660412286

Epoch: 6| Step: 1
Training loss: 2.182143211364746
Validation loss: 1.8735854664156515

Epoch: 6| Step: 2
Training loss: 1.040736436843872
Validation loss: 1.8981433299279982

Epoch: 6| Step: 3
Training loss: 1.5072083473205566
Validation loss: 1.8868274650266093

Epoch: 6| Step: 4
Training loss: 2.293618679046631
Validation loss: 1.853647429455993

Epoch: 6| Step: 5
Training loss: 1.543666124343872
Validation loss: 1.85400870666709

Epoch: 6| Step: 6
Training loss: 2.177311897277832
Validation loss: 1.8830103105114353

Epoch: 6| Step: 7
Training loss: 1.3318567276000977
Validation loss: 1.8670904251836962

Epoch: 6| Step: 8
Training loss: 1.2648048400878906
Validation loss: 1.873210705736632

Epoch: 6| Step: 9
Training loss: 1.4553611278533936
Validation loss: 1.8976311837473223

Epoch: 6| Step: 10
Training loss: 1.9924771785736084
Validation loss: 1.875889047499626

Epoch: 6| Step: 11
Training loss: 1.8954458236694336
Validation loss: 1.9039663986493183

Epoch: 6| Step: 12
Training loss: 1.857439637184143
Validation loss: 1.8782404199723275

Epoch: 6| Step: 13
Training loss: 1.3520175218582153
Validation loss: 1.8561863335230018

Epoch: 206| Step: 0
Training loss: 1.4004096984863281
Validation loss: 1.88368010264571

Epoch: 6| Step: 1
Training loss: 1.1156456470489502
Validation loss: 1.8705127700682609

Epoch: 6| Step: 2
Training loss: 1.840550184249878
Validation loss: 1.8689775723283009

Epoch: 6| Step: 3
Training loss: 1.0596191883087158
Validation loss: 1.870996513674336

Epoch: 6| Step: 4
Training loss: 1.387094497680664
Validation loss: 1.8630914316382459

Epoch: 6| Step: 5
Training loss: 1.739668846130371
Validation loss: 1.83823396313575

Epoch: 6| Step: 6
Training loss: 2.4509236812591553
Validation loss: 1.8688529640115716

Epoch: 6| Step: 7
Training loss: 1.5127058029174805
Validation loss: 1.8650629469143447

Epoch: 6| Step: 8
Training loss: 1.813188076019287
Validation loss: 1.873794671027891

Epoch: 6| Step: 9
Training loss: 1.4301931858062744
Validation loss: 1.8539283314058859

Epoch: 6| Step: 10
Training loss: 1.272234559059143
Validation loss: 1.8629133701324463

Epoch: 6| Step: 11
Training loss: 2.3127834796905518
Validation loss: 1.8583187723672518

Epoch: 6| Step: 12
Training loss: 2.447566032409668
Validation loss: 1.8363308637372908

Epoch: 6| Step: 13
Training loss: 2.0385303497314453
Validation loss: 1.8475752351104573

Epoch: 207| Step: 0
Training loss: 1.9636462926864624
Validation loss: 1.8301909200606807

Epoch: 6| Step: 1
Training loss: 2.196488618850708
Validation loss: 1.8925426070408156

Epoch: 6| Step: 2
Training loss: 2.101022720336914
Validation loss: 1.902335081049191

Epoch: 6| Step: 3
Training loss: 1.5874512195587158
Validation loss: 1.8808651867733206

Epoch: 6| Step: 4
Training loss: 1.2457470893859863
Validation loss: 1.8660362279543312

Epoch: 6| Step: 5
Training loss: 1.9401452541351318
Validation loss: 1.8562344825395973

Epoch: 6| Step: 6
Training loss: 1.0423145294189453
Validation loss: 1.8873580002015637

Epoch: 6| Step: 7
Training loss: 1.23724365234375
Validation loss: 1.8830247143263459

Epoch: 6| Step: 8
Training loss: 2.130422830581665
Validation loss: 1.8753599902634979

Epoch: 6| Step: 9
Training loss: 1.1657021045684814
Validation loss: 1.8921658864585302

Epoch: 6| Step: 10
Training loss: 1.5416364669799805
Validation loss: 1.8756808491163357

Epoch: 6| Step: 11
Training loss: 1.8299181461334229
Validation loss: 1.8546175341452322

Epoch: 6| Step: 12
Training loss: 2.4251644611358643
Validation loss: 1.8797004684325187

Epoch: 6| Step: 13
Training loss: 1.7009851932525635
Validation loss: 1.8609271049499512

Epoch: 208| Step: 0
Training loss: 1.5816855430603027
Validation loss: 1.913194441026257

Epoch: 6| Step: 1
Training loss: 2.2184956073760986
Validation loss: 1.8711926578193583

Epoch: 6| Step: 2
Training loss: 0.8360545635223389
Validation loss: 1.8582420220939062

Epoch: 6| Step: 3
Training loss: 1.7306478023529053
Validation loss: 1.865077659647952

Epoch: 6| Step: 4
Training loss: 1.800911784172058
Validation loss: 1.8422956133401522

Epoch: 6| Step: 5
Training loss: 1.417830467224121
Validation loss: 1.8584154549465384

Epoch: 6| Step: 6
Training loss: 1.849103331565857
Validation loss: 1.8292890351305726

Epoch: 6| Step: 7
Training loss: 1.450601577758789
Validation loss: 1.877329158526595

Epoch: 6| Step: 8
Training loss: 2.000180244445801
Validation loss: 1.836023735743697

Epoch: 6| Step: 9
Training loss: 1.970326542854309
Validation loss: 1.8795548382625784

Epoch: 6| Step: 10
Training loss: 1.5277220010757446
Validation loss: 1.8648077134163148

Epoch: 6| Step: 11
Training loss: 1.7155205011367798
Validation loss: 1.8619114006719282

Epoch: 6| Step: 12
Training loss: 1.8103816509246826
Validation loss: 1.8598990735187326

Epoch: 6| Step: 13
Training loss: 2.3888769149780273
Validation loss: 1.8993254925615044

Epoch: 209| Step: 0
Training loss: 1.700373649597168
Validation loss: 1.8587409116888558

Epoch: 6| Step: 1
Training loss: 1.7148208618164062
Validation loss: 1.8615721259065854

Epoch: 6| Step: 2
Training loss: 1.696284294128418
Validation loss: 1.863633559596154

Epoch: 6| Step: 3
Training loss: 1.841759443283081
Validation loss: 1.8405193590348767

Epoch: 6| Step: 4
Training loss: 1.6963703632354736
Validation loss: 1.8679316069490166

Epoch: 6| Step: 5
Training loss: 1.7079342603683472
Validation loss: 1.8614829227488527

Epoch: 6| Step: 6
Training loss: 1.4771156311035156
Validation loss: 1.8808518532783753

Epoch: 6| Step: 7
Training loss: 2.1391096115112305
Validation loss: 1.87996958532641

Epoch: 6| Step: 8
Training loss: 1.337293028831482
Validation loss: 1.8741442221467213

Epoch: 6| Step: 9
Training loss: 1.8959137201309204
Validation loss: 1.8856260065109498

Epoch: 6| Step: 10
Training loss: 1.6104674339294434
Validation loss: 1.852016887357158

Epoch: 6| Step: 11
Training loss: 1.581367015838623
Validation loss: 1.8533350831718856

Epoch: 6| Step: 12
Training loss: 1.9852323532104492
Validation loss: 1.878880380302347

Epoch: 6| Step: 13
Training loss: 1.6310100555419922
Validation loss: 1.8802247778061898

Epoch: 210| Step: 0
Training loss: 1.6042760610580444
Validation loss: 1.8804309739861438

Epoch: 6| Step: 1
Training loss: 1.8078176975250244
Validation loss: 1.8850744238463781

Epoch: 6| Step: 2
Training loss: 1.2764564752578735
Validation loss: 1.855159592884843

Epoch: 6| Step: 3
Training loss: 1.2173441648483276
Validation loss: 1.8494714357519662

Epoch: 6| Step: 4
Training loss: 1.7622942924499512
Validation loss: 1.863785029739462

Epoch: 6| Step: 5
Training loss: 1.336269497871399
Validation loss: 1.8720386438472296

Epoch: 6| Step: 6
Training loss: 1.8843852281570435
Validation loss: 1.8713072897285543

Epoch: 6| Step: 7
Training loss: 1.7072137594223022
Validation loss: 1.8928550930433377

Epoch: 6| Step: 8
Training loss: 2.6318931579589844
Validation loss: 1.8675702951287712

Epoch: 6| Step: 9
Training loss: 2.277218818664551
Validation loss: 1.853289528559613

Epoch: 6| Step: 10
Training loss: 2.5207574367523193
Validation loss: 1.8618569271538847

Epoch: 6| Step: 11
Training loss: 1.3841967582702637
Validation loss: 1.834312528692266

Epoch: 6| Step: 12
Training loss: 1.125013828277588
Validation loss: 1.8425217648988128

Epoch: 6| Step: 13
Training loss: 1.2864967584609985
Validation loss: 1.868595556546283

Epoch: 211| Step: 0
Training loss: 1.1709012985229492
Validation loss: 1.8444669362037414

Epoch: 6| Step: 1
Training loss: 2.2995009422302246
Validation loss: 1.8571804518340735

Epoch: 6| Step: 2
Training loss: 1.7901644706726074
Validation loss: 1.8532666852397304

Epoch: 6| Step: 3
Training loss: 1.1716623306274414
Validation loss: 1.887529161668593

Epoch: 6| Step: 4
Training loss: 1.8915457725524902
Validation loss: 1.8589754386614727

Epoch: 6| Step: 5
Training loss: 1.4268958568572998
Validation loss: 1.8791686488736061

Epoch: 6| Step: 6
Training loss: 2.155015230178833
Validation loss: 1.8402631180260771

Epoch: 6| Step: 7
Training loss: 1.3681353330612183
Validation loss: 1.8716447827636555

Epoch: 6| Step: 8
Training loss: 1.4593894481658936
Validation loss: 1.8443077200202531

Epoch: 6| Step: 9
Training loss: 1.957240343093872
Validation loss: 1.842077075794179

Epoch: 6| Step: 10
Training loss: 1.3250086307525635
Validation loss: 1.8764195993382444

Epoch: 6| Step: 11
Training loss: 2.387457847595215
Validation loss: 1.8774417741324312

Epoch: 6| Step: 12
Training loss: 1.9886895418167114
Validation loss: 1.8425205356331282

Epoch: 6| Step: 13
Training loss: 1.692219853401184
Validation loss: 1.8299838073791996

Epoch: 212| Step: 0
Training loss: 1.1908657550811768
Validation loss: 1.8654177650328605

Epoch: 6| Step: 1
Training loss: 1.6259329319000244
Validation loss: 1.8645868839756135

Epoch: 6| Step: 2
Training loss: 1.8401851654052734
Validation loss: 1.8412338713163972

Epoch: 6| Step: 3
Training loss: 2.2361912727355957
Validation loss: 1.8325555862918976

Epoch: 6| Step: 4
Training loss: 1.5433058738708496
Validation loss: 1.8565370126437115

Epoch: 6| Step: 5
Training loss: 1.0439097881317139
Validation loss: 1.8753338693290629

Epoch: 6| Step: 6
Training loss: 1.6277532577514648
Validation loss: 1.8942836497419624

Epoch: 6| Step: 7
Training loss: 1.6772607564926147
Validation loss: 1.8648229875872213

Epoch: 6| Step: 8
Training loss: 1.5549120903015137
Validation loss: 1.8457762682309715

Epoch: 6| Step: 9
Training loss: 2.171686887741089
Validation loss: 1.8828134088106052

Epoch: 6| Step: 10
Training loss: 1.8327758312225342
Validation loss: 1.8356441836203299

Epoch: 6| Step: 11
Training loss: 1.3310859203338623
Validation loss: 1.8914998090395363

Epoch: 6| Step: 12
Training loss: 2.250910997390747
Validation loss: 1.8711119082666212

Epoch: 6| Step: 13
Training loss: 1.6710319519042969
Validation loss: 1.8676040018758466

Epoch: 213| Step: 0
Training loss: 2.10626220703125
Validation loss: 1.854926670751264

Epoch: 6| Step: 1
Training loss: 1.819512963294983
Validation loss: 1.871972022518035

Epoch: 6| Step: 2
Training loss: 1.7624799013137817
Validation loss: 1.8678622720062092

Epoch: 6| Step: 3
Training loss: 1.9293055534362793
Validation loss: 1.8804371946601457

Epoch: 6| Step: 4
Training loss: 1.0283854007720947
Validation loss: 1.8893276106926702

Epoch: 6| Step: 5
Training loss: 1.7345247268676758
Validation loss: 1.8880502882824148

Epoch: 6| Step: 6
Training loss: 2.0311226844787598
Validation loss: 1.858267314972416

Epoch: 6| Step: 7
Training loss: 1.481414794921875
Validation loss: 1.9337026316632506

Epoch: 6| Step: 8
Training loss: 1.032036304473877
Validation loss: 1.8973187515812535

Epoch: 6| Step: 9
Training loss: 1.1605792045593262
Validation loss: 1.8705218338197278

Epoch: 6| Step: 10
Training loss: 1.6084988117218018
Validation loss: 1.8805832811581191

Epoch: 6| Step: 11
Training loss: 2.5340042114257812
Validation loss: 1.8774316900519914

Epoch: 6| Step: 12
Training loss: 1.4054570198059082
Validation loss: 1.8467509438914638

Epoch: 6| Step: 13
Training loss: 2.336103677749634
Validation loss: 1.870589795932975

Epoch: 214| Step: 0
Training loss: 2.173767328262329
Validation loss: 1.8390643237739481

Epoch: 6| Step: 1
Training loss: 1.861638069152832
Validation loss: 1.8764512795273975

Epoch: 6| Step: 2
Training loss: 1.3659565448760986
Validation loss: 1.8717153546630696

Epoch: 6| Step: 3
Training loss: 1.857537865638733
Validation loss: 1.871952046630203

Epoch: 6| Step: 4
Training loss: 1.5142483711242676
Validation loss: 1.8520717979759298

Epoch: 6| Step: 5
Training loss: 1.5850046873092651
Validation loss: 1.848622529737411

Epoch: 6| Step: 6
Training loss: 1.663560390472412
Validation loss: 1.8205051665665002

Epoch: 6| Step: 7
Training loss: 1.5147316455841064
Validation loss: 1.832689921061198

Epoch: 6| Step: 8
Training loss: 1.3244984149932861
Validation loss: 1.8639998820520216

Epoch: 6| Step: 9
Training loss: 2.4529736042022705
Validation loss: 1.8557261331107027

Epoch: 6| Step: 10
Training loss: 2.191563367843628
Validation loss: 1.8632714568927724

Epoch: 6| Step: 11
Training loss: 1.3746473789215088
Validation loss: 1.851409096871653

Epoch: 6| Step: 12
Training loss: 1.4688189029693604
Validation loss: 1.867399191343656

Epoch: 6| Step: 13
Training loss: 1.400958776473999
Validation loss: 1.8352248014942292

Epoch: 215| Step: 0
Training loss: 1.1050691604614258
Validation loss: 1.8264044510420931

Epoch: 6| Step: 1
Training loss: 2.098407745361328
Validation loss: 1.8792395412280996

Epoch: 6| Step: 2
Training loss: 1.7205326557159424
Validation loss: 1.8634096832685574

Epoch: 6| Step: 3
Training loss: 1.7775014638900757
Validation loss: 1.8737140496571858

Epoch: 6| Step: 4
Training loss: 1.7445201873779297
Validation loss: 1.877991904494583

Epoch: 6| Step: 5
Training loss: 1.0819001197814941
Validation loss: 1.8790061217482372

Epoch: 6| Step: 6
Training loss: 1.8364028930664062
Validation loss: 1.85236769594172

Epoch: 6| Step: 7
Training loss: 2.034648895263672
Validation loss: 1.8726151002350675

Epoch: 6| Step: 8
Training loss: 2.2687692642211914
Validation loss: 1.8415760045410485

Epoch: 6| Step: 9
Training loss: 2.040220260620117
Validation loss: 1.8634906712398733

Epoch: 6| Step: 10
Training loss: 1.2480038404464722
Validation loss: 1.8468470137606385

Epoch: 6| Step: 11
Training loss: 1.726501226425171
Validation loss: 1.8631162463977773

Epoch: 6| Step: 12
Training loss: 1.308173418045044
Validation loss: 1.8429340508676344

Epoch: 6| Step: 13
Training loss: 1.445751667022705
Validation loss: 1.8653558877206617

Epoch: 216| Step: 0
Training loss: 1.4468923807144165
Validation loss: 1.9028735776101389

Epoch: 6| Step: 1
Training loss: 1.5418391227722168
Validation loss: 1.8675293601969236

Epoch: 6| Step: 2
Training loss: 1.838986873626709
Validation loss: 1.864527435712917

Epoch: 6| Step: 3
Training loss: 2.196385622024536
Validation loss: 1.8641048157086937

Epoch: 6| Step: 4
Training loss: 2.1465704441070557
Validation loss: 1.8710307818587109

Epoch: 6| Step: 5
Training loss: 1.6162323951721191
Validation loss: 1.8633592449208742

Epoch: 6| Step: 6
Training loss: 1.5559759140014648
Validation loss: 1.8699656353201917

Epoch: 6| Step: 7
Training loss: 0.9777624607086182
Validation loss: 1.8334781739019579

Epoch: 6| Step: 8
Training loss: 1.98879075050354
Validation loss: 1.8526609764304212

Epoch: 6| Step: 9
Training loss: 1.7962462902069092
Validation loss: 1.8682016159898491

Epoch: 6| Step: 10
Training loss: 1.8865840435028076
Validation loss: 1.8639020983890822

Epoch: 6| Step: 11
Training loss: 1.7403075695037842
Validation loss: 1.8624505112248082

Epoch: 6| Step: 12
Training loss: 1.591071605682373
Validation loss: 1.8712816546040196

Epoch: 6| Step: 13
Training loss: 0.8540492653846741
Validation loss: 1.8792243196118263

Epoch: 217| Step: 0
Training loss: 1.3747276067733765
Validation loss: 1.857069610267557

Epoch: 6| Step: 1
Training loss: 1.4591513872146606
Validation loss: 1.8639540979939122

Epoch: 6| Step: 2
Training loss: 1.9605154991149902
Validation loss: 1.842497479531073

Epoch: 6| Step: 3
Training loss: 1.5560390949249268
Validation loss: 1.8625754130783903

Epoch: 6| Step: 4
Training loss: 1.7382872104644775
Validation loss: 1.8617184956868489

Epoch: 6| Step: 5
Training loss: 1.3535172939300537
Validation loss: 1.8636955676540252

Epoch: 6| Step: 6
Training loss: 1.3539271354675293
Validation loss: 1.8496241672064668

Epoch: 6| Step: 7
Training loss: 1.7739496231079102
Validation loss: 1.8759736104678082

Epoch: 6| Step: 8
Training loss: 2.153737783432007
Validation loss: 1.8424896450452908

Epoch: 6| Step: 9
Training loss: 1.894284725189209
Validation loss: 1.85763212942308

Epoch: 6| Step: 10
Training loss: 1.8145016431808472
Validation loss: 1.8370698754505446

Epoch: 6| Step: 11
Training loss: 1.9350776672363281
Validation loss: 1.8646645443413847

Epoch: 6| Step: 12
Training loss: 1.3750815391540527
Validation loss: 1.868474134834864

Epoch: 6| Step: 13
Training loss: 1.7764891386032104
Validation loss: 1.8554392809508948

Epoch: 218| Step: 0
Training loss: 1.8763035535812378
Validation loss: 1.8480913792887042

Epoch: 6| Step: 1
Training loss: 1.9192347526550293
Validation loss: 1.8075696114570863

Epoch: 6| Step: 2
Training loss: 1.2542098760604858
Validation loss: 1.8382180275455597

Epoch: 6| Step: 3
Training loss: 1.641831636428833
Validation loss: 1.8349447109365975

Epoch: 6| Step: 4
Training loss: 2.0355257987976074
Validation loss: 1.8614173281577326

Epoch: 6| Step: 5
Training loss: 1.4572087526321411
Validation loss: 1.8494760387687272

Epoch: 6| Step: 6
Training loss: 1.2716500759124756
Validation loss: 1.8510113992998678

Epoch: 6| Step: 7
Training loss: 2.2639994621276855
Validation loss: 1.8569782908244798

Epoch: 6| Step: 8
Training loss: 1.4941083192825317
Validation loss: 1.8595830778921805

Epoch: 6| Step: 9
Training loss: 1.4409797191619873
Validation loss: 1.9050816874350271

Epoch: 6| Step: 10
Training loss: 2.3789520263671875
Validation loss: 1.8790826848758164

Epoch: 6| Step: 11
Training loss: 1.387797474861145
Validation loss: 1.8424473424111643

Epoch: 6| Step: 12
Training loss: 1.4953398704528809
Validation loss: 1.8644685181238319

Epoch: 6| Step: 13
Training loss: 1.287781000137329
Validation loss: 1.889395361305565

Epoch: 219| Step: 0
Training loss: 1.858841896057129
Validation loss: 1.8897991808511878

Epoch: 6| Step: 1
Training loss: 1.9332081079483032
Validation loss: 1.8594876053512737

Epoch: 6| Step: 2
Training loss: 1.6966776847839355
Validation loss: 1.8773791072189168

Epoch: 6| Step: 3
Training loss: 2.513004779815674
Validation loss: 1.885562580118897

Epoch: 6| Step: 4
Training loss: 1.8481626510620117
Validation loss: 1.8609081955366238

Epoch: 6| Step: 5
Training loss: 1.7897827625274658
Validation loss: 1.8754061011857883

Epoch: 6| Step: 6
Training loss: 1.1402266025543213
Validation loss: 1.9286645843136696

Epoch: 6| Step: 7
Training loss: 2.1184167861938477
Validation loss: 1.906889251483384

Epoch: 6| Step: 8
Training loss: 1.5683786869049072
Validation loss: 1.9089121600633026

Epoch: 6| Step: 9
Training loss: 1.6224862337112427
Validation loss: 1.917691566610849

Epoch: 6| Step: 10
Training loss: 0.8572569489479065
Validation loss: 1.8854627301616054

Epoch: 6| Step: 11
Training loss: 1.6399836540222168
Validation loss: 1.9003945550610941

Epoch: 6| Step: 12
Training loss: 1.4780343770980835
Validation loss: 1.8642630987269904

Epoch: 6| Step: 13
Training loss: 1.4588587284088135
Validation loss: 1.836268868497623

Epoch: 220| Step: 0
Training loss: 1.4404500722885132
Validation loss: 1.8422824669909734

Epoch: 6| Step: 1
Training loss: 2.007784128189087
Validation loss: 1.8209863465319398

Epoch: 6| Step: 2
Training loss: 1.4352993965148926
Validation loss: 1.8453555927481702

Epoch: 6| Step: 3
Training loss: 0.8870688676834106
Validation loss: 1.843503426480037

Epoch: 6| Step: 4
Training loss: 1.5371270179748535
Validation loss: 1.8213676124490716

Epoch: 6| Step: 5
Training loss: 2.4324147701263428
Validation loss: 1.8392187010857366

Epoch: 6| Step: 6
Training loss: 1.218420147895813
Validation loss: 1.8806495884413361

Epoch: 6| Step: 7
Training loss: 1.8309838771820068
Validation loss: 1.830297472656414

Epoch: 6| Step: 8
Training loss: 1.751913070678711
Validation loss: 1.861353007696008

Epoch: 6| Step: 9
Training loss: 2.0907089710235596
Validation loss: 1.8515594108130342

Epoch: 6| Step: 10
Training loss: 1.9179247617721558
Validation loss: 1.8418322019679572

Epoch: 6| Step: 11
Training loss: 1.5648247003555298
Validation loss: 1.8598803422784294

Epoch: 6| Step: 12
Training loss: 2.211827278137207
Validation loss: 1.8696057796478271

Epoch: 6| Step: 13
Training loss: 1.6643471717834473
Validation loss: 1.8400723882900771

Epoch: 221| Step: 0
Training loss: 1.9283415079116821
Validation loss: 1.8561378973786549

Epoch: 6| Step: 1
Training loss: 1.3995416164398193
Validation loss: 1.8463919431932512

Epoch: 6| Step: 2
Training loss: 1.5080862045288086
Validation loss: 1.8675431974472538

Epoch: 6| Step: 3
Training loss: 1.7243945598602295
Validation loss: 1.8698086866768457

Epoch: 6| Step: 4
Training loss: 2.154911518096924
Validation loss: 1.8416965084691201

Epoch: 6| Step: 5
Training loss: 0.803905725479126
Validation loss: 1.8271706360642628

Epoch: 6| Step: 6
Training loss: 1.9547364711761475
Validation loss: 1.8342917965304466

Epoch: 6| Step: 7
Training loss: 1.340346097946167
Validation loss: 1.847755939729752

Epoch: 6| Step: 8
Training loss: 2.0636184215545654
Validation loss: 1.8731081908748997

Epoch: 6| Step: 9
Training loss: 1.5892841815948486
Validation loss: 1.8567057194248322

Epoch: 6| Step: 10
Training loss: 1.7698757648468018
Validation loss: 1.8711345862316828

Epoch: 6| Step: 11
Training loss: 1.7817410230636597
Validation loss: 1.8641036441249232

Epoch: 6| Step: 12
Training loss: 1.4571765661239624
Validation loss: 1.8492270054355744

Epoch: 6| Step: 13
Training loss: 2.3753936290740967
Validation loss: 1.892308065968175

Epoch: 222| Step: 0
Training loss: 2.0413920879364014
Validation loss: 1.8825040683951428

Epoch: 6| Step: 1
Training loss: 1.2739392518997192
Validation loss: 1.8622565397652246

Epoch: 6| Step: 2
Training loss: 2.011228322982788
Validation loss: 1.8137404290578698

Epoch: 6| Step: 3
Training loss: 1.8332816362380981
Validation loss: 1.8507813535710818

Epoch: 6| Step: 4
Training loss: 1.1530437469482422
Validation loss: 1.8514189771426621

Epoch: 6| Step: 5
Training loss: 1.363680362701416
Validation loss: 1.876746468646552

Epoch: 6| Step: 6
Training loss: 1.6109890937805176
Validation loss: 1.863578615650054

Epoch: 6| Step: 7
Training loss: 1.1641929149627686
Validation loss: 1.819335849054398

Epoch: 6| Step: 8
Training loss: 1.8217684030532837
Validation loss: 1.869939911750055

Epoch: 6| Step: 9
Training loss: 1.3469736576080322
Validation loss: 1.8528531982052712

Epoch: 6| Step: 10
Training loss: 1.9056612253189087
Validation loss: 1.8492929730364072

Epoch: 6| Step: 11
Training loss: 1.5116486549377441
Validation loss: 1.8711233164674492

Epoch: 6| Step: 12
Training loss: 2.1572470664978027
Validation loss: 1.8689482955522434

Epoch: 6| Step: 13
Training loss: 2.3913068771362305
Validation loss: 1.8589110028359197

Epoch: 223| Step: 0
Training loss: 1.8246409893035889
Validation loss: 1.8790157251460577

Epoch: 6| Step: 1
Training loss: 0.929427981376648
Validation loss: 1.8731114787440146

Epoch: 6| Step: 2
Training loss: 2.2144298553466797
Validation loss: 1.8555215507425287

Epoch: 6| Step: 3
Training loss: 1.7240734100341797
Validation loss: 1.8837517179468626

Epoch: 6| Step: 4
Training loss: 1.9258882999420166
Validation loss: 1.897420419159756

Epoch: 6| Step: 5
Training loss: 1.6016688346862793
Validation loss: 1.9051906447256766

Epoch: 6| Step: 6
Training loss: 1.5229166746139526
Validation loss: 1.8915373868839715

Epoch: 6| Step: 7
Training loss: 1.2321041822433472
Validation loss: 1.890105019333542

Epoch: 6| Step: 8
Training loss: 1.4340547323226929
Validation loss: 1.8709395290702902

Epoch: 6| Step: 9
Training loss: 1.818108081817627
Validation loss: 1.9186132325921008

Epoch: 6| Step: 10
Training loss: 1.6770637035369873
Validation loss: 1.900783214517819

Epoch: 6| Step: 11
Training loss: 1.6688790321350098
Validation loss: 1.9172854859341857

Epoch: 6| Step: 12
Training loss: 2.483865976333618
Validation loss: 1.8623296753052743

Epoch: 6| Step: 13
Training loss: 1.0545117855072021
Validation loss: 1.8868590119064494

Epoch: 224| Step: 0
Training loss: 1.7945506572723389
Validation loss: 1.8422486532119013

Epoch: 6| Step: 1
Training loss: 1.8096380233764648
Validation loss: 1.8603447867978005

Epoch: 6| Step: 2
Training loss: 1.3082387447357178
Validation loss: 1.8420328555568573

Epoch: 6| Step: 3
Training loss: 1.6565688848495483
Validation loss: 1.8411427928555397

Epoch: 6| Step: 4
Training loss: 1.5186975002288818
Validation loss: 1.8006043305961035

Epoch: 6| Step: 5
Training loss: 1.8557181358337402
Validation loss: 1.8576201764486169

Epoch: 6| Step: 6
Training loss: 2.070758819580078
Validation loss: 1.8283000197461856

Epoch: 6| Step: 7
Training loss: 1.1831536293029785
Validation loss: 1.859092954666384

Epoch: 6| Step: 8
Training loss: 2.6063997745513916
Validation loss: 1.8313999022206953

Epoch: 6| Step: 9
Training loss: 1.8294963836669922
Validation loss: 1.8576549073701263

Epoch: 6| Step: 10
Training loss: 1.7765207290649414
Validation loss: 1.8183497805749216

Epoch: 6| Step: 11
Training loss: 1.2523809671401978
Validation loss: 1.8234697823883386

Epoch: 6| Step: 12
Training loss: 1.3574141263961792
Validation loss: 1.793653211285991

Epoch: 6| Step: 13
Training loss: 1.0639703273773193
Validation loss: 1.8196299422171809

Epoch: 225| Step: 0
Training loss: 1.3551446199417114
Validation loss: 1.8433174471701346

Epoch: 6| Step: 1
Training loss: 2.3252530097961426
Validation loss: 1.8093950549761455

Epoch: 6| Step: 2
Training loss: 1.690694808959961
Validation loss: 1.8766169176306775

Epoch: 6| Step: 3
Training loss: 1.8077828884124756
Validation loss: 1.8759444811010872

Epoch: 6| Step: 4
Training loss: 1.8433798551559448
Validation loss: 1.8443299762664302

Epoch: 6| Step: 5
Training loss: 2.630056381225586
Validation loss: 1.8687545355930124

Epoch: 6| Step: 6
Training loss: 1.838127613067627
Validation loss: 1.8745994747325938

Epoch: 6| Step: 7
Training loss: 1.745797038078308
Validation loss: 1.8683521850134737

Epoch: 6| Step: 8
Training loss: 1.733702301979065
Validation loss: 1.9009583765460598

Epoch: 6| Step: 9
Training loss: 1.1132011413574219
Validation loss: 1.9008677774860012

Epoch: 6| Step: 10
Training loss: 2.154599905014038
Validation loss: 1.9130876064300537

Epoch: 6| Step: 11
Training loss: 0.8587917685508728
Validation loss: 1.900637480520433

Epoch: 6| Step: 12
Training loss: 1.006098985671997
Validation loss: 1.8655823904980895

Epoch: 6| Step: 13
Training loss: 0.901124119758606
Validation loss: 1.8851452873599144

Epoch: 226| Step: 0
Training loss: 2.1010901927948
Validation loss: 1.8992059525623117

Epoch: 6| Step: 1
Training loss: 1.657510757446289
Validation loss: 1.8545948138801

Epoch: 6| Step: 2
Training loss: 2.026949167251587
Validation loss: 1.8652550763981317

Epoch: 6| Step: 3
Training loss: 1.1048557758331299
Validation loss: 1.8613120766096218

Epoch: 6| Step: 4
Training loss: 1.205800175666809
Validation loss: 1.8124292281366163

Epoch: 6| Step: 5
Training loss: 2.318594455718994
Validation loss: 1.8421117785156413

Epoch: 6| Step: 6
Training loss: 1.917718768119812
Validation loss: 1.8470668754269999

Epoch: 6| Step: 7
Training loss: 1.7627336978912354
Validation loss: 1.8531267258428759

Epoch: 6| Step: 8
Training loss: 1.3762664794921875
Validation loss: 1.836333167168402

Epoch: 6| Step: 9
Training loss: 1.710062026977539
Validation loss: 1.8371819462827457

Epoch: 6| Step: 10
Training loss: 1.5228073596954346
Validation loss: 1.8113561714849165

Epoch: 6| Step: 11
Training loss: 1.8542732000350952
Validation loss: 1.844244481414877

Epoch: 6| Step: 12
Training loss: 1.2007122039794922
Validation loss: 1.8504449795651179

Epoch: 6| Step: 13
Training loss: 1.6208295822143555
Validation loss: 1.861993129535388

Epoch: 227| Step: 0
Training loss: 1.8058125972747803
Validation loss: 1.8443909152861564

Epoch: 6| Step: 1
Training loss: 1.6069531440734863
Validation loss: 1.8417353674929628

Epoch: 6| Step: 2
Training loss: 1.070298671722412
Validation loss: 1.8562279362832346

Epoch: 6| Step: 3
Training loss: 2.2528634071350098
Validation loss: 1.8753527697696482

Epoch: 6| Step: 4
Training loss: 1.1450204849243164
Validation loss: 1.8473606212164766

Epoch: 6| Step: 5
Training loss: 1.3551499843597412
Validation loss: 1.8362335005114157

Epoch: 6| Step: 6
Training loss: 1.3340365886688232
Validation loss: 1.8812270984854749

Epoch: 6| Step: 7
Training loss: 1.6730830669403076
Validation loss: 1.8906852147912467

Epoch: 6| Step: 8
Training loss: 2.3058085441589355
Validation loss: 1.900668897936421

Epoch: 6| Step: 9
Training loss: 2.1455395221710205
Validation loss: 1.890093739314746

Epoch: 6| Step: 10
Training loss: 1.3873934745788574
Validation loss: 1.887578087468301

Epoch: 6| Step: 11
Training loss: 2.233588218688965
Validation loss: 1.8609722019523702

Epoch: 6| Step: 12
Training loss: 1.8993892669677734
Validation loss: 1.9130667947953748

Epoch: 6| Step: 13
Training loss: 1.1486440896987915
Validation loss: 1.8760695854822795

Epoch: 228| Step: 0
Training loss: 1.7203104496002197
Validation loss: 1.846464980033136

Epoch: 6| Step: 1
Training loss: 2.0140278339385986
Validation loss: 1.903133246206468

Epoch: 6| Step: 2
Training loss: 1.9016529321670532
Validation loss: 1.8422340218738844

Epoch: 6| Step: 3
Training loss: 1.8386574983596802
Validation loss: 1.8309265708410611

Epoch: 6| Step: 4
Training loss: 1.2015974521636963
Validation loss: 1.8512596346998726

Epoch: 6| Step: 5
Training loss: 1.2562477588653564
Validation loss: 1.8522817780894618

Epoch: 6| Step: 6
Training loss: 1.4974753856658936
Validation loss: 1.7918029036573184

Epoch: 6| Step: 7
Training loss: 1.8285577297210693
Validation loss: 1.8148256283934399

Epoch: 6| Step: 8
Training loss: 1.5859580039978027
Validation loss: 1.8314889784782165

Epoch: 6| Step: 9
Training loss: 1.9638183116912842
Validation loss: 1.864351511001587

Epoch: 6| Step: 10
Training loss: 1.559753656387329
Validation loss: 1.8316644250705678

Epoch: 6| Step: 11
Training loss: 2.199352741241455
Validation loss: 1.8484136596802743

Epoch: 6| Step: 12
Training loss: 1.0774970054626465
Validation loss: 1.8596640940635436

Epoch: 6| Step: 13
Training loss: 1.7042789459228516
Validation loss: 1.8296504764146702

Epoch: 229| Step: 0
Training loss: 1.7819854021072388
Validation loss: 1.8229386985942881

Epoch: 6| Step: 1
Training loss: 1.4820492267608643
Validation loss: 1.8661264347773727

Epoch: 6| Step: 2
Training loss: 1.9392881393432617
Validation loss: 1.861385186513265

Epoch: 6| Step: 3
Training loss: 1.4206632375717163
Validation loss: 1.8874380434713056

Epoch: 6| Step: 4
Training loss: 1.734864592552185
Validation loss: 1.8720121947667931

Epoch: 6| Step: 5
Training loss: 1.6030383110046387
Validation loss: 1.8876433372497559

Epoch: 6| Step: 6
Training loss: 1.8276973962783813
Validation loss: 1.9089184704647268

Epoch: 6| Step: 7
Training loss: 1.8776123523712158
Validation loss: 1.892747586773288

Epoch: 6| Step: 8
Training loss: 1.073820948600769
Validation loss: 1.855820644286371

Epoch: 6| Step: 9
Training loss: 1.6984142065048218
Validation loss: 1.9049041630119405

Epoch: 6| Step: 10
Training loss: 1.6533691883087158
Validation loss: 1.8503528769298265

Epoch: 6| Step: 11
Training loss: 2.0529987812042236
Validation loss: 1.821022028564125

Epoch: 6| Step: 12
Training loss: 1.5047959089279175
Validation loss: 1.854508856291412

Epoch: 6| Step: 13
Training loss: 1.5239664316177368
Validation loss: 1.8513623053027737

Epoch: 230| Step: 0
Training loss: 2.0627827644348145
Validation loss: 1.86152321164326

Epoch: 6| Step: 1
Training loss: 1.424057960510254
Validation loss: 1.8364244455932288

Epoch: 6| Step: 2
Training loss: 1.2836391925811768
Validation loss: 1.8268538854455436

Epoch: 6| Step: 3
Training loss: 1.2524586915969849
Validation loss: 1.8172569761994064

Epoch: 6| Step: 4
Training loss: 1.7393462657928467
Validation loss: 1.8765919516163487

Epoch: 6| Step: 5
Training loss: 1.72418212890625
Validation loss: 1.8293770949045818

Epoch: 6| Step: 6
Training loss: 1.8642079830169678
Validation loss: 1.8206584915038078

Epoch: 6| Step: 7
Training loss: 2.207587242126465
Validation loss: 1.8064982160445182

Epoch: 6| Step: 8
Training loss: 1.1265884637832642
Validation loss: 1.8400482285407282

Epoch: 6| Step: 9
Training loss: 2.1444826126098633
Validation loss: 1.8341267826736614

Epoch: 6| Step: 10
Training loss: 1.2107417583465576
Validation loss: 1.8239324144137803

Epoch: 6| Step: 11
Training loss: 1.9277331829071045
Validation loss: 1.869011629012323

Epoch: 6| Step: 12
Training loss: 1.2792469263076782
Validation loss: 1.8535488151734876

Epoch: 6| Step: 13
Training loss: 1.7631819248199463
Validation loss: 1.8240268820075578

Epoch: 231| Step: 0
Training loss: 2.3301949501037598
Validation loss: 1.8218463774650329

Epoch: 6| Step: 1
Training loss: 1.5673072338104248
Validation loss: 1.86184488701564

Epoch: 6| Step: 2
Training loss: 1.4586085081100464
Validation loss: 1.8726799526522238

Epoch: 6| Step: 3
Training loss: 1.034069299697876
Validation loss: 1.8372851059000979

Epoch: 6| Step: 4
Training loss: 1.744349479675293
Validation loss: 1.8587030492803103

Epoch: 6| Step: 5
Training loss: 1.9728116989135742
Validation loss: 1.8728833365184006

Epoch: 6| Step: 6
Training loss: 2.168755054473877
Validation loss: 1.8678844333976827

Epoch: 6| Step: 7
Training loss: 1.33016836643219
Validation loss: 1.838896853949434

Epoch: 6| Step: 8
Training loss: 1.361130952835083
Validation loss: 1.8213042418162029

Epoch: 6| Step: 9
Training loss: 1.692000389099121
Validation loss: 1.894915961450146

Epoch: 6| Step: 10
Training loss: 1.5609452724456787
Validation loss: 1.848860571461339

Epoch: 6| Step: 11
Training loss: 1.618311882019043
Validation loss: 1.8652692828127133

Epoch: 6| Step: 12
Training loss: 1.7820122241973877
Validation loss: 1.8398696325158561

Epoch: 6| Step: 13
Training loss: 1.7836875915527344
Validation loss: 1.8296231480054959

Epoch: 232| Step: 0
Training loss: 1.6500756740570068
Validation loss: 1.8606445122790594

Epoch: 6| Step: 1
Training loss: 1.2201306819915771
Validation loss: 1.8584236278328845

Epoch: 6| Step: 2
Training loss: 1.5552327632904053
Validation loss: 1.8173141633310625

Epoch: 6| Step: 3
Training loss: 1.6286721229553223
Validation loss: 1.8147130986695648

Epoch: 6| Step: 4
Training loss: 1.9324367046356201
Validation loss: 1.8494708922601515

Epoch: 6| Step: 5
Training loss: 1.5143483877182007
Validation loss: 1.8417378958835398

Epoch: 6| Step: 6
Training loss: 1.312291145324707
Validation loss: 1.8637475031678394

Epoch: 6| Step: 7
Training loss: 1.0776121616363525
Validation loss: 1.8422106799258982

Epoch: 6| Step: 8
Training loss: 2.087366819381714
Validation loss: 1.8235243866520543

Epoch: 6| Step: 9
Training loss: 2.528815269470215
Validation loss: 1.8216012088201379

Epoch: 6| Step: 10
Training loss: 1.748643159866333
Validation loss: 1.8397834659904562

Epoch: 6| Step: 11
Training loss: 2.081174850463867
Validation loss: 1.8254984700551597

Epoch: 6| Step: 12
Training loss: 1.097663402557373
Validation loss: 1.8316027861769482

Epoch: 6| Step: 13
Training loss: 2.089130163192749
Validation loss: 1.8578163834028347

Epoch: 233| Step: 0
Training loss: 1.2032663822174072
Validation loss: 1.8382636116396995

Epoch: 6| Step: 1
Training loss: 1.3024853467941284
Validation loss: 1.849863976560613

Epoch: 6| Step: 2
Training loss: 1.7197736501693726
Validation loss: 1.8863372354097263

Epoch: 6| Step: 3
Training loss: 0.9880567193031311
Validation loss: 1.9343411409726707

Epoch: 6| Step: 4
Training loss: 2.1278908252716064
Validation loss: 1.8973968029022217

Epoch: 6| Step: 5
Training loss: 2.3466734886169434
Validation loss: 1.9030659121851767

Epoch: 6| Step: 6
Training loss: 1.8480777740478516
Validation loss: 1.8850204893337783

Epoch: 6| Step: 7
Training loss: 1.0063090324401855
Validation loss: 1.8837581398666545

Epoch: 6| Step: 8
Training loss: 1.5472619533538818
Validation loss: 1.8895345939102994

Epoch: 6| Step: 9
Training loss: 1.9521830081939697
Validation loss: 1.866310065792453

Epoch: 6| Step: 10
Training loss: 1.9132726192474365
Validation loss: 1.8521367170477425

Epoch: 6| Step: 11
Training loss: 1.235248327255249
Validation loss: 1.8645389259502452

Epoch: 6| Step: 12
Training loss: 2.193953037261963
Validation loss: 1.8652233103270173

Epoch: 6| Step: 13
Training loss: 1.864133596420288
Validation loss: 1.8001212830184607

Epoch: 234| Step: 0
Training loss: 1.2721749544143677
Validation loss: 1.8407607514371154

Epoch: 6| Step: 1
Training loss: 1.2466914653778076
Validation loss: 1.833715428588211

Epoch: 6| Step: 2
Training loss: 1.4311646223068237
Validation loss: 1.8413966535240092

Epoch: 6| Step: 3
Training loss: 2.2015533447265625
Validation loss: 1.8165212267188615

Epoch: 6| Step: 4
Training loss: 1.992069959640503
Validation loss: 1.825260328990157

Epoch: 6| Step: 5
Training loss: 1.7676197290420532
Validation loss: 1.8469045046837098

Epoch: 6| Step: 6
Training loss: 1.7207990884780884
Validation loss: 1.845120801720568

Epoch: 6| Step: 7
Training loss: 1.5138816833496094
Validation loss: 1.844524122053577

Epoch: 6| Step: 8
Training loss: 1.5231847763061523
Validation loss: 1.8360278849960656

Epoch: 6| Step: 9
Training loss: 1.8137645721435547
Validation loss: 1.8483492866639168

Epoch: 6| Step: 10
Training loss: 1.2521865367889404
Validation loss: 1.867101594965945

Epoch: 6| Step: 11
Training loss: 2.2355360984802246
Validation loss: 1.8630344483160204

Epoch: 6| Step: 12
Training loss: 1.1512426137924194
Validation loss: 1.8662737748956169

Epoch: 6| Step: 13
Training loss: 2.2562971115112305
Validation loss: 1.8520656913839362

Epoch: 235| Step: 0
Training loss: 1.0111322402954102
Validation loss: 1.8606590635033065

Epoch: 6| Step: 1
Training loss: 1.9491482973098755
Validation loss: 1.8664661940707956

Epoch: 6| Step: 2
Training loss: 1.309261679649353
Validation loss: 1.8618922291263458

Epoch: 6| Step: 3
Training loss: 1.113156795501709
Validation loss: 1.8851519566710278

Epoch: 6| Step: 4
Training loss: 1.9726015329360962
Validation loss: 1.8505308435809227

Epoch: 6| Step: 5
Training loss: 1.2478288412094116
Validation loss: 1.8338038818810576

Epoch: 6| Step: 6
Training loss: 1.4943137168884277
Validation loss: 1.8165307839711506

Epoch: 6| Step: 7
Training loss: 2.2762246131896973
Validation loss: 1.907413487793297

Epoch: 6| Step: 8
Training loss: 1.9651755094528198
Validation loss: 1.885084698277135

Epoch: 6| Step: 9
Training loss: 1.1190237998962402
Validation loss: 1.840573472361411

Epoch: 6| Step: 10
Training loss: 1.5550522804260254
Validation loss: 1.8343774503277195

Epoch: 6| Step: 11
Training loss: 1.5483348369598389
Validation loss: 1.8355077184656614

Epoch: 6| Step: 12
Training loss: 2.160515785217285
Validation loss: 1.859550372246773

Epoch: 6| Step: 13
Training loss: 2.028998613357544
Validation loss: 1.846728269771863

Epoch: 236| Step: 0
Training loss: 1.7821485996246338
Validation loss: 1.8459243697504844

Epoch: 6| Step: 1
Training loss: 1.415097713470459
Validation loss: 1.8376603767436037

Epoch: 6| Step: 2
Training loss: 1.9360271692276
Validation loss: 1.8572400385333645

Epoch: 6| Step: 3
Training loss: 2.213139295578003
Validation loss: 1.8155485032707133

Epoch: 6| Step: 4
Training loss: 0.8344547152519226
Validation loss: 1.8465317397989252

Epoch: 6| Step: 5
Training loss: 1.6179670095443726
Validation loss: 1.8270889969282254

Epoch: 6| Step: 6
Training loss: 1.6200834512710571
Validation loss: 1.815487915469754

Epoch: 6| Step: 7
Training loss: 2.351688861846924
Validation loss: 1.8162478029087026

Epoch: 6| Step: 8
Training loss: 2.1507651805877686
Validation loss: 1.8307780937481952

Epoch: 6| Step: 9
Training loss: 1.3309175968170166
Validation loss: 1.8266815459856423

Epoch: 6| Step: 10
Training loss: 1.378234624862671
Validation loss: 1.8095275253377936

Epoch: 6| Step: 11
Training loss: 1.9863452911376953
Validation loss: 1.855884773756868

Epoch: 6| Step: 12
Training loss: 1.3492671251296997
Validation loss: 1.8543140503668016

Epoch: 6| Step: 13
Training loss: 1.1145529747009277
Validation loss: 1.8278759910214333

Epoch: 237| Step: 0
Training loss: 1.995455265045166
Validation loss: 1.838684811387011

Epoch: 6| Step: 1
Training loss: 1.4911911487579346
Validation loss: 1.8470233210953333

Epoch: 6| Step: 2
Training loss: 1.8198152780532837
Validation loss: 1.8472454035153953

Epoch: 6| Step: 3
Training loss: 1.581485629081726
Validation loss: 1.7852811454444804

Epoch: 6| Step: 4
Training loss: 1.4664530754089355
Validation loss: 1.824545532144526

Epoch: 6| Step: 5
Training loss: 1.3061141967773438
Validation loss: 1.7976025894124021

Epoch: 6| Step: 6
Training loss: 1.7630727291107178
Validation loss: 1.8124673520365069

Epoch: 6| Step: 7
Training loss: 1.1784064769744873
Validation loss: 1.8302155053743752

Epoch: 6| Step: 8
Training loss: 1.154388427734375
Validation loss: 1.8501997327291837

Epoch: 6| Step: 9
Training loss: 1.7303292751312256
Validation loss: 1.8181667917518205

Epoch: 6| Step: 10
Training loss: 1.8758243322372437
Validation loss: 1.8382332145526845

Epoch: 6| Step: 11
Training loss: 2.11865496635437
Validation loss: 1.88598572310581

Epoch: 6| Step: 12
Training loss: 1.860737681388855
Validation loss: 1.8849668387443788

Epoch: 6| Step: 13
Training loss: 1.555219292640686
Validation loss: 1.8349326400346653

Epoch: 238| Step: 0
Training loss: 1.3176829814910889
Validation loss: 1.8130228160530009

Epoch: 6| Step: 1
Training loss: 1.5330793857574463
Validation loss: 1.8500055933511386

Epoch: 6| Step: 2
Training loss: 1.3553967475891113
Validation loss: 1.8704313693508026

Epoch: 6| Step: 3
Training loss: 1.2317572832107544
Validation loss: 1.802331280964677

Epoch: 6| Step: 4
Training loss: 1.2595458030700684
Validation loss: 1.865518714791985

Epoch: 6| Step: 5
Training loss: 1.8682575225830078
Validation loss: 1.8826773294838526

Epoch: 6| Step: 6
Training loss: 1.27959406375885
Validation loss: 1.8304026049952353

Epoch: 6| Step: 7
Training loss: 1.9767080545425415
Validation loss: 1.8159256596719064

Epoch: 6| Step: 8
Training loss: 1.7979767322540283
Validation loss: 1.8048029740651448

Epoch: 6| Step: 9
Training loss: 2.127376079559326
Validation loss: 1.876288742147466

Epoch: 6| Step: 10
Training loss: 1.7839100360870361
Validation loss: 1.8435010320396834

Epoch: 6| Step: 11
Training loss: 1.6968822479248047
Validation loss: 1.8131744682147939

Epoch: 6| Step: 12
Training loss: 1.829585075378418
Validation loss: 1.8492376240350867

Epoch: 6| Step: 13
Training loss: 1.8422938585281372
Validation loss: 1.79724536659897

Epoch: 239| Step: 0
Training loss: 1.2289540767669678
Validation loss: 1.8541675254862795

Epoch: 6| Step: 1
Training loss: 2.379802703857422
Validation loss: 1.8545846246903943

Epoch: 6| Step: 2
Training loss: 2.1081366539001465
Validation loss: 1.8183960671065955

Epoch: 6| Step: 3
Training loss: 1.3446599245071411
Validation loss: 1.8897420603741881

Epoch: 6| Step: 4
Training loss: 1.3826450109481812
Validation loss: 1.7937353657137962

Epoch: 6| Step: 5
Training loss: 1.9102065563201904
Validation loss: 1.8635280965476908

Epoch: 6| Step: 6
Training loss: 0.821338415145874
Validation loss: 1.8792603246627315

Epoch: 6| Step: 7
Training loss: 1.5619580745697021
Validation loss: 1.8693735637972433

Epoch: 6| Step: 8
Training loss: 1.930831789970398
Validation loss: 1.863855081219827

Epoch: 6| Step: 9
Training loss: 1.4347889423370361
Validation loss: 1.8562379011543848

Epoch: 6| Step: 10
Training loss: 2.038302183151245
Validation loss: 1.846496820449829

Epoch: 6| Step: 11
Training loss: 1.8522117137908936
Validation loss: 1.8355141967855475

Epoch: 6| Step: 12
Training loss: 1.5349427461624146
Validation loss: 1.8476526544940086

Epoch: 6| Step: 13
Training loss: 0.7553874254226685
Validation loss: 1.855169524428665

Epoch: 240| Step: 0
Training loss: 1.6286869049072266
Validation loss: 1.8647315822621828

Epoch: 6| Step: 1
Training loss: 1.5355300903320312
Validation loss: 1.9017254280787643

Epoch: 6| Step: 2
Training loss: 1.308117151260376
Validation loss: 1.8626882158299929

Epoch: 6| Step: 3
Training loss: 1.43644118309021
Validation loss: 1.8573998738360662

Epoch: 6| Step: 4
Training loss: 2.011406898498535
Validation loss: 1.8252958277220368

Epoch: 6| Step: 5
Training loss: 1.6001689434051514
Validation loss: 1.867687040759671

Epoch: 6| Step: 6
Training loss: 1.269639015197754
Validation loss: 1.8452773004449823

Epoch: 6| Step: 7
Training loss: 1.569682002067566
Validation loss: 1.816628151042487

Epoch: 6| Step: 8
Training loss: 1.964384913444519
Validation loss: 1.8567228906898088

Epoch: 6| Step: 9
Training loss: 2.026609420776367
Validation loss: 1.847785431851623

Epoch: 6| Step: 10
Training loss: 2.635685443878174
Validation loss: 1.8811652827006515

Epoch: 6| Step: 11
Training loss: 1.0549296140670776
Validation loss: 1.8969027367971276

Epoch: 6| Step: 12
Training loss: 1.3252911567687988
Validation loss: 1.8451506348066433

Epoch: 6| Step: 13
Training loss: 1.213090419769287
Validation loss: 1.8612618356622674

Epoch: 241| Step: 0
Training loss: 1.3977642059326172
Validation loss: 1.8512960736469557

Epoch: 6| Step: 1
Training loss: 1.6715517044067383
Validation loss: 1.8689394484284103

Epoch: 6| Step: 2
Training loss: 0.7873316407203674
Validation loss: 1.8534592915606756

Epoch: 6| Step: 3
Training loss: 1.5516022443771362
Validation loss: 1.8866139996436335

Epoch: 6| Step: 4
Training loss: 1.686940312385559
Validation loss: 1.8591294903909006

Epoch: 6| Step: 5
Training loss: 1.7454885244369507
Validation loss: 1.8768131015121297

Epoch: 6| Step: 6
Training loss: 1.4955577850341797
Validation loss: 1.8333475397479149

Epoch: 6| Step: 7
Training loss: 1.8765875101089478
Validation loss: 1.8797807719117852

Epoch: 6| Step: 8
Training loss: 2.054845094680786
Validation loss: 1.8734117502807288

Epoch: 6| Step: 9
Training loss: 2.331023931503296
Validation loss: 1.8436172854515813

Epoch: 6| Step: 10
Training loss: 1.431305170059204
Validation loss: 1.8988389071597849

Epoch: 6| Step: 11
Training loss: 1.2402300834655762
Validation loss: 1.885842074630081

Epoch: 6| Step: 12
Training loss: 1.3346527814865112
Validation loss: 1.8775415664078088

Epoch: 6| Step: 13
Training loss: 2.4984443187713623
Validation loss: 1.8179331723079886

Epoch: 242| Step: 0
Training loss: 1.3731030225753784
Validation loss: 1.8329692425266388

Epoch: 6| Step: 1
Training loss: 1.4616634845733643
Validation loss: 1.839919956781531

Epoch: 6| Step: 2
Training loss: 1.2046152353286743
Validation loss: 1.8332148598086448

Epoch: 6| Step: 3
Training loss: 1.7214045524597168
Validation loss: 1.868061456629025

Epoch: 6| Step: 4
Training loss: 1.6853359937667847
Validation loss: 1.7849178750027892

Epoch: 6| Step: 5
Training loss: 1.7019399404525757
Validation loss: 1.8292244429229407

Epoch: 6| Step: 6
Training loss: 2.1866214275360107
Validation loss: 1.8644710510007796

Epoch: 6| Step: 7
Training loss: 1.2976996898651123
Validation loss: 1.8129003317125383

Epoch: 6| Step: 8
Training loss: 1.65119469165802
Validation loss: 1.8380987272467664

Epoch: 6| Step: 9
Training loss: 1.5938444137573242
Validation loss: 1.7907680439692673

Epoch: 6| Step: 10
Training loss: 2.0420637130737305
Validation loss: 1.8206655389519149

Epoch: 6| Step: 11
Training loss: 1.4939887523651123
Validation loss: 1.8307142642236525

Epoch: 6| Step: 12
Training loss: 1.5250842571258545
Validation loss: 1.8310352038311701

Epoch: 6| Step: 13
Training loss: 1.5003541707992554
Validation loss: 1.818079952270754

Epoch: 243| Step: 0
Training loss: 1.731238842010498
Validation loss: 1.8358245716300061

Epoch: 6| Step: 1
Training loss: 1.5591132640838623
Validation loss: 1.8683051434896325

Epoch: 6| Step: 2
Training loss: 2.025369882583618
Validation loss: 1.8609594786038963

Epoch: 6| Step: 3
Training loss: 2.097205638885498
Validation loss: 1.8629990085478751

Epoch: 6| Step: 4
Training loss: 1.8419517278671265
Validation loss: 1.8476145549487042

Epoch: 6| Step: 5
Training loss: 1.1763050556182861
Validation loss: 1.8491708386328913

Epoch: 6| Step: 6
Training loss: 1.4954297542572021
Validation loss: 1.8123655588396135

Epoch: 6| Step: 7
Training loss: 1.465672254562378
Validation loss: 1.8882538528852566

Epoch: 6| Step: 8
Training loss: 2.207932472229004
Validation loss: 1.8331221662541872

Epoch: 6| Step: 9
Training loss: 1.2346831560134888
Validation loss: 1.8656645115985666

Epoch: 6| Step: 10
Training loss: 1.0598561763763428
Validation loss: 1.9072443669842136

Epoch: 6| Step: 11
Training loss: 1.5904006958007812
Validation loss: 1.8127425896224154

Epoch: 6| Step: 12
Training loss: 1.357926845550537
Validation loss: 1.8590937993859733

Epoch: 6| Step: 13
Training loss: 1.5627092123031616
Validation loss: 1.8760327575027302

Epoch: 244| Step: 0
Training loss: 1.3633617162704468
Validation loss: 1.884305691206327

Epoch: 6| Step: 1
Training loss: 1.6293058395385742
Validation loss: 1.855076051527454

Epoch: 6| Step: 2
Training loss: 1.394413948059082
Validation loss: 1.847998244788057

Epoch: 6| Step: 3
Training loss: 1.109148383140564
Validation loss: 1.8810527170858076

Epoch: 6| Step: 4
Training loss: 1.5587527751922607
Validation loss: 1.9094220835675475

Epoch: 6| Step: 5
Training loss: 1.394411325454712
Validation loss: 1.8815243910717707

Epoch: 6| Step: 6
Training loss: 1.8938921689987183
Validation loss: 1.9091744410094393

Epoch: 6| Step: 7
Training loss: 2.3821592330932617
Validation loss: 1.8717235108857513

Epoch: 6| Step: 8
Training loss: 1.4341944456100464
Validation loss: 1.8657195145084011

Epoch: 6| Step: 9
Training loss: 1.9710423946380615
Validation loss: 1.902679612559657

Epoch: 6| Step: 10
Training loss: 1.9832608699798584
Validation loss: 1.881114129097231

Epoch: 6| Step: 11
Training loss: 1.2430593967437744
Validation loss: 1.8674250238685197

Epoch: 6| Step: 12
Training loss: 1.5950706005096436
Validation loss: 1.8222072739754953

Epoch: 6| Step: 13
Training loss: 1.518819808959961
Validation loss: 1.8452098318325576

Epoch: 245| Step: 0
Training loss: 1.4360896348953247
Validation loss: 1.827159785455273

Epoch: 6| Step: 1
Training loss: 1.4745049476623535
Validation loss: 1.8307829210835118

Epoch: 6| Step: 2
Training loss: 1.1563724279403687
Validation loss: 1.7779437880362234

Epoch: 6| Step: 3
Training loss: 2.0585227012634277
Validation loss: 1.842493349506009

Epoch: 6| Step: 4
Training loss: 1.4353201389312744
Validation loss: 1.8502889397323772

Epoch: 6| Step: 5
Training loss: 1.7509015798568726
Validation loss: 1.8571621397490143

Epoch: 6| Step: 6
Training loss: 1.201062798500061
Validation loss: 1.873281394281695

Epoch: 6| Step: 7
Training loss: 1.910814642906189
Validation loss: 1.7759505292420745

Epoch: 6| Step: 8
Training loss: 2.0292274951934814
Validation loss: 1.8204564920035742

Epoch: 6| Step: 9
Training loss: 1.213385820388794
Validation loss: 1.8524857221111175

Epoch: 6| Step: 10
Training loss: 1.8481262922286987
Validation loss: 1.8301270866906771

Epoch: 6| Step: 11
Training loss: 1.8621089458465576
Validation loss: 1.800944564163044

Epoch: 6| Step: 12
Training loss: 1.5500881671905518
Validation loss: 1.825058703781456

Epoch: 6| Step: 13
Training loss: 1.5157361030578613
Validation loss: 1.8721920546664987

Epoch: 246| Step: 0
Training loss: 1.6288403272628784
Validation loss: 1.8117358492266746

Epoch: 6| Step: 1
Training loss: 2.174654960632324
Validation loss: 1.8425779419560586

Epoch: 6| Step: 2
Training loss: 1.3806487321853638
Validation loss: 1.824700511911864

Epoch: 6| Step: 3
Training loss: 2.0344388484954834
Validation loss: 1.8322088641505088

Epoch: 6| Step: 4
Training loss: 1.390677571296692
Validation loss: 1.8813276585712229

Epoch: 6| Step: 5
Training loss: 1.636066198348999
Validation loss: 1.8564952112013293

Epoch: 6| Step: 6
Training loss: 1.8110780715942383
Validation loss: 1.8510210603796027

Epoch: 6| Step: 7
Training loss: 1.42247474193573
Validation loss: 1.8464256166129984

Epoch: 6| Step: 8
Training loss: 1.411365270614624
Validation loss: 1.8292463671776555

Epoch: 6| Step: 9
Training loss: 1.5757911205291748
Validation loss: 1.870168775640508

Epoch: 6| Step: 10
Training loss: 1.6807215213775635
Validation loss: 1.8293269847029

Epoch: 6| Step: 11
Training loss: 1.4707783460617065
Validation loss: 1.824793872012887

Epoch: 6| Step: 12
Training loss: 1.3805968761444092
Validation loss: 1.8552322003149218

Epoch: 6| Step: 13
Training loss: 1.5909297466278076
Validation loss: 1.850303615293195

Epoch: 247| Step: 0
Training loss: 1.2611987590789795
Validation loss: 1.8019671363215293

Epoch: 6| Step: 1
Training loss: 1.7602221965789795
Validation loss: 1.833557059687953

Epoch: 6| Step: 2
Training loss: 1.8030109405517578
Validation loss: 1.861540868718137

Epoch: 6| Step: 3
Training loss: 1.9190170764923096
Validation loss: 1.7962072433963898

Epoch: 6| Step: 4
Training loss: 1.7622771263122559
Validation loss: 1.831743727448166

Epoch: 6| Step: 5
Training loss: 1.5598596334457397
Validation loss: 1.831792437902061

Epoch: 6| Step: 6
Training loss: 1.6968586444854736
Validation loss: 1.836279696033847

Epoch: 6| Step: 7
Training loss: 2.110511541366577
Validation loss: 1.848564863204956

Epoch: 6| Step: 8
Training loss: 1.6199274063110352
Validation loss: 1.8441259604628368

Epoch: 6| Step: 9
Training loss: 1.7426438331604004
Validation loss: 1.8240955363037765

Epoch: 6| Step: 10
Training loss: 0.9357293844223022
Validation loss: 1.8403525993388186

Epoch: 6| Step: 11
Training loss: 1.5436410903930664
Validation loss: 1.8629016286583358

Epoch: 6| Step: 12
Training loss: 1.3294563293457031
Validation loss: 1.852779221791093

Epoch: 6| Step: 13
Training loss: 1.6611015796661377
Validation loss: 1.857156712521789

Epoch: 248| Step: 0
Training loss: 1.0726597309112549
Validation loss: 1.8609071508530648

Epoch: 6| Step: 1
Training loss: 2.022533416748047
Validation loss: 1.8840647230866134

Epoch: 6| Step: 2
Training loss: 1.3973325490951538
Validation loss: 1.8713915142961728

Epoch: 6| Step: 3
Training loss: 1.677567720413208
Validation loss: 1.8847924304264847

Epoch: 6| Step: 4
Training loss: 2.057177782058716
Validation loss: 1.8604120105825446

Epoch: 6| Step: 5
Training loss: 1.7443395853042603
Validation loss: 1.8542587667383172

Epoch: 6| Step: 6
Training loss: 1.4877896308898926
Validation loss: 1.863802553505026

Epoch: 6| Step: 7
Training loss: 2.0450501441955566
Validation loss: 1.8628137214209444

Epoch: 6| Step: 8
Training loss: 1.112324595451355
Validation loss: 1.8231254854509908

Epoch: 6| Step: 9
Training loss: 1.5262384414672852
Validation loss: 1.8568350922676824

Epoch: 6| Step: 10
Training loss: 1.3756213188171387
Validation loss: 1.8472783437339209

Epoch: 6| Step: 11
Training loss: 1.5034499168395996
Validation loss: 1.8044493711122902

Epoch: 6| Step: 12
Training loss: 1.1539782285690308
Validation loss: 1.8340458895570488

Epoch: 6| Step: 13
Training loss: 2.265176296234131
Validation loss: 1.8104749007891583

Epoch: 249| Step: 0
Training loss: 1.411746859550476
Validation loss: 1.8554885874512375

Epoch: 6| Step: 1
Training loss: 2.0331244468688965
Validation loss: 1.7963868366774691

Epoch: 6| Step: 2
Training loss: 1.6064637899398804
Validation loss: 1.8230168639972646

Epoch: 6| Step: 3
Training loss: 1.502065658569336
Validation loss: 1.8263145082740373

Epoch: 6| Step: 4
Training loss: 1.7559340000152588
Validation loss: 1.8040288315024426

Epoch: 6| Step: 5
Training loss: 1.5500006675720215
Validation loss: 1.8207504108387937

Epoch: 6| Step: 6
Training loss: 1.6318378448486328
Validation loss: 1.8262927186104558

Epoch: 6| Step: 7
Training loss: 1.799770712852478
Validation loss: 1.8471573193868

Epoch: 6| Step: 8
Training loss: 1.4096155166625977
Validation loss: 1.790208662709882

Epoch: 6| Step: 9
Training loss: 1.4270259141921997
Validation loss: 1.8366060949140979

Epoch: 6| Step: 10
Training loss: 1.347395420074463
Validation loss: 1.8898279256718133

Epoch: 6| Step: 11
Training loss: 2.2368264198303223
Validation loss: 1.8596923735833937

Epoch: 6| Step: 12
Training loss: 1.650879144668579
Validation loss: 1.8309787293916107

Epoch: 6| Step: 13
Training loss: 1.72346830368042
Validation loss: 1.845674871116556

Epoch: 250| Step: 0
Training loss: 1.9099903106689453
Validation loss: 1.8645081737990021

Epoch: 6| Step: 1
Training loss: 1.4122424125671387
Validation loss: 1.842910812747094

Epoch: 6| Step: 2
Training loss: 1.8089925050735474
Validation loss: 1.8456150306168424

Epoch: 6| Step: 3
Training loss: 1.3768894672393799
Validation loss: 1.8558327023701002

Epoch: 6| Step: 4
Training loss: 1.349130630493164
Validation loss: 1.852589435474847

Epoch: 6| Step: 5
Training loss: 1.9197953939437866
Validation loss: 1.8218805918129541

Epoch: 6| Step: 6
Training loss: 1.8759868144989014
Validation loss: 1.8715197142734323

Epoch: 6| Step: 7
Training loss: 1.731062412261963
Validation loss: 1.7903195004309378

Epoch: 6| Step: 8
Training loss: 1.3600943088531494
Validation loss: 1.8672216630751086

Epoch: 6| Step: 9
Training loss: 2.0385684967041016
Validation loss: 1.8481134112163256

Epoch: 6| Step: 10
Training loss: 1.3032824993133545
Validation loss: 1.7881664922160487

Epoch: 6| Step: 11
Training loss: 0.9902266263961792
Validation loss: 1.865077580175092

Epoch: 6| Step: 12
Training loss: 1.3355484008789062
Validation loss: 1.8071410937975811

Epoch: 6| Step: 13
Training loss: 1.5571777820587158
Validation loss: 1.8125201809790827

Epoch: 251| Step: 0
Training loss: 1.2863123416900635
Validation loss: 1.823740625894198

Epoch: 6| Step: 1
Training loss: 2.6057982444763184
Validation loss: 1.818659338899838

Epoch: 6| Step: 2
Training loss: 1.5797237157821655
Validation loss: 1.812898560236859

Epoch: 6| Step: 3
Training loss: 1.6910901069641113
Validation loss: 1.8646801158946047

Epoch: 6| Step: 4
Training loss: 1.4603791236877441
Validation loss: 1.81412681071989

Epoch: 6| Step: 5
Training loss: 1.1896060705184937
Validation loss: 1.8368880518021122

Epoch: 6| Step: 6
Training loss: 0.7707909345626831
Validation loss: 1.8220277063308223

Epoch: 6| Step: 7
Training loss: 2.1140201091766357
Validation loss: 1.8162188863241544

Epoch: 6| Step: 8
Training loss: 1.6087981462478638
Validation loss: 1.8331551449273222

Epoch: 6| Step: 9
Training loss: 1.7719889879226685
Validation loss: 1.7996290473527805

Epoch: 6| Step: 10
Training loss: 1.138016939163208
Validation loss: 1.8262489354738625

Epoch: 6| Step: 11
Training loss: 1.6864804029464722
Validation loss: 1.8104422656438683

Epoch: 6| Step: 12
Training loss: 2.174283504486084
Validation loss: 1.7753272556489514

Epoch: 6| Step: 13
Training loss: 1.2146108150482178
Validation loss: 1.8258725020193285

Epoch: 252| Step: 0
Training loss: 1.2306523323059082
Validation loss: 1.8005577082275062

Epoch: 6| Step: 1
Training loss: 2.037642478942871
Validation loss: 1.8353211020910611

Epoch: 6| Step: 2
Training loss: 2.3314151763916016
Validation loss: 1.853531418308135

Epoch: 6| Step: 3
Training loss: 2.0691540241241455
Validation loss: 1.8484079953162902

Epoch: 6| Step: 4
Training loss: 2.0658764839172363
Validation loss: 1.8139437795967184

Epoch: 6| Step: 5
Training loss: 1.0286507606506348
Validation loss: 1.8136129353636055

Epoch: 6| Step: 6
Training loss: 1.501700520515442
Validation loss: 1.8102032458910378

Epoch: 6| Step: 7
Training loss: 1.279862880706787
Validation loss: 1.8298009390472083

Epoch: 6| Step: 8
Training loss: 1.09395170211792
Validation loss: 1.8295830308750112

Epoch: 6| Step: 9
Training loss: 1.1153303384780884
Validation loss: 1.8450940091122863

Epoch: 6| Step: 10
Training loss: 1.2755476236343384
Validation loss: 1.8503511618542414

Epoch: 6| Step: 11
Training loss: 1.6765910387039185
Validation loss: 1.8269511653530983

Epoch: 6| Step: 12
Training loss: 2.2289016246795654
Validation loss: 1.8306845452195855

Epoch: 6| Step: 13
Training loss: 0.469201922416687
Validation loss: 1.8258152995058285

Epoch: 253| Step: 0
Training loss: 1.197981595993042
Validation loss: 1.8291645152594453

Epoch: 6| Step: 1
Training loss: 1.684445858001709
Validation loss: 1.8423496010482951

Epoch: 6| Step: 2
Training loss: 2.0894508361816406
Validation loss: 1.8432261725907684

Epoch: 6| Step: 3
Training loss: 1.3985023498535156
Validation loss: 1.8785257570205196

Epoch: 6| Step: 4
Training loss: 1.6116220951080322
Validation loss: 1.8511262196366505

Epoch: 6| Step: 5
Training loss: 1.6989305019378662
Validation loss: 1.846516272073151

Epoch: 6| Step: 6
Training loss: 1.429962158203125
Validation loss: 1.8511120529584988

Epoch: 6| Step: 7
Training loss: 1.1977424621582031
Validation loss: 1.8598389356367049

Epoch: 6| Step: 8
Training loss: 1.4877253770828247
Validation loss: 1.8194601715251963

Epoch: 6| Step: 9
Training loss: 1.2788300514221191
Validation loss: 1.856122495025717

Epoch: 6| Step: 10
Training loss: 1.6463446617126465
Validation loss: 1.78240999098747

Epoch: 6| Step: 11
Training loss: 2.8362698554992676
Validation loss: 1.8475273322033625

Epoch: 6| Step: 12
Training loss: 0.998548150062561
Validation loss: 1.8445917316662368

Epoch: 6| Step: 13
Training loss: 1.5846161842346191
Validation loss: 1.7994596701796337

Epoch: 254| Step: 0
Training loss: 1.7434314489364624
Validation loss: 1.8139485005409486

Epoch: 6| Step: 1
Training loss: 1.5489649772644043
Validation loss: 1.8211708761030627

Epoch: 6| Step: 2
Training loss: 1.1953706741333008
Validation loss: 1.8951893621875393

Epoch: 6| Step: 3
Training loss: 0.9600921273231506
Validation loss: 1.837094053786288

Epoch: 6| Step: 4
Training loss: 1.5315736532211304
Validation loss: 1.9070418214285245

Epoch: 6| Step: 5
Training loss: 2.006370782852173
Validation loss: 1.896535922122258

Epoch: 6| Step: 6
Training loss: 1.8382444381713867
Validation loss: 1.8855399252266012

Epoch: 6| Step: 7
Training loss: 1.8640868663787842
Validation loss: 1.9106544371574157

Epoch: 6| Step: 8
Training loss: 1.4488441944122314
Validation loss: 1.912743063383205

Epoch: 6| Step: 9
Training loss: 1.8772773742675781
Validation loss: 1.8840669457630446

Epoch: 6| Step: 10
Training loss: 1.733004093170166
Validation loss: 1.9127810334646573

Epoch: 6| Step: 11
Training loss: 1.2512515783309937
Validation loss: 1.8925195983661118

Epoch: 6| Step: 12
Training loss: 1.4025298357009888
Validation loss: 1.8354175283062844

Epoch: 6| Step: 13
Training loss: 2.095632314682007
Validation loss: 1.862436955974948

Epoch: 255| Step: 0
Training loss: 1.3267104625701904
Validation loss: 1.8363351411716913

Epoch: 6| Step: 1
Training loss: 1.2205736637115479
Validation loss: 1.8755817977331017

Epoch: 6| Step: 2
Training loss: 1.1620230674743652
Validation loss: 1.8482810015319495

Epoch: 6| Step: 3
Training loss: 1.4408063888549805
Validation loss: 1.8406128729543378

Epoch: 6| Step: 4
Training loss: 1.7112009525299072
Validation loss: 1.8536507814161238

Epoch: 6| Step: 5
Training loss: 2.421900749206543
Validation loss: 1.8623949430322135

Epoch: 6| Step: 6
Training loss: 2.082639694213867
Validation loss: 1.8367361919854277

Epoch: 6| Step: 7
Training loss: 1.933516025543213
Validation loss: 1.7875339805438955

Epoch: 6| Step: 8
Training loss: 0.8223515748977661
Validation loss: 1.8107665277296496

Epoch: 6| Step: 9
Training loss: 1.702235221862793
Validation loss: 1.8385491524973223

Epoch: 6| Step: 10
Training loss: 1.2104923725128174
Validation loss: 1.842823895074988

Epoch: 6| Step: 11
Training loss: 2.241596221923828
Validation loss: 1.8368895310227589

Epoch: 6| Step: 12
Training loss: 1.7959721088409424
Validation loss: 1.8479211650868899

Epoch: 6| Step: 13
Training loss: 1.0831831693649292
Validation loss: 1.814362270857698

Epoch: 256| Step: 0
Training loss: 1.6621181964874268
Validation loss: 1.8269235280252272

Epoch: 6| Step: 1
Training loss: 2.1703672409057617
Validation loss: 1.8364851731126026

Epoch: 6| Step: 2
Training loss: 1.1863253116607666
Validation loss: 1.851591206366016

Epoch: 6| Step: 3
Training loss: 1.3457567691802979
Validation loss: 1.8299320615747923

Epoch: 6| Step: 4
Training loss: 2.084179401397705
Validation loss: 1.8544282067206599

Epoch: 6| Step: 5
Training loss: 1.453627109527588
Validation loss: 1.8425554447276618

Epoch: 6| Step: 6
Training loss: 1.5120511054992676
Validation loss: 1.8691079334546161

Epoch: 6| Step: 7
Training loss: 2.0472047328948975
Validation loss: 1.8843963223118936

Epoch: 6| Step: 8
Training loss: 1.6920676231384277
Validation loss: 1.8888762907315326

Epoch: 6| Step: 9
Training loss: 1.7005244493484497
Validation loss: 1.8861666071799494

Epoch: 6| Step: 10
Training loss: 1.331858515739441
Validation loss: 1.8677521649227347

Epoch: 6| Step: 11
Training loss: 0.901827335357666
Validation loss: 1.8480539450081446

Epoch: 6| Step: 12
Training loss: 1.2408041954040527
Validation loss: 1.8426497713212044

Epoch: 6| Step: 13
Training loss: 1.7048829793930054
Validation loss: 1.878922131753737

Epoch: 257| Step: 0
Training loss: 1.1524759531021118
Validation loss: 1.8404859214700677

Epoch: 6| Step: 1
Training loss: 2.2675743103027344
Validation loss: 1.8352972538240495

Epoch: 6| Step: 2
Training loss: 1.6425461769104004
Validation loss: 1.8182593443060433

Epoch: 6| Step: 3
Training loss: 1.583351492881775
Validation loss: 1.857071812434863

Epoch: 6| Step: 4
Training loss: 1.312773585319519
Validation loss: 1.8584654126116025

Epoch: 6| Step: 5
Training loss: 1.5851621627807617
Validation loss: 1.792385289745946

Epoch: 6| Step: 6
Training loss: 1.4913208484649658
Validation loss: 1.8149463848401142

Epoch: 6| Step: 7
Training loss: 1.4768598079681396
Validation loss: 1.8318276764244161

Epoch: 6| Step: 8
Training loss: 1.308774471282959
Validation loss: 1.796377351207118

Epoch: 6| Step: 9
Training loss: 2.3552660942077637
Validation loss: 1.830282301031133

Epoch: 6| Step: 10
Training loss: 1.8490846157073975
Validation loss: 1.835765008003481

Epoch: 6| Step: 11
Training loss: 0.8411363363265991
Validation loss: 1.80624908016574

Epoch: 6| Step: 12
Training loss: 1.5912837982177734
Validation loss: 1.8011475160557737

Epoch: 6| Step: 13
Training loss: 1.4173846244812012
Validation loss: 1.8514124180680962

Epoch: 258| Step: 0
Training loss: 1.617056965827942
Validation loss: 1.827905947162259

Epoch: 6| Step: 1
Training loss: 1.0298089981079102
Validation loss: 1.8294961965212257

Epoch: 6| Step: 2
Training loss: 1.1282341480255127
Validation loss: 1.819997727230031

Epoch: 6| Step: 3
Training loss: 2.2770025730133057
Validation loss: 1.825787608341504

Epoch: 6| Step: 4
Training loss: 1.3922568559646606
Validation loss: 1.8148709817599225

Epoch: 6| Step: 5
Training loss: 1.1022093296051025
Validation loss: 1.843561194276297

Epoch: 6| Step: 6
Training loss: 1.759810209274292
Validation loss: 1.864682202698082

Epoch: 6| Step: 7
Training loss: 2.276392698287964
Validation loss: 1.8297327615881478

Epoch: 6| Step: 8
Training loss: 1.8299709558486938
Validation loss: 1.8052313968699465

Epoch: 6| Step: 9
Training loss: 1.1086642742156982
Validation loss: 1.819894809876719

Epoch: 6| Step: 10
Training loss: 1.3233962059020996
Validation loss: 1.8450823650565198

Epoch: 6| Step: 11
Training loss: 2.102454900741577
Validation loss: 1.782163139312498

Epoch: 6| Step: 12
Training loss: 1.5671520233154297
Validation loss: 1.831674192541389

Epoch: 6| Step: 13
Training loss: 0.7376146912574768
Validation loss: 1.813857025997613

Epoch: 259| Step: 0
Training loss: 1.475763201713562
Validation loss: 1.830535573344077

Epoch: 6| Step: 1
Training loss: 1.8705275058746338
Validation loss: 1.7976629875039543

Epoch: 6| Step: 2
Training loss: 1.8432300090789795
Validation loss: 1.8257622385537753

Epoch: 6| Step: 3
Training loss: 1.3005003929138184
Validation loss: 1.8106252326760242

Epoch: 6| Step: 4
Training loss: 1.4600595235824585
Validation loss: 1.8369649712757399

Epoch: 6| Step: 5
Training loss: 2.007049083709717
Validation loss: 1.8033884571444603

Epoch: 6| Step: 6
Training loss: 1.7642221450805664
Validation loss: 1.8114049947389992

Epoch: 6| Step: 7
Training loss: 1.7977890968322754
Validation loss: 1.8514233814772738

Epoch: 6| Step: 8
Training loss: 1.332634449005127
Validation loss: 1.7996334157964236

Epoch: 6| Step: 9
Training loss: 1.5129088163375854
Validation loss: 1.7987095950752177

Epoch: 6| Step: 10
Training loss: 1.0613059997558594
Validation loss: 1.8591507160535423

Epoch: 6| Step: 11
Training loss: 1.5657105445861816
Validation loss: 1.8493637564361736

Epoch: 6| Step: 12
Training loss: 1.4637799263000488
Validation loss: 1.8532309224528651

Epoch: 6| Step: 13
Training loss: 1.4714360237121582
Validation loss: 1.8383894017947617

Epoch: 260| Step: 0
Training loss: 1.7698808908462524
Validation loss: 1.8365423064078055

Epoch: 6| Step: 1
Training loss: 2.0913138389587402
Validation loss: 1.8887938581487185

Epoch: 6| Step: 2
Training loss: 1.597409725189209
Validation loss: 1.8518760819588937

Epoch: 6| Step: 3
Training loss: 1.1289576292037964
Validation loss: 1.8226179538234588

Epoch: 6| Step: 4
Training loss: 1.8833134174346924
Validation loss: 1.8614984840475104

Epoch: 6| Step: 5
Training loss: 1.2380446195602417
Validation loss: 1.8119708568819108

Epoch: 6| Step: 6
Training loss: 1.3807333707809448
Validation loss: 1.8256298752241238

Epoch: 6| Step: 7
Training loss: 1.6299054622650146
Validation loss: 1.8154844827549432

Epoch: 6| Step: 8
Training loss: 1.5923343896865845
Validation loss: 1.8009415454761957

Epoch: 6| Step: 9
Training loss: 1.229263186454773
Validation loss: 1.8306335197981967

Epoch: 6| Step: 10
Training loss: 1.4680871963500977
Validation loss: 1.8347455724593131

Epoch: 6| Step: 11
Training loss: 1.6177055835723877
Validation loss: 1.8567080343923261

Epoch: 6| Step: 12
Training loss: 1.3700157403945923
Validation loss: 1.849530275150012

Epoch: 6| Step: 13
Training loss: 1.9752788543701172
Validation loss: 1.816376677123449

Epoch: 261| Step: 0
Training loss: 1.255708932876587
Validation loss: 1.8325840375756706

Epoch: 6| Step: 1
Training loss: 1.3680280447006226
Validation loss: 1.8461173529266028

Epoch: 6| Step: 2
Training loss: 1.1413296461105347
Validation loss: 1.8321253586840887

Epoch: 6| Step: 3
Training loss: 2.1053457260131836
Validation loss: 1.864967333373203

Epoch: 6| Step: 4
Training loss: 1.7589088678359985
Validation loss: 1.8326459879516273

Epoch: 6| Step: 5
Training loss: 1.8664783239364624
Validation loss: 1.8409377733866374

Epoch: 6| Step: 6
Training loss: 1.5230141878128052
Validation loss: 1.8792955785669305

Epoch: 6| Step: 7
Training loss: 1.5773773193359375
Validation loss: 1.8741750947890743

Epoch: 6| Step: 8
Training loss: 1.3159539699554443
Validation loss: 1.8659537774260326

Epoch: 6| Step: 9
Training loss: 1.8852118253707886
Validation loss: 1.8454846335995583

Epoch: 6| Step: 10
Training loss: 2.0544509887695312
Validation loss: 1.8432530792810584

Epoch: 6| Step: 11
Training loss: 1.4530704021453857
Validation loss: 1.857621705660256

Epoch: 6| Step: 12
Training loss: 0.8094759583473206
Validation loss: 1.8617789181329871

Epoch: 6| Step: 13
Training loss: 2.0331318378448486
Validation loss: 1.831765833721366

Epoch: 262| Step: 0
Training loss: 1.2886757850646973
Validation loss: 1.8249176189463625

Epoch: 6| Step: 1
Training loss: 0.9883827567100525
Validation loss: 1.793340841929118

Epoch: 6| Step: 2
Training loss: 1.5929919481277466
Validation loss: 1.8335509197686308

Epoch: 6| Step: 3
Training loss: 1.432875394821167
Validation loss: 1.8124048543232743

Epoch: 6| Step: 4
Training loss: 1.8460458517074585
Validation loss: 1.8274306058883667

Epoch: 6| Step: 5
Training loss: 1.8059656620025635
Validation loss: 1.8248190559366697

Epoch: 6| Step: 6
Training loss: 1.8532096147537231
Validation loss: 1.841362391748736

Epoch: 6| Step: 7
Training loss: 1.4358571767807007
Validation loss: 1.8432002272657169

Epoch: 6| Step: 8
Training loss: 1.7093483209609985
Validation loss: 1.8306500578439364

Epoch: 6| Step: 9
Training loss: 1.855544924736023
Validation loss: 1.8074354638335526

Epoch: 6| Step: 10
Training loss: 1.386765956878662
Validation loss: 1.8413103421529133

Epoch: 6| Step: 11
Training loss: 1.9880619049072266
Validation loss: 1.8274426985812444

Epoch: 6| Step: 12
Training loss: 1.117941975593567
Validation loss: 1.8313032888597058

Epoch: 6| Step: 13
Training loss: 1.2775171995162964
Validation loss: 1.8584529789545203

Epoch: 263| Step: 0
Training loss: 1.328230619430542
Validation loss: 1.80207392092674

Epoch: 6| Step: 1
Training loss: 1.7030668258666992
Validation loss: 1.8466351211711924

Epoch: 6| Step: 2
Training loss: 1.7602193355560303
Validation loss: 1.850141389395601

Epoch: 6| Step: 3
Training loss: 1.5317925214767456
Validation loss: 1.8416607956732474

Epoch: 6| Step: 4
Training loss: 1.8261549472808838
Validation loss: 1.8341319561004639

Epoch: 6| Step: 5
Training loss: 1.522087574005127
Validation loss: 1.8495584585333382

Epoch: 6| Step: 6
Training loss: 1.6707570552825928
Validation loss: 1.8326935140035485

Epoch: 6| Step: 7
Training loss: 1.447735071182251
Validation loss: 1.8431302103945004

Epoch: 6| Step: 8
Training loss: 1.560502290725708
Validation loss: 1.848273838720014

Epoch: 6| Step: 9
Training loss: 1.2345836162567139
Validation loss: 1.850377317397825

Epoch: 6| Step: 10
Training loss: 2.13942813873291
Validation loss: 1.8433226039332729

Epoch: 6| Step: 11
Training loss: 1.18377685546875
Validation loss: 1.8052805392972884

Epoch: 6| Step: 12
Training loss: 1.5384023189544678
Validation loss: 1.82411450980812

Epoch: 6| Step: 13
Training loss: 1.9962210655212402
Validation loss: 1.8372142135456044

Epoch: 264| Step: 0
Training loss: 1.3556218147277832
Validation loss: 1.8405492421119445

Epoch: 6| Step: 1
Training loss: 1.470333218574524
Validation loss: 1.7694277917185137

Epoch: 6| Step: 2
Training loss: 1.9127154350280762
Validation loss: 1.8274926613735896

Epoch: 6| Step: 3
Training loss: 1.3475162982940674
Validation loss: 1.8386667043932023

Epoch: 6| Step: 4
Training loss: 1.0957396030426025
Validation loss: 1.8624426869935886

Epoch: 6| Step: 5
Training loss: 1.7219996452331543
Validation loss: 1.868787601429929

Epoch: 6| Step: 6
Training loss: 1.7975821495056152
Validation loss: 1.8358722040730138

Epoch: 6| Step: 7
Training loss: 1.8818421363830566
Validation loss: 1.8507147194236837

Epoch: 6| Step: 8
Training loss: 1.84388267993927
Validation loss: 1.8137420377423685

Epoch: 6| Step: 9
Training loss: 1.762251377105713
Validation loss: 1.7982259129965177

Epoch: 6| Step: 10
Training loss: 1.7721349000930786
Validation loss: 1.8300918994411346

Epoch: 6| Step: 11
Training loss: 1.2515074014663696
Validation loss: 1.8118173845352665

Epoch: 6| Step: 12
Training loss: 1.1279215812683105
Validation loss: 1.8429542869649909

Epoch: 6| Step: 13
Training loss: 1.1029211282730103
Validation loss: 1.8103965495222358

Epoch: 265| Step: 0
Training loss: 1.1285076141357422
Validation loss: 1.809403496403848

Epoch: 6| Step: 1
Training loss: 1.1200774908065796
Validation loss: 1.8156116540713976

Epoch: 6| Step: 2
Training loss: 1.3782894611358643
Validation loss: 1.8452056812983688

Epoch: 6| Step: 3
Training loss: 2.1650073528289795
Validation loss: 1.8048122582897064

Epoch: 6| Step: 4
Training loss: 1.46341872215271
Validation loss: 1.8463628433083976

Epoch: 6| Step: 5
Training loss: 1.6248252391815186
Validation loss: 1.8292775179750176

Epoch: 6| Step: 6
Training loss: 1.483163595199585
Validation loss: 1.783932553824558

Epoch: 6| Step: 7
Training loss: 1.4771010875701904
Validation loss: 1.815094929869457

Epoch: 6| Step: 8
Training loss: 2.101231813430786
Validation loss: 1.8031180866302983

Epoch: 6| Step: 9
Training loss: 1.0134496688842773
Validation loss: 1.834464282117864

Epoch: 6| Step: 10
Training loss: 1.48447847366333
Validation loss: 1.815208706804501

Epoch: 6| Step: 11
Training loss: 1.651810646057129
Validation loss: 1.7990750394841677

Epoch: 6| Step: 12
Training loss: 1.5498981475830078
Validation loss: 1.8460005867865779

Epoch: 6| Step: 13
Training loss: 2.8348166942596436
Validation loss: 1.8535892527590516

Epoch: 266| Step: 0
Training loss: 1.1738715171813965
Validation loss: 1.7889111670114661

Epoch: 6| Step: 1
Training loss: 2.077709674835205
Validation loss: 1.8323924836292063

Epoch: 6| Step: 2
Training loss: 2.056453227996826
Validation loss: 1.8027836327911706

Epoch: 6| Step: 3
Training loss: 0.7904853820800781
Validation loss: 1.8801679380478398

Epoch: 6| Step: 4
Training loss: 1.4196240901947021
Validation loss: 1.8767461520369335

Epoch: 6| Step: 5
Training loss: 1.5818289518356323
Validation loss: 1.8435996322221653

Epoch: 6| Step: 6
Training loss: 1.5515241622924805
Validation loss: 1.8595973048158871

Epoch: 6| Step: 7
Training loss: 1.5169272422790527
Validation loss: 1.839121336578041

Epoch: 6| Step: 8
Training loss: 1.4237792491912842
Validation loss: 1.8348541131583593

Epoch: 6| Step: 9
Training loss: 1.644822597503662
Validation loss: 1.8555691165308799

Epoch: 6| Step: 10
Training loss: 1.6928322315216064
Validation loss: 1.8901640343409714

Epoch: 6| Step: 11
Training loss: 1.8248687982559204
Validation loss: 1.838471758750177

Epoch: 6| Step: 12
Training loss: 1.5520089864730835
Validation loss: 1.8145071357809088

Epoch: 6| Step: 13
Training loss: 0.6997250318527222
Validation loss: 1.8295189270409205

Epoch: 267| Step: 0
Training loss: 1.8579537868499756
Validation loss: 1.7996539326124295

Epoch: 6| Step: 1
Training loss: 0.9391955137252808
Validation loss: 1.8180342464036838

Epoch: 6| Step: 2
Training loss: 1.6269309520721436
Validation loss: 1.7555127848861038

Epoch: 6| Step: 3
Training loss: 0.8761661648750305
Validation loss: 1.8067658562814035

Epoch: 6| Step: 4
Training loss: 1.1394469738006592
Validation loss: 1.8326785205512919

Epoch: 6| Step: 5
Training loss: 1.6170859336853027
Validation loss: 1.785754314032934

Epoch: 6| Step: 6
Training loss: 1.7834351062774658
Validation loss: 1.8164785549204836

Epoch: 6| Step: 7
Training loss: 1.9477866888046265
Validation loss: 1.8274269206549532

Epoch: 6| Step: 8
Training loss: 1.557075023651123
Validation loss: 1.8102443166958389

Epoch: 6| Step: 9
Training loss: 1.7219630479812622
Validation loss: 1.7901734344420894

Epoch: 6| Step: 10
Training loss: 1.9850432872772217
Validation loss: 1.8050520753347745

Epoch: 6| Step: 11
Training loss: 1.625042200088501
Validation loss: 1.8234150691698956

Epoch: 6| Step: 12
Training loss: 0.9963831901550293
Validation loss: 1.808648440145677

Epoch: 6| Step: 13
Training loss: 1.6933197975158691
Validation loss: 1.8763449063865087

Epoch: 268| Step: 0
Training loss: 1.4309453964233398
Validation loss: 1.8281909265825826

Epoch: 6| Step: 1
Training loss: 1.185442566871643
Validation loss: 1.8420238251327186

Epoch: 6| Step: 2
Training loss: 1.2397851943969727
Validation loss: 1.8611349674963182

Epoch: 6| Step: 3
Training loss: 1.645383358001709
Validation loss: 1.858179764081073

Epoch: 6| Step: 4
Training loss: 1.2652380466461182
Validation loss: 1.8499050967154964

Epoch: 6| Step: 5
Training loss: 1.80497407913208
Validation loss: 1.8215008153710315

Epoch: 6| Step: 6
Training loss: 1.3715698719024658
Validation loss: 1.840001331862583

Epoch: 6| Step: 7
Training loss: 1.4538403749465942
Validation loss: 1.8362462956418273

Epoch: 6| Step: 8
Training loss: 1.19761323928833
Validation loss: 1.8041753845830117

Epoch: 6| Step: 9
Training loss: 1.53110671043396
Validation loss: 1.800604933692563

Epoch: 6| Step: 10
Training loss: 2.228517532348633
Validation loss: 1.78832071955486

Epoch: 6| Step: 11
Training loss: 1.7551020383834839
Validation loss: 1.8377463561232372

Epoch: 6| Step: 12
Training loss: 1.206444263458252
Validation loss: 1.8305113443764307

Epoch: 6| Step: 13
Training loss: 1.9295496940612793
Validation loss: 1.807065648417319

Epoch: 269| Step: 0
Training loss: 1.4854917526245117
Validation loss: 1.810223581970379

Epoch: 6| Step: 1
Training loss: 1.9934570789337158
Validation loss: 1.7897969330510786

Epoch: 6| Step: 2
Training loss: 1.2472031116485596
Validation loss: 1.827018812138547

Epoch: 6| Step: 3
Training loss: 0.9452635049819946
Validation loss: 1.8428373900792931

Epoch: 6| Step: 4
Training loss: 1.650242805480957
Validation loss: 1.8213535021710139

Epoch: 6| Step: 5
Training loss: 1.2265456914901733
Validation loss: 1.8486979853722356

Epoch: 6| Step: 6
Training loss: 1.3528811931610107
Validation loss: 1.8120392086685344

Epoch: 6| Step: 7
Training loss: 1.3177636861801147
Validation loss: 1.8530953161178096

Epoch: 6| Step: 8
Training loss: 1.5457375049591064
Validation loss: 1.8336044152577717

Epoch: 6| Step: 9
Training loss: 2.3824219703674316
Validation loss: 1.813333490843414

Epoch: 6| Step: 10
Training loss: 1.2224180698394775
Validation loss: 1.8244605910393499

Epoch: 6| Step: 11
Training loss: 1.2664003372192383
Validation loss: 1.8299005980132728

Epoch: 6| Step: 12
Training loss: 1.6725963354110718
Validation loss: 1.823106719601539

Epoch: 6| Step: 13
Training loss: 2.2103803157806396
Validation loss: 1.8476381442880119

Epoch: 270| Step: 0
Training loss: 1.540617823600769
Validation loss: 1.8105658100497337

Epoch: 6| Step: 1
Training loss: 0.8574991226196289
Validation loss: 1.8401176826928252

Epoch: 6| Step: 2
Training loss: 1.2980339527130127
Validation loss: 1.8230452460627402

Epoch: 6| Step: 3
Training loss: 1.0432219505310059
Validation loss: 1.8514697359454246

Epoch: 6| Step: 4
Training loss: 2.000495672225952
Validation loss: 1.8202615143150411

Epoch: 6| Step: 5
Training loss: 1.564371943473816
Validation loss: 1.8640650344151322

Epoch: 6| Step: 6
Training loss: 1.9905526638031006
Validation loss: 1.780779609116175

Epoch: 6| Step: 7
Training loss: 1.555901050567627
Validation loss: 1.8191746088766283

Epoch: 6| Step: 8
Training loss: 1.7009124755859375
Validation loss: 1.8257727046166696

Epoch: 6| Step: 9
Training loss: 1.6752071380615234
Validation loss: 1.819181626842868

Epoch: 6| Step: 10
Training loss: 1.4718741178512573
Validation loss: 1.8404049616987987

Epoch: 6| Step: 11
Training loss: 1.3866571187973022
Validation loss: 1.799627984723737

Epoch: 6| Step: 12
Training loss: 1.646821141242981
Validation loss: 1.88869006915759

Epoch: 6| Step: 13
Training loss: 2.162552833557129
Validation loss: 1.8126961569632254

Epoch: 271| Step: 0
Training loss: 1.754347324371338
Validation loss: 1.8707732333931872

Epoch: 6| Step: 1
Training loss: 1.7401032447814941
Validation loss: 1.8127684003563338

Epoch: 6| Step: 2
Training loss: 1.7607953548431396
Validation loss: 1.8362092125800349

Epoch: 6| Step: 3
Training loss: 1.4752014875411987
Validation loss: 1.826768336757537

Epoch: 6| Step: 4
Training loss: 1.6937721967697144
Validation loss: 1.8109654829066286

Epoch: 6| Step: 5
Training loss: 1.1635496616363525
Validation loss: 1.8373499801081996

Epoch: 6| Step: 6
Training loss: 1.8412694931030273
Validation loss: 1.8259187488145725

Epoch: 6| Step: 7
Training loss: 1.8076930046081543
Validation loss: 1.7708094043116416

Epoch: 6| Step: 8
Training loss: 1.2283159494400024
Validation loss: 1.7865928872939079

Epoch: 6| Step: 9
Training loss: 1.430954098701477
Validation loss: 1.7821100629786009

Epoch: 6| Step: 10
Training loss: 1.9851038455963135
Validation loss: 1.7984685654281287

Epoch: 6| Step: 11
Training loss: 1.0987752676010132
Validation loss: 1.7991658833719069

Epoch: 6| Step: 12
Training loss: 1.2638256549835205
Validation loss: 1.8288471647488174

Epoch: 6| Step: 13
Training loss: 0.8009939193725586
Validation loss: 1.846434691900848

Epoch: 272| Step: 0
Training loss: 1.2635414600372314
Validation loss: 1.7813624361509919

Epoch: 6| Step: 1
Training loss: 2.001943588256836
Validation loss: 1.8169860480934061

Epoch: 6| Step: 2
Training loss: 1.9276007413864136
Validation loss: 1.8277499163022606

Epoch: 6| Step: 3
Training loss: 1.347829818725586
Validation loss: 1.8754879813040457

Epoch: 6| Step: 4
Training loss: 1.7221081256866455
Validation loss: 1.8638669278032036

Epoch: 6| Step: 5
Training loss: 1.2965887784957886
Validation loss: 1.8749601776881883

Epoch: 6| Step: 6
Training loss: 1.5409661531448364
Validation loss: 1.8478400963608936

Epoch: 6| Step: 7
Training loss: 1.3365519046783447
Validation loss: 1.827336360049504

Epoch: 6| Step: 8
Training loss: 1.0041799545288086
Validation loss: 1.8127612862535702

Epoch: 6| Step: 9
Training loss: 2.305830478668213
Validation loss: 1.8616080181573027

Epoch: 6| Step: 10
Training loss: 1.2998981475830078
Validation loss: 1.806907138516826

Epoch: 6| Step: 11
Training loss: 1.2836010456085205
Validation loss: 1.8475688977908062

Epoch: 6| Step: 12
Training loss: 1.7516915798187256
Validation loss: 1.8665624908221665

Epoch: 6| Step: 13
Training loss: 1.3762812614440918
Validation loss: 1.8285268122150051

Epoch: 273| Step: 0
Training loss: 1.42058265209198
Validation loss: 1.759098458033736

Epoch: 6| Step: 1
Training loss: 2.584746837615967
Validation loss: 1.7977534737638248

Epoch: 6| Step: 2
Training loss: 1.3451060056686401
Validation loss: 1.7918580642310522

Epoch: 6| Step: 3
Training loss: 1.1067891120910645
Validation loss: 1.7699771517066545

Epoch: 6| Step: 4
Training loss: 1.5674514770507812
Validation loss: 1.8337446092277445

Epoch: 6| Step: 5
Training loss: 1.2935506105422974
Validation loss: 1.8042541998688892

Epoch: 6| Step: 6
Training loss: 1.236146330833435
Validation loss: 1.8020974307931878

Epoch: 6| Step: 7
Training loss: 1.464174747467041
Validation loss: 1.806087811787923

Epoch: 6| Step: 8
Training loss: 1.6562235355377197
Validation loss: 1.7974652449289958

Epoch: 6| Step: 9
Training loss: 1.1361582279205322
Validation loss: 1.7446629360157957

Epoch: 6| Step: 10
Training loss: 1.994504451751709
Validation loss: 1.8573514735826882

Epoch: 6| Step: 11
Training loss: 1.4122021198272705
Validation loss: 1.8449297271749026

Epoch: 6| Step: 12
Training loss: 1.5082508325576782
Validation loss: 1.855131294137688

Epoch: 6| Step: 13
Training loss: 1.7265413999557495
Validation loss: 1.8452289527462375

Epoch: 274| Step: 0
Training loss: 1.6432101726531982
Validation loss: 1.8714574511333177

Epoch: 6| Step: 1
Training loss: 1.5003387928009033
Validation loss: 1.854200973305651

Epoch: 6| Step: 2
Training loss: 1.6667649745941162
Validation loss: 1.8713691837044173

Epoch: 6| Step: 3
Training loss: 1.9159801006317139
Validation loss: 1.8387223302677114

Epoch: 6| Step: 4
Training loss: 1.5114028453826904
Validation loss: 1.872109833584037

Epoch: 6| Step: 5
Training loss: 2.0788564682006836
Validation loss: 1.8565582203608688

Epoch: 6| Step: 6
Training loss: 1.3030277490615845
Validation loss: 1.851502409545324

Epoch: 6| Step: 7
Training loss: 1.4406200647354126
Validation loss: 1.8335195202981271

Epoch: 6| Step: 8
Training loss: 1.2856183052062988
Validation loss: 1.8347119977397304

Epoch: 6| Step: 9
Training loss: 1.255752682685852
Validation loss: 1.8683182629205848

Epoch: 6| Step: 10
Training loss: 1.6303108930587769
Validation loss: 1.8415707772777927

Epoch: 6| Step: 11
Training loss: 1.1053717136383057
Validation loss: 1.8442092992926156

Epoch: 6| Step: 12
Training loss: 1.8810518980026245
Validation loss: 1.8227939272439608

Epoch: 6| Step: 13
Training loss: 1.0902365446090698
Validation loss: 1.8437605314357306

Epoch: 275| Step: 0
Training loss: 1.3554967641830444
Validation loss: 1.8297266037233415

Epoch: 6| Step: 1
Training loss: 1.199296474456787
Validation loss: 1.8537525797402987

Epoch: 6| Step: 2
Training loss: 1.3409101963043213
Validation loss: 1.8550118297658942

Epoch: 6| Step: 3
Training loss: 1.1915289163589478
Validation loss: 1.8263857813291653

Epoch: 6| Step: 4
Training loss: 0.8443046808242798
Validation loss: 1.841272469489805

Epoch: 6| Step: 5
Training loss: 1.7600144147872925
Validation loss: 1.8345359230554232

Epoch: 6| Step: 6
Training loss: 1.6853917837142944
Validation loss: 1.847075657177997

Epoch: 6| Step: 7
Training loss: 1.4331068992614746
Validation loss: 1.8396484364745438

Epoch: 6| Step: 8
Training loss: 1.8924086093902588
Validation loss: 1.8400128964454896

Epoch: 6| Step: 9
Training loss: 1.6373035907745361
Validation loss: 1.810649448825467

Epoch: 6| Step: 10
Training loss: 1.602876901626587
Validation loss: 1.8196530521556895

Epoch: 6| Step: 11
Training loss: 1.2850635051727295
Validation loss: 1.8164557128824212

Epoch: 6| Step: 12
Training loss: 1.9911988973617554
Validation loss: 1.8233264210403606

Epoch: 6| Step: 13
Training loss: 2.209129571914673
Validation loss: 1.8521011593521282

Epoch: 276| Step: 0
Training loss: 1.915989875793457
Validation loss: 1.8241483050007974

Epoch: 6| Step: 1
Training loss: 1.8352165222167969
Validation loss: 1.8353597528191024

Epoch: 6| Step: 2
Training loss: 1.3438212871551514
Validation loss: 1.7923281038961103

Epoch: 6| Step: 3
Training loss: 2.339479446411133
Validation loss: 1.789228395749164

Epoch: 6| Step: 4
Training loss: 1.453768014907837
Validation loss: 1.8186431431001233

Epoch: 6| Step: 5
Training loss: 2.221740245819092
Validation loss: 1.8015037249493342

Epoch: 6| Step: 6
Training loss: 0.7407065629959106
Validation loss: 1.824666497527912

Epoch: 6| Step: 7
Training loss: 1.4958820343017578
Validation loss: 1.7878414084834438

Epoch: 6| Step: 8
Training loss: 1.6527827978134155
Validation loss: 1.8205947658067108

Epoch: 6| Step: 9
Training loss: 0.6547228693962097
Validation loss: 1.8062312936270108

Epoch: 6| Step: 10
Training loss: 0.7052367925643921
Validation loss: 1.7852454211122246

Epoch: 6| Step: 11
Training loss: 1.5879615545272827
Validation loss: 1.7877633725443194

Epoch: 6| Step: 12
Training loss: 1.5691994428634644
Validation loss: 1.7581865505505634

Epoch: 6| Step: 13
Training loss: 1.3945753574371338
Validation loss: 1.8159385394024592

Epoch: 277| Step: 0
Training loss: 1.993330955505371
Validation loss: 1.7864982402452858

Epoch: 6| Step: 1
Training loss: 1.7620331048965454
Validation loss: 1.7751591743961457

Epoch: 6| Step: 2
Training loss: 1.16732919216156
Validation loss: 1.8217528199636808

Epoch: 6| Step: 3
Training loss: 1.687200665473938
Validation loss: 1.8225183230574413

Epoch: 6| Step: 4
Training loss: 1.4265854358673096
Validation loss: 1.8082492197713544

Epoch: 6| Step: 5
Training loss: 1.3194200992584229
Validation loss: 1.8323708221476565

Epoch: 6| Step: 6
Training loss: 1.0672610998153687
Validation loss: 1.7709679757395098

Epoch: 6| Step: 7
Training loss: 1.8142799139022827
Validation loss: 1.827144850966751

Epoch: 6| Step: 8
Training loss: 2.0025699138641357
Validation loss: 1.8904864416327527

Epoch: 6| Step: 9
Training loss: 1.8927773237228394
Validation loss: 1.8049385316910282

Epoch: 6| Step: 10
Training loss: 0.8292261958122253
Validation loss: 1.7967264902207158

Epoch: 6| Step: 11
Training loss: 0.8221356868743896
Validation loss: 1.8376531370224491

Epoch: 6| Step: 12
Training loss: 1.8852436542510986
Validation loss: 1.7733362272221556

Epoch: 6| Step: 13
Training loss: 1.3133240938186646
Validation loss: 1.8311653060297812

Epoch: 278| Step: 0
Training loss: 1.4545389413833618
Validation loss: 1.8402814326747772

Epoch: 6| Step: 1
Training loss: 1.6727944612503052
Validation loss: 1.8064160500803301

Epoch: 6| Step: 2
Training loss: 0.9347772598266602
Validation loss: 1.780892959205053

Epoch: 6| Step: 3
Training loss: 1.6386046409606934
Validation loss: 1.7912189806661298

Epoch: 6| Step: 4
Training loss: 1.1488263607025146
Validation loss: 1.7708932776604929

Epoch: 6| Step: 5
Training loss: 1.2300715446472168
Validation loss: 1.7948662516891316

Epoch: 6| Step: 6
Training loss: 1.3743253946304321
Validation loss: 1.788513882185823

Epoch: 6| Step: 7
Training loss: 1.4133474826812744
Validation loss: 1.7941931986039685

Epoch: 6| Step: 8
Training loss: 1.2578617334365845
Validation loss: 1.833095209572905

Epoch: 6| Step: 9
Training loss: 2.2545268535614014
Validation loss: 1.8372382810038905

Epoch: 6| Step: 10
Training loss: 1.790595531463623
Validation loss: 1.7900206235147291

Epoch: 6| Step: 11
Training loss: 1.3526344299316406
Validation loss: 1.808001563113223

Epoch: 6| Step: 12
Training loss: 2.0566842555999756
Validation loss: 1.8338811653916554

Epoch: 6| Step: 13
Training loss: 1.3575875759124756
Validation loss: 1.8172233976343626

Epoch: 279| Step: 0
Training loss: 1.4052032232284546
Validation loss: 1.7951019605000813

Epoch: 6| Step: 1
Training loss: 1.2780237197875977
Validation loss: 1.798225713032548

Epoch: 6| Step: 2
Training loss: 1.3578202724456787
Validation loss: 1.8136413584473312

Epoch: 6| Step: 3
Training loss: 1.5182385444641113
Validation loss: 1.80813233506295

Epoch: 6| Step: 4
Training loss: 1.523640751838684
Validation loss: 1.809990308618033

Epoch: 6| Step: 5
Training loss: 2.1581239700317383
Validation loss: 1.8930306332085722

Epoch: 6| Step: 6
Training loss: 0.927797794342041
Validation loss: 1.8522584835688274

Epoch: 6| Step: 7
Training loss: 1.3808259963989258
Validation loss: 1.8695016125197053

Epoch: 6| Step: 8
Training loss: 1.6301734447479248
Validation loss: 1.8639326915946057

Epoch: 6| Step: 9
Training loss: 1.633237361907959
Validation loss: 1.8130516377828454

Epoch: 6| Step: 10
Training loss: 1.615830659866333
Validation loss: 1.847568142798639

Epoch: 6| Step: 11
Training loss: 1.850468635559082
Validation loss: 1.8047108374616152

Epoch: 6| Step: 12
Training loss: 1.2753925323486328
Validation loss: 1.8195322457180227

Epoch: 6| Step: 13
Training loss: 1.31248939037323
Validation loss: 1.807166455894388

Epoch: 280| Step: 0
Training loss: 1.4941933155059814
Validation loss: 1.8530109851591048

Epoch: 6| Step: 1
Training loss: 1.4159166812896729
Validation loss: 1.8327377227044874

Epoch: 6| Step: 2
Training loss: 1.4144436120986938
Validation loss: 1.8390968563736125

Epoch: 6| Step: 3
Training loss: 1.3009684085845947
Validation loss: 1.784865963202651

Epoch: 6| Step: 4
Training loss: 1.0451453924179077
Validation loss: 1.7880093487360145

Epoch: 6| Step: 5
Training loss: 1.3467366695404053
Validation loss: 1.791217250208701

Epoch: 6| Step: 6
Training loss: 1.2716634273529053
Validation loss: 1.815986128263576

Epoch: 6| Step: 7
Training loss: 1.1274657249450684
Validation loss: 1.792690283508711

Epoch: 6| Step: 8
Training loss: 1.5279790163040161
Validation loss: 1.7990533600571335

Epoch: 6| Step: 9
Training loss: 1.8704988956451416
Validation loss: 1.8169474832473262

Epoch: 6| Step: 10
Training loss: 1.6194067001342773
Validation loss: 1.751171874743636

Epoch: 6| Step: 11
Training loss: 2.314634084701538
Validation loss: 1.776876231675507

Epoch: 6| Step: 12
Training loss: 1.9748423099517822
Validation loss: 1.7715506758741153

Epoch: 6| Step: 13
Training loss: 1.3076540231704712
Validation loss: 1.8073605286177767

Epoch: 281| Step: 0
Training loss: 0.9807842969894409
Validation loss: 1.7872416216840026

Epoch: 6| Step: 1
Training loss: 1.7905956506729126
Validation loss: 1.788759187985492

Epoch: 6| Step: 2
Training loss: 1.3800430297851562
Validation loss: 1.843984708991102

Epoch: 6| Step: 3
Training loss: 1.7704206705093384
Validation loss: 1.8431020500839397

Epoch: 6| Step: 4
Training loss: 1.3384120464324951
Validation loss: 1.8096549357137373

Epoch: 6| Step: 5
Training loss: 1.8797335624694824
Validation loss: 1.8205797620998916

Epoch: 6| Step: 6
Training loss: 1.7912867069244385
Validation loss: 1.8043078991674608

Epoch: 6| Step: 7
Training loss: 1.2826666831970215
Validation loss: 1.8358572401026243

Epoch: 6| Step: 8
Training loss: 1.0811439752578735
Validation loss: 1.8135453898419616

Epoch: 6| Step: 9
Training loss: 1.496701955795288
Validation loss: 1.8411931043030114

Epoch: 6| Step: 10
Training loss: 1.330473780632019
Validation loss: 1.8346599378893453

Epoch: 6| Step: 11
Training loss: 1.5977193117141724
Validation loss: 1.8080518271333428

Epoch: 6| Step: 12
Training loss: 2.025163173675537
Validation loss: 1.775590758169851

Epoch: 6| Step: 13
Training loss: 1.3691916465759277
Validation loss: 1.8496075907061178

Epoch: 282| Step: 0
Training loss: 2.024979829788208
Validation loss: 1.8036778844812864

Epoch: 6| Step: 1
Training loss: 1.6552846431732178
Validation loss: 1.822833425255232

Epoch: 6| Step: 2
Training loss: 1.6625581979751587
Validation loss: 1.80031870642016

Epoch: 6| Step: 3
Training loss: 1.157526969909668
Validation loss: 1.7871909359449982

Epoch: 6| Step: 4
Training loss: 1.0807032585144043
Validation loss: 1.7839543434881395

Epoch: 6| Step: 5
Training loss: 2.187401294708252
Validation loss: 1.8158766684993621

Epoch: 6| Step: 6
Training loss: 1.3223248720169067
Validation loss: 1.8030429565778343

Epoch: 6| Step: 7
Training loss: 1.106863260269165
Validation loss: 1.822897381679986

Epoch: 6| Step: 8
Training loss: 0.9322981834411621
Validation loss: 1.816919974101487

Epoch: 6| Step: 9
Training loss: 1.3889161348342896
Validation loss: 1.8261134662935812

Epoch: 6| Step: 10
Training loss: 1.7944215536117554
Validation loss: 1.8167571970211562

Epoch: 6| Step: 11
Training loss: 2.1567165851593018
Validation loss: 1.7951862965860674

Epoch: 6| Step: 12
Training loss: 1.432767629623413
Validation loss: 1.7928639701617661

Epoch: 6| Step: 13
Training loss: 1.3347265720367432
Validation loss: 1.7914166168500019

Epoch: 283| Step: 0
Training loss: 1.637575387954712
Validation loss: 1.7930618409187562

Epoch: 6| Step: 1
Training loss: 1.0968618392944336
Validation loss: 1.817395043629472

Epoch: 6| Step: 2
Training loss: 1.543625831604004
Validation loss: 1.8574380349087458

Epoch: 6| Step: 3
Training loss: 1.0169734954833984
Validation loss: 1.8240026479126306

Epoch: 6| Step: 4
Training loss: 1.5587716102600098
Validation loss: 1.818827139433994

Epoch: 6| Step: 5
Training loss: 1.2680461406707764
Validation loss: 1.845352461261134

Epoch: 6| Step: 6
Training loss: 0.9691288471221924
Validation loss: 1.8644247106326524

Epoch: 6| Step: 7
Training loss: 1.3236329555511475
Validation loss: 1.8270668060548845

Epoch: 6| Step: 8
Training loss: 1.3846163749694824
Validation loss: 1.8356861619539158

Epoch: 6| Step: 9
Training loss: 2.036970376968384
Validation loss: 1.8229099665918658

Epoch: 6| Step: 10
Training loss: 1.4600815773010254
Validation loss: 1.7838736657173402

Epoch: 6| Step: 11
Training loss: 1.8234003782272339
Validation loss: 1.846858593725389

Epoch: 6| Step: 12
Training loss: 2.1215481758117676
Validation loss: 1.8271184018863145

Epoch: 6| Step: 13
Training loss: 1.2247977256774902
Validation loss: 1.8736428137748473

Epoch: 284| Step: 0
Training loss: 1.6842268705368042
Validation loss: 1.8163116696060344

Epoch: 6| Step: 1
Training loss: 1.9257683753967285
Validation loss: 1.8018776524451472

Epoch: 6| Step: 2
Training loss: 1.0435810089111328
Validation loss: 1.8670228271074192

Epoch: 6| Step: 3
Training loss: 1.2081732749938965
Validation loss: 1.8379044109775173

Epoch: 6| Step: 4
Training loss: 1.7068901062011719
Validation loss: 1.8264594795883342

Epoch: 6| Step: 5
Training loss: 1.061161756515503
Validation loss: 1.7885657484813402

Epoch: 6| Step: 6
Training loss: 1.5867199897766113
Validation loss: 1.8369530727786403

Epoch: 6| Step: 7
Training loss: 1.4770153760910034
Validation loss: 1.8255511406929261

Epoch: 6| Step: 8
Training loss: 1.7770955562591553
Validation loss: 1.8316209623890538

Epoch: 6| Step: 9
Training loss: 1.8964415788650513
Validation loss: 1.788731550657621

Epoch: 6| Step: 10
Training loss: 1.9220178127288818
Validation loss: 1.8631716543628323

Epoch: 6| Step: 11
Training loss: 0.9868463277816772
Validation loss: 1.8163169366057201

Epoch: 6| Step: 12
Training loss: 1.027869701385498
Validation loss: 1.8181539709850023

Epoch: 6| Step: 13
Training loss: 1.8515167236328125
Validation loss: 1.799840811760195

Epoch: 285| Step: 0
Training loss: 1.7435890436172485
Validation loss: 1.7765052498027842

Epoch: 6| Step: 1
Training loss: 1.7321584224700928
Validation loss: 1.802689488216113

Epoch: 6| Step: 2
Training loss: 1.8896344900131226
Validation loss: 1.8024717800078853

Epoch: 6| Step: 3
Training loss: 1.4872238636016846
Validation loss: 1.8239016802080217

Epoch: 6| Step: 4
Training loss: 1.5982333421707153
Validation loss: 1.8299280533226587

Epoch: 6| Step: 5
Training loss: 1.1534830331802368
Validation loss: 1.793351896347538

Epoch: 6| Step: 6
Training loss: 1.0287649631500244
Validation loss: 1.8143500128099996

Epoch: 6| Step: 7
Training loss: 1.035560131072998
Validation loss: 1.798706881461605

Epoch: 6| Step: 8
Training loss: 1.3017053604125977
Validation loss: 1.818463074263706

Epoch: 6| Step: 9
Training loss: 1.1813262701034546
Validation loss: 1.8066791667733142

Epoch: 6| Step: 10
Training loss: 1.9067628383636475
Validation loss: 1.7815278037901847

Epoch: 6| Step: 11
Training loss: 1.495069980621338
Validation loss: 1.8510835709110383

Epoch: 6| Step: 12
Training loss: 1.2415307760238647
Validation loss: 1.8180686748155983

Epoch: 6| Step: 13
Training loss: 1.822852611541748
Validation loss: 1.832490986393344

Epoch: 286| Step: 0
Training loss: 1.137727975845337
Validation loss: 1.8185434879795197

Epoch: 6| Step: 1
Training loss: 0.8888127207756042
Validation loss: 1.8418338657707296

Epoch: 6| Step: 2
Training loss: 1.4435288906097412
Validation loss: 1.7849497731013964

Epoch: 6| Step: 3
Training loss: 1.5632246732711792
Validation loss: 1.8135977137473323

Epoch: 6| Step: 4
Training loss: 1.4548550844192505
Validation loss: 1.798939392130862

Epoch: 6| Step: 5
Training loss: 1.2389030456542969
Validation loss: 1.8346765336169992

Epoch: 6| Step: 6
Training loss: 1.0440819263458252
Validation loss: 1.8229164154298845

Epoch: 6| Step: 7
Training loss: 1.2714251279830933
Validation loss: 1.8267076015472412

Epoch: 6| Step: 8
Training loss: 1.7030291557312012
Validation loss: 1.8266065095060615

Epoch: 6| Step: 9
Training loss: 2.4577736854553223
Validation loss: 1.8371084249147804

Epoch: 6| Step: 10
Training loss: 1.1590847969055176
Validation loss: 1.8163202731840071

Epoch: 6| Step: 11
Training loss: 1.3020070791244507
Validation loss: 1.7811622773447344

Epoch: 6| Step: 12
Training loss: 1.8231792449951172
Validation loss: 1.814173775334512

Epoch: 6| Step: 13
Training loss: 2.208211660385132
Validation loss: 1.7855122473932081

Epoch: 287| Step: 0
Training loss: 1.1098119020462036
Validation loss: 1.8364929012072984

Epoch: 6| Step: 1
Training loss: 1.4105132818222046
Validation loss: 1.81627901651526

Epoch: 6| Step: 2
Training loss: 1.3685044050216675
Validation loss: 1.7560915639323573

Epoch: 6| Step: 3
Training loss: 1.757813811302185
Validation loss: 1.8168316297633673

Epoch: 6| Step: 4
Training loss: 1.7194703817367554
Validation loss: 1.825736245801372

Epoch: 6| Step: 5
Training loss: 1.6603838205337524
Validation loss: 1.8261242092296641

Epoch: 6| Step: 6
Training loss: 1.939223051071167
Validation loss: 1.8307537750531269

Epoch: 6| Step: 7
Training loss: 1.2390625476837158
Validation loss: 1.8000787458112162

Epoch: 6| Step: 8
Training loss: 1.449538230895996
Validation loss: 1.8190375117845432

Epoch: 6| Step: 9
Training loss: 0.7204894423484802
Validation loss: 1.8228924402626612

Epoch: 6| Step: 10
Training loss: 1.6683576107025146
Validation loss: 1.82086314693574

Epoch: 6| Step: 11
Training loss: 1.696009635925293
Validation loss: 1.8965011386461155

Epoch: 6| Step: 12
Training loss: 1.3978075981140137
Validation loss: 1.840409528824591

Epoch: 6| Step: 13
Training loss: 1.783119797706604
Validation loss: 1.8363827492601128

Epoch: 288| Step: 0
Training loss: 1.1839637756347656
Validation loss: 1.8414391984221756

Epoch: 6| Step: 1
Training loss: 1.6034448146820068
Validation loss: 1.8570801955397411

Epoch: 6| Step: 2
Training loss: 1.5426766872406006
Validation loss: 1.8017748337919994

Epoch: 6| Step: 3
Training loss: 1.1760027408599854
Validation loss: 1.8181670186340169

Epoch: 6| Step: 4
Training loss: 1.284772515296936
Validation loss: 1.8432129121595813

Epoch: 6| Step: 5
Training loss: 1.5464327335357666
Validation loss: 1.79218666912407

Epoch: 6| Step: 6
Training loss: 1.8181654214859009
Validation loss: 1.785289067094044

Epoch: 6| Step: 7
Training loss: 1.1940126419067383
Validation loss: 1.8380596060906687

Epoch: 6| Step: 8
Training loss: 1.675061583518982
Validation loss: 1.8304445307741883

Epoch: 6| Step: 9
Training loss: 1.2006596326828003
Validation loss: 1.792377684706001

Epoch: 6| Step: 10
Training loss: 1.2901713848114014
Validation loss: 1.8391305285115396

Epoch: 6| Step: 11
Training loss: 2.5190346240997314
Validation loss: 1.84705061809991

Epoch: 6| Step: 12
Training loss: 0.7147163152694702
Validation loss: 1.7904381918650802

Epoch: 6| Step: 13
Training loss: 1.4333604574203491
Validation loss: 1.813379572283837

Epoch: 289| Step: 0
Training loss: 1.6371773481369019
Validation loss: 1.7625832685860254

Epoch: 6| Step: 1
Training loss: 1.6268374919891357
Validation loss: 1.8251845990457842

Epoch: 6| Step: 2
Training loss: 1.4627361297607422
Validation loss: 1.860536035671029

Epoch: 6| Step: 3
Training loss: 1.27241051197052
Validation loss: 1.8439703064580117

Epoch: 6| Step: 4
Training loss: 1.695418119430542
Validation loss: 1.7560107105521745

Epoch: 6| Step: 5
Training loss: 1.0323891639709473
Validation loss: 1.8032634296724874

Epoch: 6| Step: 6
Training loss: 1.0072640180587769
Validation loss: 1.7906303457034531

Epoch: 6| Step: 7
Training loss: 1.7227814197540283
Validation loss: 1.8238816389473536

Epoch: 6| Step: 8
Training loss: 1.8485655784606934
Validation loss: 1.765257735406199

Epoch: 6| Step: 9
Training loss: 1.533767819404602
Validation loss: 1.808670877128519

Epoch: 6| Step: 10
Training loss: 1.2724579572677612
Validation loss: 1.78170729965292

Epoch: 6| Step: 11
Training loss: 1.170621395111084
Validation loss: 1.7849466710962274

Epoch: 6| Step: 12
Training loss: 1.7102718353271484
Validation loss: 1.8507212079981321

Epoch: 6| Step: 13
Training loss: 1.7749810218811035
Validation loss: 1.855023012366346

Epoch: 290| Step: 0
Training loss: 1.588040828704834
Validation loss: 1.8045129391454882

Epoch: 6| Step: 1
Training loss: 0.9605892896652222
Validation loss: 1.819434727391889

Epoch: 6| Step: 2
Training loss: 1.74957275390625
Validation loss: 1.8474265324172152

Epoch: 6| Step: 3
Training loss: 1.1810088157653809
Validation loss: 1.9034936530615694

Epoch: 6| Step: 4
Training loss: 1.1408889293670654
Validation loss: 1.818081650682675

Epoch: 6| Step: 5
Training loss: 0.9588186144828796
Validation loss: 1.8318603666879798

Epoch: 6| Step: 6
Training loss: 1.8516111373901367
Validation loss: 1.8163428665489278

Epoch: 6| Step: 7
Training loss: 1.9757146835327148
Validation loss: 1.8151866492404733

Epoch: 6| Step: 8
Training loss: 1.5863502025604248
Validation loss: 1.8194678047651887

Epoch: 6| Step: 9
Training loss: 1.5432312488555908
Validation loss: 1.8435952483966787

Epoch: 6| Step: 10
Training loss: 1.3325309753417969
Validation loss: 1.8394102255503337

Epoch: 6| Step: 11
Training loss: 2.470472812652588
Validation loss: 1.7889466708706272

Epoch: 6| Step: 12
Training loss: 1.3386573791503906
Validation loss: 1.8157196391013362

Epoch: 6| Step: 13
Training loss: 1.1198455095291138
Validation loss: 1.7776896107581355

Epoch: 291| Step: 0
Training loss: 1.3572087287902832
Validation loss: 1.7838233260698215

Epoch: 6| Step: 1
Training loss: 1.2492396831512451
Validation loss: 1.8303237243365216

Epoch: 6| Step: 2
Training loss: 1.9252283573150635
Validation loss: 1.8226524091535998

Epoch: 6| Step: 3
Training loss: 1.7174394130706787
Validation loss: 1.793448184126167

Epoch: 6| Step: 4
Training loss: 1.2627040147781372
Validation loss: 1.8533686143095776

Epoch: 6| Step: 5
Training loss: 1.305174469947815
Validation loss: 1.824792318446662

Epoch: 6| Step: 6
Training loss: 1.5273432731628418
Validation loss: 1.7875417099204114

Epoch: 6| Step: 7
Training loss: 1.3517041206359863
Validation loss: 1.801041119842119

Epoch: 6| Step: 8
Training loss: 1.0604050159454346
Validation loss: 1.8243698753336424

Epoch: 6| Step: 9
Training loss: 1.792136549949646
Validation loss: 1.8136737218467138

Epoch: 6| Step: 10
Training loss: 1.3184263706207275
Validation loss: 1.8104938140479467

Epoch: 6| Step: 11
Training loss: 1.7479984760284424
Validation loss: 1.8462939582845217

Epoch: 6| Step: 12
Training loss: 1.343855857849121
Validation loss: 1.8097898678113056

Epoch: 6| Step: 13
Training loss: 1.4114577770233154
Validation loss: 1.7990130160444526

Epoch: 292| Step: 0
Training loss: 1.0822392702102661
Validation loss: 1.8039385118792135

Epoch: 6| Step: 1
Training loss: 1.6793113946914673
Validation loss: 1.7993549070050638

Epoch: 6| Step: 2
Training loss: 1.4938983917236328
Validation loss: 1.8142306817475187

Epoch: 6| Step: 3
Training loss: 0.9292433857917786
Validation loss: 1.8227191035465529

Epoch: 6| Step: 4
Training loss: 1.3477503061294556
Validation loss: 1.820578436697683

Epoch: 6| Step: 5
Training loss: 2.559859275817871
Validation loss: 1.8089329901561941

Epoch: 6| Step: 6
Training loss: 1.2839758396148682
Validation loss: 1.7953988954585085

Epoch: 6| Step: 7
Training loss: 0.9937148690223694
Validation loss: 1.755371300123071

Epoch: 6| Step: 8
Training loss: 1.808058738708496
Validation loss: 1.8169812489581365

Epoch: 6| Step: 9
Training loss: 0.8129137754440308
Validation loss: 1.7874435250477125

Epoch: 6| Step: 10
Training loss: 2.1090636253356934
Validation loss: 1.8015107377882926

Epoch: 6| Step: 11
Training loss: 1.6150398254394531
Validation loss: 1.8425623370755104

Epoch: 6| Step: 12
Training loss: 1.3077976703643799
Validation loss: 1.7973915069333968

Epoch: 6| Step: 13
Training loss: 0.8815299272537231
Validation loss: 1.7946740581143288

Epoch: 293| Step: 0
Training loss: 1.1811659336090088
Validation loss: 1.8262050536371046

Epoch: 6| Step: 1
Training loss: 1.8951568603515625
Validation loss: 1.7874271767113799

Epoch: 6| Step: 2
Training loss: 1.6320643424987793
Validation loss: 1.7483526968186902

Epoch: 6| Step: 3
Training loss: 1.8348519802093506
Validation loss: 1.7895867311826317

Epoch: 6| Step: 4
Training loss: 1.4788496494293213
Validation loss: 1.813083723027219

Epoch: 6| Step: 5
Training loss: 1.519775629043579
Validation loss: 1.850748937617066

Epoch: 6| Step: 6
Training loss: 1.402544379234314
Validation loss: 1.7887685760374992

Epoch: 6| Step: 7
Training loss: 1.504569411277771
Validation loss: 1.7845365103854929

Epoch: 6| Step: 8
Training loss: 1.3534542322158813
Validation loss: 1.8116757177537488

Epoch: 6| Step: 9
Training loss: 1.6203570365905762
Validation loss: 1.848507599164081

Epoch: 6| Step: 10
Training loss: 1.0514683723449707
Validation loss: 1.8053313186091762

Epoch: 6| Step: 11
Training loss: 1.1119420528411865
Validation loss: 1.8614226579666138

Epoch: 6| Step: 12
Training loss: 1.6946759223937988
Validation loss: 1.8667852519660868

Epoch: 6| Step: 13
Training loss: 1.6466225385665894
Validation loss: 1.868880210384246

Epoch: 294| Step: 0
Training loss: 1.7247343063354492
Validation loss: 1.8190643915566065

Epoch: 6| Step: 1
Training loss: 1.341715931892395
Validation loss: 1.8475085560993483

Epoch: 6| Step: 2
Training loss: 0.8420142531394958
Validation loss: 1.8584932998944355

Epoch: 6| Step: 3
Training loss: 1.7161543369293213
Validation loss: 1.8476225176165182

Epoch: 6| Step: 4
Training loss: 1.5570476055145264
Validation loss: 1.8291982937884588

Epoch: 6| Step: 5
Training loss: 1.5415840148925781
Validation loss: 1.80367995590292

Epoch: 6| Step: 6
Training loss: 1.3156051635742188
Validation loss: 1.8093875403045325

Epoch: 6| Step: 7
Training loss: 1.8422720432281494
Validation loss: 1.8436524586011005

Epoch: 6| Step: 8
Training loss: 1.6611175537109375
Validation loss: 1.8244383283840713

Epoch: 6| Step: 9
Training loss: 1.5951200723648071
Validation loss: 1.8241817592292704

Epoch: 6| Step: 10
Training loss: 1.200404405593872
Validation loss: 1.834286379557784

Epoch: 6| Step: 11
Training loss: 1.4272346496582031
Validation loss: 1.810359827933773

Epoch: 6| Step: 12
Training loss: 1.3392994403839111
Validation loss: 1.7990845993000975

Epoch: 6| Step: 13
Training loss: 1.2447172403335571
Validation loss: 1.8054655764692573

Epoch: 295| Step: 0
Training loss: 1.3746998310089111
Validation loss: 1.821423149877979

Epoch: 6| Step: 1
Training loss: 1.2113471031188965
Validation loss: 1.7642889458646056

Epoch: 6| Step: 2
Training loss: 1.6732783317565918
Validation loss: 1.848942651543566

Epoch: 6| Step: 3
Training loss: 0.872260570526123
Validation loss: 1.8155469920045586

Epoch: 6| Step: 4
Training loss: 1.2692716121673584
Validation loss: 1.810330061502354

Epoch: 6| Step: 5
Training loss: 1.581329107284546
Validation loss: 1.7916696750989525

Epoch: 6| Step: 6
Training loss: 1.927358627319336
Validation loss: 1.7751826188897575

Epoch: 6| Step: 7
Training loss: 0.8550846576690674
Validation loss: 1.8245982534141951

Epoch: 6| Step: 8
Training loss: 1.6856706142425537
Validation loss: 1.7914063481874363

Epoch: 6| Step: 9
Training loss: 1.629349946975708
Validation loss: 1.839028609696255

Epoch: 6| Step: 10
Training loss: 1.355151891708374
Validation loss: 1.8294500548352477

Epoch: 6| Step: 11
Training loss: 1.806152582168579
Validation loss: 1.8264826151632494

Epoch: 6| Step: 12
Training loss: 1.1898443698883057
Validation loss: 1.812040816071213

Epoch: 6| Step: 13
Training loss: 1.8805114030838013
Validation loss: 1.8657293088974491

Epoch: 296| Step: 0
Training loss: 1.1846020221710205
Validation loss: 1.808269344350343

Epoch: 6| Step: 1
Training loss: 1.8259961605072021
Validation loss: 1.8282388615351852

Epoch: 6| Step: 2
Training loss: 1.1785115003585815
Validation loss: 1.8299202842097129

Epoch: 6| Step: 3
Training loss: 0.8145980834960938
Validation loss: 1.8325059542091944

Epoch: 6| Step: 4
Training loss: 1.1239272356033325
Validation loss: 1.788144693579725

Epoch: 6| Step: 5
Training loss: 1.577595829963684
Validation loss: 1.8001481051086097

Epoch: 6| Step: 6
Training loss: 0.9453969597816467
Validation loss: 1.8058364545145342

Epoch: 6| Step: 7
Training loss: 1.3279730081558228
Validation loss: 1.8268299743693361

Epoch: 6| Step: 8
Training loss: 2.428224563598633
Validation loss: 1.7809659306721022

Epoch: 6| Step: 9
Training loss: 1.9288419485092163
Validation loss: 1.8153906342803792

Epoch: 6| Step: 10
Training loss: 1.3668427467346191
Validation loss: 1.7970783954025598

Epoch: 6| Step: 11
Training loss: 2.0901551246643066
Validation loss: 1.7908116809783443

Epoch: 6| Step: 12
Training loss: 1.1971687078475952
Validation loss: 1.8043126995845506

Epoch: 6| Step: 13
Training loss: 0.8745126724243164
Validation loss: 1.7672840241462953

Epoch: 297| Step: 0
Training loss: 1.639740228652954
Validation loss: 1.792271380142499

Epoch: 6| Step: 1
Training loss: 1.2683591842651367
Validation loss: 1.8061827587824997

Epoch: 6| Step: 2
Training loss: 1.6219335794448853
Validation loss: 1.8362516049415833

Epoch: 6| Step: 3
Training loss: 1.1359251737594604
Validation loss: 1.793148341999259

Epoch: 6| Step: 4
Training loss: 2.0437159538269043
Validation loss: 1.8240705100438928

Epoch: 6| Step: 5
Training loss: 1.2543370723724365
Validation loss: 1.8164110491352696

Epoch: 6| Step: 6
Training loss: 1.4081764221191406
Validation loss: 1.8325861141245852

Epoch: 6| Step: 7
Training loss: 1.7608790397644043
Validation loss: 1.7792181225233181

Epoch: 6| Step: 8
Training loss: 1.9589046239852905
Validation loss: 1.8092213330730316

Epoch: 6| Step: 9
Training loss: 1.1684644222259521
Validation loss: 1.8128086264415453

Epoch: 6| Step: 10
Training loss: 1.6098055839538574
Validation loss: 1.8087637309105165

Epoch: 6| Step: 11
Training loss: 0.9118442535400391
Validation loss: 1.8088954738391343

Epoch: 6| Step: 12
Training loss: 0.9355654716491699
Validation loss: 1.8126175339503954

Epoch: 6| Step: 13
Training loss: 1.714363932609558
Validation loss: 1.8496618757965744

Epoch: 298| Step: 0
Training loss: 1.8939383029937744
Validation loss: 1.810817869760657

Epoch: 6| Step: 1
Training loss: 1.4755284786224365
Validation loss: 1.8114704291025798

Epoch: 6| Step: 2
Training loss: 1.5171847343444824
Validation loss: 1.8109470593032015

Epoch: 6| Step: 3
Training loss: 0.7116067409515381
Validation loss: 1.8088900684028544

Epoch: 6| Step: 4
Training loss: 1.5112309455871582
Validation loss: 1.797488034412425

Epoch: 6| Step: 5
Training loss: 0.9467461109161377
Validation loss: 1.8240020198206748

Epoch: 6| Step: 6
Training loss: 1.875115990638733
Validation loss: 1.811599689145242

Epoch: 6| Step: 7
Training loss: 1.641523838043213
Validation loss: 1.804106604668402

Epoch: 6| Step: 8
Training loss: 2.142523765563965
Validation loss: 1.8022626779412712

Epoch: 6| Step: 9
Training loss: 1.823919415473938
Validation loss: 1.7823645081571353

Epoch: 6| Step: 10
Training loss: 1.257049798965454
Validation loss: 1.8094496521898495

Epoch: 6| Step: 11
Training loss: 1.163221836090088
Validation loss: 1.7839784468373945

Epoch: 6| Step: 12
Training loss: 1.1903913021087646
Validation loss: 1.8409766907333045

Epoch: 6| Step: 13
Training loss: 1.6338675022125244
Validation loss: 1.8249059889906196

Epoch: 299| Step: 0
Training loss: 1.85313081741333
Validation loss: 1.785232497799781

Epoch: 6| Step: 1
Training loss: 1.184128761291504
Validation loss: 1.7858455052939795

Epoch: 6| Step: 2
Training loss: 1.2274562120437622
Validation loss: 1.7971880051397509

Epoch: 6| Step: 3
Training loss: 1.9397399425506592
Validation loss: 1.7810070963316067

Epoch: 6| Step: 4
Training loss: 1.633062720298767
Validation loss: 1.8046713785458637

Epoch: 6| Step: 5
Training loss: 1.2744606733322144
Validation loss: 1.8166420831475207

Epoch: 6| Step: 6
Training loss: 1.440212607383728
Validation loss: 1.8175864937484905

Epoch: 6| Step: 7
Training loss: 1.5481455326080322
Validation loss: 1.8303789502830916

Epoch: 6| Step: 8
Training loss: 1.2510966062545776
Validation loss: 1.8328905720864572

Epoch: 6| Step: 9
Training loss: 1.1546837091445923
Validation loss: 1.7862449410141155

Epoch: 6| Step: 10
Training loss: 1.591752052307129
Validation loss: 1.8107160406727945

Epoch: 6| Step: 11
Training loss: 1.0930453538894653
Validation loss: 1.7842016758457306

Epoch: 6| Step: 12
Training loss: 1.627244234085083
Validation loss: 1.7700680353308236

Epoch: 6| Step: 13
Training loss: 1.4030060768127441
Validation loss: 1.828301340021113

Epoch: 300| Step: 0
Training loss: 2.122837543487549
Validation loss: 1.8551221880861508

Epoch: 6| Step: 1
Training loss: 1.675947904586792
Validation loss: 1.7792432603015695

Epoch: 6| Step: 2
Training loss: 1.681512713432312
Validation loss: 1.794512705136371

Epoch: 6| Step: 3
Training loss: 1.2355132102966309
Validation loss: 1.778840511075912

Epoch: 6| Step: 4
Training loss: 0.9765317440032959
Validation loss: 1.8009392702451317

Epoch: 6| Step: 5
Training loss: 1.348435878753662
Validation loss: 1.7782284982742802

Epoch: 6| Step: 6
Training loss: 1.820054292678833
Validation loss: 1.800503570546386

Epoch: 6| Step: 7
Training loss: 1.3040722608566284
Validation loss: 1.7758897863408571

Epoch: 6| Step: 8
Training loss: 1.667895793914795
Validation loss: 1.7788257393785702

Epoch: 6| Step: 9
Training loss: 1.3336479663848877
Validation loss: 1.7390930550072783

Epoch: 6| Step: 10
Training loss: 1.62900710105896
Validation loss: 1.8005257844924927

Epoch: 6| Step: 11
Training loss: 1.0301185846328735
Validation loss: 1.8183993498484294

Epoch: 6| Step: 12
Training loss: 1.4641441106796265
Validation loss: 1.7919259455896193

Epoch: 6| Step: 13
Training loss: 0.7688289284706116
Validation loss: 1.7875594272408435

Epoch: 301| Step: 0
Training loss: 1.6537442207336426
Validation loss: 1.781687577565511

Epoch: 6| Step: 1
Training loss: 1.6829209327697754
Validation loss: 1.8348266501580515

Epoch: 6| Step: 2
Training loss: 1.1521494388580322
Validation loss: 1.8494736225374284

Epoch: 6| Step: 3
Training loss: 1.3995846509933472
Validation loss: 1.8260845368908298

Epoch: 6| Step: 4
Training loss: 1.5287243127822876
Validation loss: 1.8407608821827879

Epoch: 6| Step: 5
Training loss: 1.1675066947937012
Validation loss: 1.7753901097082323

Epoch: 6| Step: 6
Training loss: 1.251443862915039
Validation loss: 1.8102734601625832

Epoch: 6| Step: 7
Training loss: 1.1776684522628784
Validation loss: 1.7921713731622184

Epoch: 6| Step: 8
Training loss: 1.8094761371612549
Validation loss: 1.8024953642199117

Epoch: 6| Step: 9
Training loss: 1.1955153942108154
Validation loss: 1.8006163976525749

Epoch: 6| Step: 10
Training loss: 1.301159381866455
Validation loss: 1.833675839567697

Epoch: 6| Step: 11
Training loss: 0.9989132881164551
Validation loss: 1.8228854774146952

Epoch: 6| Step: 12
Training loss: 1.8422191143035889
Validation loss: 1.7955857207698207

Epoch: 6| Step: 13
Training loss: 1.9707101583480835
Validation loss: 1.76993554253732

Epoch: 302| Step: 0
Training loss: 1.1697940826416016
Validation loss: 1.8067673201202064

Epoch: 6| Step: 1
Training loss: 1.2769047021865845
Validation loss: 1.8227254626571492

Epoch: 6| Step: 2
Training loss: 1.2786664962768555
Validation loss: 1.8293073074792021

Epoch: 6| Step: 3
Training loss: 1.4208598136901855
Validation loss: 1.8207491174820931

Epoch: 6| Step: 4
Training loss: 1.6659343242645264
Validation loss: 1.8563951266709195

Epoch: 6| Step: 5
Training loss: 1.3397536277770996
Validation loss: 1.8180139641607962

Epoch: 6| Step: 6
Training loss: 1.5222010612487793
Validation loss: 1.8315289148720362

Epoch: 6| Step: 7
Training loss: 1.192512035369873
Validation loss: 1.8369544013853996

Epoch: 6| Step: 8
Training loss: 1.342757225036621
Validation loss: 1.7886648062736756

Epoch: 6| Step: 9
Training loss: 1.1333264112472534
Validation loss: 1.834521892250225

Epoch: 6| Step: 10
Training loss: 1.9832253456115723
Validation loss: 1.8064136069308045

Epoch: 6| Step: 11
Training loss: 1.2074429988861084
Validation loss: 1.8075874864414174

Epoch: 6| Step: 12
Training loss: 2.0056076049804688
Validation loss: 1.8482788660193001

Epoch: 6| Step: 13
Training loss: 1.624178171157837
Validation loss: 1.8384060859680176

Epoch: 303| Step: 0
Training loss: 1.785361647605896
Validation loss: 1.799300774451225

Epoch: 6| Step: 1
Training loss: 1.81516695022583
Validation loss: 1.7876639340513496

Epoch: 6| Step: 2
Training loss: 1.1261100769042969
Validation loss: 1.7690727954269738

Epoch: 6| Step: 3
Training loss: 1.8855154514312744
Validation loss: 1.850643337413829

Epoch: 6| Step: 4
Training loss: 1.3352817296981812
Validation loss: 1.8101046610903997

Epoch: 6| Step: 5
Training loss: 0.9768052697181702
Validation loss: 1.756434735431466

Epoch: 6| Step: 6
Training loss: 1.7047672271728516
Validation loss: 1.756267382252601

Epoch: 6| Step: 7
Training loss: 1.2736080884933472
Validation loss: 1.805977967477614

Epoch: 6| Step: 8
Training loss: 1.2990491390228271
Validation loss: 1.8478772563319052

Epoch: 6| Step: 9
Training loss: 1.468734622001648
Validation loss: 1.7936630710478751

Epoch: 6| Step: 10
Training loss: 1.3075017929077148
Validation loss: 1.789164848225091

Epoch: 6| Step: 11
Training loss: 1.4693142175674438
Validation loss: 1.8270733202657392

Epoch: 6| Step: 12
Training loss: 1.237563133239746
Validation loss: 1.8044725797509635

Epoch: 6| Step: 13
Training loss: 1.1298727989196777
Validation loss: 1.8191714671350294

Epoch: 304| Step: 0
Training loss: 2.1155123710632324
Validation loss: 1.8227053560236448

Epoch: 6| Step: 1
Training loss: 2.219916820526123
Validation loss: 1.798435131708781

Epoch: 6| Step: 2
Training loss: 0.9983373284339905
Validation loss: 1.8088428602423718

Epoch: 6| Step: 3
Training loss: 1.2317030429840088
Validation loss: 1.8022714814832133

Epoch: 6| Step: 4
Training loss: 1.3613300323486328
Validation loss: 1.8553851522425169

Epoch: 6| Step: 5
Training loss: 0.9910903573036194
Validation loss: 1.7827606226808281

Epoch: 6| Step: 6
Training loss: 1.5881578922271729
Validation loss: 1.7321343332208612

Epoch: 6| Step: 7
Training loss: 1.7414350509643555
Validation loss: 1.8655135016287527

Epoch: 6| Step: 8
Training loss: 1.0965100526809692
Validation loss: 1.81486738112665

Epoch: 6| Step: 9
Training loss: 1.2266998291015625
Validation loss: 1.8222878056187783

Epoch: 6| Step: 10
Training loss: 1.4154736995697021
Validation loss: 1.7777558949685865

Epoch: 6| Step: 11
Training loss: 1.070872187614441
Validation loss: 1.7909761577524164

Epoch: 6| Step: 12
Training loss: 0.9711023569107056
Validation loss: 1.8125708769726496

Epoch: 6| Step: 13
Training loss: 1.4625617265701294
Validation loss: 1.7933888986546507

Epoch: 305| Step: 0
Training loss: 1.9046063423156738
Validation loss: 1.794144372786245

Epoch: 6| Step: 1
Training loss: 1.1169135570526123
Validation loss: 1.8046860874340098

Epoch: 6| Step: 2
Training loss: 1.3373939990997314
Validation loss: 1.7920056273860316

Epoch: 6| Step: 3
Training loss: 1.1422703266143799
Validation loss: 1.7704366560905211

Epoch: 6| Step: 4
Training loss: 1.145735263824463
Validation loss: 1.766379507639075

Epoch: 6| Step: 5
Training loss: 1.4226518869400024
Validation loss: 1.7933964363990291

Epoch: 6| Step: 6
Training loss: 1.418060064315796
Validation loss: 1.8324507462081088

Epoch: 6| Step: 7
Training loss: 1.3801395893096924
Validation loss: 1.755591307916949

Epoch: 6| Step: 8
Training loss: 1.506554126739502
Validation loss: 1.7946341089023057

Epoch: 6| Step: 9
Training loss: 1.3519036769866943
Validation loss: 1.8273517111296296

Epoch: 6| Step: 10
Training loss: 1.3822379112243652
Validation loss: 1.7714668332889516

Epoch: 6| Step: 11
Training loss: 1.604649305343628
Validation loss: 1.798306756122138

Epoch: 6| Step: 12
Training loss: 1.4839897155761719
Validation loss: 1.7941957045626897

Epoch: 6| Step: 13
Training loss: 1.8382118940353394
Validation loss: 1.8004176616668701

Epoch: 306| Step: 0
Training loss: 1.7627137899398804
Validation loss: 1.7928027517052108

Epoch: 6| Step: 1
Training loss: 0.8652005195617676
Validation loss: 1.763516934969092

Epoch: 6| Step: 2
Training loss: 1.9488108158111572
Validation loss: 1.8395525178601664

Epoch: 6| Step: 3
Training loss: 1.3418810367584229
Validation loss: 1.7208117515810075

Epoch: 6| Step: 4
Training loss: 1.6066997051239014
Validation loss: 1.8158463226851596

Epoch: 6| Step: 5
Training loss: 1.30328369140625
Validation loss: 1.8082576746581702

Epoch: 6| Step: 6
Training loss: 1.674612283706665
Validation loss: 1.753760044292737

Epoch: 6| Step: 7
Training loss: 1.3936607837677002
Validation loss: 1.7869453289175545

Epoch: 6| Step: 8
Training loss: 1.3941154479980469
Validation loss: 1.836077255587424

Epoch: 6| Step: 9
Training loss: 1.5144951343536377
Validation loss: 1.8304274505184543

Epoch: 6| Step: 10
Training loss: 1.0970935821533203
Validation loss: 1.7770572388043968

Epoch: 6| Step: 11
Training loss: 1.30914306640625
Validation loss: 1.7294035329613635

Epoch: 6| Step: 12
Training loss: 1.3765347003936768
Validation loss: 1.8062055226295226

Epoch: 6| Step: 13
Training loss: 1.061057448387146
Validation loss: 1.7808406032541746

Epoch: 307| Step: 0
Training loss: 1.4659987688064575
Validation loss: 1.8048657589061285

Epoch: 6| Step: 1
Training loss: 2.253235340118408
Validation loss: 1.8104061990655878

Epoch: 6| Step: 2
Training loss: 1.4410409927368164
Validation loss: 1.7998591930635515

Epoch: 6| Step: 3
Training loss: 1.2787108421325684
Validation loss: 1.7774585113730481

Epoch: 6| Step: 4
Training loss: 1.1475112438201904
Validation loss: 1.789047368111149

Epoch: 6| Step: 5
Training loss: 1.4043445587158203
Validation loss: 1.8338355402792654

Epoch: 6| Step: 6
Training loss: 1.0575294494628906
Validation loss: 1.7895320615460795

Epoch: 6| Step: 7
Training loss: 1.2770016193389893
Validation loss: 1.7844318830838768

Epoch: 6| Step: 8
Training loss: 1.6473413705825806
Validation loss: 1.8212806845224032

Epoch: 6| Step: 9
Training loss: 1.1362464427947998
Validation loss: 1.8128883210561608

Epoch: 6| Step: 10
Training loss: 1.2499092817306519
Validation loss: 1.7923349398438648

Epoch: 6| Step: 11
Training loss: 1.4756290912628174
Validation loss: 1.8198669495121125

Epoch: 6| Step: 12
Training loss: 1.7240828275680542
Validation loss: 1.8127688797571326

Epoch: 6| Step: 13
Training loss: 1.755129098892212
Validation loss: 1.8257491575774325

Epoch: 308| Step: 0
Training loss: 2.0515952110290527
Validation loss: 1.7998352883964457

Epoch: 6| Step: 1
Training loss: 0.8466330170631409
Validation loss: 1.8699469540708809

Epoch: 6| Step: 2
Training loss: 1.5801539421081543
Validation loss: 1.8243145840142363

Epoch: 6| Step: 3
Training loss: 2.3470702171325684
Validation loss: 1.779069185256958

Epoch: 6| Step: 4
Training loss: 1.5178711414337158
Validation loss: 1.8558619740188762

Epoch: 6| Step: 5
Training loss: 1.746983289718628
Validation loss: 1.8502510645056283

Epoch: 6| Step: 6
Training loss: 1.2089898586273193
Validation loss: 1.834374591868411

Epoch: 6| Step: 7
Training loss: 1.3257205486297607
Validation loss: 1.795844675392233

Epoch: 6| Step: 8
Training loss: 1.3899726867675781
Validation loss: 1.8327100417947257

Epoch: 6| Step: 9
Training loss: 1.1851494312286377
Validation loss: 1.8360533829658263

Epoch: 6| Step: 10
Training loss: 1.225769281387329
Validation loss: 1.7748728259917228

Epoch: 6| Step: 11
Training loss: 0.9180648922920227
Validation loss: 1.8133459937187932

Epoch: 6| Step: 12
Training loss: 1.331885576248169
Validation loss: 1.7812287858737412

Epoch: 6| Step: 13
Training loss: 1.2121431827545166
Validation loss: 1.8332046385734313

Epoch: 309| Step: 0
Training loss: 1.0415573120117188
Validation loss: 1.8195753558989494

Epoch: 6| Step: 1
Training loss: 1.4966719150543213
Validation loss: 1.8090798008826472

Epoch: 6| Step: 2
Training loss: 1.4171833992004395
Validation loss: 1.8026416429909327

Epoch: 6| Step: 3
Training loss: 1.4366430044174194
Validation loss: 1.748099124559792

Epoch: 6| Step: 4
Training loss: 1.2543213367462158
Validation loss: 1.8399381932391916

Epoch: 6| Step: 5
Training loss: 1.1719398498535156
Validation loss: 1.7995050158551944

Epoch: 6| Step: 6
Training loss: 1.2211663722991943
Validation loss: 1.8138077400063957

Epoch: 6| Step: 7
Training loss: 1.3719122409820557
Validation loss: 1.8077245963517057

Epoch: 6| Step: 8
Training loss: 1.461188554763794
Validation loss: 1.8061146646417596

Epoch: 6| Step: 9
Training loss: 1.006044626235962
Validation loss: 1.7994967916960358

Epoch: 6| Step: 10
Training loss: 2.253732204437256
Validation loss: 1.8101650412364672

Epoch: 6| Step: 11
Training loss: 1.660839319229126
Validation loss: 1.803185692397497

Epoch: 6| Step: 12
Training loss: 1.530105710029602
Validation loss: 1.7955596318808935

Epoch: 6| Step: 13
Training loss: 1.2138597965240479
Validation loss: 1.8112418305489324

Epoch: 310| Step: 0
Training loss: 1.0201579332351685
Validation loss: 1.8031235587212346

Epoch: 6| Step: 1
Training loss: 1.1531463861465454
Validation loss: 1.8083085783066288

Epoch: 6| Step: 2
Training loss: 1.3876762390136719
Validation loss: 1.800902799893451

Epoch: 6| Step: 3
Training loss: 1.96272611618042
Validation loss: 1.7898174690943893

Epoch: 6| Step: 4
Training loss: 1.781174898147583
Validation loss: 1.8654648206567253

Epoch: 6| Step: 5
Training loss: 1.2836027145385742
Validation loss: 1.8087520048182497

Epoch: 6| Step: 6
Training loss: 1.4869444370269775
Validation loss: 1.8499353303704211

Epoch: 6| Step: 7
Training loss: 1.9940896034240723
Validation loss: 1.810156778622699

Epoch: 6| Step: 8
Training loss: 1.1496437788009644
Validation loss: 1.8190113754682644

Epoch: 6| Step: 9
Training loss: 1.4020235538482666
Validation loss: 1.8156936284034484

Epoch: 6| Step: 10
Training loss: 1.5895922183990479
Validation loss: 1.8333196024740896

Epoch: 6| Step: 11
Training loss: 1.3428032398223877
Validation loss: 1.8047759917474562

Epoch: 6| Step: 12
Training loss: 0.9413679838180542
Validation loss: 1.7854514621919202

Epoch: 6| Step: 13
Training loss: 1.0359692573547363
Validation loss: 1.833848003418215

Epoch: 311| Step: 0
Training loss: 1.864733338356018
Validation loss: 1.799000152977564

Epoch: 6| Step: 1
Training loss: 0.901363730430603
Validation loss: 1.8173568915295344

Epoch: 6| Step: 2
Training loss: 1.482710838317871
Validation loss: 1.8286465073144564

Epoch: 6| Step: 3
Training loss: 1.1346325874328613
Validation loss: 1.823605223368573

Epoch: 6| Step: 4
Training loss: 1.4649958610534668
Validation loss: 1.7623861733303274

Epoch: 6| Step: 5
Training loss: 1.3741084337234497
Validation loss: 1.8330452660078644

Epoch: 6| Step: 6
Training loss: 0.9917593002319336
Validation loss: 1.7906044811330817

Epoch: 6| Step: 7
Training loss: 1.1935827732086182
Validation loss: 1.8094566970743158

Epoch: 6| Step: 8
Training loss: 1.6848433017730713
Validation loss: 1.8213181828939786

Epoch: 6| Step: 9
Training loss: 1.950410008430481
Validation loss: 1.8044320101379066

Epoch: 6| Step: 10
Training loss: 1.458592176437378
Validation loss: 1.8107891672401017

Epoch: 6| Step: 11
Training loss: 1.1439496278762817
Validation loss: 1.8057731864272908

Epoch: 6| Step: 12
Training loss: 1.1558945178985596
Validation loss: 1.8060314911668018

Epoch: 6| Step: 13
Training loss: 1.5586881637573242
Validation loss: 1.861263454601329

Epoch: 312| Step: 0
Training loss: 0.860748827457428
Validation loss: 1.789371508424

Epoch: 6| Step: 1
Training loss: 1.0589876174926758
Validation loss: 1.828165779831589

Epoch: 6| Step: 2
Training loss: 1.2817254066467285
Validation loss: 1.7844591243292696

Epoch: 6| Step: 3
Training loss: 1.5162036418914795
Validation loss: 1.8577214748628679

Epoch: 6| Step: 4
Training loss: 1.3465149402618408
Validation loss: 1.8368230148028302

Epoch: 6| Step: 5
Training loss: 1.3482170104980469
Validation loss: 1.8173761252434022

Epoch: 6| Step: 6
Training loss: 1.2643488645553589
Validation loss: 1.834988518427777

Epoch: 6| Step: 7
Training loss: 2.097421646118164
Validation loss: 1.812920944665068

Epoch: 6| Step: 8
Training loss: 1.5562306642532349
Validation loss: 1.8765024177489742

Epoch: 6| Step: 9
Training loss: 1.629616141319275
Validation loss: 1.8229616162597493

Epoch: 6| Step: 10
Training loss: 1.2174944877624512
Validation loss: 1.8187912305196126

Epoch: 6| Step: 11
Training loss: 1.4961720705032349
Validation loss: 1.8236658291150165

Epoch: 6| Step: 12
Training loss: 1.4305375814437866
Validation loss: 1.7994066566549323

Epoch: 6| Step: 13
Training loss: 1.6451083421707153
Validation loss: 1.7749454731582313

Epoch: 313| Step: 0
Training loss: 1.3880698680877686
Validation loss: 1.8312677991005681

Epoch: 6| Step: 1
Training loss: 1.5172514915466309
Validation loss: 1.7652552845657512

Epoch: 6| Step: 2
Training loss: 0.8211339712142944
Validation loss: 1.8136125713266351

Epoch: 6| Step: 3
Training loss: 1.2036212682724
Validation loss: 1.826797148232819

Epoch: 6| Step: 4
Training loss: 1.523258090019226
Validation loss: 1.77889076740511

Epoch: 6| Step: 5
Training loss: 1.8518738746643066
Validation loss: 1.8139971199856009

Epoch: 6| Step: 6
Training loss: 0.9907524585723877
Validation loss: 1.8006440375440864

Epoch: 6| Step: 7
Training loss: 1.25538170337677
Validation loss: 1.7857042461313226

Epoch: 6| Step: 8
Training loss: 1.4045653343200684
Validation loss: 1.7775043031220794

Epoch: 6| Step: 9
Training loss: 1.5705037117004395
Validation loss: 1.7909135972299883

Epoch: 6| Step: 10
Training loss: 1.6664516925811768
Validation loss: 1.7628773373942221

Epoch: 6| Step: 11
Training loss: 1.438114881515503
Validation loss: 1.7724370815420663

Epoch: 6| Step: 12
Training loss: 1.3986982107162476
Validation loss: 1.7914813769760953

Epoch: 6| Step: 13
Training loss: 1.4101643562316895
Validation loss: 1.8010794860060497

Epoch: 314| Step: 0
Training loss: 1.4410350322723389
Validation loss: 1.7943014714025682

Epoch: 6| Step: 1
Training loss: 1.213226079940796
Validation loss: 1.8261862185693556

Epoch: 6| Step: 2
Training loss: 1.6938718557357788
Validation loss: 1.8360749060107815

Epoch: 6| Step: 3
Training loss: 1.0198566913604736
Validation loss: 1.8049037264239403

Epoch: 6| Step: 4
Training loss: 1.6929686069488525
Validation loss: 1.8171543139283375

Epoch: 6| Step: 5
Training loss: 1.2459086179733276
Validation loss: 1.8253845566062517

Epoch: 6| Step: 6
Training loss: 1.3449193239212036
Validation loss: 1.827096555822639

Epoch: 6| Step: 7
Training loss: 1.7542591094970703
Validation loss: 1.8191667564453617

Epoch: 6| Step: 8
Training loss: 1.0009539127349854
Validation loss: 1.726213724382462

Epoch: 6| Step: 9
Training loss: 1.8669254779815674
Validation loss: 1.8164921691340785

Epoch: 6| Step: 10
Training loss: 1.4721652269363403
Validation loss: 1.7517256518845916

Epoch: 6| Step: 11
Training loss: 1.6383299827575684
Validation loss: 1.806405310989708

Epoch: 6| Step: 12
Training loss: 1.2052910327911377
Validation loss: 1.7572288000455467

Epoch: 6| Step: 13
Training loss: 1.6133793592453003
Validation loss: 1.8305351362433484

Epoch: 315| Step: 0
Training loss: 1.6288753747940063
Validation loss: 1.7797835693564465

Epoch: 6| Step: 1
Training loss: 1.2013258934020996
Validation loss: 1.822735433937401

Epoch: 6| Step: 2
Training loss: 1.2169406414031982
Validation loss: 1.8063776364890478

Epoch: 6| Step: 3
Training loss: 1.551797866821289
Validation loss: 1.8354907510101155

Epoch: 6| Step: 4
Training loss: 1.0892325639724731
Validation loss: 1.8198047376448108

Epoch: 6| Step: 5
Training loss: 0.9635353684425354
Validation loss: 1.8483429237078595

Epoch: 6| Step: 6
Training loss: 1.1226351261138916
Validation loss: 1.8257591429577078

Epoch: 6| Step: 7
Training loss: 0.897496223449707
Validation loss: 1.82251472755145

Epoch: 6| Step: 8
Training loss: 1.7980605363845825
Validation loss: 1.8348912513384255

Epoch: 6| Step: 9
Training loss: 1.4920661449432373
Validation loss: 1.8089256683985393

Epoch: 6| Step: 10
Training loss: 1.8296432495117188
Validation loss: 1.863706765636321

Epoch: 6| Step: 11
Training loss: 1.827164649963379
Validation loss: 1.793013403492589

Epoch: 6| Step: 12
Training loss: 1.404327392578125
Validation loss: 1.7651336231539327

Epoch: 6| Step: 13
Training loss: 1.403529405593872
Validation loss: 1.768897710307952

Epoch: 316| Step: 0
Training loss: 1.069633960723877
Validation loss: 1.804737690956362

Epoch: 6| Step: 1
Training loss: 1.1348283290863037
Validation loss: 1.7664204887164536

Epoch: 6| Step: 2
Training loss: 1.24264395236969
Validation loss: 1.7799678361544045

Epoch: 6| Step: 3
Training loss: 1.2180445194244385
Validation loss: 1.776250208577802

Epoch: 6| Step: 4
Training loss: 1.631854772567749
Validation loss: 1.771961812050112

Epoch: 6| Step: 5
Training loss: 1.2289841175079346
Validation loss: 1.7609076705030215

Epoch: 6| Step: 6
Training loss: 1.309210181236267
Validation loss: 1.7943095084159606

Epoch: 6| Step: 7
Training loss: 1.424980640411377
Validation loss: 1.7849221396189865

Epoch: 6| Step: 8
Training loss: 1.762473464012146
Validation loss: 1.8024501390354608

Epoch: 6| Step: 9
Training loss: 1.1979427337646484
Validation loss: 1.8507872063626525

Epoch: 6| Step: 10
Training loss: 1.673435926437378
Validation loss: 1.803679540593137

Epoch: 6| Step: 11
Training loss: 2.1998744010925293
Validation loss: 1.773395194802233

Epoch: 6| Step: 12
Training loss: 1.682950735092163
Validation loss: 1.8217544965846564

Epoch: 6| Step: 13
Training loss: 0.9653266072273254
Validation loss: 1.8078573044910227

Epoch: 317| Step: 0
Training loss: 1.4271471500396729
Validation loss: 1.7763419176942559

Epoch: 6| Step: 1
Training loss: 1.8745591640472412
Validation loss: 1.79550350353282

Epoch: 6| Step: 2
Training loss: 1.0352712869644165
Validation loss: 1.7510858479366507

Epoch: 6| Step: 3
Training loss: 1.5261276960372925
Validation loss: 1.8681306249351912

Epoch: 6| Step: 4
Training loss: 1.376117467880249
Validation loss: 1.859304702410134

Epoch: 6| Step: 5
Training loss: 0.9586724042892456
Validation loss: 1.7808372397576608

Epoch: 6| Step: 6
Training loss: 0.9867091178894043
Validation loss: 1.8274969477807321

Epoch: 6| Step: 7
Training loss: 1.0994516611099243
Validation loss: 1.8141199670812136

Epoch: 6| Step: 8
Training loss: 1.781001091003418
Validation loss: 1.8082373808788996

Epoch: 6| Step: 9
Training loss: 1.5082650184631348
Validation loss: 1.7990240153445993

Epoch: 6| Step: 10
Training loss: 2.0038657188415527
Validation loss: 1.739699714927263

Epoch: 6| Step: 11
Training loss: 1.5536305904388428
Validation loss: 1.7790954151461202

Epoch: 6| Step: 12
Training loss: 0.7552826404571533
Validation loss: 1.781683066839813

Epoch: 6| Step: 13
Training loss: 1.516541838645935
Validation loss: 1.7916570119960333

Epoch: 318| Step: 0
Training loss: 1.1080107688903809
Validation loss: 1.8206951310557704

Epoch: 6| Step: 1
Training loss: 1.5266048908233643
Validation loss: 1.8376238910100793

Epoch: 6| Step: 2
Training loss: 1.6387512683868408
Validation loss: 1.8357772968148673

Epoch: 6| Step: 3
Training loss: 0.9345488548278809
Validation loss: 1.8129279369949012

Epoch: 6| Step: 4
Training loss: 1.1021959781646729
Validation loss: 1.8536666330470835

Epoch: 6| Step: 5
Training loss: 1.793774127960205
Validation loss: 1.8265498017752042

Epoch: 6| Step: 6
Training loss: 1.3503810167312622
Validation loss: 1.848204078212861

Epoch: 6| Step: 7
Training loss: 0.7651745676994324
Validation loss: 1.8031660331192838

Epoch: 6| Step: 8
Training loss: 0.932081937789917
Validation loss: 1.8073799174319032

Epoch: 6| Step: 9
Training loss: 1.2930365800857544
Validation loss: 1.7762435097848215

Epoch: 6| Step: 10
Training loss: 1.6655542850494385
Validation loss: 1.7964984909180672

Epoch: 6| Step: 11
Training loss: 2.187683343887329
Validation loss: 1.8243199368958831

Epoch: 6| Step: 12
Training loss: 1.908290147781372
Validation loss: 1.7577586071465605

Epoch: 6| Step: 13
Training loss: 0.8193943500518799
Validation loss: 1.8056664210493847

Epoch: 319| Step: 0
Training loss: 1.7762517929077148
Validation loss: 1.8193523037818171

Epoch: 6| Step: 1
Training loss: 0.9393246173858643
Validation loss: 1.7475131865470641

Epoch: 6| Step: 2
Training loss: 1.4532215595245361
Validation loss: 1.801302465059424

Epoch: 6| Step: 3
Training loss: 1.7998237609863281
Validation loss: 1.837372261990783

Epoch: 6| Step: 4
Training loss: 1.533216953277588
Validation loss: 1.794789065596878

Epoch: 6| Step: 5
Training loss: 1.084252119064331
Validation loss: 1.791260926954208

Epoch: 6| Step: 6
Training loss: 0.9230650663375854
Validation loss: 1.8328447918738089

Epoch: 6| Step: 7
Training loss: 1.4093248844146729
Validation loss: 1.825483158070554

Epoch: 6| Step: 8
Training loss: 1.3238974809646606
Validation loss: 1.8227637954937514

Epoch: 6| Step: 9
Training loss: 1.2602460384368896
Validation loss: 1.8084962162920224

Epoch: 6| Step: 10
Training loss: 1.3435535430908203
Validation loss: 1.7993564772349533

Epoch: 6| Step: 11
Training loss: 1.2038977146148682
Validation loss: 1.7756615454150784

Epoch: 6| Step: 12
Training loss: 1.8284993171691895
Validation loss: 1.768134767009366

Epoch: 6| Step: 13
Training loss: 1.296903133392334
Validation loss: 1.7520330952059837

Epoch: 320| Step: 0
Training loss: 1.4123084545135498
Validation loss: 1.80122410866522

Epoch: 6| Step: 1
Training loss: 1.4788329601287842
Validation loss: 1.8341812882372128

Epoch: 6| Step: 2
Training loss: 1.641124963760376
Validation loss: 1.7884333864335091

Epoch: 6| Step: 3
Training loss: 0.9752871990203857
Validation loss: 1.7258607546488445

Epoch: 6| Step: 4
Training loss: 1.3223029375076294
Validation loss: 1.815799984880673

Epoch: 6| Step: 5
Training loss: 0.8549174070358276
Validation loss: 1.7834689514611357

Epoch: 6| Step: 6
Training loss: 1.0571131706237793
Validation loss: 1.7778070959993588

Epoch: 6| Step: 7
Training loss: 1.5200772285461426
Validation loss: 1.830493059209598

Epoch: 6| Step: 8
Training loss: 1.7564115524291992
Validation loss: 1.79137675351994

Epoch: 6| Step: 9
Training loss: 1.527374029159546
Validation loss: 1.8501108974538825

Epoch: 6| Step: 10
Training loss: 1.4557271003723145
Validation loss: 1.7823444181872952

Epoch: 6| Step: 11
Training loss: 1.4130244255065918
Validation loss: 1.7736622659108972

Epoch: 6| Step: 12
Training loss: 1.339645504951477
Validation loss: 1.7491957705507997

Epoch: 6| Step: 13
Training loss: 0.8969940543174744
Validation loss: 1.7770557890656173

Epoch: 321| Step: 0
Training loss: 1.8434572219848633
Validation loss: 1.8149102913436068

Epoch: 6| Step: 1
Training loss: 1.6810851097106934
Validation loss: 1.7992184944050287

Epoch: 6| Step: 2
Training loss: 1.1343379020690918
Validation loss: 1.82428999100962

Epoch: 6| Step: 3
Training loss: 1.0279083251953125
Validation loss: 1.8293880775410643

Epoch: 6| Step: 4
Training loss: 1.555731177330017
Validation loss: 1.799213122296077

Epoch: 6| Step: 5
Training loss: 1.2812178134918213
Validation loss: 1.7929092876372799

Epoch: 6| Step: 6
Training loss: 1.5965538024902344
Validation loss: 1.8296172016410417

Epoch: 6| Step: 7
Training loss: 1.6184558868408203
Validation loss: 1.8020078289893366

Epoch: 6| Step: 8
Training loss: 1.450958251953125
Validation loss: 1.861569212329003

Epoch: 6| Step: 9
Training loss: 1.148393988609314
Validation loss: 1.7844159154481785

Epoch: 6| Step: 10
Training loss: 0.8271209001541138
Validation loss: 1.7998492205014793

Epoch: 6| Step: 11
Training loss: 1.1240559816360474
Validation loss: 1.8083197942344091

Epoch: 6| Step: 12
Training loss: 1.3006577491760254
Validation loss: 1.7645429193332631

Epoch: 6| Step: 13
Training loss: 1.5120882987976074
Validation loss: 1.7689030619077786

Epoch: 322| Step: 0
Training loss: 1.0108981132507324
Validation loss: 1.7824407136568459

Epoch: 6| Step: 1
Training loss: 1.584163784980774
Validation loss: 1.7732338584879392

Epoch: 6| Step: 2
Training loss: 1.2303624153137207
Validation loss: 1.775331739456423

Epoch: 6| Step: 3
Training loss: 1.4552841186523438
Validation loss: 1.7941237995701451

Epoch: 6| Step: 4
Training loss: 1.04634690284729
Validation loss: 1.8173634134313112

Epoch: 6| Step: 5
Training loss: 1.6559157371520996
Validation loss: 1.7897228220457673

Epoch: 6| Step: 6
Training loss: 1.2664482593536377
Validation loss: 1.8102558992242301

Epoch: 6| Step: 7
Training loss: 1.3175337314605713
Validation loss: 1.7779173517739901

Epoch: 6| Step: 8
Training loss: 1.1633515357971191
Validation loss: 1.7950349430884085

Epoch: 6| Step: 9
Training loss: 1.680031418800354
Validation loss: 1.7856428546290244

Epoch: 6| Step: 10
Training loss: 1.1892613172531128
Validation loss: 1.8108777871695898

Epoch: 6| Step: 11
Training loss: 1.8531444072723389
Validation loss: 1.7673237657034269

Epoch: 6| Step: 12
Training loss: 1.8329756259918213
Validation loss: 1.8052797112413632

Epoch: 6| Step: 13
Training loss: 0.3475082218647003
Validation loss: 1.8311334681767288

Epoch: 323| Step: 0
Training loss: 1.874292254447937
Validation loss: 1.848650170910743

Epoch: 6| Step: 1
Training loss: 1.5042555332183838
Validation loss: 1.8183745363707184

Epoch: 6| Step: 2
Training loss: 1.0816949605941772
Validation loss: 1.8330378622137091

Epoch: 6| Step: 3
Training loss: 0.7082796096801758
Validation loss: 1.7873661466824111

Epoch: 6| Step: 4
Training loss: 1.3903433084487915
Validation loss: 1.7907309109164822

Epoch: 6| Step: 5
Training loss: 1.167027473449707
Validation loss: 1.7732610471786991

Epoch: 6| Step: 6
Training loss: 1.7652254104614258
Validation loss: 1.808067492259446

Epoch: 6| Step: 7
Training loss: 1.7461438179016113
Validation loss: 1.886349683166832

Epoch: 6| Step: 8
Training loss: 1.8566038608551025
Validation loss: 1.7725640343081566

Epoch: 6| Step: 9
Training loss: 0.9605745673179626
Validation loss: 1.8211129147519347

Epoch: 6| Step: 10
Training loss: 0.7625636458396912
Validation loss: 1.7991401841563563

Epoch: 6| Step: 11
Training loss: 1.4060161113739014
Validation loss: 1.8041044050647366

Epoch: 6| Step: 12
Training loss: 1.6918530464172363
Validation loss: 1.8410403202938777

Epoch: 6| Step: 13
Training loss: 0.9796103239059448
Validation loss: 1.8365179056762366

Epoch: 324| Step: 0
Training loss: 1.190049409866333
Validation loss: 1.7910275843835646

Epoch: 6| Step: 1
Training loss: 1.3978245258331299
Validation loss: 1.8389675232671923

Epoch: 6| Step: 2
Training loss: 1.533160924911499
Validation loss: 1.789898915957379

Epoch: 6| Step: 3
Training loss: 1.3642463684082031
Validation loss: 1.7843034587880617

Epoch: 6| Step: 4
Training loss: 0.8706620931625366
Validation loss: 1.8179976145426433

Epoch: 6| Step: 5
Training loss: 1.5603383779525757
Validation loss: 1.8146034645777878

Epoch: 6| Step: 6
Training loss: 1.9507880210876465
Validation loss: 1.8065382306293776

Epoch: 6| Step: 7
Training loss: 1.3479050397872925
Validation loss: 1.7807365476444204

Epoch: 6| Step: 8
Training loss: 1.1573991775512695
Validation loss: 1.7751205262317453

Epoch: 6| Step: 9
Training loss: 1.8005478382110596
Validation loss: 1.777709707137077

Epoch: 6| Step: 10
Training loss: 1.0840950012207031
Validation loss: 1.7643032663611955

Epoch: 6| Step: 11
Training loss: 1.4400393962860107
Validation loss: 1.795872688293457

Epoch: 6| Step: 12
Training loss: 1.0989516973495483
Validation loss: 1.7812706757617254

Epoch: 6| Step: 13
Training loss: 1.0509142875671387
Validation loss: 1.8142256377845682

Epoch: 325| Step: 0
Training loss: 1.8407824039459229
Validation loss: 1.8142656075057162

Epoch: 6| Step: 1
Training loss: 1.6346039772033691
Validation loss: 1.8340249484585178

Epoch: 6| Step: 2
Training loss: 1.3935798406600952
Validation loss: 1.869557201221425

Epoch: 6| Step: 3
Training loss: 0.8990561366081238
Validation loss: 1.7904426346543014

Epoch: 6| Step: 4
Training loss: 1.8044716119766235
Validation loss: 1.7973585256966211

Epoch: 6| Step: 5
Training loss: 1.509387731552124
Validation loss: 1.8140181892661638

Epoch: 6| Step: 6
Training loss: 1.0117065906524658
Validation loss: 1.803144565192602

Epoch: 6| Step: 7
Training loss: 1.5218172073364258
Validation loss: 1.823438770027571

Epoch: 6| Step: 8
Training loss: 1.539773941040039
Validation loss: 1.8014000026128625

Epoch: 6| Step: 9
Training loss: 1.0502901077270508
Validation loss: 1.8662776229202107

Epoch: 6| Step: 10
Training loss: 1.1493399143218994
Validation loss: 1.8255165905080817

Epoch: 6| Step: 11
Training loss: 1.349482536315918
Validation loss: 1.8125589880892026

Epoch: 6| Step: 12
Training loss: 1.1815756559371948
Validation loss: 1.8242640315845449

Epoch: 6| Step: 13
Training loss: 1.502811074256897
Validation loss: 1.738240582968599

Epoch: 326| Step: 0
Training loss: 1.3244142532348633
Validation loss: 1.7857050280417166

Epoch: 6| Step: 1
Training loss: 1.3122289180755615
Validation loss: 1.7941023303616432

Epoch: 6| Step: 2
Training loss: 1.4984474182128906
Validation loss: 1.7879070979292675

Epoch: 6| Step: 3
Training loss: 1.5771548748016357
Validation loss: 1.7673397230845627

Epoch: 6| Step: 4
Training loss: 1.5077781677246094
Validation loss: 1.8003225352174492

Epoch: 6| Step: 5
Training loss: 1.1530359983444214
Validation loss: 1.7817479974480086

Epoch: 6| Step: 6
Training loss: 1.9049904346466064
Validation loss: 1.7930336613808908

Epoch: 6| Step: 7
Training loss: 1.483715534210205
Validation loss: 1.8021745322853007

Epoch: 6| Step: 8
Training loss: 1.4899799823760986
Validation loss: 1.8033567423461585

Epoch: 6| Step: 9
Training loss: 0.8491332530975342
Validation loss: 1.7968213737651866

Epoch: 6| Step: 10
Training loss: 1.3259962797164917
Validation loss: 1.8307139950413858

Epoch: 6| Step: 11
Training loss: 1.1549651622772217
Validation loss: 1.7945635318756104

Epoch: 6| Step: 12
Training loss: 0.947287380695343
Validation loss: 1.8031056452822942

Epoch: 6| Step: 13
Training loss: 1.3408851623535156
Validation loss: 1.8059404293696086

Epoch: 327| Step: 0
Training loss: 0.8812251687049866
Validation loss: 1.7900718309546029

Epoch: 6| Step: 1
Training loss: 1.2222564220428467
Validation loss: 1.8245120304887013

Epoch: 6| Step: 2
Training loss: 1.5229201316833496
Validation loss: 1.7836727173097673

Epoch: 6| Step: 3
Training loss: 1.0686874389648438
Validation loss: 1.8151847752191688

Epoch: 6| Step: 4
Training loss: 1.7675995826721191
Validation loss: 1.8465987354196527

Epoch: 6| Step: 5
Training loss: 1.2165229320526123
Validation loss: 1.7420068607535413

Epoch: 6| Step: 6
Training loss: 1.428842306137085
Validation loss: 1.764236488649922

Epoch: 6| Step: 7
Training loss: 1.2367279529571533
Validation loss: 1.816326593839994

Epoch: 6| Step: 8
Training loss: 1.2166614532470703
Validation loss: 1.7844081412079513

Epoch: 6| Step: 9
Training loss: 1.2779147624969482
Validation loss: 1.8189452745581185

Epoch: 6| Step: 10
Training loss: 1.3306254148483276
Validation loss: 1.8293694937100975

Epoch: 6| Step: 11
Training loss: 1.5559186935424805
Validation loss: 1.7909195397489814

Epoch: 6| Step: 12
Training loss: 1.9311954975128174
Validation loss: 1.7677637761639011

Epoch: 6| Step: 13
Training loss: 0.8955118656158447
Validation loss: 1.8176737011119883

Epoch: 328| Step: 0
Training loss: 1.7394392490386963
Validation loss: 1.8165756169185843

Epoch: 6| Step: 1
Training loss: 0.7988235950469971
Validation loss: 1.7699378716048373

Epoch: 6| Step: 2
Training loss: 1.313159465789795
Validation loss: 1.8605361805167249

Epoch: 6| Step: 3
Training loss: 1.2071635723114014
Validation loss: 1.8046383562908377

Epoch: 6| Step: 4
Training loss: 1.1120634078979492
Validation loss: 1.7942261413861347

Epoch: 6| Step: 5
Training loss: 1.8387781381607056
Validation loss: 1.8486782581575456

Epoch: 6| Step: 6
Training loss: 0.7645590305328369
Validation loss: 1.7983778830497497

Epoch: 6| Step: 7
Training loss: 1.3523929119110107
Validation loss: 1.8118501401716662

Epoch: 6| Step: 8
Training loss: 1.7213854789733887
Validation loss: 1.801898447416162

Epoch: 6| Step: 9
Training loss: 1.2438831329345703
Validation loss: 1.801245709901215

Epoch: 6| Step: 10
Training loss: 1.0481252670288086
Validation loss: 1.7995869139189362

Epoch: 6| Step: 11
Training loss: 1.6319974660873413
Validation loss: 1.7718283668641122

Epoch: 6| Step: 12
Training loss: 1.203377604484558
Validation loss: 1.821202819065381

Epoch: 6| Step: 13
Training loss: 1.6275601387023926
Validation loss: 1.858909858170376

Epoch: 329| Step: 0
Training loss: 1.1659231185913086
Validation loss: 1.8365623950958252

Epoch: 6| Step: 1
Training loss: 1.261544942855835
Validation loss: 1.8406781099175895

Epoch: 6| Step: 2
Training loss: 1.2080283164978027
Validation loss: 1.787652172068114

Epoch: 6| Step: 3
Training loss: 1.7599561214447021
Validation loss: 1.8058563483658658

Epoch: 6| Step: 4
Training loss: 1.0296862125396729
Validation loss: 1.812239900712044

Epoch: 6| Step: 5
Training loss: 1.6312532424926758
Validation loss: 1.8289456995584632

Epoch: 6| Step: 6
Training loss: 1.8308329582214355
Validation loss: 1.7870292919938282

Epoch: 6| Step: 7
Training loss: 0.9971274137496948
Validation loss: 1.7619717403124737

Epoch: 6| Step: 8
Training loss: 1.5911462306976318
Validation loss: 1.8367961145216418

Epoch: 6| Step: 9
Training loss: 1.6098171472549438
Validation loss: 1.8043744897329679

Epoch: 6| Step: 10
Training loss: 1.2985358238220215
Validation loss: 1.8195280823656308

Epoch: 6| Step: 11
Training loss: 1.0209414958953857
Validation loss: 1.7899573900366341

Epoch: 6| Step: 12
Training loss: 1.1408379077911377
Validation loss: 1.8316603219637306

Epoch: 6| Step: 13
Training loss: 1.1424840688705444
Validation loss: 1.8019627678778865

Epoch: 330| Step: 0
Training loss: 1.0374975204467773
Validation loss: 1.8072017956805486

Epoch: 6| Step: 1
Training loss: 1.4683609008789062
Validation loss: 1.83928939091262

Epoch: 6| Step: 2
Training loss: 1.6406372785568237
Validation loss: 1.805917557849679

Epoch: 6| Step: 3
Training loss: 1.2079992294311523
Validation loss: 1.8168163568742814

Epoch: 6| Step: 4
Training loss: 1.043522596359253
Validation loss: 1.8514896977332331

Epoch: 6| Step: 5
Training loss: 1.1630280017852783
Validation loss: 1.7854010699897684

Epoch: 6| Step: 6
Training loss: 1.2097879648208618
Validation loss: 1.7757690927033782

Epoch: 6| Step: 7
Training loss: 1.1999677419662476
Validation loss: 1.7707407961609543

Epoch: 6| Step: 8
Training loss: 1.050467848777771
Validation loss: 1.8136168397882932

Epoch: 6| Step: 9
Training loss: 1.7181702852249146
Validation loss: 1.791589803593133

Epoch: 6| Step: 10
Training loss: 1.4037134647369385
Validation loss: 1.8142148897212038

Epoch: 6| Step: 11
Training loss: 1.8662333488464355
Validation loss: 1.8080124790950487

Epoch: 6| Step: 12
Training loss: 1.3233119249343872
Validation loss: 1.8224437313695108

Epoch: 6| Step: 13
Training loss: 1.3553721904754639
Validation loss: 1.7826925272582679

Epoch: 331| Step: 0
Training loss: 0.9275996088981628
Validation loss: 1.8161147717506654

Epoch: 6| Step: 1
Training loss: 1.2944936752319336
Validation loss: 1.7806062416363788

Epoch: 6| Step: 2
Training loss: 1.9109580516815186
Validation loss: 1.752610122003863

Epoch: 6| Step: 3
Training loss: 1.4298532009124756
Validation loss: 1.814397329925209

Epoch: 6| Step: 4
Training loss: 1.6910630464553833
Validation loss: 1.782849447701567

Epoch: 6| Step: 5
Training loss: 1.27130126953125
Validation loss: 1.765996225418583

Epoch: 6| Step: 6
Training loss: 1.1712424755096436
Validation loss: 1.8027461703105638

Epoch: 6| Step: 7
Training loss: 1.5540862083435059
Validation loss: 1.8046659936187088

Epoch: 6| Step: 8
Training loss: 1.238507628440857
Validation loss: 1.7741249517727924

Epoch: 6| Step: 9
Training loss: 1.5132248401641846
Validation loss: 1.8171170321843957

Epoch: 6| Step: 10
Training loss: 0.9071555733680725
Validation loss: 1.8113167247464579

Epoch: 6| Step: 11
Training loss: 0.711327075958252
Validation loss: 1.7652944159764115

Epoch: 6| Step: 12
Training loss: 2.180049419403076
Validation loss: 1.8183750619170487

Epoch: 6| Step: 13
Training loss: 1.2259598970413208
Validation loss: 1.783429830305038

Epoch: 332| Step: 0
Training loss: 1.1180179119110107
Validation loss: 1.774442167692287

Epoch: 6| Step: 1
Training loss: 1.705125331878662
Validation loss: 1.7407165009488341

Epoch: 6| Step: 2
Training loss: 1.1424189805984497
Validation loss: 1.791025278388813

Epoch: 6| Step: 3
Training loss: 1.2968759536743164
Validation loss: 1.7731317730360134

Epoch: 6| Step: 4
Training loss: 1.930111289024353
Validation loss: 1.8234284077921221

Epoch: 6| Step: 5
Training loss: 1.6871551275253296
Validation loss: 1.7673840035674393

Epoch: 6| Step: 6
Training loss: 1.6885948181152344
Validation loss: 1.7578519582748413

Epoch: 6| Step: 7
Training loss: 1.4469413757324219
Validation loss: 1.787299492025888

Epoch: 6| Step: 8
Training loss: 1.4192231893539429
Validation loss: 1.7914566762985722

Epoch: 6| Step: 9
Training loss: 0.8393328189849854
Validation loss: 1.8216156767260643

Epoch: 6| Step: 10
Training loss: 1.1866519451141357
Validation loss: 1.8116102833901682

Epoch: 6| Step: 11
Training loss: 0.9627764225006104
Validation loss: 1.814141522812587

Epoch: 6| Step: 12
Training loss: 1.5553934574127197
Validation loss: 1.8411157438831944

Epoch: 6| Step: 13
Training loss: 0.9121525287628174
Validation loss: 1.8085322405702324

Epoch: 333| Step: 0
Training loss: 1.0510621070861816
Validation loss: 1.7983598555288007

Epoch: 6| Step: 1
Training loss: 1.3471181392669678
Validation loss: 1.779164916725569

Epoch: 6| Step: 2
Training loss: 1.3070995807647705
Validation loss: 1.7897222016447334

Epoch: 6| Step: 3
Training loss: 1.3297474384307861
Validation loss: 1.779823536513954

Epoch: 6| Step: 4
Training loss: 0.8663864135742188
Validation loss: 1.7780314363459104

Epoch: 6| Step: 5
Training loss: 1.9642665386199951
Validation loss: 1.745396210301307

Epoch: 6| Step: 6
Training loss: 1.157480239868164
Validation loss: 1.7633914537327264

Epoch: 6| Step: 7
Training loss: 1.482264757156372
Validation loss: 1.793363586548836

Epoch: 6| Step: 8
Training loss: 0.44528841972351074
Validation loss: 1.8087168521778558

Epoch: 6| Step: 9
Training loss: 1.6066023111343384
Validation loss: 1.7717228563882972

Epoch: 6| Step: 10
Training loss: 1.621172547340393
Validation loss: 1.79385164219846

Epoch: 6| Step: 11
Training loss: 1.588942050933838
Validation loss: 1.8111833539060367

Epoch: 6| Step: 12
Training loss: 1.0284610986709595
Validation loss: 1.8152876271996448

Epoch: 6| Step: 13
Training loss: 1.201784610748291
Validation loss: 1.7846440679283553

Epoch: 334| Step: 0
Training loss: 1.4935781955718994
Validation loss: 1.7822891896770847

Epoch: 6| Step: 1
Training loss: 0.7256059646606445
Validation loss: 1.7658354851507372

Epoch: 6| Step: 2
Training loss: 1.6594455242156982
Validation loss: 1.788361277631534

Epoch: 6| Step: 3
Training loss: 1.0367285013198853
Validation loss: 1.7667030570327595

Epoch: 6| Step: 4
Training loss: 1.780578374862671
Validation loss: 1.7790612712983163

Epoch: 6| Step: 5
Training loss: 1.450155258178711
Validation loss: 1.7445884584098734

Epoch: 6| Step: 6
Training loss: 1.2688262462615967
Validation loss: 1.7645930205622027

Epoch: 6| Step: 7
Training loss: 1.2884149551391602
Validation loss: 1.7443376715465257

Epoch: 6| Step: 8
Training loss: 1.4230022430419922
Validation loss: 1.7990061429239088

Epoch: 6| Step: 9
Training loss: 0.9544886946678162
Validation loss: 1.7880261969822708

Epoch: 6| Step: 10
Training loss: 0.7485397458076477
Validation loss: 1.798163278128511

Epoch: 6| Step: 11
Training loss: 1.7927038669586182
Validation loss: 1.7832694130559121

Epoch: 6| Step: 12
Training loss: 1.666965126991272
Validation loss: 1.8134784929213985

Epoch: 6| Step: 13
Training loss: 1.2289154529571533
Validation loss: 1.818110901822326

Epoch: 335| Step: 0
Training loss: 1.8643401861190796
Validation loss: 1.822024783780498

Epoch: 6| Step: 1
Training loss: 1.71598219871521
Validation loss: 1.8458384570255075

Epoch: 6| Step: 2
Training loss: 1.1989773511886597
Validation loss: 1.8161116056544806

Epoch: 6| Step: 3
Training loss: 0.7413604855537415
Validation loss: 1.8522123572646931

Epoch: 6| Step: 4
Training loss: 1.3789002895355225
Validation loss: 1.9220180267928748

Epoch: 6| Step: 5
Training loss: 1.2338616847991943
Validation loss: 1.8344353270787064

Epoch: 6| Step: 6
Training loss: 1.287322759628296
Validation loss: 1.8475850679541146

Epoch: 6| Step: 7
Training loss: 0.9083884954452515
Validation loss: 1.8411993288224744

Epoch: 6| Step: 8
Training loss: 1.0633471012115479
Validation loss: 1.8117406739983508

Epoch: 6| Step: 9
Training loss: 1.3918421268463135
Validation loss: 1.818900465965271

Epoch: 6| Step: 10
Training loss: 2.0421650409698486
Validation loss: 1.8132679629069504

Epoch: 6| Step: 11
Training loss: 1.0498133897781372
Validation loss: 1.832553199542466

Epoch: 6| Step: 12
Training loss: 1.4067392349243164
Validation loss: 1.8234269490806005

Epoch: 6| Step: 13
Training loss: 1.2451872825622559
Validation loss: 1.746034567074109

Epoch: 336| Step: 0
Training loss: 1.0047889947891235
Validation loss: 1.7847506987151278

Epoch: 6| Step: 1
Training loss: 1.3322296142578125
Validation loss: 1.772144894446096

Epoch: 6| Step: 2
Training loss: 1.9686431884765625
Validation loss: 1.8427979228317097

Epoch: 6| Step: 3
Training loss: 0.7959279417991638
Validation loss: 1.7732162655040782

Epoch: 6| Step: 4
Training loss: 1.5055524110794067
Validation loss: 1.8163610273791897

Epoch: 6| Step: 5
Training loss: 1.99338960647583
Validation loss: 1.768890114240749

Epoch: 6| Step: 6
Training loss: 1.7161710262298584
Validation loss: 1.7715972828608688

Epoch: 6| Step: 7
Training loss: 1.9529106616973877
Validation loss: 1.7911918214572373

Epoch: 6| Step: 8
Training loss: 0.6370207071304321
Validation loss: 1.7927964489947084

Epoch: 6| Step: 9
Training loss: 1.0993170738220215
Validation loss: 1.7852846717321744

Epoch: 6| Step: 10
Training loss: 0.5001919269561768
Validation loss: 1.7756442408407889

Epoch: 6| Step: 11
Training loss: 1.5066295862197876
Validation loss: 1.8187074020344725

Epoch: 6| Step: 12
Training loss: 1.325616478919983
Validation loss: 1.8496445417404175

Epoch: 6| Step: 13
Training loss: 1.1772191524505615
Validation loss: 1.81671489438703

Epoch: 337| Step: 0
Training loss: 1.1534919738769531
Validation loss: 1.787469849791578

Epoch: 6| Step: 1
Training loss: 1.3130353689193726
Validation loss: 1.7987065622883458

Epoch: 6| Step: 2
Training loss: 1.4373782873153687
Validation loss: 1.7842059186709824

Epoch: 6| Step: 3
Training loss: 0.9755566716194153
Validation loss: 1.8154642453757666

Epoch: 6| Step: 4
Training loss: 1.1721563339233398
Validation loss: 1.8295959016328216

Epoch: 6| Step: 5
Training loss: 1.089614748954773
Validation loss: 1.794600853355982

Epoch: 6| Step: 6
Training loss: 1.6570806503295898
Validation loss: 1.8103572848022624

Epoch: 6| Step: 7
Training loss: 1.3233245611190796
Validation loss: 1.7693481829858595

Epoch: 6| Step: 8
Training loss: 1.4500540494918823
Validation loss: 1.7731199956709338

Epoch: 6| Step: 9
Training loss: 1.1951243877410889
Validation loss: 1.7449924574103406

Epoch: 6| Step: 10
Training loss: 1.7539620399475098
Validation loss: 1.8062546381386377

Epoch: 6| Step: 11
Training loss: 1.67940354347229
Validation loss: 1.76717625382126

Epoch: 6| Step: 12
Training loss: 0.9610119462013245
Validation loss: 1.7768237834335656

Epoch: 6| Step: 13
Training loss: 1.002708077430725
Validation loss: 1.8336382360868557

Epoch: 338| Step: 0
Training loss: 0.7794290781021118
Validation loss: 1.7983519838702293

Epoch: 6| Step: 1
Training loss: 1.6112463474273682
Validation loss: 1.8247697532817881

Epoch: 6| Step: 2
Training loss: 1.3685901165008545
Validation loss: 1.8487048854110062

Epoch: 6| Step: 3
Training loss: 0.8931026458740234
Validation loss: 1.7891115616726618

Epoch: 6| Step: 4
Training loss: 1.680487871170044
Validation loss: 1.8078127279076526

Epoch: 6| Step: 5
Training loss: 1.7466797828674316
Validation loss: 1.7849929191732918

Epoch: 6| Step: 6
Training loss: 1.2426495552062988
Validation loss: 1.7988788274026686

Epoch: 6| Step: 7
Training loss: 1.299680233001709
Validation loss: 1.8171362364163963

Epoch: 6| Step: 8
Training loss: 0.9042657017707825
Validation loss: 1.7700712424452587

Epoch: 6| Step: 9
Training loss: 1.5284829139709473
Validation loss: 1.8237644267338577

Epoch: 6| Step: 10
Training loss: 1.2195918560028076
Validation loss: 1.7941059156130719

Epoch: 6| Step: 11
Training loss: 1.7514346837997437
Validation loss: 1.8221483922773791

Epoch: 6| Step: 12
Training loss: 1.2014524936676025
Validation loss: 1.787783004904306

Epoch: 6| Step: 13
Training loss: 1.0924360752105713
Validation loss: 1.8260824129145632

Epoch: 339| Step: 0
Training loss: 1.2776051759719849
Validation loss: 1.817642299077844

Epoch: 6| Step: 1
Training loss: 0.9328259229660034
Validation loss: 1.8006447207543157

Epoch: 6| Step: 2
Training loss: 1.8505573272705078
Validation loss: 1.780156716223686

Epoch: 6| Step: 3
Training loss: 1.212022066116333
Validation loss: 1.8213476352794196

Epoch: 6| Step: 4
Training loss: 1.6522704362869263
Validation loss: 1.813843245147377

Epoch: 6| Step: 5
Training loss: 1.473451018333435
Validation loss: 1.7831725907582108

Epoch: 6| Step: 6
Training loss: 1.0475866794586182
Validation loss: 1.8076340357462566

Epoch: 6| Step: 7
Training loss: 1.0081560611724854
Validation loss: 1.7730500057179441

Epoch: 6| Step: 8
Training loss: 1.377924919128418
Validation loss: 1.7473940464758104

Epoch: 6| Step: 9
Training loss: 1.0899418592453003
Validation loss: 1.7974636567536222

Epoch: 6| Step: 10
Training loss: 1.1749768257141113
Validation loss: 1.7890576316464333

Epoch: 6| Step: 11
Training loss: 1.0822535753250122
Validation loss: 1.8102497939140565

Epoch: 6| Step: 12
Training loss: 1.1851024627685547
Validation loss: 1.7925599134096535

Epoch: 6| Step: 13
Training loss: 2.6453874111175537
Validation loss: 1.8328555732645013

Epoch: 340| Step: 0
Training loss: 1.1816298961639404
Validation loss: 1.7945897527920303

Epoch: 6| Step: 1
Training loss: 2.296933650970459
Validation loss: 1.8456668584577498

Epoch: 6| Step: 2
Training loss: 1.0920851230621338
Validation loss: 1.8253892596049974

Epoch: 6| Step: 3
Training loss: 1.3685309886932373
Validation loss: 1.838410517220856

Epoch: 6| Step: 4
Training loss: 1.5002105236053467
Validation loss: 1.7910263384542158

Epoch: 6| Step: 5
Training loss: 0.9025698900222778
Validation loss: 1.8091877327170423

Epoch: 6| Step: 6
Training loss: 0.8226525187492371
Validation loss: 1.8437236919197986

Epoch: 6| Step: 7
Training loss: 1.7075700759887695
Validation loss: 1.791488137296451

Epoch: 6| Step: 8
Training loss: 1.3931159973144531
Validation loss: 1.792917674587619

Epoch: 6| Step: 9
Training loss: 1.303885817527771
Validation loss: 1.7958543159628426

Epoch: 6| Step: 10
Training loss: 1.2181729078292847
Validation loss: 1.714455573789535

Epoch: 6| Step: 11
Training loss: 1.0399656295776367
Validation loss: 1.787677470073905

Epoch: 6| Step: 12
Training loss: 1.42464017868042
Validation loss: 1.768876124453801

Epoch: 6| Step: 13
Training loss: 1.1373802423477173
Validation loss: 1.838328476875059

Epoch: 341| Step: 0
Training loss: 0.7546758055686951
Validation loss: 1.780005124307448

Epoch: 6| Step: 1
Training loss: 2.073307514190674
Validation loss: 1.7579955157413278

Epoch: 6| Step: 2
Training loss: 1.4772052764892578
Validation loss: 1.7780383094664542

Epoch: 6| Step: 3
Training loss: 1.258490800857544
Validation loss: 1.7992162319921678

Epoch: 6| Step: 4
Training loss: 1.4142272472381592
Validation loss: 1.8098621009498514

Epoch: 6| Step: 5
Training loss: 1.0183554887771606
Validation loss: 1.8387981307122014

Epoch: 6| Step: 6
Training loss: 1.2122775316238403
Validation loss: 1.7698085231165732

Epoch: 6| Step: 7
Training loss: 1.5894324779510498
Validation loss: 1.8120960548359861

Epoch: 6| Step: 8
Training loss: 1.8817170858383179
Validation loss: 1.784624743205245

Epoch: 6| Step: 9
Training loss: 0.9092587232589722
Validation loss: 1.7814192374547322

Epoch: 6| Step: 10
Training loss: 0.8634426593780518
Validation loss: 1.775360147158305

Epoch: 6| Step: 11
Training loss: 1.5291019678115845
Validation loss: 1.7945506239450106

Epoch: 6| Step: 12
Training loss: 0.7306779623031616
Validation loss: 1.7820660862871396

Epoch: 6| Step: 13
Training loss: 1.4213448762893677
Validation loss: 1.821403931545955

Epoch: 342| Step: 0
Training loss: 1.439129114151001
Validation loss: 1.777013042921661

Epoch: 6| Step: 1
Training loss: 0.980888307094574
Validation loss: 1.8066012115888699

Epoch: 6| Step: 2
Training loss: 0.744613528251648
Validation loss: 1.7842862259957097

Epoch: 6| Step: 3
Training loss: 1.3942029476165771
Validation loss: 1.7866927398148404

Epoch: 6| Step: 4
Training loss: 1.6786431074142456
Validation loss: 1.7683398121146745

Epoch: 6| Step: 5
Training loss: 1.1896288394927979
Validation loss: 1.7636759486249698

Epoch: 6| Step: 6
Training loss: 1.2175283432006836
Validation loss: 1.7883162472837715

Epoch: 6| Step: 7
Training loss: 1.330789566040039
Validation loss: 1.7692088683446248

Epoch: 6| Step: 8
Training loss: 1.371148943901062
Validation loss: 1.805988847568471

Epoch: 6| Step: 9
Training loss: 1.170626163482666
Validation loss: 1.7882211887708275

Epoch: 6| Step: 10
Training loss: 1.3183951377868652
Validation loss: 1.8145015393534014

Epoch: 6| Step: 11
Training loss: 1.0884019136428833
Validation loss: 1.7835458542710991

Epoch: 6| Step: 12
Training loss: 1.4961671829223633
Validation loss: 1.7755508422851562

Epoch: 6| Step: 13
Training loss: 2.051551580429077
Validation loss: 1.8335538730826428

Epoch: 343| Step: 0
Training loss: 1.574520230293274
Validation loss: 1.8241933789304507

Epoch: 6| Step: 1
Training loss: 1.157252311706543
Validation loss: 1.8062984661389423

Epoch: 6| Step: 2
Training loss: 0.9330456256866455
Validation loss: 1.786500846185992

Epoch: 6| Step: 3
Training loss: 1.747999668121338
Validation loss: 1.8196549992407522

Epoch: 6| Step: 4
Training loss: 1.5668953657150269
Validation loss: 1.7906608812270626

Epoch: 6| Step: 5
Training loss: 1.3072103261947632
Validation loss: 1.7898885973038212

Epoch: 6| Step: 6
Training loss: 1.192988634109497
Validation loss: 1.8443765550531366

Epoch: 6| Step: 7
Training loss: 1.4631319046020508
Validation loss: 1.8195229063751877

Epoch: 6| Step: 8
Training loss: 1.1354506015777588
Validation loss: 1.782343323512744

Epoch: 6| Step: 9
Training loss: 1.3173291683197021
Validation loss: 1.7672321296507312

Epoch: 6| Step: 10
Training loss: 1.328093409538269
Validation loss: 1.8574335882740636

Epoch: 6| Step: 11
Training loss: 1.54728364944458
Validation loss: 1.8157751329483525

Epoch: 6| Step: 12
Training loss: 1.3927710056304932
Validation loss: 1.861859647176599

Epoch: 6| Step: 13
Training loss: 0.9863980412483215
Validation loss: 1.8053919679375106

Epoch: 344| Step: 0
Training loss: 1.1174966096878052
Validation loss: 1.8063340904892131

Epoch: 6| Step: 1
Training loss: 1.4841716289520264
Validation loss: 1.7899198570559103

Epoch: 6| Step: 2
Training loss: 1.1196177005767822
Validation loss: 1.7736258506774902

Epoch: 6| Step: 3
Training loss: 1.2817710638046265
Validation loss: 1.7961360639141453

Epoch: 6| Step: 4
Training loss: 1.623689889907837
Validation loss: 1.8061141173044841

Epoch: 6| Step: 5
Training loss: 1.3009788990020752
Validation loss: 1.8179851501218733

Epoch: 6| Step: 6
Training loss: 1.152465581893921
Validation loss: 1.8463760140121623

Epoch: 6| Step: 7
Training loss: 1.148730993270874
Validation loss: 1.8093089096007808

Epoch: 6| Step: 8
Training loss: 1.6204460859298706
Validation loss: 1.740394256448233

Epoch: 6| Step: 9
Training loss: 1.5229947566986084
Validation loss: 1.7838096003378592

Epoch: 6| Step: 10
Training loss: 0.7388591766357422
Validation loss: 1.7634923176098896

Epoch: 6| Step: 11
Training loss: 1.6066861152648926
Validation loss: 1.8286154987991496

Epoch: 6| Step: 12
Training loss: 1.4270728826522827
Validation loss: 1.7942664366896435

Epoch: 6| Step: 13
Training loss: 0.8607116937637329
Validation loss: 1.8247087206891788

Epoch: 345| Step: 0
Training loss: 0.9768810272216797
Validation loss: 1.8397668305263724

Epoch: 6| Step: 1
Training loss: 1.9180102348327637
Validation loss: 1.8356862247631114

Epoch: 6| Step: 2
Training loss: 1.0122439861297607
Validation loss: 1.8571620513034124

Epoch: 6| Step: 3
Training loss: 1.632732629776001
Validation loss: 1.7782690063599618

Epoch: 6| Step: 4
Training loss: 1.0930107831954956
Validation loss: 1.8348405950812883

Epoch: 6| Step: 5
Training loss: 1.2568447589874268
Validation loss: 1.7905601006682201

Epoch: 6| Step: 6
Training loss: 1.450974941253662
Validation loss: 1.8321596037956975

Epoch: 6| Step: 7
Training loss: 1.6693782806396484
Validation loss: 1.7777235123418993

Epoch: 6| Step: 8
Training loss: 1.4485783576965332
Validation loss: 1.7990493851323281

Epoch: 6| Step: 9
Training loss: 1.466015100479126
Validation loss: 1.7369442165538829

Epoch: 6| Step: 10
Training loss: 1.061051845550537
Validation loss: 1.7691357789501068

Epoch: 6| Step: 11
Training loss: 0.868146538734436
Validation loss: 1.7198291799073577

Epoch: 6| Step: 12
Training loss: 0.837409257888794
Validation loss: 1.8018497997714626

Epoch: 6| Step: 13
Training loss: 1.8600811958312988
Validation loss: 1.791071634138784

Epoch: 346| Step: 0
Training loss: 1.8180716037750244
Validation loss: 1.7940905555602042

Epoch: 6| Step: 1
Training loss: 1.186784267425537
Validation loss: 1.794125747937028

Epoch: 6| Step: 2
Training loss: 1.2610864639282227
Validation loss: 1.8046269224536033

Epoch: 6| Step: 3
Training loss: 1.3304903507232666
Validation loss: 1.805091037545153

Epoch: 6| Step: 4
Training loss: 0.976201057434082
Validation loss: 1.7558857035893265

Epoch: 6| Step: 5
Training loss: 1.453871488571167
Validation loss: 1.794821664851199

Epoch: 6| Step: 6
Training loss: 1.1438298225402832
Validation loss: 1.8236085907105477

Epoch: 6| Step: 7
Training loss: 1.3633201122283936
Validation loss: 1.8042279917706725

Epoch: 6| Step: 8
Training loss: 1.6211494207382202
Validation loss: 1.7823434863039243

Epoch: 6| Step: 9
Training loss: 0.967846155166626
Validation loss: 1.805697802574404

Epoch: 6| Step: 10
Training loss: 1.6555428504943848
Validation loss: 1.763828528824673

Epoch: 6| Step: 11
Training loss: 1.2906023263931274
Validation loss: 1.7904803983626827

Epoch: 6| Step: 12
Training loss: 0.7356199622154236
Validation loss: 1.8337466729584562

Epoch: 6| Step: 13
Training loss: 1.235034465789795
Validation loss: 1.8059977280196322

Epoch: 347| Step: 0
Training loss: 1.2848026752471924
Validation loss: 1.792844888984516

Epoch: 6| Step: 1
Training loss: 1.1455378532409668
Validation loss: 1.7677981263847762

Epoch: 6| Step: 2
Training loss: 1.5059528350830078
Validation loss: 1.7982684899401922

Epoch: 6| Step: 3
Training loss: 0.7768733501434326
Validation loss: 1.833113871594911

Epoch: 6| Step: 4
Training loss: 0.7875462770462036
Validation loss: 1.7711089080379856

Epoch: 6| Step: 5
Training loss: 1.1985670328140259
Validation loss: 1.8359494260562363

Epoch: 6| Step: 6
Training loss: 0.8344165682792664
Validation loss: 1.8269498886600617

Epoch: 6| Step: 7
Training loss: 1.5317655801773071
Validation loss: 1.7895081248334659

Epoch: 6| Step: 8
Training loss: 0.8792018890380859
Validation loss: 1.8154962242290538

Epoch: 6| Step: 9
Training loss: 2.0803871154785156
Validation loss: 1.7814950699447303

Epoch: 6| Step: 10
Training loss: 1.7138826847076416
Validation loss: 1.8135360851082751

Epoch: 6| Step: 11
Training loss: 1.2707847356796265
Validation loss: 1.7842871142971901

Epoch: 6| Step: 12
Training loss: 1.3674358129501343
Validation loss: 1.8097564533192625

Epoch: 6| Step: 13
Training loss: 1.085835337638855
Validation loss: 1.8214172906773065

Epoch: 348| Step: 0
Training loss: 2.1640119552612305
Validation loss: 1.7884733984547276

Epoch: 6| Step: 1
Training loss: 1.3407001495361328
Validation loss: 1.786615393495047

Epoch: 6| Step: 2
Training loss: 1.70413339138031
Validation loss: 1.7699143450747254

Epoch: 6| Step: 3
Training loss: 0.8839733600616455
Validation loss: 1.7854956119291243

Epoch: 6| Step: 4
Training loss: 1.1147761344909668
Validation loss: 1.7791788988215949

Epoch: 6| Step: 5
Training loss: 1.447686791419983
Validation loss: 1.7895875618021975

Epoch: 6| Step: 6
Training loss: 0.8273248672485352
Validation loss: 1.8044600871301466

Epoch: 6| Step: 7
Training loss: 1.420135736465454
Validation loss: 1.7754553364169212

Epoch: 6| Step: 8
Training loss: 1.510773777961731
Validation loss: 1.8201435855639878

Epoch: 6| Step: 9
Training loss: 1.357076644897461
Validation loss: 1.8221757693957257

Epoch: 6| Step: 10
Training loss: 0.8219159245491028
Validation loss: 1.8323858694363666

Epoch: 6| Step: 11
Training loss: 1.431659460067749
Validation loss: 1.8173898573844665

Epoch: 6| Step: 12
Training loss: 1.4115922451019287
Validation loss: 1.8267284759911158

Epoch: 6| Step: 13
Training loss: 0.8364653587341309
Validation loss: 1.8724522116363689

Epoch: 349| Step: 0
Training loss: 1.4671952724456787
Validation loss: 1.8659186440129434

Epoch: 6| Step: 1
Training loss: 1.142441987991333
Validation loss: 1.835740061216457

Epoch: 6| Step: 2
Training loss: 1.248528003692627
Validation loss: 1.8514727892414216

Epoch: 6| Step: 3
Training loss: 1.5345687866210938
Validation loss: 1.8101502605663833

Epoch: 6| Step: 4
Training loss: 1.7026547193527222
Validation loss: 1.803551003497134

Epoch: 6| Step: 5
Training loss: 0.8018813133239746
Validation loss: 1.7791130978574035

Epoch: 6| Step: 6
Training loss: 1.4426963329315186
Validation loss: 1.7759578740724953

Epoch: 6| Step: 7
Training loss: 1.23966383934021
Validation loss: 1.8297109155244724

Epoch: 6| Step: 8
Training loss: 1.4989380836486816
Validation loss: 1.8054778729715655

Epoch: 6| Step: 9
Training loss: 1.479407787322998
Validation loss: 1.7509411701592066

Epoch: 6| Step: 10
Training loss: 1.5601956844329834
Validation loss: 1.8096137764633342

Epoch: 6| Step: 11
Training loss: 0.6953748464584351
Validation loss: 1.7624308909139326

Epoch: 6| Step: 12
Training loss: 0.7313365936279297
Validation loss: 1.810657221783874

Epoch: 6| Step: 13
Training loss: 1.1843668222427368
Validation loss: 1.804951088402861

Epoch: 350| Step: 0
Training loss: 0.9980432987213135
Validation loss: 1.7969149517756637

Epoch: 6| Step: 1
Training loss: 1.6897873878479004
Validation loss: 1.7656847571813932

Epoch: 6| Step: 2
Training loss: 1.4030160903930664
Validation loss: 1.7780875582848825

Epoch: 6| Step: 3
Training loss: 0.7221633791923523
Validation loss: 1.8052442945459837

Epoch: 6| Step: 4
Training loss: 1.1944761276245117
Validation loss: 1.7901624018146145

Epoch: 6| Step: 5
Training loss: 0.9561746120452881
Validation loss: 1.7847494694494432

Epoch: 6| Step: 6
Training loss: 0.7077128291130066
Validation loss: 1.7254163885629306

Epoch: 6| Step: 7
Training loss: 1.1037427186965942
Validation loss: 1.8119111894279398

Epoch: 6| Step: 8
Training loss: 1.5338921546936035
Validation loss: 1.7566565339283278

Epoch: 6| Step: 9
Training loss: 0.9417634010314941
Validation loss: 1.7904336439665927

Epoch: 6| Step: 10
Training loss: 2.058842182159424
Validation loss: 1.8003075750925208

Epoch: 6| Step: 11
Training loss: 1.38858163356781
Validation loss: 1.7718450330918836

Epoch: 6| Step: 12
Training loss: 1.1605384349822998
Validation loss: 1.7506124511841805

Epoch: 6| Step: 13
Training loss: 1.6476579904556274
Validation loss: 1.8477398144301547

Epoch: 351| Step: 0
Training loss: 1.271221399307251
Validation loss: 1.7895930736295638

Epoch: 6| Step: 1
Training loss: 2.0600504875183105
Validation loss: 1.7755487439452962

Epoch: 6| Step: 2
Training loss: 0.8799546957015991
Validation loss: 1.809247378380068

Epoch: 6| Step: 3
Training loss: 1.3579450845718384
Validation loss: 1.7944367534370833

Epoch: 6| Step: 4
Training loss: 1.0740782022476196
Validation loss: 1.812251861377429

Epoch: 6| Step: 5
Training loss: 1.5420916080474854
Validation loss: 1.8418825352063743

Epoch: 6| Step: 6
Training loss: 1.3011447191238403
Validation loss: 1.8070855832869006

Epoch: 6| Step: 7
Training loss: 1.0064282417297363
Validation loss: 1.8257227943789573

Epoch: 6| Step: 8
Training loss: 1.5762227773666382
Validation loss: 1.8495734417310326

Epoch: 6| Step: 9
Training loss: 1.0300747156143188
Validation loss: 1.794389755495133

Epoch: 6| Step: 10
Training loss: 1.3259559869766235
Validation loss: 1.816518646414562

Epoch: 6| Step: 11
Training loss: 0.9047919511795044
Validation loss: 1.8342132811905236

Epoch: 6| Step: 12
Training loss: 1.4463828802108765
Validation loss: 1.8017579932366647

Epoch: 6| Step: 13
Training loss: 1.0669264793395996
Validation loss: 1.8425218469353133

Epoch: 352| Step: 0
Training loss: 1.0815144777297974
Validation loss: 1.7501051220842587

Epoch: 6| Step: 1
Training loss: 1.0218178033828735
Validation loss: 1.785913295643304

Epoch: 6| Step: 2
Training loss: 1.8482359647750854
Validation loss: 1.7778545630875455

Epoch: 6| Step: 3
Training loss: 1.1817655563354492
Validation loss: 1.7372254133224487

Epoch: 6| Step: 4
Training loss: 0.922933042049408
Validation loss: 1.7800952824213172

Epoch: 6| Step: 5
Training loss: 1.5322728157043457
Validation loss: 1.7131640782920263

Epoch: 6| Step: 6
Training loss: 1.2220706939697266
Validation loss: 1.7667750850800545

Epoch: 6| Step: 7
Training loss: 1.0561213493347168
Validation loss: 1.7860296772372337

Epoch: 6| Step: 8
Training loss: 1.401894211769104
Validation loss: 1.804269604785468

Epoch: 6| Step: 9
Training loss: 0.8881903290748596
Validation loss: 1.8481300236076437

Epoch: 6| Step: 10
Training loss: 1.8553791046142578
Validation loss: 1.7843043086349324

Epoch: 6| Step: 11
Training loss: 1.5043365955352783
Validation loss: 1.7729983483591387

Epoch: 6| Step: 12
Training loss: 1.0221753120422363
Validation loss: 1.7688747605969828

Epoch: 6| Step: 13
Training loss: 1.4162675142288208
Validation loss: 1.8048698979039346

Epoch: 353| Step: 0
Training loss: 1.4344408512115479
Validation loss: 1.7765591388107629

Epoch: 6| Step: 1
Training loss: 1.2618428468704224
Validation loss: 1.8066491785869803

Epoch: 6| Step: 2
Training loss: 0.9009515047073364
Validation loss: 1.7519801701268842

Epoch: 6| Step: 3
Training loss: 1.1699163913726807
Validation loss: 1.7882374127705891

Epoch: 6| Step: 4
Training loss: 0.9991101026535034
Validation loss: 1.7956599855935702

Epoch: 6| Step: 5
Training loss: 1.2320106029510498
Validation loss: 1.8254369381935365

Epoch: 6| Step: 6
Training loss: 1.6157591342926025
Validation loss: 1.7751069812364475

Epoch: 6| Step: 7
Training loss: 1.4504280090332031
Validation loss: 1.829881743718219

Epoch: 6| Step: 8
Training loss: 1.2332509756088257
Validation loss: 1.7631965837171

Epoch: 6| Step: 9
Training loss: 1.2922179698944092
Validation loss: 1.7969886243984263

Epoch: 6| Step: 10
Training loss: 1.2771716117858887
Validation loss: 1.7452852828528291

Epoch: 6| Step: 11
Training loss: 1.4790911674499512
Validation loss: 1.7637609897121307

Epoch: 6| Step: 12
Training loss: 0.7648102641105652
Validation loss: 1.821058150260679

Epoch: 6| Step: 13
Training loss: 2.0562973022460938
Validation loss: 1.8184559550336612

Epoch: 354| Step: 0
Training loss: 1.56903076171875
Validation loss: 1.7452794941522742

Epoch: 6| Step: 1
Training loss: 0.8268650770187378
Validation loss: 1.7676340200567757

Epoch: 6| Step: 2
Training loss: 0.9395501017570496
Validation loss: 1.7388772477385819

Epoch: 6| Step: 3
Training loss: 1.0025297403335571
Validation loss: 1.7779985217637913

Epoch: 6| Step: 4
Training loss: 1.743262767791748
Validation loss: 1.7718943062648977

Epoch: 6| Step: 5
Training loss: 1.1960978507995605
Validation loss: 1.7804138634794502

Epoch: 6| Step: 6
Training loss: 1.472278356552124
Validation loss: 1.799359239557738

Epoch: 6| Step: 7
Training loss: 1.4017083644866943
Validation loss: 1.8077245181606663

Epoch: 6| Step: 8
Training loss: 1.0280673503875732
Validation loss: 1.801602308468152

Epoch: 6| Step: 9
Training loss: 0.9720839858055115
Validation loss: 1.7736296192292245

Epoch: 6| Step: 10
Training loss: 1.4052330255508423
Validation loss: 1.7783170669309554

Epoch: 6| Step: 11
Training loss: 1.1759573221206665
Validation loss: 1.773437548709172

Epoch: 6| Step: 12
Training loss: 1.1984529495239258
Validation loss: 1.7909853894223449

Epoch: 6| Step: 13
Training loss: 1.8041987419128418
Validation loss: 1.7781618730996245

Epoch: 355| Step: 0
Training loss: 1.4580332040786743
Validation loss: 1.7760922665237098

Epoch: 6| Step: 1
Training loss: 1.09096360206604
Validation loss: 1.814405543829805

Epoch: 6| Step: 2
Training loss: 1.3402976989746094
Validation loss: 1.7846875767554007

Epoch: 6| Step: 3
Training loss: 0.8627094030380249
Validation loss: 1.7469967860047535

Epoch: 6| Step: 4
Training loss: 0.9882714748382568
Validation loss: 1.7280263811029413

Epoch: 6| Step: 5
Training loss: 1.4040058851242065
Validation loss: 1.7844119123233262

Epoch: 6| Step: 6
Training loss: 1.4883174896240234
Validation loss: 1.7998029467880086

Epoch: 6| Step: 7
Training loss: 0.9548441767692566
Validation loss: 1.7841654182762228

Epoch: 6| Step: 8
Training loss: 1.6328457593917847
Validation loss: 1.8015477862409366

Epoch: 6| Step: 9
Training loss: 1.4218112230300903
Validation loss: 1.7965508507144066

Epoch: 6| Step: 10
Training loss: 0.9564635753631592
Validation loss: 1.837923893364527

Epoch: 6| Step: 11
Training loss: 1.1836403608322144
Validation loss: 1.8088601122620285

Epoch: 6| Step: 12
Training loss: 1.3956350088119507
Validation loss: 1.7997471183858893

Epoch: 6| Step: 13
Training loss: 1.7039152383804321
Validation loss: 1.7544975101306874

Epoch: 356| Step: 0
Training loss: 0.8811356425285339
Validation loss: 1.7859353442345896

Epoch: 6| Step: 1
Training loss: 1.0249269008636475
Validation loss: 1.754256453565372

Epoch: 6| Step: 2
Training loss: 0.8487858772277832
Validation loss: 1.737941998307423

Epoch: 6| Step: 3
Training loss: 0.8859675526618958
Validation loss: 1.8001471001614806

Epoch: 6| Step: 4
Training loss: 1.305168628692627
Validation loss: 1.8643620219281924

Epoch: 6| Step: 5
Training loss: 0.888044536113739
Validation loss: 1.7734845684420677

Epoch: 6| Step: 6
Training loss: 1.2744112014770508
Validation loss: 1.7423230730077273

Epoch: 6| Step: 7
Training loss: 1.1310451030731201
Validation loss: 1.7170497768668718

Epoch: 6| Step: 8
Training loss: 1.3615535497665405
Validation loss: 1.7549923286643079

Epoch: 6| Step: 9
Training loss: 2.132976770401001
Validation loss: 1.7895647146368538

Epoch: 6| Step: 10
Training loss: 1.3633019924163818
Validation loss: 1.8248847300006497

Epoch: 6| Step: 11
Training loss: 1.0526105165481567
Validation loss: 1.80487230003521

Epoch: 6| Step: 12
Training loss: 1.846984624862671
Validation loss: 1.773125167815916

Epoch: 6| Step: 13
Training loss: 1.4517507553100586
Validation loss: 1.7965744054445656

Epoch: 357| Step: 0
Training loss: 1.4223570823669434
Validation loss: 1.7880713157756354

Epoch: 6| Step: 1
Training loss: 1.19053053855896
Validation loss: 1.7448603004537604

Epoch: 6| Step: 2
Training loss: 1.5019103288650513
Validation loss: 1.766209069118705

Epoch: 6| Step: 3
Training loss: 0.984734058380127
Validation loss: 1.7856944171331262

Epoch: 6| Step: 4
Training loss: 1.0741608142852783
Validation loss: 1.8251672008986115

Epoch: 6| Step: 5
Training loss: 1.2494630813598633
Validation loss: 1.7826037970922326

Epoch: 6| Step: 6
Training loss: 1.3163341283798218
Validation loss: 1.7410501177592943

Epoch: 6| Step: 7
Training loss: 1.307691216468811
Validation loss: 1.7496173548442062

Epoch: 6| Step: 8
Training loss: 0.8725746870040894
Validation loss: 1.8124908119119623

Epoch: 6| Step: 9
Training loss: 1.0855505466461182
Validation loss: 1.7451832217554892

Epoch: 6| Step: 10
Training loss: 1.6563310623168945
Validation loss: 1.754986588672925

Epoch: 6| Step: 11
Training loss: 1.5892444849014282
Validation loss: 1.7575374880144674

Epoch: 6| Step: 12
Training loss: 1.196028709411621
Validation loss: 1.751566534401268

Epoch: 6| Step: 13
Training loss: 0.9311418533325195
Validation loss: 1.7585861849528488

Epoch: 358| Step: 0
Training loss: 1.0742182731628418
Validation loss: 1.8237269975805794

Epoch: 6| Step: 1
Training loss: 1.2768659591674805
Validation loss: 1.819837301008163

Epoch: 6| Step: 2
Training loss: 1.047843337059021
Validation loss: 1.8073742158951298

Epoch: 6| Step: 3
Training loss: 1.4377703666687012
Validation loss: 1.8587475053725704

Epoch: 6| Step: 4
Training loss: 1.6636325120925903
Validation loss: 1.8737318823414464

Epoch: 6| Step: 5
Training loss: 2.0542571544647217
Validation loss: 1.8878003679296023

Epoch: 6| Step: 6
Training loss: 1.354994773864746
Validation loss: 1.880235678406172

Epoch: 6| Step: 7
Training loss: 0.6859308481216431
Validation loss: 1.8744309384335753

Epoch: 6| Step: 8
Training loss: 1.3827834129333496
Validation loss: 1.8369450569152832

Epoch: 6| Step: 9
Training loss: 0.9353853464126587
Validation loss: 1.8095519260693622

Epoch: 6| Step: 10
Training loss: 1.4447259902954102
Validation loss: 1.7906035338678667

Epoch: 6| Step: 11
Training loss: 1.0911452770233154
Validation loss: 1.7349311677358483

Epoch: 6| Step: 12
Training loss: 0.7258443236351013
Validation loss: 1.7585574183412778

Epoch: 6| Step: 13
Training loss: 1.8676024675369263
Validation loss: 1.8036722765173963

Epoch: 359| Step: 0
Training loss: 0.861791729927063
Validation loss: 1.7407672559061358

Epoch: 6| Step: 1
Training loss: 1.0767855644226074
Validation loss: 1.7565321973575059

Epoch: 6| Step: 2
Training loss: 1.2379162311553955
Validation loss: 1.7816535388269732

Epoch: 6| Step: 3
Training loss: 1.6772624254226685
Validation loss: 1.8308408196254442

Epoch: 6| Step: 4
Training loss: 1.2939634323120117
Validation loss: 1.8454498847325642

Epoch: 6| Step: 5
Training loss: 1.2636773586273193
Validation loss: 1.8052556848013273

Epoch: 6| Step: 6
Training loss: 1.630350947380066
Validation loss: 1.7574828901598532

Epoch: 6| Step: 7
Training loss: 1.1692053079605103
Validation loss: 1.7877579709535003

Epoch: 6| Step: 8
Training loss: 1.0035616159439087
Validation loss: 1.7514901507285334

Epoch: 6| Step: 9
Training loss: 1.3566486835479736
Validation loss: 1.798943567019637

Epoch: 6| Step: 10
Training loss: 1.035295009613037
Validation loss: 1.808329015649775

Epoch: 6| Step: 11
Training loss: 1.4089875221252441
Validation loss: 1.7673754269076931

Epoch: 6| Step: 12
Training loss: 1.0791230201721191
Validation loss: 1.8019256784069924

Epoch: 6| Step: 13
Training loss: 1.408341884613037
Validation loss: 1.8290883212961175

Epoch: 360| Step: 0
Training loss: 1.3148407936096191
Validation loss: 1.8404659840368456

Epoch: 6| Step: 1
Training loss: 1.4623135328292847
Validation loss: 1.835783245742962

Epoch: 6| Step: 2
Training loss: 1.2575350999832153
Validation loss: 1.773165798956348

Epoch: 6| Step: 3
Training loss: 0.8961367607116699
Validation loss: 1.8215177674447336

Epoch: 6| Step: 4
Training loss: 1.3488068580627441
Validation loss: 1.8420656214478195

Epoch: 6| Step: 5
Training loss: 1.2259496450424194
Validation loss: 1.7964342448019213

Epoch: 6| Step: 6
Training loss: 1.4512752294540405
Validation loss: 1.8430043856302898

Epoch: 6| Step: 7
Training loss: 1.4357982873916626
Validation loss: 1.8414927913296608

Epoch: 6| Step: 8
Training loss: 1.1793464422225952
Validation loss: 1.8280516516777776

Epoch: 6| Step: 9
Training loss: 1.8387680053710938
Validation loss: 1.745557121051255

Epoch: 6| Step: 10
Training loss: 0.8083553314208984
Validation loss: 1.789569370208248

Epoch: 6| Step: 11
Training loss: 1.2723608016967773
Validation loss: 1.7829546351586618

Epoch: 6| Step: 12
Training loss: 0.9280904531478882
Validation loss: 1.7868540940746185

Epoch: 6| Step: 13
Training loss: 0.9423300623893738
Validation loss: 1.825191310656968

Epoch: 361| Step: 0
Training loss: 0.6833559274673462
Validation loss: 1.8233420618118779

Epoch: 6| Step: 1
Training loss: 0.7130509614944458
Validation loss: 1.8404590211888796

Epoch: 6| Step: 2
Training loss: 0.6119980216026306
Validation loss: 1.8168183129320863

Epoch: 6| Step: 3
Training loss: 1.8716092109680176
Validation loss: 1.8062437221568117

Epoch: 6| Step: 4
Training loss: 1.4307048320770264
Validation loss: 1.7844551019771124

Epoch: 6| Step: 5
Training loss: 1.9124385118484497
Validation loss: 1.859484382854995

Epoch: 6| Step: 6
Training loss: 1.1824133396148682
Validation loss: 1.8090337784059587

Epoch: 6| Step: 7
Training loss: 1.065300703048706
Validation loss: 1.8033129553641043

Epoch: 6| Step: 8
Training loss: 1.1353142261505127
Validation loss: 1.811253821978005

Epoch: 6| Step: 9
Training loss: 1.1844581365585327
Validation loss: 1.8218838002092095

Epoch: 6| Step: 10
Training loss: 0.9201896786689758
Validation loss: 1.841860145650884

Epoch: 6| Step: 11
Training loss: 1.7615231275558472
Validation loss: 1.814355678455804

Epoch: 6| Step: 12
Training loss: 1.5521881580352783
Validation loss: 1.7764378029813048

Epoch: 6| Step: 13
Training loss: 1.2431868314743042
Validation loss: 1.8366053860674623

Epoch: 362| Step: 0
Training loss: 1.1529018878936768
Validation loss: 1.7849703706720823

Epoch: 6| Step: 1
Training loss: 1.3073620796203613
Validation loss: 1.7996301689455587

Epoch: 6| Step: 2
Training loss: 0.414640337228775
Validation loss: 1.7870076830669115

Epoch: 6| Step: 3
Training loss: 1.344374418258667
Validation loss: 1.7799063433883011

Epoch: 6| Step: 4
Training loss: 1.2182018756866455
Validation loss: 1.7738275553590508

Epoch: 6| Step: 5
Training loss: 1.1677560806274414
Validation loss: 1.751247170150921

Epoch: 6| Step: 6
Training loss: 0.9952290654182434
Validation loss: 1.8040811041350007

Epoch: 6| Step: 7
Training loss: 1.2201769351959229
Validation loss: 1.8207985995918192

Epoch: 6| Step: 8
Training loss: 0.8355808258056641
Validation loss: 1.8296543167483421

Epoch: 6| Step: 9
Training loss: 1.476933240890503
Validation loss: 1.7595343077054588

Epoch: 6| Step: 10
Training loss: 1.905409812927246
Validation loss: 1.7871262924645537

Epoch: 6| Step: 11
Training loss: 1.446223258972168
Validation loss: 1.799845093040056

Epoch: 6| Step: 12
Training loss: 1.533794641494751
Validation loss: 1.799457291121124

Epoch: 6| Step: 13
Training loss: 1.6841551065444946
Validation loss: 1.7748445823628416

Epoch: 363| Step: 0
Training loss: 1.6895115375518799
Validation loss: 1.7678011617352885

Epoch: 6| Step: 1
Training loss: 1.4954293966293335
Validation loss: 1.7583553329590829

Epoch: 6| Step: 2
Training loss: 1.3303858041763306
Validation loss: 1.7882696736243464

Epoch: 6| Step: 3
Training loss: 1.0950684547424316
Validation loss: 1.760586948804958

Epoch: 6| Step: 4
Training loss: 1.4772405624389648
Validation loss: 1.8444762922102405

Epoch: 6| Step: 5
Training loss: 0.6428464651107788
Validation loss: 1.8910998170093825

Epoch: 6| Step: 6
Training loss: 1.4186114072799683
Validation loss: 1.828743766712886

Epoch: 6| Step: 7
Training loss: 1.2202391624450684
Validation loss: 1.7943237109850811

Epoch: 6| Step: 8
Training loss: 0.685753583908081
Validation loss: 1.8444146853621288

Epoch: 6| Step: 9
Training loss: 1.3022425174713135
Validation loss: 1.796519684535201

Epoch: 6| Step: 10
Training loss: 0.9512197971343994
Validation loss: 1.7618208444246681

Epoch: 6| Step: 11
Training loss: 1.8024414777755737
Validation loss: 1.7144309397666686

Epoch: 6| Step: 12
Training loss: 0.9202212691307068
Validation loss: 1.7437469805440595

Epoch: 6| Step: 13
Training loss: 1.1533280611038208
Validation loss: 1.7921477774138093

Epoch: 364| Step: 0
Training loss: 1.6147756576538086
Validation loss: 1.728048465585196

Epoch: 6| Step: 1
Training loss: 1.635376214981079
Validation loss: 1.7751977225785613

Epoch: 6| Step: 2
Training loss: 1.342463493347168
Validation loss: 1.8553391502749534

Epoch: 6| Step: 3
Training loss: 1.2293422222137451
Validation loss: 1.757966128728723

Epoch: 6| Step: 4
Training loss: 0.8061493635177612
Validation loss: 1.799264883482328

Epoch: 6| Step: 5
Training loss: 0.9778623580932617
Validation loss: 1.8069666585614603

Epoch: 6| Step: 6
Training loss: 1.2283320426940918
Validation loss: 1.8057396591350596

Epoch: 6| Step: 7
Training loss: 1.6377863883972168
Validation loss: 1.76095240218665

Epoch: 6| Step: 8
Training loss: 0.8475841879844666
Validation loss: 1.8227964037208146

Epoch: 6| Step: 9
Training loss: 0.7703074812889099
Validation loss: 1.8055900681403376

Epoch: 6| Step: 10
Training loss: 1.623712182044983
Validation loss: 1.8338185779510006

Epoch: 6| Step: 11
Training loss: 1.4026455879211426
Validation loss: 1.7796108466322704

Epoch: 6| Step: 12
Training loss: 0.992342472076416
Validation loss: 1.804887717769992

Epoch: 6| Step: 13
Training loss: 1.2343707084655762
Validation loss: 1.7433692960328953

Epoch: 365| Step: 0
Training loss: 1.3460614681243896
Validation loss: 1.7992075309958508

Epoch: 6| Step: 1
Training loss: 1.5347182750701904
Validation loss: 1.7855259282614595

Epoch: 6| Step: 2
Training loss: 0.9849343299865723
Validation loss: 1.8741698700894591

Epoch: 6| Step: 3
Training loss: 1.0144597291946411
Validation loss: 1.7447054257956884

Epoch: 6| Step: 4
Training loss: 1.2776886224746704
Validation loss: 1.8423693244175245

Epoch: 6| Step: 5
Training loss: 0.4431363344192505
Validation loss: 1.7730243923843547

Epoch: 6| Step: 6
Training loss: 2.287782669067383
Validation loss: 1.7579252386605868

Epoch: 6| Step: 7
Training loss: 0.7042244076728821
Validation loss: 1.8326182903782013

Epoch: 6| Step: 8
Training loss: 1.5848785638809204
Validation loss: 1.827300968990531

Epoch: 6| Step: 9
Training loss: 0.28100019693374634
Validation loss: 1.7644809535754624

Epoch: 6| Step: 10
Training loss: 1.7304601669311523
Validation loss: 1.766054658479588

Epoch: 6| Step: 11
Training loss: 1.898972511291504
Validation loss: 1.8290866754388297

Epoch: 6| Step: 12
Training loss: 1.0045793056488037
Validation loss: 1.7928950607135732

Epoch: 6| Step: 13
Training loss: 1.0690350532531738
Validation loss: 1.7897743576316423

Epoch: 366| Step: 0
Training loss: 1.660597324371338
Validation loss: 1.782411995754447

Epoch: 6| Step: 1
Training loss: 1.5417613983154297
Validation loss: 1.736329977230359

Epoch: 6| Step: 2
Training loss: 1.3529953956604004
Validation loss: 1.786730763732746

Epoch: 6| Step: 3
Training loss: 0.8084959983825684
Validation loss: 1.74784436533528

Epoch: 6| Step: 4
Training loss: 1.020582675933838
Validation loss: 1.7739626515296198

Epoch: 6| Step: 5
Training loss: 0.9331138134002686
Validation loss: 1.8052486937533143

Epoch: 6| Step: 6
Training loss: 1.3442907333374023
Validation loss: 1.7687156020954091

Epoch: 6| Step: 7
Training loss: 1.0770156383514404
Validation loss: 1.7694628251496183

Epoch: 6| Step: 8
Training loss: 0.8737542033195496
Validation loss: 1.8226666142863612

Epoch: 6| Step: 9
Training loss: 1.4577338695526123
Validation loss: 1.7547628289909774

Epoch: 6| Step: 10
Training loss: 1.672476053237915
Validation loss: 1.793885746309834

Epoch: 6| Step: 11
Training loss: 1.6141526699066162
Validation loss: 1.80091219563638

Epoch: 6| Step: 12
Training loss: 0.9957115650177002
Validation loss: 1.78530155715122

Epoch: 6| Step: 13
Training loss: 1.111079216003418
Validation loss: 1.7631522276068246

Epoch: 367| Step: 0
Training loss: 1.3206665515899658
Validation loss: 1.8528105007704867

Epoch: 6| Step: 1
Training loss: 1.070347785949707
Validation loss: 1.8020380068850774

Epoch: 6| Step: 2
Training loss: 0.9168943166732788
Validation loss: 1.8011587986382105

Epoch: 6| Step: 3
Training loss: 0.9542719721794128
Validation loss: 1.809553784708823

Epoch: 6| Step: 4
Training loss: 1.0733447074890137
Validation loss: 1.691932729495469

Epoch: 6| Step: 5
Training loss: 1.4081870317459106
Validation loss: 1.777744871313854

Epoch: 6| Step: 6
Training loss: 1.7608072757720947
Validation loss: 1.7848122094267158

Epoch: 6| Step: 7
Training loss: 1.7245619297027588
Validation loss: 1.7284760846886584

Epoch: 6| Step: 8
Training loss: 1.4886363744735718
Validation loss: 1.7607867615197295

Epoch: 6| Step: 9
Training loss: 1.262109398841858
Validation loss: 1.7910568714141846

Epoch: 6| Step: 10
Training loss: 0.9891868829727173
Validation loss: 1.7876435133718676

Epoch: 6| Step: 11
Training loss: 1.184056282043457
Validation loss: 1.7475717067718506

Epoch: 6| Step: 12
Training loss: 0.7334473133087158
Validation loss: 1.7553125376342444

Epoch: 6| Step: 13
Training loss: 1.2857266664505005
Validation loss: 1.7735368410746257

Epoch: 368| Step: 0
Training loss: 1.4584039449691772
Validation loss: 1.830044698971574

Epoch: 6| Step: 1
Training loss: 1.110652208328247
Validation loss: 1.719242367693173

Epoch: 6| Step: 2
Training loss: 1.511849045753479
Validation loss: 1.745512556004268

Epoch: 6| Step: 3
Training loss: 1.132950782775879
Validation loss: 1.8331476911421745

Epoch: 6| Step: 4
Training loss: 1.4984464645385742
Validation loss: 1.8192402726860457

Epoch: 6| Step: 5
Training loss: 1.392557144165039
Validation loss: 1.77236040945976

Epoch: 6| Step: 6
Training loss: 0.8076190948486328
Validation loss: 1.822054027229227

Epoch: 6| Step: 7
Training loss: 1.5945665836334229
Validation loss: 1.7974077860514324

Epoch: 6| Step: 8
Training loss: 1.2439857721328735
Validation loss: 1.765517116874777

Epoch: 6| Step: 9
Training loss: 0.6728599667549133
Validation loss: 1.7692845226615987

Epoch: 6| Step: 10
Training loss: 1.2190804481506348
Validation loss: 1.7804334291847803

Epoch: 6| Step: 11
Training loss: 1.0076829195022583
Validation loss: 1.7636837523470643

Epoch: 6| Step: 12
Training loss: 1.2848334312438965
Validation loss: 1.7538966683931247

Epoch: 6| Step: 13
Training loss: 1.6950756311416626
Validation loss: 1.7648708435796923

Epoch: 369| Step: 0
Training loss: 0.9364781379699707
Validation loss: 1.8410042139791674

Epoch: 6| Step: 1
Training loss: 0.6209117770195007
Validation loss: 1.7926697038835095

Epoch: 6| Step: 2
Training loss: 1.3061124086380005
Validation loss: 1.7411492947609193

Epoch: 6| Step: 3
Training loss: 1.0145363807678223
Validation loss: 1.7461667868398851

Epoch: 6| Step: 4
Training loss: 1.7304143905639648
Validation loss: 1.7752466368418869

Epoch: 6| Step: 5
Training loss: 1.4047727584838867
Validation loss: 1.7747390270233154

Epoch: 6| Step: 6
Training loss: 0.469821572303772
Validation loss: 1.7803796414406068

Epoch: 6| Step: 7
Training loss: 1.6962343454360962
Validation loss: 1.7877670154776624

Epoch: 6| Step: 8
Training loss: 1.4746373891830444
Validation loss: 1.7701649845287364

Epoch: 6| Step: 9
Training loss: 1.1510332822799683
Validation loss: 1.7788524204684841

Epoch: 6| Step: 10
Training loss: 1.3350424766540527
Validation loss: 1.741282009309338

Epoch: 6| Step: 11
Training loss: 1.0369889736175537
Validation loss: 1.7986584119899298

Epoch: 6| Step: 12
Training loss: 1.2362271547317505
Validation loss: 1.807736095561776

Epoch: 6| Step: 13
Training loss: 2.1870369911193848
Validation loss: 1.7584757163960447

Epoch: 370| Step: 0
Training loss: 1.5968141555786133
Validation loss: 1.791236231403966

Epoch: 6| Step: 1
Training loss: 1.3166377544403076
Validation loss: 1.7907617579224289

Epoch: 6| Step: 2
Training loss: 1.060642123222351
Validation loss: 1.7913304272518362

Epoch: 6| Step: 3
Training loss: 0.7007185220718384
Validation loss: 1.7724381941621021

Epoch: 6| Step: 4
Training loss: 1.0010758638381958
Validation loss: 1.7626793089733328

Epoch: 6| Step: 5
Training loss: 1.3977174758911133
Validation loss: 1.7590578653479134

Epoch: 6| Step: 6
Training loss: 1.2725876569747925
Validation loss: 1.7341728210449219

Epoch: 6| Step: 7
Training loss: 0.7165557146072388
Validation loss: 1.788235233676049

Epoch: 6| Step: 8
Training loss: 1.3476759195327759
Validation loss: 1.787272168743995

Epoch: 6| Step: 9
Training loss: 1.1136990785598755
Validation loss: 1.8303100767955984

Epoch: 6| Step: 10
Training loss: 1.7562549114227295
Validation loss: 1.8378405378710838

Epoch: 6| Step: 11
Training loss: 1.4306834936141968
Validation loss: 1.8458926075248308

Epoch: 6| Step: 12
Training loss: 1.2287310361862183
Validation loss: 1.7630141819677045

Epoch: 6| Step: 13
Training loss: 1.2451964616775513
Validation loss: 1.8694652357409078

Epoch: 371| Step: 0
Training loss: 0.8321622610092163
Validation loss: 1.8165141433797858

Epoch: 6| Step: 1
Training loss: 1.050878643989563
Validation loss: 1.8992778332002702

Epoch: 6| Step: 2
Training loss: 1.26833975315094
Validation loss: 1.868215166112428

Epoch: 6| Step: 3
Training loss: 1.7965168952941895
Validation loss: 1.8038144239815332

Epoch: 6| Step: 4
Training loss: 1.2815525531768799
Validation loss: 1.839262677777198

Epoch: 6| Step: 5
Training loss: 0.9700109958648682
Validation loss: 1.7925226021838445

Epoch: 6| Step: 6
Training loss: 1.440751075744629
Validation loss: 1.7984532989481443

Epoch: 6| Step: 7
Training loss: 1.6107302904129028
Validation loss: 1.7887047759948238

Epoch: 6| Step: 8
Training loss: 1.1314705610275269
Validation loss: 1.7767286954387542

Epoch: 6| Step: 9
Training loss: 0.9137677550315857
Validation loss: 1.7610631655621272

Epoch: 6| Step: 10
Training loss: 1.275573968887329
Validation loss: 1.770212895126753

Epoch: 6| Step: 11
Training loss: 1.5007901191711426
Validation loss: 1.75501880081751

Epoch: 6| Step: 12
Training loss: 1.2088851928710938
Validation loss: 1.762815019135834

Epoch: 6| Step: 13
Training loss: 1.0739504098892212
Validation loss: 1.781171292387029

Epoch: 372| Step: 0
Training loss: 1.2099552154541016
Validation loss: 1.767931007569836

Epoch: 6| Step: 1
Training loss: 1.0130565166473389
Validation loss: 1.7508140969020065

Epoch: 6| Step: 2
Training loss: 0.9136697053909302
Validation loss: 1.802771819535122

Epoch: 6| Step: 3
Training loss: 1.6721453666687012
Validation loss: 1.7916047919181086

Epoch: 6| Step: 4
Training loss: 1.1396510601043701
Validation loss: 1.8272966595106228

Epoch: 6| Step: 5
Training loss: 1.1685764789581299
Validation loss: 1.7835522659363285

Epoch: 6| Step: 6
Training loss: 1.223025918006897
Validation loss: 1.8151439492420485

Epoch: 6| Step: 7
Training loss: 1.3232828378677368
Validation loss: 1.8201553257562781

Epoch: 6| Step: 8
Training loss: 1.5476117134094238
Validation loss: 1.8242372774308728

Epoch: 6| Step: 9
Training loss: 1.2662134170532227
Validation loss: 1.8167375710702711

Epoch: 6| Step: 10
Training loss: 1.0285093784332275
Validation loss: 1.7924510189281997

Epoch: 6| Step: 11
Training loss: 1.2742350101470947
Validation loss: 1.820893467113536

Epoch: 6| Step: 12
Training loss: 1.0792467594146729
Validation loss: 1.7901393136670511

Epoch: 6| Step: 13
Training loss: 1.4191502332687378
Validation loss: 1.7629255658836775

Epoch: 373| Step: 0
Training loss: 1.8146767616271973
Validation loss: 1.764979629106419

Epoch: 6| Step: 1
Training loss: 0.7836998701095581
Validation loss: 1.7738093676105622

Epoch: 6| Step: 2
Training loss: 0.9765936732292175
Validation loss: 1.760420198081642

Epoch: 6| Step: 3
Training loss: 1.8653576374053955
Validation loss: 1.7808015102981238

Epoch: 6| Step: 4
Training loss: 0.6749100685119629
Validation loss: 1.7873470578142392

Epoch: 6| Step: 5
Training loss: 0.8208379745483398
Validation loss: 1.7904003333019953

Epoch: 6| Step: 6
Training loss: 1.2327990531921387
Validation loss: 1.7418533935341785

Epoch: 6| Step: 7
Training loss: 0.6968418955802917
Validation loss: 1.8470110303612166

Epoch: 6| Step: 8
Training loss: 1.0274368524551392
Validation loss: 1.8244851327711535

Epoch: 6| Step: 9
Training loss: 2.2280149459838867
Validation loss: 1.764312357030889

Epoch: 6| Step: 10
Training loss: 1.6201800107955933
Validation loss: 1.799615736930601

Epoch: 6| Step: 11
Training loss: 0.8684664964675903
Validation loss: 1.7965577443440754

Epoch: 6| Step: 12
Training loss: 1.3951839208602905
Validation loss: 1.8091486346337102

Epoch: 6| Step: 13
Training loss: 0.5972477793693542
Validation loss: 1.8089240033139464

Epoch: 374| Step: 0
Training loss: 1.0841474533081055
Validation loss: 1.7730018720831922

Epoch: 6| Step: 1
Training loss: 1.366721272468567
Validation loss: 1.7698003707393524

Epoch: 6| Step: 2
Training loss: 2.027345895767212
Validation loss: 1.782085766074478

Epoch: 6| Step: 3
Training loss: 1.1532844305038452
Validation loss: 1.7838918637203913

Epoch: 6| Step: 4
Training loss: 1.2229530811309814
Validation loss: 1.765876616201093

Epoch: 6| Step: 5
Training loss: 1.7060260772705078
Validation loss: 1.7763152545498264

Epoch: 6| Step: 6
Training loss: 0.9477531909942627
Validation loss: 1.8303380249648966

Epoch: 6| Step: 7
Training loss: 0.7965837121009827
Validation loss: 1.7694225913734847

Epoch: 6| Step: 8
Training loss: 0.9539864659309387
Validation loss: 1.7796224842789352

Epoch: 6| Step: 9
Training loss: 1.1997328996658325
Validation loss: 1.8021161069152176

Epoch: 6| Step: 10
Training loss: 1.5704011917114258
Validation loss: 1.8015879841261013

Epoch: 6| Step: 11
Training loss: 0.8020647168159485
Validation loss: 1.795190192038013

Epoch: 6| Step: 12
Training loss: 1.4675724506378174
Validation loss: 1.7922948060497161

Epoch: 6| Step: 13
Training loss: 0.8760640025138855
Validation loss: 1.7760759104964554

Epoch: 375| Step: 0
Training loss: 1.482728123664856
Validation loss: 1.920519999278489

Epoch: 6| Step: 1
Training loss: 0.8493908047676086
Validation loss: 1.7913053702282649

Epoch: 6| Step: 2
Training loss: 1.0637463331222534
Validation loss: 1.816063323328572

Epoch: 6| Step: 3
Training loss: 0.8875390291213989
Validation loss: 1.7814901041728195

Epoch: 6| Step: 4
Training loss: 0.7983077168464661
Validation loss: 1.750999399410781

Epoch: 6| Step: 5
Training loss: 2.4951157569885254
Validation loss: 1.8354148839109687

Epoch: 6| Step: 6
Training loss: 1.2734136581420898
Validation loss: 1.8036997395177041

Epoch: 6| Step: 7
Training loss: 0.8023903369903564
Validation loss: 1.7732108613496185

Epoch: 6| Step: 8
Training loss: 1.1564838886260986
Validation loss: 1.7744213816940144

Epoch: 6| Step: 9
Training loss: 1.0197423696517944
Validation loss: 1.7872757398954002

Epoch: 6| Step: 10
Training loss: 1.4389770030975342
Validation loss: 1.7976063707823395

Epoch: 6| Step: 11
Training loss: 1.564126968383789
Validation loss: 1.7640366490169237

Epoch: 6| Step: 12
Training loss: 0.9203673601150513
Validation loss: 1.7772853374481201

Epoch: 6| Step: 13
Training loss: 1.2215555906295776
Validation loss: 1.8023274508855676

Epoch: 376| Step: 0
Training loss: 0.499372661113739
Validation loss: 1.8064518449127034

Epoch: 6| Step: 1
Training loss: 0.9936826825141907
Validation loss: 1.7351647077068206

Epoch: 6| Step: 2
Training loss: 1.1270716190338135
Validation loss: 1.769498263635943

Epoch: 6| Step: 3
Training loss: 1.5375010967254639
Validation loss: 1.819493716762912

Epoch: 6| Step: 4
Training loss: 1.3616008758544922
Validation loss: 1.7943270629452122

Epoch: 6| Step: 5
Training loss: 1.7397677898406982
Validation loss: 1.7278978234978133

Epoch: 6| Step: 6
Training loss: 1.1930270195007324
Validation loss: 1.8351898385632424

Epoch: 6| Step: 7
Training loss: 1.267711877822876
Validation loss: 1.8336163310594455

Epoch: 6| Step: 8
Training loss: 1.1617038249969482
Validation loss: 1.8024515541650916

Epoch: 6| Step: 9
Training loss: 1.282545804977417
Validation loss: 1.7645940883185274

Epoch: 6| Step: 10
Training loss: 1.436610221862793
Validation loss: 1.8050296255337295

Epoch: 6| Step: 11
Training loss: 1.1148717403411865
Validation loss: 1.8163365753748084

Epoch: 6| Step: 12
Training loss: 1.5076820850372314
Validation loss: 1.7563351174836517

Epoch: 6| Step: 13
Training loss: 0.6574569344520569
Validation loss: 1.8079811680701472

Epoch: 377| Step: 0
Training loss: 1.4418609142303467
Validation loss: 1.8032117274499708

Epoch: 6| Step: 1
Training loss: 0.7216148376464844
Validation loss: 1.7787477585577196

Epoch: 6| Step: 2
Training loss: 1.5477344989776611
Validation loss: 1.797720338708611

Epoch: 6| Step: 3
Training loss: 2.005998134613037
Validation loss: 1.784298999335176

Epoch: 6| Step: 4
Training loss: 0.766535222530365
Validation loss: 1.7621009349822998

Epoch: 6| Step: 5
Training loss: 1.0262370109558105
Validation loss: 1.7945906680117372

Epoch: 6| Step: 6
Training loss: 0.914740800857544
Validation loss: 1.7646641923535256

Epoch: 6| Step: 7
Training loss: 1.2758835554122925
Validation loss: 1.7926070433790966

Epoch: 6| Step: 8
Training loss: 1.0462965965270996
Validation loss: 1.7748224760896416

Epoch: 6| Step: 9
Training loss: 1.069188117980957
Validation loss: 1.748526107880377

Epoch: 6| Step: 10
Training loss: 1.4685406684875488
Validation loss: 1.7873702369710451

Epoch: 6| Step: 11
Training loss: 1.5703672170639038
Validation loss: 1.7303287008757233

Epoch: 6| Step: 12
Training loss: 1.0178624391555786
Validation loss: 1.6976549856124385

Epoch: 6| Step: 13
Training loss: 0.44515514373779297
Validation loss: 1.8264475650684808

Epoch: 378| Step: 0
Training loss: 0.6701736450195312
Validation loss: 1.7680852502904914

Epoch: 6| Step: 1
Training loss: 0.656943678855896
Validation loss: 1.769558774527683

Epoch: 6| Step: 2
Training loss: 1.1211625337600708
Validation loss: 1.822267714367118

Epoch: 6| Step: 3
Training loss: 1.1805943250656128
Validation loss: 1.7943241634676534

Epoch: 6| Step: 4
Training loss: 0.7424889802932739
Validation loss: 1.7649898695689377

Epoch: 6| Step: 5
Training loss: 1.7169773578643799
Validation loss: 1.7413732403068132

Epoch: 6| Step: 6
Training loss: 1.6774077415466309
Validation loss: 1.8154709390414658

Epoch: 6| Step: 7
Training loss: 1.2468013763427734
Validation loss: 1.7658710108008435

Epoch: 6| Step: 8
Training loss: 1.3516507148742676
Validation loss: 1.812098010893791

Epoch: 6| Step: 9
Training loss: 0.9275989532470703
Validation loss: 1.8108477656559279

Epoch: 6| Step: 10
Training loss: 1.622397541999817
Validation loss: 1.7990334469784972

Epoch: 6| Step: 11
Training loss: 1.216278076171875
Validation loss: 1.817160971703068

Epoch: 6| Step: 12
Training loss: 1.7328543663024902
Validation loss: 1.7530797130318099

Epoch: 6| Step: 13
Training loss: 1.3241074085235596
Validation loss: 1.8329301213705411

Epoch: 379| Step: 0
Training loss: 0.9416671395301819
Validation loss: 1.7957157627228768

Epoch: 6| Step: 1
Training loss: 1.541599154472351
Validation loss: 1.7820679013447096

Epoch: 6| Step: 2
Training loss: 1.417614459991455
Validation loss: 1.7960976439137613

Epoch: 6| Step: 3
Training loss: 0.6119652986526489
Validation loss: 1.7690758256502048

Epoch: 6| Step: 4
Training loss: 1.434436321258545
Validation loss: 1.7795119875220842

Epoch: 6| Step: 5
Training loss: 0.9303366541862488
Validation loss: 1.726054714572045

Epoch: 6| Step: 6
Training loss: 1.2561086416244507
Validation loss: 1.7766632674842753

Epoch: 6| Step: 7
Training loss: 1.2288365364074707
Validation loss: 1.7885668790468605

Epoch: 6| Step: 8
Training loss: 1.340323567390442
Validation loss: 1.7831131873592254

Epoch: 6| Step: 9
Training loss: 1.133105754852295
Validation loss: 1.7687199090116767

Epoch: 6| Step: 10
Training loss: 1.0721728801727295
Validation loss: 1.7709743386955672

Epoch: 6| Step: 11
Training loss: 1.3136650323867798
Validation loss: 1.7437173858765633

Epoch: 6| Step: 12
Training loss: 1.4393643140792847
Validation loss: 1.7648476810865505

Epoch: 6| Step: 13
Training loss: 0.9661567211151123
Validation loss: 1.7270780224953928

Epoch: 380| Step: 0
Training loss: 1.4737839698791504
Validation loss: 1.779594002872385

Epoch: 6| Step: 1
Training loss: 0.9534342288970947
Validation loss: 1.7833387736351258

Epoch: 6| Step: 2
Training loss: 1.9407923221588135
Validation loss: 1.8381244238986765

Epoch: 6| Step: 3
Training loss: 1.1337990760803223
Validation loss: 1.8583779014566892

Epoch: 6| Step: 4
Training loss: 1.199562668800354
Validation loss: 1.86709979913568

Epoch: 6| Step: 5
Training loss: 1.1753151416778564
Validation loss: 1.862449433213921

Epoch: 6| Step: 6
Training loss: 1.2918671369552612
Validation loss: 1.8338643094544769

Epoch: 6| Step: 7
Training loss: 1.2196366786956787
Validation loss: 1.8461503046815113

Epoch: 6| Step: 8
Training loss: 1.0033924579620361
Validation loss: 1.8493912937820598

Epoch: 6| Step: 9
Training loss: 1.2908555269241333
Validation loss: 1.8931391290439072

Epoch: 6| Step: 10
Training loss: 1.4005876779556274
Validation loss: 1.81825763692138

Epoch: 6| Step: 11
Training loss: 0.8552393913269043
Validation loss: 1.7989315589269002

Epoch: 6| Step: 12
Training loss: 0.8437157869338989
Validation loss: 1.7678793091927805

Epoch: 6| Step: 13
Training loss: 1.1019926071166992
Validation loss: 1.801069689053361

Epoch: 381| Step: 0
Training loss: 1.543881893157959
Validation loss: 1.753321252843385

Epoch: 6| Step: 1
Training loss: 1.5148203372955322
Validation loss: 1.8253283141761698

Epoch: 6| Step: 2
Training loss: 1.7149419784545898
Validation loss: 1.756937667887698

Epoch: 6| Step: 3
Training loss: 0.8989551067352295
Validation loss: 1.7924958134210238

Epoch: 6| Step: 4
Training loss: 1.042819619178772
Validation loss: 1.733641800060067

Epoch: 6| Step: 5
Training loss: 0.9447191953659058
Validation loss: 1.707447386557056

Epoch: 6| Step: 6
Training loss: 1.0571579933166504
Validation loss: 1.7780104350018244

Epoch: 6| Step: 7
Training loss: 1.4478448629379272
Validation loss: 1.8625755566422657

Epoch: 6| Step: 8
Training loss: 1.173836588859558
Validation loss: 1.775356661888861

Epoch: 6| Step: 9
Training loss: 0.7148587703704834
Validation loss: 1.732969278930336

Epoch: 6| Step: 10
Training loss: 1.3226616382598877
Validation loss: 1.763511743596805

Epoch: 6| Step: 11
Training loss: 1.7175085544586182
Validation loss: 1.8038560254599458

Epoch: 6| Step: 12
Training loss: 0.9635636806488037
Validation loss: 1.845364055325908

Epoch: 6| Step: 13
Training loss: 0.9570571184158325
Validation loss: 1.8651133865438483

Epoch: 382| Step: 0
Training loss: 0.6935078501701355
Validation loss: 1.8615840442718998

Epoch: 6| Step: 1
Training loss: 0.9095562696456909
Validation loss: 1.8479046642139394

Epoch: 6| Step: 2
Training loss: 1.6610262393951416
Validation loss: 1.833995621691468

Epoch: 6| Step: 3
Training loss: 1.4027283191680908
Validation loss: 1.8002670464977142

Epoch: 6| Step: 4
Training loss: 1.4113550186157227
Validation loss: 1.7535054433730342

Epoch: 6| Step: 5
Training loss: 1.2097774744033813
Validation loss: 1.824334603483959

Epoch: 6| Step: 6
Training loss: 1.6422456502914429
Validation loss: 1.7758023905497726

Epoch: 6| Step: 7
Training loss: 0.962303638458252
Validation loss: 1.7253487776684504

Epoch: 6| Step: 8
Training loss: 1.0807576179504395
Validation loss: 1.7910312324441888

Epoch: 6| Step: 9
Training loss: 1.168708086013794
Validation loss: 1.8311693950365948

Epoch: 6| Step: 10
Training loss: 1.3182244300842285
Validation loss: 1.7721648575157247

Epoch: 6| Step: 11
Training loss: 1.1694830656051636
Validation loss: 1.806038350187322

Epoch: 6| Step: 12
Training loss: 0.9895383715629578
Validation loss: 1.7633151995238436

Epoch: 6| Step: 13
Training loss: 0.6945440173149109
Validation loss: 1.7359605040601505

Epoch: 383| Step: 0
Training loss: 0.589309573173523
Validation loss: 1.735839484840311

Epoch: 6| Step: 1
Training loss: 1.042121171951294
Validation loss: 1.7193964399317259

Epoch: 6| Step: 2
Training loss: 0.9517754316329956
Validation loss: 1.757019022459625

Epoch: 6| Step: 3
Training loss: 1.7311553955078125
Validation loss: 1.774034425776492

Epoch: 6| Step: 4
Training loss: 1.2910735607147217
Validation loss: 1.8283918185900616

Epoch: 6| Step: 5
Training loss: 1.5770108699798584
Validation loss: 1.8091613349094187

Epoch: 6| Step: 6
Training loss: 0.8651797771453857
Validation loss: 1.769584059715271

Epoch: 6| Step: 7
Training loss: 1.2831566333770752
Validation loss: 1.7680054608211722

Epoch: 6| Step: 8
Training loss: 1.4825477600097656
Validation loss: 1.7892868506011141

Epoch: 6| Step: 9
Training loss: 1.0044560432434082
Validation loss: 1.7986103411643737

Epoch: 6| Step: 10
Training loss: 0.9969906806945801
Validation loss: 1.8178588754387313

Epoch: 6| Step: 11
Training loss: 0.9318166375160217
Validation loss: 1.844597626757878

Epoch: 6| Step: 12
Training loss: 1.4139362573623657
Validation loss: 1.7765099002468971

Epoch: 6| Step: 13
Training loss: 1.682915210723877
Validation loss: 1.791323684876965

Epoch: 384| Step: 0
Training loss: 1.334924340248108
Validation loss: 1.80336465502298

Epoch: 6| Step: 1
Training loss: 0.929913341999054
Validation loss: 1.7303973500446608

Epoch: 6| Step: 2
Training loss: 0.913421094417572
Validation loss: 1.7930176283723565

Epoch: 6| Step: 3
Training loss: 1.266629934310913
Validation loss: 1.8085608431088027

Epoch: 6| Step: 4
Training loss: 1.3513197898864746
Validation loss: 1.8012318303508144

Epoch: 6| Step: 5
Training loss: 1.3015575408935547
Validation loss: 1.791286385828449

Epoch: 6| Step: 6
Training loss: 1.0246245861053467
Validation loss: 1.779857233006467

Epoch: 6| Step: 7
Training loss: 1.0089151859283447
Validation loss: 1.7977360307529409

Epoch: 6| Step: 8
Training loss: 0.8100045919418335
Validation loss: 1.8059472358354958

Epoch: 6| Step: 9
Training loss: 2.032474994659424
Validation loss: 1.7882656653722127

Epoch: 6| Step: 10
Training loss: 0.7652941346168518
Validation loss: 1.7746734683231642

Epoch: 6| Step: 11
Training loss: 1.5088542699813843
Validation loss: 1.810973826275077

Epoch: 6| Step: 12
Training loss: 0.9864051938056946
Validation loss: 1.7599440415700276

Epoch: 6| Step: 13
Training loss: 1.9928218126296997
Validation loss: 1.8318336432979954

Epoch: 385| Step: 0
Training loss: 1.6674408912658691
Validation loss: 1.7711997955076155

Epoch: 6| Step: 1
Training loss: 1.3458008766174316
Validation loss: 1.7974695287724978

Epoch: 6| Step: 2
Training loss: 0.7135723829269409
Validation loss: 1.7871853818175614

Epoch: 6| Step: 3
Training loss: 2.0092954635620117
Validation loss: 1.793452339787637

Epoch: 6| Step: 4
Training loss: 0.7827486395835876
Validation loss: 1.7667854985883158

Epoch: 6| Step: 5
Training loss: 0.9356421232223511
Validation loss: 1.7792185570604058

Epoch: 6| Step: 6
Training loss: 1.1600834131240845
Validation loss: 1.8148250554197578

Epoch: 6| Step: 7
Training loss: 1.3599625825881958
Validation loss: 1.8258983845351844

Epoch: 6| Step: 8
Training loss: 0.7494955658912659
Validation loss: 1.8006862043052592

Epoch: 6| Step: 9
Training loss: 0.9051907062530518
Validation loss: 1.7798309479990313

Epoch: 6| Step: 10
Training loss: 1.071760892868042
Validation loss: 1.7531077323421356

Epoch: 6| Step: 11
Training loss: 1.1610063314437866
Validation loss: 1.7950103975111438

Epoch: 6| Step: 12
Training loss: 1.1995429992675781
Validation loss: 1.7512789003310665

Epoch: 6| Step: 13
Training loss: 1.935891032218933
Validation loss: 1.7973016577382241

Epoch: 386| Step: 0
Training loss: 0.8371699452400208
Validation loss: 1.791164675066548

Epoch: 6| Step: 1
Training loss: 1.0976907014846802
Validation loss: 1.736349057125789

Epoch: 6| Step: 2
Training loss: 1.4787983894348145
Validation loss: 1.7564247897876206

Epoch: 6| Step: 3
Training loss: 1.0766944885253906
Validation loss: 1.7706649816164406

Epoch: 6| Step: 4
Training loss: 1.1021233797073364
Validation loss: 1.7592993731139808

Epoch: 6| Step: 5
Training loss: 1.2516758441925049
Validation loss: 1.7329696557855094

Epoch: 6| Step: 6
Training loss: 0.8812789916992188
Validation loss: 1.7728808208178448

Epoch: 6| Step: 7
Training loss: 1.6446163654327393
Validation loss: 1.7465812557487077

Epoch: 6| Step: 8
Training loss: 1.3404901027679443
Validation loss: 1.7608507781900384

Epoch: 6| Step: 9
Training loss: 1.0154681205749512
Validation loss: 1.7776417347692675

Epoch: 6| Step: 10
Training loss: 1.3888559341430664
Validation loss: 1.784499728551475

Epoch: 6| Step: 11
Training loss: 1.1896445751190186
Validation loss: 1.7532656500416417

Epoch: 6| Step: 12
Training loss: 1.1553946733474731
Validation loss: 1.7473319909905876

Epoch: 6| Step: 13
Training loss: 1.2480796575546265
Validation loss: 1.7882185110481836

Epoch: 387| Step: 0
Training loss: 1.3343639373779297
Validation loss: 1.7690534437856367

Epoch: 6| Step: 1
Training loss: 1.1820626258850098
Validation loss: 1.8066927617596042

Epoch: 6| Step: 2
Training loss: 0.7691868543624878
Validation loss: 1.768983417941678

Epoch: 6| Step: 3
Training loss: 1.1325924396514893
Validation loss: 1.7508946862272037

Epoch: 6| Step: 4
Training loss: 1.7764105796813965
Validation loss: 1.8181541799217142

Epoch: 6| Step: 5
Training loss: 1.2770497798919678
Validation loss: 1.7218662846472956

Epoch: 6| Step: 6
Training loss: 1.5761330127716064
Validation loss: 1.7887537953674153

Epoch: 6| Step: 7
Training loss: 0.987992525100708
Validation loss: 1.8051319788861018

Epoch: 6| Step: 8
Training loss: 1.0973162651062012
Validation loss: 1.8272445983784174

Epoch: 6| Step: 9
Training loss: 0.8547561764717102
Validation loss: 1.7957713052790651

Epoch: 6| Step: 10
Training loss: 0.897928774356842
Validation loss: 1.7753148681374007

Epoch: 6| Step: 11
Training loss: 0.8324062824249268
Validation loss: 1.7401745280911844

Epoch: 6| Step: 12
Training loss: 1.7936378717422485
Validation loss: 1.7480856846737605

Epoch: 6| Step: 13
Training loss: 0.47527164220809937
Validation loss: 1.8500365416208904

Epoch: 388| Step: 0
Training loss: 0.6898699998855591
Validation loss: 1.74496796823317

Epoch: 6| Step: 1
Training loss: 1.070055603981018
Validation loss: 1.752320271666332

Epoch: 6| Step: 2
Training loss: 1.3556952476501465
Validation loss: 1.8024467857935096

Epoch: 6| Step: 3
Training loss: 1.5819858312606812
Validation loss: 1.7972054404597129

Epoch: 6| Step: 4
Training loss: 1.3066794872283936
Validation loss: 1.7493898073832195

Epoch: 6| Step: 5
Training loss: 1.746706247329712
Validation loss: 1.778009021154014

Epoch: 6| Step: 6
Training loss: 0.9713681936264038
Validation loss: 1.77513046931195

Epoch: 6| Step: 7
Training loss: 0.8093537092208862
Validation loss: 1.8144731521606445

Epoch: 6| Step: 8
Training loss: 1.2663527727127075
Validation loss: 1.7866353193918865

Epoch: 6| Step: 9
Training loss: 0.9339427947998047
Validation loss: 1.7437602371297858

Epoch: 6| Step: 10
Training loss: 1.516003966331482
Validation loss: 1.7490680089560888

Epoch: 6| Step: 11
Training loss: 1.011797308921814
Validation loss: 1.7952865554440407

Epoch: 6| Step: 12
Training loss: 1.605677604675293
Validation loss: 1.7902041763387702

Epoch: 6| Step: 13
Training loss: 0.6724745035171509
Validation loss: 1.7467039656895462

Epoch: 389| Step: 0
Training loss: 0.7721429467201233
Validation loss: 1.841835501373455

Epoch: 6| Step: 1
Training loss: 1.1093778610229492
Validation loss: 1.7916561941946707

Epoch: 6| Step: 2
Training loss: 1.2570641040802002
Validation loss: 1.826070381749061

Epoch: 6| Step: 3
Training loss: 0.9017462730407715
Validation loss: 1.8304846543137745

Epoch: 6| Step: 4
Training loss: 1.3992819786071777
Validation loss: 1.7892511083233742

Epoch: 6| Step: 5
Training loss: 0.5980082154273987
Validation loss: 1.7928063177293347

Epoch: 6| Step: 6
Training loss: 1.2078287601470947
Validation loss: 1.8337574453764065

Epoch: 6| Step: 7
Training loss: 1.0093599557876587
Validation loss: 1.8243912368692377

Epoch: 6| Step: 8
Training loss: 1.364458680152893
Validation loss: 1.7870414039140106

Epoch: 6| Step: 9
Training loss: 1.3756062984466553
Validation loss: 1.724962160151492

Epoch: 6| Step: 10
Training loss: 1.5664408206939697
Validation loss: 1.820783099820537

Epoch: 6| Step: 11
Training loss: 1.1546434164047241
Validation loss: 1.7920182212706535

Epoch: 6| Step: 12
Training loss: 1.3548383712768555
Validation loss: 1.825644769976216

Epoch: 6| Step: 13
Training loss: 1.9578783512115479
Validation loss: 1.789210214409777

Epoch: 390| Step: 0
Training loss: 1.3778746128082275
Validation loss: 1.7834048245542793

Epoch: 6| Step: 1
Training loss: 0.6472307443618774
Validation loss: 1.7866593432682816

Epoch: 6| Step: 2
Training loss: 0.9961645603179932
Validation loss: 1.7388292525404243

Epoch: 6| Step: 3
Training loss: 1.2964813709259033
Validation loss: 1.8291001486521896

Epoch: 6| Step: 4
Training loss: 1.3730392456054688
Validation loss: 1.7974686212437128

Epoch: 6| Step: 5
Training loss: 1.3181735277175903
Validation loss: 1.8091850306398125

Epoch: 6| Step: 6
Training loss: 0.8084837198257446
Validation loss: 1.838390866915385

Epoch: 6| Step: 7
Training loss: 0.5529072880744934
Validation loss: 1.7875972537584202

Epoch: 6| Step: 8
Training loss: 1.448438286781311
Validation loss: 1.7915944873645742

Epoch: 6| Step: 9
Training loss: 1.4643207788467407
Validation loss: 1.7859582695909726

Epoch: 6| Step: 10
Training loss: 1.6009917259216309
Validation loss: 1.775502925278038

Epoch: 6| Step: 11
Training loss: 1.2202109098434448
Validation loss: 1.7595501689500705

Epoch: 6| Step: 12
Training loss: 0.8950846195220947
Validation loss: 1.7772294911005164

Epoch: 6| Step: 13
Training loss: 0.9636988043785095
Validation loss: 1.7238414928477297

Epoch: 391| Step: 0
Training loss: 1.5977716445922852
Validation loss: 1.8159225166484874

Epoch: 6| Step: 1
Training loss: 1.7785395383834839
Validation loss: 1.8038832423507527

Epoch: 6| Step: 2
Training loss: 1.5256035327911377
Validation loss: 1.8056321990105413

Epoch: 6| Step: 3
Training loss: 1.1865555047988892
Validation loss: 1.7654043192504554

Epoch: 6| Step: 4
Training loss: 1.3278850317001343
Validation loss: 1.7592452777329313

Epoch: 6| Step: 5
Training loss: 0.5830790996551514
Validation loss: 1.7970428389887656

Epoch: 6| Step: 6
Training loss: 0.866233229637146
Validation loss: 1.757712573133489

Epoch: 6| Step: 7
Training loss: 1.000664234161377
Validation loss: 1.7654142097760273

Epoch: 6| Step: 8
Training loss: 0.7751339673995972
Validation loss: 1.784688006165207

Epoch: 6| Step: 9
Training loss: 0.8776242733001709
Validation loss: 1.7759569434709446

Epoch: 6| Step: 10
Training loss: 1.633679986000061
Validation loss: 1.7840815372364496

Epoch: 6| Step: 11
Training loss: 1.1944841146469116
Validation loss: 1.7955585756609518

Epoch: 6| Step: 12
Training loss: 1.0828523635864258
Validation loss: 1.7904066847216698

Epoch: 6| Step: 13
Training loss: 0.6549864411354065
Validation loss: 1.7649612670303674

Epoch: 392| Step: 0
Training loss: 1.2563021183013916
Validation loss: 1.8259048769550938

Epoch: 6| Step: 1
Training loss: 1.8093211650848389
Validation loss: 1.7862380717390327

Epoch: 6| Step: 2
Training loss: 0.9311257004737854
Validation loss: 1.8326193671072684

Epoch: 6| Step: 3
Training loss: 0.8084984421730042
Validation loss: 1.7228112118218535

Epoch: 6| Step: 4
Training loss: 0.9807331562042236
Validation loss: 1.6876187939797678

Epoch: 6| Step: 5
Training loss: 1.2660191059112549
Validation loss: 1.7866697657492854

Epoch: 6| Step: 6
Training loss: 0.7779353260993958
Validation loss: 1.8021052319516417

Epoch: 6| Step: 7
Training loss: 1.029920220375061
Validation loss: 1.7776642742977347

Epoch: 6| Step: 8
Training loss: 1.0978600978851318
Validation loss: 1.7773207144070697

Epoch: 6| Step: 9
Training loss: 0.8628506064414978
Validation loss: 1.7907146792257986

Epoch: 6| Step: 10
Training loss: 1.0069599151611328
Validation loss: 1.7762762320938932

Epoch: 6| Step: 11
Training loss: 1.3321372270584106
Validation loss: 1.773356194137245

Epoch: 6| Step: 12
Training loss: 1.8258304595947266
Validation loss: 1.8526808164452995

Epoch: 6| Step: 13
Training loss: 1.3580881357192993
Validation loss: 1.7658205775804416

Epoch: 393| Step: 0
Training loss: 0.8326766490936279
Validation loss: 1.7617166760147258

Epoch: 6| Step: 1
Training loss: 0.9315712451934814
Validation loss: 1.8663226276315668

Epoch: 6| Step: 2
Training loss: 1.291670560836792
Validation loss: 1.8049812009257655

Epoch: 6| Step: 3
Training loss: 1.2465345859527588
Validation loss: 1.7979934689819173

Epoch: 6| Step: 4
Training loss: 1.1327043771743774
Validation loss: 1.8341779337134412

Epoch: 6| Step: 5
Training loss: 1.5117685794830322
Validation loss: 1.831970973681378

Epoch: 6| Step: 6
Training loss: 1.1733759641647339
Validation loss: 1.8205937185595114

Epoch: 6| Step: 7
Training loss: 0.9487306475639343
Validation loss: 1.8266992030605194

Epoch: 6| Step: 8
Training loss: 1.2733302116394043
Validation loss: 1.8201717689473143

Epoch: 6| Step: 9
Training loss: 1.028846263885498
Validation loss: 1.7871791431980748

Epoch: 6| Step: 10
Training loss: 1.331467866897583
Validation loss: 1.7940203758978075

Epoch: 6| Step: 11
Training loss: 1.2220431566238403
Validation loss: 1.7937060517649497

Epoch: 6| Step: 12
Training loss: 1.3993144035339355
Validation loss: 1.7858843495768886

Epoch: 6| Step: 13
Training loss: 0.9172486066818237
Validation loss: 1.8107989936746576

Epoch: 394| Step: 0
Training loss: 1.118828296661377
Validation loss: 1.7949271996815999

Epoch: 6| Step: 1
Training loss: 1.209914207458496
Validation loss: 1.7593503741807834

Epoch: 6| Step: 2
Training loss: 1.2818212509155273
Validation loss: 1.7531684034614152

Epoch: 6| Step: 3
Training loss: 1.150247573852539
Validation loss: 1.8013734227867537

Epoch: 6| Step: 4
Training loss: 1.3332252502441406
Validation loss: 1.7498191107985794

Epoch: 6| Step: 5
Training loss: 1.068848729133606
Validation loss: 1.8131793109319543

Epoch: 6| Step: 6
Training loss: 1.314157247543335
Validation loss: 1.743017355600993

Epoch: 6| Step: 7
Training loss: 1.510974645614624
Validation loss: 1.7735224872507074

Epoch: 6| Step: 8
Training loss: 1.2996704578399658
Validation loss: 1.8096456771255822

Epoch: 6| Step: 9
Training loss: 0.9744167327880859
Validation loss: 1.8178889136160574

Epoch: 6| Step: 10
Training loss: 0.9594506025314331
Validation loss: 1.8116701777263353

Epoch: 6| Step: 11
Training loss: 0.9741981029510498
Validation loss: 1.7676474778882918

Epoch: 6| Step: 12
Training loss: 1.1671106815338135
Validation loss: 1.7604077669882006

Epoch: 6| Step: 13
Training loss: 0.6656176447868347
Validation loss: 1.8038995727416007

Epoch: 395| Step: 0
Training loss: 1.2196531295776367
Validation loss: 1.7677039561733123

Epoch: 6| Step: 1
Training loss: 1.2280224561691284
Validation loss: 1.7496943358452088

Epoch: 6| Step: 2
Training loss: 1.1261613368988037
Validation loss: 1.7589470212177565

Epoch: 6| Step: 3
Training loss: 1.5168696641921997
Validation loss: 1.8048860334580945

Epoch: 6| Step: 4
Training loss: 1.129899024963379
Validation loss: 1.7828785604046238

Epoch: 6| Step: 5
Training loss: 0.9672423601150513
Validation loss: 1.7848749750403947

Epoch: 6| Step: 6
Training loss: 1.3506197929382324
Validation loss: 1.7549780812314761

Epoch: 6| Step: 7
Training loss: 0.46829283237457275
Validation loss: 1.763203631165207

Epoch: 6| Step: 8
Training loss: 1.3586132526397705
Validation loss: 1.7772828942985945

Epoch: 6| Step: 9
Training loss: 1.500908374786377
Validation loss: 1.7540446583942702

Epoch: 6| Step: 10
Training loss: 1.1197423934936523
Validation loss: 1.778541539305

Epoch: 6| Step: 11
Training loss: 1.0548456907272339
Validation loss: 1.7534647987734886

Epoch: 6| Step: 12
Training loss: 0.970402181148529
Validation loss: 1.7353697976758402

Epoch: 6| Step: 13
Training loss: 0.9909507036209106
Validation loss: 1.7639364504045056

Epoch: 396| Step: 0
Training loss: 1.6047769784927368
Validation loss: 1.8073481949426795

Epoch: 6| Step: 1
Training loss: 0.5783795714378357
Validation loss: 1.7737471108795495

Epoch: 6| Step: 2
Training loss: 0.8707489967346191
Validation loss: 1.7671751617103495

Epoch: 6| Step: 3
Training loss: 1.450058102607727
Validation loss: 1.7482694323344896

Epoch: 6| Step: 4
Training loss: 0.7920740842819214
Validation loss: 1.7284121423639276

Epoch: 6| Step: 5
Training loss: 0.8831996321678162
Validation loss: 1.7655062149929743

Epoch: 6| Step: 6
Training loss: 0.964324951171875
Validation loss: 1.7514188584461008

Epoch: 6| Step: 7
Training loss: 1.2653608322143555
Validation loss: 1.7645184634834208

Epoch: 6| Step: 8
Training loss: 1.388730764389038
Validation loss: 1.7931964346157607

Epoch: 6| Step: 9
Training loss: 0.827654242515564
Validation loss: 1.7955884484834568

Epoch: 6| Step: 10
Training loss: 1.08711576461792
Validation loss: 1.761013953275578

Epoch: 6| Step: 11
Training loss: 1.1012544631958008
Validation loss: 1.8581468674444384

Epoch: 6| Step: 12
Training loss: 1.6354273557662964
Validation loss: 1.8157834519622147

Epoch: 6| Step: 13
Training loss: 2.5424835681915283
Validation loss: 1.8419164572992632

Epoch: 397| Step: 0
Training loss: 1.0271791219711304
Validation loss: 1.7433885835832166

Epoch: 6| Step: 1
Training loss: 1.0079026222229004
Validation loss: 1.80389202538357

Epoch: 6| Step: 2
Training loss: 0.7616873979568481
Validation loss: 1.7803789133666663

Epoch: 6| Step: 3
Training loss: 0.9618518352508545
Validation loss: 1.762085573647612

Epoch: 6| Step: 4
Training loss: 1.09285569190979
Validation loss: 1.7548082618303196

Epoch: 6| Step: 5
Training loss: 1.5640108585357666
Validation loss: 1.7690446274254912

Epoch: 6| Step: 6
Training loss: 1.1556377410888672
Validation loss: 1.7696271916871429

Epoch: 6| Step: 7
Training loss: 1.4742790460586548
Validation loss: 1.7479593420541415

Epoch: 6| Step: 8
Training loss: 0.6389790773391724
Validation loss: 1.761261647747409

Epoch: 6| Step: 9
Training loss: 1.1395232677459717
Validation loss: 1.73655532252404

Epoch: 6| Step: 10
Training loss: 1.471170425415039
Validation loss: 1.749888684159966

Epoch: 6| Step: 11
Training loss: 1.2505121231079102
Validation loss: 1.8065717938125774

Epoch: 6| Step: 12
Training loss: 1.3553578853607178
Validation loss: 1.824758155371553

Epoch: 6| Step: 13
Training loss: 1.476567268371582
Validation loss: 1.7890041118027062

Epoch: 398| Step: 0
Training loss: 1.37848961353302
Validation loss: 1.7675694534855504

Epoch: 6| Step: 1
Training loss: 0.8726208209991455
Validation loss: 1.802057445690196

Epoch: 6| Step: 2
Training loss: 1.470495343208313
Validation loss: 1.7988110575624692

Epoch: 6| Step: 3
Training loss: 1.3765978813171387
Validation loss: 1.7645831902821858

Epoch: 6| Step: 4
Training loss: 1.1558012962341309
Validation loss: 1.7511478906036706

Epoch: 6| Step: 5
Training loss: 0.9942830801010132
Validation loss: 1.7089903277735556

Epoch: 6| Step: 6
Training loss: 1.0306532382965088
Validation loss: 1.7497131619402158

Epoch: 6| Step: 7
Training loss: 1.6670018434524536
Validation loss: 1.7236353107677993

Epoch: 6| Step: 8
Training loss: 1.1198627948760986
Validation loss: 1.7286034655827347

Epoch: 6| Step: 9
Training loss: 1.0702327489852905
Validation loss: 1.7746900986599665

Epoch: 6| Step: 10
Training loss: 1.3650208711624146
Validation loss: 1.8063962639019053

Epoch: 6| Step: 11
Training loss: 0.4684930443763733
Validation loss: 1.7907809621544295

Epoch: 6| Step: 12
Training loss: 1.2154666185379028
Validation loss: 1.7567807294989144

Epoch: 6| Step: 13
Training loss: 0.6917234063148499
Validation loss: 1.7398314053012478

Epoch: 399| Step: 0
Training loss: 0.858913779258728
Validation loss: 1.8078055791957404

Epoch: 6| Step: 1
Training loss: 0.9259790182113647
Validation loss: 1.8487843287888395

Epoch: 6| Step: 2
Training loss: 0.6148931980133057
Validation loss: 1.7658886486484158

Epoch: 6| Step: 3
Training loss: 0.6941941976547241
Validation loss: 1.7455970728269188

Epoch: 6| Step: 4
Training loss: 0.9764362573623657
Validation loss: 1.7618292095840618

Epoch: 6| Step: 5
Training loss: 1.3404312133789062
Validation loss: 1.80374913959093

Epoch: 6| Step: 6
Training loss: 1.7118699550628662
Validation loss: 1.798118229835264

Epoch: 6| Step: 7
Training loss: 0.8723305463790894
Validation loss: 1.7719152101906397

Epoch: 6| Step: 8
Training loss: 1.363675594329834
Validation loss: 1.7339355984041769

Epoch: 6| Step: 9
Training loss: 0.8600419759750366
Validation loss: 1.8400515484553512

Epoch: 6| Step: 10
Training loss: 1.049184799194336
Validation loss: 1.7660740396027923

Epoch: 6| Step: 11
Training loss: 1.9270620346069336
Validation loss: 1.7775779642084593

Epoch: 6| Step: 12
Training loss: 1.528379201889038
Validation loss: 1.747540694411083

Epoch: 6| Step: 13
Training loss: 1.181312084197998
Validation loss: 1.7980200270170807

Epoch: 400| Step: 0
Training loss: 1.052307367324829
Validation loss: 1.7855013673023512

Epoch: 6| Step: 1
Training loss: 0.9375450611114502
Validation loss: 1.8143137090949601

Epoch: 6| Step: 2
Training loss: 1.1605162620544434
Validation loss: 1.752417229836987

Epoch: 6| Step: 3
Training loss: 1.1070235967636108
Validation loss: 1.7407166240035847

Epoch: 6| Step: 4
Training loss: 1.386120319366455
Validation loss: 1.7856126190513693

Epoch: 6| Step: 5
Training loss: 1.1281276941299438
Validation loss: 1.7565269880397345

Epoch: 6| Step: 6
Training loss: 1.4823392629623413
Validation loss: 1.732503467990506

Epoch: 6| Step: 7
Training loss: 1.0389885902404785
Validation loss: 1.8052299330311437

Epoch: 6| Step: 8
Training loss: 0.8774528503417969
Validation loss: 1.7679630120595295

Epoch: 6| Step: 9
Training loss: 0.952335000038147
Validation loss: 1.747576859689528

Epoch: 6| Step: 10
Training loss: 1.3753340244293213
Validation loss: 1.7216609549778763

Epoch: 6| Step: 11
Training loss: 1.2641310691833496
Validation loss: 1.7638401664713377

Epoch: 6| Step: 12
Training loss: 1.2704570293426514
Validation loss: 1.7697318151432981

Epoch: 6| Step: 13
Training loss: 0.9053070545196533
Validation loss: 1.7304250014725553

Epoch: 401| Step: 0
Training loss: 0.6517053246498108
Validation loss: 1.7716476032810826

Epoch: 6| Step: 1
Training loss: 0.6343308687210083
Validation loss: 1.7666176877995974

Epoch: 6| Step: 2
Training loss: 1.273646593093872
Validation loss: 1.792304091556098

Epoch: 6| Step: 3
Training loss: 1.4003716707229614
Validation loss: 1.7318421089521019

Epoch: 6| Step: 4
Training loss: 1.080237627029419
Validation loss: 1.795910572492948

Epoch: 6| Step: 5
Training loss: 0.6796330809593201
Validation loss: 1.772264447263492

Epoch: 6| Step: 6
Training loss: 1.4881510734558105
Validation loss: 1.740619421005249

Epoch: 6| Step: 7
Training loss: 1.425464153289795
Validation loss: 1.7692949361698602

Epoch: 6| Step: 8
Training loss: 1.5503252744674683
Validation loss: 1.7607860975368048

Epoch: 6| Step: 9
Training loss: 1.58820378780365
Validation loss: 1.7919529458527923

Epoch: 6| Step: 10
Training loss: 0.8446130752563477
Validation loss: 1.7466150445322837

Epoch: 6| Step: 11
Training loss: 0.9860790967941284
Validation loss: 1.7597934046099264

Epoch: 6| Step: 12
Training loss: 1.2650941610336304
Validation loss: 1.7479226371293426

Epoch: 6| Step: 13
Training loss: 0.677560567855835
Validation loss: 1.8034097404890164

Epoch: 402| Step: 0
Training loss: 1.3465595245361328
Validation loss: 1.7685462377404655

Epoch: 6| Step: 1
Training loss: 1.7346314191818237
Validation loss: 1.7528745179535241

Epoch: 6| Step: 2
Training loss: 1.360284447669983
Validation loss: 1.7934470048514746

Epoch: 6| Step: 3
Training loss: 1.35921311378479
Validation loss: 1.751428601562336

Epoch: 6| Step: 4
Training loss: 0.960659384727478
Validation loss: 1.7664136425141366

Epoch: 6| Step: 5
Training loss: 1.1306862831115723
Validation loss: 1.7964854368599512

Epoch: 6| Step: 6
Training loss: 1.318759560585022
Validation loss: 1.8148535297762962

Epoch: 6| Step: 7
Training loss: 0.7010914087295532
Validation loss: 1.8664469526660057

Epoch: 6| Step: 8
Training loss: 1.3046915531158447
Validation loss: 1.8462960386788974

Epoch: 6| Step: 9
Training loss: 0.4786626994609833
Validation loss: 1.8030447318989744

Epoch: 6| Step: 10
Training loss: 1.5101115703582764
Validation loss: 1.8150006417305238

Epoch: 6| Step: 11
Training loss: 1.1601417064666748
Validation loss: 1.7849510203125656

Epoch: 6| Step: 12
Training loss: 1.0525541305541992
Validation loss: 1.79730357662324

Epoch: 6| Step: 13
Training loss: 0.6837469935417175
Validation loss: 1.8130335846254904

Epoch: 403| Step: 0
Training loss: 1.178990125656128
Validation loss: 1.7569855169583393

Epoch: 6| Step: 1
Training loss: 1.1200796365737915
Validation loss: 1.717862577848537

Epoch: 6| Step: 2
Training loss: 1.7934691905975342
Validation loss: 1.7554991527270245

Epoch: 6| Step: 3
Training loss: 0.9163245558738708
Validation loss: 1.8067376382889286

Epoch: 6| Step: 4
Training loss: 1.5084826946258545
Validation loss: 1.795774898221416

Epoch: 6| Step: 5
Training loss: 0.9160174131393433
Validation loss: 1.7700976440983434

Epoch: 6| Step: 6
Training loss: 0.5745093822479248
Validation loss: 1.7957696889036445

Epoch: 6| Step: 7
Training loss: 0.9693211913108826
Validation loss: 1.7455512605687624

Epoch: 6| Step: 8
Training loss: 0.8852152824401855
Validation loss: 1.7880241358152

Epoch: 6| Step: 9
Training loss: 0.48048117756843567
Validation loss: 1.7607174893861175

Epoch: 6| Step: 10
Training loss: 1.1368165016174316
Validation loss: 1.7610612659044163

Epoch: 6| Step: 11
Training loss: 1.24609375
Validation loss: 1.7411888325086204

Epoch: 6| Step: 12
Training loss: 1.5213937759399414
Validation loss: 1.7596561524175829

Epoch: 6| Step: 13
Training loss: 1.6933016777038574
Validation loss: 1.817369407223117

Epoch: 404| Step: 0
Training loss: 1.0281833410263062
Validation loss: 1.7876414714321014

Epoch: 6| Step: 1
Training loss: 0.5367922782897949
Validation loss: 1.7644090101283083

Epoch: 6| Step: 2
Training loss: 1.3564527034759521
Validation loss: 1.8098481867903022

Epoch: 6| Step: 3
Training loss: 1.096510648727417
Validation loss: 1.7467835257130284

Epoch: 6| Step: 4
Training loss: 1.160673975944519
Validation loss: 1.762161757356377

Epoch: 6| Step: 5
Training loss: 1.2480816841125488
Validation loss: 1.7625013038676272

Epoch: 6| Step: 6
Training loss: 1.0089142322540283
Validation loss: 1.729017488418087

Epoch: 6| Step: 7
Training loss: 0.7481144666671753
Validation loss: 1.8061318384703768

Epoch: 6| Step: 8
Training loss: 1.8481972217559814
Validation loss: 1.8081481738757061

Epoch: 6| Step: 9
Training loss: 1.0671888589859009
Validation loss: 1.7227783779944144

Epoch: 6| Step: 10
Training loss: 1.077547550201416
Validation loss: 1.7755091869702904

Epoch: 6| Step: 11
Training loss: 0.914550244808197
Validation loss: 1.805061040386077

Epoch: 6| Step: 12
Training loss: 1.365851879119873
Validation loss: 1.7683250647719189

Epoch: 6| Step: 13
Training loss: 2.1280646324157715
Validation loss: 1.8113740823602165

Epoch: 405| Step: 0
Training loss: 1.0213961601257324
Validation loss: 1.8318405638458908

Epoch: 6| Step: 1
Training loss: 1.259091854095459
Validation loss: 1.8325766645452028

Epoch: 6| Step: 2
Training loss: 0.8227723836898804
Validation loss: 1.7547646017484768

Epoch: 6| Step: 3
Training loss: 0.839855968952179
Validation loss: 1.7760454685457292

Epoch: 6| Step: 4
Training loss: 1.5499643087387085
Validation loss: 1.7774668867870043

Epoch: 6| Step: 5
Training loss: 1.3405054807662964
Validation loss: 1.8089894722866755

Epoch: 6| Step: 6
Training loss: 1.2461252212524414
Validation loss: 1.7605921171044792

Epoch: 6| Step: 7
Training loss: 1.2551472187042236
Validation loss: 1.7785761176898915

Epoch: 6| Step: 8
Training loss: 1.7606385946273804
Validation loss: 1.7873186693396619

Epoch: 6| Step: 9
Training loss: 0.9250389337539673
Validation loss: 1.747620573607824

Epoch: 6| Step: 10
Training loss: 1.0028560161590576
Validation loss: 1.7552993976941673

Epoch: 6| Step: 11
Training loss: 0.8555983901023865
Validation loss: 1.766470161817407

Epoch: 6| Step: 12
Training loss: 0.8998926877975464
Validation loss: 1.7577158892026512

Epoch: 6| Step: 13
Training loss: 1.2316962480545044
Validation loss: 1.816232688965336

Epoch: 406| Step: 0
Training loss: 1.4695926904678345
Validation loss: 1.7890394964525778

Epoch: 6| Step: 1
Training loss: 1.0703264474868774
Validation loss: 1.7228265808474632

Epoch: 6| Step: 2
Training loss: 0.9097698926925659
Validation loss: 1.7700900352129372

Epoch: 6| Step: 3
Training loss: 1.5460164546966553
Validation loss: 1.7828533751990205

Epoch: 6| Step: 4
Training loss: 0.7805831432342529
Validation loss: 1.7610593572739632

Epoch: 6| Step: 5
Training loss: 1.1688213348388672
Validation loss: 1.7757582856762795

Epoch: 6| Step: 6
Training loss: 1.014057993888855
Validation loss: 1.7283714227778937

Epoch: 6| Step: 7
Training loss: 1.117321491241455
Validation loss: 1.7583765291398572

Epoch: 6| Step: 8
Training loss: 1.1066056489944458
Validation loss: 1.7749252806427658

Epoch: 6| Step: 9
Training loss: 1.4063003063201904
Validation loss: 1.758227030436198

Epoch: 6| Step: 10
Training loss: 1.0433018207550049
Validation loss: 1.7455318743182766

Epoch: 6| Step: 11
Training loss: 0.6818031668663025
Validation loss: 1.8156253689078874

Epoch: 6| Step: 12
Training loss: 1.4771301746368408
Validation loss: 1.7753110162673458

Epoch: 6| Step: 13
Training loss: 1.3361502885818481
Validation loss: 1.8029940743600168

Epoch: 407| Step: 0
Training loss: 1.2057511806488037
Validation loss: 1.8102753546930128

Epoch: 6| Step: 1
Training loss: 0.9940022826194763
Validation loss: 1.7939354347926315

Epoch: 6| Step: 2
Training loss: 1.1441706418991089
Validation loss: 1.7565511811164118

Epoch: 6| Step: 3
Training loss: 0.61924147605896
Validation loss: 1.762012726517134

Epoch: 6| Step: 4
Training loss: 1.250445008277893
Validation loss: 1.7629438561777915

Epoch: 6| Step: 5
Training loss: 1.197130799293518
Validation loss: 1.7652548564377653

Epoch: 6| Step: 6
Training loss: 1.785930871963501
Validation loss: 1.7295562605704031

Epoch: 6| Step: 7
Training loss: 1.3780391216278076
Validation loss: 1.7804873092200166

Epoch: 6| Step: 8
Training loss: 1.111488699913025
Validation loss: 1.7892255206261911

Epoch: 6| Step: 9
Training loss: 1.0078556537628174
Validation loss: 1.753992788253292

Epoch: 6| Step: 10
Training loss: 0.7507302761077881
Validation loss: 1.7908338718516852

Epoch: 6| Step: 11
Training loss: 1.4738744497299194
Validation loss: 1.7617994969890964

Epoch: 6| Step: 12
Training loss: 0.7166898846626282
Validation loss: 1.7565932543047014

Epoch: 6| Step: 13
Training loss: 1.8195958137512207
Validation loss: 1.7845487902241368

Epoch: 408| Step: 0
Training loss: 1.037224531173706
Validation loss: 1.7472735451113792

Epoch: 6| Step: 1
Training loss: 1.2769813537597656
Validation loss: 1.7979350769391624

Epoch: 6| Step: 2
Training loss: 0.46790850162506104
Validation loss: 1.8137732833944342

Epoch: 6| Step: 3
Training loss: 1.4647775888442993
Validation loss: 1.820798312464068

Epoch: 6| Step: 4
Training loss: 1.0768190622329712
Validation loss: 1.7654147007132088

Epoch: 6| Step: 5
Training loss: 0.84432053565979
Validation loss: 1.7773496617553055

Epoch: 6| Step: 6
Training loss: 1.2508755922317505
Validation loss: 1.7738016959159606

Epoch: 6| Step: 7
Training loss: 1.213850975036621
Validation loss: 1.7809557914733887

Epoch: 6| Step: 8
Training loss: 1.3518625497817993
Validation loss: 1.7805473830110283

Epoch: 6| Step: 9
Training loss: 0.9407673478126526
Validation loss: 1.8120943141239945

Epoch: 6| Step: 10
Training loss: 1.3934463262557983
Validation loss: 1.8317031796260546

Epoch: 6| Step: 11
Training loss: 1.3556180000305176
Validation loss: 1.8126262387921732

Epoch: 6| Step: 12
Training loss: 0.6326693892478943
Validation loss: 1.7702534365397629

Epoch: 6| Step: 13
Training loss: 1.9553189277648926
Validation loss: 1.7543437647563156

Epoch: 409| Step: 0
Training loss: 1.2259101867675781
Validation loss: 1.7879740397135417

Epoch: 6| Step: 1
Training loss: 0.9017536044120789
Validation loss: 1.771262712376092

Epoch: 6| Step: 2
Training loss: 1.0728527307510376
Validation loss: 1.7243316006916825

Epoch: 6| Step: 3
Training loss: 1.1403485536575317
Validation loss: 1.753709198326193

Epoch: 6| Step: 4
Training loss: 1.2841918468475342
Validation loss: 1.7845781041729836

Epoch: 6| Step: 5
Training loss: 1.320587158203125
Validation loss: 1.736045006782778

Epoch: 6| Step: 6
Training loss: 0.8209291696548462
Validation loss: 1.7239091498877412

Epoch: 6| Step: 7
Training loss: 0.9020859003067017
Validation loss: 1.719177589621595

Epoch: 6| Step: 8
Training loss: 1.0109498500823975
Validation loss: 1.7825613073123399

Epoch: 6| Step: 9
Training loss: 1.0886938571929932
Validation loss: 1.7980711267840477

Epoch: 6| Step: 10
Training loss: 1.737153172492981
Validation loss: 1.76290096775178

Epoch: 6| Step: 11
Training loss: 1.499282717704773
Validation loss: 1.778576518899651

Epoch: 6| Step: 12
Training loss: 0.7939785122871399
Validation loss: 1.7717726538258214

Epoch: 6| Step: 13
Training loss: 0.940246045589447
Validation loss: 1.7806843570483628

Epoch: 410| Step: 0
Training loss: 1.0644323825836182
Validation loss: 1.8241897424062092

Epoch: 6| Step: 1
Training loss: 1.6652934551239014
Validation loss: 1.8332516493335846

Epoch: 6| Step: 2
Training loss: 1.4183651208877563
Validation loss: 1.8926663206469627

Epoch: 6| Step: 3
Training loss: 1.6535687446594238
Validation loss: 1.8366865240117556

Epoch: 6| Step: 4
Training loss: 0.6770412921905518
Validation loss: 1.8473172392896426

Epoch: 6| Step: 5
Training loss: 0.9400646090507507
Validation loss: 1.7842928209612448

Epoch: 6| Step: 6
Training loss: 0.9060750007629395
Validation loss: 1.8312249055472754

Epoch: 6| Step: 7
Training loss: 1.220602035522461
Validation loss: 1.8341830340764855

Epoch: 6| Step: 8
Training loss: 1.164005994796753
Validation loss: 1.75834491304172

Epoch: 6| Step: 9
Training loss: 0.38711994886398315
Validation loss: 1.7829185980622486

Epoch: 6| Step: 10
Training loss: 1.3632123470306396
Validation loss: 1.799256081222206

Epoch: 6| Step: 11
Training loss: 1.4719319343566895
Validation loss: 1.759883608869327

Epoch: 6| Step: 12
Training loss: 0.7853038311004639
Validation loss: 1.8009394740545621

Epoch: 6| Step: 13
Training loss: 1.2873728275299072
Validation loss: 1.7797808211336854

Epoch: 411| Step: 0
Training loss: 1.229617714881897
Validation loss: 1.735217660985967

Epoch: 6| Step: 1
Training loss: 1.1889257431030273
Validation loss: 1.744083204577046

Epoch: 6| Step: 2
Training loss: 1.8267521858215332
Validation loss: 1.750125249226888

Epoch: 6| Step: 3
Training loss: 0.9293079376220703
Validation loss: 1.8065891240232734

Epoch: 6| Step: 4
Training loss: 1.1553637981414795
Validation loss: 1.8485763124240342

Epoch: 6| Step: 5
Training loss: 1.1096361875534058
Validation loss: 1.7799992458794707

Epoch: 6| Step: 6
Training loss: 1.0370408296585083
Validation loss: 1.743663740414445

Epoch: 6| Step: 7
Training loss: 1.3009922504425049
Validation loss: 1.7911218673952165

Epoch: 6| Step: 8
Training loss: 0.9856001734733582
Validation loss: 1.8263420456199235

Epoch: 6| Step: 9
Training loss: 1.185871958732605
Validation loss: 1.7984146046382126

Epoch: 6| Step: 10
Training loss: 0.8596948981285095
Validation loss: 1.8252573513215589

Epoch: 6| Step: 11
Training loss: 0.8073654770851135
Validation loss: 1.792580545589488

Epoch: 6| Step: 12
Training loss: 1.0782287120819092
Validation loss: 1.7884365153569046

Epoch: 6| Step: 13
Training loss: 0.7941411137580872
Validation loss: 1.7595571638435445

Epoch: 412| Step: 0
Training loss: 0.9332122802734375
Validation loss: 1.7663676110647057

Epoch: 6| Step: 1
Training loss: 0.9031152129173279
Validation loss: 1.7747519875085482

Epoch: 6| Step: 2
Training loss: 1.1015243530273438
Validation loss: 1.736359901325677

Epoch: 6| Step: 3
Training loss: 0.6809461712837219
Validation loss: 1.7346336777492235

Epoch: 6| Step: 4
Training loss: 1.542405366897583
Validation loss: 1.7213553728595856

Epoch: 6| Step: 5
Training loss: 0.9232038855552673
Validation loss: 1.790648489870051

Epoch: 6| Step: 6
Training loss: 1.6629083156585693
Validation loss: 1.761175908068175

Epoch: 6| Step: 7
Training loss: 1.1103265285491943
Validation loss: 1.744658773945224

Epoch: 6| Step: 8
Training loss: 1.0778896808624268
Validation loss: 1.8077016594589397

Epoch: 6| Step: 9
Training loss: 1.5522228479385376
Validation loss: 1.787370438216835

Epoch: 6| Step: 10
Training loss: 1.166985273361206
Validation loss: 1.8351956439274613

Epoch: 6| Step: 11
Training loss: 1.0427420139312744
Validation loss: 1.8453074219406291

Epoch: 6| Step: 12
Training loss: 1.276648998260498
Validation loss: 1.7838370133471746

Epoch: 6| Step: 13
Training loss: 0.8277488350868225
Validation loss: 1.8279699330688806

Epoch: 413| Step: 0
Training loss: 0.7275787591934204
Validation loss: 1.8269398827706613

Epoch: 6| Step: 1
Training loss: 1.2204234600067139
Validation loss: 1.7980721637766848

Epoch: 6| Step: 2
Training loss: 1.4128738641738892
Validation loss: 1.7855767639734412

Epoch: 6| Step: 3
Training loss: 0.9337376356124878
Validation loss: 1.820922355498037

Epoch: 6| Step: 4
Training loss: 1.347928762435913
Validation loss: 1.7951576876383957

Epoch: 6| Step: 5
Training loss: 1.2111806869506836
Validation loss: 1.80520188167531

Epoch: 6| Step: 6
Training loss: 1.0735256671905518
Validation loss: 1.8390167656765188

Epoch: 6| Step: 7
Training loss: 0.3307575583457947
Validation loss: 1.8369208407658402

Epoch: 6| Step: 8
Training loss: 1.6672275066375732
Validation loss: 1.7514117263978528

Epoch: 6| Step: 9
Training loss: 1.3730393648147583
Validation loss: 1.7719893750324045

Epoch: 6| Step: 10
Training loss: 0.6923956274986267
Validation loss: 1.762424966340424

Epoch: 6| Step: 11
Training loss: 1.1522910594940186
Validation loss: 1.7661136722051969

Epoch: 6| Step: 12
Training loss: 1.327736496925354
Validation loss: 1.7670225058832476

Epoch: 6| Step: 13
Training loss: 1.444895625114441
Validation loss: 1.8052998896568053

Epoch: 414| Step: 0
Training loss: 1.2719371318817139
Validation loss: 1.7585588988437448

Epoch: 6| Step: 1
Training loss: 1.2037379741668701
Validation loss: 1.7640089629798807

Epoch: 6| Step: 2
Training loss: 1.0434097051620483
Validation loss: 1.7808417735561248

Epoch: 6| Step: 3
Training loss: 1.3601264953613281
Validation loss: 1.7505201242303337

Epoch: 6| Step: 4
Training loss: 1.29270601272583
Validation loss: 1.764305918447433

Epoch: 6| Step: 5
Training loss: 1.5265785455703735
Validation loss: 1.7663121915632678

Epoch: 6| Step: 6
Training loss: 0.7686102390289307
Validation loss: 1.7471553497416998

Epoch: 6| Step: 7
Training loss: 0.742540180683136
Validation loss: 1.7477967046922254

Epoch: 6| Step: 8
Training loss: 1.1728459596633911
Validation loss: 1.755004939212594

Epoch: 6| Step: 9
Training loss: 1.23626708984375
Validation loss: 1.7870253888509606

Epoch: 6| Step: 10
Training loss: 1.0702176094055176
Validation loss: 1.7136266257173272

Epoch: 6| Step: 11
Training loss: 1.2348816394805908
Validation loss: 1.798727725141792

Epoch: 6| Step: 12
Training loss: 1.1208734512329102
Validation loss: 1.8322176702560917

Epoch: 6| Step: 13
Training loss: 0.8455715179443359
Validation loss: 1.837429601659057

Epoch: 415| Step: 0
Training loss: 0.9828072786331177
Validation loss: 1.8127662212617937

Epoch: 6| Step: 1
Training loss: 0.8502713441848755
Validation loss: 1.8007936644297775

Epoch: 6| Step: 2
Training loss: 1.3839374780654907
Validation loss: 1.7836025094473233

Epoch: 6| Step: 3
Training loss: 0.7905826568603516
Validation loss: 1.7919408595690163

Epoch: 6| Step: 4
Training loss: 0.5207781791687012
Validation loss: 1.7504202678639402

Epoch: 6| Step: 5
Training loss: 1.0428962707519531
Validation loss: 1.804743423256823

Epoch: 6| Step: 6
Training loss: 0.8591159582138062
Validation loss: 1.761315272700402

Epoch: 6| Step: 7
Training loss: 0.8110767602920532
Validation loss: 1.7908793700638639

Epoch: 6| Step: 8
Training loss: 1.714453935623169
Validation loss: 1.8075976217946699

Epoch: 6| Step: 9
Training loss: 1.035444736480713
Validation loss: 1.753961258037116

Epoch: 6| Step: 10
Training loss: 1.192893147468567
Validation loss: 1.7919902596422421

Epoch: 6| Step: 11
Training loss: 1.2508209943771362
Validation loss: 1.8135207750463997

Epoch: 6| Step: 12
Training loss: 1.0694262981414795
Validation loss: 1.7760191322654806

Epoch: 6| Step: 13
Training loss: 2.36130952835083
Validation loss: 1.7518956148496239

Epoch: 416| Step: 0
Training loss: 1.2136143445968628
Validation loss: 1.757859230041504

Epoch: 6| Step: 1
Training loss: 0.6909291744232178
Validation loss: 1.7472026707023702

Epoch: 6| Step: 2
Training loss: 1.4008880853652954
Validation loss: 1.779921729077575

Epoch: 6| Step: 3
Training loss: 1.117756724357605
Validation loss: 1.7912772881087435

Epoch: 6| Step: 4
Training loss: 1.3229340314865112
Validation loss: 1.7800087364771033

Epoch: 6| Step: 5
Training loss: 1.3121150732040405
Validation loss: 1.8057152558398504

Epoch: 6| Step: 6
Training loss: 0.6320824027061462
Validation loss: 1.811182355368009

Epoch: 6| Step: 7
Training loss: 1.312658429145813
Validation loss: 1.774031034079931

Epoch: 6| Step: 8
Training loss: 0.8988765478134155
Validation loss: 1.7797467554769208

Epoch: 6| Step: 9
Training loss: 1.1471807956695557
Validation loss: 1.7511227912800287

Epoch: 6| Step: 10
Training loss: 1.6112136840820312
Validation loss: 1.7984207291756906

Epoch: 6| Step: 11
Training loss: 0.8860124349594116
Validation loss: 1.7766959846660655

Epoch: 6| Step: 12
Training loss: 1.1451075077056885
Validation loss: 1.811626031834592

Epoch: 6| Step: 13
Training loss: 1.1664150953292847
Validation loss: 1.7779128038755028

Epoch: 417| Step: 0
Training loss: 1.2630150318145752
Validation loss: 1.7355152189090688

Epoch: 6| Step: 1
Training loss: 1.0256807804107666
Validation loss: 1.7952726861482025

Epoch: 6| Step: 2
Training loss: 1.087048888206482
Validation loss: 1.7862836417331491

Epoch: 6| Step: 3
Training loss: 0.9816486239433289
Validation loss: 1.7809614135373024

Epoch: 6| Step: 4
Training loss: 1.0588585138320923
Validation loss: 1.7946779445935321

Epoch: 6| Step: 5
Training loss: 1.6627435684204102
Validation loss: 1.7845706157786871

Epoch: 6| Step: 6
Training loss: 0.8722124099731445
Validation loss: 1.7712802489598591

Epoch: 6| Step: 7
Training loss: 1.4953465461730957
Validation loss: 1.7544865851761193

Epoch: 6| Step: 8
Training loss: 1.4124945402145386
Validation loss: 1.777428691105176

Epoch: 6| Step: 9
Training loss: 0.9313356280326843
Validation loss: 1.7473904240515925

Epoch: 6| Step: 10
Training loss: 0.9130745530128479
Validation loss: 1.806452384559057

Epoch: 6| Step: 11
Training loss: 1.0097317695617676
Validation loss: 1.7327736423861595

Epoch: 6| Step: 12
Training loss: 0.9823676347732544
Validation loss: 1.7180923415768532

Epoch: 6| Step: 13
Training loss: 0.5888733267784119
Validation loss: 1.7859868311112927

Epoch: 418| Step: 0
Training loss: 1.24173903465271
Validation loss: 1.7226429088141328

Epoch: 6| Step: 1
Training loss: 1.2330892086029053
Validation loss: 1.750727193329924

Epoch: 6| Step: 2
Training loss: 0.9223340749740601
Validation loss: 1.7389930768679547

Epoch: 6| Step: 3
Training loss: 0.8316789865493774
Validation loss: 1.7933805873317104

Epoch: 6| Step: 4
Training loss: 0.7413185834884644
Validation loss: 1.7850012651053808

Epoch: 6| Step: 5
Training loss: 1.2338688373565674
Validation loss: 1.782613472271991

Epoch: 6| Step: 6
Training loss: 1.3421043157577515
Validation loss: 1.7779967297789872

Epoch: 6| Step: 7
Training loss: 0.8201470375061035
Validation loss: 1.748255386147448

Epoch: 6| Step: 8
Training loss: 1.0291367769241333
Validation loss: 1.7641867386397494

Epoch: 6| Step: 9
Training loss: 1.2113065719604492
Validation loss: 1.8113146123065744

Epoch: 6| Step: 10
Training loss: 1.391282081604004
Validation loss: 1.7635869864494569

Epoch: 6| Step: 11
Training loss: 1.2942308187484741
Validation loss: 1.7344655016417145

Epoch: 6| Step: 12
Training loss: 1.1726088523864746
Validation loss: 1.7579831346388786

Epoch: 6| Step: 13
Training loss: 1.0087720155715942
Validation loss: 1.7492677037433912

Epoch: 419| Step: 0
Training loss: 1.1808470487594604
Validation loss: 1.7485520403872254

Epoch: 6| Step: 1
Training loss: 0.8257719278335571
Validation loss: 1.791714278600549

Epoch: 6| Step: 2
Training loss: 0.7146497368812561
Validation loss: 1.7657281224445631

Epoch: 6| Step: 3
Training loss: 1.0229341983795166
Validation loss: 1.739167146785285

Epoch: 6| Step: 4
Training loss: 1.123528003692627
Validation loss: 1.7350188686001686

Epoch: 6| Step: 5
Training loss: 1.1042909622192383
Validation loss: 1.7165056095328382

Epoch: 6| Step: 6
Training loss: 0.9503037929534912
Validation loss: 1.7574775936783

Epoch: 6| Step: 7
Training loss: 1.724129557609558
Validation loss: 1.704462707042694

Epoch: 6| Step: 8
Training loss: 1.2835631370544434
Validation loss: 1.7905785268352878

Epoch: 6| Step: 9
Training loss: 0.8813657760620117
Validation loss: 1.7875777098440355

Epoch: 6| Step: 10
Training loss: 1.4359242916107178
Validation loss: 1.7092924412860666

Epoch: 6| Step: 11
Training loss: 0.5882081985473633
Validation loss: 1.7884078718000842

Epoch: 6| Step: 12
Training loss: 1.3962312936782837
Validation loss: 1.8130545385422245

Epoch: 6| Step: 13
Training loss: 0.9381268620491028
Validation loss: 1.7378316733144945

Epoch: 420| Step: 0
Training loss: 1.2667934894561768
Validation loss: 1.8286533932532034

Epoch: 6| Step: 1
Training loss: 1.1007171869277954
Validation loss: 1.765364860975614

Epoch: 6| Step: 2
Training loss: 0.9852477312088013
Validation loss: 1.7766425199406122

Epoch: 6| Step: 3
Training loss: 1.433590292930603
Validation loss: 1.7308572537155562

Epoch: 6| Step: 4
Training loss: 0.7368307113647461
Validation loss: 1.783373494302073

Epoch: 6| Step: 5
Training loss: 1.1941256523132324
Validation loss: 1.7259414695924329

Epoch: 6| Step: 6
Training loss: 1.1837756633758545
Validation loss: 1.7370662099571639

Epoch: 6| Step: 7
Training loss: 0.863416314125061
Validation loss: 1.7562822257318804

Epoch: 6| Step: 8
Training loss: 1.0710265636444092
Validation loss: 1.7520873918328235

Epoch: 6| Step: 9
Training loss: 1.2500431537628174
Validation loss: 1.7957156576136106

Epoch: 6| Step: 10
Training loss: 0.9297124147415161
Validation loss: 1.8129535823739984

Epoch: 6| Step: 11
Training loss: 1.4112950563430786
Validation loss: 1.818999159720636

Epoch: 6| Step: 12
Training loss: 1.3623950481414795
Validation loss: 1.7565980098580802

Epoch: 6| Step: 13
Training loss: 0.5441907048225403
Validation loss: 1.7180994338886713

Epoch: 421| Step: 0
Training loss: 1.4532755613327026
Validation loss: 1.7364793439065256

Epoch: 6| Step: 1
Training loss: 1.0318286418914795
Validation loss: 1.8306140310020858

Epoch: 6| Step: 2
Training loss: 0.7436522245407104
Validation loss: 1.7228026261893652

Epoch: 6| Step: 3
Training loss: 1.1842341423034668
Validation loss: 1.8066872191685501

Epoch: 6| Step: 4
Training loss: 1.2257091999053955
Validation loss: 1.7890155289762764

Epoch: 6| Step: 5
Training loss: 1.2541277408599854
Validation loss: 1.7783049562925934

Epoch: 6| Step: 6
Training loss: 1.135232925415039
Validation loss: 1.7125995107876357

Epoch: 6| Step: 7
Training loss: 1.4889761209487915
Validation loss: 1.7918237409284037

Epoch: 6| Step: 8
Training loss: 0.7719473242759705
Validation loss: 1.8253841130964217

Epoch: 6| Step: 9
Training loss: 0.8694949746131897
Validation loss: 1.8021282521627282

Epoch: 6| Step: 10
Training loss: 0.8211974501609802
Validation loss: 1.7367745035438127

Epoch: 6| Step: 11
Training loss: 1.1266157627105713
Validation loss: 1.75022054103113

Epoch: 6| Step: 12
Training loss: 1.1599682569503784
Validation loss: 1.75078321015963

Epoch: 6| Step: 13
Training loss: 0.6709187626838684
Validation loss: 1.7470685628152662

Epoch: 422| Step: 0
Training loss: 0.9458507895469666
Validation loss: 1.7507170861767185

Epoch: 6| Step: 1
Training loss: 1.1490893363952637
Validation loss: 1.76235976014086

Epoch: 6| Step: 2
Training loss: 0.977662205696106
Validation loss: 1.7650117733145272

Epoch: 6| Step: 3
Training loss: 0.9778537154197693
Validation loss: 1.7720998307710052

Epoch: 6| Step: 4
Training loss: 1.3927035331726074
Validation loss: 1.7667441291193808

Epoch: 6| Step: 5
Training loss: 1.5431711673736572
Validation loss: 1.807191647509093

Epoch: 6| Step: 6
Training loss: 0.8153960108757019
Validation loss: 1.833068629746796

Epoch: 6| Step: 7
Training loss: 1.386739730834961
Validation loss: 1.7909925265978741

Epoch: 6| Step: 8
Training loss: 1.0629479885101318
Validation loss: 1.8152443106456468

Epoch: 6| Step: 9
Training loss: 0.990777850151062
Validation loss: 1.7947920894110074

Epoch: 6| Step: 10
Training loss: 0.8734719753265381
Validation loss: 1.8145243608823387

Epoch: 6| Step: 11
Training loss: 1.1516752243041992
Validation loss: 1.7796518853915635

Epoch: 6| Step: 12
Training loss: 0.7396830916404724
Validation loss: 1.7603729283937843

Epoch: 6| Step: 13
Training loss: 1.0496336221694946
Validation loss: 1.7830238726831251

Epoch: 423| Step: 0
Training loss: 0.6454181671142578
Validation loss: 1.7295212617484472

Epoch: 6| Step: 1
Training loss: 0.569499671459198
Validation loss: 1.7402367207311815

Epoch: 6| Step: 2
Training loss: 0.8547958731651306
Validation loss: 1.7397469705150974

Epoch: 6| Step: 3
Training loss: 1.3372328281402588
Validation loss: 1.73866016890413

Epoch: 6| Step: 4
Training loss: 0.9998834133148193
Validation loss: 1.7636908036406322

Epoch: 6| Step: 5
Training loss: 1.0812609195709229
Validation loss: 1.7751852184213617

Epoch: 6| Step: 6
Training loss: 1.8960621356964111
Validation loss: 1.7668186926072644

Epoch: 6| Step: 7
Training loss: 1.314561128616333
Validation loss: 1.7837462399595527

Epoch: 6| Step: 8
Training loss: 0.9075131416320801
Validation loss: 1.7787916070671492

Epoch: 6| Step: 9
Training loss: 0.7129627466201782
Validation loss: 1.7538962543651622

Epoch: 6| Step: 10
Training loss: 1.4367554187774658
Validation loss: 1.7641962023191555

Epoch: 6| Step: 11
Training loss: 1.3689091205596924
Validation loss: 1.7688102311985467

Epoch: 6| Step: 12
Training loss: 0.9038710594177246
Validation loss: 1.7526273342870897

Epoch: 6| Step: 13
Training loss: 1.023147463798523
Validation loss: 1.77689605118126

Epoch: 424| Step: 0
Training loss: 1.1437543630599976
Validation loss: 1.8078372798940188

Epoch: 6| Step: 1
Training loss: 1.176282286643982
Validation loss: 1.8453709848465458

Epoch: 6| Step: 2
Training loss: 1.0962704420089722
Validation loss: 1.8062298067154423

Epoch: 6| Step: 3
Training loss: 1.260871410369873
Validation loss: 1.8630952732537382

Epoch: 6| Step: 4
Training loss: 1.2196061611175537
Validation loss: 1.9157723739583006

Epoch: 6| Step: 5
Training loss: 1.2804844379425049
Validation loss: 1.862152950738066

Epoch: 6| Step: 6
Training loss: 0.543083667755127
Validation loss: 1.8161007845273582

Epoch: 6| Step: 7
Training loss: 0.9095479249954224
Validation loss: 1.79841515966641

Epoch: 6| Step: 8
Training loss: 1.566526174545288
Validation loss: 1.8219872097815237

Epoch: 6| Step: 9
Training loss: 0.642018735408783
Validation loss: 1.7726453683709587

Epoch: 6| Step: 10
Training loss: 1.2600741386413574
Validation loss: 1.753947416941325

Epoch: 6| Step: 11
Training loss: 0.8381471037864685
Validation loss: 1.8000090429859776

Epoch: 6| Step: 12
Training loss: 1.3531222343444824
Validation loss: 1.7255739460709274

Epoch: 6| Step: 13
Training loss: 0.8507593870162964
Validation loss: 1.7125320972934845

Epoch: 425| Step: 0
Training loss: 1.574389100074768
Validation loss: 1.7728926417648152

Epoch: 6| Step: 1
Training loss: 1.3330413103103638
Validation loss: 1.718034778871844

Epoch: 6| Step: 2
Training loss: 0.9443460702896118
Validation loss: 1.7939743931575487

Epoch: 6| Step: 3
Training loss: 0.7346442937850952
Validation loss: 1.7489495200495566

Epoch: 6| Step: 4
Training loss: 1.1950513124465942
Validation loss: 1.7679180893846738

Epoch: 6| Step: 5
Training loss: 0.8298366069793701
Validation loss: 1.7565367542287356

Epoch: 6| Step: 6
Training loss: 1.101576328277588
Validation loss: 1.7240835787147604

Epoch: 6| Step: 7
Training loss: 1.0717074871063232
Validation loss: 1.7701413785257647

Epoch: 6| Step: 8
Training loss: 1.5428662300109863
Validation loss: 1.808307465686593

Epoch: 6| Step: 9
Training loss: 1.0774898529052734
Validation loss: 1.7657056752071585

Epoch: 6| Step: 10
Training loss: 0.8792938590049744
Validation loss: 1.7823405355535529

Epoch: 6| Step: 11
Training loss: 0.7410869598388672
Validation loss: 1.818524984903233

Epoch: 6| Step: 12
Training loss: 0.9614571332931519
Validation loss: 1.8109700756688272

Epoch: 6| Step: 13
Training loss: 1.0116140842437744
Validation loss: 1.7858808809711086

Epoch: 426| Step: 0
Training loss: 0.8957889676094055
Validation loss: 1.8153063892036356

Epoch: 6| Step: 1
Training loss: 1.5286073684692383
Validation loss: 1.7453646249668573

Epoch: 6| Step: 2
Training loss: 1.5109281539916992
Validation loss: 1.7651494446621145

Epoch: 6| Step: 3
Training loss: 0.7694804072380066
Validation loss: 1.7672707214150378

Epoch: 6| Step: 4
Training loss: 0.7792602777481079
Validation loss: 1.7840674551584388

Epoch: 6| Step: 5
Training loss: 0.8272541165351868
Validation loss: 1.7433729966481526

Epoch: 6| Step: 6
Training loss: 0.8130935430526733
Validation loss: 1.8015676326649164

Epoch: 6| Step: 7
Training loss: 0.8952434659004211
Validation loss: 1.6898287342440697

Epoch: 6| Step: 8
Training loss: 1.0001474618911743
Validation loss: 1.7685589046888455

Epoch: 6| Step: 9
Training loss: 0.8658194541931152
Validation loss: 1.7892513505874141

Epoch: 6| Step: 10
Training loss: 1.612667202949524
Validation loss: 1.7695783133147864

Epoch: 6| Step: 11
Training loss: 0.9506045579910278
Validation loss: 1.7374014264793807

Epoch: 6| Step: 12
Training loss: 1.4074523448944092
Validation loss: 1.7668659123041297

Epoch: 6| Step: 13
Training loss: 1.4988175630569458
Validation loss: 1.786341610775199

Epoch: 427| Step: 0
Training loss: 0.7134702205657959
Validation loss: 1.7540284882309616

Epoch: 6| Step: 1
Training loss: 1.1749168634414673
Validation loss: 1.7296876035710818

Epoch: 6| Step: 2
Training loss: 1.0596626996994019
Validation loss: 1.7383051239034182

Epoch: 6| Step: 3
Training loss: 1.254817247390747
Validation loss: 1.7123372067687332

Epoch: 6| Step: 4
Training loss: 1.1073321104049683
Validation loss: 1.7397810002808929

Epoch: 6| Step: 5
Training loss: 1.2640368938446045
Validation loss: 1.7598097599962705

Epoch: 6| Step: 6
Training loss: 1.1515451669692993
Validation loss: 1.7821089080584946

Epoch: 6| Step: 7
Training loss: 1.185239315032959
Validation loss: 1.8176601189439014

Epoch: 6| Step: 8
Training loss: 1.2475687265396118
Validation loss: 1.7677088886178949

Epoch: 6| Step: 9
Training loss: 0.7107163071632385
Validation loss: 1.7992891983319355

Epoch: 6| Step: 10
Training loss: 0.8558630347251892
Validation loss: 1.7920051390124905

Epoch: 6| Step: 11
Training loss: 0.9500126242637634
Validation loss: 1.789121320170741

Epoch: 6| Step: 12
Training loss: 1.6265912055969238
Validation loss: 1.7783343945780108

Epoch: 6| Step: 13
Training loss: 1.1275534629821777
Validation loss: 1.7664908914155857

Epoch: 428| Step: 0
Training loss: 0.8973174691200256
Validation loss: 1.8275736352448821

Epoch: 6| Step: 1
Training loss: 0.6673467755317688
Validation loss: 1.8231420106785272

Epoch: 6| Step: 2
Training loss: 1.5565025806427002
Validation loss: 1.7868188683704664

Epoch: 6| Step: 3
Training loss: 1.152829647064209
Validation loss: 1.8382078575831589

Epoch: 6| Step: 4
Training loss: 0.9579468369483948
Validation loss: 1.7525040174043307

Epoch: 6| Step: 5
Training loss: 1.4496177434921265
Validation loss: 1.8136795490018782

Epoch: 6| Step: 6
Training loss: 1.8846826553344727
Validation loss: 1.7827545519798034

Epoch: 6| Step: 7
Training loss: 0.6595659255981445
Validation loss: 1.8366966170649375

Epoch: 6| Step: 8
Training loss: 1.1910992860794067
Validation loss: 1.7422664396224483

Epoch: 6| Step: 9
Training loss: 0.6586374044418335
Validation loss: 1.8072275038688415

Epoch: 6| Step: 10
Training loss: 1.0914244651794434
Validation loss: 1.778895055094073

Epoch: 6| Step: 11
Training loss: 0.9759554862976074
Validation loss: 1.7468350497625207

Epoch: 6| Step: 12
Training loss: 0.9700015187263489
Validation loss: 1.7962762719841414

Epoch: 6| Step: 13
Training loss: 0.6778072714805603
Validation loss: 1.7503664929379699

Epoch: 429| Step: 0
Training loss: 0.9491883516311646
Validation loss: 1.7682246136408981

Epoch: 6| Step: 1
Training loss: 0.9769953489303589
Validation loss: 1.7427283910013014

Epoch: 6| Step: 2
Training loss: 0.9447485208511353
Validation loss: 1.8025975111992127

Epoch: 6| Step: 3
Training loss: 1.1809852123260498
Validation loss: 1.7786180691052509

Epoch: 6| Step: 4
Training loss: 0.8674584031105042
Validation loss: 1.7704590571823942

Epoch: 6| Step: 5
Training loss: 1.2077503204345703
Validation loss: 1.8090507497069657

Epoch: 6| Step: 6
Training loss: 1.1270172595977783
Validation loss: 1.7577391850051058

Epoch: 6| Step: 7
Training loss: 1.6891438961029053
Validation loss: 1.8113385310737036

Epoch: 6| Step: 8
Training loss: 1.2955036163330078
Validation loss: 1.7376518621239612

Epoch: 6| Step: 9
Training loss: 0.9007428288459778
Validation loss: 1.7706098120699647

Epoch: 6| Step: 10
Training loss: 0.8054091930389404
Validation loss: 1.7952713158822828

Epoch: 6| Step: 11
Training loss: 0.6788833141326904
Validation loss: 1.815348958456388

Epoch: 6| Step: 12
Training loss: 1.2933292388916016
Validation loss: 1.8107959993423954

Epoch: 6| Step: 13
Training loss: 1.3107465505599976
Validation loss: 1.8609855764655656

Epoch: 430| Step: 0
Training loss: 0.8584643602371216
Validation loss: 1.7905234700889998

Epoch: 6| Step: 1
Training loss: 0.789194643497467
Validation loss: 1.8226171411493772

Epoch: 6| Step: 2
Training loss: 1.1293197870254517
Validation loss: 1.781276293980178

Epoch: 6| Step: 3
Training loss: 1.1050000190734863
Validation loss: 1.7853572676258702

Epoch: 6| Step: 4
Training loss: 0.811880886554718
Validation loss: 1.7146168114036642

Epoch: 6| Step: 5
Training loss: 0.4566919803619385
Validation loss: 1.8001121538941578

Epoch: 6| Step: 6
Training loss: 1.3695706129074097
Validation loss: 1.6813552738517843

Epoch: 6| Step: 7
Training loss: 0.7091877460479736
Validation loss: 1.7148901262590963

Epoch: 6| Step: 8
Training loss: 1.4597253799438477
Validation loss: 1.7233164438637354

Epoch: 6| Step: 9
Training loss: 1.3459787368774414
Validation loss: 1.7333084972955848

Epoch: 6| Step: 10
Training loss: 1.4720641374588013
Validation loss: 1.7232063508802844

Epoch: 6| Step: 11
Training loss: 1.1780126094818115
Validation loss: 1.7637845277786255

Epoch: 6| Step: 12
Training loss: 1.2983417510986328
Validation loss: 1.7581699138046594

Epoch: 6| Step: 13
Training loss: 1.1678028106689453
Validation loss: 1.7831738187420754

Epoch: 431| Step: 0
Training loss: 0.8760926127433777
Validation loss: 1.7652687705973142

Epoch: 6| Step: 1
Training loss: 0.8703885078430176
Validation loss: 1.8732299266322967

Epoch: 6| Step: 2
Training loss: 0.983457088470459
Validation loss: 1.7747792069629957

Epoch: 6| Step: 3
Training loss: 1.083808183670044
Validation loss: 1.7935547815856112

Epoch: 6| Step: 4
Training loss: 1.8079324960708618
Validation loss: 1.7888077510300504

Epoch: 6| Step: 5
Training loss: 1.646108865737915
Validation loss: 1.7756421886464602

Epoch: 6| Step: 6
Training loss: 0.9063064455986023
Validation loss: 1.8273765733165126

Epoch: 6| Step: 7
Training loss: 0.7175752520561218
Validation loss: 1.7667617977306407

Epoch: 6| Step: 8
Training loss: 0.6582304835319519
Validation loss: 1.7745981690704182

Epoch: 6| Step: 9
Training loss: 1.595539927482605
Validation loss: 1.7494102806173346

Epoch: 6| Step: 10
Training loss: 1.052612543106079
Validation loss: 1.7531793899433588

Epoch: 6| Step: 11
Training loss: 0.8889610171318054
Validation loss: 1.770021721880923

Epoch: 6| Step: 12
Training loss: 0.9427554607391357
Validation loss: 1.7831874714102796

Epoch: 6| Step: 13
Training loss: 1.2491612434387207
Validation loss: 1.7895830792765464

Epoch: 432| Step: 0
Training loss: 1.0156922340393066
Validation loss: 1.8213661486102688

Epoch: 6| Step: 1
Training loss: 0.9064525365829468
Validation loss: 1.7892094863358365

Epoch: 6| Step: 2
Training loss: 1.0971927642822266
Validation loss: 1.7778534068856189

Epoch: 6| Step: 3
Training loss: 0.6854864358901978
Validation loss: 1.784633017355396

Epoch: 6| Step: 4
Training loss: 1.0559099912643433
Validation loss: 1.756860980423548

Epoch: 6| Step: 5
Training loss: 1.1246613264083862
Validation loss: 1.7424328724543254

Epoch: 6| Step: 6
Training loss: 1.6703495979309082
Validation loss: 1.765031647938554

Epoch: 6| Step: 7
Training loss: 1.1801046133041382
Validation loss: 1.7587465317018571

Epoch: 6| Step: 8
Training loss: 0.7083277702331543
Validation loss: 1.7465815114718612

Epoch: 6| Step: 9
Training loss: 1.3350094556808472
Validation loss: 1.7593130603913338

Epoch: 6| Step: 10
Training loss: 1.287805438041687
Validation loss: 1.8150021901694677

Epoch: 6| Step: 11
Training loss: 0.8304038643836975
Validation loss: 1.8008977828487274

Epoch: 6| Step: 12
Training loss: 0.643757164478302
Validation loss: 1.8153457257055468

Epoch: 6| Step: 13
Training loss: 1.826712727546692
Validation loss: 1.81964321162111

Epoch: 433| Step: 0
Training loss: 0.8255412578582764
Validation loss: 1.7647408849449568

Epoch: 6| Step: 1
Training loss: 0.8315985798835754
Validation loss: 1.806628716889248

Epoch: 6| Step: 2
Training loss: 1.2612807750701904
Validation loss: 1.7372387057991439

Epoch: 6| Step: 3
Training loss: 1.3962900638580322
Validation loss: 1.7748416290488294

Epoch: 6| Step: 4
Training loss: 0.8412958383560181
Validation loss: 1.765632616576328

Epoch: 6| Step: 5
Training loss: 1.4192993640899658
Validation loss: 1.7978091880839357

Epoch: 6| Step: 6
Training loss: 0.7784072756767273
Validation loss: 1.7578088929576259

Epoch: 6| Step: 7
Training loss: 1.1712114810943604
Validation loss: 1.802757837439096

Epoch: 6| Step: 8
Training loss: 1.714413046836853
Validation loss: 1.7673252731241205

Epoch: 6| Step: 9
Training loss: 0.64399653673172
Validation loss: 1.7826044469751336

Epoch: 6| Step: 10
Training loss: 1.2120407819747925
Validation loss: 1.800142406135477

Epoch: 6| Step: 11
Training loss: 0.7976697683334351
Validation loss: 1.7285001252287178

Epoch: 6| Step: 12
Training loss: 0.9029184579849243
Validation loss: 1.7816115143478557

Epoch: 6| Step: 13
Training loss: 1.0758955478668213
Validation loss: 1.7724215151161276

Epoch: 434| Step: 0
Training loss: 1.427607536315918
Validation loss: 1.7676335098922893

Epoch: 6| Step: 1
Training loss: 0.7545042634010315
Validation loss: 1.7616177246134768

Epoch: 6| Step: 2
Training loss: 0.6975612640380859
Validation loss: 1.7650031864002187

Epoch: 6| Step: 3
Training loss: 1.2178459167480469
Validation loss: 1.7752701492719754

Epoch: 6| Step: 4
Training loss: 1.6673368215560913
Validation loss: 1.7385144131157988

Epoch: 6| Step: 5
Training loss: 0.9941806197166443
Validation loss: 1.7715047456884896

Epoch: 6| Step: 6
Training loss: 0.7717881202697754
Validation loss: 1.765884163559124

Epoch: 6| Step: 7
Training loss: 1.65911066532135
Validation loss: 1.7252325652748026

Epoch: 6| Step: 8
Training loss: 1.0178725719451904
Validation loss: 1.760251268263786

Epoch: 6| Step: 9
Training loss: 0.9859063029289246
Validation loss: 1.7858825088829122

Epoch: 6| Step: 10
Training loss: 0.5241748094558716
Validation loss: 1.7771388792222547

Epoch: 6| Step: 11
Training loss: 0.6549358367919922
Validation loss: 1.796443203444122

Epoch: 6| Step: 12
Training loss: 0.6794848442077637
Validation loss: 1.739526423074866

Epoch: 6| Step: 13
Training loss: 1.6409096717834473
Validation loss: 1.7157637919149091

Epoch: 435| Step: 0
Training loss: 0.9731670618057251
Validation loss: 1.7468265641120173

Epoch: 6| Step: 1
Training loss: 0.8786370158195496
Validation loss: 1.7699630811650267

Epoch: 6| Step: 2
Training loss: 0.807553768157959
Validation loss: 1.7967656825178413

Epoch: 6| Step: 3
Training loss: 0.8786223530769348
Validation loss: 1.8275837103525798

Epoch: 6| Step: 4
Training loss: 1.0292465686798096
Validation loss: 1.796041411738242

Epoch: 6| Step: 5
Training loss: 0.8240342736244202
Validation loss: 1.8364296779837659

Epoch: 6| Step: 6
Training loss: 1.6416981220245361
Validation loss: 1.7570289206761185

Epoch: 6| Step: 7
Training loss: 0.7835838794708252
Validation loss: 1.833660715369768

Epoch: 6| Step: 8
Training loss: 1.288522481918335
Validation loss: 1.8438720369851718

Epoch: 6| Step: 9
Training loss: 1.653613805770874
Validation loss: 1.795494056517078

Epoch: 6| Step: 10
Training loss: 0.9040333032608032
Validation loss: 1.7456005439963391

Epoch: 6| Step: 11
Training loss: 0.8271856307983398
Validation loss: 1.791046723242729

Epoch: 6| Step: 12
Training loss: 0.7631293535232544
Validation loss: 1.8106187928107478

Epoch: 6| Step: 13
Training loss: 2.260801315307617
Validation loss: 1.7366561043647029

Epoch: 436| Step: 0
Training loss: 1.171748399734497
Validation loss: 1.748940110206604

Epoch: 6| Step: 1
Training loss: 0.7117276191711426
Validation loss: 1.7199502529636506

Epoch: 6| Step: 2
Training loss: 0.7039012908935547
Validation loss: 1.7861662475011681

Epoch: 6| Step: 3
Training loss: 0.8931522369384766
Validation loss: 1.7493319626777404

Epoch: 6| Step: 4
Training loss: 1.173293113708496
Validation loss: 1.7693596962959535

Epoch: 6| Step: 5
Training loss: 1.1876405477523804
Validation loss: 1.7796189900367492

Epoch: 6| Step: 6
Training loss: 0.6422603726387024
Validation loss: 1.72704065615131

Epoch: 6| Step: 7
Training loss: 0.9976640939712524
Validation loss: 1.7329215618871874

Epoch: 6| Step: 8
Training loss: 1.3918079137802124
Validation loss: 1.740787011320873

Epoch: 6| Step: 9
Training loss: 1.4014928340911865
Validation loss: 1.762306740207057

Epoch: 6| Step: 10
Training loss: 1.0605603456497192
Validation loss: 1.732644037533832

Epoch: 6| Step: 11
Training loss: 0.7054500579833984
Validation loss: 1.7465792061180196

Epoch: 6| Step: 12
Training loss: 1.202742099761963
Validation loss: 1.7417612268078713

Epoch: 6| Step: 13
Training loss: 1.9087554216384888
Validation loss: 1.832357894989752

Epoch: 437| Step: 0
Training loss: 0.5049653649330139
Validation loss: 1.7987042575754144

Epoch: 6| Step: 1
Training loss: 1.6755187511444092
Validation loss: 1.8059253346535467

Epoch: 6| Step: 2
Training loss: 0.7349563837051392
Validation loss: 1.843584615697143

Epoch: 6| Step: 3
Training loss: 1.5286335945129395
Validation loss: 1.836723304563953

Epoch: 6| Step: 4
Training loss: 0.9539626836776733
Validation loss: 1.8584048094287995

Epoch: 6| Step: 5
Training loss: 0.6693799495697021
Validation loss: 1.8336248859282462

Epoch: 6| Step: 6
Training loss: 1.2200844287872314
Validation loss: 1.8526156179366573

Epoch: 6| Step: 7
Training loss: 1.127394437789917
Validation loss: 1.835009228798651

Epoch: 6| Step: 8
Training loss: 0.8961713314056396
Validation loss: 1.7735712746138215

Epoch: 6| Step: 9
Training loss: 1.4072827100753784
Validation loss: 1.8093136959178473

Epoch: 6| Step: 10
Training loss: 1.0459895133972168
Validation loss: 1.7262086022284724

Epoch: 6| Step: 11
Training loss: 0.9975312948226929
Validation loss: 1.7601860005368468

Epoch: 6| Step: 12
Training loss: 1.0984382629394531
Validation loss: 1.7490722953632314

Epoch: 6| Step: 13
Training loss: 1.6583791971206665
Validation loss: 1.7888457108569402

Epoch: 438| Step: 0
Training loss: 0.6837894916534424
Validation loss: 1.7430578611230338

Epoch: 6| Step: 1
Training loss: 1.4453833103179932
Validation loss: 1.720917651730199

Epoch: 6| Step: 2
Training loss: 0.8223363161087036
Validation loss: 1.7883086794166154

Epoch: 6| Step: 3
Training loss: 0.8563585877418518
Validation loss: 1.7624489376621861

Epoch: 6| Step: 4
Training loss: 0.9039998054504395
Validation loss: 1.8034079613224152

Epoch: 6| Step: 5
Training loss: 1.0200154781341553
Validation loss: 1.7379972063085085

Epoch: 6| Step: 6
Training loss: 1.266242265701294
Validation loss: 1.796180199551326

Epoch: 6| Step: 7
Training loss: 0.9659163951873779
Validation loss: 1.760986089706421

Epoch: 6| Step: 8
Training loss: 1.170316219329834
Validation loss: 1.7460558734914309

Epoch: 6| Step: 9
Training loss: 0.9322178363800049
Validation loss: 1.7612834797110608

Epoch: 6| Step: 10
Training loss: 1.372527837753296
Validation loss: 1.8070268746345275

Epoch: 6| Step: 11
Training loss: 1.2908070087432861
Validation loss: 1.81079351645644

Epoch: 6| Step: 12
Training loss: 1.0911507606506348
Validation loss: 1.7957752148310344

Epoch: 6| Step: 13
Training loss: 1.0221456289291382
Validation loss: 1.7747366274556806

Epoch: 439| Step: 0
Training loss: 0.8689545392990112
Validation loss: 1.7795141384165774

Epoch: 6| Step: 1
Training loss: 1.1130409240722656
Validation loss: 1.7881461292184808

Epoch: 6| Step: 2
Training loss: 0.6596093773841858
Validation loss: 1.8135012016501477

Epoch: 6| Step: 3
Training loss: 1.1828351020812988
Validation loss: 1.7426954123281664

Epoch: 6| Step: 4
Training loss: 1.117018461227417
Validation loss: 1.7395739260540213

Epoch: 6| Step: 5
Training loss: 1.2849186658859253
Validation loss: 1.7931791467051352

Epoch: 6| Step: 6
Training loss: 1.3980791568756104
Validation loss: 1.746548391157581

Epoch: 6| Step: 7
Training loss: 1.30647873878479
Validation loss: 1.8263176102792062

Epoch: 6| Step: 8
Training loss: 0.3230508267879486
Validation loss: 1.790957199629917

Epoch: 6| Step: 9
Training loss: 0.914673388004303
Validation loss: 1.7689710419665101

Epoch: 6| Step: 10
Training loss: 0.8605430722236633
Validation loss: 1.7930238182826708

Epoch: 6| Step: 11
Training loss: 1.5352922677993774
Validation loss: 1.7408720024170414

Epoch: 6| Step: 12
Training loss: 1.3115484714508057
Validation loss: 1.717803660259452

Epoch: 6| Step: 13
Training loss: 0.9192977547645569
Validation loss: 1.7995725485586351

Epoch: 440| Step: 0
Training loss: 0.9085866212844849
Validation loss: 1.7630712075900006

Epoch: 6| Step: 1
Training loss: 1.3980565071105957
Validation loss: 1.7838302978905298

Epoch: 6| Step: 2
Training loss: 1.0391716957092285
Validation loss: 1.8201623962771507

Epoch: 6| Step: 3
Training loss: 0.6447422504425049
Validation loss: 1.8249447358551847

Epoch: 6| Step: 4
Training loss: 1.1767489910125732
Validation loss: 1.791787141112871

Epoch: 6| Step: 5
Training loss: 1.3401589393615723
Validation loss: 1.7522139651800996

Epoch: 6| Step: 6
Training loss: 1.1870005130767822
Validation loss: 1.7981598825864895

Epoch: 6| Step: 7
Training loss: 1.465264916419983
Validation loss: 1.7481585510315434

Epoch: 6| Step: 8
Training loss: 1.1028118133544922
Validation loss: 1.701810311245662

Epoch: 6| Step: 9
Training loss: 0.46492546796798706
Validation loss: 1.7443473960763665

Epoch: 6| Step: 10
Training loss: 1.358351469039917
Validation loss: 1.7947723263053483

Epoch: 6| Step: 11
Training loss: 0.4891056418418884
Validation loss: 1.7687979154689337

Epoch: 6| Step: 12
Training loss: 0.9006003141403198
Validation loss: 1.7606308101325907

Epoch: 6| Step: 13
Training loss: 2.250335693359375
Validation loss: 1.78051834465355

Epoch: 441| Step: 0
Training loss: 0.6372513175010681
Validation loss: 1.7780768999489405

Epoch: 6| Step: 1
Training loss: 1.149325966835022
Validation loss: 1.774371862411499

Epoch: 6| Step: 2
Training loss: 1.0465037822723389
Validation loss: 1.7564870234458678

Epoch: 6| Step: 3
Training loss: 1.2748504877090454
Validation loss: 1.7506958592322566

Epoch: 6| Step: 4
Training loss: 0.8275247812271118
Validation loss: 1.7823018694436679

Epoch: 6| Step: 5
Training loss: 1.304152488708496
Validation loss: 1.7693089144204253

Epoch: 6| Step: 6
Training loss: 1.1286940574645996
Validation loss: 1.7963095621396137

Epoch: 6| Step: 7
Training loss: 1.468548059463501
Validation loss: 1.742760742864301

Epoch: 6| Step: 8
Training loss: 1.2053532600402832
Validation loss: 1.7828345401312715

Epoch: 6| Step: 9
Training loss: 1.1996779441833496
Validation loss: 1.7877690920265772

Epoch: 6| Step: 10
Training loss: 1.140720248222351
Validation loss: 1.7643486556186472

Epoch: 6| Step: 11
Training loss: 0.8221154808998108
Validation loss: 1.7550903648458502

Epoch: 6| Step: 12
Training loss: 0.7072569131851196
Validation loss: 1.7425047223285963

Epoch: 6| Step: 13
Training loss: 0.6276065111160278
Validation loss: 1.7522588109457364

Epoch: 442| Step: 0
Training loss: 0.7785621881484985
Validation loss: 1.808860744199445

Epoch: 6| Step: 1
Training loss: 0.8759151101112366
Validation loss: 1.7826522293911184

Epoch: 6| Step: 2
Training loss: 0.8368650674819946
Validation loss: 1.755366732997279

Epoch: 6| Step: 3
Training loss: 0.6739495992660522
Validation loss: 1.749973298400961

Epoch: 6| Step: 4
Training loss: 1.1118922233581543
Validation loss: 1.747566443617626

Epoch: 6| Step: 5
Training loss: 1.3388035297393799
Validation loss: 1.731874873561244

Epoch: 6| Step: 6
Training loss: 1.0767042636871338
Validation loss: 1.775421957815847

Epoch: 6| Step: 7
Training loss: 0.9845486879348755
Validation loss: 1.7674261395649244

Epoch: 6| Step: 8
Training loss: 1.106025218963623
Validation loss: 1.7949261614071426

Epoch: 6| Step: 9
Training loss: 1.1157457828521729
Validation loss: 1.7632299469363304

Epoch: 6| Step: 10
Training loss: 1.4156146049499512
Validation loss: 1.7890435918684928

Epoch: 6| Step: 11
Training loss: 0.7638816833496094
Validation loss: 1.7174839101811892

Epoch: 6| Step: 12
Training loss: 1.4341562986373901
Validation loss: 1.781253453223936

Epoch: 6| Step: 13
Training loss: 1.635863184928894
Validation loss: 1.7845460061104066

Epoch: 443| Step: 0
Training loss: 0.6056948900222778
Validation loss: 1.723674294769123

Epoch: 6| Step: 1
Training loss: 0.6914485692977905
Validation loss: 1.785635623880612

Epoch: 6| Step: 2
Training loss: 0.8864882588386536
Validation loss: 1.7910447556485412

Epoch: 6| Step: 3
Training loss: 1.5238862037658691
Validation loss: 1.7689620948606921

Epoch: 6| Step: 4
Training loss: 1.7584820985794067
Validation loss: 1.793963159284284

Epoch: 6| Step: 5
Training loss: 0.7514130473136902
Validation loss: 1.7703527378779587

Epoch: 6| Step: 6
Training loss: 1.0011532306671143
Validation loss: 1.7289049292123446

Epoch: 6| Step: 7
Training loss: 0.8068487644195557
Validation loss: 1.7231887912237516

Epoch: 6| Step: 8
Training loss: 0.7049305438995361
Validation loss: 1.7318108440727316

Epoch: 6| Step: 9
Training loss: 1.2390787601470947
Validation loss: 1.7535568078358967

Epoch: 6| Step: 10
Training loss: 1.3830394744873047
Validation loss: 1.7500464095864245

Epoch: 6| Step: 11
Training loss: 1.3264014720916748
Validation loss: 1.7628182031775033

Epoch: 6| Step: 12
Training loss: 1.073447585105896
Validation loss: 1.7212449914665633

Epoch: 6| Step: 13
Training loss: 1.684434413909912
Validation loss: 1.756570921149305

Epoch: 444| Step: 0
Training loss: 1.1491217613220215
Validation loss: 1.7949332883281093

Epoch: 6| Step: 1
Training loss: 0.8034977912902832
Validation loss: 1.7502827695620957

Epoch: 6| Step: 2
Training loss: 1.3021070957183838
Validation loss: 1.6998825150151406

Epoch: 6| Step: 3
Training loss: 1.0684010982513428
Validation loss: 1.7399946707551197

Epoch: 6| Step: 4
Training loss: 0.8281350135803223
Validation loss: 1.745662684081703

Epoch: 6| Step: 5
Training loss: 1.0458874702453613
Validation loss: 1.7324304478142851

Epoch: 6| Step: 6
Training loss: 0.96750408411026
Validation loss: 1.8300331125977218

Epoch: 6| Step: 7
Training loss: 1.1628566980361938
Validation loss: 1.8181204167745446

Epoch: 6| Step: 8
Training loss: 1.223322868347168
Validation loss: 1.8393064724501742

Epoch: 6| Step: 9
Training loss: 0.9300302863121033
Validation loss: 1.7978122836800032

Epoch: 6| Step: 10
Training loss: 1.3036918640136719
Validation loss: 1.7633805492872834

Epoch: 6| Step: 11
Training loss: 0.9603631496429443
Validation loss: 1.7821848725759855

Epoch: 6| Step: 12
Training loss: 1.3103446960449219
Validation loss: 1.787570873896281

Epoch: 6| Step: 13
Training loss: 0.9705470204353333
Validation loss: 1.7700563169294787

Epoch: 445| Step: 0
Training loss: 0.4909668564796448
Validation loss: 1.7953401483515257

Epoch: 6| Step: 1
Training loss: 1.12221097946167
Validation loss: 1.7186726011255735

Epoch: 6| Step: 2
Training loss: 1.2024697065353394
Validation loss: 1.737559813325123

Epoch: 6| Step: 3
Training loss: 0.9690077304840088
Validation loss: 1.7712304463950537

Epoch: 6| Step: 4
Training loss: 1.1101782321929932
Validation loss: 1.756081094024002

Epoch: 6| Step: 5
Training loss: 1.2109839916229248
Validation loss: 1.759658303312076

Epoch: 6| Step: 6
Training loss: 0.9140627384185791
Validation loss: 1.7564398229763072

Epoch: 6| Step: 7
Training loss: 1.346649169921875
Validation loss: 1.7508738374197355

Epoch: 6| Step: 8
Training loss: 0.8847031593322754
Validation loss: 1.7734603625471874

Epoch: 6| Step: 9
Training loss: 1.2216734886169434
Validation loss: 1.7518169380003406

Epoch: 6| Step: 10
Training loss: 1.1669576168060303
Validation loss: 1.7822865798909178

Epoch: 6| Step: 11
Training loss: 0.8264045715332031
Validation loss: 1.8113745579155542

Epoch: 6| Step: 12
Training loss: 1.1530275344848633
Validation loss: 1.8266806679387246

Epoch: 6| Step: 13
Training loss: 0.9597502946853638
Validation loss: 1.79521143820978

Epoch: 446| Step: 0
Training loss: 0.5888833403587341
Validation loss: 1.7845082718838927

Epoch: 6| Step: 1
Training loss: 0.7876625061035156
Validation loss: 1.8087485169851651

Epoch: 6| Step: 2
Training loss: 0.7463555932044983
Validation loss: 1.7656165669041295

Epoch: 6| Step: 3
Training loss: 1.0812766551971436
Validation loss: 1.801547388876638

Epoch: 6| Step: 4
Training loss: 0.6740313768386841
Validation loss: 1.7287657132712744

Epoch: 6| Step: 5
Training loss: 1.49118971824646
Validation loss: 1.742046111373491

Epoch: 6| Step: 6
Training loss: 0.7751984596252441
Validation loss: 1.7769934810617918

Epoch: 6| Step: 7
Training loss: 0.8540730476379395
Validation loss: 1.750029444694519

Epoch: 6| Step: 8
Training loss: 1.2311519384384155
Validation loss: 1.7770867373353691

Epoch: 6| Step: 9
Training loss: 1.5064250230789185
Validation loss: 1.7599717558071177

Epoch: 6| Step: 10
Training loss: 1.258701205253601
Validation loss: 1.7761327553820867

Epoch: 6| Step: 11
Training loss: 0.8528989553451538
Validation loss: 1.7582116947379163

Epoch: 6| Step: 12
Training loss: 1.8513383865356445
Validation loss: 1.7841201264371154

Epoch: 6| Step: 13
Training loss: 0.7717739939689636
Validation loss: 1.7911039821563228

Epoch: 447| Step: 0
Training loss: 1.072558879852295
Validation loss: 1.7877915020911925

Epoch: 6| Step: 1
Training loss: 0.5071312189102173
Validation loss: 1.8121175227626678

Epoch: 6| Step: 2
Training loss: 0.7548817992210388
Validation loss: 1.780783086694697

Epoch: 6| Step: 3
Training loss: 0.7312934398651123
Validation loss: 1.795854704354399

Epoch: 6| Step: 4
Training loss: 0.7733477354049683
Validation loss: 1.7873094543333976

Epoch: 6| Step: 5
Training loss: 1.2440495491027832
Validation loss: 1.7765299120256979

Epoch: 6| Step: 6
Training loss: 0.9706905484199524
Validation loss: 1.7204736817267634

Epoch: 6| Step: 7
Training loss: 0.8351671695709229
Validation loss: 1.7409637179425967

Epoch: 6| Step: 8
Training loss: 1.247238039970398
Validation loss: 1.8107630283601823

Epoch: 6| Step: 9
Training loss: 1.6044325828552246
Validation loss: 1.7574478028922953

Epoch: 6| Step: 10
Training loss: 1.7188042402267456
Validation loss: 1.7474610049237487

Epoch: 6| Step: 11
Training loss: 1.1389203071594238
Validation loss: 1.759595295434357

Epoch: 6| Step: 12
Training loss: 1.0648595094680786
Validation loss: 1.7267688487165718

Epoch: 6| Step: 13
Training loss: 1.0107563734054565
Validation loss: 1.7743832039576706

Epoch: 448| Step: 0
Training loss: 0.8530929684638977
Validation loss: 1.7640590052450857

Epoch: 6| Step: 1
Training loss: 1.2167048454284668
Validation loss: 1.7597113014549337

Epoch: 6| Step: 2
Training loss: 0.8251391053199768
Validation loss: 1.7674998621786795

Epoch: 6| Step: 3
Training loss: 0.8403472304344177
Validation loss: 1.755665272794744

Epoch: 6| Step: 4
Training loss: 0.550178050994873
Validation loss: 1.7627619005018664

Epoch: 6| Step: 5
Training loss: 0.7127416729927063
Validation loss: 1.8189351353594052

Epoch: 6| Step: 6
Training loss: 1.3492228984832764
Validation loss: 1.8296971282651346

Epoch: 6| Step: 7
Training loss: 1.0585426092147827
Validation loss: 1.788927908866636

Epoch: 6| Step: 8
Training loss: 1.0758954286575317
Validation loss: 1.7710087068619267

Epoch: 6| Step: 9
Training loss: 1.0085800886154175
Validation loss: 1.7900450870554934

Epoch: 6| Step: 10
Training loss: 1.389188528060913
Validation loss: 1.8023001070945495

Epoch: 6| Step: 11
Training loss: 1.2525601387023926
Validation loss: 1.7943141947510421

Epoch: 6| Step: 12
Training loss: 1.168123483657837
Validation loss: 1.7364108165105183

Epoch: 6| Step: 13
Training loss: 1.3749973773956299
Validation loss: 1.7830647307057534

Epoch: 449| Step: 0
Training loss: 1.2622013092041016
Validation loss: 1.7266275741720711

Epoch: 6| Step: 1
Training loss: 1.5578533411026
Validation loss: 1.799524691797072

Epoch: 6| Step: 2
Training loss: 1.1674981117248535
Validation loss: 1.8017003408042334

Epoch: 6| Step: 3
Training loss: 1.2265877723693848
Validation loss: 1.7437348135056034

Epoch: 6| Step: 4
Training loss: 0.7092662453651428
Validation loss: 1.7724402066200011

Epoch: 6| Step: 5
Training loss: 0.8458812236785889
Validation loss: 1.7757109967611169

Epoch: 6| Step: 6
Training loss: 0.9978355169296265
Validation loss: 1.7407283436867498

Epoch: 6| Step: 7
Training loss: 1.2860479354858398
Validation loss: 1.7799027889005599

Epoch: 6| Step: 8
Training loss: 0.31222742795944214
Validation loss: 1.8201067729662823

Epoch: 6| Step: 9
Training loss: 1.1538441181182861
Validation loss: 1.7925893260586647

Epoch: 6| Step: 10
Training loss: 0.7321873903274536
Validation loss: 1.8135721478410947

Epoch: 6| Step: 11
Training loss: 1.096419095993042
Validation loss: 1.7929182744795276

Epoch: 6| Step: 12
Training loss: 1.3373949527740479
Validation loss: 1.765911558622955

Epoch: 6| Step: 13
Training loss: 0.9701597690582275
Validation loss: 1.8268994785124255

Epoch: 450| Step: 0
Training loss: 1.4209493398666382
Validation loss: 1.7695057443393174

Epoch: 6| Step: 1
Training loss: 0.7047889232635498
Validation loss: 1.7586233974784933

Epoch: 6| Step: 2
Training loss: 1.2766560316085815
Validation loss: 1.7461889610495618

Epoch: 6| Step: 3
Training loss: 1.2759970426559448
Validation loss: 1.7694950155032578

Epoch: 6| Step: 4
Training loss: 0.7603466510772705
Validation loss: 1.716522709015877

Epoch: 6| Step: 5
Training loss: 1.037036418914795
Validation loss: 1.720284628611739

Epoch: 6| Step: 6
Training loss: 1.0563595294952393
Validation loss: 1.7085122510951052

Epoch: 6| Step: 7
Training loss: 1.343332052230835
Validation loss: 1.7736484312242078

Epoch: 6| Step: 8
Training loss: 1.3217012882232666
Validation loss: 1.7616186911059963

Epoch: 6| Step: 9
Training loss: 0.977796196937561
Validation loss: 1.7709317732882757

Epoch: 6| Step: 10
Training loss: 0.7448477149009705
Validation loss: 1.765263900961927

Epoch: 6| Step: 11
Training loss: 0.9706674218177795
Validation loss: 1.712832043247838

Epoch: 6| Step: 12
Training loss: 0.778948187828064
Validation loss: 1.746721677882697

Epoch: 6| Step: 13
Training loss: 0.7371234893798828
Validation loss: 1.7869141896565754

Epoch: 451| Step: 0
Training loss: 0.6169099807739258
Validation loss: 1.7538688131557998

Epoch: 6| Step: 1
Training loss: 0.9987474679946899
Validation loss: 1.749395501229071

Epoch: 6| Step: 2
Training loss: 0.8192777633666992
Validation loss: 1.7437391101673085

Epoch: 6| Step: 3
Training loss: 0.9306563138961792
Validation loss: 1.7618992303007392

Epoch: 6| Step: 4
Training loss: 0.7690109014511108
Validation loss: 1.734259875871802

Epoch: 6| Step: 5
Training loss: 1.2112581729888916
Validation loss: 1.7343950399788477

Epoch: 6| Step: 6
Training loss: 1.2630748748779297
Validation loss: 1.797328047854926

Epoch: 6| Step: 7
Training loss: 1.4339290857315063
Validation loss: 1.8385038760400587

Epoch: 6| Step: 8
Training loss: 1.173389196395874
Validation loss: 1.8431711286626837

Epoch: 6| Step: 9
Training loss: 1.292141079902649
Validation loss: 1.792626065592612

Epoch: 6| Step: 10
Training loss: 1.3560924530029297
Validation loss: 1.8158126261926466

Epoch: 6| Step: 11
Training loss: 0.8536748886108398
Validation loss: 1.8019357778692757

Epoch: 6| Step: 12
Training loss: 1.0845742225646973
Validation loss: 1.7800168491178943

Epoch: 6| Step: 13
Training loss: 0.9119910001754761
Validation loss: 1.8033715319889847

Epoch: 452| Step: 0
Training loss: 0.48133930563926697
Validation loss: 1.7577484448750813

Epoch: 6| Step: 1
Training loss: 1.6294450759887695
Validation loss: 1.7522305852623397

Epoch: 6| Step: 2
Training loss: 1.356745719909668
Validation loss: 1.780545788426553

Epoch: 6| Step: 3
Training loss: 0.9091176390647888
Validation loss: 1.7224522508600706

Epoch: 6| Step: 4
Training loss: 0.7023245096206665
Validation loss: 1.7670689987879928

Epoch: 6| Step: 5
Training loss: 0.788871169090271
Validation loss: 1.7299069281547301

Epoch: 6| Step: 6
Training loss: 0.7555037140846252
Validation loss: 1.7751121379995858

Epoch: 6| Step: 7
Training loss: 1.6593819856643677
Validation loss: 1.73047342992598

Epoch: 6| Step: 8
Training loss: 0.8297147750854492
Validation loss: 1.7492095911374657

Epoch: 6| Step: 9
Training loss: 0.6391641497612
Validation loss: 1.7702431435226111

Epoch: 6| Step: 10
Training loss: 1.0279576778411865
Validation loss: 1.7775395377989738

Epoch: 6| Step: 11
Training loss: 1.2089059352874756
Validation loss: 1.8230843646551973

Epoch: 6| Step: 12
Training loss: 1.1093647480010986
Validation loss: 1.8312537734226515

Epoch: 6| Step: 13
Training loss: 1.544237732887268
Validation loss: 1.8512787921454317

Epoch: 453| Step: 0
Training loss: 1.6469794511795044
Validation loss: 1.7828782835314352

Epoch: 6| Step: 1
Training loss: 0.7804858684539795
Validation loss: 1.8250335980487127

Epoch: 6| Step: 2
Training loss: 0.9790933132171631
Validation loss: 1.7370390892028809

Epoch: 6| Step: 3
Training loss: 1.5935311317443848
Validation loss: 1.7904482413363714

Epoch: 6| Step: 4
Training loss: 0.5773005485534668
Validation loss: 1.7692096207731514

Epoch: 6| Step: 5
Training loss: 0.5514535903930664
Validation loss: 1.8110179798577422

Epoch: 6| Step: 6
Training loss: 1.1274042129516602
Validation loss: 1.7451413536584506

Epoch: 6| Step: 7
Training loss: 0.9676729440689087
Validation loss: 1.7631001562200568

Epoch: 6| Step: 8
Training loss: 0.8311022520065308
Validation loss: 1.8343452586922595

Epoch: 6| Step: 9
Training loss: 0.8507598042488098
Validation loss: 1.7670662415924894

Epoch: 6| Step: 10
Training loss: 1.1558536291122437
Validation loss: 1.7260216615533317

Epoch: 6| Step: 11
Training loss: 0.5204602479934692
Validation loss: 1.808064833764107

Epoch: 6| Step: 12
Training loss: 1.4822883605957031
Validation loss: 1.7695351621156097

Epoch: 6| Step: 13
Training loss: 1.7343316078186035
Validation loss: 1.7929970564380768

Epoch: 454| Step: 0
Training loss: 0.9417985677719116
Validation loss: 1.7909943057644753

Epoch: 6| Step: 1
Training loss: 1.258497714996338
Validation loss: 1.8102658333316926

Epoch: 6| Step: 2
Training loss: 1.4442864656448364
Validation loss: 1.8195768479377992

Epoch: 6| Step: 3
Training loss: 1.6070406436920166
Validation loss: 1.881308368457261

Epoch: 6| Step: 4
Training loss: 0.9401537179946899
Validation loss: 1.8666337433681692

Epoch: 6| Step: 5
Training loss: 1.4342414140701294
Validation loss: 1.8966781529047156

Epoch: 6| Step: 6
Training loss: 0.9986474514007568
Validation loss: 1.8491581665572299

Epoch: 6| Step: 7
Training loss: 0.8123865723609924
Validation loss: 1.80476660754091

Epoch: 6| Step: 8
Training loss: 1.1397731304168701
Validation loss: 1.809719342057423

Epoch: 6| Step: 9
Training loss: 0.7959280014038086
Validation loss: 1.793586511765757

Epoch: 6| Step: 10
Training loss: 0.8689826130867004
Validation loss: 1.7562072533433155

Epoch: 6| Step: 11
Training loss: 1.0903258323669434
Validation loss: 1.7391765886737454

Epoch: 6| Step: 12
Training loss: 0.7271820306777954
Validation loss: 1.7724714573993479

Epoch: 6| Step: 13
Training loss: 0.7590653896331787
Validation loss: 1.7475236333826536

Epoch: 455| Step: 0
Training loss: 1.2571825981140137
Validation loss: 1.7497408748954855

Epoch: 6| Step: 1
Training loss: 1.0433382987976074
Validation loss: 1.767763751809315

Epoch: 6| Step: 2
Training loss: 0.6317058205604553
Validation loss: 1.7376419882620535

Epoch: 6| Step: 3
Training loss: 0.7118262052536011
Validation loss: 1.81079436373967

Epoch: 6| Step: 4
Training loss: 0.989014744758606
Validation loss: 1.7855942403116534

Epoch: 6| Step: 5
Training loss: 1.1381618976593018
Validation loss: 1.8259310568532636

Epoch: 6| Step: 6
Training loss: 1.5921125411987305
Validation loss: 1.8241554831945768

Epoch: 6| Step: 7
Training loss: 1.1805064678192139
Validation loss: 1.8189853365703295

Epoch: 6| Step: 8
Training loss: 1.152086615562439
Validation loss: 1.839783727481801

Epoch: 6| Step: 9
Training loss: 1.0094395875930786
Validation loss: 1.8451987838232389

Epoch: 6| Step: 10
Training loss: 1.0945978164672852
Validation loss: 1.8850873157542238

Epoch: 6| Step: 11
Training loss: 1.0272927284240723
Validation loss: 1.8519476203508274

Epoch: 6| Step: 12
Training loss: 1.214699387550354
Validation loss: 1.9218754050552205

Epoch: 6| Step: 13
Training loss: 0.8447001576423645
Validation loss: 1.8895780655645555

Epoch: 456| Step: 0
Training loss: 1.056489109992981
Validation loss: 1.8058439211178852

Epoch: 6| Step: 1
Training loss: 1.063252329826355
Validation loss: 1.791518247255715

Epoch: 6| Step: 2
Training loss: 1.103386402130127
Validation loss: 1.7438170486880886

Epoch: 6| Step: 3
Training loss: 1.1944149732589722
Validation loss: 1.7650741172093216

Epoch: 6| Step: 4
Training loss: 0.8961160778999329
Validation loss: 1.7079654278293732

Epoch: 6| Step: 5
Training loss: 0.5437957048416138
Validation loss: 1.740404760965737

Epoch: 6| Step: 6
Training loss: 1.3539940118789673
Validation loss: 1.7104603718685847

Epoch: 6| Step: 7
Training loss: 1.117384910583496
Validation loss: 1.7507861096371886

Epoch: 6| Step: 8
Training loss: 0.9364215135574341
Validation loss: 1.726769257617253

Epoch: 6| Step: 9
Training loss: 1.1046160459518433
Validation loss: 1.7184873601441741

Epoch: 6| Step: 10
Training loss: 0.6382033228874207
Validation loss: 1.7676927671637586

Epoch: 6| Step: 11
Training loss: 1.0426921844482422
Validation loss: 1.7474398946249357

Epoch: 6| Step: 12
Training loss: 1.5336828231811523
Validation loss: 1.7359188410543627

Epoch: 6| Step: 13
Training loss: 1.3561646938323975
Validation loss: 1.8151569520273516

Epoch: 457| Step: 0
Training loss: 1.268601655960083
Validation loss: 1.7887041056027977

Epoch: 6| Step: 1
Training loss: 1.258724331855774
Validation loss: 1.7956170574311288

Epoch: 6| Step: 2
Training loss: 0.6834794878959656
Validation loss: 1.7916779095126736

Epoch: 6| Step: 3
Training loss: 0.40705329179763794
Validation loss: 1.8036088174389255

Epoch: 6| Step: 4
Training loss: 0.9552658796310425
Validation loss: 1.831511329579097

Epoch: 6| Step: 5
Training loss: 0.8456597328186035
Validation loss: 1.822025756682119

Epoch: 6| Step: 6
Training loss: 1.0480319261550903
Validation loss: 1.7821635559041014

Epoch: 6| Step: 7
Training loss: 1.1045500040054321
Validation loss: 1.8235150460273988

Epoch: 6| Step: 8
Training loss: 0.5815788507461548
Validation loss: 1.7976117249458068

Epoch: 6| Step: 9
Training loss: 1.2557538747787476
Validation loss: 1.7893380042045348

Epoch: 6| Step: 10
Training loss: 1.4281773567199707
Validation loss: 1.812915514874202

Epoch: 6| Step: 11
Training loss: 1.210991382598877
Validation loss: 1.80994172762799

Epoch: 6| Step: 12
Training loss: 1.002110481262207
Validation loss: 1.7545928955078125

Epoch: 6| Step: 13
Training loss: 0.7242520451545715
Validation loss: 1.7328138941077775

Epoch: 458| Step: 0
Training loss: 1.0086162090301514
Validation loss: 1.7724746927138297

Epoch: 6| Step: 1
Training loss: 1.3108066320419312
Validation loss: 1.7817802698381486

Epoch: 6| Step: 2
Training loss: 1.3215630054473877
Validation loss: 1.791231671969096

Epoch: 6| Step: 3
Training loss: 0.755234956741333
Validation loss: 1.7926753067201184

Epoch: 6| Step: 4
Training loss: 1.193934679031372
Validation loss: 1.7758930383190032

Epoch: 6| Step: 5
Training loss: 0.9892785549163818
Validation loss: 1.755307283452762

Epoch: 6| Step: 6
Training loss: 0.6670633554458618
Validation loss: 1.77167211937648

Epoch: 6| Step: 7
Training loss: 0.5628248453140259
Validation loss: 1.8090345090435398

Epoch: 6| Step: 8
Training loss: 0.7619551420211792
Validation loss: 1.738464770778533

Epoch: 6| Step: 9
Training loss: 1.2405357360839844
Validation loss: 1.7615111079267276

Epoch: 6| Step: 10
Training loss: 1.6460087299346924
Validation loss: 1.7879757778618925

Epoch: 6| Step: 11
Training loss: 1.0662751197814941
Validation loss: 1.8465131162315287

Epoch: 6| Step: 12
Training loss: 1.1235700845718384
Validation loss: 1.8165271320650656

Epoch: 6| Step: 13
Training loss: 1.6938390731811523
Validation loss: 1.8441532837447299

Epoch: 459| Step: 0
Training loss: 1.072223424911499
Validation loss: 1.8004376606274677

Epoch: 6| Step: 1
Training loss: 0.6638301610946655
Validation loss: 1.752567760406002

Epoch: 6| Step: 2
Training loss: 1.3060235977172852
Validation loss: 1.8067760390620078

Epoch: 6| Step: 3
Training loss: 1.2510830163955688
Validation loss: 1.8016800348476698

Epoch: 6| Step: 4
Training loss: 1.0760678052902222
Validation loss: 1.733785306253741

Epoch: 6| Step: 5
Training loss: 0.7514889240264893
Validation loss: 1.7777047311106036

Epoch: 6| Step: 6
Training loss: 1.4326411485671997
Validation loss: 1.742114269605247

Epoch: 6| Step: 7
Training loss: 1.029388189315796
Validation loss: 1.7381550547897175

Epoch: 6| Step: 8
Training loss: 0.44088760018348694
Validation loss: 1.7101743413556008

Epoch: 6| Step: 9
Training loss: 0.789186954498291
Validation loss: 1.7929151609379759

Epoch: 6| Step: 10
Training loss: 1.141822338104248
Validation loss: 1.771766067833029

Epoch: 6| Step: 11
Training loss: 1.5184038877487183
Validation loss: 1.7132155292777604

Epoch: 6| Step: 12
Training loss: 1.0875747203826904
Validation loss: 1.7370256864896385

Epoch: 6| Step: 13
Training loss: 0.2632369101047516
Validation loss: 1.7606761288899246

Epoch: 460| Step: 0
Training loss: 1.3210465908050537
Validation loss: 1.8070130912206506

Epoch: 6| Step: 1
Training loss: 1.1388463973999023
Validation loss: 1.751526532634612

Epoch: 6| Step: 2
Training loss: 1.2016164064407349
Validation loss: 1.7628161958468858

Epoch: 6| Step: 3
Training loss: 0.6786361932754517
Validation loss: 1.812937912120614

Epoch: 6| Step: 4
Training loss: 0.6470623016357422
Validation loss: 1.8071923281556816

Epoch: 6| Step: 5
Training loss: 1.4351133108139038
Validation loss: 1.7248283047829904

Epoch: 6| Step: 6
Training loss: 0.7857052087783813
Validation loss: 1.766511001894551

Epoch: 6| Step: 7
Training loss: 0.9264249205589294
Validation loss: 1.7869312660668486

Epoch: 6| Step: 8
Training loss: 0.6029397249221802
Validation loss: 1.7536787550936463

Epoch: 6| Step: 9
Training loss: 1.2013779878616333
Validation loss: 1.7146719463409916

Epoch: 6| Step: 10
Training loss: 1.2812721729278564
Validation loss: 1.7326635199208413

Epoch: 6| Step: 11
Training loss: 0.9080514311790466
Validation loss: 1.795468775174951

Epoch: 6| Step: 12
Training loss: 1.1780072450637817
Validation loss: 1.7708223737696165

Epoch: 6| Step: 13
Training loss: 0.2885858714580536
Validation loss: 1.8123454816879765

Epoch: 461| Step: 0
Training loss: 1.0995628833770752
Validation loss: 1.775728416699235

Epoch: 6| Step: 1
Training loss: 0.7130771279335022
Validation loss: 1.781663171706661

Epoch: 6| Step: 2
Training loss: 1.090335488319397
Validation loss: 1.766074361339692

Epoch: 6| Step: 3
Training loss: 0.9642645120620728
Validation loss: 1.7266581750685168

Epoch: 6| Step: 4
Training loss: 1.429415225982666
Validation loss: 1.7294621954682052

Epoch: 6| Step: 5
Training loss: 1.4700229167938232
Validation loss: 1.765358381373908

Epoch: 6| Step: 6
Training loss: 0.7323899269104004
Validation loss: 1.7874158646470757

Epoch: 6| Step: 7
Training loss: 1.1921496391296387
Validation loss: 1.7975954509550525

Epoch: 6| Step: 8
Training loss: 0.6516443490982056
Validation loss: 1.7443421745813021

Epoch: 6| Step: 9
Training loss: 0.7482806444168091
Validation loss: 1.7080819734963038

Epoch: 6| Step: 10
Training loss: 0.8032214641571045
Validation loss: 1.7180512156537784

Epoch: 6| Step: 11
Training loss: 1.0666640996932983
Validation loss: 1.7415872837907524

Epoch: 6| Step: 12
Training loss: 1.3479294776916504
Validation loss: 1.778078200996563

Epoch: 6| Step: 13
Training loss: 0.9991236925125122
Validation loss: 1.798992827374448

Epoch: 462| Step: 0
Training loss: 1.2977149486541748
Validation loss: 1.761337185418734

Epoch: 6| Step: 1
Training loss: 0.8151746392250061
Validation loss: 1.7681284412260978

Epoch: 6| Step: 2
Training loss: 0.7247850894927979
Validation loss: 1.787879910520328

Epoch: 6| Step: 3
Training loss: 0.6336548924446106
Validation loss: 1.7700668317015453

Epoch: 6| Step: 4
Training loss: 0.9271607398986816
Validation loss: 1.7736325763886975

Epoch: 6| Step: 5
Training loss: 0.800888180732727
Validation loss: 1.768623448187305

Epoch: 6| Step: 6
Training loss: 0.5249109268188477
Validation loss: 1.8090863381662676

Epoch: 6| Step: 7
Training loss: 1.2010226249694824
Validation loss: 1.7779249504048338

Epoch: 6| Step: 8
Training loss: 1.067345142364502
Validation loss: 1.780842169638603

Epoch: 6| Step: 9
Training loss: 1.507981777191162
Validation loss: 1.7390935856808898

Epoch: 6| Step: 10
Training loss: 1.102126955986023
Validation loss: 1.7766251576844083

Epoch: 6| Step: 11
Training loss: 1.093165397644043
Validation loss: 1.7691458232941166

Epoch: 6| Step: 12
Training loss: 1.4465258121490479
Validation loss: 1.7760422627131145

Epoch: 6| Step: 13
Training loss: 1.1459256410598755
Validation loss: 1.7324032527144237

Epoch: 463| Step: 0
Training loss: 1.133088231086731
Validation loss: 1.7291224836021342

Epoch: 6| Step: 1
Training loss: 0.5989378094673157
Validation loss: 1.7647577152457288

Epoch: 6| Step: 2
Training loss: 1.0285024642944336
Validation loss: 1.7351781732292586

Epoch: 6| Step: 3
Training loss: 1.1005293130874634
Validation loss: 1.7589596356115034

Epoch: 6| Step: 4
Training loss: 0.9872323274612427
Validation loss: 1.7567653271459764

Epoch: 6| Step: 5
Training loss: 0.46382489800453186
Validation loss: 1.7460804523960236

Epoch: 6| Step: 6
Training loss: 0.9563314318656921
Validation loss: 1.7117141523668844

Epoch: 6| Step: 7
Training loss: 1.7811768054962158
Validation loss: 1.704404539959405

Epoch: 6| Step: 8
Training loss: 1.0734994411468506
Validation loss: 1.7868215960841025

Epoch: 6| Step: 9
Training loss: 1.179091453552246
Validation loss: 1.800655416263047

Epoch: 6| Step: 10
Training loss: 1.1370028257369995
Validation loss: 1.7951907419389295

Epoch: 6| Step: 11
Training loss: 0.9068570137023926
Validation loss: 1.8438074011956491

Epoch: 6| Step: 12
Training loss: 0.4924832582473755
Validation loss: 1.7905474350016604

Epoch: 6| Step: 13
Training loss: 1.4399834871292114
Validation loss: 1.803730131477438

Epoch: 464| Step: 0
Training loss: 1.2598329782485962
Validation loss: 1.8064532209468145

Epoch: 6| Step: 1
Training loss: 0.935772716999054
Validation loss: 1.7852421409340316

Epoch: 6| Step: 2
Training loss: 1.489758014678955
Validation loss: 1.752230308389151

Epoch: 6| Step: 3
Training loss: 0.8082485795021057
Validation loss: 1.7544135701271795

Epoch: 6| Step: 4
Training loss: 0.6734980344772339
Validation loss: 1.7809412812673917

Epoch: 6| Step: 5
Training loss: 0.6195151209831238
Validation loss: 1.747429637498753

Epoch: 6| Step: 6
Training loss: 1.4131605625152588
Validation loss: 1.776061301590294

Epoch: 6| Step: 7
Training loss: 0.6366115808486938
Validation loss: 1.7654347855557677

Epoch: 6| Step: 8
Training loss: 1.196968913078308
Validation loss: 1.7373484591002106

Epoch: 6| Step: 9
Training loss: 0.8987849950790405
Validation loss: 1.7385853234157767

Epoch: 6| Step: 10
Training loss: 1.212897539138794
Validation loss: 1.7207270822217386

Epoch: 6| Step: 11
Training loss: 1.0151073932647705
Validation loss: 1.730809569999736

Epoch: 6| Step: 12
Training loss: 1.0220203399658203
Validation loss: 1.7556361408643826

Epoch: 6| Step: 13
Training loss: 0.6845054626464844
Validation loss: 1.7665120209417036

Epoch: 465| Step: 0
Training loss: 1.3306804895401
Validation loss: 1.7746218513416987

Epoch: 6| Step: 1
Training loss: 0.681963324546814
Validation loss: 1.7435860326213222

Epoch: 6| Step: 2
Training loss: 0.6707871556282043
Validation loss: 1.7783474691452519

Epoch: 6| Step: 3
Training loss: 0.990543007850647
Validation loss: 1.7994261659601682

Epoch: 6| Step: 4
Training loss: 0.7453584671020508
Validation loss: 1.8060448695254583

Epoch: 6| Step: 5
Training loss: 1.396834373474121
Validation loss: 1.7751248446843957

Epoch: 6| Step: 6
Training loss: 1.394758939743042
Validation loss: 1.7402915364952498

Epoch: 6| Step: 7
Training loss: 1.2157057523727417
Validation loss: 1.7349542238379037

Epoch: 6| Step: 8
Training loss: 0.58451247215271
Validation loss: 1.7898818216016215

Epoch: 6| Step: 9
Training loss: 1.8087102174758911
Validation loss: 1.7324562457300001

Epoch: 6| Step: 10
Training loss: 0.5585317611694336
Validation loss: 1.761919035706469

Epoch: 6| Step: 11
Training loss: 1.5755150318145752
Validation loss: 1.7041790793018956

Epoch: 6| Step: 12
Training loss: 0.6018550395965576
Validation loss: 1.7478237587918517

Epoch: 6| Step: 13
Training loss: 0.5938403606414795
Validation loss: 1.7826014718701761

Epoch: 466| Step: 0
Training loss: 1.4902348518371582
Validation loss: 1.7246762744842037

Epoch: 6| Step: 1
Training loss: 1.167345643043518
Validation loss: 1.7372808892239806

Epoch: 6| Step: 2
Training loss: 0.997634768486023
Validation loss: 1.703106895569832

Epoch: 6| Step: 3
Training loss: 0.7637128829956055
Validation loss: 1.7560011084361742

Epoch: 6| Step: 4
Training loss: 0.701626181602478
Validation loss: 1.8109608157988517

Epoch: 6| Step: 5
Training loss: 1.2099730968475342
Validation loss: 1.735492221770748

Epoch: 6| Step: 6
Training loss: 0.7264703512191772
Validation loss: 1.7693153876130299

Epoch: 6| Step: 7
Training loss: 0.7948510646820068
Validation loss: 1.8270758377608431

Epoch: 6| Step: 8
Training loss: 1.59328031539917
Validation loss: 1.7973561440744708

Epoch: 6| Step: 9
Training loss: 1.6089186668395996
Validation loss: 1.7649341834488737

Epoch: 6| Step: 10
Training loss: 1.035609245300293
Validation loss: 1.7747707533580002

Epoch: 6| Step: 11
Training loss: 0.40998953580856323
Validation loss: 1.845289493119845

Epoch: 6| Step: 12
Training loss: 0.8964719772338867
Validation loss: 1.718040616281571

Epoch: 6| Step: 13
Training loss: 0.5891352891921997
Validation loss: 1.8461342857730003

Epoch: 467| Step: 0
Training loss: 0.6515735983848572
Validation loss: 1.7691806593248922

Epoch: 6| Step: 1
Training loss: 0.8062864542007446
Validation loss: 1.7840258908528153

Epoch: 6| Step: 2
Training loss: 1.4096832275390625
Validation loss: 1.7662472532641502

Epoch: 6| Step: 3
Training loss: 1.4948700666427612
Validation loss: 1.7706255823053338

Epoch: 6| Step: 4
Training loss: 0.9874802827835083
Validation loss: 1.7675364863487981

Epoch: 6| Step: 5
Training loss: 0.7921044230461121
Validation loss: 1.7757064283535045

Epoch: 6| Step: 6
Training loss: 0.5538820028305054
Validation loss: 1.7770831431111982

Epoch: 6| Step: 7
Training loss: 1.2619028091430664
Validation loss: 1.757889166955025

Epoch: 6| Step: 8
Training loss: 0.8653860092163086
Validation loss: 1.7880247997981247

Epoch: 6| Step: 9
Training loss: 0.7675909996032715
Validation loss: 1.7766309733031898

Epoch: 6| Step: 10
Training loss: 0.8874880075454712
Validation loss: 1.7880372456324998

Epoch: 6| Step: 11
Training loss: 1.0336321592330933
Validation loss: 1.7432483550040954

Epoch: 6| Step: 12
Training loss: 1.0578134059906006
Validation loss: 1.763972516982786

Epoch: 6| Step: 13
Training loss: 1.1198666095733643
Validation loss: 1.7816617142769597

Epoch: 468| Step: 0
Training loss: 1.0672675371170044
Validation loss: 1.7797925190259052

Epoch: 6| Step: 1
Training loss: 0.7299443483352661
Validation loss: 1.7622276070297405

Epoch: 6| Step: 2
Training loss: 0.67138671875
Validation loss: 1.7976979247985347

Epoch: 6| Step: 3
Training loss: 1.435720682144165
Validation loss: 1.7754314996862923

Epoch: 6| Step: 4
Training loss: 1.0459128618240356
Validation loss: 1.7288628983241257

Epoch: 6| Step: 5
Training loss: 0.7965941429138184
Validation loss: 1.7536276617357809

Epoch: 6| Step: 6
Training loss: 0.9317250847816467
Validation loss: 1.7445450982739847

Epoch: 6| Step: 7
Training loss: 0.9669962525367737
Validation loss: 1.7619960884894095

Epoch: 6| Step: 8
Training loss: 0.7892004251480103
Validation loss: 1.7480419758827455

Epoch: 6| Step: 9
Training loss: 1.5285675525665283
Validation loss: 1.7983090621168896

Epoch: 6| Step: 10
Training loss: 0.8144645690917969
Validation loss: 1.7576520968508977

Epoch: 6| Step: 11
Training loss: 0.8331739902496338
Validation loss: 1.7826110265588249

Epoch: 6| Step: 12
Training loss: 1.518615961074829
Validation loss: 1.741041906418339

Epoch: 6| Step: 13
Training loss: 0.39370620250701904
Validation loss: 1.7999212241941882

Epoch: 469| Step: 0
Training loss: 0.5026018619537354
Validation loss: 1.801855303266997

Epoch: 6| Step: 1
Training loss: 1.778892993927002
Validation loss: 1.7808220181413876

Epoch: 6| Step: 2
Training loss: 0.6821221113204956
Validation loss: 1.7640715786205825

Epoch: 6| Step: 3
Training loss: 0.8581060171127319
Validation loss: 1.7560212150696786

Epoch: 6| Step: 4
Training loss: 1.0038222074508667
Validation loss: 1.7629882680472506

Epoch: 6| Step: 5
Training loss: 1.4118844270706177
Validation loss: 1.8074838064050163

Epoch: 6| Step: 6
Training loss: 0.4717128872871399
Validation loss: 1.6974033027566888

Epoch: 6| Step: 7
Training loss: 0.7122215032577515
Validation loss: 1.7834917858082762

Epoch: 6| Step: 8
Training loss: 1.4018266201019287
Validation loss: 1.7804230105492376

Epoch: 6| Step: 9
Training loss: 0.817763090133667
Validation loss: 1.7809198235952726

Epoch: 6| Step: 10
Training loss: 0.793341875076294
Validation loss: 1.7457839647928874

Epoch: 6| Step: 11
Training loss: 1.3044816255569458
Validation loss: 1.7695664718586912

Epoch: 6| Step: 12
Training loss: 1.5071972608566284
Validation loss: 1.790635831894413

Epoch: 6| Step: 13
Training loss: 1.2350842952728271
Validation loss: 1.7490207354227703

Epoch: 470| Step: 0
Training loss: 1.2104473114013672
Validation loss: 1.7798199884353145

Epoch: 6| Step: 1
Training loss: 0.6072180271148682
Validation loss: 1.7474138339360554

Epoch: 6| Step: 2
Training loss: 0.9710638523101807
Validation loss: 1.698503017425537

Epoch: 6| Step: 3
Training loss: 0.8122021555900574
Validation loss: 1.7198716158507972

Epoch: 6| Step: 4
Training loss: 0.8631962537765503
Validation loss: 1.7912233234733663

Epoch: 6| Step: 5
Training loss: 1.053903341293335
Validation loss: 1.7825849979154524

Epoch: 6| Step: 6
Training loss: 1.2383501529693604
Validation loss: 1.7438823740969422

Epoch: 6| Step: 7
Training loss: 0.8756952881813049
Validation loss: 1.8030929808975549

Epoch: 6| Step: 8
Training loss: 1.4347598552703857
Validation loss: 1.7444592419491018

Epoch: 6| Step: 9
Training loss: 0.8366990685462952
Validation loss: 1.7502931971703806

Epoch: 6| Step: 10
Training loss: 1.1316208839416504
Validation loss: 1.779925686056896

Epoch: 6| Step: 11
Training loss: 0.9715036153793335
Validation loss: 1.7003083446974396

Epoch: 6| Step: 12
Training loss: 0.9961116313934326
Validation loss: 1.7423345863178212

Epoch: 6| Step: 13
Training loss: 0.926605761051178
Validation loss: 1.708493581382177

Epoch: 471| Step: 0
Training loss: 1.2115601301193237
Validation loss: 1.7501383789124028

Epoch: 6| Step: 1
Training loss: 1.459590196609497
Validation loss: 1.7362405343722271

Epoch: 6| Step: 2
Training loss: 1.0486348867416382
Validation loss: 1.7288413547700452

Epoch: 6| Step: 3
Training loss: 1.0043649673461914
Validation loss: 1.7379545216919274

Epoch: 6| Step: 4
Training loss: 1.2327501773834229
Validation loss: 1.7773157165896507

Epoch: 6| Step: 5
Training loss: 0.7670218348503113
Validation loss: 1.7645267158426263

Epoch: 6| Step: 6
Training loss: 0.8456323146820068
Validation loss: 1.78436537455487

Epoch: 6| Step: 7
Training loss: 0.8035256266593933
Validation loss: 1.7825932297655331

Epoch: 6| Step: 8
Training loss: 0.7071530818939209
Validation loss: 1.8040480972618185

Epoch: 6| Step: 9
Training loss: 0.6427558064460754
Validation loss: 1.8032644256468742

Epoch: 6| Step: 10
Training loss: 1.322680115699768
Validation loss: 1.7473117805296374

Epoch: 6| Step: 11
Training loss: 1.2343202829360962
Validation loss: 1.8292179646030549

Epoch: 6| Step: 12
Training loss: 0.9458414912223816
Validation loss: 1.82380384783591

Epoch: 6| Step: 13
Training loss: 0.8961624503135681
Validation loss: 1.7505510160999913

Epoch: 472| Step: 0
Training loss: 1.1654561758041382
Validation loss: 1.8070032314587665

Epoch: 6| Step: 1
Training loss: 1.166223406791687
Validation loss: 1.7707012827678392

Epoch: 6| Step: 2
Training loss: 1.0912141799926758
Validation loss: 1.7508618036905925

Epoch: 6| Step: 3
Training loss: 1.6214983463287354
Validation loss: 1.745272865859411

Epoch: 6| Step: 4
Training loss: 0.6065281629562378
Validation loss: 1.778167172144818

Epoch: 6| Step: 5
Training loss: 0.7418506145477295
Validation loss: 1.7942688426663798

Epoch: 6| Step: 6
Training loss: 0.8254204988479614
Validation loss: 1.7379826153478315

Epoch: 6| Step: 7
Training loss: 1.0721404552459717
Validation loss: 1.7525520068342968

Epoch: 6| Step: 8
Training loss: 0.6844845414161682
Validation loss: 1.7435537230583928

Epoch: 6| Step: 9
Training loss: 1.462066650390625
Validation loss: 1.7412371558527793

Epoch: 6| Step: 10
Training loss: 0.7128503322601318
Validation loss: 1.73176610085272

Epoch: 6| Step: 11
Training loss: 1.2172480821609497
Validation loss: 1.7407099021378385

Epoch: 6| Step: 12
Training loss: 0.8315915465354919
Validation loss: 1.7380641942383142

Epoch: 6| Step: 13
Training loss: 0.5556957721710205
Validation loss: 1.772915567121198

Epoch: 473| Step: 0
Training loss: 1.1646645069122314
Validation loss: 1.7696300014372794

Epoch: 6| Step: 1
Training loss: 1.026487112045288
Validation loss: 1.7676980264725224

Epoch: 6| Step: 2
Training loss: 1.0886927843093872
Validation loss: 1.7504637651546027

Epoch: 6| Step: 3
Training loss: 0.7100540995597839
Validation loss: 1.77536246725308

Epoch: 6| Step: 4
Training loss: 1.3249058723449707
Validation loss: 1.7232062329528153

Epoch: 6| Step: 5
Training loss: 0.8963086009025574
Validation loss: 1.8077055869563934

Epoch: 6| Step: 6
Training loss: 1.0330610275268555
Validation loss: 1.7809760673071748

Epoch: 6| Step: 7
Training loss: 1.0922514200210571
Validation loss: 1.69405839520116

Epoch: 6| Step: 8
Training loss: 0.8588940501213074
Validation loss: 1.7276778836404123

Epoch: 6| Step: 9
Training loss: 0.8464193344116211
Validation loss: 1.7386445409508162

Epoch: 6| Step: 10
Training loss: 0.8308982849121094
Validation loss: 1.7382805155169578

Epoch: 6| Step: 11
Training loss: 1.0598254203796387
Validation loss: 1.711195045901883

Epoch: 6| Step: 12
Training loss: 0.7763782739639282
Validation loss: 1.743308994077867

Epoch: 6| Step: 13
Training loss: 0.9885600209236145
Validation loss: 1.796476548717868

Epoch: 474| Step: 0
Training loss: 1.3706215620040894
Validation loss: 1.8337991160731162

Epoch: 6| Step: 1
Training loss: 0.9046779870986938
Validation loss: 1.8470377755421463

Epoch: 6| Step: 2
Training loss: 1.6265285015106201
Validation loss: 1.8452267864699006

Epoch: 6| Step: 3
Training loss: 1.2506003379821777
Validation loss: 1.7772907351934781

Epoch: 6| Step: 4
Training loss: 0.6773474812507629
Validation loss: 1.787857009518531

Epoch: 6| Step: 5
Training loss: 0.7342580556869507
Validation loss: 1.822720689158286

Epoch: 6| Step: 6
Training loss: 0.7159990072250366
Validation loss: 1.772549307474526

Epoch: 6| Step: 7
Training loss: 1.226117491722107
Validation loss: 1.7781575649015364

Epoch: 6| Step: 8
Training loss: 1.1260302066802979
Validation loss: 1.7190212318974156

Epoch: 6| Step: 9
Training loss: 0.9496033191680908
Validation loss: 1.7468011251059912

Epoch: 6| Step: 10
Training loss: 0.9991245865821838
Validation loss: 1.7443263633276826

Epoch: 6| Step: 11
Training loss: 0.848815381526947
Validation loss: 1.7875916842491395

Epoch: 6| Step: 12
Training loss: 0.8433657884597778
Validation loss: 1.7533765018627208

Epoch: 6| Step: 13
Training loss: 0.5069248676300049
Validation loss: 1.6853056530798636

Epoch: 475| Step: 0
Training loss: 1.2870924472808838
Validation loss: 1.748182709499072

Epoch: 6| Step: 1
Training loss: 1.0288941860198975
Validation loss: 1.755793749645192

Epoch: 6| Step: 2
Training loss: 1.0980076789855957
Validation loss: 1.7717132055631248

Epoch: 6| Step: 3
Training loss: 1.1152303218841553
Validation loss: 1.7047117128167102

Epoch: 6| Step: 4
Training loss: 1.0334588289260864
Validation loss: 1.712648162277796

Epoch: 6| Step: 5
Training loss: 0.7322883605957031
Validation loss: 1.7113000128858833

Epoch: 6| Step: 6
Training loss: 0.7341307997703552
Validation loss: 1.7589744983180877

Epoch: 6| Step: 7
Training loss: 1.3151801824569702
Validation loss: 1.7728019350318498

Epoch: 6| Step: 8
Training loss: 1.035330057144165
Validation loss: 1.808978331986294

Epoch: 6| Step: 9
Training loss: 0.957280158996582
Validation loss: 1.768449285978912

Epoch: 6| Step: 10
Training loss: 1.0253329277038574
Validation loss: 1.7435257345117547

Epoch: 6| Step: 11
Training loss: 0.7461468577384949
Validation loss: 1.7650408565357167

Epoch: 6| Step: 12
Training loss: 0.8797681927680969
Validation loss: 1.7761657302097609

Epoch: 6| Step: 13
Training loss: 1.1234078407287598
Validation loss: 1.8454210630027197

Epoch: 476| Step: 0
Training loss: 1.0634897947311401
Validation loss: 1.7949318180802047

Epoch: 6| Step: 1
Training loss: 1.81313157081604
Validation loss: 1.7882284502829275

Epoch: 6| Step: 2
Training loss: 1.2514934539794922
Validation loss: 1.8113697190438547

Epoch: 6| Step: 3
Training loss: 0.6667355298995972
Validation loss: 1.7948879272707048

Epoch: 6| Step: 4
Training loss: 0.707120418548584
Validation loss: 1.7560542245065012

Epoch: 6| Step: 5
Training loss: 0.8529074788093567
Validation loss: 1.7933658848526657

Epoch: 6| Step: 6
Training loss: 1.4908242225646973
Validation loss: 1.765779459348289

Epoch: 6| Step: 7
Training loss: 0.961654007434845
Validation loss: 1.7026276896076817

Epoch: 6| Step: 8
Training loss: 0.92481529712677
Validation loss: 1.7125046009658484

Epoch: 6| Step: 9
Training loss: 0.4570845365524292
Validation loss: 1.8386151534254833

Epoch: 6| Step: 10
Training loss: 1.1793054342269897
Validation loss: 1.727314172252532

Epoch: 6| Step: 11
Training loss: 0.9658379554748535
Validation loss: 1.7404450524237849

Epoch: 6| Step: 12
Training loss: 0.6172631978988647
Validation loss: 1.7346366374723372

Epoch: 6| Step: 13
Training loss: 0.9462851285934448
Validation loss: 1.7195397397523284

Epoch: 477| Step: 0
Training loss: 1.0149075984954834
Validation loss: 1.7315368178070232

Epoch: 6| Step: 1
Training loss: 0.7709338068962097
Validation loss: 1.7675591361138128

Epoch: 6| Step: 2
Training loss: 0.8072984218597412
Validation loss: 1.798685981381324

Epoch: 6| Step: 3
Training loss: 1.239603042602539
Validation loss: 1.7408516958195677

Epoch: 6| Step: 4
Training loss: 1.174699306488037
Validation loss: 1.743252214565072

Epoch: 6| Step: 5
Training loss: 1.0740876197814941
Validation loss: 1.774590273057261

Epoch: 6| Step: 6
Training loss: 0.781247615814209
Validation loss: 1.7720540223583099

Epoch: 6| Step: 7
Training loss: 1.1153008937835693
Validation loss: 1.7587241242008824

Epoch: 6| Step: 8
Training loss: 1.0012587308883667
Validation loss: 1.7907934111933554

Epoch: 6| Step: 9
Training loss: 0.6912243962287903
Validation loss: 1.7558807839629471

Epoch: 6| Step: 10
Training loss: 0.9636492729187012
Validation loss: 1.7704657431571715

Epoch: 6| Step: 11
Training loss: 0.9849315285682678
Validation loss: 1.7589870883572487

Epoch: 6| Step: 12
Training loss: 0.9201927185058594
Validation loss: 1.7243447701136272

Epoch: 6| Step: 13
Training loss: 0.7812118530273438
Validation loss: 1.7755875818191036

Epoch: 478| Step: 0
Training loss: 0.7388134002685547
Validation loss: 1.8016217485550912

Epoch: 6| Step: 1
Training loss: 1.1040043830871582
Validation loss: 1.7783476165545884

Epoch: 6| Step: 2
Training loss: 1.1454166173934937
Validation loss: 1.805976851012117

Epoch: 6| Step: 3
Training loss: 0.7596496939659119
Validation loss: 1.7766278610434583

Epoch: 6| Step: 4
Training loss: 1.17991304397583
Validation loss: 1.6848119612663024

Epoch: 6| Step: 5
Training loss: 1.1136219501495361
Validation loss: 1.8004202611984745

Epoch: 6| Step: 6
Training loss: 1.149522066116333
Validation loss: 1.7087625406121696

Epoch: 6| Step: 7
Training loss: 0.46204450726509094
Validation loss: 1.7720705642495105

Epoch: 6| Step: 8
Training loss: 0.6516242027282715
Validation loss: 1.8042323717506983

Epoch: 6| Step: 9
Training loss: 0.8789226412773132
Validation loss: 1.7814706525494974

Epoch: 6| Step: 10
Training loss: 1.2514636516571045
Validation loss: 1.7454781609196817

Epoch: 6| Step: 11
Training loss: 0.7407835721969604
Validation loss: 1.7571628093719482

Epoch: 6| Step: 12
Training loss: 1.0210542678833008
Validation loss: 1.7834192642601587

Epoch: 6| Step: 13
Training loss: 2.228410482406616
Validation loss: 1.7500667200293591

Epoch: 479| Step: 0
Training loss: 0.9601866006851196
Validation loss: 1.7429793124557824

Epoch: 6| Step: 1
Training loss: 0.8330920338630676
Validation loss: 1.7421121904926915

Epoch: 6| Step: 2
Training loss: 0.8017230033874512
Validation loss: 1.7770882627015472

Epoch: 6| Step: 3
Training loss: 0.9035478830337524
Validation loss: 1.8049563528389059

Epoch: 6| Step: 4
Training loss: 1.3252651691436768
Validation loss: 1.765554901092283

Epoch: 6| Step: 5
Training loss: 1.3900504112243652
Validation loss: 1.7725274114198581

Epoch: 6| Step: 6
Training loss: 0.7703738212585449
Validation loss: 1.8086565848319762

Epoch: 6| Step: 7
Training loss: 0.8056071996688843
Validation loss: 1.798180978785279

Epoch: 6| Step: 8
Training loss: 1.381555199623108
Validation loss: 1.7849834952303159

Epoch: 6| Step: 9
Training loss: 0.9706816077232361
Validation loss: 1.751314296517321

Epoch: 6| Step: 10
Training loss: 0.7505910992622375
Validation loss: 1.762498217244302

Epoch: 6| Step: 11
Training loss: 1.1290576457977295
Validation loss: 1.7324409292590233

Epoch: 6| Step: 12
Training loss: 0.6365236043930054
Validation loss: 1.72868013381958

Epoch: 6| Step: 13
Training loss: 1.3458844423294067
Validation loss: 1.760663027404457

Epoch: 480| Step: 0
Training loss: 1.2565538883209229
Validation loss: 1.7459048417306715

Epoch: 6| Step: 1
Training loss: 0.9188743829727173
Validation loss: 1.7552460752507693

Epoch: 6| Step: 2
Training loss: 1.091892957687378
Validation loss: 1.7525825039032967

Epoch: 6| Step: 3
Training loss: 1.1911563873291016
Validation loss: 1.7611165277419552

Epoch: 6| Step: 4
Training loss: 0.783504068851471
Validation loss: 1.7217862939321866

Epoch: 6| Step: 5
Training loss: 0.7964104413986206
Validation loss: 1.8286876037556639

Epoch: 6| Step: 6
Training loss: 1.0680863857269287
Validation loss: 1.7596391875256774

Epoch: 6| Step: 7
Training loss: 0.47515785694122314
Validation loss: 1.7423719347164195

Epoch: 6| Step: 8
Training loss: 1.0964516401290894
Validation loss: 1.7588080001133743

Epoch: 6| Step: 9
Training loss: 1.3091295957565308
Validation loss: 1.781573340456973

Epoch: 6| Step: 10
Training loss: 0.7183722257614136
Validation loss: 1.7705336437430432

Epoch: 6| Step: 11
Training loss: 0.8802080154418945
Validation loss: 1.7563257114861601

Epoch: 6| Step: 12
Training loss: 1.0902867317199707
Validation loss: 1.785987377166748

Epoch: 6| Step: 13
Training loss: 0.4659004807472229
Validation loss: 1.7818158185610207

Epoch: 481| Step: 0
Training loss: 0.7121660113334656
Validation loss: 1.7395180835518786

Epoch: 6| Step: 1
Training loss: 0.9918110370635986
Validation loss: 1.7750818203854304

Epoch: 6| Step: 2
Training loss: 0.8508701920509338
Validation loss: 1.791527391761862

Epoch: 6| Step: 3
Training loss: 0.7066363096237183
Validation loss: 1.7087509503928564

Epoch: 6| Step: 4
Training loss: 1.3440293073654175
Validation loss: 1.7307156119295346

Epoch: 6| Step: 5
Training loss: 0.6453044414520264
Validation loss: 1.7221379536454395

Epoch: 6| Step: 6
Training loss: 1.2793488502502441
Validation loss: 1.7787264008675852

Epoch: 6| Step: 7
Training loss: 0.9962289333343506
Validation loss: 1.760394298902122

Epoch: 6| Step: 8
Training loss: 0.687930703163147
Validation loss: 1.7816494818656676

Epoch: 6| Step: 9
Training loss: 0.883598804473877
Validation loss: 1.7528950527150144

Epoch: 6| Step: 10
Training loss: 1.243808627128601
Validation loss: 1.7602816538144184

Epoch: 6| Step: 11
Training loss: 1.0326114892959595
Validation loss: 1.8011515422533917

Epoch: 6| Step: 12
Training loss: 1.1112768650054932
Validation loss: 1.7444963096290507

Epoch: 6| Step: 13
Training loss: 1.4124046564102173
Validation loss: 1.7703287832198604

Epoch: 482| Step: 0
Training loss: 0.6585385799407959
Validation loss: 1.7474557404877038

Epoch: 6| Step: 1
Training loss: 0.9566881656646729
Validation loss: 1.7472322576789445

Epoch: 6| Step: 2
Training loss: 1.2086836099624634
Validation loss: 1.7835868968758533

Epoch: 6| Step: 3
Training loss: 0.9807583093643188
Validation loss: 1.7321871647270777

Epoch: 6| Step: 4
Training loss: 1.1346402168273926
Validation loss: 1.7835257386648526

Epoch: 6| Step: 5
Training loss: 0.6861517429351807
Validation loss: 1.733406259167579

Epoch: 6| Step: 6
Training loss: 1.367619276046753
Validation loss: 1.755899401121242

Epoch: 6| Step: 7
Training loss: 1.151928186416626
Validation loss: 1.7667986193010885

Epoch: 6| Step: 8
Training loss: 1.0602219104766846
Validation loss: 1.8121275414702713

Epoch: 6| Step: 9
Training loss: 0.9710338115692139
Validation loss: 1.774928742839444

Epoch: 6| Step: 10
Training loss: 1.3587905168533325
Validation loss: 1.7496657397157402

Epoch: 6| Step: 11
Training loss: 0.5371915102005005
Validation loss: 1.7866054196511545

Epoch: 6| Step: 12
Training loss: 0.5192169547080994
Validation loss: 1.7403479378710511

Epoch: 6| Step: 13
Training loss: 0.736054003238678
Validation loss: 1.7264630794525146

Epoch: 483| Step: 0
Training loss: 0.9679170250892639
Validation loss: 1.8006421814682663

Epoch: 6| Step: 1
Training loss: 0.38467833399772644
Validation loss: 1.7265539451311993

Epoch: 6| Step: 2
Training loss: 0.9681110978126526
Validation loss: 1.7401076901343562

Epoch: 6| Step: 3
Training loss: 1.3199012279510498
Validation loss: 1.7395448043782225

Epoch: 6| Step: 4
Training loss: 0.8404507040977478
Validation loss: 1.7458610316758514

Epoch: 6| Step: 5
Training loss: 0.4916980266571045
Validation loss: 1.715493336800606

Epoch: 6| Step: 6
Training loss: 0.9350200891494751
Validation loss: 1.7510953757070726

Epoch: 6| Step: 7
Training loss: 1.1476867198944092
Validation loss: 1.6966387635918074

Epoch: 6| Step: 8
Training loss: 0.7375855445861816
Validation loss: 1.7174042553030036

Epoch: 6| Step: 9
Training loss: 0.9453634023666382
Validation loss: 1.7040850052269556

Epoch: 6| Step: 10
Training loss: 1.3701649904251099
Validation loss: 1.7805739730916998

Epoch: 6| Step: 11
Training loss: 0.8815263509750366
Validation loss: 1.7816051078099076

Epoch: 6| Step: 12
Training loss: 1.4345645904541016
Validation loss: 1.759133174855222

Epoch: 6| Step: 13
Training loss: 0.6277644634246826
Validation loss: 1.7579773984929568

Epoch: 484| Step: 0
Training loss: 0.7143397331237793
Validation loss: 1.7504163275482834

Epoch: 6| Step: 1
Training loss: 0.8204904794692993
Validation loss: 1.718498065907468

Epoch: 6| Step: 2
Training loss: 1.1858173608779907
Validation loss: 1.7570653769277758

Epoch: 6| Step: 3
Training loss: 1.031059741973877
Validation loss: 1.756927251815796

Epoch: 6| Step: 4
Training loss: 1.3534388542175293
Validation loss: 1.7386145860918107

Epoch: 6| Step: 5
Training loss: 0.9951781630516052
Validation loss: 1.7524137227765975

Epoch: 6| Step: 6
Training loss: 1.3332455158233643
Validation loss: 1.7688548949456984

Epoch: 6| Step: 7
Training loss: 0.8640510439872742
Validation loss: 1.7912248014121928

Epoch: 6| Step: 8
Training loss: 1.0188109874725342
Validation loss: 1.7875070828263477

Epoch: 6| Step: 9
Training loss: 1.1748545169830322
Validation loss: 1.8218904131202287

Epoch: 6| Step: 10
Training loss: 0.5696306824684143
Validation loss: 1.8224592721590431

Epoch: 6| Step: 11
Training loss: 0.80879145860672
Validation loss: 1.7789851004077541

Epoch: 6| Step: 12
Training loss: 0.6255226135253906
Validation loss: 1.7987849661099014

Epoch: 6| Step: 13
Training loss: 1.160110592842102
Validation loss: 1.7806508195015691

Epoch: 485| Step: 0
Training loss: 0.935086727142334
Validation loss: 1.7992974494093208

Epoch: 6| Step: 1
Training loss: 0.399711012840271
Validation loss: 1.7319689168724963

Epoch: 6| Step: 2
Training loss: 1.541393518447876
Validation loss: 1.8007588309626426

Epoch: 6| Step: 3
Training loss: 0.8929170370101929
Validation loss: 1.7940550363191994

Epoch: 6| Step: 4
Training loss: 1.0823378562927246
Validation loss: 1.7082464361703524

Epoch: 6| Step: 5
Training loss: 0.8800333738327026
Validation loss: 1.7093489593075168

Epoch: 6| Step: 6
Training loss: 0.8199355602264404
Validation loss: 1.7255979481563772

Epoch: 6| Step: 7
Training loss: 0.9588304162025452
Validation loss: 1.7478833006274315

Epoch: 6| Step: 8
Training loss: 1.1242926120758057
Validation loss: 1.7410906566086637

Epoch: 6| Step: 9
Training loss: 0.6619696021080017
Validation loss: 1.783911915235622

Epoch: 6| Step: 10
Training loss: 0.8590019345283508
Validation loss: 1.7515954932858866

Epoch: 6| Step: 11
Training loss: 0.9660605192184448
Validation loss: 1.7472334805355276

Epoch: 6| Step: 12
Training loss: 1.741251826286316
Validation loss: 1.818831430968418

Epoch: 6| Step: 13
Training loss: 0.9965851902961731
Validation loss: 1.775840074785294

Epoch: 486| Step: 0
Training loss: 0.8648145198822021
Validation loss: 1.8283918173082414

Epoch: 6| Step: 1
Training loss: 0.9303296804428101
Validation loss: 1.8298834728938278

Epoch: 6| Step: 2
Training loss: 1.8898262977600098
Validation loss: 1.799500064183307

Epoch: 6| Step: 3
Training loss: 0.9928593039512634
Validation loss: 1.8010146681980421

Epoch: 6| Step: 4
Training loss: 1.1321051120758057
Validation loss: 1.8378040534193798

Epoch: 6| Step: 5
Training loss: 0.7408182621002197
Validation loss: 1.7819630753609441

Epoch: 6| Step: 6
Training loss: 0.5815412402153015
Validation loss: 1.7359493227415188

Epoch: 6| Step: 7
Training loss: 0.6666153073310852
Validation loss: 1.7503301007773286

Epoch: 6| Step: 8
Training loss: 0.6585420370101929
Validation loss: 1.7526555343340802

Epoch: 6| Step: 9
Training loss: 0.7797331809997559
Validation loss: 1.762873690615418

Epoch: 6| Step: 10
Training loss: 1.1152467727661133
Validation loss: 1.742874680667795

Epoch: 6| Step: 11
Training loss: 0.9352370500564575
Validation loss: 1.715269942437449

Epoch: 6| Step: 12
Training loss: 1.3905013799667358
Validation loss: 1.731464587232118

Epoch: 6| Step: 13
Training loss: 1.3001158237457275
Validation loss: 1.7719422604448052

Epoch: 487| Step: 0
Training loss: 1.2914395332336426
Validation loss: 1.7937143541151477

Epoch: 6| Step: 1
Training loss: 1.4686883687973022
Validation loss: 1.7538036787381737

Epoch: 6| Step: 2
Training loss: 0.6534723043441772
Validation loss: 1.759634587072557

Epoch: 6| Step: 3
Training loss: 0.9499531984329224
Validation loss: 1.7481314584773073

Epoch: 6| Step: 4
Training loss: 0.9670200943946838
Validation loss: 1.747535958085009

Epoch: 6| Step: 5
Training loss: 1.2175953388214111
Validation loss: 1.7529302861100884

Epoch: 6| Step: 6
Training loss: 0.7650454044342041
Validation loss: 1.7782117275781528

Epoch: 6| Step: 7
Training loss: 0.9084203243255615
Validation loss: 1.7624644284607263

Epoch: 6| Step: 8
Training loss: 1.1414204835891724
Validation loss: 1.7340130511150564

Epoch: 6| Step: 9
Training loss: 0.5626882910728455
Validation loss: 1.7634692602260138

Epoch: 6| Step: 10
Training loss: 1.2854008674621582
Validation loss: 1.7176959360799482

Epoch: 6| Step: 11
Training loss: 1.065455675125122
Validation loss: 1.78436844066907

Epoch: 6| Step: 12
Training loss: 0.7995759844779968
Validation loss: 1.726981944935296

Epoch: 6| Step: 13
Training loss: 0.39798545837402344
Validation loss: 1.7424974749165196

Epoch: 488| Step: 0
Training loss: 1.0991137027740479
Validation loss: 1.7797651354984572

Epoch: 6| Step: 1
Training loss: 0.8084093332290649
Validation loss: 1.7026209869692404

Epoch: 6| Step: 2
Training loss: 0.5529754161834717
Validation loss: 1.6824158930009412

Epoch: 6| Step: 3
Training loss: 1.3579131364822388
Validation loss: 1.742200860413172

Epoch: 6| Step: 4
Training loss: 1.2107789516448975
Validation loss: 1.7371844847997029

Epoch: 6| Step: 5
Training loss: 1.5059051513671875
Validation loss: 1.7514979211232995

Epoch: 6| Step: 6
Training loss: 0.6655458807945251
Validation loss: 1.7592443394404587

Epoch: 6| Step: 7
Training loss: 0.8003163933753967
Validation loss: 1.8056255707176783

Epoch: 6| Step: 8
Training loss: 0.949176549911499
Validation loss: 1.7493978982330651

Epoch: 6| Step: 9
Training loss: 0.6635676026344299
Validation loss: 1.7493483866414716

Epoch: 6| Step: 10
Training loss: 0.7047266364097595
Validation loss: 1.7527603872360722

Epoch: 6| Step: 11
Training loss: 1.00282883644104
Validation loss: 1.766001360390776

Epoch: 6| Step: 12
Training loss: 1.0698328018188477
Validation loss: 1.7360445760911511

Epoch: 6| Step: 13
Training loss: 0.8454038500785828
Validation loss: 1.80315698218602

Epoch: 489| Step: 0
Training loss: 0.8021587133407593
Validation loss: 1.7236837187120992

Epoch: 6| Step: 1
Training loss: 0.8216590881347656
Validation loss: 1.727941269515663

Epoch: 6| Step: 2
Training loss: 0.9727654457092285
Validation loss: 1.7486042720015331

Epoch: 6| Step: 3
Training loss: 0.7882936596870422
Validation loss: 1.7166668343287643

Epoch: 6| Step: 4
Training loss: 0.6870018243789673
Validation loss: 1.6926236767922678

Epoch: 6| Step: 5
Training loss: 0.8382319808006287
Validation loss: 1.7328835789875319

Epoch: 6| Step: 6
Training loss: 1.1588484048843384
Validation loss: 1.7694737013950144

Epoch: 6| Step: 7
Training loss: 0.7499527931213379
Validation loss: 1.7739525495036956

Epoch: 6| Step: 8
Training loss: 1.0703892707824707
Validation loss: 1.7595200974454162

Epoch: 6| Step: 9
Training loss: 1.0472580194473267
Validation loss: 1.7556357806728733

Epoch: 6| Step: 10
Training loss: 1.2308157682418823
Validation loss: 1.723124739944294

Epoch: 6| Step: 11
Training loss: 1.1214523315429688
Validation loss: 1.823017204961469

Epoch: 6| Step: 12
Training loss: 1.0333373546600342
Validation loss: 1.8852815294778476

Epoch: 6| Step: 13
Training loss: 0.8965668082237244
Validation loss: 1.8629675283226916

Epoch: 490| Step: 0
Training loss: 1.2073787450790405
Validation loss: 1.879686987528237

Epoch: 6| Step: 1
Training loss: 0.9515752196311951
Validation loss: 1.878788632731284

Epoch: 6| Step: 2
Training loss: 1.3758299350738525
Validation loss: 1.87226055898974

Epoch: 6| Step: 3
Training loss: 0.858020544052124
Validation loss: 1.8248819305050759

Epoch: 6| Step: 4
Training loss: 0.9571971297264099
Validation loss: 1.7568938757783623

Epoch: 6| Step: 5
Training loss: 0.5418779253959656
Validation loss: 1.7925593186450262

Epoch: 6| Step: 6
Training loss: 1.2494547367095947
Validation loss: 1.759976670306216

Epoch: 6| Step: 7
Training loss: 0.6844222545623779
Validation loss: 1.7576369175346949

Epoch: 6| Step: 8
Training loss: 1.0647273063659668
Validation loss: 1.7536840105569491

Epoch: 6| Step: 9
Training loss: 0.7938957214355469
Validation loss: 1.7011620793291318

Epoch: 6| Step: 10
Training loss: 1.1789854764938354
Validation loss: 1.7352010268037037

Epoch: 6| Step: 11
Training loss: 0.7977281808853149
Validation loss: 1.7374347832895094

Epoch: 6| Step: 12
Training loss: 1.2935914993286133
Validation loss: 1.7605733307459022

Epoch: 6| Step: 13
Training loss: 0.7829642295837402
Validation loss: 1.6967227612772295

Epoch: 491| Step: 0
Training loss: 1.4209165573120117
Validation loss: 1.7453353071725497

Epoch: 6| Step: 1
Training loss: 1.0559756755828857
Validation loss: 1.7246566690424436

Epoch: 6| Step: 2
Training loss: 0.9542087912559509
Validation loss: 1.7081756040614138

Epoch: 6| Step: 3
Training loss: 1.0347087383270264
Validation loss: 1.7434919021462882

Epoch: 6| Step: 4
Training loss: 0.9221608638763428
Validation loss: 1.7386433719306864

Epoch: 6| Step: 5
Training loss: 0.7137026190757751
Validation loss: 1.70245264550691

Epoch: 6| Step: 6
Training loss: 0.7930872440338135
Validation loss: 1.7707682335248558

Epoch: 6| Step: 7
Training loss: 0.7343757152557373
Validation loss: 1.7076291499599334

Epoch: 6| Step: 8
Training loss: 1.2561715841293335
Validation loss: 1.7546150389538016

Epoch: 6| Step: 9
Training loss: 0.9390238523483276
Validation loss: 1.7766989661801247

Epoch: 6| Step: 10
Training loss: 1.142041563987732
Validation loss: 1.7961839604121383

Epoch: 6| Step: 11
Training loss: 0.7407805919647217
Validation loss: 1.8266943141978274

Epoch: 6| Step: 12
Training loss: 0.7528883814811707
Validation loss: 1.8186920112179172

Epoch: 6| Step: 13
Training loss: 1.0900373458862305
Validation loss: 1.8665350258991282

Epoch: 492| Step: 0
Training loss: 1.3985904455184937
Validation loss: 1.778362217769828

Epoch: 6| Step: 1
Training loss: 0.7382221817970276
Validation loss: 1.8099073607434508

Epoch: 6| Step: 2
Training loss: 1.3602397441864014
Validation loss: 1.7852379737361785

Epoch: 6| Step: 3
Training loss: 1.3023737668991089
Validation loss: 1.706019598950622

Epoch: 6| Step: 4
Training loss: 1.1852809190750122
Validation loss: 1.7135052757878457

Epoch: 6| Step: 5
Training loss: 0.6176296472549438
Validation loss: 1.7245523621959071

Epoch: 6| Step: 6
Training loss: 0.9400508403778076
Validation loss: 1.7200971034265333

Epoch: 6| Step: 7
Training loss: 0.453390896320343
Validation loss: 1.7245105146079935

Epoch: 6| Step: 8
Training loss: 0.5687996745109558
Validation loss: 1.7690487651414768

Epoch: 6| Step: 9
Training loss: 0.9667314291000366
Validation loss: 1.6934318504025858

Epoch: 6| Step: 10
Training loss: 0.8234524726867676
Validation loss: 1.7517554785615654

Epoch: 6| Step: 11
Training loss: 1.1327311992645264
Validation loss: 1.7174475475024151

Epoch: 6| Step: 12
Training loss: 0.9224125146865845
Validation loss: 1.7468150738746888

Epoch: 6| Step: 13
Training loss: 1.1446764469146729
Validation loss: 1.7209672004945817

Epoch: 493| Step: 0
Training loss: 1.528702974319458
Validation loss: 1.742552194544064

Epoch: 6| Step: 1
Training loss: 0.8826968669891357
Validation loss: 1.7832643998566495

Epoch: 6| Step: 2
Training loss: 1.0447849035263062
Validation loss: 1.730242383095526

Epoch: 6| Step: 3
Training loss: 0.7484740018844604
Validation loss: 1.7111278323717014

Epoch: 6| Step: 4
Training loss: 1.04543936252594
Validation loss: 1.7392563384066346

Epoch: 6| Step: 5
Training loss: 1.2832438945770264
Validation loss: 1.7626240586721769

Epoch: 6| Step: 6
Training loss: 0.43753737211227417
Validation loss: 1.7517944689719909

Epoch: 6| Step: 7
Training loss: 0.8807429075241089
Validation loss: 1.7464726740314114

Epoch: 6| Step: 8
Training loss: 0.8261511325836182
Validation loss: 1.7752267968270086

Epoch: 6| Step: 9
Training loss: 0.86788010597229
Validation loss: 1.7865766427850212

Epoch: 6| Step: 10
Training loss: 1.7604992389678955
Validation loss: 1.744302366369514

Epoch: 6| Step: 11
Training loss: 0.7654651403427124
Validation loss: 1.7231737003531507

Epoch: 6| Step: 12
Training loss: 0.9536410570144653
Validation loss: 1.7830763042614024

Epoch: 6| Step: 13
Training loss: 0.9607552289962769
Validation loss: 1.717805835508531

Epoch: 494| Step: 0
Training loss: 1.067108392715454
Validation loss: 1.7609434916127114

Epoch: 6| Step: 1
Training loss: 1.3939958810806274
Validation loss: 1.7092401084079538

Epoch: 6| Step: 2
Training loss: 0.7706868648529053
Validation loss: 1.778924899716531

Epoch: 6| Step: 3
Training loss: 0.5688519477844238
Validation loss: 1.743573998892179

Epoch: 6| Step: 4
Training loss: 0.621140718460083
Validation loss: 1.7128577206724434

Epoch: 6| Step: 5
Training loss: 0.5956535339355469
Validation loss: 1.807180780236439

Epoch: 6| Step: 6
Training loss: 1.2722806930541992
Validation loss: 1.7707920587191017

Epoch: 6| Step: 7
Training loss: 1.6762409210205078
Validation loss: 1.6991959515438284

Epoch: 6| Step: 8
Training loss: 0.8864678144454956
Validation loss: 1.7632471611422877

Epoch: 6| Step: 9
Training loss: 1.079498291015625
Validation loss: 1.802236891561939

Epoch: 6| Step: 10
Training loss: 1.0155357122421265
Validation loss: 1.7267940928859096

Epoch: 6| Step: 11
Training loss: 0.9998461008071899
Validation loss: 1.7255534523276872

Epoch: 6| Step: 12
Training loss: 0.7398605346679688
Validation loss: 1.7049046639473207

Epoch: 6| Step: 13
Training loss: 0.8690270781517029
Validation loss: 1.748027942513907

Epoch: 495| Step: 0
Training loss: 0.8645111322402954
Validation loss: 1.736001378746443

Epoch: 6| Step: 1
Training loss: 0.8818540573120117
Validation loss: 1.7512940950291132

Epoch: 6| Step: 2
Training loss: 0.893435537815094
Validation loss: 1.7829305600094538

Epoch: 6| Step: 3
Training loss: 0.44719743728637695
Validation loss: 1.7567110843555902

Epoch: 6| Step: 4
Training loss: 0.8333935737609863
Validation loss: 1.7286565252529678

Epoch: 6| Step: 5
Training loss: 1.3178179264068604
Validation loss: 1.72316143461453

Epoch: 6| Step: 6
Training loss: 0.5387903451919556
Validation loss: 1.7747524246092765

Epoch: 6| Step: 7
Training loss: 1.0562400817871094
Validation loss: 1.7862023781704646

Epoch: 6| Step: 8
Training loss: 0.968174397945404
Validation loss: 1.7492062917319677

Epoch: 6| Step: 9
Training loss: 1.1301716566085815
Validation loss: 1.7936467893661991

Epoch: 6| Step: 10
Training loss: 0.5031108856201172
Validation loss: 1.717693446784891

Epoch: 6| Step: 11
Training loss: 1.084694743156433
Validation loss: 1.7540187566511092

Epoch: 6| Step: 12
Training loss: 1.3522419929504395
Validation loss: 1.708882665121427

Epoch: 6| Step: 13
Training loss: 1.115288257598877
Validation loss: 1.7348022127664218

Epoch: 496| Step: 0
Training loss: 0.9746177792549133
Validation loss: 1.705263800518487

Epoch: 6| Step: 1
Training loss: 1.7276663780212402
Validation loss: 1.732127284490934

Epoch: 6| Step: 2
Training loss: 0.9015101194381714
Validation loss: 1.7591420847882506

Epoch: 6| Step: 3
Training loss: 1.0976848602294922
Validation loss: 1.7400773879020446

Epoch: 6| Step: 4
Training loss: 0.9102182388305664
Validation loss: 1.785976743185392

Epoch: 6| Step: 5
Training loss: 0.6734472513198853
Validation loss: 1.7556793741000596

Epoch: 6| Step: 6
Training loss: 0.6680329442024231
Validation loss: 1.784385763188844

Epoch: 6| Step: 7
Training loss: 0.6369093060493469
Validation loss: 1.7902625068541496

Epoch: 6| Step: 8
Training loss: 1.5326954126358032
Validation loss: 1.815342903137207

Epoch: 6| Step: 9
Training loss: 0.7385130524635315
Validation loss: 1.7868048170561432

Epoch: 6| Step: 10
Training loss: 0.9506739377975464
Validation loss: 1.8129602991124636

Epoch: 6| Step: 11
Training loss: 1.078594446182251
Validation loss: 1.7502294278913928

Epoch: 6| Step: 12
Training loss: 0.6735610961914062
Validation loss: 1.7645728267649168

Epoch: 6| Step: 13
Training loss: 0.9113330841064453
Validation loss: 1.7791495912818498

Epoch: 497| Step: 0
Training loss: 1.281713604927063
Validation loss: 1.8163303303462204

Epoch: 6| Step: 1
Training loss: 1.142904281616211
Validation loss: 1.7546511657776371

Epoch: 6| Step: 2
Training loss: 1.3494865894317627
Validation loss: 1.7629212384582849

Epoch: 6| Step: 3
Training loss: 0.6308227181434631
Validation loss: 1.7590881547620218

Epoch: 6| Step: 4
Training loss: 0.9222860336303711
Validation loss: 1.788980092412682

Epoch: 6| Step: 5
Training loss: 0.7499369382858276
Validation loss: 1.7282806506720922

Epoch: 6| Step: 6
Training loss: 0.8609607219696045
Validation loss: 1.7526573070915796

Epoch: 6| Step: 7
Training loss: 1.2776118516921997
Validation loss: 1.7607969814731228

Epoch: 6| Step: 8
Training loss: 0.9466278553009033
Validation loss: 1.7606759430259786

Epoch: 6| Step: 9
Training loss: 1.4698458909988403
Validation loss: 1.7145121238564933

Epoch: 6| Step: 10
Training loss: 1.0407674312591553
Validation loss: 1.7081216740351852

Epoch: 6| Step: 11
Training loss: 0.6925627589225769
Validation loss: 1.7116341206335253

Epoch: 6| Step: 12
Training loss: 0.3622223734855652
Validation loss: 1.73515732313997

Epoch: 6| Step: 13
Training loss: 0.6129767894744873
Validation loss: 1.7332857642122494

Epoch: 498| Step: 0
Training loss: 1.0768729448318481
Validation loss: 1.7786306296625445

Epoch: 6| Step: 1
Training loss: 0.37288010120391846
Validation loss: 1.7469981870343607

Epoch: 6| Step: 2
Training loss: 0.45764490962028503
Validation loss: 1.7773128581303421

Epoch: 6| Step: 3
Training loss: 0.9723266959190369
Validation loss: 1.8392573069500666

Epoch: 6| Step: 4
Training loss: 0.8636995553970337
Validation loss: 1.8082250959129744

Epoch: 6| Step: 5
Training loss: 1.1915843486785889
Validation loss: 1.7605228962436799

Epoch: 6| Step: 6
Training loss: 1.1681946516036987
Validation loss: 1.8072410642459829

Epoch: 6| Step: 7
Training loss: 1.200758934020996
Validation loss: 1.7271982674957604

Epoch: 6| Step: 8
Training loss: 1.4601585865020752
Validation loss: 1.801212001872319

Epoch: 6| Step: 9
Training loss: 0.9086443781852722
Validation loss: 1.7592590739650111

Epoch: 6| Step: 10
Training loss: 0.9226976633071899
Validation loss: 1.7242616914933728

Epoch: 6| Step: 11
Training loss: 0.7795161604881287
Validation loss: 1.763253515766513

Epoch: 6| Step: 12
Training loss: 0.7246694564819336
Validation loss: 1.6842148932077552

Epoch: 6| Step: 13
Training loss: 1.1595925092697144
Validation loss: 1.7646934486204577

Epoch: 499| Step: 0
Training loss: 1.223746418952942
Validation loss: 1.7364392652306506

Epoch: 6| Step: 1
Training loss: 0.9492952227592468
Validation loss: 1.7587001708246046

Epoch: 6| Step: 2
Training loss: 0.7789843082427979
Validation loss: 1.816953097620318

Epoch: 6| Step: 3
Training loss: 0.6742650866508484
Validation loss: 1.788632260855808

Epoch: 6| Step: 4
Training loss: 0.7076358199119568
Validation loss: 1.778679399080174

Epoch: 6| Step: 5
Training loss: 0.9679021835327148
Validation loss: 1.8077177001583962

Epoch: 6| Step: 6
Training loss: 0.7777224779129028
Validation loss: 1.800817576787805

Epoch: 6| Step: 7
Training loss: 1.0957317352294922
Validation loss: 1.7526855596932032

Epoch: 6| Step: 8
Training loss: 0.7752399444580078
Validation loss: 1.7340549935576737

Epoch: 6| Step: 9
Training loss: 0.5889124870300293
Validation loss: 1.7394091352339713

Epoch: 6| Step: 10
Training loss: 1.0349352359771729
Validation loss: 1.7026869404700495

Epoch: 6| Step: 11
Training loss: 1.4265446662902832
Validation loss: 1.7261680633791032

Epoch: 6| Step: 12
Training loss: 1.0059224367141724
Validation loss: 1.7624042649422922

Epoch: 6| Step: 13
Training loss: 0.5607232451438904
Validation loss: 1.7382569236140097

Epoch: 500| Step: 0
Training loss: 0.9362730979919434
Validation loss: 1.7081636010959584

Epoch: 6| Step: 1
Training loss: 1.4322766065597534
Validation loss: 1.6820305060314875

Epoch: 6| Step: 2
Training loss: 1.388582706451416
Validation loss: 1.7596358791474374

Epoch: 6| Step: 3
Training loss: 0.6442670822143555
Validation loss: 1.6785870713572348

Epoch: 6| Step: 4
Training loss: 0.8521716594696045
Validation loss: 1.7842180164911414

Epoch: 6| Step: 5
Training loss: 0.7010789513587952
Validation loss: 1.73416470584049

Epoch: 6| Step: 6
Training loss: 0.7301080226898193
Validation loss: 1.7655058009650118

Epoch: 6| Step: 7
Training loss: 0.7885523438453674
Validation loss: 1.7259359500741447

Epoch: 6| Step: 8
Training loss: 0.6823909282684326
Validation loss: 1.7625061132574593

Epoch: 6| Step: 9
Training loss: 0.8441624641418457
Validation loss: 1.744530612422574

Epoch: 6| Step: 10
Training loss: 0.7384371757507324
Validation loss: 1.686328540566147

Epoch: 6| Step: 11
Training loss: 0.5406398773193359
Validation loss: 1.7715170216816727

Epoch: 6| Step: 12
Training loss: 1.5941410064697266
Validation loss: 1.7824216260704944

Epoch: 6| Step: 13
Training loss: 0.8441072106361389
Validation loss: 1.7429720509436823

Epoch: 501| Step: 0
Training loss: 0.8253253102302551
Validation loss: 1.7301424164925852

Epoch: 6| Step: 1
Training loss: 0.6865828633308411
Validation loss: 1.7497822366734987

Epoch: 6| Step: 2
Training loss: 0.6809433698654175
Validation loss: 1.7319605235130555

Epoch: 6| Step: 3
Training loss: 1.7609868049621582
Validation loss: 1.7505004687975811

Epoch: 6| Step: 4
Training loss: 1.3718048334121704
Validation loss: 1.7751355940295803

Epoch: 6| Step: 5
Training loss: 0.6562537550926208
Validation loss: 1.789545646277807

Epoch: 6| Step: 6
Training loss: 0.7924879789352417
Validation loss: 1.756871792577928

Epoch: 6| Step: 7
Training loss: 0.5570175051689148
Validation loss: 1.7702809431219613

Epoch: 6| Step: 8
Training loss: 1.24088454246521
Validation loss: 1.7402100550231112

Epoch: 6| Step: 9
Training loss: 0.8171910047531128
Validation loss: 1.7676202994520946

Epoch: 6| Step: 10
Training loss: 0.891829252243042
Validation loss: 1.7232898512194235

Epoch: 6| Step: 11
Training loss: 0.516647458076477
Validation loss: 1.7691215468991188

Epoch: 6| Step: 12
Training loss: 0.9278496503829956
Validation loss: 1.7703668071377663

Epoch: 6| Step: 13
Training loss: 0.8328441381454468
Validation loss: 1.7814849602278842

Epoch: 502| Step: 0
Training loss: 1.6653529405593872
Validation loss: 1.68113370608258

Epoch: 6| Step: 1
Training loss: 1.041297435760498
Validation loss: 1.7720862562938402

Epoch: 6| Step: 2
Training loss: 1.059695839881897
Validation loss: 1.7039301523598291

Epoch: 6| Step: 3
Training loss: 0.8815122842788696
Validation loss: 1.706092337126373

Epoch: 6| Step: 4
Training loss: 0.9073294997215271
Validation loss: 1.7301074663798015

Epoch: 6| Step: 5
Training loss: 1.3581962585449219
Validation loss: 1.7598822706489152

Epoch: 6| Step: 6
Training loss: 0.5765698552131653
Validation loss: 1.7095300830820555

Epoch: 6| Step: 7
Training loss: 0.9522343873977661
Validation loss: 1.7200606920385872

Epoch: 6| Step: 8
Training loss: 0.9812484979629517
Validation loss: 1.7496691737123715

Epoch: 6| Step: 9
Training loss: 0.6139213442802429
Validation loss: 1.7241312611487605

Epoch: 6| Step: 10
Training loss: 0.4235987961292267
Validation loss: 1.7485143574335242

Epoch: 6| Step: 11
Training loss: 1.2980540990829468
Validation loss: 1.7738220178952782

Epoch: 6| Step: 12
Training loss: 0.9690495133399963
Validation loss: 1.7586812216748473

Epoch: 6| Step: 13
Training loss: 0.23844999074935913
Validation loss: 1.7543973217728317

Epoch: 503| Step: 0
Training loss: 0.6121371984481812
Validation loss: 1.7753422619194112

Epoch: 6| Step: 1
Training loss: 1.0706543922424316
Validation loss: 1.8569479847467074

Epoch: 6| Step: 2
Training loss: 1.0410324335098267
Validation loss: 1.797697308242962

Epoch: 6| Step: 3
Training loss: 1.0359864234924316
Validation loss: 1.8345209783123386

Epoch: 6| Step: 4
Training loss: 1.1323660612106323
Validation loss: 1.7899059634054861

Epoch: 6| Step: 5
Training loss: 1.100470781326294
Validation loss: 1.803394276608703

Epoch: 6| Step: 6
Training loss: 0.7951246500015259
Validation loss: 1.8007916506900583

Epoch: 6| Step: 7
Training loss: 0.8455851078033447
Validation loss: 1.7527955373128254

Epoch: 6| Step: 8
Training loss: 1.270309329032898
Validation loss: 1.7011880118359801

Epoch: 6| Step: 9
Training loss: 0.7202028036117554
Validation loss: 1.7768317217467933

Epoch: 6| Step: 10
Training loss: 0.8577369451522827
Validation loss: 1.776580770810445

Epoch: 6| Step: 11
Training loss: 0.9118777513504028
Validation loss: 1.6992585325753817

Epoch: 6| Step: 12
Training loss: 0.9952298402786255
Validation loss: 1.7298713768682172

Epoch: 6| Step: 13
Training loss: 1.1901949644088745
Validation loss: 1.7234855287818498

Epoch: 504| Step: 0
Training loss: 0.8114185929298401
Validation loss: 1.751352592181134

Epoch: 6| Step: 1
Training loss: 1.2244738340377808
Validation loss: 1.7233734105222969

Epoch: 6| Step: 2
Training loss: 0.8452900052070618
Validation loss: 1.6793732220126736

Epoch: 6| Step: 3
Training loss: 1.3968538045883179
Validation loss: 1.7481989693898026

Epoch: 6| Step: 4
Training loss: 0.4192461371421814
Validation loss: 1.7456086015188566

Epoch: 6| Step: 5
Training loss: 1.030923843383789
Validation loss: 1.7747366607830088

Epoch: 6| Step: 6
Training loss: 0.9474549293518066
Validation loss: 1.818993535093082

Epoch: 6| Step: 7
Training loss: 0.44104546308517456
Validation loss: 1.7635873030590754

Epoch: 6| Step: 8
Training loss: 1.5151546001434326
Validation loss: 1.7871755002647318

Epoch: 6| Step: 9
Training loss: 0.7239683866500854
Validation loss: 1.7495582321638703

Epoch: 6| Step: 10
Training loss: 1.1285897493362427
Validation loss: 1.7149187928886824

Epoch: 6| Step: 11
Training loss: 0.911262035369873
Validation loss: 1.784433667377759

Epoch: 6| Step: 12
Training loss: 0.7948497533798218
Validation loss: 1.7050719837988577

Epoch: 6| Step: 13
Training loss: 1.1257675886154175
Validation loss: 1.7439573349491242

Epoch: 505| Step: 0
Training loss: 0.9369210004806519
Validation loss: 1.7251045498796689

Epoch: 6| Step: 1
Training loss: 0.7861150503158569
Validation loss: 1.7375875544804398

Epoch: 6| Step: 2
Training loss: 0.8554264307022095
Validation loss: 1.7474390998963387

Epoch: 6| Step: 3
Training loss: 1.2346396446228027
Validation loss: 1.7557378327974709

Epoch: 6| Step: 4
Training loss: 1.171533465385437
Validation loss: 1.6725809240853915

Epoch: 6| Step: 5
Training loss: 0.6592857241630554
Validation loss: 1.7582922161266368

Epoch: 6| Step: 6
Training loss: 0.6710991263389587
Validation loss: 1.7024068883670274

Epoch: 6| Step: 7
Training loss: 1.1226853132247925
Validation loss: 1.7402413404116066

Epoch: 6| Step: 8
Training loss: 1.0115972757339478
Validation loss: 1.7540233929951985

Epoch: 6| Step: 9
Training loss: 0.5408967733383179
Validation loss: 1.6966276835369807

Epoch: 6| Step: 10
Training loss: 1.37058687210083
Validation loss: 1.7511380898055209

Epoch: 6| Step: 11
Training loss: 0.9473041892051697
Validation loss: 1.7150756505227858

Epoch: 6| Step: 12
Training loss: 0.8107735514640808
Validation loss: 1.7612356511495446

Epoch: 6| Step: 13
Training loss: 1.001842737197876
Validation loss: 1.7442150385149064

Epoch: 506| Step: 0
Training loss: 0.3997574746608734
Validation loss: 1.806094205507668

Epoch: 6| Step: 1
Training loss: 1.0078078508377075
Validation loss: 1.7130592074445499

Epoch: 6| Step: 2
Training loss: 1.327392339706421
Validation loss: 1.7505492587243356

Epoch: 6| Step: 3
Training loss: 1.0030156373977661
Validation loss: 1.7466266052697295

Epoch: 6| Step: 4
Training loss: 0.7227041721343994
Validation loss: 1.7370915925630959

Epoch: 6| Step: 5
Training loss: 0.8638901710510254
Validation loss: 1.774262107828612

Epoch: 6| Step: 6
Training loss: 1.1237068176269531
Validation loss: 1.7062248440199002

Epoch: 6| Step: 7
Training loss: 0.733188271522522
Validation loss: 1.7822308771071895

Epoch: 6| Step: 8
Training loss: 0.9850096106529236
Validation loss: 1.7031984085677772

Epoch: 6| Step: 9
Training loss: 1.66546630859375
Validation loss: 1.6985732406698248

Epoch: 6| Step: 10
Training loss: 0.7632569670677185
Validation loss: 1.6803638973543722

Epoch: 6| Step: 11
Training loss: 0.6818063259124756
Validation loss: 1.6863660145831365

Epoch: 6| Step: 12
Training loss: 0.8973432183265686
Validation loss: 1.6677661544533187

Epoch: 6| Step: 13
Training loss: 1.0394941568374634
Validation loss: 1.6957432390541158

Epoch: 507| Step: 0
Training loss: 1.0441827774047852
Validation loss: 1.6973616269326979

Epoch: 6| Step: 1
Training loss: 1.5316057205200195
Validation loss: 1.701144136408324

Epoch: 6| Step: 2
Training loss: 1.0764646530151367
Validation loss: 1.7098809519121725

Epoch: 6| Step: 3
Training loss: 0.7490991353988647
Validation loss: 1.734416502778248

Epoch: 6| Step: 4
Training loss: 0.9681783318519592
Validation loss: 1.766735674232565

Epoch: 6| Step: 5
Training loss: 0.5306023359298706
Validation loss: 1.744886907198096

Epoch: 6| Step: 6
Training loss: 1.046738862991333
Validation loss: 1.8064926516625188

Epoch: 6| Step: 7
Training loss: 0.891959547996521
Validation loss: 1.7487306210302538

Epoch: 6| Step: 8
Training loss: 0.855455756187439
Validation loss: 1.7910723404217792

Epoch: 6| Step: 9
Training loss: 1.0886845588684082
Validation loss: 1.7847354822261359

Epoch: 6| Step: 10
Training loss: 1.0496410131454468
Validation loss: 1.7781619846179921

Epoch: 6| Step: 11
Training loss: 0.7316415309906006
Validation loss: 1.785408595556854

Epoch: 6| Step: 12
Training loss: 0.7166483402252197
Validation loss: 1.751174965212422

Epoch: 6| Step: 13
Training loss: 1.164810299873352
Validation loss: 1.75798257576522

Epoch: 508| Step: 0
Training loss: 1.362584114074707
Validation loss: 1.743503628238555

Epoch: 6| Step: 1
Training loss: 0.9170784950256348
Validation loss: 1.788732046722084

Epoch: 6| Step: 2
Training loss: 0.6931196451187134
Validation loss: 1.697339593723256

Epoch: 6| Step: 3
Training loss: 0.9328413009643555
Validation loss: 1.7357120539552422

Epoch: 6| Step: 4
Training loss: 1.0810487270355225
Validation loss: 1.6932848589394682

Epoch: 6| Step: 5
Training loss: 0.8815650939941406
Validation loss: 1.7169711576995028

Epoch: 6| Step: 6
Training loss: 1.0782206058502197
Validation loss: 1.7443070001499628

Epoch: 6| Step: 7
Training loss: 0.42304933071136475
Validation loss: 1.8143042941247263

Epoch: 6| Step: 8
Training loss: 0.6706768274307251
Validation loss: 1.7715268032525175

Epoch: 6| Step: 9
Training loss: 1.1171261072158813
Validation loss: 1.7620505722620154

Epoch: 6| Step: 10
Training loss: 0.7902066111564636
Validation loss: 1.7260416669230307

Epoch: 6| Step: 11
Training loss: 1.4239873886108398
Validation loss: 1.749883021077802

Epoch: 6| Step: 12
Training loss: 0.7256779670715332
Validation loss: 1.7821734515569543

Epoch: 6| Step: 13
Training loss: 0.8779651522636414
Validation loss: 1.745962046807812

Epoch: 509| Step: 0
Training loss: 0.7987314462661743
Validation loss: 1.7400696354527627

Epoch: 6| Step: 1
Training loss: 1.05863356590271
Validation loss: 1.7498008948500439

Epoch: 6| Step: 2
Training loss: 0.9035661816596985
Validation loss: 1.688308637629273

Epoch: 6| Step: 3
Training loss: 1.0559394359588623
Validation loss: 1.7394298789321736

Epoch: 6| Step: 4
Training loss: 0.690258800983429
Validation loss: 1.7732729501621698

Epoch: 6| Step: 5
Training loss: 0.505461573600769
Validation loss: 1.7310669140149189

Epoch: 6| Step: 6
Training loss: 0.6894323229789734
Validation loss: 1.7591244225860925

Epoch: 6| Step: 7
Training loss: 1.1619083881378174
Validation loss: 1.7434366928633822

Epoch: 6| Step: 8
Training loss: 0.7874183654785156
Validation loss: 1.7082829251084277

Epoch: 6| Step: 9
Training loss: 0.6879994869232178
Validation loss: 1.7391741378332979

Epoch: 6| Step: 10
Training loss: 1.3047009706497192
Validation loss: 1.6803540850198397

Epoch: 6| Step: 11
Training loss: 1.038905143737793
Validation loss: 1.7963609259615663

Epoch: 6| Step: 12
Training loss: 0.8582821488380432
Validation loss: 1.7046073123972902

Epoch: 6| Step: 13
Training loss: 1.2405152320861816
Validation loss: 1.7203120211119294

Epoch: 510| Step: 0
Training loss: 1.2766920328140259
Validation loss: 1.7146981159845989

Epoch: 6| Step: 1
Training loss: 0.7157174944877625
Validation loss: 1.727895595694101

Epoch: 6| Step: 2
Training loss: 1.136231780052185
Validation loss: 1.6397552054415467

Epoch: 6| Step: 3
Training loss: 0.5360954999923706
Validation loss: 1.7416630509079143

Epoch: 6| Step: 4
Training loss: 1.0213682651519775
Validation loss: 1.7120501174721667

Epoch: 6| Step: 5
Training loss: 1.265134572982788
Validation loss: 1.7589405557160736

Epoch: 6| Step: 6
Training loss: 1.0626702308654785
Validation loss: 1.7693269432231944

Epoch: 6| Step: 7
Training loss: 0.7762898206710815
Validation loss: 1.7513250202260993

Epoch: 6| Step: 8
Training loss: 0.6021463871002197
Validation loss: 1.769564922137927

Epoch: 6| Step: 9
Training loss: 0.784112811088562
Validation loss: 1.7409422320704306

Epoch: 6| Step: 10
Training loss: 1.116776943206787
Validation loss: 1.7541785342718965

Epoch: 6| Step: 11
Training loss: 1.2213873863220215
Validation loss: 1.7594252978601763

Epoch: 6| Step: 12
Training loss: 0.845642626285553
Validation loss: 1.7793684454374417

Epoch: 6| Step: 13
Training loss: 0.9959596991539001
Validation loss: 1.7540553308302356

Epoch: 511| Step: 0
Training loss: 0.9816020131111145
Validation loss: 1.7979907951047343

Epoch: 6| Step: 1
Training loss: 0.9736827611923218
Validation loss: 1.775322316795267

Epoch: 6| Step: 2
Training loss: 0.6062713861465454
Validation loss: 1.7317280243801814

Epoch: 6| Step: 3
Training loss: 1.6900112628936768
Validation loss: 1.751597717244138

Epoch: 6| Step: 4
Training loss: 0.8166472911834717
Validation loss: 1.7481829094630417

Epoch: 6| Step: 5
Training loss: 0.6115971803665161
Validation loss: 1.741516725991362

Epoch: 6| Step: 6
Training loss: 1.1895017623901367
Validation loss: 1.6845528464163504

Epoch: 6| Step: 7
Training loss: 0.6460373401641846
Validation loss: 1.7248498752552976

Epoch: 6| Step: 8
Training loss: 1.0414280891418457
Validation loss: 1.7148590036617812

Epoch: 6| Step: 9
Training loss: 0.3720332980155945
Validation loss: 1.7346206762457406

Epoch: 6| Step: 10
Training loss: 0.8954919576644897
Validation loss: 1.7261847385796167

Epoch: 6| Step: 11
Training loss: 0.8264223337173462
Validation loss: 1.7032608601354784

Epoch: 6| Step: 12
Training loss: 0.9687222242355347
Validation loss: 1.7130744264971824

Epoch: 6| Step: 13
Training loss: 1.8542414903640747
Validation loss: 1.7246911551362725

Epoch: 512| Step: 0
Training loss: 1.1842632293701172
Validation loss: 1.7515792821043281

Epoch: 6| Step: 1
Training loss: 1.1449840068817139
Validation loss: 1.767546662720301

Epoch: 6| Step: 2
Training loss: 0.627993106842041
Validation loss: 1.7678117136801443

Epoch: 6| Step: 3
Training loss: 0.8260800838470459
Validation loss: 1.815377499467583

Epoch: 6| Step: 4
Training loss: 0.9789772033691406
Validation loss: 1.7870292227755311

Epoch: 6| Step: 5
Training loss: 1.146712064743042
Validation loss: 1.78363029033907

Epoch: 6| Step: 6
Training loss: 1.6468809843063354
Validation loss: 1.7285526670435423

Epoch: 6| Step: 7
Training loss: 0.7019333243370056
Validation loss: 1.7539403630841164

Epoch: 6| Step: 8
Training loss: 1.0682332515716553
Validation loss: 1.7806790797941145

Epoch: 6| Step: 9
Training loss: 0.8175292015075684
Validation loss: 1.7758412694418302

Epoch: 6| Step: 10
Training loss: 0.5548573732376099
Validation loss: 1.7892767998480028

Epoch: 6| Step: 11
Training loss: 0.36253631114959717
Validation loss: 1.74212928869391

Epoch: 6| Step: 12
Training loss: 1.1763219833374023
Validation loss: 1.800619245857321

Epoch: 6| Step: 13
Training loss: 0.9483346939086914
Validation loss: 1.803305156769291

Epoch: 513| Step: 0
Training loss: 0.9029844999313354
Validation loss: 1.7530005080725557

Epoch: 6| Step: 1
Training loss: 0.8973067998886108
Validation loss: 1.7670275908644482

Epoch: 6| Step: 2
Training loss: 1.0803636312484741
Validation loss: 1.749403989443215

Epoch: 6| Step: 3
Training loss: 1.1104989051818848
Validation loss: 1.6724614353590115

Epoch: 6| Step: 4
Training loss: 1.0197499990463257
Validation loss: 1.7839646211234472

Epoch: 6| Step: 5
Training loss: 0.8407255411148071
Validation loss: 1.7088027923337874

Epoch: 6| Step: 6
Training loss: 1.173482894897461
Validation loss: 1.7619058483390397

Epoch: 6| Step: 7
Training loss: 0.8703014850616455
Validation loss: 1.7466904565852175

Epoch: 6| Step: 8
Training loss: 1.0045063495635986
Validation loss: 1.664169026959327

Epoch: 6| Step: 9
Training loss: 0.5437013506889343
Validation loss: 1.674573125377778

Epoch: 6| Step: 10
Training loss: 1.009855031967163
Validation loss: 1.770445546796245

Epoch: 6| Step: 11
Training loss: 0.951106607913971
Validation loss: 1.694405209633612

Epoch: 6| Step: 12
Training loss: 0.4466555416584015
Validation loss: 1.744526045296782

Epoch: 6| Step: 13
Training loss: 1.2691328525543213
Validation loss: 1.7047318053501908

Epoch: 514| Step: 0
Training loss: 0.8384372591972351
Validation loss: 1.7382103653364285

Epoch: 6| Step: 1
Training loss: 0.5697807669639587
Validation loss: 1.7503971822800175

Epoch: 6| Step: 2
Training loss: 1.0023257732391357
Validation loss: 1.7286073315528132

Epoch: 6| Step: 3
Training loss: 1.184790849685669
Validation loss: 1.7109014629035868

Epoch: 6| Step: 4
Training loss: 1.7845808267593384
Validation loss: 1.7305282033899778

Epoch: 6| Step: 5
Training loss: 0.4613293409347534
Validation loss: 1.7461835440768991

Epoch: 6| Step: 6
Training loss: 0.7156112194061279
Validation loss: 1.730080287302694

Epoch: 6| Step: 7
Training loss: 0.626464307308197
Validation loss: 1.7400185433767175

Epoch: 6| Step: 8
Training loss: 0.7695305347442627
Validation loss: 1.7151244096858527

Epoch: 6| Step: 9
Training loss: 1.1763241291046143
Validation loss: 1.7086154991580593

Epoch: 6| Step: 10
Training loss: 0.8935031294822693
Validation loss: 1.6799481581616145

Epoch: 6| Step: 11
Training loss: 0.6526269912719727
Validation loss: 1.7494014629753687

Epoch: 6| Step: 12
Training loss: 0.7382462024688721
Validation loss: 1.7240072616966822

Epoch: 6| Step: 13
Training loss: 1.8381246328353882
Validation loss: 1.7337321043014526

Epoch: 515| Step: 0
Training loss: 0.624878466129303
Validation loss: 1.7211918330961657

Epoch: 6| Step: 1
Training loss: 0.6872040629386902
Validation loss: 1.7206161317004953

Epoch: 6| Step: 2
Training loss: 1.1624202728271484
Validation loss: 1.7444876329873198

Epoch: 6| Step: 3
Training loss: 1.186347484588623
Validation loss: 1.7549093051623272

Epoch: 6| Step: 4
Training loss: 1.2456028461456299
Validation loss: 1.7961200994829978

Epoch: 6| Step: 5
Training loss: 0.6545566320419312
Validation loss: 1.7305073199733612

Epoch: 6| Step: 6
Training loss: 1.0481171607971191
Validation loss: 1.7299449533544562

Epoch: 6| Step: 7
Training loss: 0.6263796091079712
Validation loss: 1.7196719954090733

Epoch: 6| Step: 8
Training loss: 0.8443262577056885
Validation loss: 1.7056028099470242

Epoch: 6| Step: 9
Training loss: 0.7722854614257812
Validation loss: 1.764305426228431

Epoch: 6| Step: 10
Training loss: 1.1648736000061035
Validation loss: 1.730105004002971

Epoch: 6| Step: 11
Training loss: 0.901668906211853
Validation loss: 1.7289261894841348

Epoch: 6| Step: 12
Training loss: 0.8625792264938354
Validation loss: 1.7429381493599183

Epoch: 6| Step: 13
Training loss: 0.922387421131134
Validation loss: 1.734866488364435

Epoch: 516| Step: 0
Training loss: 1.0017961263656616
Validation loss: 1.7632990582014925

Epoch: 6| Step: 1
Training loss: 0.806813657283783
Validation loss: 1.7416281597588652

Epoch: 6| Step: 2
Training loss: 0.6346749067306519
Validation loss: 1.7120648404603362

Epoch: 6| Step: 3
Training loss: 1.1194703578948975
Validation loss: 1.7340199319265222

Epoch: 6| Step: 4
Training loss: 1.254907250404358
Validation loss: 1.7287765267074748

Epoch: 6| Step: 5
Training loss: 0.5966778993606567
Validation loss: 1.6904709082777782

Epoch: 6| Step: 6
Training loss: 0.6254597306251526
Validation loss: 1.754701381088585

Epoch: 6| Step: 7
Training loss: 0.7196340560913086
Validation loss: 1.7133423141253892

Epoch: 6| Step: 8
Training loss: 1.4762485027313232
Validation loss: 1.7332127273723643

Epoch: 6| Step: 9
Training loss: 0.7396156787872314
Validation loss: 1.8005027296722576

Epoch: 6| Step: 10
Training loss: 1.4574286937713623
Validation loss: 1.7210944467975247

Epoch: 6| Step: 11
Training loss: 0.8630862832069397
Validation loss: 1.7523023031091178

Epoch: 6| Step: 12
Training loss: 0.7588670253753662
Validation loss: 1.7903768067718835

Epoch: 6| Step: 13
Training loss: 0.6271696090698242
Validation loss: 1.8070993192734257

Epoch: 517| Step: 0
Training loss: 0.64273601770401
Validation loss: 1.8154974470856369

Epoch: 6| Step: 1
Training loss: 1.124681830406189
Validation loss: 1.741191630722374

Epoch: 6| Step: 2
Training loss: 0.7966294884681702
Validation loss: 1.7146524242175523

Epoch: 6| Step: 3
Training loss: 0.7468311786651611
Validation loss: 1.7587873448607743

Epoch: 6| Step: 4
Training loss: 0.5466063022613525
Validation loss: 1.7126836597278554

Epoch: 6| Step: 5
Training loss: 1.4462823867797852
Validation loss: 1.7100845318968578

Epoch: 6| Step: 6
Training loss: 1.059877634048462
Validation loss: 1.7466237891104914

Epoch: 6| Step: 7
Training loss: 0.8077945709228516
Validation loss: 1.7245927164631505

Epoch: 6| Step: 8
Training loss: 0.416014164686203
Validation loss: 1.7063126461480254

Epoch: 6| Step: 9
Training loss: 0.8843017816543579
Validation loss: 1.7460940858369232

Epoch: 6| Step: 10
Training loss: 1.0049792528152466
Validation loss: 1.7100113156021282

Epoch: 6| Step: 11
Training loss: 0.8884812593460083
Validation loss: 1.7074713194242088

Epoch: 6| Step: 12
Training loss: 1.0070579051971436
Validation loss: 1.7519891954237414

Epoch: 6| Step: 13
Training loss: 1.327179193496704
Validation loss: 1.7434028438342515

Epoch: 518| Step: 0
Training loss: 0.8397841453552246
Validation loss: 1.756701994967717

Epoch: 6| Step: 1
Training loss: 1.455816388130188
Validation loss: 1.7931501544931883

Epoch: 6| Step: 2
Training loss: 0.8866514563560486
Validation loss: 1.784227668598134

Epoch: 6| Step: 3
Training loss: 0.5881250500679016
Validation loss: 1.7327940720383839

Epoch: 6| Step: 4
Training loss: 0.8448903560638428
Validation loss: 1.7675361364118514

Epoch: 6| Step: 5
Training loss: 1.539851188659668
Validation loss: 1.8215686839113954

Epoch: 6| Step: 6
Training loss: 0.8761104345321655
Validation loss: 1.7343192203070528

Epoch: 6| Step: 7
Training loss: 0.9438124895095825
Validation loss: 1.712853939302506

Epoch: 6| Step: 8
Training loss: 0.6094392538070679
Validation loss: 1.7465970388022802

Epoch: 6| Step: 9
Training loss: 1.1487042903900146
Validation loss: 1.7363132840843611

Epoch: 6| Step: 10
Training loss: 0.947616696357727
Validation loss: 1.7126045880779144

Epoch: 6| Step: 11
Training loss: 0.6380733251571655
Validation loss: 1.7377675592258413

Epoch: 6| Step: 12
Training loss: 0.7007609009742737
Validation loss: 1.6944547173797444

Epoch: 6| Step: 13
Training loss: 0.8462268114089966
Validation loss: 1.754331822036415

Epoch: 519| Step: 0
Training loss: 1.015212893486023
Validation loss: 1.7329455857635827

Epoch: 6| Step: 1
Training loss: 0.5681125521659851
Validation loss: 1.718048664831346

Epoch: 6| Step: 2
Training loss: 1.4501781463623047
Validation loss: 1.6889998758992841

Epoch: 6| Step: 3
Training loss: 0.7198812961578369
Validation loss: 1.6791515747706096

Epoch: 6| Step: 4
Training loss: 1.1615456342697144
Validation loss: 1.7712259382329962

Epoch: 6| Step: 5
Training loss: 0.727002739906311
Validation loss: 1.7610403222422446

Epoch: 6| Step: 6
Training loss: 0.9391747117042542
Validation loss: 1.789634168788951

Epoch: 6| Step: 7
Training loss: 0.6988657712936401
Validation loss: 1.7542332603085427

Epoch: 6| Step: 8
Training loss: 0.9057288765907288
Validation loss: 1.8168070803406418

Epoch: 6| Step: 9
Training loss: 0.9885419607162476
Validation loss: 1.8192917531536472

Epoch: 6| Step: 10
Training loss: 0.9600772857666016
Validation loss: 1.794605722991369

Epoch: 6| Step: 11
Training loss: 1.4816184043884277
Validation loss: 1.8688489596048992

Epoch: 6| Step: 12
Training loss: 0.7468129396438599
Validation loss: 1.7890799724927513

Epoch: 6| Step: 13
Training loss: 0.7668763995170593
Validation loss: 1.7961338232922297

Epoch: 520| Step: 0
Training loss: 0.7950681447982788
Validation loss: 1.7764709739274875

Epoch: 6| Step: 1
Training loss: 0.25631964206695557
Validation loss: 1.7373254017163349

Epoch: 6| Step: 2
Training loss: 0.904047966003418
Validation loss: 1.686648529062989

Epoch: 6| Step: 3
Training loss: 0.9908976554870605
Validation loss: 1.7308270610788816

Epoch: 6| Step: 4
Training loss: 0.8545892834663391
Validation loss: 1.7243328671301565

Epoch: 6| Step: 5
Training loss: 0.8704805970191956
Validation loss: 1.775353584238278

Epoch: 6| Step: 6
Training loss: 0.8397841453552246
Validation loss: 1.7609273605449225

Epoch: 6| Step: 7
Training loss: 1.2391586303710938
Validation loss: 1.7583058905857865

Epoch: 6| Step: 8
Training loss: 0.8735615611076355
Validation loss: 1.7769869681327575

Epoch: 6| Step: 9
Training loss: 0.8462557792663574
Validation loss: 1.6724040367270028

Epoch: 6| Step: 10
Training loss: 1.2870924472808838
Validation loss: 1.7503788202039656

Epoch: 6| Step: 11
Training loss: 1.2550947666168213
Validation loss: 1.7230861635618313

Epoch: 6| Step: 12
Training loss: 0.5240121483802795
Validation loss: 1.734567790903071

Epoch: 6| Step: 13
Training loss: 1.066606879234314
Validation loss: 1.7308942605090398

Epoch: 521| Step: 0
Training loss: 0.872117280960083
Validation loss: 1.729973070083126

Epoch: 6| Step: 1
Training loss: 0.5348809957504272
Validation loss: 1.6853696159137193

Epoch: 6| Step: 2
Training loss: 1.206428050994873
Validation loss: 1.7351796127134753

Epoch: 6| Step: 3
Training loss: 1.1297235488891602
Validation loss: 1.7382911635983376

Epoch: 6| Step: 4
Training loss: 0.6807923316955566
Validation loss: 1.6482454858800417

Epoch: 6| Step: 5
Training loss: 0.8388561010360718
Validation loss: 1.7384468227304437

Epoch: 6| Step: 6
Training loss: 1.0282377004623413
Validation loss: 1.7351182865840133

Epoch: 6| Step: 7
Training loss: 0.9143627285957336
Validation loss: 1.718313851023233

Epoch: 6| Step: 8
Training loss: 0.5571684241294861
Validation loss: 1.757651472604403

Epoch: 6| Step: 9
Training loss: 1.1968836784362793
Validation loss: 1.7272000274350565

Epoch: 6| Step: 10
Training loss: 0.6505813002586365
Validation loss: 1.7336964094510643

Epoch: 6| Step: 11
Training loss: 0.8319271206855774
Validation loss: 1.743492926320722

Epoch: 6| Step: 12
Training loss: 0.5322574973106384
Validation loss: 1.7274910147472093

Epoch: 6| Step: 13
Training loss: 1.8938993215560913
Validation loss: 1.7433863237339964

Epoch: 522| Step: 0
Training loss: 1.0178546905517578
Validation loss: 1.7595929868759648

Epoch: 6| Step: 1
Training loss: 0.8047490119934082
Validation loss: 1.6757738282603603

Epoch: 6| Step: 2
Training loss: 0.47152554988861084
Validation loss: 1.7025403796985585

Epoch: 6| Step: 3
Training loss: 0.73687344789505
Validation loss: 1.729433701884362

Epoch: 6| Step: 4
Training loss: 0.6782026290893555
Validation loss: 1.7088695668405103

Epoch: 6| Step: 5
Training loss: 1.0607314109802246
Validation loss: 1.7042868803906184

Epoch: 6| Step: 6
Training loss: 1.8057714700698853
Validation loss: 1.739534806179744

Epoch: 6| Step: 7
Training loss: 0.6279680728912354
Validation loss: 1.7617392155431932

Epoch: 6| Step: 8
Training loss: 0.7847041487693787
Validation loss: 1.7199009259541829

Epoch: 6| Step: 9
Training loss: 0.6191551685333252
Validation loss: 1.705383212335648

Epoch: 6| Step: 10
Training loss: 1.4534029960632324
Validation loss: 1.7284337871818132

Epoch: 6| Step: 11
Training loss: 0.6680814027786255
Validation loss: 1.7134968106464674

Epoch: 6| Step: 12
Training loss: 0.8714713454246521
Validation loss: 1.7137120628869662

Epoch: 6| Step: 13
Training loss: 0.950390100479126
Validation loss: 1.7448364316776235

Epoch: 523| Step: 0
Training loss: 1.0040357112884521
Validation loss: 1.720621342300087

Epoch: 6| Step: 1
Training loss: 0.7311110496520996
Validation loss: 1.7445422013600667

Epoch: 6| Step: 2
Training loss: 0.8438534736633301
Validation loss: 1.7865465315439368

Epoch: 6| Step: 3
Training loss: 0.7878801822662354
Validation loss: 1.7117570472019974

Epoch: 6| Step: 4
Training loss: 0.6941998600959778
Validation loss: 1.685726405471884

Epoch: 6| Step: 5
Training loss: 0.8427693843841553
Validation loss: 1.7826041585655623

Epoch: 6| Step: 6
Training loss: 1.0664706230163574
Validation loss: 1.7006162007649739

Epoch: 6| Step: 7
Training loss: 0.33278730511665344
Validation loss: 1.6833588410449285

Epoch: 6| Step: 8
Training loss: 0.9001556634902954
Validation loss: 1.7414082429742301

Epoch: 6| Step: 9
Training loss: 0.8855531215667725
Validation loss: 1.6961179676876272

Epoch: 6| Step: 10
Training loss: 1.5699316263198853
Validation loss: 1.7150981554421045

Epoch: 6| Step: 11
Training loss: 1.4048545360565186
Validation loss: 1.7598920509379397

Epoch: 6| Step: 12
Training loss: 0.8161224126815796
Validation loss: 1.780149531620805

Epoch: 6| Step: 13
Training loss: 0.6230719089508057
Validation loss: 1.729602252283404

Epoch: 524| Step: 0
Training loss: 0.6377038955688477
Validation loss: 1.720776355394753

Epoch: 6| Step: 1
Training loss: 1.086643934249878
Validation loss: 1.6832654860711866

Epoch: 6| Step: 2
Training loss: 0.6248288750648499
Validation loss: 1.7238060607705066

Epoch: 6| Step: 3
Training loss: 0.5503973960876465
Validation loss: 1.7320939161444222

Epoch: 6| Step: 4
Training loss: 0.9807947874069214
Validation loss: 1.7121137931782713

Epoch: 6| Step: 5
Training loss: 0.9889857769012451
Validation loss: 1.7375165467621179

Epoch: 6| Step: 6
Training loss: 0.8627997636795044
Validation loss: 1.7343138020525697

Epoch: 6| Step: 7
Training loss: 1.0949562788009644
Validation loss: 1.7166270761079685

Epoch: 6| Step: 8
Training loss: 0.9722369909286499
Validation loss: 1.7285484626729002

Epoch: 6| Step: 9
Training loss: 1.0063540935516357
Validation loss: 1.800712413685296

Epoch: 6| Step: 10
Training loss: 0.44844597578048706
Validation loss: 1.7842811461417907

Epoch: 6| Step: 11
Training loss: 1.2634477615356445
Validation loss: 1.7335110941240865

Epoch: 6| Step: 12
Training loss: 0.9191983342170715
Validation loss: 1.8176052390888173

Epoch: 6| Step: 13
Training loss: 0.5235426425933838
Validation loss: 1.7985601258534256

Epoch: 525| Step: 0
Training loss: 1.1543042659759521
Validation loss: 1.706226118149296

Epoch: 6| Step: 1
Training loss: 1.5004010200500488
Validation loss: 1.7367045071817213

Epoch: 6| Step: 2
Training loss: 0.5772253274917603
Validation loss: 1.7629273258229738

Epoch: 6| Step: 3
Training loss: 0.9354581832885742
Validation loss: 1.7218444155108543

Epoch: 6| Step: 4
Training loss: 0.4959487020969391
Validation loss: 1.7221334236924366

Epoch: 6| Step: 5
Training loss: 0.6570519208908081
Validation loss: 1.7448650021706857

Epoch: 6| Step: 6
Training loss: 0.7480331659317017
Validation loss: 1.7255495145756712

Epoch: 6| Step: 7
Training loss: 0.8838884830474854
Validation loss: 1.76100323148953

Epoch: 6| Step: 8
Training loss: 0.7508158683776855
Validation loss: 1.7371206719388244

Epoch: 6| Step: 9
Training loss: 0.8001300692558289
Validation loss: 1.724818225829832

Epoch: 6| Step: 10
Training loss: 1.1634900569915771
Validation loss: 1.7666683645658596

Epoch: 6| Step: 11
Training loss: 1.253930926322937
Validation loss: 1.722607647219012

Epoch: 6| Step: 12
Training loss: 1.1559182405471802
Validation loss: 1.7863943807540401

Epoch: 6| Step: 13
Training loss: 0.42135122418403625
Validation loss: 1.7617773368794432

Epoch: 526| Step: 0
Training loss: 1.1743700504302979
Validation loss: 1.7791413004680345

Epoch: 6| Step: 1
Training loss: 0.6905012130737305
Validation loss: 1.6896078862169737

Epoch: 6| Step: 2
Training loss: 1.4992358684539795
Validation loss: 1.762249360802353

Epoch: 6| Step: 3
Training loss: 0.7785457372665405
Validation loss: 1.8041315206917383

Epoch: 6| Step: 4
Training loss: 0.9430373311042786
Validation loss: 1.73187171131052

Epoch: 6| Step: 5
Training loss: 0.8960548639297485
Validation loss: 1.6922318525211786

Epoch: 6| Step: 6
Training loss: 1.1060888767242432
Validation loss: 1.7569105919971262

Epoch: 6| Step: 7
Training loss: 0.8897010087966919
Validation loss: 1.678866708150474

Epoch: 6| Step: 8
Training loss: 0.8635121583938599
Validation loss: 1.7511740730654808

Epoch: 6| Step: 9
Training loss: 1.046191930770874
Validation loss: 1.7317914065494333

Epoch: 6| Step: 10
Training loss: 0.4649510681629181
Validation loss: 1.7512648490167433

Epoch: 6| Step: 11
Training loss: 0.9303262829780579
Validation loss: 1.7626395610070997

Epoch: 6| Step: 12
Training loss: 0.8150277137756348
Validation loss: 1.7280381097588489

Epoch: 6| Step: 13
Training loss: 0.6066251993179321
Validation loss: 1.7088512169417513

Epoch: 527| Step: 0
Training loss: 0.8501527309417725
Validation loss: 1.813773077021363

Epoch: 6| Step: 1
Training loss: 0.9240494966506958
Validation loss: 1.703347147151988

Epoch: 6| Step: 2
Training loss: 1.1055269241333008
Validation loss: 1.6992253539382771

Epoch: 6| Step: 3
Training loss: 1.1673226356506348
Validation loss: 1.7609805291698826

Epoch: 6| Step: 4
Training loss: 0.6629043221473694
Validation loss: 1.7485056679735902

Epoch: 6| Step: 5
Training loss: 1.0937705039978027
Validation loss: 1.7627214180525912

Epoch: 6| Step: 6
Training loss: 1.222564458847046
Validation loss: 1.7468745375192294

Epoch: 6| Step: 7
Training loss: 0.5926133394241333
Validation loss: 1.7142871913089548

Epoch: 6| Step: 8
Training loss: 0.7561078667640686
Validation loss: 1.7185571168058662

Epoch: 6| Step: 9
Training loss: 0.8292922973632812
Validation loss: 1.7649776422849266

Epoch: 6| Step: 10
Training loss: 0.7490077018737793
Validation loss: 1.7151262913980792

Epoch: 6| Step: 11
Training loss: 1.2424447536468506
Validation loss: 1.707732992787515

Epoch: 6| Step: 12
Training loss: 0.5893204212188721
Validation loss: 1.7749152747533654

Epoch: 6| Step: 13
Training loss: 0.5869832634925842
Validation loss: 1.6936549627652733

Epoch: 528| Step: 0
Training loss: 1.1059682369232178
Validation loss: 1.743861001024964

Epoch: 6| Step: 1
Training loss: 0.6888339519500732
Validation loss: 1.6984224793731526

Epoch: 6| Step: 2
Training loss: 1.0146398544311523
Validation loss: 1.7669930381159629

Epoch: 6| Step: 3
Training loss: 0.8530048131942749
Validation loss: 1.74858061985303

Epoch: 6| Step: 4
Training loss: 1.1957201957702637
Validation loss: 1.7438055430689166

Epoch: 6| Step: 5
Training loss: 1.0772647857666016
Validation loss: 1.7299995806909376

Epoch: 6| Step: 6
Training loss: 0.5752397775650024
Validation loss: 1.7180080836819065

Epoch: 6| Step: 7
Training loss: 0.9628639221191406
Validation loss: 1.7031861774383052

Epoch: 6| Step: 8
Training loss: 0.7716403007507324
Validation loss: 1.68904128895011

Epoch: 6| Step: 9
Training loss: 0.8200064897537231
Validation loss: 1.7413069458417996

Epoch: 6| Step: 10
Training loss: 1.038843035697937
Validation loss: 1.6856337234538088

Epoch: 6| Step: 11
Training loss: 0.5899995565414429
Validation loss: 1.7071748677120413

Epoch: 6| Step: 12
Training loss: 0.8580654263496399
Validation loss: 1.7730143531676261

Epoch: 6| Step: 13
Training loss: 1.2607638835906982
Validation loss: 1.742053057557793

Epoch: 529| Step: 0
Training loss: 0.8808841109275818
Validation loss: 1.759913670119419

Epoch: 6| Step: 1
Training loss: 0.8294053673744202
Validation loss: 1.774782508932134

Epoch: 6| Step: 2
Training loss: 0.4597364664077759
Validation loss: 1.7447929036232732

Epoch: 6| Step: 3
Training loss: 0.6911185383796692
Validation loss: 1.7180925210316975

Epoch: 6| Step: 4
Training loss: 0.954383134841919
Validation loss: 1.7865028509529688

Epoch: 6| Step: 5
Training loss: 0.7940425872802734
Validation loss: 1.73323844709704

Epoch: 6| Step: 6
Training loss: 0.9890786409378052
Validation loss: 1.729839619769845

Epoch: 6| Step: 7
Training loss: 0.7044006586074829
Validation loss: 1.822916938412574

Epoch: 6| Step: 8
Training loss: 1.0149285793304443
Validation loss: 1.7093907299862112

Epoch: 6| Step: 9
Training loss: 1.1918812990188599
Validation loss: 1.7804159259283414

Epoch: 6| Step: 10
Training loss: 0.7458466291427612
Validation loss: 1.7581840817646315

Epoch: 6| Step: 11
Training loss: 0.6888096332550049
Validation loss: 1.7100516237238401

Epoch: 6| Step: 12
Training loss: 1.2781684398651123
Validation loss: 1.7095433178768362

Epoch: 6| Step: 13
Training loss: 0.846917450428009
Validation loss: 1.722212447915026

Epoch: 530| Step: 0
Training loss: 1.099455714225769
Validation loss: 1.7088928004746795

Epoch: 6| Step: 1
Training loss: 0.8615552186965942
Validation loss: 1.6977752408673685

Epoch: 6| Step: 2
Training loss: 0.9178808927536011
Validation loss: 1.7231379337208246

Epoch: 6| Step: 3
Training loss: 0.6747634410858154
Validation loss: 1.7267283406308902

Epoch: 6| Step: 4
Training loss: 0.5561408400535583
Validation loss: 1.7538167327962897

Epoch: 6| Step: 5
Training loss: 1.1193060874938965
Validation loss: 1.7816876724202146

Epoch: 6| Step: 6
Training loss: 0.8030565977096558
Validation loss: 1.7424796101867512

Epoch: 6| Step: 7
Training loss: 0.9143311977386475
Validation loss: 1.7238917825042561

Epoch: 6| Step: 8
Training loss: 0.9129061698913574
Validation loss: 1.7965594824924265

Epoch: 6| Step: 9
Training loss: 0.7698683142662048
Validation loss: 1.7073937962132115

Epoch: 6| Step: 10
Training loss: 0.6562190055847168
Validation loss: 1.7388169816745225

Epoch: 6| Step: 11
Training loss: 0.8282167315483093
Validation loss: 1.7258658229663808

Epoch: 6| Step: 12
Training loss: 0.6706224679946899
Validation loss: 1.7181584194142332

Epoch: 6| Step: 13
Training loss: 2.053786039352417
Validation loss: 1.6997168551209152

Epoch: 531| Step: 0
Training loss: 0.7353872060775757
Validation loss: 1.7446680940607542

Epoch: 6| Step: 1
Training loss: 1.073921799659729
Validation loss: 1.7126917198140135

Epoch: 6| Step: 2
Training loss: 0.5942513346672058
Validation loss: 1.7866301792924122

Epoch: 6| Step: 3
Training loss: 0.9922481775283813
Validation loss: 1.7561923073184105

Epoch: 6| Step: 4
Training loss: 0.5342693328857422
Validation loss: 1.776671955662389

Epoch: 6| Step: 5
Training loss: 0.5804157853126526
Validation loss: 1.6590903805148216

Epoch: 6| Step: 6
Training loss: 0.8252555131912231
Validation loss: 1.698774245477492

Epoch: 6| Step: 7
Training loss: 0.9200950264930725
Validation loss: 1.6829534179420882

Epoch: 6| Step: 8
Training loss: 0.9193288087844849
Validation loss: 1.7416958731989707

Epoch: 6| Step: 9
Training loss: 0.7310172319412231
Validation loss: 1.7358998303772302

Epoch: 6| Step: 10
Training loss: 0.807534396648407
Validation loss: 1.775742502622707

Epoch: 6| Step: 11
Training loss: 1.2069215774536133
Validation loss: 1.7735700338117537

Epoch: 6| Step: 12
Training loss: 0.8986328840255737
Validation loss: 1.7323507865269978

Epoch: 6| Step: 13
Training loss: 1.982218623161316
Validation loss: 1.7588751636525637

Epoch: 532| Step: 0
Training loss: 0.6591547727584839
Validation loss: 1.7274763173954462

Epoch: 6| Step: 1
Training loss: 0.641861081123352
Validation loss: 1.7475454576553837

Epoch: 6| Step: 2
Training loss: 0.7501969337463379
Validation loss: 1.7475043214777464

Epoch: 6| Step: 3
Training loss: 0.9892187714576721
Validation loss: 1.74681419070049

Epoch: 6| Step: 4
Training loss: 1.1762681007385254
Validation loss: 1.7024506022853236

Epoch: 6| Step: 5
Training loss: 1.0657415390014648
Validation loss: 1.7448541579707977

Epoch: 6| Step: 6
Training loss: 0.7637996673583984
Validation loss: 1.703085804498324

Epoch: 6| Step: 7
Training loss: 0.895139217376709
Validation loss: 1.71169836162239

Epoch: 6| Step: 8
Training loss: 0.6582075357437134
Validation loss: 1.6958569224162767

Epoch: 6| Step: 9
Training loss: 1.3296561241149902
Validation loss: 1.7215011286479172

Epoch: 6| Step: 10
Training loss: 1.015669822692871
Validation loss: 1.6874505473721413

Epoch: 6| Step: 11
Training loss: 0.8258233666419983
Validation loss: 1.6928621940715338

Epoch: 6| Step: 12
Training loss: 0.6555498242378235
Validation loss: 1.7114780961826284

Epoch: 6| Step: 13
Training loss: 0.8752349019050598
Validation loss: 1.6991337396765267

Epoch: 533| Step: 0
Training loss: 1.0741310119628906
Validation loss: 1.7426658336834242

Epoch: 6| Step: 1
Training loss: 1.161125659942627
Validation loss: 1.7450465540732107

Epoch: 6| Step: 2
Training loss: 0.9009047746658325
Validation loss: 1.7802771637516637

Epoch: 6| Step: 3
Training loss: 0.545384407043457
Validation loss: 1.8029422785646172

Epoch: 6| Step: 4
Training loss: 1.5670522451400757
Validation loss: 1.763880560475011

Epoch: 6| Step: 5
Training loss: 0.8904772996902466
Validation loss: 1.8270957918577297

Epoch: 6| Step: 6
Training loss: 0.7777746915817261
Validation loss: 1.800577429674005

Epoch: 6| Step: 7
Training loss: 1.0390633344650269
Validation loss: 1.784486291229084

Epoch: 6| Step: 8
Training loss: 1.1740460395812988
Validation loss: 1.6932865060785764

Epoch: 6| Step: 9
Training loss: 0.6083714962005615
Validation loss: 1.7017763135253743

Epoch: 6| Step: 10
Training loss: 0.744066596031189
Validation loss: 1.6975381015449442

Epoch: 6| Step: 11
Training loss: 0.9395045042037964
Validation loss: 1.7182543636650167

Epoch: 6| Step: 12
Training loss: 0.415852814912796
Validation loss: 1.6951740095692296

Epoch: 6| Step: 13
Training loss: 0.6345138549804688
Validation loss: 1.746930831222124

Epoch: 534| Step: 0
Training loss: 1.4691760540008545
Validation loss: 1.6906069709408669

Epoch: 6| Step: 1
Training loss: 0.9657914042472839
Validation loss: 1.6831142928010674

Epoch: 6| Step: 2
Training loss: 0.6752161979675293
Validation loss: 1.6752544744040376

Epoch: 6| Step: 3
Training loss: 0.8096791505813599
Validation loss: 1.6884579235507595

Epoch: 6| Step: 4
Training loss: 0.8671771287918091
Validation loss: 1.7010967116202078

Epoch: 6| Step: 5
Training loss: 0.5932790040969849
Validation loss: 1.7382342514171396

Epoch: 6| Step: 6
Training loss: 0.9331350326538086
Validation loss: 1.7241360487476471

Epoch: 6| Step: 7
Training loss: 0.7579542398452759
Validation loss: 1.77542084006853

Epoch: 6| Step: 8
Training loss: 0.6115269064903259
Validation loss: 1.8414111944936937

Epoch: 6| Step: 9
Training loss: 0.8719325065612793
Validation loss: 1.7623747766658824

Epoch: 6| Step: 10
Training loss: 0.8260742425918579
Validation loss: 1.7725669466039187

Epoch: 6| Step: 11
Training loss: 1.4348034858703613
Validation loss: 1.7665172879413893

Epoch: 6| Step: 12
Training loss: 0.5960425138473511
Validation loss: 1.7403831264024139

Epoch: 6| Step: 13
Training loss: 1.2344021797180176
Validation loss: 1.6802773039828065

Epoch: 535| Step: 0
Training loss: 0.7303388714790344
Validation loss: 1.694095975609236

Epoch: 6| Step: 1
Training loss: 0.5728781223297119
Validation loss: 1.7057876599732267

Epoch: 6| Step: 2
Training loss: 1.0103477239608765
Validation loss: 1.7108600319072764

Epoch: 6| Step: 3
Training loss: 0.8432419300079346
Validation loss: 1.69563845152496

Epoch: 6| Step: 4
Training loss: 0.5381964445114136
Validation loss: 1.7312956317778556

Epoch: 6| Step: 5
Training loss: 1.46566641330719
Validation loss: 1.7093894673931984

Epoch: 6| Step: 6
Training loss: 0.7914159297943115
Validation loss: 1.7228615245511454

Epoch: 6| Step: 7
Training loss: 1.0114749670028687
Validation loss: 1.6943414185636787

Epoch: 6| Step: 8
Training loss: 1.0824666023254395
Validation loss: 1.7308011247265724

Epoch: 6| Step: 9
Training loss: 0.8803508281707764
Validation loss: 1.7416752512736986

Epoch: 6| Step: 10
Training loss: 0.9346606135368347
Validation loss: 1.741328062549714

Epoch: 6| Step: 11
Training loss: 0.8772593140602112
Validation loss: 1.7522943686413508

Epoch: 6| Step: 12
Training loss: 0.9787909984588623
Validation loss: 1.7259295871180873

Epoch: 6| Step: 13
Training loss: 0.6168134212493896
Validation loss: 1.7260437383446643

Epoch: 536| Step: 0
Training loss: 0.6873723268508911
Validation loss: 1.699600729891049

Epoch: 6| Step: 1
Training loss: 1.354823350906372
Validation loss: 1.6946920361570132

Epoch: 6| Step: 2
Training loss: 0.9326193332672119
Validation loss: 1.7154236596117738

Epoch: 6| Step: 3
Training loss: 0.517877459526062
Validation loss: 1.6885639211182952

Epoch: 6| Step: 4
Training loss: 0.9977381229400635
Validation loss: 1.710888502418354

Epoch: 6| Step: 5
Training loss: 0.7152385711669922
Validation loss: 1.7027365969073387

Epoch: 6| Step: 6
Training loss: 0.9693173170089722
Validation loss: 1.734172978708821

Epoch: 6| Step: 7
Training loss: 0.6869314908981323
Validation loss: 1.6656893325108353

Epoch: 6| Step: 8
Training loss: 1.1945815086364746
Validation loss: 1.7000546545110724

Epoch: 6| Step: 9
Training loss: 0.7162522673606873
Validation loss: 1.7462980670313681

Epoch: 6| Step: 10
Training loss: 1.2645399570465088
Validation loss: 1.7119280163959791

Epoch: 6| Step: 11
Training loss: 0.506138026714325
Validation loss: 1.7461257801260999

Epoch: 6| Step: 12
Training loss: 0.8183245062828064
Validation loss: 1.7340041911730202

Epoch: 6| Step: 13
Training loss: 0.396098256111145
Validation loss: 1.8220843166433356

Epoch: 537| Step: 0
Training loss: 1.029221773147583
Validation loss: 1.81627090771993

Epoch: 6| Step: 1
Training loss: 0.9380297660827637
Validation loss: 1.7532327700686712

Epoch: 6| Step: 2
Training loss: 1.032283067703247
Validation loss: 1.7540180324226298

Epoch: 6| Step: 3
Training loss: 1.084654450416565
Validation loss: 1.7698961765535417

Epoch: 6| Step: 4
Training loss: 0.9786564111709595
Validation loss: 1.769386661949978

Epoch: 6| Step: 5
Training loss: 0.9754939675331116
Validation loss: 1.7387987823896511

Epoch: 6| Step: 6
Training loss: 1.0102633237838745
Validation loss: 1.777421401393029

Epoch: 6| Step: 7
Training loss: 0.8704323768615723
Validation loss: 1.7279038621533302

Epoch: 6| Step: 8
Training loss: 0.7308883666992188
Validation loss: 1.7632066613884383

Epoch: 6| Step: 9
Training loss: 0.669888973236084
Validation loss: 1.6697782265242709

Epoch: 6| Step: 10
Training loss: 0.5018048286437988
Validation loss: 1.733442360355008

Epoch: 6| Step: 11
Training loss: 0.731595516204834
Validation loss: 1.7210943698883057

Epoch: 6| Step: 12
Training loss: 0.7290855646133423
Validation loss: 1.7214025348745368

Epoch: 6| Step: 13
Training loss: 1.0198040008544922
Validation loss: 1.7106380052463983

Epoch: 538| Step: 0
Training loss: 0.7139809131622314
Validation loss: 1.7222216808667747

Epoch: 6| Step: 1
Training loss: 1.5583622455596924
Validation loss: 1.7285815156916136

Epoch: 6| Step: 2
Training loss: 1.1108436584472656
Validation loss: 1.7074634144383092

Epoch: 6| Step: 3
Training loss: 0.8130508065223694
Validation loss: 1.7854524350935412

Epoch: 6| Step: 4
Training loss: 0.7984607815742493
Validation loss: 1.7686584431638

Epoch: 6| Step: 5
Training loss: 0.8883017897605896
Validation loss: 1.7594510406576178

Epoch: 6| Step: 6
Training loss: 0.7971954345703125
Validation loss: 1.7476699121536747

Epoch: 6| Step: 7
Training loss: 0.9139702320098877
Validation loss: 1.7767263484257523

Epoch: 6| Step: 8
Training loss: 0.5744118690490723
Validation loss: 1.713066352311001

Epoch: 6| Step: 9
Training loss: 0.9644758701324463
Validation loss: 1.7167296255788496

Epoch: 6| Step: 10
Training loss: 1.0041570663452148
Validation loss: 1.702212208060808

Epoch: 6| Step: 11
Training loss: 0.6572984457015991
Validation loss: 1.7531908532624603

Epoch: 6| Step: 12
Training loss: 0.8860230445861816
Validation loss: 1.6719348648543

Epoch: 6| Step: 13
Training loss: 0.7279922962188721
Validation loss: 1.6784660431646532

Epoch: 539| Step: 0
Training loss: 0.5170662999153137
Validation loss: 1.6969055321908766

Epoch: 6| Step: 1
Training loss: 1.1898274421691895
Validation loss: 1.6921047228638844

Epoch: 6| Step: 2
Training loss: 0.8626977801322937
Validation loss: 1.7583866491112659

Epoch: 6| Step: 3
Training loss: 0.727649450302124
Validation loss: 1.6870715861679406

Epoch: 6| Step: 4
Training loss: 0.8774466514587402
Validation loss: 1.7527611704282864

Epoch: 6| Step: 5
Training loss: 0.8715087175369263
Validation loss: 1.7221507346758278

Epoch: 6| Step: 6
Training loss: 1.1817196607589722
Validation loss: 1.7338726161628641

Epoch: 6| Step: 7
Training loss: 0.8119087219238281
Validation loss: 1.7214701329508135

Epoch: 6| Step: 8
Training loss: 0.9571564793586731
Validation loss: 1.7150873407240836

Epoch: 6| Step: 9
Training loss: 0.3990023136138916
Validation loss: 1.7214105218969367

Epoch: 6| Step: 10
Training loss: 0.7285102605819702
Validation loss: 1.777076740418711

Epoch: 6| Step: 11
Training loss: 0.8195698261260986
Validation loss: 1.731223657567014

Epoch: 6| Step: 12
Training loss: 1.2498884201049805
Validation loss: 1.7177552407787693

Epoch: 6| Step: 13
Training loss: 0.9059664607048035
Validation loss: 1.6599545889003302

Epoch: 540| Step: 0
Training loss: 0.7755039930343628
Validation loss: 1.7713386140843874

Epoch: 6| Step: 1
Training loss: 1.6522207260131836
Validation loss: 1.7284904603035218

Epoch: 6| Step: 2
Training loss: 0.6516029834747314
Validation loss: 1.7078408041308004

Epoch: 6| Step: 3
Training loss: 1.0988028049468994
Validation loss: 1.7708326078230334

Epoch: 6| Step: 4
Training loss: 0.6285648345947266
Validation loss: 1.7124328036462106

Epoch: 6| Step: 5
Training loss: 0.7524938583374023
Validation loss: 1.7768714915039718

Epoch: 6| Step: 6
Training loss: 0.9546005129814148
Validation loss: 1.7788212171164892

Epoch: 6| Step: 7
Training loss: 0.8972278833389282
Validation loss: 1.7248265333073114

Epoch: 6| Step: 8
Training loss: 0.6340555548667908
Validation loss: 1.7164101998011272

Epoch: 6| Step: 9
Training loss: 0.47463083267211914
Validation loss: 1.7349605521848124

Epoch: 6| Step: 10
Training loss: 0.9274182319641113
Validation loss: 1.7283540759035336

Epoch: 6| Step: 11
Training loss: 0.7803519368171692
Validation loss: 1.727722482014728

Epoch: 6| Step: 12
Training loss: 1.0367457866668701
Validation loss: 1.7145969278068953

Epoch: 6| Step: 13
Training loss: 0.8736070394515991
Validation loss: 1.7462344784890451

Epoch: 541| Step: 0
Training loss: 1.026271939277649
Validation loss: 1.7083701459310388

Epoch: 6| Step: 1
Training loss: 0.5173354744911194
Validation loss: 1.6810206354305308

Epoch: 6| Step: 2
Training loss: 0.7207531332969666
Validation loss: 1.729254484817546

Epoch: 6| Step: 3
Training loss: 1.3707151412963867
Validation loss: 1.6991913190452002

Epoch: 6| Step: 4
Training loss: 0.5686359405517578
Validation loss: 1.7034511745616954

Epoch: 6| Step: 5
Training loss: 0.6103700995445251
Validation loss: 1.786552821436236

Epoch: 6| Step: 6
Training loss: 0.7430951595306396
Validation loss: 1.764805406652471

Epoch: 6| Step: 7
Training loss: 1.2409478425979614
Validation loss: 1.7355975156189294

Epoch: 6| Step: 8
Training loss: 1.0348293781280518
Validation loss: 1.743035965068366

Epoch: 6| Step: 9
Training loss: 0.8350780010223389
Validation loss: 1.7532476737935057

Epoch: 6| Step: 10
Training loss: 1.210252285003662
Validation loss: 1.71124162661132

Epoch: 6| Step: 11
Training loss: 0.6710496544837952
Validation loss: 1.753090953314176

Epoch: 6| Step: 12
Training loss: 0.6752827167510986
Validation loss: 1.7448241736299248

Epoch: 6| Step: 13
Training loss: 1.1578484773635864
Validation loss: 1.7066906344506048

Epoch: 542| Step: 0
Training loss: 1.602015733718872
Validation loss: 1.79182800169914

Epoch: 6| Step: 1
Training loss: 0.9596875905990601
Validation loss: 1.7200675882318968

Epoch: 6| Step: 2
Training loss: 0.6494902968406677
Validation loss: 1.7320545123469444

Epoch: 6| Step: 3
Training loss: 0.8350812196731567
Validation loss: 1.7525092658176218

Epoch: 6| Step: 4
Training loss: 0.682884693145752
Validation loss: 1.6994899165245794

Epoch: 6| Step: 5
Training loss: 0.7028931975364685
Validation loss: 1.8177803024168937

Epoch: 6| Step: 6
Training loss: 0.8530259728431702
Validation loss: 1.7325084837534095

Epoch: 6| Step: 7
Training loss: 0.6717262268066406
Validation loss: 1.7362578825284076

Epoch: 6| Step: 8
Training loss: 1.009741187095642
Validation loss: 1.7656199342461043

Epoch: 6| Step: 9
Training loss: 0.7583366632461548
Validation loss: 1.7321911704155706

Epoch: 6| Step: 10
Training loss: 0.5494135618209839
Validation loss: 1.6983189787915958

Epoch: 6| Step: 11
Training loss: 0.7724199891090393
Validation loss: 1.7853581892546786

Epoch: 6| Step: 12
Training loss: 1.1615897417068481
Validation loss: 1.6659737466483988

Epoch: 6| Step: 13
Training loss: 1.0820317268371582
Validation loss: 1.6831774839790918

Epoch: 543| Step: 0
Training loss: 0.8849202394485474
Validation loss: 1.68016605864289

Epoch: 6| Step: 1
Training loss: 1.167163372039795
Validation loss: 1.6710561693355601

Epoch: 6| Step: 2
Training loss: 1.255099892616272
Validation loss: 1.6646335432606358

Epoch: 6| Step: 3
Training loss: 0.7721740007400513
Validation loss: 1.6720746114689817

Epoch: 6| Step: 4
Training loss: 0.9165645837783813
Validation loss: 1.7227590237894366

Epoch: 6| Step: 5
Training loss: 0.4486377239227295
Validation loss: 1.677083505097256

Epoch: 6| Step: 6
Training loss: 1.118757963180542
Validation loss: 1.7021448214848836

Epoch: 6| Step: 7
Training loss: 0.8181368112564087
Validation loss: 1.671969380429996

Epoch: 6| Step: 8
Training loss: 1.0481743812561035
Validation loss: 1.7192350593946313

Epoch: 6| Step: 9
Training loss: 0.7863849997520447
Validation loss: 1.682453458027173

Epoch: 6| Step: 10
Training loss: 0.4688280522823334
Validation loss: 1.6890514896761986

Epoch: 6| Step: 11
Training loss: 0.7368597984313965
Validation loss: 1.7223956367020965

Epoch: 6| Step: 12
Training loss: 0.8394031524658203
Validation loss: 1.759109495788492

Epoch: 6| Step: 13
Training loss: 0.5216290354728699
Validation loss: 1.8112840626829414

Epoch: 544| Step: 0
Training loss: 1.1301767826080322
Validation loss: 1.7294634567793978

Epoch: 6| Step: 1
Training loss: 0.5848478078842163
Validation loss: 1.6976861107733943

Epoch: 6| Step: 2
Training loss: 0.6653002500534058
Validation loss: 1.710243409679782

Epoch: 6| Step: 3
Training loss: 0.6067731380462646
Validation loss: 1.6923197251494213

Epoch: 6| Step: 4
Training loss: 1.311586618423462
Validation loss: 1.7829031764820058

Epoch: 6| Step: 5
Training loss: 1.1755144596099854
Validation loss: 1.6541315817063855

Epoch: 6| Step: 6
Training loss: 0.6233097314834595
Validation loss: 1.6743002489048948

Epoch: 6| Step: 7
Training loss: 0.8567858934402466
Validation loss: 1.722420641171035

Epoch: 6| Step: 8
Training loss: 0.9016293287277222
Validation loss: 1.756555623905633

Epoch: 6| Step: 9
Training loss: 0.9874420762062073
Validation loss: 1.7314458290735881

Epoch: 6| Step: 10
Training loss: 1.028531551361084
Validation loss: 1.7165203273937266

Epoch: 6| Step: 11
Training loss: 0.9149996638298035
Validation loss: 1.7265239889903734

Epoch: 6| Step: 12
Training loss: 0.7465963363647461
Validation loss: 1.777309952243682

Epoch: 6| Step: 13
Training loss: 0.46987664699554443
Validation loss: 1.758324279580065

Epoch: 545| Step: 0
Training loss: 0.7444567680358887
Validation loss: 1.7389146820191415

Epoch: 6| Step: 1
Training loss: 1.0796496868133545
Validation loss: 1.8003706650067401

Epoch: 6| Step: 2
Training loss: 0.8134051561355591
Validation loss: 1.8142346182177145

Epoch: 6| Step: 3
Training loss: 1.5496803522109985
Validation loss: 1.8098741513426586

Epoch: 6| Step: 4
Training loss: 0.600954532623291
Validation loss: 1.758152400293658

Epoch: 6| Step: 5
Training loss: 0.5183426141738892
Validation loss: 1.849913445852136

Epoch: 6| Step: 6
Training loss: 0.6748107075691223
Validation loss: 1.7612793458405362

Epoch: 6| Step: 7
Training loss: 0.9998083114624023
Validation loss: 1.7492061161225843

Epoch: 6| Step: 8
Training loss: 1.3368604183197021
Validation loss: 1.762488627946505

Epoch: 6| Step: 9
Training loss: 0.8526496887207031
Validation loss: 1.7816537669909898

Epoch: 6| Step: 10
Training loss: 0.5756580829620361
Validation loss: 1.7562725774703487

Epoch: 6| Step: 11
Training loss: 1.0404410362243652
Validation loss: 1.717525259140999

Epoch: 6| Step: 12
Training loss: 0.38757577538490295
Validation loss: 1.638643621116556

Epoch: 6| Step: 13
Training loss: 0.37206941843032837
Validation loss: 1.7862167627580705

Epoch: 546| Step: 0
Training loss: 0.849139928817749
Validation loss: 1.7308728182187645

Epoch: 6| Step: 1
Training loss: 0.6113380789756775
Validation loss: 1.8061520361131238

Epoch: 6| Step: 2
Training loss: 0.6261830925941467
Validation loss: 1.7526740463831092

Epoch: 6| Step: 3
Training loss: 0.7329938411712646
Validation loss: 1.7324348700943815

Epoch: 6| Step: 4
Training loss: 0.8754251599311829
Validation loss: 1.8053906015170518

Epoch: 6| Step: 5
Training loss: 1.7228275537490845
Validation loss: 1.802217545047883

Epoch: 6| Step: 6
Training loss: 1.0095336437225342
Validation loss: 1.7336214409079602

Epoch: 6| Step: 7
Training loss: 0.9434572458267212
Validation loss: 1.6916862098119592

Epoch: 6| Step: 8
Training loss: 1.0433096885681152
Validation loss: 1.7220823969892276

Epoch: 6| Step: 9
Training loss: 0.3439945876598358
Validation loss: 1.7344769854699411

Epoch: 6| Step: 10
Training loss: 0.5601054430007935
Validation loss: 1.6883196946113341

Epoch: 6| Step: 11
Training loss: 0.8760812282562256
Validation loss: 1.704157652393464

Epoch: 6| Step: 12
Training loss: 0.8440203666687012
Validation loss: 1.7192515955176404

Epoch: 6| Step: 13
Training loss: 1.6621425151824951
Validation loss: 1.7443237458505938

Epoch: 547| Step: 0
Training loss: 0.9400906562805176
Validation loss: 1.718365643614082

Epoch: 6| Step: 1
Training loss: 0.8528162837028503
Validation loss: 1.7463729650743547

Epoch: 6| Step: 2
Training loss: 0.6100009679794312
Validation loss: 1.7109341506035096

Epoch: 6| Step: 3
Training loss: 0.4313545525074005
Validation loss: 1.6861719867234588

Epoch: 6| Step: 4
Training loss: 1.0483826398849487
Validation loss: 1.7829496873322355

Epoch: 6| Step: 5
Training loss: 0.9282283782958984
Validation loss: 1.7293058902986589

Epoch: 6| Step: 6
Training loss: 0.6666660308837891
Validation loss: 1.6829130175293132

Epoch: 6| Step: 7
Training loss: 0.80359947681427
Validation loss: 1.6918044602999123

Epoch: 6| Step: 8
Training loss: 0.8565045595169067
Validation loss: 1.768405036259723

Epoch: 6| Step: 9
Training loss: 0.9962966442108154
Validation loss: 1.717976749584239

Epoch: 6| Step: 10
Training loss: 0.8249619603157043
Validation loss: 1.756856946535008

Epoch: 6| Step: 11
Training loss: 0.972192645072937
Validation loss: 1.7340553806674095

Epoch: 6| Step: 12
Training loss: 1.2282536029815674
Validation loss: 1.8029693403551657

Epoch: 6| Step: 13
Training loss: 0.4270285964012146
Validation loss: 1.8102059351500643

Epoch: 548| Step: 0
Training loss: 1.036320447921753
Validation loss: 1.7655779033578851

Epoch: 6| Step: 1
Training loss: 0.7979333400726318
Validation loss: 1.8122688544693815

Epoch: 6| Step: 2
Training loss: 1.0016441345214844
Validation loss: 1.8457285088877524

Epoch: 6| Step: 3
Training loss: 1.4084925651550293
Validation loss: 1.8095071649038663

Epoch: 6| Step: 4
Training loss: 0.5746846199035645
Validation loss: 1.8948636747175647

Epoch: 6| Step: 5
Training loss: 0.9576127529144287
Validation loss: 1.8009734897203342

Epoch: 6| Step: 6
Training loss: 0.6971875429153442
Validation loss: 1.757159661221248

Epoch: 6| Step: 7
Training loss: 0.6338856220245361
Validation loss: 1.8361238356559508

Epoch: 6| Step: 8
Training loss: 0.7586846351623535
Validation loss: 1.8018325413427045

Epoch: 6| Step: 9
Training loss: 0.9965623617172241
Validation loss: 1.7538215857680126

Epoch: 6| Step: 10
Training loss: 0.6309221386909485
Validation loss: 1.7335227189525482

Epoch: 6| Step: 11
Training loss: 0.9963488578796387
Validation loss: 1.7162839892090007

Epoch: 6| Step: 12
Training loss: 0.7263579368591309
Validation loss: 1.7533048788706462

Epoch: 6| Step: 13
Training loss: 1.6238949298858643
Validation loss: 1.7766143186118013

Epoch: 549| Step: 0
Training loss: 0.8558790683746338
Validation loss: 1.6904434632229548

Epoch: 6| Step: 1
Training loss: 1.1832616329193115
Validation loss: 1.724507898412725

Epoch: 6| Step: 2
Training loss: 1.1233668327331543
Validation loss: 1.7447463504729732

Epoch: 6| Step: 3
Training loss: 0.8489407300949097
Validation loss: 1.6656709230074318

Epoch: 6| Step: 4
Training loss: 1.0044209957122803
Validation loss: 1.7170012535587433

Epoch: 6| Step: 5
Training loss: 0.8495599627494812
Validation loss: 1.738639304714818

Epoch: 6| Step: 6
Training loss: 0.5003153681755066
Validation loss: 1.796247834800392

Epoch: 6| Step: 7
Training loss: 0.5326897501945496
Validation loss: 1.7664626849594938

Epoch: 6| Step: 8
Training loss: 0.8247302770614624
Validation loss: 1.7230896308857908

Epoch: 6| Step: 9
Training loss: 0.717725396156311
Validation loss: 1.7561283957573675

Epoch: 6| Step: 10
Training loss: 0.7067779302597046
Validation loss: 1.7359429431217972

Epoch: 6| Step: 11
Training loss: 1.1876440048217773
Validation loss: 1.693460928496494

Epoch: 6| Step: 12
Training loss: 1.0449053049087524
Validation loss: 1.739236249718615

Epoch: 6| Step: 13
Training loss: 0.5297604203224182
Validation loss: 1.7159752102308377

Epoch: 550| Step: 0
Training loss: 0.5749503970146179
Validation loss: 1.7167773874857093

Epoch: 6| Step: 1
Training loss: 0.46826446056365967
Validation loss: 1.675883307251879

Epoch: 6| Step: 2
Training loss: 0.9635987281799316
Validation loss: 1.6967210013379332

Epoch: 6| Step: 3
Training loss: 0.9398751258850098
Validation loss: 1.7388824057835404

Epoch: 6| Step: 4
Training loss: 0.683394730091095
Validation loss: 1.7397108129275742

Epoch: 6| Step: 5
Training loss: 0.6465662717819214
Validation loss: 1.7709923533983127

Epoch: 6| Step: 6
Training loss: 0.607090175151825
Validation loss: 1.7016828495969054

Epoch: 6| Step: 7
Training loss: 0.7269784212112427
Validation loss: 1.7585492569913146

Epoch: 6| Step: 8
Training loss: 1.28831946849823
Validation loss: 1.7373843013599355

Epoch: 6| Step: 9
Training loss: 0.6909456253051758
Validation loss: 1.702285014173036

Epoch: 6| Step: 10
Training loss: 1.5355305671691895
Validation loss: 1.7289504402427263

Epoch: 6| Step: 11
Training loss: 1.0907047986984253
Validation loss: 1.7970968138787053

Epoch: 6| Step: 12
Training loss: 0.7651225328445435
Validation loss: 1.7312129300127748

Epoch: 6| Step: 13
Training loss: 0.6760991215705872
Validation loss: 1.7578973462504726

Epoch: 551| Step: 0
Training loss: 0.5555726289749146
Validation loss: 1.783429257331356

Epoch: 6| Step: 1
Training loss: 0.7683112621307373
Validation loss: 1.7464891659316195

Epoch: 6| Step: 2
Training loss: 0.5585182309150696
Validation loss: 1.7687346730180966

Epoch: 6| Step: 3
Training loss: 0.8026966452598572
Validation loss: 1.7406712129551878

Epoch: 6| Step: 4
Training loss: 0.6402614712715149
Validation loss: 1.7370665483577277

Epoch: 6| Step: 5
Training loss: 0.5445795059204102
Validation loss: 1.747378058330987

Epoch: 6| Step: 6
Training loss: 1.3115036487579346
Validation loss: 1.737275932424812

Epoch: 6| Step: 7
Training loss: 0.6077671051025391
Validation loss: 1.7300611042207288

Epoch: 6| Step: 8
Training loss: 1.2790024280548096
Validation loss: 1.7302194218481741

Epoch: 6| Step: 9
Training loss: 0.6448129415512085
Validation loss: 1.7614767500149306

Epoch: 6| Step: 10
Training loss: 1.7224395275115967
Validation loss: 1.7471386085274399

Epoch: 6| Step: 11
Training loss: 0.973759114742279
Validation loss: 1.7161574081708026

Epoch: 6| Step: 12
Training loss: 0.6855001449584961
Validation loss: 1.7025232417609102

Epoch: 6| Step: 13
Training loss: 0.507124125957489
Validation loss: 1.7129251905666885

Epoch: 552| Step: 0
Training loss: 0.7864490747451782
Validation loss: 1.7318126527211999

Epoch: 6| Step: 1
Training loss: 0.917323648929596
Validation loss: 1.7171846589734476

Epoch: 6| Step: 2
Training loss: 0.7085277438163757
Validation loss: 1.715195890395872

Epoch: 6| Step: 3
Training loss: 0.738887369632721
Validation loss: 1.7265736979822959

Epoch: 6| Step: 4
Training loss: 0.8728412985801697
Validation loss: 1.7452299235969462

Epoch: 6| Step: 5
Training loss: 0.5146396160125732
Validation loss: 1.772518596341533

Epoch: 6| Step: 6
Training loss: 1.1456024646759033
Validation loss: 1.7379274342649726

Epoch: 6| Step: 7
Training loss: 1.0496978759765625
Validation loss: 1.7221120621568413

Epoch: 6| Step: 8
Training loss: 0.7038541436195374
Validation loss: 1.7344651068410566

Epoch: 6| Step: 9
Training loss: 0.688414454460144
Validation loss: 1.7115053925462949

Epoch: 6| Step: 10
Training loss: 0.8623653054237366
Validation loss: 1.7026885171090402

Epoch: 6| Step: 11
Training loss: 0.9460265636444092
Validation loss: 1.7443797947258077

Epoch: 6| Step: 12
Training loss: 1.5329357385635376
Validation loss: 1.6914154944881317

Epoch: 6| Step: 13
Training loss: 0.5817989706993103
Validation loss: 1.6957326166091427

Epoch: 553| Step: 0
Training loss: 0.5704101324081421
Validation loss: 1.6798902057832288

Epoch: 6| Step: 1
Training loss: 0.9813528060913086
Validation loss: 1.6922426390391525

Epoch: 6| Step: 2
Training loss: 0.8627413511276245
Validation loss: 1.6751457401501235

Epoch: 6| Step: 3
Training loss: 0.3585239052772522
Validation loss: 1.7107218209133352

Epoch: 6| Step: 4
Training loss: 0.9408261775970459
Validation loss: 1.6669048981000019

Epoch: 6| Step: 5
Training loss: 1.1257977485656738
Validation loss: 1.7246023480610182

Epoch: 6| Step: 6
Training loss: 0.8353937864303589
Validation loss: 1.7435447105797388

Epoch: 6| Step: 7
Training loss: 1.0021214485168457
Validation loss: 1.6978184990985419

Epoch: 6| Step: 8
Training loss: 0.7695037126541138
Validation loss: 1.6926907518858552

Epoch: 6| Step: 9
Training loss: 0.8287897109985352
Validation loss: 1.713318932440973

Epoch: 6| Step: 10
Training loss: 0.7798000574111938
Validation loss: 1.7385206594262073

Epoch: 6| Step: 11
Training loss: 0.894934892654419
Validation loss: 1.7393438610979306

Epoch: 6| Step: 12
Training loss: 1.2703394889831543
Validation loss: 1.6945458342952113

Epoch: 6| Step: 13
Training loss: 0.4915383756160736
Validation loss: 1.6635789409760506

Epoch: 554| Step: 0
Training loss: 0.9228991270065308
Validation loss: 1.7404890111697617

Epoch: 6| Step: 1
Training loss: 0.6434807777404785
Validation loss: 1.6695028094835178

Epoch: 6| Step: 2
Training loss: 0.6400615572929382
Validation loss: 1.671816566938995

Epoch: 6| Step: 3
Training loss: 0.9503529667854309
Validation loss: 1.7177919341671852

Epoch: 6| Step: 4
Training loss: 1.091931700706482
Validation loss: 1.734005610148112

Epoch: 6| Step: 5
Training loss: 0.7886736989021301
Validation loss: 1.6455475489298503

Epoch: 6| Step: 6
Training loss: 0.8969688415527344
Validation loss: 1.7306072545307938

Epoch: 6| Step: 7
Training loss: 0.657224178314209
Validation loss: 1.638347831464583

Epoch: 6| Step: 8
Training loss: 0.8180055022239685
Validation loss: 1.6812741538529754

Epoch: 6| Step: 9
Training loss: 0.5856978297233582
Validation loss: 1.6780004116796678

Epoch: 6| Step: 10
Training loss: 1.4785127639770508
Validation loss: 1.7253350006636752

Epoch: 6| Step: 11
Training loss: 0.7099003791809082
Validation loss: 1.7214424712683565

Epoch: 6| Step: 12
Training loss: 0.961672306060791
Validation loss: 1.7262108889959191

Epoch: 6| Step: 13
Training loss: 0.9897406697273254
Validation loss: 1.7045762308182255

Epoch: 555| Step: 0
Training loss: 1.284513235092163
Validation loss: 1.7231795954447922

Epoch: 6| Step: 1
Training loss: 0.42549240589141846
Validation loss: 1.6757393229392268

Epoch: 6| Step: 2
Training loss: 0.7258689403533936
Validation loss: 1.714228662111426

Epoch: 6| Step: 3
Training loss: 0.4798332154750824
Validation loss: 1.7672088479483

Epoch: 6| Step: 4
Training loss: 0.8863717913627625
Validation loss: 1.7160505107654038

Epoch: 6| Step: 5
Training loss: 0.689897358417511
Validation loss: 1.6748691015346076

Epoch: 6| Step: 6
Training loss: 0.8977240324020386
Validation loss: 1.7641066902427263

Epoch: 6| Step: 7
Training loss: 0.6653960943222046
Validation loss: 1.7028491779040265

Epoch: 6| Step: 8
Training loss: 0.9060099124908447
Validation loss: 1.7727210880607687

Epoch: 6| Step: 9
Training loss: 1.3078454732894897
Validation loss: 1.7346491300931541

Epoch: 6| Step: 10
Training loss: 1.0512244701385498
Validation loss: 1.6957298645409205

Epoch: 6| Step: 11
Training loss: 1.1627227067947388
Validation loss: 1.723277917472265

Epoch: 6| Step: 12
Training loss: 0.5768990516662598
Validation loss: 1.7291467010333974

Epoch: 6| Step: 13
Training loss: 0.7324509024620056
Validation loss: 1.7116625693536573

Epoch: 556| Step: 0
Training loss: 0.6887302398681641
Validation loss: 1.7447677043176466

Epoch: 6| Step: 1
Training loss: 1.3573484420776367
Validation loss: 1.691054053204034

Epoch: 6| Step: 2
Training loss: 0.9642235040664673
Validation loss: 1.6835891123740905

Epoch: 6| Step: 3
Training loss: 1.1677510738372803
Validation loss: 1.7485587571256904

Epoch: 6| Step: 4
Training loss: 1.1707310676574707
Validation loss: 1.6928433666947067

Epoch: 6| Step: 5
Training loss: 1.0981062650680542
Validation loss: 1.6663855339891167

Epoch: 6| Step: 6
Training loss: 0.4483732581138611
Validation loss: 1.7296778925003544

Epoch: 6| Step: 7
Training loss: 0.5684711933135986
Validation loss: 1.741416374842326

Epoch: 6| Step: 8
Training loss: 0.43237096071243286
Validation loss: 1.6869507194847189

Epoch: 6| Step: 9
Training loss: 0.4941661059856415
Validation loss: 1.7181068825465378

Epoch: 6| Step: 10
Training loss: 0.6688275933265686
Validation loss: 1.7342183269480222

Epoch: 6| Step: 11
Training loss: 0.6439595222473145
Validation loss: 1.7061841898067023

Epoch: 6| Step: 12
Training loss: 0.6905632019042969
Validation loss: 1.721210361808859

Epoch: 6| Step: 13
Training loss: 1.3738348484039307
Validation loss: 1.7073657346028153

Epoch: 557| Step: 0
Training loss: 0.5836730003356934
Validation loss: 1.7790911595026653

Epoch: 6| Step: 1
Training loss: 0.743389368057251
Validation loss: 1.7130114134921823

Epoch: 6| Step: 2
Training loss: 0.7465189099311829
Validation loss: 1.6975645301162556

Epoch: 6| Step: 3
Training loss: 1.0665557384490967
Validation loss: 1.7364165001018073

Epoch: 6| Step: 4
Training loss: 1.0194354057312012
Validation loss: 1.6981797115777129

Epoch: 6| Step: 5
Training loss: 1.0595455169677734
Validation loss: 1.7345587361243464

Epoch: 6| Step: 6
Training loss: 0.6449729204177856
Validation loss: 1.7373422666262555

Epoch: 6| Step: 7
Training loss: 1.162376880645752
Validation loss: 1.6501302257660897

Epoch: 6| Step: 8
Training loss: 0.749567985534668
Validation loss: 1.7098013047249085

Epoch: 6| Step: 9
Training loss: 0.7545331120491028
Validation loss: 1.685456306703629

Epoch: 6| Step: 10
Training loss: 0.4603697955608368
Validation loss: 1.6916861508482246

Epoch: 6| Step: 11
Training loss: 1.0647679567337036
Validation loss: 1.7134444559774091

Epoch: 6| Step: 12
Training loss: 0.2912624478340149
Validation loss: 1.68600586921938

Epoch: 6| Step: 13
Training loss: 1.6808422803878784
Validation loss: 1.6684362593517508

Epoch: 558| Step: 0
Training loss: 0.8285053968429565
Validation loss: 1.7760801071761756

Epoch: 6| Step: 1
Training loss: 0.8008882999420166
Validation loss: 1.7145101767714306

Epoch: 6| Step: 2
Training loss: 0.8630285859107971
Validation loss: 1.7267112142296248

Epoch: 6| Step: 3
Training loss: 0.5253305435180664
Validation loss: 1.721991119846221

Epoch: 6| Step: 4
Training loss: 1.1300817728042603
Validation loss: 1.7539005612814298

Epoch: 6| Step: 5
Training loss: 0.8244633078575134
Validation loss: 1.7088233424771218

Epoch: 6| Step: 6
Training loss: 0.8837535381317139
Validation loss: 1.793595629353677

Epoch: 6| Step: 7
Training loss: 0.8635555505752563
Validation loss: 1.752423991439163

Epoch: 6| Step: 8
Training loss: 0.9803165793418884
Validation loss: 1.721505735510139

Epoch: 6| Step: 9
Training loss: 0.8339232206344604
Validation loss: 1.7329552391523957

Epoch: 6| Step: 10
Training loss: 0.5174894332885742
Validation loss: 1.6778858810342767

Epoch: 6| Step: 11
Training loss: 0.8109327554702759
Validation loss: 1.6683273558975549

Epoch: 6| Step: 12
Training loss: 1.0264374017715454
Validation loss: 1.7228474706731818

Epoch: 6| Step: 13
Training loss: 1.066108226776123
Validation loss: 1.7222428834566506

Epoch: 559| Step: 0
Training loss: 0.4750008285045624
Validation loss: 1.7461066758760841

Epoch: 6| Step: 1
Training loss: 0.9939838647842407
Validation loss: 1.7131335709684639

Epoch: 6| Step: 2
Training loss: 0.7630895376205444
Validation loss: 1.736774993199174

Epoch: 6| Step: 3
Training loss: 0.658332347869873
Validation loss: 1.7255539048102595

Epoch: 6| Step: 4
Training loss: 0.7285717725753784
Validation loss: 1.6753484215787662

Epoch: 6| Step: 5
Training loss: 0.5273193120956421
Validation loss: 1.7342275611815914

Epoch: 6| Step: 6
Training loss: 0.7954410314559937
Validation loss: 1.703030732370192

Epoch: 6| Step: 7
Training loss: 0.6043668389320374
Validation loss: 1.776249502294807

Epoch: 6| Step: 8
Training loss: 0.4025011658668518
Validation loss: 1.7314623337919994

Epoch: 6| Step: 9
Training loss: 0.7901812195777893
Validation loss: 1.8046580142872308

Epoch: 6| Step: 10
Training loss: 1.1999489068984985
Validation loss: 1.7616626793338406

Epoch: 6| Step: 11
Training loss: 0.9198077917098999
Validation loss: 1.732227692040064

Epoch: 6| Step: 12
Training loss: 1.7017675638198853
Validation loss: 1.7381025488658617

Epoch: 6| Step: 13
Training loss: 1.1498818397521973
Validation loss: 1.7484525813851306

Epoch: 560| Step: 0
Training loss: 0.6164095997810364
Validation loss: 1.7636691870227936

Epoch: 6| Step: 1
Training loss: 0.8570874333381653
Validation loss: 1.7570665485115462

Epoch: 6| Step: 2
Training loss: 0.8445552587509155
Validation loss: 1.6682522873724661

Epoch: 6| Step: 3
Training loss: 0.9047039747238159
Validation loss: 1.7367082885516587

Epoch: 6| Step: 4
Training loss: 0.8466227054595947
Validation loss: 1.694017885833658

Epoch: 6| Step: 5
Training loss: 0.9076957106590271
Validation loss: 1.70084386615343

Epoch: 6| Step: 6
Training loss: 0.8524696230888367
Validation loss: 1.722171014355075

Epoch: 6| Step: 7
Training loss: 0.851107120513916
Validation loss: 1.6787597876723095

Epoch: 6| Step: 8
Training loss: 0.4583735764026642
Validation loss: 1.7232229273806337

Epoch: 6| Step: 9
Training loss: 0.8059403896331787
Validation loss: 1.7803245257305842

Epoch: 6| Step: 10
Training loss: 0.9284204840660095
Validation loss: 1.692244170814432

Epoch: 6| Step: 11
Training loss: 0.6042097806930542
Validation loss: 1.7589742150357974

Epoch: 6| Step: 12
Training loss: 0.6305292844772339
Validation loss: 1.7879380154353317

Epoch: 6| Step: 13
Training loss: 2.0859899520874023
Validation loss: 1.7277225243147982

Epoch: 561| Step: 0
Training loss: 0.6790269613265991
Validation loss: 1.7241912708487561

Epoch: 6| Step: 1
Training loss: 1.2006734609603882
Validation loss: 1.7092128453716156

Epoch: 6| Step: 2
Training loss: 0.8834550380706787
Validation loss: 1.7404049692615386

Epoch: 6| Step: 3
Training loss: 1.144266128540039
Validation loss: 1.7400228438838836

Epoch: 6| Step: 4
Training loss: 0.7158318161964417
Validation loss: 1.7229388119072042

Epoch: 6| Step: 5
Training loss: 0.9348832368850708
Validation loss: 1.7434980318110476

Epoch: 6| Step: 6
Training loss: 0.5037478804588318
Validation loss: 1.6797176894321237

Epoch: 6| Step: 7
Training loss: 0.6753622889518738
Validation loss: 1.7307600423853884

Epoch: 6| Step: 8
Training loss: 0.5101466774940491
Validation loss: 1.7114086561305548

Epoch: 6| Step: 9
Training loss: 0.853081464767456
Validation loss: 1.713353346752864

Epoch: 6| Step: 10
Training loss: 0.7694332599639893
Validation loss: 1.6688702619203957

Epoch: 6| Step: 11
Training loss: 0.7207409143447876
Validation loss: 1.6964956457896898

Epoch: 6| Step: 12
Training loss: 1.2830637693405151
Validation loss: 1.6663646480088592

Epoch: 6| Step: 13
Training loss: 0.7582290768623352
Validation loss: 1.7170560795773742

Epoch: 562| Step: 0
Training loss: 0.8418291211128235
Validation loss: 1.689906999629031

Epoch: 6| Step: 1
Training loss: 0.5149590969085693
Validation loss: 1.7038568745377243

Epoch: 6| Step: 2
Training loss: 0.6239098906517029
Validation loss: 1.7139526618424283

Epoch: 6| Step: 3
Training loss: 0.8042488694190979
Validation loss: 1.7053512680915095

Epoch: 6| Step: 4
Training loss: 0.5862277746200562
Validation loss: 1.706353251652051

Epoch: 6| Step: 5
Training loss: 0.8721238970756531
Validation loss: 1.7456087245736072

Epoch: 6| Step: 6
Training loss: 0.7566317319869995
Validation loss: 1.6968732392916115

Epoch: 6| Step: 7
Training loss: 0.5090148448944092
Validation loss: 1.7259270414229362

Epoch: 6| Step: 8
Training loss: 0.7789273262023926
Validation loss: 1.7245360625687467

Epoch: 6| Step: 9
Training loss: 0.681142270565033
Validation loss: 1.7191772909574612

Epoch: 6| Step: 10
Training loss: 0.9881234169006348
Validation loss: 1.7720734816725536

Epoch: 6| Step: 11
Training loss: 1.7290788888931274
Validation loss: 1.7402942257542764

Epoch: 6| Step: 12
Training loss: 1.104567289352417
Validation loss: 1.7345330971543507

Epoch: 6| Step: 13
Training loss: 0.8866594433784485
Validation loss: 1.6870745664001794

Epoch: 563| Step: 0
Training loss: 0.8320118188858032
Validation loss: 1.6801969902489775

Epoch: 6| Step: 1
Training loss: 0.8592699766159058
Validation loss: 1.7100251579797396

Epoch: 6| Step: 2
Training loss: 0.4783894419670105
Validation loss: 1.7094069232222855

Epoch: 6| Step: 3
Training loss: 1.0482367277145386
Validation loss: 1.746062022383495

Epoch: 6| Step: 4
Training loss: 0.4767262637615204
Validation loss: 1.7352872010200255

Epoch: 6| Step: 5
Training loss: 0.7353180646896362
Validation loss: 1.7396189833200106

Epoch: 6| Step: 6
Training loss: 0.9136013388633728
Validation loss: 1.7492843674075218

Epoch: 6| Step: 7
Training loss: 0.778882622718811
Validation loss: 1.686565569652024

Epoch: 6| Step: 8
Training loss: 1.1260067224502563
Validation loss: 1.691259552073735

Epoch: 6| Step: 9
Training loss: 0.5495811700820923
Validation loss: 1.714713869556304

Epoch: 6| Step: 10
Training loss: 1.5888185501098633
Validation loss: 1.7228434470392042

Epoch: 6| Step: 11
Training loss: 0.6923410296440125
Validation loss: 1.7131922937208606

Epoch: 6| Step: 12
Training loss: 0.29181328415870667
Validation loss: 1.7403254406426543

Epoch: 6| Step: 13
Training loss: 0.6631232500076294
Validation loss: 1.7129240600011681

Epoch: 564| Step: 0
Training loss: 0.872531533241272
Validation loss: 1.713516814734346

Epoch: 6| Step: 1
Training loss: 1.1588435173034668
Validation loss: 1.6959281275349278

Epoch: 6| Step: 2
Training loss: 0.9469546675682068
Validation loss: 1.712860757304776

Epoch: 6| Step: 3
Training loss: 0.5291553735733032
Validation loss: 1.6809280944126908

Epoch: 6| Step: 4
Training loss: 0.6749998927116394
Validation loss: 1.7048134201316423

Epoch: 6| Step: 5
Training loss: 0.6267516613006592
Validation loss: 1.7239863308527137

Epoch: 6| Step: 6
Training loss: 0.5946746468544006
Validation loss: 1.6749801007650231

Epoch: 6| Step: 7
Training loss: 0.5255332589149475
Validation loss: 1.7537888903771677

Epoch: 6| Step: 8
Training loss: 0.9105285406112671
Validation loss: 1.7549737012514504

Epoch: 6| Step: 9
Training loss: 0.8311077952384949
Validation loss: 1.7198602537955008

Epoch: 6| Step: 10
Training loss: 0.6264564394950867
Validation loss: 1.7386939320512997

Epoch: 6| Step: 11
Training loss: 1.1541072130203247
Validation loss: 1.7451665542458976

Epoch: 6| Step: 12
Training loss: 1.3955777883529663
Validation loss: 1.787384929195527

Epoch: 6| Step: 13
Training loss: 0.93804931640625
Validation loss: 1.7709020953024588

Epoch: 565| Step: 0
Training loss: 0.7229340076446533
Validation loss: 1.7413649437248067

Epoch: 6| Step: 1
Training loss: 0.9848384261131287
Validation loss: 1.7168300459461827

Epoch: 6| Step: 2
Training loss: 0.5703086853027344
Validation loss: 1.7233522758688977

Epoch: 6| Step: 3
Training loss: 0.878515362739563
Validation loss: 1.6840035261646393

Epoch: 6| Step: 4
Training loss: 1.0950056314468384
Validation loss: 1.6395915721052436

Epoch: 6| Step: 5
Training loss: 0.6143958568572998
Validation loss: 1.686062248804236

Epoch: 6| Step: 6
Training loss: 1.0080727338790894
Validation loss: 1.7212888245941491

Epoch: 6| Step: 7
Training loss: 0.7923499941825867
Validation loss: 1.7226518200289818

Epoch: 6| Step: 8
Training loss: 1.177106499671936
Validation loss: 1.7010986747280243

Epoch: 6| Step: 9
Training loss: 1.4185078144073486
Validation loss: 1.7255926221929572

Epoch: 6| Step: 10
Training loss: 0.4930380582809448
Validation loss: 1.7120517005202591

Epoch: 6| Step: 11
Training loss: 0.6433383226394653
Validation loss: 1.6581505883124568

Epoch: 6| Step: 12
Training loss: 0.398457795381546
Validation loss: 1.6772723018482167

Epoch: 6| Step: 13
Training loss: 0.7529497146606445
Validation loss: 1.7515889008839924

Epoch: 566| Step: 0
Training loss: 0.7143654823303223
Validation loss: 1.6863265934810843

Epoch: 6| Step: 1
Training loss: 0.4898277819156647
Validation loss: 1.7020579589310514

Epoch: 6| Step: 2
Training loss: 0.7556468844413757
Validation loss: 1.6944508257732596

Epoch: 6| Step: 3
Training loss: 0.8411810398101807
Validation loss: 1.757953473316726

Epoch: 6| Step: 4
Training loss: 1.1699814796447754
Validation loss: 1.7000416658257926

Epoch: 6| Step: 5
Training loss: 0.872182309627533
Validation loss: 1.7102979806161696

Epoch: 6| Step: 6
Training loss: 0.7830240726470947
Validation loss: 1.702827666395454

Epoch: 6| Step: 7
Training loss: 0.7908213138580322
Validation loss: 1.7363244077210784

Epoch: 6| Step: 8
Training loss: 0.4874045252799988
Validation loss: 1.6889970892219133

Epoch: 6| Step: 9
Training loss: 1.3333799839019775
Validation loss: 1.7100281741029473

Epoch: 6| Step: 10
Training loss: 0.46919625997543335
Validation loss: 1.768890142440796

Epoch: 6| Step: 11
Training loss: 0.7360371947288513
Validation loss: 1.7139389027831375

Epoch: 6| Step: 12
Training loss: 1.4044270515441895
Validation loss: 1.6976822832579255

Epoch: 6| Step: 13
Training loss: 1.50345778465271
Validation loss: 1.7898005413752731

Epoch: 567| Step: 0
Training loss: 0.8849849700927734
Validation loss: 1.7179723337132444

Epoch: 6| Step: 1
Training loss: 0.9732925295829773
Validation loss: 1.6771170170076433

Epoch: 6| Step: 2
Training loss: 1.2928104400634766
Validation loss: 1.7466200218405774

Epoch: 6| Step: 3
Training loss: 0.5914440155029297
Validation loss: 1.7101530695474276

Epoch: 6| Step: 4
Training loss: 0.7450534105300903
Validation loss: 1.6818505025679065

Epoch: 6| Step: 5
Training loss: 1.3806782960891724
Validation loss: 1.6672772476750035

Epoch: 6| Step: 6
Training loss: 0.6329644918441772
Validation loss: 1.7179010939854447

Epoch: 6| Step: 7
Training loss: 0.8826603889465332
Validation loss: 1.6938290583190097

Epoch: 6| Step: 8
Training loss: 0.7323700785636902
Validation loss: 1.6602746184154222

Epoch: 6| Step: 9
Training loss: 0.34722185134887695
Validation loss: 1.6932578484217327

Epoch: 6| Step: 10
Training loss: 0.7660925388336182
Validation loss: 1.6953404257374425

Epoch: 6| Step: 11
Training loss: 0.8186829090118408
Validation loss: 1.6837197029462425

Epoch: 6| Step: 12
Training loss: 1.2014461755752563
Validation loss: 1.704875498689631

Epoch: 6| Step: 13
Training loss: 0.20893457531929016
Validation loss: 1.7413679694616666

Epoch: 568| Step: 0
Training loss: 0.44704216718673706
Validation loss: 1.730416372258176

Epoch: 6| Step: 1
Training loss: 0.9172353744506836
Validation loss: 1.7144407303102556

Epoch: 6| Step: 2
Training loss: 1.100956678390503
Validation loss: 1.706091824398246

Epoch: 6| Step: 3
Training loss: 0.5315038561820984
Validation loss: 1.7044626923017605

Epoch: 6| Step: 4
Training loss: 0.8879047632217407
Validation loss: 1.7157427598071355

Epoch: 6| Step: 5
Training loss: 0.7998752593994141
Validation loss: 1.7191773819667038

Epoch: 6| Step: 6
Training loss: 0.9846310615539551
Validation loss: 1.7022924794945666

Epoch: 6| Step: 7
Training loss: 0.6285735368728638
Validation loss: 1.6769528324886034

Epoch: 6| Step: 8
Training loss: 0.763573408126831
Validation loss: 1.708608461964515

Epoch: 6| Step: 9
Training loss: 1.1298158168792725
Validation loss: 1.7044640548767582

Epoch: 6| Step: 10
Training loss: 0.9763298034667969
Validation loss: 1.6888085783168834

Epoch: 6| Step: 11
Training loss: 0.7609307765960693
Validation loss: 1.6944140375301402

Epoch: 6| Step: 12
Training loss: 0.7061375379562378
Validation loss: 1.6856804124770626

Epoch: 6| Step: 13
Training loss: 0.6074878573417664
Validation loss: 1.6754471563523816

Epoch: 569| Step: 0
Training loss: 0.9407229423522949
Validation loss: 1.7058868254384687

Epoch: 6| Step: 1
Training loss: 1.0699636936187744
Validation loss: 1.6968602127926324

Epoch: 6| Step: 2
Training loss: 0.6987802982330322
Validation loss: 1.6350250000594764

Epoch: 6| Step: 3
Training loss: 1.0450143814086914
Validation loss: 1.6998499189653704

Epoch: 6| Step: 4
Training loss: 0.4380470812320709
Validation loss: 1.70146914387262

Epoch: 6| Step: 5
Training loss: 0.4335702657699585
Validation loss: 1.6759106651429208

Epoch: 6| Step: 6
Training loss: 1.2018650770187378
Validation loss: 1.745135509839622

Epoch: 6| Step: 7
Training loss: 1.0669485330581665
Validation loss: 1.7804949924510012

Epoch: 6| Step: 8
Training loss: 0.5982601046562195
Validation loss: 1.7689756616469352

Epoch: 6| Step: 9
Training loss: 1.408639907836914
Validation loss: 1.7953814383476012

Epoch: 6| Step: 10
Training loss: 0.7901610136032104
Validation loss: 1.8139396457261936

Epoch: 6| Step: 11
Training loss: 0.7489317059516907
Validation loss: 1.7843506323393954

Epoch: 6| Step: 12
Training loss: 0.848150372505188
Validation loss: 1.7416128676424745

Epoch: 6| Step: 13
Training loss: 0.4031706154346466
Validation loss: 1.7787126123264272

Epoch: 570| Step: 0
Training loss: 0.8915314078330994
Validation loss: 1.7632091122288858

Epoch: 6| Step: 1
Training loss: 0.9351884126663208
Validation loss: 1.7234226888225925

Epoch: 6| Step: 2
Training loss: 1.0223002433776855
Validation loss: 1.7291664436299314

Epoch: 6| Step: 3
Training loss: 0.688412070274353
Validation loss: 1.726488850450003

Epoch: 6| Step: 4
Training loss: 0.932744026184082
Validation loss: 1.7733004926353373

Epoch: 6| Step: 5
Training loss: 0.642471194267273
Validation loss: 1.719382696254279

Epoch: 6| Step: 6
Training loss: 0.5114478468894958
Validation loss: 1.6898576495467976

Epoch: 6| Step: 7
Training loss: 1.1534638404846191
Validation loss: 1.6911584202961256

Epoch: 6| Step: 8
Training loss: 0.4408162534236908
Validation loss: 1.658518241297814

Epoch: 6| Step: 9
Training loss: 0.8180550336837769
Validation loss: 1.716870742459451

Epoch: 6| Step: 10
Training loss: 1.0773944854736328
Validation loss: 1.6794769129445475

Epoch: 6| Step: 11
Training loss: 0.49930328130722046
Validation loss: 1.7033353415868615

Epoch: 6| Step: 12
Training loss: 0.6445639133453369
Validation loss: 1.6571247782758487

Epoch: 6| Step: 13
Training loss: 1.0071995258331299
Validation loss: 1.7307507171425769

Epoch: 571| Step: 0
Training loss: 0.6366225481033325
Validation loss: 1.705002583483214

Epoch: 6| Step: 1
Training loss: 0.42831432819366455
Validation loss: 1.7437396575045843

Epoch: 6| Step: 2
Training loss: 0.7009506225585938
Validation loss: 1.7368062990967945

Epoch: 6| Step: 3
Training loss: 1.100406527519226
Validation loss: 1.7102723044733847

Epoch: 6| Step: 4
Training loss: 0.7857085466384888
Validation loss: 1.6786082688198294

Epoch: 6| Step: 5
Training loss: 1.235950231552124
Validation loss: 1.6925876307231125

Epoch: 6| Step: 6
Training loss: 1.2630832195281982
Validation loss: 1.7085352943789573

Epoch: 6| Step: 7
Training loss: 0.5665050745010376
Validation loss: 1.6975251205505864

Epoch: 6| Step: 8
Training loss: 1.0757704973220825
Validation loss: 1.727538363907927

Epoch: 6| Step: 9
Training loss: 0.7282636165618896
Validation loss: 1.7187251506313201

Epoch: 6| Step: 10
Training loss: 0.7540697455406189
Validation loss: 1.7610181659780524

Epoch: 6| Step: 11
Training loss: 0.5956790447235107
Validation loss: 1.702852693937158

Epoch: 6| Step: 12
Training loss: 0.699704110622406
Validation loss: 1.677440122891498

Epoch: 6| Step: 13
Training loss: 0.6156390309333801
Validation loss: 1.6612440129762054

Epoch: 572| Step: 0
Training loss: 0.8913518786430359
Validation loss: 1.6858142242636731

Epoch: 6| Step: 1
Training loss: 1.0727274417877197
Validation loss: 1.6853055082341677

Epoch: 6| Step: 2
Training loss: 0.8257058262825012
Validation loss: 1.730015863654434

Epoch: 6| Step: 3
Training loss: 0.8819369077682495
Validation loss: 1.6827821834113008

Epoch: 6| Step: 4
Training loss: 0.8511865139007568
Validation loss: 1.7148430501261065

Epoch: 6| Step: 5
Training loss: 0.4208965301513672
Validation loss: 1.689722118839141

Epoch: 6| Step: 6
Training loss: 0.7812491655349731
Validation loss: 1.7085078300968293

Epoch: 6| Step: 7
Training loss: 1.7637715339660645
Validation loss: 1.699713368569651

Epoch: 6| Step: 8
Training loss: 0.8909231424331665
Validation loss: 1.6847282391722485

Epoch: 6| Step: 9
Training loss: 0.6244632601737976
Validation loss: 1.6391814216490714

Epoch: 6| Step: 10
Training loss: 0.3872533440589905
Validation loss: 1.7243678339066044

Epoch: 6| Step: 11
Training loss: 0.63973468542099
Validation loss: 1.6669087781701037

Epoch: 6| Step: 12
Training loss: 0.591102123260498
Validation loss: 1.7071984583331692

Epoch: 6| Step: 13
Training loss: 0.5264098644256592
Validation loss: 1.766134028793663

Epoch: 573| Step: 0
Training loss: 0.8697293996810913
Validation loss: 1.6894204360182568

Epoch: 6| Step: 1
Training loss: 1.052109956741333
Validation loss: 1.7177702855038386

Epoch: 6| Step: 2
Training loss: 0.45332375168800354
Validation loss: 1.6786726956726403

Epoch: 6| Step: 3
Training loss: 0.7063192129135132
Validation loss: 1.6715682885980094

Epoch: 6| Step: 4
Training loss: 1.4969943761825562
Validation loss: 1.6853067464725946

Epoch: 6| Step: 5
Training loss: 0.5764766931533813
Validation loss: 1.7310461164802633

Epoch: 6| Step: 6
Training loss: 0.5793334245681763
Validation loss: 1.7346185535512946

Epoch: 6| Step: 7
Training loss: 0.7382815480232239
Validation loss: 1.7157653685539

Epoch: 6| Step: 8
Training loss: 0.6578338146209717
Validation loss: 1.6700484130972175

Epoch: 6| Step: 9
Training loss: 0.44029444456100464
Validation loss: 1.7040283064688406

Epoch: 6| Step: 10
Training loss: 0.6172956228256226
Validation loss: 1.7233130598580966

Epoch: 6| Step: 11
Training loss: 1.327480435371399
Validation loss: 1.6511589852712487

Epoch: 6| Step: 12
Training loss: 0.853706955909729
Validation loss: 1.6887353645857943

Epoch: 6| Step: 13
Training loss: 0.8264259696006775
Validation loss: 1.7094604943388252

Epoch: 574| Step: 0
Training loss: 0.6406595706939697
Validation loss: 1.673009322535607

Epoch: 6| Step: 1
Training loss: 1.069702386856079
Validation loss: 1.7180957871098672

Epoch: 6| Step: 2
Training loss: 1.0222450494766235
Validation loss: 1.7140837792427308

Epoch: 6| Step: 3
Training loss: 0.614263653755188
Validation loss: 1.7446077331419914

Epoch: 6| Step: 4
Training loss: 0.4814983904361725
Validation loss: 1.673184637100466

Epoch: 6| Step: 5
Training loss: 0.6245813965797424
Validation loss: 1.7485659789013606

Epoch: 6| Step: 6
Training loss: 0.7187737226486206
Validation loss: 1.7075206464336765

Epoch: 6| Step: 7
Training loss: 0.499260276556015
Validation loss: 1.6948611351751512

Epoch: 6| Step: 8
Training loss: 0.939407467842102
Validation loss: 1.7599392937075706

Epoch: 6| Step: 9
Training loss: 1.454033374786377
Validation loss: 1.7296485131786716

Epoch: 6| Step: 10
Training loss: 0.8166255950927734
Validation loss: 1.7428536850919005

Epoch: 6| Step: 11
Training loss: 0.675391435623169
Validation loss: 1.713977684256851

Epoch: 6| Step: 12
Training loss: 0.7219111919403076
Validation loss: 1.7706260834970782

Epoch: 6| Step: 13
Training loss: 0.8965660929679871
Validation loss: 1.7200319049178914

Epoch: 575| Step: 0
Training loss: 0.4771479368209839
Validation loss: 1.7395408076624717

Epoch: 6| Step: 1
Training loss: 1.246464729309082
Validation loss: 1.7427875072725358

Epoch: 6| Step: 2
Training loss: 0.9987521171569824
Validation loss: 1.7250263466629931

Epoch: 6| Step: 3
Training loss: 0.7749135494232178
Validation loss: 1.7200139209788332

Epoch: 6| Step: 4
Training loss: 0.6726614236831665
Validation loss: 1.7810358308976697

Epoch: 6| Step: 5
Training loss: 1.0690451860427856
Validation loss: 1.7075757339436521

Epoch: 6| Step: 6
Training loss: 0.9899227619171143
Validation loss: 1.7680294770066456

Epoch: 6| Step: 7
Training loss: 0.7999885082244873
Validation loss: 1.6884719453832155

Epoch: 6| Step: 8
Training loss: 0.7110391855239868
Validation loss: 1.656973651660386

Epoch: 6| Step: 9
Training loss: 0.5892258882522583
Validation loss: 1.6696727250211982

Epoch: 6| Step: 10
Training loss: 0.6860957145690918
Validation loss: 1.6577791488298805

Epoch: 6| Step: 11
Training loss: 0.9614275693893433
Validation loss: 1.7281427626968713

Epoch: 6| Step: 12
Training loss: 0.7163031101226807
Validation loss: 1.7110828212512437

Epoch: 6| Step: 13
Training loss: 0.43731582164764404
Validation loss: 1.7046559164600987

Epoch: 576| Step: 0
Training loss: 0.4938022196292877
Validation loss: 1.7701539749740272

Epoch: 6| Step: 1
Training loss: 0.44631263613700867
Validation loss: 1.6915847575792702

Epoch: 6| Step: 2
Training loss: 0.8721331357955933
Validation loss: 1.7468909550738592

Epoch: 6| Step: 3
Training loss: 1.3059604167938232
Validation loss: 1.7185660946753718

Epoch: 6| Step: 4
Training loss: 0.9072726368904114
Validation loss: 1.7336130603667228

Epoch: 6| Step: 5
Training loss: 0.7440062165260315
Validation loss: 1.7151220556228393

Epoch: 6| Step: 6
Training loss: 0.7254558205604553
Validation loss: 1.7820153954208537

Epoch: 6| Step: 7
Training loss: 0.8719121217727661
Validation loss: 1.80671025219784

Epoch: 6| Step: 8
Training loss: 0.8067761659622192
Validation loss: 1.722208446071994

Epoch: 6| Step: 9
Training loss: 0.5769310593605042
Validation loss: 1.7791067829696081

Epoch: 6| Step: 10
Training loss: 1.2413055896759033
Validation loss: 1.76698814540781

Epoch: 6| Step: 11
Training loss: 0.7199075222015381
Validation loss: 1.7609197349958523

Epoch: 6| Step: 12
Training loss: 0.5122054815292358
Validation loss: 1.7070722631228867

Epoch: 6| Step: 13
Training loss: 1.0469040870666504
Validation loss: 1.686435152125615

Epoch: 577| Step: 0
Training loss: 0.7980682849884033
Validation loss: 1.6889007501704718

Epoch: 6| Step: 1
Training loss: 1.0666437149047852
Validation loss: 1.7274333610329577

Epoch: 6| Step: 2
Training loss: 0.795014500617981
Validation loss: 1.6756980765250422

Epoch: 6| Step: 3
Training loss: 0.7519776821136475
Validation loss: 1.7021175481939828

Epoch: 6| Step: 4
Training loss: 0.8523167967796326
Validation loss: 1.7260235817201677

Epoch: 6| Step: 5
Training loss: 1.1624720096588135
Validation loss: 1.7125959960363244

Epoch: 6| Step: 6
Training loss: 0.7350978851318359
Validation loss: 1.6745307727526593

Epoch: 6| Step: 7
Training loss: 1.0498578548431396
Validation loss: 1.7057647730714531

Epoch: 6| Step: 8
Training loss: 0.48372411727905273
Validation loss: 1.7304611026599843

Epoch: 6| Step: 9
Training loss: 0.5978386998176575
Validation loss: 1.7169673365931357

Epoch: 6| Step: 10
Training loss: 0.8016900420188904
Validation loss: 1.7026085238302908

Epoch: 6| Step: 11
Training loss: 0.7360022664070129
Validation loss: 1.683669400471513

Epoch: 6| Step: 12
Training loss: 0.6333324909210205
Validation loss: 1.7447795201373357

Epoch: 6| Step: 13
Training loss: 1.6235413551330566
Validation loss: 1.738775489150837

Epoch: 578| Step: 0
Training loss: 0.7723665237426758
Validation loss: 1.6951684182690037

Epoch: 6| Step: 1
Training loss: 0.7041648626327515
Validation loss: 1.70778194550545

Epoch: 6| Step: 2
Training loss: 0.7930601239204407
Validation loss: 1.697083314259847

Epoch: 6| Step: 3
Training loss: 0.988469123840332
Validation loss: 1.6907462073910622

Epoch: 6| Step: 4
Training loss: 0.35084080696105957
Validation loss: 1.6992098413487917

Epoch: 6| Step: 5
Training loss: 0.6596856713294983
Validation loss: 1.7206270605005243

Epoch: 6| Step: 6
Training loss: 0.7828371524810791
Validation loss: 1.6816657217600013

Epoch: 6| Step: 7
Training loss: 1.1502659320831299
Validation loss: 1.692625141912891

Epoch: 6| Step: 8
Training loss: 0.7432675361633301
Validation loss: 1.6932166827622281

Epoch: 6| Step: 9
Training loss: 0.9395102262496948
Validation loss: 1.6987312859104526

Epoch: 6| Step: 10
Training loss: 0.9635212421417236
Validation loss: 1.6765066321178148

Epoch: 6| Step: 11
Training loss: 0.842256486415863
Validation loss: 1.7126162270063996

Epoch: 6| Step: 12
Training loss: 0.6369037628173828
Validation loss: 1.6865354314927132

Epoch: 6| Step: 13
Training loss: 0.5954190492630005
Validation loss: 1.7029612730908137

Epoch: 579| Step: 0
Training loss: 0.7500181794166565
Validation loss: 1.7545153774240965

Epoch: 6| Step: 1
Training loss: 0.8523945808410645
Validation loss: 1.7205680519021966

Epoch: 6| Step: 2
Training loss: 0.6465662717819214
Validation loss: 1.710635604396943

Epoch: 6| Step: 3
Training loss: 0.719550609588623
Validation loss: 1.7308927684701898

Epoch: 6| Step: 4
Training loss: 0.6961737871170044
Validation loss: 1.7039674251310286

Epoch: 6| Step: 5
Training loss: 1.3334451913833618
Validation loss: 1.7428221625666465

Epoch: 6| Step: 6
Training loss: 0.718793511390686
Validation loss: 1.722484580932125

Epoch: 6| Step: 7
Training loss: 0.44008418917655945
Validation loss: 1.6765799099399197

Epoch: 6| Step: 8
Training loss: 0.7437512874603271
Validation loss: 1.673548416424823

Epoch: 6| Step: 9
Training loss: 1.079293966293335
Validation loss: 1.6725988080424647

Epoch: 6| Step: 10
Training loss: 1.1369216442108154
Validation loss: 1.7539833425193705

Epoch: 6| Step: 11
Training loss: 0.5755151510238647
Validation loss: 1.629870489079465

Epoch: 6| Step: 12
Training loss: 0.5155413150787354
Validation loss: 1.7023921051333029

Epoch: 6| Step: 13
Training loss: 1.5306062698364258
Validation loss: 1.7101798454920452

Epoch: 580| Step: 0
Training loss: 0.8951236009597778
Validation loss: 1.7094028213972687

Epoch: 6| Step: 1
Training loss: 0.608797013759613
Validation loss: 1.6789929546335691

Epoch: 6| Step: 2
Training loss: 0.7263429760932922
Validation loss: 1.6872615583481327

Epoch: 6| Step: 3
Training loss: 1.2832354307174683
Validation loss: 1.7049042319738736

Epoch: 6| Step: 4
Training loss: 0.6062852144241333
Validation loss: 1.6966326070088211

Epoch: 6| Step: 5
Training loss: 0.5991852879524231
Validation loss: 1.7625682430882608

Epoch: 6| Step: 6
Training loss: 0.7486779689788818
Validation loss: 1.7224636731609222

Epoch: 6| Step: 7
Training loss: 0.7241954803466797
Validation loss: 1.6965042070675922

Epoch: 6| Step: 8
Training loss: 1.0220890045166016
Validation loss: 1.7081672837657313

Epoch: 6| Step: 9
Training loss: 0.7220088243484497
Validation loss: 1.6684252010878695

Epoch: 6| Step: 10
Training loss: 0.6608849763870239
Validation loss: 1.6740035382650231

Epoch: 6| Step: 11
Training loss: 0.5953863859176636
Validation loss: 1.7315602238460253

Epoch: 6| Step: 12
Training loss: 0.6388506889343262
Validation loss: 1.6893041505608508

Epoch: 6| Step: 13
Training loss: 1.771747350692749
Validation loss: 1.6524222127852901

Epoch: 581| Step: 0
Training loss: 0.537075936794281
Validation loss: 1.689953113114962

Epoch: 6| Step: 1
Training loss: 0.7308874130249023
Validation loss: 1.7043853934093187

Epoch: 6| Step: 2
Training loss: 0.5030723810195923
Validation loss: 1.7207015445155482

Epoch: 6| Step: 3
Training loss: 1.1573151350021362
Validation loss: 1.734076689648372

Epoch: 6| Step: 4
Training loss: 1.152593970298767
Validation loss: 1.7023967837774625

Epoch: 6| Step: 5
Training loss: 0.5311379432678223
Validation loss: 1.6788553909588886

Epoch: 6| Step: 6
Training loss: 0.6311728358268738
Validation loss: 1.6574094231410692

Epoch: 6| Step: 7
Training loss: 0.3765947222709656
Validation loss: 1.7254062647460608

Epoch: 6| Step: 8
Training loss: 0.9256465435028076
Validation loss: 1.7259281860884799

Epoch: 6| Step: 9
Training loss: 0.8895344138145447
Validation loss: 1.72357024428665

Epoch: 6| Step: 10
Training loss: 0.7898615002632141
Validation loss: 1.7024030980243479

Epoch: 6| Step: 11
Training loss: 1.1284763813018799
Validation loss: 1.7094802664172264

Epoch: 6| Step: 12
Training loss: 0.6562916040420532
Validation loss: 1.6901113307604225

Epoch: 6| Step: 13
Training loss: 0.7352004647254944
Validation loss: 1.6917370519330424

Epoch: 582| Step: 0
Training loss: 1.3793836832046509
Validation loss: 1.6639432753286054

Epoch: 6| Step: 1
Training loss: 0.8225919008255005
Validation loss: 1.681606759307205

Epoch: 6| Step: 2
Training loss: 0.877797544002533
Validation loss: 1.7253951000910934

Epoch: 6| Step: 3
Training loss: 0.46541184186935425
Validation loss: 1.6962419274032756

Epoch: 6| Step: 4
Training loss: 0.4489459991455078
Validation loss: 1.6976544728843115

Epoch: 6| Step: 5
Training loss: 0.8245972394943237
Validation loss: 1.7140479600557716

Epoch: 6| Step: 6
Training loss: 1.182929277420044
Validation loss: 1.6957408356410202

Epoch: 6| Step: 7
Training loss: 0.6919463276863098
Validation loss: 1.7097234866952384

Epoch: 6| Step: 8
Training loss: 1.2314345836639404
Validation loss: 1.6713619667996642

Epoch: 6| Step: 9
Training loss: 0.5824391841888428
Validation loss: 1.7416400524877733

Epoch: 6| Step: 10
Training loss: 0.3827543258666992
Validation loss: 1.6790400243574573

Epoch: 6| Step: 11
Training loss: 0.8519072532653809
Validation loss: 1.7222254763367355

Epoch: 6| Step: 12
Training loss: 0.7173976898193359
Validation loss: 1.7111423874414096

Epoch: 6| Step: 13
Training loss: 0.7343223094940186
Validation loss: 1.7331917926829348

Epoch: 583| Step: 0
Training loss: 0.7818995714187622
Validation loss: 1.7501357678444154

Epoch: 6| Step: 1
Training loss: 1.0760128498077393
Validation loss: 1.7195903460184734

Epoch: 6| Step: 2
Training loss: 0.6721937656402588
Validation loss: 1.7325333613221363

Epoch: 6| Step: 3
Training loss: 0.7591874599456787
Validation loss: 1.6818387111028035

Epoch: 6| Step: 4
Training loss: 0.7039381265640259
Validation loss: 1.671638015777834

Epoch: 6| Step: 5
Training loss: 1.2087143659591675
Validation loss: 1.669969694588774

Epoch: 6| Step: 6
Training loss: 0.8296903371810913
Validation loss: 1.7311114316345544

Epoch: 6| Step: 7
Training loss: 0.5790107250213623
Validation loss: 1.7631954762243456

Epoch: 6| Step: 8
Training loss: 0.7613868713378906
Validation loss: 1.706117101894912

Epoch: 6| Step: 9
Training loss: 0.6891460418701172
Validation loss: 1.7548097769419353

Epoch: 6| Step: 10
Training loss: 1.1189556121826172
Validation loss: 1.6953490703336653

Epoch: 6| Step: 11
Training loss: 0.6561065912246704
Validation loss: 1.683747551774466

Epoch: 6| Step: 12
Training loss: 0.587469756603241
Validation loss: 1.7627522458312332

Epoch: 6| Step: 13
Training loss: 0.6920345425605774
Validation loss: 1.7340687885079333

Epoch: 584| Step: 0
Training loss: 0.5743700265884399
Validation loss: 1.7178041845239618

Epoch: 6| Step: 1
Training loss: 1.1426823139190674
Validation loss: 1.683953785127209

Epoch: 6| Step: 2
Training loss: 1.1398354768753052
Validation loss: 1.6966650485992432

Epoch: 6| Step: 3
Training loss: 1.2776317596435547
Validation loss: 1.6952965644098097

Epoch: 6| Step: 4
Training loss: 0.7364859580993652
Validation loss: 1.7194488856100267

Epoch: 6| Step: 5
Training loss: 0.7507424354553223
Validation loss: 1.650156081363719

Epoch: 6| Step: 6
Training loss: 0.8940354585647583
Validation loss: 1.7358749297357374

Epoch: 6| Step: 7
Training loss: 0.9563745856285095
Validation loss: 1.685308890957986

Epoch: 6| Step: 8
Training loss: 0.43346744775772095
Validation loss: 1.6425335381620674

Epoch: 6| Step: 9
Training loss: 0.6768869757652283
Validation loss: 1.6885072633784304

Epoch: 6| Step: 10
Training loss: 0.6521164178848267
Validation loss: 1.6923134455116846

Epoch: 6| Step: 11
Training loss: 0.49405437707901
Validation loss: 1.7527212712072557

Epoch: 6| Step: 12
Training loss: 0.8072590827941895
Validation loss: 1.7056580974209694

Epoch: 6| Step: 13
Training loss: 1.1230741739273071
Validation loss: 1.7720231932978476

Epoch: 585| Step: 0
Training loss: 0.7235422134399414
Validation loss: 1.774373451868693

Epoch: 6| Step: 1
Training loss: 1.2912497520446777
Validation loss: 1.7395369570742372

Epoch: 6| Step: 2
Training loss: 0.6558811664581299
Validation loss: 1.7093650461525045

Epoch: 6| Step: 3
Training loss: 1.1083223819732666
Validation loss: 1.7617158582133632

Epoch: 6| Step: 4
Training loss: 0.5736480951309204
Validation loss: 1.7560759975064186

Epoch: 6| Step: 5
Training loss: 1.0929903984069824
Validation loss: 1.6903280878579745

Epoch: 6| Step: 6
Training loss: 0.8624330759048462
Validation loss: 1.6924682727424047

Epoch: 6| Step: 7
Training loss: 0.6094467639923096
Validation loss: 1.7128745317459106

Epoch: 6| Step: 8
Training loss: 0.842761754989624
Validation loss: 1.6740894740627659

Epoch: 6| Step: 9
Training loss: 0.8874607086181641
Validation loss: 1.6509870688120525

Epoch: 6| Step: 10
Training loss: 0.6590930819511414
Validation loss: 1.7062950506005237

Epoch: 6| Step: 11
Training loss: 0.7577943205833435
Validation loss: 1.6418289933153378

Epoch: 6| Step: 12
Training loss: 0.5503805875778198
Validation loss: 1.6747538082061275

Epoch: 6| Step: 13
Training loss: 0.445335328578949
Validation loss: 1.6511677490767611

Epoch: 586| Step: 0
Training loss: 0.4376164674758911
Validation loss: 1.648539141942096

Epoch: 6| Step: 1
Training loss: 0.8792175054550171
Validation loss: 1.6456003829997072

Epoch: 6| Step: 2
Training loss: 0.8350203037261963
Validation loss: 1.7522105042652418

Epoch: 6| Step: 3
Training loss: 0.8888055086135864
Validation loss: 1.7097966158261864

Epoch: 6| Step: 4
Training loss: 0.6182237863540649
Validation loss: 1.7469263435691915

Epoch: 6| Step: 5
Training loss: 0.74654221534729
Validation loss: 1.6881082429680774

Epoch: 6| Step: 6
Training loss: 0.8516138195991516
Validation loss: 1.6923359888856129

Epoch: 6| Step: 7
Training loss: 0.8212196826934814
Validation loss: 1.698238980385565

Epoch: 6| Step: 8
Training loss: 1.0380131006240845
Validation loss: 1.698983919235968

Epoch: 6| Step: 9
Training loss: 0.924131453037262
Validation loss: 1.6639046976643224

Epoch: 6| Step: 10
Training loss: 0.6548657417297363
Validation loss: 1.6832451410191034

Epoch: 6| Step: 11
Training loss: 0.7591338157653809
Validation loss: 1.7245920678620696

Epoch: 6| Step: 12
Training loss: 0.5288810729980469
Validation loss: 1.7350704849407237

Epoch: 6| Step: 13
Training loss: 1.2761425971984863
Validation loss: 1.7146187097795549

Epoch: 587| Step: 0
Training loss: 0.7744606137275696
Validation loss: 1.6794614971324962

Epoch: 6| Step: 1
Training loss: 0.41989922523498535
Validation loss: 1.7307099603837537

Epoch: 6| Step: 2
Training loss: 0.9378997087478638
Validation loss: 1.7561323360730243

Epoch: 6| Step: 3
Training loss: 0.5705358982086182
Validation loss: 1.7391286793575491

Epoch: 6| Step: 4
Training loss: 0.27065181732177734
Validation loss: 1.7722287921495334

Epoch: 6| Step: 5
Training loss: 0.8994225263595581
Validation loss: 1.7378426905601256

Epoch: 6| Step: 6
Training loss: 0.7388375997543335
Validation loss: 1.7676861952709895

Epoch: 6| Step: 7
Training loss: 1.0427545309066772
Validation loss: 1.7429681080643848

Epoch: 6| Step: 8
Training loss: 0.9906339645385742
Validation loss: 1.7471009890238445

Epoch: 6| Step: 9
Training loss: 0.9587416648864746
Validation loss: 1.7517805535306212

Epoch: 6| Step: 10
Training loss: 0.5922258496284485
Validation loss: 1.709977578091365

Epoch: 6| Step: 11
Training loss: 0.8681904077529907
Validation loss: 1.6699500391560216

Epoch: 6| Step: 12
Training loss: 0.6969720125198364
Validation loss: 1.7034811204479587

Epoch: 6| Step: 13
Training loss: 1.5969431400299072
Validation loss: 1.6896586828334357

Epoch: 588| Step: 0
Training loss: 0.6645302772521973
Validation loss: 1.7095266426763227

Epoch: 6| Step: 1
Training loss: 1.111889123916626
Validation loss: 1.6589450156816872

Epoch: 6| Step: 2
Training loss: 0.9271615147590637
Validation loss: 1.6965570155010428

Epoch: 6| Step: 3
Training loss: 0.9557652473449707
Validation loss: 1.7038976146328835

Epoch: 6| Step: 4
Training loss: 0.6244670748710632
Validation loss: 1.6984852449868315

Epoch: 6| Step: 5
Training loss: 0.43730390071868896
Validation loss: 1.6744081256210164

Epoch: 6| Step: 6
Training loss: 0.695979118347168
Validation loss: 1.7144282607622043

Epoch: 6| Step: 7
Training loss: 0.858957827091217
Validation loss: 1.7054088961693548

Epoch: 6| Step: 8
Training loss: 1.0460288524627686
Validation loss: 1.7455448796672206

Epoch: 6| Step: 9
Training loss: 0.6047320365905762
Validation loss: 1.744519534931388

Epoch: 6| Step: 10
Training loss: 0.6892237067222595
Validation loss: 1.7050105320510043

Epoch: 6| Step: 11
Training loss: 0.6428918838500977
Validation loss: 1.7227160123086744

Epoch: 6| Step: 12
Training loss: 0.7228554487228394
Validation loss: 1.7017283131999354

Epoch: 6| Step: 13
Training loss: 1.0365508794784546
Validation loss: 1.7639514002748715

Epoch: 589| Step: 0
Training loss: 0.7029462456703186
Validation loss: 1.690201392737768

Epoch: 6| Step: 1
Training loss: 0.5090082883834839
Validation loss: 1.6851377794819493

Epoch: 6| Step: 2
Training loss: 0.7380367517471313
Validation loss: 1.7189890300073931

Epoch: 6| Step: 3
Training loss: 0.7953944206237793
Validation loss: 1.733879953302363

Epoch: 6| Step: 4
Training loss: 0.7126363515853882
Validation loss: 1.6997899701518397

Epoch: 6| Step: 5
Training loss: 0.6974396705627441
Validation loss: 1.7247365046572942

Epoch: 6| Step: 6
Training loss: 1.305828332901001
Validation loss: 1.6467832416616461

Epoch: 6| Step: 7
Training loss: 1.1897209882736206
Validation loss: 1.6786762540058424

Epoch: 6| Step: 8
Training loss: 0.8016144633293152
Validation loss: 1.6857998755670363

Epoch: 6| Step: 9
Training loss: 1.062469482421875
Validation loss: 1.7280485899217668

Epoch: 6| Step: 10
Training loss: 0.6988714337348938
Validation loss: 1.672415687191871

Epoch: 6| Step: 11
Training loss: 0.6951360702514648
Validation loss: 1.7059304944930538

Epoch: 6| Step: 12
Training loss: 0.8217182755470276
Validation loss: 1.6628688548200874

Epoch: 6| Step: 13
Training loss: 0.4495827257633209
Validation loss: 1.7297111865012877

Epoch: 590| Step: 0
Training loss: 0.7447586059570312
Validation loss: 1.7039179981395762

Epoch: 6| Step: 1
Training loss: 0.7574944496154785
Validation loss: 1.7331890444601736

Epoch: 6| Step: 2
Training loss: 0.8716357350349426
Validation loss: 1.7077284205344416

Epoch: 6| Step: 3
Training loss: 1.0241715908050537
Validation loss: 1.6865297517468851

Epoch: 6| Step: 4
Training loss: 0.5083826780319214
Validation loss: 1.7239625710313038

Epoch: 6| Step: 5
Training loss: 0.8558308482170105
Validation loss: 1.6854157781088224

Epoch: 6| Step: 6
Training loss: 0.46838855743408203
Validation loss: 1.6667291509207858

Epoch: 6| Step: 7
Training loss: 0.9777798056602478
Validation loss: 1.6753776714365969

Epoch: 6| Step: 8
Training loss: 0.6549783945083618
Validation loss: 1.68048462816464

Epoch: 6| Step: 9
Training loss: 0.7616216540336609
Validation loss: 1.674751276611

Epoch: 6| Step: 10
Training loss: 0.9421512484550476
Validation loss: 1.723297773509897

Epoch: 6| Step: 11
Training loss: 0.8902250528335571
Validation loss: 1.6864269600119641

Epoch: 6| Step: 12
Training loss: 0.8061414361000061
Validation loss: 1.6972121025926323

Epoch: 6| Step: 13
Training loss: 0.859677255153656
Validation loss: 1.6828718057242773

Epoch: 591| Step: 0
Training loss: 0.45552903413772583
Validation loss: 1.6649992606973136

Epoch: 6| Step: 1
Training loss: 0.4932756721973419
Validation loss: 1.6228714553258752

Epoch: 6| Step: 2
Training loss: 0.6535569429397583
Validation loss: 1.692171453147806

Epoch: 6| Step: 3
Training loss: 0.5156968832015991
Validation loss: 1.7061993614319833

Epoch: 6| Step: 4
Training loss: 0.6987393498420715
Validation loss: 1.7665953405441777

Epoch: 6| Step: 5
Training loss: 0.7836363315582275
Validation loss: 1.7062130756275629

Epoch: 6| Step: 6
Training loss: 1.0914766788482666
Validation loss: 1.7344674705177225

Epoch: 6| Step: 7
Training loss: 1.0218007564544678
Validation loss: 1.7287244540388866

Epoch: 6| Step: 8
Training loss: 1.178858995437622
Validation loss: 1.724975929465345

Epoch: 6| Step: 9
Training loss: 0.6425731778144836
Validation loss: 1.7342021798574796

Epoch: 6| Step: 10
Training loss: 0.8390636444091797
Validation loss: 1.7336582278692594

Epoch: 6| Step: 11
Training loss: 0.9794909358024597
Validation loss: 1.6558097947028376

Epoch: 6| Step: 12
Training loss: 0.3415051996707916
Validation loss: 1.6388600590408489

Epoch: 6| Step: 13
Training loss: 1.5512118339538574
Validation loss: 1.652376704318549

Epoch: 592| Step: 0
Training loss: 0.9045432806015015
Validation loss: 1.653429744064167

Epoch: 6| Step: 1
Training loss: 1.0527559518814087
Validation loss: 1.6667489082582536

Epoch: 6| Step: 2
Training loss: 0.9228504300117493
Validation loss: 1.694942428219703

Epoch: 6| Step: 3
Training loss: 0.6454784274101257
Validation loss: 1.7163016507702489

Epoch: 6| Step: 4
Training loss: 0.5572848320007324
Validation loss: 1.7339774818830593

Epoch: 6| Step: 5
Training loss: 0.6251047849655151
Validation loss: 1.6665027756844797

Epoch: 6| Step: 6
Training loss: 0.922477662563324
Validation loss: 1.7087331715450491

Epoch: 6| Step: 7
Training loss: 0.6092491149902344
Validation loss: 1.6768747946267486

Epoch: 6| Step: 8
Training loss: 0.6073276996612549
Validation loss: 1.6436498690676946

Epoch: 6| Step: 9
Training loss: 0.550595223903656
Validation loss: 1.6486733318657003

Epoch: 6| Step: 10
Training loss: 1.1026246547698975
Validation loss: 1.6479032167824366

Epoch: 6| Step: 11
Training loss: 0.5307188630104065
Validation loss: 1.7544318168394026

Epoch: 6| Step: 12
Training loss: 0.6295716762542725
Validation loss: 1.6955568969890635

Epoch: 6| Step: 13
Training loss: 1.4286437034606934
Validation loss: 1.6857211346267371

Epoch: 593| Step: 0
Training loss: 0.6236726641654968
Validation loss: 1.692027525235248

Epoch: 6| Step: 1
Training loss: 0.9371334910392761
Validation loss: 1.681591283890509

Epoch: 6| Step: 2
Training loss: 0.8295925855636597
Validation loss: 1.7283474758107176

Epoch: 6| Step: 3
Training loss: 0.6089306473731995
Validation loss: 1.6764396595698532

Epoch: 6| Step: 4
Training loss: 1.1981406211853027
Validation loss: 1.717223128964824

Epoch: 6| Step: 5
Training loss: 0.7425470948219299
Validation loss: 1.6433216269298265

Epoch: 6| Step: 6
Training loss: 0.8693070411682129
Validation loss: 1.6865281981806601

Epoch: 6| Step: 7
Training loss: 0.7572218775749207
Validation loss: 1.676599641000071

Epoch: 6| Step: 8
Training loss: 0.9018969535827637
Validation loss: 1.6690178673754457

Epoch: 6| Step: 9
Training loss: 0.8004550933837891
Validation loss: 1.7305384348797541

Epoch: 6| Step: 10
Training loss: 0.9648064374923706
Validation loss: 1.6132657181832097

Epoch: 6| Step: 11
Training loss: 0.5350170135498047
Validation loss: 1.7229476436491935

Epoch: 6| Step: 12
Training loss: 0.7055986523628235
Validation loss: 1.6840987423414826

Epoch: 6| Step: 13
Training loss: 0.5548654794692993
Validation loss: 1.7615544411443895

Epoch: 594| Step: 0
Training loss: 1.2019121646881104
Validation loss: 1.6562768483674655

Epoch: 6| Step: 1
Training loss: 0.8080099821090698
Validation loss: 1.6720830727648992

Epoch: 6| Step: 2
Training loss: 1.2400399446487427
Validation loss: 1.6556713324721142

Epoch: 6| Step: 3
Training loss: 0.4428488612174988
Validation loss: 1.7179674461323728

Epoch: 6| Step: 4
Training loss: 0.823628306388855
Validation loss: 1.6164191845924623

Epoch: 6| Step: 5
Training loss: 0.5657448768615723
Validation loss: 1.7066698510159728

Epoch: 6| Step: 6
Training loss: 1.063650369644165
Validation loss: 1.7175876517449655

Epoch: 6| Step: 7
Training loss: 0.43273359537124634
Validation loss: 1.7281455865470312

Epoch: 6| Step: 8
Training loss: 0.600142240524292
Validation loss: 1.7711755409035632

Epoch: 6| Step: 9
Training loss: 0.610647439956665
Validation loss: 1.6662244002024333

Epoch: 6| Step: 10
Training loss: 0.6092389822006226
Validation loss: 1.6896333156093475

Epoch: 6| Step: 11
Training loss: 0.6603859066963196
Validation loss: 1.6798284925440305

Epoch: 6| Step: 12
Training loss: 0.7393161058425903
Validation loss: 1.6950304328754384

Epoch: 6| Step: 13
Training loss: 1.1600286960601807
Validation loss: 1.716950205064589

Epoch: 595| Step: 0
Training loss: 0.7935636043548584
Validation loss: 1.7163312909423665

Epoch: 6| Step: 1
Training loss: 0.5844846963882446
Validation loss: 1.696129107988009

Epoch: 6| Step: 2
Training loss: 0.8906425833702087
Validation loss: 1.6959624380193732

Epoch: 6| Step: 3
Training loss: 0.7421247363090515
Validation loss: 1.6987078651305167

Epoch: 6| Step: 4
Training loss: 0.8571765422821045
Validation loss: 1.714299455765755

Epoch: 6| Step: 5
Training loss: 0.5415029525756836
Validation loss: 1.6885605076307892

Epoch: 6| Step: 6
Training loss: 1.1888554096221924
Validation loss: 1.6518120765686035

Epoch: 6| Step: 7
Training loss: 0.993556022644043
Validation loss: 1.6402670080943773

Epoch: 6| Step: 8
Training loss: 0.8985169529914856
Validation loss: 1.6533549383122434

Epoch: 6| Step: 9
Training loss: 0.8092778921127319
Validation loss: 1.7350254443383986

Epoch: 6| Step: 10
Training loss: 0.7762966156005859
Validation loss: 1.7335913976033528

Epoch: 6| Step: 11
Training loss: 0.4780532121658325
Validation loss: 1.7589826558225898

Epoch: 6| Step: 12
Training loss: 0.7731386423110962
Validation loss: 1.727220932642619

Epoch: 6| Step: 13
Training loss: 0.40691468119621277
Validation loss: 1.7575940085995583

Epoch: 596| Step: 0
Training loss: 0.9619939923286438
Validation loss: 1.7407681672803816

Epoch: 6| Step: 1
Training loss: 0.7789636850357056
Validation loss: 1.7414770228888399

Epoch: 6| Step: 2
Training loss: 0.9370415806770325
Validation loss: 1.731254417409179

Epoch: 6| Step: 3
Training loss: 0.7930981516838074
Validation loss: 1.7431844613885368

Epoch: 6| Step: 4
Training loss: 0.6009886264801025
Validation loss: 1.7919612417938888

Epoch: 6| Step: 5
Training loss: 1.1587146520614624
Validation loss: 1.7261301727705105

Epoch: 6| Step: 6
Training loss: 1.1800408363342285
Validation loss: 1.7356360907195716

Epoch: 6| Step: 7
Training loss: 0.754827618598938
Validation loss: 1.6646152363028577

Epoch: 6| Step: 8
Training loss: 0.45071887969970703
Validation loss: 1.7346624110334663

Epoch: 6| Step: 9
Training loss: 0.9153257608413696
Validation loss: 1.710246983394828

Epoch: 6| Step: 10
Training loss: 0.7095655202865601
Validation loss: 1.7039659600104056

Epoch: 6| Step: 11
Training loss: 0.5298581719398499
Validation loss: 1.6891940127136886

Epoch: 6| Step: 12
Training loss: 0.8465882539749146
Validation loss: 1.6822525685833347

Epoch: 6| Step: 13
Training loss: 0.7250329852104187
Validation loss: 1.6591554008504397

Epoch: 597| Step: 0
Training loss: 0.889607846736908
Validation loss: 1.6471152485057872

Epoch: 6| Step: 1
Training loss: 0.7332472801208496
Validation loss: 1.676450470442413

Epoch: 6| Step: 2
Training loss: 0.8221402168273926
Validation loss: 1.6957706853907595

Epoch: 6| Step: 3
Training loss: 0.8885290622711182
Validation loss: 1.73241187039242

Epoch: 6| Step: 4
Training loss: 0.7222944498062134
Validation loss: 1.6712938252315725

Epoch: 6| Step: 5
Training loss: 0.7157018780708313
Validation loss: 1.6582739686453214

Epoch: 6| Step: 6
Training loss: 0.4918018579483032
Validation loss: 1.7381114831534765

Epoch: 6| Step: 7
Training loss: 1.350482702255249
Validation loss: 1.7787525153929187

Epoch: 6| Step: 8
Training loss: 1.158280611038208
Validation loss: 1.8019579443880307

Epoch: 6| Step: 9
Training loss: 0.3685430586338043
Validation loss: 1.7125252280184018

Epoch: 6| Step: 10
Training loss: 1.000093698501587
Validation loss: 1.7312208888351277

Epoch: 6| Step: 11
Training loss: 0.8990373611450195
Validation loss: 1.7032404612469416

Epoch: 6| Step: 12
Training loss: 0.5240952968597412
Validation loss: 1.6815545033383112

Epoch: 6| Step: 13
Training loss: 0.5123801231384277
Validation loss: 1.7132546606884207

Epoch: 598| Step: 0
Training loss: 0.7372102737426758
Validation loss: 1.6965976299778107

Epoch: 6| Step: 1
Training loss: 0.9608283042907715
Validation loss: 1.6632568131210983

Epoch: 6| Step: 2
Training loss: 0.4868454933166504
Validation loss: 1.7276824546116654

Epoch: 6| Step: 3
Training loss: 1.113289713859558
Validation loss: 1.6810205341667257

Epoch: 6| Step: 4
Training loss: 0.7424221038818359
Validation loss: 1.7199932503443893

Epoch: 6| Step: 5
Training loss: 0.8767761588096619
Validation loss: 1.7273803205900295

Epoch: 6| Step: 6
Training loss: 1.2025229930877686
Validation loss: 1.7377153494024788

Epoch: 6| Step: 7
Training loss: 0.3196234107017517
Validation loss: 1.7422137516801075

Epoch: 6| Step: 8
Training loss: 0.6275944113731384
Validation loss: 1.765323491506679

Epoch: 6| Step: 9
Training loss: 0.8156088590621948
Validation loss: 1.7353318070852628

Epoch: 6| Step: 10
Training loss: 0.731060266494751
Validation loss: 1.6829629149488223

Epoch: 6| Step: 11
Training loss: 0.5862927436828613
Validation loss: 1.6792686818748392

Epoch: 6| Step: 12
Training loss: 0.8259385824203491
Validation loss: 1.6913192041458622

Epoch: 6| Step: 13
Training loss: 0.7946793437004089
Validation loss: 1.678803574654364

Epoch: 599| Step: 0
Training loss: 0.7543349266052246
Validation loss: 1.6990519851766608

Epoch: 6| Step: 1
Training loss: 1.0590527057647705
Validation loss: 1.6776924107664375

Epoch: 6| Step: 2
Training loss: 0.41223716735839844
Validation loss: 1.662179631571616

Epoch: 6| Step: 3
Training loss: 0.6654039621353149
Validation loss: 1.719467439959126

Epoch: 6| Step: 4
Training loss: 0.782727837562561
Validation loss: 1.7144136300650976

Epoch: 6| Step: 5
Training loss: 0.920708417892456
Validation loss: 1.6814289272472422

Epoch: 6| Step: 6
Training loss: 0.4632711708545685
Validation loss: 1.7082020082781393

Epoch: 6| Step: 7
Training loss: 0.751268744468689
Validation loss: 1.6398962941221011

Epoch: 6| Step: 8
Training loss: 0.8428321480751038
Validation loss: 1.6823156713157572

Epoch: 6| Step: 9
Training loss: 0.831895112991333
Validation loss: 1.6567747182743524

Epoch: 6| Step: 10
Training loss: 1.4312713146209717
Validation loss: 1.7458223860750917

Epoch: 6| Step: 11
Training loss: 0.2948780953884125
Validation loss: 1.7034263431385

Epoch: 6| Step: 12
Training loss: 0.8167786598205566
Validation loss: 1.7120623870562481

Epoch: 6| Step: 13
Training loss: 0.7132009267807007
Validation loss: 1.6676955351265528

Epoch: 600| Step: 0
Training loss: 1.4950263500213623
Validation loss: 1.6609149402187717

Epoch: 6| Step: 1
Training loss: 0.4595760107040405
Validation loss: 1.6773984944948586

Epoch: 6| Step: 2
Training loss: 0.7100949883460999
Validation loss: 1.721002350571335

Epoch: 6| Step: 3
Training loss: 0.5142202377319336
Validation loss: 1.7110012295425578

Epoch: 6| Step: 4
Training loss: 1.4132779836654663
Validation loss: 1.7209518058325655

Epoch: 6| Step: 5
Training loss: 0.622820258140564
Validation loss: 1.700163395174088

Epoch: 6| Step: 6
Training loss: 0.7835036516189575
Validation loss: 1.7545456296654158

Epoch: 6| Step: 7
Training loss: 0.6642354130744934
Validation loss: 1.679728756668747

Epoch: 6| Step: 8
Training loss: 0.8674699068069458
Validation loss: 1.702734911313621

Epoch: 6| Step: 9
Training loss: 0.46309390664100647
Validation loss: 1.7117190463568575

Epoch: 6| Step: 10
Training loss: 0.7619727253913879
Validation loss: 1.6878955928228234

Epoch: 6| Step: 11
Training loss: 0.8796924948692322
Validation loss: 1.7115105800731207

Epoch: 6| Step: 12
Training loss: 0.7526881098747253
Validation loss: 1.7200194584426058

Epoch: 6| Step: 13
Training loss: 0.4223659336566925
Validation loss: 1.7476825726929532

Epoch: 601| Step: 0
Training loss: 0.9459137916564941
Validation loss: 1.740649100272886

Epoch: 6| Step: 1
Training loss: 0.7510945796966553
Validation loss: 1.7157285034015615

Epoch: 6| Step: 2
Training loss: 0.5985487699508667
Validation loss: 1.6996295426481514

Epoch: 6| Step: 3
Training loss: 0.6724070310592651
Validation loss: 1.7576883915931947

Epoch: 6| Step: 4
Training loss: 1.012333631515503
Validation loss: 1.6488040634380874

Epoch: 6| Step: 5
Training loss: 0.6557313799858093
Validation loss: 1.6563401222229004

Epoch: 6| Step: 6
Training loss: 0.632625937461853
Validation loss: 1.660747531921633

Epoch: 6| Step: 7
Training loss: 0.7478663921356201
Validation loss: 1.6910342195982575

Epoch: 6| Step: 8
Training loss: 0.7263607978820801
Validation loss: 1.6848839700862925

Epoch: 6| Step: 9
Training loss: 0.6980040073394775
Validation loss: 1.693553787405773

Epoch: 6| Step: 10
Training loss: 1.247887134552002
Validation loss: 1.7038270888790008

Epoch: 6| Step: 11
Training loss: 0.5277767181396484
Validation loss: 1.6214941650308587

Epoch: 6| Step: 12
Training loss: 0.8422113060951233
Validation loss: 1.6631052032593758

Epoch: 6| Step: 13
Training loss: 1.0187535285949707
Validation loss: 1.725747472496443

Epoch: 602| Step: 0
Training loss: 0.7738980054855347
Validation loss: 1.7019703394623213

Epoch: 6| Step: 1
Training loss: 0.8503531813621521
Validation loss: 1.6888771416038595

Epoch: 6| Step: 2
Training loss: 0.8004108667373657
Validation loss: 1.7285150853536462

Epoch: 6| Step: 3
Training loss: 0.6868578195571899
Validation loss: 1.728751645293287

Epoch: 6| Step: 4
Training loss: 0.8589690923690796
Validation loss: 1.6983301549829461

Epoch: 6| Step: 5
Training loss: 0.8462116718292236
Validation loss: 1.668522265649611

Epoch: 6| Step: 6
Training loss: 0.5887775421142578
Validation loss: 1.733739096631286

Epoch: 6| Step: 7
Training loss: 0.8585647344589233
Validation loss: 1.7381755664784422

Epoch: 6| Step: 8
Training loss: 0.39980900287628174
Validation loss: 1.6952267090479534

Epoch: 6| Step: 9
Training loss: 0.6717780828475952
Validation loss: 1.7125567197799683

Epoch: 6| Step: 10
Training loss: 0.9608509540557861
Validation loss: 1.7555113915474183

Epoch: 6| Step: 11
Training loss: 0.9404538869857788
Validation loss: 1.7572352655472294

Epoch: 6| Step: 12
Training loss: 0.5611104369163513
Validation loss: 1.6994189805881952

Epoch: 6| Step: 13
Training loss: 1.1484036445617676
Validation loss: 1.7145872385271135

Epoch: 603| Step: 0
Training loss: 0.7055038213729858
Validation loss: 1.6584672671492382

Epoch: 6| Step: 1
Training loss: 0.7149087190628052
Validation loss: 1.7209245466416883

Epoch: 6| Step: 2
Training loss: 0.2934200167655945
Validation loss: 1.6740718938971078

Epoch: 6| Step: 3
Training loss: 0.5794978141784668
Validation loss: 1.7266422394783265

Epoch: 6| Step: 4
Training loss: 0.8166613578796387
Validation loss: 1.6844265768604894

Epoch: 6| Step: 5
Training loss: 0.8534560203552246
Validation loss: 1.6691820890672746

Epoch: 6| Step: 6
Training loss: 0.7614442110061646
Validation loss: 1.6749017738526868

Epoch: 6| Step: 7
Training loss: 0.8078036904335022
Validation loss: 1.7079753016912809

Epoch: 6| Step: 8
Training loss: 0.6599570512771606
Validation loss: 1.741990222725817

Epoch: 6| Step: 9
Training loss: 0.3861527442932129
Validation loss: 1.755694277824894

Epoch: 6| Step: 10
Training loss: 0.9653812646865845
Validation loss: 1.7518245661130516

Epoch: 6| Step: 11
Training loss: 0.8204171657562256
Validation loss: 1.710561575428132

Epoch: 6| Step: 12
Training loss: 0.8786040544509888
Validation loss: 1.7702895890000045

Epoch: 6| Step: 13
Training loss: 1.5934665203094482
Validation loss: 1.7622061147484729

Epoch: 604| Step: 0
Training loss: 0.6970194578170776
Validation loss: 1.7729076621352986

Epoch: 6| Step: 1
Training loss: 0.5024750828742981
Validation loss: 1.8097378438518894

Epoch: 6| Step: 2
Training loss: 0.6006786227226257
Validation loss: 1.797849157805084

Epoch: 6| Step: 3
Training loss: 0.9829270839691162
Validation loss: 1.7182260508178382

Epoch: 6| Step: 4
Training loss: 0.6985936164855957
Validation loss: 1.7318709973366029

Epoch: 6| Step: 5
Training loss: 1.0432106256484985
Validation loss: 1.6906496683756511

Epoch: 6| Step: 6
Training loss: 0.794187605381012
Validation loss: 1.6538882845191545

Epoch: 6| Step: 7
Training loss: 0.6262723207473755
Validation loss: 1.7174599093775595

Epoch: 6| Step: 8
Training loss: 0.9151802062988281
Validation loss: 1.65547526010903

Epoch: 6| Step: 9
Training loss: 0.8411937952041626
Validation loss: 1.689556606354252

Epoch: 6| Step: 10
Training loss: 0.6063565611839294
Validation loss: 1.6337905135205997

Epoch: 6| Step: 11
Training loss: 0.5664633512496948
Validation loss: 1.659865484442762

Epoch: 6| Step: 12
Training loss: 0.5791877508163452
Validation loss: 1.6565520340396511

Epoch: 6| Step: 13
Training loss: 1.1361571550369263
Validation loss: 1.7388612019118441

Epoch: 605| Step: 0
Training loss: 0.37371277809143066
Validation loss: 1.7057542826539727

Epoch: 6| Step: 1
Training loss: 0.8015344142913818
Validation loss: 1.630245013903546

Epoch: 6| Step: 2
Training loss: 0.4833260178565979
Validation loss: 1.7146378781205864

Epoch: 6| Step: 3
Training loss: 0.6669068932533264
Validation loss: 1.748514252324258

Epoch: 6| Step: 4
Training loss: 0.8841407895088196
Validation loss: 1.7310454589064403

Epoch: 6| Step: 5
Training loss: 0.7271327972412109
Validation loss: 1.6718501980586717

Epoch: 6| Step: 6
Training loss: 0.8009487986564636
Validation loss: 1.767521506996565

Epoch: 6| Step: 7
Training loss: 1.5403181314468384
Validation loss: 1.690585861923874

Epoch: 6| Step: 8
Training loss: 1.139633059501648
Validation loss: 1.7000462265424832

Epoch: 6| Step: 9
Training loss: 0.7983992099761963
Validation loss: 1.7435714147424186

Epoch: 6| Step: 10
Training loss: 0.6388499736785889
Validation loss: 1.6861731224162604

Epoch: 6| Step: 11
Training loss: 0.36378681659698486
Validation loss: 1.724057359080161

Epoch: 6| Step: 12
Training loss: 0.9834718704223633
Validation loss: 1.6720067865105086

Epoch: 6| Step: 13
Training loss: 0.47286754846572876
Validation loss: 1.7192001317137031

Epoch: 606| Step: 0
Training loss: 0.5542213916778564
Validation loss: 1.6679800325824368

Epoch: 6| Step: 1
Training loss: 0.6269461512565613
Validation loss: 1.7093989797817764

Epoch: 6| Step: 2
Training loss: 0.8091710805892944
Validation loss: 1.751978451205838

Epoch: 6| Step: 3
Training loss: 1.3113073110580444
Validation loss: 1.7169071512837564

Epoch: 6| Step: 4
Training loss: 0.758661150932312
Validation loss: 1.7005743006224274

Epoch: 6| Step: 5
Training loss: 0.9291291832923889
Validation loss: 1.7061027044891028

Epoch: 6| Step: 6
Training loss: 0.4155351221561432
Validation loss: 1.7398788031711374

Epoch: 6| Step: 7
Training loss: 0.9081252813339233
Validation loss: 1.6986441022606307

Epoch: 6| Step: 8
Training loss: 0.5216510891914368
Validation loss: 1.6863826346653763

Epoch: 6| Step: 9
Training loss: 0.6957379579544067
Validation loss: 1.7398007864593177

Epoch: 6| Step: 10
Training loss: 0.70320063829422
Validation loss: 1.695569384482599

Epoch: 6| Step: 11
Training loss: 0.7465113997459412
Validation loss: 1.7313018319427327

Epoch: 6| Step: 12
Training loss: 0.9865821003913879
Validation loss: 1.7238641195399786

Epoch: 6| Step: 13
Training loss: 0.39365726709365845
Validation loss: 1.7009048820823751

Epoch: 607| Step: 0
Training loss: 0.7224716544151306
Validation loss: 1.6983194812651603

Epoch: 6| Step: 1
Training loss: 0.6148692965507507
Validation loss: 1.6686877896708827

Epoch: 6| Step: 2
Training loss: 0.714753270149231
Validation loss: 1.7248562792296052

Epoch: 6| Step: 3
Training loss: 0.7240703105926514
Validation loss: 1.7135110106519473

Epoch: 6| Step: 4
Training loss: 0.8022321462631226
Validation loss: 1.7342679077579128

Epoch: 6| Step: 5
Training loss: 0.5736981630325317
Validation loss: 1.6933733340232604

Epoch: 6| Step: 6
Training loss: 0.5626582503318787
Validation loss: 1.723115937684172

Epoch: 6| Step: 7
Training loss: 0.9138480424880981
Validation loss: 1.7093385393901537

Epoch: 6| Step: 8
Training loss: 0.4915873110294342
Validation loss: 1.683900019173981

Epoch: 6| Step: 9
Training loss: 0.974632203578949
Validation loss: 1.680318832397461

Epoch: 6| Step: 10
Training loss: 0.5322167873382568
Validation loss: 1.683642138716995

Epoch: 6| Step: 11
Training loss: 1.1376897096633911
Validation loss: 1.6944480339686077

Epoch: 6| Step: 12
Training loss: 0.7217185497283936
Validation loss: 1.6632545468627766

Epoch: 6| Step: 13
Training loss: 0.7316234111785889
Validation loss: 1.7392057744405602

Epoch: 608| Step: 0
Training loss: 0.9905394315719604
Validation loss: 1.680237406043596

Epoch: 6| Step: 1
Training loss: 0.3988076448440552
Validation loss: 1.6669508923766434

Epoch: 6| Step: 2
Training loss: 0.41353318095207214
Validation loss: 1.6995183883174774

Epoch: 6| Step: 3
Training loss: 0.7973584532737732
Validation loss: 1.717791385548089

Epoch: 6| Step: 4
Training loss: 0.8806803226470947
Validation loss: 1.6952830886328092

Epoch: 6| Step: 5
Training loss: 0.8744112253189087
Validation loss: 1.6964634618451517

Epoch: 6| Step: 6
Training loss: 0.3375706076622009
Validation loss: 1.6760627979873328

Epoch: 6| Step: 7
Training loss: 0.6891983151435852
Validation loss: 1.7258860026636431

Epoch: 6| Step: 8
Training loss: 0.8159152269363403
Validation loss: 1.723785238881265

Epoch: 6| Step: 9
Training loss: 0.7106698751449585
Validation loss: 1.6966566911307714

Epoch: 6| Step: 10
Training loss: 1.1926956176757812
Validation loss: 1.6897433445017824

Epoch: 6| Step: 11
Training loss: 0.6964284777641296
Validation loss: 1.7457085001853205

Epoch: 6| Step: 12
Training loss: 1.1667237281799316
Validation loss: 1.7084069828833304

Epoch: 6| Step: 13
Training loss: 0.49073097109794617
Validation loss: 1.6519056340699554

Epoch: 609| Step: 0
Training loss: 1.0942821502685547
Validation loss: 1.7247258719577585

Epoch: 6| Step: 1
Training loss: 0.6145415306091309
Validation loss: 1.7038835287094116

Epoch: 6| Step: 2
Training loss: 0.7163476347923279
Validation loss: 1.6478111141471452

Epoch: 6| Step: 3
Training loss: 0.7249066233634949
Validation loss: 1.665226049320672

Epoch: 6| Step: 4
Training loss: 0.4574475884437561
Validation loss: 1.7304903422632525

Epoch: 6| Step: 5
Training loss: 1.0236716270446777
Validation loss: 1.6484530728350404

Epoch: 6| Step: 6
Training loss: 0.3837953805923462
Validation loss: 1.6863243887501378

Epoch: 6| Step: 7
Training loss: 0.5405303239822388
Validation loss: 1.6744034444132159

Epoch: 6| Step: 8
Training loss: 0.6426526308059692
Validation loss: 1.6478285225488807

Epoch: 6| Step: 9
Training loss: 0.7287878394126892
Validation loss: 1.6552735887547976

Epoch: 6| Step: 10
Training loss: 0.5893312692642212
Validation loss: 1.667343298594157

Epoch: 6| Step: 11
Training loss: 1.2209434509277344
Validation loss: 1.690329456842074

Epoch: 6| Step: 12
Training loss: 1.3760297298431396
Validation loss: 1.6838368010777298

Epoch: 6| Step: 13
Training loss: 0.4147416353225708
Validation loss: 1.735869812709029

Epoch: 610| Step: 0
Training loss: 0.6937141418457031
Validation loss: 1.763965001670263

Epoch: 6| Step: 1
Training loss: 0.7845607995986938
Validation loss: 1.7552073860681185

Epoch: 6| Step: 2
Training loss: 0.8558309674263
Validation loss: 1.7524695242604902

Epoch: 6| Step: 3
Training loss: 0.5805264711380005
Validation loss: 1.7394817580458939

Epoch: 6| Step: 4
Training loss: 1.1788170337677002
Validation loss: 1.7278379471071306

Epoch: 6| Step: 5
Training loss: 0.6140038371086121
Validation loss: 1.7217075645282705

Epoch: 6| Step: 6
Training loss: 0.7560781836509705
Validation loss: 1.6981670356565906

Epoch: 6| Step: 7
Training loss: 0.33229076862335205
Validation loss: 1.6450902569678523

Epoch: 6| Step: 8
Training loss: 0.8493164777755737
Validation loss: 1.6799040686699651

Epoch: 6| Step: 9
Training loss: 0.8615832328796387
Validation loss: 1.696380115324451

Epoch: 6| Step: 10
Training loss: 0.5897093415260315
Validation loss: 1.6565143023767779

Epoch: 6| Step: 11
Training loss: 0.8968042731285095
Validation loss: 1.6923316588965795

Epoch: 6| Step: 12
Training loss: 0.5930449366569519
Validation loss: 1.6570510274620467

Epoch: 6| Step: 13
Training loss: 0.7722993493080139
Validation loss: 1.6920177654553485

Epoch: 611| Step: 0
Training loss: 0.8985174894332886
Validation loss: 1.6523723275430742

Epoch: 6| Step: 1
Training loss: 0.5891231298446655
Validation loss: 1.660594601784983

Epoch: 6| Step: 2
Training loss: 1.194079875946045
Validation loss: 1.6912984053293865

Epoch: 6| Step: 3
Training loss: 0.9782235622406006
Validation loss: 1.7078391787826375

Epoch: 6| Step: 4
Training loss: 0.6039685010910034
Validation loss: 1.7783788839975994

Epoch: 6| Step: 5
Training loss: 0.7637184262275696
Validation loss: 1.7536300279760872

Epoch: 6| Step: 6
Training loss: 0.4916399419307709
Validation loss: 1.7277081038362236

Epoch: 6| Step: 7
Training loss: 0.5898659229278564
Validation loss: 1.7913371209175355

Epoch: 6| Step: 8
Training loss: 0.8212419152259827
Validation loss: 1.7479468378969418

Epoch: 6| Step: 9
Training loss: 0.7459497451782227
Validation loss: 1.6908849746950212

Epoch: 6| Step: 10
Training loss: 0.6577761769294739
Validation loss: 1.7745682065204909

Epoch: 6| Step: 11
Training loss: 0.5306726694107056
Validation loss: 1.727214902959844

Epoch: 6| Step: 12
Training loss: 0.5124664306640625
Validation loss: 1.7017381075889833

Epoch: 6| Step: 13
Training loss: 0.8663158416748047
Validation loss: 1.6882142789902226

Epoch: 612| Step: 0
Training loss: 0.46331170201301575
Validation loss: 1.6973112719033354

Epoch: 6| Step: 1
Training loss: 0.6916710138320923
Validation loss: 1.6839134488054501

Epoch: 6| Step: 2
Training loss: 0.6240133047103882
Validation loss: 1.6336586206190047

Epoch: 6| Step: 3
Training loss: 0.5738215446472168
Validation loss: 1.6908096574967908

Epoch: 6| Step: 4
Training loss: 0.6618615984916687
Validation loss: 1.6853109252068303

Epoch: 6| Step: 5
Training loss: 0.4631228744983673
Validation loss: 1.666693889966575

Epoch: 6| Step: 6
Training loss: 0.6713860034942627
Validation loss: 1.7356798033560477

Epoch: 6| Step: 7
Training loss: 0.7738171219825745
Validation loss: 1.6686119161626345

Epoch: 6| Step: 8
Training loss: 0.95794278383255
Validation loss: 1.6368738476948073

Epoch: 6| Step: 9
Training loss: 1.0966757535934448
Validation loss: 1.6781147603065736

Epoch: 6| Step: 10
Training loss: 0.5539807677268982
Validation loss: 1.6404638008404804

Epoch: 6| Step: 11
Training loss: 1.0010783672332764
Validation loss: 1.655622338735929

Epoch: 6| Step: 12
Training loss: 0.9699149131774902
Validation loss: 1.6770512839799285

Epoch: 6| Step: 13
Training loss: 1.413647174835205
Validation loss: 1.7014385320807015

Epoch: 613| Step: 0
Training loss: 1.1249703168869019
Validation loss: 1.6858087149999474

Epoch: 6| Step: 1
Training loss: 0.8253577947616577
Validation loss: 1.6818311727175148

Epoch: 6| Step: 2
Training loss: 0.45952627062797546
Validation loss: 1.7253779365170387

Epoch: 6| Step: 3
Training loss: 0.5277890563011169
Validation loss: 1.7498747738458778

Epoch: 6| Step: 4
Training loss: 0.30632859468460083
Validation loss: 1.678946675792817

Epoch: 6| Step: 5
Training loss: 0.4709357023239136
Validation loss: 1.6988615374411307

Epoch: 6| Step: 6
Training loss: 0.5135762691497803
Validation loss: 1.668188952630566

Epoch: 6| Step: 7
Training loss: 0.6873977184295654
Validation loss: 1.6746341143884966

Epoch: 6| Step: 8
Training loss: 0.6274728775024414
Validation loss: 1.7183165838641505

Epoch: 6| Step: 9
Training loss: 0.7396281361579895
Validation loss: 1.6435137141135432

Epoch: 6| Step: 10
Training loss: 0.743110179901123
Validation loss: 1.629173888955065

Epoch: 6| Step: 11
Training loss: 0.6173878908157349
Validation loss: 1.6988908642081804

Epoch: 6| Step: 12
Training loss: 1.2752575874328613
Validation loss: 1.6654291486227384

Epoch: 6| Step: 13
Training loss: 0.8711162209510803
Validation loss: 1.7196652389341784

Epoch: 614| Step: 0
Training loss: 0.5220432281494141
Validation loss: 1.711950461069743

Epoch: 6| Step: 1
Training loss: 0.9358017444610596
Validation loss: 1.689379676695793

Epoch: 6| Step: 2
Training loss: 0.5474585890769958
Validation loss: 1.6614116302100561

Epoch: 6| Step: 3
Training loss: 0.5181527137756348
Validation loss: 1.6576693993742748

Epoch: 6| Step: 4
Training loss: 1.2182540893554688
Validation loss: 1.6996029115492297

Epoch: 6| Step: 5
Training loss: 0.5262224078178406
Validation loss: 1.6806923099743423

Epoch: 6| Step: 6
Training loss: 0.9769316911697388
Validation loss: 1.6774114806164977

Epoch: 6| Step: 7
Training loss: 0.5721301436424255
Validation loss: 1.6441306503870154

Epoch: 6| Step: 8
Training loss: 0.7286778092384338
Validation loss: 1.724362842498287

Epoch: 6| Step: 9
Training loss: 0.5358864068984985
Validation loss: 1.7437808500823153

Epoch: 6| Step: 10
Training loss: 0.4747576415538788
Validation loss: 1.6842410192694715

Epoch: 6| Step: 11
Training loss: 0.7415688633918762
Validation loss: 1.7485772871202039

Epoch: 6| Step: 12
Training loss: 1.1995677947998047
Validation loss: 1.7428810263192782

Epoch: 6| Step: 13
Training loss: 1.0489972829818726
Validation loss: 1.7436440426816222

Epoch: 615| Step: 0
Training loss: 0.8052917718887329
Validation loss: 1.7566501299540203

Epoch: 6| Step: 1
Training loss: 0.6506118178367615
Validation loss: 1.7528180588958084

Epoch: 6| Step: 2
Training loss: 0.875997006893158
Validation loss: 1.7734639529258973

Epoch: 6| Step: 3
Training loss: 0.6700047254562378
Validation loss: 1.7733552930175618

Epoch: 6| Step: 4
Training loss: 1.0842124223709106
Validation loss: 1.7097623476418116

Epoch: 6| Step: 5
Training loss: 0.6651856303215027
Validation loss: 1.7032230489997453

Epoch: 6| Step: 6
Training loss: 0.44997739791870117
Validation loss: 1.695169270679515

Epoch: 6| Step: 7
Training loss: 0.7020182609558105
Validation loss: 1.6559581218227264

Epoch: 6| Step: 8
Training loss: 0.5583038330078125
Validation loss: 1.6304980067796604

Epoch: 6| Step: 9
Training loss: 0.891234278678894
Validation loss: 1.6664634353371077

Epoch: 6| Step: 10
Training loss: 0.9416646957397461
Validation loss: 1.6872351989951184

Epoch: 6| Step: 11
Training loss: 0.6449592709541321
Validation loss: 1.705819155580254

Epoch: 6| Step: 12
Training loss: 0.6460545659065247
Validation loss: 1.6418086072450042

Epoch: 6| Step: 13
Training loss: 0.6246750354766846
Validation loss: 1.6563241545872023

Epoch: 616| Step: 0
Training loss: 1.075538992881775
Validation loss: 1.6413513088739047

Epoch: 6| Step: 1
Training loss: 0.6940786838531494
Validation loss: 1.7107297169264926

Epoch: 6| Step: 2
Training loss: 1.481062412261963
Validation loss: 1.7218931093010852

Epoch: 6| Step: 3
Training loss: 0.6662707328796387
Validation loss: 1.6894411015254196

Epoch: 6| Step: 4
Training loss: 0.7418254613876343
Validation loss: 1.7373278640931653

Epoch: 6| Step: 5
Training loss: 0.895920991897583
Validation loss: 1.7439096281605382

Epoch: 6| Step: 6
Training loss: 0.4763534665107727
Validation loss: 1.7058364127271919

Epoch: 6| Step: 7
Training loss: 0.8639271259307861
Validation loss: 1.717236070222752

Epoch: 6| Step: 8
Training loss: 0.5984431505203247
Validation loss: 1.7384094935591503

Epoch: 6| Step: 9
Training loss: 0.6571371555328369
Validation loss: 1.7291571376144246

Epoch: 6| Step: 10
Training loss: 0.6700076460838318
Validation loss: 1.7484846115112305

Epoch: 6| Step: 11
Training loss: 0.6953743696212769
Validation loss: 1.6797575924986152

Epoch: 6| Step: 12
Training loss: 0.5880005955696106
Validation loss: 1.6963515986678421

Epoch: 6| Step: 13
Training loss: 0.7350299954414368
Validation loss: 1.6537192713829778

Epoch: 617| Step: 0
Training loss: 1.079559326171875
Validation loss: 1.7117119181540705

Epoch: 6| Step: 1
Training loss: 0.37126609683036804
Validation loss: 1.7082942147408762

Epoch: 6| Step: 2
Training loss: 1.0007562637329102
Validation loss: 1.683966431566464

Epoch: 6| Step: 3
Training loss: 0.7359330058097839
Validation loss: 1.6913024520361295

Epoch: 6| Step: 4
Training loss: 0.4090878367424011
Validation loss: 1.6898601106418076

Epoch: 6| Step: 5
Training loss: 0.9501730799674988
Validation loss: 1.7227024083496423

Epoch: 6| Step: 6
Training loss: 0.4847765862941742
Validation loss: 1.699277913698586

Epoch: 6| Step: 7
Training loss: 0.936486542224884
Validation loss: 1.716210739586943

Epoch: 6| Step: 8
Training loss: 0.796607494354248
Validation loss: 1.7076825621307536

Epoch: 6| Step: 9
Training loss: 0.5787531137466431
Validation loss: 1.710724715263613

Epoch: 6| Step: 10
Training loss: 0.5275359153747559
Validation loss: 1.713783852515682

Epoch: 6| Step: 11
Training loss: 1.0724856853485107
Validation loss: 1.6536470446535336

Epoch: 6| Step: 12
Training loss: 0.6008202433586121
Validation loss: 1.6788804813097882

Epoch: 6| Step: 13
Training loss: 0.796185314655304
Validation loss: 1.7147561516813052

Epoch: 618| Step: 0
Training loss: 0.7674069404602051
Validation loss: 1.6526204783429381

Epoch: 6| Step: 1
Training loss: 0.8476238250732422
Validation loss: 1.6991554767854753

Epoch: 6| Step: 2
Training loss: 0.7002683281898499
Validation loss: 1.6734449953161261

Epoch: 6| Step: 3
Training loss: 0.8121162056922913
Validation loss: 1.6735965013504028

Epoch: 6| Step: 4
Training loss: 0.7809217572212219
Validation loss: 1.7257575591405232

Epoch: 6| Step: 5
Training loss: 0.6630020141601562
Validation loss: 1.6263810973013602

Epoch: 6| Step: 6
Training loss: 0.5702782273292542
Validation loss: 1.7204731151621828

Epoch: 6| Step: 7
Training loss: 0.5478544235229492
Validation loss: 1.7015194380155174

Epoch: 6| Step: 8
Training loss: 0.7626413106918335
Validation loss: 1.692380851314914

Epoch: 6| Step: 9
Training loss: 1.00217604637146
Validation loss: 1.724213687322473

Epoch: 6| Step: 10
Training loss: 0.8177464008331299
Validation loss: 1.6980008156068864

Epoch: 6| Step: 11
Training loss: 0.8973400592803955
Validation loss: 1.7044510251732283

Epoch: 6| Step: 12
Training loss: 0.4031933546066284
Validation loss: 1.6687481428987236

Epoch: 6| Step: 13
Training loss: 0.3805335760116577
Validation loss: 1.6684497235923685

Epoch: 619| Step: 0
Training loss: 0.4802939295768738
Validation loss: 1.7004857909294866

Epoch: 6| Step: 1
Training loss: 0.6610386371612549
Validation loss: 1.6527557937047814

Epoch: 6| Step: 2
Training loss: 0.47802650928497314
Validation loss: 1.6913168020145868

Epoch: 6| Step: 3
Training loss: 0.43215593695640564
Validation loss: 1.704671282922068

Epoch: 6| Step: 4
Training loss: 0.9149636030197144
Validation loss: 1.6741520730398034

Epoch: 6| Step: 5
Training loss: 0.6609696745872498
Validation loss: 1.7227404822585404

Epoch: 6| Step: 6
Training loss: 1.2658544778823853
Validation loss: 1.7037822020951139

Epoch: 6| Step: 7
Training loss: 0.6858761310577393
Validation loss: 1.7083623306725615

Epoch: 6| Step: 8
Training loss: 0.6007649898529053
Validation loss: 1.6461648761585195

Epoch: 6| Step: 9
Training loss: 0.698689877986908
Validation loss: 1.7296309676221622

Epoch: 6| Step: 10
Training loss: 0.8015748858451843
Validation loss: 1.7239564413665442

Epoch: 6| Step: 11
Training loss: 0.7250545024871826
Validation loss: 1.6681094067071074

Epoch: 6| Step: 12
Training loss: 1.261449933052063
Validation loss: 1.6540066772891628

Epoch: 6| Step: 13
Training loss: 0.7299323678016663
Validation loss: 1.6693582816790509

Epoch: 620| Step: 0
Training loss: 0.5694437026977539
Validation loss: 1.6962933732617287

Epoch: 6| Step: 1
Training loss: 0.4880799651145935
Validation loss: 1.7049399370788245

Epoch: 6| Step: 2
Training loss: 0.6882319450378418
Validation loss: 1.7755305279967606

Epoch: 6| Step: 3
Training loss: 0.8305258750915527
Validation loss: 1.7614991023976316

Epoch: 6| Step: 4
Training loss: 0.6545888781547546
Validation loss: 1.7492123675602738

Epoch: 6| Step: 5
Training loss: 0.785529613494873
Validation loss: 1.6846404126895371

Epoch: 6| Step: 6
Training loss: 0.7709159851074219
Validation loss: 1.7442757109160065

Epoch: 6| Step: 7
Training loss: 0.6847391724586487
Validation loss: 1.712877986251667

Epoch: 6| Step: 8
Training loss: 0.7017805576324463
Validation loss: 1.6909017883321291

Epoch: 6| Step: 9
Training loss: 0.4894633889198303
Validation loss: 1.7379767535835184

Epoch: 6| Step: 10
Training loss: 1.1152522563934326
Validation loss: 1.6801956712558705

Epoch: 6| Step: 11
Training loss: 0.8811888694763184
Validation loss: 1.7378197382855158

Epoch: 6| Step: 12
Training loss: 1.0907336473464966
Validation loss: 1.6966603994369507

Epoch: 6| Step: 13
Training loss: 0.7624030709266663
Validation loss: 1.708602766836843

Epoch: 621| Step: 0
Training loss: 0.54655921459198
Validation loss: 1.6909179674681796

Epoch: 6| Step: 1
Training loss: 0.802688479423523
Validation loss: 1.747266154135427

Epoch: 6| Step: 2
Training loss: 1.1936085224151611
Validation loss: 1.6470534391300653

Epoch: 6| Step: 3
Training loss: 0.7424678802490234
Validation loss: 1.6440187679824008

Epoch: 6| Step: 4
Training loss: 0.6556129455566406
Validation loss: 1.6876073114333614

Epoch: 6| Step: 5
Training loss: 0.5864666700363159
Validation loss: 1.7136793072505663

Epoch: 6| Step: 6
Training loss: 0.7087945938110352
Validation loss: 1.6779201094822218

Epoch: 6| Step: 7
Training loss: 0.7857102155685425
Validation loss: 1.7343695317545245

Epoch: 6| Step: 8
Training loss: 0.7739524841308594
Validation loss: 1.701662391744634

Epoch: 6| Step: 9
Training loss: 0.509852945804596
Validation loss: 1.6632362065776702

Epoch: 6| Step: 10
Training loss: 0.9893699884414673
Validation loss: 1.7492578824361165

Epoch: 6| Step: 11
Training loss: 0.5831714868545532
Validation loss: 1.723807752773326

Epoch: 6| Step: 12
Training loss: 0.7077618837356567
Validation loss: 1.675796062715592

Epoch: 6| Step: 13
Training loss: 1.4627270698547363
Validation loss: 1.6919746616835236

Epoch: 622| Step: 0
Training loss: 0.7290716171264648
Validation loss: 1.6477295173111783

Epoch: 6| Step: 1
Training loss: 0.5434510111808777
Validation loss: 1.7000496092663016

Epoch: 6| Step: 2
Training loss: 0.861088752746582
Validation loss: 1.6868187548011861

Epoch: 6| Step: 3
Training loss: 0.6611047983169556
Validation loss: 1.7051908598151257

Epoch: 6| Step: 4
Training loss: 0.4951232671737671
Validation loss: 1.6540214515501452

Epoch: 6| Step: 5
Training loss: 0.7031269669532776
Validation loss: 1.6807775535891134

Epoch: 6| Step: 6
Training loss: 0.7151206135749817
Validation loss: 1.6994580837988085

Epoch: 6| Step: 7
Training loss: 0.7514158487319946
Validation loss: 1.6230153473474647

Epoch: 6| Step: 8
Training loss: 0.6674532890319824
Validation loss: 1.6927734831328034

Epoch: 6| Step: 9
Training loss: 1.1359158754348755
Validation loss: 1.7209434791277813

Epoch: 6| Step: 10
Training loss: 0.8026936650276184
Validation loss: 1.6646217594864547

Epoch: 6| Step: 11
Training loss: 0.8370960354804993
Validation loss: 1.6984283308829031

Epoch: 6| Step: 12
Training loss: 0.8023334741592407
Validation loss: 1.6745854680256178

Epoch: 6| Step: 13
Training loss: 1.0957484245300293
Validation loss: 1.6782167201401086

Epoch: 623| Step: 0
Training loss: 0.7056148052215576
Validation loss: 1.6515573673350836

Epoch: 6| Step: 1
Training loss: 0.541475772857666
Validation loss: 1.669077697620597

Epoch: 6| Step: 2
Training loss: 1.525382161140442
Validation loss: 1.6880397283902733

Epoch: 6| Step: 3
Training loss: 0.7977412939071655
Validation loss: 1.7473721324756581

Epoch: 6| Step: 4
Training loss: 0.748723030090332
Validation loss: 1.733313113130549

Epoch: 6| Step: 5
Training loss: 0.9491866230964661
Validation loss: 1.7254445334916473

Epoch: 6| Step: 6
Training loss: 0.7507901787757874
Validation loss: 1.710960126692249

Epoch: 6| Step: 7
Training loss: 0.47204500436782837
Validation loss: 1.7086320038764709

Epoch: 6| Step: 8
Training loss: 0.7179621458053589
Validation loss: 1.7134740903813352

Epoch: 6| Step: 9
Training loss: 0.29710960388183594
Validation loss: 1.663880527660411

Epoch: 6| Step: 10
Training loss: 0.7560076713562012
Validation loss: 1.6552186448086974

Epoch: 6| Step: 11
Training loss: 0.7194647789001465
Validation loss: 1.685857428017483

Epoch: 6| Step: 12
Training loss: 0.5442585945129395
Validation loss: 1.643942448400682

Epoch: 6| Step: 13
Training loss: 0.9892959594726562
Validation loss: 1.6778451704209851

Epoch: 624| Step: 0
Training loss: 0.9592409729957581
Validation loss: 1.6644612807099537

Epoch: 6| Step: 1
Training loss: 1.1677405834197998
Validation loss: 1.7137750271827943

Epoch: 6| Step: 2
Training loss: 0.6452292799949646
Validation loss: 1.6604363200485066

Epoch: 6| Step: 3
Training loss: 0.8188549280166626
Validation loss: 1.6581154830994145

Epoch: 6| Step: 4
Training loss: 0.6576252579689026
Validation loss: 1.712935265674386

Epoch: 6| Step: 5
Training loss: 0.9922437071800232
Validation loss: 1.6689120697718796

Epoch: 6| Step: 6
Training loss: 0.2516767084598541
Validation loss: 1.679153274464351

Epoch: 6| Step: 7
Training loss: 0.8797847628593445
Validation loss: 1.719500905723982

Epoch: 6| Step: 8
Training loss: 0.7731583118438721
Validation loss: 1.672912028528029

Epoch: 6| Step: 9
Training loss: 0.5475162267684937
Validation loss: 1.7630551117722706

Epoch: 6| Step: 10
Training loss: 0.6981704831123352
Validation loss: 1.765270313908977

Epoch: 6| Step: 11
Training loss: 1.2066383361816406
Validation loss: 1.7890238787538262

Epoch: 6| Step: 12
Training loss: 0.6818429231643677
Validation loss: 1.8263395268429992

Epoch: 6| Step: 13
Training loss: 0.42971691489219666
Validation loss: 1.717818465284122

Epoch: 625| Step: 0
Training loss: 0.5819263458251953
Validation loss: 1.7349725102865567

Epoch: 6| Step: 1
Training loss: 0.5429279804229736
Validation loss: 1.762653999431159

Epoch: 6| Step: 2
Training loss: 1.0853362083435059
Validation loss: 1.6649174472337127

Epoch: 6| Step: 3
Training loss: 0.5252456068992615
Validation loss: 1.7159103872955486

Epoch: 6| Step: 4
Training loss: 0.5488616228103638
Validation loss: 1.694636502573567

Epoch: 6| Step: 5
Training loss: 0.3543912172317505
Validation loss: 1.6690058298008417

Epoch: 6| Step: 6
Training loss: 0.6525232791900635
Validation loss: 1.7076985105391471

Epoch: 6| Step: 7
Training loss: 0.6283133029937744
Validation loss: 1.6610651067508164

Epoch: 6| Step: 8
Training loss: 0.9252884984016418
Validation loss: 1.7174345177988852

Epoch: 6| Step: 9
Training loss: 0.6431282758712769
Validation loss: 1.6969157547079108

Epoch: 6| Step: 10
Training loss: 0.8617266416549683
Validation loss: 1.7369336607635661

Epoch: 6| Step: 11
Training loss: 0.8857021331787109
Validation loss: 1.6845784392408145

Epoch: 6| Step: 12
Training loss: 1.2924234867095947
Validation loss: 1.6846359237547843

Epoch: 6| Step: 13
Training loss: 0.7294957041740417
Validation loss: 1.6938892820829987

Epoch: 626| Step: 0
Training loss: 0.5226954221725464
Validation loss: 1.6785444546771306

Epoch: 6| Step: 1
Training loss: 0.7807066440582275
Validation loss: 1.745023271088959

Epoch: 6| Step: 2
Training loss: 0.44061046838760376
Validation loss: 1.6971312953579811

Epoch: 6| Step: 3
Training loss: 0.5570844411849976
Validation loss: 1.759504569474087

Epoch: 6| Step: 4
Training loss: 0.7034708261489868
Validation loss: 1.738026225438682

Epoch: 6| Step: 5
Training loss: 0.571337878704071
Validation loss: 1.7020939447546517

Epoch: 6| Step: 6
Training loss: 0.5118283033370972
Validation loss: 1.799923349452275

Epoch: 6| Step: 7
Training loss: 1.4167296886444092
Validation loss: 1.7730466063304613

Epoch: 6| Step: 8
Training loss: 0.7163786292076111
Validation loss: 1.6763112006648895

Epoch: 6| Step: 9
Training loss: 1.1863843202590942
Validation loss: 1.7200479738173946

Epoch: 6| Step: 10
Training loss: 0.7067494988441467
Validation loss: 1.6977944194629628

Epoch: 6| Step: 11
Training loss: 0.2388787716627121
Validation loss: 1.6733638317354265

Epoch: 6| Step: 12
Training loss: 0.7281367182731628
Validation loss: 1.6981214515624508

Epoch: 6| Step: 13
Training loss: 1.1033775806427002
Validation loss: 1.7085096489998601

Epoch: 627| Step: 0
Training loss: 1.0786137580871582
Validation loss: 1.6730569665149977

Epoch: 6| Step: 1
Training loss: 0.4599614441394806
Validation loss: 1.5981583338911816

Epoch: 6| Step: 2
Training loss: 0.9226466417312622
Validation loss: 1.6844727505919754

Epoch: 6| Step: 3
Training loss: 0.4465552568435669
Validation loss: 1.7014160386977657

Epoch: 6| Step: 4
Training loss: 0.4931302070617676
Validation loss: 1.6308934047657957

Epoch: 6| Step: 5
Training loss: 0.9248201847076416
Validation loss: 1.7218425568713938

Epoch: 6| Step: 6
Training loss: 0.8883799314498901
Validation loss: 1.6654873266015002

Epoch: 6| Step: 7
Training loss: 0.8437787294387817
Validation loss: 1.7237644990285237

Epoch: 6| Step: 8
Training loss: 0.48238134384155273
Validation loss: 1.7060424512432468

Epoch: 6| Step: 9
Training loss: 0.7949895858764648
Validation loss: 1.7235327536059963

Epoch: 6| Step: 10
Training loss: 0.9894905686378479
Validation loss: 1.7299883416903916

Epoch: 6| Step: 11
Training loss: 0.5841571688652039
Validation loss: 1.7355064422853532

Epoch: 6| Step: 12
Training loss: 0.6992889046669006
Validation loss: 1.6603099569197624

Epoch: 6| Step: 13
Training loss: 0.4742489457130432
Validation loss: 1.6938913970865228

Epoch: 628| Step: 0
Training loss: 0.4244993031024933
Validation loss: 1.7419424544098556

Epoch: 6| Step: 1
Training loss: 0.809131383895874
Validation loss: 1.728443004751718

Epoch: 6| Step: 2
Training loss: 0.6345621347427368
Validation loss: 1.7312928604823288

Epoch: 6| Step: 3
Training loss: 0.7457650303840637
Validation loss: 1.700444995716054

Epoch: 6| Step: 4
Training loss: 0.5764685273170471
Validation loss: 1.7215640570527764

Epoch: 6| Step: 5
Training loss: 0.5479187965393066
Validation loss: 1.6842168825928883

Epoch: 6| Step: 6
Training loss: 0.6860656142234802
Validation loss: 1.6770170222046554

Epoch: 6| Step: 7
Training loss: 0.7222760319709778
Validation loss: 1.6947618492187992

Epoch: 6| Step: 8
Training loss: 0.6253033876419067
Validation loss: 1.681590255870614

Epoch: 6| Step: 9
Training loss: 0.8378734588623047
Validation loss: 1.6856587804773802

Epoch: 6| Step: 10
Training loss: 0.682563304901123
Validation loss: 1.716698415817753

Epoch: 6| Step: 11
Training loss: 1.0970970392227173
Validation loss: 1.604976406661413

Epoch: 6| Step: 12
Training loss: 0.695185124874115
Validation loss: 1.7081688245137532

Epoch: 6| Step: 13
Training loss: 0.8255487084388733
Validation loss: 1.6743838094895886

Epoch: 629| Step: 0
Training loss: 0.7186110019683838
Validation loss: 1.6324686683634275

Epoch: 6| Step: 1
Training loss: 0.8280903100967407
Validation loss: 1.674190200785155

Epoch: 6| Step: 2
Training loss: 0.5556173324584961
Validation loss: 1.7317391621169222

Epoch: 6| Step: 3
Training loss: 0.9279948472976685
Validation loss: 1.7103504519308768

Epoch: 6| Step: 4
Training loss: 0.5522469282150269
Validation loss: 1.6803173775314002

Epoch: 6| Step: 5
Training loss: 1.0986921787261963
Validation loss: 1.6520046187985329

Epoch: 6| Step: 6
Training loss: 0.5086851716041565
Validation loss: 1.7145112304277317

Epoch: 6| Step: 7
Training loss: 0.6241726875305176
Validation loss: 1.7025985692137031

Epoch: 6| Step: 8
Training loss: 0.783064603805542
Validation loss: 1.7243427089465562

Epoch: 6| Step: 9
Training loss: 0.8751547932624817
Validation loss: 1.702144702275594

Epoch: 6| Step: 10
Training loss: 0.4994232654571533
Validation loss: 1.750967594885057

Epoch: 6| Step: 11
Training loss: 0.9236587882041931
Validation loss: 1.7246971168825704

Epoch: 6| Step: 12
Training loss: 0.8090610504150391
Validation loss: 1.7125405009074877

Epoch: 6| Step: 13
Training loss: 0.5112485289573669
Validation loss: 1.7405497925255888

Epoch: 630| Step: 0
Training loss: 0.6099231839179993
Validation loss: 1.731313177334365

Epoch: 6| Step: 1
Training loss: 0.7799646258354187
Validation loss: 1.7325652184024933

Epoch: 6| Step: 2
Training loss: 0.48382842540740967
Validation loss: 1.7008214624979163

Epoch: 6| Step: 3
Training loss: 1.0127956867218018
Validation loss: 1.7000754917821577

Epoch: 6| Step: 4
Training loss: 0.38330864906311035
Validation loss: 1.7674442491223734

Epoch: 6| Step: 5
Training loss: 1.0189790725708008
Validation loss: 1.6805167646818264

Epoch: 6| Step: 6
Training loss: 0.7997786402702332
Validation loss: 1.6757124265034993

Epoch: 6| Step: 7
Training loss: 0.7242909073829651
Validation loss: 1.7494144029514764

Epoch: 6| Step: 8
Training loss: 0.9576008915901184
Validation loss: 1.633291385507071

Epoch: 6| Step: 9
Training loss: 0.6821225881576538
Validation loss: 1.6592249857482089

Epoch: 6| Step: 10
Training loss: 0.25232401490211487
Validation loss: 1.6774017246820594

Epoch: 6| Step: 11
Training loss: 0.8391995429992676
Validation loss: 1.6149493084158948

Epoch: 6| Step: 12
Training loss: 0.519314706325531
Validation loss: 1.714942568091936

Epoch: 6| Step: 13
Training loss: 0.4858610928058624
Validation loss: 1.6907551032240673

Epoch: 631| Step: 0
Training loss: 0.5418169498443604
Validation loss: 1.6990471886050316

Epoch: 6| Step: 1
Training loss: 0.5480281710624695
Validation loss: 1.6960303539870887

Epoch: 6| Step: 2
Training loss: 1.481043815612793
Validation loss: 1.6469306574072888

Epoch: 6| Step: 3
Training loss: 0.615667998790741
Validation loss: 1.7057708745361657

Epoch: 6| Step: 4
Training loss: 0.6792882680892944
Validation loss: 1.6923040446414743

Epoch: 6| Step: 5
Training loss: 0.6401451826095581
Validation loss: 1.700490609292061

Epoch: 6| Step: 6
Training loss: 0.9496256709098816
Validation loss: 1.6710435857055008

Epoch: 6| Step: 7
Training loss: 0.7677356600761414
Validation loss: 1.734030177516322

Epoch: 6| Step: 8
Training loss: 0.4927578866481781
Validation loss: 1.690921305328287

Epoch: 6| Step: 9
Training loss: 0.6099233627319336
Validation loss: 1.6760212247089674

Epoch: 6| Step: 10
Training loss: 0.589233934879303
Validation loss: 1.686781644821167

Epoch: 6| Step: 11
Training loss: 0.7112167477607727
Validation loss: 1.6974152134310814

Epoch: 6| Step: 12
Training loss: 0.6605187654495239
Validation loss: 1.7087811244431363

Epoch: 6| Step: 13
Training loss: 0.8702224493026733
Validation loss: 1.701146360366575

Epoch: 632| Step: 0
Training loss: 0.9017734527587891
Validation loss: 1.6628591040129304

Epoch: 6| Step: 1
Training loss: 0.5618914365768433
Validation loss: 1.6757128982133762

Epoch: 6| Step: 2
Training loss: 0.8252370357513428
Validation loss: 1.6716292410768487

Epoch: 6| Step: 3
Training loss: 0.8135982751846313
Validation loss: 1.632133549259555

Epoch: 6| Step: 4
Training loss: 0.4546293020248413
Validation loss: 1.6308208844994987

Epoch: 6| Step: 5
Training loss: 0.6559047102928162
Validation loss: 1.633761477085852

Epoch: 6| Step: 6
Training loss: 0.34358349442481995
Validation loss: 1.6763580281247374

Epoch: 6| Step: 7
Training loss: 0.7127312421798706
Validation loss: 1.7140687140085364

Epoch: 6| Step: 8
Training loss: 0.7255598306655884
Validation loss: 1.703117226400683

Epoch: 6| Step: 9
Training loss: 0.57096928358078
Validation loss: 1.7145863348437893

Epoch: 6| Step: 10
Training loss: 0.5623514652252197
Validation loss: 1.652235443874072

Epoch: 6| Step: 11
Training loss: 0.8886019587516785
Validation loss: 1.7239106342356691

Epoch: 6| Step: 12
Training loss: 1.1354975700378418
Validation loss: 1.6748867983459144

Epoch: 6| Step: 13
Training loss: 0.5571567416191101
Validation loss: 1.705485906652225

Epoch: 633| Step: 0
Training loss: 0.683993935585022
Validation loss: 1.7032017182278376

Epoch: 6| Step: 1
Training loss: 0.6648849844932556
Validation loss: 1.662375739825669

Epoch: 6| Step: 2
Training loss: 0.5907196998596191
Validation loss: 1.7032476445680023

Epoch: 6| Step: 3
Training loss: 1.130476951599121
Validation loss: 1.7341973461130613

Epoch: 6| Step: 4
Training loss: 0.6214288473129272
Validation loss: 1.7065613013441845

Epoch: 6| Step: 5
Training loss: 0.4919528365135193
Validation loss: 1.6352754536495413

Epoch: 6| Step: 6
Training loss: 0.7714176177978516
Validation loss: 1.6688714668314943

Epoch: 6| Step: 7
Training loss: 0.5642129182815552
Validation loss: 1.6652938883791688

Epoch: 6| Step: 8
Training loss: 0.8676782250404358
Validation loss: 1.6522004988885695

Epoch: 6| Step: 9
Training loss: 0.5193960070610046
Validation loss: 1.6778104715449835

Epoch: 6| Step: 10
Training loss: 0.7436929941177368
Validation loss: 1.727303788226138

Epoch: 6| Step: 11
Training loss: 0.7156451940536499
Validation loss: 1.6789610719168058

Epoch: 6| Step: 12
Training loss: 0.600001871585846
Validation loss: 1.7374257195380427

Epoch: 6| Step: 13
Training loss: 1.0643706321716309
Validation loss: 1.7015271071464784

Epoch: 634| Step: 0
Training loss: 0.8752983808517456
Validation loss: 1.7194974909546554

Epoch: 6| Step: 1
Training loss: 1.0273182392120361
Validation loss: 1.7106667603215864

Epoch: 6| Step: 2
Training loss: 0.7098792195320129
Validation loss: 1.6861940430056663

Epoch: 6| Step: 3
Training loss: 0.8131312131881714
Validation loss: 1.810677247662698

Epoch: 6| Step: 4
Training loss: 0.6227638125419617
Validation loss: 1.6815523793620448

Epoch: 6| Step: 5
Training loss: 0.5957998037338257
Validation loss: 1.704357611235752

Epoch: 6| Step: 6
Training loss: 0.6784988641738892
Validation loss: 1.713944544074356

Epoch: 6| Step: 7
Training loss: 1.017557144165039
Validation loss: 1.734688433267737

Epoch: 6| Step: 8
Training loss: 0.34966492652893066
Validation loss: 1.668819260212683

Epoch: 6| Step: 9
Training loss: 0.8306540846824646
Validation loss: 1.6594097909107004

Epoch: 6| Step: 10
Training loss: 0.8433387875556946
Validation loss: 1.6927837030861967

Epoch: 6| Step: 11
Training loss: 0.5428247451782227
Validation loss: 1.6298551379993398

Epoch: 6| Step: 12
Training loss: 0.6577332615852356
Validation loss: 1.659350872039795

Epoch: 6| Step: 13
Training loss: 0.4547869861125946
Validation loss: 1.6953275280614053

Epoch: 635| Step: 0
Training loss: 1.161118507385254
Validation loss: 1.6741344236558484

Epoch: 6| Step: 1
Training loss: 0.8038051724433899
Validation loss: 1.6487335569115096

Epoch: 6| Step: 2
Training loss: 0.7722873091697693
Validation loss: 1.6468986862449235

Epoch: 6| Step: 3
Training loss: 0.9753459095954895
Validation loss: 1.6379831952433432

Epoch: 6| Step: 4
Training loss: 0.5345926880836487
Validation loss: 1.6420963297608078

Epoch: 6| Step: 5
Training loss: 0.7882437705993652
Validation loss: 1.7455675012321883

Epoch: 6| Step: 6
Training loss: 0.7550162672996521
Validation loss: 1.7453419085471862

Epoch: 6| Step: 7
Training loss: 0.750838041305542
Validation loss: 1.7171917474398048

Epoch: 6| Step: 8
Training loss: 0.33752769231796265
Validation loss: 1.7460803972777499

Epoch: 6| Step: 9
Training loss: 0.6295939683914185
Validation loss: 1.6858677120618923

Epoch: 6| Step: 10
Training loss: 0.4739343523979187
Validation loss: 1.7470702266180387

Epoch: 6| Step: 11
Training loss: 0.9640365242958069
Validation loss: 1.677302747644404

Epoch: 6| Step: 12
Training loss: 0.6789454221725464
Validation loss: 1.6407446694630448

Epoch: 6| Step: 13
Training loss: 0.38964584469795227
Validation loss: 1.6937712456590386

Epoch: 636| Step: 0
Training loss: 0.3211900293827057
Validation loss: 1.7105702597607848

Epoch: 6| Step: 1
Training loss: 1.0471125841140747
Validation loss: 1.7182845325880154

Epoch: 6| Step: 2
Training loss: 0.7404778003692627
Validation loss: 1.6728738354098411

Epoch: 6| Step: 3
Training loss: 0.8084903955459595
Validation loss: 1.6576264519845285

Epoch: 6| Step: 4
Training loss: 0.7788310647010803
Validation loss: 1.6217459619686168

Epoch: 6| Step: 5
Training loss: 0.4084264636039734
Validation loss: 1.6898543052775885

Epoch: 6| Step: 6
Training loss: 0.6486003398895264
Validation loss: 1.702510767085578

Epoch: 6| Step: 7
Training loss: 0.5607284307479858
Validation loss: 1.6778132454041512

Epoch: 6| Step: 8
Training loss: 0.6620926856994629
Validation loss: 1.631219284508818

Epoch: 6| Step: 9
Training loss: 0.6693307757377625
Validation loss: 1.6593702813630462

Epoch: 6| Step: 10
Training loss: 0.7671231031417847
Validation loss: 1.684994787298223

Epoch: 6| Step: 11
Training loss: 0.6061353087425232
Validation loss: 1.699798084074451

Epoch: 6| Step: 12
Training loss: 1.150037169456482
Validation loss: 1.672053998516452

Epoch: 6| Step: 13
Training loss: 0.6849010586738586
Validation loss: 1.7119551256138792

Epoch: 637| Step: 0
Training loss: 0.4706021845340729
Validation loss: 1.6202228120578233

Epoch: 6| Step: 1
Training loss: 0.43977415561676025
Validation loss: 1.6587365211979035

Epoch: 6| Step: 2
Training loss: 1.1502349376678467
Validation loss: 1.6480979099068591

Epoch: 6| Step: 3
Training loss: 0.5811805725097656
Validation loss: 1.6727267670375046

Epoch: 6| Step: 4
Training loss: 0.6320745944976807
Validation loss: 1.6845787686686362

Epoch: 6| Step: 5
Training loss: 1.1427116394042969
Validation loss: 1.6487755967724709

Epoch: 6| Step: 6
Training loss: 0.8262491226196289
Validation loss: 1.6846977997851629

Epoch: 6| Step: 7
Training loss: 0.8664809465408325
Validation loss: 1.6078530870458132

Epoch: 6| Step: 8
Training loss: 0.8185024857521057
Validation loss: 1.6816081513640702

Epoch: 6| Step: 9
Training loss: 0.7288318872451782
Validation loss: 1.7066153608342653

Epoch: 6| Step: 10
Training loss: 0.8624979257583618
Validation loss: 1.6569531809899114

Epoch: 6| Step: 11
Training loss: 0.401518315076828
Validation loss: 1.6964027625258251

Epoch: 6| Step: 12
Training loss: 0.6873616576194763
Validation loss: 1.7385772735841813

Epoch: 6| Step: 13
Training loss: 0.44419601559638977
Validation loss: 1.689270580968549

Epoch: 638| Step: 0
Training loss: 0.6215933561325073
Validation loss: 1.7406839504036853

Epoch: 6| Step: 1
Training loss: 0.7842618823051453
Validation loss: 1.6765231240180232

Epoch: 6| Step: 2
Training loss: 1.1136455535888672
Validation loss: 1.6387348918504612

Epoch: 6| Step: 3
Training loss: 0.5266648530960083
Validation loss: 1.7045679053952616

Epoch: 6| Step: 4
Training loss: 0.7127739191055298
Validation loss: 1.6956503673266339

Epoch: 6| Step: 5
Training loss: 0.5955647230148315
Validation loss: 1.6499585079890426

Epoch: 6| Step: 6
Training loss: 0.7484158873558044
Validation loss: 1.7082138305069299

Epoch: 6| Step: 7
Training loss: 0.7340523600578308
Validation loss: 1.6796919274073776

Epoch: 6| Step: 8
Training loss: 0.778828501701355
Validation loss: 1.7094661305027623

Epoch: 6| Step: 9
Training loss: 0.5742648839950562
Validation loss: 1.6785834104784074

Epoch: 6| Step: 10
Training loss: 0.7054849863052368
Validation loss: 1.6280712876268613

Epoch: 6| Step: 11
Training loss: 0.8954086303710938
Validation loss: 1.692123297722109

Epoch: 6| Step: 12
Training loss: 0.6594131588935852
Validation loss: 1.6513276894887288

Epoch: 6| Step: 13
Training loss: 0.7160879373550415
Validation loss: 1.6705968065928387

Epoch: 639| Step: 0
Training loss: 0.649171769618988
Validation loss: 1.71948274489372

Epoch: 6| Step: 1
Training loss: 0.8965153098106384
Validation loss: 1.7609787192395938

Epoch: 6| Step: 2
Training loss: 0.7872291803359985
Validation loss: 1.6895336515160018

Epoch: 6| Step: 3
Training loss: 0.6976534128189087
Validation loss: 1.7039504115299513

Epoch: 6| Step: 4
Training loss: 1.1101911067962646
Validation loss: 1.7636823846447853

Epoch: 6| Step: 5
Training loss: 0.7152048349380493
Validation loss: 1.7064520466712214

Epoch: 6| Step: 6
Training loss: 0.4644117057323456
Validation loss: 1.6888371103553361

Epoch: 6| Step: 7
Training loss: 0.8167829513549805
Validation loss: 1.6828813822038713

Epoch: 6| Step: 8
Training loss: 0.7116219401359558
Validation loss: 1.6683002748797018

Epoch: 6| Step: 9
Training loss: 0.529037594795227
Validation loss: 1.638056332065213

Epoch: 6| Step: 10
Training loss: 0.8154211640357971
Validation loss: 1.6766822158649404

Epoch: 6| Step: 11
Training loss: 0.7718411684036255
Validation loss: 1.7053352145738498

Epoch: 6| Step: 12
Training loss: 0.3393205404281616
Validation loss: 1.6176213231138004

Epoch: 6| Step: 13
Training loss: 0.6446740627288818
Validation loss: 1.65046473087803

Epoch: 640| Step: 0
Training loss: 0.7042558193206787
Validation loss: 1.6271059410546416

Epoch: 6| Step: 1
Training loss: 0.8702974915504456
Validation loss: 1.6384000983289493

Epoch: 6| Step: 2
Training loss: 0.4968789517879486
Validation loss: 1.6374190827851653

Epoch: 6| Step: 3
Training loss: 0.9135948419570923
Validation loss: 1.6951308775973577

Epoch: 6| Step: 4
Training loss: 0.4144006669521332
Validation loss: 1.6962053468150478

Epoch: 6| Step: 5
Training loss: 1.0246548652648926
Validation loss: 1.738822840875195

Epoch: 6| Step: 6
Training loss: 0.7245363593101501
Validation loss: 1.752106571710238

Epoch: 6| Step: 7
Training loss: 0.8280181884765625
Validation loss: 1.7454902754035047

Epoch: 6| Step: 8
Training loss: 0.7774575352668762
Validation loss: 1.7868107416296517

Epoch: 6| Step: 9
Training loss: 0.8600708842277527
Validation loss: 1.7891350356481408

Epoch: 6| Step: 10
Training loss: 0.7357619404792786
Validation loss: 1.7239526112874348

Epoch: 6| Step: 11
Training loss: 0.561731219291687
Validation loss: 1.7168526264929003

Epoch: 6| Step: 12
Training loss: 1.0953013896942139
Validation loss: 1.7191495139111754

Epoch: 6| Step: 13
Training loss: 0.5988988876342773
Validation loss: 1.6733542885831607

Epoch: 641| Step: 0
Training loss: 0.6739588975906372
Validation loss: 1.6048601852950228

Epoch: 6| Step: 1
Training loss: 0.768883466720581
Validation loss: 1.6557376461644326

Epoch: 6| Step: 2
Training loss: 0.9384335279464722
Validation loss: 1.6613404135550223

Epoch: 6| Step: 3
Training loss: 0.7612934708595276
Validation loss: 1.664567224441036

Epoch: 6| Step: 4
Training loss: 0.6581901907920837
Validation loss: 1.6955252988364107

Epoch: 6| Step: 5
Training loss: 0.6861727833747864
Validation loss: 1.7583818640760196

Epoch: 6| Step: 6
Training loss: 0.9968576431274414
Validation loss: 1.652797584892601

Epoch: 6| Step: 7
Training loss: 0.699438214302063
Validation loss: 1.6785069819419616

Epoch: 6| Step: 8
Training loss: 0.38622596859931946
Validation loss: 1.6834481480301067

Epoch: 6| Step: 9
Training loss: 1.0340757369995117
Validation loss: 1.6705223373187486

Epoch: 6| Step: 10
Training loss: 0.8657546043395996
Validation loss: 1.6889048801955355

Epoch: 6| Step: 11
Training loss: 0.7606430053710938
Validation loss: 1.709675423560604

Epoch: 6| Step: 12
Training loss: 0.457710325717926
Validation loss: 1.7338098697764899

Epoch: 6| Step: 13
Training loss: 0.41791900992393494
Validation loss: 1.7114455969102922

Epoch: 642| Step: 0
Training loss: 0.4820534288883209
Validation loss: 1.6537694738757225

Epoch: 6| Step: 1
Training loss: 1.177372694015503
Validation loss: 1.7099685604854296

Epoch: 6| Step: 2
Training loss: 0.466569721698761
Validation loss: 1.7118387760654572

Epoch: 6| Step: 3
Training loss: 0.8587017059326172
Validation loss: 1.6730141370527205

Epoch: 6| Step: 4
Training loss: 0.8735464215278625
Validation loss: 1.711139735355172

Epoch: 6| Step: 5
Training loss: 0.4994550347328186
Validation loss: 1.7076466493709113

Epoch: 6| Step: 6
Training loss: 0.5451856851577759
Validation loss: 1.636149775597357

Epoch: 6| Step: 7
Training loss: 0.5307386517524719
Validation loss: 1.687627644949062

Epoch: 6| Step: 8
Training loss: 1.0793524980545044
Validation loss: 1.6841407463114748

Epoch: 6| Step: 9
Training loss: 1.1999115943908691
Validation loss: 1.6394643578478085

Epoch: 6| Step: 10
Training loss: 0.8759728670120239
Validation loss: 1.6645650363737536

Epoch: 6| Step: 11
Training loss: 0.42548972368240356
Validation loss: 1.694947470900833

Epoch: 6| Step: 12
Training loss: 0.3860447406768799
Validation loss: 1.7394837987038396

Epoch: 6| Step: 13
Training loss: 0.5610042810440063
Validation loss: 1.7100935097663634

Epoch: 643| Step: 0
Training loss: 0.5249437689781189
Validation loss: 1.7237191430984005

Epoch: 6| Step: 1
Training loss: 0.5973711013793945
Validation loss: 1.693427767804874

Epoch: 6| Step: 2
Training loss: 0.5132803320884705
Validation loss: 1.7465821901957195

Epoch: 6| Step: 3
Training loss: 1.0057017803192139
Validation loss: 1.7010416651284823

Epoch: 6| Step: 4
Training loss: 0.5534697771072388
Validation loss: 1.6811245795219176

Epoch: 6| Step: 5
Training loss: 1.149383783340454
Validation loss: 1.6536952757066297

Epoch: 6| Step: 6
Training loss: 0.6565576195716858
Validation loss: 1.7019963854102678

Epoch: 6| Step: 7
Training loss: 0.9140353798866272
Validation loss: 1.6530568471518896

Epoch: 6| Step: 8
Training loss: 0.7105180025100708
Validation loss: 1.679471887567992

Epoch: 6| Step: 9
Training loss: 0.44898706674575806
Validation loss: 1.6065010639929003

Epoch: 6| Step: 10
Training loss: 1.1316587924957275
Validation loss: 1.625856618727407

Epoch: 6| Step: 11
Training loss: 0.7411608695983887
Validation loss: 1.696029258030717

Epoch: 6| Step: 12
Training loss: 0.5197523832321167
Validation loss: 1.699221013694681

Epoch: 6| Step: 13
Training loss: 0.7123280763626099
Validation loss: 1.6821879904757264

Epoch: 644| Step: 0
Training loss: 0.5761523246765137
Validation loss: 1.6609335048224336

Epoch: 6| Step: 1
Training loss: 0.7558093070983887
Validation loss: 1.722219115944319

Epoch: 6| Step: 2
Training loss: 0.5039938688278198
Validation loss: 1.7011615371191373

Epoch: 6| Step: 3
Training loss: 0.5451403856277466
Validation loss: 1.7149456252333939

Epoch: 6| Step: 4
Training loss: 1.1793217658996582
Validation loss: 1.6683134776289745

Epoch: 6| Step: 5
Training loss: 0.42901378870010376
Validation loss: 1.697820299415178

Epoch: 6| Step: 6
Training loss: 0.7640312314033508
Validation loss: 1.6908897046119935

Epoch: 6| Step: 7
Training loss: 0.5448256731033325
Validation loss: 1.6520860477160382

Epoch: 6| Step: 8
Training loss: 0.8293688297271729
Validation loss: 1.6331897833014046

Epoch: 6| Step: 9
Training loss: 0.6272034645080566
Validation loss: 1.6417388685287968

Epoch: 6| Step: 10
Training loss: 0.6034392714500427
Validation loss: 1.6611192508410382

Epoch: 6| Step: 11
Training loss: 0.6941546201705933
Validation loss: 1.7178741321768811

Epoch: 6| Step: 12
Training loss: 0.5722534656524658
Validation loss: 1.6694296149797336

Epoch: 6| Step: 13
Training loss: 1.1847996711730957
Validation loss: 1.6792643916222356

Epoch: 645| Step: 0
Training loss: 0.43604305386543274
Validation loss: 1.690322877258383

Epoch: 6| Step: 1
Training loss: 0.24288898706436157
Validation loss: 1.6913567512266097

Epoch: 6| Step: 2
Training loss: 0.6165462732315063
Validation loss: 1.6642999931048321

Epoch: 6| Step: 3
Training loss: 0.5954594612121582
Validation loss: 1.7381405817565097

Epoch: 6| Step: 4
Training loss: 1.0174649953842163
Validation loss: 1.7797120284008723

Epoch: 6| Step: 5
Training loss: 0.9039148092269897
Validation loss: 1.7492179357877342

Epoch: 6| Step: 6
Training loss: 0.6726458072662354
Validation loss: 1.7084910292779245

Epoch: 6| Step: 7
Training loss: 1.1583631038665771
Validation loss: 1.6752014621611564

Epoch: 6| Step: 8
Training loss: 0.6699122786521912
Validation loss: 1.6903891486506308

Epoch: 6| Step: 9
Training loss: 0.829534649848938
Validation loss: 1.7339109541267477

Epoch: 6| Step: 10
Training loss: 0.5869630575180054
Validation loss: 1.6988588020365725

Epoch: 6| Step: 11
Training loss: 0.7534419298171997
Validation loss: 1.6680517324837305

Epoch: 6| Step: 12
Training loss: 0.9127281904220581
Validation loss: 1.7083001534144084

Epoch: 6| Step: 13
Training loss: 0.9774834513664246
Validation loss: 1.662760814030965

Epoch: 646| Step: 0
Training loss: 0.8349943161010742
Validation loss: 1.6950648856419388

Epoch: 6| Step: 1
Training loss: 0.3865410387516022
Validation loss: 1.635592701614544

Epoch: 6| Step: 2
Training loss: 0.9766660928726196
Validation loss: 1.6533727697146836

Epoch: 6| Step: 3
Training loss: 1.0400750637054443
Validation loss: 1.668522757868613

Epoch: 6| Step: 4
Training loss: 0.5019241571426392
Validation loss: 1.7101518748908915

Epoch: 6| Step: 5
Training loss: 0.6424474120140076
Validation loss: 1.6542281617400467

Epoch: 6| Step: 6
Training loss: 0.474904865026474
Validation loss: 1.7326728733637

Epoch: 6| Step: 7
Training loss: 1.0862478017807007
Validation loss: 1.7445575934584423

Epoch: 6| Step: 8
Training loss: 0.9385907053947449
Validation loss: 1.7305289391548402

Epoch: 6| Step: 9
Training loss: 0.6689406633377075
Validation loss: 1.7596628153195946

Epoch: 6| Step: 10
Training loss: 0.7392742037773132
Validation loss: 1.7558567254774031

Epoch: 6| Step: 11
Training loss: 0.6343626976013184
Validation loss: 1.7322884631413284

Epoch: 6| Step: 12
Training loss: 0.7112816572189331
Validation loss: 1.6877136320196173

Epoch: 6| Step: 13
Training loss: 0.5311596393585205
Validation loss: 1.6691432383752638

Epoch: 647| Step: 0
Training loss: 0.8984537720680237
Validation loss: 1.695111031173378

Epoch: 6| Step: 1
Training loss: 0.8894789218902588
Validation loss: 1.6571708174162014

Epoch: 6| Step: 2
Training loss: 0.44321346282958984
Validation loss: 1.6727632271346224

Epoch: 6| Step: 3
Training loss: 0.3592652678489685
Validation loss: 1.770775141254548

Epoch: 6| Step: 4
Training loss: 0.8971304893493652
Validation loss: 1.6377862050969114

Epoch: 6| Step: 5
Training loss: 1.2511026859283447
Validation loss: 1.691086051284626

Epoch: 6| Step: 6
Training loss: 0.5137453079223633
Validation loss: 1.6664020438348093

Epoch: 6| Step: 7
Training loss: 0.7237143516540527
Validation loss: 1.657477282708691

Epoch: 6| Step: 8
Training loss: 0.5628337860107422
Validation loss: 1.6685634915546705

Epoch: 6| Step: 9
Training loss: 0.8472148180007935
Validation loss: 1.6505318072534376

Epoch: 6| Step: 10
Training loss: 0.875556468963623
Validation loss: 1.7114628438026673

Epoch: 6| Step: 11
Training loss: 0.4899536967277527
Validation loss: 1.652990234795437

Epoch: 6| Step: 12
Training loss: 0.4250877797603607
Validation loss: 1.7204816213218115

Epoch: 6| Step: 13
Training loss: 0.6917428970336914
Validation loss: 1.7282223752749863

Epoch: 648| Step: 0
Training loss: 1.2829827070236206
Validation loss: 1.7186769644419353

Epoch: 6| Step: 1
Training loss: 0.4472757577896118
Validation loss: 1.654071589951874

Epoch: 6| Step: 2
Training loss: 0.7358399629592896
Validation loss: 1.646403431892395

Epoch: 6| Step: 3
Training loss: 0.48564469814300537
Validation loss: 1.6369954386065084

Epoch: 6| Step: 4
Training loss: 0.5656733512878418
Validation loss: 1.6659021531381915

Epoch: 6| Step: 5
Training loss: 0.775348424911499
Validation loss: 1.705801522859963

Epoch: 6| Step: 6
Training loss: 0.8466808795928955
Validation loss: 1.7244950186821721

Epoch: 6| Step: 7
Training loss: 0.616174578666687
Validation loss: 1.6830867798097673

Epoch: 6| Step: 8
Training loss: 0.579380214214325
Validation loss: 1.7319583444185154

Epoch: 6| Step: 9
Training loss: 0.6962198615074158
Validation loss: 1.6668726000734555

Epoch: 6| Step: 10
Training loss: 0.4224500358104706
Validation loss: 1.733441323362371

Epoch: 6| Step: 11
Training loss: 0.7198448181152344
Validation loss: 1.7114524610580937

Epoch: 6| Step: 12
Training loss: 0.649040699005127
Validation loss: 1.7172080970579577

Epoch: 6| Step: 13
Training loss: 0.7281312942504883
Validation loss: 1.7059204283580984

Epoch: 649| Step: 0
Training loss: 0.7524545192718506
Validation loss: 1.705947531166897

Epoch: 6| Step: 1
Training loss: 0.5375974178314209
Validation loss: 1.6757955499874648

Epoch: 6| Step: 2
Training loss: 1.0909318923950195
Validation loss: 1.6398168212624007

Epoch: 6| Step: 3
Training loss: 0.4242219924926758
Validation loss: 1.6986883058342883

Epoch: 6| Step: 4
Training loss: 1.2552905082702637
Validation loss: 1.6616805881582282

Epoch: 6| Step: 5
Training loss: 0.5472012758255005
Validation loss: 1.6015424215665428

Epoch: 6| Step: 6
Training loss: 0.809455394744873
Validation loss: 1.6456809479703185

Epoch: 6| Step: 7
Training loss: 0.620853841304779
Validation loss: 1.6637745557292816

Epoch: 6| Step: 8
Training loss: 0.8778382539749146
Validation loss: 1.6618207436735912

Epoch: 6| Step: 9
Training loss: 0.5137065649032593
Validation loss: 1.6946307664276452

Epoch: 6| Step: 10
Training loss: 1.0828771591186523
Validation loss: 1.697733199724587

Epoch: 6| Step: 11
Training loss: 0.574669599533081
Validation loss: 1.6674719946358794

Epoch: 6| Step: 12
Training loss: 0.48520129919052124
Validation loss: 1.665952423567413

Epoch: 6| Step: 13
Training loss: 0.4599708020687103
Validation loss: 1.668416161690989

Epoch: 650| Step: 0
Training loss: 0.40735068917274475
Validation loss: 1.7210223444046513

Epoch: 6| Step: 1
Training loss: 1.2882291078567505
Validation loss: 1.7036962188700193

Epoch: 6| Step: 2
Training loss: 0.4813980460166931
Validation loss: 1.6863051845181374

Epoch: 6| Step: 3
Training loss: 0.6000030040740967
Validation loss: 1.7390814686334262

Epoch: 6| Step: 4
Training loss: 0.4485534727573395
Validation loss: 1.6957557086021668

Epoch: 6| Step: 5
Training loss: 0.7084580659866333
Validation loss: 1.7241993719531643

Epoch: 6| Step: 6
Training loss: 0.8134487867355347
Validation loss: 1.7331901224710609

Epoch: 6| Step: 7
Training loss: 0.8758658170700073
Validation loss: 1.680036747327415

Epoch: 6| Step: 8
Training loss: 0.9473822116851807
Validation loss: 1.6760732255956179

Epoch: 6| Step: 9
Training loss: 0.4840233325958252
Validation loss: 1.659105335512469

Epoch: 6| Step: 10
Training loss: 0.7002564668655396
Validation loss: 1.623799244562785

Epoch: 6| Step: 11
Training loss: 0.5181571245193481
Validation loss: 1.6444246474132742

Epoch: 6| Step: 12
Training loss: 0.5563366413116455
Validation loss: 1.6793859645884524

Epoch: 6| Step: 13
Training loss: 0.4821993410587311
Validation loss: 1.6883530789805996

Epoch: 651| Step: 0
Training loss: 0.4307951331138611
Validation loss: 1.7159820448967718

Epoch: 6| Step: 1
Training loss: 0.7691768407821655
Validation loss: 1.651712808557736

Epoch: 6| Step: 2
Training loss: 0.8061739206314087
Validation loss: 1.6468066656461327

Epoch: 6| Step: 3
Training loss: 0.6189997792243958
Validation loss: 1.647652619628496

Epoch: 6| Step: 4
Training loss: 0.6970462799072266
Validation loss: 1.705956453918129

Epoch: 6| Step: 5
Training loss: 1.074657678604126
Validation loss: 1.692527389013639

Epoch: 6| Step: 6
Training loss: 0.35612115263938904
Validation loss: 1.7154135306676228

Epoch: 6| Step: 7
Training loss: 0.4127843976020813
Validation loss: 1.655323496428869

Epoch: 6| Step: 8
Training loss: 0.558932900428772
Validation loss: 1.6914957800219137

Epoch: 6| Step: 9
Training loss: 0.6769973039627075
Validation loss: 1.713705615330768

Epoch: 6| Step: 10
Training loss: 1.1081854104995728
Validation loss: 1.6699310656516784

Epoch: 6| Step: 11
Training loss: 0.624139130115509
Validation loss: 1.720320185025533

Epoch: 6| Step: 12
Training loss: 0.601509153842926
Validation loss: 1.7617131330633675

Epoch: 6| Step: 13
Training loss: 0.32887187600135803
Validation loss: 1.735585686981037

Epoch: 652| Step: 0
Training loss: 0.7716673612594604
Validation loss: 1.6877037966123192

Epoch: 6| Step: 1
Training loss: 0.7640591263771057
Validation loss: 1.6914813172432683

Epoch: 6| Step: 2
Training loss: 0.403944194316864
Validation loss: 1.6772662644745202

Epoch: 6| Step: 3
Training loss: 1.2127878665924072
Validation loss: 1.7220266301144835

Epoch: 6| Step: 4
Training loss: 0.8388444185256958
Validation loss: 1.7058503089412567

Epoch: 6| Step: 5
Training loss: 0.8290574550628662
Validation loss: 1.7242312008334744

Epoch: 6| Step: 6
Training loss: 0.5741062164306641
Validation loss: 1.6388046574848953

Epoch: 6| Step: 7
Training loss: 0.7391238212585449
Validation loss: 1.6116263110150573

Epoch: 6| Step: 8
Training loss: 0.5053536891937256
Validation loss: 1.6453649920801963

Epoch: 6| Step: 9
Training loss: 0.9126879572868347
Validation loss: 1.699352769441502

Epoch: 6| Step: 10
Training loss: 0.5429751873016357
Validation loss: 1.6872159281084615

Epoch: 6| Step: 11
Training loss: 0.9844027757644653
Validation loss: 1.690584381421407

Epoch: 6| Step: 12
Training loss: 0.6387796401977539
Validation loss: 1.6460111961569837

Epoch: 6| Step: 13
Training loss: 0.6621789336204529
Validation loss: 1.7167863192096833

Epoch: 653| Step: 0
Training loss: 1.1161727905273438
Validation loss: 1.6297408701271139

Epoch: 6| Step: 1
Training loss: 0.8784881234169006
Validation loss: 1.6540949818908528

Epoch: 6| Step: 2
Training loss: 0.46224915981292725
Validation loss: 1.7024482373268373

Epoch: 6| Step: 3
Training loss: 0.8488067388534546
Validation loss: 1.6471911796959497

Epoch: 6| Step: 4
Training loss: 0.6696325540542603
Validation loss: 1.6755893332983858

Epoch: 6| Step: 5
Training loss: 0.6172807216644287
Validation loss: 1.6414069578211794

Epoch: 6| Step: 6
Training loss: 0.5501581430435181
Validation loss: 1.6873913452189455

Epoch: 6| Step: 7
Training loss: 0.46326905488967896
Validation loss: 1.6296922442733601

Epoch: 6| Step: 8
Training loss: 0.8145512938499451
Validation loss: 1.6736394692492742

Epoch: 6| Step: 9
Training loss: 0.8113277554512024
Validation loss: 1.7009225083935646

Epoch: 6| Step: 10
Training loss: 0.4992920756340027
Validation loss: 1.6342932972856747

Epoch: 6| Step: 11
Training loss: 0.6915768384933472
Validation loss: 1.681706586191731

Epoch: 6| Step: 12
Training loss: 0.6090499758720398
Validation loss: 1.6957538384263233

Epoch: 6| Step: 13
Training loss: 0.7593802809715271
Validation loss: 1.6199092185625465

Epoch: 654| Step: 0
Training loss: 0.5024253129959106
Validation loss: 1.6448270044019144

Epoch: 6| Step: 1
Training loss: 0.8626608848571777
Validation loss: 1.6556599781077395

Epoch: 6| Step: 2
Training loss: 1.0385003089904785
Validation loss: 1.6730722355586227

Epoch: 6| Step: 3
Training loss: 0.6503908038139343
Validation loss: 1.675373992612285

Epoch: 6| Step: 4
Training loss: 0.6652804613113403
Validation loss: 1.6725061529426164

Epoch: 6| Step: 5
Training loss: 0.5309492349624634
Validation loss: 1.656577411518302

Epoch: 6| Step: 6
Training loss: 1.1419017314910889
Validation loss: 1.69462082206562

Epoch: 6| Step: 7
Training loss: 0.6342703104019165
Validation loss: 1.6648207851635513

Epoch: 6| Step: 8
Training loss: 0.4016893804073334
Validation loss: 1.6195719883006106

Epoch: 6| Step: 9
Training loss: 0.6966376304626465
Validation loss: 1.6563666969217279

Epoch: 6| Step: 10
Training loss: 0.5339296460151672
Validation loss: 1.6453554040642195

Epoch: 6| Step: 11
Training loss: 0.7337378263473511
Validation loss: 1.640846820287807

Epoch: 6| Step: 12
Training loss: 0.4566884934902191
Validation loss: 1.6698896397826493

Epoch: 6| Step: 13
Training loss: 0.9002305269241333
Validation loss: 1.6683244974382463

Epoch: 655| Step: 0
Training loss: 0.48961079120635986
Validation loss: 1.668319438093452

Epoch: 6| Step: 1
Training loss: 0.646245002746582
Validation loss: 1.6447614546745055

Epoch: 6| Step: 2
Training loss: 0.9098535180091858
Validation loss: 1.6771616141001384

Epoch: 6| Step: 3
Training loss: 0.6609451174736023
Validation loss: 1.6983887995443037

Epoch: 6| Step: 4
Training loss: 0.584662139415741
Validation loss: 1.6995211416675198

Epoch: 6| Step: 5
Training loss: 0.7496726512908936
Validation loss: 1.725207217278019

Epoch: 6| Step: 6
Training loss: 0.8437670469284058
Validation loss: 1.6892326262689406

Epoch: 6| Step: 7
Training loss: 0.3398025631904602
Validation loss: 1.7003656446292836

Epoch: 6| Step: 8
Training loss: 0.8041570782661438
Validation loss: 1.6544079357577908

Epoch: 6| Step: 9
Training loss: 0.3415945768356323
Validation loss: 1.6637546003505748

Epoch: 6| Step: 10
Training loss: 0.8090599179267883
Validation loss: 1.7447769577785204

Epoch: 6| Step: 11
Training loss: 0.7454763650894165
Validation loss: 1.6780654332971061

Epoch: 6| Step: 12
Training loss: 0.8123949766159058
Validation loss: 1.6474723290371638

Epoch: 6| Step: 13
Training loss: 0.6369833946228027
Validation loss: 1.7005950789297781

Epoch: 656| Step: 0
Training loss: 0.5501415729522705
Validation loss: 1.6625067034075338

Epoch: 6| Step: 1
Training loss: 0.5475224852561951
Validation loss: 1.641394704900762

Epoch: 6| Step: 2
Training loss: 0.7749226093292236
Validation loss: 1.6204354288757488

Epoch: 6| Step: 3
Training loss: 0.7725175619125366
Validation loss: 1.6548952312879666

Epoch: 6| Step: 4
Training loss: 0.6147527098655701
Validation loss: 1.673031000680821

Epoch: 6| Step: 5
Training loss: 0.7142072319984436
Validation loss: 1.665680282859392

Epoch: 6| Step: 6
Training loss: 0.4722006022930145
Validation loss: 1.731441658030274

Epoch: 6| Step: 7
Training loss: 1.0187050104141235
Validation loss: 1.623691052518865

Epoch: 6| Step: 8
Training loss: 0.420382022857666
Validation loss: 1.6973120345864245

Epoch: 6| Step: 9
Training loss: 1.1349178552627563
Validation loss: 1.708536196780461

Epoch: 6| Step: 10
Training loss: 0.3327314555644989
Validation loss: 1.650750094844449

Epoch: 6| Step: 11
Training loss: 0.5502523183822632
Validation loss: 1.627297773156115

Epoch: 6| Step: 12
Training loss: 1.0848239660263062
Validation loss: 1.7273165974565732

Epoch: 6| Step: 13
Training loss: 0.43191882967948914
Validation loss: 1.6567186822173416

Epoch: 657| Step: 0
Training loss: 0.5388966798782349
Validation loss: 1.7054571669588807

Epoch: 6| Step: 1
Training loss: 0.6084171533584595
Validation loss: 1.6625748757393128

Epoch: 6| Step: 2
Training loss: 0.444905549287796
Validation loss: 1.6868791734018633

Epoch: 6| Step: 3
Training loss: 0.7889115214347839
Validation loss: 1.6783549567704559

Epoch: 6| Step: 4
Training loss: 0.9461268782615662
Validation loss: 1.7034297707260295

Epoch: 6| Step: 5
Training loss: 0.7347251176834106
Validation loss: 1.7010805619660245

Epoch: 6| Step: 6
Training loss: 1.0122038125991821
Validation loss: 1.7230255071834852

Epoch: 6| Step: 7
Training loss: 0.5324376821517944
Validation loss: 1.7188401863139162

Epoch: 6| Step: 8
Training loss: 0.6125884056091309
Validation loss: 1.6877387018613919

Epoch: 6| Step: 9
Training loss: 0.6225680112838745
Validation loss: 1.7097352473966536

Epoch: 6| Step: 10
Training loss: 0.532706618309021
Validation loss: 1.7106704494004608

Epoch: 6| Step: 11
Training loss: 0.9336493015289307
Validation loss: 1.722210221393134

Epoch: 6| Step: 12
Training loss: 0.5527245998382568
Validation loss: 1.6575748125712078

Epoch: 6| Step: 13
Training loss: 1.3473269939422607
Validation loss: 1.6944997900275773

Epoch: 658| Step: 0
Training loss: 0.7917428016662598
Validation loss: 1.678303313511674

Epoch: 6| Step: 1
Training loss: 1.0510327816009521
Validation loss: 1.6348167760397798

Epoch: 6| Step: 2
Training loss: 0.47212347388267517
Validation loss: 1.6706756161105247

Epoch: 6| Step: 3
Training loss: 0.44461125135421753
Validation loss: 1.6496746924615675

Epoch: 6| Step: 4
Training loss: 0.7881417274475098
Validation loss: 1.693400263786316

Epoch: 6| Step: 5
Training loss: 0.6086852550506592
Validation loss: 1.7184014269100722

Epoch: 6| Step: 6
Training loss: 0.4999728798866272
Validation loss: 1.658653030472417

Epoch: 6| Step: 7
Training loss: 0.4405084252357483
Validation loss: 1.6542305523349392

Epoch: 6| Step: 8
Training loss: 0.8115111589431763
Validation loss: 1.6588459566075315

Epoch: 6| Step: 9
Training loss: 0.8108351230621338
Validation loss: 1.6731638972477247

Epoch: 6| Step: 10
Training loss: 1.009941816329956
Validation loss: 1.665771069065217

Epoch: 6| Step: 11
Training loss: 0.6929317712783813
Validation loss: 1.6727242892788303

Epoch: 6| Step: 12
Training loss: 0.4333094358444214
Validation loss: 1.7230443813467538

Epoch: 6| Step: 13
Training loss: 0.5632787346839905
Validation loss: 1.6845250629609632

Epoch: 659| Step: 0
Training loss: 0.9443734288215637
Validation loss: 1.7227859138160624

Epoch: 6| Step: 1
Training loss: 0.2723644971847534
Validation loss: 1.7229271601605158

Epoch: 6| Step: 2
Training loss: 0.6270097494125366
Validation loss: 1.7073947396329654

Epoch: 6| Step: 3
Training loss: 1.1944284439086914
Validation loss: 1.7038476646587413

Epoch: 6| Step: 4
Training loss: 0.9231600761413574
Validation loss: 1.6977755510678856

Epoch: 6| Step: 5
Training loss: 0.36060571670532227
Validation loss: 1.6884358211230206

Epoch: 6| Step: 6
Training loss: 0.49848270416259766
Validation loss: 1.6563003704112063

Epoch: 6| Step: 7
Training loss: 0.7928973436355591
Validation loss: 1.7076941805501138

Epoch: 6| Step: 8
Training loss: 0.666784405708313
Validation loss: 1.660094484206169

Epoch: 6| Step: 9
Training loss: 0.6714850068092346
Validation loss: 1.6436030659624326

Epoch: 6| Step: 10
Training loss: 0.8359032869338989
Validation loss: 1.6457361123895133

Epoch: 6| Step: 11
Training loss: 0.6783998608589172
Validation loss: 1.6933293868136663

Epoch: 6| Step: 12
Training loss: 0.49536195397377014
Validation loss: 1.631203825755786

Epoch: 6| Step: 13
Training loss: 0.5085312724113464
Validation loss: 1.6233119592871716

Epoch: 660| Step: 0
Training loss: 0.6968747973442078
Validation loss: 1.6404969961412492

Epoch: 6| Step: 1
Training loss: 0.7283188104629517
Validation loss: 1.7078023777213147

Epoch: 6| Step: 2
Training loss: 0.9993283152580261
Validation loss: 1.6444494955001339

Epoch: 6| Step: 3
Training loss: 1.0636310577392578
Validation loss: 1.6765529263404109

Epoch: 6| Step: 4
Training loss: 0.4927821755409241
Validation loss: 1.627879027397402

Epoch: 6| Step: 5
Training loss: 0.893685519695282
Validation loss: 1.6692088175845403

Epoch: 6| Step: 6
Training loss: 0.7441762685775757
Validation loss: 1.6800640078001126

Epoch: 6| Step: 7
Training loss: 0.6595137119293213
Validation loss: 1.6611317203890892

Epoch: 6| Step: 8
Training loss: 0.3915823698043823
Validation loss: 1.642270682960428

Epoch: 6| Step: 9
Training loss: 0.2668699622154236
Validation loss: 1.600245879542443

Epoch: 6| Step: 10
Training loss: 0.5072623491287231
Validation loss: 1.6420069048481603

Epoch: 6| Step: 11
Training loss: 0.7214552760124207
Validation loss: 1.71301144425587

Epoch: 6| Step: 12
Training loss: 0.6542415618896484
Validation loss: 1.6488926359402236

Epoch: 6| Step: 13
Training loss: 0.2551387548446655
Validation loss: 1.6993638097598989

Epoch: 661| Step: 0
Training loss: 0.8963984251022339
Validation loss: 1.669133065849222

Epoch: 6| Step: 1
Training loss: 0.49728989601135254
Validation loss: 1.680903680862919

Epoch: 6| Step: 2
Training loss: 0.3927905559539795
Validation loss: 1.6916693013201478

Epoch: 6| Step: 3
Training loss: 0.5614444613456726
Validation loss: 1.7263998677653651

Epoch: 6| Step: 4
Training loss: 0.7517720460891724
Validation loss: 1.690223228546881

Epoch: 6| Step: 5
Training loss: 0.4964965283870697
Validation loss: 1.6998017859715286

Epoch: 6| Step: 6
Training loss: 0.5309499502182007
Validation loss: 1.6690239585855955

Epoch: 6| Step: 7
Training loss: 0.6203317642211914
Validation loss: 1.6298736923484392

Epoch: 6| Step: 8
Training loss: 0.45133328437805176
Validation loss: 1.6695305211569673

Epoch: 6| Step: 9
Training loss: 0.3788771629333496
Validation loss: 1.6721460409061883

Epoch: 6| Step: 10
Training loss: 0.7228696942329407
Validation loss: 1.659329181076378

Epoch: 6| Step: 11
Training loss: 0.5219879746437073
Validation loss: 1.655119519079885

Epoch: 6| Step: 12
Training loss: 1.0912278890609741
Validation loss: 1.6555737795368317

Epoch: 6| Step: 13
Training loss: 1.518746018409729
Validation loss: 1.6319899789748653

Epoch: 662| Step: 0
Training loss: 0.8965998888015747
Validation loss: 1.6159103134626984

Epoch: 6| Step: 1
Training loss: 0.46716272830963135
Validation loss: 1.6901800030021257

Epoch: 6| Step: 2
Training loss: 1.0368434190750122
Validation loss: 1.6664207007295342

Epoch: 6| Step: 3
Training loss: 0.9806159138679504
Validation loss: 1.699721344055668

Epoch: 6| Step: 4
Training loss: 0.8228237628936768
Validation loss: 1.7007641407751268

Epoch: 6| Step: 5
Training loss: 0.8543457984924316
Validation loss: 1.652026685335303

Epoch: 6| Step: 6
Training loss: 0.4349896311759949
Validation loss: 1.64866340673098

Epoch: 6| Step: 7
Training loss: 0.5649895668029785
Validation loss: 1.6614741433051325

Epoch: 6| Step: 8
Training loss: 0.6484190225601196
Validation loss: 1.6818277630754697

Epoch: 6| Step: 9
Training loss: 0.6617804765701294
Validation loss: 1.6651922823280416

Epoch: 6| Step: 10
Training loss: 0.23859906196594238
Validation loss: 1.6058143415758688

Epoch: 6| Step: 11
Training loss: 0.5518556833267212
Validation loss: 1.611087986218032

Epoch: 6| Step: 12
Training loss: 0.5926507711410522
Validation loss: 1.6693751376162294

Epoch: 6| Step: 13
Training loss: 0.6131389141082764
Validation loss: 1.666826214841617

Epoch: 663| Step: 0
Training loss: 0.9084031581878662
Validation loss: 1.7284080918117235

Epoch: 6| Step: 1
Training loss: 0.45300164818763733
Validation loss: 1.63531619246288

Epoch: 6| Step: 2
Training loss: 0.7751144170761108
Validation loss: 1.669393798356415

Epoch: 6| Step: 3
Training loss: 1.1714768409729004
Validation loss: 1.646193059541846

Epoch: 6| Step: 4
Training loss: 0.5508058071136475
Validation loss: 1.6806384427573091

Epoch: 6| Step: 5
Training loss: 0.7005290985107422
Validation loss: 1.6950001485886113

Epoch: 6| Step: 6
Training loss: 0.3996220827102661
Validation loss: 1.7484734045561923

Epoch: 6| Step: 7
Training loss: 0.7642554044723511
Validation loss: 1.6919961885739399

Epoch: 6| Step: 8
Training loss: 0.6884176731109619
Validation loss: 1.7093554466001448

Epoch: 6| Step: 9
Training loss: 0.9566906094551086
Validation loss: 1.6901105552591302

Epoch: 6| Step: 10
Training loss: 0.7295659780502319
Validation loss: 1.7076554324037285

Epoch: 6| Step: 11
Training loss: 0.6171775460243225
Validation loss: 1.6193925924198602

Epoch: 6| Step: 12
Training loss: 0.5573711395263672
Validation loss: 1.6775560020118632

Epoch: 6| Step: 13
Training loss: 0.8666197061538696
Validation loss: 1.6411645963627806

Epoch: 664| Step: 0
Training loss: 0.6031972765922546
Validation loss: 1.6541710053720782

Epoch: 6| Step: 1
Training loss: 0.8251960873603821
Validation loss: 1.6284030932252125

Epoch: 6| Step: 2
Training loss: 0.3369672894477844
Validation loss: 1.6271133115214687

Epoch: 6| Step: 3
Training loss: 0.45493900775909424
Validation loss: 1.6283866641342

Epoch: 6| Step: 4
Training loss: 1.0580015182495117
Validation loss: 1.660240336131024

Epoch: 6| Step: 5
Training loss: 0.6517599821090698
Validation loss: 1.678436811252307

Epoch: 6| Step: 6
Training loss: 0.7299226522445679
Validation loss: 1.6301966354411135

Epoch: 6| Step: 7
Training loss: 0.4480639696121216
Validation loss: 1.6094278802153885

Epoch: 6| Step: 8
Training loss: 0.6106530427932739
Validation loss: 1.700562802694177

Epoch: 6| Step: 9
Training loss: 0.8057846426963806
Validation loss: 1.6941341200182516

Epoch: 6| Step: 10
Training loss: 0.7368382811546326
Validation loss: 1.6882682666983655

Epoch: 6| Step: 11
Training loss: 0.58964604139328
Validation loss: 1.7416267446292344

Epoch: 6| Step: 12
Training loss: 1.1761611700057983
Validation loss: 1.6748951224870579

Epoch: 6| Step: 13
Training loss: 0.6416956782341003
Validation loss: 1.7274121174248316

Epoch: 665| Step: 0
Training loss: 1.0689514875411987
Validation loss: 1.6655066013336182

Epoch: 6| Step: 1
Training loss: 0.4272223114967346
Validation loss: 1.6730502202946653

Epoch: 6| Step: 2
Training loss: 0.5549540519714355
Validation loss: 1.6767490115216983

Epoch: 6| Step: 3
Training loss: 0.7074844837188721
Validation loss: 1.6163649225747714

Epoch: 6| Step: 4
Training loss: 0.6297653317451477
Validation loss: 1.674027504459504

Epoch: 6| Step: 5
Training loss: 0.8034137487411499
Validation loss: 1.641480771444177

Epoch: 6| Step: 6
Training loss: 0.5679078698158264
Validation loss: 1.6414512331767748

Epoch: 6| Step: 7
Training loss: 1.0199493169784546
Validation loss: 1.6666132275776198

Epoch: 6| Step: 8
Training loss: 0.5205879211425781
Validation loss: 1.6887553635463919

Epoch: 6| Step: 9
Training loss: 0.76792311668396
Validation loss: 1.6244444154923963

Epoch: 6| Step: 10
Training loss: 0.8644995093345642
Validation loss: 1.6312318399388304

Epoch: 6| Step: 11
Training loss: 0.19078496098518372
Validation loss: 1.6333739847265265

Epoch: 6| Step: 12
Training loss: 0.7152340412139893
Validation loss: 1.6892122812168573

Epoch: 6| Step: 13
Training loss: 0.30061012506484985
Validation loss: 1.6623870441990514

Epoch: 666| Step: 0
Training loss: 0.7813606858253479
Validation loss: 1.6930247301696448

Epoch: 6| Step: 1
Training loss: 0.6642271280288696
Validation loss: 1.6607470358571699

Epoch: 6| Step: 2
Training loss: 1.1724876165390015
Validation loss: 1.6784608902469758

Epoch: 6| Step: 3
Training loss: 0.8322391510009766
Validation loss: 1.7216777224694528

Epoch: 6| Step: 4
Training loss: 0.45995837450027466
Validation loss: 1.712669216176515

Epoch: 6| Step: 5
Training loss: 0.41925060749053955
Validation loss: 1.6442905715716782

Epoch: 6| Step: 6
Training loss: 0.5692212581634521
Validation loss: 1.69123472193236

Epoch: 6| Step: 7
Training loss: 0.7750444412231445
Validation loss: 1.684383620498001

Epoch: 6| Step: 8
Training loss: 0.4493832290172577
Validation loss: 1.6741404200112948

Epoch: 6| Step: 9
Training loss: 0.8183119297027588
Validation loss: 1.5987379243296962

Epoch: 6| Step: 10
Training loss: 0.46700114011764526
Validation loss: 1.6902777302649714

Epoch: 6| Step: 11
Training loss: 0.6352332830429077
Validation loss: 1.6594967444737752

Epoch: 6| Step: 12
Training loss: 0.8401768207550049
Validation loss: 1.6612401957152991

Epoch: 6| Step: 13
Training loss: 0.7831010818481445
Validation loss: 1.628441027415696

Epoch: 667| Step: 0
Training loss: 0.5726994276046753
Validation loss: 1.6322016228911698

Epoch: 6| Step: 1
Training loss: 0.7070116400718689
Validation loss: 1.6517196291236467

Epoch: 6| Step: 2
Training loss: 0.7174357771873474
Validation loss: 1.6606476396642706

Epoch: 6| Step: 3
Training loss: 0.5437206029891968
Validation loss: 1.7063754117617043

Epoch: 6| Step: 4
Training loss: 0.5836340188980103
Validation loss: 1.6446317895766227

Epoch: 6| Step: 5
Training loss: 0.5969626903533936
Validation loss: 1.6717939017921366

Epoch: 6| Step: 6
Training loss: 0.7267390489578247
Validation loss: 1.6924320574729674

Epoch: 6| Step: 7
Training loss: 0.6054202318191528
Validation loss: 1.6578099291811708

Epoch: 6| Step: 8
Training loss: 0.9409645795822144
Validation loss: 1.649022190801559

Epoch: 6| Step: 9
Training loss: 1.106553077697754
Validation loss: 1.685677505308582

Epoch: 6| Step: 10
Training loss: 0.5577458143234253
Validation loss: 1.657789207273914

Epoch: 6| Step: 11
Training loss: 0.5613297820091248
Validation loss: 1.7023454699465024

Epoch: 6| Step: 12
Training loss: 0.8499223589897156
Validation loss: 1.6990839486481042

Epoch: 6| Step: 13
Training loss: 0.9212623238563538
Validation loss: 1.6995516541183635

Epoch: 668| Step: 0
Training loss: 0.6114707589149475
Validation loss: 1.693707577643856

Epoch: 6| Step: 1
Training loss: 0.5369722247123718
Validation loss: 1.732729317039572

Epoch: 6| Step: 2
Training loss: 1.4327017068862915
Validation loss: 1.6545765810115363

Epoch: 6| Step: 3
Training loss: 0.6359943747520447
Validation loss: 1.699740061195948

Epoch: 6| Step: 4
Training loss: 1.068772792816162
Validation loss: 1.6648924760921027

Epoch: 6| Step: 5
Training loss: 0.4096245765686035
Validation loss: 1.6782362486726494

Epoch: 6| Step: 6
Training loss: 0.4529820382595062
Validation loss: 1.5799826845046012

Epoch: 6| Step: 7
Training loss: 0.4618658721446991
Validation loss: 1.5973591496867519

Epoch: 6| Step: 8
Training loss: 0.8913809061050415
Validation loss: 1.6662692408407889

Epoch: 6| Step: 9
Training loss: 0.5666323900222778
Validation loss: 1.6637821043691328

Epoch: 6| Step: 10
Training loss: 0.6246873736381531
Validation loss: 1.6394273119588052

Epoch: 6| Step: 11
Training loss: 0.5982372164726257
Validation loss: 1.64974013451607

Epoch: 6| Step: 12
Training loss: 0.46863776445388794
Validation loss: 1.684205401328302

Epoch: 6| Step: 13
Training loss: 0.7200592160224915
Validation loss: 1.6742748291261735

Epoch: 669| Step: 0
Training loss: 0.5299451351165771
Validation loss: 1.641389996774735

Epoch: 6| Step: 1
Training loss: 0.5324865579605103
Validation loss: 1.7392571741534817

Epoch: 6| Step: 2
Training loss: 0.6971761584281921
Validation loss: 1.7179270969924105

Epoch: 6| Step: 3
Training loss: 0.7864221334457397
Validation loss: 1.657672921816508

Epoch: 6| Step: 4
Training loss: 0.4124751091003418
Validation loss: 1.7066856943151003

Epoch: 6| Step: 5
Training loss: 1.167277455329895
Validation loss: 1.6299609573938514

Epoch: 6| Step: 6
Training loss: 0.5682777166366577
Validation loss: 1.6470255210835447

Epoch: 6| Step: 7
Training loss: 0.6531885862350464
Validation loss: 1.669717452859366

Epoch: 6| Step: 8
Training loss: 0.7117563486099243
Validation loss: 1.6302450985036872

Epoch: 6| Step: 9
Training loss: 0.5211573243141174
Validation loss: 1.669617074792103

Epoch: 6| Step: 10
Training loss: 0.4135068953037262
Validation loss: 1.6754560162944179

Epoch: 6| Step: 11
Training loss: 0.5882799625396729
Validation loss: 1.69115694620276

Epoch: 6| Step: 12
Training loss: 0.8955090045928955
Validation loss: 1.6791152005554528

Epoch: 6| Step: 13
Training loss: 0.6964207291603088
Validation loss: 1.6335174306746452

Epoch: 670| Step: 0
Training loss: 0.7074462175369263
Validation loss: 1.6426636659970848

Epoch: 6| Step: 1
Training loss: 0.6677844524383545
Validation loss: 1.665616630226053

Epoch: 6| Step: 2
Training loss: 0.8502310514450073
Validation loss: 1.6837763811952324

Epoch: 6| Step: 3
Training loss: 0.930176854133606
Validation loss: 1.7344038050661805

Epoch: 6| Step: 4
Training loss: 0.4147804081439972
Validation loss: 1.7056380369329964

Epoch: 6| Step: 5
Training loss: 0.7045004367828369
Validation loss: 1.724778494527263

Epoch: 6| Step: 6
Training loss: 0.5525588393211365
Validation loss: 1.6645744667258313

Epoch: 6| Step: 7
Training loss: 1.0895015001296997
Validation loss: 1.7059103058230491

Epoch: 6| Step: 8
Training loss: 0.5968891978263855
Validation loss: 1.6281155129914642

Epoch: 6| Step: 9
Training loss: 0.3888689875602722
Validation loss: 1.6599512984675746

Epoch: 6| Step: 10
Training loss: 0.4929124116897583
Validation loss: 1.6813867040859756

Epoch: 6| Step: 11
Training loss: 0.5069682598114014
Validation loss: 1.6653260825782694

Epoch: 6| Step: 12
Training loss: 0.9764613509178162
Validation loss: 1.6427515155525618

Epoch: 6| Step: 13
Training loss: 0.5211328268051147
Validation loss: 1.684568452578719

Epoch: 671| Step: 0
Training loss: 0.7177037000656128
Validation loss: 1.6276882156249015

Epoch: 6| Step: 1
Training loss: 0.950760543346405
Validation loss: 1.6695344537817023

Epoch: 6| Step: 2
Training loss: 0.6322213411331177
Validation loss: 1.6780993733354794

Epoch: 6| Step: 3
Training loss: 0.40303167700767517
Validation loss: 1.688166905474919

Epoch: 6| Step: 4
Training loss: 0.5735282897949219
Validation loss: 1.6844092504952544

Epoch: 6| Step: 5
Training loss: 0.31082481145858765
Validation loss: 1.7458894316868117

Epoch: 6| Step: 6
Training loss: 0.8238223791122437
Validation loss: 1.6830963319347751

Epoch: 6| Step: 7
Training loss: 0.9724624752998352
Validation loss: 1.7322567932067379

Epoch: 6| Step: 8
Training loss: 0.5946433544158936
Validation loss: 1.797164326073021

Epoch: 6| Step: 9
Training loss: 0.8410141468048096
Validation loss: 1.7584141608207458

Epoch: 6| Step: 10
Training loss: 0.5249066948890686
Validation loss: 1.7353063962792838

Epoch: 6| Step: 11
Training loss: 0.6704860925674438
Validation loss: 1.7181833508194133

Epoch: 6| Step: 12
Training loss: 0.6533217430114746
Validation loss: 1.654464493515671

Epoch: 6| Step: 13
Training loss: 1.0009318590164185
Validation loss: 1.7175334166455012

Epoch: 672| Step: 0
Training loss: 0.7465085983276367
Validation loss: 1.708820104598999

Epoch: 6| Step: 1
Training loss: 0.801796555519104
Validation loss: 1.709804343920882

Epoch: 6| Step: 2
Training loss: 0.8879224061965942
Validation loss: 1.6965505935812508

Epoch: 6| Step: 3
Training loss: 0.46420955657958984
Validation loss: 1.6436827516043058

Epoch: 6| Step: 4
Training loss: 0.7455856800079346
Validation loss: 1.630375014838352

Epoch: 6| Step: 5
Training loss: 0.7195736765861511
Validation loss: 1.6279798502563148

Epoch: 6| Step: 6
Training loss: 0.9148625731468201
Validation loss: 1.657594516713132

Epoch: 6| Step: 7
Training loss: 0.4829410910606384
Validation loss: 1.6452781641355125

Epoch: 6| Step: 8
Training loss: 0.7232670187950134
Validation loss: 1.6907068913982761

Epoch: 6| Step: 9
Training loss: 0.4467077851295471
Validation loss: 1.647066641879338

Epoch: 6| Step: 10
Training loss: 0.49814051389694214
Validation loss: 1.6511656879096903

Epoch: 6| Step: 11
Training loss: 0.41494861245155334
Validation loss: 1.6582946520979687

Epoch: 6| Step: 12
Training loss: 0.7120046615600586
Validation loss: 1.6833390753756288

Epoch: 6| Step: 13
Training loss: 0.754683256149292
Validation loss: 1.666163839319701

Epoch: 673| Step: 0
Training loss: 0.455111026763916
Validation loss: 1.7369296127750027

Epoch: 6| Step: 1
Training loss: 1.0131821632385254
Validation loss: 1.6508485335175709

Epoch: 6| Step: 2
Training loss: 0.5150911808013916
Validation loss: 1.7226337476443219

Epoch: 6| Step: 3
Training loss: 0.7330983281135559
Validation loss: 1.6788958900718278

Epoch: 6| Step: 4
Training loss: 0.5315946936607361
Validation loss: 1.6858420320736465

Epoch: 6| Step: 5
Training loss: 0.5569086670875549
Validation loss: 1.68972824722208

Epoch: 6| Step: 6
Training loss: 0.6260136365890503
Validation loss: 1.6851014360304801

Epoch: 6| Step: 7
Training loss: 0.3295931816101074
Validation loss: 1.7146349337793165

Epoch: 6| Step: 8
Training loss: 0.6640228033065796
Validation loss: 1.6668624390837967

Epoch: 6| Step: 9
Training loss: 0.6565059423446655
Validation loss: 1.6421157198567544

Epoch: 6| Step: 10
Training loss: 0.6191777586936951
Validation loss: 1.6342215153478807

Epoch: 6| Step: 11
Training loss: 0.6295715570449829
Validation loss: 1.6584794111149286

Epoch: 6| Step: 12
Training loss: 0.9236905574798584
Validation loss: 1.6857496077014553

Epoch: 6| Step: 13
Training loss: 1.3896546363830566
Validation loss: 1.6385042064933366

Epoch: 674| Step: 0
Training loss: 0.4675590991973877
Validation loss: 1.7058427026194911

Epoch: 6| Step: 1
Training loss: 0.7451965808868408
Validation loss: 1.6801525469749206

Epoch: 6| Step: 2
Training loss: 0.5706123113632202
Validation loss: 1.6450919835798201

Epoch: 6| Step: 3
Training loss: 0.5564853549003601
Validation loss: 1.674663761610626

Epoch: 6| Step: 4
Training loss: 0.47052645683288574
Validation loss: 1.6795271340236868

Epoch: 6| Step: 5
Training loss: 0.4728580117225647
Validation loss: 1.6984011550103464

Epoch: 6| Step: 6
Training loss: 0.6975723505020142
Validation loss: 1.682512592243892

Epoch: 6| Step: 7
Training loss: 0.8613654375076294
Validation loss: 1.655707804105615

Epoch: 6| Step: 8
Training loss: 0.6255396604537964
Validation loss: 1.6762416965218

Epoch: 6| Step: 9
Training loss: 0.47827619314193726
Validation loss: 1.6399399208766159

Epoch: 6| Step: 10
Training loss: 0.7478910088539124
Validation loss: 1.6777064659262215

Epoch: 6| Step: 11
Training loss: 1.041700839996338
Validation loss: 1.648031550069009

Epoch: 6| Step: 12
Training loss: 1.1439526081085205
Validation loss: 1.6507193016749557

Epoch: 6| Step: 13
Training loss: 0.690352737903595
Validation loss: 1.6986784422269432

Epoch: 675| Step: 0
Training loss: 0.8316267728805542
Validation loss: 1.6170318203587686

Epoch: 6| Step: 1
Training loss: 0.7128105163574219
Validation loss: 1.697688865405257

Epoch: 6| Step: 2
Training loss: 0.5929321050643921
Validation loss: 1.6296184114230576

Epoch: 6| Step: 3
Training loss: 0.47450515627861023
Validation loss: 1.6759941385638328

Epoch: 6| Step: 4
Training loss: 0.48754942417144775
Validation loss: 1.6718017644779657

Epoch: 6| Step: 5
Training loss: 0.609157145023346
Validation loss: 1.58898720049089

Epoch: 6| Step: 6
Training loss: 0.5237084627151489
Validation loss: 1.677842297861653

Epoch: 6| Step: 7
Training loss: 1.2915196418762207
Validation loss: 1.6327842935439079

Epoch: 6| Step: 8
Training loss: 0.8851971626281738
Validation loss: 1.6688672470790085

Epoch: 6| Step: 9
Training loss: 0.7944691181182861
Validation loss: 1.6772061471016175

Epoch: 6| Step: 10
Training loss: 0.37297558784484863
Validation loss: 1.6802808828251337

Epoch: 6| Step: 11
Training loss: 0.35845980048179626
Validation loss: 1.6363092801904167

Epoch: 6| Step: 12
Training loss: 0.7613492012023926
Validation loss: 1.6731420088839788

Epoch: 6| Step: 13
Training loss: 0.5276532769203186
Validation loss: 1.6664874207588933

Epoch: 676| Step: 0
Training loss: 0.6554466485977173
Validation loss: 1.6311600656919583

Epoch: 6| Step: 1
Training loss: 0.9423738718032837
Validation loss: 1.6452789498913674

Epoch: 6| Step: 2
Training loss: 0.6030063629150391
Validation loss: 1.6967157176745835

Epoch: 6| Step: 3
Training loss: 0.7287153005599976
Validation loss: 1.7035108945702995

Epoch: 6| Step: 4
Training loss: 0.5273849964141846
Validation loss: 1.6637388249879241

Epoch: 6| Step: 5
Training loss: 0.5472739934921265
Validation loss: 1.687646480016811

Epoch: 6| Step: 6
Training loss: 0.6442155241966248
Validation loss: 1.6172548750395417

Epoch: 6| Step: 7
Training loss: 0.9441990852355957
Validation loss: 1.6698974294047202

Epoch: 6| Step: 8
Training loss: 0.697920024394989
Validation loss: 1.688112775484721

Epoch: 6| Step: 9
Training loss: 0.4253121018409729
Validation loss: 1.6991326937111475

Epoch: 6| Step: 10
Training loss: 0.4219914674758911
Validation loss: 1.6468891789836269

Epoch: 6| Step: 11
Training loss: 0.6231340169906616
Validation loss: 1.6740252138465963

Epoch: 6| Step: 12
Training loss: 0.6681456565856934
Validation loss: 1.6740365246290803

Epoch: 6| Step: 13
Training loss: 0.6095567345619202
Validation loss: 1.6547632781408166

Epoch: 677| Step: 0
Training loss: 0.4689294695854187
Validation loss: 1.631204887103009

Epoch: 6| Step: 1
Training loss: 0.6775333881378174
Validation loss: 1.6733314747451453

Epoch: 6| Step: 2
Training loss: 0.9340053200721741
Validation loss: 1.6149545882337837

Epoch: 6| Step: 3
Training loss: 0.9729102849960327
Validation loss: 1.6283621390660603

Epoch: 6| Step: 4
Training loss: 1.0395638942718506
Validation loss: 1.6731329079597228

Epoch: 6| Step: 5
Training loss: 0.7233849763870239
Validation loss: 1.592938312920191

Epoch: 6| Step: 6
Training loss: 0.6555953025817871
Validation loss: 1.6630145298537387

Epoch: 6| Step: 7
Training loss: 0.5028535723686218
Validation loss: 1.6624485613197408

Epoch: 6| Step: 8
Training loss: 0.576797604560852
Validation loss: 1.6964541994115359

Epoch: 6| Step: 9
Training loss: 0.652681827545166
Validation loss: 1.7449566446324831

Epoch: 6| Step: 10
Training loss: 0.47185051441192627
Validation loss: 1.655119155042915

Epoch: 6| Step: 11
Training loss: 0.39797934889793396
Validation loss: 1.6681780456214823

Epoch: 6| Step: 12
Training loss: 0.3506000339984894
Validation loss: 1.6770364546006726

Epoch: 6| Step: 13
Training loss: 0.8144163489341736
Validation loss: 1.7045726929941485

Epoch: 678| Step: 0
Training loss: 0.9181088209152222
Validation loss: 1.6551580621350197

Epoch: 6| Step: 1
Training loss: 0.5686052441596985
Validation loss: 1.7031314129470496

Epoch: 6| Step: 2
Training loss: 0.6900244355201721
Validation loss: 1.670688049767607

Epoch: 6| Step: 3
Training loss: 0.8579704761505127
Validation loss: 1.6998962215197984

Epoch: 6| Step: 4
Training loss: 0.5740446448326111
Validation loss: 1.6205224311479958

Epoch: 6| Step: 5
Training loss: 0.49076205492019653
Validation loss: 1.6617490040358676

Epoch: 6| Step: 6
Training loss: 0.5625983476638794
Validation loss: 1.6790104360990628

Epoch: 6| Step: 7
Training loss: 0.440696656703949
Validation loss: 1.6474409026484336

Epoch: 6| Step: 8
Training loss: 0.5080525875091553
Validation loss: 1.7070018245327858

Epoch: 6| Step: 9
Training loss: 0.7944605350494385
Validation loss: 1.668359548814835

Epoch: 6| Step: 10
Training loss: 0.5537232160568237
Validation loss: 1.6882496239036642

Epoch: 6| Step: 11
Training loss: 0.7723382711410522
Validation loss: 1.6809458822332404

Epoch: 6| Step: 12
Training loss: 0.6203052401542664
Validation loss: 1.6746996628340853

Epoch: 6| Step: 13
Training loss: 0.7827584743499756
Validation loss: 1.7514096588216803

Epoch: 679| Step: 0
Training loss: 0.6786501407623291
Validation loss: 1.712650127308343

Epoch: 6| Step: 1
Training loss: 1.3876017332077026
Validation loss: 1.7573582638976395

Epoch: 6| Step: 2
Training loss: 0.5000829100608826
Validation loss: 1.732756386521042

Epoch: 6| Step: 3
Training loss: 0.38565030694007874
Validation loss: 1.7306175193478983

Epoch: 6| Step: 4
Training loss: 0.6108725666999817
Validation loss: 1.744624581388248

Epoch: 6| Step: 5
Training loss: 0.6937965154647827
Validation loss: 1.7817349254444081

Epoch: 6| Step: 6
Training loss: 0.3667653203010559
Validation loss: 1.6507931857980707

Epoch: 6| Step: 7
Training loss: 0.8460791110992432
Validation loss: 1.6940786838531494

Epoch: 6| Step: 8
Training loss: 0.5880223512649536
Validation loss: 1.6845886656033096

Epoch: 6| Step: 9
Training loss: 0.8283425569534302
Validation loss: 1.6599631206963652

Epoch: 6| Step: 10
Training loss: 0.48046284914016724
Validation loss: 1.641642451286316

Epoch: 6| Step: 11
Training loss: 0.5349409580230713
Validation loss: 1.6287730368234778

Epoch: 6| Step: 12
Training loss: 0.7961666584014893
Validation loss: 1.6543386854151243

Epoch: 6| Step: 13
Training loss: 0.26600420475006104
Validation loss: 1.7001649218220865

Epoch: 680| Step: 0
Training loss: 0.43933606147766113
Validation loss: 1.6177669725110453

Epoch: 6| Step: 1
Training loss: 1.2469969987869263
Validation loss: 1.6141725317124398

Epoch: 6| Step: 2
Training loss: 0.48514872789382935
Validation loss: 1.6634493675283206

Epoch: 6| Step: 3
Training loss: 0.38014644384384155
Validation loss: 1.6780084756112867

Epoch: 6| Step: 4
Training loss: 0.42521506547927856
Validation loss: 1.6800419245996783

Epoch: 6| Step: 5
Training loss: 0.5246421694755554
Validation loss: 1.7067916931644562

Epoch: 6| Step: 6
Training loss: 0.7113226652145386
Validation loss: 1.7048127317941317

Epoch: 6| Step: 7
Training loss: 0.7140606641769409
Validation loss: 1.684179780303791

Epoch: 6| Step: 8
Training loss: 0.7783925533294678
Validation loss: 1.6823934124362083

Epoch: 6| Step: 9
Training loss: 0.6767711639404297
Validation loss: 1.6373082463459303

Epoch: 6| Step: 10
Training loss: 0.8528012037277222
Validation loss: 1.6602814812814035

Epoch: 6| Step: 11
Training loss: 0.279073566198349
Validation loss: 1.7074881445976995

Epoch: 6| Step: 12
Training loss: 0.4187124967575073
Validation loss: 1.7222416798273723

Epoch: 6| Step: 13
Training loss: 0.9706472754478455
Validation loss: 1.731221604090865

Epoch: 681| Step: 0
Training loss: 0.5574887990951538
Validation loss: 1.695199449857076

Epoch: 6| Step: 1
Training loss: 0.953269898891449
Validation loss: 1.7254911109965334

Epoch: 6| Step: 2
Training loss: 0.5253453254699707
Validation loss: 1.6836666548123924

Epoch: 6| Step: 3
Training loss: 0.36240047216415405
Validation loss: 1.6679781598429526

Epoch: 6| Step: 4
Training loss: 0.548336386680603
Validation loss: 1.6796014103838193

Epoch: 6| Step: 5
Training loss: 0.4395137131214142
Validation loss: 1.699166109485011

Epoch: 6| Step: 6
Training loss: 1.1381194591522217
Validation loss: 1.6630591372007966

Epoch: 6| Step: 7
Training loss: 0.7973034381866455
Validation loss: 1.6441860429702266

Epoch: 6| Step: 8
Training loss: 0.3522966504096985
Validation loss: 1.6995503428161784

Epoch: 6| Step: 9
Training loss: 0.41583016514778137
Validation loss: 1.6460942901590818

Epoch: 6| Step: 10
Training loss: 0.9265857338905334
Validation loss: 1.6595774196809339

Epoch: 6| Step: 11
Training loss: 0.49187180399894714
Validation loss: 1.6518488878844886

Epoch: 6| Step: 12
Training loss: 0.8936326503753662
Validation loss: 1.6332800196063133

Epoch: 6| Step: 13
Training loss: 0.4946590065956116
Validation loss: 1.6608234669572564

Epoch: 682| Step: 0
Training loss: 0.42483773827552795
Validation loss: 1.6636698476729854

Epoch: 6| Step: 1
Training loss: 0.6468115448951721
Validation loss: 1.6568905474037252

Epoch: 6| Step: 2
Training loss: 0.9029175043106079
Validation loss: 1.684762793202554

Epoch: 6| Step: 3
Training loss: 0.619807243347168
Validation loss: 1.63940804876307

Epoch: 6| Step: 4
Training loss: 0.7913113832473755
Validation loss: 1.5946621535926737

Epoch: 6| Step: 5
Training loss: 0.629253625869751
Validation loss: 1.650960873532039

Epoch: 6| Step: 6
Training loss: 0.4942949414253235
Validation loss: 1.6868066467264646

Epoch: 6| Step: 7
Training loss: 0.5117403268814087
Validation loss: 1.6220646058359454

Epoch: 6| Step: 8
Training loss: 0.5264211893081665
Validation loss: 1.6497903280360724

Epoch: 6| Step: 9
Training loss: 0.8594068884849548
Validation loss: 1.6458149033208047

Epoch: 6| Step: 10
Training loss: 0.5848051309585571
Validation loss: 1.7442445857550508

Epoch: 6| Step: 11
Training loss: 0.5773075819015503
Validation loss: 1.6989674465630644

Epoch: 6| Step: 12
Training loss: 0.7641963958740234
Validation loss: 1.720588530263593

Epoch: 6| Step: 13
Training loss: 1.1817755699157715
Validation loss: 1.7087187587573964

Epoch: 683| Step: 0
Training loss: 0.5293965339660645
Validation loss: 1.6890045981253348

Epoch: 6| Step: 1
Training loss: 0.8394131660461426
Validation loss: 1.630978157443385

Epoch: 6| Step: 2
Training loss: 0.7127869129180908
Validation loss: 1.6729170122454244

Epoch: 6| Step: 3
Training loss: 0.5117919445037842
Validation loss: 1.6709824287763206

Epoch: 6| Step: 4
Training loss: 0.5268206596374512
Validation loss: 1.629853448560161

Epoch: 6| Step: 5
Training loss: 0.8336292505264282
Validation loss: 1.6118828891426005

Epoch: 6| Step: 6
Training loss: 0.5194079875946045
Validation loss: 1.6775492211823821

Epoch: 6| Step: 7
Training loss: 1.0328930616378784
Validation loss: 1.6790067226656022

Epoch: 6| Step: 8
Training loss: 0.6139041781425476
Validation loss: 1.667857869978874

Epoch: 6| Step: 9
Training loss: 0.720942497253418
Validation loss: 1.6787199519013847

Epoch: 6| Step: 10
Training loss: 0.43821072578430176
Validation loss: 1.6318850709545998

Epoch: 6| Step: 11
Training loss: 0.6604753732681274
Validation loss: 1.651259510747848

Epoch: 6| Step: 12
Training loss: 0.6262420415878296
Validation loss: 1.6796303038956018

Epoch: 6| Step: 13
Training loss: 0.7403485774993896
Validation loss: 1.6770247195356636

Epoch: 684| Step: 0
Training loss: 0.66362464427948
Validation loss: 1.6697419458819973

Epoch: 6| Step: 1
Training loss: 0.3479270935058594
Validation loss: 1.667474103230302

Epoch: 6| Step: 2
Training loss: 0.7473635673522949
Validation loss: 1.6597556914052656

Epoch: 6| Step: 3
Training loss: 0.7301936745643616
Validation loss: 1.6679131677073817

Epoch: 6| Step: 4
Training loss: 0.6760752201080322
Validation loss: 1.6682904074268956

Epoch: 6| Step: 5
Training loss: 0.44946274161338806
Validation loss: 1.6537182529767354

Epoch: 6| Step: 6
Training loss: 0.55701744556427
Validation loss: 1.649616713164955

Epoch: 6| Step: 7
Training loss: 0.6991499662399292
Validation loss: 1.6671221358801729

Epoch: 6| Step: 8
Training loss: 0.8271595239639282
Validation loss: 1.6671733638291717

Epoch: 6| Step: 9
Training loss: 0.671565592288971
Validation loss: 1.6111447990581553

Epoch: 6| Step: 10
Training loss: 0.42777833342552185
Validation loss: 1.6615350137474716

Epoch: 6| Step: 11
Training loss: 1.0325572490692139
Validation loss: 1.6546526506382933

Epoch: 6| Step: 12
Training loss: 0.6925218105316162
Validation loss: 1.6831778659615466

Epoch: 6| Step: 13
Training loss: 0.7147460579872131
Validation loss: 1.631159774718746

Epoch: 685| Step: 0
Training loss: 0.5452621579170227
Validation loss: 1.6879903962535243

Epoch: 6| Step: 1
Training loss: 0.7237407565116882
Validation loss: 1.630597988764445

Epoch: 6| Step: 2
Training loss: 0.6763795614242554
Validation loss: 1.6611288452661166

Epoch: 6| Step: 3
Training loss: 0.44027701020240784
Validation loss: 1.6850765187253234

Epoch: 6| Step: 4
Training loss: 0.7320577502250671
Validation loss: 1.6542987131303357

Epoch: 6| Step: 5
Training loss: 0.9710581302642822
Validation loss: 1.6848277225289294

Epoch: 6| Step: 6
Training loss: 0.8217738270759583
Validation loss: 1.6583428690510411

Epoch: 6| Step: 7
Training loss: 0.5635513067245483
Validation loss: 1.6628885038437382

Epoch: 6| Step: 8
Training loss: 0.36465710401535034
Validation loss: 1.6653977132612658

Epoch: 6| Step: 9
Training loss: 0.9092887043952942
Validation loss: 1.6303053414949806

Epoch: 6| Step: 10
Training loss: 0.5849977135658264
Validation loss: 1.5987100549923476

Epoch: 6| Step: 11
Training loss: 0.7416226267814636
Validation loss: 1.6360978311108005

Epoch: 6| Step: 12
Training loss: 0.34362494945526123
Validation loss: 1.6602899694955477

Epoch: 6| Step: 13
Training loss: 0.8281400799751282
Validation loss: 1.6445504567956413

Epoch: 686| Step: 0
Training loss: 0.5676060318946838
Validation loss: 1.6332790120955436

Epoch: 6| Step: 1
Training loss: 0.6209714412689209
Validation loss: 1.6626485752803024

Epoch: 6| Step: 2
Training loss: 0.5419743061065674
Validation loss: 1.661205736539697

Epoch: 6| Step: 3
Training loss: 0.7046802043914795
Validation loss: 1.6831107024223573

Epoch: 6| Step: 4
Training loss: 0.42020493745803833
Validation loss: 1.6408403996498353

Epoch: 6| Step: 5
Training loss: 0.4495358467102051
Validation loss: 1.6817488272984822

Epoch: 6| Step: 6
Training loss: 0.5418583154678345
Validation loss: 1.690242362278764

Epoch: 6| Step: 7
Training loss: 0.9198156595230103
Validation loss: 1.6486855168496408

Epoch: 6| Step: 8
Training loss: 0.8365217447280884
Validation loss: 1.6478062868118286

Epoch: 6| Step: 9
Training loss: 0.9570515155792236
Validation loss: 1.6485034355553247

Epoch: 6| Step: 10
Training loss: 0.3404310941696167
Validation loss: 1.6417130488221363

Epoch: 6| Step: 11
Training loss: 0.8619248270988464
Validation loss: 1.6363470259533133

Epoch: 6| Step: 12
Training loss: 0.5208667516708374
Validation loss: 1.687050029795657

Epoch: 6| Step: 13
Training loss: 0.4182112216949463
Validation loss: 1.6553847225763465

Epoch: 687| Step: 0
Training loss: 0.7441942691802979
Validation loss: 1.6559271504802089

Epoch: 6| Step: 1
Training loss: 0.5373724102973938
Validation loss: 1.649639723121479

Epoch: 6| Step: 2
Training loss: 0.5823864340782166
Validation loss: 1.6178652112201979

Epoch: 6| Step: 3
Training loss: 0.7605186104774475
Validation loss: 1.6461687325149454

Epoch: 6| Step: 4
Training loss: 0.4445500373840332
Validation loss: 1.679559043658677

Epoch: 6| Step: 5
Training loss: 0.9114705324172974
Validation loss: 1.64956739641005

Epoch: 6| Step: 6
Training loss: 0.8204530477523804
Validation loss: 1.7243385391850625

Epoch: 6| Step: 7
Training loss: 0.2679474353790283
Validation loss: 1.6648504285402195

Epoch: 6| Step: 8
Training loss: 0.6269885897636414
Validation loss: 1.654976479468807

Epoch: 6| Step: 9
Training loss: 0.6450275182723999
Validation loss: 1.6209221116958126

Epoch: 6| Step: 10
Training loss: 0.5423546433448792
Validation loss: 1.6445246409344416

Epoch: 6| Step: 11
Training loss: 1.257086157798767
Validation loss: 1.660928814641891

Epoch: 6| Step: 12
Training loss: 0.4537670314311981
Validation loss: 1.67422015436234

Epoch: 6| Step: 13
Training loss: 0.3167358934879303
Validation loss: 1.6614100817711122

Epoch: 688| Step: 0
Training loss: 0.9104760885238647
Validation loss: 1.6325201167855212

Epoch: 6| Step: 1
Training loss: 0.47041481733322144
Validation loss: 1.6478856122621925

Epoch: 6| Step: 2
Training loss: 0.4734106659889221
Validation loss: 1.6782592394018685

Epoch: 6| Step: 3
Training loss: 0.5102308988571167
Validation loss: 1.6841966298318678

Epoch: 6| Step: 4
Training loss: 0.45261526107788086
Validation loss: 1.6798584717576222

Epoch: 6| Step: 5
Training loss: 0.7032167315483093
Validation loss: 1.6303912029471448

Epoch: 6| Step: 6
Training loss: 0.922498345375061
Validation loss: 1.6381399887864307

Epoch: 6| Step: 7
Training loss: 0.596348762512207
Validation loss: 1.6707325404690159

Epoch: 6| Step: 8
Training loss: 0.3737982511520386
Validation loss: 1.6958551112041678

Epoch: 6| Step: 9
Training loss: 1.0808782577514648
Validation loss: 1.703046856387969

Epoch: 6| Step: 10
Training loss: 0.6287713050842285
Validation loss: 1.6698555741258847

Epoch: 6| Step: 11
Training loss: 0.862206757068634
Validation loss: 1.6751253630525322

Epoch: 6| Step: 12
Training loss: 0.5116642713546753
Validation loss: 1.666593805436165

Epoch: 6| Step: 13
Training loss: 0.1972915530204773
Validation loss: 1.6711918230979674

Epoch: 689| Step: 0
Training loss: 0.9206632375717163
Validation loss: 1.7404743048452562

Epoch: 6| Step: 1
Training loss: 0.4498927593231201
Validation loss: 1.6312833588610414

Epoch: 6| Step: 2
Training loss: 0.6810168027877808
Validation loss: 1.6530189744887813

Epoch: 6| Step: 3
Training loss: 0.5893362760543823
Validation loss: 1.6596658601555774

Epoch: 6| Step: 4
Training loss: 0.5121899843215942
Validation loss: 1.639947888671711

Epoch: 6| Step: 5
Training loss: 0.9119783639907837
Validation loss: 1.6091932186516382

Epoch: 6| Step: 6
Training loss: 0.6685060858726501
Validation loss: 1.7063915857704737

Epoch: 6| Step: 7
Training loss: 0.4413272738456726
Validation loss: 1.7402149310676

Epoch: 6| Step: 8
Training loss: 1.2431427240371704
Validation loss: 1.7261960762803272

Epoch: 6| Step: 9
Training loss: 0.7404735088348389
Validation loss: 1.6949968491831133

Epoch: 6| Step: 10
Training loss: 0.4646349549293518
Validation loss: 1.6619216806145125

Epoch: 6| Step: 11
Training loss: 0.3736210763454437
Validation loss: 1.6696843434405584

Epoch: 6| Step: 12
Training loss: 0.622529149055481
Validation loss: 1.6352090053660895

Epoch: 6| Step: 13
Training loss: 0.6522237062454224
Validation loss: 1.6864899217441518

Epoch: 690| Step: 0
Training loss: 0.689000129699707
Validation loss: 1.6448722988046625

Epoch: 6| Step: 1
Training loss: 0.9834803342819214
Validation loss: 1.6968506190084642

Epoch: 6| Step: 2
Training loss: 0.6081506013870239
Validation loss: 1.6359852372959096

Epoch: 6| Step: 3
Training loss: 0.6598266363143921
Validation loss: 1.6220226198114374

Epoch: 6| Step: 4
Training loss: 0.466541051864624
Validation loss: 1.6221548113771664

Epoch: 6| Step: 5
Training loss: 0.45684248208999634
Validation loss: 1.6455526198110273

Epoch: 6| Step: 6
Training loss: 0.44816288352012634
Validation loss: 1.6721648939194218

Epoch: 6| Step: 7
Training loss: 0.49587568640708923
Validation loss: 1.63141926001477

Epoch: 6| Step: 8
Training loss: 0.5651082992553711
Validation loss: 1.7178412560493714

Epoch: 6| Step: 9
Training loss: 0.6120757460594177
Validation loss: 1.6738356364670621

Epoch: 6| Step: 10
Training loss: 0.8570078611373901
Validation loss: 1.685013419838362

Epoch: 6| Step: 11
Training loss: 0.38031622767448425
Validation loss: 1.6768135338701227

Epoch: 6| Step: 12
Training loss: 0.9685757160186768
Validation loss: 1.669323775076097

Epoch: 6| Step: 13
Training loss: 0.4808555245399475
Validation loss: 1.6884894447941934

Epoch: 691| Step: 0
Training loss: 0.7263661623001099
Validation loss: 1.6720124508744927

Epoch: 6| Step: 1
Training loss: 0.44269055128097534
Validation loss: 1.6237736825020082

Epoch: 6| Step: 2
Training loss: 0.8263329863548279
Validation loss: 1.664443249343544

Epoch: 6| Step: 3
Training loss: 0.397319495677948
Validation loss: 1.6822999382531771

Epoch: 6| Step: 4
Training loss: 0.6912848353385925
Validation loss: 1.6468135746576453

Epoch: 6| Step: 5
Training loss: 0.884356677532196
Validation loss: 1.6478012351579563

Epoch: 6| Step: 6
Training loss: 0.47585704922676086
Validation loss: 1.6386367172323248

Epoch: 6| Step: 7
Training loss: 0.39821332693099976
Validation loss: 1.6628978226774482

Epoch: 6| Step: 8
Training loss: 0.3684476613998413
Validation loss: 1.6246436821517123

Epoch: 6| Step: 9
Training loss: 1.0493654012680054
Validation loss: 1.6264959150745022

Epoch: 6| Step: 10
Training loss: 0.49725639820098877
Validation loss: 1.6845632214700021

Epoch: 6| Step: 11
Training loss: 1.0564252138137817
Validation loss: 1.6688994355099176

Epoch: 6| Step: 12
Training loss: 0.4500906467437744
Validation loss: 1.7065824231793802

Epoch: 6| Step: 13
Training loss: 0.30268722772598267
Validation loss: 1.660896493542579

Epoch: 692| Step: 0
Training loss: 0.6060701608657837
Validation loss: 1.6675180671035603

Epoch: 6| Step: 1
Training loss: 0.6950311064720154
Validation loss: 1.6944672189733034

Epoch: 6| Step: 2
Training loss: 0.9421865940093994
Validation loss: 1.6924548661837013

Epoch: 6| Step: 3
Training loss: 0.8479642868041992
Validation loss: 1.7312240023766794

Epoch: 6| Step: 4
Training loss: 0.3377841114997864
Validation loss: 1.7262584893934187

Epoch: 6| Step: 5
Training loss: 0.5388984680175781
Validation loss: 1.6344802559062999

Epoch: 6| Step: 6
Training loss: 0.6797904968261719
Validation loss: 1.671367173553795

Epoch: 6| Step: 7
Training loss: 0.7140580415725708
Validation loss: 1.6315920673390871

Epoch: 6| Step: 8
Training loss: 0.47757744789123535
Validation loss: 1.6340772721075243

Epoch: 6| Step: 9
Training loss: 0.33852148056030273
Validation loss: 1.6449486235136628

Epoch: 6| Step: 10
Training loss: 0.3421967625617981
Validation loss: 1.7197587605445617

Epoch: 6| Step: 11
Training loss: 1.136849045753479
Validation loss: 1.654914347074365

Epoch: 6| Step: 12
Training loss: 0.6708478927612305
Validation loss: 1.6640611899796354

Epoch: 6| Step: 13
Training loss: 0.8043825626373291
Validation loss: 1.6564178473205977

Epoch: 693| Step: 0
Training loss: 0.6215615272521973
Validation loss: 1.7016331175322175

Epoch: 6| Step: 1
Training loss: 0.2694709002971649
Validation loss: 1.7701145718174596

Epoch: 6| Step: 2
Training loss: 0.9424742460250854
Validation loss: 1.6724780567230717

Epoch: 6| Step: 3
Training loss: 0.5294822454452515
Validation loss: 1.6597607507500598

Epoch: 6| Step: 4
Training loss: 1.2969999313354492
Validation loss: 1.7102938640502192

Epoch: 6| Step: 5
Training loss: 0.45818135142326355
Validation loss: 1.7123705238424323

Epoch: 6| Step: 6
Training loss: 0.6130037903785706
Validation loss: 1.657906409232847

Epoch: 6| Step: 7
Training loss: 0.4019047021865845
Validation loss: 1.7011494867263302

Epoch: 6| Step: 8
Training loss: 0.6381174921989441
Validation loss: 1.7223428654414352

Epoch: 6| Step: 9
Training loss: 0.8839465975761414
Validation loss: 1.6545164738931963

Epoch: 6| Step: 10
Training loss: 0.7730822563171387
Validation loss: 1.6981816804537209

Epoch: 6| Step: 11
Training loss: 0.7679713368415833
Validation loss: 1.6444407047763947

Epoch: 6| Step: 12
Training loss: 0.2875403165817261
Validation loss: 1.6206310641381048

Epoch: 6| Step: 13
Training loss: 0.4957561492919922
Validation loss: 1.6903163797111922

Epoch: 694| Step: 0
Training loss: 0.551554799079895
Validation loss: 1.6583414334122852

Epoch: 6| Step: 1
Training loss: 0.836795449256897
Validation loss: 1.6624403589515275

Epoch: 6| Step: 2
Training loss: 0.6075931191444397
Validation loss: 1.6437946916908346

Epoch: 6| Step: 3
Training loss: 0.7295405268669128
Validation loss: 1.686492645612327

Epoch: 6| Step: 4
Training loss: 0.6966264843940735
Validation loss: 1.617151633385689

Epoch: 6| Step: 5
Training loss: 0.6321864128112793
Validation loss: 1.65669769881874

Epoch: 6| Step: 6
Training loss: 0.5792085528373718
Validation loss: 1.7077016112624959

Epoch: 6| Step: 7
Training loss: 0.5777453780174255
Validation loss: 1.6646142352011897

Epoch: 6| Step: 8
Training loss: 0.42664942145347595
Validation loss: 1.7446589444273262

Epoch: 6| Step: 9
Training loss: 0.41344359517097473
Validation loss: 1.6674705038788498

Epoch: 6| Step: 10
Training loss: 0.5225973129272461
Validation loss: 1.72992278170842

Epoch: 6| Step: 11
Training loss: 0.45781219005584717
Validation loss: 1.635825308420325

Epoch: 6| Step: 12
Training loss: 1.173492193222046
Validation loss: 1.6782741764540314

Epoch: 6| Step: 13
Training loss: 0.6286832690238953
Validation loss: 1.6770827565141904

Epoch: 695| Step: 0
Training loss: 0.6125109195709229
Validation loss: 1.6689750968769033

Epoch: 6| Step: 1
Training loss: 0.8940249085426331
Validation loss: 1.660326127723981

Epoch: 6| Step: 2
Training loss: 0.8966156244277954
Validation loss: 1.6521214926114647

Epoch: 6| Step: 3
Training loss: 0.8417608737945557
Validation loss: 1.6431844554921633

Epoch: 6| Step: 4
Training loss: 0.3500264585018158
Validation loss: 1.6198018558563725

Epoch: 6| Step: 5
Training loss: 0.8395954370498657
Validation loss: 1.6592558724905855

Epoch: 6| Step: 6
Training loss: 0.7922757267951965
Validation loss: 1.6666008182751235

Epoch: 6| Step: 7
Training loss: 0.7097344398498535
Validation loss: 1.6536966023906585

Epoch: 6| Step: 8
Training loss: 0.5087619423866272
Validation loss: 1.6198042656785698

Epoch: 6| Step: 9
Training loss: 0.6679218411445618
Validation loss: 1.5915359450924782

Epoch: 6| Step: 10
Training loss: 0.5454437136650085
Validation loss: 1.6339564765653303

Epoch: 6| Step: 11
Training loss: 0.4535682201385498
Validation loss: 1.6462928248989968

Epoch: 6| Step: 12
Training loss: 0.5048519372940063
Validation loss: 1.6933799212978733

Epoch: 6| Step: 13
Training loss: 0.3360919952392578
Validation loss: 1.7145665819926927

Epoch: 696| Step: 0
Training loss: 1.2154252529144287
Validation loss: 1.7265977359587146

Epoch: 6| Step: 1
Training loss: 0.41823655366897583
Validation loss: 1.691225944026824

Epoch: 6| Step: 2
Training loss: 0.35671135783195496
Validation loss: 1.7067641404367262

Epoch: 6| Step: 3
Training loss: 0.3774212896823883
Validation loss: 1.7245221894274476

Epoch: 6| Step: 4
Training loss: 0.9806380867958069
Validation loss: 1.7146301320804063

Epoch: 6| Step: 5
Training loss: 0.5458090305328369
Validation loss: 1.7337122296774259

Epoch: 6| Step: 6
Training loss: 0.7957407236099243
Validation loss: 1.6293920932277557

Epoch: 6| Step: 7
Training loss: 0.8423663377761841
Validation loss: 1.6328459228238752

Epoch: 6| Step: 8
Training loss: 0.4075253903865814
Validation loss: 1.6242243602711668

Epoch: 6| Step: 9
Training loss: 0.7178016901016235
Validation loss: 1.6983457021815802

Epoch: 6| Step: 10
Training loss: 0.6147446632385254
Validation loss: 1.66969802559063

Epoch: 6| Step: 11
Training loss: 0.4828847050666809
Validation loss: 1.6431334044343682

Epoch: 6| Step: 12
Training loss: 0.4742991328239441
Validation loss: 1.5721007239434026

Epoch: 6| Step: 13
Training loss: 0.6837005019187927
Validation loss: 1.7132601507248417

Epoch: 697| Step: 0
Training loss: 0.4615178108215332
Validation loss: 1.6694927010484921

Epoch: 6| Step: 1
Training loss: 0.6344990134239197
Validation loss: 1.637379087427611

Epoch: 6| Step: 2
Training loss: 0.6877135038375854
Validation loss: 1.6126947082499021

Epoch: 6| Step: 3
Training loss: 0.4168836772441864
Validation loss: 1.6628643364034674

Epoch: 6| Step: 4
Training loss: 0.6550867557525635
Validation loss: 1.6488244482266006

Epoch: 6| Step: 5
Training loss: 0.7934666275978088
Validation loss: 1.73249606163271

Epoch: 6| Step: 6
Training loss: 1.028889536857605
Validation loss: 1.6994828485673474

Epoch: 6| Step: 7
Training loss: 0.668437123298645
Validation loss: 1.7660410711842198

Epoch: 6| Step: 8
Training loss: 1.1370365619659424
Validation loss: 1.7323155556955645

Epoch: 6| Step: 9
Training loss: 0.962038516998291
Validation loss: 1.7412231417112454

Epoch: 6| Step: 10
Training loss: 0.7721763849258423
Validation loss: 1.7736197915128482

Epoch: 6| Step: 11
Training loss: 0.5509713888168335
Validation loss: 1.6749884864335418

Epoch: 6| Step: 12
Training loss: 0.40938854217529297
Validation loss: 1.6669378511367305

Epoch: 6| Step: 13
Training loss: 0.5141236186027527
Validation loss: 1.6560148641627321

Epoch: 698| Step: 0
Training loss: 0.8048405647277832
Validation loss: 1.6034367866413568

Epoch: 6| Step: 1
Training loss: 0.9568355083465576
Validation loss: 1.6637212864814266

Epoch: 6| Step: 2
Training loss: 0.605954647064209
Validation loss: 1.6414967160071097

Epoch: 6| Step: 3
Training loss: 0.6523594260215759
Validation loss: 1.5988155731590845

Epoch: 6| Step: 4
Training loss: 0.7110756039619446
Validation loss: 1.649249061461418

Epoch: 6| Step: 5
Training loss: 0.6379474401473999
Validation loss: 1.599696215762887

Epoch: 6| Step: 6
Training loss: 0.8333014249801636
Validation loss: 1.644403621073692

Epoch: 6| Step: 7
Training loss: 0.7905822992324829
Validation loss: 1.6596033855151104

Epoch: 6| Step: 8
Training loss: 0.4948611855506897
Validation loss: 1.7175924310120203

Epoch: 6| Step: 9
Training loss: 0.41015908122062683
Validation loss: 1.6926767390261415

Epoch: 6| Step: 10
Training loss: 0.8908334970474243
Validation loss: 1.714733354506954

Epoch: 6| Step: 11
Training loss: 0.3289271593093872
Validation loss: 1.6970813351292764

Epoch: 6| Step: 12
Training loss: 0.960192084312439
Validation loss: 1.7003200566896828

Epoch: 6| Step: 13
Training loss: 0.3034188449382782
Validation loss: 1.6467305614102272

Epoch: 699| Step: 0
Training loss: 0.7997745275497437
Validation loss: 1.6765126707733318

Epoch: 6| Step: 1
Training loss: 0.5780007243156433
Validation loss: 1.6394923181943997

Epoch: 6| Step: 2
Training loss: 0.4164203405380249
Validation loss: 1.6536548342756046

Epoch: 6| Step: 3
Training loss: 0.7852264642715454
Validation loss: 1.6548685284071072

Epoch: 6| Step: 4
Training loss: 0.39349818229675293
Validation loss: 1.6115915083116101

Epoch: 6| Step: 5
Training loss: 0.5746093392372131
Validation loss: 1.663343568002024

Epoch: 6| Step: 6
Training loss: 0.6046066284179688
Validation loss: 1.6742696787721367

Epoch: 6| Step: 7
Training loss: 0.8204669952392578
Validation loss: 1.643592280726279

Epoch: 6| Step: 8
Training loss: 0.25410279631614685
Validation loss: 1.6804002574695054

Epoch: 6| Step: 9
Training loss: 0.7856188416481018
Validation loss: 1.667248878427731

Epoch: 6| Step: 10
Training loss: 0.9868981838226318
Validation loss: 1.7078968594151158

Epoch: 6| Step: 11
Training loss: 0.4855791926383972
Validation loss: 1.7201374923029253

Epoch: 6| Step: 12
Training loss: 1.0588860511779785
Validation loss: 1.789068498919087

Epoch: 6| Step: 13
Training loss: 0.4214826822280884
Validation loss: 1.7328153464101976

Epoch: 700| Step: 0
Training loss: 0.34892815351486206
Validation loss: 1.7296344964734969

Epoch: 6| Step: 1
Training loss: 0.3815099596977234
Validation loss: 1.7027380697188839

Epoch: 6| Step: 2
Training loss: 0.9347041249275208
Validation loss: 1.692201655398133

Epoch: 6| Step: 3
Training loss: 1.0651955604553223
Validation loss: 1.6463298695061797

Epoch: 6| Step: 4
Training loss: 0.5969066619873047
Validation loss: 1.6715213483379734

Epoch: 6| Step: 5
Training loss: 0.5357258319854736
Validation loss: 1.6751903564699235

Epoch: 6| Step: 6
Training loss: 0.8550711870193481
Validation loss: 1.6450364384599911

Epoch: 6| Step: 7
Training loss: 0.532039999961853
Validation loss: 1.6647194098400813

Epoch: 6| Step: 8
Training loss: 0.5726918578147888
Validation loss: 1.6199571573606102

Epoch: 6| Step: 9
Training loss: 0.6514636874198914
Validation loss: 1.6560624081601378

Epoch: 6| Step: 10
Training loss: 0.6916510462760925
Validation loss: 1.688604188221757

Epoch: 6| Step: 11
Training loss: 0.5448359251022339
Validation loss: 1.6581757465998332

Epoch: 6| Step: 12
Training loss: 0.4704080820083618
Validation loss: 1.6916910704746042

Epoch: 6| Step: 13
Training loss: 0.6060211658477783
Validation loss: 1.6382729673898349

Epoch: 701| Step: 0
Training loss: 0.3113009035587311
Validation loss: 1.6168373310437767

Epoch: 6| Step: 1
Training loss: 0.23066726326942444
Validation loss: 1.6893185889849098

Epoch: 6| Step: 2
Training loss: 1.0176743268966675
Validation loss: 1.6744828172909316

Epoch: 6| Step: 3
Training loss: 0.8757697343826294
Validation loss: 1.6463141518254434

Epoch: 6| Step: 4
Training loss: 0.6571861505508423
Validation loss: 1.697948810874775

Epoch: 6| Step: 5
Training loss: 0.40392619371414185
Validation loss: 1.6428165666518673

Epoch: 6| Step: 6
Training loss: 0.4600314199924469
Validation loss: 1.6673431524666407

Epoch: 6| Step: 7
Training loss: 0.6279551982879639
Validation loss: 1.687915704583609

Epoch: 6| Step: 8
Training loss: 0.45931172370910645
Validation loss: 1.6267795742198985

Epoch: 6| Step: 9
Training loss: 0.4918254613876343
Validation loss: 1.6200466489279142

Epoch: 6| Step: 10
Training loss: 0.6839606165885925
Validation loss: 1.6216189528024325

Epoch: 6| Step: 11
Training loss: 1.1591724157333374
Validation loss: 1.614698798425736

Epoch: 6| Step: 12
Training loss: 0.5113281607627869
Validation loss: 1.5994325325053225

Epoch: 6| Step: 13
Training loss: 0.446006715297699
Validation loss: 1.6546810301401282

Epoch: 702| Step: 0
Training loss: 0.9433671236038208
Validation loss: 1.619200735963801

Epoch: 6| Step: 1
Training loss: 0.9563626050949097
Validation loss: 1.6287820749385382

Epoch: 6| Step: 2
Training loss: 0.5034221410751343
Validation loss: 1.6317622994863858

Epoch: 6| Step: 3
Training loss: 0.5462566614151001
Validation loss: 1.6544788652850735

Epoch: 6| Step: 4
Training loss: 0.7471305727958679
Validation loss: 1.6455197744472052

Epoch: 6| Step: 5
Training loss: 0.5917154550552368
Validation loss: 1.625044661183511

Epoch: 6| Step: 6
Training loss: 0.2653752565383911
Validation loss: 1.6096334982943792

Epoch: 6| Step: 7
Training loss: 0.6255239844322205
Validation loss: 1.6389206852964175

Epoch: 6| Step: 8
Training loss: 0.8069717884063721
Validation loss: 1.5774966183529104

Epoch: 6| Step: 9
Training loss: 0.6094282865524292
Validation loss: 1.6483875589986001

Epoch: 6| Step: 10
Training loss: 0.4133950471878052
Validation loss: 1.63606842102543

Epoch: 6| Step: 11
Training loss: 0.664368748664856
Validation loss: 1.640018980990174

Epoch: 6| Step: 12
Training loss: 0.5324835181236267
Validation loss: 1.6764031828090709

Epoch: 6| Step: 13
Training loss: 0.5904321074485779
Validation loss: 1.6894895312606648

Epoch: 703| Step: 0
Training loss: 0.7299122214317322
Validation loss: 1.69607215158401

Epoch: 6| Step: 1
Training loss: 0.5049234628677368
Validation loss: 1.6564006081191442

Epoch: 6| Step: 2
Training loss: 0.5681686401367188
Validation loss: 1.6443740501198718

Epoch: 6| Step: 3
Training loss: 0.42755913734436035
Validation loss: 1.6627783160055838

Epoch: 6| Step: 4
Training loss: 0.5277507305145264
Validation loss: 1.6720178832289994

Epoch: 6| Step: 5
Training loss: 0.8565312623977661
Validation loss: 1.6400424421474498

Epoch: 6| Step: 6
Training loss: 0.6479849219322205
Validation loss: 1.7063451249112365

Epoch: 6| Step: 7
Training loss: 0.7657385468482971
Validation loss: 1.6256095593975437

Epoch: 6| Step: 8
Training loss: 0.7063337564468384
Validation loss: 1.6147608680109824

Epoch: 6| Step: 9
Training loss: 0.7693737149238586
Validation loss: 1.5886837949034989

Epoch: 6| Step: 10
Training loss: 0.6423530578613281
Validation loss: 1.724727347332944

Epoch: 6| Step: 11
Training loss: 0.3645630478858948
Validation loss: 1.6430450113870765

Epoch: 6| Step: 12
Training loss: 0.3268328309059143
Validation loss: 1.6425872387424592

Epoch: 6| Step: 13
Training loss: 1.171934962272644
Validation loss: 1.670318841934204

Epoch: 704| Step: 0
Training loss: 0.2928207218647003
Validation loss: 1.6318455767887894

Epoch: 6| Step: 1
Training loss: 0.44743430614471436
Validation loss: 1.6799283963377758

Epoch: 6| Step: 2
Training loss: 0.3616490960121155
Validation loss: 1.701319743228215

Epoch: 6| Step: 3
Training loss: 0.5753803253173828
Validation loss: 1.6773222774587653

Epoch: 6| Step: 4
Training loss: 0.532871425151825
Validation loss: 1.6683272892428982

Epoch: 6| Step: 5
Training loss: 0.7003607153892517
Validation loss: 1.6890635349417245

Epoch: 6| Step: 6
Training loss: 0.8935084342956543
Validation loss: 1.695921072395899

Epoch: 6| Step: 7
Training loss: 0.9663299322128296
Validation loss: 1.6282276889329315

Epoch: 6| Step: 8
Training loss: 0.44894862174987793
Validation loss: 1.6140489424428632

Epoch: 6| Step: 9
Training loss: 0.6481693983078003
Validation loss: 1.644568217697964

Epoch: 6| Step: 10
Training loss: 0.9547622203826904
Validation loss: 1.6559917772969892

Epoch: 6| Step: 11
Training loss: 0.56339430809021
Validation loss: 1.5492486466643631

Epoch: 6| Step: 12
Training loss: 0.7263497114181519
Validation loss: 1.620591886581913

Epoch: 6| Step: 13
Training loss: 0.39021480083465576
Validation loss: 1.624577779923716

Epoch: 705| Step: 0
Training loss: 0.3253194987773895
Validation loss: 1.641550180732563

Epoch: 6| Step: 1
Training loss: 0.39176440238952637
Validation loss: 1.6510826208258187

Epoch: 6| Step: 2
Training loss: 0.7663930058479309
Validation loss: 1.6298717555179392

Epoch: 6| Step: 3
Training loss: 0.38344433903694153
Validation loss: 1.6435792599954913

Epoch: 6| Step: 4
Training loss: 0.8131517171859741
Validation loss: 1.6642887925588956

Epoch: 6| Step: 5
Training loss: 0.6574838161468506
Validation loss: 1.6837227729059034

Epoch: 6| Step: 6
Training loss: 1.0125236511230469
Validation loss: 1.6556410251125213

Epoch: 6| Step: 7
Training loss: 0.4604681432247162
Validation loss: 1.6588553779868669

Epoch: 6| Step: 8
Training loss: 0.6168683171272278
Validation loss: 1.6451622465605378

Epoch: 6| Step: 9
Training loss: 0.3480181097984314
Validation loss: 1.638702800196986

Epoch: 6| Step: 10
Training loss: 0.7378042936325073
Validation loss: 1.683240993048555

Epoch: 6| Step: 11
Training loss: 0.5113092660903931
Validation loss: 1.7079063166854203

Epoch: 6| Step: 12
Training loss: 0.8072259426116943
Validation loss: 1.7145624276130431

Epoch: 6| Step: 13
Training loss: 0.5868802666664124
Validation loss: 1.7153207461039226

Epoch: 706| Step: 0
Training loss: 0.8282572031021118
Validation loss: 1.6849564211342924

Epoch: 6| Step: 1
Training loss: 0.469576895236969
Validation loss: 1.7638215903312928

Epoch: 6| Step: 2
Training loss: 0.8129382729530334
Validation loss: 1.7164984108299337

Epoch: 6| Step: 3
Training loss: 0.8433520793914795
Validation loss: 1.6482148670381116

Epoch: 6| Step: 4
Training loss: 0.3936161994934082
Validation loss: 1.6585597158760153

Epoch: 6| Step: 5
Training loss: 0.4200429916381836
Validation loss: 1.6453813673347555

Epoch: 6| Step: 6
Training loss: 0.5247578620910645
Validation loss: 1.6330085454448577

Epoch: 6| Step: 7
Training loss: 1.2266364097595215
Validation loss: 1.6490831855804688

Epoch: 6| Step: 8
Training loss: 0.26467812061309814
Validation loss: 1.6164950875825779

Epoch: 6| Step: 9
Training loss: 0.5020782947540283
Validation loss: 1.6361703218952302

Epoch: 6| Step: 10
Training loss: 0.5695379972457886
Validation loss: 1.596350673706301

Epoch: 6| Step: 11
Training loss: 0.975066602230072
Validation loss: 1.6551162632562781

Epoch: 6| Step: 12
Training loss: 0.5164297223091125
Validation loss: 1.6454663238217753

Epoch: 6| Step: 13
Training loss: 0.3132833242416382
Validation loss: 1.6541059927273822

Epoch: 707| Step: 0
Training loss: 0.21182970702648163
Validation loss: 1.6443409483919862

Epoch: 6| Step: 1
Training loss: 0.8569992780685425
Validation loss: 1.648186235017674

Epoch: 6| Step: 2
Training loss: 0.33123961091041565
Validation loss: 1.6401136408569992

Epoch: 6| Step: 3
Training loss: 0.5301377773284912
Validation loss: 1.5841749701448666

Epoch: 6| Step: 4
Training loss: 0.6305267810821533
Validation loss: 1.6610184254184845

Epoch: 6| Step: 5
Training loss: 0.5598595142364502
Validation loss: 1.639172028469783

Epoch: 6| Step: 6
Training loss: 0.6820913553237915
Validation loss: 1.608410801938785

Epoch: 6| Step: 7
Training loss: 0.7086236476898193
Validation loss: 1.6644837548655849

Epoch: 6| Step: 8
Training loss: 0.6902039647102356
Validation loss: 1.6124603222775202

Epoch: 6| Step: 9
Training loss: 0.3481180667877197
Validation loss: 1.6871681277469923

Epoch: 6| Step: 10
Training loss: 0.5682068467140198
Validation loss: 1.6915445148303945

Epoch: 6| Step: 11
Training loss: 0.4806845486164093
Validation loss: 1.6663324243278914

Epoch: 6| Step: 12
Training loss: 0.5871621370315552
Validation loss: 1.6889144489842076

Epoch: 6| Step: 13
Training loss: 1.4637428522109985
Validation loss: 1.7013288774797994

Epoch: 708| Step: 0
Training loss: 1.0031229257583618
Validation loss: 1.642551484287426

Epoch: 6| Step: 1
Training loss: 0.3059130609035492
Validation loss: 1.6903300759612874

Epoch: 6| Step: 2
Training loss: 0.5272146463394165
Validation loss: 1.6791033167992868

Epoch: 6| Step: 3
Training loss: 0.5666133165359497
Validation loss: 1.7047953067287323

Epoch: 6| Step: 4
Training loss: 0.40680044889450073
Validation loss: 1.6232719132977147

Epoch: 6| Step: 5
Training loss: 0.3836468458175659
Validation loss: 1.6796404354033931

Epoch: 6| Step: 6
Training loss: 0.47423848509788513
Validation loss: 1.6417934189560592

Epoch: 6| Step: 7
Training loss: 0.3710198998451233
Validation loss: 1.6372022962057462

Epoch: 6| Step: 8
Training loss: 0.535807728767395
Validation loss: 1.6412864449203655

Epoch: 6| Step: 9
Training loss: 1.1305010318756104
Validation loss: 1.668007916019809

Epoch: 6| Step: 10
Training loss: 0.3226851522922516
Validation loss: 1.6844695909048921

Epoch: 6| Step: 11
Training loss: 0.6941856145858765
Validation loss: 1.616208222604567

Epoch: 6| Step: 12
Training loss: 0.6340256929397583
Validation loss: 1.663300928249154

Epoch: 6| Step: 13
Training loss: 1.3752838373184204
Validation loss: 1.6351453117145005

Epoch: 709| Step: 0
Training loss: 0.8580513000488281
Validation loss: 1.6340870831602363

Epoch: 6| Step: 1
Training loss: 0.41373777389526367
Validation loss: 1.6598336209533036

Epoch: 6| Step: 2
Training loss: 0.5528002977371216
Validation loss: 1.640271952075343

Epoch: 6| Step: 3
Training loss: 0.8977868556976318
Validation loss: 1.6184937338675223

Epoch: 6| Step: 4
Training loss: 0.7188605070114136
Validation loss: 1.6579271285764632

Epoch: 6| Step: 5
Training loss: 0.5657280683517456
Validation loss: 1.6678373685447119

Epoch: 6| Step: 6
Training loss: 0.6599040031433105
Validation loss: 1.7325037653728197

Epoch: 6| Step: 7
Training loss: 0.4437156617641449
Validation loss: 1.632028087492912

Epoch: 6| Step: 8
Training loss: 0.8290835618972778
Validation loss: 1.6591018040974934

Epoch: 6| Step: 9
Training loss: 0.39168718457221985
Validation loss: 1.6662884380227776

Epoch: 6| Step: 10
Training loss: 0.3696655035018921
Validation loss: 1.6276273048052223

Epoch: 6| Step: 11
Training loss: 0.7443279027938843
Validation loss: 1.727416176949778

Epoch: 6| Step: 12
Training loss: 0.9335849285125732
Validation loss: 1.72988982354441

Epoch: 6| Step: 13
Training loss: 0.24952609837055206
Validation loss: 1.6978019245209233

Epoch: 710| Step: 0
Training loss: 0.3935452997684479
Validation loss: 1.7179254536987634

Epoch: 6| Step: 1
Training loss: 0.5430213809013367
Validation loss: 1.6722138517646379

Epoch: 6| Step: 2
Training loss: 1.1697630882263184
Validation loss: 1.6728959801376506

Epoch: 6| Step: 3
Training loss: 0.3967862129211426
Validation loss: 1.6855124594062887

Epoch: 6| Step: 4
Training loss: 0.7333397269248962
Validation loss: 1.6389764073074504

Epoch: 6| Step: 5
Training loss: 0.46759143471717834
Validation loss: 1.6403221648226503

Epoch: 6| Step: 6
Training loss: 0.7667757272720337
Validation loss: 1.6623297173489806

Epoch: 6| Step: 7
Training loss: 0.37346702814102173
Validation loss: 1.6279647119583622

Epoch: 6| Step: 8
Training loss: 0.7396122813224792
Validation loss: 1.6807313042302285

Epoch: 6| Step: 9
Training loss: 0.5997334122657776
Validation loss: 1.647079844628611

Epoch: 6| Step: 10
Training loss: 0.5703676342964172
Validation loss: 1.6383335462180517

Epoch: 6| Step: 11
Training loss: 0.46949049830436707
Validation loss: 1.6464968689026371

Epoch: 6| Step: 12
Training loss: 0.601226270198822
Validation loss: 1.6568868365339053

Epoch: 6| Step: 13
Training loss: 0.9458190202713013
Validation loss: 1.607264975065826

Epoch: 711| Step: 0
Training loss: 0.2476833015680313
Validation loss: 1.6225692969496532

Epoch: 6| Step: 1
Training loss: 0.5289996862411499
Validation loss: 1.6970835667784496

Epoch: 6| Step: 2
Training loss: 0.5819655060768127
Validation loss: 1.6251723804781515

Epoch: 6| Step: 3
Training loss: 0.47149258852005005
Validation loss: 1.7174767089146439

Epoch: 6| Step: 4
Training loss: 0.8568077087402344
Validation loss: 1.7099854792318037

Epoch: 6| Step: 5
Training loss: 0.7337793111801147
Validation loss: 1.7230739465323828

Epoch: 6| Step: 6
Training loss: 0.458746075630188
Validation loss: 1.6364339474708802

Epoch: 6| Step: 7
Training loss: 0.4474133849143982
Validation loss: 1.7162557494255803

Epoch: 6| Step: 8
Training loss: 0.6352165341377258
Validation loss: 1.7436869708440637

Epoch: 6| Step: 9
Training loss: 1.147374153137207
Validation loss: 1.6217946032042145

Epoch: 6| Step: 10
Training loss: 0.5766901969909668
Validation loss: 1.6636524815713205

Epoch: 6| Step: 11
Training loss: 0.8866602182388306
Validation loss: 1.633949116993976

Epoch: 6| Step: 12
Training loss: 0.45721712708473206
Validation loss: 1.6462624021755752

Epoch: 6| Step: 13
Training loss: 0.5348314046859741
Validation loss: 1.640990972518921

Epoch: 712| Step: 0
Training loss: 0.8525878190994263
Validation loss: 1.614672923600802

Epoch: 6| Step: 1
Training loss: 0.9370931386947632
Validation loss: 1.6015024364635508

Epoch: 6| Step: 2
Training loss: 1.0898669958114624
Validation loss: 1.6957700649897258

Epoch: 6| Step: 3
Training loss: 0.7542269229888916
Validation loss: 1.6538173126918014

Epoch: 6| Step: 4
Training loss: 0.3503018617630005
Validation loss: 1.650240280294931

Epoch: 6| Step: 5
Training loss: 0.562000036239624
Validation loss: 1.6423997340663787

Epoch: 6| Step: 6
Training loss: 0.886322021484375
Validation loss: 1.619662982161327

Epoch: 6| Step: 7
Training loss: 0.5667243003845215
Validation loss: 1.683412250652108

Epoch: 6| Step: 8
Training loss: 0.5213634967803955
Validation loss: 1.6818642154816659

Epoch: 6| Step: 9
Training loss: 0.4434686303138733
Validation loss: 1.7356932522148214

Epoch: 6| Step: 10
Training loss: 0.4467799663543701
Validation loss: 1.7717692262382918

Epoch: 6| Step: 11
Training loss: 0.5431919097900391
Validation loss: 1.7513511257786905

Epoch: 6| Step: 12
Training loss: 0.3945966362953186
Validation loss: 1.7632165544776506

Epoch: 6| Step: 13
Training loss: 0.3518044948577881
Validation loss: 1.6920745039498934

Epoch: 713| Step: 0
Training loss: 0.5944939851760864
Validation loss: 1.6692988910982687

Epoch: 6| Step: 1
Training loss: 0.5112104415893555
Validation loss: 1.6428852645299767

Epoch: 6| Step: 2
Training loss: 0.5213227868080139
Validation loss: 1.6498367337770359

Epoch: 6| Step: 3
Training loss: 0.5405704379081726
Validation loss: 1.6709298292795818

Epoch: 6| Step: 4
Training loss: 0.5211980938911438
Validation loss: 1.6449732254910212

Epoch: 6| Step: 5
Training loss: 0.606497049331665
Validation loss: 1.6189698096244567

Epoch: 6| Step: 6
Training loss: 0.7137420177459717
Validation loss: 1.6776360119542768

Epoch: 6| Step: 7
Training loss: 0.6834433078765869
Validation loss: 1.6256737683409004

Epoch: 6| Step: 8
Training loss: 1.140383005142212
Validation loss: 1.6500481764475505

Epoch: 6| Step: 9
Training loss: 0.4760207533836365
Validation loss: 1.666967950841432

Epoch: 6| Step: 10
Training loss: 0.8850189447402954
Validation loss: 1.6667543906037525

Epoch: 6| Step: 11
Training loss: 0.6566160917282104
Validation loss: 1.6266165497482463

Epoch: 6| Step: 12
Training loss: 0.4914546608924866
Validation loss: 1.667854711573611

Epoch: 6| Step: 13
Training loss: 0.23576360940933228
Validation loss: 1.6684505836938017

Epoch: 714| Step: 0
Training loss: 0.5729703903198242
Validation loss: 1.6661540628761373

Epoch: 6| Step: 1
Training loss: 0.526208758354187
Validation loss: 1.6959962844848633

Epoch: 6| Step: 2
Training loss: 0.5615933537483215
Validation loss: 1.6979991184767855

Epoch: 6| Step: 3
Training loss: 0.7122651934623718
Validation loss: 1.6946257263101556

Epoch: 6| Step: 4
Training loss: 0.7353986501693726
Validation loss: 1.713102275325406

Epoch: 6| Step: 5
Training loss: 0.6005218029022217
Validation loss: 1.7130723525119085

Epoch: 6| Step: 6
Training loss: 1.1481165885925293
Validation loss: 1.6625400089448499

Epoch: 6| Step: 7
Training loss: 0.2992420792579651
Validation loss: 1.7063582251148839

Epoch: 6| Step: 8
Training loss: 0.7588353157043457
Validation loss: 1.6807331923515565

Epoch: 6| Step: 9
Training loss: 0.4418063759803772
Validation loss: 1.6567640804475354

Epoch: 6| Step: 10
Training loss: 0.48454320430755615
Validation loss: 1.6052432560151624

Epoch: 6| Step: 11
Training loss: 0.6672772765159607
Validation loss: 1.6051997087335075

Epoch: 6| Step: 12
Training loss: 0.5007427930831909
Validation loss: 1.637434237746782

Epoch: 6| Step: 13
Training loss: 0.7186456918716431
Validation loss: 1.644274797490848

Epoch: 715| Step: 0
Training loss: 0.6077201962471008
Validation loss: 1.6475574585699266

Epoch: 6| Step: 1
Training loss: 0.9338172078132629
Validation loss: 1.6471980130800636

Epoch: 6| Step: 2
Training loss: 0.394218385219574
Validation loss: 1.5982510402638426

Epoch: 6| Step: 3
Training loss: 0.32017675042152405
Validation loss: 1.6042852106914725

Epoch: 6| Step: 4
Training loss: 0.5853241086006165
Validation loss: 1.653398439448367

Epoch: 6| Step: 5
Training loss: 1.0409435033798218
Validation loss: 1.646499749152891

Epoch: 6| Step: 6
Training loss: 0.5749783515930176
Validation loss: 1.674317479133606

Epoch: 6| Step: 7
Training loss: 0.5339943170547485
Validation loss: 1.66698375568595

Epoch: 6| Step: 8
Training loss: 0.5110943913459778
Validation loss: 1.6012469222468715

Epoch: 6| Step: 9
Training loss: 0.51908278465271
Validation loss: 1.6354726565781461

Epoch: 6| Step: 10
Training loss: 1.1572859287261963
Validation loss: 1.7024735930145427

Epoch: 6| Step: 11
Training loss: 0.3926198482513428
Validation loss: 1.6318989607595629

Epoch: 6| Step: 12
Training loss: 0.5392768383026123
Validation loss: 1.6305724664400982

Epoch: 6| Step: 13
Training loss: 0.6724205017089844
Validation loss: 1.6646852954741447

Epoch: 716| Step: 0
Training loss: 0.7289902567863464
Validation loss: 1.655564715785365

Epoch: 6| Step: 1
Training loss: 0.3865675628185272
Validation loss: 1.6508661688015025

Epoch: 6| Step: 2
Training loss: 0.658031702041626
Validation loss: 1.6669304614425988

Epoch: 6| Step: 3
Training loss: 0.33018919825553894
Validation loss: 1.654326190230667

Epoch: 6| Step: 4
Training loss: 0.7155776619911194
Validation loss: 1.7043415128543813

Epoch: 6| Step: 5
Training loss: 0.2211105227470398
Validation loss: 1.6578217911463913

Epoch: 6| Step: 6
Training loss: 0.6809886693954468
Validation loss: 1.667395330244495

Epoch: 6| Step: 7
Training loss: 0.6150110960006714
Validation loss: 1.674471519326651

Epoch: 6| Step: 8
Training loss: 0.4063776731491089
Validation loss: 1.6596529522249777

Epoch: 6| Step: 9
Training loss: 0.970579981803894
Validation loss: 1.7275966149504467

Epoch: 6| Step: 10
Training loss: 0.730932354927063
Validation loss: 1.682519793510437

Epoch: 6| Step: 11
Training loss: 0.5551187992095947
Validation loss: 1.6533412318075857

Epoch: 6| Step: 12
Training loss: 0.7076395750045776
Validation loss: 1.6909912017083937

Epoch: 6| Step: 13
Training loss: 0.48804107308387756
Validation loss: 1.6837736009269633

Epoch: 717| Step: 0
Training loss: 0.45586901903152466
Validation loss: 1.6340762312694261

Epoch: 6| Step: 1
Training loss: 0.6004007458686829
Validation loss: 1.7052542330116354

Epoch: 6| Step: 2
Training loss: 0.8290091753005981
Validation loss: 1.6704010566075642

Epoch: 6| Step: 3
Training loss: 0.7302200794219971
Validation loss: 1.6812426877278153

Epoch: 6| Step: 4
Training loss: 0.9349421262741089
Validation loss: 1.6786923293144471

Epoch: 6| Step: 5
Training loss: 0.5842578411102295
Validation loss: 1.6868962626303396

Epoch: 6| Step: 6
Training loss: 0.5178670883178711
Validation loss: 1.6378762625878858

Epoch: 6| Step: 7
Training loss: 0.37772297859191895
Validation loss: 1.6946172470687537

Epoch: 6| Step: 8
Training loss: 0.47691547870635986
Validation loss: 1.6607690036937754

Epoch: 6| Step: 9
Training loss: 0.412850022315979
Validation loss: 1.6837134668903966

Epoch: 6| Step: 10
Training loss: 0.5491224527359009
Validation loss: 1.6908999232835666

Epoch: 6| Step: 11
Training loss: 0.8988077044487
Validation loss: 1.6811108678899787

Epoch: 6| Step: 12
Training loss: 0.6386326551437378
Validation loss: 1.6676075971254738

Epoch: 6| Step: 13
Training loss: 0.5135264992713928
Validation loss: 1.7089915993393108

Epoch: 718| Step: 0
Training loss: 1.024972915649414
Validation loss: 1.719922827136132

Epoch: 6| Step: 1
Training loss: 0.7535868883132935
Validation loss: 1.6779144605000813

Epoch: 6| Step: 2
Training loss: 0.6885390281677246
Validation loss: 1.6131336535176923

Epoch: 6| Step: 3
Training loss: 0.6778832077980042
Validation loss: 1.6475610348486132

Epoch: 6| Step: 4
Training loss: 0.7947251796722412
Validation loss: 1.6317160603820637

Epoch: 6| Step: 5
Training loss: 0.42161568999290466
Validation loss: 1.649078280695023

Epoch: 6| Step: 6
Training loss: 0.612550675868988
Validation loss: 1.6254404565339446

Epoch: 6| Step: 7
Training loss: 0.40710681676864624
Validation loss: 1.7113587330746394

Epoch: 6| Step: 8
Training loss: 0.47204869985580444
Validation loss: 1.624088389899141

Epoch: 6| Step: 9
Training loss: 0.40536463260650635
Validation loss: 1.7104084594275362

Epoch: 6| Step: 10
Training loss: 0.6509655714035034
Validation loss: 1.6466003079568186

Epoch: 6| Step: 11
Training loss: 0.45415014028549194
Validation loss: 1.5941367867172405

Epoch: 6| Step: 12
Training loss: 0.7640246748924255
Validation loss: 1.6209532548022527

Epoch: 6| Step: 13
Training loss: 0.35083484649658203
Validation loss: 1.6302415452977663

Epoch: 719| Step: 0
Training loss: 0.4559857249259949
Validation loss: 1.6936255962617937

Epoch: 6| Step: 1
Training loss: 0.916620671749115
Validation loss: 1.6811356249675955

Epoch: 6| Step: 2
Training loss: 0.6457768082618713
Validation loss: 1.735061663453297

Epoch: 6| Step: 3
Training loss: 0.4642302095890045
Validation loss: 1.6991560138681883

Epoch: 6| Step: 4
Training loss: 0.8338494896888733
Validation loss: 1.6819983092687463

Epoch: 6| Step: 5
Training loss: 0.356404185295105
Validation loss: 1.7148150167157572

Epoch: 6| Step: 6
Training loss: 0.7860022783279419
Validation loss: 1.6313363108583676

Epoch: 6| Step: 7
Training loss: 0.6441632509231567
Validation loss: 1.6407990635082286

Epoch: 6| Step: 8
Training loss: 0.5155515670776367
Validation loss: 1.6526799189147128

Epoch: 6| Step: 9
Training loss: 0.7513338923454285
Validation loss: 1.6247298858499015

Epoch: 6| Step: 10
Training loss: 0.477344810962677
Validation loss: 1.646104073652657

Epoch: 6| Step: 11
Training loss: 0.3930537700653076
Validation loss: 1.6877773128530031

Epoch: 6| Step: 12
Training loss: 0.8571039438247681
Validation loss: 1.6540942615078342

Epoch: 6| Step: 13
Training loss: 0.5074012875556946
Validation loss: 1.6649390112969182

Epoch: 720| Step: 0
Training loss: 0.534160315990448
Validation loss: 1.67570702363086

Epoch: 6| Step: 1
Training loss: 0.45795732736587524
Validation loss: 1.6150422198798067

Epoch: 6| Step: 2
Training loss: 0.44368892908096313
Validation loss: 1.6341214820902834

Epoch: 6| Step: 3
Training loss: 0.6650153398513794
Validation loss: 1.640364263647346

Epoch: 6| Step: 4
Training loss: 0.6349408626556396
Validation loss: 1.6413128786189581

Epoch: 6| Step: 5
Training loss: 0.4402753710746765
Validation loss: 1.6494122089878205

Epoch: 6| Step: 6
Training loss: 0.6066253185272217
Validation loss: 1.666228594318513

Epoch: 6| Step: 7
Training loss: 0.6340374946594238
Validation loss: 1.6139536423067893

Epoch: 6| Step: 8
Training loss: 0.4048139452934265
Validation loss: 1.6609403176974225

Epoch: 6| Step: 9
Training loss: 1.0316014289855957
Validation loss: 1.624726681299107

Epoch: 6| Step: 10
Training loss: 1.1146953105926514
Validation loss: 1.658078981343136

Epoch: 6| Step: 11
Training loss: 0.6157466173171997
Validation loss: 1.6365125320291007

Epoch: 6| Step: 12
Training loss: 0.6987712383270264
Validation loss: 1.6315533909746396

Epoch: 6| Step: 13
Training loss: 0.39919403195381165
Validation loss: 1.6494521453816404

Epoch: 721| Step: 0
Training loss: 0.49228012561798096
Validation loss: 1.6579879291595951

Epoch: 6| Step: 1
Training loss: 0.7507851719856262
Validation loss: 1.650951188097718

Epoch: 6| Step: 2
Training loss: 0.7646868228912354
Validation loss: 1.6233856524190595

Epoch: 6| Step: 3
Training loss: 0.46383988857269287
Validation loss: 1.6460665977129372

Epoch: 6| Step: 4
Training loss: 0.4782099723815918
Validation loss: 1.6433190030436362

Epoch: 6| Step: 5
Training loss: 0.5204513072967529
Validation loss: 1.6409282453598515

Epoch: 6| Step: 6
Training loss: 0.3537749648094177
Validation loss: 1.6547284036554315

Epoch: 6| Step: 7
Training loss: 0.686956524848938
Validation loss: 1.6536455641510666

Epoch: 6| Step: 8
Training loss: 0.39649343490600586
Validation loss: 1.7424839337666829

Epoch: 6| Step: 9
Training loss: 1.1658077239990234
Validation loss: 1.7051296375131095

Epoch: 6| Step: 10
Training loss: 0.27285826206207275
Validation loss: 1.6091954374826083

Epoch: 6| Step: 11
Training loss: 0.6862953901290894
Validation loss: 1.625071173073143

Epoch: 6| Step: 12
Training loss: 0.8529072999954224
Validation loss: 1.6488752800931212

Epoch: 6| Step: 13
Training loss: 1.3159918785095215
Validation loss: 1.6640989370243524

Epoch: 722| Step: 0
Training loss: 0.7996693849563599
Validation loss: 1.6549188590818835

Epoch: 6| Step: 1
Training loss: 0.5164217948913574
Validation loss: 1.6451003205391668

Epoch: 6| Step: 2
Training loss: 0.6233841180801392
Validation loss: 1.6248748866460656

Epoch: 6| Step: 3
Training loss: 0.7633850574493408
Validation loss: 1.7079979399199128

Epoch: 6| Step: 4
Training loss: 0.821031391620636
Validation loss: 1.6863235683851345

Epoch: 6| Step: 5
Training loss: 0.34025534987449646
Validation loss: 1.6299753547996603

Epoch: 6| Step: 6
Training loss: 0.8130707740783691
Validation loss: 1.6334948212869707

Epoch: 6| Step: 7
Training loss: 0.4370545744895935
Validation loss: 1.6776487301754694

Epoch: 6| Step: 8
Training loss: 0.40945321321487427
Validation loss: 1.6578549454289098

Epoch: 6| Step: 9
Training loss: 0.5134066343307495
Validation loss: 1.595202285756347

Epoch: 6| Step: 10
Training loss: 0.8098998069763184
Validation loss: 1.6514472384606638

Epoch: 6| Step: 11
Training loss: 0.8697354793548584
Validation loss: 1.682829987618231

Epoch: 6| Step: 12
Training loss: 0.3517121970653534
Validation loss: 1.6174153845797303

Epoch: 6| Step: 13
Training loss: 0.63753342628479
Validation loss: 1.6761546122130526

Epoch: 723| Step: 0
Training loss: 0.4164530634880066
Validation loss: 1.6298890536831272

Epoch: 6| Step: 1
Training loss: 0.3352848291397095
Validation loss: 1.5949336482632546

Epoch: 6| Step: 2
Training loss: 0.4059532880783081
Validation loss: 1.66587019735767

Epoch: 6| Step: 3
Training loss: 0.6925786137580872
Validation loss: 1.6195363511321366

Epoch: 6| Step: 4
Training loss: 0.3763229548931122
Validation loss: 1.6388365825017293

Epoch: 6| Step: 5
Training loss: 0.48592326045036316
Validation loss: 1.6063501091413601

Epoch: 6| Step: 6
Training loss: 0.7851383686065674
Validation loss: 1.61024244177726

Epoch: 6| Step: 7
Training loss: 0.8664496541023254
Validation loss: 1.6131670962097824

Epoch: 6| Step: 8
Training loss: 0.48104214668273926
Validation loss: 1.6602765988278132

Epoch: 6| Step: 9
Training loss: 0.7562512159347534
Validation loss: 1.6790894757034958

Epoch: 6| Step: 10
Training loss: 0.5126450061798096
Validation loss: 1.6740245614000546

Epoch: 6| Step: 11
Training loss: 0.7718261480331421
Validation loss: 1.625697922962968

Epoch: 6| Step: 12
Training loss: 0.9272435307502747
Validation loss: 1.6854034123882171

Epoch: 6| Step: 13
Training loss: 0.39602595567703247
Validation loss: 1.639670669391591

Epoch: 724| Step: 0
Training loss: 0.23260445892810822
Validation loss: 1.6446713324516051

Epoch: 6| Step: 1
Training loss: 1.1416161060333252
Validation loss: 1.6487437320011917

Epoch: 6| Step: 2
Training loss: 0.3511202931404114
Validation loss: 1.619025666226623

Epoch: 6| Step: 3
Training loss: 0.41267481446266174
Validation loss: 1.676869361631332

Epoch: 6| Step: 4
Training loss: 0.6096483469009399
Validation loss: 1.6636013010496735

Epoch: 6| Step: 5
Training loss: 0.8749178647994995
Validation loss: 1.6576310357739847

Epoch: 6| Step: 6
Training loss: 0.5370100140571594
Validation loss: 1.6725152500214115

Epoch: 6| Step: 7
Training loss: 0.42474979162216187
Validation loss: 1.6655500332514446

Epoch: 6| Step: 8
Training loss: 0.6198580265045166
Validation loss: 1.6687301307596185

Epoch: 6| Step: 9
Training loss: 0.43415528535842896
Validation loss: 1.669270061677502

Epoch: 6| Step: 10
Training loss: 0.5990097522735596
Validation loss: 1.6756061789810017

Epoch: 6| Step: 11
Training loss: 0.5887738466262817
Validation loss: 1.628426545409746

Epoch: 6| Step: 12
Training loss: 0.8973479270935059
Validation loss: 1.710865834707855

Epoch: 6| Step: 13
Training loss: 0.2883877456188202
Validation loss: 1.661348701805197

Epoch: 725| Step: 0
Training loss: 0.5387890934944153
Validation loss: 1.6589504877726238

Epoch: 6| Step: 1
Training loss: 0.6557966470718384
Validation loss: 1.6718090464991908

Epoch: 6| Step: 2
Training loss: 0.5159487128257751
Validation loss: 1.6501419146855671

Epoch: 6| Step: 3
Training loss: 0.5471280217170715
Validation loss: 1.6621788227429954

Epoch: 6| Step: 4
Training loss: 0.4796980023384094
Validation loss: 1.6709300356526529

Epoch: 6| Step: 5
Training loss: 0.8406586050987244
Validation loss: 1.6572503248850505

Epoch: 6| Step: 6
Training loss: 0.7174276113510132
Validation loss: 1.6607822500249392

Epoch: 6| Step: 7
Training loss: 0.29710516333580017
Validation loss: 1.686785404400159

Epoch: 6| Step: 8
Training loss: 0.556939423084259
Validation loss: 1.6646064455791185

Epoch: 6| Step: 9
Training loss: 0.6402067542076111
Validation loss: 1.6511436136819984

Epoch: 6| Step: 10
Training loss: 0.38076093792915344
Validation loss: 1.6778363361153552

Epoch: 6| Step: 11
Training loss: 0.6839156150817871
Validation loss: 1.6089147143466498

Epoch: 6| Step: 12
Training loss: 0.8480886220932007
Validation loss: 1.630734944856295

Epoch: 6| Step: 13
Training loss: 0.5281778573989868
Validation loss: 1.637845955869203

Epoch: 726| Step: 0
Training loss: 0.3003063201904297
Validation loss: 1.6552836164351432

Epoch: 6| Step: 1
Training loss: 0.5518319606781006
Validation loss: 1.6103663982883576

Epoch: 6| Step: 2
Training loss: 0.4825302064418793
Validation loss: 1.631252114490796

Epoch: 6| Step: 3
Training loss: 0.35773754119873047
Validation loss: 1.7097759695463284

Epoch: 6| Step: 4
Training loss: 0.7387087345123291
Validation loss: 1.6569799691118219

Epoch: 6| Step: 5
Training loss: 0.486587792634964
Validation loss: 1.6613794270382132

Epoch: 6| Step: 6
Training loss: 1.02857506275177
Validation loss: 1.672865863769285

Epoch: 6| Step: 7
Training loss: 0.6221717000007629
Validation loss: 1.67610877431849

Epoch: 6| Step: 8
Training loss: 0.4385875463485718
Validation loss: 1.661616462533192

Epoch: 6| Step: 9
Training loss: 0.651626467704773
Validation loss: 1.7051660155737272

Epoch: 6| Step: 10
Training loss: 0.46008363366127014
Validation loss: 1.6561176276976062

Epoch: 6| Step: 11
Training loss: 0.6392123699188232
Validation loss: 1.6793795336959183

Epoch: 6| Step: 12
Training loss: 0.8207613229751587
Validation loss: 1.6998190777276152

Epoch: 6| Step: 13
Training loss: 0.6497194766998291
Validation loss: 1.6488779757612495

Epoch: 727| Step: 0
Training loss: 0.5289540886878967
Validation loss: 1.6807353881097609

Epoch: 6| Step: 1
Training loss: 0.5427414178848267
Validation loss: 1.656972747977062

Epoch: 6| Step: 2
Training loss: 0.8777542114257812
Validation loss: 1.6528534209856423

Epoch: 6| Step: 3
Training loss: 0.35406196117401123
Validation loss: 1.7072980544900382

Epoch: 6| Step: 4
Training loss: 0.4800768494606018
Validation loss: 1.6324492808311217

Epoch: 6| Step: 5
Training loss: 0.5851472616195679
Validation loss: 1.6455722380709905

Epoch: 6| Step: 6
Training loss: 0.8422535061836243
Validation loss: 1.6646823229328278

Epoch: 6| Step: 7
Training loss: 0.40458351373672485
Validation loss: 1.683570933598344

Epoch: 6| Step: 8
Training loss: 0.28056100010871887
Validation loss: 1.66411603138011

Epoch: 6| Step: 9
Training loss: 0.6346710920333862
Validation loss: 1.696624752013914

Epoch: 6| Step: 10
Training loss: 0.6311557292938232
Validation loss: 1.6700166130578646

Epoch: 6| Step: 11
Training loss: 0.40649959444999695
Validation loss: 1.6606762575846847

Epoch: 6| Step: 12
Training loss: 0.9233555793762207
Validation loss: 1.6794226425950245

Epoch: 6| Step: 13
Training loss: 0.8930302858352661
Validation loss: 1.6854020011040471

Epoch: 728| Step: 0
Training loss: 0.6125481128692627
Validation loss: 1.6389174897183654

Epoch: 6| Step: 1
Training loss: 0.6053817868232727
Validation loss: 1.6341025008950183

Epoch: 6| Step: 2
Training loss: 0.5503746271133423
Validation loss: 1.5809421462397422

Epoch: 6| Step: 3
Training loss: 0.6774835586547852
Validation loss: 1.6137377613334245

Epoch: 6| Step: 4
Training loss: 0.553470253944397
Validation loss: 1.6244168845556115

Epoch: 6| Step: 5
Training loss: 0.6665370464324951
Validation loss: 1.5950843031688402

Epoch: 6| Step: 6
Training loss: 0.3541690707206726
Validation loss: 1.6636748608722483

Epoch: 6| Step: 7
Training loss: 0.45899325609207153
Validation loss: 1.5952008770358177

Epoch: 6| Step: 8
Training loss: 1.0310165882110596
Validation loss: 1.6429100036621094

Epoch: 6| Step: 9
Training loss: 0.47253942489624023
Validation loss: 1.656287658599115

Epoch: 6| Step: 10
Training loss: 0.4388076663017273
Validation loss: 1.6435969516795168

Epoch: 6| Step: 11
Training loss: 0.7186746597290039
Validation loss: 1.6440192666105045

Epoch: 6| Step: 12
Training loss: 0.6438829898834229
Validation loss: 1.6426815525177987

Epoch: 6| Step: 13
Training loss: 0.48818594217300415
Validation loss: 1.65531289064756

Epoch: 729| Step: 0
Training loss: 0.5444692373275757
Validation loss: 1.6138994020800437

Epoch: 6| Step: 1
Training loss: 0.5697433352470398
Validation loss: 1.6389078927296463

Epoch: 6| Step: 2
Training loss: 0.43277373909950256
Validation loss: 1.6738657566808886

Epoch: 6| Step: 3
Training loss: 0.5674766302108765
Validation loss: 1.609880844751994

Epoch: 6| Step: 4
Training loss: 0.40722018480300903
Validation loss: 1.6621103748198478

Epoch: 6| Step: 5
Training loss: 0.6669174432754517
Validation loss: 1.642311688392393

Epoch: 6| Step: 6
Training loss: 0.3755837082862854
Validation loss: 1.6816482531127108

Epoch: 6| Step: 7
Training loss: 1.157219648361206
Validation loss: 1.6656376200337564

Epoch: 6| Step: 8
Training loss: 0.3940896987915039
Validation loss: 1.6788627332256687

Epoch: 6| Step: 9
Training loss: 0.4517610967159271
Validation loss: 1.6532296660125896

Epoch: 6| Step: 10
Training loss: 0.7394183874130249
Validation loss: 1.6804097942126694

Epoch: 6| Step: 11
Training loss: 0.6186190843582153
Validation loss: 1.7041909335761942

Epoch: 6| Step: 12
Training loss: 0.6588454246520996
Validation loss: 1.6431946152000017

Epoch: 6| Step: 13
Training loss: 1.288392424583435
Validation loss: 1.6329664799474901

Epoch: 730| Step: 0
Training loss: 0.6124188899993896
Validation loss: 1.6403998072429369

Epoch: 6| Step: 1
Training loss: 0.4090029001235962
Validation loss: 1.6346998586449573

Epoch: 6| Step: 2
Training loss: 0.4424695372581482
Validation loss: 1.643186071867584

Epoch: 6| Step: 3
Training loss: 0.3275453448295593
Validation loss: 1.6795752253583682

Epoch: 6| Step: 4
Training loss: 0.871262788772583
Validation loss: 1.6425820640338364

Epoch: 6| Step: 5
Training loss: 0.496334433555603
Validation loss: 1.6653021304838118

Epoch: 6| Step: 6
Training loss: 0.8179689645767212
Validation loss: 1.6476803819338481

Epoch: 6| Step: 7
Training loss: 0.5693773031234741
Validation loss: 1.6357088793990433

Epoch: 6| Step: 8
Training loss: 0.7886664867401123
Validation loss: 1.6873242944799445

Epoch: 6| Step: 9
Training loss: 0.6434634327888489
Validation loss: 1.6854530175526936

Epoch: 6| Step: 10
Training loss: 0.35529154539108276
Validation loss: 1.6170433503325268

Epoch: 6| Step: 11
Training loss: 0.978725016117096
Validation loss: 1.637643321867912

Epoch: 6| Step: 12
Training loss: 0.396060049533844
Validation loss: 1.615162157243298

Epoch: 6| Step: 13
Training loss: 0.77835613489151
Validation loss: 1.6422680244650891

Epoch: 731| Step: 0
Training loss: 0.37179815769195557
Validation loss: 1.6459015659106675

Epoch: 6| Step: 1
Training loss: 0.5568745732307434
Validation loss: 1.6793675082986073

Epoch: 6| Step: 2
Training loss: 0.5536374449729919
Validation loss: 1.6289444341454455

Epoch: 6| Step: 3
Training loss: 0.8166911602020264
Validation loss: 1.605825129375663

Epoch: 6| Step: 4
Training loss: 0.9272230863571167
Validation loss: 1.6720709557174354

Epoch: 6| Step: 5
Training loss: 0.4046761393547058
Validation loss: 1.6217991254662956

Epoch: 6| Step: 6
Training loss: 0.7339061498641968
Validation loss: 1.6723504399740567

Epoch: 6| Step: 7
Training loss: 0.3397764563560486
Validation loss: 1.6624948581059773

Epoch: 6| Step: 8
Training loss: 0.7783710956573486
Validation loss: 1.6487086883155249

Epoch: 6| Step: 9
Training loss: 0.35312211513519287
Validation loss: 1.6753758852199843

Epoch: 6| Step: 10
Training loss: 0.8381897211074829
Validation loss: 1.5974679685408069

Epoch: 6| Step: 11
Training loss: 0.6402792930603027
Validation loss: 1.667536231779283

Epoch: 6| Step: 12
Training loss: 0.5252439975738525
Validation loss: 1.680958371008596

Epoch: 6| Step: 13
Training loss: 0.622520923614502
Validation loss: 1.665675251714645

Epoch: 732| Step: 0
Training loss: 0.3780616819858551
Validation loss: 1.6329656390733616

Epoch: 6| Step: 1
Training loss: 0.8934057354927063
Validation loss: 1.6262052559083509

Epoch: 6| Step: 2
Training loss: 1.0350115299224854
Validation loss: 1.641125290624557

Epoch: 6| Step: 3
Training loss: 0.6137717962265015
Validation loss: 1.6673330747953026

Epoch: 6| Step: 4
Training loss: 0.7547035217285156
Validation loss: 1.62071644618947

Epoch: 6| Step: 5
Training loss: 0.5552317500114441
Validation loss: 1.6984125209111038

Epoch: 6| Step: 6
Training loss: 0.54000324010849
Validation loss: 1.7048674501398557

Epoch: 6| Step: 7
Training loss: 0.4666772484779358
Validation loss: 1.6423602834824593

Epoch: 6| Step: 8
Training loss: 0.3562472462654114
Validation loss: 1.6614681225951

Epoch: 6| Step: 9
Training loss: 0.6396700739860535
Validation loss: 1.681093801734268

Epoch: 6| Step: 10
Training loss: 0.37592190504074097
Validation loss: 1.6323794562329528

Epoch: 6| Step: 11
Training loss: 0.40990233421325684
Validation loss: 1.6275985497300343

Epoch: 6| Step: 12
Training loss: 0.24354344606399536
Validation loss: 1.593104018959948

Epoch: 6| Step: 13
Training loss: 0.7775663733482361
Validation loss: 1.664543588315287

Epoch: 733| Step: 0
Training loss: 0.6512503027915955
Validation loss: 1.62216951001075

Epoch: 6| Step: 1
Training loss: 0.8548131585121155
Validation loss: 1.6988544451293124

Epoch: 6| Step: 2
Training loss: 0.5984896421432495
Validation loss: 1.6790420752699657

Epoch: 6| Step: 3
Training loss: 0.7272129058837891
Validation loss: 1.7325708520027898

Epoch: 6| Step: 4
Training loss: 0.8362444043159485
Validation loss: 1.691974764229149

Epoch: 6| Step: 5
Training loss: 0.6288528442382812
Validation loss: 1.704110191714379

Epoch: 6| Step: 6
Training loss: 0.48447859287261963
Validation loss: 1.6793192958319059

Epoch: 6| Step: 7
Training loss: 0.42535537481307983
Validation loss: 1.6419662544804234

Epoch: 6| Step: 8
Training loss: 0.4346573054790497
Validation loss: 1.6558230371885403

Epoch: 6| Step: 9
Training loss: 0.733858048915863
Validation loss: 1.6209578129553026

Epoch: 6| Step: 10
Training loss: 0.4768320918083191
Validation loss: 1.6042765936543864

Epoch: 6| Step: 11
Training loss: 0.5314887762069702
Validation loss: 1.6066898427983767

Epoch: 6| Step: 12
Training loss: 0.44986796379089355
Validation loss: 1.6400604799229612

Epoch: 6| Step: 13
Training loss: 0.4009031653404236
Validation loss: 1.6307434189704157

Epoch: 734| Step: 0
Training loss: 0.3199332654476166
Validation loss: 1.6252877212339831

Epoch: 6| Step: 1
Training loss: 0.7206028699874878
Validation loss: 1.6632239632709052

Epoch: 6| Step: 2
Training loss: 0.44579508900642395
Validation loss: 1.6451979683291527

Epoch: 6| Step: 3
Training loss: 0.5664107203483582
Validation loss: 1.6368786942574285

Epoch: 6| Step: 4
Training loss: 0.37559568881988525
Validation loss: 1.675766368066111

Epoch: 6| Step: 5
Training loss: 0.8661486506462097
Validation loss: 1.6512540989024664

Epoch: 6| Step: 6
Training loss: 0.588911235332489
Validation loss: 1.6812049752922469

Epoch: 6| Step: 7
Training loss: 1.1737650632858276
Validation loss: 1.6514535129711192

Epoch: 6| Step: 8
Training loss: 0.3438630998134613
Validation loss: 1.650401912709718

Epoch: 6| Step: 9
Training loss: 0.7268696427345276
Validation loss: 1.6994434210561937

Epoch: 6| Step: 10
Training loss: 0.396860271692276
Validation loss: 1.7071562890083558

Epoch: 6| Step: 11
Training loss: 0.5465863347053528
Validation loss: 1.6768408001110118

Epoch: 6| Step: 12
Training loss: 0.5593404769897461
Validation loss: 1.7090003246902137

Epoch: 6| Step: 13
Training loss: 0.4557933211326599
Validation loss: 1.6651352669603081

Epoch: 735| Step: 0
Training loss: 0.7266452312469482
Validation loss: 1.6644936812821256

Epoch: 6| Step: 1
Training loss: 0.4316505789756775
Validation loss: 1.647064721712502

Epoch: 6| Step: 2
Training loss: 0.6250802278518677
Validation loss: 1.6559066234096405

Epoch: 6| Step: 3
Training loss: 0.4569302797317505
Validation loss: 1.6197770154604347

Epoch: 6| Step: 4
Training loss: 0.9438087344169617
Validation loss: 1.6025104497068672

Epoch: 6| Step: 5
Training loss: 0.4730927348136902
Validation loss: 1.6393385394926994

Epoch: 6| Step: 6
Training loss: 0.5393977761268616
Validation loss: 1.6228602752890637

Epoch: 6| Step: 7
Training loss: 0.5596761107444763
Validation loss: 1.607607582563995

Epoch: 6| Step: 8
Training loss: 1.0604901313781738
Validation loss: 1.6560029086246286

Epoch: 6| Step: 9
Training loss: 0.631861686706543
Validation loss: 1.6222122997365973

Epoch: 6| Step: 10
Training loss: 0.47489863634109497
Validation loss: 1.6365705446530414

Epoch: 6| Step: 11
Training loss: 0.6609129309654236
Validation loss: 1.660030444463094

Epoch: 6| Step: 12
Training loss: 0.4277445673942566
Validation loss: 1.6516929364973498

Epoch: 6| Step: 13
Training loss: 0.6221978664398193
Validation loss: 1.6864805426648868

Epoch: 736| Step: 0
Training loss: 0.4546312093734741
Validation loss: 1.6830825536481795

Epoch: 6| Step: 1
Training loss: 0.5170015692710876
Validation loss: 1.7402422351221885

Epoch: 6| Step: 2
Training loss: 0.6558828353881836
Validation loss: 1.6887044752797773

Epoch: 6| Step: 3
Training loss: 0.6556615829467773
Validation loss: 1.653238925882565

Epoch: 6| Step: 4
Training loss: 0.368444561958313
Validation loss: 1.7050449899447861

Epoch: 6| Step: 5
Training loss: 0.6309938430786133
Validation loss: 1.6316273071432625

Epoch: 6| Step: 6
Training loss: 0.6115471720695496
Validation loss: 1.6137414068304083

Epoch: 6| Step: 7
Training loss: 0.9585726261138916
Validation loss: 1.6288269617224251

Epoch: 6| Step: 8
Training loss: 0.4656198024749756
Validation loss: 1.6860176414571784

Epoch: 6| Step: 9
Training loss: 0.5922263860702515
Validation loss: 1.6557446679761332

Epoch: 6| Step: 10
Training loss: 0.32614439725875854
Validation loss: 1.6414080589048323

Epoch: 6| Step: 11
Training loss: 1.3557053804397583
Validation loss: 1.6178041940094323

Epoch: 6| Step: 12
Training loss: 0.2900039255619049
Validation loss: 1.6284092036626672

Epoch: 6| Step: 13
Training loss: 0.5512163043022156
Validation loss: 1.6267933550701346

Epoch: 737| Step: 0
Training loss: 0.48439928889274597
Validation loss: 1.6344164725272887

Epoch: 6| Step: 1
Training loss: 0.5615571737289429
Validation loss: 1.6203557624611804

Epoch: 6| Step: 2
Training loss: 0.22004058957099915
Validation loss: 1.6919224018691688

Epoch: 6| Step: 3
Training loss: 0.6197014451026917
Validation loss: 1.656301950895658

Epoch: 6| Step: 4
Training loss: 0.5715087652206421
Validation loss: 1.6317062775293987

Epoch: 6| Step: 5
Training loss: 1.0627464056015015
Validation loss: 1.652594982936818

Epoch: 6| Step: 6
Training loss: 0.6778643131256104
Validation loss: 1.6304028803302395

Epoch: 6| Step: 7
Training loss: 0.3563080132007599
Validation loss: 1.6268224024003552

Epoch: 6| Step: 8
Training loss: 0.5525302290916443
Validation loss: 1.620504262626812

Epoch: 6| Step: 9
Training loss: 0.5545486211776733
Validation loss: 1.575012614650111

Epoch: 6| Step: 10
Training loss: 0.637965977191925
Validation loss: 1.6834521037276073

Epoch: 6| Step: 11
Training loss: 0.5994625091552734
Validation loss: 1.6649484583126601

Epoch: 6| Step: 12
Training loss: 0.7883636951446533
Validation loss: 1.5954028983269968

Epoch: 6| Step: 13
Training loss: 0.5766332149505615
Validation loss: 1.6484289938403713

Epoch: 738| Step: 0
Training loss: 0.7833961248397827
Validation loss: 1.623883839576475

Epoch: 6| Step: 1
Training loss: 0.5369635820388794
Validation loss: 1.640167966965706

Epoch: 6| Step: 2
Training loss: 0.7392556667327881
Validation loss: 1.617880816100746

Epoch: 6| Step: 3
Training loss: 0.7614032030105591
Validation loss: 1.641026625069239

Epoch: 6| Step: 4
Training loss: 0.3676758408546448
Validation loss: 1.6038056176195863

Epoch: 6| Step: 5
Training loss: 0.6179546117782593
Validation loss: 1.6257562547601678

Epoch: 6| Step: 6
Training loss: 0.5047541856765747
Validation loss: 1.6391732026171941

Epoch: 6| Step: 7
Training loss: 0.5518522262573242
Validation loss: 1.6568823552900744

Epoch: 6| Step: 8
Training loss: 0.37257373332977295
Validation loss: 1.6388454873074767

Epoch: 6| Step: 9
Training loss: 0.829064130783081
Validation loss: 1.650098777586414

Epoch: 6| Step: 10
Training loss: 0.4305371046066284
Validation loss: 1.6312986804592995

Epoch: 6| Step: 11
Training loss: 0.8712029457092285
Validation loss: 1.6726774848917478

Epoch: 6| Step: 12
Training loss: 0.4774221181869507
Validation loss: 1.625798568930677

Epoch: 6| Step: 13
Training loss: 0.3585447072982788
Validation loss: 1.6666813922184769

Epoch: 739| Step: 0
Training loss: 1.1185030937194824
Validation loss: 1.6345007329858758

Epoch: 6| Step: 1
Training loss: 0.6135215759277344
Validation loss: 1.6503088333273446

Epoch: 6| Step: 2
Training loss: 0.5272653102874756
Validation loss: 1.6531012058258057

Epoch: 6| Step: 3
Training loss: 0.7351781725883484
Validation loss: 1.670780861249534

Epoch: 6| Step: 4
Training loss: 0.5020842552185059
Validation loss: 1.6300528869833997

Epoch: 6| Step: 5
Training loss: 0.4722674787044525
Validation loss: 1.666214087957977

Epoch: 6| Step: 6
Training loss: 0.6002917289733887
Validation loss: 1.6368169476909022

Epoch: 6| Step: 7
Training loss: 0.5942784547805786
Validation loss: 1.6744800408681233

Epoch: 6| Step: 8
Training loss: 0.408417284488678
Validation loss: 1.641054855879917

Epoch: 6| Step: 9
Training loss: 0.7416254281997681
Validation loss: 1.6218519467179493

Epoch: 6| Step: 10
Training loss: 0.472960889339447
Validation loss: 1.5981206791375273

Epoch: 6| Step: 11
Training loss: 0.5047410726547241
Validation loss: 1.6479742924372356

Epoch: 6| Step: 12
Training loss: 0.7607886791229248
Validation loss: 1.6229609148476714

Epoch: 6| Step: 13
Training loss: 0.19189924001693726
Validation loss: 1.6170940617079377

Epoch: 740| Step: 0
Training loss: 0.6526837348937988
Validation loss: 1.6917174477731027

Epoch: 6| Step: 1
Training loss: 0.6835107207298279
Validation loss: 1.7168734663276262

Epoch: 6| Step: 2
Training loss: 0.8845024704933167
Validation loss: 1.6675666378390404

Epoch: 6| Step: 3
Training loss: 0.8888662457466125
Validation loss: 1.6788658185671734

Epoch: 6| Step: 4
Training loss: 0.39308279752731323
Validation loss: 1.7060080523131995

Epoch: 6| Step: 5
Training loss: 0.6530872583389282
Validation loss: 1.6524524868175547

Epoch: 6| Step: 6
Training loss: 0.2980239987373352
Validation loss: 1.6817680892123972

Epoch: 6| Step: 7
Training loss: 0.4612620770931244
Validation loss: 1.6081390175768124

Epoch: 6| Step: 8
Training loss: 0.7532760500907898
Validation loss: 1.5963575019631335

Epoch: 6| Step: 9
Training loss: 0.5745347738265991
Validation loss: 1.6922573722818846

Epoch: 6| Step: 10
Training loss: 0.3592703342437744
Validation loss: 1.6356836621479323

Epoch: 6| Step: 11
Training loss: 0.5600512027740479
Validation loss: 1.6594376897299161

Epoch: 6| Step: 12
Training loss: 0.6917360424995422
Validation loss: 1.6082319213498024

Epoch: 6| Step: 13
Training loss: 0.7043418884277344
Validation loss: 1.5811179825054702

Epoch: 741| Step: 0
Training loss: 0.710286021232605
Validation loss: 1.6311217443917387

Epoch: 6| Step: 1
Training loss: 0.4212172329425812
Validation loss: 1.6697347779427805

Epoch: 6| Step: 2
Training loss: 0.5175802707672119
Validation loss: 1.6182526798658474

Epoch: 6| Step: 3
Training loss: 0.580236554145813
Validation loss: 1.6717975780528078

Epoch: 6| Step: 4
Training loss: 0.6391919851303101
Validation loss: 1.638609077340813

Epoch: 6| Step: 5
Training loss: 0.6444270014762878
Validation loss: 1.6776919544384044

Epoch: 6| Step: 6
Training loss: 0.42195096611976624
Validation loss: 1.6400749785925752

Epoch: 6| Step: 7
Training loss: 0.7242892384529114
Validation loss: 1.6275201382175568

Epoch: 6| Step: 8
Training loss: 0.7597827315330505
Validation loss: 1.6001090541962655

Epoch: 6| Step: 9
Training loss: 0.603452205657959
Validation loss: 1.6510557256719118

Epoch: 6| Step: 10
Training loss: 0.4569177031517029
Validation loss: 1.5980524593783962

Epoch: 6| Step: 11
Training loss: 0.4491289258003235
Validation loss: 1.6196123733315417

Epoch: 6| Step: 12
Training loss: 0.45393508672714233
Validation loss: 1.6260198226539038

Epoch: 6| Step: 13
Training loss: 1.0984530448913574
Validation loss: 1.6578318559995262

Epoch: 742| Step: 0
Training loss: 0.4988030195236206
Validation loss: 1.6544929409539828

Epoch: 6| Step: 1
Training loss: 0.4786475896835327
Validation loss: 1.658635861130171

Epoch: 6| Step: 2
Training loss: 0.8563203811645508
Validation loss: 1.6379348116536294

Epoch: 6| Step: 3
Training loss: 0.5676875710487366
Validation loss: 1.627783472819995

Epoch: 6| Step: 4
Training loss: 0.5445713996887207
Validation loss: 1.6157919629927604

Epoch: 6| Step: 5
Training loss: 0.5513410568237305
Validation loss: 1.6577000733344787

Epoch: 6| Step: 6
Training loss: 0.4240168333053589
Validation loss: 1.71944329174616

Epoch: 6| Step: 7
Training loss: 0.4187012016773224
Validation loss: 1.6641454068563317

Epoch: 6| Step: 8
Training loss: 1.3802669048309326
Validation loss: 1.679644997401904

Epoch: 6| Step: 9
Training loss: 0.2748880982398987
Validation loss: 1.6112867157946351

Epoch: 6| Step: 10
Training loss: 0.29192450642585754
Validation loss: 1.6475871839830953

Epoch: 6| Step: 11
Training loss: 0.3912464380264282
Validation loss: 1.6353185240940382

Epoch: 6| Step: 12
Training loss: 0.7197904586791992
Validation loss: 1.6799282873830488

Epoch: 6| Step: 13
Training loss: 0.563262939453125
Validation loss: 1.6110972614698513

Epoch: 743| Step: 0
Training loss: 0.3674463629722595
Validation loss: 1.5920182735689226

Epoch: 6| Step: 1
Training loss: 0.44113296270370483
Validation loss: 1.641065348861038

Epoch: 6| Step: 2
Training loss: 0.49797743558883667
Validation loss: 1.610015623031124

Epoch: 6| Step: 3
Training loss: 0.46256208419799805
Validation loss: 1.673024005787347

Epoch: 6| Step: 4
Training loss: 0.6211203932762146
Validation loss: 1.678681319759738

Epoch: 6| Step: 5
Training loss: 0.39866721630096436
Validation loss: 1.6389687029264306

Epoch: 6| Step: 6
Training loss: 0.5404515266418457
Validation loss: 1.6152834244953689

Epoch: 6| Step: 7
Training loss: 0.6356563568115234
Validation loss: 1.6299664435848114

Epoch: 6| Step: 8
Training loss: 1.037866234779358
Validation loss: 1.669608881396632

Epoch: 6| Step: 9
Training loss: 0.6114003658294678
Validation loss: 1.6544078575667513

Epoch: 6| Step: 10
Training loss: 0.6848230361938477
Validation loss: 1.6510774884172665

Epoch: 6| Step: 11
Training loss: 0.6713865995407104
Validation loss: 1.6374477494147517

Epoch: 6| Step: 12
Training loss: 0.5666291117668152
Validation loss: 1.6508821723281697

Epoch: 6| Step: 13
Training loss: 0.29301467537879944
Validation loss: 1.636983202349755

Epoch: 744| Step: 0
Training loss: 0.7042413949966431
Validation loss: 1.6721741883985457

Epoch: 6| Step: 1
Training loss: 0.5973283052444458
Validation loss: 1.606897355407797

Epoch: 6| Step: 2
Training loss: 0.32802310585975647
Validation loss: 1.6447704479258547

Epoch: 6| Step: 3
Training loss: 0.5544863343238831
Validation loss: 1.6385290648347588

Epoch: 6| Step: 4
Training loss: 0.5323144197463989
Validation loss: 1.6993157863616943

Epoch: 6| Step: 5
Training loss: 0.3238409757614136
Validation loss: 1.6861382915127663

Epoch: 6| Step: 6
Training loss: 0.43322354555130005
Validation loss: 1.5963778726516231

Epoch: 6| Step: 7
Training loss: 0.7090492248535156
Validation loss: 1.6260363568541825

Epoch: 6| Step: 8
Training loss: 0.27476000785827637
Validation loss: 1.628832358185963

Epoch: 6| Step: 9
Training loss: 0.6039212942123413
Validation loss: 1.6532250476139847

Epoch: 6| Step: 10
Training loss: 1.2340209484100342
Validation loss: 1.655614778559695

Epoch: 6| Step: 11
Training loss: 0.3531303405761719
Validation loss: 1.6978385512546827

Epoch: 6| Step: 12
Training loss: 0.5631171464920044
Validation loss: 1.6260091886725476

Epoch: 6| Step: 13
Training loss: 0.7164676189422607
Validation loss: 1.6209508513891568

Epoch: 745| Step: 0
Training loss: 0.5660759806632996
Validation loss: 1.6130765035588255

Epoch: 6| Step: 1
Training loss: 0.33234187960624695
Validation loss: 1.6180795700319353

Epoch: 6| Step: 2
Training loss: 0.47100630402565
Validation loss: 1.6609979932026198

Epoch: 6| Step: 3
Training loss: 0.6517984867095947
Validation loss: 1.6929665239908362

Epoch: 6| Step: 4
Training loss: 0.5279337167739868
Validation loss: 1.6203028617366668

Epoch: 6| Step: 5
Training loss: 0.8095650672912598
Validation loss: 1.6432081640407603

Epoch: 6| Step: 6
Training loss: 0.9314426183700562
Validation loss: 1.698836499644864

Epoch: 6| Step: 7
Training loss: 0.47698381543159485
Validation loss: 1.6209232986614268

Epoch: 6| Step: 8
Training loss: 0.7273833751678467
Validation loss: 1.6811608524732693

Epoch: 6| Step: 9
Training loss: 0.6831153035163879
Validation loss: 1.6099988427213443

Epoch: 6| Step: 10
Training loss: 0.4215158522129059
Validation loss: 1.6494873018674954

Epoch: 6| Step: 11
Training loss: 0.7121981382369995
Validation loss: 1.5722623768673147

Epoch: 6| Step: 12
Training loss: 0.259916216135025
Validation loss: 1.6323131643315798

Epoch: 6| Step: 13
Training loss: 0.630338728427887
Validation loss: 1.6281721476585633

Epoch: 746| Step: 0
Training loss: 0.4592514634132385
Validation loss: 1.7034918108294088

Epoch: 6| Step: 1
Training loss: 0.26253294944763184
Validation loss: 1.6791993302683677

Epoch: 6| Step: 2
Training loss: 0.4488067626953125
Validation loss: 1.7090957241673623

Epoch: 6| Step: 3
Training loss: 0.9591844081878662
Validation loss: 1.681980259956852

Epoch: 6| Step: 4
Training loss: 0.6086121797561646
Validation loss: 1.6961541201478691

Epoch: 6| Step: 5
Training loss: 0.5360456705093384
Validation loss: 1.644190066604204

Epoch: 6| Step: 6
Training loss: 0.610572099685669
Validation loss: 1.6936139419514646

Epoch: 6| Step: 7
Training loss: 0.6871260404586792
Validation loss: 1.7162003465878066

Epoch: 6| Step: 8
Training loss: 0.9153218269348145
Validation loss: 1.7012156478820308

Epoch: 6| Step: 9
Training loss: 0.3856911063194275
Validation loss: 1.6417645728716286

Epoch: 6| Step: 10
Training loss: 0.47655385732650757
Validation loss: 1.6748901695333502

Epoch: 6| Step: 11
Training loss: 0.7211682796478271
Validation loss: 1.6169721727730126

Epoch: 6| Step: 12
Training loss: 0.5472330451011658
Validation loss: 1.6102246853613085

Epoch: 6| Step: 13
Training loss: 0.9296063184738159
Validation loss: 1.6093688613624983

Epoch: 747| Step: 0
Training loss: 0.662098228931427
Validation loss: 1.6275598592655633

Epoch: 6| Step: 1
Training loss: 0.47985225915908813
Validation loss: 1.6349865044316938

Epoch: 6| Step: 2
Training loss: 0.5463919639587402
Validation loss: 1.6394969289020827

Epoch: 6| Step: 3
Training loss: 0.47910529375076294
Validation loss: 1.6103876739419916

Epoch: 6| Step: 4
Training loss: 0.6023383140563965
Validation loss: 1.6281730487782469

Epoch: 6| Step: 5
Training loss: 0.38473159074783325
Validation loss: 1.6505363090063936

Epoch: 6| Step: 6
Training loss: 0.6428449749946594
Validation loss: 1.6619432228867725

Epoch: 6| Step: 7
Training loss: 0.48321446776390076
Validation loss: 1.6818877984118719

Epoch: 6| Step: 8
Training loss: 0.5313929915428162
Validation loss: 1.717173913473724

Epoch: 6| Step: 9
Training loss: 0.7977039217948914
Validation loss: 1.723348106107404

Epoch: 6| Step: 10
Training loss: 0.5100374221801758
Validation loss: 1.688357017373526

Epoch: 6| Step: 11
Training loss: 0.817720890045166
Validation loss: 1.6642047948734735

Epoch: 6| Step: 12
Training loss: 0.7585486173629761
Validation loss: 1.6296273892925632

Epoch: 6| Step: 13
Training loss: 0.5647384524345398
Validation loss: 1.6067176288174045

Epoch: 748| Step: 0
Training loss: 1.1115576028823853
Validation loss: 1.6229876843831872

Epoch: 6| Step: 1
Training loss: 0.5247501134872437
Validation loss: 1.6131601871982697

Epoch: 6| Step: 2
Training loss: 0.6423227787017822
Validation loss: 1.6311983254648024

Epoch: 6| Step: 3
Training loss: 0.4230760931968689
Validation loss: 1.6887023269489247

Epoch: 6| Step: 4
Training loss: 0.2867391109466553
Validation loss: 1.6641974013338807

Epoch: 6| Step: 5
Training loss: 0.756248950958252
Validation loss: 1.6461789890002179

Epoch: 6| Step: 6
Training loss: 0.7219209671020508
Validation loss: 1.5774546925739577

Epoch: 6| Step: 7
Training loss: 0.4153684079647064
Validation loss: 1.6897775537224227

Epoch: 6| Step: 8
Training loss: 0.37639427185058594
Validation loss: 1.626794271571662

Epoch: 6| Step: 9
Training loss: 0.39465397596359253
Validation loss: 1.6441816322265133

Epoch: 6| Step: 10
Training loss: 0.9226484894752502
Validation loss: 1.6974960693749048

Epoch: 6| Step: 11
Training loss: 0.5047550201416016
Validation loss: 1.6277348200480144

Epoch: 6| Step: 12
Training loss: 0.4271244406700134
Validation loss: 1.716957353776501

Epoch: 6| Step: 13
Training loss: 0.7009329199790955
Validation loss: 1.6385511711079588

Epoch: 749| Step: 0
Training loss: 0.49217382073402405
Validation loss: 1.6784829503746443

Epoch: 6| Step: 1
Training loss: 0.8245820999145508
Validation loss: 1.646593302808782

Epoch: 6| Step: 2
Training loss: 0.5311744213104248
Validation loss: 1.6248801703094153

Epoch: 6| Step: 3
Training loss: 0.8688830137252808
Validation loss: 1.6338157897354455

Epoch: 6| Step: 4
Training loss: 0.5671685934066772
Validation loss: 1.5979804274856404

Epoch: 6| Step: 5
Training loss: 0.7097002267837524
Validation loss: 1.6447333776822655

Epoch: 6| Step: 6
Training loss: 0.42603975534439087
Validation loss: 1.6367445914976058

Epoch: 6| Step: 7
Training loss: 0.4304068088531494
Validation loss: 1.609991934991652

Epoch: 6| Step: 8
Training loss: 0.5393664836883545
Validation loss: 1.6626670399019796

Epoch: 6| Step: 9
Training loss: 0.6891747117042542
Validation loss: 1.6483493530622093

Epoch: 6| Step: 10
Training loss: 0.6076769828796387
Validation loss: 1.5915751995578888

Epoch: 6| Step: 11
Training loss: 0.4307088255882263
Validation loss: 1.61957896396678

Epoch: 6| Step: 12
Training loss: 0.6087503433227539
Validation loss: 1.66687338454749

Epoch: 6| Step: 13
Training loss: 0.4066064655780792
Validation loss: 1.6382352357269616

Epoch: 750| Step: 0
Training loss: 0.4009438157081604
Validation loss: 1.6158545337697512

Epoch: 6| Step: 1
Training loss: 0.6578102111816406
Validation loss: 1.6635770438819804

Epoch: 6| Step: 2
Training loss: 0.43034207820892334
Validation loss: 1.652563174565633

Epoch: 6| Step: 3
Training loss: 0.4905967712402344
Validation loss: 1.6340599521513908

Epoch: 6| Step: 4
Training loss: 1.092714548110962
Validation loss: 1.6476147918290989

Epoch: 6| Step: 5
Training loss: 0.3212243914604187
Validation loss: 1.6596681046229538

Epoch: 6| Step: 6
Training loss: 0.5470468997955322
Validation loss: 1.6297512926081175

Epoch: 6| Step: 7
Training loss: 0.7761008739471436
Validation loss: 1.6081708708117086

Epoch: 6| Step: 8
Training loss: 0.4293367266654968
Validation loss: 1.6174132157397527

Epoch: 6| Step: 9
Training loss: 0.4676675796508789
Validation loss: 1.6878237698667793

Epoch: 6| Step: 10
Training loss: 0.9173372983932495
Validation loss: 1.5962955720963017

Epoch: 6| Step: 11
Training loss: 0.8215963244438171
Validation loss: 1.5953387560382966

Epoch: 6| Step: 12
Training loss: 0.272765576839447
Validation loss: 1.6042120495150167

Epoch: 6| Step: 13
Training loss: 0.529088020324707
Validation loss: 1.5828678223394579

Testing loss: 2.6640300856696233
