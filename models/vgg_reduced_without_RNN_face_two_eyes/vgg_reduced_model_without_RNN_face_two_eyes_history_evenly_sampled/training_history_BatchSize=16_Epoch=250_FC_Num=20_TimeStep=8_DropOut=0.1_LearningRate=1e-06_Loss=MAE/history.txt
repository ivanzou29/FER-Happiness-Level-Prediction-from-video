Epoch: 1| Step: 0
Training loss: 4.821638107299805
Validation loss: 5.243376921581966

Epoch: 6| Step: 1
Training loss: 6.33935022354126
Validation loss: 5.236785801508093

Epoch: 6| Step: 2
Training loss: 6.115786552429199
Validation loss: 5.2341826295339935

Epoch: 6| Step: 3
Training loss: 4.606889724731445
Validation loss: 5.224021198928997

Epoch: 6| Step: 4
Training loss: 4.648853778839111
Validation loss: 5.218179923231884

Epoch: 6| Step: 5
Training loss: 4.567801475524902
Validation loss: 5.20898574911138

Epoch: 6| Step: 6
Training loss: 3.993919610977173
Validation loss: 5.2012792095061275

Epoch: 6| Step: 7
Training loss: 5.1527605056762695
Validation loss: 5.194833073564755

Epoch: 6| Step: 8
Training loss: 4.924333572387695
Validation loss: 5.187921898339384

Epoch: 6| Step: 9
Training loss: 5.263947010040283
Validation loss: 5.180291770606913

Epoch: 6| Step: 10
Training loss: 4.681018829345703
Validation loss: 5.172431648418468

Epoch: 6| Step: 11
Training loss: 5.752457618713379
Validation loss: 5.1681497891743975

Epoch: 6| Step: 12
Training loss: 3.9377822875976562
Validation loss: 5.159659221608152

Epoch: 6| Step: 13
Training loss: 5.2004899978637695
Validation loss: 5.15457284578713

Epoch: 2| Step: 0
Training loss: 4.714621543884277
Validation loss: 5.146552101258309

Epoch: 6| Step: 1
Training loss: 5.223662376403809
Validation loss: 5.140959442302745

Epoch: 6| Step: 2
Training loss: 4.379855155944824
Validation loss: 5.132412736133863

Epoch: 6| Step: 3
Training loss: 4.016583442687988
Validation loss: 5.1257537411105245

Epoch: 6| Step: 4
Training loss: 4.875471115112305
Validation loss: 5.119944674994356

Epoch: 6| Step: 5
Training loss: 4.388448715209961
Validation loss: 5.1132090476251415

Epoch: 6| Step: 6
Training loss: 4.42696475982666
Validation loss: 5.107550580014465

Epoch: 6| Step: 7
Training loss: 5.251038074493408
Validation loss: 5.10001294330884

Epoch: 6| Step: 8
Training loss: 4.465278625488281
Validation loss: 5.092235683113016

Epoch: 6| Step: 9
Training loss: 5.949612617492676
Validation loss: 5.086583286203364

Epoch: 6| Step: 10
Training loss: 5.336153984069824
Validation loss: 5.080298034093714

Epoch: 6| Step: 11
Training loss: 5.595415115356445
Validation loss: 5.0751256481293705

Epoch: 6| Step: 12
Training loss: 5.589210510253906
Validation loss: 5.0680113761655745

Epoch: 6| Step: 13
Training loss: 3.9704835414886475
Validation loss: 5.060924514647453

Epoch: 3| Step: 0
Training loss: 5.764163017272949
Validation loss: 5.055544812192199

Epoch: 6| Step: 1
Training loss: 4.5526652336120605
Validation loss: 5.048649398229456

Epoch: 6| Step: 2
Training loss: 5.849579811096191
Validation loss: 5.042641209017846

Epoch: 6| Step: 3
Training loss: 3.8857998847961426
Validation loss: 5.034637481935563

Epoch: 6| Step: 4
Training loss: 4.560688018798828
Validation loss: 5.03036956889655

Epoch: 6| Step: 5
Training loss: 5.375847339630127
Validation loss: 5.024872415809221

Epoch: 6| Step: 6
Training loss: 3.5456645488739014
Validation loss: 5.017591471313148

Epoch: 6| Step: 7
Training loss: 5.017307281494141
Validation loss: 5.009881045228692

Epoch: 6| Step: 8
Training loss: 3.8948230743408203
Validation loss: 5.005842813881495

Epoch: 6| Step: 9
Training loss: 4.399949073791504
Validation loss: 4.999816679185437

Epoch: 6| Step: 10
Training loss: 5.592419624328613
Validation loss: 4.990723327923846

Epoch: 6| Step: 11
Training loss: 5.1886677742004395
Validation loss: 4.9845560596835226

Epoch: 6| Step: 12
Training loss: 5.038597583770752
Validation loss: 4.978372122651788

Epoch: 6| Step: 13
Training loss: 4.501020908355713
Validation loss: 4.972707086993802

Epoch: 4| Step: 0
Training loss: 4.549225330352783
Validation loss: 4.967072127967753

Epoch: 6| Step: 1
Training loss: 3.881361484527588
Validation loss: 4.958186734107233

Epoch: 6| Step: 2
Training loss: 4.725400924682617
Validation loss: 4.9528849612000165

Epoch: 6| Step: 3
Training loss: 4.608680725097656
Validation loss: 4.943854983134936

Epoch: 6| Step: 4
Training loss: 5.88429069519043
Validation loss: 4.935710158399356

Epoch: 6| Step: 5
Training loss: 4.85539436340332
Validation loss: 4.930653638737176

Epoch: 6| Step: 6
Training loss: 3.8547115325927734
Validation loss: 4.92066603834911

Epoch: 6| Step: 7
Training loss: 5.253007888793945
Validation loss: 4.917120338768087

Epoch: 6| Step: 8
Training loss: 5.26037073135376
Validation loss: 4.908796218133742

Epoch: 6| Step: 9
Training loss: 3.9377059936523438
Validation loss: 4.902255258252544

Epoch: 6| Step: 10
Training loss: 4.5888824462890625
Validation loss: 4.893695574934765

Epoch: 6| Step: 11
Training loss: 5.021557807922363
Validation loss: 4.887424750994611

Epoch: 6| Step: 12
Training loss: 5.0741963386535645
Validation loss: 4.88201351575954

Epoch: 6| Step: 13
Training loss: 4.243083953857422
Validation loss: 4.870169378096057

Epoch: 5| Step: 0
Training loss: 5.281039237976074
Validation loss: 4.865858713785808

Epoch: 6| Step: 1
Training loss: 4.78415584564209
Validation loss: 4.858066133273545

Epoch: 6| Step: 2
Training loss: 4.567228317260742
Validation loss: 4.851421807401923

Epoch: 6| Step: 3
Training loss: 5.309255123138428
Validation loss: 4.844188377421389

Epoch: 6| Step: 4
Training loss: 4.637874603271484
Validation loss: 4.83461049807969

Epoch: 6| Step: 5
Training loss: 4.9098896980285645
Validation loss: 4.8262143699071745

Epoch: 6| Step: 6
Training loss: 5.0322675704956055
Validation loss: 4.818564517523653

Epoch: 6| Step: 7
Training loss: 3.532606363296509
Validation loss: 4.8119559646934595

Epoch: 6| Step: 8
Training loss: 4.796926975250244
Validation loss: 4.8012741816941125

Epoch: 6| Step: 9
Training loss: 5.155290603637695
Validation loss: 4.794150819060623

Epoch: 6| Step: 10
Training loss: 4.07614803314209
Validation loss: 4.786617919962893

Epoch: 6| Step: 11
Training loss: 4.093813896179199
Validation loss: 4.777649587200534

Epoch: 6| Step: 12
Training loss: 3.4138941764831543
Validation loss: 4.7706228481825965

Epoch: 6| Step: 13
Training loss: 5.094003677368164
Validation loss: 4.759805694703133

Epoch: 6| Step: 0
Training loss: 4.2843708992004395
Validation loss: 4.752103267177459

Epoch: 6| Step: 1
Training loss: 6.332633018493652
Validation loss: 4.742337380686114

Epoch: 6| Step: 2
Training loss: 4.02691650390625
Validation loss: 4.73414477481637

Epoch: 6| Step: 3
Training loss: 5.433719635009766
Validation loss: 4.72799721071797

Epoch: 6| Step: 4
Training loss: 4.549828052520752
Validation loss: 4.718208718043502

Epoch: 6| Step: 5
Training loss: 3.8018641471862793
Validation loss: 4.705465368045274

Epoch: 6| Step: 6
Training loss: 3.340393543243408
Validation loss: 4.693504969278972

Epoch: 6| Step: 7
Training loss: 4.465280532836914
Validation loss: 4.6914793445218

Epoch: 6| Step: 8
Training loss: 3.5438411235809326
Validation loss: 4.677392349448255

Epoch: 6| Step: 9
Training loss: 5.607542991638184
Validation loss: 4.667819787097233

Epoch: 6| Step: 10
Training loss: 3.458189010620117
Validation loss: 4.661181496035669

Epoch: 6| Step: 11
Training loss: 5.218276023864746
Validation loss: 4.6479994814882994

Epoch: 6| Step: 12
Training loss: 4.395442962646484
Validation loss: 4.636253792752502

Epoch: 6| Step: 13
Training loss: 3.97145938873291
Validation loss: 4.627851804097493

Epoch: 7| Step: 0
Training loss: 3.948540449142456
Validation loss: 4.617673658555554

Epoch: 6| Step: 1
Training loss: 3.3618435859680176
Validation loss: 4.605806309689758

Epoch: 6| Step: 2
Training loss: 3.4804224967956543
Validation loss: 4.5952310869770665

Epoch: 6| Step: 3
Training loss: 4.386813640594482
Validation loss: 4.584032289443478

Epoch: 6| Step: 4
Training loss: 5.035364627838135
Validation loss: 4.574017791337864

Epoch: 6| Step: 5
Training loss: 5.447775840759277
Validation loss: 4.566410982480613

Epoch: 6| Step: 6
Training loss: 3.2522380352020264
Validation loss: 4.554782395721764

Epoch: 6| Step: 7
Training loss: 6.175195693969727
Validation loss: 4.5424360049668175

Epoch: 6| Step: 8
Training loss: 5.303749084472656
Validation loss: 4.532699451651625

Epoch: 6| Step: 9
Training loss: 3.847235679626465
Validation loss: 4.516941470484579

Epoch: 6| Step: 10
Training loss: 3.7020349502563477
Validation loss: 4.505717513381794

Epoch: 6| Step: 11
Training loss: 3.682720899581909
Validation loss: 4.497331388535038

Epoch: 6| Step: 12
Training loss: 4.163181304931641
Validation loss: 4.480948914763748

Epoch: 6| Step: 13
Training loss: 5.116219997406006
Validation loss: 4.472752294232769

Epoch: 8| Step: 0
Training loss: 4.686190605163574
Validation loss: 4.458098601269466

Epoch: 6| Step: 1
Training loss: 4.712977886199951
Validation loss: 4.449184361324515

Epoch: 6| Step: 2
Training loss: 5.042638778686523
Validation loss: 4.436398439509894

Epoch: 6| Step: 3
Training loss: 3.999863624572754
Validation loss: 4.418758320552047

Epoch: 6| Step: 4
Training loss: 4.10330867767334
Validation loss: 4.410867752567414

Epoch: 6| Step: 5
Training loss: 3.727825403213501
Validation loss: 4.394386873450331

Epoch: 6| Step: 6
Training loss: 4.071957111358643
Validation loss: 4.384874877109323

Epoch: 6| Step: 7
Training loss: 4.571315288543701
Validation loss: 4.370349079050044

Epoch: 6| Step: 8
Training loss: 3.4433860778808594
Validation loss: 4.355415451911188

Epoch: 6| Step: 9
Training loss: 3.9308977127075195
Validation loss: 4.338411343994961

Epoch: 6| Step: 10
Training loss: 4.394786834716797
Validation loss: 4.33293656892674

Epoch: 6| Step: 11
Training loss: 2.7865867614746094
Validation loss: 4.318427834459531

Epoch: 6| Step: 12
Training loss: 4.4762163162231445
Validation loss: 4.301910820827689

Epoch: 6| Step: 13
Training loss: 4.524622917175293
Validation loss: 4.285689166797105

Epoch: 9| Step: 0
Training loss: 4.722362041473389
Validation loss: 4.277499073295183

Epoch: 6| Step: 1
Training loss: 3.8331756591796875
Validation loss: 4.263421627783006

Epoch: 6| Step: 2
Training loss: 3.713057518005371
Validation loss: 4.246321360270183

Epoch: 6| Step: 3
Training loss: 3.020646333694458
Validation loss: 4.237991691917501

Epoch: 6| Step: 4
Training loss: 3.424086570739746
Validation loss: 4.222458160051736

Epoch: 6| Step: 5
Training loss: 3.259634494781494
Validation loss: 4.215241701372208

Epoch: 6| Step: 6
Training loss: 4.236520767211914
Validation loss: 4.20041948492809

Epoch: 6| Step: 7
Training loss: 4.650979995727539
Validation loss: 4.186130867209486

Epoch: 6| Step: 8
Training loss: 4.067084312438965
Validation loss: 4.169047719688826

Epoch: 6| Step: 9
Training loss: 3.7598319053649902
Validation loss: 4.15711094743462

Epoch: 6| Step: 10
Training loss: 4.194975852966309
Validation loss: 4.144427714809295

Epoch: 6| Step: 11
Training loss: 3.7220845222473145
Validation loss: 4.124028877545428

Epoch: 6| Step: 12
Training loss: 5.010369300842285
Validation loss: 4.108216429269442

Epoch: 6| Step: 13
Training loss: 4.299440383911133
Validation loss: 4.10017648050862

Epoch: 10| Step: 0
Training loss: 4.30020809173584
Validation loss: 4.080065050432759

Epoch: 6| Step: 1
Training loss: 3.6026527881622314
Validation loss: 4.065024247733495

Epoch: 6| Step: 2
Training loss: 2.9100492000579834
Validation loss: 4.0536335488801365

Epoch: 6| Step: 3
Training loss: 4.450756072998047
Validation loss: 4.036128838857015

Epoch: 6| Step: 4
Training loss: 3.075382709503174
Validation loss: 4.023867725044169

Epoch: 6| Step: 5
Training loss: 4.239057540893555
Validation loss: 4.012369871139526

Epoch: 6| Step: 6
Training loss: 3.267213821411133
Validation loss: 3.9908592982958724

Epoch: 6| Step: 7
Training loss: 3.438314914703369
Validation loss: 3.9780894146170667

Epoch: 6| Step: 8
Training loss: 5.378505706787109
Validation loss: 3.964711784034647

Epoch: 6| Step: 9
Training loss: 4.058035850524902
Validation loss: 3.9490013122558594

Epoch: 6| Step: 10
Training loss: 3.651970386505127
Validation loss: 3.935536528146395

Epoch: 6| Step: 11
Training loss: 3.1222991943359375
Validation loss: 3.918607475937054

Epoch: 6| Step: 12
Training loss: 3.8648271560668945
Validation loss: 3.903701397680467

Epoch: 6| Step: 13
Training loss: 3.9941203594207764
Validation loss: 3.892280827286423

Epoch: 11| Step: 0
Training loss: 2.8834495544433594
Validation loss: 3.872620480034941

Epoch: 6| Step: 1
Training loss: 3.660977363586426
Validation loss: 3.855130918564335

Epoch: 6| Step: 2
Training loss: 3.5724833011627197
Validation loss: 3.8458861997050624

Epoch: 6| Step: 3
Training loss: 4.7893571853637695
Validation loss: 3.8211095974009526

Epoch: 6| Step: 4
Training loss: 3.7393741607666016
Validation loss: 3.8094250412397486

Epoch: 6| Step: 5
Training loss: 1.9076433181762695
Validation loss: 3.786898748849028

Epoch: 6| Step: 6
Training loss: 3.3435497283935547
Validation loss: 3.7713694418630292

Epoch: 6| Step: 7
Training loss: 3.3004353046417236
Validation loss: 3.7565911944194506

Epoch: 6| Step: 8
Training loss: 3.317750930786133
Validation loss: 3.744719100254838

Epoch: 6| Step: 9
Training loss: 3.111119270324707
Validation loss: 3.7249149404546267

Epoch: 6| Step: 10
Training loss: 4.8049139976501465
Validation loss: 3.7138447838444866

Epoch: 6| Step: 11
Training loss: 4.981283187866211
Validation loss: 3.6845200574526222

Epoch: 6| Step: 12
Training loss: 3.428741931915283
Validation loss: 3.67615770780912

Epoch: 6| Step: 13
Training loss: 3.915069103240967
Validation loss: 3.65634778494476

Epoch: 12| Step: 0
Training loss: 4.130220413208008
Validation loss: 3.6392174023453907

Epoch: 6| Step: 1
Training loss: 4.728137969970703
Validation loss: 3.6241013465389127

Epoch: 6| Step: 2
Training loss: 3.198047637939453
Validation loss: 3.6061864770868772

Epoch: 6| Step: 3
Training loss: 4.436702728271484
Validation loss: 3.589458070775514

Epoch: 6| Step: 4
Training loss: 3.2123732566833496
Validation loss: 3.57086000134868

Epoch: 6| Step: 5
Training loss: 3.4739737510681152
Validation loss: 3.554790868554064

Epoch: 6| Step: 6
Training loss: 3.090564727783203
Validation loss: 3.5365564233513287

Epoch: 6| Step: 7
Training loss: 3.0620217323303223
Validation loss: 3.520111068602531

Epoch: 6| Step: 8
Training loss: 2.681041717529297
Validation loss: 3.5050435066223145

Epoch: 6| Step: 9
Training loss: 2.954728603363037
Validation loss: 3.492257389971005

Epoch: 6| Step: 10
Training loss: 3.7408037185668945
Validation loss: 3.470441546491397

Epoch: 6| Step: 11
Training loss: 2.4169907569885254
Validation loss: 3.4528154660296697

Epoch: 6| Step: 12
Training loss: 3.4116992950439453
Validation loss: 3.433592934762278

Epoch: 6| Step: 13
Training loss: 2.954993724822998
Validation loss: 3.4179140470361196

Epoch: 13| Step: 0
Training loss: 3.2172605991363525
Validation loss: 3.4006688389726865

Epoch: 6| Step: 1
Training loss: 3.3589236736297607
Validation loss: 3.375410441429384

Epoch: 6| Step: 2
Training loss: 3.5935280323028564
Validation loss: 3.368051059784428

Epoch: 6| Step: 3
Training loss: 3.2653591632843018
Validation loss: 3.3420024712880454

Epoch: 6| Step: 4
Training loss: 3.241579294204712
Validation loss: 3.3244643724092873

Epoch: 6| Step: 5
Training loss: 3.515839099884033
Validation loss: 3.307102895552112

Epoch: 6| Step: 6
Training loss: 2.6956253051757812
Validation loss: 3.2809847862489763

Epoch: 6| Step: 7
Training loss: 3.237093925476074
Validation loss: 3.269142827680034

Epoch: 6| Step: 8
Training loss: 2.5878539085388184
Validation loss: 3.2489502096688874

Epoch: 6| Step: 9
Training loss: 2.723942518234253
Validation loss: 3.2263970169969785

Epoch: 6| Step: 10
Training loss: 3.694385051727295
Validation loss: 3.204608381435435

Epoch: 6| Step: 11
Training loss: 3.5671744346618652
Validation loss: 3.1814575092766875

Epoch: 6| Step: 12
Training loss: 2.3687491416931152
Validation loss: 3.163811634945613

Epoch: 6| Step: 13
Training loss: 3.630337715148926
Validation loss: 3.1406851789002777

Epoch: 14| Step: 0
Training loss: 3.6359164714813232
Validation loss: 3.133210002735097

Epoch: 6| Step: 1
Training loss: 2.915632486343384
Validation loss: 3.109438814142699

Epoch: 6| Step: 2
Training loss: 3.0273385047912598
Validation loss: 3.0858080310206257

Epoch: 6| Step: 3
Training loss: 2.058587074279785
Validation loss: 3.0712962253119356

Epoch: 6| Step: 4
Training loss: 3.61234188079834
Validation loss: 3.0581204660477175

Epoch: 6| Step: 5
Training loss: 2.1024484634399414
Validation loss: 3.0323164283588366

Epoch: 6| Step: 6
Training loss: 3.208484649658203
Validation loss: 3.0159442373501357

Epoch: 6| Step: 7
Training loss: 2.942516326904297
Validation loss: 2.99576227126583

Epoch: 6| Step: 8
Training loss: 3.0085601806640625
Validation loss: 2.97699369922761

Epoch: 6| Step: 9
Training loss: 3.21193265914917
Validation loss: 2.9525455710708455

Epoch: 6| Step: 10
Training loss: 3.31618070602417
Validation loss: 2.943950340312014

Epoch: 6| Step: 11
Training loss: 2.959437131881714
Validation loss: 2.9138060000634964

Epoch: 6| Step: 12
Training loss: 3.0141377449035645
Validation loss: 2.9043205886758785

Epoch: 6| Step: 13
Training loss: 2.8396992683410645
Validation loss: 2.886555197418377

Epoch: 15| Step: 0
Training loss: 2.7047858238220215
Validation loss: 2.8743209403048278

Epoch: 6| Step: 1
Training loss: 2.179644823074341
Validation loss: 2.8566296741526616

Epoch: 6| Step: 2
Training loss: 2.859192371368408
Validation loss: 2.831294159735403

Epoch: 6| Step: 3
Training loss: 3.0038270950317383
Validation loss: 2.8143598443718365

Epoch: 6| Step: 4
Training loss: 3.613600492477417
Validation loss: 2.8070223408360637

Epoch: 6| Step: 5
Training loss: 3.1677680015563965
Validation loss: 2.778309550336612

Epoch: 6| Step: 6
Training loss: 2.943068265914917
Validation loss: 2.759554127211212

Epoch: 6| Step: 7
Training loss: 3.101895809173584
Validation loss: 2.744294551111037

Epoch: 6| Step: 8
Training loss: 2.8766841888427734
Validation loss: 2.7205820493800665

Epoch: 6| Step: 9
Training loss: 3.801698923110962
Validation loss: 2.710515886224726

Epoch: 6| Step: 10
Training loss: 2.036665916442871
Validation loss: 2.6973862583919237

Epoch: 6| Step: 11
Training loss: 2.4584908485412598
Validation loss: 2.675974444676471

Epoch: 6| Step: 12
Training loss: 2.272031307220459
Validation loss: 2.6532330615546114

Epoch: 6| Step: 13
Training loss: 2.627018690109253
Validation loss: 2.640326092320104

Epoch: 16| Step: 0
Training loss: 2.689225435256958
Validation loss: 2.6277612127283567

Epoch: 6| Step: 1
Training loss: 2.0822160243988037
Validation loss: 2.620941738928518

Epoch: 6| Step: 2
Training loss: 1.8890516757965088
Validation loss: 2.60507228297572

Epoch: 6| Step: 3
Training loss: 2.773031711578369
Validation loss: 2.5878509193338375

Epoch: 6| Step: 4
Training loss: 2.6469011306762695
Validation loss: 2.5709311885218464

Epoch: 6| Step: 5
Training loss: 3.521475315093994
Validation loss: 2.5610730135312645

Epoch: 6| Step: 6
Training loss: 2.3065452575683594
Validation loss: 2.548089417078162

Epoch: 6| Step: 7
Training loss: 2.5609049797058105
Validation loss: 2.5210173873491186

Epoch: 6| Step: 8
Training loss: 2.2298078536987305
Validation loss: 2.51035495983657

Epoch: 6| Step: 9
Training loss: 3.0008699893951416
Validation loss: 2.4932345805629605

Epoch: 6| Step: 10
Training loss: 3.443026065826416
Validation loss: 2.4814567668463594

Epoch: 6| Step: 11
Training loss: 3.1820201873779297
Validation loss: 2.467873837358208

Epoch: 6| Step: 12
Training loss: 2.637779951095581
Validation loss: 2.4588358120251725

Epoch: 6| Step: 13
Training loss: 2.6634607315063477
Validation loss: 2.439624345430764

Epoch: 17| Step: 0
Training loss: 2.546581745147705
Validation loss: 2.417873846587314

Epoch: 6| Step: 1
Training loss: 2.559203624725342
Validation loss: 2.4185378141300653

Epoch: 6| Step: 2
Training loss: 2.485990524291992
Validation loss: 2.413587277935397

Epoch: 6| Step: 3
Training loss: 2.1954345703125
Validation loss: 2.4107375170594905

Epoch: 6| Step: 4
Training loss: 2.285994529724121
Validation loss: 2.3849868851323284

Epoch: 6| Step: 5
Training loss: 2.7552566528320312
Validation loss: 2.3871657566357682

Epoch: 6| Step: 6
Training loss: 2.516395092010498
Validation loss: 2.3750549208733345

Epoch: 6| Step: 7
Training loss: 3.0659875869750977
Validation loss: 2.371169328689575

Epoch: 6| Step: 8
Training loss: 2.497082233428955
Validation loss: 2.3687704634922806

Epoch: 6| Step: 9
Training loss: 3.0584545135498047
Validation loss: 2.3677264644253637

Epoch: 6| Step: 10
Training loss: 2.5822553634643555
Validation loss: 2.355470671448656

Epoch: 6| Step: 11
Training loss: 2.8583450317382812
Validation loss: 2.356462128700749

Epoch: 6| Step: 12
Training loss: 2.310784339904785
Validation loss: 2.3435428501457296

Epoch: 6| Step: 13
Training loss: 2.263279914855957
Validation loss: 2.3481893872701995

Epoch: 18| Step: 0
Training loss: 2.4277515411376953
Validation loss: 2.3346157458520707

Epoch: 6| Step: 1
Training loss: 2.315865993499756
Validation loss: 2.329240499004241

Epoch: 6| Step: 2
Training loss: 2.3652915954589844
Validation loss: 2.3362477928079586

Epoch: 6| Step: 3
Training loss: 2.4337844848632812
Validation loss: 2.3174618828681206

Epoch: 6| Step: 4
Training loss: 3.196357250213623
Validation loss: 2.306213119978546

Epoch: 6| Step: 5
Training loss: 2.8619537353515625
Validation loss: 2.2834370572079896

Epoch: 6| Step: 6
Training loss: 2.7027411460876465
Validation loss: 2.2950840893612114

Epoch: 6| Step: 7
Training loss: 2.0536551475524902
Validation loss: 2.284581635587959

Epoch: 6| Step: 8
Training loss: 2.386691093444824
Validation loss: 2.2783347278512935

Epoch: 6| Step: 9
Training loss: 2.533641815185547
Validation loss: 2.2815497126630557

Epoch: 6| Step: 10
Training loss: 2.1586480140686035
Validation loss: 2.2712086580132924

Epoch: 6| Step: 11
Training loss: 2.5889124870300293
Validation loss: 2.270043685872068

Epoch: 6| Step: 12
Training loss: 3.006948709487915
Validation loss: 2.27046214636936

Epoch: 6| Step: 13
Training loss: 1.8004695177078247
Validation loss: 2.2508316091311875

Epoch: 19| Step: 0
Training loss: 2.4522688388824463
Validation loss: 2.2501679722980787

Epoch: 6| Step: 1
Training loss: 2.11820650100708
Validation loss: 2.254107600899153

Epoch: 6| Step: 2
Training loss: 2.430854082107544
Validation loss: 2.2465660213142313

Epoch: 6| Step: 3
Training loss: 3.769702911376953
Validation loss: 2.2464671557949436

Epoch: 6| Step: 4
Training loss: 2.0496976375579834
Validation loss: 2.233120374782111

Epoch: 6| Step: 5
Training loss: 3.641972541809082
Validation loss: 2.2517008935251543

Epoch: 6| Step: 6
Training loss: 2.6252315044403076
Validation loss: 2.2267043821273313

Epoch: 6| Step: 7
Training loss: 3.147305488586426
Validation loss: 2.236794692213817

Epoch: 6| Step: 8
Training loss: 2.057354688644409
Validation loss: 2.2249131125788533

Epoch: 6| Step: 9
Training loss: 2.655071973800659
Validation loss: 2.226105272129018

Epoch: 6| Step: 10
Training loss: 1.685316801071167
Validation loss: 2.219496835944473

Epoch: 6| Step: 11
Training loss: 2.3358540534973145
Validation loss: 2.206955676437706

Epoch: 6| Step: 12
Training loss: 1.8642710447311401
Validation loss: 2.2047535757864676

Epoch: 6| Step: 13
Training loss: 1.9120908975601196
Validation loss: 2.223174206672176

Epoch: 20| Step: 0
Training loss: 2.601593017578125
Validation loss: 2.2062486756232476

Epoch: 6| Step: 1
Training loss: 2.480560302734375
Validation loss: 2.2109622263139292

Epoch: 6| Step: 2
Training loss: 3.0202255249023438
Validation loss: 2.201006112560149

Epoch: 6| Step: 3
Training loss: 2.5762991905212402
Validation loss: 2.205226082955637

Epoch: 6| Step: 4
Training loss: 2.5714569091796875
Validation loss: 2.2047997213179067

Epoch: 6| Step: 5
Training loss: 2.1532413959503174
Validation loss: 2.200416495723109

Epoch: 6| Step: 6
Training loss: 2.520275115966797
Validation loss: 2.193868047447615

Epoch: 6| Step: 7
Training loss: 2.092095136642456
Validation loss: 2.200084311987764

Epoch: 6| Step: 8
Training loss: 2.244567632675171
Validation loss: 2.2013019669440483

Epoch: 6| Step: 9
Training loss: 3.0301506519317627
Validation loss: 2.1906100421823482

Epoch: 6| Step: 10
Training loss: 2.6106061935424805
Validation loss: 2.188126984462943

Epoch: 6| Step: 11
Training loss: 2.347320556640625
Validation loss: 2.1980241011547785

Epoch: 6| Step: 12
Training loss: 2.1900949478149414
Validation loss: 2.188570991639168

Epoch: 6| Step: 13
Training loss: 2.363654613494873
Validation loss: 2.1904442848697787

Epoch: 21| Step: 0
Training loss: 2.5471720695495605
Validation loss: 2.1883035347025883

Epoch: 6| Step: 1
Training loss: 2.5825119018554688
Validation loss: 2.1840906617461995

Epoch: 6| Step: 2
Training loss: 1.8496057987213135
Validation loss: 2.1805657186815814

Epoch: 6| Step: 3
Training loss: 1.9611923694610596
Validation loss: 2.1845016658947034

Epoch: 6| Step: 4
Training loss: 1.683060646057129
Validation loss: 2.1750099018055904

Epoch: 6| Step: 5
Training loss: 2.338709831237793
Validation loss: 2.175571515995969

Epoch: 6| Step: 6
Training loss: 3.005540370941162
Validation loss: 2.181303890802527

Epoch: 6| Step: 7
Training loss: 1.8055000305175781
Validation loss: 2.1713014366806194

Epoch: 6| Step: 8
Training loss: 3.2202765941619873
Validation loss: 2.1836200055255683

Epoch: 6| Step: 9
Training loss: 3.2125821113586426
Validation loss: 2.178666830062866

Epoch: 6| Step: 10
Training loss: 2.788130283355713
Validation loss: 2.164513841752083

Epoch: 6| Step: 11
Training loss: 2.7142958641052246
Validation loss: 2.162838605142409

Epoch: 6| Step: 12
Training loss: 2.2449779510498047
Validation loss: 2.1622647521316365

Epoch: 6| Step: 13
Training loss: 2.946399211883545
Validation loss: 2.1710693528575282

Epoch: 22| Step: 0
Training loss: 2.0874948501586914
Validation loss: 2.1569385169654764

Epoch: 6| Step: 1
Training loss: 2.5923869609832764
Validation loss: 2.1589050036604687

Epoch: 6| Step: 2
Training loss: 2.925471305847168
Validation loss: 2.1669050019274474

Epoch: 6| Step: 3
Training loss: 2.2140562534332275
Validation loss: 2.1772922623542046

Epoch: 6| Step: 4
Training loss: 1.442483901977539
Validation loss: 2.162558706857825

Epoch: 6| Step: 5
Training loss: 2.998246192932129
Validation loss: 2.159500895007964

Epoch: 6| Step: 6
Training loss: 2.395024538040161
Validation loss: 2.1739644670999176

Epoch: 6| Step: 7
Training loss: 2.8450541496276855
Validation loss: 2.1452609236522386

Epoch: 6| Step: 8
Training loss: 2.453644275665283
Validation loss: 2.183238096134637

Epoch: 6| Step: 9
Training loss: 2.4713969230651855
Validation loss: 2.155646995831561

Epoch: 6| Step: 10
Training loss: 1.9827771186828613
Validation loss: 2.170398904431251

Epoch: 6| Step: 11
Training loss: 2.888308048248291
Validation loss: 2.1640202050567954

Epoch: 6| Step: 12
Training loss: 2.6846535205841064
Validation loss: 2.1713984268967823

Epoch: 6| Step: 13
Training loss: 2.262897491455078
Validation loss: 2.1458206125485

Epoch: 23| Step: 0
Training loss: 2.920884609222412
Validation loss: 2.144290421598701

Epoch: 6| Step: 1
Training loss: 2.916701555252075
Validation loss: 2.162792936448128

Epoch: 6| Step: 2
Training loss: 2.3248047828674316
Validation loss: 2.152904613043672

Epoch: 6| Step: 3
Training loss: 2.218998670578003
Validation loss: 2.140904052283174

Epoch: 6| Step: 4
Training loss: 2.562931537628174
Validation loss: 2.1568392271636636

Epoch: 6| Step: 5
Training loss: 2.754005193710327
Validation loss: 2.1639429394916823

Epoch: 6| Step: 6
Training loss: 1.7461186647415161
Validation loss: 2.158795492623442

Epoch: 6| Step: 7
Training loss: 2.515439033508301
Validation loss: 2.1385925867224254

Epoch: 6| Step: 8
Training loss: 2.6620476245880127
Validation loss: 2.165171874466763

Epoch: 6| Step: 9
Training loss: 2.274993658065796
Validation loss: 2.1446858964940554

Epoch: 6| Step: 10
Training loss: 2.1719229221343994
Validation loss: 2.1685990800139723

Epoch: 6| Step: 11
Training loss: 2.1952977180480957
Validation loss: 2.1638344154563

Epoch: 6| Step: 12
Training loss: 2.6840527057647705
Validation loss: 2.140919618709113

Epoch: 6| Step: 13
Training loss: 2.3532705307006836
Validation loss: 2.158762803641699

Epoch: 24| Step: 0
Training loss: 2.249080181121826
Validation loss: 2.158494880122523

Epoch: 6| Step: 1
Training loss: 2.7170093059539795
Validation loss: 2.1428137851017777

Epoch: 6| Step: 2
Training loss: 2.540882110595703
Validation loss: 2.1424637494548673

Epoch: 6| Step: 3
Training loss: 1.8997915983200073
Validation loss: 2.1520852299146753

Epoch: 6| Step: 4
Training loss: 3.157306671142578
Validation loss: 2.1522132735098563

Epoch: 6| Step: 5
Training loss: 2.35384202003479
Validation loss: 2.1534956014284523

Epoch: 6| Step: 6
Training loss: 1.9299037456512451
Validation loss: 2.1630832328591296

Epoch: 6| Step: 7
Training loss: 2.5386433601379395
Validation loss: 2.1403367365560224

Epoch: 6| Step: 8
Training loss: 2.1492457389831543
Validation loss: 2.148614001530473

Epoch: 6| Step: 9
Training loss: 2.932108163833618
Validation loss: 2.1527660110945344

Epoch: 6| Step: 10
Training loss: 2.421935558319092
Validation loss: 2.150823503412226

Epoch: 6| Step: 11
Training loss: 2.6675002574920654
Validation loss: 2.14900206494075

Epoch: 6| Step: 12
Training loss: 1.8055312633514404
Validation loss: 2.15269499440347

Epoch: 6| Step: 13
Training loss: 3.099600076675415
Validation loss: 2.1427416750179824

Epoch: 25| Step: 0
Training loss: 3.0388948917388916
Validation loss: 2.149189013306813

Epoch: 6| Step: 1
Training loss: 2.659632444381714
Validation loss: 2.1437860253036662

Epoch: 6| Step: 2
Training loss: 2.901160478591919
Validation loss: 2.1581065988027923

Epoch: 6| Step: 3
Training loss: 2.561969518661499
Validation loss: 2.137074480774582

Epoch: 6| Step: 4
Training loss: 2.337883949279785
Validation loss: 2.1505768581103255

Epoch: 6| Step: 5
Training loss: 1.6668014526367188
Validation loss: 2.142729151633478

Epoch: 6| Step: 6
Training loss: 1.9584565162658691
Validation loss: 2.138458973617964

Epoch: 6| Step: 7
Training loss: 2.985903263092041
Validation loss: 2.1415014343876995

Epoch: 6| Step: 8
Training loss: 2.650834083557129
Validation loss: 2.1639516738153275

Epoch: 6| Step: 9
Training loss: 2.599513530731201
Validation loss: 2.132352182942052

Epoch: 6| Step: 10
Training loss: 1.9719377756118774
Validation loss: 2.1536062532855618

Epoch: 6| Step: 11
Training loss: 2.012565851211548
Validation loss: 2.1489086022941013

Epoch: 6| Step: 12
Training loss: 2.3360767364501953
Validation loss: 2.1380402349656626

Epoch: 6| Step: 13
Training loss: 2.416846990585327
Validation loss: 2.149969626498479

Epoch: 26| Step: 0
Training loss: 1.6761507987976074
Validation loss: 2.1611463151952273

Epoch: 6| Step: 1
Training loss: 2.636918067932129
Validation loss: 2.135589322736186

Epoch: 6| Step: 2
Training loss: 2.515219211578369
Validation loss: 2.13614050931828

Epoch: 6| Step: 3
Training loss: 3.3553948402404785
Validation loss: 2.133809510097709

Epoch: 6| Step: 4
Training loss: 2.431358575820923
Validation loss: 2.13101069260669

Epoch: 6| Step: 5
Training loss: 2.5693540573120117
Validation loss: 2.1319359066665813

Epoch: 6| Step: 6
Training loss: 2.281229019165039
Validation loss: 2.1336318549289497

Epoch: 6| Step: 7
Training loss: 2.0060172080993652
Validation loss: 2.1423687114510486

Epoch: 6| Step: 8
Training loss: 2.0078742504119873
Validation loss: 2.131639189617608

Epoch: 6| Step: 9
Training loss: 2.6835412979125977
Validation loss: 2.1445469035897204

Epoch: 6| Step: 10
Training loss: 3.2109694480895996
Validation loss: 2.1383477564780944

Epoch: 6| Step: 11
Training loss: 1.9512948989868164
Validation loss: 2.1573521603820143

Epoch: 6| Step: 12
Training loss: 2.4081363677978516
Validation loss: 2.147912891962195

Epoch: 6| Step: 13
Training loss: 2.071354866027832
Validation loss: 2.1403488343761814

Epoch: 27| Step: 0
Training loss: 1.9028542041778564
Validation loss: 2.1352070685355895

Epoch: 6| Step: 1
Training loss: 2.60183048248291
Validation loss: 2.1263880422038417

Epoch: 6| Step: 2
Training loss: 1.8010557889938354
Validation loss: 2.1554893857689312

Epoch: 6| Step: 3
Training loss: 2.821148157119751
Validation loss: 2.1434993179895545

Epoch: 6| Step: 4
Training loss: 2.963043451309204
Validation loss: 2.133907920570784

Epoch: 6| Step: 5
Training loss: 2.8982675075531006
Validation loss: 2.133690418735627

Epoch: 6| Step: 6
Training loss: 1.728440284729004
Validation loss: 2.147572300767386

Epoch: 6| Step: 7
Training loss: 2.6167030334472656
Validation loss: 2.134725114350678

Epoch: 6| Step: 8
Training loss: 3.1040987968444824
Validation loss: 2.1353219503997476

Epoch: 6| Step: 9
Training loss: 2.700404644012451
Validation loss: 2.1388975061396116

Epoch: 6| Step: 10
Training loss: 2.2990970611572266
Validation loss: 2.123048665702984

Epoch: 6| Step: 11
Training loss: 1.7189538478851318
Validation loss: 2.1232195669604885

Epoch: 6| Step: 12
Training loss: 2.737121105194092
Validation loss: 2.1238307901608047

Epoch: 6| Step: 13
Training loss: 1.6718955039978027
Validation loss: 2.1278371041820896

Epoch: 28| Step: 0
Training loss: 2.3220019340515137
Validation loss: 2.12714401624536

Epoch: 6| Step: 1
Training loss: 1.8897948265075684
Validation loss: 2.12800080801851

Epoch: 6| Step: 2
Training loss: 1.776860237121582
Validation loss: 2.1287187363511775

Epoch: 6| Step: 3
Training loss: 2.1886117458343506
Validation loss: 2.119986681527989

Epoch: 6| Step: 4
Training loss: 2.7114920616149902
Validation loss: 2.124546341998603

Epoch: 6| Step: 5
Training loss: 2.2199630737304688
Validation loss: 2.129240761521042

Epoch: 6| Step: 6
Training loss: 2.679248809814453
Validation loss: 2.126734674617808

Epoch: 6| Step: 7
Training loss: 2.515162467956543
Validation loss: 2.127662125454154

Epoch: 6| Step: 8
Training loss: 2.6712911128997803
Validation loss: 2.1287890954684188

Epoch: 6| Step: 9
Training loss: 2.752124309539795
Validation loss: 2.1090567906697593

Epoch: 6| Step: 10
Training loss: 1.9871726036071777
Validation loss: 2.1220018786768757

Epoch: 6| Step: 11
Training loss: 2.2474002838134766
Validation loss: 2.126431849695021

Epoch: 6| Step: 12
Training loss: 3.133545160293579
Validation loss: 2.115999032092351

Epoch: 6| Step: 13
Training loss: 2.6779370307922363
Validation loss: 2.1331680026105655

Epoch: 29| Step: 0
Training loss: 2.8436355590820312
Validation loss: 2.121935967476137

Epoch: 6| Step: 1
Training loss: 2.330097198486328
Validation loss: 2.0898093254335466

Epoch: 6| Step: 2
Training loss: 2.5059823989868164
Validation loss: 2.132196646864696

Epoch: 6| Step: 3
Training loss: 1.7521617412567139
Validation loss: 2.132636788070843

Epoch: 6| Step: 4
Training loss: 2.663215160369873
Validation loss: 2.1205476765991538

Epoch: 6| Step: 5
Training loss: 2.9699604511260986
Validation loss: 2.128768544043264

Epoch: 6| Step: 6
Training loss: 1.7070972919464111
Validation loss: 2.126829380630165

Epoch: 6| Step: 7
Training loss: 2.244997024536133
Validation loss: 2.120186592942925

Epoch: 6| Step: 8
Training loss: 3.28926420211792
Validation loss: 2.1002507696869555

Epoch: 6| Step: 9
Training loss: 2.377587080001831
Validation loss: 2.1140496987168507

Epoch: 6| Step: 10
Training loss: 2.1628198623657227
Validation loss: 2.1075094387095463

Epoch: 6| Step: 11
Training loss: 2.6468963623046875
Validation loss: 2.11136640784561

Epoch: 6| Step: 12
Training loss: 2.056177854537964
Validation loss: 2.114837560602414

Epoch: 6| Step: 13
Training loss: 1.8038406372070312
Validation loss: 2.11687566900766

Epoch: 30| Step: 0
Training loss: 2.5407509803771973
Validation loss: 2.106009262864308

Epoch: 6| Step: 1
Training loss: 2.6824193000793457
Validation loss: 2.0880687185513076

Epoch: 6| Step: 2
Training loss: 2.5674936771392822
Validation loss: 2.095128923334101

Epoch: 6| Step: 3
Training loss: 3.2616264820098877
Validation loss: 2.1068596070812595

Epoch: 6| Step: 4
Training loss: 2.653622627258301
Validation loss: 2.1058872284427768

Epoch: 6| Step: 5
Training loss: 2.5585594177246094
Validation loss: 2.1006156065130748

Epoch: 6| Step: 6
Training loss: 2.1391162872314453
Validation loss: 2.108583829736197

Epoch: 6| Step: 7
Training loss: 1.7146883010864258
Validation loss: 2.1080967136608657

Epoch: 6| Step: 8
Training loss: 2.004826545715332
Validation loss: 2.1123681170966035

Epoch: 6| Step: 9
Training loss: 1.8876522779464722
Validation loss: 2.103855256111391

Epoch: 6| Step: 10
Training loss: 2.627375602722168
Validation loss: 2.1090612411499023

Epoch: 6| Step: 11
Training loss: 1.4342553615570068
Validation loss: 2.10715659715796

Epoch: 6| Step: 12
Training loss: 2.7274866104125977
Validation loss: 2.1055154300505117

Epoch: 6| Step: 13
Training loss: 2.906885862350464
Validation loss: 2.0899914259551675

Epoch: 31| Step: 0
Training loss: 2.6942062377929688
Validation loss: 2.100499949147624

Epoch: 6| Step: 1
Training loss: 2.050827741622925
Validation loss: 2.0946276021260086

Epoch: 6| Step: 2
Training loss: 1.8974032402038574
Validation loss: 2.0921160687682447

Epoch: 6| Step: 3
Training loss: 3.2004759311676025
Validation loss: 2.1093984368026897

Epoch: 6| Step: 4
Training loss: 2.3393402099609375
Validation loss: 2.1056283673932477

Epoch: 6| Step: 5
Training loss: 2.892644166946411
Validation loss: 2.1067624220284085

Epoch: 6| Step: 6
Training loss: 1.623837947845459
Validation loss: 2.106194229536159

Epoch: 6| Step: 7
Training loss: 2.215357542037964
Validation loss: 2.1033866226032214

Epoch: 6| Step: 8
Training loss: 2.209260940551758
Validation loss: 2.107163885588287

Epoch: 6| Step: 9
Training loss: 1.7527191638946533
Validation loss: 2.094496468062042

Epoch: 6| Step: 10
Training loss: 2.6073484420776367
Validation loss: 2.0940570280116093

Epoch: 6| Step: 11
Training loss: 2.304760694503784
Validation loss: 2.095517419999646

Epoch: 6| Step: 12
Training loss: 2.5536694526672363
Validation loss: 2.086639250478437

Epoch: 6| Step: 13
Training loss: 3.3710126876831055
Validation loss: 2.101471809930699

Epoch: 32| Step: 0
Training loss: 3.053833484649658
Validation loss: 2.0926025413697764

Epoch: 6| Step: 1
Training loss: 2.681612491607666
Validation loss: 2.106248478735647

Epoch: 6| Step: 2
Training loss: 1.8379909992218018
Validation loss: 2.1065737765322448

Epoch: 6| Step: 3
Training loss: 2.2087209224700928
Validation loss: 2.105122773878036

Epoch: 6| Step: 4
Training loss: 2.2264602184295654
Validation loss: 2.0860843043173514

Epoch: 6| Step: 5
Training loss: 1.9186826944351196
Validation loss: 2.0915039559846282

Epoch: 6| Step: 6
Training loss: 2.7775001525878906
Validation loss: 2.1036465680727394

Epoch: 6| Step: 7
Training loss: 2.7245898246765137
Validation loss: 2.0976079740831928

Epoch: 6| Step: 8
Training loss: 1.8404746055603027
Validation loss: 2.1020577492252475

Epoch: 6| Step: 9
Training loss: 2.2256364822387695
Validation loss: 2.1141102980541926

Epoch: 6| Step: 10
Training loss: 2.3263661861419678
Validation loss: 2.1116522935128983

Epoch: 6| Step: 11
Training loss: 2.195141553878784
Validation loss: 2.1139789704353578

Epoch: 6| Step: 12
Training loss: 2.935512065887451
Validation loss: 2.1232392608478503

Epoch: 6| Step: 13
Training loss: 2.1982767581939697
Validation loss: 2.1120152217085644

Epoch: 33| Step: 0
Training loss: 2.3338727951049805
Validation loss: 2.115274706194478

Epoch: 6| Step: 1
Training loss: 3.2542009353637695
Validation loss: 2.1093495943213023

Epoch: 6| Step: 2
Training loss: 2.2514700889587402
Validation loss: 2.1119354014755576

Epoch: 6| Step: 3
Training loss: 2.285860061645508
Validation loss: 2.108728701068509

Epoch: 6| Step: 4
Training loss: 1.5973479747772217
Validation loss: 2.0930749524024224

Epoch: 6| Step: 5
Training loss: 3.1908631324768066
Validation loss: 2.1041472855434624

Epoch: 6| Step: 6
Training loss: 1.7774118185043335
Validation loss: 2.0931034882863364

Epoch: 6| Step: 7
Training loss: 2.3961844444274902
Validation loss: 2.089526320016512

Epoch: 6| Step: 8
Training loss: 2.446760654449463
Validation loss: 2.0820762431749733

Epoch: 6| Step: 9
Training loss: 3.3979830741882324
Validation loss: 2.1075758139292398

Epoch: 6| Step: 10
Training loss: 2.3465633392333984
Validation loss: 2.1044098907901394

Epoch: 6| Step: 11
Training loss: 1.865583062171936
Validation loss: 2.0962358264512915

Epoch: 6| Step: 12
Training loss: 2.004034996032715
Validation loss: 2.0867130243650047

Epoch: 6| Step: 13
Training loss: 1.8585553169250488
Validation loss: 2.0908991854677916

Epoch: 34| Step: 0
Training loss: 2.712369918823242
Validation loss: 2.102072937514192

Epoch: 6| Step: 1
Training loss: 2.4346704483032227
Validation loss: 2.0984412752172

Epoch: 6| Step: 2
Training loss: 1.9887762069702148
Validation loss: 2.096940743025913

Epoch: 6| Step: 3
Training loss: 2.5926733016967773
Validation loss: 2.0790921539388676

Epoch: 6| Step: 4
Training loss: 2.4027533531188965
Validation loss: 2.088781641375634

Epoch: 6| Step: 5
Training loss: 2.302518367767334
Validation loss: 2.1099833250045776

Epoch: 6| Step: 6
Training loss: 2.1958260536193848
Validation loss: 2.098869244257609

Epoch: 6| Step: 7
Training loss: 2.063328742980957
Validation loss: 2.0897212695049983

Epoch: 6| Step: 8
Training loss: 2.050102710723877
Validation loss: 2.0955639039316485

Epoch: 6| Step: 9
Training loss: 3.2856903076171875
Validation loss: 2.0950334956569057

Epoch: 6| Step: 10
Training loss: 2.2485151290893555
Validation loss: 2.099362265679144

Epoch: 6| Step: 11
Training loss: 2.3916845321655273
Validation loss: 2.102311034356394

Epoch: 6| Step: 12
Training loss: 2.54768705368042
Validation loss: 2.0811970144189815

Epoch: 6| Step: 13
Training loss: 1.7145706415176392
Validation loss: 2.100656606817758

Epoch: 35| Step: 0
Training loss: 2.428431510925293
Validation loss: 2.0791176352449643

Epoch: 6| Step: 1
Training loss: 2.414501667022705
Validation loss: 2.0854484752942155

Epoch: 6| Step: 2
Training loss: 2.276446580886841
Validation loss: 2.0839075273083103

Epoch: 6| Step: 3
Training loss: 2.1570606231689453
Validation loss: 2.093764987043155

Epoch: 6| Step: 4
Training loss: 2.635824680328369
Validation loss: 2.1004559942471084

Epoch: 6| Step: 5
Training loss: 2.3882288932800293
Validation loss: 2.1030049529126895

Epoch: 6| Step: 6
Training loss: 1.9298458099365234
Validation loss: 2.077287625241023

Epoch: 6| Step: 7
Training loss: 3.078646183013916
Validation loss: 2.0989708080086658

Epoch: 6| Step: 8
Training loss: 2.59901762008667
Validation loss: 2.0769245175905127

Epoch: 6| Step: 9
Training loss: 1.8611927032470703
Validation loss: 2.0868243632778043

Epoch: 6| Step: 10
Training loss: 3.270289897918701
Validation loss: 2.0889033412420623

Epoch: 6| Step: 11
Training loss: 1.6269817352294922
Validation loss: 2.0839919095398276

Epoch: 6| Step: 12
Training loss: 2.2676961421966553
Validation loss: 2.0875156784570343

Epoch: 6| Step: 13
Training loss: 2.159644603729248
Validation loss: 2.0884313993556525

Epoch: 36| Step: 0
Training loss: 1.9230419397354126
Validation loss: 2.0860464162723993

Epoch: 6| Step: 1
Training loss: 2.1827712059020996
Validation loss: 2.0833023837817612

Epoch: 6| Step: 2
Training loss: 2.9850075244903564
Validation loss: 2.093097920058876

Epoch: 6| Step: 3
Training loss: 1.7407476902008057
Validation loss: 2.087927977244059

Epoch: 6| Step: 4
Training loss: 2.0149054527282715
Validation loss: 2.0940034966314993

Epoch: 6| Step: 5
Training loss: 2.5157361030578613
Validation loss: 2.0967808923413678

Epoch: 6| Step: 6
Training loss: 1.723691463470459
Validation loss: 2.0937987706994496

Epoch: 6| Step: 7
Training loss: 2.4399051666259766
Validation loss: 2.088635681777872

Epoch: 6| Step: 8
Training loss: 2.3102431297302246
Validation loss: 2.0878402186978247

Epoch: 6| Step: 9
Training loss: 2.1423099040985107
Validation loss: 2.1111131406599477

Epoch: 6| Step: 10
Training loss: 2.328333616256714
Validation loss: 2.1021121830068608

Epoch: 6| Step: 11
Training loss: 2.8810529708862305
Validation loss: 2.0896551916676183

Epoch: 6| Step: 12
Training loss: 2.9842371940612793
Validation loss: 2.0872207495474044

Epoch: 6| Step: 13
Training loss: 3.0981409549713135
Validation loss: 2.0961337820176156

Epoch: 37| Step: 0
Training loss: 2.085979461669922
Validation loss: 2.0965228747296076

Epoch: 6| Step: 1
Training loss: 2.6502442359924316
Validation loss: 2.094949660762664

Epoch: 6| Step: 2
Training loss: 2.9256253242492676
Validation loss: 2.08661296034372

Epoch: 6| Step: 3
Training loss: 2.230597972869873
Validation loss: 2.0880552850743777

Epoch: 6| Step: 4
Training loss: 1.5206761360168457
Validation loss: 2.0820428607284382

Epoch: 6| Step: 5
Training loss: 1.64402437210083
Validation loss: 2.0893875168215845

Epoch: 6| Step: 6
Training loss: 3.0448555946350098
Validation loss: 2.085769032919279

Epoch: 6| Step: 7
Training loss: 2.0414676666259766
Validation loss: 2.0760248476459133

Epoch: 6| Step: 8
Training loss: 2.2940170764923096
Validation loss: 2.0898218424089494

Epoch: 6| Step: 9
Training loss: 1.9717488288879395
Validation loss: 2.0884481886381745

Epoch: 6| Step: 10
Training loss: 2.0179593563079834
Validation loss: 2.0753411913430817

Epoch: 6| Step: 11
Training loss: 3.2371599674224854
Validation loss: 2.0930167013599026

Epoch: 6| Step: 12
Training loss: 2.5640816688537598
Validation loss: 2.085106216451173

Epoch: 6| Step: 13
Training loss: 2.6749229431152344
Validation loss: 2.0692776057028

Epoch: 38| Step: 0
Training loss: 2.9959867000579834
Validation loss: 2.0764376194246355

Epoch: 6| Step: 1
Training loss: 3.1008973121643066
Validation loss: 2.082151405272945

Epoch: 6| Step: 2
Training loss: 1.9905418157577515
Validation loss: 2.0839016552894347

Epoch: 6| Step: 3
Training loss: 1.6355624198913574
Validation loss: 2.088692024189939

Epoch: 6| Step: 4
Training loss: 1.7643263339996338
Validation loss: 2.097970243423216

Epoch: 6| Step: 5
Training loss: 2.101524829864502
Validation loss: 2.073699087224981

Epoch: 6| Step: 6
Training loss: 2.9817466735839844
Validation loss: 2.0852169118901736

Epoch: 6| Step: 7
Training loss: 1.5026865005493164
Validation loss: 2.0801169462101434

Epoch: 6| Step: 8
Training loss: 2.6285672187805176
Validation loss: 2.106906331995482

Epoch: 6| Step: 9
Training loss: 2.515120029449463
Validation loss: 2.0850086019885157

Epoch: 6| Step: 10
Training loss: 3.006086587905884
Validation loss: 2.0801721849749164

Epoch: 6| Step: 11
Training loss: 2.4676053524017334
Validation loss: 2.0900210090862807

Epoch: 6| Step: 12
Training loss: 2.2110633850097656
Validation loss: 2.088140570989219

Epoch: 6| Step: 13
Training loss: 1.4484162330627441
Validation loss: 2.1007798102594193

Epoch: 39| Step: 0
Training loss: 1.9682865142822266
Validation loss: 2.082239374037712

Epoch: 6| Step: 1
Training loss: 2.2157821655273438
Validation loss: 2.1050128680403515

Epoch: 6| Step: 2
Training loss: 2.157656669616699
Validation loss: 2.090123197083832

Epoch: 6| Step: 3
Training loss: 2.655879259109497
Validation loss: 2.085060745157221

Epoch: 6| Step: 4
Training loss: 2.6741342544555664
Validation loss: 2.09699857875865

Epoch: 6| Step: 5
Training loss: 1.7779313325881958
Validation loss: 2.0938984553019204

Epoch: 6| Step: 6
Training loss: 3.056190013885498
Validation loss: 2.0733548107967583

Epoch: 6| Step: 7
Training loss: 1.6760194301605225
Validation loss: 2.0770374498059674

Epoch: 6| Step: 8
Training loss: 2.7550222873687744
Validation loss: 2.087856774689049

Epoch: 6| Step: 9
Training loss: 2.33558988571167
Validation loss: 2.064891440894014

Epoch: 6| Step: 10
Training loss: 2.4891648292541504
Validation loss: 2.067092413543373

Epoch: 6| Step: 11
Training loss: 1.8200618028640747
Validation loss: 2.0740534977246354

Epoch: 6| Step: 12
Training loss: 2.3892245292663574
Validation loss: 2.08223315464553

Epoch: 6| Step: 13
Training loss: 3.0385379791259766
Validation loss: 2.0750885035402034

Epoch: 40| Step: 0
Training loss: 2.4691476821899414
Validation loss: 2.0674212030185166

Epoch: 6| Step: 1
Training loss: 2.343862771987915
Validation loss: 2.0741663017580585

Epoch: 6| Step: 2
Training loss: 1.6682298183441162
Validation loss: 2.0866578984004196

Epoch: 6| Step: 3
Training loss: 2.1072397232055664
Validation loss: 2.073612766881143

Epoch: 6| Step: 4
Training loss: 2.242445945739746
Validation loss: 2.0751349900358464

Epoch: 6| Step: 5
Training loss: 3.381922960281372
Validation loss: 2.094605653516708

Epoch: 6| Step: 6
Training loss: 2.082825183868408
Validation loss: 2.0804098434345697

Epoch: 6| Step: 7
Training loss: 1.8160041570663452
Validation loss: 2.0643299125855967

Epoch: 6| Step: 8
Training loss: 2.9053220748901367
Validation loss: 2.082056153205133

Epoch: 6| Step: 9
Training loss: 2.2338128089904785
Validation loss: 2.0906523043109524

Epoch: 6| Step: 10
Training loss: 2.2800469398498535
Validation loss: 2.0740030106677803

Epoch: 6| Step: 11
Training loss: 2.5332179069519043
Validation loss: 2.0789619902128815

Epoch: 6| Step: 12
Training loss: 2.017864465713501
Validation loss: 2.082078572242491

Epoch: 6| Step: 13
Training loss: 2.7172861099243164
Validation loss: 2.0813848997956965

Epoch: 41| Step: 0
Training loss: 2.3848981857299805
Validation loss: 2.0875420801101194

Epoch: 6| Step: 1
Training loss: 2.1325535774230957
Validation loss: 2.0931486301524664

Epoch: 6| Step: 2
Training loss: 1.7299668788909912
Validation loss: 2.0857774801151727

Epoch: 6| Step: 3
Training loss: 2.3561999797821045
Validation loss: 2.0932808973455943

Epoch: 6| Step: 4
Training loss: 1.8117315769195557
Validation loss: 2.0766854158011814

Epoch: 6| Step: 5
Training loss: 3.182919502258301
Validation loss: 2.080921680696549

Epoch: 6| Step: 6
Training loss: 3.437234878540039
Validation loss: 2.0804734999133694

Epoch: 6| Step: 7
Training loss: 1.706329345703125
Validation loss: 2.0647642330456804

Epoch: 6| Step: 8
Training loss: 1.864331603050232
Validation loss: 2.0712866270413963

Epoch: 6| Step: 9
Training loss: 3.0892395973205566
Validation loss: 2.0810329824365597

Epoch: 6| Step: 10
Training loss: 2.3089349269866943
Validation loss: 2.074534728962888

Epoch: 6| Step: 11
Training loss: 2.433497905731201
Validation loss: 2.0886576201326106

Epoch: 6| Step: 12
Training loss: 2.171236038208008
Validation loss: 2.0885410180655857

Epoch: 6| Step: 13
Training loss: 1.4655930995941162
Validation loss: 2.0835308541533766

Epoch: 42| Step: 0
Training loss: 2.118765354156494
Validation loss: 2.0744904446345505

Epoch: 6| Step: 1
Training loss: 2.680267333984375
Validation loss: 2.069941456599902

Epoch: 6| Step: 2
Training loss: 2.305943250656128
Validation loss: 2.06874781270181

Epoch: 6| Step: 3
Training loss: 2.4393177032470703
Validation loss: 2.0870002469708844

Epoch: 6| Step: 4
Training loss: 2.64522647857666
Validation loss: 2.0832554089125765

Epoch: 6| Step: 5
Training loss: 1.9585869312286377
Validation loss: 2.0844966365445043

Epoch: 6| Step: 6
Training loss: 2.304992198944092
Validation loss: 2.0934246022214174

Epoch: 6| Step: 7
Training loss: 2.5287718772888184
Validation loss: 2.091924775031305

Epoch: 6| Step: 8
Training loss: 2.3319451808929443
Validation loss: 2.06673361152731

Epoch: 6| Step: 9
Training loss: 2.1278319358825684
Validation loss: 2.082256386356969

Epoch: 6| Step: 10
Training loss: 1.7481070756912231
Validation loss: 2.0913304564773396

Epoch: 6| Step: 11
Training loss: 2.336453914642334
Validation loss: 2.085357906997845

Epoch: 6| Step: 12
Training loss: 2.5887842178344727
Validation loss: 2.073069259684573

Epoch: 6| Step: 13
Training loss: 2.050818920135498
Validation loss: 2.0767673946196035

Epoch: 43| Step: 0
Training loss: 1.8203015327453613
Validation loss: 2.0863463083902993

Epoch: 6| Step: 1
Training loss: 2.351902723312378
Validation loss: 2.08580772594739

Epoch: 6| Step: 2
Training loss: 3.40091609954834
Validation loss: 2.0762690779983357

Epoch: 6| Step: 3
Training loss: 2.055518627166748
Validation loss: 2.0795984422006915

Epoch: 6| Step: 4
Training loss: 2.634028673171997
Validation loss: 2.0638981250024613

Epoch: 6| Step: 5
Training loss: 2.0308585166931152
Validation loss: 2.094619366430467

Epoch: 6| Step: 6
Training loss: 2.681440591812134
Validation loss: 2.0738885864134757

Epoch: 6| Step: 7
Training loss: 2.1917264461517334
Validation loss: 2.0898869563174505

Epoch: 6| Step: 8
Training loss: 2.1248152256011963
Validation loss: 2.086311181386312

Epoch: 6| Step: 9
Training loss: 2.791353464126587
Validation loss: 2.0645765886511853

Epoch: 6| Step: 10
Training loss: 2.1474392414093018
Validation loss: 2.0829146805629937

Epoch: 6| Step: 11
Training loss: 1.887426495552063
Validation loss: 2.0777280471658193

Epoch: 6| Step: 12
Training loss: 1.9667516946792603
Validation loss: 2.0808628989804174

Epoch: 6| Step: 13
Training loss: 2.181605339050293
Validation loss: 2.0749140631768013

Epoch: 44| Step: 0
Training loss: 2.5058774948120117
Validation loss: 2.0770088780310845

Epoch: 6| Step: 1
Training loss: 2.3909037113189697
Validation loss: 2.067043688989455

Epoch: 6| Step: 2
Training loss: 1.893760085105896
Validation loss: 2.0730134646097818

Epoch: 6| Step: 3
Training loss: 1.6507786512374878
Validation loss: 2.0741555331855692

Epoch: 6| Step: 4
Training loss: 2.6470911502838135
Validation loss: 2.088188473896314

Epoch: 6| Step: 5
Training loss: 2.2643375396728516
Validation loss: 2.089963343835646

Epoch: 6| Step: 6
Training loss: 2.3914012908935547
Validation loss: 2.0712445089893956

Epoch: 6| Step: 7
Training loss: 2.24040150642395
Validation loss: 2.076243592846778

Epoch: 6| Step: 8
Training loss: 2.524867534637451
Validation loss: 2.073984379409462

Epoch: 6| Step: 9
Training loss: 2.0372908115386963
Validation loss: 2.068585776513623

Epoch: 6| Step: 10
Training loss: 3.007946491241455
Validation loss: 2.056747155804788

Epoch: 6| Step: 11
Training loss: 2.15932035446167
Validation loss: 2.091398624963658

Epoch: 6| Step: 12
Training loss: 2.6221001148223877
Validation loss: 2.077875519311556

Epoch: 6| Step: 13
Training loss: 1.8123278617858887
Validation loss: 2.091846558355516

Epoch: 45| Step: 0
Training loss: 2.367995500564575
Validation loss: 2.0669713763780493

Epoch: 6| Step: 1
Training loss: 2.5239875316619873
Validation loss: 2.064860982279624

Epoch: 6| Step: 2
Training loss: 2.5316929817199707
Validation loss: 2.0795944275394564

Epoch: 6| Step: 3
Training loss: 2.2290408611297607
Validation loss: 2.0911046458828833

Epoch: 6| Step: 4
Training loss: 2.390896797180176
Validation loss: 2.075899193363805

Epoch: 6| Step: 5
Training loss: 2.240865468978882
Validation loss: 2.087118924305003

Epoch: 6| Step: 6
Training loss: 2.7561028003692627
Validation loss: 2.084851634117865

Epoch: 6| Step: 7
Training loss: 1.705298900604248
Validation loss: 2.075364519191045

Epoch: 6| Step: 8
Training loss: 2.198850631713867
Validation loss: 2.073887389193299

Epoch: 6| Step: 9
Training loss: 2.097846269607544
Validation loss: 2.085207723802136

Epoch: 6| Step: 10
Training loss: 2.2285237312316895
Validation loss: 2.0881127670247066

Epoch: 6| Step: 11
Training loss: 2.840780735015869
Validation loss: 2.086005167294574

Epoch: 6| Step: 12
Training loss: 1.8848943710327148
Validation loss: 2.06227211670209

Epoch: 6| Step: 13
Training loss: 2.220501184463501
Validation loss: 2.0932569811421056

Epoch: 46| Step: 0
Training loss: 2.5348734855651855
Validation loss: 2.068989505050003

Epoch: 6| Step: 1
Training loss: 2.947838068008423
Validation loss: 2.0887515980710267

Epoch: 6| Step: 2
Training loss: 1.806390643119812
Validation loss: 2.0864272745706702

Epoch: 6| Step: 3
Training loss: 1.9421058893203735
Validation loss: 2.0931488929256314

Epoch: 6| Step: 4
Training loss: 1.6326026916503906
Validation loss: 2.0844877048205306

Epoch: 6| Step: 5
Training loss: 2.629051446914673
Validation loss: 2.0967227015444028

Epoch: 6| Step: 6
Training loss: 2.8645918369293213
Validation loss: 2.074255253679009

Epoch: 6| Step: 7
Training loss: 2.028031826019287
Validation loss: 2.0839609753700996

Epoch: 6| Step: 8
Training loss: 1.6840084791183472
Validation loss: 2.077193731902748

Epoch: 6| Step: 9
Training loss: 2.7021210193634033
Validation loss: 2.0884139255810807

Epoch: 6| Step: 10
Training loss: 2.578367233276367
Validation loss: 2.0589725791767077

Epoch: 6| Step: 11
Training loss: 2.2075138092041016
Validation loss: 2.0773898247749574

Epoch: 6| Step: 12
Training loss: 2.419045925140381
Validation loss: 2.090735653395294

Epoch: 6| Step: 13
Training loss: 2.1412980556488037
Validation loss: 2.059415514751147

Epoch: 47| Step: 0
Training loss: 2.5180182456970215
Validation loss: 2.067350936192338

Epoch: 6| Step: 1
Training loss: 2.5094094276428223
Validation loss: 2.0659063208487725

Epoch: 6| Step: 2
Training loss: 2.7945351600646973
Validation loss: 2.0879219437158234

Epoch: 6| Step: 3
Training loss: 1.9159451723098755
Validation loss: 2.0743406729031633

Epoch: 6| Step: 4
Training loss: 2.234788417816162
Validation loss: 2.0718673531727125

Epoch: 6| Step: 5
Training loss: 2.9620139598846436
Validation loss: 2.068320602499029

Epoch: 6| Step: 6
Training loss: 2.049424886703491
Validation loss: 2.0888053999152234

Epoch: 6| Step: 7
Training loss: 2.6566879749298096
Validation loss: 2.076265158191804

Epoch: 6| Step: 8
Training loss: 2.6272854804992676
Validation loss: 2.075413730836684

Epoch: 6| Step: 9
Training loss: 1.4644715785980225
Validation loss: 2.091466029485067

Epoch: 6| Step: 10
Training loss: 1.8533997535705566
Validation loss: 2.0815085031652965

Epoch: 6| Step: 11
Training loss: 1.8652433156967163
Validation loss: 2.0833113014057116

Epoch: 6| Step: 12
Training loss: 2.4923651218414307
Validation loss: 2.08297550037343

Epoch: 6| Step: 13
Training loss: 1.9176496267318726
Validation loss: 2.0682469080853205

Epoch: 48| Step: 0
Training loss: 2.506509780883789
Validation loss: 2.081112059213782

Epoch: 6| Step: 1
Training loss: 2.535721778869629
Validation loss: 2.08726772698023

Epoch: 6| Step: 2
Training loss: 1.8946542739868164
Validation loss: 2.081884382873453

Epoch: 6| Step: 3
Training loss: 2.2151551246643066
Validation loss: 2.0728575644954557

Epoch: 6| Step: 4
Training loss: 2.019716262817383
Validation loss: 2.0885675568734445

Epoch: 6| Step: 5
Training loss: 2.128657817840576
Validation loss: 2.0908463949798257

Epoch: 6| Step: 6
Training loss: 2.4337778091430664
Validation loss: 2.0777635189794723

Epoch: 6| Step: 7
Training loss: 2.1148390769958496
Validation loss: 2.0866164802223124

Epoch: 6| Step: 8
Training loss: 2.4335532188415527
Validation loss: 2.0910912944424536

Epoch: 6| Step: 9
Training loss: 2.2821779251098633
Validation loss: 2.088945516975977

Epoch: 6| Step: 10
Training loss: 2.1107845306396484
Validation loss: 2.0835786122147755

Epoch: 6| Step: 11
Training loss: 2.3212602138519287
Validation loss: 2.090147165841954

Epoch: 6| Step: 12
Training loss: 2.3652758598327637
Validation loss: 2.0554361292110976

Epoch: 6| Step: 13
Training loss: 2.630385398864746
Validation loss: 2.0812771627979894

Epoch: 49| Step: 0
Training loss: 2.4967145919799805
Validation loss: 2.086668696454776

Epoch: 6| Step: 1
Training loss: 2.229674816131592
Validation loss: 2.082905674493441

Epoch: 6| Step: 2
Training loss: 2.3318443298339844
Validation loss: 2.073299824550588

Epoch: 6| Step: 3
Training loss: 1.8044400215148926
Validation loss: 2.0795735184864332

Epoch: 6| Step: 4
Training loss: 2.9025373458862305
Validation loss: 2.0686642841626237

Epoch: 6| Step: 5
Training loss: 2.482651472091675
Validation loss: 2.093987044467721

Epoch: 6| Step: 6
Training loss: 1.8138782978057861
Validation loss: 2.0882110646975938

Epoch: 6| Step: 7
Training loss: 2.289350986480713
Validation loss: 2.090798283136019

Epoch: 6| Step: 8
Training loss: 2.6282761096954346
Validation loss: 2.0886519685868294

Epoch: 6| Step: 9
Training loss: 2.278505325317383
Validation loss: 2.090836806963849

Epoch: 6| Step: 10
Training loss: 1.748899221420288
Validation loss: 2.1071750040977233

Epoch: 6| Step: 11
Training loss: 2.169370174407959
Validation loss: 2.071719063225613

Epoch: 6| Step: 12
Training loss: 2.2314701080322266
Validation loss: 2.0851450658613637

Epoch: 6| Step: 13
Training loss: 2.7195844650268555
Validation loss: 2.107925940585393

Epoch: 50| Step: 0
Training loss: 1.8681050539016724
Validation loss: 2.0740292520933252

Epoch: 6| Step: 1
Training loss: 2.194303035736084
Validation loss: 2.0760478409387733

Epoch: 6| Step: 2
Training loss: 2.490924835205078
Validation loss: 2.0815384131605907

Epoch: 6| Step: 3
Training loss: 1.8839969635009766
Validation loss: 2.0830889606988556

Epoch: 6| Step: 4
Training loss: 2.556894302368164
Validation loss: 2.08903399590523

Epoch: 6| Step: 5
Training loss: 1.9907394647598267
Validation loss: 2.0877957138963925

Epoch: 6| Step: 6
Training loss: 2.2368102073669434
Validation loss: 2.0819404689214562

Epoch: 6| Step: 7
Training loss: 2.1981611251831055
Validation loss: 2.0875815512031637

Epoch: 6| Step: 8
Training loss: 2.262291431427002
Validation loss: 2.0665834026951946

Epoch: 6| Step: 9
Training loss: 1.978905439376831
Validation loss: 2.076607240143643

Epoch: 6| Step: 10
Training loss: 1.9605129957199097
Validation loss: 2.0861899442570184

Epoch: 6| Step: 11
Training loss: 2.8590784072875977
Validation loss: 2.1013976655980593

Epoch: 6| Step: 12
Training loss: 2.6247782707214355
Validation loss: 2.0819547701907415

Epoch: 6| Step: 13
Training loss: 3.3739824295043945
Validation loss: 2.0902086842444634

Epoch: 51| Step: 0
Training loss: 1.9955955743789673
Validation loss: 2.078910522563483

Epoch: 6| Step: 1
Training loss: 2.3065130710601807
Validation loss: 2.084768279906242

Epoch: 6| Step: 2
Training loss: 2.050447702407837
Validation loss: 2.0653840175238987

Epoch: 6| Step: 3
Training loss: 2.140239953994751
Validation loss: 2.0850390823938514

Epoch: 6| Step: 4
Training loss: 3.130375862121582
Validation loss: 2.0620323060661234

Epoch: 6| Step: 5
Training loss: 3.020914316177368
Validation loss: 2.080363145438574

Epoch: 6| Step: 6
Training loss: 2.31099271774292
Validation loss: 2.081914130077567

Epoch: 6| Step: 7
Training loss: 1.9361802339553833
Validation loss: 2.0815462861009824

Epoch: 6| Step: 8
Training loss: 1.349792242050171
Validation loss: 2.075953504090668

Epoch: 6| Step: 9
Training loss: 3.0561580657958984
Validation loss: 2.083051621273

Epoch: 6| Step: 10
Training loss: 1.8462125062942505
Validation loss: 2.0873004979984735

Epoch: 6| Step: 11
Training loss: 1.5952045917510986
Validation loss: 2.066194362537835

Epoch: 6| Step: 12
Training loss: 2.717988967895508
Validation loss: 2.081015581725746

Epoch: 6| Step: 13
Training loss: 2.3924009799957275
Validation loss: 2.079658777483048

Epoch: 52| Step: 0
Training loss: 1.9475256204605103
Validation loss: 2.080818277533336

Epoch: 6| Step: 1
Training loss: 2.9700300693511963
Validation loss: 2.0633787032096618

Epoch: 6| Step: 2
Training loss: 2.5041496753692627
Validation loss: 2.075983717877378

Epoch: 6| Step: 3
Training loss: 1.9402557611465454
Validation loss: 2.069768762075773

Epoch: 6| Step: 4
Training loss: 1.7638049125671387
Validation loss: 2.0820407482885543

Epoch: 6| Step: 5
Training loss: 2.428873062133789
Validation loss: 2.067456196713191

Epoch: 6| Step: 6
Training loss: 2.4235901832580566
Validation loss: 2.0620307794181247

Epoch: 6| Step: 7
Training loss: 2.442811965942383
Validation loss: 2.086759892843103

Epoch: 6| Step: 8
Training loss: 1.9931094646453857
Validation loss: 2.082304390527869

Epoch: 6| Step: 9
Training loss: 1.4629597663879395
Validation loss: 2.091012124092348

Epoch: 6| Step: 10
Training loss: 2.756538152694702
Validation loss: 2.0653295491331365

Epoch: 6| Step: 11
Training loss: 2.6443979740142822
Validation loss: 2.07057031636597

Epoch: 6| Step: 12
Training loss: 2.072540283203125
Validation loss: 2.063031636258607

Epoch: 6| Step: 13
Training loss: 2.386155843734741
Validation loss: 2.0828825491730885

Epoch: 53| Step: 0
Training loss: 2.4496350288391113
Validation loss: 2.07319006740406

Epoch: 6| Step: 1
Training loss: 2.9132509231567383
Validation loss: 2.0823545455932617

Epoch: 6| Step: 2
Training loss: 2.0291996002197266
Validation loss: 2.069063586573447

Epoch: 6| Step: 3
Training loss: 2.4049434661865234
Validation loss: 2.105499928997409

Epoch: 6| Step: 4
Training loss: 1.8814475536346436
Validation loss: 2.064036524423989

Epoch: 6| Step: 5
Training loss: 2.2917895317077637
Validation loss: 2.077562011698241

Epoch: 6| Step: 6
Training loss: 1.951662540435791
Validation loss: 2.070466297929005

Epoch: 6| Step: 7
Training loss: 2.8971381187438965
Validation loss: 2.0869263654114096

Epoch: 6| Step: 8
Training loss: 2.0223498344421387
Validation loss: 2.079453295277011

Epoch: 6| Step: 9
Training loss: 2.2751965522766113
Validation loss: 2.063807277269261

Epoch: 6| Step: 10
Training loss: 2.1834702491760254
Validation loss: 2.0619337263927666

Epoch: 6| Step: 11
Training loss: 2.215894937515259
Validation loss: 2.0733702772407123

Epoch: 6| Step: 12
Training loss: 2.136183738708496
Validation loss: 2.0868127653675694

Epoch: 6| Step: 13
Training loss: 2.3124542236328125
Validation loss: 2.076453995961015

Epoch: 54| Step: 0
Training loss: 2.034395217895508
Validation loss: 2.0632508339420443

Epoch: 6| Step: 1
Training loss: 1.6732568740844727
Validation loss: 2.0852704919794554

Epoch: 6| Step: 2
Training loss: 2.3576478958129883
Validation loss: 2.0910565571118425

Epoch: 6| Step: 3
Training loss: 2.3509621620178223
Validation loss: 2.072591067642294

Epoch: 6| Step: 4
Training loss: 3.3141415119171143
Validation loss: 2.08584616902054

Epoch: 6| Step: 5
Training loss: 2.776972770690918
Validation loss: 2.0753500294941727

Epoch: 6| Step: 6
Training loss: 2.5952749252319336
Validation loss: 2.0764006196811633

Epoch: 6| Step: 7
Training loss: 2.4726696014404297
Validation loss: 2.0715893442912767

Epoch: 6| Step: 8
Training loss: 1.8854928016662598
Validation loss: 2.0794032260935795

Epoch: 6| Step: 9
Training loss: 2.377638578414917
Validation loss: 2.0601546982283234

Epoch: 6| Step: 10
Training loss: 1.8505308628082275
Validation loss: 2.0818410381194083

Epoch: 6| Step: 11
Training loss: 1.7148847579956055
Validation loss: 2.0738476245634017

Epoch: 6| Step: 12
Training loss: 2.079998731613159
Validation loss: 2.06793112139548

Epoch: 6| Step: 13
Training loss: 2.3321914672851562
Validation loss: 2.078716306276219

Epoch: 55| Step: 0
Training loss: 2.678570508956909
Validation loss: 2.0797102938416185

Epoch: 6| Step: 1
Training loss: 2.512559413909912
Validation loss: 2.079376418103454

Epoch: 6| Step: 2
Training loss: 2.2891101837158203
Validation loss: 2.090271463958166

Epoch: 6| Step: 3
Training loss: 2.252633810043335
Validation loss: 2.084775232499646

Epoch: 6| Step: 4
Training loss: 2.55501651763916
Validation loss: 2.0871317386627197

Epoch: 6| Step: 5
Training loss: 2.0127813816070557
Validation loss: 2.105296891222718

Epoch: 6| Step: 6
Training loss: 3.287329912185669
Validation loss: 2.0904912538425897

Epoch: 6| Step: 7
Training loss: 1.7327327728271484
Validation loss: 2.0754923256494666

Epoch: 6| Step: 8
Training loss: 1.7125985622406006
Validation loss: 2.0780353328233123

Epoch: 6| Step: 9
Training loss: 2.4145400524139404
Validation loss: 2.1058451719181512

Epoch: 6| Step: 10
Training loss: 2.041569471359253
Validation loss: 2.112646115723477

Epoch: 6| Step: 11
Training loss: 1.8460004329681396
Validation loss: 2.10526458678707

Epoch: 6| Step: 12
Training loss: 2.542861223220825
Validation loss: 2.087388269362911

Epoch: 6| Step: 13
Training loss: 1.65096914768219
Validation loss: 2.075658402135295

Epoch: 56| Step: 0
Training loss: 2.365907669067383
Validation loss: 2.1011697784546883

Epoch: 6| Step: 1
Training loss: 2.651516914367676
Validation loss: 2.0977193411960395

Epoch: 6| Step: 2
Training loss: 1.9939239025115967
Validation loss: 2.0945389578419347

Epoch: 6| Step: 3
Training loss: 2.953092098236084
Validation loss: 2.098215836350636

Epoch: 6| Step: 4
Training loss: 2.753777265548706
Validation loss: 2.075262713175948

Epoch: 6| Step: 5
Training loss: 2.1262354850769043
Validation loss: 2.092238180098995

Epoch: 6| Step: 6
Training loss: 1.7170454263687134
Validation loss: 2.103617086205431

Epoch: 6| Step: 7
Training loss: 2.076448917388916
Validation loss: 2.09047189066487

Epoch: 6| Step: 8
Training loss: 1.6256511211395264
Validation loss: 2.0951791476177912

Epoch: 6| Step: 9
Training loss: 2.56486177444458
Validation loss: 2.083011546442586

Epoch: 6| Step: 10
Training loss: 2.167184829711914
Validation loss: 2.089581202435237

Epoch: 6| Step: 11
Training loss: 2.33469557762146
Validation loss: 2.0863463776085966

Epoch: 6| Step: 12
Training loss: 2.0178799629211426
Validation loss: 2.0867334437626663

Epoch: 6| Step: 13
Training loss: 2.36505126953125
Validation loss: 2.0878432950665875

Epoch: 57| Step: 0
Training loss: 2.688833713531494
Validation loss: 2.084031052486871

Epoch: 6| Step: 1
Training loss: 2.3920226097106934
Validation loss: 2.1011486886650004

Epoch: 6| Step: 2
Training loss: 1.8893656730651855
Validation loss: 2.0779954566750476

Epoch: 6| Step: 3
Training loss: 2.1013240814208984
Validation loss: 2.0918591817220054

Epoch: 6| Step: 4
Training loss: 2.217911720275879
Validation loss: 2.0697826595716577

Epoch: 6| Step: 5
Training loss: 1.8859376907348633
Validation loss: 2.0637237871846845

Epoch: 6| Step: 6
Training loss: 2.1022591590881348
Validation loss: 2.0856418148163827

Epoch: 6| Step: 7
Training loss: 1.9044164419174194
Validation loss: 2.0822229564830823

Epoch: 6| Step: 8
Training loss: 2.0859286785125732
Validation loss: 2.0744748448812835

Epoch: 6| Step: 9
Training loss: 2.7376327514648438
Validation loss: 2.0737257554966915

Epoch: 6| Step: 10
Training loss: 3.1720728874206543
Validation loss: 2.0667367378870645

Epoch: 6| Step: 11
Training loss: 2.3161802291870117
Validation loss: 2.0745363209837224

Epoch: 6| Step: 12
Training loss: 1.9044508934020996
Validation loss: 2.0667357214035524

Epoch: 6| Step: 13
Training loss: 2.5522003173828125
Validation loss: 2.075618528550671

Epoch: 58| Step: 0
Training loss: 2.236963987350464
Validation loss: 2.0874555303204443

Epoch: 6| Step: 1
Training loss: 1.9563853740692139
Validation loss: 2.07161707006475

Epoch: 6| Step: 2
Training loss: 2.6695430278778076
Validation loss: 2.0644008459583407

Epoch: 6| Step: 3
Training loss: 2.1357274055480957
Validation loss: 2.080724129112818

Epoch: 6| Step: 4
Training loss: 1.87656569480896
Validation loss: 2.0718659303521596

Epoch: 6| Step: 5
Training loss: 1.5634191036224365
Validation loss: 2.084077819701164

Epoch: 6| Step: 6
Training loss: 2.460684299468994
Validation loss: 2.089321881212214

Epoch: 6| Step: 7
Training loss: 2.635165214538574
Validation loss: 2.0734597534261723

Epoch: 6| Step: 8
Training loss: 2.113267421722412
Validation loss: 2.085000750839069

Epoch: 6| Step: 9
Training loss: 3.0696749687194824
Validation loss: 2.072733571452479

Epoch: 6| Step: 10
Training loss: 2.730900764465332
Validation loss: 2.0897160345508206

Epoch: 6| Step: 11
Training loss: 1.9181268215179443
Validation loss: 2.096304544838526

Epoch: 6| Step: 12
Training loss: 2.3640880584716797
Validation loss: 2.085025002879481

Epoch: 6| Step: 13
Training loss: 1.7667680978775024
Validation loss: 2.0944054331830753

Epoch: 59| Step: 0
Training loss: 1.8536114692687988
Validation loss: 2.0791507036455217

Epoch: 6| Step: 1
Training loss: 1.9340825080871582
Validation loss: 2.078370837755101

Epoch: 6| Step: 2
Training loss: 1.927470326423645
Validation loss: 2.074658654069388

Epoch: 6| Step: 3
Training loss: 2.091841697692871
Validation loss: 2.0914724667867026

Epoch: 6| Step: 4
Training loss: 2.5667624473571777
Validation loss: 2.0676507167918707

Epoch: 6| Step: 5
Training loss: 1.695041537284851
Validation loss: 2.06457975346555

Epoch: 6| Step: 6
Training loss: 2.0016298294067383
Validation loss: 2.0648291457083916

Epoch: 6| Step: 7
Training loss: 2.389418601989746
Validation loss: 2.070999042962187

Epoch: 6| Step: 8
Training loss: 1.9450831413269043
Validation loss: 2.0802510707609114

Epoch: 6| Step: 9
Training loss: 2.669020891189575
Validation loss: 2.0789040057889876

Epoch: 6| Step: 10
Training loss: 2.6954760551452637
Validation loss: 2.077275353093301

Epoch: 6| Step: 11
Training loss: 2.8155689239501953
Validation loss: 2.0856564326952864

Epoch: 6| Step: 12
Training loss: 2.200023651123047
Validation loss: 2.080042467322401

Epoch: 6| Step: 13
Training loss: 2.9338040351867676
Validation loss: 2.11012170391698

Epoch: 60| Step: 0
Training loss: 2.6273303031921387
Validation loss: 2.0638722168501986

Epoch: 6| Step: 1
Training loss: 2.2072389125823975
Validation loss: 2.0698062578837075

Epoch: 6| Step: 2
Training loss: 2.251030921936035
Validation loss: 2.0834989035001366

Epoch: 6| Step: 3
Training loss: 1.725865364074707
Validation loss: 2.0752990220182683

Epoch: 6| Step: 4
Training loss: 1.9559077024459839
Validation loss: 2.080647844140248

Epoch: 6| Step: 5
Training loss: 2.722580909729004
Validation loss: 2.086004844275854

Epoch: 6| Step: 6
Training loss: 2.449380397796631
Validation loss: 2.080369782704179

Epoch: 6| Step: 7
Training loss: 1.9163897037506104
Validation loss: 2.0848925446951263

Epoch: 6| Step: 8
Training loss: 1.5594244003295898
Validation loss: 2.0939825247692805

Epoch: 6| Step: 9
Training loss: 2.6423442363739014
Validation loss: 2.0893349109157437

Epoch: 6| Step: 10
Training loss: 2.2814884185791016
Validation loss: 2.0973738393475934

Epoch: 6| Step: 11
Training loss: 2.228330135345459
Validation loss: 2.0938552746208767

Epoch: 6| Step: 12
Training loss: 2.5083365440368652
Validation loss: 2.087432838255359

Epoch: 6| Step: 13
Training loss: 2.549891233444214
Validation loss: 2.0780881476658646

Epoch: 61| Step: 0
Training loss: 2.157656192779541
Validation loss: 2.0765553418026177

Epoch: 6| Step: 1
Training loss: 2.425286293029785
Validation loss: 2.0984900254075245

Epoch: 6| Step: 2
Training loss: 2.3119523525238037
Validation loss: 2.0753059233388593

Epoch: 6| Step: 3
Training loss: 1.5039037466049194
Validation loss: 2.0937377509250434

Epoch: 6| Step: 4
Training loss: 3.08203125
Validation loss: 2.073809605772777

Epoch: 6| Step: 5
Training loss: 2.782743453979492
Validation loss: 2.106846223595322

Epoch: 6| Step: 6
Training loss: 1.5967497825622559
Validation loss: 2.082065318220405

Epoch: 6| Step: 7
Training loss: 2.5541915893554688
Validation loss: 2.087475863836145

Epoch: 6| Step: 8
Training loss: 1.829895257949829
Validation loss: 2.084380672823998

Epoch: 6| Step: 9
Training loss: 2.1672003269195557
Validation loss: 2.0969782695975354

Epoch: 6| Step: 10
Training loss: 1.9594112634658813
Validation loss: 2.0935110815109743

Epoch: 6| Step: 11
Training loss: 2.4885411262512207
Validation loss: 2.0869017980431996

Epoch: 6| Step: 12
Training loss: 2.2959346771240234
Validation loss: 2.07545445939546

Epoch: 6| Step: 13
Training loss: 2.4679229259490967
Validation loss: 2.077053136723016

Epoch: 62| Step: 0
Training loss: 2.0051584243774414
Validation loss: 2.0932801846534974

Epoch: 6| Step: 1
Training loss: 2.661315441131592
Validation loss: 2.07619781391595

Epoch: 6| Step: 2
Training loss: 1.5891385078430176
Validation loss: 2.0864316571143364

Epoch: 6| Step: 3
Training loss: 2.8381271362304688
Validation loss: 2.0908960373170915

Epoch: 6| Step: 4
Training loss: 1.569317102432251
Validation loss: 2.0884085086084183

Epoch: 6| Step: 5
Training loss: 2.214332103729248
Validation loss: 2.097377828372422

Epoch: 6| Step: 6
Training loss: 2.499239444732666
Validation loss: 2.094558297946889

Epoch: 6| Step: 7
Training loss: 2.0446038246154785
Validation loss: 2.0768630299516904

Epoch: 6| Step: 8
Training loss: 2.8370308876037598
Validation loss: 2.0861015242914998

Epoch: 6| Step: 9
Training loss: 2.270667314529419
Validation loss: 2.0854158914217384

Epoch: 6| Step: 10
Training loss: 2.0929155349731445
Validation loss: 2.0827183441449235

Epoch: 6| Step: 11
Training loss: 2.55487322807312
Validation loss: 2.1052184310010684

Epoch: 6| Step: 12
Training loss: 1.8683120012283325
Validation loss: 2.1033277460323867

Epoch: 6| Step: 13
Training loss: 2.5359115600585938
Validation loss: 2.0732912645545056

Epoch: 63| Step: 0
Training loss: 2.2506909370422363
Validation loss: 2.0867435047703404

Epoch: 6| Step: 1
Training loss: 2.2610392570495605
Validation loss: 2.0759033900435253

Epoch: 6| Step: 2
Training loss: 2.3502395153045654
Validation loss: 2.0854493700047976

Epoch: 6| Step: 3
Training loss: 2.4258594512939453
Validation loss: 2.078481467821265

Epoch: 6| Step: 4
Training loss: 2.289247512817383
Validation loss: 2.076671637514586

Epoch: 6| Step: 5
Training loss: 2.2143423557281494
Validation loss: 2.087957138656288

Epoch: 6| Step: 6
Training loss: 2.9370017051696777
Validation loss: 2.107821200483589

Epoch: 6| Step: 7
Training loss: 2.038113594055176
Validation loss: 2.0946558534458117

Epoch: 6| Step: 8
Training loss: 1.6664454936981201
Validation loss: 2.0925601707991732

Epoch: 6| Step: 9
Training loss: 1.7901678085327148
Validation loss: 2.096712232917868

Epoch: 6| Step: 10
Training loss: 2.279573440551758
Validation loss: 2.0799575851809595

Epoch: 6| Step: 11
Training loss: 2.2961273193359375
Validation loss: 2.066639760489105

Epoch: 6| Step: 12
Training loss: 1.9995369911193848
Validation loss: 2.0729087885989936

Epoch: 6| Step: 13
Training loss: 2.870120048522949
Validation loss: 2.0845052939589306

Epoch: 64| Step: 0
Training loss: 2.2660255432128906
Validation loss: 2.08956999932566

Epoch: 6| Step: 1
Training loss: 2.7463455200195312
Validation loss: 2.0788800870218584

Epoch: 6| Step: 2
Training loss: 2.0452256202697754
Validation loss: 2.0921832951166297

Epoch: 6| Step: 3
Training loss: 2.160590171813965
Validation loss: 2.097401163911307

Epoch: 6| Step: 4
Training loss: 2.280280113220215
Validation loss: 2.085608437497129

Epoch: 6| Step: 5
Training loss: 2.426401376724243
Validation loss: 2.090130836732926

Epoch: 6| Step: 6
Training loss: 2.6963887214660645
Validation loss: 2.0915282541705715

Epoch: 6| Step: 7
Training loss: 2.0741517543792725
Validation loss: 2.0914002618482037

Epoch: 6| Step: 8
Training loss: 1.5687594413757324
Validation loss: 2.08554809324203

Epoch: 6| Step: 9
Training loss: 2.1173336505889893
Validation loss: 2.0965147531160744

Epoch: 6| Step: 10
Training loss: 1.6432240009307861
Validation loss: 2.0996173081859464

Epoch: 6| Step: 11
Training loss: 2.4555113315582275
Validation loss: 2.0966870451486237

Epoch: 6| Step: 12
Training loss: 2.526780366897583
Validation loss: 2.081236384248221

Epoch: 6| Step: 13
Training loss: 2.502030372619629
Validation loss: 2.059803478179439

Epoch: 65| Step: 0
Training loss: 2.2856857776641846
Validation loss: 2.1028229087911625

Epoch: 6| Step: 1
Training loss: 1.8500936031341553
Validation loss: 2.087274024563451

Epoch: 6| Step: 2
Training loss: 3.048722982406616
Validation loss: 2.0927320629037838

Epoch: 6| Step: 3
Training loss: 1.8322858810424805
Validation loss: 2.0780251385063253

Epoch: 6| Step: 4
Training loss: 2.3814444541931152
Validation loss: 2.068274330067378

Epoch: 6| Step: 5
Training loss: 1.9557037353515625
Validation loss: 2.0795565446217856

Epoch: 6| Step: 6
Training loss: 1.7137556076049805
Validation loss: 2.094512580543436

Epoch: 6| Step: 7
Training loss: 2.2785940170288086
Validation loss: 2.070301737836612

Epoch: 6| Step: 8
Training loss: 2.0884416103363037
Validation loss: 2.085043189346149

Epoch: 6| Step: 9
Training loss: 1.7301115989685059
Validation loss: 2.081090659223577

Epoch: 6| Step: 10
Training loss: 2.230363607406616
Validation loss: 2.064331569979268

Epoch: 6| Step: 11
Training loss: 2.6527740955352783
Validation loss: 2.0837153414244294

Epoch: 6| Step: 12
Training loss: 2.9587509632110596
Validation loss: 2.079756672664355

Epoch: 6| Step: 13
Training loss: 2.6518819332122803
Validation loss: 2.0691496761896278

Epoch: 66| Step: 0
Training loss: 1.9604620933532715
Validation loss: 2.0746095026693037

Epoch: 6| Step: 1
Training loss: 2.0799918174743652
Validation loss: 2.078274647394816

Epoch: 6| Step: 2
Training loss: 1.2933015823364258
Validation loss: 2.0601445039113364

Epoch: 6| Step: 3
Training loss: 2.611276865005493
Validation loss: 2.0988061992071008

Epoch: 6| Step: 4
Training loss: 2.5196573734283447
Validation loss: 2.088688124892532

Epoch: 6| Step: 5
Training loss: 2.5031208992004395
Validation loss: 2.0804044482528523

Epoch: 6| Step: 6
Training loss: 2.984387159347534
Validation loss: 2.0723172695406022

Epoch: 6| Step: 7
Training loss: 2.7674560546875
Validation loss: 2.0798186409857964

Epoch: 6| Step: 8
Training loss: 1.4724469184875488
Validation loss: 2.084208793537591

Epoch: 6| Step: 9
Training loss: 3.187861442565918
Validation loss: 2.0744764343384774

Epoch: 6| Step: 10
Training loss: 1.4855351448059082
Validation loss: 2.0884883813960577

Epoch: 6| Step: 11
Training loss: 1.9663124084472656
Validation loss: 2.078961564648536

Epoch: 6| Step: 12
Training loss: 2.437142848968506
Validation loss: 2.06444913084789

Epoch: 6| Step: 13
Training loss: 1.7613866329193115
Validation loss: 2.0885153483319026

Epoch: 67| Step: 0
Training loss: 2.2413320541381836
Validation loss: 2.0773280871811735

Epoch: 6| Step: 1
Training loss: 2.069304943084717
Validation loss: 2.0767107253433554

Epoch: 6| Step: 2
Training loss: 2.3686323165893555
Validation loss: 2.0784191290537515

Epoch: 6| Step: 3
Training loss: 2.301673412322998
Validation loss: 2.0685245401115826

Epoch: 6| Step: 4
Training loss: 1.5756407976150513
Validation loss: 2.0841969802815425

Epoch: 6| Step: 5
Training loss: 2.857863664627075
Validation loss: 2.0839849184918147

Epoch: 6| Step: 6
Training loss: 1.88188898563385
Validation loss: 2.1104687772771364

Epoch: 6| Step: 7
Training loss: 2.2356019020080566
Validation loss: 2.0772090137645765

Epoch: 6| Step: 8
Training loss: 2.309474468231201
Validation loss: 2.0774254170797204

Epoch: 6| Step: 9
Training loss: 2.3385274410247803
Validation loss: 2.0763614331522295

Epoch: 6| Step: 10
Training loss: 2.4106550216674805
Validation loss: 2.0952567977289998

Epoch: 6| Step: 11
Training loss: 2.645631790161133
Validation loss: 2.070390127038443

Epoch: 6| Step: 12
Training loss: 1.5736130475997925
Validation loss: 2.0667046193153626

Epoch: 6| Step: 13
Training loss: 2.71232008934021
Validation loss: 2.0732625607521302

Epoch: 68| Step: 0
Training loss: 2.013174057006836
Validation loss: 2.076041608728388

Epoch: 6| Step: 1
Training loss: 1.452566385269165
Validation loss: 2.091230297601351

Epoch: 6| Step: 2
Training loss: 2.410836696624756
Validation loss: 2.088396672279604

Epoch: 6| Step: 3
Training loss: 2.8274550437927246
Validation loss: 2.0835284699675856

Epoch: 6| Step: 4
Training loss: 2.396937847137451
Validation loss: 2.0779031912485757

Epoch: 6| Step: 5
Training loss: 2.045328140258789
Validation loss: 2.0837659169268865

Epoch: 6| Step: 6
Training loss: 1.9220595359802246
Validation loss: 2.0864312789773427

Epoch: 6| Step: 7
Training loss: 3.0540060997009277
Validation loss: 2.084821019121396

Epoch: 6| Step: 8
Training loss: 1.7619268894195557
Validation loss: 2.080969818176762

Epoch: 6| Step: 9
Training loss: 2.7698135375976562
Validation loss: 2.0784293707980903

Epoch: 6| Step: 10
Training loss: 2.395758628845215
Validation loss: 2.099097186519254

Epoch: 6| Step: 11
Training loss: 2.4632694721221924
Validation loss: 2.087121012390301

Epoch: 6| Step: 12
Training loss: 1.468719720840454
Validation loss: 2.1021305489283737

Epoch: 6| Step: 13
Training loss: 2.4642064571380615
Validation loss: 2.081671163599978

Epoch: 69| Step: 0
Training loss: 2.437659740447998
Validation loss: 2.0937640282415573

Epoch: 6| Step: 1
Training loss: 1.7720755338668823
Validation loss: 2.067209700102447

Epoch: 6| Step: 2
Training loss: 2.572554111480713
Validation loss: 2.1024441488327517

Epoch: 6| Step: 3
Training loss: 1.7123223543167114
Validation loss: 2.073138234435871

Epoch: 6| Step: 4
Training loss: 2.9221596717834473
Validation loss: 2.0892549945462133

Epoch: 6| Step: 5
Training loss: 1.9560112953186035
Validation loss: 2.069517979057886

Epoch: 6| Step: 6
Training loss: 2.6581687927246094
Validation loss: 2.095354026363742

Epoch: 6| Step: 7
Training loss: 2.141066312789917
Validation loss: 2.093837284272717

Epoch: 6| Step: 8
Training loss: 2.915663719177246
Validation loss: 2.086000056676967

Epoch: 6| Step: 9
Training loss: 2.014723777770996
Validation loss: 2.068769963838721

Epoch: 6| Step: 10
Training loss: 2.230846405029297
Validation loss: 2.0856600166648946

Epoch: 6| Step: 11
Training loss: 2.0806467533111572
Validation loss: 2.0715060272524433

Epoch: 6| Step: 12
Training loss: 1.9455815553665161
Validation loss: 2.0723874056211082

Epoch: 6| Step: 13
Training loss: 1.8964617252349854
Validation loss: 2.0771481170449206

Epoch: 70| Step: 0
Training loss: 1.8726823329925537
Validation loss: 2.097559480256932

Epoch: 6| Step: 1
Training loss: 2.68734073638916
Validation loss: 2.112352171251851

Epoch: 6| Step: 2
Training loss: 2.8051493167877197
Validation loss: 2.087641090475103

Epoch: 6| Step: 3
Training loss: 2.1318869590759277
Validation loss: 2.092802587375846

Epoch: 6| Step: 4
Training loss: 2.142911672592163
Validation loss: 2.0966804232648624

Epoch: 6| Step: 5
Training loss: 2.7373781204223633
Validation loss: 2.083717848664971

Epoch: 6| Step: 6
Training loss: 1.9559816122055054
Validation loss: 2.0879370294591433

Epoch: 6| Step: 7
Training loss: 1.4135441780090332
Validation loss: 2.0685853009582846

Epoch: 6| Step: 8
Training loss: 3.0440101623535156
Validation loss: 2.082222256609189

Epoch: 6| Step: 9
Training loss: 1.8437004089355469
Validation loss: 2.0943239465836556

Epoch: 6| Step: 10
Training loss: 2.241994857788086
Validation loss: 2.0990532136732534

Epoch: 6| Step: 11
Training loss: 2.142772674560547
Validation loss: 2.088180721447032

Epoch: 6| Step: 12
Training loss: 2.0354549884796143
Validation loss: 2.0947757792729202

Epoch: 6| Step: 13
Training loss: 2.260158061981201
Validation loss: 2.0946728311559206

Epoch: 71| Step: 0
Training loss: 1.534142017364502
Validation loss: 2.087054337224653

Epoch: 6| Step: 1
Training loss: 2.419185161590576
Validation loss: 2.0903631807655416

Epoch: 6| Step: 2
Training loss: 1.9375758171081543
Validation loss: 2.098638480709445

Epoch: 6| Step: 3
Training loss: 2.2064197063446045
Validation loss: 2.086687139285508

Epoch: 6| Step: 4
Training loss: 1.9337964057922363
Validation loss: 2.0846802547413814

Epoch: 6| Step: 5
Training loss: 2.0884485244750977
Validation loss: 2.088779313589937

Epoch: 6| Step: 6
Training loss: 2.1765637397766113
Validation loss: 2.0875318665658273

Epoch: 6| Step: 7
Training loss: 3.150716781616211
Validation loss: 2.1035336627755115

Epoch: 6| Step: 8
Training loss: 1.7495942115783691
Validation loss: 2.095997066907985

Epoch: 6| Step: 9
Training loss: 2.8101816177368164
Validation loss: 2.0930990685698805

Epoch: 6| Step: 10
Training loss: 2.7801506519317627
Validation loss: 2.0789441280467535

Epoch: 6| Step: 11
Training loss: 2.0732712745666504
Validation loss: 2.10464874903361

Epoch: 6| Step: 12
Training loss: 2.3450710773468018
Validation loss: 2.086455641254302

Epoch: 6| Step: 13
Training loss: 2.0820488929748535
Validation loss: 2.1023059275842484

Epoch: 72| Step: 0
Training loss: 2.222670316696167
Validation loss: 2.097372305008673

Epoch: 6| Step: 1
Training loss: 1.930675983428955
Validation loss: 2.081919357340823

Epoch: 6| Step: 2
Training loss: 2.2203733921051025
Validation loss: 2.10298131614603

Epoch: 6| Step: 3
Training loss: 2.390784740447998
Validation loss: 2.0934303550310034

Epoch: 6| Step: 4
Training loss: 1.677718162536621
Validation loss: 2.081579186583078

Epoch: 6| Step: 5
Training loss: 1.8350015878677368
Validation loss: 2.100405289280799

Epoch: 6| Step: 6
Training loss: 3.119468927383423
Validation loss: 2.0874647094357397

Epoch: 6| Step: 7
Training loss: 2.3473737239837646
Validation loss: 2.0709840354099067

Epoch: 6| Step: 8
Training loss: 2.695716381072998
Validation loss: 2.0828309084779475

Epoch: 6| Step: 9
Training loss: 2.03611421585083
Validation loss: 2.1113741141493603

Epoch: 6| Step: 10
Training loss: 2.0772781372070312
Validation loss: 2.086152302321567

Epoch: 6| Step: 11
Training loss: 2.3268795013427734
Validation loss: 2.096848339162847

Epoch: 6| Step: 12
Training loss: 2.470428943634033
Validation loss: 2.0949401317104215

Epoch: 6| Step: 13
Training loss: 1.532914161682129
Validation loss: 2.096349127830998

Epoch: 73| Step: 0
Training loss: 1.935042142868042
Validation loss: 2.083397267967142

Epoch: 6| Step: 1
Training loss: 2.569457769393921
Validation loss: 2.0747420454537995

Epoch: 6| Step: 2
Training loss: 1.405737042427063
Validation loss: 2.086925055391045

Epoch: 6| Step: 3
Training loss: 2.884593963623047
Validation loss: 2.0882174097081667

Epoch: 6| Step: 4
Training loss: 2.075984001159668
Validation loss: 2.087078796919956

Epoch: 6| Step: 5
Training loss: 1.1385791301727295
Validation loss: 2.102388740867697

Epoch: 6| Step: 6
Training loss: 2.3000447750091553
Validation loss: 2.074901209082655

Epoch: 6| Step: 7
Training loss: 2.2648134231567383
Validation loss: 2.0798705265086186

Epoch: 6| Step: 8
Training loss: 2.928699493408203
Validation loss: 2.0675141273006314

Epoch: 6| Step: 9
Training loss: 1.988660216331482
Validation loss: 2.091027590536302

Epoch: 6| Step: 10
Training loss: 2.8502564430236816
Validation loss: 2.0925800838778095

Epoch: 6| Step: 11
Training loss: 2.9480416774749756
Validation loss: 2.0961581994128484

Epoch: 6| Step: 12
Training loss: 2.051551342010498
Validation loss: 2.0927708661684425

Epoch: 6| Step: 13
Training loss: 1.6439276933670044
Validation loss: 2.085707305580057

Epoch: 74| Step: 0
Training loss: 2.172353982925415
Validation loss: 2.0869208253839964

Epoch: 6| Step: 1
Training loss: 2.395195245742798
Validation loss: 2.090553555437314

Epoch: 6| Step: 2
Training loss: 2.293713092803955
Validation loss: 2.080657369347029

Epoch: 6| Step: 3
Training loss: 1.4164141416549683
Validation loss: 2.0894383307426208

Epoch: 6| Step: 4
Training loss: 2.5826849937438965
Validation loss: 2.0966931684042818

Epoch: 6| Step: 5
Training loss: 2.1132917404174805
Validation loss: 2.0954258903380363

Epoch: 6| Step: 6
Training loss: 2.6545815467834473
Validation loss: 2.0928860954059068

Epoch: 6| Step: 7
Training loss: 2.127268075942993
Validation loss: 2.078916759901149

Epoch: 6| Step: 8
Training loss: 2.29085373878479
Validation loss: 2.075073956161417

Epoch: 6| Step: 9
Training loss: 2.065002918243408
Validation loss: 2.0678422451019287

Epoch: 6| Step: 10
Training loss: 2.3161661624908447
Validation loss: 2.0915524498108895

Epoch: 6| Step: 11
Training loss: 2.3329837322235107
Validation loss: 2.085795251272058

Epoch: 6| Step: 12
Training loss: 1.9882020950317383
Validation loss: 2.0873161977337253

Epoch: 6| Step: 13
Training loss: 2.5157835483551025
Validation loss: 2.0804433591904177

Epoch: 75| Step: 0
Training loss: 1.6033849716186523
Validation loss: 2.0938007600845827

Epoch: 6| Step: 1
Training loss: 1.965061068534851
Validation loss: 2.07232831370446

Epoch: 6| Step: 2
Training loss: 2.6450376510620117
Validation loss: 2.0725055856089436

Epoch: 6| Step: 3
Training loss: 1.763744592666626
Validation loss: 2.099165480623963

Epoch: 6| Step: 4
Training loss: 2.0560197830200195
Validation loss: 2.0757665275245585

Epoch: 6| Step: 5
Training loss: 2.7484593391418457
Validation loss: 2.0888291482002503

Epoch: 6| Step: 6
Training loss: 2.3691070079803467
Validation loss: 2.0917575000434794

Epoch: 6| Step: 7
Training loss: 2.3434348106384277
Validation loss: 2.098583270144719

Epoch: 6| Step: 8
Training loss: 2.7265357971191406
Validation loss: 2.083434070310285

Epoch: 6| Step: 9
Training loss: 2.2909440994262695
Validation loss: 2.1005070055684736

Epoch: 6| Step: 10
Training loss: 1.84459388256073
Validation loss: 2.1054372761839177

Epoch: 6| Step: 11
Training loss: 2.832573890686035
Validation loss: 2.0988287566810526

Epoch: 6| Step: 12
Training loss: 1.9799373149871826
Validation loss: 2.0886997279300483

Epoch: 6| Step: 13
Training loss: 1.325953722000122
Validation loss: 2.0909891487449728

Epoch: 76| Step: 0
Training loss: 2.1065897941589355
Validation loss: 2.0859804563624884

Epoch: 6| Step: 1
Training loss: 2.5230872631073
Validation loss: 2.103178616492979

Epoch: 6| Step: 2
Training loss: 2.7438457012176514
Validation loss: 2.102016874538955

Epoch: 6| Step: 3
Training loss: 2.600517988204956
Validation loss: 2.082597920971532

Epoch: 6| Step: 4
Training loss: 2.31575345993042
Validation loss: 2.08268504758035

Epoch: 6| Step: 5
Training loss: 2.8303027153015137
Validation loss: 2.0737210242978987

Epoch: 6| Step: 6
Training loss: 1.7112829685211182
Validation loss: 2.091782851885724

Epoch: 6| Step: 7
Training loss: 1.9000616073608398
Validation loss: 2.1021535576030774

Epoch: 6| Step: 8
Training loss: 2.382711410522461
Validation loss: 2.081522149424399

Epoch: 6| Step: 9
Training loss: 2.2426047325134277
Validation loss: 2.0947834137947328

Epoch: 6| Step: 10
Training loss: 1.3147897720336914
Validation loss: 2.089627024947956

Epoch: 6| Step: 11
Training loss: 2.018852949142456
Validation loss: 2.0842266954401487

Epoch: 6| Step: 12
Training loss: 2.2707386016845703
Validation loss: 2.079516722309974

Epoch: 6| Step: 13
Training loss: 2.0782063007354736
Validation loss: 2.1110069187738563

Epoch: 77| Step: 0
Training loss: 1.9035724401474
Validation loss: 2.0529163447759484

Epoch: 6| Step: 1
Training loss: 2.009284734725952
Validation loss: 2.076716358943652

Epoch: 6| Step: 2
Training loss: 1.784136176109314
Validation loss: 2.090703087468301

Epoch: 6| Step: 3
Training loss: 2.6831021308898926
Validation loss: 2.0815476448305192

Epoch: 6| Step: 4
Training loss: 2.4084291458129883
Validation loss: 2.088148505456986

Epoch: 6| Step: 5
Training loss: 2.320819139480591
Validation loss: 2.085023723622804

Epoch: 6| Step: 6
Training loss: 2.3368475437164307
Validation loss: 2.074518894636503

Epoch: 6| Step: 7
Training loss: 2.3561758995056152
Validation loss: 2.1036815386946484

Epoch: 6| Step: 8
Training loss: 2.5129706859588623
Validation loss: 2.0815012775441653

Epoch: 6| Step: 9
Training loss: 1.5100523233413696
Validation loss: 2.0753724985225226

Epoch: 6| Step: 10
Training loss: 1.9516355991363525
Validation loss: 2.0665307224437757

Epoch: 6| Step: 11
Training loss: 2.18794584274292
Validation loss: 2.100366985926064

Epoch: 6| Step: 12
Training loss: 2.786919116973877
Validation loss: 2.0699234700972036

Epoch: 6| Step: 13
Training loss: 2.1360318660736084
Validation loss: 2.0734019587116856

Epoch: 78| Step: 0
Training loss: 2.0355238914489746
Validation loss: 2.0938463698151293

Epoch: 6| Step: 1
Training loss: 2.411196231842041
Validation loss: 2.0874419340523342

Epoch: 6| Step: 2
Training loss: 2.2059593200683594
Validation loss: 2.0876731693103747

Epoch: 6| Step: 3
Training loss: 2.0466127395629883
Validation loss: 2.093592846265403

Epoch: 6| Step: 4
Training loss: 2.0058846473693848
Validation loss: 2.1014218638020177

Epoch: 6| Step: 5
Training loss: 2.2125749588012695
Validation loss: 2.0702323170118433

Epoch: 6| Step: 6
Training loss: 2.078089714050293
Validation loss: 2.068709332455871

Epoch: 6| Step: 7
Training loss: 2.2988219261169434
Validation loss: 2.092063319298529

Epoch: 6| Step: 8
Training loss: 2.3033833503723145
Validation loss: 2.1054735440079884

Epoch: 6| Step: 9
Training loss: 1.9656893014907837
Validation loss: 2.0898077257217897

Epoch: 6| Step: 10
Training loss: 2.512791872024536
Validation loss: 2.094630763094912

Epoch: 6| Step: 11
Training loss: 2.3587515354156494
Validation loss: 2.0962567919044086

Epoch: 6| Step: 12
Training loss: 2.512451648712158
Validation loss: 2.097941624220981

Epoch: 6| Step: 13
Training loss: 2.0950605869293213
Validation loss: 2.0811990563587477

Epoch: 79| Step: 0
Training loss: 3.0769360065460205
Validation loss: 2.1004286735288558

Epoch: 6| Step: 1
Training loss: 1.9795494079589844
Validation loss: 2.082752561056486

Epoch: 6| Step: 2
Training loss: 2.025261878967285
Validation loss: 2.1065344861758653

Epoch: 6| Step: 3
Training loss: 1.5745958089828491
Validation loss: 2.079053627547397

Epoch: 6| Step: 4
Training loss: 2.2012205123901367
Validation loss: 2.0777073188494612

Epoch: 6| Step: 5
Training loss: 1.80918550491333
Validation loss: 2.1252062154072586

Epoch: 6| Step: 6
Training loss: 2.2106974124908447
Validation loss: 2.0896905301719584

Epoch: 6| Step: 7
Training loss: 2.771350383758545
Validation loss: 2.0812952787645402

Epoch: 6| Step: 8
Training loss: 2.4194960594177246
Validation loss: 2.070246688781246

Epoch: 6| Step: 9
Training loss: 1.7479898929595947
Validation loss: 2.074955983828473

Epoch: 6| Step: 10
Training loss: 2.212371826171875
Validation loss: 2.076844569175474

Epoch: 6| Step: 11
Training loss: 1.6695611476898193
Validation loss: 2.08024759446421

Epoch: 6| Step: 12
Training loss: 2.4388113021850586
Validation loss: 2.0814551294490857

Epoch: 6| Step: 13
Training loss: 3.3009185791015625
Validation loss: 2.1001750679426294

Epoch: 80| Step: 0
Training loss: 2.1480417251586914
Validation loss: 2.0828643998792096

Epoch: 6| Step: 1
Training loss: 2.440833806991577
Validation loss: 2.0774972002993346

Epoch: 6| Step: 2
Training loss: 2.9287281036376953
Validation loss: 2.080749083590764

Epoch: 6| Step: 3
Training loss: 2.667339324951172
Validation loss: 2.0890288532421155

Epoch: 6| Step: 4
Training loss: 2.3048629760742188
Validation loss: 2.0842368551479873

Epoch: 6| Step: 5
Training loss: 1.4773750305175781
Validation loss: 2.0782871092519453

Epoch: 6| Step: 6
Training loss: 2.979910373687744
Validation loss: 2.08578848197896

Epoch: 6| Step: 7
Training loss: 1.895996332168579
Validation loss: 2.065437775786205

Epoch: 6| Step: 8
Training loss: 1.499512791633606
Validation loss: 2.0895875577003724

Epoch: 6| Step: 9
Training loss: 1.9657163619995117
Validation loss: 2.0932015898407146

Epoch: 6| Step: 10
Training loss: 1.7681719064712524
Validation loss: 2.089522602737591

Epoch: 6| Step: 11
Training loss: 2.522627353668213
Validation loss: 2.0928543434348157

Epoch: 6| Step: 12
Training loss: 1.8141542673110962
Validation loss: 2.0939022879446707

Epoch: 6| Step: 13
Training loss: 2.9698071479797363
Validation loss: 2.0861900570572063

Epoch: 81| Step: 0
Training loss: 2.160862922668457
Validation loss: 2.0997416383476666

Epoch: 6| Step: 1
Training loss: 3.285811185836792
Validation loss: 2.0785952383472073

Epoch: 6| Step: 2
Training loss: 2.0785679817199707
Validation loss: 2.075891715224071

Epoch: 6| Step: 3
Training loss: 2.235185146331787
Validation loss: 2.087239118032558

Epoch: 6| Step: 4
Training loss: 2.4398996829986572
Validation loss: 2.082681478992585

Epoch: 6| Step: 5
Training loss: 2.1224546432495117
Validation loss: 2.086292113027265

Epoch: 6| Step: 6
Training loss: 1.4856806993484497
Validation loss: 2.0898862936163463

Epoch: 6| Step: 7
Training loss: 2.3865480422973633
Validation loss: 2.097323780418724

Epoch: 6| Step: 8
Training loss: 1.7158784866333008
Validation loss: 2.072799604426148

Epoch: 6| Step: 9
Training loss: 2.235332489013672
Validation loss: 2.0774476117985223

Epoch: 6| Step: 10
Training loss: 2.076491355895996
Validation loss: 2.0774444867205877

Epoch: 6| Step: 11
Training loss: 2.247119903564453
Validation loss: 2.079303341527139

Epoch: 6| Step: 12
Training loss: 2.5016818046569824
Validation loss: 2.085990357142623

Epoch: 6| Step: 13
Training loss: 1.5463510751724243
Validation loss: 2.0802784453156176

Epoch: 82| Step: 0
Training loss: 1.8128349781036377
Validation loss: 2.091781045800896

Epoch: 6| Step: 1
Training loss: 1.607428789138794
Validation loss: 2.077715294335478

Epoch: 6| Step: 2
Training loss: 2.0236754417419434
Validation loss: 2.094256588207778

Epoch: 6| Step: 3
Training loss: 2.5456783771514893
Validation loss: 2.089431155112482

Epoch: 6| Step: 4
Training loss: 2.3712940216064453
Validation loss: 2.107231434955392

Epoch: 6| Step: 5
Training loss: 2.149028778076172
Validation loss: 2.078414083808981

Epoch: 6| Step: 6
Training loss: 2.4589648246765137
Validation loss: 2.0965253717155865

Epoch: 6| Step: 7
Training loss: 2.5518574714660645
Validation loss: 2.0870090825583345

Epoch: 6| Step: 8
Training loss: 2.174067974090576
Validation loss: 2.1004626392036356

Epoch: 6| Step: 9
Training loss: 2.7830026149749756
Validation loss: 2.0794278139709146

Epoch: 6| Step: 10
Training loss: 2.4761123657226562
Validation loss: 2.0921483039855957

Epoch: 6| Step: 11
Training loss: 2.214667797088623
Validation loss: 2.1106718996519684

Epoch: 6| Step: 12
Training loss: 1.7933721542358398
Validation loss: 2.09121472092085

Epoch: 6| Step: 13
Training loss: 1.757204532623291
Validation loss: 2.0728976136894635

Epoch: 83| Step: 0
Training loss: 1.595261812210083
Validation loss: 2.0508936733327885

Epoch: 6| Step: 1
Training loss: 2.3212223052978516
Validation loss: 2.093983598934707

Epoch: 6| Step: 2
Training loss: 3.20304012298584
Validation loss: 2.097978504755164

Epoch: 6| Step: 3
Training loss: 1.7051786184310913
Validation loss: 2.0795707087362967

Epoch: 6| Step: 4
Training loss: 1.8062795400619507
Validation loss: 2.0735279642125612

Epoch: 6| Step: 5
Training loss: 1.6578248739242554
Validation loss: 2.0880754147806475

Epoch: 6| Step: 6
Training loss: 2.7091493606567383
Validation loss: 2.075923268513013

Epoch: 6| Step: 7
Training loss: 1.5706028938293457
Validation loss: 2.07552691172528

Epoch: 6| Step: 8
Training loss: 1.9839471578598022
Validation loss: 2.089945662406183

Epoch: 6| Step: 9
Training loss: 2.0414249897003174
Validation loss: 2.07841888038061

Epoch: 6| Step: 10
Training loss: 2.501408100128174
Validation loss: 2.0973469057390766

Epoch: 6| Step: 11
Training loss: 2.3587613105773926
Validation loss: 2.07510268944566

Epoch: 6| Step: 12
Training loss: 2.243321180343628
Validation loss: 2.0748864681490007

Epoch: 6| Step: 13
Training loss: 3.7295315265655518
Validation loss: 2.075536386941069

Epoch: 84| Step: 0
Training loss: 1.7175827026367188
Validation loss: 2.089948784920477

Epoch: 6| Step: 1
Training loss: 2.4296183586120605
Validation loss: 2.091502860028257

Epoch: 6| Step: 2
Training loss: 1.678167700767517
Validation loss: 2.0851777932977162

Epoch: 6| Step: 3
Training loss: 2.163620948791504
Validation loss: 2.081976300926619

Epoch: 6| Step: 4
Training loss: 3.025083303451538
Validation loss: 2.0983707135723484

Epoch: 6| Step: 5
Training loss: 2.543698787689209
Validation loss: 2.092917924286217

Epoch: 6| Step: 6
Training loss: 2.273653745651245
Validation loss: 2.0890806951830463

Epoch: 6| Step: 7
Training loss: 1.605994701385498
Validation loss: 2.066084127272329

Epoch: 6| Step: 8
Training loss: 2.186885356903076
Validation loss: 2.0715908363301265

Epoch: 6| Step: 9
Training loss: 3.0772531032562256
Validation loss: 2.104787834229008

Epoch: 6| Step: 10
Training loss: 2.2775936126708984
Validation loss: 2.097629767592235

Epoch: 6| Step: 11
Training loss: 1.8437860012054443
Validation loss: 2.109836927024267

Epoch: 6| Step: 12
Training loss: 1.7508995532989502
Validation loss: 2.0747960331619426

Epoch: 6| Step: 13
Training loss: 2.312201499938965
Validation loss: 2.0659843798606627

Epoch: 85| Step: 0
Training loss: 2.8441786766052246
Validation loss: 2.1006335212338354

Epoch: 6| Step: 1
Training loss: 1.752930998802185
Validation loss: 2.0906348625818887

Epoch: 6| Step: 2
Training loss: 1.6884175539016724
Validation loss: 2.098091801007589

Epoch: 6| Step: 3
Training loss: 2.046170234680176
Validation loss: 2.081659096543507

Epoch: 6| Step: 4
Training loss: 2.045508623123169
Validation loss: 2.0965703225904897

Epoch: 6| Step: 5
Training loss: 2.314194440841675
Validation loss: 2.0951542828672673

Epoch: 6| Step: 6
Training loss: 2.1327085494995117
Validation loss: 2.0903736237556703

Epoch: 6| Step: 7
Training loss: 2.2003860473632812
Validation loss: 2.0785549174072924

Epoch: 6| Step: 8
Training loss: 2.6069021224975586
Validation loss: 2.0864935075083086

Epoch: 6| Step: 9
Training loss: 2.8384270668029785
Validation loss: 2.0716270938996346

Epoch: 6| Step: 10
Training loss: 1.7510852813720703
Validation loss: 2.0921354909096994

Epoch: 6| Step: 11
Training loss: 2.497833251953125
Validation loss: 2.0815850201473443

Epoch: 6| Step: 12
Training loss: 2.449096918106079
Validation loss: 2.0709825459346978

Epoch: 6| Step: 13
Training loss: 1.0450793504714966
Validation loss: 2.0993839950971704

Epoch: 86| Step: 0
Training loss: 2.3512790203094482
Validation loss: 2.0758585699142946

Epoch: 6| Step: 1
Training loss: 2.269749402999878
Validation loss: 2.0689364787070983

Epoch: 6| Step: 2
Training loss: 2.9742727279663086
Validation loss: 2.081128376786427

Epoch: 6| Step: 3
Training loss: 2.1119816303253174
Validation loss: 2.0731685597409486

Epoch: 6| Step: 4
Training loss: 2.024296522140503
Validation loss: 2.0782190881749636

Epoch: 6| Step: 5
Training loss: 2.023247480392456
Validation loss: 2.0691603781074606

Epoch: 6| Step: 6
Training loss: 2.206883430480957
Validation loss: 2.1077505183476273

Epoch: 6| Step: 7
Training loss: 2.7451159954071045
Validation loss: 2.080525090617518

Epoch: 6| Step: 8
Training loss: 1.960326910018921
Validation loss: 2.0748120712977585

Epoch: 6| Step: 9
Training loss: 1.950909972190857
Validation loss: 2.1004597371624363

Epoch: 6| Step: 10
Training loss: 2.01943302154541
Validation loss: 2.0666591031576997

Epoch: 6| Step: 11
Training loss: 2.4875049591064453
Validation loss: 2.07765910830549

Epoch: 6| Step: 12
Training loss: 1.913192868232727
Validation loss: 2.06492046899693

Epoch: 6| Step: 13
Training loss: 1.4697270393371582
Validation loss: 2.0700003844435497

Epoch: 87| Step: 0
Training loss: 2.2457919120788574
Validation loss: 2.0903000831604004

Epoch: 6| Step: 1
Training loss: 2.13370418548584
Validation loss: 2.0865864305086035

Epoch: 6| Step: 2
Training loss: 2.320579767227173
Validation loss: 2.080890042807466

Epoch: 6| Step: 3
Training loss: 2.411083936691284
Validation loss: 2.097848556374991

Epoch: 6| Step: 4
Training loss: 1.9348915815353394
Validation loss: 2.086567686450097

Epoch: 6| Step: 5
Training loss: 2.040860891342163
Validation loss: 2.070427078072743

Epoch: 6| Step: 6
Training loss: 3.073662042617798
Validation loss: 2.0721123987628567

Epoch: 6| Step: 7
Training loss: 1.4791638851165771
Validation loss: 2.085844850027433

Epoch: 6| Step: 8
Training loss: 2.414479970932007
Validation loss: 2.0578765766595

Epoch: 6| Step: 9
Training loss: 1.8529062271118164
Validation loss: 2.095280021749517

Epoch: 6| Step: 10
Training loss: 1.8684265613555908
Validation loss: 2.0786513410588747

Epoch: 6| Step: 11
Training loss: 2.051090717315674
Validation loss: 2.074599181452105

Epoch: 6| Step: 12
Training loss: 2.6309781074523926
Validation loss: 2.0869062459597023

Epoch: 6| Step: 13
Training loss: 2.182293653488159
Validation loss: 2.0826417502536567

Epoch: 88| Step: 0
Training loss: 1.864891529083252
Validation loss: 2.098123264569108

Epoch: 6| Step: 1
Training loss: 2.5543556213378906
Validation loss: 2.0860062196690548

Epoch: 6| Step: 2
Training loss: 2.140511989593506
Validation loss: 2.085837184741933

Epoch: 6| Step: 3
Training loss: 1.7692363262176514
Validation loss: 2.0840412621857016

Epoch: 6| Step: 4
Training loss: 1.7215701341629028
Validation loss: 2.0925887861559467

Epoch: 6| Step: 5
Training loss: 2.4150843620300293
Validation loss: 2.078117346250883

Epoch: 6| Step: 6
Training loss: 1.9006861448287964
Validation loss: 2.069507452749437

Epoch: 6| Step: 7
Training loss: 2.4333853721618652
Validation loss: 2.06847398255461

Epoch: 6| Step: 8
Training loss: 2.8048136234283447
Validation loss: 2.0800711416429087

Epoch: 6| Step: 9
Training loss: 2.3126108646392822
Validation loss: 2.0853852174615346

Epoch: 6| Step: 10
Training loss: 2.30940580368042
Validation loss: 2.075156186216621

Epoch: 6| Step: 11
Training loss: 2.197465658187866
Validation loss: 2.0737639319512153

Epoch: 6| Step: 12
Training loss: 2.206407070159912
Validation loss: 2.0691905970214517

Epoch: 6| Step: 13
Training loss: 1.947462558746338
Validation loss: 2.0582817216073312

Epoch: 89| Step: 0
Training loss: 2.2932095527648926
Validation loss: 2.0858731705655336

Epoch: 6| Step: 1
Training loss: 2.6750526428222656
Validation loss: 2.1012247159916866

Epoch: 6| Step: 2
Training loss: 2.234218120574951
Validation loss: 2.0647468823258595

Epoch: 6| Step: 3
Training loss: 2.1298182010650635
Validation loss: 2.0636262598858086

Epoch: 6| Step: 4
Training loss: 2.1071982383728027
Validation loss: 2.0899012729685795

Epoch: 6| Step: 5
Training loss: 2.5260934829711914
Validation loss: 2.0788322033420688

Epoch: 6| Step: 6
Training loss: 1.6324503421783447
Validation loss: 2.0789184519039687

Epoch: 6| Step: 7
Training loss: 2.23169207572937
Validation loss: 2.0739254156748452

Epoch: 6| Step: 8
Training loss: 2.018214702606201
Validation loss: 2.0904701550801597

Epoch: 6| Step: 9
Training loss: 2.130265951156616
Validation loss: 2.095313431114279

Epoch: 6| Step: 10
Training loss: 2.63409423828125
Validation loss: 2.080939826144967

Epoch: 6| Step: 11
Training loss: 1.8881158828735352
Validation loss: 2.1022988493724535

Epoch: 6| Step: 12
Training loss: 1.7024757862091064
Validation loss: 2.088524474892565

Epoch: 6| Step: 13
Training loss: 2.2777023315429688
Validation loss: 2.0897460342735372

Epoch: 90| Step: 0
Training loss: 2.582207679748535
Validation loss: 2.088489286361202

Epoch: 6| Step: 1
Training loss: 2.331949472427368
Validation loss: 2.084839867007348

Epoch: 6| Step: 2
Training loss: 1.4752204418182373
Validation loss: 2.0863972504933677

Epoch: 6| Step: 3
Training loss: 2.419926881790161
Validation loss: 2.098296078302527

Epoch: 6| Step: 4
Training loss: 1.8908607959747314
Validation loss: 2.0676382715984056

Epoch: 6| Step: 5
Training loss: 1.5070734024047852
Validation loss: 2.0729258598819857

Epoch: 6| Step: 6
Training loss: 2.001474142074585
Validation loss: 2.073929694391066

Epoch: 6| Step: 7
Training loss: 2.7338080406188965
Validation loss: 2.0908894705516037

Epoch: 6| Step: 8
Training loss: 2.7805862426757812
Validation loss: 2.0766020346713323

Epoch: 6| Step: 9
Training loss: 1.855757713317871
Validation loss: 2.084281629131686

Epoch: 6| Step: 10
Training loss: 2.045731782913208
Validation loss: 2.0830012213799263

Epoch: 6| Step: 11
Training loss: 2.375936269760132
Validation loss: 2.09165983815347

Epoch: 6| Step: 12
Training loss: 2.849010944366455
Validation loss: 2.06945514422591

Epoch: 6| Step: 13
Training loss: 1.4580243825912476
Validation loss: 2.0869562074702275

Epoch: 91| Step: 0
Training loss: 1.8023550510406494
Validation loss: 2.0930765380141554

Epoch: 6| Step: 1
Training loss: 2.209827184677124
Validation loss: 2.0810358473049697

Epoch: 6| Step: 2
Training loss: 2.310540199279785
Validation loss: 2.077854683322291

Epoch: 6| Step: 3
Training loss: 2.244142532348633
Validation loss: 2.0804429746443227

Epoch: 6| Step: 4
Training loss: 2.519306182861328
Validation loss: 2.0911981598023446

Epoch: 6| Step: 5
Training loss: 2.203144073486328
Validation loss: 2.0729553930221067

Epoch: 6| Step: 6
Training loss: 1.5056147575378418
Validation loss: 2.0886885491750573

Epoch: 6| Step: 7
Training loss: 2.6867456436157227
Validation loss: 2.10340783672948

Epoch: 6| Step: 8
Training loss: 2.579134225845337
Validation loss: 2.106647724746376

Epoch: 6| Step: 9
Training loss: 2.6501388549804688
Validation loss: 2.109144256960961

Epoch: 6| Step: 10
Training loss: 2.3281960487365723
Validation loss: 2.086398909168859

Epoch: 6| Step: 11
Training loss: 1.9013360738754272
Validation loss: 2.089709343448762

Epoch: 6| Step: 12
Training loss: 1.7607396841049194
Validation loss: 2.0965583785887687

Epoch: 6| Step: 13
Training loss: 1.6885170936584473
Validation loss: 2.0998400283116165

Epoch: 92| Step: 0
Training loss: 1.7343902587890625
Validation loss: 2.0805918119286977

Epoch: 6| Step: 1
Training loss: 2.919543743133545
Validation loss: 2.0717019906608005

Epoch: 6| Step: 2
Training loss: 2.7628700733184814
Validation loss: 2.090544193021713

Epoch: 6| Step: 3
Training loss: 2.424790382385254
Validation loss: 2.0847969106448594

Epoch: 6| Step: 4
Training loss: 2.443469762802124
Validation loss: 2.0860870858674407

Epoch: 6| Step: 5
Training loss: 2.4093339443206787
Validation loss: 2.061556580246136

Epoch: 6| Step: 6
Training loss: 1.6187076568603516
Validation loss: 2.102949571865861

Epoch: 6| Step: 7
Training loss: 1.7355889081954956
Validation loss: 2.074232371904517

Epoch: 6| Step: 8
Training loss: 1.720587968826294
Validation loss: 2.0918130977179414

Epoch: 6| Step: 9
Training loss: 2.4165515899658203
Validation loss: 2.0753022598963913

Epoch: 6| Step: 10
Training loss: 2.7487945556640625
Validation loss: 2.0725671322115007

Epoch: 6| Step: 11
Training loss: 1.9190224409103394
Validation loss: 2.0865629898604525

Epoch: 6| Step: 12
Training loss: 1.893555760383606
Validation loss: 2.0819347212391515

Epoch: 6| Step: 13
Training loss: 1.239096999168396
Validation loss: 2.0872815091122865

Epoch: 93| Step: 0
Training loss: 2.1593947410583496
Validation loss: 2.105519958721694

Epoch: 6| Step: 1
Training loss: 1.9052531719207764
Validation loss: 2.0999450555411716

Epoch: 6| Step: 2
Training loss: 1.9737043380737305
Validation loss: 2.0687010852239465

Epoch: 6| Step: 3
Training loss: 2.0475940704345703
Validation loss: 2.0725805656884306

Epoch: 6| Step: 4
Training loss: 1.9292635917663574
Validation loss: 2.0702165275491695

Epoch: 6| Step: 5
Training loss: 2.6014790534973145
Validation loss: 2.0723347945879866

Epoch: 6| Step: 6
Training loss: 1.7188141345977783
Validation loss: 2.063221944275723

Epoch: 6| Step: 7
Training loss: 2.7787041664123535
Validation loss: 2.0747757496372348

Epoch: 6| Step: 8
Training loss: 2.409533977508545
Validation loss: 2.061810426814582

Epoch: 6| Step: 9
Training loss: 1.4064009189605713
Validation loss: 2.0543093142970914

Epoch: 6| Step: 10
Training loss: 1.986269235610962
Validation loss: 2.0622812958173853

Epoch: 6| Step: 11
Training loss: 2.2487447261810303
Validation loss: 2.0801269315904185

Epoch: 6| Step: 12
Training loss: 3.260239839553833
Validation loss: 2.0651611602434548

Epoch: 6| Step: 13
Training loss: 1.9404348134994507
Validation loss: 2.075552393031377

Epoch: 94| Step: 0
Training loss: 2.4895248413085938
Validation loss: 2.0550973479465773

Epoch: 6| Step: 1
Training loss: 1.9096134901046753
Validation loss: 2.075485970384331

Epoch: 6| Step: 2
Training loss: 2.0368764400482178
Validation loss: 2.078738148494433

Epoch: 6| Step: 3
Training loss: 2.7408673763275146
Validation loss: 2.0801113933645268

Epoch: 6| Step: 4
Training loss: 1.583154320716858
Validation loss: 2.0736572934735205

Epoch: 6| Step: 5
Training loss: 2.167705535888672
Validation loss: 2.061653103879703

Epoch: 6| Step: 6
Training loss: 2.5225696563720703
Validation loss: 2.0679987527990855

Epoch: 6| Step: 7
Training loss: 2.496396541595459
Validation loss: 2.0787594215844267

Epoch: 6| Step: 8
Training loss: 2.1986706256866455
Validation loss: 2.075189172580678

Epoch: 6| Step: 9
Training loss: 1.506160020828247
Validation loss: 2.079703495066653

Epoch: 6| Step: 10
Training loss: 2.059811592102051
Validation loss: 2.0905839755970943

Epoch: 6| Step: 11
Training loss: 2.397010326385498
Validation loss: 2.09043042121395

Epoch: 6| Step: 12
Training loss: 1.7401149272918701
Validation loss: 2.085453353902345

Epoch: 6| Step: 13
Training loss: 2.7744898796081543
Validation loss: 2.0979570829740135

Epoch: 95| Step: 0
Training loss: 2.5539498329162598
Validation loss: 2.081750192949849

Epoch: 6| Step: 1
Training loss: 2.033632755279541
Validation loss: 2.0848200141742663

Epoch: 6| Step: 2
Training loss: 2.3877949714660645
Validation loss: 2.0843333505815074

Epoch: 6| Step: 3
Training loss: 1.7149062156677246
Validation loss: 2.0865997755399315

Epoch: 6| Step: 4
Training loss: 2.5837032794952393
Validation loss: 2.083307712308822

Epoch: 6| Step: 5
Training loss: 2.982217311859131
Validation loss: 2.069520709335163

Epoch: 6| Step: 6
Training loss: 1.6817381381988525
Validation loss: 2.0726513683155017

Epoch: 6| Step: 7
Training loss: 1.9343695640563965
Validation loss: 2.066473704512401

Epoch: 6| Step: 8
Training loss: 1.9829461574554443
Validation loss: 2.0759062869574434

Epoch: 6| Step: 9
Training loss: 1.669184923171997
Validation loss: 2.086923853043587

Epoch: 6| Step: 10
Training loss: 1.7957016229629517
Validation loss: 2.074167384896227

Epoch: 6| Step: 11
Training loss: 3.0173206329345703
Validation loss: 2.0783522308513684

Epoch: 6| Step: 12
Training loss: 2.1214752197265625
Validation loss: 2.0717334349950156

Epoch: 6| Step: 13
Training loss: 1.7631773948669434
Validation loss: 2.0798014081934446

Epoch: 96| Step: 0
Training loss: 2.101001024246216
Validation loss: 2.0565666998586347

Epoch: 6| Step: 1
Training loss: 2.1324658393859863
Validation loss: 2.075313929588564

Epoch: 6| Step: 2
Training loss: 2.111128330230713
Validation loss: 2.082685394953656

Epoch: 6| Step: 3
Training loss: 2.407020330429077
Validation loss: 2.0688548152164747

Epoch: 6| Step: 4
Training loss: 2.029412269592285
Validation loss: 2.0963169887501705

Epoch: 6| Step: 5
Training loss: 2.1546010971069336
Validation loss: 2.083601218397899

Epoch: 6| Step: 6
Training loss: 1.6544263362884521
Validation loss: 2.065066677267833

Epoch: 6| Step: 7
Training loss: 2.2186646461486816
Validation loss: 2.074337422206838

Epoch: 6| Step: 8
Training loss: 1.6018729209899902
Validation loss: 2.072584634186119

Epoch: 6| Step: 9
Training loss: 2.2787463665008545
Validation loss: 2.060435861669561

Epoch: 6| Step: 10
Training loss: 3.193878650665283
Validation loss: 2.085090992271259

Epoch: 6| Step: 11
Training loss: 2.2704529762268066
Validation loss: 2.0798002212278304

Epoch: 6| Step: 12
Training loss: 2.5193300247192383
Validation loss: 2.0614831139964442

Epoch: 6| Step: 13
Training loss: 1.5775460004806519
Validation loss: 2.0623763453575874

Epoch: 97| Step: 0
Training loss: 2.958559036254883
Validation loss: 2.082689046859741

Epoch: 6| Step: 1
Training loss: 2.272209644317627
Validation loss: 2.0653475997268513

Epoch: 6| Step: 2
Training loss: 2.332709789276123
Validation loss: 2.071438408667041

Epoch: 6| Step: 3
Training loss: 2.755312919616699
Validation loss: 2.091483393023091

Epoch: 6| Step: 4
Training loss: 1.4224269390106201
Validation loss: 2.055961337140811

Epoch: 6| Step: 5
Training loss: 1.5969264507293701
Validation loss: 2.066680553138897

Epoch: 6| Step: 6
Training loss: 1.8395705223083496
Validation loss: 2.0748861297484367

Epoch: 6| Step: 7
Training loss: 1.7973686456680298
Validation loss: 2.074021917517467

Epoch: 6| Step: 8
Training loss: 1.7758233547210693
Validation loss: 2.076262377923535

Epoch: 6| Step: 9
Training loss: 2.5484533309936523
Validation loss: 2.0761311823321926

Epoch: 6| Step: 10
Training loss: 2.2336111068725586
Validation loss: 2.075436676702192

Epoch: 6| Step: 11
Training loss: 2.083155870437622
Validation loss: 2.0756494024748444

Epoch: 6| Step: 12
Training loss: 2.3899483680725098
Validation loss: 2.0771274617923203

Epoch: 6| Step: 13
Training loss: 2.063473701477051
Validation loss: 2.075034692723264

Epoch: 98| Step: 0
Training loss: 2.559257745742798
Validation loss: 2.0598673128312632

Epoch: 6| Step: 1
Training loss: 2.123880624771118
Validation loss: 2.076941918301326

Epoch: 6| Step: 2
Training loss: 2.5079293251037598
Validation loss: 2.056576416056643

Epoch: 6| Step: 3
Training loss: 1.921496868133545
Validation loss: 2.0663669955345894

Epoch: 6| Step: 4
Training loss: 2.509838342666626
Validation loss: 2.091299310807259

Epoch: 6| Step: 5
Training loss: 2.2507011890411377
Validation loss: 2.0817407638795915

Epoch: 6| Step: 6
Training loss: 1.9871560335159302
Validation loss: 2.0771169816294024

Epoch: 6| Step: 7
Training loss: 2.0842230319976807
Validation loss: 2.0796987125950475

Epoch: 6| Step: 8
Training loss: 2.1966359615325928
Validation loss: 2.0985928607243363

Epoch: 6| Step: 9
Training loss: 1.5806572437286377
Validation loss: 2.079937063237672

Epoch: 6| Step: 10
Training loss: 1.9430153369903564
Validation loss: 2.0860832019518782

Epoch: 6| Step: 11
Training loss: 2.441120147705078
Validation loss: 2.0679630489759546

Epoch: 6| Step: 12
Training loss: 2.2442820072174072
Validation loss: 2.0594042654960387

Epoch: 6| Step: 13
Training loss: 1.8277955055236816
Validation loss: 2.068165765013746

Epoch: 99| Step: 0
Training loss: 2.4963808059692383
Validation loss: 2.0825120736193914

Epoch: 6| Step: 1
Training loss: 2.967555046081543
Validation loss: 2.067700950048303

Epoch: 6| Step: 2
Training loss: 2.0551400184631348
Validation loss: 2.0846804572689916

Epoch: 6| Step: 3
Training loss: 2.231649398803711
Validation loss: 2.08431331060266

Epoch: 6| Step: 4
Training loss: 1.8701322078704834
Validation loss: 2.0529383036398117

Epoch: 6| Step: 5
Training loss: 1.6204599142074585
Validation loss: 2.0898197004871983

Epoch: 6| Step: 6
Training loss: 2.055817127227783
Validation loss: 2.070993831080775

Epoch: 6| Step: 7
Training loss: 1.5874195098876953
Validation loss: 2.075571080689789

Epoch: 6| Step: 8
Training loss: 2.8796253204345703
Validation loss: 2.0533587330131122

Epoch: 6| Step: 9
Training loss: 2.2498228549957275
Validation loss: 2.0910510863027265

Epoch: 6| Step: 10
Training loss: 1.5910977125167847
Validation loss: 2.077748667809271

Epoch: 6| Step: 11
Training loss: 2.2138078212738037
Validation loss: 2.0739685335466937

Epoch: 6| Step: 12
Training loss: 2.335695743560791
Validation loss: 2.059802145086309

Epoch: 6| Step: 13
Training loss: 2.069091796875
Validation loss: 2.0871721941937684

Epoch: 100| Step: 0
Training loss: 2.7167224884033203
Validation loss: 2.086861305339362

Epoch: 6| Step: 1
Training loss: 2.333944797515869
Validation loss: 2.081625441069244

Epoch: 6| Step: 2
Training loss: 2.2712936401367188
Validation loss: 2.086717446645101

Epoch: 6| Step: 3
Training loss: 2.655242919921875
Validation loss: 2.1072518902440227

Epoch: 6| Step: 4
Training loss: 1.7479686737060547
Validation loss: 2.0780335985204226

Epoch: 6| Step: 5
Training loss: 1.6002323627471924
Validation loss: 2.073961880899245

Epoch: 6| Step: 6
Training loss: 2.753507375717163
Validation loss: 2.0632721839412564

Epoch: 6| Step: 7
Training loss: 2.005863666534424
Validation loss: 2.0671162579649236

Epoch: 6| Step: 8
Training loss: 2.051687717437744
Validation loss: 2.0742188807456725

Epoch: 6| Step: 9
Training loss: 2.2692368030548096
Validation loss: 2.0873015721639

Epoch: 6| Step: 10
Training loss: 1.5564076900482178
Validation loss: 2.0605660061682425

Epoch: 6| Step: 11
Training loss: 1.933115839958191
Validation loss: 2.0664317261788154

Epoch: 6| Step: 12
Training loss: 2.2328333854675293
Validation loss: 2.0941939853852793

Epoch: 6| Step: 13
Training loss: 1.9699816703796387
Validation loss: 2.076575579181794

Epoch: 101| Step: 0
Training loss: 2.2109150886535645
Validation loss: 2.0929476791812527

Epoch: 6| Step: 1
Training loss: 2.4008851051330566
Validation loss: 2.0648229199071086

Epoch: 6| Step: 2
Training loss: 1.7919089794158936
Validation loss: 2.0794149496222056

Epoch: 6| Step: 3
Training loss: 1.9116644859313965
Validation loss: 2.0737232110833608

Epoch: 6| Step: 4
Training loss: 1.9128220081329346
Validation loss: 2.0530664510624383

Epoch: 6| Step: 5
Training loss: 2.458250045776367
Validation loss: 2.058267572874664

Epoch: 6| Step: 6
Training loss: 2.6913106441497803
Validation loss: 2.0517943623245403

Epoch: 6| Step: 7
Training loss: 2.495242118835449
Validation loss: 2.048333256475387

Epoch: 6| Step: 8
Training loss: 2.4404590129852295
Validation loss: 2.0558146558782107

Epoch: 6| Step: 9
Training loss: 2.3554868698120117
Validation loss: 2.068551263501567

Epoch: 6| Step: 10
Training loss: 1.5132251977920532
Validation loss: 2.0738214344106694

Epoch: 6| Step: 11
Training loss: 1.8148112297058105
Validation loss: 2.033519423136147

Epoch: 6| Step: 12
Training loss: 2.2797346115112305
Validation loss: 2.055039546822989

Epoch: 6| Step: 13
Training loss: 1.6495813131332397
Validation loss: 2.0613861942803986

Epoch: 102| Step: 0
Training loss: 3.2018446922302246
Validation loss: 2.073172419301925

Epoch: 6| Step: 1
Training loss: 2.035928964614868
Validation loss: 2.0776349690652665

Epoch: 6| Step: 2
Training loss: 1.9957977533340454
Validation loss: 2.070988159025869

Epoch: 6| Step: 3
Training loss: 1.427863359451294
Validation loss: 2.066135257802984

Epoch: 6| Step: 4
Training loss: 1.9578053951263428
Validation loss: 2.0754591585487447

Epoch: 6| Step: 5
Training loss: 2.3347764015197754
Validation loss: 2.0958061243898127

Epoch: 6| Step: 6
Training loss: 2.029843807220459
Validation loss: 2.075403280155633

Epoch: 6| Step: 7
Training loss: 2.1318235397338867
Validation loss: 2.0810924678720455

Epoch: 6| Step: 8
Training loss: 1.9731444120407104
Validation loss: 2.0696009897416636

Epoch: 6| Step: 9
Training loss: 2.8018198013305664
Validation loss: 2.0931660770088114

Epoch: 6| Step: 10
Training loss: 2.3162496089935303
Validation loss: 2.077553447856698

Epoch: 6| Step: 11
Training loss: 1.5478812456130981
Validation loss: 2.0845126157165854

Epoch: 6| Step: 12
Training loss: 2.0005807876586914
Validation loss: 2.0943658851808116

Epoch: 6| Step: 13
Training loss: 2.2785820960998535
Validation loss: 2.0794460760649813

Epoch: 103| Step: 0
Training loss: 2.609755516052246
Validation loss: 2.067408646306684

Epoch: 6| Step: 1
Training loss: 2.764418125152588
Validation loss: 2.0646757592437086

Epoch: 6| Step: 2
Training loss: 1.7737400531768799
Validation loss: 2.098006368965231

Epoch: 6| Step: 3
Training loss: 1.9372494220733643
Validation loss: 2.0938438087381344

Epoch: 6| Step: 4
Training loss: 2.3683156967163086
Validation loss: 2.088717838769318

Epoch: 6| Step: 5
Training loss: 2.0040643215179443
Validation loss: 2.0893132866069837

Epoch: 6| Step: 6
Training loss: 2.500173568725586
Validation loss: 2.079622014876335

Epoch: 6| Step: 7
Training loss: 2.3457248210906982
Validation loss: 2.0871073199856665

Epoch: 6| Step: 8
Training loss: 2.1727943420410156
Validation loss: 2.0750080295788345

Epoch: 6| Step: 9
Training loss: 1.7747048139572144
Validation loss: 2.1061380858062417

Epoch: 6| Step: 10
Training loss: 1.9428846836090088
Validation loss: 2.0900838708364837

Epoch: 6| Step: 11
Training loss: 1.6003265380859375
Validation loss: 2.0856752357175274

Epoch: 6| Step: 12
Training loss: 2.6056737899780273
Validation loss: 2.093648038884645

Epoch: 6| Step: 13
Training loss: 1.498555064201355
Validation loss: 2.087801792288339

Epoch: 104| Step: 0
Training loss: 1.8431816101074219
Validation loss: 2.104057793976158

Epoch: 6| Step: 1
Training loss: 2.292804002761841
Validation loss: 2.082450561625983

Epoch: 6| Step: 2
Training loss: 1.7592990398406982
Validation loss: 2.0958550296803957

Epoch: 6| Step: 3
Training loss: 2.2243587970733643
Validation loss: 2.089958426772907

Epoch: 6| Step: 4
Training loss: 2.465916156768799
Validation loss: 2.087612972464613

Epoch: 6| Step: 5
Training loss: 1.9909663200378418
Validation loss: 2.0915067554802023

Epoch: 6| Step: 6
Training loss: 1.9030016660690308
Validation loss: 2.09293346763939

Epoch: 6| Step: 7
Training loss: 2.6643686294555664
Validation loss: 2.097605836006903

Epoch: 6| Step: 8
Training loss: 2.7407355308532715
Validation loss: 2.102545820256715

Epoch: 6| Step: 9
Training loss: 2.4984827041625977
Validation loss: 2.092748661195078

Epoch: 6| Step: 10
Training loss: 1.7856247425079346
Validation loss: 2.0901548388183757

Epoch: 6| Step: 11
Training loss: 2.0129098892211914
Validation loss: 2.0931145901321084

Epoch: 6| Step: 12
Training loss: 2.0896520614624023
Validation loss: 2.0864880366991927

Epoch: 6| Step: 13
Training loss: 1.3805568218231201
Validation loss: 2.0923577957255866

Epoch: 105| Step: 0
Training loss: 1.9737132787704468
Validation loss: 2.106253985435732

Epoch: 6| Step: 1
Training loss: 2.1036691665649414
Validation loss: 2.0940365278592674

Epoch: 6| Step: 2
Training loss: 1.752183437347412
Validation loss: 2.084830686610232

Epoch: 6| Step: 3
Training loss: 2.4188106060028076
Validation loss: 2.076670474903558

Epoch: 6| Step: 4
Training loss: 1.6655735969543457
Validation loss: 2.074937880680125

Epoch: 6| Step: 5
Training loss: 1.7808747291564941
Validation loss: 2.1085501511891684

Epoch: 6| Step: 6
Training loss: 1.7850570678710938
Validation loss: 2.0918159446408673

Epoch: 6| Step: 7
Training loss: 1.7701928615570068
Validation loss: 2.0834074148567776

Epoch: 6| Step: 8
Training loss: 2.5883102416992188
Validation loss: 2.0892560482025146

Epoch: 6| Step: 9
Training loss: 2.866546630859375
Validation loss: 2.076874158715689

Epoch: 6| Step: 10
Training loss: 2.06307053565979
Validation loss: 2.086990487190985

Epoch: 6| Step: 11
Training loss: 2.2229323387145996
Validation loss: 2.0611808043654247

Epoch: 6| Step: 12
Training loss: 2.3900914192199707
Validation loss: 2.0828060386001424

Epoch: 6| Step: 13
Training loss: 2.8942928314208984
Validation loss: 2.070916848797952

Epoch: 106| Step: 0
Training loss: 1.921770691871643
Validation loss: 2.076636763029201

Epoch: 6| Step: 1
Training loss: 1.9176926612854004
Validation loss: 2.077059652215691

Epoch: 6| Step: 2
Training loss: 1.5038630962371826
Validation loss: 2.0814314042368243

Epoch: 6| Step: 3
Training loss: 2.552496910095215
Validation loss: 2.0601594589089833

Epoch: 6| Step: 4
Training loss: 2.9116806983947754
Validation loss: 2.0865663431024037

Epoch: 6| Step: 5
Training loss: 1.5370001792907715
Validation loss: 2.076170413724838

Epoch: 6| Step: 6
Training loss: 2.3753347396850586
Validation loss: 2.0717302804352133

Epoch: 6| Step: 7
Training loss: 1.7977964878082275
Validation loss: 2.048678710896482

Epoch: 6| Step: 8
Training loss: 2.565431594848633
Validation loss: 2.0769696453566193

Epoch: 6| Step: 9
Training loss: 2.3537662029266357
Validation loss: 2.0550217115750877

Epoch: 6| Step: 10
Training loss: 2.0298945903778076
Validation loss: 2.082489094426555

Epoch: 6| Step: 11
Training loss: 1.9071414470672607
Validation loss: 2.0557396616987003

Epoch: 6| Step: 12
Training loss: 2.1916966438293457
Validation loss: 2.0755427140061573

Epoch: 6| Step: 13
Training loss: 2.75195574760437
Validation loss: 2.06762949369287

Epoch: 107| Step: 0
Training loss: 1.6572773456573486
Validation loss: 2.0642854077841646

Epoch: 6| Step: 1
Training loss: 2.2153444290161133
Validation loss: 2.0661864408882717

Epoch: 6| Step: 2
Training loss: 2.4043593406677246
Validation loss: 2.088913386867892

Epoch: 6| Step: 3
Training loss: 1.594684362411499
Validation loss: 2.080850085904521

Epoch: 6| Step: 4
Training loss: 2.4686508178710938
Validation loss: 2.0743982509900163

Epoch: 6| Step: 5
Training loss: 1.958566427230835
Validation loss: 2.1048024162169425

Epoch: 6| Step: 6
Training loss: 2.529745578765869
Validation loss: 2.0942462336632515

Epoch: 6| Step: 7
Training loss: 1.872260570526123
Validation loss: 2.082282143254434

Epoch: 6| Step: 8
Training loss: 2.1674396991729736
Validation loss: 2.0855494058260353

Epoch: 6| Step: 9
Training loss: 1.9958499670028687
Validation loss: 2.088471499822473

Epoch: 6| Step: 10
Training loss: 2.5596272945404053
Validation loss: 2.0616919148352837

Epoch: 6| Step: 11
Training loss: 2.398958921432495
Validation loss: 2.0803646887502363

Epoch: 6| Step: 12
Training loss: 1.932257890701294
Validation loss: 2.0782704020059235

Epoch: 6| Step: 13
Training loss: 2.067183256149292
Validation loss: 2.0710216517089517

Epoch: 108| Step: 0
Training loss: 2.1747448444366455
Validation loss: 2.0847062628756285

Epoch: 6| Step: 1
Training loss: 1.8988783359527588
Validation loss: 2.072127811370357

Epoch: 6| Step: 2
Training loss: 1.5779540538787842
Validation loss: 2.07412076252763

Epoch: 6| Step: 3
Training loss: 3.1589512825012207
Validation loss: 2.0749380229621806

Epoch: 6| Step: 4
Training loss: 2.1366610527038574
Validation loss: 2.074386412097562

Epoch: 6| Step: 5
Training loss: 2.732633113861084
Validation loss: 2.0669851418464416

Epoch: 6| Step: 6
Training loss: 2.28464412689209
Validation loss: 2.0874372323354087

Epoch: 6| Step: 7
Training loss: 0.9937645196914673
Validation loss: 2.0912292413814093

Epoch: 6| Step: 8
Training loss: 1.8748522996902466
Validation loss: 2.083713949367564

Epoch: 6| Step: 9
Training loss: 2.395723819732666
Validation loss: 2.0811769500855477

Epoch: 6| Step: 10
Training loss: 1.71268892288208
Validation loss: 2.0640030035408596

Epoch: 6| Step: 11
Training loss: 2.110226631164551
Validation loss: 2.0774862894447903

Epoch: 6| Step: 12
Training loss: 2.203878879547119
Validation loss: 2.070178942013812

Epoch: 6| Step: 13
Training loss: 2.8937485218048096
Validation loss: 2.0656990158942437

Epoch: 109| Step: 0
Training loss: 2.4552383422851562
Validation loss: 2.0660666650341404

Epoch: 6| Step: 1
Training loss: 1.8729034662246704
Validation loss: 2.070549172739829

Epoch: 6| Step: 2
Training loss: 1.9873684644699097
Validation loss: 2.0483190423698834

Epoch: 6| Step: 3
Training loss: 1.950083613395691
Validation loss: 2.053577378231992

Epoch: 6| Step: 4
Training loss: 2.0775766372680664
Validation loss: 2.07110664408694

Epoch: 6| Step: 5
Training loss: 2.3265819549560547
Validation loss: 2.097439553148003

Epoch: 6| Step: 6
Training loss: 2.6147313117980957
Validation loss: 2.0684927842950307

Epoch: 6| Step: 7
Training loss: 2.2867729663848877
Validation loss: 2.0606302727935133

Epoch: 6| Step: 8
Training loss: 2.0394492149353027
Validation loss: 2.0751462495455177

Epoch: 6| Step: 9
Training loss: 1.6879870891571045
Validation loss: 2.0870145854129585

Epoch: 6| Step: 10
Training loss: 1.8750255107879639
Validation loss: 2.0752471954591813

Epoch: 6| Step: 11
Training loss: 2.0100901126861572
Validation loss: 2.0729694404909687

Epoch: 6| Step: 12
Training loss: 2.8450822830200195
Validation loss: 2.084353977634061

Epoch: 6| Step: 13
Training loss: 1.72245192527771
Validation loss: 2.075253749406466

Epoch: 110| Step: 0
Training loss: 2.2586944103240967
Validation loss: 2.06576685367092

Epoch: 6| Step: 1
Training loss: 2.9641599655151367
Validation loss: 2.0701999125942105

Epoch: 6| Step: 2
Training loss: 2.3759095668792725
Validation loss: 2.0858172908906014

Epoch: 6| Step: 3
Training loss: 1.771956443786621
Validation loss: 2.07413689936361

Epoch: 6| Step: 4
Training loss: 2.9609243869781494
Validation loss: 2.082077524995291

Epoch: 6| Step: 5
Training loss: 1.7248494625091553
Validation loss: 2.0972754622018464

Epoch: 6| Step: 6
Training loss: 2.4160315990448
Validation loss: 2.072521389171641

Epoch: 6| Step: 7
Training loss: 2.2356700897216797
Validation loss: 2.0848016713255193

Epoch: 6| Step: 8
Training loss: 1.9134770631790161
Validation loss: 2.074294723490233

Epoch: 6| Step: 9
Training loss: 1.55869460105896
Validation loss: 2.091136118417145

Epoch: 6| Step: 10
Training loss: 2.055537700653076
Validation loss: 2.111891472211448

Epoch: 6| Step: 11
Training loss: 1.4711252450942993
Validation loss: 2.1044850131516815

Epoch: 6| Step: 12
Training loss: 1.7248822450637817
Validation loss: 2.0851300070362706

Epoch: 6| Step: 13
Training loss: 2.5270297527313232
Validation loss: 2.0892626444498696

Epoch: 111| Step: 0
Training loss: 2.6061978340148926
Validation loss: 2.086007446371099

Epoch: 6| Step: 1
Training loss: 1.6194782257080078
Validation loss: 2.0936524098919285

Epoch: 6| Step: 2
Training loss: 2.6072278022766113
Validation loss: 2.0813267538624425

Epoch: 6| Step: 3
Training loss: 2.85168719291687
Validation loss: 2.075114709074779

Epoch: 6| Step: 4
Training loss: 1.7772552967071533
Validation loss: 2.073293892286157

Epoch: 6| Step: 5
Training loss: 2.176644802093506
Validation loss: 2.077285712765109

Epoch: 6| Step: 6
Training loss: 2.0626211166381836
Validation loss: 2.0845421334748626

Epoch: 6| Step: 7
Training loss: 1.8913764953613281
Validation loss: 2.0906337563709547

Epoch: 6| Step: 8
Training loss: 2.2559096813201904
Validation loss: 2.0483816439105618

Epoch: 6| Step: 9
Training loss: 1.9377856254577637
Validation loss: 2.056538244729401

Epoch: 6| Step: 10
Training loss: 2.222527503967285
Validation loss: 2.0803188034283218

Epoch: 6| Step: 11
Training loss: 2.069223165512085
Validation loss: 2.0669640802568003

Epoch: 6| Step: 12
Training loss: 1.4460042715072632
Validation loss: 2.062975186173634

Epoch: 6| Step: 13
Training loss: 2.371601104736328
Validation loss: 2.0565474520447435

Epoch: 112| Step: 0
Training loss: 1.667825698852539
Validation loss: 2.0760380350133425

Epoch: 6| Step: 1
Training loss: 2.0566394329071045
Validation loss: 2.0528048930629605

Epoch: 6| Step: 2
Training loss: 2.2252767086029053
Validation loss: 2.0427190232020553

Epoch: 6| Step: 3
Training loss: 2.280703544616699
Validation loss: 2.0599373976389566

Epoch: 6| Step: 4
Training loss: 2.009763479232788
Validation loss: 2.070130632769677

Epoch: 6| Step: 5
Training loss: 2.391993522644043
Validation loss: 2.0649557164920274

Epoch: 6| Step: 6
Training loss: 1.826039433479309
Validation loss: 2.044595087728193

Epoch: 6| Step: 7
Training loss: 2.4899520874023438
Validation loss: 2.064190729971855

Epoch: 6| Step: 8
Training loss: 1.9845942258834839
Validation loss: 2.060187247491652

Epoch: 6| Step: 9
Training loss: 2.0578861236572266
Validation loss: 2.0581280621149207

Epoch: 6| Step: 10
Training loss: 2.34360933303833
Validation loss: 2.051880359649658

Epoch: 6| Step: 11
Training loss: 2.7781734466552734
Validation loss: 2.023441840243596

Epoch: 6| Step: 12
Training loss: 1.7294526100158691
Validation loss: 2.050878619634977

Epoch: 6| Step: 13
Training loss: 2.173057794570923
Validation loss: 2.0698307188608314

Epoch: 113| Step: 0
Training loss: 2.3500876426696777
Validation loss: 2.0394387322087444

Epoch: 6| Step: 1
Training loss: 2.3151557445526123
Validation loss: 2.0477635360533193

Epoch: 6| Step: 2
Training loss: 1.6266437768936157
Validation loss: 2.0426167172770344

Epoch: 6| Step: 3
Training loss: 2.4018733501434326
Validation loss: 2.0772360486368977

Epoch: 6| Step: 4
Training loss: 1.3409136533737183
Validation loss: 2.0516262451807656

Epoch: 6| Step: 5
Training loss: 1.9832184314727783
Validation loss: 2.076175082114435

Epoch: 6| Step: 6
Training loss: 2.3685550689697266
Validation loss: 2.0678964097012758

Epoch: 6| Step: 7
Training loss: 1.8969981670379639
Validation loss: 2.073147822451848

Epoch: 6| Step: 8
Training loss: 2.512092113494873
Validation loss: 2.0618639863947386

Epoch: 6| Step: 9
Training loss: 2.265401840209961
Validation loss: 2.0805358835445937

Epoch: 6| Step: 10
Training loss: 1.70747971534729
Validation loss: 2.0818807463492117

Epoch: 6| Step: 11
Training loss: 2.099154233932495
Validation loss: 2.0761134278389717

Epoch: 6| Step: 12
Training loss: 2.114328384399414
Validation loss: 2.0844888635860976

Epoch: 6| Step: 13
Training loss: 3.465623140335083
Validation loss: 2.0566280093244327

Epoch: 114| Step: 0
Training loss: 2.399975299835205
Validation loss: 2.0680013266942834

Epoch: 6| Step: 1
Training loss: 1.4105451107025146
Validation loss: 2.085083202649188

Epoch: 6| Step: 2
Training loss: 2.0050578117370605
Validation loss: 2.0625676006399174

Epoch: 6| Step: 3
Training loss: 2.452800750732422
Validation loss: 2.0577019978595037

Epoch: 6| Step: 4
Training loss: 2.1514811515808105
Validation loss: 2.0653308360807356

Epoch: 6| Step: 5
Training loss: 2.492177724838257
Validation loss: 2.0796493894310406

Epoch: 6| Step: 6
Training loss: 2.3504385948181152
Validation loss: 2.0591060807628017

Epoch: 6| Step: 7
Training loss: 1.562788724899292
Validation loss: 2.061080571143858

Epoch: 6| Step: 8
Training loss: 2.5517501831054688
Validation loss: 2.0678561528523765

Epoch: 6| Step: 9
Training loss: 1.5139377117156982
Validation loss: 2.064171616749097

Epoch: 6| Step: 10
Training loss: 2.5062499046325684
Validation loss: 2.0440377548176754

Epoch: 6| Step: 11
Training loss: 1.9766610860824585
Validation loss: 2.063331006675638

Epoch: 6| Step: 12
Training loss: 2.1552538871765137
Validation loss: 2.057185567835326

Epoch: 6| Step: 13
Training loss: 1.8919048309326172
Validation loss: 2.059837750209275

Epoch: 115| Step: 0
Training loss: 1.5827984809875488
Validation loss: 2.0647711958936465

Epoch: 6| Step: 1
Training loss: 1.7272984981536865
Validation loss: 2.0924887836620374

Epoch: 6| Step: 2
Training loss: 1.7884132862091064
Validation loss: 2.059406906045893

Epoch: 6| Step: 3
Training loss: 2.663715362548828
Validation loss: 2.0516762220731346

Epoch: 6| Step: 4
Training loss: 1.5514590740203857
Validation loss: 2.077214333318895

Epoch: 6| Step: 5
Training loss: 2.7276039123535156
Validation loss: 2.031504092677947

Epoch: 6| Step: 6
Training loss: 2.01845121383667
Validation loss: 2.0411631074002994

Epoch: 6| Step: 7
Training loss: 3.1332967281341553
Validation loss: 2.0455661050734983

Epoch: 6| Step: 8
Training loss: 1.6174458265304565
Validation loss: 2.049921690776784

Epoch: 6| Step: 9
Training loss: 2.1232457160949707
Validation loss: 2.057559105657762

Epoch: 6| Step: 10
Training loss: 2.2299203872680664
Validation loss: 2.0725882027738836

Epoch: 6| Step: 11
Training loss: 2.6120004653930664
Validation loss: 2.052661500951295

Epoch: 6| Step: 12
Training loss: 1.8876304626464844
Validation loss: 2.0735468172257945

Epoch: 6| Step: 13
Training loss: 2.0186731815338135
Validation loss: 2.0714253994726364

Epoch: 116| Step: 0
Training loss: 1.6927220821380615
Validation loss: 2.0611586365648495

Epoch: 6| Step: 1
Training loss: 2.1585073471069336
Validation loss: 2.053090400593255

Epoch: 6| Step: 2
Training loss: 1.888070821762085
Validation loss: 2.0619568414585565

Epoch: 6| Step: 3
Training loss: 2.165156602859497
Validation loss: 2.059691221483292

Epoch: 6| Step: 4
Training loss: 1.5590126514434814
Validation loss: 2.0398721720582698

Epoch: 6| Step: 5
Training loss: 2.048691511154175
Validation loss: 2.0465319220737745

Epoch: 6| Step: 6
Training loss: 2.3611440658569336
Validation loss: 2.0621809292865056

Epoch: 6| Step: 7
Training loss: 3.133510112762451
Validation loss: 2.040902555629771

Epoch: 6| Step: 8
Training loss: 2.735640048980713
Validation loss: 2.040522026759322

Epoch: 6| Step: 9
Training loss: 1.482500672340393
Validation loss: 2.0482332975633684

Epoch: 6| Step: 10
Training loss: 1.820603609085083
Validation loss: 2.0632319668287873

Epoch: 6| Step: 11
Training loss: 1.4759955406188965
Validation loss: 2.043731931717165

Epoch: 6| Step: 12
Training loss: 2.473926544189453
Validation loss: 2.0303212211978052

Epoch: 6| Step: 13
Training loss: 2.6262717247009277
Validation loss: 2.0615126650820494

Epoch: 117| Step: 0
Training loss: 1.9219022989273071
Validation loss: 2.0487684357550835

Epoch: 6| Step: 1
Training loss: 1.2914235591888428
Validation loss: 2.054670836335869

Epoch: 6| Step: 2
Training loss: 2.603043794631958
Validation loss: 2.0372669542989423

Epoch: 6| Step: 3
Training loss: 2.398594379425049
Validation loss: 2.0550383598573747

Epoch: 6| Step: 4
Training loss: 1.829230546951294
Validation loss: 2.053676070705537

Epoch: 6| Step: 5
Training loss: 2.046398878097534
Validation loss: 2.032499174917898

Epoch: 6| Step: 6
Training loss: 2.3798153400421143
Validation loss: 2.0387543785956597

Epoch: 6| Step: 7
Training loss: 2.264967918395996
Validation loss: 2.0427384068889003

Epoch: 6| Step: 8
Training loss: 2.651620626449585
Validation loss: 2.0594278227898384

Epoch: 6| Step: 9
Training loss: 1.6485798358917236
Validation loss: 2.052215387744288

Epoch: 6| Step: 10
Training loss: 1.991361141204834
Validation loss: 2.046200357457643

Epoch: 6| Step: 11
Training loss: 2.592109203338623
Validation loss: 2.0428895078679568

Epoch: 6| Step: 12
Training loss: 1.8315377235412598
Validation loss: 2.0588827953543714

Epoch: 6| Step: 13
Training loss: 2.5141689777374268
Validation loss: 2.0617739808174873

Epoch: 118| Step: 0
Training loss: 2.4496352672576904
Validation loss: 2.0352552398558585

Epoch: 6| Step: 1
Training loss: 1.5932013988494873
Validation loss: 2.0684728545527302

Epoch: 6| Step: 2
Training loss: 2.4368584156036377
Validation loss: 2.0453497773857525

Epoch: 6| Step: 3
Training loss: 2.4698147773742676
Validation loss: 2.0394806836241033

Epoch: 6| Step: 4
Training loss: 1.9824318885803223
Validation loss: 2.0591150586323073

Epoch: 6| Step: 5
Training loss: 2.2242331504821777
Validation loss: 2.040833871851685

Epoch: 6| Step: 6
Training loss: 2.277580976486206
Validation loss: 2.0356739208262455

Epoch: 6| Step: 7
Training loss: 1.8125171661376953
Validation loss: 2.054352787233168

Epoch: 6| Step: 8
Training loss: 2.575450897216797
Validation loss: 2.0560362172383133

Epoch: 6| Step: 9
Training loss: 2.096916675567627
Validation loss: 2.0523151313104937

Epoch: 6| Step: 10
Training loss: 1.8441493511199951
Validation loss: 2.0374520517164663

Epoch: 6| Step: 11
Training loss: 2.177051544189453
Validation loss: 2.0567739240584837

Epoch: 6| Step: 12
Training loss: 1.8927767276763916
Validation loss: 2.043578742652811

Epoch: 6| Step: 13
Training loss: 0.9844250082969666
Validation loss: 2.0626710461032007

Epoch: 119| Step: 0
Training loss: 2.2690212726593018
Validation loss: 2.0527388229165027

Epoch: 6| Step: 1
Training loss: 2.6586875915527344
Validation loss: 2.0578762600498814

Epoch: 6| Step: 2
Training loss: 2.4812674522399902
Validation loss: 2.0606108685975433

Epoch: 6| Step: 3
Training loss: 1.2496774196624756
Validation loss: 2.038985442089778

Epoch: 6| Step: 4
Training loss: 1.581030011177063
Validation loss: 2.0867363663129908

Epoch: 6| Step: 5
Training loss: 2.0517890453338623
Validation loss: 2.083672749098911

Epoch: 6| Step: 6
Training loss: 1.9074392318725586
Validation loss: 2.0681020700803368

Epoch: 6| Step: 7
Training loss: 2.181471824645996
Validation loss: 2.0620819778852564

Epoch: 6| Step: 8
Training loss: 2.699552059173584
Validation loss: 2.062987550612419

Epoch: 6| Step: 9
Training loss: 1.9848365783691406
Validation loss: 2.0808390289224605

Epoch: 6| Step: 10
Training loss: 2.5699872970581055
Validation loss: 2.0648930098420832

Epoch: 6| Step: 11
Training loss: 1.9050168991088867
Validation loss: 2.056292878684177

Epoch: 6| Step: 12
Training loss: 1.6243565082550049
Validation loss: 2.0678556580697336

Epoch: 6| Step: 13
Training loss: 2.258115768432617
Validation loss: 2.0693398701247347

Epoch: 120| Step: 0
Training loss: 2.3132834434509277
Validation loss: 2.090538204357188

Epoch: 6| Step: 1
Training loss: 1.8535430431365967
Validation loss: 2.0403935217088267

Epoch: 6| Step: 2
Training loss: 2.539177417755127
Validation loss: 2.0448492316789526

Epoch: 6| Step: 3
Training loss: 1.639636754989624
Validation loss: 2.059570083054163

Epoch: 6| Step: 4
Training loss: 1.6989935636520386
Validation loss: 2.0522007250016734

Epoch: 6| Step: 5
Training loss: 2.243974208831787
Validation loss: 2.0471622379877235

Epoch: 6| Step: 6
Training loss: 2.396221876144409
Validation loss: 2.03623451212401

Epoch: 6| Step: 7
Training loss: 1.8607475757598877
Validation loss: 2.049490628703948

Epoch: 6| Step: 8
Training loss: 2.3243825435638428
Validation loss: 2.0616978958088863

Epoch: 6| Step: 9
Training loss: 1.8430538177490234
Validation loss: 2.0467684192042195

Epoch: 6| Step: 10
Training loss: 2.4608051776885986
Validation loss: 2.05939906643283

Epoch: 6| Step: 11
Training loss: 2.0090556144714355
Validation loss: 2.0393247142914803

Epoch: 6| Step: 12
Training loss: 2.0900189876556396
Validation loss: 2.040780718608569

Epoch: 6| Step: 13
Training loss: 2.4099035263061523
Validation loss: 2.0570069513013287

Epoch: 121| Step: 0
Training loss: 1.635350227355957
Validation loss: 2.0480566473417383

Epoch: 6| Step: 1
Training loss: 2.431565284729004
Validation loss: 2.041487483568089

Epoch: 6| Step: 2
Training loss: 2.0332131385803223
Validation loss: 2.0419108021643853

Epoch: 6| Step: 3
Training loss: 2.4522321224212646
Validation loss: 2.0141055532681045

Epoch: 6| Step: 4
Training loss: 2.0868237018585205
Validation loss: 2.0276811712531635

Epoch: 6| Step: 5
Training loss: 1.8073649406433105
Validation loss: 2.047416365274819

Epoch: 6| Step: 6
Training loss: 1.772108793258667
Validation loss: 2.0531691543517576

Epoch: 6| Step: 7
Training loss: 2.385693311691284
Validation loss: 2.0590117926238687

Epoch: 6| Step: 8
Training loss: 2.1070194244384766
Validation loss: 2.030942779715343

Epoch: 6| Step: 9
Training loss: 2.8548789024353027
Validation loss: 2.0358109063999628

Epoch: 6| Step: 10
Training loss: 2.2435734272003174
Validation loss: 2.0486877169660342

Epoch: 6| Step: 11
Training loss: 1.9138259887695312
Validation loss: 2.0392152135090162

Epoch: 6| Step: 12
Training loss: 1.7014015913009644
Validation loss: 2.0541265703016713

Epoch: 6| Step: 13
Training loss: 2.337646007537842
Validation loss: 2.0350395479509906

Epoch: 122| Step: 0
Training loss: 1.773040533065796
Validation loss: 2.0358369863161476

Epoch: 6| Step: 1
Training loss: 1.9679577350616455
Validation loss: 2.0658900019943074

Epoch: 6| Step: 2
Training loss: 2.216769218444824
Validation loss: 2.026056653709822

Epoch: 6| Step: 3
Training loss: 1.3899099826812744
Validation loss: 2.0472195956014816

Epoch: 6| Step: 4
Training loss: 2.3179268836975098
Validation loss: 2.0476715257090907

Epoch: 6| Step: 5
Training loss: 2.342655658721924
Validation loss: 2.0468970037275747

Epoch: 6| Step: 6
Training loss: 1.886272668838501
Validation loss: 2.040982554035802

Epoch: 6| Step: 7
Training loss: 2.549966335296631
Validation loss: 2.0483090774987334

Epoch: 6| Step: 8
Training loss: 2.809304714202881
Validation loss: 2.0647361560534407

Epoch: 6| Step: 9
Training loss: 2.0810611248016357
Validation loss: 2.069222537420129

Epoch: 6| Step: 10
Training loss: 1.9168591499328613
Validation loss: 2.0455949024487565

Epoch: 6| Step: 11
Training loss: 2.2169852256774902
Validation loss: 2.046740516539543

Epoch: 6| Step: 12
Training loss: 1.8697919845581055
Validation loss: 2.053341575848159

Epoch: 6| Step: 13
Training loss: 1.8659120798110962
Validation loss: 2.05251040509952

Epoch: 123| Step: 0
Training loss: 2.555241107940674
Validation loss: 2.061882884271683

Epoch: 6| Step: 1
Training loss: 2.0407981872558594
Validation loss: 2.055592897117779

Epoch: 6| Step: 2
Training loss: 2.420588731765747
Validation loss: 2.0641679263884023

Epoch: 6| Step: 3
Training loss: 2.6154656410217285
Validation loss: 2.052608823263517

Epoch: 6| Step: 4
Training loss: 1.9736812114715576
Validation loss: 2.07095403568719

Epoch: 6| Step: 5
Training loss: 1.9719308614730835
Validation loss: 2.0717075332518546

Epoch: 6| Step: 6
Training loss: 2.0108046531677246
Validation loss: 2.0580164578653153

Epoch: 6| Step: 7
Training loss: 1.8371472358703613
Validation loss: 2.0597467089212067

Epoch: 6| Step: 8
Training loss: 2.275059223175049
Validation loss: 2.073575145454817

Epoch: 6| Step: 9
Training loss: 1.9383430480957031
Validation loss: 2.048169838484897

Epoch: 6| Step: 10
Training loss: 1.8955793380737305
Validation loss: 2.078928442411525

Epoch: 6| Step: 11
Training loss: 2.2311489582061768
Validation loss: 2.049874687707552

Epoch: 6| Step: 12
Training loss: 1.556516408920288
Validation loss: 2.069606836124133

Epoch: 6| Step: 13
Training loss: 1.7588211297988892
Validation loss: 2.086392738485849

Epoch: 124| Step: 0
Training loss: 1.5757997035980225
Validation loss: 2.053311309506816

Epoch: 6| Step: 1
Training loss: 2.667062759399414
Validation loss: 2.0387487385862615

Epoch: 6| Step: 2
Training loss: 2.945720672607422
Validation loss: 2.0542483022136073

Epoch: 6| Step: 3
Training loss: 1.763449788093567
Validation loss: 2.062494477918071

Epoch: 6| Step: 4
Training loss: 2.432187080383301
Validation loss: 2.0523265664295485

Epoch: 6| Step: 5
Training loss: 1.5281965732574463
Validation loss: 2.0750745906624743

Epoch: 6| Step: 6
Training loss: 2.4614295959472656
Validation loss: 2.0291181559203775

Epoch: 6| Step: 7
Training loss: 2.2837390899658203
Validation loss: 2.0693382883584626

Epoch: 6| Step: 8
Training loss: 2.2531189918518066
Validation loss: 2.037750526141095

Epoch: 6| Step: 9
Training loss: 2.4131839275360107
Validation loss: 2.035599325292854

Epoch: 6| Step: 10
Training loss: 1.8903700113296509
Validation loss: 2.0592095134078816

Epoch: 6| Step: 11
Training loss: 1.4501584768295288
Validation loss: 2.032004584548294

Epoch: 6| Step: 12
Training loss: 1.6086304187774658
Validation loss: 2.050175165617338

Epoch: 6| Step: 13
Training loss: 2.0683844089508057
Validation loss: 2.050830703909679

Epoch: 125| Step: 0
Training loss: 2.288252115249634
Validation loss: 2.0468997032411638

Epoch: 6| Step: 1
Training loss: 2.4055118560791016
Validation loss: 2.0551933832066034

Epoch: 6| Step: 2
Training loss: 1.8300635814666748
Validation loss: 2.056714762923538

Epoch: 6| Step: 3
Training loss: 2.273129940032959
Validation loss: 2.0530853245847966

Epoch: 6| Step: 4
Training loss: 2.789733409881592
Validation loss: 2.0509895432379937

Epoch: 6| Step: 5
Training loss: 2.2666983604431152
Validation loss: 2.0416431427001953

Epoch: 6| Step: 6
Training loss: 2.7289509773254395
Validation loss: 2.0562458192148516

Epoch: 6| Step: 7
Training loss: 1.4363839626312256
Validation loss: 2.0601480353263115

Epoch: 6| Step: 8
Training loss: 1.694615364074707
Validation loss: 2.0719239557943037

Epoch: 6| Step: 9
Training loss: 1.8635237216949463
Validation loss: 2.086601065051171

Epoch: 6| Step: 10
Training loss: 1.891897201538086
Validation loss: 2.055188545616724

Epoch: 6| Step: 11
Training loss: 2.334613800048828
Validation loss: 2.0518373225324895

Epoch: 6| Step: 12
Training loss: 1.366347312927246
Validation loss: 2.0631998867116947

Epoch: 6| Step: 13
Training loss: 2.270197629928589
Validation loss: 2.0657687443558888

Epoch: 126| Step: 0
Training loss: 3.1264235973358154
Validation loss: 2.069500747547355

Epoch: 6| Step: 1
Training loss: 1.7646775245666504
Validation loss: 2.0583398726678666

Epoch: 6| Step: 2
Training loss: 2.4459662437438965
Validation loss: 2.07421971905616

Epoch: 6| Step: 3
Training loss: 2.0218405723571777
Validation loss: 2.0730319817860923

Epoch: 6| Step: 4
Training loss: 2.2990806102752686
Validation loss: 2.0498039260987313

Epoch: 6| Step: 5
Training loss: 2.068085193634033
Validation loss: 2.0649486869894047

Epoch: 6| Step: 6
Training loss: 1.6142804622650146
Validation loss: 2.0471398138230845

Epoch: 6| Step: 7
Training loss: 2.238800287246704
Validation loss: 2.0520426022109164

Epoch: 6| Step: 8
Training loss: 1.9364428520202637
Validation loss: 2.0408917447572112

Epoch: 6| Step: 9
Training loss: 2.0628397464752197
Validation loss: 2.056162643176253

Epoch: 6| Step: 10
Training loss: 1.4550057649612427
Validation loss: 2.0578005185691257

Epoch: 6| Step: 11
Training loss: 2.2729530334472656
Validation loss: 2.0519078854591615

Epoch: 6| Step: 12
Training loss: 1.9343534708023071
Validation loss: 2.062739513253653

Epoch: 6| Step: 13
Training loss: 1.8112871646881104
Validation loss: 2.0547583077543523

Epoch: 127| Step: 0
Training loss: 2.383329391479492
Validation loss: 2.0445924958875104

Epoch: 6| Step: 1
Training loss: 1.5201319456100464
Validation loss: 2.0177230347869215

Epoch: 6| Step: 2
Training loss: 2.8737130165100098
Validation loss: 2.020363002695063

Epoch: 6| Step: 3
Training loss: 2.532546043395996
Validation loss: 2.0778680052808536

Epoch: 6| Step: 4
Training loss: 1.6588654518127441
Validation loss: 2.03600335890247

Epoch: 6| Step: 5
Training loss: 2.1763339042663574
Validation loss: 2.052876962128506

Epoch: 6| Step: 6
Training loss: 1.5893845558166504
Validation loss: 2.0614317488926712

Epoch: 6| Step: 7
Training loss: 1.852315902709961
Validation loss: 2.0455705273535942

Epoch: 6| Step: 8
Training loss: 2.4049811363220215
Validation loss: 2.016726302844222

Epoch: 6| Step: 9
Training loss: 2.077619791030884
Validation loss: 2.0318205612961964

Epoch: 6| Step: 10
Training loss: 2.148242712020874
Validation loss: 2.0487502659520795

Epoch: 6| Step: 11
Training loss: 1.963545799255371
Validation loss: 2.033803729600804

Epoch: 6| Step: 12
Training loss: 1.8688541650772095
Validation loss: 2.0417595576214533

Epoch: 6| Step: 13
Training loss: 2.4629600048065186
Validation loss: 2.0486159529737247

Epoch: 128| Step: 0
Training loss: 2.1047606468200684
Validation loss: 2.0421735445658364

Epoch: 6| Step: 1
Training loss: 1.6913883686065674
Validation loss: 2.0380209517735306

Epoch: 6| Step: 2
Training loss: 3.0151915550231934
Validation loss: 2.0277283435226767

Epoch: 6| Step: 3
Training loss: 1.8508086204528809
Validation loss: 2.029498815536499

Epoch: 6| Step: 4
Training loss: 1.68717622756958
Validation loss: 2.0334132512410483

Epoch: 6| Step: 5
Training loss: 1.546872615814209
Validation loss: 2.0145806471506753

Epoch: 6| Step: 6
Training loss: 1.925882339477539
Validation loss: 2.0321325627706384

Epoch: 6| Step: 7
Training loss: 2.03175687789917
Validation loss: 2.027771443449041

Epoch: 6| Step: 8
Training loss: 3.1022238731384277
Validation loss: 2.0402144206467496

Epoch: 6| Step: 9
Training loss: 2.5910449028015137
Validation loss: 2.0343392408022316

Epoch: 6| Step: 10
Training loss: 1.9376617670059204
Validation loss: 2.0528046623353036

Epoch: 6| Step: 11
Training loss: 1.8681713342666626
Validation loss: 2.0170078944134455

Epoch: 6| Step: 12
Training loss: 1.9386664628982544
Validation loss: 2.029435174439543

Epoch: 6| Step: 13
Training loss: 1.5710148811340332
Validation loss: 2.038630272752495

Epoch: 129| Step: 0
Training loss: 2.1305534839630127
Validation loss: 2.0323975829667944

Epoch: 6| Step: 1
Training loss: 1.670691967010498
Validation loss: 2.034182785659708

Epoch: 6| Step: 2
Training loss: 2.805428981781006
Validation loss: 2.0300929161810104

Epoch: 6| Step: 3
Training loss: 2.141160011291504
Validation loss: 2.0460793664378505

Epoch: 6| Step: 4
Training loss: 1.578306794166565
Validation loss: 2.047990349031264

Epoch: 6| Step: 5
Training loss: 1.701271891593933
Validation loss: 2.0499444418056036

Epoch: 6| Step: 6
Training loss: 2.1119542121887207
Validation loss: 2.049044562924293

Epoch: 6| Step: 7
Training loss: 1.8706468343734741
Validation loss: 2.0338521849724556

Epoch: 6| Step: 8
Training loss: 2.4491286277770996
Validation loss: 2.0293686107922624

Epoch: 6| Step: 9
Training loss: 1.9416035413742065
Validation loss: 2.0537846114045832

Epoch: 6| Step: 10
Training loss: 2.0362749099731445
Validation loss: 2.0504027694784184

Epoch: 6| Step: 11
Training loss: 2.4198341369628906
Validation loss: 2.051460709623111

Epoch: 6| Step: 12
Training loss: 2.1918067932128906
Validation loss: 2.039425334622783

Epoch: 6| Step: 13
Training loss: 2.020637273788452
Validation loss: 2.0466328769601803

Epoch: 130| Step: 0
Training loss: 1.9514273405075073
Validation loss: 2.064904382151942

Epoch: 6| Step: 1
Training loss: 1.7540321350097656
Validation loss: 2.022872333885521

Epoch: 6| Step: 2
Training loss: 1.6797194480895996
Validation loss: 2.0536779601086854

Epoch: 6| Step: 3
Training loss: 2.3726649284362793
Validation loss: 2.0421934999445432

Epoch: 6| Step: 4
Training loss: 1.5957963466644287
Validation loss: 2.0486627112152758

Epoch: 6| Step: 5
Training loss: 1.676024317741394
Validation loss: 2.048068000424293

Epoch: 6| Step: 6
Training loss: 2.109916925430298
Validation loss: 2.041131768175351

Epoch: 6| Step: 7
Training loss: 2.4115219116210938
Validation loss: 2.03297528143852

Epoch: 6| Step: 8
Training loss: 2.1396756172180176
Validation loss: 2.047323940902628

Epoch: 6| Step: 9
Training loss: 2.518573760986328
Validation loss: 2.0511496900230326

Epoch: 6| Step: 10
Training loss: 2.1944127082824707
Validation loss: 2.049253535527055

Epoch: 6| Step: 11
Training loss: 2.4267115592956543
Validation loss: 2.017988037037593

Epoch: 6| Step: 12
Training loss: 1.5638347864151
Validation loss: 2.0600742998943535

Epoch: 6| Step: 13
Training loss: 2.796196222305298
Validation loss: 2.0311546735866095

Epoch: 131| Step: 0
Training loss: 1.720941185951233
Validation loss: 2.052931011364024

Epoch: 6| Step: 1
Training loss: 2.6827449798583984
Validation loss: 2.053595777480833

Epoch: 6| Step: 2
Training loss: 1.3330183029174805
Validation loss: 2.0411217469041065

Epoch: 6| Step: 3
Training loss: 1.962093472480774
Validation loss: 2.0604389021473546

Epoch: 6| Step: 4
Training loss: 1.9990804195404053
Validation loss: 2.055194151016974

Epoch: 6| Step: 5
Training loss: 1.7938604354858398
Validation loss: 2.0232483904848815

Epoch: 6| Step: 6
Training loss: 2.2390596866607666
Validation loss: 2.067444432166315

Epoch: 6| Step: 7
Training loss: 2.8602097034454346
Validation loss: 2.0751638412475586

Epoch: 6| Step: 8
Training loss: 1.9810999631881714
Validation loss: 2.050242195847214

Epoch: 6| Step: 9
Training loss: 1.717769742012024
Validation loss: 2.0469131726090626

Epoch: 6| Step: 10
Training loss: 1.2881901264190674
Validation loss: 2.0464443186277985

Epoch: 6| Step: 11
Training loss: 3.1164655685424805
Validation loss: 2.0265739258899482

Epoch: 6| Step: 12
Training loss: 1.7188591957092285
Validation loss: 2.0753770605210335

Epoch: 6| Step: 13
Training loss: 2.8808581829071045
Validation loss: 2.0518692385765815

Epoch: 132| Step: 0
Training loss: 2.1600897312164307
Validation loss: 2.0512622325651106

Epoch: 6| Step: 1
Training loss: 1.806221604347229
Validation loss: 2.065903966144849

Epoch: 6| Step: 2
Training loss: 2.5829195976257324
Validation loss: 2.033811935814478

Epoch: 6| Step: 3
Training loss: 1.849838376045227
Validation loss: 2.0363871974329792

Epoch: 6| Step: 4
Training loss: 2.484837770462036
Validation loss: 2.0485262140150993

Epoch: 6| Step: 5
Training loss: 2.0853285789489746
Validation loss: 2.060609940559633

Epoch: 6| Step: 6
Training loss: 1.975813388824463
Validation loss: 2.0417365899649997

Epoch: 6| Step: 7
Training loss: 1.8342554569244385
Validation loss: 2.055810518162225

Epoch: 6| Step: 8
Training loss: 2.417572498321533
Validation loss: 2.0448106053054973

Epoch: 6| Step: 9
Training loss: 2.2635533809661865
Validation loss: 2.0623741406266407

Epoch: 6| Step: 10
Training loss: 1.9404771327972412
Validation loss: 2.0230117651724044

Epoch: 6| Step: 11
Training loss: 1.9683194160461426
Validation loss: 2.0648924355865805

Epoch: 6| Step: 12
Training loss: 1.7724127769470215
Validation loss: 2.0475132375635128

Epoch: 6| Step: 13
Training loss: 1.8078149557113647
Validation loss: 2.0481936803428074

Epoch: 133| Step: 0
Training loss: 1.4255127906799316
Validation loss: 2.038863533286638

Epoch: 6| Step: 1
Training loss: 1.7037841081619263
Validation loss: 2.0139417071496286

Epoch: 6| Step: 2
Training loss: 1.804445505142212
Validation loss: 2.0343864028171827

Epoch: 6| Step: 3
Training loss: 1.8628487586975098
Validation loss: 2.0267952539587535

Epoch: 6| Step: 4
Training loss: 2.060304641723633
Validation loss: 2.0375733580640567

Epoch: 6| Step: 5
Training loss: 2.1402904987335205
Validation loss: 2.019591713464388

Epoch: 6| Step: 6
Training loss: 2.39517879486084
Validation loss: 2.041938025464294

Epoch: 6| Step: 7
Training loss: 2.0423970222473145
Validation loss: 2.029612395071214

Epoch: 6| Step: 8
Training loss: 3.0115137100219727
Validation loss: 2.0026590208853445

Epoch: 6| Step: 9
Training loss: 1.8725173473358154
Validation loss: 2.037721223728631

Epoch: 6| Step: 10
Training loss: 2.952524185180664
Validation loss: 2.0257210039323374

Epoch: 6| Step: 11
Training loss: 1.8757096529006958
Validation loss: 2.0609760553606096

Epoch: 6| Step: 12
Training loss: 1.5858150720596313
Validation loss: 2.0251462562109834

Epoch: 6| Step: 13
Training loss: 2.234978675842285
Validation loss: 2.0033565490476546

Epoch: 134| Step: 0
Training loss: 2.2590067386627197
Validation loss: 2.0171630459447063

Epoch: 6| Step: 1
Training loss: 2.4111390113830566
Validation loss: 2.012928052615094

Epoch: 6| Step: 2
Training loss: 2.301285743713379
Validation loss: 2.030560073032174

Epoch: 6| Step: 3
Training loss: 2.1600756645202637
Validation loss: 2.0096295636187316

Epoch: 6| Step: 4
Training loss: 1.5433101654052734
Validation loss: 2.031547220804358

Epoch: 6| Step: 5
Training loss: 2.4634604454040527
Validation loss: 2.034087875837921

Epoch: 6| Step: 6
Training loss: 1.8259236812591553
Validation loss: 2.0358911022063224

Epoch: 6| Step: 7
Training loss: 1.4859908819198608
Validation loss: 2.0211133649272304

Epoch: 6| Step: 8
Training loss: 2.522418975830078
Validation loss: 2.0313898337784635

Epoch: 6| Step: 9
Training loss: 1.9106284379959106
Validation loss: 2.0227885720550374

Epoch: 6| Step: 10
Training loss: 2.5160980224609375
Validation loss: 2.012667259862346

Epoch: 6| Step: 11
Training loss: 1.5692288875579834
Validation loss: 2.0604046595993863

Epoch: 6| Step: 12
Training loss: 2.1940953731536865
Validation loss: 2.0429756897752003

Epoch: 6| Step: 13
Training loss: 1.5248228311538696
Validation loss: 2.047505577405294

Epoch: 135| Step: 0
Training loss: 1.894405722618103
Validation loss: 2.0352611977566957

Epoch: 6| Step: 1
Training loss: 2.299682140350342
Validation loss: 2.019773885767947

Epoch: 6| Step: 2
Training loss: 1.924098014831543
Validation loss: 2.0389963503806823

Epoch: 6| Step: 3
Training loss: 1.7542872428894043
Validation loss: 2.0300956913219985

Epoch: 6| Step: 4
Training loss: 2.4658613204956055
Validation loss: 2.0445000048606627

Epoch: 6| Step: 5
Training loss: 1.8471845388412476
Validation loss: 2.039293857030971

Epoch: 6| Step: 6
Training loss: 1.6486167907714844
Validation loss: 2.036957727965488

Epoch: 6| Step: 7
Training loss: 2.2505743503570557
Validation loss: 2.0424267015149518

Epoch: 6| Step: 8
Training loss: 1.6280722618103027
Validation loss: 2.049188624146164

Epoch: 6| Step: 9
Training loss: 2.4199390411376953
Validation loss: 2.047398159580846

Epoch: 6| Step: 10
Training loss: 2.367659568786621
Validation loss: 2.0578632457281953

Epoch: 6| Step: 11
Training loss: 1.919353723526001
Validation loss: 2.0454024217462026

Epoch: 6| Step: 12
Training loss: 2.037322521209717
Validation loss: 2.035706950772193

Epoch: 6| Step: 13
Training loss: 2.368124485015869
Validation loss: 2.0369273411330355

Epoch: 136| Step: 0
Training loss: 2.0825178623199463
Validation loss: 2.0412525823039394

Epoch: 6| Step: 1
Training loss: 1.8342772722244263
Validation loss: 2.0625860255251647

Epoch: 6| Step: 2
Training loss: 1.7325379848480225
Validation loss: 2.0243876749469387

Epoch: 6| Step: 3
Training loss: 2.214888095855713
Validation loss: 2.0458575589682466

Epoch: 6| Step: 4
Training loss: 1.583949327468872
Validation loss: 2.0423682479448217

Epoch: 6| Step: 5
Training loss: 2.5268936157226562
Validation loss: 2.0296081881369314

Epoch: 6| Step: 6
Training loss: 1.830165147781372
Validation loss: 2.018336034590198

Epoch: 6| Step: 7
Training loss: 2.3124585151672363
Validation loss: 2.0263298391014017

Epoch: 6| Step: 8
Training loss: 1.6339712142944336
Validation loss: 2.045786328213189

Epoch: 6| Step: 9
Training loss: 2.9235806465148926
Validation loss: 2.046752711778046

Epoch: 6| Step: 10
Training loss: 2.0508713722229004
Validation loss: 2.0255634297606764

Epoch: 6| Step: 11
Training loss: 1.9099466800689697
Validation loss: 2.04119421205213

Epoch: 6| Step: 12
Training loss: 2.641944408416748
Validation loss: 2.0245995662545644

Epoch: 6| Step: 13
Training loss: 1.179530382156372
Validation loss: 2.028364558373728

Epoch: 137| Step: 0
Training loss: 1.7825874090194702
Validation loss: 2.0359677294249177

Epoch: 6| Step: 1
Training loss: 2.062117099761963
Validation loss: 2.0415463755207677

Epoch: 6| Step: 2
Training loss: 2.252340316772461
Validation loss: 2.0320844201631445

Epoch: 6| Step: 3
Training loss: 2.2417640686035156
Validation loss: 2.0347420323279595

Epoch: 6| Step: 4
Training loss: 2.434917449951172
Validation loss: 2.027534451535953

Epoch: 6| Step: 5
Training loss: 1.4358984231948853
Validation loss: 2.03205919009383

Epoch: 6| Step: 6
Training loss: 2.273073196411133
Validation loss: 2.0483177272222375

Epoch: 6| Step: 7
Training loss: 2.55460786819458
Validation loss: 2.059033255423269

Epoch: 6| Step: 8
Training loss: 1.8398135900497437
Validation loss: 2.0386238444236016

Epoch: 6| Step: 9
Training loss: 1.997306227684021
Validation loss: 2.0192928160390546

Epoch: 6| Step: 10
Training loss: 1.6820210218429565
Validation loss: 2.029939410507038

Epoch: 6| Step: 11
Training loss: 1.8655123710632324
Validation loss: 2.0129803201203704

Epoch: 6| Step: 12
Training loss: 2.300128936767578
Validation loss: 2.0370007215007657

Epoch: 6| Step: 13
Training loss: 2.1426095962524414
Validation loss: 2.0548796243565057

Epoch: 138| Step: 0
Training loss: 2.0506014823913574
Validation loss: 2.0410221571563394

Epoch: 6| Step: 1
Training loss: 2.412700891494751
Validation loss: 2.018323040777637

Epoch: 6| Step: 2
Training loss: 2.7383646965026855
Validation loss: 2.034272578454787

Epoch: 6| Step: 3
Training loss: 1.616052508354187
Validation loss: 2.0515485796877133

Epoch: 6| Step: 4
Training loss: 2.199636936187744
Validation loss: 2.042412281036377

Epoch: 6| Step: 5
Training loss: 2.7292985916137695
Validation loss: 2.0405290434437413

Epoch: 6| Step: 6
Training loss: 1.3498072624206543
Validation loss: 2.037431146508904

Epoch: 6| Step: 7
Training loss: 2.1157631874084473
Validation loss: 2.0546423658247916

Epoch: 6| Step: 8
Training loss: 1.719063639640808
Validation loss: 2.037460352784844

Epoch: 6| Step: 9
Training loss: 2.2549803256988525
Validation loss: 2.0398319921185895

Epoch: 6| Step: 10
Training loss: 1.9347076416015625
Validation loss: 2.030066769610169

Epoch: 6| Step: 11
Training loss: 1.6710565090179443
Validation loss: 2.0353688783543085

Epoch: 6| Step: 12
Training loss: 1.6468514204025269
Validation loss: 2.040059507534068

Epoch: 6| Step: 13
Training loss: 2.443077564239502
Validation loss: 2.0204761041108

Epoch: 139| Step: 0
Training loss: 1.9649772644042969
Validation loss: 2.0470120829920613

Epoch: 6| Step: 1
Training loss: 2.195432186126709
Validation loss: 2.0512067310271727

Epoch: 6| Step: 2
Training loss: 1.8897947072982788
Validation loss: 2.067275462612029

Epoch: 6| Step: 3
Training loss: 2.154550075531006
Validation loss: 2.057617356700282

Epoch: 6| Step: 4
Training loss: 2.090452194213867
Validation loss: 2.0451803899580434

Epoch: 6| Step: 5
Training loss: 1.9534666538238525
Validation loss: 2.0493114353508077

Epoch: 6| Step: 6
Training loss: 2.0181665420532227
Validation loss: 2.0547854259449947

Epoch: 6| Step: 7
Training loss: 1.7154650688171387
Validation loss: 2.036789490330604

Epoch: 6| Step: 8
Training loss: 1.7605814933776855
Validation loss: 2.02722184119686

Epoch: 6| Step: 9
Training loss: 2.245175361633301
Validation loss: 2.029554905429963

Epoch: 6| Step: 10
Training loss: 1.7054028511047363
Validation loss: 2.0519618808582263

Epoch: 6| Step: 11
Training loss: 2.735828399658203
Validation loss: 2.0341626662080006

Epoch: 6| Step: 12
Training loss: 2.107161045074463
Validation loss: 2.05958124642731

Epoch: 6| Step: 13
Training loss: 2.3304734230041504
Validation loss: 2.041337263199591

Epoch: 140| Step: 0
Training loss: 1.8743736743927002
Validation loss: 2.0396183895808395

Epoch: 6| Step: 1
Training loss: 1.9181469678878784
Validation loss: 2.041356389240552

Epoch: 6| Step: 2
Training loss: 2.353025197982788
Validation loss: 2.0397568825752503

Epoch: 6| Step: 3
Training loss: 2.816925287246704
Validation loss: 2.0291033957594182

Epoch: 6| Step: 4
Training loss: 2.0744199752807617
Validation loss: 2.0429379029940535

Epoch: 6| Step: 5
Training loss: 1.660412073135376
Validation loss: 2.0281677502457813

Epoch: 6| Step: 6
Training loss: 1.6951031684875488
Validation loss: 2.016578864025813

Epoch: 6| Step: 7
Training loss: 1.7807849645614624
Validation loss: 2.03177652307736

Epoch: 6| Step: 8
Training loss: 2.127913236618042
Validation loss: 2.0430962475397254

Epoch: 6| Step: 9
Training loss: 1.7140069007873535
Validation loss: 2.042016790759179

Epoch: 6| Step: 10
Training loss: 1.714024543762207
Validation loss: 2.022669930611887

Epoch: 6| Step: 11
Training loss: 2.7374253273010254
Validation loss: 2.018497536259313

Epoch: 6| Step: 12
Training loss: 2.3895905017852783
Validation loss: 2.046556403560023

Epoch: 6| Step: 13
Training loss: 1.4035786390304565
Validation loss: 2.037204709104312

Epoch: 141| Step: 0
Training loss: 3.0597615242004395
Validation loss: 2.021641182643111

Epoch: 6| Step: 1
Training loss: 2.4365038871765137
Validation loss: 2.0382633491228987

Epoch: 6| Step: 2
Training loss: 2.6633825302124023
Validation loss: 2.04977741677274

Epoch: 6| Step: 3
Training loss: 1.768484115600586
Validation loss: 2.0235549685775593

Epoch: 6| Step: 4
Training loss: 1.982779622077942
Validation loss: 2.029780903170186

Epoch: 6| Step: 5
Training loss: 0.9588813781738281
Validation loss: 2.0307349094780545

Epoch: 6| Step: 6
Training loss: 2.0139408111572266
Validation loss: 2.0305085515463226

Epoch: 6| Step: 7
Training loss: 1.858204960823059
Validation loss: 2.04200102180563

Epoch: 6| Step: 8
Training loss: 1.7168159484863281
Validation loss: 2.028602118133217

Epoch: 6| Step: 9
Training loss: 1.8028454780578613
Validation loss: 2.0505812065575713

Epoch: 6| Step: 10
Training loss: 1.883063793182373
Validation loss: 2.0121207493607716

Epoch: 6| Step: 11
Training loss: 1.7972620725631714
Validation loss: 2.051823293009112

Epoch: 6| Step: 12
Training loss: 2.2472944259643555
Validation loss: 2.031523371255526

Epoch: 6| Step: 13
Training loss: 2.8699591159820557
Validation loss: 2.0426017776612313

Epoch: 142| Step: 0
Training loss: 2.1255617141723633
Validation loss: 2.0330193991302163

Epoch: 6| Step: 1
Training loss: 1.8930566310882568
Validation loss: 2.0375702432406846

Epoch: 6| Step: 2
Training loss: 1.929107666015625
Validation loss: 2.047672620383642

Epoch: 6| Step: 3
Training loss: 2.054898738861084
Validation loss: 2.044526893605468

Epoch: 6| Step: 4
Training loss: 1.9534530639648438
Validation loss: 2.0038123720435688

Epoch: 6| Step: 5
Training loss: 2.3056206703186035
Validation loss: 2.0296005818151657

Epoch: 6| Step: 6
Training loss: 2.237889289855957
Validation loss: 2.010092519944714

Epoch: 6| Step: 7
Training loss: 2.060872793197632
Validation loss: 2.0407526646890948

Epoch: 6| Step: 8
Training loss: 2.0901100635528564
Validation loss: 2.039982532942167

Epoch: 6| Step: 9
Training loss: 1.845284342765808
Validation loss: 2.019448221370738

Epoch: 6| Step: 10
Training loss: 1.8876241445541382
Validation loss: 2.0230040832232405

Epoch: 6| Step: 11
Training loss: 2.0934078693389893
Validation loss: 2.0218424386875604

Epoch: 6| Step: 12
Training loss: 2.372903347015381
Validation loss: 2.031479231772884

Epoch: 6| Step: 13
Training loss: 1.7927271127700806
Validation loss: 2.044664534189368

Epoch: 143| Step: 0
Training loss: 1.9912960529327393
Validation loss: 2.009213864162404

Epoch: 6| Step: 1
Training loss: 1.191225528717041
Validation loss: 2.0207583776084324

Epoch: 6| Step: 2
Training loss: 2.5820508003234863
Validation loss: 2.0449971896345898

Epoch: 6| Step: 3
Training loss: 1.8944461345672607
Validation loss: 2.035350147114005

Epoch: 6| Step: 4
Training loss: 1.9180880784988403
Validation loss: 2.0250082067264024

Epoch: 6| Step: 5
Training loss: 2.304511547088623
Validation loss: 2.0290804588666527

Epoch: 6| Step: 6
Training loss: 2.2935845851898193
Validation loss: 2.0169206626953615

Epoch: 6| Step: 7
Training loss: 1.8010996580123901
Validation loss: 2.0363392701712986

Epoch: 6| Step: 8
Training loss: 1.846352458000183
Validation loss: 2.0304405381602626

Epoch: 6| Step: 9
Training loss: 2.2560603618621826
Validation loss: 2.057126696391772

Epoch: 6| Step: 10
Training loss: 1.4841126203536987
Validation loss: 2.030382561427291

Epoch: 6| Step: 11
Training loss: 2.74056339263916
Validation loss: 2.020312777129553

Epoch: 6| Step: 12
Training loss: 1.907301664352417
Validation loss: 2.0388303623404553

Epoch: 6| Step: 13
Training loss: 2.3833634853363037
Validation loss: 2.0285014798564296

Epoch: 144| Step: 0
Training loss: 1.9234424829483032
Validation loss: 2.02046642252194

Epoch: 6| Step: 1
Training loss: 2.346128225326538
Validation loss: 2.032201131184896

Epoch: 6| Step: 2
Training loss: 1.9930353164672852
Validation loss: 2.063803611263152

Epoch: 6| Step: 3
Training loss: 1.7791521549224854
Validation loss: 2.0647244427793767

Epoch: 6| Step: 4
Training loss: 2.053831100463867
Validation loss: 2.0294180634201213

Epoch: 6| Step: 5
Training loss: 1.7333729267120361
Validation loss: 2.0213885409857637

Epoch: 6| Step: 6
Training loss: 1.9656124114990234
Validation loss: 2.0084661104345836

Epoch: 6| Step: 7
Training loss: 2.077977418899536
Validation loss: 2.0373405769307125

Epoch: 6| Step: 8
Training loss: 1.9098756313323975
Validation loss: 2.034274334548622

Epoch: 6| Step: 9
Training loss: 2.5349550247192383
Validation loss: 2.037814712011686

Epoch: 6| Step: 10
Training loss: 1.8685680627822876
Validation loss: 2.033061178781653

Epoch: 6| Step: 11
Training loss: 2.368802785873413
Validation loss: 2.0575557472885295

Epoch: 6| Step: 12
Training loss: 1.797548532485962
Validation loss: 2.021882313554005

Epoch: 6| Step: 13
Training loss: 2.0687448978424072
Validation loss: 2.0440628631140596

Epoch: 145| Step: 0
Training loss: 2.0678374767303467
Validation loss: 2.0252989902291247

Epoch: 6| Step: 1
Training loss: 2.2256598472595215
Validation loss: 2.0311557759520826

Epoch: 6| Step: 2
Training loss: 1.8246628046035767
Validation loss: 2.027033357210057

Epoch: 6| Step: 3
Training loss: 2.1378014087677
Validation loss: 2.0281751002034833

Epoch: 6| Step: 4
Training loss: 1.9263029098510742
Validation loss: 2.0368441586853354

Epoch: 6| Step: 5
Training loss: 3.0023841857910156
Validation loss: 2.030991967006396

Epoch: 6| Step: 6
Training loss: 1.3285273313522339
Validation loss: 2.0327803422045965

Epoch: 6| Step: 7
Training loss: 2.29166316986084
Validation loss: 2.0303815987802323

Epoch: 6| Step: 8
Training loss: 2.0720443725585938
Validation loss: 2.009766932456724

Epoch: 6| Step: 9
Training loss: 1.8076539039611816
Validation loss: 2.036391344121707

Epoch: 6| Step: 10
Training loss: 1.9678683280944824
Validation loss: 2.0404744648164317

Epoch: 6| Step: 11
Training loss: 2.098639965057373
Validation loss: 2.0428080328049196

Epoch: 6| Step: 12
Training loss: 1.5587453842163086
Validation loss: 2.0089815573025773

Epoch: 6| Step: 13
Training loss: 2.144598960876465
Validation loss: 2.0251708671610844

Epoch: 146| Step: 0
Training loss: 2.634031295776367
Validation loss: 2.0057450635458833

Epoch: 6| Step: 1
Training loss: 2.24963641166687
Validation loss: 2.0252000375460555

Epoch: 6| Step: 2
Training loss: 2.307440996170044
Validation loss: 2.0179153501346545

Epoch: 6| Step: 3
Training loss: 1.481551170349121
Validation loss: 2.012626865858673

Epoch: 6| Step: 4
Training loss: 1.710641622543335
Validation loss: 2.018940971743676

Epoch: 6| Step: 5
Training loss: 2.4597222805023193
Validation loss: 2.0320956489091277

Epoch: 6| Step: 6
Training loss: 1.7911667823791504
Validation loss: 2.05304523949982

Epoch: 6| Step: 7
Training loss: 2.1678478717803955
Validation loss: 2.0427434316245456

Epoch: 6| Step: 8
Training loss: 1.8746334314346313
Validation loss: 2.0354369045585714

Epoch: 6| Step: 9
Training loss: 2.070887565612793
Validation loss: 2.0408560511886433

Epoch: 6| Step: 10
Training loss: 2.6211066246032715
Validation loss: 2.042182622417327

Epoch: 6| Step: 11
Training loss: 1.9345972537994385
Validation loss: 2.046960690970062

Epoch: 6| Step: 12
Training loss: 1.5931620597839355
Validation loss: 2.026054866852299

Epoch: 6| Step: 13
Training loss: 1.0842658281326294
Validation loss: 2.0261827848290883

Epoch: 147| Step: 0
Training loss: 2.345114231109619
Validation loss: 2.033175035189557

Epoch: 6| Step: 1
Training loss: 1.7309218645095825
Validation loss: 2.0472969880668064

Epoch: 6| Step: 2
Training loss: 2.2816715240478516
Validation loss: 2.03514196795802

Epoch: 6| Step: 3
Training loss: 2.240359306335449
Validation loss: 2.031714362482871

Epoch: 6| Step: 4
Training loss: 1.9660158157348633
Validation loss: 2.05519760552273

Epoch: 6| Step: 5
Training loss: 1.8467779159545898
Validation loss: 2.0273947382485993

Epoch: 6| Step: 6
Training loss: 2.5177955627441406
Validation loss: 2.0082242745225147

Epoch: 6| Step: 7
Training loss: 1.516878366470337
Validation loss: 2.0239177134729203

Epoch: 6| Step: 8
Training loss: 1.7321557998657227
Validation loss: 2.0294112672087965

Epoch: 6| Step: 9
Training loss: 2.143068313598633
Validation loss: 2.014550478227677

Epoch: 6| Step: 10
Training loss: 2.5372610092163086
Validation loss: 2.0196844582916587

Epoch: 6| Step: 11
Training loss: 1.5261635780334473
Validation loss: 2.0170123179753623

Epoch: 6| Step: 12
Training loss: 1.8767220973968506
Validation loss: 2.008104432013727

Epoch: 6| Step: 13
Training loss: 2.1033384799957275
Validation loss: 2.040284578518201

Epoch: 148| Step: 0
Training loss: 2.35416316986084
Validation loss: 1.9966249747942852

Epoch: 6| Step: 1
Training loss: 1.8450703620910645
Validation loss: 2.0381255739478656

Epoch: 6| Step: 2
Training loss: 2.083841323852539
Validation loss: 2.025033143258864

Epoch: 6| Step: 3
Training loss: 1.7267367839813232
Validation loss: 2.0418517602387296

Epoch: 6| Step: 4
Training loss: 1.700596809387207
Validation loss: 2.0241769026684504

Epoch: 6| Step: 5
Training loss: 2.316493272781372
Validation loss: 2.0090996988358034

Epoch: 6| Step: 6
Training loss: 1.6799122095108032
Validation loss: 2.0175427236864643

Epoch: 6| Step: 7
Training loss: 1.9551281929016113
Validation loss: 2.0264689409604637

Epoch: 6| Step: 8
Training loss: 2.045307159423828
Validation loss: 2.011695841307281

Epoch: 6| Step: 9
Training loss: 2.606327533721924
Validation loss: 2.0258945303578533

Epoch: 6| Step: 10
Training loss: 2.427480697631836
Validation loss: 2.0257166303614134

Epoch: 6| Step: 11
Training loss: 1.4455626010894775
Validation loss: 2.0224263924424366

Epoch: 6| Step: 12
Training loss: 2.347386598587036
Validation loss: 2.0398245780698714

Epoch: 6| Step: 13
Training loss: 1.7694462537765503
Validation loss: 2.0018923795351418

Epoch: 149| Step: 0
Training loss: 2.479281425476074
Validation loss: 2.019214040489607

Epoch: 6| Step: 1
Training loss: 2.4781229496002197
Validation loss: 2.014512877310476

Epoch: 6| Step: 2
Training loss: 1.3999842405319214
Validation loss: 2.0170672350032355

Epoch: 6| Step: 3
Training loss: 2.2708802223205566
Validation loss: 2.029968838537893

Epoch: 6| Step: 4
Training loss: 1.7136285305023193
Validation loss: 2.032060120695381

Epoch: 6| Step: 5
Training loss: 1.8005048036575317
Validation loss: 2.0243389183475125

Epoch: 6| Step: 6
Training loss: 2.624011754989624
Validation loss: 2.0273575769957675

Epoch: 6| Step: 7
Training loss: 2.200054883956909
Validation loss: 2.0293217102686563

Epoch: 6| Step: 8
Training loss: 1.8311705589294434
Validation loss: 2.0441137641988774

Epoch: 6| Step: 9
Training loss: 1.436171293258667
Validation loss: 2.015842491580594

Epoch: 6| Step: 10
Training loss: 1.8609340190887451
Validation loss: 2.0464997624838226

Epoch: 6| Step: 11
Training loss: 2.529191017150879
Validation loss: 2.0223364778744277

Epoch: 6| Step: 12
Training loss: 1.7710435390472412
Validation loss: 2.006022153362151

Epoch: 6| Step: 13
Training loss: 1.9090228080749512
Validation loss: 2.0148694169136787

Epoch: 150| Step: 0
Training loss: 1.3124024868011475
Validation loss: 2.0041021095809115

Epoch: 6| Step: 1
Training loss: 2.664062023162842
Validation loss: 2.0259873444034207

Epoch: 6| Step: 2
Training loss: 1.80631422996521
Validation loss: 2.026483781876103

Epoch: 6| Step: 3
Training loss: 2.1296916007995605
Validation loss: 2.021791181256694

Epoch: 6| Step: 4
Training loss: 2.214236259460449
Validation loss: 2.0038133308451664

Epoch: 6| Step: 5
Training loss: 2.8869214057922363
Validation loss: 2.0291074463116225

Epoch: 6| Step: 6
Training loss: 2.0907344818115234
Validation loss: 2.0180775824413506

Epoch: 6| Step: 7
Training loss: 2.045642375946045
Validation loss: 2.025382844350671

Epoch: 6| Step: 8
Training loss: 1.6657620668411255
Validation loss: 2.0304214441648094

Epoch: 6| Step: 9
Training loss: 1.7141706943511963
Validation loss: 2.0184712999610492

Epoch: 6| Step: 10
Training loss: 2.1584787368774414
Validation loss: 2.0251174947266937

Epoch: 6| Step: 11
Training loss: 1.653702974319458
Validation loss: 2.032004053874682

Epoch: 6| Step: 12
Training loss: 1.7946553230285645
Validation loss: 2.003721639674197

Epoch: 6| Step: 13
Training loss: 2.1037473678588867
Validation loss: 2.021275476742816

Epoch: 151| Step: 0
Training loss: 2.6712770462036133
Validation loss: 1.993438700194

Epoch: 6| Step: 1
Training loss: 1.7614995241165161
Validation loss: 2.015072850770848

Epoch: 6| Step: 2
Training loss: 1.5041882991790771
Validation loss: 2.0365147065090876

Epoch: 6| Step: 3
Training loss: 1.8405401706695557
Validation loss: 2.00419633875611

Epoch: 6| Step: 4
Training loss: 2.249502420425415
Validation loss: 2.0150001766861125

Epoch: 6| Step: 5
Training loss: 1.2853477001190186
Validation loss: 2.020791079408379

Epoch: 6| Step: 6
Training loss: 2.4451193809509277
Validation loss: 2.0407666775488083

Epoch: 6| Step: 7
Training loss: 2.02083158493042
Validation loss: 2.009564886810959

Epoch: 6| Step: 8
Training loss: 1.9786685705184937
Validation loss: 2.0356750155007965

Epoch: 6| Step: 9
Training loss: 2.3274917602539062
Validation loss: 1.9900994672570178

Epoch: 6| Step: 10
Training loss: 2.6687698364257812
Validation loss: 2.015268536024196

Epoch: 6| Step: 11
Training loss: 2.1318888664245605
Validation loss: 2.0221630578399985

Epoch: 6| Step: 12
Training loss: 1.6143310070037842
Validation loss: 2.013406644585312

Epoch: 6| Step: 13
Training loss: 1.6029804944992065
Validation loss: 1.9734617817786433

Epoch: 152| Step: 0
Training loss: 1.8414478302001953
Validation loss: 2.0059296341352564

Epoch: 6| Step: 1
Training loss: 2.1105964183807373
Validation loss: 2.029816953084802

Epoch: 6| Step: 2
Training loss: 2.2569420337677
Validation loss: 2.0311395365704774

Epoch: 6| Step: 3
Training loss: 2.0544638633728027
Validation loss: 2.0174640429917203

Epoch: 6| Step: 4
Training loss: 2.56213116645813
Validation loss: 2.022695013271865

Epoch: 6| Step: 5
Training loss: 1.7051701545715332
Validation loss: 2.0413403972502677

Epoch: 6| Step: 6
Training loss: 2.680601119995117
Validation loss: 2.0032669523710847

Epoch: 6| Step: 7
Training loss: 1.508885145187378
Validation loss: 2.009458036832912

Epoch: 6| Step: 8
Training loss: 2.346456289291382
Validation loss: 2.027575462095199

Epoch: 6| Step: 9
Training loss: 2.1175642013549805
Validation loss: 2.00723482331922

Epoch: 6| Step: 10
Training loss: 1.3469643592834473
Validation loss: 2.0146224601294405

Epoch: 6| Step: 11
Training loss: 1.735685110092163
Validation loss: 2.0037325659105854

Epoch: 6| Step: 12
Training loss: 2.359835147857666
Validation loss: 2.0246960193880144

Epoch: 6| Step: 13
Training loss: 1.3886964321136475
Validation loss: 2.027039840657224

Epoch: 153| Step: 0
Training loss: 1.8915824890136719
Validation loss: 2.0326353990903465

Epoch: 6| Step: 1
Training loss: 2.1486692428588867
Validation loss: 2.034008854178972

Epoch: 6| Step: 2
Training loss: 2.086207866668701
Validation loss: 2.029778052401799

Epoch: 6| Step: 3
Training loss: 1.5066436529159546
Validation loss: 2.0237252237976238

Epoch: 6| Step: 4
Training loss: 1.4775594472885132
Validation loss: 2.032059045248134

Epoch: 6| Step: 5
Training loss: 1.9702587127685547
Validation loss: 2.0186580919450328

Epoch: 6| Step: 6
Training loss: 2.472620964050293
Validation loss: 1.9994779889301588

Epoch: 6| Step: 7
Training loss: 2.293945789337158
Validation loss: 2.0317689026555708

Epoch: 6| Step: 8
Training loss: 1.9035004377365112
Validation loss: 2.0324286260912494

Epoch: 6| Step: 9
Training loss: 1.4285372495651245
Validation loss: 2.01349018209724

Epoch: 6| Step: 10
Training loss: 1.9847557544708252
Validation loss: 2.0340186062679497

Epoch: 6| Step: 11
Training loss: 2.2679781913757324
Validation loss: 2.0194104653532787

Epoch: 6| Step: 12
Training loss: 2.652602195739746
Validation loss: 2.0439380497060795

Epoch: 6| Step: 13
Training loss: 2.036620855331421
Validation loss: 2.0077666992782266

Epoch: 154| Step: 0
Training loss: 2.476128578186035
Validation loss: 2.013487974802653

Epoch: 6| Step: 1
Training loss: 1.7366020679473877
Validation loss: 2.0042639778506373

Epoch: 6| Step: 2
Training loss: 1.6712050437927246
Validation loss: 2.0219679250512073

Epoch: 6| Step: 3
Training loss: 2.3135924339294434
Validation loss: 2.0313015522495395

Epoch: 6| Step: 4
Training loss: 2.0244364738464355
Validation loss: 1.9976903238604147

Epoch: 6| Step: 5
Training loss: 1.7864679098129272
Validation loss: 1.9941307242198656

Epoch: 6| Step: 6
Training loss: 1.7606515884399414
Validation loss: 2.0201258749090214

Epoch: 6| Step: 7
Training loss: 2.0056958198547363
Validation loss: 2.0052425874176847

Epoch: 6| Step: 8
Training loss: 2.20042085647583
Validation loss: 2.0307216131558983

Epoch: 6| Step: 9
Training loss: 2.0365452766418457
Validation loss: 2.0078176682995212

Epoch: 6| Step: 10
Training loss: 2.4319276809692383
Validation loss: 2.005503672425465

Epoch: 6| Step: 11
Training loss: 1.7092045545578003
Validation loss: 2.0292607891944145

Epoch: 6| Step: 12
Training loss: 2.5064799785614014
Validation loss: 2.034232213932981

Epoch: 6| Step: 13
Training loss: 0.8953450322151184
Validation loss: 1.9895007892321515

Epoch: 155| Step: 0
Training loss: 1.4163998365402222
Validation loss: 2.010725713545276

Epoch: 6| Step: 1
Training loss: 1.6718984842300415
Validation loss: 2.0250578503454886

Epoch: 6| Step: 2
Training loss: 2.3281466960906982
Validation loss: 2.038300170693346

Epoch: 6| Step: 3
Training loss: 2.8641467094421387
Validation loss: 2.009772350711207

Epoch: 6| Step: 4
Training loss: 2.336747646331787
Validation loss: 2.0095952198069584

Epoch: 6| Step: 5
Training loss: 2.3558826446533203
Validation loss: 2.0024506302290064

Epoch: 6| Step: 6
Training loss: 1.6942651271820068
Validation loss: 2.0234470034158356

Epoch: 6| Step: 7
Training loss: 1.5153905153274536
Validation loss: 2.0262960208359586

Epoch: 6| Step: 8
Training loss: 2.135793924331665
Validation loss: 2.0440483605989845

Epoch: 6| Step: 9
Training loss: 2.047497510910034
Validation loss: 2.05330987386806

Epoch: 6| Step: 10
Training loss: 1.6393697261810303
Validation loss: 2.0056810866120043

Epoch: 6| Step: 11
Training loss: 1.221542239189148
Validation loss: 2.0480894247690835

Epoch: 6| Step: 12
Training loss: 2.3547961711883545
Validation loss: 2.0458388392643263

Epoch: 6| Step: 13
Training loss: 2.802905559539795
Validation loss: 2.010801935708651

Epoch: 156| Step: 0
Training loss: 1.4594330787658691
Validation loss: 2.0355101170078402

Epoch: 6| Step: 1
Training loss: 2.2937474250793457
Validation loss: 2.038569845179076

Epoch: 6| Step: 2
Training loss: 1.7490205764770508
Validation loss: 2.0276382456543627

Epoch: 6| Step: 3
Training loss: 2.2636890411376953
Validation loss: 2.042925742364699

Epoch: 6| Step: 4
Training loss: 2.005920171737671
Validation loss: 1.9929855574843705

Epoch: 6| Step: 5
Training loss: 2.2873973846435547
Validation loss: 2.027239975108895

Epoch: 6| Step: 6
Training loss: 2.1136813163757324
Validation loss: 2.011149044959776

Epoch: 6| Step: 7
Training loss: 2.4625909328460693
Validation loss: 2.0175250627661265

Epoch: 6| Step: 8
Training loss: 1.8114904165267944
Validation loss: 2.0302576057372557

Epoch: 6| Step: 9
Training loss: 1.7815592288970947
Validation loss: 2.0078230545084965

Epoch: 6| Step: 10
Training loss: 1.9991660118103027
Validation loss: 2.0250088732729674

Epoch: 6| Step: 11
Training loss: 1.842812418937683
Validation loss: 1.9967113438472952

Epoch: 6| Step: 12
Training loss: 1.9733045101165771
Validation loss: 1.993410930838636

Epoch: 6| Step: 13
Training loss: 1.9137978553771973
Validation loss: 2.0030598922442366

Epoch: 157| Step: 0
Training loss: 1.968389630317688
Validation loss: 1.9951815810254825

Epoch: 6| Step: 1
Training loss: 1.6641948223114014
Validation loss: 2.0247710750949

Epoch: 6| Step: 2
Training loss: 2.5197904109954834
Validation loss: 1.998437484105428

Epoch: 6| Step: 3
Training loss: 1.6187477111816406
Validation loss: 2.02867986566277

Epoch: 6| Step: 4
Training loss: 2.269930839538574
Validation loss: 2.0224252875133226

Epoch: 6| Step: 5
Training loss: 2.576399087905884
Validation loss: 2.043891394010154

Epoch: 6| Step: 6
Training loss: 2.2470955848693848
Validation loss: 2.0071429462843042

Epoch: 6| Step: 7
Training loss: 1.5959537029266357
Validation loss: 2.0281214201322166

Epoch: 6| Step: 8
Training loss: 2.149290084838867
Validation loss: 2.0454971328858407

Epoch: 6| Step: 9
Training loss: 2.094989538192749
Validation loss: 2.011573355684998

Epoch: 6| Step: 10
Training loss: 1.903390645980835
Validation loss: 2.0064499762750443

Epoch: 6| Step: 11
Training loss: 1.8970530033111572
Validation loss: 2.011973802761365

Epoch: 6| Step: 12
Training loss: 1.8967633247375488
Validation loss: 2.021861683937811

Epoch: 6| Step: 13
Training loss: 1.9051611423492432
Validation loss: 2.020731674727573

Epoch: 158| Step: 0
Training loss: 1.5338152647018433
Validation loss: 2.0232003965685443

Epoch: 6| Step: 1
Training loss: 1.7876362800598145
Validation loss: 2.012335228663619

Epoch: 6| Step: 2
Training loss: 2.1132774353027344
Validation loss: 2.0189950491792414

Epoch: 6| Step: 3
Training loss: 1.670478343963623
Validation loss: 1.9907468313811927

Epoch: 6| Step: 4
Training loss: 2.248793601989746
Validation loss: 1.9758936974310106

Epoch: 6| Step: 5
Training loss: 2.684065341949463
Validation loss: 2.025508652451218

Epoch: 6| Step: 6
Training loss: 2.744718074798584
Validation loss: 1.9970213649093465

Epoch: 6| Step: 7
Training loss: 1.8969862461090088
Validation loss: 1.995553772936585

Epoch: 6| Step: 8
Training loss: 1.4594099521636963
Validation loss: 2.023835289862848

Epoch: 6| Step: 9
Training loss: 2.541013717651367
Validation loss: 2.0257849757389357

Epoch: 6| Step: 10
Training loss: 1.705634355545044
Validation loss: 1.9946325158560148

Epoch: 6| Step: 11
Training loss: 1.9358283281326294
Validation loss: 1.9818523083963702

Epoch: 6| Step: 12
Training loss: 1.4718936681747437
Validation loss: 2.011075976074383

Epoch: 6| Step: 13
Training loss: 2.3790507316589355
Validation loss: 1.9977078181441112

Epoch: 159| Step: 0
Training loss: 1.8533316850662231
Validation loss: 2.0133247426761094

Epoch: 6| Step: 1
Training loss: 2.3144805431365967
Validation loss: 2.0198056851663897

Epoch: 6| Step: 2
Training loss: 1.7286365032196045
Validation loss: 1.9751499468280422

Epoch: 6| Step: 3
Training loss: 1.9056282043457031
Validation loss: 2.01923494826081

Epoch: 6| Step: 4
Training loss: 1.8909767866134644
Validation loss: 1.993460137356994

Epoch: 6| Step: 5
Training loss: 1.5447757244110107
Validation loss: 2.0234954510965655

Epoch: 6| Step: 6
Training loss: 2.7213878631591797
Validation loss: 2.008685153017762

Epoch: 6| Step: 7
Training loss: 1.9940884113311768
Validation loss: 2.027551338236819

Epoch: 6| Step: 8
Training loss: 2.0139002799987793
Validation loss: 1.9978378190789172

Epoch: 6| Step: 9
Training loss: 1.977097511291504
Validation loss: 2.001132419032435

Epoch: 6| Step: 10
Training loss: 1.3823516368865967
Validation loss: 2.018720926777009

Epoch: 6| Step: 11
Training loss: 2.356973648071289
Validation loss: 2.0144846336815947

Epoch: 6| Step: 12
Training loss: 2.2180428504943848
Validation loss: 2.028713887737643

Epoch: 6| Step: 13
Training loss: 1.8565531969070435
Validation loss: 2.024843221069664

Epoch: 160| Step: 0
Training loss: 1.7744734287261963
Validation loss: 2.026349402243091

Epoch: 6| Step: 1
Training loss: 1.5419878959655762
Validation loss: 2.0199008487885997

Epoch: 6| Step: 2
Training loss: 1.9570109844207764
Validation loss: 1.999410080653365

Epoch: 6| Step: 3
Training loss: 2.58760142326355
Validation loss: 2.0135678142629643

Epoch: 6| Step: 4
Training loss: 2.188380479812622
Validation loss: 2.0220724203253306

Epoch: 6| Step: 5
Training loss: 1.6422311067581177
Validation loss: 2.0141495273959253

Epoch: 6| Step: 6
Training loss: 1.5397319793701172
Validation loss: 1.9857273050533828

Epoch: 6| Step: 7
Training loss: 1.413992166519165
Validation loss: 2.017923096174835

Epoch: 6| Step: 8
Training loss: 2.266940116882324
Validation loss: 1.9996473173941336

Epoch: 6| Step: 9
Training loss: 2.2282485961914062
Validation loss: 2.0226282099241852

Epoch: 6| Step: 10
Training loss: 2.191481113433838
Validation loss: 1.996919176911795

Epoch: 6| Step: 11
Training loss: 2.2874722480773926
Validation loss: 2.0067303783150128

Epoch: 6| Step: 12
Training loss: 2.780973196029663
Validation loss: 1.9952900255880048

Epoch: 6| Step: 13
Training loss: 1.1374098062515259
Validation loss: 1.9988798377334431

Epoch: 161| Step: 0
Training loss: 2.385287284851074
Validation loss: 1.9774130672536872

Epoch: 6| Step: 1
Training loss: 2.3839540481567383
Validation loss: 2.014415167993115

Epoch: 6| Step: 2
Training loss: 1.1590886116027832
Validation loss: 2.0032448230251187

Epoch: 6| Step: 3
Training loss: 2.1667063236236572
Validation loss: 2.026359477350789

Epoch: 6| Step: 4
Training loss: 1.9416155815124512
Validation loss: 1.9939220233630108

Epoch: 6| Step: 5
Training loss: 1.3971573114395142
Validation loss: 1.9898157760661135

Epoch: 6| Step: 6
Training loss: 1.9099631309509277
Validation loss: 1.9951083660125732

Epoch: 6| Step: 7
Training loss: 3.614914894104004
Validation loss: 2.013626226814844

Epoch: 6| Step: 8
Training loss: 1.3401451110839844
Validation loss: 1.9983815941759335

Epoch: 6| Step: 9
Training loss: 2.3057785034179688
Validation loss: 2.0227649493884017

Epoch: 6| Step: 10
Training loss: 1.629240870475769
Validation loss: 2.0186893311879968

Epoch: 6| Step: 11
Training loss: 1.8676173686981201
Validation loss: 2.013413001132268

Epoch: 6| Step: 12
Training loss: 1.661210536956787
Validation loss: 1.9926787602004183

Epoch: 6| Step: 13
Training loss: 2.21471905708313
Validation loss: 2.019218470460625

Epoch: 162| Step: 0
Training loss: 2.156130790710449
Validation loss: 1.9969131241562545

Epoch: 6| Step: 1
Training loss: 2.627206563949585
Validation loss: 1.9947509932261642

Epoch: 6| Step: 2
Training loss: 2.166710376739502
Validation loss: 2.0153869352033063

Epoch: 6| Step: 3
Training loss: 1.824135661125183
Validation loss: 2.0092527225453365

Epoch: 6| Step: 4
Training loss: 1.7846320867538452
Validation loss: 2.0093889890178556

Epoch: 6| Step: 5
Training loss: 1.5820789337158203
Validation loss: 2.0115498022366594

Epoch: 6| Step: 6
Training loss: 2.0568771362304688
Validation loss: 2.022923274706769

Epoch: 6| Step: 7
Training loss: 2.114917039871216
Validation loss: 2.01839187324688

Epoch: 6| Step: 8
Training loss: 2.609090805053711
Validation loss: 2.031866878591558

Epoch: 6| Step: 9
Training loss: 1.7506945133209229
Validation loss: 2.0242153867598502

Epoch: 6| Step: 10
Training loss: 2.0830817222595215
Validation loss: 2.0455126198389197

Epoch: 6| Step: 11
Training loss: 1.6196084022521973
Validation loss: 2.0241344077612764

Epoch: 6| Step: 12
Training loss: 1.473912000656128
Validation loss: 1.9823778239629601

Epoch: 6| Step: 13
Training loss: 2.33316969871521
Validation loss: 2.0040666339217976

Epoch: 163| Step: 0
Training loss: 1.5356502532958984
Validation loss: 2.0032423734664917

Epoch: 6| Step: 1
Training loss: 1.838865041732788
Validation loss: 1.9817223241252284

Epoch: 6| Step: 2
Training loss: 2.125643730163574
Validation loss: 2.038389007250468

Epoch: 6| Step: 3
Training loss: 1.250629186630249
Validation loss: 2.006365450479651

Epoch: 6| Step: 4
Training loss: 2.58286452293396
Validation loss: 1.980698162509549

Epoch: 6| Step: 5
Training loss: 2.6086044311523438
Validation loss: 2.004681364182503

Epoch: 6| Step: 6
Training loss: 2.2549281120300293
Validation loss: 2.019080791422116

Epoch: 6| Step: 7
Training loss: 1.593366026878357
Validation loss: 2.003772976577923

Epoch: 6| Step: 8
Training loss: 1.8824213743209839
Validation loss: 1.9855498934304843

Epoch: 6| Step: 9
Training loss: 1.5853710174560547
Validation loss: 2.0129098892211914

Epoch: 6| Step: 10
Training loss: 2.268115520477295
Validation loss: 1.9911533581313265

Epoch: 6| Step: 11
Training loss: 2.162628412246704
Validation loss: 1.9995143259725263

Epoch: 6| Step: 12
Training loss: 1.7828187942504883
Validation loss: 2.003301984520369

Epoch: 6| Step: 13
Training loss: 2.325516939163208
Validation loss: 2.013712211321759

Epoch: 164| Step: 0
Training loss: 2.503418445587158
Validation loss: 2.026177921602803

Epoch: 6| Step: 1
Training loss: 2.0907979011535645
Validation loss: 1.9832435602782874

Epoch: 6| Step: 2
Training loss: 1.9699177742004395
Validation loss: 1.99725212717569

Epoch: 6| Step: 3
Training loss: 2.021787643432617
Validation loss: 1.9947885338978102

Epoch: 6| Step: 4
Training loss: 1.3515326976776123
Validation loss: 1.976555960152739

Epoch: 6| Step: 5
Training loss: 1.6688663959503174
Validation loss: 1.9991841264950332

Epoch: 6| Step: 6
Training loss: 1.977730631828308
Validation loss: 2.016447359515775

Epoch: 6| Step: 7
Training loss: 2.0495030879974365
Validation loss: 2.016574308436404

Epoch: 6| Step: 8
Training loss: 2.3806028366088867
Validation loss: 1.9910892440426735

Epoch: 6| Step: 9
Training loss: 1.5933159589767456
Validation loss: 2.0146238393681024

Epoch: 6| Step: 10
Training loss: 1.6574726104736328
Validation loss: 2.0229180089889036

Epoch: 6| Step: 11
Training loss: 1.8788410425186157
Validation loss: 2.0084222696160756

Epoch: 6| Step: 12
Training loss: 2.216958522796631
Validation loss: 1.9910686836447766

Epoch: 6| Step: 13
Training loss: 2.4991025924682617
Validation loss: 2.002979042709515

Epoch: 165| Step: 0
Training loss: 2.093674659729004
Validation loss: 1.9976735550870177

Epoch: 6| Step: 1
Training loss: 1.9163463115692139
Validation loss: 2.0339433557243756

Epoch: 6| Step: 2
Training loss: 2.2054905891418457
Validation loss: 1.9890568461469424

Epoch: 6| Step: 3
Training loss: 2.098275661468506
Validation loss: 1.994793366360408

Epoch: 6| Step: 4
Training loss: 2.0274415016174316
Validation loss: 1.993941012249198

Epoch: 6| Step: 5
Training loss: 1.4905864000320435
Validation loss: 2.0023698652944257

Epoch: 6| Step: 6
Training loss: 1.3404743671417236
Validation loss: 2.04013692819944

Epoch: 6| Step: 7
Training loss: 2.4085452556610107
Validation loss: 2.002331808049192

Epoch: 6| Step: 8
Training loss: 1.7681818008422852
Validation loss: 1.9850865102583362

Epoch: 6| Step: 9
Training loss: 3.0036909580230713
Validation loss: 2.008804735317025

Epoch: 6| Step: 10
Training loss: 2.0430281162261963
Validation loss: 2.0149037735436552

Epoch: 6| Step: 11
Training loss: 1.130524754524231
Validation loss: 1.9963921039335188

Epoch: 6| Step: 12
Training loss: 2.171722412109375
Validation loss: 1.9961185416867655

Epoch: 6| Step: 13
Training loss: 1.4327025413513184
Validation loss: 2.0006630010502313

Epoch: 166| Step: 0
Training loss: 1.9400354623794556
Validation loss: 2.0209061817456315

Epoch: 6| Step: 1
Training loss: 1.998337745666504
Validation loss: 1.9924232306018952

Epoch: 6| Step: 2
Training loss: 1.7919892072677612
Validation loss: 2.023505744113717

Epoch: 6| Step: 3
Training loss: 1.8695881366729736
Validation loss: 2.020742139508647

Epoch: 6| Step: 4
Training loss: 2.1611828804016113
Validation loss: 2.0367397377567906

Epoch: 6| Step: 5
Training loss: 2.258364677429199
Validation loss: 1.958511931921846

Epoch: 6| Step: 6
Training loss: 2.6020219326019287
Validation loss: 1.9806156581447971

Epoch: 6| Step: 7
Training loss: 2.0249032974243164
Validation loss: 2.0050147835926344

Epoch: 6| Step: 8
Training loss: 2.007391929626465
Validation loss: 1.9741325762964064

Epoch: 6| Step: 9
Training loss: 1.513413429260254
Validation loss: 2.0048298592208535

Epoch: 6| Step: 10
Training loss: 1.4182958602905273
Validation loss: 1.9812805562890985

Epoch: 6| Step: 11
Training loss: 2.3037662506103516
Validation loss: 1.9859226313970422

Epoch: 6| Step: 12
Training loss: 1.5136750936508179
Validation loss: 2.0149916359173354

Epoch: 6| Step: 13
Training loss: 2.3241281509399414
Validation loss: 2.0145593407333537

Epoch: 167| Step: 0
Training loss: 1.9360487461090088
Validation loss: 2.0232468125640706

Epoch: 6| Step: 1
Training loss: 1.9058868885040283
Validation loss: 1.9814353989016624

Epoch: 6| Step: 2
Training loss: 2.11281681060791
Validation loss: 2.0003920178259573

Epoch: 6| Step: 3
Training loss: 2.0842859745025635
Validation loss: 1.9824888475479618

Epoch: 6| Step: 4
Training loss: 2.234447956085205
Validation loss: 1.9901787132345221

Epoch: 6| Step: 5
Training loss: 1.4980484247207642
Validation loss: 2.0224164519258725

Epoch: 6| Step: 6
Training loss: 1.6935985088348389
Validation loss: 1.9854565333294611

Epoch: 6| Step: 7
Training loss: 2.2278380393981934
Validation loss: 2.0161005271378385

Epoch: 6| Step: 8
Training loss: 1.5844547748565674
Validation loss: 1.9784273332165134

Epoch: 6| Step: 9
Training loss: 2.1797637939453125
Validation loss: 1.9926896402912755

Epoch: 6| Step: 10
Training loss: 2.145116090774536
Validation loss: 1.9882176230030675

Epoch: 6| Step: 11
Training loss: 2.048731803894043
Validation loss: 2.0031652501834336

Epoch: 6| Step: 12
Training loss: 1.832302451133728
Validation loss: 2.019421903035974

Epoch: 6| Step: 13
Training loss: 2.1288998126983643
Validation loss: 2.0019160714200748

Epoch: 168| Step: 0
Training loss: 2.1244330406188965
Validation loss: 2.0255443126924577

Epoch: 6| Step: 1
Training loss: 1.8512489795684814
Validation loss: 2.010552872893631

Epoch: 6| Step: 2
Training loss: 2.3625175952911377
Validation loss: 2.006081053005752

Epoch: 6| Step: 3
Training loss: 1.3033130168914795
Validation loss: 2.0076283075476207

Epoch: 6| Step: 4
Training loss: 2.5154504776000977
Validation loss: 2.0023341076348418

Epoch: 6| Step: 5
Training loss: 1.805917501449585
Validation loss: 2.002253611882528

Epoch: 6| Step: 6
Training loss: 1.7939274311065674
Validation loss: 2.0219674982050413

Epoch: 6| Step: 7
Training loss: 2.110823154449463
Validation loss: 2.0152389528930827

Epoch: 6| Step: 8
Training loss: 2.550291061401367
Validation loss: 2.0087052032511723

Epoch: 6| Step: 9
Training loss: 2.030545711517334
Validation loss: 2.0231791709059026

Epoch: 6| Step: 10
Training loss: 1.9406696557998657
Validation loss: 2.020931270814711

Epoch: 6| Step: 11
Training loss: 2.0751683712005615
Validation loss: 1.9921463945860505

Epoch: 6| Step: 12
Training loss: 1.7940752506256104
Validation loss: 2.0235804434745543

Epoch: 6| Step: 13
Training loss: 1.0541127920150757
Validation loss: 2.021229627311871

Epoch: 169| Step: 0
Training loss: 1.3963732719421387
Validation loss: 2.0156903215633926

Epoch: 6| Step: 1
Training loss: 1.2667748928070068
Validation loss: 2.034838250888291

Epoch: 6| Step: 2
Training loss: 1.9879367351531982
Validation loss: 1.9993402522097352

Epoch: 6| Step: 3
Training loss: 1.7677042484283447
Validation loss: 2.0175882526623306

Epoch: 6| Step: 4
Training loss: 2.3804264068603516
Validation loss: 2.014167736935359

Epoch: 6| Step: 5
Training loss: 1.8636144399642944
Validation loss: 2.003202207626835

Epoch: 6| Step: 6
Training loss: 2.2396509647369385
Validation loss: 1.9963373548241072

Epoch: 6| Step: 7
Training loss: 2.2231013774871826
Validation loss: 1.9590755508792015

Epoch: 6| Step: 8
Training loss: 2.1508562564849854
Validation loss: 2.005205008291429

Epoch: 6| Step: 9
Training loss: 1.515463948249817
Validation loss: 2.00798777867389

Epoch: 6| Step: 10
Training loss: 2.328242778778076
Validation loss: 1.9856998074439265

Epoch: 6| Step: 11
Training loss: 2.165919303894043
Validation loss: 1.9905566861552577

Epoch: 6| Step: 12
Training loss: 2.5112266540527344
Validation loss: 1.9704140386273783

Epoch: 6| Step: 13
Training loss: 1.9769469499588013
Validation loss: 1.9923290565449705

Epoch: 170| Step: 0
Training loss: 2.2855842113494873
Validation loss: 1.9714740053299935

Epoch: 6| Step: 1
Training loss: 2.099541187286377
Validation loss: 1.9860085415583786

Epoch: 6| Step: 2
Training loss: 1.8485925197601318
Validation loss: 1.988639598251671

Epoch: 6| Step: 3
Training loss: 2.013856887817383
Validation loss: 1.9933393642466555

Epoch: 6| Step: 4
Training loss: 1.6375983953475952
Validation loss: 1.987679991670834

Epoch: 6| Step: 5
Training loss: 1.6048325300216675
Validation loss: 2.0436709209155013

Epoch: 6| Step: 6
Training loss: 1.9978772401809692
Validation loss: 2.0190354880466255

Epoch: 6| Step: 7
Training loss: 2.178896903991699
Validation loss: 2.0057482988603654

Epoch: 6| Step: 8
Training loss: 2.0254080295562744
Validation loss: 2.0089449805598103

Epoch: 6| Step: 9
Training loss: 2.2869491577148438
Validation loss: 2.0102630584470687

Epoch: 6| Step: 10
Training loss: 2.1710171699523926
Validation loss: 2.0068234461610035

Epoch: 6| Step: 11
Training loss: 1.8195979595184326
Validation loss: 2.004826553406254

Epoch: 6| Step: 12
Training loss: 1.4554340839385986
Validation loss: 2.02573646524901

Epoch: 6| Step: 13
Training loss: 2.0902328491210938
Validation loss: 1.9908186325462915

Epoch: 171| Step: 0
Training loss: 2.320383071899414
Validation loss: 2.0177247819080146

Epoch: 6| Step: 1
Training loss: 1.1061961650848389
Validation loss: 1.9860187666390532

Epoch: 6| Step: 2
Training loss: 2.586313247680664
Validation loss: 2.001113954410758

Epoch: 6| Step: 3
Training loss: 1.9286811351776123
Validation loss: 1.973229218554753

Epoch: 6| Step: 4
Training loss: 1.9237096309661865
Validation loss: 1.98928617149271

Epoch: 6| Step: 5
Training loss: 1.9538917541503906
Validation loss: 1.9727139639598068

Epoch: 6| Step: 6
Training loss: 1.8774890899658203
Validation loss: 2.004598827772243

Epoch: 6| Step: 7
Training loss: 2.087524890899658
Validation loss: 1.986350428673529

Epoch: 6| Step: 8
Training loss: 2.1886579990386963
Validation loss: 1.9622360506365377

Epoch: 6| Step: 9
Training loss: 2.1649186611175537
Validation loss: 2.0025283803222

Epoch: 6| Step: 10
Training loss: 1.4296733140945435
Validation loss: 2.019229014714559

Epoch: 6| Step: 11
Training loss: 1.7356904745101929
Validation loss: 2.0177840699431715

Epoch: 6| Step: 12
Training loss: 1.8828763961791992
Validation loss: 1.993174240153323

Epoch: 6| Step: 13
Training loss: 2.5099291801452637
Validation loss: 2.008678109415116

Epoch: 172| Step: 0
Training loss: 1.1979737281799316
Validation loss: 1.978509928590508

Epoch: 6| Step: 1
Training loss: 1.7418484687805176
Validation loss: 1.9846640902180825

Epoch: 6| Step: 2
Training loss: 2.1626195907592773
Validation loss: 1.9871326159405451

Epoch: 6| Step: 3
Training loss: 1.8787540197372437
Validation loss: 1.9633826940290389

Epoch: 6| Step: 4
Training loss: 2.115633010864258
Validation loss: 1.9852051658015097

Epoch: 6| Step: 5
Training loss: 2.057788372039795
Validation loss: 1.9700276826017646

Epoch: 6| Step: 6
Training loss: 1.810788869857788
Validation loss: 1.9887977005333028

Epoch: 6| Step: 7
Training loss: 2.3760504722595215
Validation loss: 2.0227860225144254

Epoch: 6| Step: 8
Training loss: 1.8505933284759521
Validation loss: 1.961653164637986

Epoch: 6| Step: 9
Training loss: 1.5359578132629395
Validation loss: 1.9689886467431181

Epoch: 6| Step: 10
Training loss: 2.099355697631836
Validation loss: 2.0018294524121028

Epoch: 6| Step: 11
Training loss: 2.500852346420288
Validation loss: 1.9825067648323633

Epoch: 6| Step: 12
Training loss: 2.154364824295044
Validation loss: 1.9922795808443459

Epoch: 6| Step: 13
Training loss: 2.0288655757904053
Validation loss: 1.9973311039709276

Epoch: 173| Step: 0
Training loss: 1.4741225242614746
Validation loss: 1.991637937484249

Epoch: 6| Step: 1
Training loss: 1.5981249809265137
Validation loss: 1.9826257780034056

Epoch: 6| Step: 2
Training loss: 1.563965916633606
Validation loss: 1.9981945381369641

Epoch: 6| Step: 3
Training loss: 2.1324172019958496
Validation loss: 1.980599057289862

Epoch: 6| Step: 4
Training loss: 1.850196123123169
Validation loss: 1.9904408788168302

Epoch: 6| Step: 5
Training loss: 2.046546697616577
Validation loss: 1.9618198666521298

Epoch: 6| Step: 6
Training loss: 1.5069866180419922
Validation loss: 1.976312211764756

Epoch: 6| Step: 7
Training loss: 2.070676803588867
Validation loss: 1.969796601162162

Epoch: 6| Step: 8
Training loss: 2.0822181701660156
Validation loss: 1.9908290755364202

Epoch: 6| Step: 9
Training loss: 2.1034598350524902
Validation loss: 1.9637628934716667

Epoch: 6| Step: 10
Training loss: 2.2397119998931885
Validation loss: 1.995819930107363

Epoch: 6| Step: 11
Training loss: 2.291835308074951
Validation loss: 1.955866838014254

Epoch: 6| Step: 12
Training loss: 2.374201774597168
Validation loss: 1.9887919425964355

Epoch: 6| Step: 13
Training loss: 2.019228935241699
Validation loss: 1.956914795342312

Epoch: 174| Step: 0
Training loss: 1.909665822982788
Validation loss: 1.9756289438534809

Epoch: 6| Step: 1
Training loss: 2.0588231086730957
Validation loss: 1.9775068554826962

Epoch: 6| Step: 2
Training loss: 2.600369930267334
Validation loss: 1.9678331626358854

Epoch: 6| Step: 3
Training loss: 1.6075429916381836
Validation loss: 1.9928756055011545

Epoch: 6| Step: 4
Training loss: 2.405259847640991
Validation loss: 1.9803945608036493

Epoch: 6| Step: 5
Training loss: 1.4136687517166138
Validation loss: 1.9957664141090967

Epoch: 6| Step: 6
Training loss: 3.0440025329589844
Validation loss: 1.995364086602324

Epoch: 6| Step: 7
Training loss: 2.1355652809143066
Validation loss: 1.998401080408404

Epoch: 6| Step: 8
Training loss: 0.8009294867515564
Validation loss: 2.0141751843114055

Epoch: 6| Step: 9
Training loss: 1.885890245437622
Validation loss: 2.0062681064810803

Epoch: 6| Step: 10
Training loss: 1.7161445617675781
Validation loss: 1.9867842684509933

Epoch: 6| Step: 11
Training loss: 1.5609911680221558
Validation loss: 2.006735670951105

Epoch: 6| Step: 12
Training loss: 2.060040235519409
Validation loss: 2.038001657814108

Epoch: 6| Step: 13
Training loss: 2.1159491539001465
Validation loss: 1.9959718706787273

Epoch: 175| Step: 0
Training loss: 1.8989990949630737
Validation loss: 2.022315440639373

Epoch: 6| Step: 1
Training loss: 2.1585183143615723
Validation loss: 2.001704474931122

Epoch: 6| Step: 2
Training loss: 2.0102779865264893
Validation loss: 2.0122596922741143

Epoch: 6| Step: 3
Training loss: 1.524688482284546
Validation loss: 2.01248901121078

Epoch: 6| Step: 4
Training loss: 2.0833563804626465
Validation loss: 1.9985143779426493

Epoch: 6| Step: 5
Training loss: 1.7085130214691162
Validation loss: 1.9827882743650866

Epoch: 6| Step: 6
Training loss: 1.883718729019165
Validation loss: 1.9716418750824467

Epoch: 6| Step: 7
Training loss: 1.8929312229156494
Validation loss: 1.9726332541434997

Epoch: 6| Step: 8
Training loss: 2.214141845703125
Validation loss: 1.9994279261558288

Epoch: 6| Step: 9
Training loss: 1.3917485475540161
Validation loss: 1.978583566604122

Epoch: 6| Step: 10
Training loss: 1.5732743740081787
Validation loss: 1.9849408390701457

Epoch: 6| Step: 11
Training loss: 2.707902431488037
Validation loss: 1.9817124002723283

Epoch: 6| Step: 12
Training loss: 2.542405366897583
Validation loss: 1.973419020252843

Epoch: 6| Step: 13
Training loss: 1.3349554538726807
Validation loss: 2.0171953119257444

Epoch: 176| Step: 0
Training loss: 2.4981324672698975
Validation loss: 2.0005841357733614

Epoch: 6| Step: 1
Training loss: 2.4340686798095703
Validation loss: 1.963475868266116

Epoch: 6| Step: 2
Training loss: 1.5027484893798828
Validation loss: 2.018925172026439

Epoch: 6| Step: 3
Training loss: 1.9136050939559937
Validation loss: 1.9598955185182634

Epoch: 6| Step: 4
Training loss: 1.9936802387237549
Validation loss: 2.024078997232581

Epoch: 6| Step: 5
Training loss: 1.5623385906219482
Validation loss: 1.9639387502465198

Epoch: 6| Step: 6
Training loss: 2.2710986137390137
Validation loss: 2.0040969412813903

Epoch: 6| Step: 7
Training loss: 1.5825891494750977
Validation loss: 1.9976251099699287

Epoch: 6| Step: 8
Training loss: 1.3993570804595947
Validation loss: 1.9960723013006232

Epoch: 6| Step: 9
Training loss: 1.6738405227661133
Validation loss: 2.0105682521738033

Epoch: 6| Step: 10
Training loss: 2.415379524230957
Validation loss: 2.025346945690852

Epoch: 6| Step: 11
Training loss: 2.2369589805603027
Validation loss: 1.9655606951764835

Epoch: 6| Step: 12
Training loss: 1.9840879440307617
Validation loss: 2.000675182188711

Epoch: 6| Step: 13
Training loss: 1.576514482498169
Validation loss: 1.9818941239387757

Epoch: 177| Step: 0
Training loss: 2.095919132232666
Validation loss: 2.0218206144148305

Epoch: 6| Step: 1
Training loss: 1.7701590061187744
Validation loss: 1.9848408904126895

Epoch: 6| Step: 2
Training loss: 1.4832358360290527
Validation loss: 2.003437239636657

Epoch: 6| Step: 3
Training loss: 1.2187130451202393
Validation loss: 1.9885002182376

Epoch: 6| Step: 4
Training loss: 2.5135726928710938
Validation loss: 1.9986398322607881

Epoch: 6| Step: 5
Training loss: 2.2693004608154297
Validation loss: 1.9962094317200363

Epoch: 6| Step: 6
Training loss: 1.7260711193084717
Validation loss: 1.9900751088255195

Epoch: 6| Step: 7
Training loss: 2.218411922454834
Validation loss: 1.9704339683696788

Epoch: 6| Step: 8
Training loss: 2.2621755599975586
Validation loss: 1.9834782461966238

Epoch: 6| Step: 9
Training loss: 1.9962807893753052
Validation loss: 1.9792175318605156

Epoch: 6| Step: 10
Training loss: 1.7093766927719116
Validation loss: 1.9512713775839856

Epoch: 6| Step: 11
Training loss: 2.030773401260376
Validation loss: 2.0074595789755545

Epoch: 6| Step: 12
Training loss: 2.15225887298584
Validation loss: 1.9898839945434241

Epoch: 6| Step: 13
Training loss: 1.3938164710998535
Validation loss: 1.9719548597130725

Epoch: 178| Step: 0
Training loss: 1.7480928897857666
Validation loss: 1.9734495544946322

Epoch: 6| Step: 1
Training loss: 2.2095489501953125
Validation loss: 1.976299193597609

Epoch: 6| Step: 2
Training loss: 1.8096201419830322
Validation loss: 1.9579013803953766

Epoch: 6| Step: 3
Training loss: 1.587625503540039
Validation loss: 2.0033603842540453

Epoch: 6| Step: 4
Training loss: 2.4324018955230713
Validation loss: 1.9892557667147728

Epoch: 6| Step: 5
Training loss: 2.501560688018799
Validation loss: 1.986728722049344

Epoch: 6| Step: 6
Training loss: 1.7966282367706299
Validation loss: 1.989166505875126

Epoch: 6| Step: 7
Training loss: 2.1104557514190674
Validation loss: 1.981331261255408

Epoch: 6| Step: 8
Training loss: 1.8623297214508057
Validation loss: 2.0138726080617597

Epoch: 6| Step: 9
Training loss: 1.7409021854400635
Validation loss: 1.972578328142884

Epoch: 6| Step: 10
Training loss: 1.8287869691848755
Validation loss: 1.9985373173990557

Epoch: 6| Step: 11
Training loss: 1.7296924591064453
Validation loss: 1.967615923573894

Epoch: 6| Step: 12
Training loss: 1.9294447898864746
Validation loss: 1.9903231243933401

Epoch: 6| Step: 13
Training loss: 1.6720768213272095
Validation loss: 1.9728561191148655

Epoch: 179| Step: 0
Training loss: 1.639275312423706
Validation loss: 1.9848858053966234

Epoch: 6| Step: 1
Training loss: 1.41706383228302
Validation loss: 2.016627373233918

Epoch: 6| Step: 2
Training loss: 1.9639792442321777
Validation loss: 1.9489554487248903

Epoch: 6| Step: 3
Training loss: 2.5265696048736572
Validation loss: 1.9712065906934841

Epoch: 6| Step: 4
Training loss: 1.8368499279022217
Validation loss: 1.9898964320459673

Epoch: 6| Step: 5
Training loss: 1.6780809164047241
Validation loss: 1.9879489944827171

Epoch: 6| Step: 6
Training loss: 3.0160112380981445
Validation loss: 1.9982336887749292

Epoch: 6| Step: 7
Training loss: 2.019576072692871
Validation loss: 1.9848901174401725

Epoch: 6| Step: 8
Training loss: 1.9823942184448242
Validation loss: 1.996077270917995

Epoch: 6| Step: 9
Training loss: 1.9627352952957153
Validation loss: 2.0064827421660065

Epoch: 6| Step: 10
Training loss: 1.8532369136810303
Validation loss: 1.9749836101326892

Epoch: 6| Step: 11
Training loss: 1.358365774154663
Validation loss: 1.9703706784914898

Epoch: 6| Step: 12
Training loss: 1.684706449508667
Validation loss: 1.9718247126507502

Epoch: 6| Step: 13
Training loss: 1.8049002885818481
Validation loss: 1.9747352356551795

Epoch: 180| Step: 0
Training loss: 1.9035489559173584
Validation loss: 1.9541595725603

Epoch: 6| Step: 1
Training loss: 2.103447675704956
Validation loss: 1.9883367964016494

Epoch: 6| Step: 2
Training loss: 1.0410747528076172
Validation loss: 1.977026629191573

Epoch: 6| Step: 3
Training loss: 2.12677001953125
Validation loss: 1.9800618694674583

Epoch: 6| Step: 4
Training loss: 2.3746085166931152
Validation loss: 1.9666092293236845

Epoch: 6| Step: 5
Training loss: 2.2626161575317383
Validation loss: 1.943377451230121

Epoch: 6| Step: 6
Training loss: 2.0227973461151123
Validation loss: 1.9704064681965818

Epoch: 6| Step: 7
Training loss: 2.77485990524292
Validation loss: 1.9783315376568866

Epoch: 6| Step: 8
Training loss: 1.7291362285614014
Validation loss: 1.9689924524676414

Epoch: 6| Step: 9
Training loss: 1.4097645282745361
Validation loss: 1.9880367735380768

Epoch: 6| Step: 10
Training loss: 2.3352510929107666
Validation loss: 1.9640138841444446

Epoch: 6| Step: 11
Training loss: 0.9712966680526733
Validation loss: 1.9905163959790302

Epoch: 6| Step: 12
Training loss: 1.6870776414871216
Validation loss: 1.962774145987726

Epoch: 6| Step: 13
Training loss: 2.146911144256592
Validation loss: 1.9981035442762478

Epoch: 181| Step: 0
Training loss: 1.6129213571548462
Validation loss: 1.9786032553642028

Epoch: 6| Step: 1
Training loss: 1.9395933151245117
Validation loss: 1.9572580757961477

Epoch: 6| Step: 2
Training loss: 2.010228157043457
Validation loss: 1.9659302811468802

Epoch: 6| Step: 3
Training loss: 1.7772982120513916
Validation loss: 1.9542692399794055

Epoch: 6| Step: 4
Training loss: 2.181685447692871
Validation loss: 1.9827098384980233

Epoch: 6| Step: 5
Training loss: 1.5207773447036743
Validation loss: 1.956852013064969

Epoch: 6| Step: 6
Training loss: 2.365166664123535
Validation loss: 1.9650408196192917

Epoch: 6| Step: 7
Training loss: 1.3711252212524414
Validation loss: 1.961688216014575

Epoch: 6| Step: 8
Training loss: 2.303380012512207
Validation loss: 1.9671647100038425

Epoch: 6| Step: 9
Training loss: 2.2128653526306152
Validation loss: 2.0093731905824397

Epoch: 6| Step: 10
Training loss: 2.0058982372283936
Validation loss: 1.9909857934521091

Epoch: 6| Step: 11
Training loss: 2.297842502593994
Validation loss: 1.9747262975221038

Epoch: 6| Step: 12
Training loss: 1.5563900470733643
Validation loss: 1.938787047581006

Epoch: 6| Step: 13
Training loss: 1.625225305557251
Validation loss: 1.9615060616565008

Epoch: 182| Step: 0
Training loss: 2.240682601928711
Validation loss: 1.988645435661398

Epoch: 6| Step: 1
Training loss: 1.4431028366088867
Validation loss: 2.0021523557683474

Epoch: 6| Step: 2
Training loss: 2.8806021213531494
Validation loss: 1.9642158580082718

Epoch: 6| Step: 3
Training loss: 1.731308937072754
Validation loss: 1.9708044298233525

Epoch: 6| Step: 4
Training loss: 2.2938308715820312
Validation loss: 1.9385163873754523

Epoch: 6| Step: 5
Training loss: 1.8139843940734863
Validation loss: 1.9806634379971413

Epoch: 6| Step: 6
Training loss: 1.987764835357666
Validation loss: 1.9857459811754123

Epoch: 6| Step: 7
Training loss: 1.0472569465637207
Validation loss: 2.0072412516481135

Epoch: 6| Step: 8
Training loss: 1.8067548274993896
Validation loss: 2.0029154080216602

Epoch: 6| Step: 9
Training loss: 1.6506580114364624
Validation loss: 1.9840565394329768

Epoch: 6| Step: 10
Training loss: 2.8452680110931396
Validation loss: 1.9955885102671962

Epoch: 6| Step: 11
Training loss: 2.0530896186828613
Validation loss: 2.001583706948065

Epoch: 6| Step: 12
Training loss: 1.3898361921310425
Validation loss: 1.9771783890262726

Epoch: 6| Step: 13
Training loss: 2.087831735610962
Validation loss: 1.9653535196858067

Epoch: 183| Step: 0
Training loss: 1.9380528926849365
Validation loss: 1.9640589478195354

Epoch: 6| Step: 1
Training loss: 2.713681221008301
Validation loss: 1.9762832951802078

Epoch: 6| Step: 2
Training loss: 0.4638449251651764
Validation loss: 1.973417417977446

Epoch: 6| Step: 3
Training loss: 2.559814691543579
Validation loss: 1.9889662086322744

Epoch: 6| Step: 4
Training loss: 1.7875993251800537
Validation loss: 2.009693331615899

Epoch: 6| Step: 5
Training loss: 2.354579448699951
Validation loss: 1.9737613380596202

Epoch: 6| Step: 6
Training loss: 1.5440990924835205
Validation loss: 2.001136367039014

Epoch: 6| Step: 7
Training loss: 1.9940975904464722
Validation loss: 1.9890258696771437

Epoch: 6| Step: 8
Training loss: 1.7092864513397217
Validation loss: 1.9753702173950851

Epoch: 6| Step: 9
Training loss: 1.580983281135559
Validation loss: 1.9908837503002537

Epoch: 6| Step: 10
Training loss: 2.140183448791504
Validation loss: 1.9577416207200737

Epoch: 6| Step: 11
Training loss: 2.0341856479644775
Validation loss: 1.9877673438800278

Epoch: 6| Step: 12
Training loss: 1.8860722780227661
Validation loss: 1.988929053788544

Epoch: 6| Step: 13
Training loss: 1.9429049491882324
Validation loss: 2.0018596379987654

Epoch: 184| Step: 0
Training loss: 2.6363492012023926
Validation loss: 1.975946513555383

Epoch: 6| Step: 1
Training loss: 1.995904564857483
Validation loss: 1.9779266106185092

Epoch: 6| Step: 2
Training loss: 2.198147773742676
Validation loss: 1.9435957003665227

Epoch: 6| Step: 3
Training loss: 1.871119499206543
Validation loss: 1.9986842242620324

Epoch: 6| Step: 4
Training loss: 2.133051633834839
Validation loss: 1.9645308397149528

Epoch: 6| Step: 5
Training loss: 1.9656577110290527
Validation loss: 1.9418116346482308

Epoch: 6| Step: 6
Training loss: 0.9796099662780762
Validation loss: 1.9513762176677745

Epoch: 6| Step: 7
Training loss: 2.2823498249053955
Validation loss: 1.9593461636574037

Epoch: 6| Step: 8
Training loss: 1.6085195541381836
Validation loss: 1.9780517547361312

Epoch: 6| Step: 9
Training loss: 1.8098737001419067
Validation loss: 1.9704519702542214

Epoch: 6| Step: 10
Training loss: 1.2091681957244873
Validation loss: 1.9535525716761106

Epoch: 6| Step: 11
Training loss: 1.360154151916504
Validation loss: 1.9452368892649168

Epoch: 6| Step: 12
Training loss: 2.578540325164795
Validation loss: 1.9579183824600712

Epoch: 6| Step: 13
Training loss: 2.288764476776123
Validation loss: 1.9729766332974998

Epoch: 185| Step: 0
Training loss: 2.1722984313964844
Validation loss: 1.938243850584953

Epoch: 6| Step: 1
Training loss: 1.9616730213165283
Validation loss: 1.9810796130088069

Epoch: 6| Step: 2
Training loss: 1.760453224182129
Validation loss: 1.9806056150826075

Epoch: 6| Step: 3
Training loss: 2.1745247840881348
Validation loss: 1.9304600569509691

Epoch: 6| Step: 4
Training loss: 1.8538146018981934
Validation loss: 1.9437176412151707

Epoch: 6| Step: 5
Training loss: 2.1828107833862305
Validation loss: 1.9528919804480769

Epoch: 6| Step: 6
Training loss: 2.243746757507324
Validation loss: 1.9691919152454664

Epoch: 6| Step: 7
Training loss: 1.782331943511963
Validation loss: 1.9518025536690988

Epoch: 6| Step: 8
Training loss: 1.5440384149551392
Validation loss: 1.964377257131761

Epoch: 6| Step: 9
Training loss: 1.8261756896972656
Validation loss: 1.985254700465869

Epoch: 6| Step: 10
Training loss: 2.260399103164673
Validation loss: 1.9808147133037608

Epoch: 6| Step: 11
Training loss: 1.4223862886428833
Validation loss: 1.9853209667308356

Epoch: 6| Step: 12
Training loss: 2.0719573497772217
Validation loss: 1.9616762515037292

Epoch: 6| Step: 13
Training loss: 1.0515532493591309
Validation loss: 1.9701846184269074

Epoch: 186| Step: 0
Training loss: 1.8434083461761475
Validation loss: 1.9550609947532736

Epoch: 6| Step: 1
Training loss: 2.0964887142181396
Validation loss: 1.9728830578506633

Epoch: 6| Step: 2
Training loss: 1.4932851791381836
Validation loss: 1.9680960229648057

Epoch: 6| Step: 3
Training loss: 2.1909232139587402
Validation loss: 1.9952597938558108

Epoch: 6| Step: 4
Training loss: 1.984426498413086
Validation loss: 1.9537309369733256

Epoch: 6| Step: 5
Training loss: 1.7112247943878174
Validation loss: 1.94924928808725

Epoch: 6| Step: 6
Training loss: 1.9399776458740234
Validation loss: 1.9674578815378168

Epoch: 6| Step: 7
Training loss: 1.6888748407363892
Validation loss: 1.9768323026677614

Epoch: 6| Step: 8
Training loss: 1.7897429466247559
Validation loss: 1.9530254615250455

Epoch: 6| Step: 9
Training loss: 1.901174783706665
Validation loss: 1.9682199390985633

Epoch: 6| Step: 10
Training loss: 2.1530652046203613
Validation loss: 1.9602973230423466

Epoch: 6| Step: 11
Training loss: 2.0781607627868652
Validation loss: 1.938762628903953

Epoch: 6| Step: 12
Training loss: 1.7155797481536865
Validation loss: 1.9687527264318159

Epoch: 6| Step: 13
Training loss: 1.978527307510376
Validation loss: 1.9669169943819764

Epoch: 187| Step: 0
Training loss: 1.0010371208190918
Validation loss: 1.958800196647644

Epoch: 6| Step: 1
Training loss: 1.5699118375778198
Validation loss: 1.9521353693418606

Epoch: 6| Step: 2
Training loss: 2.2137436866760254
Validation loss: 1.9535820714889034

Epoch: 6| Step: 3
Training loss: 2.1657328605651855
Validation loss: 1.9821746246789091

Epoch: 6| Step: 4
Training loss: 2.048243284225464
Validation loss: 1.958289651460545

Epoch: 6| Step: 5
Training loss: 1.47735595703125
Validation loss: 1.95707994122659

Epoch: 6| Step: 6
Training loss: 1.4983294010162354
Validation loss: 1.9577567218452372

Epoch: 6| Step: 7
Training loss: 2.7684590816497803
Validation loss: 1.9650598559328305

Epoch: 6| Step: 8
Training loss: 2.421969413757324
Validation loss: 1.9527059921654322

Epoch: 6| Step: 9
Training loss: 1.978804349899292
Validation loss: 1.966673074230071

Epoch: 6| Step: 10
Training loss: 2.1282973289489746
Validation loss: 1.9535757136601273

Epoch: 6| Step: 11
Training loss: 1.6920063495635986
Validation loss: 1.960711670178239

Epoch: 6| Step: 12
Training loss: 1.6961115598678589
Validation loss: 1.9680068505707609

Epoch: 6| Step: 13
Training loss: 1.769519567489624
Validation loss: 1.961709628822983

Epoch: 188| Step: 0
Training loss: 1.90315842628479
Validation loss: 1.9437192614360521

Epoch: 6| Step: 1
Training loss: 1.9632607698440552
Validation loss: 1.975552378162261

Epoch: 6| Step: 2
Training loss: 2.325058937072754
Validation loss: 1.9748475205513738

Epoch: 6| Step: 3
Training loss: 1.3554763793945312
Validation loss: 1.972948166631883

Epoch: 6| Step: 4
Training loss: 1.533281683921814
Validation loss: 1.9585537102914625

Epoch: 6| Step: 5
Training loss: 1.706092119216919
Validation loss: 1.973894170535508

Epoch: 6| Step: 6
Training loss: 1.830398440361023
Validation loss: 1.9650950662551387

Epoch: 6| Step: 7
Training loss: 1.4403256177902222
Validation loss: 1.9907028213624032

Epoch: 6| Step: 8
Training loss: 2.478400230407715
Validation loss: 2.000235765211044

Epoch: 6| Step: 9
Training loss: 1.753466248512268
Validation loss: 1.9816783012882355

Epoch: 6| Step: 10
Training loss: 2.006925106048584
Validation loss: 1.9799287267910537

Epoch: 6| Step: 11
Training loss: 1.8967735767364502
Validation loss: 2.0155862556990756

Epoch: 6| Step: 12
Training loss: 2.0760815143585205
Validation loss: 1.9865658744688957

Epoch: 6| Step: 13
Training loss: 2.3108582496643066
Validation loss: 2.0064720671664

Epoch: 189| Step: 0
Training loss: 1.4342787265777588
Validation loss: 1.9850394174616823

Epoch: 6| Step: 1
Training loss: 2.0736024379730225
Validation loss: 1.96732803826691

Epoch: 6| Step: 2
Training loss: 2.021186590194702
Validation loss: 1.9800142331789898

Epoch: 6| Step: 3
Training loss: 1.861825942993164
Validation loss: 1.970140786581142

Epoch: 6| Step: 4
Training loss: 1.6391675472259521
Validation loss: 1.9724503896569694

Epoch: 6| Step: 5
Training loss: 1.776906967163086
Validation loss: 1.9580615233349543

Epoch: 6| Step: 6
Training loss: 2.439032554626465
Validation loss: 1.9466669085205242

Epoch: 6| Step: 7
Training loss: 2.0083250999450684
Validation loss: 1.965547800064087

Epoch: 6| Step: 8
Training loss: 1.6476523876190186
Validation loss: 1.9405090026958014

Epoch: 6| Step: 9
Training loss: 2.2988431453704834
Validation loss: 1.9496362363138506

Epoch: 6| Step: 10
Training loss: 1.9812126159667969
Validation loss: 1.9572199557417183

Epoch: 6| Step: 11
Training loss: 2.0392963886260986
Validation loss: 1.9401938351251746

Epoch: 6| Step: 12
Training loss: 1.5210843086242676
Validation loss: 1.9278434143271497

Epoch: 6| Step: 13
Training loss: 1.7313624620437622
Validation loss: 1.9693677835567023

Epoch: 190| Step: 0
Training loss: 2.146204948425293
Validation loss: 1.9371096421313543

Epoch: 6| Step: 1
Training loss: 2.0291903018951416
Validation loss: 1.9812827469200216

Epoch: 6| Step: 2
Training loss: 1.9783117771148682
Validation loss: 1.9513791389362787

Epoch: 6| Step: 3
Training loss: 2.1076791286468506
Validation loss: 1.9518309716255433

Epoch: 6| Step: 4
Training loss: 1.8422024250030518
Validation loss: 1.9630008166836155

Epoch: 6| Step: 5
Training loss: 1.6969456672668457
Validation loss: 1.9186606330256308

Epoch: 6| Step: 6
Training loss: 1.761967658996582
Validation loss: 1.9852145077079855

Epoch: 6| Step: 7
Training loss: 2.2172107696533203
Validation loss: 1.956337905699207

Epoch: 6| Step: 8
Training loss: 1.558884859085083
Validation loss: 1.936605543218633

Epoch: 6| Step: 9
Training loss: 1.8511452674865723
Validation loss: 1.9498751573665167

Epoch: 6| Step: 10
Training loss: 1.6774531602859497
Validation loss: 1.9594136450880317

Epoch: 6| Step: 11
Training loss: 1.8727761507034302
Validation loss: 1.9473301620893582

Epoch: 6| Step: 12
Training loss: 1.3641153573989868
Validation loss: 1.9635276922615625

Epoch: 6| Step: 13
Training loss: 2.023681163787842
Validation loss: 1.9449295561800721

Epoch: 191| Step: 0
Training loss: 2.2840871810913086
Validation loss: 1.978359007066296

Epoch: 6| Step: 1
Training loss: 2.3769683837890625
Validation loss: 1.9936743269684494

Epoch: 6| Step: 2
Training loss: 2.2561874389648438
Validation loss: 1.9568922942684543

Epoch: 6| Step: 3
Training loss: 1.4726169109344482
Validation loss: 1.9813556696778984

Epoch: 6| Step: 4
Training loss: 2.152909755706787
Validation loss: 1.9609038022256666

Epoch: 6| Step: 5
Training loss: 2.1383090019226074
Validation loss: 1.9626746857038109

Epoch: 6| Step: 6
Training loss: 1.525298833847046
Validation loss: 1.9799760618517477

Epoch: 6| Step: 7
Training loss: 2.048269748687744
Validation loss: 1.9563883158468431

Epoch: 6| Step: 8
Training loss: 1.5233516693115234
Validation loss: 1.9570980636022424

Epoch: 6| Step: 9
Training loss: 1.729968786239624
Validation loss: 1.967098734712088

Epoch: 6| Step: 10
Training loss: 1.8053247928619385
Validation loss: 1.9706090214431926

Epoch: 6| Step: 11
Training loss: 1.35347318649292
Validation loss: 1.9492321219495548

Epoch: 6| Step: 12
Training loss: 1.8415894508361816
Validation loss: 1.975744928083112

Epoch: 6| Step: 13
Training loss: 1.8131814002990723
Validation loss: 1.9443750484015352

Epoch: 192| Step: 0
Training loss: 1.007933259010315
Validation loss: 1.940355436776274

Epoch: 6| Step: 1
Training loss: 2.250929355621338
Validation loss: 1.9167713298592517

Epoch: 6| Step: 2
Training loss: 1.6114435195922852
Validation loss: 1.9479750869094685

Epoch: 6| Step: 3
Training loss: 1.947930097579956
Validation loss: 1.9725181671880907

Epoch: 6| Step: 4
Training loss: 1.6585628986358643
Validation loss: 1.915771758684548

Epoch: 6| Step: 5
Training loss: 1.6955493688583374
Validation loss: 1.9562316889403968

Epoch: 6| Step: 6
Training loss: 2.291027545928955
Validation loss: 1.9196088262783584

Epoch: 6| Step: 7
Training loss: 1.8442425727844238
Validation loss: 1.9461730295611965

Epoch: 6| Step: 8
Training loss: 1.5911531448364258
Validation loss: 1.9546147085005237

Epoch: 6| Step: 9
Training loss: 2.1561245918273926
Validation loss: 1.955917763453658

Epoch: 6| Step: 10
Training loss: 2.1913228034973145
Validation loss: 1.9194763475848782

Epoch: 6| Step: 11
Training loss: 2.2677791118621826
Validation loss: 1.9474688255658714

Epoch: 6| Step: 12
Training loss: 1.924588918685913
Validation loss: 1.940984567006429

Epoch: 6| Step: 13
Training loss: 1.8050482273101807
Validation loss: 1.9159106823705858

Epoch: 193| Step: 0
Training loss: 1.6220930814743042
Validation loss: 1.9711675964375979

Epoch: 6| Step: 1
Training loss: 1.6438100337982178
Validation loss: 1.9669871663534513

Epoch: 6| Step: 2
Training loss: 1.652808427810669
Validation loss: 1.9898618408428725

Epoch: 6| Step: 3
Training loss: 1.9387233257293701
Validation loss: 1.9508840755749774

Epoch: 6| Step: 4
Training loss: 1.7442476749420166
Validation loss: 1.9880323281852148

Epoch: 6| Step: 5
Training loss: 2.102051258087158
Validation loss: 1.96611358786142

Epoch: 6| Step: 6
Training loss: 2.078824043273926
Validation loss: 2.004439362915613

Epoch: 6| Step: 7
Training loss: 1.7144997119903564
Validation loss: 2.0015224231186735

Epoch: 6| Step: 8
Training loss: 2.3737456798553467
Validation loss: 1.9619314952563214

Epoch: 6| Step: 9
Training loss: 2.1507019996643066
Validation loss: 1.9707842526897308

Epoch: 6| Step: 10
Training loss: 2.1434860229492188
Validation loss: 2.0084883269443305

Epoch: 6| Step: 11
Training loss: 1.8048217296600342
Validation loss: 2.0241775269149453

Epoch: 6| Step: 12
Training loss: 1.8970359563827515
Validation loss: 2.0013341160230738

Epoch: 6| Step: 13
Training loss: 1.337431788444519
Validation loss: 2.0026661170426237

Epoch: 194| Step: 0
Training loss: 2.1812686920166016
Validation loss: 1.9897403076130857

Epoch: 6| Step: 1
Training loss: 1.6722383499145508
Validation loss: 2.005286688445717

Epoch: 6| Step: 2
Training loss: 1.6912479400634766
Validation loss: 1.9985211895358177

Epoch: 6| Step: 3
Training loss: 1.5041862726211548
Validation loss: 2.0060393233453073

Epoch: 6| Step: 4
Training loss: 1.9887807369232178
Validation loss: 1.9489657007237917

Epoch: 6| Step: 5
Training loss: 2.0352001190185547
Validation loss: 1.9904967751554263

Epoch: 6| Step: 6
Training loss: 1.744221806526184
Validation loss: 1.9397870609837193

Epoch: 6| Step: 7
Training loss: 2.0538785457611084
Validation loss: 1.951034725353282

Epoch: 6| Step: 8
Training loss: 1.6386897563934326
Validation loss: 1.9435514903837634

Epoch: 6| Step: 9
Training loss: 2.025599479675293
Validation loss: 1.9576699579915693

Epoch: 6| Step: 10
Training loss: 2.0534629821777344
Validation loss: 1.961153268814087

Epoch: 6| Step: 11
Training loss: 2.2018566131591797
Validation loss: 1.9658920431649813

Epoch: 6| Step: 12
Training loss: 1.6729216575622559
Validation loss: 1.952183513231175

Epoch: 6| Step: 13
Training loss: 1.7445216178894043
Validation loss: 1.9528084288361252

Epoch: 195| Step: 0
Training loss: 1.6244194507598877
Validation loss: 1.9508123782373243

Epoch: 6| Step: 1
Training loss: 1.846398949623108
Validation loss: 1.9227457072145195

Epoch: 6| Step: 2
Training loss: 2.176128387451172
Validation loss: 1.9653863112131755

Epoch: 6| Step: 3
Training loss: 2.033043384552002
Validation loss: 1.9402652414896155

Epoch: 6| Step: 4
Training loss: 2.2278785705566406
Validation loss: 1.9377760041144587

Epoch: 6| Step: 5
Training loss: 2.476707935333252
Validation loss: 1.9444418748219807

Epoch: 6| Step: 6
Training loss: 1.9835975170135498
Validation loss: 1.9388287221231768

Epoch: 6| Step: 7
Training loss: 1.1001887321472168
Validation loss: 1.976623260846702

Epoch: 6| Step: 8
Training loss: 0.9668792486190796
Validation loss: 1.929038888664656

Epoch: 6| Step: 9
Training loss: 1.6256258487701416
Validation loss: 1.925559046447918

Epoch: 6| Step: 10
Training loss: 2.074125289916992
Validation loss: 1.9474962283206243

Epoch: 6| Step: 11
Training loss: 2.1609580516815186
Validation loss: 1.9372768184190154

Epoch: 6| Step: 12
Training loss: 1.6709274053573608
Validation loss: 1.9440056124041158

Epoch: 6| Step: 13
Training loss: 2.078986883163452
Validation loss: 1.963823785064041

Epoch: 196| Step: 0
Training loss: 1.6333184242248535
Validation loss: 1.9675892373566986

Epoch: 6| Step: 1
Training loss: 1.8750152587890625
Validation loss: 1.9541884109538088

Epoch: 6| Step: 2
Training loss: 1.771843671798706
Validation loss: 1.995772664264966

Epoch: 6| Step: 3
Training loss: 2.036693811416626
Validation loss: 1.9466484592806907

Epoch: 6| Step: 4
Training loss: 2.5210256576538086
Validation loss: 1.9609127095950547

Epoch: 6| Step: 5
Training loss: 1.9716849327087402
Validation loss: 1.9788389385387462

Epoch: 6| Step: 6
Training loss: 2.0572125911712646
Validation loss: 1.9758403467875656

Epoch: 6| Step: 7
Training loss: 2.504734516143799
Validation loss: 1.972428398747598

Epoch: 6| Step: 8
Training loss: 1.283273696899414
Validation loss: 1.9749393770771642

Epoch: 6| Step: 9
Training loss: 1.610775351524353
Validation loss: 1.9580100902947046

Epoch: 6| Step: 10
Training loss: 1.4325463771820068
Validation loss: 1.9900748947615265

Epoch: 6| Step: 11
Training loss: 1.6536527872085571
Validation loss: 1.9621219942646642

Epoch: 6| Step: 12
Training loss: 1.326907992362976
Validation loss: 1.9906595573630383

Epoch: 6| Step: 13
Training loss: 2.715879201889038
Validation loss: 1.9610464406269852

Epoch: 197| Step: 0
Training loss: 1.6675615310668945
Validation loss: 1.9388781093781995

Epoch: 6| Step: 1
Training loss: 2.8187737464904785
Validation loss: 1.9450808417412542

Epoch: 6| Step: 2
Training loss: 1.6394484043121338
Validation loss: 1.9546533066739318

Epoch: 6| Step: 3
Training loss: 1.9606902599334717
Validation loss: 1.9542911091158468

Epoch: 6| Step: 4
Training loss: 2.3998987674713135
Validation loss: 1.965734520266133

Epoch: 6| Step: 5
Training loss: 1.429512858390808
Validation loss: 1.9344873274526289

Epoch: 6| Step: 6
Training loss: 2.4429821968078613
Validation loss: 1.9416707484952864

Epoch: 6| Step: 7
Training loss: 1.2647907733917236
Validation loss: 1.9515673370771511

Epoch: 6| Step: 8
Training loss: 2.08461332321167
Validation loss: 1.9375534621618127

Epoch: 6| Step: 9
Training loss: 1.4892979860305786
Validation loss: 1.9464091575273903

Epoch: 6| Step: 10
Training loss: 1.4518048763275146
Validation loss: 1.9621093644890735

Epoch: 6| Step: 11
Training loss: 2.0657448768615723
Validation loss: 1.9677895115267845

Epoch: 6| Step: 12
Training loss: 1.8005437850952148
Validation loss: 1.9267075548889816

Epoch: 6| Step: 13
Training loss: 1.2618802785873413
Validation loss: 1.935528693660613

Epoch: 198| Step: 0
Training loss: 1.1279900074005127
Validation loss: 1.9567696817459599

Epoch: 6| Step: 1
Training loss: 2.079745292663574
Validation loss: 1.919474080044736

Epoch: 6| Step: 2
Training loss: 2.468440294265747
Validation loss: 1.9336879714842765

Epoch: 6| Step: 3
Training loss: 2.3990159034729004
Validation loss: 1.9337155588211552

Epoch: 6| Step: 4
Training loss: 2.0425126552581787
Validation loss: 1.9631425847289383

Epoch: 6| Step: 5
Training loss: 1.8024709224700928
Validation loss: 1.9410196978558776

Epoch: 6| Step: 6
Training loss: 1.2723822593688965
Validation loss: 1.9381713521096013

Epoch: 6| Step: 7
Training loss: 2.051933526992798
Validation loss: 1.9287325874451668

Epoch: 6| Step: 8
Training loss: 1.8654718399047852
Validation loss: 1.9003132671438239

Epoch: 6| Step: 9
Training loss: 1.3952394723892212
Validation loss: 1.9168612187908542

Epoch: 6| Step: 10
Training loss: 2.216675043106079
Validation loss: 1.9300465660710489

Epoch: 6| Step: 11
Training loss: 1.8529629707336426
Validation loss: 1.943401405888219

Epoch: 6| Step: 12
Training loss: 1.7962055206298828
Validation loss: 1.9263673264493224

Epoch: 6| Step: 13
Training loss: 1.6265888214111328
Validation loss: 1.9711308120399393

Epoch: 199| Step: 0
Training loss: 1.4763975143432617
Validation loss: 1.9481641348972116

Epoch: 6| Step: 1
Training loss: 1.963736891746521
Validation loss: 1.9250754925512499

Epoch: 6| Step: 2
Training loss: 2.3555355072021484
Validation loss: 1.9769871234893799

Epoch: 6| Step: 3
Training loss: 2.3364014625549316
Validation loss: 1.9418253411528885

Epoch: 6| Step: 4
Training loss: 1.1956119537353516
Validation loss: 1.9172408375688779

Epoch: 6| Step: 5
Training loss: 1.7094981670379639
Validation loss: 1.8979075339532667

Epoch: 6| Step: 6
Training loss: 1.4379463195800781
Validation loss: 1.9589144029924948

Epoch: 6| Step: 7
Training loss: 1.4538432359695435
Validation loss: 1.9197556511048348

Epoch: 6| Step: 8
Training loss: 2.6243042945861816
Validation loss: 1.9424238281865274

Epoch: 6| Step: 9
Training loss: 1.9704376459121704
Validation loss: 1.946959908290576

Epoch: 6| Step: 10
Training loss: 1.8323689699172974
Validation loss: 1.9427798281433761

Epoch: 6| Step: 11
Training loss: 1.6886122226715088
Validation loss: 1.9377436817333262

Epoch: 6| Step: 12
Training loss: 2.2274255752563477
Validation loss: 1.9424680330420052

Epoch: 6| Step: 13
Training loss: 1.1092274188995361
Validation loss: 1.907919115917657

Epoch: 200| Step: 0
Training loss: 1.7053449153900146
Validation loss: 1.9586430826494772

Epoch: 6| Step: 1
Training loss: 2.191148042678833
Validation loss: 1.9186443795440018

Epoch: 6| Step: 2
Training loss: 2.2490878105163574
Validation loss: 1.9321621451326596

Epoch: 6| Step: 3
Training loss: 2.2422232627868652
Validation loss: 1.9409089114076348

Epoch: 6| Step: 4
Training loss: 1.5554721355438232
Validation loss: 1.9371272825425672

Epoch: 6| Step: 5
Training loss: 1.320141315460205
Validation loss: 1.9262148077769945

Epoch: 6| Step: 6
Training loss: 1.8496136665344238
Validation loss: 1.946497788993261

Epoch: 6| Step: 7
Training loss: 1.7570449113845825
Validation loss: 1.9559140436110958

Epoch: 6| Step: 8
Training loss: 1.5679714679718018
Validation loss: 1.9819451660238288

Epoch: 6| Step: 9
Training loss: 1.6881704330444336
Validation loss: 1.9366318615533973

Epoch: 6| Step: 10
Training loss: 1.644273281097412
Validation loss: 1.9668660804789553

Epoch: 6| Step: 11
Training loss: 1.8146893978118896
Validation loss: 1.9503124760043236

Epoch: 6| Step: 12
Training loss: 2.290438652038574
Validation loss: 1.9582055640477005

Epoch: 6| Step: 13
Training loss: 1.702473521232605
Validation loss: 1.9407812062130179

Epoch: 201| Step: 0
Training loss: 1.8194270133972168
Validation loss: 1.9555152129101496

Epoch: 6| Step: 1
Training loss: 1.9520039558410645
Validation loss: 1.955342943950366

Epoch: 6| Step: 2
Training loss: 2.3242063522338867
Validation loss: 1.939060821328112

Epoch: 6| Step: 3
Training loss: 1.643533706665039
Validation loss: 1.8852070223900579

Epoch: 6| Step: 4
Training loss: 1.3767635822296143
Validation loss: 1.9560361728873303

Epoch: 6| Step: 5
Training loss: 2.083238124847412
Validation loss: 1.91220691768072

Epoch: 6| Step: 6
Training loss: 1.846086859703064
Validation loss: 1.9513925942041541

Epoch: 6| Step: 7
Training loss: 1.8958358764648438
Validation loss: 1.9277641183586531

Epoch: 6| Step: 8
Training loss: 2.1550307273864746
Validation loss: 1.9485573666070097

Epoch: 6| Step: 9
Training loss: 2.2190473079681396
Validation loss: 1.9031643662401425

Epoch: 6| Step: 10
Training loss: 1.5346925258636475
Validation loss: 1.9220562109383204

Epoch: 6| Step: 11
Training loss: 1.5952246189117432
Validation loss: 1.9204848069016651

Epoch: 6| Step: 12
Training loss: 2.09587025642395
Validation loss: 1.9336948253775155

Epoch: 6| Step: 13
Training loss: 1.4047987461090088
Validation loss: 1.9416347498534827

Epoch: 202| Step: 0
Training loss: 1.4613862037658691
Validation loss: 1.9345872991828508

Epoch: 6| Step: 1
Training loss: 1.820245623588562
Validation loss: 1.9656761307870187

Epoch: 6| Step: 2
Training loss: 1.7939655780792236
Validation loss: 1.9575806766427972

Epoch: 6| Step: 3
Training loss: 2.2358784675598145
Validation loss: 1.919637349344069

Epoch: 6| Step: 4
Training loss: 1.4044158458709717
Validation loss: 1.9530349777590843

Epoch: 6| Step: 5
Training loss: 1.638283610343933
Validation loss: 1.9641255537668865

Epoch: 6| Step: 6
Training loss: 2.4437966346740723
Validation loss: 1.9135839759662587

Epoch: 6| Step: 7
Training loss: 1.94862699508667
Validation loss: 1.9451793586054156

Epoch: 6| Step: 8
Training loss: 1.5492711067199707
Validation loss: 1.9404133648000739

Epoch: 6| Step: 9
Training loss: 2.1082825660705566
Validation loss: 1.9132859873515304

Epoch: 6| Step: 10
Training loss: 1.727449893951416
Validation loss: 1.9564889259235834

Epoch: 6| Step: 11
Training loss: 1.9563692808151245
Validation loss: 1.9296806935341126

Epoch: 6| Step: 12
Training loss: 1.5491023063659668
Validation loss: 1.951727528725901

Epoch: 6| Step: 13
Training loss: 2.3495612144470215
Validation loss: 1.9380173606257285

Epoch: 203| Step: 0
Training loss: 1.5617930889129639
Validation loss: 1.9629541750877135

Epoch: 6| Step: 1
Training loss: 1.5901333093643188
Validation loss: 1.9249193335092196

Epoch: 6| Step: 2
Training loss: 2.423685073852539
Validation loss: 1.9229385763086297

Epoch: 6| Step: 3
Training loss: 1.7581706047058105
Validation loss: 1.9414994588462255

Epoch: 6| Step: 4
Training loss: 1.527580738067627
Validation loss: 1.9296188662129063

Epoch: 6| Step: 5
Training loss: 1.8377559185028076
Validation loss: 1.9539377291997273

Epoch: 6| Step: 6
Training loss: 2.1568527221679688
Validation loss: 1.8942610281769947

Epoch: 6| Step: 7
Training loss: 1.673926591873169
Validation loss: 1.9170377433940928

Epoch: 6| Step: 8
Training loss: 1.7676560878753662
Validation loss: 1.942462710924046

Epoch: 6| Step: 9
Training loss: 1.540950059890747
Validation loss: 1.9447277361346829

Epoch: 6| Step: 10
Training loss: 1.8448883295059204
Validation loss: 1.9255621074348368

Epoch: 6| Step: 11
Training loss: 1.9899405241012573
Validation loss: 1.9045344988505046

Epoch: 6| Step: 12
Training loss: 1.747717022895813
Validation loss: 1.8981725221039147

Epoch: 6| Step: 13
Training loss: 2.7103395462036133
Validation loss: 1.9485080011429325

Epoch: 204| Step: 0
Training loss: 1.9816088676452637
Validation loss: 1.9176102351116877

Epoch: 6| Step: 1
Training loss: 2.2079343795776367
Validation loss: 1.9256916405052267

Epoch: 6| Step: 2
Training loss: 1.5585722923278809
Validation loss: 1.9235559022554787

Epoch: 6| Step: 3
Training loss: 1.9566597938537598
Validation loss: 1.9174097250866633

Epoch: 6| Step: 4
Training loss: 1.7617708444595337
Validation loss: 1.938759192343681

Epoch: 6| Step: 5
Training loss: 1.773618459701538
Validation loss: 1.971136764813495

Epoch: 6| Step: 6
Training loss: 1.5392000675201416
Validation loss: 1.9419114999873663

Epoch: 6| Step: 7
Training loss: 1.4316463470458984
Validation loss: 1.9303763848479076

Epoch: 6| Step: 8
Training loss: 1.778439998626709
Validation loss: 1.9631955187807801

Epoch: 6| Step: 9
Training loss: 2.5807204246520996
Validation loss: 1.9491441096028974

Epoch: 6| Step: 10
Training loss: 1.5108578205108643
Validation loss: 1.9429874150983748

Epoch: 6| Step: 11
Training loss: 1.5534892082214355
Validation loss: 1.942151733624038

Epoch: 6| Step: 12
Training loss: 2.235447645187378
Validation loss: 1.9557191095044535

Epoch: 6| Step: 13
Training loss: 1.1161280870437622
Validation loss: 1.9366218043911843

Epoch: 205| Step: 0
Training loss: 2.2201249599456787
Validation loss: 1.9141072445018317

Epoch: 6| Step: 1
Training loss: 2.6194467544555664
Validation loss: 1.9572459805396296

Epoch: 6| Step: 2
Training loss: 1.2579820156097412
Validation loss: 1.9563634062326083

Epoch: 6| Step: 3
Training loss: 1.592094898223877
Validation loss: 1.9401996520257765

Epoch: 6| Step: 4
Training loss: 1.577082872390747
Validation loss: 1.9301301446012271

Epoch: 6| Step: 5
Training loss: 1.994829535484314
Validation loss: 1.9294278980583273

Epoch: 6| Step: 6
Training loss: 1.5621156692504883
Validation loss: 1.9111415955328173

Epoch: 6| Step: 7
Training loss: 2.1802597045898438
Validation loss: 1.9212157982651905

Epoch: 6| Step: 8
Training loss: 1.803575873374939
Validation loss: 1.9030021480334702

Epoch: 6| Step: 9
Training loss: 0.9254723191261292
Validation loss: 1.9167031985457226

Epoch: 6| Step: 10
Training loss: 1.9675462245941162
Validation loss: 1.9395333836155553

Epoch: 6| Step: 11
Training loss: 2.200946807861328
Validation loss: 1.908963757176553

Epoch: 6| Step: 12
Training loss: 1.5820121765136719
Validation loss: 1.9279087602451284

Epoch: 6| Step: 13
Training loss: 2.1771788597106934
Validation loss: 1.9048134985790457

Epoch: 206| Step: 0
Training loss: 1.491783618927002
Validation loss: 1.9107852264117169

Epoch: 6| Step: 1
Training loss: 0.7916806936264038
Validation loss: 1.9272825461561962

Epoch: 6| Step: 2
Training loss: 2.6443161964416504
Validation loss: 1.9203206070007817

Epoch: 6| Step: 3
Training loss: 1.617140769958496
Validation loss: 1.9169270479550926

Epoch: 6| Step: 4
Training loss: 1.604098916053772
Validation loss: 1.9072171077933362

Epoch: 6| Step: 5
Training loss: 1.310556411743164
Validation loss: 1.90359458743885

Epoch: 6| Step: 6
Training loss: 2.1340858936309814
Validation loss: 1.9326464847851825

Epoch: 6| Step: 7
Training loss: 1.818583369255066
Validation loss: 1.9398405936456495

Epoch: 6| Step: 8
Training loss: 1.8980964422225952
Validation loss: 1.931651948600687

Epoch: 6| Step: 9
Training loss: 1.7241532802581787
Validation loss: 1.917728175399124

Epoch: 6| Step: 10
Training loss: 2.7064898014068604
Validation loss: 1.920909422700123

Epoch: 6| Step: 11
Training loss: 1.7885955572128296
Validation loss: 1.9458835714606828

Epoch: 6| Step: 12
Training loss: 1.9929476976394653
Validation loss: 1.933237252696868

Epoch: 6| Step: 13
Training loss: 1.6690964698791504
Validation loss: 1.9643270700208602

Epoch: 207| Step: 0
Training loss: 2.2600157260894775
Validation loss: 1.9662224810610536

Epoch: 6| Step: 1
Training loss: 1.7960691452026367
Validation loss: 1.9762508715352705

Epoch: 6| Step: 2
Training loss: 1.1254976987838745
Validation loss: 1.9513469075643888

Epoch: 6| Step: 3
Training loss: 1.3677476644515991
Validation loss: 1.9098585190311554

Epoch: 6| Step: 4
Training loss: 1.9669655561447144
Validation loss: 1.936518265355018

Epoch: 6| Step: 5
Training loss: 1.496799349784851
Validation loss: 1.962842373437779

Epoch: 6| Step: 6
Training loss: 1.7132132053375244
Validation loss: 1.937021755403088

Epoch: 6| Step: 7
Training loss: 1.9557526111602783
Validation loss: 1.9517960253582205

Epoch: 6| Step: 8
Training loss: 2.1268444061279297
Validation loss: 1.8979498288964713

Epoch: 6| Step: 9
Training loss: 2.2796034812927246
Validation loss: 1.910457564938453

Epoch: 6| Step: 10
Training loss: 1.8691108226776123
Validation loss: 1.9225018639718332

Epoch: 6| Step: 11
Training loss: 1.6032497882843018
Validation loss: 1.9252624639900782

Epoch: 6| Step: 12
Training loss: 1.501232624053955
Validation loss: 1.9032532656064598

Epoch: 6| Step: 13
Training loss: 2.414275646209717
Validation loss: 1.9510897051903509

Epoch: 208| Step: 0
Training loss: 2.444077253341675
Validation loss: 1.8876491233866701

Epoch: 6| Step: 1
Training loss: 2.2807021141052246
Validation loss: 1.9151432898736769

Epoch: 6| Step: 2
Training loss: 1.495850920677185
Validation loss: 1.9414570164936844

Epoch: 6| Step: 3
Training loss: 1.6603538990020752
Validation loss: 1.943632004081562

Epoch: 6| Step: 4
Training loss: 1.7333635091781616
Validation loss: 1.9178741465332687

Epoch: 6| Step: 5
Training loss: 2.2428016662597656
Validation loss: 1.9106415599905036

Epoch: 6| Step: 6
Training loss: 2.4976205825805664
Validation loss: 1.8964332329329623

Epoch: 6| Step: 7
Training loss: 1.1498150825500488
Validation loss: 1.909979538250995

Epoch: 6| Step: 8
Training loss: 1.8520777225494385
Validation loss: 1.891118562349709

Epoch: 6| Step: 9
Training loss: 1.6516590118408203
Validation loss: 1.9528164581585956

Epoch: 6| Step: 10
Training loss: 1.6870390176773071
Validation loss: 1.9410332402875345

Epoch: 6| Step: 11
Training loss: 1.2755036354064941
Validation loss: 1.9598484500761955

Epoch: 6| Step: 12
Training loss: 1.9086966514587402
Validation loss: 1.9272360109513806

Epoch: 6| Step: 13
Training loss: 1.1641995906829834
Validation loss: 1.9464182110242947

Epoch: 209| Step: 0
Training loss: 1.3417415618896484
Validation loss: 1.9267541285484069

Epoch: 6| Step: 1
Training loss: 1.8715503215789795
Validation loss: 1.9499603599630377

Epoch: 6| Step: 2
Training loss: 2.3530731201171875
Validation loss: 1.915991078140915

Epoch: 6| Step: 3
Training loss: 1.5998075008392334
Validation loss: 1.9261625710354056

Epoch: 6| Step: 4
Training loss: 1.2927539348602295
Validation loss: 1.9419187268903177

Epoch: 6| Step: 5
Training loss: 1.9709763526916504
Validation loss: 1.9443702415753437

Epoch: 6| Step: 6
Training loss: 2.2096314430236816
Validation loss: 1.9641609114985312

Epoch: 6| Step: 7
Training loss: 1.3553986549377441
Validation loss: 1.9429685095305085

Epoch: 6| Step: 8
Training loss: 1.3062684535980225
Validation loss: 1.9552838879246865

Epoch: 6| Step: 9
Training loss: 1.810584545135498
Validation loss: 1.9454551204558341

Epoch: 6| Step: 10
Training loss: 1.9514273405075073
Validation loss: 1.9123803159242034

Epoch: 6| Step: 11
Training loss: 1.287858009338379
Validation loss: 1.9626976674602878

Epoch: 6| Step: 12
Training loss: 2.470553159713745
Validation loss: 1.9407507206804009

Epoch: 6| Step: 13
Training loss: 2.894512176513672
Validation loss: 1.9432450033003283

Epoch: 210| Step: 0
Training loss: 2.124419689178467
Validation loss: 1.9032094196606708

Epoch: 6| Step: 1
Training loss: 1.6645100116729736
Validation loss: 1.923010536419448

Epoch: 6| Step: 2
Training loss: 2.1462082862854004
Validation loss: 1.928158083269673

Epoch: 6| Step: 3
Training loss: 1.0637931823730469
Validation loss: 1.9273222774587653

Epoch: 6| Step: 4
Training loss: 1.8794721364974976
Validation loss: 1.9323716701999787

Epoch: 6| Step: 5
Training loss: 1.8057911396026611
Validation loss: 1.9188834646696686

Epoch: 6| Step: 6
Training loss: 1.529565691947937
Validation loss: 1.9063802931898384

Epoch: 6| Step: 7
Training loss: 1.352732539176941
Validation loss: 1.917662723090059

Epoch: 6| Step: 8
Training loss: 2.5472724437713623
Validation loss: 1.9152473070288216

Epoch: 6| Step: 9
Training loss: 1.6961638927459717
Validation loss: 1.9249177363611036

Epoch: 6| Step: 10
Training loss: 1.8659260272979736
Validation loss: 1.9268355382386075

Epoch: 6| Step: 11
Training loss: 1.979658603668213
Validation loss: 1.9240221900324668

Epoch: 6| Step: 12
Training loss: 1.8604929447174072
Validation loss: 1.9202796131051996

Epoch: 6| Step: 13
Training loss: 1.6398991346359253
Validation loss: 1.881211175713488

Epoch: 211| Step: 0
Training loss: 1.6625113487243652
Validation loss: 1.9215848176710066

Epoch: 6| Step: 1
Training loss: 1.3802447319030762
Validation loss: 1.9173447034692253

Epoch: 6| Step: 2
Training loss: 1.483161449432373
Validation loss: 1.8963361414529945

Epoch: 6| Step: 3
Training loss: 2.3542652130126953
Validation loss: 1.9239233770678121

Epoch: 6| Step: 4
Training loss: 2.2675957679748535
Validation loss: 1.9108682781137445

Epoch: 6| Step: 5
Training loss: 2.3541650772094727
Validation loss: 1.8785231600525558

Epoch: 6| Step: 6
Training loss: 0.9640549421310425
Validation loss: 1.9767472897806475

Epoch: 6| Step: 7
Training loss: 1.240613579750061
Validation loss: 1.892898246806155

Epoch: 6| Step: 8
Training loss: 1.5826350450515747
Validation loss: 1.9313250639105355

Epoch: 6| Step: 9
Training loss: 1.6597404479980469
Validation loss: 1.9394356358435847

Epoch: 6| Step: 10
Training loss: 1.7556604146957397
Validation loss: 1.9393525918324788

Epoch: 6| Step: 11
Training loss: 1.8008856773376465
Validation loss: 1.9141631318676857

Epoch: 6| Step: 12
Training loss: 2.694949150085449
Validation loss: 1.9080658587076331

Epoch: 6| Step: 13
Training loss: 1.7961457967758179
Validation loss: 1.9326990855637418

Epoch: 212| Step: 0
Training loss: 2.478970527648926
Validation loss: 1.9194861163375199

Epoch: 6| Step: 1
Training loss: 2.404480218887329
Validation loss: 1.8967866166945426

Epoch: 6| Step: 2
Training loss: 2.3286309242248535
Validation loss: 1.9334693185744747

Epoch: 6| Step: 3
Training loss: 1.3932304382324219
Validation loss: 1.9226021792299004

Epoch: 6| Step: 4
Training loss: 1.6495540142059326
Validation loss: 1.914161419355741

Epoch: 6| Step: 5
Training loss: 2.063115358352661
Validation loss: 1.926114245127606

Epoch: 6| Step: 6
Training loss: 1.697826862335205
Validation loss: 1.9327039103354178

Epoch: 6| Step: 7
Training loss: 0.7379730939865112
Validation loss: 1.9337288000250374

Epoch: 6| Step: 8
Training loss: 1.6158632040023804
Validation loss: 1.915188035657329

Epoch: 6| Step: 9
Training loss: 1.2473688125610352
Validation loss: 1.8975519916062713

Epoch: 6| Step: 10
Training loss: 2.5105857849121094
Validation loss: 1.9329171988271898

Epoch: 6| Step: 11
Training loss: 1.67686927318573
Validation loss: 1.9188422272282262

Epoch: 6| Step: 12
Training loss: 1.8111326694488525
Validation loss: 1.9258730847348449

Epoch: 6| Step: 13
Training loss: 1.068208932876587
Validation loss: 1.9005887841665616

Epoch: 213| Step: 0
Training loss: 2.06565523147583
Validation loss: 1.9202006068280948

Epoch: 6| Step: 1
Training loss: 1.6263418197631836
Validation loss: 1.9220514553849415

Epoch: 6| Step: 2
Training loss: 1.3848084211349487
Validation loss: 1.918943589733493

Epoch: 6| Step: 3
Training loss: 1.3867318630218506
Validation loss: 1.9329347084927302

Epoch: 6| Step: 4
Training loss: 1.319397211074829
Validation loss: 1.9002080937867523

Epoch: 6| Step: 5
Training loss: 2.372215747833252
Validation loss: 1.921879445352862

Epoch: 6| Step: 6
Training loss: 1.7523373365402222
Validation loss: 1.9226713834270355

Epoch: 6| Step: 7
Training loss: 1.6281448602676392
Validation loss: 1.906930354333693

Epoch: 6| Step: 8
Training loss: 2.6432135105133057
Validation loss: 1.936649973674487

Epoch: 6| Step: 9
Training loss: 1.5359690189361572
Validation loss: 1.933906719248782

Epoch: 6| Step: 10
Training loss: 1.5453494787216187
Validation loss: 1.8790127026137484

Epoch: 6| Step: 11
Training loss: 1.9027960300445557
Validation loss: 1.8916275065432313

Epoch: 6| Step: 12
Training loss: 1.8530381917953491
Validation loss: 1.9240196520282375

Epoch: 6| Step: 13
Training loss: 2.009591817855835
Validation loss: 1.9615009241206671

Epoch: 214| Step: 0
Training loss: 2.174471378326416
Validation loss: 1.915474986517301

Epoch: 6| Step: 1
Training loss: 2.428109884262085
Validation loss: 1.9259063159265826

Epoch: 6| Step: 2
Training loss: 1.292233943939209
Validation loss: 1.9154140872340049

Epoch: 6| Step: 3
Training loss: 2.059159755706787
Validation loss: 1.929662617303992

Epoch: 6| Step: 4
Training loss: 1.4216935634613037
Validation loss: 1.8586981373448526

Epoch: 6| Step: 5
Training loss: 2.5439229011535645
Validation loss: 1.9020302205957391

Epoch: 6| Step: 6
Training loss: 1.9723442792892456
Validation loss: 1.9014739477506248

Epoch: 6| Step: 7
Training loss: 1.2221064567565918
Validation loss: 1.9455074981976581

Epoch: 6| Step: 8
Training loss: 2.1001834869384766
Validation loss: 1.9211107915447605

Epoch: 6| Step: 9
Training loss: 1.9019807577133179
Validation loss: 1.9496984584357149

Epoch: 6| Step: 10
Training loss: 1.5341116189956665
Validation loss: 1.9140949531268048

Epoch: 6| Step: 11
Training loss: 1.2641487121582031
Validation loss: 1.9076664217056767

Epoch: 6| Step: 12
Training loss: 1.194348931312561
Validation loss: 1.9087857110525972

Epoch: 6| Step: 13
Training loss: 1.9371389150619507
Validation loss: 1.9460901444958103

Epoch: 215| Step: 0
Training loss: 1.7132322788238525
Validation loss: 1.92576721150388

Epoch: 6| Step: 1
Training loss: 1.7523976564407349
Validation loss: 1.9302589239612702

Epoch: 6| Step: 2
Training loss: 1.51318359375
Validation loss: 1.9121103722562072

Epoch: 6| Step: 3
Training loss: 1.6634190082550049
Validation loss: 1.9139779767682474

Epoch: 6| Step: 4
Training loss: 1.3140159845352173
Validation loss: 1.9387099512161747

Epoch: 6| Step: 5
Training loss: 1.2719227075576782
Validation loss: 1.9272913522617792

Epoch: 6| Step: 6
Training loss: 1.9340178966522217
Validation loss: 1.9210960198474187

Epoch: 6| Step: 7
Training loss: 2.029940128326416
Validation loss: 1.9307394694256526

Epoch: 6| Step: 8
Training loss: 2.0523173809051514
Validation loss: 1.938551002933133

Epoch: 6| Step: 9
Training loss: 2.1156811714172363
Validation loss: 1.9191253133999404

Epoch: 6| Step: 10
Training loss: 1.8555480241775513
Validation loss: 1.933882664608699

Epoch: 6| Step: 11
Training loss: 1.8739910125732422
Validation loss: 1.9073905765369374

Epoch: 6| Step: 12
Training loss: 1.877667784690857
Validation loss: 1.9695136649634248

Epoch: 6| Step: 13
Training loss: 1.900281310081482
Validation loss: 1.9414460005298737

Epoch: 216| Step: 0
Training loss: 2.1846046447753906
Validation loss: 1.8880356255398

Epoch: 6| Step: 1
Training loss: 2.26163911819458
Validation loss: 1.8795523848584903

Epoch: 6| Step: 2
Training loss: 2.400019645690918
Validation loss: 1.9617854510584185

Epoch: 6| Step: 3
Training loss: 2.1846423149108887
Validation loss: 1.906903564289052

Epoch: 6| Step: 4
Training loss: 1.6544973850250244
Validation loss: 1.9449845231989378

Epoch: 6| Step: 5
Training loss: 1.3103989362716675
Validation loss: 1.8978397897494736

Epoch: 6| Step: 6
Training loss: 1.7121143341064453
Validation loss: 1.8931814380871352

Epoch: 6| Step: 7
Training loss: 1.6985321044921875
Validation loss: 1.8893343402493386

Epoch: 6| Step: 8
Training loss: 2.000194549560547
Validation loss: 1.94939164961538

Epoch: 6| Step: 9
Training loss: 1.6651614904403687
Validation loss: 1.9070061047871907

Epoch: 6| Step: 10
Training loss: 0.695013701915741
Validation loss: 1.91521571400345

Epoch: 6| Step: 11
Training loss: 1.7458170652389526
Validation loss: 1.9091943079425442

Epoch: 6| Step: 12
Training loss: 1.860074520111084
Validation loss: 1.8924591643835909

Epoch: 6| Step: 13
Training loss: 1.1438508033752441
Validation loss: 1.933897379905947

Epoch: 217| Step: 0
Training loss: 2.034527063369751
Validation loss: 1.9266255542796145

Epoch: 6| Step: 1
Training loss: 1.6258020401000977
Validation loss: 1.9235967179780364

Epoch: 6| Step: 2
Training loss: 2.4563369750976562
Validation loss: 1.9101238917278986

Epoch: 6| Step: 3
Training loss: 1.4437839984893799
Validation loss: 1.8909977328392766

Epoch: 6| Step: 4
Training loss: 1.8188153505325317
Validation loss: 1.931496371505081

Epoch: 6| Step: 5
Training loss: 1.6557512283325195
Validation loss: 1.9183079517015846

Epoch: 6| Step: 6
Training loss: 1.3661270141601562
Validation loss: 1.9323004714904293

Epoch: 6| Step: 7
Training loss: 1.2826627492904663
Validation loss: 1.9142113795844458

Epoch: 6| Step: 8
Training loss: 2.160632610321045
Validation loss: 1.9469909321877263

Epoch: 6| Step: 9
Training loss: 1.9682778120040894
Validation loss: 1.9197496265493414

Epoch: 6| Step: 10
Training loss: 1.8045865297317505
Validation loss: 1.8960299491882324

Epoch: 6| Step: 11
Training loss: 1.4893499612808228
Validation loss: 1.9140329309689101

Epoch: 6| Step: 12
Training loss: 1.773691177368164
Validation loss: 1.9471300994196246

Epoch: 6| Step: 13
Training loss: 1.9369229078292847
Validation loss: 1.9318297550242434

Epoch: 218| Step: 0
Training loss: 1.7759475708007812
Validation loss: 1.9345851034246466

Epoch: 6| Step: 1
Training loss: 1.6309934854507446
Validation loss: 1.9216350816911267

Epoch: 6| Step: 2
Training loss: 1.413562297821045
Validation loss: 1.90607068615575

Epoch: 6| Step: 3
Training loss: 1.6406233310699463
Validation loss: 1.9034319859679028

Epoch: 6| Step: 4
Training loss: 2.0978715419769287
Validation loss: 1.9477588745855516

Epoch: 6| Step: 5
Training loss: 1.7183080911636353
Validation loss: 1.900848595044946

Epoch: 6| Step: 6
Training loss: 0.6859504580497742
Validation loss: 1.9307365417480469

Epoch: 6| Step: 7
Training loss: 2.190918207168579
Validation loss: 1.909261744509461

Epoch: 6| Step: 8
Training loss: 1.1241767406463623
Validation loss: 1.9195657930066508

Epoch: 6| Step: 9
Training loss: 1.50323486328125
Validation loss: 1.9190115851740683

Epoch: 6| Step: 10
Training loss: 2.5603904724121094
Validation loss: 1.9236992059215423

Epoch: 6| Step: 11
Training loss: 2.6760873794555664
Validation loss: 1.9189330672705045

Epoch: 6| Step: 12
Training loss: 2.0025970935821533
Validation loss: 1.9384797029597785

Epoch: 6| Step: 13
Training loss: 1.1762157678604126
Validation loss: 1.9299195966412943

Epoch: 219| Step: 0
Training loss: 1.7330057621002197
Validation loss: 1.9675331807905627

Epoch: 6| Step: 1
Training loss: 1.3463704586029053
Validation loss: 1.8999460717683196

Epoch: 6| Step: 2
Training loss: 1.613476276397705
Validation loss: 1.937366799641681

Epoch: 6| Step: 3
Training loss: 1.476651906967163
Validation loss: 1.9468219613516202

Epoch: 6| Step: 4
Training loss: 1.735005497932434
Validation loss: 1.9319158138767365

Epoch: 6| Step: 5
Training loss: 2.2958171367645264
Validation loss: 1.9089001583796676

Epoch: 6| Step: 6
Training loss: 1.606924295425415
Validation loss: 1.9351889189853464

Epoch: 6| Step: 7
Training loss: 1.2862608432769775
Validation loss: 1.9055037037018807

Epoch: 6| Step: 8
Training loss: 2.129850149154663
Validation loss: 1.9433884031029158

Epoch: 6| Step: 9
Training loss: 1.7715749740600586
Validation loss: 1.9497474944719704

Epoch: 6| Step: 10
Training loss: 1.8076027631759644
Validation loss: 1.9474846547649753

Epoch: 6| Step: 11
Training loss: 1.5002868175506592
Validation loss: 1.9281178392389768

Epoch: 6| Step: 12
Training loss: 2.3058462142944336
Validation loss: 1.9418302659065492

Epoch: 6| Step: 13
Training loss: 1.9251158237457275
Validation loss: 1.9691825605207873

Epoch: 220| Step: 0
Training loss: 1.184104084968567
Validation loss: 1.9145554304122925

Epoch: 6| Step: 1
Training loss: 0.9885389804840088
Validation loss: 1.9361637612824798

Epoch: 6| Step: 2
Training loss: 1.7918347120285034
Validation loss: 1.917786039331908

Epoch: 6| Step: 3
Training loss: 2.124781847000122
Validation loss: 1.9179005930500646

Epoch: 6| Step: 4
Training loss: 2.214618682861328
Validation loss: 1.8869066879313479

Epoch: 6| Step: 5
Training loss: 1.5828473567962646
Validation loss: 1.9001374962509319

Epoch: 6| Step: 6
Training loss: 1.3723620176315308
Validation loss: 1.9234444069606003

Epoch: 6| Step: 7
Training loss: 1.884448528289795
Validation loss: 1.895701095622073

Epoch: 6| Step: 8
Training loss: 2.1876730918884277
Validation loss: 1.90574546142291

Epoch: 6| Step: 9
Training loss: 2.1663002967834473
Validation loss: 1.8917742044694963

Epoch: 6| Step: 10
Training loss: 1.9110803604125977
Validation loss: 1.9045009664309922

Epoch: 6| Step: 11
Training loss: 2.1099839210510254
Validation loss: 1.9189134208104943

Epoch: 6| Step: 12
Training loss: 1.4392422437667847
Validation loss: 1.933489905890598

Epoch: 6| Step: 13
Training loss: 1.5304248332977295
Validation loss: 1.9031221943516885

Epoch: 221| Step: 0
Training loss: 1.7159591913223267
Validation loss: 1.931393370833448

Epoch: 6| Step: 1
Training loss: 1.3189263343811035
Validation loss: 1.908667831010716

Epoch: 6| Step: 2
Training loss: 1.29804265499115
Validation loss: 1.9355343951973865

Epoch: 6| Step: 3
Training loss: 1.6800001859664917
Validation loss: 1.954609497900932

Epoch: 6| Step: 4
Training loss: 1.2911980152130127
Validation loss: 1.9132136811492264

Epoch: 6| Step: 5
Training loss: 2.1418895721435547
Validation loss: 1.9228843078818372

Epoch: 6| Step: 6
Training loss: 2.2190210819244385
Validation loss: 1.9454127870580202

Epoch: 6| Step: 7
Training loss: 1.85776948928833
Validation loss: 1.90729461690431

Epoch: 6| Step: 8
Training loss: 1.821406602859497
Validation loss: 1.9565466616743354

Epoch: 6| Step: 9
Training loss: 2.0621495246887207
Validation loss: 1.9173039838831911

Epoch: 6| Step: 10
Training loss: 2.3926777839660645
Validation loss: 1.9243000207408782

Epoch: 6| Step: 11
Training loss: 1.5230731964111328
Validation loss: 1.9578886685832855

Epoch: 6| Step: 12
Training loss: 1.6911356449127197
Validation loss: 1.924348885013211

Epoch: 6| Step: 13
Training loss: 1.814389705657959
Validation loss: 1.9255821192136375

Epoch: 222| Step: 0
Training loss: 1.7608225345611572
Validation loss: 1.9098815174512966

Epoch: 6| Step: 1
Training loss: 1.3484328985214233
Validation loss: 1.9424432657098258

Epoch: 6| Step: 2
Training loss: 1.3730099201202393
Validation loss: 1.9218927237295336

Epoch: 6| Step: 3
Training loss: 1.5750823020935059
Validation loss: 1.939529311272406

Epoch: 6| Step: 4
Training loss: 1.2528269290924072
Validation loss: 1.904068123909735

Epoch: 6| Step: 5
Training loss: 1.2620782852172852
Validation loss: 1.9113045892407816

Epoch: 6| Step: 6
Training loss: 1.8449336290359497
Validation loss: 1.8786702232976114

Epoch: 6| Step: 7
Training loss: 2.2044272422790527
Validation loss: 1.9399328718903244

Epoch: 6| Step: 8
Training loss: 1.8311554193496704
Validation loss: 1.888661205127675

Epoch: 6| Step: 9
Training loss: 1.8095483779907227
Validation loss: 1.9022370141039613

Epoch: 6| Step: 10
Training loss: 3.013861656188965
Validation loss: 1.9411069744376725

Epoch: 6| Step: 11
Training loss: 1.535405158996582
Validation loss: 1.9326142739224177

Epoch: 6| Step: 12
Training loss: 1.8715827465057373
Validation loss: 1.8853410649043258

Epoch: 6| Step: 13
Training loss: 1.8729557991027832
Validation loss: 1.8789137781307261

Epoch: 223| Step: 0
Training loss: 1.7523598670959473
Validation loss: 1.8741006620468632

Epoch: 6| Step: 1
Training loss: 2.3104090690612793
Validation loss: 1.9133525817624983

Epoch: 6| Step: 2
Training loss: 1.392816185951233
Validation loss: 1.9225137413188975

Epoch: 6| Step: 3
Training loss: 1.4409968852996826
Validation loss: 1.9299585870517197

Epoch: 6| Step: 4
Training loss: 2.1532037258148193
Validation loss: 1.8723375463998446

Epoch: 6| Step: 5
Training loss: 2.255736827850342
Validation loss: 1.866589798722216

Epoch: 6| Step: 6
Training loss: 1.500748872756958
Validation loss: 1.9281117800743348

Epoch: 6| Step: 7
Training loss: 1.2594804763793945
Validation loss: 1.936017681193608

Epoch: 6| Step: 8
Training loss: 1.584917426109314
Validation loss: 1.9161133612355878

Epoch: 6| Step: 9
Training loss: 1.3007044792175293
Validation loss: 1.91269943534687

Epoch: 6| Step: 10
Training loss: 1.8511569499969482
Validation loss: 1.9096624876863213

Epoch: 6| Step: 11
Training loss: 2.3764164447784424
Validation loss: 1.937322191012803

Epoch: 6| Step: 12
Training loss: 1.4850102663040161
Validation loss: 1.8795275072897635

Epoch: 6| Step: 13
Training loss: 1.7780603170394897
Validation loss: 1.9711113527256956

Epoch: 224| Step: 0
Training loss: 2.2756834030151367
Validation loss: 1.9403060072211809

Epoch: 6| Step: 1
Training loss: 1.6328738927841187
Validation loss: 1.9392549530152352

Epoch: 6| Step: 2
Training loss: 2.3386518955230713
Validation loss: 1.954831571989162

Epoch: 6| Step: 3
Training loss: 1.0851666927337646
Validation loss: 1.994107407908286

Epoch: 6| Step: 4
Training loss: 2.1472530364990234
Validation loss: 1.9581439059267762

Epoch: 6| Step: 5
Training loss: 1.8382560014724731
Validation loss: 2.0017197080837783

Epoch: 6| Step: 6
Training loss: 1.7179944515228271
Validation loss: 2.0158884986754386

Epoch: 6| Step: 7
Training loss: 1.645369291305542
Validation loss: 1.9653877878701815

Epoch: 6| Step: 8
Training loss: 1.3165478706359863
Validation loss: 1.9807762792033534

Epoch: 6| Step: 9
Training loss: 1.652874231338501
Validation loss: 2.002429126411356

Epoch: 6| Step: 10
Training loss: 1.4480206966400146
Validation loss: 1.9090844969595633

Epoch: 6| Step: 11
Training loss: 2.5436718463897705
Validation loss: 1.9456129727825042

Epoch: 6| Step: 12
Training loss: 1.734933853149414
Validation loss: 1.9370060979679067

Epoch: 6| Step: 13
Training loss: 1.5490773916244507
Validation loss: 1.902452140726069

Epoch: 225| Step: 0
Training loss: 1.5258207321166992
Validation loss: 1.9087148174162833

Epoch: 6| Step: 1
Training loss: 1.621114730834961
Validation loss: 1.9348934568384641

Epoch: 6| Step: 2
Training loss: 1.905766248703003
Validation loss: 1.8896508550131192

Epoch: 6| Step: 3
Training loss: 1.5968823432922363
Validation loss: 1.911023239935598

Epoch: 6| Step: 4
Training loss: 2.507255792617798
Validation loss: 1.859729161826513

Epoch: 6| Step: 5
Training loss: 0.7530206441879272
Validation loss: 1.891659217496072

Epoch: 6| Step: 6
Training loss: 1.692152976989746
Validation loss: 1.9046703410404984

Epoch: 6| Step: 7
Training loss: 2.2528538703918457
Validation loss: 1.9051038001173286

Epoch: 6| Step: 8
Training loss: 2.040879487991333
Validation loss: 1.9035413931774836

Epoch: 6| Step: 9
Training loss: 1.5233827829360962
Validation loss: 1.9331614971160889

Epoch: 6| Step: 10
Training loss: 1.6355829238891602
Validation loss: 1.9263985054467314

Epoch: 6| Step: 11
Training loss: 2.416083574295044
Validation loss: 1.8742802066187705

Epoch: 6| Step: 12
Training loss: 1.4872747659683228
Validation loss: 1.8871307424319688

Epoch: 6| Step: 13
Training loss: 2.0243754386901855
Validation loss: 1.9358915449470602

Epoch: 226| Step: 0
Training loss: 2.0405659675598145
Validation loss: 1.8753628000136344

Epoch: 6| Step: 1
Training loss: 1.3246341943740845
Validation loss: 1.9329511721928914

Epoch: 6| Step: 2
Training loss: 1.9089268445968628
Validation loss: 1.9159048949518511

Epoch: 6| Step: 3
Training loss: 1.470701813697815
Validation loss: 1.963803627157724

Epoch: 6| Step: 4
Training loss: 2.284183979034424
Validation loss: 1.964238048881613

Epoch: 6| Step: 5
Training loss: 1.3521535396575928
Validation loss: 1.9698013400518766

Epoch: 6| Step: 6
Training loss: 1.987939715385437
Validation loss: 2.001715419112995

Epoch: 6| Step: 7
Training loss: 2.1301109790802
Validation loss: 1.978388665824808

Epoch: 6| Step: 8
Training loss: 1.3297324180603027
Validation loss: 1.9760741431226012

Epoch: 6| Step: 9
Training loss: 1.2865605354309082
Validation loss: 1.9566997251202982

Epoch: 6| Step: 10
Training loss: 2.2362966537475586
Validation loss: 1.948725337623268

Epoch: 6| Step: 11
Training loss: 1.6652017831802368
Validation loss: 1.9630336505110546

Epoch: 6| Step: 12
Training loss: 1.2226183414459229
Validation loss: 1.967061149176731

Epoch: 6| Step: 13
Training loss: 2.5207653045654297
Validation loss: 1.9434100248480355

Epoch: 227| Step: 0
Training loss: 1.8117722272872925
Validation loss: 1.9568123202170096

Epoch: 6| Step: 1
Training loss: 1.549816370010376
Validation loss: 1.9564872762208343

Epoch: 6| Step: 2
Training loss: 1.9158616065979004
Validation loss: 1.9436660146200528

Epoch: 6| Step: 3
Training loss: 1.7255101203918457
Validation loss: 1.9387669755566506

Epoch: 6| Step: 4
Training loss: 1.8427996635437012
Validation loss: 1.9224718514309134

Epoch: 6| Step: 5
Training loss: 1.4683449268341064
Validation loss: 1.9348003761742705

Epoch: 6| Step: 6
Training loss: 1.8133213520050049
Validation loss: 1.9238010375730452

Epoch: 6| Step: 7
Training loss: 1.7539916038513184
Validation loss: 1.8770584611482517

Epoch: 6| Step: 8
Training loss: 1.3395131826400757
Validation loss: 1.9501611250703053

Epoch: 6| Step: 9
Training loss: 1.9803497791290283
Validation loss: 1.8973111426958473

Epoch: 6| Step: 10
Training loss: 1.8949511051177979
Validation loss: 1.9198909677484983

Epoch: 6| Step: 11
Training loss: 1.8680424690246582
Validation loss: 1.8953860677698606

Epoch: 6| Step: 12
Training loss: 1.5481438636779785
Validation loss: 1.8776521426375195

Epoch: 6| Step: 13
Training loss: 1.6190286874771118
Validation loss: 1.9077014282185545

Epoch: 228| Step: 0
Training loss: 1.3500187397003174
Validation loss: 1.9370426747106737

Epoch: 6| Step: 1
Training loss: 1.0579159259796143
Validation loss: 1.9028748966032458

Epoch: 6| Step: 2
Training loss: 1.7305881977081299
Validation loss: 1.9215032849260556

Epoch: 6| Step: 3
Training loss: 1.6605896949768066
Validation loss: 1.8819101651509602

Epoch: 6| Step: 4
Training loss: 2.215521812438965
Validation loss: 1.8891263290118145

Epoch: 6| Step: 5
Training loss: 0.8023492097854614
Validation loss: 1.9107593861959313

Epoch: 6| Step: 6
Training loss: 1.4608447551727295
Validation loss: 1.8859817930447158

Epoch: 6| Step: 7
Training loss: 2.163484573364258
Validation loss: 1.88483965012335

Epoch: 6| Step: 8
Training loss: 2.1873087882995605
Validation loss: 1.9548546216821159

Epoch: 6| Step: 9
Training loss: 1.8852753639221191
Validation loss: 1.9341862688782394

Epoch: 6| Step: 10
Training loss: 2.1482362747192383
Validation loss: 1.8911158782179638

Epoch: 6| Step: 11
Training loss: 0.9754657745361328
Validation loss: 1.9191403722250333

Epoch: 6| Step: 12
Training loss: 2.8317203521728516
Validation loss: 1.9214092326420609

Epoch: 6| Step: 13
Training loss: 2.27875018119812
Validation loss: 1.918705645427909

Epoch: 229| Step: 0
Training loss: 2.6427745819091797
Validation loss: 1.904470069434053

Epoch: 6| Step: 1
Training loss: 2.085022211074829
Validation loss: 1.932296299165295

Epoch: 6| Step: 2
Training loss: 2.3239808082580566
Validation loss: 1.9101206705134401

Epoch: 6| Step: 3
Training loss: 1.6167656183242798
Validation loss: 1.956103104417042

Epoch: 6| Step: 4
Training loss: 1.4328758716583252
Validation loss: 1.9295756457954325

Epoch: 6| Step: 5
Training loss: 0.8946424722671509
Validation loss: 1.8945860375640213

Epoch: 6| Step: 6
Training loss: 1.6565356254577637
Validation loss: 1.909220649350074

Epoch: 6| Step: 7
Training loss: 1.4573957920074463
Validation loss: 1.9222412981012815

Epoch: 6| Step: 8
Training loss: 1.4608681201934814
Validation loss: 1.9250076176017843

Epoch: 6| Step: 9
Training loss: 1.112593173980713
Validation loss: 1.9449336349323232

Epoch: 6| Step: 10
Training loss: 2.0361592769622803
Validation loss: 1.8898775398090322

Epoch: 6| Step: 11
Training loss: 1.9243569374084473
Validation loss: 1.9122421536394345

Epoch: 6| Step: 12
Training loss: 1.9362531900405884
Validation loss: 1.9186059082708051

Epoch: 6| Step: 13
Training loss: 1.831014633178711
Validation loss: 1.9047098800700197

Epoch: 230| Step: 0
Training loss: 2.161731719970703
Validation loss: 1.9011350293313303

Epoch: 6| Step: 1
Training loss: 2.0428264141082764
Validation loss: 1.9219037781479538

Epoch: 6| Step: 2
Training loss: 1.1030614376068115
Validation loss: 1.8946609061251405

Epoch: 6| Step: 3
Training loss: 1.8229575157165527
Validation loss: 1.8935447380106936

Epoch: 6| Step: 4
Training loss: 1.3569872379302979
Validation loss: 1.9264383610858713

Epoch: 6| Step: 5
Training loss: 2.3889379501342773
Validation loss: 1.899974056469497

Epoch: 6| Step: 6
Training loss: 1.119825839996338
Validation loss: 1.907126211350964

Epoch: 6| Step: 7
Training loss: 1.23543119430542
Validation loss: 1.876335669589299

Epoch: 6| Step: 8
Training loss: 1.7265313863754272
Validation loss: 1.878368777613486

Epoch: 6| Step: 9
Training loss: 1.7334178686141968
Validation loss: 1.8982852799918062

Epoch: 6| Step: 10
Training loss: 2.313516855239868
Validation loss: 1.903637856565496

Epoch: 6| Step: 11
Training loss: 1.6764767169952393
Validation loss: 1.9202730360851492

Epoch: 6| Step: 12
Training loss: 2.001704692840576
Validation loss: 1.9000268725938694

Epoch: 6| Step: 13
Training loss: 1.5714632272720337
Validation loss: 1.9269550218377063

Epoch: 231| Step: 0
Training loss: 1.7997238636016846
Validation loss: 1.9273864979385047

Epoch: 6| Step: 1
Training loss: 1.4005261659622192
Validation loss: 1.9099375342810025

Epoch: 6| Step: 2
Training loss: 0.7371165752410889
Validation loss: 1.9063239712868967

Epoch: 6| Step: 3
Training loss: 2.1407902240753174
Validation loss: 1.9156639088866532

Epoch: 6| Step: 4
Training loss: 1.8274383544921875
Validation loss: 1.9304952762460197

Epoch: 6| Step: 5
Training loss: 1.670167326927185
Validation loss: 1.880946022208019

Epoch: 6| Step: 6
Training loss: 1.45054030418396
Validation loss: 1.9135058964452436

Epoch: 6| Step: 7
Training loss: 1.471631646156311
Validation loss: 1.9239709633652882

Epoch: 6| Step: 8
Training loss: 1.5903651714324951
Validation loss: 1.929941705478135

Epoch: 6| Step: 9
Training loss: 3.3315134048461914
Validation loss: 1.9256253037401425

Epoch: 6| Step: 10
Training loss: 1.3913029432296753
Validation loss: 1.9312239308511057

Epoch: 6| Step: 11
Training loss: 1.908538579940796
Validation loss: 1.9131213900863484

Epoch: 6| Step: 12
Training loss: 1.3351757526397705
Validation loss: 1.91729102980706

Epoch: 6| Step: 13
Training loss: 1.6260148286819458
Validation loss: 1.932882934488276

Epoch: 232| Step: 0
Training loss: 1.3072612285614014
Validation loss: 1.883727458215529

Epoch: 6| Step: 1
Training loss: 2.156245470046997
Validation loss: 1.8989272553433654

Epoch: 6| Step: 2
Training loss: 1.7236676216125488
Validation loss: 1.8445455861347977

Epoch: 6| Step: 3
Training loss: 1.3204572200775146
Validation loss: 1.891111437992383

Epoch: 6| Step: 4
Training loss: 1.9178342819213867
Validation loss: 1.8782059261875768

Epoch: 6| Step: 5
Training loss: 1.7141605615615845
Validation loss: 1.8986179828643799

Epoch: 6| Step: 6
Training loss: 1.446327805519104
Validation loss: 1.9229656201536938

Epoch: 6| Step: 7
Training loss: 1.2960759401321411
Validation loss: 1.8903422919652795

Epoch: 6| Step: 8
Training loss: 1.0611375570297241
Validation loss: 1.9050585864692606

Epoch: 6| Step: 9
Training loss: 1.9003844261169434
Validation loss: 1.895113319479009

Epoch: 6| Step: 10
Training loss: 1.8204150199890137
Validation loss: 1.9160156391000236

Epoch: 6| Step: 11
Training loss: 1.6980509757995605
Validation loss: 1.905377294427605

Epoch: 6| Step: 12
Training loss: 2.5633678436279297
Validation loss: 1.8793090363984466

Epoch: 6| Step: 13
Training loss: 2.8396453857421875
Validation loss: 1.8484000544394217

Epoch: 233| Step: 0
Training loss: 1.6691014766693115
Validation loss: 1.9045996524954354

Epoch: 6| Step: 1
Training loss: 1.8140487670898438
Validation loss: 1.882601890512692

Epoch: 6| Step: 2
Training loss: 1.6581149101257324
Validation loss: 1.9042442690941594

Epoch: 6| Step: 3
Training loss: 1.6054444313049316
Validation loss: 1.9636308787971415

Epoch: 6| Step: 4
Training loss: 2.1042563915252686
Validation loss: 1.9457859672525877

Epoch: 6| Step: 5
Training loss: 1.656954288482666
Validation loss: 1.9296452153113581

Epoch: 6| Step: 6
Training loss: 1.4141439199447632
Validation loss: 1.9463065696018997

Epoch: 6| Step: 7
Training loss: 1.9018144607543945
Validation loss: 1.9295730244728826

Epoch: 6| Step: 8
Training loss: 1.3870301246643066
Validation loss: 1.918472332339133

Epoch: 6| Step: 9
Training loss: 1.9213207960128784
Validation loss: 1.9352598344126055

Epoch: 6| Step: 10
Training loss: 1.4421615600585938
Validation loss: 1.903139204107305

Epoch: 6| Step: 11
Training loss: 1.587394118309021
Validation loss: 1.9348932312380882

Epoch: 6| Step: 12
Training loss: 2.4952237606048584
Validation loss: 1.8996429251086326

Epoch: 6| Step: 13
Training loss: 1.2206573486328125
Validation loss: 1.920902862343737

Epoch: 234| Step: 0
Training loss: 1.7556657791137695
Validation loss: 1.8611777251766575

Epoch: 6| Step: 1
Training loss: 2.1955127716064453
Validation loss: 1.8817913891166769

Epoch: 6| Step: 2
Training loss: 2.044759750366211
Validation loss: 1.9383253487207557

Epoch: 6| Step: 3
Training loss: 1.754467487335205
Validation loss: 1.903611716403756

Epoch: 6| Step: 4
Training loss: 2.1960082054138184
Validation loss: 1.884156979540343

Epoch: 6| Step: 5
Training loss: 2.2179160118103027
Validation loss: 1.8904653736340102

Epoch: 6| Step: 6
Training loss: 1.174133539199829
Validation loss: 1.8847575315865137

Epoch: 6| Step: 7
Training loss: 1.8703138828277588
Validation loss: 1.8715625732175765

Epoch: 6| Step: 8
Training loss: 1.5182809829711914
Validation loss: 1.9348222401834303

Epoch: 6| Step: 9
Training loss: 1.5011603832244873
Validation loss: 1.9027753632555726

Epoch: 6| Step: 10
Training loss: 0.904663622379303
Validation loss: 1.896006032984744

Epoch: 6| Step: 11
Training loss: 1.893865942955017
Validation loss: 1.861369300914067

Epoch: 6| Step: 12
Training loss: 1.1433982849121094
Validation loss: 1.8899777473941926

Epoch: 6| Step: 13
Training loss: 2.2442610263824463
Validation loss: 1.8966574284338182

Epoch: 235| Step: 0
Training loss: 1.5778908729553223
Validation loss: 1.9064108376861901

Epoch: 6| Step: 1
Training loss: 1.9121465682983398
Validation loss: 1.882297428705359

Epoch: 6| Step: 2
Training loss: 1.9880651235580444
Validation loss: 1.9286114759342645

Epoch: 6| Step: 3
Training loss: 1.1669409275054932
Validation loss: 1.9075472829162434

Epoch: 6| Step: 4
Training loss: 1.7179784774780273
Validation loss: 1.9354795691787556

Epoch: 6| Step: 5
Training loss: 1.1026721000671387
Validation loss: 1.9518580205978886

Epoch: 6| Step: 6
Training loss: 2.3483870029449463
Validation loss: 1.9419060778874222

Epoch: 6| Step: 7
Training loss: 2.2348594665527344
Validation loss: 1.9320404785935597

Epoch: 6| Step: 8
Training loss: 1.0727962255477905
Validation loss: 1.9494870965198805

Epoch: 6| Step: 9
Training loss: 1.675696849822998
Validation loss: 1.9211880673644364

Epoch: 6| Step: 10
Training loss: 1.969772219657898
Validation loss: 1.9131664640160018

Epoch: 6| Step: 11
Training loss: 1.633631706237793
Validation loss: 1.9565050550686416

Epoch: 6| Step: 12
Training loss: 1.6382408142089844
Validation loss: 1.9191100699927217

Epoch: 6| Step: 13
Training loss: 1.72842538356781
Validation loss: 1.8667774764440392

Epoch: 236| Step: 0
Training loss: 1.068870186805725
Validation loss: 1.9233373480458413

Epoch: 6| Step: 1
Training loss: 1.4784057140350342
Validation loss: 1.9074540497154318

Epoch: 6| Step: 2
Training loss: 1.6462547779083252
Validation loss: 1.952947619140789

Epoch: 6| Step: 3
Training loss: 1.0978257656097412
Validation loss: 1.9415814543283114

Epoch: 6| Step: 4
Training loss: 1.4277868270874023
Validation loss: 1.9114017563481485

Epoch: 6| Step: 5
Training loss: 1.389633297920227
Validation loss: 1.9053371747334797

Epoch: 6| Step: 6
Training loss: 2.3014163970947266
Validation loss: 1.8810117424175303

Epoch: 6| Step: 7
Training loss: 1.8826079368591309
Validation loss: 1.857302365764495

Epoch: 6| Step: 8
Training loss: 1.7459570169448853
Validation loss: 1.9090341778211697

Epoch: 6| Step: 9
Training loss: 2.342719554901123
Validation loss: 1.8638520984239475

Epoch: 6| Step: 10
Training loss: 2.073835849761963
Validation loss: 1.8998926249883508

Epoch: 6| Step: 11
Training loss: 1.3270937204360962
Validation loss: 1.9587415392680834

Epoch: 6| Step: 12
Training loss: 1.9543089866638184
Validation loss: 1.8794356289730276

Epoch: 6| Step: 13
Training loss: 2.4253063201904297
Validation loss: 1.889791811666181

Epoch: 237| Step: 0
Training loss: 1.9078341722488403
Validation loss: 1.8940636175934986

Epoch: 6| Step: 1
Training loss: 1.5910899639129639
Validation loss: 1.9063251172342608

Epoch: 6| Step: 2
Training loss: 2.382082939147949
Validation loss: 1.9234556869793964

Epoch: 6| Step: 3
Training loss: 1.352418303489685
Validation loss: 1.903125081011044

Epoch: 6| Step: 4
Training loss: 2.018643856048584
Validation loss: 1.9303588687732656

Epoch: 6| Step: 5
Training loss: 2.1803393363952637
Validation loss: 1.960653628072431

Epoch: 6| Step: 6
Training loss: 1.8437981605529785
Validation loss: 1.930891832997722

Epoch: 6| Step: 7
Training loss: 1.756960153579712
Validation loss: 1.9074265918424052

Epoch: 6| Step: 8
Training loss: 1.375962734222412
Validation loss: 1.9392330467060048

Epoch: 6| Step: 9
Training loss: 1.6400588750839233
Validation loss: 1.9094996042149042

Epoch: 6| Step: 10
Training loss: 1.322884202003479
Validation loss: 1.9049175144523702

Epoch: 6| Step: 11
Training loss: 1.1947224140167236
Validation loss: 1.9608099575965636

Epoch: 6| Step: 12
Training loss: 2.032036542892456
Validation loss: 1.952009923996464

Epoch: 6| Step: 13
Training loss: 1.2885231971740723
Validation loss: 1.9453105170239684

Epoch: 238| Step: 0
Training loss: 1.0925828218460083
Validation loss: 1.915624277566069

Epoch: 6| Step: 1
Training loss: 1.67743718624115
Validation loss: 1.8919953774380427

Epoch: 6| Step: 2
Training loss: 1.8899821043014526
Validation loss: 1.8994821194679505

Epoch: 6| Step: 3
Training loss: 2.0294671058654785
Validation loss: 1.9301012792894918

Epoch: 6| Step: 4
Training loss: 2.115813970565796
Validation loss: 1.8981533242810158

Epoch: 6| Step: 5
Training loss: 1.7952522039413452
Validation loss: 1.8912754494656798

Epoch: 6| Step: 6
Training loss: 1.6782602071762085
Validation loss: 1.8856093960423623

Epoch: 6| Step: 7
Training loss: 1.382243037223816
Validation loss: 1.8842746352636686

Epoch: 6| Step: 8
Training loss: 1.4642598628997803
Validation loss: 1.8763087129080167

Epoch: 6| Step: 9
Training loss: 2.004478931427002
Validation loss: 1.8348522596461798

Epoch: 6| Step: 10
Training loss: 2.1984570026397705
Validation loss: 1.8900243518173054

Epoch: 6| Step: 11
Training loss: 1.0815041065216064
Validation loss: 1.8807281845359392

Epoch: 6| Step: 12
Training loss: 1.4493908882141113
Validation loss: 1.8859350412122664

Epoch: 6| Step: 13
Training loss: 2.0736289024353027
Validation loss: 1.9312358825437483

Epoch: 239| Step: 0
Training loss: 2.2582664489746094
Validation loss: 1.9385226298403997

Epoch: 6| Step: 1
Training loss: 1.4011046886444092
Validation loss: 1.9201802361396052

Epoch: 6| Step: 2
Training loss: 1.2200288772583008
Validation loss: 1.9636529799430602

Epoch: 6| Step: 3
Training loss: 2.182535171508789
Validation loss: 1.9347869632064656

Epoch: 6| Step: 4
Training loss: 1.337458610534668
Validation loss: 1.9152646962032522

Epoch: 6| Step: 5
Training loss: 0.9670290350914001
Validation loss: 1.9496315448514876

Epoch: 6| Step: 6
Training loss: 2.3118996620178223
Validation loss: 1.9082048669938119

Epoch: 6| Step: 7
Training loss: 1.925148606300354
Validation loss: 1.909739581487512

Epoch: 6| Step: 8
Training loss: 1.9134931564331055
Validation loss: 1.955645025417369

Epoch: 6| Step: 9
Training loss: 1.4390075206756592
Validation loss: 1.9581318952703988

Epoch: 6| Step: 10
Training loss: 1.5805069208145142
Validation loss: 1.9377955326469996

Epoch: 6| Step: 11
Training loss: 1.7828822135925293
Validation loss: 1.9567220941666634

Epoch: 6| Step: 12
Training loss: 2.0064632892608643
Validation loss: 1.9327974678367696

Epoch: 6| Step: 13
Training loss: 1.3028368949890137
Validation loss: 1.8950891417841758

Epoch: 240| Step: 0
Training loss: 1.458055019378662
Validation loss: 1.9187931424827986

Epoch: 6| Step: 1
Training loss: 2.01235294342041
Validation loss: 1.89499072874746

Epoch: 6| Step: 2
Training loss: 1.3838446140289307
Validation loss: 1.8725052008064844

Epoch: 6| Step: 3
Training loss: 1.8057395219802856
Validation loss: 1.8522909738684212

Epoch: 6| Step: 4
Training loss: 1.7578917741775513
Validation loss: 1.860277150266914

Epoch: 6| Step: 5
Training loss: 2.3933234214782715
Validation loss: 1.9024499872679352

Epoch: 6| Step: 6
Training loss: 1.7445576190948486
Validation loss: 1.9211800111237394

Epoch: 6| Step: 7
Training loss: 1.340173602104187
Validation loss: 1.941719611485799

Epoch: 6| Step: 8
Training loss: 1.858276128768921
Validation loss: 1.88176179188554

Epoch: 6| Step: 9
Training loss: 1.8009006977081299
Validation loss: 1.866258555842984

Epoch: 6| Step: 10
Training loss: 1.3892664909362793
Validation loss: 1.862492589540379

Epoch: 6| Step: 11
Training loss: 1.4706025123596191
Validation loss: 1.9079925449945594

Epoch: 6| Step: 12
Training loss: 1.4884884357452393
Validation loss: 1.8721152761931061

Epoch: 6| Step: 13
Training loss: 1.6358765363693237
Validation loss: 1.8683395783106487

Epoch: 241| Step: 0
Training loss: 1.8775687217712402
Validation loss: 1.9251762590100687

Epoch: 6| Step: 1
Training loss: 1.3734960556030273
Validation loss: 1.9064121477065548

Epoch: 6| Step: 2
Training loss: 1.4646024703979492
Validation loss: 1.8939733197612147

Epoch: 6| Step: 3
Training loss: 2.0178165435791016
Validation loss: 1.9366749384069954

Epoch: 6| Step: 4
Training loss: 1.1979421377182007
Validation loss: 1.9016587990586475

Epoch: 6| Step: 5
Training loss: 1.813429594039917
Validation loss: 1.9485103596923172

Epoch: 6| Step: 6
Training loss: 1.3133995532989502
Validation loss: 1.9152099701666063

Epoch: 6| Step: 7
Training loss: 2.3266329765319824
Validation loss: 1.9268840718012985

Epoch: 6| Step: 8
Training loss: 2.2269089221954346
Validation loss: 1.9341615605097946

Epoch: 6| Step: 9
Training loss: 1.186837077140808
Validation loss: 1.903961379040954

Epoch: 6| Step: 10
Training loss: 1.7532681226730347
Validation loss: 1.8966459817783807

Epoch: 6| Step: 11
Training loss: 1.6463813781738281
Validation loss: 1.8710180021101428

Epoch: 6| Step: 12
Training loss: 2.03813099861145
Validation loss: 1.9446322994847451

Epoch: 6| Step: 13
Training loss: 0.8821027278900146
Validation loss: 1.9252719545877108

Epoch: 242| Step: 0
Training loss: 1.9429187774658203
Validation loss: 1.9116026304101432

Epoch: 6| Step: 1
Training loss: 1.4046387672424316
Validation loss: 1.8778109794021935

Epoch: 6| Step: 2
Training loss: 1.7158019542694092
Validation loss: 1.9152731510900682

Epoch: 6| Step: 3
Training loss: 1.4132964611053467
Validation loss: 1.8843146498485277

Epoch: 6| Step: 4
Training loss: 2.570173978805542
Validation loss: 1.9111137441409531

Epoch: 6| Step: 5
Training loss: 1.6610398292541504
Validation loss: 1.9003548237585253

Epoch: 6| Step: 6
Training loss: 1.4931387901306152
Validation loss: 1.9054282544761576

Epoch: 6| Step: 7
Training loss: 1.757239580154419
Validation loss: 1.838112877261254

Epoch: 6| Step: 8
Training loss: 1.1158618927001953
Validation loss: 1.8844932586916032

Epoch: 6| Step: 9
Training loss: 1.484937071800232
Validation loss: 1.9113517397193498

Epoch: 6| Step: 10
Training loss: 1.3788808584213257
Validation loss: 1.908418155485584

Epoch: 6| Step: 11
Training loss: 2.3054921627044678
Validation loss: 1.908611346316594

Epoch: 6| Step: 12
Training loss: 1.3954195976257324
Validation loss: 1.926091314643942

Epoch: 6| Step: 13
Training loss: 1.8843023777008057
Validation loss: 1.8819554364809425

Epoch: 243| Step: 0
Training loss: 2.278188943862915
Validation loss: 1.924450300073111

Epoch: 6| Step: 1
Training loss: 1.3698408603668213
Validation loss: 1.8773190872643584

Epoch: 6| Step: 2
Training loss: 1.7530502080917358
Validation loss: 1.8665746129969114

Epoch: 6| Step: 3
Training loss: 1.158068060874939
Validation loss: 1.927278636604227

Epoch: 6| Step: 4
Training loss: 1.312110424041748
Validation loss: 1.9142916035908524

Epoch: 6| Step: 5
Training loss: 1.6562846899032593
Validation loss: 1.8997376426573722

Epoch: 6| Step: 6
Training loss: 1.6081875562667847
Validation loss: 1.9107551228615545

Epoch: 6| Step: 7
Training loss: 2.303029775619507
Validation loss: 1.8891568696627052

Epoch: 6| Step: 8
Training loss: 1.4689257144927979
Validation loss: 1.8877243790575253

Epoch: 6| Step: 9
Training loss: 1.337670087814331
Validation loss: 1.879734605871221

Epoch: 6| Step: 10
Training loss: 1.435189962387085
Validation loss: 1.903408229991954

Epoch: 6| Step: 11
Training loss: 1.816521167755127
Validation loss: 1.8866833384319017

Epoch: 6| Step: 12
Training loss: 1.6317945718765259
Validation loss: 1.884129644722067

Epoch: 6| Step: 13
Training loss: 2.851285457611084
Validation loss: 1.8863624577881188

Epoch: 244| Step: 0
Training loss: 1.7143768072128296
Validation loss: 1.9192704231508317

Epoch: 6| Step: 1
Training loss: 1.3708652257919312
Validation loss: 1.9214144419598322

Epoch: 6| Step: 2
Training loss: 1.307440996170044
Validation loss: 1.9234141765102264

Epoch: 6| Step: 3
Training loss: 1.9638786315917969
Validation loss: 1.9247471222313501

Epoch: 6| Step: 4
Training loss: 1.0343811511993408
Validation loss: 1.9431341450701478

Epoch: 6| Step: 5
Training loss: 1.6833999156951904
Validation loss: 1.88174726886134

Epoch: 6| Step: 6
Training loss: 1.8913828134536743
Validation loss: 1.9173245314628846

Epoch: 6| Step: 7
Training loss: 1.7925244569778442
Validation loss: 1.8767106635596162

Epoch: 6| Step: 8
Training loss: 2.40090274810791
Validation loss: 1.9105878632555726

Epoch: 6| Step: 9
Training loss: 1.8259094953536987
Validation loss: 1.8791574931913806

Epoch: 6| Step: 10
Training loss: 1.5540616512298584
Validation loss: 1.884493479164698

Epoch: 6| Step: 11
Training loss: 1.5261204242706299
Validation loss: 1.896901208867309

Epoch: 6| Step: 12
Training loss: 2.4829602241516113
Validation loss: 1.9092397433455273

Epoch: 6| Step: 13
Training loss: 0.6518307328224182
Validation loss: 1.9069747565894999

Epoch: 245| Step: 0
Training loss: 1.0079916715621948
Validation loss: 1.9119444021614649

Epoch: 6| Step: 1
Training loss: 1.7693294286727905
Validation loss: 1.9266947072039369

Epoch: 6| Step: 2
Training loss: 1.670046329498291
Validation loss: 1.9335382471802414

Epoch: 6| Step: 3
Training loss: 1.6351466178894043
Validation loss: 1.9401289545079714

Epoch: 6| Step: 4
Training loss: 1.6228795051574707
Validation loss: 1.9001552802260204

Epoch: 6| Step: 5
Training loss: 1.0928399562835693
Validation loss: 1.9319201156657229

Epoch: 6| Step: 6
Training loss: 1.8476550579071045
Validation loss: 1.8904988329897645

Epoch: 6| Step: 7
Training loss: 2.302626132965088
Validation loss: 1.8976773779879335

Epoch: 6| Step: 8
Training loss: 1.615539312362671
Validation loss: 1.8840056555245512

Epoch: 6| Step: 9
Training loss: 2.1138739585876465
Validation loss: 1.891273444698703

Epoch: 6| Step: 10
Training loss: 1.4810476303100586
Validation loss: 1.8722558572728147

Epoch: 6| Step: 11
Training loss: 2.51078724861145
Validation loss: 1.8786806239876697

Epoch: 6| Step: 12
Training loss: 1.3512287139892578
Validation loss: 1.866529962067963

Epoch: 6| Step: 13
Training loss: 1.7799879312515259
Validation loss: 1.9242713400112685

Epoch: 246| Step: 0
Training loss: 1.473196268081665
Validation loss: 1.8953785268209313

Epoch: 6| Step: 1
Training loss: 1.3170262575149536
Validation loss: 1.890002283998715

Epoch: 6| Step: 2
Training loss: 2.2815611362457275
Validation loss: 1.9115953970980901

Epoch: 6| Step: 3
Training loss: 2.251570224761963
Validation loss: 1.8521628008093884

Epoch: 6| Step: 4
Training loss: 1.6695334911346436
Validation loss: 1.918230128544633

Epoch: 6| Step: 5
Training loss: 2.2429699897766113
Validation loss: 1.8955696885303785

Epoch: 6| Step: 6
Training loss: 1.4839022159576416
Validation loss: 1.906452460955548

Epoch: 6| Step: 7
Training loss: 1.529228687286377
Validation loss: 1.8983057750168668

Epoch: 6| Step: 8
Training loss: 2.0587961673736572
Validation loss: 1.9467797715176818

Epoch: 6| Step: 9
Training loss: 2.2193593978881836
Validation loss: 1.8950898826763194

Epoch: 6| Step: 10
Training loss: 1.0654023885726929
Validation loss: 1.8913963969035814

Epoch: 6| Step: 11
Training loss: 1.3182008266448975
Validation loss: 1.8910835237913235

Epoch: 6| Step: 12
Training loss: 1.5563092231750488
Validation loss: 1.9368062224439395

Epoch: 6| Step: 13
Training loss: 0.6254164576530457
Validation loss: 1.90611433470121

Epoch: 247| Step: 0
Training loss: 1.8520219326019287
Validation loss: 1.905071279054047

Epoch: 6| Step: 1
Training loss: 1.6130633354187012
Validation loss: 1.9343190244449082

Epoch: 6| Step: 2
Training loss: 2.238750457763672
Validation loss: 1.9205858784337198

Epoch: 6| Step: 3
Training loss: 1.3073408603668213
Validation loss: 1.9502360513133388

Epoch: 6| Step: 4
Training loss: 2.0556113719940186
Validation loss: 1.8977795211217736

Epoch: 6| Step: 5
Training loss: 1.7819125652313232
Validation loss: 1.9212673428238078

Epoch: 6| Step: 6
Training loss: 1.7409721612930298
Validation loss: 1.9348942874580302

Epoch: 6| Step: 7
Training loss: 1.3865852355957031
Validation loss: 1.9026695707792878

Epoch: 6| Step: 8
Training loss: 1.5914154052734375
Validation loss: 1.8827301020263343

Epoch: 6| Step: 9
Training loss: 1.7430217266082764
Validation loss: 1.8969090164348643

Epoch: 6| Step: 10
Training loss: 1.419743537902832
Validation loss: 1.9055710556686565

Epoch: 6| Step: 11
Training loss: 1.9539523124694824
Validation loss: 1.9074629083756478

Epoch: 6| Step: 12
Training loss: 1.483065128326416
Validation loss: 1.868200054732702

Epoch: 6| Step: 13
Training loss: 1.289557695388794
Validation loss: 1.8594317474672872

Epoch: 248| Step: 0
Training loss: 2.038013458251953
Validation loss: 1.8767195311925744

Epoch: 6| Step: 1
Training loss: 1.3824021816253662
Validation loss: 1.867546909598894

Epoch: 6| Step: 2
Training loss: 1.7906025648117065
Validation loss: 1.9467432857841573

Epoch: 6| Step: 3
Training loss: 1.3677369356155396
Validation loss: 1.9261097882383613

Epoch: 6| Step: 4
Training loss: 1.2964026927947998
Validation loss: 1.8833179935332267

Epoch: 6| Step: 5
Training loss: 1.8035528659820557
Validation loss: 1.9094785874889744

Epoch: 6| Step: 6
Training loss: 1.4742156267166138
Validation loss: 1.9079542224125197

Epoch: 6| Step: 7
Training loss: 2.1686959266662598
Validation loss: 1.8613933106904388

Epoch: 6| Step: 8
Training loss: 2.009521484375
Validation loss: 1.8971592546791158

Epoch: 6| Step: 9
Training loss: 1.696285367012024
Validation loss: 1.8803790717996576

Epoch: 6| Step: 10
Training loss: 1.8782597780227661
Validation loss: 1.8983114355353898

Epoch: 6| Step: 11
Training loss: 1.4536330699920654
Validation loss: 1.8642790381626417

Epoch: 6| Step: 12
Training loss: 1.1529524326324463
Validation loss: 1.8701404999661189

Epoch: 6| Step: 13
Training loss: 1.7954095602035522
Validation loss: 1.9090906586698306

Epoch: 249| Step: 0
Training loss: 1.5037815570831299
Validation loss: 1.8857330455574939

Epoch: 6| Step: 1
Training loss: 0.8104773759841919
Validation loss: 1.9139471079713555

Epoch: 6| Step: 2
Training loss: 1.910181999206543
Validation loss: 1.9310141327560588

Epoch: 6| Step: 3
Training loss: 2.217050075531006
Validation loss: 1.9150330456354285

Epoch: 6| Step: 4
Training loss: 1.8815932273864746
Validation loss: 1.9554583129062448

Epoch: 6| Step: 5
Training loss: 1.4546985626220703
Validation loss: 1.8724360953095138

Epoch: 6| Step: 6
Training loss: 1.3226888179779053
Validation loss: 1.953490218808574

Epoch: 6| Step: 7
Training loss: 1.2267024517059326
Validation loss: 1.8712891378710348

Epoch: 6| Step: 8
Training loss: 1.4050213098526
Validation loss: 1.969543171185319

Epoch: 6| Step: 9
Training loss: 1.9348628520965576
Validation loss: 1.9259641952412103

Epoch: 6| Step: 10
Training loss: 1.5590406656265259
Validation loss: 1.939450325504426

Epoch: 6| Step: 11
Training loss: 2.224733829498291
Validation loss: 1.9300643654279812

Epoch: 6| Step: 12
Training loss: 2.122335910797119
Validation loss: 1.9475238707757765

Epoch: 6| Step: 13
Training loss: 1.992351770401001
Validation loss: 1.9229309546050204

Epoch: 250| Step: 0
Training loss: 1.9685249328613281
Validation loss: 1.9021164281393892

Epoch: 6| Step: 1
Training loss: 2.2061424255371094
Validation loss: 1.9432796919217674

Epoch: 6| Step: 2
Training loss: 1.6500883102416992
Validation loss: 1.9466561181570894

Epoch: 6| Step: 3
Training loss: 2.053180456161499
Validation loss: 1.92483611260691

Epoch: 6| Step: 4
Training loss: 1.8759145736694336
Validation loss: 1.9341509521648448

Epoch: 6| Step: 5
Training loss: 1.8293758630752563
Validation loss: 1.8865724122652443

Epoch: 6| Step: 6
Training loss: 1.3656731843948364
Validation loss: 1.9114901865682294

Epoch: 6| Step: 7
Training loss: 1.504530668258667
Validation loss: 1.9009474092914211

Epoch: 6| Step: 8
Training loss: 1.3699455261230469
Validation loss: 1.894726186670283

Epoch: 6| Step: 9
Training loss: 1.4478075504302979
Validation loss: 1.909102528325973

Epoch: 6| Step: 10
Training loss: 1.7882335186004639
Validation loss: 1.87068336625253

Epoch: 6| Step: 11
Training loss: 1.6254448890686035
Validation loss: 1.8583567488578059

Epoch: 6| Step: 12
Training loss: 0.9449610114097595
Validation loss: 1.8921872159486175

Epoch: 6| Step: 13
Training loss: 2.04237699508667
Validation loss: 1.9076501784786102

Testing loss: 2.1942307710647584
