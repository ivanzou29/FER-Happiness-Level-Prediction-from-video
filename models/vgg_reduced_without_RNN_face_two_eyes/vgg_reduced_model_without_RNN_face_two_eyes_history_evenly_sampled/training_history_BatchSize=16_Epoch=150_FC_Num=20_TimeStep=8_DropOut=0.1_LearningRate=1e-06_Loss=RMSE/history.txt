Epoch: 1| Step: 0
Training loss: 5.906747948379344
Validation loss: 6.349369495842809

Epoch: 6| Step: 1
Training loss: 5.979075822129
Validation loss: 6.341431400980758

Epoch: 6| Step: 2
Training loss: 6.293017244536921
Validation loss: 6.334677960973263

Epoch: 6| Step: 3
Training loss: 6.959742176936843
Validation loss: 6.3294680425183545

Epoch: 6| Step: 4
Training loss: 5.832202947175365
Validation loss: 6.323397140653669

Epoch: 6| Step: 5
Training loss: 5.040157228772439
Validation loss: 6.314908635713452

Epoch: 6| Step: 6
Training loss: 5.955423066735779
Validation loss: 6.307152433133767

Epoch: 6| Step: 7
Training loss: 8.06634808166073
Validation loss: 6.302336168281128

Epoch: 6| Step: 8
Training loss: 7.771630403959145
Validation loss: 6.2942050940909775

Epoch: 6| Step: 9
Training loss: 5.5554291435270775
Validation loss: 6.28694004734429

Epoch: 6| Step: 10
Training loss: 5.865604761136501
Validation loss: 6.280275076035689

Epoch: 6| Step: 11
Training loss: 6.544470151898609
Validation loss: 6.276731642713514

Epoch: 6| Step: 12
Training loss: 5.640332158906332
Validation loss: 6.265563357347673

Epoch: 6| Step: 13
Training loss: 6.309069314989168
Validation loss: 6.261372431141319

Epoch: 2| Step: 0
Training loss: 5.942625704387848
Validation loss: 6.256394997809489

Epoch: 6| Step: 1
Training loss: 5.348819581051929
Validation loss: 6.246722011897297

Epoch: 6| Step: 2
Training loss: 7.774545009829404
Validation loss: 6.240416479302899

Epoch: 6| Step: 3
Training loss: 6.7709911464982016
Validation loss: 6.228178853514863

Epoch: 6| Step: 4
Training loss: 7.019454081031026
Validation loss: 6.225458619461618

Epoch: 6| Step: 5
Training loss: 7.043246601736382
Validation loss: 6.2178068665560415

Epoch: 6| Step: 6
Training loss: 5.310911412299858
Validation loss: 6.212842327002568

Epoch: 6| Step: 7
Training loss: 6.3942759188486065
Validation loss: 6.20229513350996

Epoch: 6| Step: 8
Training loss: 5.999077726053599
Validation loss: 6.196459595535662

Epoch: 6| Step: 9
Training loss: 5.448858565045089
Validation loss: 6.191264002353667

Epoch: 6| Step: 10
Training loss: 5.198766400659204
Validation loss: 6.183188999858492

Epoch: 6| Step: 11
Training loss: 6.535761247119245
Validation loss: 6.173806831287925

Epoch: 6| Step: 12
Training loss: 6.5044986122887
Validation loss: 6.1714796602968125

Epoch: 6| Step: 13
Training loss: 4.144759277053576
Validation loss: 6.157568565969039

Epoch: 3| Step: 0
Training loss: 6.274640149744769
Validation loss: 6.151631911597752

Epoch: 6| Step: 1
Training loss: 6.0408113422257514
Validation loss: 6.143230180455501

Epoch: 6| Step: 2
Training loss: 5.914505935633718
Validation loss: 6.136754439481435

Epoch: 6| Step: 3
Training loss: 6.102082956856086
Validation loss: 6.12733659339219

Epoch: 6| Step: 4
Training loss: 6.819989208761051
Validation loss: 6.12485949832508

Epoch: 6| Step: 5
Training loss: 5.889706324977708
Validation loss: 6.116001001772251

Epoch: 6| Step: 6
Training loss: 7.3458506075662635
Validation loss: 6.109733096663198

Epoch: 6| Step: 7
Training loss: 5.195951448315031
Validation loss: 6.101500732610065

Epoch: 6| Step: 8
Training loss: 6.352216210690054
Validation loss: 6.0925478641114506

Epoch: 6| Step: 9
Training loss: 6.492223930027151
Validation loss: 6.084262472959623

Epoch: 6| Step: 10
Training loss: 5.605379429547507
Validation loss: 6.078009828941564

Epoch: 6| Step: 11
Training loss: 6.410928050923758
Validation loss: 6.069032425008051

Epoch: 6| Step: 12
Training loss: 5.662966623511382
Validation loss: 6.060373613126662

Epoch: 6| Step: 13
Training loss: 4.363261578822041
Validation loss: 6.050906439899854

Epoch: 4| Step: 0
Training loss: 5.844457246954127
Validation loss: 6.045157601161048

Epoch: 6| Step: 1
Training loss: 5.7793394488758
Validation loss: 6.03281574008606

Epoch: 6| Step: 2
Training loss: 5.468433479958538
Validation loss: 6.026080001485204

Epoch: 6| Step: 3
Training loss: 6.646049025651796
Validation loss: 6.019232186361246

Epoch: 6| Step: 4
Training loss: 6.445050302432007
Validation loss: 6.008627997985575

Epoch: 6| Step: 5
Training loss: 4.732983475950256
Validation loss: 5.999411878850717

Epoch: 6| Step: 6
Training loss: 6.36499375072571
Validation loss: 5.9938179798320155

Epoch: 6| Step: 7
Training loss: 5.659935862039635
Validation loss: 5.984283605071665

Epoch: 6| Step: 8
Training loss: 6.229131726153138
Validation loss: 5.978138546016262

Epoch: 6| Step: 9
Training loss: 6.99413517086495
Validation loss: 5.9664217606425485

Epoch: 6| Step: 10
Training loss: 5.132276811907932
Validation loss: 5.956899821450303

Epoch: 6| Step: 11
Training loss: 6.4241217699493145
Validation loss: 5.950600717176685

Epoch: 6| Step: 12
Training loss: 6.283296621739863
Validation loss: 5.938968810530133

Epoch: 6| Step: 13
Training loss: 5.3903843922752275
Validation loss: 5.933530968576142

Epoch: 5| Step: 0
Training loss: 6.05688877575325
Validation loss: 5.917674744673097

Epoch: 6| Step: 1
Training loss: 7.198709255658946
Validation loss: 5.9128699778276435

Epoch: 6| Step: 2
Training loss: 5.895358907889496
Validation loss: 5.901853552922186

Epoch: 6| Step: 3
Training loss: 4.470459084372524
Validation loss: 5.890907435542794

Epoch: 6| Step: 4
Training loss: 5.8787135298561095
Validation loss: 5.881265232371194

Epoch: 6| Step: 5
Training loss: 6.00692857606687
Validation loss: 5.867537458365867

Epoch: 6| Step: 6
Training loss: 5.982762370941888
Validation loss: 5.861368371023054

Epoch: 6| Step: 7
Training loss: 6.002067845368807
Validation loss: 5.85238185605923

Epoch: 6| Step: 8
Training loss: 5.282119950191674
Validation loss: 5.842886915790061

Epoch: 6| Step: 9
Training loss: 5.815716581530555
Validation loss: 5.833165964752099

Epoch: 6| Step: 10
Training loss: 5.698958372007898
Validation loss: 5.8217402471433175

Epoch: 6| Step: 11
Training loss: 5.403825690405378
Validation loss: 5.814553684731567

Epoch: 6| Step: 12
Training loss: 6.421372442698801
Validation loss: 5.80368028263028

Epoch: 6| Step: 13
Training loss: 5.7806920787587215
Validation loss: 5.7951415638647426

Epoch: 6| Step: 0
Training loss: 5.6893079629825145
Validation loss: 5.781574550344363

Epoch: 6| Step: 1
Training loss: 5.064479111363141
Validation loss: 5.772616120993044

Epoch: 6| Step: 2
Training loss: 6.181838094199846
Validation loss: 5.76273995842284

Epoch: 6| Step: 3
Training loss: 5.517325768565294
Validation loss: 5.756214615989869

Epoch: 6| Step: 4
Training loss: 6.183940749996146
Validation loss: 5.738153549970696

Epoch: 6| Step: 5
Training loss: 5.748903916420449
Validation loss: 5.730843179420799

Epoch: 6| Step: 6
Training loss: 6.499905805638858
Validation loss: 5.7175501472442765

Epoch: 6| Step: 7
Training loss: 5.121640476631975
Validation loss: 5.706956593039625

Epoch: 6| Step: 8
Training loss: 4.450950546754403
Validation loss: 5.701329357724115

Epoch: 6| Step: 9
Training loss: 6.323708733391774
Validation loss: 5.686712319326523

Epoch: 6| Step: 10
Training loss: 6.62892610348014
Validation loss: 5.675586113372432

Epoch: 6| Step: 11
Training loss: 5.458996429157085
Validation loss: 5.668390172401122

Epoch: 6| Step: 12
Training loss: 5.158270052931006
Validation loss: 5.65205349729606

Epoch: 6| Step: 13
Training loss: 5.904659319424517
Validation loss: 5.644814194235285

Epoch: 7| Step: 0
Training loss: 5.157649549644986
Validation loss: 5.634554624876699

Epoch: 6| Step: 1
Training loss: 5.8097737799772995
Validation loss: 5.625444942911017

Epoch: 6| Step: 2
Training loss: 5.307719155098028
Validation loss: 5.60408714498152

Epoch: 6| Step: 3
Training loss: 5.671635898563054
Validation loss: 5.598666090171903

Epoch: 6| Step: 4
Training loss: 5.658894463395793
Validation loss: 5.581551589702309

Epoch: 6| Step: 5
Training loss: 6.056423012355547
Validation loss: 5.570563387510948

Epoch: 6| Step: 6
Training loss: 5.203783331568875
Validation loss: 5.561479663630693

Epoch: 6| Step: 7
Training loss: 5.005222073105112
Validation loss: 5.547935841721278

Epoch: 6| Step: 8
Training loss: 6.6947034026835235
Validation loss: 5.5347327239822395

Epoch: 6| Step: 9
Training loss: 5.563311914060275
Validation loss: 5.526164899734733

Epoch: 6| Step: 10
Training loss: 6.225425932380111
Validation loss: 5.512384765676593

Epoch: 6| Step: 11
Training loss: 4.618888322258517
Validation loss: 5.495874977913409

Epoch: 6| Step: 12
Training loss: 5.630273678024286
Validation loss: 5.480904289792298

Epoch: 6| Step: 13
Training loss: 4.8177912964422
Validation loss: 5.470809825183201

Epoch: 8| Step: 0
Training loss: 4.118258429267689
Validation loss: 5.459985155102464

Epoch: 6| Step: 1
Training loss: 6.461166580733264
Validation loss: 5.443514042012571

Epoch: 6| Step: 2
Training loss: 6.2022738317163775
Validation loss: 5.435467615666497

Epoch: 6| Step: 3
Training loss: 6.180159096259426
Validation loss: 5.4228477474246715

Epoch: 6| Step: 4
Training loss: 5.233587313925827
Validation loss: 5.4002424552567625

Epoch: 6| Step: 5
Training loss: 4.872845295805672
Validation loss: 5.39373161892555

Epoch: 6| Step: 6
Training loss: 5.708251989671434
Validation loss: 5.379889860278081

Epoch: 6| Step: 7
Training loss: 5.3149419221190035
Validation loss: 5.3650831050866294

Epoch: 6| Step: 8
Training loss: 6.3582312752801915
Validation loss: 5.350621135429931

Epoch: 6| Step: 9
Training loss: 5.224038556726308
Validation loss: 5.3362099647278365

Epoch: 6| Step: 10
Training loss: 4.875268390799036
Validation loss: 5.326059058004107

Epoch: 6| Step: 11
Training loss: 4.279544908446819
Validation loss: 5.30530906200142

Epoch: 6| Step: 12
Training loss: 4.6797790008922835
Validation loss: 5.291566800173216

Epoch: 6| Step: 13
Training loss: 5.546933971682559
Validation loss: 5.278472101854532

Epoch: 9| Step: 0
Training loss: 4.582694939745237
Validation loss: 5.261711332482189

Epoch: 6| Step: 1
Training loss: 6.099993671351418
Validation loss: 5.250517130675903

Epoch: 6| Step: 2
Training loss: 5.7923108664279965
Validation loss: 5.231806018829265

Epoch: 6| Step: 3
Training loss: 4.577760232708671
Validation loss: 5.217142697726462

Epoch: 6| Step: 4
Training loss: 4.754392901472518
Validation loss: 5.1991021506029265

Epoch: 6| Step: 5
Training loss: 5.550681599870824
Validation loss: 5.185882838161458

Epoch: 6| Step: 6
Training loss: 6.416242742365276
Validation loss: 5.1767514271128645

Epoch: 6| Step: 7
Training loss: 3.9104931788139323
Validation loss: 5.159938451847123

Epoch: 6| Step: 8
Training loss: 4.061787939023489
Validation loss: 5.1384362869624525

Epoch: 6| Step: 9
Training loss: 6.529447315889497
Validation loss: 5.130360774708119

Epoch: 6| Step: 10
Training loss: 4.379249906368857
Validation loss: 5.110056352250251

Epoch: 6| Step: 11
Training loss: 4.261326227197304
Validation loss: 5.096021749459481

Epoch: 6| Step: 12
Training loss: 5.386887999289992
Validation loss: 5.0818059527241575

Epoch: 6| Step: 13
Training loss: 5.8889922046995204
Validation loss: 5.0652661430166726

Epoch: 10| Step: 0
Training loss: 4.381073577855099
Validation loss: 5.0442301288345455

Epoch: 6| Step: 1
Training loss: 5.379784517191744
Validation loss: 5.027774284615545

Epoch: 6| Step: 2
Training loss: 5.879927820813664
Validation loss: 5.009336835348772

Epoch: 6| Step: 3
Training loss: 4.309446276434207
Validation loss: 4.9911213502052725

Epoch: 6| Step: 4
Training loss: 4.249855936638057
Validation loss: 4.9820565876439

Epoch: 6| Step: 5
Training loss: 5.417196316377669
Validation loss: 4.960594126476124

Epoch: 6| Step: 6
Training loss: 4.762299124418735
Validation loss: 4.944332460434452

Epoch: 6| Step: 7
Training loss: 5.021734301928959
Validation loss: 4.925048702872225

Epoch: 6| Step: 8
Training loss: 6.059930945276806
Validation loss: 4.90976966469518

Epoch: 6| Step: 9
Training loss: 4.650039935196878
Validation loss: 4.895630590063018

Epoch: 6| Step: 10
Training loss: 4.8357075527166025
Validation loss: 4.875999648991981

Epoch: 6| Step: 11
Training loss: 4.47904412153707
Validation loss: 4.852521437019172

Epoch: 6| Step: 12
Training loss: 5.025018280147876
Validation loss: 4.836049098039669

Epoch: 6| Step: 13
Training loss: 4.817612149764811
Validation loss: 4.823693666565546

Epoch: 11| Step: 0
Training loss: 4.364201106387865
Validation loss: 4.797576377369391

Epoch: 6| Step: 1
Training loss: 5.150810192784223
Validation loss: 4.7854172574437195

Epoch: 6| Step: 2
Training loss: 5.369541679160176
Validation loss: 4.762355843624381

Epoch: 6| Step: 3
Training loss: 5.0175959912342485
Validation loss: 4.745228834976421

Epoch: 6| Step: 4
Training loss: 4.6774395620824
Validation loss: 4.723829803995771

Epoch: 6| Step: 5
Training loss: 4.718954321877653
Validation loss: 4.704580317118715

Epoch: 6| Step: 6
Training loss: 5.795190119023275
Validation loss: 4.6823270216184945

Epoch: 6| Step: 7
Training loss: 4.611757031488158
Validation loss: 4.660678741367856

Epoch: 6| Step: 8
Training loss: 4.261766414218446
Validation loss: 4.646767937459454

Epoch: 6| Step: 9
Training loss: 5.097873072196824
Validation loss: 4.629503728478636

Epoch: 6| Step: 10
Training loss: 2.944741757895065
Validation loss: 4.6047976467059595

Epoch: 6| Step: 11
Training loss: 3.9556186937681797
Validation loss: 4.587529287518317

Epoch: 6| Step: 12
Training loss: 5.6983465373103925
Validation loss: 4.565059489547795

Epoch: 6| Step: 13
Training loss: 3.057747871289024
Validation loss: 4.543091785872991

Epoch: 12| Step: 0
Training loss: 5.008289713148599
Validation loss: 4.520131622577438

Epoch: 6| Step: 1
Training loss: 4.751149690929567
Validation loss: 4.503075404455289

Epoch: 6| Step: 2
Training loss: 4.245021821629812
Validation loss: 4.482139844156434

Epoch: 6| Step: 3
Training loss: 3.704151381527946
Validation loss: 4.465561754956027

Epoch: 6| Step: 4
Training loss: 4.279058633472587
Validation loss: 4.441447171955561

Epoch: 6| Step: 5
Training loss: 4.598356467494494
Validation loss: 4.416523698724444

Epoch: 6| Step: 6
Training loss: 3.82227485667319
Validation loss: 4.400388702439785

Epoch: 6| Step: 7
Training loss: 3.893697115568082
Validation loss: 4.380665225303321

Epoch: 6| Step: 8
Training loss: 3.712229164596846
Validation loss: 4.355604536170227

Epoch: 6| Step: 9
Training loss: 4.414207253572291
Validation loss: 4.337808259423959

Epoch: 6| Step: 10
Training loss: 5.230965759503651
Validation loss: 4.318279234799095

Epoch: 6| Step: 11
Training loss: 5.374289709666092
Validation loss: 4.292953825452009

Epoch: 6| Step: 12
Training loss: 4.444180470150771
Validation loss: 4.28219133062475

Epoch: 6| Step: 13
Training loss: 4.5993910427878975
Validation loss: 4.246110182022616

Epoch: 13| Step: 0
Training loss: 4.202932587370915
Validation loss: 4.236793055593024

Epoch: 6| Step: 1
Training loss: 4.123004546280232
Validation loss: 4.205540251107423

Epoch: 6| Step: 2
Training loss: 4.165608589615088
Validation loss: 4.18439846676001

Epoch: 6| Step: 3
Training loss: 5.3432406355602176
Validation loss: 4.16480579209385

Epoch: 6| Step: 4
Training loss: 4.68959893600103
Validation loss: 4.130332090936687

Epoch: 6| Step: 5
Training loss: 4.222145579016109
Validation loss: 4.1126679919615015

Epoch: 6| Step: 6
Training loss: 3.5082238174947866
Validation loss: 4.090001339786206

Epoch: 6| Step: 7
Training loss: 3.8913215718364182
Validation loss: 4.06854482635336

Epoch: 6| Step: 8
Training loss: 4.0613500287954105
Validation loss: 4.043830410794879

Epoch: 6| Step: 9
Training loss: 3.6196781424232083
Validation loss: 4.0135504115564515

Epoch: 6| Step: 10
Training loss: 4.744843746140959
Validation loss: 4.002586738382542

Epoch: 6| Step: 11
Training loss: 3.296831031253014
Validation loss: 3.977311015036024

Epoch: 6| Step: 12
Training loss: 4.020466894868601
Validation loss: 3.958451187805857

Epoch: 6| Step: 13
Training loss: 4.114036092300358
Validation loss: 3.93947688029106

Epoch: 14| Step: 0
Training loss: 4.044097536414423
Validation loss: 3.91003514290874

Epoch: 6| Step: 1
Training loss: 4.5955829726245145
Validation loss: 3.8854489110563066

Epoch: 6| Step: 2
Training loss: 3.517552097696602
Validation loss: 3.863398804774532

Epoch: 6| Step: 3
Training loss: 3.457537701250184
Validation loss: 3.846785171289152

Epoch: 6| Step: 4
Training loss: 3.851736440077488
Validation loss: 3.8218078417952195

Epoch: 6| Step: 5
Training loss: 3.5413495688506704
Validation loss: 3.804249792742229

Epoch: 6| Step: 6
Training loss: 3.375945912366289
Validation loss: 3.7785560654520145

Epoch: 6| Step: 7
Training loss: 4.446547619905131
Validation loss: 3.757042703881529

Epoch: 6| Step: 8
Training loss: 3.593278936942797
Validation loss: 3.740720501219798

Epoch: 6| Step: 9
Training loss: 4.601067767401359
Validation loss: 3.715710740994221

Epoch: 6| Step: 10
Training loss: 3.677671880692476
Validation loss: 3.699946365588526

Epoch: 6| Step: 11
Training loss: 3.3128358202875337
Validation loss: 3.670219948696933

Epoch: 6| Step: 12
Training loss: 4.194238507490346
Validation loss: 3.6548438076793994

Epoch: 6| Step: 13
Training loss: 3.537498549605972
Validation loss: 3.6230287436055453

Epoch: 15| Step: 0
Training loss: 3.768499266727756
Validation loss: 3.6026691216071614

Epoch: 6| Step: 1
Training loss: 3.662872837084888
Validation loss: 3.58062148137158

Epoch: 6| Step: 2
Training loss: 3.2599771384157226
Validation loss: 3.5487582156683053

Epoch: 6| Step: 3
Training loss: 4.202413846232872
Validation loss: 3.5262134587887304

Epoch: 6| Step: 4
Training loss: 4.803479149692264
Validation loss: 3.5178174371453728

Epoch: 6| Step: 5
Training loss: 3.232538116301159
Validation loss: 3.487691166387418

Epoch: 6| Step: 6
Training loss: 3.283850520366648
Validation loss: 3.4729234317727653

Epoch: 6| Step: 7
Training loss: 3.777904701594016
Validation loss: 3.4517040433285175

Epoch: 6| Step: 8
Training loss: 3.5437032491301395
Validation loss: 3.422588929268203

Epoch: 6| Step: 9
Training loss: 3.532585499154676
Validation loss: 3.404664731079097

Epoch: 6| Step: 10
Training loss: 3.6463536063858006
Validation loss: 3.377171481359034

Epoch: 6| Step: 11
Training loss: 2.577439650560749
Validation loss: 3.3494495175874897

Epoch: 6| Step: 12
Training loss: 3.284201321061293
Validation loss: 3.3337742303677134

Epoch: 6| Step: 13
Training loss: 3.3365886686991844
Validation loss: 3.3291631551945784

Epoch: 16| Step: 0
Training loss: 3.990669454567451
Validation loss: 3.302637256327606

Epoch: 6| Step: 1
Training loss: 2.4856193832859637
Validation loss: 3.287315515196709

Epoch: 6| Step: 2
Training loss: 3.4580195334364334
Validation loss: 3.274296893197223

Epoch: 6| Step: 3
Training loss: 3.2529934522138966
Validation loss: 3.24506041922648

Epoch: 6| Step: 4
Training loss: 3.0397992258529336
Validation loss: 3.2346541165544784

Epoch: 6| Step: 5
Training loss: 2.966983309645809
Validation loss: 3.2162718623106055

Epoch: 6| Step: 6
Training loss: 3.629447576349968
Validation loss: 3.1915637272767334

Epoch: 6| Step: 7
Training loss: 3.4211211745928494
Validation loss: 3.181766464589243

Epoch: 6| Step: 8
Training loss: 2.8609823076540466
Validation loss: 3.1613136073626347

Epoch: 6| Step: 9
Training loss: 3.331794828768101
Validation loss: 3.145493901768338

Epoch: 6| Step: 10
Training loss: 4.088079587575989
Validation loss: 3.1304393051988018

Epoch: 6| Step: 11
Training loss: 3.70778957766566
Validation loss: 3.1217195746224653

Epoch: 6| Step: 12
Training loss: 2.9913692301713306
Validation loss: 3.096974288368499

Epoch: 6| Step: 13
Training loss: 3.6463073131724273
Validation loss: 3.078959835134585

Epoch: 17| Step: 0
Training loss: 3.415838342758964
Validation loss: 3.0689260147395636

Epoch: 6| Step: 1
Training loss: 2.699864709078338
Validation loss: 3.0608771776947146

Epoch: 6| Step: 2
Training loss: 2.768250851383249
Validation loss: 3.0451703078021906

Epoch: 6| Step: 3
Training loss: 3.3441809260690696
Validation loss: 3.034393992328192

Epoch: 6| Step: 4
Training loss: 3.3334282543654594
Validation loss: 3.0144637618612937

Epoch: 6| Step: 5
Training loss: 3.259610272380368
Validation loss: 3.000416111544381

Epoch: 6| Step: 6
Training loss: 4.111669095866818
Validation loss: 2.9985684180257453

Epoch: 6| Step: 7
Training loss: 2.645672370239636
Validation loss: 2.972203661246338

Epoch: 6| Step: 8
Training loss: 2.732430426016373
Validation loss: 2.9665653638237965

Epoch: 6| Step: 9
Training loss: 3.4262988614004874
Validation loss: 2.9573370246495045

Epoch: 6| Step: 10
Training loss: 2.6437682455528977
Validation loss: 2.9398322794654073

Epoch: 6| Step: 11
Training loss: 3.4247906251938987
Validation loss: 2.933932204118968

Epoch: 6| Step: 12
Training loss: 3.8362179282679003
Validation loss: 2.932433112250205

Epoch: 6| Step: 13
Training loss: 2.554681713785974
Validation loss: 2.9123614101540465

Epoch: 18| Step: 0
Training loss: 2.7299812984175316
Validation loss: 2.9075671195232307

Epoch: 6| Step: 1
Training loss: 2.9035178847697383
Validation loss: 2.898754802468645

Epoch: 6| Step: 2
Training loss: 3.46805696179734
Validation loss: 2.8828545761917277

Epoch: 6| Step: 3
Training loss: 2.7135717252407616
Validation loss: 2.8726193601911616

Epoch: 6| Step: 4
Training loss: 3.532088998694986
Validation loss: 2.8675422807727244

Epoch: 6| Step: 5
Training loss: 3.2261000479635182
Validation loss: 2.854695247755458

Epoch: 6| Step: 6
Training loss: 2.8058787926606494
Validation loss: 2.8455163544728803

Epoch: 6| Step: 7
Training loss: 3.5172129117911126
Validation loss: 2.8333741341342877

Epoch: 6| Step: 8
Training loss: 2.6878454296878833
Validation loss: 2.8371771020805157

Epoch: 6| Step: 9
Training loss: 2.88205400945498
Validation loss: 2.831683205564082

Epoch: 6| Step: 10
Training loss: 3.5343911033148845
Validation loss: 2.811605951729928

Epoch: 6| Step: 11
Training loss: 3.0572396078448594
Validation loss: 2.8072179016422183

Epoch: 6| Step: 12
Training loss: 3.0205300716020274
Validation loss: 2.809432716383137

Epoch: 6| Step: 13
Training loss: 3.6662410286742566
Validation loss: 2.803615416697953

Epoch: 19| Step: 0
Training loss: 3.305788835117527
Validation loss: 2.7981716992294996

Epoch: 6| Step: 1
Training loss: 3.006433106236996
Validation loss: 2.782844631996233

Epoch: 6| Step: 2
Training loss: 3.054553875354207
Validation loss: 2.806438470648674

Epoch: 6| Step: 3
Training loss: 3.9224319366521145
Validation loss: 2.780376881210894

Epoch: 6| Step: 4
Training loss: 3.0493954919313
Validation loss: 2.782182643802047

Epoch: 6| Step: 5
Training loss: 3.006447856522587
Validation loss: 2.785956835112448

Epoch: 6| Step: 6
Training loss: 3.1076063176916144
Validation loss: 2.768499029674771

Epoch: 6| Step: 7
Training loss: 2.518927450058303
Validation loss: 2.7777061869170314

Epoch: 6| Step: 8
Training loss: 3.1657279446913633
Validation loss: 2.775800833994596

Epoch: 6| Step: 9
Training loss: 3.3124700580899122
Validation loss: 2.7663278012907946

Epoch: 6| Step: 10
Training loss: 2.682236062865466
Validation loss: 2.7611023236894434

Epoch: 6| Step: 11
Training loss: 2.655813113916532
Validation loss: 2.7700498720658473

Epoch: 6| Step: 12
Training loss: 2.7556737976529524
Validation loss: 2.7603780539829037

Epoch: 6| Step: 13
Training loss: 3.26574677600773
Validation loss: 2.7731683577667465

Epoch: 20| Step: 0
Training loss: 3.113298250963226
Validation loss: 2.7596182568038956

Epoch: 6| Step: 1
Training loss: 3.3297281478484426
Validation loss: 2.756428918069617

Epoch: 6| Step: 2
Training loss: 2.940928467224018
Validation loss: 2.757099042475262

Epoch: 6| Step: 3
Training loss: 3.754003168258184
Validation loss: 2.7524958328913396

Epoch: 6| Step: 4
Training loss: 2.4055227196174944
Validation loss: 2.7570430659831002

Epoch: 6| Step: 5
Training loss: 2.766205635111507
Validation loss: 2.7526571556820696

Epoch: 6| Step: 6
Training loss: 2.604185689220888
Validation loss: 2.745178590156108

Epoch: 6| Step: 7
Training loss: 2.8368295154677696
Validation loss: 2.7471058845560896

Epoch: 6| Step: 8
Training loss: 3.302275803469137
Validation loss: 2.7472670745343044

Epoch: 6| Step: 9
Training loss: 3.6771507509155095
Validation loss: 2.7388817784006596

Epoch: 6| Step: 10
Training loss: 2.6838003909137957
Validation loss: 2.7445215982498183

Epoch: 6| Step: 11
Training loss: 2.386060158724982
Validation loss: 2.7456671756115862

Epoch: 6| Step: 12
Training loss: 3.290351089713543
Validation loss: 2.73452066481789

Epoch: 6| Step: 13
Training loss: 3.230306674346439
Validation loss: 2.7333934150678414

Epoch: 21| Step: 0
Training loss: 3.4746391548137128
Validation loss: 2.7420904268983035

Epoch: 6| Step: 1
Training loss: 3.257228881373972
Validation loss: 2.7349079462371595

Epoch: 6| Step: 2
Training loss: 2.9782476185776554
Validation loss: 2.7401247500571926

Epoch: 6| Step: 3
Training loss: 3.4444700841735587
Validation loss: 2.722825991763424

Epoch: 6| Step: 4
Training loss: 2.4772076172659667
Validation loss: 2.735925331622064

Epoch: 6| Step: 5
Training loss: 3.327730253924332
Validation loss: 2.738712347482689

Epoch: 6| Step: 6
Training loss: 3.7484194921686687
Validation loss: 2.7354983463164833

Epoch: 6| Step: 7
Training loss: 3.0680880265719144
Validation loss: 2.7343912023952033

Epoch: 6| Step: 8
Training loss: 3.0029277820115907
Validation loss: 2.7231664574574257

Epoch: 6| Step: 9
Training loss: 2.9407882142454467
Validation loss: 2.736193904606487

Epoch: 6| Step: 10
Training loss: 3.0678051521467404
Validation loss: 2.743752028711448

Epoch: 6| Step: 11
Training loss: 2.56156597327555
Validation loss: 2.730145390148278

Epoch: 6| Step: 12
Training loss: 2.461696447176372
Validation loss: 2.7480826121294455

Epoch: 6| Step: 13
Training loss: 1.6764622440563521
Validation loss: 2.742333532300867

Epoch: 22| Step: 0
Training loss: 2.771394562828609
Validation loss: 2.737479857305431

Epoch: 6| Step: 1
Training loss: 3.5737221628221043
Validation loss: 2.7341847090129225

Epoch: 6| Step: 2
Training loss: 3.8883008027844976
Validation loss: 2.7333852731745525

Epoch: 6| Step: 3
Training loss: 3.5951408016979256
Validation loss: 2.7287452921665802

Epoch: 6| Step: 4
Training loss: 3.118430747775925
Validation loss: 2.7398139828134465

Epoch: 6| Step: 5
Training loss: 3.0218640553099694
Validation loss: 2.7228982970568256

Epoch: 6| Step: 6
Training loss: 3.2212952855412667
Validation loss: 2.727882397452267

Epoch: 6| Step: 7
Training loss: 2.591899533455786
Validation loss: 2.718677394841833

Epoch: 6| Step: 8
Training loss: 2.500313929874568
Validation loss: 2.7384251651561313

Epoch: 6| Step: 9
Training loss: 2.4582147946846793
Validation loss: 2.7326893522674984

Epoch: 6| Step: 10
Training loss: 2.507092238766428
Validation loss: 2.7296013509798644

Epoch: 6| Step: 11
Training loss: 2.6373724233136606
Validation loss: 2.747524425298704

Epoch: 6| Step: 12
Training loss: 3.1821900063783644
Validation loss: 2.7234098325767087

Epoch: 6| Step: 13
Training loss: 2.67556962338879
Validation loss: 2.721434276445993

Epoch: 23| Step: 0
Training loss: 3.061943315007456
Validation loss: 2.7306600078225705

Epoch: 6| Step: 1
Training loss: 3.4505630586547653
Validation loss: 2.7356206491359227

Epoch: 6| Step: 2
Training loss: 3.669570524360031
Validation loss: 2.724648230973176

Epoch: 6| Step: 3
Training loss: 2.745954659250881
Validation loss: 2.7206197694562633

Epoch: 6| Step: 4
Training loss: 3.43892501424516
Validation loss: 2.720560561261622

Epoch: 6| Step: 5
Training loss: 2.72631004060993
Validation loss: 2.7150542057170606

Epoch: 6| Step: 6
Training loss: 2.820555784769654
Validation loss: 2.7251839514611036

Epoch: 6| Step: 7
Training loss: 2.6585181930347086
Validation loss: 2.7178626964630492

Epoch: 6| Step: 8
Training loss: 2.944038905000699
Validation loss: 2.7203346144626486

Epoch: 6| Step: 9
Training loss: 3.191654564524947
Validation loss: 2.7120307622725672

Epoch: 6| Step: 10
Training loss: 3.354790260365026
Validation loss: 2.722392573567802

Epoch: 6| Step: 11
Training loss: 2.99123963165718
Validation loss: 2.7128610657117576

Epoch: 6| Step: 12
Training loss: 2.234355793050096
Validation loss: 2.718222891733255

Epoch: 6| Step: 13
Training loss: 2.1745672211930596
Validation loss: 2.7161685681244263

Epoch: 24| Step: 0
Training loss: 3.0120409287284677
Validation loss: 2.717307718449374

Epoch: 6| Step: 1
Training loss: 2.584758386000801
Validation loss: 2.701986526099949

Epoch: 6| Step: 2
Training loss: 3.252684731423587
Validation loss: 2.7121310758987596

Epoch: 6| Step: 3
Training loss: 2.9641189593949053
Validation loss: 2.7082731393288664

Epoch: 6| Step: 4
Training loss: 2.8124969482405318
Validation loss: 2.7099197840131777

Epoch: 6| Step: 5
Training loss: 2.4269201090095933
Validation loss: 2.7134088430152135

Epoch: 6| Step: 6
Training loss: 3.6920456105532167
Validation loss: 2.7027242888572753

Epoch: 6| Step: 7
Training loss: 2.8649452859337545
Validation loss: 2.711814037689261

Epoch: 6| Step: 8
Training loss: 2.842340476358334
Validation loss: 2.7033549086586772

Epoch: 6| Step: 9
Training loss: 3.1126858514044895
Validation loss: 2.7169309147347844

Epoch: 6| Step: 10
Training loss: 3.3258186193064394
Validation loss: 2.718901488907187

Epoch: 6| Step: 11
Training loss: 3.010156604837119
Validation loss: 2.705022137263418

Epoch: 6| Step: 12
Training loss: 2.6745661517406183
Validation loss: 2.709600562638097

Epoch: 6| Step: 13
Training loss: 3.6330113510345114
Validation loss: 2.705968793595294

Epoch: 25| Step: 0
Training loss: 3.2244407937838133
Validation loss: 2.7212127056861006

Epoch: 6| Step: 1
Training loss: 3.089153998895821
Validation loss: 2.7159266707843064

Epoch: 6| Step: 2
Training loss: 3.277395836799293
Validation loss: 2.6974509752626736

Epoch: 6| Step: 3
Training loss: 2.6129805273534137
Validation loss: 2.7153084971611694

Epoch: 6| Step: 4
Training loss: 3.7984645953951848
Validation loss: 2.702488484940691

Epoch: 6| Step: 5
Training loss: 3.0694541604956065
Validation loss: 2.708311621024387

Epoch: 6| Step: 6
Training loss: 2.6545837561693295
Validation loss: 2.705184657337785

Epoch: 6| Step: 7
Training loss: 2.336294701864463
Validation loss: 2.71714091819081

Epoch: 6| Step: 8
Training loss: 3.6904847301730075
Validation loss: 2.713430321641212

Epoch: 6| Step: 9
Training loss: 1.8966042414930657
Validation loss: 2.718479684779708

Epoch: 6| Step: 10
Training loss: 3.013571717136284
Validation loss: 2.713938471825047

Epoch: 6| Step: 11
Training loss: 3.4902160678206218
Validation loss: 2.7035768856605515

Epoch: 6| Step: 12
Training loss: 2.3832290035256474
Validation loss: 2.7162982350994733

Epoch: 6| Step: 13
Training loss: 3.0100260726458523
Validation loss: 2.717523783214718

Epoch: 26| Step: 0
Training loss: 2.8982302033771536
Validation loss: 2.7227124080544436

Epoch: 6| Step: 1
Training loss: 2.8449387633264864
Validation loss: 2.709494902198569

Epoch: 6| Step: 2
Training loss: 2.9560442024198754
Validation loss: 2.716150869095585

Epoch: 6| Step: 3
Training loss: 2.70051607568678
Validation loss: 2.709006509031639

Epoch: 6| Step: 4
Training loss: 2.871851980555017
Validation loss: 2.711904750085713

Epoch: 6| Step: 5
Training loss: 3.815409941240175
Validation loss: 2.70998122547925

Epoch: 6| Step: 6
Training loss: 3.0875000679541205
Validation loss: 2.698421823582039

Epoch: 6| Step: 7
Training loss: 2.7436343992033083
Validation loss: 2.7025816010425796

Epoch: 6| Step: 8
Training loss: 3.0335140621575527
Validation loss: 2.7128632240798938

Epoch: 6| Step: 9
Training loss: 3.3824851778527507
Validation loss: 2.711076347594805

Epoch: 6| Step: 10
Training loss: 3.207146627416042
Validation loss: 2.7022758334165897

Epoch: 6| Step: 11
Training loss: 2.9418504032608483
Validation loss: 2.7006912347769423

Epoch: 6| Step: 12
Training loss: 2.4274958204082178
Validation loss: 2.7069706668463134

Epoch: 6| Step: 13
Training loss: 2.7883003967431534
Validation loss: 2.7057042678820733

Epoch: 27| Step: 0
Training loss: 2.928797716443178
Validation loss: 2.703364103536216

Epoch: 6| Step: 1
Training loss: 3.292506501141432
Validation loss: 2.707099139857334

Epoch: 6| Step: 2
Training loss: 3.6294567729447893
Validation loss: 2.702578507690322

Epoch: 6| Step: 3
Training loss: 2.5622534284357514
Validation loss: 2.6913643936757157

Epoch: 6| Step: 4
Training loss: 2.755917770880905
Validation loss: 2.7033634643718543

Epoch: 6| Step: 5
Training loss: 3.1838275472529873
Validation loss: 2.7145333845192963

Epoch: 6| Step: 6
Training loss: 3.18179274090591
Validation loss: 2.6960249278052717

Epoch: 6| Step: 7
Training loss: 3.3358411574019815
Validation loss: 2.7045764666872913

Epoch: 6| Step: 8
Training loss: 2.8860077143597085
Validation loss: 2.697405669610591

Epoch: 6| Step: 9
Training loss: 3.328336467203401
Validation loss: 2.704729973095383

Epoch: 6| Step: 10
Training loss: 2.9490601351697068
Validation loss: 2.7139459640684582

Epoch: 6| Step: 11
Training loss: 2.688495274266294
Validation loss: 2.703440710178621

Epoch: 6| Step: 12
Training loss: 2.302577925035458
Validation loss: 2.6906085569766742

Epoch: 6| Step: 13
Training loss: 2.3836778413986037
Validation loss: 2.6933554058344193

Epoch: 28| Step: 0
Training loss: 2.5879156838409405
Validation loss: 2.69690573912013

Epoch: 6| Step: 1
Training loss: 2.5113696008420767
Validation loss: 2.7172370456695703

Epoch: 6| Step: 2
Training loss: 3.8133238855880687
Validation loss: 2.6991778202431327

Epoch: 6| Step: 3
Training loss: 2.476852159377964
Validation loss: 2.6979366169829038

Epoch: 6| Step: 4
Training loss: 2.1868659054113793
Validation loss: 2.6887088421688046

Epoch: 6| Step: 5
Training loss: 3.4302294048855684
Validation loss: 2.694566623659383

Epoch: 6| Step: 6
Training loss: 2.819797204618978
Validation loss: 2.7052432894636276

Epoch: 6| Step: 7
Training loss: 2.8487834609419553
Validation loss: 2.7061790367010743

Epoch: 6| Step: 8
Training loss: 3.283448563569177
Validation loss: 2.7086892839867622

Epoch: 6| Step: 9
Training loss: 3.605916401525082
Validation loss: 2.689940738640481

Epoch: 6| Step: 10
Training loss: 2.66604307950035
Validation loss: 2.701014832998396

Epoch: 6| Step: 11
Training loss: 3.535604172460323
Validation loss: 2.7180085963476417

Epoch: 6| Step: 12
Training loss: 3.089635096858249
Validation loss: 2.701998942047976

Epoch: 6| Step: 13
Training loss: 2.2599936117233868
Validation loss: 2.6968062708264275

Epoch: 29| Step: 0
Training loss: 2.290763561434696
Validation loss: 2.6961003471053204

Epoch: 6| Step: 1
Training loss: 2.354299985998442
Validation loss: 2.704501168111485

Epoch: 6| Step: 2
Training loss: 2.401076564135263
Validation loss: 2.7051695380604808

Epoch: 6| Step: 3
Training loss: 3.5859638287942754
Validation loss: 2.7067514932090093

Epoch: 6| Step: 4
Training loss: 2.3538170839090182
Validation loss: 2.7123669432110633

Epoch: 6| Step: 5
Training loss: 2.6934127525700156
Validation loss: 2.7129150026655533

Epoch: 6| Step: 6
Training loss: 3.3987338232880933
Validation loss: 2.6897261648356454

Epoch: 6| Step: 7
Training loss: 3.206169505159231
Validation loss: 2.694765029337265

Epoch: 6| Step: 8
Training loss: 3.3543386632444876
Validation loss: 2.700878134427524

Epoch: 6| Step: 9
Training loss: 3.162490265721957
Validation loss: 2.687254182601178

Epoch: 6| Step: 10
Training loss: 3.2033858030258147
Validation loss: 2.7065870364515447

Epoch: 6| Step: 11
Training loss: 3.9179465995915486
Validation loss: 2.697024075916232

Epoch: 6| Step: 12
Training loss: 2.5303844337749215
Validation loss: 2.7042695509696517

Epoch: 6| Step: 13
Training loss: 2.5751625380095855
Validation loss: 2.6956067633684646

Epoch: 30| Step: 0
Training loss: 2.2800232188397747
Validation loss: 2.684961574399637

Epoch: 6| Step: 1
Training loss: 2.541598605719482
Validation loss: 2.710252952078399

Epoch: 6| Step: 2
Training loss: 2.897733453754218
Validation loss: 2.7063416199198382

Epoch: 6| Step: 3
Training loss: 3.743091577574007
Validation loss: 2.69320191647512

Epoch: 6| Step: 4
Training loss: 3.041614706213976
Validation loss: 2.6852626301530713

Epoch: 6| Step: 5
Training loss: 2.9760744991411885
Validation loss: 2.681067900551732

Epoch: 6| Step: 6
Training loss: 2.6644997335825034
Validation loss: 2.685475055170523

Epoch: 6| Step: 7
Training loss: 2.7978128746779807
Validation loss: 2.6841948528405353

Epoch: 6| Step: 8
Training loss: 3.0948724733372623
Validation loss: 2.7047858010117354

Epoch: 6| Step: 9
Training loss: 2.805902924346406
Validation loss: 2.6817759315026537

Epoch: 6| Step: 10
Training loss: 3.3921972048852136
Validation loss: 2.692490690746925

Epoch: 6| Step: 11
Training loss: 2.8348921433372856
Validation loss: 2.7046177773081106

Epoch: 6| Step: 12
Training loss: 3.691446552359357
Validation loss: 2.685206598256908

Epoch: 6| Step: 13
Training loss: 2.2739913632808455
Validation loss: 2.6808801438503944

Epoch: 31| Step: 0
Training loss: 2.7521248324603347
Validation loss: 2.6840067885916534

Epoch: 6| Step: 1
Training loss: 3.6872661969046847
Validation loss: 2.689686260127098

Epoch: 6| Step: 2
Training loss: 3.163614877191363
Validation loss: 2.6841109829194867

Epoch: 6| Step: 3
Training loss: 3.592113885378266
Validation loss: 2.690637002037095

Epoch: 6| Step: 4
Training loss: 3.096703554829577
Validation loss: 2.698853749086694

Epoch: 6| Step: 5
Training loss: 2.4296602204683415
Validation loss: 2.690250362061777

Epoch: 6| Step: 6
Training loss: 3.0913236717395076
Validation loss: 2.69585673179146

Epoch: 6| Step: 7
Training loss: 2.408293809753428
Validation loss: 2.686167791008751

Epoch: 6| Step: 8
Training loss: 2.632236859247038
Validation loss: 2.692699262334344

Epoch: 6| Step: 9
Training loss: 3.98352496485586
Validation loss: 2.6831630694296646

Epoch: 6| Step: 10
Training loss: 2.4877996292998423
Validation loss: 2.687911694399135

Epoch: 6| Step: 11
Training loss: 1.8714143163872348
Validation loss: 2.68706946657822

Epoch: 6| Step: 12
Training loss: 2.7136112626438065
Validation loss: 2.6789495176100258

Epoch: 6| Step: 13
Training loss: 2.879493684502426
Validation loss: 2.6835551689238013

Epoch: 32| Step: 0
Training loss: 3.282011543183888
Validation loss: 2.6909514497944724

Epoch: 6| Step: 1
Training loss: 3.428507469352696
Validation loss: 2.6990567312410816

Epoch: 6| Step: 2
Training loss: 2.5877910321343323
Validation loss: 2.6908201984003677

Epoch: 6| Step: 3
Training loss: 3.465207877480841
Validation loss: 2.678246359234579

Epoch: 6| Step: 4
Training loss: 3.1321083095526174
Validation loss: 2.68101504217852

Epoch: 6| Step: 5
Training loss: 2.530791535478777
Validation loss: 2.691393586106381

Epoch: 6| Step: 6
Training loss: 3.1765610229068444
Validation loss: 2.7024963774660655

Epoch: 6| Step: 7
Training loss: 1.7333035295320556
Validation loss: 2.681893390190188

Epoch: 6| Step: 8
Training loss: 2.961369545851576
Validation loss: 2.6919705543373458

Epoch: 6| Step: 9
Training loss: 2.762517875509986
Validation loss: 2.6984677059458764

Epoch: 6| Step: 10
Training loss: 3.3586706088372216
Validation loss: 2.6824315749151846

Epoch: 6| Step: 11
Training loss: 3.1006442231234255
Validation loss: 2.6901533341148176

Epoch: 6| Step: 12
Training loss: 2.731007098607406
Validation loss: 2.676756628731894

Epoch: 6| Step: 13
Training loss: 2.854001692484706
Validation loss: 2.6848574861278323

Epoch: 33| Step: 0
Training loss: 2.1153788706561425
Validation loss: 2.690838342239072

Epoch: 6| Step: 1
Training loss: 2.994314209845098
Validation loss: 2.690874370410566

Epoch: 6| Step: 2
Training loss: 2.7518311386199765
Validation loss: 2.6948856652462574

Epoch: 6| Step: 3
Training loss: 3.236930979796874
Validation loss: 2.6774744516039273

Epoch: 6| Step: 4
Training loss: 3.1383519083757423
Validation loss: 2.681058950492543

Epoch: 6| Step: 5
Training loss: 3.28749188324249
Validation loss: 2.688449753803512

Epoch: 6| Step: 6
Training loss: 2.9443892187861476
Validation loss: 2.685873658942599

Epoch: 6| Step: 7
Training loss: 3.0831487102049233
Validation loss: 2.6866551869764272

Epoch: 6| Step: 8
Training loss: 2.9648160870333324
Validation loss: 2.6869920640266143

Epoch: 6| Step: 9
Training loss: 3.563858041078922
Validation loss: 2.6768013022066133

Epoch: 6| Step: 10
Training loss: 2.587745979153385
Validation loss: 2.6751565269666338

Epoch: 6| Step: 11
Training loss: 1.963373198900558
Validation loss: 2.6904334265751784

Epoch: 6| Step: 12
Training loss: 3.5323900391134235
Validation loss: 2.691148885502217

Epoch: 6| Step: 13
Training loss: 2.7603305635279063
Validation loss: 2.6983399924756304

Epoch: 34| Step: 0
Training loss: 3.029956974441679
Validation loss: 2.6956800365085276

Epoch: 6| Step: 1
Training loss: 2.520001697236958
Validation loss: 2.668873266850877

Epoch: 6| Step: 2
Training loss: 2.648979559145927
Validation loss: 2.6849577990598723

Epoch: 6| Step: 3
Training loss: 3.778822190392986
Validation loss: 2.6840767775658905

Epoch: 6| Step: 4
Training loss: 3.7149035652551614
Validation loss: 2.6904652523360166

Epoch: 6| Step: 5
Training loss: 3.134973860149523
Validation loss: 2.696477925361779

Epoch: 6| Step: 6
Training loss: 2.546119437449528
Validation loss: 2.6906611287465227

Epoch: 6| Step: 7
Training loss: 3.0231315201678575
Validation loss: 2.690970859816135

Epoch: 6| Step: 8
Training loss: 2.539836964969261
Validation loss: 2.6866908265862697

Epoch: 6| Step: 9
Training loss: 1.8645769328712563
Validation loss: 2.6814462771329084

Epoch: 6| Step: 10
Training loss: 3.600459461561897
Validation loss: 2.686066210934741

Epoch: 6| Step: 11
Training loss: 2.6330066462171033
Validation loss: 2.681598947982972

Epoch: 6| Step: 12
Training loss: 3.1126069567583925
Validation loss: 2.6877281548089362

Epoch: 6| Step: 13
Training loss: 2.431693178397963
Validation loss: 2.703879515743893

Epoch: 35| Step: 0
Training loss: 2.3627978626570263
Validation loss: 2.671682823306352

Epoch: 6| Step: 1
Training loss: 2.5744755664583923
Validation loss: 2.688918676720967

Epoch: 6| Step: 2
Training loss: 2.370152998544868
Validation loss: 2.685244309729124

Epoch: 6| Step: 3
Training loss: 2.937773346864735
Validation loss: 2.677016855490763

Epoch: 6| Step: 4
Training loss: 1.9102851184521925
Validation loss: 2.6827369649254913

Epoch: 6| Step: 5
Training loss: 3.206209214454894
Validation loss: 2.6887816730513094

Epoch: 6| Step: 6
Training loss: 3.148310580665304
Validation loss: 2.681656724898673

Epoch: 6| Step: 7
Training loss: 3.2529412678512726
Validation loss: 2.6769235616832234

Epoch: 6| Step: 8
Training loss: 3.0940639452155025
Validation loss: 2.6958712157605693

Epoch: 6| Step: 9
Training loss: 3.405666756348579
Validation loss: 2.688475996081561

Epoch: 6| Step: 10
Training loss: 3.6788235761807178
Validation loss: 2.6957795235341893

Epoch: 6| Step: 11
Training loss: 2.72160689109791
Validation loss: 2.681309429947811

Epoch: 6| Step: 12
Training loss: 3.1316894649253015
Validation loss: 2.6889687712501718

Epoch: 6| Step: 13
Training loss: 2.8437763254812563
Validation loss: 2.6769230876307533

Epoch: 36| Step: 0
Training loss: 3.2466071098186338
Validation loss: 2.6785660612498865

Epoch: 6| Step: 1
Training loss: 2.83360307942788
Validation loss: 2.6896719735122954

Epoch: 6| Step: 2
Training loss: 2.556160505075916
Validation loss: 2.6766512789359487

Epoch: 6| Step: 3
Training loss: 3.0229827775480382
Validation loss: 2.671662551559622

Epoch: 6| Step: 4
Training loss: 3.407479300600518
Validation loss: 2.687125181525532

Epoch: 6| Step: 5
Training loss: 3.2908617476080817
Validation loss: 2.6704502515622854

Epoch: 6| Step: 6
Training loss: 2.7007292786911807
Validation loss: 2.667406297472185

Epoch: 6| Step: 7
Training loss: 3.475248555686875
Validation loss: 2.661546560762474

Epoch: 6| Step: 8
Training loss: 2.6686497010584262
Validation loss: 2.6638738295767586

Epoch: 6| Step: 9
Training loss: 2.9109162637506203
Validation loss: 2.6762784125507944

Epoch: 6| Step: 10
Training loss: 2.56387887468055
Validation loss: 2.6818304028272015

Epoch: 6| Step: 11
Training loss: 2.9291215273624456
Validation loss: 2.6795785628801867

Epoch: 6| Step: 12
Training loss: 2.9095178095824306
Validation loss: 2.6601660558132445

Epoch: 6| Step: 13
Training loss: 1.833576648634034
Validation loss: 2.6682356447463946

Epoch: 37| Step: 0
Training loss: 1.8668736150102359
Validation loss: 2.670668771977146

Epoch: 6| Step: 1
Training loss: 3.301298960879121
Validation loss: 2.6743473976239076

Epoch: 6| Step: 2
Training loss: 2.7368445879040784
Validation loss: 2.6713459935474915

Epoch: 6| Step: 3
Training loss: 3.4640385703919474
Validation loss: 2.684166789361279

Epoch: 6| Step: 4
Training loss: 3.19747321981828
Validation loss: 2.6721755907349958

Epoch: 6| Step: 5
Training loss: 3.2332755906235207
Validation loss: 2.67546302813948

Epoch: 6| Step: 6
Training loss: 2.687851638854927
Validation loss: 2.6717651590239404

Epoch: 6| Step: 7
Training loss: 2.8303323635479583
Validation loss: 2.6741363564177276

Epoch: 6| Step: 8
Training loss: 2.863644440269365
Validation loss: 2.671931372393669

Epoch: 6| Step: 9
Training loss: 3.3368056014254264
Validation loss: 2.682177321595961

Epoch: 6| Step: 10
Training loss: 2.489069408112618
Validation loss: 2.6627206102533822

Epoch: 6| Step: 11
Training loss: 3.160466012755974
Validation loss: 2.675806296285019

Epoch: 6| Step: 12
Training loss: 3.113184143619674
Validation loss: 2.670559130979179

Epoch: 6| Step: 13
Training loss: 2.0865311938581494
Validation loss: 2.6664028082048405

Epoch: 38| Step: 0
Training loss: 3.4368768300552617
Validation loss: 2.6796707740686707

Epoch: 6| Step: 1
Training loss: 2.5230814679661338
Validation loss: 2.6694994814367057

Epoch: 6| Step: 2
Training loss: 3.011842084405164
Validation loss: 2.676440676099163

Epoch: 6| Step: 3
Training loss: 3.0536033482106224
Validation loss: 2.6824693426026744

Epoch: 6| Step: 4
Training loss: 3.360118978755306
Validation loss: 2.6711318320941424

Epoch: 6| Step: 5
Training loss: 2.78156887326712
Validation loss: 2.668729473274362

Epoch: 6| Step: 6
Training loss: 2.2117732864280284
Validation loss: 2.67276798934868

Epoch: 6| Step: 7
Training loss: 3.3725987121749688
Validation loss: 2.6731172092041326

Epoch: 6| Step: 8
Training loss: 2.4929496532487
Validation loss: 2.6698744467994024

Epoch: 6| Step: 9
Training loss: 2.4472808228528495
Validation loss: 2.685433064395599

Epoch: 6| Step: 10
Training loss: 2.949420522899106
Validation loss: 2.6708419281211073

Epoch: 6| Step: 11
Training loss: 2.8946422807863184
Validation loss: 2.6885587901248615

Epoch: 6| Step: 12
Training loss: 3.2115424484305497
Validation loss: 2.6908551559539187

Epoch: 6| Step: 13
Training loss: 2.8379773246821682
Validation loss: 2.6674139016739953

Epoch: 39| Step: 0
Training loss: 3.6724933509428888
Validation loss: 2.665173644895624

Epoch: 6| Step: 1
Training loss: 2.93110105872228
Validation loss: 2.6771850860271535

Epoch: 6| Step: 2
Training loss: 2.9095255123422126
Validation loss: 2.660375835662893

Epoch: 6| Step: 3
Training loss: 2.340222565263454
Validation loss: 2.666391966755647

Epoch: 6| Step: 4
Training loss: 2.5952572407314167
Validation loss: 2.6710005070731198

Epoch: 6| Step: 5
Training loss: 2.9554755327518487
Validation loss: 2.6721980805036663

Epoch: 6| Step: 6
Training loss: 2.3670027758344743
Validation loss: 2.6621717590852225

Epoch: 6| Step: 7
Training loss: 2.571185488413159
Validation loss: 2.6757378270693484

Epoch: 6| Step: 8
Training loss: 3.567899126209244
Validation loss: 2.662199658158691

Epoch: 6| Step: 9
Training loss: 2.9055483391475434
Validation loss: 2.660789487739492

Epoch: 6| Step: 10
Training loss: 2.8097709130680637
Validation loss: 2.6625378987062005

Epoch: 6| Step: 11
Training loss: 2.987793567231616
Validation loss: 2.665261421018833

Epoch: 6| Step: 12
Training loss: 3.1607710684662718
Validation loss: 2.6659194113370814

Epoch: 6| Step: 13
Training loss: 2.752006925513181
Validation loss: 2.6796995849298604

Epoch: 40| Step: 0
Training loss: 2.362866578095629
Validation loss: 2.6671114920369465

Epoch: 6| Step: 1
Training loss: 3.09102780578211
Validation loss: 2.6746634901804476

Epoch: 6| Step: 2
Training loss: 2.2439521464720986
Validation loss: 2.684971720240897

Epoch: 6| Step: 3
Training loss: 3.200448755746478
Validation loss: 2.673936403797098

Epoch: 6| Step: 4
Training loss: 3.13671875
Validation loss: 2.6695284971446105

Epoch: 6| Step: 5
Training loss: 3.4076339290100726
Validation loss: 2.669862713005162

Epoch: 6| Step: 6
Training loss: 3.750985969625017
Validation loss: 2.6661157112577154

Epoch: 6| Step: 7
Training loss: 2.9985117399676997
Validation loss: 2.677450726944647

Epoch: 6| Step: 8
Training loss: 3.3895008667189157
Validation loss: 2.6773313612772354

Epoch: 6| Step: 9
Training loss: 2.985118992924152
Validation loss: 2.6606965181260094

Epoch: 6| Step: 10
Training loss: 1.887279292964857
Validation loss: 2.6638968556982974

Epoch: 6| Step: 11
Training loss: 2.6963901300496103
Validation loss: 2.676360374123797

Epoch: 6| Step: 12
Training loss: 2.4212484226014883
Validation loss: 2.656097462742301

Epoch: 6| Step: 13
Training loss: 2.501969705924273
Validation loss: 2.6757759737903326

Epoch: 41| Step: 0
Training loss: 2.593099673449301
Validation loss: 2.6649706687329737

Epoch: 6| Step: 1
Training loss: 3.477024964851586
Validation loss: 2.6629381904476244

Epoch: 6| Step: 2
Training loss: 3.0916198178535037
Validation loss: 2.648657522918348

Epoch: 6| Step: 3
Training loss: 3.4300256097577098
Validation loss: 2.674314630414559

Epoch: 6| Step: 4
Training loss: 2.772918136752967
Validation loss: 2.6699690680751313

Epoch: 6| Step: 5
Training loss: 2.6378931665485963
Validation loss: 2.658791859335133

Epoch: 6| Step: 6
Training loss: 2.124513794870136
Validation loss: 2.655084064315286

Epoch: 6| Step: 7
Training loss: 4.094200051299227
Validation loss: 2.675964278310317

Epoch: 6| Step: 8
Training loss: 2.2726221883928566
Validation loss: 2.6732018397805897

Epoch: 6| Step: 9
Training loss: 2.106280961077964
Validation loss: 2.6519221112175635

Epoch: 6| Step: 10
Training loss: 3.117851626366798
Validation loss: 2.666299953036307

Epoch: 6| Step: 11
Training loss: 2.5241015242638833
Validation loss: 2.674589614432011

Epoch: 6| Step: 12
Training loss: 3.417182108138322
Validation loss: 2.6578604394027794

Epoch: 6| Step: 13
Training loss: 1.6179640375250135
Validation loss: 2.6746033997934746

Epoch: 42| Step: 0
Training loss: 3.057480259829261
Validation loss: 2.671279699864205

Epoch: 6| Step: 1
Training loss: 3.0507710904820433
Validation loss: 2.6517742352078697

Epoch: 6| Step: 2
Training loss: 2.650041842580139
Validation loss: 2.676891308685534

Epoch: 6| Step: 3
Training loss: 2.5315313300631996
Validation loss: 2.65190636442541

Epoch: 6| Step: 4
Training loss: 3.3456830293015134
Validation loss: 2.6627072048138087

Epoch: 6| Step: 5
Training loss: 2.8273901221717
Validation loss: 2.6647215617898015

Epoch: 6| Step: 6
Training loss: 2.2700541381429864
Validation loss: 2.6684138825541064

Epoch: 6| Step: 7
Training loss: 3.2276650824017157
Validation loss: 2.6562822835795363

Epoch: 6| Step: 8
Training loss: 2.8716567129832353
Validation loss: 2.6507468771749974

Epoch: 6| Step: 9
Training loss: 2.619357083768381
Validation loss: 2.6697159574838807

Epoch: 6| Step: 10
Training loss: 3.1434592747732877
Validation loss: 2.6622761440228926

Epoch: 6| Step: 11
Training loss: 3.08374007008117
Validation loss: 2.669028104385114

Epoch: 6| Step: 12
Training loss: 2.6898623884376853
Validation loss: 2.646420912982006

Epoch: 6| Step: 13
Training loss: 3.5293842889613876
Validation loss: 2.6610930589707893

Epoch: 43| Step: 0
Training loss: 2.648317947615081
Validation loss: 2.6692991805153343

Epoch: 6| Step: 1
Training loss: 3.3482490290701117
Validation loss: 2.6501798825652916

Epoch: 6| Step: 2
Training loss: 2.738233013517279
Validation loss: 2.651895124393244

Epoch: 6| Step: 3
Training loss: 2.9761571733337173
Validation loss: 2.6688659809145214

Epoch: 6| Step: 4
Training loss: 2.1220699754443473
Validation loss: 2.6588491850135956

Epoch: 6| Step: 5
Training loss: 2.1589463555163464
Validation loss: 2.670314089885144

Epoch: 6| Step: 6
Training loss: 2.993748190606512
Validation loss: 2.6732580077394497

Epoch: 6| Step: 7
Training loss: 3.1548304623183285
Validation loss: 2.6635091835692686

Epoch: 6| Step: 8
Training loss: 3.3225549642524372
Validation loss: 2.6691592498354866

Epoch: 6| Step: 9
Training loss: 3.003822752110822
Validation loss: 2.6697302932742417

Epoch: 6| Step: 10
Training loss: 2.3340984747541937
Validation loss: 2.662944836998011

Epoch: 6| Step: 11
Training loss: 3.6485989063182886
Validation loss: 2.6529488730544424

Epoch: 6| Step: 12
Training loss: 3.0560268578073146
Validation loss: 2.6615078007227804

Epoch: 6| Step: 13
Training loss: 2.572343852621217
Validation loss: 2.6654087016931167

Epoch: 44| Step: 0
Training loss: 2.1700316366183605
Validation loss: 2.6629031147938225

Epoch: 6| Step: 1
Training loss: 1.9368214188014978
Validation loss: 2.670428414281499

Epoch: 6| Step: 2
Training loss: 2.9378608319669213
Validation loss: 2.6806365396956195

Epoch: 6| Step: 3
Training loss: 3.232864100697569
Validation loss: 2.6563370228940535

Epoch: 6| Step: 4
Training loss: 3.1823073333171457
Validation loss: 2.6580577665723757

Epoch: 6| Step: 5
Training loss: 3.331690637814909
Validation loss: 2.6510962572856878

Epoch: 6| Step: 6
Training loss: 3.4313674322993064
Validation loss: 2.662990239887046

Epoch: 6| Step: 7
Training loss: 3.4971397156527644
Validation loss: 2.6484836200833275

Epoch: 6| Step: 8
Training loss: 3.4338277448442587
Validation loss: 2.6437194279032

Epoch: 6| Step: 9
Training loss: 2.7943458416705202
Validation loss: 2.6581362662799917

Epoch: 6| Step: 10
Training loss: 2.32722855276752
Validation loss: 2.662670764707087

Epoch: 6| Step: 11
Training loss: 2.151404201693048
Validation loss: 2.6629465352159296

Epoch: 6| Step: 12
Training loss: 2.6574671929703793
Validation loss: 2.6635840249736638

Epoch: 6| Step: 13
Training loss: 2.9576329938018664
Validation loss: 2.6619394862514802

Epoch: 45| Step: 0
Training loss: 2.862366992242401
Validation loss: 2.6681464416284815

Epoch: 6| Step: 1
Training loss: 3.284038412485112
Validation loss: 2.664100139331456

Epoch: 6| Step: 2
Training loss: 3.0386678640484037
Validation loss: 2.6606538029090823

Epoch: 6| Step: 3
Training loss: 3.19614360418906
Validation loss: 2.6659831650326598

Epoch: 6| Step: 4
Training loss: 2.2786765018397457
Validation loss: 2.6562377774984647

Epoch: 6| Step: 5
Training loss: 3.60479445677025
Validation loss: 2.6755424055785486

Epoch: 6| Step: 6
Training loss: 3.1488306448476457
Validation loss: 2.6725686902343417

Epoch: 6| Step: 7
Training loss: 2.799542566808732
Validation loss: 2.672317716713037

Epoch: 6| Step: 8
Training loss: 2.288002888584314
Validation loss: 2.6689035496211964

Epoch: 6| Step: 9
Training loss: 2.813780937956806
Validation loss: 2.664521178792445

Epoch: 6| Step: 10
Training loss: 2.9046188206835746
Validation loss: 2.655177325067323

Epoch: 6| Step: 11
Training loss: 3.2270525174591524
Validation loss: 2.668466281528639

Epoch: 6| Step: 12
Training loss: 1.8365519043410854
Validation loss: 2.6708163966201695

Epoch: 6| Step: 13
Training loss: 2.6821946407411064
Validation loss: 2.6577115095964374

Epoch: 46| Step: 0
Training loss: 2.8891114267401674
Validation loss: 2.6636325651769694

Epoch: 6| Step: 1
Training loss: 3.131210259891595
Validation loss: 2.6522707816975157

Epoch: 6| Step: 2
Training loss: 2.828913289008434
Validation loss: 2.654451859699159

Epoch: 6| Step: 3
Training loss: 3.0194475525067275
Validation loss: 2.664747927105059

Epoch: 6| Step: 4
Training loss: 2.7594891603384477
Validation loss: 2.65323870591188

Epoch: 6| Step: 5
Training loss: 2.432404302457302
Validation loss: 2.6553587883634986

Epoch: 6| Step: 6
Training loss: 2.127307984846138
Validation loss: 2.645484477570324

Epoch: 6| Step: 7
Training loss: 2.5354205024667236
Validation loss: 2.656763226742455

Epoch: 6| Step: 8
Training loss: 2.8070807911519395
Validation loss: 2.6672742315572626

Epoch: 6| Step: 9
Training loss: 3.2508017211357507
Validation loss: 2.6411309914893604

Epoch: 6| Step: 10
Training loss: 2.659185246333246
Validation loss: 2.663762607715263

Epoch: 6| Step: 11
Training loss: 3.3617440320482044
Validation loss: 2.652489957003028

Epoch: 6| Step: 12
Training loss: 3.48438594799289
Validation loss: 2.6608024350692983

Epoch: 6| Step: 13
Training loss: 2.8835019990250306
Validation loss: 2.6539113558579985

Epoch: 47| Step: 0
Training loss: 2.805228433538177
Validation loss: 2.662598439515675

Epoch: 6| Step: 1
Training loss: 2.447462605238439
Validation loss: 2.6575269613149617

Epoch: 6| Step: 2
Training loss: 2.90560741909105
Validation loss: 2.658092778854874

Epoch: 6| Step: 3
Training loss: 2.626103487135738
Validation loss: 2.6571502183144617

Epoch: 6| Step: 4
Training loss: 3.2332888636201917
Validation loss: 2.6536789130779286

Epoch: 6| Step: 5
Training loss: 3.2984339205796096
Validation loss: 2.6467511754910586

Epoch: 6| Step: 6
Training loss: 2.6574203605597075
Validation loss: 2.6480641229056414

Epoch: 6| Step: 7
Training loss: 2.5038219800744725
Validation loss: 2.6471801671388127

Epoch: 6| Step: 8
Training loss: 2.866160195728446
Validation loss: 2.663194197728839

Epoch: 6| Step: 9
Training loss: 3.28212675460976
Validation loss: 2.648482147807471

Epoch: 6| Step: 10
Training loss: 2.787885743551536
Validation loss: 2.6512724854108636

Epoch: 6| Step: 11
Training loss: 3.197999454052123
Validation loss: 2.6629013713001575

Epoch: 6| Step: 12
Training loss: 2.5848008161354015
Validation loss: 2.647725651785715

Epoch: 6| Step: 13
Training loss: 3.084866494824947
Validation loss: 2.6447024261597445

Epoch: 48| Step: 0
Training loss: 2.9922751471130247
Validation loss: 2.656976843356969

Epoch: 6| Step: 1
Training loss: 3.2411910766471195
Validation loss: 2.643504511112145

Epoch: 6| Step: 2
Training loss: 3.0178764516772203
Validation loss: 2.655703208086686

Epoch: 6| Step: 3
Training loss: 2.5480315969834586
Validation loss: 2.6424305158098544

Epoch: 6| Step: 4
Training loss: 2.9793758363364478
Validation loss: 2.6447346975421397

Epoch: 6| Step: 5
Training loss: 2.955130083089981
Validation loss: 2.660006843483765

Epoch: 6| Step: 6
Training loss: 2.4388972459194678
Validation loss: 2.663981421683966

Epoch: 6| Step: 7
Training loss: 2.77595925462266
Validation loss: 2.643645289640388

Epoch: 6| Step: 8
Training loss: 2.709295209613916
Validation loss: 2.647032586980483

Epoch: 6| Step: 9
Training loss: 1.8558687120321977
Validation loss: 2.6615142389354647

Epoch: 6| Step: 10
Training loss: 3.2532467396994704
Validation loss: 2.6511509160816824

Epoch: 6| Step: 11
Training loss: 2.6201080879454364
Validation loss: 2.652866203633848

Epoch: 6| Step: 12
Training loss: 3.517939776140957
Validation loss: 2.6661390261957854

Epoch: 6| Step: 13
Training loss: 2.9688882895936697
Validation loss: 2.662924822205227

Epoch: 49| Step: 0
Training loss: 3.6080840473239686
Validation loss: 2.6507792113353643

Epoch: 6| Step: 1
Training loss: 1.9180066635207018
Validation loss: 2.651921736133909

Epoch: 6| Step: 2
Training loss: 2.217827188637489
Validation loss: 2.6572270487493777

Epoch: 6| Step: 3
Training loss: 3.171970159296472
Validation loss: 2.6643758254006045

Epoch: 6| Step: 4
Training loss: 2.1854899299300565
Validation loss: 2.6520742409668854

Epoch: 6| Step: 5
Training loss: 2.4762380489733022
Validation loss: 2.6610356554259056

Epoch: 6| Step: 6
Training loss: 2.470293938448213
Validation loss: 2.649784184368967

Epoch: 6| Step: 7
Training loss: 3.186961259379634
Validation loss: 2.6628917122668105

Epoch: 6| Step: 8
Training loss: 2.5067235180650673
Validation loss: 2.6506108107679838

Epoch: 6| Step: 9
Training loss: 2.218913649850292
Validation loss: 2.6573292266794377

Epoch: 6| Step: 10
Training loss: 2.9449941933644275
Validation loss: 2.665761964006734

Epoch: 6| Step: 11
Training loss: 3.28165077305076
Validation loss: 2.64741739673088

Epoch: 6| Step: 12
Training loss: 3.8790894126096793
Validation loss: 2.6658107742122183

Epoch: 6| Step: 13
Training loss: 3.7955675424981608
Validation loss: 2.667442323051322

Epoch: 50| Step: 0
Training loss: 2.5409690858535985
Validation loss: 2.6536992091732396

Epoch: 6| Step: 1
Training loss: 2.480962460862367
Validation loss: 2.651560327080874

Epoch: 6| Step: 2
Training loss: 3.25681675758033
Validation loss: 2.6626000320428393

Epoch: 6| Step: 3
Training loss: 3.0934862737281748
Validation loss: 2.657395225880232

Epoch: 6| Step: 4
Training loss: 2.6783611251379806
Validation loss: 2.6515959665815307

Epoch: 6| Step: 5
Training loss: 1.8546668960210977
Validation loss: 2.656857651099704

Epoch: 6| Step: 6
Training loss: 3.287564985554008
Validation loss: 2.656882154991996

Epoch: 6| Step: 7
Training loss: 3.3064672849390284
Validation loss: 2.6565113969290803

Epoch: 6| Step: 8
Training loss: 2.4493966897333634
Validation loss: 2.6504789264814765

Epoch: 6| Step: 9
Training loss: 3.5899776396413667
Validation loss: 2.6465766688732217

Epoch: 6| Step: 10
Training loss: 3.086949744979232
Validation loss: 2.6494180278263757

Epoch: 6| Step: 11
Training loss: 2.940608875258826
Validation loss: 2.6540275160040676

Epoch: 6| Step: 12
Training loss: 2.0983160533400564
Validation loss: 2.639169451902558

Epoch: 6| Step: 13
Training loss: 3.004711107785166
Validation loss: 2.661682799171594

Epoch: 51| Step: 0
Training loss: 2.6487594903881218
Validation loss: 2.648722586420398

Epoch: 6| Step: 1
Training loss: 3.5857816508548623
Validation loss: 2.6555994152759976

Epoch: 6| Step: 2
Training loss: 2.4082728218827576
Validation loss: 2.6537470877899705

Epoch: 6| Step: 3
Training loss: 1.6639526044349666
Validation loss: 2.644605212201945

Epoch: 6| Step: 4
Training loss: 3.3642267721263965
Validation loss: 2.658247806488524

Epoch: 6| Step: 5
Training loss: 3.492934588711278
Validation loss: 2.642205674141744

Epoch: 6| Step: 6
Training loss: 2.6550174321753577
Validation loss: 2.6384093033575167

Epoch: 6| Step: 7
Training loss: 2.7210764084602093
Validation loss: 2.652232821766648

Epoch: 6| Step: 8
Training loss: 2.9762917543163545
Validation loss: 2.651371138302394

Epoch: 6| Step: 9
Training loss: 3.196860239362154
Validation loss: 2.6445406886642258

Epoch: 6| Step: 10
Training loss: 1.6620717924107373
Validation loss: 2.645064231420959

Epoch: 6| Step: 11
Training loss: 2.822727004620664
Validation loss: 2.6359199459394627

Epoch: 6| Step: 12
Training loss: 2.4154833713875887
Validation loss: 2.6581843301965264

Epoch: 6| Step: 13
Training loss: 4.132852651476745
Validation loss: 2.642081420978889

Epoch: 52| Step: 0
Training loss: 2.451046494396647
Validation loss: 2.653135660723259

Epoch: 6| Step: 1
Training loss: 2.7122038156559496
Validation loss: 2.6543335749427768

Epoch: 6| Step: 2
Training loss: 2.9815537463904196
Validation loss: 2.6437631682412692

Epoch: 6| Step: 3
Training loss: 3.5806075233835992
Validation loss: 2.6388197148411456

Epoch: 6| Step: 4
Training loss: 2.8273130484245113
Validation loss: 2.648376370243985

Epoch: 6| Step: 5
Training loss: 2.6600780951716643
Validation loss: 2.64486897937112

Epoch: 6| Step: 6
Training loss: 3.1735671467220317
Validation loss: 2.6572974709983868

Epoch: 6| Step: 7
Training loss: 2.7471400908752437
Validation loss: 2.6534195133968237

Epoch: 6| Step: 8
Training loss: 2.71588624108106
Validation loss: 2.6410407127274054

Epoch: 6| Step: 9
Training loss: 3.4416559239205227
Validation loss: 2.6492626789696776

Epoch: 6| Step: 10
Training loss: 2.854611457267074
Validation loss: 2.6402621727767626

Epoch: 6| Step: 11
Training loss: 2.031849464577556
Validation loss: 2.642866651689999

Epoch: 6| Step: 12
Training loss: 2.8988629052075705
Validation loss: 2.645237913242481

Epoch: 6| Step: 13
Training loss: 2.5759197629433395
Validation loss: 2.6401601082282173

Epoch: 53| Step: 0
Training loss: 3.30313802696698
Validation loss: 2.6660800879617224

Epoch: 6| Step: 1
Training loss: 2.1349849605700624
Validation loss: 2.6420143813421633

Epoch: 6| Step: 2
Training loss: 2.957625738777838
Validation loss: 2.6413641405640824

Epoch: 6| Step: 3
Training loss: 3.1993880640483425
Validation loss: 2.64074826837202

Epoch: 6| Step: 4
Training loss: 3.0178710795295967
Validation loss: 2.6417553259066486

Epoch: 6| Step: 5
Training loss: 3.5248546922102038
Validation loss: 2.644904744899379

Epoch: 6| Step: 6
Training loss: 2.9661627487937245
Validation loss: 2.6541154936460782

Epoch: 6| Step: 7
Training loss: 2.794789138510337
Validation loss: 2.6479143681204014

Epoch: 6| Step: 8
Training loss: 2.414816531839694
Validation loss: 2.6599950661614638

Epoch: 6| Step: 9
Training loss: 2.628448310406217
Validation loss: 2.6595009624339716

Epoch: 6| Step: 10
Training loss: 2.3632741880705437
Validation loss: 2.6583512451584754

Epoch: 6| Step: 11
Training loss: 3.216638705934218
Validation loss: 2.6608699089269057

Epoch: 6| Step: 12
Training loss: 2.33272676303955
Validation loss: 2.650424628155589

Epoch: 6| Step: 13
Training loss: 2.9465512369887117
Validation loss: 2.6442825453209986

Epoch: 54| Step: 0
Training loss: 2.9382871831110333
Validation loss: 2.649699898171381

Epoch: 6| Step: 1
Training loss: 2.9576455691346912
Validation loss: 2.6547590912986645

Epoch: 6| Step: 2
Training loss: 2.0184606669564538
Validation loss: 2.6503110543247517

Epoch: 6| Step: 3
Training loss: 3.2692900173290265
Validation loss: 2.652701054214685

Epoch: 6| Step: 4
Training loss: 3.0970010341091974
Validation loss: 2.6427192982245007

Epoch: 6| Step: 5
Training loss: 2.17642175092017
Validation loss: 2.6585976251092736

Epoch: 6| Step: 6
Training loss: 2.9205275095679317
Validation loss: 2.647544856332457

Epoch: 6| Step: 7
Training loss: 3.2858636300875643
Validation loss: 2.637844887435969

Epoch: 6| Step: 8
Training loss: 2.4059925684762593
Validation loss: 2.6629630687163264

Epoch: 6| Step: 9
Training loss: 3.1616343282179566
Validation loss: 2.647897539274398

Epoch: 6| Step: 10
Training loss: 3.515580240600488
Validation loss: 2.644775301810813

Epoch: 6| Step: 11
Training loss: 2.3844386820957078
Validation loss: 2.6489707818123365

Epoch: 6| Step: 12
Training loss: 2.9415707890462564
Validation loss: 2.6498563542965123

Epoch: 6| Step: 13
Training loss: 2.2213650189246805
Validation loss: 2.6425648429358617

Epoch: 55| Step: 0
Training loss: 2.908273956071617
Validation loss: 2.6596064884070882

Epoch: 6| Step: 1
Training loss: 2.6673529655740245
Validation loss: 2.6518254084482638

Epoch: 6| Step: 2
Training loss: 2.9479859864045483
Validation loss: 2.6484190017935534

Epoch: 6| Step: 3
Training loss: 3.01874250644046
Validation loss: 2.659355967039653

Epoch: 6| Step: 4
Training loss: 2.7485835155326663
Validation loss: 2.6357535411569804

Epoch: 6| Step: 5
Training loss: 3.203953184664452
Validation loss: 2.6477365435237523

Epoch: 6| Step: 6
Training loss: 2.533217807277228
Validation loss: 2.6549387321033073

Epoch: 6| Step: 7
Training loss: 3.481967521976143
Validation loss: 2.651536567792207

Epoch: 6| Step: 8
Training loss: 2.342805595860988
Validation loss: 2.6321042452167682

Epoch: 6| Step: 9
Training loss: 2.5322822067437634
Validation loss: 2.6492438884772147

Epoch: 6| Step: 10
Training loss: 2.343977039784543
Validation loss: 2.6609220566297602

Epoch: 6| Step: 11
Training loss: 2.917592873423026
Validation loss: 2.6494501304954072

Epoch: 6| Step: 12
Training loss: 3.6301723279585874
Validation loss: 2.63108828378465

Epoch: 6| Step: 13
Training loss: 1.8813285836570546
Validation loss: 2.6392137465316456

Epoch: 56| Step: 0
Training loss: 2.861823029405512
Validation loss: 2.6602645359764656

Epoch: 6| Step: 1
Training loss: 1.8634482254930018
Validation loss: 2.649494524177554

Epoch: 6| Step: 2
Training loss: 3.2202186567097404
Validation loss: 2.6424629119553096

Epoch: 6| Step: 3
Training loss: 3.167782854489209
Validation loss: 2.643195628962674

Epoch: 6| Step: 4
Training loss: 2.4632817804037748
Validation loss: 2.640228093115786

Epoch: 6| Step: 5
Training loss: 3.5602908060689784
Validation loss: 2.6429625396041065

Epoch: 6| Step: 6
Training loss: 2.7497812530908443
Validation loss: 2.6369412654079905

Epoch: 6| Step: 7
Training loss: 2.9499882584677612
Validation loss: 2.645673267527922

Epoch: 6| Step: 8
Training loss: 2.691764553010533
Validation loss: 2.6521277312445743

Epoch: 6| Step: 9
Training loss: 2.71852540590259
Validation loss: 2.6408898956794338

Epoch: 6| Step: 10
Training loss: 1.8149106667342356
Validation loss: 2.648468043537523

Epoch: 6| Step: 11
Training loss: 3.411145533230289
Validation loss: 2.6373566343643566

Epoch: 6| Step: 12
Training loss: 3.3056151618890457
Validation loss: 2.645823833231156

Epoch: 6| Step: 13
Training loss: 2.2586389632764825
Validation loss: 2.649070262201966

Epoch: 57| Step: 0
Training loss: 3.128659661299886
Validation loss: 2.645618734909432

Epoch: 6| Step: 1
Training loss: 2.8092829637228913
Validation loss: 2.663726383193713

Epoch: 6| Step: 2
Training loss: 2.579615121862352
Validation loss: 2.6562674901242898

Epoch: 6| Step: 3
Training loss: 2.649247217320695
Validation loss: 2.6425149669326777

Epoch: 6| Step: 4
Training loss: 3.1284231129605944
Validation loss: 2.656271974109575

Epoch: 6| Step: 5
Training loss: 1.9832350693196819
Validation loss: 2.640095422160056

Epoch: 6| Step: 6
Training loss: 2.9232049047198227
Validation loss: 2.6591068098899524

Epoch: 6| Step: 7
Training loss: 3.022309953064473
Validation loss: 2.6360336642422975

Epoch: 6| Step: 8
Training loss: 3.5018629837987385
Validation loss: 2.6446510957043268

Epoch: 6| Step: 9
Training loss: 2.424374183050826
Validation loss: 2.6579227679257476

Epoch: 6| Step: 10
Training loss: 3.624116592628517
Validation loss: 2.6394164413147605

Epoch: 6| Step: 11
Training loss: 2.4433195627751694
Validation loss: 2.6467893128347155

Epoch: 6| Step: 12
Training loss: 2.790182364324989
Validation loss: 2.6411567468605144

Epoch: 6| Step: 13
Training loss: 1.937475142780945
Validation loss: 2.639493486853532

Epoch: 58| Step: 0
Training loss: 2.7419026544766276
Validation loss: 2.638240505787428

Epoch: 6| Step: 1
Training loss: 2.4635414516026817
Validation loss: 2.656624253103343

Epoch: 6| Step: 2
Training loss: 3.0479717139285745
Validation loss: 2.638025065862666

Epoch: 6| Step: 3
Training loss: 3.0317404438735442
Validation loss: 2.6326117312582116

Epoch: 6| Step: 4
Training loss: 3.337145691541972
Validation loss: 2.6450452773497113

Epoch: 6| Step: 5
Training loss: 3.0352443844286356
Validation loss: 2.6611491202827238

Epoch: 6| Step: 6
Training loss: 2.3229194150717403
Validation loss: 2.6672530689550924

Epoch: 6| Step: 7
Training loss: 3.089771679834661
Validation loss: 2.655819041780767

Epoch: 6| Step: 8
Training loss: 2.625875508671772
Validation loss: 2.6663323226133464

Epoch: 6| Step: 9
Training loss: 3.549658401602386
Validation loss: 2.6376992730892677

Epoch: 6| Step: 10
Training loss: 2.5754065775944954
Validation loss: 2.6436494381719915

Epoch: 6| Step: 11
Training loss: 3.0002673347887177
Validation loss: 2.6513492908522287

Epoch: 6| Step: 12
Training loss: 2.3105855698299926
Validation loss: 2.6445641535813538

Epoch: 6| Step: 13
Training loss: 1.9115920336233057
Validation loss: 2.6533938181185306

Epoch: 59| Step: 0
Training loss: 2.919289653807019
Validation loss: 2.6486474315539676

Epoch: 6| Step: 1
Training loss: 2.9920051857806467
Validation loss: 2.6450179819303417

Epoch: 6| Step: 2
Training loss: 3.192834616191784
Validation loss: 2.64308303840475

Epoch: 6| Step: 3
Training loss: 2.0899981004989243
Validation loss: 2.6430231417885537

Epoch: 6| Step: 4
Training loss: 2.9991972167068552
Validation loss: 2.644468499209225

Epoch: 6| Step: 5
Training loss: 2.742840376728904
Validation loss: 2.644266392377297

Epoch: 6| Step: 6
Training loss: 2.4033824132950903
Validation loss: 2.6401119249485774

Epoch: 6| Step: 7
Training loss: 3.2648602187888502
Validation loss: 2.6430130444308833

Epoch: 6| Step: 8
Training loss: 3.3856541633441433
Validation loss: 2.6456961385865365

Epoch: 6| Step: 9
Training loss: 2.8413431231388095
Validation loss: 2.650306524947902

Epoch: 6| Step: 10
Training loss: 3.2411245786834386
Validation loss: 2.6402435561197874

Epoch: 6| Step: 11
Training loss: 2.4898776169081436
Validation loss: 2.6552744107140014

Epoch: 6| Step: 12
Training loss: 2.3217019182182077
Validation loss: 2.6324224505969473

Epoch: 6| Step: 13
Training loss: 2.1703304589381944
Validation loss: 2.6506947343310876

Epoch: 60| Step: 0
Training loss: 2.2605557259768188
Validation loss: 2.6452777645195034

Epoch: 6| Step: 1
Training loss: 2.9486511896969057
Validation loss: 2.6242024430371296

Epoch: 6| Step: 2
Training loss: 3.8737633485370204
Validation loss: 2.6457408365313224

Epoch: 6| Step: 3
Training loss: 2.066657528805784
Validation loss: 2.6280651762350904

Epoch: 6| Step: 4
Training loss: 2.0320454140491795
Validation loss: 2.628002005932703

Epoch: 6| Step: 5
Training loss: 3.301820056580182
Validation loss: 2.649427638251135

Epoch: 6| Step: 6
Training loss: 3.811290486572057
Validation loss: 2.6432736874600478

Epoch: 6| Step: 7
Training loss: 2.7647139778305143
Validation loss: 2.6437112745706357

Epoch: 6| Step: 8
Training loss: 2.6991505593548184
Validation loss: 2.641930755525511

Epoch: 6| Step: 9
Training loss: 2.7827969652927833
Validation loss: 2.647049543355221

Epoch: 6| Step: 10
Training loss: 2.2759257853765775
Validation loss: 2.642841648266703

Epoch: 6| Step: 11
Training loss: 2.419085957854842
Validation loss: 2.6448591449534424

Epoch: 6| Step: 12
Training loss: 2.754624899305977
Validation loss: 2.63808133265548

Epoch: 6| Step: 13
Training loss: 3.1107211625478497
Validation loss: 2.647122607158711

Epoch: 61| Step: 0
Training loss: 1.7936194741213611
Validation loss: 2.6455057988044657

Epoch: 6| Step: 1
Training loss: 2.3732582531886672
Validation loss: 2.645724398891536

Epoch: 6| Step: 2
Training loss: 2.174761932322771
Validation loss: 2.6386540370105136

Epoch: 6| Step: 3
Training loss: 3.4774471914640754
Validation loss: 2.637046607267474

Epoch: 6| Step: 4
Training loss: 2.873792975437484
Validation loss: 2.652642741330685

Epoch: 6| Step: 5
Training loss: 2.445265504428097
Validation loss: 2.627638359159971

Epoch: 6| Step: 6
Training loss: 2.697699421466206
Validation loss: 2.6450330583179915

Epoch: 6| Step: 7
Training loss: 3.0341765443940916
Validation loss: 2.6420314475497464

Epoch: 6| Step: 8
Training loss: 3.2150439806076077
Validation loss: 2.6275477890177674

Epoch: 6| Step: 9
Training loss: 2.0572587666516546
Validation loss: 2.6453614415251616

Epoch: 6| Step: 10
Training loss: 2.667368518338265
Validation loss: 2.649445862353946

Epoch: 6| Step: 11
Training loss: 3.8146932578103945
Validation loss: 2.6315468229228536

Epoch: 6| Step: 12
Training loss: 2.985828305438152
Validation loss: 2.6303509358716157

Epoch: 6| Step: 13
Training loss: 3.3350385754597633
Validation loss: 2.6456270761656797

Epoch: 62| Step: 0
Training loss: 2.951568193162604
Validation loss: 2.626922340089172

Epoch: 6| Step: 1
Training loss: 3.111108344697479
Validation loss: 2.650639085409552

Epoch: 6| Step: 2
Training loss: 3.567840454922247
Validation loss: 2.654433408234541

Epoch: 6| Step: 3
Training loss: 3.316341547789775
Validation loss: 2.6333300775336745

Epoch: 6| Step: 4
Training loss: 3.1257489642034977
Validation loss: 2.6262834422315633

Epoch: 6| Step: 5
Training loss: 1.8138818406102302
Validation loss: 2.643070185655077

Epoch: 6| Step: 6
Training loss: 3.2109516078518388
Validation loss: 2.63937372748944

Epoch: 6| Step: 7
Training loss: 2.7097163459439946
Validation loss: 2.652443115967317

Epoch: 6| Step: 8
Training loss: 1.9384310546452976
Validation loss: 2.6248616710961934

Epoch: 6| Step: 9
Training loss: 2.8333594003114055
Validation loss: 2.6293332663785898

Epoch: 6| Step: 10
Training loss: 2.9140688816849525
Validation loss: 2.646414399301298

Epoch: 6| Step: 11
Training loss: 3.0035189017978614
Validation loss: 2.619067808855036

Epoch: 6| Step: 12
Training loss: 1.6473708475802884
Validation loss: 2.638832961351369

Epoch: 6| Step: 13
Training loss: 2.5639948322821327
Validation loss: 2.6348967789436926

Epoch: 63| Step: 0
Training loss: 2.888299945154788
Validation loss: 2.622828419867557

Epoch: 6| Step: 1
Training loss: 2.55859263179842
Validation loss: 2.625756929552975

Epoch: 6| Step: 2
Training loss: 2.9077266100333934
Validation loss: 2.6475094721606274

Epoch: 6| Step: 3
Training loss: 2.2289173188788753
Validation loss: 2.634721767398909

Epoch: 6| Step: 4
Training loss: 2.9897088922768185
Validation loss: 2.6310798837695937

Epoch: 6| Step: 5
Training loss: 2.5965007305706194
Validation loss: 2.6394591214255025

Epoch: 6| Step: 6
Training loss: 2.0773628386057683
Validation loss: 2.628735861127571

Epoch: 6| Step: 7
Training loss: 3.301859048793662
Validation loss: 2.621883839745569

Epoch: 6| Step: 8
Training loss: 2.800806532230948
Validation loss: 2.652611656322797

Epoch: 6| Step: 9
Training loss: 2.806516258335373
Validation loss: 2.644421890296808

Epoch: 6| Step: 10
Training loss: 2.9996833634171653
Validation loss: 2.635668570886144

Epoch: 6| Step: 11
Training loss: 3.4341560050973503
Validation loss: 2.6431047184880616

Epoch: 6| Step: 12
Training loss: 2.7102521310331134
Validation loss: 2.6407158220670364

Epoch: 6| Step: 13
Training loss: 2.990562216678692
Validation loss: 2.626717367990236

Epoch: 64| Step: 0
Training loss: 3.579489368698418
Validation loss: 2.6487254145587524

Epoch: 6| Step: 1
Training loss: 3.2552944487307154
Validation loss: 2.6452829998007257

Epoch: 6| Step: 2
Training loss: 3.0442387057333975
Validation loss: 2.648151122439715

Epoch: 6| Step: 3
Training loss: 3.147702720603927
Validation loss: 2.6365467890818506

Epoch: 6| Step: 4
Training loss: 2.684864348637964
Validation loss: 2.63850071276921

Epoch: 6| Step: 5
Training loss: 2.5289192300722068
Validation loss: 2.6387591501915955

Epoch: 6| Step: 6
Training loss: 2.5650817147190526
Validation loss: 2.639193614909157

Epoch: 6| Step: 7
Training loss: 2.1296029447029325
Validation loss: 2.632254967650243

Epoch: 6| Step: 8
Training loss: 2.303293821858073
Validation loss: 2.624681517915411

Epoch: 6| Step: 9
Training loss: 2.5368676661469736
Validation loss: 2.635579159913748

Epoch: 6| Step: 10
Training loss: 2.82779147884478
Validation loss: 2.6258848420772734

Epoch: 6| Step: 11
Training loss: 2.666326461389538
Validation loss: 2.635033940871895

Epoch: 6| Step: 12
Training loss: 2.668391137038082
Validation loss: 2.6318821497921525

Epoch: 6| Step: 13
Training loss: 3.3071233911832985
Validation loss: 2.6340117504585856

Epoch: 65| Step: 0
Training loss: 2.772913493769144
Validation loss: 2.645927839954726

Epoch: 6| Step: 1
Training loss: 2.5135922008060745
Validation loss: 2.638445648104095

Epoch: 6| Step: 2
Training loss: 2.8518691642679785
Validation loss: 2.626959684008243

Epoch: 6| Step: 3
Training loss: 2.482631047257945
Validation loss: 2.640776847623282

Epoch: 6| Step: 4
Training loss: 3.0613220440637576
Validation loss: 2.633732300052021

Epoch: 6| Step: 5
Training loss: 3.1250900255587326
Validation loss: 2.637931771126332

Epoch: 6| Step: 6
Training loss: 2.689386725731495
Validation loss: 2.6339424936016544

Epoch: 6| Step: 7
Training loss: 2.4250829308870423
Validation loss: 2.644830690266366

Epoch: 6| Step: 8
Training loss: 2.97057118019358
Validation loss: 2.627655433369221

Epoch: 6| Step: 9
Training loss: 2.430880826953192
Validation loss: 2.630429549992792

Epoch: 6| Step: 10
Training loss: 2.597315440372165
Validation loss: 2.63027313714661

Epoch: 6| Step: 11
Training loss: 3.527339424139097
Validation loss: 2.632327916187712

Epoch: 6| Step: 12
Training loss: 3.118905647995956
Validation loss: 2.636765047834396

Epoch: 6| Step: 13
Training loss: 2.1655003147094187
Validation loss: 2.6265769593106434

Epoch: 66| Step: 0
Training loss: 2.4811674320502233
Validation loss: 2.6387783145748003

Epoch: 6| Step: 1
Training loss: 3.3341365482260614
Validation loss: 2.634219480908086

Epoch: 6| Step: 2
Training loss: 2.0359723876399753
Validation loss: 2.6430833090189116

Epoch: 6| Step: 3
Training loss: 2.3227418454562585
Validation loss: 2.635958097996096

Epoch: 6| Step: 4
Training loss: 2.9057734929421386
Validation loss: 2.644700602812948

Epoch: 6| Step: 5
Training loss: 3.092303930310232
Validation loss: 2.64884003582621

Epoch: 6| Step: 6
Training loss: 3.412772277477641
Validation loss: 2.65376269517641

Epoch: 6| Step: 7
Training loss: 2.4329353041821595
Validation loss: 2.6357115723580224

Epoch: 6| Step: 8
Training loss: 2.4551039567679407
Validation loss: 2.631691302840808

Epoch: 6| Step: 9
Training loss: 3.19239670361577
Validation loss: 2.6508504015785905

Epoch: 6| Step: 10
Training loss: 2.3588304712328525
Validation loss: 2.630101093033864

Epoch: 6| Step: 11
Training loss: 2.1558595386746293
Validation loss: 2.647695207644325

Epoch: 6| Step: 12
Training loss: 3.7459361626948944
Validation loss: 2.6559856700695352

Epoch: 6| Step: 13
Training loss: 2.794302497866858
Validation loss: 2.6397532692642214

Epoch: 67| Step: 0
Training loss: 1.8502662724816803
Validation loss: 2.628162910305349

Epoch: 6| Step: 1
Training loss: 2.5428393634278676
Validation loss: 2.650967583609476

Epoch: 6| Step: 2
Training loss: 2.5113363731344953
Validation loss: 2.6302947863626733

Epoch: 6| Step: 3
Training loss: 3.157463822327445
Validation loss: 2.626391357051211

Epoch: 6| Step: 4
Training loss: 3.3801419683131875
Validation loss: 2.6391898877494637

Epoch: 6| Step: 5
Training loss: 2.927914991145326
Validation loss: 2.630035636119544

Epoch: 6| Step: 6
Training loss: 2.0825620622305574
Validation loss: 2.639531670299575

Epoch: 6| Step: 7
Training loss: 2.451384686354462
Validation loss: 2.6354595431973755

Epoch: 6| Step: 8
Training loss: 3.168964873784002
Validation loss: 2.6342081877907444

Epoch: 6| Step: 9
Training loss: 2.8775639918127864
Validation loss: 2.6371109228804204

Epoch: 6| Step: 10
Training loss: 2.9560161344838938
Validation loss: 2.6418215317453937

Epoch: 6| Step: 11
Training loss: 2.967089379301814
Validation loss: 2.638573521665249

Epoch: 6| Step: 12
Training loss: 2.3876743432744862
Validation loss: 2.6307095022864977

Epoch: 6| Step: 13
Training loss: 3.9447995296158487
Validation loss: 2.6239657163865204

Epoch: 68| Step: 0
Training loss: 2.1111057669030973
Validation loss: 2.633158820234163

Epoch: 6| Step: 1
Training loss: 2.615235104322154
Validation loss: 2.632013979236498

Epoch: 6| Step: 2
Training loss: 2.9519899800861955
Validation loss: 2.614419960873129

Epoch: 6| Step: 3
Training loss: 2.0121323243722546
Validation loss: 2.6330343485093697

Epoch: 6| Step: 4
Training loss: 2.7320570357919083
Validation loss: 2.6421926550890897

Epoch: 6| Step: 5
Training loss: 3.545416981824875
Validation loss: 2.6344539783036356

Epoch: 6| Step: 6
Training loss: 3.2963881291310306
Validation loss: 2.6531879802488145

Epoch: 6| Step: 7
Training loss: 3.1063539790781993
Validation loss: 2.64720612029057

Epoch: 6| Step: 8
Training loss: 1.9801181580708447
Validation loss: 2.635143886211845

Epoch: 6| Step: 9
Training loss: 2.7068021603043095
Validation loss: 2.637661551515327

Epoch: 6| Step: 10
Training loss: 2.0084945766992073
Validation loss: 2.6386198588526026

Epoch: 6| Step: 11
Training loss: 3.4588523077025166
Validation loss: 2.639406097048565

Epoch: 6| Step: 12
Training loss: 2.344917108498196
Validation loss: 2.643145011234233

Epoch: 6| Step: 13
Training loss: 3.9562856229651766
Validation loss: 2.6536606175737214

Epoch: 69| Step: 0
Training loss: 3.2465629009085384
Validation loss: 2.633804595428285

Epoch: 6| Step: 1
Training loss: 2.9460292925443388
Validation loss: 2.638527236131506

Epoch: 6| Step: 2
Training loss: 2.309608714004214
Validation loss: 2.647149985469705

Epoch: 6| Step: 3
Training loss: 2.7241945668780723
Validation loss: 2.634438871540845

Epoch: 6| Step: 4
Training loss: 3.4213309356292547
Validation loss: 2.6387331926549287

Epoch: 6| Step: 5
Training loss: 1.90133063502118
Validation loss: 2.644326583671872

Epoch: 6| Step: 6
Training loss: 2.651498201902306
Validation loss: 2.633303271093877

Epoch: 6| Step: 7
Training loss: 2.9336298344776397
Validation loss: 2.6298464634687093

Epoch: 6| Step: 8
Training loss: 2.438344369038944
Validation loss: 2.640126221455678

Epoch: 6| Step: 9
Training loss: 2.6912219866168603
Validation loss: 2.633331272061612

Epoch: 6| Step: 10
Training loss: 2.33027887239015
Validation loss: 2.6408109823323613

Epoch: 6| Step: 11
Training loss: 3.7318024652830406
Validation loss: 2.645262784502646

Epoch: 6| Step: 12
Training loss: 2.6476146578793207
Validation loss: 2.6425442158772388

Epoch: 6| Step: 13
Training loss: 2.6550365593471077
Validation loss: 2.6475579768824082

Epoch: 70| Step: 0
Training loss: 3.8016518265232313
Validation loss: 2.6489841251479755

Epoch: 6| Step: 1
Training loss: 2.3665600439240504
Validation loss: 2.628715877468995

Epoch: 6| Step: 2
Training loss: 3.182229865057284
Validation loss: 2.6415826301668868

Epoch: 6| Step: 3
Training loss: 2.4023300542673627
Validation loss: 2.629927468246593

Epoch: 6| Step: 4
Training loss: 3.0279313630824882
Validation loss: 2.628703901439563

Epoch: 6| Step: 5
Training loss: 2.602344658839154
Validation loss: 2.644977697846814

Epoch: 6| Step: 6
Training loss: 2.085944243573779
Validation loss: 2.6436629911602063

Epoch: 6| Step: 7
Training loss: 1.897725792117468
Validation loss: 2.6432548573024057

Epoch: 6| Step: 8
Training loss: 2.8078718464671533
Validation loss: 2.625770867795378

Epoch: 6| Step: 9
Training loss: 2.645251402850672
Validation loss: 2.6262247272650714

Epoch: 6| Step: 10
Training loss: 2.6197935879183953
Validation loss: 2.6327932259770748

Epoch: 6| Step: 11
Training loss: 3.5246184879841738
Validation loss: 2.6392383549852645

Epoch: 6| Step: 12
Training loss: 3.0391735850922146
Validation loss: 2.6173476176166925

Epoch: 6| Step: 13
Training loss: 2.269385853507422
Validation loss: 2.629036990257769

Epoch: 71| Step: 0
Training loss: 3.587621090005077
Validation loss: 2.627846314899687

Epoch: 6| Step: 1
Training loss: 2.6829648453964694
Validation loss: 2.622216678397078

Epoch: 6| Step: 2
Training loss: 2.9398829757340246
Validation loss: 2.622304620519129

Epoch: 6| Step: 3
Training loss: 2.677704992487864
Validation loss: 2.6260394564377587

Epoch: 6| Step: 4
Training loss: 3.0560549433896966
Validation loss: 2.6196828295329047

Epoch: 6| Step: 5
Training loss: 2.0481058162085297
Validation loss: 2.6308617010108653

Epoch: 6| Step: 6
Training loss: 2.881903114686364
Validation loss: 2.6206315720933

Epoch: 6| Step: 7
Training loss: 2.453192545938853
Validation loss: 2.6319254449532754

Epoch: 6| Step: 8
Training loss: 2.4352576872595915
Validation loss: 2.6242589221876416

Epoch: 6| Step: 9
Training loss: 2.7113107209992853
Validation loss: 2.6149101927307674

Epoch: 6| Step: 10
Training loss: 2.9771273019550066
Validation loss: 2.627338816818361

Epoch: 6| Step: 11
Training loss: 2.98750899564913
Validation loss: 2.626557413087864

Epoch: 6| Step: 12
Training loss: 3.1975471871289116
Validation loss: 2.6232398900714133

Epoch: 6| Step: 13
Training loss: 1.5895816671313565
Validation loss: 2.643605467090809

Epoch: 72| Step: 0
Training loss: 2.0907455067479677
Validation loss: 2.6399770214591625

Epoch: 6| Step: 1
Training loss: 3.1215848954043053
Validation loss: 2.6224478363011023

Epoch: 6| Step: 2
Training loss: 3.05472215403537
Validation loss: 2.6284933104310113

Epoch: 6| Step: 3
Training loss: 3.04563150706967
Validation loss: 2.6213899439600175

Epoch: 6| Step: 4
Training loss: 2.311004361210021
Validation loss: 2.6257997984921686

Epoch: 6| Step: 5
Training loss: 3.1379534997746616
Validation loss: 2.626037493709662

Epoch: 6| Step: 6
Training loss: 2.401376123089821
Validation loss: 2.635556003113969

Epoch: 6| Step: 7
Training loss: 3.1692018566707287
Validation loss: 2.629157941049796

Epoch: 6| Step: 8
Training loss: 2.6026689622248758
Validation loss: 2.631022412955293

Epoch: 6| Step: 9
Training loss: 2.494785975142473
Validation loss: 2.6248403052347427

Epoch: 6| Step: 10
Training loss: 2.742040907373105
Validation loss: 2.6274031358905177

Epoch: 6| Step: 11
Training loss: 2.320739912233677
Validation loss: 2.630005672952008

Epoch: 6| Step: 12
Training loss: 3.4066509045897537
Validation loss: 2.622248426788697

Epoch: 6| Step: 13
Training loss: 3.0067526795573642
Validation loss: 2.632819380346041

Epoch: 73| Step: 0
Training loss: 2.3781516596218393
Validation loss: 2.6339377642876847

Epoch: 6| Step: 1
Training loss: 2.6846341666366937
Validation loss: 2.631427416014324

Epoch: 6| Step: 2
Training loss: 2.446090623188975
Validation loss: 2.6430142549518783

Epoch: 6| Step: 3
Training loss: 2.2330909720859595
Validation loss: 2.624606847742233

Epoch: 6| Step: 4
Training loss: 2.7698016337348923
Validation loss: 2.6191471693144637

Epoch: 6| Step: 5
Training loss: 3.714533619415178
Validation loss: 2.6290979114837687

Epoch: 6| Step: 6
Training loss: 1.9736498454933609
Validation loss: 2.6303965407493064

Epoch: 6| Step: 7
Training loss: 2.649189979984227
Validation loss: 2.6154265276905315

Epoch: 6| Step: 8
Training loss: 3.2855208440667174
Validation loss: 2.6506061566522163

Epoch: 6| Step: 9
Training loss: 3.2879935586685236
Validation loss: 2.6352706694290635

Epoch: 6| Step: 10
Training loss: 2.1919619149846477
Validation loss: 2.6359485473903157

Epoch: 6| Step: 11
Training loss: 2.7911893711774423
Validation loss: 2.6285574471555604

Epoch: 6| Step: 12
Training loss: 3.166393184564319
Validation loss: 2.6388788393265004

Epoch: 6| Step: 13
Training loss: 3.07398825027315
Validation loss: 2.6363316590362267

Epoch: 74| Step: 0
Training loss: 2.6942702780034185
Validation loss: 2.638287563999591

Epoch: 6| Step: 1
Training loss: 3.1112953275303687
Validation loss: 2.6331185226656935

Epoch: 6| Step: 2
Training loss: 2.4335603420848466
Validation loss: 2.639226904613111

Epoch: 6| Step: 3
Training loss: 2.5440049177278214
Validation loss: 2.638208246309201

Epoch: 6| Step: 4
Training loss: 2.8647259116091752
Validation loss: 2.634214730680812

Epoch: 6| Step: 5
Training loss: 2.7714552981979823
Validation loss: 2.637832397913193

Epoch: 6| Step: 6
Training loss: 2.892027478605921
Validation loss: 2.6374150004179477

Epoch: 6| Step: 7
Training loss: 2.6803207316566313
Validation loss: 2.636738752732085

Epoch: 6| Step: 8
Training loss: 3.3080340816213574
Validation loss: 2.6400307335358906

Epoch: 6| Step: 9
Training loss: 2.840687034945133
Validation loss: 2.6367795248558896

Epoch: 6| Step: 10
Training loss: 2.8922615985662525
Validation loss: 2.630060717910664

Epoch: 6| Step: 11
Training loss: 2.2195800518080615
Validation loss: 2.6237253765620476

Epoch: 6| Step: 12
Training loss: 2.9533650941482827
Validation loss: 2.635003764070117

Epoch: 6| Step: 13
Training loss: 2.605494920865095
Validation loss: 2.6280412552599417

Epoch: 75| Step: 0
Training loss: 2.8757613459372147
Validation loss: 2.6388029873231122

Epoch: 6| Step: 1
Training loss: 1.8372642755144577
Validation loss: 2.6388856902550173

Epoch: 6| Step: 2
Training loss: 2.4216856851725774
Validation loss: 2.6510788268456436

Epoch: 6| Step: 3
Training loss: 3.1076425297796892
Validation loss: 2.6325486174678527

Epoch: 6| Step: 4
Training loss: 2.7471575351921196
Validation loss: 2.6253962513137346

Epoch: 6| Step: 5
Training loss: 3.4801588337923386
Validation loss: 2.6329242328031577

Epoch: 6| Step: 6
Training loss: 3.6726440922857027
Validation loss: 2.6230950326102587

Epoch: 6| Step: 7
Training loss: 3.1453063388694003
Validation loss: 2.6313098304685942

Epoch: 6| Step: 8
Training loss: 2.654643302131937
Validation loss: 2.6249995624719618

Epoch: 6| Step: 9
Training loss: 2.400003325936874
Validation loss: 2.640755393069769

Epoch: 6| Step: 10
Training loss: 1.8901719740681624
Validation loss: 2.6376648910884586

Epoch: 6| Step: 11
Training loss: 2.44574195088896
Validation loss: 2.6181488872028202

Epoch: 6| Step: 12
Training loss: 2.6538456525557605
Validation loss: 2.629640535278112

Epoch: 6| Step: 13
Training loss: 3.070764251166585
Validation loss: 2.6280776955918577

Epoch: 76| Step: 0
Training loss: 2.7168563737531337
Validation loss: 2.6360068483393944

Epoch: 6| Step: 1
Training loss: 2.3489659570766204
Validation loss: 2.642994854055242

Epoch: 6| Step: 2
Training loss: 2.4141225467855683
Validation loss: 2.620164238542056

Epoch: 6| Step: 3
Training loss: 3.2902077608686318
Validation loss: 2.621369493550279

Epoch: 6| Step: 4
Training loss: 1.8893729233296572
Validation loss: 2.6266836591529277

Epoch: 6| Step: 5
Training loss: 3.056897390872843
Validation loss: 2.627617234910455

Epoch: 6| Step: 6
Training loss: 2.9441626451905556
Validation loss: 2.6221779979070066

Epoch: 6| Step: 7
Training loss: 2.727036224572273
Validation loss: 2.6259738504432875

Epoch: 6| Step: 8
Training loss: 2.600855459184126
Validation loss: 2.608156277852617

Epoch: 6| Step: 9
Training loss: 2.7125573499391646
Validation loss: 2.6150871359840573

Epoch: 6| Step: 10
Training loss: 3.268309589424885
Validation loss: 2.6096830883104234

Epoch: 6| Step: 11
Training loss: 2.2663423652152885
Validation loss: 2.6248482866877016

Epoch: 6| Step: 12
Training loss: 2.9486838556740684
Validation loss: 2.6216502358361393

Epoch: 6| Step: 13
Training loss: 3.7681016810358883
Validation loss: 2.6247895484079717

Epoch: 77| Step: 0
Training loss: 3.3795996511243582
Validation loss: 2.626530287655753

Epoch: 6| Step: 1
Training loss: 2.2338300987530846
Validation loss: 2.6128998498060523

Epoch: 6| Step: 2
Training loss: 2.8364674306876085
Validation loss: 2.6242467773288167

Epoch: 6| Step: 3
Training loss: 2.5069677528525918
Validation loss: 2.628303738053398

Epoch: 6| Step: 4
Training loss: 2.461830195232045
Validation loss: 2.6070801402867043

Epoch: 6| Step: 5
Training loss: 2.398691170166344
Validation loss: 2.6205594464653257

Epoch: 6| Step: 6
Training loss: 3.4131317615843715
Validation loss: 2.6151669039788494

Epoch: 6| Step: 7
Training loss: 2.4671791970401373
Validation loss: 2.6182941269931566

Epoch: 6| Step: 8
Training loss: 2.3644042318353677
Validation loss: 2.6381400431991064

Epoch: 6| Step: 9
Training loss: 2.198476445897591
Validation loss: 2.6285910666190833

Epoch: 6| Step: 10
Training loss: 3.2794207605768344
Validation loss: 2.6404976005522247

Epoch: 6| Step: 11
Training loss: 2.87501708315874
Validation loss: 2.603993937680875

Epoch: 6| Step: 12
Training loss: 3.4764151895581215
Validation loss: 2.6399256923493604

Epoch: 6| Step: 13
Training loss: 2.393904387672088
Validation loss: 2.624937635892929

Epoch: 78| Step: 0
Training loss: 3.0137528849286923
Validation loss: 2.645047550178369

Epoch: 6| Step: 1
Training loss: 2.9149378057685937
Validation loss: 2.6358510835222972

Epoch: 6| Step: 2
Training loss: 3.002641627443889
Validation loss: 2.6090231369547787

Epoch: 6| Step: 3
Training loss: 3.3574294023057707
Validation loss: 2.63024804909635

Epoch: 6| Step: 4
Training loss: 2.7262677139903095
Validation loss: 2.6179567923363196

Epoch: 6| Step: 5
Training loss: 2.3984709995179356
Validation loss: 2.6248441396949813

Epoch: 6| Step: 6
Training loss: 2.562855858633124
Validation loss: 2.6319718319747394

Epoch: 6| Step: 7
Training loss: 2.687009722324013
Validation loss: 2.6122980298691667

Epoch: 6| Step: 8
Training loss: 2.3628110812005976
Validation loss: 2.6281938943059306

Epoch: 6| Step: 9
Training loss: 2.959817558800589
Validation loss: 2.6207645602545897

Epoch: 6| Step: 10
Training loss: 2.4441623115522426
Validation loss: 2.627975866053068

Epoch: 6| Step: 11
Training loss: 3.0765147378371043
Validation loss: 2.6288035114767707

Epoch: 6| Step: 12
Training loss: 2.609406248350974
Validation loss: 2.6175464671079403

Epoch: 6| Step: 13
Training loss: 2.2585521925088696
Validation loss: 2.612625780280175

Epoch: 79| Step: 0
Training loss: 3.364491810848062
Validation loss: 2.637683386959716

Epoch: 6| Step: 1
Training loss: 2.679196415603031
Validation loss: 2.631917755750385

Epoch: 6| Step: 2
Training loss: 2.703821169780253
Validation loss: 2.630847455501912

Epoch: 6| Step: 3
Training loss: 2.3895821883695785
Validation loss: 2.6274318651788233

Epoch: 6| Step: 4
Training loss: 2.923366879742298
Validation loss: 2.621241685388379

Epoch: 6| Step: 5
Training loss: 2.6872130839645694
Validation loss: 2.6154416942785126

Epoch: 6| Step: 6
Training loss: 2.881029854595625
Validation loss: 2.6265812548532397

Epoch: 6| Step: 7
Training loss: 3.251189674366301
Validation loss: 2.630213112564318

Epoch: 6| Step: 8
Training loss: 2.1107720164075094
Validation loss: 2.6238808919878887

Epoch: 6| Step: 9
Training loss: 2.5062416361909423
Validation loss: 2.6409642879641395

Epoch: 6| Step: 10
Training loss: 2.2934164360795415
Validation loss: 2.614860301016224

Epoch: 6| Step: 11
Training loss: 2.6604166001509317
Validation loss: 2.637522953557395

Epoch: 6| Step: 12
Training loss: 3.0524895997616164
Validation loss: 2.624158285799199

Epoch: 6| Step: 13
Training loss: 3.283219536553643
Validation loss: 2.625735717429036

Epoch: 80| Step: 0
Training loss: 2.9401074463809396
Validation loss: 2.61648968923106

Epoch: 6| Step: 1
Training loss: 2.683146743526366
Validation loss: 2.622798101656794

Epoch: 6| Step: 2
Training loss: 2.588393874269941
Validation loss: 2.623706682628678

Epoch: 6| Step: 3
Training loss: 2.3933590482571794
Validation loss: 2.6114156396057746

Epoch: 6| Step: 4
Training loss: 3.3695954742785252
Validation loss: 2.625099134355603

Epoch: 6| Step: 5
Training loss: 2.1624547170848185
Validation loss: 2.6208903991797943

Epoch: 6| Step: 6
Training loss: 2.471245675206199
Validation loss: 2.634559469243501

Epoch: 6| Step: 7
Training loss: 2.618778303261989
Validation loss: 2.620059768781255

Epoch: 6| Step: 8
Training loss: 2.3826463985395803
Validation loss: 2.6283258287609033

Epoch: 6| Step: 9
Training loss: 3.272098094253216
Validation loss: 2.6283360527706443

Epoch: 6| Step: 10
Training loss: 3.324890427469046
Validation loss: 2.624098814985537

Epoch: 6| Step: 11
Training loss: 3.449151147544978
Validation loss: 2.616086082745239

Epoch: 6| Step: 12
Training loss: 2.1386514741107456
Validation loss: 2.633897035773422

Epoch: 6| Step: 13
Training loss: 2.1063761551654445
Validation loss: 2.6293430535657576

Epoch: 81| Step: 0
Training loss: 2.6045244098353586
Validation loss: 2.6268125966807467

Epoch: 6| Step: 1
Training loss: 2.056311831950526
Validation loss: 2.6269825550179347

Epoch: 6| Step: 2
Training loss: 3.0267054518624676
Validation loss: 2.6216273422655267

Epoch: 6| Step: 3
Training loss: 2.581404201529153
Validation loss: 2.6135838743243403

Epoch: 6| Step: 4
Training loss: 2.7222742499571897
Validation loss: 2.6257991453289686

Epoch: 6| Step: 5
Training loss: 2.848672149250597
Validation loss: 2.6158373099225196

Epoch: 6| Step: 6
Training loss: 2.789641931861813
Validation loss: 2.6223428445507255

Epoch: 6| Step: 7
Training loss: 2.5918239198263984
Validation loss: 2.6241678734537897

Epoch: 6| Step: 8
Training loss: 2.6730160423907705
Validation loss: 2.6227655759985318

Epoch: 6| Step: 9
Training loss: 3.818111355036415
Validation loss: 2.623882051735944

Epoch: 6| Step: 10
Training loss: 2.060366133586735
Validation loss: 2.624405357485487

Epoch: 6| Step: 11
Training loss: 2.8476033356280643
Validation loss: 2.6372992745702573

Epoch: 6| Step: 12
Training loss: 3.1900685750831297
Validation loss: 2.622490469975272

Epoch: 6| Step: 13
Training loss: 2.237046891690869
Validation loss: 2.636054030063832

Epoch: 82| Step: 0
Training loss: 2.7786414096633796
Validation loss: 2.61456543231937

Epoch: 6| Step: 1
Training loss: 2.70182610323921
Validation loss: 2.6081225075258696

Epoch: 6| Step: 2
Training loss: 3.3906442668033385
Validation loss: 2.6285362673847352

Epoch: 6| Step: 3
Training loss: 2.5970663906772673
Validation loss: 2.6302956694036306

Epoch: 6| Step: 4
Training loss: 2.925395619299883
Validation loss: 2.60974699280255

Epoch: 6| Step: 5
Training loss: 2.2820602441269395
Validation loss: 2.621462079988153

Epoch: 6| Step: 6
Training loss: 2.551841714022022
Validation loss: 2.62136543885203

Epoch: 6| Step: 7
Training loss: 3.109014442280243
Validation loss: 2.6154856320921955

Epoch: 6| Step: 8
Training loss: 3.204743660184108
Validation loss: 2.6162874376381997

Epoch: 6| Step: 9
Training loss: 2.9739289736036167
Validation loss: 2.610787455239992

Epoch: 6| Step: 10
Training loss: 2.2940781361211102
Validation loss: 2.617609734010172

Epoch: 6| Step: 11
Training loss: 2.0069593702536372
Validation loss: 2.633516633450906

Epoch: 6| Step: 12
Training loss: 2.8390020621232797
Validation loss: 2.6241384265230585

Epoch: 6| Step: 13
Training loss: 2.6261647682939224
Validation loss: 2.6144045177170105

Epoch: 83| Step: 0
Training loss: 2.31850170029641
Validation loss: 2.6058092488413243

Epoch: 6| Step: 1
Training loss: 2.130690192928617
Validation loss: 2.618474786697168

Epoch: 6| Step: 2
Training loss: 2.3578027197936446
Validation loss: 2.6038807488449973

Epoch: 6| Step: 3
Training loss: 3.3155693373111017
Validation loss: 2.614250699922681

Epoch: 6| Step: 4
Training loss: 2.609761009674719
Validation loss: 2.649330491237079

Epoch: 6| Step: 5
Training loss: 3.9057605894582847
Validation loss: 2.6123416927838212

Epoch: 6| Step: 6
Training loss: 3.0727920420747465
Validation loss: 2.612155566831192

Epoch: 6| Step: 7
Training loss: 1.9676957713813785
Validation loss: 2.617329762607969

Epoch: 6| Step: 8
Training loss: 2.5832775068916436
Validation loss: 2.6317132219153034

Epoch: 6| Step: 9
Training loss: 3.0885170500848056
Validation loss: 2.634304903733907

Epoch: 6| Step: 10
Training loss: 2.3452310587385776
Validation loss: 2.6267816851997714

Epoch: 6| Step: 11
Training loss: 2.2876322056655956
Validation loss: 2.6201255708035904

Epoch: 6| Step: 12
Training loss: 2.9845216725042323
Validation loss: 2.6206649185686004

Epoch: 6| Step: 13
Training loss: 3.2359741975111618
Validation loss: 2.6156594980713397

Epoch: 84| Step: 0
Training loss: 2.6109126694215936
Validation loss: 2.6300315918575468

Epoch: 6| Step: 1
Training loss: 2.232850414939251
Validation loss: 2.6282423243647224

Epoch: 6| Step: 2
Training loss: 3.332419047534992
Validation loss: 2.6224375648956864

Epoch: 6| Step: 3
Training loss: 2.8266118675294285
Validation loss: 2.623194597625456

Epoch: 6| Step: 4
Training loss: 2.544715199601425
Validation loss: 2.626447318169449

Epoch: 6| Step: 5
Training loss: 2.5716463008164023
Validation loss: 2.622925035444975

Epoch: 6| Step: 6
Training loss: 2.2699846087366686
Validation loss: 2.619280575408187

Epoch: 6| Step: 7
Training loss: 2.304468176799337
Validation loss: 2.6144732870597878

Epoch: 6| Step: 8
Training loss: 2.644478418450764
Validation loss: 2.620372647043311

Epoch: 6| Step: 9
Training loss: 2.2161984883801997
Validation loss: 2.619010522278972

Epoch: 6| Step: 10
Training loss: 3.7191073462350914
Validation loss: 2.6417294880612405

Epoch: 6| Step: 11
Training loss: 3.123473137732846
Validation loss: 2.617353264314984

Epoch: 6| Step: 12
Training loss: 2.798800098947041
Validation loss: 2.626044698832894

Epoch: 6| Step: 13
Training loss: 2.9731380758906147
Validation loss: 2.613112292021134

Epoch: 85| Step: 0
Training loss: 2.644207302069401
Validation loss: 2.61444297442871

Epoch: 6| Step: 1
Training loss: 2.2013406223443694
Validation loss: 2.6088741579074477

Epoch: 6| Step: 2
Training loss: 2.1747803500406313
Validation loss: 2.6295039538733107

Epoch: 6| Step: 3
Training loss: 3.355824568226838
Validation loss: 2.6268572109303294

Epoch: 6| Step: 4
Training loss: 2.760455456347204
Validation loss: 2.6235466892771155

Epoch: 6| Step: 5
Training loss: 2.7958747311145684
Validation loss: 2.6274765533117366

Epoch: 6| Step: 6
Training loss: 2.6861544944716353
Validation loss: 2.6121089554912875

Epoch: 6| Step: 7
Training loss: 2.999899544623458
Validation loss: 2.624610333836678

Epoch: 6| Step: 8
Training loss: 3.052937896836573
Validation loss: 2.6337203458598295

Epoch: 6| Step: 9
Training loss: 2.993240848321767
Validation loss: 2.6190965586099666

Epoch: 6| Step: 10
Training loss: 2.4995959909149024
Validation loss: 2.619985239887094

Epoch: 6| Step: 11
Training loss: 3.037621791579992
Validation loss: 2.6089899217276695

Epoch: 6| Step: 12
Training loss: 2.759854606171236
Validation loss: 2.608572254982305

Epoch: 6| Step: 13
Training loss: 1.9849413566670802
Validation loss: 2.6217417323369765

Epoch: 86| Step: 0
Training loss: 3.025321275028269
Validation loss: 2.610567212175532

Epoch: 6| Step: 1
Training loss: 2.9688656433068528
Validation loss: 2.607946037641

Epoch: 6| Step: 2
Training loss: 2.306251124766833
Validation loss: 2.6219784016549887

Epoch: 6| Step: 3
Training loss: 2.8562314623475293
Validation loss: 2.6305029087731175

Epoch: 6| Step: 4
Training loss: 2.5412157523816408
Validation loss: 2.6053476391719017

Epoch: 6| Step: 5
Training loss: 3.1127016300937487
Validation loss: 2.6281597088775923

Epoch: 6| Step: 6
Training loss: 3.063462086802347
Validation loss: 2.6118514283772067

Epoch: 6| Step: 7
Training loss: 2.5200136181296884
Validation loss: 2.6168561005340494

Epoch: 6| Step: 8
Training loss: 2.4615993033739456
Validation loss: 2.6263279444297916

Epoch: 6| Step: 9
Training loss: 2.75841768448885
Validation loss: 2.6115446776556563

Epoch: 6| Step: 10
Training loss: 2.6445970625696558
Validation loss: 2.6188140697621622

Epoch: 6| Step: 11
Training loss: 3.2777569297802813
Validation loss: 2.606991227326893

Epoch: 6| Step: 12
Training loss: 2.5532614551250994
Validation loss: 2.6175426914952045

Epoch: 6| Step: 13
Training loss: 1.8608282484755834
Validation loss: 2.620819505359998

Epoch: 87| Step: 0
Training loss: 1.7998210473644347
Validation loss: 2.6229455528951537

Epoch: 6| Step: 1
Training loss: 3.1010680296963313
Validation loss: 2.6244730549907445

Epoch: 6| Step: 2
Training loss: 2.762937026171534
Validation loss: 2.623556625082233

Epoch: 6| Step: 3
Training loss: 2.4514873894295737
Validation loss: 2.6226222240985053

Epoch: 6| Step: 4
Training loss: 2.0636676604159123
Validation loss: 2.626855889514655

Epoch: 6| Step: 5
Training loss: 2.687382540242929
Validation loss: 2.6267445671286067

Epoch: 6| Step: 6
Training loss: 2.567952194137288
Validation loss: 2.6150101507486294

Epoch: 6| Step: 7
Training loss: 3.273108272338569
Validation loss: 2.62216116813742

Epoch: 6| Step: 8
Training loss: 2.443810339765671
Validation loss: 2.6222644504198716

Epoch: 6| Step: 9
Training loss: 2.8833920276231844
Validation loss: 2.6273532101501944

Epoch: 6| Step: 10
Training loss: 3.35482579422824
Validation loss: 2.6260640702219367

Epoch: 6| Step: 11
Training loss: 3.1455440430329626
Validation loss: 2.657261378309404

Epoch: 6| Step: 12
Training loss: 2.705179921792863
Validation loss: 2.643414290135699

Epoch: 6| Step: 13
Training loss: 2.9110124186254516
Validation loss: 2.6197710093703943

Epoch: 88| Step: 0
Training loss: 3.0160462080352657
Validation loss: 2.6191506812730667

Epoch: 6| Step: 1
Training loss: 3.084191864358759
Validation loss: 2.6365838693068513

Epoch: 6| Step: 2
Training loss: 2.338000761033612
Validation loss: 2.6221234958113366

Epoch: 6| Step: 3
Training loss: 2.6669498134335123
Validation loss: 2.6360260755240863

Epoch: 6| Step: 4
Training loss: 2.225269249901707
Validation loss: 2.6272610762416364

Epoch: 6| Step: 5
Training loss: 2.301452331599602
Validation loss: 2.6304953703709884

Epoch: 6| Step: 6
Training loss: 2.735197368662512
Validation loss: 2.6139672401672627

Epoch: 6| Step: 7
Training loss: 2.748641632289285
Validation loss: 2.613083065844422

Epoch: 6| Step: 8
Training loss: 3.059613482928357
Validation loss: 2.6158529210271073

Epoch: 6| Step: 9
Training loss: 2.5089929957377586
Validation loss: 2.6082442714023624

Epoch: 6| Step: 10
Training loss: 2.6299998487175147
Validation loss: 2.6193159386584592

Epoch: 6| Step: 11
Training loss: 2.539767874526298
Validation loss: 2.630633932204751

Epoch: 6| Step: 12
Training loss: 3.524158209532516
Validation loss: 2.62976364296426

Epoch: 6| Step: 13
Training loss: 3.0011155915261196
Validation loss: 2.6203833120110316

Epoch: 89| Step: 0
Training loss: 2.235407664010394
Validation loss: 2.615746632543934

Epoch: 6| Step: 1
Training loss: 2.812154112845619
Validation loss: 2.626462643176005

Epoch: 6| Step: 2
Training loss: 2.68248493769844
Validation loss: 2.618773758015152

Epoch: 6| Step: 3
Training loss: 2.6696902260403053
Validation loss: 2.6264231760148964

Epoch: 6| Step: 4
Training loss: 2.28673489808955
Validation loss: 2.6237459366082234

Epoch: 6| Step: 5
Training loss: 3.1216039896991834
Validation loss: 2.6256285265071746

Epoch: 6| Step: 6
Training loss: 2.218325399685073
Validation loss: 2.627439055257563

Epoch: 6| Step: 7
Training loss: 2.3422576221965405
Validation loss: 2.6023379323816025

Epoch: 6| Step: 8
Training loss: 2.4463149870757057
Validation loss: 2.6410273515851035

Epoch: 6| Step: 9
Training loss: 3.6080278797383536
Validation loss: 2.6084146150108425

Epoch: 6| Step: 10
Training loss: 2.984939601676922
Validation loss: 2.617663954990749

Epoch: 6| Step: 11
Training loss: 3.1780968888951575
Validation loss: 2.61119881018448

Epoch: 6| Step: 12
Training loss: 2.7464117568746973
Validation loss: 2.612602858165417

Epoch: 6| Step: 13
Training loss: 2.8724254192766505
Validation loss: 2.6194912865816753

Epoch: 90| Step: 0
Training loss: 3.1147077826873586
Validation loss: 2.617851992598667

Epoch: 6| Step: 1
Training loss: 2.0881283573876077
Validation loss: 2.618875796564641

Epoch: 6| Step: 2
Training loss: 1.5659544333579811
Validation loss: 2.6212426066880314

Epoch: 6| Step: 3
Training loss: 2.7641155196862983
Validation loss: 2.6248914956961693

Epoch: 6| Step: 4
Training loss: 2.0905956591270676
Validation loss: 2.614387734004442

Epoch: 6| Step: 5
Training loss: 3.7254255627752513
Validation loss: 2.6098597150464546

Epoch: 6| Step: 6
Training loss: 2.825059272346856
Validation loss: 2.631912690156703

Epoch: 6| Step: 7
Training loss: 2.695316745920569
Validation loss: 2.609906016867204

Epoch: 6| Step: 8
Training loss: 2.7508785405027223
Validation loss: 2.621318174651569

Epoch: 6| Step: 9
Training loss: 2.653960554023826
Validation loss: 2.6257641134784095

Epoch: 6| Step: 10
Training loss: 3.0918833948826836
Validation loss: 2.604809672721682

Epoch: 6| Step: 11
Training loss: 2.8630166133141444
Validation loss: 2.614862962833676

Epoch: 6| Step: 12
Training loss: 2.3163429496054264
Validation loss: 2.6095076825605426

Epoch: 6| Step: 13
Training loss: 3.522398937283576
Validation loss: 2.623457008334283

Epoch: 91| Step: 0
Training loss: 2.6531371782470425
Validation loss: 2.6053338563627193

Epoch: 6| Step: 1
Training loss: 2.7575845164872224
Validation loss: 2.598598483836099

Epoch: 6| Step: 2
Training loss: 2.5150017766017214
Validation loss: 2.6348226128113525

Epoch: 6| Step: 3
Training loss: 3.0109971662626487
Validation loss: 2.5999266400333103

Epoch: 6| Step: 4
Training loss: 2.8343496369864214
Validation loss: 2.6175248711172228

Epoch: 6| Step: 5
Training loss: 2.8341667595085376
Validation loss: 2.614221117747962

Epoch: 6| Step: 6
Training loss: 2.4894681342591434
Validation loss: 2.6089468994060923

Epoch: 6| Step: 7
Training loss: 2.982278137140811
Validation loss: 2.6139117802952616

Epoch: 6| Step: 8
Training loss: 2.303793316670369
Validation loss: 2.624028216923228

Epoch: 6| Step: 9
Training loss: 3.2950916257862484
Validation loss: 2.601935676737288

Epoch: 6| Step: 10
Training loss: 2.372681138225574
Validation loss: 2.611831399945586

Epoch: 6| Step: 11
Training loss: 2.8986798208278053
Validation loss: 2.620088824182002

Epoch: 6| Step: 12
Training loss: 3.0003591958222398
Validation loss: 2.6008654442179715

Epoch: 6| Step: 13
Training loss: 1.1407218787451336
Validation loss: 2.6300086693815996

Epoch: 92| Step: 0
Training loss: 2.7423744246631214
Validation loss: 2.6236353714561678

Epoch: 6| Step: 1
Training loss: 2.648121682750865
Validation loss: 2.6228076581181985

Epoch: 6| Step: 2
Training loss: 2.7825931349091193
Validation loss: 2.610078251800743

Epoch: 6| Step: 3
Training loss: 2.316050921972344
Validation loss: 2.6120927292147442

Epoch: 6| Step: 4
Training loss: 2.7645139024798544
Validation loss: 2.6016732301667544

Epoch: 6| Step: 5
Training loss: 2.3711621244774976
Validation loss: 2.610929535367928

Epoch: 6| Step: 6
Training loss: 2.6878099484581797
Validation loss: 2.621802755609119

Epoch: 6| Step: 7
Training loss: 3.1848991104986633
Validation loss: 2.6049932629066688

Epoch: 6| Step: 8
Training loss: 3.544037208826796
Validation loss: 2.612388457966833

Epoch: 6| Step: 9
Training loss: 2.776018687732248
Validation loss: 2.6086202788428325

Epoch: 6| Step: 10
Training loss: 2.1587940632575755
Validation loss: 2.602736465677763

Epoch: 6| Step: 11
Training loss: 2.370382940846243
Validation loss: 2.6159698362126425

Epoch: 6| Step: 12
Training loss: 2.742256707081629
Validation loss: 2.6055020721032034

Epoch: 6| Step: 13
Training loss: 3.0444866503120394
Validation loss: 2.6153305682876966

Epoch: 93| Step: 0
Training loss: 2.6929169997645395
Validation loss: 2.6162829037420656

Epoch: 6| Step: 1
Training loss: 3.2439660031645676
Validation loss: 2.6121254829686853

Epoch: 6| Step: 2
Training loss: 1.982039812225144
Validation loss: 2.6062613790082736

Epoch: 6| Step: 3
Training loss: 3.0098654342430287
Validation loss: 2.61407140127367

Epoch: 6| Step: 4
Training loss: 2.5423858959058854
Validation loss: 2.6007178904946855

Epoch: 6| Step: 5
Training loss: 3.2021563298069102
Validation loss: 2.6045570176139683

Epoch: 6| Step: 6
Training loss: 3.27061978430672
Validation loss: 2.6154102470107974

Epoch: 6| Step: 7
Training loss: 2.340276152789127
Validation loss: 2.6003966070005733

Epoch: 6| Step: 8
Training loss: 2.897321542768835
Validation loss: 2.6054161732972965

Epoch: 6| Step: 9
Training loss: 2.7194248107402292
Validation loss: 2.6284255292034904

Epoch: 6| Step: 10
Training loss: 2.5270453487685307
Validation loss: 2.6084840051726865

Epoch: 6| Step: 11
Training loss: 2.0554654929332092
Validation loss: 2.6269849859537078

Epoch: 6| Step: 12
Training loss: 2.831037844357451
Validation loss: 2.6168489411371727

Epoch: 6| Step: 13
Training loss: 2.3894209478711548
Validation loss: 2.6323689854943098

Epoch: 94| Step: 0
Training loss: 2.5313289300362714
Validation loss: 2.6022105234113275

Epoch: 6| Step: 1
Training loss: 2.4229753517222807
Validation loss: 2.6198131346990623

Epoch: 6| Step: 2
Training loss: 2.4382896122518614
Validation loss: 2.6163873538172173

Epoch: 6| Step: 3
Training loss: 2.5109856516049467
Validation loss: 2.61867715374633

Epoch: 6| Step: 4
Training loss: 2.6102900927748856
Validation loss: 2.615760812301147

Epoch: 6| Step: 5
Training loss: 2.326271087042556
Validation loss: 2.6227947157854654

Epoch: 6| Step: 6
Training loss: 2.640888268703983
Validation loss: 2.6171219522602915

Epoch: 6| Step: 7
Training loss: 2.9575173949683755
Validation loss: 2.60812819533015

Epoch: 6| Step: 8
Training loss: 3.4081730445037173
Validation loss: 2.601797375910985

Epoch: 6| Step: 9
Training loss: 2.256636897594615
Validation loss: 2.623016421506

Epoch: 6| Step: 10
Training loss: 3.3925070044178853
Validation loss: 2.616561838862342

Epoch: 6| Step: 11
Training loss: 2.731981199666204
Validation loss: 2.608356607456417

Epoch: 6| Step: 12
Training loss: 2.9477593657421077
Validation loss: 2.6111492098421016

Epoch: 6| Step: 13
Training loss: 2.9479754726264313
Validation loss: 2.616529097532158

Epoch: 95| Step: 0
Training loss: 2.6076147115314345
Validation loss: 2.6158346735977154

Epoch: 6| Step: 1
Training loss: 2.8687089838158357
Validation loss: 2.6108169015366185

Epoch: 6| Step: 2
Training loss: 2.3745563494256987
Validation loss: 2.618249989565878

Epoch: 6| Step: 3
Training loss: 2.687628277223389
Validation loss: 2.6108255994621254

Epoch: 6| Step: 4
Training loss: 2.295322853932357
Validation loss: 2.628220433893587

Epoch: 6| Step: 5
Training loss: 2.0163439274364174
Validation loss: 2.6148135712175424

Epoch: 6| Step: 6
Training loss: 3.3626814782615324
Validation loss: 2.6085572715455587

Epoch: 6| Step: 7
Training loss: 2.7178522140375168
Validation loss: 2.6071781359305404

Epoch: 6| Step: 8
Training loss: 3.0336247216863144
Validation loss: 2.6156319048178758

Epoch: 6| Step: 9
Training loss: 2.674638534794764
Validation loss: 2.6167278593281145

Epoch: 6| Step: 10
Training loss: 2.9623565896649
Validation loss: 2.597380843433345

Epoch: 6| Step: 11
Training loss: 2.52647316514649
Validation loss: 2.6110963773722635

Epoch: 6| Step: 12
Training loss: 3.098760381621974
Validation loss: 2.627785314902234

Epoch: 6| Step: 13
Training loss: 2.580312921783424
Validation loss: 2.624703661574091

Epoch: 96| Step: 0
Training loss: 2.462227425762941
Validation loss: 2.6212381263519657

Epoch: 6| Step: 1
Training loss: 3.608361171999723
Validation loss: 2.6164426348186365

Epoch: 6| Step: 2
Training loss: 3.190754743398422
Validation loss: 2.625379916745595

Epoch: 6| Step: 3
Training loss: 2.3251848537012787
Validation loss: 2.606702939008707

Epoch: 6| Step: 4
Training loss: 3.204966392638446
Validation loss: 2.6206586226049944

Epoch: 6| Step: 5
Training loss: 2.4926070574665653
Validation loss: 2.62239120620994

Epoch: 6| Step: 6
Training loss: 2.780073710088747
Validation loss: 2.6105039582371794

Epoch: 6| Step: 7
Training loss: 2.624784369921923
Validation loss: 2.601061779849268

Epoch: 6| Step: 8
Training loss: 2.9519260132157785
Validation loss: 2.6035809185889

Epoch: 6| Step: 9
Training loss: 2.5024324980786568
Validation loss: 2.6125391815163015

Epoch: 6| Step: 10
Training loss: 2.4813240559093788
Validation loss: 2.5976648770180675

Epoch: 6| Step: 11
Training loss: 2.599129303613396
Validation loss: 2.611572303295682

Epoch: 6| Step: 12
Training loss: 2.186800272608702
Validation loss: 2.6199739030275526

Epoch: 6| Step: 13
Training loss: 2.237161779147928
Validation loss: 2.6178327455295363

Epoch: 97| Step: 0
Training loss: 2.332827944745947
Validation loss: 2.61045294328241

Epoch: 6| Step: 1
Training loss: 3.990869353004308
Validation loss: 2.621863306164583

Epoch: 6| Step: 2
Training loss: 2.494075143980634
Validation loss: 2.626063128160513

Epoch: 6| Step: 3
Training loss: 2.480747093142854
Validation loss: 2.6169177598819315

Epoch: 6| Step: 4
Training loss: 2.266490060807624
Validation loss: 2.5997819765321615

Epoch: 6| Step: 5
Training loss: 2.318155538440601
Validation loss: 2.6084038819414146

Epoch: 6| Step: 6
Training loss: 3.056968208284941
Validation loss: 2.6077095244540223

Epoch: 6| Step: 7
Training loss: 2.348666514830955
Validation loss: 2.6038900518044756

Epoch: 6| Step: 8
Training loss: 2.3865205523271085
Validation loss: 2.619414595208182

Epoch: 6| Step: 9
Training loss: 2.329361145780779
Validation loss: 2.5998800707561553

Epoch: 6| Step: 10
Training loss: 2.9004986367198606
Validation loss: 2.6118340030123757

Epoch: 6| Step: 11
Training loss: 3.0230901947446958
Validation loss: 2.6010834721181357

Epoch: 6| Step: 12
Training loss: 2.7993766635788484
Validation loss: 2.612067522490881

Epoch: 6| Step: 13
Training loss: 2.7579328386457256
Validation loss: 2.6138595705589167

Epoch: 98| Step: 0
Training loss: 3.0090025293980442
Validation loss: 2.6113744783405743

Epoch: 6| Step: 1
Training loss: 3.1154749858098736
Validation loss: 2.6121683999422944

Epoch: 6| Step: 2
Training loss: 2.2352305021622785
Validation loss: 2.616198223189546

Epoch: 6| Step: 3
Training loss: 2.0460189310430446
Validation loss: 2.6090230180595033

Epoch: 6| Step: 4
Training loss: 2.1047572701379917
Validation loss: 2.621707969303516

Epoch: 6| Step: 5
Training loss: 2.179318632682883
Validation loss: 2.610402696304317

Epoch: 6| Step: 6
Training loss: 2.90727265116096
Validation loss: 2.6269958163258935

Epoch: 6| Step: 7
Training loss: 2.8647846682916174
Validation loss: 2.6202961976872485

Epoch: 6| Step: 8
Training loss: 2.401240099956512
Validation loss: 2.608853278228741

Epoch: 6| Step: 9
Training loss: 2.953073168102923
Validation loss: 2.6194059512495307

Epoch: 6| Step: 10
Training loss: 3.5493018632444695
Validation loss: 2.6299507511265476

Epoch: 6| Step: 11
Training loss: 2.159834163445524
Validation loss: 2.6029044543265956

Epoch: 6| Step: 12
Training loss: 2.7843578847579593
Validation loss: 2.6131515104073846

Epoch: 6| Step: 13
Training loss: 3.5125697444629904
Validation loss: 2.616560619042773

Epoch: 99| Step: 0
Training loss: 2.8995290176457833
Validation loss: 2.6242616174555593

Epoch: 6| Step: 1
Training loss: 3.3323420640132064
Validation loss: 2.6022963920819624

Epoch: 6| Step: 2
Training loss: 2.209890488375289
Validation loss: 2.61231573575382

Epoch: 6| Step: 3
Training loss: 2.2069530371926867
Validation loss: 2.6097800264881585

Epoch: 6| Step: 4
Training loss: 2.543168254942881
Validation loss: 2.6105079119601187

Epoch: 6| Step: 5
Training loss: 2.215813641393109
Validation loss: 2.6030508253804583

Epoch: 6| Step: 6
Training loss: 2.4954267634515923
Validation loss: 2.622346874274986

Epoch: 6| Step: 7
Training loss: 2.892745935902878
Validation loss: 2.6101434106889108

Epoch: 6| Step: 8
Training loss: 2.1343932389782796
Validation loss: 2.609480577366351

Epoch: 6| Step: 9
Training loss: 3.6543809074718157
Validation loss: 2.614947076340092

Epoch: 6| Step: 10
Training loss: 3.0754913061642677
Validation loss: 2.6169303443234164

Epoch: 6| Step: 11
Training loss: 3.022265460914271
Validation loss: 2.6248240067628545

Epoch: 6| Step: 12
Training loss: 2.5803928457628995
Validation loss: 2.6099370722307267

Epoch: 6| Step: 13
Training loss: 2.110990456708175
Validation loss: 2.6177175715736705

Epoch: 100| Step: 0
Training loss: 2.7287197378020895
Validation loss: 2.6151129419857715

Epoch: 6| Step: 1
Training loss: 2.1209023180261375
Validation loss: 2.5939750736817038

Epoch: 6| Step: 2
Training loss: 2.473772950839403
Validation loss: 2.608133985839315

Epoch: 6| Step: 3
Training loss: 1.769789788430579
Validation loss: 2.6028604321764055

Epoch: 6| Step: 4
Training loss: 3.1135014895240625
Validation loss: 2.60242702501012

Epoch: 6| Step: 5
Training loss: 2.394671636700871
Validation loss: 2.623061415028389

Epoch: 6| Step: 6
Training loss: 2.269458973139131
Validation loss: 2.6149157839082213

Epoch: 6| Step: 7
Training loss: 2.1309676802792037
Validation loss: 2.6074201969075115

Epoch: 6| Step: 8
Training loss: 3.6709952091777054
Validation loss: 2.6243481722806754

Epoch: 6| Step: 9
Training loss: 3.19436549397821
Validation loss: 2.618601430757432

Epoch: 6| Step: 10
Training loss: 2.9004399459190346
Validation loss: 2.605007697529352

Epoch: 6| Step: 11
Training loss: 2.2760925520061464
Validation loss: 2.608105471561241

Epoch: 6| Step: 12
Training loss: 3.5520208060540166
Validation loss: 2.616163537060516

Epoch: 6| Step: 13
Training loss: 2.553129508529287
Validation loss: 2.5998148262179086

Epoch: 101| Step: 0
Training loss: 2.2299337998216258
Validation loss: 2.614415110933741

Epoch: 6| Step: 1
Training loss: 2.7067519535132694
Validation loss: 2.629982315500606

Epoch: 6| Step: 2
Training loss: 2.7478586009043413
Validation loss: 2.607088235111494

Epoch: 6| Step: 3
Training loss: 2.607239174603363
Validation loss: 2.604786571594387

Epoch: 6| Step: 4
Training loss: 2.2217223982845073
Validation loss: 2.614680088202394

Epoch: 6| Step: 5
Training loss: 2.7725111582938253
Validation loss: 2.609623660925119

Epoch: 6| Step: 6
Training loss: 3.589554967046778
Validation loss: 2.609580954576579

Epoch: 6| Step: 7
Training loss: 2.239574757640891
Validation loss: 2.6203985937256484

Epoch: 6| Step: 8
Training loss: 2.5823315144293613
Validation loss: 2.6089990944512063

Epoch: 6| Step: 9
Training loss: 2.422287542831162
Validation loss: 2.611307601681779

Epoch: 6| Step: 10
Training loss: 2.39121473430945
Validation loss: 2.601014581365206

Epoch: 6| Step: 11
Training loss: 3.07230566814734
Validation loss: 2.6339747031282594

Epoch: 6| Step: 12
Training loss: 2.975228879442857
Validation loss: 2.6311471435484477

Epoch: 6| Step: 13
Training loss: 3.1684365262305563
Validation loss: 2.628030376519175

Epoch: 102| Step: 0
Training loss: 2.7696876643121726
Validation loss: 2.608727222266163

Epoch: 6| Step: 1
Training loss: 1.7993096484778117
Validation loss: 2.6252667964864282

Epoch: 6| Step: 2
Training loss: 2.9566863046515044
Validation loss: 2.618877040268011

Epoch: 6| Step: 3
Training loss: 3.2054286209558573
Validation loss: 2.6218246341504248

Epoch: 6| Step: 4
Training loss: 2.390732307768318
Validation loss: 2.6322992539704404

Epoch: 6| Step: 5
Training loss: 2.5131324123983827
Validation loss: 2.638993772665079

Epoch: 6| Step: 6
Training loss: 3.213966147870603
Validation loss: 2.6277557972904746

Epoch: 6| Step: 7
Training loss: 2.5625264236204335
Validation loss: 2.616448127679105

Epoch: 6| Step: 8
Training loss: 3.0914444472522513
Validation loss: 2.624939547192774

Epoch: 6| Step: 9
Training loss: 2.65283791793993
Validation loss: 2.6245637424709143

Epoch: 6| Step: 10
Training loss: 2.2768177190502645
Validation loss: 2.617767138538591

Epoch: 6| Step: 11
Training loss: 2.453278166247425
Validation loss: 2.6015540066216145

Epoch: 6| Step: 12
Training loss: 2.686268013973198
Validation loss: 2.6225210410172712

Epoch: 6| Step: 13
Training loss: 3.204588020971693
Validation loss: 2.6121545618495023

Epoch: 103| Step: 0
Training loss: 2.6960346526061154
Validation loss: 2.6260440159553866

Epoch: 6| Step: 1
Training loss: 2.7181772966193605
Validation loss: 2.629736263506004

Epoch: 6| Step: 2
Training loss: 1.6414269076994266
Validation loss: 2.6125163037811485

Epoch: 6| Step: 3
Training loss: 2.5860044349697286
Validation loss: 2.6179594637356742

Epoch: 6| Step: 4
Training loss: 3.151246741481187
Validation loss: 2.606105035465658

Epoch: 6| Step: 5
Training loss: 3.1018713501865145
Validation loss: 2.6152961608047667

Epoch: 6| Step: 6
Training loss: 2.262888340789996
Validation loss: 2.615862698868442

Epoch: 6| Step: 7
Training loss: 2.6919256630959865
Validation loss: 2.6141162761234025

Epoch: 6| Step: 8
Training loss: 2.9528889233722313
Validation loss: 2.6185690649302513

Epoch: 6| Step: 9
Training loss: 2.506219185428065
Validation loss: 2.6173143376002876

Epoch: 6| Step: 10
Training loss: 1.8042535301365303
Validation loss: 2.600665592335657

Epoch: 6| Step: 11
Training loss: 2.977590948937059
Validation loss: 2.6089029232039165

Epoch: 6| Step: 12
Training loss: 3.312944490372433
Validation loss: 2.600118088111169

Epoch: 6| Step: 13
Training loss: 2.9285489324044605
Validation loss: 2.6220290701506865

Epoch: 104| Step: 0
Training loss: 2.4451514242825327
Validation loss: 2.6031452224998337

Epoch: 6| Step: 1
Training loss: 3.0521276338419594
Validation loss: 2.601492707435005

Epoch: 6| Step: 2
Training loss: 2.489511230786656
Validation loss: 2.6215525890113303

Epoch: 6| Step: 3
Training loss: 2.9225546306532633
Validation loss: 2.614352612982204

Epoch: 6| Step: 4
Training loss: 2.4440539353970157
Validation loss: 2.5929533012475754

Epoch: 6| Step: 5
Training loss: 2.6642166943268397
Validation loss: 2.60437755559382

Epoch: 6| Step: 6
Training loss: 2.54969434963297
Validation loss: 2.609965157881936

Epoch: 6| Step: 7
Training loss: 2.313067289311228
Validation loss: 2.593488767801922

Epoch: 6| Step: 8
Training loss: 2.8328869598921265
Validation loss: 2.6087870945961162

Epoch: 6| Step: 9
Training loss: 2.487109712433227
Validation loss: 2.6202053263025715

Epoch: 6| Step: 10
Training loss: 3.233506532991911
Validation loss: 2.6075150982605617

Epoch: 6| Step: 11
Training loss: 2.6083566654449584
Validation loss: 2.6147199316506327

Epoch: 6| Step: 12
Training loss: 2.799076684215467
Validation loss: 2.620418602168797

Epoch: 6| Step: 13
Training loss: 3.0482113768505994
Validation loss: 2.6060242178626503

Epoch: 105| Step: 0
Training loss: 2.7049365726163415
Validation loss: 2.6149276721058725

Epoch: 6| Step: 1
Training loss: 2.578776699118405
Validation loss: 2.6162601479134406

Epoch: 6| Step: 2
Training loss: 3.2613763503853
Validation loss: 2.5997771180212066

Epoch: 6| Step: 3
Training loss: 2.838181125713431
Validation loss: 2.605969898328969

Epoch: 6| Step: 4
Training loss: 2.171024732395252
Validation loss: 2.6022280880911337

Epoch: 6| Step: 5
Training loss: 2.9917737709644525
Validation loss: 2.608461562640691

Epoch: 6| Step: 6
Training loss: 3.558892816398561
Validation loss: 2.6007468948483328

Epoch: 6| Step: 7
Training loss: 2.967883656229068
Validation loss: 2.596290708971361

Epoch: 6| Step: 8
Training loss: 2.4546768236808325
Validation loss: 2.6082948656366796

Epoch: 6| Step: 9
Training loss: 2.0843010244439375
Validation loss: 2.627674792883824

Epoch: 6| Step: 10
Training loss: 2.76482780734357
Validation loss: 2.6169338592570264

Epoch: 6| Step: 11
Training loss: 2.5171723908172785
Validation loss: 2.6069759043885727

Epoch: 6| Step: 12
Training loss: 2.185695557910318
Validation loss: 2.598037211908699

Epoch: 6| Step: 13
Training loss: 1.9522019303107412
Validation loss: 2.595517902813127

Epoch: 106| Step: 0
Training loss: 2.5380314538207553
Validation loss: 2.601523007870973

Epoch: 6| Step: 1
Training loss: 2.6268247892095062
Validation loss: 2.6058553899635792

Epoch: 6| Step: 2
Training loss: 2.3192909123919128
Validation loss: 2.6075182257346756

Epoch: 6| Step: 3
Training loss: 2.6962096559409217
Validation loss: 2.6045747751376958

Epoch: 6| Step: 4
Training loss: 2.848216144374953
Validation loss: 2.603321046105254

Epoch: 6| Step: 5
Training loss: 2.9056681388923313
Validation loss: 2.6107239925693504

Epoch: 6| Step: 6
Training loss: 3.3622671053755715
Validation loss: 2.594051345061252

Epoch: 6| Step: 7
Training loss: 2.6664475311204345
Validation loss: 2.6140308918367254

Epoch: 6| Step: 8
Training loss: 2.693036431418496
Validation loss: 2.606112230279938

Epoch: 6| Step: 9
Training loss: 2.9538673396298343
Validation loss: 2.6050930168911757

Epoch: 6| Step: 10
Training loss: 2.255172611743621
Validation loss: 2.603088235018737

Epoch: 6| Step: 11
Training loss: 2.795445508441852
Validation loss: 2.5827659045944413

Epoch: 6| Step: 12
Training loss: 2.5825981406575687
Validation loss: 2.6004021771332364

Epoch: 6| Step: 13
Training loss: 2.124172386120828
Validation loss: 2.580559192367633

Epoch: 107| Step: 0
Training loss: 2.8378568517325347
Validation loss: 2.6030864957803916

Epoch: 6| Step: 1
Training loss: 2.3480279155416968
Validation loss: 2.6081426199747506

Epoch: 6| Step: 2
Training loss: 2.676336924082481
Validation loss: 2.6031343189949148

Epoch: 6| Step: 3
Training loss: 2.2665953564178825
Validation loss: 2.6099236436995703

Epoch: 6| Step: 4
Training loss: 2.975669106002542
Validation loss: 2.606059384230819

Epoch: 6| Step: 5
Training loss: 2.375567518992563
Validation loss: 2.605199638670004

Epoch: 6| Step: 6
Training loss: 2.375355442955264
Validation loss: 2.6156826541073595

Epoch: 6| Step: 7
Training loss: 2.5493273016041598
Validation loss: 2.597524014158176

Epoch: 6| Step: 8
Training loss: 2.4073521455578883
Validation loss: 2.590878033888948

Epoch: 6| Step: 9
Training loss: 2.6671814322332765
Validation loss: 2.614464542435953

Epoch: 6| Step: 10
Training loss: 2.4142763111031345
Validation loss: 2.607421115962547

Epoch: 6| Step: 11
Training loss: 3.508242438461037
Validation loss: 2.6088899728164217

Epoch: 6| Step: 12
Training loss: 2.392727992755226
Validation loss: 2.60357251155268

Epoch: 6| Step: 13
Training loss: 3.9018071658195415
Validation loss: 2.6181110866415085

Epoch: 108| Step: 0
Training loss: 2.661141413403532
Validation loss: 2.6071668358119853

Epoch: 6| Step: 1
Training loss: 2.2712286742095693
Validation loss: 2.6199197181106615

Epoch: 6| Step: 2
Training loss: 2.3234461934915327
Validation loss: 2.6118714085600785

Epoch: 6| Step: 3
Training loss: 3.082190911976592
Validation loss: 2.6098393943219396

Epoch: 6| Step: 4
Training loss: 2.7908478480231467
Validation loss: 2.6002564585360224

Epoch: 6| Step: 5
Training loss: 2.689105064680285
Validation loss: 2.622061230478442

Epoch: 6| Step: 6
Training loss: 2.7041303936877146
Validation loss: 2.605068475590389

Epoch: 6| Step: 7
Training loss: 2.351740123846047
Validation loss: 2.5840188184430906

Epoch: 6| Step: 8
Training loss: 2.758939863826447
Validation loss: 2.601234977848975

Epoch: 6| Step: 9
Training loss: 3.3165356506336288
Validation loss: 2.6092907653302935

Epoch: 6| Step: 10
Training loss: 2.612321298136442
Validation loss: 2.6035605242418574

Epoch: 6| Step: 11
Training loss: 2.7233992538349154
Validation loss: 2.626969951394751

Epoch: 6| Step: 12
Training loss: 2.5172498679885127
Validation loss: 2.6095818632922754

Epoch: 6| Step: 13
Training loss: 2.660021628671925
Validation loss: 2.609189255874981

Epoch: 109| Step: 0
Training loss: 2.735958665278998
Validation loss: 2.6166658143882806

Epoch: 6| Step: 1
Training loss: 2.961857554635299
Validation loss: 2.5982274158706677

Epoch: 6| Step: 2
Training loss: 2.535958796404099
Validation loss: 2.6079485632417674

Epoch: 6| Step: 3
Training loss: 2.5915562188102164
Validation loss: 2.5983290684326716

Epoch: 6| Step: 4
Training loss: 3.1317528052577437
Validation loss: 2.6197242468005593

Epoch: 6| Step: 5
Training loss: 1.8488793871148395
Validation loss: 2.6078143847645663

Epoch: 6| Step: 6
Training loss: 2.6879338646143753
Validation loss: 2.612631708989622

Epoch: 6| Step: 7
Training loss: 2.669569749920148
Validation loss: 2.6032719298632405

Epoch: 6| Step: 8
Training loss: 2.5808362171952277
Validation loss: 2.592346658820917

Epoch: 6| Step: 9
Training loss: 2.6654883006419996
Validation loss: 2.59276978302625

Epoch: 6| Step: 10
Training loss: 3.187390045064683
Validation loss: 2.609220139966275

Epoch: 6| Step: 11
Training loss: 2.9498185312092384
Validation loss: 2.592365164538822

Epoch: 6| Step: 12
Training loss: 2.096062479201784
Validation loss: 2.5829057098076817

Epoch: 6| Step: 13
Training loss: 2.5617122835041037
Validation loss: 2.6144764601409984

Epoch: 110| Step: 0
Training loss: 3.0207722274037008
Validation loss: 2.592972624235717

Epoch: 6| Step: 1
Training loss: 2.873373483729874
Validation loss: 2.604381335526908

Epoch: 6| Step: 2
Training loss: 3.049359213633174
Validation loss: 2.601848276806406

Epoch: 6| Step: 3
Training loss: 3.0195258807964875
Validation loss: 2.6107255077415266

Epoch: 6| Step: 4
Training loss: 1.950384063067897
Validation loss: 2.603631417345298

Epoch: 6| Step: 5
Training loss: 2.4595639225329924
Validation loss: 2.611233468993585

Epoch: 6| Step: 6
Training loss: 2.686236062135745
Validation loss: 2.606151692214047

Epoch: 6| Step: 7
Training loss: 3.150975115785247
Validation loss: 2.602590737902111

Epoch: 6| Step: 8
Training loss: 2.6300022057063495
Validation loss: 2.6174616398721144

Epoch: 6| Step: 9
Training loss: 3.3818428464681807
Validation loss: 2.605988108587663

Epoch: 6| Step: 10
Training loss: 2.460482988316952
Validation loss: 2.618896187156138

Epoch: 6| Step: 11
Training loss: 2.117165428131029
Validation loss: 2.618082760342494

Epoch: 6| Step: 12
Training loss: 1.4813036816362146
Validation loss: 2.6021136618602836

Epoch: 6| Step: 13
Training loss: 2.713945726024858
Validation loss: 2.608669636378783

Epoch: 111| Step: 0
Training loss: 2.153076711702825
Validation loss: 2.6051064870521525

Epoch: 6| Step: 1
Training loss: 1.8224665785499718
Validation loss: 2.6023766999056863

Epoch: 6| Step: 2
Training loss: 1.9134109322277972
Validation loss: 2.608629203246655

Epoch: 6| Step: 3
Training loss: 2.9310045867540437
Validation loss: 2.6055364455914427

Epoch: 6| Step: 4
Training loss: 2.4157803543490837
Validation loss: 2.598643072437398

Epoch: 6| Step: 5
Training loss: 2.479210626121612
Validation loss: 2.597781895792324

Epoch: 6| Step: 6
Training loss: 2.423748645201723
Validation loss: 2.604517429150638

Epoch: 6| Step: 7
Training loss: 2.741045765781046
Validation loss: 2.610172487096875

Epoch: 6| Step: 8
Training loss: 2.8711904081306088
Validation loss: 2.6105812315178687

Epoch: 6| Step: 9
Training loss: 3.0548030119224365
Validation loss: 2.615531123702997

Epoch: 6| Step: 10
Training loss: 3.5302816768143823
Validation loss: 2.6056746620886804

Epoch: 6| Step: 11
Training loss: 2.70256362995401
Validation loss: 2.599642517781406

Epoch: 6| Step: 12
Training loss: 2.9331673669102365
Validation loss: 2.611957950943666

Epoch: 6| Step: 13
Training loss: 3.440709505767113
Validation loss: 2.611248103273011

Epoch: 112| Step: 0
Training loss: 2.106370156140695
Validation loss: 2.605113399240972

Epoch: 6| Step: 1
Training loss: 2.434136050130903
Validation loss: 2.595871182657615

Epoch: 6| Step: 2
Training loss: 3.3040079631109083
Validation loss: 2.612301818950352

Epoch: 6| Step: 3
Training loss: 2.848781787114145
Validation loss: 2.6135573582566103

Epoch: 6| Step: 4
Training loss: 2.543318810811042
Validation loss: 2.595211706882246

Epoch: 6| Step: 5
Training loss: 2.660459615967621
Validation loss: 2.5902069737385527

Epoch: 6| Step: 6
Training loss: 2.3996193424982226
Validation loss: 2.6017454679733625

Epoch: 6| Step: 7
Training loss: 2.8758018039009268
Validation loss: 2.603536689278661

Epoch: 6| Step: 8
Training loss: 2.911579782390246
Validation loss: 2.603621473443083

Epoch: 6| Step: 9
Training loss: 2.3759773652639415
Validation loss: 2.618306268131102

Epoch: 6| Step: 10
Training loss: 2.2302867060192377
Validation loss: 2.603505628467063

Epoch: 6| Step: 11
Training loss: 2.2752447646382294
Validation loss: 2.6033867955819505

Epoch: 6| Step: 12
Training loss: 2.9612215655705993
Validation loss: 2.5944764787417616

Epoch: 6| Step: 13
Training loss: 3.782495214808451
Validation loss: 2.600598511265314

Epoch: 113| Step: 0
Training loss: 2.630076268471794
Validation loss: 2.589531284683327

Epoch: 6| Step: 1
Training loss: 3.1125571678457424
Validation loss: 2.592006286499024

Epoch: 6| Step: 2
Training loss: 2.6022987584004285
Validation loss: 2.5894297055362276

Epoch: 6| Step: 3
Training loss: 2.6149218417389304
Validation loss: 2.6023515034942806

Epoch: 6| Step: 4
Training loss: 2.453157558346589
Validation loss: 2.5900438944991833

Epoch: 6| Step: 5
Training loss: 2.6153075796968275
Validation loss: 2.599625693987187

Epoch: 6| Step: 6
Training loss: 2.7095540059056193
Validation loss: 2.5955037300039647

Epoch: 6| Step: 7
Training loss: 2.4029371567667175
Validation loss: 2.609068556518748

Epoch: 6| Step: 8
Training loss: 2.2660229563615024
Validation loss: 2.601120837117415

Epoch: 6| Step: 9
Training loss: 2.120041166301722
Validation loss: 2.5946538610251237

Epoch: 6| Step: 10
Training loss: 2.564292559859356
Validation loss: 2.584194321376392

Epoch: 6| Step: 11
Training loss: 3.868663159506606
Validation loss: 2.5983754889004618

Epoch: 6| Step: 12
Training loss: 2.702845123443447
Validation loss: 2.5947400983328714

Epoch: 6| Step: 13
Training loss: 2.1125782698177025
Validation loss: 2.6103890629471773

Epoch: 114| Step: 0
Training loss: 2.2323077048329147
Validation loss: 2.6108127911724863

Epoch: 6| Step: 1
Training loss: 3.1190268842756046
Validation loss: 2.592392617789551

Epoch: 6| Step: 2
Training loss: 3.048873949897851
Validation loss: 2.600806702491956

Epoch: 6| Step: 3
Training loss: 2.9487310751598357
Validation loss: 2.5951414224668974

Epoch: 6| Step: 4
Training loss: 2.7146645027100806
Validation loss: 2.621644318231799

Epoch: 6| Step: 5
Training loss: 1.9418767899970628
Validation loss: 2.6125279978084865

Epoch: 6| Step: 6
Training loss: 1.9312946869948475
Validation loss: 2.5819827693241217

Epoch: 6| Step: 7
Training loss: 2.7512001539859803
Validation loss: 2.585169761329192

Epoch: 6| Step: 8
Training loss: 3.13401470756853
Validation loss: 2.6017893237452454

Epoch: 6| Step: 9
Training loss: 2.096389245792166
Validation loss: 2.5930056452123336

Epoch: 6| Step: 10
Training loss: 2.1242802466876363
Validation loss: 2.602766381286561

Epoch: 6| Step: 11
Training loss: 3.144216732621073
Validation loss: 2.601010803438791

Epoch: 6| Step: 12
Training loss: 2.842109961812558
Validation loss: 2.5951950183461876

Epoch: 6| Step: 13
Training loss: 3.0127787227614675
Validation loss: 2.6052833069636914

Epoch: 115| Step: 0
Training loss: 3.211220239224443
Validation loss: 2.587313194996222

Epoch: 6| Step: 1
Training loss: 3.086399323878553
Validation loss: 2.589877658198163

Epoch: 6| Step: 2
Training loss: 3.6078596360674084
Validation loss: 2.5884947809790706

Epoch: 6| Step: 3
Training loss: 2.060962450687671
Validation loss: 2.583951158374939

Epoch: 6| Step: 4
Training loss: 2.1481219805601075
Validation loss: 2.5950701561625147

Epoch: 6| Step: 5
Training loss: 2.5136578373491094
Validation loss: 2.605390336192931

Epoch: 6| Step: 6
Training loss: 2.9873016546956657
Validation loss: 2.5910053876556587

Epoch: 6| Step: 7
Training loss: 2.1139180181264408
Validation loss: 2.6041020457135855

Epoch: 6| Step: 8
Training loss: 1.55080784695588
Validation loss: 2.5989504976027256

Epoch: 6| Step: 9
Training loss: 2.6596089386836694
Validation loss: 2.58924636035002

Epoch: 6| Step: 10
Training loss: 2.0302203576514937
Validation loss: 2.5887544414562793

Epoch: 6| Step: 11
Training loss: 2.4725634902501232
Validation loss: 2.5841937380530515

Epoch: 6| Step: 12
Training loss: 3.353482494512744
Validation loss: 2.586370083674317

Epoch: 6| Step: 13
Training loss: 2.882938868122941
Validation loss: 2.578017249517217

Epoch: 116| Step: 0
Training loss: 3.299042048273907
Validation loss: 2.593421950871955

Epoch: 6| Step: 1
Training loss: 2.038529600466061
Validation loss: 2.597776758206922

Epoch: 6| Step: 2
Training loss: 2.9021045283310136
Validation loss: 2.613316976958243

Epoch: 6| Step: 3
Training loss: 3.0810895092624158
Validation loss: 2.5987166547321623

Epoch: 6| Step: 4
Training loss: 2.410918030378997
Validation loss: 2.611209952459585

Epoch: 6| Step: 5
Training loss: 1.9973276881828714
Validation loss: 2.5880435627691893

Epoch: 6| Step: 6
Training loss: 3.0219981786796892
Validation loss: 2.5969633185008254

Epoch: 6| Step: 7
Training loss: 2.335656598913221
Validation loss: 2.6143904992648026

Epoch: 6| Step: 8
Training loss: 2.929021734248851
Validation loss: 2.6038165300491896

Epoch: 6| Step: 9
Training loss: 2.3597328975626364
Validation loss: 2.5833046528166577

Epoch: 6| Step: 10
Training loss: 2.5936156088701168
Validation loss: 2.5963280530912654

Epoch: 6| Step: 11
Training loss: 2.882850543342305
Validation loss: 2.593475538791427

Epoch: 6| Step: 12
Training loss: 2.283643433705426
Validation loss: 2.5997352281488704

Epoch: 6| Step: 13
Training loss: 2.856911019728475
Validation loss: 2.5981415705955726

Epoch: 117| Step: 0
Training loss: 2.8223181696557607
Validation loss: 2.590106663267283

Epoch: 6| Step: 1
Training loss: 2.0545487157560998
Validation loss: 2.6069717338825797

Epoch: 6| Step: 2
Training loss: 2.9656751268690713
Validation loss: 2.600704892449024

Epoch: 6| Step: 3
Training loss: 2.9422870345658687
Validation loss: 2.6026947445899182

Epoch: 6| Step: 4
Training loss: 3.3511228473108168
Validation loss: 2.6067970966825933

Epoch: 6| Step: 5
Training loss: 3.055774700128322
Validation loss: 2.606408985783705

Epoch: 6| Step: 6
Training loss: 3.089433838169979
Validation loss: 2.6021519470219503

Epoch: 6| Step: 7
Training loss: 2.449367098901401
Validation loss: 2.6032401016969606

Epoch: 6| Step: 8
Training loss: 1.9059036440515391
Validation loss: 2.5953356189187895

Epoch: 6| Step: 9
Training loss: 2.560836624290701
Validation loss: 2.6030994779946375

Epoch: 6| Step: 10
Training loss: 2.823176316898466
Validation loss: 2.5992322622814243

Epoch: 6| Step: 11
Training loss: 2.5729509626772042
Validation loss: 2.6105258155917994

Epoch: 6| Step: 12
Training loss: 1.9207772321914263
Validation loss: 2.6011037035513955

Epoch: 6| Step: 13
Training loss: 2.1450574885847455
Validation loss: 2.6290724016966487

Epoch: 118| Step: 0
Training loss: 2.4761323284476133
Validation loss: 2.6133457541730403

Epoch: 6| Step: 1
Training loss: 2.9688759224939094
Validation loss: 2.5935532749421584

Epoch: 6| Step: 2
Training loss: 2.5695178070134252
Validation loss: 2.6083002193780818

Epoch: 6| Step: 3
Training loss: 3.041497752755555
Validation loss: 2.5881754073690706

Epoch: 6| Step: 4
Training loss: 3.183020342340881
Validation loss: 2.5992305756961303

Epoch: 6| Step: 5
Training loss: 1.6918710682220488
Validation loss: 2.5954346802824153

Epoch: 6| Step: 6
Training loss: 2.2381263666007634
Validation loss: 2.599150208145176

Epoch: 6| Step: 7
Training loss: 1.4306030677057495
Validation loss: 2.6112836813323974

Epoch: 6| Step: 8
Training loss: 2.5055583199173066
Validation loss: 2.58731170525203

Epoch: 6| Step: 9
Training loss: 2.5068508693129994
Validation loss: 2.60623068757229

Epoch: 6| Step: 10
Training loss: 3.2466539617938706
Validation loss: 2.615786970360446

Epoch: 6| Step: 11
Training loss: 3.197188668323997
Validation loss: 2.59424178789498

Epoch: 6| Step: 12
Training loss: 2.8349870082012583
Validation loss: 2.593826752411791

Epoch: 6| Step: 13
Training loss: 2.601124494642115
Validation loss: 2.6023095673848102

Epoch: 119| Step: 0
Training loss: 2.482818787880696
Validation loss: 2.6016937028646625

Epoch: 6| Step: 1
Training loss: 3.065877803290913
Validation loss: 2.590321609237804

Epoch: 6| Step: 2
Training loss: 2.6220661298267385
Validation loss: 2.5922613852422014

Epoch: 6| Step: 3
Training loss: 2.393487351154018
Validation loss: 2.5981467459416328

Epoch: 6| Step: 4
Training loss: 3.8832020247584196
Validation loss: 2.594153828324214

Epoch: 6| Step: 5
Training loss: 2.199634140110986
Validation loss: 2.611394040035918

Epoch: 6| Step: 6
Training loss: 1.9278957682012001
Validation loss: 2.617806573636552

Epoch: 6| Step: 7
Training loss: 2.5750256953762896
Validation loss: 2.5811729196575848

Epoch: 6| Step: 8
Training loss: 2.355599723957633
Validation loss: 2.595685821351825

Epoch: 6| Step: 9
Training loss: 2.3721288090383967
Validation loss: 2.5947830449883025

Epoch: 6| Step: 10
Training loss: 2.478027680495667
Validation loss: 2.589625871687924

Epoch: 6| Step: 11
Training loss: 2.931397612866886
Validation loss: 2.5959416132245057

Epoch: 6| Step: 12
Training loss: 2.742682344395855
Validation loss: 2.5959619311452777

Epoch: 6| Step: 13
Training loss: 2.832032765355198
Validation loss: 2.601141644826093

Epoch: 120| Step: 0
Training loss: 2.4630131762853353
Validation loss: 2.5969571259848334

Epoch: 6| Step: 1
Training loss: 2.5086811023141045
Validation loss: 2.578029475923723

Epoch: 6| Step: 2
Training loss: 3.2176937110760466
Validation loss: 2.6068654491228074

Epoch: 6| Step: 3
Training loss: 2.47262423767291
Validation loss: 2.5944176556002287

Epoch: 6| Step: 4
Training loss: 1.8722589165965124
Validation loss: 2.5814070875303137

Epoch: 6| Step: 5
Training loss: 2.5626859830028432
Validation loss: 2.594149692546106

Epoch: 6| Step: 6
Training loss: 3.367972510363825
Validation loss: 2.5850036360455513

Epoch: 6| Step: 7
Training loss: 2.9534923183741015
Validation loss: 2.595681262828738

Epoch: 6| Step: 8
Training loss: 1.8604041705365084
Validation loss: 2.570494275485611

Epoch: 6| Step: 9
Training loss: 3.213245314293495
Validation loss: 2.592521032366189

Epoch: 6| Step: 10
Training loss: 2.2952868102462234
Validation loss: 2.5967797855272914

Epoch: 6| Step: 11
Training loss: 2.63343074795455
Validation loss: 2.5969883431041887

Epoch: 6| Step: 12
Training loss: 1.9711765896342146
Validation loss: 2.6003806576237434

Epoch: 6| Step: 13
Training loss: 3.434528106525576
Validation loss: 2.620086490564309

Epoch: 121| Step: 0
Training loss: 2.9652474069541386
Validation loss: 2.5960590923369233

Epoch: 6| Step: 1
Training loss: 2.826700262673777
Validation loss: 2.5994602183784346

Epoch: 6| Step: 2
Training loss: 2.6462748201744204
Validation loss: 2.6179568540292237

Epoch: 6| Step: 3
Training loss: 1.859946539736094
Validation loss: 2.589211965654615

Epoch: 6| Step: 4
Training loss: 2.8305250911385578
Validation loss: 2.581473372308955

Epoch: 6| Step: 5
Training loss: 3.274357122557043
Validation loss: 2.605982970456681

Epoch: 6| Step: 6
Training loss: 2.1613949195720923
Validation loss: 2.613073113761203

Epoch: 6| Step: 7
Training loss: 2.403134595755082
Validation loss: 2.6106279634246006

Epoch: 6| Step: 8
Training loss: 2.7295538552403076
Validation loss: 2.597888120939186

Epoch: 6| Step: 9
Training loss: 2.2796449632447735
Validation loss: 2.592567094049821

Epoch: 6| Step: 10
Training loss: 3.250675718047152
Validation loss: 2.606829152847019

Epoch: 6| Step: 11
Training loss: 2.8791169253817275
Validation loss: 2.587817265869097

Epoch: 6| Step: 12
Training loss: 2.772065158931393
Validation loss: 2.589039494189605

Epoch: 6| Step: 13
Training loss: 1.563083082122845
Validation loss: 2.598185501012885

Epoch: 122| Step: 0
Training loss: 2.522719620670395
Validation loss: 2.6008002224277065

Epoch: 6| Step: 1
Training loss: 2.9987087649857145
Validation loss: 2.590565581498584

Epoch: 6| Step: 2
Training loss: 2.2419142074708542
Validation loss: 2.5872108192854943

Epoch: 6| Step: 3
Training loss: 2.436333499454199
Validation loss: 2.5850333304281663

Epoch: 6| Step: 4
Training loss: 2.939423438647852
Validation loss: 2.6240662390156615

Epoch: 6| Step: 5
Training loss: 3.285624902705989
Validation loss: 2.574222004568906

Epoch: 6| Step: 6
Training loss: 2.5931301985013007
Validation loss: 2.592460722075382

Epoch: 6| Step: 7
Training loss: 2.345750184107211
Validation loss: 2.6008108523268727

Epoch: 6| Step: 8
Training loss: 2.6561650879695597
Validation loss: 2.6085938513822726

Epoch: 6| Step: 9
Training loss: 2.52767786473641
Validation loss: 2.5849872168155876

Epoch: 6| Step: 10
Training loss: 2.529606603562424
Validation loss: 2.610631710739722

Epoch: 6| Step: 11
Training loss: 2.7676751248328717
Validation loss: 2.5982398935011606

Epoch: 6| Step: 12
Training loss: 2.2130131228851235
Validation loss: 2.5955131963309674

Epoch: 6| Step: 13
Training loss: 3.0135164943944317
Validation loss: 2.599416659618108

Epoch: 123| Step: 0
Training loss: 3.243799750914912
Validation loss: 2.5955446797192123

Epoch: 6| Step: 1
Training loss: 3.0484410100669344
Validation loss: 2.584049305919197

Epoch: 6| Step: 2
Training loss: 1.973686085415669
Validation loss: 2.590161675749586

Epoch: 6| Step: 3
Training loss: 2.864947116756525
Validation loss: 2.585840830941471

Epoch: 6| Step: 4
Training loss: 2.3767460879430797
Validation loss: 2.592974441443424

Epoch: 6| Step: 5
Training loss: 2.5134195647215756
Validation loss: 2.5814173513796006

Epoch: 6| Step: 6
Training loss: 2.3401306689694836
Validation loss: 2.594711461564873

Epoch: 6| Step: 7
Training loss: 3.274239453245957
Validation loss: 2.5847226997148716

Epoch: 6| Step: 8
Training loss: 2.9090769155122405
Validation loss: 2.5946934656091942

Epoch: 6| Step: 9
Training loss: 2.4450778056365516
Validation loss: 2.590094424585456

Epoch: 6| Step: 10
Training loss: 2.4048416177540535
Validation loss: 2.5660320184005294

Epoch: 6| Step: 11
Training loss: 1.970695987079801
Validation loss: 2.588264591302136

Epoch: 6| Step: 12
Training loss: 2.493724002559213
Validation loss: 2.5954423215052564

Epoch: 6| Step: 13
Training loss: 3.094295569201507
Validation loss: 2.583033710719533

Epoch: 124| Step: 0
Training loss: 2.739816711309767
Validation loss: 2.5909068515537172

Epoch: 6| Step: 1
Training loss: 3.1129537718882183
Validation loss: 2.5935371490488697

Epoch: 6| Step: 2
Training loss: 2.7353972349810713
Validation loss: 2.6124613753992936

Epoch: 6| Step: 3
Training loss: 2.3960393291869186
Validation loss: 2.5946296498021293

Epoch: 6| Step: 4
Training loss: 3.0718303937186113
Validation loss: 2.6179220580210534

Epoch: 6| Step: 5
Training loss: 2.4359277398364743
Validation loss: 2.5860080613327554

Epoch: 6| Step: 6
Training loss: 2.9290455025745747
Validation loss: 2.610072885499943

Epoch: 6| Step: 7
Training loss: 2.7144644273277523
Validation loss: 2.5902723474542872

Epoch: 6| Step: 8
Training loss: 1.3713765518364676
Validation loss: 2.595924676564567

Epoch: 6| Step: 9
Training loss: 2.0172415468287266
Validation loss: 2.599262356302409

Epoch: 6| Step: 10
Training loss: 3.0148184690974893
Validation loss: 2.578427335003944

Epoch: 6| Step: 11
Training loss: 2.3985227886530467
Validation loss: 2.600289330818868

Epoch: 6| Step: 12
Training loss: 3.0688232226677483
Validation loss: 2.591887488696344

Epoch: 6| Step: 13
Training loss: 2.4586449010793063
Validation loss: 2.576389762691716

Epoch: 125| Step: 0
Training loss: 3.483539292910161
Validation loss: 2.596688619374444

Epoch: 6| Step: 1
Training loss: 2.6141999002795915
Validation loss: 2.5839293014439826

Epoch: 6| Step: 2
Training loss: 2.4182812022035214
Validation loss: 2.59395490524664

Epoch: 6| Step: 3
Training loss: 1.905776668629711
Validation loss: 2.5946734549163346

Epoch: 6| Step: 4
Training loss: 2.7473258107499006
Validation loss: 2.595871553001558

Epoch: 6| Step: 5
Training loss: 2.7116564586082283
Validation loss: 2.594836137485315

Epoch: 6| Step: 6
Training loss: 2.7674585503676346
Validation loss: 2.6021713544084455

Epoch: 6| Step: 7
Training loss: 2.621816521266372
Validation loss: 2.581294844932878

Epoch: 6| Step: 8
Training loss: 2.311293828702369
Validation loss: 2.5864853684578386

Epoch: 6| Step: 9
Training loss: 2.74269086342268
Validation loss: 2.5996312519654796

Epoch: 6| Step: 10
Training loss: 1.9903830939704923
Validation loss: 2.595841313010139

Epoch: 6| Step: 11
Training loss: 2.576481428195283
Validation loss: 2.6086088886607985

Epoch: 6| Step: 12
Training loss: 2.7859284559649717
Validation loss: 2.5885482738152477

Epoch: 6| Step: 13
Training loss: 3.152852864615329
Validation loss: 2.585968493253664

Epoch: 126| Step: 0
Training loss: 2.2686946725535697
Validation loss: 2.584714520959708

Epoch: 6| Step: 1
Training loss: 2.50187593649228
Validation loss: 2.5766509156619315

Epoch: 6| Step: 2
Training loss: 2.39922933523364
Validation loss: 2.597293061236525

Epoch: 6| Step: 3
Training loss: 2.500112435673548
Validation loss: 2.594482478567957

Epoch: 6| Step: 4
Training loss: 2.012312066443146
Validation loss: 2.6078515383076066

Epoch: 6| Step: 5
Training loss: 2.628568675797958
Validation loss: 2.591370282238001

Epoch: 6| Step: 6
Training loss: 2.957553510012524
Validation loss: 2.598313621892141

Epoch: 6| Step: 7
Training loss: 2.0695266095718194
Validation loss: 2.580405151322206

Epoch: 6| Step: 8
Training loss: 2.886555048904144
Validation loss: 2.615413824269895

Epoch: 6| Step: 9
Training loss: 2.52722997866266
Validation loss: 2.6125934890856115

Epoch: 6| Step: 10
Training loss: 2.566000617499214
Validation loss: 2.5802659711902587

Epoch: 6| Step: 11
Training loss: 3.5234759343455306
Validation loss: 2.600055041412887

Epoch: 6| Step: 12
Training loss: 2.893363686269064
Validation loss: 2.59402786053451

Epoch: 6| Step: 13
Training loss: 3.050187564773329
Validation loss: 2.599164766453384

Epoch: 127| Step: 0
Training loss: 2.019817870588009
Validation loss: 2.59145074316882

Epoch: 6| Step: 1
Training loss: 2.41754274821628
Validation loss: 2.5959567242858688

Epoch: 6| Step: 2
Training loss: 1.8721985551650653
Validation loss: 2.6081706443492294

Epoch: 6| Step: 3
Training loss: 3.1954377016940443
Validation loss: 2.6015884303028436

Epoch: 6| Step: 4
Training loss: 3.3394825165575512
Validation loss: 2.591082974308001

Epoch: 6| Step: 5
Training loss: 2.892848628736343
Validation loss: 2.6133231169741804

Epoch: 6| Step: 6
Training loss: 2.672235921832115
Validation loss: 2.581716525399925

Epoch: 6| Step: 7
Training loss: 2.3313499490620138
Validation loss: 2.5681607668728654

Epoch: 6| Step: 8
Training loss: 2.9390095829192546
Validation loss: 2.603934312524633

Epoch: 6| Step: 9
Training loss: 2.624741859459019
Validation loss: 2.5932509111020687

Epoch: 6| Step: 10
Training loss: 2.141424767554353
Validation loss: 2.5720568349410295

Epoch: 6| Step: 11
Training loss: 3.0604904744125125
Validation loss: 2.5976190256404195

Epoch: 6| Step: 12
Training loss: 2.067892019983402
Validation loss: 2.59080206885393

Epoch: 6| Step: 13
Training loss: 2.976770909339833
Validation loss: 2.570490412809185

Epoch: 128| Step: 0
Training loss: 2.7202998161567993
Validation loss: 2.5916873604495287

Epoch: 6| Step: 1
Training loss: 2.885489360752034
Validation loss: 2.5787945456878476

Epoch: 6| Step: 2
Training loss: 2.8653307315405736
Validation loss: 2.5906612677563685

Epoch: 6| Step: 3
Training loss: 2.554367185337554
Validation loss: 2.56913284863149

Epoch: 6| Step: 4
Training loss: 3.0658899346370205
Validation loss: 2.6154216580532474

Epoch: 6| Step: 5
Training loss: 2.6776327813684855
Validation loss: 2.6011513045058203

Epoch: 6| Step: 6
Training loss: 2.6114081953236954
Validation loss: 2.596444439971242

Epoch: 6| Step: 7
Training loss: 2.5780598025314436
Validation loss: 2.595767386500174

Epoch: 6| Step: 8
Training loss: 2.3285339815503794
Validation loss: 2.595727479294317

Epoch: 6| Step: 9
Training loss: 2.9890072009349877
Validation loss: 2.591359065044357

Epoch: 6| Step: 10
Training loss: 2.6861052331484268
Validation loss: 2.5932307963503147

Epoch: 6| Step: 11
Training loss: 1.9066151128592719
Validation loss: 2.5939092131347588

Epoch: 6| Step: 12
Training loss: 2.1051704605926465
Validation loss: 2.5932249893693187

Epoch: 6| Step: 13
Training loss: 2.9720071693015617
Validation loss: 2.591535261924904

Epoch: 129| Step: 0
Training loss: 2.5549503856104345
Validation loss: 2.5842338610666817

Epoch: 6| Step: 1
Training loss: 2.6165883759208106
Validation loss: 2.558064948442214

Epoch: 6| Step: 2
Training loss: 3.1665636514337656
Validation loss: 2.5796385641820403

Epoch: 6| Step: 3
Training loss: 1.9085448163162035
Validation loss: 2.586828914086405

Epoch: 6| Step: 4
Training loss: 2.548694077982548
Validation loss: 2.5833730611878973

Epoch: 6| Step: 5
Training loss: 2.4062832916731054
Validation loss: 2.5849314912184154

Epoch: 6| Step: 6
Training loss: 3.386191849601787
Validation loss: 2.567039525615896

Epoch: 6| Step: 7
Training loss: 2.722237640994601
Validation loss: 2.590450715321172

Epoch: 6| Step: 8
Training loss: 2.7588690876114663
Validation loss: 2.6213127096000757

Epoch: 6| Step: 9
Training loss: 2.6876727203934303
Validation loss: 2.606894228716741

Epoch: 6| Step: 10
Training loss: 2.0542959558166083
Validation loss: 2.6132115702842444

Epoch: 6| Step: 11
Training loss: 3.4783072561819783
Validation loss: 2.5971212241504578

Epoch: 6| Step: 12
Training loss: 1.3703331209586376
Validation loss: 2.5845929082675627

Epoch: 6| Step: 13
Training loss: 2.844073602059318
Validation loss: 2.598690950294306

Epoch: 130| Step: 0
Training loss: 2.961134931680447
Validation loss: 2.5945324528657743

Epoch: 6| Step: 1
Training loss: 2.3840108890924814
Validation loss: 2.6005891413268043

Epoch: 6| Step: 2
Training loss: 2.7901893711426036
Validation loss: 2.5932628284282004

Epoch: 6| Step: 3
Training loss: 3.242627658610414
Validation loss: 2.5898235058367955

Epoch: 6| Step: 4
Training loss: 2.962884509407828
Validation loss: 2.6084602879265972

Epoch: 6| Step: 5
Training loss: 2.6073490889887734
Validation loss: 2.5987052023986954

Epoch: 6| Step: 6
Training loss: 2.3463234569531197
Validation loss: 2.589417335938963

Epoch: 6| Step: 7
Training loss: 1.5760954090274941
Validation loss: 2.585222573277241

Epoch: 6| Step: 8
Training loss: 2.9625352559627482
Validation loss: 2.6010694479080967

Epoch: 6| Step: 9
Training loss: 1.6828892200659438
Validation loss: 2.5828965873443255

Epoch: 6| Step: 10
Training loss: 2.8548623418273062
Validation loss: 2.582062083625495

Epoch: 6| Step: 11
Training loss: 3.0079331410972276
Validation loss: 2.586802554376001

Epoch: 6| Step: 12
Training loss: 2.7485363272920096
Validation loss: 2.5964840947503656

Epoch: 6| Step: 13
Training loss: 1.44072370211741
Validation loss: 2.58068722423375

Epoch: 131| Step: 0
Training loss: 2.38624021037568
Validation loss: 2.5982466359946446

Epoch: 6| Step: 1
Training loss: 3.057374362812766
Validation loss: 2.5980964183473847

Epoch: 6| Step: 2
Training loss: 2.6365421490337666
Validation loss: 2.5869374203447233

Epoch: 6| Step: 3
Training loss: 2.210720739084487
Validation loss: 2.580055840784546

Epoch: 6| Step: 4
Training loss: 2.2122798659302116
Validation loss: 2.590439798464398

Epoch: 6| Step: 5
Training loss: 2.810960645087366
Validation loss: 2.5938121058291683

Epoch: 6| Step: 6
Training loss: 1.7438784206778744
Validation loss: 2.5951080503107407

Epoch: 6| Step: 7
Training loss: 2.3255733357334205
Validation loss: 2.5865231366255577

Epoch: 6| Step: 8
Training loss: 3.410524119038088
Validation loss: 2.5900554534262734

Epoch: 6| Step: 9
Training loss: 2.5705262069212114
Validation loss: 2.5915135332594854

Epoch: 6| Step: 10
Training loss: 2.1404858843296313
Validation loss: 2.5874622017432563

Epoch: 6| Step: 11
Training loss: 3.09121415218881
Validation loss: 2.595352553496092

Epoch: 6| Step: 12
Training loss: 2.9242139624134267
Validation loss: 2.568186181935839

Epoch: 6| Step: 13
Training loss: 2.8427462640405157
Validation loss: 2.578076359354321

Epoch: 132| Step: 0
Training loss: 2.9138023117128524
Validation loss: 2.604936461508421

Epoch: 6| Step: 1
Training loss: 2.061321962487235
Validation loss: 2.5884718224560115

Epoch: 6| Step: 2
Training loss: 3.1587805848175052
Validation loss: 2.5825009654034496

Epoch: 6| Step: 3
Training loss: 2.997685175147944
Validation loss: 2.5697438747832373

Epoch: 6| Step: 4
Training loss: 2.726327180954906
Validation loss: 2.585141769250266

Epoch: 6| Step: 5
Training loss: 2.3501854600163297
Validation loss: 2.5817402927096063

Epoch: 6| Step: 6
Training loss: 2.7423276512217267
Validation loss: 2.5705651101375686

Epoch: 6| Step: 7
Training loss: 2.8611631378414573
Validation loss: 2.570553854514654

Epoch: 6| Step: 8
Training loss: 3.080829806818933
Validation loss: 2.567801583012591

Epoch: 6| Step: 9
Training loss: 2.3835466098281244
Validation loss: 2.589995542031377

Epoch: 6| Step: 10
Training loss: 2.2296695914347926
Validation loss: 2.576776914133024

Epoch: 6| Step: 11
Training loss: 1.722564487219034
Validation loss: 2.57543821619252

Epoch: 6| Step: 12
Training loss: 2.4092301578747684
Validation loss: 2.5717206899368623

Epoch: 6| Step: 13
Training loss: 2.7736936638961582
Validation loss: 2.5755267412817644

Epoch: 133| Step: 0
Training loss: 2.0735538084960603
Validation loss: 2.591869298555471

Epoch: 6| Step: 1
Training loss: 2.3755261691640657
Validation loss: 2.5987556676561083

Epoch: 6| Step: 2
Training loss: 2.7743806336808245
Validation loss: 2.5614647403526436

Epoch: 6| Step: 3
Training loss: 2.700251380379692
Validation loss: 2.5625833357239087

Epoch: 6| Step: 4
Training loss: 3.030640531009615
Validation loss: 2.5984239162986125

Epoch: 6| Step: 5
Training loss: 2.833098869346287
Validation loss: 2.596570835030912

Epoch: 6| Step: 6
Training loss: 3.5369803596276994
Validation loss: 2.597415990618479

Epoch: 6| Step: 7
Training loss: 2.0154267442772142
Validation loss: 2.5926692651810685

Epoch: 6| Step: 8
Training loss: 2.1059150859671907
Validation loss: 2.5816448914803782

Epoch: 6| Step: 9
Training loss: 1.7499539505485644
Validation loss: 2.571434741737944

Epoch: 6| Step: 10
Training loss: 2.273090139378173
Validation loss: 2.597610165062847

Epoch: 6| Step: 11
Training loss: 2.6337749408687046
Validation loss: 2.5845068863691716

Epoch: 6| Step: 12
Training loss: 3.2850283712384143
Validation loss: 2.587496824789177

Epoch: 6| Step: 13
Training loss: 2.554620024463691
Validation loss: 2.590653209675437

Epoch: 134| Step: 0
Training loss: 2.91220319815534
Validation loss: 2.5740716358027127

Epoch: 6| Step: 1
Training loss: 3.362989175942998
Validation loss: 2.5690961230474536

Epoch: 6| Step: 2
Training loss: 2.289114889645521
Validation loss: 2.587090034934856

Epoch: 6| Step: 3
Training loss: 2.270643792131079
Validation loss: 2.5817799980767506

Epoch: 6| Step: 4
Training loss: 2.9126928961403675
Validation loss: 2.5884153844877367

Epoch: 6| Step: 5
Training loss: 2.586961065364328
Validation loss: 2.5688159739043686

Epoch: 6| Step: 6
Training loss: 1.9835387142279488
Validation loss: 2.586459676025674

Epoch: 6| Step: 7
Training loss: 2.9570720473263097
Validation loss: 2.5820705537480877

Epoch: 6| Step: 8
Training loss: 2.026637547852652
Validation loss: 2.5800460246194783

Epoch: 6| Step: 9
Training loss: 3.0515538994374447
Validation loss: 2.5887065640236795

Epoch: 6| Step: 10
Training loss: 2.3542309192452575
Validation loss: 2.565717250694339

Epoch: 6| Step: 11
Training loss: 2.877815029421956
Validation loss: 2.577631051185554

Epoch: 6| Step: 12
Training loss: 1.9242350036702833
Validation loss: 2.585012326611712

Epoch: 6| Step: 13
Training loss: 2.9501026976215035
Validation loss: 2.5531187313192305

Epoch: 135| Step: 0
Training loss: 2.649014570444544
Validation loss: 2.5868995452504366

Epoch: 6| Step: 1
Training loss: 1.9211299041163223
Validation loss: 2.5730623865995494

Epoch: 6| Step: 2
Training loss: 3.1783519442539663
Validation loss: 2.587958608033497

Epoch: 6| Step: 3
Training loss: 3.6950962253372985
Validation loss: 2.577167693965516

Epoch: 6| Step: 4
Training loss: 2.5143315561871464
Validation loss: 2.5747210004116523

Epoch: 6| Step: 5
Training loss: 1.818327775428639
Validation loss: 2.60014341659291

Epoch: 6| Step: 6
Training loss: 2.794483974228598
Validation loss: 2.5842124241754245

Epoch: 6| Step: 7
Training loss: 2.7477871054260383
Validation loss: 2.5848128071341656

Epoch: 6| Step: 8
Training loss: 2.2068881098148005
Validation loss: 2.609719155792235

Epoch: 6| Step: 9
Training loss: 2.12787433778118
Validation loss: 2.5890201824448833

Epoch: 6| Step: 10
Training loss: 2.680314327140186
Validation loss: 2.5990780801912994

Epoch: 6| Step: 11
Training loss: 2.4238400270721576
Validation loss: 2.6085939874955346

Epoch: 6| Step: 12
Training loss: 2.7258548200742587
Validation loss: 2.5968329211142973

Epoch: 6| Step: 13
Training loss: 2.7199882230784205
Validation loss: 2.5929617249174983

Epoch: 136| Step: 0
Training loss: 1.9886642117222464
Validation loss: 2.608521613057261

Epoch: 6| Step: 1
Training loss: 2.531911504515752
Validation loss: 2.5943243510422396

Epoch: 6| Step: 2
Training loss: 2.0601316784003476
Validation loss: 2.592742565142641

Epoch: 6| Step: 3
Training loss: 2.855685495899235
Validation loss: 2.579978561445843

Epoch: 6| Step: 4
Training loss: 2.0833985382048583
Validation loss: 2.590448717216206

Epoch: 6| Step: 5
Training loss: 3.091767880273078
Validation loss: 2.6000578219166117

Epoch: 6| Step: 6
Training loss: 2.634200910108121
Validation loss: 2.586767797164011

Epoch: 6| Step: 7
Training loss: 2.733838709964809
Validation loss: 2.573576202759999

Epoch: 6| Step: 8
Training loss: 2.160359102351005
Validation loss: 2.5569460026443362

Epoch: 6| Step: 9
Training loss: 2.0739872402729342
Validation loss: 2.570850220192305

Epoch: 6| Step: 10
Training loss: 2.7529313330021243
Validation loss: 2.574586028224719

Epoch: 6| Step: 11
Training loss: 3.5149171922026827
Validation loss: 2.582246222850657

Epoch: 6| Step: 12
Training loss: 2.7260203874627478
Validation loss: 2.58157567018184

Epoch: 6| Step: 13
Training loss: 3.2792167540186217
Validation loss: 2.5640763227281114

Epoch: 137| Step: 0
Training loss: 2.389204413500902
Validation loss: 2.581340834816446

Epoch: 6| Step: 1
Training loss: 3.1692032108077326
Validation loss: 2.5792988938301415

Epoch: 6| Step: 2
Training loss: 2.5017129751549425
Validation loss: 2.576063401928453

Epoch: 6| Step: 3
Training loss: 3.0424194623683234
Validation loss: 2.57821857460321

Epoch: 6| Step: 4
Training loss: 2.4155476270278635
Validation loss: 2.5866940850771156

Epoch: 6| Step: 5
Training loss: 2.5041671355168247
Validation loss: 2.5803206942246333

Epoch: 6| Step: 6
Training loss: 2.838646805708846
Validation loss: 2.5894494280606515

Epoch: 6| Step: 7
Training loss: 2.850787499029702
Validation loss: 2.589930228638413

Epoch: 6| Step: 8
Training loss: 1.9376976158513677
Validation loss: 2.588876604319991

Epoch: 6| Step: 9
Training loss: 2.2395715639263485
Validation loss: 2.577747131081086

Epoch: 6| Step: 10
Training loss: 1.9231601543021473
Validation loss: 2.590767887770122

Epoch: 6| Step: 11
Training loss: 2.9449046533042837
Validation loss: 2.5790704091915804

Epoch: 6| Step: 12
Training loss: 2.7883023633983215
Validation loss: 2.575070160522146

Epoch: 6| Step: 13
Training loss: 2.7130753500261346
Validation loss: 2.573880186626965

Epoch: 138| Step: 0
Training loss: 2.743063936073174
Validation loss: 2.5753125494166134

Epoch: 6| Step: 1
Training loss: 2.4148011296687786
Validation loss: 2.5919050565688044

Epoch: 6| Step: 2
Training loss: 2.8644590778567287
Validation loss: 2.596719871314076

Epoch: 6| Step: 3
Training loss: 2.8707022678998415
Validation loss: 2.5591332793659354

Epoch: 6| Step: 4
Training loss: 2.374703238166898
Validation loss: 2.5799417577295123

Epoch: 6| Step: 5
Training loss: 1.3574248169791634
Validation loss: 2.576351743481444

Epoch: 6| Step: 6
Training loss: 3.11740822835169
Validation loss: 2.583936900791442

Epoch: 6| Step: 7
Training loss: 2.8143753581054245
Validation loss: 2.5721357935112743

Epoch: 6| Step: 8
Training loss: 2.1953040289121484
Validation loss: 2.58915301696738

Epoch: 6| Step: 9
Training loss: 2.684825009516649
Validation loss: 2.58013277799468

Epoch: 6| Step: 10
Training loss: 2.77272579033893
Validation loss: 2.577170761776366

Epoch: 6| Step: 11
Training loss: 2.2065448596369692
Validation loss: 2.583422454529903

Epoch: 6| Step: 12
Training loss: 3.0087454797942974
Validation loss: 2.5841122292261414

Epoch: 6| Step: 13
Training loss: 2.9142387275487605
Validation loss: 2.5909722808299827

Epoch: 139| Step: 0
Training loss: 2.6499161545066907
Validation loss: 2.6018484492365594

Epoch: 6| Step: 1
Training loss: 2.072875771686222
Validation loss: 2.6020498102972667

Epoch: 6| Step: 2
Training loss: 2.966823072989581
Validation loss: 2.583466799963713

Epoch: 6| Step: 3
Training loss: 2.6635442772291684
Validation loss: 2.597972860509039

Epoch: 6| Step: 4
Training loss: 2.598694374476309
Validation loss: 2.574819986670062

Epoch: 6| Step: 5
Training loss: 2.43747926360871
Validation loss: 2.5750876992688427

Epoch: 6| Step: 6
Training loss: 2.6551690089856947
Validation loss: 2.5895368465074724

Epoch: 6| Step: 7
Training loss: 2.8463334306460104
Validation loss: 2.5905166538997153

Epoch: 6| Step: 8
Training loss: 2.295398471123337
Validation loss: 2.56372749527887

Epoch: 6| Step: 9
Training loss: 2.8754106311286085
Validation loss: 2.577848609684126

Epoch: 6| Step: 10
Training loss: 2.851326041673041
Validation loss: 2.5946112017340304

Epoch: 6| Step: 11
Training loss: 3.228351235747898
Validation loss: 2.5839605201885845

Epoch: 6| Step: 12
Training loss: 1.667176748739826
Validation loss: 2.5665864712455218

Epoch: 6| Step: 13
Training loss: 2.1672036410324025
Validation loss: 2.576082429156617

Epoch: 140| Step: 0
Training loss: 1.5357688089368053
Validation loss: 2.575894173382523

Epoch: 6| Step: 1
Training loss: 2.8427566637902593
Validation loss: 2.588129574592115

Epoch: 6| Step: 2
Training loss: 2.5768449784629626
Validation loss: 2.586199546498712

Epoch: 6| Step: 3
Training loss: 2.9984591023599756
Validation loss: 2.571147660961135

Epoch: 6| Step: 4
Training loss: 2.7658643026323926
Validation loss: 2.575666985216448

Epoch: 6| Step: 5
Training loss: 2.911160985585748
Validation loss: 2.5866138374452006

Epoch: 6| Step: 6
Training loss: 2.2696577289681894
Validation loss: 2.5703625931433884

Epoch: 6| Step: 7
Training loss: 2.7185944260557418
Validation loss: 2.5954280774121266

Epoch: 6| Step: 8
Training loss: 1.866982037719887
Validation loss: 2.5818120103698643

Epoch: 6| Step: 9
Training loss: 2.013995909496347
Validation loss: 2.57866819941858

Epoch: 6| Step: 10
Training loss: 3.2463249555710045
Validation loss: 2.573377495164176

Epoch: 6| Step: 11
Training loss: 2.2513129324327106
Validation loss: 2.600010745221156

Epoch: 6| Step: 12
Training loss: 3.0861315702425354
Validation loss: 2.575979500122833

Epoch: 6| Step: 13
Training loss: 2.835698729833082
Validation loss: 2.57713882413472

Epoch: 141| Step: 0
Training loss: 2.822170501478694
Validation loss: 2.593049206868838

Epoch: 6| Step: 1
Training loss: 2.944941732610627
Validation loss: 2.5857478890992693

Epoch: 6| Step: 2
Training loss: 2.776713582803032
Validation loss: 2.5951412895995043

Epoch: 6| Step: 3
Training loss: 2.2997538891019302
Validation loss: 2.5767649852298273

Epoch: 6| Step: 4
Training loss: 2.6089930454686368
Validation loss: 2.581694994123679

Epoch: 6| Step: 5
Training loss: 2.523731698758189
Validation loss: 2.590950205090188

Epoch: 6| Step: 6
Training loss: 2.994327108867684
Validation loss: 2.5782901038598816

Epoch: 6| Step: 7
Training loss: 1.9815134156143797
Validation loss: 2.5748335743816773

Epoch: 6| Step: 8
Training loss: 2.530523784683205
Validation loss: 2.5856611952278263

Epoch: 6| Step: 9
Training loss: 3.001562665217493
Validation loss: 2.5725582527960302

Epoch: 6| Step: 10
Training loss: 2.9022637378039873
Validation loss: 2.583573684136431

Epoch: 6| Step: 11
Training loss: 2.3299897169942247
Validation loss: 2.587811922256916

Epoch: 6| Step: 12
Training loss: 2.399678161022694
Validation loss: 2.600636396820819

Epoch: 6| Step: 13
Training loss: 1.8870479699300866
Validation loss: 2.578427803302823

Epoch: 142| Step: 0
Training loss: 2.5118457530706855
Validation loss: 2.5594994450033193

Epoch: 6| Step: 1
Training loss: 2.2787116573453905
Validation loss: 2.6090914988756566

Epoch: 6| Step: 2
Training loss: 2.529188281935237
Validation loss: 2.582582436736187

Epoch: 6| Step: 3
Training loss: 2.294256677197802
Validation loss: 2.5913101553955458

Epoch: 6| Step: 4
Training loss: 2.7951132910736414
Validation loss: 2.6052190696028417

Epoch: 6| Step: 5
Training loss: 2.25261017609311
Validation loss: 2.5667129537864506

Epoch: 6| Step: 6
Training loss: 2.486309138343157
Validation loss: 2.598447116416208

Epoch: 6| Step: 7
Training loss: 2.1789605353791957
Validation loss: 2.5820685213580594

Epoch: 6| Step: 8
Training loss: 2.0264315454764805
Validation loss: 2.5658026650835732

Epoch: 6| Step: 9
Training loss: 2.5100437589075733
Validation loss: 2.581701884588537

Epoch: 6| Step: 10
Training loss: 2.948779910955858
Validation loss: 2.5769373042651966

Epoch: 6| Step: 11
Training loss: 3.5959593242852543
Validation loss: 2.583153750846149

Epoch: 6| Step: 12
Training loss: 2.6236919595478794
Validation loss: 2.590815076011816

Epoch: 6| Step: 13
Training loss: 3.2243050351346607
Validation loss: 2.573577380196492

Epoch: 143| Step: 0
Training loss: 2.1087915814635436
Validation loss: 2.580281120402114

Epoch: 6| Step: 1
Training loss: 3.1031490082978928
Validation loss: 2.571118139737201

Epoch: 6| Step: 2
Training loss: 2.4985492311535604
Validation loss: 2.5691374288150466

Epoch: 6| Step: 3
Training loss: 2.5984156366232467
Validation loss: 2.572284794435602

Epoch: 6| Step: 4
Training loss: 2.732588702242802
Validation loss: 2.5660567462149846

Epoch: 6| Step: 5
Training loss: 2.353753877981985
Validation loss: 2.5764059173030387

Epoch: 6| Step: 6
Training loss: 2.4777637540689352
Validation loss: 2.570543215183037

Epoch: 6| Step: 7
Training loss: 2.5449204697389156
Validation loss: 2.5644864482223633

Epoch: 6| Step: 8
Training loss: 2.1040505355161647
Validation loss: 2.598266991637647

Epoch: 6| Step: 9
Training loss: 3.5695471412804234
Validation loss: 2.572169381988812

Epoch: 6| Step: 10
Training loss: 2.0189176176890875
Validation loss: 2.5812234654853317

Epoch: 6| Step: 11
Training loss: 2.3724958368713063
Validation loss: 2.575923067115144

Epoch: 6| Step: 12
Training loss: 2.1521769214922384
Validation loss: 2.584512871646195

Epoch: 6| Step: 13
Training loss: 3.5548950134741997
Validation loss: 2.5672549629355945

Epoch: 144| Step: 0
Training loss: 2.3615134949727636
Validation loss: 2.579058028676245

Epoch: 6| Step: 1
Training loss: 2.919211086146138
Validation loss: 2.57097026578409

Epoch: 6| Step: 2
Training loss: 2.7767796111138368
Validation loss: 2.579825418840268

Epoch: 6| Step: 3
Training loss: 2.977736514392351
Validation loss: 2.5893396498738874

Epoch: 6| Step: 4
Training loss: 2.255899324930346
Validation loss: 2.594582823406939

Epoch: 6| Step: 5
Training loss: 3.049485403956358
Validation loss: 2.5618955297915154

Epoch: 6| Step: 6
Training loss: 2.3221458102567585
Validation loss: 2.5883559798792604

Epoch: 6| Step: 7
Training loss: 1.7902853172557152
Validation loss: 2.5757608690767775

Epoch: 6| Step: 8
Training loss: 2.4792397645918096
Validation loss: 2.5754087127940135

Epoch: 6| Step: 9
Training loss: 2.8774397076637825
Validation loss: 2.5858212087870966

Epoch: 6| Step: 10
Training loss: 2.5710662385945966
Validation loss: 2.574011496792325

Epoch: 6| Step: 11
Training loss: 2.506142889383372
Validation loss: 2.5710211547837525

Epoch: 6| Step: 12
Training loss: 2.4837580460608617
Validation loss: 2.579091884846193

Epoch: 6| Step: 13
Training loss: 2.950913342828753
Validation loss: 2.57704834891216

Epoch: 145| Step: 0
Training loss: 2.517809659670548
Validation loss: 2.5622866181801527

Epoch: 6| Step: 1
Training loss: 1.9517027902992778
Validation loss: 2.553211553607662

Epoch: 6| Step: 2
Training loss: 2.5334800033608316
Validation loss: 2.57605150554776

Epoch: 6| Step: 3
Training loss: 2.765783100673866
Validation loss: 2.5785120658885305

Epoch: 6| Step: 4
Training loss: 2.8449240137019114
Validation loss: 2.574996668121224

Epoch: 6| Step: 5
Training loss: 2.7046620844325076
Validation loss: 2.5638128859636002

Epoch: 6| Step: 6
Training loss: 2.0440297626485924
Validation loss: 2.557016029053315

Epoch: 6| Step: 7
Training loss: 2.6218152481563393
Validation loss: 2.5773588611437175

Epoch: 6| Step: 8
Training loss: 3.1974081987530347
Validation loss: 2.5884044085346773

Epoch: 6| Step: 9
Training loss: 3.030438658684629
Validation loss: 2.572488736665205

Epoch: 6| Step: 10
Training loss: 2.386354209418895
Validation loss: 2.560452599496384

Epoch: 6| Step: 11
Training loss: 2.4034943097187864
Validation loss: 2.54510621737246

Epoch: 6| Step: 12
Training loss: 2.0185020081871765
Validation loss: 2.582351162107639

Epoch: 6| Step: 13
Training loss: 3.351442561637827
Validation loss: 2.5717137184001957

Epoch: 146| Step: 0
Training loss: 2.7151921988614016
Validation loss: 2.5620215584832042

Epoch: 6| Step: 1
Training loss: 2.7388276386268715
Validation loss: 2.5693003922198363

Epoch: 6| Step: 2
Training loss: 2.424698690985218
Validation loss: 2.5948770572293767

Epoch: 6| Step: 3
Training loss: 2.9536129180055366
Validation loss: 2.5714452098907787

Epoch: 6| Step: 4
Training loss: 2.4217657249163045
Validation loss: 2.5725848506375306

Epoch: 6| Step: 5
Training loss: 2.0466834990630365
Validation loss: 2.552955576494077

Epoch: 6| Step: 6
Training loss: 1.976462983653054
Validation loss: 2.5893829326239772

Epoch: 6| Step: 7
Training loss: 2.6712605623171193
Validation loss: 2.574673183635605

Epoch: 6| Step: 8
Training loss: 2.7745990738482136
Validation loss: 2.5954726491151354

Epoch: 6| Step: 9
Training loss: 2.6640684066214764
Validation loss: 2.596220533750098

Epoch: 6| Step: 10
Training loss: 2.411485401328466
Validation loss: 2.5695583397712527

Epoch: 6| Step: 11
Training loss: 2.803266244857396
Validation loss: 2.5912827154100255

Epoch: 6| Step: 12
Training loss: 2.5956138440486467
Validation loss: 2.5753612960163967

Epoch: 6| Step: 13
Training loss: 3.094604220128293
Validation loss: 2.58578754780037

Epoch: 147| Step: 0
Training loss: 3.0804993432751218
Validation loss: 2.5679151272088805

Epoch: 6| Step: 1
Training loss: 2.6751489045241863
Validation loss: 2.575632810307313

Epoch: 6| Step: 2
Training loss: 2.3370837203027937
Validation loss: 2.5821899397069825

Epoch: 6| Step: 3
Training loss: 2.300659383710139
Validation loss: 2.5805835524890757

Epoch: 6| Step: 4
Training loss: 3.6515146222156747
Validation loss: 2.5796241754320137

Epoch: 6| Step: 5
Training loss: 2.1668073412881577
Validation loss: 2.578830627153153

Epoch: 6| Step: 6
Training loss: 2.8452607218740873
Validation loss: 2.589298389156672

Epoch: 6| Step: 7
Training loss: 2.6137908301865482
Validation loss: 2.590923114533306

Epoch: 6| Step: 8
Training loss: 1.9581690847899411
Validation loss: 2.5821243613624496

Epoch: 6| Step: 9
Training loss: 2.149417168330332
Validation loss: 2.61676432396821

Epoch: 6| Step: 10
Training loss: 2.402441602745434
Validation loss: 2.5761119313077945

Epoch: 6| Step: 11
Training loss: 2.189343792570146
Validation loss: 2.5733354375564863

Epoch: 6| Step: 12
Training loss: 2.9929258864760544
Validation loss: 2.5660110448789912

Epoch: 6| Step: 13
Training loss: 2.3743407689755145
Validation loss: 2.5675480729407445

Epoch: 148| Step: 0
Training loss: 2.7949995007454795
Validation loss: 2.5719755903722077

Epoch: 6| Step: 1
Training loss: 2.731875950645782
Validation loss: 2.5692569836854764

Epoch: 6| Step: 2
Training loss: 2.0257832837195733
Validation loss: 2.5800053823773754

Epoch: 6| Step: 3
Training loss: 2.2287561151460205
Validation loss: 2.579395330001447

Epoch: 6| Step: 4
Training loss: 2.632551321777411
Validation loss: 2.584972349567102

Epoch: 6| Step: 5
Training loss: 2.264286145523532
Validation loss: 2.5850141851176756

Epoch: 6| Step: 6
Training loss: 2.3664752152960733
Validation loss: 2.5747244216224825

Epoch: 6| Step: 7
Training loss: 2.785119354731297
Validation loss: 2.564224215328114

Epoch: 6| Step: 8
Training loss: 1.9930145342153804
Validation loss: 2.5565022599608893

Epoch: 6| Step: 9
Training loss: 2.9567271067374175
Validation loss: 2.5670406201645033

Epoch: 6| Step: 10
Training loss: 3.1256166994030017
Validation loss: 2.5778955401607804

Epoch: 6| Step: 11
Training loss: 2.51584837496358
Validation loss: 2.5583433057323384

Epoch: 6| Step: 12
Training loss: 3.1389061318733176
Validation loss: 2.5665365740959016

Epoch: 6| Step: 13
Training loss: 1.977056388818764
Validation loss: 2.570596970882704

Epoch: 149| Step: 0
Training loss: 2.8366631034114467
Validation loss: 2.5544171295139853

Epoch: 6| Step: 1
Training loss: 2.345821431628357
Validation loss: 2.571395708611221

Epoch: 6| Step: 2
Training loss: 2.322464173269548
Validation loss: 2.554435584595536

Epoch: 6| Step: 3
Training loss: 2.271073413255233
Validation loss: 2.5921144138333663

Epoch: 6| Step: 4
Training loss: 3.427164248793455
Validation loss: 2.5606834792122832

Epoch: 6| Step: 5
Training loss: 2.4032806306405035
Validation loss: 2.58520628336169

Epoch: 6| Step: 6
Training loss: 2.176348134676092
Validation loss: 2.5905133188605487

Epoch: 6| Step: 7
Training loss: 2.6993863044108144
Validation loss: 2.572499467606178

Epoch: 6| Step: 8
Training loss: 2.5631471142469486
Validation loss: 2.5916196888962735

Epoch: 6| Step: 9
Training loss: 3.050290428467107
Validation loss: 2.5886261143558826

Epoch: 6| Step: 10
Training loss: 2.6039370219383553
Validation loss: 2.580799578685678

Epoch: 6| Step: 11
Training loss: 2.4704437240308703
Validation loss: 2.5915668767335176

Epoch: 6| Step: 12
Training loss: 2.5662269471587527
Validation loss: 2.5762522916569734

Epoch: 6| Step: 13
Training loss: 1.6761915153752032
Validation loss: 2.5453315243796633

Epoch: 150| Step: 0
Training loss: 2.63661105465826
Validation loss: 2.5594621344620347

Epoch: 6| Step: 1
Training loss: 2.00994759524529
Validation loss: 2.5871077329911745

Epoch: 6| Step: 2
Training loss: 2.41420738007681
Validation loss: 2.566625244398745

Epoch: 6| Step: 3
Training loss: 3.5157398798504698
Validation loss: 2.5672328849669674

Epoch: 6| Step: 4
Training loss: 2.4424903842889023
Validation loss: 2.5714054506228967

Epoch: 6| Step: 5
Training loss: 1.9588960150343062
Validation loss: 2.565728645438978

Epoch: 6| Step: 6
Training loss: 2.5406267717456155
Validation loss: 2.566212597595054

Epoch: 6| Step: 7
Training loss: 2.8315798064215456
Validation loss: 2.5730930696512693

Epoch: 6| Step: 8
Training loss: 2.066581271571011
Validation loss: 2.5517536592457373

Epoch: 6| Step: 9
Training loss: 2.083022463175154
Validation loss: 2.5961096208814616

Epoch: 6| Step: 10
Training loss: 2.49880523742718
Validation loss: 2.566325277073527

Epoch: 6| Step: 11
Training loss: 2.599637989371068
Validation loss: 2.584101467142664

Epoch: 6| Step: 12
Training loss: 3.3971079363088563
Validation loss: 2.5663021252135882

Epoch: 6| Step: 13
Training loss: 2.2129374917463687
Validation loss: 2.578719966447641

Testing loss: 2.4511145320836567
