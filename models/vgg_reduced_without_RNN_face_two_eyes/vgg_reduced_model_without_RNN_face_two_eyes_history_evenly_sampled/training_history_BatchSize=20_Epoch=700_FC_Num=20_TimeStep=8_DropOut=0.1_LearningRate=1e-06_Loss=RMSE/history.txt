Epoch: 1| Step: 0
Training loss: 7.891885245121597
Validation loss: 8.447983784598197

Epoch: 5| Step: 1
Training loss: 8.09809199337137
Validation loss: 8.442634778104908

Epoch: 5| Step: 2
Training loss: 6.667853472293652
Validation loss: 8.436181732099355

Epoch: 5| Step: 3
Training loss: 9.620416515953439
Validation loss: 8.430497022557146

Epoch: 5| Step: 4
Training loss: 7.607716969164281
Validation loss: 8.424424894084874

Epoch: 5| Step: 5
Training loss: 8.937821815939081
Validation loss: 8.421672664814961

Epoch: 5| Step: 6
Training loss: 9.100457618022396
Validation loss: 8.414433388822138

Epoch: 5| Step: 7
Training loss: 8.58978157662811
Validation loss: 8.407553992546216

Epoch: 5| Step: 8
Training loss: 9.100868820802607
Validation loss: 8.401620803036268

Epoch: 5| Step: 9
Training loss: 7.356685851739995
Validation loss: 8.39702491871431

Epoch: 5| Step: 10
Training loss: 8.7173467347719
Validation loss: 8.391055066782636

Epoch: 2| Step: 0
Training loss: 7.661087936551964
Validation loss: 8.385490206105091

Epoch: 5| Step: 1
Training loss: 8.573955363266656
Validation loss: 8.37856609964812

Epoch: 5| Step: 2
Training loss: 9.570206472626959
Validation loss: 8.37434081445125

Epoch: 5| Step: 3
Training loss: 8.496272447833373
Validation loss: 8.368397960506135

Epoch: 5| Step: 4
Training loss: 7.809244927356883
Validation loss: 8.364950270975235

Epoch: 5| Step: 5
Training loss: 7.320820305309163
Validation loss: 8.357808815439203

Epoch: 5| Step: 6
Training loss: 8.73073265820363
Validation loss: 8.351720379402545

Epoch: 5| Step: 7
Training loss: 8.796304308197954
Validation loss: 8.34537732011564

Epoch: 5| Step: 8
Training loss: 8.939126460262132
Validation loss: 8.337126977911874

Epoch: 5| Step: 9
Training loss: 8.306260140371915
Validation loss: 8.33336315354785

Epoch: 5| Step: 10
Training loss: 6.537462118414686
Validation loss: 8.328723305028348

Epoch: 3| Step: 0
Training loss: 7.944943759880006
Validation loss: 8.32060320578049

Epoch: 5| Step: 1
Training loss: 8.564806550931715
Validation loss: 8.316892083014222

Epoch: 5| Step: 2
Training loss: 8.167213058358708
Validation loss: 8.30909347217385

Epoch: 5| Step: 3
Training loss: 7.872657548594464
Validation loss: 8.305119596846552

Epoch: 5| Step: 4
Training loss: 8.543011616833466
Validation loss: 8.297867234401467

Epoch: 5| Step: 5
Training loss: 7.262369062126439
Validation loss: 8.292938355865308

Epoch: 5| Step: 6
Training loss: 8.267478691744964
Validation loss: 8.29117343536487

Epoch: 5| Step: 7
Training loss: 9.016775391699378
Validation loss: 8.283239596247034

Epoch: 5| Step: 8
Training loss: 7.8737486798808725
Validation loss: 8.276157049348212

Epoch: 5| Step: 9
Training loss: 8.762625604401352
Validation loss: 8.273241244673015

Epoch: 5| Step: 10
Training loss: 8.32586238392367
Validation loss: 8.268244115641384

Epoch: 4| Step: 0
Training loss: 8.633488113410161
Validation loss: 8.260071057557742

Epoch: 5| Step: 1
Training loss: 7.127857906650661
Validation loss: 8.257029974102178

Epoch: 5| Step: 2
Training loss: 7.483055301024014
Validation loss: 8.248271613174618

Epoch: 5| Step: 3
Training loss: 8.101192396018298
Validation loss: 8.24385414646434

Epoch: 5| Step: 4
Training loss: 8.258599625447253
Validation loss: 8.238008626334532

Epoch: 5| Step: 5
Training loss: 8.960375554524765
Validation loss: 8.233281467701667

Epoch: 5| Step: 6
Training loss: 7.759162408909985
Validation loss: 8.22772840083682

Epoch: 5| Step: 7
Training loss: 9.059622893243043
Validation loss: 8.220151740144848

Epoch: 5| Step: 8
Training loss: 7.802739263922123
Validation loss: 8.217629256330293

Epoch: 5| Step: 9
Training loss: 8.59488451318119
Validation loss: 8.212391429605573

Epoch: 5| Step: 10
Training loss: 8.059307087156913
Validation loss: 8.204425940108207

Epoch: 5| Step: 0
Training loss: 7.989025933733915
Validation loss: 8.198845309782804

Epoch: 5| Step: 1
Training loss: 7.917614635797583
Validation loss: 8.195722496442322

Epoch: 5| Step: 2
Training loss: 8.55324215458562
Validation loss: 8.188016412877168

Epoch: 5| Step: 3
Training loss: 7.529674064401013
Validation loss: 8.182570063421055

Epoch: 5| Step: 4
Training loss: 8.178704349344361
Validation loss: 8.177222268751969

Epoch: 5| Step: 5
Training loss: 7.148779021896414
Validation loss: 8.170054323474163

Epoch: 5| Step: 6
Training loss: 8.168351706708776
Validation loss: 8.164253574825475

Epoch: 5| Step: 7
Training loss: 8.890242261642994
Validation loss: 8.160271389634707

Epoch: 5| Step: 8
Training loss: 8.113978966147616
Validation loss: 8.154474406106203

Epoch: 5| Step: 9
Training loss: 8.276586061357344
Validation loss: 8.150574549505539

Epoch: 5| Step: 10
Training loss: 8.533314661164518
Validation loss: 8.141948795832638

Epoch: 6| Step: 0
Training loss: 8.068712783124859
Validation loss: 8.13756293654667

Epoch: 5| Step: 1
Training loss: 7.097949965114955
Validation loss: 8.129856073897916

Epoch: 5| Step: 2
Training loss: 8.217414080173826
Validation loss: 8.12389745054799

Epoch: 5| Step: 3
Training loss: 6.6848090631440895
Validation loss: 8.116704641694968

Epoch: 5| Step: 4
Training loss: 9.047337126582121
Validation loss: 8.113609355241051

Epoch: 5| Step: 5
Training loss: 9.159219201805291
Validation loss: 8.10639842871696

Epoch: 5| Step: 6
Training loss: 9.232230775008162
Validation loss: 8.099628267072038

Epoch: 5| Step: 7
Training loss: 7.727305007295962
Validation loss: 8.09651866314008

Epoch: 5| Step: 8
Training loss: 8.59216338336541
Validation loss: 8.087979179083936

Epoch: 5| Step: 9
Training loss: 7.533114507192015
Validation loss: 8.079373366421162

Epoch: 5| Step: 10
Training loss: 6.512760548129755
Validation loss: 8.071063334280087

Epoch: 7| Step: 0
Training loss: 8.142815879009737
Validation loss: 8.067082897130492

Epoch: 5| Step: 1
Training loss: 8.149436472501392
Validation loss: 8.057724554915469

Epoch: 5| Step: 2
Training loss: 7.828712913380268
Validation loss: 8.055615798598579

Epoch: 5| Step: 3
Training loss: 8.090546316366135
Validation loss: 8.045740959652706

Epoch: 5| Step: 4
Training loss: 9.273729147820143
Validation loss: 8.04102800032707

Epoch: 5| Step: 5
Training loss: 6.935573550973058
Validation loss: 8.03283287650681

Epoch: 5| Step: 6
Training loss: 8.190459437263396
Validation loss: 8.027566251302629

Epoch: 5| Step: 7
Training loss: 7.458047900429939
Validation loss: 8.01883100668974

Epoch: 5| Step: 8
Training loss: 8.432894431693887
Validation loss: 8.01142727041199

Epoch: 5| Step: 9
Training loss: 7.287102831426304
Validation loss: 8.001020089608941

Epoch: 5| Step: 10
Training loss: 7.819433934633982
Validation loss: 7.997848626521918

Epoch: 8| Step: 0
Training loss: 7.940456050199903
Validation loss: 7.989610776046451

Epoch: 5| Step: 1
Training loss: 8.162031558091002
Validation loss: 7.982462503016749

Epoch: 5| Step: 2
Training loss: 8.25540307875247
Validation loss: 7.97278008082442

Epoch: 5| Step: 3
Training loss: 7.814214167413075
Validation loss: 7.964793592267099

Epoch: 5| Step: 4
Training loss: 7.980921407102544
Validation loss: 7.959177136659053

Epoch: 5| Step: 5
Training loss: 6.845262891515203
Validation loss: 7.951515691708321

Epoch: 5| Step: 6
Training loss: 8.504016600397941
Validation loss: 7.944313174824348

Epoch: 5| Step: 7
Training loss: 7.655900472330889
Validation loss: 7.936965429579005

Epoch: 5| Step: 8
Training loss: 7.576066891915702
Validation loss: 7.924916651823076

Epoch: 5| Step: 9
Training loss: 8.256492141072135
Validation loss: 7.91982873569244

Epoch: 5| Step: 10
Training loss: 7.827623789078625
Validation loss: 7.908491757247314

Epoch: 9| Step: 0
Training loss: 8.702882170927898
Validation loss: 7.9017266907432875

Epoch: 5| Step: 1
Training loss: 6.931240797939676
Validation loss: 7.891822035200055

Epoch: 5| Step: 2
Training loss: 7.938883983674909
Validation loss: 7.885293473539998

Epoch: 5| Step: 3
Training loss: 7.7870243815119595
Validation loss: 7.878302584002048

Epoch: 5| Step: 4
Training loss: 7.728576582792833
Validation loss: 7.86860200731597

Epoch: 5| Step: 5
Training loss: 7.342312026769054
Validation loss: 7.859981494789829

Epoch: 5| Step: 6
Training loss: 7.297423642299078
Validation loss: 7.850749178213277

Epoch: 5| Step: 7
Training loss: 6.300019267219267
Validation loss: 7.8433815056097025

Epoch: 5| Step: 8
Training loss: 9.152871820419817
Validation loss: 7.83241039102385

Epoch: 5| Step: 9
Training loss: 7.733240032729399
Validation loss: 7.822354629815443

Epoch: 5| Step: 10
Training loss: 8.731431714230688
Validation loss: 7.8141581899114145

Epoch: 10| Step: 0
Training loss: 8.359552969776086
Validation loss: 7.8062557738962175

Epoch: 5| Step: 1
Training loss: 7.439333136831013
Validation loss: 7.793159144070088

Epoch: 5| Step: 2
Training loss: 7.808295743750681
Validation loss: 7.782972040908363

Epoch: 5| Step: 3
Training loss: 7.153155994806429
Validation loss: 7.777186718274357

Epoch: 5| Step: 4
Training loss: 7.384689689837045
Validation loss: 7.766903985341255

Epoch: 5| Step: 5
Training loss: 7.401131064089598
Validation loss: 7.753473062695246

Epoch: 5| Step: 6
Training loss: 8.589790902662582
Validation loss: 7.748413304584318

Epoch: 5| Step: 7
Training loss: 8.734398584214581
Validation loss: 7.735821735322188

Epoch: 5| Step: 8
Training loss: 7.654717739689453
Validation loss: 7.725128382817239

Epoch: 5| Step: 9
Training loss: 7.408719323154127
Validation loss: 7.715038347595096

Epoch: 5| Step: 10
Training loss: 6.4425056032949115
Validation loss: 7.705243607958461

Epoch: 11| Step: 0
Training loss: 7.245503576875767
Validation loss: 7.690008829716811

Epoch: 5| Step: 1
Training loss: 7.525134884458675
Validation loss: 7.683132293799386

Epoch: 5| Step: 2
Training loss: 7.206663904933536
Validation loss: 7.672201997538927

Epoch: 5| Step: 3
Training loss: 8.579406531378734
Validation loss: 7.662777114233688

Epoch: 5| Step: 4
Training loss: 6.894861558128758
Validation loss: 7.650269277874736

Epoch: 5| Step: 5
Training loss: 7.532116345479914
Validation loss: 7.640305721362007

Epoch: 5| Step: 6
Training loss: 7.753236894518914
Validation loss: 7.63067941549433

Epoch: 5| Step: 7
Training loss: 6.929552629571125
Validation loss: 7.616171952695947

Epoch: 5| Step: 8
Training loss: 7.992519696175293
Validation loss: 7.606295076179832

Epoch: 5| Step: 9
Training loss: 7.074398314431445
Validation loss: 7.594703413593455

Epoch: 5| Step: 10
Training loss: 8.720339831808538
Validation loss: 7.58208926044594

Epoch: 12| Step: 0
Training loss: 8.483615117617441
Validation loss: 7.569079665147891

Epoch: 5| Step: 1
Training loss: 7.113629286001087
Validation loss: 7.5597585510824805

Epoch: 5| Step: 2
Training loss: 7.676556994038072
Validation loss: 7.544662656442466

Epoch: 5| Step: 3
Training loss: 7.674626682409736
Validation loss: 7.534654759538097

Epoch: 5| Step: 4
Training loss: 6.489317993160562
Validation loss: 7.52143327846357

Epoch: 5| Step: 5
Training loss: 7.284722936594051
Validation loss: 7.5098542069999

Epoch: 5| Step: 6
Training loss: 8.102655761878806
Validation loss: 7.497782778036804

Epoch: 5| Step: 7
Training loss: 7.808080781362425
Validation loss: 7.48463789033976

Epoch: 5| Step: 8
Training loss: 7.332550469428679
Validation loss: 7.473964701421105

Epoch: 5| Step: 9
Training loss: 7.919118668811742
Validation loss: 7.4598988535130974

Epoch: 5| Step: 10
Training loss: 5.592807626461547
Validation loss: 7.445307412185758

Epoch: 13| Step: 0
Training loss: 6.977384819958066
Validation loss: 7.435265585719745

Epoch: 5| Step: 1
Training loss: 7.081176100208086
Validation loss: 7.4210389640144

Epoch: 5| Step: 2
Training loss: 7.692350020658968
Validation loss: 7.40742880877385

Epoch: 5| Step: 3
Training loss: 6.800582120325654
Validation loss: 7.398307088709237

Epoch: 5| Step: 4
Training loss: 7.552839934935975
Validation loss: 7.381789924853654

Epoch: 5| Step: 5
Training loss: 7.239778350472123
Validation loss: 7.37334160558824

Epoch: 5| Step: 6
Training loss: 7.454182100004621
Validation loss: 7.3517111203899805

Epoch: 5| Step: 7
Training loss: 7.0366887060290395
Validation loss: 7.3417739740572845

Epoch: 5| Step: 8
Training loss: 7.021800290615581
Validation loss: 7.324885335930048

Epoch: 5| Step: 9
Training loss: 7.70415175831743
Validation loss: 7.313558390586771

Epoch: 5| Step: 10
Training loss: 7.969775324661664
Validation loss: 7.2973308262318595

Epoch: 14| Step: 0
Training loss: 7.678547430159368
Validation loss: 7.285468431387799

Epoch: 5| Step: 1
Training loss: 7.4075308549272485
Validation loss: 7.272997152097855

Epoch: 5| Step: 2
Training loss: 6.766938044676357
Validation loss: 7.260002842521241

Epoch: 5| Step: 3
Training loss: 6.209148720398896
Validation loss: 7.241136280381615

Epoch: 5| Step: 4
Training loss: 7.126045016565992
Validation loss: 7.225465624399117

Epoch: 5| Step: 5
Training loss: 7.610129692987616
Validation loss: 7.2110105976176335

Epoch: 5| Step: 6
Training loss: 8.153901796192613
Validation loss: 7.194851900812821

Epoch: 5| Step: 7
Training loss: 6.813989319000517
Validation loss: 7.181188153722667

Epoch: 5| Step: 8
Training loss: 6.217799741899951
Validation loss: 7.165830628761036

Epoch: 5| Step: 9
Training loss: 7.803711365227275
Validation loss: 7.148657193061705

Epoch: 5| Step: 10
Training loss: 6.649525285570204
Validation loss: 7.13189039973287

Epoch: 15| Step: 0
Training loss: 8.007947788491327
Validation loss: 7.118057112301359

Epoch: 5| Step: 1
Training loss: 7.67063704251084
Validation loss: 7.101566560489734

Epoch: 5| Step: 2
Training loss: 7.261512297865424
Validation loss: 7.086154013719048

Epoch: 5| Step: 3
Training loss: 7.337864111943052
Validation loss: 7.067896349544048

Epoch: 5| Step: 4
Training loss: 6.557655217336674
Validation loss: 7.051672564007035

Epoch: 5| Step: 5
Training loss: 7.378439149869712
Validation loss: 7.032996701095264

Epoch: 5| Step: 6
Training loss: 6.798498201022535
Validation loss: 7.01310494153536

Epoch: 5| Step: 7
Training loss: 5.654591691364189
Validation loss: 6.999908464246389

Epoch: 5| Step: 8
Training loss: 6.98863742148877
Validation loss: 6.976263841794918

Epoch: 5| Step: 9
Training loss: 6.574722098507847
Validation loss: 6.968177789943784

Epoch: 5| Step: 10
Training loss: 6.137549486757119
Validation loss: 6.945487501121445

Epoch: 16| Step: 0
Training loss: 6.392192620326872
Validation loss: 6.926460938238256

Epoch: 5| Step: 1
Training loss: 6.821529738618275
Validation loss: 6.911182417128736

Epoch: 5| Step: 2
Training loss: 6.536412001568448
Validation loss: 6.89222805601855

Epoch: 5| Step: 3
Training loss: 6.593486183999611
Validation loss: 6.87319660417947

Epoch: 5| Step: 4
Training loss: 7.108547019951636
Validation loss: 6.86174218512145

Epoch: 5| Step: 5
Training loss: 7.251571484958611
Validation loss: 6.844645447361624

Epoch: 5| Step: 6
Training loss: 6.772996793531321
Validation loss: 6.8260360168845375

Epoch: 5| Step: 7
Training loss: 7.334766363519828
Validation loss: 6.7966632422007605

Epoch: 5| Step: 8
Training loss: 7.135372709338446
Validation loss: 6.784667077571999

Epoch: 5| Step: 9
Training loss: 6.450319433064863
Validation loss: 6.770491114850831

Epoch: 5| Step: 10
Training loss: 6.1418639042246435
Validation loss: 6.740014301541818

Epoch: 17| Step: 0
Training loss: 6.23880344753954
Validation loss: 6.730557462725038

Epoch: 5| Step: 1
Training loss: 6.684738016637168
Validation loss: 6.7029996118689175

Epoch: 5| Step: 2
Training loss: 6.3666284982758805
Validation loss: 6.684142382993692

Epoch: 5| Step: 3
Training loss: 7.1591540445293385
Validation loss: 6.666566938249101

Epoch: 5| Step: 4
Training loss: 6.811245023991977
Validation loss: 6.646090784087174

Epoch: 5| Step: 5
Training loss: 6.081457955077466
Validation loss: 6.6242585435759915

Epoch: 5| Step: 6
Training loss: 7.29144437905224
Validation loss: 6.6052731775215

Epoch: 5| Step: 7
Training loss: 6.930963134332949
Validation loss: 6.586654720374444

Epoch: 5| Step: 8
Training loss: 6.346848205780314
Validation loss: 6.56672415780265

Epoch: 5| Step: 9
Training loss: 6.691340689440941
Validation loss: 6.538330385281707

Epoch: 5| Step: 10
Training loss: 5.314253035384811
Validation loss: 6.524577113219497

Epoch: 18| Step: 0
Training loss: 5.585241912001321
Validation loss: 6.494754267914475

Epoch: 5| Step: 1
Training loss: 6.381228228166672
Validation loss: 6.478875426851869

Epoch: 5| Step: 2
Training loss: 6.221063998068691
Validation loss: 6.449346334129398

Epoch: 5| Step: 3
Training loss: 6.858837202187648
Validation loss: 6.425149901984259

Epoch: 5| Step: 4
Training loss: 6.665758388953379
Validation loss: 6.41094073529642

Epoch: 5| Step: 5
Training loss: 6.16275842213768
Validation loss: 6.3811450338121585

Epoch: 5| Step: 6
Training loss: 6.667350002871532
Validation loss: 6.369486001125869

Epoch: 5| Step: 7
Training loss: 6.024112252961369
Validation loss: 6.342264465914861

Epoch: 5| Step: 8
Training loss: 6.811830820237328
Validation loss: 6.312113337948096

Epoch: 5| Step: 9
Training loss: 6.17056886396874
Validation loss: 6.302961067644405

Epoch: 5| Step: 10
Training loss: 6.040651573758155
Validation loss: 6.273403232146647

Epoch: 19| Step: 0
Training loss: 5.354004596478808
Validation loss: 6.246606364025053

Epoch: 5| Step: 1
Training loss: 6.274858705670036
Validation loss: 6.217191289239849

Epoch: 5| Step: 2
Training loss: 7.653785028497415
Validation loss: 6.200801678053388

Epoch: 5| Step: 3
Training loss: 5.426745423128965
Validation loss: 6.175110575311295

Epoch: 5| Step: 4
Training loss: 6.384350072034361
Validation loss: 6.156540470652889

Epoch: 5| Step: 5
Training loss: 6.190554086663192
Validation loss: 6.125914678862957

Epoch: 5| Step: 6
Training loss: 5.39571664259329
Validation loss: 6.101071755356552

Epoch: 5| Step: 7
Training loss: 5.795887495382468
Validation loss: 6.0701921634030676

Epoch: 5| Step: 8
Training loss: 6.447346684207188
Validation loss: 6.053995229024542

Epoch: 5| Step: 9
Training loss: 6.005462067651089
Validation loss: 6.020430908425196

Epoch: 5| Step: 10
Training loss: 5.4474098840256255
Validation loss: 5.996835783500538

Epoch: 20| Step: 0
Training loss: 5.691886467922625
Validation loss: 5.966672663302676

Epoch: 5| Step: 1
Training loss: 5.4899988276579395
Validation loss: 5.948388252968222

Epoch: 5| Step: 2
Training loss: 5.565633512701414
Validation loss: 5.920099770548605

Epoch: 5| Step: 3
Training loss: 5.391203299200065
Validation loss: 5.890410303302024

Epoch: 5| Step: 4
Training loss: 5.759648727726099
Validation loss: 5.863745989507465

Epoch: 5| Step: 5
Training loss: 5.828806001286607
Validation loss: 5.842969976482297

Epoch: 5| Step: 6
Training loss: 6.061373261818793
Validation loss: 5.821813641764251

Epoch: 5| Step: 7
Training loss: 6.405807554271615
Validation loss: 5.773900452374668

Epoch: 5| Step: 8
Training loss: 6.1797384267220465
Validation loss: 5.760041233451243

Epoch: 5| Step: 9
Training loss: 5.545614437805594
Validation loss: 5.732351414520895

Epoch: 5| Step: 10
Training loss: 5.600833095162119
Validation loss: 5.700887087071162

Epoch: 21| Step: 0
Training loss: 5.43857695339085
Validation loss: 5.663498433745795

Epoch: 5| Step: 1
Training loss: 4.992859510105054
Validation loss: 5.643893020131942

Epoch: 5| Step: 2
Training loss: 5.057327265144353
Validation loss: 5.612902138822717

Epoch: 5| Step: 3
Training loss: 6.582657727048008
Validation loss: 5.580892744208829

Epoch: 5| Step: 4
Training loss: 5.541597332437015
Validation loss: 5.556852105248766

Epoch: 5| Step: 5
Training loss: 6.1047876799433
Validation loss: 5.5270217503138035

Epoch: 5| Step: 6
Training loss: 5.16117152377275
Validation loss: 5.493297796497834

Epoch: 5| Step: 7
Training loss: 5.09711106699158
Validation loss: 5.463355880317686

Epoch: 5| Step: 8
Training loss: 4.725815289917597
Validation loss: 5.441831401305172

Epoch: 5| Step: 9
Training loss: 6.20141024394225
Validation loss: 5.405804298660423

Epoch: 5| Step: 10
Training loss: 5.040436881067589
Validation loss: 5.368058375643531

Epoch: 22| Step: 0
Training loss: 5.129805754019796
Validation loss: 5.340563652359077

Epoch: 5| Step: 1
Training loss: 6.038353092429065
Validation loss: 5.315190654380424

Epoch: 5| Step: 2
Training loss: 6.025552380831207
Validation loss: 5.275974814512742

Epoch: 5| Step: 3
Training loss: 4.732880309189972
Validation loss: 5.247879133169364

Epoch: 5| Step: 4
Training loss: 4.8862581592490715
Validation loss: 5.210612472810406

Epoch: 5| Step: 5
Training loss: 4.290984732265332
Validation loss: 5.192060517577452

Epoch: 5| Step: 6
Training loss: 5.22666066623525
Validation loss: 5.154685999937879

Epoch: 5| Step: 7
Training loss: 5.77513863533372
Validation loss: 5.123932812116449

Epoch: 5| Step: 8
Training loss: 4.530238387212168
Validation loss: 5.08262688206079

Epoch: 5| Step: 9
Training loss: 4.491725944359085
Validation loss: 5.0562582425016425

Epoch: 5| Step: 10
Training loss: 5.311492644899482
Validation loss: 5.0263678332086625

Epoch: 23| Step: 0
Training loss: 5.972376815017338
Validation loss: 4.9861807391236574

Epoch: 5| Step: 1
Training loss: 5.741830412472638
Validation loss: 4.964702986537106

Epoch: 5| Step: 2
Training loss: 5.028626320588868
Validation loss: 4.925882795698138

Epoch: 5| Step: 3
Training loss: 5.182520671238321
Validation loss: 4.890217176145571

Epoch: 5| Step: 4
Training loss: 4.45389076475119
Validation loss: 4.862053948227647

Epoch: 5| Step: 5
Training loss: 4.922417117341805
Validation loss: 4.832666390683468

Epoch: 5| Step: 6
Training loss: 3.720576759255047
Validation loss: 4.803917010102926

Epoch: 5| Step: 7
Training loss: 5.150233231976005
Validation loss: 4.779831203604416

Epoch: 5| Step: 8
Training loss: 4.385612477380761
Validation loss: 4.739910634326276

Epoch: 5| Step: 9
Training loss: 4.220433330253801
Validation loss: 4.719968363991501

Epoch: 5| Step: 10
Training loss: 3.311492190808421
Validation loss: 4.679445754787124

Epoch: 24| Step: 0
Training loss: 4.416131592973647
Validation loss: 4.642790799600546

Epoch: 5| Step: 1
Training loss: 4.56233612184283
Validation loss: 4.617825757047447

Epoch: 5| Step: 2
Training loss: 4.570712497519982
Validation loss: 4.590309140766658

Epoch: 5| Step: 3
Training loss: 4.125671794402331
Validation loss: 4.554558581262726

Epoch: 5| Step: 4
Training loss: 4.182574435596067
Validation loss: 4.508564330691002

Epoch: 5| Step: 5
Training loss: 4.498552937432635
Validation loss: 4.478480973335119

Epoch: 5| Step: 6
Training loss: 4.703629678915218
Validation loss: 4.454723852489535

Epoch: 5| Step: 7
Training loss: 3.90375640624318
Validation loss: 4.426321698084374

Epoch: 5| Step: 8
Training loss: 4.534571200016335
Validation loss: 4.3859906870122956

Epoch: 5| Step: 9
Training loss: 5.422551269570271
Validation loss: 4.354017506053394

Epoch: 5| Step: 10
Training loss: 3.889760974708941
Validation loss: 4.335922200683043

Epoch: 25| Step: 0
Training loss: 4.552431048185829
Validation loss: 4.279833299434046

Epoch: 5| Step: 1
Training loss: 3.9663681933095245
Validation loss: 4.265594550827198

Epoch: 5| Step: 2
Training loss: 4.2744766450396305
Validation loss: 4.230777027542591

Epoch: 5| Step: 3
Training loss: 4.47309077788253
Validation loss: 4.2173839646900095

Epoch: 5| Step: 4
Training loss: 3.201138806361382
Validation loss: 4.17017055153355

Epoch: 5| Step: 5
Training loss: 4.722201670184322
Validation loss: 4.1360916046071425

Epoch: 5| Step: 6
Training loss: 4.195578909430009
Validation loss: 4.116421580823094

Epoch: 5| Step: 7
Training loss: 4.26741901162189
Validation loss: 4.080695991745898

Epoch: 5| Step: 8
Training loss: 3.510975386682959
Validation loss: 4.029586760488578

Epoch: 5| Step: 9
Training loss: 4.070165591233787
Validation loss: 4.006871665986102

Epoch: 5| Step: 10
Training loss: 3.915920037603649
Validation loss: 3.9792357450954525

Epoch: 26| Step: 0
Training loss: 3.9098823443806356
Validation loss: 3.9592003089303454

Epoch: 5| Step: 1
Training loss: 3.983665253498179
Validation loss: 3.929019043012802

Epoch: 5| Step: 2
Training loss: 3.811185641497606
Validation loss: 3.9020313871777192

Epoch: 5| Step: 3
Training loss: 3.94926897841451
Validation loss: 3.8581443207086945

Epoch: 5| Step: 4
Training loss: 3.2315784102991563
Validation loss: 3.8198562196254153

Epoch: 5| Step: 5
Training loss: 4.511357280568616
Validation loss: 3.7895447356804497

Epoch: 5| Step: 6
Training loss: 3.3926649856648172
Validation loss: 3.77748425767205

Epoch: 5| Step: 7
Training loss: 3.867520527997862
Validation loss: 3.7375301748784753

Epoch: 5| Step: 8
Training loss: 3.843715264388272
Validation loss: 3.729572620295738

Epoch: 5| Step: 9
Training loss: 3.5073332937134616
Validation loss: 3.6868357073069444

Epoch: 5| Step: 10
Training loss: 3.876613527121277
Validation loss: 3.6614148675001554

Epoch: 27| Step: 0
Training loss: 4.223758691223902
Validation loss: 3.6286066152515457

Epoch: 5| Step: 1
Training loss: 3.454536253173109
Validation loss: 3.617160695404419

Epoch: 5| Step: 2
Training loss: 3.6039283247328897
Validation loss: 3.58294578673432

Epoch: 5| Step: 3
Training loss: 3.0712134517223055
Validation loss: 3.5736073606328853

Epoch: 5| Step: 4
Training loss: 3.622523020584958
Validation loss: 3.5416049515174595

Epoch: 5| Step: 5
Training loss: 3.243320790966073
Validation loss: 3.5220949539093396

Epoch: 5| Step: 6
Training loss: 2.9371625016495413
Validation loss: 3.5061427661547584

Epoch: 5| Step: 7
Training loss: 4.531916076112052
Validation loss: 3.4710161957738386

Epoch: 5| Step: 8
Training loss: 3.3906760497579027
Validation loss: 3.447648390429566

Epoch: 5| Step: 9
Training loss: 3.6825565888510567
Validation loss: 3.437692598408404

Epoch: 5| Step: 10
Training loss: 2.8581670492162607
Validation loss: 3.4105842022133217

Epoch: 28| Step: 0
Training loss: 3.2606797442265285
Validation loss: 3.3961699848809217

Epoch: 5| Step: 1
Training loss: 3.376093086966109
Validation loss: 3.3449686333208826

Epoch: 5| Step: 2
Training loss: 3.7705893815234797
Validation loss: 3.347361651527044

Epoch: 5| Step: 3
Training loss: 3.1109300874844985
Validation loss: 3.3387085280659905

Epoch: 5| Step: 4
Training loss: 3.8206164155299205
Validation loss: 3.3159872263062633

Epoch: 5| Step: 5
Training loss: 3.1693025126110745
Validation loss: 3.2986816065965554

Epoch: 5| Step: 6
Training loss: 2.5793690772019775
Validation loss: 3.272259398924127

Epoch: 5| Step: 7
Training loss: 3.5790434745456765
Validation loss: 3.272050982945208

Epoch: 5| Step: 8
Training loss: 3.7718419083832155
Validation loss: 3.251687308385688

Epoch: 5| Step: 9
Training loss: 3.599456237416719
Validation loss: 3.2300693267861615

Epoch: 5| Step: 10
Training loss: 2.408633253260479
Validation loss: 3.197822654127587

Epoch: 29| Step: 0
Training loss: 3.1999266496834724
Validation loss: 3.2156365327327214

Epoch: 5| Step: 1
Training loss: 3.428041241160706
Validation loss: 3.1715943370780546

Epoch: 5| Step: 2
Training loss: 2.784904479301182
Validation loss: 3.1464099226596587

Epoch: 5| Step: 3
Training loss: 2.693711753626805
Validation loss: 3.1400701164984914

Epoch: 5| Step: 4
Training loss: 2.857694538533033
Validation loss: 3.1340148809856485

Epoch: 5| Step: 5
Training loss: 3.436384956537763
Validation loss: 3.1264016927134084

Epoch: 5| Step: 6
Training loss: 3.3366425459298275
Validation loss: 3.111241175188316

Epoch: 5| Step: 7
Training loss: 3.713747522641553
Validation loss: 3.096137602051259

Epoch: 5| Step: 8
Training loss: 2.914288795827524
Validation loss: 3.0856247950779

Epoch: 5| Step: 9
Training loss: 3.042793239482793
Validation loss: 3.075065967110009

Epoch: 5| Step: 10
Training loss: 3.9297930663473264
Validation loss: 3.0942851635702477

Epoch: 30| Step: 0
Training loss: 3.5909013155467813
Validation loss: 3.0631083699748194

Epoch: 5| Step: 1
Training loss: 4.128998177045483
Validation loss: 3.045759637942506

Epoch: 5| Step: 2
Training loss: 2.912343517896773
Validation loss: 3.0518626830099445

Epoch: 5| Step: 3
Training loss: 2.7341230003856434
Validation loss: 3.039206330833957

Epoch: 5| Step: 4
Training loss: 1.7148107295235206
Validation loss: 3.0415707459428196

Epoch: 5| Step: 5
Training loss: 3.0932934356725363
Validation loss: 3.0450680339093776

Epoch: 5| Step: 6
Training loss: 3.633447997590758
Validation loss: 3.0302369954142727

Epoch: 5| Step: 7
Training loss: 2.7658183574433894
Validation loss: 3.016522781785495

Epoch: 5| Step: 8
Training loss: 3.3896338073186145
Validation loss: 3.024181109495115

Epoch: 5| Step: 9
Training loss: 2.553164433486446
Validation loss: 2.988706044054636

Epoch: 5| Step: 10
Training loss: 3.4746725024127723
Validation loss: 3.003548871344866

Epoch: 31| Step: 0
Training loss: 2.930689607259131
Validation loss: 3.006437936029771

Epoch: 5| Step: 1
Training loss: 3.621405825700697
Validation loss: 2.999669417416849

Epoch: 5| Step: 2
Training loss: 2.955279820549828
Validation loss: 2.9973315767538624

Epoch: 5| Step: 3
Training loss: 3.9007005258004592
Validation loss: 2.9888278818050074

Epoch: 5| Step: 4
Training loss: 2.4270937896197666
Validation loss: 2.998025502464777

Epoch: 5| Step: 5
Training loss: 2.965302402970809
Validation loss: 2.9891693401986528

Epoch: 5| Step: 6
Training loss: 3.2247180608481805
Validation loss: 2.9966868765814727

Epoch: 5| Step: 7
Training loss: 3.3460689596308355
Validation loss: 3.00118015945571

Epoch: 5| Step: 8
Training loss: 3.250381007235876
Validation loss: 2.9703481486286254

Epoch: 5| Step: 9
Training loss: 2.75705715133767
Validation loss: 2.9532258406697047

Epoch: 5| Step: 10
Training loss: 2.8237437670581076
Validation loss: 2.9788801429924927

Epoch: 32| Step: 0
Training loss: 3.3631255748488114
Validation loss: 2.976270089463151

Epoch: 5| Step: 1
Training loss: 2.322981099374103
Validation loss: 2.987888719564659

Epoch: 5| Step: 2
Training loss: 2.601004234190255
Validation loss: 2.9771426831013597

Epoch: 5| Step: 3
Training loss: 3.0407550090035653
Validation loss: 2.9696381825427998

Epoch: 5| Step: 4
Training loss: 3.4826022030305475
Validation loss: 2.9516225294705607

Epoch: 5| Step: 5
Training loss: 2.932212778840497
Validation loss: 2.9691553690756773

Epoch: 5| Step: 6
Training loss: 3.3728997088534793
Validation loss: 2.9602130052557434

Epoch: 5| Step: 7
Training loss: 3.4062880767653905
Validation loss: 2.9668007686798203

Epoch: 5| Step: 8
Training loss: 3.766631818852098
Validation loss: 2.9735970763774797

Epoch: 5| Step: 9
Training loss: 2.657119429173004
Validation loss: 2.984365992292767

Epoch: 5| Step: 10
Training loss: 3.038802657995132
Validation loss: 2.956168890943049

Epoch: 33| Step: 0
Training loss: 3.1371677785117305
Validation loss: 2.9504838513658034

Epoch: 5| Step: 1
Training loss: 2.8627766038276286
Validation loss: 2.9708070261592345

Epoch: 5| Step: 2
Training loss: 2.3369348750640286
Validation loss: 2.97432912554408

Epoch: 5| Step: 3
Training loss: 3.313743214062477
Validation loss: 2.9496440278485663

Epoch: 5| Step: 4
Training loss: 3.7959787072246765
Validation loss: 2.947217131189316

Epoch: 5| Step: 5
Training loss: 2.3630054155272338
Validation loss: 2.935642762804395

Epoch: 5| Step: 6
Training loss: 3.488663296853957
Validation loss: 2.9491986282793334

Epoch: 5| Step: 7
Training loss: 3.5758913222830606
Validation loss: 2.9421970513857487

Epoch: 5| Step: 8
Training loss: 2.6052728261874702
Validation loss: 2.975544684081544

Epoch: 5| Step: 9
Training loss: 3.1912950848907182
Validation loss: 2.9421044496232964

Epoch: 5| Step: 10
Training loss: 3.2522468136433047
Validation loss: 2.941143383283974

Epoch: 34| Step: 0
Training loss: 2.716466712223915
Validation loss: 2.950675132642826

Epoch: 5| Step: 1
Training loss: 3.1652499760988624
Validation loss: 2.957853281488955

Epoch: 5| Step: 2
Training loss: 3.124324725624707
Validation loss: 2.9422248764809096

Epoch: 5| Step: 3
Training loss: 2.99955984701387
Validation loss: 2.9325359792552828

Epoch: 5| Step: 4
Training loss: 2.823228760155937
Validation loss: 2.9683651893320766

Epoch: 5| Step: 5
Training loss: 3.65249062309132
Validation loss: 2.9551115857260175

Epoch: 5| Step: 6
Training loss: 2.5078850376179447
Validation loss: 2.9503348819346185

Epoch: 5| Step: 7
Training loss: 3.7135309091691284
Validation loss: 2.939044898289985

Epoch: 5| Step: 8
Training loss: 2.454539868961748
Validation loss: 2.9639283692850245

Epoch: 5| Step: 9
Training loss: 3.154969512743788
Validation loss: 2.9692626329183245

Epoch: 5| Step: 10
Training loss: 3.6081700811538377
Validation loss: 2.9523784012502534

Epoch: 35| Step: 0
Training loss: 2.7163507683534944
Validation loss: 2.9639987301497643

Epoch: 5| Step: 1
Training loss: 3.3210121046039234
Validation loss: 2.955614082611639

Epoch: 5| Step: 2
Training loss: 3.3886440133040483
Validation loss: 2.9389338086833057

Epoch: 5| Step: 3
Training loss: 4.151121948435884
Validation loss: 2.927029002478074

Epoch: 5| Step: 4
Training loss: 2.0660074638830115
Validation loss: 2.916576876041943

Epoch: 5| Step: 5
Training loss: 3.485767445505088
Validation loss: 2.9411346450035847

Epoch: 5| Step: 6
Training loss: 2.479842363700506
Validation loss: 2.9463551634368055

Epoch: 5| Step: 7
Training loss: 2.7320439457018875
Validation loss: 2.962164152641598

Epoch: 5| Step: 8
Training loss: 2.9836907526086125
Validation loss: 2.9480889220513085

Epoch: 5| Step: 9
Training loss: 3.407596566951279
Validation loss: 2.93223466342191

Epoch: 5| Step: 10
Training loss: 2.599768859419238
Validation loss: 2.9213704889974883

Epoch: 36| Step: 0
Training loss: 1.9396917190616498
Validation loss: 2.942980638356303

Epoch: 5| Step: 1
Training loss: 3.2487485383497576
Validation loss: 2.9448522127191272

Epoch: 5| Step: 2
Training loss: 3.672445958975331
Validation loss: 2.9489850886211015

Epoch: 5| Step: 3
Training loss: 2.786107482688048
Validation loss: 2.937953368533108

Epoch: 5| Step: 4
Training loss: 2.3061887862189177
Validation loss: 2.9426924998105797

Epoch: 5| Step: 5
Training loss: 3.931419279156441
Validation loss: 2.9648512329299397

Epoch: 5| Step: 6
Training loss: 3.4147015634720006
Validation loss: 2.941950647439046

Epoch: 5| Step: 7
Training loss: 2.9265199347566098
Validation loss: 2.9185192717079427

Epoch: 5| Step: 8
Training loss: 3.089187648864183
Validation loss: 2.9688486330047303

Epoch: 5| Step: 9
Training loss: 2.8396822163266227
Validation loss: 2.9378211012396758

Epoch: 5| Step: 10
Training loss: 3.474815221031544
Validation loss: 2.936785078356356

Epoch: 37| Step: 0
Training loss: 3.528862340086845
Validation loss: 2.9557188550581213

Epoch: 5| Step: 1
Training loss: 3.3469060816243212
Validation loss: 2.953460044104644

Epoch: 5| Step: 2
Training loss: 3.2691103209664574
Validation loss: 2.9360745701785054

Epoch: 5| Step: 3
Training loss: 2.691842762134276
Validation loss: 2.9419006987544383

Epoch: 5| Step: 4
Training loss: 2.9320200675183936
Validation loss: 2.923355938919016

Epoch: 5| Step: 5
Training loss: 4.016596932551124
Validation loss: 2.950374416341666

Epoch: 5| Step: 6
Training loss: 2.4510660460221976
Validation loss: 2.939424252370826

Epoch: 5| Step: 7
Training loss: 1.8567236581795439
Validation loss: 2.9504975276345493

Epoch: 5| Step: 8
Training loss: 3.0237500721622754
Validation loss: 2.9598058068785513

Epoch: 5| Step: 9
Training loss: 3.45353924091999
Validation loss: 2.931886923971808

Epoch: 5| Step: 10
Training loss: 2.8298501501410667
Validation loss: 2.9153854752694146

Epoch: 38| Step: 0
Training loss: 3.2531738922519926
Validation loss: 2.946424167237162

Epoch: 5| Step: 1
Training loss: 3.026492130719915
Validation loss: 2.9155902358717145

Epoch: 5| Step: 2
Training loss: 3.1148813842918655
Validation loss: 2.925080454753823

Epoch: 5| Step: 3
Training loss: 3.0816808000910645
Validation loss: 2.9248602704123305

Epoch: 5| Step: 4
Training loss: 2.9104154535362503
Validation loss: 2.9207259471953204

Epoch: 5| Step: 5
Training loss: 3.2299807270998575
Validation loss: 2.9198979849953886

Epoch: 5| Step: 6
Training loss: 2.5081621443248285
Validation loss: 2.9489541524883522

Epoch: 5| Step: 7
Training loss: 3.698738816255019
Validation loss: 2.9329777758230753

Epoch: 5| Step: 8
Training loss: 2.7254921634934415
Validation loss: 2.916619477717987

Epoch: 5| Step: 9
Training loss: 3.467521106130424
Validation loss: 2.9571199946056614

Epoch: 5| Step: 10
Training loss: 2.7943684518524488
Validation loss: 2.9272329310973477

Epoch: 39| Step: 0
Training loss: 3.9267726272724763
Validation loss: 2.9477791128863187

Epoch: 5| Step: 1
Training loss: 2.775463642875252
Validation loss: 2.936261579502181

Epoch: 5| Step: 2
Training loss: 3.2149189491793537
Validation loss: 2.9261704464540794

Epoch: 5| Step: 3
Training loss: 3.074014775684315
Validation loss: 2.9041786588246237

Epoch: 5| Step: 4
Training loss: 3.375095789927528
Validation loss: 2.9411718786141647

Epoch: 5| Step: 5
Training loss: 2.8280207156349304
Validation loss: 2.9376599895097266

Epoch: 5| Step: 6
Training loss: 2.663658670822603
Validation loss: 2.917774718330069

Epoch: 5| Step: 7
Training loss: 3.124518700729131
Validation loss: 2.9264807806585957

Epoch: 5| Step: 8
Training loss: 3.2755653184629945
Validation loss: 2.934865833880398

Epoch: 5| Step: 9
Training loss: 2.478515721194098
Validation loss: 2.952402598052796

Epoch: 5| Step: 10
Training loss: 2.9949127615066926
Validation loss: 2.926389056961829

Epoch: 40| Step: 0
Training loss: 3.211443264893205
Validation loss: 2.914050332180107

Epoch: 5| Step: 1
Training loss: 3.885866986207463
Validation loss: 2.923135807098474

Epoch: 5| Step: 2
Training loss: 2.1861844057654336
Validation loss: 2.930454814880807

Epoch: 5| Step: 3
Training loss: 2.2943743113384496
Validation loss: 2.9601217240240776

Epoch: 5| Step: 4
Training loss: 3.2519661751333495
Validation loss: 2.9592208329756198

Epoch: 5| Step: 5
Training loss: 2.1410808217144734
Validation loss: 2.9503255704437192

Epoch: 5| Step: 6
Training loss: 3.9282192270514087
Validation loss: 2.9384978822068657

Epoch: 5| Step: 7
Training loss: 2.468259835171759
Validation loss: 2.9487700590085817

Epoch: 5| Step: 8
Training loss: 2.9890038507972125
Validation loss: 2.9440259467411494

Epoch: 5| Step: 9
Training loss: 3.603296222572124
Validation loss: 2.933452831721368

Epoch: 5| Step: 10
Training loss: 3.1740476186121223
Validation loss: 2.943583403747242

Epoch: 41| Step: 0
Training loss: 2.790050256884919
Validation loss: 2.912635723798004

Epoch: 5| Step: 1
Training loss: 2.7977984731274215
Validation loss: 2.9435550375804427

Epoch: 5| Step: 2
Training loss: 2.4295593424173934
Validation loss: 2.956079261815017

Epoch: 5| Step: 3
Training loss: 3.1024388533352405
Validation loss: 2.915681831519866

Epoch: 5| Step: 4
Training loss: 3.6195452196859033
Validation loss: 2.9315269885263464

Epoch: 5| Step: 5
Training loss: 3.3705704902868705
Validation loss: 2.916774665719851

Epoch: 5| Step: 6
Training loss: 3.3000056873619315
Validation loss: 2.9324617556014245

Epoch: 5| Step: 7
Training loss: 2.6345424684847103
Validation loss: 2.9213395333542778

Epoch: 5| Step: 8
Training loss: 3.586437049261145
Validation loss: 2.926873364911714

Epoch: 5| Step: 9
Training loss: 3.0187244990754554
Validation loss: 2.946413826254095

Epoch: 5| Step: 10
Training loss: 2.8601868524401657
Validation loss: 2.9325381367949706

Epoch: 42| Step: 0
Training loss: 3.2927802089596874
Validation loss: 2.913428500463574

Epoch: 5| Step: 1
Training loss: 2.8275022716833513
Validation loss: 2.920733318454137

Epoch: 5| Step: 2
Training loss: 3.5916888089541126
Validation loss: 2.939499376433448

Epoch: 5| Step: 3
Training loss: 3.181430498259987
Validation loss: 2.9255845722160285

Epoch: 5| Step: 4
Training loss: 3.3155920604108657
Validation loss: 2.9123663765871557

Epoch: 5| Step: 5
Training loss: 2.3048004639953126
Validation loss: 2.927011471396357

Epoch: 5| Step: 6
Training loss: 3.0767514025039557
Validation loss: 2.926009249575616

Epoch: 5| Step: 7
Training loss: 3.4458266240108046
Validation loss: 2.9233075588722994

Epoch: 5| Step: 8
Training loss: 2.483114246543876
Validation loss: 2.94837511852438

Epoch: 5| Step: 9
Training loss: 2.369835810547097
Validation loss: 2.9117305646760268

Epoch: 5| Step: 10
Training loss: 3.42864195717068
Validation loss: 2.9070127264563683

Epoch: 43| Step: 0
Training loss: 3.585237056497344
Validation loss: 2.893761679422619

Epoch: 5| Step: 1
Training loss: 3.047284064587364
Validation loss: 2.9125912172096613

Epoch: 5| Step: 2
Training loss: 2.582226998300489
Validation loss: 2.9324757467154696

Epoch: 5| Step: 3
Training loss: 2.403129932810231
Validation loss: 2.922721972107047

Epoch: 5| Step: 4
Training loss: 3.0795280241065064
Validation loss: 2.9346457713509437

Epoch: 5| Step: 5
Training loss: 2.8101387284267925
Validation loss: 2.9465814257551495

Epoch: 5| Step: 6
Training loss: 3.3171148722564054
Validation loss: 2.9490971013779683

Epoch: 5| Step: 7
Training loss: 3.2988122247433562
Validation loss: 2.93581610393739

Epoch: 5| Step: 8
Training loss: 2.915465316406531
Validation loss: 2.9023822333652882

Epoch: 5| Step: 9
Training loss: 2.932565480937773
Validation loss: 2.925797874556463

Epoch: 5| Step: 10
Training loss: 3.559287513414646
Validation loss: 2.9194723343692632

Epoch: 44| Step: 0
Training loss: 3.386084544496854
Validation loss: 2.9275543177881183

Epoch: 5| Step: 1
Training loss: 2.657208617520259
Validation loss: 2.9126252619722877

Epoch: 5| Step: 2
Training loss: 2.506694508847709
Validation loss: 2.93001005763808

Epoch: 5| Step: 3
Training loss: 3.7608278988382566
Validation loss: 2.9180958570232556

Epoch: 5| Step: 4
Training loss: 3.3624436668016537
Validation loss: 2.8986684357101824

Epoch: 5| Step: 5
Training loss: 3.0374808228440733
Validation loss: 2.9171298917572774

Epoch: 5| Step: 6
Training loss: 2.4703435462771774
Validation loss: 2.898776326763865

Epoch: 5| Step: 7
Training loss: 3.325609429517807
Validation loss: 2.914220041012048

Epoch: 5| Step: 8
Training loss: 3.560135575402513
Validation loss: 2.9073519355986805

Epoch: 5| Step: 9
Training loss: 2.733635677115324
Validation loss: 2.9066479168262984

Epoch: 5| Step: 10
Training loss: 2.479441031866935
Validation loss: 2.9201686689946387

Epoch: 45| Step: 0
Training loss: 2.6466733745358626
Validation loss: 2.928316764625219

Epoch: 5| Step: 1
Training loss: 2.7777351715211207
Validation loss: 2.908745578865963

Epoch: 5| Step: 2
Training loss: 2.594569616772087
Validation loss: 2.906027724628735

Epoch: 5| Step: 3
Training loss: 2.2459145648635026
Validation loss: 2.9064599414637504

Epoch: 5| Step: 4
Training loss: 2.6764383887417376
Validation loss: 2.9293344531341123

Epoch: 5| Step: 5
Training loss: 3.541360340708658
Validation loss: 2.9248122693610554

Epoch: 5| Step: 6
Training loss: 4.125721723823801
Validation loss: 2.9054003410856994

Epoch: 5| Step: 7
Training loss: 3.281066598762161
Validation loss: 2.895415840735011

Epoch: 5| Step: 8
Training loss: 2.5704641558305985
Validation loss: 2.9213880170736535

Epoch: 5| Step: 9
Training loss: 3.1765198921914974
Validation loss: 2.9075968648513797

Epoch: 5| Step: 10
Training loss: 3.6470798359723435
Validation loss: 2.934073514404494

Epoch: 46| Step: 0
Training loss: 2.8169755717373794
Validation loss: 2.92614802852284

Epoch: 5| Step: 1
Training loss: 2.6451465786735633
Validation loss: 2.9262044799762643

Epoch: 5| Step: 2
Training loss: 4.156315164843941
Validation loss: 2.8953120931910163

Epoch: 5| Step: 3
Training loss: 2.6537293086276224
Validation loss: 2.9149129584858198

Epoch: 5| Step: 4
Training loss: 2.800535651469223
Validation loss: 2.924958384200016

Epoch: 5| Step: 5
Training loss: 2.4337667584344334
Validation loss: 2.9229502383825836

Epoch: 5| Step: 6
Training loss: 3.2974236922150975
Validation loss: 2.9275071131430135

Epoch: 5| Step: 7
Training loss: 3.4861905281845558
Validation loss: 2.9301261948582304

Epoch: 5| Step: 8
Training loss: 2.9577551979765375
Validation loss: 2.9184203862746405

Epoch: 5| Step: 9
Training loss: 2.387814534025071
Validation loss: 2.9189374071238667

Epoch: 5| Step: 10
Training loss: 3.554844578217276
Validation loss: 2.8931261323040993

Epoch: 47| Step: 0
Training loss: 2.914556139332171
Validation loss: 2.914598711612349

Epoch: 5| Step: 1
Training loss: 2.887723549120064
Validation loss: 2.911151178931171

Epoch: 5| Step: 2
Training loss: 2.9388387348468163
Validation loss: 2.8914962737029115

Epoch: 5| Step: 3
Training loss: 2.4402503122853783
Validation loss: 2.903270533660397

Epoch: 5| Step: 4
Training loss: 3.5712034753980784
Validation loss: 2.9036022134259243

Epoch: 5| Step: 5
Training loss: 3.382664067137184
Validation loss: 2.915302144350871

Epoch: 5| Step: 6
Training loss: 3.182523245535533
Validation loss: 2.9195312142086403

Epoch: 5| Step: 7
Training loss: 3.5248825594770485
Validation loss: 2.9242747517387904

Epoch: 5| Step: 8
Training loss: 2.1971615643761666
Validation loss: 2.919329266154861

Epoch: 5| Step: 9
Training loss: 3.124538387537089
Validation loss: 2.9055124388483855

Epoch: 5| Step: 10
Training loss: 3.13091222346031
Validation loss: 2.9141097332869417

Epoch: 48| Step: 0
Training loss: 2.9565477668855573
Validation loss: 2.9217604019743773

Epoch: 5| Step: 1
Training loss: 3.5436420242571827
Validation loss: 2.923075406293877

Epoch: 5| Step: 2
Training loss: 3.072132609713891
Validation loss: 2.9214510142558776

Epoch: 5| Step: 3
Training loss: 2.289588008617826
Validation loss: 2.9228622438356564

Epoch: 5| Step: 4
Training loss: 3.0841886176134095
Validation loss: 2.9256693969534626

Epoch: 5| Step: 5
Training loss: 3.3168367032373456
Validation loss: 2.9139566617551993

Epoch: 5| Step: 6
Training loss: 2.834932175351427
Validation loss: 2.906956114406507

Epoch: 5| Step: 7
Training loss: 3.0134291486219893
Validation loss: 2.9090779412937033

Epoch: 5| Step: 8
Training loss: 3.2099493506407852
Validation loss: 2.900791479016639

Epoch: 5| Step: 9
Training loss: 3.3719139118088264
Validation loss: 2.9080787979820957

Epoch: 5| Step: 10
Training loss: 2.6547367946814697
Validation loss: 2.896072728963451

Epoch: 49| Step: 0
Training loss: 3.322965679385219
Validation loss: 2.928538909100706

Epoch: 5| Step: 1
Training loss: 3.3758155402552155
Validation loss: 2.928865207356797

Epoch: 5| Step: 2
Training loss: 3.0583826530561296
Validation loss: 2.9063271873827863

Epoch: 5| Step: 3
Training loss: 2.811767482732725
Validation loss: 2.920932297670402

Epoch: 5| Step: 4
Training loss: 3.19013135418368
Validation loss: 2.8861511872318957

Epoch: 5| Step: 5
Training loss: 3.3555763236267
Validation loss: 2.878476388499118

Epoch: 5| Step: 6
Training loss: 2.55666972027944
Validation loss: 2.89869891178229

Epoch: 5| Step: 7
Training loss: 2.746868518044871
Validation loss: 2.889626512517516

Epoch: 5| Step: 8
Training loss: 3.145683200782084
Validation loss: 2.8955565012101196

Epoch: 5| Step: 9
Training loss: 2.705694487823411
Validation loss: 2.8774910398953364

Epoch: 5| Step: 10
Training loss: 2.999156515435156
Validation loss: 2.8879133840836655

Epoch: 50| Step: 0
Training loss: 2.827191615063205
Validation loss: 2.8876080085857994

Epoch: 5| Step: 1
Training loss: 2.9181583041678176
Validation loss: 2.9443868714137746

Epoch: 5| Step: 2
Training loss: 2.8438970506815973
Validation loss: 2.8747206958426115

Epoch: 5| Step: 3
Training loss: 3.1138561679989896
Validation loss: 2.9041634244222925

Epoch: 5| Step: 4
Training loss: 2.616158992170478
Validation loss: 2.9044954400162046

Epoch: 5| Step: 5
Training loss: 2.147105188814348
Validation loss: 2.8766828759436063

Epoch: 5| Step: 6
Training loss: 3.3439199814417147
Validation loss: 2.882752488674933

Epoch: 5| Step: 7
Training loss: 3.3937459197467703
Validation loss: 2.890514613124951

Epoch: 5| Step: 8
Training loss: 3.4326917832844126
Validation loss: 2.915659224793989

Epoch: 5| Step: 9
Training loss: 4.1755914600374515
Validation loss: 2.888306580807504

Epoch: 5| Step: 10
Training loss: 1.9858478877080752
Validation loss: 2.9005768839706163

Epoch: 51| Step: 0
Training loss: 3.2349580248507688
Validation loss: 2.8868921790548843

Epoch: 5| Step: 1
Training loss: 2.6177904032420924
Validation loss: 2.8932332331931936

Epoch: 5| Step: 2
Training loss: 2.476221199465108
Validation loss: 2.8951236731435994

Epoch: 5| Step: 3
Training loss: 3.4721392320675726
Validation loss: 2.9091165770362473

Epoch: 5| Step: 4
Training loss: 2.521378471342998
Validation loss: 2.87374827139657

Epoch: 5| Step: 5
Training loss: 3.1159408485762645
Validation loss: 2.896856429283911

Epoch: 5| Step: 6
Training loss: 2.5739228189926564
Validation loss: 2.879990526942029

Epoch: 5| Step: 7
Training loss: 3.642820293977438
Validation loss: 2.8925919137463083

Epoch: 5| Step: 8
Training loss: 2.4552693319100487
Validation loss: 2.9153017838075472

Epoch: 5| Step: 9
Training loss: 3.786069588555171
Validation loss: 2.886819639589151

Epoch: 5| Step: 10
Training loss: 3.009459364234385
Validation loss: 2.8638604760996387

Epoch: 52| Step: 0
Training loss: 2.9360497323795216
Validation loss: 2.902976441925659

Epoch: 5| Step: 1
Training loss: 3.0863852646867005
Validation loss: 2.8872454983846283

Epoch: 5| Step: 2
Training loss: 3.165288390991338
Validation loss: 2.885219283057223

Epoch: 5| Step: 3
Training loss: 3.008907128840196
Validation loss: 2.9045584311143395

Epoch: 5| Step: 4
Training loss: 2.8967961602043064
Validation loss: 2.891624482315755

Epoch: 5| Step: 5
Training loss: 3.247751925639581
Validation loss: 2.884763957831208

Epoch: 5| Step: 6
Training loss: 2.950531320084703
Validation loss: 2.8828092879023925

Epoch: 5| Step: 7
Training loss: 2.9693246385675147
Validation loss: 2.8752050616452207

Epoch: 5| Step: 8
Training loss: 2.6568574098710527
Validation loss: 2.8948309712768068

Epoch: 5| Step: 9
Training loss: 2.6215992651842033
Validation loss: 2.901117594062552

Epoch: 5| Step: 10
Training loss: 3.7203158119440056
Validation loss: 2.907140816916838

Epoch: 53| Step: 0
Training loss: 3.5774595483056384
Validation loss: 2.8728868950202613

Epoch: 5| Step: 1
Training loss: 3.197683037953928
Validation loss: 2.897038409480292

Epoch: 5| Step: 2
Training loss: 2.299807797569553
Validation loss: 2.897776710220581

Epoch: 5| Step: 3
Training loss: 3.248800643285459
Validation loss: 2.8694536944989415

Epoch: 5| Step: 4
Training loss: 2.3572055366571494
Validation loss: 2.898463735640539

Epoch: 5| Step: 5
Training loss: 3.5469348247036905
Validation loss: 2.9028930347445523

Epoch: 5| Step: 6
Training loss: 2.660881223772291
Validation loss: 2.8841348723144193

Epoch: 5| Step: 7
Training loss: 3.1794133548511523
Validation loss: 2.8936277172817357

Epoch: 5| Step: 8
Training loss: 2.937221270384431
Validation loss: 2.878898090417717

Epoch: 5| Step: 9
Training loss: 2.3572101893035327
Validation loss: 2.8749392352787337

Epoch: 5| Step: 10
Training loss: 3.7518311162489066
Validation loss: 2.9134012072542026

Epoch: 54| Step: 0
Training loss: 3.9612338765936608
Validation loss: 2.8966515560268866

Epoch: 5| Step: 1
Training loss: 2.796631360230886
Validation loss: 2.874480843986336

Epoch: 5| Step: 2
Training loss: 2.7006872574018046
Validation loss: 2.8973149879315376

Epoch: 5| Step: 3
Training loss: 2.4976228856736014
Validation loss: 2.8846695728223897

Epoch: 5| Step: 4
Training loss: 3.570409593993983
Validation loss: 2.8993990789324493

Epoch: 5| Step: 5
Training loss: 2.924144495867953
Validation loss: 2.8873243898132595

Epoch: 5| Step: 6
Training loss: 2.7546962173159537
Validation loss: 2.9068905691970506

Epoch: 5| Step: 7
Training loss: 3.1407695376410887
Validation loss: 2.8843054622865805

Epoch: 5| Step: 8
Training loss: 2.2480898272191747
Validation loss: 2.889170175527741

Epoch: 5| Step: 9
Training loss: 3.456314616090791
Validation loss: 2.8799129755135824

Epoch: 5| Step: 10
Training loss: 2.9254225140449632
Validation loss: 2.869535361283183

Epoch: 55| Step: 0
Training loss: 2.896195606285626
Validation loss: 2.905572754768047

Epoch: 5| Step: 1
Training loss: 2.9769597626959854
Validation loss: 2.868023657266114

Epoch: 5| Step: 2
Training loss: 2.361063674998767
Validation loss: 2.8806814507459437

Epoch: 5| Step: 3
Training loss: 2.4383944313110884
Validation loss: 2.907363852811645

Epoch: 5| Step: 4
Training loss: 3.0516904680069397
Validation loss: 2.898248697569688

Epoch: 5| Step: 5
Training loss: 3.0217687452032633
Validation loss: 2.854390663630972

Epoch: 5| Step: 6
Training loss: 3.1828651390161133
Validation loss: 2.894670261441993

Epoch: 5| Step: 7
Training loss: 3.658094152975187
Validation loss: 2.873815751821825

Epoch: 5| Step: 8
Training loss: 3.0761002595830385
Validation loss: 2.8954233897617367

Epoch: 5| Step: 9
Training loss: 2.898998442708308
Validation loss: 2.8883992857433762

Epoch: 5| Step: 10
Training loss: 3.487373601338827
Validation loss: 2.900551655141561

Epoch: 56| Step: 0
Training loss: 3.7422258538369233
Validation loss: 2.8479337804734266

Epoch: 5| Step: 1
Training loss: 3.0062043882466765
Validation loss: 2.8932307388725085

Epoch: 5| Step: 2
Training loss: 3.076868410725253
Validation loss: 2.8798526117821566

Epoch: 5| Step: 3
Training loss: 2.7872166442544932
Validation loss: 2.8713593422143058

Epoch: 5| Step: 4
Training loss: 3.0312553484368085
Validation loss: 2.875966557428012

Epoch: 5| Step: 5
Training loss: 2.76253910641155
Validation loss: 2.8999274942445137

Epoch: 5| Step: 6
Training loss: 2.631240873706059
Validation loss: 2.8711696556403474

Epoch: 5| Step: 7
Training loss: 3.3347609006167485
Validation loss: 2.87537313307538

Epoch: 5| Step: 8
Training loss: 2.941928528395366
Validation loss: 2.8693093098707756

Epoch: 5| Step: 9
Training loss: 3.0456711175794275
Validation loss: 2.887731750347833

Epoch: 5| Step: 10
Training loss: 2.4479760237186587
Validation loss: 2.864202591249786

Epoch: 57| Step: 0
Training loss: 3.3225057381723193
Validation loss: 2.8707533303544364

Epoch: 5| Step: 1
Training loss: 2.720491837884528
Validation loss: 2.8594977132124315

Epoch: 5| Step: 2
Training loss: 2.454295468364132
Validation loss: 2.8657852887911583

Epoch: 5| Step: 3
Training loss: 2.5800017028625546
Validation loss: 2.862727533126114

Epoch: 5| Step: 4
Training loss: 4.003361481613398
Validation loss: 2.868858093688846

Epoch: 5| Step: 5
Training loss: 2.8144061940374954
Validation loss: 2.877726930445778

Epoch: 5| Step: 6
Training loss: 2.809598825129044
Validation loss: 2.8558589459460415

Epoch: 5| Step: 7
Training loss: 3.0464320716716418
Validation loss: 2.8575559644668376

Epoch: 5| Step: 8
Training loss: 3.397456586615136
Validation loss: 2.865884937045688

Epoch: 5| Step: 9
Training loss: 2.79226116473896
Validation loss: 2.889309829541567

Epoch: 5| Step: 10
Training loss: 2.704414721506463
Validation loss: 2.8526479199660955

Epoch: 58| Step: 0
Training loss: 3.1955624508271203
Validation loss: 2.862903494562636

Epoch: 5| Step: 1
Training loss: 2.6222336133971704
Validation loss: 2.8550958063443383

Epoch: 5| Step: 2
Training loss: 2.629752534457676
Validation loss: 2.8873391678983586

Epoch: 5| Step: 3
Training loss: 2.897816223846416
Validation loss: 2.856667928842458

Epoch: 5| Step: 4
Training loss: 3.2313904191280445
Validation loss: 2.879840004762617

Epoch: 5| Step: 5
Training loss: 2.296281283710085
Validation loss: 2.900298777137235

Epoch: 5| Step: 6
Training loss: 2.8969818325980783
Validation loss: 2.8877347962839317

Epoch: 5| Step: 7
Training loss: 2.957640410030257
Validation loss: 2.8523666913307997

Epoch: 5| Step: 8
Training loss: 3.390131338720436
Validation loss: 2.874813709581363

Epoch: 5| Step: 9
Training loss: 3.6065871796748135
Validation loss: 2.860101171996349

Epoch: 5| Step: 10
Training loss: 2.946419505315927
Validation loss: 2.8707930292917303

Epoch: 59| Step: 0
Training loss: 3.0060790776697166
Validation loss: 2.88214220743229

Epoch: 5| Step: 1
Training loss: 3.135681056707153
Validation loss: 2.8968297604903244

Epoch: 5| Step: 2
Training loss: 2.897196789495071
Validation loss: 2.878858423992719

Epoch: 5| Step: 3
Training loss: 2.742679649596146
Validation loss: 2.882890807555918

Epoch: 5| Step: 4
Training loss: 2.945936384831091
Validation loss: 2.8696269457486667

Epoch: 5| Step: 5
Training loss: 2.959494045163283
Validation loss: 2.8654202942108147

Epoch: 5| Step: 6
Training loss: 3.143394349990275
Validation loss: 2.852599533291692

Epoch: 5| Step: 7
Training loss: 2.6873578765904176
Validation loss: 2.8787086645976836

Epoch: 5| Step: 8
Training loss: 2.496124601695829
Validation loss: 2.885169963182587

Epoch: 5| Step: 9
Training loss: 3.604416913879761
Validation loss: 2.8874247201951664

Epoch: 5| Step: 10
Training loss: 3.1645612912208785
Validation loss: 2.888609397455651

Epoch: 60| Step: 0
Training loss: 2.575977702772892
Validation loss: 2.8535527760064747

Epoch: 5| Step: 1
Training loss: 2.65578770822053
Validation loss: 2.868165599880922

Epoch: 5| Step: 2
Training loss: 3.239664810644328
Validation loss: 2.8764839533588717

Epoch: 5| Step: 3
Training loss: 2.9282512755630985
Validation loss: 2.8578597187609676

Epoch: 5| Step: 4
Training loss: 3.2203011339959686
Validation loss: 2.8646232952712647

Epoch: 5| Step: 5
Training loss: 3.0714154385764365
Validation loss: 2.8833402260745307

Epoch: 5| Step: 6
Training loss: 2.6146441043513806
Validation loss: 2.8704729574448984

Epoch: 5| Step: 7
Training loss: 3.0247957397100014
Validation loss: 2.8456528427687564

Epoch: 5| Step: 8
Training loss: 2.792754563875356
Validation loss: 2.8503659922769224

Epoch: 5| Step: 9
Training loss: 3.3078939695420875
Validation loss: 2.8803869884553968

Epoch: 5| Step: 10
Training loss: 3.0084842872963753
Validation loss: 2.866424105737606

Epoch: 61| Step: 0
Training loss: 3.0871422069975307
Validation loss: 2.858392494766375

Epoch: 5| Step: 1
Training loss: 3.0465654264806377
Validation loss: 2.845700388121396

Epoch: 5| Step: 2
Training loss: 2.8058747990165824
Validation loss: 2.8603453406030552

Epoch: 5| Step: 3
Training loss: 3.196931834382229
Validation loss: 2.872306646447106

Epoch: 5| Step: 4
Training loss: 2.544536054850871
Validation loss: 2.848059627649505

Epoch: 5| Step: 5
Training loss: 2.5756156037383016
Validation loss: 2.867643752948637

Epoch: 5| Step: 6
Training loss: 2.657637469377668
Validation loss: 2.872761072609727

Epoch: 5| Step: 7
Training loss: 2.7856291681078327
Validation loss: 2.865792889033243

Epoch: 5| Step: 8
Training loss: 3.8775441831411688
Validation loss: 2.848014975159419

Epoch: 5| Step: 9
Training loss: 2.7595688195595436
Validation loss: 2.857616508519618

Epoch: 5| Step: 10
Training loss: 3.248855829573695
Validation loss: 2.8667789943987385

Epoch: 62| Step: 0
Training loss: 3.3058465318453996
Validation loss: 2.8423977638504665

Epoch: 5| Step: 1
Training loss: 2.350059256922549
Validation loss: 2.8527869984391883

Epoch: 5| Step: 2
Training loss: 2.6302787746149536
Validation loss: 2.8478222159194946

Epoch: 5| Step: 3
Training loss: 3.283111189735657
Validation loss: 2.876949562397079

Epoch: 5| Step: 4
Training loss: 2.4732013601719824
Validation loss: 2.868991221753189

Epoch: 5| Step: 5
Training loss: 3.1716167175668333
Validation loss: 2.863348669107775

Epoch: 5| Step: 6
Training loss: 3.5705223105320774
Validation loss: 2.8850996462943233

Epoch: 5| Step: 7
Training loss: 3.05464051349533
Validation loss: 2.8599001664827592

Epoch: 5| Step: 8
Training loss: 2.3827332530367205
Validation loss: 2.8644464532063107

Epoch: 5| Step: 9
Training loss: 3.2128539665936793
Validation loss: 2.855647537736854

Epoch: 5| Step: 10
Training loss: 3.1141316438263438
Validation loss: 2.839066684228659

Epoch: 63| Step: 0
Training loss: 2.4672865574128964
Validation loss: 2.8646475925490917

Epoch: 5| Step: 1
Training loss: 2.9056328559189986
Validation loss: 2.841396111686994

Epoch: 5| Step: 2
Training loss: 3.0694226244519602
Validation loss: 2.8275156596931095

Epoch: 5| Step: 3
Training loss: 2.3448136014405256
Validation loss: 2.846558458892634

Epoch: 5| Step: 4
Training loss: 3.9911833394185914
Validation loss: 2.8211250896864923

Epoch: 5| Step: 5
Training loss: 2.8026920116027476
Validation loss: 2.866618102101816

Epoch: 5| Step: 6
Training loss: 2.168930142970928
Validation loss: 2.836965865944882

Epoch: 5| Step: 7
Training loss: 2.7459904310777925
Validation loss: 2.854131269194288

Epoch: 5| Step: 8
Training loss: 3.3361521881846894
Validation loss: 2.8676361093364817

Epoch: 5| Step: 9
Training loss: 2.78755578981687
Validation loss: 2.843368804022362

Epoch: 5| Step: 10
Training loss: 3.5516477226373864
Validation loss: 2.837109259843929

Epoch: 64| Step: 0
Training loss: 3.056767762681402
Validation loss: 2.8447090739428385

Epoch: 5| Step: 1
Training loss: 2.955687526235915
Validation loss: 2.8305276253196925

Epoch: 5| Step: 2
Training loss: 3.0433026621492685
Validation loss: 2.866574677734459

Epoch: 5| Step: 3
Training loss: 2.783258377329853
Validation loss: 2.819364148594579

Epoch: 5| Step: 4
Training loss: 3.220536560230113
Validation loss: 2.826856484699904

Epoch: 5| Step: 5
Training loss: 3.2783751473202978
Validation loss: 2.8344645084946114

Epoch: 5| Step: 6
Training loss: 3.0380101281826613
Validation loss: 2.8352471866329445

Epoch: 5| Step: 7
Training loss: 2.5502654367560638
Validation loss: 2.821907038787219

Epoch: 5| Step: 8
Training loss: 3.2826598998474403
Validation loss: 2.838387199926257

Epoch: 5| Step: 9
Training loss: 2.668417494918113
Validation loss: 2.8071812698495617

Epoch: 5| Step: 10
Training loss: 2.6580848191034265
Validation loss: 2.837649129982086

Epoch: 65| Step: 0
Training loss: 3.0466826549363715
Validation loss: 2.816587389870174

Epoch: 5| Step: 1
Training loss: 2.029547696955538
Validation loss: 2.8610533902180397

Epoch: 5| Step: 2
Training loss: 3.538348464849613
Validation loss: 2.8307845802331166

Epoch: 5| Step: 3
Training loss: 2.8149812561549434
Validation loss: 2.8384963743297984

Epoch: 5| Step: 4
Training loss: 3.1016724228297354
Validation loss: 2.8319561791574457

Epoch: 5| Step: 5
Training loss: 3.503698030236761
Validation loss: 2.806643149690716

Epoch: 5| Step: 6
Training loss: 2.191190494789156
Validation loss: 2.856413748382437

Epoch: 5| Step: 7
Training loss: 2.920241608226114
Validation loss: 2.8386251722736255

Epoch: 5| Step: 8
Training loss: 2.4969416030575466
Validation loss: 2.883565158001955

Epoch: 5| Step: 9
Training loss: 3.517482826174718
Validation loss: 2.8300625388146403

Epoch: 5| Step: 10
Training loss: 2.6146441043513806
Validation loss: 2.874190379243295

Epoch: 66| Step: 0
Training loss: 3.0547962998626907
Validation loss: 2.816556821752665

Epoch: 5| Step: 1
Training loss: 3.051653279459695
Validation loss: 2.816089593608608

Epoch: 5| Step: 2
Training loss: 3.928390986769785
Validation loss: 2.8202204549080965

Epoch: 5| Step: 3
Training loss: 2.5128804274686702
Validation loss: 2.854534979303854

Epoch: 5| Step: 4
Training loss: 2.5051671035979743
Validation loss: 2.8421525476718426

Epoch: 5| Step: 5
Training loss: 2.4483376215444275
Validation loss: 2.8325655597872186

Epoch: 5| Step: 6
Training loss: 3.6526441481160075
Validation loss: 2.827319897030922

Epoch: 5| Step: 7
Training loss: 2.4449530876667374
Validation loss: 2.8623186704487806

Epoch: 5| Step: 8
Training loss: 3.0349157132506406
Validation loss: 2.859706124971368

Epoch: 5| Step: 9
Training loss: 2.5051211357142096
Validation loss: 2.829145678933593

Epoch: 5| Step: 10
Training loss: 2.8399219948170247
Validation loss: 2.8630638694206367

Epoch: 67| Step: 0
Training loss: 2.2419686559549996
Validation loss: 2.8321727851122733

Epoch: 5| Step: 1
Training loss: 2.754027711611127
Validation loss: 2.8445001401829995

Epoch: 5| Step: 2
Training loss: 3.3054563381004414
Validation loss: 2.8538021734853567

Epoch: 5| Step: 3
Training loss: 2.703749832527201
Validation loss: 2.8382150251913716

Epoch: 5| Step: 4
Training loss: 3.7271985165044677
Validation loss: 2.824824868205067

Epoch: 5| Step: 5
Training loss: 2.7527225195860963
Validation loss: 2.859511677612141

Epoch: 5| Step: 6
Training loss: 3.110113775005899
Validation loss: 2.835128862797024

Epoch: 5| Step: 7
Training loss: 2.6744108603030745
Validation loss: 2.8536345690452896

Epoch: 5| Step: 8
Training loss: 3.176397998038558
Validation loss: 2.8331706804449457

Epoch: 5| Step: 9
Training loss: 2.643431577151615
Validation loss: 2.841971610192818

Epoch: 5| Step: 10
Training loss: 3.0276715107350243
Validation loss: 2.823631914055762

Epoch: 68| Step: 0
Training loss: 3.182983639535136
Validation loss: 2.8625917613343668

Epoch: 5| Step: 1
Training loss: 2.954819289102127
Validation loss: 2.8127798317234665

Epoch: 5| Step: 2
Training loss: 3.266675278269517
Validation loss: 2.8379605921822053

Epoch: 5| Step: 3
Training loss: 3.0015142116207003
Validation loss: 2.8386696870821932

Epoch: 5| Step: 4
Training loss: 2.8005891997439853
Validation loss: 2.8471019759165648

Epoch: 5| Step: 5
Training loss: 2.83117241826825
Validation loss: 2.8629255588277998

Epoch: 5| Step: 6
Training loss: 3.026938606962861
Validation loss: 2.825217997018366

Epoch: 5| Step: 7
Training loss: 2.4835902480118435
Validation loss: 2.8351635999183635

Epoch: 5| Step: 8
Training loss: 3.0750732785309296
Validation loss: 2.8310248995193086

Epoch: 5| Step: 9
Training loss: 2.5480996212550417
Validation loss: 2.8337931872078745

Epoch: 5| Step: 10
Training loss: 3.0853947802035044
Validation loss: 2.859382710524062

Epoch: 69| Step: 0
Training loss: 2.8440596862517498
Validation loss: 2.8040038291397456

Epoch: 5| Step: 1
Training loss: 2.7049156828764453
Validation loss: 2.829885810868235

Epoch: 5| Step: 2
Training loss: 3.0356394654357963
Validation loss: 2.827393646575659

Epoch: 5| Step: 3
Training loss: 2.8972603188782813
Validation loss: 2.811785571876622

Epoch: 5| Step: 4
Training loss: 3.975583178847913
Validation loss: 2.803822221018797

Epoch: 5| Step: 5
Training loss: 3.092467687710921
Validation loss: 2.832577435049258

Epoch: 5| Step: 6
Training loss: 3.283354601976731
Validation loss: 2.806647450976579

Epoch: 5| Step: 7
Training loss: 2.2537026139798306
Validation loss: 2.7939515336182446

Epoch: 5| Step: 8
Training loss: 3.2283599502130564
Validation loss: 2.8283961860710205

Epoch: 5| Step: 9
Training loss: 2.2511452832985555
Validation loss: 2.815213783510409

Epoch: 5| Step: 10
Training loss: 2.448917352119047
Validation loss: 2.8025085465715276

Epoch: 70| Step: 0
Training loss: 2.798105150484253
Validation loss: 2.819988895844726

Epoch: 5| Step: 1
Training loss: 2.533394929070117
Validation loss: 2.8263925855008956

Epoch: 5| Step: 2
Training loss: 2.849650706252267
Validation loss: 2.8061446144078936

Epoch: 5| Step: 3
Training loss: 3.053232612392311
Validation loss: 2.8252071279998927

Epoch: 5| Step: 4
Training loss: 3.393587988820418
Validation loss: 2.8072820517897203

Epoch: 5| Step: 5
Training loss: 3.570962057979789
Validation loss: 2.808174584542507

Epoch: 5| Step: 6
Training loss: 2.828943123691694
Validation loss: 2.795743359399168

Epoch: 5| Step: 7
Training loss: 3.4332221028602796
Validation loss: 2.7937913877134912

Epoch: 5| Step: 8
Training loss: 2.6391162060546063
Validation loss: 2.835405207175143

Epoch: 5| Step: 9
Training loss: 2.688486849553512
Validation loss: 2.800535829516622

Epoch: 5| Step: 10
Training loss: 2.5268571199420933
Validation loss: 2.822875665373648

Epoch: 71| Step: 0
Training loss: 3.0557639330315594
Validation loss: 2.8262677092425794

Epoch: 5| Step: 1
Training loss: 2.5926492032677375
Validation loss: 2.828476881155767

Epoch: 5| Step: 2
Training loss: 2.6744840498709124
Validation loss: 2.7883547399075375

Epoch: 5| Step: 3
Training loss: 3.0391599350242724
Validation loss: 2.805025108095905

Epoch: 5| Step: 4
Training loss: 3.4538525121374457
Validation loss: 2.805083813641187

Epoch: 5| Step: 5
Training loss: 2.5762549814234386
Validation loss: 2.809040998839647

Epoch: 5| Step: 6
Training loss: 3.5655330662823657
Validation loss: 2.8077925140295723

Epoch: 5| Step: 7
Training loss: 2.3436118530249757
Validation loss: 2.8502568416868823

Epoch: 5| Step: 8
Training loss: 2.760283057860059
Validation loss: 2.813074862159921

Epoch: 5| Step: 9
Training loss: 3.185187155166858
Validation loss: 2.7909883407551646

Epoch: 5| Step: 10
Training loss: 2.786676834428602
Validation loss: 2.80192755114285

Epoch: 72| Step: 0
Training loss: 2.6169656687996548
Validation loss: 2.779729877768589

Epoch: 5| Step: 1
Training loss: 2.8769602519747943
Validation loss: 2.813818558917281

Epoch: 5| Step: 2
Training loss: 3.013303347272409
Validation loss: 2.825807990951089

Epoch: 5| Step: 3
Training loss: 3.0299989930708318
Validation loss: 2.7983507241364136

Epoch: 5| Step: 4
Training loss: 2.5111514291743022
Validation loss: 2.8309409237079124

Epoch: 5| Step: 5
Training loss: 3.0607400625052446
Validation loss: 2.8246836024926436

Epoch: 5| Step: 6
Training loss: 2.4350744062957865
Validation loss: 2.799785401101585

Epoch: 5| Step: 7
Training loss: 3.0021677132863065
Validation loss: 2.8060284894544303

Epoch: 5| Step: 8
Training loss: 3.8624333298740794
Validation loss: 2.7890070106026053

Epoch: 5| Step: 9
Training loss: 2.5991429713731464
Validation loss: 2.8332345325198633

Epoch: 5| Step: 10
Training loss: 2.616213398042656
Validation loss: 2.811360541060325

Epoch: 73| Step: 0
Training loss: 3.194683581997897
Validation loss: 2.8137258130298237

Epoch: 5| Step: 1
Training loss: 3.3194205488535746
Validation loss: 2.7935779428347804

Epoch: 5| Step: 2
Training loss: 2.3671760181110773
Validation loss: 2.811291387326439

Epoch: 5| Step: 3
Training loss: 2.7118345859573068
Validation loss: 2.82488814842256

Epoch: 5| Step: 4
Training loss: 3.288937237816629
Validation loss: 2.8072578041085565

Epoch: 5| Step: 5
Training loss: 2.563293520250748
Validation loss: 2.81327797396921

Epoch: 5| Step: 6
Training loss: 3.24529777159859
Validation loss: 2.8505637885144077

Epoch: 5| Step: 7
Training loss: 3.106058009640665
Validation loss: 2.814126956756737

Epoch: 5| Step: 8
Training loss: 2.6725711027273533
Validation loss: 2.8205202714860493

Epoch: 5| Step: 9
Training loss: 2.522670853786072
Validation loss: 2.8097317771359926

Epoch: 5| Step: 10
Training loss: 2.8256218723683975
Validation loss: 2.7998643780749504

Epoch: 74| Step: 0
Training loss: 3.255007334289257
Validation loss: 2.80872537408118

Epoch: 5| Step: 1
Training loss: 3.1995807671109215
Validation loss: 2.811148561494115

Epoch: 5| Step: 2
Training loss: 3.6062596735832804
Validation loss: 2.8290992073690027

Epoch: 5| Step: 3
Training loss: 2.8124235354731515
Validation loss: 2.827397334183742

Epoch: 5| Step: 4
Training loss: 2.9178607312984317
Validation loss: 2.8059828857969307

Epoch: 5| Step: 5
Training loss: 2.172980157711548
Validation loss: 2.8365161205690677

Epoch: 5| Step: 6
Training loss: 3.062291975157379
Validation loss: 2.815244978152738

Epoch: 5| Step: 7
Training loss: 2.8936642726780923
Validation loss: 2.817962577391373

Epoch: 5| Step: 8
Training loss: 3.1583281370202414
Validation loss: 2.7989348608671705

Epoch: 5| Step: 9
Training loss: 2.7284717597247954
Validation loss: 2.8026387367597114

Epoch: 5| Step: 10
Training loss: 1.907993394928222
Validation loss: 2.790454903331099

Epoch: 75| Step: 0
Training loss: 2.644741123272911
Validation loss: 2.789634852907111

Epoch: 5| Step: 1
Training loss: 2.771244439242939
Validation loss: 2.779555020520948

Epoch: 5| Step: 2
Training loss: 3.3914733387977383
Validation loss: 2.791913464405469

Epoch: 5| Step: 3
Training loss: 3.000937951010555
Validation loss: 2.809222633701154

Epoch: 5| Step: 4
Training loss: 2.843369846295889
Validation loss: 2.7875570847165774

Epoch: 5| Step: 5
Training loss: 3.5496495355966515
Validation loss: 2.792663093958694

Epoch: 5| Step: 6
Training loss: 3.0134492447032906
Validation loss: 2.80537879557864

Epoch: 5| Step: 7
Training loss: 3.2258749314699613
Validation loss: 2.8054686785041953

Epoch: 5| Step: 8
Training loss: 2.5507450773002263
Validation loss: 2.80299060529676

Epoch: 5| Step: 9
Training loss: 2.117144369551746
Validation loss: 2.8019180923109777

Epoch: 5| Step: 10
Training loss: 2.352635034461826
Validation loss: 2.8107732797807357

Epoch: 76| Step: 0
Training loss: 3.2197012375312033
Validation loss: 2.806678556320572

Epoch: 5| Step: 1
Training loss: 2.9739499779543217
Validation loss: 2.8255795663205636

Epoch: 5| Step: 2
Training loss: 2.860881137761479
Validation loss: 2.797245003222966

Epoch: 5| Step: 3
Training loss: 2.9041678240284376
Validation loss: 2.813817618672726

Epoch: 5| Step: 4
Training loss: 3.027543781193907
Validation loss: 2.7758172743786647

Epoch: 5| Step: 5
Training loss: 2.496967192703578
Validation loss: 2.8073945151151007

Epoch: 5| Step: 6
Training loss: 2.610624916272097
Validation loss: 2.796191094948496

Epoch: 5| Step: 7
Training loss: 3.438681936807243
Validation loss: 2.814531059165596

Epoch: 5| Step: 8
Training loss: 2.418968573263212
Validation loss: 2.7983315907885977

Epoch: 5| Step: 9
Training loss: 2.922511883035197
Validation loss: 2.7841242453516672

Epoch: 5| Step: 10
Training loss: 2.756128677846678
Validation loss: 2.8164248591392185

Epoch: 77| Step: 0
Training loss: 2.8373912101426075
Validation loss: 2.7917444943443286

Epoch: 5| Step: 1
Training loss: 2.685794200259026
Validation loss: 2.8243387286132093

Epoch: 5| Step: 2
Training loss: 2.144784603196812
Validation loss: 2.7729006612684417

Epoch: 5| Step: 3
Training loss: 2.981526238461155
Validation loss: 2.8093238360973123

Epoch: 5| Step: 4
Training loss: 3.1003875428653416
Validation loss: 2.8054673096296687

Epoch: 5| Step: 5
Training loss: 3.487312891599843
Validation loss: 2.800273605608596

Epoch: 5| Step: 6
Training loss: 2.8338977214203043
Validation loss: 2.764924286148007

Epoch: 5| Step: 7
Training loss: 2.9784437427289228
Validation loss: 2.823494664070969

Epoch: 5| Step: 8
Training loss: 2.8398976484848233
Validation loss: 2.82944494752713

Epoch: 5| Step: 9
Training loss: 3.1188822563429137
Validation loss: 2.805645034764522

Epoch: 5| Step: 10
Training loss: 2.6397688341080316
Validation loss: 2.790817722751908

Epoch: 78| Step: 0
Training loss: 2.977552674770049
Validation loss: 2.826617229506867

Epoch: 5| Step: 1
Training loss: 3.106029148041184
Validation loss: 2.7746325429996106

Epoch: 5| Step: 2
Training loss: 3.458630208214705
Validation loss: 2.782230570738898

Epoch: 5| Step: 3
Training loss: 3.4388676090297636
Validation loss: 2.819452065375818

Epoch: 5| Step: 4
Training loss: 2.2039123643251437
Validation loss: 2.792288293320797

Epoch: 5| Step: 5
Training loss: 2.8423428250275076
Validation loss: 2.7849665190003714

Epoch: 5| Step: 6
Training loss: 2.7952865266739355
Validation loss: 2.834243668586114

Epoch: 5| Step: 7
Training loss: 2.536177278230958
Validation loss: 2.771041487274588

Epoch: 5| Step: 8
Training loss: 2.965459988247107
Validation loss: 2.8009140063963245

Epoch: 5| Step: 9
Training loss: 2.438458767643821
Validation loss: 2.802631113440361

Epoch: 5| Step: 10
Training loss: 2.8794796086745365
Validation loss: 2.7997465449645307

Epoch: 79| Step: 0
Training loss: 2.85683824754641
Validation loss: 2.800110490511622

Epoch: 5| Step: 1
Training loss: 3.4357725484613706
Validation loss: 2.7678429819599857

Epoch: 5| Step: 2
Training loss: 2.627472031405448
Validation loss: 2.7989928865398364

Epoch: 5| Step: 3
Training loss: 2.679556529233779
Validation loss: 2.7874538982693187

Epoch: 5| Step: 4
Training loss: 3.5485885446871497
Validation loss: 2.787309202542506

Epoch: 5| Step: 5
Training loss: 3.197329605012342
Validation loss: 2.7949523398995573

Epoch: 5| Step: 6
Training loss: 2.6585552310311087
Validation loss: 2.7612110517228636

Epoch: 5| Step: 7
Training loss: 2.8097366320905284
Validation loss: 2.79304836121581

Epoch: 5| Step: 8
Training loss: 2.807515623162977
Validation loss: 2.799395968361574

Epoch: 5| Step: 9
Training loss: 2.2870252481392113
Validation loss: 2.8206227417990926

Epoch: 5| Step: 10
Training loss: 2.8933205073668575
Validation loss: 2.7721644561255663

Epoch: 80| Step: 0
Training loss: 3.11497966239254
Validation loss: 2.808673037900045

Epoch: 5| Step: 1
Training loss: 2.9442952876028903
Validation loss: 2.766613454494797

Epoch: 5| Step: 2
Training loss: 3.584037460225044
Validation loss: 2.764899682759311

Epoch: 5| Step: 3
Training loss: 1.9931646605906133
Validation loss: 2.803339243568245

Epoch: 5| Step: 4
Training loss: 2.33383349325985
Validation loss: 2.7595493662218544

Epoch: 5| Step: 5
Training loss: 3.09355455802331
Validation loss: 2.764984341233467

Epoch: 5| Step: 6
Training loss: 3.026306525942943
Validation loss: 2.8082582232633038

Epoch: 5| Step: 7
Training loss: 3.0088129930990073
Validation loss: 2.804532568761594

Epoch: 5| Step: 8
Training loss: 3.5383977876297936
Validation loss: 2.818758638775856

Epoch: 5| Step: 9
Training loss: 2.3079652398663626
Validation loss: 2.8041744073056614

Epoch: 5| Step: 10
Training loss: 2.164828278600887
Validation loss: 2.7624258201527385

Epoch: 81| Step: 0
Training loss: 2.5714582770766183
Validation loss: 2.790175573410088

Epoch: 5| Step: 1
Training loss: 2.473276744445364
Validation loss: 2.798447911461456

Epoch: 5| Step: 2
Training loss: 2.3764352978856
Validation loss: 2.8269121752020294

Epoch: 5| Step: 3
Training loss: 2.803179152017738
Validation loss: 2.822296198503917

Epoch: 5| Step: 4
Training loss: 3.4615714911164774
Validation loss: 2.8081149291073944

Epoch: 5| Step: 5
Training loss: 3.346139642194557
Validation loss: 2.8269677385546768

Epoch: 5| Step: 6
Training loss: 3.4852679694987394
Validation loss: 2.773783229716508

Epoch: 5| Step: 7
Training loss: 2.2002613042491834
Validation loss: 2.8115698621962872

Epoch: 5| Step: 8
Training loss: 3.0410774043379436
Validation loss: 2.7710145707079317

Epoch: 5| Step: 9
Training loss: 2.8288018696977297
Validation loss: 2.784913140731909

Epoch: 5| Step: 10
Training loss: 2.802449302929404
Validation loss: 2.7674183853081527

Epoch: 82| Step: 0
Training loss: 3.1349168212174545
Validation loss: 2.775899099883194

Epoch: 5| Step: 1
Training loss: 2.7670359487621305
Validation loss: 2.785262733873137

Epoch: 5| Step: 2
Training loss: 2.6119300987272243
Validation loss: 2.811205064738377

Epoch: 5| Step: 3
Training loss: 3.136691082634051
Validation loss: 2.7889943045444667

Epoch: 5| Step: 4
Training loss: 2.575291967042793
Validation loss: 2.775897127211225

Epoch: 5| Step: 5
Training loss: 2.443834534570792
Validation loss: 2.7743363800945016

Epoch: 5| Step: 6
Training loss: 2.8626451813641185
Validation loss: 2.768457536059326

Epoch: 5| Step: 7
Training loss: 2.5517929430943784
Validation loss: 2.808285001953109

Epoch: 5| Step: 8
Training loss: 2.661488562086898
Validation loss: 2.8068785269338035

Epoch: 5| Step: 9
Training loss: 3.9114196748342747
Validation loss: 2.794404614919141

Epoch: 5| Step: 10
Training loss: 2.7108335447580054
Validation loss: 2.7609475920589

Epoch: 83| Step: 0
Training loss: 3.2087290796386276
Validation loss: 2.8076538172575476

Epoch: 5| Step: 1
Training loss: 2.9937650739891573
Validation loss: 2.7554104421463137

Epoch: 5| Step: 2
Training loss: 2.757466842991544
Validation loss: 2.779410847016535

Epoch: 5| Step: 3
Training loss: 3.0413582179472853
Validation loss: 2.785355595473794

Epoch: 5| Step: 4
Training loss: 2.4350083160258387
Validation loss: 2.7690677616867037

Epoch: 5| Step: 5
Training loss: 3.0684768586276796
Validation loss: 2.768164788797005

Epoch: 5| Step: 6
Training loss: 1.9439812206844749
Validation loss: 2.7722484183518614

Epoch: 5| Step: 7
Training loss: 3.32864046358501
Validation loss: 2.776920107509147

Epoch: 5| Step: 8
Training loss: 2.7950332800670066
Validation loss: 2.787374549425528

Epoch: 5| Step: 9
Training loss: 2.9246031728367687
Validation loss: 2.7552979393065242

Epoch: 5| Step: 10
Training loss: 2.9007227030012763
Validation loss: 2.7748941485758927

Epoch: 84| Step: 0
Training loss: 2.647552252263739
Validation loss: 2.7926079565573834

Epoch: 5| Step: 1
Training loss: 2.9439603499562046
Validation loss: 2.7809250777651373

Epoch: 5| Step: 2
Training loss: 2.5527440883040144
Validation loss: 2.805711267612729

Epoch: 5| Step: 3
Training loss: 2.5563118812886905
Validation loss: 2.8381065598893636

Epoch: 5| Step: 4
Training loss: 2.6597666181993023
Validation loss: 2.79140279573082

Epoch: 5| Step: 5
Training loss: 3.5785680771402197
Validation loss: 2.7694088076430687

Epoch: 5| Step: 6
Training loss: 1.7514217595803818
Validation loss: 2.7582120431954924

Epoch: 5| Step: 7
Training loss: 3.0190080236256924
Validation loss: 2.7676061717305154

Epoch: 5| Step: 8
Training loss: 3.0926810835891305
Validation loss: 2.797891781800683

Epoch: 5| Step: 9
Training loss: 2.88843614339874
Validation loss: 2.791540656982676

Epoch: 5| Step: 10
Training loss: 3.5543489064358385
Validation loss: 2.7870760984512692

Epoch: 85| Step: 0
Training loss: 2.914087863024259
Validation loss: 2.7853257743617696

Epoch: 5| Step: 1
Training loss: 2.507646977081068
Validation loss: 2.765549464208397

Epoch: 5| Step: 2
Training loss: 3.5606366019104305
Validation loss: 2.7761031816628434

Epoch: 5| Step: 3
Training loss: 1.9354059531822467
Validation loss: 2.760946995009861

Epoch: 5| Step: 4
Training loss: 3.1888894437404716
Validation loss: 2.773844942364582

Epoch: 5| Step: 5
Training loss: 2.414202936031935
Validation loss: 2.794351410517053

Epoch: 5| Step: 6
Training loss: 3.30178048623352
Validation loss: 2.7706425366960117

Epoch: 5| Step: 7
Training loss: 2.2814962175828226
Validation loss: 2.7752391647454475

Epoch: 5| Step: 8
Training loss: 2.897252748092255
Validation loss: 2.7670571014528487

Epoch: 5| Step: 9
Training loss: 2.2135384832621106
Validation loss: 2.8228600966353055

Epoch: 5| Step: 10
Training loss: 3.815746113622536
Validation loss: 2.7875554164294845

Epoch: 86| Step: 0
Training loss: 3.45403723081172
Validation loss: 2.7344059393050886

Epoch: 5| Step: 1
Training loss: 2.5539480649944637
Validation loss: 2.7912399677284254

Epoch: 5| Step: 2
Training loss: 1.9100414155793888
Validation loss: 2.783947885920045

Epoch: 5| Step: 3
Training loss: 2.739319434467308
Validation loss: 2.761222312844625

Epoch: 5| Step: 4
Training loss: 3.047093153748679
Validation loss: 2.7881353895258694

Epoch: 5| Step: 5
Training loss: 3.1377632425828286
Validation loss: 2.7502989657744683

Epoch: 5| Step: 6
Training loss: 2.8747329587894916
Validation loss: 2.7836440335596873

Epoch: 5| Step: 7
Training loss: 2.5124853219130197
Validation loss: 2.765031247843874

Epoch: 5| Step: 8
Training loss: 2.719672211081692
Validation loss: 2.7955254535440246

Epoch: 5| Step: 9
Training loss: 3.479609767694793
Validation loss: 2.7905048218765134

Epoch: 5| Step: 10
Training loss: 2.6881581764683915
Validation loss: 2.749576678653165

Epoch: 87| Step: 0
Training loss: 3.4248149905391077
Validation loss: 2.774081498185938

Epoch: 5| Step: 1
Training loss: 2.3542158296115927
Validation loss: 2.7646609271884737

Epoch: 5| Step: 2
Training loss: 2.863432793035222
Validation loss: 2.745036814717509

Epoch: 5| Step: 3
Training loss: 3.055346327660058
Validation loss: 2.758279813750325

Epoch: 5| Step: 4
Training loss: 2.6109397901870848
Validation loss: 2.7742996176911783

Epoch: 5| Step: 5
Training loss: 3.378099219464676
Validation loss: 2.7758997629814157

Epoch: 5| Step: 6
Training loss: 2.553791600662007
Validation loss: 2.811504881631535

Epoch: 5| Step: 7
Training loss: 3.3419173022208093
Validation loss: 2.7627535091429465

Epoch: 5| Step: 8
Training loss: 2.1094650814460256
Validation loss: 2.7989116583215643

Epoch: 5| Step: 9
Training loss: 2.8936398841553874
Validation loss: 2.8169197293828496

Epoch: 5| Step: 10
Training loss: 2.8160080118932322
Validation loss: 2.78888603827157

Epoch: 88| Step: 0
Training loss: 2.5552484205677946
Validation loss: 2.750435992234307

Epoch: 5| Step: 1
Training loss: 2.171673003758601
Validation loss: 2.7841307674188425

Epoch: 5| Step: 2
Training loss: 2.581892647536318
Validation loss: 2.753556013559779

Epoch: 5| Step: 3
Training loss: 2.6009429102186763
Validation loss: 2.748598420252151

Epoch: 5| Step: 4
Training loss: 3.143709101325586
Validation loss: 2.751841212128872

Epoch: 5| Step: 5
Training loss: 3.449812737510423
Validation loss: 2.7575378216107334

Epoch: 5| Step: 6
Training loss: 2.775356950226741
Validation loss: 2.78506978747925

Epoch: 5| Step: 7
Training loss: 2.9231461804405403
Validation loss: 2.7890184646650154

Epoch: 5| Step: 8
Training loss: 3.0318223865090452
Validation loss: 2.7521267774592286

Epoch: 5| Step: 9
Training loss: 3.3323267529520484
Validation loss: 2.7983628801801195

Epoch: 5| Step: 10
Training loss: 3.1028926889179442
Validation loss: 2.776299056028612

Epoch: 89| Step: 0
Training loss: 2.8873751130282606
Validation loss: 2.7610100465751093

Epoch: 5| Step: 1
Training loss: 3.488369555065799
Validation loss: 2.8219168076349024

Epoch: 5| Step: 2
Training loss: 2.6030550504264287
Validation loss: 2.782517361369468

Epoch: 5| Step: 3
Training loss: 3.1898343383440935
Validation loss: 2.737027535147209

Epoch: 5| Step: 4
Training loss: 3.082989097830829
Validation loss: 2.787072869840523

Epoch: 5| Step: 5
Training loss: 2.2104303971372588
Validation loss: 2.7590419433340556

Epoch: 5| Step: 6
Training loss: 3.1842983846834696
Validation loss: 2.76969686667574

Epoch: 5| Step: 7
Training loss: 2.7912665882292473
Validation loss: 2.7477958325418963

Epoch: 5| Step: 8
Training loss: 2.7919371080119255
Validation loss: 2.7603091215303377

Epoch: 5| Step: 9
Training loss: 2.8743189129351734
Validation loss: 2.7831197170963877

Epoch: 5| Step: 10
Training loss: 2.1103774337912684
Validation loss: 2.739241295885124

Epoch: 90| Step: 0
Training loss: 2.4349907895644436
Validation loss: 2.760762557317135

Epoch: 5| Step: 1
Training loss: 2.199327483123248
Validation loss: 2.7425208667248415

Epoch: 5| Step: 2
Training loss: 2.7084493954561126
Validation loss: 2.7569276085538554

Epoch: 5| Step: 3
Training loss: 2.740665198001949
Validation loss: 2.742993799790578

Epoch: 5| Step: 4
Training loss: 3.067610699708857
Validation loss: 2.7961401295639634

Epoch: 5| Step: 5
Training loss: 2.8715685393456427
Validation loss: 2.7565135074685556

Epoch: 5| Step: 6
Training loss: 2.685125233235493
Validation loss: 2.775733307427471

Epoch: 5| Step: 7
Training loss: 3.314830032525235
Validation loss: 2.780985691646249

Epoch: 5| Step: 8
Training loss: 3.306060577908367
Validation loss: 2.773751308141378

Epoch: 5| Step: 9
Training loss: 2.7010188193825475
Validation loss: 2.782856514919762

Epoch: 5| Step: 10
Training loss: 3.533524987283151
Validation loss: 2.75093133599095

Epoch: 91| Step: 0
Training loss: 2.899385939731834
Validation loss: 2.773362244008614

Epoch: 5| Step: 1
Training loss: 3.063571975871103
Validation loss: 2.7902117338539045

Epoch: 5| Step: 2
Training loss: 2.9619815163457432
Validation loss: 2.7441980156173917

Epoch: 5| Step: 3
Training loss: 2.921375089096545
Validation loss: 2.7454073116021642

Epoch: 5| Step: 4
Training loss: 2.5870983825662024
Validation loss: 2.781863905397696

Epoch: 5| Step: 5
Training loss: 2.590668743946828
Validation loss: 2.74293024903519

Epoch: 5| Step: 6
Training loss: 2.7787369936880193
Validation loss: 2.757105977158246

Epoch: 5| Step: 7
Training loss: 3.1748913483539147
Validation loss: 2.8014839563025453

Epoch: 5| Step: 8
Training loss: 2.6432791468713464
Validation loss: 2.7884426359365726

Epoch: 5| Step: 9
Training loss: 2.75884998895666
Validation loss: 2.7571202648933792

Epoch: 5| Step: 10
Training loss: 2.828389192328172
Validation loss: 2.780747882996907

Epoch: 92| Step: 0
Training loss: 2.9466722825228424
Validation loss: 2.743630930723668

Epoch: 5| Step: 1
Training loss: 3.2696791311202693
Validation loss: 2.7345058483687446

Epoch: 5| Step: 2
Training loss: 2.9681143632329903
Validation loss: 2.7911442846601275

Epoch: 5| Step: 3
Training loss: 2.7993097203745596
Validation loss: 2.7502845400676565

Epoch: 5| Step: 4
Training loss: 2.8197939916534667
Validation loss: 2.73372657037113

Epoch: 5| Step: 5
Training loss: 3.2222451797485996
Validation loss: 2.7423633086345056

Epoch: 5| Step: 6
Training loss: 2.4308897521339854
Validation loss: 2.7327859816218534

Epoch: 5| Step: 7
Training loss: 2.755997619838268
Validation loss: 2.760515379267752

Epoch: 5| Step: 8
Training loss: 2.3856370538132694
Validation loss: 2.772333339747469

Epoch: 5| Step: 9
Training loss: 3.0341757586171054
Validation loss: 2.7527048581485087

Epoch: 5| Step: 10
Training loss: 2.7890634403173746
Validation loss: 2.7540948423148834

Epoch: 93| Step: 0
Training loss: 2.5962505007409544
Validation loss: 2.798342360813642

Epoch: 5| Step: 1
Training loss: 2.8127965982659595
Validation loss: 2.764920476276365

Epoch: 5| Step: 2
Training loss: 2.1133020086203183
Validation loss: 2.7584272673931456

Epoch: 5| Step: 3
Training loss: 2.809228392988179
Validation loss: 2.7868717006979002

Epoch: 5| Step: 4
Training loss: 3.7876358964668317
Validation loss: 2.7334869620965905

Epoch: 5| Step: 5
Training loss: 3.1568092379520394
Validation loss: 2.756365787288756

Epoch: 5| Step: 6
Training loss: 3.4234597355561407
Validation loss: 2.7112996809038914

Epoch: 5| Step: 7
Training loss: 1.7374743699852355
Validation loss: 2.7556854572478358

Epoch: 5| Step: 8
Training loss: 2.6870933047564236
Validation loss: 2.7543626460474964

Epoch: 5| Step: 9
Training loss: 3.2290781480695587
Validation loss: 2.7622159434420297

Epoch: 5| Step: 10
Training loss: 2.505375328499028
Validation loss: 2.773501862087197

Epoch: 94| Step: 0
Training loss: 3.0055236827251712
Validation loss: 2.7741620108969327

Epoch: 5| Step: 1
Training loss: 2.415552266001789
Validation loss: 2.7558257825053842

Epoch: 5| Step: 2
Training loss: 3.3364213150421045
Validation loss: 2.7433955703071273

Epoch: 5| Step: 3
Training loss: 3.151532717608023
Validation loss: 2.756217100227836

Epoch: 5| Step: 4
Training loss: 2.52228739603379
Validation loss: 2.7513922190442393

Epoch: 5| Step: 5
Training loss: 2.5996203805646076
Validation loss: 2.7489312370690864

Epoch: 5| Step: 6
Training loss: 2.614938071048238
Validation loss: 2.752071834437501

Epoch: 5| Step: 7
Training loss: 2.41529404913367
Validation loss: 2.7550354718868832

Epoch: 5| Step: 8
Training loss: 2.838614217315141
Validation loss: 2.754121026913595

Epoch: 5| Step: 9
Training loss: 3.6660057396976473
Validation loss: 2.757546814900709

Epoch: 5| Step: 10
Training loss: 2.3463043535020547
Validation loss: 2.7940546443417764

Epoch: 95| Step: 0
Training loss: 2.260771188900104
Validation loss: 2.746057914168999

Epoch: 5| Step: 1
Training loss: 2.832838314420612
Validation loss: 2.791696458001583

Epoch: 5| Step: 2
Training loss: 3.4736092014062603
Validation loss: 2.747762132137319

Epoch: 5| Step: 3
Training loss: 2.5171516477469384
Validation loss: 2.778449587713495

Epoch: 5| Step: 4
Training loss: 3.6746646754070733
Validation loss: 2.7680586539128664

Epoch: 5| Step: 5
Training loss: 2.3131418110757873
Validation loss: 2.7596991152976225

Epoch: 5| Step: 6
Training loss: 3.6446704572154696
Validation loss: 2.7794337880678044

Epoch: 5| Step: 7
Training loss: 2.5402851623498273
Validation loss: 2.7250522321391775

Epoch: 5| Step: 8
Training loss: 2.3576194851026417
Validation loss: 2.800476549176844

Epoch: 5| Step: 9
Training loss: 2.568887147235537
Validation loss: 2.7167554372278913

Epoch: 5| Step: 10
Training loss: 2.563929275501364
Validation loss: 2.7199356036175755

Epoch: 96| Step: 0
Training loss: 3.20093696109343
Validation loss: 2.7428420815598176

Epoch: 5| Step: 1
Training loss: 2.2639451738263348
Validation loss: 2.7191695814936145

Epoch: 5| Step: 2
Training loss: 2.95793591547652
Validation loss: 2.7678756366957016

Epoch: 5| Step: 3
Training loss: 3.0156520387692454
Validation loss: 2.740964959350307

Epoch: 5| Step: 4
Training loss: 2.642768486480101
Validation loss: 2.7436760131419278

Epoch: 5| Step: 5
Training loss: 3.0740417662186283
Validation loss: 2.740441426135049

Epoch: 5| Step: 6
Training loss: 2.742065253073277
Validation loss: 2.7690943231519354

Epoch: 5| Step: 7
Training loss: 3.0798009966679905
Validation loss: 2.7161339042718673

Epoch: 5| Step: 8
Training loss: 3.093665844321788
Validation loss: 2.757339492285703

Epoch: 5| Step: 9
Training loss: 2.88623009702512
Validation loss: 2.751194672978276

Epoch: 5| Step: 10
Training loss: 2.174421066756717
Validation loss: 2.776039817227799

Epoch: 97| Step: 0
Training loss: 2.5270439335665085
Validation loss: 2.7199475493085035

Epoch: 5| Step: 1
Training loss: 2.6090363608268663
Validation loss: 2.780650893887039

Epoch: 5| Step: 2
Training loss: 1.7760606095393603
Validation loss: 2.7482544196251193

Epoch: 5| Step: 3
Training loss: 3.5167448845672444
Validation loss: 2.755451666109841

Epoch: 5| Step: 4
Training loss: 2.626702891630894
Validation loss: 2.751586685651561

Epoch: 5| Step: 5
Training loss: 3.040573881842838
Validation loss: 2.768758290266685

Epoch: 5| Step: 6
Training loss: 3.2028871029225154
Validation loss: 2.7613466881322974

Epoch: 5| Step: 7
Training loss: 2.465744506879325
Validation loss: 2.7734701406293327

Epoch: 5| Step: 8
Training loss: 3.307723434178952
Validation loss: 2.744315671412111

Epoch: 5| Step: 9
Training loss: 3.4532745467034136
Validation loss: 2.761321275787419

Epoch: 5| Step: 10
Training loss: 2.3022578476800963
Validation loss: 2.7579525822491338

Epoch: 98| Step: 0
Training loss: 2.926753413566514
Validation loss: 2.738587740873444

Epoch: 5| Step: 1
Training loss: 2.8161778456600057
Validation loss: 2.7549197637485956

Epoch: 5| Step: 2
Training loss: 3.5039021673784743
Validation loss: 2.7780194251939974

Epoch: 5| Step: 3
Training loss: 2.955879823763432
Validation loss: 2.7464167825699586

Epoch: 5| Step: 4
Training loss: 1.9308681196894144
Validation loss: 2.734139396021735

Epoch: 5| Step: 5
Training loss: 2.502653525689726
Validation loss: 2.75672199002054

Epoch: 5| Step: 6
Training loss: 3.1082855309568274
Validation loss: 2.7846322053819526

Epoch: 5| Step: 7
Training loss: 3.105122941634681
Validation loss: 2.7420291140288002

Epoch: 5| Step: 8
Training loss: 3.0935719756722246
Validation loss: 2.732066318926699

Epoch: 5| Step: 9
Training loss: 2.1646550327893412
Validation loss: 2.744665208613486

Epoch: 5| Step: 10
Training loss: 2.83788491213723
Validation loss: 2.763208476371121

Epoch: 99| Step: 0
Training loss: 2.9273011114121825
Validation loss: 2.73361086995819

Epoch: 5| Step: 1
Training loss: 2.5666520510500965
Validation loss: 2.7493562606794546

Epoch: 5| Step: 2
Training loss: 2.718086951071283
Validation loss: 2.7303075922264157

Epoch: 5| Step: 3
Training loss: 2.988285398792055
Validation loss: 2.75982598648332

Epoch: 5| Step: 4
Training loss: 2.5672293958536425
Validation loss: 2.7626586879620634

Epoch: 5| Step: 5
Training loss: 2.4720231582087693
Validation loss: 2.7451362131314365

Epoch: 5| Step: 6
Training loss: 2.3512305345393703
Validation loss: 2.734576122663193

Epoch: 5| Step: 7
Training loss: 2.99478857067888
Validation loss: 2.7597070885203796

Epoch: 5| Step: 8
Training loss: 3.021961887061216
Validation loss: 2.756372401544596

Epoch: 5| Step: 9
Training loss: 3.322324757887916
Validation loss: 2.7389511354659213

Epoch: 5| Step: 10
Training loss: 3.05786342354282
Validation loss: 2.7492544211319

Epoch: 100| Step: 0
Training loss: 2.0196622883472792
Validation loss: 2.7000435858687064

Epoch: 5| Step: 1
Training loss: 2.955966934297912
Validation loss: 2.750950560446751

Epoch: 5| Step: 2
Training loss: 2.495808520907537
Validation loss: 2.7288394015663058

Epoch: 5| Step: 3
Training loss: 2.1339616858449104
Validation loss: 2.7421995002075694

Epoch: 5| Step: 4
Training loss: 2.887907988553999
Validation loss: 2.785334644335147

Epoch: 5| Step: 5
Training loss: 2.8798458889948177
Validation loss: 2.7371362257625798

Epoch: 5| Step: 6
Training loss: 2.4259653313369665
Validation loss: 2.7608241672989635

Epoch: 5| Step: 7
Training loss: 3.2022422504556127
Validation loss: 2.7447766678004863

Epoch: 5| Step: 8
Training loss: 3.2989243921899365
Validation loss: 2.750263960280769

Epoch: 5| Step: 9
Training loss: 3.236456307340065
Validation loss: 2.732309194048088

Epoch: 5| Step: 10
Training loss: 3.204433415838208
Validation loss: 2.716712409708322

Epoch: 101| Step: 0
Training loss: 2.9856186118086523
Validation loss: 2.751844341402451

Epoch: 5| Step: 1
Training loss: 2.7376856353386256
Validation loss: 2.7409354647884343

Epoch: 5| Step: 2
Training loss: 2.4065457447173606
Validation loss: 2.746880476336921

Epoch: 5| Step: 3
Training loss: 1.972668456993481
Validation loss: 2.743850209997154

Epoch: 5| Step: 4
Training loss: 2.4312517337743857
Validation loss: 2.7355719107525114

Epoch: 5| Step: 5
Training loss: 2.1793329641031254
Validation loss: 2.7583149628832517

Epoch: 5| Step: 6
Training loss: 3.1702312852018166
Validation loss: 2.689086935840586

Epoch: 5| Step: 7
Training loss: 3.96587574123263
Validation loss: 2.7342945167896846

Epoch: 5| Step: 8
Training loss: 3.4823299958522322
Validation loss: 2.7296248618634684

Epoch: 5| Step: 9
Training loss: 2.8795682024448976
Validation loss: 2.7037822344770563

Epoch: 5| Step: 10
Training loss: 1.773114078287743
Validation loss: 2.658577738625489

Epoch: 102| Step: 0
Training loss: 2.127878371412565
Validation loss: 2.722383932637749

Epoch: 5| Step: 1
Training loss: 2.467189440445623
Validation loss: 2.7479598027495085

Epoch: 5| Step: 2
Training loss: 3.2748472687728603
Validation loss: 2.726675080901844

Epoch: 5| Step: 3
Training loss: 2.412051057303628
Validation loss: 2.731185794288818

Epoch: 5| Step: 4
Training loss: 3.05366908899611
Validation loss: 2.7403060628538545

Epoch: 5| Step: 5
Training loss: 3.066577921149954
Validation loss: 2.7230739021586667

Epoch: 5| Step: 6
Training loss: 3.0169107334888667
Validation loss: 2.7504976555025387

Epoch: 5| Step: 7
Training loss: 3.1158464266990036
Validation loss: 2.722452669460623

Epoch: 5| Step: 8
Training loss: 2.8772285780175917
Validation loss: 2.739749498372303

Epoch: 5| Step: 9
Training loss: 2.515605002377086
Validation loss: 2.736936716858695

Epoch: 5| Step: 10
Training loss: 2.850710054252366
Validation loss: 2.7015240952954565

Epoch: 103| Step: 0
Training loss: 3.442316183973985
Validation loss: 2.7305617785107916

Epoch: 5| Step: 1
Training loss: 2.9831032165205142
Validation loss: 2.7528437363509504

Epoch: 5| Step: 2
Training loss: 2.946325477018505
Validation loss: 2.756356941748916

Epoch: 5| Step: 3
Training loss: 3.0051292439879003
Validation loss: 2.7258266691664508

Epoch: 5| Step: 4
Training loss: 2.7471731568744113
Validation loss: 2.7421219878131726

Epoch: 5| Step: 5
Training loss: 2.3953011847799237
Validation loss: 2.729932336802245

Epoch: 5| Step: 6
Training loss: 2.2596125307705055
Validation loss: 2.7177036446775955

Epoch: 5| Step: 7
Training loss: 2.9566308258132135
Validation loss: 2.753802665624761

Epoch: 5| Step: 8
Training loss: 1.8062554356054337
Validation loss: 2.7120326282635228

Epoch: 5| Step: 9
Training loss: 2.8179246087314658
Validation loss: 2.7148998770227695

Epoch: 5| Step: 10
Training loss: 3.4738488740085804
Validation loss: 2.734853126925676

Epoch: 104| Step: 0
Training loss: 3.101772810486141
Validation loss: 2.6823797937657323

Epoch: 5| Step: 1
Training loss: 2.5354236056238872
Validation loss: 2.7633204094435517

Epoch: 5| Step: 2
Training loss: 2.7054932203516335
Validation loss: 2.748381818189727

Epoch: 5| Step: 3
Training loss: 2.6011696825363377
Validation loss: 2.7101721781922605

Epoch: 5| Step: 4
Training loss: 2.3538162735873605
Validation loss: 2.7445917468643506

Epoch: 5| Step: 5
Training loss: 3.0571438408660323
Validation loss: 2.745185061869361

Epoch: 5| Step: 6
Training loss: 2.8551342477317596
Validation loss: 2.74787001004171

Epoch: 5| Step: 7
Training loss: 3.4273484580653495
Validation loss: 2.7281124064190263

Epoch: 5| Step: 8
Training loss: 2.7552329472750574
Validation loss: 2.7507968281397717

Epoch: 5| Step: 9
Training loss: 2.8842384512703907
Validation loss: 2.727689812343221

Epoch: 5| Step: 10
Training loss: 2.4771750862789363
Validation loss: 2.721395888933349

Epoch: 105| Step: 0
Training loss: 2.5533355962213724
Validation loss: 2.7525376472224408

Epoch: 5| Step: 1
Training loss: 2.3332963895143712
Validation loss: 2.7479751232025644

Epoch: 5| Step: 2
Training loss: 3.041995479281927
Validation loss: 2.7562814812249052

Epoch: 5| Step: 3
Training loss: 3.3996593865712708
Validation loss: 2.774092487117027

Epoch: 5| Step: 4
Training loss: 1.9385105696993399
Validation loss: 2.7068329175417074

Epoch: 5| Step: 5
Training loss: 2.7163543669886123
Validation loss: 2.7584306847392863

Epoch: 5| Step: 6
Training loss: 2.955719953122112
Validation loss: 2.7197506375877567

Epoch: 5| Step: 7
Training loss: 3.147132167517243
Validation loss: 2.7638822811638124

Epoch: 5| Step: 8
Training loss: 2.8341563282387066
Validation loss: 2.6981093277349046

Epoch: 5| Step: 9
Training loss: 2.658305909624223
Validation loss: 2.739277470773157

Epoch: 5| Step: 10
Training loss: 3.200124088504027
Validation loss: 2.704539784996347

Epoch: 106| Step: 0
Training loss: 3.133069415509708
Validation loss: 2.7324996578649903

Epoch: 5| Step: 1
Training loss: 2.4308119744570074
Validation loss: 2.730052485488289

Epoch: 5| Step: 2
Training loss: 2.859788541645988
Validation loss: 2.6974996663478765

Epoch: 5| Step: 3
Training loss: 2.3861289036888875
Validation loss: 2.72692307570459

Epoch: 5| Step: 4
Training loss: 2.407175752981782
Validation loss: 2.7277416882428644

Epoch: 5| Step: 5
Training loss: 2.941279151470496
Validation loss: 2.7414399675283834

Epoch: 5| Step: 6
Training loss: 2.9371358767527767
Validation loss: 2.734869443193395

Epoch: 5| Step: 7
Training loss: 3.047381706163756
Validation loss: 2.740480522562286

Epoch: 5| Step: 8
Training loss: 3.135819131530291
Validation loss: 2.744458912366553

Epoch: 5| Step: 9
Training loss: 3.3594048077347636
Validation loss: 2.7052930125286387

Epoch: 5| Step: 10
Training loss: 2.0186396093272743
Validation loss: 2.7409984112961774

Epoch: 107| Step: 0
Training loss: 3.2499715363649906
Validation loss: 2.7037115039885546

Epoch: 5| Step: 1
Training loss: 3.1580630090284996
Validation loss: 2.7082879970595934

Epoch: 5| Step: 2
Training loss: 2.8590993279317845
Validation loss: 2.710194546571813

Epoch: 5| Step: 3
Training loss: 2.692868836056964
Validation loss: 2.7376749712959607

Epoch: 5| Step: 4
Training loss: 2.4187913521477227
Validation loss: 2.7464774402315335

Epoch: 5| Step: 5
Training loss: 2.9017367851407987
Validation loss: 2.712291474330103

Epoch: 5| Step: 6
Training loss: 2.5257448212072946
Validation loss: 2.724828391773983

Epoch: 5| Step: 7
Training loss: 2.502063948285946
Validation loss: 2.7325439604114674

Epoch: 5| Step: 8
Training loss: 2.735218027131443
Validation loss: 2.721298007274733

Epoch: 5| Step: 9
Training loss: 2.8985615418411976
Validation loss: 2.682389540319805

Epoch: 5| Step: 10
Training loss: 3.0134813665076914
Validation loss: 2.75160238560582

Epoch: 108| Step: 0
Training loss: 2.590722396731512
Validation loss: 2.742739653363044

Epoch: 5| Step: 1
Training loss: 2.6484380401340712
Validation loss: 2.747307164675665

Epoch: 5| Step: 2
Training loss: 3.2603664861520456
Validation loss: 2.794225188555128

Epoch: 5| Step: 3
Training loss: 3.5016905925017467
Validation loss: 2.71388894636202

Epoch: 5| Step: 4
Training loss: 1.9709067263120346
Validation loss: 2.7076682631717928

Epoch: 5| Step: 5
Training loss: 2.5731391553139646
Validation loss: 2.756498270742707

Epoch: 5| Step: 6
Training loss: 2.5408222379991647
Validation loss: 2.7145543003535764

Epoch: 5| Step: 7
Training loss: 2.7980670626267674
Validation loss: 2.714018347246884

Epoch: 5| Step: 8
Training loss: 2.4867479999151074
Validation loss: 2.7452717785534877

Epoch: 5| Step: 9
Training loss: 3.1693691634401064
Validation loss: 2.716285441868524

Epoch: 5| Step: 10
Training loss: 3.037152550687881
Validation loss: 2.690103142520578

Epoch: 109| Step: 0
Training loss: 3.1463529818643705
Validation loss: 2.6777773605844133

Epoch: 5| Step: 1
Training loss: 3.6381667846733725
Validation loss: 2.728644991791227

Epoch: 5| Step: 2
Training loss: 2.6679006542714463
Validation loss: 2.7296494291257707

Epoch: 5| Step: 3
Training loss: 2.606068692201512
Validation loss: 2.727011383703612

Epoch: 5| Step: 4
Training loss: 2.9220786610171663
Validation loss: 2.6987236647733113

Epoch: 5| Step: 5
Training loss: 3.3673578559991046
Validation loss: 2.7230364434488235

Epoch: 5| Step: 6
Training loss: 2.4395223200004286
Validation loss: 2.724367975873344

Epoch: 5| Step: 7
Training loss: 2.2896629821789163
Validation loss: 2.7174503198201245

Epoch: 5| Step: 8
Training loss: 2.54282726825965
Validation loss: 2.710643127124754

Epoch: 5| Step: 9
Training loss: 2.410362098843301
Validation loss: 2.697320998178283

Epoch: 5| Step: 10
Training loss: 2.825769697676699
Validation loss: 2.7117331212252402

Epoch: 110| Step: 0
Training loss: 2.913157631953829
Validation loss: 2.7323109289066614

Epoch: 5| Step: 1
Training loss: 2.6480350695013617
Validation loss: 2.7174212573069463

Epoch: 5| Step: 2
Training loss: 2.7294523560376347
Validation loss: 2.7080189568974875

Epoch: 5| Step: 3
Training loss: 2.598926755500536
Validation loss: 2.6834880361850275

Epoch: 5| Step: 4
Training loss: 3.4459108970489054
Validation loss: 2.7166486291709964

Epoch: 5| Step: 5
Training loss: 2.8448098691350747
Validation loss: 2.7154882797190787

Epoch: 5| Step: 6
Training loss: 2.765810082056189
Validation loss: 2.717667100551031

Epoch: 5| Step: 7
Training loss: 2.4384556388644762
Validation loss: 2.662089843139061

Epoch: 5| Step: 8
Training loss: 2.2297458312244456
Validation loss: 2.747047313953512

Epoch: 5| Step: 9
Training loss: 3.29262974488506
Validation loss: 2.74613294006193

Epoch: 5| Step: 10
Training loss: 3.019863174572591
Validation loss: 2.7633556271264843

Epoch: 111| Step: 0
Training loss: 3.2497879839479977
Validation loss: 2.732284956579368

Epoch: 5| Step: 1
Training loss: 2.868266804211917
Validation loss: 2.68896492145154

Epoch: 5| Step: 2
Training loss: 2.41613453454475
Validation loss: 2.702336498105941

Epoch: 5| Step: 3
Training loss: 1.8077452545715686
Validation loss: 2.690896768684214

Epoch: 5| Step: 4
Training loss: 3.510852745129855
Validation loss: 2.741336495652898

Epoch: 5| Step: 5
Training loss: 2.577570630205646
Validation loss: 2.7657450561902226

Epoch: 5| Step: 6
Training loss: 2.270405323627728
Validation loss: 2.7248633778042772

Epoch: 5| Step: 7
Training loss: 3.3342641166690785
Validation loss: 2.7645952900872173

Epoch: 5| Step: 8
Training loss: 2.9532593388756516
Validation loss: 2.7376860848231783

Epoch: 5| Step: 9
Training loss: 2.7212940458869355
Validation loss: 2.682676856609027

Epoch: 5| Step: 10
Training loss: 2.3322895871815192
Validation loss: 2.7355186459200356

Epoch: 112| Step: 0
Training loss: 2.5500700398718372
Validation loss: 2.7432938692673896

Epoch: 5| Step: 1
Training loss: 2.9499669218633437
Validation loss: 2.739058499311414

Epoch: 5| Step: 2
Training loss: 1.6459716867489251
Validation loss: 2.7165672801072405

Epoch: 5| Step: 3
Training loss: 2.8923704084348953
Validation loss: 2.6798445194797815

Epoch: 5| Step: 4
Training loss: 3.0758987353935283
Validation loss: 2.715426332199753

Epoch: 5| Step: 5
Training loss: 3.019520353665252
Validation loss: 2.7127901145457063

Epoch: 5| Step: 6
Training loss: 3.005772123997654
Validation loss: 2.695938615451215

Epoch: 5| Step: 7
Training loss: 2.8781709184825237
Validation loss: 2.6977919550005307

Epoch: 5| Step: 8
Training loss: 3.14596149781391
Validation loss: 2.6860864407868816

Epoch: 5| Step: 9
Training loss: 2.6248326929453216
Validation loss: 2.72561377298026

Epoch: 5| Step: 10
Training loss: 2.8271481001726912
Validation loss: 2.758356423190421

Epoch: 113| Step: 0
Training loss: 3.1192636865693317
Validation loss: 2.708985350684114

Epoch: 5| Step: 1
Training loss: 3.5911480316015223
Validation loss: 2.642856776840502

Epoch: 5| Step: 2
Training loss: 2.199112288234097
Validation loss: 2.720226295791621

Epoch: 5| Step: 3
Training loss: 2.9608622921372905
Validation loss: 2.7314076382166035

Epoch: 5| Step: 4
Training loss: 2.62720451428424
Validation loss: 2.7075103424362252

Epoch: 5| Step: 5
Training loss: 2.385396188262148
Validation loss: 2.7151773156505152

Epoch: 5| Step: 6
Training loss: 1.905646369291294
Validation loss: 2.7422461309301105

Epoch: 5| Step: 7
Training loss: 2.4059559035473725
Validation loss: 2.74996764573262

Epoch: 5| Step: 8
Training loss: 3.0297851169042103
Validation loss: 2.7069188938867623

Epoch: 5| Step: 9
Training loss: 3.258970059543202
Validation loss: 2.7195390568282054

Epoch: 5| Step: 10
Training loss: 2.512936879602084
Validation loss: 2.746370778072721

Epoch: 114| Step: 0
Training loss: 2.630433227190441
Validation loss: 2.7363425043621574

Epoch: 5| Step: 1
Training loss: 2.380387269576449
Validation loss: 2.706429374688089

Epoch: 5| Step: 2
Training loss: 3.3615758029936584
Validation loss: 2.735099375417414

Epoch: 5| Step: 3
Training loss: 2.711952129532296
Validation loss: 2.7160769589246723

Epoch: 5| Step: 4
Training loss: 2.5970940232440696
Validation loss: 2.6870806749179175

Epoch: 5| Step: 5
Training loss: 3.068339793958049
Validation loss: 2.691929091534051

Epoch: 5| Step: 6
Training loss: 2.569163984738003
Validation loss: 2.7468571290135704

Epoch: 5| Step: 7
Training loss: 2.77347205771824
Validation loss: 2.709882209223284

Epoch: 5| Step: 8
Training loss: 2.6831877066701977
Validation loss: 2.7293345864595846

Epoch: 5| Step: 9
Training loss: 2.906322027154751
Validation loss: 2.715230507906852

Epoch: 5| Step: 10
Training loss: 2.702222199255263
Validation loss: 2.7267284174171618

Epoch: 115| Step: 0
Training loss: 2.517452074066346
Validation loss: 2.713256753587276

Epoch: 5| Step: 1
Training loss: 3.220557732940997
Validation loss: 2.7188618011928702

Epoch: 5| Step: 2
Training loss: 2.747188431322315
Validation loss: 2.7279411337874144

Epoch: 5| Step: 3
Training loss: 3.025709299206661
Validation loss: 2.720856712781197

Epoch: 5| Step: 4
Training loss: 2.88975256048677
Validation loss: 2.72041121534493

Epoch: 5| Step: 5
Training loss: 1.9645429195105097
Validation loss: 2.729402613794924

Epoch: 5| Step: 6
Training loss: 2.770369259015633
Validation loss: 2.7017040236706706

Epoch: 5| Step: 7
Training loss: 2.65024453240507
Validation loss: 2.7116300416941916

Epoch: 5| Step: 8
Training loss: 3.0064740262060248
Validation loss: 2.714152918076066

Epoch: 5| Step: 9
Training loss: 3.0197482210007682
Validation loss: 2.7172110707816612

Epoch: 5| Step: 10
Training loss: 2.671393100045499
Validation loss: 2.6854077451283382

Epoch: 116| Step: 0
Training loss: 3.1114259023203306
Validation loss: 2.7101855054060797

Epoch: 5| Step: 1
Training loss: 3.1602298836446168
Validation loss: 2.7033657792082404

Epoch: 5| Step: 2
Training loss: 3.419439973543331
Validation loss: 2.674115092814161

Epoch: 5| Step: 3
Training loss: 2.425953243135246
Validation loss: 2.7243013246994314

Epoch: 5| Step: 4
Training loss: 3.227514537539197
Validation loss: 2.710062572639435

Epoch: 5| Step: 5
Training loss: 2.4846095328319997
Validation loss: 2.724052639481287

Epoch: 5| Step: 6
Training loss: 2.4151610803688475
Validation loss: 2.68855072986341

Epoch: 5| Step: 7
Training loss: 2.4266346092342372
Validation loss: 2.7206767563504632

Epoch: 5| Step: 8
Training loss: 2.1018640238066673
Validation loss: 2.711182832410828

Epoch: 5| Step: 9
Training loss: 2.9706503156774726
Validation loss: 2.7321593005477167

Epoch: 5| Step: 10
Training loss: 2.3010296258457377
Validation loss: 2.707637705733914

Epoch: 117| Step: 0
Training loss: 3.185204071741353
Validation loss: 2.686435604107061

Epoch: 5| Step: 1
Training loss: 2.3258005097206524
Validation loss: 2.675449946700062

Epoch: 5| Step: 2
Training loss: 2.257392078578607
Validation loss: 2.650664872192264

Epoch: 5| Step: 3
Training loss: 2.5860636239541113
Validation loss: 2.726115307515505

Epoch: 5| Step: 4
Training loss: 2.706586440671651
Validation loss: 2.685369115649824

Epoch: 5| Step: 5
Training loss: 3.033909682828744
Validation loss: 2.6796847887281685

Epoch: 5| Step: 6
Training loss: 2.7322224891234645
Validation loss: 2.7071586292085805

Epoch: 5| Step: 7
Training loss: 2.7212421789657073
Validation loss: 2.7228009307653918

Epoch: 5| Step: 8
Training loss: 2.9213987564127097
Validation loss: 2.6949176134650146

Epoch: 5| Step: 9
Training loss: 3.3839942330475856
Validation loss: 2.7007621468802236

Epoch: 5| Step: 10
Training loss: 2.290766475622821
Validation loss: 2.7295412856837276

Epoch: 118| Step: 0
Training loss: 3.2375029398194153
Validation loss: 2.694849384380628

Epoch: 5| Step: 1
Training loss: 2.542960030677016
Validation loss: 2.706250428332807

Epoch: 5| Step: 2
Training loss: 2.6998285027186073
Validation loss: 2.699618433580758

Epoch: 5| Step: 3
Training loss: 2.782130412793236
Validation loss: 2.6978236873022423

Epoch: 5| Step: 4
Training loss: 2.2846485062919957
Validation loss: 2.6867984496133404

Epoch: 5| Step: 5
Training loss: 2.8835337493863493
Validation loss: 2.672066124777129

Epoch: 5| Step: 6
Training loss: 3.091788392528241
Validation loss: 2.6690860717761766

Epoch: 5| Step: 7
Training loss: 2.4506848098317118
Validation loss: 2.681408806717536

Epoch: 5| Step: 8
Training loss: 3.0433460633372715
Validation loss: 2.6722976896174133

Epoch: 5| Step: 9
Training loss: 2.9050932192003156
Validation loss: 2.6929836432749132

Epoch: 5| Step: 10
Training loss: 2.5392500118560957
Validation loss: 2.7051247132754375

Epoch: 119| Step: 0
Training loss: 2.7957495444221605
Validation loss: 2.711487380521853

Epoch: 5| Step: 1
Training loss: 2.6944853909539406
Validation loss: 2.7421816101936507

Epoch: 5| Step: 2
Training loss: 3.003733695720566
Validation loss: 2.6753806093079455

Epoch: 5| Step: 3
Training loss: 2.464922098162984
Validation loss: 2.733795310831597

Epoch: 5| Step: 4
Training loss: 2.718440158771215
Validation loss: 2.6928633753165823

Epoch: 5| Step: 5
Training loss: 2.6120224730735586
Validation loss: 2.737876360925747

Epoch: 5| Step: 6
Training loss: 3.5886852898206327
Validation loss: 2.713679527314284

Epoch: 5| Step: 7
Training loss: 2.9840894632402666
Validation loss: 2.674575907598324

Epoch: 5| Step: 8
Training loss: 2.744536608162201
Validation loss: 2.6768220062345454

Epoch: 5| Step: 9
Training loss: 2.1741718250163267
Validation loss: 2.6742237674176352

Epoch: 5| Step: 10
Training loss: 2.6944415910668575
Validation loss: 2.7107668293912686

Epoch: 120| Step: 0
Training loss: 2.0772524270954706
Validation loss: 2.6573517012449117

Epoch: 5| Step: 1
Training loss: 2.9919723552915896
Validation loss: 2.72390746238523

Epoch: 5| Step: 2
Training loss: 3.867855869680964
Validation loss: 2.716137205879891

Epoch: 5| Step: 3
Training loss: 2.266671826786825
Validation loss: 2.736438167169553

Epoch: 5| Step: 4
Training loss: 3.3354523281372748
Validation loss: 2.6637355964858576

Epoch: 5| Step: 5
Training loss: 3.164120219139822
Validation loss: 2.688572454277227

Epoch: 5| Step: 6
Training loss: 2.8860410893741038
Validation loss: 2.682228481569196

Epoch: 5| Step: 7
Training loss: 1.8104155821041579
Validation loss: 2.721399828506206

Epoch: 5| Step: 8
Training loss: 2.4906605793363257
Validation loss: 2.6565689175352203

Epoch: 5| Step: 9
Training loss: 2.581119994060054
Validation loss: 2.699684429261227

Epoch: 5| Step: 10
Training loss: 2.3611965600302907
Validation loss: 2.6937666650068213

Epoch: 121| Step: 0
Training loss: 3.4595795802658427
Validation loss: 2.6835073349177065

Epoch: 5| Step: 1
Training loss: 3.193865833309477
Validation loss: 2.687366345862745

Epoch: 5| Step: 2
Training loss: 2.452737765515653
Validation loss: 2.742452378626031

Epoch: 5| Step: 3
Training loss: 3.345791772669
Validation loss: 2.6961170072451566

Epoch: 5| Step: 4
Training loss: 2.430788925108759
Validation loss: 2.68504718935433

Epoch: 5| Step: 5
Training loss: 2.6834220109427918
Validation loss: 2.7405324584963675

Epoch: 5| Step: 6
Training loss: 2.8358638533180085
Validation loss: 2.7147807102965524

Epoch: 5| Step: 7
Training loss: 2.6435852612692208
Validation loss: 2.7008472970375004

Epoch: 5| Step: 8
Training loss: 2.7697851067377237
Validation loss: 2.681580059988385

Epoch: 5| Step: 9
Training loss: 2.511257479301924
Validation loss: 2.6951474346534443

Epoch: 5| Step: 10
Training loss: 1.6324083476020708
Validation loss: 2.67286070117667

Epoch: 122| Step: 0
Training loss: 2.9090098740930395
Validation loss: 2.6592798295557207

Epoch: 5| Step: 1
Training loss: 2.033439864301912
Validation loss: 2.6915227493106495

Epoch: 5| Step: 2
Training loss: 2.9412710455106277
Validation loss: 2.686047476520333

Epoch: 5| Step: 3
Training loss: 2.732112100750424
Validation loss: 2.715561241087637

Epoch: 5| Step: 4
Training loss: 2.6592036262636674
Validation loss: 2.6771747526738

Epoch: 5| Step: 5
Training loss: 2.746714363131532
Validation loss: 2.6779171520684386

Epoch: 5| Step: 6
Training loss: 2.8020081539539134
Validation loss: 2.710970429771352

Epoch: 5| Step: 7
Training loss: 2.726104435521791
Validation loss: 2.6760781400313705

Epoch: 5| Step: 8
Training loss: 3.460382076843078
Validation loss: 2.693242771422103

Epoch: 5| Step: 9
Training loss: 2.8894228523280674
Validation loss: 2.700741802936533

Epoch: 5| Step: 10
Training loss: 2.5425120235072547
Validation loss: 2.6892881518659135

Epoch: 123| Step: 0
Training loss: 2.3917140100912766
Validation loss: 2.7366639066706258

Epoch: 5| Step: 1
Training loss: 2.4610620860700974
Validation loss: 2.7103507473868182

Epoch: 5| Step: 2
Training loss: 2.6184412444192966
Validation loss: 2.6738083326173063

Epoch: 5| Step: 3
Training loss: 2.734110879403541
Validation loss: 2.673767158661

Epoch: 5| Step: 4
Training loss: 3.0984824619310873
Validation loss: 2.7001325147127773

Epoch: 5| Step: 5
Training loss: 2.6512331990200217
Validation loss: 2.655887638399176

Epoch: 5| Step: 6
Training loss: 2.6186128748861077
Validation loss: 2.6625804334938428

Epoch: 5| Step: 7
Training loss: 2.4150722330162373
Validation loss: 2.704061097256446

Epoch: 5| Step: 8
Training loss: 3.3649403448612722
Validation loss: 2.731929579750209

Epoch: 5| Step: 9
Training loss: 3.084597680615306
Validation loss: 2.735255943231156

Epoch: 5| Step: 10
Training loss: 2.590334010145922
Validation loss: 2.7122240046241313

Epoch: 124| Step: 0
Training loss: 2.496288596415045
Validation loss: 2.7211857117067937

Epoch: 5| Step: 1
Training loss: 2.6335225492011416
Validation loss: 2.662119018574778

Epoch: 5| Step: 2
Training loss: 2.820754505297562
Validation loss: 2.673795245958761

Epoch: 5| Step: 3
Training loss: 2.236239528983322
Validation loss: 2.6835007469396177

Epoch: 5| Step: 4
Training loss: 1.95965911411561
Validation loss: 2.6915222997367114

Epoch: 5| Step: 5
Training loss: 3.0239394606630885
Validation loss: 2.716721240422236

Epoch: 5| Step: 6
Training loss: 3.017130421632472
Validation loss: 2.7031781553359884

Epoch: 5| Step: 7
Training loss: 2.9465823079745213
Validation loss: 2.645343259060509

Epoch: 5| Step: 8
Training loss: 2.7151140476390694
Validation loss: 2.681487541596431

Epoch: 5| Step: 9
Training loss: 2.848659260247468
Validation loss: 2.676481876933736

Epoch: 5| Step: 10
Training loss: 3.684834567617717
Validation loss: 2.706285961455658

Epoch: 125| Step: 0
Training loss: 2.531602340477042
Validation loss: 2.6836999984194554

Epoch: 5| Step: 1
Training loss: 2.8628069184191305
Validation loss: 2.704702307514602

Epoch: 5| Step: 2
Training loss: 2.8910352261170913
Validation loss: 2.6768091881060565

Epoch: 5| Step: 3
Training loss: 2.631215593199137
Validation loss: 2.613492059361708

Epoch: 5| Step: 4
Training loss: 2.913977245893901
Validation loss: 2.695987147472191

Epoch: 5| Step: 5
Training loss: 3.2377805610364923
Validation loss: 2.7098161170648374

Epoch: 5| Step: 6
Training loss: 3.1563364149293376
Validation loss: 2.6970223991557134

Epoch: 5| Step: 7
Training loss: 2.8564533253092743
Validation loss: 2.6889684499571334

Epoch: 5| Step: 8
Training loss: 2.1744262201559876
Validation loss: 2.6612765801573053

Epoch: 5| Step: 9
Training loss: 2.539607626277488
Validation loss: 2.7356817832671694

Epoch: 5| Step: 10
Training loss: 2.570079665377935
Validation loss: 2.658813440254164

Epoch: 126| Step: 0
Training loss: 3.079920056531738
Validation loss: 2.6838629184393454

Epoch: 5| Step: 1
Training loss: 2.3772397773563796
Validation loss: 2.677825525753904

Epoch: 5| Step: 2
Training loss: 3.0315579916622943
Validation loss: 2.69530359914391

Epoch: 5| Step: 3
Training loss: 3.1297435616449016
Validation loss: 2.7423231265870043

Epoch: 5| Step: 4
Training loss: 2.160461073161241
Validation loss: 2.7205443344501234

Epoch: 5| Step: 5
Training loss: 2.4366696239336942
Validation loss: 2.7065760405499937

Epoch: 5| Step: 6
Training loss: 2.6441325530905195
Validation loss: 2.7026497819528505

Epoch: 5| Step: 7
Training loss: 2.7099471248240325
Validation loss: 2.684963386637224

Epoch: 5| Step: 8
Training loss: 3.085020291155048
Validation loss: 2.6919913416864665

Epoch: 5| Step: 9
Training loss: 3.011766564451023
Validation loss: 2.7257965720521247

Epoch: 5| Step: 10
Training loss: 2.8046746638862343
Validation loss: 2.663591183874319

Epoch: 127| Step: 0
Training loss: 2.9398589706331006
Validation loss: 2.7103507076602593

Epoch: 5| Step: 1
Training loss: 2.706585031258598
Validation loss: 2.662403144559485

Epoch: 5| Step: 2
Training loss: 3.4184311908147937
Validation loss: 2.697411148717208

Epoch: 5| Step: 3
Training loss: 2.674067974827226
Validation loss: 2.669829783209292

Epoch: 5| Step: 4
Training loss: 2.9189134572429554
Validation loss: 2.6899682987197995

Epoch: 5| Step: 5
Training loss: 2.231873826299277
Validation loss: 2.6641905777907215

Epoch: 5| Step: 6
Training loss: 2.7532301918397257
Validation loss: 2.6762982642565194

Epoch: 5| Step: 7
Training loss: 2.931899555520637
Validation loss: 2.7352115927582092

Epoch: 5| Step: 8
Training loss: 2.0196540249188955
Validation loss: 2.712480385493315

Epoch: 5| Step: 9
Training loss: 2.443730339107791
Validation loss: 2.6454440498988947

Epoch: 5| Step: 10
Training loss: 3.1202426556834775
Validation loss: 2.7017377700564156

Epoch: 128| Step: 0
Training loss: 2.6101625818645604
Validation loss: 2.678688655540165

Epoch: 5| Step: 1
Training loss: 3.0499405526793355
Validation loss: 2.708323240300785

Epoch: 5| Step: 2
Training loss: 2.6586233867705116
Validation loss: 2.660765600820132

Epoch: 5| Step: 3
Training loss: 2.9204034210469274
Validation loss: 2.65752075509334

Epoch: 5| Step: 4
Training loss: 2.7514092562458288
Validation loss: 2.663526258351432

Epoch: 5| Step: 5
Training loss: 3.4501179163587707
Validation loss: 2.6706881734225965

Epoch: 5| Step: 6
Training loss: 2.695705219351454
Validation loss: 2.6756809676609

Epoch: 5| Step: 7
Training loss: 2.679883232419707
Validation loss: 2.6800039154737973

Epoch: 5| Step: 8
Training loss: 3.012213640334073
Validation loss: 2.694647234565953

Epoch: 5| Step: 9
Training loss: 2.2483462508018808
Validation loss: 2.6700087307371727

Epoch: 5| Step: 10
Training loss: 1.9385240986181889
Validation loss: 2.7068328038897413

Epoch: 129| Step: 0
Training loss: 2.572634868144899
Validation loss: 2.6796504976952744

Epoch: 5| Step: 1
Training loss: 2.3521543246002885
Validation loss: 2.685600200701628

Epoch: 5| Step: 2
Training loss: 2.8919936780319655
Validation loss: 2.709424069153724

Epoch: 5| Step: 3
Training loss: 2.9158668147938807
Validation loss: 2.691721863178955

Epoch: 5| Step: 4
Training loss: 2.6337506804535527
Validation loss: 2.7031679071201373

Epoch: 5| Step: 5
Training loss: 3.566378439787518
Validation loss: 2.6864680326194508

Epoch: 5| Step: 6
Training loss: 2.2221802535332538
Validation loss: 2.7009104854023325

Epoch: 5| Step: 7
Training loss: 2.886795889478043
Validation loss: 2.67883153651578

Epoch: 5| Step: 8
Training loss: 2.497972715468554
Validation loss: 2.677304586527225

Epoch: 5| Step: 9
Training loss: 2.946950765467064
Validation loss: 2.6582208298765058

Epoch: 5| Step: 10
Training loss: 2.3846482506562494
Validation loss: 2.6751214476433134

Epoch: 130| Step: 0
Training loss: 2.5372627335290048
Validation loss: 2.675609637072267

Epoch: 5| Step: 1
Training loss: 2.5852129056457014
Validation loss: 2.6921316968514577

Epoch: 5| Step: 2
Training loss: 3.0097821016745625
Validation loss: 2.670138281278208

Epoch: 5| Step: 3
Training loss: 2.8627073121273203
Validation loss: 2.6886711297084815

Epoch: 5| Step: 4
Training loss: 2.6004532749032108
Validation loss: 2.657751787319148

Epoch: 5| Step: 5
Training loss: 2.6822072630012723
Validation loss: 2.6627172428934127

Epoch: 5| Step: 6
Training loss: 3.0388100330443746
Validation loss: 2.7528657850098743

Epoch: 5| Step: 7
Training loss: 2.4284246664821225
Validation loss: 2.6734149848318474

Epoch: 5| Step: 8
Training loss: 2.9141017716857776
Validation loss: 2.6608572432569715

Epoch: 5| Step: 9
Training loss: 2.7232773891883206
Validation loss: 2.655408864330356

Epoch: 5| Step: 10
Training loss: 2.7691371190709044
Validation loss: 2.681970184746387

Epoch: 131| Step: 0
Training loss: 3.32898783356634
Validation loss: 2.6643576937961764

Epoch: 5| Step: 1
Training loss: 2.7114726920717964
Validation loss: 2.705119130382163

Epoch: 5| Step: 2
Training loss: 2.415031164690887
Validation loss: 2.6520343332845617

Epoch: 5| Step: 3
Training loss: 2.268129004198725
Validation loss: 2.69669504777878

Epoch: 5| Step: 4
Training loss: 2.9548615693329694
Validation loss: 2.731728021988186

Epoch: 5| Step: 5
Training loss: 2.6965034838964645
Validation loss: 2.6576227210867955

Epoch: 5| Step: 6
Training loss: 3.084700324343261
Validation loss: 2.6820767660736573

Epoch: 5| Step: 7
Training loss: 2.9800783554119064
Validation loss: 2.7127948377510416

Epoch: 5| Step: 8
Training loss: 2.5341730077284317
Validation loss: 2.684948128666124

Epoch: 5| Step: 9
Training loss: 2.6524527840542165
Validation loss: 2.6805160132811015

Epoch: 5| Step: 10
Training loss: 2.198641170998536
Validation loss: 2.641133709336415

Epoch: 132| Step: 0
Training loss: 2.765837838986336
Validation loss: 2.679409872187723

Epoch: 5| Step: 1
Training loss: 2.6225586392053386
Validation loss: 2.667179051390109

Epoch: 5| Step: 2
Training loss: 3.0693635905928973
Validation loss: 2.7219147236108148

Epoch: 5| Step: 3
Training loss: 2.4476368737450724
Validation loss: 2.674188442903958

Epoch: 5| Step: 4
Training loss: 2.6573287568493966
Validation loss: 2.6795640472912012

Epoch: 5| Step: 5
Training loss: 1.6813374067650946
Validation loss: 2.707566013604975

Epoch: 5| Step: 6
Training loss: 3.2314129963535967
Validation loss: 2.6840514932613884

Epoch: 5| Step: 7
Training loss: 2.4656833965701237
Validation loss: 2.6600748068669824

Epoch: 5| Step: 8
Training loss: 2.4989846074857938
Validation loss: 2.660495663341635

Epoch: 5| Step: 9
Training loss: 2.906722819926228
Validation loss: 2.6723969736516366

Epoch: 5| Step: 10
Training loss: 3.418003766561702
Validation loss: 2.6922065338863055

Epoch: 133| Step: 0
Training loss: 2.8348251977816092
Validation loss: 2.6616695151619862

Epoch: 5| Step: 1
Training loss: 2.7648973100297534
Validation loss: 2.672053658970177

Epoch: 5| Step: 2
Training loss: 3.3154843400318725
Validation loss: 2.7026866609835345

Epoch: 5| Step: 3
Training loss: 2.5522623012357255
Validation loss: 2.70323049213897

Epoch: 5| Step: 4
Training loss: 3.1376646143067233
Validation loss: 2.667334244854204

Epoch: 5| Step: 5
Training loss: 2.0815596341587437
Validation loss: 2.660648013003863

Epoch: 5| Step: 6
Training loss: 2.3808998311011123
Validation loss: 2.685095875268918

Epoch: 5| Step: 7
Training loss: 2.195127214642549
Validation loss: 2.683726265171188

Epoch: 5| Step: 8
Training loss: 3.2070580131724333
Validation loss: 2.692583358059593

Epoch: 5| Step: 9
Training loss: 3.1183102528954665
Validation loss: 2.6714533259798325

Epoch: 5| Step: 10
Training loss: 2.528371893635435
Validation loss: 2.6689452404591645

Epoch: 134| Step: 0
Training loss: 2.720898009890229
Validation loss: 2.6968328044288503

Epoch: 5| Step: 1
Training loss: 2.6601402069369846
Validation loss: 2.6620914032278855

Epoch: 5| Step: 2
Training loss: 2.352090263074922
Validation loss: 2.6651455658141154

Epoch: 5| Step: 3
Training loss: 3.296285567541994
Validation loss: 2.6705007290104947

Epoch: 5| Step: 4
Training loss: 3.525163519563404
Validation loss: 2.6513643911869647

Epoch: 5| Step: 5
Training loss: 2.034924514082804
Validation loss: 2.6759972360828668

Epoch: 5| Step: 6
Training loss: 2.2599502527618824
Validation loss: 2.6557387437246276

Epoch: 5| Step: 7
Training loss: 2.7327908531976166
Validation loss: 2.7063898214074427

Epoch: 5| Step: 8
Training loss: 2.8422404883563854
Validation loss: 2.6608536350811804

Epoch: 5| Step: 9
Training loss: 2.571477284045745
Validation loss: 2.6464240758506308

Epoch: 5| Step: 10
Training loss: 2.999137277532468
Validation loss: 2.620970396477528

Epoch: 135| Step: 0
Training loss: 3.082977652439981
Validation loss: 2.675345006366276

Epoch: 5| Step: 1
Training loss: 2.1783878731509487
Validation loss: 2.6688900614107385

Epoch: 5| Step: 2
Training loss: 2.7722328686132816
Validation loss: 2.6829413919268728

Epoch: 5| Step: 3
Training loss: 1.937628341854032
Validation loss: 2.6223655974540794

Epoch: 5| Step: 4
Training loss: 2.96160993766086
Validation loss: 2.6636441935971025

Epoch: 5| Step: 5
Training loss: 3.3873400266816827
Validation loss: 2.6870178797541775

Epoch: 5| Step: 6
Training loss: 2.3679295752144
Validation loss: 2.6953314934040953

Epoch: 5| Step: 7
Training loss: 2.5573174707751454
Validation loss: 2.720759574478199

Epoch: 5| Step: 8
Training loss: 2.843127675133816
Validation loss: 2.6976113009788283

Epoch: 5| Step: 9
Training loss: 2.805843104575938
Validation loss: 2.653376567988385

Epoch: 5| Step: 10
Training loss: 2.9157080210225064
Validation loss: 2.6790024062109903

Epoch: 136| Step: 0
Training loss: 2.2758069881263197
Validation loss: 2.656032067370071

Epoch: 5| Step: 1
Training loss: 2.9322213977007734
Validation loss: 2.6777952835665206

Epoch: 5| Step: 2
Training loss: 2.787958776243115
Validation loss: 2.669760930258573

Epoch: 5| Step: 3
Training loss: 3.485987542450226
Validation loss: 2.658281174863379

Epoch: 5| Step: 4
Training loss: 2.5238604589722318
Validation loss: 2.6345159886915783

Epoch: 5| Step: 5
Training loss: 2.180160635183251
Validation loss: 2.6358284324386796

Epoch: 5| Step: 6
Training loss: 2.37803676606961
Validation loss: 2.680616635001397

Epoch: 5| Step: 7
Training loss: 2.627888860991396
Validation loss: 2.6570401236860013

Epoch: 5| Step: 8
Training loss: 3.1506262807572933
Validation loss: 2.647325258058582

Epoch: 5| Step: 9
Training loss: 2.8210571658546764
Validation loss: 2.7244925139396434

Epoch: 5| Step: 10
Training loss: 2.7947548443821963
Validation loss: 2.6778946251274993

Epoch: 137| Step: 0
Training loss: 2.3645383407636693
Validation loss: 2.695200428676965

Epoch: 5| Step: 1
Training loss: 3.1118326107401124
Validation loss: 2.684781706120711

Epoch: 5| Step: 2
Training loss: 2.107811581531548
Validation loss: 2.6993712979635296

Epoch: 5| Step: 3
Training loss: 3.7718742718257374
Validation loss: 2.6637539960268866

Epoch: 5| Step: 4
Training loss: 2.8427796437475195
Validation loss: 2.646155955306591

Epoch: 5| Step: 5
Training loss: 3.0327857148502444
Validation loss: 2.686500405392871

Epoch: 5| Step: 6
Training loss: 2.230922672827871
Validation loss: 2.6563341989991853

Epoch: 5| Step: 7
Training loss: 3.0469757845911354
Validation loss: 2.643297940001108

Epoch: 5| Step: 8
Training loss: 2.028406235955398
Validation loss: 2.707168754361248

Epoch: 5| Step: 9
Training loss: 2.424322552783623
Validation loss: 2.6600149381941183

Epoch: 5| Step: 10
Training loss: 2.605919474402053
Validation loss: 2.6731249726649855

Epoch: 138| Step: 0
Training loss: 2.8828358222824386
Validation loss: 2.682187384300527

Epoch: 5| Step: 1
Training loss: 2.644210998888066
Validation loss: 2.688013171351714

Epoch: 5| Step: 2
Training loss: 2.8059124410104874
Validation loss: 2.7081135934392147

Epoch: 5| Step: 3
Training loss: 2.8142270189959837
Validation loss: 2.6657477165090113

Epoch: 5| Step: 4
Training loss: 3.2585805449564615
Validation loss: 2.6472731872704403

Epoch: 5| Step: 5
Training loss: 2.2390566775877825
Validation loss: 2.694340820555463

Epoch: 5| Step: 6
Training loss: 2.833395414981241
Validation loss: 2.678819712759967

Epoch: 5| Step: 7
Training loss: 2.884200260907611
Validation loss: 2.7111681219807204

Epoch: 5| Step: 8
Training loss: 2.7768212536494383
Validation loss: 2.6411765247650516

Epoch: 5| Step: 9
Training loss: 2.0230918795302504
Validation loss: 2.670673782778824

Epoch: 5| Step: 10
Training loss: 2.3750323243200167
Validation loss: 2.631113392079469

Epoch: 139| Step: 0
Training loss: 3.221576227641204
Validation loss: 2.612530850409211

Epoch: 5| Step: 1
Training loss: 2.3304139220655067
Validation loss: 2.6816757959023216

Epoch: 5| Step: 2
Training loss: 2.915607114616398
Validation loss: 2.6780242450677783

Epoch: 5| Step: 3
Training loss: 2.9475544054285794
Validation loss: 2.6307144878514386

Epoch: 5| Step: 4
Training loss: 2.042353170806704
Validation loss: 2.6171181397911734

Epoch: 5| Step: 5
Training loss: 2.989806819276014
Validation loss: 2.643365704529698

Epoch: 5| Step: 6
Training loss: 3.3530618652770916
Validation loss: 2.687508128278631

Epoch: 5| Step: 7
Training loss: 2.3611998921576074
Validation loss: 2.672674129974093

Epoch: 5| Step: 8
Training loss: 2.8792780683930816
Validation loss: 2.6805696370342615

Epoch: 5| Step: 9
Training loss: 2.4197892590654613
Validation loss: 2.6595817059785185

Epoch: 5| Step: 10
Training loss: 2.047377197160106
Validation loss: 2.633656608395574

Epoch: 140| Step: 0
Training loss: 2.9315727983388795
Validation loss: 2.6660966539545643

Epoch: 5| Step: 1
Training loss: 3.150955745481893
Validation loss: 2.6792074301022004

Epoch: 5| Step: 2
Training loss: 2.8220471571477197
Validation loss: 2.6138919589018705

Epoch: 5| Step: 3
Training loss: 2.1976697761995423
Validation loss: 2.6547796234503713

Epoch: 5| Step: 4
Training loss: 1.8067490333817406
Validation loss: 2.653057381697961

Epoch: 5| Step: 5
Training loss: 3.289678013127381
Validation loss: 2.6520343777513573

Epoch: 5| Step: 6
Training loss: 3.10319141881572
Validation loss: 2.6756370515758885

Epoch: 5| Step: 7
Training loss: 2.267251003435514
Validation loss: 2.6956608677185856

Epoch: 5| Step: 8
Training loss: 2.3499387286700517
Validation loss: 2.6672645883594663

Epoch: 5| Step: 9
Training loss: 3.300123160404825
Validation loss: 2.70593261727632

Epoch: 5| Step: 10
Training loss: 2.2928322226643276
Validation loss: 2.663266102452576

Epoch: 141| Step: 0
Training loss: 2.838580620641304
Validation loss: 2.6326461724360817

Epoch: 5| Step: 1
Training loss: 2.7064672545871655
Validation loss: 2.6736703734445917

Epoch: 5| Step: 2
Training loss: 2.3679290717817665
Validation loss: 2.622722164817902

Epoch: 5| Step: 3
Training loss: 2.5715200260338658
Validation loss: 2.6638432384459456

Epoch: 5| Step: 4
Training loss: 3.450738418724382
Validation loss: 2.6783321898034917

Epoch: 5| Step: 5
Training loss: 2.7510921736999943
Validation loss: 2.6541965903353275

Epoch: 5| Step: 6
Training loss: 2.3564491572311153
Validation loss: 2.703206372344763

Epoch: 5| Step: 7
Training loss: 2.453420439016912
Validation loss: 2.632275977254467

Epoch: 5| Step: 8
Training loss: 2.750926208576922
Validation loss: 2.6161827082174085

Epoch: 5| Step: 9
Training loss: 3.131941905071153
Validation loss: 2.6619247613142267

Epoch: 5| Step: 10
Training loss: 2.1943489756788885
Validation loss: 2.6719403559054338

Epoch: 142| Step: 0
Training loss: 2.656458767933352
Validation loss: 2.6358998815563686

Epoch: 5| Step: 1
Training loss: 3.272317407933057
Validation loss: 2.663544103980564

Epoch: 5| Step: 2
Training loss: 2.101644521481126
Validation loss: 2.661872458934466

Epoch: 5| Step: 3
Training loss: 2.7506479020260683
Validation loss: 2.6868240467919198

Epoch: 5| Step: 4
Training loss: 3.140407877386716
Validation loss: 2.6213778757828523

Epoch: 5| Step: 5
Training loss: 2.945297767339231
Validation loss: 2.6655089155743106

Epoch: 5| Step: 6
Training loss: 2.626892316036436
Validation loss: 2.6818953478869867

Epoch: 5| Step: 7
Training loss: 2.7008046681892584
Validation loss: 2.683795049752461

Epoch: 5| Step: 8
Training loss: 2.576523346889733
Validation loss: 2.650325173452693

Epoch: 5| Step: 9
Training loss: 2.928115789344005
Validation loss: 2.6699427994466425

Epoch: 5| Step: 10
Training loss: 1.889006244840947
Validation loss: 2.6380768721711427

Epoch: 143| Step: 0
Training loss: 3.6294164391344883
Validation loss: 2.636929744784345

Epoch: 5| Step: 1
Training loss: 2.6487848734843977
Validation loss: 2.653642948931634

Epoch: 5| Step: 2
Training loss: 2.710720086517819
Validation loss: 2.6161570950342248

Epoch: 5| Step: 3
Training loss: 2.6607314060790523
Validation loss: 2.6661738246621147

Epoch: 5| Step: 4
Training loss: 2.5907394218254636
Validation loss: 2.733803416337849

Epoch: 5| Step: 5
Training loss: 2.372404788712573
Validation loss: 2.6465612477148994

Epoch: 5| Step: 6
Training loss: 2.481799920396314
Validation loss: 2.6553721628364477

Epoch: 5| Step: 7
Training loss: 3.076808899815106
Validation loss: 2.658431686102834

Epoch: 5| Step: 8
Training loss: 2.5146827591711167
Validation loss: 2.6756528723722854

Epoch: 5| Step: 9
Training loss: 2.382813500576122
Validation loss: 2.6585303876945785

Epoch: 5| Step: 10
Training loss: 2.2955914498610794
Validation loss: 2.682033023536311

Epoch: 144| Step: 0
Training loss: 2.295770288652965
Validation loss: 2.6593483397967987

Epoch: 5| Step: 1
Training loss: 2.555749981390337
Validation loss: 2.6764930788457493

Epoch: 5| Step: 2
Training loss: 3.5448453364240704
Validation loss: 2.6157399464304736

Epoch: 5| Step: 3
Training loss: 2.5818681766417075
Validation loss: 2.6649357121814865

Epoch: 5| Step: 4
Training loss: 2.7372601791612046
Validation loss: 2.61874176289588

Epoch: 5| Step: 5
Training loss: 2.5776603511211844
Validation loss: 2.665993874480786

Epoch: 5| Step: 6
Training loss: 2.9288582810864163
Validation loss: 2.6323351747010593

Epoch: 5| Step: 7
Training loss: 2.2015384886645823
Validation loss: 2.6755019041288315

Epoch: 5| Step: 8
Training loss: 2.5830129814456786
Validation loss: 2.644411043073826

Epoch: 5| Step: 9
Training loss: 3.0606158941942443
Validation loss: 2.6658424366564044

Epoch: 5| Step: 10
Training loss: 3.0611714186576906
Validation loss: 2.697196622688255

Epoch: 145| Step: 0
Training loss: 2.8995852601339616
Validation loss: 2.645709550277918

Epoch: 5| Step: 1
Training loss: 2.5945577627571614
Validation loss: 2.6454978602939527

Epoch: 5| Step: 2
Training loss: 2.450592191321372
Validation loss: 2.6711883439777155

Epoch: 5| Step: 3
Training loss: 2.654619771307843
Validation loss: 2.6978444780149937

Epoch: 5| Step: 4
Training loss: 2.7105305390965886
Validation loss: 2.653386187263768

Epoch: 5| Step: 5
Training loss: 3.29388943400573
Validation loss: 2.6644343722054646

Epoch: 5| Step: 6
Training loss: 3.005959789837129
Validation loss: 2.627425052685468

Epoch: 5| Step: 7
Training loss: 3.0715661825991822
Validation loss: 2.6838967067110016

Epoch: 5| Step: 8
Training loss: 1.9093159268445328
Validation loss: 2.631701408568961

Epoch: 5| Step: 9
Training loss: 2.4090290617814913
Validation loss: 2.5995476621097975

Epoch: 5| Step: 10
Training loss: 2.648661466147733
Validation loss: 2.665800173659777

Epoch: 146| Step: 0
Training loss: 2.6016286664000443
Validation loss: 2.6467677936925385

Epoch: 5| Step: 1
Training loss: 2.5178983853101693
Validation loss: 2.6561270900715543

Epoch: 5| Step: 2
Training loss: 2.5725700876013735
Validation loss: 2.6520787223753475

Epoch: 5| Step: 3
Training loss: 2.3770621532551965
Validation loss: 2.6852948164947774

Epoch: 5| Step: 4
Training loss: 2.446379115108962
Validation loss: 2.682520403349613

Epoch: 5| Step: 5
Training loss: 2.5582415855267095
Validation loss: 2.6847765889213395

Epoch: 5| Step: 6
Training loss: 3.2036558130107085
Validation loss: 2.6672312996920335

Epoch: 5| Step: 7
Training loss: 2.6930968092308083
Validation loss: 2.6191245509353616

Epoch: 5| Step: 8
Training loss: 2.7803804559882637
Validation loss: 2.662480688075606

Epoch: 5| Step: 9
Training loss: 3.0496689726247883
Validation loss: 2.6222712352592077

Epoch: 5| Step: 10
Training loss: 3.0950524256985155
Validation loss: 2.6515430959617494

Epoch: 147| Step: 0
Training loss: 3.2177873671929147
Validation loss: 2.665230814072448

Epoch: 5| Step: 1
Training loss: 3.2162918037102557
Validation loss: 2.656148485129534

Epoch: 5| Step: 2
Training loss: 2.6306376997481857
Validation loss: 2.689204680549811

Epoch: 5| Step: 3
Training loss: 2.689494523981253
Validation loss: 2.609895104771836

Epoch: 5| Step: 4
Training loss: 2.919989808992343
Validation loss: 2.6524093846707926

Epoch: 5| Step: 5
Training loss: 2.41052886209417
Validation loss: 2.6290953021074825

Epoch: 5| Step: 6
Training loss: 2.9607419877939605
Validation loss: 2.6469921829534226

Epoch: 5| Step: 7
Training loss: 2.755649139582352
Validation loss: 2.646020709369424

Epoch: 5| Step: 8
Training loss: 2.1885473741193375
Validation loss: 2.682409436636882

Epoch: 5| Step: 9
Training loss: 2.244114170964347
Validation loss: 2.6564300186567906

Epoch: 5| Step: 10
Training loss: 2.00296063634061
Validation loss: 2.6821749636220202

Epoch: 148| Step: 0
Training loss: 1.9295499806688527
Validation loss: 2.686081315097343

Epoch: 5| Step: 1
Training loss: 2.555946249974277
Validation loss: 2.6308198266538527

Epoch: 5| Step: 2
Training loss: 2.257009290758041
Validation loss: 2.607948554394673

Epoch: 5| Step: 3
Training loss: 3.1788423431940283
Validation loss: 2.6570787192672185

Epoch: 5| Step: 4
Training loss: 1.9948945446394348
Validation loss: 2.66806809903651

Epoch: 5| Step: 5
Training loss: 3.628122366182224
Validation loss: 2.6243618288538437

Epoch: 5| Step: 6
Training loss: 3.3413041340687943
Validation loss: 2.641375953399702

Epoch: 5| Step: 7
Training loss: 2.2501752573210085
Validation loss: 2.62676053112563

Epoch: 5| Step: 8
Training loss: 2.6072796843544634
Validation loss: 2.658285375777071

Epoch: 5| Step: 9
Training loss: 2.5900158026666062
Validation loss: 2.652271186695886

Epoch: 5| Step: 10
Training loss: 2.72576499140344
Validation loss: 2.6277924025528097

Epoch: 149| Step: 0
Training loss: 2.532598160011571
Validation loss: 2.6200809368393756

Epoch: 5| Step: 1
Training loss: 2.070518742491019
Validation loss: 2.6413419288736453

Epoch: 5| Step: 2
Training loss: 3.421246057131094
Validation loss: 2.640806188627309

Epoch: 5| Step: 3
Training loss: 2.533272112140093
Validation loss: 2.6614266089392506

Epoch: 5| Step: 4
Training loss: 2.548151737659515
Validation loss: 2.6166445197485

Epoch: 5| Step: 5
Training loss: 2.575368991820543
Validation loss: 2.6581366197510468

Epoch: 5| Step: 6
Training loss: 2.4825995476961626
Validation loss: 2.6324150783809945

Epoch: 5| Step: 7
Training loss: 2.7446678659700385
Validation loss: 2.6218925889577895

Epoch: 5| Step: 8
Training loss: 2.5113827019316517
Validation loss: 2.642491316466411

Epoch: 5| Step: 9
Training loss: 3.192381020093562
Validation loss: 2.6881828871374953

Epoch: 5| Step: 10
Training loss: 2.799756829737908
Validation loss: 2.642585236033122

Epoch: 150| Step: 0
Training loss: 3.0182455269230526
Validation loss: 2.658226939468523

Epoch: 5| Step: 1
Training loss: 2.781146015409313
Validation loss: 2.623442774409092

Epoch: 5| Step: 2
Training loss: 2.6297105576246076
Validation loss: 2.6282693726274946

Epoch: 5| Step: 3
Training loss: 2.8933322085833963
Validation loss: 2.6309714051188617

Epoch: 5| Step: 4
Training loss: 2.9259095106545203
Validation loss: 2.6261953190162624

Epoch: 5| Step: 5
Training loss: 1.8541744817790518
Validation loss: 2.6403905040280424

Epoch: 5| Step: 6
Training loss: 2.8761085363395407
Validation loss: 2.6361851315773235

Epoch: 5| Step: 7
Training loss: 2.4844605053276574
Validation loss: 2.6393477371443974

Epoch: 5| Step: 8
Training loss: 1.9896109880319595
Validation loss: 2.6586857494769904

Epoch: 5| Step: 9
Training loss: 3.2824298009171833
Validation loss: 2.647557237098148

Epoch: 5| Step: 10
Training loss: 2.957048826782718
Validation loss: 2.6214307973590527

Epoch: 151| Step: 0
Training loss: 2.3732918067399478
Validation loss: 2.6706176852615866

Epoch: 5| Step: 1
Training loss: 3.329197670446477
Validation loss: 2.6600188356741605

Epoch: 5| Step: 2
Training loss: 2.552370192826034
Validation loss: 2.6705073932180317

Epoch: 5| Step: 3
Training loss: 2.3543066697702546
Validation loss: 2.665485293122219

Epoch: 5| Step: 4
Training loss: 2.9874052471632986
Validation loss: 2.67299496744752

Epoch: 5| Step: 5
Training loss: 3.5050523259369686
Validation loss: 2.6445853969288335

Epoch: 5| Step: 6
Training loss: 2.080181509681358
Validation loss: 2.6677346635309114

Epoch: 5| Step: 7
Training loss: 2.558469719828924
Validation loss: 2.645887710701095

Epoch: 5| Step: 8
Training loss: 2.69350596161107
Validation loss: 2.6354755487608212

Epoch: 5| Step: 9
Training loss: 2.424136576364694
Validation loss: 2.6681403388966882

Epoch: 5| Step: 10
Training loss: 2.649686715663214
Validation loss: 2.6794794530990873

Epoch: 152| Step: 0
Training loss: 2.5175587111050826
Validation loss: 2.647729870415142

Epoch: 5| Step: 1
Training loss: 2.6833869154735708
Validation loss: 2.6223681059901627

Epoch: 5| Step: 2
Training loss: 2.2198004586522884
Validation loss: 2.6572616995771146

Epoch: 5| Step: 3
Training loss: 2.828109741169774
Validation loss: 2.675365638297318

Epoch: 5| Step: 4
Training loss: 3.130872472972446
Validation loss: 2.6170820327296513

Epoch: 5| Step: 5
Training loss: 3.140311306142642
Validation loss: 2.675766507820637

Epoch: 5| Step: 6
Training loss: 3.1007521793524213
Validation loss: 2.630208205973694

Epoch: 5| Step: 7
Training loss: 3.547022341722107
Validation loss: 2.6169052184843524

Epoch: 5| Step: 8
Training loss: 1.8338730913388523
Validation loss: 2.643703628374231

Epoch: 5| Step: 9
Training loss: 1.467202202963969
Validation loss: 2.6303024042868293

Epoch: 5| Step: 10
Training loss: 2.5408222379991647
Validation loss: 2.633194338831127

Epoch: 153| Step: 0
Training loss: 1.878057593534005
Validation loss: 2.602891167784179

Epoch: 5| Step: 1
Training loss: 2.6933603487296556
Validation loss: 2.6182111427661017

Epoch: 5| Step: 2
Training loss: 2.1410169033860327
Validation loss: 2.6041651962440198

Epoch: 5| Step: 3
Training loss: 2.7035565335017666
Validation loss: 2.645536021519332

Epoch: 5| Step: 4
Training loss: 3.141405606406145
Validation loss: 2.585441515766781

Epoch: 5| Step: 5
Training loss: 2.805172169071325
Validation loss: 2.6239290176818284

Epoch: 5| Step: 6
Training loss: 3.1411590881186067
Validation loss: 2.6394870094970004

Epoch: 5| Step: 7
Training loss: 3.1305142389109837
Validation loss: 2.6584412051179505

Epoch: 5| Step: 8
Training loss: 2.825148728768212
Validation loss: 2.6195043000415903

Epoch: 5| Step: 9
Training loss: 2.2030935082315417
Validation loss: 2.6009687998802105

Epoch: 5| Step: 10
Training loss: 2.7356881612450223
Validation loss: 2.673262564879045

Epoch: 154| Step: 0
Training loss: 2.3452776190230713
Validation loss: 2.6646441719978373

Epoch: 5| Step: 1
Training loss: 2.6875834784739
Validation loss: 2.604175364490053

Epoch: 5| Step: 2
Training loss: 2.747003309705453
Validation loss: 2.5878624226168565

Epoch: 5| Step: 3
Training loss: 2.6672368532786956
Validation loss: 2.622102216163398

Epoch: 5| Step: 4
Training loss: 2.9852466209168234
Validation loss: 2.631356496265563

Epoch: 5| Step: 5
Training loss: 2.9985643766514087
Validation loss: 2.658745711719183

Epoch: 5| Step: 6
Training loss: 2.4899079711024115
Validation loss: 2.6406116314145667

Epoch: 5| Step: 7
Training loss: 2.5592837735453866
Validation loss: 2.6543718100295326

Epoch: 5| Step: 8
Training loss: 2.7738093596987947
Validation loss: 2.6045653171379377

Epoch: 5| Step: 9
Training loss: 2.6983610300296306
Validation loss: 2.656600693505131

Epoch: 5| Step: 10
Training loss: 2.5764118398059415
Validation loss: 2.6365492899593677

Epoch: 155| Step: 0
Training loss: 2.770706078229164
Validation loss: 2.685254704636251

Epoch: 5| Step: 1
Training loss: 2.87456243751172
Validation loss: 2.66608261113793

Epoch: 5| Step: 2
Training loss: 3.1529609992908756
Validation loss: 2.6484378329858917

Epoch: 5| Step: 3
Training loss: 2.672219237521755
Validation loss: 2.631706450702987

Epoch: 5| Step: 4
Training loss: 2.1326436964592475
Validation loss: 2.700396607437222

Epoch: 5| Step: 5
Training loss: 2.4312568331036486
Validation loss: 2.657650387690397

Epoch: 5| Step: 6
Training loss: 2.2761392696121234
Validation loss: 2.6119797549083854

Epoch: 5| Step: 7
Training loss: 2.5932692116636478
Validation loss: 2.645633052047196

Epoch: 5| Step: 8
Training loss: 2.405289098926377
Validation loss: 2.6539561569344183

Epoch: 5| Step: 9
Training loss: 2.811180822624663
Validation loss: 2.6078915057432863

Epoch: 5| Step: 10
Training loss: 3.2373264870118215
Validation loss: 2.6203138964888244

Epoch: 156| Step: 0
Training loss: 2.345673649052418
Validation loss: 2.684165528632457

Epoch: 5| Step: 1
Training loss: 2.7764090938404347
Validation loss: 2.649160975700528

Epoch: 5| Step: 2
Training loss: 2.775419746477012
Validation loss: 2.6518283019163675

Epoch: 5| Step: 3
Training loss: 2.954080417021428
Validation loss: 2.6533288875196717

Epoch: 5| Step: 4
Training loss: 2.312378132676186
Validation loss: 2.6848913258575116

Epoch: 5| Step: 5
Training loss: 2.6907003110830643
Validation loss: 2.6175023317646433

Epoch: 5| Step: 6
Training loss: 2.7497456172849577
Validation loss: 2.6452288981645906

Epoch: 5| Step: 7
Training loss: 2.213616140272154
Validation loss: 2.6381105569014687

Epoch: 5| Step: 8
Training loss: 3.0355252663885537
Validation loss: 2.640725329219355

Epoch: 5| Step: 9
Training loss: 3.0813471780738584
Validation loss: 2.662644079387652

Epoch: 5| Step: 10
Training loss: 2.8057835384520375
Validation loss: 2.6541110021538765

Epoch: 157| Step: 0
Training loss: 2.923483013408407
Validation loss: 2.6817815352689967

Epoch: 5| Step: 1
Training loss: 3.360031844396914
Validation loss: 2.6388837025938106

Epoch: 5| Step: 2
Training loss: 1.7287141675124822
Validation loss: 2.623962972941123

Epoch: 5| Step: 3
Training loss: 2.8444672403150624
Validation loss: 2.621302219564157

Epoch: 5| Step: 4
Training loss: 2.8081563680642856
Validation loss: 2.5946340081155967

Epoch: 5| Step: 5
Training loss: 2.794142939095837
Validation loss: 2.633739866177871

Epoch: 5| Step: 6
Training loss: 2.7563901696926227
Validation loss: 2.619920099732956

Epoch: 5| Step: 7
Training loss: 2.4554694568658504
Validation loss: 2.640434382039565

Epoch: 5| Step: 8
Training loss: 3.2423941305107866
Validation loss: 2.6147699221272327

Epoch: 5| Step: 9
Training loss: 2.5773557497909025
Validation loss: 2.633759221850529

Epoch: 5| Step: 10
Training loss: 1.9194381275186534
Validation loss: 2.6528737451461395

Epoch: 158| Step: 0
Training loss: 2.9970297414470486
Validation loss: 2.6169251581223385

Epoch: 5| Step: 1
Training loss: 2.2636038347868683
Validation loss: 2.6515341100559664

Epoch: 5| Step: 2
Training loss: 2.3710195413505786
Validation loss: 2.669128175650502

Epoch: 5| Step: 3
Training loss: 2.613748870659634
Validation loss: 2.6553962479171695

Epoch: 5| Step: 4
Training loss: 2.763238599263104
Validation loss: 2.6742444645589174

Epoch: 5| Step: 5
Training loss: 3.43580099947532
Validation loss: 2.620523357471283

Epoch: 5| Step: 6
Training loss: 2.2369087631521203
Validation loss: 2.642746310844548

Epoch: 5| Step: 7
Training loss: 3.0259920117259558
Validation loss: 2.682609315807015

Epoch: 5| Step: 8
Training loss: 2.4226177430252593
Validation loss: 2.6168784039674686

Epoch: 5| Step: 9
Training loss: 2.868003292597925
Validation loss: 2.626324937943989

Epoch: 5| Step: 10
Training loss: 2.4029399349152585
Validation loss: 2.593350658075231

Epoch: 159| Step: 0
Training loss: 2.600042959005077
Validation loss: 2.6396218982097

Epoch: 5| Step: 1
Training loss: 2.2776969517993035
Validation loss: 2.6218822743101287

Epoch: 5| Step: 2
Training loss: 2.5944755182939874
Validation loss: 2.621809870188549

Epoch: 5| Step: 3
Training loss: 2.9210566226286234
Validation loss: 2.656361968776834

Epoch: 5| Step: 4
Training loss: 2.8803063227084507
Validation loss: 2.6298973498272713

Epoch: 5| Step: 5
Training loss: 2.960916886471782
Validation loss: 2.6580961728092567

Epoch: 5| Step: 6
Training loss: 3.1608873801752835
Validation loss: 2.6624820977267305

Epoch: 5| Step: 7
Training loss: 2.2773644788266516
Validation loss: 2.6677356667942256

Epoch: 5| Step: 8
Training loss: 3.0836486826976937
Validation loss: 2.653825504415021

Epoch: 5| Step: 9
Training loss: 2.773291441604085
Validation loss: 2.6404961718827895

Epoch: 5| Step: 10
Training loss: 1.9669034866485964
Validation loss: 2.666324324001075

Epoch: 160| Step: 0
Training loss: 2.939618097789584
Validation loss: 2.62247238115075

Epoch: 5| Step: 1
Training loss: 1.9529871777544747
Validation loss: 2.621714035886174

Epoch: 5| Step: 2
Training loss: 2.2566832784194375
Validation loss: 2.6659958390448977

Epoch: 5| Step: 3
Training loss: 2.6356698217418515
Validation loss: 2.631463741259091

Epoch: 5| Step: 4
Training loss: 3.1495330646121893
Validation loss: 2.6219940915699644

Epoch: 5| Step: 5
Training loss: 2.66049949459307
Validation loss: 2.640158781818513

Epoch: 5| Step: 6
Training loss: 2.5467602288533255
Validation loss: 2.609504648836236

Epoch: 5| Step: 7
Training loss: 3.1552779712130845
Validation loss: 2.624812645386185

Epoch: 5| Step: 8
Training loss: 3.1812104648014574
Validation loss: 2.6101779636871227

Epoch: 5| Step: 9
Training loss: 2.818054648016348
Validation loss: 2.6631271177599585

Epoch: 5| Step: 10
Training loss: 2.290001998633966
Validation loss: 2.6237631802676162

Epoch: 161| Step: 0
Training loss: 2.117270492672546
Validation loss: 2.555037827530511

Epoch: 5| Step: 1
Training loss: 2.799248737639837
Validation loss: 2.597534390000719

Epoch: 5| Step: 2
Training loss: 3.1989233232224317
Validation loss: 2.5731397341691884

Epoch: 5| Step: 3
Training loss: 2.340453920109204
Validation loss: 2.5988837510558747

Epoch: 5| Step: 4
Training loss: 2.8599531079162785
Validation loss: 2.6435102027955257

Epoch: 5| Step: 5
Training loss: 2.886118246964498
Validation loss: 2.6097861149040265

Epoch: 5| Step: 6
Training loss: 2.7639429181908026
Validation loss: 2.6189018001696374

Epoch: 5| Step: 7
Training loss: 2.2015295000493187
Validation loss: 2.614843412383136

Epoch: 5| Step: 8
Training loss: 2.8163451295270683
Validation loss: 2.6326847487859046

Epoch: 5| Step: 9
Training loss: 2.7445939419278207
Validation loss: 2.666878954900038

Epoch: 5| Step: 10
Training loss: 2.4466696193826234
Validation loss: 2.661480094268926

Epoch: 162| Step: 0
Training loss: 2.511257194482154
Validation loss: 2.687952679348802

Epoch: 5| Step: 1
Training loss: 3.032532410853341
Validation loss: 2.635295795271144

Epoch: 5| Step: 2
Training loss: 3.194805524754741
Validation loss: 2.613033367839534

Epoch: 5| Step: 3
Training loss: 2.7078099747704885
Validation loss: 2.6301031555635026

Epoch: 5| Step: 4
Training loss: 2.628990228680502
Validation loss: 2.6507822945350354

Epoch: 5| Step: 5
Training loss: 2.266054520505803
Validation loss: 2.620794106719798

Epoch: 5| Step: 6
Training loss: 2.397373025373925
Validation loss: 2.650056553734623

Epoch: 5| Step: 7
Training loss: 1.7532728789003649
Validation loss: 2.6162328765220817

Epoch: 5| Step: 8
Training loss: 2.6994345284761128
Validation loss: 2.6789693514362223

Epoch: 5| Step: 9
Training loss: 3.1319286593208338
Validation loss: 2.6646040600343026

Epoch: 5| Step: 10
Training loss: 3.2002193018154106
Validation loss: 2.5754200935268967

Epoch: 163| Step: 0
Training loss: 2.508639095422852
Validation loss: 2.640294922743643

Epoch: 5| Step: 1
Training loss: 2.4629737785514054
Validation loss: 2.6352576024956407

Epoch: 5| Step: 2
Training loss: 2.8210324876842208
Validation loss: 2.6817686739291133

Epoch: 5| Step: 3
Training loss: 2.7579522029948067
Validation loss: 2.63489446087319

Epoch: 5| Step: 4
Training loss: 2.3433920014671643
Validation loss: 2.636440027014342

Epoch: 5| Step: 5
Training loss: 3.227172202817157
Validation loss: 2.6220236994655965

Epoch: 5| Step: 6
Training loss: 2.7512007606048288
Validation loss: 2.6113148508837365

Epoch: 5| Step: 7
Training loss: 2.15858587262887
Validation loss: 2.6319024289025883

Epoch: 5| Step: 8
Training loss: 2.2198990546293182
Validation loss: 2.6301796649128706

Epoch: 5| Step: 9
Training loss: 3.031659285452653
Validation loss: 2.6568381694032808

Epoch: 5| Step: 10
Training loss: 2.641165773896564
Validation loss: 2.6181205769798415

Epoch: 164| Step: 0
Training loss: 3.192927956093011
Validation loss: 2.5991302199286124

Epoch: 5| Step: 1
Training loss: 2.1464056220980168
Validation loss: 2.6290554688183576

Epoch: 5| Step: 2
Training loss: 1.9962135473086893
Validation loss: 2.616927593502515

Epoch: 5| Step: 3
Training loss: 2.450315093194898
Validation loss: 2.6303455558629683

Epoch: 5| Step: 4
Training loss: 2.7043371404471115
Validation loss: 2.634995205303104

Epoch: 5| Step: 5
Training loss: 2.512569870617796
Validation loss: 2.5954015005596935

Epoch: 5| Step: 6
Training loss: 2.6852718254035572
Validation loss: 2.5608725393216023

Epoch: 5| Step: 7
Training loss: 3.25019366347571
Validation loss: 2.6297636644110898

Epoch: 5| Step: 8
Training loss: 2.533464193310539
Validation loss: 2.6257407407519717

Epoch: 5| Step: 9
Training loss: 3.0636739232529333
Validation loss: 2.6258070272112617

Epoch: 5| Step: 10
Training loss: 2.7766596599488924
Validation loss: 2.6488313446518226

Epoch: 165| Step: 0
Training loss: 1.9094999156990842
Validation loss: 2.6245329891181393

Epoch: 5| Step: 1
Training loss: 3.496207907746891
Validation loss: 2.618925591225489

Epoch: 5| Step: 2
Training loss: 2.675116285131742
Validation loss: 2.5871549988920415

Epoch: 5| Step: 3
Training loss: 3.185688476409077
Validation loss: 2.624346636644398

Epoch: 5| Step: 4
Training loss: 2.284868062423541
Validation loss: 2.6294732417250524

Epoch: 5| Step: 5
Training loss: 2.9311384753258665
Validation loss: 2.638676686184359

Epoch: 5| Step: 6
Training loss: 2.520784382830892
Validation loss: 2.613916384996259

Epoch: 5| Step: 7
Training loss: 2.929009687215584
Validation loss: 2.622383620538422

Epoch: 5| Step: 8
Training loss: 2.01339977361091
Validation loss: 2.6188743585471785

Epoch: 5| Step: 9
Training loss: 2.41641634159836
Validation loss: 2.6308640445597415

Epoch: 5| Step: 10
Training loss: 2.6644739633105194
Validation loss: 2.5858790169798724

Epoch: 166| Step: 0
Training loss: 1.4975400462710662
Validation loss: 2.618266603608259

Epoch: 5| Step: 1
Training loss: 3.6131929623926657
Validation loss: 2.6337861024924334

Epoch: 5| Step: 2
Training loss: 2.5574174113283465
Validation loss: 2.6447772462713575

Epoch: 5| Step: 3
Training loss: 2.4471209484058423
Validation loss: 2.6030733588797235

Epoch: 5| Step: 4
Training loss: 2.6414045278007086
Validation loss: 2.6230965220672435

Epoch: 5| Step: 5
Training loss: 2.05060313586642
Validation loss: 2.6522293584468675

Epoch: 5| Step: 6
Training loss: 2.9081814818284637
Validation loss: 2.6065461321488073

Epoch: 5| Step: 7
Training loss: 2.5115305116635245
Validation loss: 2.636099691879274

Epoch: 5| Step: 8
Training loss: 2.3520097782424805
Validation loss: 2.597353167527989

Epoch: 5| Step: 9
Training loss: 3.151932586742945
Validation loss: 2.591649978146612

Epoch: 5| Step: 10
Training loss: 2.9998470903210412
Validation loss: 2.638729464844897

Epoch: 167| Step: 0
Training loss: 2.4949167070265093
Validation loss: 2.6081151162614566

Epoch: 5| Step: 1
Training loss: 2.7628918952351103
Validation loss: 2.5676056535311935

Epoch: 5| Step: 2
Training loss: 1.9653968108500968
Validation loss: 2.628285540976488

Epoch: 5| Step: 3
Training loss: 2.423807665103011
Validation loss: 2.6456734826445065

Epoch: 5| Step: 4
Training loss: 2.494338682670657
Validation loss: 2.6151534611296237

Epoch: 5| Step: 5
Training loss: 2.962438037079452
Validation loss: 2.6273150658432813

Epoch: 5| Step: 6
Training loss: 2.8640463770835574
Validation loss: 2.5914009844632035

Epoch: 5| Step: 7
Training loss: 2.7178502841273566
Validation loss: 2.601124107305466

Epoch: 5| Step: 8
Training loss: 2.6650354840347905
Validation loss: 2.657906507864865

Epoch: 5| Step: 9
Training loss: 2.88884387429534
Validation loss: 2.648638181264161

Epoch: 5| Step: 10
Training loss: 2.978426772496436
Validation loss: 2.629388763673993

Epoch: 168| Step: 0
Training loss: 2.9516849942735965
Validation loss: 2.6055237500347315

Epoch: 5| Step: 1
Training loss: 2.745250154502704
Validation loss: 2.593541488440337

Epoch: 5| Step: 2
Training loss: 2.093764575508968
Validation loss: 2.566348398756259

Epoch: 5| Step: 3
Training loss: 2.203117208264147
Validation loss: 2.6148736326257493

Epoch: 5| Step: 4
Training loss: 3.093154387504996
Validation loss: 2.61722155300731

Epoch: 5| Step: 5
Training loss: 2.5200434201148036
Validation loss: 2.614055247982925

Epoch: 5| Step: 6
Training loss: 2.401834474251988
Validation loss: 2.6472871487723197

Epoch: 5| Step: 7
Training loss: 3.0764651397907397
Validation loss: 2.6219556189921205

Epoch: 5| Step: 8
Training loss: 2.587596257580079
Validation loss: 2.6254582959674235

Epoch: 5| Step: 9
Training loss: 2.916536564422982
Validation loss: 2.619925624443335

Epoch: 5| Step: 10
Training loss: 2.7265881206543834
Validation loss: 2.6139581241076226

Epoch: 169| Step: 0
Training loss: 3.0485422121303527
Validation loss: 2.6463148757447352

Epoch: 5| Step: 1
Training loss: 2.992751743113793
Validation loss: 2.6371058259462243

Epoch: 5| Step: 2
Training loss: 2.974622359469773
Validation loss: 2.617772047882232

Epoch: 5| Step: 3
Training loss: 2.0907679715614025
Validation loss: 2.6096839675198544

Epoch: 5| Step: 4
Training loss: 2.7666816201629367
Validation loss: 2.631544781982838

Epoch: 5| Step: 5
Training loss: 2.1213987914431427
Validation loss: 2.5942277761097623

Epoch: 5| Step: 6
Training loss: 2.3039434751424808
Validation loss: 2.62391720934775

Epoch: 5| Step: 7
Training loss: 2.9794228894862393
Validation loss: 2.6033119671151352

Epoch: 5| Step: 8
Training loss: 2.5267311544752538
Validation loss: 2.6501937552364905

Epoch: 5| Step: 9
Training loss: 2.7776044463014395
Validation loss: 2.653140347603053

Epoch: 5| Step: 10
Training loss: 2.7848033708231448
Validation loss: 2.672724398523414

Epoch: 170| Step: 0
Training loss: 2.981721187439232
Validation loss: 2.6548005919226427

Epoch: 5| Step: 1
Training loss: 2.663294617184893
Validation loss: 2.637682890304016

Epoch: 5| Step: 2
Training loss: 2.8938717315973057
Validation loss: 2.6635649283821117

Epoch: 5| Step: 3
Training loss: 2.724586798461571
Validation loss: 2.628218283073267

Epoch: 5| Step: 4
Training loss: 2.2603022697319535
Validation loss: 2.6338822333890426

Epoch: 5| Step: 5
Training loss: 2.735086664503963
Validation loss: 2.6287767349455033

Epoch: 5| Step: 6
Training loss: 1.7528324365867756
Validation loss: 2.657427524488298

Epoch: 5| Step: 7
Training loss: 2.5089582161250177
Validation loss: 2.67557365630769

Epoch: 5| Step: 8
Training loss: 2.7362914426687834
Validation loss: 2.6239598601822944

Epoch: 5| Step: 9
Training loss: 2.8600929901371117
Validation loss: 2.6288886412267733

Epoch: 5| Step: 10
Training loss: 2.9834976904009713
Validation loss: 2.653502858297665

Epoch: 171| Step: 0
Training loss: 2.9224347073168757
Validation loss: 2.62395521155442

Epoch: 5| Step: 1
Training loss: 2.4438173640886087
Validation loss: 2.6231319013086782

Epoch: 5| Step: 2
Training loss: 2.306940251463401
Validation loss: 2.634397630143395

Epoch: 5| Step: 3
Training loss: 2.1955303477737687
Validation loss: 2.5955966899339113

Epoch: 5| Step: 4
Training loss: 1.9917573950730665
Validation loss: 2.694781367619202

Epoch: 5| Step: 5
Training loss: 2.8400544687877294
Validation loss: 2.6192950981724343

Epoch: 5| Step: 6
Training loss: 2.8382374078381734
Validation loss: 2.584214739594431

Epoch: 5| Step: 7
Training loss: 2.864896019718061
Validation loss: 2.603214043080878

Epoch: 5| Step: 8
Training loss: 2.4500371852310514
Validation loss: 2.649547024455563

Epoch: 5| Step: 9
Training loss: 3.2342163636745993
Validation loss: 2.640307696761546

Epoch: 5| Step: 10
Training loss: 2.9491291765163954
Validation loss: 2.5695441205543297

Epoch: 172| Step: 0
Training loss: 2.7342308660393857
Validation loss: 2.623190036575636

Epoch: 5| Step: 1
Training loss: 2.4189821747923013
Validation loss: 2.628215463106181

Epoch: 5| Step: 2
Training loss: 2.4088326997917346
Validation loss: 2.5618094457476133

Epoch: 5| Step: 3
Training loss: 2.286930588690127
Validation loss: 2.645301452097686

Epoch: 5| Step: 4
Training loss: 3.3550826218006744
Validation loss: 2.619789973093516

Epoch: 5| Step: 5
Training loss: 3.0606193217434594
Validation loss: 2.637470998829611

Epoch: 5| Step: 6
Training loss: 2.1141060226257204
Validation loss: 2.6470188652927167

Epoch: 5| Step: 7
Training loss: 2.49709971995785
Validation loss: 2.6093394646900028

Epoch: 5| Step: 8
Training loss: 2.608036817407797
Validation loss: 2.5568797287214813

Epoch: 5| Step: 9
Training loss: 2.6398279014037147
Validation loss: 2.6701500897102575

Epoch: 5| Step: 10
Training loss: 2.865335391187513
Validation loss: 2.6102971464131834

Epoch: 173| Step: 0
Training loss: 2.7432563633123164
Validation loss: 2.6073492020609614

Epoch: 5| Step: 1
Training loss: 2.533607609440681
Validation loss: 2.5797843875507662

Epoch: 5| Step: 2
Training loss: 2.7745493204995952
Validation loss: 2.6589793862890883

Epoch: 5| Step: 3
Training loss: 2.498749515596374
Validation loss: 2.5972557023671294

Epoch: 5| Step: 4
Training loss: 2.432650510359883
Validation loss: 2.6265407958535834

Epoch: 5| Step: 5
Training loss: 2.655611836685161
Validation loss: 2.612615355452917

Epoch: 5| Step: 6
Training loss: 2.346060364365301
Validation loss: 2.5658559286108105

Epoch: 5| Step: 7
Training loss: 2.8126808956039797
Validation loss: 2.6051287774175917

Epoch: 5| Step: 8
Training loss: 2.1733579992677132
Validation loss: 2.6147702633224084

Epoch: 5| Step: 9
Training loss: 2.6684371514727236
Validation loss: 2.6512153614198017

Epoch: 5| Step: 10
Training loss: 3.3854293744753483
Validation loss: 2.6227213114836565

Epoch: 174| Step: 0
Training loss: 2.9590137039594335
Validation loss: 2.6096799983044265

Epoch: 5| Step: 1
Training loss: 2.7757184172631044
Validation loss: 2.6084524607556228

Epoch: 5| Step: 2
Training loss: 2.6297158160982907
Validation loss: 2.6712504776451

Epoch: 5| Step: 3
Training loss: 2.672073713799138
Validation loss: 2.6255056828779195

Epoch: 5| Step: 4
Training loss: 2.2671156616186874
Validation loss: 2.633011625485132

Epoch: 5| Step: 5
Training loss: 2.7441081306461346
Validation loss: 2.613028860673502

Epoch: 5| Step: 6
Training loss: 2.2679246478337753
Validation loss: 2.631940040155752

Epoch: 5| Step: 7
Training loss: 2.259055564321978
Validation loss: 2.613425110348478

Epoch: 5| Step: 8
Training loss: 3.18621531010058
Validation loss: 2.622887247026742

Epoch: 5| Step: 9
Training loss: 2.556628222103939
Validation loss: 2.5828208292571655

Epoch: 5| Step: 10
Training loss: 2.5649670146286114
Validation loss: 2.679229255154054

Epoch: 175| Step: 0
Training loss: 3.3308193422249053
Validation loss: 2.6332185926890537

Epoch: 5| Step: 1
Training loss: 2.579667248522209
Validation loss: 2.6121418719595484

Epoch: 5| Step: 2
Training loss: 2.4244438084128426
Validation loss: 2.589576972368402

Epoch: 5| Step: 3
Training loss: 2.3046308090220338
Validation loss: 2.616375235129682

Epoch: 5| Step: 4
Training loss: 2.5373391274255592
Validation loss: 2.575888941384777

Epoch: 5| Step: 5
Training loss: 3.1382964502545287
Validation loss: 2.6219003584058567

Epoch: 5| Step: 6
Training loss: 2.309393574765138
Validation loss: 2.586535239568739

Epoch: 5| Step: 7
Training loss: 2.192220988599006
Validation loss: 2.5928472031773855

Epoch: 5| Step: 8
Training loss: 2.493175633572101
Validation loss: 2.59506570473195

Epoch: 5| Step: 9
Training loss: 3.1063679478931263
Validation loss: 2.5976252629636005

Epoch: 5| Step: 10
Training loss: 2.5704883642818155
Validation loss: 2.6177844235396766

Epoch: 176| Step: 0
Training loss: 2.5888185615246635
Validation loss: 2.606827602956863

Epoch: 5| Step: 1
Training loss: 2.610443718707381
Validation loss: 2.585710657887893

Epoch: 5| Step: 2
Training loss: 2.527590802954742
Validation loss: 2.6355373853137714

Epoch: 5| Step: 3
Training loss: 2.887544877665493
Validation loss: 2.5714547488333195

Epoch: 5| Step: 4
Training loss: 2.2629317488144625
Validation loss: 2.6367862033153733

Epoch: 5| Step: 5
Training loss: 2.242027037723792
Validation loss: 2.662627251208111

Epoch: 5| Step: 6
Training loss: 2.8781001749531634
Validation loss: 2.6492702781561217

Epoch: 5| Step: 7
Training loss: 2.3718252546197727
Validation loss: 2.625968437060373

Epoch: 5| Step: 8
Training loss: 2.4959879152787927
Validation loss: 2.5938014432943

Epoch: 5| Step: 9
Training loss: 3.168357364323274
Validation loss: 2.6554794255459346

Epoch: 5| Step: 10
Training loss: 3.178470613035025
Validation loss: 2.612103587964404

Epoch: 177| Step: 0
Training loss: 3.102603305323231
Validation loss: 2.621933489279876

Epoch: 5| Step: 1
Training loss: 2.4748380897043476
Validation loss: 2.641821568620838

Epoch: 5| Step: 2
Training loss: 2.5412771103628295
Validation loss: 2.6186680579987014

Epoch: 5| Step: 3
Training loss: 2.857221449043548
Validation loss: 2.5941945819389707

Epoch: 5| Step: 4
Training loss: 2.742614278159776
Validation loss: 2.5914491227464813

Epoch: 5| Step: 5
Training loss: 2.5889836835173927
Validation loss: 2.6048706911123163

Epoch: 5| Step: 6
Training loss: 2.082301252940027
Validation loss: 2.6032278479461506

Epoch: 5| Step: 7
Training loss: 2.39233875556421
Validation loss: 2.659394616734682

Epoch: 5| Step: 8
Training loss: 2.6834603933102126
Validation loss: 2.551877552715826

Epoch: 5| Step: 9
Training loss: 1.948157746055392
Validation loss: 2.619398916267563

Epoch: 5| Step: 10
Training loss: 3.5311618220029772
Validation loss: 2.6358304729796744

Epoch: 178| Step: 0
Training loss: 2.588362280132534
Validation loss: 2.58211294465097

Epoch: 5| Step: 1
Training loss: 3.1866432983414157
Validation loss: 2.6165437825353006

Epoch: 5| Step: 2
Training loss: 2.2770851472624605
Validation loss: 2.653374317753102

Epoch: 5| Step: 3
Training loss: 3.427654524087721
Validation loss: 2.619377236698878

Epoch: 5| Step: 4
Training loss: 2.046705166126362
Validation loss: 2.5998252649018525

Epoch: 5| Step: 5
Training loss: 2.475514668599377
Validation loss: 2.604748502316275

Epoch: 5| Step: 6
Training loss: 2.966813429584738
Validation loss: 2.581913507934439

Epoch: 5| Step: 7
Training loss: 2.2958992682633546
Validation loss: 2.6085186204463606

Epoch: 5| Step: 8
Training loss: 1.9524342650656554
Validation loss: 2.6020356287302118

Epoch: 5| Step: 9
Training loss: 2.6323870306600075
Validation loss: 2.592062272425971

Epoch: 5| Step: 10
Training loss: 2.6839363956618367
Validation loss: 2.6698468771022363

Epoch: 179| Step: 0
Training loss: 2.9690702566774863
Validation loss: 2.5736440170441104

Epoch: 5| Step: 1
Training loss: 2.327947929868378
Validation loss: 2.6329391544939993

Epoch: 5| Step: 2
Training loss: 2.6823132165333257
Validation loss: 2.5920173955576953

Epoch: 5| Step: 3
Training loss: 2.1398419806705333
Validation loss: 2.552021069213938

Epoch: 5| Step: 4
Training loss: 3.040317148931813
Validation loss: 2.583789646867215

Epoch: 5| Step: 5
Training loss: 2.6171284683174676
Validation loss: 2.6307901959436824

Epoch: 5| Step: 6
Training loss: 2.189839665017484
Validation loss: 2.621822461460544

Epoch: 5| Step: 7
Training loss: 2.672575027939957
Validation loss: 2.623362549561789

Epoch: 5| Step: 8
Training loss: 2.972659939376406
Validation loss: 2.625236947830573

Epoch: 5| Step: 9
Training loss: 3.0010997028205395
Validation loss: 2.617207900806369

Epoch: 5| Step: 10
Training loss: 2.160125897765118
Validation loss: 2.572754394016035

Epoch: 180| Step: 0
Training loss: 2.4279379479273344
Validation loss: 2.6688076408355323

Epoch: 5| Step: 1
Training loss: 2.923957612885016
Validation loss: 2.537310216654323

Epoch: 5| Step: 2
Training loss: 2.55171800969962
Validation loss: 2.6588714211123734

Epoch: 5| Step: 3
Training loss: 2.6176213602316074
Validation loss: 2.617931246452694

Epoch: 5| Step: 4
Training loss: 2.47870002222968
Validation loss: 2.5882616961090426

Epoch: 5| Step: 5
Training loss: 2.1836373149095034
Validation loss: 2.599161997816632

Epoch: 5| Step: 6
Training loss: 2.946769536094151
Validation loss: 2.6054742413970122

Epoch: 5| Step: 7
Training loss: 2.615886125553403
Validation loss: 2.6048762595511876

Epoch: 5| Step: 8
Training loss: 2.282476017336076
Validation loss: 2.583102261241492

Epoch: 5| Step: 9
Training loss: 2.651771449958488
Validation loss: 2.6445890466882034

Epoch: 5| Step: 10
Training loss: 3.2429557165932987
Validation loss: 2.5648891917115035

Epoch: 181| Step: 0
Training loss: 3.399349818051364
Validation loss: 2.605349128935016

Epoch: 5| Step: 1
Training loss: 2.6870989832987027
Validation loss: 2.579395361805994

Epoch: 5| Step: 2
Training loss: 2.2269149768976484
Validation loss: 2.599103715701073

Epoch: 5| Step: 3
Training loss: 2.510147291322424
Validation loss: 2.628186533639213

Epoch: 5| Step: 4
Training loss: 2.8976612131133352
Validation loss: 2.6322559172349904

Epoch: 5| Step: 5
Training loss: 2.5472922890151946
Validation loss: 2.617479400445579

Epoch: 5| Step: 6
Training loss: 2.6960244827856785
Validation loss: 2.619768655898096

Epoch: 5| Step: 7
Training loss: 3.0987240657359747
Validation loss: 2.616763352106908

Epoch: 5| Step: 8
Training loss: 2.24484871233497
Validation loss: 2.619219549164101

Epoch: 5| Step: 9
Training loss: 2.342029397729478
Validation loss: 2.579494242234304

Epoch: 5| Step: 10
Training loss: 1.9385386728478513
Validation loss: 2.5991507023004705

Epoch: 182| Step: 0
Training loss: 2.0781420943625517
Validation loss: 2.577967892828961

Epoch: 5| Step: 1
Training loss: 3.0781026926539403
Validation loss: 2.5759346904014966

Epoch: 5| Step: 2
Training loss: 3.2694062604450678
Validation loss: 2.6520919451928058

Epoch: 5| Step: 3
Training loss: 2.8503975774955466
Validation loss: 2.6701774719373135

Epoch: 5| Step: 4
Training loss: 2.368877349087439
Validation loss: 2.5902836816865173

Epoch: 5| Step: 5
Training loss: 2.3239315079856793
Validation loss: 2.5907533297747203

Epoch: 5| Step: 6
Training loss: 2.1002785543347198
Validation loss: 2.5674796682888097

Epoch: 5| Step: 7
Training loss: 3.2419165808307637
Validation loss: 2.5906798102524156

Epoch: 5| Step: 8
Training loss: 2.1231355903008753
Validation loss: 2.6285161788249543

Epoch: 5| Step: 9
Training loss: 2.390837815729165
Validation loss: 2.6024098714757153

Epoch: 5| Step: 10
Training loss: 2.6874514730641117
Validation loss: 2.5798802982877858

Epoch: 183| Step: 0
Training loss: 3.0070682546152887
Validation loss: 2.63050752633831

Epoch: 5| Step: 1
Training loss: 3.265811604548151
Validation loss: 2.558536175009052

Epoch: 5| Step: 2
Training loss: 2.0163694677652426
Validation loss: 2.628906950174733

Epoch: 5| Step: 3
Training loss: 3.300189769952661
Validation loss: 2.630480440665053

Epoch: 5| Step: 4
Training loss: 2.301286573891248
Validation loss: 2.6255236062925165

Epoch: 5| Step: 5
Training loss: 2.08406880430251
Validation loss: 2.620579203731725

Epoch: 5| Step: 6
Training loss: 2.5213663677846787
Validation loss: 2.6232678391614823

Epoch: 5| Step: 7
Training loss: 2.883254102673064
Validation loss: 2.5943920558031124

Epoch: 5| Step: 8
Training loss: 2.7537674672754164
Validation loss: 2.6236039320143294

Epoch: 5| Step: 9
Training loss: 2.3207881966475807
Validation loss: 2.6008056182109582

Epoch: 5| Step: 10
Training loss: 2.1484592506001268
Validation loss: 2.6365831721431463

Epoch: 184| Step: 0
Training loss: 2.904250903301258
Validation loss: 2.616236449226736

Epoch: 5| Step: 1
Training loss: 2.9067443099136416
Validation loss: 2.6157633683343593

Epoch: 5| Step: 2
Training loss: 2.8433770574477655
Validation loss: 2.6244790546190337

Epoch: 5| Step: 3
Training loss: 2.5344015211794364
Validation loss: 2.5804259671161596

Epoch: 5| Step: 4
Training loss: 2.768561921286846
Validation loss: 2.5858773444874155

Epoch: 5| Step: 5
Training loss: 2.517923951349658
Validation loss: 2.629574861189963

Epoch: 5| Step: 6
Training loss: 2.3508504505564254
Validation loss: 2.5896230374147433

Epoch: 5| Step: 7
Training loss: 2.1812154685186376
Validation loss: 2.6103722548898904

Epoch: 5| Step: 8
Training loss: 2.6059377725685455
Validation loss: 2.6292964017598943

Epoch: 5| Step: 9
Training loss: 2.57930649936561
Validation loss: 2.647739456951996

Epoch: 5| Step: 10
Training loss: 2.7899262616110576
Validation loss: 2.605235528609426

Epoch: 185| Step: 0
Training loss: 2.9215838445344215
Validation loss: 2.598646134626249

Epoch: 5| Step: 1
Training loss: 3.2256860166032837
Validation loss: 2.592251721609782

Epoch: 5| Step: 2
Training loss: 2.957686196767636
Validation loss: 2.593874800212764

Epoch: 5| Step: 3
Training loss: 2.4652049046403413
Validation loss: 2.5790517076820687

Epoch: 5| Step: 4
Training loss: 2.7626210941338694
Validation loss: 2.6129273899858236

Epoch: 5| Step: 5
Training loss: 2.483270843624229
Validation loss: 2.6212910311894473

Epoch: 5| Step: 6
Training loss: 2.3182432664625123
Validation loss: 2.6264004621673744

Epoch: 5| Step: 7
Training loss: 2.237258437772179
Validation loss: 2.626567525392108

Epoch: 5| Step: 8
Training loss: 2.436123385870281
Validation loss: 2.555009223384009

Epoch: 5| Step: 9
Training loss: 2.7674124593423532
Validation loss: 2.6147976225205274

Epoch: 5| Step: 10
Training loss: 1.9539574031852702
Validation loss: 2.6622979422483004

Epoch: 186| Step: 0
Training loss: 2.7793977548891435
Validation loss: 2.633915498730825

Epoch: 5| Step: 1
Training loss: 2.6261966339310545
Validation loss: 2.5449365400367565

Epoch: 5| Step: 2
Training loss: 2.910256853860899
Validation loss: 2.5809745446340786

Epoch: 5| Step: 3
Training loss: 2.342137710418717
Validation loss: 2.557753207479762

Epoch: 5| Step: 4
Training loss: 2.4509911459144593
Validation loss: 2.6273126039884254

Epoch: 5| Step: 5
Training loss: 2.622878352565356
Validation loss: 2.5956729857629406

Epoch: 5| Step: 6
Training loss: 2.4053947613281084
Validation loss: 2.587909669780869

Epoch: 5| Step: 7
Training loss: 2.4645029548786734
Validation loss: 2.602673928612818

Epoch: 5| Step: 8
Training loss: 2.902797658346219
Validation loss: 2.5724933975743935

Epoch: 5| Step: 9
Training loss: 2.7489540538535295
Validation loss: 2.594546698170564

Epoch: 5| Step: 10
Training loss: 2.5575715097701357
Validation loss: 2.5815156032021616

Epoch: 187| Step: 0
Training loss: 2.301313199527995
Validation loss: 2.60674689233366

Epoch: 5| Step: 1
Training loss: 2.545886544162141
Validation loss: 2.64577939636842

Epoch: 5| Step: 2
Training loss: 2.7070932532581766
Validation loss: 2.616539508725835

Epoch: 5| Step: 3
Training loss: 2.7033632206548397
Validation loss: 2.5701339664163405

Epoch: 5| Step: 4
Training loss: 2.4078967912043665
Validation loss: 2.622812785770463

Epoch: 5| Step: 5
Training loss: 3.015304627472979
Validation loss: 2.5727338579396632

Epoch: 5| Step: 6
Training loss: 3.071705121361765
Validation loss: 2.5798110206982265

Epoch: 5| Step: 7
Training loss: 2.496261662669437
Validation loss: 2.637815795337975

Epoch: 5| Step: 8
Training loss: 2.4317212194851683
Validation loss: 2.5920695358897574

Epoch: 5| Step: 9
Training loss: 2.495274464526961
Validation loss: 2.622729185021052

Epoch: 5| Step: 10
Training loss: 2.7562008219719436
Validation loss: 2.583096781832034

Epoch: 188| Step: 0
Training loss: 2.671886600223813
Validation loss: 2.5952363339827813

Epoch: 5| Step: 1
Training loss: 2.9988073521449023
Validation loss: 2.6010404885473477

Epoch: 5| Step: 2
Training loss: 2.095598230643198
Validation loss: 2.6484863555522726

Epoch: 5| Step: 3
Training loss: 2.279648937503158
Validation loss: 2.609966898429957

Epoch: 5| Step: 4
Training loss: 3.3289852552835106
Validation loss: 2.6130779034021994

Epoch: 5| Step: 5
Training loss: 2.999431874204374
Validation loss: 2.5800007251024004

Epoch: 5| Step: 6
Training loss: 2.716186279307836
Validation loss: 2.626040626947375

Epoch: 5| Step: 7
Training loss: 2.0564535115647646
Validation loss: 2.5981929708465534

Epoch: 5| Step: 8
Training loss: 1.993944657249317
Validation loss: 2.6209797013785323

Epoch: 5| Step: 9
Training loss: 3.058143163549517
Validation loss: 2.6448822392022326

Epoch: 5| Step: 10
Training loss: 2.4411836812611045
Validation loss: 2.60595607355784

Epoch: 189| Step: 0
Training loss: 2.7889749636123033
Validation loss: 2.5955460822644074

Epoch: 5| Step: 1
Training loss: 2.440516732485009
Validation loss: 2.601772633059486

Epoch: 5| Step: 2
Training loss: 2.6672074445125165
Validation loss: 2.5751619476627434

Epoch: 5| Step: 3
Training loss: 2.036255054783738
Validation loss: 2.571177578679484

Epoch: 5| Step: 4
Training loss: 2.9046912166085352
Validation loss: 2.556791858481658

Epoch: 5| Step: 5
Training loss: 1.956051396535237
Validation loss: 2.6233903488069874

Epoch: 5| Step: 6
Training loss: 2.81504875831996
Validation loss: 2.6014006490216577

Epoch: 5| Step: 7
Training loss: 2.4133522939551884
Validation loss: 2.5737005328950797

Epoch: 5| Step: 8
Training loss: 2.950151510712158
Validation loss: 2.5762497526462074

Epoch: 5| Step: 9
Training loss: 2.30225070212622
Validation loss: 2.6266181829556627

Epoch: 5| Step: 10
Training loss: 3.105290169049679
Validation loss: 2.550974716138534

Epoch: 190| Step: 0
Training loss: 2.8617403846566525
Validation loss: 2.590038257548652

Epoch: 5| Step: 1
Training loss: 3.2182076006416422
Validation loss: 2.544376488778063

Epoch: 5| Step: 2
Training loss: 2.10500181891211
Validation loss: 2.596543663902563

Epoch: 5| Step: 3
Training loss: 2.713170256185611
Validation loss: 2.619512209672559

Epoch: 5| Step: 4
Training loss: 2.7494449055242374
Validation loss: 2.6086302567586697

Epoch: 5| Step: 5
Training loss: 2.39082963853003
Validation loss: 2.622671835217235

Epoch: 5| Step: 6
Training loss: 2.641031177589495
Validation loss: 2.5482496629300986

Epoch: 5| Step: 7
Training loss: 2.529405840437562
Validation loss: 2.591677562620948

Epoch: 5| Step: 8
Training loss: 2.2407716540833444
Validation loss: 2.604478993708795

Epoch: 5| Step: 9
Training loss: 2.031972668546557
Validation loss: 2.6549060874585355

Epoch: 5| Step: 10
Training loss: 3.048950740247385
Validation loss: 2.618208994494035

Epoch: 191| Step: 0
Training loss: 2.5499625184539516
Validation loss: 2.617067313522521

Epoch: 5| Step: 1
Training loss: 2.68295542581209
Validation loss: 2.5939090915700547

Epoch: 5| Step: 2
Training loss: 3.057820540287478
Validation loss: 2.5470197505496537

Epoch: 5| Step: 3
Training loss: 2.6423540943758272
Validation loss: 2.643129217970903

Epoch: 5| Step: 4
Training loss: 2.3262171768914746
Validation loss: 2.5999192585015605

Epoch: 5| Step: 5
Training loss: 2.69163957312523
Validation loss: 2.5605737698151576

Epoch: 5| Step: 6
Training loss: 2.3832003918719473
Validation loss: 2.5978578461984445

Epoch: 5| Step: 7
Training loss: 2.440177229713971
Validation loss: 2.5726189858169874

Epoch: 5| Step: 8
Training loss: 2.32055303181022
Validation loss: 2.556931981992786

Epoch: 5| Step: 9
Training loss: 2.7796875926334565
Validation loss: 2.5683161701604917

Epoch: 5| Step: 10
Training loss: 2.367751554762312
Validation loss: 2.5698429110953187

Epoch: 192| Step: 0
Training loss: 2.7254655702775015
Validation loss: 2.6139534655387813

Epoch: 5| Step: 1
Training loss: 2.657627870312962
Validation loss: 2.5602606365923677

Epoch: 5| Step: 2
Training loss: 2.407017771117628
Validation loss: 2.6183205133348033

Epoch: 5| Step: 3
Training loss: 3.164620357361304
Validation loss: 2.5875664271532517

Epoch: 5| Step: 4
Training loss: 2.3490291903368172
Validation loss: 2.6032163504621564

Epoch: 5| Step: 5
Training loss: 3.070337038209037
Validation loss: 2.5766194491589154

Epoch: 5| Step: 6
Training loss: 2.4958044132176833
Validation loss: 2.583154112096472

Epoch: 5| Step: 7
Training loss: 2.3249342386113176
Validation loss: 2.6124360485858493

Epoch: 5| Step: 8
Training loss: 2.0902050240811527
Validation loss: 2.588682631907606

Epoch: 5| Step: 9
Training loss: 2.9708820918622063
Validation loss: 2.6330383560289947

Epoch: 5| Step: 10
Training loss: 2.342254568492299
Validation loss: 2.5409948606634964

Epoch: 193| Step: 0
Training loss: 2.5386329639679364
Validation loss: 2.5730517875307544

Epoch: 5| Step: 1
Training loss: 2.3965916193785883
Validation loss: 2.606125521058402

Epoch: 5| Step: 2
Training loss: 2.3382974906380327
Validation loss: 2.6558142949535575

Epoch: 5| Step: 3
Training loss: 2.3220284535769995
Validation loss: 2.6003741479074622

Epoch: 5| Step: 4
Training loss: 2.3963017102603503
Validation loss: 2.610868069431372

Epoch: 5| Step: 5
Training loss: 2.4893597192508383
Validation loss: 2.6256842222007157

Epoch: 5| Step: 6
Training loss: 3.2636308193763437
Validation loss: 2.621935643300191

Epoch: 5| Step: 7
Training loss: 2.8057524378049705
Validation loss: 2.564960813829289

Epoch: 5| Step: 8
Training loss: 3.280199300479576
Validation loss: 2.5854752957831817

Epoch: 5| Step: 9
Training loss: 2.294425852312568
Validation loss: 2.581263415177527

Epoch: 5| Step: 10
Training loss: 2.1251742347644558
Validation loss: 2.5776428676728522

Epoch: 194| Step: 0
Training loss: 3.374755567953421
Validation loss: 2.6218029795289692

Epoch: 5| Step: 1
Training loss: 2.3674107814521728
Validation loss: 2.5567634273701683

Epoch: 5| Step: 2
Training loss: 2.9886897188151806
Validation loss: 2.577398449000586

Epoch: 5| Step: 3
Training loss: 3.0531743587381244
Validation loss: 2.566067117419634

Epoch: 5| Step: 4
Training loss: 2.319779048954451
Validation loss: 2.6055591337147037

Epoch: 5| Step: 5
Training loss: 2.1266928269183394
Validation loss: 2.5621150888465083

Epoch: 5| Step: 6
Training loss: 2.20370865253471
Validation loss: 2.585335281964694

Epoch: 5| Step: 7
Training loss: 2.5113256452378776
Validation loss: 2.5802773667640744

Epoch: 5| Step: 8
Training loss: 2.6905401023735864
Validation loss: 2.5801038161454004

Epoch: 5| Step: 9
Training loss: 1.9702380173087293
Validation loss: 2.5956391483338273

Epoch: 5| Step: 10
Training loss: 2.4804699995383173
Validation loss: 2.6191758482143213

Epoch: 195| Step: 0
Training loss: 2.5482409038293405
Validation loss: 2.592304851610674

Epoch: 5| Step: 1
Training loss: 2.9523682608675905
Validation loss: 2.5545976265549495

Epoch: 5| Step: 2
Training loss: 2.8273376717756404
Validation loss: 2.6025946809906424

Epoch: 5| Step: 3
Training loss: 2.350796191293858
Validation loss: 2.5588343383426646

Epoch: 5| Step: 4
Training loss: 2.5324023414151497
Validation loss: 2.588801229684856

Epoch: 5| Step: 5
Training loss: 3.0277242704401766
Validation loss: 2.5743422713494666

Epoch: 5| Step: 6
Training loss: 2.421070186651731
Validation loss: 2.599998472306376

Epoch: 5| Step: 7
Training loss: 2.720062991142163
Validation loss: 2.617352220190945

Epoch: 5| Step: 8
Training loss: 2.596425342763946
Validation loss: 2.603922833912479

Epoch: 5| Step: 9
Training loss: 2.1029329617526984
Validation loss: 2.6613199991813254

Epoch: 5| Step: 10
Training loss: 2.4700574672052444
Validation loss: 2.54541974592586

Epoch: 196| Step: 0
Training loss: 2.5908454350282626
Validation loss: 2.54366262716752

Epoch: 5| Step: 1
Training loss: 2.6717834456970277
Validation loss: 2.5998137089823907

Epoch: 5| Step: 2
Training loss: 2.7346955901627723
Validation loss: 2.5626891881943936

Epoch: 5| Step: 3
Training loss: 1.9974667479763561
Validation loss: 2.596136510182447

Epoch: 5| Step: 4
Training loss: 3.4282831258131035
Validation loss: 2.573779522716833

Epoch: 5| Step: 5
Training loss: 2.5359094379632863
Validation loss: 2.5408292902600773

Epoch: 5| Step: 6
Training loss: 2.8058451439072924
Validation loss: 2.560773474442052

Epoch: 5| Step: 7
Training loss: 2.450373959708892
Validation loss: 2.609075397290587

Epoch: 5| Step: 8
Training loss: 2.11928541682049
Validation loss: 2.5658343431723463

Epoch: 5| Step: 9
Training loss: 2.153918346306032
Validation loss: 2.5790980178746463

Epoch: 5| Step: 10
Training loss: 2.787882322769663
Validation loss: 2.5415175212779793

Epoch: 197| Step: 0
Training loss: 2.843090442003837
Validation loss: 2.5930797157079173

Epoch: 5| Step: 1
Training loss: 2.8819314080572895
Validation loss: 2.618485069241436

Epoch: 5| Step: 2
Training loss: 2.7320192488945914
Validation loss: 2.6023572566159254

Epoch: 5| Step: 3
Training loss: 2.2893378707286827
Validation loss: 2.625867676786452

Epoch: 5| Step: 4
Training loss: 3.1784476597478895
Validation loss: 2.5879121631756137

Epoch: 5| Step: 5
Training loss: 2.6065051349565165
Validation loss: 2.6279232177357197

Epoch: 5| Step: 6
Training loss: 2.186287462143637
Validation loss: 2.5744673900022006

Epoch: 5| Step: 7
Training loss: 2.08365531976312
Validation loss: 2.5865109701916427

Epoch: 5| Step: 8
Training loss: 2.7129495063692
Validation loss: 2.590608305429327

Epoch: 5| Step: 9
Training loss: 2.3136281535062055
Validation loss: 2.5858381095066623

Epoch: 5| Step: 10
Training loss: 2.306682279438403
Validation loss: 2.5781506300640697

Epoch: 198| Step: 0
Training loss: 2.4774166523514256
Validation loss: 2.573763803834911

Epoch: 5| Step: 1
Training loss: 2.9122385652618736
Validation loss: 2.6490897497340002

Epoch: 5| Step: 2
Training loss: 3.210334517021807
Validation loss: 2.61182047037402

Epoch: 5| Step: 3
Training loss: 2.611337072546844
Validation loss: 2.5423590693507947

Epoch: 5| Step: 4
Training loss: 2.5244915063072564
Validation loss: 2.547280150579606

Epoch: 5| Step: 5
Training loss: 2.624731413406559
Validation loss: 2.6152371589705683

Epoch: 5| Step: 6
Training loss: 2.58308931449277
Validation loss: 2.6224236294659753

Epoch: 5| Step: 7
Training loss: 2.570383923126673
Validation loss: 2.5565474659369167

Epoch: 5| Step: 8
Training loss: 2.9518953215484935
Validation loss: 2.606317603652241

Epoch: 5| Step: 9
Training loss: 1.7063709090434402
Validation loss: 2.5907167988601376

Epoch: 5| Step: 10
Training loss: 2.0066306350278142
Validation loss: 2.553778562538786

Epoch: 199| Step: 0
Training loss: 2.532045875043336
Validation loss: 2.582069975902136

Epoch: 5| Step: 1
Training loss: 2.5632131561098825
Validation loss: 2.581335829370766

Epoch: 5| Step: 2
Training loss: 2.687878959019517
Validation loss: 2.5524921917627936

Epoch: 5| Step: 3
Training loss: 2.068060920946915
Validation loss: 2.5841383505052438

Epoch: 5| Step: 4
Training loss: 2.174767413802723
Validation loss: 2.574012344363451

Epoch: 5| Step: 5
Training loss: 2.7676734019525298
Validation loss: 2.545706477817099

Epoch: 5| Step: 6
Training loss: 3.2914240461982547
Validation loss: 2.590999798311214

Epoch: 5| Step: 7
Training loss: 2.3545568924837275
Validation loss: 2.565766485340228

Epoch: 5| Step: 8
Training loss: 2.9352872915209933
Validation loss: 2.605675288812696

Epoch: 5| Step: 9
Training loss: 2.4872607858929903
Validation loss: 2.568586900111663

Epoch: 5| Step: 10
Training loss: 2.730561654580041
Validation loss: 2.6138123873917083

Epoch: 200| Step: 0
Training loss: 2.504866441223304
Validation loss: 2.591676041753271

Epoch: 5| Step: 1
Training loss: 3.013017703323695
Validation loss: 2.551087731008585

Epoch: 5| Step: 2
Training loss: 2.677178278524548
Validation loss: 2.557969252526157

Epoch: 5| Step: 3
Training loss: 2.229677076522533
Validation loss: 2.570399423308817

Epoch: 5| Step: 4
Training loss: 2.604396616637983
Validation loss: 2.564337006171536

Epoch: 5| Step: 5
Training loss: 3.2698335678722965
Validation loss: 2.5572408787183347

Epoch: 5| Step: 6
Training loss: 2.3773378610929776
Validation loss: 2.6128956132069194

Epoch: 5| Step: 7
Training loss: 2.180109892358922
Validation loss: 2.5858068668333094

Epoch: 5| Step: 8
Training loss: 2.4524985321382724
Validation loss: 2.5738825591496686

Epoch: 5| Step: 9
Training loss: 2.113857677205346
Validation loss: 2.554707865041004

Epoch: 5| Step: 10
Training loss: 2.947881008691879
Validation loss: 2.5595247076870575

Epoch: 201| Step: 0
Training loss: 2.6414937954565683
Validation loss: 2.579029633285087

Epoch: 5| Step: 1
Training loss: 2.177419596960312
Validation loss: 2.5484509469490573

Epoch: 5| Step: 2
Training loss: 2.9402517862261814
Validation loss: 2.5568064985508636

Epoch: 5| Step: 3
Training loss: 2.956943041998863
Validation loss: 2.5663585060608183

Epoch: 5| Step: 4
Training loss: 2.6042266126726736
Validation loss: 2.5910065116576173

Epoch: 5| Step: 5
Training loss: 1.8107755942457542
Validation loss: 2.6069795409148795

Epoch: 5| Step: 6
Training loss: 3.0098175895903427
Validation loss: 2.575939690418811

Epoch: 5| Step: 7
Training loss: 1.9382675865395957
Validation loss: 2.5689651344478577

Epoch: 5| Step: 8
Training loss: 2.402428701495943
Validation loss: 2.574780255618677

Epoch: 5| Step: 9
Training loss: 2.8513614949490234
Validation loss: 2.571042420473308

Epoch: 5| Step: 10
Training loss: 3.092527668242471
Validation loss: 2.56209847490621

Epoch: 202| Step: 0
Training loss: 2.4537965863586457
Validation loss: 2.574086002805662

Epoch: 5| Step: 1
Training loss: 3.14294696964357
Validation loss: 2.5765011961053337

Epoch: 5| Step: 2
Training loss: 1.7936746375438446
Validation loss: 2.587333166502307

Epoch: 5| Step: 3
Training loss: 2.8732090222875177
Validation loss: 2.5945738714382385

Epoch: 5| Step: 4
Training loss: 2.0930081092177986
Validation loss: 2.596681005513691

Epoch: 5| Step: 5
Training loss: 3.010764993933244
Validation loss: 2.5953884749010863

Epoch: 5| Step: 6
Training loss: 2.326503726788177
Validation loss: 2.6003517862227166

Epoch: 5| Step: 7
Training loss: 2.6262529198667988
Validation loss: 2.622022456765914

Epoch: 5| Step: 8
Training loss: 3.201465455907443
Validation loss: 2.6158585689918357

Epoch: 5| Step: 9
Training loss: 1.9853250226875268
Validation loss: 2.6094212750531764

Epoch: 5| Step: 10
Training loss: 2.27707080285015
Validation loss: 2.5944902243704857

Epoch: 203| Step: 0
Training loss: 2.5902003622432264
Validation loss: 2.625738627930823

Epoch: 5| Step: 1
Training loss: 2.568222912546306
Validation loss: 2.6279339369324077

Epoch: 5| Step: 2
Training loss: 2.6021047032875786
Validation loss: 2.5533237023842505

Epoch: 5| Step: 3
Training loss: 3.6474143968750985
Validation loss: 2.6002273412454766

Epoch: 5| Step: 4
Training loss: 2.3159299621335823
Validation loss: 2.568049915426086

Epoch: 5| Step: 5
Training loss: 2.158783129607393
Validation loss: 2.5844437921359145

Epoch: 5| Step: 6
Training loss: 2.308021332442207
Validation loss: 2.568847902250336

Epoch: 5| Step: 7
Training loss: 2.7931055849074453
Validation loss: 2.5595175241438066

Epoch: 5| Step: 8
Training loss: 2.3464057625966106
Validation loss: 2.5549069715775947

Epoch: 5| Step: 9
Training loss: 2.409069638624562
Validation loss: 2.5860274818180287

Epoch: 5| Step: 10
Training loss: 2.331603657996135
Validation loss: 2.6518320055122637

Epoch: 204| Step: 0
Training loss: 1.9672121975100574
Validation loss: 2.565813797670807

Epoch: 5| Step: 1
Training loss: 2.633662689311556
Validation loss: 2.59696835601729

Epoch: 5| Step: 2
Training loss: 2.526856270757723
Validation loss: 2.556105843502919

Epoch: 5| Step: 3
Training loss: 2.338088050352504
Validation loss: 2.5872922800388225

Epoch: 5| Step: 4
Training loss: 2.5293332601750667
Validation loss: 2.5186091120702354

Epoch: 5| Step: 5
Training loss: 2.6176159863792927
Validation loss: 2.6086603878083805

Epoch: 5| Step: 6
Training loss: 2.1456214898978283
Validation loss: 2.581312461557538

Epoch: 5| Step: 7
Training loss: 3.0176580819706227
Validation loss: 2.5293076543831283

Epoch: 5| Step: 8
Training loss: 2.7565855587517154
Validation loss: 2.578094758682657

Epoch: 5| Step: 9
Training loss: 2.1322127955810717
Validation loss: 2.5631018791397464

Epoch: 5| Step: 10
Training loss: 3.526175574836045
Validation loss: 2.5755337428102014

Epoch: 205| Step: 0
Training loss: 2.2461964990085357
Validation loss: 2.5938481157754345

Epoch: 5| Step: 1
Training loss: 2.532749344204844
Validation loss: 2.6189218807395

Epoch: 5| Step: 2
Training loss: 2.1940320173307657
Validation loss: 2.605700708887213

Epoch: 5| Step: 3
Training loss: 2.943395015751369
Validation loss: 2.5314399752266254

Epoch: 5| Step: 4
Training loss: 3.010099576906157
Validation loss: 2.548374494826754

Epoch: 5| Step: 5
Training loss: 2.522128778520132
Validation loss: 2.6004170103876185

Epoch: 5| Step: 6
Training loss: 2.7047575502453323
Validation loss: 2.622674819498494

Epoch: 5| Step: 7
Training loss: 2.6088403393868997
Validation loss: 2.56567828795908

Epoch: 5| Step: 8
Training loss: 2.1677877264654306
Validation loss: 2.5248757959579895

Epoch: 5| Step: 9
Training loss: 2.7504193246365594
Validation loss: 2.543338775996117

Epoch: 5| Step: 10
Training loss: 2.3441640869553146
Validation loss: 2.510309237400645

Epoch: 206| Step: 0
Training loss: 2.8858803239992126
Validation loss: 2.597791405134117

Epoch: 5| Step: 1
Training loss: 2.9367497886241325
Validation loss: 2.5634251676955615

Epoch: 5| Step: 2
Training loss: 2.8914150498675535
Validation loss: 2.603707815948676

Epoch: 5| Step: 3
Training loss: 1.8468353835244469
Validation loss: 2.5856663350736304

Epoch: 5| Step: 4
Training loss: 3.24991050010104
Validation loss: 2.560101802258877

Epoch: 5| Step: 5
Training loss: 2.114330771511081
Validation loss: 2.529885348938371

Epoch: 5| Step: 6
Training loss: 2.21063144034714
Validation loss: 2.609876771484499

Epoch: 5| Step: 7
Training loss: 2.5480027773496143
Validation loss: 2.58094970546238

Epoch: 5| Step: 8
Training loss: 2.778432211608625
Validation loss: 2.574196808441538

Epoch: 5| Step: 9
Training loss: 2.303413892663037
Validation loss: 2.6151186435053666

Epoch: 5| Step: 10
Training loss: 2.1550101433535165
Validation loss: 2.5638288138439296

Epoch: 207| Step: 0
Training loss: 2.1277659870990777
Validation loss: 2.5686895639773017

Epoch: 5| Step: 1
Training loss: 2.229234985540568
Validation loss: 2.588101099440218

Epoch: 5| Step: 2
Training loss: 2.5281264259136313
Validation loss: 2.5601120503848414

Epoch: 5| Step: 3
Training loss: 2.8626206951432973
Validation loss: 2.551642238192199

Epoch: 5| Step: 4
Training loss: 2.1592854681375866
Validation loss: 2.51780601348398

Epoch: 5| Step: 5
Training loss: 2.5663390825792454
Validation loss: 2.558482650878504

Epoch: 5| Step: 6
Training loss: 2.445823152987746
Validation loss: 2.583811325392529

Epoch: 5| Step: 7
Training loss: 2.7196364437493172
Validation loss: 2.6084344367476127

Epoch: 5| Step: 8
Training loss: 2.673105413879321
Validation loss: 2.5586539938906867

Epoch: 5| Step: 9
Training loss: 2.738796125865373
Validation loss: 2.5945676336960934

Epoch: 5| Step: 10
Training loss: 3.3298029005584375
Validation loss: 2.5816631983472607

Epoch: 208| Step: 0
Training loss: 2.455986929047933
Validation loss: 2.5584387762283005

Epoch: 5| Step: 1
Training loss: 2.361870765651956
Validation loss: 2.6155447929874316

Epoch: 5| Step: 2
Training loss: 3.0821627551356707
Validation loss: 2.597702126873138

Epoch: 5| Step: 3
Training loss: 2.253000589816799
Validation loss: 2.5715937593530005

Epoch: 5| Step: 4
Training loss: 2.3358534986006827
Validation loss: 2.6131644185829024

Epoch: 5| Step: 5
Training loss: 3.4060944687918555
Validation loss: 2.553773180830235

Epoch: 5| Step: 6
Training loss: 2.919955515587985
Validation loss: 2.6573688175211094

Epoch: 5| Step: 7
Training loss: 1.9790463728904952
Validation loss: 2.574650130739382

Epoch: 5| Step: 8
Training loss: 2.0284673557602573
Validation loss: 2.523088732893718

Epoch: 5| Step: 9
Training loss: 2.081708757857127
Validation loss: 2.572396102706704

Epoch: 5| Step: 10
Training loss: 2.8864070326560847
Validation loss: 2.5806745504749027

Epoch: 209| Step: 0
Training loss: 2.7258647036712857
Validation loss: 2.61546873965553

Epoch: 5| Step: 1
Training loss: 2.9349318295933813
Validation loss: 2.5495113556086038

Epoch: 5| Step: 2
Training loss: 2.4345562104735983
Validation loss: 2.6054754152418886

Epoch: 5| Step: 3
Training loss: 2.435407669751268
Validation loss: 2.5759988588755944

Epoch: 5| Step: 4
Training loss: 2.501376250062885
Validation loss: 2.527574281578441

Epoch: 5| Step: 5
Training loss: 2.145716160905297
Validation loss: 2.5858542893611256

Epoch: 5| Step: 6
Training loss: 2.6020216894572585
Validation loss: 2.589299987162806

Epoch: 5| Step: 7
Training loss: 3.4845034998989606
Validation loss: 2.5454442962982973

Epoch: 5| Step: 8
Training loss: 2.058679568041926
Validation loss: 2.506796474788454

Epoch: 5| Step: 9
Training loss: 2.866164521291538
Validation loss: 2.5574654945993127

Epoch: 5| Step: 10
Training loss: 1.8992411478370326
Validation loss: 2.563859378418204

Epoch: 210| Step: 0
Training loss: 2.6500126028660924
Validation loss: 2.553231609116525

Epoch: 5| Step: 1
Training loss: 2.3678634232493456
Validation loss: 2.570536587020737

Epoch: 5| Step: 2
Training loss: 2.6238992290394942
Validation loss: 2.5756926148565777

Epoch: 5| Step: 3
Training loss: 3.1153008050323105
Validation loss: 2.6139385090248055

Epoch: 5| Step: 4
Training loss: 2.3333282697713496
Validation loss: 2.5513061180421515

Epoch: 5| Step: 5
Training loss: 2.4260228231792103
Validation loss: 2.5402904570808187

Epoch: 5| Step: 6
Training loss: 2.0382306386177085
Validation loss: 2.5745175556520516

Epoch: 5| Step: 7
Training loss: 2.74688770000486
Validation loss: 2.5486153879958975

Epoch: 5| Step: 8
Training loss: 2.496271500205953
Validation loss: 2.514167853298124

Epoch: 5| Step: 9
Training loss: 2.501597752224431
Validation loss: 2.560413681804576

Epoch: 5| Step: 10
Training loss: 2.742573594085641
Validation loss: 2.5770490810828393

Epoch: 211| Step: 0
Training loss: 2.4893656572975416
Validation loss: 2.555418589978721

Epoch: 5| Step: 1
Training loss: 2.9440063494530913
Validation loss: 2.6064105555945996

Epoch: 5| Step: 2
Training loss: 2.0632143806388257
Validation loss: 2.549650655563499

Epoch: 5| Step: 3
Training loss: 2.2760273971517675
Validation loss: 2.546628524255399

Epoch: 5| Step: 4
Training loss: 2.644003067349546
Validation loss: 2.544391745376405

Epoch: 5| Step: 5
Training loss: 2.3866039691802214
Validation loss: 2.5611536624512037

Epoch: 5| Step: 6
Training loss: 2.7407659339987904
Validation loss: 2.5839955205305483

Epoch: 5| Step: 7
Training loss: 2.3621083777658822
Validation loss: 2.555403060124715

Epoch: 5| Step: 8
Training loss: 3.0138531949868788
Validation loss: 2.589000220981797

Epoch: 5| Step: 9
Training loss: 2.4583681287296577
Validation loss: 2.565696365526792

Epoch: 5| Step: 10
Training loss: 2.66239299648698
Validation loss: 2.572591364403557

Epoch: 212| Step: 0
Training loss: 2.4284026744457705
Validation loss: 2.5891320089451906

Epoch: 5| Step: 1
Training loss: 2.662549705220501
Validation loss: 2.5689923118582576

Epoch: 5| Step: 2
Training loss: 3.077432932242978
Validation loss: 2.5568416058994248

Epoch: 5| Step: 3
Training loss: 2.7181057221410354
Validation loss: 2.582726009906335

Epoch: 5| Step: 4
Training loss: 3.1145078379859594
Validation loss: 2.588299921707558

Epoch: 5| Step: 5
Training loss: 2.67882842148036
Validation loss: 2.5387320859618776

Epoch: 5| Step: 6
Training loss: 2.1262564590957016
Validation loss: 2.562362292031323

Epoch: 5| Step: 7
Training loss: 2.2591922332581538
Validation loss: 2.5459518012593834

Epoch: 5| Step: 8
Training loss: 2.441167175794354
Validation loss: 2.559056058434194

Epoch: 5| Step: 9
Training loss: 1.8569787235879678
Validation loss: 2.5700487259011213

Epoch: 5| Step: 10
Training loss: 2.980015791524739
Validation loss: 2.5355990087194002

Epoch: 213| Step: 0
Training loss: 2.7005505954104216
Validation loss: 2.5832297740692236

Epoch: 5| Step: 1
Training loss: 2.699725532709822
Validation loss: 2.5491752230072646

Epoch: 5| Step: 2
Training loss: 2.0317896199541474
Validation loss: 2.633577368308813

Epoch: 5| Step: 3
Training loss: 2.546771369183121
Validation loss: 2.534258415015176

Epoch: 5| Step: 4
Training loss: 2.920686204572243
Validation loss: 2.5594742812313873

Epoch: 5| Step: 5
Training loss: 2.6107165148921037
Validation loss: 2.554135547971572

Epoch: 5| Step: 6
Training loss: 2.3296704379300595
Validation loss: 2.5929884095785374

Epoch: 5| Step: 7
Training loss: 2.8663194054220344
Validation loss: 2.5474999367763442

Epoch: 5| Step: 8
Training loss: 2.14510194727355
Validation loss: 2.5245418181208192

Epoch: 5| Step: 9
Training loss: 2.871968370980707
Validation loss: 2.5963350528322824

Epoch: 5| Step: 10
Training loss: 2.0242372795384664
Validation loss: 2.5482527197802622

Epoch: 214| Step: 0
Training loss: 2.95301552221428
Validation loss: 2.584775117125129

Epoch: 5| Step: 1
Training loss: 2.7808064310633807
Validation loss: 2.5790047445660402

Epoch: 5| Step: 2
Training loss: 2.6625397656833627
Validation loss: 2.5353303120793482

Epoch: 5| Step: 3
Training loss: 1.9170715346702556
Validation loss: 2.508638484311716

Epoch: 5| Step: 4
Training loss: 2.4831495801629386
Validation loss: 2.5809474904168646

Epoch: 5| Step: 5
Training loss: 2.834112920284207
Validation loss: 2.5686337343223697

Epoch: 5| Step: 6
Training loss: 2.574779119554889
Validation loss: 2.539964079085705

Epoch: 5| Step: 7
Training loss: 2.62506775541509
Validation loss: 2.5755951521875367

Epoch: 5| Step: 8
Training loss: 2.0192249884889457
Validation loss: 2.546362670285266

Epoch: 5| Step: 9
Training loss: 2.8139007471037036
Validation loss: 2.561319209702529

Epoch: 5| Step: 10
Training loss: 2.101244593970194
Validation loss: 2.547958760474805

Epoch: 215| Step: 0
Training loss: 3.1479635710201945
Validation loss: 2.554240265087513

Epoch: 5| Step: 1
Training loss: 1.9058380307149552
Validation loss: 2.5488185033890463

Epoch: 5| Step: 2
Training loss: 2.7754480945239686
Validation loss: 2.5087632439572762

Epoch: 5| Step: 3
Training loss: 2.2159519013579874
Validation loss: 2.6036363543274965

Epoch: 5| Step: 4
Training loss: 3.008355426090797
Validation loss: 2.5747581217001967

Epoch: 5| Step: 5
Training loss: 1.9453330900642256
Validation loss: 2.5626354546890844

Epoch: 5| Step: 6
Training loss: 2.6959575378798206
Validation loss: 2.562960617561331

Epoch: 5| Step: 7
Training loss: 2.995244707863675
Validation loss: 2.5635748079051957

Epoch: 5| Step: 8
Training loss: 2.5487303733350637
Validation loss: 2.5400993831183696

Epoch: 5| Step: 9
Training loss: 1.9891612086109998
Validation loss: 2.5800896153010138

Epoch: 5| Step: 10
Training loss: 2.191018136482615
Validation loss: 2.5738574294215253

Epoch: 216| Step: 0
Training loss: 2.3356469015064856
Validation loss: 2.5122231776396475

Epoch: 5| Step: 1
Training loss: 2.147392990057376
Validation loss: 2.609906082679505

Epoch: 5| Step: 2
Training loss: 3.1410094068617718
Validation loss: 2.5965373124128472

Epoch: 5| Step: 3
Training loss: 2.552581478989194
Validation loss: 2.5396436133883213

Epoch: 5| Step: 4
Training loss: 2.5890137966550157
Validation loss: 2.555788793556879

Epoch: 5| Step: 5
Training loss: 1.9025829877561378
Validation loss: 2.582981219262281

Epoch: 5| Step: 6
Training loss: 2.720522686300562
Validation loss: 2.5539821516420913

Epoch: 5| Step: 7
Training loss: 2.5494038015778817
Validation loss: 2.5381994908999697

Epoch: 5| Step: 8
Training loss: 3.0930845527524906
Validation loss: 2.526828798424098

Epoch: 5| Step: 9
Training loss: 2.374043924736775
Validation loss: 2.548934004577289

Epoch: 5| Step: 10
Training loss: 2.231475228874952
Validation loss: 2.5596545188124367

Epoch: 217| Step: 0
Training loss: 2.052723108727111
Validation loss: 2.583621360991738

Epoch: 5| Step: 1
Training loss: 2.531034766571472
Validation loss: 2.6030043799533695

Epoch: 5| Step: 2
Training loss: 2.347582519185898
Validation loss: 2.559500809206629

Epoch: 5| Step: 3
Training loss: 2.564913752632077
Validation loss: 2.511491787234684

Epoch: 5| Step: 4
Training loss: 2.1144740886061286
Validation loss: 2.56417923717225

Epoch: 5| Step: 5
Training loss: 2.9380635471729613
Validation loss: 2.5117769419110343

Epoch: 5| Step: 6
Training loss: 2.253059532283149
Validation loss: 2.6156676780776835

Epoch: 5| Step: 7
Training loss: 2.6629047283186926
Validation loss: 2.5355390456295694

Epoch: 5| Step: 8
Training loss: 2.8967171470653703
Validation loss: 2.5633105004936274

Epoch: 5| Step: 9
Training loss: 2.3264743150301217
Validation loss: 2.56894327575362

Epoch: 5| Step: 10
Training loss: 3.050762493940424
Validation loss: 2.5566882295420243

Epoch: 218| Step: 0
Training loss: 1.702171828896575
Validation loss: 2.56064464712542

Epoch: 5| Step: 1
Training loss: 2.98516435819242
Validation loss: 2.548196541964793

Epoch: 5| Step: 2
Training loss: 2.228234342698322
Validation loss: 2.562051787896479

Epoch: 5| Step: 3
Training loss: 2.8318073052620902
Validation loss: 2.5696972932563207

Epoch: 5| Step: 4
Training loss: 2.758595817346914
Validation loss: 2.5005736390199984

Epoch: 5| Step: 5
Training loss: 2.0352496164178855
Validation loss: 2.5688985937845255

Epoch: 5| Step: 6
Training loss: 3.293750023163247
Validation loss: 2.5632504980645803

Epoch: 5| Step: 7
Training loss: 2.303972036225109
Validation loss: 2.5714126029497835

Epoch: 5| Step: 8
Training loss: 2.6386650983270217
Validation loss: 2.5568023073746264

Epoch: 5| Step: 9
Training loss: 2.6054030471593013
Validation loss: 2.5773816670064646

Epoch: 5| Step: 10
Training loss: 2.0172839767349933
Validation loss: 2.512510496119745

Epoch: 219| Step: 0
Training loss: 2.1870480751785246
Validation loss: 2.5850023408382787

Epoch: 5| Step: 1
Training loss: 2.5275130767936766
Validation loss: 2.5495091967091104

Epoch: 5| Step: 2
Training loss: 2.474728263040432
Validation loss: 2.625582740194564

Epoch: 5| Step: 3
Training loss: 2.3612166536964283
Validation loss: 2.5591038354289437

Epoch: 5| Step: 4
Training loss: 2.76241508456944
Validation loss: 2.555046184560572

Epoch: 5| Step: 5
Training loss: 2.9230761991337797
Validation loss: 2.581265983521132

Epoch: 5| Step: 6
Training loss: 2.900683085791479
Validation loss: 2.580637360312351

Epoch: 5| Step: 7
Training loss: 2.2893053778732053
Validation loss: 2.5601799299153165

Epoch: 5| Step: 8
Training loss: 2.5563327729271013
Validation loss: 2.5692330559938923

Epoch: 5| Step: 9
Training loss: 2.4760592457734774
Validation loss: 2.5357769615274757

Epoch: 5| Step: 10
Training loss: 2.5602423794564726
Validation loss: 2.6245272338133865

Epoch: 220| Step: 0
Training loss: 2.3038349191017695
Validation loss: 2.5684666852345654

Epoch: 5| Step: 1
Training loss: 3.023378987694871
Validation loss: 2.5525945503437093

Epoch: 5| Step: 2
Training loss: 2.0429659491496097
Validation loss: 2.6143542839282827

Epoch: 5| Step: 3
Training loss: 2.1381572226087
Validation loss: 2.55275022839462

Epoch: 5| Step: 4
Training loss: 2.1096819618953657
Validation loss: 2.533895751833118

Epoch: 5| Step: 5
Training loss: 2.7377242148909993
Validation loss: 2.553989508347832

Epoch: 5| Step: 6
Training loss: 2.0225198793318397
Validation loss: 2.594995305715461

Epoch: 5| Step: 7
Training loss: 2.807896895034526
Validation loss: 2.5624003837425264

Epoch: 5| Step: 8
Training loss: 2.5541071334629923
Validation loss: 2.577625476601366

Epoch: 5| Step: 9
Training loss: 3.041876972888364
Validation loss: 2.562378479051777

Epoch: 5| Step: 10
Training loss: 2.883544167397481
Validation loss: 2.5278280983122117

Epoch: 221| Step: 0
Training loss: 2.472658949815864
Validation loss: 2.5428945889304386

Epoch: 5| Step: 1
Training loss: 2.773464149024698
Validation loss: 2.567493588405746

Epoch: 5| Step: 2
Training loss: 2.674294786990965
Validation loss: 2.541085220257435

Epoch: 5| Step: 3
Training loss: 2.432930404363846
Validation loss: 2.6046633404683273

Epoch: 5| Step: 4
Training loss: 2.5113288731053967
Validation loss: 2.53740589555952

Epoch: 5| Step: 5
Training loss: 2.194887493439288
Validation loss: 2.588606832208957

Epoch: 5| Step: 6
Training loss: 2.2841742598268135
Validation loss: 2.5762797573940155

Epoch: 5| Step: 7
Training loss: 2.984912923696157
Validation loss: 2.5442955271237455

Epoch: 5| Step: 8
Training loss: 2.484967910743625
Validation loss: 2.5412319510245336

Epoch: 5| Step: 9
Training loss: 1.9171732012053058
Validation loss: 2.5194563267944803

Epoch: 5| Step: 10
Training loss: 3.247349318370295
Validation loss: 2.5801150251390106

Epoch: 222| Step: 0
Training loss: 2.2295460838590597
Validation loss: 2.5186604330327866

Epoch: 5| Step: 1
Training loss: 2.7820179768357898
Validation loss: 2.5314583610967913

Epoch: 5| Step: 2
Training loss: 2.2139796164107572
Validation loss: 2.5298306040312815

Epoch: 5| Step: 3
Training loss: 2.7813039195802585
Validation loss: 2.5433231471815216

Epoch: 5| Step: 4
Training loss: 2.4478936268689404
Validation loss: 2.5877179708561866

Epoch: 5| Step: 5
Training loss: 2.6725506736868567
Validation loss: 2.5285801887492885

Epoch: 5| Step: 6
Training loss: 2.496578163578194
Validation loss: 2.5666608786654193

Epoch: 5| Step: 7
Training loss: 2.7395822696659553
Validation loss: 2.499317100530066

Epoch: 5| Step: 8
Training loss: 2.8850438029700958
Validation loss: 2.5720663277593934

Epoch: 5| Step: 9
Training loss: 1.9514031717027351
Validation loss: 2.541811555807275

Epoch: 5| Step: 10
Training loss: 2.5522441787376833
Validation loss: 2.536965487360825

Epoch: 223| Step: 0
Training loss: 1.900295776634861
Validation loss: 2.550773067945233

Epoch: 5| Step: 1
Training loss: 2.916651825640023
Validation loss: 2.512460535194878

Epoch: 5| Step: 2
Training loss: 2.5248924761247182
Validation loss: 2.571423136992994

Epoch: 5| Step: 3
Training loss: 2.5997629901258077
Validation loss: 2.581412069003047

Epoch: 5| Step: 4
Training loss: 2.3887231779164644
Validation loss: 2.552882212669513

Epoch: 5| Step: 5
Training loss: 2.9092160747976146
Validation loss: 2.553675937697048

Epoch: 5| Step: 6
Training loss: 2.921812169016548
Validation loss: 2.5527051715963127

Epoch: 5| Step: 7
Training loss: 2.4129410888967695
Validation loss: 2.587385863944003

Epoch: 5| Step: 8
Training loss: 2.2737485273040816
Validation loss: 2.5170402604326623

Epoch: 5| Step: 9
Training loss: 2.3825205139365773
Validation loss: 2.5309986479393194

Epoch: 5| Step: 10
Training loss: 2.136832337088854
Validation loss: 2.5629021023720915

Epoch: 224| Step: 0
Training loss: 2.5613787919630258
Validation loss: 2.567431803519114

Epoch: 5| Step: 1
Training loss: 2.442407411911305
Validation loss: 2.5032513118845694

Epoch: 5| Step: 2
Training loss: 2.4711338557348497
Validation loss: 2.5961289026023695

Epoch: 5| Step: 3
Training loss: 3.2645993607027615
Validation loss: 2.5542144784030794

Epoch: 5| Step: 4
Training loss: 2.152550218375161
Validation loss: 2.559472042592239

Epoch: 5| Step: 5
Training loss: 2.941649083705437
Validation loss: 2.550959345150572

Epoch: 5| Step: 6
Training loss: 2.466109976798191
Validation loss: 2.5024072081447355

Epoch: 5| Step: 7
Training loss: 2.111644061338148
Validation loss: 2.556432015906213

Epoch: 5| Step: 8
Training loss: 2.185954610718079
Validation loss: 2.5068522366007935

Epoch: 5| Step: 9
Training loss: 2.8767487556293716
Validation loss: 2.554900627456959

Epoch: 5| Step: 10
Training loss: 1.9522805181172833
Validation loss: 2.571434466574494

Epoch: 225| Step: 0
Training loss: 2.6593760327921028
Validation loss: 2.5331483865183224

Epoch: 5| Step: 1
Training loss: 2.7277131808682746
Validation loss: 2.5302454065079187

Epoch: 5| Step: 2
Training loss: 2.4848868364629517
Validation loss: 2.5682640876189073

Epoch: 5| Step: 3
Training loss: 2.599564435127618
Validation loss: 2.5807678081352616

Epoch: 5| Step: 4
Training loss: 2.4418829612709554
Validation loss: 2.544037609918991

Epoch: 5| Step: 5
Training loss: 2.446054754247911
Validation loss: 2.5274165831617794

Epoch: 5| Step: 6
Training loss: 2.3087209805253575
Validation loss: 2.6142120741614527

Epoch: 5| Step: 7
Training loss: 2.1303214592652227
Validation loss: 2.5164801671987767

Epoch: 5| Step: 8
Training loss: 2.894106690934732
Validation loss: 2.540949750286643

Epoch: 5| Step: 9
Training loss: 2.2752752577713995
Validation loss: 2.5460622872193523

Epoch: 5| Step: 10
Training loss: 2.3412824738669453
Validation loss: 2.597099220419959

Epoch: 226| Step: 0
Training loss: 2.7104694061269705
Validation loss: 2.5529045372583608

Epoch: 5| Step: 1
Training loss: 2.7556524273378473
Validation loss: 2.5653951803487858

Epoch: 5| Step: 2
Training loss: 2.400992061298406
Validation loss: 2.566707373467943

Epoch: 5| Step: 3
Training loss: 1.732210475405202
Validation loss: 2.5721016225162603

Epoch: 5| Step: 4
Training loss: 2.9016759830729186
Validation loss: 2.5258210153795937

Epoch: 5| Step: 5
Training loss: 2.950724276840276
Validation loss: 2.532250610058688

Epoch: 5| Step: 6
Training loss: 2.662056802746896
Validation loss: 2.5299782737896024

Epoch: 5| Step: 7
Training loss: 2.118901421191427
Validation loss: 2.5289209473298047

Epoch: 5| Step: 8
Training loss: 2.4501759485397145
Validation loss: 2.547929054590818

Epoch: 5| Step: 9
Training loss: 2.654464839872739
Validation loss: 2.520688478814379

Epoch: 5| Step: 10
Training loss: 2.472903849422037
Validation loss: 2.5502368987065878

Epoch: 227| Step: 0
Training loss: 3.320704825167192
Validation loss: 2.4886622380064676

Epoch: 5| Step: 1
Training loss: 2.483239832233707
Validation loss: 2.5482177053717656

Epoch: 5| Step: 2
Training loss: 2.520798948279391
Validation loss: 2.5648232689699193

Epoch: 5| Step: 3
Training loss: 2.2027709892951917
Validation loss: 2.5082209522845726

Epoch: 5| Step: 4
Training loss: 2.370870714837097
Validation loss: 2.5425173887198094

Epoch: 5| Step: 5
Training loss: 2.3808976280637992
Validation loss: 2.55489225289257

Epoch: 5| Step: 6
Training loss: 2.5111470617498415
Validation loss: 2.5518483683895035

Epoch: 5| Step: 7
Training loss: 2.0845836574999734
Validation loss: 2.500259695613489

Epoch: 5| Step: 8
Training loss: 2.4012599578285565
Validation loss: 2.5464892432141837

Epoch: 5| Step: 9
Training loss: 2.649616890331005
Validation loss: 2.5650019862964015

Epoch: 5| Step: 10
Training loss: 2.5517419288278136
Validation loss: 2.5335726585025187

Epoch: 228| Step: 0
Training loss: 2.7556002553865775
Validation loss: 2.5637507053874113

Epoch: 5| Step: 1
Training loss: 2.5555131143924954
Validation loss: 2.5493209953874962

Epoch: 5| Step: 2
Training loss: 2.7280574514934033
Validation loss: 2.548215385413787

Epoch: 5| Step: 3
Training loss: 2.306423038100854
Validation loss: 2.5814814808926574

Epoch: 5| Step: 4
Training loss: 2.2693700946575195
Validation loss: 2.527564242322389

Epoch: 5| Step: 5
Training loss: 2.134512758068096
Validation loss: 2.524069626099023

Epoch: 5| Step: 6
Training loss: 2.666869175692041
Validation loss: 2.5556090868580092

Epoch: 5| Step: 7
Training loss: 1.9291696201024473
Validation loss: 2.5375533376523727

Epoch: 5| Step: 8
Training loss: 2.9320987798332627
Validation loss: 2.5175653718241118

Epoch: 5| Step: 9
Training loss: 2.43977572504759
Validation loss: 2.570057770277793

Epoch: 5| Step: 10
Training loss: 2.634153483027053
Validation loss: 2.580436374950168

Epoch: 229| Step: 0
Training loss: 2.57067729367174
Validation loss: 2.5215910804332204

Epoch: 5| Step: 1
Training loss: 2.234085704508471
Validation loss: 2.573185820988705

Epoch: 5| Step: 2
Training loss: 2.5864201121297836
Validation loss: 2.4771059308983867

Epoch: 5| Step: 3
Training loss: 2.2694581326969776
Validation loss: 2.534116713034046

Epoch: 5| Step: 4
Training loss: 2.2822083850768404
Validation loss: 2.5775824390132045

Epoch: 5| Step: 5
Training loss: 3.0143336560227607
Validation loss: 2.6043431963410804

Epoch: 5| Step: 6
Training loss: 2.954076543024215
Validation loss: 2.558514572906128

Epoch: 5| Step: 7
Training loss: 2.6329278665956273
Validation loss: 2.531799670958325

Epoch: 5| Step: 8
Training loss: 2.023988508810059
Validation loss: 2.54624399370323

Epoch: 5| Step: 9
Training loss: 2.4370767274783236
Validation loss: 2.5149926066069264

Epoch: 5| Step: 10
Training loss: 2.1346082568297473
Validation loss: 2.5591269762761852

Epoch: 230| Step: 0
Training loss: 2.3494955211271176
Validation loss: 2.519159905846967

Epoch: 5| Step: 1
Training loss: 2.404618639142834
Validation loss: 2.573048561371987

Epoch: 5| Step: 2
Training loss: 2.724742380266134
Validation loss: 2.5688302739962365

Epoch: 5| Step: 3
Training loss: 2.2427333473078037
Validation loss: 2.545944094069045

Epoch: 5| Step: 4
Training loss: 3.0554398100537554
Validation loss: 2.512815565375573

Epoch: 5| Step: 5
Training loss: 1.9264233120451906
Validation loss: 2.501894411537073

Epoch: 5| Step: 6
Training loss: 2.2131265647471126
Validation loss: 2.584884763860002

Epoch: 5| Step: 7
Training loss: 2.8477426523671916
Validation loss: 2.5596992920378097

Epoch: 5| Step: 8
Training loss: 2.4946694765583133
Validation loss: 2.520211603216192

Epoch: 5| Step: 9
Training loss: 3.0279083709862125
Validation loss: 2.569168560874658

Epoch: 5| Step: 10
Training loss: 1.7282180098877333
Validation loss: 2.484624958317583

Epoch: 231| Step: 0
Training loss: 3.247727406492849
Validation loss: 2.5253887469788765

Epoch: 5| Step: 1
Training loss: 1.9477506012600438
Validation loss: 2.5541775639077424

Epoch: 5| Step: 2
Training loss: 3.2717567808696453
Validation loss: 2.4756825438689685

Epoch: 5| Step: 3
Training loss: 2.766663695720625
Validation loss: 2.5898373603015035

Epoch: 5| Step: 4
Training loss: 2.1182550082769382
Validation loss: 2.4996561583053007

Epoch: 5| Step: 5
Training loss: 2.3171295014709288
Validation loss: 2.5510038559409915

Epoch: 5| Step: 6
Training loss: 2.527104692193257
Validation loss: 2.5216013915381286

Epoch: 5| Step: 7
Training loss: 1.9014739568402903
Validation loss: 2.5321571864482406

Epoch: 5| Step: 8
Training loss: 3.0785673956359405
Validation loss: 2.505250362275386

Epoch: 5| Step: 9
Training loss: 1.720982159820777
Validation loss: 2.510077259061272

Epoch: 5| Step: 10
Training loss: 2.155560811791233
Validation loss: 2.5397389873647285

Epoch: 232| Step: 0
Training loss: 2.844705609743039
Validation loss: 2.507989179441683

Epoch: 5| Step: 1
Training loss: 2.7757832667533746
Validation loss: 2.487157289791893

Epoch: 5| Step: 2
Training loss: 2.1110031061262573
Validation loss: 2.5433769328823326

Epoch: 5| Step: 3
Training loss: 2.0120503272707206
Validation loss: 2.5357629613239636

Epoch: 5| Step: 4
Training loss: 2.5231734099243104
Validation loss: 2.5452922485773097

Epoch: 5| Step: 5
Training loss: 2.2192753989092053
Validation loss: 2.5481450683565217

Epoch: 5| Step: 6
Training loss: 2.09656961096119
Validation loss: 2.5751496389500437

Epoch: 5| Step: 7
Training loss: 2.7462099140281935
Validation loss: 2.5468672845309506

Epoch: 5| Step: 8
Training loss: 2.6945372420211444
Validation loss: 2.5570232722599777

Epoch: 5| Step: 9
Training loss: 2.3901799604266407
Validation loss: 2.5269751781411927

Epoch: 5| Step: 10
Training loss: 2.7788247667859833
Validation loss: 2.545590586470227

Epoch: 233| Step: 0
Training loss: 2.302124356786068
Validation loss: 2.5532341193073025

Epoch: 5| Step: 1
Training loss: 3.1455210010686723
Validation loss: 2.5838598064855303

Epoch: 5| Step: 2
Training loss: 2.55424266990438
Validation loss: 2.577544169846134

Epoch: 5| Step: 3
Training loss: 2.8498345979578836
Validation loss: 2.591705764044579

Epoch: 5| Step: 4
Training loss: 2.8104634010797214
Validation loss: 2.5296424947910787

Epoch: 5| Step: 5
Training loss: 1.782551808400176
Validation loss: 2.5371319030450166

Epoch: 5| Step: 6
Training loss: 2.3771756897842695
Validation loss: 2.5086562820961342

Epoch: 5| Step: 7
Training loss: 2.6670542276402682
Validation loss: 2.527333912701346

Epoch: 5| Step: 8
Training loss: 2.4864162480394154
Validation loss: 2.5177171613820764

Epoch: 5| Step: 9
Training loss: 2.3508557242871317
Validation loss: 2.514619842886018

Epoch: 5| Step: 10
Training loss: 2.3236575691345296
Validation loss: 2.5432993414042997

Epoch: 234| Step: 0
Training loss: 2.935500093190109
Validation loss: 2.5530788945082077

Epoch: 5| Step: 1
Training loss: 1.7530887457214954
Validation loss: 2.5524282634622213

Epoch: 5| Step: 2
Training loss: 2.4724936770829835
Validation loss: 2.5093603378380607

Epoch: 5| Step: 3
Training loss: 2.3927164341400973
Validation loss: 2.5051305030219813

Epoch: 5| Step: 4
Training loss: 2.7347744023313383
Validation loss: 2.5270100263064594

Epoch: 5| Step: 5
Training loss: 1.9581438202840842
Validation loss: 2.47698751404822

Epoch: 5| Step: 6
Training loss: 3.2784171818798207
Validation loss: 2.5576669619652916

Epoch: 5| Step: 7
Training loss: 2.769686717416661
Validation loss: 2.521612710118153

Epoch: 5| Step: 8
Training loss: 1.9864618937142573
Validation loss: 2.501253654595917

Epoch: 5| Step: 9
Training loss: 2.637060434313634
Validation loss: 2.4995961191176486

Epoch: 5| Step: 10
Training loss: 1.9643015179679546
Validation loss: 2.5594284553469158

Epoch: 235| Step: 0
Training loss: 2.7516007532843227
Validation loss: 2.5573071302496064

Epoch: 5| Step: 1
Training loss: 2.5895356099975833
Validation loss: 2.5517267382784294

Epoch: 5| Step: 2
Training loss: 1.7618049549741135
Validation loss: 2.5668195408346426

Epoch: 5| Step: 3
Training loss: 2.5772946031873523
Validation loss: 2.519336249451103

Epoch: 5| Step: 4
Training loss: 2.9572352310032453
Validation loss: 2.601157862541585

Epoch: 5| Step: 5
Training loss: 2.567983110954625
Validation loss: 2.6170463052521344

Epoch: 5| Step: 6
Training loss: 3.0648254596243203
Validation loss: 2.5305877988120398

Epoch: 5| Step: 7
Training loss: 2.2372040877917527
Validation loss: 2.549318006691899

Epoch: 5| Step: 8
Training loss: 2.559736855512733
Validation loss: 2.5301828326264664

Epoch: 5| Step: 9
Training loss: 2.3387248782384193
Validation loss: 2.6034054227228953

Epoch: 5| Step: 10
Training loss: 2.2269255760374476
Validation loss: 2.551570851091074

Epoch: 236| Step: 0
Training loss: 2.7106117250672894
Validation loss: 2.5677472750824974

Epoch: 5| Step: 1
Training loss: 2.7748094201156674
Validation loss: 2.519971159229398

Epoch: 5| Step: 2
Training loss: 2.1754906287336673
Validation loss: 2.585193905456211

Epoch: 5| Step: 3
Training loss: 2.0328715967476954
Validation loss: 2.5498379739305026

Epoch: 5| Step: 4
Training loss: 2.7799979831496135
Validation loss: 2.5400866562189357

Epoch: 5| Step: 5
Training loss: 2.54461635298538
Validation loss: 2.5262119710685114

Epoch: 5| Step: 6
Training loss: 3.05305534915875
Validation loss: 2.554213400439327

Epoch: 5| Step: 7
Training loss: 2.214721245716496
Validation loss: 2.552238908302975

Epoch: 5| Step: 8
Training loss: 2.2966009482553438
Validation loss: 2.5563651680673596

Epoch: 5| Step: 9
Training loss: 2.018769288339972
Validation loss: 2.5383484306266495

Epoch: 5| Step: 10
Training loss: 2.2441828020745542
Validation loss: 2.540371031200654

Epoch: 237| Step: 0
Training loss: 2.895820196840052
Validation loss: 2.582960219105375

Epoch: 5| Step: 1
Training loss: 2.446771253625054
Validation loss: 2.5076097967384308

Epoch: 5| Step: 2
Training loss: 2.860782797863678
Validation loss: 2.541098623143632

Epoch: 5| Step: 3
Training loss: 2.502540060936447
Validation loss: 2.5050131300237273

Epoch: 5| Step: 4
Training loss: 2.516897128670744
Validation loss: 2.543393794102487

Epoch: 5| Step: 5
Training loss: 2.3666264338051026
Validation loss: 2.5561050165723556

Epoch: 5| Step: 6
Training loss: 2.2285617352194502
Validation loss: 2.5062004568699057

Epoch: 5| Step: 7
Training loss: 2.5413633280195183
Validation loss: 2.535218697083483

Epoch: 5| Step: 8
Training loss: 2.5640795421789484
Validation loss: 2.5079929574518633

Epoch: 5| Step: 9
Training loss: 2.4427412365701637
Validation loss: 2.5321778470933607

Epoch: 5| Step: 10
Training loss: 1.6645439776692506
Validation loss: 2.547875534024904

Epoch: 238| Step: 0
Training loss: 2.519985897236675
Validation loss: 2.536010841349982

Epoch: 5| Step: 1
Training loss: 2.782192113521812
Validation loss: 2.556215316417219

Epoch: 5| Step: 2
Training loss: 1.489766258620901
Validation loss: 2.572815374504754

Epoch: 5| Step: 3
Training loss: 3.373626712159062
Validation loss: 2.5082791354019913

Epoch: 5| Step: 4
Training loss: 2.289981696542946
Validation loss: 2.507967729721891

Epoch: 5| Step: 5
Training loss: 2.511415644224472
Validation loss: 2.5017305158094287

Epoch: 5| Step: 6
Training loss: 2.8146993726579685
Validation loss: 2.5181437485084177

Epoch: 5| Step: 7
Training loss: 2.65005506782176
Validation loss: 2.5572173208011737

Epoch: 5| Step: 8
Training loss: 2.341831999221837
Validation loss: 2.5189881917518635

Epoch: 5| Step: 9
Training loss: 2.572210474950973
Validation loss: 2.5631720579274577

Epoch: 5| Step: 10
Training loss: 1.755854758319153
Validation loss: 2.4712919754741707

Epoch: 239| Step: 0
Training loss: 2.325829212436103
Validation loss: 2.553134874524672

Epoch: 5| Step: 1
Training loss: 2.4541988087887874
Validation loss: 2.493314051430446

Epoch: 5| Step: 2
Training loss: 1.9154046160579081
Validation loss: 2.489714724879761

Epoch: 5| Step: 3
Training loss: 3.6734483310632275
Validation loss: 2.5655340935136337

Epoch: 5| Step: 4
Training loss: 2.5020178280994894
Validation loss: 2.5363094092983713

Epoch: 5| Step: 5
Training loss: 2.7748229099163217
Validation loss: 2.515188491259801

Epoch: 5| Step: 6
Training loss: 2.0738484829815773
Validation loss: 2.5311546565990377

Epoch: 5| Step: 7
Training loss: 1.752556160150773
Validation loss: 2.5575105266743137

Epoch: 5| Step: 8
Training loss: 2.6146559584866993
Validation loss: 2.4974920819361173

Epoch: 5| Step: 9
Training loss: 2.441655748970004
Validation loss: 2.5364717559516574

Epoch: 5| Step: 10
Training loss: 2.273969974624908
Validation loss: 2.4757752613127

Epoch: 240| Step: 0
Training loss: 2.6453024163817243
Validation loss: 2.492623255224276

Epoch: 5| Step: 1
Training loss: 2.3029051014491495
Validation loss: 2.4928951230278695

Epoch: 5| Step: 2
Training loss: 2.5466445163276132
Validation loss: 2.553226488319686

Epoch: 5| Step: 3
Training loss: 2.166217708534071
Validation loss: 2.5975522389584764

Epoch: 5| Step: 4
Training loss: 2.179648778427902
Validation loss: 2.5435685301589075

Epoch: 5| Step: 5
Training loss: 3.304945771065331
Validation loss: 2.5813116630616486

Epoch: 5| Step: 6
Training loss: 2.4295079204762304
Validation loss: 2.5333000944619952

Epoch: 5| Step: 7
Training loss: 2.6481335670921426
Validation loss: 2.5207991028626693

Epoch: 5| Step: 8
Training loss: 2.0887442575372352
Validation loss: 2.6461585900028655

Epoch: 5| Step: 9
Training loss: 2.7045355848361057
Validation loss: 2.615378272007776

Epoch: 5| Step: 10
Training loss: 2.2353902790921363
Validation loss: 2.546118649061168

Epoch: 241| Step: 0
Training loss: 2.4349117720519162
Validation loss: 2.543409217868224

Epoch: 5| Step: 1
Training loss: 2.0888621654334205
Validation loss: 2.5516057260473892

Epoch: 5| Step: 2
Training loss: 2.2788317678976204
Validation loss: 2.5605410729916636

Epoch: 5| Step: 3
Training loss: 2.6996229120355864
Validation loss: 2.5095521744419615

Epoch: 5| Step: 4
Training loss: 2.303685374520369
Validation loss: 2.5014620269323773

Epoch: 5| Step: 5
Training loss: 2.8980660007666845
Validation loss: 2.540826137706631

Epoch: 5| Step: 6
Training loss: 2.9473250012139416
Validation loss: 2.515623622194052

Epoch: 5| Step: 7
Training loss: 2.2545063667740455
Validation loss: 2.5057519955524388

Epoch: 5| Step: 8
Training loss: 2.5510369679439
Validation loss: 2.559962991887924

Epoch: 5| Step: 9
Training loss: 2.8429899772067517
Validation loss: 2.4705153872260763

Epoch: 5| Step: 10
Training loss: 2.061816131038175
Validation loss: 2.5205354127205006

Epoch: 242| Step: 0
Training loss: 2.247564481122123
Validation loss: 2.5680893752542975

Epoch: 5| Step: 1
Training loss: 2.332424827092107
Validation loss: 2.55384891822477

Epoch: 5| Step: 2
Training loss: 2.6402801649669345
Validation loss: 2.5406721143866124

Epoch: 5| Step: 3
Training loss: 2.5491641002225185
Validation loss: 2.4577762423739493

Epoch: 5| Step: 4
Training loss: 2.495855520040474
Validation loss: 2.547657862211687

Epoch: 5| Step: 5
Training loss: 2.4820523711096243
Validation loss: 2.5033774357663345

Epoch: 5| Step: 6
Training loss: 2.1283627997588805
Validation loss: 2.5454138661288876

Epoch: 5| Step: 7
Training loss: 2.857423710643207
Validation loss: 2.5181886764501575

Epoch: 5| Step: 8
Training loss: 2.7892379919239665
Validation loss: 2.500043074944324

Epoch: 5| Step: 9
Training loss: 1.8069458409834298
Validation loss: 2.5716409455341345

Epoch: 5| Step: 10
Training loss: 2.314839494220428
Validation loss: 2.5035636605671296

Epoch: 243| Step: 0
Training loss: 2.5534863929423337
Validation loss: 2.5432530254907206

Epoch: 5| Step: 1
Training loss: 2.20598897713668
Validation loss: 2.450996378850706

Epoch: 5| Step: 2
Training loss: 2.7206592213962604
Validation loss: 2.560431360997101

Epoch: 5| Step: 3
Training loss: 2.176107549940648
Validation loss: 2.512163103564804

Epoch: 5| Step: 4
Training loss: 1.9976290716262608
Validation loss: 2.579937341804734

Epoch: 5| Step: 5
Training loss: 2.8126862358316065
Validation loss: 2.5553254084357047

Epoch: 5| Step: 6
Training loss: 2.336814894208029
Validation loss: 2.510958915325234

Epoch: 5| Step: 7
Training loss: 2.621826615188324
Validation loss: 2.503374378907285

Epoch: 5| Step: 8
Training loss: 2.5340673520983423
Validation loss: 2.567177244328479

Epoch: 5| Step: 9
Training loss: 2.7936850316218904
Validation loss: 2.5709171849962993

Epoch: 5| Step: 10
Training loss: 2.127107360684212
Validation loss: 2.525926877910683

Epoch: 244| Step: 0
Training loss: 2.4256027573723333
Validation loss: 2.5184680575015546

Epoch: 5| Step: 1
Training loss: 1.7800596844385792
Validation loss: 2.53697239977645

Epoch: 5| Step: 2
Training loss: 2.4967852904588352
Validation loss: 2.5250904507692873

Epoch: 5| Step: 3
Training loss: 2.441724393333631
Validation loss: 2.5139177598301776

Epoch: 5| Step: 4
Training loss: 2.89485279927878
Validation loss: 2.5356870178708735

Epoch: 5| Step: 5
Training loss: 2.328327656572649
Validation loss: 2.5465186759575875

Epoch: 5| Step: 6
Training loss: 2.8219815965967534
Validation loss: 2.5309364846814666

Epoch: 5| Step: 7
Training loss: 2.2501459074395256
Validation loss: 2.556565746450899

Epoch: 5| Step: 8
Training loss: 2.6637859480610304
Validation loss: 2.5244282332897896

Epoch: 5| Step: 9
Training loss: 2.0217509070967865
Validation loss: 2.601162418858773

Epoch: 5| Step: 10
Training loss: 3.1926824289653553
Validation loss: 2.484489558493741

Epoch: 245| Step: 0
Training loss: 2.0176289377525647
Validation loss: 2.545185585956942

Epoch: 5| Step: 1
Training loss: 2.213794816445022
Validation loss: 2.5175833855134893

Epoch: 5| Step: 2
Training loss: 2.3006181383846713
Validation loss: 2.505216247540635

Epoch: 5| Step: 3
Training loss: 2.815579402778769
Validation loss: 2.483043194755051

Epoch: 5| Step: 4
Training loss: 2.6034071971982846
Validation loss: 2.4833893459164407

Epoch: 5| Step: 5
Training loss: 2.224945980659262
Validation loss: 2.5461021391660754

Epoch: 5| Step: 6
Training loss: 2.7993069949175697
Validation loss: 2.516260591503648

Epoch: 5| Step: 7
Training loss: 2.7289376393284
Validation loss: 2.5206664140382347

Epoch: 5| Step: 8
Training loss: 2.5435489396999387
Validation loss: 2.5496933381301634

Epoch: 5| Step: 9
Training loss: 2.408687892364531
Validation loss: 2.5441171226848627

Epoch: 5| Step: 10
Training loss: 1.9041440618774566
Validation loss: 2.5330389201754375

Epoch: 246| Step: 0
Training loss: 2.695382822197437
Validation loss: 2.496223670867081

Epoch: 5| Step: 1
Training loss: 2.4837515186598904
Validation loss: 2.4888973000529453

Epoch: 5| Step: 2
Training loss: 2.5588563274734435
Validation loss: 2.5121100859301757

Epoch: 5| Step: 3
Training loss: 2.14061196873172
Validation loss: 2.557595015309049

Epoch: 5| Step: 4
Training loss: 1.8889576519186944
Validation loss: 2.4844306923563955

Epoch: 5| Step: 5
Training loss: 2.5388351573401216
Validation loss: 2.571047913108997

Epoch: 5| Step: 6
Training loss: 2.152825995558136
Validation loss: 2.5429086305223882

Epoch: 5| Step: 7
Training loss: 2.3160829366681037
Validation loss: 2.4872911812985823

Epoch: 5| Step: 8
Training loss: 3.3670910602397996
Validation loss: 2.537153925670283

Epoch: 5| Step: 9
Training loss: 2.3137058516401385
Validation loss: 2.500372355428981

Epoch: 5| Step: 10
Training loss: 2.3241801795644155
Validation loss: 2.4881251568176803

Epoch: 247| Step: 0
Training loss: 2.057213220831014
Validation loss: 2.5639009145376463

Epoch: 5| Step: 1
Training loss: 2.5359292754711538
Validation loss: 2.535749417003835

Epoch: 5| Step: 2
Training loss: 2.1522508106139324
Validation loss: 2.5271075062971544

Epoch: 5| Step: 3
Training loss: 3.1404792410205884
Validation loss: 2.5277538261990173

Epoch: 5| Step: 4
Training loss: 2.3786618963815274
Validation loss: 2.5249182094419185

Epoch: 5| Step: 5
Training loss: 2.286612178924406
Validation loss: 2.454424488106185

Epoch: 5| Step: 6
Training loss: 2.1892860750417205
Validation loss: 2.4777550701605024

Epoch: 5| Step: 7
Training loss: 2.5787620913230866
Validation loss: 2.4748302175053234

Epoch: 5| Step: 8
Training loss: 2.75376478332347
Validation loss: 2.507624770970994

Epoch: 5| Step: 9
Training loss: 2.627991379687427
Validation loss: 2.4770605403562467

Epoch: 5| Step: 10
Training loss: 2.11753037269905
Validation loss: 2.575313598639427

Epoch: 248| Step: 0
Training loss: 2.656011862458315
Validation loss: 2.512626842941056

Epoch: 5| Step: 1
Training loss: 2.566629014007368
Validation loss: 2.532401111427293

Epoch: 5| Step: 2
Training loss: 2.4841335347229143
Validation loss: 2.5691789933580824

Epoch: 5| Step: 3
Training loss: 2.1286318540911355
Validation loss: 2.524036857084305

Epoch: 5| Step: 4
Training loss: 2.315956007636821
Validation loss: 2.5749871960616417

Epoch: 5| Step: 5
Training loss: 2.9233032652447846
Validation loss: 2.5238296212762497

Epoch: 5| Step: 6
Training loss: 2.0725895864821235
Validation loss: 2.4532460849762523

Epoch: 5| Step: 7
Training loss: 2.9224492289079094
Validation loss: 2.529953035266228

Epoch: 5| Step: 8
Training loss: 2.6697244299078378
Validation loss: 2.5257865527444965

Epoch: 5| Step: 9
Training loss: 2.5799302687573538
Validation loss: 2.546758416921942

Epoch: 5| Step: 10
Training loss: 1.4653339837228745
Validation loss: 2.4656321733069038

Epoch: 249| Step: 0
Training loss: 2.1232400225502945
Validation loss: 2.524744911511675

Epoch: 5| Step: 1
Training loss: 2.8184008261526445
Validation loss: 2.484947544670906

Epoch: 5| Step: 2
Training loss: 2.427302327461024
Validation loss: 2.513988848641589

Epoch: 5| Step: 3
Training loss: 3.3562454195186677
Validation loss: 2.491235998415329

Epoch: 5| Step: 4
Training loss: 1.6552295060080986
Validation loss: 2.5391071920823722

Epoch: 5| Step: 5
Training loss: 2.5361068659627684
Validation loss: 2.5497179348286876

Epoch: 5| Step: 6
Training loss: 1.9976518078196295
Validation loss: 2.4667374182811295

Epoch: 5| Step: 7
Training loss: 2.653254896023736
Validation loss: 2.4990031357079094

Epoch: 5| Step: 8
Training loss: 2.280837139237499
Validation loss: 2.5759290245660065

Epoch: 5| Step: 9
Training loss: 2.4484980007893378
Validation loss: 2.5094062280671414

Epoch: 5| Step: 10
Training loss: 2.2313066234937042
Validation loss: 2.496994866269726

Epoch: 250| Step: 0
Training loss: 2.5303423160672773
Validation loss: 2.5090884864800755

Epoch: 5| Step: 1
Training loss: 1.769564259875951
Validation loss: 2.5461387151303274

Epoch: 5| Step: 2
Training loss: 2.5894060642479317
Validation loss: 2.548662955342174

Epoch: 5| Step: 3
Training loss: 2.718645466515894
Validation loss: 2.5596198366517386

Epoch: 5| Step: 4
Training loss: 2.677618801925564
Validation loss: 2.5452132016068103

Epoch: 5| Step: 5
Training loss: 2.3631276987176926
Validation loss: 2.4960831876819474

Epoch: 5| Step: 6
Training loss: 2.851557985067059
Validation loss: 2.539590398718779

Epoch: 5| Step: 7
Training loss: 2.567457845874833
Validation loss: 2.4881345494737763

Epoch: 5| Step: 8
Training loss: 1.9674161600865243
Validation loss: 2.514090642124873

Epoch: 5| Step: 9
Training loss: 2.6723258547163367
Validation loss: 2.517137706906217

Epoch: 5| Step: 10
Training loss: 2.060639322385572
Validation loss: 2.522167521575912

Epoch: 251| Step: 0
Training loss: 2.866697513798782
Validation loss: 2.504577832310872

Epoch: 5| Step: 1
Training loss: 2.6063466115924645
Validation loss: 2.522363780020693

Epoch: 5| Step: 2
Training loss: 1.8037749786656534
Validation loss: 2.4890433015927473

Epoch: 5| Step: 3
Training loss: 2.4452456139140137
Validation loss: 2.4961551859810585

Epoch: 5| Step: 4
Training loss: 2.1784614204666157
Validation loss: 2.5230098123058555

Epoch: 5| Step: 5
Training loss: 2.9672648680424776
Validation loss: 2.5274500893832483

Epoch: 5| Step: 6
Training loss: 2.2008031419471603
Validation loss: 2.44460998107807

Epoch: 5| Step: 7
Training loss: 2.34364654312678
Validation loss: 2.5095297594252055

Epoch: 5| Step: 8
Training loss: 2.7233862972206424
Validation loss: 2.512162939775942

Epoch: 5| Step: 9
Training loss: 3.0675004889776187
Validation loss: 2.4764387320364314

Epoch: 5| Step: 10
Training loss: 1.5542489971754678
Validation loss: 2.498432535570872

Epoch: 252| Step: 0
Training loss: 2.6437962016223735
Validation loss: 2.5151590231508085

Epoch: 5| Step: 1
Training loss: 2.78905540486777
Validation loss: 2.5328395617180957

Epoch: 5| Step: 2
Training loss: 2.8419584562632974
Validation loss: 2.521330205211134

Epoch: 5| Step: 3
Training loss: 2.348974077012673
Validation loss: 2.4760641058015054

Epoch: 5| Step: 4
Training loss: 2.4495569996381628
Validation loss: 2.501560270860792

Epoch: 5| Step: 5
Training loss: 1.9385593348590822
Validation loss: 2.449722927147998

Epoch: 5| Step: 6
Training loss: 2.497813508420006
Validation loss: 2.526400484396131

Epoch: 5| Step: 7
Training loss: 1.6458852091794416
Validation loss: 2.505783634791387

Epoch: 5| Step: 8
Training loss: 2.226188976344649
Validation loss: 2.516931833212513

Epoch: 5| Step: 9
Training loss: 2.463312365537749
Validation loss: 2.498817766255152

Epoch: 5| Step: 10
Training loss: 2.864978739874284
Validation loss: 2.484941155543337

Epoch: 253| Step: 0
Training loss: 2.7438047155950764
Validation loss: 2.5173575676221356

Epoch: 5| Step: 1
Training loss: 2.6778599148293227
Validation loss: 2.5014993314456238

Epoch: 5| Step: 2
Training loss: 1.9375513746772108
Validation loss: 2.506415621761906

Epoch: 5| Step: 3
Training loss: 1.9233917206089306
Validation loss: 2.5427750356680683

Epoch: 5| Step: 4
Training loss: 2.1511541772810228
Validation loss: 2.5331579320360835

Epoch: 5| Step: 5
Training loss: 2.863589989643102
Validation loss: 2.498214131498142

Epoch: 5| Step: 6
Training loss: 2.557789730094177
Validation loss: 2.4709507883691875

Epoch: 5| Step: 7
Training loss: 2.1249203386521756
Validation loss: 2.511793354901248

Epoch: 5| Step: 8
Training loss: 3.0127410538970842
Validation loss: 2.5003555127109487

Epoch: 5| Step: 9
Training loss: 2.425495026390876
Validation loss: 2.4778022513629523

Epoch: 5| Step: 10
Training loss: 1.6222696107245462
Validation loss: 2.5586909645372145

Epoch: 254| Step: 0
Training loss: 2.8350822062742744
Validation loss: 2.457175237707129

Epoch: 5| Step: 1
Training loss: 2.5065452725187383
Validation loss: 2.5708204836462856

Epoch: 5| Step: 2
Training loss: 2.239676634744993
Validation loss: 2.521797717423504

Epoch: 5| Step: 3
Training loss: 2.908056374581927
Validation loss: 2.552617690946329

Epoch: 5| Step: 4
Training loss: 2.2341226288513907
Validation loss: 2.4401228208375265

Epoch: 5| Step: 5
Training loss: 2.4710074618021167
Validation loss: 2.496243755973551

Epoch: 5| Step: 6
Training loss: 2.341022786664646
Validation loss: 2.540985644234121

Epoch: 5| Step: 7
Training loss: 2.2140895629176454
Validation loss: 2.5162433834137787

Epoch: 5| Step: 8
Training loss: 2.710987981056917
Validation loss: 2.543167095685173

Epoch: 5| Step: 9
Training loss: 2.5370970645691044
Validation loss: 2.4815446660433205

Epoch: 5| Step: 10
Training loss: 1.800047354605095
Validation loss: 2.475293828643326

Epoch: 255| Step: 0
Training loss: 3.0232348312543746
Validation loss: 2.4676330685688166

Epoch: 5| Step: 1
Training loss: 2.103244718003836
Validation loss: 2.4723428491522714

Epoch: 5| Step: 2
Training loss: 2.031669103961554
Validation loss: 2.508760865032823

Epoch: 5| Step: 3
Training loss: 2.5398709462639113
Validation loss: 2.5137235828328652

Epoch: 5| Step: 4
Training loss: 2.2080606136225964
Validation loss: 2.493935415582571

Epoch: 5| Step: 5
Training loss: 2.259507542860319
Validation loss: 2.5558968502323585

Epoch: 5| Step: 6
Training loss: 2.613696967617228
Validation loss: 2.5314920082605594

Epoch: 5| Step: 7
Training loss: 3.0155214282023852
Validation loss: 2.5901193858922866

Epoch: 5| Step: 8
Training loss: 1.9748702815468078
Validation loss: 2.537562041709027

Epoch: 5| Step: 9
Training loss: 2.3610023797623865
Validation loss: 2.5294914238883544

Epoch: 5| Step: 10
Training loss: 2.613143940099448
Validation loss: 2.4956527773115638

Epoch: 256| Step: 0
Training loss: 2.722067288987388
Validation loss: 2.4932837849729443

Epoch: 5| Step: 1
Training loss: 3.1021995370661504
Validation loss: 2.4687493634382127

Epoch: 5| Step: 2
Training loss: 2.1308181996480067
Validation loss: 2.521275068642019

Epoch: 5| Step: 3
Training loss: 2.49887918143137
Validation loss: 2.510637327665914

Epoch: 5| Step: 4
Training loss: 1.961649001935161
Validation loss: 2.5468162727643797

Epoch: 5| Step: 5
Training loss: 1.6400447000831635
Validation loss: 2.5352748378766665

Epoch: 5| Step: 6
Training loss: 2.517697730230801
Validation loss: 2.4532905963209997

Epoch: 5| Step: 7
Training loss: 2.4614047136788098
Validation loss: 2.454714990627195

Epoch: 5| Step: 8
Training loss: 2.3651049426548725
Validation loss: 2.5185190291395494

Epoch: 5| Step: 9
Training loss: 2.4030000612002524
Validation loss: 2.521129460248397

Epoch: 5| Step: 10
Training loss: 2.860561937466745
Validation loss: 2.555146086529381

Epoch: 257| Step: 0
Training loss: 1.9317436846480152
Validation loss: 2.5553469482099667

Epoch: 5| Step: 1
Training loss: 2.449130748767927
Validation loss: 2.4932116358898995

Epoch: 5| Step: 2
Training loss: 2.060529634665732
Validation loss: 2.529978541302213

Epoch: 5| Step: 3
Training loss: 3.0799274879441
Validation loss: 2.4238347556026385

Epoch: 5| Step: 4
Training loss: 2.7464565509530994
Validation loss: 2.440755345228594

Epoch: 5| Step: 5
Training loss: 2.1259379841182797
Validation loss: 2.5057235889560006

Epoch: 5| Step: 6
Training loss: 2.376744884186529
Validation loss: 2.4840732529748393

Epoch: 5| Step: 7
Training loss: 1.9544821334767826
Validation loss: 2.485724603370647

Epoch: 5| Step: 8
Training loss: 2.7687138264447957
Validation loss: 2.498713333496224

Epoch: 5| Step: 9
Training loss: 2.6365198130970904
Validation loss: 2.5478444617577742

Epoch: 5| Step: 10
Training loss: 3.0923429429825795
Validation loss: 2.5264712787976515

Epoch: 258| Step: 0
Training loss: 2.101856196986092
Validation loss: 2.559669147516368

Epoch: 5| Step: 1
Training loss: 3.2047994563402695
Validation loss: 2.5225386780661347

Epoch: 5| Step: 2
Training loss: 2.3340867279466417
Validation loss: 2.487826712363785

Epoch: 5| Step: 3
Training loss: 2.08734677603304
Validation loss: 2.519168996560273

Epoch: 5| Step: 4
Training loss: 2.0993808923646005
Validation loss: 2.429022240097516

Epoch: 5| Step: 5
Training loss: 2.289057604683599
Validation loss: 2.5466575124548476

Epoch: 5| Step: 6
Training loss: 2.650804120546094
Validation loss: 2.535674464459305

Epoch: 5| Step: 7
Training loss: 2.8245681398842843
Validation loss: 2.468736629052673

Epoch: 5| Step: 8
Training loss: 2.6397022689202054
Validation loss: 2.5326227374963004

Epoch: 5| Step: 9
Training loss: 1.6583618519437855
Validation loss: 2.522183844588318

Epoch: 5| Step: 10
Training loss: 2.41678295732643
Validation loss: 2.5128510700217137

Epoch: 259| Step: 0
Training loss: 1.7544321745717986
Validation loss: 2.5371707595371076

Epoch: 5| Step: 1
Training loss: 2.447352719108154
Validation loss: 2.5140639368263193

Epoch: 5| Step: 2
Training loss: 2.156254533403579
Validation loss: 2.5653403143117592

Epoch: 5| Step: 3
Training loss: 2.5512664940920917
Validation loss: 2.5323206668995435

Epoch: 5| Step: 4
Training loss: 2.7008559565629944
Validation loss: 2.481192924008574

Epoch: 5| Step: 5
Training loss: 2.4689716287916466
Validation loss: 2.4894860938107417

Epoch: 5| Step: 6
Training loss: 2.594664355053841
Validation loss: 2.525465440164954

Epoch: 5| Step: 7
Training loss: 2.576557399543447
Validation loss: 2.474789154147121

Epoch: 5| Step: 8
Training loss: 3.0146606168263044
Validation loss: 2.5325111949992167

Epoch: 5| Step: 9
Training loss: 2.4979686113375283
Validation loss: 2.5118714031677936

Epoch: 5| Step: 10
Training loss: 1.8669163973968905
Validation loss: 2.453000144061943

Epoch: 260| Step: 0
Training loss: 2.277341970243462
Validation loss: 2.47420053916653

Epoch: 5| Step: 1
Training loss: 2.818958496367398
Validation loss: 2.503914887238355

Epoch: 5| Step: 2
Training loss: 1.7623794568551543
Validation loss: 2.504872141911315

Epoch: 5| Step: 3
Training loss: 2.5826172502753244
Validation loss: 2.4934882275673447

Epoch: 5| Step: 4
Training loss: 2.494225413196393
Validation loss: 2.5207458056477945

Epoch: 5| Step: 5
Training loss: 2.675219489388908
Validation loss: 2.5032139064871535

Epoch: 5| Step: 6
Training loss: 2.830428897451811
Validation loss: 2.523724598212097

Epoch: 5| Step: 7
Training loss: 2.318657692771043
Validation loss: 2.540110874616081

Epoch: 5| Step: 8
Training loss: 2.276711011243421
Validation loss: 2.489860377834439

Epoch: 5| Step: 9
Training loss: 2.47930688755339
Validation loss: 2.4845097523903057

Epoch: 5| Step: 10
Training loss: 2.1325466563229147
Validation loss: 2.5076482503917172

Epoch: 261| Step: 0
Training loss: 1.795563061313448
Validation loss: 2.4937172334401536

Epoch: 5| Step: 1
Training loss: 2.325177265915898
Validation loss: 2.4553845942368633

Epoch: 5| Step: 2
Training loss: 3.0244441759176492
Validation loss: 2.5468866169459035

Epoch: 5| Step: 3
Training loss: 2.5113046639978753
Validation loss: 2.504369116280416

Epoch: 5| Step: 4
Training loss: 2.6954104198415463
Validation loss: 2.518586482471071

Epoch: 5| Step: 5
Training loss: 2.3366740924900418
Validation loss: 2.473771684446035

Epoch: 5| Step: 6
Training loss: 2.4265885292126064
Validation loss: 2.496370958922117

Epoch: 5| Step: 7
Training loss: 2.850309917263504
Validation loss: 2.505670598257415

Epoch: 5| Step: 8
Training loss: 2.142994481181534
Validation loss: 2.4654175580418154

Epoch: 5| Step: 9
Training loss: 2.1651126227918396
Validation loss: 2.486495938305776

Epoch: 5| Step: 10
Training loss: 2.236044306839844
Validation loss: 2.4952770319938846

Epoch: 262| Step: 0
Training loss: 2.0720098483245573
Validation loss: 2.51789413853271

Epoch: 5| Step: 1
Training loss: 2.0822069047472795
Validation loss: 2.474872635097526

Epoch: 5| Step: 2
Training loss: 2.5064409254605398
Validation loss: 2.470008984949985

Epoch: 5| Step: 3
Training loss: 2.007502194186065
Validation loss: 2.47222639010308

Epoch: 5| Step: 4
Training loss: 1.809132242471208
Validation loss: 2.5054278506618326

Epoch: 5| Step: 5
Training loss: 2.7348376073519294
Validation loss: 2.553339497901948

Epoch: 5| Step: 6
Training loss: 2.8337652961711877
Validation loss: 2.5494322805739777

Epoch: 5| Step: 7
Training loss: 3.1637603238712404
Validation loss: 2.506718592709183

Epoch: 5| Step: 8
Training loss: 2.514948309638309
Validation loss: 2.475855987835952

Epoch: 5| Step: 9
Training loss: 2.312756292213966
Validation loss: 2.4933936045211564

Epoch: 5| Step: 10
Training loss: 2.1755813698584108
Validation loss: 2.505203570095164

Epoch: 263| Step: 0
Training loss: 2.8386767060708684
Validation loss: 2.508385589044935

Epoch: 5| Step: 1
Training loss: 1.9658258914631466
Validation loss: 2.538571123988595

Epoch: 5| Step: 2
Training loss: 2.3740082728138137
Validation loss: 2.4881253479476637

Epoch: 5| Step: 3
Training loss: 2.7006173381771776
Validation loss: 2.4811000535760375

Epoch: 5| Step: 4
Training loss: 1.4792542319728033
Validation loss: 2.4955474827325252

Epoch: 5| Step: 5
Training loss: 2.424911760907447
Validation loss: 2.4820085222374058

Epoch: 5| Step: 6
Training loss: 2.498938716691114
Validation loss: 2.476555741425343

Epoch: 5| Step: 7
Training loss: 2.4606734845668057
Validation loss: 2.5177875391193574

Epoch: 5| Step: 8
Training loss: 2.6771929727112997
Validation loss: 2.4431109894271565

Epoch: 5| Step: 9
Training loss: 2.9110078320936794
Validation loss: 2.4701847452032926

Epoch: 5| Step: 10
Training loss: 2.4591290323068002
Validation loss: 2.533428462476283

Epoch: 264| Step: 0
Training loss: 2.54744887176209
Validation loss: 2.5531262642253343

Epoch: 5| Step: 1
Training loss: 1.8982574628695565
Validation loss: 2.5464504493802838

Epoch: 5| Step: 2
Training loss: 2.3619043800321466
Validation loss: 2.4720615551214573

Epoch: 5| Step: 3
Training loss: 2.6342508705371595
Validation loss: 2.4402568226256274

Epoch: 5| Step: 4
Training loss: 2.3071187272427567
Validation loss: 2.4440254137845208

Epoch: 5| Step: 5
Training loss: 2.1164405321489776
Validation loss: 2.5113257432377116

Epoch: 5| Step: 6
Training loss: 2.2984683161160193
Validation loss: 2.512178483852615

Epoch: 5| Step: 7
Training loss: 2.6563381404838795
Validation loss: 2.553720669175031

Epoch: 5| Step: 8
Training loss: 2.323945255376682
Validation loss: 2.5600256630261096

Epoch: 5| Step: 9
Training loss: 2.314746281209781
Validation loss: 2.4760323264915014

Epoch: 5| Step: 10
Training loss: 2.9508385258560437
Validation loss: 2.5060463114998575

Epoch: 265| Step: 0
Training loss: 2.8690119870966893
Validation loss: 2.4727231286720577

Epoch: 5| Step: 1
Training loss: 1.9402695211994725
Validation loss: 2.5303304671378894

Epoch: 5| Step: 2
Training loss: 1.8485117054971838
Validation loss: 2.548663198764319

Epoch: 5| Step: 3
Training loss: 2.467373041444478
Validation loss: 2.528564720153517

Epoch: 5| Step: 4
Training loss: 2.436172808720468
Validation loss: 2.506204125055571

Epoch: 5| Step: 5
Training loss: 2.708731861625889
Validation loss: 2.482196403930598

Epoch: 5| Step: 6
Training loss: 2.9467023813088473
Validation loss: 2.544385097452381

Epoch: 5| Step: 7
Training loss: 2.6141418955728493
Validation loss: 2.5112034558657874

Epoch: 5| Step: 8
Training loss: 1.6523321345216364
Validation loss: 2.526229399460469

Epoch: 5| Step: 9
Training loss: 2.412150987273909
Validation loss: 2.442836209672321

Epoch: 5| Step: 10
Training loss: 2.6045523294342687
Validation loss: 2.5326212100145997

Epoch: 266| Step: 0
Training loss: 2.393659473430515
Validation loss: 2.512731217767225

Epoch: 5| Step: 1
Training loss: 2.2969694572281463
Validation loss: 2.453492164763161

Epoch: 5| Step: 2
Training loss: 3.101305434482263
Validation loss: 2.5081020337976394

Epoch: 5| Step: 3
Training loss: 2.076322648754219
Validation loss: 2.4743319597905775

Epoch: 5| Step: 4
Training loss: 2.336187955257984
Validation loss: 2.5353973596095116

Epoch: 5| Step: 5
Training loss: 2.5062332647435532
Validation loss: 2.509905202425534

Epoch: 5| Step: 6
Training loss: 2.2764988373892314
Validation loss: 2.470620839139234

Epoch: 5| Step: 7
Training loss: 2.2219100799151974
Validation loss: 2.479469341505672

Epoch: 5| Step: 8
Training loss: 2.4706745613467462
Validation loss: 2.536754440189493

Epoch: 5| Step: 9
Training loss: 1.997785295682818
Validation loss: 2.5367183120407657

Epoch: 5| Step: 10
Training loss: 2.4849208016314845
Validation loss: 2.4960122431594676

Epoch: 267| Step: 0
Training loss: 2.135022035435905
Validation loss: 2.5508644489813683

Epoch: 5| Step: 1
Training loss: 2.199664272354256
Validation loss: 2.501102855416473

Epoch: 5| Step: 2
Training loss: 2.406989442238754
Validation loss: 2.5362693499082707

Epoch: 5| Step: 3
Training loss: 2.327636667535268
Validation loss: 2.4919063237068393

Epoch: 5| Step: 4
Training loss: 2.7535564660398597
Validation loss: 2.4686996643824926

Epoch: 5| Step: 5
Training loss: 3.0935265046126905
Validation loss: 2.5060996410376943

Epoch: 5| Step: 6
Training loss: 2.445401613604368
Validation loss: 2.4871985055876613

Epoch: 5| Step: 7
Training loss: 2.086851569789935
Validation loss: 2.475833940802637

Epoch: 5| Step: 8
Training loss: 2.354641542954444
Validation loss: 2.555880014322182

Epoch: 5| Step: 9
Training loss: 2.455190869931336
Validation loss: 2.532519722025901

Epoch: 5| Step: 10
Training loss: 2.009089557313013
Validation loss: 2.490798754081547

Epoch: 268| Step: 0
Training loss: 2.6668944758224162
Validation loss: 2.5045190841600227

Epoch: 5| Step: 1
Training loss: 2.4280114970932676
Validation loss: 2.523547557565631

Epoch: 5| Step: 2
Training loss: 2.014948650112839
Validation loss: 2.492717069324267

Epoch: 5| Step: 3
Training loss: 2.500068663607843
Validation loss: 2.5284916006849483

Epoch: 5| Step: 4
Training loss: 2.663545351370266
Validation loss: 2.4904126854695936

Epoch: 5| Step: 5
Training loss: 2.4199570475462977
Validation loss: 2.4871122275132636

Epoch: 5| Step: 6
Training loss: 2.4094638911967445
Validation loss: 2.5112853133878175

Epoch: 5| Step: 7
Training loss: 1.951671944841023
Validation loss: 2.4774541844078253

Epoch: 5| Step: 8
Training loss: 2.830821737947505
Validation loss: 2.5154670482818355

Epoch: 5| Step: 9
Training loss: 2.260201849742808
Validation loss: 2.5295128187918645

Epoch: 5| Step: 10
Training loss: 2.42635693683438
Validation loss: 2.4981297321588736

Epoch: 269| Step: 0
Training loss: 2.2331331443264433
Validation loss: 2.465044524532371

Epoch: 5| Step: 1
Training loss: 2.2135794124002963
Validation loss: 2.5123630552683567

Epoch: 5| Step: 2
Training loss: 2.1863631427816967
Validation loss: 2.468187991194472

Epoch: 5| Step: 3
Training loss: 2.655416649635307
Validation loss: 2.511791234007234

Epoch: 5| Step: 4
Training loss: 1.9764837317169963
Validation loss: 2.54174835891469

Epoch: 5| Step: 5
Training loss: 2.7825011107518804
Validation loss: 2.5058400432127534

Epoch: 5| Step: 6
Training loss: 2.3164398036540117
Validation loss: 2.5369609263991295

Epoch: 5| Step: 7
Training loss: 2.434109604047065
Validation loss: 2.4539197829921213

Epoch: 5| Step: 8
Training loss: 2.7254718686942003
Validation loss: 2.479605106442868

Epoch: 5| Step: 9
Training loss: 2.2000920406508464
Validation loss: 2.5250272592620253

Epoch: 5| Step: 10
Training loss: 2.7408041222387114
Validation loss: 2.4939483975279404

Epoch: 270| Step: 0
Training loss: 2.0868636800408136
Validation loss: 2.536157751978902

Epoch: 5| Step: 1
Training loss: 2.0668286070391138
Validation loss: 2.4867730449827916

Epoch: 5| Step: 2
Training loss: 2.8162030743288695
Validation loss: 2.5328018786953304

Epoch: 5| Step: 3
Training loss: 2.143653453732601
Validation loss: 2.4958436193471134

Epoch: 5| Step: 4
Training loss: 2.260718986112047
Validation loss: 2.514361088032745

Epoch: 5| Step: 5
Training loss: 1.8180399449222802
Validation loss: 2.5292274500094667

Epoch: 5| Step: 6
Training loss: 2.67345546803325
Validation loss: 2.4779693529807743

Epoch: 5| Step: 7
Training loss: 2.5100412892748887
Validation loss: 2.5347612699845286

Epoch: 5| Step: 8
Training loss: 2.398982678807622
Validation loss: 2.4902553031632317

Epoch: 5| Step: 9
Training loss: 3.070291844266953
Validation loss: 2.54502637690454

Epoch: 5| Step: 10
Training loss: 1.8805926521031957
Validation loss: 2.4584212797551324

Epoch: 271| Step: 0
Training loss: 2.861169137541184
Validation loss: 2.52641365264797

Epoch: 5| Step: 1
Training loss: 1.8877550521215147
Validation loss: 2.5082496791282027

Epoch: 5| Step: 2
Training loss: 2.170897668725966
Validation loss: 2.5000845899935

Epoch: 5| Step: 3
Training loss: 2.7298555354087255
Validation loss: 2.542452144304918

Epoch: 5| Step: 4
Training loss: 2.144469658083536
Validation loss: 2.4828975559278335

Epoch: 5| Step: 5
Training loss: 2.330978897326506
Validation loss: 2.504947213747062

Epoch: 5| Step: 6
Training loss: 2.089891322655088
Validation loss: 2.5308267433718497

Epoch: 5| Step: 7
Training loss: 2.2573149769812706
Validation loss: 2.511833793414147

Epoch: 5| Step: 8
Training loss: 3.0482798932040365
Validation loss: 2.5447474655939963

Epoch: 5| Step: 9
Training loss: 2.109815763412055
Validation loss: 2.5698887408087794

Epoch: 5| Step: 10
Training loss: 2.623332992934997
Validation loss: 2.481284428186624

Epoch: 272| Step: 0
Training loss: 2.3325633299837776
Validation loss: 2.5682620263355442

Epoch: 5| Step: 1
Training loss: 2.3346666432193137
Validation loss: 2.519118568281706

Epoch: 5| Step: 2
Training loss: 2.7331174738091426
Validation loss: 2.4531591656131067

Epoch: 5| Step: 3
Training loss: 2.8289973984103276
Validation loss: 2.472307849485907

Epoch: 5| Step: 4
Training loss: 2.0043779379451716
Validation loss: 2.496947802338668

Epoch: 5| Step: 5
Training loss: 2.617066246753926
Validation loss: 2.4925003228321216

Epoch: 5| Step: 6
Training loss: 2.2650623543684723
Validation loss: 2.502560942533313

Epoch: 5| Step: 7
Training loss: 2.3291262323444535
Validation loss: 2.4069715120524946

Epoch: 5| Step: 8
Training loss: 2.222742491324458
Validation loss: 2.4354581376522484

Epoch: 5| Step: 9
Training loss: 2.5822733478478552
Validation loss: 2.4737419043247764

Epoch: 5| Step: 10
Training loss: 2.4194707934987068
Validation loss: 2.496814833726286

Epoch: 273| Step: 0
Training loss: 2.4341144035428806
Validation loss: 2.5011851424155216

Epoch: 5| Step: 1
Training loss: 2.643603118351387
Validation loss: 2.43831126277825

Epoch: 5| Step: 2
Training loss: 2.558429741880872
Validation loss: 2.4727835461175

Epoch: 5| Step: 3
Training loss: 2.3230167133585615
Validation loss: 2.50543326766031

Epoch: 5| Step: 4
Training loss: 2.4962687304180395
Validation loss: 2.4991862274936163

Epoch: 5| Step: 5
Training loss: 2.2419953479905743
Validation loss: 2.5552785379818546

Epoch: 5| Step: 6
Training loss: 1.8650839220652875
Validation loss: 2.5011028574664813

Epoch: 5| Step: 7
Training loss: 2.1531650755409575
Validation loss: 2.5256105082709337

Epoch: 5| Step: 8
Training loss: 2.836564764425583
Validation loss: 2.5102780136633127

Epoch: 5| Step: 9
Training loss: 2.8850355390081996
Validation loss: 2.5062118184080133

Epoch: 5| Step: 10
Training loss: 1.8775435679088122
Validation loss: 2.5048695832558234

Epoch: 274| Step: 0
Training loss: 1.9582877931643048
Validation loss: 2.471509210615959

Epoch: 5| Step: 1
Training loss: 2.3668871396309727
Validation loss: 2.4877320501947073

Epoch: 5| Step: 2
Training loss: 2.208014939105593
Validation loss: 2.5224274026105413

Epoch: 5| Step: 3
Training loss: 2.112457396850768
Validation loss: 2.500205694986138

Epoch: 5| Step: 4
Training loss: 2.6167402653963636
Validation loss: 2.5219717429048365

Epoch: 5| Step: 5
Training loss: 2.1180471103965397
Validation loss: 2.4980833643635947

Epoch: 5| Step: 6
Training loss: 2.832886791570136
Validation loss: 2.4979685672070504

Epoch: 5| Step: 7
Training loss: 2.3667439967492645
Validation loss: 2.4940944466954353

Epoch: 5| Step: 8
Training loss: 2.329325117022838
Validation loss: 2.4352145275271715

Epoch: 5| Step: 9
Training loss: 2.322820059872933
Validation loss: 2.443525175699609

Epoch: 5| Step: 10
Training loss: 2.408895945143756
Validation loss: 2.465702850848302

Epoch: 275| Step: 0
Training loss: 2.5623277745870388
Validation loss: 2.471037846008167

Epoch: 5| Step: 1
Training loss: 2.072099022815165
Validation loss: 2.516261525770168

Epoch: 5| Step: 2
Training loss: 2.0833287302602144
Validation loss: 2.4859926572452706

Epoch: 5| Step: 3
Training loss: 2.2302264133690364
Validation loss: 2.448861853968179

Epoch: 5| Step: 4
Training loss: 2.1696096997471828
Validation loss: 2.4702632363464554

Epoch: 5| Step: 5
Training loss: 2.576013891366264
Validation loss: 2.4697792376108123

Epoch: 5| Step: 6
Training loss: 2.7935849236995876
Validation loss: 2.4869739108273574

Epoch: 5| Step: 7
Training loss: 2.750918668409271
Validation loss: 2.520169292609523

Epoch: 5| Step: 8
Training loss: 1.7428650500723433
Validation loss: 2.5119549499193385

Epoch: 5| Step: 9
Training loss: 2.1723345812296957
Validation loss: 2.4768990664213275

Epoch: 5| Step: 10
Training loss: 2.485423220817406
Validation loss: 2.5017795638150986

Epoch: 276| Step: 0
Training loss: 2.9609139876828667
Validation loss: 2.5595338423364726

Epoch: 5| Step: 1
Training loss: 2.2245262070164795
Validation loss: 2.409806083205907

Epoch: 5| Step: 2
Training loss: 1.8528905041495116
Validation loss: 2.462859141518972

Epoch: 5| Step: 3
Training loss: 2.8020740116536302
Validation loss: 2.4641959993277567

Epoch: 5| Step: 4
Training loss: 2.3306361231355606
Validation loss: 2.43987728500897

Epoch: 5| Step: 5
Training loss: 2.5882254905693514
Validation loss: 2.502066480096857

Epoch: 5| Step: 6
Training loss: 2.3453141143203657
Validation loss: 2.487108400261362

Epoch: 5| Step: 7
Training loss: 2.170241146136819
Validation loss: 2.43474549219878

Epoch: 5| Step: 8
Training loss: 2.1274958146767964
Validation loss: 2.4745006094334214

Epoch: 5| Step: 9
Training loss: 2.4543277197573348
Validation loss: 2.446588539683868

Epoch: 5| Step: 10
Training loss: 2.3693394715088845
Validation loss: 2.51073157040366

Epoch: 277| Step: 0
Training loss: 2.1454476932789452
Validation loss: 2.5158490118362984

Epoch: 5| Step: 1
Training loss: 2.143414204714621
Validation loss: 2.449859550490226

Epoch: 5| Step: 2
Training loss: 2.333725408129263
Validation loss: 2.4815574824330593

Epoch: 5| Step: 3
Training loss: 2.83332978042679
Validation loss: 2.5123269682060103

Epoch: 5| Step: 4
Training loss: 2.3615859831939354
Validation loss: 2.4859223332971787

Epoch: 5| Step: 5
Training loss: 2.4816831004168876
Validation loss: 2.5330395476655974

Epoch: 5| Step: 6
Training loss: 1.8354373331743064
Validation loss: 2.447599960153358

Epoch: 5| Step: 7
Training loss: 2.100839142943292
Validation loss: 2.4538635747272415

Epoch: 5| Step: 8
Training loss: 2.0332474497600055
Validation loss: 2.469063803938316

Epoch: 5| Step: 9
Training loss: 2.4675494787942656
Validation loss: 2.4870230983278643

Epoch: 5| Step: 10
Training loss: 3.1058125239655077
Validation loss: 2.5120993480709677

Epoch: 278| Step: 0
Training loss: 1.989194469164384
Validation loss: 2.522454758997416

Epoch: 5| Step: 1
Training loss: 2.3894295290133782
Validation loss: 2.5093856414702915

Epoch: 5| Step: 2
Training loss: 2.4222410848254468
Validation loss: 2.4700515138780035

Epoch: 5| Step: 3
Training loss: 1.8184786223779965
Validation loss: 2.475693278655258

Epoch: 5| Step: 4
Training loss: 2.636371324043665
Validation loss: 2.461048630644978

Epoch: 5| Step: 5
Training loss: 2.503861877714771
Validation loss: 2.426381139795723

Epoch: 5| Step: 6
Training loss: 1.947422644923807
Validation loss: 2.4660930170278004

Epoch: 5| Step: 7
Training loss: 2.399233906386564
Validation loss: 2.4544508072171207

Epoch: 5| Step: 8
Training loss: 2.1790149156918632
Validation loss: 2.4566673169572293

Epoch: 5| Step: 9
Training loss: 2.862173243367499
Validation loss: 2.472110045862536

Epoch: 5| Step: 10
Training loss: 2.454150914744509
Validation loss: 2.5137144749761666

Epoch: 279| Step: 0
Training loss: 2.1451830820054183
Validation loss: 2.448499987520032

Epoch: 5| Step: 1
Training loss: 2.327954996545763
Validation loss: 2.4714255590020717

Epoch: 5| Step: 2
Training loss: 1.9630096551285554
Validation loss: 2.4499287131785072

Epoch: 5| Step: 3
Training loss: 2.4067753800365232
Validation loss: 2.4585318546912416

Epoch: 5| Step: 4
Training loss: 2.2065820287432674
Validation loss: 2.501278189543997

Epoch: 5| Step: 5
Training loss: 3.164123082463994
Validation loss: 2.445839465616936

Epoch: 5| Step: 6
Training loss: 2.3519296961417155
Validation loss: 2.4696609142617705

Epoch: 5| Step: 7
Training loss: 2.1580433782083723
Validation loss: 2.426191576402285

Epoch: 5| Step: 8
Training loss: 2.6171243688456256
Validation loss: 2.511190800989371

Epoch: 5| Step: 9
Training loss: 2.500065802661834
Validation loss: 2.5193042003844477

Epoch: 5| Step: 10
Training loss: 1.2425840692458907
Validation loss: 2.5594803581001355

Epoch: 280| Step: 0
Training loss: 2.1533540822536246
Validation loss: 2.4978713068711595

Epoch: 5| Step: 1
Training loss: 1.6636808432314703
Validation loss: 2.502655492477392

Epoch: 5| Step: 2
Training loss: 2.2661993942880736
Validation loss: 2.471788911160535

Epoch: 5| Step: 3
Training loss: 2.866693355376924
Validation loss: 2.438950955809622

Epoch: 5| Step: 4
Training loss: 2.319066184970985
Validation loss: 2.516382996821007

Epoch: 5| Step: 5
Training loss: 3.299518411348264
Validation loss: 2.4526815479314794

Epoch: 5| Step: 6
Training loss: 2.2198437426106516
Validation loss: 2.4932616753485104

Epoch: 5| Step: 7
Training loss: 2.396821611548396
Validation loss: 2.4911987547765637

Epoch: 5| Step: 8
Training loss: 2.149290934896239
Validation loss: 2.4959926913105503

Epoch: 5| Step: 9
Training loss: 2.126454136292646
Validation loss: 2.531387078267571

Epoch: 5| Step: 10
Training loss: 2.0351196988680305
Validation loss: 2.4731835715697796

Epoch: 281| Step: 0
Training loss: 2.2023247963264647
Validation loss: 2.472502489377686

Epoch: 5| Step: 1
Training loss: 1.8658784882620263
Validation loss: 2.5138895587024725

Epoch: 5| Step: 2
Training loss: 2.6687462764240526
Validation loss: 2.479158873186885

Epoch: 5| Step: 3
Training loss: 2.1416990829369627
Validation loss: 2.4866449056820894

Epoch: 5| Step: 4
Training loss: 2.2799212622850025
Validation loss: 2.529502829796432

Epoch: 5| Step: 5
Training loss: 2.028076509857058
Validation loss: 2.5083615303873534

Epoch: 5| Step: 6
Training loss: 2.2647082348455068
Validation loss: 2.4903101928158846

Epoch: 5| Step: 7
Training loss: 2.792638884585199
Validation loss: 2.4700000402477045

Epoch: 5| Step: 8
Training loss: 2.1916546196358677
Validation loss: 2.4695469919886364

Epoch: 5| Step: 9
Training loss: 2.516955195765116
Validation loss: 2.4543724642598654

Epoch: 5| Step: 10
Training loss: 2.7461887305209265
Validation loss: 2.4226237801112354

Epoch: 282| Step: 0
Training loss: 1.9128620353558021
Validation loss: 2.510274356536989

Epoch: 5| Step: 1
Training loss: 1.8758018050841052
Validation loss: 2.4263416707877052

Epoch: 5| Step: 2
Training loss: 2.361438884298843
Validation loss: 2.518377175506294

Epoch: 5| Step: 3
Training loss: 3.4370804964194814
Validation loss: 2.4992973960552995

Epoch: 5| Step: 4
Training loss: 2.312985549677113
Validation loss: 2.5015018064369197

Epoch: 5| Step: 5
Training loss: 2.4279549361168065
Validation loss: 2.44839865172851

Epoch: 5| Step: 6
Training loss: 2.3349535857004713
Validation loss: 2.5242526638391496

Epoch: 5| Step: 7
Training loss: 1.7749217539989202
Validation loss: 2.4392635107201497

Epoch: 5| Step: 8
Training loss: 2.2493502420439233
Validation loss: 2.495488990444886

Epoch: 5| Step: 9
Training loss: 2.7625782882160914
Validation loss: 2.4254776013576875

Epoch: 5| Step: 10
Training loss: 1.7821236191373844
Validation loss: 2.4978721689883376

Epoch: 283| Step: 0
Training loss: 1.3771846495430715
Validation loss: 2.4970633527664274

Epoch: 5| Step: 1
Training loss: 2.3070256156607143
Validation loss: 2.5271914887119267

Epoch: 5| Step: 2
Training loss: 2.287667223545329
Validation loss: 2.504350693273232

Epoch: 5| Step: 3
Training loss: 2.181270994943395
Validation loss: 2.4839755151350493

Epoch: 5| Step: 4
Training loss: 2.8624980943165395
Validation loss: 2.5116043484518307

Epoch: 5| Step: 5
Training loss: 1.797591356865986
Validation loss: 2.5158507390343

Epoch: 5| Step: 6
Training loss: 2.5517142723155866
Validation loss: 2.48050505973525

Epoch: 5| Step: 7
Training loss: 2.749839084425555
Validation loss: 2.4087084774979615

Epoch: 5| Step: 8
Training loss: 2.44394692020246
Validation loss: 2.4542549895291854

Epoch: 5| Step: 9
Training loss: 2.337122995909769
Validation loss: 2.508745391750074

Epoch: 5| Step: 10
Training loss: 2.4776617552826066
Validation loss: 2.443936086358668

Epoch: 284| Step: 0
Training loss: 2.2492730767810043
Validation loss: 2.4793366091038407

Epoch: 5| Step: 1
Training loss: 3.1404573765901818
Validation loss: 2.4187184505700263

Epoch: 5| Step: 2
Training loss: 1.840666568720639
Validation loss: 2.484400559139931

Epoch: 5| Step: 3
Training loss: 2.2776077667098544
Validation loss: 2.4786035955288455

Epoch: 5| Step: 4
Training loss: 2.279684914684856
Validation loss: 2.509913312402652

Epoch: 5| Step: 5
Training loss: 2.1883144497353233
Validation loss: 2.4157206501610813

Epoch: 5| Step: 6
Training loss: 2.1120116532755633
Validation loss: 2.463180326791137

Epoch: 5| Step: 7
Training loss: 2.202524306198906
Validation loss: 2.4787271499021175

Epoch: 5| Step: 8
Training loss: 2.1388074300647992
Validation loss: 2.4945421159356145

Epoch: 5| Step: 9
Training loss: 2.747318000353865
Validation loss: 2.4381371310404445

Epoch: 5| Step: 10
Training loss: 2.3221525865768293
Validation loss: 2.494901563013785

Epoch: 285| Step: 0
Training loss: 2.862857219945136
Validation loss: 2.486305658368335

Epoch: 5| Step: 1
Training loss: 2.1022274284262483
Validation loss: 2.46035932216514

Epoch: 5| Step: 2
Training loss: 2.2065908887285217
Validation loss: 2.448258886108496

Epoch: 5| Step: 3
Training loss: 2.8720266474388136
Validation loss: 2.4643892269206495

Epoch: 5| Step: 4
Training loss: 2.2695332459852993
Validation loss: 2.492625697889253

Epoch: 5| Step: 5
Training loss: 2.02596993470549
Validation loss: 2.465943390820411

Epoch: 5| Step: 6
Training loss: 2.260807993777668
Validation loss: 2.444574773119532

Epoch: 5| Step: 7
Training loss: 1.922867867404049
Validation loss: 2.535099366845199

Epoch: 5| Step: 8
Training loss: 2.5988921703002417
Validation loss: 2.451035287154241

Epoch: 5| Step: 9
Training loss: 2.080033193470119
Validation loss: 2.5607396563970894

Epoch: 5| Step: 10
Training loss: 2.2827077936889792
Validation loss: 2.471756081716421

Epoch: 286| Step: 0
Training loss: 2.034339081759173
Validation loss: 2.4691419102148098

Epoch: 5| Step: 1
Training loss: 2.3450177642214483
Validation loss: 2.4948053668958714

Epoch: 5| Step: 2
Training loss: 2.26601611740562
Validation loss: 2.525384234646738

Epoch: 5| Step: 3
Training loss: 2.685732770554722
Validation loss: 2.4457252361438697

Epoch: 5| Step: 4
Training loss: 2.363020348137199
Validation loss: 2.5020842283165554

Epoch: 5| Step: 5
Training loss: 2.4202732819346715
Validation loss: 2.5571726494860254

Epoch: 5| Step: 6
Training loss: 2.438792350710247
Validation loss: 2.4633568469346834

Epoch: 5| Step: 7
Training loss: 2.2364426229559133
Validation loss: 2.5123750511808494

Epoch: 5| Step: 8
Training loss: 2.0751862361933866
Validation loss: 2.487574968235319

Epoch: 5| Step: 9
Training loss: 2.3739462070621267
Validation loss: 2.481538001618467

Epoch: 5| Step: 10
Training loss: 3.0048831298748615
Validation loss: 2.499026775636382

Epoch: 287| Step: 0
Training loss: 2.327793072073904
Validation loss: 2.4733140864130716

Epoch: 5| Step: 1
Training loss: 2.098463759041422
Validation loss: 2.486559458973428

Epoch: 5| Step: 2
Training loss: 2.2998797426712363
Validation loss: 2.503919525287908

Epoch: 5| Step: 3
Training loss: 1.9786682973779572
Validation loss: 2.51212516906489

Epoch: 5| Step: 4
Training loss: 2.1770644727069417
Validation loss: 2.5415271644764914

Epoch: 5| Step: 5
Training loss: 2.3699248447654253
Validation loss: 2.5007995454924643

Epoch: 5| Step: 6
Training loss: 2.5435674990858814
Validation loss: 2.4507999995861782

Epoch: 5| Step: 7
Training loss: 2.546743752309839
Validation loss: 2.4963593800679824

Epoch: 5| Step: 8
Training loss: 2.428870453176581
Validation loss: 2.5013992454601364

Epoch: 5| Step: 9
Training loss: 2.0546594189947793
Validation loss: 2.443319099008871

Epoch: 5| Step: 10
Training loss: 3.0478316932526814
Validation loss: 2.4971759504347686

Epoch: 288| Step: 0
Training loss: 1.5205074204950924
Validation loss: 2.4895586206588876

Epoch: 5| Step: 1
Training loss: 2.8392249355340105
Validation loss: 2.394898678952793

Epoch: 5| Step: 2
Training loss: 2.7682101995775916
Validation loss: 2.4542452165147086

Epoch: 5| Step: 3
Training loss: 2.2885169723444787
Validation loss: 2.4908714042955453

Epoch: 5| Step: 4
Training loss: 2.433848360069549
Validation loss: 2.4629958501449285

Epoch: 5| Step: 5
Training loss: 2.1244045994204055
Validation loss: 2.445536022211173

Epoch: 5| Step: 6
Training loss: 2.268900220537341
Validation loss: 2.4849439761290495

Epoch: 5| Step: 7
Training loss: 1.7594593386991138
Validation loss: 2.4786854441763886

Epoch: 5| Step: 8
Training loss: 2.1099185949595203
Validation loss: 2.4647019077999217

Epoch: 5| Step: 9
Training loss: 2.8041837021951217
Validation loss: 2.4823933677010803

Epoch: 5| Step: 10
Training loss: 2.315000882900391
Validation loss: 2.478807152260032

Epoch: 289| Step: 0
Training loss: 2.66381816918204
Validation loss: 2.4995470723693822

Epoch: 5| Step: 1
Training loss: 3.0418732107050226
Validation loss: 2.5006546681002426

Epoch: 5| Step: 2
Training loss: 2.241508779909773
Validation loss: 2.500105535679214

Epoch: 5| Step: 3
Training loss: 2.432783601230294
Validation loss: 2.4953225432200044

Epoch: 5| Step: 4
Training loss: 1.8292554310990032
Validation loss: 2.455103538040261

Epoch: 5| Step: 5
Training loss: 1.798011155222233
Validation loss: 2.516554965081737

Epoch: 5| Step: 6
Training loss: 2.444049545622494
Validation loss: 2.466011155349049

Epoch: 5| Step: 7
Training loss: 1.9748177045880386
Validation loss: 2.448479552124826

Epoch: 5| Step: 8
Training loss: 2.275316019431422
Validation loss: 2.5239862264289834

Epoch: 5| Step: 9
Training loss: 2.5616739383744043
Validation loss: 2.480042842970605

Epoch: 5| Step: 10
Training loss: 2.043820380535992
Validation loss: 2.5024856700328963

Epoch: 290| Step: 0
Training loss: 2.2510163872561657
Validation loss: 2.469284612409192

Epoch: 5| Step: 1
Training loss: 2.247111161385826
Validation loss: 2.4919685964298885

Epoch: 5| Step: 2
Training loss: 2.410166834679705
Validation loss: 2.440442381556718

Epoch: 5| Step: 3
Training loss: 1.8380324727532389
Validation loss: 2.4706542714892272

Epoch: 5| Step: 4
Training loss: 1.9196208356943907
Validation loss: 2.4513263732960517

Epoch: 5| Step: 5
Training loss: 2.0515783886029118
Validation loss: 2.5194816185731552

Epoch: 5| Step: 6
Training loss: 3.085093399686635
Validation loss: 2.501319499096452

Epoch: 5| Step: 7
Training loss: 2.2755859291182086
Validation loss: 2.5275088573282884

Epoch: 5| Step: 8
Training loss: 2.497718437501691
Validation loss: 2.4951876858790243

Epoch: 5| Step: 9
Training loss: 1.9404966499282004
Validation loss: 2.5000676607389694

Epoch: 5| Step: 10
Training loss: 3.0345389230532045
Validation loss: 2.5060520903193413

Epoch: 291| Step: 0
Training loss: 2.379106885845986
Validation loss: 2.4455711827860496

Epoch: 5| Step: 1
Training loss: 1.9109194738328543
Validation loss: 2.515611745720072

Epoch: 5| Step: 2
Training loss: 2.436129062208991
Validation loss: 2.4667630333799266

Epoch: 5| Step: 3
Training loss: 1.9170934229668652
Validation loss: 2.4546753004371245

Epoch: 5| Step: 4
Training loss: 2.3664675584056867
Validation loss: 2.4855648160174724

Epoch: 5| Step: 5
Training loss: 2.6925489328059014
Validation loss: 2.446473830671194

Epoch: 5| Step: 6
Training loss: 2.4197854164448973
Validation loss: 2.511266472035688

Epoch: 5| Step: 7
Training loss: 2.186566071735696
Validation loss: 2.445998899775982

Epoch: 5| Step: 8
Training loss: 2.1419782607313738
Validation loss: 2.4458940051692744

Epoch: 5| Step: 9
Training loss: 2.3842674941078807
Validation loss: 2.468187317095495

Epoch: 5| Step: 10
Training loss: 2.656133581864024
Validation loss: 2.5464881212074344

Epoch: 292| Step: 0
Training loss: 2.7977709480641964
Validation loss: 2.4557643194469403

Epoch: 5| Step: 1
Training loss: 2.455202619966493
Validation loss: 2.4956808671000537

Epoch: 5| Step: 2
Training loss: 1.9477251404086655
Validation loss: 2.491061383847496

Epoch: 5| Step: 3
Training loss: 1.8362560888595854
Validation loss: 2.4973188235678117

Epoch: 5| Step: 4
Training loss: 2.421039166347586
Validation loss: 2.456230441167982

Epoch: 5| Step: 5
Training loss: 2.594314238062577
Validation loss: 2.4541353635252126

Epoch: 5| Step: 6
Training loss: 2.104250185476673
Validation loss: 2.4791728662744403

Epoch: 5| Step: 7
Training loss: 1.9914306998295248
Validation loss: 2.4845940288327326

Epoch: 5| Step: 8
Training loss: 2.4921241680457094
Validation loss: 2.44686546681623

Epoch: 5| Step: 9
Training loss: 2.331076370605061
Validation loss: 2.46138784595197

Epoch: 5| Step: 10
Training loss: 2.186271431470532
Validation loss: 2.4701714992980133

Epoch: 293| Step: 0
Training loss: 2.400100876754436
Validation loss: 2.4324029649901475

Epoch: 5| Step: 1
Training loss: 2.8891840462005574
Validation loss: 2.4281224485684763

Epoch: 5| Step: 2
Training loss: 1.988979374421409
Validation loss: 2.466896922426579

Epoch: 5| Step: 3
Training loss: 2.364797260393303
Validation loss: 2.481399386615118

Epoch: 5| Step: 4
Training loss: 1.827532810902928
Validation loss: 2.4427176952718344

Epoch: 5| Step: 5
Training loss: 1.675511051616233
Validation loss: 2.5160917688410187

Epoch: 5| Step: 6
Training loss: 2.142998152589202
Validation loss: 2.4455867161332536

Epoch: 5| Step: 7
Training loss: 2.2915026056922847
Validation loss: 2.4958275215814933

Epoch: 5| Step: 8
Training loss: 3.3756738625775533
Validation loss: 2.463136430260412

Epoch: 5| Step: 9
Training loss: 1.8040609882347742
Validation loss: 2.4898651439977346

Epoch: 5| Step: 10
Training loss: 2.326645348933076
Validation loss: 2.5302127529386973

Epoch: 294| Step: 0
Training loss: 1.9034436940912982
Validation loss: 2.46341938449914

Epoch: 5| Step: 1
Training loss: 2.2231657118095196
Validation loss: 2.4729233101352635

Epoch: 5| Step: 2
Training loss: 2.4311479797140234
Validation loss: 2.5081405121012064

Epoch: 5| Step: 3
Training loss: 2.2468776230670753
Validation loss: 2.454172940333853

Epoch: 5| Step: 4
Training loss: 1.7302715800570654
Validation loss: 2.504700425766606

Epoch: 5| Step: 5
Training loss: 2.6017982903012116
Validation loss: 2.472679567436882

Epoch: 5| Step: 6
Training loss: 2.387986066780784
Validation loss: 2.4365035050806756

Epoch: 5| Step: 7
Training loss: 2.3219551411451156
Validation loss: 2.556448935927246

Epoch: 5| Step: 8
Training loss: 2.1582523944461
Validation loss: 2.533459621491892

Epoch: 5| Step: 9
Training loss: 3.2211688684054085
Validation loss: 2.4666206831444297

Epoch: 5| Step: 10
Training loss: 1.7897153770869394
Validation loss: 2.5164304037729512

Epoch: 295| Step: 0
Training loss: 2.184676391590782
Validation loss: 2.4629314917193437

Epoch: 5| Step: 1
Training loss: 2.645940362963215
Validation loss: 2.403641123740334

Epoch: 5| Step: 2
Training loss: 2.2622321671082237
Validation loss: 2.471244325564028

Epoch: 5| Step: 3
Training loss: 1.880547391659953
Validation loss: 2.4581501807188704

Epoch: 5| Step: 4
Training loss: 2.424531525655314
Validation loss: 2.534265521453141

Epoch: 5| Step: 5
Training loss: 2.6411921326652537
Validation loss: 2.464931588075045

Epoch: 5| Step: 6
Training loss: 2.59493495117274
Validation loss: 2.4522218836036886

Epoch: 5| Step: 7
Training loss: 2.2910239503258794
Validation loss: 2.411495060599947

Epoch: 5| Step: 8
Training loss: 2.3016070970822975
Validation loss: 2.4551899427067596

Epoch: 5| Step: 9
Training loss: 1.885520791678859
Validation loss: 2.4819285949251397

Epoch: 5| Step: 10
Training loss: 2.032212249544143
Validation loss: 2.5285524664684327

Epoch: 296| Step: 0
Training loss: 2.537419841233136
Validation loss: 2.482991224348027

Epoch: 5| Step: 1
Training loss: 2.304074480674159
Validation loss: 2.441184878446564

Epoch: 5| Step: 2
Training loss: 2.308236496290802
Validation loss: 2.4470316857885788

Epoch: 5| Step: 3
Training loss: 2.170234994074235
Validation loss: 2.4976472263689655

Epoch: 5| Step: 4
Training loss: 2.1730104401184476
Validation loss: 2.5081808362596916

Epoch: 5| Step: 5
Training loss: 1.7484220475101206
Validation loss: 2.4684590409250178

Epoch: 5| Step: 6
Training loss: 1.9807452548672067
Validation loss: 2.486162422502956

Epoch: 5| Step: 7
Training loss: 2.6998436034788846
Validation loss: 2.540227585159175

Epoch: 5| Step: 8
Training loss: 2.3037283243038247
Validation loss: 2.4631622139467253

Epoch: 5| Step: 9
Training loss: 2.371597462777286
Validation loss: 2.4930091779177035

Epoch: 5| Step: 10
Training loss: 2.322130922817462
Validation loss: 2.4902553268410186

Epoch: 297| Step: 0
Training loss: 2.406429432705955
Validation loss: 2.4556221501125464

Epoch: 5| Step: 1
Training loss: 2.12166715567504
Validation loss: 2.5026100828486637

Epoch: 5| Step: 2
Training loss: 2.0965395890839247
Validation loss: 2.534279933551625

Epoch: 5| Step: 3
Training loss: 2.307723396042958
Validation loss: 2.4799215653586724

Epoch: 5| Step: 4
Training loss: 2.1911679714623884
Validation loss: 2.5150918173246892

Epoch: 5| Step: 5
Training loss: 2.2051821364004622
Validation loss: 2.4978754080830763

Epoch: 5| Step: 6
Training loss: 2.3581255705565067
Validation loss: 2.5169027145127254

Epoch: 5| Step: 7
Training loss: 2.3090460474602907
Validation loss: 2.456019561143883

Epoch: 5| Step: 8
Training loss: 2.799201040720303
Validation loss: 2.5059273460822915

Epoch: 5| Step: 9
Training loss: 2.184892680939199
Validation loss: 2.5217235060959586

Epoch: 5| Step: 10
Training loss: 2.5612676494952797
Validation loss: 2.4429049436481063

Epoch: 298| Step: 0
Training loss: 2.100614085556409
Validation loss: 2.462422770835193

Epoch: 5| Step: 1
Training loss: 1.8450913803090279
Validation loss: 2.5291194459351662

Epoch: 5| Step: 2
Training loss: 3.211371250974336
Validation loss: 2.4023533137027977

Epoch: 5| Step: 3
Training loss: 2.4579267219440815
Validation loss: 2.4581021894936037

Epoch: 5| Step: 4
Training loss: 2.412015868316631
Validation loss: 2.457475511435588

Epoch: 5| Step: 5
Training loss: 2.8332471460435578
Validation loss: 2.392640938016991

Epoch: 5| Step: 6
Training loss: 2.413098485366759
Validation loss: 2.426554149018538

Epoch: 5| Step: 7
Training loss: 1.2795194708835966
Validation loss: 2.5153899580130217

Epoch: 5| Step: 8
Training loss: 1.870356914404016
Validation loss: 2.508070305235067

Epoch: 5| Step: 9
Training loss: 2.1241185099053004
Validation loss: 2.3925281969979815

Epoch: 5| Step: 10
Training loss: 2.479837171992784
Validation loss: 2.5226364385621456

Epoch: 299| Step: 0
Training loss: 2.0183967635595597
Validation loss: 2.4533076074982643

Epoch: 5| Step: 1
Training loss: 2.694988109583625
Validation loss: 2.464567946316807

Epoch: 5| Step: 2
Training loss: 2.3162527821540078
Validation loss: 2.45648605083729

Epoch: 5| Step: 3
Training loss: 1.8032573631535056
Validation loss: 2.471166148799062

Epoch: 5| Step: 4
Training loss: 2.614917556455057
Validation loss: 2.509860319254669

Epoch: 5| Step: 5
Training loss: 2.6921812583244353
Validation loss: 2.4807899867180283

Epoch: 5| Step: 6
Training loss: 1.524208538856109
Validation loss: 2.4104516111688725

Epoch: 5| Step: 7
Training loss: 2.248672623631066
Validation loss: 2.4548641571736

Epoch: 5| Step: 8
Training loss: 1.9939831588401236
Validation loss: 2.479967039989467

Epoch: 5| Step: 9
Training loss: 2.7788775322700836
Validation loss: 2.4429740503234774

Epoch: 5| Step: 10
Training loss: 1.9428746524690956
Validation loss: 2.4941271342312743

Epoch: 300| Step: 0
Training loss: 2.612975691421323
Validation loss: 2.480961384137441

Epoch: 5| Step: 1
Training loss: 2.3399943460901538
Validation loss: 2.501940241457858

Epoch: 5| Step: 2
Training loss: 2.4879865007678257
Validation loss: 2.4969954494298

Epoch: 5| Step: 3
Training loss: 2.47511051586285
Validation loss: 2.535844987990331

Epoch: 5| Step: 4
Training loss: 2.265273283920129
Validation loss: 2.528565193631635

Epoch: 5| Step: 5
Training loss: 1.7168258994364658
Validation loss: 2.4695239615976847

Epoch: 5| Step: 6
Training loss: 3.0797043829406276
Validation loss: 2.5279386791762968

Epoch: 5| Step: 7
Training loss: 1.7427770874299866
Validation loss: 2.510668111946539

Epoch: 5| Step: 8
Training loss: 2.4159422040683087
Validation loss: 2.4255573151574916

Epoch: 5| Step: 9
Training loss: 1.9030168975544934
Validation loss: 2.492619041493003

Epoch: 5| Step: 10
Training loss: 2.1927298018491097
Validation loss: 2.423846116112868

Epoch: 301| Step: 0
Training loss: 2.121053509128524
Validation loss: 2.499968081444873

Epoch: 5| Step: 1
Training loss: 1.971868860201942
Validation loss: 2.3866691194152647

Epoch: 5| Step: 2
Training loss: 2.2749339418986305
Validation loss: 2.4131208176672265

Epoch: 5| Step: 3
Training loss: 2.1459527090502206
Validation loss: 2.432633699339743

Epoch: 5| Step: 4
Training loss: 3.067112932353018
Validation loss: 2.455857670915876

Epoch: 5| Step: 5
Training loss: 2.3281892089182086
Validation loss: 2.4734862257394554

Epoch: 5| Step: 6
Training loss: 1.900499895488733
Validation loss: 2.4858587179711575

Epoch: 5| Step: 7
Training loss: 2.110440811465977
Validation loss: 2.4617910732743877

Epoch: 5| Step: 8
Training loss: 2.6265808068521928
Validation loss: 2.420723088140626

Epoch: 5| Step: 9
Training loss: 1.5097690991834218
Validation loss: 2.5244482920215012

Epoch: 5| Step: 10
Training loss: 2.7885060329580615
Validation loss: 2.466576088073992

Epoch: 302| Step: 0
Training loss: 3.1092842127135447
Validation loss: 2.425798736261414

Epoch: 5| Step: 1
Training loss: 2.083238548665748
Validation loss: 2.468157752117348

Epoch: 5| Step: 2
Training loss: 1.8925379383713947
Validation loss: 2.4558767541603688

Epoch: 5| Step: 3
Training loss: 2.3974029596159148
Validation loss: 2.4843513578968253

Epoch: 5| Step: 4
Training loss: 2.2358419231297657
Validation loss: 2.4253541501957594

Epoch: 5| Step: 5
Training loss: 2.2856436446036787
Validation loss: 2.4638753303977023

Epoch: 5| Step: 6
Training loss: 2.3823543921184345
Validation loss: 2.4881011845708674

Epoch: 5| Step: 7
Training loss: 1.7561609944769696
Validation loss: 2.459433812108231

Epoch: 5| Step: 8
Training loss: 2.5895915879608786
Validation loss: 2.4858176423920284

Epoch: 5| Step: 9
Training loss: 2.5379393925325435
Validation loss: 2.471405060584668

Epoch: 5| Step: 10
Training loss: 2.03460861716366
Validation loss: 2.4300691386463233

Epoch: 303| Step: 0
Training loss: 2.0312671367215827
Validation loss: 2.429833139703056

Epoch: 5| Step: 1
Training loss: 2.344607590497388
Validation loss: 2.4287842632362024

Epoch: 5| Step: 2
Training loss: 2.2521580836911843
Validation loss: 2.439317623473596

Epoch: 5| Step: 3
Training loss: 2.4070922566488893
Validation loss: 2.4741007922638065

Epoch: 5| Step: 4
Training loss: 1.863895466971819
Validation loss: 2.476783167837299

Epoch: 5| Step: 5
Training loss: 2.438551455910865
Validation loss: 2.4434008558698346

Epoch: 5| Step: 6
Training loss: 2.3468530077354637
Validation loss: 2.512096296722636

Epoch: 5| Step: 7
Training loss: 2.3337939579751357
Validation loss: 2.425468308519183

Epoch: 5| Step: 8
Training loss: 2.143544454702227
Validation loss: 2.4401998757327212

Epoch: 5| Step: 9
Training loss: 2.357068684059094
Validation loss: 2.456293390830085

Epoch: 5| Step: 10
Training loss: 2.6517030281948144
Validation loss: 2.485042382028654

Epoch: 304| Step: 0
Training loss: 2.37290370179593
Validation loss: 2.5141060167389964

Epoch: 5| Step: 1
Training loss: 3.092079250914036
Validation loss: 2.4360703997569706

Epoch: 5| Step: 2
Training loss: 2.168918600866865
Validation loss: 2.49589886988541

Epoch: 5| Step: 3
Training loss: 2.37349000411885
Validation loss: 2.4540165726503513

Epoch: 5| Step: 4
Training loss: 2.3123178152540915
Validation loss: 2.4234989661288857

Epoch: 5| Step: 5
Training loss: 2.037545293760901
Validation loss: 2.4704729918468007

Epoch: 5| Step: 6
Training loss: 2.233023815152742
Validation loss: 2.499341484217871

Epoch: 5| Step: 7
Training loss: 2.0419020484648382
Validation loss: 2.4718359267328243

Epoch: 5| Step: 8
Training loss: 2.352357748921782
Validation loss: 2.513315457167084

Epoch: 5| Step: 9
Training loss: 1.830246045399481
Validation loss: 2.4967470612209257

Epoch: 5| Step: 10
Training loss: 2.4362174352247616
Validation loss: 2.5311552420172823

Epoch: 305| Step: 0
Training loss: 2.97687614971093
Validation loss: 2.467794574842604

Epoch: 5| Step: 1
Training loss: 2.2322599630971927
Validation loss: 2.414141559590554

Epoch: 5| Step: 2
Training loss: 2.373777878182268
Validation loss: 2.3900723865198277

Epoch: 5| Step: 3
Training loss: 2.28822128931049
Validation loss: 2.39510859423911

Epoch: 5| Step: 4
Training loss: 1.4228619514248386
Validation loss: 2.5245962933595054

Epoch: 5| Step: 5
Training loss: 2.7290971664625907
Validation loss: 2.3680244492434346

Epoch: 5| Step: 6
Training loss: 2.62771438856422
Validation loss: 2.5003135925417967

Epoch: 5| Step: 7
Training loss: 2.405818652839474
Validation loss: 2.4519317099008244

Epoch: 5| Step: 8
Training loss: 2.104763500311242
Validation loss: 2.421074691683843

Epoch: 5| Step: 9
Training loss: 1.9928131916104164
Validation loss: 2.497564506658084

Epoch: 5| Step: 10
Training loss: 1.175747436848336
Validation loss: 2.4825648186149674

Epoch: 306| Step: 0
Training loss: 2.2006027176348337
Validation loss: 2.4841506907309006

Epoch: 5| Step: 1
Training loss: 2.6142269869423758
Validation loss: 2.5145900744952985

Epoch: 5| Step: 2
Training loss: 2.5067538584938838
Validation loss: 2.481976078964982

Epoch: 5| Step: 3
Training loss: 2.1526129081789174
Validation loss: 2.4689685905967043

Epoch: 5| Step: 4
Training loss: 2.7633419635240672
Validation loss: 2.4818134409869947

Epoch: 5| Step: 5
Training loss: 2.224339496428892
Validation loss: 2.4790387560540377

Epoch: 5| Step: 6
Training loss: 1.9169620894383252
Validation loss: 2.42296534885181

Epoch: 5| Step: 7
Training loss: 2.5595740384129693
Validation loss: 2.444955358811761

Epoch: 5| Step: 8
Training loss: 1.8598958415944158
Validation loss: 2.484018282782762

Epoch: 5| Step: 9
Training loss: 2.1707029404776557
Validation loss: 2.4513809455504987

Epoch: 5| Step: 10
Training loss: 2.0439223330573393
Validation loss: 2.4880575144278407

Epoch: 307| Step: 0
Training loss: 1.7260695914674538
Validation loss: 2.459826700628605

Epoch: 5| Step: 1
Training loss: 2.3615443885535767
Validation loss: 2.4511761819451676

Epoch: 5| Step: 2
Training loss: 2.7981320758156674
Validation loss: 2.472451178757202

Epoch: 5| Step: 3
Training loss: 2.379630243285095
Validation loss: 2.4743859127642125

Epoch: 5| Step: 4
Training loss: 1.906256378663444
Validation loss: 2.4746267959431263

Epoch: 5| Step: 5
Training loss: 2.043101902665178
Validation loss: 2.467720715418595

Epoch: 5| Step: 6
Training loss: 2.3340042943383783
Validation loss: 2.4657603342191137

Epoch: 5| Step: 7
Training loss: 2.2203601850829213
Validation loss: 2.4402440866315147

Epoch: 5| Step: 8
Training loss: 2.112205358419312
Validation loss: 2.468056650594092

Epoch: 5| Step: 9
Training loss: 1.9614944578934088
Validation loss: 2.470595412942481

Epoch: 5| Step: 10
Training loss: 3.130444628301516
Validation loss: 2.4698651309451334

Epoch: 308| Step: 0
Training loss: 2.1122473481006208
Validation loss: 2.4687518577625807

Epoch: 5| Step: 1
Training loss: 2.008084171187607
Validation loss: 2.453793516314958

Epoch: 5| Step: 2
Training loss: 1.7587933325834824
Validation loss: 2.47188204637566

Epoch: 5| Step: 3
Training loss: 2.422605834948116
Validation loss: 2.4382910999957184

Epoch: 5| Step: 4
Training loss: 2.241604932008228
Validation loss: 2.439476829164117

Epoch: 5| Step: 5
Training loss: 2.7242539040627745
Validation loss: 2.4608163038426385

Epoch: 5| Step: 6
Training loss: 2.01611038396271
Validation loss: 2.487164715313248

Epoch: 5| Step: 7
Training loss: 2.010949441419357
Validation loss: 2.436571736956161

Epoch: 5| Step: 8
Training loss: 2.321828533133782
Validation loss: 2.4339757683434433

Epoch: 5| Step: 9
Training loss: 2.9014163274721994
Validation loss: 2.461434055644845

Epoch: 5| Step: 10
Training loss: 1.6893011300395442
Validation loss: 2.4395310138996447

Epoch: 309| Step: 0
Training loss: 2.1390797404673534
Validation loss: 2.4200639244138045

Epoch: 5| Step: 1
Training loss: 1.5059158967687636
Validation loss: 2.461779988884387

Epoch: 5| Step: 2
Training loss: 2.2505591015753925
Validation loss: 2.4692756048664366

Epoch: 5| Step: 3
Training loss: 1.845002993242684
Validation loss: 2.4706540333516775

Epoch: 5| Step: 4
Training loss: 2.118109470647062
Validation loss: 2.5012720768407015

Epoch: 5| Step: 5
Training loss: 2.714587126753863
Validation loss: 2.488982062926223

Epoch: 5| Step: 6
Training loss: 2.601782253938946
Validation loss: 2.4707979934301902

Epoch: 5| Step: 7
Training loss: 3.2001223004335215
Validation loss: 2.4606432739987185

Epoch: 5| Step: 8
Training loss: 1.9743794685644074
Validation loss: 2.381456973660233

Epoch: 5| Step: 9
Training loss: 1.4395090244986861
Validation loss: 2.4570959559919237

Epoch: 5| Step: 10
Training loss: 2.2603900280860922
Validation loss: 2.5015086164934988

Epoch: 310| Step: 0
Training loss: 2.2128960120328296
Validation loss: 2.423923445704976

Epoch: 5| Step: 1
Training loss: 1.8015652685483254
Validation loss: 2.3916000414242173

Epoch: 5| Step: 2
Training loss: 2.400204284238969
Validation loss: 2.511321090283043

Epoch: 5| Step: 3
Training loss: 2.4974597422855807
Validation loss: 2.4474785539459094

Epoch: 5| Step: 4
Training loss: 3.0582473188426094
Validation loss: 2.3862624373559553

Epoch: 5| Step: 5
Training loss: 1.819778757062284
Validation loss: 2.4063523815051653

Epoch: 5| Step: 6
Training loss: 1.906751848043124
Validation loss: 2.464050394108692

Epoch: 5| Step: 7
Training loss: 1.7674410097672857
Validation loss: 2.4101573668661964

Epoch: 5| Step: 8
Training loss: 2.2375384790958504
Validation loss: 2.4745660427727865

Epoch: 5| Step: 9
Training loss: 1.6756644397207567
Validation loss: 2.4718164372341884

Epoch: 5| Step: 10
Training loss: 2.9765777187008418
Validation loss: 2.4495917194570374

Epoch: 311| Step: 0
Training loss: 2.4556922842406683
Validation loss: 2.4746580893095307

Epoch: 5| Step: 1
Training loss: 2.6246219544436413
Validation loss: 2.441260545677349

Epoch: 5| Step: 2
Training loss: 3.112978586683876
Validation loss: 2.5349199091434635

Epoch: 5| Step: 3
Training loss: 1.9508917896757918
Validation loss: 2.443002082606253

Epoch: 5| Step: 4
Training loss: 1.7534541373584478
Validation loss: 2.399727269369318

Epoch: 5| Step: 5
Training loss: 1.6492301879081401
Validation loss: 2.483732976267964

Epoch: 5| Step: 6
Training loss: 1.7334240204978317
Validation loss: 2.4660941381881853

Epoch: 5| Step: 7
Training loss: 1.915140774684496
Validation loss: 2.458806848642301

Epoch: 5| Step: 8
Training loss: 2.488716315018038
Validation loss: 2.471368163834757

Epoch: 5| Step: 9
Training loss: 2.0120480758580817
Validation loss: 2.5461210222805635

Epoch: 5| Step: 10
Training loss: 2.519484124740971
Validation loss: 2.3532313625926533

Epoch: 312| Step: 0
Training loss: 1.928592324774428
Validation loss: 2.464113660031536

Epoch: 5| Step: 1
Training loss: 2.0573583149475896
Validation loss: 2.4076386525131754

Epoch: 5| Step: 2
Training loss: 2.3949643314389353
Validation loss: 2.5279444292468947

Epoch: 5| Step: 3
Training loss: 2.158452885187551
Validation loss: 2.4803161403615013

Epoch: 5| Step: 4
Training loss: 1.7971458562630558
Validation loss: 2.4578217804437203

Epoch: 5| Step: 5
Training loss: 2.1111020400315312
Validation loss: 2.4480634810687

Epoch: 5| Step: 6
Training loss: 2.148456476301138
Validation loss: 2.49401712392491

Epoch: 5| Step: 7
Training loss: 2.8542960664323305
Validation loss: 2.4188032917226088

Epoch: 5| Step: 8
Training loss: 2.2522246700780224
Validation loss: 2.4372260647324486

Epoch: 5| Step: 9
Training loss: 2.4831595656598133
Validation loss: 2.4226721852507476

Epoch: 5| Step: 10
Training loss: 2.0866958439811216
Validation loss: 2.4404071523402653

Epoch: 313| Step: 0
Training loss: 2.376427873739684
Validation loss: 2.409905436077511

Epoch: 5| Step: 1
Training loss: 1.9392810142036614
Validation loss: 2.4843708393528763

Epoch: 5| Step: 2
Training loss: 2.5893100286385096
Validation loss: 2.4410990996725124

Epoch: 5| Step: 3
Training loss: 2.0756806647496093
Validation loss: 2.472480101380323

Epoch: 5| Step: 4
Training loss: 1.4673516129916824
Validation loss: 2.424601371713586

Epoch: 5| Step: 5
Training loss: 2.4218339485873157
Validation loss: 2.478140317025918

Epoch: 5| Step: 6
Training loss: 1.6795647154886304
Validation loss: 2.4670598018065104

Epoch: 5| Step: 7
Training loss: 2.7151573384255294
Validation loss: 2.447332082959939

Epoch: 5| Step: 8
Training loss: 2.0397923358236523
Validation loss: 2.460807588256878

Epoch: 5| Step: 9
Training loss: 2.5050094007365162
Validation loss: 2.429188126532363

Epoch: 5| Step: 10
Training loss: 2.3121146834748045
Validation loss: 2.522117219321267

Epoch: 314| Step: 0
Training loss: 2.9785955099430717
Validation loss: 2.4328509800937557

Epoch: 5| Step: 1
Training loss: 2.2939603828594475
Validation loss: 2.370172704772525

Epoch: 5| Step: 2
Training loss: 2.598600058365308
Validation loss: 2.4459171663449437

Epoch: 5| Step: 3
Training loss: 2.0261149127602494
Validation loss: 2.4449265100801574

Epoch: 5| Step: 4
Training loss: 2.334967063981925
Validation loss: 2.451171313360405

Epoch: 5| Step: 5
Training loss: 1.662571628719731
Validation loss: 2.4507859281838456

Epoch: 5| Step: 6
Training loss: 2.1097707871598343
Validation loss: 2.4854795560011245

Epoch: 5| Step: 7
Training loss: 1.767733909528309
Validation loss: 2.48031311916351

Epoch: 5| Step: 8
Training loss: 2.1106303682674135
Validation loss: 2.4363364426056715

Epoch: 5| Step: 9
Training loss: 2.5632485017600035
Validation loss: 2.4194071628525067

Epoch: 5| Step: 10
Training loss: 2.0245975424118825
Validation loss: 2.40457645299968

Epoch: 315| Step: 0
Training loss: 2.5333885295610354
Validation loss: 2.4119419312960617

Epoch: 5| Step: 1
Training loss: 2.413399417018085
Validation loss: 2.3265912182616426

Epoch: 5| Step: 2
Training loss: 2.659878574840955
Validation loss: 2.4691751492273384

Epoch: 5| Step: 3
Training loss: 1.8742150252998109
Validation loss: 2.396315222202441

Epoch: 5| Step: 4
Training loss: 2.257032424646523
Validation loss: 2.4118253150952063

Epoch: 5| Step: 5
Training loss: 2.0942124951963734
Validation loss: 2.4768223743752373

Epoch: 5| Step: 6
Training loss: 2.3041984427148248
Validation loss: 2.4626936483315465

Epoch: 5| Step: 7
Training loss: 1.7599643675491627
Validation loss: 2.468849146908023

Epoch: 5| Step: 8
Training loss: 2.1877943658315573
Validation loss: 2.4546866388411384

Epoch: 5| Step: 9
Training loss: 2.046754673340353
Validation loss: 2.46855691798829

Epoch: 5| Step: 10
Training loss: 2.111736191124678
Validation loss: 2.448778314914039

Epoch: 316| Step: 0
Training loss: 2.127308208996631
Validation loss: 2.5188021058297325

Epoch: 5| Step: 1
Training loss: 1.8201620015156548
Validation loss: 2.447866075805043

Epoch: 5| Step: 2
Training loss: 2.7066608742556424
Validation loss: 2.3990157486071673

Epoch: 5| Step: 3
Training loss: 2.1072345187222354
Validation loss: 2.465080975142255

Epoch: 5| Step: 4
Training loss: 2.4651201821639868
Validation loss: 2.5339758893841346

Epoch: 5| Step: 5
Training loss: 1.519350722702316
Validation loss: 2.434227767683961

Epoch: 5| Step: 6
Training loss: 2.076463651923628
Validation loss: 2.409612710856551

Epoch: 5| Step: 7
Training loss: 1.9109988236276467
Validation loss: 2.40216868973525

Epoch: 5| Step: 8
Training loss: 2.0553462491854084
Validation loss: 2.518199965575373

Epoch: 5| Step: 9
Training loss: 3.068561705116968
Validation loss: 2.410160649386136

Epoch: 5| Step: 10
Training loss: 2.0893186676072206
Validation loss: 2.387329776848183

Epoch: 317| Step: 0
Training loss: 2.3097734615993604
Validation loss: 2.4857298776654275

Epoch: 5| Step: 1
Training loss: 1.986454692397826
Validation loss: 2.5300200221340985

Epoch: 5| Step: 2
Training loss: 2.2639121058963125
Validation loss: 2.447212672714195

Epoch: 5| Step: 3
Training loss: 1.9056633844009825
Validation loss: 2.449902529657973

Epoch: 5| Step: 4
Training loss: 2.049196281120862
Validation loss: 2.4050743343004535

Epoch: 5| Step: 5
Training loss: 2.6782495850258545
Validation loss: 2.421672696950573

Epoch: 5| Step: 6
Training loss: 2.002541357939653
Validation loss: 2.3906357408593664

Epoch: 5| Step: 7
Training loss: 2.4468034093134916
Validation loss: 2.4631545380904463

Epoch: 5| Step: 8
Training loss: 2.3759580988544826
Validation loss: 2.408675677009327

Epoch: 5| Step: 9
Training loss: 2.2713763669707734
Validation loss: 2.509907792718303

Epoch: 5| Step: 10
Training loss: 1.8803053502407643
Validation loss: 2.448010909431393

Epoch: 318| Step: 0
Training loss: 2.360874432189101
Validation loss: 2.4843800945130425

Epoch: 5| Step: 1
Training loss: 1.9757519292560142
Validation loss: 2.4341029182293528

Epoch: 5| Step: 2
Training loss: 2.295898229809114
Validation loss: 2.448920496844008

Epoch: 5| Step: 3
Training loss: 2.049107971571165
Validation loss: 2.39713590576636

Epoch: 5| Step: 4
Training loss: 2.2033986672407004
Validation loss: 2.45053351521936

Epoch: 5| Step: 5
Training loss: 2.325578051664477
Validation loss: 2.4835655032297623

Epoch: 5| Step: 6
Training loss: 1.4203398245521606
Validation loss: 2.441559601198587

Epoch: 5| Step: 7
Training loss: 2.0195703262887204
Validation loss: 2.40667865607007

Epoch: 5| Step: 8
Training loss: 3.2779319335406116
Validation loss: 2.399384136252808

Epoch: 5| Step: 9
Training loss: 2.1115207637169733
Validation loss: 2.4614968331749854

Epoch: 5| Step: 10
Training loss: 2.5288906640205044
Validation loss: 2.477656479333422

Epoch: 319| Step: 0
Training loss: 2.244521464808824
Validation loss: 2.4837899778509356

Epoch: 5| Step: 1
Training loss: 1.9151868981972087
Validation loss: 2.4742341029163266

Epoch: 5| Step: 2
Training loss: 2.453957094614878
Validation loss: 2.4060876053985054

Epoch: 5| Step: 3
Training loss: 2.933395765102568
Validation loss: 2.4453234409712743

Epoch: 5| Step: 4
Training loss: 1.6207888396889052
Validation loss: 2.4100694551494137

Epoch: 5| Step: 5
Training loss: 2.3896703871080205
Validation loss: 2.437077519057531

Epoch: 5| Step: 6
Training loss: 2.6677626701957102
Validation loss: 2.417105258000969

Epoch: 5| Step: 7
Training loss: 1.5980005616102317
Validation loss: 2.3705142095566676

Epoch: 5| Step: 8
Training loss: 2.334940617886544
Validation loss: 2.4215805515131543

Epoch: 5| Step: 9
Training loss: 2.399770856885686
Validation loss: 2.4412434600044683

Epoch: 5| Step: 10
Training loss: 1.707550249267946
Validation loss: 2.5016898750413055

Epoch: 320| Step: 0
Training loss: 1.9643603843269033
Validation loss: 2.459812163406507

Epoch: 5| Step: 1
Training loss: 2.0494746814437965
Validation loss: 2.4425486322579464

Epoch: 5| Step: 2
Training loss: 1.8050820716099871
Validation loss: 2.3668936968759926

Epoch: 5| Step: 3
Training loss: 2.5522252153674203
Validation loss: 2.5024279586946903

Epoch: 5| Step: 4
Training loss: 2.0486230738518643
Validation loss: 2.4405769634904173

Epoch: 5| Step: 5
Training loss: 2.335970773109078
Validation loss: 2.438003755128337

Epoch: 5| Step: 6
Training loss: 2.4662862144939663
Validation loss: 2.4624127595492533

Epoch: 5| Step: 7
Training loss: 2.1658288240501995
Validation loss: 2.4178662655523753

Epoch: 5| Step: 8
Training loss: 2.682310372197873
Validation loss: 2.4430030753207355

Epoch: 5| Step: 9
Training loss: 2.0483843647389
Validation loss: 2.4642017223184456

Epoch: 5| Step: 10
Training loss: 1.886672751930227
Validation loss: 2.4471259151435616

Epoch: 321| Step: 0
Training loss: 2.3320195950164155
Validation loss: 2.4595102552272063

Epoch: 5| Step: 1
Training loss: 2.088906108106611
Validation loss: 2.4073343059297594

Epoch: 5| Step: 2
Training loss: 2.1148869589318617
Validation loss: 2.453144981292973

Epoch: 5| Step: 3
Training loss: 2.023785299802641
Validation loss: 2.4799391557353005

Epoch: 5| Step: 4
Training loss: 2.2482592948824087
Validation loss: 2.462700825950425

Epoch: 5| Step: 5
Training loss: 2.4566122161683235
Validation loss: 2.433791265862071

Epoch: 5| Step: 6
Training loss: 2.266393176109794
Validation loss: 2.4594229328658788

Epoch: 5| Step: 7
Training loss: 1.9504749477746086
Validation loss: 2.4951729061973316

Epoch: 5| Step: 8
Training loss: 2.5454132940615852
Validation loss: 2.388151073327272

Epoch: 5| Step: 9
Training loss: 2.4804230933605695
Validation loss: 2.3872880374378607

Epoch: 5| Step: 10
Training loss: 1.977688253920889
Validation loss: 2.396216136067374

Epoch: 322| Step: 0
Training loss: 2.309880912815719
Validation loss: 2.5350812253094706

Epoch: 5| Step: 1
Training loss: 1.6457362166454388
Validation loss: 2.5026339427513484

Epoch: 5| Step: 2
Training loss: 2.257007600601643
Validation loss: 2.41872223394055

Epoch: 5| Step: 3
Training loss: 2.3253229675754583
Validation loss: 2.395304820515039

Epoch: 5| Step: 4
Training loss: 2.0860602524889256
Validation loss: 2.394342677998583

Epoch: 5| Step: 5
Training loss: 2.464344778202119
Validation loss: 2.4805748768644653

Epoch: 5| Step: 6
Training loss: 2.537323623315243
Validation loss: 2.465199003030299

Epoch: 5| Step: 7
Training loss: 2.157160027903894
Validation loss: 2.4519004218541967

Epoch: 5| Step: 8
Training loss: 2.69407992721176
Validation loss: 2.413264998974013

Epoch: 5| Step: 9
Training loss: 2.27375586728623
Validation loss: 2.4384733201998285

Epoch: 5| Step: 10
Training loss: 1.711255187757499
Validation loss: 2.459629262314586

Epoch: 323| Step: 0
Training loss: 2.086465261609412
Validation loss: 2.4156826768506328

Epoch: 5| Step: 1
Training loss: 2.6365665646185206
Validation loss: 2.4703955336981673

Epoch: 5| Step: 2
Training loss: 1.928769221330593
Validation loss: 2.5583835495735574

Epoch: 5| Step: 3
Training loss: 2.1153502428156603
Validation loss: 2.3914620000372

Epoch: 5| Step: 4
Training loss: 1.8172169178675017
Validation loss: 2.46398430903744

Epoch: 5| Step: 5
Training loss: 2.6136696930218997
Validation loss: 2.4515158033126445

Epoch: 5| Step: 6
Training loss: 2.6195260147693173
Validation loss: 2.4813988493806516

Epoch: 5| Step: 7
Training loss: 2.3361710141434893
Validation loss: 2.4196522336112585

Epoch: 5| Step: 8
Training loss: 2.1312911088396387
Validation loss: 2.4230092716628175

Epoch: 5| Step: 9
Training loss: 2.140121957744127
Validation loss: 2.462280781883986

Epoch: 5| Step: 10
Training loss: 1.8747541902268663
Validation loss: 2.476638259161122

Epoch: 324| Step: 0
Training loss: 1.90028442211514
Validation loss: 2.4276761232380006

Epoch: 5| Step: 1
Training loss: 2.318754861420422
Validation loss: 2.495386043647361

Epoch: 5| Step: 2
Training loss: 1.9542241170066335
Validation loss: 2.4263604383385515

Epoch: 5| Step: 3
Training loss: 2.8812241559307306
Validation loss: 2.4574108756841615

Epoch: 5| Step: 4
Training loss: 1.4994588511571354
Validation loss: 2.4707994242470446

Epoch: 5| Step: 5
Training loss: 1.8897807230222683
Validation loss: 2.462619475081577

Epoch: 5| Step: 6
Training loss: 1.7206984832735706
Validation loss: 2.483227838560514

Epoch: 5| Step: 7
Training loss: 2.1118361067542084
Validation loss: 2.4272557658192664

Epoch: 5| Step: 8
Training loss: 2.290843804331921
Validation loss: 2.5297559539374723

Epoch: 5| Step: 9
Training loss: 2.328902351609032
Validation loss: 2.3801160176823486

Epoch: 5| Step: 10
Training loss: 2.5741943913929566
Validation loss: 2.416885184874337

Epoch: 325| Step: 0
Training loss: 2.2807171342951498
Validation loss: 2.45335213653598

Epoch: 5| Step: 1
Training loss: 1.7829038070044967
Validation loss: 2.407488521909382

Epoch: 5| Step: 2
Training loss: 2.495679650858309
Validation loss: 2.454531041266631

Epoch: 5| Step: 3
Training loss: 1.5284705335018556
Validation loss: 2.37224371855695

Epoch: 5| Step: 4
Training loss: 2.1236203146547195
Validation loss: 2.43045459639204

Epoch: 5| Step: 5
Training loss: 2.0620582569894834
Validation loss: 2.4713156118041235

Epoch: 5| Step: 6
Training loss: 2.5653608216335027
Validation loss: 2.473461384021451

Epoch: 5| Step: 7
Training loss: 2.2771765515046067
Validation loss: 2.393363366584555

Epoch: 5| Step: 8
Training loss: 2.5618453701564503
Validation loss: 2.4390851722817564

Epoch: 5| Step: 9
Training loss: 2.4438420466188115
Validation loss: 2.4823441452639825

Epoch: 5| Step: 10
Training loss: 2.275748949119596
Validation loss: 2.3642986166490885

Epoch: 326| Step: 0
Training loss: 2.6064680891017282
Validation loss: 2.4131960071900873

Epoch: 5| Step: 1
Training loss: 2.056146604031261
Validation loss: 2.4650065123233587

Epoch: 5| Step: 2
Training loss: 2.909822626639957
Validation loss: 2.3907296623425096

Epoch: 5| Step: 3
Training loss: 1.8596043805877167
Validation loss: 2.4331032523970295

Epoch: 5| Step: 4
Training loss: 1.765609673627652
Validation loss: 2.4824608907624173

Epoch: 5| Step: 5
Training loss: 2.262936279215631
Validation loss: 2.403658140732241

Epoch: 5| Step: 6
Training loss: 2.266238846327976
Validation loss: 2.381007482415538

Epoch: 5| Step: 7
Training loss: 2.032241813899402
Validation loss: 2.4149935266048805

Epoch: 5| Step: 8
Training loss: 2.182644823825314
Validation loss: 2.4218392455828917

Epoch: 5| Step: 9
Training loss: 2.6210266195646144
Validation loss: 2.528560890756573

Epoch: 5| Step: 10
Training loss: 2.055251823644429
Validation loss: 2.39890887442449

Epoch: 327| Step: 0
Training loss: 1.860065748631859
Validation loss: 2.4881807724475027

Epoch: 5| Step: 1
Training loss: 2.384884193215945
Validation loss: 2.4673186763993478

Epoch: 5| Step: 2
Training loss: 2.190254656822114
Validation loss: 2.4601773589612757

Epoch: 5| Step: 3
Training loss: 2.3471242393894265
Validation loss: 2.449529109350964

Epoch: 5| Step: 4
Training loss: 2.266152997810356
Validation loss: 2.428120403459917

Epoch: 5| Step: 5
Training loss: 2.4141323239990595
Validation loss: 2.4342193228751534

Epoch: 5| Step: 6
Training loss: 1.9166722159374454
Validation loss: 2.3883009762914242

Epoch: 5| Step: 7
Training loss: 2.1479474982766185
Validation loss: 2.484980432994514

Epoch: 5| Step: 8
Training loss: 2.132330200662121
Validation loss: 2.408567453941032

Epoch: 5| Step: 9
Training loss: 2.40675160517906
Validation loss: 2.494691453729096

Epoch: 5| Step: 10
Training loss: 1.9165613795124326
Validation loss: 2.428779563510028

Epoch: 328| Step: 0
Training loss: 2.0858682342344586
Validation loss: 2.4484536023037826

Epoch: 5| Step: 1
Training loss: 1.7821964627167148
Validation loss: 2.4863887134694087

Epoch: 5| Step: 2
Training loss: 2.6138528560794816
Validation loss: 2.4587921797520997

Epoch: 5| Step: 3
Training loss: 2.0897544200023095
Validation loss: 2.4907813618491828

Epoch: 5| Step: 4
Training loss: 2.6351210437167896
Validation loss: 2.42052516362696

Epoch: 5| Step: 5
Training loss: 2.472458769760188
Validation loss: 2.4420350122799253

Epoch: 5| Step: 6
Training loss: 1.94953362438696
Validation loss: 2.462866281182518

Epoch: 5| Step: 7
Training loss: 1.5592012297107276
Validation loss: 2.3775873846171134

Epoch: 5| Step: 8
Training loss: 2.5475187833653203
Validation loss: 2.4224322220174628

Epoch: 5| Step: 9
Training loss: 1.5866734342804734
Validation loss: 2.396389157815369

Epoch: 5| Step: 10
Training loss: 2.537898057806666
Validation loss: 2.3724781371183297

Epoch: 329| Step: 0
Training loss: 2.1349280069617493
Validation loss: 2.4901083019754773

Epoch: 5| Step: 1
Training loss: 1.5950893683195388
Validation loss: 2.4683324778281985

Epoch: 5| Step: 2
Training loss: 2.19087982654633
Validation loss: 2.426396115567515

Epoch: 5| Step: 3
Training loss: 2.2448090967857297
Validation loss: 2.5121160957231896

Epoch: 5| Step: 4
Training loss: 1.5322743317820522
Validation loss: 2.4153695339988763

Epoch: 5| Step: 5
Training loss: 2.160873762998824
Validation loss: 2.4182580726440546

Epoch: 5| Step: 6
Training loss: 2.545239631448116
Validation loss: 2.4305846353677154

Epoch: 5| Step: 7
Training loss: 2.340731902794354
Validation loss: 2.4243951489080984

Epoch: 5| Step: 8
Training loss: 2.2166471590412278
Validation loss: 2.4711581419677575

Epoch: 5| Step: 9
Training loss: 2.9054633275653554
Validation loss: 2.4295691292616937

Epoch: 5| Step: 10
Training loss: 2.0816323647932027
Validation loss: 2.4095457434662695

Epoch: 330| Step: 0
Training loss: 2.513763117820016
Validation loss: 2.467688946574263

Epoch: 5| Step: 1
Training loss: 2.0766103860975447
Validation loss: 2.4502489076117957

Epoch: 5| Step: 2
Training loss: 2.4948771441528947
Validation loss: 2.377168440501559

Epoch: 5| Step: 3
Training loss: 2.7495604944145287
Validation loss: 2.411778164465271

Epoch: 5| Step: 4
Training loss: 2.1830444736956918
Validation loss: 2.4952362070047847

Epoch: 5| Step: 5
Training loss: 2.470410814446166
Validation loss: 2.4286384936046987

Epoch: 5| Step: 6
Training loss: 1.5597026962246208
Validation loss: 2.3997811401807825

Epoch: 5| Step: 7
Training loss: 1.9699584037726798
Validation loss: 2.496600134215638

Epoch: 5| Step: 8
Training loss: 2.062190755144103
Validation loss: 2.4650937814512983

Epoch: 5| Step: 9
Training loss: 1.9529549486518174
Validation loss: 2.409803518825693

Epoch: 5| Step: 10
Training loss: 2.4567112069856334
Validation loss: 2.341848370640327

Epoch: 331| Step: 0
Training loss: 2.617658976888913
Validation loss: 2.39601105988934

Epoch: 5| Step: 1
Training loss: 2.6903824540715444
Validation loss: 2.4466159898725217

Epoch: 5| Step: 2
Training loss: 1.7076589447259911
Validation loss: 2.4521779226327314

Epoch: 5| Step: 3
Training loss: 1.807839551507307
Validation loss: 2.457021942947931

Epoch: 5| Step: 4
Training loss: 1.7578017170893232
Validation loss: 2.366952944129669

Epoch: 5| Step: 5
Training loss: 2.5263393475768434
Validation loss: 2.387522787096938

Epoch: 5| Step: 6
Training loss: 1.5970927319580621
Validation loss: 2.432010523101304

Epoch: 5| Step: 7
Training loss: 2.349667618965861
Validation loss: 2.4342087063971976

Epoch: 5| Step: 8
Training loss: 2.2934171637841843
Validation loss: 2.4247761287179235

Epoch: 5| Step: 9
Training loss: 2.0237180301810653
Validation loss: 2.4264418833368384

Epoch: 5| Step: 10
Training loss: 2.586338530731125
Validation loss: 2.441166681689299

Epoch: 332| Step: 0
Training loss: 2.5937272036366443
Validation loss: 2.463273976908419

Epoch: 5| Step: 1
Training loss: 2.370159034060947
Validation loss: 2.517237693657051

Epoch: 5| Step: 2
Training loss: 1.6886675292573983
Validation loss: 2.5020063834769743

Epoch: 5| Step: 3
Training loss: 2.41066436110375
Validation loss: 2.451017320943465

Epoch: 5| Step: 4
Training loss: 2.1622021111618914
Validation loss: 2.4238003807710724

Epoch: 5| Step: 5
Training loss: 1.8565755333898055
Validation loss: 2.481145134637809

Epoch: 5| Step: 6
Training loss: 2.21191039769288
Validation loss: 2.412531132480977

Epoch: 5| Step: 7
Training loss: 2.018097300169558
Validation loss: 2.5177490697706575

Epoch: 5| Step: 8
Training loss: 2.057827946424623
Validation loss: 2.4383504371045155

Epoch: 5| Step: 9
Training loss: 2.0982103805737546
Validation loss: 2.446486421062553

Epoch: 5| Step: 10
Training loss: 2.307398969395472
Validation loss: 2.431608962526512

Epoch: 333| Step: 0
Training loss: 2.23871612318724
Validation loss: 2.4237318147471685

Epoch: 5| Step: 1
Training loss: 1.8752966328264145
Validation loss: 2.447326189579273

Epoch: 5| Step: 2
Training loss: 2.0350576072993256
Validation loss: 2.4254113817074856

Epoch: 5| Step: 3
Training loss: 2.647249208410391
Validation loss: 2.351686508664084

Epoch: 5| Step: 4
Training loss: 2.1328572139314743
Validation loss: 2.3642651338989937

Epoch: 5| Step: 5
Training loss: 2.0645530192911274
Validation loss: 2.468243822361714

Epoch: 5| Step: 6
Training loss: 2.9659814071741306
Validation loss: 2.3816351413548467

Epoch: 5| Step: 7
Training loss: 1.9115370925629187
Validation loss: 2.4444119413824565

Epoch: 5| Step: 8
Training loss: 2.098406723148979
Validation loss: 2.4311276130547137

Epoch: 5| Step: 9
Training loss: 2.096204315579426
Validation loss: 2.5044805553357206

Epoch: 5| Step: 10
Training loss: 1.8418263243892614
Validation loss: 2.37041681196572

Epoch: 334| Step: 0
Training loss: 1.6752657864488165
Validation loss: 2.447479093388749

Epoch: 5| Step: 1
Training loss: 1.892491640805689
Validation loss: 2.463996446841192

Epoch: 5| Step: 2
Training loss: 1.9153272537407593
Validation loss: 2.4001801057031056

Epoch: 5| Step: 3
Training loss: 2.212150537511033
Validation loss: 2.346799890460452

Epoch: 5| Step: 4
Training loss: 2.596194482686371
Validation loss: 2.4209398605813033

Epoch: 5| Step: 5
Training loss: 2.6890061172523585
Validation loss: 2.5001249415443025

Epoch: 5| Step: 6
Training loss: 1.742757524372603
Validation loss: 2.401543449479854

Epoch: 5| Step: 7
Training loss: 2.431953379422611
Validation loss: 2.411260753351106

Epoch: 5| Step: 8
Training loss: 2.142106038109089
Validation loss: 2.44335632174513

Epoch: 5| Step: 9
Training loss: 2.093010045719598
Validation loss: 2.4087605233297853

Epoch: 5| Step: 10
Training loss: 2.34265121134764
Validation loss: 2.471558963125437

Epoch: 335| Step: 0
Training loss: 1.8373074229526118
Validation loss: 2.4099956706329895

Epoch: 5| Step: 1
Training loss: 2.5195837680754662
Validation loss: 2.4595817877490602

Epoch: 5| Step: 2
Training loss: 2.3842778937288176
Validation loss: 2.4771145932790843

Epoch: 5| Step: 3
Training loss: 1.8440179145257232
Validation loss: 2.4528684213460297

Epoch: 5| Step: 4
Training loss: 1.7885007017847165
Validation loss: 2.4806164381756948

Epoch: 5| Step: 5
Training loss: 2.4233997098532964
Validation loss: 2.4079492186929343

Epoch: 5| Step: 6
Training loss: 2.312099215856894
Validation loss: 2.520294259105426

Epoch: 5| Step: 7
Training loss: 2.3112535983976223
Validation loss: 2.3843605288894567

Epoch: 5| Step: 8
Training loss: 1.8870450639989025
Validation loss: 2.4259115178226747

Epoch: 5| Step: 9
Training loss: 1.9581393761324737
Validation loss: 2.4149450270024886

Epoch: 5| Step: 10
Training loss: 2.47842077580284
Validation loss: 2.4363306825697495

Epoch: 336| Step: 0
Training loss: 2.030538111430725
Validation loss: 2.4009476748433176

Epoch: 5| Step: 1
Training loss: 2.2764533839522962
Validation loss: 2.501878483863747

Epoch: 5| Step: 2
Training loss: 1.9113315328867406
Validation loss: 2.463087290321916

Epoch: 5| Step: 3
Training loss: 3.0839877765774464
Validation loss: 2.4279536648312123

Epoch: 5| Step: 4
Training loss: 2.100406598283483
Validation loss: 2.4521084992842095

Epoch: 5| Step: 5
Training loss: 1.8656263648560099
Validation loss: 2.4091237634299074

Epoch: 5| Step: 6
Training loss: 2.351077818743999
Validation loss: 2.42229229695809

Epoch: 5| Step: 7
Training loss: 2.405171040977885
Validation loss: 2.3837181926647104

Epoch: 5| Step: 8
Training loss: 1.6585289013943212
Validation loss: 2.359158824461461

Epoch: 5| Step: 9
Training loss: 1.8624261777443978
Validation loss: 2.4319077744114215

Epoch: 5| Step: 10
Training loss: 2.030256057525418
Validation loss: 2.392408849250004

Epoch: 337| Step: 0
Training loss: 2.6766473635321506
Validation loss: 2.4201817653901236

Epoch: 5| Step: 1
Training loss: 2.179202883864972
Validation loss: 2.4436329878038263

Epoch: 5| Step: 2
Training loss: 2.337979855981723
Validation loss: 2.388216898424793

Epoch: 5| Step: 3
Training loss: 2.352043837651288
Validation loss: 2.4348629416511756

Epoch: 5| Step: 4
Training loss: 1.3927874093537818
Validation loss: 2.4577880874851523

Epoch: 5| Step: 5
Training loss: 1.7907668079192944
Validation loss: 2.4321288656682016

Epoch: 5| Step: 6
Training loss: 2.2286845485043285
Validation loss: 2.4205959693871697

Epoch: 5| Step: 7
Training loss: 2.1676876401364185
Validation loss: 2.328589513697546

Epoch: 5| Step: 8
Training loss: 2.5875621659187042
Validation loss: 2.413964169950765

Epoch: 5| Step: 9
Training loss: 1.8264204376293631
Validation loss: 2.424305731600725

Epoch: 5| Step: 10
Training loss: 1.975468449627643
Validation loss: 2.489000073364559

Epoch: 338| Step: 0
Training loss: 1.5306206791833505
Validation loss: 2.400199814266925

Epoch: 5| Step: 1
Training loss: 1.5692469079639115
Validation loss: 2.44718059363952

Epoch: 5| Step: 2
Training loss: 2.755851069707542
Validation loss: 2.4406661197508814

Epoch: 5| Step: 3
Training loss: 1.9630940042530571
Validation loss: 2.4119443982737256

Epoch: 5| Step: 4
Training loss: 2.1810106206230424
Validation loss: 2.4332238439312555

Epoch: 5| Step: 5
Training loss: 2.212178451534669
Validation loss: 2.418887304811846

Epoch: 5| Step: 6
Training loss: 2.485726043128409
Validation loss: 2.428140222041365

Epoch: 5| Step: 7
Training loss: 1.642675299383884
Validation loss: 2.4255576755700807

Epoch: 5| Step: 8
Training loss: 1.9989594494483724
Validation loss: 2.449319904803812

Epoch: 5| Step: 9
Training loss: 2.153568535508863
Validation loss: 2.4800003758065334

Epoch: 5| Step: 10
Training loss: 2.8862396792511853
Validation loss: 2.454053387634802

Epoch: 339| Step: 0
Training loss: 2.1299459455911403
Validation loss: 2.4515640792831657

Epoch: 5| Step: 1
Training loss: 1.9979179989595184
Validation loss: 2.4460945366279883

Epoch: 5| Step: 2
Training loss: 1.8940668854429012
Validation loss: 2.439080766207146

Epoch: 5| Step: 3
Training loss: 2.409307345814701
Validation loss: 2.4550679396611406

Epoch: 5| Step: 4
Training loss: 2.049161958361979
Validation loss: 2.5036712567440635

Epoch: 5| Step: 5
Training loss: 1.9561051482663754
Validation loss: 2.3875055283947013

Epoch: 5| Step: 6
Training loss: 2.683129060761271
Validation loss: 2.4688812507578266

Epoch: 5| Step: 7
Training loss: 1.7834017957338877
Validation loss: 2.457748333747807

Epoch: 5| Step: 8
Training loss: 1.8651572965504126
Validation loss: 2.373112749598006

Epoch: 5| Step: 9
Training loss: 2.7574842219796203
Validation loss: 2.4378058528508366

Epoch: 5| Step: 10
Training loss: 2.0402531563998885
Validation loss: 2.433862353491856

Epoch: 340| Step: 0
Training loss: 2.2362255622633027
Validation loss: 2.425088454412401

Epoch: 5| Step: 1
Training loss: 2.041295958618894
Validation loss: 2.493385825350122

Epoch: 5| Step: 2
Training loss: 2.135271827313744
Validation loss: 2.4058337704608217

Epoch: 5| Step: 3
Training loss: 2.103540220267364
Validation loss: 2.349809876472363

Epoch: 5| Step: 4
Training loss: 2.2135100478363676
Validation loss: 2.4688198058442583

Epoch: 5| Step: 5
Training loss: 1.4032510781514225
Validation loss: 2.38196256969845

Epoch: 5| Step: 6
Training loss: 1.8974914705388854
Validation loss: 2.3579107352111905

Epoch: 5| Step: 7
Training loss: 2.0580657918958694
Validation loss: 2.4345751489960676

Epoch: 5| Step: 8
Training loss: 2.747484617320379
Validation loss: 2.412260384391396

Epoch: 5| Step: 9
Training loss: 2.325793231475793
Validation loss: 2.4171560051603835

Epoch: 5| Step: 10
Training loss: 1.8643767457315097
Validation loss: 2.381230024609746

Epoch: 341| Step: 0
Training loss: 1.9032998942674038
Validation loss: 2.442251861284525

Epoch: 5| Step: 1
Training loss: 2.094313133006732
Validation loss: 2.4147868580492737

Epoch: 5| Step: 2
Training loss: 2.1994403300619294
Validation loss: 2.466385031158819

Epoch: 5| Step: 3
Training loss: 1.8934171251887117
Validation loss: 2.339787035384552

Epoch: 5| Step: 4
Training loss: 2.0503494244020937
Validation loss: 2.4021114626236755

Epoch: 5| Step: 5
Training loss: 1.6761532528442211
Validation loss: 2.387300870704977

Epoch: 5| Step: 6
Training loss: 2.8331651824720483
Validation loss: 2.411700564498861

Epoch: 5| Step: 7
Training loss: 2.5611342535492687
Validation loss: 2.4390528433651024

Epoch: 5| Step: 8
Training loss: 1.898818115258216
Validation loss: 2.4932115927034704

Epoch: 5| Step: 9
Training loss: 1.94452875121076
Validation loss: 2.4461575983085493

Epoch: 5| Step: 10
Training loss: 2.607144893264722
Validation loss: 2.439490746162913

Epoch: 342| Step: 0
Training loss: 2.2804071619983586
Validation loss: 2.452307815878345

Epoch: 5| Step: 1
Training loss: 2.053295055296838
Validation loss: 2.4921608500817842

Epoch: 5| Step: 2
Training loss: 1.8954727193186918
Validation loss: 2.510894742804156

Epoch: 5| Step: 3
Training loss: 2.3661645876083632
Validation loss: 2.469280536385962

Epoch: 5| Step: 4
Training loss: 2.6479494438473767
Validation loss: 2.4500620196045197

Epoch: 5| Step: 5
Training loss: 1.9618359213610421
Validation loss: 2.4266436683555948

Epoch: 5| Step: 6
Training loss: 2.171880818091634
Validation loss: 2.443307265593779

Epoch: 5| Step: 7
Training loss: 2.248945306902487
Validation loss: 2.4450862763759162

Epoch: 5| Step: 8
Training loss: 1.897682008219037
Validation loss: 2.405868425440433

Epoch: 5| Step: 9
Training loss: 2.1917511095766704
Validation loss: 2.4383827253938737

Epoch: 5| Step: 10
Training loss: 1.842720261429701
Validation loss: 2.335819324941061

Epoch: 343| Step: 0
Training loss: 2.243748138341955
Validation loss: 2.464048300788214

Epoch: 5| Step: 1
Training loss: 1.7573253719562416
Validation loss: 2.520635385723877

Epoch: 5| Step: 2
Training loss: 2.442897591379502
Validation loss: 2.4854746849875067

Epoch: 5| Step: 3
Training loss: 2.2912926339752584
Validation loss: 2.3981331311499345

Epoch: 5| Step: 4
Training loss: 2.1581266778032955
Validation loss: 2.425830916317577

Epoch: 5| Step: 5
Training loss: 1.558586636864055
Validation loss: 2.388289121454983

Epoch: 5| Step: 6
Training loss: 1.7816969996630736
Validation loss: 2.4225080580349663

Epoch: 5| Step: 7
Training loss: 2.8752600510785324
Validation loss: 2.407627575429472

Epoch: 5| Step: 8
Training loss: 2.2897447213891855
Validation loss: 2.4089019963982214

Epoch: 5| Step: 9
Training loss: 1.577475083482325
Validation loss: 2.389037974169001

Epoch: 5| Step: 10
Training loss: 2.1682029803788057
Validation loss: 2.4412286346471617

Epoch: 344| Step: 0
Training loss: 2.297993186674982
Validation loss: 2.36669112875586

Epoch: 5| Step: 1
Training loss: 2.133661345755882
Validation loss: 2.4898589868008307

Epoch: 5| Step: 2
Training loss: 2.964307171059459
Validation loss: 2.3870441149270594

Epoch: 5| Step: 3
Training loss: 2.046226340444313
Validation loss: 2.3812176339475535

Epoch: 5| Step: 4
Training loss: 2.316815962429012
Validation loss: 2.414518660552934

Epoch: 5| Step: 5
Training loss: 1.8268520781586046
Validation loss: 2.398300889570433

Epoch: 5| Step: 6
Training loss: 1.5272213625837059
Validation loss: 2.410900641415137

Epoch: 5| Step: 7
Training loss: 1.8209783948761482
Validation loss: 2.367950137910051

Epoch: 5| Step: 8
Training loss: 2.7481407469419104
Validation loss: 2.426819095401888

Epoch: 5| Step: 9
Training loss: 1.9481998448562834
Validation loss: 2.3831846665034884

Epoch: 5| Step: 10
Training loss: 2.1181807211770005
Validation loss: 2.3462082023480804

Epoch: 345| Step: 0
Training loss: 2.0471138851164277
Validation loss: 2.4212365501423654

Epoch: 5| Step: 1
Training loss: 2.224718689011997
Validation loss: 2.473091369601099

Epoch: 5| Step: 2
Training loss: 1.777022984662494
Validation loss: 2.4193859847603676

Epoch: 5| Step: 3
Training loss: 1.7968822976669065
Validation loss: 2.382321233083589

Epoch: 5| Step: 4
Training loss: 2.4848194804334978
Validation loss: 2.416307001078939

Epoch: 5| Step: 5
Training loss: 2.879875692757815
Validation loss: 2.3919457879395387

Epoch: 5| Step: 6
Training loss: 2.186051134123957
Validation loss: 2.4619196710437525

Epoch: 5| Step: 7
Training loss: 1.9191402423655608
Validation loss: 2.451063194818556

Epoch: 5| Step: 8
Training loss: 1.9189350001710823
Validation loss: 2.4073913332787544

Epoch: 5| Step: 9
Training loss: 2.738219691739637
Validation loss: 2.469426293120705

Epoch: 5| Step: 10
Training loss: 1.2916126803939638
Validation loss: 2.4599759714650657

Epoch: 346| Step: 0
Training loss: 1.5316779647980512
Validation loss: 2.3774693146037014

Epoch: 5| Step: 1
Training loss: 2.65160888919028
Validation loss: 2.4197190770408326

Epoch: 5| Step: 2
Training loss: 1.955293534918346
Validation loss: 2.485106886860595

Epoch: 5| Step: 3
Training loss: 1.3117337033462881
Validation loss: 2.4626438083261513

Epoch: 5| Step: 4
Training loss: 2.229451443554279
Validation loss: 2.4699148906233086

Epoch: 5| Step: 5
Training loss: 2.4674187463061075
Validation loss: 2.3879601853134567

Epoch: 5| Step: 6
Training loss: 1.9890584869224417
Validation loss: 2.518131000233298

Epoch: 5| Step: 7
Training loss: 2.6726501411249974
Validation loss: 2.435111142340211

Epoch: 5| Step: 8
Training loss: 2.050850887024536
Validation loss: 2.407901701505588

Epoch: 5| Step: 9
Training loss: 1.9311293801969076
Validation loss: 2.458097875650213

Epoch: 5| Step: 10
Training loss: 2.2682183517624517
Validation loss: 2.3866518975061735

Epoch: 347| Step: 0
Training loss: 1.686970804383564
Validation loss: 2.418975527708943

Epoch: 5| Step: 1
Training loss: 2.0955048224635555
Validation loss: 2.4116616307020133

Epoch: 5| Step: 2
Training loss: 2.2556997795953486
Validation loss: 2.414047209834661

Epoch: 5| Step: 3
Training loss: 2.546078235523938
Validation loss: 2.344237707114039

Epoch: 5| Step: 4
Training loss: 1.7630090830499154
Validation loss: 2.409220175614441

Epoch: 5| Step: 5
Training loss: 2.013610542909941
Validation loss: 2.4114175525201595

Epoch: 5| Step: 6
Training loss: 2.0288609466959118
Validation loss: 2.429693660906986

Epoch: 5| Step: 7
Training loss: 3.0023994387033794
Validation loss: 2.4672053884018927

Epoch: 5| Step: 8
Training loss: 2.130716152954891
Validation loss: 2.448994345424253

Epoch: 5| Step: 9
Training loss: 1.9612821602843777
Validation loss: 2.476441184453921

Epoch: 5| Step: 10
Training loss: 2.1882266336398746
Validation loss: 2.4126397579244756

Epoch: 348| Step: 0
Training loss: 2.2303757522890457
Validation loss: 2.3861093797360327

Epoch: 5| Step: 1
Training loss: 1.5825923725184925
Validation loss: 2.4807163245780033

Epoch: 5| Step: 2
Training loss: 2.0628293092410046
Validation loss: 2.3827388284699813

Epoch: 5| Step: 3
Training loss: 1.5772487360474121
Validation loss: 2.426733920184271

Epoch: 5| Step: 4
Training loss: 2.2034718125533264
Validation loss: 2.3384947226809425

Epoch: 5| Step: 5
Training loss: 2.68327585083737
Validation loss: 2.4867716053157536

Epoch: 5| Step: 6
Training loss: 1.9694025683856857
Validation loss: 2.470085918638837

Epoch: 5| Step: 7
Training loss: 2.186115916935013
Validation loss: 2.373110979008484

Epoch: 5| Step: 8
Training loss: 1.8051139030551313
Validation loss: 2.4609822128721217

Epoch: 5| Step: 9
Training loss: 2.816778531383119
Validation loss: 2.420652179132638

Epoch: 5| Step: 10
Training loss: 1.8697618430760101
Validation loss: 2.4452384343338744

Epoch: 349| Step: 0
Training loss: 1.8906439788117988
Validation loss: 2.4250464361895525

Epoch: 5| Step: 1
Training loss: 2.2039835454184638
Validation loss: 2.3557456889448973

Epoch: 5| Step: 2
Training loss: 2.354094501390773
Validation loss: 2.4675648831382846

Epoch: 5| Step: 3
Training loss: 2.2797619917937255
Validation loss: 2.4087547739814767

Epoch: 5| Step: 4
Training loss: 1.9960785807352301
Validation loss: 2.427390288873703

Epoch: 5| Step: 5
Training loss: 2.055003790933124
Validation loss: 2.4215880849558777

Epoch: 5| Step: 6
Training loss: 1.8225987693071684
Validation loss: 2.4540268971148986

Epoch: 5| Step: 7
Training loss: 2.174819487173207
Validation loss: 2.4692049563938303

Epoch: 5| Step: 8
Training loss: 1.7733003672544825
Validation loss: 2.36577028861774

Epoch: 5| Step: 9
Training loss: 2.730729468563475
Validation loss: 2.4224775365986795

Epoch: 5| Step: 10
Training loss: 2.406280715548176
Validation loss: 2.4357187574417987

Epoch: 350| Step: 0
Training loss: 1.8906651642371495
Validation loss: 2.4017157095766817

Epoch: 5| Step: 1
Training loss: 1.5976356560981702
Validation loss: 2.3711500050180785

Epoch: 5| Step: 2
Training loss: 2.1304634768424613
Validation loss: 2.4372772249618375

Epoch: 5| Step: 3
Training loss: 1.8653320286936874
Validation loss: 2.4034901445225905

Epoch: 5| Step: 4
Training loss: 1.8797765290572004
Validation loss: 2.3743711922577755

Epoch: 5| Step: 5
Training loss: 1.8755175829810407
Validation loss: 2.4371334743776143

Epoch: 5| Step: 6
Training loss: 2.799171740781049
Validation loss: 2.3973363360892352

Epoch: 5| Step: 7
Training loss: 2.4407345755739396
Validation loss: 2.419252444018044

Epoch: 5| Step: 8
Training loss: 2.9078312335674084
Validation loss: 2.3787051941539845

Epoch: 5| Step: 9
Training loss: 1.7403049304843434
Validation loss: 2.4166450193649904

Epoch: 5| Step: 10
Training loss: 2.1393620461716174
Validation loss: 2.412346165223075

Epoch: 351| Step: 0
Training loss: 1.828553565238228
Validation loss: 2.4034316571525993

Epoch: 5| Step: 1
Training loss: 2.0333172182580603
Validation loss: 2.356924148129662

Epoch: 5| Step: 2
Training loss: 1.9043082681950845
Validation loss: 2.4076148089820344

Epoch: 5| Step: 3
Training loss: 1.928506157542559
Validation loss: 2.417194681826231

Epoch: 5| Step: 4
Training loss: 1.6280848492670656
Validation loss: 2.4580927717731424

Epoch: 5| Step: 5
Training loss: 2.610846555668037
Validation loss: 2.406393423761565

Epoch: 5| Step: 6
Training loss: 1.9705676210847416
Validation loss: 2.393715563871025

Epoch: 5| Step: 7
Training loss: 2.364963204095589
Validation loss: 2.4347500545830214

Epoch: 5| Step: 8
Training loss: 2.0990109748644286
Validation loss: 2.4567578855220193

Epoch: 5| Step: 9
Training loss: 2.975608692889689
Validation loss: 2.453900575877909

Epoch: 5| Step: 10
Training loss: 1.8603513061843655
Validation loss: 2.4209379851900974

Epoch: 352| Step: 0
Training loss: 2.601055290564342
Validation loss: 2.3953399585349033

Epoch: 5| Step: 1
Training loss: 1.6124021337810641
Validation loss: 2.3745306406135582

Epoch: 5| Step: 2
Training loss: 1.8430759038171611
Validation loss: 2.3707550337227583

Epoch: 5| Step: 3
Training loss: 2.1132127676707175
Validation loss: 2.4628631303232016

Epoch: 5| Step: 4
Training loss: 2.2347867359590503
Validation loss: 2.356477505129916

Epoch: 5| Step: 5
Training loss: 2.143927039129104
Validation loss: 2.367589849696355

Epoch: 5| Step: 6
Training loss: 2.037392352484279
Validation loss: 2.43593083187048

Epoch: 5| Step: 7
Training loss: 2.2999242148145624
Validation loss: 2.472420629944887

Epoch: 5| Step: 8
Training loss: 1.7599042187984215
Validation loss: 2.456900216607762

Epoch: 5| Step: 9
Training loss: 2.6853489806348505
Validation loss: 2.455534276050486

Epoch: 5| Step: 10
Training loss: 2.255622303052872
Validation loss: 2.400591760192904

Epoch: 353| Step: 0
Training loss: 1.957490543522897
Validation loss: 2.426665192481013

Epoch: 5| Step: 1
Training loss: 2.188578312630731
Validation loss: 2.4012285097161583

Epoch: 5| Step: 2
Training loss: 2.1746696221249486
Validation loss: 2.4442430647799203

Epoch: 5| Step: 3
Training loss: 1.9807338800473688
Validation loss: 2.405248677870781

Epoch: 5| Step: 4
Training loss: 1.8343372269596676
Validation loss: 2.480362887324171

Epoch: 5| Step: 5
Training loss: 2.6168719201061856
Validation loss: 2.409751120509463

Epoch: 5| Step: 6
Training loss: 1.9306738799660292
Validation loss: 2.392988339304049

Epoch: 5| Step: 7
Training loss: 1.7809580513470717
Validation loss: 2.3705501730368628

Epoch: 5| Step: 8
Training loss: 2.2171676796154256
Validation loss: 2.3964788614989847

Epoch: 5| Step: 9
Training loss: 2.310277541030375
Validation loss: 2.407953312296648

Epoch: 5| Step: 10
Training loss: 2.222465091255236
Validation loss: 2.4071979719608785

Epoch: 354| Step: 0
Training loss: 1.9304097171589467
Validation loss: 2.38147177442546

Epoch: 5| Step: 1
Training loss: 2.8210689132640856
Validation loss: 2.494442160870321

Epoch: 5| Step: 2
Training loss: 2.403281126667791
Validation loss: 2.4178088861907443

Epoch: 5| Step: 3
Training loss: 2.0776029232158812
Validation loss: 2.3918882149543084

Epoch: 5| Step: 4
Training loss: 2.0090508705333034
Validation loss: 2.4472565563162103

Epoch: 5| Step: 5
Training loss: 2.083897654079543
Validation loss: 2.3582387316543065

Epoch: 5| Step: 6
Training loss: 2.039234841031665
Validation loss: 2.3531471816064173

Epoch: 5| Step: 7
Training loss: 1.9116416101828477
Validation loss: 2.4100524834267643

Epoch: 5| Step: 8
Training loss: 2.402412326733357
Validation loss: 2.47047801437006

Epoch: 5| Step: 9
Training loss: 2.117190990937793
Validation loss: 2.4558408392062256

Epoch: 5| Step: 10
Training loss: 1.9378343109148517
Validation loss: 2.3955643695949367

Epoch: 355| Step: 0
Training loss: 1.6226439635794703
Validation loss: 2.399110426634384

Epoch: 5| Step: 1
Training loss: 1.9552587221860984
Validation loss: 2.4071477880661574

Epoch: 5| Step: 2
Training loss: 2.350174199404718
Validation loss: 2.4319526734063777

Epoch: 5| Step: 3
Training loss: 2.0617302122733427
Validation loss: 2.484432738578615

Epoch: 5| Step: 4
Training loss: 2.8057037467553276
Validation loss: 2.4353200826603447

Epoch: 5| Step: 5
Training loss: 2.3459265203131356
Validation loss: 2.368029030833239

Epoch: 5| Step: 6
Training loss: 2.0481566864440186
Validation loss: 2.422685351179803

Epoch: 5| Step: 7
Training loss: 1.811750256921185
Validation loss: 2.410756174608956

Epoch: 5| Step: 8
Training loss: 2.454174619013062
Validation loss: 2.437499856961995

Epoch: 5| Step: 9
Training loss: 1.9670503333691205
Validation loss: 2.4559783132337887

Epoch: 5| Step: 10
Training loss: 1.555946109010102
Validation loss: 2.4451599031545026

Epoch: 356| Step: 0
Training loss: 2.7677483462560546
Validation loss: 2.392298034252048

Epoch: 5| Step: 1
Training loss: 1.9549253177280934
Validation loss: 2.438832829701535

Epoch: 5| Step: 2
Training loss: 1.935362467367918
Validation loss: 2.4274799315653763

Epoch: 5| Step: 3
Training loss: 2.114961023535185
Validation loss: 2.420147164949152

Epoch: 5| Step: 4
Training loss: 1.8618633385402235
Validation loss: 2.377045052637076

Epoch: 5| Step: 5
Training loss: 1.9443755440387804
Validation loss: 2.465914083797697

Epoch: 5| Step: 6
Training loss: 1.7013365428250533
Validation loss: 2.413652068091942

Epoch: 5| Step: 7
Training loss: 2.005837147857923
Validation loss: 2.3944006582484922

Epoch: 5| Step: 8
Training loss: 2.969251088467795
Validation loss: 2.411394320979458

Epoch: 5| Step: 9
Training loss: 1.855771459682277
Validation loss: 2.4936424377947977

Epoch: 5| Step: 10
Training loss: 1.8693625578471031
Validation loss: 2.331643043504594

Epoch: 357| Step: 0
Training loss: 2.072837930330951
Validation loss: 2.4106455144249366

Epoch: 5| Step: 1
Training loss: 2.4454193579387646
Validation loss: 2.418199783434366

Epoch: 5| Step: 2
Training loss: 2.3345865789533073
Validation loss: 2.386442633808736

Epoch: 5| Step: 3
Training loss: 2.446421119034189
Validation loss: 2.4306676801454703

Epoch: 5| Step: 4
Training loss: 2.149552933099072
Validation loss: 2.4368040817846164

Epoch: 5| Step: 5
Training loss: 1.5911912760720281
Validation loss: 2.453966928324279

Epoch: 5| Step: 6
Training loss: 1.8347265917122528
Validation loss: 2.4147382927194703

Epoch: 5| Step: 7
Training loss: 1.8958346887381043
Validation loss: 2.433569864224885

Epoch: 5| Step: 8
Training loss: 1.8678520648015133
Validation loss: 2.3609930709473326

Epoch: 5| Step: 9
Training loss: 1.7845789270066788
Validation loss: 2.3841263028301793

Epoch: 5| Step: 10
Training loss: 2.048899806598768
Validation loss: 2.4786817042377236

Epoch: 358| Step: 0
Training loss: 1.8889223108264381
Validation loss: 2.409741185089557

Epoch: 5| Step: 1
Training loss: 1.9116163543603446
Validation loss: 2.3980627044671157

Epoch: 5| Step: 2
Training loss: 2.1677438430285156
Validation loss: 2.390671394675962

Epoch: 5| Step: 3
Training loss: 2.023204657512838
Validation loss: 2.3847106753649325

Epoch: 5| Step: 4
Training loss: 1.9276434694323952
Validation loss: 2.4246986846414016

Epoch: 5| Step: 5
Training loss: 2.1033426566101214
Validation loss: 2.3681286262556305

Epoch: 5| Step: 6
Training loss: 1.598835479622484
Validation loss: 2.3962230377911684

Epoch: 5| Step: 7
Training loss: 2.3978809618066177
Validation loss: 2.3868131263612655

Epoch: 5| Step: 8
Training loss: 1.9965230998845975
Validation loss: 2.354831657899195

Epoch: 5| Step: 9
Training loss: 2.5094911655316885
Validation loss: 2.434427947993014

Epoch: 5| Step: 10
Training loss: 2.3752915052909658
Validation loss: 2.4140056923737485

Epoch: 359| Step: 0
Training loss: 2.041838061346249
Validation loss: 2.3753549238282066

Epoch: 5| Step: 1
Training loss: 1.930386497755292
Validation loss: 2.3660115420085686

Epoch: 5| Step: 2
Training loss: 2.0503457033770998
Validation loss: 2.369813024908506

Epoch: 5| Step: 3
Training loss: 2.283729773120222
Validation loss: 2.479562415177917

Epoch: 5| Step: 4
Training loss: 1.7682856539962735
Validation loss: 2.488670297714831

Epoch: 5| Step: 5
Training loss: 1.7954031845841323
Validation loss: 2.37545983267622

Epoch: 5| Step: 6
Training loss: 1.4022785904816422
Validation loss: 2.409605860251289

Epoch: 5| Step: 7
Training loss: 2.261138578066362
Validation loss: 2.360926352174269

Epoch: 5| Step: 8
Training loss: 2.0505162821757885
Validation loss: 2.4518604947595475

Epoch: 5| Step: 9
Training loss: 2.4709692528979574
Validation loss: 2.373457629630359

Epoch: 5| Step: 10
Training loss: 2.4618825883983253
Validation loss: 2.489427612544893

Epoch: 360| Step: 0
Training loss: 1.8006317010375477
Validation loss: 2.420858673131956

Epoch: 5| Step: 1
Training loss: 1.7443922658002249
Validation loss: 2.4220939883895083

Epoch: 5| Step: 2
Training loss: 2.265960352841195
Validation loss: 2.3869312309210504

Epoch: 5| Step: 3
Training loss: 1.8834587032934167
Validation loss: 2.458610281996273

Epoch: 5| Step: 4
Training loss: 2.1079641639660154
Validation loss: 2.37703542054328

Epoch: 5| Step: 5
Training loss: 2.691701930930159
Validation loss: 2.4044559003290558

Epoch: 5| Step: 6
Training loss: 2.235495546435905
Validation loss: 2.4305654263234926

Epoch: 5| Step: 7
Training loss: 2.4950387363828694
Validation loss: 2.428036073170239

Epoch: 5| Step: 8
Training loss: 1.945619735048929
Validation loss: 2.4764761847107093

Epoch: 5| Step: 9
Training loss: 2.2092632519034345
Validation loss: 2.3955179369800175

Epoch: 5| Step: 10
Training loss: 1.653444469136569
Validation loss: 2.385830261711713

Epoch: 361| Step: 0
Training loss: 2.25275792532422
Validation loss: 2.4727358176451455

Epoch: 5| Step: 1
Training loss: 2.0752505737127427
Validation loss: 2.410118995301856

Epoch: 5| Step: 2
Training loss: 2.350941826409341
Validation loss: 2.3313625310842925

Epoch: 5| Step: 3
Training loss: 2.3642950232318007
Validation loss: 2.351700037120645

Epoch: 5| Step: 4
Training loss: 1.8432643703416358
Validation loss: 2.4131377561240734

Epoch: 5| Step: 5
Training loss: 1.7248966932460668
Validation loss: 2.3661464656156257

Epoch: 5| Step: 6
Training loss: 1.858036232479021
Validation loss: 2.4115773106101903

Epoch: 5| Step: 7
Training loss: 2.1224976560042776
Validation loss: 2.359792449536507

Epoch: 5| Step: 8
Training loss: 2.6908468653422415
Validation loss: 2.4361236405375957

Epoch: 5| Step: 9
Training loss: 1.7174342581259106
Validation loss: 2.4781700354983776

Epoch: 5| Step: 10
Training loss: 2.1685499907068833
Validation loss: 2.3754744064006283

Epoch: 362| Step: 0
Training loss: 2.2910377911131974
Validation loss: 2.331935703140088

Epoch: 5| Step: 1
Training loss: 1.7510619347477432
Validation loss: 2.373546271469396

Epoch: 5| Step: 2
Training loss: 2.897681124722617
Validation loss: 2.4156643129294944

Epoch: 5| Step: 3
Training loss: 1.8086182034448037
Validation loss: 2.3991199829233683

Epoch: 5| Step: 4
Training loss: 2.2889339684344385
Validation loss: 2.448776444615811

Epoch: 5| Step: 5
Training loss: 1.5799448077303977
Validation loss: 2.4532130021628435

Epoch: 5| Step: 6
Training loss: 2.574243200993513
Validation loss: 2.4108248783849735

Epoch: 5| Step: 7
Training loss: 2.0720548387730506
Validation loss: 2.4656355353356902

Epoch: 5| Step: 8
Training loss: 1.8343934404268365
Validation loss: 2.418710600282542

Epoch: 5| Step: 9
Training loss: 2.271823690430578
Validation loss: 2.37814860781004

Epoch: 5| Step: 10
Training loss: 1.5878236575861728
Validation loss: 2.4262826908661497

Epoch: 363| Step: 0
Training loss: 2.169315064442212
Validation loss: 2.383168027738347

Epoch: 5| Step: 1
Training loss: 1.6641510416035017
Validation loss: 2.3579305665847246

Epoch: 5| Step: 2
Training loss: 2.0163671029335717
Validation loss: 2.4446883705267655

Epoch: 5| Step: 3
Training loss: 2.361024696663636
Validation loss: 2.4652278110729138

Epoch: 5| Step: 4
Training loss: 1.9563853402898232
Validation loss: 2.408102152917474

Epoch: 5| Step: 5
Training loss: 2.2072368154750914
Validation loss: 2.399080510491333

Epoch: 5| Step: 6
Training loss: 1.6822730458019335
Validation loss: 2.4549652213834916

Epoch: 5| Step: 7
Training loss: 2.6653142320839978
Validation loss: 2.3034345783118715

Epoch: 5| Step: 8
Training loss: 2.048597004585046
Validation loss: 2.4517467701020865

Epoch: 5| Step: 9
Training loss: 1.803969599626261
Validation loss: 2.391661629748871

Epoch: 5| Step: 10
Training loss: 2.2123757796249253
Validation loss: 2.36954459590805

Epoch: 364| Step: 0
Training loss: 2.164691929912481
Validation loss: 2.5224905733689553

Epoch: 5| Step: 1
Training loss: 1.910061200045195
Validation loss: 2.37641600714036

Epoch: 5| Step: 2
Training loss: 1.5677083755780423
Validation loss: 2.456513382077816

Epoch: 5| Step: 3
Training loss: 2.2873787269338863
Validation loss: 2.4412492987604635

Epoch: 5| Step: 4
Training loss: 1.7947435425343166
Validation loss: 2.41128519927229

Epoch: 5| Step: 5
Training loss: 1.8089294781115723
Validation loss: 2.3735862349569143

Epoch: 5| Step: 6
Training loss: 2.7245384945417355
Validation loss: 2.388733669754131

Epoch: 5| Step: 7
Training loss: 2.2704620291082955
Validation loss: 2.4116414013774325

Epoch: 5| Step: 8
Training loss: 1.9197880648825671
Validation loss: 2.4290754506659926

Epoch: 5| Step: 9
Training loss: 2.0153416870672585
Validation loss: 2.424049385256982

Epoch: 5| Step: 10
Training loss: 1.4978076490152152
Validation loss: 2.44363217893962

Epoch: 365| Step: 0
Training loss: 1.8844728232529593
Validation loss: 2.4069041724100346

Epoch: 5| Step: 1
Training loss: 1.81090784846758
Validation loss: 2.3935159555156305

Epoch: 5| Step: 2
Training loss: 2.075782086160798
Validation loss: 2.4791771586992284

Epoch: 5| Step: 3
Training loss: 2.1992465029332346
Validation loss: 2.407012006955893

Epoch: 5| Step: 4
Training loss: 1.9306977750992498
Validation loss: 2.4103856381353945

Epoch: 5| Step: 5
Training loss: 2.1240306213958973
Validation loss: 2.3487986037458546

Epoch: 5| Step: 6
Training loss: 2.648686400113966
Validation loss: 2.473155518577353

Epoch: 5| Step: 7
Training loss: 1.8057811775415453
Validation loss: 2.411651925324691

Epoch: 5| Step: 8
Training loss: 1.7018840363396042
Validation loss: 2.3774911437404436

Epoch: 5| Step: 9
Training loss: 2.278938167166737
Validation loss: 2.4007800933624845

Epoch: 5| Step: 10
Training loss: 2.4150622621649025
Validation loss: 2.48612683678631

Epoch: 366| Step: 0
Training loss: 1.8112024069062405
Validation loss: 2.3876172165008414

Epoch: 5| Step: 1
Training loss: 1.958336309336031
Validation loss: 2.4336236463926655

Epoch: 5| Step: 2
Training loss: 2.207621105669519
Validation loss: 2.4503541221707636

Epoch: 5| Step: 3
Training loss: 1.5785305899458444
Validation loss: 2.4313550974938627

Epoch: 5| Step: 4
Training loss: 1.9578474402449446
Validation loss: 2.435976798313416

Epoch: 5| Step: 5
Training loss: 2.264044690637986
Validation loss: 2.3941376415840017

Epoch: 5| Step: 6
Training loss: 2.038850269015386
Validation loss: 2.4067826136394337

Epoch: 5| Step: 7
Training loss: 2.6752936371400198
Validation loss: 2.4611747068749255

Epoch: 5| Step: 8
Training loss: 1.9670173044185346
Validation loss: 2.4407241906803345

Epoch: 5| Step: 9
Training loss: 1.9410330031751863
Validation loss: 2.4625825055162975

Epoch: 5| Step: 10
Training loss: 2.090701716773119
Validation loss: 2.453162981038054

Epoch: 367| Step: 0
Training loss: 2.190654768585071
Validation loss: 2.388551034794466

Epoch: 5| Step: 1
Training loss: 1.5311954255012812
Validation loss: 2.4512390524949117

Epoch: 5| Step: 2
Training loss: 2.0836641303334686
Validation loss: 2.4466591381341534

Epoch: 5| Step: 3
Training loss: 2.8611516383818145
Validation loss: 2.3823505612156812

Epoch: 5| Step: 4
Training loss: 2.228562912033911
Validation loss: 2.419763822647272

Epoch: 5| Step: 5
Training loss: 1.6817296588291895
Validation loss: 2.3737296197147635

Epoch: 5| Step: 6
Training loss: 2.122630312708148
Validation loss: 2.4025864067817353

Epoch: 5| Step: 7
Training loss: 2.2573367346850457
Validation loss: 2.433478429494062

Epoch: 5| Step: 8
Training loss: 1.6807054850357332
Validation loss: 2.424560406642227

Epoch: 5| Step: 9
Training loss: 1.9885947349451785
Validation loss: 2.525021829980822

Epoch: 5| Step: 10
Training loss: 1.9411937819948246
Validation loss: 2.35935013466005

Epoch: 368| Step: 0
Training loss: 1.7925096642993157
Validation loss: 2.3647156100570457

Epoch: 5| Step: 1
Training loss: 1.8525537340450922
Validation loss: 2.4532727176858633

Epoch: 5| Step: 2
Training loss: 2.301983608197432
Validation loss: 2.3799290934280872

Epoch: 5| Step: 3
Training loss: 2.125173786013289
Validation loss: 2.445685858662711

Epoch: 5| Step: 4
Training loss: 2.0924776680870147
Validation loss: 2.348522410947767

Epoch: 5| Step: 5
Training loss: 2.442098925174686
Validation loss: 2.417557591042885

Epoch: 5| Step: 6
Training loss: 2.1188020637889604
Validation loss: 2.4333047757964286

Epoch: 5| Step: 7
Training loss: 1.6203830861798647
Validation loss: 2.3723831569942204

Epoch: 5| Step: 8
Training loss: 1.505958247123966
Validation loss: 2.4185204282530215

Epoch: 5| Step: 9
Training loss: 2.4861922425494054
Validation loss: 2.3969671978836535

Epoch: 5| Step: 10
Training loss: 2.13169099155095
Validation loss: 2.4645180339520785

Epoch: 369| Step: 0
Training loss: 2.3781670986464496
Validation loss: 2.3471646041417813

Epoch: 5| Step: 1
Training loss: 1.7258854569920734
Validation loss: 2.4037348250237085

Epoch: 5| Step: 2
Training loss: 1.957909971156595
Validation loss: 2.4221483873497096

Epoch: 5| Step: 3
Training loss: 1.7769675726564234
Validation loss: 2.438278655489812

Epoch: 5| Step: 4
Training loss: 2.334768659906583
Validation loss: 2.480788568897102

Epoch: 5| Step: 5
Training loss: 2.354280339650224
Validation loss: 2.4013215674328974

Epoch: 5| Step: 6
Training loss: 2.233181401204303
Validation loss: 2.449316946899948

Epoch: 5| Step: 7
Training loss: 1.7524708606947588
Validation loss: 2.4025038350949153

Epoch: 5| Step: 8
Training loss: 1.6628930365822967
Validation loss: 2.451019151877591

Epoch: 5| Step: 9
Training loss: 2.279326163318682
Validation loss: 2.4269334710822985

Epoch: 5| Step: 10
Training loss: 2.2684509542644022
Validation loss: 2.441603963348418

Epoch: 370| Step: 0
Training loss: 1.3834950976793283
Validation loss: 2.364638572706465

Epoch: 5| Step: 1
Training loss: 2.0540452540834524
Validation loss: 2.4540039832844567

Epoch: 5| Step: 2
Training loss: 1.8269780139153504
Validation loss: 2.3555835710924486

Epoch: 5| Step: 3
Training loss: 2.3945031716721425
Validation loss: 2.5101697978484783

Epoch: 5| Step: 4
Training loss: 1.6834104221305535
Validation loss: 2.423282038585345

Epoch: 5| Step: 5
Training loss: 2.4861312512577096
Validation loss: 2.445225365724504

Epoch: 5| Step: 6
Training loss: 1.6624692354725914
Validation loss: 2.3822661797159377

Epoch: 5| Step: 7
Training loss: 2.0497044233905046
Validation loss: 2.4127123294280484

Epoch: 5| Step: 8
Training loss: 2.2163765260883603
Validation loss: 2.4005417713918353

Epoch: 5| Step: 9
Training loss: 2.7372815188660065
Validation loss: 2.4078717987658167

Epoch: 5| Step: 10
Training loss: 2.151579179332079
Validation loss: 2.418311634548855

Epoch: 371| Step: 0
Training loss: 2.015963976840958
Validation loss: 2.328000249422592

Epoch: 5| Step: 1
Training loss: 2.6855842504501455
Validation loss: 2.4793146292119834

Epoch: 5| Step: 2
Training loss: 1.7326659984247303
Validation loss: 2.416732970344087

Epoch: 5| Step: 3
Training loss: 1.8501034553056384
Validation loss: 2.430489398702469

Epoch: 5| Step: 4
Training loss: 2.4047079718736484
Validation loss: 2.3607540771116122

Epoch: 5| Step: 5
Training loss: 1.9732177539540976
Validation loss: 2.430431422878932

Epoch: 5| Step: 6
Training loss: 1.4841367028346162
Validation loss: 2.4438517825595514

Epoch: 5| Step: 7
Training loss: 2.0588215479320318
Validation loss: 2.4114555951199512

Epoch: 5| Step: 8
Training loss: 2.3562893932499955
Validation loss: 2.4406803461324795

Epoch: 5| Step: 9
Training loss: 1.4615704802237555
Validation loss: 2.372344024241256

Epoch: 5| Step: 10
Training loss: 2.1474903585197542
Validation loss: 2.397063874423488

Epoch: 372| Step: 0
Training loss: 2.192531684289874
Validation loss: 2.3847135102230173

Epoch: 5| Step: 1
Training loss: 2.1038287681480297
Validation loss: 2.3886163734094366

Epoch: 5| Step: 2
Training loss: 1.7656653745643036
Validation loss: 2.3980593273467194

Epoch: 5| Step: 3
Training loss: 2.2039397336193813
Validation loss: 2.4899019736017567

Epoch: 5| Step: 4
Training loss: 2.0452632236591786
Validation loss: 2.3642040431127977

Epoch: 5| Step: 5
Training loss: 1.7632780427443002
Validation loss: 2.359191820052557

Epoch: 5| Step: 6
Training loss: 1.7094292808157434
Validation loss: 2.449467905337051

Epoch: 5| Step: 7
Training loss: 2.3717755966566476
Validation loss: 2.3678366852094848

Epoch: 5| Step: 8
Training loss: 2.7115774141459608
Validation loss: 2.388998011079061

Epoch: 5| Step: 9
Training loss: 1.8849489745461165
Validation loss: 2.3927319377573606

Epoch: 5| Step: 10
Training loss: 1.7757965396033237
Validation loss: 2.4236983729683237

Epoch: 373| Step: 0
Training loss: 1.6786824612868
Validation loss: 2.3794124569911275

Epoch: 5| Step: 1
Training loss: 2.3141109937986712
Validation loss: 2.4322622591263596

Epoch: 5| Step: 2
Training loss: 2.5691284420681
Validation loss: 2.363713321835593

Epoch: 5| Step: 3
Training loss: 1.7113904658223291
Validation loss: 2.39314306731983

Epoch: 5| Step: 4
Training loss: 1.495699439613343
Validation loss: 2.398235650717986

Epoch: 5| Step: 5
Training loss: 1.5422726376733835
Validation loss: 2.4714889120512615

Epoch: 5| Step: 6
Training loss: 1.3385953286345216
Validation loss: 2.4073894313594777

Epoch: 5| Step: 7
Training loss: 1.9799412131974765
Validation loss: 2.39682765585094

Epoch: 5| Step: 8
Training loss: 2.1369720253083995
Validation loss: 2.3917655028574925

Epoch: 5| Step: 9
Training loss: 2.7823440457327457
Validation loss: 2.358218529993913

Epoch: 5| Step: 10
Training loss: 2.3903896240846683
Validation loss: 2.360479727119205

Epoch: 374| Step: 0
Training loss: 1.6515489474834943
Validation loss: 2.3699200851081104

Epoch: 5| Step: 1
Training loss: 1.8470460557549935
Validation loss: 2.4092990567954775

Epoch: 5| Step: 2
Training loss: 2.1108135827976953
Validation loss: 2.396402727567788

Epoch: 5| Step: 3
Training loss: 2.2732951850524312
Validation loss: 2.4096054075510316

Epoch: 5| Step: 4
Training loss: 1.7244424361135864
Validation loss: 2.3685262219310523

Epoch: 5| Step: 5
Training loss: 1.8998529628276475
Validation loss: 2.41537548359362

Epoch: 5| Step: 6
Training loss: 1.732378592482677
Validation loss: 2.357491780208461

Epoch: 5| Step: 7
Training loss: 2.646424375184709
Validation loss: 2.408153846707002

Epoch: 5| Step: 8
Training loss: 2.1564308864628194
Validation loss: 2.450872550441913

Epoch: 5| Step: 9
Training loss: 1.9835303003080116
Validation loss: 2.427605433164872

Epoch: 5| Step: 10
Training loss: 1.9277026512990953
Validation loss: 2.3990627439983605

Epoch: 375| Step: 0
Training loss: 1.9176443412197768
Validation loss: 2.370171949797394

Epoch: 5| Step: 1
Training loss: 1.6523704436470443
Validation loss: 2.36327670096998

Epoch: 5| Step: 2
Training loss: 2.7225093063041306
Validation loss: 2.347716912000514

Epoch: 5| Step: 3
Training loss: 1.9288316442647644
Validation loss: 2.3825650725999754

Epoch: 5| Step: 4
Training loss: 1.7436515917064677
Validation loss: 2.441512945522233

Epoch: 5| Step: 5
Training loss: 2.2673995861964618
Validation loss: 2.409606781610422

Epoch: 5| Step: 6
Training loss: 1.8470329539855321
Validation loss: 2.3148583124601907

Epoch: 5| Step: 7
Training loss: 2.3430787206003507
Validation loss: 2.3929467023439015

Epoch: 5| Step: 8
Training loss: 2.0731040703743706
Validation loss: 2.43200783824602

Epoch: 5| Step: 9
Training loss: 1.5460803370113216
Validation loss: 2.4092720827036866

Epoch: 5| Step: 10
Training loss: 1.698936140740711
Validation loss: 2.352923326726963

Epoch: 376| Step: 0
Training loss: 1.7662046038172265
Validation loss: 2.3681357570656947

Epoch: 5| Step: 1
Training loss: 1.6822919658585824
Validation loss: 2.3915927769072947

Epoch: 5| Step: 2
Training loss: 1.5679532828183467
Validation loss: 2.4412827631740486

Epoch: 5| Step: 3
Training loss: 2.810468575856212
Validation loss: 2.4750115483092157

Epoch: 5| Step: 4
Training loss: 1.910785033287541
Validation loss: 2.452873530084137

Epoch: 5| Step: 5
Training loss: 2.199658094194132
Validation loss: 2.3458945872358536

Epoch: 5| Step: 6
Training loss: 2.3693105914982096
Validation loss: 2.477459831241213

Epoch: 5| Step: 7
Training loss: 1.6654681505852982
Validation loss: 2.378197932197963

Epoch: 5| Step: 8
Training loss: 2.250663871312929
Validation loss: 2.4925267870707697

Epoch: 5| Step: 9
Training loss: 2.0849772897119294
Validation loss: 2.4396781938742995

Epoch: 5| Step: 10
Training loss: 1.7554764208012759
Validation loss: 2.3254292923934616

Epoch: 377| Step: 0
Training loss: 2.125561023030902
Validation loss: 2.388899100066322

Epoch: 5| Step: 1
Training loss: 1.7378055221562954
Validation loss: 2.4230597925442674

Epoch: 5| Step: 2
Training loss: 1.9654410271600358
Validation loss: 2.3840399114750044

Epoch: 5| Step: 3
Training loss: 2.3014886931001364
Validation loss: 2.3370057770277155

Epoch: 5| Step: 4
Training loss: 2.2241626321073062
Validation loss: 2.291097126848357

Epoch: 5| Step: 5
Training loss: 2.042292466563478
Validation loss: 2.39126495132458

Epoch: 5| Step: 6
Training loss: 2.19621676355267
Validation loss: 2.4233791257411768

Epoch: 5| Step: 7
Training loss: 2.1161476199716596
Validation loss: 2.4289854774014445

Epoch: 5| Step: 8
Training loss: 2.4607752186386835
Validation loss: 2.423524718241322

Epoch: 5| Step: 9
Training loss: 1.5010161137132103
Validation loss: 2.341642730526911

Epoch: 5| Step: 10
Training loss: 2.1498123486267033
Validation loss: 2.330280070445871

Epoch: 378| Step: 0
Training loss: 1.9135813205564822
Validation loss: 2.4161246821407074

Epoch: 5| Step: 1
Training loss: 1.9039874798739738
Validation loss: 2.381157404979831

Epoch: 5| Step: 2
Training loss: 2.268862496101207
Validation loss: 2.382283561389252

Epoch: 5| Step: 3
Training loss: 1.9620850385538455
Validation loss: 2.326904044989964

Epoch: 5| Step: 4
Training loss: 1.9423335909660242
Validation loss: 2.3986942781371536

Epoch: 5| Step: 5
Training loss: 1.7863623219780165
Validation loss: 2.377186550725668

Epoch: 5| Step: 6
Training loss: 1.8121760506357887
Validation loss: 2.461150430457995

Epoch: 5| Step: 7
Training loss: 1.9452523831190007
Validation loss: 2.4555382130678516

Epoch: 5| Step: 8
Training loss: 2.6170663378553933
Validation loss: 2.403012895371581

Epoch: 5| Step: 9
Training loss: 2.205086666661656
Validation loss: 2.3396656328022782

Epoch: 5| Step: 10
Training loss: 2.217033904591097
Validation loss: 2.4652418868749963

Epoch: 379| Step: 0
Training loss: 1.5205170637864835
Validation loss: 2.369959605659225

Epoch: 5| Step: 1
Training loss: 2.0507582308975962
Validation loss: 2.402118444528106

Epoch: 5| Step: 2
Training loss: 2.5112038376753625
Validation loss: 2.416773575895749

Epoch: 5| Step: 3
Training loss: 1.8523728412224574
Validation loss: 2.36794493581285

Epoch: 5| Step: 4
Training loss: 1.6705620860231614
Validation loss: 2.393665905926507

Epoch: 5| Step: 5
Training loss: 1.8784456382401287
Validation loss: 2.3581082619479825

Epoch: 5| Step: 6
Training loss: 1.931938433856818
Validation loss: 2.4428049297523717

Epoch: 5| Step: 7
Training loss: 2.183661335289882
Validation loss: 2.3790165987919405

Epoch: 5| Step: 8
Training loss: 2.0607798946294307
Validation loss: 2.436063881385686

Epoch: 5| Step: 9
Training loss: 1.7791718523841822
Validation loss: 2.4382540480693025

Epoch: 5| Step: 10
Training loss: 2.1640529150354633
Validation loss: 2.3384722570933296

Epoch: 380| Step: 0
Training loss: 1.6296306801360692
Validation loss: 2.4084037908270943

Epoch: 5| Step: 1
Training loss: 2.318606793281911
Validation loss: 2.487181722085574

Epoch: 5| Step: 2
Training loss: 2.2248538237142124
Validation loss: 2.4027604955571378

Epoch: 5| Step: 3
Training loss: 2.4638238359493734
Validation loss: 2.370446009438351

Epoch: 5| Step: 4
Training loss: 2.0386281921185834
Validation loss: 2.407091905186884

Epoch: 5| Step: 5
Training loss: 2.105284277596698
Validation loss: 2.4115226646837518

Epoch: 5| Step: 6
Training loss: 1.7292952508877835
Validation loss: 2.400779679041883

Epoch: 5| Step: 7
Training loss: 2.0288416743880946
Validation loss: 2.374249614484496

Epoch: 5| Step: 8
Training loss: 2.274233334650825
Validation loss: 2.461749806474763

Epoch: 5| Step: 9
Training loss: 2.038288656552457
Validation loss: 2.3959914142376677

Epoch: 5| Step: 10
Training loss: 1.63004912390142
Validation loss: 2.4032426719819764

Epoch: 381| Step: 0
Training loss: 2.5457511247596627
Validation loss: 2.3827842626002993

Epoch: 5| Step: 1
Training loss: 1.6453821875729582
Validation loss: 2.334389108961494

Epoch: 5| Step: 2
Training loss: 2.6097180717759634
Validation loss: 2.4291324562482726

Epoch: 5| Step: 3
Training loss: 2.083390527575919
Validation loss: 2.4133349400587325

Epoch: 5| Step: 4
Training loss: 2.0080661242414735
Validation loss: 2.3715591202381985

Epoch: 5| Step: 5
Training loss: 1.7381760468954865
Validation loss: 2.401214400850471

Epoch: 5| Step: 6
Training loss: 1.8882522195676479
Validation loss: 2.39161045096578

Epoch: 5| Step: 7
Training loss: 1.8193355443588544
Validation loss: 2.3899865635402247

Epoch: 5| Step: 8
Training loss: 1.545266905016495
Validation loss: 2.382346303095476

Epoch: 5| Step: 9
Training loss: 1.6668101090057148
Validation loss: 2.4116189480103816

Epoch: 5| Step: 10
Training loss: 2.032769793707641
Validation loss: 2.395148127847585

Epoch: 382| Step: 0
Training loss: 1.889456395684062
Validation loss: 2.3770114927477928

Epoch: 5| Step: 1
Training loss: 2.0101207719645355
Validation loss: 2.4133978401030745

Epoch: 5| Step: 2
Training loss: 2.3184375315911847
Validation loss: 2.343446180552314

Epoch: 5| Step: 3
Training loss: 1.9155073668065177
Validation loss: 2.3829865078571095

Epoch: 5| Step: 4
Training loss: 1.9897116441611333
Validation loss: 2.435149779124909

Epoch: 5| Step: 5
Training loss: 2.4544825594001303
Validation loss: 2.456275111348763

Epoch: 5| Step: 6
Training loss: 2.6633342743236548
Validation loss: 2.4805779948912616

Epoch: 5| Step: 7
Training loss: 1.4710138608174435
Validation loss: 2.3879354018386127

Epoch: 5| Step: 8
Training loss: 2.1170807420904554
Validation loss: 2.3658420764362327

Epoch: 5| Step: 9
Training loss: 2.0107934101355687
Validation loss: 2.445111616073099

Epoch: 5| Step: 10
Training loss: 1.52982996276247
Validation loss: 2.460620088383765

Epoch: 383| Step: 0
Training loss: 2.0717527741848274
Validation loss: 2.341425324040949

Epoch: 5| Step: 1
Training loss: 2.1144089149238083
Validation loss: 2.3208296916094544

Epoch: 5| Step: 2
Training loss: 2.382084869852238
Validation loss: 2.3683633265608357

Epoch: 5| Step: 3
Training loss: 2.3554501256000844
Validation loss: 2.4197635154041337

Epoch: 5| Step: 4
Training loss: 1.8683496154747192
Validation loss: 2.3929186514909015

Epoch: 5| Step: 5
Training loss: 2.7720710934471438
Validation loss: 2.462303607239066

Epoch: 5| Step: 6
Training loss: 2.1792400816980213
Validation loss: 2.3754906182689233

Epoch: 5| Step: 7
Training loss: 1.4446690132134965
Validation loss: 2.357569646448043

Epoch: 5| Step: 8
Training loss: 2.0684347598248913
Validation loss: 2.366458228839095

Epoch: 5| Step: 9
Training loss: 1.9583991289922236
Validation loss: 2.3894352776533085

Epoch: 5| Step: 10
Training loss: 1.6891229384034334
Validation loss: 2.421306864999666

Epoch: 384| Step: 0
Training loss: 1.488858649119145
Validation loss: 2.4208229206481056

Epoch: 5| Step: 1
Training loss: 1.9931884046429726
Validation loss: 2.278178849472779

Epoch: 5| Step: 2
Training loss: 2.189582269621741
Validation loss: 2.4296472643245033

Epoch: 5| Step: 3
Training loss: 1.7031590169606723
Validation loss: 2.448475951896759

Epoch: 5| Step: 4
Training loss: 2.152806836277354
Validation loss: 2.3597790141879873

Epoch: 5| Step: 5
Training loss: 2.3114209106038137
Validation loss: 2.3798836699613704

Epoch: 5| Step: 6
Training loss: 2.7097677295990636
Validation loss: 2.4221528453938475

Epoch: 5| Step: 7
Training loss: 1.5230413459781182
Validation loss: 2.3821528067065953

Epoch: 5| Step: 8
Training loss: 2.0147052411102546
Validation loss: 2.4009520601377514

Epoch: 5| Step: 9
Training loss: 1.6759442870319
Validation loss: 2.476661286538752

Epoch: 5| Step: 10
Training loss: 2.0087328037363856
Validation loss: 2.4215757610529143

Epoch: 385| Step: 0
Training loss: 1.9444819749510212
Validation loss: 2.327822314088335

Epoch: 5| Step: 1
Training loss: 1.1126187679029234
Validation loss: 2.3672354792243206

Epoch: 5| Step: 2
Training loss: 2.332614947039031
Validation loss: 2.4535227157227757

Epoch: 5| Step: 3
Training loss: 1.8651014350530937
Validation loss: 2.4321445059486066

Epoch: 5| Step: 4
Training loss: 2.1754741897191696
Validation loss: 2.418887038791253

Epoch: 5| Step: 5
Training loss: 2.008226166500036
Validation loss: 2.409320404952342

Epoch: 5| Step: 6
Training loss: 1.9178254176887828
Validation loss: 2.450576485705264

Epoch: 5| Step: 7
Training loss: 2.4620634863606505
Validation loss: 2.4312196602665375

Epoch: 5| Step: 8
Training loss: 2.0703928805887726
Validation loss: 2.434372609208781

Epoch: 5| Step: 9
Training loss: 2.2167204049654714
Validation loss: 2.426460680223835

Epoch: 5| Step: 10
Training loss: 2.1834552973492407
Validation loss: 2.3870594771055056

Epoch: 386| Step: 0
Training loss: 2.526978833416721
Validation loss: 2.409859244145232

Epoch: 5| Step: 1
Training loss: 1.991262902016278
Validation loss: 2.3546320630979394

Epoch: 5| Step: 2
Training loss: 1.9558012670102294
Validation loss: 2.414988934327588

Epoch: 5| Step: 3
Training loss: 1.7613690826466055
Validation loss: 2.4339939582978847

Epoch: 5| Step: 4
Training loss: 1.7431078477017659
Validation loss: 2.4144848857139496

Epoch: 5| Step: 5
Training loss: 2.22981062764995
Validation loss: 2.360578222981735

Epoch: 5| Step: 6
Training loss: 1.6387171233230635
Validation loss: 2.380943916184164

Epoch: 5| Step: 7
Training loss: 1.7279584255956966
Validation loss: 2.4544754809967526

Epoch: 5| Step: 8
Training loss: 2.6127854405756104
Validation loss: 2.28059767160346

Epoch: 5| Step: 9
Training loss: 1.9213294518745037
Validation loss: 2.3972455774358896

Epoch: 5| Step: 10
Training loss: 2.2660497859121866
Validation loss: 2.4595389000680687

Epoch: 387| Step: 0
Training loss: 1.6837464725766123
Validation loss: 2.38998859944617

Epoch: 5| Step: 1
Training loss: 2.5266721797201894
Validation loss: 2.304134413071329

Epoch: 5| Step: 2
Training loss: 1.634394559141449
Validation loss: 2.3808447459425075

Epoch: 5| Step: 3
Training loss: 1.8120492177304173
Validation loss: 2.330621328429666

Epoch: 5| Step: 4
Training loss: 1.7120376603226808
Validation loss: 2.40128415858737

Epoch: 5| Step: 5
Training loss: 2.0950971226724016
Validation loss: 2.368663902361984

Epoch: 5| Step: 6
Training loss: 1.9270253215684066
Validation loss: 2.4546467241681826

Epoch: 5| Step: 7
Training loss: 1.7894946246944423
Validation loss: 2.3388785803725876

Epoch: 5| Step: 8
Training loss: 2.660853357603106
Validation loss: 2.3414111274467166

Epoch: 5| Step: 9
Training loss: 2.190089192076544
Validation loss: 2.42080466349644

Epoch: 5| Step: 10
Training loss: 1.9915871706729993
Validation loss: 2.4290616396924722

Epoch: 388| Step: 0
Training loss: 2.01320165403538
Validation loss: 2.3377582471004263

Epoch: 5| Step: 1
Training loss: 1.8878439634063187
Validation loss: 2.3824270059303316

Epoch: 5| Step: 2
Training loss: 1.3776222280701667
Validation loss: 2.3641628545468483

Epoch: 5| Step: 3
Training loss: 2.2025826510315665
Validation loss: 2.426845883439933

Epoch: 5| Step: 4
Training loss: 2.089703763747615
Validation loss: 2.3919253055923324

Epoch: 5| Step: 5
Training loss: 1.7980268684051515
Validation loss: 2.3980211540098257

Epoch: 5| Step: 6
Training loss: 2.4140583519761085
Validation loss: 2.4529481856361914

Epoch: 5| Step: 7
Training loss: 1.8289732310117857
Validation loss: 2.3262106207024034

Epoch: 5| Step: 8
Training loss: 2.1549272764817493
Validation loss: 2.3980674831003856

Epoch: 5| Step: 9
Training loss: 2.01430414968246
Validation loss: 2.3919975324021188

Epoch: 5| Step: 10
Training loss: 2.0804228734263117
Validation loss: 2.4246193412287638

Epoch: 389| Step: 0
Training loss: 1.8511531071416871
Validation loss: 2.42447796475674

Epoch: 5| Step: 1
Training loss: 1.9368473307284828
Validation loss: 2.3580105992686886

Epoch: 5| Step: 2
Training loss: 1.8040853709640015
Validation loss: 2.4435635724322293

Epoch: 5| Step: 3
Training loss: 1.9058155127480156
Validation loss: 2.4099147511632832

Epoch: 5| Step: 4
Training loss: 1.958931919357831
Validation loss: 2.400612959384868

Epoch: 5| Step: 5
Training loss: 1.4897822622924257
Validation loss: 2.4904678933351776

Epoch: 5| Step: 6
Training loss: 2.001008971339546
Validation loss: 2.434826226078776

Epoch: 5| Step: 7
Training loss: 2.2186038546718616
Validation loss: 2.442839660269796

Epoch: 5| Step: 8
Training loss: 1.9493981777622156
Validation loss: 2.4009542191475544

Epoch: 5| Step: 9
Training loss: 2.2000188913401217
Validation loss: 2.420870606746849

Epoch: 5| Step: 10
Training loss: 2.2858530922023093
Validation loss: 2.3596608923780886

Epoch: 390| Step: 0
Training loss: 1.7257647159970761
Validation loss: 2.3408335823197937

Epoch: 5| Step: 1
Training loss: 1.3423506969493717
Validation loss: 2.3403940852803213

Epoch: 5| Step: 2
Training loss: 1.9032157137192824
Validation loss: 2.39917099136292

Epoch: 5| Step: 3
Training loss: 1.8522192840397769
Validation loss: 2.3566440390213454

Epoch: 5| Step: 4
Training loss: 2.1645438970572064
Validation loss: 2.3707480465021717

Epoch: 5| Step: 5
Training loss: 1.8311762980449164
Validation loss: 2.3802680206911013

Epoch: 5| Step: 6
Training loss: 2.682498447385767
Validation loss: 2.3737971612070403

Epoch: 5| Step: 7
Training loss: 1.9606326652768578
Validation loss: 2.4082770618391156

Epoch: 5| Step: 8
Training loss: 1.946969425856746
Validation loss: 2.4141589326438115

Epoch: 5| Step: 9
Training loss: 1.9726860421829824
Validation loss: 2.3773300396905506

Epoch: 5| Step: 10
Training loss: 2.0218422982874524
Validation loss: 2.397816904172893

Epoch: 391| Step: 0
Training loss: 1.95164677947239
Validation loss: 2.486091123723514

Epoch: 5| Step: 1
Training loss: 2.2251821421961138
Validation loss: 2.3784149426100374

Epoch: 5| Step: 2
Training loss: 1.6150833668169575
Validation loss: 2.377144657479377

Epoch: 5| Step: 3
Training loss: 2.13906547373418
Validation loss: 2.4152692361983674

Epoch: 5| Step: 4
Training loss: 2.100309430894736
Validation loss: 2.42965013010834

Epoch: 5| Step: 5
Training loss: 2.009309322060989
Validation loss: 2.395069978366317

Epoch: 5| Step: 6
Training loss: 1.9958664975632967
Validation loss: 2.403105919194386

Epoch: 5| Step: 7
Training loss: 1.4181790786996804
Validation loss: 2.352890659446123

Epoch: 5| Step: 8
Training loss: 2.9303495345735446
Validation loss: 2.474176218555573

Epoch: 5| Step: 9
Training loss: 1.9700000366946764
Validation loss: 2.437352136292538

Epoch: 5| Step: 10
Training loss: 1.806501195527628
Validation loss: 2.4749232460402064

Epoch: 392| Step: 0
Training loss: 2.092942381006028
Validation loss: 2.3481789354924243

Epoch: 5| Step: 1
Training loss: 2.434251527997137
Validation loss: 2.3970872683773248

Epoch: 5| Step: 2
Training loss: 1.7941849849041602
Validation loss: 2.395085124228702

Epoch: 5| Step: 3
Training loss: 1.4859349937698616
Validation loss: 2.3660099492213247

Epoch: 5| Step: 4
Training loss: 2.1734928170685057
Validation loss: 2.4126496250910026

Epoch: 5| Step: 5
Training loss: 2.469450839072169
Validation loss: 2.4439493349430497

Epoch: 5| Step: 6
Training loss: 1.9131117347274837
Validation loss: 2.4543206275894818

Epoch: 5| Step: 7
Training loss: 2.264898459914246
Validation loss: 2.4175303602133558

Epoch: 5| Step: 8
Training loss: 1.7277442029707546
Validation loss: 2.3929704916907806

Epoch: 5| Step: 9
Training loss: 2.113387522960375
Validation loss: 2.3600465845126966

Epoch: 5| Step: 10
Training loss: 1.241382265909557
Validation loss: 2.381358345832636

Epoch: 393| Step: 0
Training loss: 2.020378835109797
Validation loss: 2.3441837305973343

Epoch: 5| Step: 1
Training loss: 2.097867418738373
Validation loss: 2.3996026301933155

Epoch: 5| Step: 2
Training loss: 2.079165090841895
Validation loss: 2.458083990211699

Epoch: 5| Step: 3
Training loss: 1.6776280041903586
Validation loss: 2.419574075630344

Epoch: 5| Step: 4
Training loss: 1.816766715429933
Validation loss: 2.4425501761838824

Epoch: 5| Step: 5
Training loss: 1.6850305785395716
Validation loss: 2.4380552586552517

Epoch: 5| Step: 6
Training loss: 2.8302873806566873
Validation loss: 2.4257007942413185

Epoch: 5| Step: 7
Training loss: 1.8371138030608578
Validation loss: 2.3393917030207056

Epoch: 5| Step: 8
Training loss: 1.9261188327260554
Validation loss: 2.2952433718876897

Epoch: 5| Step: 9
Training loss: 1.254388259034533
Validation loss: 2.4060259063317244

Epoch: 5| Step: 10
Training loss: 1.790919976295974
Validation loss: 2.4224241313616295

Epoch: 394| Step: 0
Training loss: 1.729216938743425
Validation loss: 2.3895227211515637

Epoch: 5| Step: 1
Training loss: 2.1396742888385827
Validation loss: 2.369333986811745

Epoch: 5| Step: 2
Training loss: 2.1585832217964502
Validation loss: 2.408990642447448

Epoch: 5| Step: 3
Training loss: 1.834295114470631
Validation loss: 2.4005051577711627

Epoch: 5| Step: 4
Training loss: 1.891977882272104
Validation loss: 2.352173524407311

Epoch: 5| Step: 5
Training loss: 1.9359311550920035
Validation loss: 2.3729350780203613

Epoch: 5| Step: 6
Training loss: 1.6436630458096941
Validation loss: 2.4120562301732305

Epoch: 5| Step: 7
Training loss: 1.6876524397202468
Validation loss: 2.404232499943088

Epoch: 5| Step: 8
Training loss: 2.650877242369735
Validation loss: 2.3257770678046628

Epoch: 5| Step: 9
Training loss: 2.1097137179219683
Validation loss: 2.408725286271488

Epoch: 5| Step: 10
Training loss: 1.9874755186096642
Validation loss: 2.3748778563838484

Epoch: 395| Step: 0
Training loss: 2.0497524623751375
Validation loss: 2.3707618419581244

Epoch: 5| Step: 1
Training loss: 1.7347560154752424
Validation loss: 2.428076866628225

Epoch: 5| Step: 2
Training loss: 1.7471941525027828
Validation loss: 2.4125154500589105

Epoch: 5| Step: 3
Training loss: 2.0618648128945876
Validation loss: 2.358549835808527

Epoch: 5| Step: 4
Training loss: 1.7399371885604085
Validation loss: 2.422975530533531

Epoch: 5| Step: 5
Training loss: 2.0153306849684474
Validation loss: 2.391417034690732

Epoch: 5| Step: 6
Training loss: 1.7110426360971003
Validation loss: 2.398725065854671

Epoch: 5| Step: 7
Training loss: 2.4800630012323857
Validation loss: 2.46198942116273

Epoch: 5| Step: 8
Training loss: 2.325644791315633
Validation loss: 2.356339734428557

Epoch: 5| Step: 9
Training loss: 1.709874628613148
Validation loss: 2.3445615548801224

Epoch: 5| Step: 10
Training loss: 1.9445333490785677
Validation loss: 2.4588177264400435

Epoch: 396| Step: 0
Training loss: 1.6910484587472776
Validation loss: 2.3573153140423564

Epoch: 5| Step: 1
Training loss: 2.528065691842866
Validation loss: 2.447589659378193

Epoch: 5| Step: 2
Training loss: 1.9318044070400415
Validation loss: 2.398316550030165

Epoch: 5| Step: 3
Training loss: 2.6290511704924784
Validation loss: 2.374660357825954

Epoch: 5| Step: 4
Training loss: 1.8048671616469192
Validation loss: 2.3374756964946264

Epoch: 5| Step: 5
Training loss: 1.6590238411531422
Validation loss: 2.404419681104452

Epoch: 5| Step: 6
Training loss: 1.3225329535981196
Validation loss: 2.402799115866774

Epoch: 5| Step: 7
Training loss: 1.7827210626047036
Validation loss: 2.3670977931469777

Epoch: 5| Step: 8
Training loss: 2.206194747794889
Validation loss: 2.319025395258004

Epoch: 5| Step: 9
Training loss: 1.6773581743619568
Validation loss: 2.3238644460932933

Epoch: 5| Step: 10
Training loss: 1.9113436325819393
Validation loss: 2.358627755158686

Epoch: 397| Step: 0
Training loss: 1.9549571484798787
Validation loss: 2.4631262438970127

Epoch: 5| Step: 1
Training loss: 1.5828500394897862
Validation loss: 2.44002275358135

Epoch: 5| Step: 2
Training loss: 1.603042885980663
Validation loss: 2.3593235326720916

Epoch: 5| Step: 3
Training loss: 1.493287405105332
Validation loss: 2.387461306763039

Epoch: 5| Step: 4
Training loss: 1.554990039315167
Validation loss: 2.2616134359182505

Epoch: 5| Step: 5
Training loss: 2.829363809794751
Validation loss: 2.3593605017697064

Epoch: 5| Step: 6
Training loss: 2.05895251743579
Validation loss: 2.3766970656508857

Epoch: 5| Step: 7
Training loss: 2.0537091961253315
Validation loss: 2.385910020418533

Epoch: 5| Step: 8
Training loss: 2.393714055919451
Validation loss: 2.3651724047235736

Epoch: 5| Step: 9
Training loss: 2.075561089087404
Validation loss: 2.3934103728119616

Epoch: 5| Step: 10
Training loss: 1.7404025389384306
Validation loss: 2.3716381763189447

Epoch: 398| Step: 0
Training loss: 1.8895844677883502
Validation loss: 2.3910766181415934

Epoch: 5| Step: 1
Training loss: 2.666129107732388
Validation loss: 2.3498739870732797

Epoch: 5| Step: 2
Training loss: 2.2700806049706617
Validation loss: 2.3705202349606034

Epoch: 5| Step: 3
Training loss: 1.944044810810808
Validation loss: 2.4401174358813007

Epoch: 5| Step: 4
Training loss: 1.9370711067236697
Validation loss: 2.36636555408583

Epoch: 5| Step: 5
Training loss: 1.5987248286457152
Validation loss: 2.3823705743863086

Epoch: 5| Step: 6
Training loss: 1.9214369111733502
Validation loss: 2.3243085290119936

Epoch: 5| Step: 7
Training loss: 2.0519618532527817
Validation loss: 2.4021575394027863

Epoch: 5| Step: 8
Training loss: 2.3471059550946816
Validation loss: 2.3694146178304956

Epoch: 5| Step: 9
Training loss: 1.644816104384448
Validation loss: 2.367594178751023

Epoch: 5| Step: 10
Training loss: 1.3713283501134104
Validation loss: 2.4607760791670152

Epoch: 399| Step: 0
Training loss: 1.7844064419142485
Validation loss: 2.4122372895622903

Epoch: 5| Step: 1
Training loss: 1.4429749427253586
Validation loss: 2.389552186195648

Epoch: 5| Step: 2
Training loss: 1.511410388497206
Validation loss: 2.4097205103696653

Epoch: 5| Step: 3
Training loss: 1.5148622618907008
Validation loss: 2.3638567794656877

Epoch: 5| Step: 4
Training loss: 2.2328838361018475
Validation loss: 2.3926763685564025

Epoch: 5| Step: 5
Training loss: 1.7320497063602807
Validation loss: 2.376931259644262

Epoch: 5| Step: 6
Training loss: 1.7919746917785226
Validation loss: 2.419257677786613

Epoch: 5| Step: 7
Training loss: 2.486954028150654
Validation loss: 2.3762734566027763

Epoch: 5| Step: 8
Training loss: 2.1302034957818377
Validation loss: 2.3675672438463313

Epoch: 5| Step: 9
Training loss: 2.617913080099967
Validation loss: 2.4403070211044953

Epoch: 5| Step: 10
Training loss: 2.056783557065851
Validation loss: 2.41604710558898

Epoch: 400| Step: 0
Training loss: 1.891832202720937
Validation loss: 2.3915048012875144

Epoch: 5| Step: 1
Training loss: 1.7498075515650393
Validation loss: 2.4019095986881562

Epoch: 5| Step: 2
Training loss: 1.8003164092757946
Validation loss: 2.3156327487939405

Epoch: 5| Step: 3
Training loss: 1.740712109890913
Validation loss: 2.4559354696209343

Epoch: 5| Step: 4
Training loss: 1.877621852105419
Validation loss: 2.3814861735688138

Epoch: 5| Step: 5
Training loss: 2.1864615018863143
Validation loss: 2.3680273257293734

Epoch: 5| Step: 6
Training loss: 2.580545756998155
Validation loss: 2.441485895248258

Epoch: 5| Step: 7
Training loss: 1.3309700505865907
Validation loss: 2.4031238019467582

Epoch: 5| Step: 8
Training loss: 2.0313430764807934
Validation loss: 2.390547876939057

Epoch: 5| Step: 9
Training loss: 1.9854307595146767
Validation loss: 2.3300514264702814

Epoch: 5| Step: 10
Training loss: 1.7134567595280779
Validation loss: 2.4718263067193234

Epoch: 401| Step: 0
Training loss: 1.9238754034284211
Validation loss: 2.411818248618291

Epoch: 5| Step: 1
Training loss: 1.6910989319179939
Validation loss: 2.4108088956203932

Epoch: 5| Step: 2
Training loss: 1.8066151550147191
Validation loss: 2.333326200358597

Epoch: 5| Step: 3
Training loss: 2.3062854464321636
Validation loss: 2.351138562563909

Epoch: 5| Step: 4
Training loss: 1.8013031507349835
Validation loss: 2.446482160351432

Epoch: 5| Step: 5
Training loss: 1.760793032470083
Validation loss: 2.4319477681822965

Epoch: 5| Step: 6
Training loss: 2.6941892190593637
Validation loss: 2.2954771235827165

Epoch: 5| Step: 7
Training loss: 2.071365952132507
Validation loss: 2.382022947816361

Epoch: 5| Step: 8
Training loss: 2.2276232953097983
Validation loss: 2.319929182759606

Epoch: 5| Step: 9
Training loss: 1.6191556444380284
Validation loss: 2.338368558493436

Epoch: 5| Step: 10
Training loss: 1.9162122837443352
Validation loss: 2.4176186718623693

Epoch: 402| Step: 0
Training loss: 2.3395479298667508
Validation loss: 2.3600302122402432

Epoch: 5| Step: 1
Training loss: 1.838380203145293
Validation loss: 2.437500522719696

Epoch: 5| Step: 2
Training loss: 1.6989974656111397
Validation loss: 2.361502241697183

Epoch: 5| Step: 3
Training loss: 1.604595754465218
Validation loss: 2.4229154904759933

Epoch: 5| Step: 4
Training loss: 1.6140525027295063
Validation loss: 2.3289597418732733

Epoch: 5| Step: 5
Training loss: 2.17154367238643
Validation loss: 2.448123997635653

Epoch: 5| Step: 6
Training loss: 2.361149000973332
Validation loss: 2.430648246048585

Epoch: 5| Step: 7
Training loss: 1.9095200803489498
Validation loss: 2.372874887853409

Epoch: 5| Step: 8
Training loss: 1.5262508140518054
Validation loss: 2.3469850201219424

Epoch: 5| Step: 9
Training loss: 2.0082408878476325
Validation loss: 2.4214595103515064

Epoch: 5| Step: 10
Training loss: 2.320062488996868
Validation loss: 2.3716268002924394

Epoch: 403| Step: 0
Training loss: 1.7680292554911825
Validation loss: 2.4050050841018438

Epoch: 5| Step: 1
Training loss: 1.6691360855665733
Validation loss: 2.4022439104382123

Epoch: 5| Step: 2
Training loss: 1.7246468389811764
Validation loss: 2.383109364339944

Epoch: 5| Step: 3
Training loss: 2.080678188827832
Validation loss: 2.4098101885490113

Epoch: 5| Step: 4
Training loss: 1.8691118610843536
Validation loss: 2.3986750926588254

Epoch: 5| Step: 5
Training loss: 2.3847531280065164
Validation loss: 2.3657192676406096

Epoch: 5| Step: 6
Training loss: 2.327123336880736
Validation loss: 2.391291129366607

Epoch: 5| Step: 7
Training loss: 1.5144622117646374
Validation loss: 2.3742468632320226

Epoch: 5| Step: 8
Training loss: 1.6814583603180664
Validation loss: 2.353162839156834

Epoch: 5| Step: 9
Training loss: 1.9900857048173355
Validation loss: 2.39460014468045

Epoch: 5| Step: 10
Training loss: 2.048134103474831
Validation loss: 2.4115636311726223

Epoch: 404| Step: 0
Training loss: 2.1708813047569557
Validation loss: 2.415014003851571

Epoch: 5| Step: 1
Training loss: 1.918934938048451
Validation loss: 2.381060369535979

Epoch: 5| Step: 2
Training loss: 2.0770701549217825
Validation loss: 2.3733904694935846

Epoch: 5| Step: 3
Training loss: 1.7418521849223179
Validation loss: 2.393751758707701

Epoch: 5| Step: 4
Training loss: 1.2429959047853092
Validation loss: 2.4239434667650035

Epoch: 5| Step: 5
Training loss: 2.6563450515794322
Validation loss: 2.3920540272735193

Epoch: 5| Step: 6
Training loss: 1.6652370838534296
Validation loss: 2.415343732085744

Epoch: 5| Step: 7
Training loss: 2.257260159312357
Validation loss: 2.3957341805405608

Epoch: 5| Step: 8
Training loss: 1.5778696590110466
Validation loss: 2.4470331755510104

Epoch: 5| Step: 9
Training loss: 2.181011385832411
Validation loss: 2.4592031487299746

Epoch: 5| Step: 10
Training loss: 1.838270028627632
Validation loss: 2.3848508645739472

Epoch: 405| Step: 0
Training loss: 2.0460079773778137
Validation loss: 2.382169856129836

Epoch: 5| Step: 1
Training loss: 1.4407741742466609
Validation loss: 2.3275197936826357

Epoch: 5| Step: 2
Training loss: 1.5261236522467705
Validation loss: 2.3892674884981844

Epoch: 5| Step: 3
Training loss: 1.7240967555719873
Validation loss: 2.3425697488736663

Epoch: 5| Step: 4
Training loss: 2.151574968511042
Validation loss: 2.4026728402909385

Epoch: 5| Step: 5
Training loss: 2.0646089117914515
Validation loss: 2.3585501836345215

Epoch: 5| Step: 6
Training loss: 1.9461868956030886
Validation loss: 2.3857969285559646

Epoch: 5| Step: 7
Training loss: 2.1285029318002766
Validation loss: 2.473204115367383

Epoch: 5| Step: 8
Training loss: 1.9910131845502321
Validation loss: 2.4161264445520487

Epoch: 5| Step: 9
Training loss: 2.3804208227978556
Validation loss: 2.4627028631620083

Epoch: 5| Step: 10
Training loss: 1.805665779009798
Validation loss: 2.3870960827033527

Epoch: 406| Step: 0
Training loss: 2.86257338783774
Validation loss: 2.3743414578414557

Epoch: 5| Step: 1
Training loss: 1.9426846200213332
Validation loss: 2.3289799835034852

Epoch: 5| Step: 2
Training loss: 1.9453950427823907
Validation loss: 2.397102312727245

Epoch: 5| Step: 3
Training loss: 1.473653116964781
Validation loss: 2.3934541749789546

Epoch: 5| Step: 4
Training loss: 2.1965439353003138
Validation loss: 2.4023156349263717

Epoch: 5| Step: 5
Training loss: 1.4772395443690756
Validation loss: 2.431273744326255

Epoch: 5| Step: 6
Training loss: 2.0617354160689008
Validation loss: 2.4301211927550854

Epoch: 5| Step: 7
Training loss: 1.595459115131259
Validation loss: 2.3735051289120355

Epoch: 5| Step: 8
Training loss: 1.8106929057630707
Validation loss: 2.3901965965002234

Epoch: 5| Step: 9
Training loss: 1.972114050350776
Validation loss: 2.47187856164684

Epoch: 5| Step: 10
Training loss: 1.9157327643446371
Validation loss: 2.3677636401872744

Epoch: 407| Step: 0
Training loss: 1.5445617178814346
Validation loss: 2.370837854751274

Epoch: 5| Step: 1
Training loss: 1.8091967506431803
Validation loss: 2.340523286614878

Epoch: 5| Step: 2
Training loss: 1.7738855946968846
Validation loss: 2.403752604977856

Epoch: 5| Step: 3
Training loss: 1.8839830740636059
Validation loss: 2.309244190327708

Epoch: 5| Step: 4
Training loss: 1.7074932110541168
Validation loss: 2.4099295282100104

Epoch: 5| Step: 5
Training loss: 2.643098744649641
Validation loss: 2.3718161968911287

Epoch: 5| Step: 6
Training loss: 2.069325568122321
Validation loss: 2.423516593151208

Epoch: 5| Step: 7
Training loss: 1.8191852271682152
Validation loss: 2.492022540997725

Epoch: 5| Step: 8
Training loss: 2.0534751419335024
Validation loss: 2.4253381500762314

Epoch: 5| Step: 9
Training loss: 1.8907721596185574
Validation loss: 2.382323400368932

Epoch: 5| Step: 10
Training loss: 1.9498758374323704
Validation loss: 2.3667737670396667

Epoch: 408| Step: 0
Training loss: 1.8938216620757067
Validation loss: 2.438287035246043

Epoch: 5| Step: 1
Training loss: 1.8684331338221807
Validation loss: 2.397937851013237

Epoch: 5| Step: 2
Training loss: 1.3745771104560565
Validation loss: 2.427566318303294

Epoch: 5| Step: 3
Training loss: 1.7395792369070953
Validation loss: 2.4581425835959547

Epoch: 5| Step: 4
Training loss: 1.8180224375877179
Validation loss: 2.376608767315994

Epoch: 5| Step: 5
Training loss: 1.7670606329833871
Validation loss: 2.4405754456272537

Epoch: 5| Step: 6
Training loss: 1.827558054595495
Validation loss: 2.4321360048921075

Epoch: 5| Step: 7
Training loss: 2.678285905061614
Validation loss: 2.3725262886739147

Epoch: 5| Step: 8
Training loss: 2.247031903259849
Validation loss: 2.399260849085022

Epoch: 5| Step: 9
Training loss: 1.7603774959863705
Validation loss: 2.4421526538792304

Epoch: 5| Step: 10
Training loss: 1.7781239568241325
Validation loss: 2.4734747874693825

Epoch: 409| Step: 0
Training loss: 1.5340657716997126
Validation loss: 2.379542761083934

Epoch: 5| Step: 1
Training loss: 1.6257197913340733
Validation loss: 2.3234246753038814

Epoch: 5| Step: 2
Training loss: 2.7290239563726013
Validation loss: 2.397742883213361

Epoch: 5| Step: 3
Training loss: 2.4274734270898404
Validation loss: 2.3027336179539692

Epoch: 5| Step: 4
Training loss: 2.0805729953435033
Validation loss: 2.4724113901561093

Epoch: 5| Step: 5
Training loss: 1.921998679050464
Validation loss: 2.31910113500911

Epoch: 5| Step: 6
Training loss: 1.9229249024826134
Validation loss: 2.414532802100146

Epoch: 5| Step: 7
Training loss: 1.8594055814391952
Validation loss: 2.3993495916958123

Epoch: 5| Step: 8
Training loss: 1.869504058168286
Validation loss: 2.3503391860216625

Epoch: 5| Step: 9
Training loss: 1.6666627009662496
Validation loss: 2.39814234069772

Epoch: 5| Step: 10
Training loss: 1.6915241579185025
Validation loss: 2.314983357062464

Epoch: 410| Step: 0
Training loss: 2.343240504517562
Validation loss: 2.295203996753092

Epoch: 5| Step: 1
Training loss: 1.5364116941798025
Validation loss: 2.380984395074887

Epoch: 5| Step: 2
Training loss: 1.6792919314148202
Validation loss: 2.361654239978796

Epoch: 5| Step: 3
Training loss: 2.2828721850019154
Validation loss: 2.3420144418395665

Epoch: 5| Step: 4
Training loss: 2.210274317187905
Validation loss: 2.332368462968934

Epoch: 5| Step: 5
Training loss: 1.8938316075836021
Validation loss: 2.4109729196873517

Epoch: 5| Step: 6
Training loss: 1.8914796142971988
Validation loss: 2.3801160198365636

Epoch: 5| Step: 7
Training loss: 1.8552725919132653
Validation loss: 2.390767205239546

Epoch: 5| Step: 8
Training loss: 1.6329435451067307
Validation loss: 2.4650820546436685

Epoch: 5| Step: 9
Training loss: 2.0146981407465576
Validation loss: 2.3570342861262317

Epoch: 5| Step: 10
Training loss: 1.955979664316541
Validation loss: 2.32259092654809

Epoch: 411| Step: 0
Training loss: 2.11244859350735
Validation loss: 2.3819747132492872

Epoch: 5| Step: 1
Training loss: 2.0423147639086268
Validation loss: 2.4283933020110737

Epoch: 5| Step: 2
Training loss: 2.183604122676336
Validation loss: 2.402994720543176

Epoch: 5| Step: 3
Training loss: 2.201367048869883
Validation loss: 2.3850384688388417

Epoch: 5| Step: 4
Training loss: 1.4955922374333106
Validation loss: 2.405821746274622

Epoch: 5| Step: 5
Training loss: 2.743474240011947
Validation loss: 2.3701260613516864

Epoch: 5| Step: 6
Training loss: 2.065690203169975
Validation loss: 2.321676398738776

Epoch: 5| Step: 7
Training loss: 1.8724145229575824
Validation loss: 2.4010997193345642

Epoch: 5| Step: 8
Training loss: 1.5364985918708305
Validation loss: 2.3669643350378635

Epoch: 5| Step: 9
Training loss: 1.36939497257155
Validation loss: 2.3479948122008767

Epoch: 5| Step: 10
Training loss: 1.358960362480193
Validation loss: 2.4197940096251567

Epoch: 412| Step: 0
Training loss: 1.8770604574296341
Validation loss: 2.413189396223767

Epoch: 5| Step: 1
Training loss: 1.9097866332626332
Validation loss: 2.4166600167505115

Epoch: 5| Step: 2
Training loss: 1.6999233845668507
Validation loss: 2.385097381450139

Epoch: 5| Step: 3
Training loss: 2.176257206413524
Validation loss: 2.336138025914122

Epoch: 5| Step: 4
Training loss: 1.8795491028886895
Validation loss: 2.4302692279446156

Epoch: 5| Step: 5
Training loss: 1.7491080190717156
Validation loss: 2.4192754093585505

Epoch: 5| Step: 6
Training loss: 2.061025728386249
Validation loss: 2.408313016539306

Epoch: 5| Step: 7
Training loss: 1.6489092255840856
Validation loss: 2.407077684778099

Epoch: 5| Step: 8
Training loss: 1.813229118232188
Validation loss: 2.3609497990798927

Epoch: 5| Step: 9
Training loss: 1.8446996150716737
Validation loss: 2.357130789622673

Epoch: 5| Step: 10
Training loss: 2.0984150173093465
Validation loss: 2.426690442464504

Epoch: 413| Step: 0
Training loss: 1.9074324395650628
Validation loss: 2.3910531632354717

Epoch: 5| Step: 1
Training loss: 1.361010302272711
Validation loss: 2.360024917732398

Epoch: 5| Step: 2
Training loss: 1.7811842789153856
Validation loss: 2.3803121971751153

Epoch: 5| Step: 3
Training loss: 1.7518198904623115
Validation loss: 2.281054364900343

Epoch: 5| Step: 4
Training loss: 2.3325834658818057
Validation loss: 2.3667018347092497

Epoch: 5| Step: 5
Training loss: 2.553221955903877
Validation loss: 2.4239402769442218

Epoch: 5| Step: 6
Training loss: 1.7450315244171712
Validation loss: 2.395658081264947

Epoch: 5| Step: 7
Training loss: 1.9054927885409056
Validation loss: 2.4917776973310657

Epoch: 5| Step: 8
Training loss: 1.8140539545322856
Validation loss: 2.3745762263977506

Epoch: 5| Step: 9
Training loss: 1.6040149798656946
Validation loss: 2.374238809213618

Epoch: 5| Step: 10
Training loss: 2.301255596595436
Validation loss: 2.347781771498902

Epoch: 414| Step: 0
Training loss: 2.0282922190895687
Validation loss: 2.4225403548220723

Epoch: 5| Step: 1
Training loss: 1.6557689903952313
Validation loss: 2.373725073967987

Epoch: 5| Step: 2
Training loss: 1.6782791265821044
Validation loss: 2.437503447634076

Epoch: 5| Step: 3
Training loss: 1.2711879777360233
Validation loss: 2.4563775087156605

Epoch: 5| Step: 4
Training loss: 2.1487327788918353
Validation loss: 2.384133382566208

Epoch: 5| Step: 5
Training loss: 1.671148053000756
Validation loss: 2.3668655143493624

Epoch: 5| Step: 6
Training loss: 2.598017938430091
Validation loss: 2.392343222007003

Epoch: 5| Step: 7
Training loss: 1.9633557124500465
Validation loss: 2.443682127638083

Epoch: 5| Step: 8
Training loss: 1.8888884837330902
Validation loss: 2.399875776261741

Epoch: 5| Step: 9
Training loss: 1.6546580022932904
Validation loss: 2.3749541217234955

Epoch: 5| Step: 10
Training loss: 1.821822362960568
Validation loss: 2.388317208433995

Epoch: 415| Step: 0
Training loss: 2.081980863895476
Validation loss: 2.3762216443067485

Epoch: 5| Step: 1
Training loss: 3.0084801663592455
Validation loss: 2.348273362926324

Epoch: 5| Step: 2
Training loss: 1.809346184641083
Validation loss: 2.419177507375637

Epoch: 5| Step: 3
Training loss: 1.5688586740733175
Validation loss: 2.394755583223577

Epoch: 5| Step: 4
Training loss: 1.4565764425576557
Validation loss: 2.3209691537389006

Epoch: 5| Step: 5
Training loss: 1.9195895368198286
Validation loss: 2.337884166244385

Epoch: 5| Step: 6
Training loss: 1.6598527698259202
Validation loss: 2.3881801881677256

Epoch: 5| Step: 7
Training loss: 1.8002438353581425
Validation loss: 2.420760442282978

Epoch: 5| Step: 8
Training loss: 1.7957812090018783
Validation loss: 2.40379470106265

Epoch: 5| Step: 9
Training loss: 1.8393474322478403
Validation loss: 2.3185582201848614

Epoch: 5| Step: 10
Training loss: 1.7704709149664637
Validation loss: 2.3811331390876393

Epoch: 416| Step: 0
Training loss: 1.9768741648428325
Validation loss: 2.394991322168411

Epoch: 5| Step: 1
Training loss: 1.6311173103707286
Validation loss: 2.344245453563293

Epoch: 5| Step: 2
Training loss: 2.6551564377783707
Validation loss: 2.4228245562377833

Epoch: 5| Step: 3
Training loss: 1.7289590212994534
Validation loss: 2.3724861890095066

Epoch: 5| Step: 4
Training loss: 1.2325090235443659
Validation loss: 2.3516001721674225

Epoch: 5| Step: 5
Training loss: 1.4747611870840116
Validation loss: 2.3722556292616175

Epoch: 5| Step: 6
Training loss: 2.4938723808987246
Validation loss: 2.37987194878239

Epoch: 5| Step: 7
Training loss: 2.102021801756541
Validation loss: 2.380733197769254

Epoch: 5| Step: 8
Training loss: 1.906721900937963
Validation loss: 2.342748446292495

Epoch: 5| Step: 9
Training loss: 1.9120967190472695
Validation loss: 2.4453566923750953

Epoch: 5| Step: 10
Training loss: 1.839901220634881
Validation loss: 2.3838181962021054

Epoch: 417| Step: 0
Training loss: 1.9443323814555
Validation loss: 2.30750468580993

Epoch: 5| Step: 1
Training loss: 1.5153721077323512
Validation loss: 2.349369268968054

Epoch: 5| Step: 2
Training loss: 2.106039617428462
Validation loss: 2.3040771243415867

Epoch: 5| Step: 3
Training loss: 1.8673425713791478
Validation loss: 2.361970676642433

Epoch: 5| Step: 4
Training loss: 2.109820170581171
Validation loss: 2.384510835716142

Epoch: 5| Step: 5
Training loss: 1.6461621531435289
Validation loss: 2.3697107080592508

Epoch: 5| Step: 6
Training loss: 2.6718404667279025
Validation loss: 2.3523422658336384

Epoch: 5| Step: 7
Training loss: 1.771943727805335
Validation loss: 2.4296261559708556

Epoch: 5| Step: 8
Training loss: 1.9775326726362814
Validation loss: 2.3783047243577817

Epoch: 5| Step: 9
Training loss: 1.6462389128361614
Validation loss: 2.3866962748469374

Epoch: 5| Step: 10
Training loss: 1.1934195095962734
Validation loss: 2.472773721922836

Epoch: 418| Step: 0
Training loss: 2.6556209043640457
Validation loss: 2.339662564757689

Epoch: 5| Step: 1
Training loss: 1.8037538962213069
Validation loss: 2.375379892523954

Epoch: 5| Step: 2
Training loss: 1.5567438529331084
Validation loss: 2.3610846753443098

Epoch: 5| Step: 3
Training loss: 1.712706396097711
Validation loss: 2.3596392557363606

Epoch: 5| Step: 4
Training loss: 1.6630183422891527
Validation loss: 2.3314496082095206

Epoch: 5| Step: 5
Training loss: 2.1331519670679144
Validation loss: 2.4155276024460455

Epoch: 5| Step: 6
Training loss: 1.8352560523686436
Validation loss: 2.3774767268710852

Epoch: 5| Step: 7
Training loss: 1.8279667973330642
Validation loss: 2.357679112205777

Epoch: 5| Step: 8
Training loss: 1.9136655434797472
Validation loss: 2.3779600702565693

Epoch: 5| Step: 9
Training loss: 1.4607294107840578
Validation loss: 2.3622695920312418

Epoch: 5| Step: 10
Training loss: 2.1201739767051673
Validation loss: 2.4130997102968315

Epoch: 419| Step: 0
Training loss: 2.8269112021308107
Validation loss: 2.390740122855918

Epoch: 5| Step: 1
Training loss: 2.4055814929099286
Validation loss: 2.3734373112350315

Epoch: 5| Step: 2
Training loss: 1.716819094708315
Validation loss: 2.346695365261247

Epoch: 5| Step: 3
Training loss: 1.7077081590836745
Validation loss: 2.3883918660672485

Epoch: 5| Step: 4
Training loss: 1.4398738499857133
Validation loss: 2.4236124497082314

Epoch: 5| Step: 5
Training loss: 1.5257857002783282
Validation loss: 2.4060101692550395

Epoch: 5| Step: 6
Training loss: 1.6629349734678942
Validation loss: 2.4140657219880377

Epoch: 5| Step: 7
Training loss: 1.658199242900712
Validation loss: 2.4125147715617943

Epoch: 5| Step: 8
Training loss: 1.7822604743134969
Validation loss: 2.3394024851407127

Epoch: 5| Step: 9
Training loss: 1.8296189683805772
Validation loss: 2.3247766183893006

Epoch: 5| Step: 10
Training loss: 2.2445138167790724
Validation loss: 2.417517658255727

Epoch: 420| Step: 0
Training loss: 1.7947912988498138
Validation loss: 2.4898983122878176

Epoch: 5| Step: 1
Training loss: 1.509394551973884
Validation loss: 2.4196887037170427

Epoch: 5| Step: 2
Training loss: 1.990645825622948
Validation loss: 2.2764148724848545

Epoch: 5| Step: 3
Training loss: 1.8349613922589578
Validation loss: 2.379763428455302

Epoch: 5| Step: 4
Training loss: 2.4117378968126624
Validation loss: 2.4156733335970593

Epoch: 5| Step: 5
Training loss: 2.0603935582401838
Validation loss: 2.323794737865455

Epoch: 5| Step: 6
Training loss: 1.7882767330194291
Validation loss: 2.3390349204044867

Epoch: 5| Step: 7
Training loss: 2.066383751095912
Validation loss: 2.407355638497299

Epoch: 5| Step: 8
Training loss: 2.1182192157267443
Validation loss: 2.439228436842317

Epoch: 5| Step: 9
Training loss: 1.8808149449378162
Validation loss: 2.3356086174856854

Epoch: 5| Step: 10
Training loss: 1.3689533274227224
Validation loss: 2.3850283702785564

Epoch: 421| Step: 0
Training loss: 1.8907329433932287
Validation loss: 2.35137431654625

Epoch: 5| Step: 1
Training loss: 1.8655971633649104
Validation loss: 2.472593979235355

Epoch: 5| Step: 2
Training loss: 1.6127457364933235
Validation loss: 2.437455141397788

Epoch: 5| Step: 3
Training loss: 2.1683320711891123
Validation loss: 2.3330178120720815

Epoch: 5| Step: 4
Training loss: 2.5444892052938513
Validation loss: 2.379104213485032

Epoch: 5| Step: 5
Training loss: 1.4899900543597815
Validation loss: 2.3164668726587143

Epoch: 5| Step: 6
Training loss: 1.5179892121887866
Validation loss: 2.368451476598829

Epoch: 5| Step: 7
Training loss: 1.7533704453276793
Validation loss: 2.4017907053716243

Epoch: 5| Step: 8
Training loss: 1.6901985067674898
Validation loss: 2.3572974089536873

Epoch: 5| Step: 9
Training loss: 2.044747214887583
Validation loss: 2.3549413913602657

Epoch: 5| Step: 10
Training loss: 2.1356794490242152
Validation loss: 2.3832075528854015

Epoch: 422| Step: 0
Training loss: 1.7486943415086622
Validation loss: 2.382724083992094

Epoch: 5| Step: 1
Training loss: 1.7682188442942064
Validation loss: 2.371901283052065

Epoch: 5| Step: 2
Training loss: 1.9236890093855952
Validation loss: 2.2912486768157625

Epoch: 5| Step: 3
Training loss: 1.4107503722543748
Validation loss: 2.4082978389012206

Epoch: 5| Step: 4
Training loss: 1.4030400834587482
Validation loss: 2.334562242438907

Epoch: 5| Step: 5
Training loss: 1.3261966843454434
Validation loss: 2.3199344295369917

Epoch: 5| Step: 6
Training loss: 1.7411109095418251
Validation loss: 2.390390853144309

Epoch: 5| Step: 7
Training loss: 2.7320583447974607
Validation loss: 2.4598007657724272

Epoch: 5| Step: 8
Training loss: 2.5046643613625825
Validation loss: 2.4152864865066133

Epoch: 5| Step: 9
Training loss: 1.771311691598959
Validation loss: 2.417629998488698

Epoch: 5| Step: 10
Training loss: 2.0852852133656783
Validation loss: 2.36075832721102

Epoch: 423| Step: 0
Training loss: 1.7217498955392176
Validation loss: 2.342449498479431

Epoch: 5| Step: 1
Training loss: 1.54910910752707
Validation loss: 2.356517526904205

Epoch: 5| Step: 2
Training loss: 1.4382004068127119
Validation loss: 2.3703810416785256

Epoch: 5| Step: 3
Training loss: 1.8787940739317897
Validation loss: 2.3945665845863693

Epoch: 5| Step: 4
Training loss: 1.786972290784845
Validation loss: 2.482882251873699

Epoch: 5| Step: 5
Training loss: 2.7791573012926722
Validation loss: 2.435709331062054

Epoch: 5| Step: 6
Training loss: 2.0208918638372233
Validation loss: 2.324863033558406

Epoch: 5| Step: 7
Training loss: 1.7568818065683807
Validation loss: 2.3708700649711116

Epoch: 5| Step: 8
Training loss: 1.7293481233670718
Validation loss: 2.4405346930118568

Epoch: 5| Step: 9
Training loss: 2.1441823540044633
Validation loss: 2.393002219201081

Epoch: 5| Step: 10
Training loss: 1.9212031236736344
Validation loss: 2.4057447198346127

Epoch: 424| Step: 0
Training loss: 2.1716946314282017
Validation loss: 2.373423699292648

Epoch: 5| Step: 1
Training loss: 1.673104377878841
Validation loss: 2.5053157732617977

Epoch: 5| Step: 2
Training loss: 1.6082162481721822
Validation loss: 2.359617894858186

Epoch: 5| Step: 3
Training loss: 1.7491294194012115
Validation loss: 2.4056653731015047

Epoch: 5| Step: 4
Training loss: 1.5430378186182863
Validation loss: 2.3620804534333595

Epoch: 5| Step: 5
Training loss: 2.0841993312215616
Validation loss: 2.3899182374022114

Epoch: 5| Step: 6
Training loss: 2.595963418394241
Validation loss: 2.3469098465308305

Epoch: 5| Step: 7
Training loss: 1.8389777800071723
Validation loss: 2.343595068401395

Epoch: 5| Step: 8
Training loss: 1.6759196760007604
Validation loss: 2.3506880616244445

Epoch: 5| Step: 9
Training loss: 1.5831813822998502
Validation loss: 2.333461286805779

Epoch: 5| Step: 10
Training loss: 2.1024727250551503
Validation loss: 2.4090645955550327

Epoch: 425| Step: 0
Training loss: 1.8350800804937508
Validation loss: 2.4166383122812936

Epoch: 5| Step: 1
Training loss: 1.6184199700047892
Validation loss: 2.4091278475888735

Epoch: 5| Step: 2
Training loss: 1.8847589206082183
Validation loss: 2.4082871651044826

Epoch: 5| Step: 3
Training loss: 2.5386756015321166
Validation loss: 2.264331874902694

Epoch: 5| Step: 4
Training loss: 1.9946440267748489
Validation loss: 2.492168628961799

Epoch: 5| Step: 5
Training loss: 1.579064797543761
Validation loss: 2.420336274940177

Epoch: 5| Step: 6
Training loss: 1.6530020193928812
Validation loss: 2.402564731495131

Epoch: 5| Step: 7
Training loss: 2.019395008324522
Validation loss: 2.4192005571442654

Epoch: 5| Step: 8
Training loss: 1.8612357053598483
Validation loss: 2.3658931868694864

Epoch: 5| Step: 9
Training loss: 1.5632684725230175
Validation loss: 2.343521248103658

Epoch: 5| Step: 10
Training loss: 1.8984805129716067
Validation loss: 2.3289020477899984

Epoch: 426| Step: 0
Training loss: 1.725224109963398
Validation loss: 2.3312517504339243

Epoch: 5| Step: 1
Training loss: 1.9562879662287767
Validation loss: 2.4362711252728264

Epoch: 5| Step: 2
Training loss: 2.637069565782327
Validation loss: 2.2547165783237233

Epoch: 5| Step: 3
Training loss: 1.8336328204055357
Validation loss: 2.361869910334546

Epoch: 5| Step: 4
Training loss: 2.0700119088240387
Validation loss: 2.4045425289143383

Epoch: 5| Step: 5
Training loss: 1.4987866739680904
Validation loss: 2.2927698541506922

Epoch: 5| Step: 6
Training loss: 1.8737038901001646
Validation loss: 2.3326445242564215

Epoch: 5| Step: 7
Training loss: 2.2607450349266625
Validation loss: 2.398928190547093

Epoch: 5| Step: 8
Training loss: 1.5257483537900403
Validation loss: 2.375188660266159

Epoch: 5| Step: 9
Training loss: 1.7110418697208272
Validation loss: 2.3278823002572793

Epoch: 5| Step: 10
Training loss: 1.799612795721156
Validation loss: 2.4226007449230558

Epoch: 427| Step: 0
Training loss: 1.5999559485808639
Validation loss: 2.349436997919437

Epoch: 5| Step: 1
Training loss: 1.7883672571060627
Validation loss: 2.406648321361612

Epoch: 5| Step: 2
Training loss: 1.8716871240550312
Validation loss: 2.3590851792978245

Epoch: 5| Step: 3
Training loss: 2.189160180209913
Validation loss: 2.4154833018700477

Epoch: 5| Step: 4
Training loss: 2.612852600249835
Validation loss: 2.357382043665685

Epoch: 5| Step: 5
Training loss: 1.7094504107869573
Validation loss: 2.360922832892321

Epoch: 5| Step: 6
Training loss: 1.4107343592948736
Validation loss: 2.3029795218046742

Epoch: 5| Step: 7
Training loss: 1.8043969651230745
Validation loss: 2.410198141701142

Epoch: 5| Step: 8
Training loss: 1.6345047645767798
Validation loss: 2.389267072181193

Epoch: 5| Step: 9
Training loss: 1.581330923791586
Validation loss: 2.388427500785215

Epoch: 5| Step: 10
Training loss: 2.025702780760654
Validation loss: 2.3522908865782517

Epoch: 428| Step: 0
Training loss: 1.9114903197007225
Validation loss: 2.316079945859199

Epoch: 5| Step: 1
Training loss: 2.5744978850343587
Validation loss: 2.3835282499965986

Epoch: 5| Step: 2
Training loss: 1.416310415166165
Validation loss: 2.41168759691215

Epoch: 5| Step: 3
Training loss: 1.7022268044164108
Validation loss: 2.297736038815548

Epoch: 5| Step: 4
Training loss: 1.6006120047736239
Validation loss: 2.3852580963046575

Epoch: 5| Step: 5
Training loss: 1.5520160669006378
Validation loss: 2.341610130311005

Epoch: 5| Step: 6
Training loss: 2.0276176252946505
Validation loss: 2.3731374318456755

Epoch: 5| Step: 7
Training loss: 1.1863432319591147
Validation loss: 2.4034208689450365

Epoch: 5| Step: 8
Training loss: 2.047375566849169
Validation loss: 2.402053979071144

Epoch: 5| Step: 9
Training loss: 1.70127502198776
Validation loss: 2.2971310701955985

Epoch: 5| Step: 10
Training loss: 2.1288216950309904
Validation loss: 2.300284704276065

Epoch: 429| Step: 0
Training loss: 1.2222082030089556
Validation loss: 2.4390265283742796

Epoch: 5| Step: 1
Training loss: 1.765411296503493
Validation loss: 2.4089499078341494

Epoch: 5| Step: 2
Training loss: 2.243296491859831
Validation loss: 2.394737419593048

Epoch: 5| Step: 3
Training loss: 2.1378965043513847
Validation loss: 2.458145116320508

Epoch: 5| Step: 4
Training loss: 2.7675825184939984
Validation loss: 2.4191166587886785

Epoch: 5| Step: 5
Training loss: 1.4170445144003898
Validation loss: 2.356126679549068

Epoch: 5| Step: 6
Training loss: 1.9205395780784045
Validation loss: 2.379329355834262

Epoch: 5| Step: 7
Training loss: 1.8584739361018878
Validation loss: 2.4138581530307883

Epoch: 5| Step: 8
Training loss: 1.4828822610923806
Validation loss: 2.326082998911423

Epoch: 5| Step: 9
Training loss: 1.4431167832277363
Validation loss: 2.3831095203243424

Epoch: 5| Step: 10
Training loss: 1.8234243358146678
Validation loss: 2.393262414874142

Epoch: 430| Step: 0
Training loss: 2.178102415999422
Validation loss: 2.3575842927039936

Epoch: 5| Step: 1
Training loss: 1.6115993202179635
Validation loss: 2.3671001763558146

Epoch: 5| Step: 2
Training loss: 1.6070450147485293
Validation loss: 2.417385514913506

Epoch: 5| Step: 3
Training loss: 1.2983713364986946
Validation loss: 2.3605701945480906

Epoch: 5| Step: 4
Training loss: 1.7831088623001212
Validation loss: 2.4033360655898517

Epoch: 5| Step: 5
Training loss: 2.201118691994218
Validation loss: 2.2803133037286645

Epoch: 5| Step: 6
Training loss: 2.0743992039118075
Validation loss: 2.3434587184151283

Epoch: 5| Step: 7
Training loss: 2.2308399539583745
Validation loss: 2.4036357994395887

Epoch: 5| Step: 8
Training loss: 1.417441361978843
Validation loss: 2.3998759877730316

Epoch: 5| Step: 9
Training loss: 1.8942456846234597
Validation loss: 2.3057217993509544

Epoch: 5| Step: 10
Training loss: 2.1534807417916078
Validation loss: 2.424975890409873

Epoch: 431| Step: 0
Training loss: 1.9378461220969083
Validation loss: 2.3595319615714914

Epoch: 5| Step: 1
Training loss: 1.7787210012016967
Validation loss: 2.3538238322220946

Epoch: 5| Step: 2
Training loss: 2.442367974640055
Validation loss: 2.3852622374493033

Epoch: 5| Step: 3
Training loss: 1.7478698299833195
Validation loss: 2.339324323233777

Epoch: 5| Step: 4
Training loss: 1.1907761205050422
Validation loss: 2.386685373397723

Epoch: 5| Step: 5
Training loss: 1.8254890021915202
Validation loss: 2.3766858993686593

Epoch: 5| Step: 6
Training loss: 1.859492835149786
Validation loss: 2.397075847356519

Epoch: 5| Step: 7
Training loss: 1.4431734494435633
Validation loss: 2.4520317637269082

Epoch: 5| Step: 8
Training loss: 2.1304979446139805
Validation loss: 2.3362532313904945

Epoch: 5| Step: 9
Training loss: 2.034067986874045
Validation loss: 2.3204158338580103

Epoch: 5| Step: 10
Training loss: 1.729489499331797
Validation loss: 2.3622431933055776

Epoch: 432| Step: 0
Training loss: 1.9209140763375845
Validation loss: 2.4031931511603277

Epoch: 5| Step: 1
Training loss: 2.8759589876373024
Validation loss: 2.3992526578528484

Epoch: 5| Step: 2
Training loss: 1.6980494893863227
Validation loss: 2.3399997478192582

Epoch: 5| Step: 3
Training loss: 1.9741203691177869
Validation loss: 2.2951905223213505

Epoch: 5| Step: 4
Training loss: 1.7093095393783748
Validation loss: 2.3928793649594677

Epoch: 5| Step: 5
Training loss: 1.7688519856196674
Validation loss: 2.357741020106022

Epoch: 5| Step: 6
Training loss: 1.4557491931208806
Validation loss: 2.3879690765974684

Epoch: 5| Step: 7
Training loss: 1.7859184257443244
Validation loss: 2.3353728439377544

Epoch: 5| Step: 8
Training loss: 1.6403793877721204
Validation loss: 2.4968873212153713

Epoch: 5| Step: 9
Training loss: 1.1655921358686285
Validation loss: 2.3639715705341864

Epoch: 5| Step: 10
Training loss: 1.4981641661322904
Validation loss: 2.355668208611964

Epoch: 433| Step: 0
Training loss: 2.0094352131745987
Validation loss: 2.4410981513423344

Epoch: 5| Step: 1
Training loss: 1.6265132167360088
Validation loss: 2.3567146406520862

Epoch: 5| Step: 2
Training loss: 2.664203360404994
Validation loss: 2.4226231473025788

Epoch: 5| Step: 3
Training loss: 1.6006601908731655
Validation loss: 2.359608091670324

Epoch: 5| Step: 4
Training loss: 1.2768368429718229
Validation loss: 2.363645257919828

Epoch: 5| Step: 5
Training loss: 1.3072259387429876
Validation loss: 2.3167918597330286

Epoch: 5| Step: 6
Training loss: 1.850270911304868
Validation loss: 2.4390372557929787

Epoch: 5| Step: 7
Training loss: 1.597093478372214
Validation loss: 2.4547173174914745

Epoch: 5| Step: 8
Training loss: 2.0428539119851155
Validation loss: 2.416345298779778

Epoch: 5| Step: 9
Training loss: 1.7128920169072166
Validation loss: 2.3814367450454337

Epoch: 5| Step: 10
Training loss: 2.0699567381166593
Validation loss: 2.3239542569945226

Epoch: 434| Step: 0
Training loss: 1.7890258518779834
Validation loss: 2.372698407515789

Epoch: 5| Step: 1
Training loss: 1.7913045369355878
Validation loss: 2.303058586031819

Epoch: 5| Step: 2
Training loss: 2.75883814945268
Validation loss: 2.3492584229639917

Epoch: 5| Step: 3
Training loss: 1.638246683420951
Validation loss: 2.3600119600424003

Epoch: 5| Step: 4
Training loss: 1.3010611476411968
Validation loss: 2.360611515847165

Epoch: 5| Step: 5
Training loss: 1.6729381425301713
Validation loss: 2.351360800389304

Epoch: 5| Step: 6
Training loss: 1.9182440721352385
Validation loss: 2.4009224077248263

Epoch: 5| Step: 7
Training loss: 1.6925781982478203
Validation loss: 2.423573332812385

Epoch: 5| Step: 8
Training loss: 1.7028991829491311
Validation loss: 2.35015743874126

Epoch: 5| Step: 9
Training loss: 2.109914978990124
Validation loss: 2.3689740573201203

Epoch: 5| Step: 10
Training loss: 1.5571609833488524
Validation loss: 2.295735075555923

Epoch: 435| Step: 0
Training loss: 1.7628296185416128
Validation loss: 2.363391793022639

Epoch: 5| Step: 1
Training loss: 1.300066960884401
Validation loss: 2.2786782141756468

Epoch: 5| Step: 2
Training loss: 1.6800860974411589
Validation loss: 2.414402077492906

Epoch: 5| Step: 3
Training loss: 1.310761981258169
Validation loss: 2.2861307990479545

Epoch: 5| Step: 4
Training loss: 1.377078133177449
Validation loss: 2.4506464179716434

Epoch: 5| Step: 5
Training loss: 2.2752419353577324
Validation loss: 2.385313985566741

Epoch: 5| Step: 6
Training loss: 1.7443816732882405
Validation loss: 2.4601835143737034

Epoch: 5| Step: 7
Training loss: 2.4707673920124753
Validation loss: 2.3882376202881055

Epoch: 5| Step: 8
Training loss: 2.139463569040317
Validation loss: 2.413798998185428

Epoch: 5| Step: 9
Training loss: 2.0543407539226637
Validation loss: 2.445908965233288

Epoch: 5| Step: 10
Training loss: 1.883369521690782
Validation loss: 2.381045448316205

Epoch: 436| Step: 0
Training loss: 1.3906202851976341
Validation loss: 2.483880138017384

Epoch: 5| Step: 1
Training loss: 1.9286836182796196
Validation loss: 2.3887451027567628

Epoch: 5| Step: 2
Training loss: 1.6833599308795695
Validation loss: 2.447186929452468

Epoch: 5| Step: 3
Training loss: 2.00044078737938
Validation loss: 2.390277262198259

Epoch: 5| Step: 4
Training loss: 2.441374023224802
Validation loss: 2.485864621066723

Epoch: 5| Step: 5
Training loss: 1.8678168349513322
Validation loss: 2.4060034996528055

Epoch: 5| Step: 6
Training loss: 1.7665489952317546
Validation loss: 2.3871087210061646

Epoch: 5| Step: 7
Training loss: 1.4795522142577346
Validation loss: 2.346702749099836

Epoch: 5| Step: 8
Training loss: 1.5279401702501756
Validation loss: 2.358643010037242

Epoch: 5| Step: 9
Training loss: 1.5960894599068935
Validation loss: 2.391333295802652

Epoch: 5| Step: 10
Training loss: 2.1566932333243956
Validation loss: 2.3817923522084614

Epoch: 437| Step: 0
Training loss: 1.413755056775238
Validation loss: 2.3203045869169387

Epoch: 5| Step: 1
Training loss: 2.20603447744865
Validation loss: 2.3679573396290827

Epoch: 5| Step: 2
Training loss: 1.9446940837039421
Validation loss: 2.446963747676846

Epoch: 5| Step: 3
Training loss: 1.5820508414103287
Validation loss: 2.391390355781269

Epoch: 5| Step: 4
Training loss: 1.6872445372316274
Validation loss: 2.4361508334866775

Epoch: 5| Step: 5
Training loss: 1.9772327477848843
Validation loss: 2.5007826031380156

Epoch: 5| Step: 6
Training loss: 1.8709950590287603
Validation loss: 2.4414859487999374

Epoch: 5| Step: 7
Training loss: 2.441293454425612
Validation loss: 2.4615398002638424

Epoch: 5| Step: 8
Training loss: 1.8101633729494082
Validation loss: 2.381538378345381

Epoch: 5| Step: 9
Training loss: 1.7120024967799297
Validation loss: 2.37060447653902

Epoch: 5| Step: 10
Training loss: 2.054852845243836
Validation loss: 2.369636024431325

Epoch: 438| Step: 0
Training loss: 2.433756570283067
Validation loss: 2.3800485370226667

Epoch: 5| Step: 1
Training loss: 1.4569846138125395
Validation loss: 2.350684616443081

Epoch: 5| Step: 2
Training loss: 1.9708801129564468
Validation loss: 2.395917694796558

Epoch: 5| Step: 3
Training loss: 1.8086209717384767
Validation loss: 2.3826759814352725

Epoch: 5| Step: 4
Training loss: 1.7987775598764737
Validation loss: 2.366988673077815

Epoch: 5| Step: 5
Training loss: 1.4773611502427089
Validation loss: 2.3662802309532487

Epoch: 5| Step: 6
Training loss: 1.862096829909264
Validation loss: 2.301852630680016

Epoch: 5| Step: 7
Training loss: 1.7724446613836033
Validation loss: 2.34240333508184

Epoch: 5| Step: 8
Training loss: 1.904894049494085
Validation loss: 2.3491877740354807

Epoch: 5| Step: 9
Training loss: 1.6291374938902559
Validation loss: 2.4465118070345646

Epoch: 5| Step: 10
Training loss: 1.5302839540510922
Validation loss: 2.2754168461086226

Epoch: 439| Step: 0
Training loss: 1.788062003291652
Validation loss: 2.374879577619111

Epoch: 5| Step: 1
Training loss: 2.3959845011469354
Validation loss: 2.3284312678089787

Epoch: 5| Step: 2
Training loss: 1.9569753307645315
Validation loss: 2.382539957545556

Epoch: 5| Step: 3
Training loss: 1.5580928446928655
Validation loss: 2.341874761717124

Epoch: 5| Step: 4
Training loss: 1.3651536036270686
Validation loss: 2.3697557196222814

Epoch: 5| Step: 5
Training loss: 1.2720850215783628
Validation loss: 2.4114094663704395

Epoch: 5| Step: 6
Training loss: 1.4505991158401064
Validation loss: 2.4136810750088795

Epoch: 5| Step: 7
Training loss: 2.2151009008361244
Validation loss: 2.328484775482335

Epoch: 5| Step: 8
Training loss: 1.6315274817408185
Validation loss: 2.4308843820539465

Epoch: 5| Step: 9
Training loss: 2.02591838968288
Validation loss: 2.4204073637305514

Epoch: 5| Step: 10
Training loss: 2.369717093052404
Validation loss: 2.4195372181175765

Epoch: 440| Step: 0
Training loss: 2.497181543432146
Validation loss: 2.376225966266811

Epoch: 5| Step: 1
Training loss: 1.4230104042257274
Validation loss: 2.4481699649946456

Epoch: 5| Step: 2
Training loss: 1.6529823313770926
Validation loss: 2.362388199791618

Epoch: 5| Step: 3
Training loss: 1.8524335912623782
Validation loss: 2.4357262387364256

Epoch: 5| Step: 4
Training loss: 1.9145636700383875
Validation loss: 2.399792077216905

Epoch: 5| Step: 5
Training loss: 1.6455647535122127
Validation loss: 2.3839295935706657

Epoch: 5| Step: 6
Training loss: 1.3855587688029118
Validation loss: 2.3474315078257457

Epoch: 5| Step: 7
Training loss: 1.61232413286559
Validation loss: 2.346284775690471

Epoch: 5| Step: 8
Training loss: 2.0517022671414007
Validation loss: 2.3496289229278613

Epoch: 5| Step: 9
Training loss: 1.8342457870387183
Validation loss: 2.3916297220580427

Epoch: 5| Step: 10
Training loss: 2.029624405864749
Validation loss: 2.298637539269741

Epoch: 441| Step: 0
Training loss: 1.674744042724911
Validation loss: 2.4137896816271436

Epoch: 5| Step: 1
Training loss: 1.9151458788255837
Validation loss: 2.315628178674179

Epoch: 5| Step: 2
Training loss: 2.1682963355756635
Validation loss: 2.299937282530191

Epoch: 5| Step: 3
Training loss: 1.5095228071483064
Validation loss: 2.3586783692381315

Epoch: 5| Step: 4
Training loss: 2.216135338034845
Validation loss: 2.3468359387872626

Epoch: 5| Step: 5
Training loss: 1.1983359501473652
Validation loss: 2.507115961938807

Epoch: 5| Step: 6
Training loss: 1.4695302635729013
Validation loss: 2.377377903725356

Epoch: 5| Step: 7
Training loss: 1.6543302386273695
Validation loss: 2.360538090857845

Epoch: 5| Step: 8
Training loss: 1.8000873544477163
Validation loss: 2.4216459284382683

Epoch: 5| Step: 9
Training loss: 1.5954510455820563
Validation loss: 2.2859701640431482

Epoch: 5| Step: 10
Training loss: 2.4120081583014787
Validation loss: 2.3549253727796904

Epoch: 442| Step: 0
Training loss: 1.2522483632295391
Validation loss: 2.4284363591715072

Epoch: 5| Step: 1
Training loss: 1.6243394095854315
Validation loss: 2.416713773723035

Epoch: 5| Step: 2
Training loss: 1.3656067783702592
Validation loss: 2.40276095621551

Epoch: 5| Step: 3
Training loss: 2.1728167790404096
Validation loss: 2.397845186393137

Epoch: 5| Step: 4
Training loss: 2.1416562234745142
Validation loss: 2.35401139077125

Epoch: 5| Step: 5
Training loss: 1.5674419071073646
Validation loss: 2.4595330145688936

Epoch: 5| Step: 6
Training loss: 1.824476138137916
Validation loss: 2.3146247182290196

Epoch: 5| Step: 7
Training loss: 1.8248158688607383
Validation loss: 2.3645825373623097

Epoch: 5| Step: 8
Training loss: 2.537289795836621
Validation loss: 2.354415875645307

Epoch: 5| Step: 9
Training loss: 1.620398241237344
Validation loss: 2.4067159307352695

Epoch: 5| Step: 10
Training loss: 1.4508184359401146
Validation loss: 2.3821837291100176

Epoch: 443| Step: 0
Training loss: 1.8151332537282994
Validation loss: 2.3980678839920055

Epoch: 5| Step: 1
Training loss: 2.425694265971405
Validation loss: 2.426527635092645

Epoch: 5| Step: 2
Training loss: 2.006077710891333
Validation loss: 2.484852069193517

Epoch: 5| Step: 3
Training loss: 1.3001631909425717
Validation loss: 2.338042707637902

Epoch: 5| Step: 4
Training loss: 1.91675101661282
Validation loss: 2.4002561748249063

Epoch: 5| Step: 5
Training loss: 2.037064666111132
Validation loss: 2.377016944091538

Epoch: 5| Step: 6
Training loss: 1.4739288578748202
Validation loss: 2.403622100403253

Epoch: 5| Step: 7
Training loss: 1.342543304142751
Validation loss: 2.3944954529114533

Epoch: 5| Step: 8
Training loss: 1.8224543466592924
Validation loss: 2.3844780001816743

Epoch: 5| Step: 9
Training loss: 1.907933226818498
Validation loss: 2.3968001124899634

Epoch: 5| Step: 10
Training loss: 1.6257891572744396
Validation loss: 2.296929304172847

Epoch: 444| Step: 0
Training loss: 1.8578966177849372
Validation loss: 2.3670655467579955

Epoch: 5| Step: 1
Training loss: 1.6605836564941419
Validation loss: 2.389278818086613

Epoch: 5| Step: 2
Training loss: 2.943298622724466
Validation loss: 2.410962389054563

Epoch: 5| Step: 3
Training loss: 1.9065066305545944
Validation loss: 2.3988621474662275

Epoch: 5| Step: 4
Training loss: 1.354720995003842
Validation loss: 2.358111238589786

Epoch: 5| Step: 5
Training loss: 1.2661280162231903
Validation loss: 2.400818686799417

Epoch: 5| Step: 6
Training loss: 1.8635008100789865
Validation loss: 2.3735390224426522

Epoch: 5| Step: 7
Training loss: 1.530400721862192
Validation loss: 2.285460982519012

Epoch: 5| Step: 8
Training loss: 1.5284412080278735
Validation loss: 2.3241321956063232

Epoch: 5| Step: 9
Training loss: 1.8690561177792606
Validation loss: 2.3447770557127012

Epoch: 5| Step: 10
Training loss: 1.6750438997579535
Validation loss: 2.4394455101092496

Epoch: 445| Step: 0
Training loss: 2.466471622677304
Validation loss: 2.3441880635063455

Epoch: 5| Step: 1
Training loss: 1.6582243326041868
Validation loss: 2.4335264248863857

Epoch: 5| Step: 2
Training loss: 1.9138474324126813
Validation loss: 2.3199926847654435

Epoch: 5| Step: 3
Training loss: 2.2171717658637236
Validation loss: 2.4120474861358927

Epoch: 5| Step: 4
Training loss: 1.561727180095627
Validation loss: 2.397490143519204

Epoch: 5| Step: 5
Training loss: 1.5693679929734086
Validation loss: 2.3875109359129105

Epoch: 5| Step: 6
Training loss: 1.66528776666217
Validation loss: 2.3720084316518344

Epoch: 5| Step: 7
Training loss: 1.716779515652779
Validation loss: 2.375253258000296

Epoch: 5| Step: 8
Training loss: 1.3744149263766026
Validation loss: 2.3547160652518855

Epoch: 5| Step: 9
Training loss: 1.5822141188436039
Validation loss: 2.3414229743714943

Epoch: 5| Step: 10
Training loss: 1.9649675152061497
Validation loss: 2.430508481774512

Epoch: 446| Step: 0
Training loss: 1.5363791062785346
Validation loss: 2.4207770138158966

Epoch: 5| Step: 1
Training loss: 1.6002407667683
Validation loss: 2.4052829991465345

Epoch: 5| Step: 2
Training loss: 1.3121025755315134
Validation loss: 2.399406514462319

Epoch: 5| Step: 3
Training loss: 1.9066818873702698
Validation loss: 2.3702065486112547

Epoch: 5| Step: 4
Training loss: 1.8509125031369793
Validation loss: 2.363412663124749

Epoch: 5| Step: 5
Training loss: 1.6585636173912535
Validation loss: 2.335562774401731

Epoch: 5| Step: 6
Training loss: 2.095815408477071
Validation loss: 2.3869616677211676

Epoch: 5| Step: 7
Training loss: 1.7855575410987077
Validation loss: 2.3296311236147553

Epoch: 5| Step: 8
Training loss: 1.4737547159807043
Validation loss: 2.3981987934372286

Epoch: 5| Step: 9
Training loss: 1.6246195861392778
Validation loss: 2.423596831585808

Epoch: 5| Step: 10
Training loss: 2.390448669712298
Validation loss: 2.2974589229733495

Epoch: 447| Step: 0
Training loss: 1.7831489746963638
Validation loss: 2.3395321548982015

Epoch: 5| Step: 1
Training loss: 1.6924855794813494
Validation loss: 2.3824777126893544

Epoch: 5| Step: 2
Training loss: 1.8903473579269012
Validation loss: 2.37996645230862

Epoch: 5| Step: 3
Training loss: 1.5778541710243443
Validation loss: 2.3380130331385525

Epoch: 5| Step: 4
Training loss: 1.8842718396646418
Validation loss: 2.3969513836849803

Epoch: 5| Step: 5
Training loss: 1.6053853628217218
Validation loss: 2.3089538535450926

Epoch: 5| Step: 6
Training loss: 2.1913589227635084
Validation loss: 2.368481091209881

Epoch: 5| Step: 7
Training loss: 2.543712220157436
Validation loss: 2.416547747059849

Epoch: 5| Step: 8
Training loss: 1.550037119021031
Validation loss: 2.381065084314055

Epoch: 5| Step: 9
Training loss: 1.4403537122442294
Validation loss: 2.424049997599185

Epoch: 5| Step: 10
Training loss: 1.317192951883457
Validation loss: 2.4004088013894305

Epoch: 448| Step: 0
Training loss: 1.6961188442318966
Validation loss: 2.3596026745305343

Epoch: 5| Step: 1
Training loss: 2.1189977360380716
Validation loss: 2.4366374071086927

Epoch: 5| Step: 2
Training loss: 1.1691330939756766
Validation loss: 2.316236522021667

Epoch: 5| Step: 3
Training loss: 1.8472519285001199
Validation loss: 2.3802986859377713

Epoch: 5| Step: 4
Training loss: 1.6873320036729276
Validation loss: 2.3063766615897547

Epoch: 5| Step: 5
Training loss: 1.657594890496211
Validation loss: 2.4218729617890595

Epoch: 5| Step: 6
Training loss: 2.670925127694568
Validation loss: 2.4019800022324875

Epoch: 5| Step: 7
Training loss: 1.5187538335304387
Validation loss: 2.4281907486091847

Epoch: 5| Step: 8
Training loss: 1.7711710289988496
Validation loss: 2.4363047380374576

Epoch: 5| Step: 9
Training loss: 1.571729864924405
Validation loss: 2.3448549057584835

Epoch: 5| Step: 10
Training loss: 2.1352429078902944
Validation loss: 2.3872077996310224

Epoch: 449| Step: 0
Training loss: 1.9604188757575545
Validation loss: 2.3332981265908757

Epoch: 5| Step: 1
Training loss: 1.803029012521739
Validation loss: 2.3182151134379616

Epoch: 5| Step: 2
Training loss: 1.7335621759153268
Validation loss: 2.400808372710217

Epoch: 5| Step: 3
Training loss: 1.7526376465031743
Validation loss: 2.387017504208173

Epoch: 5| Step: 4
Training loss: 2.2942685240186544
Validation loss: 2.3893961977874514

Epoch: 5| Step: 5
Training loss: 2.394827247234735
Validation loss: 2.3696825563305817

Epoch: 5| Step: 6
Training loss: 1.4414980479216284
Validation loss: 2.421103553021634

Epoch: 5| Step: 7
Training loss: 1.6823206644147453
Validation loss: 2.4099399484680553

Epoch: 5| Step: 8
Training loss: 1.3145947316315902
Validation loss: 2.3524889843535615

Epoch: 5| Step: 9
Training loss: 1.8895869912894052
Validation loss: 2.379399332829904

Epoch: 5| Step: 10
Training loss: 1.4714765199634383
Validation loss: 2.405188958472246

Epoch: 450| Step: 0
Training loss: 1.1242956499701802
Validation loss: 2.3707148889590015

Epoch: 5| Step: 1
Training loss: 2.5048306524783697
Validation loss: 2.3590415322875686

Epoch: 5| Step: 2
Training loss: 1.967815358967224
Validation loss: 2.376264599234621

Epoch: 5| Step: 3
Training loss: 1.7694555944307366
Validation loss: 2.4074795589576587

Epoch: 5| Step: 4
Training loss: 2.0122812614273267
Validation loss: 2.330688398844161

Epoch: 5| Step: 5
Training loss: 1.7757608931952622
Validation loss: 2.374783789438455

Epoch: 5| Step: 6
Training loss: 1.3602491177270515
Validation loss: 2.315157555294752

Epoch: 5| Step: 7
Training loss: 2.089010881971738
Validation loss: 2.3771827492400575

Epoch: 5| Step: 8
Training loss: 1.7918001908811563
Validation loss: 2.2880604150776223

Epoch: 5| Step: 9
Training loss: 1.1471829990848375
Validation loss: 2.292497071270018

Epoch: 5| Step: 10
Training loss: 1.922983733633578
Validation loss: 2.3536773897006316

Epoch: 451| Step: 0
Training loss: 1.5088240634845969
Validation loss: 2.355197359799253

Epoch: 5| Step: 1
Training loss: 1.510435994342485
Validation loss: 2.3759309728317137

Epoch: 5| Step: 2
Training loss: 2.0597306356889145
Validation loss: 2.43959428517454

Epoch: 5| Step: 3
Training loss: 1.73758016442539
Validation loss: 2.3453389765325676

Epoch: 5| Step: 4
Training loss: 2.2549533362117344
Validation loss: 2.3945556558013883

Epoch: 5| Step: 5
Training loss: 1.778118392315271
Validation loss: 2.319587180656627

Epoch: 5| Step: 6
Training loss: 1.7464845633885284
Validation loss: 2.350490834038815

Epoch: 5| Step: 7
Training loss: 1.7663166413150488
Validation loss: 2.324805131945776

Epoch: 5| Step: 8
Training loss: 1.76469829174354
Validation loss: 2.390307429018768

Epoch: 5| Step: 9
Training loss: 2.1027652744586103
Validation loss: 2.3270333469800186

Epoch: 5| Step: 10
Training loss: 1.9055352043397222
Validation loss: 2.4047574668311658

Epoch: 452| Step: 0
Training loss: 0.9332493741441862
Validation loss: 2.3712378628032065

Epoch: 5| Step: 1
Training loss: 1.432170525254019
Validation loss: 2.4186480132947508

Epoch: 5| Step: 2
Training loss: 1.9386265463663301
Validation loss: 2.387986185945677

Epoch: 5| Step: 3
Training loss: 2.49771070567151
Validation loss: 2.336173261553231

Epoch: 5| Step: 4
Training loss: 1.7862534104268624
Validation loss: 2.4478717961297485

Epoch: 5| Step: 5
Training loss: 1.8515363602865418
Validation loss: 2.3998446638694544

Epoch: 5| Step: 6
Training loss: 1.7068104197389478
Validation loss: 2.38613072800782

Epoch: 5| Step: 7
Training loss: 2.04661418621776
Validation loss: 2.3302354311777176

Epoch: 5| Step: 8
Training loss: 1.783518300609845
Validation loss: 2.375756935951028

Epoch: 5| Step: 9
Training loss: 1.6165324188153272
Validation loss: 2.3564749800843385

Epoch: 5| Step: 10
Training loss: 1.718224878721118
Validation loss: 2.423234820472217

Epoch: 453| Step: 0
Training loss: 1.8146934391198473
Validation loss: 2.3289883065862322

Epoch: 5| Step: 1
Training loss: 1.5659797829922186
Validation loss: 2.3587120274833486

Epoch: 5| Step: 2
Training loss: 2.5422187789183788
Validation loss: 2.3913586176058987

Epoch: 5| Step: 3
Training loss: 1.5923280543468146
Validation loss: 2.3146210964274503

Epoch: 5| Step: 4
Training loss: 1.4806035365444656
Validation loss: 2.39235314984644

Epoch: 5| Step: 5
Training loss: 1.9483343346394406
Validation loss: 2.431176410922335

Epoch: 5| Step: 6
Training loss: 1.5371991801414318
Validation loss: 2.2971804188849636

Epoch: 5| Step: 7
Training loss: 1.8569636376333032
Validation loss: 2.3480651083391155

Epoch: 5| Step: 8
Training loss: 1.606649813636197
Validation loss: 2.3269176866806776

Epoch: 5| Step: 9
Training loss: 1.8187302683385866
Validation loss: 2.3535551269113695

Epoch: 5| Step: 10
Training loss: 1.8273619665156904
Validation loss: 2.3753429655269622

Epoch: 454| Step: 0
Training loss: 1.2451047889241758
Validation loss: 2.3239042170445043

Epoch: 5| Step: 1
Training loss: 1.3266779028274522
Validation loss: 2.4216445627979355

Epoch: 5| Step: 2
Training loss: 1.1669382505840957
Validation loss: 2.32708285364376

Epoch: 5| Step: 3
Training loss: 1.530732281415517
Validation loss: 2.3018537232481644

Epoch: 5| Step: 4
Training loss: 1.6645797140617635
Validation loss: 2.360489223947021

Epoch: 5| Step: 5
Training loss: 2.134529512545844
Validation loss: 2.4140635773593657

Epoch: 5| Step: 6
Training loss: 1.7044310855065654
Validation loss: 2.470603366601643

Epoch: 5| Step: 7
Training loss: 2.3391713496117035
Validation loss: 2.3556560132479394

Epoch: 5| Step: 8
Training loss: 1.5548735080800464
Validation loss: 2.41356645688632

Epoch: 5| Step: 9
Training loss: 2.5703703807122755
Validation loss: 2.3324688358856447

Epoch: 5| Step: 10
Training loss: 1.6389904053635889
Validation loss: 2.3241755611729067

Epoch: 455| Step: 0
Training loss: 1.0886701054827295
Validation loss: 2.4350324035181115

Epoch: 5| Step: 1
Training loss: 1.544389519679175
Validation loss: 2.365771710351506

Epoch: 5| Step: 2
Training loss: 1.6311577986460606
Validation loss: 2.3587628201729496

Epoch: 5| Step: 3
Training loss: 2.3627451895581184
Validation loss: 2.274435326374204

Epoch: 5| Step: 4
Training loss: 1.6970168305586903
Validation loss: 2.390338135999253

Epoch: 5| Step: 5
Training loss: 1.1838688798161594
Validation loss: 2.359867923767881

Epoch: 5| Step: 6
Training loss: 2.1417712184851916
Validation loss: 2.4132484682786366

Epoch: 5| Step: 7
Training loss: 1.8459919375556622
Validation loss: 2.3898823352815577

Epoch: 5| Step: 8
Training loss: 2.0992786803526595
Validation loss: 2.375071824028859

Epoch: 5| Step: 9
Training loss: 1.986638137796024
Validation loss: 2.3441226009497265

Epoch: 5| Step: 10
Training loss: 1.7348615634006763
Validation loss: 2.2681975212662033

Epoch: 456| Step: 0
Training loss: 2.3020209969988934
Validation loss: 2.3399131899225956

Epoch: 5| Step: 1
Training loss: 1.713707619218839
Validation loss: 2.383408847409666

Epoch: 5| Step: 2
Training loss: 1.6859551882235773
Validation loss: 2.379541264620823

Epoch: 5| Step: 3
Training loss: 1.921110357745638
Validation loss: 2.344532359813351

Epoch: 5| Step: 4
Training loss: 1.6272817877347228
Validation loss: 2.3544430328663375

Epoch: 5| Step: 5
Training loss: 1.9009168470678965
Validation loss: 2.3729535603260006

Epoch: 5| Step: 6
Training loss: 1.442783927543681
Validation loss: 2.3584621831095824

Epoch: 5| Step: 7
Training loss: 2.044570324254349
Validation loss: 2.372173262460068

Epoch: 5| Step: 8
Training loss: 1.7272256121529403
Validation loss: 2.3804518393175327

Epoch: 5| Step: 9
Training loss: 1.398756363814181
Validation loss: 2.365524650694346

Epoch: 5| Step: 10
Training loss: 1.585280559510543
Validation loss: 2.3674435147631816

Epoch: 457| Step: 0
Training loss: 1.8084072074508566
Validation loss: 2.388670874731358

Epoch: 5| Step: 1
Training loss: 1.9165639296930175
Validation loss: 2.348114755683976

Epoch: 5| Step: 2
Training loss: 1.868864447619966
Validation loss: 2.4052943321691638

Epoch: 5| Step: 3
Training loss: 1.7212785328125608
Validation loss: 2.3845324079463457

Epoch: 5| Step: 4
Training loss: 1.533005078396283
Validation loss: 2.2871355312533077

Epoch: 5| Step: 5
Training loss: 1.5425497910734272
Validation loss: 2.360651431697057

Epoch: 5| Step: 6
Training loss: 2.0303649147786973
Validation loss: 2.3305523475611434

Epoch: 5| Step: 7
Training loss: 2.5949897101461037
Validation loss: 2.3558949823426594

Epoch: 5| Step: 8
Training loss: 1.312454359078441
Validation loss: 2.375641266151095

Epoch: 5| Step: 9
Training loss: 1.638343678141338
Validation loss: 2.2651144304602906

Epoch: 5| Step: 10
Training loss: 1.339814210794094
Validation loss: 2.3356462434863126

Epoch: 458| Step: 0
Training loss: 1.6041583354122597
Validation loss: 2.2870678337489223

Epoch: 5| Step: 1
Training loss: 1.9292692279398778
Validation loss: 2.324700226535479

Epoch: 5| Step: 2
Training loss: 1.5622473703241093
Validation loss: 2.466359868449712

Epoch: 5| Step: 3
Training loss: 1.9554655165727488
Validation loss: 2.356370093110042

Epoch: 5| Step: 4
Training loss: 1.2965803156263362
Validation loss: 2.3865576060761344

Epoch: 5| Step: 5
Training loss: 2.2257528338722237
Validation loss: 2.380273709602408

Epoch: 5| Step: 6
Training loss: 1.8373150790839066
Validation loss: 2.352815025682934

Epoch: 5| Step: 7
Training loss: 1.7712324777192754
Validation loss: 2.4067034678298165

Epoch: 5| Step: 8
Training loss: 1.4628233951455425
Validation loss: 2.3761036170188254

Epoch: 5| Step: 9
Training loss: 1.8875931950481453
Validation loss: 2.516196247519835

Epoch: 5| Step: 10
Training loss: 1.8866127252899123
Validation loss: 2.3561193247000807

Epoch: 459| Step: 0
Training loss: 1.7570280231939788
Validation loss: 2.3213362565110387

Epoch: 5| Step: 1
Training loss: 2.6911782222093446
Validation loss: 2.3150910204877917

Epoch: 5| Step: 2
Training loss: 1.3086625266149727
Validation loss: 2.378778230819258

Epoch: 5| Step: 3
Training loss: 1.5660953355857468
Validation loss: 2.342583909992912

Epoch: 5| Step: 4
Training loss: 1.1972522330351911
Validation loss: 2.341236546972171

Epoch: 5| Step: 5
Training loss: 2.1390622414142237
Validation loss: 2.3540884802275643

Epoch: 5| Step: 6
Training loss: 1.9647028665865454
Validation loss: 2.3778921699415343

Epoch: 5| Step: 7
Training loss: 1.3607269229309247
Validation loss: 2.34530800284328

Epoch: 5| Step: 8
Training loss: 1.3936936884567794
Validation loss: 2.3623066919163946

Epoch: 5| Step: 9
Training loss: 1.8876554639846381
Validation loss: 2.304366212658753

Epoch: 5| Step: 10
Training loss: 1.989929115911554
Validation loss: 2.3645348864889426

Epoch: 460| Step: 0
Training loss: 1.6623942291343177
Validation loss: 2.280273430754386

Epoch: 5| Step: 1
Training loss: 1.1626924478529876
Validation loss: 2.3481725017599975

Epoch: 5| Step: 2
Training loss: 1.7283816872984177
Validation loss: 2.449110253213044

Epoch: 5| Step: 3
Training loss: 1.5917309706449003
Validation loss: 2.3033378941801086

Epoch: 5| Step: 4
Training loss: 1.608459656783091
Validation loss: 2.353643628414825

Epoch: 5| Step: 5
Training loss: 1.3967395042569946
Validation loss: 2.3814358601539927

Epoch: 5| Step: 6
Training loss: 2.6573807048846727
Validation loss: 2.3520732740964267

Epoch: 5| Step: 7
Training loss: 1.9529656917451328
Validation loss: 2.344190143562294

Epoch: 5| Step: 8
Training loss: 2.09014856129912
Validation loss: 2.357636257960343

Epoch: 5| Step: 9
Training loss: 1.5419613410517055
Validation loss: 2.3775678072366406

Epoch: 5| Step: 10
Training loss: 1.4868769390643553
Validation loss: 2.421540192780235

Epoch: 461| Step: 0
Training loss: 2.104421833039491
Validation loss: 2.3677669955545775

Epoch: 5| Step: 1
Training loss: 1.485994599826699
Validation loss: 2.397575984465328

Epoch: 5| Step: 2
Training loss: 1.7418297370365186
Validation loss: 2.3839532981505855

Epoch: 5| Step: 3
Training loss: 1.7702808939577817
Validation loss: 2.3945023205165907

Epoch: 5| Step: 4
Training loss: 1.4972351341815313
Validation loss: 2.366971158508959

Epoch: 5| Step: 5
Training loss: 1.5369578266202772
Validation loss: 2.40333532103254

Epoch: 5| Step: 6
Training loss: 1.7064869447170183
Validation loss: 2.377717844793926

Epoch: 5| Step: 7
Training loss: 1.6418421272323978
Validation loss: 2.353621500764021

Epoch: 5| Step: 8
Training loss: 1.5359063487808564
Validation loss: 2.38204239333429

Epoch: 5| Step: 9
Training loss: 1.9415073176581807
Validation loss: 2.3785377032546253

Epoch: 5| Step: 10
Training loss: 2.3426303477952155
Validation loss: 2.3180840610210245

Epoch: 462| Step: 0
Training loss: 2.389497678153328
Validation loss: 2.3483267454493078

Epoch: 5| Step: 1
Training loss: 1.3407541635175877
Validation loss: 2.342673668048439

Epoch: 5| Step: 2
Training loss: 1.680011239014225
Validation loss: 2.4299434235204878

Epoch: 5| Step: 3
Training loss: 1.819345438385183
Validation loss: 2.325696514523194

Epoch: 5| Step: 4
Training loss: 1.1181615571239671
Validation loss: 2.343023144530437

Epoch: 5| Step: 5
Training loss: 1.8022670615440735
Validation loss: 2.383628181914407

Epoch: 5| Step: 6
Training loss: 1.5910573165754576
Validation loss: 2.335133487337406

Epoch: 5| Step: 7
Training loss: 1.624613642612437
Validation loss: 2.3357148834857666

Epoch: 5| Step: 8
Training loss: 1.3132773776567455
Validation loss: 2.318546528434276

Epoch: 5| Step: 9
Training loss: 2.220283945156371
Validation loss: 2.4265804925609973

Epoch: 5| Step: 10
Training loss: 2.2424756439825564
Validation loss: 2.4834955559781173

Epoch: 463| Step: 0
Training loss: 1.6138941452690723
Validation loss: 2.38557197963287

Epoch: 5| Step: 1
Training loss: 2.011299045076183
Validation loss: 2.3752878114003937

Epoch: 5| Step: 2
Training loss: 2.0944582751778995
Validation loss: 2.3969900441147947

Epoch: 5| Step: 3
Training loss: 1.4760683231822802
Validation loss: 2.2861873381929314

Epoch: 5| Step: 4
Training loss: 1.8663883813551168
Validation loss: 2.4515822684058444

Epoch: 5| Step: 5
Training loss: 2.5686272659124687
Validation loss: 2.3572762731830794

Epoch: 5| Step: 6
Training loss: 1.7036343434093189
Validation loss: 2.3462705090686637

Epoch: 5| Step: 7
Training loss: 1.7356848367192104
Validation loss: 2.2449335940811888

Epoch: 5| Step: 8
Training loss: 1.5754930057642778
Validation loss: 2.3032973139945607

Epoch: 5| Step: 9
Training loss: 1.9204271647002975
Validation loss: 2.3214576933245636

Epoch: 5| Step: 10
Training loss: 1.1864390402082912
Validation loss: 2.3109216844179667

Epoch: 464| Step: 0
Training loss: 2.1065228429823857
Validation loss: 2.318766382962925

Epoch: 5| Step: 1
Training loss: 1.7487072256772613
Validation loss: 2.35038786529978

Epoch: 5| Step: 2
Training loss: 2.1526321799425054
Validation loss: 2.3638543371342644

Epoch: 5| Step: 3
Training loss: 1.9500340532117133
Validation loss: 2.3277970202959324

Epoch: 5| Step: 4
Training loss: 1.62872020656127
Validation loss: 2.3199847810892815

Epoch: 5| Step: 5
Training loss: 1.7951450146936032
Validation loss: 2.3302860057082415

Epoch: 5| Step: 6
Training loss: 1.9783799933651733
Validation loss: 2.315678873506984

Epoch: 5| Step: 7
Training loss: 1.5892441577284926
Validation loss: 2.2954628156451147

Epoch: 5| Step: 8
Training loss: 1.4385032470051249
Validation loss: 2.376065407616342

Epoch: 5| Step: 9
Training loss: 1.4772590729942723
Validation loss: 2.2904398665120578

Epoch: 5| Step: 10
Training loss: 1.558882760617195
Validation loss: 2.364743348244385

Epoch: 465| Step: 0
Training loss: 1.9446553418668109
Validation loss: 2.345339098137596

Epoch: 5| Step: 1
Training loss: 1.4245319902945952
Validation loss: 2.3725100657344864

Epoch: 5| Step: 2
Training loss: 1.4146974097179306
Validation loss: 2.3575796842920416

Epoch: 5| Step: 3
Training loss: 1.925483107943201
Validation loss: 2.3296962670938948

Epoch: 5| Step: 4
Training loss: 1.572378896104186
Validation loss: 2.333338173481833

Epoch: 5| Step: 5
Training loss: 1.5273020706929008
Validation loss: 2.3293955088340557

Epoch: 5| Step: 6
Training loss: 1.2055381255542759
Validation loss: 2.3561653896466384

Epoch: 5| Step: 7
Training loss: 1.7576070707869127
Validation loss: 2.3464025897364182

Epoch: 5| Step: 8
Training loss: 2.616642863981348
Validation loss: 2.3179340156348216

Epoch: 5| Step: 9
Training loss: 1.9347438898065235
Validation loss: 2.3043963799584986

Epoch: 5| Step: 10
Training loss: 1.6360702504508786
Validation loss: 2.3762144050599767

Epoch: 466| Step: 0
Training loss: 1.6126978375809073
Validation loss: 2.3239109970624785

Epoch: 5| Step: 1
Training loss: 1.8675710371976462
Validation loss: 2.4694187665049143

Epoch: 5| Step: 2
Training loss: 2.27735683640242
Validation loss: 2.295859203129966

Epoch: 5| Step: 3
Training loss: 1.962423361964452
Validation loss: 2.4107327404922922

Epoch: 5| Step: 4
Training loss: 2.107274005216869
Validation loss: 2.411376935450233

Epoch: 5| Step: 5
Training loss: 1.516086861937687
Validation loss: 2.3143168515074124

Epoch: 5| Step: 6
Training loss: 1.3352030023254229
Validation loss: 2.4225756851239892

Epoch: 5| Step: 7
Training loss: 1.602821339184773
Validation loss: 2.4346717726555944

Epoch: 5| Step: 8
Training loss: 1.567055356053952
Validation loss: 2.278026984822083

Epoch: 5| Step: 9
Training loss: 1.9310244974867095
Validation loss: 2.423164719197752

Epoch: 5| Step: 10
Training loss: 1.4637961748953245
Validation loss: 2.271464639880805

Epoch: 467| Step: 0
Training loss: 1.7183997057365719
Validation loss: 2.411362580838816

Epoch: 5| Step: 1
Training loss: 1.5894480219787446
Validation loss: 2.3533858498905187

Epoch: 5| Step: 2
Training loss: 2.275263102482075
Validation loss: 2.317181800873612

Epoch: 5| Step: 3
Training loss: 1.3965858689352733
Validation loss: 2.3233423842174092

Epoch: 5| Step: 4
Training loss: 1.4925360946507957
Validation loss: 2.3819898928698398

Epoch: 5| Step: 5
Training loss: 1.662922643416422
Validation loss: 2.286803803861771

Epoch: 5| Step: 6
Training loss: 1.7020985721324635
Validation loss: 2.327567314595059

Epoch: 5| Step: 7
Training loss: 1.651572333733363
Validation loss: 2.3607036389375917

Epoch: 5| Step: 8
Training loss: 1.786003863152131
Validation loss: 2.358973956289829

Epoch: 5| Step: 9
Training loss: 1.7147152793918536
Validation loss: 2.3279258244758387

Epoch: 5| Step: 10
Training loss: 1.91843994319429
Validation loss: 2.3847158532516435

Epoch: 468| Step: 0
Training loss: 1.4762983136261552
Validation loss: 2.3746107146169417

Epoch: 5| Step: 1
Training loss: 1.3938487971575193
Validation loss: 2.3851339843783856

Epoch: 5| Step: 2
Training loss: 1.412230047237955
Validation loss: 2.4279664304511877

Epoch: 5| Step: 3
Training loss: 2.735222123940076
Validation loss: 2.41597706952677

Epoch: 5| Step: 4
Training loss: 1.8596384839492615
Validation loss: 2.340211895373725

Epoch: 5| Step: 5
Training loss: 1.366307351321267
Validation loss: 2.353007010730835

Epoch: 5| Step: 6
Training loss: 1.491838344448076
Validation loss: 2.3757758187620266

Epoch: 5| Step: 7
Training loss: 1.9209367276027722
Validation loss: 2.3944469230224783

Epoch: 5| Step: 8
Training loss: 1.7824986414750368
Validation loss: 2.304709377223221

Epoch: 5| Step: 9
Training loss: 1.7285185905474207
Validation loss: 2.4329477570523372

Epoch: 5| Step: 10
Training loss: 2.0660299668848374
Validation loss: 2.329501577337497

Epoch: 469| Step: 0
Training loss: 1.4576242993909811
Validation loss: 2.371241060273265

Epoch: 5| Step: 1
Training loss: 1.6869447289069197
Validation loss: 2.327218320119683

Epoch: 5| Step: 2
Training loss: 1.4750588647766822
Validation loss: 2.3451166381102313

Epoch: 5| Step: 3
Training loss: 1.3184001548959123
Validation loss: 2.366676660178942

Epoch: 5| Step: 4
Training loss: 1.58622190434049
Validation loss: 2.411163026197606

Epoch: 5| Step: 5
Training loss: 1.6723208679612598
Validation loss: 2.408701692437743

Epoch: 5| Step: 6
Training loss: 1.8156415088316662
Validation loss: 2.357312687666688

Epoch: 5| Step: 7
Training loss: 1.6300718678972064
Validation loss: 2.403691060883675

Epoch: 5| Step: 8
Training loss: 2.442419223445357
Validation loss: 2.383535477785466

Epoch: 5| Step: 9
Training loss: 1.807133985634411
Validation loss: 2.383865215891199

Epoch: 5| Step: 10
Training loss: 1.7568208737281508
Validation loss: 2.3489706364114755

Epoch: 470| Step: 0
Training loss: 1.4076044129963996
Validation loss: 2.3222725908474784

Epoch: 5| Step: 1
Training loss: 1.7030100652427498
Validation loss: 2.297684172656156

Epoch: 5| Step: 2
Training loss: 1.770436642663449
Validation loss: 2.4632421559175537

Epoch: 5| Step: 3
Training loss: 2.209776233029271
Validation loss: 2.398064292000701

Epoch: 5| Step: 4
Training loss: 1.7579808133394346
Validation loss: 2.3233296147638045

Epoch: 5| Step: 5
Training loss: 1.5530580195331187
Validation loss: 2.313005118950941

Epoch: 5| Step: 6
Training loss: 1.824056287306923
Validation loss: 2.3820820566188967

Epoch: 5| Step: 7
Training loss: 1.6094899553149642
Validation loss: 2.309648967410306

Epoch: 5| Step: 8
Training loss: 1.46399153269732
Validation loss: 2.4580178834457223

Epoch: 5| Step: 9
Training loss: 1.9034154485547166
Validation loss: 2.4453168099265903

Epoch: 5| Step: 10
Training loss: 1.7205094781651675
Validation loss: 2.3729161715233973

Epoch: 471| Step: 0
Training loss: 1.5937298044159314
Validation loss: 2.404987223865861

Epoch: 5| Step: 1
Training loss: 1.2604116749730325
Validation loss: 2.279392680371399

Epoch: 5| Step: 2
Training loss: 2.479737662160743
Validation loss: 2.31797196530877

Epoch: 5| Step: 3
Training loss: 1.6861219784244847
Validation loss: 2.4470254234334177

Epoch: 5| Step: 4
Training loss: 1.9391371055593527
Validation loss: 2.3744416587138466

Epoch: 5| Step: 5
Training loss: 1.8818348605950148
Validation loss: 2.3696206509937054

Epoch: 5| Step: 6
Training loss: 1.2784778098700815
Validation loss: 2.461305994954995

Epoch: 5| Step: 7
Training loss: 1.4376130266950544
Validation loss: 2.4138648556257887

Epoch: 5| Step: 8
Training loss: 1.8341244450096903
Validation loss: 2.3068872220130423

Epoch: 5| Step: 9
Training loss: 1.5459757030694892
Validation loss: 2.400001299594541

Epoch: 5| Step: 10
Training loss: 1.3467012421651319
Validation loss: 2.4053032744863936

Epoch: 472| Step: 0
Training loss: 1.8486755011496814
Validation loss: 2.3946051025885664

Epoch: 5| Step: 1
Training loss: 1.5130018363280917
Validation loss: 2.2924538462046824

Epoch: 5| Step: 2
Training loss: 1.9185789423437236
Validation loss: 2.3741082361474097

Epoch: 5| Step: 3
Training loss: 1.555849647347901
Validation loss: 2.2923759779721435

Epoch: 5| Step: 4
Training loss: 2.8419264092041567
Validation loss: 2.4181067773096108

Epoch: 5| Step: 5
Training loss: 1.1411930916543331
Validation loss: 2.4689435819361414

Epoch: 5| Step: 6
Training loss: 1.6593641837534432
Validation loss: 2.2916189649284036

Epoch: 5| Step: 7
Training loss: 1.6089273959909032
Validation loss: 2.3512074301218426

Epoch: 5| Step: 8
Training loss: 1.4828438340505181
Validation loss: 2.3581297419545617

Epoch: 5| Step: 9
Training loss: 1.6752193193471172
Validation loss: 2.3694334397433123

Epoch: 5| Step: 10
Training loss: 1.450534767983402
Validation loss: 2.352419121738465

Epoch: 473| Step: 0
Training loss: 1.601072431809387
Validation loss: 2.3924151243730365

Epoch: 5| Step: 1
Training loss: 1.3601225189811796
Validation loss: 2.3267595612230716

Epoch: 5| Step: 2
Training loss: 1.6804717606110076
Validation loss: 2.418775223824138

Epoch: 5| Step: 3
Training loss: 1.4802772579302361
Validation loss: 2.430450536467998

Epoch: 5| Step: 4
Training loss: 2.037934557671698
Validation loss: 2.348621320676119

Epoch: 5| Step: 5
Training loss: 1.1774774527365188
Validation loss: 2.3138343882229653

Epoch: 5| Step: 6
Training loss: 1.5771712641053222
Validation loss: 2.40831337527458

Epoch: 5| Step: 7
Training loss: 1.6168460208992852
Validation loss: 2.391558087650378

Epoch: 5| Step: 8
Training loss: 1.7749175227170755
Validation loss: 2.317775807096175

Epoch: 5| Step: 9
Training loss: 2.455026266419778
Validation loss: 2.3995416725089065

Epoch: 5| Step: 10
Training loss: 1.50610571205794
Validation loss: 2.303843772847041

Epoch: 474| Step: 0
Training loss: 1.381179664512603
Validation loss: 2.355295687168672

Epoch: 5| Step: 1
Training loss: 1.8238743328255094
Validation loss: 2.3204671875092315

Epoch: 5| Step: 2
Training loss: 1.6246685276879156
Validation loss: 2.3249908844037734

Epoch: 5| Step: 3
Training loss: 1.6105828798624067
Validation loss: 2.34961679223357

Epoch: 5| Step: 4
Training loss: 1.378608952533249
Validation loss: 2.3870212406276905

Epoch: 5| Step: 5
Training loss: 2.58135700512047
Validation loss: 2.3529963612249123

Epoch: 5| Step: 6
Training loss: 2.0484141612523787
Validation loss: 2.3363314702543363

Epoch: 5| Step: 7
Training loss: 1.5017580220627536
Validation loss: 2.4095593300930043

Epoch: 5| Step: 8
Training loss: 1.5945969369489283
Validation loss: 2.39936395139785

Epoch: 5| Step: 9
Training loss: 1.4115374872551687
Validation loss: 2.310260931462784

Epoch: 5| Step: 10
Training loss: 1.6412722083025155
Validation loss: 2.3939408505883497

Epoch: 475| Step: 0
Training loss: 1.2354876658133882
Validation loss: 2.3170558061117164

Epoch: 5| Step: 1
Training loss: 1.722157793309711
Validation loss: 2.3762929146466587

Epoch: 5| Step: 2
Training loss: 1.8592420257975946
Validation loss: 2.294602258645696

Epoch: 5| Step: 3
Training loss: 1.590966805117172
Validation loss: 2.3091668050232483

Epoch: 5| Step: 4
Training loss: 1.6496181508579908
Validation loss: 2.311119901642293

Epoch: 5| Step: 5
Training loss: 1.837871944644705
Validation loss: 2.2723651535133227

Epoch: 5| Step: 6
Training loss: 1.5006510593196403
Validation loss: 2.332361213463396

Epoch: 5| Step: 7
Training loss: 2.4488236931562826
Validation loss: 2.394051588473378

Epoch: 5| Step: 8
Training loss: 2.0128393514992315
Validation loss: 2.3014424544233587

Epoch: 5| Step: 9
Training loss: 1.1710622893949771
Validation loss: 2.3515039835356495

Epoch: 5| Step: 10
Training loss: 1.414794058219376
Validation loss: 2.3293147119864077

Epoch: 476| Step: 0
Training loss: 1.5464369799122
Validation loss: 2.370389839917078

Epoch: 5| Step: 1
Training loss: 1.7530890857193373
Validation loss: 2.3253624407202764

Epoch: 5| Step: 2
Training loss: 1.59941127794093
Validation loss: 2.372053591450173

Epoch: 5| Step: 3
Training loss: 1.2781305252366153
Validation loss: 2.3719949617402047

Epoch: 5| Step: 4
Training loss: 1.858325950824574
Validation loss: 2.365782012477594

Epoch: 5| Step: 5
Training loss: 1.546536264033226
Validation loss: 2.3458061906351744

Epoch: 5| Step: 6
Training loss: 1.7661562770158616
Validation loss: 2.3525910661874905

Epoch: 5| Step: 7
Training loss: 1.5918041392903646
Validation loss: 2.340617357515344

Epoch: 5| Step: 8
Training loss: 1.5888675626392075
Validation loss: 2.313494673207239

Epoch: 5| Step: 9
Training loss: 2.833281310856759
Validation loss: 2.3794284534798655

Epoch: 5| Step: 10
Training loss: 1.3031098197949333
Validation loss: 2.2788566905728564

Epoch: 477| Step: 0
Training loss: 1.5919250811100338
Validation loss: 2.3750302583227416

Epoch: 5| Step: 1
Training loss: 2.326582634546019
Validation loss: 2.3864013316868875

Epoch: 5| Step: 2
Training loss: 1.6894833953438844
Validation loss: 2.3932187645229384

Epoch: 5| Step: 3
Training loss: 1.4442753550195833
Validation loss: 2.432226983100238

Epoch: 5| Step: 4
Training loss: 1.4626659429583735
Validation loss: 2.319541428759371

Epoch: 5| Step: 5
Training loss: 1.9693389496065679
Validation loss: 2.399893483324258

Epoch: 5| Step: 6
Training loss: 1.904334559923593
Validation loss: 2.2715998230276995

Epoch: 5| Step: 7
Training loss: 1.103614519127176
Validation loss: 2.4057193373915267

Epoch: 5| Step: 8
Training loss: 1.9416614878944238
Validation loss: 2.305655139580029

Epoch: 5| Step: 9
Training loss: 1.4102532097195497
Validation loss: 2.339218427239858

Epoch: 5| Step: 10
Training loss: 1.9896800698401775
Validation loss: 2.3616351774961064

Epoch: 478| Step: 0
Training loss: 1.6145796088719224
Validation loss: 2.3522416750454416

Epoch: 5| Step: 1
Training loss: 1.526458952250962
Validation loss: 2.3566251595636465

Epoch: 5| Step: 2
Training loss: 1.5769517521997523
Validation loss: 2.311825136899361

Epoch: 5| Step: 3
Training loss: 1.6577674823656632
Validation loss: 2.284245044157446

Epoch: 5| Step: 4
Training loss: 1.664450586760635
Validation loss: 2.3909635058190397

Epoch: 5| Step: 5
Training loss: 2.0094100593130575
Validation loss: 2.3110650845245604

Epoch: 5| Step: 6
Training loss: 1.0795116629171477
Validation loss: 2.368817879404495

Epoch: 5| Step: 7
Training loss: 1.4328739531638914
Validation loss: 2.3936880227207666

Epoch: 5| Step: 8
Training loss: 1.4345472111929107
Validation loss: 2.299203814502757

Epoch: 5| Step: 9
Training loss: 1.7733204000522453
Validation loss: 2.3973622548153974

Epoch: 5| Step: 10
Training loss: 2.3888481368302594
Validation loss: 2.3744973156407827

Epoch: 479| Step: 0
Training loss: 1.9324217047381862
Validation loss: 2.383236917441101

Epoch: 5| Step: 1
Training loss: 1.2130639387011455
Validation loss: 2.372263630035735

Epoch: 5| Step: 2
Training loss: 1.5454565152752404
Validation loss: 2.378162986110587

Epoch: 5| Step: 3
Training loss: 1.6389565839992892
Validation loss: 2.2958651620539623

Epoch: 5| Step: 4
Training loss: 1.4365728124746695
Validation loss: 2.3274785771558237

Epoch: 5| Step: 5
Training loss: 2.3594582650352938
Validation loss: 2.3121071414994137

Epoch: 5| Step: 6
Training loss: 1.8873177598297017
Validation loss: 2.332380916391846

Epoch: 5| Step: 7
Training loss: 2.1881791286752375
Validation loss: 2.360592285028341

Epoch: 5| Step: 8
Training loss: 1.353246356552578
Validation loss: 2.388101379114715

Epoch: 5| Step: 9
Training loss: 1.5065157359124663
Validation loss: 2.288404048103127

Epoch: 5| Step: 10
Training loss: 1.407465769485336
Validation loss: 2.441551881577187

Epoch: 480| Step: 0
Training loss: 1.316031881012898
Validation loss: 2.380222998973063

Epoch: 5| Step: 1
Training loss: 1.5416572501779917
Validation loss: 2.4043570857052114

Epoch: 5| Step: 2
Training loss: 2.0067703570489015
Validation loss: 2.3727974028658947

Epoch: 5| Step: 3
Training loss: 1.745947710112867
Validation loss: 2.4424401314944646

Epoch: 5| Step: 4
Training loss: 1.6160735933429338
Validation loss: 2.2993876069066785

Epoch: 5| Step: 5
Training loss: 1.2398231124842947
Validation loss: 2.3380868804199846

Epoch: 5| Step: 6
Training loss: 1.5504188402395263
Validation loss: 2.32800719700975

Epoch: 5| Step: 7
Training loss: 1.8252190863386142
Validation loss: 2.3597426915407564

Epoch: 5| Step: 8
Training loss: 1.5053870899044703
Validation loss: 2.344112812796333

Epoch: 5| Step: 9
Training loss: 1.3210538329100792
Validation loss: 2.3714347789131

Epoch: 5| Step: 10
Training loss: 2.4809138341760684
Validation loss: 2.3001923525693377

Epoch: 481| Step: 0
Training loss: 1.4409173896294583
Validation loss: 2.308296714062967

Epoch: 5| Step: 1
Training loss: 1.8362131764022158
Validation loss: 2.312425684822602

Epoch: 5| Step: 2
Training loss: 1.5556690433898996
Validation loss: 2.3872633221568713

Epoch: 5| Step: 3
Training loss: 1.4084994656389473
Validation loss: 2.438376400348217

Epoch: 5| Step: 4
Training loss: 1.5884122285065259
Validation loss: 2.4043815591681517

Epoch: 5| Step: 5
Training loss: 1.2850697033156453
Validation loss: 2.3524764063480896

Epoch: 5| Step: 6
Training loss: 2.0750844409720552
Validation loss: 2.332624282278871

Epoch: 5| Step: 7
Training loss: 1.6537704621056115
Validation loss: 2.369712074418941

Epoch: 5| Step: 8
Training loss: 1.928828986695869
Validation loss: 2.3036080039095124

Epoch: 5| Step: 9
Training loss: 2.254164127294364
Validation loss: 2.3407122049935185

Epoch: 5| Step: 10
Training loss: 1.499093974190404
Validation loss: 2.3279173800349375

Epoch: 482| Step: 0
Training loss: 1.8243429725713405
Validation loss: 2.3566424605717593

Epoch: 5| Step: 1
Training loss: 1.3194991546576114
Validation loss: 2.375688722852477

Epoch: 5| Step: 2
Training loss: 1.3002274626025712
Validation loss: 2.43384404247423

Epoch: 5| Step: 3
Training loss: 1.2975349126098799
Validation loss: 2.3575391118272164

Epoch: 5| Step: 4
Training loss: 1.5209197538025185
Validation loss: 2.3670408867574446

Epoch: 5| Step: 5
Training loss: 1.8154112356806709
Validation loss: 2.41737635269461

Epoch: 5| Step: 6
Training loss: 1.7723774031193624
Validation loss: 2.3725845627271966

Epoch: 5| Step: 7
Training loss: 1.4520628954608914
Validation loss: 2.4209797390388883

Epoch: 5| Step: 8
Training loss: 2.4599778014631366
Validation loss: 2.2724006080369037

Epoch: 5| Step: 9
Training loss: 2.3158359694034067
Validation loss: 2.3706558773877187

Epoch: 5| Step: 10
Training loss: 1.0974931154491365
Validation loss: 2.3959221230024967

Epoch: 483| Step: 0
Training loss: 2.5148871625155564
Validation loss: 2.3628716476150555

Epoch: 5| Step: 1
Training loss: 1.5581391324023224
Validation loss: 2.330990231970583

Epoch: 5| Step: 2
Training loss: 1.5192464448812852
Validation loss: 2.3634596049949117

Epoch: 5| Step: 3
Training loss: 1.1478045010099749
Validation loss: 2.363107560549148

Epoch: 5| Step: 4
Training loss: 1.5273661502063822
Validation loss: 2.3444025428817445

Epoch: 5| Step: 5
Training loss: 1.332558088628902
Validation loss: 2.365876378818644

Epoch: 5| Step: 6
Training loss: 1.733688080994565
Validation loss: 2.3260958562982883

Epoch: 5| Step: 7
Training loss: 1.4586167287216896
Validation loss: 2.371112598588152

Epoch: 5| Step: 8
Training loss: 2.0537029271643
Validation loss: 2.3646535638467308

Epoch: 5| Step: 9
Training loss: 1.3822767868716785
Validation loss: 2.3789930001988275

Epoch: 5| Step: 10
Training loss: 1.5984489134738076
Validation loss: 2.335007086092225

Epoch: 484| Step: 0
Training loss: 1.873663489524936
Validation loss: 2.3614175234151786

Epoch: 5| Step: 1
Training loss: 1.7800836592741625
Validation loss: 2.3429506148682875

Epoch: 5| Step: 2
Training loss: 1.9303828542596868
Validation loss: 2.4117460679626896

Epoch: 5| Step: 3
Training loss: 1.4868442275978722
Validation loss: 2.43345890195977

Epoch: 5| Step: 4
Training loss: 1.5070109237953375
Validation loss: 2.355684457753575

Epoch: 5| Step: 5
Training loss: 1.447263648151484
Validation loss: 2.4117726200229495

Epoch: 5| Step: 6
Training loss: 1.667001841538939
Validation loss: 2.482065832484649

Epoch: 5| Step: 7
Training loss: 1.6458127064760357
Validation loss: 2.337436906104429

Epoch: 5| Step: 8
Training loss: 1.3576944420590544
Validation loss: 2.319338831262343

Epoch: 5| Step: 9
Training loss: 1.3085809052249728
Validation loss: 2.4317131439213586

Epoch: 5| Step: 10
Training loss: 2.2674872801570087
Validation loss: 2.298650271351221

Epoch: 485| Step: 0
Training loss: 1.7122635949678846
Validation loss: 2.3784928912985346

Epoch: 5| Step: 1
Training loss: 2.1951303644070763
Validation loss: 2.403805845933934

Epoch: 5| Step: 2
Training loss: 1.991564305387116
Validation loss: 2.4151172472937237

Epoch: 5| Step: 3
Training loss: 1.585650563708732
Validation loss: 2.350138281369247

Epoch: 5| Step: 4
Training loss: 2.1251369880951594
Validation loss: 2.3400720988920343

Epoch: 5| Step: 5
Training loss: 1.8743807723823644
Validation loss: 2.3794593439499874

Epoch: 5| Step: 6
Training loss: 1.4055321874715696
Validation loss: 2.3543552566711377

Epoch: 5| Step: 7
Training loss: 1.6367548025890188
Validation loss: 2.3412818727267988

Epoch: 5| Step: 8
Training loss: 1.2941661718203419
Validation loss: 2.3736223641225527

Epoch: 5| Step: 9
Training loss: 1.3661857204550443
Validation loss: 2.416700502596524

Epoch: 5| Step: 10
Training loss: 1.4581566930695682
Validation loss: 2.3665496596056332

Epoch: 486| Step: 0
Training loss: 1.9028779519374022
Validation loss: 2.314309744294084

Epoch: 5| Step: 1
Training loss: 1.9386291905042456
Validation loss: 2.3996072727493227

Epoch: 5| Step: 2
Training loss: 2.5722952850416037
Validation loss: 2.302361844881507

Epoch: 5| Step: 3
Training loss: 1.4676321929971108
Validation loss: 2.3469268707017643

Epoch: 5| Step: 4
Training loss: 1.7972261832008691
Validation loss: 2.3501641124776147

Epoch: 5| Step: 5
Training loss: 1.2729957141878991
Validation loss: 2.3086676011024174

Epoch: 5| Step: 6
Training loss: 1.6991915996618658
Validation loss: 2.3014623635680795

Epoch: 5| Step: 7
Training loss: 1.488488050295602
Validation loss: 2.30947203366472

Epoch: 5| Step: 8
Training loss: 1.2258768291177735
Validation loss: 2.4525803608722954

Epoch: 5| Step: 9
Training loss: 1.0262063115400355
Validation loss: 2.304561555235778

Epoch: 5| Step: 10
Training loss: 1.2449986539779803
Validation loss: 2.4517513139196594

Epoch: 487| Step: 0
Training loss: 1.4361617451802189
Validation loss: 2.4566614219696477

Epoch: 5| Step: 1
Training loss: 1.0582074801389536
Validation loss: 2.3741303045937268

Epoch: 5| Step: 2
Training loss: 1.6212386101033656
Validation loss: 2.399146233403443

Epoch: 5| Step: 3
Training loss: 1.2683221311655157
Validation loss: 2.3797977827909467

Epoch: 5| Step: 4
Training loss: 1.8562950462758137
Validation loss: 2.280044649657

Epoch: 5| Step: 5
Training loss: 1.643797794706019
Validation loss: 2.2934843961018916

Epoch: 5| Step: 6
Training loss: 1.7250722952910447
Validation loss: 2.334751596493946

Epoch: 5| Step: 7
Training loss: 1.5812452082504826
Validation loss: 2.3590937382075214

Epoch: 5| Step: 8
Training loss: 1.8703003796126567
Validation loss: 2.2864636973742485

Epoch: 5| Step: 9
Training loss: 2.6666725774540563
Validation loss: 2.322687983631792

Epoch: 5| Step: 10
Training loss: 1.6155573050448533
Validation loss: 2.377147520772432

Epoch: 488| Step: 0
Training loss: 1.6097581277740742
Validation loss: 2.421876227900855

Epoch: 5| Step: 1
Training loss: 1.6913094790220848
Validation loss: 2.3407696029207825

Epoch: 5| Step: 2
Training loss: 1.9076347949396022
Validation loss: 2.3496925911340893

Epoch: 5| Step: 3
Training loss: 1.0955391011400597
Validation loss: 2.3951508743575074

Epoch: 5| Step: 4
Training loss: 1.3421945662750998
Validation loss: 2.4070034895615566

Epoch: 5| Step: 5
Training loss: 1.5302442244788586
Validation loss: 2.4171366363679843

Epoch: 5| Step: 6
Training loss: 2.2774318985539983
Validation loss: 2.426031325579192

Epoch: 5| Step: 7
Training loss: 1.2753116413796863
Validation loss: 2.2935229523681206

Epoch: 5| Step: 8
Training loss: 1.6976157859898808
Validation loss: 2.3141608577791564

Epoch: 5| Step: 9
Training loss: 2.053576266833938
Validation loss: 2.302165919221841

Epoch: 5| Step: 10
Training loss: 1.3743626678038416
Validation loss: 2.4688659730034335

Epoch: 489| Step: 0
Training loss: 1.4973929319491819
Validation loss: 2.347769875856737

Epoch: 5| Step: 1
Training loss: 1.4926854446193174
Validation loss: 2.353020394316971

Epoch: 5| Step: 2
Training loss: 1.5976331191498694
Validation loss: 2.3280239359955366

Epoch: 5| Step: 3
Training loss: 1.2174046745032567
Validation loss: 2.3312680229535694

Epoch: 5| Step: 4
Training loss: 1.3111902695716626
Validation loss: 2.3484714966621394

Epoch: 5| Step: 5
Training loss: 1.6519017270856298
Validation loss: 2.314154542170128

Epoch: 5| Step: 6
Training loss: 2.0497134962147614
Validation loss: 2.438597685185404

Epoch: 5| Step: 7
Training loss: 2.215933180280162
Validation loss: 2.356670900785951

Epoch: 5| Step: 8
Training loss: 1.5088340184696054
Validation loss: 2.3186222429180283

Epoch: 5| Step: 9
Training loss: 1.5123017835385961
Validation loss: 2.389910810087308

Epoch: 5| Step: 10
Training loss: 1.713340152227189
Validation loss: 2.3723931888929255

Epoch: 490| Step: 0
Training loss: 1.3228328508072842
Validation loss: 2.38221628525823

Epoch: 5| Step: 1
Training loss: 1.8109940158823064
Validation loss: 2.443714900966292

Epoch: 5| Step: 2
Training loss: 1.6529702155585138
Validation loss: 2.359763784035574

Epoch: 5| Step: 3
Training loss: 1.6016654376932618
Validation loss: 2.341986315137823

Epoch: 5| Step: 4
Training loss: 1.3762127989575328
Validation loss: 2.3619513225726583

Epoch: 5| Step: 5
Training loss: 1.3806516930903905
Validation loss: 2.306417192597681

Epoch: 5| Step: 6
Training loss: 1.3878117941305061
Validation loss: 2.323421476577709

Epoch: 5| Step: 7
Training loss: 1.4159161973443986
Validation loss: 2.2951871948890896

Epoch: 5| Step: 8
Training loss: 1.7091403388654227
Validation loss: 2.3366996648584655

Epoch: 5| Step: 9
Training loss: 2.6455902728877523
Validation loss: 2.3581047558548445

Epoch: 5| Step: 10
Training loss: 1.5874209677179556
Validation loss: 2.373708141551644

Epoch: 491| Step: 0
Training loss: 1.6097269506698615
Validation loss: 2.3007298837134815

Epoch: 5| Step: 1
Training loss: 1.516975509023401
Validation loss: 2.3114378390237107

Epoch: 5| Step: 2
Training loss: 1.535667586646285
Validation loss: 2.372699033110566

Epoch: 5| Step: 3
Training loss: 1.8669649254845422
Validation loss: 2.379222297725641

Epoch: 5| Step: 4
Training loss: 2.3111057718023753
Validation loss: 2.4290339510186634

Epoch: 5| Step: 5
Training loss: 1.2296660211764268
Validation loss: 2.3410591369415714

Epoch: 5| Step: 6
Training loss: 1.261007669569223
Validation loss: 2.391763285175647

Epoch: 5| Step: 7
Training loss: 1.4039500608066997
Validation loss: 2.346932383732124

Epoch: 5| Step: 8
Training loss: 1.7262248403827478
Validation loss: 2.369578340528096

Epoch: 5| Step: 9
Training loss: 1.5910911071989156
Validation loss: 2.31615965147817

Epoch: 5| Step: 10
Training loss: 2.108345289033105
Validation loss: 2.313799607371634

Epoch: 492| Step: 0
Training loss: 1.5191613852861972
Validation loss: 2.3453382824273397

Epoch: 5| Step: 1
Training loss: 1.5684058157575869
Validation loss: 2.402945084723586

Epoch: 5| Step: 2
Training loss: 1.4654092332992918
Validation loss: 2.41664882825888

Epoch: 5| Step: 3
Training loss: 1.0304435119546076
Validation loss: 2.414342863769498

Epoch: 5| Step: 4
Training loss: 1.9928245573021532
Validation loss: 2.312445093648818

Epoch: 5| Step: 5
Training loss: 1.164857989402639
Validation loss: 2.418805117894734

Epoch: 5| Step: 6
Training loss: 1.4855915906437018
Validation loss: 2.331453273142913

Epoch: 5| Step: 7
Training loss: 1.5587205572337888
Validation loss: 2.394120473934515

Epoch: 5| Step: 8
Training loss: 2.4937856685984428
Validation loss: 2.276374791577565

Epoch: 5| Step: 9
Training loss: 1.6735281925932466
Validation loss: 2.3876217492201546

Epoch: 5| Step: 10
Training loss: 1.6508922649701676
Validation loss: 2.4127325497735357

Epoch: 493| Step: 0
Training loss: 1.4716593558078388
Validation loss: 2.4024431158899255

Epoch: 5| Step: 1
Training loss: 2.0995281824780956
Validation loss: 2.400649263273797

Epoch: 5| Step: 2
Training loss: 1.4750075453225806
Validation loss: 2.385042256191006

Epoch: 5| Step: 3
Training loss: 1.8446485625094258
Validation loss: 2.37454353095229

Epoch: 5| Step: 4
Training loss: 1.8905074658391472
Validation loss: 2.3205236064963763

Epoch: 5| Step: 5
Training loss: 1.6774966123634845
Validation loss: 2.452325971259093

Epoch: 5| Step: 6
Training loss: 1.6446427332406333
Validation loss: 2.2828063566763337

Epoch: 5| Step: 7
Training loss: 1.5226035941322686
Validation loss: 2.2636933133930657

Epoch: 5| Step: 8
Training loss: 1.3812448268465547
Validation loss: 2.3585247095925386

Epoch: 5| Step: 9
Training loss: 1.4127289611783553
Validation loss: 2.2437215848443075

Epoch: 5| Step: 10
Training loss: 1.6156409788540553
Validation loss: 2.3939613044466586

Epoch: 494| Step: 0
Training loss: 1.3844833193869714
Validation loss: 2.33298632316469

Epoch: 5| Step: 1
Training loss: 1.790584466551997
Validation loss: 2.335716077655619

Epoch: 5| Step: 2
Training loss: 2.041873791626852
Validation loss: 2.390758468051742

Epoch: 5| Step: 3
Training loss: 1.7155091682618258
Validation loss: 2.376398867351207

Epoch: 5| Step: 4
Training loss: 1.0425570814939669
Validation loss: 2.4665945614461466

Epoch: 5| Step: 5
Training loss: 1.6331537063592547
Validation loss: 2.38692142230323

Epoch: 5| Step: 6
Training loss: 1.087948645203681
Validation loss: 2.305390875401996

Epoch: 5| Step: 7
Training loss: 1.0667490425686668
Validation loss: 2.3067929808519856

Epoch: 5| Step: 8
Training loss: 2.489189138022632
Validation loss: 2.330956743690207

Epoch: 5| Step: 9
Training loss: 1.339374026157098
Validation loss: 2.2822456159505453

Epoch: 5| Step: 10
Training loss: 1.4544023211724
Validation loss: 2.3054931689593405

Epoch: 495| Step: 0
Training loss: 1.279869126319913
Validation loss: 2.3974294930206654

Epoch: 5| Step: 1
Training loss: 1.4976657347759372
Validation loss: 2.359100286687041

Epoch: 5| Step: 2
Training loss: 1.5541028787785442
Validation loss: 2.3027421124414853

Epoch: 5| Step: 3
Training loss: 1.69960357868431
Validation loss: 2.36281932064606

Epoch: 5| Step: 4
Training loss: 1.7881774045591174
Validation loss: 2.2976396169877487

Epoch: 5| Step: 5
Training loss: 2.2828986076601048
Validation loss: 2.46230166444237

Epoch: 5| Step: 6
Training loss: 1.6429080881192626
Validation loss: 2.3534876411962076

Epoch: 5| Step: 7
Training loss: 0.944330540891137
Validation loss: 2.3437738003086337

Epoch: 5| Step: 8
Training loss: 1.6936123668873233
Validation loss: 2.3858388020423598

Epoch: 5| Step: 9
Training loss: 1.4726361746393593
Validation loss: 2.4273002742682896

Epoch: 5| Step: 10
Training loss: 1.8074335121388594
Validation loss: 2.3664207287452985

Epoch: 496| Step: 0
Training loss: 2.374613379079584
Validation loss: 2.324641259963469

Epoch: 5| Step: 1
Training loss: 1.6034597184986146
Validation loss: 2.3136937824618395

Epoch: 5| Step: 2
Training loss: 1.6252619458862536
Validation loss: 2.424971670136029

Epoch: 5| Step: 3
Training loss: 2.2086634719039484
Validation loss: 2.372911549672254

Epoch: 5| Step: 4
Training loss: 1.1005395779665983
Validation loss: 2.3978144397667527

Epoch: 5| Step: 5
Training loss: 1.4832983027118587
Validation loss: 2.2167072103997545

Epoch: 5| Step: 6
Training loss: 1.5182008386218906
Validation loss: 2.3348945151932385

Epoch: 5| Step: 7
Training loss: 1.3836564759005003
Validation loss: 2.3403733571530037

Epoch: 5| Step: 8
Training loss: 1.7020152965131716
Validation loss: 2.3324771025547055

Epoch: 5| Step: 9
Training loss: 1.3486240615947533
Validation loss: 2.307977172940428

Epoch: 5| Step: 10
Training loss: 1.1857242859978412
Validation loss: 2.3471238964236796

Epoch: 497| Step: 0
Training loss: 2.378669113090922
Validation loss: 2.4055351950346737

Epoch: 5| Step: 1
Training loss: 1.3697297791786343
Validation loss: 2.2581863806254963

Epoch: 5| Step: 2
Training loss: 1.571101279978109
Validation loss: 2.3462089847025136

Epoch: 5| Step: 3
Training loss: 1.1153745546443725
Validation loss: 2.404498446825518

Epoch: 5| Step: 4
Training loss: 1.3571574221094769
Validation loss: 2.432959456454207

Epoch: 5| Step: 5
Training loss: 2.1659842541334533
Validation loss: 2.381445238694734

Epoch: 5| Step: 6
Training loss: 1.8772961861708377
Validation loss: 2.327861316452031

Epoch: 5| Step: 7
Training loss: 1.5995737521311983
Validation loss: 2.432956771592391

Epoch: 5| Step: 8
Training loss: 1.2757152477227824
Validation loss: 2.3174083162042964

Epoch: 5| Step: 9
Training loss: 1.4042883860791755
Validation loss: 2.337759560306701

Epoch: 5| Step: 10
Training loss: 1.4534107870642043
Validation loss: 2.292642679383438

Epoch: 498| Step: 0
Training loss: 1.3692644746191887
Validation loss: 2.388096374425521

Epoch: 5| Step: 1
Training loss: 1.9368552704181985
Validation loss: 2.326996739045346

Epoch: 5| Step: 2
Training loss: 1.2355280934732555
Validation loss: 2.3642334712877475

Epoch: 5| Step: 3
Training loss: 1.2471081183549735
Validation loss: 2.306204603621953

Epoch: 5| Step: 4
Training loss: 1.5429539160679346
Validation loss: 2.4209369474235887

Epoch: 5| Step: 5
Training loss: 1.657987870442343
Validation loss: 2.3360283096226935

Epoch: 5| Step: 6
Training loss: 1.2072604557421143
Validation loss: 2.363451486556479

Epoch: 5| Step: 7
Training loss: 1.6967518405232662
Validation loss: 2.4113174884957496

Epoch: 5| Step: 8
Training loss: 2.6080159742767144
Validation loss: 2.27604709496098

Epoch: 5| Step: 9
Training loss: 1.7960738012957396
Validation loss: 2.3504338806039016

Epoch: 5| Step: 10
Training loss: 1.1751132220645892
Validation loss: 2.35985326452622

Epoch: 499| Step: 0
Training loss: 1.6320371110006504
Validation loss: 2.3032893652720583

Epoch: 5| Step: 1
Training loss: 1.4308448651218812
Validation loss: 2.3946131266482955

Epoch: 5| Step: 2
Training loss: 1.862306863896539
Validation loss: 2.4880244813085297

Epoch: 5| Step: 3
Training loss: 1.1840908907529384
Validation loss: 2.378334302511029

Epoch: 5| Step: 4
Training loss: 1.9476315566791655
Validation loss: 2.3198914355595086

Epoch: 5| Step: 5
Training loss: 1.665082162427878
Validation loss: 2.3029027681382845

Epoch: 5| Step: 6
Training loss: 0.8553797706070715
Validation loss: 2.33993607389126

Epoch: 5| Step: 7
Training loss: 1.7591808503321695
Validation loss: 2.294798842923993

Epoch: 5| Step: 8
Training loss: 1.5734063032707475
Validation loss: 2.3815133267404174

Epoch: 5| Step: 9
Training loss: 2.4661173243152072
Validation loss: 2.36282755355286

Epoch: 5| Step: 10
Training loss: 1.6775514727226801
Validation loss: 2.3454531108718815

Epoch: 500| Step: 0
Training loss: 2.203641032934464
Validation loss: 2.361994652068109

Epoch: 5| Step: 1
Training loss: 1.7490391818413014
Validation loss: 2.366320877263953

Epoch: 5| Step: 2
Training loss: 1.3919963718317696
Validation loss: 2.418971679556514

Epoch: 5| Step: 3
Training loss: 1.4873359461484559
Validation loss: 2.3293788671996167

Epoch: 5| Step: 4
Training loss: 1.8328044374098358
Validation loss: 2.376685703052177

Epoch: 5| Step: 5
Training loss: 1.4640035025028377
Validation loss: 2.3315784360119394

Epoch: 5| Step: 6
Training loss: 1.726388361507849
Validation loss: 2.3600938171001316

Epoch: 5| Step: 7
Training loss: 1.438894010573166
Validation loss: 2.282210997907791

Epoch: 5| Step: 8
Training loss: 1.504204658528679
Validation loss: 2.3270910873928

Epoch: 5| Step: 9
Training loss: 1.6475464640940714
Validation loss: 2.359388069301896

Epoch: 5| Step: 10
Training loss: 1.5999505094980337
Validation loss: 2.3370630505708134

Epoch: 501| Step: 0
Training loss: 1.2672736650139795
Validation loss: 2.3163519486707504

Epoch: 5| Step: 1
Training loss: 1.467284181312072
Validation loss: 2.2862441529089144

Epoch: 5| Step: 2
Training loss: 2.181437784325917
Validation loss: 2.408116822918209

Epoch: 5| Step: 3
Training loss: 2.059435098839137
Validation loss: 2.3287679914800075

Epoch: 5| Step: 4
Training loss: 1.391369995124636
Validation loss: 2.2605457869181778

Epoch: 5| Step: 5
Training loss: 1.395983583515014
Validation loss: 2.3755353541200344

Epoch: 5| Step: 6
Training loss: 1.4407820345011115
Validation loss: 2.2825589315223263

Epoch: 5| Step: 7
Training loss: 1.0905320923152637
Validation loss: 2.278033843988482

Epoch: 5| Step: 8
Training loss: 1.7973155932744234
Validation loss: 2.400643407466043

Epoch: 5| Step: 9
Training loss: 1.7395816353734423
Validation loss: 2.339405315726641

Epoch: 5| Step: 10
Training loss: 1.7205629670544589
Validation loss: 2.361446479872448

Epoch: 502| Step: 0
Training loss: 1.7986798054436999
Validation loss: 2.3514986294926277

Epoch: 5| Step: 1
Training loss: 1.8529801233278569
Validation loss: 2.3930481746270758

Epoch: 5| Step: 2
Training loss: 1.325108232216298
Validation loss: 2.336502180893682

Epoch: 5| Step: 3
Training loss: 1.904534552976032
Validation loss: 2.454061229851926

Epoch: 5| Step: 4
Training loss: 1.3905985969008587
Validation loss: 2.3963620343945378

Epoch: 5| Step: 5
Training loss: 1.668411374828018
Validation loss: 2.352244346863357

Epoch: 5| Step: 6
Training loss: 1.104684126658597
Validation loss: 2.3768584628353353

Epoch: 5| Step: 7
Training loss: 2.283581626460559
Validation loss: 2.404854164397262

Epoch: 5| Step: 8
Training loss: 1.1566285725036152
Validation loss: 2.3557881499071813

Epoch: 5| Step: 9
Training loss: 2.023534117052632
Validation loss: 2.353810091608113

Epoch: 5| Step: 10
Training loss: 1.7441467080004855
Validation loss: 2.3381117087404437

Epoch: 503| Step: 0
Training loss: 1.5456057649210717
Validation loss: 2.3535444613680507

Epoch: 5| Step: 1
Training loss: 1.8938793830611886
Validation loss: 2.418561028174485

Epoch: 5| Step: 2
Training loss: 1.3314466340174698
Validation loss: 2.3069878251297458

Epoch: 5| Step: 3
Training loss: 1.4706407105676278
Validation loss: 2.348581811099029

Epoch: 5| Step: 4
Training loss: 1.7408732430701266
Validation loss: 2.3790714854403743

Epoch: 5| Step: 5
Training loss: 2.0057740309406245
Validation loss: 2.281866230025557

Epoch: 5| Step: 6
Training loss: 1.8100437753347098
Validation loss: 2.3959595331782775

Epoch: 5| Step: 7
Training loss: 1.5252615938794873
Validation loss: 2.393447176368922

Epoch: 5| Step: 8
Training loss: 1.5123710703478326
Validation loss: 2.3057241564936812

Epoch: 5| Step: 9
Training loss: 1.4874703508515643
Validation loss: 2.362269429244526

Epoch: 5| Step: 10
Training loss: 1.5295057677814614
Validation loss: 2.3140989084541066

Epoch: 504| Step: 0
Training loss: 2.379113299500028
Validation loss: 2.3505269091962773

Epoch: 5| Step: 1
Training loss: 1.486249362698379
Validation loss: 2.2846858522513567

Epoch: 5| Step: 2
Training loss: 1.6768289061078614
Validation loss: 2.3677290663096033

Epoch: 5| Step: 3
Training loss: 1.7484689554584332
Validation loss: 2.4215308853609208

Epoch: 5| Step: 4
Training loss: 1.4187703874778446
Validation loss: 2.3468373430435197

Epoch: 5| Step: 5
Training loss: 1.636120670998059
Validation loss: 2.37115737487203

Epoch: 5| Step: 6
Training loss: 1.900644346199561
Validation loss: 2.3096866433634053

Epoch: 5| Step: 7
Training loss: 1.2244965472408291
Validation loss: 2.3732572280598236

Epoch: 5| Step: 8
Training loss: 1.537080369455126
Validation loss: 2.300993877669585

Epoch: 5| Step: 9
Training loss: 1.3860472866815758
Validation loss: 2.3291471651293914

Epoch: 5| Step: 10
Training loss: 1.4563877024235365
Validation loss: 2.273660072454651

Epoch: 505| Step: 0
Training loss: 1.7362266485128326
Validation loss: 2.414093574111273

Epoch: 5| Step: 1
Training loss: 1.6740142825575852
Validation loss: 2.438754751361094

Epoch: 5| Step: 2
Training loss: 1.473176656795676
Validation loss: 2.30962882914017

Epoch: 5| Step: 3
Training loss: 1.4727930465828334
Validation loss: 2.398388433654312

Epoch: 5| Step: 4
Training loss: 1.5325809844432212
Validation loss: 2.3716293881162627

Epoch: 5| Step: 5
Training loss: 1.481505340587145
Validation loss: 2.293211033051674

Epoch: 5| Step: 6
Training loss: 1.4770753161701953
Validation loss: 2.3913867864569025

Epoch: 5| Step: 7
Training loss: 1.6745478574942474
Validation loss: 2.3293664747671325

Epoch: 5| Step: 8
Training loss: 2.427921941605374
Validation loss: 2.3494498780822757

Epoch: 5| Step: 9
Training loss: 1.5020694762008275
Validation loss: 2.3956203571122616

Epoch: 5| Step: 10
Training loss: 1.329784702643562
Validation loss: 2.4023972729512266

Epoch: 506| Step: 0
Training loss: 1.4824229203975645
Validation loss: 2.3404948051758763

Epoch: 5| Step: 1
Training loss: 0.9998944346020762
Validation loss: 2.3202128773757917

Epoch: 5| Step: 2
Training loss: 0.9845065982591679
Validation loss: 2.377147882593211

Epoch: 5| Step: 3
Training loss: 2.268506762704066
Validation loss: 2.4573986041587164

Epoch: 5| Step: 4
Training loss: 1.5039320906363591
Validation loss: 2.3832503840529204

Epoch: 5| Step: 5
Training loss: 1.668212944219458
Validation loss: 2.42624118888517

Epoch: 5| Step: 6
Training loss: 1.3000623302922667
Validation loss: 2.358773187146795

Epoch: 5| Step: 7
Training loss: 1.6996925132019658
Validation loss: 2.3802612978064066

Epoch: 5| Step: 8
Training loss: 1.9913896346717905
Validation loss: 2.398179757930207

Epoch: 5| Step: 9
Training loss: 1.5063827930970897
Validation loss: 2.384059704001731

Epoch: 5| Step: 10
Training loss: 1.9219397557211781
Validation loss: 2.3105728713400158

Epoch: 507| Step: 0
Training loss: 1.6811774454450428
Validation loss: 2.427033250413367

Epoch: 5| Step: 1
Training loss: 2.4025392530332823
Validation loss: 2.364927812031449

Epoch: 5| Step: 2
Training loss: 1.5012111542541184
Validation loss: 2.410390139206455

Epoch: 5| Step: 3
Training loss: 2.0142905379201843
Validation loss: 2.346223115115056

Epoch: 5| Step: 4
Training loss: 1.3362728835627447
Validation loss: 2.2761854000263395

Epoch: 5| Step: 5
Training loss: 1.6601291070850972
Validation loss: 2.3635833170227083

Epoch: 5| Step: 6
Training loss: 1.5726554434746287
Validation loss: 2.3597054600841303

Epoch: 5| Step: 7
Training loss: 1.4832925965933912
Validation loss: 2.3776405887967678

Epoch: 5| Step: 8
Training loss: 1.1445351558267132
Validation loss: 2.416185614034535

Epoch: 5| Step: 9
Training loss: 1.5702476677867403
Validation loss: 2.448786707421361

Epoch: 5| Step: 10
Training loss: 1.4656340641481609
Validation loss: 2.3363951453110294

Epoch: 508| Step: 0
Training loss: 1.309770698207606
Validation loss: 2.3934674769944744

Epoch: 5| Step: 1
Training loss: 2.3594740284733033
Validation loss: 2.4004996983595097

Epoch: 5| Step: 2
Training loss: 1.7669434477559685
Validation loss: 2.3262338604303014

Epoch: 5| Step: 3
Training loss: 1.6772015294980318
Validation loss: 2.456670422542449

Epoch: 5| Step: 4
Training loss: 1.610554235322664
Validation loss: 2.3676763399575824

Epoch: 5| Step: 5
Training loss: 1.1666877381374643
Validation loss: 2.4127756638082207

Epoch: 5| Step: 6
Training loss: 1.5026300737691833
Validation loss: 2.3875771372885994

Epoch: 5| Step: 7
Training loss: 1.5248240885349897
Validation loss: 2.359880873014839

Epoch: 5| Step: 8
Training loss: 1.6671683112830458
Validation loss: 2.3394344367010076

Epoch: 5| Step: 9
Training loss: 1.1635817488708031
Validation loss: 2.4148014200263006

Epoch: 5| Step: 10
Training loss: 1.263632347750473
Validation loss: 2.3297367247254437

Epoch: 509| Step: 0
Training loss: 1.4804669785300253
Validation loss: 2.3763228630655377

Epoch: 5| Step: 1
Training loss: 1.5551872791961143
Validation loss: 2.33781030269018

Epoch: 5| Step: 2
Training loss: 1.5666700031704917
Validation loss: 2.303912747214901

Epoch: 5| Step: 3
Training loss: 1.5754924004461353
Validation loss: 2.2951916878709193

Epoch: 5| Step: 4
Training loss: 1.2150338566933316
Validation loss: 2.326624130291887

Epoch: 5| Step: 5
Training loss: 1.139077377745452
Validation loss: 2.3168748017420913

Epoch: 5| Step: 6
Training loss: 1.6131492727020915
Validation loss: 2.378432023677996

Epoch: 5| Step: 7
Training loss: 1.5169132695912968
Validation loss: 2.3456968434956935

Epoch: 5| Step: 8
Training loss: 2.6709982342530316
Validation loss: 2.447878657988253

Epoch: 5| Step: 9
Training loss: 1.8539062345675963
Validation loss: 2.38365893084311

Epoch: 5| Step: 10
Training loss: 1.0867393881115355
Validation loss: 2.3230469612548883

Epoch: 510| Step: 0
Training loss: 1.3843705187998419
Validation loss: 2.3686613838134787

Epoch: 5| Step: 1
Training loss: 1.649125665145667
Validation loss: 2.3465573097479813

Epoch: 5| Step: 2
Training loss: 1.4245856301682551
Validation loss: 2.325660254825542

Epoch: 5| Step: 3
Training loss: 1.263611357240636
Validation loss: 2.292952136360573

Epoch: 5| Step: 4
Training loss: 1.244482834730934
Validation loss: 2.318610199331268

Epoch: 5| Step: 5
Training loss: 1.38288413686595
Validation loss: 2.3675161733429086

Epoch: 5| Step: 6
Training loss: 2.6180201785808572
Validation loss: 2.4370839416219154

Epoch: 5| Step: 7
Training loss: 1.40414860861889
Validation loss: 2.3620652695950137

Epoch: 5| Step: 8
Training loss: 1.0520747848515961
Validation loss: 2.425952420978942

Epoch: 5| Step: 9
Training loss: 2.0220472353842887
Validation loss: 2.347295604585467

Epoch: 5| Step: 10
Training loss: 1.4751460633452964
Validation loss: 2.34466130304211

Epoch: 511| Step: 0
Training loss: 1.619154171950264
Validation loss: 2.312809321217661

Epoch: 5| Step: 1
Training loss: 1.31176128488888
Validation loss: 2.316193318281075

Epoch: 5| Step: 2
Training loss: 1.4563066659797987
Validation loss: 2.2986857637750773

Epoch: 5| Step: 3
Training loss: 1.829934813792418
Validation loss: 2.3884181738122208

Epoch: 5| Step: 4
Training loss: 1.6446077958729532
Validation loss: 2.468356210006679

Epoch: 5| Step: 5
Training loss: 1.378079606949987
Validation loss: 2.411441310079281

Epoch: 5| Step: 6
Training loss: 1.819844459971783
Validation loss: 2.312156536445128

Epoch: 5| Step: 7
Training loss: 2.45157861260589
Validation loss: 2.314659375371465

Epoch: 5| Step: 8
Training loss: 1.6485464051055332
Validation loss: 2.417928465634306

Epoch: 5| Step: 9
Training loss: 1.1973040576136764
Validation loss: 2.4597504950725786

Epoch: 5| Step: 10
Training loss: 0.969362311510757
Validation loss: 2.364900733476428

Epoch: 512| Step: 0
Training loss: 1.2266734370704757
Validation loss: 2.3509001415855635

Epoch: 5| Step: 1
Training loss: 1.4867145772806245
Validation loss: 2.376143817471936

Epoch: 5| Step: 2
Training loss: 2.4473772685652575
Validation loss: 2.3921846110274374

Epoch: 5| Step: 3
Training loss: 1.483097691338788
Validation loss: 2.387436750051253

Epoch: 5| Step: 4
Training loss: 1.5970292854800847
Validation loss: 2.446525186800749

Epoch: 5| Step: 5
Training loss: 1.659726147755654
Validation loss: 2.3717469873524273

Epoch: 5| Step: 6
Training loss: 1.3717632778269697
Validation loss: 2.350821121483982

Epoch: 5| Step: 7
Training loss: 1.6407467751495275
Validation loss: 2.372387635072197

Epoch: 5| Step: 8
Training loss: 1.5165026768208922
Validation loss: 2.312678032307472

Epoch: 5| Step: 9
Training loss: 1.6752210271960284
Validation loss: 2.3448939189149898

Epoch: 5| Step: 10
Training loss: 1.118376092922384
Validation loss: 2.396241345290212

Epoch: 513| Step: 0
Training loss: 1.4946034630868945
Validation loss: 2.3974485585444256

Epoch: 5| Step: 1
Training loss: 2.4032141620579344
Validation loss: 2.30713463049814

Epoch: 5| Step: 2
Training loss: 1.5138262270092477
Validation loss: 2.3790912223198233

Epoch: 5| Step: 3
Training loss: 1.2640186995378557
Validation loss: 2.3238842718069783

Epoch: 5| Step: 4
Training loss: 1.4670401827269748
Validation loss: 2.3755197431271693

Epoch: 5| Step: 5
Training loss: 1.1069040854028935
Validation loss: 2.2946547636908043

Epoch: 5| Step: 6
Training loss: 1.893597118891856
Validation loss: 2.3179466649500085

Epoch: 5| Step: 7
Training loss: 1.8005058425516147
Validation loss: 2.3185975895708437

Epoch: 5| Step: 8
Training loss: 1.6291382256226188
Validation loss: 2.335351670562864

Epoch: 5| Step: 9
Training loss: 1.2300154077913967
Validation loss: 2.349316432286708

Epoch: 5| Step: 10
Training loss: 1.476315674512039
Validation loss: 2.4208324717098884

Epoch: 514| Step: 0
Training loss: 1.7747927961164167
Validation loss: 2.4326974392801337

Epoch: 5| Step: 1
Training loss: 1.171632461880611
Validation loss: 2.399108526164683

Epoch: 5| Step: 2
Training loss: 1.6024743438428461
Validation loss: 2.3840422341966367

Epoch: 5| Step: 3
Training loss: 1.2299572078115097
Validation loss: 2.392011598102573

Epoch: 5| Step: 4
Training loss: 1.8614186828295416
Validation loss: 2.33006471525994

Epoch: 5| Step: 5
Training loss: 1.8389229383642447
Validation loss: 2.451602532063143

Epoch: 5| Step: 6
Training loss: 1.268853015193986
Validation loss: 2.3915756890728765

Epoch: 5| Step: 7
Training loss: 1.603696564329011
Validation loss: 2.3346717580501757

Epoch: 5| Step: 8
Training loss: 1.2854450214459174
Validation loss: 2.2958657929519712

Epoch: 5| Step: 9
Training loss: 2.332909704535124
Validation loss: 2.3640828468731057

Epoch: 5| Step: 10
Training loss: 1.5586442293869598
Validation loss: 2.3824361632055915

Epoch: 515| Step: 0
Training loss: 0.9492019840219743
Validation loss: 2.3081813191426135

Epoch: 5| Step: 1
Training loss: 1.4791626012325385
Validation loss: 2.348367362995651

Epoch: 5| Step: 2
Training loss: 2.3395382485896166
Validation loss: 2.2909891706286203

Epoch: 5| Step: 3
Training loss: 1.3745413362012224
Validation loss: 2.3780740511869785

Epoch: 5| Step: 4
Training loss: 1.447399714921009
Validation loss: 2.387381714782031

Epoch: 5| Step: 5
Training loss: 1.2382752331127231
Validation loss: 2.378272369597636

Epoch: 5| Step: 6
Training loss: 1.252133598947793
Validation loss: 2.340153255026159

Epoch: 5| Step: 7
Training loss: 1.8002378094724867
Validation loss: 2.2561836451758275

Epoch: 5| Step: 8
Training loss: 1.8176949472307928
Validation loss: 2.27777433028295

Epoch: 5| Step: 9
Training loss: 1.4925951974946134
Validation loss: 2.3509424839649937

Epoch: 5| Step: 10
Training loss: 1.823178110902022
Validation loss: 2.312061722808707

Epoch: 516| Step: 0
Training loss: 2.073735010094068
Validation loss: 2.3390610483973786

Epoch: 5| Step: 1
Training loss: 1.6526431991467223
Validation loss: 2.3430632954572133

Epoch: 5| Step: 2
Training loss: 1.5136940837584463
Validation loss: 2.3128610054522283

Epoch: 5| Step: 3
Training loss: 1.2145800043565376
Validation loss: 2.4254736335144833

Epoch: 5| Step: 4
Training loss: 1.4723503948694472
Validation loss: 2.3580047479247535

Epoch: 5| Step: 5
Training loss: 1.8717185233663984
Validation loss: 2.3273773391303956

Epoch: 5| Step: 6
Training loss: 1.5548575610211686
Validation loss: 2.2704985549531616

Epoch: 5| Step: 7
Training loss: 1.3426064349273306
Validation loss: 2.3150267594589593

Epoch: 5| Step: 8
Training loss: 1.8460919651792909
Validation loss: 2.2860709054678496

Epoch: 5| Step: 9
Training loss: 1.371897144182354
Validation loss: 2.3874325375119745

Epoch: 5| Step: 10
Training loss: 1.4365202010978584
Validation loss: 2.447228465915145

Epoch: 517| Step: 0
Training loss: 1.5046884063369381
Validation loss: 2.3153418102431598

Epoch: 5| Step: 1
Training loss: 2.6426832314936695
Validation loss: 2.3791553197129343

Epoch: 5| Step: 2
Training loss: 1.6379050823931902
Validation loss: 2.321928402210631

Epoch: 5| Step: 3
Training loss: 1.0223267912649665
Validation loss: 2.39650480180095

Epoch: 5| Step: 4
Training loss: 1.446884290364637
Validation loss: 2.3185157695828242

Epoch: 5| Step: 5
Training loss: 0.9410572908962519
Validation loss: 2.3021313045123026

Epoch: 5| Step: 6
Training loss: 1.5345285311644628
Validation loss: 2.3062715165174192

Epoch: 5| Step: 7
Training loss: 1.7422596185237786
Validation loss: 2.306698371304898

Epoch: 5| Step: 8
Training loss: 1.7395026212992137
Validation loss: 2.311874476326295

Epoch: 5| Step: 9
Training loss: 1.237130385408053
Validation loss: 2.2871863044677236

Epoch: 5| Step: 10
Training loss: 1.5822976723967794
Validation loss: 2.361961613684714

Epoch: 518| Step: 0
Training loss: 1.2280188497624982
Validation loss: 2.311843355356013

Epoch: 5| Step: 1
Training loss: 1.746442448490964
Validation loss: 2.38189914734881

Epoch: 5| Step: 2
Training loss: 1.9271354943166814
Validation loss: 2.3187556242918133

Epoch: 5| Step: 3
Training loss: 1.4987075323685155
Validation loss: 2.366685745160048

Epoch: 5| Step: 4
Training loss: 1.7655173749951916
Validation loss: 2.3091927747125767

Epoch: 5| Step: 5
Training loss: 1.4281098045692637
Validation loss: 2.405478636840721

Epoch: 5| Step: 6
Training loss: 1.5131723281032314
Validation loss: 2.3411380096479664

Epoch: 5| Step: 7
Training loss: 1.6737479298630804
Validation loss: 2.4077755806725984

Epoch: 5| Step: 8
Training loss: 1.1247208566851805
Validation loss: 2.2499923637561356

Epoch: 5| Step: 9
Training loss: 2.24540378753976
Validation loss: 2.3200468467375113

Epoch: 5| Step: 10
Training loss: 1.2402758493772759
Validation loss: 2.3997930717817924

Epoch: 519| Step: 0
Training loss: 1.7106500671579374
Validation loss: 2.2678184214137684

Epoch: 5| Step: 1
Training loss: 1.1514109828860501
Validation loss: 2.3401825890772114

Epoch: 5| Step: 2
Training loss: 1.5681829483922773
Validation loss: 2.405086296668964

Epoch: 5| Step: 3
Training loss: 1.6081646562320524
Validation loss: 2.3766562920711705

Epoch: 5| Step: 4
Training loss: 0.9483843931510018
Validation loss: 2.3147793970942017

Epoch: 5| Step: 5
Training loss: 1.4646391458670633
Validation loss: 2.31922768630902

Epoch: 5| Step: 6
Training loss: 1.1004596898427543
Validation loss: 2.373174149562954

Epoch: 5| Step: 7
Training loss: 1.5567067896854354
Validation loss: 2.3313774937276914

Epoch: 5| Step: 8
Training loss: 1.4432181365372758
Validation loss: 2.2634065549663296

Epoch: 5| Step: 9
Training loss: 2.314406356660913
Validation loss: 2.4261063347729164

Epoch: 5| Step: 10
Training loss: 1.9050794665965647
Validation loss: 2.3758105469231263

Epoch: 520| Step: 0
Training loss: 1.878272506836954
Validation loss: 2.2964794685338665

Epoch: 5| Step: 1
Training loss: 1.0249076359699894
Validation loss: 2.2888379889671246

Epoch: 5| Step: 2
Training loss: 1.52025157653496
Validation loss: 2.3704641266802695

Epoch: 5| Step: 3
Training loss: 1.1290496946232136
Validation loss: 2.360098174025701

Epoch: 5| Step: 4
Training loss: 1.8422585613596905
Validation loss: 2.3370031673189433

Epoch: 5| Step: 5
Training loss: 2.490590699078127
Validation loss: 2.391248449190586

Epoch: 5| Step: 6
Training loss: 1.5907111273870083
Validation loss: 2.326153888892709

Epoch: 5| Step: 7
Training loss: 1.1385092251068418
Validation loss: 2.2575371619035427

Epoch: 5| Step: 8
Training loss: 1.4357059727952044
Validation loss: 2.3684063179337596

Epoch: 5| Step: 9
Training loss: 1.6759639898223573
Validation loss: 2.324833271330417

Epoch: 5| Step: 10
Training loss: 1.217626983474919
Validation loss: 2.377561193169323

Epoch: 521| Step: 0
Training loss: 1.006344043293945
Validation loss: 2.2924644990620964

Epoch: 5| Step: 1
Training loss: 1.8158688642443204
Validation loss: 2.3307231537042488

Epoch: 5| Step: 2
Training loss: 1.561397163290616
Validation loss: 2.334339565058618

Epoch: 5| Step: 3
Training loss: 1.346909733654109
Validation loss: 2.3441223887823655

Epoch: 5| Step: 4
Training loss: 2.176092978152967
Validation loss: 2.340846553081139

Epoch: 5| Step: 5
Training loss: 1.1664316020032184
Validation loss: 2.3437719594275372

Epoch: 5| Step: 6
Training loss: 1.5464416821766318
Validation loss: 2.3202610827084484

Epoch: 5| Step: 7
Training loss: 1.301260370218691
Validation loss: 2.3097924548559425

Epoch: 5| Step: 8
Training loss: 1.3995089981236857
Validation loss: 2.3837464523407332

Epoch: 5| Step: 9
Training loss: 1.4822612770952528
Validation loss: 2.366373326413564

Epoch: 5| Step: 10
Training loss: 1.7976591969797049
Validation loss: 2.3227207931369156

Epoch: 522| Step: 0
Training loss: 1.7561670358413743
Validation loss: 2.269648281581199

Epoch: 5| Step: 1
Training loss: 2.118656563738163
Validation loss: 2.4010468977780266

Epoch: 5| Step: 2
Training loss: 1.432297122829333
Validation loss: 2.295841171609787

Epoch: 5| Step: 3
Training loss: 1.661955811772694
Validation loss: 2.349263071706844

Epoch: 5| Step: 4
Training loss: 1.2038816079421877
Validation loss: 2.3442618649933724

Epoch: 5| Step: 5
Training loss: 1.1721564399999576
Validation loss: 2.287905796601065

Epoch: 5| Step: 6
Training loss: 1.89906350948526
Validation loss: 2.3479065705577193

Epoch: 5| Step: 7
Training loss: 1.1657876665679876
Validation loss: 2.350534913037756

Epoch: 5| Step: 8
Training loss: 1.2535649961245197
Validation loss: 2.3608540500197703

Epoch: 5| Step: 9
Training loss: 1.8374775372643803
Validation loss: 2.3905397577307372

Epoch: 5| Step: 10
Training loss: 1.5016057638392033
Validation loss: 2.383053581512952

Epoch: 523| Step: 0
Training loss: 1.3596986407290639
Validation loss: 2.2330155858585394

Epoch: 5| Step: 1
Training loss: 1.594209193479853
Validation loss: 2.368131694227857

Epoch: 5| Step: 2
Training loss: 2.394052180646539
Validation loss: 2.3190540989182944

Epoch: 5| Step: 3
Training loss: 1.8080893816375219
Validation loss: 2.3598641302334187

Epoch: 5| Step: 4
Training loss: 1.2404527847333202
Validation loss: 2.2529075384605886

Epoch: 5| Step: 5
Training loss: 1.3870421986063444
Validation loss: 2.313261155718896

Epoch: 5| Step: 6
Training loss: 1.5972982066043688
Validation loss: 2.3275475929476626

Epoch: 5| Step: 7
Training loss: 1.6053379126184573
Validation loss: 2.38786918355521

Epoch: 5| Step: 8
Training loss: 1.2889489326156849
Validation loss: 2.446315154749325

Epoch: 5| Step: 9
Training loss: 1.1687899353221953
Validation loss: 2.3335089075449473

Epoch: 5| Step: 10
Training loss: 1.7445222409362093
Validation loss: 2.353363024809485

Epoch: 524| Step: 0
Training loss: 2.344828243187818
Validation loss: 2.320487695176511

Epoch: 5| Step: 1
Training loss: 1.429945542025489
Validation loss: 2.3501586430259134

Epoch: 5| Step: 2
Training loss: 1.3655116682360744
Validation loss: 2.380011647185069

Epoch: 5| Step: 3
Training loss: 1.9475440894683165
Validation loss: 2.3056754459831628

Epoch: 5| Step: 4
Training loss: 1.3002711490142593
Validation loss: 2.33385247305628

Epoch: 5| Step: 5
Training loss: 1.4517143539642987
Validation loss: 2.3817270034524425

Epoch: 5| Step: 6
Training loss: 1.2812054789181553
Validation loss: 2.3118836607831517

Epoch: 5| Step: 7
Training loss: 0.9534746372988471
Validation loss: 2.303560522926233

Epoch: 5| Step: 8
Training loss: 1.7213557517948057
Validation loss: 2.2975916014941977

Epoch: 5| Step: 9
Training loss: 1.7773635360119486
Validation loss: 2.4032565235909322

Epoch: 5| Step: 10
Training loss: 1.612820908307038
Validation loss: 2.3644172408104467

Epoch: 525| Step: 0
Training loss: 2.2047781727594864
Validation loss: 2.3325070362521076

Epoch: 5| Step: 1
Training loss: 1.3447831639918097
Validation loss: 2.342851486526515

Epoch: 5| Step: 2
Training loss: 1.1187041331857193
Validation loss: 2.3700787014889713

Epoch: 5| Step: 3
Training loss: 1.2018165905070612
Validation loss: 2.3246577480366497

Epoch: 5| Step: 4
Training loss: 1.082340072464784
Validation loss: 2.285961667791599

Epoch: 5| Step: 5
Training loss: 2.0243960433577586
Validation loss: 2.22934917622469

Epoch: 5| Step: 6
Training loss: 1.1474924156254134
Validation loss: 2.223118840433634

Epoch: 5| Step: 7
Training loss: 1.8499056972490786
Validation loss: 2.3238245354583698

Epoch: 5| Step: 8
Training loss: 1.425838939597016
Validation loss: 2.3599566312037505

Epoch: 5| Step: 9
Training loss: 1.4437502278909875
Validation loss: 2.3131572495563457

Epoch: 5| Step: 10
Training loss: 1.1200323097643552
Validation loss: 2.2913593524330462

Epoch: 526| Step: 0
Training loss: 1.501388384105038
Validation loss: 2.4017598886383187

Epoch: 5| Step: 1
Training loss: 1.2163334878022534
Validation loss: 2.279076844594762

Epoch: 5| Step: 2
Training loss: 1.644616928949432
Validation loss: 2.3786293627181427

Epoch: 5| Step: 3
Training loss: 1.7317544883778901
Validation loss: 2.381918908154751

Epoch: 5| Step: 4
Training loss: 1.6325538831992874
Validation loss: 2.31845111584028

Epoch: 5| Step: 5
Training loss: 1.1481624455541648
Validation loss: 2.342224301580457

Epoch: 5| Step: 6
Training loss: 2.1687139106847875
Validation loss: 2.3828606788771447

Epoch: 5| Step: 7
Training loss: 1.5002862339306868
Validation loss: 2.290701357630315

Epoch: 5| Step: 8
Training loss: 1.543071192950102
Validation loss: 2.284656264588823

Epoch: 5| Step: 9
Training loss: 1.2039509204892194
Validation loss: 2.3924881764811756

Epoch: 5| Step: 10
Training loss: 1.6973761027631935
Validation loss: 2.3566439296938926

Epoch: 527| Step: 0
Training loss: 1.6829040955787622
Validation loss: 2.4007784713182785

Epoch: 5| Step: 1
Training loss: 1.2385696412251315
Validation loss: 2.2733980804150558

Epoch: 5| Step: 2
Training loss: 1.5492279190969442
Validation loss: 2.362157807008239

Epoch: 5| Step: 3
Training loss: 2.261716430873703
Validation loss: 2.326955926396757

Epoch: 5| Step: 4
Training loss: 1.7664657886430433
Validation loss: 2.3703700349117383

Epoch: 5| Step: 5
Training loss: 1.585580644720178
Validation loss: 2.318332318139971

Epoch: 5| Step: 6
Training loss: 1.425147012187745
Validation loss: 2.3241870745951805

Epoch: 5| Step: 7
Training loss: 1.243176192758597
Validation loss: 2.3184666704541343

Epoch: 5| Step: 8
Training loss: 1.547320754434937
Validation loss: 2.3312078484292935

Epoch: 5| Step: 9
Training loss: 1.619478455054246
Validation loss: 2.3043726151703336

Epoch: 5| Step: 10
Training loss: 1.1996822393430697
Validation loss: 2.408304448392209

Epoch: 528| Step: 0
Training loss: 1.4007123633412017
Validation loss: 2.3638297032827222

Epoch: 5| Step: 1
Training loss: 1.9428890099937306
Validation loss: 2.392091462576266

Epoch: 5| Step: 2
Training loss: 1.4747586004275113
Validation loss: 2.3384559554980915

Epoch: 5| Step: 3
Training loss: 1.23040543650665
Validation loss: 2.4079861481763887

Epoch: 5| Step: 4
Training loss: 1.2921102848991974
Validation loss: 2.4037401267081595

Epoch: 5| Step: 5
Training loss: 1.5073294384627796
Validation loss: 2.3108604425793198

Epoch: 5| Step: 6
Training loss: 1.6152140790224643
Validation loss: 2.3030785324100385

Epoch: 5| Step: 7
Training loss: 1.5611874980647806
Validation loss: 2.414254582018456

Epoch: 5| Step: 8
Training loss: 1.305140981841774
Validation loss: 2.262688888363724

Epoch: 5| Step: 9
Training loss: 1.4220593511103692
Validation loss: 2.381424184292819

Epoch: 5| Step: 10
Training loss: 2.4420849642520084
Validation loss: 2.353985484261515

Epoch: 529| Step: 0
Training loss: 1.7566534671733922
Validation loss: 2.362061214766488

Epoch: 5| Step: 1
Training loss: 1.069742816873296
Validation loss: 2.329882391029447

Epoch: 5| Step: 2
Training loss: 1.2456634639575983
Validation loss: 2.319629669121289

Epoch: 5| Step: 3
Training loss: 1.4300821728871795
Validation loss: 2.3700656451674638

Epoch: 5| Step: 4
Training loss: 1.2419827370449787
Validation loss: 2.315682708427236

Epoch: 5| Step: 5
Training loss: 2.348764776698025
Validation loss: 2.335771509843354

Epoch: 5| Step: 6
Training loss: 1.6601343490053557
Validation loss: 2.3136884434162197

Epoch: 5| Step: 7
Training loss: 1.642097901895371
Validation loss: 2.2820924447127595

Epoch: 5| Step: 8
Training loss: 1.2280894694151179
Validation loss: 2.302472879279615

Epoch: 5| Step: 9
Training loss: 1.9820229114782593
Validation loss: 2.3791859777505997

Epoch: 5| Step: 10
Training loss: 1.1636520276485152
Validation loss: 2.310364547335882

Epoch: 530| Step: 0
Training loss: 1.4596270227205075
Validation loss: 2.342307173737632

Epoch: 5| Step: 1
Training loss: 1.5179125639470576
Validation loss: 2.409402123774405

Epoch: 5| Step: 2
Training loss: 1.5223675222654058
Validation loss: 2.4173033273119318

Epoch: 5| Step: 3
Training loss: 1.3514611531445742
Validation loss: 2.3415019804398822

Epoch: 5| Step: 4
Training loss: 2.1243980901618693
Validation loss: 2.374535646363779

Epoch: 5| Step: 5
Training loss: 1.5133134183679613
Validation loss: 2.3068410026395383

Epoch: 5| Step: 6
Training loss: 1.5169193993457029
Validation loss: 2.3154169081778595

Epoch: 5| Step: 7
Training loss: 1.4162111765564462
Validation loss: 2.365163595747872

Epoch: 5| Step: 8
Training loss: 1.4792838072621421
Validation loss: 2.374192859538848

Epoch: 5| Step: 9
Training loss: 1.3683423641540282
Validation loss: 2.3298174326635337

Epoch: 5| Step: 10
Training loss: 1.7813752782836294
Validation loss: 2.359304893064352

Epoch: 531| Step: 0
Training loss: 2.332215063879618
Validation loss: 2.3541514778863255

Epoch: 5| Step: 1
Training loss: 1.438739905301233
Validation loss: 2.356170078076642

Epoch: 5| Step: 2
Training loss: 1.7118198436306695
Validation loss: 2.3392384735216467

Epoch: 5| Step: 3
Training loss: 1.2521965754241737
Validation loss: 2.311691774843995

Epoch: 5| Step: 4
Training loss: 1.1570116575901734
Validation loss: 2.3854060004648243

Epoch: 5| Step: 5
Training loss: 1.3159228606124287
Validation loss: 2.3024957356416738

Epoch: 5| Step: 6
Training loss: 1.4866208403556491
Validation loss: 2.345899818559591

Epoch: 5| Step: 7
Training loss: 1.6045349078257907
Validation loss: 2.286007368415864

Epoch: 5| Step: 8
Training loss: 1.2780417305605953
Validation loss: 2.314491892979267

Epoch: 5| Step: 9
Training loss: 1.4858152128616937
Validation loss: 2.436809502994142

Epoch: 5| Step: 10
Training loss: 1.756897276930843
Validation loss: 2.246216550861215

Epoch: 532| Step: 0
Training loss: 1.6478835345706053
Validation loss: 2.425604758628114

Epoch: 5| Step: 1
Training loss: 1.4597061598346024
Validation loss: 2.4076715283543852

Epoch: 5| Step: 2
Training loss: 1.6450280098429098
Validation loss: 2.281897548617685

Epoch: 5| Step: 3
Training loss: 1.3751942757428008
Validation loss: 2.358935448776929

Epoch: 5| Step: 4
Training loss: 0.9453980588419729
Validation loss: 2.386796668097122

Epoch: 5| Step: 5
Training loss: 1.2143690156813736
Validation loss: 2.3550507441512467

Epoch: 5| Step: 6
Training loss: 1.2085596672830183
Validation loss: 2.3834643153776267

Epoch: 5| Step: 7
Training loss: 1.3444178939637497
Validation loss: 2.367079774689224

Epoch: 5| Step: 8
Training loss: 1.734298704376555
Validation loss: 2.41063344564568

Epoch: 5| Step: 9
Training loss: 1.7307559909477177
Validation loss: 2.305968477389924

Epoch: 5| Step: 10
Training loss: 2.1308857805135233
Validation loss: 2.3907871608224274

Epoch: 533| Step: 0
Training loss: 2.284194717912284
Validation loss: 2.3306614477141587

Epoch: 5| Step: 1
Training loss: 1.589331767056374
Validation loss: 2.356861418743621

Epoch: 5| Step: 2
Training loss: 1.5856628931890888
Validation loss: 2.3169940846660775

Epoch: 5| Step: 3
Training loss: 1.5262696374728033
Validation loss: 2.3205360019622217

Epoch: 5| Step: 4
Training loss: 0.9716587696986844
Validation loss: 2.2796304786224666

Epoch: 5| Step: 5
Training loss: 1.6399088431820024
Validation loss: 2.305591081451891

Epoch: 5| Step: 6
Training loss: 1.4593116566799642
Validation loss: 2.343354487255016

Epoch: 5| Step: 7
Training loss: 1.4610128128304558
Validation loss: 2.2540743352421044

Epoch: 5| Step: 8
Training loss: 1.0839828353733436
Validation loss: 2.3492298177154365

Epoch: 5| Step: 9
Training loss: 1.182445913775559
Validation loss: 2.3011275099013884

Epoch: 5| Step: 10
Training loss: 1.702623555969697
Validation loss: 2.3329563733645897

Epoch: 534| Step: 0
Training loss: 1.3949423218838661
Validation loss: 2.3226547818303964

Epoch: 5| Step: 1
Training loss: 1.6649530024955055
Validation loss: 2.3431169892439327

Epoch: 5| Step: 2
Training loss: 1.4239873600838129
Validation loss: 2.398595558552138

Epoch: 5| Step: 3
Training loss: 2.1340770954767487
Validation loss: 2.3651514162850127

Epoch: 5| Step: 4
Training loss: 0.8748056332105502
Validation loss: 2.337584237728315

Epoch: 5| Step: 5
Training loss: 0.8256489065724522
Validation loss: 2.362113097269979

Epoch: 5| Step: 6
Training loss: 1.3696756881911274
Validation loss: 2.383205907048252

Epoch: 5| Step: 7
Training loss: 1.5749859703286813
Validation loss: 2.410051091006232

Epoch: 5| Step: 8
Training loss: 1.900752034180333
Validation loss: 2.3747318852654

Epoch: 5| Step: 9
Training loss: 1.697330311199913
Validation loss: 2.373236000015654

Epoch: 5| Step: 10
Training loss: 0.9207279698835642
Validation loss: 2.354826491053504

Epoch: 535| Step: 0
Training loss: 1.8373362306028498
Validation loss: 2.302292478303336

Epoch: 5| Step: 1
Training loss: 1.3773334383781395
Validation loss: 2.4090350094763746

Epoch: 5| Step: 2
Training loss: 2.544870441938776
Validation loss: 2.369838733514458

Epoch: 5| Step: 3
Training loss: 1.2408062434948794
Validation loss: 2.3534382368246938

Epoch: 5| Step: 4
Training loss: 1.0384615544240359
Validation loss: 2.3954191844179085

Epoch: 5| Step: 5
Training loss: 1.8016156892625228
Validation loss: 2.3513204624250186

Epoch: 5| Step: 6
Training loss: 1.8897811015083312
Validation loss: 2.3343273241602196

Epoch: 5| Step: 7
Training loss: 1.1776366944553858
Validation loss: 2.2930497687667284

Epoch: 5| Step: 8
Training loss: 1.358790918907969
Validation loss: 2.2771569467751576

Epoch: 5| Step: 9
Training loss: 1.0436721315861182
Validation loss: 2.420771966542258

Epoch: 5| Step: 10
Training loss: 1.204296977946091
Validation loss: 2.2494554396178232

Epoch: 536| Step: 0
Training loss: 1.415456348334963
Validation loss: 2.3174711638155068

Epoch: 5| Step: 1
Training loss: 1.278750330532475
Validation loss: 2.321929564827407

Epoch: 5| Step: 2
Training loss: 1.5997919483816292
Validation loss: 2.3246293848611264

Epoch: 5| Step: 3
Training loss: 1.1303128254251642
Validation loss: 2.3261353174297437

Epoch: 5| Step: 4
Training loss: 2.048223037026368
Validation loss: 2.407363486410821

Epoch: 5| Step: 5
Training loss: 1.1476998068358393
Validation loss: 2.3866464198324344

Epoch: 5| Step: 6
Training loss: 1.5238172009039108
Validation loss: 2.3805978118483986

Epoch: 5| Step: 7
Training loss: 1.3827924134255725
Validation loss: 2.3784222775570694

Epoch: 5| Step: 8
Training loss: 1.3420832743383657
Validation loss: 2.318306990474303

Epoch: 5| Step: 9
Training loss: 1.5494443574302565
Validation loss: 2.2514326862085388

Epoch: 5| Step: 10
Training loss: 2.02894273445308
Validation loss: 2.2888191864077805

Epoch: 537| Step: 0
Training loss: 1.391889704269896
Validation loss: 2.339033003456061

Epoch: 5| Step: 1
Training loss: 1.5270878804318262
Validation loss: 2.312797810457918

Epoch: 5| Step: 2
Training loss: 1.0717528737952622
Validation loss: 2.35650958309082

Epoch: 5| Step: 3
Training loss: 1.4481583903500541
Validation loss: 2.363223708220156

Epoch: 5| Step: 4
Training loss: 1.100979156788843
Validation loss: 2.3545237883875507

Epoch: 5| Step: 5
Training loss: 2.0702613680301356
Validation loss: 2.3737585296613255

Epoch: 5| Step: 6
Training loss: 1.6891521560630343
Validation loss: 2.429011085329295

Epoch: 5| Step: 7
Training loss: 1.332817404985067
Validation loss: 2.409523455699975

Epoch: 5| Step: 8
Training loss: 1.5217968836481355
Validation loss: 2.3703639469375166

Epoch: 5| Step: 9
Training loss: 1.4428949705881857
Validation loss: 2.391401962078802

Epoch: 5| Step: 10
Training loss: 1.7737153629633633
Validation loss: 2.3570293372898035

Epoch: 538| Step: 0
Training loss: 1.3783285427509964
Validation loss: 2.3073808775065094

Epoch: 5| Step: 1
Training loss: 1.2566198535230575
Validation loss: 2.308329783926646

Epoch: 5| Step: 2
Training loss: 2.136711497181189
Validation loss: 2.461241673586946

Epoch: 5| Step: 3
Training loss: 1.3692669123200112
Validation loss: 2.40636089587732

Epoch: 5| Step: 4
Training loss: 1.468979594364836
Validation loss: 2.330971935500522

Epoch: 5| Step: 5
Training loss: 1.7130259826836378
Validation loss: 2.3666783727552505

Epoch: 5| Step: 6
Training loss: 1.423224008338595
Validation loss: 2.3656191535537503

Epoch: 5| Step: 7
Training loss: 1.1891253541231905
Validation loss: 2.3360003429551095

Epoch: 5| Step: 8
Training loss: 1.5145838986290354
Validation loss: 2.393668641285032

Epoch: 5| Step: 9
Training loss: 1.4676066879404954
Validation loss: 2.3865862397846445

Epoch: 5| Step: 10
Training loss: 1.643946527836629
Validation loss: 2.365453696426501

Epoch: 539| Step: 0
Training loss: 1.1823007804530536
Validation loss: 2.3440093631868866

Epoch: 5| Step: 1
Training loss: 1.4217119228200372
Validation loss: 2.317186406651784

Epoch: 5| Step: 2
Training loss: 1.1851854857608846
Validation loss: 2.3542129171933537

Epoch: 5| Step: 3
Training loss: 1.1746010163811862
Validation loss: 2.3641395978278616

Epoch: 5| Step: 4
Training loss: 1.556477192300802
Validation loss: 2.4001843460700294

Epoch: 5| Step: 5
Training loss: 1.285912798323301
Validation loss: 2.3585391988300537

Epoch: 5| Step: 6
Training loss: 1.9279347231566035
Validation loss: 2.321702237334149

Epoch: 5| Step: 7
Training loss: 2.174317667249943
Validation loss: 2.3812459206077183

Epoch: 5| Step: 8
Training loss: 1.548021142376574
Validation loss: 2.3759854878386757

Epoch: 5| Step: 9
Training loss: 2.039618405387024
Validation loss: 2.3673441677449185

Epoch: 5| Step: 10
Training loss: 1.0071526666548076
Validation loss: 2.3158207231349563

Epoch: 540| Step: 0
Training loss: 1.465462027722539
Validation loss: 2.373959536854204

Epoch: 5| Step: 1
Training loss: 1.2631658516704345
Validation loss: 2.3532632151765593

Epoch: 5| Step: 2
Training loss: 2.268758146413254
Validation loss: 2.297120884272705

Epoch: 5| Step: 3
Training loss: 1.5300938659746457
Validation loss: 2.259329922524444

Epoch: 5| Step: 4
Training loss: 1.3505812594538922
Validation loss: 2.3442146043130943

Epoch: 5| Step: 5
Training loss: 1.3588749634552628
Validation loss: 2.282642078548321

Epoch: 5| Step: 6
Training loss: 1.5783442732053523
Validation loss: 2.329692365006985

Epoch: 5| Step: 7
Training loss: 1.4692799849722695
Validation loss: 2.3137893430343723

Epoch: 5| Step: 8
Training loss: 1.2825764558545056
Validation loss: 2.269545808113946

Epoch: 5| Step: 9
Training loss: 1.6138712471489998
Validation loss: 2.344387773267448

Epoch: 5| Step: 10
Training loss: 1.2700430439991137
Validation loss: 2.3308601123082577

Epoch: 541| Step: 0
Training loss: 1.2631641529476167
Validation loss: 2.30788142835991

Epoch: 5| Step: 1
Training loss: 2.0861036827382953
Validation loss: 2.2674940242273207

Epoch: 5| Step: 2
Training loss: 1.5271568086372513
Validation loss: 2.3104479253503634

Epoch: 5| Step: 3
Training loss: 1.491444427657023
Validation loss: 2.3562647173021976

Epoch: 5| Step: 4
Training loss: 1.6257325501963926
Validation loss: 2.3206634140119586

Epoch: 5| Step: 5
Training loss: 1.4423310742561475
Validation loss: 2.273247390081287

Epoch: 5| Step: 6
Training loss: 1.3289523969438843
Validation loss: 2.3540273197353305

Epoch: 5| Step: 7
Training loss: 0.9223174633562866
Validation loss: 2.429747951443884

Epoch: 5| Step: 8
Training loss: 1.3277216130423604
Validation loss: 2.2883156679434133

Epoch: 5| Step: 9
Training loss: 1.7206406338414817
Validation loss: 2.4332244729293913

Epoch: 5| Step: 10
Training loss: 1.6911090827647903
Validation loss: 2.326333670975326

Epoch: 542| Step: 0
Training loss: 1.3897996660674328
Validation loss: 2.357432828036777

Epoch: 5| Step: 1
Training loss: 1.6529956730983848
Validation loss: 2.3125977832238336

Epoch: 5| Step: 2
Training loss: 2.2531278909143535
Validation loss: 2.3332914892156813

Epoch: 5| Step: 3
Training loss: 1.249216072313446
Validation loss: 2.319960908563966

Epoch: 5| Step: 4
Training loss: 0.6776279948621728
Validation loss: 2.3325555996915037

Epoch: 5| Step: 5
Training loss: 1.24097897262649
Validation loss: 2.344335489189586

Epoch: 5| Step: 6
Training loss: 1.4422485041089037
Validation loss: 2.2681615280235383

Epoch: 5| Step: 7
Training loss: 1.6917734782631983
Validation loss: 2.237871784838162

Epoch: 5| Step: 8
Training loss: 1.9051265219977742
Validation loss: 2.4726612058809305

Epoch: 5| Step: 9
Training loss: 1.4264523115774288
Validation loss: 2.3919617986775976

Epoch: 5| Step: 10
Training loss: 1.3186687643332105
Validation loss: 2.3676028530786137

Epoch: 543| Step: 0
Training loss: 1.104323909767291
Validation loss: 2.4406120158878424

Epoch: 5| Step: 1
Training loss: 0.6983060367441837
Validation loss: 2.3941842171477132

Epoch: 5| Step: 2
Training loss: 1.2570828993234633
Validation loss: 2.3475276219797103

Epoch: 5| Step: 3
Training loss: 1.64144629856731
Validation loss: 2.304425592350746

Epoch: 5| Step: 4
Training loss: 1.3874288540719446
Validation loss: 2.3361336363737513

Epoch: 5| Step: 5
Training loss: 2.2030259779733066
Validation loss: 2.298171310931155

Epoch: 5| Step: 6
Training loss: 1.6264706339256363
Validation loss: 2.34233131048463

Epoch: 5| Step: 7
Training loss: 1.1723897185039764
Validation loss: 2.306553241482256

Epoch: 5| Step: 8
Training loss: 1.5029334154386433
Validation loss: 2.390314258248443

Epoch: 5| Step: 9
Training loss: 1.478366778804272
Validation loss: 2.2797718841850463

Epoch: 5| Step: 10
Training loss: 1.5915653739107805
Validation loss: 2.3460378417347774

Epoch: 544| Step: 0
Training loss: 1.3081743621625743
Validation loss: 2.330108217416856

Epoch: 5| Step: 1
Training loss: 1.2322089106464957
Validation loss: 2.429836502731874

Epoch: 5| Step: 2
Training loss: 1.4356832218944229
Validation loss: 2.3035223555835076

Epoch: 5| Step: 3
Training loss: 1.613457917153154
Validation loss: 2.3686735089710576

Epoch: 5| Step: 4
Training loss: 1.0728260236554996
Validation loss: 2.3659397062375325

Epoch: 5| Step: 5
Training loss: 1.160942042715393
Validation loss: 2.3354666198223675

Epoch: 5| Step: 6
Training loss: 1.4282218215809528
Validation loss: 2.3233014146844413

Epoch: 5| Step: 7
Training loss: 1.7187196208696616
Validation loss: 2.335272410312277

Epoch: 5| Step: 8
Training loss: 1.0734943513654998
Validation loss: 2.3439595862306555

Epoch: 5| Step: 9
Training loss: 2.2332890145568447
Validation loss: 2.302458207297373

Epoch: 5| Step: 10
Training loss: 1.6632564544621302
Validation loss: 2.3207170963663373

Epoch: 545| Step: 0
Training loss: 1.6000919941443152
Validation loss: 2.3236725626362817

Epoch: 5| Step: 1
Training loss: 1.7179182641077984
Validation loss: 2.3878019338145218

Epoch: 5| Step: 2
Training loss: 1.4876120356834732
Validation loss: 2.2540753770419433

Epoch: 5| Step: 3
Training loss: 1.0894011005332322
Validation loss: 2.395078593858369

Epoch: 5| Step: 4
Training loss: 0.860829942357443
Validation loss: 2.3333579192499676

Epoch: 5| Step: 5
Training loss: 1.4009203474231569
Validation loss: 2.377698376307895

Epoch: 5| Step: 6
Training loss: 2.1004803789289785
Validation loss: 2.412623428557167

Epoch: 5| Step: 7
Training loss: 1.1890033942832654
Validation loss: 2.3109467452454906

Epoch: 5| Step: 8
Training loss: 1.7469188950812289
Validation loss: 2.342180759578094

Epoch: 5| Step: 9
Training loss: 1.4701474623124047
Validation loss: 2.343823688401486

Epoch: 5| Step: 10
Training loss: 1.6285793058663787
Validation loss: 2.3874965108261725

Epoch: 546| Step: 0
Training loss: 1.2354518683802165
Validation loss: 2.336412494076575

Epoch: 5| Step: 1
Training loss: 1.1118608481764716
Validation loss: 2.3451154640318563

Epoch: 5| Step: 2
Training loss: 1.3152884426622238
Validation loss: 2.474951607355463

Epoch: 5| Step: 3
Training loss: 1.9016439729161696
Validation loss: 2.3684999584248643

Epoch: 5| Step: 4
Training loss: 2.390529755334352
Validation loss: 2.3692323850726784

Epoch: 5| Step: 5
Training loss: 1.3829128422942367
Validation loss: 2.3354599383901316

Epoch: 5| Step: 6
Training loss: 0.9684116018598498
Validation loss: 2.4109251250147077

Epoch: 5| Step: 7
Training loss: 1.4899900543597815
Validation loss: 2.418297403788577

Epoch: 5| Step: 8
Training loss: 1.5023596799961063
Validation loss: 2.3776884002171608

Epoch: 5| Step: 9
Training loss: 1.4548201159414607
Validation loss: 2.368498718546811

Epoch: 5| Step: 10
Training loss: 0.773094794902221
Validation loss: 2.270008431996705

Epoch: 547| Step: 0
Training loss: 1.2504707403714108
Validation loss: 2.357039907121685

Epoch: 5| Step: 1
Training loss: 1.5824213747858533
Validation loss: 2.352222914471421

Epoch: 5| Step: 2
Training loss: 1.2748215999331785
Validation loss: 2.2875391089309693

Epoch: 5| Step: 3
Training loss: 1.499691375136014
Validation loss: 2.3579941530630846

Epoch: 5| Step: 4
Training loss: 1.0961369762203592
Validation loss: 2.3321210091209377

Epoch: 5| Step: 5
Training loss: 1.5459452445486082
Validation loss: 2.378978045537449

Epoch: 5| Step: 6
Training loss: 1.6406709937051887
Validation loss: 2.322480792701507

Epoch: 5| Step: 7
Training loss: 1.2053871685910376
Validation loss: 2.341842171299534

Epoch: 5| Step: 8
Training loss: 1.4151976860443658
Validation loss: 2.3053017875388027

Epoch: 5| Step: 9
Training loss: 2.5259217119083366
Validation loss: 2.2341022814084304

Epoch: 5| Step: 10
Training loss: 1.0600081563131958
Validation loss: 2.3808948392697507

Epoch: 548| Step: 0
Training loss: 1.0746356501915133
Validation loss: 2.343570088143351

Epoch: 5| Step: 1
Training loss: 2.378577298877596
Validation loss: 2.324631777972627

Epoch: 5| Step: 2
Training loss: 1.0944577788064023
Validation loss: 2.3345041717804844

Epoch: 5| Step: 3
Training loss: 1.395902968800034
Validation loss: 2.3597458556985993

Epoch: 5| Step: 4
Training loss: 1.2865460426402835
Validation loss: 2.34766827944123

Epoch: 5| Step: 5
Training loss: 1.5365622102784866
Validation loss: 2.2540181091819607

Epoch: 5| Step: 6
Training loss: 1.6543248341977632
Validation loss: 2.364750765167628

Epoch: 5| Step: 7
Training loss: 1.6094593655593161
Validation loss: 2.3464099389874824

Epoch: 5| Step: 8
Training loss: 1.1782820457796759
Validation loss: 2.3336204329840706

Epoch: 5| Step: 9
Training loss: 1.1804400942320439
Validation loss: 2.3228043567184415

Epoch: 5| Step: 10
Training loss: 1.4082129447689868
Validation loss: 2.3414701424942

Epoch: 549| Step: 0
Training loss: 2.229463100034738
Validation loss: 2.3582146598826257

Epoch: 5| Step: 1
Training loss: 1.5321048763622063
Validation loss: 2.4216153357929233

Epoch: 5| Step: 2
Training loss: 1.1583336278974492
Validation loss: 2.424690247614944

Epoch: 5| Step: 3
Training loss: 1.3573511338496937
Validation loss: 2.240934643555649

Epoch: 5| Step: 4
Training loss: 1.3560358449733096
Validation loss: 2.373885151586622

Epoch: 5| Step: 5
Training loss: 1.6015001238329527
Validation loss: 2.3994135475097202

Epoch: 5| Step: 6
Training loss: 1.8083536800288749
Validation loss: 2.3378691114627514

Epoch: 5| Step: 7
Training loss: 1.4729875348788004
Validation loss: 2.3678089691845043

Epoch: 5| Step: 8
Training loss: 1.4278312264089192
Validation loss: 2.3919711970386337

Epoch: 5| Step: 9
Training loss: 1.3501385370449461
Validation loss: 2.2960587446942684

Epoch: 5| Step: 10
Training loss: 1.2862830512394556
Validation loss: 2.3364822148228828

Epoch: 550| Step: 0
Training loss: 1.2766205493143852
Validation loss: 2.3348792270297514

Epoch: 5| Step: 1
Training loss: 2.279072388460547
Validation loss: 2.3857307696574104

Epoch: 5| Step: 2
Training loss: 1.630246788603216
Validation loss: 2.3125852919982064

Epoch: 5| Step: 3
Training loss: 1.3790799212570959
Validation loss: 2.2495561461600926

Epoch: 5| Step: 4
Training loss: 1.2541664780440247
Validation loss: 2.42503011530656

Epoch: 5| Step: 5
Training loss: 1.5677968081562863
Validation loss: 2.225125184627254

Epoch: 5| Step: 6
Training loss: 1.132259365394286
Validation loss: 2.364572874017802

Epoch: 5| Step: 7
Training loss: 1.518977910276097
Validation loss: 2.3250308229818284

Epoch: 5| Step: 8
Training loss: 1.2043088067893095
Validation loss: 2.330653592867353

Epoch: 5| Step: 9
Training loss: 1.6809527222964802
Validation loss: 2.2733267531015393

Epoch: 5| Step: 10
Training loss: 1.6335864263486226
Validation loss: 2.277374578629732

Epoch: 551| Step: 0
Training loss: 2.3937730195455047
Validation loss: 2.3539823292412536

Epoch: 5| Step: 1
Training loss: 0.6748589191644109
Validation loss: 2.343840475762993

Epoch: 5| Step: 2
Training loss: 1.1525234276299818
Validation loss: 2.404986973363249

Epoch: 5| Step: 3
Training loss: 1.6115447297595016
Validation loss: 2.2761454845875875

Epoch: 5| Step: 4
Training loss: 1.4366118963353112
Validation loss: 2.350703546883455

Epoch: 5| Step: 5
Training loss: 1.0511162092821371
Validation loss: 2.3071289379186934

Epoch: 5| Step: 6
Training loss: 1.5019085186707646
Validation loss: 2.373262046917691

Epoch: 5| Step: 7
Training loss: 1.1636371219358899
Validation loss: 2.2882595519401963

Epoch: 5| Step: 8
Training loss: 1.3408906366697722
Validation loss: 2.379527513599867

Epoch: 5| Step: 9
Training loss: 1.43657414018165
Validation loss: 2.439142132061731

Epoch: 5| Step: 10
Training loss: 1.7206016276774767
Validation loss: 2.324593350038731

Epoch: 552| Step: 0
Training loss: 1.2490298320973428
Validation loss: 2.4256658616629236

Epoch: 5| Step: 1
Training loss: 1.5982681259256388
Validation loss: 2.311885851962397

Epoch: 5| Step: 2
Training loss: 1.023011388232402
Validation loss: 2.3890556553238826

Epoch: 5| Step: 3
Training loss: 1.6434945578860758
Validation loss: 2.338273705853151

Epoch: 5| Step: 4
Training loss: 1.7244831527192288
Validation loss: 2.2572998368664567

Epoch: 5| Step: 5
Training loss: 2.185862445974345
Validation loss: 2.3899465374702054

Epoch: 5| Step: 6
Training loss: 1.1029321258771965
Validation loss: 2.390660793383131

Epoch: 5| Step: 7
Training loss: 1.1326560076780265
Validation loss: 2.400650002790766

Epoch: 5| Step: 8
Training loss: 1.7890436429691603
Validation loss: 2.36230290229826

Epoch: 5| Step: 9
Training loss: 1.1090914404160013
Validation loss: 2.3514604149427214

Epoch: 5| Step: 10
Training loss: 0.9372976720554945
Validation loss: 2.438310683456742

Epoch: 553| Step: 0
Training loss: 1.0541258835473888
Validation loss: 2.338345812673168

Epoch: 5| Step: 1
Training loss: 1.7185776363990464
Validation loss: 2.3030426512905677

Epoch: 5| Step: 2
Training loss: 2.050468028535769
Validation loss: 2.387859807699205

Epoch: 5| Step: 3
Training loss: 1.0823092327338455
Validation loss: 2.2640018316268975

Epoch: 5| Step: 4
Training loss: 1.3174719868673166
Validation loss: 2.253356859812228

Epoch: 5| Step: 5
Training loss: 1.2139047998936967
Validation loss: 2.3270556955055657

Epoch: 5| Step: 6
Training loss: 1.638783102159484
Validation loss: 2.3254941553329855

Epoch: 5| Step: 7
Training loss: 1.3011820865758343
Validation loss: 2.3586884833372372

Epoch: 5| Step: 8
Training loss: 1.4560996342251615
Validation loss: 2.3520801560262843

Epoch: 5| Step: 9
Training loss: 1.3333591319608251
Validation loss: 2.263657918417726

Epoch: 5| Step: 10
Training loss: 1.609579202974362
Validation loss: 2.298134388260233

Epoch: 554| Step: 0
Training loss: 1.333200741175329
Validation loss: 2.243685133829866

Epoch: 5| Step: 1
Training loss: 1.5991805064106241
Validation loss: 2.287597849565459

Epoch: 5| Step: 2
Training loss: 2.1137989136435276
Validation loss: 2.386292168263953

Epoch: 5| Step: 3
Training loss: 1.2756001182121874
Validation loss: 2.292234892516376

Epoch: 5| Step: 4
Training loss: 0.9835627398704231
Validation loss: 2.3731855684038963

Epoch: 5| Step: 5
Training loss: 1.5692514659126633
Validation loss: 2.324029190800413

Epoch: 5| Step: 6
Training loss: 1.0261802321588525
Validation loss: 2.317362269058769

Epoch: 5| Step: 7
Training loss: 1.217979187397649
Validation loss: 2.248828168046006

Epoch: 5| Step: 8
Training loss: 1.6522948345762725
Validation loss: 2.3463709810843216

Epoch: 5| Step: 9
Training loss: 1.7780252009645119
Validation loss: 2.372450872973076

Epoch: 5| Step: 10
Training loss: 1.5121099079341043
Validation loss: 2.380136551569727

Epoch: 555| Step: 0
Training loss: 1.2570498980175595
Validation loss: 2.296959570819971

Epoch: 5| Step: 1
Training loss: 1.1214248753053744
Validation loss: 2.3096397707370997

Epoch: 5| Step: 2
Training loss: 1.2564535441070417
Validation loss: 2.340865242197154

Epoch: 5| Step: 3
Training loss: 1.4866076894503013
Validation loss: 2.34186668175295

Epoch: 5| Step: 4
Training loss: 2.1005143171556644
Validation loss: 2.355199640757292

Epoch: 5| Step: 5
Training loss: 1.6029640578002258
Validation loss: 2.483185835212454

Epoch: 5| Step: 6
Training loss: 1.1163907177473962
Validation loss: 2.273987007100315

Epoch: 5| Step: 7
Training loss: 1.645558958079406
Validation loss: 2.3562284079377003

Epoch: 5| Step: 8
Training loss: 0.9728414520063019
Validation loss: 2.291392058385501

Epoch: 5| Step: 9
Training loss: 1.379505837599932
Validation loss: 2.34875918829011

Epoch: 5| Step: 10
Training loss: 1.3460831458525884
Validation loss: 2.4188087723546023

Epoch: 556| Step: 0
Training loss: 1.5872447071404772
Validation loss: 2.3400334276832515

Epoch: 5| Step: 1
Training loss: 1.7731448028609627
Validation loss: 2.3876512726188848

Epoch: 5| Step: 2
Training loss: 1.5006865678555321
Validation loss: 2.3887514991184813

Epoch: 5| Step: 3
Training loss: 1.1945866394174627
Validation loss: 2.38636918607316

Epoch: 5| Step: 4
Training loss: 1.1027610156698842
Validation loss: 2.323107528699618

Epoch: 5| Step: 5
Training loss: 0.858196560292406
Validation loss: 2.3789278439564265

Epoch: 5| Step: 6
Training loss: 1.4537806518682033
Validation loss: 2.3449743167254278

Epoch: 5| Step: 7
Training loss: 1.2729516535985537
Validation loss: 2.3036021334569177

Epoch: 5| Step: 8
Training loss: 1.1685408910044974
Validation loss: 2.4087869145994754

Epoch: 5| Step: 9
Training loss: 1.789156115885332
Validation loss: 2.375659107983482

Epoch: 5| Step: 10
Training loss: 2.4483254490416604
Validation loss: 2.352067180181956

Epoch: 557| Step: 0
Training loss: 1.3716213156865236
Validation loss: 2.3651931089932363

Epoch: 5| Step: 1
Training loss: 1.2066693303481009
Validation loss: 2.401498013171541

Epoch: 5| Step: 2
Training loss: 1.0998195088301894
Validation loss: 2.311918205990329

Epoch: 5| Step: 3
Training loss: 1.1995092779375558
Validation loss: 2.3465838117401123

Epoch: 5| Step: 4
Training loss: 1.1822045359945745
Validation loss: 2.2599387830243467

Epoch: 5| Step: 5
Training loss: 1.2990495765452479
Validation loss: 2.397416839618435

Epoch: 5| Step: 6
Training loss: 2.153499673652491
Validation loss: 2.2949920829274286

Epoch: 5| Step: 7
Training loss: 1.7770851030896204
Validation loss: 2.3290216140301028

Epoch: 5| Step: 8
Training loss: 1.4000912057595356
Validation loss: 2.3642527806515417

Epoch: 5| Step: 9
Training loss: 1.9110423648036856
Validation loss: 2.295705717960555

Epoch: 5| Step: 10
Training loss: 1.2507345902116793
Validation loss: 2.3303268117404854

Epoch: 558| Step: 0
Training loss: 1.4971102057887982
Validation loss: 2.34138195222278

Epoch: 5| Step: 1
Training loss: 2.280281174705824
Validation loss: 2.3940182926860323

Epoch: 5| Step: 2
Training loss: 1.1404571932327194
Validation loss: 2.332883853806173

Epoch: 5| Step: 3
Training loss: 1.4394970166412953
Validation loss: 2.2289683537732765

Epoch: 5| Step: 4
Training loss: 1.5791381756201088
Validation loss: 2.3870972466049154

Epoch: 5| Step: 5
Training loss: 1.2159772779261704
Validation loss: 2.3056413509600233

Epoch: 5| Step: 6
Training loss: 1.2246509405014832
Validation loss: 2.4450941001717474

Epoch: 5| Step: 7
Training loss: 1.1119815132539217
Validation loss: 2.327542823732477

Epoch: 5| Step: 8
Training loss: 1.4821142548445623
Validation loss: 2.406917049670678

Epoch: 5| Step: 9
Training loss: 1.7064740910635208
Validation loss: 2.452543346598186

Epoch: 5| Step: 10
Training loss: 1.2616652250008722
Validation loss: 2.3574584117486905

Epoch: 559| Step: 0
Training loss: 1.6732615487911153
Validation loss: 2.319692954978129

Epoch: 5| Step: 1
Training loss: 1.4424903328503873
Validation loss: 2.3383121161761697

Epoch: 5| Step: 2
Training loss: 1.2510245892420275
Validation loss: 2.305460897122555

Epoch: 5| Step: 3
Training loss: 1.6919153870016879
Validation loss: 2.4514383684064684

Epoch: 5| Step: 4
Training loss: 1.1855206305978483
Validation loss: 2.3125680582529435

Epoch: 5| Step: 5
Training loss: 1.419037555340089
Validation loss: 2.2706712851422677

Epoch: 5| Step: 6
Training loss: 1.2218161917580979
Validation loss: 2.311229057235097

Epoch: 5| Step: 7
Training loss: 1.0461159986504587
Validation loss: 2.3189644680328443

Epoch: 5| Step: 8
Training loss: 1.4194574449212998
Validation loss: 2.22503387072358

Epoch: 5| Step: 9
Training loss: 1.2236977915396108
Validation loss: 2.326689575575395

Epoch: 5| Step: 10
Training loss: 2.206055011723914
Validation loss: 2.388106600641124

Epoch: 560| Step: 0
Training loss: 1.2667448481892964
Validation loss: 2.3867960515678908

Epoch: 5| Step: 1
Training loss: 1.1705047734687521
Validation loss: 2.3388206563451854

Epoch: 5| Step: 2
Training loss: 1.4768390699254446
Validation loss: 2.3168957445254352

Epoch: 5| Step: 3
Training loss: 1.519153538220139
Validation loss: 2.35504280301027

Epoch: 5| Step: 4
Training loss: 1.6512957195966897
Validation loss: 2.3123813411353678

Epoch: 5| Step: 5
Training loss: 2.126456939297163
Validation loss: 2.3511830214046774

Epoch: 5| Step: 6
Training loss: 1.1028561402245007
Validation loss: 2.3019427741615526

Epoch: 5| Step: 7
Training loss: 0.9140200482805355
Validation loss: 2.3635831922889285

Epoch: 5| Step: 8
Training loss: 1.350772913680379
Validation loss: 2.338713890202016

Epoch: 5| Step: 9
Training loss: 1.0161034264148494
Validation loss: 2.3415718375880306

Epoch: 5| Step: 10
Training loss: 1.4326329142637553
Validation loss: 2.247858136085353

Epoch: 561| Step: 0
Training loss: 1.4534353109477358
Validation loss: 2.3115340934172415

Epoch: 5| Step: 1
Training loss: 1.2907667973467367
Validation loss: 2.3527951381158596

Epoch: 5| Step: 2
Training loss: 2.311902974359868
Validation loss: 2.3889537709302857

Epoch: 5| Step: 3
Training loss: 1.2416655205501583
Validation loss: 2.339789598161451

Epoch: 5| Step: 4
Training loss: 1.5999570661983336
Validation loss: 2.328490134549555

Epoch: 5| Step: 5
Training loss: 1.0378170723887603
Validation loss: 2.312444646317507

Epoch: 5| Step: 6
Training loss: 1.4609454149653993
Validation loss: 2.2741960379898827

Epoch: 5| Step: 7
Training loss: 1.3429002070841018
Validation loss: 2.3738260665511746

Epoch: 5| Step: 8
Training loss: 1.1709945931932833
Validation loss: 2.2839221596013766

Epoch: 5| Step: 9
Training loss: 1.1659616429087087
Validation loss: 2.293599213476203

Epoch: 5| Step: 10
Training loss: 1.5224132518139437
Validation loss: 2.3545859970063274

Epoch: 562| Step: 0
Training loss: 1.2351002071823651
Validation loss: 2.3077556006926057

Epoch: 5| Step: 1
Training loss: 1.314420929240966
Validation loss: 2.324343806110032

Epoch: 5| Step: 2
Training loss: 2.1896288730617353
Validation loss: 2.4163798465049244

Epoch: 5| Step: 3
Training loss: 0.9802503000505568
Validation loss: 2.339550438116398

Epoch: 5| Step: 4
Training loss: 1.1045340640547157
Validation loss: 2.299496010565916

Epoch: 5| Step: 5
Training loss: 1.3800685835810003
Validation loss: 2.3654691240400263

Epoch: 5| Step: 6
Training loss: 1.1718600462913105
Validation loss: 2.32327917349453

Epoch: 5| Step: 7
Training loss: 1.5962652666023538
Validation loss: 2.4105516085080687

Epoch: 5| Step: 8
Training loss: 1.1088610250972555
Validation loss: 2.3448558580265892

Epoch: 5| Step: 9
Training loss: 1.7135792025674448
Validation loss: 2.3898321181774866

Epoch: 5| Step: 10
Training loss: 1.5741252256114735
Validation loss: 2.335959276062241

Epoch: 563| Step: 0
Training loss: 1.3532671459499397
Validation loss: 2.4148463496453245

Epoch: 5| Step: 1
Training loss: 1.395973378837583
Validation loss: 2.306620210671845

Epoch: 5| Step: 2
Training loss: 1.327743026557068
Validation loss: 2.3567033938327557

Epoch: 5| Step: 3
Training loss: 2.3429701461355354
Validation loss: 2.406917697259799

Epoch: 5| Step: 4
Training loss: 1.3808042091670147
Validation loss: 2.3418596789488224

Epoch: 5| Step: 5
Training loss: 1.3057961693112612
Validation loss: 2.2971301790547005

Epoch: 5| Step: 6
Training loss: 0.9836663617032685
Validation loss: 2.2918037929135573

Epoch: 5| Step: 7
Training loss: 1.42645314728188
Validation loss: 2.3632498529989876

Epoch: 5| Step: 8
Training loss: 1.2607233709442542
Validation loss: 2.4425162384515806

Epoch: 5| Step: 9
Training loss: 1.3617876062804877
Validation loss: 2.3544946776518314

Epoch: 5| Step: 10
Training loss: 2.003532270666193
Validation loss: 2.361643645206579

Epoch: 564| Step: 0
Training loss: 2.372499253621602
Validation loss: 2.307748923180416

Epoch: 5| Step: 1
Training loss: 1.1484201650543846
Validation loss: 2.388174255089701

Epoch: 5| Step: 2
Training loss: 1.1898662682729944
Validation loss: 2.3812105627683153

Epoch: 5| Step: 3
Training loss: 1.5203702909770997
Validation loss: 2.312431682540904

Epoch: 5| Step: 4
Training loss: 1.2365092405505338
Validation loss: 2.3118929477760752

Epoch: 5| Step: 5
Training loss: 1.3355222357780834
Validation loss: 2.313064052986921

Epoch: 5| Step: 6
Training loss: 1.5297039557128083
Validation loss: 2.2934068663507623

Epoch: 5| Step: 7
Training loss: 1.899760597606065
Validation loss: 2.306404492276749

Epoch: 5| Step: 8
Training loss: 1.1366665228417567
Validation loss: 2.363587967961031

Epoch: 5| Step: 9
Training loss: 1.1476901990051391
Validation loss: 2.3086776069927355

Epoch: 5| Step: 10
Training loss: 1.225099067185442
Validation loss: 2.2841169205427723

Epoch: 565| Step: 0
Training loss: 1.1471821677661527
Validation loss: 2.3470191737486803

Epoch: 5| Step: 1
Training loss: 1.34349896059894
Validation loss: 2.2956211556694415

Epoch: 5| Step: 2
Training loss: 1.4437797873590683
Validation loss: 2.322261250083841

Epoch: 5| Step: 3
Training loss: 1.1434420978946827
Validation loss: 2.3101717317810304

Epoch: 5| Step: 4
Training loss: 1.3733002386843067
Validation loss: 2.2686907288260585

Epoch: 5| Step: 5
Training loss: 2.2102772296306474
Validation loss: 2.3097135489910787

Epoch: 5| Step: 6
Training loss: 1.0610486383893785
Validation loss: 2.40149756908431

Epoch: 5| Step: 7
Training loss: 1.5137069205872435
Validation loss: 2.3069375127292306

Epoch: 5| Step: 8
Training loss: 1.6862934178785196
Validation loss: 2.3916621346173677

Epoch: 5| Step: 9
Training loss: 1.10861620675287
Validation loss: 2.255861743332148

Epoch: 5| Step: 10
Training loss: 1.1988399541077972
Validation loss: 2.340869219843842

Epoch: 566| Step: 0
Training loss: 1.232645489073561
Validation loss: 2.2983761128341422

Epoch: 5| Step: 1
Training loss: 1.758859280334154
Validation loss: 2.3412902777251143

Epoch: 5| Step: 2
Training loss: 1.426674842380259
Validation loss: 2.285658028308742

Epoch: 5| Step: 3
Training loss: 1.1884812767919544
Validation loss: 2.322840631197867

Epoch: 5| Step: 4
Training loss: 1.474304895355433
Validation loss: 2.267109221738093

Epoch: 5| Step: 5
Training loss: 0.9758514562292697
Validation loss: 2.3081250766224897

Epoch: 5| Step: 6
Training loss: 1.0261504927238236
Validation loss: 2.2282528775885155

Epoch: 5| Step: 7
Training loss: 1.4565168602828908
Validation loss: 2.2795636434937627

Epoch: 5| Step: 8
Training loss: 1.283899034357053
Validation loss: 2.3787330698977596

Epoch: 5| Step: 9
Training loss: 1.2181335748768978
Validation loss: 2.370118855405912

Epoch: 5| Step: 10
Training loss: 2.122412845722813
Validation loss: 2.3354266173875504

Epoch: 567| Step: 0
Training loss: 0.974375878383199
Validation loss: 2.350627386868761

Epoch: 5| Step: 1
Training loss: 1.340166281090744
Validation loss: 2.272720590928399

Epoch: 5| Step: 2
Training loss: 1.2560703225008718
Validation loss: 2.2813738919794724

Epoch: 5| Step: 3
Training loss: 1.4306671455011577
Validation loss: 2.3252518080533173

Epoch: 5| Step: 4
Training loss: 1.5343162820617064
Validation loss: 2.313155744502975

Epoch: 5| Step: 5
Training loss: 1.2814953266762585
Validation loss: 2.298300465892505

Epoch: 5| Step: 6
Training loss: 1.452709671881339
Validation loss: 2.3466034657161017

Epoch: 5| Step: 7
Training loss: 2.1561303589288903
Validation loss: 2.298564027295502

Epoch: 5| Step: 8
Training loss: 1.368179615267262
Validation loss: 2.4181441103774914

Epoch: 5| Step: 9
Training loss: 1.4605087222237498
Validation loss: 2.3370144157024204

Epoch: 5| Step: 10
Training loss: 1.45085401378239
Validation loss: 2.377963384284387

Epoch: 568| Step: 0
Training loss: 1.4040029162379353
Validation loss: 2.258678747704094

Epoch: 5| Step: 1
Training loss: 1.2086726512441657
Validation loss: 2.3416919414651147

Epoch: 5| Step: 2
Training loss: 1.0862551437273702
Validation loss: 2.306050525781178

Epoch: 5| Step: 3
Training loss: 1.2100991577314475
Validation loss: 2.4189813205922417

Epoch: 5| Step: 4
Training loss: 1.1042276161694007
Validation loss: 2.330737954363352

Epoch: 5| Step: 5
Training loss: 2.012209223241799
Validation loss: 2.2523947633661714

Epoch: 5| Step: 6
Training loss: 1.5526983676790036
Validation loss: 2.292612297598165

Epoch: 5| Step: 7
Training loss: 1.3337063366965591
Validation loss: 2.3621774920267247

Epoch: 5| Step: 8
Training loss: 1.4726660447338813
Validation loss: 2.33858289192858

Epoch: 5| Step: 9
Training loss: 1.1515339220245764
Validation loss: 2.3492622532668683

Epoch: 5| Step: 10
Training loss: 1.5441089135678996
Validation loss: 2.3352384883292836

Epoch: 569| Step: 0
Training loss: 1.1941994365251904
Validation loss: 2.3547329752836146

Epoch: 5| Step: 1
Training loss: 2.222554236352088
Validation loss: 2.3065753260778536

Epoch: 5| Step: 2
Training loss: 1.142798560633569
Validation loss: 2.293094766900187

Epoch: 5| Step: 3
Training loss: 1.142936454728665
Validation loss: 2.4160008692611816

Epoch: 5| Step: 4
Training loss: 1.295741309591477
Validation loss: 2.3125794520942824

Epoch: 5| Step: 5
Training loss: 1.3474526956496653
Validation loss: 2.3209982017257085

Epoch: 5| Step: 6
Training loss: 1.1561071977839876
Validation loss: 2.335798380609855

Epoch: 5| Step: 7
Training loss: 1.1572701361456306
Validation loss: 2.3511030687060046

Epoch: 5| Step: 8
Training loss: 1.1720277813818283
Validation loss: 2.367785320063756

Epoch: 5| Step: 9
Training loss: 1.5046548144631897
Validation loss: 2.38074403925085

Epoch: 5| Step: 10
Training loss: 1.6915026630647891
Validation loss: 2.3049649324143715

Epoch: 570| Step: 0
Training loss: 1.2359880458753694
Validation loss: 2.324262538051745

Epoch: 5| Step: 1
Training loss: 1.1575428719542042
Validation loss: 2.4159890187651003

Epoch: 5| Step: 2
Training loss: 1.1143944244489012
Validation loss: 2.276549966635055

Epoch: 5| Step: 3
Training loss: 2.124545553644185
Validation loss: 2.3007424888895387

Epoch: 5| Step: 4
Training loss: 1.3800701815962046
Validation loss: 2.3501954235891316

Epoch: 5| Step: 5
Training loss: 1.7088406747620422
Validation loss: 2.3142499175524027

Epoch: 5| Step: 6
Training loss: 1.6540950935823735
Validation loss: 2.330485881006396

Epoch: 5| Step: 7
Training loss: 0.9204734234099541
Validation loss: 2.2969060921812554

Epoch: 5| Step: 8
Training loss: 1.683663280493977
Validation loss: 2.2977243973155232

Epoch: 5| Step: 9
Training loss: 1.197178101568689
Validation loss: 2.393365274294106

Epoch: 5| Step: 10
Training loss: 1.3581449709607571
Validation loss: 2.2440057172393337

Epoch: 571| Step: 0
Training loss: 1.2698114174028368
Validation loss: 2.3516514356962723

Epoch: 5| Step: 1
Training loss: 0.823769541900799
Validation loss: 2.367077021601493

Epoch: 5| Step: 2
Training loss: 1.6273770186548497
Validation loss: 2.3071316347563444

Epoch: 5| Step: 3
Training loss: 1.436597208894559
Validation loss: 2.293874399458156

Epoch: 5| Step: 4
Training loss: 1.1589808819817498
Validation loss: 2.265562942215081

Epoch: 5| Step: 5
Training loss: 1.0641505940138887
Validation loss: 2.3887372392865953

Epoch: 5| Step: 6
Training loss: 1.2117521929476103
Validation loss: 2.395543096296128

Epoch: 5| Step: 7
Training loss: 1.2414553902024559
Validation loss: 2.26040848870913

Epoch: 5| Step: 8
Training loss: 1.6545381156194612
Validation loss: 2.272141717155182

Epoch: 5| Step: 9
Training loss: 1.7152856070699745
Validation loss: 2.4009930841952514

Epoch: 5| Step: 10
Training loss: 2.0773831527662914
Validation loss: 2.3604522225676137

Epoch: 572| Step: 0
Training loss: 1.4012206529305646
Validation loss: 2.320932835097913

Epoch: 5| Step: 1
Training loss: 1.4222611123138893
Validation loss: 2.312756522777484

Epoch: 5| Step: 2
Training loss: 1.4438275931508915
Validation loss: 2.393214816038446

Epoch: 5| Step: 3
Training loss: 1.1860960139510663
Validation loss: 2.270938398586126

Epoch: 5| Step: 4
Training loss: 1.0229842368894329
Validation loss: 2.325594572780895

Epoch: 5| Step: 5
Training loss: 1.2477281906799185
Validation loss: 2.3212683355077406

Epoch: 5| Step: 6
Training loss: 2.4159596713470695
Validation loss: 2.3964682259902954

Epoch: 5| Step: 7
Training loss: 1.502106617796902
Validation loss: 2.290015988612259

Epoch: 5| Step: 8
Training loss: 1.1703773592609688
Validation loss: 2.337820344226423

Epoch: 5| Step: 9
Training loss: 0.8899285119523945
Validation loss: 2.394915847446523

Epoch: 5| Step: 10
Training loss: 1.3968774202398373
Validation loss: 2.384895639297922

Epoch: 573| Step: 0
Training loss: 1.2255017498631087
Validation loss: 2.2831432590439613

Epoch: 5| Step: 1
Training loss: 0.7568660213274951
Validation loss: 2.310474898118613

Epoch: 5| Step: 2
Training loss: 1.9262762768219974
Validation loss: 2.2769224785130446

Epoch: 5| Step: 3
Training loss: 2.0151159545627273
Validation loss: 2.2775209284398588

Epoch: 5| Step: 4
Training loss: 1.1361943244512993
Validation loss: 2.3528259042809765

Epoch: 5| Step: 5
Training loss: 1.1820571543596319
Validation loss: 2.4159231491934205

Epoch: 5| Step: 6
Training loss: 1.372939299578739
Validation loss: 2.3713887603110293

Epoch: 5| Step: 7
Training loss: 1.4150639144157813
Validation loss: 2.3712781243936507

Epoch: 5| Step: 8
Training loss: 1.4143235613697904
Validation loss: 2.3577760970847907

Epoch: 5| Step: 9
Training loss: 1.6959216873559242
Validation loss: 2.303024184551878

Epoch: 5| Step: 10
Training loss: 1.1625139317651882
Validation loss: 2.367786375170915

Epoch: 574| Step: 0
Training loss: 1.382776550860176
Validation loss: 2.39215199228152

Epoch: 5| Step: 1
Training loss: 1.0821340353721733
Validation loss: 2.4129722419927995

Epoch: 5| Step: 2
Training loss: 1.1717143648042379
Validation loss: 2.3757045005361874

Epoch: 5| Step: 3
Training loss: 0.8890881244741166
Validation loss: 2.386266187849734

Epoch: 5| Step: 4
Training loss: 1.4594792722907501
Validation loss: 2.358670859854242

Epoch: 5| Step: 5
Training loss: 0.7539871251502064
Validation loss: 2.374106519212174

Epoch: 5| Step: 6
Training loss: 1.4478385501710644
Validation loss: 2.345005822854356

Epoch: 5| Step: 7
Training loss: 1.3177191642145227
Validation loss: 2.362733517901542

Epoch: 5| Step: 8
Training loss: 1.461232364701495
Validation loss: 2.4107758270185005

Epoch: 5| Step: 9
Training loss: 2.3120010456294033
Validation loss: 2.329334119311915

Epoch: 5| Step: 10
Training loss: 1.601307992949608
Validation loss: 2.3417559124966054

Epoch: 575| Step: 0
Training loss: 2.326802742302603
Validation loss: 2.3812484498003195

Epoch: 5| Step: 1
Training loss: 1.3080627274943883
Validation loss: 2.335401567320629

Epoch: 5| Step: 2
Training loss: 1.4938656622507283
Validation loss: 2.3547863490882426

Epoch: 5| Step: 3
Training loss: 1.1140451052726865
Validation loss: 2.342938509777622

Epoch: 5| Step: 4
Training loss: 1.0618731388571934
Validation loss: 2.3147128004704363

Epoch: 5| Step: 5
Training loss: 1.4182996967927777
Validation loss: 2.3472412598718457

Epoch: 5| Step: 6
Training loss: 1.3419354629575762
Validation loss: 2.3063261735676703

Epoch: 5| Step: 7
Training loss: 1.1070502194089737
Validation loss: 2.440556351983499

Epoch: 5| Step: 8
Training loss: 1.0601370284742209
Validation loss: 2.3877722463991295

Epoch: 5| Step: 9
Training loss: 1.437528361165112
Validation loss: 2.3637980239935383

Epoch: 5| Step: 10
Training loss: 1.1895217750419496
Validation loss: 2.259965427018351

Epoch: 576| Step: 0
Training loss: 0.9760419144658955
Validation loss: 2.4357050662342203

Epoch: 5| Step: 1
Training loss: 1.1785348477817332
Validation loss: 2.3544142510584245

Epoch: 5| Step: 2
Training loss: 1.2014974509540368
Validation loss: 2.331885983430651

Epoch: 5| Step: 3
Training loss: 1.654892563113019
Validation loss: 2.3871554428388997

Epoch: 5| Step: 4
Training loss: 0.9523968651270952
Validation loss: 2.317893853020922

Epoch: 5| Step: 5
Training loss: 1.378373688903113
Validation loss: 2.326075852704077

Epoch: 5| Step: 6
Training loss: 1.3661308783196078
Validation loss: 2.236577459646125

Epoch: 5| Step: 7
Training loss: 1.1831301546060082
Validation loss: 2.3882775413569215

Epoch: 5| Step: 8
Training loss: 2.318568026658779
Validation loss: 2.364685541466263

Epoch: 5| Step: 9
Training loss: 1.6902158569985999
Validation loss: 2.357462854016718

Epoch: 5| Step: 10
Training loss: 1.1864988222433837
Validation loss: 2.3877805897478734

Epoch: 577| Step: 0
Training loss: 1.2317444984680166
Validation loss: 2.353673665700773

Epoch: 5| Step: 1
Training loss: 2.3502128504679916
Validation loss: 2.3474249715709012

Epoch: 5| Step: 2
Training loss: 1.3195837594262365
Validation loss: 2.424880563500856

Epoch: 5| Step: 3
Training loss: 1.481989982324017
Validation loss: 2.3190965949387192

Epoch: 5| Step: 4
Training loss: 1.1140565548346255
Validation loss: 2.426566605054406

Epoch: 5| Step: 5
Training loss: 1.4480510438911023
Validation loss: 2.361479562373511

Epoch: 5| Step: 6
Training loss: 1.0902574635831683
Validation loss: 2.4002705018676664

Epoch: 5| Step: 7
Training loss: 1.3039449988859304
Validation loss: 2.2888482834345383

Epoch: 5| Step: 8
Training loss: 1.0458335250813788
Validation loss: 2.349586359386852

Epoch: 5| Step: 9
Training loss: 1.3198717273173386
Validation loss: 2.3067913038332164

Epoch: 5| Step: 10
Training loss: 1.2909002440078603
Validation loss: 2.31802874723049

Epoch: 578| Step: 0
Training loss: 1.3751807960943594
Validation loss: 2.3706888600302864

Epoch: 5| Step: 1
Training loss: 1.2913406124615527
Validation loss: 2.4095616026802555

Epoch: 5| Step: 2
Training loss: 1.3697968351124001
Validation loss: 2.26072135162125

Epoch: 5| Step: 3
Training loss: 1.1578701627840928
Validation loss: 2.3076495536059975

Epoch: 5| Step: 4
Training loss: 1.494727005927961
Validation loss: 2.3772848814529084

Epoch: 5| Step: 5
Training loss: 2.228819763666392
Validation loss: 2.427089936382408

Epoch: 5| Step: 6
Training loss: 1.5240700997778498
Validation loss: 2.352963924305538

Epoch: 5| Step: 7
Training loss: 1.5726852330940122
Validation loss: 2.4288618467221896

Epoch: 5| Step: 8
Training loss: 1.5857684416464626
Validation loss: 2.3835793060039228

Epoch: 5| Step: 9
Training loss: 1.3643340933901933
Validation loss: 2.2957159525972792

Epoch: 5| Step: 10
Training loss: 0.9353564871026917
Validation loss: 2.3303179337499675

Epoch: 579| Step: 0
Training loss: 0.9646968034666985
Validation loss: 2.352255419371947

Epoch: 5| Step: 1
Training loss: 1.8907327542454764
Validation loss: 2.328917887056273

Epoch: 5| Step: 2
Training loss: 1.143450698880616
Validation loss: 2.345893874717074

Epoch: 5| Step: 3
Training loss: 1.1909300806259355
Validation loss: 2.4089463341975157

Epoch: 5| Step: 4
Training loss: 1.514090636378707
Validation loss: 2.3501700771543503

Epoch: 5| Step: 5
Training loss: 2.13928414555571
Validation loss: 2.2987634843472966

Epoch: 5| Step: 6
Training loss: 1.2774464977131736
Validation loss: 2.419580884238401

Epoch: 5| Step: 7
Training loss: 1.2741537595602046
Validation loss: 2.407243058935357

Epoch: 5| Step: 8
Training loss: 1.3428136979049585
Validation loss: 2.3388507990503022

Epoch: 5| Step: 9
Training loss: 1.4550180717211159
Validation loss: 2.2475400811919792

Epoch: 5| Step: 10
Training loss: 1.3870555200115395
Validation loss: 2.296129412751055

Epoch: 580| Step: 0
Training loss: 0.7986564918192607
Validation loss: 2.3573047916654044

Epoch: 5| Step: 1
Training loss: 1.1623273372606708
Validation loss: 2.3337674694759807

Epoch: 5| Step: 2
Training loss: 1.4879827725736041
Validation loss: 2.354777064691614

Epoch: 5| Step: 3
Training loss: 1.5859959784188582
Validation loss: 2.2454109929743375

Epoch: 5| Step: 4
Training loss: 1.548081130082656
Validation loss: 2.359917541159712

Epoch: 5| Step: 5
Training loss: 2.2311341584211237
Validation loss: 2.3145511314126734

Epoch: 5| Step: 6
Training loss: 1.6792739004092885
Validation loss: 2.3711833413560206

Epoch: 5| Step: 7
Training loss: 1.3093816861730765
Validation loss: 2.257278386587699

Epoch: 5| Step: 8
Training loss: 1.3523643187970134
Validation loss: 2.297111197169258

Epoch: 5| Step: 9
Training loss: 0.9417291617684254
Validation loss: 2.323902921933061

Epoch: 5| Step: 10
Training loss: 1.825417951513606
Validation loss: 2.3623750130655203

Epoch: 581| Step: 0
Training loss: 1.4533949570467153
Validation loss: 2.4140950074744856

Epoch: 5| Step: 1
Training loss: 1.371361991530639
Validation loss: 2.31177720312032

Epoch: 5| Step: 2
Training loss: 0.8647514700655147
Validation loss: 2.3374203612061466

Epoch: 5| Step: 3
Training loss: 2.337326810408066
Validation loss: 2.2398806451643436

Epoch: 5| Step: 4
Training loss: 0.8789747423399087
Validation loss: 2.3611998579569113

Epoch: 5| Step: 5
Training loss: 1.4576664989502452
Validation loss: 2.3607706257149146

Epoch: 5| Step: 6
Training loss: 1.0340325932632222
Validation loss: 2.3731470624762427

Epoch: 5| Step: 7
Training loss: 1.3824031245417074
Validation loss: 2.267951503493933

Epoch: 5| Step: 8
Training loss: 1.7279386257778244
Validation loss: 2.2605065893580036

Epoch: 5| Step: 9
Training loss: 1.456845105427858
Validation loss: 2.3266178005829015

Epoch: 5| Step: 10
Training loss: 1.1772109556076538
Validation loss: 2.239804279926136

Epoch: 582| Step: 0
Training loss: 1.0455020042812524
Validation loss: 2.3110333408732253

Epoch: 5| Step: 1
Training loss: 1.171356289823357
Validation loss: 2.285339672887739

Epoch: 5| Step: 2
Training loss: 1.4766677738182676
Validation loss: 2.303399876934103

Epoch: 5| Step: 3
Training loss: 1.1391911312360794
Validation loss: 2.3674202615758517

Epoch: 5| Step: 4
Training loss: 1.4456446910264191
Validation loss: 2.4136850006344237

Epoch: 5| Step: 5
Training loss: 1.1367719185576177
Validation loss: 2.349740934132158

Epoch: 5| Step: 6
Training loss: 1.3102260600572193
Validation loss: 2.352666864063657

Epoch: 5| Step: 7
Training loss: 1.610028624902101
Validation loss: 2.3576977537932065

Epoch: 5| Step: 8
Training loss: 1.0879709429857822
Validation loss: 2.2706719399756485

Epoch: 5| Step: 9
Training loss: 1.3843725854581352
Validation loss: 2.2881369893335424

Epoch: 5| Step: 10
Training loss: 2.2864232390077643
Validation loss: 2.432637845197654

Epoch: 583| Step: 0
Training loss: 1.2918470420820372
Validation loss: 2.302882755670285

Epoch: 5| Step: 1
Training loss: 1.2136662409724999
Validation loss: 2.3262068229754207

Epoch: 5| Step: 2
Training loss: 1.032463169318473
Validation loss: 2.258802486227794

Epoch: 5| Step: 3
Training loss: 1.2800412873225482
Validation loss: 2.3523319386323887

Epoch: 5| Step: 4
Training loss: 1.3424073986175806
Validation loss: 2.3499610584561

Epoch: 5| Step: 5
Training loss: 1.2210733325347127
Validation loss: 2.256825944573077

Epoch: 5| Step: 6
Training loss: 1.53616711286602
Validation loss: 2.3616959716294996

Epoch: 5| Step: 7
Training loss: 1.2865310782226946
Validation loss: 2.276657354244858

Epoch: 5| Step: 8
Training loss: 2.0514332343442043
Validation loss: 2.3247555238446385

Epoch: 5| Step: 9
Training loss: 1.354013943007337
Validation loss: 2.2949027078422013

Epoch: 5| Step: 10
Training loss: 1.4042485299098473
Validation loss: 2.2912512603166064

Epoch: 584| Step: 0
Training loss: 1.3661822301699376
Validation loss: 2.282409645179736

Epoch: 5| Step: 1
Training loss: 0.9930852297963548
Validation loss: 2.3134614386460024

Epoch: 5| Step: 2
Training loss: 1.442629328835675
Validation loss: 2.346846137786855

Epoch: 5| Step: 3
Training loss: 1.1841040792083901
Validation loss: 2.239385527345909

Epoch: 5| Step: 4
Training loss: 1.3939911466944035
Validation loss: 2.3061335339526354

Epoch: 5| Step: 5
Training loss: 1.2729080597398699
Validation loss: 2.394845935790929

Epoch: 5| Step: 6
Training loss: 0.9415235011104665
Validation loss: 2.247097860052476

Epoch: 5| Step: 7
Training loss: 1.106859713706767
Validation loss: 2.267358258215686

Epoch: 5| Step: 8
Training loss: 1.3675574101979697
Validation loss: 2.356701301977182

Epoch: 5| Step: 9
Training loss: 1.2061739349100562
Validation loss: 2.247055139867561

Epoch: 5| Step: 10
Training loss: 2.1130285200079975
Validation loss: 2.3273616281714604

Epoch: 585| Step: 0
Training loss: 1.0990770586192222
Validation loss: 2.3507883339297377

Epoch: 5| Step: 1
Training loss: 1.2823206452298181
Validation loss: 2.3306066865282657

Epoch: 5| Step: 2
Training loss: 1.2292568475432852
Validation loss: 2.3673949641963214

Epoch: 5| Step: 3
Training loss: 1.1171076285881287
Validation loss: 2.2930247717202814

Epoch: 5| Step: 4
Training loss: 2.2384777681849886
Validation loss: 2.350649744467158

Epoch: 5| Step: 5
Training loss: 1.057628008081766
Validation loss: 2.347411393357927

Epoch: 5| Step: 6
Training loss: 1.1669304356537147
Validation loss: 2.309941985294038

Epoch: 5| Step: 7
Training loss: 1.0918142354878153
Validation loss: 2.338698580966264

Epoch: 5| Step: 8
Training loss: 1.631422190146699
Validation loss: 2.3786240535648706

Epoch: 5| Step: 9
Training loss: 1.6990399847596322
Validation loss: 2.341009354199815

Epoch: 5| Step: 10
Training loss: 1.054258414687438
Validation loss: 2.35508407705694

Epoch: 586| Step: 0
Training loss: 1.0642348879457422
Validation loss: 2.405792566807211

Epoch: 5| Step: 1
Training loss: 0.7914713359252362
Validation loss: 2.3196608121720463

Epoch: 5| Step: 2
Training loss: 0.9876933101779344
Validation loss: 2.3022954903634667

Epoch: 5| Step: 3
Training loss: 1.1385026809332455
Validation loss: 2.342372643251676

Epoch: 5| Step: 4
Training loss: 1.9411860442817954
Validation loss: 2.367643547605509

Epoch: 5| Step: 5
Training loss: 0.8601006651890976
Validation loss: 2.2614599158399216

Epoch: 5| Step: 6
Training loss: 1.0987665934172246
Validation loss: 2.437963647238743

Epoch: 5| Step: 7
Training loss: 1.3343629983902745
Validation loss: 2.3800763981101722

Epoch: 5| Step: 8
Training loss: 1.6368497736888887
Validation loss: 2.333054940877404

Epoch: 5| Step: 9
Training loss: 1.112189899044338
Validation loss: 2.2941522863171055

Epoch: 5| Step: 10
Training loss: 2.490142653028955
Validation loss: 2.296254490873704

Epoch: 587| Step: 0
Training loss: 1.0574227363010784
Validation loss: 2.3488920414486496

Epoch: 5| Step: 1
Training loss: 1.1868864281271396
Validation loss: 2.269488679858215

Epoch: 5| Step: 2
Training loss: 1.1599518053138846
Validation loss: 2.334439633588213

Epoch: 5| Step: 3
Training loss: 2.2887670957800808
Validation loss: 2.2752122722075097

Epoch: 5| Step: 4
Training loss: 1.3927182505598557
Validation loss: 2.3177662964656975

Epoch: 5| Step: 5
Training loss: 1.4044328180761074
Validation loss: 2.3578948786903373

Epoch: 5| Step: 6
Training loss: 1.1543614196804675
Validation loss: 2.4288031037428435

Epoch: 5| Step: 7
Training loss: 1.7994120723804867
Validation loss: 2.3772772604573973

Epoch: 5| Step: 8
Training loss: 1.625119278271481
Validation loss: 2.3854246811535766

Epoch: 5| Step: 9
Training loss: 1.2498438737642437
Validation loss: 2.35599201455046

Epoch: 5| Step: 10
Training loss: 1.1649486062170096
Validation loss: 2.2217305978672965

Epoch: 588| Step: 0
Training loss: 1.4764257297044276
Validation loss: 2.3961263915207147

Epoch: 5| Step: 1
Training loss: 1.235088962794768
Validation loss: 2.3557710330666666

Epoch: 5| Step: 2
Training loss: 1.2644959582456143
Validation loss: 2.3048180350073726

Epoch: 5| Step: 3
Training loss: 1.2210787019882379
Validation loss: 2.210626486158546

Epoch: 5| Step: 4
Training loss: 1.1796943209621462
Validation loss: 2.280953063047214

Epoch: 5| Step: 5
Training loss: 1.2647667317683384
Validation loss: 2.3290287500981743

Epoch: 5| Step: 6
Training loss: 1.2816991251459535
Validation loss: 2.3258958082055727

Epoch: 5| Step: 7
Training loss: 2.091660553010109
Validation loss: 2.3079958905142766

Epoch: 5| Step: 8
Training loss: 1.2564589046796815
Validation loss: 2.420912403057026

Epoch: 5| Step: 9
Training loss: 0.960660661967393
Validation loss: 2.224421878475121

Epoch: 5| Step: 10
Training loss: 1.4245652957892674
Validation loss: 2.4742808404539955

Epoch: 589| Step: 0
Training loss: 1.4400991079875078
Validation loss: 2.2805708704364047

Epoch: 5| Step: 1
Training loss: 1.4131663312102145
Validation loss: 2.2898255239529166

Epoch: 5| Step: 2
Training loss: 2.2395513369618145
Validation loss: 2.3256378267500004

Epoch: 5| Step: 3
Training loss: 0.9956703333283239
Validation loss: 2.270505555983494

Epoch: 5| Step: 4
Training loss: 1.0776884328431833
Validation loss: 2.3256618906798576

Epoch: 5| Step: 5
Training loss: 1.4014203530039082
Validation loss: 2.311407531263708

Epoch: 5| Step: 6
Training loss: 1.1523696637876786
Validation loss: 2.3255138213608384

Epoch: 5| Step: 7
Training loss: 1.067844915570619
Validation loss: 2.3374539060436565

Epoch: 5| Step: 8
Training loss: 1.3953368267061768
Validation loss: 2.2583789837929062

Epoch: 5| Step: 9
Training loss: 1.4438417942210642
Validation loss: 2.377275417481983

Epoch: 5| Step: 10
Training loss: 1.08492149192049
Validation loss: 2.2897947084523858

Epoch: 590| Step: 0
Training loss: 1.2834280621051808
Validation loss: 2.2500476675441954

Epoch: 5| Step: 1
Training loss: 1.0023352059931547
Validation loss: 2.282013424176811

Epoch: 5| Step: 2
Training loss: 1.1160873117679095
Validation loss: 2.379779372492287

Epoch: 5| Step: 3
Training loss: 1.5431777233141464
Validation loss: 2.285417277759991

Epoch: 5| Step: 4
Training loss: 1.435183109204467
Validation loss: 2.362912363408974

Epoch: 5| Step: 5
Training loss: 1.0866388484889025
Validation loss: 2.3589841946419523

Epoch: 5| Step: 6
Training loss: 0.9715280385744552
Validation loss: 2.272503630205197

Epoch: 5| Step: 7
Training loss: 1.3032375662141187
Validation loss: 2.2786881922756144

Epoch: 5| Step: 8
Training loss: 1.4346258205947597
Validation loss: 2.266175114114907

Epoch: 5| Step: 9
Training loss: 1.7157882140299405
Validation loss: 2.251674570729635

Epoch: 5| Step: 10
Training loss: 2.1707071141935184
Validation loss: 2.315474137777733

Epoch: 591| Step: 0
Training loss: 1.054285156365785
Validation loss: 2.3490011334410905

Epoch: 5| Step: 1
Training loss: 1.5800963826297616
Validation loss: 2.3113563062973936

Epoch: 5| Step: 2
Training loss: 1.6087208131218833
Validation loss: 2.274718984236411

Epoch: 5| Step: 3
Training loss: 1.104344419650747
Validation loss: 2.2555534051239343

Epoch: 5| Step: 4
Training loss: 0.7694289628417368
Validation loss: 2.341408171180726

Epoch: 5| Step: 5
Training loss: 1.3398778260460387
Validation loss: 2.3100860504804044

Epoch: 5| Step: 6
Training loss: 0.9330991128957561
Validation loss: 2.3296539875349547

Epoch: 5| Step: 7
Training loss: 1.30225158621592
Validation loss: 2.3367067078116124

Epoch: 5| Step: 8
Training loss: 1.3357046716371752
Validation loss: 2.3450961780159822

Epoch: 5| Step: 9
Training loss: 1.9849871795009668
Validation loss: 2.3404423191180337

Epoch: 5| Step: 10
Training loss: 1.489636462493455
Validation loss: 2.38618705880898

Epoch: 592| Step: 0
Training loss: 1.2743619126213341
Validation loss: 2.3957457042646157

Epoch: 5| Step: 1
Training loss: 1.6084005868847584
Validation loss: 2.374417860255854

Epoch: 5| Step: 2
Training loss: 1.0624890607382917
Validation loss: 2.2302683616023296

Epoch: 5| Step: 3
Training loss: 1.6149104207472202
Validation loss: 2.368033291963627

Epoch: 5| Step: 4
Training loss: 1.0998978719118286
Validation loss: 2.456412134218296

Epoch: 5| Step: 5
Training loss: 2.0972377139341067
Validation loss: 2.352441360958795

Epoch: 5| Step: 6
Training loss: 1.0143935734334677
Validation loss: 2.32277585226393

Epoch: 5| Step: 7
Training loss: 1.508862381915937
Validation loss: 2.2888479171758567

Epoch: 5| Step: 8
Training loss: 1.1071679633234086
Validation loss: 2.351967450717515

Epoch: 5| Step: 9
Training loss: 1.0298358005824004
Validation loss: 2.3345165654920743

Epoch: 5| Step: 10
Training loss: 1.2219536563308016
Validation loss: 2.3358966899142155

Epoch: 593| Step: 0
Training loss: 1.0970894650062046
Validation loss: 2.3635102034599793

Epoch: 5| Step: 1
Training loss: 1.5036250656626435
Validation loss: 2.331382302932029

Epoch: 5| Step: 2
Training loss: 1.179940607063296
Validation loss: 2.363698017251154

Epoch: 5| Step: 3
Training loss: 1.2909898625514342
Validation loss: 2.3329589282607213

Epoch: 5| Step: 4
Training loss: 2.058712458219025
Validation loss: 2.2771833220432596

Epoch: 5| Step: 5
Training loss: 1.1964895897781855
Validation loss: 2.2936081486481377

Epoch: 5| Step: 6
Training loss: 1.2076816226378144
Validation loss: 2.3474599799108544

Epoch: 5| Step: 7
Training loss: 1.4890557624208143
Validation loss: 2.2673969376418213

Epoch: 5| Step: 8
Training loss: 1.256475745267952
Validation loss: 2.2801657142498146

Epoch: 5| Step: 9
Training loss: 1.2642684070951205
Validation loss: 2.3687507771171377

Epoch: 5| Step: 10
Training loss: 1.1618988615789991
Validation loss: 2.273853056112333

Epoch: 594| Step: 0
Training loss: 1.1397897457849662
Validation loss: 2.340928395301427

Epoch: 5| Step: 1
Training loss: 1.384624307198182
Validation loss: 2.2920752473398904

Epoch: 5| Step: 2
Training loss: 1.3552487329457055
Validation loss: 2.3655015049026082

Epoch: 5| Step: 3
Training loss: 1.0309580765422852
Validation loss: 2.3614421585461027

Epoch: 5| Step: 4
Training loss: 1.1206148832835738
Validation loss: 2.257219982466017

Epoch: 5| Step: 5
Training loss: 1.4919796943765713
Validation loss: 2.3719648786974097

Epoch: 5| Step: 6
Training loss: 0.9865466791623805
Validation loss: 2.399026588148364

Epoch: 5| Step: 7
Training loss: 1.1892986228582714
Validation loss: 2.384564235364848

Epoch: 5| Step: 8
Training loss: 1.0682071668026274
Validation loss: 2.290413049555866

Epoch: 5| Step: 9
Training loss: 1.3071060606164506
Validation loss: 2.388839096427379

Epoch: 5| Step: 10
Training loss: 2.1067322176179077
Validation loss: 2.324516719456424

Epoch: 595| Step: 0
Training loss: 2.1038005497753023
Validation loss: 2.3839483987430565

Epoch: 5| Step: 1
Training loss: 1.1011418831412514
Validation loss: 2.3256068497232003

Epoch: 5| Step: 2
Training loss: 1.5712608396509802
Validation loss: 2.3741676661774074

Epoch: 5| Step: 3
Training loss: 1.4384683581582478
Validation loss: 2.318315545116741

Epoch: 5| Step: 4
Training loss: 1.2050371209437816
Validation loss: 2.2637166032080547

Epoch: 5| Step: 5
Training loss: 1.3024391857893975
Validation loss: 2.3137024926642242

Epoch: 5| Step: 6
Training loss: 1.2364572755872814
Validation loss: 2.248467579818513

Epoch: 5| Step: 7
Training loss: 1.4189124631918961
Validation loss: 2.256578229205904

Epoch: 5| Step: 8
Training loss: 1.1956054228851427
Validation loss: 2.312209641293299

Epoch: 5| Step: 9
Training loss: 1.337778707682081
Validation loss: 2.36777459627222

Epoch: 5| Step: 10
Training loss: 0.882853853050492
Validation loss: 2.3554930250603654

Epoch: 596| Step: 0
Training loss: 2.0974366483339644
Validation loss: 2.376606281996915

Epoch: 5| Step: 1
Training loss: 1.3040288758942244
Validation loss: 2.261285129517926

Epoch: 5| Step: 2
Training loss: 1.0245172759536156
Validation loss: 2.342974504266676

Epoch: 5| Step: 3
Training loss: 1.3620958393760134
Validation loss: 2.4323874765610314

Epoch: 5| Step: 4
Training loss: 1.1621316859563917
Validation loss: 2.3484076321487866

Epoch: 5| Step: 5
Training loss: 1.1355934472075375
Validation loss: 2.331765118850989

Epoch: 5| Step: 6
Training loss: 1.0154169896662317
Validation loss: 2.3188244541594183

Epoch: 5| Step: 7
Training loss: 1.09860514288073
Validation loss: 2.3282717272923543

Epoch: 5| Step: 8
Training loss: 1.3442999135945928
Validation loss: 2.357412756492816

Epoch: 5| Step: 9
Training loss: 1.326100051125975
Validation loss: 2.360431684156928

Epoch: 5| Step: 10
Training loss: 1.2466854018233249
Validation loss: 2.3047673749143875

Epoch: 597| Step: 0
Training loss: 1.405394145348958
Validation loss: 2.283415377596262

Epoch: 5| Step: 1
Training loss: 1.4073496863289843
Validation loss: 2.337163445639693

Epoch: 5| Step: 2
Training loss: 1.1768077032506172
Validation loss: 2.280508222238593

Epoch: 5| Step: 3
Training loss: 1.12136592950364
Validation loss: 2.424891146284664

Epoch: 5| Step: 4
Training loss: 1.3708978496701885
Validation loss: 2.310701816851703

Epoch: 5| Step: 5
Training loss: 1.0318860491155868
Validation loss: 2.3437629885296536

Epoch: 5| Step: 6
Training loss: 2.1918944768635824
Validation loss: 2.382012804184261

Epoch: 5| Step: 7
Training loss: 1.5935849871012533
Validation loss: 2.3235536655912417

Epoch: 5| Step: 8
Training loss: 1.407730594669946
Validation loss: 2.3556184451225755

Epoch: 5| Step: 9
Training loss: 0.953441379755529
Validation loss: 2.3467754621184804

Epoch: 5| Step: 10
Training loss: 1.384141445048783
Validation loss: 2.4042338178933935

Epoch: 598| Step: 0
Training loss: 1.5396992871603865
Validation loss: 2.255879970542286

Epoch: 5| Step: 1
Training loss: 1.4237124967785022
Validation loss: 2.351451768285889

Epoch: 5| Step: 2
Training loss: 1.2859273064210481
Validation loss: 2.325139353630656

Epoch: 5| Step: 3
Training loss: 1.1156006861155614
Validation loss: 2.397800119432102

Epoch: 5| Step: 4
Training loss: 1.2598540045912152
Validation loss: 2.2828584126217537

Epoch: 5| Step: 5
Training loss: 1.0996762622932243
Validation loss: 2.3148688948841634

Epoch: 5| Step: 6
Training loss: 2.131668286933114
Validation loss: 2.318625269146152

Epoch: 5| Step: 7
Training loss: 1.2979865308953253
Validation loss: 2.3782473277858105

Epoch: 5| Step: 8
Training loss: 1.3317686028947329
Validation loss: 2.356068327583671

Epoch: 5| Step: 9
Training loss: 1.256948138536583
Validation loss: 2.2887229321784743

Epoch: 5| Step: 10
Training loss: 0.8991319046041778
Validation loss: 2.3237112805074536

Epoch: 599| Step: 0
Training loss: 1.045961066471481
Validation loss: 2.3025753475629096

Epoch: 5| Step: 1
Training loss: 1.13238533121591
Validation loss: 2.3587870249235716

Epoch: 5| Step: 2
Training loss: 1.3387946200303438
Validation loss: 2.3515927710012425

Epoch: 5| Step: 3
Training loss: 1.5032627066426199
Validation loss: 2.319528760510017

Epoch: 5| Step: 4
Training loss: 1.1662279507595994
Validation loss: 2.3143277908795405

Epoch: 5| Step: 5
Training loss: 0.9201401372617174
Validation loss: 2.3426254352852713

Epoch: 5| Step: 6
Training loss: 1.1774800850060851
Validation loss: 2.398013322560921

Epoch: 5| Step: 7
Training loss: 1.4214401418539506
Validation loss: 2.3224528411683796

Epoch: 5| Step: 8
Training loss: 2.077276874224695
Validation loss: 2.2822902312034388

Epoch: 5| Step: 9
Training loss: 1.312355124334238
Validation loss: 2.3566213999716434

Epoch: 5| Step: 10
Training loss: 1.40759916223868
Validation loss: 2.2986579154734774

Epoch: 600| Step: 0
Training loss: 1.4569307757959626
Validation loss: 2.276489174020807

Epoch: 5| Step: 1
Training loss: 1.3931645553675702
Validation loss: 2.351892278325143

Epoch: 5| Step: 2
Training loss: 0.9738948549742046
Validation loss: 2.3234263496956977

Epoch: 5| Step: 3
Training loss: 1.010303700742388
Validation loss: 2.403097358084956

Epoch: 5| Step: 4
Training loss: 2.155220228125184
Validation loss: 2.3072830120774257

Epoch: 5| Step: 5
Training loss: 1.5543276883215795
Validation loss: 2.3668758880753855

Epoch: 5| Step: 6
Training loss: 1.2031094438612313
Validation loss: 2.354485277777627

Epoch: 5| Step: 7
Training loss: 1.1637618937637488
Validation loss: 2.298961451008166

Epoch: 5| Step: 8
Training loss: 0.6815498532079931
Validation loss: 2.401099922196485

Epoch: 5| Step: 9
Training loss: 1.381129474473483
Validation loss: 2.180041706592792

Epoch: 5| Step: 10
Training loss: 1.217267724504148
Validation loss: 2.2174783228559103

Epoch: 601| Step: 0
Training loss: 1.9800245400073637
Validation loss: 2.267757307683264

Epoch: 5| Step: 1
Training loss: 0.7093944362044707
Validation loss: 2.3043750938442367

Epoch: 5| Step: 2
Training loss: 1.3776516488539128
Validation loss: 2.3136683081726543

Epoch: 5| Step: 3
Training loss: 1.3386798396456603
Validation loss: 2.362562103809466

Epoch: 5| Step: 4
Training loss: 1.2395826174095501
Validation loss: 2.320388776670978

Epoch: 5| Step: 5
Training loss: 1.1121057561903276
Validation loss: 2.3124224148955075

Epoch: 5| Step: 6
Training loss: 1.4880094505286823
Validation loss: 2.30560072069555

Epoch: 5| Step: 7
Training loss: 0.9910954751100882
Validation loss: 2.380827669263016

Epoch: 5| Step: 8
Training loss: 1.190123270606279
Validation loss: 2.389673766428589

Epoch: 5| Step: 9
Training loss: 1.037925959090804
Validation loss: 2.3586458957904886

Epoch: 5| Step: 10
Training loss: 0.8903970259298882
Validation loss: 2.2801294309636178

Epoch: 602| Step: 0
Training loss: 0.9277073263943428
Validation loss: 2.371161645246738

Epoch: 5| Step: 1
Training loss: 1.095299957682458
Validation loss: 2.3019359717595496

Epoch: 5| Step: 2
Training loss: 1.7094466450686392
Validation loss: 2.312999594881807

Epoch: 5| Step: 3
Training loss: 2.1429098145505607
Validation loss: 2.27108895145511

Epoch: 5| Step: 4
Training loss: 0.9863586723205122
Validation loss: 2.3869740221222933

Epoch: 5| Step: 5
Training loss: 1.2168161748883224
Validation loss: 2.224228172092542

Epoch: 5| Step: 6
Training loss: 1.1978332269329808
Validation loss: 2.3147043942147003

Epoch: 5| Step: 7
Training loss: 1.159703381449434
Validation loss: 2.184862151370262

Epoch: 5| Step: 8
Training loss: 1.3672330576254477
Validation loss: 2.3979109592002223

Epoch: 5| Step: 9
Training loss: 1.3685636733228173
Validation loss: 2.3131942239104872

Epoch: 5| Step: 10
Training loss: 1.1844418952187625
Validation loss: 2.3451556152108863

Epoch: 603| Step: 0
Training loss: 2.1000442409396545
Validation loss: 2.2810681990282298

Epoch: 5| Step: 1
Training loss: 0.8880344326435988
Validation loss: 2.2475580913008852

Epoch: 5| Step: 2
Training loss: 1.4896000503277795
Validation loss: 2.359542369712471

Epoch: 5| Step: 3
Training loss: 1.1410665833071632
Validation loss: 2.3919362785489553

Epoch: 5| Step: 4
Training loss: 1.506103891591226
Validation loss: 2.330614774729931

Epoch: 5| Step: 5
Training loss: 1.2004321790330887
Validation loss: 2.2635626832709614

Epoch: 5| Step: 6
Training loss: 1.5376206048323193
Validation loss: 2.261825937286562

Epoch: 5| Step: 7
Training loss: 1.4206821342555898
Validation loss: 2.3043283957583567

Epoch: 5| Step: 8
Training loss: 0.923270446331955
Validation loss: 2.2957526919429823

Epoch: 5| Step: 9
Training loss: 1.147346653218358
Validation loss: 2.2462426811160796

Epoch: 5| Step: 10
Training loss: 0.9447385448479054
Validation loss: 2.348355354875191

Epoch: 604| Step: 0
Training loss: 1.4355902217626577
Validation loss: 2.3176379995169594

Epoch: 5| Step: 1
Training loss: 1.4250722297967704
Validation loss: 2.2818681107373178

Epoch: 5| Step: 2
Training loss: 2.2135768274244843
Validation loss: 2.3588764962768836

Epoch: 5| Step: 3
Training loss: 1.406091723541824
Validation loss: 2.331519000155645

Epoch: 5| Step: 4
Training loss: 1.2187787566093593
Validation loss: 2.349987075877471

Epoch: 5| Step: 5
Training loss: 1.503488616423269
Validation loss: 2.338851789386592

Epoch: 5| Step: 6
Training loss: 1.4676377975520618
Validation loss: 2.342248468733521

Epoch: 5| Step: 7
Training loss: 0.9048368353786165
Validation loss: 2.2406152757817592

Epoch: 5| Step: 8
Training loss: 1.1512360502178638
Validation loss: 2.3329841320237574

Epoch: 5| Step: 9
Training loss: 1.2789026016807834
Validation loss: 2.249751554693592

Epoch: 5| Step: 10
Training loss: 0.8947814857931042
Validation loss: 2.3648994640683947

Epoch: 605| Step: 0
Training loss: 1.2139730982714243
Validation loss: 2.2902272709162927

Epoch: 5| Step: 1
Training loss: 1.4474519308538603
Validation loss: 2.3314052486436014

Epoch: 5| Step: 2
Training loss: 1.4203888388955532
Validation loss: 2.3791450614875616

Epoch: 5| Step: 3
Training loss: 1.308803347982261
Validation loss: 2.291019308736634

Epoch: 5| Step: 4
Training loss: 1.1139880162147529
Validation loss: 2.3050770514657413

Epoch: 5| Step: 5
Training loss: 1.0492380147544382
Validation loss: 2.235865208381905

Epoch: 5| Step: 6
Training loss: 2.0531256363634025
Validation loss: 2.252233612312391

Epoch: 5| Step: 7
Training loss: 1.112412016314748
Validation loss: 2.298878704093163

Epoch: 5| Step: 8
Training loss: 1.3008545634369908
Validation loss: 2.3834982936972136

Epoch: 5| Step: 9
Training loss: 1.4194755009992288
Validation loss: 2.2864937765641953

Epoch: 5| Step: 10
Training loss: 0.8955434544582913
Validation loss: 2.2142299972148805

Epoch: 606| Step: 0
Training loss: 1.0008930748338536
Validation loss: 2.3765191356172917

Epoch: 5| Step: 1
Training loss: 1.253461289409512
Validation loss: 2.3687039639154883

Epoch: 5| Step: 2
Training loss: 1.3638724982387562
Validation loss: 2.330990556413785

Epoch: 5| Step: 3
Training loss: 1.3245353657806016
Validation loss: 2.3930162436432427

Epoch: 5| Step: 4
Training loss: 1.3349415597018521
Validation loss: 2.3073256498977797

Epoch: 5| Step: 5
Training loss: 0.8465007518104779
Validation loss: 2.3501684736308195

Epoch: 5| Step: 6
Training loss: 2.4051315879114967
Validation loss: 2.361538983997317

Epoch: 5| Step: 7
Training loss: 1.31571965182917
Validation loss: 2.251629916985178

Epoch: 5| Step: 8
Training loss: 0.9573522535431755
Validation loss: 2.2912673005580864

Epoch: 5| Step: 9
Training loss: 1.0859481481675002
Validation loss: 2.353158613197292

Epoch: 5| Step: 10
Training loss: 0.9264448338846063
Validation loss: 2.3286271898098736

Epoch: 607| Step: 0
Training loss: 1.1646408078245865
Validation loss: 2.386881653086891

Epoch: 5| Step: 1
Training loss: 0.9643700243660218
Validation loss: 2.341530508202848

Epoch: 5| Step: 2
Training loss: 2.167357762475486
Validation loss: 2.345424263559001

Epoch: 5| Step: 3
Training loss: 1.1043388604304938
Validation loss: 2.359864091124784

Epoch: 5| Step: 4
Training loss: 1.2593612613354555
Validation loss: 2.2129642275322756

Epoch: 5| Step: 5
Training loss: 1.3039410677330197
Validation loss: 2.4580372382983082

Epoch: 5| Step: 6
Training loss: 0.9664371938847428
Validation loss: 2.3015159724812038

Epoch: 5| Step: 7
Training loss: 1.0651915622412804
Validation loss: 2.321444687668495

Epoch: 5| Step: 8
Training loss: 1.4905407191987743
Validation loss: 2.256711517464236

Epoch: 5| Step: 9
Training loss: 1.271364361655576
Validation loss: 2.33305598147319

Epoch: 5| Step: 10
Training loss: 1.0178566110461382
Validation loss: 2.2388901019413914

Epoch: 608| Step: 0
Training loss: 0.7845007214345344
Validation loss: 2.324812709918438

Epoch: 5| Step: 1
Training loss: 2.0211760502335263
Validation loss: 2.3197268943095426

Epoch: 5| Step: 2
Training loss: 1.391535685803678
Validation loss: 2.319248579106085

Epoch: 5| Step: 3
Training loss: 1.31801368984991
Validation loss: 2.3211221810758005

Epoch: 5| Step: 4
Training loss: 1.4348947717716931
Validation loss: 2.3305348693702572

Epoch: 5| Step: 5
Training loss: 1.0661796356989865
Validation loss: 2.3071657866489237

Epoch: 5| Step: 6
Training loss: 1.0816608442219366
Validation loss: 2.2545494995359667

Epoch: 5| Step: 7
Training loss: 1.126723611556936
Validation loss: 2.32588556528549

Epoch: 5| Step: 8
Training loss: 1.5879458784974725
Validation loss: 2.258698505440436

Epoch: 5| Step: 9
Training loss: 1.3225629689129388
Validation loss: 2.31204520811119

Epoch: 5| Step: 10
Training loss: 1.5119321214183563
Validation loss: 2.3575374448082203

Epoch: 609| Step: 0
Training loss: 0.723109005526128
Validation loss: 2.2991719787286464

Epoch: 5| Step: 1
Training loss: 1.5753098864194093
Validation loss: 2.3220761348941004

Epoch: 5| Step: 2
Training loss: 1.3856778388644733
Validation loss: 2.3384643522905297

Epoch: 5| Step: 3
Training loss: 1.121909187242283
Validation loss: 2.332073823944179

Epoch: 5| Step: 4
Training loss: 0.9875435469477916
Validation loss: 2.3018042219285433

Epoch: 5| Step: 5
Training loss: 1.389908080732367
Validation loss: 2.416621761166482

Epoch: 5| Step: 6
Training loss: 1.4154269553592802
Validation loss: 2.3385441763610184

Epoch: 5| Step: 7
Training loss: 1.340863832127285
Validation loss: 2.3512545949484287

Epoch: 5| Step: 8
Training loss: 1.3542115815367846
Validation loss: 2.3529810517607017

Epoch: 5| Step: 9
Training loss: 1.961284834659983
Validation loss: 2.4233857618038206

Epoch: 5| Step: 10
Training loss: 1.043366374253333
Validation loss: 2.2797346230330673

Epoch: 610| Step: 0
Training loss: 1.2781213848930288
Validation loss: 2.416319187403803

Epoch: 5| Step: 1
Training loss: 2.1252640952762576
Validation loss: 2.2998277777153704

Epoch: 5| Step: 2
Training loss: 1.4953514229582658
Validation loss: 2.288983909363476

Epoch: 5| Step: 3
Training loss: 1.243192446160657
Validation loss: 2.238625469876221

Epoch: 5| Step: 4
Training loss: 1.357323073489516
Validation loss: 2.2568539603253353

Epoch: 5| Step: 5
Training loss: 1.0131205270281354
Validation loss: 2.3093104495378984

Epoch: 5| Step: 6
Training loss: 1.2904431434323558
Validation loss: 2.2724058592113505

Epoch: 5| Step: 7
Training loss: 1.0324408850938531
Validation loss: 2.3105274751932474

Epoch: 5| Step: 8
Training loss: 1.3084510383789298
Validation loss: 2.402227235068317

Epoch: 5| Step: 9
Training loss: 1.076944063776007
Validation loss: 2.3848634314653747

Epoch: 5| Step: 10
Training loss: 1.0568684950977467
Validation loss: 2.3444807853474794

Epoch: 611| Step: 0
Training loss: 2.129023613450743
Validation loss: 2.3130065875264907

Epoch: 5| Step: 1
Training loss: 1.406602179614466
Validation loss: 2.3421682323871766

Epoch: 5| Step: 2
Training loss: 1.4595196213221713
Validation loss: 2.348243576439018

Epoch: 5| Step: 3
Training loss: 1.3050911558768645
Validation loss: 2.2989895030445933

Epoch: 5| Step: 4
Training loss: 1.4495771021579735
Validation loss: 2.3180452508183964

Epoch: 5| Step: 5
Training loss: 1.163339992292815
Validation loss: 2.3121216721430655

Epoch: 5| Step: 6
Training loss: 1.2575712268747035
Validation loss: 2.249374755684849

Epoch: 5| Step: 7
Training loss: 1.0132497154628863
Validation loss: 2.269605357825212

Epoch: 5| Step: 8
Training loss: 1.0831573355592181
Validation loss: 2.284185399674384

Epoch: 5| Step: 9
Training loss: 1.2681004369470996
Validation loss: 2.3174988070650824

Epoch: 5| Step: 10
Training loss: 1.024252414222872
Validation loss: 2.238673195531036

Epoch: 612| Step: 0
Training loss: 1.0243908467675915
Validation loss: 2.332092646023212

Epoch: 5| Step: 1
Training loss: 1.021812080056087
Validation loss: 2.3200404963213908

Epoch: 5| Step: 2
Training loss: 1.0507872627398254
Validation loss: 2.3335405036555437

Epoch: 5| Step: 3
Training loss: 1.1325589652637051
Validation loss: 2.307354420217545

Epoch: 5| Step: 4
Training loss: 1.1910322759308247
Validation loss: 2.3288531940544557

Epoch: 5| Step: 5
Training loss: 1.1525561120860701
Validation loss: 2.3088404981645776

Epoch: 5| Step: 6
Training loss: 1.3546320726787835
Validation loss: 2.3368451371105228

Epoch: 5| Step: 7
Training loss: 1.2326581580337919
Validation loss: 2.3413403161857835

Epoch: 5| Step: 8
Training loss: 2.439217866864801
Validation loss: 2.3234546100476825

Epoch: 5| Step: 9
Training loss: 1.0003816949042863
Validation loss: 2.2811847334114055

Epoch: 5| Step: 10
Training loss: 1.2294309084212676
Validation loss: 2.294851813223251

Epoch: 613| Step: 0
Training loss: 1.0871281854206292
Validation loss: 2.30510038192198

Epoch: 5| Step: 1
Training loss: 1.0740433428345861
Validation loss: 2.2747422299128806

Epoch: 5| Step: 2
Training loss: 1.3375217792484686
Validation loss: 2.316545685719278

Epoch: 5| Step: 3
Training loss: 1.0339139573546574
Validation loss: 2.4493334529207993

Epoch: 5| Step: 4
Training loss: 1.3590957530171084
Validation loss: 2.31463234836063

Epoch: 5| Step: 5
Training loss: 1.465303150618216
Validation loss: 2.302388583905553

Epoch: 5| Step: 6
Training loss: 1.4977156410918078
Validation loss: 2.2439696849813213

Epoch: 5| Step: 7
Training loss: 1.3512172809348377
Validation loss: 2.3515799189282083

Epoch: 5| Step: 8
Training loss: 1.3232435388311827
Validation loss: 2.290011060909848

Epoch: 5| Step: 9
Training loss: 2.2435855560822584
Validation loss: 2.348981652865872

Epoch: 5| Step: 10
Training loss: 1.0539246802842892
Validation loss: 2.3400748640312554

Epoch: 614| Step: 0
Training loss: 2.0789543160634407
Validation loss: 2.214477009246198

Epoch: 5| Step: 1
Training loss: 1.4363905730481785
Validation loss: 2.1941185950702042

Epoch: 5| Step: 2
Training loss: 0.9899036524831563
Validation loss: 2.3097817975632844

Epoch: 5| Step: 3
Training loss: 1.2741331295059837
Validation loss: 2.319664203964207

Epoch: 5| Step: 4
Training loss: 1.1696167103664328
Validation loss: 2.329275218870126

Epoch: 5| Step: 5
Training loss: 1.3580614079115463
Validation loss: 2.3034452663622496

Epoch: 5| Step: 6
Training loss: 1.0157089198727447
Validation loss: 2.3862065284083527

Epoch: 5| Step: 7
Training loss: 1.13394192922682
Validation loss: 2.2910966954901455

Epoch: 5| Step: 8
Training loss: 1.3346533598895456
Validation loss: 2.338184506917524

Epoch: 5| Step: 9
Training loss: 1.0514071844388473
Validation loss: 2.407859891758994

Epoch: 5| Step: 10
Training loss: 1.074626110172619
Validation loss: 2.4026729854022957

Epoch: 615| Step: 0
Training loss: 1.0821943470019249
Validation loss: 2.35369787649592

Epoch: 5| Step: 1
Training loss: 1.39658702126309
Validation loss: 2.230405522093201

Epoch: 5| Step: 2
Training loss: 2.1712881708825305
Validation loss: 2.322616911705243

Epoch: 5| Step: 3
Training loss: 1.0172118481418924
Validation loss: 2.3804627208507565

Epoch: 5| Step: 4
Training loss: 1.063883721881622
Validation loss: 2.3396724728836342

Epoch: 5| Step: 5
Training loss: 1.2436478865221217
Validation loss: 2.361462321230276

Epoch: 5| Step: 6
Training loss: 0.9734754980517791
Validation loss: 2.3458598353009195

Epoch: 5| Step: 7
Training loss: 1.5291730847687428
Validation loss: 2.331862549370439

Epoch: 5| Step: 8
Training loss: 1.3528009815214759
Validation loss: 2.2811021362158717

Epoch: 5| Step: 9
Training loss: 0.9096011978354573
Validation loss: 2.3649963712765234

Epoch: 5| Step: 10
Training loss: 0.7615532328433532
Validation loss: 2.326036617055585

Epoch: 616| Step: 0
Training loss: 1.0191276014321236
Validation loss: 2.344511109512544

Epoch: 5| Step: 1
Training loss: 1.501577898436792
Validation loss: 2.3151314288316476

Epoch: 5| Step: 2
Training loss: 1.032815092374979
Validation loss: 2.3740722817525515

Epoch: 5| Step: 3
Training loss: 1.953363449799742
Validation loss: 2.314848458707596

Epoch: 5| Step: 4
Training loss: 1.1007841891269148
Validation loss: 2.3637598461442937

Epoch: 5| Step: 5
Training loss: 1.380336031014715
Validation loss: 2.2235290196735096

Epoch: 5| Step: 6
Training loss: 1.297651035727831
Validation loss: 2.379958265763671

Epoch: 5| Step: 7
Training loss: 1.5694454703238556
Validation loss: 2.2575236471853612

Epoch: 5| Step: 8
Training loss: 0.9814802021258857
Validation loss: 2.285088508442585

Epoch: 5| Step: 9
Training loss: 1.0265530636613542
Validation loss: 2.3183906893716304

Epoch: 5| Step: 10
Training loss: 1.3484468214435563
Validation loss: 2.39020762404935

Epoch: 617| Step: 0
Training loss: 1.206076432622794
Validation loss: 2.2807221076500013

Epoch: 5| Step: 1
Training loss: 0.8269196140885567
Validation loss: 2.31977830465415

Epoch: 5| Step: 2
Training loss: 1.6340580620179248
Validation loss: 2.346913531015383

Epoch: 5| Step: 3
Training loss: 2.1513320566738434
Validation loss: 2.32824756921549

Epoch: 5| Step: 4
Training loss: 1.0096060001370313
Validation loss: 2.2579774764714124

Epoch: 5| Step: 5
Training loss: 1.4952357448860811
Validation loss: 2.301232233286984

Epoch: 5| Step: 6
Training loss: 1.2682071764826104
Validation loss: 2.3247259929249733

Epoch: 5| Step: 7
Training loss: 0.9583093011302994
Validation loss: 2.3150377547216783

Epoch: 5| Step: 8
Training loss: 1.0323530135930647
Validation loss: 2.3021346291461215

Epoch: 5| Step: 9
Training loss: 1.2765322099171381
Validation loss: 2.3316020153153794

Epoch: 5| Step: 10
Training loss: 0.7972395567905296
Validation loss: 2.2163842813317842

Epoch: 618| Step: 0
Training loss: 1.0412286536878244
Validation loss: 2.291039326362326

Epoch: 5| Step: 1
Training loss: 0.9687069914099949
Validation loss: 2.324456553789999

Epoch: 5| Step: 2
Training loss: 1.043748542647572
Validation loss: 2.281885737559924

Epoch: 5| Step: 3
Training loss: 1.0936628034438762
Validation loss: 2.3732043215204603

Epoch: 5| Step: 4
Training loss: 1.0497276952144978
Validation loss: 2.347481520220949

Epoch: 5| Step: 5
Training loss: 1.3807325075565509
Validation loss: 2.3305934283287386

Epoch: 5| Step: 6
Training loss: 2.1512856210422693
Validation loss: 2.3248805246166766

Epoch: 5| Step: 7
Training loss: 1.3625271960702758
Validation loss: 2.332442518638987

Epoch: 5| Step: 8
Training loss: 1.226786113206684
Validation loss: 2.204318279994069

Epoch: 5| Step: 9
Training loss: 0.9787766038146118
Validation loss: 2.1569276517363627

Epoch: 5| Step: 10
Training loss: 1.3665575156392467
Validation loss: 2.2544502822606534

Epoch: 619| Step: 0
Training loss: 1.8853110043193968
Validation loss: 2.2812946262959004

Epoch: 5| Step: 1
Training loss: 1.050512740419705
Validation loss: 2.274046890322977

Epoch: 5| Step: 2
Training loss: 1.453324991225586
Validation loss: 2.3193885795348774

Epoch: 5| Step: 3
Training loss: 0.9978486403584697
Validation loss: 2.297616869643052

Epoch: 5| Step: 4
Training loss: 1.5555368528301396
Validation loss: 2.2554465153447745

Epoch: 5| Step: 5
Training loss: 1.4066687066543997
Validation loss: 2.374546238135858

Epoch: 5| Step: 6
Training loss: 1.067605039980995
Validation loss: 2.322188317041449

Epoch: 5| Step: 7
Training loss: 1.3350329990094678
Validation loss: 2.323914613211064

Epoch: 5| Step: 8
Training loss: 1.1111600778969037
Validation loss: 2.262549146989667

Epoch: 5| Step: 9
Training loss: 1.1247548789965474
Validation loss: 2.2830739334362016

Epoch: 5| Step: 10
Training loss: 0.9580184827048971
Validation loss: 2.2915106059285217

Epoch: 620| Step: 0
Training loss: 1.3628744923103377
Validation loss: 2.231949303352505

Epoch: 5| Step: 1
Training loss: 1.2087716699687407
Validation loss: 2.3422066904862193

Epoch: 5| Step: 2
Training loss: 1.0997937659356605
Validation loss: 2.238218518830016

Epoch: 5| Step: 3
Training loss: 1.2119348172263409
Validation loss: 2.283920895696588

Epoch: 5| Step: 4
Training loss: 1.8848088234808238
Validation loss: 2.3325642273708493

Epoch: 5| Step: 5
Training loss: 1.417559604098062
Validation loss: 2.2969043281406645

Epoch: 5| Step: 6
Training loss: 1.0636244041449272
Validation loss: 2.2532535487350316

Epoch: 5| Step: 7
Training loss: 1.0319430016812323
Validation loss: 2.2957935009615955

Epoch: 5| Step: 8
Training loss: 1.4121935807443484
Validation loss: 2.271784145794673

Epoch: 5| Step: 9
Training loss: 0.8067409277524946
Validation loss: 2.412148033743336

Epoch: 5| Step: 10
Training loss: 1.463913197268319
Validation loss: 2.3213201777662333

Epoch: 621| Step: 0
Training loss: 1.2254865264089656
Validation loss: 2.391982731924943

Epoch: 5| Step: 1
Training loss: 0.6050685175015353
Validation loss: 2.339728758022474

Epoch: 5| Step: 2
Training loss: 1.0536954947569444
Validation loss: 2.3020875220167163

Epoch: 5| Step: 3
Training loss: 2.103305476750306
Validation loss: 2.2864066725528023

Epoch: 5| Step: 4
Training loss: 1.1541053367781564
Validation loss: 2.3685620012886126

Epoch: 5| Step: 5
Training loss: 1.2087732478907218
Validation loss: 2.2608442492336973

Epoch: 5| Step: 6
Training loss: 0.8049648880853515
Validation loss: 2.2381702548695253

Epoch: 5| Step: 7
Training loss: 1.259701418164527
Validation loss: 2.35812440784729

Epoch: 5| Step: 8
Training loss: 1.191061301401779
Validation loss: 2.271660683853885

Epoch: 5| Step: 9
Training loss: 1.410891270012154
Validation loss: 2.33493448804138

Epoch: 5| Step: 10
Training loss: 1.43213281848788
Validation loss: 2.3084471023911513

Epoch: 622| Step: 0
Training loss: 1.0706051614307344
Validation loss: 2.373280854520627

Epoch: 5| Step: 1
Training loss: 1.3582734654500914
Validation loss: 2.3841381885809865

Epoch: 5| Step: 2
Training loss: 1.1492533996876952
Validation loss: 2.3277941678851524

Epoch: 5| Step: 3
Training loss: 1.0669441403655011
Validation loss: 2.3685841452217486

Epoch: 5| Step: 4
Training loss: 1.1854651735613095
Validation loss: 2.2558411265992073

Epoch: 5| Step: 5
Training loss: 2.167867022352899
Validation loss: 2.215697607662129

Epoch: 5| Step: 6
Training loss: 1.3158623451834002
Validation loss: 2.3108075042006853

Epoch: 5| Step: 7
Training loss: 1.1900360232598797
Validation loss: 2.3078488272315836

Epoch: 5| Step: 8
Training loss: 0.8539781168494716
Validation loss: 2.357523980297162

Epoch: 5| Step: 9
Training loss: 1.4051584882028019
Validation loss: 2.282936016495816

Epoch: 5| Step: 10
Training loss: 1.069670937376768
Validation loss: 2.3066747363720705

Epoch: 623| Step: 0
Training loss: 1.3069874028194937
Validation loss: 2.263904348983669

Epoch: 5| Step: 1
Training loss: 1.147917130061135
Validation loss: 2.2680134778370773

Epoch: 5| Step: 2
Training loss: 2.1034677937487847
Validation loss: 2.3321597763550006

Epoch: 5| Step: 3
Training loss: 1.2011177857168736
Validation loss: 2.1902378206297954

Epoch: 5| Step: 4
Training loss: 1.2639527281450404
Validation loss: 2.4087550038705285

Epoch: 5| Step: 5
Training loss: 1.2107382825827546
Validation loss: 2.383779337205962

Epoch: 5| Step: 6
Training loss: 1.1139222558388995
Validation loss: 2.381206405964508

Epoch: 5| Step: 7
Training loss: 1.4013977260119832
Validation loss: 2.3229454727038528

Epoch: 5| Step: 8
Training loss: 0.977751229628997
Validation loss: 2.26966030937211

Epoch: 5| Step: 9
Training loss: 0.9836154611144148
Validation loss: 2.137740190529288

Epoch: 5| Step: 10
Training loss: 1.2157965355198894
Validation loss: 2.3065212390053262

Epoch: 624| Step: 0
Training loss: 1.0504458434549295
Validation loss: 2.332099577021522

Epoch: 5| Step: 1
Training loss: 2.1620179581721195
Validation loss: 2.2953294335668133

Epoch: 5| Step: 2
Training loss: 1.0142099940360296
Validation loss: 2.3736458119818824

Epoch: 5| Step: 3
Training loss: 0.8454618043601902
Validation loss: 2.3495607216006857

Epoch: 5| Step: 4
Training loss: 1.2318283078399066
Validation loss: 2.2308085282119947

Epoch: 5| Step: 5
Training loss: 1.1397709196379417
Validation loss: 2.289016518779711

Epoch: 5| Step: 6
Training loss: 1.0065862011065811
Validation loss: 2.309395135554756

Epoch: 5| Step: 7
Training loss: 1.1025822025370446
Validation loss: 2.3668832360361143

Epoch: 5| Step: 8
Training loss: 1.3409869596827269
Validation loss: 2.301960104158724

Epoch: 5| Step: 9
Training loss: 1.3990852944070282
Validation loss: 2.353976944895908

Epoch: 5| Step: 10
Training loss: 1.2128793221406218
Validation loss: 2.32430348292259

Epoch: 625| Step: 0
Training loss: 0.832948313619623
Validation loss: 2.3525550063368668

Epoch: 5| Step: 1
Training loss: 1.5016230702960585
Validation loss: 2.281178948541504

Epoch: 5| Step: 2
Training loss: 1.104151179846833
Validation loss: 2.3299132616971883

Epoch: 5| Step: 3
Training loss: 2.1882350231709755
Validation loss: 2.317233974079884

Epoch: 5| Step: 4
Training loss: 0.8213827871215611
Validation loss: 2.260552564172397

Epoch: 5| Step: 5
Training loss: 1.358272763327443
Validation loss: 2.264805890033912

Epoch: 5| Step: 6
Training loss: 1.0712804941757963
Validation loss: 2.3150527675063866

Epoch: 5| Step: 7
Training loss: 1.1376700075143142
Validation loss: 2.243093291562649

Epoch: 5| Step: 8
Training loss: 1.1561936029650188
Validation loss: 2.251613460588391

Epoch: 5| Step: 9
Training loss: 0.9211116798732992
Validation loss: 2.2928113094232043

Epoch: 5| Step: 10
Training loss: 1.1813769337912048
Validation loss: 2.287368486935228

Epoch: 626| Step: 0
Training loss: 1.044176695172456
Validation loss: 2.2548550564925987

Epoch: 5| Step: 1
Training loss: 0.9920413893402142
Validation loss: 2.2760438724525063

Epoch: 5| Step: 2
Training loss: 1.0869528325681692
Validation loss: 2.4478140518649134

Epoch: 5| Step: 3
Training loss: 1.4182390948380155
Validation loss: 2.285732903094326

Epoch: 5| Step: 4
Training loss: 1.0233662121820517
Validation loss: 2.240487669939315

Epoch: 5| Step: 5
Training loss: 1.2592095618996144
Validation loss: 2.327961809916908

Epoch: 5| Step: 6
Training loss: 1.4254366523585273
Validation loss: 2.268401407768227

Epoch: 5| Step: 7
Training loss: 1.2076026033362688
Validation loss: 2.268942883071459

Epoch: 5| Step: 8
Training loss: 2.075801496941798
Validation loss: 2.340195928242017

Epoch: 5| Step: 9
Training loss: 1.2545573602929432
Validation loss: 2.291082124934153

Epoch: 5| Step: 10
Training loss: 1.0366133313600385
Validation loss: 2.2576184404217807

Epoch: 627| Step: 0
Training loss: 1.047001617517834
Validation loss: 2.3133531785295607

Epoch: 5| Step: 1
Training loss: 0.7872323822758854
Validation loss: 2.4109991793453642

Epoch: 5| Step: 2
Training loss: 2.3600707386212783
Validation loss: 2.403893279655709

Epoch: 5| Step: 3
Training loss: 1.2257676191283222
Validation loss: 2.2968801822454608

Epoch: 5| Step: 4
Training loss: 1.207085617470591
Validation loss: 2.318498544536226

Epoch: 5| Step: 5
Training loss: 1.080535240085877
Validation loss: 2.285801710093575

Epoch: 5| Step: 6
Training loss: 1.0530213936120496
Validation loss: 2.363910998139684

Epoch: 5| Step: 7
Training loss: 1.2206143034091779
Validation loss: 2.394919522838031

Epoch: 5| Step: 8
Training loss: 0.9837092009909523
Validation loss: 2.259126352112439

Epoch: 5| Step: 9
Training loss: 1.0585663851758853
Validation loss: 2.3165805260463563

Epoch: 5| Step: 10
Training loss: 1.5507461197955368
Validation loss: 2.3093398367790603

Epoch: 628| Step: 0
Training loss: 1.1183931474186495
Validation loss: 2.3243345313645927

Epoch: 5| Step: 1
Training loss: 1.321811028774575
Validation loss: 2.3480550789523287

Epoch: 5| Step: 2
Training loss: 1.3788679944315954
Validation loss: 2.312105476096651

Epoch: 5| Step: 3
Training loss: 1.1460724956723327
Validation loss: 2.2737453804626964

Epoch: 5| Step: 4
Training loss: 2.02440016539791
Validation loss: 2.3085788429064493

Epoch: 5| Step: 5
Training loss: 1.2417796683041833
Validation loss: 2.2412553830410973

Epoch: 5| Step: 6
Training loss: 0.886595192253696
Validation loss: 2.371440944135804

Epoch: 5| Step: 7
Training loss: 1.188645713636099
Validation loss: 2.316511860801967

Epoch: 5| Step: 8
Training loss: 1.1117031758464728
Validation loss: 2.4052434828994396

Epoch: 5| Step: 9
Training loss: 1.1469036940641297
Validation loss: 2.3362072059014793

Epoch: 5| Step: 10
Training loss: 1.040725467173734
Validation loss: 2.3077842290157293

Epoch: 629| Step: 0
Training loss: 0.8342496999317667
Validation loss: 2.265306179201167

Epoch: 5| Step: 1
Training loss: 0.803053854971273
Validation loss: 2.294803111560343

Epoch: 5| Step: 2
Training loss: 1.4903210056067813
Validation loss: 2.392156843808273

Epoch: 5| Step: 3
Training loss: 1.185879756441466
Validation loss: 2.2864748325145503

Epoch: 5| Step: 4
Training loss: 1.087354325808909
Validation loss: 2.250828768091919

Epoch: 5| Step: 5
Training loss: 1.0721461606485359
Validation loss: 2.2660306064643696

Epoch: 5| Step: 6
Training loss: 1.140331178210587
Validation loss: 2.2596873768483587

Epoch: 5| Step: 7
Training loss: 2.0493471780920283
Validation loss: 2.337843540372126

Epoch: 5| Step: 8
Training loss: 1.2907209882532775
Validation loss: 2.336378251784265

Epoch: 5| Step: 9
Training loss: 1.1650135328464615
Validation loss: 2.296488755864945

Epoch: 5| Step: 10
Training loss: 1.1676972242649857
Validation loss: 2.3254275764487393

Epoch: 630| Step: 0
Training loss: 1.131845627250369
Validation loss: 2.337152687742788

Epoch: 5| Step: 1
Training loss: 0.942205888812279
Validation loss: 2.2547943531763384

Epoch: 5| Step: 2
Training loss: 1.0495640394601258
Validation loss: 2.2840637955697907

Epoch: 5| Step: 3
Training loss: 0.9037879846697277
Validation loss: 2.341783876660183

Epoch: 5| Step: 4
Training loss: 1.3795198366758286
Validation loss: 2.2577578386168575

Epoch: 5| Step: 5
Training loss: 2.101739358373414
Validation loss: 2.2437185615647093

Epoch: 5| Step: 6
Training loss: 1.4524772594989472
Validation loss: 2.3402141328777324

Epoch: 5| Step: 7
Training loss: 1.18291718436715
Validation loss: 2.326388438524784

Epoch: 5| Step: 8
Training loss: 0.9890742079778564
Validation loss: 2.235023652785441

Epoch: 5| Step: 9
Training loss: 1.202107631012461
Validation loss: 2.2847121349935353

Epoch: 5| Step: 10
Training loss: 1.1920757476305728
Validation loss: 2.3187001009718284

Epoch: 631| Step: 0
Training loss: 1.1607677761789625
Validation loss: 2.344079059211542

Epoch: 5| Step: 1
Training loss: 0.9322532702731579
Validation loss: 2.2595067900521015

Epoch: 5| Step: 2
Training loss: 1.212607382905617
Validation loss: 2.296149937934313

Epoch: 5| Step: 3
Training loss: 1.4768839491267527
Validation loss: 2.2556759910373256

Epoch: 5| Step: 4
Training loss: 0.901694390287334
Validation loss: 2.321563726955641

Epoch: 5| Step: 5
Training loss: 1.0013488374996384
Validation loss: 2.3826736805147153

Epoch: 5| Step: 6
Training loss: 2.0847978657685933
Validation loss: 2.288743065937865

Epoch: 5| Step: 7
Training loss: 1.4546767942237466
Validation loss: 2.272470434112866

Epoch: 5| Step: 8
Training loss: 1.1558959521984038
Validation loss: 2.3108915964779397

Epoch: 5| Step: 9
Training loss: 1.2046727715172019
Validation loss: 2.325422414275244

Epoch: 5| Step: 10
Training loss: 1.1898056034177413
Validation loss: 2.336048131969163

Epoch: 632| Step: 0
Training loss: 0.9703381349184238
Validation loss: 2.2485818278894545

Epoch: 5| Step: 1
Training loss: 0.9388168305584824
Validation loss: 2.4015051249611536

Epoch: 5| Step: 2
Training loss: 1.7727074149604571
Validation loss: 2.3474823097955855

Epoch: 5| Step: 3
Training loss: 1.1864519513734155
Validation loss: 2.356736346567934

Epoch: 5| Step: 4
Training loss: 1.0889119639406175
Validation loss: 2.2090110234280598

Epoch: 5| Step: 5
Training loss: 0.5570856289850762
Validation loss: 2.3908298808654704

Epoch: 5| Step: 6
Training loss: 0.9609952149465558
Validation loss: 2.3852120499030494

Epoch: 5| Step: 7
Training loss: 1.0939578267604042
Validation loss: 2.2637644357615607

Epoch: 5| Step: 8
Training loss: 0.8423555648787452
Validation loss: 2.2723236586139044

Epoch: 5| Step: 9
Training loss: 1.281847930577752
Validation loss: 2.248478269764308

Epoch: 5| Step: 10
Training loss: 2.2985897799523656
Validation loss: 2.261955738341322

Epoch: 633| Step: 0
Training loss: 1.115258051258502
Validation loss: 2.3048249139937433

Epoch: 5| Step: 1
Training loss: 1.0782420329828453
Validation loss: 2.3407362968544185

Epoch: 5| Step: 2
Training loss: 1.3985340788326797
Validation loss: 2.3422872494880975

Epoch: 5| Step: 3
Training loss: 1.925007693783136
Validation loss: 2.2825200794206864

Epoch: 5| Step: 4
Training loss: 0.9968876685410799
Validation loss: 2.3438951979203684

Epoch: 5| Step: 5
Training loss: 1.1528877655219247
Validation loss: 2.333478635411053

Epoch: 5| Step: 6
Training loss: 1.336943175372959
Validation loss: 2.27110214501351

Epoch: 5| Step: 7
Training loss: 1.0237032130429553
Validation loss: 2.3113176670736397

Epoch: 5| Step: 8
Training loss: 1.230195950740004
Validation loss: 2.2642245775339647

Epoch: 5| Step: 9
Training loss: 1.3740230904628203
Validation loss: 2.2890425927626725

Epoch: 5| Step: 10
Training loss: 0.7042904837133743
Validation loss: 2.3359165523384244

Epoch: 634| Step: 0
Training loss: 1.4569320031285304
Validation loss: 2.265971022771002

Epoch: 5| Step: 1
Training loss: 1.0335477027237505
Validation loss: 2.280165718747103

Epoch: 5| Step: 2
Training loss: 0.9530621492269019
Validation loss: 2.352815966012455

Epoch: 5| Step: 3
Training loss: 2.143032530010363
Validation loss: 2.3147502937713513

Epoch: 5| Step: 4
Training loss: 1.105722620629178
Validation loss: 2.395876429751133

Epoch: 5| Step: 5
Training loss: 1.4146880562867354
Validation loss: 2.289240450131521

Epoch: 5| Step: 6
Training loss: 1.269173251807265
Validation loss: 2.342656931419487

Epoch: 5| Step: 7
Training loss: 0.9493118366076142
Validation loss: 2.290381981161562

Epoch: 5| Step: 8
Training loss: 1.0445949720462901
Validation loss: 2.3291778925495414

Epoch: 5| Step: 9
Training loss: 1.0955583065295893
Validation loss: 2.2958662485383905

Epoch: 5| Step: 10
Training loss: 1.1339652674501115
Validation loss: 2.3926226088620335

Epoch: 635| Step: 0
Training loss: 1.2729543693856766
Validation loss: 2.293143725641741

Epoch: 5| Step: 1
Training loss: 1.40200529556798
Validation loss: 2.3412585989581953

Epoch: 5| Step: 2
Training loss: 0.8431280457573829
Validation loss: 2.25420604546161

Epoch: 5| Step: 3
Training loss: 1.2189599369872832
Validation loss: 2.229831879405108

Epoch: 5| Step: 4
Training loss: 1.0315006991747855
Validation loss: 2.369339856703156

Epoch: 5| Step: 5
Training loss: 2.0659991550203793
Validation loss: 2.301897112040161

Epoch: 5| Step: 6
Training loss: 0.9331391316983499
Validation loss: 2.267261023911003

Epoch: 5| Step: 7
Training loss: 1.4260029659588158
Validation loss: 2.2170691006398404

Epoch: 5| Step: 8
Training loss: 0.8847951652530142
Validation loss: 2.3245800365882836

Epoch: 5| Step: 9
Training loss: 1.0602439040152916
Validation loss: 2.3710314533392576

Epoch: 5| Step: 10
Training loss: 1.140793670306629
Validation loss: 2.259683063432663

Epoch: 636| Step: 0
Training loss: 1.0768695100100827
Validation loss: 2.271529995582862

Epoch: 5| Step: 1
Training loss: 1.2423949638195848
Validation loss: 2.3456390577850335

Epoch: 5| Step: 2
Training loss: 1.0033692582459084
Validation loss: 2.1551872387950057

Epoch: 5| Step: 3
Training loss: 0.7851838823456955
Validation loss: 2.367940692116456

Epoch: 5| Step: 4
Training loss: 1.5019109791967573
Validation loss: 2.1653516936490007

Epoch: 5| Step: 5
Training loss: 1.4689878717522982
Validation loss: 2.224727476767937

Epoch: 5| Step: 6
Training loss: 1.0375757120841278
Validation loss: 2.2261206490175742

Epoch: 5| Step: 7
Training loss: 1.1385568655569525
Validation loss: 2.3475757398271684

Epoch: 5| Step: 8
Training loss: 1.0449121777806458
Validation loss: 2.2865808245626034

Epoch: 5| Step: 9
Training loss: 0.9763128648218419
Validation loss: 2.26001422630767

Epoch: 5| Step: 10
Training loss: 2.052572111472976
Validation loss: 2.256733800704351

Epoch: 637| Step: 0
Training loss: 1.2957224492819133
Validation loss: 2.253642389246171

Epoch: 5| Step: 1
Training loss: 1.2407500388986896
Validation loss: 2.231482331082937

Epoch: 5| Step: 2
Training loss: 1.1629930742603707
Validation loss: 2.275716933646455

Epoch: 5| Step: 3
Training loss: 1.0215825166838777
Validation loss: 2.387370851899271

Epoch: 5| Step: 4
Training loss: 2.12255381988838
Validation loss: 2.2971309931903248

Epoch: 5| Step: 5
Training loss: 1.1640517471124059
Validation loss: 2.2870051382102794

Epoch: 5| Step: 6
Training loss: 0.9300742426842895
Validation loss: 2.184910787978826

Epoch: 5| Step: 7
Training loss: 1.104720060955855
Validation loss: 2.2658805864247884

Epoch: 5| Step: 8
Training loss: 1.1113879249721335
Validation loss: 2.2730868224518095

Epoch: 5| Step: 9
Training loss: 0.9656254308508249
Validation loss: 2.2805995286309657

Epoch: 5| Step: 10
Training loss: 1.020830284165999
Validation loss: 2.2827049062741906

Epoch: 638| Step: 0
Training loss: 2.221894520862955
Validation loss: 2.182549210446677

Epoch: 5| Step: 1
Training loss: 1.1685405849579413
Validation loss: 2.3118407405300463

Epoch: 5| Step: 2
Training loss: 0.9396600316977068
Validation loss: 2.277911551912766

Epoch: 5| Step: 3
Training loss: 1.0688126908147049
Validation loss: 2.3022030728852982

Epoch: 5| Step: 4
Training loss: 1.320122067413815
Validation loss: 2.3468156788425882

Epoch: 5| Step: 5
Training loss: 1.0646177951935776
Validation loss: 2.3440524129705764

Epoch: 5| Step: 6
Training loss: 0.9703865379307007
Validation loss: 2.3756097389760056

Epoch: 5| Step: 7
Training loss: 1.1697894548421837
Validation loss: 2.273677167010708

Epoch: 5| Step: 8
Training loss: 0.711623227925174
Validation loss: 2.272530068223047

Epoch: 5| Step: 9
Training loss: 1.407990544076075
Validation loss: 2.2432199857673205

Epoch: 5| Step: 10
Training loss: 1.249706949214779
Validation loss: 2.2989064861562696

Epoch: 639| Step: 0
Training loss: 1.1138547256845523
Validation loss: 2.2155546247093936

Epoch: 5| Step: 1
Training loss: 1.0813567334895415
Validation loss: 2.3167624613412694

Epoch: 5| Step: 2
Training loss: 1.2416729131110522
Validation loss: 2.3547186858139426

Epoch: 5| Step: 3
Training loss: 0.9627158604118293
Validation loss: 2.3472516837393513

Epoch: 5| Step: 4
Training loss: 0.8716615613881477
Validation loss: 2.365162227302474

Epoch: 5| Step: 5
Training loss: 1.0985767129774164
Validation loss: 2.2841700094872968

Epoch: 5| Step: 6
Training loss: 1.344190658352072
Validation loss: 2.290424546333141

Epoch: 5| Step: 7
Training loss: 1.1115296621890698
Validation loss: 2.3741228397652203

Epoch: 5| Step: 8
Training loss: 1.1853347915415882
Validation loss: 2.308871199372541

Epoch: 5| Step: 9
Training loss: 1.1413165569639623
Validation loss: 2.367853718077364

Epoch: 5| Step: 10
Training loss: 2.1586564498449103
Validation loss: 2.3176435081059608

Epoch: 640| Step: 0
Training loss: 1.3209228007985765
Validation loss: 2.241714061106888

Epoch: 5| Step: 1
Training loss: 1.2333505942880905
Validation loss: 2.297063701870571

Epoch: 5| Step: 2
Training loss: 1.2490161361659886
Validation loss: 2.2142953374038385

Epoch: 5| Step: 3
Training loss: 1.096627129699107
Validation loss: 2.2809575818192713

Epoch: 5| Step: 4
Training loss: 1.0936338635503051
Validation loss: 2.31673252146085

Epoch: 5| Step: 5
Training loss: 1.9793189809982723
Validation loss: 2.3170719780668687

Epoch: 5| Step: 6
Training loss: 1.1936930737728058
Validation loss: 2.295411283714989

Epoch: 5| Step: 7
Training loss: 1.3910614357496167
Validation loss: 2.351326123791977

Epoch: 5| Step: 8
Training loss: 1.1798247705892428
Validation loss: 2.254194424523719

Epoch: 5| Step: 9
Training loss: 0.8326052266424419
Validation loss: 2.286032684425723

Epoch: 5| Step: 10
Training loss: 0.9378638832890589
Validation loss: 2.2575548918283217

Epoch: 641| Step: 0
Training loss: 1.0041228183232087
Validation loss: 2.3422919908706907

Epoch: 5| Step: 1
Training loss: 1.02489402734909
Validation loss: 2.2974363501470574

Epoch: 5| Step: 2
Training loss: 1.25558891172371
Validation loss: 2.3240794751490665

Epoch: 5| Step: 3
Training loss: 1.1324418086244672
Validation loss: 2.3290410507657584

Epoch: 5| Step: 4
Training loss: 1.5193756729934187
Validation loss: 2.275834579848026

Epoch: 5| Step: 5
Training loss: 1.2001180352333813
Validation loss: 2.309511303741331

Epoch: 5| Step: 6
Training loss: 1.045181384794511
Validation loss: 2.323440972298483

Epoch: 5| Step: 7
Training loss: 0.9005289364581279
Validation loss: 2.3072164340804613

Epoch: 5| Step: 8
Training loss: 2.0454634830009866
Validation loss: 2.3206208085934374

Epoch: 5| Step: 9
Training loss: 1.2657731993762613
Validation loss: 2.409920683906845

Epoch: 5| Step: 10
Training loss: 1.1771610313135534
Validation loss: 2.3550376654751215

Epoch: 642| Step: 0
Training loss: 0.911976643284143
Validation loss: 2.376949375989646

Epoch: 5| Step: 1
Training loss: 0.966670295829099
Validation loss: 2.342154446379671

Epoch: 5| Step: 2
Training loss: 1.6916169702656025
Validation loss: 2.347865200362166

Epoch: 5| Step: 3
Training loss: 1.1553478329873643
Validation loss: 2.2756772933155216

Epoch: 5| Step: 4
Training loss: 1.0778577169178274
Validation loss: 2.254022638163655

Epoch: 5| Step: 5
Training loss: 1.2418904459145865
Validation loss: 2.246195229854571

Epoch: 5| Step: 6
Training loss: 1.2540272686988345
Validation loss: 2.3076320519244

Epoch: 5| Step: 7
Training loss: 1.261263502443776
Validation loss: 2.32702913856758

Epoch: 5| Step: 8
Training loss: 0.9314412477468187
Validation loss: 2.3926872577100022

Epoch: 5| Step: 9
Training loss: 1.1682090894742887
Validation loss: 2.2795239227284605

Epoch: 5| Step: 10
Training loss: 2.129402312833322
Validation loss: 2.3167044031937376

Epoch: 643| Step: 0
Training loss: 1.4039972274758332
Validation loss: 2.3203394973094147

Epoch: 5| Step: 1
Training loss: 1.4490640151505634
Validation loss: 2.36166276461091

Epoch: 5| Step: 2
Training loss: 2.0632775892740147
Validation loss: 2.2807160613889463

Epoch: 5| Step: 3
Training loss: 1.0040232668114655
Validation loss: 2.3438986563624167

Epoch: 5| Step: 4
Training loss: 0.8189021748072182
Validation loss: 2.2890210569127794

Epoch: 5| Step: 5
Training loss: 1.1566202756463042
Validation loss: 2.2185466753498133

Epoch: 5| Step: 6
Training loss: 1.2324534561777951
Validation loss: 2.400023985558294

Epoch: 5| Step: 7
Training loss: 1.0478354645671946
Validation loss: 2.318021588358333

Epoch: 5| Step: 8
Training loss: 1.0609769563824123
Validation loss: 2.3587174472120793

Epoch: 5| Step: 9
Training loss: 0.9627820741079797
Validation loss: 2.298395612974712

Epoch: 5| Step: 10
Training loss: 1.021833079466889
Validation loss: 2.3453511315388504

Epoch: 644| Step: 0
Training loss: 1.0386884202388986
Validation loss: 2.211809133262748

Epoch: 5| Step: 1
Training loss: 1.3087672787521283
Validation loss: 2.318250923665538

Epoch: 5| Step: 2
Training loss: 1.1666509536411633
Validation loss: 2.3392244132508573

Epoch: 5| Step: 3
Training loss: 1.0381509324520328
Validation loss: 2.303989008248195

Epoch: 5| Step: 4
Training loss: 0.9053541886116728
Validation loss: 2.320487953143858

Epoch: 5| Step: 5
Training loss: 1.9579845550754016
Validation loss: 2.3723500055546256

Epoch: 5| Step: 6
Training loss: 1.4101726922003908
Validation loss: 2.308806072908673

Epoch: 5| Step: 7
Training loss: 0.973401561581872
Validation loss: 2.3635772538687543

Epoch: 5| Step: 8
Training loss: 1.2241996797732921
Validation loss: 2.330981477486116

Epoch: 5| Step: 9
Training loss: 0.8186288904204506
Validation loss: 2.3340072555886144

Epoch: 5| Step: 10
Training loss: 1.1534362786347798
Validation loss: 2.2717061180776597

Epoch: 645| Step: 0
Training loss: 1.2457323177980517
Validation loss: 2.285888923513167

Epoch: 5| Step: 1
Training loss: 1.3851476661515127
Validation loss: 2.2346455405731156

Epoch: 5| Step: 2
Training loss: 1.1133669100816872
Validation loss: 2.4321689201009025

Epoch: 5| Step: 3
Training loss: 1.2119987513532595
Validation loss: 2.262933207969417

Epoch: 5| Step: 4
Training loss: 1.0726563900296646
Validation loss: 2.2526836797814473

Epoch: 5| Step: 5
Training loss: 0.9138030963818528
Validation loss: 2.3411411666472284

Epoch: 5| Step: 6
Training loss: 1.8749692914355407
Validation loss: 2.3689109116624856

Epoch: 5| Step: 7
Training loss: 1.3992829990172846
Validation loss: 2.3016175210059067

Epoch: 5| Step: 8
Training loss: 1.035694716414311
Validation loss: 2.3041209380143406

Epoch: 5| Step: 9
Training loss: 0.8585284485077506
Validation loss: 2.251354361945185

Epoch: 5| Step: 10
Training loss: 0.9905722980138645
Validation loss: 2.320065644839743

Epoch: 646| Step: 0
Training loss: 1.5936138618517457
Validation loss: 2.28965356135286

Epoch: 5| Step: 1
Training loss: 1.217426118978562
Validation loss: 2.396246169280088

Epoch: 5| Step: 2
Training loss: 0.8042082609445363
Validation loss: 2.297869987691619

Epoch: 5| Step: 3
Training loss: 1.212422893471385
Validation loss: 2.359501769608459

Epoch: 5| Step: 4
Training loss: 0.8669617161355629
Validation loss: 2.210301149559802

Epoch: 5| Step: 5
Training loss: 0.8895597277568417
Validation loss: 2.306822116774735

Epoch: 5| Step: 6
Training loss: 2.067494327671153
Validation loss: 2.35164186093481

Epoch: 5| Step: 7
Training loss: 1.20022739401666
Validation loss: 2.3674639950514402

Epoch: 5| Step: 8
Training loss: 0.7682568992307438
Validation loss: 2.2540451680631737

Epoch: 5| Step: 9
Training loss: 1.332247182398197
Validation loss: 2.2674448480189606

Epoch: 5| Step: 10
Training loss: 0.9975870943409368
Validation loss: 2.2375632991557453

Epoch: 647| Step: 0
Training loss: 1.1405588418246684
Validation loss: 2.2605473145239396

Epoch: 5| Step: 1
Training loss: 0.7789022646450983
Validation loss: 2.255996444381164

Epoch: 5| Step: 2
Training loss: 1.351954056134106
Validation loss: 2.3680119396826496

Epoch: 5| Step: 3
Training loss: 0.9971505935136951
Validation loss: 2.3428796728722032

Epoch: 5| Step: 4
Training loss: 1.2487804185371918
Validation loss: 2.342267681880095

Epoch: 5| Step: 5
Training loss: 1.0767450761932675
Validation loss: 2.3663482201619446

Epoch: 5| Step: 6
Training loss: 1.6010196417056979
Validation loss: 2.271164093208837

Epoch: 5| Step: 7
Training loss: 1.0066727099858288
Validation loss: 2.207858504939824

Epoch: 5| Step: 8
Training loss: 1.1638882397781622
Validation loss: 2.2744782795827283

Epoch: 5| Step: 9
Training loss: 1.9567357980493738
Validation loss: 2.296833594075045

Epoch: 5| Step: 10
Training loss: 1.0507485196713302
Validation loss: 2.3048728661149145

Epoch: 648| Step: 0
Training loss: 1.9871662363473537
Validation loss: 2.2497236282628417

Epoch: 5| Step: 1
Training loss: 1.1024468301421186
Validation loss: 2.2292630938870546

Epoch: 5| Step: 2
Training loss: 1.3187539195504179
Validation loss: 2.303118817578558

Epoch: 5| Step: 3
Training loss: 1.1131892651486153
Validation loss: 2.400532494157213

Epoch: 5| Step: 4
Training loss: 1.014468899539224
Validation loss: 2.3114443328582333

Epoch: 5| Step: 5
Training loss: 0.8221361869362932
Validation loss: 2.2500246814572704

Epoch: 5| Step: 6
Training loss: 1.002465427592122
Validation loss: 2.267061800133053

Epoch: 5| Step: 7
Training loss: 0.9995239137801017
Validation loss: 2.287753368520466

Epoch: 5| Step: 8
Training loss: 0.704365420272117
Validation loss: 2.3177343116586515

Epoch: 5| Step: 9
Training loss: 1.362465600795646
Validation loss: 2.259387912984813

Epoch: 5| Step: 10
Training loss: 1.3120912187778877
Validation loss: 2.285151883690744

Epoch: 649| Step: 0
Training loss: 1.0212579479865425
Validation loss: 2.3207738395681843

Epoch: 5| Step: 1
Training loss: 1.3029949608190823
Validation loss: 2.261542657393549

Epoch: 5| Step: 2
Training loss: 1.0102190368446138
Validation loss: 2.236476455829714

Epoch: 5| Step: 3
Training loss: 2.243141423311693
Validation loss: 2.3455042486169435

Epoch: 5| Step: 4
Training loss: 0.9848430065967454
Validation loss: 2.3087343429548066

Epoch: 5| Step: 5
Training loss: 1.1639383237006544
Validation loss: 2.3037338405581855

Epoch: 5| Step: 6
Training loss: 1.2424079651393642
Validation loss: 2.295630333123037

Epoch: 5| Step: 7
Training loss: 0.9966151051170645
Validation loss: 2.2062531524303814

Epoch: 5| Step: 8
Training loss: 1.1976257579129386
Validation loss: 2.3367707862451934

Epoch: 5| Step: 9
Training loss: 0.8648679831537611
Validation loss: 2.357087082494419

Epoch: 5| Step: 10
Training loss: 1.0612119272005371
Validation loss: 2.3557602714519787

Epoch: 650| Step: 0
Training loss: 1.1876613105833735
Validation loss: 2.2744176559001748

Epoch: 5| Step: 1
Training loss: 0.7440665300781618
Validation loss: 2.304324707153319

Epoch: 5| Step: 2
Training loss: 1.084312265653682
Validation loss: 2.354502742589861

Epoch: 5| Step: 3
Training loss: 0.8864692975691173
Validation loss: 2.2877017455757707

Epoch: 5| Step: 4
Training loss: 1.2615246224829693
Validation loss: 2.283650679017969

Epoch: 5| Step: 5
Training loss: 1.1788075177590152
Validation loss: 2.3206092388121076

Epoch: 5| Step: 6
Training loss: 1.2838910028565047
Validation loss: 2.2626497930790723

Epoch: 5| Step: 7
Training loss: 2.0774987216399263
Validation loss: 2.2746889620700657

Epoch: 5| Step: 8
Training loss: 1.3860146037676875
Validation loss: 2.3315240674637083

Epoch: 5| Step: 9
Training loss: 0.7304665468560108
Validation loss: 2.227143302830748

Epoch: 5| Step: 10
Training loss: 1.0980932377242183
Validation loss: 2.364108718641385

Epoch: 651| Step: 0
Training loss: 0.9155662101125142
Validation loss: 2.2211236263671172

Epoch: 5| Step: 1
Training loss: 1.2049994790800242
Validation loss: 2.256093542606445

Epoch: 5| Step: 2
Training loss: 1.0090811972068736
Validation loss: 2.204048025636601

Epoch: 5| Step: 3
Training loss: 1.344134120598387
Validation loss: 2.30654186010835

Epoch: 5| Step: 4
Training loss: 0.8962446237080953
Validation loss: 2.3103848950135646

Epoch: 5| Step: 5
Training loss: 1.0292321316880113
Validation loss: 2.2469050075420047

Epoch: 5| Step: 6
Training loss: 1.2988248208369626
Validation loss: 2.1818035179969493

Epoch: 5| Step: 7
Training loss: 1.1132599410309891
Validation loss: 2.3598737922189725

Epoch: 5| Step: 8
Training loss: 1.1201409201864065
Validation loss: 2.34792897753972

Epoch: 5| Step: 9
Training loss: 1.3355520930582978
Validation loss: 2.276870921890081

Epoch: 5| Step: 10
Training loss: 2.040694478883657
Validation loss: 2.345070998386968

Epoch: 652| Step: 0
Training loss: 1.0158563203742983
Validation loss: 2.250710159947209

Epoch: 5| Step: 1
Training loss: 1.976115783148706
Validation loss: 2.269084123124956

Epoch: 5| Step: 2
Training loss: 1.200515393998518
Validation loss: 2.310870986177958

Epoch: 5| Step: 3
Training loss: 1.1740429978303157
Validation loss: 2.3545190150180932

Epoch: 5| Step: 4
Training loss: 1.0022665801338475
Validation loss: 2.351936771423924

Epoch: 5| Step: 5
Training loss: 1.0745805165871578
Validation loss: 2.269019201449163

Epoch: 5| Step: 6
Training loss: 0.8789107598083082
Validation loss: 2.3256218477441255

Epoch: 5| Step: 7
Training loss: 1.3819306142339665
Validation loss: 2.363393758551551

Epoch: 5| Step: 8
Training loss: 1.1495463409408069
Validation loss: 2.2464076798935206

Epoch: 5| Step: 9
Training loss: 1.4964959224055263
Validation loss: 2.308670238399804

Epoch: 5| Step: 10
Training loss: 0.9467859056310907
Validation loss: 2.305688285968807

Epoch: 653| Step: 0
Training loss: 1.2051366362131117
Validation loss: 2.275125474342036

Epoch: 5| Step: 1
Training loss: 1.0090845640906227
Validation loss: 2.3931438809296632

Epoch: 5| Step: 2
Training loss: 1.4770879062999678
Validation loss: 2.3775202020390016

Epoch: 5| Step: 3
Training loss: 1.0977469301608693
Validation loss: 2.3586315626377927

Epoch: 5| Step: 4
Training loss: 1.0728865251967663
Validation loss: 2.3506888244931394

Epoch: 5| Step: 5
Training loss: 0.9060749345257602
Validation loss: 2.2924166827100705

Epoch: 5| Step: 6
Training loss: 0.9886471519559223
Validation loss: 2.2861834089416595

Epoch: 5| Step: 7
Training loss: 2.0806174568550606
Validation loss: 2.282003302214728

Epoch: 5| Step: 8
Training loss: 1.0838895739091483
Validation loss: 2.191935720094122

Epoch: 5| Step: 9
Training loss: 0.9522433346139265
Validation loss: 2.2361272201216007

Epoch: 5| Step: 10
Training loss: 0.9653286970020187
Validation loss: 2.219158995139001

Epoch: 654| Step: 0
Training loss: 1.318085456931489
Validation loss: 2.258266878582521

Epoch: 5| Step: 1
Training loss: 0.9000527830010625
Validation loss: 2.227887487461276

Epoch: 5| Step: 2
Training loss: 1.3782877196698624
Validation loss: 2.298838926749198

Epoch: 5| Step: 3
Training loss: 2.0413730436150668
Validation loss: 2.2544423716859514

Epoch: 5| Step: 4
Training loss: 1.09062740904971
Validation loss: 2.279651294615214

Epoch: 5| Step: 5
Training loss: 1.105311136501033
Validation loss: 2.320574782108361

Epoch: 5| Step: 6
Training loss: 1.1483157346361512
Validation loss: 2.355790916187617

Epoch: 5| Step: 7
Training loss: 0.9572331118325574
Validation loss: 2.37724234936433

Epoch: 5| Step: 8
Training loss: 1.0776737761596806
Validation loss: 2.366322871236388

Epoch: 5| Step: 9
Training loss: 1.0453453275489542
Validation loss: 2.191014412152386

Epoch: 5| Step: 10
Training loss: 1.043283822120877
Validation loss: 2.3122234251149796

Epoch: 655| Step: 0
Training loss: 0.979015869676358
Validation loss: 2.343813682429318

Epoch: 5| Step: 1
Training loss: 1.165859908500232
Validation loss: 2.3605345563354714

Epoch: 5| Step: 2
Training loss: 1.102960173312377
Validation loss: 2.2880188720457477

Epoch: 5| Step: 3
Training loss: 1.1108688183034403
Validation loss: 2.268162547811686

Epoch: 5| Step: 4
Training loss: 1.2119743092429616
Validation loss: 2.344952784542498

Epoch: 5| Step: 5
Training loss: 0.8303817014387908
Validation loss: 2.3334313941894282

Epoch: 5| Step: 6
Training loss: 1.3572628229940444
Validation loss: 2.3427093525408766

Epoch: 5| Step: 7
Training loss: 0.8321288503793
Validation loss: 2.2686934284156313

Epoch: 5| Step: 8
Training loss: 1.336867917520489
Validation loss: 2.272437368400517

Epoch: 5| Step: 9
Training loss: 1.2898800193821305
Validation loss: 2.375168001572399

Epoch: 5| Step: 10
Training loss: 2.1435955069789365
Validation loss: 2.319489786033488

Epoch: 656| Step: 0
Training loss: 0.8402866349046845
Validation loss: 2.259022442974597

Epoch: 5| Step: 1
Training loss: 0.9357771301433622
Validation loss: 2.327170190049423

Epoch: 5| Step: 2
Training loss: 0.999046168809848
Validation loss: 2.3347775879526504

Epoch: 5| Step: 3
Training loss: 2.0961440334480743
Validation loss: 2.224102409737001

Epoch: 5| Step: 4
Training loss: 1.423526684911895
Validation loss: 2.3805055518657405

Epoch: 5| Step: 5
Training loss: 1.102156674998013
Validation loss: 2.357105641210427

Epoch: 5| Step: 6
Training loss: 1.1514734634906303
Validation loss: 2.290044271409536

Epoch: 5| Step: 7
Training loss: 1.1707222418613248
Validation loss: 2.3400377764937965

Epoch: 5| Step: 8
Training loss: 0.937724849439931
Validation loss: 2.2421388475398323

Epoch: 5| Step: 9
Training loss: 0.9038161777732521
Validation loss: 2.3087445406558813

Epoch: 5| Step: 10
Training loss: 1.1899593384792133
Validation loss: 2.365773479932051

Epoch: 657| Step: 0
Training loss: 1.4250655376689212
Validation loss: 2.3054217115088567

Epoch: 5| Step: 1
Training loss: 1.255383248494736
Validation loss: 2.3486726088366425

Epoch: 5| Step: 2
Training loss: 2.053267071364882
Validation loss: 2.301173336020728

Epoch: 5| Step: 3
Training loss: 0.9643463520633152
Validation loss: 2.348706422203625

Epoch: 5| Step: 4
Training loss: 0.7847864978951886
Validation loss: 2.3093977248424613

Epoch: 5| Step: 5
Training loss: 1.0468370800836964
Validation loss: 2.263525089600203

Epoch: 5| Step: 6
Training loss: 1.0806252058038908
Validation loss: 2.233481255595942

Epoch: 5| Step: 7
Training loss: 1.1516076792080336
Validation loss: 2.2632499718630297

Epoch: 5| Step: 8
Training loss: 0.8091608905749771
Validation loss: 2.227397714987668

Epoch: 5| Step: 9
Training loss: 0.7987520512776907
Validation loss: 2.2706528255373737

Epoch: 5| Step: 10
Training loss: 1.3528358767281392
Validation loss: 2.3841528501189595

Epoch: 658| Step: 0
Training loss: 1.5701232340611198
Validation loss: 2.2630406702197123

Epoch: 5| Step: 1
Training loss: 1.1318326197946684
Validation loss: 2.350347374293739

Epoch: 5| Step: 2
Training loss: 1.2430064542699488
Validation loss: 2.2857752413631385

Epoch: 5| Step: 3
Training loss: 0.7339564815010259
Validation loss: 2.234250924379806

Epoch: 5| Step: 4
Training loss: 1.2266833008972093
Validation loss: 2.294097545959479

Epoch: 5| Step: 5
Training loss: 0.9352907853644026
Validation loss: 2.257111366815705

Epoch: 5| Step: 6
Training loss: 1.9148797606525998
Validation loss: 2.2914572350645925

Epoch: 5| Step: 7
Training loss: 1.546303460469827
Validation loss: 2.3044951939706464

Epoch: 5| Step: 8
Training loss: 1.0349259030268105
Validation loss: 2.2938701637393293

Epoch: 5| Step: 9
Training loss: 1.0233178687609792
Validation loss: 2.2318233781940795

Epoch: 5| Step: 10
Training loss: 0.5580889147875783
Validation loss: 2.330437520851946

Epoch: 659| Step: 0
Training loss: 1.2803809312144723
Validation loss: 2.266841610714804

Epoch: 5| Step: 1
Training loss: 1.1892389314467995
Validation loss: 2.297157804261784

Epoch: 5| Step: 2
Training loss: 1.1879133709652525
Validation loss: 2.3392856906230595

Epoch: 5| Step: 3
Training loss: 0.9437524833393898
Validation loss: 2.274782228577552

Epoch: 5| Step: 4
Training loss: 1.1911974114161252
Validation loss: 2.254813653212938

Epoch: 5| Step: 5
Training loss: 0.9909487222440864
Validation loss: 2.1541486091909756

Epoch: 5| Step: 6
Training loss: 0.9772542410890485
Validation loss: 2.2684668918428588

Epoch: 5| Step: 7
Training loss: 1.0030245935690012
Validation loss: 2.3405844034750194

Epoch: 5| Step: 8
Training loss: 1.971676362154359
Validation loss: 2.305003189315335

Epoch: 5| Step: 9
Training loss: 1.0410072655547924
Validation loss: 2.2828716044164645

Epoch: 5| Step: 10
Training loss: 1.211082449820811
Validation loss: 2.3192322869188717

Epoch: 660| Step: 0
Training loss: 0.8947903786688088
Validation loss: 2.2825529016390878

Epoch: 5| Step: 1
Training loss: 1.4831220458491983
Validation loss: 2.2753124364637944

Epoch: 5| Step: 2
Training loss: 1.9304192889062846
Validation loss: 2.335693614428155

Epoch: 5| Step: 3
Training loss: 1.2095318911804147
Validation loss: 2.3593709557600535

Epoch: 5| Step: 4
Training loss: 0.947856223446485
Validation loss: 2.2633640548204035

Epoch: 5| Step: 5
Training loss: 1.2075058087511317
Validation loss: 2.2910970798521353

Epoch: 5| Step: 6
Training loss: 1.1896091102083226
Validation loss: 2.2320713266844865

Epoch: 5| Step: 7
Training loss: 1.2314644796163976
Validation loss: 2.3000426915323198

Epoch: 5| Step: 8
Training loss: 0.9610883392791931
Validation loss: 2.3799830515192464

Epoch: 5| Step: 9
Training loss: 0.8195778963470737
Validation loss: 2.3225759680078784

Epoch: 5| Step: 10
Training loss: 1.0048646619397597
Validation loss: 2.27643965269614

Epoch: 661| Step: 0
Training loss: 0.9491423901899382
Validation loss: 2.31317360337211

Epoch: 5| Step: 1
Training loss: 0.8145249149874514
Validation loss: 2.276184669628359

Epoch: 5| Step: 2
Training loss: 0.7957586809332586
Validation loss: 2.294234538832104

Epoch: 5| Step: 3
Training loss: 2.0891872052082268
Validation loss: 2.3465637861466835

Epoch: 5| Step: 4
Training loss: 0.8519672516810795
Validation loss: 2.2758395757004664

Epoch: 5| Step: 5
Training loss: 1.2381092036249097
Validation loss: 2.2327687652646344

Epoch: 5| Step: 6
Training loss: 1.2599249687258554
Validation loss: 2.3422500349928534

Epoch: 5| Step: 7
Training loss: 1.2200413733642979
Validation loss: 2.2758259838020707

Epoch: 5| Step: 8
Training loss: 0.7338738862297067
Validation loss: 2.2950831641231813

Epoch: 5| Step: 9
Training loss: 1.2180547932199906
Validation loss: 2.317873095114847

Epoch: 5| Step: 10
Training loss: 1.0098365744008684
Validation loss: 2.2596108581613503

Epoch: 662| Step: 0
Training loss: 1.122372207333937
Validation loss: 2.2262955484510054

Epoch: 5| Step: 1
Training loss: 0.951404550907637
Validation loss: 2.227515372563273

Epoch: 5| Step: 2
Training loss: 1.2297588904474908
Validation loss: 2.268504543185591

Epoch: 5| Step: 3
Training loss: 1.9438578977413261
Validation loss: 2.2718209358811774

Epoch: 5| Step: 4
Training loss: 1.2918353227004449
Validation loss: 2.2872609370012404

Epoch: 5| Step: 5
Training loss: 1.270675331466115
Validation loss: 2.237593594310663

Epoch: 5| Step: 6
Training loss: 1.3379494313034024
Validation loss: 2.325930436282209

Epoch: 5| Step: 7
Training loss: 0.9884145895527642
Validation loss: 2.2670366098289914

Epoch: 5| Step: 8
Training loss: 0.7040570756929316
Validation loss: 2.4258752078471644

Epoch: 5| Step: 9
Training loss: 0.8543862936617119
Validation loss: 2.323061112817945

Epoch: 5| Step: 10
Training loss: 1.1404139702379106
Validation loss: 2.2695717623968945

Epoch: 663| Step: 0
Training loss: 0.8732985575379358
Validation loss: 2.240425912527648

Epoch: 5| Step: 1
Training loss: 0.979361619547552
Validation loss: 2.218256636562216

Epoch: 5| Step: 2
Training loss: 1.042971721744947
Validation loss: 2.1894302372090464

Epoch: 5| Step: 3
Training loss: 0.947217110246852
Validation loss: 2.2057857872031725

Epoch: 5| Step: 4
Training loss: 1.0029233878438348
Validation loss: 2.4198299658895146

Epoch: 5| Step: 5
Training loss: 2.0194247603240543
Validation loss: 2.2541576299413624

Epoch: 5| Step: 6
Training loss: 1.4782260626343953
Validation loss: 2.2466526437934426

Epoch: 5| Step: 7
Training loss: 1.2213510975531412
Validation loss: 2.306656944996064

Epoch: 5| Step: 8
Training loss: 0.7682709030624556
Validation loss: 2.3641411745250434

Epoch: 5| Step: 9
Training loss: 1.05316747698597
Validation loss: 2.286820166771777

Epoch: 5| Step: 10
Training loss: 0.909738960710697
Validation loss: 2.23127226873136

Epoch: 664| Step: 0
Training loss: 0.9416319707088092
Validation loss: 2.3012528377276906

Epoch: 5| Step: 1
Training loss: 1.5120332770192588
Validation loss: 2.27295488809073

Epoch: 5| Step: 2
Training loss: 0.8788627783303037
Validation loss: 2.272592540119221

Epoch: 5| Step: 3
Training loss: 1.8822160464621729
Validation loss: 2.336122065505809

Epoch: 5| Step: 4
Training loss: 1.1823894555518581
Validation loss: 2.3607365553817714

Epoch: 5| Step: 5
Training loss: 1.334258022139136
Validation loss: 2.377402125454059

Epoch: 5| Step: 6
Training loss: 1.0938485237433508
Validation loss: 2.268010035929992

Epoch: 5| Step: 7
Training loss: 0.7975025324048819
Validation loss: 2.3223967273562343

Epoch: 5| Step: 8
Training loss: 1.095312201789674
Validation loss: 2.243309147198268

Epoch: 5| Step: 9
Training loss: 0.9853929977854184
Validation loss: 2.357357942483465

Epoch: 5| Step: 10
Training loss: 1.2288702860697083
Validation loss: 2.259468841271887

Epoch: 665| Step: 0
Training loss: 0.8348370019496134
Validation loss: 2.290791480525122

Epoch: 5| Step: 1
Training loss: 2.272670760752596
Validation loss: 2.3658114833324357

Epoch: 5| Step: 2
Training loss: 0.8610912178845417
Validation loss: 2.3568346396437283

Epoch: 5| Step: 3
Training loss: 1.1299426855051322
Validation loss: 2.324526200813736

Epoch: 5| Step: 4
Training loss: 0.765762589216972
Validation loss: 2.3619805883307508

Epoch: 5| Step: 5
Training loss: 1.0307043539372576
Validation loss: 2.388756501361911

Epoch: 5| Step: 6
Training loss: 0.9846219252649379
Validation loss: 2.367987720422188

Epoch: 5| Step: 7
Training loss: 1.0843924089512922
Validation loss: 2.3128230449346345

Epoch: 5| Step: 8
Training loss: 1.3137011708223802
Validation loss: 2.3723642460987358

Epoch: 5| Step: 9
Training loss: 1.1192993797092632
Validation loss: 2.2701878401222433

Epoch: 5| Step: 10
Training loss: 0.7671270622485523
Validation loss: 2.373219694428469

Epoch: 666| Step: 0
Training loss: 1.0786348878657255
Validation loss: 2.385600954008679

Epoch: 5| Step: 1
Training loss: 1.2660673804740132
Validation loss: 2.314271516062427

Epoch: 5| Step: 2
Training loss: 1.234061672184334
Validation loss: 2.309256523110828

Epoch: 5| Step: 3
Training loss: 1.264237102054267
Validation loss: 2.3027533411484553

Epoch: 5| Step: 4
Training loss: 0.959127163016919
Validation loss: 2.3042250689164416

Epoch: 5| Step: 5
Training loss: 0.8741560680836648
Validation loss: 2.3500949874458508

Epoch: 5| Step: 6
Training loss: 2.074754089123449
Validation loss: 2.3686072197612797

Epoch: 5| Step: 7
Training loss: 0.7033245651171636
Validation loss: 2.3416945218633054

Epoch: 5| Step: 8
Training loss: 1.4088314522294765
Validation loss: 2.2968661824544676

Epoch: 5| Step: 9
Training loss: 0.6556283867805798
Validation loss: 2.299202670499807

Epoch: 5| Step: 10
Training loss: 1.0141250097349306
Validation loss: 2.323753952825012

Epoch: 667| Step: 0
Training loss: 0.9011559202636302
Validation loss: 2.2993412791503243

Epoch: 5| Step: 1
Training loss: 0.8976709827777815
Validation loss: 2.2318962960666426

Epoch: 5| Step: 2
Training loss: 1.157997717823817
Validation loss: 2.2884874101291532

Epoch: 5| Step: 3
Training loss: 1.1668445190469654
Validation loss: 2.3234426053017967

Epoch: 5| Step: 4
Training loss: 0.841063744443642
Validation loss: 2.2705085328685697

Epoch: 5| Step: 5
Training loss: 1.14563034455946
Validation loss: 2.223387214873127

Epoch: 5| Step: 6
Training loss: 1.9791749117495472
Validation loss: 2.2250745284975624

Epoch: 5| Step: 7
Training loss: 1.1082026775091625
Validation loss: 2.30389335552855

Epoch: 5| Step: 8
Training loss: 0.9432345163554174
Validation loss: 2.208786460729249

Epoch: 5| Step: 9
Training loss: 1.0935373372007802
Validation loss: 2.2614331378301156

Epoch: 5| Step: 10
Training loss: 1.2545141725070292
Validation loss: 2.2335791271511116

Epoch: 668| Step: 0
Training loss: 1.321179077352576
Validation loss: 2.2145392211500456

Epoch: 5| Step: 1
Training loss: 0.9128536806151778
Validation loss: 2.3458627422435097

Epoch: 5| Step: 2
Training loss: 0.9523077728761028
Validation loss: 2.350805821845482

Epoch: 5| Step: 3
Training loss: 0.5248110385704976
Validation loss: 2.3665743073925016

Epoch: 5| Step: 4
Training loss: 0.8105224238005325
Validation loss: 2.2302197198325717

Epoch: 5| Step: 5
Training loss: 1.119518169744603
Validation loss: 2.314097903647202

Epoch: 5| Step: 6
Training loss: 1.1509483552742426
Validation loss: 2.2983397606503524

Epoch: 5| Step: 7
Training loss: 1.4084192287427106
Validation loss: 2.3342996056352776

Epoch: 5| Step: 8
Training loss: 1.3599172804022837
Validation loss: 2.3312308365466565

Epoch: 5| Step: 9
Training loss: 2.057493896846132
Validation loss: 2.265530357321829

Epoch: 5| Step: 10
Training loss: 0.7640725570048036
Validation loss: 2.302301340764009

Epoch: 669| Step: 0
Training loss: 1.0336588844080992
Validation loss: 2.3217410222927612

Epoch: 5| Step: 1
Training loss: 1.2793155115531845
Validation loss: 2.3433854123735576

Epoch: 5| Step: 2
Training loss: 1.923262118812223
Validation loss: 2.281068357213946

Epoch: 5| Step: 3
Training loss: 0.9235270939205094
Validation loss: 2.3306642779164415

Epoch: 5| Step: 4
Training loss: 1.1182082521460577
Validation loss: 2.2141355602122967

Epoch: 5| Step: 5
Training loss: 1.0042914456814602
Validation loss: 2.4025449975150193

Epoch: 5| Step: 6
Training loss: 1.0244688704877816
Validation loss: 2.2341036945587907

Epoch: 5| Step: 7
Training loss: 1.17824491502752
Validation loss: 2.322033806015923

Epoch: 5| Step: 8
Training loss: 1.1943969710967641
Validation loss: 2.386181675149862

Epoch: 5| Step: 9
Training loss: 0.9841829142789185
Validation loss: 2.317394580922414

Epoch: 5| Step: 10
Training loss: 0.9416441557452552
Validation loss: 2.2783777239647396

Epoch: 670| Step: 0
Training loss: 1.4666361104787726
Validation loss: 2.2785299640969128

Epoch: 5| Step: 1
Training loss: 1.1304648968064785
Validation loss: 2.323153582527843

Epoch: 5| Step: 2
Training loss: 1.2112983904168806
Validation loss: 2.30277572046834

Epoch: 5| Step: 3
Training loss: 1.1350957026024138
Validation loss: 2.275523504195365

Epoch: 5| Step: 4
Training loss: 0.938079464167527
Validation loss: 2.218610667606017

Epoch: 5| Step: 5
Training loss: 1.1199683412266779
Validation loss: 2.2517384754098213

Epoch: 5| Step: 6
Training loss: 1.1763084471691385
Validation loss: 2.308079007548983

Epoch: 5| Step: 7
Training loss: 1.8995025535700885
Validation loss: 2.369014904142852

Epoch: 5| Step: 8
Training loss: 0.9779622841429444
Validation loss: 2.2421053373674034

Epoch: 5| Step: 9
Training loss: 0.9050230072848451
Validation loss: 2.2787166443588003

Epoch: 5| Step: 10
Training loss: 0.8494209869937561
Validation loss: 2.3643933414531326

Epoch: 671| Step: 0
Training loss: 1.0620128973592597
Validation loss: 2.3418082317251496

Epoch: 5| Step: 1
Training loss: 0.9829553327492123
Validation loss: 2.2899177250275438

Epoch: 5| Step: 2
Training loss: 1.0946119998875636
Validation loss: 2.2541571022367433

Epoch: 5| Step: 3
Training loss: 0.9148123510169953
Validation loss: 2.3856969972171056

Epoch: 5| Step: 4
Training loss: 1.2134122110934773
Validation loss: 2.2307796532768873

Epoch: 5| Step: 5
Training loss: 1.1189098286608117
Validation loss: 2.3245634669045563

Epoch: 5| Step: 6
Training loss: 1.3639835417836885
Validation loss: 2.2470969154140916

Epoch: 5| Step: 7
Training loss: 0.9126549341015635
Validation loss: 2.3065108311301823

Epoch: 5| Step: 8
Training loss: 1.0034095930877627
Validation loss: 2.29578482889646

Epoch: 5| Step: 9
Training loss: 0.9250697689550447
Validation loss: 2.3208562106819866

Epoch: 5| Step: 10
Training loss: 2.0700836630974364
Validation loss: 2.3155061106259422

Epoch: 672| Step: 0
Training loss: 1.9718912888714106
Validation loss: 2.2099791262549444

Epoch: 5| Step: 1
Training loss: 1.057055774299906
Validation loss: 2.331822163803705

Epoch: 5| Step: 2
Training loss: 1.3312217512402045
Validation loss: 2.2863977905288895

Epoch: 5| Step: 3
Training loss: 1.2250320702850717
Validation loss: 2.3216512234991185

Epoch: 5| Step: 4
Training loss: 0.9496110960843971
Validation loss: 2.343967908348102

Epoch: 5| Step: 5
Training loss: 1.0667340120771802
Validation loss: 2.3054091013368567

Epoch: 5| Step: 6
Training loss: 1.2060815229017268
Validation loss: 2.24353306197153

Epoch: 5| Step: 7
Training loss: 0.7913430748867226
Validation loss: 2.4062207841744256

Epoch: 5| Step: 8
Training loss: 0.7647067811419094
Validation loss: 2.2022829616101256

Epoch: 5| Step: 9
Training loss: 0.8943214003778324
Validation loss: 2.3158016287649317

Epoch: 5| Step: 10
Training loss: 0.8797232327564012
Validation loss: 2.3614360692676457

Epoch: 673| Step: 0
Training loss: 0.9721592625410637
Validation loss: 2.2973277756480304

Epoch: 5| Step: 1
Training loss: 1.2087324678082514
Validation loss: 2.321445817397644

Epoch: 5| Step: 2
Training loss: 1.069880934534685
Validation loss: 2.227786238104843

Epoch: 5| Step: 3
Training loss: 1.940608453603285
Validation loss: 2.356898370987076

Epoch: 5| Step: 4
Training loss: 1.2893224280730187
Validation loss: 2.287023764001113

Epoch: 5| Step: 5
Training loss: 0.9743369109592362
Validation loss: 2.26439284332999

Epoch: 5| Step: 6
Training loss: 1.0244341358294582
Validation loss: 2.2676591510249526

Epoch: 5| Step: 7
Training loss: 1.153549339558732
Validation loss: 2.3419835117535523

Epoch: 5| Step: 8
Training loss: 1.0497969658146253
Validation loss: 2.378242953445453

Epoch: 5| Step: 9
Training loss: 1.1410195700248473
Validation loss: 2.2774890977174347

Epoch: 5| Step: 10
Training loss: 1.0530370160486189
Validation loss: 2.3883204780348684

Epoch: 674| Step: 0
Training loss: 0.9735250614273115
Validation loss: 2.3651640775488554

Epoch: 5| Step: 1
Training loss: 1.062696438750035
Validation loss: 2.252893462848802

Epoch: 5| Step: 2
Training loss: 1.3589418093733143
Validation loss: 2.432176680043929

Epoch: 5| Step: 3
Training loss: 0.8479160315083992
Validation loss: 2.2794375252278423

Epoch: 5| Step: 4
Training loss: 1.919893375158034
Validation loss: 2.384568638962869

Epoch: 5| Step: 5
Training loss: 1.0457241507957513
Validation loss: 2.3704232621106356

Epoch: 5| Step: 6
Training loss: 0.681609013652415
Validation loss: 2.234420967504074

Epoch: 5| Step: 7
Training loss: 0.9671494582772593
Validation loss: 2.2745455109744763

Epoch: 5| Step: 8
Training loss: 1.2444469128784796
Validation loss: 2.3115235023805774

Epoch: 5| Step: 9
Training loss: 1.1823759455057516
Validation loss: 2.3372505940225294

Epoch: 5| Step: 10
Training loss: 1.1679724243514529
Validation loss: 2.2498012754626955

Epoch: 675| Step: 0
Training loss: 1.0264839664884917
Validation loss: 2.32778210402114

Epoch: 5| Step: 1
Training loss: 1.284168176635673
Validation loss: 2.342026406668599

Epoch: 5| Step: 2
Training loss: 1.0160212404065854
Validation loss: 2.299502670514878

Epoch: 5| Step: 3
Training loss: 0.8972589142963197
Validation loss: 2.166199887268389

Epoch: 5| Step: 4
Training loss: 1.129078149082622
Validation loss: 2.3045222074879015

Epoch: 5| Step: 5
Training loss: 1.1066934117183918
Validation loss: 2.3186672533693766

Epoch: 5| Step: 6
Training loss: 0.9280760125997851
Validation loss: 2.3524008453599516

Epoch: 5| Step: 7
Training loss: 0.9745534448877581
Validation loss: 2.2613036293153304

Epoch: 5| Step: 8
Training loss: 1.872730471047703
Validation loss: 2.215026221754722

Epoch: 5| Step: 9
Training loss: 1.2977396369245475
Validation loss: 2.2264499220626366

Epoch: 5| Step: 10
Training loss: 1.0749691648274824
Validation loss: 2.3594426166657443

Epoch: 676| Step: 0
Training loss: 1.1903560825340072
Validation loss: 2.3637766280321078

Epoch: 5| Step: 1
Training loss: 0.9841019387941554
Validation loss: 2.253004945610983

Epoch: 5| Step: 2
Training loss: 1.08436855347226
Validation loss: 2.2826322704746067

Epoch: 5| Step: 3
Training loss: 1.0720815031468682
Validation loss: 2.222284014758796

Epoch: 5| Step: 4
Training loss: 1.1624073319775563
Validation loss: 2.2207620485039365

Epoch: 5| Step: 5
Training loss: 0.8663919597303734
Validation loss: 2.3299113295416456

Epoch: 5| Step: 6
Training loss: 0.8298099937461454
Validation loss: 2.2368613224752703

Epoch: 5| Step: 7
Training loss: 1.9463185233007667
Validation loss: 2.2861715622754826

Epoch: 5| Step: 8
Training loss: 0.7705785914645398
Validation loss: 2.2236680911578404

Epoch: 5| Step: 9
Training loss: 1.1419320129960882
Validation loss: 2.3180597204615396

Epoch: 5| Step: 10
Training loss: 0.9794419219639142
Validation loss: 2.2814862978343013

Epoch: 677| Step: 0
Training loss: 1.218728285375965
Validation loss: 2.3590229176200874

Epoch: 5| Step: 1
Training loss: 1.0277645859143782
Validation loss: 2.2964794104844404

Epoch: 5| Step: 2
Training loss: 1.1747116851143629
Validation loss: 2.30610269235629

Epoch: 5| Step: 3
Training loss: 1.0644814583743478
Validation loss: 2.2661367322901653

Epoch: 5| Step: 4
Training loss: 1.1870631368054225
Validation loss: 2.2460133613514293

Epoch: 5| Step: 5
Training loss: 0.9712430193243938
Validation loss: 2.1624535173348205

Epoch: 5| Step: 6
Training loss: 1.0469837416923158
Validation loss: 2.3203949460467403

Epoch: 5| Step: 7
Training loss: 0.8950010173941003
Validation loss: 2.2365702091325987

Epoch: 5| Step: 8
Training loss: 1.2018379163649833
Validation loss: 2.3342384900614768

Epoch: 5| Step: 9
Training loss: 1.4348982610756977
Validation loss: 2.2431903534549855

Epoch: 5| Step: 10
Training loss: 2.0959169931064032
Validation loss: 2.2812989741412215

Epoch: 678| Step: 0
Training loss: 1.0898646964517937
Validation loss: 2.3052326528866507

Epoch: 5| Step: 1
Training loss: 0.8693396522581446
Validation loss: 2.228222676913548

Epoch: 5| Step: 2
Training loss: 0.8650615166415379
Validation loss: 2.25406926044168

Epoch: 5| Step: 3
Training loss: 0.78025105507537
Validation loss: 2.282396526532558

Epoch: 5| Step: 4
Training loss: 1.0416471415915058
Validation loss: 2.3496351508224924

Epoch: 5| Step: 5
Training loss: 1.3329126568601077
Validation loss: 2.266418936873919

Epoch: 5| Step: 6
Training loss: 0.9602833513974721
Validation loss: 2.2719099814034016

Epoch: 5| Step: 7
Training loss: 0.999806087289476
Validation loss: 2.3020898138365324

Epoch: 5| Step: 8
Training loss: 1.0806076655588854
Validation loss: 2.2379479399455113

Epoch: 5| Step: 9
Training loss: 0.9909367525067212
Validation loss: 2.334171793487167

Epoch: 5| Step: 10
Training loss: 2.143425884156955
Validation loss: 2.1977959021212805

Epoch: 679| Step: 0
Training loss: 0.9962812957730158
Validation loss: 2.2632450728205527

Epoch: 5| Step: 1
Training loss: 2.014028345592327
Validation loss: 2.2367513812513664

Epoch: 5| Step: 2
Training loss: 0.9802544044156349
Validation loss: 2.38134868812328

Epoch: 5| Step: 3
Training loss: 1.0371616731090587
Validation loss: 2.2485674977452614

Epoch: 5| Step: 4
Training loss: 1.0676103438405464
Validation loss: 2.2798017247164464

Epoch: 5| Step: 5
Training loss: 0.9583145568224507
Validation loss: 2.299280552831738

Epoch: 5| Step: 6
Training loss: 1.2307581001246097
Validation loss: 2.244444116396565

Epoch: 5| Step: 7
Training loss: 1.2635689978016655
Validation loss: 2.268455123303894

Epoch: 5| Step: 8
Training loss: 0.9169823724223454
Validation loss: 2.289723823613825

Epoch: 5| Step: 9
Training loss: 1.0368641134084917
Validation loss: 2.2320881310242475

Epoch: 5| Step: 10
Training loss: 1.1305285350331367
Validation loss: 2.288458387491481

Epoch: 680| Step: 0
Training loss: 0.9272765626165048
Validation loss: 2.3667386788070375

Epoch: 5| Step: 1
Training loss: 1.171317718241836
Validation loss: 2.3222366966385177

Epoch: 5| Step: 2
Training loss: 1.0536766011297638
Validation loss: 2.232263986116555

Epoch: 5| Step: 3
Training loss: 1.9923507324364451
Validation loss: 2.3109164560053967

Epoch: 5| Step: 4
Training loss: 1.055821974215766
Validation loss: 2.217816762174595

Epoch: 5| Step: 5
Training loss: 1.1806929894777543
Validation loss: 2.2274115667209733

Epoch: 5| Step: 6
Training loss: 1.258496305930862
Validation loss: 2.2310606571925544

Epoch: 5| Step: 7
Training loss: 1.0052260099184365
Validation loss: 2.3512315381971005

Epoch: 5| Step: 8
Training loss: 0.9451327192366904
Validation loss: 2.273262023637652

Epoch: 5| Step: 9
Training loss: 1.0783711028129788
Validation loss: 2.331614284815231

Epoch: 5| Step: 10
Training loss: 0.8227475310398406
Validation loss: 2.3031944136767906

Epoch: 681| Step: 0
Training loss: 2.0302696796802646
Validation loss: 2.2260846629670823

Epoch: 5| Step: 1
Training loss: 0.9488646863392693
Validation loss: 2.246402649399423

Epoch: 5| Step: 2
Training loss: 0.9882245556397518
Validation loss: 2.2669402325069368

Epoch: 5| Step: 3
Training loss: 0.9203016788902169
Validation loss: 2.268652615566915

Epoch: 5| Step: 4
Training loss: 1.1624225098409302
Validation loss: 2.294749284379632

Epoch: 5| Step: 5
Training loss: 1.1401697582873407
Validation loss: 2.3042284962244817

Epoch: 5| Step: 6
Training loss: 0.9390230522819873
Validation loss: 2.249485273744935

Epoch: 5| Step: 7
Training loss: 0.9844695454561474
Validation loss: 2.362113047888072

Epoch: 5| Step: 8
Training loss: 1.1956139477360048
Validation loss: 2.3595194504461228

Epoch: 5| Step: 9
Training loss: 1.101915992671027
Validation loss: 2.337478017777675

Epoch: 5| Step: 10
Training loss: 1.0815135392087993
Validation loss: 2.31865385724295

Epoch: 682| Step: 0
Training loss: 0.972622851675436
Validation loss: 2.3477405923812946

Epoch: 5| Step: 1
Training loss: 0.9837878156225812
Validation loss: 2.3362020167944997

Epoch: 5| Step: 2
Training loss: 1.2630475490405697
Validation loss: 2.345913977061833

Epoch: 5| Step: 3
Training loss: 2.0345336195932893
Validation loss: 2.2456506886545586

Epoch: 5| Step: 4
Training loss: 0.9384355962824813
Validation loss: 2.2979403155631877

Epoch: 5| Step: 5
Training loss: 0.9505689147215086
Validation loss: 2.239118942186975

Epoch: 5| Step: 6
Training loss: 0.8372688387223309
Validation loss: 2.347076636575176

Epoch: 5| Step: 7
Training loss: 1.2852783145156383
Validation loss: 2.2254712634287657

Epoch: 5| Step: 8
Training loss: 1.0202683747405221
Validation loss: 2.3308258346407724

Epoch: 5| Step: 9
Training loss: 1.347925220130223
Validation loss: 2.302020669586415

Epoch: 5| Step: 10
Training loss: 1.0112242208054811
Validation loss: 2.2327904360794966

Epoch: 683| Step: 0
Training loss: 1.0452023709021743
Validation loss: 2.3523157426210974

Epoch: 5| Step: 1
Training loss: 1.096247899696139
Validation loss: 2.2670700245778037

Epoch: 5| Step: 2
Training loss: 0.6479614762596368
Validation loss: 2.3334261184327554

Epoch: 5| Step: 3
Training loss: 1.0539516000908995
Validation loss: 2.3125206456680405

Epoch: 5| Step: 4
Training loss: 1.2833984319268614
Validation loss: 2.3625362910630043

Epoch: 5| Step: 5
Training loss: 0.8653904621220196
Validation loss: 2.3131010277224733

Epoch: 5| Step: 6
Training loss: 1.0440306097856094
Validation loss: 2.3310699281616536

Epoch: 5| Step: 7
Training loss: 1.1386934935936888
Validation loss: 2.3901226961822104

Epoch: 5| Step: 8
Training loss: 2.0188675459426015
Validation loss: 2.3304205665363527

Epoch: 5| Step: 9
Training loss: 0.6996283583459066
Validation loss: 2.168125749464905

Epoch: 5| Step: 10
Training loss: 1.3005482691247896
Validation loss: 2.1996405526002083

Epoch: 684| Step: 0
Training loss: 1.0243056015330734
Validation loss: 2.3022043852150675

Epoch: 5| Step: 1
Training loss: 1.121320322780751
Validation loss: 2.280980005271299

Epoch: 5| Step: 2
Training loss: 1.2118295644709307
Validation loss: 2.2227299876240028

Epoch: 5| Step: 3
Training loss: 0.8486384664858582
Validation loss: 2.2360918909635066

Epoch: 5| Step: 4
Training loss: 0.8853072977771603
Validation loss: 2.3659736095432318

Epoch: 5| Step: 5
Training loss: 1.8578666531536294
Validation loss: 2.2239535740584837

Epoch: 5| Step: 6
Training loss: 1.1711674906880343
Validation loss: 2.239368717091523

Epoch: 5| Step: 7
Training loss: 1.1489020206119878
Validation loss: 2.33522784616615

Epoch: 5| Step: 8
Training loss: 1.0735825752939228
Validation loss: 2.2447492204658865

Epoch: 5| Step: 9
Training loss: 0.980890707581262
Validation loss: 2.256422994076028

Epoch: 5| Step: 10
Training loss: 1.2555761893066986
Validation loss: 2.2238977922617758

Epoch: 685| Step: 0
Training loss: 1.0005221195930871
Validation loss: 2.2931131498185957

Epoch: 5| Step: 1
Training loss: 1.8462108418335275
Validation loss: 2.1986694541717644

Epoch: 5| Step: 2
Training loss: 0.9436990825231049
Validation loss: 2.2299050549683264

Epoch: 5| Step: 3
Training loss: 1.0882302649522781
Validation loss: 2.298345878784151

Epoch: 5| Step: 4
Training loss: 0.9603598184096872
Validation loss: 2.30065871679736

Epoch: 5| Step: 5
Training loss: 0.8313450020445597
Validation loss: 2.3071170487939874

Epoch: 5| Step: 6
Training loss: 1.319061679979913
Validation loss: 2.291813687020786

Epoch: 5| Step: 7
Training loss: 1.065699192719692
Validation loss: 2.329733421324436

Epoch: 5| Step: 8
Training loss: 0.9288758333069225
Validation loss: 2.268198058137065

Epoch: 5| Step: 9
Training loss: 0.646727663113762
Validation loss: 2.3499473743485173

Epoch: 5| Step: 10
Training loss: 0.9165457551859234
Validation loss: 2.225430130225364

Epoch: 686| Step: 0
Training loss: 1.042470177056927
Validation loss: 2.2358906071236437

Epoch: 5| Step: 1
Training loss: 1.0292153371404247
Validation loss: 2.2979643554918585

Epoch: 5| Step: 2
Training loss: 0.8295624690846558
Validation loss: 2.2680909866189123

Epoch: 5| Step: 3
Training loss: 1.2423168091077208
Validation loss: 2.230386106249009

Epoch: 5| Step: 4
Training loss: 0.9609502155734229
Validation loss: 2.188832239762636

Epoch: 5| Step: 5
Training loss: 1.1248297032632912
Validation loss: 2.292918361425945

Epoch: 5| Step: 6
Training loss: 0.8697421960220159
Validation loss: 2.2844184025749454

Epoch: 5| Step: 7
Training loss: 0.9363306382089434
Validation loss: 2.2946718264126815

Epoch: 5| Step: 8
Training loss: 1.1605481856835307
Validation loss: 2.2461949382458024

Epoch: 5| Step: 9
Training loss: 1.8266325507261483
Validation loss: 2.261484945507603

Epoch: 5| Step: 10
Training loss: 1.186184304833085
Validation loss: 2.2556411345674916

Epoch: 687| Step: 0
Training loss: 1.0820070670279607
Validation loss: 2.178732738875863

Epoch: 5| Step: 1
Training loss: 1.1951263382497923
Validation loss: 2.2982142589069534

Epoch: 5| Step: 2
Training loss: 0.9844293427983402
Validation loss: 2.1546697421358205

Epoch: 5| Step: 3
Training loss: 0.9897491650752482
Validation loss: 2.2491517310905795

Epoch: 5| Step: 4
Training loss: 0.9294217795814511
Validation loss: 2.2763250211225534

Epoch: 5| Step: 5
Training loss: 0.8279138691788823
Validation loss: 2.269292147743234

Epoch: 5| Step: 6
Training loss: 0.9433514770429932
Validation loss: 2.241312526339964

Epoch: 5| Step: 7
Training loss: 0.9335304781490091
Validation loss: 2.2246808664645323

Epoch: 5| Step: 8
Training loss: 1.1967540849209939
Validation loss: 2.2536035960348677

Epoch: 5| Step: 9
Training loss: 1.0713833095436143
Validation loss: 2.2695845547433877

Epoch: 5| Step: 10
Training loss: 2.0570558308176943
Validation loss: 2.200515214262767

Epoch: 688| Step: 0
Training loss: 1.0736164415848695
Validation loss: 2.233785147399452

Epoch: 5| Step: 1
Training loss: 1.035334388232098
Validation loss: 2.255146399661671

Epoch: 5| Step: 2
Training loss: 1.1989613607828522
Validation loss: 2.2442885799837797

Epoch: 5| Step: 3
Training loss: 0.4815135698505793
Validation loss: 2.305784606374568

Epoch: 5| Step: 4
Training loss: 1.8656731374079845
Validation loss: 2.314732713982101

Epoch: 5| Step: 5
Training loss: 1.3126272866425606
Validation loss: 2.213388011215051

Epoch: 5| Step: 6
Training loss: 1.1293103507896196
Validation loss: 2.232335767598937

Epoch: 5| Step: 7
Training loss: 0.8346526351953839
Validation loss: 2.2287048671904306

Epoch: 5| Step: 8
Training loss: 0.5406353988088372
Validation loss: 2.1933595316217724

Epoch: 5| Step: 9
Training loss: 1.1838376137073687
Validation loss: 2.3506803031430556

Epoch: 5| Step: 10
Training loss: 1.0464686843589994
Validation loss: 2.333897533046293

Epoch: 689| Step: 0
Training loss: 1.091410887700838
Validation loss: 2.3071002247916743

Epoch: 5| Step: 1
Training loss: 1.8905166721047724
Validation loss: 2.3003824261162906

Epoch: 5| Step: 2
Training loss: 1.052387244013198
Validation loss: 2.2049626994568894

Epoch: 5| Step: 3
Training loss: 0.8307563434488363
Validation loss: 2.254652022953883

Epoch: 5| Step: 4
Training loss: 1.0102463542643059
Validation loss: 2.3542509509466045

Epoch: 5| Step: 5
Training loss: 1.2412502183558645
Validation loss: 2.2096173536734045

Epoch: 5| Step: 6
Training loss: 1.0580695286567532
Validation loss: 2.265727366792904

Epoch: 5| Step: 7
Training loss: 1.1328307577832286
Validation loss: 2.2392387006686865

Epoch: 5| Step: 8
Training loss: 0.9681706695916059
Validation loss: 2.2821727195229298

Epoch: 5| Step: 9
Training loss: 1.1323352202900492
Validation loss: 2.1308215407234976

Epoch: 5| Step: 10
Training loss: 0.8217598635015122
Validation loss: 2.30442130148921

Epoch: 690| Step: 0
Training loss: 0.8939417933369153
Validation loss: 2.300293471939653

Epoch: 5| Step: 1
Training loss: 1.7899769940309724
Validation loss: 2.231388329542418

Epoch: 5| Step: 2
Training loss: 0.9732283782438618
Validation loss: 2.31669697243371

Epoch: 5| Step: 3
Training loss: 1.205812202818576
Validation loss: 2.32518625504632

Epoch: 5| Step: 4
Training loss: 0.8390802505860347
Validation loss: 2.364816166213644

Epoch: 5| Step: 5
Training loss: 0.8234330178994773
Validation loss: 2.2906119704178476

Epoch: 5| Step: 6
Training loss: 0.9903131637980294
Validation loss: 2.2905470802723884

Epoch: 5| Step: 7
Training loss: 1.2114680450828643
Validation loss: 2.3036785116060474

Epoch: 5| Step: 8
Training loss: 1.0313795181783878
Validation loss: 2.336710304158346

Epoch: 5| Step: 9
Training loss: 1.0348217693691757
Validation loss: 2.3264987300882747

Epoch: 5| Step: 10
Training loss: 1.0624271255633835
Validation loss: 2.2991417732638477

Epoch: 691| Step: 0
Training loss: 1.2886159412355365
Validation loss: 2.268174310239398

Epoch: 5| Step: 1
Training loss: 1.459341881190384
Validation loss: 2.212742564509875

Epoch: 5| Step: 2
Training loss: 0.8802303258793094
Validation loss: 2.2734649738861465

Epoch: 5| Step: 3
Training loss: 0.9511696817423699
Validation loss: 2.2203322192009463

Epoch: 5| Step: 4
Training loss: 0.8781086333029094
Validation loss: 2.2026617534343003

Epoch: 5| Step: 5
Training loss: 1.8231243632841518
Validation loss: 2.335448668249514

Epoch: 5| Step: 6
Training loss: 0.9349389380645352
Validation loss: 2.236354279086436

Epoch: 5| Step: 7
Training loss: 0.8915203680064084
Validation loss: 2.2795617636922927

Epoch: 5| Step: 8
Training loss: 1.0990284118485536
Validation loss: 2.3411869234953313

Epoch: 5| Step: 9
Training loss: 0.8165612324625624
Validation loss: 2.3275471534753556

Epoch: 5| Step: 10
Training loss: 1.0324924960106185
Validation loss: 2.310285611075479

Epoch: 692| Step: 0
Training loss: 0.963495679565546
Validation loss: 2.31375546563394

Epoch: 5| Step: 1
Training loss: 1.2411803475128766
Validation loss: 2.270352108164148

Epoch: 5| Step: 2
Training loss: 1.9823716631764503
Validation loss: 2.2756034722298906

Epoch: 5| Step: 3
Training loss: 0.9980797510275236
Validation loss: 2.2564327405392364

Epoch: 5| Step: 4
Training loss: 0.6568517196987023
Validation loss: 2.3145938806779087

Epoch: 5| Step: 5
Training loss: 1.1339495509967044
Validation loss: 2.2974968283970796

Epoch: 5| Step: 6
Training loss: 0.9983869895038431
Validation loss: 2.3487381235838036

Epoch: 5| Step: 7
Training loss: 1.0751936494154373
Validation loss: 2.2254446577389855

Epoch: 5| Step: 8
Training loss: 0.7082616732383027
Validation loss: 2.389663154273143

Epoch: 5| Step: 9
Training loss: 1.0698846114857063
Validation loss: 2.352295598260952

Epoch: 5| Step: 10
Training loss: 1.2086193414899482
Validation loss: 2.328428528478967

Epoch: 693| Step: 0
Training loss: 0.9374644908538061
Validation loss: 2.1956130529889166

Epoch: 5| Step: 1
Training loss: 0.9386399649832893
Validation loss: 2.2757618205196137

Epoch: 5| Step: 2
Training loss: 1.1832370535317358
Validation loss: 2.206555319611003

Epoch: 5| Step: 3
Training loss: 0.8869591609709466
Validation loss: 2.332890662672449

Epoch: 5| Step: 4
Training loss: 0.9937126272599471
Validation loss: 2.3827809429045907

Epoch: 5| Step: 5
Training loss: 0.9269738864944771
Validation loss: 2.2800695860595

Epoch: 5| Step: 6
Training loss: 0.5674723621814125
Validation loss: 2.2469195605072176

Epoch: 5| Step: 7
Training loss: 0.7893733554801815
Validation loss: 2.2678493399636754

Epoch: 5| Step: 8
Training loss: 1.92538466635471
Validation loss: 2.280247752306786

Epoch: 5| Step: 9
Training loss: 1.0625818445434942
Validation loss: 2.277030980617179

Epoch: 5| Step: 10
Training loss: 1.0950575505988418
Validation loss: 2.230603156506463

Epoch: 694| Step: 0
Training loss: 0.8911301033835989
Validation loss: 2.2835162811275493

Epoch: 5| Step: 1
Training loss: 1.2814977452871883
Validation loss: 2.265885689079499

Epoch: 5| Step: 2
Training loss: 0.7260069004603132
Validation loss: 2.269604607801576

Epoch: 5| Step: 3
Training loss: 1.9250625600185962
Validation loss: 2.226842917066037

Epoch: 5| Step: 4
Training loss: 1.1757408464656616
Validation loss: 2.2905309023580607

Epoch: 5| Step: 5
Training loss: 1.3874078032646022
Validation loss: 2.2782695605619043

Epoch: 5| Step: 6
Training loss: 0.8604029662832632
Validation loss: 2.332778041294345

Epoch: 5| Step: 7
Training loss: 1.0781527529475379
Validation loss: 2.237520754405042

Epoch: 5| Step: 8
Training loss: 0.9731852307113424
Validation loss: 2.2167120295652567

Epoch: 5| Step: 9
Training loss: 0.8248886712414436
Validation loss: 2.2776514040881337

Epoch: 5| Step: 10
Training loss: 0.8186894299765202
Validation loss: 2.143697447335795

Epoch: 695| Step: 0
Training loss: 1.9151181171134948
Validation loss: 2.274609080790013

Epoch: 5| Step: 1
Training loss: 0.9699150278784601
Validation loss: 2.369786659369756

Epoch: 5| Step: 2
Training loss: 0.804115388319132
Validation loss: 2.349313923551449

Epoch: 5| Step: 3
Training loss: 1.2328035999745577
Validation loss: 2.2582602363722666

Epoch: 5| Step: 4
Training loss: 0.9581431877465381
Validation loss: 2.29938577843187

Epoch: 5| Step: 5
Training loss: 0.8147482211622336
Validation loss: 2.3059644328711446

Epoch: 5| Step: 6
Training loss: 0.7139577742894343
Validation loss: 2.292466147421292

Epoch: 5| Step: 7
Training loss: 1.1876020387678934
Validation loss: 2.2315026713966173

Epoch: 5| Step: 8
Training loss: 1.0905957106015702
Validation loss: 2.2811602862657714

Epoch: 5| Step: 9
Training loss: 0.5439056984740553
Validation loss: 2.2841437126505455

Epoch: 5| Step: 10
Training loss: 0.9815739333863197
Validation loss: 2.2099803147046875

Epoch: 696| Step: 0
Training loss: 0.9240996463805918
Validation loss: 2.347821883085762

Epoch: 5| Step: 1
Training loss: 0.8931805937584579
Validation loss: 2.220022849470048

Epoch: 5| Step: 2
Training loss: 0.829177655254247
Validation loss: 2.2403589142463947

Epoch: 5| Step: 3
Training loss: 0.9818457550413966
Validation loss: 2.288209475042169

Epoch: 5| Step: 4
Training loss: 2.057232922709242
Validation loss: 2.278535047425047

Epoch: 5| Step: 5
Training loss: 0.7633706203526824
Validation loss: 2.2670376671579398

Epoch: 5| Step: 6
Training loss: 1.138438493684748
Validation loss: 2.2650162747182416

Epoch: 5| Step: 7
Training loss: 1.0881444884805827
Validation loss: 2.3326078340315837

Epoch: 5| Step: 8
Training loss: 0.9247190280707754
Validation loss: 2.3604353252699752

Epoch: 5| Step: 9
Training loss: 0.8213734985927664
Validation loss: 2.302595060701038

Epoch: 5| Step: 10
Training loss: 1.0789138561646374
Validation loss: 2.288007096228759

Epoch: 697| Step: 0
Training loss: 0.6842210126108974
Validation loss: 2.213434859901463

Epoch: 5| Step: 1
Training loss: 0.892335587485735
Validation loss: 2.2793255897031504

Epoch: 5| Step: 2
Training loss: 0.7737094516636845
Validation loss: 2.3165398397526613

Epoch: 5| Step: 3
Training loss: 0.8031366458746085
Validation loss: 2.328403692694009

Epoch: 5| Step: 4
Training loss: 1.0772491435669251
Validation loss: 2.240336239273306

Epoch: 5| Step: 5
Training loss: 1.0497903796263357
Validation loss: 2.2633453645842043

Epoch: 5| Step: 6
Training loss: 1.1142431554072694
Validation loss: 2.2320122440288768

Epoch: 5| Step: 7
Training loss: 1.101414988495678
Validation loss: 2.2381349963330255

Epoch: 5| Step: 8
Training loss: 1.907344191401079
Validation loss: 2.225640734759853

Epoch: 5| Step: 9
Training loss: 0.9648465608254698
Validation loss: 2.2353198435018378

Epoch: 5| Step: 10
Training loss: 1.3197445974208684
Validation loss: 2.2712193123696567

Epoch: 698| Step: 0
Training loss: 0.9460954497595339
Validation loss: 2.2029147961672537

Epoch: 5| Step: 1
Training loss: 1.1916065485446208
Validation loss: 2.3201028234616965

Epoch: 5| Step: 2
Training loss: 0.9680232736965956
Validation loss: 2.3002243305322834

Epoch: 5| Step: 3
Training loss: 1.0829919069186782
Validation loss: 2.312747791276694

Epoch: 5| Step: 4
Training loss: 1.0054417604323067
Validation loss: 2.3648719442512767

Epoch: 5| Step: 5
Training loss: 1.016891218359718
Validation loss: 2.3224045764613073

Epoch: 5| Step: 6
Training loss: 1.1290159601142709
Validation loss: 2.421494695500595

Epoch: 5| Step: 7
Training loss: 0.9646165402644408
Validation loss: 2.3833243533242876

Epoch: 5| Step: 8
Training loss: 0.7861001333706564
Validation loss: 2.2083959758260905

Epoch: 5| Step: 9
Training loss: 1.892405467626639
Validation loss: 2.28530267359055

Epoch: 5| Step: 10
Training loss: 1.0357146286611505
Validation loss: 2.1991505546082033

Epoch: 699| Step: 0
Training loss: 0.761440911117637
Validation loss: 2.249872147609011

Epoch: 5| Step: 1
Training loss: 0.9039790540437546
Validation loss: 2.289818590389496

Epoch: 5| Step: 2
Training loss: 1.90713349177274
Validation loss: 2.255006005574964

Epoch: 5| Step: 3
Training loss: 0.9593666076293085
Validation loss: 2.278692920860441

Epoch: 5| Step: 4
Training loss: 0.9535987177067334
Validation loss: 2.3183132228927272

Epoch: 5| Step: 5
Training loss: 1.0824423329276112
Validation loss: 2.38248401181751

Epoch: 5| Step: 6
Training loss: 0.9724437987163241
Validation loss: 2.3619537267124313

Epoch: 5| Step: 7
Training loss: 0.8187340217953138
Validation loss: 2.2798647631222155

Epoch: 5| Step: 8
Training loss: 1.0169184737710064
Validation loss: 2.346162847198466

Epoch: 5| Step: 9
Training loss: 0.7581768143347163
Validation loss: 2.3050155431212573

Epoch: 5| Step: 10
Training loss: 1.0868851074310344
Validation loss: 2.2199840507924753

Epoch: 700| Step: 0
Training loss: 1.0039030438679957
Validation loss: 2.1952397519791487

Epoch: 5| Step: 1
Training loss: 1.0580628249619526
Validation loss: 2.340509346881874

Epoch: 5| Step: 2
Training loss: 0.8112510839258132
Validation loss: 2.3105645701290833

Epoch: 5| Step: 3
Training loss: 0.8453543210217053
Validation loss: 2.263454900354394

Epoch: 5| Step: 4
Training loss: 1.0145270648577984
Validation loss: 2.3759691401576437

Epoch: 5| Step: 5
Training loss: 0.7959559133172337
Validation loss: 2.4074457737498633

Epoch: 5| Step: 6
Training loss: 1.8102859918150682
Validation loss: 2.272689404754779

Epoch: 5| Step: 7
Training loss: 1.0370510393823424
Validation loss: 2.225631659186498

Epoch: 5| Step: 8
Training loss: 0.9997593470921308
Validation loss: 2.260571711847111

Epoch: 5| Step: 9
Training loss: 1.0631143252528108
Validation loss: 2.273928662337654

Epoch: 5| Step: 10
Training loss: 0.8463651959605375
Validation loss: 2.203307131538766

Testing loss: 3.0502944234409606
