Epoch: 1| Step: 0
Training loss: 5.612942297144975
Validation loss: 5.317454956159501

Epoch: 6| Step: 1
Training loss: 3.504770842065927
Validation loss: 5.3088052620827515

Epoch: 6| Step: 2
Training loss: 6.348374057971982
Validation loss: 5.305354389939161

Epoch: 6| Step: 3
Training loss: 5.555997669853892
Validation loss: 5.300736059000636

Epoch: 6| Step: 4
Training loss: 5.078418523668375
Validation loss: 5.294178062595305

Epoch: 6| Step: 5
Training loss: 6.630002130706583
Validation loss: 5.290726034588231

Epoch: 6| Step: 6
Training loss: 4.747681503643034
Validation loss: 5.284446266077845

Epoch: 6| Step: 7
Training loss: 5.787242526100682
Validation loss: 5.277759815927427

Epoch: 6| Step: 8
Training loss: 4.977408488422476
Validation loss: 5.27552194785686

Epoch: 6| Step: 9
Training loss: 5.592063436440331
Validation loss: 5.265539085417826

Epoch: 6| Step: 10
Training loss: 5.094348708463893
Validation loss: 5.2629442703554155

Epoch: 6| Step: 11
Training loss: 4.7822826990591745
Validation loss: 5.256082063743236

Epoch: 6| Step: 12
Training loss: 4.973048240392358
Validation loss: 5.250009342386476

Epoch: 6| Step: 13
Training loss: 5.440843628374899
Validation loss: 5.245808533282279

Epoch: 2| Step: 0
Training loss: 5.740689244375477
Validation loss: 5.238729157728073

Epoch: 6| Step: 1
Training loss: 4.041343885818477
Validation loss: 5.234149320803723

Epoch: 6| Step: 2
Training loss: 4.8082831597754385
Validation loss: 5.228686916122989

Epoch: 6| Step: 3
Training loss: 5.249589268194343
Validation loss: 5.225458949648251

Epoch: 6| Step: 4
Training loss: 5.7161332277290775
Validation loss: 5.2187391731356705

Epoch: 6| Step: 5
Training loss: 5.771172725828578
Validation loss: 5.212497816608907

Epoch: 6| Step: 6
Training loss: 5.088671627617154
Validation loss: 5.204987388946168

Epoch: 6| Step: 7
Training loss: 5.022047452689534
Validation loss: 5.198796483157396

Epoch: 6| Step: 8
Training loss: 5.042915988117193
Validation loss: 5.1954092000257655

Epoch: 6| Step: 9
Training loss: 4.993231770119612
Validation loss: 5.190707163552377

Epoch: 6| Step: 10
Training loss: 5.698172815157196
Validation loss: 5.182865013857598

Epoch: 6| Step: 11
Training loss: 5.628720727175593
Validation loss: 5.178073875036286

Epoch: 6| Step: 12
Training loss: 4.783508166442069
Validation loss: 5.172751125183859

Epoch: 6| Step: 13
Training loss: 6.151817623833162
Validation loss: 5.166236749731714

Epoch: 3| Step: 0
Training loss: 4.805241250482831
Validation loss: 5.158083636226318

Epoch: 6| Step: 1
Training loss: 5.2546329945786745
Validation loss: 5.1532756968875235

Epoch: 6| Step: 2
Training loss: 4.70371017110741
Validation loss: 5.147272634155964

Epoch: 6| Step: 3
Training loss: 4.894606459542874
Validation loss: 5.142111194789643

Epoch: 6| Step: 4
Training loss: 5.2986215058315445
Validation loss: 5.135320125604997

Epoch: 6| Step: 5
Training loss: 5.712833867239422
Validation loss: 5.127875567058656

Epoch: 6| Step: 6
Training loss: 4.183358493035231
Validation loss: 5.121366604015745

Epoch: 6| Step: 7
Training loss: 5.10612379686214
Validation loss: 5.116053710620152

Epoch: 6| Step: 8
Training loss: 4.059120063323646
Validation loss: 5.1094991500726925

Epoch: 6| Step: 9
Training loss: 5.3689519877511795
Validation loss: 5.1042975798395815

Epoch: 6| Step: 10
Training loss: 6.702143243773486
Validation loss: 5.095696699421814

Epoch: 6| Step: 11
Training loss: 5.34435817536967
Validation loss: 5.089042208789098

Epoch: 6| Step: 12
Training loss: 5.703514942790693
Validation loss: 5.083937942696066

Epoch: 6| Step: 13
Training loss: 4.559498256719411
Validation loss: 5.077969753268209

Epoch: 4| Step: 0
Training loss: 5.862173159990657
Validation loss: 5.069161757062819

Epoch: 6| Step: 1
Training loss: 4.946557730394638
Validation loss: 5.062665216790125

Epoch: 6| Step: 2
Training loss: 5.715339686059857
Validation loss: 5.055013659501896

Epoch: 6| Step: 3
Training loss: 5.809667409809072
Validation loss: 5.048157195124229

Epoch: 6| Step: 4
Training loss: 4.226010552714036
Validation loss: 5.037857780350781

Epoch: 6| Step: 5
Training loss: 5.226934719088922
Validation loss: 5.034084211958551

Epoch: 6| Step: 6
Training loss: 4.760454017720787
Validation loss: 5.0275540486879375

Epoch: 6| Step: 7
Training loss: 5.5411469447670285
Validation loss: 5.020001449705682

Epoch: 6| Step: 8
Training loss: 3.957155607929905
Validation loss: 5.009092445755058

Epoch: 6| Step: 9
Training loss: 4.375329141497305
Validation loss: 5.003372642317474

Epoch: 6| Step: 10
Training loss: 5.2604875717168555
Validation loss: 4.99380343403974

Epoch: 6| Step: 11
Training loss: 5.316348667659781
Validation loss: 4.989419805704727

Epoch: 6| Step: 12
Training loss: 5.075280528466082
Validation loss: 4.98118808674048

Epoch: 6| Step: 13
Training loss: 4.489928312685154
Validation loss: 4.9751114277350466

Epoch: 5| Step: 0
Training loss: 5.246642719555064
Validation loss: 4.96789689988284

Epoch: 6| Step: 1
Training loss: 5.785843957056754
Validation loss: 4.95768473515797

Epoch: 6| Step: 2
Training loss: 6.028984632646163
Validation loss: 4.950970175142831

Epoch: 6| Step: 3
Training loss: 4.262052835853909
Validation loss: 4.94371292301349

Epoch: 6| Step: 4
Training loss: 5.422097852892621
Validation loss: 4.933816967371961

Epoch: 6| Step: 5
Training loss: 3.6220724188622886
Validation loss: 4.926535854097965

Epoch: 6| Step: 6
Training loss: 5.9957864589418515
Validation loss: 4.919036245561454

Epoch: 6| Step: 7
Training loss: 4.095135403398521
Validation loss: 4.906735276765321

Epoch: 6| Step: 8
Training loss: 4.785519358034512
Validation loss: 4.902972925791461

Epoch: 6| Step: 9
Training loss: 4.229267939715832
Validation loss: 4.891593861511955

Epoch: 6| Step: 10
Training loss: 5.6794759299057604
Validation loss: 4.885850808325321

Epoch: 6| Step: 11
Training loss: 4.481889946651578
Validation loss: 4.8781360229183495

Epoch: 6| Step: 12
Training loss: 4.628747607381698
Validation loss: 4.865030815361556

Epoch: 6| Step: 13
Training loss: 4.5767964072474925
Validation loss: 4.856987730709693

Epoch: 6| Step: 0
Training loss: 4.398086018857801
Validation loss: 4.849685653345603

Epoch: 6| Step: 1
Training loss: 4.741948783182828
Validation loss: 4.84148436296602

Epoch: 6| Step: 2
Training loss: 4.218554682978668
Validation loss: 4.832883560730144

Epoch: 6| Step: 3
Training loss: 5.556423683155247
Validation loss: 4.824236883818792

Epoch: 6| Step: 4
Training loss: 4.790611925001523
Validation loss: 4.8161557368809

Epoch: 6| Step: 5
Training loss: 5.383891713066612
Validation loss: 4.807677462003519

Epoch: 6| Step: 6
Training loss: 4.217516909634939
Validation loss: 4.795724093454244

Epoch: 6| Step: 7
Training loss: 4.101513206549028
Validation loss: 4.789182010031952

Epoch: 6| Step: 8
Training loss: 5.291999666244254
Validation loss: 4.779074081335295

Epoch: 6| Step: 9
Training loss: 5.521920131980336
Validation loss: 4.768055855831919

Epoch: 6| Step: 10
Training loss: 5.286476934491084
Validation loss: 4.758535568921907

Epoch: 6| Step: 11
Training loss: 5.240342476405481
Validation loss: 4.748648534890563

Epoch: 6| Step: 12
Training loss: 3.9498634604503953
Validation loss: 4.737521113074477

Epoch: 6| Step: 13
Training loss: 5.086829978817695
Validation loss: 4.72930032139095

Epoch: 7| Step: 0
Training loss: 4.640374276423505
Validation loss: 4.717489170679133

Epoch: 6| Step: 1
Training loss: 4.633434955022232
Validation loss: 4.709611588325778

Epoch: 6| Step: 2
Training loss: 5.4316673127265975
Validation loss: 4.696592697663474

Epoch: 6| Step: 3
Training loss: 3.937150243332634
Validation loss: 4.687007604189102

Epoch: 6| Step: 4
Training loss: 4.427230126434273
Validation loss: 4.679194971306769

Epoch: 6| Step: 5
Training loss: 3.9921964581831366
Validation loss: 4.666391809927427

Epoch: 6| Step: 6
Training loss: 4.954193866335307
Validation loss: 4.656818098390565

Epoch: 6| Step: 7
Training loss: 5.222314588032022
Validation loss: 4.6505119566760085

Epoch: 6| Step: 8
Training loss: 5.27514530361422
Validation loss: 4.636416242044152

Epoch: 6| Step: 9
Training loss: 5.5311644811538665
Validation loss: 4.622218758292145

Epoch: 6| Step: 10
Training loss: 4.691304608338991
Validation loss: 4.615036106676972

Epoch: 6| Step: 11
Training loss: 5.109651983843527
Validation loss: 4.603303051651037

Epoch: 6| Step: 12
Training loss: 3.1205119138519866
Validation loss: 4.598318248747334

Epoch: 6| Step: 13
Training loss: 4.612325260811887
Validation loss: 4.57831111435718

Epoch: 8| Step: 0
Training loss: 5.754834340459577
Validation loss: 4.568342508348571

Epoch: 6| Step: 1
Training loss: 3.692497100312393
Validation loss: 4.557151560046305

Epoch: 6| Step: 2
Training loss: 5.117632152079137
Validation loss: 4.539716844866975

Epoch: 6| Step: 3
Training loss: 4.129941581331383
Validation loss: 4.533805683731027

Epoch: 6| Step: 4
Training loss: 4.760403333293292
Validation loss: 4.524539461406033

Epoch: 6| Step: 5
Training loss: 4.077937914770007
Validation loss: 4.51002221792522

Epoch: 6| Step: 6
Training loss: 3.6330836697348365
Validation loss: 4.4969414089175075

Epoch: 6| Step: 7
Training loss: 3.753578004964792
Validation loss: 4.487487618275622

Epoch: 6| Step: 8
Training loss: 4.8941140693493965
Validation loss: 4.46980538108371

Epoch: 6| Step: 9
Training loss: 3.753511818955233
Validation loss: 4.459966371772663

Epoch: 6| Step: 10
Training loss: 5.234324531881235
Validation loss: 4.446784680205027

Epoch: 6| Step: 11
Training loss: 4.5325174597915705
Validation loss: 4.432702958352552

Epoch: 6| Step: 12
Training loss: 5.632242583967615
Validation loss: 4.419453187477968

Epoch: 6| Step: 13
Training loss: 4.141807300986595
Validation loss: 4.4056384586523665

Epoch: 9| Step: 0
Training loss: 3.3409800241804284
Validation loss: 4.396640622783322

Epoch: 6| Step: 1
Training loss: 4.604917485163661
Validation loss: 4.379526820567857

Epoch: 6| Step: 2
Training loss: 4.872276523528659
Validation loss: 4.366453142604416

Epoch: 6| Step: 3
Training loss: 4.573512126182127
Validation loss: 4.355255242089227

Epoch: 6| Step: 4
Training loss: 4.386592221154967
Validation loss: 4.343071197024028

Epoch: 6| Step: 5
Training loss: 4.326833373876106
Validation loss: 4.321434471224264

Epoch: 6| Step: 6
Training loss: 4.528751921183479
Validation loss: 4.309263739317494

Epoch: 6| Step: 7
Training loss: 4.372437516862555
Validation loss: 4.294160324914782

Epoch: 6| Step: 8
Training loss: 5.283661963092867
Validation loss: 4.283075539695049

Epoch: 6| Step: 9
Training loss: 3.8919412002826457
Validation loss: 4.268736088700846

Epoch: 6| Step: 10
Training loss: 4.708731417861053
Validation loss: 4.250091037824784

Epoch: 6| Step: 11
Training loss: 4.281740926175558
Validation loss: 4.236717757538247

Epoch: 6| Step: 12
Training loss: 3.924633985814145
Validation loss: 4.216476560723029

Epoch: 6| Step: 13
Training loss: 3.8095589221743973
Validation loss: 4.204273700480745

Epoch: 10| Step: 0
Training loss: 3.54861394123546
Validation loss: 4.191029630342138

Epoch: 6| Step: 1
Training loss: 5.153239903230213
Validation loss: 4.171688434380047

Epoch: 6| Step: 2
Training loss: 4.064007523402061
Validation loss: 4.16295443070121

Epoch: 6| Step: 3
Training loss: 3.3048958498520253
Validation loss: 4.140370301337956

Epoch: 6| Step: 4
Training loss: 3.5989073525703956
Validation loss: 4.122759511682868

Epoch: 6| Step: 5
Training loss: 4.076244402954414
Validation loss: 4.11343117228322

Epoch: 6| Step: 6
Training loss: 4.464702774185131
Validation loss: 4.096836200844299

Epoch: 6| Step: 7
Training loss: 4.538037497892166
Validation loss: 4.072446785262776

Epoch: 6| Step: 8
Training loss: 4.4830694657474135
Validation loss: 4.056755779387464

Epoch: 6| Step: 9
Training loss: 4.838948287823147
Validation loss: 4.038477126358169

Epoch: 6| Step: 10
Training loss: 3.652116313523555
Validation loss: 4.025368371512814

Epoch: 6| Step: 11
Training loss: 3.6371777630992
Validation loss: 4.003734291399833

Epoch: 6| Step: 12
Training loss: 4.064401973638965
Validation loss: 3.9924064643448176

Epoch: 6| Step: 13
Training loss: 4.976361856053848
Validation loss: 3.9692546965088544

Epoch: 11| Step: 0
Training loss: 4.513956045319576
Validation loss: 3.9529243926445146

Epoch: 6| Step: 1
Training loss: 3.394724815126341
Validation loss: 3.9350265779059064

Epoch: 6| Step: 2
Training loss: 4.411037360428131
Validation loss: 3.9131558710364205

Epoch: 6| Step: 3
Training loss: 4.309969837056623
Validation loss: 3.8946121238197158

Epoch: 6| Step: 4
Training loss: 4.720288158607795
Validation loss: 3.875504272019305

Epoch: 6| Step: 5
Training loss: 3.1723202547898905
Validation loss: 3.854720507169772

Epoch: 6| Step: 6
Training loss: 4.247520621139108
Validation loss: 3.838398265521209

Epoch: 6| Step: 7
Training loss: 3.370766421590333
Validation loss: 3.8176154494256944

Epoch: 6| Step: 8
Training loss: 3.5958330834404486
Validation loss: 3.800373733548386

Epoch: 6| Step: 9
Training loss: 4.4449216003712895
Validation loss: 3.7731510278574882

Epoch: 6| Step: 10
Training loss: 4.331124598681806
Validation loss: 3.757290157595046

Epoch: 6| Step: 11
Training loss: 3.587135929149373
Validation loss: 3.732032673206786

Epoch: 6| Step: 12
Training loss: 3.692708103769974
Validation loss: 3.713678426013045

Epoch: 6| Step: 13
Training loss: 2.0877288099055673
Validation loss: 3.7044623093219045

Epoch: 12| Step: 0
Training loss: 4.065989477546463
Validation loss: 3.6758697207239748

Epoch: 6| Step: 1
Training loss: 3.510641677542461
Validation loss: 3.660420088086728

Epoch: 6| Step: 2
Training loss: 4.2022252591092615
Validation loss: 3.638252613064205

Epoch: 6| Step: 3
Training loss: 3.2729705987408697
Validation loss: 3.620039377732035

Epoch: 6| Step: 4
Training loss: 3.9714346388704818
Validation loss: 3.6101430753933372

Epoch: 6| Step: 5
Training loss: 3.3654687305041144
Validation loss: 3.585952167166875

Epoch: 6| Step: 6
Training loss: 3.681469657834047
Validation loss: 3.559382385841458

Epoch: 6| Step: 7
Training loss: 3.433560420060076
Validation loss: 3.5440613431712995

Epoch: 6| Step: 8
Training loss: 3.782509081842849
Validation loss: 3.5216860878317076

Epoch: 6| Step: 9
Training loss: 4.509422398223589
Validation loss: 3.5084095667449744

Epoch: 6| Step: 10
Training loss: 3.4958741529322315
Validation loss: 3.4835381154221623

Epoch: 6| Step: 11
Training loss: 3.3621655606290535
Validation loss: 3.4547816152061985

Epoch: 6| Step: 12
Training loss: 3.677888920677431
Validation loss: 3.4433992004892695

Epoch: 6| Step: 13
Training loss: 2.6879902769491912
Validation loss: 3.4231447134307986

Epoch: 13| Step: 0
Training loss: 3.5937274434584228
Validation loss: 3.4080260953191543

Epoch: 6| Step: 1
Training loss: 2.9781217721159057
Validation loss: 3.39092415463906

Epoch: 6| Step: 2
Training loss: 3.9824340879992968
Validation loss: 3.3605988517040752

Epoch: 6| Step: 3
Training loss: 4.605328765631264
Validation loss: 3.3543964435432296

Epoch: 6| Step: 4
Training loss: 2.9398687024543966
Validation loss: 3.3237853978252643

Epoch: 6| Step: 5
Training loss: 3.8178570741385545
Validation loss: 3.3193764771373733

Epoch: 6| Step: 6
Training loss: 3.4736017885879136
Validation loss: 3.286303716245095

Epoch: 6| Step: 7
Training loss: 3.78876448570309
Validation loss: 3.266187368702716

Epoch: 6| Step: 8
Training loss: 3.834223906408902
Validation loss: 3.2505102932309278

Epoch: 6| Step: 9
Training loss: 3.4857670351186862
Validation loss: 3.2326166296339056

Epoch: 6| Step: 10
Training loss: 2.9107545788021323
Validation loss: 3.2105246434326866

Epoch: 6| Step: 11
Training loss: 2.74103115295387
Validation loss: 3.189251417945077

Epoch: 6| Step: 12
Training loss: 2.607549885668537
Validation loss: 3.169728274673939

Epoch: 6| Step: 13
Training loss: 2.4728896767595745
Validation loss: 3.1442548590236523

Epoch: 14| Step: 0
Training loss: 3.376219917510778
Validation loss: 3.136399972040366

Epoch: 6| Step: 1
Training loss: 3.4239270053997446
Validation loss: 3.1220696835106665

Epoch: 6| Step: 2
Training loss: 3.205238203459763
Validation loss: 3.1032307671551695

Epoch: 6| Step: 3
Training loss: 3.978936526581991
Validation loss: 3.083608199896513

Epoch: 6| Step: 4
Training loss: 3.990217883822383
Validation loss: 3.066627030386212

Epoch: 6| Step: 5
Training loss: 3.192044926100148
Validation loss: 3.0512564625147562

Epoch: 6| Step: 6
Training loss: 2.94033287291838
Validation loss: 3.0327985854956374

Epoch: 6| Step: 7
Training loss: 2.4977765686436477
Validation loss: 3.009972379265618

Epoch: 6| Step: 8
Training loss: 2.7085986863259928
Validation loss: 2.9841930830258563

Epoch: 6| Step: 9
Training loss: 3.210088390191048
Validation loss: 2.9823926146341044

Epoch: 6| Step: 10
Training loss: 2.758981948456122
Validation loss: 2.9595568020618317

Epoch: 6| Step: 11
Training loss: 3.3479680346805396
Validation loss: 2.9517607217051354

Epoch: 6| Step: 12
Training loss: 2.9490813166446626
Validation loss: 2.9350725039193852

Epoch: 6| Step: 13
Training loss: 3.4449552666537784
Validation loss: 2.9103496101044097

Epoch: 15| Step: 0
Training loss: 3.1462140052988565
Validation loss: 2.908636828948932

Epoch: 6| Step: 1
Training loss: 3.564278409673554
Validation loss: 2.8937331021680035

Epoch: 6| Step: 2
Training loss: 2.730355321795692
Validation loss: 2.8785029245238567

Epoch: 6| Step: 3
Training loss: 3.413332793513891
Validation loss: 2.856257235681969

Epoch: 6| Step: 4
Training loss: 3.631038240702559
Validation loss: 2.842388335070302

Epoch: 6| Step: 5
Training loss: 3.2425997184766944
Validation loss: 2.8513451161153776

Epoch: 6| Step: 6
Training loss: 2.6216079957883753
Validation loss: 2.832844182255913

Epoch: 6| Step: 7
Training loss: 3.044433554593524
Validation loss: 2.822492536672647

Epoch: 6| Step: 8
Training loss: 2.204623314824125
Validation loss: 2.8194254154818843

Epoch: 6| Step: 9
Training loss: 2.927044706440436
Validation loss: 2.802653979677329

Epoch: 6| Step: 10
Training loss: 3.2377525790748223
Validation loss: 2.7983190608255346

Epoch: 6| Step: 11
Training loss: 2.5802356749836344
Validation loss: 2.7873159516940498

Epoch: 6| Step: 12
Training loss: 3.0401640712231397
Validation loss: 2.7705506587600066

Epoch: 6| Step: 13
Training loss: 3.3112790718688867
Validation loss: 2.7713162222452525

Epoch: 16| Step: 0
Training loss: 3.0017845885818586
Validation loss: 2.759333149026764

Epoch: 6| Step: 1
Training loss: 3.058996259334755
Validation loss: 2.7680995015068315

Epoch: 6| Step: 2
Training loss: 2.4627830729948847
Validation loss: 2.754497152884571

Epoch: 6| Step: 3
Training loss: 2.600360489576538
Validation loss: 2.7352338444717215

Epoch: 6| Step: 4
Training loss: 2.65134164927848
Validation loss: 2.7405657913076404

Epoch: 6| Step: 5
Training loss: 2.995837343626208
Validation loss: 2.72738059098756

Epoch: 6| Step: 6
Training loss: 3.0383480379547785
Validation loss: 2.7166872404119577

Epoch: 6| Step: 7
Training loss: 3.229497502925018
Validation loss: 2.708565334924884

Epoch: 6| Step: 8
Training loss: 2.2128298583613843
Validation loss: 2.7087289324057

Epoch: 6| Step: 9
Training loss: 3.605321680708494
Validation loss: 2.7111813752714444

Epoch: 6| Step: 10
Training loss: 3.826338869026762
Validation loss: 2.7031760063056045

Epoch: 6| Step: 11
Training loss: 3.2667593560076438
Validation loss: 2.6828848667415675

Epoch: 6| Step: 12
Training loss: 2.913937481609466
Validation loss: 2.7063870487913455

Epoch: 6| Step: 13
Training loss: 2.506996378503047
Validation loss: 2.693694871136063

Epoch: 17| Step: 0
Training loss: 3.24985709242973
Validation loss: 2.693262138278068

Epoch: 6| Step: 1
Training loss: 2.528654486775283
Validation loss: 2.7008952188051096

Epoch: 6| Step: 2
Training loss: 2.9318502759084133
Validation loss: 2.6898438472524466

Epoch: 6| Step: 3
Training loss: 3.2048684934395824
Validation loss: 2.6821965771904503

Epoch: 6| Step: 4
Training loss: 2.5518654451324494
Validation loss: 2.6764776988336427

Epoch: 6| Step: 5
Training loss: 3.0331858323114593
Validation loss: 2.6949124080164193

Epoch: 6| Step: 6
Training loss: 3.1587544693064196
Validation loss: 2.679182268253979

Epoch: 6| Step: 7
Training loss: 3.7391033803232983
Validation loss: 2.6743134292685156

Epoch: 6| Step: 8
Training loss: 2.711463723242658
Validation loss: 2.672790459745268

Epoch: 6| Step: 9
Training loss: 2.965542797561263
Validation loss: 2.664342092666096

Epoch: 6| Step: 10
Training loss: 2.925733660118633
Validation loss: 2.6818975197052013

Epoch: 6| Step: 11
Training loss: 2.0799004563940797
Validation loss: 2.6652620125701167

Epoch: 6| Step: 12
Training loss: 3.2511937809959766
Validation loss: 2.665073763743782

Epoch: 6| Step: 13
Training loss: 2.6287136149008394
Validation loss: 2.669123867900266

Epoch: 18| Step: 0
Training loss: 2.3577784511162916
Validation loss: 2.677228599435329

Epoch: 6| Step: 1
Training loss: 3.1465302931065215
Validation loss: 2.671539315297748

Epoch: 6| Step: 2
Training loss: 2.413703768350138
Validation loss: 2.666289237125569

Epoch: 6| Step: 3
Training loss: 3.205812991812929
Validation loss: 2.6653787649097507

Epoch: 6| Step: 4
Training loss: 3.3631927797597516
Validation loss: 2.658586499188124

Epoch: 6| Step: 5
Training loss: 3.724663784547857
Validation loss: 2.6670802844148733

Epoch: 6| Step: 6
Training loss: 3.6374720726383085
Validation loss: 2.644366656149977

Epoch: 6| Step: 7
Training loss: 2.945907734997428
Validation loss: 2.6422563215080355

Epoch: 6| Step: 8
Training loss: 2.756386190842794
Validation loss: 2.6559507583873665

Epoch: 6| Step: 9
Training loss: 2.7507601467667593
Validation loss: 2.654169475958127

Epoch: 6| Step: 10
Training loss: 2.9823763081305383
Validation loss: 2.651400948009282

Epoch: 6| Step: 11
Training loss: 2.1242134658169727
Validation loss: 2.645386848504612

Epoch: 6| Step: 12
Training loss: 2.712195376681316
Validation loss: 2.6374444828276165

Epoch: 6| Step: 13
Training loss: 2.383829468881225
Validation loss: 2.6408720551981557

Epoch: 19| Step: 0
Training loss: 3.507427508800743
Validation loss: 2.661174857244062

Epoch: 6| Step: 1
Training loss: 2.8572975491472343
Validation loss: 2.6532990714530533

Epoch: 6| Step: 2
Training loss: 3.3436091027922794
Validation loss: 2.643744693571287

Epoch: 6| Step: 3
Training loss: 3.009835491817647
Validation loss: 2.6402055727998346

Epoch: 6| Step: 4
Training loss: 3.104798288965184
Validation loss: 2.6451099586733466

Epoch: 6| Step: 5
Training loss: 3.1898120647784185
Validation loss: 2.648154146741729

Epoch: 6| Step: 6
Training loss: 2.314665630902148
Validation loss: 2.6387180103213854

Epoch: 6| Step: 7
Training loss: 3.3005524144049545
Validation loss: 2.639833348518461

Epoch: 6| Step: 8
Training loss: 3.352463678878667
Validation loss: 2.64541844674416

Epoch: 6| Step: 9
Training loss: 2.406167759666539
Validation loss: 2.650231993943763

Epoch: 6| Step: 10
Training loss: 2.705268142581545
Validation loss: 2.6446115878394347

Epoch: 6| Step: 11
Training loss: 2.5663702975328477
Validation loss: 2.6544413596194483

Epoch: 6| Step: 12
Training loss: 2.421215336698708
Validation loss: 2.658792734840038

Epoch: 6| Step: 13
Training loss: 2.7035868696645404
Validation loss: 2.655825203231881

Epoch: 20| Step: 0
Training loss: 2.675828295663063
Validation loss: 2.6433232223060186

Epoch: 6| Step: 1
Training loss: 2.9794006433617737
Validation loss: 2.6461438271443116

Epoch: 6| Step: 2
Training loss: 3.008070104887918
Validation loss: 2.6541651149528924

Epoch: 6| Step: 3
Training loss: 2.9701271476887148
Validation loss: 2.647895835277584

Epoch: 6| Step: 4
Training loss: 2.9188668989342164
Validation loss: 2.6433072293462434

Epoch: 6| Step: 5
Training loss: 3.015023126972123
Validation loss: 2.6668990563325368

Epoch: 6| Step: 6
Training loss: 2.7400153705416406
Validation loss: 2.6523972097125954

Epoch: 6| Step: 7
Training loss: 2.799257595549698
Validation loss: 2.6476561920588466

Epoch: 6| Step: 8
Training loss: 2.4718792554816305
Validation loss: 2.6410977869378205

Epoch: 6| Step: 9
Training loss: 3.5111399885457484
Validation loss: 2.65767123898026

Epoch: 6| Step: 10
Training loss: 2.9473652857570176
Validation loss: 2.654848672774887

Epoch: 6| Step: 11
Training loss: 2.7749782527037063
Validation loss: 2.63942862904229

Epoch: 6| Step: 12
Training loss: 3.1021681801947634
Validation loss: 2.6532524630686174

Epoch: 6| Step: 13
Training loss: 3.107568877631457
Validation loss: 2.653426942227867

Epoch: 21| Step: 0
Training loss: 2.953647143509911
Validation loss: 2.6492426072584347

Epoch: 6| Step: 1
Training loss: 2.587084006073243
Validation loss: 2.650407705947871

Epoch: 6| Step: 2
Training loss: 2.826159389549995
Validation loss: 2.638189191478774

Epoch: 6| Step: 3
Training loss: 2.6315256477278837
Validation loss: 2.6262549893232343

Epoch: 6| Step: 4
Training loss: 3.659790932776196
Validation loss: 2.636174291306442

Epoch: 6| Step: 5
Training loss: 2.64697801553887
Validation loss: 2.6491591409066544

Epoch: 6| Step: 6
Training loss: 2.675397725707835
Validation loss: 2.6362367873307404

Epoch: 6| Step: 7
Training loss: 3.458859200692454
Validation loss: 2.634309938938432

Epoch: 6| Step: 8
Training loss: 2.8879086490142427
Validation loss: 2.6309727244675036

Epoch: 6| Step: 9
Training loss: 2.8750553955048725
Validation loss: 2.63061053063008

Epoch: 6| Step: 10
Training loss: 2.8506045051746263
Validation loss: 2.630448804787448

Epoch: 6| Step: 11
Training loss: 2.564721702811499
Validation loss: 2.6491217499306323

Epoch: 6| Step: 12
Training loss: 3.042183261705766
Validation loss: 2.6322883324440665

Epoch: 6| Step: 13
Training loss: 3.1390452800789195
Validation loss: 2.6349152494901036

Epoch: 22| Step: 0
Training loss: 3.084178413534345
Validation loss: 2.6461676687615134

Epoch: 6| Step: 1
Training loss: 3.215804743215044
Validation loss: 2.642281237327362

Epoch: 6| Step: 2
Training loss: 2.217754946807549
Validation loss: 2.6473428768692546

Epoch: 6| Step: 3
Training loss: 2.69912043832699
Validation loss: 2.635327014486878

Epoch: 6| Step: 4
Training loss: 3.0225044801992778
Validation loss: 2.6384703667153384

Epoch: 6| Step: 5
Training loss: 3.261796523212
Validation loss: 2.6293290357830204

Epoch: 6| Step: 6
Training loss: 2.6686111950121254
Validation loss: 2.634086577391218

Epoch: 6| Step: 7
Training loss: 3.032426743341931
Validation loss: 2.6253004053581406

Epoch: 6| Step: 8
Training loss: 2.7721090224433835
Validation loss: 2.6279293021631585

Epoch: 6| Step: 9
Training loss: 3.109617137586331
Validation loss: 2.624974254085387

Epoch: 6| Step: 10
Training loss: 2.684239916350219
Validation loss: 2.621105567141732

Epoch: 6| Step: 11
Training loss: 2.6840023967885718
Validation loss: 2.627740392508824

Epoch: 6| Step: 12
Training loss: 3.1238956788994225
Validation loss: 2.6247493235507005

Epoch: 6| Step: 13
Training loss: 3.2845848938343316
Validation loss: 2.638479697347891

Epoch: 23| Step: 0
Training loss: 2.849422456547373
Validation loss: 2.6377195599603875

Epoch: 6| Step: 1
Training loss: 2.796883183472665
Validation loss: 2.6315841616167095

Epoch: 6| Step: 2
Training loss: 2.607685112970311
Validation loss: 2.6272957856428065

Epoch: 6| Step: 3
Training loss: 2.981245867008567
Validation loss: 2.623481054169918

Epoch: 6| Step: 4
Training loss: 3.3032291161360523
Validation loss: 2.6276983679223305

Epoch: 6| Step: 5
Training loss: 2.668125578039611
Validation loss: 2.6167493404132243

Epoch: 6| Step: 6
Training loss: 2.27532356392594
Validation loss: 2.639012679855943

Epoch: 6| Step: 7
Training loss: 3.3058595134703976
Validation loss: 2.619598495716226

Epoch: 6| Step: 8
Training loss: 3.078180148022796
Validation loss: 2.6129955982541815

Epoch: 6| Step: 9
Training loss: 3.4527481356762078
Validation loss: 2.6350455213479402

Epoch: 6| Step: 10
Training loss: 2.9434562520346046
Validation loss: 2.637311604768782

Epoch: 6| Step: 11
Training loss: 3.275240817934814
Validation loss: 2.6282825806232126

Epoch: 6| Step: 12
Training loss: 2.6693210107072405
Validation loss: 2.636145162294579

Epoch: 6| Step: 13
Training loss: 1.885570042169315
Validation loss: 2.6251437494048595

Epoch: 24| Step: 0
Training loss: 3.1619742578451504
Validation loss: 2.6220754660370527

Epoch: 6| Step: 1
Training loss: 3.7667832235571352
Validation loss: 2.6301785001440607

Epoch: 6| Step: 2
Training loss: 2.3610084386704644
Validation loss: 2.6142095695669005

Epoch: 6| Step: 3
Training loss: 2.516139955118291
Validation loss: 2.627279598517723

Epoch: 6| Step: 4
Training loss: 2.9278478924894946
Validation loss: 2.6233535594767394

Epoch: 6| Step: 5
Training loss: 2.938056568419158
Validation loss: 2.6338757383397056

Epoch: 6| Step: 6
Training loss: 3.58441675057079
Validation loss: 2.6217883758078564

Epoch: 6| Step: 7
Training loss: 2.858856154098464
Validation loss: 2.633250472269689

Epoch: 6| Step: 8
Training loss: 2.818538287346828
Validation loss: 2.6252761486569076

Epoch: 6| Step: 9
Training loss: 2.267192219598486
Validation loss: 2.6213115281772814

Epoch: 6| Step: 10
Training loss: 2.3344499323205095
Validation loss: 2.624851627912822

Epoch: 6| Step: 11
Training loss: 3.104457474640783
Validation loss: 2.6179017616865545

Epoch: 6| Step: 12
Training loss: 3.0845877870634633
Validation loss: 2.6168788913462846

Epoch: 6| Step: 13
Training loss: 1.9799058102832527
Validation loss: 2.6197022538363925

Epoch: 25| Step: 0
Training loss: 2.226438712978951
Validation loss: 2.638674155261532

Epoch: 6| Step: 1
Training loss: 2.005191740157265
Validation loss: 2.6259149469654304

Epoch: 6| Step: 2
Training loss: 2.5650584776757985
Validation loss: 2.604381138655528

Epoch: 6| Step: 3
Training loss: 2.8684504998803226
Validation loss: 2.6262548448518004

Epoch: 6| Step: 4
Training loss: 3.9551994097916
Validation loss: 2.6245090994415223

Epoch: 6| Step: 5
Training loss: 3.1322456284592293
Validation loss: 2.6128112300632846

Epoch: 6| Step: 6
Training loss: 3.0192720960809973
Validation loss: 2.6156990835365725

Epoch: 6| Step: 7
Training loss: 3.5078891669308345
Validation loss: 2.6297406908564978

Epoch: 6| Step: 8
Training loss: 2.6636713809186188
Validation loss: 2.6227777218513926

Epoch: 6| Step: 9
Training loss: 3.0748451690151044
Validation loss: 2.6206566905745965

Epoch: 6| Step: 10
Training loss: 3.210705528326138
Validation loss: 2.620622660193532

Epoch: 6| Step: 11
Training loss: 2.1358031380620415
Validation loss: 2.6295653010492193

Epoch: 6| Step: 12
Training loss: 2.676595165901804
Validation loss: 2.6137309861628486

Epoch: 6| Step: 13
Training loss: 3.016894137691462
Validation loss: 2.6086809024710367

Epoch: 26| Step: 0
Training loss: 2.3780810799471777
Validation loss: 2.6222712548120333

Epoch: 6| Step: 1
Training loss: 2.40428180209532
Validation loss: 2.599008250502601

Epoch: 6| Step: 2
Training loss: 3.826820867623785
Validation loss: 2.5950691949465745

Epoch: 6| Step: 3
Training loss: 2.876623938969931
Validation loss: 2.6144656279161915

Epoch: 6| Step: 4
Training loss: 2.597664602165849
Validation loss: 2.6211774390983713

Epoch: 6| Step: 5
Training loss: 2.75602296685669
Validation loss: 2.6230034450180786

Epoch: 6| Step: 6
Training loss: 2.756460836568584
Validation loss: 2.616493893556104

Epoch: 6| Step: 7
Training loss: 2.470979577079304
Validation loss: 2.6055370556220607

Epoch: 6| Step: 8
Training loss: 2.912496437430761
Validation loss: 2.62204875865767

Epoch: 6| Step: 9
Training loss: 3.3244780855069003
Validation loss: 2.629512888319991

Epoch: 6| Step: 10
Training loss: 3.0380926864779587
Validation loss: 2.624418902401183

Epoch: 6| Step: 11
Training loss: 3.3385239876900443
Validation loss: 2.6162145905867904

Epoch: 6| Step: 12
Training loss: 2.656694083397407
Validation loss: 2.6359077507419797

Epoch: 6| Step: 13
Training loss: 2.655017611773855
Validation loss: 2.6149938699274804

Epoch: 27| Step: 0
Training loss: 2.6011128538200925
Validation loss: 2.6260937903779484

Epoch: 6| Step: 1
Training loss: 2.328088747292722
Validation loss: 2.6221250679466355

Epoch: 6| Step: 2
Training loss: 2.9342051756510457
Validation loss: 2.619236967481349

Epoch: 6| Step: 3
Training loss: 3.223661064941706
Validation loss: 2.6324581329990053

Epoch: 6| Step: 4
Training loss: 2.7785787720290758
Validation loss: 2.619650242687081

Epoch: 6| Step: 5
Training loss: 3.1679275077270734
Validation loss: 2.616620304294447

Epoch: 6| Step: 6
Training loss: 2.9358522379433727
Validation loss: 2.613330632318357

Epoch: 6| Step: 7
Training loss: 2.555891120919878
Validation loss: 2.611001429206527

Epoch: 6| Step: 8
Training loss: 2.916650027273035
Validation loss: 2.6145591108821806

Epoch: 6| Step: 9
Training loss: 2.6488005352735193
Validation loss: 2.613588900404473

Epoch: 6| Step: 10
Training loss: 2.8923921699174215
Validation loss: 2.6042161138618725

Epoch: 6| Step: 11
Training loss: 3.4377127841635295
Validation loss: 2.615526416967414

Epoch: 6| Step: 12
Training loss: 2.8285031566389844
Validation loss: 2.6013824036932456

Epoch: 6| Step: 13
Training loss: 3.1750562527696973
Validation loss: 2.5972900576621183

Epoch: 28| Step: 0
Training loss: 2.7493025155299686
Validation loss: 2.6189269675447697

Epoch: 6| Step: 1
Training loss: 2.7462488079111864
Validation loss: 2.6074638488372672

Epoch: 6| Step: 2
Training loss: 3.1901186489892357
Validation loss: 2.621207584359093

Epoch: 6| Step: 3
Training loss: 2.3496128250312367
Validation loss: 2.606936245468277

Epoch: 6| Step: 4
Training loss: 2.0997039631673493
Validation loss: 2.6151650178864725

Epoch: 6| Step: 5
Training loss: 3.3134718135189223
Validation loss: 2.6125835591784825

Epoch: 6| Step: 6
Training loss: 2.8575965895727466
Validation loss: 2.6053147411673447

Epoch: 6| Step: 7
Training loss: 2.488796881363968
Validation loss: 2.614543611677183

Epoch: 6| Step: 8
Training loss: 2.99910818195759
Validation loss: 2.611557049447215

Epoch: 6| Step: 9
Training loss: 3.02150126121453
Validation loss: 2.6205735894196884

Epoch: 6| Step: 10
Training loss: 2.6466715728880845
Validation loss: 2.609018666095659

Epoch: 6| Step: 11
Training loss: 2.989048359464069
Validation loss: 2.6244292031719265

Epoch: 6| Step: 12
Training loss: 3.1434812700148353
Validation loss: 2.6081215004986573

Epoch: 6| Step: 13
Training loss: 3.9034412509410643
Validation loss: 2.60869288001122

Epoch: 29| Step: 0
Training loss: 3.1770779635691473
Validation loss: 2.6053852746172983

Epoch: 6| Step: 1
Training loss: 2.580104738223834
Validation loss: 2.6172906024223357

Epoch: 6| Step: 2
Training loss: 2.845433501886781
Validation loss: 2.6007658297142364

Epoch: 6| Step: 3
Training loss: 2.5802207982410694
Validation loss: 2.607414040778976

Epoch: 6| Step: 4
Training loss: 2.7582660766730505
Validation loss: 2.5970420854629976

Epoch: 6| Step: 5
Training loss: 2.17004822673033
Validation loss: 2.6014884916770695

Epoch: 6| Step: 6
Training loss: 2.4708345521491797
Validation loss: 2.6130020019626055

Epoch: 6| Step: 7
Training loss: 3.2747973255605505
Validation loss: 2.6002024473943774

Epoch: 6| Step: 8
Training loss: 2.6038150600851946
Validation loss: 2.6051606130151885

Epoch: 6| Step: 9
Training loss: 2.530764686307468
Validation loss: 2.584213641407526

Epoch: 6| Step: 10
Training loss: 3.6171102494956986
Validation loss: 2.623446316773774

Epoch: 6| Step: 11
Training loss: 3.7844093932298613
Validation loss: 2.5928643309896193

Epoch: 6| Step: 12
Training loss: 2.8716685024734567
Validation loss: 2.6065199059406425

Epoch: 6| Step: 13
Training loss: 2.082080375277917
Validation loss: 2.620554457233082

Epoch: 30| Step: 0
Training loss: 2.1298411705007627
Validation loss: 2.6126253838548994

Epoch: 6| Step: 1
Training loss: 2.919565522255857
Validation loss: 2.5908087767756114

Epoch: 6| Step: 2
Training loss: 2.761616792644795
Validation loss: 2.621417992966562

Epoch: 6| Step: 3
Training loss: 3.0207738059306393
Validation loss: 2.6086049458182945

Epoch: 6| Step: 4
Training loss: 2.6411403175757293
Validation loss: 2.6008771640162975

Epoch: 6| Step: 5
Training loss: 2.990120833899252
Validation loss: 2.6070531003216932

Epoch: 6| Step: 6
Training loss: 3.1780265200200395
Validation loss: 2.6052846166887482

Epoch: 6| Step: 7
Training loss: 3.066564393065772
Validation loss: 2.6216227149266222

Epoch: 6| Step: 8
Training loss: 2.7690146842834444
Validation loss: 2.5985301398646934

Epoch: 6| Step: 9
Training loss: 2.5596958727787578
Validation loss: 2.596558548818992

Epoch: 6| Step: 10
Training loss: 2.711141529155806
Validation loss: 2.6128943190707057

Epoch: 6| Step: 11
Training loss: 3.16375926884168
Validation loss: 2.6004965264668276

Epoch: 6| Step: 12
Training loss: 3.001870843557625
Validation loss: 2.60400160596582

Epoch: 6| Step: 13
Training loss: 3.1956366115801536
Validation loss: 2.5937953489855894

Epoch: 31| Step: 0
Training loss: 2.9535317115663458
Validation loss: 2.6046201905784083

Epoch: 6| Step: 1
Training loss: 2.8970993531229188
Validation loss: 2.6038937270993414

Epoch: 6| Step: 2
Training loss: 1.953483365560476
Validation loss: 2.6060976655313928

Epoch: 6| Step: 3
Training loss: 2.4849196502774413
Validation loss: 2.6032183564936417

Epoch: 6| Step: 4
Training loss: 3.558849271107228
Validation loss: 2.606529166040154

Epoch: 6| Step: 5
Training loss: 2.763003556284098
Validation loss: 2.607758271038565

Epoch: 6| Step: 6
Training loss: 3.286492220083732
Validation loss: 2.601103052071537

Epoch: 6| Step: 7
Training loss: 3.2045067760855983
Validation loss: 2.597670761414516

Epoch: 6| Step: 8
Training loss: 3.461687613803285
Validation loss: 2.6092784407612934

Epoch: 6| Step: 9
Training loss: 2.98289013417378
Validation loss: 2.6076070194618093

Epoch: 6| Step: 10
Training loss: 2.4977654006967356
Validation loss: 2.610695378431703

Epoch: 6| Step: 11
Training loss: 2.3406055974219804
Validation loss: 2.603283694959738

Epoch: 6| Step: 12
Training loss: 2.6225660938701867
Validation loss: 2.589509590682991

Epoch: 6| Step: 13
Training loss: 2.380476810553099
Validation loss: 2.603969069993176

Epoch: 32| Step: 0
Training loss: 3.1572082877699534
Validation loss: 2.6080090845256065

Epoch: 6| Step: 1
Training loss: 2.3650141140151715
Validation loss: 2.5940847367412028

Epoch: 6| Step: 2
Training loss: 3.1957695594468953
Validation loss: 2.6060035632533336

Epoch: 6| Step: 3
Training loss: 2.668657473673231
Validation loss: 2.5938153101159354

Epoch: 6| Step: 4
Training loss: 2.8932796351405683
Validation loss: 2.6017250523410955

Epoch: 6| Step: 5
Training loss: 2.5752631747374743
Validation loss: 2.5867394834320128

Epoch: 6| Step: 6
Training loss: 2.6582136189003465
Validation loss: 2.585969930733625

Epoch: 6| Step: 7
Training loss: 2.9058325683079302
Validation loss: 2.5781242184157693

Epoch: 6| Step: 8
Training loss: 2.9638300231916253
Validation loss: 2.57416485382031

Epoch: 6| Step: 9
Training loss: 2.812734212660008
Validation loss: 2.594292435830534

Epoch: 6| Step: 10
Training loss: 2.8894586632935804
Validation loss: 2.6080738006784108

Epoch: 6| Step: 11
Training loss: 2.370709006251458
Validation loss: 2.5819475709172726

Epoch: 6| Step: 12
Training loss: 2.889406679488482
Validation loss: 2.5919978221397764

Epoch: 6| Step: 13
Training loss: 3.724772729276999
Validation loss: 2.586543010161648

Epoch: 33| Step: 0
Training loss: 2.945142179466959
Validation loss: 2.5939958270323817

Epoch: 6| Step: 1
Training loss: 2.714714826637564
Validation loss: 2.600570991842254

Epoch: 6| Step: 2
Training loss: 3.2088894217635415
Validation loss: 2.5931112108460184

Epoch: 6| Step: 3
Training loss: 2.414957516377504
Validation loss: 2.598105164285513

Epoch: 6| Step: 4
Training loss: 3.499170750064985
Validation loss: 2.590537071766965

Epoch: 6| Step: 5
Training loss: 2.865612626543028
Validation loss: 2.5838005084770534

Epoch: 6| Step: 6
Training loss: 2.8919564145023604
Validation loss: 2.5905417595804825

Epoch: 6| Step: 7
Training loss: 3.1849820532659936
Validation loss: 2.5887869200850537

Epoch: 6| Step: 8
Training loss: 2.7670499934404384
Validation loss: 2.5880080693799656

Epoch: 6| Step: 9
Training loss: 2.5265392219825253
Validation loss: 2.5731510013957934

Epoch: 6| Step: 10
Training loss: 2.9582355823396007
Validation loss: 2.5778805683664454

Epoch: 6| Step: 11
Training loss: 2.41482995929316
Validation loss: 2.5872710121638374

Epoch: 6| Step: 12
Training loss: 2.5669648884837706
Validation loss: 2.5845322170697522

Epoch: 6| Step: 13
Training loss: 2.7234683255559253
Validation loss: 2.5764063640783457

Epoch: 34| Step: 0
Training loss: 2.659888972496465
Validation loss: 2.5965056139717717

Epoch: 6| Step: 1
Training loss: 3.3197971796796537
Validation loss: 2.6012561256413163

Epoch: 6| Step: 2
Training loss: 2.7213290029332744
Validation loss: 2.603760369548954

Epoch: 6| Step: 3
Training loss: 3.108429578121189
Validation loss: 2.58376376912352

Epoch: 6| Step: 4
Training loss: 3.22463599228112
Validation loss: 2.598209172926335

Epoch: 6| Step: 5
Training loss: 3.189079641233483
Validation loss: 2.5882680956403163

Epoch: 6| Step: 6
Training loss: 2.5971925249855508
Validation loss: 2.5838054387021705

Epoch: 6| Step: 7
Training loss: 2.684492513196072
Validation loss: 2.5897313404795588

Epoch: 6| Step: 8
Training loss: 2.6317844817558
Validation loss: 2.580641367740304

Epoch: 6| Step: 9
Training loss: 2.971189279798438
Validation loss: 2.587044453459455

Epoch: 6| Step: 10
Training loss: 2.1803387725152596
Validation loss: 2.6020050377017423

Epoch: 6| Step: 11
Training loss: 2.511954906034575
Validation loss: 2.5940142488398754

Epoch: 6| Step: 12
Training loss: 3.0115214677805837
Validation loss: 2.5970717744755345

Epoch: 6| Step: 13
Training loss: 2.3588434087859356
Validation loss: 2.586886478268754

Epoch: 35| Step: 0
Training loss: 2.7488902193520417
Validation loss: 2.6035511462546133

Epoch: 6| Step: 1
Training loss: 2.6518734050011408
Validation loss: 2.582812648449832

Epoch: 6| Step: 2
Training loss: 2.1544955206112033
Validation loss: 2.6023107042367375

Epoch: 6| Step: 3
Training loss: 2.5876457357598985
Validation loss: 2.5974814582619374

Epoch: 6| Step: 4
Training loss: 2.222172635902729
Validation loss: 2.5990571652156516

Epoch: 6| Step: 5
Training loss: 3.4744364549087985
Validation loss: 2.600180440159963

Epoch: 6| Step: 6
Training loss: 3.0360885229159464
Validation loss: 2.5974893688278975

Epoch: 6| Step: 7
Training loss: 2.863982277437071
Validation loss: 2.589654037047204

Epoch: 6| Step: 8
Training loss: 2.3991413885306225
Validation loss: 2.590735380045632

Epoch: 6| Step: 9
Training loss: 3.1098796492469436
Validation loss: 2.601883137024381

Epoch: 6| Step: 10
Training loss: 3.1067148455648184
Validation loss: 2.580792040131596

Epoch: 6| Step: 11
Training loss: 3.133236216670094
Validation loss: 2.576640712422288

Epoch: 6| Step: 12
Training loss: 3.3513237572492636
Validation loss: 2.5950618430652947

Epoch: 6| Step: 13
Training loss: 2.2393200978376973
Validation loss: 2.5851223530197545

Epoch: 36| Step: 0
Training loss: 3.18342988698305
Validation loss: 2.578676220388662

Epoch: 6| Step: 1
Training loss: 3.0240679731651605
Validation loss: 2.5716090957294364

Epoch: 6| Step: 2
Training loss: 2.749074520090443
Validation loss: 2.596277376733713

Epoch: 6| Step: 3
Training loss: 2.0917341862250933
Validation loss: 2.585239122901271

Epoch: 6| Step: 4
Training loss: 3.214838262022579
Validation loss: 2.6018016384644054

Epoch: 6| Step: 5
Training loss: 3.5619804940479427
Validation loss: 2.590875152500637

Epoch: 6| Step: 6
Training loss: 2.3201522001130557
Validation loss: 2.6064063851675856

Epoch: 6| Step: 7
Training loss: 2.2978410830017624
Validation loss: 2.596253439359632

Epoch: 6| Step: 8
Training loss: 3.0578088447498275
Validation loss: 2.5972880431036938

Epoch: 6| Step: 9
Training loss: 2.6641109160109755
Validation loss: 2.5909671950458173

Epoch: 6| Step: 10
Training loss: 2.4659661157388535
Validation loss: 2.5949048514231476

Epoch: 6| Step: 11
Training loss: 3.0905535590359103
Validation loss: 2.5925894338842794

Epoch: 6| Step: 12
Training loss: 2.852506799982309
Validation loss: 2.587867169760503

Epoch: 6| Step: 13
Training loss: 2.586584649833992
Validation loss: 2.5883713031065056

Epoch: 37| Step: 0
Training loss: 3.268686857762439
Validation loss: 2.583036740796236

Epoch: 6| Step: 1
Training loss: 3.2561125859939883
Validation loss: 2.5969755850288414

Epoch: 6| Step: 2
Training loss: 2.6060786641471787
Validation loss: 2.586831328249027

Epoch: 6| Step: 3
Training loss: 3.0980284420355364
Validation loss: 2.584616496872703

Epoch: 6| Step: 4
Training loss: 1.7724226682120352
Validation loss: 2.575503195342417

Epoch: 6| Step: 5
Training loss: 3.226612450903454
Validation loss: 2.5729156417084056

Epoch: 6| Step: 6
Training loss: 2.847681702132483
Validation loss: 2.5680585840020944

Epoch: 6| Step: 7
Training loss: 2.9440803682614907
Validation loss: 2.5680152073865017

Epoch: 6| Step: 8
Training loss: 2.8419881540007284
Validation loss: 2.5838265961965674

Epoch: 6| Step: 9
Training loss: 2.0605864462284447
Validation loss: 2.5895315757438406

Epoch: 6| Step: 10
Training loss: 2.6127862618320523
Validation loss: 2.580760870475001

Epoch: 6| Step: 11
Training loss: 2.2004351055593703
Validation loss: 2.5709761010938843

Epoch: 6| Step: 12
Training loss: 3.179097488737253
Validation loss: 2.5840772274886783

Epoch: 6| Step: 13
Training loss: 3.2487276961414846
Validation loss: 2.573617668720442

Epoch: 38| Step: 0
Training loss: 1.9945506721384711
Validation loss: 2.5792861019288718

Epoch: 6| Step: 1
Training loss: 2.2876482555936786
Validation loss: 2.5861904990959164

Epoch: 6| Step: 2
Training loss: 2.560391186390031
Validation loss: 2.5900957706948193

Epoch: 6| Step: 3
Training loss: 2.9968567912291424
Validation loss: 2.5845396683371673

Epoch: 6| Step: 4
Training loss: 3.242877491526442
Validation loss: 2.5640918910350274

Epoch: 6| Step: 5
Training loss: 2.9641353680668177
Validation loss: 2.572372004893442

Epoch: 6| Step: 6
Training loss: 3.1620149745598645
Validation loss: 2.5785619917870974

Epoch: 6| Step: 7
Training loss: 2.644466157052939
Validation loss: 2.5827526315794134

Epoch: 6| Step: 8
Training loss: 2.627591987836204
Validation loss: 2.5730774671320504

Epoch: 6| Step: 9
Training loss: 2.5224023355078176
Validation loss: 2.5708574299066864

Epoch: 6| Step: 10
Training loss: 3.596810803805786
Validation loss: 2.5912233597169703

Epoch: 6| Step: 11
Training loss: 3.0491810996926936
Validation loss: 2.571849808231702

Epoch: 6| Step: 12
Training loss: 2.6839428803666445
Validation loss: 2.5789525478538544

Epoch: 6| Step: 13
Training loss: 3.0244345585760137
Validation loss: 2.5919705912045745

Epoch: 39| Step: 0
Training loss: 2.5010391936527614
Validation loss: 2.584282773694465

Epoch: 6| Step: 1
Training loss: 2.4027397015543097
Validation loss: 2.576213662399947

Epoch: 6| Step: 2
Training loss: 3.2401335679297083
Validation loss: 2.5928017337893348

Epoch: 6| Step: 3
Training loss: 2.9985400462145644
Validation loss: 2.579349083787562

Epoch: 6| Step: 4
Training loss: 2.7540477094098366
Validation loss: 2.575050866468567

Epoch: 6| Step: 5
Training loss: 2.525668831803393
Validation loss: 2.5714428121890585

Epoch: 6| Step: 6
Training loss: 3.719511835616078
Validation loss: 2.5754574038214435

Epoch: 6| Step: 7
Training loss: 3.0160106353066323
Validation loss: 2.5817066877450485

Epoch: 6| Step: 8
Training loss: 3.166636834924289
Validation loss: 2.5616204738015522

Epoch: 6| Step: 9
Training loss: 2.4973650397721636
Validation loss: 2.577215929994157

Epoch: 6| Step: 10
Training loss: 2.7948504744712372
Validation loss: 2.559898694844983

Epoch: 6| Step: 11
Training loss: 2.801550000189976
Validation loss: 2.5652743541943868

Epoch: 6| Step: 12
Training loss: 2.4606530403552966
Validation loss: 2.5858138643207687

Epoch: 6| Step: 13
Training loss: 1.3242673611791078
Validation loss: 2.580562642595786

Epoch: 40| Step: 0
Training loss: 2.9182679458284673
Validation loss: 2.585494024699616

Epoch: 6| Step: 1
Training loss: 3.064676406729805
Validation loss: 2.5686588512800506

Epoch: 6| Step: 2
Training loss: 2.752485885653224
Validation loss: 2.585799195154144

Epoch: 6| Step: 3
Training loss: 2.4002863315804173
Validation loss: 2.566913486620856

Epoch: 6| Step: 4
Training loss: 2.7638498417467234
Validation loss: 2.5889563277983068

Epoch: 6| Step: 5
Training loss: 2.133839454317728
Validation loss: 2.554494685372535

Epoch: 6| Step: 6
Training loss: 2.774504808112038
Validation loss: 2.5709195462929886

Epoch: 6| Step: 7
Training loss: 3.272582896255832
Validation loss: 2.5630815897955954

Epoch: 6| Step: 8
Training loss: 2.3133172318102493
Validation loss: 2.572755867776384

Epoch: 6| Step: 9
Training loss: 3.1722240537811475
Validation loss: 2.587412803282022

Epoch: 6| Step: 10
Training loss: 3.0621624196116755
Validation loss: 2.5659289724515766

Epoch: 6| Step: 11
Training loss: 2.705462024315745
Validation loss: 2.5726350096484465

Epoch: 6| Step: 12
Training loss: 2.848837190292206
Validation loss: 2.5695092835394044

Epoch: 6| Step: 13
Training loss: 2.9258467663100127
Validation loss: 2.5809576254761644

Epoch: 41| Step: 0
Training loss: 2.6534969648707203
Validation loss: 2.564154952159325

Epoch: 6| Step: 1
Training loss: 3.0285853048865254
Validation loss: 2.5804173882714387

Epoch: 6| Step: 2
Training loss: 2.436073864147397
Validation loss: 2.5719165835372237

Epoch: 6| Step: 3
Training loss: 3.38788560875515
Validation loss: 2.5631382465245047

Epoch: 6| Step: 4
Training loss: 2.3203626428188877
Validation loss: 2.5791857662968467

Epoch: 6| Step: 5
Training loss: 2.750434667740943
Validation loss: 2.5639746939853763

Epoch: 6| Step: 6
Training loss: 1.859249335137695
Validation loss: 2.5803970651874324

Epoch: 6| Step: 7
Training loss: 2.9937454828853416
Validation loss: 2.5767706800692345

Epoch: 6| Step: 8
Training loss: 2.9735364375289737
Validation loss: 2.584663467128963

Epoch: 6| Step: 9
Training loss: 3.555419578203843
Validation loss: 2.5737071270108474

Epoch: 6| Step: 10
Training loss: 3.4978868372275573
Validation loss: 2.575806895064584

Epoch: 6| Step: 11
Training loss: 2.4044169590429507
Validation loss: 2.5721191441284135

Epoch: 6| Step: 12
Training loss: 2.2563945185061347
Validation loss: 2.580832834879827

Epoch: 6| Step: 13
Training loss: 2.61544258821542
Validation loss: 2.562321597416218

Epoch: 42| Step: 0
Training loss: 2.0821993475469163
Validation loss: 2.5795315363355455

Epoch: 6| Step: 1
Training loss: 2.706445495733197
Validation loss: 2.561138298500685

Epoch: 6| Step: 2
Training loss: 2.84658387220825
Validation loss: 2.579196201996722

Epoch: 6| Step: 3
Training loss: 1.8053357830134291
Validation loss: 2.560072039001093

Epoch: 6| Step: 4
Training loss: 3.0414115241353095
Validation loss: 2.5666058319253886

Epoch: 6| Step: 5
Training loss: 3.2952649854234357
Validation loss: 2.567537525994443

Epoch: 6| Step: 6
Training loss: 3.3090476993594007
Validation loss: 2.56194335189865

Epoch: 6| Step: 7
Training loss: 2.730095528129447
Validation loss: 2.5789959174524606

Epoch: 6| Step: 8
Training loss: 2.9187618541272595
Validation loss: 2.574381317060098

Epoch: 6| Step: 9
Training loss: 2.572926128745859
Validation loss: 2.5706099346732043

Epoch: 6| Step: 10
Training loss: 2.620298626020776
Validation loss: 2.5688633438388773

Epoch: 6| Step: 11
Training loss: 2.6991976393496553
Validation loss: 2.5683452629363877

Epoch: 6| Step: 12
Training loss: 3.2468536993067842
Validation loss: 2.5759873254474126

Epoch: 6| Step: 13
Training loss: 3.041854713235914
Validation loss: 2.5735797500099316

Epoch: 43| Step: 0
Training loss: 2.117680003184199
Validation loss: 2.5897794365447195

Epoch: 6| Step: 1
Training loss: 2.936443382316238
Validation loss: 2.592085500800855

Epoch: 6| Step: 2
Training loss: 2.5128045234415994
Validation loss: 2.5766346710506243

Epoch: 6| Step: 3
Training loss: 2.565541393111892
Validation loss: 2.5745264967017034

Epoch: 6| Step: 4
Training loss: 2.625060671150608
Validation loss: 2.5704676305796696

Epoch: 6| Step: 5
Training loss: 2.461276173372531
Validation loss: 2.5882278786668116

Epoch: 6| Step: 6
Training loss: 2.662335146246378
Validation loss: 2.5785613216872436

Epoch: 6| Step: 7
Training loss: 2.3800544160344135
Validation loss: 2.586968473960539

Epoch: 6| Step: 8
Training loss: 2.713707907203968
Validation loss: 2.5661449835369496

Epoch: 6| Step: 9
Training loss: 3.731071000142649
Validation loss: 2.5707347313738045

Epoch: 6| Step: 10
Training loss: 2.5845762052247587
Validation loss: 2.574722467072149

Epoch: 6| Step: 11
Training loss: 3.7212546753269358
Validation loss: 2.5751772976321634

Epoch: 6| Step: 12
Training loss: 2.9271258331869756
Validation loss: 2.5749390317821796

Epoch: 6| Step: 13
Training loss: 2.466971903894179
Validation loss: 2.588992845925397

Epoch: 44| Step: 0
Training loss: 2.7810658597530873
Validation loss: 2.586093004804928

Epoch: 6| Step: 1
Training loss: 2.80188239037694
Validation loss: 2.578100641507811

Epoch: 6| Step: 2
Training loss: 1.8509752332121692
Validation loss: 2.5625622879569607

Epoch: 6| Step: 3
Training loss: 2.8656582197054705
Validation loss: 2.574237293418932

Epoch: 6| Step: 4
Training loss: 2.1177923598337296
Validation loss: 2.5712591276336285

Epoch: 6| Step: 5
Training loss: 3.3039482137487113
Validation loss: 2.568949923993764

Epoch: 6| Step: 6
Training loss: 2.6195482225604905
Validation loss: 2.568631024598557

Epoch: 6| Step: 7
Training loss: 2.573381904413792
Validation loss: 2.576909406807344

Epoch: 6| Step: 8
Training loss: 3.3390863998764457
Validation loss: 2.5708085231155895

Epoch: 6| Step: 9
Training loss: 2.2795715428040872
Validation loss: 2.5589682478981226

Epoch: 6| Step: 10
Training loss: 2.452962298981003
Validation loss: 2.5654592766802558

Epoch: 6| Step: 11
Training loss: 3.520751199761227
Validation loss: 2.5515414525121156

Epoch: 6| Step: 12
Training loss: 3.4287946577289525
Validation loss: 2.574541605501428

Epoch: 6| Step: 13
Training loss: 2.4485797930805266
Validation loss: 2.5654558501087683

Epoch: 45| Step: 0
Training loss: 3.2665960155035116
Validation loss: 2.567726332045144

Epoch: 6| Step: 1
Training loss: 3.1662388228118634
Validation loss: 2.5723027019918328

Epoch: 6| Step: 2
Training loss: 1.8219439354445566
Validation loss: 2.5662531246161504

Epoch: 6| Step: 3
Training loss: 2.7289733721201763
Validation loss: 2.5773687153939755

Epoch: 6| Step: 4
Training loss: 2.240109959866636
Validation loss: 2.575915038567436

Epoch: 6| Step: 5
Training loss: 2.1230894363474717
Validation loss: 2.5762187126268214

Epoch: 6| Step: 6
Training loss: 3.4597650957575525
Validation loss: 2.5722135028274793

Epoch: 6| Step: 7
Training loss: 3.1864556490356937
Validation loss: 2.5694327336334273

Epoch: 6| Step: 8
Training loss: 2.5948065019324087
Validation loss: 2.5701792742577636

Epoch: 6| Step: 9
Training loss: 2.2202104946384993
Validation loss: 2.552027507386532

Epoch: 6| Step: 10
Training loss: 2.653239260528232
Validation loss: 2.5508309518257493

Epoch: 6| Step: 11
Training loss: 2.8388959097811717
Validation loss: 2.574363361225351

Epoch: 6| Step: 12
Training loss: 3.0663664408243942
Validation loss: 2.5628486894284763

Epoch: 6| Step: 13
Training loss: 3.3524794669094997
Validation loss: 2.5724032393234584

Epoch: 46| Step: 0
Training loss: 3.269331876995059
Validation loss: 2.5724574903178423

Epoch: 6| Step: 1
Training loss: 2.3946713380144997
Validation loss: 2.5793971274546794

Epoch: 6| Step: 2
Training loss: 3.1164458116691702
Validation loss: 2.5680810352133805

Epoch: 6| Step: 3
Training loss: 2.8074493835723557
Validation loss: 2.5686278338077724

Epoch: 6| Step: 4
Training loss: 2.6788271754651776
Validation loss: 2.57459598170927

Epoch: 6| Step: 5
Training loss: 2.222330884131171
Validation loss: 2.565098454754453

Epoch: 6| Step: 6
Training loss: 2.803326714954282
Validation loss: 2.5834782831317966

Epoch: 6| Step: 7
Training loss: 2.7003017963293967
Validation loss: 2.5762921602162923

Epoch: 6| Step: 8
Training loss: 2.2725213685830337
Validation loss: 2.587826180285439

Epoch: 6| Step: 9
Training loss: 2.9545478420648066
Validation loss: 2.5638276289306314

Epoch: 6| Step: 10
Training loss: 3.1690825398831577
Validation loss: 2.562447147939839

Epoch: 6| Step: 11
Training loss: 2.691865170445153
Validation loss: 2.566934285983143

Epoch: 6| Step: 12
Training loss: 2.095640098000876
Validation loss: 2.580173008869988

Epoch: 6| Step: 13
Training loss: 3.6501037582908604
Validation loss: 2.5560182781442475

Epoch: 47| Step: 0
Training loss: 2.5766730641643
Validation loss: 2.582758305275608

Epoch: 6| Step: 1
Training loss: 2.0820617100990653
Validation loss: 2.5776030359186617

Epoch: 6| Step: 2
Training loss: 2.9062522970211018
Validation loss: 2.5678970393039773

Epoch: 6| Step: 3
Training loss: 2.1269555910654896
Validation loss: 2.5630344720877796

Epoch: 6| Step: 4
Training loss: 2.6212239126527233
Validation loss: 2.5608010921808124

Epoch: 6| Step: 5
Training loss: 3.209809859399166
Validation loss: 2.5638276969256713

Epoch: 6| Step: 6
Training loss: 2.748369774084284
Validation loss: 2.56638825135347

Epoch: 6| Step: 7
Training loss: 2.6908230308823007
Validation loss: 2.558444396626437

Epoch: 6| Step: 8
Training loss: 2.537256155841188
Validation loss: 2.5719343640764043

Epoch: 6| Step: 9
Training loss: 3.122936635698973
Validation loss: 2.572016022599382

Epoch: 6| Step: 10
Training loss: 3.3287318576342697
Validation loss: 2.5563052743928516

Epoch: 6| Step: 11
Training loss: 2.9337065531533053
Validation loss: 2.5578641117737684

Epoch: 6| Step: 12
Training loss: 2.943795620510105
Validation loss: 2.555905602655165

Epoch: 6| Step: 13
Training loss: 2.7889187131944437
Validation loss: 2.5592087359220987

Epoch: 48| Step: 0
Training loss: 2.6389882810736474
Validation loss: 2.551917158136553

Epoch: 6| Step: 1
Training loss: 2.4136174356495244
Validation loss: 2.558870166262266

Epoch: 6| Step: 2
Training loss: 2.675108620408047
Validation loss: 2.566590849211138

Epoch: 6| Step: 3
Training loss: 3.3831674156158695
Validation loss: 2.5718652706719527

Epoch: 6| Step: 4
Training loss: 2.6198873230677857
Validation loss: 2.5577238939934386

Epoch: 6| Step: 5
Training loss: 3.165292006486625
Validation loss: 2.571644549285436

Epoch: 6| Step: 6
Training loss: 2.5783271479106045
Validation loss: 2.5486216345990185

Epoch: 6| Step: 7
Training loss: 3.159885390170997
Validation loss: 2.5690020515079466

Epoch: 6| Step: 8
Training loss: 2.387762612484562
Validation loss: 2.570944504308539

Epoch: 6| Step: 9
Training loss: 2.0667810803193607
Validation loss: 2.5680278517790485

Epoch: 6| Step: 10
Training loss: 2.625283543849675
Validation loss: 2.553653103841708

Epoch: 6| Step: 11
Training loss: 3.0084059885256305
Validation loss: 2.55448009527994

Epoch: 6| Step: 12
Training loss: 2.772112634701674
Validation loss: 2.566488853557811

Epoch: 6| Step: 13
Training loss: 3.3464947424824087
Validation loss: 2.567619676803946

Epoch: 49| Step: 0
Training loss: 2.6752647625389563
Validation loss: 2.547644156729529

Epoch: 6| Step: 1
Training loss: 2.8180935655686303
Validation loss: 2.5593108243750775

Epoch: 6| Step: 2
Training loss: 2.8770113004874216
Validation loss: 2.5685377379932177

Epoch: 6| Step: 3
Training loss: 2.4813584541813394
Validation loss: 2.5566507987592217

Epoch: 6| Step: 4
Training loss: 2.4434770514603126
Validation loss: 2.5572202571566605

Epoch: 6| Step: 5
Training loss: 2.2724365967486695
Validation loss: 2.555681819187088

Epoch: 6| Step: 6
Training loss: 2.2387843873041713
Validation loss: 2.5655686147844285

Epoch: 6| Step: 7
Training loss: 2.7089836709173563
Validation loss: 2.5684870697796462

Epoch: 6| Step: 8
Training loss: 2.130033925820545
Validation loss: 2.550083764486152

Epoch: 6| Step: 9
Training loss: 3.8317261242882084
Validation loss: 2.566635922944465

Epoch: 6| Step: 10
Training loss: 2.9309476456536205
Validation loss: 2.544636247541851

Epoch: 6| Step: 11
Training loss: 2.604646704616882
Validation loss: 2.573169343287063

Epoch: 6| Step: 12
Training loss: 3.114053092058042
Validation loss: 2.56674319037201

Epoch: 6| Step: 13
Training loss: 3.308075162741716
Validation loss: 2.5498211130961908

Epoch: 50| Step: 0
Training loss: 2.7878757377527412
Validation loss: 2.5423053690053505

Epoch: 6| Step: 1
Training loss: 3.3629231013031387
Validation loss: 2.5613058795972066

Epoch: 6| Step: 2
Training loss: 2.6839769026022546
Validation loss: 2.563468131946583

Epoch: 6| Step: 3
Training loss: 2.779371677445591
Validation loss: 2.5650351034965193

Epoch: 6| Step: 4
Training loss: 2.6942009001929654
Validation loss: 2.550252893282723

Epoch: 6| Step: 5
Training loss: 2.8718473314814132
Validation loss: 2.5736628385331595

Epoch: 6| Step: 6
Training loss: 1.9353014870306706
Validation loss: 2.5559844082165766

Epoch: 6| Step: 7
Training loss: 3.174773296763069
Validation loss: 2.5528425529290195

Epoch: 6| Step: 8
Training loss: 3.151972222917418
Validation loss: 2.5657092271810362

Epoch: 6| Step: 9
Training loss: 2.8594707202002643
Validation loss: 2.563718702561701

Epoch: 6| Step: 10
Training loss: 2.2697224364125432
Validation loss: 2.563205226775427

Epoch: 6| Step: 11
Training loss: 2.976557213485709
Validation loss: 2.5597419021925902

Epoch: 6| Step: 12
Training loss: 2.3156174962054745
Validation loss: 2.571536506328445

Epoch: 6| Step: 13
Training loss: 2.3879488258501587
Validation loss: 2.5555501144268624

Epoch: 51| Step: 0
Training loss: 2.842129423734057
Validation loss: 2.5555695928241886

Epoch: 6| Step: 1
Training loss: 2.6383116932999817
Validation loss: 2.5734107058130427

Epoch: 6| Step: 2
Training loss: 2.921128284691968
Validation loss: 2.5491688057899085

Epoch: 6| Step: 3
Training loss: 2.8377797261968842
Validation loss: 2.570108266381991

Epoch: 6| Step: 4
Training loss: 2.8894225222710213
Validation loss: 2.553821225303252

Epoch: 6| Step: 5
Training loss: 1.7240758742476978
Validation loss: 2.552594970152526

Epoch: 6| Step: 6
Training loss: 2.495429247547724
Validation loss: 2.552486551729911

Epoch: 6| Step: 7
Training loss: 2.7397604958769786
Validation loss: 2.5492549073901825

Epoch: 6| Step: 8
Training loss: 2.72737979389764
Validation loss: 2.5696458402987346

Epoch: 6| Step: 9
Training loss: 3.3082560577463958
Validation loss: 2.554249629407546

Epoch: 6| Step: 10
Training loss: 2.772805843149666
Validation loss: 2.5643372531044486

Epoch: 6| Step: 11
Training loss: 2.879660933191428
Validation loss: 2.5766757873195227

Epoch: 6| Step: 12
Training loss: 2.638409108053556
Validation loss: 2.5491265348204992

Epoch: 6| Step: 13
Training loss: 3.1025693397857705
Validation loss: 2.5609632796928192

Epoch: 52| Step: 0
Training loss: 3.20318707661837
Validation loss: 2.5627211048409837

Epoch: 6| Step: 1
Training loss: 3.42527010332933
Validation loss: 2.5557440220410728

Epoch: 6| Step: 2
Training loss: 2.0331184596775325
Validation loss: 2.563657871692394

Epoch: 6| Step: 3
Training loss: 1.8538218045363053
Validation loss: 2.5695724980503107

Epoch: 6| Step: 4
Training loss: 2.0366987653950974
Validation loss: 2.5738958709336

Epoch: 6| Step: 5
Training loss: 3.2609773261467283
Validation loss: 2.561191323709542

Epoch: 6| Step: 6
Training loss: 2.7013845849568114
Validation loss: 2.566116454247662

Epoch: 6| Step: 7
Training loss: 2.996228867807613
Validation loss: 2.572540709759414

Epoch: 6| Step: 8
Training loss: 2.67541394462342
Validation loss: 2.5521756572150767

Epoch: 6| Step: 9
Training loss: 2.8875362905888773
Validation loss: 2.54262858148686

Epoch: 6| Step: 10
Training loss: 3.0440209740055253
Validation loss: 2.549492184879136

Epoch: 6| Step: 11
Training loss: 2.4869179816317386
Validation loss: 2.5433994658902392

Epoch: 6| Step: 12
Training loss: 2.703427512821018
Validation loss: 2.5598907392204513

Epoch: 6| Step: 13
Training loss: 2.9470146785250146
Validation loss: 2.568309179899709

Epoch: 53| Step: 0
Training loss: 3.406037490235199
Validation loss: 2.5550808234513553

Epoch: 6| Step: 1
Training loss: 3.133870771322988
Validation loss: 2.557168290484694

Epoch: 6| Step: 2
Training loss: 2.926821840672256
Validation loss: 2.5428237880022055

Epoch: 6| Step: 3
Training loss: 3.2871833561750488
Validation loss: 2.5382259533725846

Epoch: 6| Step: 4
Training loss: 2.0157889366018136
Validation loss: 2.540262933744736

Epoch: 6| Step: 5
Training loss: 2.5944751507151156
Validation loss: 2.5705475175952204

Epoch: 6| Step: 6
Training loss: 2.0271732207151585
Validation loss: 2.544212439804422

Epoch: 6| Step: 7
Training loss: 3.167125886111729
Validation loss: 2.543190189511204

Epoch: 6| Step: 8
Training loss: 2.730528649367571
Validation loss: 2.551225731013411

Epoch: 6| Step: 9
Training loss: 3.462050558178319
Validation loss: 2.5393982145815417

Epoch: 6| Step: 10
Training loss: 2.481742567853423
Validation loss: 2.5608607025134584

Epoch: 6| Step: 11
Training loss: 2.810270994429859
Validation loss: 2.564710289598956

Epoch: 6| Step: 12
Training loss: 1.8400536678614436
Validation loss: 2.5556593799262513

Epoch: 6| Step: 13
Training loss: 1.1910359291755632
Validation loss: 2.538543729959553

Epoch: 54| Step: 0
Training loss: 2.4414639641615765
Validation loss: 2.55440502894983

Epoch: 6| Step: 1
Training loss: 2.5876354163665845
Validation loss: 2.557460963681511

Epoch: 6| Step: 2
Training loss: 2.858781596660932
Validation loss: 2.5359413004252227

Epoch: 6| Step: 3
Training loss: 2.6739698975722517
Validation loss: 2.5567554198768057

Epoch: 6| Step: 4
Training loss: 2.152894989705824
Validation loss: 2.5594743663697503

Epoch: 6| Step: 5
Training loss: 2.7082160239611954
Validation loss: 2.55203095500169

Epoch: 6| Step: 6
Training loss: 2.238735079734238
Validation loss: 2.5589439685325632

Epoch: 6| Step: 7
Training loss: 2.6809698211895086
Validation loss: 2.564270709322748

Epoch: 6| Step: 8
Training loss: 3.1145528496278563
Validation loss: 2.551498550676572

Epoch: 6| Step: 9
Training loss: 3.543201039363513
Validation loss: 2.5535838144650715

Epoch: 6| Step: 10
Training loss: 2.9688272566530696
Validation loss: 2.554575860685428

Epoch: 6| Step: 11
Training loss: 2.70877472630769
Validation loss: 2.5621334547097034

Epoch: 6| Step: 12
Training loss: 2.6200163626705884
Validation loss: 2.5508608646157804

Epoch: 6| Step: 13
Training loss: 2.96846793993137
Validation loss: 2.5579275198639033

Epoch: 55| Step: 0
Training loss: 2.359536070725594
Validation loss: 2.54048440476072

Epoch: 6| Step: 1
Training loss: 2.0863579601332267
Validation loss: 2.553675523085447

Epoch: 6| Step: 2
Training loss: 3.230309331389928
Validation loss: 2.5578157884337585

Epoch: 6| Step: 3
Training loss: 2.3947399353395675
Validation loss: 2.5553438501856114

Epoch: 6| Step: 4
Training loss: 2.6140619089840746
Validation loss: 2.549091754676118

Epoch: 6| Step: 5
Training loss: 2.8110996574885556
Validation loss: 2.5583745400825673

Epoch: 6| Step: 6
Training loss: 2.870926666588117
Validation loss: 2.5350769972041425

Epoch: 6| Step: 7
Training loss: 3.10284074631965
Validation loss: 2.537562475117835

Epoch: 6| Step: 8
Training loss: 2.938362157387811
Validation loss: 2.5408935709253275

Epoch: 6| Step: 9
Training loss: 2.9561037249194944
Validation loss: 2.5648843160814194

Epoch: 6| Step: 10
Training loss: 2.5625666167741423
Validation loss: 2.535494518150693

Epoch: 6| Step: 11
Training loss: 2.5605774156740813
Validation loss: 2.544844715448187

Epoch: 6| Step: 12
Training loss: 2.7429663266720197
Validation loss: 2.5456847819500816

Epoch: 6| Step: 13
Training loss: 3.3836467322158588
Validation loss: 2.553938733697868

Epoch: 56| Step: 0
Training loss: 3.6591334262404636
Validation loss: 2.5766486939360576

Epoch: 6| Step: 1
Training loss: 2.2965178958154846
Validation loss: 2.56462465489895

Epoch: 6| Step: 2
Training loss: 2.7252466037702137
Validation loss: 2.5497115571848448

Epoch: 6| Step: 3
Training loss: 2.9425881330309034
Validation loss: 2.5516255982596827

Epoch: 6| Step: 4
Training loss: 2.7473646888353707
Validation loss: 2.5468517689690042

Epoch: 6| Step: 5
Training loss: 2.37252216581998
Validation loss: 2.547060918121372

Epoch: 6| Step: 6
Training loss: 2.398849203454758
Validation loss: 2.5463670573486556

Epoch: 6| Step: 7
Training loss: 2.5946736357276112
Validation loss: 2.552922652056104

Epoch: 6| Step: 8
Training loss: 2.9849431161236795
Validation loss: 2.564338815679374

Epoch: 6| Step: 9
Training loss: 2.292153416583683
Validation loss: 2.5573316116142224

Epoch: 6| Step: 10
Training loss: 2.792389496176734
Validation loss: 2.531950342908449

Epoch: 6| Step: 11
Training loss: 2.7237974645742735
Validation loss: 2.54640586201731

Epoch: 6| Step: 12
Training loss: 2.5550003093562528
Validation loss: 2.5522088193063452

Epoch: 6| Step: 13
Training loss: 3.2211019570937465
Validation loss: 2.5318042842522703

Epoch: 57| Step: 0
Training loss: 2.440052652103606
Validation loss: 2.5412883110457978

Epoch: 6| Step: 1
Training loss: 3.055125485604165
Validation loss: 2.547835546811784

Epoch: 6| Step: 2
Training loss: 2.3460724577190013
Validation loss: 2.5529903291047598

Epoch: 6| Step: 3
Training loss: 3.7213751238621455
Validation loss: 2.5435314152982706

Epoch: 6| Step: 4
Training loss: 2.2288139872370167
Validation loss: 2.54182046162372

Epoch: 6| Step: 5
Training loss: 2.2791115130551267
Validation loss: 2.557089286809206

Epoch: 6| Step: 6
Training loss: 2.7820361451489157
Validation loss: 2.5483187442331534

Epoch: 6| Step: 7
Training loss: 3.22526010455039
Validation loss: 2.5499233793312572

Epoch: 6| Step: 8
Training loss: 2.395653516130441
Validation loss: 2.537994020612908

Epoch: 6| Step: 9
Training loss: 2.3570413732769637
Validation loss: 2.548755374621889

Epoch: 6| Step: 10
Training loss: 2.8261006734508753
Validation loss: 2.540625889828472

Epoch: 6| Step: 11
Training loss: 2.562597226415092
Validation loss: 2.544635946308779

Epoch: 6| Step: 12
Training loss: 2.9470944465489874
Validation loss: 2.5386999000386785

Epoch: 6| Step: 13
Training loss: 3.0227777120954036
Validation loss: 2.5446735669205185

Epoch: 58| Step: 0
Training loss: 2.7624106828568626
Validation loss: 2.543971827062604

Epoch: 6| Step: 1
Training loss: 2.812872374573007
Validation loss: 2.5327537179031916

Epoch: 6| Step: 2
Training loss: 2.177672517864487
Validation loss: 2.555102438029763

Epoch: 6| Step: 3
Training loss: 2.5700078627172935
Validation loss: 2.546136461745527

Epoch: 6| Step: 4
Training loss: 1.7573202842759512
Validation loss: 2.53175749477417

Epoch: 6| Step: 5
Training loss: 2.4053490673693863
Validation loss: 2.555071689938943

Epoch: 6| Step: 6
Training loss: 2.887376764483313
Validation loss: 2.5604674599331294

Epoch: 6| Step: 7
Training loss: 3.6799318916818273
Validation loss: 2.5661368304884675

Epoch: 6| Step: 8
Training loss: 2.6746226677411755
Validation loss: 2.5648531000349855

Epoch: 6| Step: 9
Training loss: 3.3510884125286795
Validation loss: 2.5572496024810993

Epoch: 6| Step: 10
Training loss: 2.8398815294190096
Validation loss: 2.5444395659876213

Epoch: 6| Step: 11
Training loss: 2.910542261521642
Validation loss: 2.545741302197372

Epoch: 6| Step: 12
Training loss: 2.467890626082012
Validation loss: 2.565148832112295

Epoch: 6| Step: 13
Training loss: 2.5065778979180555
Validation loss: 2.5535061220106576

Epoch: 59| Step: 0
Training loss: 2.7768715673026625
Validation loss: 2.5500181657520895

Epoch: 6| Step: 1
Training loss: 2.8938610212149825
Validation loss: 2.5568530983527933

Epoch: 6| Step: 2
Training loss: 3.0058385936273995
Validation loss: 2.553629071101369

Epoch: 6| Step: 3
Training loss: 2.746529209561517
Validation loss: 2.5418720764183527

Epoch: 6| Step: 4
Training loss: 2.6958215205205462
Validation loss: 2.5441991722235655

Epoch: 6| Step: 5
Training loss: 2.9794344125933216
Validation loss: 2.548172812904429

Epoch: 6| Step: 6
Training loss: 2.801006824129638
Validation loss: 2.5584868733705814

Epoch: 6| Step: 7
Training loss: 2.33828627473984
Validation loss: 2.5422883220798433

Epoch: 6| Step: 8
Training loss: 2.501582884362948
Validation loss: 2.559074232871249

Epoch: 6| Step: 9
Training loss: 2.617860075659588
Validation loss: 2.5468278743758352

Epoch: 6| Step: 10
Training loss: 2.8831707491450427
Validation loss: 2.528382983173415

Epoch: 6| Step: 11
Training loss: 2.1599086736869717
Validation loss: 2.5515250008150234

Epoch: 6| Step: 12
Training loss: 2.8064979086888004
Validation loss: 2.5552171590409074

Epoch: 6| Step: 13
Training loss: 3.288141189532439
Validation loss: 2.557248643089202

Epoch: 60| Step: 0
Training loss: 2.3566408799454424
Validation loss: 2.546350283774963

Epoch: 6| Step: 1
Training loss: 2.006098390358892
Validation loss: 2.5524249148143445

Epoch: 6| Step: 2
Training loss: 3.295991318135725
Validation loss: 2.572365427287328

Epoch: 6| Step: 3
Training loss: 2.5075554166319973
Validation loss: 2.561534546650489

Epoch: 6| Step: 4
Training loss: 2.635571762969324
Validation loss: 2.5588506328397003

Epoch: 6| Step: 5
Training loss: 2.6827694266787843
Validation loss: 2.5561025693778525

Epoch: 6| Step: 6
Training loss: 3.0910450834048993
Validation loss: 2.538959078390241

Epoch: 6| Step: 7
Training loss: 3.061776834858251
Validation loss: 2.5537604096421114

Epoch: 6| Step: 8
Training loss: 2.830289233898538
Validation loss: 2.521526420039818

Epoch: 6| Step: 9
Training loss: 3.0230834122739516
Validation loss: 2.544838289325539

Epoch: 6| Step: 10
Training loss: 2.9491168882450602
Validation loss: 2.5382651304557187

Epoch: 6| Step: 11
Training loss: 2.3205699842010166
Validation loss: 2.5407452061988525

Epoch: 6| Step: 12
Training loss: 2.6326244977618476
Validation loss: 2.542432185265754

Epoch: 6| Step: 13
Training loss: 2.5225624480518394
Validation loss: 2.5465076704306098

Epoch: 61| Step: 0
Training loss: 2.437790290957273
Validation loss: 2.5411739962893414

Epoch: 6| Step: 1
Training loss: 2.2675844335345063
Validation loss: 2.5527630658964946

Epoch: 6| Step: 2
Training loss: 2.646230943094936
Validation loss: 2.5482086699988

Epoch: 6| Step: 3
Training loss: 2.740930426704484
Validation loss: 2.531831359338938

Epoch: 6| Step: 4
Training loss: 2.1141993983702996
Validation loss: 2.52797667909182

Epoch: 6| Step: 5
Training loss: 2.4430433963976426
Validation loss: 2.5444249907812977

Epoch: 6| Step: 6
Training loss: 2.701155016357595
Validation loss: 2.5603735209379677

Epoch: 6| Step: 7
Training loss: 2.576833505530027
Validation loss: 2.561622297237781

Epoch: 6| Step: 8
Training loss: 3.0146716888984284
Validation loss: 2.5292129624944955

Epoch: 6| Step: 9
Training loss: 3.5266683107118673
Validation loss: 2.5358561034832507

Epoch: 6| Step: 10
Training loss: 2.145202753937088
Validation loss: 2.542057733156877

Epoch: 6| Step: 11
Training loss: 2.4445366649378744
Validation loss: 2.5450685437255194

Epoch: 6| Step: 12
Training loss: 3.5141500812368602
Validation loss: 2.548009439982106

Epoch: 6| Step: 13
Training loss: 2.9777509264265176
Validation loss: 2.548486420888345

Epoch: 62| Step: 0
Training loss: 3.028737865743288
Validation loss: 2.537825388069773

Epoch: 6| Step: 1
Training loss: 2.6105969702905663
Validation loss: 2.5439378259733787

Epoch: 6| Step: 2
Training loss: 1.7375241120126763
Validation loss: 2.5548703139323456

Epoch: 6| Step: 3
Training loss: 2.784432893744147
Validation loss: 2.5565892411817392

Epoch: 6| Step: 4
Training loss: 2.2779330870033796
Validation loss: 2.5506707041113414

Epoch: 6| Step: 5
Training loss: 2.765325756371006
Validation loss: 2.549178434124068

Epoch: 6| Step: 6
Training loss: 2.6179366676416125
Validation loss: 2.536252794092928

Epoch: 6| Step: 7
Training loss: 3.003518584278845
Validation loss: 2.5455147493958004

Epoch: 6| Step: 8
Training loss: 2.5483180913309256
Validation loss: 2.5297376002840672

Epoch: 6| Step: 9
Training loss: 3.4017034863266256
Validation loss: 2.52916476782506

Epoch: 6| Step: 10
Training loss: 3.031746420570589
Validation loss: 2.5613106053967254

Epoch: 6| Step: 11
Training loss: 2.661855549791638
Validation loss: 2.5541179827857996

Epoch: 6| Step: 12
Training loss: 2.536870391608444
Validation loss: 2.5416324252749356

Epoch: 6| Step: 13
Training loss: 3.0351669330973507
Validation loss: 2.534738195446429

Epoch: 63| Step: 0
Training loss: 2.62074552630496
Validation loss: 2.54415183983974

Epoch: 6| Step: 1
Training loss: 3.529032187994171
Validation loss: 2.5489876708787262

Epoch: 6| Step: 2
Training loss: 3.1301760722109533
Validation loss: 2.5454918211823325

Epoch: 6| Step: 3
Training loss: 2.199947256843183
Validation loss: 2.5435358137963555

Epoch: 6| Step: 4
Training loss: 3.073865082499581
Validation loss: 2.549346350889471

Epoch: 6| Step: 5
Training loss: 2.6066776427926523
Validation loss: 2.5541518157351657

Epoch: 6| Step: 6
Training loss: 2.7955278956509355
Validation loss: 2.55664984816723

Epoch: 6| Step: 7
Training loss: 2.6342867111308195
Validation loss: 2.5530127863018577

Epoch: 6| Step: 8
Training loss: 2.737204259635379
Validation loss: 2.5499968946350737

Epoch: 6| Step: 9
Training loss: 3.0757021590788507
Validation loss: 2.552279588906168

Epoch: 6| Step: 10
Training loss: 2.653567945980111
Validation loss: 2.548505329591904

Epoch: 6| Step: 11
Training loss: 1.8688867729428036
Validation loss: 2.548593863754059

Epoch: 6| Step: 12
Training loss: 2.127066112701421
Validation loss: 2.542777598526017

Epoch: 6| Step: 13
Training loss: 2.8212740202199376
Validation loss: 2.540231985341094

Epoch: 64| Step: 0
Training loss: 2.2647824529463274
Validation loss: 2.5502747282152534

Epoch: 6| Step: 1
Training loss: 2.997896410617609
Validation loss: 2.547292933122589

Epoch: 6| Step: 2
Training loss: 2.5809129841327545
Validation loss: 2.549872573983977

Epoch: 6| Step: 3
Training loss: 2.7216157388993416
Validation loss: 2.5366288429107224

Epoch: 6| Step: 4
Training loss: 2.3789505476812645
Validation loss: 2.5466784405096563

Epoch: 6| Step: 5
Training loss: 3.297936435880386
Validation loss: 2.5664478687645182

Epoch: 6| Step: 6
Training loss: 2.475818510247634
Validation loss: 2.5308662416344254

Epoch: 6| Step: 7
Training loss: 2.9275070010524207
Validation loss: 2.5642529606234614

Epoch: 6| Step: 8
Training loss: 2.395374442118923
Validation loss: 2.5570423404084686

Epoch: 6| Step: 9
Training loss: 3.148032642772069
Validation loss: 2.550653837725699

Epoch: 6| Step: 10
Training loss: 2.5733404904432367
Validation loss: 2.5587377845059027

Epoch: 6| Step: 11
Training loss: 2.8625147523458216
Validation loss: 2.54370962195907

Epoch: 6| Step: 12
Training loss: 2.6894088885534537
Validation loss: 2.533997374404486

Epoch: 6| Step: 13
Training loss: 2.613920261961863
Validation loss: 2.5315204092581056

Epoch: 65| Step: 0
Training loss: 2.1603911066949704
Validation loss: 2.547995250425353

Epoch: 6| Step: 1
Training loss: 2.471398779597378
Validation loss: 2.547599252142824

Epoch: 6| Step: 2
Training loss: 2.920456812412069
Validation loss: 2.5544131772915715

Epoch: 6| Step: 3
Training loss: 3.249687766702316
Validation loss: 2.544011361071288

Epoch: 6| Step: 4
Training loss: 2.465997247674277
Validation loss: 2.5436213234621543

Epoch: 6| Step: 5
Training loss: 2.4377769899709922
Validation loss: 2.5507668577672407

Epoch: 6| Step: 6
Training loss: 3.1641905958831233
Validation loss: 2.5395981908067142

Epoch: 6| Step: 7
Training loss: 3.2159943868009253
Validation loss: 2.5438328903450507

Epoch: 6| Step: 8
Training loss: 2.7180571276097556
Validation loss: 2.5473190978349702

Epoch: 6| Step: 9
Training loss: 2.771034424638521
Validation loss: 2.545408794062897

Epoch: 6| Step: 10
Training loss: 2.8436183689380017
Validation loss: 2.5378609287091463

Epoch: 6| Step: 11
Training loss: 1.7861218668506882
Validation loss: 2.5406018055014723

Epoch: 6| Step: 12
Training loss: 3.1940073644926983
Validation loss: 2.538272079226837

Epoch: 6| Step: 13
Training loss: 1.6604947810862059
Validation loss: 2.5497000033833155

Epoch: 66| Step: 0
Training loss: 3.0300392800482396
Validation loss: 2.5445881132683517

Epoch: 6| Step: 1
Training loss: 2.8599619445403026
Validation loss: 2.552540993019181

Epoch: 6| Step: 2
Training loss: 2.5227440982666782
Validation loss: 2.5417800362282335

Epoch: 6| Step: 3
Training loss: 1.9629194722499352
Validation loss: 2.5534823218138984

Epoch: 6| Step: 4
Training loss: 2.684307597583105
Validation loss: 2.5327450028892953

Epoch: 6| Step: 5
Training loss: 3.163375214707139
Validation loss: 2.5286876541984284

Epoch: 6| Step: 6
Training loss: 2.2391536803224477
Validation loss: 2.5278157097210165

Epoch: 6| Step: 7
Training loss: 3.002563017502258
Validation loss: 2.5446152417387924

Epoch: 6| Step: 8
Training loss: 2.8017316878846943
Validation loss: 2.5493310374594875

Epoch: 6| Step: 9
Training loss: 2.64650878894989
Validation loss: 2.540378141731524

Epoch: 6| Step: 10
Training loss: 2.2464597188266135
Validation loss: 2.5413508132390916

Epoch: 6| Step: 11
Training loss: 3.0048048959572324
Validation loss: 2.5465700727093283

Epoch: 6| Step: 12
Training loss: 2.6675313699981706
Validation loss: 2.544204915773555

Epoch: 6| Step: 13
Training loss: 3.1467074428222417
Validation loss: 2.539370631601664

Epoch: 67| Step: 0
Training loss: 3.2672413015656265
Validation loss: 2.5423558808803417

Epoch: 6| Step: 1
Training loss: 2.032796417806052
Validation loss: 2.544486222509513

Epoch: 6| Step: 2
Training loss: 3.081576044191948
Validation loss: 2.5617483844047566

Epoch: 6| Step: 3
Training loss: 2.166720744216187
Validation loss: 2.5416539711503177

Epoch: 6| Step: 4
Training loss: 3.059087915559484
Validation loss: 2.5471372345431993

Epoch: 6| Step: 5
Training loss: 2.5094089833543967
Validation loss: 2.5409710199571087

Epoch: 6| Step: 6
Training loss: 3.2740419690070155
Validation loss: 2.51766630690195

Epoch: 6| Step: 7
Training loss: 2.446724675848163
Validation loss: 2.5332890446644565

Epoch: 6| Step: 8
Training loss: 2.1495093428947105
Validation loss: 2.5576898592171258

Epoch: 6| Step: 9
Training loss: 2.8657535636458396
Validation loss: 2.5241418732500582

Epoch: 6| Step: 10
Training loss: 2.8384882277378476
Validation loss: 2.5370248306517436

Epoch: 6| Step: 11
Training loss: 2.775989486652441
Validation loss: 2.530212773202927

Epoch: 6| Step: 12
Training loss: 2.3523767018615316
Validation loss: 2.5407958742053154

Epoch: 6| Step: 13
Training loss: 2.652749571281343
Validation loss: 2.525351062413342

Epoch: 68| Step: 0
Training loss: 2.5657141462071738
Validation loss: 2.528426202198726

Epoch: 6| Step: 1
Training loss: 2.8893796145340205
Validation loss: 2.540024581139758

Epoch: 6| Step: 2
Training loss: 2.1365819465317974
Validation loss: 2.5381687779255295

Epoch: 6| Step: 3
Training loss: 2.9372712715866376
Validation loss: 2.5209848746020147

Epoch: 6| Step: 4
Training loss: 2.888261478305839
Validation loss: 2.532814954960061

Epoch: 6| Step: 5
Training loss: 2.7542392826943467
Validation loss: 2.5440078129012167

Epoch: 6| Step: 6
Training loss: 3.050028416235454
Validation loss: 2.54489982188139

Epoch: 6| Step: 7
Training loss: 2.949567640269734
Validation loss: 2.538503934066519

Epoch: 6| Step: 8
Training loss: 2.030076142560245
Validation loss: 2.5349147129244276

Epoch: 6| Step: 9
Training loss: 3.1382039165773605
Validation loss: 2.5240992197197905

Epoch: 6| Step: 10
Training loss: 2.5045654571746496
Validation loss: 2.5379358853698184

Epoch: 6| Step: 11
Training loss: 2.6681617678166143
Validation loss: 2.5189333764147213

Epoch: 6| Step: 12
Training loss: 2.3580037357342793
Validation loss: 2.5516939205559814

Epoch: 6| Step: 13
Training loss: 2.771599474849643
Validation loss: 2.529659561061416

Epoch: 69| Step: 0
Training loss: 2.300755343590885
Validation loss: 2.538714205168215

Epoch: 6| Step: 1
Training loss: 2.8037095769110247
Validation loss: 2.540491250586896

Epoch: 6| Step: 2
Training loss: 2.65517610271213
Validation loss: 2.5507034455472337

Epoch: 6| Step: 3
Training loss: 2.8046828246011257
Validation loss: 2.5291485010172403

Epoch: 6| Step: 4
Training loss: 2.461053367188014
Validation loss: 2.551752247198028

Epoch: 6| Step: 5
Training loss: 2.4467100592081943
Validation loss: 2.5338456045035036

Epoch: 6| Step: 6
Training loss: 2.5110273343949023
Validation loss: 2.5463456414608947

Epoch: 6| Step: 7
Training loss: 2.3962531565056886
Validation loss: 2.542671695494389

Epoch: 6| Step: 8
Training loss: 2.0563207596775626
Validation loss: 2.535090928385087

Epoch: 6| Step: 9
Training loss: 3.317463161606061
Validation loss: 2.536328379976455

Epoch: 6| Step: 10
Training loss: 3.850229647834588
Validation loss: 2.5400526152343352

Epoch: 6| Step: 11
Training loss: 2.497389193072887
Validation loss: 2.5599183374404535

Epoch: 6| Step: 12
Training loss: 2.9724276601396347
Validation loss: 2.5479247824046496

Epoch: 6| Step: 13
Training loss: 1.8496678311900048
Validation loss: 2.5302647504181155

Epoch: 70| Step: 0
Training loss: 2.2369075907283267
Validation loss: 2.5429121429245636

Epoch: 6| Step: 1
Training loss: 2.5511536027040482
Validation loss: 2.5403536473523327

Epoch: 6| Step: 2
Training loss: 2.8072870899698654
Validation loss: 2.5305088355279413

Epoch: 6| Step: 3
Training loss: 3.0425069162232177
Validation loss: 2.5483892084019235

Epoch: 6| Step: 4
Training loss: 3.197902981773362
Validation loss: 2.528713508569629

Epoch: 6| Step: 5
Training loss: 2.2900327117116097
Validation loss: 2.542292751972158

Epoch: 6| Step: 6
Training loss: 3.008272844236555
Validation loss: 2.5414006167770213

Epoch: 6| Step: 7
Training loss: 3.1709043022832275
Validation loss: 2.5360507557188177

Epoch: 6| Step: 8
Training loss: 2.3469827355496284
Validation loss: 2.5450133039502005

Epoch: 6| Step: 9
Training loss: 3.188065273052247
Validation loss: 2.5297984391295083

Epoch: 6| Step: 10
Training loss: 2.763583706908537
Validation loss: 2.534070090688319

Epoch: 6| Step: 11
Training loss: 2.350347870584789
Validation loss: 2.5399817461897363

Epoch: 6| Step: 12
Training loss: 2.0435528768031737
Validation loss: 2.5425434190660128

Epoch: 6| Step: 13
Training loss: 2.0289234629221466
Validation loss: 2.541770669338057

Epoch: 71| Step: 0
Training loss: 2.5620457316358842
Validation loss: 2.525910679565397

Epoch: 6| Step: 1
Training loss: 2.2569474935918574
Validation loss: 2.5361504173391958

Epoch: 6| Step: 2
Training loss: 3.186135991280291
Validation loss: 2.5380923271852374

Epoch: 6| Step: 3
Training loss: 2.8092047142214125
Validation loss: 2.543304145014206

Epoch: 6| Step: 4
Training loss: 1.983731142854633
Validation loss: 2.533733555807447

Epoch: 6| Step: 5
Training loss: 2.8858206749584387
Validation loss: 2.5321311930984383

Epoch: 6| Step: 6
Training loss: 2.4145301933683703
Validation loss: 2.527042082136143

Epoch: 6| Step: 7
Training loss: 3.255836381470622
Validation loss: 2.517775091451016

Epoch: 6| Step: 8
Training loss: 2.6420739165830462
Validation loss: 2.5380550716393397

Epoch: 6| Step: 9
Training loss: 2.7804841262207867
Validation loss: 2.5377038937723984

Epoch: 6| Step: 10
Training loss: 2.5505326107522603
Validation loss: 2.532078720627715

Epoch: 6| Step: 11
Training loss: 3.1561152363324387
Validation loss: 2.5548059449151497

Epoch: 6| Step: 12
Training loss: 2.5251908485124708
Validation loss: 2.544576449559202

Epoch: 6| Step: 13
Training loss: 1.960831232725035
Validation loss: 2.5452277038075257

Epoch: 72| Step: 0
Training loss: 2.669690404651718
Validation loss: 2.5270233009469467

Epoch: 6| Step: 1
Training loss: 2.5098452306806123
Validation loss: 2.5363778298233193

Epoch: 6| Step: 2
Training loss: 2.9484060216051153
Validation loss: 2.5522266065617756

Epoch: 6| Step: 3
Training loss: 2.4484757021788384
Validation loss: 2.522411529382482

Epoch: 6| Step: 4
Training loss: 2.3286962640350106
Validation loss: 2.553366307487171

Epoch: 6| Step: 5
Training loss: 2.1097522539528386
Validation loss: 2.5254324877585987

Epoch: 6| Step: 6
Training loss: 2.9919796864029102
Validation loss: 2.5540909090774506

Epoch: 6| Step: 7
Training loss: 2.653798127351141
Validation loss: 2.5380038236637095

Epoch: 6| Step: 8
Training loss: 2.9684003122074327
Validation loss: 2.5521665203373325

Epoch: 6| Step: 9
Training loss: 2.6656723751674654
Validation loss: 2.5328957704260984

Epoch: 6| Step: 10
Training loss: 2.893896777259701
Validation loss: 2.5235207603406193

Epoch: 6| Step: 11
Training loss: 3.011105327749231
Validation loss: 2.526945674507355

Epoch: 6| Step: 12
Training loss: 2.5707922026952073
Validation loss: 2.5366566558103933

Epoch: 6| Step: 13
Training loss: 2.546026825822705
Validation loss: 2.5519431488598614

Epoch: 73| Step: 0
Training loss: 2.083247017661775
Validation loss: 2.525972145442396

Epoch: 6| Step: 1
Training loss: 1.9595514999789994
Validation loss: 2.526266051055602

Epoch: 6| Step: 2
Training loss: 3.2416734402805614
Validation loss: 2.534658532591054

Epoch: 6| Step: 3
Training loss: 2.323147566970278
Validation loss: 2.524369520571663

Epoch: 6| Step: 4
Training loss: 3.3583839551519667
Validation loss: 2.5431260485492424

Epoch: 6| Step: 5
Training loss: 2.319750168601473
Validation loss: 2.53660062342083

Epoch: 6| Step: 6
Training loss: 2.6162143093541634
Validation loss: 2.5276296722387053

Epoch: 6| Step: 7
Training loss: 2.596592643802474
Validation loss: 2.5488791814919147

Epoch: 6| Step: 8
Training loss: 3.0739998842535945
Validation loss: 2.5230463689265714

Epoch: 6| Step: 9
Training loss: 2.8144405875631575
Validation loss: 2.544401472392472

Epoch: 6| Step: 10
Training loss: 2.6382527727979874
Validation loss: 2.5349324905635173

Epoch: 6| Step: 11
Training loss: 2.5848617851745597
Validation loss: 2.5470219457810863

Epoch: 6| Step: 12
Training loss: 2.376903373554928
Validation loss: 2.5394904107535585

Epoch: 6| Step: 13
Training loss: 3.5394359669460513
Validation loss: 2.53758188953388

Epoch: 74| Step: 0
Training loss: 2.365363598671134
Validation loss: 2.551025718111485

Epoch: 6| Step: 1
Training loss: 2.2246387402720558
Validation loss: 2.54153255395947

Epoch: 6| Step: 2
Training loss: 2.5030134159510427
Validation loss: 2.5301225106611933

Epoch: 6| Step: 3
Training loss: 2.4858693361078275
Validation loss: 2.535102012801531

Epoch: 6| Step: 4
Training loss: 2.7024813199875393
Validation loss: 2.5450702108019807

Epoch: 6| Step: 5
Training loss: 2.8046477163569423
Validation loss: 2.527196427931654

Epoch: 6| Step: 6
Training loss: 2.7463562841254716
Validation loss: 2.524233509478525

Epoch: 6| Step: 7
Training loss: 2.7046807723730235
Validation loss: 2.543939014104461

Epoch: 6| Step: 8
Training loss: 2.95024945772268
Validation loss: 2.53668031775854

Epoch: 6| Step: 9
Training loss: 2.294478327316505
Validation loss: 2.5614626836061505

Epoch: 6| Step: 10
Training loss: 3.4313711843300894
Validation loss: 2.525590570427012

Epoch: 6| Step: 11
Training loss: 2.5202987566465023
Validation loss: 2.533246376145977

Epoch: 6| Step: 12
Training loss: 2.769270224167893
Validation loss: 2.512840893387123

Epoch: 6| Step: 13
Training loss: 2.951751227981391
Validation loss: 2.5457083106380924

Epoch: 75| Step: 0
Training loss: 1.9867889259896072
Validation loss: 2.53951508305494

Epoch: 6| Step: 1
Training loss: 2.5556450312149632
Validation loss: 2.545663194660855

Epoch: 6| Step: 2
Training loss: 2.4163706587233995
Validation loss: 2.5064607016282663

Epoch: 6| Step: 3
Training loss: 3.3954762152056586
Validation loss: 2.53685717152661

Epoch: 6| Step: 4
Training loss: 2.130914199641297
Validation loss: 2.5440956833228543

Epoch: 6| Step: 5
Training loss: 2.197474599437577
Validation loss: 2.542865952028774

Epoch: 6| Step: 6
Training loss: 2.905228958430526
Validation loss: 2.532660410025457

Epoch: 6| Step: 7
Training loss: 3.052921809265073
Validation loss: 2.5485095545317615

Epoch: 6| Step: 8
Training loss: 2.603549416187547
Validation loss: 2.5469675677008152

Epoch: 6| Step: 9
Training loss: 2.5082176570474326
Validation loss: 2.5398217980984197

Epoch: 6| Step: 10
Training loss: 2.919359889218998
Validation loss: 2.5315642177669737

Epoch: 6| Step: 11
Training loss: 2.9014590572063104
Validation loss: 2.53115305429443

Epoch: 6| Step: 12
Training loss: 2.890902284261936
Validation loss: 2.533776289982289

Epoch: 6| Step: 13
Training loss: 2.566016598737732
Validation loss: 2.5484012228492596

Epoch: 76| Step: 0
Training loss: 3.5329326570399964
Validation loss: 2.5420849390548557

Epoch: 6| Step: 1
Training loss: 2.430882396218123
Validation loss: 2.528221563087175

Epoch: 6| Step: 2
Training loss: 2.3180405510818747
Validation loss: 2.5592536050971337

Epoch: 6| Step: 3
Training loss: 2.8569742766101194
Validation loss: 2.549309527304968

Epoch: 6| Step: 4
Training loss: 2.1639241198423633
Validation loss: 2.53010099932258

Epoch: 6| Step: 5
Training loss: 3.179705495572541
Validation loss: 2.547729624603079

Epoch: 6| Step: 6
Training loss: 2.5244223736565314
Validation loss: 2.5423905283082164

Epoch: 6| Step: 7
Training loss: 2.9584085338508643
Validation loss: 2.5312449679165794

Epoch: 6| Step: 8
Training loss: 1.872201229446899
Validation loss: 2.548389215443817

Epoch: 6| Step: 9
Training loss: 1.8596152783464306
Validation loss: 2.519551085203009

Epoch: 6| Step: 10
Training loss: 3.2132301777259635
Validation loss: 2.515111724233504

Epoch: 6| Step: 11
Training loss: 2.833416787956707
Validation loss: 2.537955849465259

Epoch: 6| Step: 12
Training loss: 2.447599371508876
Validation loss: 2.532997181609946

Epoch: 6| Step: 13
Training loss: 2.8933580829364605
Validation loss: 2.53861084611845

Epoch: 77| Step: 0
Training loss: 2.70606931299052
Validation loss: 2.521739871630457

Epoch: 6| Step: 1
Training loss: 2.50480647574958
Validation loss: 2.530090443197009

Epoch: 6| Step: 2
Training loss: 2.9065699247423917
Validation loss: 2.536221008322685

Epoch: 6| Step: 3
Training loss: 2.439509223922114
Validation loss: 2.531876859494405

Epoch: 6| Step: 4
Training loss: 2.6110625149779167
Validation loss: 2.5443423701711576

Epoch: 6| Step: 5
Training loss: 2.5440961972408647
Validation loss: 2.5074174373211133

Epoch: 6| Step: 6
Training loss: 2.84039813353812
Validation loss: 2.520987480967336

Epoch: 6| Step: 7
Training loss: 2.2113297724418657
Validation loss: 2.5387348639515555

Epoch: 6| Step: 8
Training loss: 2.3127015515721623
Validation loss: 2.5155459665265254

Epoch: 6| Step: 9
Training loss: 3.502505087130635
Validation loss: 2.533196576745733

Epoch: 6| Step: 10
Training loss: 2.33903731521778
Validation loss: 2.5465173798005285

Epoch: 6| Step: 11
Training loss: 3.068607856892491
Validation loss: 2.5175318185655566

Epoch: 6| Step: 12
Training loss: 2.530199657146288
Validation loss: 2.542543316219647

Epoch: 6| Step: 13
Training loss: 2.8500745261637457
Validation loss: 2.515387266351429

Epoch: 78| Step: 0
Training loss: 2.1817776629269026
Validation loss: 2.5232145276402536

Epoch: 6| Step: 1
Training loss: 3.6602518726670032
Validation loss: 2.541162054105384

Epoch: 6| Step: 2
Training loss: 2.6307935812694496
Validation loss: 2.5242669767031365

Epoch: 6| Step: 3
Training loss: 2.4430092393760523
Validation loss: 2.537718570214179

Epoch: 6| Step: 4
Training loss: 2.7787495206145207
Validation loss: 2.5249401776661173

Epoch: 6| Step: 5
Training loss: 2.567673276051934
Validation loss: 2.5312077640163078

Epoch: 6| Step: 6
Training loss: 3.1222318977969277
Validation loss: 2.5267607747559473

Epoch: 6| Step: 7
Training loss: 2.21062464573032
Validation loss: 2.528171846727497

Epoch: 6| Step: 8
Training loss: 3.2059188939506633
Validation loss: 2.5256605826057124

Epoch: 6| Step: 9
Training loss: 2.3372434709918632
Validation loss: 2.5203149107021865

Epoch: 6| Step: 10
Training loss: 1.8862255391632452
Validation loss: 2.5223465098984557

Epoch: 6| Step: 11
Training loss: 2.932474748351508
Validation loss: 2.527990259985763

Epoch: 6| Step: 12
Training loss: 2.113391584241379
Validation loss: 2.5106545425255917

Epoch: 6| Step: 13
Training loss: 2.88194679556346
Validation loss: 2.530570883670517

Epoch: 79| Step: 0
Training loss: 2.7285778390813373
Validation loss: 2.5491515020513784

Epoch: 6| Step: 1
Training loss: 2.9196220320545936
Validation loss: 2.5268329931536404

Epoch: 6| Step: 2
Training loss: 2.9277011495362864
Validation loss: 2.5387199272984415

Epoch: 6| Step: 3
Training loss: 2.5286189404258064
Validation loss: 2.5247595282359057

Epoch: 6| Step: 4
Training loss: 2.983551391077124
Validation loss: 2.5259743467865894

Epoch: 6| Step: 5
Training loss: 1.8708367858152528
Validation loss: 2.5587063932793606

Epoch: 6| Step: 6
Training loss: 2.907010870977178
Validation loss: 2.5316976163874276

Epoch: 6| Step: 7
Training loss: 2.514762588428512
Validation loss: 2.5415080232969

Epoch: 6| Step: 8
Training loss: 2.3281534692444525
Validation loss: 2.5391203378506066

Epoch: 6| Step: 9
Training loss: 3.0955249049152687
Validation loss: 2.5322115950497217

Epoch: 6| Step: 10
Training loss: 2.62995171129113
Validation loss: 2.5377445760382695

Epoch: 6| Step: 11
Training loss: 2.447558848966217
Validation loss: 2.520986472183263

Epoch: 6| Step: 12
Training loss: 2.736350343275027
Validation loss: 2.5313914249501686

Epoch: 6| Step: 13
Training loss: 2.692450023389197
Validation loss: 2.518054797350546

Epoch: 80| Step: 0
Training loss: 2.5336122204545184
Validation loss: 2.5280829391206305

Epoch: 6| Step: 1
Training loss: 2.160784831691297
Validation loss: 2.5373141561123416

Epoch: 6| Step: 2
Training loss: 2.9311314800841055
Validation loss: 2.524560120185518

Epoch: 6| Step: 3
Training loss: 2.15365366874724
Validation loss: 2.538711526118253

Epoch: 6| Step: 4
Training loss: 3.3321006561957307
Validation loss: 2.545843064683118

Epoch: 6| Step: 5
Training loss: 2.227695645218581
Validation loss: 2.545780172293623

Epoch: 6| Step: 6
Training loss: 3.3600420622236427
Validation loss: 2.53004817974975

Epoch: 6| Step: 7
Training loss: 2.068560395094689
Validation loss: 2.527763639044147

Epoch: 6| Step: 8
Training loss: 3.0251977020476875
Validation loss: 2.535826605618044

Epoch: 6| Step: 9
Training loss: 2.907901089818728
Validation loss: 2.5092966689783687

Epoch: 6| Step: 10
Training loss: 2.258868119191805
Validation loss: 2.5227478277587756

Epoch: 6| Step: 11
Training loss: 2.314598162649624
Validation loss: 2.526079695457313

Epoch: 6| Step: 12
Training loss: 3.019017026476059
Validation loss: 2.5129886244917397

Epoch: 6| Step: 13
Training loss: 2.441871928244095
Validation loss: 2.536132783185455

Epoch: 81| Step: 0
Training loss: 2.070276454395821
Validation loss: 2.5215950281822717

Epoch: 6| Step: 1
Training loss: 3.090876622462968
Validation loss: 2.5296373384036155

Epoch: 6| Step: 2
Training loss: 3.7667171429878192
Validation loss: 2.535309639710712

Epoch: 6| Step: 3
Training loss: 2.1751575500602773
Validation loss: 2.5282652655040883

Epoch: 6| Step: 4
Training loss: 2.744234804322488
Validation loss: 2.5408745359582796

Epoch: 6| Step: 5
Training loss: 2.3508699227340766
Validation loss: 2.5169350253707394

Epoch: 6| Step: 6
Training loss: 2.582270024003624
Validation loss: 2.510654121319953

Epoch: 6| Step: 7
Training loss: 2.1419410836516866
Validation loss: 2.531539236072875

Epoch: 6| Step: 8
Training loss: 2.669043217080067
Validation loss: 2.5297432256712

Epoch: 6| Step: 9
Training loss: 2.9041221786732923
Validation loss: 2.5337379783969545

Epoch: 6| Step: 10
Training loss: 2.8690814589287545
Validation loss: 2.534977589695656

Epoch: 6| Step: 11
Training loss: 1.9985843058716317
Validation loss: 2.533082788447752

Epoch: 6| Step: 12
Training loss: 2.274989905701764
Validation loss: 2.543073976331721

Epoch: 6| Step: 13
Training loss: 3.2374452033984027
Validation loss: 2.5335864605949165

Epoch: 82| Step: 0
Training loss: 3.036287349818278
Validation loss: 2.5335868582567715

Epoch: 6| Step: 1
Training loss: 2.8117233899569247
Validation loss: 2.532186490152449

Epoch: 6| Step: 2
Training loss: 2.561238606447614
Validation loss: 2.5168139140469483

Epoch: 6| Step: 3
Training loss: 2.6506687544053964
Validation loss: 2.5312021044098185

Epoch: 6| Step: 4
Training loss: 2.291748658071753
Validation loss: 2.5178435401379917

Epoch: 6| Step: 5
Training loss: 2.3257705765115033
Validation loss: 2.527972158195616

Epoch: 6| Step: 6
Training loss: 3.259337143938762
Validation loss: 2.525470867984923

Epoch: 6| Step: 7
Training loss: 2.3591028523907047
Validation loss: 2.511624606567138

Epoch: 6| Step: 8
Training loss: 2.049647193881124
Validation loss: 2.5129195875408974

Epoch: 6| Step: 9
Training loss: 2.9210141795753533
Validation loss: 2.521045972465687

Epoch: 6| Step: 10
Training loss: 2.3760032542556413
Validation loss: 2.53059377080152

Epoch: 6| Step: 11
Training loss: 2.396081121042638
Validation loss: 2.5338166154240027

Epoch: 6| Step: 12
Training loss: 3.1646315074783984
Validation loss: 2.517839604834371

Epoch: 6| Step: 13
Training loss: 2.865006701077119
Validation loss: 2.5252314481085576

Epoch: 83| Step: 0
Training loss: 2.7144249901855364
Validation loss: 2.541696669994715

Epoch: 6| Step: 1
Training loss: 2.508904430310108
Validation loss: 2.5338314292169235

Epoch: 6| Step: 2
Training loss: 2.3743520153888213
Validation loss: 2.512179858445628

Epoch: 6| Step: 3
Training loss: 2.323353120545347
Validation loss: 2.526697907594646

Epoch: 6| Step: 4
Training loss: 2.1920526268621163
Validation loss: 2.529634388272334

Epoch: 6| Step: 5
Training loss: 2.1608328285711984
Validation loss: 2.5066720887318374

Epoch: 6| Step: 6
Training loss: 2.484397936061333
Validation loss: 2.519702848743772

Epoch: 6| Step: 7
Training loss: 2.8727408115783457
Validation loss: 2.528480151686823

Epoch: 6| Step: 8
Training loss: 2.6814338176468966
Validation loss: 2.516834273852445

Epoch: 6| Step: 9
Training loss: 3.2760843942319133
Validation loss: 2.507954191689558

Epoch: 6| Step: 10
Training loss: 3.307736552595958
Validation loss: 2.520963559862914

Epoch: 6| Step: 11
Training loss: 3.494406590326613
Validation loss: 2.538218347965004

Epoch: 6| Step: 12
Training loss: 2.142111603152676
Validation loss: 2.5336679840173617

Epoch: 6| Step: 13
Training loss: 1.8660909712961682
Validation loss: 2.52867508986401

Epoch: 84| Step: 0
Training loss: 2.4330133079607
Validation loss: 2.5185921215679694

Epoch: 6| Step: 1
Training loss: 2.6079918399168265
Validation loss: 2.5539713248293485

Epoch: 6| Step: 2
Training loss: 2.838323424929223
Validation loss: 2.537910816894199

Epoch: 6| Step: 3
Training loss: 2.344248299079694
Validation loss: 2.51873451475888

Epoch: 6| Step: 4
Training loss: 2.7390684990564207
Validation loss: 2.5453375846540096

Epoch: 6| Step: 5
Training loss: 2.2918118055217165
Validation loss: 2.512195365680402

Epoch: 6| Step: 6
Training loss: 2.892907473548488
Validation loss: 2.5242955879694358

Epoch: 6| Step: 7
Training loss: 3.2852810757720827
Validation loss: 2.53409243836218

Epoch: 6| Step: 8
Training loss: 2.2354105437077276
Validation loss: 2.516904051894278

Epoch: 6| Step: 9
Training loss: 2.5664541858394228
Validation loss: 2.532453907232729

Epoch: 6| Step: 10
Training loss: 2.6549508900958605
Validation loss: 2.517422597829883

Epoch: 6| Step: 11
Training loss: 2.237592607851335
Validation loss: 2.5280535280199476

Epoch: 6| Step: 12
Training loss: 3.026048740153272
Validation loss: 2.5099617756089034

Epoch: 6| Step: 13
Training loss: 2.505707519877549
Validation loss: 2.5117165004382245

Epoch: 85| Step: 0
Training loss: 3.0756837100258947
Validation loss: 2.52074887093433

Epoch: 6| Step: 1
Training loss: 2.7617341166585394
Validation loss: 2.51862015400307

Epoch: 6| Step: 2
Training loss: 2.5602304596283303
Validation loss: 2.5123954245090143

Epoch: 6| Step: 3
Training loss: 1.9565616737197036
Validation loss: 2.5349425446312015

Epoch: 6| Step: 4
Training loss: 2.447429776299662
Validation loss: 2.5314269546483215

Epoch: 6| Step: 5
Training loss: 2.407880354611504
Validation loss: 2.5289408771644437

Epoch: 6| Step: 6
Training loss: 2.467936128145334
Validation loss: 2.5128733268665737

Epoch: 6| Step: 7
Training loss: 3.3155116659599764
Validation loss: 2.5276951501581673

Epoch: 6| Step: 8
Training loss: 2.4863067410276907
Validation loss: 2.523966017761541

Epoch: 6| Step: 9
Training loss: 3.388209172300859
Validation loss: 2.528287006412086

Epoch: 6| Step: 10
Training loss: 2.277543806707873
Validation loss: 2.5514583710603436

Epoch: 6| Step: 11
Training loss: 2.670817918975991
Validation loss: 2.5267939000740625

Epoch: 6| Step: 12
Training loss: 2.2975228362665963
Validation loss: 2.534974635666125

Epoch: 6| Step: 13
Training loss: 2.980546182848993
Validation loss: 2.520344914594711

Epoch: 86| Step: 0
Training loss: 3.1272725806427775
Validation loss: 2.5140584731619913

Epoch: 6| Step: 1
Training loss: 2.4611565386462004
Validation loss: 2.5303095178518

Epoch: 6| Step: 2
Training loss: 2.8292554419123808
Validation loss: 2.5138584793757377

Epoch: 6| Step: 3
Training loss: 2.90122157052117
Validation loss: 2.5136110354341534

Epoch: 6| Step: 4
Training loss: 2.841655420931791
Validation loss: 2.530824061037305

Epoch: 6| Step: 5
Training loss: 1.6986784678956994
Validation loss: 2.529901704235312

Epoch: 6| Step: 6
Training loss: 2.413938056182659
Validation loss: 2.507091263248414

Epoch: 6| Step: 7
Training loss: 2.3182588987744284
Validation loss: 2.5273862513967504

Epoch: 6| Step: 8
Training loss: 3.2284045560900827
Validation loss: 2.5256561986542065

Epoch: 6| Step: 9
Training loss: 3.0058095629197865
Validation loss: 2.5045605285984087

Epoch: 6| Step: 10
Training loss: 2.3419626159811604
Validation loss: 2.5044893820100573

Epoch: 6| Step: 11
Training loss: 2.923019429849941
Validation loss: 2.509539567424314

Epoch: 6| Step: 12
Training loss: 2.354259579155651
Validation loss: 2.5284187427237526

Epoch: 6| Step: 13
Training loss: 1.8122559744891265
Validation loss: 2.515006425804851

Epoch: 87| Step: 0
Training loss: 2.541852996333238
Validation loss: 2.5099483157438143

Epoch: 6| Step: 1
Training loss: 2.814287168863431
Validation loss: 2.5137768264957514

Epoch: 6| Step: 2
Training loss: 2.7612953562916327
Validation loss: 2.5065287740243183

Epoch: 6| Step: 3
Training loss: 1.740385072564593
Validation loss: 2.525888049409955

Epoch: 6| Step: 4
Training loss: 2.7102166792333735
Validation loss: 2.531832902485611

Epoch: 6| Step: 5
Training loss: 2.6463935639401166
Validation loss: 2.5284060634922683

Epoch: 6| Step: 6
Training loss: 2.455324583952402
Validation loss: 2.520029482046435

Epoch: 6| Step: 7
Training loss: 3.255714088315114
Validation loss: 2.508869193732973

Epoch: 6| Step: 8
Training loss: 2.3367971414153503
Validation loss: 2.518921721640947

Epoch: 6| Step: 9
Training loss: 2.9460742886066633
Validation loss: 2.5291783793366847

Epoch: 6| Step: 10
Training loss: 2.9234277200051038
Validation loss: 2.5128645296416363

Epoch: 6| Step: 11
Training loss: 2.49171180131364
Validation loss: 2.535799397278792

Epoch: 6| Step: 12
Training loss: 2.520586038444903
Validation loss: 2.5284004351301106

Epoch: 6| Step: 13
Training loss: 2.7266416346917364
Validation loss: 2.5183751700981643

Epoch: 88| Step: 0
Training loss: 2.0637272737985795
Validation loss: 2.5022327153875863

Epoch: 6| Step: 1
Training loss: 2.238244181221188
Validation loss: 2.5079910807137513

Epoch: 6| Step: 2
Training loss: 3.4809457642566466
Validation loss: 2.513618512335425

Epoch: 6| Step: 3
Training loss: 2.3703581974701557
Validation loss: 2.5274609770598935

Epoch: 6| Step: 4
Training loss: 2.41460543455904
Validation loss: 2.521252668367337

Epoch: 6| Step: 5
Training loss: 2.534991948192081
Validation loss: 2.5079732250545437

Epoch: 6| Step: 6
Training loss: 2.8066724803287464
Validation loss: 2.497025584657273

Epoch: 6| Step: 7
Training loss: 2.673773375592232
Validation loss: 2.5230386379986345

Epoch: 6| Step: 8
Training loss: 2.2466369502802954
Validation loss: 2.523578396676633

Epoch: 6| Step: 9
Training loss: 2.5208657212712016
Validation loss: 2.508748371554911

Epoch: 6| Step: 10
Training loss: 2.0568539181894967
Validation loss: 2.5078747856310715

Epoch: 6| Step: 11
Training loss: 2.8352371065535977
Validation loss: 2.522176732569559

Epoch: 6| Step: 12
Training loss: 3.0198690168762874
Validation loss: 2.5197359691750827

Epoch: 6| Step: 13
Training loss: 3.2387469684994468
Validation loss: 2.535635135122863

Epoch: 89| Step: 0
Training loss: 3.2564714997091513
Validation loss: 2.506140351461187

Epoch: 6| Step: 1
Training loss: 2.0214121930047617
Validation loss: 2.533780417056047

Epoch: 6| Step: 2
Training loss: 2.5539435840490627
Validation loss: 2.4990297362539167

Epoch: 6| Step: 3
Training loss: 2.5929065849757573
Validation loss: 2.516184211749856

Epoch: 6| Step: 4
Training loss: 3.4094189942595747
Validation loss: 2.5258847203840196

Epoch: 6| Step: 5
Training loss: 2.756187587040043
Validation loss: 2.518045610985073

Epoch: 6| Step: 6
Training loss: 2.8227878179857324
Validation loss: 2.5046032958293427

Epoch: 6| Step: 7
Training loss: 2.6254563616102953
Validation loss: 2.516635207108813

Epoch: 6| Step: 8
Training loss: 2.174065672036078
Validation loss: 2.532555201477633

Epoch: 6| Step: 9
Training loss: 2.8552708589837184
Validation loss: 2.5371251421263876

Epoch: 6| Step: 10
Training loss: 2.3332116799203306
Validation loss: 2.5165670163965395

Epoch: 6| Step: 11
Training loss: 2.1643813135956633
Validation loss: 2.525731344965658

Epoch: 6| Step: 12
Training loss: 2.537034759716405
Validation loss: 2.521962250601295

Epoch: 6| Step: 13
Training loss: 2.5074349472720177
Validation loss: 2.514098437787426

Epoch: 90| Step: 0
Training loss: 2.7325733461858177
Validation loss: 2.5274514211837382

Epoch: 6| Step: 1
Training loss: 2.74842442546812
Validation loss: 2.501616545984927

Epoch: 6| Step: 2
Training loss: 2.654677879491194
Validation loss: 2.50637954163549

Epoch: 6| Step: 3
Training loss: 1.9747110372723138
Validation loss: 2.5360632769415377

Epoch: 6| Step: 4
Training loss: 2.5247350610407593
Validation loss: 2.519657690384856

Epoch: 6| Step: 5
Training loss: 3.2273282303964477
Validation loss: 2.5159097381831934

Epoch: 6| Step: 6
Training loss: 3.045146745424902
Validation loss: 2.497178708436968

Epoch: 6| Step: 7
Training loss: 2.3083433993380575
Validation loss: 2.5252982551601786

Epoch: 6| Step: 8
Training loss: 2.4904693133660314
Validation loss: 2.532596306061893

Epoch: 6| Step: 9
Training loss: 2.2783559967268165
Validation loss: 2.5485203331263606

Epoch: 6| Step: 10
Training loss: 2.423576102114745
Validation loss: 2.5119039481630883

Epoch: 6| Step: 11
Training loss: 3.1800439433294545
Validation loss: 2.5115397718755195

Epoch: 6| Step: 12
Training loss: 2.4890122230753815
Validation loss: 2.5402759584835457

Epoch: 6| Step: 13
Training loss: 2.2291730601376503
Validation loss: 2.534828225361293

Epoch: 91| Step: 0
Training loss: 2.7416032565435655
Validation loss: 2.5035014596819556

Epoch: 6| Step: 1
Training loss: 3.2320185383746582
Validation loss: 2.515469189007498

Epoch: 6| Step: 2
Training loss: 2.653579176994325
Validation loss: 2.5092207270389313

Epoch: 6| Step: 3
Training loss: 2.7284423993059788
Validation loss: 2.524817599305178

Epoch: 6| Step: 4
Training loss: 1.8618665398811758
Validation loss: 2.523586729886903

Epoch: 6| Step: 5
Training loss: 2.473060611005231
Validation loss: 2.5217500459010114

Epoch: 6| Step: 6
Training loss: 2.280527078706558
Validation loss: 2.5236513334281545

Epoch: 6| Step: 7
Training loss: 2.3906099406248003
Validation loss: 2.5238379038842615

Epoch: 6| Step: 8
Training loss: 3.133040802739546
Validation loss: 2.537235975065224

Epoch: 6| Step: 9
Training loss: 2.7152276735054333
Validation loss: 2.5197741111064427

Epoch: 6| Step: 10
Training loss: 2.4726730273793964
Validation loss: 2.5179838050043832

Epoch: 6| Step: 11
Training loss: 2.4349360552778867
Validation loss: 2.49929241606064

Epoch: 6| Step: 12
Training loss: 2.9585614899960913
Validation loss: 2.538860697334816

Epoch: 6| Step: 13
Training loss: 2.3612247315039743
Validation loss: 2.544122114696879

Epoch: 92| Step: 0
Training loss: 2.206867043117028
Validation loss: 2.5292584083942966

Epoch: 6| Step: 1
Training loss: 2.6763259667381356
Validation loss: 2.5217371166000926

Epoch: 6| Step: 2
Training loss: 2.795456169449362
Validation loss: 2.530317449968774

Epoch: 6| Step: 3
Training loss: 2.2693790246859
Validation loss: 2.5242207127409153

Epoch: 6| Step: 4
Training loss: 3.195516043524712
Validation loss: 2.522116090029828

Epoch: 6| Step: 5
Training loss: 2.669114856659786
Validation loss: 2.5183736675679804

Epoch: 6| Step: 6
Training loss: 2.1724479523318436
Validation loss: 2.5228053547300022

Epoch: 6| Step: 7
Training loss: 1.7456103174102242
Validation loss: 2.5212701686624883

Epoch: 6| Step: 8
Training loss: 2.7403236423561284
Validation loss: 2.51193472508569

Epoch: 6| Step: 9
Training loss: 2.6753232243709166
Validation loss: 2.502597126371378

Epoch: 6| Step: 10
Training loss: 3.3650946607496297
Validation loss: 2.485354396029436

Epoch: 6| Step: 11
Training loss: 2.0262175208282613
Validation loss: 2.51430106147021

Epoch: 6| Step: 12
Training loss: 3.4963414280283978
Validation loss: 2.4987517799098975

Epoch: 6| Step: 13
Training loss: 2.1535559146903416
Validation loss: 2.500989191156086

Epoch: 93| Step: 0
Training loss: 2.071283422279862
Validation loss: 2.513980862965076

Epoch: 6| Step: 1
Training loss: 2.9700568284271793
Validation loss: 2.4870163991046277

Epoch: 6| Step: 2
Training loss: 2.7602872902163695
Validation loss: 2.500694552713182

Epoch: 6| Step: 3
Training loss: 1.9807893091085829
Validation loss: 2.5096272217134064

Epoch: 6| Step: 4
Training loss: 3.443125335477299
Validation loss: 2.513816316283357

Epoch: 6| Step: 5
Training loss: 2.518272949174773
Validation loss: 2.511559818198527

Epoch: 6| Step: 6
Training loss: 2.6191093107281658
Validation loss: 2.51278539455091

Epoch: 6| Step: 7
Training loss: 2.2370256826932713
Validation loss: 2.5144533916765996

Epoch: 6| Step: 8
Training loss: 2.648181644110282
Validation loss: 2.5073227346477625

Epoch: 6| Step: 9
Training loss: 2.488624249686547
Validation loss: 2.4983662260823176

Epoch: 6| Step: 10
Training loss: 3.255806650742867
Validation loss: 2.508285573422151

Epoch: 6| Step: 11
Training loss: 2.4949227274088
Validation loss: 2.494667315414866

Epoch: 6| Step: 12
Training loss: 2.4637350015943382
Validation loss: 2.5118887366349663

Epoch: 6| Step: 13
Training loss: 2.214702191277876
Validation loss: 2.5110368139246724

Epoch: 94| Step: 0
Training loss: 2.6597045873506096
Validation loss: 2.503264688961153

Epoch: 6| Step: 1
Training loss: 2.2436292312975774
Validation loss: 2.519107978347249

Epoch: 6| Step: 2
Training loss: 2.6747028934514026
Validation loss: 2.5135192444850167

Epoch: 6| Step: 3
Training loss: 2.370102802574033
Validation loss: 2.51783677833566

Epoch: 6| Step: 4
Training loss: 3.066408893559768
Validation loss: 2.5112698959832955

Epoch: 6| Step: 5
Training loss: 2.5783351003406128
Validation loss: 2.5047363535235783

Epoch: 6| Step: 6
Training loss: 2.6232352000991184
Validation loss: 2.5303745890477005

Epoch: 6| Step: 7
Training loss: 2.5407187356583933
Validation loss: 2.51769887830514

Epoch: 6| Step: 8
Training loss: 2.731580952511214
Validation loss: 2.5181037768199235

Epoch: 6| Step: 9
Training loss: 2.5893504505803016
Validation loss: 2.5327498179128756

Epoch: 6| Step: 10
Training loss: 2.516281895139268
Validation loss: 2.5093700928639366

Epoch: 6| Step: 11
Training loss: 2.5198638459920106
Validation loss: 2.511708941324322

Epoch: 6| Step: 12
Training loss: 2.448388355884182
Validation loss: 2.5184964995055377

Epoch: 6| Step: 13
Training loss: 3.3927384922247596
Validation loss: 2.5297506305708426

Epoch: 95| Step: 0
Training loss: 1.8895987886121324
Validation loss: 2.5224469690876736

Epoch: 6| Step: 1
Training loss: 3.4866652552770185
Validation loss: 2.5180079621135176

Epoch: 6| Step: 2
Training loss: 2.405371567539969
Validation loss: 2.5125153703280145

Epoch: 6| Step: 3
Training loss: 2.5756094017010063
Validation loss: 2.494772571099554

Epoch: 6| Step: 4
Training loss: 1.9669503357614424
Validation loss: 2.5175788887221526

Epoch: 6| Step: 5
Training loss: 2.1609039943963375
Validation loss: 2.5264445450547837

Epoch: 6| Step: 6
Training loss: 2.573746077769377
Validation loss: 2.5203509311983003

Epoch: 6| Step: 7
Training loss: 3.105304756872768
Validation loss: 2.504090508718478

Epoch: 6| Step: 8
Training loss: 2.5143756488872224
Validation loss: 2.5327840122121037

Epoch: 6| Step: 9
Training loss: 3.1550780282747293
Validation loss: 2.5042766303316895

Epoch: 6| Step: 10
Training loss: 3.0112035090435145
Validation loss: 2.516157422708839

Epoch: 6| Step: 11
Training loss: 2.4677913108090874
Validation loss: 2.4969929781853835

Epoch: 6| Step: 12
Training loss: 2.4730322673958494
Validation loss: 2.5352520850232385

Epoch: 6| Step: 13
Training loss: 1.9634020997759636
Validation loss: 2.5147328553693566

Epoch: 96| Step: 0
Training loss: 2.450765459023781
Validation loss: 2.51900137941527

Epoch: 6| Step: 1
Training loss: 2.8975216634498406
Validation loss: 2.5278792980306037

Epoch: 6| Step: 2
Training loss: 2.538413002866184
Validation loss: 2.5019033118898815

Epoch: 6| Step: 3
Training loss: 2.7601044292320016
Validation loss: 2.5166432429364964

Epoch: 6| Step: 4
Training loss: 2.425095121740033
Validation loss: 2.5089338533516354

Epoch: 6| Step: 5
Training loss: 2.220524253116637
Validation loss: 2.5005684503710763

Epoch: 6| Step: 6
Training loss: 2.944468572105863
Validation loss: 2.5380396365480724

Epoch: 6| Step: 7
Training loss: 2.6867374846572565
Validation loss: 2.500432107354923

Epoch: 6| Step: 8
Training loss: 2.413773899048952
Validation loss: 2.5173500773850837

Epoch: 6| Step: 9
Training loss: 2.683577491677688
Validation loss: 2.507808999773543

Epoch: 6| Step: 10
Training loss: 2.238268254693405
Validation loss: 2.5210904226156545

Epoch: 6| Step: 11
Training loss: 2.8438043274772817
Validation loss: 2.525009023024224

Epoch: 6| Step: 12
Training loss: 2.649076041605175
Validation loss: 2.5198294015871263

Epoch: 6| Step: 13
Training loss: 2.721834647123693
Validation loss: 2.522653686374576

Epoch: 97| Step: 0
Training loss: 2.8050320979439087
Validation loss: 2.5146952700612095

Epoch: 6| Step: 1
Training loss: 2.1445563754362618
Validation loss: 2.521013035001028

Epoch: 6| Step: 2
Training loss: 2.5567142950973953
Validation loss: 2.5146341514480275

Epoch: 6| Step: 3
Training loss: 3.3122686629217646
Validation loss: 2.5165307216956156

Epoch: 6| Step: 4
Training loss: 2.6093936394122816
Validation loss: 2.516049322215099

Epoch: 6| Step: 5
Training loss: 1.9080590591007285
Validation loss: 2.521911370920036

Epoch: 6| Step: 6
Training loss: 2.525677138830899
Validation loss: 2.509971233628459

Epoch: 6| Step: 7
Training loss: 2.904554631404189
Validation loss: 2.5133238009448338

Epoch: 6| Step: 8
Training loss: 2.577549263217909
Validation loss: 2.4893483745145297

Epoch: 6| Step: 9
Training loss: 2.8198439613080524
Validation loss: 2.507174705478277

Epoch: 6| Step: 10
Training loss: 2.615183595444978
Validation loss: 2.516642914923243

Epoch: 6| Step: 11
Training loss: 2.094591797092635
Validation loss: 2.528582844062072

Epoch: 6| Step: 12
Training loss: 2.632821012307734
Validation loss: 2.49486649858916

Epoch: 6| Step: 13
Training loss: 3.046504697549699
Validation loss: 2.512278355720706

Epoch: 98| Step: 0
Training loss: 3.0366207404350374
Validation loss: 2.499429512561943

Epoch: 6| Step: 1
Training loss: 2.4040601599872944
Validation loss: 2.519952482010544

Epoch: 6| Step: 2
Training loss: 3.0436067708054813
Validation loss: 2.500665057331736

Epoch: 6| Step: 3
Training loss: 1.7193792405070987
Validation loss: 2.5265865271540178

Epoch: 6| Step: 4
Training loss: 2.634155655278433
Validation loss: 2.525574975922844

Epoch: 6| Step: 5
Training loss: 2.3803027333934015
Validation loss: 2.5143119408302117

Epoch: 6| Step: 6
Training loss: 2.736493320093796
Validation loss: 2.488934842843871

Epoch: 6| Step: 7
Training loss: 2.4155097252901285
Validation loss: 2.5098921579728577

Epoch: 6| Step: 8
Training loss: 2.041356809289658
Validation loss: 2.503154689007514

Epoch: 6| Step: 9
Training loss: 2.879341827526077
Validation loss: 2.510098500786856

Epoch: 6| Step: 10
Training loss: 3.150564379314145
Validation loss: 2.5006287768485422

Epoch: 6| Step: 11
Training loss: 2.9704360189747003
Validation loss: 2.5204862801310837

Epoch: 6| Step: 12
Training loss: 2.1753588939399973
Validation loss: 2.4859456356150043

Epoch: 6| Step: 13
Training loss: 2.506003324398384
Validation loss: 2.4942913563796316

Epoch: 99| Step: 0
Training loss: 2.674269824330139
Validation loss: 2.5026796643764477

Epoch: 6| Step: 1
Training loss: 2.4338419926934347
Validation loss: 2.504644941538077

Epoch: 6| Step: 2
Training loss: 3.0686723439011265
Validation loss: 2.5018662562521112

Epoch: 6| Step: 3
Training loss: 2.682998613446048
Validation loss: 2.505672675221696

Epoch: 6| Step: 4
Training loss: 1.572971199892394
Validation loss: 2.501206769196615

Epoch: 6| Step: 5
Training loss: 2.2798520337996737
Validation loss: 2.5179821250855325

Epoch: 6| Step: 6
Training loss: 2.2298592771938877
Validation loss: 2.5069329124190523

Epoch: 6| Step: 7
Training loss: 2.5566302737149598
Validation loss: 2.505342788743128

Epoch: 6| Step: 8
Training loss: 2.308189911868278
Validation loss: 2.512198486811075

Epoch: 6| Step: 9
Training loss: 2.76971830911942
Validation loss: 2.511685258471136

Epoch: 6| Step: 10
Training loss: 3.2234595944733275
Validation loss: 2.4941787441217214

Epoch: 6| Step: 11
Training loss: 2.303365037021795
Validation loss: 2.51747779637052

Epoch: 6| Step: 12
Training loss: 2.942370009877142
Validation loss: 2.5034066892578233

Epoch: 6| Step: 13
Training loss: 2.798529109168908
Validation loss: 2.5064408221556076

Epoch: 100| Step: 0
Training loss: 3.124415686339204
Validation loss: 2.5118646967316747

Epoch: 6| Step: 1
Training loss: 2.732453548528674
Validation loss: 2.5028084915284707

Epoch: 6| Step: 2
Training loss: 1.4148400629459998
Validation loss: 2.5273042788503415

Epoch: 6| Step: 3
Training loss: 2.257044044318401
Validation loss: 2.5111810453796064

Epoch: 6| Step: 4
Training loss: 2.5038736850090815
Validation loss: 2.50034582248311

Epoch: 6| Step: 5
Training loss: 2.8387376816758203
Validation loss: 2.511208340778032

Epoch: 6| Step: 6
Training loss: 2.5046805435817014
Validation loss: 2.5198504603841005

Epoch: 6| Step: 7
Training loss: 2.5112176042197953
Validation loss: 2.5067050581577335

Epoch: 6| Step: 8
Training loss: 2.7841889358843237
Validation loss: 2.5074417269007734

Epoch: 6| Step: 9
Training loss: 2.0837867879108756
Validation loss: 2.5214683168917165

Epoch: 6| Step: 10
Training loss: 3.577634019773873
Validation loss: 2.506672406799841

Epoch: 6| Step: 11
Training loss: 2.2948033338732987
Validation loss: 2.5106111033435345

Epoch: 6| Step: 12
Training loss: 2.64779151082485
Validation loss: 2.512690971225404

Epoch: 6| Step: 13
Training loss: 2.5175164735287288
Validation loss: 2.510570875913717

Epoch: 101| Step: 0
Training loss: 1.8303519484815096
Validation loss: 2.48927142131729

Epoch: 6| Step: 1
Training loss: 3.582988914674884
Validation loss: 2.5072932804301056

Epoch: 6| Step: 2
Training loss: 2.669196498425058
Validation loss: 2.4919841111294425

Epoch: 6| Step: 3
Training loss: 3.201768094597045
Validation loss: 2.501452866744572

Epoch: 6| Step: 4
Training loss: 2.275924318781663
Validation loss: 2.501314140833502

Epoch: 6| Step: 5
Training loss: 2.477629807629373
Validation loss: 2.503091134222778

Epoch: 6| Step: 6
Training loss: 2.8195258652362685
Validation loss: 2.4816004601415873

Epoch: 6| Step: 7
Training loss: 2.5478631659375486
Validation loss: 2.5163834226710056

Epoch: 6| Step: 8
Training loss: 2.602280434645884
Validation loss: 2.5076532976231536

Epoch: 6| Step: 9
Training loss: 1.7697214862214747
Validation loss: 2.5105768853067314

Epoch: 6| Step: 10
Training loss: 2.4463368180842653
Validation loss: 2.509795112511651

Epoch: 6| Step: 11
Training loss: 2.328763528601295
Validation loss: 2.5190985444550162

Epoch: 6| Step: 12
Training loss: 2.4996633302970106
Validation loss: 2.5097068430204392

Epoch: 6| Step: 13
Training loss: 2.9149564542838533
Validation loss: 2.5067915884376797

Epoch: 102| Step: 0
Training loss: 3.0043668753425026
Validation loss: 2.514225333906551

Epoch: 6| Step: 1
Training loss: 2.55935978960634
Validation loss: 2.5378264628927574

Epoch: 6| Step: 2
Training loss: 2.7534763731142826
Validation loss: 2.4888217904467784

Epoch: 6| Step: 3
Training loss: 1.9296792219347365
Validation loss: 2.4865139255110105

Epoch: 6| Step: 4
Training loss: 2.8494771779008743
Validation loss: 2.5146894224104193

Epoch: 6| Step: 5
Training loss: 3.0069813558433727
Validation loss: 2.484518468925332

Epoch: 6| Step: 6
Training loss: 2.7899621532976924
Validation loss: 2.511335617722207

Epoch: 6| Step: 7
Training loss: 2.775871219137883
Validation loss: 2.490352807410665

Epoch: 6| Step: 8
Training loss: 3.030049194339456
Validation loss: 2.4910499213057546

Epoch: 6| Step: 9
Training loss: 2.514574767579852
Validation loss: 2.520264991579139

Epoch: 6| Step: 10
Training loss: 2.201760160129703
Validation loss: 2.4918230101204073

Epoch: 6| Step: 11
Training loss: 2.05776178968044
Validation loss: 2.49763639964382

Epoch: 6| Step: 12
Training loss: 1.757718367705264
Validation loss: 2.5167321085052827

Epoch: 6| Step: 13
Training loss: 2.515639026673822
Validation loss: 2.5302947883035865

Epoch: 103| Step: 0
Training loss: 2.5102700999252763
Validation loss: 2.4906148316116385

Epoch: 6| Step: 1
Training loss: 2.144194807610969
Validation loss: 2.4989415358400775

Epoch: 6| Step: 2
Training loss: 2.237111689794671
Validation loss: 2.5084811560529365

Epoch: 6| Step: 3
Training loss: 2.579677414946595
Validation loss: 2.5018143161593525

Epoch: 6| Step: 4
Training loss: 2.9438087408923326
Validation loss: 2.4916624337168387

Epoch: 6| Step: 5
Training loss: 2.604711328133172
Validation loss: 2.4925740404146004

Epoch: 6| Step: 6
Training loss: 2.9284193218751042
Validation loss: 2.501070185248004

Epoch: 6| Step: 7
Training loss: 2.515630117849511
Validation loss: 2.478754577208865

Epoch: 6| Step: 8
Training loss: 2.7469581773682776
Validation loss: 2.532305616990804

Epoch: 6| Step: 9
Training loss: 2.0869594170975296
Validation loss: 2.4958102065067433

Epoch: 6| Step: 10
Training loss: 2.600402940191189
Validation loss: 2.5115958657576947

Epoch: 6| Step: 11
Training loss: 2.654623723063867
Validation loss: 2.509853972095455

Epoch: 6| Step: 12
Training loss: 2.6457298639045423
Validation loss: 2.5206932934764366

Epoch: 6| Step: 13
Training loss: 3.2714553695076103
Validation loss: 2.513348971598232

Epoch: 104| Step: 0
Training loss: 2.5144263782415024
Validation loss: 2.504545873831658

Epoch: 6| Step: 1
Training loss: 2.89770794758328
Validation loss: 2.4980946997052405

Epoch: 6| Step: 2
Training loss: 1.8663993033738517
Validation loss: 2.4902932285123818

Epoch: 6| Step: 3
Training loss: 2.5437837340721363
Validation loss: 2.5089250545751387

Epoch: 6| Step: 4
Training loss: 2.950438392522177
Validation loss: 2.495359983692395

Epoch: 6| Step: 5
Training loss: 2.5249918116068497
Validation loss: 2.491485305445769

Epoch: 6| Step: 6
Training loss: 2.9010129935161966
Validation loss: 2.5052534352649056

Epoch: 6| Step: 7
Training loss: 2.4260852273120754
Validation loss: 2.50076218338372

Epoch: 6| Step: 8
Training loss: 2.7377452897216026
Validation loss: 2.512837784276757

Epoch: 6| Step: 9
Training loss: 2.580649509733905
Validation loss: 2.5142346545490946

Epoch: 6| Step: 10
Training loss: 1.790030538202562
Validation loss: 2.4876175482720857

Epoch: 6| Step: 11
Training loss: 2.5973153485779306
Validation loss: 2.4894479048934546

Epoch: 6| Step: 12
Training loss: 2.6320238148965553
Validation loss: 2.496410081187991

Epoch: 6| Step: 13
Training loss: 3.0918776886548347
Validation loss: 2.5165561457667773

Epoch: 105| Step: 0
Training loss: 2.913946318164012
Validation loss: 2.5046744954767473

Epoch: 6| Step: 1
Training loss: 2.124973072554575
Validation loss: 2.484783504059031

Epoch: 6| Step: 2
Training loss: 2.9294612542848975
Validation loss: 2.5115079662934403

Epoch: 6| Step: 3
Training loss: 3.0987880798929948
Validation loss: 2.5150009952778785

Epoch: 6| Step: 4
Training loss: 2.0272167364475866
Validation loss: 2.5131752296151944

Epoch: 6| Step: 5
Training loss: 3.062332927272686
Validation loss: 2.506379194379202

Epoch: 6| Step: 6
Training loss: 2.3467996719807456
Validation loss: 2.510324372205202

Epoch: 6| Step: 7
Training loss: 2.442306865135159
Validation loss: 2.5098596328552194

Epoch: 6| Step: 8
Training loss: 2.9543990359005465
Validation loss: 2.5163342935724407

Epoch: 6| Step: 9
Training loss: 2.7915668944184704
Validation loss: 2.5284309250681996

Epoch: 6| Step: 10
Training loss: 2.15060160448186
Validation loss: 2.5141274115396794

Epoch: 6| Step: 11
Training loss: 2.555425508157199
Validation loss: 2.5202778531590098

Epoch: 6| Step: 12
Training loss: 2.0523057484675307
Validation loss: 2.488252916981433

Epoch: 6| Step: 13
Training loss: 2.212537638026214
Validation loss: 2.5036969409267886

Epoch: 106| Step: 0
Training loss: 2.5878004295897723
Validation loss: 2.506578031900293

Epoch: 6| Step: 1
Training loss: 2.7039729205191985
Validation loss: 2.499292714552875

Epoch: 6| Step: 2
Training loss: 2.9553196739617147
Validation loss: 2.4940737943576794

Epoch: 6| Step: 3
Training loss: 2.4531339414397157
Validation loss: 2.5038189749527664

Epoch: 6| Step: 4
Training loss: 1.508916737114231
Validation loss: 2.5181938593346516

Epoch: 6| Step: 5
Training loss: 2.43616693675115
Validation loss: 2.504748211965306

Epoch: 6| Step: 6
Training loss: 2.821608818739545
Validation loss: 2.5123669185380235

Epoch: 6| Step: 7
Training loss: 2.8294652639880113
Validation loss: 2.503740084866269

Epoch: 6| Step: 8
Training loss: 2.6342187402975137
Validation loss: 2.5195993579442346

Epoch: 6| Step: 9
Training loss: 2.9886683394102405
Validation loss: 2.508159238438315

Epoch: 6| Step: 10
Training loss: 2.6726904622965555
Validation loss: 2.520736465348918

Epoch: 6| Step: 11
Training loss: 2.0666337636153727
Validation loss: 2.5201359103329715

Epoch: 6| Step: 12
Training loss: 2.4243289451620598
Validation loss: 2.5156410169387713

Epoch: 6| Step: 13
Training loss: 2.438250010594947
Validation loss: 2.507331772167514

Epoch: 107| Step: 0
Training loss: 2.2088000206283795
Validation loss: 2.5041228364468586

Epoch: 6| Step: 1
Training loss: 2.522371616177695
Validation loss: 2.516894466122446

Epoch: 6| Step: 2
Training loss: 2.627865362779966
Validation loss: 2.4929555416102733

Epoch: 6| Step: 3
Training loss: 2.3441652057352496
Validation loss: 2.506680777803371

Epoch: 6| Step: 4
Training loss: 2.7088579892336475
Validation loss: 2.5078437186553284

Epoch: 6| Step: 5
Training loss: 2.0519864855018244
Validation loss: 2.5022010609608865

Epoch: 6| Step: 6
Training loss: 3.1104374129635497
Validation loss: 2.5187408680385017

Epoch: 6| Step: 7
Training loss: 2.069619347039011
Validation loss: 2.4992722590334115

Epoch: 6| Step: 8
Training loss: 3.0052606235408725
Validation loss: 2.5019644433217243

Epoch: 6| Step: 9
Training loss: 2.4095655116104298
Validation loss: 2.5069349954958584

Epoch: 6| Step: 10
Training loss: 2.6615308439426464
Validation loss: 2.501325044907015

Epoch: 6| Step: 11
Training loss: 1.9881500620552988
Validation loss: 2.493112378133601

Epoch: 6| Step: 12
Training loss: 3.1784691128252422
Validation loss: 2.492493616730912

Epoch: 6| Step: 13
Training loss: 2.7642591304071082
Validation loss: 2.503061753627044

Epoch: 108| Step: 0
Training loss: 3.029090662811246
Validation loss: 2.506679977010962

Epoch: 6| Step: 1
Training loss: 1.6451129382940344
Validation loss: 2.5008177537568086

Epoch: 6| Step: 2
Training loss: 2.980811903011536
Validation loss: 2.513348393507599

Epoch: 6| Step: 3
Training loss: 2.9926974108601008
Validation loss: 2.5087224381416373

Epoch: 6| Step: 4
Training loss: 2.7715000316131935
Validation loss: 2.486934842165301

Epoch: 6| Step: 5
Training loss: 2.0168867080485775
Validation loss: 2.5060709754780457

Epoch: 6| Step: 6
Training loss: 2.3673141999534555
Validation loss: 2.513076441053582

Epoch: 6| Step: 7
Training loss: 3.234713329366476
Validation loss: 2.505978480727655

Epoch: 6| Step: 8
Training loss: 2.3912242063655684
Validation loss: 2.5039578006430254

Epoch: 6| Step: 9
Training loss: 2.3054706859160374
Validation loss: 2.496657109515471

Epoch: 6| Step: 10
Training loss: 2.1956430641080575
Validation loss: 2.487794514996664

Epoch: 6| Step: 11
Training loss: 3.0044216314116823
Validation loss: 2.478977980705947

Epoch: 6| Step: 12
Training loss: 2.220130490944185
Validation loss: 2.5252648645452536

Epoch: 6| Step: 13
Training loss: 2.163183150679523
Validation loss: 2.499215927019595

Epoch: 109| Step: 0
Training loss: 2.861238466492052
Validation loss: 2.4956878152805477

Epoch: 6| Step: 1
Training loss: 2.9481779775738053
Validation loss: 2.5030249353459033

Epoch: 6| Step: 2
Training loss: 2.4241153322486473
Validation loss: 2.4767737145371833

Epoch: 6| Step: 3
Training loss: 2.4292829857573484
Validation loss: 2.5071328880805717

Epoch: 6| Step: 4
Training loss: 1.9480335860088829
Validation loss: 2.499373049723915

Epoch: 6| Step: 5
Training loss: 2.2547229364879198
Validation loss: 2.5149960560619817

Epoch: 6| Step: 6
Training loss: 3.0702714990105875
Validation loss: 2.478276664751125

Epoch: 6| Step: 7
Training loss: 2.2980808544094615
Validation loss: 2.50318009223966

Epoch: 6| Step: 8
Training loss: 2.466009042901183
Validation loss: 2.5068486614024144

Epoch: 6| Step: 9
Training loss: 2.44368604493418
Validation loss: 2.4917919991952493

Epoch: 6| Step: 10
Training loss: 3.047715760652074
Validation loss: 2.489259321275979

Epoch: 6| Step: 11
Training loss: 2.8401291820535124
Validation loss: 2.4887913230878302

Epoch: 6| Step: 12
Training loss: 2.1661070932487636
Validation loss: 2.492383497294144

Epoch: 6| Step: 13
Training loss: 2.1005417851516817
Validation loss: 2.5050769098003047

Epoch: 110| Step: 0
Training loss: 2.293688893348755
Validation loss: 2.5143894271239087

Epoch: 6| Step: 1
Training loss: 1.697952324740502
Validation loss: 2.478015816261292

Epoch: 6| Step: 2
Training loss: 2.21596621104071
Validation loss: 2.4937929613021845

Epoch: 6| Step: 3
Training loss: 3.0027210293360738
Validation loss: 2.480322085588814

Epoch: 6| Step: 4
Training loss: 2.5689318812966193
Validation loss: 2.4886194759959825

Epoch: 6| Step: 5
Training loss: 3.17892319399822
Validation loss: 2.504066392413817

Epoch: 6| Step: 6
Training loss: 2.3789049471145343
Validation loss: 2.5074909106108354

Epoch: 6| Step: 7
Training loss: 2.7903606909034817
Validation loss: 2.5128086961822147

Epoch: 6| Step: 8
Training loss: 2.895921463391462
Validation loss: 2.508451271888898

Epoch: 6| Step: 9
Training loss: 2.276270408978793
Validation loss: 2.5164463295006643

Epoch: 6| Step: 10
Training loss: 1.7607788826857727
Validation loss: 2.522403573420376

Epoch: 6| Step: 11
Training loss: 3.0140920903566286
Validation loss: 2.5041291469443854

Epoch: 6| Step: 12
Training loss: 2.6250016348697476
Validation loss: 2.4960449250948993

Epoch: 6| Step: 13
Training loss: 3.0852538305187256
Validation loss: 2.510426431714418

Epoch: 111| Step: 0
Training loss: 2.09387673521081
Validation loss: 2.515130968448209

Epoch: 6| Step: 1
Training loss: 2.2149612960706153
Validation loss: 2.497009341535591

Epoch: 6| Step: 2
Training loss: 2.317205024390599
Validation loss: 2.5122081063185746

Epoch: 6| Step: 3
Training loss: 3.2652273711736255
Validation loss: 2.499065193633646

Epoch: 6| Step: 4
Training loss: 2.3533142256929125
Validation loss: 2.4882143227699416

Epoch: 6| Step: 5
Training loss: 3.012990166132465
Validation loss: 2.4968771175059463

Epoch: 6| Step: 6
Training loss: 2.7763233912633405
Validation loss: 2.5068517283420673

Epoch: 6| Step: 7
Training loss: 3.234389005621473
Validation loss: 2.504705554679405

Epoch: 6| Step: 8
Training loss: 2.3254677373813033
Validation loss: 2.4999412652776307

Epoch: 6| Step: 9
Training loss: 2.475977302028169
Validation loss: 2.486479128409744

Epoch: 6| Step: 10
Training loss: 2.1949972014528827
Validation loss: 2.512856849515641

Epoch: 6| Step: 11
Training loss: 2.332860546805373
Validation loss: 2.512044986571665

Epoch: 6| Step: 12
Training loss: 2.4138614114012737
Validation loss: 2.51820026997078

Epoch: 6| Step: 13
Training loss: 2.3045411144254713
Validation loss: 2.487203366525538

Epoch: 112| Step: 0
Training loss: 2.725327876252884
Validation loss: 2.4926295012424178

Epoch: 6| Step: 1
Training loss: 2.6596440789872786
Validation loss: 2.514006347494149

Epoch: 6| Step: 2
Training loss: 2.531974877068627
Validation loss: 2.4946613982089145

Epoch: 6| Step: 3
Training loss: 3.547185270879894
Validation loss: 2.504647658050284

Epoch: 6| Step: 4
Training loss: 2.4699757104521067
Validation loss: 2.497079434351847

Epoch: 6| Step: 5
Training loss: 1.80340821473255
Validation loss: 2.4803520523356224

Epoch: 6| Step: 6
Training loss: 2.1389943615668314
Validation loss: 2.496432612977045

Epoch: 6| Step: 7
Training loss: 2.7268779757944883
Validation loss: 2.475697291826565

Epoch: 6| Step: 8
Training loss: 2.272224023761776
Validation loss: 2.4838682888359087

Epoch: 6| Step: 9
Training loss: 2.6097760834503623
Validation loss: 2.515614438160567

Epoch: 6| Step: 10
Training loss: 2.383502597622569
Validation loss: 2.5121729426125747

Epoch: 6| Step: 11
Training loss: 2.9049290762301316
Validation loss: 2.484478027452894

Epoch: 6| Step: 12
Training loss: 2.1500678517480236
Validation loss: 2.498123935525999

Epoch: 6| Step: 13
Training loss: 2.4815643534204863
Validation loss: 2.5007920087371143

Epoch: 113| Step: 0
Training loss: 1.9174714541144413
Validation loss: 2.4730978650146223

Epoch: 6| Step: 1
Training loss: 3.2461569145291045
Validation loss: 2.4931908919223225

Epoch: 6| Step: 2
Training loss: 2.6792901192121237
Validation loss: 2.4994665253484745

Epoch: 6| Step: 3
Training loss: 2.703016157660138
Validation loss: 2.48191328076445

Epoch: 6| Step: 4
Training loss: 2.2745998072500777
Validation loss: 2.499875644441745

Epoch: 6| Step: 5
Training loss: 2.6559974101525055
Validation loss: 2.5019231659360495

Epoch: 6| Step: 6
Training loss: 2.917847494238482
Validation loss: 2.506899059366108

Epoch: 6| Step: 7
Training loss: 2.015827257521221
Validation loss: 2.507985880833444

Epoch: 6| Step: 8
Training loss: 2.4866368775547887
Validation loss: 2.485865355343178

Epoch: 6| Step: 9
Training loss: 2.7923354491244443
Validation loss: 2.4968067130332794

Epoch: 6| Step: 10
Training loss: 1.845001765614727
Validation loss: 2.4837775920354663

Epoch: 6| Step: 11
Training loss: 2.55200380992904
Validation loss: 2.498225258957142

Epoch: 6| Step: 12
Training loss: 2.7518030671251275
Validation loss: 2.465210125083615

Epoch: 6| Step: 13
Training loss: 2.493708227280978
Validation loss: 2.495405694251446

Epoch: 114| Step: 0
Training loss: 1.9571510628517297
Validation loss: 2.486174942862018

Epoch: 6| Step: 1
Training loss: 1.9590418190107153
Validation loss: 2.4972113242896654

Epoch: 6| Step: 2
Training loss: 2.486823836397328
Validation loss: 2.4739486778774644

Epoch: 6| Step: 3
Training loss: 2.477180668549678
Validation loss: 2.516207514509253

Epoch: 6| Step: 4
Training loss: 2.4222022050891763
Validation loss: 2.508290540160973

Epoch: 6| Step: 5
Training loss: 2.790937717597055
Validation loss: 2.5106728130818183

Epoch: 6| Step: 6
Training loss: 2.5464494969939944
Validation loss: 2.480254989584655

Epoch: 6| Step: 7
Training loss: 2.7413535738406822
Validation loss: 2.4945424160239615

Epoch: 6| Step: 8
Training loss: 3.3942550704860865
Validation loss: 2.5138931728373297

Epoch: 6| Step: 9
Training loss: 2.5282558110254363
Validation loss: 2.5250910782041247

Epoch: 6| Step: 10
Training loss: 2.639324522590368
Validation loss: 2.494045357539704

Epoch: 6| Step: 11
Training loss: 2.714399079056372
Validation loss: 2.5165045659190097

Epoch: 6| Step: 12
Training loss: 2.1078003834234074
Validation loss: 2.5073406971847487

Epoch: 6| Step: 13
Training loss: 2.780107585005318
Validation loss: 2.513800682391216

Epoch: 115| Step: 0
Training loss: 2.6778271503918036
Validation loss: 2.5078946537370497

Epoch: 6| Step: 1
Training loss: 2.4151942492092795
Validation loss: 2.5154615270254967

Epoch: 6| Step: 2
Training loss: 2.1787619317625895
Validation loss: 2.5154018115835037

Epoch: 6| Step: 3
Training loss: 3.029995530883716
Validation loss: 2.4889213511536514

Epoch: 6| Step: 4
Training loss: 2.1541725876786435
Validation loss: 2.4915260324090904

Epoch: 6| Step: 5
Training loss: 2.45664763981125
Validation loss: 2.503226310835964

Epoch: 6| Step: 6
Training loss: 2.565956947328227
Validation loss: 2.5160274144262518

Epoch: 6| Step: 7
Training loss: 2.657397033763708
Validation loss: 2.502834228097465

Epoch: 6| Step: 8
Training loss: 2.5157198680736217
Validation loss: 2.4967675805537546

Epoch: 6| Step: 9
Training loss: 2.5249860517664233
Validation loss: 2.4846295250683865

Epoch: 6| Step: 10
Training loss: 2.59349830968922
Validation loss: 2.4866870335949525

Epoch: 6| Step: 11
Training loss: 2.554337690476203
Validation loss: 2.4819252007384955

Epoch: 6| Step: 12
Training loss: 2.6269789910727024
Validation loss: 2.490825761307831

Epoch: 6| Step: 13
Training loss: 2.749926305997222
Validation loss: 2.4902216701838964

Epoch: 116| Step: 0
Training loss: 2.332941283486587
Validation loss: 2.48251478479382

Epoch: 6| Step: 1
Training loss: 2.4913369763355946
Validation loss: 2.478758263256897

Epoch: 6| Step: 2
Training loss: 2.2091997953924207
Validation loss: 2.516882950110263

Epoch: 6| Step: 3
Training loss: 2.081128237716573
Validation loss: 2.5034861172249467

Epoch: 6| Step: 4
Training loss: 2.9221106449513323
Validation loss: 2.5047877888267474

Epoch: 6| Step: 5
Training loss: 2.7037918062192166
Validation loss: 2.500460872418267

Epoch: 6| Step: 6
Training loss: 2.0949712579253212
Validation loss: 2.501340352961217

Epoch: 6| Step: 7
Training loss: 3.233816789749086
Validation loss: 2.4970603107643807

Epoch: 6| Step: 8
Training loss: 2.2627222868752526
Validation loss: 2.4765071886657988

Epoch: 6| Step: 9
Training loss: 2.750340787405971
Validation loss: 2.498903263672219

Epoch: 6| Step: 10
Training loss: 2.4499738341510717
Validation loss: 2.49260969247629

Epoch: 6| Step: 11
Training loss: 2.6106582501398834
Validation loss: 2.495742240313165

Epoch: 6| Step: 12
Training loss: 2.4394679805892743
Validation loss: 2.4884687600870725

Epoch: 6| Step: 13
Training loss: 2.999554124122864
Validation loss: 2.464926170992889

Epoch: 117| Step: 0
Training loss: 1.9409359030224886
Validation loss: 2.5039107027478655

Epoch: 6| Step: 1
Training loss: 2.7712333409587697
Validation loss: 2.500055189446426

Epoch: 6| Step: 2
Training loss: 2.779470324381725
Validation loss: 2.4963962288787345

Epoch: 6| Step: 3
Training loss: 2.486010031418268
Validation loss: 2.504526664462411

Epoch: 6| Step: 4
Training loss: 2.651808402371288
Validation loss: 2.4799556998379177

Epoch: 6| Step: 5
Training loss: 2.6693838898821767
Validation loss: 2.5050237017654746

Epoch: 6| Step: 6
Training loss: 2.815085176632632
Validation loss: 2.5040315372066453

Epoch: 6| Step: 7
Training loss: 2.760635616808032
Validation loss: 2.5107602113426286

Epoch: 6| Step: 8
Training loss: 2.3396934499215303
Validation loss: 2.504669699152298

Epoch: 6| Step: 9
Training loss: 2.40849803594565
Validation loss: 2.5085843135211086

Epoch: 6| Step: 10
Training loss: 2.922807514076707
Validation loss: 2.506373708848599

Epoch: 6| Step: 11
Training loss: 1.9552743910407162
Validation loss: 2.50865259501382

Epoch: 6| Step: 12
Training loss: 1.9505616724062091
Validation loss: 2.4991606482593314

Epoch: 6| Step: 13
Training loss: 2.992179691314468
Validation loss: 2.5150062117439442

Epoch: 118| Step: 0
Training loss: 2.962286085944514
Validation loss: 2.4823863523602925

Epoch: 6| Step: 1
Training loss: 2.8165596379217193
Validation loss: 2.501561189096349

Epoch: 6| Step: 2
Training loss: 2.724841079977475
Validation loss: 2.491773227017135

Epoch: 6| Step: 3
Training loss: 2.760022021219611
Validation loss: 2.504674835292813

Epoch: 6| Step: 4
Training loss: 2.530300009207738
Validation loss: 2.496803091620764

Epoch: 6| Step: 5
Training loss: 2.0983680923810883
Validation loss: 2.49536387431322

Epoch: 6| Step: 6
Training loss: 2.3468035325141616
Validation loss: 2.480830444909421

Epoch: 6| Step: 7
Training loss: 2.5963487589992478
Validation loss: 2.486198238687622

Epoch: 6| Step: 8
Training loss: 2.259116670605724
Validation loss: 2.4958972151603396

Epoch: 6| Step: 9
Training loss: 2.602460551553817
Validation loss: 2.452518407732441

Epoch: 6| Step: 10
Training loss: 2.5553090683843003
Validation loss: 2.5058091985954265

Epoch: 6| Step: 11
Training loss: 2.610968919584384
Validation loss: 2.487567190449174

Epoch: 6| Step: 12
Training loss: 2.155030831915202
Validation loss: 2.5083293364968626

Epoch: 6| Step: 13
Training loss: 2.1938276054371113
Validation loss: 2.490105647846307

Epoch: 119| Step: 0
Training loss: 3.1099690392231816
Validation loss: 2.4985202522079164

Epoch: 6| Step: 1
Training loss: 2.6502342768342073
Validation loss: 2.490658146066424

Epoch: 6| Step: 2
Training loss: 2.499480861168555
Validation loss: 2.497405973674321

Epoch: 6| Step: 3
Training loss: 2.8380825032990544
Validation loss: 2.4894833556053686

Epoch: 6| Step: 4
Training loss: 2.457709238607791
Validation loss: 2.504001137172804

Epoch: 6| Step: 5
Training loss: 2.169345178204074
Validation loss: 2.484460710669809

Epoch: 6| Step: 6
Training loss: 2.4442448341866743
Validation loss: 2.460730215504576

Epoch: 6| Step: 7
Training loss: 2.977218595670504
Validation loss: 2.4746983970520673

Epoch: 6| Step: 8
Training loss: 2.343882951144483
Validation loss: 2.480749597105528

Epoch: 6| Step: 9
Training loss: 2.0491574207338807
Validation loss: 2.487379448007502

Epoch: 6| Step: 10
Training loss: 2.676453176070661
Validation loss: 2.4903031493342795

Epoch: 6| Step: 11
Training loss: 2.125067653701029
Validation loss: 2.4953114783294414

Epoch: 6| Step: 12
Training loss: 2.370940704685437
Validation loss: 2.4860462901259552

Epoch: 6| Step: 13
Training loss: 2.448208979475371
Validation loss: 2.4769725243401735

Epoch: 120| Step: 0
Training loss: 2.2277760193591365
Validation loss: 2.491800843037674

Epoch: 6| Step: 1
Training loss: 2.768696173495595
Validation loss: 2.474832120944122

Epoch: 6| Step: 2
Training loss: 2.944009588827191
Validation loss: 2.479803028645346

Epoch: 6| Step: 3
Training loss: 2.286982193170704
Validation loss: 2.4915449978317814

Epoch: 6| Step: 4
Training loss: 2.914235291458872
Validation loss: 2.5049352927943915

Epoch: 6| Step: 5
Training loss: 2.324150020320454
Validation loss: 2.5082904456197865

Epoch: 6| Step: 6
Training loss: 2.2419331369766202
Validation loss: 2.495097739604205

Epoch: 6| Step: 7
Training loss: 2.440120266780168
Validation loss: 2.486356849080128

Epoch: 6| Step: 8
Training loss: 2.648746258677657
Validation loss: 2.487241010642626

Epoch: 6| Step: 9
Training loss: 2.0650976757382096
Validation loss: 2.482635289300574

Epoch: 6| Step: 10
Training loss: 3.1781872108394675
Validation loss: 2.4963676213421775

Epoch: 6| Step: 11
Training loss: 2.6158125724669423
Validation loss: 2.4916585980208326

Epoch: 6| Step: 12
Training loss: 1.8280632465072402
Validation loss: 2.461821174993399

Epoch: 6| Step: 13
Training loss: 2.4168464878749267
Validation loss: 2.4812403477360423

Epoch: 121| Step: 0
Training loss: 2.98138277729823
Validation loss: 2.475695404068043

Epoch: 6| Step: 1
Training loss: 2.0092700462162436
Validation loss: 2.484163938980704

Epoch: 6| Step: 2
Training loss: 1.7726061380565226
Validation loss: 2.4900532513804503

Epoch: 6| Step: 3
Training loss: 2.5957992914783308
Validation loss: 2.4881734674160563

Epoch: 6| Step: 4
Training loss: 2.728065579216232
Validation loss: 2.4815379396333435

Epoch: 6| Step: 5
Training loss: 2.741637258942025
Validation loss: 2.52024309907435

Epoch: 6| Step: 6
Training loss: 2.4141966155984664
Validation loss: 2.488237670593057

Epoch: 6| Step: 7
Training loss: 2.480738251230501
Validation loss: 2.4913603504613806

Epoch: 6| Step: 8
Training loss: 2.4036238570498503
Validation loss: 2.500971884140762

Epoch: 6| Step: 9
Training loss: 2.9479935886515203
Validation loss: 2.473487232130566

Epoch: 6| Step: 10
Training loss: 2.5060154070186487
Validation loss: 2.48894664936471

Epoch: 6| Step: 11
Training loss: 2.652669670294382
Validation loss: 2.525669451989308

Epoch: 6| Step: 12
Training loss: 2.4125191406123188
Validation loss: 2.453114945544112

Epoch: 6| Step: 13
Training loss: 2.2597339730119073
Validation loss: 2.480856533484442

Epoch: 122| Step: 0
Training loss: 2.975290902925502
Validation loss: 2.479766980526193

Epoch: 6| Step: 1
Training loss: 2.8339217827770824
Validation loss: 2.4871220600087227

Epoch: 6| Step: 2
Training loss: 2.648043802982388
Validation loss: 2.497883545828226

Epoch: 6| Step: 3
Training loss: 2.5805637731331172
Validation loss: 2.470178068292041

Epoch: 6| Step: 4
Training loss: 2.297928341524331
Validation loss: 2.4785478818781894

Epoch: 6| Step: 5
Training loss: 1.8922043186136446
Validation loss: 2.485810087026938

Epoch: 6| Step: 6
Training loss: 3.4737232744493585
Validation loss: 2.494575420383333

Epoch: 6| Step: 7
Training loss: 2.753279897465316
Validation loss: 2.486857212252516

Epoch: 6| Step: 8
Training loss: 2.223528806375848
Validation loss: 2.493737478032289

Epoch: 6| Step: 9
Training loss: 2.0838967387999237
Validation loss: 2.478099488006766

Epoch: 6| Step: 10
Training loss: 2.2487876592921068
Validation loss: 2.47960331160798

Epoch: 6| Step: 11
Training loss: 1.9125044105827984
Validation loss: 2.475977032305009

Epoch: 6| Step: 12
Training loss: 2.6023435594369113
Validation loss: 2.489800456632822

Epoch: 6| Step: 13
Training loss: 2.2732996948005715
Validation loss: 2.480974232473302

Epoch: 123| Step: 0
Training loss: 2.549241353296301
Validation loss: 2.453633394917525

Epoch: 6| Step: 1
Training loss: 1.4779900003283366
Validation loss: 2.4435529965521328

Epoch: 6| Step: 2
Training loss: 2.6261160158443717
Validation loss: 2.500343071562998

Epoch: 6| Step: 3
Training loss: 1.9958808322529091
Validation loss: 2.487829515251368

Epoch: 6| Step: 4
Training loss: 2.9519021060497876
Validation loss: 2.4882251925528944

Epoch: 6| Step: 5
Training loss: 2.3803948816920366
Validation loss: 2.464762293559775

Epoch: 6| Step: 6
Training loss: 2.6135928847726047
Validation loss: 2.499514579817386

Epoch: 6| Step: 7
Training loss: 3.053931569569988
Validation loss: 2.477705197366687

Epoch: 6| Step: 8
Training loss: 2.5321817449273385
Validation loss: 2.4976610604494676

Epoch: 6| Step: 9
Training loss: 2.729615172206933
Validation loss: 2.483924914212239

Epoch: 6| Step: 10
Training loss: 3.087171554084046
Validation loss: 2.5080045664156074

Epoch: 6| Step: 11
Training loss: 2.4438499488781704
Validation loss: 2.5026182267101587

Epoch: 6| Step: 12
Training loss: 2.1552715569415786
Validation loss: 2.4698326911224284

Epoch: 6| Step: 13
Training loss: 1.4418165661860611
Validation loss: 2.477023668854906

Epoch: 124| Step: 0
Training loss: 2.5456348980758725
Validation loss: 2.487391080515923

Epoch: 6| Step: 1
Training loss: 2.577881402731765
Validation loss: 2.4693802869720862

Epoch: 6| Step: 2
Training loss: 2.3904642287902944
Validation loss: 2.49232157232365

Epoch: 6| Step: 3
Training loss: 2.2765161178356776
Validation loss: 2.502611664501322

Epoch: 6| Step: 4
Training loss: 3.0966716803546745
Validation loss: 2.4743803418016785

Epoch: 6| Step: 5
Training loss: 2.561523251346257
Validation loss: 2.4853307529278332

Epoch: 6| Step: 6
Training loss: 2.259126802057795
Validation loss: 2.5103637993723367

Epoch: 6| Step: 7
Training loss: 2.4333635101885793
Validation loss: 2.492899501861194

Epoch: 6| Step: 8
Training loss: 2.7235587552117946
Validation loss: 2.4847906364398797

Epoch: 6| Step: 9
Training loss: 2.552749785513211
Validation loss: 2.473155741443528

Epoch: 6| Step: 10
Training loss: 2.6392891117459754
Validation loss: 2.4839597481268605

Epoch: 6| Step: 11
Training loss: 1.9906622938558216
Validation loss: 2.4942257081836923

Epoch: 6| Step: 12
Training loss: 1.9042162442865787
Validation loss: 2.4833228804434464

Epoch: 6| Step: 13
Training loss: 3.1208213333965324
Validation loss: 2.472010079788582

Epoch: 125| Step: 0
Training loss: 2.4648592263777207
Validation loss: 2.4908375562926826

Epoch: 6| Step: 1
Training loss: 2.6952166111792866
Validation loss: 2.510193612448121

Epoch: 6| Step: 2
Training loss: 2.9534787566617515
Validation loss: 2.453956082303663

Epoch: 6| Step: 3
Training loss: 2.499429446917762
Validation loss: 2.473157538884414

Epoch: 6| Step: 4
Training loss: 2.5993923724346777
Validation loss: 2.499251848480109

Epoch: 6| Step: 5
Training loss: 1.5041483102173265
Validation loss: 2.495029518705288

Epoch: 6| Step: 6
Training loss: 2.3353244142803975
Validation loss: 2.4927696062285842

Epoch: 6| Step: 7
Training loss: 2.831050476723757
Validation loss: 2.4872886148646547

Epoch: 6| Step: 8
Training loss: 2.148866700736502
Validation loss: 2.473598593877134

Epoch: 6| Step: 9
Training loss: 2.642227679668437
Validation loss: 2.485153731454953

Epoch: 6| Step: 10
Training loss: 3.1378141511886746
Validation loss: 2.493121878479799

Epoch: 6| Step: 11
Training loss: 1.927688489868357
Validation loss: 2.499376170968094

Epoch: 6| Step: 12
Training loss: 2.232433622768193
Validation loss: 2.4762687432542996

Epoch: 6| Step: 13
Training loss: 2.549232468376693
Validation loss: 2.471016355133408

Epoch: 126| Step: 0
Training loss: 2.956527606599747
Validation loss: 2.4785515620276333

Epoch: 6| Step: 1
Training loss: 2.462835252277017
Validation loss: 2.4777030281518218

Epoch: 6| Step: 2
Training loss: 2.549289050756434
Validation loss: 2.476361509146796

Epoch: 6| Step: 3
Training loss: 2.5737380185249017
Validation loss: 2.4831883356835847

Epoch: 6| Step: 4
Training loss: 3.0575059927182173
Validation loss: 2.4759671146520237

Epoch: 6| Step: 5
Training loss: 2.6081244847187235
Validation loss: 2.4992733104319096

Epoch: 6| Step: 6
Training loss: 2.5744262056011507
Validation loss: 2.526249870107112

Epoch: 6| Step: 7
Training loss: 1.9002962784905204
Validation loss: 2.500767335750725

Epoch: 6| Step: 8
Training loss: 2.545802727331648
Validation loss: 2.5324469414848334

Epoch: 6| Step: 9
Training loss: 1.8223239770768531
Validation loss: 2.4742018022319474

Epoch: 6| Step: 10
Training loss: 2.9029660283018486
Validation loss: 2.5049224486412696

Epoch: 6| Step: 11
Training loss: 2.258453172645434
Validation loss: 2.5137353810302865

Epoch: 6| Step: 12
Training loss: 1.9912847530495634
Validation loss: 2.5092714727456715

Epoch: 6| Step: 13
Training loss: 2.7196867633421027
Validation loss: 2.516760255371482

Epoch: 127| Step: 0
Training loss: 2.1789069196577606
Validation loss: 2.4705386179873052

Epoch: 6| Step: 1
Training loss: 2.262322696040082
Validation loss: 2.4875549203160086

Epoch: 6| Step: 2
Training loss: 2.6307251576692865
Validation loss: 2.4711642897392214

Epoch: 6| Step: 3
Training loss: 3.1120854358271877
Validation loss: 2.472673461794024

Epoch: 6| Step: 4
Training loss: 2.348750362507872
Validation loss: 2.500191679138507

Epoch: 6| Step: 5
Training loss: 1.6810507986051
Validation loss: 2.468550194614016

Epoch: 6| Step: 6
Training loss: 2.403969712236378
Validation loss: 2.497830255380449

Epoch: 6| Step: 7
Training loss: 2.544052619647806
Validation loss: 2.4663345661970886

Epoch: 6| Step: 8
Training loss: 3.046740250175353
Validation loss: 2.4639128647918858

Epoch: 6| Step: 9
Training loss: 2.5396389820322134
Validation loss: 2.4447635245526187

Epoch: 6| Step: 10
Training loss: 2.352923433503403
Validation loss: 2.4501255358172105

Epoch: 6| Step: 11
Training loss: 2.681684545058673
Validation loss: 2.469925214022132

Epoch: 6| Step: 12
Training loss: 2.442876315220909
Validation loss: 2.4645681626781495

Epoch: 6| Step: 13
Training loss: 2.527920263650537
Validation loss: 2.4634982025475534

Epoch: 128| Step: 0
Training loss: 2.2771284940615004
Validation loss: 2.4837492788614863

Epoch: 6| Step: 1
Training loss: 2.7016728199397084
Validation loss: 2.491480913837337

Epoch: 6| Step: 2
Training loss: 2.3164288936235162
Validation loss: 2.476957629761026

Epoch: 6| Step: 3
Training loss: 2.757757343032435
Validation loss: 2.4727144405395216

Epoch: 6| Step: 4
Training loss: 2.51853859442561
Validation loss: 2.497696843126729

Epoch: 6| Step: 5
Training loss: 2.3229977261437313
Validation loss: 2.479389875178409

Epoch: 6| Step: 6
Training loss: 2.727225761298169
Validation loss: 2.4595709967154566

Epoch: 6| Step: 7
Training loss: 2.3219210511026662
Validation loss: 2.464741633633464

Epoch: 6| Step: 8
Training loss: 2.366146148159894
Validation loss: 2.457680666843598

Epoch: 6| Step: 9
Training loss: 2.6044588662566643
Validation loss: 2.4938926175496356

Epoch: 6| Step: 10
Training loss: 2.9234595260728233
Validation loss: 2.4829122930377525

Epoch: 6| Step: 11
Training loss: 2.6755348704715347
Validation loss: 2.4586530049670103

Epoch: 6| Step: 12
Training loss: 2.0644914665018086
Validation loss: 2.48125622552936

Epoch: 6| Step: 13
Training loss: 2.34213333321731
Validation loss: 2.4803532952144667

Epoch: 129| Step: 0
Training loss: 2.3821877582964754
Validation loss: 2.4997877748712045

Epoch: 6| Step: 1
Training loss: 2.8279333734662853
Validation loss: 2.480737560906892

Epoch: 6| Step: 2
Training loss: 2.4188892294858615
Validation loss: 2.4887395262794865

Epoch: 6| Step: 3
Training loss: 1.9918328661452733
Validation loss: 2.4928386407360765

Epoch: 6| Step: 4
Training loss: 2.6449089738437945
Validation loss: 2.470516425958217

Epoch: 6| Step: 5
Training loss: 1.9560249467284718
Validation loss: 2.4763902556604704

Epoch: 6| Step: 6
Training loss: 2.303755853141515
Validation loss: 2.5113831408792384

Epoch: 6| Step: 7
Training loss: 2.6457298639045423
Validation loss: 2.466513012116479

Epoch: 6| Step: 8
Training loss: 2.6765066235661834
Validation loss: 2.467060572854319

Epoch: 6| Step: 9
Training loss: 2.646783542967111
Validation loss: 2.506439905707707

Epoch: 6| Step: 10
Training loss: 2.0300117826824526
Validation loss: 2.5002763415984743

Epoch: 6| Step: 11
Training loss: 2.744348093247134
Validation loss: 2.4811755977299517

Epoch: 6| Step: 12
Training loss: 2.5314586223767157
Validation loss: 2.500410417482717

Epoch: 6| Step: 13
Training loss: 3.1345149335117553
Validation loss: 2.4976748728987173

Epoch: 130| Step: 0
Training loss: 2.4527273645496743
Validation loss: 2.4860734273514433

Epoch: 6| Step: 1
Training loss: 2.0056449381787376
Validation loss: 2.4948849371699815

Epoch: 6| Step: 2
Training loss: 2.8458747052768794
Validation loss: 2.4581415490212875

Epoch: 6| Step: 3
Training loss: 2.3431975667303337
Validation loss: 2.484057212581032

Epoch: 6| Step: 4
Training loss: 2.76576586003615
Validation loss: 2.5019038109071134

Epoch: 6| Step: 5
Training loss: 3.193989001623624
Validation loss: 2.4919900182325483

Epoch: 6| Step: 6
Training loss: 2.8500643204240497
Validation loss: 2.4846737692883822

Epoch: 6| Step: 7
Training loss: 2.2444746202175647
Validation loss: 2.480155206574468

Epoch: 6| Step: 8
Training loss: 2.0434878913253702
Validation loss: 2.503721918333153

Epoch: 6| Step: 9
Training loss: 2.310419125866649
Validation loss: 2.4563307498927442

Epoch: 6| Step: 10
Training loss: 2.4825594043827155
Validation loss: 2.481810881284212

Epoch: 6| Step: 11
Training loss: 2.4828386654684427
Validation loss: 2.457759050902171

Epoch: 6| Step: 12
Training loss: 1.8091806732343072
Validation loss: 2.492211346533571

Epoch: 6| Step: 13
Training loss: 2.640012591071881
Validation loss: 2.482640118900653

Epoch: 131| Step: 0
Training loss: 1.881549205622189
Validation loss: 2.485901837884535

Epoch: 6| Step: 1
Training loss: 2.1857062478545464
Validation loss: 2.5102112603117113

Epoch: 6| Step: 2
Training loss: 2.454118758178166
Validation loss: 2.4736705916230703

Epoch: 6| Step: 3
Training loss: 3.0670213604790506
Validation loss: 2.465418936869723

Epoch: 6| Step: 4
Training loss: 2.9353394374791164
Validation loss: 2.4558701150745703

Epoch: 6| Step: 5
Training loss: 2.2990026675122133
Validation loss: 2.4756203678664974

Epoch: 6| Step: 6
Training loss: 2.9815147234386656
Validation loss: 2.4962151292304102

Epoch: 6| Step: 7
Training loss: 2.777467877797118
Validation loss: 2.4549936446165743

Epoch: 6| Step: 8
Training loss: 2.165846106841506
Validation loss: 2.445199643477774

Epoch: 6| Step: 9
Training loss: 2.0199301231686535
Validation loss: 2.4642056434072837

Epoch: 6| Step: 10
Training loss: 2.485541112000725
Validation loss: 2.484318374563239

Epoch: 6| Step: 11
Training loss: 2.0414550308256367
Validation loss: 2.4556158120517892

Epoch: 6| Step: 12
Training loss: 2.274439115865396
Validation loss: 2.4739360738809633

Epoch: 6| Step: 13
Training loss: 2.968368023843335
Validation loss: 2.4732463530201336

Epoch: 132| Step: 0
Training loss: 1.6648073633693798
Validation loss: 2.465066477746061

Epoch: 6| Step: 1
Training loss: 2.2996856723451047
Validation loss: 2.448406648176126

Epoch: 6| Step: 2
Training loss: 2.397446617192466
Validation loss: 2.46263891556703

Epoch: 6| Step: 3
Training loss: 2.675107194410518
Validation loss: 2.473808628252599

Epoch: 6| Step: 4
Training loss: 3.1426351766107827
Validation loss: 2.473168351489997

Epoch: 6| Step: 5
Training loss: 2.1007688931250335
Validation loss: 2.4927625655824963

Epoch: 6| Step: 6
Training loss: 2.126519949863619
Validation loss: 2.460463210402471

Epoch: 6| Step: 7
Training loss: 3.0953488312639386
Validation loss: 2.454051223107426

Epoch: 6| Step: 8
Training loss: 2.4308072665227862
Validation loss: 2.482863135096318

Epoch: 6| Step: 9
Training loss: 2.341520342435249
Validation loss: 2.4774541259422853

Epoch: 6| Step: 10
Training loss: 1.9260235183325685
Validation loss: 2.461829723497918

Epoch: 6| Step: 11
Training loss: 2.5793145412109864
Validation loss: 2.465800833156584

Epoch: 6| Step: 12
Training loss: 2.644830007877415
Validation loss: 2.470237160431291

Epoch: 6| Step: 13
Training loss: 2.884307060392137
Validation loss: 2.4771599574754544

Epoch: 133| Step: 0
Training loss: 2.3950955346789944
Validation loss: 2.464122389933413

Epoch: 6| Step: 1
Training loss: 2.4272069503890865
Validation loss: 2.474560754007321

Epoch: 6| Step: 2
Training loss: 2.3718119857921423
Validation loss: 2.470909387150907

Epoch: 6| Step: 3
Training loss: 2.594430121909377
Validation loss: 2.44978296006237

Epoch: 6| Step: 4
Training loss: 2.603982801940192
Validation loss: 2.456323445116102

Epoch: 6| Step: 5
Training loss: 2.516612552119971
Validation loss: 2.47459564255678

Epoch: 6| Step: 6
Training loss: 2.275809711942258
Validation loss: 2.487327799590294

Epoch: 6| Step: 7
Training loss: 2.523878124021069
Validation loss: 2.4525737269745616

Epoch: 6| Step: 8
Training loss: 2.59951555066998
Validation loss: 2.470881444256539

Epoch: 6| Step: 9
Training loss: 2.708755978593975
Validation loss: 2.4666418355619286

Epoch: 6| Step: 10
Training loss: 2.649695533679976
Validation loss: 2.4624668893461474

Epoch: 6| Step: 11
Training loss: 2.3604420655228844
Validation loss: 2.456732059665939

Epoch: 6| Step: 12
Training loss: 2.1304406472322563
Validation loss: 2.4703811463594665

Epoch: 6| Step: 13
Training loss: 2.617450393454444
Validation loss: 2.470232664627602

Epoch: 134| Step: 0
Training loss: 2.935885695994701
Validation loss: 2.4783344073095037

Epoch: 6| Step: 1
Training loss: 3.0764815692321634
Validation loss: 2.456523368356563

Epoch: 6| Step: 2
Training loss: 2.861623578229499
Validation loss: 2.467850809660023

Epoch: 6| Step: 3
Training loss: 2.062212143664195
Validation loss: 2.494154380883557

Epoch: 6| Step: 4
Training loss: 2.595853205605292
Validation loss: 2.43808177550213

Epoch: 6| Step: 5
Training loss: 3.143669360967598
Validation loss: 2.509296850322489

Epoch: 6| Step: 6
Training loss: 2.0109624829996773
Validation loss: 2.483613266672546

Epoch: 6| Step: 7
Training loss: 1.989954336303811
Validation loss: 2.5000405728729223

Epoch: 6| Step: 8
Training loss: 2.7738534534857453
Validation loss: 2.5018232465136636

Epoch: 6| Step: 9
Training loss: 1.7665658655139629
Validation loss: 2.5290184671981004

Epoch: 6| Step: 10
Training loss: 2.3693972304742
Validation loss: 2.5035087870608357

Epoch: 6| Step: 11
Training loss: 2.3121471651356083
Validation loss: 2.508330736195387

Epoch: 6| Step: 12
Training loss: 2.3821177986413695
Validation loss: 2.500878303842089

Epoch: 6| Step: 13
Training loss: 1.5475973119012831
Validation loss: 2.5065372477857144

Epoch: 135| Step: 0
Training loss: 2.6305189698345037
Validation loss: 2.477003540712298

Epoch: 6| Step: 1
Training loss: 2.438448207997442
Validation loss: 2.4955897901146553

Epoch: 6| Step: 2
Training loss: 1.9380912493904268
Validation loss: 2.458607686666319

Epoch: 6| Step: 3
Training loss: 2.7607142066144816
Validation loss: 2.4594478350752156

Epoch: 6| Step: 4
Training loss: 2.6632873660414886
Validation loss: 2.4695704342872635

Epoch: 6| Step: 5
Training loss: 2.4364699118932864
Validation loss: 2.4865823728234857

Epoch: 6| Step: 6
Training loss: 3.122576269557575
Validation loss: 2.516154215299878

Epoch: 6| Step: 7
Training loss: 1.6826319945708397
Validation loss: 2.462419821382989

Epoch: 6| Step: 8
Training loss: 2.349994326645516
Validation loss: 2.4516980444356737

Epoch: 6| Step: 9
Training loss: 2.089296073096077
Validation loss: 2.4559347326591605

Epoch: 6| Step: 10
Training loss: 2.276153515148731
Validation loss: 2.4406992675956976

Epoch: 6| Step: 11
Training loss: 2.295615960530992
Validation loss: 2.4595075044960777

Epoch: 6| Step: 12
Training loss: 2.9344460053226906
Validation loss: 2.466269978894607

Epoch: 6| Step: 13
Training loss: 2.6483725030625935
Validation loss: 2.4763231364618403

Epoch: 136| Step: 0
Training loss: 2.6869028891877154
Validation loss: 2.4276844012551906

Epoch: 6| Step: 1
Training loss: 2.6043953350125544
Validation loss: 2.458560998412649

Epoch: 6| Step: 2
Training loss: 1.7949038100967973
Validation loss: 2.491696880121864

Epoch: 6| Step: 3
Training loss: 2.803408530364877
Validation loss: 2.466841409960128

Epoch: 6| Step: 4
Training loss: 2.3303015858375566
Validation loss: 2.4634021444710537

Epoch: 6| Step: 5
Training loss: 2.3276290877424994
Validation loss: 2.4706280689576303

Epoch: 6| Step: 6
Training loss: 1.7366793334167074
Validation loss: 2.4454089735455318

Epoch: 6| Step: 7
Training loss: 3.1573834791754884
Validation loss: 2.461170284097506

Epoch: 6| Step: 8
Training loss: 2.2714237063990725
Validation loss: 2.4398066668453633

Epoch: 6| Step: 9
Training loss: 2.692962240992007
Validation loss: 2.4577388447844495

Epoch: 6| Step: 10
Training loss: 2.071169808860739
Validation loss: 2.476634565817302

Epoch: 6| Step: 11
Training loss: 2.893846520941907
Validation loss: 2.4547640287208767

Epoch: 6| Step: 12
Training loss: 2.1808674124286562
Validation loss: 2.4524600181428506

Epoch: 6| Step: 13
Training loss: 2.826934057880116
Validation loss: 2.457744730929275

Epoch: 137| Step: 0
Training loss: 2.8465230646771964
Validation loss: 2.4543550259398548

Epoch: 6| Step: 1
Training loss: 2.0621245071309726
Validation loss: 2.475631768263399

Epoch: 6| Step: 2
Training loss: 2.1615836478678627
Validation loss: 2.464342112969998

Epoch: 6| Step: 3
Training loss: 2.0536844684456907
Validation loss: 2.5086686319429594

Epoch: 6| Step: 4
Training loss: 2.2444295805049674
Validation loss: 2.4752533006697153

Epoch: 6| Step: 5
Training loss: 2.677557184657653
Validation loss: 2.4717963994445338

Epoch: 6| Step: 6
Training loss: 2.436933304861364
Validation loss: 2.5078095875747644

Epoch: 6| Step: 7
Training loss: 3.046131532390233
Validation loss: 2.481583056129165

Epoch: 6| Step: 8
Training loss: 2.0971666613609137
Validation loss: 2.4649444924039434

Epoch: 6| Step: 9
Training loss: 2.1958721709994022
Validation loss: 2.4815609453056604

Epoch: 6| Step: 10
Training loss: 2.6659255686770083
Validation loss: 2.4701485598332464

Epoch: 6| Step: 11
Training loss: 1.955901773677747
Validation loss: 2.4726137482475745

Epoch: 6| Step: 12
Training loss: 3.197096944284734
Validation loss: 2.485745921188655

Epoch: 6| Step: 13
Training loss: 2.023545192371262
Validation loss: 2.4532429750561286

Epoch: 138| Step: 0
Training loss: 2.707087352441058
Validation loss: 2.460813854605723

Epoch: 6| Step: 1
Training loss: 1.9760649888011832
Validation loss: 2.462271675837826

Epoch: 6| Step: 2
Training loss: 2.278771504161018
Validation loss: 2.4592857942058273

Epoch: 6| Step: 3
Training loss: 2.773478590969808
Validation loss: 2.479625900999131

Epoch: 6| Step: 4
Training loss: 2.2191304699988232
Validation loss: 2.4576198650739434

Epoch: 6| Step: 5
Training loss: 2.7672978745886536
Validation loss: 2.4943720324870364

Epoch: 6| Step: 6
Training loss: 2.632863120659273
Validation loss: 2.4838982148641033

Epoch: 6| Step: 7
Training loss: 1.699356950423422
Validation loss: 2.46326949649614

Epoch: 6| Step: 8
Training loss: 2.1811964493001206
Validation loss: 2.467638072977526

Epoch: 6| Step: 9
Training loss: 2.891019886984259
Validation loss: 2.4865934456274363

Epoch: 6| Step: 10
Training loss: 2.0661470939363777
Validation loss: 2.4843997852185242

Epoch: 6| Step: 11
Training loss: 2.1755201090552037
Validation loss: 2.476090937250235

Epoch: 6| Step: 12
Training loss: 2.849298451059139
Validation loss: 2.456283184437822

Epoch: 6| Step: 13
Training loss: 2.5758363680254477
Validation loss: 2.4834519457551103

Epoch: 139| Step: 0
Training loss: 2.0073024235430412
Validation loss: 2.490271374151926

Epoch: 6| Step: 1
Training loss: 1.8593825652665816
Validation loss: 2.5042461790161035

Epoch: 6| Step: 2
Training loss: 2.4723658097343835
Validation loss: 2.4511770510728157

Epoch: 6| Step: 3
Training loss: 2.468693599780987
Validation loss: 2.449920669901172

Epoch: 6| Step: 4
Training loss: 2.494642716476135
Validation loss: 2.4618453354544125

Epoch: 6| Step: 5
Training loss: 2.7290068329655313
Validation loss: 2.4495848090225927

Epoch: 6| Step: 6
Training loss: 2.0621424278331695
Validation loss: 2.4588521455478167

Epoch: 6| Step: 7
Training loss: 2.3262854355414566
Validation loss: 2.4869897721166523

Epoch: 6| Step: 8
Training loss: 2.8563721945770015
Validation loss: 2.475119280517401

Epoch: 6| Step: 9
Training loss: 2.8437406099604585
Validation loss: 2.474098335195002

Epoch: 6| Step: 10
Training loss: 2.7645898810747265
Validation loss: 2.4559548915111464

Epoch: 6| Step: 11
Training loss: 2.4212749106918348
Validation loss: 2.4767015420127665

Epoch: 6| Step: 12
Training loss: 2.0355390602361503
Validation loss: 2.43085188712173

Epoch: 6| Step: 13
Training loss: 2.9125031499886567
Validation loss: 2.4418984960326213

Epoch: 140| Step: 0
Training loss: 2.86447122990281
Validation loss: 2.4718837586617415

Epoch: 6| Step: 1
Training loss: 2.6350948051755525
Validation loss: 2.452544819423764

Epoch: 6| Step: 2
Training loss: 2.537141795314655
Validation loss: 2.435005035417083

Epoch: 6| Step: 3
Training loss: 2.2947820353006456
Validation loss: 2.4541616920044573

Epoch: 6| Step: 4
Training loss: 2.5040781137695403
Validation loss: 2.4537219221412583

Epoch: 6| Step: 5
Training loss: 2.6159084553872587
Validation loss: 2.501940978701352

Epoch: 6| Step: 6
Training loss: 2.266853788543234
Validation loss: 2.460758295548202

Epoch: 6| Step: 7
Training loss: 2.3755113151664604
Validation loss: 2.467147989097039

Epoch: 6| Step: 8
Training loss: 2.332395387779285
Validation loss: 2.461901947751971

Epoch: 6| Step: 9
Training loss: 2.297847619724093
Validation loss: 2.4843496521399437

Epoch: 6| Step: 10
Training loss: 2.3421582729763135
Validation loss: 2.500115023807395

Epoch: 6| Step: 11
Training loss: 2.93578174740286
Validation loss: 2.4633153409801873

Epoch: 6| Step: 12
Training loss: 2.092049776633868
Validation loss: 2.46361180306042

Epoch: 6| Step: 13
Training loss: 1.4088789208494432
Validation loss: 2.479546186897134

Epoch: 141| Step: 0
Training loss: 2.6310127966876613
Validation loss: 2.463347198491378

Epoch: 6| Step: 1
Training loss: 2.0559797393453643
Validation loss: 2.480992524238949

Epoch: 6| Step: 2
Training loss: 2.4885681082809894
Validation loss: 2.489783952204993

Epoch: 6| Step: 3
Training loss: 2.064407160453892
Validation loss: 2.4544049862128903

Epoch: 6| Step: 4
Training loss: 2.864757370719346
Validation loss: 2.465096905539983

Epoch: 6| Step: 5
Training loss: 2.164524070459629
Validation loss: 2.481456638612248

Epoch: 6| Step: 6
Training loss: 3.1574840588140805
Validation loss: 2.4564205481302444

Epoch: 6| Step: 7
Training loss: 2.1581547382160697
Validation loss: 2.462081941529081

Epoch: 6| Step: 8
Training loss: 2.3937455299275943
Validation loss: 2.4637382855694607

Epoch: 6| Step: 9
Training loss: 2.5836508053367497
Validation loss: 2.4636080407591585

Epoch: 6| Step: 10
Training loss: 2.3995150155553286
Validation loss: 2.463009625924909

Epoch: 6| Step: 11
Training loss: 2.254082578640762
Validation loss: 2.455759150954979

Epoch: 6| Step: 12
Training loss: 2.714454590054154
Validation loss: 2.4477266201654997

Epoch: 6| Step: 13
Training loss: 1.7190923176509298
Validation loss: 2.444654119037689

Epoch: 142| Step: 0
Training loss: 2.3972339903404003
Validation loss: 2.476676119758173

Epoch: 6| Step: 1
Training loss: 2.8624411231236895
Validation loss: 2.4426639548567994

Epoch: 6| Step: 2
Training loss: 1.9487182341525864
Validation loss: 2.4592775308256596

Epoch: 6| Step: 3
Training loss: 2.7931613242176807
Validation loss: 2.4538673587596214

Epoch: 6| Step: 4
Training loss: 2.302236307392376
Validation loss: 2.476829594371864

Epoch: 6| Step: 5
Training loss: 1.9845029534365743
Validation loss: 2.46470938849177

Epoch: 6| Step: 6
Training loss: 2.559920245209744
Validation loss: 2.4824336500175725

Epoch: 6| Step: 7
Training loss: 2.9322070871264247
Validation loss: 2.480707630853363

Epoch: 6| Step: 8
Training loss: 2.6164146079211554
Validation loss: 2.454013799046534

Epoch: 6| Step: 9
Training loss: 2.0534934864298484
Validation loss: 2.4590450538943602

Epoch: 6| Step: 10
Training loss: 2.2454673888871475
Validation loss: 2.454721708031891

Epoch: 6| Step: 11
Training loss: 2.654046614570289
Validation loss: 2.476950784289634

Epoch: 6| Step: 12
Training loss: 2.0789456002153557
Validation loss: 2.482797083533218

Epoch: 6| Step: 13
Training loss: 2.7453297926608364
Validation loss: 2.5063863266761652

Epoch: 143| Step: 0
Training loss: 2.1386317419179632
Validation loss: 2.4560581278768203

Epoch: 6| Step: 1
Training loss: 2.4788712290764554
Validation loss: 2.497165930643093

Epoch: 6| Step: 2
Training loss: 2.301949843827205
Validation loss: 2.491998660766216

Epoch: 6| Step: 3
Training loss: 2.7093001376218497
Validation loss: 2.463124634807862

Epoch: 6| Step: 4
Training loss: 2.806192998158505
Validation loss: 2.4627449014848373

Epoch: 6| Step: 5
Training loss: 2.8820462332729253
Validation loss: 2.4667725001010603

Epoch: 6| Step: 6
Training loss: 2.4342181291095195
Validation loss: 2.506456944833235

Epoch: 6| Step: 7
Training loss: 2.4269578325516674
Validation loss: 2.4856940041956355

Epoch: 6| Step: 8
Training loss: 1.9926956426279854
Validation loss: 2.473031595653964

Epoch: 6| Step: 9
Training loss: 2.021111642871125
Validation loss: 2.4622438785542435

Epoch: 6| Step: 10
Training loss: 2.148324082588697
Validation loss: 2.4859835483369426

Epoch: 6| Step: 11
Training loss: 2.354775397894676
Validation loss: 2.4907214206040567

Epoch: 6| Step: 12
Training loss: 2.6877366782365577
Validation loss: 2.45600291530099

Epoch: 6| Step: 13
Training loss: 2.190467565432641
Validation loss: 2.446397388890879

Epoch: 144| Step: 0
Training loss: 2.708664702659882
Validation loss: 2.454430544096149

Epoch: 6| Step: 1
Training loss: 1.9662283233786386
Validation loss: 2.4689848053354653

Epoch: 6| Step: 2
Training loss: 2.046168664097565
Validation loss: 2.4623452374848127

Epoch: 6| Step: 3
Training loss: 2.113440883057868
Validation loss: 2.447853201360023

Epoch: 6| Step: 4
Training loss: 2.6895795361654327
Validation loss: 2.4901577395044328

Epoch: 6| Step: 5
Training loss: 2.281956393467994
Validation loss: 2.4571784735879376

Epoch: 6| Step: 6
Training loss: 2.518220498439278
Validation loss: 2.487502491764695

Epoch: 6| Step: 7
Training loss: 2.978042995288535
Validation loss: 2.484883448380459

Epoch: 6| Step: 8
Training loss: 2.6083264099939214
Validation loss: 2.4643935716221925

Epoch: 6| Step: 9
Training loss: 2.8592762747642433
Validation loss: 2.4387632198850775

Epoch: 6| Step: 10
Training loss: 1.7772629939586386
Validation loss: 2.4647354708821445

Epoch: 6| Step: 11
Training loss: 1.628691002691402
Validation loss: 2.456252833242671

Epoch: 6| Step: 12
Training loss: 3.0793449966210886
Validation loss: 2.463904507679587

Epoch: 6| Step: 13
Training loss: 2.0659931541543632
Validation loss: 2.433261829016199

Epoch: 145| Step: 0
Training loss: 2.181525327253499
Validation loss: 2.4530856911382597

Epoch: 6| Step: 1
Training loss: 1.501564243406937
Validation loss: 2.4808599446336985

Epoch: 6| Step: 2
Training loss: 3.002696097368066
Validation loss: 2.4493556149833693

Epoch: 6| Step: 3
Training loss: 2.178262990250168
Validation loss: 2.4357802132596515

Epoch: 6| Step: 4
Training loss: 2.9085129982033386
Validation loss: 2.444451659256563

Epoch: 6| Step: 5
Training loss: 3.102082408309672
Validation loss: 2.4574825376443243

Epoch: 6| Step: 6
Training loss: 2.855867329344944
Validation loss: 2.482395910279583

Epoch: 6| Step: 7
Training loss: 2.6171474169038778
Validation loss: 2.4380684981876555

Epoch: 6| Step: 8
Training loss: 1.3552713827625293
Validation loss: 2.4918982811521015

Epoch: 6| Step: 9
Training loss: 1.9425056767718265
Validation loss: 2.4571367119833836

Epoch: 6| Step: 10
Training loss: 2.33641195422698
Validation loss: 2.439377684407691

Epoch: 6| Step: 11
Training loss: 2.6337381880630653
Validation loss: 2.4723112257677933

Epoch: 6| Step: 12
Training loss: 2.2447652321046014
Validation loss: 2.4693241523923137

Epoch: 6| Step: 13
Training loss: 1.425465337165277
Validation loss: 2.442862004029821

Epoch: 146| Step: 0
Training loss: 2.3142192738530944
Validation loss: 2.46294664494861

Epoch: 6| Step: 1
Training loss: 2.1199054234479457
Validation loss: 2.489492640158654

Epoch: 6| Step: 2
Training loss: 2.6762581727403325
Validation loss: 2.461012657829169

Epoch: 6| Step: 3
Training loss: 2.4078765920021756
Validation loss: 2.4525211401697864

Epoch: 6| Step: 4
Training loss: 2.622761453081562
Validation loss: 2.4726262055368156

Epoch: 6| Step: 5
Training loss: 2.4220681390351912
Validation loss: 2.486751099892502

Epoch: 6| Step: 6
Training loss: 2.124347362153349
Validation loss: 2.4665892805328515

Epoch: 6| Step: 7
Training loss: 2.2903355518356783
Validation loss: 2.5047148411475586

Epoch: 6| Step: 8
Training loss: 2.5282377050525753
Validation loss: 2.4856729809033014

Epoch: 6| Step: 9
Training loss: 2.803016441054751
Validation loss: 2.465800968314813

Epoch: 6| Step: 10
Training loss: 2.204550424014267
Validation loss: 2.455822853868764

Epoch: 6| Step: 11
Training loss: 2.1233922823034606
Validation loss: 2.460353469366954

Epoch: 6| Step: 12
Training loss: 2.4810710506144362
Validation loss: 2.4689779990207836

Epoch: 6| Step: 13
Training loss: 2.797716578877335
Validation loss: 2.450395304682884

Epoch: 147| Step: 0
Training loss: 2.304203202393118
Validation loss: 2.4971555751050842

Epoch: 6| Step: 1
Training loss: 2.3064613886358614
Validation loss: 2.4549328927343224

Epoch: 6| Step: 2
Training loss: 2.3580200144441705
Validation loss: 2.475484966404876

Epoch: 6| Step: 3
Training loss: 2.3947727896759567
Validation loss: 2.4568413102920745

Epoch: 6| Step: 4
Training loss: 2.6433734021350888
Validation loss: 2.4965892690633784

Epoch: 6| Step: 5
Training loss: 3.1233384865223304
Validation loss: 2.5202699535282798

Epoch: 6| Step: 6
Training loss: 2.7131058433856445
Validation loss: 2.4641996114404967

Epoch: 6| Step: 7
Training loss: 2.015926013323065
Validation loss: 2.5089217924497773

Epoch: 6| Step: 8
Training loss: 2.481264962792623
Validation loss: 2.493285550423568

Epoch: 6| Step: 9
Training loss: 2.290543945876866
Validation loss: 2.476455708430048

Epoch: 6| Step: 10
Training loss: 2.355613792597222
Validation loss: 2.511143865296691

Epoch: 6| Step: 11
Training loss: 1.912947349338275
Validation loss: 2.4719299712697875

Epoch: 6| Step: 12
Training loss: 2.29502295738157
Validation loss: 2.4870155940421195

Epoch: 6| Step: 13
Training loss: 2.3439532382584107
Validation loss: 2.4772167460253893

Epoch: 148| Step: 0
Training loss: 2.4221542689603446
Validation loss: 2.4755400903542895

Epoch: 6| Step: 1
Training loss: 2.9781048000487225
Validation loss: 2.4917639324423138

Epoch: 6| Step: 2
Training loss: 2.138082065859288
Validation loss: 2.4690144683959945

Epoch: 6| Step: 3
Training loss: 2.471917932573988
Validation loss: 2.4730824422669646

Epoch: 6| Step: 4
Training loss: 2.6084113254607195
Validation loss: 2.4539056333654243

Epoch: 6| Step: 5
Training loss: 2.8818079741209393
Validation loss: 2.4486509298403956

Epoch: 6| Step: 6
Training loss: 2.252015906167645
Validation loss: 2.467800362206503

Epoch: 6| Step: 7
Training loss: 2.3667009816793776
Validation loss: 2.4735604840737815

Epoch: 6| Step: 8
Training loss: 2.419302872745718
Validation loss: 2.46438213067969

Epoch: 6| Step: 9
Training loss: 2.2478608452975415
Validation loss: 2.473209271762267

Epoch: 6| Step: 10
Training loss: 2.1612478743587387
Validation loss: 2.4566618769559163

Epoch: 6| Step: 11
Training loss: 1.9719164376960447
Validation loss: 2.4721676913522193

Epoch: 6| Step: 12
Training loss: 1.7538804220154247
Validation loss: 2.437631428396022

Epoch: 6| Step: 13
Training loss: 2.995715737897639
Validation loss: 2.4735402168523692

Epoch: 149| Step: 0
Training loss: 2.254679793399533
Validation loss: 2.4768855459151924

Epoch: 6| Step: 1
Training loss: 2.2590807880142094
Validation loss: 2.480562909061981

Epoch: 6| Step: 2
Training loss: 1.9322068297757946
Validation loss: 2.45001922007211

Epoch: 6| Step: 3
Training loss: 2.643846882517178
Validation loss: 2.4687755973322747

Epoch: 6| Step: 4
Training loss: 1.9458507727659018
Validation loss: 2.4497235215612223

Epoch: 6| Step: 5
Training loss: 2.3933118294659232
Validation loss: 2.440804638577058

Epoch: 6| Step: 6
Training loss: 2.379563615045178
Validation loss: 2.439916575512079

Epoch: 6| Step: 7
Training loss: 2.6258957560665874
Validation loss: 2.4781951165669835

Epoch: 6| Step: 8
Training loss: 2.814982018421803
Validation loss: 2.458071494684026

Epoch: 6| Step: 9
Training loss: 2.542455102754801
Validation loss: 2.461639923882002

Epoch: 6| Step: 10
Training loss: 2.3796247327495523
Validation loss: 2.485990854647245

Epoch: 6| Step: 11
Training loss: 2.6963963195402174
Validation loss: 2.4691193962245244

Epoch: 6| Step: 12
Training loss: 2.1355813187800448
Validation loss: 2.4600393968826126

Epoch: 6| Step: 13
Training loss: 2.668184285652351
Validation loss: 2.4653871274463395

Epoch: 150| Step: 0
Training loss: 3.0417035941055355
Validation loss: 2.460934987337907

Epoch: 6| Step: 1
Training loss: 1.9729359645631492
Validation loss: 2.4388958699670598

Epoch: 6| Step: 2
Training loss: 2.325291490227917
Validation loss: 2.4616376972906533

Epoch: 6| Step: 3
Training loss: 1.9081640795926924
Validation loss: 2.4417132000001267

Epoch: 6| Step: 4
Training loss: 2.7762715218854983
Validation loss: 2.48518637463129

Epoch: 6| Step: 5
Training loss: 2.454372599002916
Validation loss: 2.4520135376859025

Epoch: 6| Step: 6
Training loss: 2.453786870025496
Validation loss: 2.463184581515711

Epoch: 6| Step: 7
Training loss: 2.1708070613079173
Validation loss: 2.482595957191627

Epoch: 6| Step: 8
Training loss: 2.652274264294847
Validation loss: 2.4756567248941432

Epoch: 6| Step: 9
Training loss: 2.857691701898255
Validation loss: 2.500108765727974

Epoch: 6| Step: 10
Training loss: 1.582979346742444
Validation loss: 2.4703475012034692

Epoch: 6| Step: 11
Training loss: 2.2364482730757067
Validation loss: 2.5131787040064206

Epoch: 6| Step: 12
Training loss: 2.388646522568342
Validation loss: 2.4896526665973835

Epoch: 6| Step: 13
Training loss: 2.170203025039675
Validation loss: 2.457781251206558

Epoch: 151| Step: 0
Training loss: 2.902381044458823
Validation loss: 2.4766138434478018

Epoch: 6| Step: 1
Training loss: 2.332579581813483
Validation loss: 2.449999675788381

Epoch: 6| Step: 2
Training loss: 2.521426317653166
Validation loss: 2.4856788349344727

Epoch: 6| Step: 3
Training loss: 2.6813114683845893
Validation loss: 2.461964303600281

Epoch: 6| Step: 4
Training loss: 2.575391024926975
Validation loss: 2.4504295658963526

Epoch: 6| Step: 5
Training loss: 2.0369190628234723
Validation loss: 2.4442595851365785

Epoch: 6| Step: 6
Training loss: 2.9045661231952824
Validation loss: 2.438252016715853

Epoch: 6| Step: 7
Training loss: 1.7906855920788984
Validation loss: 2.478969822265489

Epoch: 6| Step: 8
Training loss: 2.355011599890777
Validation loss: 2.4264107985806835

Epoch: 6| Step: 9
Training loss: 2.490387556563188
Validation loss: 2.423642746357412

Epoch: 6| Step: 10
Training loss: 2.0858437734970767
Validation loss: 2.460388030579422

Epoch: 6| Step: 11
Training loss: 2.2144170010228303
Validation loss: 2.476326591125211

Epoch: 6| Step: 12
Training loss: 2.0472963787550102
Validation loss: 2.4665440222992707

Epoch: 6| Step: 13
Training loss: 2.0285622053493158
Validation loss: 2.4735372163981655

Epoch: 152| Step: 0
Training loss: 2.2162357107391397
Validation loss: 2.4490550274111778

Epoch: 6| Step: 1
Training loss: 2.557695117417177
Validation loss: 2.4631359712660945

Epoch: 6| Step: 2
Training loss: 2.4497379318517765
Validation loss: 2.4181443287722284

Epoch: 6| Step: 3
Training loss: 1.8263943296995295
Validation loss: 2.478209030269549

Epoch: 6| Step: 4
Training loss: 1.9774467088774341
Validation loss: 2.454683617430256

Epoch: 6| Step: 5
Training loss: 2.672269647018379
Validation loss: 2.4432951183940252

Epoch: 6| Step: 6
Training loss: 2.396729895863442
Validation loss: 2.457029545100947

Epoch: 6| Step: 7
Training loss: 2.8265310611526355
Validation loss: 2.4556106776990276

Epoch: 6| Step: 8
Training loss: 2.276005399110957
Validation loss: 2.464841569986298

Epoch: 6| Step: 9
Training loss: 1.8302638266032945
Validation loss: 2.446538261565206

Epoch: 6| Step: 10
Training loss: 2.843572590083334
Validation loss: 2.469246456789363

Epoch: 6| Step: 11
Training loss: 2.256473976071406
Validation loss: 2.4795154985514953

Epoch: 6| Step: 12
Training loss: 2.3987983158845445
Validation loss: 2.481412840167995

Epoch: 6| Step: 13
Training loss: 2.5851967664018156
Validation loss: 2.4723426832438435

Epoch: 153| Step: 0
Training loss: 2.00489684488818
Validation loss: 2.4663243717336765

Epoch: 6| Step: 1
Training loss: 2.461214952117621
Validation loss: 2.443689006506573

Epoch: 6| Step: 2
Training loss: 2.548838040270465
Validation loss: 2.4642140421525895

Epoch: 6| Step: 3
Training loss: 2.3712222521681188
Validation loss: 2.4516549064311954

Epoch: 6| Step: 4
Training loss: 2.4476857719016896
Validation loss: 2.440892347626921

Epoch: 6| Step: 5
Training loss: 2.2064225429249147
Validation loss: 2.487755253120986

Epoch: 6| Step: 6
Training loss: 2.7046971682899663
Validation loss: 2.459548847483387

Epoch: 6| Step: 7
Training loss: 2.3813179707275465
Validation loss: 2.4988750449338255

Epoch: 6| Step: 8
Training loss: 2.0548527292167513
Validation loss: 2.4348652064145626

Epoch: 6| Step: 9
Training loss: 2.2023532679129865
Validation loss: 2.482992186619897

Epoch: 6| Step: 10
Training loss: 2.069777048792397
Validation loss: 2.4580606094121307

Epoch: 6| Step: 11
Training loss: 2.395294416325757
Validation loss: 2.455466051162094

Epoch: 6| Step: 12
Training loss: 2.622156146756175
Validation loss: 2.4953641177978705

Epoch: 6| Step: 13
Training loss: 2.9980588036713014
Validation loss: 2.4887249035087344

Epoch: 154| Step: 0
Training loss: 2.752193356513485
Validation loss: 2.4735284668663704

Epoch: 6| Step: 1
Training loss: 1.8827540598303696
Validation loss: 2.461840493696612

Epoch: 6| Step: 2
Training loss: 2.2521961937878547
Validation loss: 2.4919577764103433

Epoch: 6| Step: 3
Training loss: 2.9529959837165696
Validation loss: 2.436523109222455

Epoch: 6| Step: 4
Training loss: 2.371094453864959
Validation loss: 2.4605168860964945

Epoch: 6| Step: 5
Training loss: 2.5420789436369544
Validation loss: 2.437089779823974

Epoch: 6| Step: 6
Training loss: 2.1235503693731044
Validation loss: 2.4737635658335453

Epoch: 6| Step: 7
Training loss: 1.5472977185887502
Validation loss: 2.470500280420965

Epoch: 6| Step: 8
Training loss: 1.9998262449127722
Validation loss: 2.4735177501505734

Epoch: 6| Step: 9
Training loss: 1.8677051417218362
Validation loss: 2.4922350004811946

Epoch: 6| Step: 10
Training loss: 2.6994584635439245
Validation loss: 2.453643173503416

Epoch: 6| Step: 11
Training loss: 2.56235410693681
Validation loss: 2.4778130912934477

Epoch: 6| Step: 12
Training loss: 2.5276288162141514
Validation loss: 2.450741714458395

Epoch: 6| Step: 13
Training loss: 3.1517410553037983
Validation loss: 2.429460751083796

Epoch: 155| Step: 0
Training loss: 2.982717962750166
Validation loss: 2.435276812972822

Epoch: 6| Step: 1
Training loss: 2.342693141437381
Validation loss: 2.43297975930863

Epoch: 6| Step: 2
Training loss: 3.2305705966601135
Validation loss: 2.4657894226563135

Epoch: 6| Step: 3
Training loss: 2.3066433124058223
Validation loss: 2.4691091670554135

Epoch: 6| Step: 4
Training loss: 2.3056792630733054
Validation loss: 2.4713633692603647

Epoch: 6| Step: 5
Training loss: 1.6694215973263766
Validation loss: 2.471332721938524

Epoch: 6| Step: 6
Training loss: 2.1654301807578133
Validation loss: 2.460408836468221

Epoch: 6| Step: 7
Training loss: 2.2626134390870987
Validation loss: 2.5085033045049756

Epoch: 6| Step: 8
Training loss: 2.031735054202406
Validation loss: 2.4365068425938414

Epoch: 6| Step: 9
Training loss: 2.1415785176384947
Validation loss: 2.4654077580470397

Epoch: 6| Step: 10
Training loss: 2.8447285739565493
Validation loss: 2.4671346816860176

Epoch: 6| Step: 11
Training loss: 2.6422273187327057
Validation loss: 2.4611921499982565

Epoch: 6| Step: 12
Training loss: 1.271037689829688
Validation loss: 2.486145438146359

Epoch: 6| Step: 13
Training loss: 2.255928388588542
Validation loss: 2.487408596426283

Epoch: 156| Step: 0
Training loss: 2.683394911949973
Validation loss: 2.4439063769600433

Epoch: 6| Step: 1
Training loss: 2.0352363790307684
Validation loss: 2.4575796809212407

Epoch: 6| Step: 2
Training loss: 2.213026805165464
Validation loss: 2.446306469240729

Epoch: 6| Step: 3
Training loss: 2.870546789684003
Validation loss: 2.4872086253157404

Epoch: 6| Step: 4
Training loss: 2.694562990217886
Validation loss: 2.4644255150600056

Epoch: 6| Step: 5
Training loss: 2.1494587638397507
Validation loss: 2.4624646936940824

Epoch: 6| Step: 6
Training loss: 2.336387055174749
Validation loss: 2.4711830410739153

Epoch: 6| Step: 7
Training loss: 1.8880346538870956
Validation loss: 2.4666719747412498

Epoch: 6| Step: 8
Training loss: 2.1834326942295963
Validation loss: 2.4690675137983424

Epoch: 6| Step: 9
Training loss: 2.2043592093680604
Validation loss: 2.458041108729057

Epoch: 6| Step: 10
Training loss: 2.451157090343858
Validation loss: 2.477395852703923

Epoch: 6| Step: 11
Training loss: 2.9639025816461597
Validation loss: 2.4657376209203017

Epoch: 6| Step: 12
Training loss: 1.7242310952633486
Validation loss: 2.441650558750193

Epoch: 6| Step: 13
Training loss: 2.6632682086046753
Validation loss: 2.4585746832982722

Epoch: 157| Step: 0
Training loss: 2.106249040099698
Validation loss: 2.487613520837997

Epoch: 6| Step: 1
Training loss: 2.832273023084978
Validation loss: 2.458644179527536

Epoch: 6| Step: 2
Training loss: 2.28545024317439
Validation loss: 2.474652272401268

Epoch: 6| Step: 3
Training loss: 1.7434870914805132
Validation loss: 2.4679932728032834

Epoch: 6| Step: 4
Training loss: 1.9062977769211278
Validation loss: 2.440263971163024

Epoch: 6| Step: 5
Training loss: 2.2389442300806373
Validation loss: 2.45625131776051

Epoch: 6| Step: 6
Training loss: 2.3730689781635235
Validation loss: 2.449718979738207

Epoch: 6| Step: 7
Training loss: 2.7114114924129398
Validation loss: 2.4775878226792916

Epoch: 6| Step: 8
Training loss: 1.9512671828261792
Validation loss: 2.477222129504294

Epoch: 6| Step: 9
Training loss: 2.5583948888010735
Validation loss: 2.446170368491315

Epoch: 6| Step: 10
Training loss: 2.2945715324338996
Validation loss: 2.45025943314221

Epoch: 6| Step: 11
Training loss: 2.9234761629550206
Validation loss: 2.427795781612842

Epoch: 6| Step: 12
Training loss: 2.271766494195737
Validation loss: 2.4291878436988834

Epoch: 6| Step: 13
Training loss: 2.508759221856883
Validation loss: 2.4629030117647783

Epoch: 158| Step: 0
Training loss: 2.096397206751173
Validation loss: 2.4862958040843197

Epoch: 6| Step: 1
Training loss: 2.0105197333235743
Validation loss: 2.4242234851538074

Epoch: 6| Step: 2
Training loss: 1.9086222661714751
Validation loss: 2.4668697597488816

Epoch: 6| Step: 3
Training loss: 2.7194633863354625
Validation loss: 2.4610444045200413

Epoch: 6| Step: 4
Training loss: 2.4553500247208104
Validation loss: 2.474441704065543

Epoch: 6| Step: 5
Training loss: 1.718767755590106
Validation loss: 2.4394392760959795

Epoch: 6| Step: 6
Training loss: 1.964710572357398
Validation loss: 2.4944460714219967

Epoch: 6| Step: 7
Training loss: 2.438224293618955
Validation loss: 2.4772796239567634

Epoch: 6| Step: 8
Training loss: 2.982126877140667
Validation loss: 2.4437895520154633

Epoch: 6| Step: 9
Training loss: 3.0749287542757915
Validation loss: 2.464095141009654

Epoch: 6| Step: 10
Training loss: 2.7671907809392606
Validation loss: 2.4552758222648627

Epoch: 6| Step: 11
Training loss: 2.041251575027858
Validation loss: 2.4615303155014

Epoch: 6| Step: 12
Training loss: 1.619907542639718
Validation loss: 2.48862608746226

Epoch: 6| Step: 13
Training loss: 2.769885214069546
Validation loss: 2.4785857339919173

Epoch: 159| Step: 0
Training loss: 1.5412414926756668
Validation loss: 2.4465482864645076

Epoch: 6| Step: 1
Training loss: 2.052371500246584
Validation loss: 2.502728014644556

Epoch: 6| Step: 2
Training loss: 2.5850924583442807
Validation loss: 2.4701282376329563

Epoch: 6| Step: 3
Training loss: 2.1592401973090656
Validation loss: 2.4879225878742317

Epoch: 6| Step: 4
Training loss: 2.0518900462356213
Validation loss: 2.454135690491474

Epoch: 6| Step: 5
Training loss: 2.3924730924012017
Validation loss: 2.4872564053783464

Epoch: 6| Step: 6
Training loss: 1.7679970260698672
Validation loss: 2.4838081177983717

Epoch: 6| Step: 7
Training loss: 2.6770631267413374
Validation loss: 2.499551642626272

Epoch: 6| Step: 8
Training loss: 2.433886661934382
Validation loss: 2.4799622351622155

Epoch: 6| Step: 9
Training loss: 2.293406664023394
Validation loss: 2.4818244173096717

Epoch: 6| Step: 10
Training loss: 2.9178095803517374
Validation loss: 2.4897972945539615

Epoch: 6| Step: 11
Training loss: 2.8597165096605295
Validation loss: 2.473744826805213

Epoch: 6| Step: 12
Training loss: 2.1752923659335583
Validation loss: 2.4359191320056826

Epoch: 6| Step: 13
Training loss: 2.6177445914786683
Validation loss: 2.4700426533990876

Epoch: 160| Step: 0
Training loss: 1.5859450166270457
Validation loss: 2.4784719256005308

Epoch: 6| Step: 1
Training loss: 2.08003984156378
Validation loss: 2.4752449963458343

Epoch: 6| Step: 2
Training loss: 2.287957351073667
Validation loss: 2.496801149999359

Epoch: 6| Step: 3
Training loss: 2.1122615702227883
Validation loss: 2.430362592460749

Epoch: 6| Step: 4
Training loss: 2.1511946308961303
Validation loss: 2.4487757609855954

Epoch: 6| Step: 5
Training loss: 2.402692270196846
Validation loss: 2.4464866453103014

Epoch: 6| Step: 6
Training loss: 2.9852183483526473
Validation loss: 2.4757735693213894

Epoch: 6| Step: 7
Training loss: 2.669831325332201
Validation loss: 2.434679341404882

Epoch: 6| Step: 8
Training loss: 2.5134982009799303
Validation loss: 2.4378802263512465

Epoch: 6| Step: 9
Training loss: 2.832704324650484
Validation loss: 2.4310229119820232

Epoch: 6| Step: 10
Training loss: 2.413659713376162
Validation loss: 2.404416384349588

Epoch: 6| Step: 11
Training loss: 1.8330815604753479
Validation loss: 2.450091446138238

Epoch: 6| Step: 12
Training loss: 2.4493906547900743
Validation loss: 2.4734842678878097

Epoch: 6| Step: 13
Training loss: 2.2217470800218124
Validation loss: 2.4515286632289395

Epoch: 161| Step: 0
Training loss: 2.6565376574767465
Validation loss: 2.5191451202654664

Epoch: 6| Step: 1
Training loss: 1.7414484894303108
Validation loss: 2.4939537089117167

Epoch: 6| Step: 2
Training loss: 1.8351805080013905
Validation loss: 2.45222673964834

Epoch: 6| Step: 3
Training loss: 2.5145080171655634
Validation loss: 2.4712804959268553

Epoch: 6| Step: 4
Training loss: 1.543782620722411
Validation loss: 2.4676127048737126

Epoch: 6| Step: 5
Training loss: 2.9586804325126765
Validation loss: 2.4604917425617097

Epoch: 6| Step: 6
Training loss: 2.4348405855544195
Validation loss: 2.4501314371131073

Epoch: 6| Step: 7
Training loss: 2.025492445796759
Validation loss: 2.476497059369573

Epoch: 6| Step: 8
Training loss: 2.1289185689867205
Validation loss: 2.4511922408851503

Epoch: 6| Step: 9
Training loss: 2.5570481152652835
Validation loss: 2.4645386036941095

Epoch: 6| Step: 10
Training loss: 2.3934710148318765
Validation loss: 2.4726357172025506

Epoch: 6| Step: 11
Training loss: 2.6071775400501203
Validation loss: 2.456704205963502

Epoch: 6| Step: 12
Training loss: 2.7142342960535464
Validation loss: 2.472720704706886

Epoch: 6| Step: 13
Training loss: 2.166573290157699
Validation loss: 2.4493050540179437

Epoch: 162| Step: 0
Training loss: 2.3493142771097775
Validation loss: 2.4829308121320794

Epoch: 6| Step: 1
Training loss: 1.746737572684331
Validation loss: 2.441676146455857

Epoch: 6| Step: 2
Training loss: 2.289559476367713
Validation loss: 2.4542894987389428

Epoch: 6| Step: 3
Training loss: 2.416191865603535
Validation loss: 2.4288559032478414

Epoch: 6| Step: 4
Training loss: 2.244659231104298
Validation loss: 2.3830197835028595

Epoch: 6| Step: 5
Training loss: 2.8801409326614884
Validation loss: 2.445747114344751

Epoch: 6| Step: 6
Training loss: 2.8082137613470497
Validation loss: 2.46010746315719

Epoch: 6| Step: 7
Training loss: 2.391655394453363
Validation loss: 2.443860976122119

Epoch: 6| Step: 8
Training loss: 2.317922472258799
Validation loss: 2.457746523994514

Epoch: 6| Step: 9
Training loss: 2.3522896387014165
Validation loss: 2.42410314069853

Epoch: 6| Step: 10
Training loss: 2.75418743023762
Validation loss: 2.4052433086321514

Epoch: 6| Step: 11
Training loss: 1.6498566073908276
Validation loss: 2.471984867518685

Epoch: 6| Step: 12
Training loss: 1.983806739000515
Validation loss: 2.4356974701489746

Epoch: 6| Step: 13
Training loss: 2.6300062851051105
Validation loss: 2.4560996019917054

Epoch: 163| Step: 0
Training loss: 2.4694952503876197
Validation loss: 2.47293137656222

Epoch: 6| Step: 1
Training loss: 2.316699879451677
Validation loss: 2.4704715686237355

Epoch: 6| Step: 2
Training loss: 2.766087121663041
Validation loss: 2.4440998287850455

Epoch: 6| Step: 3
Training loss: 1.9655943511853775
Validation loss: 2.442236733958715

Epoch: 6| Step: 4
Training loss: 2.4924953354282025
Validation loss: 2.4530357290776563

Epoch: 6| Step: 5
Training loss: 2.5863158534107
Validation loss: 2.4928426833816784

Epoch: 6| Step: 6
Training loss: 1.664600482354214
Validation loss: 2.4613050200383797

Epoch: 6| Step: 7
Training loss: 2.0482931102200084
Validation loss: 2.4671328279012825

Epoch: 6| Step: 8
Training loss: 2.4220624297433413
Validation loss: 2.5116330631361863

Epoch: 6| Step: 9
Training loss: 2.086314649454468
Validation loss: 2.4547317579952956

Epoch: 6| Step: 10
Training loss: 2.2677209038678803
Validation loss: 2.4641581717000047

Epoch: 6| Step: 11
Training loss: 2.956242928688028
Validation loss: 2.4719316461870675

Epoch: 6| Step: 12
Training loss: 2.3341853992927564
Validation loss: 2.458492811636066

Epoch: 6| Step: 13
Training loss: 2.058609732578493
Validation loss: 2.477211325278754

Epoch: 164| Step: 0
Training loss: 2.1557121158824755
Validation loss: 2.4190552814359507

Epoch: 6| Step: 1
Training loss: 2.3520175835672283
Validation loss: 2.429013158184413

Epoch: 6| Step: 2
Training loss: 2.2357577866814613
Validation loss: 2.4095712941343197

Epoch: 6| Step: 3
Training loss: 2.8801187474883374
Validation loss: 2.4618973742472705

Epoch: 6| Step: 4
Training loss: 2.4755974944256867
Validation loss: 2.425842088879606

Epoch: 6| Step: 5
Training loss: 2.4900243094609626
Validation loss: 2.4429285345632463

Epoch: 6| Step: 6
Training loss: 2.048355149767754
Validation loss: 2.498795126703384

Epoch: 6| Step: 7
Training loss: 2.330477147178343
Validation loss: 2.448253239987359

Epoch: 6| Step: 8
Training loss: 2.6552347374719774
Validation loss: 2.454356633466722

Epoch: 6| Step: 9
Training loss: 2.1402536334601914
Validation loss: 2.425547998843407

Epoch: 6| Step: 10
Training loss: 2.4443078460481287
Validation loss: 2.454866025444534

Epoch: 6| Step: 11
Training loss: 2.206061604266492
Validation loss: 2.4632928726062957

Epoch: 6| Step: 12
Training loss: 2.1844088921489413
Validation loss: 2.465272587557878

Epoch: 6| Step: 13
Training loss: 1.6534846990781165
Validation loss: 2.4425789511741973

Epoch: 165| Step: 0
Training loss: 2.3422775729662786
Validation loss: 2.4760542066163205

Epoch: 6| Step: 1
Training loss: 2.318206756376061
Validation loss: 2.444000584679405

Epoch: 6| Step: 2
Training loss: 2.3716917587886615
Validation loss: 2.4508410093341104

Epoch: 6| Step: 3
Training loss: 2.2511623347283964
Validation loss: 2.444920621386535

Epoch: 6| Step: 4
Training loss: 1.7582015899671843
Validation loss: 2.48199260019411

Epoch: 6| Step: 5
Training loss: 1.6446240324182948
Validation loss: 2.4408236599072657

Epoch: 6| Step: 6
Training loss: 2.1931228306331
Validation loss: 2.424024494843243

Epoch: 6| Step: 7
Training loss: 2.240483823023605
Validation loss: 2.4967362336727374

Epoch: 6| Step: 8
Training loss: 2.383343746811674
Validation loss: 2.4905888555467595

Epoch: 6| Step: 9
Training loss: 2.4298226174811806
Validation loss: 2.4659828762586367

Epoch: 6| Step: 10
Training loss: 2.9678757835984504
Validation loss: 2.4955035422477043

Epoch: 6| Step: 11
Training loss: 2.568288081234831
Validation loss: 2.461045140993408

Epoch: 6| Step: 12
Training loss: 2.0818078241472984
Validation loss: 2.4343072560324286

Epoch: 6| Step: 13
Training loss: 2.463589066310874
Validation loss: 2.425190453957562

Epoch: 166| Step: 0
Training loss: 2.867777334968066
Validation loss: 2.4490660280782226

Epoch: 6| Step: 1
Training loss: 2.039930604614546
Validation loss: 2.467248394792032

Epoch: 6| Step: 2
Training loss: 2.2653017010709635
Validation loss: 2.4598743221051285

Epoch: 6| Step: 3
Training loss: 2.2194411584763225
Validation loss: 2.4649417071755044

Epoch: 6| Step: 4
Training loss: 2.7491978429079023
Validation loss: 2.4663571638174004

Epoch: 6| Step: 5
Training loss: 2.3874710320917294
Validation loss: 2.415517694765711

Epoch: 6| Step: 6
Training loss: 2.149440905599649
Validation loss: 2.45194862804167

Epoch: 6| Step: 7
Training loss: 2.401068322508851
Validation loss: 2.471499308746112

Epoch: 6| Step: 8
Training loss: 2.4744945279683512
Validation loss: 2.4758801728702027

Epoch: 6| Step: 9
Training loss: 1.8447663690120202
Validation loss: 2.4877720162658585

Epoch: 6| Step: 10
Training loss: 2.8194932249596314
Validation loss: 2.459333898369182

Epoch: 6| Step: 11
Training loss: 2.0043316662835013
Validation loss: 2.46500707601074

Epoch: 6| Step: 12
Training loss: 1.9909588783803676
Validation loss: 2.439095911004213

Epoch: 6| Step: 13
Training loss: 2.0710592974283366
Validation loss: 2.449264284937151

Epoch: 167| Step: 0
Training loss: 2.471459748585721
Validation loss: 2.446191982803858

Epoch: 6| Step: 1
Training loss: 2.404608724095734
Validation loss: 2.4456407592108365

Epoch: 6| Step: 2
Training loss: 2.050619645790428
Validation loss: 2.455603555567683

Epoch: 6| Step: 3
Training loss: 2.5440521510674805
Validation loss: 2.4448780831228616

Epoch: 6| Step: 4
Training loss: 2.5505822470647264
Validation loss: 2.428768043468987

Epoch: 6| Step: 5
Training loss: 2.0223635618307365
Validation loss: 2.4451234785008102

Epoch: 6| Step: 6
Training loss: 1.9581820517470852
Validation loss: 2.439507839907804

Epoch: 6| Step: 7
Training loss: 2.707025437121735
Validation loss: 2.412944358067711

Epoch: 6| Step: 8
Training loss: 1.9849194958598586
Validation loss: 2.4729862510998872

Epoch: 6| Step: 9
Training loss: 2.1143604280092005
Validation loss: 2.4428578073098706

Epoch: 6| Step: 10
Training loss: 1.9739997745347595
Validation loss: 2.471559352096599

Epoch: 6| Step: 11
Training loss: 1.8612633100434675
Validation loss: 2.4656732529606398

Epoch: 6| Step: 12
Training loss: 2.6567958495330783
Validation loss: 2.464032985785088

Epoch: 6| Step: 13
Training loss: 3.005717709817547
Validation loss: 2.4469909584543883

Epoch: 168| Step: 0
Training loss: 2.5413124796574498
Validation loss: 2.4801052978002436

Epoch: 6| Step: 1
Training loss: 2.004705258630483
Validation loss: 2.4560820016210823

Epoch: 6| Step: 2
Training loss: 2.336344195528923
Validation loss: 2.4617698541842374

Epoch: 6| Step: 3
Training loss: 1.8496311593308616
Validation loss: 2.445952931968097

Epoch: 6| Step: 4
Training loss: 2.461366549435482
Validation loss: 2.489560890242475

Epoch: 6| Step: 5
Training loss: 2.1684112372198157
Validation loss: 2.4558250575468286

Epoch: 6| Step: 6
Training loss: 2.0600454579124636
Validation loss: 2.4484837125097485

Epoch: 6| Step: 7
Training loss: 2.5153579096250267
Validation loss: 2.4859532441931615

Epoch: 6| Step: 8
Training loss: 2.6661390338882294
Validation loss: 2.485659591663196

Epoch: 6| Step: 9
Training loss: 1.9709315247972095
Validation loss: 2.47035321201869

Epoch: 6| Step: 10
Training loss: 2.3709580007088884
Validation loss: 2.468943686810024

Epoch: 6| Step: 11
Training loss: 2.8564815368963763
Validation loss: 2.4510998805403106

Epoch: 6| Step: 12
Training loss: 2.4866104145522607
Validation loss: 2.4530556567535977

Epoch: 6| Step: 13
Training loss: 1.3755946607420102
Validation loss: 2.474085039003961

Epoch: 169| Step: 0
Training loss: 3.0176966375392706
Validation loss: 2.4348656623150733

Epoch: 6| Step: 1
Training loss: 1.7670617798355248
Validation loss: 2.4487880244242026

Epoch: 6| Step: 2
Training loss: 1.9642226221430144
Validation loss: 2.5040397818967555

Epoch: 6| Step: 3
Training loss: 2.671493324547034
Validation loss: 2.456410830695993

Epoch: 6| Step: 4
Training loss: 1.8520671301677558
Validation loss: 2.4363558692102605

Epoch: 6| Step: 5
Training loss: 2.3768133970267606
Validation loss: 2.434322950243306

Epoch: 6| Step: 6
Training loss: 2.5553815639624085
Validation loss: 2.4718119339314306

Epoch: 6| Step: 7
Training loss: 1.808143773962158
Validation loss: 2.45036513479153

Epoch: 6| Step: 8
Training loss: 2.2781979772864687
Validation loss: 2.4834874180557382

Epoch: 6| Step: 9
Training loss: 2.117902233918394
Validation loss: 2.444166857407536

Epoch: 6| Step: 10
Training loss: 2.5973133291039447
Validation loss: 2.4245141359927564

Epoch: 6| Step: 11
Training loss: 2.2413134848543916
Validation loss: 2.438756968359601

Epoch: 6| Step: 12
Training loss: 2.3001156736393895
Validation loss: 2.4550160505826355

Epoch: 6| Step: 13
Training loss: 2.174436526917888
Validation loss: 2.471016989554967

Epoch: 170| Step: 0
Training loss: 1.992422232169192
Validation loss: 2.446488051573749

Epoch: 6| Step: 1
Training loss: 2.249352361931367
Validation loss: 2.457149796013115

Epoch: 6| Step: 2
Training loss: 1.9339313250935832
Validation loss: 2.4716949343789945

Epoch: 6| Step: 3
Training loss: 1.73480913382112
Validation loss: 2.4702756110496535

Epoch: 6| Step: 4
Training loss: 2.939718180014076
Validation loss: 2.4599615085964284

Epoch: 6| Step: 5
Training loss: 2.443983990718271
Validation loss: 2.4625536842255715

Epoch: 6| Step: 6
Training loss: 2.5500677959929137
Validation loss: 2.4727457373722044

Epoch: 6| Step: 7
Training loss: 1.9840921515782954
Validation loss: 2.495131132189112

Epoch: 6| Step: 8
Training loss: 2.2999798815303443
Validation loss: 2.4654940168364567

Epoch: 6| Step: 9
Training loss: 2.7697154684633434
Validation loss: 2.4976028532285914

Epoch: 6| Step: 10
Training loss: 1.9136253636274043
Validation loss: 2.4285083303620225

Epoch: 6| Step: 11
Training loss: 2.375269824310756
Validation loss: 2.4745111841020857

Epoch: 6| Step: 12
Training loss: 3.025075857929521
Validation loss: 2.4845247384141858

Epoch: 6| Step: 13
Training loss: 1.7758928685954425
Validation loss: 2.521705918466883

Epoch: 171| Step: 0
Training loss: 1.6624163871906534
Validation loss: 2.470548706339371

Epoch: 6| Step: 1
Training loss: 1.8584784261515066
Validation loss: 2.4847943517078352

Epoch: 6| Step: 2
Training loss: 3.0089575235316914
Validation loss: 2.4618459331887728

Epoch: 6| Step: 3
Training loss: 1.9580070819044773
Validation loss: 2.4751456136534697

Epoch: 6| Step: 4
Training loss: 2.8078865359930822
Validation loss: 2.4487201905282516

Epoch: 6| Step: 5
Training loss: 2.1872004712621242
Validation loss: 2.452069031938921

Epoch: 6| Step: 6
Training loss: 2.006589524485611
Validation loss: 2.463355767717953

Epoch: 6| Step: 7
Training loss: 2.132004693167497
Validation loss: 2.456869327306563

Epoch: 6| Step: 8
Training loss: 2.215674296746685
Validation loss: 2.432312134072551

Epoch: 6| Step: 9
Training loss: 2.9067687525306303
Validation loss: 2.4654712745688294

Epoch: 6| Step: 10
Training loss: 2.3927476223443667
Validation loss: 2.40542237147103

Epoch: 6| Step: 11
Training loss: 2.313830740255121
Validation loss: 2.3924356148497115

Epoch: 6| Step: 12
Training loss: 2.419564209154045
Validation loss: 2.450782145670006

Epoch: 6| Step: 13
Training loss: 2.045333981091539
Validation loss: 2.442316780917016

Epoch: 172| Step: 0
Training loss: 2.5500406822998487
Validation loss: 2.428083702073322

Epoch: 6| Step: 1
Training loss: 2.5983414054714227
Validation loss: 2.431143505474974

Epoch: 6| Step: 2
Training loss: 2.000955591794699
Validation loss: 2.4771048007504275

Epoch: 6| Step: 3
Training loss: 1.6082531620790932
Validation loss: 2.4714145925099467

Epoch: 6| Step: 4
Training loss: 2.384036890858163
Validation loss: 2.4328074631117316

Epoch: 6| Step: 5
Training loss: 1.9923343978278205
Validation loss: 2.4903203534302234

Epoch: 6| Step: 6
Training loss: 2.3111627165930098
Validation loss: 2.4057922535173595

Epoch: 6| Step: 7
Training loss: 2.3829747879545127
Validation loss: 2.443797457591688

Epoch: 6| Step: 8
Training loss: 2.228544938799864
Validation loss: 2.4933593095661544

Epoch: 6| Step: 9
Training loss: 1.9550810517585486
Validation loss: 2.4170929918495134

Epoch: 6| Step: 10
Training loss: 3.011533184742073
Validation loss: 2.4464829750846415

Epoch: 6| Step: 11
Training loss: 1.7895452522723252
Validation loss: 2.4784569231484435

Epoch: 6| Step: 12
Training loss: 2.2642214933161195
Validation loss: 2.4335781074457974

Epoch: 6| Step: 13
Training loss: 2.533120206183155
Validation loss: 2.42937166374145

Epoch: 173| Step: 0
Training loss: 2.2798212881486997
Validation loss: 2.4489396990499905

Epoch: 6| Step: 1
Training loss: 2.555737854034749
Validation loss: 2.4564576623534284

Epoch: 6| Step: 2
Training loss: 2.3113953297437737
Validation loss: 2.4750260573691714

Epoch: 6| Step: 3
Training loss: 2.2596219214112274
Validation loss: 2.4762592828138925

Epoch: 6| Step: 4
Training loss: 2.777732253231418
Validation loss: 2.4660041412250746

Epoch: 6| Step: 5
Training loss: 1.7276092394283857
Validation loss: 2.4656430298308627

Epoch: 6| Step: 6
Training loss: 1.3960399000373656
Validation loss: 2.4659889033436437

Epoch: 6| Step: 7
Training loss: 2.2391525090740965
Validation loss: 2.456173060414332

Epoch: 6| Step: 8
Training loss: 2.3585878789726946
Validation loss: 2.410599945520178

Epoch: 6| Step: 9
Training loss: 1.8268616052084956
Validation loss: 2.439639551045257

Epoch: 6| Step: 10
Training loss: 2.820963691918605
Validation loss: 2.437152451779189

Epoch: 6| Step: 11
Training loss: 2.371622896932117
Validation loss: 2.452313936683038

Epoch: 6| Step: 12
Training loss: 2.0655400384232667
Validation loss: 2.4714080636274507

Epoch: 6| Step: 13
Training loss: 2.390060258369076
Validation loss: 2.4419845406757488

Epoch: 174| Step: 0
Training loss: 2.315998009254246
Validation loss: 2.4537993936404248

Epoch: 6| Step: 1
Training loss: 2.1394438443375257
Validation loss: 2.458316916245304

Epoch: 6| Step: 2
Training loss: 2.0309610014514075
Validation loss: 2.4345290418344026

Epoch: 6| Step: 3
Training loss: 2.5924274795674433
Validation loss: 2.4083050072547643

Epoch: 6| Step: 4
Training loss: 2.3230736740719213
Validation loss: 2.438405439595203

Epoch: 6| Step: 5
Training loss: 2.3252578592359336
Validation loss: 2.4310971297078545

Epoch: 6| Step: 6
Training loss: 2.178648013749849
Validation loss: 2.435842071673912

Epoch: 6| Step: 7
Training loss: 1.7368056988969218
Validation loss: 2.474968963740024

Epoch: 6| Step: 8
Training loss: 2.360630939002491
Validation loss: 2.4635474810184466

Epoch: 6| Step: 9
Training loss: 2.8572670092175305
Validation loss: 2.4743867115751828

Epoch: 6| Step: 10
Training loss: 2.1017762256273396
Validation loss: 2.457454241259835

Epoch: 6| Step: 11
Training loss: 2.4523898438456944
Validation loss: 2.438529473201754

Epoch: 6| Step: 12
Training loss: 2.293889187531798
Validation loss: 2.4406589004397254

Epoch: 6| Step: 13
Training loss: 1.5929088242630716
Validation loss: 2.4528672988436364

Epoch: 175| Step: 0
Training loss: 2.500224198778769
Validation loss: 2.47449832500068

Epoch: 6| Step: 1
Training loss: 2.4062721944999153
Validation loss: 2.460107077585778

Epoch: 6| Step: 2
Training loss: 2.457611258113923
Validation loss: 2.4517565922869737

Epoch: 6| Step: 3
Training loss: 1.4486872682986367
Validation loss: 2.4562740509384544

Epoch: 6| Step: 4
Training loss: 1.8916619979980038
Validation loss: 2.4311219345288846

Epoch: 6| Step: 5
Training loss: 1.8025860461941106
Validation loss: 2.44014253878477

Epoch: 6| Step: 6
Training loss: 1.5078303676989422
Validation loss: 2.4168697147408174

Epoch: 6| Step: 7
Training loss: 2.1422352546917183
Validation loss: 2.4634015023645746

Epoch: 6| Step: 8
Training loss: 2.315929447397365
Validation loss: 2.4619363164516046

Epoch: 6| Step: 9
Training loss: 2.6503759621289777
Validation loss: 2.4733120123347767

Epoch: 6| Step: 10
Training loss: 2.968502636692906
Validation loss: 2.4460353837110285

Epoch: 6| Step: 11
Training loss: 2.435690868682227
Validation loss: 2.4334261696008284

Epoch: 6| Step: 12
Training loss: 2.2360752279220746
Validation loss: 2.4294551857927367

Epoch: 6| Step: 13
Training loss: 2.4249291635765893
Validation loss: 2.4077184112287684

Epoch: 176| Step: 0
Training loss: 1.758830746204926
Validation loss: 2.4547728232033066

Epoch: 6| Step: 1
Training loss: 2.487303057978216
Validation loss: 2.4780286291767615

Epoch: 6| Step: 2
Training loss: 2.16688700313671
Validation loss: 2.4256977980244283

Epoch: 6| Step: 3
Training loss: 2.48831718095501
Validation loss: 2.4696878573174614

Epoch: 6| Step: 4
Training loss: 2.2965128087559252
Validation loss: 2.4770228388103006

Epoch: 6| Step: 5
Training loss: 1.4604198334242824
Validation loss: 2.48011757998142

Epoch: 6| Step: 6
Training loss: 2.318101028149762
Validation loss: 2.481485314737735

Epoch: 6| Step: 7
Training loss: 2.7628871491090905
Validation loss: 2.415737576756

Epoch: 6| Step: 8
Training loss: 2.736419959368584
Validation loss: 2.440659120496157

Epoch: 6| Step: 9
Training loss: 2.1642756718605356
Validation loss: 2.444992776828141

Epoch: 6| Step: 10
Training loss: 2.4444200148469526
Validation loss: 2.475212730603504

Epoch: 6| Step: 11
Training loss: 1.8381167200778188
Validation loss: 2.435893111523815

Epoch: 6| Step: 12
Training loss: 2.1454854763502214
Validation loss: 2.5116569036688725

Epoch: 6| Step: 13
Training loss: 2.194864573547949
Validation loss: 2.450471595594768

Epoch: 177| Step: 0
Training loss: 2.3257564298607925
Validation loss: 2.4839252506744183

Epoch: 6| Step: 1
Training loss: 2.287584263651432
Validation loss: 2.4474109791483336

Epoch: 6| Step: 2
Training loss: 2.710509868390644
Validation loss: 2.4904222712606527

Epoch: 6| Step: 3
Training loss: 2.7488276843880652
Validation loss: 2.4543474447495734

Epoch: 6| Step: 4
Training loss: 2.083674085088907
Validation loss: 2.485244766410947

Epoch: 6| Step: 5
Training loss: 2.103142920498502
Validation loss: 2.4846711041951237

Epoch: 6| Step: 6
Training loss: 2.4301611141278054
Validation loss: 2.468604380917237

Epoch: 6| Step: 7
Training loss: 2.0660958588805833
Validation loss: 2.4905691128974796

Epoch: 6| Step: 8
Training loss: 2.09760851246309
Validation loss: 2.4447799658918163

Epoch: 6| Step: 9
Training loss: 2.712930611740719
Validation loss: 2.4596134580596773

Epoch: 6| Step: 10
Training loss: 1.653065192541491
Validation loss: 2.5034276219969445

Epoch: 6| Step: 11
Training loss: 1.9966827538828797
Validation loss: 2.4522769920891365

Epoch: 6| Step: 12
Training loss: 2.360999451284575
Validation loss: 2.445553042252644

Epoch: 6| Step: 13
Training loss: 1.84422780973993
Validation loss: 2.4261913502787062

Epoch: 178| Step: 0
Training loss: 3.0803388196190924
Validation loss: 2.4072655073245173

Epoch: 6| Step: 1
Training loss: 2.2942610418231277
Validation loss: 2.455633565053382

Epoch: 6| Step: 2
Training loss: 2.2450531514424137
Validation loss: 2.4590370842223264

Epoch: 6| Step: 3
Training loss: 2.0798435992347675
Validation loss: 2.4532855292057145

Epoch: 6| Step: 4
Training loss: 2.196134908718606
Validation loss: 2.4223597861386876

Epoch: 6| Step: 5
Training loss: 1.5469793419374105
Validation loss: 2.419073225383979

Epoch: 6| Step: 6
Training loss: 2.0306393218892977
Validation loss: 2.463978947617516

Epoch: 6| Step: 7
Training loss: 2.033555116700477
Validation loss: 2.442076558686192

Epoch: 6| Step: 8
Training loss: 2.6746787368518543
Validation loss: 2.421580017946339

Epoch: 6| Step: 9
Training loss: 2.0874243305676847
Validation loss: 2.4589030257654345

Epoch: 6| Step: 10
Training loss: 2.471948796652448
Validation loss: 2.5035912939864335

Epoch: 6| Step: 11
Training loss: 2.149195312017216
Validation loss: 2.4546575295388195

Epoch: 6| Step: 12
Training loss: 2.197213541049368
Validation loss: 2.4550950820231128

Epoch: 6| Step: 13
Training loss: 1.6941188002524783
Validation loss: 2.4214991663938945

Epoch: 179| Step: 0
Training loss: 2.4304204001011898
Validation loss: 2.46077015182926

Epoch: 6| Step: 1
Training loss: 2.578638384017298
Validation loss: 2.454676196002189

Epoch: 6| Step: 2
Training loss: 2.4258018898201033
Validation loss: 2.412214622810308

Epoch: 6| Step: 3
Training loss: 1.82519524718683
Validation loss: 2.4546768309915645

Epoch: 6| Step: 4
Training loss: 2.0773991055553593
Validation loss: 2.4255248788621184

Epoch: 6| Step: 5
Training loss: 1.860434927286521
Validation loss: 2.3915759854660013

Epoch: 6| Step: 6
Training loss: 1.9981560551410946
Validation loss: 2.4858208755367404

Epoch: 6| Step: 7
Training loss: 2.7934947125501077
Validation loss: 2.471619250850543

Epoch: 6| Step: 8
Training loss: 2.725776449753046
Validation loss: 2.4815663131618724

Epoch: 6| Step: 9
Training loss: 1.965586103045376
Validation loss: 2.4716996131813014

Epoch: 6| Step: 10
Training loss: 2.0797484517211506
Validation loss: 2.467241128573762

Epoch: 6| Step: 11
Training loss: 1.7790170694511163
Validation loss: 2.487805430924611

Epoch: 6| Step: 12
Training loss: 2.274170223283159
Validation loss: 2.4433104553123024

Epoch: 6| Step: 13
Training loss: 1.9951319458238717
Validation loss: 2.46017529673315

Epoch: 180| Step: 0
Training loss: 2.0387348481813334
Validation loss: 2.470122761891746

Epoch: 6| Step: 1
Training loss: 1.9393643669109843
Validation loss: 2.4639278423892312

Epoch: 6| Step: 2
Training loss: 2.2876470049539774
Validation loss: 2.4635604149708303

Epoch: 6| Step: 3
Training loss: 2.471579945698402
Validation loss: 2.4797098652719223

Epoch: 6| Step: 4
Training loss: 2.0164880605164925
Validation loss: 2.442828282095062

Epoch: 6| Step: 5
Training loss: 2.058014819048289
Validation loss: 2.4487546374507136

Epoch: 6| Step: 6
Training loss: 1.942198992547108
Validation loss: 2.465027436270935

Epoch: 6| Step: 7
Training loss: 2.3408447569906397
Validation loss: 2.437254335630555

Epoch: 6| Step: 8
Training loss: 2.7145005263030995
Validation loss: 2.452187544977789

Epoch: 6| Step: 9
Training loss: 2.3637027080934976
Validation loss: 2.4633744619328133

Epoch: 6| Step: 10
Training loss: 2.5856251138968807
Validation loss: 2.4212259386790826

Epoch: 6| Step: 11
Training loss: 2.0164333171720106
Validation loss: 2.4417631438568397

Epoch: 6| Step: 12
Training loss: 2.1311751008506645
Validation loss: 2.4269519277236586

Epoch: 6| Step: 13
Training loss: 3.002660048869933
Validation loss: 2.425298207981404

Epoch: 181| Step: 0
Training loss: 2.0269780940945585
Validation loss: 2.4578319773176616

Epoch: 6| Step: 1
Training loss: 2.807069324943337
Validation loss: 2.5180470892764486

Epoch: 6| Step: 2
Training loss: 2.1180442962625157
Validation loss: 2.458329192572253

Epoch: 6| Step: 3
Training loss: 2.5632980778637946
Validation loss: 2.4684968452258564

Epoch: 6| Step: 4
Training loss: 1.6231231120689438
Validation loss: 2.4990724504141295

Epoch: 6| Step: 5
Training loss: 1.984232259107047
Validation loss: 2.4509106464041435

Epoch: 6| Step: 6
Training loss: 2.0316145349729555
Validation loss: 2.38580849060723

Epoch: 6| Step: 7
Training loss: 2.5164537663964035
Validation loss: 2.4210020791171947

Epoch: 6| Step: 8
Training loss: 2.2624154343792133
Validation loss: 2.4887873408163825

Epoch: 6| Step: 9
Training loss: 2.1986096150059877
Validation loss: 2.459165269320295

Epoch: 6| Step: 10
Training loss: 2.2970680622783597
Validation loss: 2.431873397732798

Epoch: 6| Step: 11
Training loss: 2.0574774420835378
Validation loss: 2.4726767038310884

Epoch: 6| Step: 12
Training loss: 2.521256109257693
Validation loss: 2.462612328456336

Epoch: 6| Step: 13
Training loss: 2.4100339787410725
Validation loss: 2.4690899680406737

Epoch: 182| Step: 0
Training loss: 2.164039694325061
Validation loss: 2.4873879566003847

Epoch: 6| Step: 1
Training loss: 2.3779475342631105
Validation loss: 2.4355069140152517

Epoch: 6| Step: 2
Training loss: 2.002635173450085
Validation loss: 2.459343836189596

Epoch: 6| Step: 3
Training loss: 2.5222261432536937
Validation loss: 2.4588757179587906

Epoch: 6| Step: 4
Training loss: 2.0100325248705797
Validation loss: 2.4603674610429467

Epoch: 6| Step: 5
Training loss: 2.3195033862251027
Validation loss: 2.474794629922455

Epoch: 6| Step: 6
Training loss: 1.6979041615905213
Validation loss: 2.466008608352136

Epoch: 6| Step: 7
Training loss: 2.042062708012315
Validation loss: 2.4199490100590944

Epoch: 6| Step: 8
Training loss: 1.9056851535109711
Validation loss: 2.45575123743091

Epoch: 6| Step: 9
Training loss: 3.0230176372915816
Validation loss: 2.4475862212380357

Epoch: 6| Step: 10
Training loss: 1.8719209184571006
Validation loss: 2.441261671416317

Epoch: 6| Step: 11
Training loss: 2.4158543723344827
Validation loss: 2.466530258983594

Epoch: 6| Step: 12
Training loss: 2.384724434661678
Validation loss: 2.447434981236243

Epoch: 6| Step: 13
Training loss: 2.2873430792344163
Validation loss: 2.461985500188734

Epoch: 183| Step: 0
Training loss: 1.9558836718879178
Validation loss: 2.453074616530782

Epoch: 6| Step: 1
Training loss: 2.2205285479285166
Validation loss: 2.4401376061610573

Epoch: 6| Step: 2
Training loss: 1.9684088880727808
Validation loss: 2.458081095001192

Epoch: 6| Step: 3
Training loss: 2.427501615136785
Validation loss: 2.44509916958385

Epoch: 6| Step: 4
Training loss: 2.62282981173264
Validation loss: 2.4710802830505996

Epoch: 6| Step: 5
Training loss: 2.1778637766347178
Validation loss: 2.4528719884754566

Epoch: 6| Step: 6
Training loss: 2.0987517552598494
Validation loss: 2.4400166880986562

Epoch: 6| Step: 7
Training loss: 1.709024274087816
Validation loss: 2.4899247310800092

Epoch: 6| Step: 8
Training loss: 2.3746241221885387
Validation loss: 2.4686038294747537

Epoch: 6| Step: 9
Training loss: 2.0264330749830486
Validation loss: 2.4598249075163827

Epoch: 6| Step: 10
Training loss: 2.099062201593766
Validation loss: 2.449612412967622

Epoch: 6| Step: 11
Training loss: 2.506716384682089
Validation loss: 2.4727028722125626

Epoch: 6| Step: 12
Training loss: 2.5029272108478775
Validation loss: 2.427916047569346

Epoch: 6| Step: 13
Training loss: 2.7451429823861444
Validation loss: 2.4507655604913183

Epoch: 184| Step: 0
Training loss: 1.974410864929031
Validation loss: 2.450277895608515

Epoch: 6| Step: 1
Training loss: 2.315585989887333
Validation loss: 2.436451902462892

Epoch: 6| Step: 2
Training loss: 1.894599708814668
Validation loss: 2.4313314564937487

Epoch: 6| Step: 3
Training loss: 2.470134105671188
Validation loss: 2.4444870493722513

Epoch: 6| Step: 4
Training loss: 1.8238271419533119
Validation loss: 2.4567316996526927

Epoch: 6| Step: 5
Training loss: 2.9031013742395095
Validation loss: 2.4456047201424966

Epoch: 6| Step: 6
Training loss: 2.413101548221966
Validation loss: 2.436128952765433

Epoch: 6| Step: 7
Training loss: 2.4754553404901554
Validation loss: 2.433837577126884

Epoch: 6| Step: 8
Training loss: 2.0629692699752713
Validation loss: 2.463549188691165

Epoch: 6| Step: 9
Training loss: 2.0750988029029083
Validation loss: 2.448439249894991

Epoch: 6| Step: 10
Training loss: 2.0850735707647607
Validation loss: 2.4732198763114224

Epoch: 6| Step: 11
Training loss: 1.8123207003600024
Validation loss: 2.4451074179719368

Epoch: 6| Step: 12
Training loss: 1.981762645836525
Validation loss: 2.4865918501775797

Epoch: 6| Step: 13
Training loss: 2.875109628992109
Validation loss: 2.471276525895688

Epoch: 185| Step: 0
Training loss: 2.22425010131136
Validation loss: 2.441116691498078

Epoch: 6| Step: 1
Training loss: 2.125366403742821
Validation loss: 2.484072774112403

Epoch: 6| Step: 2
Training loss: 2.4843141560331494
Validation loss: 2.4667735248202596

Epoch: 6| Step: 3
Training loss: 2.0827101983532676
Validation loss: 2.451523005292374

Epoch: 6| Step: 4
Training loss: 1.9766346311412373
Validation loss: 2.4712291765321983

Epoch: 6| Step: 5
Training loss: 2.64076674944293
Validation loss: 2.4272782995051867

Epoch: 6| Step: 6
Training loss: 2.4665852000555955
Validation loss: 2.413827213160715

Epoch: 6| Step: 7
Training loss: 2.2844095167482474
Validation loss: 2.461648224113575

Epoch: 6| Step: 8
Training loss: 2.389897254427217
Validation loss: 2.457906360230553

Epoch: 6| Step: 9
Training loss: 2.250525413201888
Validation loss: 2.4361990892928755

Epoch: 6| Step: 10
Training loss: 1.9299428670461352
Validation loss: 2.4475116807530535

Epoch: 6| Step: 11
Training loss: 1.6866146166815517
Validation loss: 2.443324943297187

Epoch: 6| Step: 12
Training loss: 2.0291622289756592
Validation loss: 2.447954947740223

Epoch: 6| Step: 13
Training loss: 1.9180443276860808
Validation loss: 2.39592728040492

Epoch: 186| Step: 0
Training loss: 2.527517321609321
Validation loss: 2.4374745538275735

Epoch: 6| Step: 1
Training loss: 2.3728076453167426
Validation loss: 2.423029517172892

Epoch: 6| Step: 2
Training loss: 2.139950165569424
Validation loss: 2.4413930836968567

Epoch: 6| Step: 3
Training loss: 1.6187824732052916
Validation loss: 2.430173454623189

Epoch: 6| Step: 4
Training loss: 2.398226849876387
Validation loss: 2.47722799522693

Epoch: 6| Step: 5
Training loss: 2.55738813810061
Validation loss: 2.5065367159391307

Epoch: 6| Step: 6
Training loss: 2.507106598470386
Validation loss: 2.4370856283903795

Epoch: 6| Step: 7
Training loss: 1.715025872571988
Validation loss: 2.4550232527365776

Epoch: 6| Step: 8
Training loss: 2.2709778789281083
Validation loss: 2.4271233277342095

Epoch: 6| Step: 9
Training loss: 2.0517870952217856
Validation loss: 2.4789741584763156

Epoch: 6| Step: 10
Training loss: 2.017671595842756
Validation loss: 2.4376796406950887

Epoch: 6| Step: 11
Training loss: 2.0542395505942306
Validation loss: 2.448184749888404

Epoch: 6| Step: 12
Training loss: 2.1321219978854837
Validation loss: 2.415937687343303

Epoch: 6| Step: 13
Training loss: 2.8130959621135085
Validation loss: 2.416216844131415

Epoch: 187| Step: 0
Training loss: 1.9412325929154814
Validation loss: 2.4371584791586685

Epoch: 6| Step: 1
Training loss: 2.4188867653517288
Validation loss: 2.4678258997875098

Epoch: 6| Step: 2
Training loss: 2.736120832870261
Validation loss: 2.4368877004694802

Epoch: 6| Step: 3
Training loss: 1.7449905358087923
Validation loss: 2.4045279266653306

Epoch: 6| Step: 4
Training loss: 1.9620693633313369
Validation loss: 2.4204546460044027

Epoch: 6| Step: 5
Training loss: 2.671079818452719
Validation loss: 2.487958228278645

Epoch: 6| Step: 6
Training loss: 1.8349474246109685
Validation loss: 2.4479965654231517

Epoch: 6| Step: 7
Training loss: 2.74995855820381
Validation loss: 2.4028129124183315

Epoch: 6| Step: 8
Training loss: 2.4261574568632525
Validation loss: 2.4660905532799613

Epoch: 6| Step: 9
Training loss: 1.6258931273168906
Validation loss: 2.416237960345841

Epoch: 6| Step: 10
Training loss: 1.870163847737094
Validation loss: 2.432289718167253

Epoch: 6| Step: 11
Training loss: 1.7306399981839693
Validation loss: 2.4775566594446783

Epoch: 6| Step: 12
Training loss: 2.413507391552209
Validation loss: 2.4477778143809026

Epoch: 6| Step: 13
Training loss: 2.6379122371231687
Validation loss: 2.4752989211329095

Epoch: 188| Step: 0
Training loss: 2.1378062826310726
Validation loss: 2.437725944343707

Epoch: 6| Step: 1
Training loss: 2.675948490012001
Validation loss: 2.457079658622897

Epoch: 6| Step: 2
Training loss: 2.290330763338161
Validation loss: 2.47157111974189

Epoch: 6| Step: 3
Training loss: 2.622022029496099
Validation loss: 2.4721324258040016

Epoch: 6| Step: 4
Training loss: 2.263717374434883
Validation loss: 2.4074414641770154

Epoch: 6| Step: 5
Training loss: 2.4538496368591374
Validation loss: 2.422556265479785

Epoch: 6| Step: 6
Training loss: 1.916663197500434
Validation loss: 2.467575680770806

Epoch: 6| Step: 7
Training loss: 2.007717145147247
Validation loss: 2.471432726821081

Epoch: 6| Step: 8
Training loss: 1.797957318296894
Validation loss: 2.4390613045476375

Epoch: 6| Step: 9
Training loss: 2.2164413906534737
Validation loss: 2.4811574354362125

Epoch: 6| Step: 10
Training loss: 2.076589949564919
Validation loss: 2.450540979531912

Epoch: 6| Step: 11
Training loss: 2.178858773804044
Validation loss: 2.478664130794398

Epoch: 6| Step: 12
Training loss: 2.110755299258919
Validation loss: 2.490684420932536

Epoch: 6| Step: 13
Training loss: 1.5606906332896775
Validation loss: 2.4642718546640743

Epoch: 189| Step: 0
Training loss: 2.3108062727515666
Validation loss: 2.4819986250701214

Epoch: 6| Step: 1
Training loss: 2.250287779312166
Validation loss: 2.4568194515815795

Epoch: 6| Step: 2
Training loss: 2.021379521548464
Validation loss: 2.48065125447456

Epoch: 6| Step: 3
Training loss: 2.9184810081544983
Validation loss: 2.4459751414299906

Epoch: 6| Step: 4
Training loss: 1.8805446658561853
Validation loss: 2.4505756310105515

Epoch: 6| Step: 5
Training loss: 1.6332866947496063
Validation loss: 2.465249124148916

Epoch: 6| Step: 6
Training loss: 2.0968104527369733
Validation loss: 2.488136302092495

Epoch: 6| Step: 7
Training loss: 1.799656713387656
Validation loss: 2.47320728414927

Epoch: 6| Step: 8
Training loss: 2.6027239248955376
Validation loss: 2.48431863460938

Epoch: 6| Step: 9
Training loss: 2.196428442942829
Validation loss: 2.4828797603870596

Epoch: 6| Step: 10
Training loss: 2.134146360603359
Validation loss: 2.4867371535720326

Epoch: 6| Step: 11
Training loss: 2.3528238253220173
Validation loss: 2.4422954724068613

Epoch: 6| Step: 12
Training loss: 2.1896459680001796
Validation loss: 2.471662944347829

Epoch: 6| Step: 13
Training loss: 1.5953471838518178
Validation loss: 2.3931672869574374

Epoch: 190| Step: 0
Training loss: 2.22177755622348
Validation loss: 2.466963595594696

Epoch: 6| Step: 1
Training loss: 2.304439208023627
Validation loss: 2.4365799500306085

Epoch: 6| Step: 2
Training loss: 2.1879598951552146
Validation loss: 2.434105538107338

Epoch: 6| Step: 3
Training loss: 2.240742181030782
Validation loss: 2.4577363653603737

Epoch: 6| Step: 4
Training loss: 1.8545851360247434
Validation loss: 2.436730203583638

Epoch: 6| Step: 5
Training loss: 1.4597827611279286
Validation loss: 2.467614911269131

Epoch: 6| Step: 6
Training loss: 2.3396898833617192
Validation loss: 2.407519264250177

Epoch: 6| Step: 7
Training loss: 2.1257765977746206
Validation loss: 2.4382353815286777

Epoch: 6| Step: 8
Training loss: 2.416651846303111
Validation loss: 2.487236827991085

Epoch: 6| Step: 9
Training loss: 2.52804494384458
Validation loss: 2.434160787649281

Epoch: 6| Step: 10
Training loss: 1.9871158444520693
Validation loss: 2.436495954624185

Epoch: 6| Step: 11
Training loss: 2.1565248618263815
Validation loss: 2.438278099291673

Epoch: 6| Step: 12
Training loss: 1.8931297545500854
Validation loss: 2.3982223933222704

Epoch: 6| Step: 13
Training loss: 3.0409892821595053
Validation loss: 2.4124993669161676

Epoch: 191| Step: 0
Training loss: 2.067136235369157
Validation loss: 2.450840324710741

Epoch: 6| Step: 1
Training loss: 1.5188765108140092
Validation loss: 2.4479401520331416

Epoch: 6| Step: 2
Training loss: 2.2855345323249234
Validation loss: 2.459569455135363

Epoch: 6| Step: 3
Training loss: 2.0333421936259017
Validation loss: 2.4503779656982347

Epoch: 6| Step: 4
Training loss: 2.680789643005655
Validation loss: 2.387811106980523

Epoch: 6| Step: 5
Training loss: 2.143599399804175
Validation loss: 2.4540439878056324

Epoch: 6| Step: 6
Training loss: 1.8924825071385574
Validation loss: 2.4615430798772704

Epoch: 6| Step: 7
Training loss: 2.3079179268364243
Validation loss: 2.428355154202844

Epoch: 6| Step: 8
Training loss: 2.601268304909822
Validation loss: 2.4538751378426458

Epoch: 6| Step: 9
Training loss: 1.8100633356172713
Validation loss: 2.445818727606237

Epoch: 6| Step: 10
Training loss: 2.191687472381274
Validation loss: 2.409610078711407

Epoch: 6| Step: 11
Training loss: 2.954717943184983
Validation loss: 2.4312844215970206

Epoch: 6| Step: 12
Training loss: 1.5824557264742736
Validation loss: 2.4358536950792042

Epoch: 6| Step: 13
Training loss: 2.489117971258355
Validation loss: 2.471621427997902

Epoch: 192| Step: 0
Training loss: 2.0029562321117074
Validation loss: 2.441495324525935

Epoch: 6| Step: 1
Training loss: 2.1736489056709485
Validation loss: 2.485610715477203

Epoch: 6| Step: 2
Training loss: 2.071321522243889
Validation loss: 2.4204147567771006

Epoch: 6| Step: 3
Training loss: 2.3850941224789213
Validation loss: 2.4021122022241124

Epoch: 6| Step: 4
Training loss: 2.3682766162041493
Validation loss: 2.4350013705212663

Epoch: 6| Step: 5
Training loss: 1.9230138614291836
Validation loss: 2.44299217432818

Epoch: 6| Step: 6
Training loss: 1.3502847883280582
Validation loss: 2.4496958958448953

Epoch: 6| Step: 7
Training loss: 1.9477323013067558
Validation loss: 2.4180263344314996

Epoch: 6| Step: 8
Training loss: 2.2825915428765016
Validation loss: 2.458118523886209

Epoch: 6| Step: 9
Training loss: 2.3717206098042953
Validation loss: 2.427524111690208

Epoch: 6| Step: 10
Training loss: 2.6913621342424876
Validation loss: 2.4491665203229247

Epoch: 6| Step: 11
Training loss: 1.8392879999281482
Validation loss: 2.3902645891671708

Epoch: 6| Step: 12
Training loss: 2.567933439610255
Validation loss: 2.4326811876429675

Epoch: 6| Step: 13
Training loss: 2.285054626813541
Validation loss: 2.439063338380306

Epoch: 193| Step: 0
Training loss: 2.284698805709956
Validation loss: 2.460439254135946

Epoch: 6| Step: 1
Training loss: 2.0424365194627607
Validation loss: 2.441870021684968

Epoch: 6| Step: 2
Training loss: 2.4067374392148304
Validation loss: 2.444358743737351

Epoch: 6| Step: 3
Training loss: 2.564950283230522
Validation loss: 2.465776737445012

Epoch: 6| Step: 4
Training loss: 1.6986602917830549
Validation loss: 2.4471947140573276

Epoch: 6| Step: 5
Training loss: 2.4006065476395384
Validation loss: 2.4355108749860914

Epoch: 6| Step: 6
Training loss: 1.9137921823627948
Validation loss: 2.4699382121432976

Epoch: 6| Step: 7
Training loss: 2.1003809447133723
Validation loss: 2.446916450649473

Epoch: 6| Step: 8
Training loss: 2.0209738561269015
Validation loss: 2.4421394931748006

Epoch: 6| Step: 9
Training loss: 1.5738459067477495
Validation loss: 2.4158469313744537

Epoch: 6| Step: 10
Training loss: 2.084554034869807
Validation loss: 2.4301199758774157

Epoch: 6| Step: 11
Training loss: 2.326977952866645
Validation loss: 2.4755236472268454

Epoch: 6| Step: 12
Training loss: 2.2867735788062444
Validation loss: 2.4380899908502536

Epoch: 6| Step: 13
Training loss: 3.1184948161273076
Validation loss: 2.4579808243313996

Epoch: 194| Step: 0
Training loss: 2.051047578502509
Validation loss: 2.445944654987748

Epoch: 6| Step: 1
Training loss: 2.366458390254343
Validation loss: 2.437305234937611

Epoch: 6| Step: 2
Training loss: 2.541519431763938
Validation loss: 2.4311337692577037

Epoch: 6| Step: 3
Training loss: 2.225523160657522
Validation loss: 2.45076338050742

Epoch: 6| Step: 4
Training loss: 2.578234213625449
Validation loss: 2.4481672470734805

Epoch: 6| Step: 5
Training loss: 2.039173108605032
Validation loss: 2.4394811105176677

Epoch: 6| Step: 6
Training loss: 2.908614970418494
Validation loss: 2.454269652111622

Epoch: 6| Step: 7
Training loss: 2.174321614723298
Validation loss: 2.4108952810420927

Epoch: 6| Step: 8
Training loss: 1.8496884547632468
Validation loss: 2.4495576171162554

Epoch: 6| Step: 9
Training loss: 1.4159620814230274
Validation loss: 2.467590398222118

Epoch: 6| Step: 10
Training loss: 2.332642952646472
Validation loss: 2.476278473866559

Epoch: 6| Step: 11
Training loss: 1.5047244533861628
Validation loss: 2.4589804080530824

Epoch: 6| Step: 12
Training loss: 2.0846254029630145
Validation loss: 2.4173118068240056

Epoch: 6| Step: 13
Training loss: 1.7482233565766077
Validation loss: 2.49798691002427

Epoch: 195| Step: 0
Training loss: 1.8354220052144252
Validation loss: 2.481797888530992

Epoch: 6| Step: 1
Training loss: 2.6953841490137163
Validation loss: 2.4723975817349806

Epoch: 6| Step: 2
Training loss: 2.67119861987142
Validation loss: 2.4478208416205227

Epoch: 6| Step: 3
Training loss: 1.9439569982474294
Validation loss: 2.4685216704378976

Epoch: 6| Step: 4
Training loss: 2.445532060705098
Validation loss: 2.446233394157159

Epoch: 6| Step: 5
Training loss: 2.5334886612037075
Validation loss: 2.431566041673291

Epoch: 6| Step: 6
Training loss: 1.7707902416895307
Validation loss: 2.472940102289656

Epoch: 6| Step: 7
Training loss: 2.4147768414304234
Validation loss: 2.425538325248938

Epoch: 6| Step: 8
Training loss: 1.948585545009688
Validation loss: 2.432881703848242

Epoch: 6| Step: 9
Training loss: 2.028870347755245
Validation loss: 2.3834486552109473

Epoch: 6| Step: 10
Training loss: 1.581321123657136
Validation loss: 2.4108539086843526

Epoch: 6| Step: 11
Training loss: 2.3020608708132997
Validation loss: 2.4251817815890293

Epoch: 6| Step: 12
Training loss: 1.8937174199389413
Validation loss: 2.4349680503535938

Epoch: 6| Step: 13
Training loss: 2.090978923769835
Validation loss: 2.4365176842191865

Epoch: 196| Step: 0
Training loss: 1.7263855994552872
Validation loss: 2.423662851712188

Epoch: 6| Step: 1
Training loss: 2.6584042060357294
Validation loss: 2.4510058803198205

Epoch: 6| Step: 2
Training loss: 2.425851817801564
Validation loss: 2.4707990714713923

Epoch: 6| Step: 3
Training loss: 2.568033616906573
Validation loss: 2.462278832822285

Epoch: 6| Step: 4
Training loss: 1.8156289683313387
Validation loss: 2.453902208775761

Epoch: 6| Step: 5
Training loss: 2.256897315160887
Validation loss: 2.4423330608083997

Epoch: 6| Step: 6
Training loss: 2.5643043678294393
Validation loss: 2.4263401667358977

Epoch: 6| Step: 7
Training loss: 1.9324372503202196
Validation loss: 2.4193283087120094

Epoch: 6| Step: 8
Training loss: 1.6879466843162547
Validation loss: 2.4235398412453155

Epoch: 6| Step: 9
Training loss: 1.7290256243561504
Validation loss: 2.4594121922118677

Epoch: 6| Step: 10
Training loss: 1.6308371536659765
Validation loss: 2.471341961610807

Epoch: 6| Step: 11
Training loss: 2.4459391513096107
Validation loss: 2.429789174596975

Epoch: 6| Step: 12
Training loss: 2.0592825097484937
Validation loss: 2.4363033090598134

Epoch: 6| Step: 13
Training loss: 2.9196511031434755
Validation loss: 2.4718858489766675

Epoch: 197| Step: 0
Training loss: 2.1136819456075933
Validation loss: 2.478841254770047

Epoch: 6| Step: 1
Training loss: 2.4257702420241376
Validation loss: 2.4786711577044067

Epoch: 6| Step: 2
Training loss: 1.8892722216131292
Validation loss: 2.475599656683211

Epoch: 6| Step: 3
Training loss: 2.030607503367688
Validation loss: 2.4924436392519262

Epoch: 6| Step: 4
Training loss: 1.880366846167463
Validation loss: 2.4567991474743396

Epoch: 6| Step: 5
Training loss: 2.488224621761682
Validation loss: 2.461846063357386

Epoch: 6| Step: 6
Training loss: 2.3339106208927363
Validation loss: 2.5026499086402496

Epoch: 6| Step: 7
Training loss: 1.871123375389326
Validation loss: 2.5022294614424587

Epoch: 6| Step: 8
Training loss: 1.9867451847911377
Validation loss: 2.49885874099339

Epoch: 6| Step: 9
Training loss: 1.5233536134756938
Validation loss: 2.4270553985119014

Epoch: 6| Step: 10
Training loss: 2.3952769974219397
Validation loss: 2.4983366283044846

Epoch: 6| Step: 11
Training loss: 2.43876419540333
Validation loss: 2.491179935420976

Epoch: 6| Step: 12
Training loss: 2.4909259150088143
Validation loss: 2.4453318783599216

Epoch: 6| Step: 13
Training loss: 2.048032477031929
Validation loss: 2.4798743345388083

Epoch: 198| Step: 0
Training loss: 2.069602758281744
Validation loss: 2.4591573917767517

Epoch: 6| Step: 1
Training loss: 2.3800675387376375
Validation loss: 2.464187866852937

Epoch: 6| Step: 2
Training loss: 2.24934303441167
Validation loss: 2.474127693704743

Epoch: 6| Step: 3
Training loss: 2.1213621528213547
Validation loss: 2.4288430451969196

Epoch: 6| Step: 4
Training loss: 1.9493172721962158
Validation loss: 2.4261507110914464

Epoch: 6| Step: 5
Training loss: 2.0986566697544604
Validation loss: 2.453603173940525

Epoch: 6| Step: 6
Training loss: 1.890387780306046
Validation loss: 2.4412304655718478

Epoch: 6| Step: 7
Training loss: 2.065208967964226
Validation loss: 2.4310971228534743

Epoch: 6| Step: 8
Training loss: 2.51889413274507
Validation loss: 2.407404956556948

Epoch: 6| Step: 9
Training loss: 1.6782871530285364
Validation loss: 2.4703005953283697

Epoch: 6| Step: 10
Training loss: 2.286297270388881
Validation loss: 2.449508610849685

Epoch: 6| Step: 11
Training loss: 2.0373481179012156
Validation loss: 2.4702985005586777

Epoch: 6| Step: 12
Training loss: 2.369076620245275
Validation loss: 2.428199106694798

Epoch: 6| Step: 13
Training loss: 2.4416824062564855
Validation loss: 2.4534187734057125

Epoch: 199| Step: 0
Training loss: 2.1618648897382915
Validation loss: 2.460332708857476

Epoch: 6| Step: 1
Training loss: 2.0441993522700495
Validation loss: 2.424353357653543

Epoch: 6| Step: 2
Training loss: 2.4117996820105603
Validation loss: 2.5006288270832635

Epoch: 6| Step: 3
Training loss: 2.230421930947432
Validation loss: 2.432164776605836

Epoch: 6| Step: 4
Training loss: 2.2980557475420467
Validation loss: 2.4480564176158253

Epoch: 6| Step: 5
Training loss: 1.7496043847999345
Validation loss: 2.3998994184084013

Epoch: 6| Step: 6
Training loss: 1.783814909194416
Validation loss: 2.421582000824009

Epoch: 6| Step: 7
Training loss: 1.9853830855719556
Validation loss: 2.424807857153062

Epoch: 6| Step: 8
Training loss: 2.6569450815344835
Validation loss: 2.477309308773255

Epoch: 6| Step: 9
Training loss: 2.0476282495522127
Validation loss: 2.4130086313850123

Epoch: 6| Step: 10
Training loss: 1.6737346823392394
Validation loss: 2.4491250695903655

Epoch: 6| Step: 11
Training loss: 2.702341749020156
Validation loss: 2.459430093449556

Epoch: 6| Step: 12
Training loss: 1.54010377311336
Validation loss: 2.4615563649227234

Epoch: 6| Step: 13
Training loss: 2.953235119577984
Validation loss: 2.392905339996391

Epoch: 200| Step: 0
Training loss: 2.226689920627592
Validation loss: 2.4527261155109987

Epoch: 6| Step: 1
Training loss: 2.1881558116409505
Validation loss: 2.4621438013617154

Epoch: 6| Step: 2
Training loss: 2.5359479846373296
Validation loss: 2.4384650661924847

Epoch: 6| Step: 3
Training loss: 1.8670910926095188
Validation loss: 2.4479141985885824

Epoch: 6| Step: 4
Training loss: 1.6806938527828994
Validation loss: 2.480094352115551

Epoch: 6| Step: 5
Training loss: 1.6454333370572078
Validation loss: 2.419912313987853

Epoch: 6| Step: 6
Training loss: 2.6966773958625376
Validation loss: 2.4726203724435663

Epoch: 6| Step: 7
Training loss: 1.7481107050147895
Validation loss: 2.4733935427216185

Epoch: 6| Step: 8
Training loss: 2.558075224771707
Validation loss: 2.427401056099078

Epoch: 6| Step: 9
Training loss: 1.9740366119189718
Validation loss: 2.4412196280739313

Epoch: 6| Step: 10
Training loss: 2.213940956155455
Validation loss: 2.4522088919381377

Epoch: 6| Step: 11
Training loss: 2.3185857133683014
Validation loss: 2.4228055322123647

Epoch: 6| Step: 12
Training loss: 2.0875097628610706
Validation loss: 2.4206090862408893

Epoch: 6| Step: 13
Training loss: 1.6820999209449385
Validation loss: 2.4430456850584235

Epoch: 201| Step: 0
Training loss: 2.3274424531667233
Validation loss: 2.434882427391659

Epoch: 6| Step: 1
Training loss: 2.0793926990192637
Validation loss: 2.451166247093513

Epoch: 6| Step: 2
Training loss: 1.8318749464823085
Validation loss: 2.4479800619077756

Epoch: 6| Step: 3
Training loss: 2.027691585270804
Validation loss: 2.4962508915546158

Epoch: 6| Step: 4
Training loss: 2.3134153461851255
Validation loss: 2.4998285152728577

Epoch: 6| Step: 5
Training loss: 1.6964248313002122
Validation loss: 2.4479171356710396

Epoch: 6| Step: 6
Training loss: 2.126953573375756
Validation loss: 2.526460610093527

Epoch: 6| Step: 7
Training loss: 2.5040940141426478
Validation loss: 2.4984917367122326

Epoch: 6| Step: 8
Training loss: 1.7853959671773199
Validation loss: 2.5496257213744964

Epoch: 6| Step: 9
Training loss: 2.5364809028723214
Validation loss: 2.4781787955391423

Epoch: 6| Step: 10
Training loss: 1.6634360553592569
Validation loss: 2.498299329925896

Epoch: 6| Step: 11
Training loss: 2.6951693731812623
Validation loss: 2.482056719493948

Epoch: 6| Step: 12
Training loss: 2.515467857997136
Validation loss: 2.449611922135859

Epoch: 6| Step: 13
Training loss: 1.6600507635374775
Validation loss: 2.4538433036228406

Epoch: 202| Step: 0
Training loss: 2.28844383654563
Validation loss: 2.4203278722249535

Epoch: 6| Step: 1
Training loss: 2.206064954567465
Validation loss: 2.450251504471513

Epoch: 6| Step: 2
Training loss: 1.8315924991428252
Validation loss: 2.394704363508799

Epoch: 6| Step: 3
Training loss: 1.7221030387178649
Validation loss: 2.5071988992483702

Epoch: 6| Step: 4
Training loss: 1.9109715007211916
Validation loss: 2.3899838400574307

Epoch: 6| Step: 5
Training loss: 1.9971982882283976
Validation loss: 2.3920284545416797

Epoch: 6| Step: 6
Training loss: 1.5508987805008452
Validation loss: 2.408745882792707

Epoch: 6| Step: 7
Training loss: 2.2655315511439067
Validation loss: 2.412478650480151

Epoch: 6| Step: 8
Training loss: 2.1273511333806754
Validation loss: 2.357898642775359

Epoch: 6| Step: 9
Training loss: 2.5027732725828518
Validation loss: 2.4178969119948115

Epoch: 6| Step: 10
Training loss: 2.4393781615346
Validation loss: 2.445468667348552

Epoch: 6| Step: 11
Training loss: 1.8297789175388655
Validation loss: 2.446964889650299

Epoch: 6| Step: 12
Training loss: 2.666997193674357
Validation loss: 2.4489183110302823

Epoch: 6| Step: 13
Training loss: 2.5700193661208717
Validation loss: 2.4672898304265725

Epoch: 203| Step: 0
Training loss: 1.7390690422106418
Validation loss: 2.4391951313259086

Epoch: 6| Step: 1
Training loss: 1.8971427615374148
Validation loss: 2.421705879289907

Epoch: 6| Step: 2
Training loss: 1.6279364244199235
Validation loss: 2.4814761402112473

Epoch: 6| Step: 3
Training loss: 2.054671254837158
Validation loss: 2.457301266455552

Epoch: 6| Step: 4
Training loss: 2.23869088304125
Validation loss: 2.450780741870519

Epoch: 6| Step: 5
Training loss: 1.8761324959187802
Validation loss: 2.4903145648705194

Epoch: 6| Step: 6
Training loss: 2.5880250370459534
Validation loss: 2.470607797396098

Epoch: 6| Step: 7
Training loss: 2.3010531460734858
Validation loss: 2.512239358110943

Epoch: 6| Step: 8
Training loss: 2.540335186596448
Validation loss: 2.4725093533859215

Epoch: 6| Step: 9
Training loss: 1.977246916113173
Validation loss: 2.483345592914764

Epoch: 6| Step: 10
Training loss: 1.8927989472648292
Validation loss: 2.489497022917118

Epoch: 6| Step: 11
Training loss: 2.4805029678988255
Validation loss: 2.461922288915167

Epoch: 6| Step: 12
Training loss: 2.054863171628167
Validation loss: 2.4442790284810445

Epoch: 6| Step: 13
Training loss: 1.9962621569278243
Validation loss: 2.4596345925666716

Epoch: 204| Step: 0
Training loss: 1.9798693831546128
Validation loss: 2.419866468277339

Epoch: 6| Step: 1
Training loss: 2.377848071943847
Validation loss: 2.452124840147443

Epoch: 6| Step: 2
Training loss: 2.1947546416425956
Validation loss: 2.448597088261274

Epoch: 6| Step: 3
Training loss: 1.9031928515435912
Validation loss: 2.4359674245003773

Epoch: 6| Step: 4
Training loss: 2.0869903764708484
Validation loss: 2.4120744663897806

Epoch: 6| Step: 5
Training loss: 2.1841091578176535
Validation loss: 2.398541730586873

Epoch: 6| Step: 6
Training loss: 1.4234308805845677
Validation loss: 2.398966834080786

Epoch: 6| Step: 7
Training loss: 2.3204896390453875
Validation loss: 2.4557643465890626

Epoch: 6| Step: 8
Training loss: 1.5114385458529285
Validation loss: 2.4535653047254056

Epoch: 6| Step: 9
Training loss: 1.3205002871263531
Validation loss: 2.4620111095393433

Epoch: 6| Step: 10
Training loss: 2.5470464917819675
Validation loss: 2.4005605970088104

Epoch: 6| Step: 11
Training loss: 2.44546147584336
Validation loss: 2.4393791683351282

Epoch: 6| Step: 12
Training loss: 2.513943886433375
Validation loss: 2.423881612472476

Epoch: 6| Step: 13
Training loss: 2.6233109080686274
Validation loss: 2.434203300458931

Epoch: 205| Step: 0
Training loss: 2.422843690157505
Validation loss: 2.4338368945672175

Epoch: 6| Step: 1
Training loss: 1.9628139803522044
Validation loss: 2.4915203402846613

Epoch: 6| Step: 2
Training loss: 1.6648549087128974
Validation loss: 2.435441077589232

Epoch: 6| Step: 3
Training loss: 2.271796404333029
Validation loss: 2.485920817339567

Epoch: 6| Step: 4
Training loss: 1.9611528741870192
Validation loss: 2.448955641801863

Epoch: 6| Step: 5
Training loss: 1.5101927317215442
Validation loss: 2.4272735055034693

Epoch: 6| Step: 6
Training loss: 1.9955674166186468
Validation loss: 2.500292338434808

Epoch: 6| Step: 7
Training loss: 2.6459385608163215
Validation loss: 2.4446549967761015

Epoch: 6| Step: 8
Training loss: 2.434413324918706
Validation loss: 2.528399528669604

Epoch: 6| Step: 9
Training loss: 1.8174625729743645
Validation loss: 2.4793249744786725

Epoch: 6| Step: 10
Training loss: 1.725735496511997
Validation loss: 2.4207806314105023

Epoch: 6| Step: 11
Training loss: 2.6051541300039545
Validation loss: 2.454034230665477

Epoch: 6| Step: 12
Training loss: 2.2927212687197804
Validation loss: 2.503838767734011

Epoch: 6| Step: 13
Training loss: 1.8594443684949513
Validation loss: 2.4305012407303805

Epoch: 206| Step: 0
Training loss: 2.159948301049821
Validation loss: 2.441132875949646

Epoch: 6| Step: 1
Training loss: 1.9257288184775818
Validation loss: 2.40693605761702

Epoch: 6| Step: 2
Training loss: 2.1858352866281017
Validation loss: 2.4387141186460015

Epoch: 6| Step: 3
Training loss: 2.4010475693724613
Validation loss: 2.4355273724708733

Epoch: 6| Step: 4
Training loss: 2.3528022413046603
Validation loss: 2.3927007257769173

Epoch: 6| Step: 5
Training loss: 2.2593319541872163
Validation loss: 2.458632751453926

Epoch: 6| Step: 6
Training loss: 1.955095563538299
Validation loss: 2.4292805226683165

Epoch: 6| Step: 7
Training loss: 1.6897635643249953
Validation loss: 2.430352675901443

Epoch: 6| Step: 8
Training loss: 1.8754697846938406
Validation loss: 2.437954795274903

Epoch: 6| Step: 9
Training loss: 1.9393107658761313
Validation loss: 2.4220914915287732

Epoch: 6| Step: 10
Training loss: 2.200336179190043
Validation loss: 2.3914911785517505

Epoch: 6| Step: 11
Training loss: 2.422102000765413
Validation loss: 2.4674738146097375

Epoch: 6| Step: 12
Training loss: 2.058432295835966
Validation loss: 2.4005492304247973

Epoch: 6| Step: 13
Training loss: 2.082713289180241
Validation loss: 2.4776053540899703

Epoch: 207| Step: 0
Training loss: 1.6242700551247928
Validation loss: 2.4300914948582366

Epoch: 6| Step: 1
Training loss: 1.3115767456037255
Validation loss: 2.446917290906784

Epoch: 6| Step: 2
Training loss: 2.9078691135739323
Validation loss: 2.481124399310991

Epoch: 6| Step: 3
Training loss: 1.7107723626694988
Validation loss: 2.458624003102556

Epoch: 6| Step: 4
Training loss: 2.162176418901815
Validation loss: 2.4624480648715803

Epoch: 6| Step: 5
Training loss: 2.3130735768557478
Validation loss: 2.488044843317623

Epoch: 6| Step: 6
Training loss: 2.298569657437593
Validation loss: 2.5043218991835947

Epoch: 6| Step: 7
Training loss: 2.159419618799777
Validation loss: 2.4853772178405764

Epoch: 6| Step: 8
Training loss: 2.87883983105837
Validation loss: 2.457924276607365

Epoch: 6| Step: 9
Training loss: 1.8701564535694966
Validation loss: 2.4829042105083716

Epoch: 6| Step: 10
Training loss: 1.7269011980872913
Validation loss: 2.4199638243550843

Epoch: 6| Step: 11
Training loss: 1.8343705653278353
Validation loss: 2.4985818306548597

Epoch: 6| Step: 12
Training loss: 2.345465070729098
Validation loss: 2.455617428149217

Epoch: 6| Step: 13
Training loss: 1.7565558116373565
Validation loss: 2.471762963354971

Epoch: 208| Step: 0
Training loss: 2.159415644085149
Validation loss: 2.42924975811711

Epoch: 6| Step: 1
Training loss: 1.8994732452821879
Validation loss: 2.4779096108322762

Epoch: 6| Step: 2
Training loss: 3.0479193047081634
Validation loss: 2.4081567146482548

Epoch: 6| Step: 3
Training loss: 2.456091381125003
Validation loss: 2.4191516586496675

Epoch: 6| Step: 4
Training loss: 1.435473547898713
Validation loss: 2.380757341211824

Epoch: 6| Step: 5
Training loss: 2.0655908255700592
Validation loss: 2.4479220489533544

Epoch: 6| Step: 6
Training loss: 1.814048237378996
Validation loss: 2.46016406438498

Epoch: 6| Step: 7
Training loss: 2.4203656815657464
Validation loss: 2.448791545152487

Epoch: 6| Step: 8
Training loss: 2.232391544112633
Validation loss: 2.4390399907201217

Epoch: 6| Step: 9
Training loss: 1.823645164608885
Validation loss: 2.4836357917222425

Epoch: 6| Step: 10
Training loss: 1.1343347253296732
Validation loss: 2.474938607078527

Epoch: 6| Step: 11
Training loss: 2.2054232250437784
Validation loss: 2.4633443583804384

Epoch: 6| Step: 12
Training loss: 1.9726911787207808
Validation loss: 2.4296837110186185

Epoch: 6| Step: 13
Training loss: 2.4008349635145043
Validation loss: 2.413298533809733

Epoch: 209| Step: 0
Training loss: 2.428950943264177
Validation loss: 2.4282940752893967

Epoch: 6| Step: 1
Training loss: 2.2150325526478274
Validation loss: 2.4125603027050153

Epoch: 6| Step: 2
Training loss: 2.0541471633862205
Validation loss: 2.395416393266065

Epoch: 6| Step: 3
Training loss: 2.2273095734756296
Validation loss: 2.4305305549597604

Epoch: 6| Step: 4
Training loss: 1.7839767599559324
Validation loss: 2.4789819559839765

Epoch: 6| Step: 5
Training loss: 2.3611675804217014
Validation loss: 2.4292825119242196

Epoch: 6| Step: 6
Training loss: 1.6456559564480049
Validation loss: 2.4262847100518092

Epoch: 6| Step: 7
Training loss: 1.8806832964942946
Validation loss: 2.4966262181921404

Epoch: 6| Step: 8
Training loss: 2.384741030854445
Validation loss: 2.4851617076366

Epoch: 6| Step: 9
Training loss: 2.824893179705315
Validation loss: 2.491818463754852

Epoch: 6| Step: 10
Training loss: 1.6762216696169272
Validation loss: 2.4373366609068303

Epoch: 6| Step: 11
Training loss: 1.8350913837348033
Validation loss: 2.464362009555216

Epoch: 6| Step: 12
Training loss: 1.1433630700502941
Validation loss: 2.414737456128119

Epoch: 6| Step: 13
Training loss: 2.501801128073519
Validation loss: 2.394223005244

Epoch: 210| Step: 0
Training loss: 1.8745207491967943
Validation loss: 2.4207722477114713

Epoch: 6| Step: 1
Training loss: 1.8612767599729967
Validation loss: 2.471824181609681

Epoch: 6| Step: 2
Training loss: 2.4396780015758823
Validation loss: 2.4121636080232176

Epoch: 6| Step: 3
Training loss: 1.7515611497123476
Validation loss: 2.439549180297368

Epoch: 6| Step: 4
Training loss: 1.6449729344422683
Validation loss: 2.419401960666027

Epoch: 6| Step: 5
Training loss: 1.8234567623216067
Validation loss: 2.3896009587138733

Epoch: 6| Step: 6
Training loss: 2.108850145387164
Validation loss: 2.395601510865323

Epoch: 6| Step: 7
Training loss: 1.9624163154205294
Validation loss: 2.419572157328583

Epoch: 6| Step: 8
Training loss: 2.3813919585758816
Validation loss: 2.4038001583233037

Epoch: 6| Step: 9
Training loss: 2.420680286693086
Validation loss: 2.426278144258274

Epoch: 6| Step: 10
Training loss: 2.069145132632078
Validation loss: 2.4064159232226894

Epoch: 6| Step: 11
Training loss: 2.6210122472425255
Validation loss: 2.406993427771531

Epoch: 6| Step: 12
Training loss: 1.9344820082343737
Validation loss: 2.4151072798127373

Epoch: 6| Step: 13
Training loss: 2.2953258662032647
Validation loss: 2.3617710892391504

Epoch: 211| Step: 0
Training loss: 1.6548221839505883
Validation loss: 2.4276312341184814

Epoch: 6| Step: 1
Training loss: 1.9071436178880443
Validation loss: 2.5071176266426467

Epoch: 6| Step: 2
Training loss: 2.0647397451371265
Validation loss: 2.4535156371624565

Epoch: 6| Step: 3
Training loss: 2.443920775395285
Validation loss: 2.490909571388716

Epoch: 6| Step: 4
Training loss: 2.0179915618493225
Validation loss: 2.484285244255846

Epoch: 6| Step: 5
Training loss: 1.596271241001169
Validation loss: 2.4760873787221276

Epoch: 6| Step: 6
Training loss: 1.6949321830033404
Validation loss: 2.4433542610582437

Epoch: 6| Step: 7
Training loss: 2.0328151834808863
Validation loss: 2.489667898142245

Epoch: 6| Step: 8
Training loss: 2.580899496966114
Validation loss: 2.5116978965667656

Epoch: 6| Step: 9
Training loss: 2.2133731433819475
Validation loss: 2.4417508314875565

Epoch: 6| Step: 10
Training loss: 1.97141255368267
Validation loss: 2.458082708434846

Epoch: 6| Step: 11
Training loss: 2.462805629295172
Validation loss: 2.464910648233054

Epoch: 6| Step: 12
Training loss: 2.1326899790243448
Validation loss: 2.4569988055889325

Epoch: 6| Step: 13
Training loss: 2.6169423458233707
Validation loss: 2.429279050512369

Epoch: 212| Step: 0
Training loss: 2.3269683217514094
Validation loss: 2.4515906194204153

Epoch: 6| Step: 1
Training loss: 1.614041128691026
Validation loss: 2.433397758356994

Epoch: 6| Step: 2
Training loss: 1.7546815241969216
Validation loss: 2.3785885597493652

Epoch: 6| Step: 3
Training loss: 1.689911214651933
Validation loss: 2.4183694938545113

Epoch: 6| Step: 4
Training loss: 2.1844477476304363
Validation loss: 2.4243257325842342

Epoch: 6| Step: 5
Training loss: 2.256664789594417
Validation loss: 2.454064911203766

Epoch: 6| Step: 6
Training loss: 2.3298147329258394
Validation loss: 2.417481696231802

Epoch: 6| Step: 7
Training loss: 2.375355442955264
Validation loss: 2.47170841689792

Epoch: 6| Step: 8
Training loss: 2.4321023893260594
Validation loss: 2.486459286626841

Epoch: 6| Step: 9
Training loss: 2.25883582133158
Validation loss: 2.422170856359002

Epoch: 6| Step: 10
Training loss: 2.4247484450283663
Validation loss: 2.473379138617688

Epoch: 6| Step: 11
Training loss: 2.005386371057433
Validation loss: 2.4558140579270518

Epoch: 6| Step: 12
Training loss: 2.008398779387066
Validation loss: 2.4731872711037286

Epoch: 6| Step: 13
Training loss: 1.2941086460886775
Validation loss: 2.4505307010577804

Epoch: 213| Step: 0
Training loss: 2.6149628706971177
Validation loss: 2.4118254277675044

Epoch: 6| Step: 1
Training loss: 1.9243595222031589
Validation loss: 2.4490976438605037

Epoch: 6| Step: 2
Training loss: 2.284544877651597
Validation loss: 2.443416994764903

Epoch: 6| Step: 3
Training loss: 2.3587069544581576
Validation loss: 2.4372830900488447

Epoch: 6| Step: 4
Training loss: 1.75214935190451
Validation loss: 2.4531214823559475

Epoch: 6| Step: 5
Training loss: 1.5177931074851791
Validation loss: 2.460162597162877

Epoch: 6| Step: 6
Training loss: 2.065357771539059
Validation loss: 2.4783478319861567

Epoch: 6| Step: 7
Training loss: 1.121607539775772
Validation loss: 2.3922195205339944

Epoch: 6| Step: 8
Training loss: 2.052611255673842
Validation loss: 2.401812294247931

Epoch: 6| Step: 9
Training loss: 1.5289406781810897
Validation loss: 2.4100724559034856

Epoch: 6| Step: 10
Training loss: 2.347811625539007
Validation loss: 2.420899890396099

Epoch: 6| Step: 11
Training loss: 1.757359425117085
Validation loss: 2.459118547346345

Epoch: 6| Step: 12
Training loss: 2.1673886734511183
Validation loss: 2.365853302567611

Epoch: 6| Step: 13
Training loss: 3.3320099269815238
Validation loss: 2.4237849288610382

Epoch: 214| Step: 0
Training loss: 2.0674245593181095
Validation loss: 2.3849318712459615

Epoch: 6| Step: 1
Training loss: 1.8783472066173437
Validation loss: 2.43289217806613

Epoch: 6| Step: 2
Training loss: 2.206765920168248
Validation loss: 2.474274899878864

Epoch: 6| Step: 3
Training loss: 1.971900417448203
Validation loss: 2.4420714871986804

Epoch: 6| Step: 4
Training loss: 1.7994155173263209
Validation loss: 2.4972077855921406

Epoch: 6| Step: 5
Training loss: 1.6622788447084647
Validation loss: 2.465710939856846

Epoch: 6| Step: 6
Training loss: 3.0013424730651783
Validation loss: 2.4581388942714972

Epoch: 6| Step: 7
Training loss: 1.4864659088875574
Validation loss: 2.5098557177190535

Epoch: 6| Step: 8
Training loss: 2.029133559733036
Validation loss: 2.452799718863482

Epoch: 6| Step: 9
Training loss: 2.0446063566132766
Validation loss: 2.498127451375037

Epoch: 6| Step: 10
Training loss: 2.328660122605652
Validation loss: 2.493522609167585

Epoch: 6| Step: 11
Training loss: 2.404879885903868
Validation loss: 2.503237895819566

Epoch: 6| Step: 12
Training loss: 1.6801332813709053
Validation loss: 2.4916426265225056

Epoch: 6| Step: 13
Training loss: 2.4707941211936197
Validation loss: 2.465461870959653

Epoch: 215| Step: 0
Training loss: 1.4887151611248992
Validation loss: 2.4426141606123632

Epoch: 6| Step: 1
Training loss: 2.0782383479132767
Validation loss: 2.5146334408644324

Epoch: 6| Step: 2
Training loss: 1.829148943155518
Validation loss: 2.460202207684333

Epoch: 6| Step: 3
Training loss: 2.7316757394090314
Validation loss: 2.4501174780141675

Epoch: 6| Step: 4
Training loss: 1.9579401094903475
Validation loss: 2.4100257113683425

Epoch: 6| Step: 5
Training loss: 2.5285342683286025
Validation loss: 2.4556662613512668

Epoch: 6| Step: 6
Training loss: 2.284978667311973
Validation loss: 2.4452860951124222

Epoch: 6| Step: 7
Training loss: 1.7702168532254
Validation loss: 2.4301295600253088

Epoch: 6| Step: 8
Training loss: 2.3801344533816398
Validation loss: 2.46090982880265

Epoch: 6| Step: 9
Training loss: 2.349663560199709
Validation loss: 2.4139104170602184

Epoch: 6| Step: 10
Training loss: 2.1205351429415056
Validation loss: 2.482519530981504

Epoch: 6| Step: 11
Training loss: 1.5619664616421576
Validation loss: 2.4292442218917576

Epoch: 6| Step: 12
Training loss: 1.411319833789737
Validation loss: 2.4610620131524543

Epoch: 6| Step: 13
Training loss: 1.8814670931746253
Validation loss: 2.4259546808513526

Epoch: 216| Step: 0
Training loss: 1.588252440424431
Validation loss: 2.438535951340643

Epoch: 6| Step: 1
Training loss: 1.704323513147205
Validation loss: 2.354689724467377

Epoch: 6| Step: 2
Training loss: 1.9021298016000405
Validation loss: 2.3909246208819592

Epoch: 6| Step: 3
Training loss: 2.34859322179469
Validation loss: 2.4445718828836327

Epoch: 6| Step: 4
Training loss: 1.9937655313777765
Validation loss: 2.4660767494894213

Epoch: 6| Step: 5
Training loss: 1.5296688090381652
Validation loss: 2.4338938139084707

Epoch: 6| Step: 6
Training loss: 1.6761603649049137
Validation loss: 2.4091161143923525

Epoch: 6| Step: 7
Training loss: 2.3431473020650677
Validation loss: 2.423792556991302

Epoch: 6| Step: 8
Training loss: 2.5433077491016745
Validation loss: 2.418355059900084

Epoch: 6| Step: 9
Training loss: 2.0430489227143456
Validation loss: 2.4342379622884747

Epoch: 6| Step: 10
Training loss: 1.8983677352833588
Validation loss: 2.4350320318740986

Epoch: 6| Step: 11
Training loss: 2.6898394316218424
Validation loss: 2.4054327872740853

Epoch: 6| Step: 12
Training loss: 1.9733486659940676
Validation loss: 2.430997006768444

Epoch: 6| Step: 13
Training loss: 2.08923901516212
Validation loss: 2.414897868281006

Epoch: 217| Step: 0
Training loss: 1.769686458424998
Validation loss: 2.396503054912448

Epoch: 6| Step: 1
Training loss: 2.4469326124558277
Validation loss: 2.4100663501468507

Epoch: 6| Step: 2
Training loss: 2.303535820230597
Validation loss: 2.397633283476362

Epoch: 6| Step: 3
Training loss: 2.149222268781482
Validation loss: 2.488471552979623

Epoch: 6| Step: 4
Training loss: 1.6780021551479827
Validation loss: 2.482585927089177

Epoch: 6| Step: 5
Training loss: 1.739429223397324
Validation loss: 2.502165789408997

Epoch: 6| Step: 6
Training loss: 2.1910216186027958
Validation loss: 2.5037201121167043

Epoch: 6| Step: 7
Training loss: 1.9519268786070627
Validation loss: 2.46251636335409

Epoch: 6| Step: 8
Training loss: 1.8133316762767027
Validation loss: 2.4890294711133527

Epoch: 6| Step: 9
Training loss: 2.769923259071453
Validation loss: 2.4502622988826697

Epoch: 6| Step: 10
Training loss: 2.1454213558621658
Validation loss: 2.512189886726906

Epoch: 6| Step: 11
Training loss: 2.0471915662734146
Validation loss: 2.4580130127677218

Epoch: 6| Step: 12
Training loss: 1.8730184893003556
Validation loss: 2.5034848443574447

Epoch: 6| Step: 13
Training loss: 2.2113476699641907
Validation loss: 2.490467762089081

Epoch: 218| Step: 0
Training loss: 2.412510246294627
Validation loss: 2.414070185400749

Epoch: 6| Step: 1
Training loss: 1.9163636368851384
Validation loss: 2.4491374029824433

Epoch: 6| Step: 2
Training loss: 2.2590161979131715
Validation loss: 2.4519897785455167

Epoch: 6| Step: 3
Training loss: 2.3762711586529432
Validation loss: 2.3801251601526148

Epoch: 6| Step: 4
Training loss: 1.6931240881899452
Validation loss: 2.388454498836626

Epoch: 6| Step: 5
Training loss: 1.6439667591437723
Validation loss: 2.45888972325655

Epoch: 6| Step: 6
Training loss: 2.136095252417055
Validation loss: 2.4644199444671697

Epoch: 6| Step: 7
Training loss: 2.0764247277383734
Validation loss: 2.45272154763004

Epoch: 6| Step: 8
Training loss: 1.6670812885806126
Validation loss: 2.4006740633983656

Epoch: 6| Step: 9
Training loss: 2.095604715587584
Validation loss: 2.395756996796965

Epoch: 6| Step: 10
Training loss: 2.4985362536182123
Validation loss: 2.4401660324352448

Epoch: 6| Step: 11
Training loss: 1.6016973671301273
Validation loss: 2.4542617625104017

Epoch: 6| Step: 12
Training loss: 2.033864612690911
Validation loss: 2.406969501694791

Epoch: 6| Step: 13
Training loss: 1.4544255988905481
Validation loss: 2.391357196075699

Epoch: 219| Step: 0
Training loss: 1.4675703790220123
Validation loss: 2.443909775694938

Epoch: 6| Step: 1
Training loss: 2.154728228078298
Validation loss: 2.409307654391246

Epoch: 6| Step: 2
Training loss: 1.6089594776795404
Validation loss: 2.4438425039917475

Epoch: 6| Step: 3
Training loss: 1.796979552834607
Validation loss: 2.4358305808244833

Epoch: 6| Step: 4
Training loss: 1.920099942864532
Validation loss: 2.4202125318680943

Epoch: 6| Step: 5
Training loss: 2.4279541505384117
Validation loss: 2.4223871711665

Epoch: 6| Step: 6
Training loss: 2.6097669478391534
Validation loss: 2.4394550565680118

Epoch: 6| Step: 7
Training loss: 2.0589071248818294
Validation loss: 2.414530997117126

Epoch: 6| Step: 8
Training loss: 3.0474626023436455
Validation loss: 2.4873072477332085

Epoch: 6| Step: 9
Training loss: 1.8113046848211052
Validation loss: 2.430991438666953

Epoch: 6| Step: 10
Training loss: 1.3690622609305243
Validation loss: 2.4013711233805335

Epoch: 6| Step: 11
Training loss: 2.156573285179659
Validation loss: 2.3883667747163964

Epoch: 6| Step: 12
Training loss: 1.7889769421238173
Validation loss: 2.3967618351317967

Epoch: 6| Step: 13
Training loss: 1.9492587465758093
Validation loss: 2.391544009634989

Epoch: 220| Step: 0
Training loss: 1.5527428200929934
Validation loss: 2.4059121979238065

Epoch: 6| Step: 1
Training loss: 2.0721975130182413
Validation loss: 2.4696740668860797

Epoch: 6| Step: 2
Training loss: 1.6750632573039888
Validation loss: 2.4446356508030957

Epoch: 6| Step: 3
Training loss: 2.0459621810997577
Validation loss: 2.390684993129732

Epoch: 6| Step: 4
Training loss: 1.8562662759703112
Validation loss: 2.397523576077606

Epoch: 6| Step: 5
Training loss: 1.9445343299556264
Validation loss: 2.4158076569030746

Epoch: 6| Step: 6
Training loss: 2.1485997364170792
Validation loss: 2.4293843322129085

Epoch: 6| Step: 7
Training loss: 2.099227572480414
Validation loss: 2.4316618286742324

Epoch: 6| Step: 8
Training loss: 1.410072133944876
Validation loss: 2.4314502454237648

Epoch: 6| Step: 9
Training loss: 1.8580049869031061
Validation loss: 2.4470857666218864

Epoch: 6| Step: 10
Training loss: 3.0369288154728
Validation loss: 2.399764469597619

Epoch: 6| Step: 11
Training loss: 1.600320027055639
Validation loss: 2.4638830622757877

Epoch: 6| Step: 12
Training loss: 2.05474261655965
Validation loss: 2.452844777093734

Epoch: 6| Step: 13
Training loss: 2.7363437213766355
Validation loss: 2.4166677723911403

Epoch: 221| Step: 0
Training loss: 2.2289352891102
Validation loss: 2.4382418147117306

Epoch: 6| Step: 1
Training loss: 1.905251413410635
Validation loss: 2.470604125129314

Epoch: 6| Step: 2
Training loss: 2.045976747457129
Validation loss: 2.465158183780662

Epoch: 6| Step: 3
Training loss: 2.3230810634675247
Validation loss: 2.4224442579424523

Epoch: 6| Step: 4
Training loss: 1.8680022947840513
Validation loss: 2.476518018219612

Epoch: 6| Step: 5
Training loss: 2.0411581327342447
Validation loss: 2.442236517718419

Epoch: 6| Step: 6
Training loss: 2.6053205044735424
Validation loss: 2.508761140939125

Epoch: 6| Step: 7
Training loss: 2.1580279110861507
Validation loss: 2.4611017175311822

Epoch: 6| Step: 8
Training loss: 1.9876873575827112
Validation loss: 2.4773425882531903

Epoch: 6| Step: 9
Training loss: 2.0524723310382855
Validation loss: 2.453167299117964

Epoch: 6| Step: 10
Training loss: 1.7310977937740828
Validation loss: 2.4776726599789978

Epoch: 6| Step: 11
Training loss: 1.5972938779523151
Validation loss: 2.4597736336462535

Epoch: 6| Step: 12
Training loss: 2.021521644433008
Validation loss: 2.4271670041922166

Epoch: 6| Step: 13
Training loss: 1.81324029471097
Validation loss: 2.430496651384467

Epoch: 222| Step: 0
Training loss: 1.9675906567366641
Validation loss: 2.4332800622363497

Epoch: 6| Step: 1
Training loss: 1.9406880637225161
Validation loss: 2.415651779451938

Epoch: 6| Step: 2
Training loss: 2.100270381051675
Validation loss: 2.4321927316214773

Epoch: 6| Step: 3
Training loss: 2.9050360984988712
Validation loss: 2.41136789126827

Epoch: 6| Step: 4
Training loss: 1.965531640193328
Validation loss: 2.391691312834075

Epoch: 6| Step: 5
Training loss: 1.612466897550775
Validation loss: 2.419515008085252

Epoch: 6| Step: 6
Training loss: 1.7713609545191709
Validation loss: 2.442406843008107

Epoch: 6| Step: 7
Training loss: 1.6887356508042102
Validation loss: 2.443807849357201

Epoch: 6| Step: 8
Training loss: 1.9984554644888968
Validation loss: 2.4799650345334414

Epoch: 6| Step: 9
Training loss: 2.410611645970879
Validation loss: 2.3842107405385597

Epoch: 6| Step: 10
Training loss: 1.6272989297116327
Validation loss: 2.4628755078580387

Epoch: 6| Step: 11
Training loss: 1.7016563732920649
Validation loss: 2.378797737347714

Epoch: 6| Step: 12
Training loss: 2.4437118995603755
Validation loss: 2.39844289997307

Epoch: 6| Step: 13
Training loss: 2.067736365242789
Validation loss: 2.458938383044226

Epoch: 223| Step: 0
Training loss: 1.9856861018408587
Validation loss: 2.4017738576731036

Epoch: 6| Step: 1
Training loss: 1.9876312212541092
Validation loss: 2.4291484387633324

Epoch: 6| Step: 2
Training loss: 1.8776468668053508
Validation loss: 2.439920938049106

Epoch: 6| Step: 3
Training loss: 1.6359221857587438
Validation loss: 2.422553474905074

Epoch: 6| Step: 4
Training loss: 1.822452057258868
Validation loss: 2.458786090713761

Epoch: 6| Step: 5
Training loss: 2.2236847065200656
Validation loss: 2.461295211480817

Epoch: 6| Step: 6
Training loss: 2.437809655498737
Validation loss: 2.449189611299121

Epoch: 6| Step: 7
Training loss: 1.607728875509175
Validation loss: 2.4405447268151383

Epoch: 6| Step: 8
Training loss: 1.740508908795551
Validation loss: 2.491065216346544

Epoch: 6| Step: 9
Training loss: 1.4305585698627865
Validation loss: 2.3937756037761164

Epoch: 6| Step: 10
Training loss: 2.6693304784050054
Validation loss: 2.4874622564924973

Epoch: 6| Step: 11
Training loss: 2.6688497270090807
Validation loss: 2.4087582420044935

Epoch: 6| Step: 12
Training loss: 1.9362544085930813
Validation loss: 2.4093721034607403

Epoch: 6| Step: 13
Training loss: 1.6436205446735712
Validation loss: 2.4485874413367315

Epoch: 224| Step: 0
Training loss: 2.051965106585641
Validation loss: 2.421046797834592

Epoch: 6| Step: 1
Training loss: 1.7101097020436091
Validation loss: 2.4865314754376167

Epoch: 6| Step: 2
Training loss: 1.7936688554333713
Validation loss: 2.4800545155761866

Epoch: 6| Step: 3
Training loss: 2.1120577106538363
Validation loss: 2.41806003435951

Epoch: 6| Step: 4
Training loss: 1.7806438284642037
Validation loss: 2.4157638058458537

Epoch: 6| Step: 5
Training loss: 2.1197971153345465
Validation loss: 2.409352523128337

Epoch: 6| Step: 6
Training loss: 1.5676440440162505
Validation loss: 2.4579602534240377

Epoch: 6| Step: 7
Training loss: 2.245901295253476
Validation loss: 2.4419420058575043

Epoch: 6| Step: 8
Training loss: 1.8886617760846858
Validation loss: 2.3978808228200297

Epoch: 6| Step: 9
Training loss: 1.7001814997778588
Validation loss: 2.4613589856750564

Epoch: 6| Step: 10
Training loss: 1.9758338640658233
Validation loss: 2.467501219469367

Epoch: 6| Step: 11
Training loss: 2.756434196147561
Validation loss: 2.467164954084594

Epoch: 6| Step: 12
Training loss: 2.2419099536273395
Validation loss: 2.394905596248296

Epoch: 6| Step: 13
Training loss: 2.103910701278131
Validation loss: 2.4340579633168478

Epoch: 225| Step: 0
Training loss: 1.9321281658688878
Validation loss: 2.429528772388163

Epoch: 6| Step: 1
Training loss: 2.327947929868378
Validation loss: 2.474714664374434

Epoch: 6| Step: 2
Training loss: 1.5317309655746563
Validation loss: 2.4143094113981207

Epoch: 6| Step: 3
Training loss: 1.3512584366301241
Validation loss: 2.457617260352949

Epoch: 6| Step: 4
Training loss: 2.1483875615645003
Validation loss: 2.434440166817428

Epoch: 6| Step: 5
Training loss: 2.4360386306881665
Validation loss: 2.379970372145633

Epoch: 6| Step: 6
Training loss: 1.5790878229245342
Validation loss: 2.464786443913118

Epoch: 6| Step: 7
Training loss: 2.9673296291225637
Validation loss: 2.4656880347933985

Epoch: 6| Step: 8
Training loss: 1.680361803128556
Validation loss: 2.4823845667654556

Epoch: 6| Step: 9
Training loss: 2.100065698050113
Validation loss: 2.4358716242099265

Epoch: 6| Step: 10
Training loss: 1.9777854784745352
Validation loss: 2.3779364234451745

Epoch: 6| Step: 11
Training loss: 1.7570437636551037
Validation loss: 2.407235997111697

Epoch: 6| Step: 12
Training loss: 1.7576377273141088
Validation loss: 2.4023161695704447

Epoch: 6| Step: 13
Training loss: 1.7156542554907575
Validation loss: 2.433198709159117

Epoch: 226| Step: 0
Training loss: 1.938311499190857
Validation loss: 2.4429893399362217

Epoch: 6| Step: 1
Training loss: 2.074090468755644
Validation loss: 2.3773996010658416

Epoch: 6| Step: 2
Training loss: 1.6342805532441596
Validation loss: 2.4395819355878943

Epoch: 6| Step: 3
Training loss: 2.0110449986746533
Validation loss: 2.404707257591706

Epoch: 6| Step: 4
Training loss: 1.4024878722701772
Validation loss: 2.427148546281704

Epoch: 6| Step: 5
Training loss: 2.748844250654349
Validation loss: 2.4260804985816518

Epoch: 6| Step: 6
Training loss: 2.0030759760768633
Validation loss: 2.446228652498687

Epoch: 6| Step: 7
Training loss: 2.372968005215847
Validation loss: 2.4350762160542905

Epoch: 6| Step: 8
Training loss: 2.3367436781675592
Validation loss: 2.457191406113684

Epoch: 6| Step: 9
Training loss: 1.4612875942227028
Validation loss: 2.4977291437837743

Epoch: 6| Step: 10
Training loss: 2.158831944061746
Validation loss: 2.394390425187602

Epoch: 6| Step: 11
Training loss: 2.0756225433381017
Validation loss: 2.378360615871228

Epoch: 6| Step: 12
Training loss: 1.8197109554612736
Validation loss: 2.477363775372878

Epoch: 6| Step: 13
Training loss: 2.8936219222065476
Validation loss: 2.4011121664831863

Epoch: 227| Step: 0
Training loss: 2.239718257181361
Validation loss: 2.4553942859761086

Epoch: 6| Step: 1
Training loss: 1.9864323681509812
Validation loss: 2.421147125244205

Epoch: 6| Step: 2
Training loss: 1.7304593811470423
Validation loss: 2.403205460521945

Epoch: 6| Step: 3
Training loss: 1.7644706260720229
Validation loss: 2.4661889791306764

Epoch: 6| Step: 4
Training loss: 1.8240777232776737
Validation loss: 2.5069277328415818

Epoch: 6| Step: 5
Training loss: 2.45015230289324
Validation loss: 2.510255277301193

Epoch: 6| Step: 6
Training loss: 1.8424825029305831
Validation loss: 2.54294234494719

Epoch: 6| Step: 7
Training loss: 1.7906762054205394
Validation loss: 2.5011742613065127

Epoch: 6| Step: 8
Training loss: 2.469424964285378
Validation loss: 2.5452663480724085

Epoch: 6| Step: 9
Training loss: 1.8224555894754615
Validation loss: 2.4753300061167227

Epoch: 6| Step: 10
Training loss: 2.0751164966650535
Validation loss: 2.4987811798905044

Epoch: 6| Step: 11
Training loss: 2.3270063336871827
Validation loss: 2.4779489785300757

Epoch: 6| Step: 12
Training loss: 2.005707702548286
Validation loss: 2.4691827824877106

Epoch: 6| Step: 13
Training loss: 2.0095704691068677
Validation loss: 2.4444782498715654

Epoch: 228| Step: 0
Training loss: 1.691232720827419
Validation loss: 2.4224433721562892

Epoch: 6| Step: 1
Training loss: 1.6027254673828601
Validation loss: 2.4458054493173105

Epoch: 6| Step: 2
Training loss: 1.6736809789373217
Validation loss: 2.413341932515418

Epoch: 6| Step: 3
Training loss: 2.533996975289506
Validation loss: 2.4112713161713617

Epoch: 6| Step: 4
Training loss: 2.1338194541599953
Validation loss: 2.4695786684171095

Epoch: 6| Step: 5
Training loss: 1.9330210444473612
Validation loss: 2.4207353083630756

Epoch: 6| Step: 6
Training loss: 1.6987460476434244
Validation loss: 2.4160367196290307

Epoch: 6| Step: 7
Training loss: 1.357718763199676
Validation loss: 2.4290334729152914

Epoch: 6| Step: 8
Training loss: 1.669103874946472
Validation loss: 2.4411063176818266

Epoch: 6| Step: 9
Training loss: 1.8332150666786566
Validation loss: 2.4668245357601086

Epoch: 6| Step: 10
Training loss: 2.1241971911689874
Validation loss: 2.409087283431929

Epoch: 6| Step: 11
Training loss: 2.229431231714349
Validation loss: 2.451883342884173

Epoch: 6| Step: 12
Training loss: 2.289141031942666
Validation loss: 2.4316854643539174

Epoch: 6| Step: 13
Training loss: 3.1410001464280195
Validation loss: 2.39296575269562

Epoch: 229| Step: 0
Training loss: 1.461552617935008
Validation loss: 2.4453672683172005

Epoch: 6| Step: 1
Training loss: 1.8051746586122084
Validation loss: 2.416040386765064

Epoch: 6| Step: 2
Training loss: 2.289784600734582
Validation loss: 2.442245232397128

Epoch: 6| Step: 3
Training loss: 1.5912875431303655
Validation loss: 2.4021420304507846

Epoch: 6| Step: 4
Training loss: 2.6534882493377996
Validation loss: 2.4058524555688825

Epoch: 6| Step: 5
Training loss: 2.689445589784969
Validation loss: 2.4260810839936946

Epoch: 6| Step: 6
Training loss: 1.755343046216295
Validation loss: 2.4148945624756104

Epoch: 6| Step: 7
Training loss: 1.6367893977611447
Validation loss: 2.4799168379753698

Epoch: 6| Step: 8
Training loss: 1.787374574755778
Validation loss: 2.447594553417048

Epoch: 6| Step: 9
Training loss: 2.0823366324102093
Validation loss: 2.383891696724079

Epoch: 6| Step: 10
Training loss: 1.9451493650613778
Validation loss: 2.4934818202264997

Epoch: 6| Step: 11
Training loss: 1.5332561508047873
Validation loss: 2.441031471149953

Epoch: 6| Step: 12
Training loss: 2.2086309796202226
Validation loss: 2.4627173828000486

Epoch: 6| Step: 13
Training loss: 2.1684931490286137
Validation loss: 2.4148831375603317

Epoch: 230| Step: 0
Training loss: 2.0653402250497956
Validation loss: 2.401464569757214

Epoch: 6| Step: 1
Training loss: 1.565369070001507
Validation loss: 2.3878584549446984

Epoch: 6| Step: 2
Training loss: 1.7243076980802154
Validation loss: 2.419905503134111

Epoch: 6| Step: 3
Training loss: 2.7396209095358994
Validation loss: 2.455136110872425

Epoch: 6| Step: 4
Training loss: 1.8004812789278464
Validation loss: 2.4356797739255676

Epoch: 6| Step: 5
Training loss: 1.2915194130094592
Validation loss: 2.4532168331792383

Epoch: 6| Step: 6
Training loss: 1.7160909718228161
Validation loss: 2.4190400201793323

Epoch: 6| Step: 7
Training loss: 2.1086485565514197
Validation loss: 2.4222722664839234

Epoch: 6| Step: 8
Training loss: 1.9485074811541703
Validation loss: 2.4916070532251484

Epoch: 6| Step: 9
Training loss: 1.3617939090614395
Validation loss: 2.3954447263028578

Epoch: 6| Step: 10
Training loss: 2.534622206667058
Validation loss: 2.3881247986019933

Epoch: 6| Step: 11
Training loss: 2.062694193627786
Validation loss: 2.417864968816744

Epoch: 6| Step: 12
Training loss: 2.4856571751565473
Validation loss: 2.4281898707261047

Epoch: 6| Step: 13
Training loss: 2.3441967347684
Validation loss: 2.4331177179227423

Epoch: 231| Step: 0
Training loss: 1.423511108773141
Validation loss: 2.4518139237419145

Epoch: 6| Step: 1
Training loss: 1.7611656927935952
Validation loss: 2.3337568310406405

Epoch: 6| Step: 2
Training loss: 1.7432165827172061
Validation loss: 2.383025753081529

Epoch: 6| Step: 3
Training loss: 1.7602420547234523
Validation loss: 2.432082299452834

Epoch: 6| Step: 4
Training loss: 1.5658735858371549
Validation loss: 2.5273902347249164

Epoch: 6| Step: 5
Training loss: 2.773745323613863
Validation loss: 2.4179113295993235

Epoch: 6| Step: 6
Training loss: 1.9164925855557366
Validation loss: 2.388647037733462

Epoch: 6| Step: 7
Training loss: 1.288839054971233
Validation loss: 2.42902599211562

Epoch: 6| Step: 8
Training loss: 2.2834610348745885
Validation loss: 2.408018185138428

Epoch: 6| Step: 9
Training loss: 1.772092468802647
Validation loss: 2.4275716260238913

Epoch: 6| Step: 10
Training loss: 2.243280124609555
Validation loss: 2.486684179934136

Epoch: 6| Step: 11
Training loss: 2.1003557448836894
Validation loss: 2.459830793880465

Epoch: 6| Step: 12
Training loss: 2.696769254341819
Validation loss: 2.3954120577703066

Epoch: 6| Step: 13
Training loss: 1.5874612187732362
Validation loss: 2.419709384381238

Epoch: 232| Step: 0
Training loss: 1.8902665736401802
Validation loss: 2.4370988042893313

Epoch: 6| Step: 1
Training loss: 1.3809385371414713
Validation loss: 2.39197537157534

Epoch: 6| Step: 2
Training loss: 2.2135593787587933
Validation loss: 2.4340531205269285

Epoch: 6| Step: 3
Training loss: 2.2532035485912667
Validation loss: 2.4177016424256936

Epoch: 6| Step: 4
Training loss: 2.292302153358601
Validation loss: 2.3885887299958593

Epoch: 6| Step: 5
Training loss: 2.342761021812141
Validation loss: 2.464967630063115

Epoch: 6| Step: 6
Training loss: 1.853663865684383
Validation loss: 2.434908889297684

Epoch: 6| Step: 7
Training loss: 2.1523479593170047
Validation loss: 2.403608986841187

Epoch: 6| Step: 8
Training loss: 1.7061245603178639
Validation loss: 2.417344523006737

Epoch: 6| Step: 9
Training loss: 2.079626473119679
Validation loss: 2.4045009683521728

Epoch: 6| Step: 10
Training loss: 1.9518677594151046
Validation loss: 2.407911404963856

Epoch: 6| Step: 11
Training loss: 2.1368154890906523
Validation loss: 2.4091388975559127

Epoch: 6| Step: 12
Training loss: 1.8756292558804168
Validation loss: 2.41636462298971

Epoch: 6| Step: 13
Training loss: 1.702029304471765
Validation loss: 2.4548777989649286

Epoch: 233| Step: 0
Training loss: 1.7440308539522325
Validation loss: 2.4844175038307372

Epoch: 6| Step: 1
Training loss: 2.121772446773558
Validation loss: 2.4732074821332177

Epoch: 6| Step: 2
Training loss: 2.8146025533935224
Validation loss: 2.5123657420067125

Epoch: 6| Step: 3
Training loss: 1.8568797960094248
Validation loss: 2.5001780990002036

Epoch: 6| Step: 4
Training loss: 2.186405453005375
Validation loss: 2.4828670860845734

Epoch: 6| Step: 5
Training loss: 1.8412743451178746
Validation loss: 2.49100599616811

Epoch: 6| Step: 6
Training loss: 2.6370673959312443
Validation loss: 2.5179174982654966

Epoch: 6| Step: 7
Training loss: 1.6185247080380902
Validation loss: 2.5148374781730287

Epoch: 6| Step: 8
Training loss: 1.77124802464797
Validation loss: 2.4240610387688424

Epoch: 6| Step: 9
Training loss: 1.9081114763567206
Validation loss: 2.478313280209237

Epoch: 6| Step: 10
Training loss: 2.1419810434209627
Validation loss: 2.5067141111996354

Epoch: 6| Step: 11
Training loss: 1.6858378100685396
Validation loss: 2.4532239664196838

Epoch: 6| Step: 12
Training loss: 1.6292021777615415
Validation loss: 2.4286738639758383

Epoch: 6| Step: 13
Training loss: 1.735849595612551
Validation loss: 2.4726807804767144

Epoch: 234| Step: 0
Training loss: 2.0757108734570884
Validation loss: 2.4414331756747742

Epoch: 6| Step: 1
Training loss: 1.8245486628910301
Validation loss: 2.418074216687378

Epoch: 6| Step: 2
Training loss: 2.0082914619776786
Validation loss: 2.4694304758328602

Epoch: 6| Step: 3
Training loss: 1.757265811255853
Validation loss: 2.447193805802324

Epoch: 6| Step: 4
Training loss: 1.8708988478417508
Validation loss: 2.4303056716404767

Epoch: 6| Step: 5
Training loss: 1.6463612140463249
Validation loss: 2.415565282887458

Epoch: 6| Step: 6
Training loss: 1.9293150136882382
Validation loss: 2.419536112998063

Epoch: 6| Step: 7
Training loss: 1.7969110899908296
Validation loss: 2.431302408147592

Epoch: 6| Step: 8
Training loss: 1.7025622916904337
Validation loss: 2.4475376510351112

Epoch: 6| Step: 9
Training loss: 1.806038949113424
Validation loss: 2.449484466857284

Epoch: 6| Step: 10
Training loss: 1.7146315736655044
Validation loss: 2.4766907655343453

Epoch: 6| Step: 11
Training loss: 1.616041062753963
Validation loss: 2.4394119710982998

Epoch: 6| Step: 12
Training loss: 2.7358889503027477
Validation loss: 2.4302453116040654

Epoch: 6| Step: 13
Training loss: 3.0592380200776743
Validation loss: 2.4058985512750373

Epoch: 235| Step: 0
Training loss: 1.8759273143303055
Validation loss: 2.4643004493580265

Epoch: 6| Step: 1
Training loss: 2.1520028787685836
Validation loss: 2.4271032853732173

Epoch: 6| Step: 2
Training loss: 1.9530194673637367
Validation loss: 2.4134934447547316

Epoch: 6| Step: 3
Training loss: 1.8345544678531678
Validation loss: 2.4543982522737307

Epoch: 6| Step: 4
Training loss: 1.669375753056204
Validation loss: 2.4280527154127745

Epoch: 6| Step: 5
Training loss: 1.888669855221257
Validation loss: 2.4179513915973567

Epoch: 6| Step: 6
Training loss: 1.918056012128327
Validation loss: 2.420949092440719

Epoch: 6| Step: 7
Training loss: 2.4804181912293233
Validation loss: 2.443539297307025

Epoch: 6| Step: 8
Training loss: 1.779197648230549
Validation loss: 2.382312874381457

Epoch: 6| Step: 9
Training loss: 1.8670960088684239
Validation loss: 2.477059629597653

Epoch: 6| Step: 10
Training loss: 1.9728058711048886
Validation loss: 2.4282748734634283

Epoch: 6| Step: 11
Training loss: 2.236593998592184
Validation loss: 2.448618523059697

Epoch: 6| Step: 12
Training loss: 2.0040521103866085
Validation loss: 2.4275126902429136

Epoch: 6| Step: 13
Training loss: 1.3653633809840746
Validation loss: 2.417099965479787

Epoch: 236| Step: 0
Training loss: 2.187176162727406
Validation loss: 2.4197547462447284

Epoch: 6| Step: 1
Training loss: 1.8477914772792572
Validation loss: 2.4421174934246053

Epoch: 6| Step: 2
Training loss: 2.2313174154745115
Validation loss: 2.454734032625385

Epoch: 6| Step: 3
Training loss: 2.475102713409092
Validation loss: 2.462340000556248

Epoch: 6| Step: 4
Training loss: 1.6727267796106704
Validation loss: 2.4737927373743327

Epoch: 6| Step: 5
Training loss: 1.308286716254312
Validation loss: 2.472319676821711

Epoch: 6| Step: 6
Training loss: 1.869830316199027
Validation loss: 2.3885720049098764

Epoch: 6| Step: 7
Training loss: 2.108761620526272
Validation loss: 2.4308216265373663

Epoch: 6| Step: 8
Training loss: 1.8825433942395773
Validation loss: 2.4443170347489005

Epoch: 6| Step: 9
Training loss: 1.803859834664502
Validation loss: 2.467689002673956

Epoch: 6| Step: 10
Training loss: 1.7701817678881244
Validation loss: 2.4895146429493806

Epoch: 6| Step: 11
Training loss: 1.8204379713832077
Validation loss: 2.419960754294615

Epoch: 6| Step: 12
Training loss: 1.7835543935195652
Validation loss: 2.4639136493101854

Epoch: 6| Step: 13
Training loss: 2.732033822655932
Validation loss: 2.3706769084713106

Epoch: 237| Step: 0
Training loss: 1.7066782710803414
Validation loss: 2.4237967359526533

Epoch: 6| Step: 1
Training loss: 2.1118400581226098
Validation loss: 2.3528455823864323

Epoch: 6| Step: 2
Training loss: 1.798378158107325
Validation loss: 2.38986026103972

Epoch: 6| Step: 3
Training loss: 3.115972678969439
Validation loss: 2.40915658974159

Epoch: 6| Step: 4
Training loss: 2.093095819560892
Validation loss: 2.4346410135765573

Epoch: 6| Step: 5
Training loss: 1.4829073426411816
Validation loss: 2.4323247888099044

Epoch: 6| Step: 6
Training loss: 2.1472120084378457
Validation loss: 2.4219530662633364

Epoch: 6| Step: 7
Training loss: 1.6226181767808558
Validation loss: 2.406403725098753

Epoch: 6| Step: 8
Training loss: 1.9388435381540963
Validation loss: 2.417818989917599

Epoch: 6| Step: 9
Training loss: 1.6520915098176383
Validation loss: 2.4601962961577306

Epoch: 6| Step: 10
Training loss: 1.9224824023092437
Validation loss: 2.499853220086555

Epoch: 6| Step: 11
Training loss: 2.0588927658043636
Validation loss: 2.4737830747087393

Epoch: 6| Step: 12
Training loss: 1.7977944716755263
Validation loss: 2.4606715467341393

Epoch: 6| Step: 13
Training loss: 1.4488219671666205
Validation loss: 2.4591618749897983

Epoch: 238| Step: 0
Training loss: 2.175302778194072
Validation loss: 2.38650286098392

Epoch: 6| Step: 1
Training loss: 1.556684735102761
Validation loss: 2.432745607624458

Epoch: 6| Step: 2
Training loss: 2.2554014855909923
Validation loss: 2.428703016594139

Epoch: 6| Step: 3
Training loss: 1.856436386769212
Validation loss: 2.440133448881316

Epoch: 6| Step: 4
Training loss: 1.2760251206343824
Validation loss: 2.4186578008329125

Epoch: 6| Step: 5
Training loss: 2.402617449792286
Validation loss: 2.4782627064296734

Epoch: 6| Step: 6
Training loss: 2.1921737877110345
Validation loss: 2.4105705245167925

Epoch: 6| Step: 7
Training loss: 1.4366970307459737
Validation loss: 2.429587389139115

Epoch: 6| Step: 8
Training loss: 1.6493573266542818
Validation loss: 2.448219317959857

Epoch: 6| Step: 9
Training loss: 2.0299242828605033
Validation loss: 2.513947463268634

Epoch: 6| Step: 10
Training loss: 1.9715310693044292
Validation loss: 2.447260805203547

Epoch: 6| Step: 11
Training loss: 2.132452742308995
Validation loss: 2.453689676367964

Epoch: 6| Step: 12
Training loss: 2.1575555580738905
Validation loss: 2.4711715682824913

Epoch: 6| Step: 13
Training loss: 2.1282812478491393
Validation loss: 2.461801822814822

Epoch: 239| Step: 0
Training loss: 1.3200638215212945
Validation loss: 2.439263711459159

Epoch: 6| Step: 1
Training loss: 1.6192972178828504
Validation loss: 2.423609332438466

Epoch: 6| Step: 2
Training loss: 2.3949022114645993
Validation loss: 2.4506367069325488

Epoch: 6| Step: 3
Training loss: 1.8820418050746333
Validation loss: 2.454205852474057

Epoch: 6| Step: 4
Training loss: 2.2211180394119583
Validation loss: 2.405317490464109

Epoch: 6| Step: 5
Training loss: 1.7768854577410556
Validation loss: 2.44844525734243

Epoch: 6| Step: 6
Training loss: 2.159245939027678
Validation loss: 2.425697603560841

Epoch: 6| Step: 7
Training loss: 2.275696356539142
Validation loss: 2.3569399937780107

Epoch: 6| Step: 8
Training loss: 1.3465970949733985
Validation loss: 2.4185665183653238

Epoch: 6| Step: 9
Training loss: 2.218656081240112
Validation loss: 2.4419679240914265

Epoch: 6| Step: 10
Training loss: 2.1248204772514017
Validation loss: 2.4690264828309036

Epoch: 6| Step: 11
Training loss: 1.410885946994308
Validation loss: 2.4365098370926206

Epoch: 6| Step: 12
Training loss: 1.9773954664300106
Validation loss: 2.473728552068815

Epoch: 6| Step: 13
Training loss: 2.1908954970327676
Validation loss: 2.410669108376209

Epoch: 240| Step: 0
Training loss: 1.882032050627035
Validation loss: 2.4282193923399418

Epoch: 6| Step: 1
Training loss: 2.172900938694602
Validation loss: 2.391426919742607

Epoch: 6| Step: 2
Training loss: 1.816939080954936
Validation loss: 2.432981651760375

Epoch: 6| Step: 3
Training loss: 2.1333816383773954
Validation loss: 2.411424508543378

Epoch: 6| Step: 4
Training loss: 1.9138003422788938
Validation loss: 2.405034304035998

Epoch: 6| Step: 5
Training loss: 1.8405663757832642
Validation loss: 2.4804838105638267

Epoch: 6| Step: 6
Training loss: 2.6015973246308444
Validation loss: 2.4573035564428034

Epoch: 6| Step: 7
Training loss: 2.3811777980000732
Validation loss: 2.483283550966211

Epoch: 6| Step: 8
Training loss: 1.3550183430095228
Validation loss: 2.4476643724013067

Epoch: 6| Step: 9
Training loss: 1.6559433563238288
Validation loss: 2.4162836149610665

Epoch: 6| Step: 10
Training loss: 2.1033284875337346
Validation loss: 2.462495327496337

Epoch: 6| Step: 11
Training loss: 1.8503859117450725
Validation loss: 2.4512112229195986

Epoch: 6| Step: 12
Training loss: 1.7197114509468796
Validation loss: 2.4277948766601067

Epoch: 6| Step: 13
Training loss: 1.5608126875853934
Validation loss: 2.4379280162586934

Epoch: 241| Step: 0
Training loss: 1.4803629412119257
Validation loss: 2.4116090644018326

Epoch: 6| Step: 1
Training loss: 2.2761067978351472
Validation loss: 2.421234394394858

Epoch: 6| Step: 2
Training loss: 2.2609912710379847
Validation loss: 2.447008077856944

Epoch: 6| Step: 3
Training loss: 1.2931135390425086
Validation loss: 2.415128299579177

Epoch: 6| Step: 4
Training loss: 2.035520553931125
Validation loss: 2.4822210446216424

Epoch: 6| Step: 5
Training loss: 2.5067195233731003
Validation loss: 2.468702104757319

Epoch: 6| Step: 6
Training loss: 1.4897261686689898
Validation loss: 2.4553116243658155

Epoch: 6| Step: 7
Training loss: 1.8986097971903824
Validation loss: 2.4638963908903704

Epoch: 6| Step: 8
Training loss: 1.4477228634161348
Validation loss: 2.456257968340561

Epoch: 6| Step: 9
Training loss: 2.606041337769337
Validation loss: 2.5206873143034803

Epoch: 6| Step: 10
Training loss: 1.4728707478589835
Validation loss: 2.48334281696866

Epoch: 6| Step: 11
Training loss: 1.7746129110856526
Validation loss: 2.5210941067608768

Epoch: 6| Step: 12
Training loss: 1.784443051298196
Validation loss: 2.4556224304233716

Epoch: 6| Step: 13
Training loss: 2.120462509842075
Validation loss: 2.5058295956373717

Epoch: 242| Step: 0
Training loss: 1.5093011178520226
Validation loss: 2.4614923068265067

Epoch: 6| Step: 1
Training loss: 1.7819164434809651
Validation loss: 2.3947087125970556

Epoch: 6| Step: 2
Training loss: 2.1662758205699784
Validation loss: 2.443231934563679

Epoch: 6| Step: 3
Training loss: 2.126140961360098
Validation loss: 2.460077034092346

Epoch: 6| Step: 4
Training loss: 2.0587839114761004
Validation loss: 2.434546624797758

Epoch: 6| Step: 5
Training loss: 1.623159686963906
Validation loss: 2.3960421356623245

Epoch: 6| Step: 6
Training loss: 2.3563349255705615
Validation loss: 2.4137845230932555

Epoch: 6| Step: 7
Training loss: 1.797808727974584
Validation loss: 2.406931651271873

Epoch: 6| Step: 8
Training loss: 1.6407235978789483
Validation loss: 2.3977476453770326

Epoch: 6| Step: 9
Training loss: 2.2976261908709334
Validation loss: 2.419929800282377

Epoch: 6| Step: 10
Training loss: 1.8684829623185901
Validation loss: 2.395157661413142

Epoch: 6| Step: 11
Training loss: 1.5920996255181625
Validation loss: 2.408682943221373

Epoch: 6| Step: 12
Training loss: 2.124184620321053
Validation loss: 2.3906492054707336

Epoch: 6| Step: 13
Training loss: 1.9506483931820857
Validation loss: 2.4559429686641443

Epoch: 243| Step: 0
Training loss: 1.921155345126318
Validation loss: 2.4242865277941554

Epoch: 6| Step: 1
Training loss: 2.6336126271954443
Validation loss: 2.469712303613295

Epoch: 6| Step: 2
Training loss: 1.7813644372419315
Validation loss: 2.4281688468360074

Epoch: 6| Step: 3
Training loss: 1.689683984407465
Validation loss: 2.4443009196264947

Epoch: 6| Step: 4
Training loss: 2.3317486513497307
Validation loss: 2.4511449349803933

Epoch: 6| Step: 5
Training loss: 1.6581925570417442
Validation loss: 2.4917404108606434

Epoch: 6| Step: 6
Training loss: 1.8033796583467032
Validation loss: 2.461946606662463

Epoch: 6| Step: 7
Training loss: 1.6538607079781666
Validation loss: 2.4474681641488685

Epoch: 6| Step: 8
Training loss: 1.9364456876766287
Validation loss: 2.4873350906145326

Epoch: 6| Step: 9
Training loss: 1.5318267670239814
Validation loss: 2.427469258682408

Epoch: 6| Step: 10
Training loss: 2.1219090814339396
Validation loss: 2.4638236861155023

Epoch: 6| Step: 11
Training loss: 1.6549470202675909
Validation loss: 2.4571651335727553

Epoch: 6| Step: 12
Training loss: 1.6082304060157606
Validation loss: 2.4954484082904993

Epoch: 6| Step: 13
Training loss: 2.527461478131269
Validation loss: 2.4562294496245767

Epoch: 244| Step: 0
Training loss: 2.1479128665193623
Validation loss: 2.4474652752348676

Epoch: 6| Step: 1
Training loss: 2.311655044838153
Validation loss: 2.4092726924172627

Epoch: 6| Step: 2
Training loss: 2.5090876394559642
Validation loss: 2.393064683097882

Epoch: 6| Step: 3
Training loss: 1.6067018251938276
Validation loss: 2.4153425746311155

Epoch: 6| Step: 4
Training loss: 1.9922487735675105
Validation loss: 2.344466671770825

Epoch: 6| Step: 5
Training loss: 2.641128853124158
Validation loss: 2.409076434354226

Epoch: 6| Step: 6
Training loss: 1.9594836677947198
Validation loss: 2.399654299823637

Epoch: 6| Step: 7
Training loss: 1.5101657352060824
Validation loss: 2.366704445791158

Epoch: 6| Step: 8
Training loss: 1.626019304876462
Validation loss: 2.4006194821755025

Epoch: 6| Step: 9
Training loss: 1.5049026953332447
Validation loss: 2.472909651782613

Epoch: 6| Step: 10
Training loss: 1.7101149998861753
Validation loss: 2.3818806542717854

Epoch: 6| Step: 11
Training loss: 1.8411198622739156
Validation loss: 2.440746623129545

Epoch: 6| Step: 12
Training loss: 1.318988926653766
Validation loss: 2.396260674356813

Epoch: 6| Step: 13
Training loss: 1.5260749092864552
Validation loss: 2.4016354947871985

Epoch: 245| Step: 0
Training loss: 1.6197630786723944
Validation loss: 2.4484349878704013

Epoch: 6| Step: 1
Training loss: 2.0503745411441705
Validation loss: 2.43887910199574

Epoch: 6| Step: 2
Training loss: 2.2079639725717457
Validation loss: 2.4698938876774106

Epoch: 6| Step: 3
Training loss: 2.241268381616771
Validation loss: 2.37402295587719

Epoch: 6| Step: 4
Training loss: 2.389457567181838
Validation loss: 2.4552671005855844

Epoch: 6| Step: 5
Training loss: 1.6940417471316285
Validation loss: 2.4345604099207057

Epoch: 6| Step: 6
Training loss: 1.8587108034825284
Validation loss: 2.5025798120368186

Epoch: 6| Step: 7
Training loss: 1.5367516533994925
Validation loss: 2.4079399082471302

Epoch: 6| Step: 8
Training loss: 1.964654022217961
Validation loss: 2.4240441911822916

Epoch: 6| Step: 9
Training loss: 1.8958735479204802
Validation loss: 2.4437216213326174

Epoch: 6| Step: 10
Training loss: 1.4738004979613548
Validation loss: 2.455626447164364

Epoch: 6| Step: 11
Training loss: 2.47522639385495
Validation loss: 2.4495950087876808

Epoch: 6| Step: 12
Training loss: 1.9725580474280149
Validation loss: 2.4292017331055975

Epoch: 6| Step: 13
Training loss: 1.5579894000808094
Validation loss: 2.423450933997713

Epoch: 246| Step: 0
Training loss: 1.6447713137577962
Validation loss: 2.4569457427416674

Epoch: 6| Step: 1
Training loss: 2.176738973393129
Validation loss: 2.3960151856590177

Epoch: 6| Step: 2
Training loss: 1.6880466141027228
Validation loss: 2.419388302158013

Epoch: 6| Step: 3
Training loss: 2.682145306689686
Validation loss: 2.45724384706621

Epoch: 6| Step: 4
Training loss: 1.775567007168468
Validation loss: 2.399174806627294

Epoch: 6| Step: 5
Training loss: 2.2682392690954045
Validation loss: 2.431178152932003

Epoch: 6| Step: 6
Training loss: 1.3605228269709573
Validation loss: 2.3946409660194354

Epoch: 6| Step: 7
Training loss: 2.3222559743412803
Validation loss: 2.4176953375008727

Epoch: 6| Step: 8
Training loss: 1.9218416288626499
Validation loss: 2.377724386186705

Epoch: 6| Step: 9
Training loss: 1.934781597833225
Validation loss: 2.408758953488727

Epoch: 6| Step: 10
Training loss: 1.87129914305225
Validation loss: 2.3527337364255065

Epoch: 6| Step: 11
Training loss: 1.676679179458998
Validation loss: 2.4288110623207504

Epoch: 6| Step: 12
Training loss: 1.758753410287247
Validation loss: 2.4206643255785147

Epoch: 6| Step: 13
Training loss: 1.6556867685456418
Validation loss: 2.4479773641971128

Epoch: 247| Step: 0
Training loss: 1.7909515935169897
Validation loss: 2.490520503933962

Epoch: 6| Step: 1
Training loss: 2.147618252004195
Validation loss: 2.4479925670564553

Epoch: 6| Step: 2
Training loss: 2.5369696340040497
Validation loss: 2.4604686096992947

Epoch: 6| Step: 3
Training loss: 1.6236751731211692
Validation loss: 2.453601322992846

Epoch: 6| Step: 4
Training loss: 1.5815086726126646
Validation loss: 2.427361199700266

Epoch: 6| Step: 5
Training loss: 2.1633321583200487
Validation loss: 2.4492366027521557

Epoch: 6| Step: 6
Training loss: 1.346976111349607
Validation loss: 2.450033821678641

Epoch: 6| Step: 7
Training loss: 1.8647967239542578
Validation loss: 2.4226757619207584

Epoch: 6| Step: 8
Training loss: 2.1371593404655878
Validation loss: 2.439859139967403

Epoch: 6| Step: 9
Training loss: 1.9347921337681506
Validation loss: 2.47997478062102

Epoch: 6| Step: 10
Training loss: 1.5183998740418265
Validation loss: 2.445312720161844

Epoch: 6| Step: 11
Training loss: 1.9214287836882018
Validation loss: 2.4452540515712045

Epoch: 6| Step: 12
Training loss: 1.8238112588781945
Validation loss: 2.396689088710736

Epoch: 6| Step: 13
Training loss: 2.0612608915449533
Validation loss: 2.39135739976409

Epoch: 248| Step: 0
Training loss: 1.8910273604569623
Validation loss: 2.413595303382807

Epoch: 6| Step: 1
Training loss: 1.9208093185192412
Validation loss: 2.4404112503260103

Epoch: 6| Step: 2
Training loss: 1.3745246412303291
Validation loss: 2.406276603118049

Epoch: 6| Step: 3
Training loss: 2.3689676270372373
Validation loss: 2.3749544326046395

Epoch: 6| Step: 4
Training loss: 1.603931740076538
Validation loss: 2.3482402248351013

Epoch: 6| Step: 5
Training loss: 2.3956423697176557
Validation loss: 2.4381331491007536

Epoch: 6| Step: 6
Training loss: 1.606695889580492
Validation loss: 2.4140581417074265

Epoch: 6| Step: 7
Training loss: 2.14089474057511
Validation loss: 2.458471598490272

Epoch: 6| Step: 8
Training loss: 1.3583858003995222
Validation loss: 2.3637289527779473

Epoch: 6| Step: 9
Training loss: 2.298427757590034
Validation loss: 2.3950386266620427

Epoch: 6| Step: 10
Training loss: 1.9946803633777213
Validation loss: 2.387616454157058

Epoch: 6| Step: 11
Training loss: 1.3176625762755017
Validation loss: 2.416371877750926

Epoch: 6| Step: 12
Training loss: 2.0694062174680705
Validation loss: 2.420448348250766

Epoch: 6| Step: 13
Training loss: 1.4990140535638692
Validation loss: 2.411373360094708

Epoch: 249| Step: 0
Training loss: 1.9147973965871186
Validation loss: 2.4568323698233354

Epoch: 6| Step: 1
Training loss: 1.8663568284975134
Validation loss: 2.364515685139764

Epoch: 6| Step: 2
Training loss: 1.749281190658174
Validation loss: 2.4272868830576413

Epoch: 6| Step: 3
Training loss: 1.6287907621211635
Validation loss: 2.4035533640644298

Epoch: 6| Step: 4
Training loss: 1.9108554675881362
Validation loss: 2.422340361588648

Epoch: 6| Step: 5
Training loss: 1.9232188542882653
Validation loss: 2.4815624907866223

Epoch: 6| Step: 6
Training loss: 1.5685726415067138
Validation loss: 2.479253285701796

Epoch: 6| Step: 7
Training loss: 1.8553705771725753
Validation loss: 2.490099661117098

Epoch: 6| Step: 8
Training loss: 2.036868497189082
Validation loss: 2.463786717971169

Epoch: 6| Step: 9
Training loss: 1.201723000232847
Validation loss: 2.477037865472511

Epoch: 6| Step: 10
Training loss: 2.2467994178506356
Validation loss: 2.455925147960538

Epoch: 6| Step: 11
Training loss: 2.10526717712621
Validation loss: 2.4698895542082293

Epoch: 6| Step: 12
Training loss: 2.139489088301214
Validation loss: 2.407423534695134

Epoch: 6| Step: 13
Training loss: 2.299222200982799
Validation loss: 2.411737998859197

Epoch: 250| Step: 0
Training loss: 1.3932642376725144
Validation loss: 2.428573014624279

Epoch: 6| Step: 1
Training loss: 1.3742429643311742
Validation loss: 2.4015012066473713

Epoch: 6| Step: 2
Training loss: 1.8278037547024422
Validation loss: 2.3769195465558894

Epoch: 6| Step: 3
Training loss: 2.777818341488832
Validation loss: 2.447274675841848

Epoch: 6| Step: 4
Training loss: 2.0678070454772706
Validation loss: 2.4135508013729754

Epoch: 6| Step: 5
Training loss: 1.1476261620573311
Validation loss: 2.387073519815732

Epoch: 6| Step: 6
Training loss: 1.8193228327493676
Validation loss: 2.409446415130679

Epoch: 6| Step: 7
Training loss: 2.0868691639048866
Validation loss: 2.473597789629646

Epoch: 6| Step: 8
Training loss: 2.7291584063300616
Validation loss: 2.430668386798622

Epoch: 6| Step: 9
Training loss: 1.8626815502597922
Validation loss: 2.4147088377347194

Epoch: 6| Step: 10
Training loss: 1.692300256299308
Validation loss: 2.462980191355931

Epoch: 6| Step: 11
Training loss: 2.254695549181914
Validation loss: 2.4127245498473333

Epoch: 6| Step: 12
Training loss: 1.213885895637839
Validation loss: 2.406609591317257

Epoch: 6| Step: 13
Training loss: 1.3333235929053877
Validation loss: 2.4810302899741234

Epoch: 251| Step: 0
Training loss: 1.9277964604205649
Validation loss: 2.4226855808051613

Epoch: 6| Step: 1
Training loss: 1.4959562153758155
Validation loss: 2.4725733951160787

Epoch: 6| Step: 2
Training loss: 1.4406188633719794
Validation loss: 2.4759636242830996

Epoch: 6| Step: 3
Training loss: 1.9364370075738992
Validation loss: 2.4546107181074093

Epoch: 6| Step: 4
Training loss: 2.0894050494197556
Validation loss: 2.501563427806514

Epoch: 6| Step: 5
Training loss: 2.9665773171103353
Validation loss: 2.454677697835348

Epoch: 6| Step: 6
Training loss: 2.0099019262955133
Validation loss: 2.450045165867182

Epoch: 6| Step: 7
Training loss: 2.136434086278111
Validation loss: 2.41437544604407

Epoch: 6| Step: 8
Training loss: 2.181052050858362
Validation loss: 2.4808707298693626

Epoch: 6| Step: 9
Training loss: 1.3371090130327667
Validation loss: 2.465315053649245

Epoch: 6| Step: 10
Training loss: 2.049230486959454
Validation loss: 2.4033385275341637

Epoch: 6| Step: 11
Training loss: 1.1627630879484323
Validation loss: 2.4171290307177102

Epoch: 6| Step: 12
Training loss: 1.4771743394859795
Validation loss: 2.4421819878127846

Epoch: 6| Step: 13
Training loss: 1.592453897069357
Validation loss: 2.4662448565913015

Epoch: 252| Step: 0
Training loss: 1.589575292617773
Validation loss: 2.4151235249810825

Epoch: 6| Step: 1
Training loss: 2.5717885147700947
Validation loss: 2.4257414451935664

Epoch: 6| Step: 2
Training loss: 1.8295672995341767
Validation loss: 2.4804176920237637

Epoch: 6| Step: 3
Training loss: 1.7603901592117401
Validation loss: 2.4109229387802693

Epoch: 6| Step: 4
Training loss: 1.3327110547078749
Validation loss: 2.412190031141524

Epoch: 6| Step: 5
Training loss: 1.9293795814867556
Validation loss: 2.3648867908184235

Epoch: 6| Step: 6
Training loss: 1.5984180378404917
Validation loss: 2.392163406803403

Epoch: 6| Step: 7
Training loss: 1.88167540850888
Validation loss: 2.4117677069731087

Epoch: 6| Step: 8
Training loss: 2.725490238993103
Validation loss: 2.3381132887354856

Epoch: 6| Step: 9
Training loss: 1.5332650141768482
Validation loss: 2.4362363355783083

Epoch: 6| Step: 10
Training loss: 2.1116847073276874
Validation loss: 2.428570535508737

Epoch: 6| Step: 11
Training loss: 1.6560857439463967
Validation loss: 2.37230502592451

Epoch: 6| Step: 12
Training loss: 1.8164094658279664
Validation loss: 2.345658828969987

Epoch: 6| Step: 13
Training loss: 1.2485293797376882
Validation loss: 2.392170470255019

Epoch: 253| Step: 0
Training loss: 1.3618915109040566
Validation loss: 2.4397312382359506

Epoch: 6| Step: 1
Training loss: 1.9556098085461375
Validation loss: 2.401870381301739

Epoch: 6| Step: 2
Training loss: 1.741240787303731
Validation loss: 2.4301822431528612

Epoch: 6| Step: 3
Training loss: 2.10977779357373
Validation loss: 2.3938460725169826

Epoch: 6| Step: 4
Training loss: 2.6228544458630085
Validation loss: 2.4328304248407933

Epoch: 6| Step: 5
Training loss: 2.1011116083015557
Validation loss: 2.4904310324684693

Epoch: 6| Step: 6
Training loss: 1.6981333806880947
Validation loss: 2.4145327867047084

Epoch: 6| Step: 7
Training loss: 1.5623725076160042
Validation loss: 2.5405362919092696

Epoch: 6| Step: 8
Training loss: 2.0910892946067126
Validation loss: 2.4685477083940537

Epoch: 6| Step: 9
Training loss: 1.818340493994348
Validation loss: 2.461647356600092

Epoch: 6| Step: 10
Training loss: 1.7671883337691792
Validation loss: 2.5423438459313266

Epoch: 6| Step: 11
Training loss: 1.5711624350536162
Validation loss: 2.449299749957118

Epoch: 6| Step: 12
Training loss: 1.851718815510689
Validation loss: 2.4057979651898758

Epoch: 6| Step: 13
Training loss: 1.8205648746639345
Validation loss: 2.48022788740894

Epoch: 254| Step: 0
Training loss: 2.138999600318133
Validation loss: 2.466568508068667

Epoch: 6| Step: 1
Training loss: 1.4684349696171455
Validation loss: 2.420182658359688

Epoch: 6| Step: 2
Training loss: 1.7503225846656454
Validation loss: 2.446342241223665

Epoch: 6| Step: 3
Training loss: 2.237560855314955
Validation loss: 2.4038553050760734

Epoch: 6| Step: 4
Training loss: 1.5810367425344347
Validation loss: 2.394519454915495

Epoch: 6| Step: 5
Training loss: 1.341540271815692
Validation loss: 2.385224129619041

Epoch: 6| Step: 6
Training loss: 2.0059353257818366
Validation loss: 2.4169362055416013

Epoch: 6| Step: 7
Training loss: 1.8825259168646886
Validation loss: 2.3835436004172754

Epoch: 6| Step: 8
Training loss: 1.9617137816201768
Validation loss: 2.4162103294948

Epoch: 6| Step: 9
Training loss: 1.9813391824861002
Validation loss: 2.3786312488334844

Epoch: 6| Step: 10
Training loss: 1.6177420287380218
Validation loss: 2.386135533760028

Epoch: 6| Step: 11
Training loss: 2.0365450581249593
Validation loss: 2.4125469439104426

Epoch: 6| Step: 12
Training loss: 1.867647824545664
Validation loss: 2.4003545740595467

Epoch: 6| Step: 13
Training loss: 2.2286355523780657
Validation loss: 2.4213863042497525

Epoch: 255| Step: 0
Training loss: 1.8827746375617946
Validation loss: 2.43050017118467

Epoch: 6| Step: 1
Training loss: 1.7934957822564512
Validation loss: 2.3905594894716753

Epoch: 6| Step: 2
Training loss: 1.3951858138340933
Validation loss: 2.3899312630375302

Epoch: 6| Step: 3
Training loss: 1.1572455167224114
Validation loss: 2.474593421924822

Epoch: 6| Step: 4
Training loss: 2.0432250115628423
Validation loss: 2.45651780071635

Epoch: 6| Step: 5
Training loss: 1.7970273824016139
Validation loss: 2.4013021349769157

Epoch: 6| Step: 6
Training loss: 2.730264244006805
Validation loss: 2.447837846822743

Epoch: 6| Step: 7
Training loss: 1.9287088360352476
Validation loss: 2.4383386147976926

Epoch: 6| Step: 8
Training loss: 2.1850582118540167
Validation loss: 2.411003330505809

Epoch: 6| Step: 9
Training loss: 1.66228264556603
Validation loss: 2.4735000602129

Epoch: 6| Step: 10
Training loss: 1.8105680758686584
Validation loss: 2.387495651803816

Epoch: 6| Step: 11
Training loss: 1.9509197144718855
Validation loss: 2.446212400105026

Epoch: 6| Step: 12
Training loss: 1.5657277147783235
Validation loss: 2.478660832463122

Epoch: 6| Step: 13
Training loss: 1.7190737332724406
Validation loss: 2.439060601377189

Epoch: 256| Step: 0
Training loss: 1.4650229382590718
Validation loss: 2.411205996054946

Epoch: 6| Step: 1
Training loss: 1.7294869490145115
Validation loss: 2.39476885231787

Epoch: 6| Step: 2
Training loss: 1.9428300452947247
Validation loss: 2.374858406176756

Epoch: 6| Step: 3
Training loss: 1.8450284501856953
Validation loss: 2.3805354935948326

Epoch: 6| Step: 4
Training loss: 1.3983453048918038
Validation loss: 2.4187268276089786

Epoch: 6| Step: 5
Training loss: 2.299754303787273
Validation loss: 2.386198661944386

Epoch: 6| Step: 6
Training loss: 1.6898724867890018
Validation loss: 2.3879669439591327

Epoch: 6| Step: 7
Training loss: 2.87798403250776
Validation loss: 2.4330662110291863

Epoch: 6| Step: 8
Training loss: 2.4547586043444327
Validation loss: 2.43999447798579

Epoch: 6| Step: 9
Training loss: 1.9506381262301224
Validation loss: 2.384826744836108

Epoch: 6| Step: 10
Training loss: 1.9516819009531072
Validation loss: 2.403424771862578

Epoch: 6| Step: 11
Training loss: 1.1796887631441138
Validation loss: 2.422340966954551

Epoch: 6| Step: 12
Training loss: 1.8516785146687291
Validation loss: 2.461927167478772

Epoch: 6| Step: 13
Training loss: 1.5303617742830509
Validation loss: 2.4283055711856663

Epoch: 257| Step: 0
Training loss: 2.560643616921269
Validation loss: 2.4635105009244604

Epoch: 6| Step: 1
Training loss: 1.8221224844135935
Validation loss: 2.3766036968955584

Epoch: 6| Step: 2
Training loss: 1.7194722825390125
Validation loss: 2.4093569878241574

Epoch: 6| Step: 3
Training loss: 1.24072899754873
Validation loss: 2.4242122321635264

Epoch: 6| Step: 4
Training loss: 1.9302049939091865
Validation loss: 2.4576652328832553

Epoch: 6| Step: 5
Training loss: 2.325541451687771
Validation loss: 2.4510903627008855

Epoch: 6| Step: 6
Training loss: 1.4659662040676469
Validation loss: 2.415730546131445

Epoch: 6| Step: 7
Training loss: 2.028612507916529
Validation loss: 2.4511555403344207

Epoch: 6| Step: 8
Training loss: 1.8896894425864286
Validation loss: 2.343637111775411

Epoch: 6| Step: 9
Training loss: 1.9105695967648055
Validation loss: 2.43115861113942

Epoch: 6| Step: 10
Training loss: 1.6643470198556674
Validation loss: 2.422833581989909

Epoch: 6| Step: 11
Training loss: 1.7260043938095728
Validation loss: 2.3524424240377377

Epoch: 6| Step: 12
Training loss: 1.9271950010645773
Validation loss: 2.4260225188421933

Epoch: 6| Step: 13
Training loss: 1.3217844235385985
Validation loss: 2.406086572414451

Epoch: 258| Step: 0
Training loss: 1.7452234749214761
Validation loss: 2.4081296936943106

Epoch: 6| Step: 1
Training loss: 1.5413353881943237
Validation loss: 2.443851049821476

Epoch: 6| Step: 2
Training loss: 1.677131162478721
Validation loss: 2.4155955011075

Epoch: 6| Step: 3
Training loss: 1.8233299295555205
Validation loss: 2.438173972348836

Epoch: 6| Step: 4
Training loss: 1.6637991396828744
Validation loss: 2.418418590492182

Epoch: 6| Step: 5
Training loss: 1.3151831675554517
Validation loss: 2.4438816772464986

Epoch: 6| Step: 6
Training loss: 1.8524308884427805
Validation loss: 2.441325670188189

Epoch: 6| Step: 7
Training loss: 2.0850583627706127
Validation loss: 2.4265987918311644

Epoch: 6| Step: 8
Training loss: 2.290715372714979
Validation loss: 2.473825709744766

Epoch: 6| Step: 9
Training loss: 0.873784651717229
Validation loss: 2.452467619802275

Epoch: 6| Step: 10
Training loss: 2.604852560633784
Validation loss: 2.4850684862200336

Epoch: 6| Step: 11
Training loss: 2.337398416688392
Validation loss: 2.364582439243729

Epoch: 6| Step: 12
Training loss: 1.721827162616383
Validation loss: 2.437599995184075

Epoch: 6| Step: 13
Training loss: 1.753741760017032
Validation loss: 2.4622301224373184

Epoch: 259| Step: 0
Training loss: 1.929575804902527
Validation loss: 2.411937623379424

Epoch: 6| Step: 1
Training loss: 1.6483656881157174
Validation loss: 2.494753572666956

Epoch: 6| Step: 2
Training loss: 1.364455758263433
Validation loss: 2.4702655859258655

Epoch: 6| Step: 3
Training loss: 1.5339537125707445
Validation loss: 2.390670530360301

Epoch: 6| Step: 4
Training loss: 1.5580245965037096
Validation loss: 2.4528266657924496

Epoch: 6| Step: 5
Training loss: 1.914615162061498
Validation loss: 2.4105056677203174

Epoch: 6| Step: 6
Training loss: 2.405771579493821
Validation loss: 2.45713210561209

Epoch: 6| Step: 7
Training loss: 1.3247545446809965
Validation loss: 2.4103336476028137

Epoch: 6| Step: 8
Training loss: 2.699238005595663
Validation loss: 2.4357179049011384

Epoch: 6| Step: 9
Training loss: 1.4931336444079164
Validation loss: 2.4516600542966493

Epoch: 6| Step: 10
Training loss: 1.858972329527323
Validation loss: 2.4304698070707977

Epoch: 6| Step: 11
Training loss: 1.5908642242347244
Validation loss: 2.401524460766608

Epoch: 6| Step: 12
Training loss: 1.9688152726267316
Validation loss: 2.4002959819825764

Epoch: 6| Step: 13
Training loss: 2.0834229132148945
Validation loss: 2.4230152739160826

Epoch: 260| Step: 0
Training loss: 1.5063130725618765
Validation loss: 2.4437163812109146

Epoch: 6| Step: 1
Training loss: 1.8772578314631676
Validation loss: 2.4890415073838663

Epoch: 6| Step: 2
Training loss: 2.085678827484528
Validation loss: 2.4636799558590843

Epoch: 6| Step: 3
Training loss: 1.669357614944406
Validation loss: 2.486688355267675

Epoch: 6| Step: 4
Training loss: 1.9021178939815955
Validation loss: 2.4817838808041315

Epoch: 6| Step: 5
Training loss: 1.876534279286331
Validation loss: 2.441482005398098

Epoch: 6| Step: 6
Training loss: 1.6536075457448294
Validation loss: 2.4577315838303972

Epoch: 6| Step: 7
Training loss: 2.0319732552142526
Validation loss: 2.5091526137532827

Epoch: 6| Step: 8
Training loss: 1.7384118191832947
Validation loss: 2.416221881822083

Epoch: 6| Step: 9
Training loss: 2.4061694441353003
Validation loss: 2.4095842438520654

Epoch: 6| Step: 10
Training loss: 1.3935362955656074
Validation loss: 2.422438941104038

Epoch: 6| Step: 11
Training loss: 1.7030816028910527
Validation loss: 2.3495127426078555

Epoch: 6| Step: 12
Training loss: 2.2729183272773232
Validation loss: 2.4298966656077825

Epoch: 6| Step: 13
Training loss: 1.5437663274357183
Validation loss: 2.4030463193713785

Epoch: 261| Step: 0
Training loss: 1.4256503110358758
Validation loss: 2.4766275590072344

Epoch: 6| Step: 1
Training loss: 1.9229447403742732
Validation loss: 2.425446883697836

Epoch: 6| Step: 2
Training loss: 1.9983930688710347
Validation loss: 2.424561333949462

Epoch: 6| Step: 3
Training loss: 1.9922116147246074
Validation loss: 2.4384922304027543

Epoch: 6| Step: 4
Training loss: 2.123098644758928
Validation loss: 2.423754062823177

Epoch: 6| Step: 5
Training loss: 1.8880369900417713
Validation loss: 2.3789977325442577

Epoch: 6| Step: 6
Training loss: 1.7457052391724024
Validation loss: 2.4423375072010813

Epoch: 6| Step: 7
Training loss: 1.4197102091150857
Validation loss: 2.413394770719236

Epoch: 6| Step: 8
Training loss: 1.7734689583698018
Validation loss: 2.427232939357087

Epoch: 6| Step: 9
Training loss: 2.3269728299379713
Validation loss: 2.4241094300147004

Epoch: 6| Step: 10
Training loss: 1.7599118729765764
Validation loss: 2.5270478393192692

Epoch: 6| Step: 11
Training loss: 1.554625313440058
Validation loss: 2.4184788386497225

Epoch: 6| Step: 12
Training loss: 1.94372959923541
Validation loss: 2.4501890012071206

Epoch: 6| Step: 13
Training loss: 1.7727839404165426
Validation loss: 2.453056358002514

Epoch: 262| Step: 0
Training loss: 2.085663623903719
Validation loss: 2.4720423199242574

Epoch: 6| Step: 1
Training loss: 1.5564663166012798
Validation loss: 2.422846187301174

Epoch: 6| Step: 2
Training loss: 1.8221909159139464
Validation loss: 2.383503817864393

Epoch: 6| Step: 3
Training loss: 1.664172818104558
Validation loss: 2.411776269194339

Epoch: 6| Step: 4
Training loss: 2.0361466295244623
Validation loss: 2.3401265695609386

Epoch: 6| Step: 5
Training loss: 1.73934979117929
Validation loss: 2.3750946811872504

Epoch: 6| Step: 6
Training loss: 2.047758421373754
Validation loss: 2.4493585037611108

Epoch: 6| Step: 7
Training loss: 2.2129990095781884
Validation loss: 2.4567238346544915

Epoch: 6| Step: 8
Training loss: 1.8719292608939948
Validation loss: 2.443448991052523

Epoch: 6| Step: 9
Training loss: 1.3969850296277875
Validation loss: 2.381898004316784

Epoch: 6| Step: 10
Training loss: 1.6049371660714178
Validation loss: 2.4370936014719096

Epoch: 6| Step: 11
Training loss: 2.509128118510511
Validation loss: 2.4189802236971825

Epoch: 6| Step: 12
Training loss: 1.3866946795886304
Validation loss: 2.4109591932241043

Epoch: 6| Step: 13
Training loss: 1.5965069878649563
Validation loss: 2.432499298686467

Epoch: 263| Step: 0
Training loss: 1.7424941541445076
Validation loss: 2.403615427907575

Epoch: 6| Step: 1
Training loss: 1.7958811789715863
Validation loss: 2.459464618125642

Epoch: 6| Step: 2
Training loss: 1.7053257433583453
Validation loss: 2.5155709908685706

Epoch: 6| Step: 3
Training loss: 1.7952120840012717
Validation loss: 2.4295074857297423

Epoch: 6| Step: 4
Training loss: 1.9300221759134848
Validation loss: 2.452550493557044

Epoch: 6| Step: 5
Training loss: 1.7581975218525332
Validation loss: 2.4935025365846384

Epoch: 6| Step: 6
Training loss: 1.9747641603681962
Validation loss: 2.4702250314980283

Epoch: 6| Step: 7
Training loss: 2.2320542454160877
Validation loss: 2.5152800388509897

Epoch: 6| Step: 8
Training loss: 1.5160600490101275
Validation loss: 2.4510460979864273

Epoch: 6| Step: 9
Training loss: 1.8616398713389983
Validation loss: 2.4079502178735726

Epoch: 6| Step: 10
Training loss: 1.5446155885892974
Validation loss: 2.5167839541327215

Epoch: 6| Step: 11
Training loss: 2.311382745507119
Validation loss: 2.377675916701998

Epoch: 6| Step: 12
Training loss: 1.9680971546692723
Validation loss: 2.4226803502092302

Epoch: 6| Step: 13
Training loss: 1.6280506549049767
Validation loss: 2.443252325186393

Epoch: 264| Step: 0
Training loss: 2.2060539309773493
Validation loss: 2.369812066442147

Epoch: 6| Step: 1
Training loss: 2.0874429477958754
Validation loss: 2.37037672961041

Epoch: 6| Step: 2
Training loss: 1.9108844765319428
Validation loss: 2.4264398891107573

Epoch: 6| Step: 3
Training loss: 1.4176372214072135
Validation loss: 2.420913691806598

Epoch: 6| Step: 4
Training loss: 2.1867657110221805
Validation loss: 2.4618969452204373

Epoch: 6| Step: 5
Training loss: 1.973762066292677
Validation loss: 2.398820661619918

Epoch: 6| Step: 6
Training loss: 0.8221697898705926
Validation loss: 2.426010714129338

Epoch: 6| Step: 7
Training loss: 1.5844982362630844
Validation loss: 2.4188506074716374

Epoch: 6| Step: 8
Training loss: 1.8563401274202564
Validation loss: 2.395809835467643

Epoch: 6| Step: 9
Training loss: 2.312193566716641
Validation loss: 2.3837302756490284

Epoch: 6| Step: 10
Training loss: 1.7424001521177899
Validation loss: 2.4154579076683778

Epoch: 6| Step: 11
Training loss: 1.8794560569787568
Validation loss: 2.3865436532490705

Epoch: 6| Step: 12
Training loss: 2.0691369515952265
Validation loss: 2.460712877456914

Epoch: 6| Step: 13
Training loss: 1.0951731006764416
Validation loss: 2.411918544307492

Epoch: 265| Step: 0
Training loss: 1.6471339852750286
Validation loss: 2.4293050753542054

Epoch: 6| Step: 1
Training loss: 1.7044819317165247
Validation loss: 2.472936198160217

Epoch: 6| Step: 2
Training loss: 1.9328067295293623
Validation loss: 2.4578518212559977

Epoch: 6| Step: 3
Training loss: 2.6324023371564516
Validation loss: 2.460426533005205

Epoch: 6| Step: 4
Training loss: 1.4876100323155426
Validation loss: 2.4422232273011444

Epoch: 6| Step: 5
Training loss: 1.351126098739653
Validation loss: 2.4561393938959792

Epoch: 6| Step: 6
Training loss: 1.6789170028320881
Validation loss: 2.335900837353356

Epoch: 6| Step: 7
Training loss: 1.7057240803960625
Validation loss: 2.440968895637922

Epoch: 6| Step: 8
Training loss: 1.5235874982495714
Validation loss: 2.396977259514318

Epoch: 6| Step: 9
Training loss: 2.109584656645347
Validation loss: 2.4655144692569393

Epoch: 6| Step: 10
Training loss: 1.0875865024934264
Validation loss: 2.4539270907450756

Epoch: 6| Step: 11
Training loss: 2.006406655538432
Validation loss: 2.4462980058704002

Epoch: 6| Step: 12
Training loss: 2.1152327969898317
Validation loss: 2.490707404908658

Epoch: 6| Step: 13
Training loss: 1.660585738332787
Validation loss: 2.4245914892164833

Epoch: 266| Step: 0
Training loss: 1.436363351331316
Validation loss: 2.3793779888091366

Epoch: 6| Step: 1
Training loss: 1.251265124020935
Validation loss: 2.398410843066432

Epoch: 6| Step: 2
Training loss: 2.476515904899801
Validation loss: 2.4158765634927577

Epoch: 6| Step: 3
Training loss: 1.8470192067087912
Validation loss: 2.4693430900394713

Epoch: 6| Step: 4
Training loss: 1.9210824960671409
Validation loss: 2.4450288521776575

Epoch: 6| Step: 5
Training loss: 1.8974064040188434
Validation loss: 2.4359797029568186

Epoch: 6| Step: 6
Training loss: 1.8365058181633145
Validation loss: 2.4759942070368424

Epoch: 6| Step: 7
Training loss: 1.6539172172633243
Validation loss: 2.387784994929769

Epoch: 6| Step: 8
Training loss: 1.8619738456454418
Validation loss: 2.3648975642912213

Epoch: 6| Step: 9
Training loss: 1.8328709741811084
Validation loss: 2.41137924885021

Epoch: 6| Step: 10
Training loss: 1.2770991193201244
Validation loss: 2.4327987536153572

Epoch: 6| Step: 11
Training loss: 1.6901221918478158
Validation loss: 2.4141186409863793

Epoch: 6| Step: 12
Training loss: 2.3442336537101536
Validation loss: 2.41611175633684

Epoch: 6| Step: 13
Training loss: 1.7550461087595592
Validation loss: 2.377124276772522

Epoch: 267| Step: 0
Training loss: 1.2669436331828168
Validation loss: 2.410554823490252

Epoch: 6| Step: 1
Training loss: 2.257834780890008
Validation loss: 2.487284349321925

Epoch: 6| Step: 2
Training loss: 1.7558870748301738
Validation loss: 2.3932541324126912

Epoch: 6| Step: 3
Training loss: 1.7969581916458695
Validation loss: 2.4851555160917145

Epoch: 6| Step: 4
Training loss: 2.2500199211086427
Validation loss: 2.445370332689976

Epoch: 6| Step: 5
Training loss: 1.9035678191752736
Validation loss: 2.4717269172544234

Epoch: 6| Step: 6
Training loss: 1.5937963740763883
Validation loss: 2.454565012887634

Epoch: 6| Step: 7
Training loss: 1.9330449722355294
Validation loss: 2.397365939823294

Epoch: 6| Step: 8
Training loss: 1.8404611252272896
Validation loss: 2.4720422260708954

Epoch: 6| Step: 9
Training loss: 1.7676042923650097
Validation loss: 2.441305128534167

Epoch: 6| Step: 10
Training loss: 1.255199870269652
Validation loss: 2.4329322483826488

Epoch: 6| Step: 11
Training loss: 1.9701568178993971
Validation loss: 2.475000589419755

Epoch: 6| Step: 12
Training loss: 1.7530957496637238
Validation loss: 2.5103051238226093

Epoch: 6| Step: 13
Training loss: 2.1540768494564575
Validation loss: 2.46533909668018

Epoch: 268| Step: 0
Training loss: 1.8646543549663228
Validation loss: 2.4421789252129122

Epoch: 6| Step: 1
Training loss: 1.476865061283773
Validation loss: 2.3774796814198713

Epoch: 6| Step: 2
Training loss: 1.8473224620662116
Validation loss: 2.4673574275786785

Epoch: 6| Step: 3
Training loss: 1.6844175938473946
Validation loss: 2.444427205221045

Epoch: 6| Step: 4
Training loss: 1.2358972362031522
Validation loss: 2.387604701147309

Epoch: 6| Step: 5
Training loss: 1.7861018441478798
Validation loss: 2.4047009047374543

Epoch: 6| Step: 6
Training loss: 1.4971817084646108
Validation loss: 2.392656162471826

Epoch: 6| Step: 7
Training loss: 1.9768142841384972
Validation loss: 2.423772230593999

Epoch: 6| Step: 8
Training loss: 2.0202463090502003
Validation loss: 2.4106315755298335

Epoch: 6| Step: 9
Training loss: 1.6237735521636183
Validation loss: 2.467179084817565

Epoch: 6| Step: 10
Training loss: 1.8889709046578242
Validation loss: 2.4598731121296904

Epoch: 6| Step: 11
Training loss: 2.2078162493609796
Validation loss: 2.505119382698005

Epoch: 6| Step: 12
Training loss: 1.8323232584780367
Validation loss: 2.4985892571089847

Epoch: 6| Step: 13
Training loss: 2.8776201664866754
Validation loss: 2.4441332615122113

Epoch: 269| Step: 0
Training loss: 1.2238768313712411
Validation loss: 2.4790188604069914

Epoch: 6| Step: 1
Training loss: 1.7923557671440133
Validation loss: 2.426218597489869

Epoch: 6| Step: 2
Training loss: 1.8205724047663427
Validation loss: 2.408318914906864

Epoch: 6| Step: 3
Training loss: 1.5363507852791485
Validation loss: 2.456562660822843

Epoch: 6| Step: 4
Training loss: 1.593145068683133
Validation loss: 2.379049761321744

Epoch: 6| Step: 5
Training loss: 2.490301680309809
Validation loss: 2.395794709167596

Epoch: 6| Step: 6
Training loss: 2.6582228570860216
Validation loss: 2.4208052575973364

Epoch: 6| Step: 7
Training loss: 1.602927096459958
Validation loss: 2.3824619443512107

Epoch: 6| Step: 8
Training loss: 1.5154097099378765
Validation loss: 2.3991791855452904

Epoch: 6| Step: 9
Training loss: 2.045527706379138
Validation loss: 2.42401091314663

Epoch: 6| Step: 10
Training loss: 1.6667657663764874
Validation loss: 2.4495915164247113

Epoch: 6| Step: 11
Training loss: 2.066539392346449
Validation loss: 2.3912837030996674

Epoch: 6| Step: 12
Training loss: 1.8063494803413305
Validation loss: 2.394542223862338

Epoch: 6| Step: 13
Training loss: 1.0661898103386291
Validation loss: 2.4248385977094347

Epoch: 270| Step: 0
Training loss: 2.477597763334453
Validation loss: 2.4201682256854893

Epoch: 6| Step: 1
Training loss: 1.3001672710496677
Validation loss: 2.4257157372233156

Epoch: 6| Step: 2
Training loss: 1.9070504180932548
Validation loss: 2.3685332373535615

Epoch: 6| Step: 3
Training loss: 2.081026618585635
Validation loss: 2.4375487975564982

Epoch: 6| Step: 4
Training loss: 1.6407427790917515
Validation loss: 2.4330960749187414

Epoch: 6| Step: 5
Training loss: 1.8970738289461837
Validation loss: 2.424126247271987

Epoch: 6| Step: 6
Training loss: 1.0959393523727874
Validation loss: 2.378391077198215

Epoch: 6| Step: 7
Training loss: 1.7199900228743281
Validation loss: 2.4242259734736162

Epoch: 6| Step: 8
Training loss: 1.9297733673883057
Validation loss: 2.4578819201107

Epoch: 6| Step: 9
Training loss: 1.4326643672733543
Validation loss: 2.4407064069594635

Epoch: 6| Step: 10
Training loss: 1.7629346352207484
Validation loss: 2.4511778909154853

Epoch: 6| Step: 11
Training loss: 1.952966180066152
Validation loss: 2.47034281309479

Epoch: 6| Step: 12
Training loss: 1.9553565742606316
Validation loss: 2.4317841183536224

Epoch: 6| Step: 13
Training loss: 1.593680810361451
Validation loss: 2.4423386439899786

Epoch: 271| Step: 0
Training loss: 1.5285532813401939
Validation loss: 2.48041060908188

Epoch: 6| Step: 1
Training loss: 1.2544691301959177
Validation loss: 2.4680683674230877

Epoch: 6| Step: 2
Training loss: 1.205982431571621
Validation loss: 2.4255002667712526

Epoch: 6| Step: 3
Training loss: 2.346069612229621
Validation loss: 2.4298674924936536

Epoch: 6| Step: 4
Training loss: 1.649811158789065
Validation loss: 2.4202374572481435

Epoch: 6| Step: 5
Training loss: 1.9970674472778958
Validation loss: 2.413896455598758

Epoch: 6| Step: 6
Training loss: 1.6955616851358095
Validation loss: 2.4067037149581414

Epoch: 6| Step: 7
Training loss: 1.9293737117761798
Validation loss: 2.406352002235635

Epoch: 6| Step: 8
Training loss: 1.3948647663921463
Validation loss: 2.3963955514254254

Epoch: 6| Step: 9
Training loss: 2.5478777637355345
Validation loss: 2.487476389412132

Epoch: 6| Step: 10
Training loss: 1.5374025794698256
Validation loss: 2.4245439561317723

Epoch: 6| Step: 11
Training loss: 2.338625990629509
Validation loss: 2.4134252933610756

Epoch: 6| Step: 12
Training loss: 1.9742904692327004
Validation loss: 2.406058298632291

Epoch: 6| Step: 13
Training loss: 1.1366275606578584
Validation loss: 2.4200305151076957

Epoch: 272| Step: 0
Training loss: 2.2856227822380375
Validation loss: 2.4362500964082496

Epoch: 6| Step: 1
Training loss: 1.55016416480181
Validation loss: 2.3617426371713

Epoch: 6| Step: 2
Training loss: 1.561551072935961
Validation loss: 2.408552574871285

Epoch: 6| Step: 3
Training loss: 1.5187944131016544
Validation loss: 2.4722744503851457

Epoch: 6| Step: 4
Training loss: 1.6682256639221305
Validation loss: 2.3860767107086702

Epoch: 6| Step: 5
Training loss: 1.9241905839154188
Validation loss: 2.415394594265715

Epoch: 6| Step: 6
Training loss: 1.6270707947674874
Validation loss: 2.4014762346526872

Epoch: 6| Step: 7
Training loss: 2.2364431559866924
Validation loss: 2.429899497336207

Epoch: 6| Step: 8
Training loss: 1.7872281061139597
Validation loss: 2.389525359330639

Epoch: 6| Step: 9
Training loss: 1.8650179592628062
Validation loss: 2.4094029568982123

Epoch: 6| Step: 10
Training loss: 1.4235956868315631
Validation loss: 2.461970733612377

Epoch: 6| Step: 11
Training loss: 1.614398707837135
Validation loss: 2.390177598621437

Epoch: 6| Step: 12
Training loss: 1.7126583694404522
Validation loss: 2.379443932703522

Epoch: 6| Step: 13
Training loss: 2.3983097601556724
Validation loss: 2.4114771027863213

Epoch: 273| Step: 0
Training loss: 1.7550782363928923
Validation loss: 2.4079811464880594

Epoch: 6| Step: 1
Training loss: 1.670841931759343
Validation loss: 2.5112509508980034

Epoch: 6| Step: 2
Training loss: 2.396286686560227
Validation loss: 2.4519535797725713

Epoch: 6| Step: 3
Training loss: 1.564486423476194
Validation loss: 2.48229906119101

Epoch: 6| Step: 4
Training loss: 1.7229139347200826
Validation loss: 2.443858798371264

Epoch: 6| Step: 5
Training loss: 1.612569508791734
Validation loss: 2.47428000845314

Epoch: 6| Step: 6
Training loss: 1.6038820171058508
Validation loss: 2.4581678705721326

Epoch: 6| Step: 7
Training loss: 1.5522619140433191
Validation loss: 2.4586509320759915

Epoch: 6| Step: 8
Training loss: 1.45625640474802
Validation loss: 2.42363683133716

Epoch: 6| Step: 9
Training loss: 1.8423510270989654
Validation loss: 2.412300932386699

Epoch: 6| Step: 10
Training loss: 2.0380062714649623
Validation loss: 2.390598558363721

Epoch: 6| Step: 11
Training loss: 1.9219697138080214
Validation loss: 2.371550127433971

Epoch: 6| Step: 12
Training loss: 2.4041217458176654
Validation loss: 2.400919087481722

Epoch: 6| Step: 13
Training loss: 1.521715883557238
Validation loss: 2.407910299832004

Epoch: 274| Step: 0
Training loss: 1.2592017989408737
Validation loss: 2.3976482816309876

Epoch: 6| Step: 1
Training loss: 1.4777342975565007
Validation loss: 2.424087419451853

Epoch: 6| Step: 2
Training loss: 1.6993089673877106
Validation loss: 2.4243490453548526

Epoch: 6| Step: 3
Training loss: 1.7797012288382066
Validation loss: 2.4194770164471837

Epoch: 6| Step: 4
Training loss: 1.6094535141838822
Validation loss: 2.364935674450981

Epoch: 6| Step: 5
Training loss: 2.1036333849857285
Validation loss: 2.447102449550085

Epoch: 6| Step: 6
Training loss: 1.5420422826726552
Validation loss: 2.4021395411329984

Epoch: 6| Step: 7
Training loss: 1.7575460274368235
Validation loss: 2.392012063242428

Epoch: 6| Step: 8
Training loss: 1.7096759203499685
Validation loss: 2.4203149148483103

Epoch: 6| Step: 9
Training loss: 1.5633385506212794
Validation loss: 2.436727408199452

Epoch: 6| Step: 10
Training loss: 2.1739760740098846
Validation loss: 2.4287883264733208

Epoch: 6| Step: 11
Training loss: 1.2950258055071031
Validation loss: 2.4138792027912253

Epoch: 6| Step: 12
Training loss: 2.4333772272131244
Validation loss: 2.419694241674982

Epoch: 6| Step: 13
Training loss: 2.523415391193299
Validation loss: 2.3984317472837224

Epoch: 275| Step: 0
Training loss: 1.7898547155143418
Validation loss: 2.39729771840518

Epoch: 6| Step: 1
Training loss: 1.3392831057568533
Validation loss: 2.434237774826091

Epoch: 6| Step: 2
Training loss: 1.9541955074088053
Validation loss: 2.3734877585600347

Epoch: 6| Step: 3
Training loss: 1.9204391450146474
Validation loss: 2.4512612723682103

Epoch: 6| Step: 4
Training loss: 1.6305951846735343
Validation loss: 2.3871779125949986

Epoch: 6| Step: 5
Training loss: 2.1617294570442622
Validation loss: 2.371590154285303

Epoch: 6| Step: 6
Training loss: 1.4690172479862111
Validation loss: 2.4009564977443207

Epoch: 6| Step: 7
Training loss: 2.7618320986783904
Validation loss: 2.4247694013059373

Epoch: 6| Step: 8
Training loss: 1.5825172713845328
Validation loss: 2.4246034705429103

Epoch: 6| Step: 9
Training loss: 1.2175104244185386
Validation loss: 2.42523796380066

Epoch: 6| Step: 10
Training loss: 1.9571884000807496
Validation loss: 2.4277841703150336

Epoch: 6| Step: 11
Training loss: 1.4482019358396137
Validation loss: 2.414555097776191

Epoch: 6| Step: 12
Training loss: 1.863163014625232
Validation loss: 2.3798599345409546

Epoch: 6| Step: 13
Training loss: 1.5733437958197058
Validation loss: 2.3792081079274716

Epoch: 276| Step: 0
Training loss: 1.604677251172047
Validation loss: 2.4236197938403206

Epoch: 6| Step: 1
Training loss: 1.6837298344889229
Validation loss: 2.364072591563268

Epoch: 6| Step: 2
Training loss: 1.7696886140017243
Validation loss: 2.425870320716935

Epoch: 6| Step: 3
Training loss: 2.0723482307846406
Validation loss: 2.407908481367313

Epoch: 6| Step: 4
Training loss: 2.6713993474528994
Validation loss: 2.480247828139618

Epoch: 6| Step: 5
Training loss: 1.842812898068824
Validation loss: 2.4588926321113367

Epoch: 6| Step: 6
Training loss: 1.2685666219547826
Validation loss: 2.468749173404238

Epoch: 6| Step: 7
Training loss: 1.6904748197686863
Validation loss: 2.415714930643156

Epoch: 6| Step: 8
Training loss: 1.8305068190780285
Validation loss: 2.4709181345440943

Epoch: 6| Step: 9
Training loss: 1.5760549433372317
Validation loss: 2.435060930448458

Epoch: 6| Step: 10
Training loss: 1.8791671222875117
Validation loss: 2.466383441866091

Epoch: 6| Step: 11
Training loss: 1.6803183147322007
Validation loss: 2.4539331176660544

Epoch: 6| Step: 12
Training loss: 1.3833820441681874
Validation loss: 2.4065325235137345

Epoch: 6| Step: 13
Training loss: 1.0929680890401023
Validation loss: 2.4545709975092906

Epoch: 277| Step: 0
Training loss: 1.723131110035576
Validation loss: 2.3598155513780594

Epoch: 6| Step: 1
Training loss: 1.1920689475133601
Validation loss: 2.4095052501828094

Epoch: 6| Step: 2
Training loss: 1.7457078340833498
Validation loss: 2.4127049085293715

Epoch: 6| Step: 3
Training loss: 1.3267893189533646
Validation loss: 2.3432951061198826

Epoch: 6| Step: 4
Training loss: 1.5865110666181794
Validation loss: 2.36923003160107

Epoch: 6| Step: 5
Training loss: 1.6378881242015624
Validation loss: 2.507315049816337

Epoch: 6| Step: 6
Training loss: 1.9615514637586633
Validation loss: 2.350314273625632

Epoch: 6| Step: 7
Training loss: 1.536054430960787
Validation loss: 2.396392988741472

Epoch: 6| Step: 8
Training loss: 1.8007654946521316
Validation loss: 2.3827345549047823

Epoch: 6| Step: 9
Training loss: 2.6730852564991605
Validation loss: 2.3963074017606845

Epoch: 6| Step: 10
Training loss: 1.9757498778254228
Validation loss: 2.4284379827998

Epoch: 6| Step: 11
Training loss: 1.6479449508046584
Validation loss: 2.3545726724036546

Epoch: 6| Step: 12
Training loss: 1.6692822754021932
Validation loss: 2.4397689549336974

Epoch: 6| Step: 13
Training loss: 1.89296250037257
Validation loss: 2.405435039780152

Epoch: 278| Step: 0
Training loss: 1.7085821931899032
Validation loss: 2.4106008197059694

Epoch: 6| Step: 1
Training loss: 2.1840567601202587
Validation loss: 2.454550874291569

Epoch: 6| Step: 2
Training loss: 1.7030093652509148
Validation loss: 2.388926099226843

Epoch: 6| Step: 3
Training loss: 1.5459193350559652
Validation loss: 2.4516868558566176

Epoch: 6| Step: 4
Training loss: 1.7362965429671364
Validation loss: 2.418018081662505

Epoch: 6| Step: 5
Training loss: 1.7881098047202169
Validation loss: 2.4023954118972495

Epoch: 6| Step: 6
Training loss: 1.632476699102
Validation loss: 2.4114027707713044

Epoch: 6| Step: 7
Training loss: 1.410372054475878
Validation loss: 2.430065039044483

Epoch: 6| Step: 8
Training loss: 2.3803680388602193
Validation loss: 2.3916579938350204

Epoch: 6| Step: 9
Training loss: 1.7836659427290371
Validation loss: 2.3700017703193246

Epoch: 6| Step: 10
Training loss: 1.9738150941383512
Validation loss: 2.4057643737540553

Epoch: 6| Step: 11
Training loss: 1.3151038544405829
Validation loss: 2.3794977789741614

Epoch: 6| Step: 12
Training loss: 1.8781674651614968
Validation loss: 2.491512513077862

Epoch: 6| Step: 13
Training loss: 1.2682815269403178
Validation loss: 2.362428113294343

Epoch: 279| Step: 0
Training loss: 1.3858191782644593
Validation loss: 2.485918510400938

Epoch: 6| Step: 1
Training loss: 1.4550748479409406
Validation loss: 2.4157110889702986

Epoch: 6| Step: 2
Training loss: 1.391084059478315
Validation loss: 2.4679595587370002

Epoch: 6| Step: 3
Training loss: 1.9333491623438759
Validation loss: 2.3915872757120242

Epoch: 6| Step: 4
Training loss: 1.874991480490085
Validation loss: 2.4236788644779605

Epoch: 6| Step: 5
Training loss: 2.1206524075401787
Validation loss: 2.3872962536147284

Epoch: 6| Step: 6
Training loss: 1.9074399392207921
Validation loss: 2.3716342437914384

Epoch: 6| Step: 7
Training loss: 1.4675236715977802
Validation loss: 2.430542783884303

Epoch: 6| Step: 8
Training loss: 1.876148825604531
Validation loss: 2.3904148293332

Epoch: 6| Step: 9
Training loss: 1.9397884513110815
Validation loss: 2.39321055903783

Epoch: 6| Step: 10
Training loss: 1.7662444251877587
Validation loss: 2.3993211241965837

Epoch: 6| Step: 11
Training loss: 1.5714462514601089
Validation loss: 2.475362204047975

Epoch: 6| Step: 12
Training loss: 1.6659020656866677
Validation loss: 2.462500982605521

Epoch: 6| Step: 13
Training loss: 1.9148843052031193
Validation loss: 2.4525799526892373

Epoch: 280| Step: 0
Training loss: 1.6363345767340434
Validation loss: 2.4648733089649424

Epoch: 6| Step: 1
Training loss: 2.5498344218033613
Validation loss: 2.3919662840443814

Epoch: 6| Step: 2
Training loss: 1.4264377702415996
Validation loss: 2.400783492283689

Epoch: 6| Step: 3
Training loss: 1.9945267052305435
Validation loss: 2.4688886928268756

Epoch: 6| Step: 4
Training loss: 1.9300105639153768
Validation loss: 2.379010102440179

Epoch: 6| Step: 5
Training loss: 1.7650144078258296
Validation loss: 2.4283065160658945

Epoch: 6| Step: 6
Training loss: 1.8998352682076631
Validation loss: 2.4620148695951896

Epoch: 6| Step: 7
Training loss: 1.5562970441578758
Validation loss: 2.4011803182292812

Epoch: 6| Step: 8
Training loss: 1.1239865294494364
Validation loss: 2.422475277186476

Epoch: 6| Step: 9
Training loss: 1.5440374994714896
Validation loss: 2.4062228415034883

Epoch: 6| Step: 10
Training loss: 1.871671519738844
Validation loss: 2.3615590264419697

Epoch: 6| Step: 11
Training loss: 1.6197677152606655
Validation loss: 2.42331534011854

Epoch: 6| Step: 12
Training loss: 1.870487122761345
Validation loss: 2.3917690239189335

Epoch: 6| Step: 13
Training loss: 0.6098425611972584
Validation loss: 2.3585878202779997

Epoch: 281| Step: 0
Training loss: 1.8460917714576919
Validation loss: 2.379632390397444

Epoch: 6| Step: 1
Training loss: 1.7999659614523507
Validation loss: 2.390342460320376

Epoch: 6| Step: 2
Training loss: 1.8347905898593644
Validation loss: 2.3926965696488423

Epoch: 6| Step: 3
Training loss: 1.7349572106617352
Validation loss: 2.413047023930918

Epoch: 6| Step: 4
Training loss: 1.3878720068333696
Validation loss: 2.473458613565724

Epoch: 6| Step: 5
Training loss: 2.2575755275456992
Validation loss: 2.415231637911582

Epoch: 6| Step: 6
Training loss: 1.355388627996045
Validation loss: 2.4312108501797036

Epoch: 6| Step: 7
Training loss: 1.7547487134438262
Validation loss: 2.4099969870272298

Epoch: 6| Step: 8
Training loss: 1.711291690204333
Validation loss: 2.423511279723165

Epoch: 6| Step: 9
Training loss: 1.8099744235386686
Validation loss: 2.4408781403359545

Epoch: 6| Step: 10
Training loss: 1.6314489338324394
Validation loss: 2.4288716163227257

Epoch: 6| Step: 11
Training loss: 1.661308911658899
Validation loss: 2.4174841013520054

Epoch: 6| Step: 12
Training loss: 1.3443227035445242
Validation loss: 2.4188607375829427

Epoch: 6| Step: 13
Training loss: 2.7624490034134497
Validation loss: 2.3623070001210387

Epoch: 282| Step: 0
Training loss: 1.4848325325398555
Validation loss: 2.4236357661665644

Epoch: 6| Step: 1
Training loss: 1.9509915105262523
Validation loss: 2.36696933675241

Epoch: 6| Step: 2
Training loss: 1.9044994383450835
Validation loss: 2.4980936678223453

Epoch: 6| Step: 3
Training loss: 1.9667411728124196
Validation loss: 2.473072693896413

Epoch: 6| Step: 4
Training loss: 1.8637635188696577
Validation loss: 2.4639184198835933

Epoch: 6| Step: 5
Training loss: 1.7823837419987467
Validation loss: 2.4772721315501376

Epoch: 6| Step: 6
Training loss: 1.5448269628023783
Validation loss: 2.4686854291607445

Epoch: 6| Step: 7
Training loss: 1.728116195132018
Validation loss: 2.5052873166943335

Epoch: 6| Step: 8
Training loss: 1.7889562183777956
Validation loss: 2.451170396120045

Epoch: 6| Step: 9
Training loss: 1.1644573182162006
Validation loss: 2.413559607412568

Epoch: 6| Step: 10
Training loss: 1.581809624112657
Validation loss: 2.415319139903148

Epoch: 6| Step: 11
Training loss: 2.1727491856148715
Validation loss: 2.402947477721711

Epoch: 6| Step: 12
Training loss: 1.3667812070687158
Validation loss: 2.459189725875126

Epoch: 6| Step: 13
Training loss: 1.7050298135561608
Validation loss: 2.4488437922490474

Epoch: 283| Step: 0
Training loss: 1.5368028502343043
Validation loss: 2.4406227699506884

Epoch: 6| Step: 1
Training loss: 1.6140260616594964
Validation loss: 2.3878519402400413

Epoch: 6| Step: 2
Training loss: 1.764864462384338
Validation loss: 2.4395656662361316

Epoch: 6| Step: 3
Training loss: 1.981333165875133
Validation loss: 2.383178159999075

Epoch: 6| Step: 4
Training loss: 1.5581659862943764
Validation loss: 2.4257461428795515

Epoch: 6| Step: 5
Training loss: 1.6760089426143485
Validation loss: 2.421077172121614

Epoch: 6| Step: 6
Training loss: 1.697513118912309
Validation loss: 2.4209883025658017

Epoch: 6| Step: 7
Training loss: 1.876778331481259
Validation loss: 2.436361754403363

Epoch: 6| Step: 8
Training loss: 2.031766620375089
Validation loss: 2.414178506912771

Epoch: 6| Step: 9
Training loss: 1.390645487773719
Validation loss: 2.4035870770604193

Epoch: 6| Step: 10
Training loss: 1.715295545286066
Validation loss: 2.4074446428471346

Epoch: 6| Step: 11
Training loss: 2.658536756937598
Validation loss: 2.4637772808786225

Epoch: 6| Step: 12
Training loss: 1.3268069739564705
Validation loss: 2.442374552811073

Epoch: 6| Step: 13
Training loss: 1.4212760082807552
Validation loss: 2.39376448342535

Epoch: 284| Step: 0
Training loss: 1.9478282058403311
Validation loss: 2.3839584935440246

Epoch: 6| Step: 1
Training loss: 1.5052835870254362
Validation loss: 2.4207325982939345

Epoch: 6| Step: 2
Training loss: 1.5713120500911322
Validation loss: 2.396710731028476

Epoch: 6| Step: 3
Training loss: 1.7500208444716323
Validation loss: 2.4163379643666794

Epoch: 6| Step: 4
Training loss: 1.4158278768313415
Validation loss: 2.365120992554987

Epoch: 6| Step: 5
Training loss: 1.0187698385729236
Validation loss: 2.398409728212481

Epoch: 6| Step: 6
Training loss: 1.9439235155969914
Validation loss: 2.410933822082369

Epoch: 6| Step: 7
Training loss: 1.4266897155260556
Validation loss: 2.452612645794165

Epoch: 6| Step: 8
Training loss: 2.097653522170014
Validation loss: 2.431959889836629

Epoch: 6| Step: 9
Training loss: 2.014290064465928
Validation loss: 2.37958496925177

Epoch: 6| Step: 10
Training loss: 1.6240985277241455
Validation loss: 2.4165916056392276

Epoch: 6| Step: 11
Training loss: 2.2175083178307218
Validation loss: 2.3958371596196577

Epoch: 6| Step: 12
Training loss: 1.7074927223463778
Validation loss: 2.424485572730786

Epoch: 6| Step: 13
Training loss: 1.88439893564993
Validation loss: 2.4110282458247654

Epoch: 285| Step: 0
Training loss: 1.809333798165052
Validation loss: 2.47549987191595

Epoch: 6| Step: 1
Training loss: 1.1914369672974088
Validation loss: 2.3986697605413636

Epoch: 6| Step: 2
Training loss: 2.327325978232069
Validation loss: 2.4036716625155625

Epoch: 6| Step: 3
Training loss: 1.691655728660262
Validation loss: 2.426581871270704

Epoch: 6| Step: 4
Training loss: 1.5007921352517952
Validation loss: 2.4928822805996322

Epoch: 6| Step: 5
Training loss: 1.4238101241199645
Validation loss: 2.4902825643825914

Epoch: 6| Step: 6
Training loss: 2.157891353682876
Validation loss: 2.4180401135455285

Epoch: 6| Step: 7
Training loss: 1.6088787906434026
Validation loss: 2.444327484087793

Epoch: 6| Step: 8
Training loss: 1.7954689827526216
Validation loss: 2.433840719216213

Epoch: 6| Step: 9
Training loss: 1.6326233238618753
Validation loss: 2.392828365429866

Epoch: 6| Step: 10
Training loss: 1.3858835203373872
Validation loss: 2.425193050165221

Epoch: 6| Step: 11
Training loss: 1.436104304241984
Validation loss: 2.428989847433543

Epoch: 6| Step: 12
Training loss: 1.1658007553180598
Validation loss: 2.3990588639053123

Epoch: 6| Step: 13
Training loss: 2.846103239501748
Validation loss: 2.411165016047076

Epoch: 286| Step: 0
Training loss: 1.7529488650152218
Validation loss: 2.436166708396502

Epoch: 6| Step: 1
Training loss: 2.1121288266916847
Validation loss: 2.462541001085101

Epoch: 6| Step: 2
Training loss: 1.8885948062861266
Validation loss: 2.401419079646383

Epoch: 6| Step: 3
Training loss: 1.3762319421233138
Validation loss: 2.469817471152834

Epoch: 6| Step: 4
Training loss: 2.4377873569224207
Validation loss: 2.3945026925626083

Epoch: 6| Step: 5
Training loss: 1.7435390549911112
Validation loss: 2.453414901952477

Epoch: 6| Step: 6
Training loss: 1.7778390718198616
Validation loss: 2.4562478004188337

Epoch: 6| Step: 7
Training loss: 1.238904296858065
Validation loss: 2.3987006180431147

Epoch: 6| Step: 8
Training loss: 1.4802318373372618
Validation loss: 2.448318862776222

Epoch: 6| Step: 9
Training loss: 1.8723031040056102
Validation loss: 2.412108624648217

Epoch: 6| Step: 10
Training loss: 1.2189544115061572
Validation loss: 2.4077153085180902

Epoch: 6| Step: 11
Training loss: 1.947314109696042
Validation loss: 2.472677568511826

Epoch: 6| Step: 12
Training loss: 1.9371603391158305
Validation loss: 2.4734312094144983

Epoch: 6| Step: 13
Training loss: 1.5154904964580729
Validation loss: 2.4394899233145546

Epoch: 287| Step: 0
Training loss: 1.3635908502150347
Validation loss: 2.4103283678665144

Epoch: 6| Step: 1
Training loss: 2.024787364203772
Validation loss: 2.3381823096836305

Epoch: 6| Step: 2
Training loss: 1.6560452892542026
Validation loss: 2.3893075565232125

Epoch: 6| Step: 3
Training loss: 1.5332351584034183
Validation loss: 2.35987813434194

Epoch: 6| Step: 4
Training loss: 1.8183837626754744
Validation loss: 2.3475446394864914

Epoch: 6| Step: 5
Training loss: 1.6740343641174436
Validation loss: 2.428270334808636

Epoch: 6| Step: 6
Training loss: 1.6860427215521336
Validation loss: 2.39210084542391

Epoch: 6| Step: 7
Training loss: 2.216000102025935
Validation loss: 2.377309523618852

Epoch: 6| Step: 8
Training loss: 1.55612576153461
Validation loss: 2.4072825593980607

Epoch: 6| Step: 9
Training loss: 1.866840090813179
Validation loss: 2.39767653162525

Epoch: 6| Step: 10
Training loss: 2.1727814463757276
Validation loss: 2.4173112749662966

Epoch: 6| Step: 11
Training loss: 1.4832638245630634
Validation loss: 2.396709452796883

Epoch: 6| Step: 12
Training loss: 1.502369757162846
Validation loss: 2.432769048360466

Epoch: 6| Step: 13
Training loss: 1.8955588788362037
Validation loss: 2.4549439620916766

Epoch: 288| Step: 0
Training loss: 1.9850391868355408
Validation loss: 2.3859143586750338

Epoch: 6| Step: 1
Training loss: 1.7646265498262126
Validation loss: 2.4247021055421003

Epoch: 6| Step: 2
Training loss: 1.8907523624617755
Validation loss: 2.4244921243457327

Epoch: 6| Step: 3
Training loss: 1.557488453487011
Validation loss: 2.4381699789032423

Epoch: 6| Step: 4
Training loss: 1.5739181648075318
Validation loss: 2.4495374903900013

Epoch: 6| Step: 5
Training loss: 1.8543566774312294
Validation loss: 2.483340578866307

Epoch: 6| Step: 6
Training loss: 2.15364448027624
Validation loss: 2.4728393974153904

Epoch: 6| Step: 7
Training loss: 1.3701712175565988
Validation loss: 2.4290610771622365

Epoch: 6| Step: 8
Training loss: 2.04665635666544
Validation loss: 2.431866971422129

Epoch: 6| Step: 9
Training loss: 1.6899330119112161
Validation loss: 2.454612159404399

Epoch: 6| Step: 10
Training loss: 1.73624944347705
Validation loss: 2.424870312640457

Epoch: 6| Step: 11
Training loss: 1.8040783667448965
Validation loss: 2.448252709615704

Epoch: 6| Step: 12
Training loss: 0.9801049032312259
Validation loss: 2.400029020386085

Epoch: 6| Step: 13
Training loss: 1.7627026840436235
Validation loss: 2.4810756822868822

Epoch: 289| Step: 0
Training loss: 1.6178964728582625
Validation loss: 2.4558933215240275

Epoch: 6| Step: 1
Training loss: 1.714385021262479
Validation loss: 2.3924752376317033

Epoch: 6| Step: 2
Training loss: 1.69099354279028
Validation loss: 2.374797223020906

Epoch: 6| Step: 3
Training loss: 1.5260189779458921
Validation loss: 2.3852965131255

Epoch: 6| Step: 4
Training loss: 1.6200167467876487
Validation loss: 2.3779317994925457

Epoch: 6| Step: 5
Training loss: 1.3734132107093897
Validation loss: 2.3896463455180377

Epoch: 6| Step: 6
Training loss: 1.7624424972352406
Validation loss: 2.4076937502116973

Epoch: 6| Step: 7
Training loss: 2.2051460248901584
Validation loss: 2.431775404137874

Epoch: 6| Step: 8
Training loss: 1.5171048519987034
Validation loss: 2.4138255011118375

Epoch: 6| Step: 9
Training loss: 1.6649865105801362
Validation loss: 2.3589307191115894

Epoch: 6| Step: 10
Training loss: 2.220966253066336
Validation loss: 2.433597028297491

Epoch: 6| Step: 11
Training loss: 1.720852346369133
Validation loss: 2.3817931051147085

Epoch: 6| Step: 12
Training loss: 2.0770847326928887
Validation loss: 2.437608302602402

Epoch: 6| Step: 13
Training loss: 1.6814024221537833
Validation loss: 2.4152969032895015

Epoch: 290| Step: 0
Training loss: 1.4443709322163552
Validation loss: 2.420165129931868

Epoch: 6| Step: 1
Training loss: 1.2290812101668884
Validation loss: 2.4561812971857866

Epoch: 6| Step: 2
Training loss: 2.344451087361708
Validation loss: 2.425550579342859

Epoch: 6| Step: 3
Training loss: 1.6062149578383622
Validation loss: 2.3822048338355613

Epoch: 6| Step: 4
Training loss: 2.05139046475743
Validation loss: 2.3903854365900736

Epoch: 6| Step: 5
Training loss: 1.7230304475951213
Validation loss: 2.4233473172421682

Epoch: 6| Step: 6
Training loss: 1.679685725721265
Validation loss: 2.3761534488643634

Epoch: 6| Step: 7
Training loss: 1.7628557887693708
Validation loss: 2.4201537886880677

Epoch: 6| Step: 8
Training loss: 1.277650382191854
Validation loss: 2.4320873970406596

Epoch: 6| Step: 9
Training loss: 1.7247720816598047
Validation loss: 2.3721701116365783

Epoch: 6| Step: 10
Training loss: 1.8756398063057462
Validation loss: 2.408777676570469

Epoch: 6| Step: 11
Training loss: 1.609801300771716
Validation loss: 2.4205377751344956

Epoch: 6| Step: 12
Training loss: 1.8498342955326985
Validation loss: 2.4379292434351516

Epoch: 6| Step: 13
Training loss: 1.4473951026975973
Validation loss: 2.39492578174864

Epoch: 291| Step: 0
Training loss: 1.8074802736337665
Validation loss: 2.4489577098139783

Epoch: 6| Step: 1
Training loss: 1.8450191461660332
Validation loss: 2.4405287359468626

Epoch: 6| Step: 2
Training loss: 2.1808479528795908
Validation loss: 2.4834221093209803

Epoch: 6| Step: 3
Training loss: 1.8550149141724894
Validation loss: 2.3927570513684513

Epoch: 6| Step: 4
Training loss: 1.6877875612871196
Validation loss: 2.4257651290475453

Epoch: 6| Step: 5
Training loss: 1.5557560148201022
Validation loss: 2.4683939836862274

Epoch: 6| Step: 6
Training loss: 1.4116112132404557
Validation loss: 2.376927729545528

Epoch: 6| Step: 7
Training loss: 1.2307296234185976
Validation loss: 2.4468440983839335

Epoch: 6| Step: 8
Training loss: 1.2880448919759833
Validation loss: 2.435255116519842

Epoch: 6| Step: 9
Training loss: 1.947362409537629
Validation loss: 2.39161400441337

Epoch: 6| Step: 10
Training loss: 2.1415225187048854
Validation loss: 2.4192994267260493

Epoch: 6| Step: 11
Training loss: 1.501808189274458
Validation loss: 2.432249593523467

Epoch: 6| Step: 12
Training loss: 1.414747546425576
Validation loss: 2.431929161288449

Epoch: 6| Step: 13
Training loss: 1.2610945914545373
Validation loss: 2.443921992219671

Epoch: 292| Step: 0
Training loss: 1.459673656152155
Validation loss: 2.5086543445391416

Epoch: 6| Step: 1
Training loss: 1.3176852388833447
Validation loss: 2.456801326276493

Epoch: 6| Step: 2
Training loss: 1.6545989246093324
Validation loss: 2.4792967252326505

Epoch: 6| Step: 3
Training loss: 1.4479596614171641
Validation loss: 2.423258026307495

Epoch: 6| Step: 4
Training loss: 1.7282653972304602
Validation loss: 2.413990981165641

Epoch: 6| Step: 5
Training loss: 1.621376693116515
Validation loss: 2.4110377942186347

Epoch: 6| Step: 6
Training loss: 2.030179137608312
Validation loss: 2.4450380664785167

Epoch: 6| Step: 7
Training loss: 1.3662866730929089
Validation loss: 2.4792451116226295

Epoch: 6| Step: 8
Training loss: 1.7879626629022474
Validation loss: 2.4472291258835157

Epoch: 6| Step: 9
Training loss: 1.5816862507215
Validation loss: 2.440402896772804

Epoch: 6| Step: 10
Training loss: 2.5357558095437276
Validation loss: 2.4011827439482234

Epoch: 6| Step: 11
Training loss: 1.5390786107183425
Validation loss: 2.4412020165121255

Epoch: 6| Step: 12
Training loss: 2.0651570169453635
Validation loss: 2.4397005602834985

Epoch: 6| Step: 13
Training loss: 1.4761545737979573
Validation loss: 2.4444320463361455

Epoch: 293| Step: 0
Training loss: 1.7257421970050109
Validation loss: 2.4367653260449

Epoch: 6| Step: 1
Training loss: 1.6944264852200899
Validation loss: 2.379365922510966

Epoch: 6| Step: 2
Training loss: 2.03573641131622
Validation loss: 2.420747247881266

Epoch: 6| Step: 3
Training loss: 1.4047024582860965
Validation loss: 2.470662522240743

Epoch: 6| Step: 4
Training loss: 1.3107554330896918
Validation loss: 2.4563915277353137

Epoch: 6| Step: 5
Training loss: 1.7430361746242056
Validation loss: 2.4786944992312847

Epoch: 6| Step: 6
Training loss: 1.758285119840519
Validation loss: 2.5188253085443284

Epoch: 6| Step: 7
Training loss: 1.8897805337792084
Validation loss: 2.471197524372576

Epoch: 6| Step: 8
Training loss: 1.8034812562083231
Validation loss: 2.4418796683759223

Epoch: 6| Step: 9
Training loss: 1.4393385035351445
Validation loss: 2.4886013288832847

Epoch: 6| Step: 10
Training loss: 1.448568028367825
Validation loss: 2.455074038965404

Epoch: 6| Step: 11
Training loss: 1.938319740389884
Validation loss: 2.427445625250509

Epoch: 6| Step: 12
Training loss: 1.6584134636821473
Validation loss: 2.406205256663642

Epoch: 6| Step: 13
Training loss: 2.0940840725057264
Validation loss: 2.462766017967152

Epoch: 294| Step: 0
Training loss: 1.3645783732472125
Validation loss: 2.344048267103667

Epoch: 6| Step: 1
Training loss: 1.990168187591625
Validation loss: 2.3771989996048606

Epoch: 6| Step: 2
Training loss: 1.542570193036789
Validation loss: 2.381709089749627

Epoch: 6| Step: 3
Training loss: 1.5706078550508826
Validation loss: 2.422375453511244

Epoch: 6| Step: 4
Training loss: 1.811430187858541
Validation loss: 2.422704656564789

Epoch: 6| Step: 5
Training loss: 1.4066773083285806
Validation loss: 2.3980926268930713

Epoch: 6| Step: 6
Training loss: 1.595837590914924
Validation loss: 2.464569353185291

Epoch: 6| Step: 7
Training loss: 2.001604390357407
Validation loss: 2.380768347335764

Epoch: 6| Step: 8
Training loss: 2.1592744265596107
Validation loss: 2.475511737334535

Epoch: 6| Step: 9
Training loss: 1.6577319586745358
Validation loss: 2.515975464051438

Epoch: 6| Step: 10
Training loss: 1.6115578227616054
Validation loss: 2.4119927254427687

Epoch: 6| Step: 11
Training loss: 1.5965590311827713
Validation loss: 2.411892549759132

Epoch: 6| Step: 12
Training loss: 2.2436921391159292
Validation loss: 2.4996393610160963

Epoch: 6| Step: 13
Training loss: 1.9170778151445647
Validation loss: 2.4607661132720335

Epoch: 295| Step: 0
Training loss: 1.7734042933375835
Validation loss: 2.450231351010159

Epoch: 6| Step: 1
Training loss: 1.8466947929131676
Validation loss: 2.4965635733703095

Epoch: 6| Step: 2
Training loss: 2.0146336446303126
Validation loss: 2.461269468648605

Epoch: 6| Step: 3
Training loss: 1.7007931485896663
Validation loss: 2.442514432631306

Epoch: 6| Step: 4
Training loss: 1.7471725237795899
Validation loss: 2.4788350246855

Epoch: 6| Step: 5
Training loss: 1.5479447490186478
Validation loss: 2.4403316372383976

Epoch: 6| Step: 6
Training loss: 1.477572948120194
Validation loss: 2.417625711841666

Epoch: 6| Step: 7
Training loss: 1.7854547230223023
Validation loss: 2.3634353499315783

Epoch: 6| Step: 8
Training loss: 2.134683870947133
Validation loss: 2.4749412686682133

Epoch: 6| Step: 9
Training loss: 1.4601036588893779
Validation loss: 2.400788281518878

Epoch: 6| Step: 10
Training loss: 1.7647190977050518
Validation loss: 2.406646125915891

Epoch: 6| Step: 11
Training loss: 1.5247376200606044
Validation loss: 2.3771051760371678

Epoch: 6| Step: 12
Training loss: 1.4719222690904934
Validation loss: 2.444262917303422

Epoch: 6| Step: 13
Training loss: 1.1971779024182045
Validation loss: 2.4091450514206296

Epoch: 296| Step: 0
Training loss: 2.0603571076715834
Validation loss: 2.3830722376112536

Epoch: 6| Step: 1
Training loss: 1.4440079033442492
Validation loss: 2.44011661692145

Epoch: 6| Step: 2
Training loss: 2.062088202779522
Validation loss: 2.371658394466274

Epoch: 6| Step: 3
Training loss: 2.1105205674749685
Validation loss: 2.3832438330866297

Epoch: 6| Step: 4
Training loss: 1.8492333292738945
Validation loss: 2.3870016734954924

Epoch: 6| Step: 5
Training loss: 2.233217379658131
Validation loss: 2.430633882900244

Epoch: 6| Step: 6
Training loss: 1.2870864981903325
Validation loss: 2.3931340618885018

Epoch: 6| Step: 7
Training loss: 1.394898182014245
Validation loss: 2.373098255895747

Epoch: 6| Step: 8
Training loss: 1.4005792934955412
Validation loss: 2.367957768895017

Epoch: 6| Step: 9
Training loss: 1.6277192179388649
Validation loss: 2.335504337846129

Epoch: 6| Step: 10
Training loss: 1.272073213845436
Validation loss: 2.454453984542876

Epoch: 6| Step: 11
Training loss: 1.8807012980771591
Validation loss: 2.3759525107464805

Epoch: 6| Step: 12
Training loss: 1.3265501671027953
Validation loss: 2.330255023362146

Epoch: 6| Step: 13
Training loss: 1.5470647213891047
Validation loss: 2.470855416367643

Epoch: 297| Step: 0
Training loss: 1.3358338075963394
Validation loss: 2.4060005172653787

Epoch: 6| Step: 1
Training loss: 1.0606682639438663
Validation loss: 2.369602027471287

Epoch: 6| Step: 2
Training loss: 1.4821506900547545
Validation loss: 2.3781539816264985

Epoch: 6| Step: 3
Training loss: 1.7556419025719705
Validation loss: 2.382300370978133

Epoch: 6| Step: 4
Training loss: 1.9289269435015128
Validation loss: 2.4074171719704958

Epoch: 6| Step: 5
Training loss: 1.242522668305513
Validation loss: 2.4054662863565737

Epoch: 6| Step: 6
Training loss: 1.0621368124063575
Validation loss: 2.468304099659385

Epoch: 6| Step: 7
Training loss: 1.6960248022065323
Validation loss: 2.4443407211114985

Epoch: 6| Step: 8
Training loss: 1.308232636231337
Validation loss: 2.4611234882088913

Epoch: 6| Step: 9
Training loss: 2.390034322133078
Validation loss: 2.44713863522613

Epoch: 6| Step: 10
Training loss: 2.4698557248624344
Validation loss: 2.42170970404269

Epoch: 6| Step: 11
Training loss: 1.6443020259914063
Validation loss: 2.3705824899022856

Epoch: 6| Step: 12
Training loss: 1.4750734925145566
Validation loss: 2.373395591065072

Epoch: 6| Step: 13
Training loss: 1.2759932164965562
Validation loss: 2.395235719197984

Epoch: 298| Step: 0
Training loss: 1.539642534507189
Validation loss: 2.368485930609112

Epoch: 6| Step: 1
Training loss: 1.7896778098034383
Validation loss: 2.4179389675187544

Epoch: 6| Step: 2
Training loss: 1.3769829929440145
Validation loss: 2.4103425483568928

Epoch: 6| Step: 3
Training loss: 1.3490771335835818
Validation loss: 2.433057606772405

Epoch: 6| Step: 4
Training loss: 1.3329968127121705
Validation loss: 2.452513771780707

Epoch: 6| Step: 5
Training loss: 1.6648511853313845
Validation loss: 2.391638988806216

Epoch: 6| Step: 6
Training loss: 1.6466766643349369
Validation loss: 2.3843838421206027

Epoch: 6| Step: 7
Training loss: 1.958980358724385
Validation loss: 2.4018608348884145

Epoch: 6| Step: 8
Training loss: 2.139669608878027
Validation loss: 2.3945280889830065

Epoch: 6| Step: 9
Training loss: 2.515514868937802
Validation loss: 2.351685169985827

Epoch: 6| Step: 10
Training loss: 1.4710034878065097
Validation loss: 2.422666517593609

Epoch: 6| Step: 11
Training loss: 1.4156790076726053
Validation loss: 2.4210594447450053

Epoch: 6| Step: 12
Training loss: 1.2947384803673463
Validation loss: 2.427963806588542

Epoch: 6| Step: 13
Training loss: 1.8111469216827154
Validation loss: 2.3776679993721395

Epoch: 299| Step: 0
Training loss: 1.2454119404490083
Validation loss: 2.417617095048411

Epoch: 6| Step: 1
Training loss: 1.6854399363165287
Validation loss: 2.464579967865091

Epoch: 6| Step: 2
Training loss: 1.7213997962278749
Validation loss: 2.48586097752599

Epoch: 6| Step: 3
Training loss: 1.3406210554727354
Validation loss: 2.3967202305676025

Epoch: 6| Step: 4
Training loss: 1.4981632112890477
Validation loss: 2.4425067669329943

Epoch: 6| Step: 5
Training loss: 1.5225636641497655
Validation loss: 2.432791634250695

Epoch: 6| Step: 6
Training loss: 1.7181898418026325
Validation loss: 2.4806238217852603

Epoch: 6| Step: 7
Training loss: 1.174245242938614
Validation loss: 2.366875560969292

Epoch: 6| Step: 8
Training loss: 1.805043899551776
Validation loss: 2.4522404619735583

Epoch: 6| Step: 9
Training loss: 1.3939681425572823
Validation loss: 2.4384005744244304

Epoch: 6| Step: 10
Training loss: 2.782460067339093
Validation loss: 2.397504522378005

Epoch: 6| Step: 11
Training loss: 1.4813382054073398
Validation loss: 2.416002263558206

Epoch: 6| Step: 12
Training loss: 1.9644681598105438
Validation loss: 2.3522466459430786

Epoch: 6| Step: 13
Training loss: 1.8039649739047583
Validation loss: 2.36651651094444

Epoch: 300| Step: 0
Training loss: 1.5085038887810835
Validation loss: 2.3456510401922266

Epoch: 6| Step: 1
Training loss: 1.7538429707621828
Validation loss: 2.428792152739234

Epoch: 6| Step: 2
Training loss: 1.6535733024329962
Validation loss: 2.4295211200601154

Epoch: 6| Step: 3
Training loss: 1.9596602699165435
Validation loss: 2.4256496826074074

Epoch: 6| Step: 4
Training loss: 1.8127642471791057
Validation loss: 2.405057710000337

Epoch: 6| Step: 5
Training loss: 1.4985951361611496
Validation loss: 2.383022353575596

Epoch: 6| Step: 6
Training loss: 1.7517316289096028
Validation loss: 2.390933263642092

Epoch: 6| Step: 7
Training loss: 2.186542192304559
Validation loss: 2.417556459568206

Epoch: 6| Step: 8
Training loss: 1.6968704307873996
Validation loss: 2.370845209896426

Epoch: 6| Step: 9
Training loss: 2.2712933368988715
Validation loss: 2.3710445189390583

Epoch: 6| Step: 10
Training loss: 1.2782710264771875
Validation loss: 2.4397902329716796

Epoch: 6| Step: 11
Training loss: 1.076049797763489
Validation loss: 2.3490463628513685

Epoch: 6| Step: 12
Training loss: 1.408132945519595
Validation loss: 2.3496669665087646

Epoch: 6| Step: 13
Training loss: 1.8554954767811935
Validation loss: 2.4300006492799895

Epoch: 301| Step: 0
Training loss: 1.4463837648613582
Validation loss: 2.411859111233926

Epoch: 6| Step: 1
Training loss: 1.5352356091824813
Validation loss: 2.360084579652675

Epoch: 6| Step: 2
Training loss: 1.1297088198938572
Validation loss: 2.4515776285924424

Epoch: 6| Step: 3
Training loss: 2.253149900682391
Validation loss: 2.4334522923132385

Epoch: 6| Step: 4
Training loss: 1.713806464268823
Validation loss: 2.4670093444128223

Epoch: 6| Step: 5
Training loss: 1.8737416177247856
Validation loss: 2.434864360418816

Epoch: 6| Step: 6
Training loss: 1.8933814266078388
Validation loss: 2.3798042371343153

Epoch: 6| Step: 7
Training loss: 1.8532666440098247
Validation loss: 2.394864569607103

Epoch: 6| Step: 8
Training loss: 1.4704861221203385
Validation loss: 2.415405340668706

Epoch: 6| Step: 9
Training loss: 0.9671612601965326
Validation loss: 2.4664756357818334

Epoch: 6| Step: 10
Training loss: 1.8070856319545099
Validation loss: 2.4126110455791765

Epoch: 6| Step: 11
Training loss: 1.566412338283056
Validation loss: 2.4007253821355037

Epoch: 6| Step: 12
Training loss: 1.7135165907427008
Validation loss: 2.4100354849912073

Epoch: 6| Step: 13
Training loss: 2.6531481414971876
Validation loss: 2.4058144256001

Epoch: 302| Step: 0
Training loss: 1.749030662193691
Validation loss: 2.465546882712715

Epoch: 6| Step: 1
Training loss: 1.7587153172004748
Validation loss: 2.423946698886819

Epoch: 6| Step: 2
Training loss: 1.7976375786094734
Validation loss: 2.378730971549449

Epoch: 6| Step: 3
Training loss: 1.5038246826246626
Validation loss: 2.4476122336727792

Epoch: 6| Step: 4
Training loss: 1.5260949065867142
Validation loss: 2.415583600864583

Epoch: 6| Step: 5
Training loss: 1.556854960811474
Validation loss: 2.4230030165224936

Epoch: 6| Step: 6
Training loss: 0.9177396772547606
Validation loss: 2.4501516939355708

Epoch: 6| Step: 7
Training loss: 1.9748754727664655
Validation loss: 2.45975806899028

Epoch: 6| Step: 8
Training loss: 1.818604548035727
Validation loss: 2.3854413348072967

Epoch: 6| Step: 9
Training loss: 1.3639100818752825
Validation loss: 2.378548836053621

Epoch: 6| Step: 10
Training loss: 2.1491516036232636
Validation loss: 2.414874025827866

Epoch: 6| Step: 11
Training loss: 1.5980995514551288
Validation loss: 2.3759207201071373

Epoch: 6| Step: 12
Training loss: 1.8583120946426008
Validation loss: 2.3560669048909992

Epoch: 6| Step: 13
Training loss: 1.4245881405652856
Validation loss: 2.401349004486239

Epoch: 303| Step: 0
Training loss: 1.2361342050535784
Validation loss: 2.356835334714183

Epoch: 6| Step: 1
Training loss: 2.040241236915275
Validation loss: 2.3475886826194023

Epoch: 6| Step: 2
Training loss: 1.343573625211788
Validation loss: 2.433350867701169

Epoch: 6| Step: 3
Training loss: 1.9332136917365035
Validation loss: 2.367057924268678

Epoch: 6| Step: 4
Training loss: 1.6757623275719984
Validation loss: 2.4090858670421147

Epoch: 6| Step: 5
Training loss: 1.5393894061375886
Validation loss: 2.3451418850258055

Epoch: 6| Step: 6
Training loss: 1.6845298342057056
Validation loss: 2.3981351644158773

Epoch: 6| Step: 7
Training loss: 1.172251373885723
Validation loss: 2.409245429663421

Epoch: 6| Step: 8
Training loss: 1.4857662707969879
Validation loss: 2.4225251552049065

Epoch: 6| Step: 9
Training loss: 1.384810216963182
Validation loss: 2.453653172508633

Epoch: 6| Step: 10
Training loss: 1.8400608590676102
Validation loss: 2.4391727718434084

Epoch: 6| Step: 11
Training loss: 2.3395695342565346
Validation loss: 2.39020940664309

Epoch: 6| Step: 12
Training loss: 1.6804468611919257
Validation loss: 2.3950587254102205

Epoch: 6| Step: 13
Training loss: 1.3464280876167471
Validation loss: 2.3930890861800522

Epoch: 304| Step: 0
Training loss: 1.838566752002386
Validation loss: 2.449314407663279

Epoch: 6| Step: 1
Training loss: 1.9579179472052146
Validation loss: 2.414282189592359

Epoch: 6| Step: 2
Training loss: 1.6261757485212769
Validation loss: 2.4280789270830017

Epoch: 6| Step: 3
Training loss: 1.480641780192985
Validation loss: 2.4214570276585907

Epoch: 6| Step: 4
Training loss: 1.4334533788992019
Validation loss: 2.4313205147693435

Epoch: 6| Step: 5
Training loss: 1.706815727822267
Validation loss: 2.378714326958291

Epoch: 6| Step: 6
Training loss: 1.2167510242916364
Validation loss: 2.474032132268313

Epoch: 6| Step: 7
Training loss: 1.876892533450651
Validation loss: 2.364543117759261

Epoch: 6| Step: 8
Training loss: 2.475402945652923
Validation loss: 2.408341980248809

Epoch: 6| Step: 9
Training loss: 1.566633935681126
Validation loss: 2.3725648441160656

Epoch: 6| Step: 10
Training loss: 1.351492995751705
Validation loss: 2.3986940622466015

Epoch: 6| Step: 11
Training loss: 1.2218209237622948
Validation loss: 2.413990263258515

Epoch: 6| Step: 12
Training loss: 1.360196796932524
Validation loss: 2.417679798855447

Epoch: 6| Step: 13
Training loss: 1.7213384384229282
Validation loss: 2.3109465017439255

Epoch: 305| Step: 0
Training loss: 1.8069005830709255
Validation loss: 2.3494738126941317

Epoch: 6| Step: 1
Training loss: 1.4621616885146407
Validation loss: 2.3477832581769498

Epoch: 6| Step: 2
Training loss: 2.336839686675559
Validation loss: 2.4016596810873914

Epoch: 6| Step: 3
Training loss: 2.131983781162429
Validation loss: 2.4459082860422856

Epoch: 6| Step: 4
Training loss: 1.670850493358034
Validation loss: 2.336945385492007

Epoch: 6| Step: 5
Training loss: 1.3480662731100341
Validation loss: 2.4517109541102675

Epoch: 6| Step: 6
Training loss: 1.327818936255826
Validation loss: 2.420695400461516

Epoch: 6| Step: 7
Training loss: 1.5018012040669249
Validation loss: 2.4138799791436627

Epoch: 6| Step: 8
Training loss: 1.618961264473829
Validation loss: 2.380309591865569

Epoch: 6| Step: 9
Training loss: 1.013468521683209
Validation loss: 2.441086475193739

Epoch: 6| Step: 10
Training loss: 1.561771680842323
Validation loss: 2.4259620390278323

Epoch: 6| Step: 11
Training loss: 1.5419306486097455
Validation loss: 2.4329802155624427

Epoch: 6| Step: 12
Training loss: 1.6519886834770703
Validation loss: 2.3655601183602935

Epoch: 6| Step: 13
Training loss: 1.6847293856053465
Validation loss: 2.431659703254604

Epoch: 306| Step: 0
Training loss: 1.3001079477828221
Validation loss: 2.4380083240335737

Epoch: 6| Step: 1
Training loss: 1.5483163611087847
Validation loss: 2.4576855611287045

Epoch: 6| Step: 2
Training loss: 1.7237259707252512
Validation loss: 2.4780176112114547

Epoch: 6| Step: 3
Training loss: 1.3858497583253575
Validation loss: 2.463625169563451

Epoch: 6| Step: 4
Training loss: 1.7508627263609384
Validation loss: 2.40627512940676

Epoch: 6| Step: 5
Training loss: 2.4148220608001636
Validation loss: 2.415614024743626

Epoch: 6| Step: 6
Training loss: 1.6231513879134403
Validation loss: 2.446224636570344

Epoch: 6| Step: 7
Training loss: 1.4595838180891112
Validation loss: 2.3258005135785678

Epoch: 6| Step: 8
Training loss: 1.5192242388227415
Validation loss: 2.3611352248129704

Epoch: 6| Step: 9
Training loss: 1.5559431976256946
Validation loss: 2.4070001619968786

Epoch: 6| Step: 10
Training loss: 1.8626726544123977
Validation loss: 2.3819944443693744

Epoch: 6| Step: 11
Training loss: 1.8039474621373355
Validation loss: 2.433894114627981

Epoch: 6| Step: 12
Training loss: 2.048552080873649
Validation loss: 2.4314687505466472

Epoch: 6| Step: 13
Training loss: 1.2203647480230935
Validation loss: 2.372219310152018

Epoch: 307| Step: 0
Training loss: 1.276550606680368
Validation loss: 2.382364590252844

Epoch: 6| Step: 1
Training loss: 1.6268928947153356
Validation loss: 2.41679452070643

Epoch: 6| Step: 2
Training loss: 1.5718937594012918
Validation loss: 2.362181651928314

Epoch: 6| Step: 3
Training loss: 1.4403757272731907
Validation loss: 2.420262743572578

Epoch: 6| Step: 4
Training loss: 1.205677248315532
Validation loss: 2.406831699521151

Epoch: 6| Step: 5
Training loss: 1.403301453911645
Validation loss: 2.365341679289069

Epoch: 6| Step: 6
Training loss: 1.5696862333650698
Validation loss: 2.3502180858148765

Epoch: 6| Step: 7
Training loss: 2.006855183529976
Validation loss: 2.376420900501588

Epoch: 6| Step: 8
Training loss: 1.6316508125935096
Validation loss: 2.376898926634474

Epoch: 6| Step: 9
Training loss: 1.8670114729518046
Validation loss: 2.426190817725896

Epoch: 6| Step: 10
Training loss: 1.2988606154888283
Validation loss: 2.422642865881279

Epoch: 6| Step: 11
Training loss: 2.4447193340387563
Validation loss: 2.4327511095366106

Epoch: 6| Step: 12
Training loss: 1.438179270264517
Validation loss: 2.4486850605126147

Epoch: 6| Step: 13
Training loss: 0.9907446755885349
Validation loss: 2.4192021202096776

Epoch: 308| Step: 0
Training loss: 1.522429695322683
Validation loss: 2.4353873323989235

Epoch: 6| Step: 1
Training loss: 1.4801944689959299
Validation loss: 2.449891291021641

Epoch: 6| Step: 2
Training loss: 2.1246638312622594
Validation loss: 2.3651449875324313

Epoch: 6| Step: 3
Training loss: 1.3375882663301137
Validation loss: 2.3622270750156718

Epoch: 6| Step: 4
Training loss: 1.257571511254483
Validation loss: 2.313660167931033

Epoch: 6| Step: 5
Training loss: 1.5909652316108545
Validation loss: 2.4178346008294924

Epoch: 6| Step: 6
Training loss: 1.4403489119300728
Validation loss: 2.3694073869995638

Epoch: 6| Step: 7
Training loss: 1.7892670493652119
Validation loss: 2.4629452418371915

Epoch: 6| Step: 8
Training loss: 1.9725785343989064
Validation loss: 2.3702349012423376

Epoch: 6| Step: 9
Training loss: 1.9043350607148988
Validation loss: 2.445323164197595

Epoch: 6| Step: 10
Training loss: 1.213485056112009
Validation loss: 2.3987133084923324

Epoch: 6| Step: 11
Training loss: 1.8568721563470894
Validation loss: 2.356676656450025

Epoch: 6| Step: 12
Training loss: 1.7635313465997886
Validation loss: 2.3785513527552444

Epoch: 6| Step: 13
Training loss: 1.7639132954401604
Validation loss: 2.3579959676199906

Epoch: 309| Step: 0
Training loss: 1.6407421978461731
Validation loss: 2.374738101303324

Epoch: 6| Step: 1
Training loss: 1.0017168089830428
Validation loss: 2.422187439410471

Epoch: 6| Step: 2
Training loss: 1.72629679711047
Validation loss: 2.357038965214326

Epoch: 6| Step: 3
Training loss: 2.144709345192025
Validation loss: 2.3489985425158935

Epoch: 6| Step: 4
Training loss: 0.9608087841139007
Validation loss: 2.3541342968738546

Epoch: 6| Step: 5
Training loss: 1.975134412803067
Validation loss: 2.3904386605000334

Epoch: 6| Step: 6
Training loss: 1.8337253310423622
Validation loss: 2.3820732908035724

Epoch: 6| Step: 7
Training loss: 1.706397456130838
Validation loss: 2.382924103607082

Epoch: 6| Step: 8
Training loss: 1.4431561854822925
Validation loss: 2.4053659358558006

Epoch: 6| Step: 9
Training loss: 1.5827379696801092
Validation loss: 2.4504226301003262

Epoch: 6| Step: 10
Training loss: 1.5059231795314616
Validation loss: 2.4307004238108947

Epoch: 6| Step: 11
Training loss: 1.8810513439035865
Validation loss: 2.364627570108513

Epoch: 6| Step: 12
Training loss: 1.4621573674455473
Validation loss: 2.4254526698451655

Epoch: 6| Step: 13
Training loss: 1.7071295039970924
Validation loss: 2.4658940760186305

Epoch: 310| Step: 0
Training loss: 1.803114564756348
Validation loss: 2.4031266182841047

Epoch: 6| Step: 1
Training loss: 1.4020122678222704
Validation loss: 2.41397673874044

Epoch: 6| Step: 2
Training loss: 1.3498894363621865
Validation loss: 2.437871386703581

Epoch: 6| Step: 3
Training loss: 1.6646672972063168
Validation loss: 2.453451291281884

Epoch: 6| Step: 4
Training loss: 1.35623195829565
Validation loss: 2.3781270574443543

Epoch: 6| Step: 5
Training loss: 1.348266905494887
Validation loss: 2.4280874228110667

Epoch: 6| Step: 6
Training loss: 0.7725187296896124
Validation loss: 2.3590912561703745

Epoch: 6| Step: 7
Training loss: 1.572635356008162
Validation loss: 2.3900564156835507

Epoch: 6| Step: 8
Training loss: 1.5954076336956706
Validation loss: 2.395751708478483

Epoch: 6| Step: 9
Training loss: 1.9715832501992987
Validation loss: 2.443297721595325

Epoch: 6| Step: 10
Training loss: 2.2624008915728115
Validation loss: 2.409719334787858

Epoch: 6| Step: 11
Training loss: 1.5294533913760175
Validation loss: 2.390767075490182

Epoch: 6| Step: 12
Training loss: 1.4553096305453546
Validation loss: 2.322412279829052

Epoch: 6| Step: 13
Training loss: 2.207077701046021
Validation loss: 2.3932803947438637

Epoch: 311| Step: 0
Training loss: 1.483123010376031
Validation loss: 2.323954799738013

Epoch: 6| Step: 1
Training loss: 1.3478855103906613
Validation loss: 2.415157677267607

Epoch: 6| Step: 2
Training loss: 1.5788668409107574
Validation loss: 2.501097330638371

Epoch: 6| Step: 3
Training loss: 1.142344811248182
Validation loss: 2.3903594406053643

Epoch: 6| Step: 4
Training loss: 1.6062600814562333
Validation loss: 2.3968365826942395

Epoch: 6| Step: 5
Training loss: 2.335298380605515
Validation loss: 2.425045799784475

Epoch: 6| Step: 6
Training loss: 1.6437616790240543
Validation loss: 2.3927061381612926

Epoch: 6| Step: 7
Training loss: 1.7223641976249546
Validation loss: 2.4039494736383067

Epoch: 6| Step: 8
Training loss: 1.7697165015389023
Validation loss: 2.4434965293591024

Epoch: 6| Step: 9
Training loss: 1.6684943985654952
Validation loss: 2.416614553832372

Epoch: 6| Step: 10
Training loss: 1.5237869253214236
Validation loss: 2.3944362924070615

Epoch: 6| Step: 11
Training loss: 1.9723563088995815
Validation loss: 2.411886754730851

Epoch: 6| Step: 12
Training loss: 1.4375620289563744
Validation loss: 2.4481566612365673

Epoch: 6| Step: 13
Training loss: 1.7670506485921509
Validation loss: 2.422228586436843

Epoch: 312| Step: 0
Training loss: 1.9436802278120933
Validation loss: 2.3769534151274248

Epoch: 6| Step: 1
Training loss: 1.3420839849306831
Validation loss: 2.32471011020998

Epoch: 6| Step: 2
Training loss: 1.3383087173199666
Validation loss: 2.4148166475573145

Epoch: 6| Step: 3
Training loss: 2.070133302238792
Validation loss: 2.3991390825643397

Epoch: 6| Step: 4
Training loss: 1.445608820051594
Validation loss: 2.4250675600918847

Epoch: 6| Step: 5
Training loss: 1.511155055418445
Validation loss: 2.3516875513718243

Epoch: 6| Step: 6
Training loss: 1.4873541399823977
Validation loss: 2.404758299965

Epoch: 6| Step: 7
Training loss: 1.7269798913523857
Validation loss: 2.3925905087962303

Epoch: 6| Step: 8
Training loss: 1.3127270456754343
Validation loss: 2.4243469494776333

Epoch: 6| Step: 9
Training loss: 1.661112718499865
Validation loss: 2.4027347903065794

Epoch: 6| Step: 10
Training loss: 1.9055823736030595
Validation loss: 2.404715034724717

Epoch: 6| Step: 11
Training loss: 1.18678834571709
Validation loss: 2.4295102477403923

Epoch: 6| Step: 12
Training loss: 1.6460589564067623
Validation loss: 2.3937529340989654

Epoch: 6| Step: 13
Training loss: 2.352071611923146
Validation loss: 2.4334800171001536

Epoch: 313| Step: 0
Training loss: 2.2924734487212803
Validation loss: 2.361891981332144

Epoch: 6| Step: 1
Training loss: 1.118922347107614
Validation loss: 2.3587076141965984

Epoch: 6| Step: 2
Training loss: 1.43102531168669
Validation loss: 2.3817958675628246

Epoch: 6| Step: 3
Training loss: 1.5213509379919319
Validation loss: 2.381889464924574

Epoch: 6| Step: 4
Training loss: 1.9146429310662747
Validation loss: 2.4023156626723745

Epoch: 6| Step: 5
Training loss: 1.6819751154298244
Validation loss: 2.407207363020231

Epoch: 6| Step: 6
Training loss: 1.7294142978561124
Validation loss: 2.360362441119033

Epoch: 6| Step: 7
Training loss: 1.6603617462431044
Validation loss: 2.3762125429193124

Epoch: 6| Step: 8
Training loss: 1.5262125416500938
Validation loss: 2.348611039332002

Epoch: 6| Step: 9
Training loss: 1.8221290921562214
Validation loss: 2.442040545752792

Epoch: 6| Step: 10
Training loss: 1.7433864419602276
Validation loss: 2.3790855607530035

Epoch: 6| Step: 11
Training loss: 1.8284107865185006
Validation loss: 2.5061980274355626

Epoch: 6| Step: 12
Training loss: 1.2640286963319927
Validation loss: 2.444525369121584

Epoch: 6| Step: 13
Training loss: 1.184421061322172
Validation loss: 2.4093408037944664

Epoch: 314| Step: 0
Training loss: 1.8158861953979497
Validation loss: 2.465135702564444

Epoch: 6| Step: 1
Training loss: 1.3880680021343315
Validation loss: 2.40430990910511

Epoch: 6| Step: 2
Training loss: 1.6937413120398863
Validation loss: 2.4027082349319255

Epoch: 6| Step: 3
Training loss: 1.5515791908434369
Validation loss: 2.4958020943575225

Epoch: 6| Step: 4
Training loss: 1.2353903541957862
Validation loss: 2.5292346354536424

Epoch: 6| Step: 5
Training loss: 1.7431149601365106
Validation loss: 2.445924221301861

Epoch: 6| Step: 6
Training loss: 1.7811602519665166
Validation loss: 2.410520612903328

Epoch: 6| Step: 7
Training loss: 1.534508721454555
Validation loss: 2.4239790864977917

Epoch: 6| Step: 8
Training loss: 1.5471614996186078
Validation loss: 2.4433836477158706

Epoch: 6| Step: 9
Training loss: 2.177243410884336
Validation loss: 2.4087319270510683

Epoch: 6| Step: 10
Training loss: 1.9725006344290175
Validation loss: 2.399050964781593

Epoch: 6| Step: 11
Training loss: 1.2056971216852566
Validation loss: 2.3936342702177336

Epoch: 6| Step: 12
Training loss: 1.6118173677244558
Validation loss: 2.3839592858237264

Epoch: 6| Step: 13
Training loss: 1.2591017755634815
Validation loss: 2.356818006296419

Epoch: 315| Step: 0
Training loss: 1.9025967094915033
Validation loss: 2.4217903495547093

Epoch: 6| Step: 1
Training loss: 1.1426625277653104
Validation loss: 2.4725082491321064

Epoch: 6| Step: 2
Training loss: 1.467762716714839
Validation loss: 2.4048798075516844

Epoch: 6| Step: 3
Training loss: 1.8907983873796617
Validation loss: 2.404635890161207

Epoch: 6| Step: 4
Training loss: 1.4498112128120026
Validation loss: 2.3746448077454616

Epoch: 6| Step: 5
Training loss: 1.5329177493670243
Validation loss: 2.399594516515877

Epoch: 6| Step: 6
Training loss: 1.8301974555879017
Validation loss: 2.375412475009063

Epoch: 6| Step: 7
Training loss: 1.2315005865556417
Validation loss: 2.4518402719213728

Epoch: 6| Step: 8
Training loss: 1.5981326710289747
Validation loss: 2.434055799966474

Epoch: 6| Step: 9
Training loss: 1.5271744500108662
Validation loss: 2.356703100124597

Epoch: 6| Step: 10
Training loss: 1.8208822905755309
Validation loss: 2.384760320907711

Epoch: 6| Step: 11
Training loss: 1.3443924898209643
Validation loss: 2.427929701395588

Epoch: 6| Step: 12
Training loss: 1.5398680616808194
Validation loss: 2.3942757150158664

Epoch: 6| Step: 13
Training loss: 3.061391045781782
Validation loss: 2.5115964511415747

Epoch: 316| Step: 0
Training loss: 1.598617973095642
Validation loss: 2.433721272727813

Epoch: 6| Step: 1
Training loss: 1.730989605983158
Validation loss: 2.3961634443724953

Epoch: 6| Step: 2
Training loss: 1.6856298326784418
Validation loss: 2.3921389883837234

Epoch: 6| Step: 3
Training loss: 1.3706169929740175
Validation loss: 2.386648283499683

Epoch: 6| Step: 4
Training loss: 1.326041798118391
Validation loss: 2.3988060384334937

Epoch: 6| Step: 5
Training loss: 1.3847088929944853
Validation loss: 2.3896454593753824

Epoch: 6| Step: 6
Training loss: 1.224527894736246
Validation loss: 2.4169030531822555

Epoch: 6| Step: 7
Training loss: 1.6974126227563822
Validation loss: 2.3858254752233994

Epoch: 6| Step: 8
Training loss: 2.558046331885288
Validation loss: 2.399692536385868

Epoch: 6| Step: 9
Training loss: 1.5337995207485993
Validation loss: 2.3874696973713676

Epoch: 6| Step: 10
Training loss: 1.728192004927692
Validation loss: 2.3547565666000136

Epoch: 6| Step: 11
Training loss: 1.1898118654163141
Validation loss: 2.4177918415563604

Epoch: 6| Step: 12
Training loss: 1.881641577842555
Validation loss: 2.4260402295022896

Epoch: 6| Step: 13
Training loss: 1.9090220198442882
Validation loss: 2.3720295107265557

Epoch: 317| Step: 0
Training loss: 1.438538135005843
Validation loss: 2.4180956241372464

Epoch: 6| Step: 1
Training loss: 1.9238599745539366
Validation loss: 2.3716213803381563

Epoch: 6| Step: 2
Training loss: 2.52621788642476
Validation loss: 2.3712938527727054

Epoch: 6| Step: 3
Training loss: 1.4824634490886819
Validation loss: 2.403838754464271

Epoch: 6| Step: 4
Training loss: 0.5959241363275243
Validation loss: 2.417282309224822

Epoch: 6| Step: 5
Training loss: 1.5226817285980827
Validation loss: 2.394451979748447

Epoch: 6| Step: 6
Training loss: 1.7943484912855447
Validation loss: 2.35599253903214

Epoch: 6| Step: 7
Training loss: 1.1926039881920873
Validation loss: 2.4095278317704114

Epoch: 6| Step: 8
Training loss: 1.6938784110740315
Validation loss: 2.4196412814534005

Epoch: 6| Step: 9
Training loss: 1.810191163774688
Validation loss: 2.396059213042457

Epoch: 6| Step: 10
Training loss: 1.8265949595547317
Validation loss: 2.4140234003970247

Epoch: 6| Step: 11
Training loss: 1.1051081955702917
Validation loss: 2.4666438539287645

Epoch: 6| Step: 12
Training loss: 1.4139674876628539
Validation loss: 2.2683211451431586

Epoch: 6| Step: 13
Training loss: 1.017643492607138
Validation loss: 2.4303533383427895

Epoch: 318| Step: 0
Training loss: 1.303033111040317
Validation loss: 2.4295312236183193

Epoch: 6| Step: 1
Training loss: 1.243070420591292
Validation loss: 2.4234669576842673

Epoch: 6| Step: 2
Training loss: 1.8670528475040349
Validation loss: 2.3843941455435234

Epoch: 6| Step: 3
Training loss: 1.2733139258964523
Validation loss: 2.424047331424146

Epoch: 6| Step: 4
Training loss: 1.0972513015263057
Validation loss: 2.4058228022827475

Epoch: 6| Step: 5
Training loss: 1.6496865119215731
Validation loss: 2.407590390746626

Epoch: 6| Step: 6
Training loss: 1.5088574835315398
Validation loss: 2.45839709555012

Epoch: 6| Step: 7
Training loss: 1.414437344433296
Validation loss: 2.4151953945281663

Epoch: 6| Step: 8
Training loss: 2.5189000958193053
Validation loss: 2.3566796838518904

Epoch: 6| Step: 9
Training loss: 1.3423905704162558
Validation loss: 2.389088293810458

Epoch: 6| Step: 10
Training loss: 1.3333528735795293
Validation loss: 2.379776703579652

Epoch: 6| Step: 11
Training loss: 1.5713339752359958
Validation loss: 2.3808558851822155

Epoch: 6| Step: 12
Training loss: 2.1622258183413576
Validation loss: 2.3717438700112896

Epoch: 6| Step: 13
Training loss: 2.1642458180478252
Validation loss: 2.3688678147316566

Epoch: 319| Step: 0
Training loss: 1.2594296502686564
Validation loss: 2.35181432058467

Epoch: 6| Step: 1
Training loss: 1.7255483557381759
Validation loss: 2.4173071680451494

Epoch: 6| Step: 2
Training loss: 1.9661692097939454
Validation loss: 2.3753539508693944

Epoch: 6| Step: 3
Training loss: 1.389834747371068
Validation loss: 2.4279474910618895

Epoch: 6| Step: 4
Training loss: 1.5257923412945327
Validation loss: 2.338946939730938

Epoch: 6| Step: 5
Training loss: 1.1693254838956957
Validation loss: 2.4260494313861023

Epoch: 6| Step: 6
Training loss: 2.0976407922498423
Validation loss: 2.4863165354645673

Epoch: 6| Step: 7
Training loss: 1.5868040827274328
Validation loss: 2.459465335267286

Epoch: 6| Step: 8
Training loss: 1.8941960933003392
Validation loss: 2.390727347190404

Epoch: 6| Step: 9
Training loss: 1.7162743512097958
Validation loss: 2.384301859349226

Epoch: 6| Step: 10
Training loss: 1.8356929535021247
Validation loss: 2.454349761517013

Epoch: 6| Step: 11
Training loss: 1.3108502419204335
Validation loss: 2.4324613796846406

Epoch: 6| Step: 12
Training loss: 1.6302882490791157
Validation loss: 2.4729724826901887

Epoch: 6| Step: 13
Training loss: 1.2588025574001471
Validation loss: 2.3407459600337646

Epoch: 320| Step: 0
Training loss: 2.3391085633537374
Validation loss: 2.382094972281384

Epoch: 6| Step: 1
Training loss: 1.5566599233237568
Validation loss: 2.431409934534638

Epoch: 6| Step: 2
Training loss: 1.5925240382801134
Validation loss: 2.4170739420694067

Epoch: 6| Step: 3
Training loss: 1.054536596734864
Validation loss: 2.3569460082004587

Epoch: 6| Step: 4
Training loss: 1.5571955860654496
Validation loss: 2.3334075290409624

Epoch: 6| Step: 5
Training loss: 1.49104568974818
Validation loss: 2.4216837251401144

Epoch: 6| Step: 6
Training loss: 1.0030024278331822
Validation loss: 2.467084387929292

Epoch: 6| Step: 7
Training loss: 1.5685384417739827
Validation loss: 2.3196334510918426

Epoch: 6| Step: 8
Training loss: 1.6932318088303973
Validation loss: 2.3928936129636957

Epoch: 6| Step: 9
Training loss: 1.8909403009981798
Validation loss: 2.4131579389093276

Epoch: 6| Step: 10
Training loss: 1.0533057309610379
Validation loss: 2.386708457686532

Epoch: 6| Step: 11
Training loss: 2.225598578356488
Validation loss: 2.358729994110742

Epoch: 6| Step: 12
Training loss: 1.742353628132449
Validation loss: 2.318546506320071

Epoch: 6| Step: 13
Training loss: 1.4816178263512545
Validation loss: 2.3722508380780307

Epoch: 321| Step: 0
Training loss: 1.9169770763421543
Validation loss: 2.3500199182469603

Epoch: 6| Step: 1
Training loss: 1.7799782479489423
Validation loss: 2.454366877117096

Epoch: 6| Step: 2
Training loss: 1.851821816871934
Validation loss: 2.466571527393475

Epoch: 6| Step: 3
Training loss: 1.2762141000927363
Validation loss: 2.357749214204565

Epoch: 6| Step: 4
Training loss: 1.363200144281626
Validation loss: 2.4288940611344905

Epoch: 6| Step: 5
Training loss: 1.6761344768589963
Validation loss: 2.356223613540894

Epoch: 6| Step: 6
Training loss: 1.5357498690769513
Validation loss: 2.4643996811344726

Epoch: 6| Step: 7
Training loss: 1.5382046705163905
Validation loss: 2.4238138652823404

Epoch: 6| Step: 8
Training loss: 0.903997384029587
Validation loss: 2.415827927215579

Epoch: 6| Step: 9
Training loss: 1.5291424474781823
Validation loss: 2.4721536669094526

Epoch: 6| Step: 10
Training loss: 2.282596556510791
Validation loss: 2.408976688123756

Epoch: 6| Step: 11
Training loss: 1.46774054393344
Validation loss: 2.493757348773639

Epoch: 6| Step: 12
Training loss: 1.7567572923310508
Validation loss: 2.4696936464729715

Epoch: 6| Step: 13
Training loss: 1.7087485886451457
Validation loss: 2.4051341322242448

Epoch: 322| Step: 0
Training loss: 1.6542129945713433
Validation loss: 2.389738328771259

Epoch: 6| Step: 1
Training loss: 1.6463404328946936
Validation loss: 2.4981709326594594

Epoch: 6| Step: 2
Training loss: 1.5455014845150767
Validation loss: 2.3803033586051328

Epoch: 6| Step: 3
Training loss: 1.3641593313204428
Validation loss: 2.3666105771845554

Epoch: 6| Step: 4
Training loss: 1.347634666380604
Validation loss: 2.3762292276907804

Epoch: 6| Step: 5
Training loss: 1.7171862337560733
Validation loss: 2.3701401183993016

Epoch: 6| Step: 6
Training loss: 1.6846410056498298
Validation loss: 2.3697581082717205

Epoch: 6| Step: 7
Training loss: 1.9622391715721166
Validation loss: 2.443199975306734

Epoch: 6| Step: 8
Training loss: 1.7950837204517192
Validation loss: 2.4061612220840094

Epoch: 6| Step: 9
Training loss: 1.1446463881766102
Validation loss: 2.2875510241616834

Epoch: 6| Step: 10
Training loss: 2.140456478418713
Validation loss: 2.338385573586186

Epoch: 6| Step: 11
Training loss: 1.6214996197488618
Validation loss: 2.362784487798323

Epoch: 6| Step: 12
Training loss: 1.365970440434428
Validation loss: 2.393660249914882

Epoch: 6| Step: 13
Training loss: 1.5424868833209848
Validation loss: 2.4006031602148723

Epoch: 323| Step: 0
Training loss: 1.265062937320543
Validation loss: 2.3911146530700966

Epoch: 6| Step: 1
Training loss: 2.2075744500571584
Validation loss: 2.4134753116730825

Epoch: 6| Step: 2
Training loss: 1.595674437471626
Validation loss: 2.3410342697949793

Epoch: 6| Step: 3
Training loss: 1.5251608466700592
Validation loss: 2.4444631405185637

Epoch: 6| Step: 4
Training loss: 1.2079220049765242
Validation loss: 2.4291980905870836

Epoch: 6| Step: 5
Training loss: 1.4543051900531159
Validation loss: 2.4173157721562593

Epoch: 6| Step: 6
Training loss: 1.6387001007886426
Validation loss: 2.4122849179548145

Epoch: 6| Step: 7
Training loss: 1.1466161596925764
Validation loss: 2.364077577707625

Epoch: 6| Step: 8
Training loss: 1.9048918591740858
Validation loss: 2.374916810833156

Epoch: 6| Step: 9
Training loss: 1.2582511847672548
Validation loss: 2.3496132396456555

Epoch: 6| Step: 10
Training loss: 1.701596755566573
Validation loss: 2.410356207602794

Epoch: 6| Step: 11
Training loss: 1.6907741431487113
Validation loss: 2.392251663621187

Epoch: 6| Step: 12
Training loss: 2.2962957157740433
Validation loss: 2.3774656052264187

Epoch: 6| Step: 13
Training loss: 1.774230376473836
Validation loss: 2.409255699120712

Epoch: 324| Step: 0
Training loss: 1.5497664583294992
Validation loss: 2.361961979459849

Epoch: 6| Step: 1
Training loss: 1.8821150251581398
Validation loss: 2.368560004330558

Epoch: 6| Step: 2
Training loss: 1.7560159276096554
Validation loss: 2.4501455666829726

Epoch: 6| Step: 3
Training loss: 1.4597117131551904
Validation loss: 2.38059908446215

Epoch: 6| Step: 4
Training loss: 1.6863222604118981
Validation loss: 2.4578237424273555

Epoch: 6| Step: 5
Training loss: 1.929575681342423
Validation loss: 2.406590058815757

Epoch: 6| Step: 6
Training loss: 1.5320229428468288
Validation loss: 2.3646778432752966

Epoch: 6| Step: 7
Training loss: 1.5943152977185626
Validation loss: 2.436793670671916

Epoch: 6| Step: 8
Training loss: 1.3516319565759358
Validation loss: 2.412088392164018

Epoch: 6| Step: 9
Training loss: 2.567954700920128
Validation loss: 2.460428393405653

Epoch: 6| Step: 10
Training loss: 1.1038107688306613
Validation loss: 2.320770275967587

Epoch: 6| Step: 11
Training loss: 1.1538872161307832
Validation loss: 2.372445629956983

Epoch: 6| Step: 12
Training loss: 1.170476409475584
Validation loss: 2.3779134394333643

Epoch: 6| Step: 13
Training loss: 1.5091007244098005
Validation loss: 2.3862760711407547

Epoch: 325| Step: 0
Training loss: 1.4115862583122814
Validation loss: 2.39930102055137

Epoch: 6| Step: 1
Training loss: 1.0923527648492681
Validation loss: 2.382180550094311

Epoch: 6| Step: 2
Training loss: 1.1828109116335728
Validation loss: 2.40715292780729

Epoch: 6| Step: 3
Training loss: 2.2455073113501878
Validation loss: 2.358363392605462

Epoch: 6| Step: 4
Training loss: 1.9912788263546444
Validation loss: 2.261650561479855

Epoch: 6| Step: 5
Training loss: 1.5094890069652869
Validation loss: 2.427824957446197

Epoch: 6| Step: 6
Training loss: 1.4199646913141388
Validation loss: 2.430762559676881

Epoch: 6| Step: 7
Training loss: 1.5196337040191197
Validation loss: 2.3963758206674193

Epoch: 6| Step: 8
Training loss: 1.373842619254647
Validation loss: 2.4015159836902553

Epoch: 6| Step: 9
Training loss: 1.8459567425578796
Validation loss: 2.408276807420654

Epoch: 6| Step: 10
Training loss: 1.2431614254715992
Validation loss: 2.3957350986738253

Epoch: 6| Step: 11
Training loss: 1.7393380028274648
Validation loss: 2.305336357423539

Epoch: 6| Step: 12
Training loss: 1.593114464396872
Validation loss: 2.4160553019558693

Epoch: 6| Step: 13
Training loss: 1.5611242722891325
Validation loss: 2.3242054906577008

Epoch: 326| Step: 0
Training loss: 1.3161909793326112
Validation loss: 2.470970228151583

Epoch: 6| Step: 1
Training loss: 1.8449020019598132
Validation loss: 2.4811594109976474

Epoch: 6| Step: 2
Training loss: 1.4860035044293778
Validation loss: 2.409206583882753

Epoch: 6| Step: 3
Training loss: 1.6792766689620893
Validation loss: 2.3550243951356804

Epoch: 6| Step: 4
Training loss: 1.2518519034804718
Validation loss: 2.4332985281579758

Epoch: 6| Step: 5
Training loss: 2.2922154087481696
Validation loss: 2.422680854962759

Epoch: 6| Step: 6
Training loss: 0.996032054710859
Validation loss: 2.42757448739372

Epoch: 6| Step: 7
Training loss: 1.1458093582881803
Validation loss: 2.424657121713291

Epoch: 6| Step: 8
Training loss: 2.1719474505957583
Validation loss: 2.3880306598007897

Epoch: 6| Step: 9
Training loss: 1.3470645213600687
Validation loss: 2.395784364889169

Epoch: 6| Step: 10
Training loss: 1.579424936450863
Validation loss: 2.3493067519802926

Epoch: 6| Step: 11
Training loss: 1.5754399638793628
Validation loss: 2.382128755431709

Epoch: 6| Step: 12
Training loss: 1.2972904596935215
Validation loss: 2.3097901013099666

Epoch: 6| Step: 13
Training loss: 1.2791743329012066
Validation loss: 2.337857924213554

Epoch: 327| Step: 0
Training loss: 2.1519631050946195
Validation loss: 2.4494903037617357

Epoch: 6| Step: 1
Training loss: 1.5680544736167854
Validation loss: 2.375979785422947

Epoch: 6| Step: 2
Training loss: 1.6469084531799323
Validation loss: 2.3948281914074716

Epoch: 6| Step: 3
Training loss: 1.01539820559728
Validation loss: 2.350600066685445

Epoch: 6| Step: 4
Training loss: 1.5072765287189671
Validation loss: 2.372113170763556

Epoch: 6| Step: 5
Training loss: 1.3284384862393146
Validation loss: 2.4220515858622

Epoch: 6| Step: 6
Training loss: 1.3843691410259324
Validation loss: 2.3944957371661375

Epoch: 6| Step: 7
Training loss: 1.4112811475886236
Validation loss: 2.3887704251656348

Epoch: 6| Step: 8
Training loss: 1.3859204210607416
Validation loss: 2.3383112237359085

Epoch: 6| Step: 9
Training loss: 1.985796441831925
Validation loss: 2.4959018794073997

Epoch: 6| Step: 10
Training loss: 1.0944835927473242
Validation loss: 2.396687042986561

Epoch: 6| Step: 11
Training loss: 1.8860896544561732
Validation loss: 2.437751813806812

Epoch: 6| Step: 12
Training loss: 1.5729776416942935
Validation loss: 2.39935464877394

Epoch: 6| Step: 13
Training loss: 1.1679531849107863
Validation loss: 2.4083943565322548

Epoch: 328| Step: 0
Training loss: 1.876656563439736
Validation loss: 2.37607929034347

Epoch: 6| Step: 1
Training loss: 1.7103979226625208
Validation loss: 2.4307133611576197

Epoch: 6| Step: 2
Training loss: 1.222149338620241
Validation loss: 2.292500275123746

Epoch: 6| Step: 3
Training loss: 1.3659951378385322
Validation loss: 2.3963583486452373

Epoch: 6| Step: 4
Training loss: 1.6426380704448724
Validation loss: 2.4487977281379307

Epoch: 6| Step: 5
Training loss: 1.9700891693382925
Validation loss: 2.4194128248997706

Epoch: 6| Step: 6
Training loss: 0.8686969438996411
Validation loss: 2.3987227252880876

Epoch: 6| Step: 7
Training loss: 1.4014971629619974
Validation loss: 2.3604442898238425

Epoch: 6| Step: 8
Training loss: 1.3180890293558196
Validation loss: 2.387637696614415

Epoch: 6| Step: 9
Training loss: 1.6832640429043702
Validation loss: 2.310249832458823

Epoch: 6| Step: 10
Training loss: 1.4492458947613638
Validation loss: 2.3847915701618696

Epoch: 6| Step: 11
Training loss: 1.38769539840451
Validation loss: 2.466968399239679

Epoch: 6| Step: 12
Training loss: 2.5454065501035505
Validation loss: 2.3586737107926403

Epoch: 6| Step: 13
Training loss: 1.335070278375258
Validation loss: 2.422881857024556

Epoch: 329| Step: 0
Training loss: 2.454767248459639
Validation loss: 2.4766204036352333

Epoch: 6| Step: 1
Training loss: 1.8308288272159194
Validation loss: 2.439305225718044

Epoch: 6| Step: 2
Training loss: 1.24434484126256
Validation loss: 2.465566157146733

Epoch: 6| Step: 3
Training loss: 1.3914106057306104
Validation loss: 2.406175317925115

Epoch: 6| Step: 4
Training loss: 1.311041884875657
Validation loss: 2.374907997521165

Epoch: 6| Step: 5
Training loss: 1.4762718277883258
Validation loss: 2.3678175517782654

Epoch: 6| Step: 6
Training loss: 1.492927407770735
Validation loss: 2.399769165788995

Epoch: 6| Step: 7
Training loss: 1.1258122373044943
Validation loss: 2.387126499144494

Epoch: 6| Step: 8
Training loss: 1.292394135823194
Validation loss: 2.452019249903263

Epoch: 6| Step: 9
Training loss: 1.7548512926704665
Validation loss: 2.3780429896395034

Epoch: 6| Step: 10
Training loss: 0.974749660142603
Validation loss: 2.433069299324071

Epoch: 6| Step: 11
Training loss: 1.6377402966485124
Validation loss: 2.4362645337787607

Epoch: 6| Step: 12
Training loss: 1.580977628266093
Validation loss: 2.393890469098575

Epoch: 6| Step: 13
Training loss: 2.1834273436984253
Validation loss: 2.406994702139451

Epoch: 330| Step: 0
Training loss: 1.262944573790786
Validation loss: 2.4464101195728882

Epoch: 6| Step: 1
Training loss: 1.2421022781792197
Validation loss: 2.44110736892802

Epoch: 6| Step: 2
Training loss: 0.9988454770224627
Validation loss: 2.375575278210484

Epoch: 6| Step: 3
Training loss: 1.9784015649000335
Validation loss: 2.32254360129127

Epoch: 6| Step: 4
Training loss: 2.203393365193184
Validation loss: 2.490649942512056

Epoch: 6| Step: 5
Training loss: 2.4312729155335746
Validation loss: 2.4099798190623694

Epoch: 6| Step: 6
Training loss: 1.4577361746184594
Validation loss: 2.370371624769193

Epoch: 6| Step: 7
Training loss: 0.8553483434099927
Validation loss: 2.3785948088204028

Epoch: 6| Step: 8
Training loss: 1.4455520019044492
Validation loss: 2.380847557407538

Epoch: 6| Step: 9
Training loss: 1.6126037357289418
Validation loss: 2.371513068375452

Epoch: 6| Step: 10
Training loss: 1.353020471495539
Validation loss: 2.437955612332071

Epoch: 6| Step: 11
Training loss: 1.516793577243188
Validation loss: 2.346929195744976

Epoch: 6| Step: 12
Training loss: 1.0228478866315882
Validation loss: 2.3629087537791627

Epoch: 6| Step: 13
Training loss: 1.7976743164215683
Validation loss: 2.363795633659525

Epoch: 331| Step: 0
Training loss: 1.4773479976018062
Validation loss: 2.3732113258146965

Epoch: 6| Step: 1
Training loss: 1.33826355574491
Validation loss: 2.339356092302661

Epoch: 6| Step: 2
Training loss: 1.5765443950176823
Validation loss: 2.4983611559844667

Epoch: 6| Step: 3
Training loss: 1.570731491443681
Validation loss: 2.3532961550784273

Epoch: 6| Step: 4
Training loss: 1.5993923463883235
Validation loss: 2.3388651240841503

Epoch: 6| Step: 5
Training loss: 1.5878269609777422
Validation loss: 2.4305241092770826

Epoch: 6| Step: 6
Training loss: 1.604119097842447
Validation loss: 2.332373991725354

Epoch: 6| Step: 7
Training loss: 1.4498564353114125
Validation loss: 2.354430491432516

Epoch: 6| Step: 8
Training loss: 1.387732293899935
Validation loss: 2.360507033688299

Epoch: 6| Step: 9
Training loss: 1.8189169318812304
Validation loss: 2.4042190698176786

Epoch: 6| Step: 10
Training loss: 1.4501213286052244
Validation loss: 2.333641090913815

Epoch: 6| Step: 11
Training loss: 1.9977743162399324
Validation loss: 2.4542980379621055

Epoch: 6| Step: 12
Training loss: 1.8239196924299035
Validation loss: 2.4416798968784224

Epoch: 6| Step: 13
Training loss: 1.6456173461318815
Validation loss: 2.424152162456085

Epoch: 332| Step: 0
Training loss: 1.3329120755312809
Validation loss: 2.4025479036296002

Epoch: 6| Step: 1
Training loss: 1.3172337226404964
Validation loss: 2.4125113960756535

Epoch: 6| Step: 2
Training loss: 1.8615052658281175
Validation loss: 2.380908800435307

Epoch: 6| Step: 3
Training loss: 1.5402020723117686
Validation loss: 2.333897359493158

Epoch: 6| Step: 4
Training loss: 1.9553282250980244
Validation loss: 2.314262405885882

Epoch: 6| Step: 5
Training loss: 1.4495357362119154
Validation loss: 2.3649617547755426

Epoch: 6| Step: 6
Training loss: 1.0978815248042062
Validation loss: 2.2860218115116733

Epoch: 6| Step: 7
Training loss: 1.6248339054613903
Validation loss: 2.4565919531348714

Epoch: 6| Step: 8
Training loss: 1.3253084723355852
Validation loss: 2.4405400113949276

Epoch: 6| Step: 9
Training loss: 1.4716683471485765
Validation loss: 2.386104918814853

Epoch: 6| Step: 10
Training loss: 2.4235045826504407
Validation loss: 2.446486745907415

Epoch: 6| Step: 11
Training loss: 1.673816872272925
Validation loss: 2.365539971638175

Epoch: 6| Step: 12
Training loss: 1.2311863819862594
Validation loss: 2.3677649048115854

Epoch: 6| Step: 13
Training loss: 1.5567377268373408
Validation loss: 2.401305748814964

Epoch: 333| Step: 0
Training loss: 1.799954570091001
Validation loss: 2.4119349613530714

Epoch: 6| Step: 1
Training loss: 1.498962758976507
Validation loss: 2.428957690758137

Epoch: 6| Step: 2
Training loss: 2.5159251347973433
Validation loss: 2.4162526897033088

Epoch: 6| Step: 3
Training loss: 1.0559620820339821
Validation loss: 2.4207224802520506

Epoch: 6| Step: 4
Training loss: 1.9139895055437328
Validation loss: 2.368371974798727

Epoch: 6| Step: 5
Training loss: 1.2527515644527327
Validation loss: 2.3910936355633945

Epoch: 6| Step: 6
Training loss: 1.081837109938546
Validation loss: 2.47041045331311

Epoch: 6| Step: 7
Training loss: 1.5282687534983208
Validation loss: 2.431855131300843

Epoch: 6| Step: 8
Training loss: 1.378060662461057
Validation loss: 2.372121863690151

Epoch: 6| Step: 9
Training loss: 1.2217897019528503
Validation loss: 2.3454805139602697

Epoch: 6| Step: 10
Training loss: 1.5876637351835072
Validation loss: 2.380641738301685

Epoch: 6| Step: 11
Training loss: 1.4860112858853274
Validation loss: 2.412860832920324

Epoch: 6| Step: 12
Training loss: 1.3059970884655778
Validation loss: 2.4173228342282695

Epoch: 6| Step: 13
Training loss: 1.8024805619756483
Validation loss: 2.4100651321848354

Epoch: 334| Step: 0
Training loss: 1.5160992067331815
Validation loss: 2.3909016797001725

Epoch: 6| Step: 1
Training loss: 1.2047368436571138
Validation loss: 2.4075739392840783

Epoch: 6| Step: 2
Training loss: 1.218548293417168
Validation loss: 2.3835078227700346

Epoch: 6| Step: 3
Training loss: 1.4111969718735184
Validation loss: 2.3478350691104777

Epoch: 6| Step: 4
Training loss: 1.7677811142507467
Validation loss: 2.402027756099144

Epoch: 6| Step: 5
Training loss: 1.3643090164089067
Validation loss: 2.433361808724307

Epoch: 6| Step: 6
Training loss: 1.610549128103149
Validation loss: 2.3730559096659594

Epoch: 6| Step: 7
Training loss: 1.8397846576895682
Validation loss: 2.4052097424919

Epoch: 6| Step: 8
Training loss: 1.8363018567142408
Validation loss: 2.407539038385238

Epoch: 6| Step: 9
Training loss: 1.4071562072405546
Validation loss: 2.3215478916237626

Epoch: 6| Step: 10
Training loss: 2.070179600318698
Validation loss: 2.2992947207770764

Epoch: 6| Step: 11
Training loss: 1.3252555816596174
Validation loss: 2.3895708124778783

Epoch: 6| Step: 12
Training loss: 1.2137320973483423
Validation loss: 2.4523145435356852

Epoch: 6| Step: 13
Training loss: 1.4841415221654408
Validation loss: 2.371148653001748

Epoch: 335| Step: 0
Training loss: 1.2807667448910147
Validation loss: 2.4035045504175914

Epoch: 6| Step: 1
Training loss: 1.258429618755828
Validation loss: 2.4106698995873765

Epoch: 6| Step: 2
Training loss: 1.5015363772339925
Validation loss: 2.3707701819116673

Epoch: 6| Step: 3
Training loss: 2.227495714005822
Validation loss: 2.4175813518888076

Epoch: 6| Step: 4
Training loss: 1.902870747537227
Validation loss: 2.4610576735071112

Epoch: 6| Step: 5
Training loss: 1.8488514040979103
Validation loss: 2.3900421373577205

Epoch: 6| Step: 6
Training loss: 1.287530902380584
Validation loss: 2.38688767207991

Epoch: 6| Step: 7
Training loss: 1.2769141918559122
Validation loss: 2.4899745995315326

Epoch: 6| Step: 8
Training loss: 1.4372879369469562
Validation loss: 2.3476503510085647

Epoch: 6| Step: 9
Training loss: 1.4997753928823672
Validation loss: 2.412496562583175

Epoch: 6| Step: 10
Training loss: 1.9761801489321071
Validation loss: 2.4127030894281596

Epoch: 6| Step: 11
Training loss: 1.4664400481940985
Validation loss: 2.437387489076006

Epoch: 6| Step: 12
Training loss: 1.6489283838723168
Validation loss: 2.3618684412067736

Epoch: 6| Step: 13
Training loss: 1.472759860413541
Validation loss: 2.3334423290965023

Epoch: 336| Step: 0
Training loss: 1.407506381506538
Validation loss: 2.4225478598822825

Epoch: 6| Step: 1
Training loss: 2.0700206622875443
Validation loss: 2.4773829133724132

Epoch: 6| Step: 2
Training loss: 1.532597318860556
Validation loss: 2.4019314714715296

Epoch: 6| Step: 3
Training loss: 1.504913151538555
Validation loss: 2.330510694051874

Epoch: 6| Step: 4
Training loss: 1.012756051547602
Validation loss: 2.388040471914036

Epoch: 6| Step: 5
Training loss: 1.4038845088169003
Validation loss: 2.4156694605510354

Epoch: 6| Step: 6
Training loss: 1.7783885525845085
Validation loss: 2.3604743231119825

Epoch: 6| Step: 7
Training loss: 1.2457522698675885
Validation loss: 2.33546003279256

Epoch: 6| Step: 8
Training loss: 2.03113121272258
Validation loss: 2.4443419408732483

Epoch: 6| Step: 9
Training loss: 1.6588923411465768
Validation loss: 2.3142874676470484

Epoch: 6| Step: 10
Training loss: 1.0420517336876598
Validation loss: 2.3901016720978894

Epoch: 6| Step: 11
Training loss: 1.819933806881966
Validation loss: 2.373248011602326

Epoch: 6| Step: 12
Training loss: 0.8696800015585798
Validation loss: 2.3733370841624497

Epoch: 6| Step: 13
Training loss: 1.6248225335270168
Validation loss: 2.3852211051278696

Epoch: 337| Step: 0
Training loss: 1.049081157374102
Validation loss: 2.4223650772219667

Epoch: 6| Step: 1
Training loss: 1.5816698203073838
Validation loss: 2.394629297803717

Epoch: 6| Step: 2
Training loss: 1.868606028544792
Validation loss: 2.3621163960875844

Epoch: 6| Step: 3
Training loss: 1.2268077823766452
Validation loss: 2.34152688750856

Epoch: 6| Step: 4
Training loss: 1.6743486589878012
Validation loss: 2.3774641268654295

Epoch: 6| Step: 5
Training loss: 1.4264054277735043
Validation loss: 2.3905856135764054

Epoch: 6| Step: 6
Training loss: 1.5174654767855789
Validation loss: 2.429226019588776

Epoch: 6| Step: 7
Training loss: 1.7079006748175125
Validation loss: 2.411772211842643

Epoch: 6| Step: 8
Training loss: 1.3960780693074426
Validation loss: 2.4126769848559424

Epoch: 6| Step: 9
Training loss: 1.4574356949559184
Validation loss: 2.359442738358784

Epoch: 6| Step: 10
Training loss: 1.6341901743960308
Validation loss: 2.3191040887584364

Epoch: 6| Step: 11
Training loss: 1.3632708442531327
Validation loss: 2.44579126637319

Epoch: 6| Step: 12
Training loss: 2.1163533386848705
Validation loss: 2.438314374920475

Epoch: 6| Step: 13
Training loss: 1.8278291250911876
Validation loss: 2.355638341502765

Epoch: 338| Step: 0
Training loss: 1.2314078002346829
Validation loss: 2.389704572738224

Epoch: 6| Step: 1
Training loss: 1.1678397321090672
Validation loss: 2.441115706418008

Epoch: 6| Step: 2
Training loss: 1.2949150626116996
Validation loss: 2.4764531649287633

Epoch: 6| Step: 3
Training loss: 1.5055842562649933
Validation loss: 2.399031984123921

Epoch: 6| Step: 4
Training loss: 1.6848441523350077
Validation loss: 2.433344037043244

Epoch: 6| Step: 5
Training loss: 1.5565546220213602
Validation loss: 2.395545880879326

Epoch: 6| Step: 6
Training loss: 1.458271960829019
Validation loss: 2.3877967277265224

Epoch: 6| Step: 7
Training loss: 1.4914798356731902
Validation loss: 2.4122700309949177

Epoch: 6| Step: 8
Training loss: 1.7780026734013405
Validation loss: 2.365666680720558

Epoch: 6| Step: 9
Training loss: 1.4510393659797534
Validation loss: 2.4188303757381844

Epoch: 6| Step: 10
Training loss: 1.4302513803263022
Validation loss: 2.3532306168893955

Epoch: 6| Step: 11
Training loss: 1.459643356841579
Validation loss: 2.3611684957098222

Epoch: 6| Step: 12
Training loss: 2.037735079444284
Validation loss: 2.4178262424355585

Epoch: 6| Step: 13
Training loss: 2.2249942007953636
Validation loss: 2.326437688381098

Epoch: 339| Step: 0
Training loss: 1.2459791363948671
Validation loss: 2.4098718364719387

Epoch: 6| Step: 1
Training loss: 1.190547996694193
Validation loss: 2.3764604979521775

Epoch: 6| Step: 2
Training loss: 2.2287677752630546
Validation loss: 2.3733268159115712

Epoch: 6| Step: 3
Training loss: 1.6338232097260854
Validation loss: 2.454066225373999

Epoch: 6| Step: 4
Training loss: 1.8366989180103885
Validation loss: 2.3614632939417675

Epoch: 6| Step: 5
Training loss: 1.8461983152682477
Validation loss: 2.428238214530497

Epoch: 6| Step: 6
Training loss: 1.3967481244048852
Validation loss: 2.427379085416746

Epoch: 6| Step: 7
Training loss: 1.497915488478295
Validation loss: 2.4315850656890396

Epoch: 6| Step: 8
Training loss: 1.461192389299699
Validation loss: 2.378839544364636

Epoch: 6| Step: 9
Training loss: 1.354406022657015
Validation loss: 2.4224713033673937

Epoch: 6| Step: 10
Training loss: 1.3954818434865028
Validation loss: 2.4089458968044606

Epoch: 6| Step: 11
Training loss: 1.5811337786396191
Validation loss: 2.374585216378752

Epoch: 6| Step: 12
Training loss: 1.1344267820199054
Validation loss: 2.321223595276118

Epoch: 6| Step: 13
Training loss: 1.6081494600145967
Validation loss: 2.389375905488806

Epoch: 340| Step: 0
Training loss: 1.2493446539532524
Validation loss: 2.344741513117633

Epoch: 6| Step: 1
Training loss: 2.1540097748261
Validation loss: 2.350575217585079

Epoch: 6| Step: 2
Training loss: 1.434215857626208
Validation loss: 2.3825441496830675

Epoch: 6| Step: 3
Training loss: 1.472191046538643
Validation loss: 2.4792808778023896

Epoch: 6| Step: 4
Training loss: 1.5747158884198582
Validation loss: 2.3874093088162343

Epoch: 6| Step: 5
Training loss: 1.5100429028611886
Validation loss: 2.388511528305587

Epoch: 6| Step: 6
Training loss: 0.9065472345602128
Validation loss: 2.402898246346458

Epoch: 6| Step: 7
Training loss: 1.4557701564561436
Validation loss: 2.398694078278079

Epoch: 6| Step: 8
Training loss: 1.741954565513403
Validation loss: 2.4342846247021446

Epoch: 6| Step: 9
Training loss: 1.3843129955726428
Validation loss: 2.410702127396815

Epoch: 6| Step: 10
Training loss: 1.1890098108956835
Validation loss: 2.4005697684097522

Epoch: 6| Step: 11
Training loss: 1.4167518964074552
Validation loss: 2.4134856385493575

Epoch: 6| Step: 12
Training loss: 2.0100441490373044
Validation loss: 2.4540784592413405

Epoch: 6| Step: 13
Training loss: 1.5868997895992754
Validation loss: 2.4235758048750324

Epoch: 341| Step: 0
Training loss: 1.5516246740939648
Validation loss: 2.357541965765351

Epoch: 6| Step: 1
Training loss: 2.0097651504797787
Validation loss: 2.4314061935760103

Epoch: 6| Step: 2
Training loss: 1.2963533846202846
Validation loss: 2.4206777963171002

Epoch: 6| Step: 3
Training loss: 0.9154488898677097
Validation loss: 2.4836647048664706

Epoch: 6| Step: 4
Training loss: 1.6802280709450863
Validation loss: 2.368787683502189

Epoch: 6| Step: 5
Training loss: 1.3806974971693022
Validation loss: 2.4538054919188066

Epoch: 6| Step: 6
Training loss: 2.068536075468329
Validation loss: 2.44586795035324

Epoch: 6| Step: 7
Training loss: 1.1038694641506654
Validation loss: 2.4507976355292858

Epoch: 6| Step: 8
Training loss: 1.4818052032006581
Validation loss: 2.4553530171208795

Epoch: 6| Step: 9
Training loss: 1.3448118849026625
Validation loss: 2.3810147480040516

Epoch: 6| Step: 10
Training loss: 1.4374558815198184
Validation loss: 2.352421893615319

Epoch: 6| Step: 11
Training loss: 1.544085366582176
Validation loss: 2.311422569845104

Epoch: 6| Step: 12
Training loss: 1.7538344744500638
Validation loss: 2.3674855829221735

Epoch: 6| Step: 13
Training loss: 1.1964573084017422
Validation loss: 2.38452164604578

Epoch: 342| Step: 0
Training loss: 1.4275955988578046
Validation loss: 2.4083811891200053

Epoch: 6| Step: 1
Training loss: 1.9843600415244216
Validation loss: 2.381409838600761

Epoch: 6| Step: 2
Training loss: 1.3899462468573496
Validation loss: 2.381503425298624

Epoch: 6| Step: 3
Training loss: 1.446687199246184
Validation loss: 2.390002728725092

Epoch: 6| Step: 4
Training loss: 1.6090168971187415
Validation loss: 2.4133273240207624

Epoch: 6| Step: 5
Training loss: 1.471134036541147
Validation loss: 2.373797301603734

Epoch: 6| Step: 6
Training loss: 1.3687600819116243
Validation loss: 2.387115644765884

Epoch: 6| Step: 7
Training loss: 2.382482887358717
Validation loss: 2.3665051915452553

Epoch: 6| Step: 8
Training loss: 1.1206367970328088
Validation loss: 2.3315428549469024

Epoch: 6| Step: 9
Training loss: 1.2096231526333805
Validation loss: 2.3545727878156373

Epoch: 6| Step: 10
Training loss: 1.4291248986430931
Validation loss: 2.3229648101892884

Epoch: 6| Step: 11
Training loss: 1.1194577391954845
Validation loss: 2.393745797671227

Epoch: 6| Step: 12
Training loss: 1.2773420701322096
Validation loss: 2.434033960973691

Epoch: 6| Step: 13
Training loss: 1.436130949818381
Validation loss: 2.374312396810765

Epoch: 343| Step: 0
Training loss: 1.4126841534775465
Validation loss: 2.3643592192317797

Epoch: 6| Step: 1
Training loss: 1.7164339586815978
Validation loss: 2.3892465566766834

Epoch: 6| Step: 2
Training loss: 2.12179458308471
Validation loss: 2.409139969136114

Epoch: 6| Step: 3
Training loss: 1.0781425253507941
Validation loss: 2.362372841044117

Epoch: 6| Step: 4
Training loss: 1.4915076499586766
Validation loss: 2.3331046620471914

Epoch: 6| Step: 5
Training loss: 1.5314545786688807
Validation loss: 2.406160101232026

Epoch: 6| Step: 6
Training loss: 1.477751964249626
Validation loss: 2.4000757358421287

Epoch: 6| Step: 7
Training loss: 1.1081357669898917
Validation loss: 2.3620444147215656

Epoch: 6| Step: 8
Training loss: 1.1819345156059209
Validation loss: 2.421214159286259

Epoch: 6| Step: 9
Training loss: 1.1335642983667928
Validation loss: 2.379136331185709

Epoch: 6| Step: 10
Training loss: 1.4106227705383936
Validation loss: 2.3662721297759597

Epoch: 6| Step: 11
Training loss: 1.5759190920379313
Validation loss: 2.372725676379947

Epoch: 6| Step: 12
Training loss: 1.8276567429982717
Validation loss: 2.458397833859362

Epoch: 6| Step: 13
Training loss: 1.7981090123032983
Validation loss: 2.3208610334035895

Epoch: 344| Step: 0
Training loss: 1.5706297900259292
Validation loss: 2.3662359582633132

Epoch: 6| Step: 1
Training loss: 1.5880290554088592
Validation loss: 2.429976677545719

Epoch: 6| Step: 2
Training loss: 1.367007390829002
Validation loss: 2.354848239412746

Epoch: 6| Step: 3
Training loss: 1.448305896430381
Validation loss: 2.4329317447022234

Epoch: 6| Step: 4
Training loss: 1.6777006951927231
Validation loss: 2.350791563031481

Epoch: 6| Step: 5
Training loss: 1.019196437069221
Validation loss: 2.3915945080875223

Epoch: 6| Step: 6
Training loss: 1.6389629846551081
Validation loss: 2.4098747066238744

Epoch: 6| Step: 7
Training loss: 1.9991570126659646
Validation loss: 2.3857947171460956

Epoch: 6| Step: 8
Training loss: 1.5022589046108343
Validation loss: 2.4266916362357223

Epoch: 6| Step: 9
Training loss: 1.6165318288645911
Validation loss: 2.4283860683838925

Epoch: 6| Step: 10
Training loss: 1.1707331880433132
Validation loss: 2.400275408011043

Epoch: 6| Step: 11
Training loss: 2.320164325748097
Validation loss: 2.3294495600337286

Epoch: 6| Step: 12
Training loss: 1.5556842924767502
Validation loss: 2.368141150355781

Epoch: 6| Step: 13
Training loss: 0.6493445337691842
Validation loss: 2.3618221998481275

Epoch: 345| Step: 0
Training loss: 2.150336851301712
Validation loss: 2.3845479464969053

Epoch: 6| Step: 1
Training loss: 1.1569269621404539
Validation loss: 2.2658161584806584

Epoch: 6| Step: 2
Training loss: 1.6631462906052064
Validation loss: 2.3273185626588253

Epoch: 6| Step: 3
Training loss: 1.4490883658023366
Validation loss: 2.294349038765026

Epoch: 6| Step: 4
Training loss: 1.1669112811912423
Validation loss: 2.383218254026288

Epoch: 6| Step: 5
Training loss: 1.1601473104729765
Validation loss: 2.3318395542878454

Epoch: 6| Step: 6
Training loss: 1.4012719098708382
Validation loss: 2.3863006854551663

Epoch: 6| Step: 7
Training loss: 2.092680245023151
Validation loss: 2.404828796540429

Epoch: 6| Step: 8
Training loss: 1.9829056473685194
Validation loss: 2.3759103594369155

Epoch: 6| Step: 9
Training loss: 1.6667558964049545
Validation loss: 2.4043362020836194

Epoch: 6| Step: 10
Training loss: 1.382899825792483
Validation loss: 2.390873665436754

Epoch: 6| Step: 11
Training loss: 1.2805257006043034
Validation loss: 2.373437149214275

Epoch: 6| Step: 12
Training loss: 1.0494781696071889
Validation loss: 2.3929136515201175

Epoch: 6| Step: 13
Training loss: 1.5749312461499667
Validation loss: 2.404019001649155

Epoch: 346| Step: 0
Training loss: 1.643135257542378
Validation loss: 2.3647175506349463

Epoch: 6| Step: 1
Training loss: 1.5669588935830694
Validation loss: 2.2723565104973757

Epoch: 6| Step: 2
Training loss: 1.8603077320131973
Validation loss: 2.376409668194477

Epoch: 6| Step: 3
Training loss: 1.7525231020026466
Validation loss: 2.4390061045251845

Epoch: 6| Step: 4
Training loss: 1.3834361593491147
Validation loss: 2.4522383021185328

Epoch: 6| Step: 5
Training loss: 1.4255162659101401
Validation loss: 2.455428868702949

Epoch: 6| Step: 6
Training loss: 1.2200621363966269
Validation loss: 2.3513087455054524

Epoch: 6| Step: 7
Training loss: 1.1566289332351916
Validation loss: 2.3973410044213876

Epoch: 6| Step: 8
Training loss: 1.3221162291837543
Validation loss: 2.350100405775078

Epoch: 6| Step: 9
Training loss: 1.9734035171881068
Validation loss: 2.3540239649311876

Epoch: 6| Step: 10
Training loss: 1.7351835273615033
Validation loss: 2.417228940602985

Epoch: 6| Step: 11
Training loss: 1.242684990449668
Validation loss: 2.37059629064741

Epoch: 6| Step: 12
Training loss: 1.7215491649466452
Validation loss: 2.3207609642953746

Epoch: 6| Step: 13
Training loss: 1.5619937839653013
Validation loss: 2.4573878922134202

Epoch: 347| Step: 0
Training loss: 1.7569151898119313
Validation loss: 2.3860339001917104

Epoch: 6| Step: 1
Training loss: 1.3886731197389155
Validation loss: 2.421599657150589

Epoch: 6| Step: 2
Training loss: 1.245445106558544
Validation loss: 2.33458181643095

Epoch: 6| Step: 3
Training loss: 1.5091126523953171
Validation loss: 2.34947455467957

Epoch: 6| Step: 4
Training loss: 2.0002758312752973
Validation loss: 2.3838997837294182

Epoch: 6| Step: 5
Training loss: 1.2282662191564375
Validation loss: 2.3269187757429117

Epoch: 6| Step: 6
Training loss: 1.4323013675245582
Validation loss: 2.404147626047499

Epoch: 6| Step: 7
Training loss: 1.4373600103796114
Validation loss: 2.3542008727348525

Epoch: 6| Step: 8
Training loss: 1.5599379324180902
Validation loss: 2.3944614197268295

Epoch: 6| Step: 9
Training loss: 1.3126384117168561
Validation loss: 2.4528578422109053

Epoch: 6| Step: 10
Training loss: 1.6222211846837482
Validation loss: 2.3835216008417106

Epoch: 6| Step: 11
Training loss: 1.5482006365302783
Validation loss: 2.4462065606191867

Epoch: 6| Step: 12
Training loss: 1.1472972996683528
Validation loss: 2.3687066913017643

Epoch: 6| Step: 13
Training loss: 1.498989082464627
Validation loss: 2.335919883212455

Epoch: 348| Step: 0
Training loss: 1.705252062827757
Validation loss: 2.3488627965207223

Epoch: 6| Step: 1
Training loss: 1.4871641757688718
Validation loss: 2.375836460932134

Epoch: 6| Step: 2
Training loss: 1.1816097539226669
Validation loss: 2.385613375635568

Epoch: 6| Step: 3
Training loss: 0.9580610068015507
Validation loss: 2.4437323763980596

Epoch: 6| Step: 4
Training loss: 1.517007413600844
Validation loss: 2.517640511171693

Epoch: 6| Step: 5
Training loss: 1.583757828811288
Validation loss: 2.3974085645588086

Epoch: 6| Step: 6
Training loss: 1.3099932574324316
Validation loss: 2.362885523775306

Epoch: 6| Step: 7
Training loss: 1.5772890955320775
Validation loss: 2.3520965367694524

Epoch: 6| Step: 8
Training loss: 1.7599012384014627
Validation loss: 2.3853476468199974

Epoch: 6| Step: 9
Training loss: 2.000957617383777
Validation loss: 2.417336616291813

Epoch: 6| Step: 10
Training loss: 1.592629281729498
Validation loss: 2.425290018010737

Epoch: 6| Step: 11
Training loss: 1.4015840050313753
Validation loss: 2.3293494818395617

Epoch: 6| Step: 12
Training loss: 1.2853283984246497
Validation loss: 2.4104073829531303

Epoch: 6| Step: 13
Training loss: 1.4951037126627844
Validation loss: 2.3844463414860253

Epoch: 349| Step: 0
Training loss: 1.536320601502364
Validation loss: 2.394283773372234

Epoch: 6| Step: 1
Training loss: 0.9532185492961034
Validation loss: 2.316206230566096

Epoch: 6| Step: 2
Training loss: 1.2825554965469204
Validation loss: 2.3487065916608167

Epoch: 6| Step: 3
Training loss: 1.4921994034057702
Validation loss: 2.3570820859129813

Epoch: 6| Step: 4
Training loss: 1.0366671494015698
Validation loss: 2.3776948640602438

Epoch: 6| Step: 5
Training loss: 1.4623404717451935
Validation loss: 2.346224812572668

Epoch: 6| Step: 6
Training loss: 1.0105670279611934
Validation loss: 2.429780043850992

Epoch: 6| Step: 7
Training loss: 1.376950527756859
Validation loss: 2.3733296184593105

Epoch: 6| Step: 8
Training loss: 1.9450158808434954
Validation loss: 2.3555947212283983

Epoch: 6| Step: 9
Training loss: 1.5540650621734797
Validation loss: 2.344333502760933

Epoch: 6| Step: 10
Training loss: 1.4625798749712018
Validation loss: 2.3563909040953326

Epoch: 6| Step: 11
Training loss: 1.2796043899991474
Validation loss: 2.4203221281107683

Epoch: 6| Step: 12
Training loss: 2.577075444062682
Validation loss: 2.368660487655479

Epoch: 6| Step: 13
Training loss: 1.5926813020609907
Validation loss: 2.3780028892102187

Epoch: 350| Step: 0
Training loss: 1.305739977619023
Validation loss: 2.4306458202033756

Epoch: 6| Step: 1
Training loss: 1.4061642938563503
Validation loss: 2.315941109188758

Epoch: 6| Step: 2
Training loss: 1.510153420845772
Validation loss: 2.3732436858393924

Epoch: 6| Step: 3
Training loss: 1.3242366193167723
Validation loss: 2.389533939025044

Epoch: 6| Step: 4
Training loss: 1.504859047812844
Validation loss: 2.41637310102162

Epoch: 6| Step: 5
Training loss: 1.427263800726202
Validation loss: 2.3945448051215776

Epoch: 6| Step: 6
Training loss: 1.4727749156952075
Validation loss: 2.3525082620706215

Epoch: 6| Step: 7
Training loss: 1.5721570469108255
Validation loss: 2.343971982445292

Epoch: 6| Step: 8
Training loss: 1.370873588427021
Validation loss: 2.4883980157225034

Epoch: 6| Step: 9
Training loss: 2.086257395699788
Validation loss: 2.4089168163734245

Epoch: 6| Step: 10
Training loss: 1.6504130164438877
Validation loss: 2.3964848349927204

Epoch: 6| Step: 11
Training loss: 1.7888728545176504
Validation loss: 2.402050257497067

Epoch: 6| Step: 12
Training loss: 1.5426980082878796
Validation loss: 2.4315741651697387

Epoch: 6| Step: 13
Training loss: 1.2075346356907624
Validation loss: 2.3654506932594037

Epoch: 351| Step: 0
Training loss: 1.2207970666977626
Validation loss: 2.3330658621652796

Epoch: 6| Step: 1
Training loss: 1.873671378839568
Validation loss: 2.3025190438200984

Epoch: 6| Step: 2
Training loss: 1.5598382021065835
Validation loss: 2.415374356934354

Epoch: 6| Step: 3
Training loss: 1.6595076427140059
Validation loss: 2.325124468268567

Epoch: 6| Step: 4
Training loss: 1.899501674955613
Validation loss: 2.372629306369875

Epoch: 6| Step: 5
Training loss: 1.1355868337428956
Validation loss: 2.404024513853195

Epoch: 6| Step: 6
Training loss: 1.3527148852044493
Validation loss: 2.4531935146742274

Epoch: 6| Step: 7
Training loss: 2.3585847453261053
Validation loss: 2.3514479164740405

Epoch: 6| Step: 8
Training loss: 1.4082653016055304
Validation loss: 2.4570626067848984

Epoch: 6| Step: 9
Training loss: 1.0893218181889401
Validation loss: 2.342171338195453

Epoch: 6| Step: 10
Training loss: 1.131227107369637
Validation loss: 2.430968243379676

Epoch: 6| Step: 11
Training loss: 1.2653423040699763
Validation loss: 2.3732270000626556

Epoch: 6| Step: 12
Training loss: 1.5632600080351855
Validation loss: 2.3474630590602725

Epoch: 6| Step: 13
Training loss: 1.4219313390280686
Validation loss: 2.373534577319646

Epoch: 352| Step: 0
Training loss: 1.574167104020604
Validation loss: 2.4169061653123722

Epoch: 6| Step: 1
Training loss: 2.2165733728877597
Validation loss: 2.4447065059411757

Epoch: 6| Step: 2
Training loss: 1.3745130196763382
Validation loss: 2.3777435967742586

Epoch: 6| Step: 3
Training loss: 1.3162714948647027
Validation loss: 2.3526231862429516

Epoch: 6| Step: 4
Training loss: 1.5825676656180505
Validation loss: 2.3956757991694224

Epoch: 6| Step: 5
Training loss: 1.0438072463000958
Validation loss: 2.423031153946483

Epoch: 6| Step: 6
Training loss: 1.0190222627942496
Validation loss: 2.406773557518799

Epoch: 6| Step: 7
Training loss: 1.2187914719005624
Validation loss: 2.4466086267514076

Epoch: 6| Step: 8
Training loss: 1.5417393675836955
Validation loss: 2.3729709664587215

Epoch: 6| Step: 9
Training loss: 1.8742226578742085
Validation loss: 2.404176757234557

Epoch: 6| Step: 10
Training loss: 1.6240894994643946
Validation loss: 2.4072074503490297

Epoch: 6| Step: 11
Training loss: 1.2940745623831735
Validation loss: 2.3796748189008072

Epoch: 6| Step: 12
Training loss: 1.3058923879747277
Validation loss: 2.4035044810868955

Epoch: 6| Step: 13
Training loss: 1.4322123095173707
Validation loss: 2.4101832088780877

Epoch: 353| Step: 0
Training loss: 1.336018743888918
Validation loss: 2.380186063101727

Epoch: 6| Step: 1
Training loss: 2.0463298042409024
Validation loss: 2.4094883691800377

Epoch: 6| Step: 2
Training loss: 1.3393976564400232
Validation loss: 2.419396893040069

Epoch: 6| Step: 3
Training loss: 1.692309765964518
Validation loss: 2.4577700418172355

Epoch: 6| Step: 4
Training loss: 1.6293091492978231
Validation loss: 2.2838568386042093

Epoch: 6| Step: 5
Training loss: 1.5446145852838284
Validation loss: 2.3537709180017328

Epoch: 6| Step: 6
Training loss: 1.1139723924575204
Validation loss: 2.332061676686014

Epoch: 6| Step: 7
Training loss: 1.2140331937377706
Validation loss: 2.3738114152089795

Epoch: 6| Step: 8
Training loss: 1.0428590181038975
Validation loss: 2.3269566447143744

Epoch: 6| Step: 9
Training loss: 1.2810733952576119
Validation loss: 2.3702329343560904

Epoch: 6| Step: 10
Training loss: 1.7697109779553286
Validation loss: 2.464367436719901

Epoch: 6| Step: 11
Training loss: 1.3126948529881048
Validation loss: 2.4105915109935414

Epoch: 6| Step: 12
Training loss: 1.952489093256733
Validation loss: 2.4708694959062822

Epoch: 6| Step: 13
Training loss: 1.4680073260506499
Validation loss: 2.408169335039574

Epoch: 354| Step: 0
Training loss: 1.2293230808544928
Validation loss: 2.3764589003017806

Epoch: 6| Step: 1
Training loss: 1.4740749173736147
Validation loss: 2.359828317316315

Epoch: 6| Step: 2
Training loss: 1.4433498769403743
Validation loss: 2.366227755633806

Epoch: 6| Step: 3
Training loss: 0.966346466262948
Validation loss: 2.4134269345237196

Epoch: 6| Step: 4
Training loss: 2.743891781421836
Validation loss: 2.4375943369946045

Epoch: 6| Step: 5
Training loss: 1.2082655438229
Validation loss: 2.5270292428096686

Epoch: 6| Step: 6
Training loss: 1.335857098931798
Validation loss: 2.411107947171664

Epoch: 6| Step: 7
Training loss: 1.1838045341715506
Validation loss: 2.370695057471682

Epoch: 6| Step: 8
Training loss: 1.5848263009378305
Validation loss: 2.4285885031012784

Epoch: 6| Step: 9
Training loss: 1.1872243059261325
Validation loss: 2.4158812729328933

Epoch: 6| Step: 10
Training loss: 1.8156823469287602
Validation loss: 2.4180945782596526

Epoch: 6| Step: 11
Training loss: 0.9932286364362742
Validation loss: 2.346851837802879

Epoch: 6| Step: 12
Training loss: 1.3651681428268798
Validation loss: 2.3979814822807897

Epoch: 6| Step: 13
Training loss: 1.6567005048605423
Validation loss: 2.362953517898267

Epoch: 355| Step: 0
Training loss: 1.2163304005754163
Validation loss: 2.3460079235972957

Epoch: 6| Step: 1
Training loss: 1.1799167132484147
Validation loss: 2.2892289093319675

Epoch: 6| Step: 2
Training loss: 1.4590021053191822
Validation loss: 2.374925592808059

Epoch: 6| Step: 3
Training loss: 0.6552540169352243
Validation loss: 2.4036177135807346

Epoch: 6| Step: 4
Training loss: 1.365155000794136
Validation loss: 2.3615962167353266

Epoch: 6| Step: 5
Training loss: 1.2792276844212616
Validation loss: 2.390680876927439

Epoch: 6| Step: 6
Training loss: 1.3005644929844837
Validation loss: 2.3714727656406276

Epoch: 6| Step: 7
Training loss: 1.9423253667975844
Validation loss: 2.341105563376923

Epoch: 6| Step: 8
Training loss: 2.2893400577312364
Validation loss: 2.35275149536556

Epoch: 6| Step: 9
Training loss: 1.426619275604264
Validation loss: 2.384030324847655

Epoch: 6| Step: 10
Training loss: 1.2452337950912094
Validation loss: 2.407314986971331

Epoch: 6| Step: 11
Training loss: 1.3446744356046019
Validation loss: 2.375792284312602

Epoch: 6| Step: 12
Training loss: 1.6738607432370962
Validation loss: 2.3374379820397317

Epoch: 6| Step: 13
Training loss: 1.0740966727508985
Validation loss: 2.394859046489312

Epoch: 356| Step: 0
Training loss: 1.254323444304833
Validation loss: 2.395905498329115

Epoch: 6| Step: 1
Training loss: 1.6854883141804244
Validation loss: 2.345944465198238

Epoch: 6| Step: 2
Training loss: 1.3075913874706901
Validation loss: 2.3864087774443505

Epoch: 6| Step: 3
Training loss: 1.1565476627217557
Validation loss: 2.3913365891531115

Epoch: 6| Step: 4
Training loss: 1.3776386691738294
Validation loss: 2.455554893381397

Epoch: 6| Step: 5
Training loss: 1.2595332914694817
Validation loss: 2.4056826581745603

Epoch: 6| Step: 6
Training loss: 1.4020012992602544
Validation loss: 2.434306113913284

Epoch: 6| Step: 7
Training loss: 1.3879966328165068
Validation loss: 2.3682170870525616

Epoch: 6| Step: 8
Training loss: 1.5185989618746734
Validation loss: 2.4584080643207535

Epoch: 6| Step: 9
Training loss: 1.168764385604043
Validation loss: 2.3902374088497016

Epoch: 6| Step: 10
Training loss: 1.2926181191015114
Validation loss: 2.3543644218645245

Epoch: 6| Step: 11
Training loss: 1.796748148545521
Validation loss: 2.414788204742556

Epoch: 6| Step: 12
Training loss: 1.429694253874288
Validation loss: 2.412432783583475

Epoch: 6| Step: 13
Training loss: 2.8849770294808805
Validation loss: 2.469126759704923

Epoch: 357| Step: 0
Training loss: 1.2025462157950715
Validation loss: 2.3676982047020436

Epoch: 6| Step: 1
Training loss: 1.7853030221648447
Validation loss: 2.378570696239818

Epoch: 6| Step: 2
Training loss: 1.0060197128351487
Validation loss: 2.368051916456106

Epoch: 6| Step: 3
Training loss: 1.524943932299914
Validation loss: 2.354212147843907

Epoch: 6| Step: 4
Training loss: 1.9967484865422864
Validation loss: 2.3851660294831736

Epoch: 6| Step: 5
Training loss: 1.3684563117031177
Validation loss: 2.4170215860209074

Epoch: 6| Step: 6
Training loss: 1.127246309485436
Validation loss: 2.3854841645560576

Epoch: 6| Step: 7
Training loss: 0.9494678186243125
Validation loss: 2.391254760057486

Epoch: 6| Step: 8
Training loss: 1.3991285779599332
Validation loss: 2.362095454025559

Epoch: 6| Step: 9
Training loss: 2.1658269526568783
Validation loss: 2.390864030615944

Epoch: 6| Step: 10
Training loss: 1.2522578828136677
Validation loss: 2.4017209474034695

Epoch: 6| Step: 11
Training loss: 1.266858853433446
Validation loss: 2.354758442441924

Epoch: 6| Step: 12
Training loss: 1.5991251938163087
Validation loss: 2.3127950986123498

Epoch: 6| Step: 13
Training loss: 1.71876782494752
Validation loss: 2.412864399696798

Epoch: 358| Step: 0
Training loss: 1.5630171873547356
Validation loss: 2.498307142026476

Epoch: 6| Step: 1
Training loss: 1.7218402478264452
Validation loss: 2.369861765548985

Epoch: 6| Step: 2
Training loss: 1.5739409625215992
Validation loss: 2.4296752456679407

Epoch: 6| Step: 3
Training loss: 1.3019087661708229
Validation loss: 2.4569740674158096

Epoch: 6| Step: 4
Training loss: 1.2599648961218042
Validation loss: 2.3832786949922924

Epoch: 6| Step: 5
Training loss: 1.494689521445236
Validation loss: 2.37436689931301

Epoch: 6| Step: 6
Training loss: 1.2737461956293048
Validation loss: 2.4057547852487717

Epoch: 6| Step: 7
Training loss: 1.1353726626393854
Validation loss: 2.398580420961824

Epoch: 6| Step: 8
Training loss: 1.725733631421684
Validation loss: 2.3406186379019367

Epoch: 6| Step: 9
Training loss: 1.4786175348794985
Validation loss: 2.3573203318799076

Epoch: 6| Step: 10
Training loss: 1.413283665761997
Validation loss: 2.39919330317378

Epoch: 6| Step: 11
Training loss: 1.2433895796529544
Validation loss: 2.3507057836710112

Epoch: 6| Step: 12
Training loss: 2.1289386151854597
Validation loss: 2.403093401295227

Epoch: 6| Step: 13
Training loss: 0.9631944219681978
Validation loss: 2.3665499445087805

Epoch: 359| Step: 0
Training loss: 1.4219826458436708
Validation loss: 2.308608152843862

Epoch: 6| Step: 1
Training loss: 1.3418762538923599
Validation loss: 2.3612970896212113

Epoch: 6| Step: 2
Training loss: 1.6021453541167148
Validation loss: 2.3970563665778952

Epoch: 6| Step: 3
Training loss: 1.578039639118934
Validation loss: 2.3387408197880397

Epoch: 6| Step: 4
Training loss: 1.6075178374966397
Validation loss: 2.309082028474394

Epoch: 6| Step: 5
Training loss: 1.488614583170467
Validation loss: 2.3699163238903296

Epoch: 6| Step: 6
Training loss: 2.0541771084389175
Validation loss: 2.387950492036986

Epoch: 6| Step: 7
Training loss: 1.4249651519797562
Validation loss: 2.3838458132033833

Epoch: 6| Step: 8
Training loss: 1.5642446314722782
Validation loss: 2.3680253881344586

Epoch: 6| Step: 9
Training loss: 1.6075024126903885
Validation loss: 2.4941030644628914

Epoch: 6| Step: 10
Training loss: 1.2984902308070487
Validation loss: 2.3448924484443183

Epoch: 6| Step: 11
Training loss: 1.4948872215574596
Validation loss: 2.3791357223693392

Epoch: 6| Step: 12
Training loss: 1.6913438041031097
Validation loss: 2.418590488713711

Epoch: 6| Step: 13
Training loss: 1.3385410927302495
Validation loss: 2.4258563662652706

Epoch: 360| Step: 0
Training loss: 1.1883256952825887
Validation loss: 2.416673064798012

Epoch: 6| Step: 1
Training loss: 1.2668371635850528
Validation loss: 2.393194334375717

Epoch: 6| Step: 2
Training loss: 1.453251986953897
Validation loss: 2.3761393874714516

Epoch: 6| Step: 3
Training loss: 1.2821134123663942
Validation loss: 2.3738590969422546

Epoch: 6| Step: 4
Training loss: 2.0772134029127183
Validation loss: 2.4248660361496848

Epoch: 6| Step: 5
Training loss: 1.5902111182014984
Validation loss: 2.4128723152230114

Epoch: 6| Step: 6
Training loss: 1.9406265135926566
Validation loss: 2.3694061402930173

Epoch: 6| Step: 7
Training loss: 1.445051674892331
Validation loss: 2.3796588396892395

Epoch: 6| Step: 8
Training loss: 1.964402500000149
Validation loss: 2.3772194923659664

Epoch: 6| Step: 9
Training loss: 1.2953107661292018
Validation loss: 2.3584597207889977

Epoch: 6| Step: 10
Training loss: 1.2136965422246087
Validation loss: 2.4068076972753167

Epoch: 6| Step: 11
Training loss: 1.4188412170663127
Validation loss: 2.4037222112124703

Epoch: 6| Step: 12
Training loss: 1.6126209598091763
Validation loss: 2.3335905500964103

Epoch: 6| Step: 13
Training loss: 1.7280583870657484
Validation loss: 2.4200878884053068

Epoch: 361| Step: 0
Training loss: 2.0523237549062263
Validation loss: 2.410934006040057

Epoch: 6| Step: 1
Training loss: 1.25481598078663
Validation loss: 2.3252618079038645

Epoch: 6| Step: 2
Training loss: 1.4435744273782254
Validation loss: 2.359524302249945

Epoch: 6| Step: 3
Training loss: 1.2428069579432757
Validation loss: 2.3149165060569654

Epoch: 6| Step: 4
Training loss: 1.5235522887192916
Validation loss: 2.3997681573264718

Epoch: 6| Step: 5
Training loss: 1.649750823655308
Validation loss: 2.323127469570582

Epoch: 6| Step: 6
Training loss: 1.3334229657722279
Validation loss: 2.319228295376346

Epoch: 6| Step: 7
Training loss: 1.2756755796775179
Validation loss: 2.3638881196029695

Epoch: 6| Step: 8
Training loss: 1.0411625341564725
Validation loss: 2.4067878691988738

Epoch: 6| Step: 9
Training loss: 1.9900231665791552
Validation loss: 2.3722216271565277

Epoch: 6| Step: 10
Training loss: 1.281787712960495
Validation loss: 2.4539210857482447

Epoch: 6| Step: 11
Training loss: 1.3587091064616261
Validation loss: 2.3868789937268255

Epoch: 6| Step: 12
Training loss: 1.3200144233782583
Validation loss: 2.40706503949232

Epoch: 6| Step: 13
Training loss: 1.4944077994633198
Validation loss: 2.4521100873741597

Epoch: 362| Step: 0
Training loss: 1.501214807051816
Validation loss: 2.350948466295369

Epoch: 6| Step: 1
Training loss: 1.3773786171466578
Validation loss: 2.386929789569608

Epoch: 6| Step: 2
Training loss: 1.6246437269074974
Validation loss: 2.3688086521680667

Epoch: 6| Step: 3
Training loss: 1.2706253736263688
Validation loss: 2.3306566078732973

Epoch: 6| Step: 4
Training loss: 1.5246862526505598
Validation loss: 2.3752973140504374

Epoch: 6| Step: 5
Training loss: 1.363645226276381
Validation loss: 2.3962862960690083

Epoch: 6| Step: 6
Training loss: 1.0433194146025155
Validation loss: 2.3757183195471328

Epoch: 6| Step: 7
Training loss: 0.9986556374537572
Validation loss: 2.3652098498205865

Epoch: 6| Step: 8
Training loss: 1.8321693221974371
Validation loss: 2.311294058302595

Epoch: 6| Step: 9
Training loss: 1.316477244469147
Validation loss: 2.352491676051074

Epoch: 6| Step: 10
Training loss: 2.189521400550919
Validation loss: 2.388970436468432

Epoch: 6| Step: 11
Training loss: 1.5183197134072164
Validation loss: 2.3331513599406866

Epoch: 6| Step: 12
Training loss: 1.4258008145596888
Validation loss: 2.338550146009744

Epoch: 6| Step: 13
Training loss: 0.8570944958338408
Validation loss: 2.3595039084177487

Epoch: 363| Step: 0
Training loss: 1.5494246614844527
Validation loss: 2.3279321434701328

Epoch: 6| Step: 1
Training loss: 1.1913217983644473
Validation loss: 2.3582354062139563

Epoch: 6| Step: 2
Training loss: 1.5170911009911914
Validation loss: 2.4088391221010936

Epoch: 6| Step: 3
Training loss: 1.1924158040199373
Validation loss: 2.350668360004773

Epoch: 6| Step: 4
Training loss: 1.3240452655591628
Validation loss: 2.361425627676418

Epoch: 6| Step: 5
Training loss: 2.034185078980493
Validation loss: 2.403352833002097

Epoch: 6| Step: 6
Training loss: 1.2635547990527956
Validation loss: 2.328728798437898

Epoch: 6| Step: 7
Training loss: 1.7223261302789747
Validation loss: 2.418219081163448

Epoch: 6| Step: 8
Training loss: 1.5096696870037605
Validation loss: 2.366779969316897

Epoch: 6| Step: 9
Training loss: 1.3909727369004812
Validation loss: 2.351454846024023

Epoch: 6| Step: 10
Training loss: 1.6219502955251666
Validation loss: 2.366593162727405

Epoch: 6| Step: 11
Training loss: 1.1228954976102927
Validation loss: 2.3940587641458806

Epoch: 6| Step: 12
Training loss: 1.3012937160627793
Validation loss: 2.375818466666183

Epoch: 6| Step: 13
Training loss: 1.3853550182575325
Validation loss: 2.4102445212534307

Epoch: 364| Step: 0
Training loss: 1.3355558865363935
Validation loss: 2.4506898498955465

Epoch: 6| Step: 1
Training loss: 1.2832925843709377
Validation loss: 2.352489978211463

Epoch: 6| Step: 2
Training loss: 1.3355085788624077
Validation loss: 2.3880660025431872

Epoch: 6| Step: 3
Training loss: 1.2520623836362088
Validation loss: 2.362643111335247

Epoch: 6| Step: 4
Training loss: 1.379277252342895
Validation loss: 2.3979727777932474

Epoch: 6| Step: 5
Training loss: 1.052037222327024
Validation loss: 2.3262857441103533

Epoch: 6| Step: 6
Training loss: 1.1043266624316752
Validation loss: 2.348061309929543

Epoch: 6| Step: 7
Training loss: 1.7294560002698844
Validation loss: 2.3806926473045182

Epoch: 6| Step: 8
Training loss: 1.0375871437886581
Validation loss: 2.34869950937672

Epoch: 6| Step: 9
Training loss: 1.4111682926984233
Validation loss: 2.368223574581669

Epoch: 6| Step: 10
Training loss: 1.955719772973255
Validation loss: 2.3834762501421154

Epoch: 6| Step: 11
Training loss: 2.0038981595535996
Validation loss: 2.3774719370436834

Epoch: 6| Step: 12
Training loss: 1.4780830748340366
Validation loss: 2.35865504648525

Epoch: 6| Step: 13
Training loss: 1.480751835876182
Validation loss: 2.368112445180385

Epoch: 365| Step: 0
Training loss: 1.7271757115720476
Validation loss: 2.425022955691624

Epoch: 6| Step: 1
Training loss: 1.3685668962189133
Validation loss: 2.33135594647911

Epoch: 6| Step: 2
Training loss: 1.010523616728085
Validation loss: 2.4138939582240018

Epoch: 6| Step: 3
Training loss: 1.4786562329936914
Validation loss: 2.368508780969204

Epoch: 6| Step: 4
Training loss: 1.399933850905467
Validation loss: 2.3108996019766486

Epoch: 6| Step: 5
Training loss: 1.3874233121556798
Validation loss: 2.35779873265847

Epoch: 6| Step: 6
Training loss: 2.275137039919802
Validation loss: 2.399594355727075

Epoch: 6| Step: 7
Training loss: 1.4635467891218834
Validation loss: 2.417431950640731

Epoch: 6| Step: 8
Training loss: 1.1982610401016653
Validation loss: 2.433817883939597

Epoch: 6| Step: 9
Training loss: 0.8769696410393159
Validation loss: 2.418215421571875

Epoch: 6| Step: 10
Training loss: 1.1586027179764498
Validation loss: 2.4562814717135826

Epoch: 6| Step: 11
Training loss: 1.8400908545163621
Validation loss: 2.333017339565794

Epoch: 6| Step: 12
Training loss: 1.3462005271782507
Validation loss: 2.375408686872939

Epoch: 6| Step: 13
Training loss: 1.5963460684524744
Validation loss: 2.361050198022809

Epoch: 366| Step: 0
Training loss: 1.1144310083611504
Validation loss: 2.341131074747023

Epoch: 6| Step: 1
Training loss: 1.6070540645836253
Validation loss: 2.357327050588885

Epoch: 6| Step: 2
Training loss: 1.8836412307533108
Validation loss: 2.4449568120918186

Epoch: 6| Step: 3
Training loss: 1.3003588382941738
Validation loss: 2.3751361297341282

Epoch: 6| Step: 4
Training loss: 1.6833617721018634
Validation loss: 2.382351790118303

Epoch: 6| Step: 5
Training loss: 1.0697971411951548
Validation loss: 2.362934659016432

Epoch: 6| Step: 6
Training loss: 1.3977855675855433
Validation loss: 2.337383672462712

Epoch: 6| Step: 7
Training loss: 1.2974440004321988
Validation loss: 2.3907833975832573

Epoch: 6| Step: 8
Training loss: 1.5142775375988593
Validation loss: 2.3840450080179547

Epoch: 6| Step: 9
Training loss: 1.6033752602999076
Validation loss: 2.3826152588755005

Epoch: 6| Step: 10
Training loss: 1.2511518893043576
Validation loss: 2.3504191619780515

Epoch: 6| Step: 11
Training loss: 1.7311199676486801
Validation loss: 2.4114063088736404

Epoch: 6| Step: 12
Training loss: 1.4901436594378876
Validation loss: 2.3797647771932176

Epoch: 6| Step: 13
Training loss: 1.509132637484241
Validation loss: 2.3517501080847394

Epoch: 367| Step: 0
Training loss: 1.9384728727137428
Validation loss: 2.4055700845090247

Epoch: 6| Step: 1
Training loss: 1.2572406866973043
Validation loss: 2.358413799302693

Epoch: 6| Step: 2
Training loss: 1.6454581142810265
Validation loss: 2.3785290860508783

Epoch: 6| Step: 3
Training loss: 1.3883558469017743
Validation loss: 2.396225509183322

Epoch: 6| Step: 4
Training loss: 0.883520466997589
Validation loss: 2.4122087998607817

Epoch: 6| Step: 5
Training loss: 0.72873723236468
Validation loss: 2.4383563937086437

Epoch: 6| Step: 6
Training loss: 1.4906008608480956
Validation loss: 2.3989327964709277

Epoch: 6| Step: 7
Training loss: 1.6102388896585496
Validation loss: 2.37454881360115

Epoch: 6| Step: 8
Training loss: 1.47289300528176
Validation loss: 2.3446807544561237

Epoch: 6| Step: 9
Training loss: 1.6615685054720029
Validation loss: 2.395812770617942

Epoch: 6| Step: 10
Training loss: 1.2958659647342077
Validation loss: 2.3272589331886944

Epoch: 6| Step: 11
Training loss: 1.3072980244799826
Validation loss: 2.3658634174180673

Epoch: 6| Step: 12
Training loss: 2.178272950498858
Validation loss: 2.3935591281105575

Epoch: 6| Step: 13
Training loss: 1.4653106352309557
Validation loss: 2.4460647538790576

Epoch: 368| Step: 0
Training loss: 1.2591500604385697
Validation loss: 2.387982043083439

Epoch: 6| Step: 1
Training loss: 1.3012362763984797
Validation loss: 2.307991996724922

Epoch: 6| Step: 2
Training loss: 1.2767266232195607
Validation loss: 2.3707502454540266

Epoch: 6| Step: 3
Training loss: 1.528378265549589
Validation loss: 2.3680575020972685

Epoch: 6| Step: 4
Training loss: 1.3809895541758004
Validation loss: 2.4096309043907187

Epoch: 6| Step: 5
Training loss: 1.1081013419976364
Validation loss: 2.4006155725613056

Epoch: 6| Step: 6
Training loss: 1.8356984084260677
Validation loss: 2.362788890757653

Epoch: 6| Step: 7
Training loss: 1.0783951462349202
Validation loss: 2.352327186971164

Epoch: 6| Step: 8
Training loss: 0.8816069076371316
Validation loss: 2.4201881962466167

Epoch: 6| Step: 9
Training loss: 1.6675884876478795
Validation loss: 2.373560261277757

Epoch: 6| Step: 10
Training loss: 1.1227797746228982
Validation loss: 2.291252570527485

Epoch: 6| Step: 11
Training loss: 0.8818204589026026
Validation loss: 2.3889489622624125

Epoch: 6| Step: 12
Training loss: 2.1928519038106287
Validation loss: 2.3807159549953174

Epoch: 6| Step: 13
Training loss: 2.102866296600179
Validation loss: 2.3716465591313787

Epoch: 369| Step: 0
Training loss: 1.3590299234106382
Validation loss: 2.4181235557398773

Epoch: 6| Step: 1
Training loss: 1.2325259495725147
Validation loss: 2.3414511461616616

Epoch: 6| Step: 2
Training loss: 0.9504527794849035
Validation loss: 2.358311143341195

Epoch: 6| Step: 3
Training loss: 2.1310953347028003
Validation loss: 2.304741423212249

Epoch: 6| Step: 4
Training loss: 1.5444679413219429
Validation loss: 2.377388628410898

Epoch: 6| Step: 5
Training loss: 1.307117050282429
Validation loss: 2.3333051660774236

Epoch: 6| Step: 6
Training loss: 1.8614893840412288
Validation loss: 2.382855594325338

Epoch: 6| Step: 7
Training loss: 1.454814134242464
Validation loss: 2.3675248847727186

Epoch: 6| Step: 8
Training loss: 1.0864178809403762
Validation loss: 2.4000405379088274

Epoch: 6| Step: 9
Training loss: 1.221079727063045
Validation loss: 2.3864256412310088

Epoch: 6| Step: 10
Training loss: 1.6269289452266076
Validation loss: 2.3589690006549664

Epoch: 6| Step: 11
Training loss: 1.6078670807555708
Validation loss: 2.404099891895304

Epoch: 6| Step: 12
Training loss: 0.8498403301054479
Validation loss: 2.369186430817312

Epoch: 6| Step: 13
Training loss: 1.658962188349589
Validation loss: 2.4774867344951628

Epoch: 370| Step: 0
Training loss: 1.314850654969243
Validation loss: 2.292500837614881

Epoch: 6| Step: 1
Training loss: 1.333154065279837
Validation loss: 2.441377349879351

Epoch: 6| Step: 2
Training loss: 0.913097034733701
Validation loss: 2.437352367691565

Epoch: 6| Step: 3
Training loss: 1.3603840733002714
Validation loss: 2.3333605517134433

Epoch: 6| Step: 4
Training loss: 1.6533159142135456
Validation loss: 2.3926756763975665

Epoch: 6| Step: 5
Training loss: 1.4342322317974041
Validation loss: 2.370146576868681

Epoch: 6| Step: 6
Training loss: 2.0998108097413306
Validation loss: 2.352834904365135

Epoch: 6| Step: 7
Training loss: 1.097086150883757
Validation loss: 2.310125006605108

Epoch: 6| Step: 8
Training loss: 1.6971156643376606
Validation loss: 2.359672250041722

Epoch: 6| Step: 9
Training loss: 1.2450637147678354
Validation loss: 2.4131018456894866

Epoch: 6| Step: 10
Training loss: 1.1351329320624781
Validation loss: 2.4163680530367375

Epoch: 6| Step: 11
Training loss: 1.2596110404337835
Validation loss: 2.3992542285713334

Epoch: 6| Step: 12
Training loss: 1.9682548748059194
Validation loss: 2.350335084239639

Epoch: 6| Step: 13
Training loss: 1.2344074969299512
Validation loss: 2.330987081019848

Epoch: 371| Step: 0
Training loss: 1.4819218492121105
Validation loss: 2.364556685414945

Epoch: 6| Step: 1
Training loss: 1.9024948906046648
Validation loss: 2.3286533255895354

Epoch: 6| Step: 2
Training loss: 1.570666372936029
Validation loss: 2.3825289122608635

Epoch: 6| Step: 3
Training loss: 1.2966894913325908
Validation loss: 2.3986907565536937

Epoch: 6| Step: 4
Training loss: 1.3995153013825952
Validation loss: 2.492597178726543

Epoch: 6| Step: 5
Training loss: 1.2840440569713838
Validation loss: 2.3844360759191083

Epoch: 6| Step: 6
Training loss: 1.5708958695137067
Validation loss: 2.329826006111813

Epoch: 6| Step: 7
Training loss: 2.1730491702629777
Validation loss: 2.405717617974145

Epoch: 6| Step: 8
Training loss: 0.9588802926011087
Validation loss: 2.304897337034347

Epoch: 6| Step: 9
Training loss: 1.093615714412767
Validation loss: 2.3610336166330326

Epoch: 6| Step: 10
Training loss: 1.0156037548484067
Validation loss: 2.3894584598315505

Epoch: 6| Step: 11
Training loss: 1.1936510794032973
Validation loss: 2.3499916320875216

Epoch: 6| Step: 12
Training loss: 1.462935280213803
Validation loss: 2.4047215026789623

Epoch: 6| Step: 13
Training loss: 1.2208083938985008
Validation loss: 2.3580178139492487

Epoch: 372| Step: 0
Training loss: 1.3127774444890328
Validation loss: 2.330058333833729

Epoch: 6| Step: 1
Training loss: 1.4441010217702503
Validation loss: 2.408676485904677

Epoch: 6| Step: 2
Training loss: 1.300770894143978
Validation loss: 2.393055528998837

Epoch: 6| Step: 3
Training loss: 1.2301519561347654
Validation loss: 2.37029579819657

Epoch: 6| Step: 4
Training loss: 1.4731680792626145
Validation loss: 2.3625857601821783

Epoch: 6| Step: 5
Training loss: 1.16683246365432
Validation loss: 2.4083310123166584

Epoch: 6| Step: 6
Training loss: 1.2970949928567606
Validation loss: 2.3557714074206664

Epoch: 6| Step: 7
Training loss: 1.4345714758653383
Validation loss: 2.383790640181359

Epoch: 6| Step: 8
Training loss: 1.3623841840184385
Validation loss: 2.3932236835156666

Epoch: 6| Step: 9
Training loss: 1.3859780926012037
Validation loss: 2.3559594202876974

Epoch: 6| Step: 10
Training loss: 1.0345638091300813
Validation loss: 2.358876643539064

Epoch: 6| Step: 11
Training loss: 2.0825217637187623
Validation loss: 2.3688229302352046

Epoch: 6| Step: 12
Training loss: 1.003057157890284
Validation loss: 2.403599134823987

Epoch: 6| Step: 13
Training loss: 1.2033540581972884
Validation loss: 2.477482230116723

Epoch: 373| Step: 0
Training loss: 1.5182941176413036
Validation loss: 2.3228840269465203

Epoch: 6| Step: 1
Training loss: 1.3664542275365295
Validation loss: 2.3556996653075783

Epoch: 6| Step: 2
Training loss: 0.8613943476748125
Validation loss: 2.421985679000183

Epoch: 6| Step: 3
Training loss: 1.282808983597019
Validation loss: 2.388022353826153

Epoch: 6| Step: 4
Training loss: 1.2864893344536377
Validation loss: 2.3728909889158647

Epoch: 6| Step: 5
Training loss: 2.196074546966136
Validation loss: 2.421856585646642

Epoch: 6| Step: 6
Training loss: 1.7664463529627805
Validation loss: 2.3867933341113674

Epoch: 6| Step: 7
Training loss: 1.044337028758255
Validation loss: 2.406224052886997

Epoch: 6| Step: 8
Training loss: 1.5297852341755087
Validation loss: 2.348677493962687

Epoch: 6| Step: 9
Training loss: 1.6800012339859927
Validation loss: 2.3967302381485474

Epoch: 6| Step: 10
Training loss: 1.0966707740482606
Validation loss: 2.366228515117669

Epoch: 6| Step: 11
Training loss: 1.1657727881619018
Validation loss: 2.3047801821402216

Epoch: 6| Step: 12
Training loss: 1.5002297384441432
Validation loss: 2.327940824625855

Epoch: 6| Step: 13
Training loss: 1.0294925279350782
Validation loss: 2.376598605429624

Epoch: 374| Step: 0
Training loss: 1.4569835501627828
Validation loss: 2.3317110916424677

Epoch: 6| Step: 1
Training loss: 1.4981350431396063
Validation loss: 2.36768832344555

Epoch: 6| Step: 2
Training loss: 1.4522438248870633
Validation loss: 2.381426182305208

Epoch: 6| Step: 3
Training loss: 1.105184403908579
Validation loss: 2.3434169157970905

Epoch: 6| Step: 4
Training loss: 1.8591530931912867
Validation loss: 2.34834339308975

Epoch: 6| Step: 5
Training loss: 1.2202800536390763
Validation loss: 2.4084683843637404

Epoch: 6| Step: 6
Training loss: 1.6352762862616421
Validation loss: 2.359893610354963

Epoch: 6| Step: 7
Training loss: 1.31070914024332
Validation loss: 2.391069881687947

Epoch: 6| Step: 8
Training loss: 0.985330209037549
Validation loss: 2.477046806495088

Epoch: 6| Step: 9
Training loss: 1.9165619393084614
Validation loss: 2.5110919986769726

Epoch: 6| Step: 10
Training loss: 1.4506237694350073
Validation loss: 2.4032685240760867

Epoch: 6| Step: 11
Training loss: 1.3581174975423655
Validation loss: 2.3760195445168435

Epoch: 6| Step: 12
Training loss: 1.1584696728355208
Validation loss: 2.3700636657014806

Epoch: 6| Step: 13
Training loss: 1.0088694153622748
Validation loss: 2.476062491660319

Epoch: 375| Step: 0
Training loss: 1.3216731717758152
Validation loss: 2.350033721385157

Epoch: 6| Step: 1
Training loss: 1.4055663248302102
Validation loss: 2.338420022191927

Epoch: 6| Step: 2
Training loss: 1.3241494309728243
Validation loss: 2.3954327131104947

Epoch: 6| Step: 3
Training loss: 1.1401859117632895
Validation loss: 2.445028694900942

Epoch: 6| Step: 4
Training loss: 1.2401572856824254
Validation loss: 2.3474872951396817

Epoch: 6| Step: 5
Training loss: 1.2283120282282451
Validation loss: 2.365171991210806

Epoch: 6| Step: 6
Training loss: 2.377105682918808
Validation loss: 2.3773398388156424

Epoch: 6| Step: 7
Training loss: 1.408389223370415
Validation loss: 2.420026866730145

Epoch: 6| Step: 8
Training loss: 1.36687317640953
Validation loss: 2.357801672722802

Epoch: 6| Step: 9
Training loss: 1.5027959514998976
Validation loss: 2.3399400235362076

Epoch: 6| Step: 10
Training loss: 1.5329746732168688
Validation loss: 2.350694791655525

Epoch: 6| Step: 11
Training loss: 1.0768344175869289
Validation loss: 2.3711741968441107

Epoch: 6| Step: 12
Training loss: 1.1838202432901128
Validation loss: 2.3785237723624624

Epoch: 6| Step: 13
Training loss: 1.8213196943637184
Validation loss: 2.3773196905541996

Epoch: 376| Step: 0
Training loss: 1.1246513780207827
Validation loss: 2.373825353776512

Epoch: 6| Step: 1
Training loss: 1.1750193817488082
Validation loss: 2.3991370095436393

Epoch: 6| Step: 2
Training loss: 1.2956725831409905
Validation loss: 2.4006698911732314

Epoch: 6| Step: 3
Training loss: 1.8281054373452506
Validation loss: 2.317254674650569

Epoch: 6| Step: 4
Training loss: 0.8122292581048516
Validation loss: 2.3569026756268836

Epoch: 6| Step: 5
Training loss: 1.1692289870264008
Validation loss: 2.349762293152588

Epoch: 6| Step: 6
Training loss: 2.2991057481907013
Validation loss: 2.336957983462797

Epoch: 6| Step: 7
Training loss: 1.7694142283972578
Validation loss: 2.4273627495896815

Epoch: 6| Step: 8
Training loss: 1.6403782250232326
Validation loss: 2.394756740458527

Epoch: 6| Step: 9
Training loss: 1.02538632346568
Validation loss: 2.3378523481141498

Epoch: 6| Step: 10
Training loss: 1.390908630249754
Validation loss: 2.325624441012347

Epoch: 6| Step: 11
Training loss: 1.2910237968520917
Validation loss: 2.3781919844571537

Epoch: 6| Step: 12
Training loss: 1.2385692562348842
Validation loss: 2.3956246708283593

Epoch: 6| Step: 13
Training loss: 0.9005798008713202
Validation loss: 2.3706275043781604

Epoch: 377| Step: 0
Training loss: 0.9035577245552971
Validation loss: 2.419246966510527

Epoch: 6| Step: 1
Training loss: 1.5754875578926235
Validation loss: 2.3804063116665133

Epoch: 6| Step: 2
Training loss: 1.502964031776409
Validation loss: 2.3144270282459805

Epoch: 6| Step: 3
Training loss: 1.4516616343963211
Validation loss: 2.353916774216653

Epoch: 6| Step: 4
Training loss: 1.0285428667644205
Validation loss: 2.4176051793067193

Epoch: 6| Step: 5
Training loss: 1.1238655092069665
Validation loss: 2.2982336739708953

Epoch: 6| Step: 6
Training loss: 0.9550043557352326
Validation loss: 2.3617856405133297

Epoch: 6| Step: 7
Training loss: 1.422929728919525
Validation loss: 2.3348638383007256

Epoch: 6| Step: 8
Training loss: 1.1874897605052988
Validation loss: 2.4054784860369867

Epoch: 6| Step: 9
Training loss: 2.311632354452342
Validation loss: 2.3804768827083578

Epoch: 6| Step: 10
Training loss: 1.0917683224023906
Validation loss: 2.4000346394913796

Epoch: 6| Step: 11
Training loss: 1.38259519604533
Validation loss: 2.364398164280924

Epoch: 6| Step: 12
Training loss: 1.7331998125637436
Validation loss: 2.3490021751581036

Epoch: 6| Step: 13
Training loss: 1.0992774801283163
Validation loss: 2.3165673723835503

Epoch: 378| Step: 0
Training loss: 2.0377931114880803
Validation loss: 2.420261536037957

Epoch: 6| Step: 1
Training loss: 1.3806462966568114
Validation loss: 2.404285146484174

Epoch: 6| Step: 2
Training loss: 1.081335291502842
Validation loss: 2.3767356402650974

Epoch: 6| Step: 3
Training loss: 1.1369419992930465
Validation loss: 2.4033540095646435

Epoch: 6| Step: 4
Training loss: 1.5770494176055703
Validation loss: 2.3423631038910866

Epoch: 6| Step: 5
Training loss: 1.4648616535364234
Validation loss: 2.4191009989236822

Epoch: 6| Step: 6
Training loss: 1.0400355092735665
Validation loss: 2.389201955233336

Epoch: 6| Step: 7
Training loss: 1.3966293579814741
Validation loss: 2.4520600824339924

Epoch: 6| Step: 8
Training loss: 1.1564964856507918
Validation loss: 2.3422527789540926

Epoch: 6| Step: 9
Training loss: 1.5013242280445698
Validation loss: 2.3706632725686507

Epoch: 6| Step: 10
Training loss: 1.678661583157741
Validation loss: 2.350930424386889

Epoch: 6| Step: 11
Training loss: 1.558176773624989
Validation loss: 2.3357713380757934

Epoch: 6| Step: 12
Training loss: 0.8255052695426751
Validation loss: 2.4471104313761627

Epoch: 6| Step: 13
Training loss: 1.6517638864142787
Validation loss: 2.3328883123740574

Epoch: 379| Step: 0
Training loss: 1.1475145432957246
Validation loss: 2.326068426532589

Epoch: 6| Step: 1
Training loss: 1.5121120365151919
Validation loss: 2.3615954535906174

Epoch: 6| Step: 2
Training loss: 1.3419577156517373
Validation loss: 2.38859968715516

Epoch: 6| Step: 3
Training loss: 1.8790160085616376
Validation loss: 2.3686010904564365

Epoch: 6| Step: 4
Training loss: 0.9848109899510387
Validation loss: 2.3349902341253324

Epoch: 6| Step: 5
Training loss: 1.2439302898451596
Validation loss: 2.279953092784467

Epoch: 6| Step: 6
Training loss: 0.8050039465434319
Validation loss: 2.3881120744288586

Epoch: 6| Step: 7
Training loss: 1.3403706307055825
Validation loss: 2.397629997705712

Epoch: 6| Step: 8
Training loss: 1.5394636686671095
Validation loss: 2.3322344712531566

Epoch: 6| Step: 9
Training loss: 1.4602625302516943
Validation loss: 2.392668134424765

Epoch: 6| Step: 10
Training loss: 1.2241095050496027
Validation loss: 2.4189577038547703

Epoch: 6| Step: 11
Training loss: 1.9856811189871046
Validation loss: 2.4196674470372415

Epoch: 6| Step: 12
Training loss: 1.5380423790955173
Validation loss: 2.4200592633676457

Epoch: 6| Step: 13
Training loss: 1.267234061969675
Validation loss: 2.379577864671086

Epoch: 380| Step: 0
Training loss: 1.3310983920741262
Validation loss: 2.376781760279839

Epoch: 6| Step: 1
Training loss: 1.1816924785239384
Validation loss: 2.4176328896515384

Epoch: 6| Step: 2
Training loss: 1.1693459750742303
Validation loss: 2.462562997438073

Epoch: 6| Step: 3
Training loss: 1.308802619320783
Validation loss: 2.4497273360581477

Epoch: 6| Step: 4
Training loss: 1.3211369395175367
Validation loss: 2.3683335524371705

Epoch: 6| Step: 5
Training loss: 1.1397652717331967
Validation loss: 2.292687138156919

Epoch: 6| Step: 6
Training loss: 1.5626778310668792
Validation loss: 2.3947824387451355

Epoch: 6| Step: 7
Training loss: 2.220132316563983
Validation loss: 2.371963498504105

Epoch: 6| Step: 8
Training loss: 1.2768980409370407
Validation loss: 2.4406463503627522

Epoch: 6| Step: 9
Training loss: 1.9082853363975376
Validation loss: 2.401099916324166

Epoch: 6| Step: 10
Training loss: 1.4297861367474953
Validation loss: 2.357918778679838

Epoch: 6| Step: 11
Training loss: 1.8302991930995836
Validation loss: 2.3358112185424242

Epoch: 6| Step: 12
Training loss: 1.0847033616392385
Validation loss: 2.3203103808608825

Epoch: 6| Step: 13
Training loss: 1.246538375885001
Validation loss: 2.450831849277251

Epoch: 381| Step: 0
Training loss: 1.397158842669573
Validation loss: 2.3391046769683905

Epoch: 6| Step: 1
Training loss: 1.1460116970071135
Validation loss: 2.4176852215931945

Epoch: 6| Step: 2
Training loss: 1.1716796712212452
Validation loss: 2.3579743504920962

Epoch: 6| Step: 3
Training loss: 1.7573668190429037
Validation loss: 2.322702153937977

Epoch: 6| Step: 4
Training loss: 0.9821949994501525
Validation loss: 2.367273780249152

Epoch: 6| Step: 5
Training loss: 1.4696952537674377
Validation loss: 2.3764129401541894

Epoch: 6| Step: 6
Training loss: 1.6827647564560766
Validation loss: 2.310535570994456

Epoch: 6| Step: 7
Training loss: 2.4447521993742463
Validation loss: 2.407091091498893

Epoch: 6| Step: 8
Training loss: 1.1170672371964019
Validation loss: 2.2921536892039023

Epoch: 6| Step: 9
Training loss: 1.331926089971256
Validation loss: 2.397227986630872

Epoch: 6| Step: 10
Training loss: 1.4685297861789857
Validation loss: 2.396498974377057

Epoch: 6| Step: 11
Training loss: 1.168480292223022
Validation loss: 2.417766256883967

Epoch: 6| Step: 12
Training loss: 1.4281713231960858
Validation loss: 2.429736143201028

Epoch: 6| Step: 13
Training loss: 1.3519299839952386
Validation loss: 2.2922564926762425

Epoch: 382| Step: 0
Training loss: 1.9145743794970371
Validation loss: 2.373158759615804

Epoch: 6| Step: 1
Training loss: 0.9949452080328895
Validation loss: 2.3161814950541677

Epoch: 6| Step: 2
Training loss: 1.5617735890792661
Validation loss: 2.336883449143522

Epoch: 6| Step: 3
Training loss: 1.132486967470747
Validation loss: 2.325507974788319

Epoch: 6| Step: 4
Training loss: 0.8039623808101941
Validation loss: 2.397806531197708

Epoch: 6| Step: 5
Training loss: 1.4036333110677757
Validation loss: 2.2826086210847305

Epoch: 6| Step: 6
Training loss: 0.8725013820888645
Validation loss: 2.299694202616

Epoch: 6| Step: 7
Training loss: 1.3517978000334565
Validation loss: 2.423878655784439

Epoch: 6| Step: 8
Training loss: 1.5752877139135746
Validation loss: 2.305812186821982

Epoch: 6| Step: 9
Training loss: 1.4133971951709607
Validation loss: 2.39266687492692

Epoch: 6| Step: 10
Training loss: 1.3154909930991963
Validation loss: 2.3156419487896533

Epoch: 6| Step: 11
Training loss: 2.033385460086398
Validation loss: 2.3768197575465297

Epoch: 6| Step: 12
Training loss: 1.2078620989289264
Validation loss: 2.3726781787819444

Epoch: 6| Step: 13
Training loss: 1.545910544236587
Validation loss: 2.315488405928925

Epoch: 383| Step: 0
Training loss: 1.3309198032697522
Validation loss: 2.357400488592263

Epoch: 6| Step: 1
Training loss: 1.1811067241991149
Validation loss: 2.389336416930557

Epoch: 6| Step: 2
Training loss: 1.8245403651599217
Validation loss: 2.3195059537289637

Epoch: 6| Step: 3
Training loss: 1.2808954166926876
Validation loss: 2.498792851143672

Epoch: 6| Step: 4
Training loss: 0.9318745317464326
Validation loss: 2.3570922596115964

Epoch: 6| Step: 5
Training loss: 1.6442929636646433
Validation loss: 2.3772032006218025

Epoch: 6| Step: 6
Training loss: 0.8137807288864927
Validation loss: 2.4620965293859247

Epoch: 6| Step: 7
Training loss: 1.5112133512005113
Validation loss: 2.4329282729397996

Epoch: 6| Step: 8
Training loss: 1.2726156472976298
Validation loss: 2.4112367787138456

Epoch: 6| Step: 9
Training loss: 1.5559763717622521
Validation loss: 2.4240478187072485

Epoch: 6| Step: 10
Training loss: 1.5374772481087804
Validation loss: 2.378453350319118

Epoch: 6| Step: 11
Training loss: 1.0542636726185715
Validation loss: 2.3633484934812876

Epoch: 6| Step: 12
Training loss: 2.1472475397751216
Validation loss: 2.4041589079063956

Epoch: 6| Step: 13
Training loss: 1.534497301623227
Validation loss: 2.280447331667141

Epoch: 384| Step: 0
Training loss: 1.0631614197105546
Validation loss: 2.3727935089942895

Epoch: 6| Step: 1
Training loss: 1.508654265570373
Validation loss: 2.361251119901758

Epoch: 6| Step: 2
Training loss: 1.211780279430919
Validation loss: 2.3776075872178697

Epoch: 6| Step: 3
Training loss: 1.3106725322670398
Validation loss: 2.334818054159672

Epoch: 6| Step: 4
Training loss: 1.7493750955105314
Validation loss: 2.363365650898763

Epoch: 6| Step: 5
Training loss: 1.953235653603761
Validation loss: 2.40126453685973

Epoch: 6| Step: 6
Training loss: 1.6206368779204314
Validation loss: 2.351977261772181

Epoch: 6| Step: 7
Training loss: 1.0521661077488136
Validation loss: 2.358613280595235

Epoch: 6| Step: 8
Training loss: 1.1131944589078768
Validation loss: 2.3810814680683645

Epoch: 6| Step: 9
Training loss: 1.535690874573967
Validation loss: 2.3599023531819805

Epoch: 6| Step: 10
Training loss: 1.1436143138009722
Validation loss: 2.383144828474844

Epoch: 6| Step: 11
Training loss: 1.2459932962424018
Validation loss: 2.373586064305758

Epoch: 6| Step: 12
Training loss: 1.0382763175761085
Validation loss: 2.34383718184889

Epoch: 6| Step: 13
Training loss: 1.353803155477157
Validation loss: 2.34729627080772

Epoch: 385| Step: 0
Training loss: 1.1012423976847954
Validation loss: 2.4205751644392546

Epoch: 6| Step: 1
Training loss: 2.201398890245611
Validation loss: 2.3884174761259134

Epoch: 6| Step: 2
Training loss: 1.2475547238045408
Validation loss: 2.3799175620595414

Epoch: 6| Step: 3
Training loss: 1.8362759541961842
Validation loss: 2.369518417801265

Epoch: 6| Step: 4
Training loss: 1.6519689833844367
Validation loss: 2.414382337268882

Epoch: 6| Step: 5
Training loss: 1.4128040594107434
Validation loss: 2.416947842436956

Epoch: 6| Step: 6
Training loss: 1.131366148407756
Validation loss: 2.4200038015260654

Epoch: 6| Step: 7
Training loss: 1.210094182865166
Validation loss: 2.3537263000088715

Epoch: 6| Step: 8
Training loss: 1.2416142514492396
Validation loss: 2.329363562645989

Epoch: 6| Step: 9
Training loss: 1.5562828734575882
Validation loss: 2.336838709199741

Epoch: 6| Step: 10
Training loss: 1.5453019283538638
Validation loss: 2.4043494705508226

Epoch: 6| Step: 11
Training loss: 1.1940986603465726
Validation loss: 2.3533346622708122

Epoch: 6| Step: 12
Training loss: 0.868220701826663
Validation loss: 2.377803696581624

Epoch: 6| Step: 13
Training loss: 1.2183625020937647
Validation loss: 2.3610187843829396

Epoch: 386| Step: 0
Training loss: 0.8933596538881868
Validation loss: 2.290502547502079

Epoch: 6| Step: 1
Training loss: 1.4209528017950488
Validation loss: 2.3535290089616736

Epoch: 6| Step: 2
Training loss: 1.9986479480639638
Validation loss: 2.3224135719082213

Epoch: 6| Step: 3
Training loss: 1.522012836707943
Validation loss: 2.2765861645189016

Epoch: 6| Step: 4
Training loss: 1.3665520635485924
Validation loss: 2.434146170869007

Epoch: 6| Step: 5
Training loss: 1.65384751739514
Validation loss: 2.3937891621056777

Epoch: 6| Step: 6
Training loss: 1.5785628362938398
Validation loss: 2.3614483650560527

Epoch: 6| Step: 7
Training loss: 1.169682702786685
Validation loss: 2.3606990007781334

Epoch: 6| Step: 8
Training loss: 1.2619555460752492
Validation loss: 2.301637440331553

Epoch: 6| Step: 9
Training loss: 1.034474677501005
Validation loss: 2.412103139952211

Epoch: 6| Step: 10
Training loss: 1.2096017669278818
Validation loss: 2.351041961401949

Epoch: 6| Step: 11
Training loss: 1.4139647054840132
Validation loss: 2.3768406332417205

Epoch: 6| Step: 12
Training loss: 1.346122864481964
Validation loss: 2.3863938289696764

Epoch: 6| Step: 13
Training loss: 1.105248149522545
Validation loss: 2.368586131335944

Epoch: 387| Step: 0
Training loss: 1.5589336129882472
Validation loss: 2.3829852986464

Epoch: 6| Step: 1
Training loss: 1.0892979065080979
Validation loss: 2.3190603569655144

Epoch: 6| Step: 2
Training loss: 1.3519403006786657
Validation loss: 2.464584137998236

Epoch: 6| Step: 3
Training loss: 1.0421244314804623
Validation loss: 2.431929226646322

Epoch: 6| Step: 4
Training loss: 1.0992365420161623
Validation loss: 2.3251888126917906

Epoch: 6| Step: 5
Training loss: 1.2781386395684968
Validation loss: 2.418274738712911

Epoch: 6| Step: 6
Training loss: 1.1979454313501157
Validation loss: 2.3778940561025506

Epoch: 6| Step: 7
Training loss: 1.4755902192453183
Validation loss: 2.46059220211535

Epoch: 6| Step: 8
Training loss: 1.1157408731588587
Validation loss: 2.4017649609219776

Epoch: 6| Step: 9
Training loss: 2.290267679153529
Validation loss: 2.288511683223448

Epoch: 6| Step: 10
Training loss: 1.2708340577087005
Validation loss: 2.3782691174431796

Epoch: 6| Step: 11
Training loss: 1.2420564018502531
Validation loss: 2.4000975708628762

Epoch: 6| Step: 12
Training loss: 1.4830311363794582
Validation loss: 2.4080267958243917

Epoch: 6| Step: 13
Training loss: 1.3403820591329532
Validation loss: 2.366247810909797

Epoch: 388| Step: 0
Training loss: 1.5377469709574598
Validation loss: 2.402633068778841

Epoch: 6| Step: 1
Training loss: 1.113986571561463
Validation loss: 2.3584930112218148

Epoch: 6| Step: 2
Training loss: 1.670363411337137
Validation loss: 2.365890619319178

Epoch: 6| Step: 3
Training loss: 0.991069734785481
Validation loss: 2.345231006268374

Epoch: 6| Step: 4
Training loss: 1.348304658890577
Validation loss: 2.351551601384793

Epoch: 6| Step: 5
Training loss: 1.7892765100403918
Validation loss: 2.365310000740927

Epoch: 6| Step: 6
Training loss: 1.7728277157958128
Validation loss: 2.355128168056121

Epoch: 6| Step: 7
Training loss: 1.458682763152659
Validation loss: 2.3647285208328084

Epoch: 6| Step: 8
Training loss: 1.0534503603964727
Validation loss: 2.257077833598136

Epoch: 6| Step: 9
Training loss: 1.422083745032958
Validation loss: 2.362675045907707

Epoch: 6| Step: 10
Training loss: 1.2178368203953003
Validation loss: 2.2582542054645605

Epoch: 6| Step: 11
Training loss: 1.4114095343943573
Validation loss: 2.403857178863914

Epoch: 6| Step: 12
Training loss: 1.0068619259459644
Validation loss: 2.3665057933196345

Epoch: 6| Step: 13
Training loss: 1.1949121141237695
Validation loss: 2.3701959185179913

Epoch: 389| Step: 0
Training loss: 1.1982949640889753
Validation loss: 2.368863137363972

Epoch: 6| Step: 1
Training loss: 0.8908639219282264
Validation loss: 2.3072362000665407

Epoch: 6| Step: 2
Training loss: 1.3179335973333333
Validation loss: 2.3298339019860412

Epoch: 6| Step: 3
Training loss: 1.6283092548278137
Validation loss: 2.3673988555770125

Epoch: 6| Step: 4
Training loss: 2.179520139114158
Validation loss: 2.380445050180552

Epoch: 6| Step: 5
Training loss: 1.0619778191428673
Validation loss: 2.4046855566456733

Epoch: 6| Step: 6
Training loss: 1.3402079095676218
Validation loss: 2.318123559004204

Epoch: 6| Step: 7
Training loss: 0.9302968824957433
Validation loss: 2.35968535246314

Epoch: 6| Step: 8
Training loss: 1.5051582970491926
Validation loss: 2.3517553481851916

Epoch: 6| Step: 9
Training loss: 0.9914092668828611
Validation loss: 2.3768386416212683

Epoch: 6| Step: 10
Training loss: 1.7934622822930546
Validation loss: 2.3648448490666163

Epoch: 6| Step: 11
Training loss: 1.8267163449282104
Validation loss: 2.3863122063904685

Epoch: 6| Step: 12
Training loss: 1.6619238923661137
Validation loss: 2.277644957978483

Epoch: 6| Step: 13
Training loss: 1.0087939074862478
Validation loss: 2.3803878446862017

Epoch: 390| Step: 0
Training loss: 1.2193426011951503
Validation loss: 2.364230041507521

Epoch: 6| Step: 1
Training loss: 1.7840154496024316
Validation loss: 2.3554408993277924

Epoch: 6| Step: 2
Training loss: 1.358410591822534
Validation loss: 2.3593323580197008

Epoch: 6| Step: 3
Training loss: 1.4558514684120054
Validation loss: 2.3757029574119066

Epoch: 6| Step: 4
Training loss: 1.0598474939868725
Validation loss: 2.3487499668422345

Epoch: 6| Step: 5
Training loss: 1.22652007594514
Validation loss: 2.400050313740086

Epoch: 6| Step: 6
Training loss: 1.5181654256414343
Validation loss: 2.3872795613548994

Epoch: 6| Step: 7
Training loss: 1.3206608781034603
Validation loss: 2.3352647032590435

Epoch: 6| Step: 8
Training loss: 1.1061157921024047
Validation loss: 2.4553831591357835

Epoch: 6| Step: 9
Training loss: 1.3423535831532185
Validation loss: 2.4028133349238034

Epoch: 6| Step: 10
Training loss: 1.4695107944815025
Validation loss: 2.355756305889586

Epoch: 6| Step: 11
Training loss: 1.9612001645896697
Validation loss: 2.4143558399240725

Epoch: 6| Step: 12
Training loss: 1.2871913854841808
Validation loss: 2.371834142617489

Epoch: 6| Step: 13
Training loss: 0.9826451193915647
Validation loss: 2.4002034014602036

Epoch: 391| Step: 0
Training loss: 1.1848355064824694
Validation loss: 2.431308029312768

Epoch: 6| Step: 1
Training loss: 1.5294871400689685
Validation loss: 2.2929905059207756

Epoch: 6| Step: 2
Training loss: 1.8049967447182844
Validation loss: 2.388128444189091

Epoch: 6| Step: 3
Training loss: 1.4306881430620595
Validation loss: 2.381950234508227

Epoch: 6| Step: 4
Training loss: 1.0329672646962642
Validation loss: 2.3985609524031384

Epoch: 6| Step: 5
Training loss: 1.2660127210716174
Validation loss: 2.3195622115235635

Epoch: 6| Step: 6
Training loss: 1.3399881446370876
Validation loss: 2.3480743180101697

Epoch: 6| Step: 7
Training loss: 1.6418908458303743
Validation loss: 2.388578356656894

Epoch: 6| Step: 8
Training loss: 1.2547039216179496
Validation loss: 2.3113423326300317

Epoch: 6| Step: 9
Training loss: 1.033954887704657
Validation loss: 2.4216688742565924

Epoch: 6| Step: 10
Training loss: 1.808513334723457
Validation loss: 2.4107968250005456

Epoch: 6| Step: 11
Training loss: 0.9638510473691396
Validation loss: 2.4430192819047747

Epoch: 6| Step: 12
Training loss: 0.9906245559546982
Validation loss: 2.3352753897146865

Epoch: 6| Step: 13
Training loss: 1.4935500230562953
Validation loss: 2.3517205803855177

Epoch: 392| Step: 0
Training loss: 1.7188007000467864
Validation loss: 2.425850610935459

Epoch: 6| Step: 1
Training loss: 1.2256279075700895
Validation loss: 2.3830393435262636

Epoch: 6| Step: 2
Training loss: 1.2668570655641078
Validation loss: 2.383008354229962

Epoch: 6| Step: 3
Training loss: 1.2815344890071794
Validation loss: 2.378016197879955

Epoch: 6| Step: 4
Training loss: 1.0233333039568504
Validation loss: 2.4197915548879596

Epoch: 6| Step: 5
Training loss: 1.12676069444753
Validation loss: 2.3275294555592136

Epoch: 6| Step: 6
Training loss: 1.292655976142241
Validation loss: 2.3294709603876345

Epoch: 6| Step: 7
Training loss: 1.2092118796412057
Validation loss: 2.3256633677979957

Epoch: 6| Step: 8
Training loss: 2.0404661762301064
Validation loss: 2.283191484068121

Epoch: 6| Step: 9
Training loss: 1.4768757159941266
Validation loss: 2.323720970355303

Epoch: 6| Step: 10
Training loss: 1.3416126019185677
Validation loss: 2.353296777115992

Epoch: 6| Step: 11
Training loss: 1.2457611692487873
Validation loss: 2.30545183066448

Epoch: 6| Step: 12
Training loss: 1.5265883506999114
Validation loss: 2.3884804919411544

Epoch: 6| Step: 13
Training loss: 1.019829717334717
Validation loss: 2.3572619512784

Epoch: 393| Step: 0
Training loss: 0.9160492978281699
Validation loss: 2.3959380146143654

Epoch: 6| Step: 1
Training loss: 1.2867262969174975
Validation loss: 2.432985962456488

Epoch: 6| Step: 2
Training loss: 2.1141085036770995
Validation loss: 2.3561832728723937

Epoch: 6| Step: 3
Training loss: 1.047505658482675
Validation loss: 2.3917964794454996

Epoch: 6| Step: 4
Training loss: 1.1365655225535811
Validation loss: 2.434562130028156

Epoch: 6| Step: 5
Training loss: 1.2555810314358309
Validation loss: 2.2936764505946967

Epoch: 6| Step: 6
Training loss: 0.996929939693348
Validation loss: 2.429907473423867

Epoch: 6| Step: 7
Training loss: 1.2489719454819195
Validation loss: 2.4319023016893575

Epoch: 6| Step: 8
Training loss: 1.5336478784912806
Validation loss: 2.3616208836540484

Epoch: 6| Step: 9
Training loss: 1.3452500686602955
Validation loss: 2.355932541705655

Epoch: 6| Step: 10
Training loss: 1.4512012832968189
Validation loss: 2.3778946630805993

Epoch: 6| Step: 11
Training loss: 1.7964579886140801
Validation loss: 2.3511458964660004

Epoch: 6| Step: 12
Training loss: 1.438499932186694
Validation loss: 2.410663843199581

Epoch: 6| Step: 13
Training loss: 1.4525479227062281
Validation loss: 2.338570967582343

Epoch: 394| Step: 0
Training loss: 1.208448793660836
Validation loss: 2.3597267854043875

Epoch: 6| Step: 1
Training loss: 1.2482520757100568
Validation loss: 2.318103210134297

Epoch: 6| Step: 2
Training loss: 1.687820404152884
Validation loss: 2.410513420828069

Epoch: 6| Step: 3
Training loss: 1.6641095651767404
Validation loss: 2.3647842762746647

Epoch: 6| Step: 4
Training loss: 1.3257172694416364
Validation loss: 2.357573700846141

Epoch: 6| Step: 5
Training loss: 0.8642878123103668
Validation loss: 2.3571240660038217

Epoch: 6| Step: 6
Training loss: 1.4938644652622004
Validation loss: 2.385796463278937

Epoch: 6| Step: 7
Training loss: 1.2171456952928628
Validation loss: 2.4534797378005933

Epoch: 6| Step: 8
Training loss: 1.593252590572993
Validation loss: 2.331081298655334

Epoch: 6| Step: 9
Training loss: 1.364524252779794
Validation loss: 2.309476132538622

Epoch: 6| Step: 10
Training loss: 1.2158172729944436
Validation loss: 2.3616621176387635

Epoch: 6| Step: 11
Training loss: 2.144454204238442
Validation loss: 2.395153684014633

Epoch: 6| Step: 12
Training loss: 1.0569535389688698
Validation loss: 2.4198278904651134

Epoch: 6| Step: 13
Training loss: 1.1041162527319368
Validation loss: 2.2782071776648913

Epoch: 395| Step: 0
Training loss: 1.3583786919788396
Validation loss: 2.4791552559836543

Epoch: 6| Step: 1
Training loss: 1.6158449063895728
Validation loss: 2.4479581806238278

Epoch: 6| Step: 2
Training loss: 1.0403516989026682
Validation loss: 2.3403381929652602

Epoch: 6| Step: 3
Training loss: 1.3273303178867617
Validation loss: 2.2793343165167754

Epoch: 6| Step: 4
Training loss: 1.4665392206190784
Validation loss: 2.3927558519167937

Epoch: 6| Step: 5
Training loss: 1.1219611450954177
Validation loss: 2.3491047724710254

Epoch: 6| Step: 6
Training loss: 1.3130839728982309
Validation loss: 2.408649583602542

Epoch: 6| Step: 7
Training loss: 2.1212904471844296
Validation loss: 2.371714050771658

Epoch: 6| Step: 8
Training loss: 1.2284702601949347
Validation loss: 2.3212513672330766

Epoch: 6| Step: 9
Training loss: 1.3279039086713589
Validation loss: 2.3120703449108833

Epoch: 6| Step: 10
Training loss: 1.3977037774625498
Validation loss: 2.3990722032349825

Epoch: 6| Step: 11
Training loss: 1.3080253163579585
Validation loss: 2.343199626878084

Epoch: 6| Step: 12
Training loss: 1.3058485244633387
Validation loss: 2.379048897094271

Epoch: 6| Step: 13
Training loss: 0.5302212796632316
Validation loss: 2.2939983136833995

Epoch: 396| Step: 0
Training loss: 1.1732269626504042
Validation loss: 2.381079872441862

Epoch: 6| Step: 1
Training loss: 1.2173080717608409
Validation loss: 2.3536104137143097

Epoch: 6| Step: 2
Training loss: 1.0605424350484007
Validation loss: 2.404571056139271

Epoch: 6| Step: 3
Training loss: 1.397098603582773
Validation loss: 2.363207279852162

Epoch: 6| Step: 4
Training loss: 1.2342003807461672
Validation loss: 2.3583508459305023

Epoch: 6| Step: 5
Training loss: 2.0787186312530856
Validation loss: 2.3754464751490074

Epoch: 6| Step: 6
Training loss: 0.9603545118453033
Validation loss: 2.429394569302642

Epoch: 6| Step: 7
Training loss: 1.3280290905598529
Validation loss: 2.37334054290895

Epoch: 6| Step: 8
Training loss: 1.0109525747221788
Validation loss: 2.401176870757431

Epoch: 6| Step: 9
Training loss: 1.3917772041705847
Validation loss: 2.4122001977263796

Epoch: 6| Step: 10
Training loss: 1.485696866580483
Validation loss: 2.3940131193916887

Epoch: 6| Step: 11
Training loss: 1.4078389833184226
Validation loss: 2.3965062406028323

Epoch: 6| Step: 12
Training loss: 1.294610677986302
Validation loss: 2.3370769313312216

Epoch: 6| Step: 13
Training loss: 1.274205496957083
Validation loss: 2.361268381586946

Epoch: 397| Step: 0
Training loss: 1.556219142010403
Validation loss: 2.3728455646890194

Epoch: 6| Step: 1
Training loss: 1.3089423327409364
Validation loss: 2.4395393357596458

Epoch: 6| Step: 2
Training loss: 1.3976149883971036
Validation loss: 2.3656554677915618

Epoch: 6| Step: 3
Training loss: 0.9583459037840897
Validation loss: 2.450890638527355

Epoch: 6| Step: 4
Training loss: 1.388102526046975
Validation loss: 2.379302590411869

Epoch: 6| Step: 5
Training loss: 0.9538244901293049
Validation loss: 2.365465133570362

Epoch: 6| Step: 6
Training loss: 1.9302044998298316
Validation loss: 2.3205730907449653

Epoch: 6| Step: 7
Training loss: 1.5880712427546217
Validation loss: 2.388866936820159

Epoch: 6| Step: 8
Training loss: 1.3420025752507614
Validation loss: 2.3647689016504136

Epoch: 6| Step: 9
Training loss: 1.0676009085352989
Validation loss: 2.2920459138921294

Epoch: 6| Step: 10
Training loss: 1.619727015866104
Validation loss: 2.366953005324673

Epoch: 6| Step: 11
Training loss: 1.4890961105860494
Validation loss: 2.364468866696232

Epoch: 6| Step: 12
Training loss: 0.9643244716636213
Validation loss: 2.4263035440809646

Epoch: 6| Step: 13
Training loss: 0.7708939622971905
Validation loss: 2.3287184722021887

Epoch: 398| Step: 0
Training loss: 0.735773905006375
Validation loss: 2.3163582228723403

Epoch: 6| Step: 1
Training loss: 1.5224525593349092
Validation loss: 2.3542519217374007

Epoch: 6| Step: 2
Training loss: 1.5843610774224173
Validation loss: 2.3489963608542546

Epoch: 6| Step: 3
Training loss: 0.7025656276470712
Validation loss: 2.398436764610803

Epoch: 6| Step: 4
Training loss: 1.5323747668973653
Validation loss: 2.3711330639436916

Epoch: 6| Step: 5
Training loss: 1.0634275763152605
Validation loss: 2.374630879385923

Epoch: 6| Step: 6
Training loss: 1.1491007025258004
Validation loss: 2.3950956866716617

Epoch: 6| Step: 7
Training loss: 1.3589593536889313
Validation loss: 2.3275987099498585

Epoch: 6| Step: 8
Training loss: 1.3366763207966128
Validation loss: 2.4024651534829182

Epoch: 6| Step: 9
Training loss: 1.4796965907944493
Validation loss: 2.362918716864824

Epoch: 6| Step: 10
Training loss: 1.2546078154270763
Validation loss: 2.4009503848216855

Epoch: 6| Step: 11
Training loss: 0.9157200968965847
Validation loss: 2.3351848741243177

Epoch: 6| Step: 12
Training loss: 1.2853101736725192
Validation loss: 2.3595815653848113

Epoch: 6| Step: 13
Training loss: 2.666036372400955
Validation loss: 2.396649156928892

Epoch: 399| Step: 0
Training loss: 1.394891473315464
Validation loss: 2.336641678039799

Epoch: 6| Step: 1
Training loss: 1.5874615942446937
Validation loss: 2.2829904663821297

Epoch: 6| Step: 2
Training loss: 1.2581760047090724
Validation loss: 2.296732867086469

Epoch: 6| Step: 3
Training loss: 0.9680335564274768
Validation loss: 2.3649935225399545

Epoch: 6| Step: 4
Training loss: 1.416878693739456
Validation loss: 2.3524286475653966

Epoch: 6| Step: 5
Training loss: 1.4787872347170616
Validation loss: 2.3870687766312337

Epoch: 6| Step: 6
Training loss: 0.7792989400965354
Validation loss: 2.3211537359485677

Epoch: 6| Step: 7
Training loss: 1.4352347728863044
Validation loss: 2.3342215243646116

Epoch: 6| Step: 8
Training loss: 0.9231534918105364
Validation loss: 2.3048603085539114

Epoch: 6| Step: 9
Training loss: 0.9877480738531018
Validation loss: 2.2722292001747157

Epoch: 6| Step: 10
Training loss: 1.1336293399621296
Validation loss: 2.403547718520618

Epoch: 6| Step: 11
Training loss: 2.1746402399097344
Validation loss: 2.358743158283329

Epoch: 6| Step: 12
Training loss: 1.4372248178884683
Validation loss: 2.3313654846937344

Epoch: 6| Step: 13
Training loss: 1.186008269318158
Validation loss: 2.332230888889826

Epoch: 400| Step: 0
Training loss: 1.629826055033336
Validation loss: 2.3764771901522344

Epoch: 6| Step: 1
Training loss: 1.0430558986186347
Validation loss: 2.3249826498329207

Epoch: 6| Step: 2
Training loss: 1.3074728648942173
Validation loss: 2.3682557911303173

Epoch: 6| Step: 3
Training loss: 1.2772851399732117
Validation loss: 2.4012684176592156

Epoch: 6| Step: 4
Training loss: 1.1594522311662978
Validation loss: 2.4039942184359475

Epoch: 6| Step: 5
Training loss: 2.0001013253294126
Validation loss: 2.365114979952365

Epoch: 6| Step: 6
Training loss: 1.192198943036959
Validation loss: 2.3895037817512024

Epoch: 6| Step: 7
Training loss: 1.382004539529215
Validation loss: 2.3627976337215726

Epoch: 6| Step: 8
Training loss: 1.3308946341145373
Validation loss: 2.339377122587294

Epoch: 6| Step: 9
Training loss: 1.1834186890313099
Validation loss: 2.4308813943353873

Epoch: 6| Step: 10
Training loss: 1.5094220361429636
Validation loss: 2.3418196398471416

Epoch: 6| Step: 11
Training loss: 1.0510405606937292
Validation loss: 2.312222441667748

Epoch: 6| Step: 12
Training loss: 1.1028473307383424
Validation loss: 2.3419115738605965

Epoch: 6| Step: 13
Training loss: 1.0143666615028837
Validation loss: 2.3120994276364475

Epoch: 401| Step: 0
Training loss: 2.0571477397035753
Validation loss: 2.3967706397484347

Epoch: 6| Step: 1
Training loss: 1.404744295832697
Validation loss: 2.354871547068689

Epoch: 6| Step: 2
Training loss: 1.3284189235597172
Validation loss: 2.496977149637488

Epoch: 6| Step: 3
Training loss: 1.2053020646363308
Validation loss: 2.3309991370952337

Epoch: 6| Step: 4
Training loss: 1.2793679719926634
Validation loss: 2.335352556449828

Epoch: 6| Step: 5
Training loss: 1.0484220546261247
Validation loss: 2.390343189619794

Epoch: 6| Step: 6
Training loss: 1.3980332541515026
Validation loss: 2.3532561950842936

Epoch: 6| Step: 7
Training loss: 1.7416851876230803
Validation loss: 2.3640367729966227

Epoch: 6| Step: 8
Training loss: 1.5390807794560095
Validation loss: 2.371154710850594

Epoch: 6| Step: 9
Training loss: 1.069871017846203
Validation loss: 2.3223540163014875

Epoch: 6| Step: 10
Training loss: 0.8936918226394035
Validation loss: 2.377411613722239

Epoch: 6| Step: 11
Training loss: 1.487672856649561
Validation loss: 2.4266007220099786

Epoch: 6| Step: 12
Training loss: 1.398036622284021
Validation loss: 2.4099009803762343

Epoch: 6| Step: 13
Training loss: 1.36055791841067
Validation loss: 2.5092583115928697

Epoch: 402| Step: 0
Training loss: 1.9217697983147835
Validation loss: 2.4499938500381373

Epoch: 6| Step: 1
Training loss: 1.1597411572299534
Validation loss: 2.46243263528522

Epoch: 6| Step: 2
Training loss: 1.3801448111641492
Validation loss: 2.4874207126849277

Epoch: 6| Step: 3
Training loss: 1.3319411261266045
Validation loss: 2.4606933774769124

Epoch: 6| Step: 4
Training loss: 1.6249547365193575
Validation loss: 2.4096131843019166

Epoch: 6| Step: 5
Training loss: 1.3283538621172104
Validation loss: 2.468225359256097

Epoch: 6| Step: 6
Training loss: 1.4269721087621792
Validation loss: 2.404194682138914

Epoch: 6| Step: 7
Training loss: 1.5253972677362164
Validation loss: 2.359067189837646

Epoch: 6| Step: 8
Training loss: 1.2255722227507038
Validation loss: 2.412042739982019

Epoch: 6| Step: 9
Training loss: 0.977186873154886
Validation loss: 2.3781812563875455

Epoch: 6| Step: 10
Training loss: 1.2829349882166587
Validation loss: 2.3425207883877

Epoch: 6| Step: 11
Training loss: 1.1611010881586572
Validation loss: 2.4283264017504123

Epoch: 6| Step: 12
Training loss: 1.8140579631002833
Validation loss: 2.2600055905065233

Epoch: 6| Step: 13
Training loss: 1.3485855657766512
Validation loss: 2.3967004762759796

Epoch: 403| Step: 0
Training loss: 1.256143113708631
Validation loss: 2.309113457555796

Epoch: 6| Step: 1
Training loss: 1.2434493559343784
Validation loss: 2.3307899583120646

Epoch: 6| Step: 2
Training loss: 1.101727953450259
Validation loss: 2.337566032352192

Epoch: 6| Step: 3
Training loss: 1.5328993964183673
Validation loss: 2.3395592339535645

Epoch: 6| Step: 4
Training loss: 2.0856248714182914
Validation loss: 2.3596972760379757

Epoch: 6| Step: 5
Training loss: 0.7900867801397007
Validation loss: 2.329265668794113

Epoch: 6| Step: 6
Training loss: 1.40810043658942
Validation loss: 2.3492083021660224

Epoch: 6| Step: 7
Training loss: 1.3366662430386018
Validation loss: 2.393284116029787

Epoch: 6| Step: 8
Training loss: 0.9647931537412153
Validation loss: 2.3019124444035857

Epoch: 6| Step: 9
Training loss: 1.4570613581842295
Validation loss: 2.3465911582386187

Epoch: 6| Step: 10
Training loss: 1.491835787401229
Validation loss: 2.4111788061957125

Epoch: 6| Step: 11
Training loss: 1.2755903990116577
Validation loss: 2.3691170221764706

Epoch: 6| Step: 12
Training loss: 1.3766878345946472
Validation loss: 2.4052890285812842

Epoch: 6| Step: 13
Training loss: 1.734003938039072
Validation loss: 2.382329372768687

Epoch: 404| Step: 0
Training loss: 1.346656716132148
Validation loss: 2.3833305141444634

Epoch: 6| Step: 1
Training loss: 0.7615273259570672
Validation loss: 2.338855099638775

Epoch: 6| Step: 2
Training loss: 2.079796828470821
Validation loss: 2.305838776878307

Epoch: 6| Step: 3
Training loss: 0.9076703877923202
Validation loss: 2.292724742296665

Epoch: 6| Step: 4
Training loss: 1.1630178282659476
Validation loss: 2.361672405126209

Epoch: 6| Step: 5
Training loss: 1.2469304543308026
Validation loss: 2.3165199594824415

Epoch: 6| Step: 6
Training loss: 1.0271861604566344
Validation loss: 2.346747519200516

Epoch: 6| Step: 7
Training loss: 1.5417945740022734
Validation loss: 2.344525879990057

Epoch: 6| Step: 8
Training loss: 1.257341474396154
Validation loss: 2.334109963393316

Epoch: 6| Step: 9
Training loss: 1.1239022621307837
Validation loss: 2.3438020247834697

Epoch: 6| Step: 10
Training loss: 1.446891705476294
Validation loss: 2.344449400101545

Epoch: 6| Step: 11
Training loss: 1.4487188664695927
Validation loss: 2.3817442948781316

Epoch: 6| Step: 12
Training loss: 1.0896580582348012
Validation loss: 2.3778920464973914

Epoch: 6| Step: 13
Training loss: 1.837225993480387
Validation loss: 2.376004693603658

Epoch: 405| Step: 0
Training loss: 1.1558591852320097
Validation loss: 2.3718465790569896

Epoch: 6| Step: 1
Training loss: 1.2573715289946203
Validation loss: 2.3319453632107217

Epoch: 6| Step: 2
Training loss: 1.0652129375005863
Validation loss: 2.3930471435134235

Epoch: 6| Step: 3
Training loss: 1.436004856260796
Validation loss: 2.303449636670701

Epoch: 6| Step: 4
Training loss: 1.0668025695134769
Validation loss: 2.332335185733729

Epoch: 6| Step: 5
Training loss: 1.432824533925746
Validation loss: 2.3442085342605723

Epoch: 6| Step: 6
Training loss: 1.3691451525647322
Validation loss: 2.387957512124517

Epoch: 6| Step: 7
Training loss: 1.4082772794925928
Validation loss: 2.3143696420439657

Epoch: 6| Step: 8
Training loss: 1.2853974460955708
Validation loss: 2.325037865446719

Epoch: 6| Step: 9
Training loss: 1.1817411017457147
Validation loss: 2.3128240835487825

Epoch: 6| Step: 10
Training loss: 0.9874098483111611
Validation loss: 2.287711838963298

Epoch: 6| Step: 11
Training loss: 1.9755643955626996
Validation loss: 2.4275615681686538

Epoch: 6| Step: 12
Training loss: 1.497734106803139
Validation loss: 2.3433980402682124

Epoch: 6| Step: 13
Training loss: 1.0471066460605538
Validation loss: 2.3001652692542724

Epoch: 406| Step: 0
Training loss: 2.116414847625809
Validation loss: 2.3459264503736033

Epoch: 6| Step: 1
Training loss: 1.2529986653180027
Validation loss: 2.3188524671182877

Epoch: 6| Step: 2
Training loss: 1.279997795222291
Validation loss: 2.3070838645943588

Epoch: 6| Step: 3
Training loss: 1.467115507299416
Validation loss: 2.336293650640797

Epoch: 6| Step: 4
Training loss: 1.2597824213845148
Validation loss: 2.321773606678167

Epoch: 6| Step: 5
Training loss: 1.229384947107719
Validation loss: 2.3300887598768165

Epoch: 6| Step: 6
Training loss: 1.0736524719248197
Validation loss: 2.3934740910216976

Epoch: 6| Step: 7
Training loss: 1.0916844072914529
Validation loss: 2.354711284651106

Epoch: 6| Step: 8
Training loss: 1.3118407546576487
Validation loss: 2.297215065787885

Epoch: 6| Step: 9
Training loss: 1.4221580139872105
Validation loss: 2.3991446412429647

Epoch: 6| Step: 10
Training loss: 1.2162543935196533
Validation loss: 2.352675579262625

Epoch: 6| Step: 11
Training loss: 1.4230669496111423
Validation loss: 2.4188011550040827

Epoch: 6| Step: 12
Training loss: 0.9054628768611934
Validation loss: 2.3951337696289907

Epoch: 6| Step: 13
Training loss: 1.5815111600498375
Validation loss: 2.3917147968542043

Epoch: 407| Step: 0
Training loss: 1.381283189193577
Validation loss: 2.323632476040685

Epoch: 6| Step: 1
Training loss: 1.4831554020379112
Validation loss: 2.3313998270015004

Epoch: 6| Step: 2
Training loss: 1.0711106714293481
Validation loss: 2.39634774523094

Epoch: 6| Step: 3
Training loss: 1.1129566455564681
Validation loss: 2.343937847307399

Epoch: 6| Step: 4
Training loss: 1.1260065238519723
Validation loss: 2.37426291611897

Epoch: 6| Step: 5
Training loss: 1.0413237897502354
Validation loss: 2.3413707281065608

Epoch: 6| Step: 6
Training loss: 0.9403861442776719
Validation loss: 2.344979207915988

Epoch: 6| Step: 7
Training loss: 1.2831221138335933
Validation loss: 2.3135903372985713

Epoch: 6| Step: 8
Training loss: 1.5465105186077555
Validation loss: 2.356181846440957

Epoch: 6| Step: 9
Training loss: 1.4317482027069528
Validation loss: 2.333921685365677

Epoch: 6| Step: 10
Training loss: 0.8922666177225566
Validation loss: 2.3625210244291024

Epoch: 6| Step: 11
Training loss: 1.2532357773368532
Validation loss: 2.311242803645828

Epoch: 6| Step: 12
Training loss: 2.4011458721152334
Validation loss: 2.3311259717641057

Epoch: 6| Step: 13
Training loss: 1.2171143045808575
Validation loss: 2.475201678353344

Epoch: 408| Step: 0
Training loss: 2.0636581868128046
Validation loss: 2.4071782205840333

Epoch: 6| Step: 1
Training loss: 0.9403357216226493
Validation loss: 2.3677378754853264

Epoch: 6| Step: 2
Training loss: 1.3952637786731696
Validation loss: 2.287647816300958

Epoch: 6| Step: 3
Training loss: 1.2216972514474835
Validation loss: 2.4217413276252158

Epoch: 6| Step: 4
Training loss: 1.2956012767454512
Validation loss: 2.2988584692438985

Epoch: 6| Step: 5
Training loss: 1.599800294095344
Validation loss: 2.283225693698131

Epoch: 6| Step: 6
Training loss: 1.0788119242411194
Validation loss: 2.442105545011323

Epoch: 6| Step: 7
Training loss: 1.3763713067389491
Validation loss: 2.2986007523479604

Epoch: 6| Step: 8
Training loss: 1.7154944364968403
Validation loss: 2.388261292306523

Epoch: 6| Step: 9
Training loss: 0.936871954039444
Validation loss: 2.2451164932405843

Epoch: 6| Step: 10
Training loss: 0.8703558152547182
Validation loss: 2.3767338249143433

Epoch: 6| Step: 11
Training loss: 1.2902734790388661
Validation loss: 2.276389685450321

Epoch: 6| Step: 12
Training loss: 0.7277264040204818
Validation loss: 2.331719427790382

Epoch: 6| Step: 13
Training loss: 1.0809506966766014
Validation loss: 2.371304629840074

Epoch: 409| Step: 0
Training loss: 1.2560479718116127
Validation loss: 2.3409325918681096

Epoch: 6| Step: 1
Training loss: 1.374829845303961
Validation loss: 2.3075896214048184

Epoch: 6| Step: 2
Training loss: 0.9782386433453741
Validation loss: 2.3375803318097157

Epoch: 6| Step: 3
Training loss: 1.1654323224318712
Validation loss: 2.4516072303884986

Epoch: 6| Step: 4
Training loss: 2.0288906773970985
Validation loss: 2.3585486792867254

Epoch: 6| Step: 5
Training loss: 1.450625084281633
Validation loss: 2.3112430565444124

Epoch: 6| Step: 6
Training loss: 1.0735125075430274
Validation loss: 2.4141971985826896

Epoch: 6| Step: 7
Training loss: 1.479337476440606
Validation loss: 2.372964881916275

Epoch: 6| Step: 8
Training loss: 1.5832371766188345
Validation loss: 2.3780084239872226

Epoch: 6| Step: 9
Training loss: 0.969973130394726
Validation loss: 2.2830381612527635

Epoch: 6| Step: 10
Training loss: 0.894458684518319
Validation loss: 2.359713188891781

Epoch: 6| Step: 11
Training loss: 1.3987052277600196
Validation loss: 2.3691637666194905

Epoch: 6| Step: 12
Training loss: 1.1822775393186733
Validation loss: 2.330862678301077

Epoch: 6| Step: 13
Training loss: 1.0662993772282912
Validation loss: 2.320867800219617

Epoch: 410| Step: 0
Training loss: 0.9196791926069372
Validation loss: 2.4404249098786317

Epoch: 6| Step: 1
Training loss: 1.3290885123033311
Validation loss: 2.2821328812827026

Epoch: 6| Step: 2
Training loss: 1.423869316855284
Validation loss: 2.2697088146593525

Epoch: 6| Step: 3
Training loss: 1.518227221148004
Validation loss: 2.3782294983638828

Epoch: 6| Step: 4
Training loss: 0.9968698507433074
Validation loss: 2.37849063213966

Epoch: 6| Step: 5
Training loss: 1.0516029746894655
Validation loss: 2.4056461419796937

Epoch: 6| Step: 6
Training loss: 1.472983569289878
Validation loss: 2.3486039704042563

Epoch: 6| Step: 7
Training loss: 1.265720787662092
Validation loss: 2.3481399130459635

Epoch: 6| Step: 8
Training loss: 1.817174080613002
Validation loss: 2.3536355147854806

Epoch: 6| Step: 9
Training loss: 1.5841931300768124
Validation loss: 2.328016375633682

Epoch: 6| Step: 10
Training loss: 1.6454147901191871
Validation loss: 2.368578763763908

Epoch: 6| Step: 11
Training loss: 0.9711450687514414
Validation loss: 2.3524731021857845

Epoch: 6| Step: 12
Training loss: 0.9068620193677666
Validation loss: 2.332488479103082

Epoch: 6| Step: 13
Training loss: 0.9355841770580013
Validation loss: 2.3098733790849044

Epoch: 411| Step: 0
Training loss: 1.4175991280692972
Validation loss: 2.311779948873862

Epoch: 6| Step: 1
Training loss: 1.342592894467628
Validation loss: 2.4302400888397773

Epoch: 6| Step: 2
Training loss: 1.5125416332221155
Validation loss: 2.3978005823799013

Epoch: 6| Step: 3
Training loss: 1.4799162706970708
Validation loss: 2.431313276143644

Epoch: 6| Step: 4
Training loss: 1.316481455117772
Validation loss: 2.3694286574595584

Epoch: 6| Step: 5
Training loss: 0.7989874123690601
Validation loss: 2.3330259105952016

Epoch: 6| Step: 6
Training loss: 1.175164349201799
Validation loss: 2.330031408423661

Epoch: 6| Step: 7
Training loss: 1.4755736577086658
Validation loss: 2.360870848762383

Epoch: 6| Step: 8
Training loss: 1.1409580319348283
Validation loss: 2.3279659461641744

Epoch: 6| Step: 9
Training loss: 1.2633970454077739
Validation loss: 2.3755867777780804

Epoch: 6| Step: 10
Training loss: 1.152310438806137
Validation loss: 2.260637540097774

Epoch: 6| Step: 11
Training loss: 0.9129218785392389
Validation loss: 2.32167016044164

Epoch: 6| Step: 12
Training loss: 2.1030277405422484
Validation loss: 2.2867785636529154

Epoch: 6| Step: 13
Training loss: 1.0727224019789363
Validation loss: 2.4269933071672143

Epoch: 412| Step: 0
Training loss: 1.2286655352755087
Validation loss: 2.3423587621339057

Epoch: 6| Step: 1
Training loss: 1.389054429467424
Validation loss: 2.304819502125761

Epoch: 6| Step: 2
Training loss: 1.3544859827582967
Validation loss: 2.361649900035842

Epoch: 6| Step: 3
Training loss: 1.322168974957378
Validation loss: 2.2799658729850285

Epoch: 6| Step: 4
Training loss: 1.237083168342419
Validation loss: 2.3221067571593985

Epoch: 6| Step: 5
Training loss: 1.2327855173694804
Validation loss: 2.2694122659981826

Epoch: 6| Step: 6
Training loss: 1.207106109569296
Validation loss: 2.3095854185442386

Epoch: 6| Step: 7
Training loss: 1.233997818504396
Validation loss: 2.336219791667024

Epoch: 6| Step: 8
Training loss: 1.077080095877784
Validation loss: 2.354725930177633

Epoch: 6| Step: 9
Training loss: 1.1625681764853628
Validation loss: 2.348488067409371

Epoch: 6| Step: 10
Training loss: 2.24082474716015
Validation loss: 2.323179533528087

Epoch: 6| Step: 11
Training loss: 1.0483518403445808
Validation loss: 2.358550171134526

Epoch: 6| Step: 12
Training loss: 1.3007207633036983
Validation loss: 2.348470920832029

Epoch: 6| Step: 13
Training loss: 1.23755887016757
Validation loss: 2.3693967140991443

Epoch: 413| Step: 0
Training loss: 1.366646708753671
Validation loss: 2.3155852381500703

Epoch: 6| Step: 1
Training loss: 0.8055592971656401
Validation loss: 2.352608315134594

Epoch: 6| Step: 2
Training loss: 1.4952751290525468
Validation loss: 2.3893389244154717

Epoch: 6| Step: 3
Training loss: 1.217696296799918
Validation loss: 2.306429123677407

Epoch: 6| Step: 4
Training loss: 1.3711827784486146
Validation loss: 2.443972679759997

Epoch: 6| Step: 5
Training loss: 1.0637519416836188
Validation loss: 2.350136274210425

Epoch: 6| Step: 6
Training loss: 0.9196095837566997
Validation loss: 2.3244464881611617

Epoch: 6| Step: 7
Training loss: 1.9327112515203972
Validation loss: 2.331732143052243

Epoch: 6| Step: 8
Training loss: 1.3739392784172042
Validation loss: 2.37246954004781

Epoch: 6| Step: 9
Training loss: 0.9793973441335085
Validation loss: 2.387282742171519

Epoch: 6| Step: 10
Training loss: 1.4052143946074604
Validation loss: 2.3379257607566104

Epoch: 6| Step: 11
Training loss: 1.3332653425683305
Validation loss: 2.4334131544941844

Epoch: 6| Step: 12
Training loss: 1.1688000836580574
Validation loss: 2.3579935425932064

Epoch: 6| Step: 13
Training loss: 1.3478544669955392
Validation loss: 2.2980807316981666

Epoch: 414| Step: 0
Training loss: 1.033111510514697
Validation loss: 2.319494309860647

Epoch: 6| Step: 1
Training loss: 1.3260216157310738
Validation loss: 2.3198977095815607

Epoch: 6| Step: 2
Training loss: 1.4873523767130767
Validation loss: 2.401960951864408

Epoch: 6| Step: 3
Training loss: 0.9739107062514616
Validation loss: 2.3766592239090527

Epoch: 6| Step: 4
Training loss: 1.6320820319792437
Validation loss: 2.3255705991000384

Epoch: 6| Step: 5
Training loss: 1.310521905834581
Validation loss: 2.377438391267699

Epoch: 6| Step: 6
Training loss: 1.31314647738701
Validation loss: 2.4400945096294278

Epoch: 6| Step: 7
Training loss: 1.1435099657339187
Validation loss: 2.3531014176454774

Epoch: 6| Step: 8
Training loss: 1.10595519884644
Validation loss: 2.4333396769379263

Epoch: 6| Step: 9
Training loss: 1.1306325523583927
Validation loss: 2.3200849963832253

Epoch: 6| Step: 10
Training loss: 1.003626862475156
Validation loss: 2.4100656230927435

Epoch: 6| Step: 11
Training loss: 1.0964638963940314
Validation loss: 2.382572844537171

Epoch: 6| Step: 12
Training loss: 0.9685079826022069
Validation loss: 2.379820946277731

Epoch: 6| Step: 13
Training loss: 2.592229558363216
Validation loss: 2.326162127032029

Epoch: 415| Step: 0
Training loss: 1.3553963677596166
Validation loss: 2.3322631744796043

Epoch: 6| Step: 1
Training loss: 1.1883197765638174
Validation loss: 2.358371539973011

Epoch: 6| Step: 2
Training loss: 0.9661501792679729
Validation loss: 2.313141815508962

Epoch: 6| Step: 3
Training loss: 1.3534870447441387
Validation loss: 2.341968486060207

Epoch: 6| Step: 4
Training loss: 1.2243497777174284
Validation loss: 2.2945481256477116

Epoch: 6| Step: 5
Training loss: 1.1882315941943518
Validation loss: 2.331297018493087

Epoch: 6| Step: 6
Training loss: 1.1836244686156536
Validation loss: 2.3697304742199643

Epoch: 6| Step: 7
Training loss: 1.1808635584144802
Validation loss: 2.3271317957701

Epoch: 6| Step: 8
Training loss: 1.8134626265787908
Validation loss: 2.3990160820171598

Epoch: 6| Step: 9
Training loss: 1.172147541143052
Validation loss: 2.327397709354855

Epoch: 6| Step: 10
Training loss: 1.3049017450460565
Validation loss: 2.387192240806788

Epoch: 6| Step: 11
Training loss: 1.0304281254208492
Validation loss: 2.3643770849379786

Epoch: 6| Step: 12
Training loss: 1.5366549953312596
Validation loss: 2.381651014735279

Epoch: 6| Step: 13
Training loss: 1.6364230888095503
Validation loss: 2.3474471887565826

Epoch: 416| Step: 0
Training loss: 2.0367292011023572
Validation loss: 2.3825098656150736

Epoch: 6| Step: 1
Training loss: 1.4170589838774679
Validation loss: 2.442381985377752

Epoch: 6| Step: 2
Training loss: 1.2092083798939948
Validation loss: 2.3860711839028292

Epoch: 6| Step: 3
Training loss: 1.2335752962941489
Validation loss: 2.3332940382512617

Epoch: 6| Step: 4
Training loss: 1.374733378829969
Validation loss: 2.3865297637189835

Epoch: 6| Step: 5
Training loss: 1.1726684935640292
Validation loss: 2.3758377762907963

Epoch: 6| Step: 6
Training loss: 1.5208688845028282
Validation loss: 2.369216796931674

Epoch: 6| Step: 7
Training loss: 1.6366157590377508
Validation loss: 2.3869252297594445

Epoch: 6| Step: 8
Training loss: 0.9117662981280009
Validation loss: 2.4292305184661225

Epoch: 6| Step: 9
Training loss: 0.9565284498124444
Validation loss: 2.336303435342164

Epoch: 6| Step: 10
Training loss: 1.1227698473708225
Validation loss: 2.3438383510986895

Epoch: 6| Step: 11
Training loss: 1.0425226064559074
Validation loss: 2.333781541202476

Epoch: 6| Step: 12
Training loss: 1.2657272862674267
Validation loss: 2.3169217802783884

Epoch: 6| Step: 13
Training loss: 1.0399089606492478
Validation loss: 2.3449457641695965

Epoch: 417| Step: 0
Training loss: 1.4928567394196075
Validation loss: 2.326291655400887

Epoch: 6| Step: 1
Training loss: 1.1725734409521091
Validation loss: 2.3314084479618304

Epoch: 6| Step: 2
Training loss: 1.0755597985747043
Validation loss: 2.3561613736273506

Epoch: 6| Step: 3
Training loss: 1.2753623503607563
Validation loss: 2.2850319426699386

Epoch: 6| Step: 4
Training loss: 0.8663556344715224
Validation loss: 2.3393601727877193

Epoch: 6| Step: 5
Training loss: 1.4097641164550152
Validation loss: 2.4630252522604152

Epoch: 6| Step: 6
Training loss: 0.9058568693704566
Validation loss: 2.361862972266137

Epoch: 6| Step: 7
Training loss: 2.1560479774374137
Validation loss: 2.3950368112691227

Epoch: 6| Step: 8
Training loss: 1.2332653901141102
Validation loss: 2.3485030464782892

Epoch: 6| Step: 9
Training loss: 1.2426813451496268
Validation loss: 2.3353359693407585

Epoch: 6| Step: 10
Training loss: 1.1284196062129779
Validation loss: 2.379992929125656

Epoch: 6| Step: 11
Training loss: 1.408160416673686
Validation loss: 2.415790293584145

Epoch: 6| Step: 12
Training loss: 0.9303217415419488
Validation loss: 2.292994601833539

Epoch: 6| Step: 13
Training loss: 1.0133505957057507
Validation loss: 2.3862749608236182

Epoch: 418| Step: 0
Training loss: 1.1432691261531833
Validation loss: 2.3964214000933306

Epoch: 6| Step: 1
Training loss: 0.8335711775550646
Validation loss: 2.321735002247144

Epoch: 6| Step: 2
Training loss: 1.2250256963876298
Validation loss: 2.3735510924406547

Epoch: 6| Step: 3
Training loss: 1.2909974343638555
Validation loss: 2.362452813305722

Epoch: 6| Step: 4
Training loss: 1.2548463808701147
Validation loss: 2.2353345923127983

Epoch: 6| Step: 5
Training loss: 1.2917498233648128
Validation loss: 2.3906815669829484

Epoch: 6| Step: 6
Training loss: 1.0209378883120543
Validation loss: 2.3132516326223485

Epoch: 6| Step: 7
Training loss: 1.5221338416211867
Validation loss: 2.30439372191669

Epoch: 6| Step: 8
Training loss: 1.147096590676112
Validation loss: 2.3653199656344697

Epoch: 6| Step: 9
Training loss: 1.173640637650211
Validation loss: 2.3691096454343104

Epoch: 6| Step: 10
Training loss: 0.7717519561673586
Validation loss: 2.3750325952526508

Epoch: 6| Step: 11
Training loss: 2.238503436766085
Validation loss: 2.296151488187527

Epoch: 6| Step: 12
Training loss: 1.2050804496755079
Validation loss: 2.339964617458264

Epoch: 6| Step: 13
Training loss: 1.3267455622841595
Validation loss: 2.3314010552703723

Epoch: 419| Step: 0
Training loss: 1.0187312235593828
Validation loss: 2.3209223427316226

Epoch: 6| Step: 1
Training loss: 1.1752707554960964
Validation loss: 2.344718853174688

Epoch: 6| Step: 2
Training loss: 1.8220652381154887
Validation loss: 2.3846628284291986

Epoch: 6| Step: 3
Training loss: 1.0751219125860134
Validation loss: 2.315004473654233

Epoch: 6| Step: 4
Training loss: 1.9850230923325567
Validation loss: 2.3359978188216415

Epoch: 6| Step: 5
Training loss: 0.8443799316465531
Validation loss: 2.3412021677317294

Epoch: 6| Step: 6
Training loss: 1.3793882224689802
Validation loss: 2.4251671905021217

Epoch: 6| Step: 7
Training loss: 1.2381474756610784
Validation loss: 2.3532167889262716

Epoch: 6| Step: 8
Training loss: 0.9122295749705878
Validation loss: 2.3223407832933165

Epoch: 6| Step: 9
Training loss: 1.1837866094098386
Validation loss: 2.4033734600974492

Epoch: 6| Step: 10
Training loss: 1.5427095219592302
Validation loss: 2.3704802895397905

Epoch: 6| Step: 11
Training loss: 1.088787264093136
Validation loss: 2.3967663938767823

Epoch: 6| Step: 12
Training loss: 1.1885716471567058
Validation loss: 2.3069722986899857

Epoch: 6| Step: 13
Training loss: 1.395125575002349
Validation loss: 2.3242199644156405

Epoch: 420| Step: 0
Training loss: 1.1582077566636415
Validation loss: 2.356196283715154

Epoch: 6| Step: 1
Training loss: 1.176739780398668
Validation loss: 2.3317904270451844

Epoch: 6| Step: 2
Training loss: 1.0663023957485405
Validation loss: 2.3437069380984736

Epoch: 6| Step: 3
Training loss: 1.1879382579602558
Validation loss: 2.3349947526250983

Epoch: 6| Step: 4
Training loss: 1.2320575447638877
Validation loss: 2.3535556154457966

Epoch: 6| Step: 5
Training loss: 0.8541997267365158
Validation loss: 2.3714655410851897

Epoch: 6| Step: 6
Training loss: 0.8955044179537966
Validation loss: 2.343614691653485

Epoch: 6| Step: 7
Training loss: 1.7902325797691059
Validation loss: 2.3834736343084373

Epoch: 6| Step: 8
Training loss: 1.3445641025428512
Validation loss: 2.376929801443404

Epoch: 6| Step: 9
Training loss: 1.968626593703283
Validation loss: 2.3778923020105878

Epoch: 6| Step: 10
Training loss: 0.9921527766361841
Validation loss: 2.3302239173851644

Epoch: 6| Step: 11
Training loss: 1.6286695569096414
Validation loss: 2.3439393900163625

Epoch: 6| Step: 12
Training loss: 1.1107837168169392
Validation loss: 2.298364008888468

Epoch: 6| Step: 13
Training loss: 1.1649487085470898
Validation loss: 2.2924116603584217

Epoch: 421| Step: 0
Training loss: 1.5590551931363306
Validation loss: 2.304933334985279

Epoch: 6| Step: 1
Training loss: 0.8013462957401195
Validation loss: 2.335084842471973

Epoch: 6| Step: 2
Training loss: 1.8543106480390907
Validation loss: 2.4371207010231206

Epoch: 6| Step: 3
Training loss: 1.4637349319008204
Validation loss: 2.3606557913944224

Epoch: 6| Step: 4
Training loss: 1.0326597807793985
Validation loss: 2.303273437692619

Epoch: 6| Step: 5
Training loss: 1.2421247358480216
Validation loss: 2.276316704824236

Epoch: 6| Step: 6
Training loss: 0.840692880435317
Validation loss: 2.3626201038743972

Epoch: 6| Step: 7
Training loss: 1.331732036735103
Validation loss: 2.376294011827022

Epoch: 6| Step: 8
Training loss: 1.5946489678477702
Validation loss: 2.334015246332282

Epoch: 6| Step: 9
Training loss: 1.2048059091127987
Validation loss: 2.3062377265509992

Epoch: 6| Step: 10
Training loss: 1.3099895264301502
Validation loss: 2.2967964104785317

Epoch: 6| Step: 11
Training loss: 1.4037375576456357
Validation loss: 2.364870380778913

Epoch: 6| Step: 12
Training loss: 1.0263113193569056
Validation loss: 2.3574069906636317

Epoch: 6| Step: 13
Training loss: 1.090658669375578
Validation loss: 2.407227574227824

Epoch: 422| Step: 0
Training loss: 0.9219336410233778
Validation loss: 2.3548203544569284

Epoch: 6| Step: 1
Training loss: 1.5254093808866114
Validation loss: 2.3970775713683907

Epoch: 6| Step: 2
Training loss: 1.0526946277935383
Validation loss: 2.347047360288483

Epoch: 6| Step: 3
Training loss: 0.9642169476264918
Validation loss: 2.315778826237663

Epoch: 6| Step: 4
Training loss: 1.0625338829472162
Validation loss: 2.3518170730080907

Epoch: 6| Step: 5
Training loss: 1.2362577831150594
Validation loss: 2.3618268244046394

Epoch: 6| Step: 6
Training loss: 1.089259821831962
Validation loss: 2.386432381126171

Epoch: 6| Step: 7
Training loss: 1.0046827823415434
Validation loss: 2.3267379486218918

Epoch: 6| Step: 8
Training loss: 1.9386115423526562
Validation loss: 2.3105077101792935

Epoch: 6| Step: 9
Training loss: 1.7015930425251495
Validation loss: 2.3177681259253564

Epoch: 6| Step: 10
Training loss: 1.5548600144254878
Validation loss: 2.3521674427415276

Epoch: 6| Step: 11
Training loss: 0.8387207329727792
Validation loss: 2.2291447755599134

Epoch: 6| Step: 12
Training loss: 1.330178681324155
Validation loss: 2.341354000777813

Epoch: 6| Step: 13
Training loss: 1.139223884274815
Validation loss: 2.486560504406325

Epoch: 423| Step: 0
Training loss: 0.6649277827838912
Validation loss: 2.335436697164478

Epoch: 6| Step: 1
Training loss: 1.2814299294272717
Validation loss: 2.2889816727410035

Epoch: 6| Step: 2
Training loss: 1.610765319561906
Validation loss: 2.3483194758862247

Epoch: 6| Step: 3
Training loss: 1.3109910556188389
Validation loss: 2.2737016669916432

Epoch: 6| Step: 4
Training loss: 1.2292736728879903
Validation loss: 2.389983547221168

Epoch: 6| Step: 5
Training loss: 1.3121937894113997
Validation loss: 2.317493135518853

Epoch: 6| Step: 6
Training loss: 1.3220520297789906
Validation loss: 2.338498343684822

Epoch: 6| Step: 7
Training loss: 1.0308969066591596
Validation loss: 2.4140133827342765

Epoch: 6| Step: 8
Training loss: 1.8495009006808465
Validation loss: 2.2447897786843254

Epoch: 6| Step: 9
Training loss: 1.0161348090395814
Validation loss: 2.3606885885059157

Epoch: 6| Step: 10
Training loss: 0.9537792149340165
Validation loss: 2.2938176379408026

Epoch: 6| Step: 11
Training loss: 1.4162121024789203
Validation loss: 2.368569242276869

Epoch: 6| Step: 12
Training loss: 1.3726359765906462
Validation loss: 2.402219728953027

Epoch: 6| Step: 13
Training loss: 0.8915789665041304
Validation loss: 2.3365157950732844

Epoch: 424| Step: 0
Training loss: 1.5706686498524742
Validation loss: 2.3303990951465305

Epoch: 6| Step: 1
Training loss: 1.411354380177829
Validation loss: 2.3164585812256524

Epoch: 6| Step: 2
Training loss: 1.847941402827398
Validation loss: 2.3771294231925006

Epoch: 6| Step: 3
Training loss: 1.5364696523820573
Validation loss: 2.2971045099191736

Epoch: 6| Step: 4
Training loss: 1.1104098584012319
Validation loss: 2.3952778739891585

Epoch: 6| Step: 5
Training loss: 0.9788505909798849
Validation loss: 2.420526453641833

Epoch: 6| Step: 6
Training loss: 1.4598551121763295
Validation loss: 2.320739155537887

Epoch: 6| Step: 7
Training loss: 1.2494632522228877
Validation loss: 2.312408150553595

Epoch: 6| Step: 8
Training loss: 1.2637145139879378
Validation loss: 2.3955458196121096

Epoch: 6| Step: 9
Training loss: 1.149686640049332
Validation loss: 2.375388769919401

Epoch: 6| Step: 10
Training loss: 1.1715963922555115
Validation loss: 2.3553154382462855

Epoch: 6| Step: 11
Training loss: 0.9517343726071325
Validation loss: 2.3734439087108377

Epoch: 6| Step: 12
Training loss: 0.8766942651076578
Validation loss: 2.397451419509431

Epoch: 6| Step: 13
Training loss: 1.3265210058689367
Validation loss: 2.345419929654611

Epoch: 425| Step: 0
Training loss: 1.1519944000869649
Validation loss: 2.2852480824776955

Epoch: 6| Step: 1
Training loss: 1.319627392226755
Validation loss: 2.3660919807040557

Epoch: 6| Step: 2
Training loss: 1.957348217298651
Validation loss: 2.340764681714169

Epoch: 6| Step: 3
Training loss: 0.9124481748208257
Validation loss: 2.316155346935653

Epoch: 6| Step: 4
Training loss: 1.2315672315706525
Validation loss: 2.3900861433744445

Epoch: 6| Step: 5
Training loss: 1.1581844952324947
Validation loss: 2.2937050394888785

Epoch: 6| Step: 6
Training loss: 0.8365331292509467
Validation loss: 2.350711905107497

Epoch: 6| Step: 7
Training loss: 1.000590626818994
Validation loss: 2.3608526980795665

Epoch: 6| Step: 8
Training loss: 1.369467790072353
Validation loss: 2.2693243532698397

Epoch: 6| Step: 9
Training loss: 1.0802022300457055
Validation loss: 2.308734073958081

Epoch: 6| Step: 10
Training loss: 1.2846918165486538
Validation loss: 2.313230373134794

Epoch: 6| Step: 11
Training loss: 1.2007794491240003
Validation loss: 2.310526571466402

Epoch: 6| Step: 12
Training loss: 1.1306368225053114
Validation loss: 2.409000293630786

Epoch: 6| Step: 13
Training loss: 1.2667442364950232
Validation loss: 2.3309305809457257

Epoch: 426| Step: 0
Training loss: 1.3310234306846804
Validation loss: 2.38852520103996

Epoch: 6| Step: 1
Training loss: 1.3025249902008238
Validation loss: 2.3902025444006916

Epoch: 6| Step: 2
Training loss: 1.5288152216350661
Validation loss: 2.3483573501831723

Epoch: 6| Step: 3
Training loss: 1.4057817739240013
Validation loss: 2.31503468753699

Epoch: 6| Step: 4
Training loss: 2.123516237933808
Validation loss: 2.379348547537473

Epoch: 6| Step: 5
Training loss: 1.1283840568857681
Validation loss: 2.31734090346544

Epoch: 6| Step: 6
Training loss: 1.1472573477135064
Validation loss: 2.3050059531480227

Epoch: 6| Step: 7
Training loss: 1.2105643405005184
Validation loss: 2.3189276542256616

Epoch: 6| Step: 8
Training loss: 0.971147032769759
Validation loss: 2.4349170248045953

Epoch: 6| Step: 9
Training loss: 1.090481533899897
Validation loss: 2.260335661543064

Epoch: 6| Step: 10
Training loss: 0.7949132895416091
Validation loss: 2.3397327628022895

Epoch: 6| Step: 11
Training loss: 1.648724860866603
Validation loss: 2.282544913528494

Epoch: 6| Step: 12
Training loss: 0.9842318476174716
Validation loss: 2.4012435227820843

Epoch: 6| Step: 13
Training loss: 1.4974513654501196
Validation loss: 2.2730078333997463

Epoch: 427| Step: 0
Training loss: 0.8116474447056572
Validation loss: 2.347554991023837

Epoch: 6| Step: 1
Training loss: 1.195993516186774
Validation loss: 2.351637560292045

Epoch: 6| Step: 2
Training loss: 0.8396108614918261
Validation loss: 2.4244401994564413

Epoch: 6| Step: 3
Training loss: 1.222460063757876
Validation loss: 2.4227404648742144

Epoch: 6| Step: 4
Training loss: 1.2652542607345552
Validation loss: 2.4743595466771198

Epoch: 6| Step: 5
Training loss: 0.9252746741265299
Validation loss: 2.476486989037886

Epoch: 6| Step: 6
Training loss: 1.1749348683263086
Validation loss: 2.4564289703625355

Epoch: 6| Step: 7
Training loss: 1.5045278874529162
Validation loss: 2.4522749368076093

Epoch: 6| Step: 8
Training loss: 1.2964235462194915
Validation loss: 2.41504850586796

Epoch: 6| Step: 9
Training loss: 1.334859625119019
Validation loss: 2.361553822207559

Epoch: 6| Step: 10
Training loss: 1.1783613114675244
Validation loss: 2.3909870838366363

Epoch: 6| Step: 11
Training loss: 1.2911423983059527
Validation loss: 2.275170940786507

Epoch: 6| Step: 12
Training loss: 1.163317653273431
Validation loss: 2.302065838704757

Epoch: 6| Step: 13
Training loss: 2.7370337067362365
Validation loss: 2.313842079128584

Epoch: 428| Step: 0
Training loss: 1.2357834132772822
Validation loss: 2.3096475244490966

Epoch: 6| Step: 1
Training loss: 0.8569182913519753
Validation loss: 2.2186713530440847

Epoch: 6| Step: 2
Training loss: 1.2557957753263038
Validation loss: 2.3179403734810253

Epoch: 6| Step: 3
Training loss: 0.6729531619762301
Validation loss: 2.3048537338815316

Epoch: 6| Step: 4
Training loss: 1.0794241444632446
Validation loss: 2.3582081263376415

Epoch: 6| Step: 5
Training loss: 1.2644226579645919
Validation loss: 2.2317282922640618

Epoch: 6| Step: 6
Training loss: 1.3962902014126484
Validation loss: 2.3230325110886

Epoch: 6| Step: 7
Training loss: 2.140942403831985
Validation loss: 2.3640528599704154

Epoch: 6| Step: 8
Training loss: 0.7907774013145992
Validation loss: 2.3404269488936853

Epoch: 6| Step: 9
Training loss: 1.4928945893253938
Validation loss: 2.2605622446328097

Epoch: 6| Step: 10
Training loss: 1.1732474872945056
Validation loss: 2.3309062865486427

Epoch: 6| Step: 11
Training loss: 1.4766169139382646
Validation loss: 2.2965207041868005

Epoch: 6| Step: 12
Training loss: 1.1581669973878987
Validation loss: 2.2929238891517625

Epoch: 6| Step: 13
Training loss: 1.7703012976161518
Validation loss: 2.4296489377907333

Epoch: 429| Step: 0
Training loss: 1.0475799692077812
Validation loss: 2.4412138333532707

Epoch: 6| Step: 1
Training loss: 1.2641726979811916
Validation loss: 2.3606597166898453

Epoch: 6| Step: 2
Training loss: 1.0900785678580207
Validation loss: 2.375821698436029

Epoch: 6| Step: 3
Training loss: 1.0484742432479075
Validation loss: 2.300368795347269

Epoch: 6| Step: 4
Training loss: 2.12316276563869
Validation loss: 2.3489218502723492

Epoch: 6| Step: 5
Training loss: 1.2580038363484651
Validation loss: 2.384374130004368

Epoch: 6| Step: 6
Training loss: 1.4060850258590583
Validation loss: 2.3526740907725645

Epoch: 6| Step: 7
Training loss: 1.2406067777203458
Validation loss: 2.3664207975374523

Epoch: 6| Step: 8
Training loss: 1.134560335010032
Validation loss: 2.3195779211537757

Epoch: 6| Step: 9
Training loss: 1.3475265661674725
Validation loss: 2.361304978243877

Epoch: 6| Step: 10
Training loss: 1.0170060964343486
Validation loss: 2.3199964904546446

Epoch: 6| Step: 11
Training loss: 1.048546666290614
Validation loss: 2.3114592869085584

Epoch: 6| Step: 12
Training loss: 1.1712030137122313
Validation loss: 2.344085604796138

Epoch: 6| Step: 13
Training loss: 1.337265247171755
Validation loss: 2.323578568662584

Epoch: 430| Step: 0
Training loss: 1.0039373608232673
Validation loss: 2.300861602582915

Epoch: 6| Step: 1
Training loss: 1.1862887177816517
Validation loss: 2.3280354298348676

Epoch: 6| Step: 2
Training loss: 1.3031409685725364
Validation loss: 2.3196579873325613

Epoch: 6| Step: 3
Training loss: 1.6369830443914568
Validation loss: 2.29943076573696

Epoch: 6| Step: 4
Training loss: 1.8280743322931479
Validation loss: 2.359141626668689

Epoch: 6| Step: 5
Training loss: 1.4089074774037997
Validation loss: 2.3692936870447907

Epoch: 6| Step: 6
Training loss: 1.201851009262365
Validation loss: 2.365732512665233

Epoch: 6| Step: 7
Training loss: 1.1041360107100888
Validation loss: 2.2609453799804804

Epoch: 6| Step: 8
Training loss: 0.9131214481731166
Validation loss: 2.3306517594976395

Epoch: 6| Step: 9
Training loss: 1.0060499881019211
Validation loss: 2.420843056305243

Epoch: 6| Step: 10
Training loss: 1.0198283146373508
Validation loss: 2.3950170302476517

Epoch: 6| Step: 11
Training loss: 1.2668359402853606
Validation loss: 2.302880422336779

Epoch: 6| Step: 12
Training loss: 1.253208191885597
Validation loss: 2.3408828108158017

Epoch: 6| Step: 13
Training loss: 1.281897125573971
Validation loss: 2.3277642096516122

Epoch: 431| Step: 0
Training loss: 1.0515064445620994
Validation loss: 2.2948143064990356

Epoch: 6| Step: 1
Training loss: 1.0605710976997544
Validation loss: 2.350787488211881

Epoch: 6| Step: 2
Training loss: 1.421063118007331
Validation loss: 2.3426439974930946

Epoch: 6| Step: 3
Training loss: 1.383273893634294
Validation loss: 2.342024085515154

Epoch: 6| Step: 4
Training loss: 0.9798709825330467
Validation loss: 2.389264546380157

Epoch: 6| Step: 5
Training loss: 0.7516524072747984
Validation loss: 2.2599220314991038

Epoch: 6| Step: 6
Training loss: 0.9015268698912559
Validation loss: 2.408162190767128

Epoch: 6| Step: 7
Training loss: 1.5405653379080582
Validation loss: 2.324122672380056

Epoch: 6| Step: 8
Training loss: 1.3553815478327065
Validation loss: 2.291111090278203

Epoch: 6| Step: 9
Training loss: 2.0337674313333363
Validation loss: 2.3238617306142895

Epoch: 6| Step: 10
Training loss: 1.100998375557958
Validation loss: 2.338580727408009

Epoch: 6| Step: 11
Training loss: 1.2765214705673131
Validation loss: 2.355720214503165

Epoch: 6| Step: 12
Training loss: 1.0749695529618137
Validation loss: 2.3188126482177625

Epoch: 6| Step: 13
Training loss: 1.200077904715554
Validation loss: 2.3295821586143712

Epoch: 432| Step: 0
Training loss: 1.168938428815493
Validation loss: 2.369111509911577

Epoch: 6| Step: 1
Training loss: 1.28696085372528
Validation loss: 2.3152196955383606

Epoch: 6| Step: 2
Training loss: 1.0123978622159238
Validation loss: 2.3459256438832234

Epoch: 6| Step: 3
Training loss: 1.323157591420617
Validation loss: 2.371678730263628

Epoch: 6| Step: 4
Training loss: 1.416184492894135
Validation loss: 2.3556041947620865

Epoch: 6| Step: 5
Training loss: 1.3976246266761596
Validation loss: 2.3065194684250123

Epoch: 6| Step: 6
Training loss: 1.1293461876272388
Validation loss: 2.374320208718545

Epoch: 6| Step: 7
Training loss: 1.0778098267665592
Validation loss: 2.285912730741707

Epoch: 6| Step: 8
Training loss: 1.8684920219024448
Validation loss: 2.3685180385981726

Epoch: 6| Step: 9
Training loss: 1.0972392420246788
Validation loss: 2.290873840838666

Epoch: 6| Step: 10
Training loss: 1.4560434710699355
Validation loss: 2.392864691537016

Epoch: 6| Step: 11
Training loss: 1.0251811076870025
Validation loss: 2.3074537369512433

Epoch: 6| Step: 12
Training loss: 1.1374082800807779
Validation loss: 2.3064849212746084

Epoch: 6| Step: 13
Training loss: 0.8991293855303214
Validation loss: 2.2156578023931757

Epoch: 433| Step: 0
Training loss: 1.2240932904233086
Validation loss: 2.240110005643685

Epoch: 6| Step: 1
Training loss: 1.1172318349724317
Validation loss: 2.325983242087019

Epoch: 6| Step: 2
Training loss: 1.4079047745451436
Validation loss: 2.312594328965491

Epoch: 6| Step: 3
Training loss: 1.2275802860302896
Validation loss: 2.335321790617268

Epoch: 6| Step: 4
Training loss: 1.5576051717551824
Validation loss: 2.3719621680272622

Epoch: 6| Step: 5
Training loss: 1.2799519732525153
Validation loss: 2.3372981183626482

Epoch: 6| Step: 6
Training loss: 1.0235595048007022
Validation loss: 2.374594349374317

Epoch: 6| Step: 7
Training loss: 0.9700399854618238
Validation loss: 2.3679621032315605

Epoch: 6| Step: 8
Training loss: 1.0142120509674974
Validation loss: 2.2999086629825296

Epoch: 6| Step: 9
Training loss: 0.7890256740927978
Validation loss: 2.338978164803855

Epoch: 6| Step: 10
Training loss: 0.8704418942265304
Validation loss: 2.3128268502283773

Epoch: 6| Step: 11
Training loss: 2.1341814391808955
Validation loss: 2.3695050651892697

Epoch: 6| Step: 12
Training loss: 1.1237513712534106
Validation loss: 2.381825926536908

Epoch: 6| Step: 13
Training loss: 1.4137837256364394
Validation loss: 2.3868388237111544

Epoch: 434| Step: 0
Training loss: 1.0620805248903298
Validation loss: 2.335108818379648

Epoch: 6| Step: 1
Training loss: 1.4642536246209452
Validation loss: 2.3681515937310316

Epoch: 6| Step: 2
Training loss: 1.106469500042469
Validation loss: 2.3789012464417523

Epoch: 6| Step: 3
Training loss: 1.2274021263493256
Validation loss: 2.41956554842037

Epoch: 6| Step: 4
Training loss: 1.156592344173692
Validation loss: 2.3015965678523562

Epoch: 6| Step: 5
Training loss: 1.1566390336736563
Validation loss: 2.3312080144847234

Epoch: 6| Step: 6
Training loss: 0.9078413047751032
Validation loss: 2.306987640106583

Epoch: 6| Step: 7
Training loss: 0.8901652102951004
Validation loss: 2.326623463659582

Epoch: 6| Step: 8
Training loss: 1.2946954819831207
Validation loss: 2.3091042379329236

Epoch: 6| Step: 9
Training loss: 1.1211867875362145
Validation loss: 2.314989972733037

Epoch: 6| Step: 10
Training loss: 0.9558260121074835
Validation loss: 2.3911973360762486

Epoch: 6| Step: 11
Training loss: 1.1745824437151018
Validation loss: 2.345673159422872

Epoch: 6| Step: 12
Training loss: 2.1402580893494783
Validation loss: 2.296335818505813

Epoch: 6| Step: 13
Training loss: 1.0555190022870966
Validation loss: 2.3476062871921415

Epoch: 435| Step: 0
Training loss: 0.9781289012209572
Validation loss: 2.3020360156042305

Epoch: 6| Step: 1
Training loss: 1.4340223456467933
Validation loss: 2.392017089747993

Epoch: 6| Step: 2
Training loss: 1.2817121463109322
Validation loss: 2.307874432405527

Epoch: 6| Step: 3
Training loss: 0.921976439503909
Validation loss: 2.2625552519961047

Epoch: 6| Step: 4
Training loss: 1.2182003640299108
Validation loss: 2.373117736193246

Epoch: 6| Step: 5
Training loss: 2.0226586216234526
Validation loss: 2.3098599008817304

Epoch: 6| Step: 6
Training loss: 1.1498451688446443
Validation loss: 2.308634279839683

Epoch: 6| Step: 7
Training loss: 0.9120715376461656
Validation loss: 2.298841841852251

Epoch: 6| Step: 8
Training loss: 1.0169243350543382
Validation loss: 2.3981562228348934

Epoch: 6| Step: 9
Training loss: 1.302410262708626
Validation loss: 2.3272037823898764

Epoch: 6| Step: 10
Training loss: 1.2989223360010649
Validation loss: 2.3846899927317806

Epoch: 6| Step: 11
Training loss: 1.144715590490307
Validation loss: 2.3142694423483503

Epoch: 6| Step: 12
Training loss: 1.1237120143084145
Validation loss: 2.370047419956177

Epoch: 6| Step: 13
Training loss: 1.7723554763735596
Validation loss: 2.377580619109289

Epoch: 436| Step: 0
Training loss: 0.6065666826704363
Validation loss: 2.3218950184097262

Epoch: 6| Step: 1
Training loss: 1.2206244115246958
Validation loss: 2.3545402479451987

Epoch: 6| Step: 2
Training loss: 1.3380914913224264
Validation loss: 2.3367813012510013

Epoch: 6| Step: 3
Training loss: 0.81190230319987
Validation loss: 2.3445613099492393

Epoch: 6| Step: 4
Training loss: 0.9756182568822327
Validation loss: 2.3336514612805015

Epoch: 6| Step: 5
Training loss: 1.1234415704178586
Validation loss: 2.287679599808057

Epoch: 6| Step: 6
Training loss: 1.0242973384779026
Validation loss: 2.3766702975510734

Epoch: 6| Step: 7
Training loss: 1.3960352035226358
Validation loss: 2.287026234574877

Epoch: 6| Step: 8
Training loss: 1.3862781953137133
Validation loss: 2.3380995681808083

Epoch: 6| Step: 9
Training loss: 0.996985750414106
Validation loss: 2.3688040753329087

Epoch: 6| Step: 10
Training loss: 1.8588521526821347
Validation loss: 2.3741475007135806

Epoch: 6| Step: 11
Training loss: 1.5481163207616677
Validation loss: 2.380081190236053

Epoch: 6| Step: 12
Training loss: 0.9853377705148493
Validation loss: 2.3622487796586698

Epoch: 6| Step: 13
Training loss: 1.579918097654825
Validation loss: 2.394407330726686

Epoch: 437| Step: 0
Training loss: 1.2490381832012933
Validation loss: 2.4409628535114303

Epoch: 6| Step: 1
Training loss: 0.8468428897752647
Validation loss: 2.3502724816824463

Epoch: 6| Step: 2
Training loss: 1.0188113773321743
Validation loss: 2.3553602198760646

Epoch: 6| Step: 3
Training loss: 1.1071298473226627
Validation loss: 2.38796133617942

Epoch: 6| Step: 4
Training loss: 0.9630739915672029
Validation loss: 2.399281195617167

Epoch: 6| Step: 5
Training loss: 1.1880466809012036
Validation loss: 2.359243282647343

Epoch: 6| Step: 6
Training loss: 1.1634510149543482
Validation loss: 2.3428369309074917

Epoch: 6| Step: 7
Training loss: 1.2679597018724649
Validation loss: 2.3974383117598594

Epoch: 6| Step: 8
Training loss: 1.4980711456282347
Validation loss: 2.3886237183510146

Epoch: 6| Step: 9
Training loss: 1.006230672804703
Validation loss: 2.3351974508536206

Epoch: 6| Step: 10
Training loss: 0.97131110633675
Validation loss: 2.385969004988585

Epoch: 6| Step: 11
Training loss: 1.5046168642507853
Validation loss: 2.4052452266374806

Epoch: 6| Step: 12
Training loss: 0.9866047990471507
Validation loss: 2.345550160806032

Epoch: 6| Step: 13
Training loss: 2.5627735271079097
Validation loss: 2.3211245700719014

Epoch: 438| Step: 0
Training loss: 1.1468500077437507
Validation loss: 2.3413273706063573

Epoch: 6| Step: 1
Training loss: 1.157413515851891
Validation loss: 2.271312880498065

Epoch: 6| Step: 2
Training loss: 1.107383552439874
Validation loss: 2.3336378007295853

Epoch: 6| Step: 3
Training loss: 1.1362112688738257
Validation loss: 2.4509104539410296

Epoch: 6| Step: 4
Training loss: 1.2306871977161526
Validation loss: 2.3371466541945343

Epoch: 6| Step: 5
Training loss: 1.9590407236957552
Validation loss: 2.4469743224354077

Epoch: 6| Step: 6
Training loss: 1.274397786354398
Validation loss: 2.256675409185055

Epoch: 6| Step: 7
Training loss: 1.3115450245890734
Validation loss: 2.361114837294487

Epoch: 6| Step: 8
Training loss: 1.0076432788337573
Validation loss: 2.3698782137744288

Epoch: 6| Step: 9
Training loss: 1.1004248080565706
Validation loss: 2.3133453602182823

Epoch: 6| Step: 10
Training loss: 0.9754941360614137
Validation loss: 2.4156125745053245

Epoch: 6| Step: 11
Training loss: 1.1726569555027597
Validation loss: 2.3936532476233108

Epoch: 6| Step: 12
Training loss: 1.7129812357999958
Validation loss: 2.3669687432190583

Epoch: 6| Step: 13
Training loss: 1.4057285613654313
Validation loss: 2.346326240947988

Epoch: 439| Step: 0
Training loss: 1.085491720131986
Validation loss: 2.321968684941635

Epoch: 6| Step: 1
Training loss: 1.2847380725925275
Validation loss: 2.3395332912342366

Epoch: 6| Step: 2
Training loss: 0.7230427301371524
Validation loss: 2.324918936777149

Epoch: 6| Step: 3
Training loss: 1.426231417722953
Validation loss: 2.290741929291391

Epoch: 6| Step: 4
Training loss: 1.3272161627886145
Validation loss: 2.292822654969635

Epoch: 6| Step: 5
Training loss: 1.1440490123346558
Validation loss: 2.334833898310263

Epoch: 6| Step: 6
Training loss: 1.1441807128718284
Validation loss: 2.3584107773879066

Epoch: 6| Step: 7
Training loss: 1.0203324600767651
Validation loss: 2.3321708337449274

Epoch: 6| Step: 8
Training loss: 1.1736100640126108
Validation loss: 2.2905859853689456

Epoch: 6| Step: 9
Training loss: 1.0169798983422447
Validation loss: 2.2735871871589026

Epoch: 6| Step: 10
Training loss: 2.0677985132443957
Validation loss: 2.3399337150571315

Epoch: 6| Step: 11
Training loss: 0.956559886461468
Validation loss: 2.3383850879122523

Epoch: 6| Step: 12
Training loss: 1.0500720725982369
Validation loss: 2.279874974134704

Epoch: 6| Step: 13
Training loss: 1.3866228527168354
Validation loss: 2.3445553463117137

Epoch: 440| Step: 0
Training loss: 0.8614048653322823
Validation loss: 2.3816249546286694

Epoch: 6| Step: 1
Training loss: 0.7710675236069171
Validation loss: 2.3617620369130594

Epoch: 6| Step: 2
Training loss: 1.1578541015893677
Validation loss: 2.2539893632431762

Epoch: 6| Step: 3
Training loss: 1.4678902240110854
Validation loss: 2.3521672378392524

Epoch: 6| Step: 4
Training loss: 1.310421615049463
Validation loss: 2.3566838393163185

Epoch: 6| Step: 5
Training loss: 1.142471647599424
Validation loss: 2.299725549863501

Epoch: 6| Step: 6
Training loss: 1.3710191494462043
Validation loss: 2.312459777375798

Epoch: 6| Step: 7
Training loss: 1.069383816975331
Validation loss: 2.2903494717776867

Epoch: 6| Step: 8
Training loss: 1.001746500285704
Validation loss: 2.376688703348732

Epoch: 6| Step: 9
Training loss: 1.3248240569997625
Validation loss: 2.34533886831775

Epoch: 6| Step: 10
Training loss: 1.238736234524919
Validation loss: 2.2922307421219106

Epoch: 6| Step: 11
Training loss: 2.019925283806469
Validation loss: 2.357977198467346

Epoch: 6| Step: 12
Training loss: 1.2719848866524528
Validation loss: 2.353833654598993

Epoch: 6| Step: 13
Training loss: 1.0584551167943723
Validation loss: 2.385304304106837

Epoch: 441| Step: 0
Training loss: 1.1079846117968597
Validation loss: 2.3724143942215417

Epoch: 6| Step: 1
Training loss: 0.8285577830767165
Validation loss: 2.363996920814589

Epoch: 6| Step: 2
Training loss: 2.035110560982465
Validation loss: 2.329791915698453

Epoch: 6| Step: 3
Training loss: 1.2525117434257587
Validation loss: 2.3108006269372527

Epoch: 6| Step: 4
Training loss: 1.4044163935578866
Validation loss: 2.4136674319234817

Epoch: 6| Step: 5
Training loss: 0.7558716765592957
Validation loss: 2.3065449227482278

Epoch: 6| Step: 6
Training loss: 1.0474369192134891
Validation loss: 2.4046116591671622

Epoch: 6| Step: 7
Training loss: 1.3977527327097183
Validation loss: 2.3244391483254407

Epoch: 6| Step: 8
Training loss: 0.9765488890653043
Validation loss: 2.38036893922652

Epoch: 6| Step: 9
Training loss: 0.8046081652003919
Validation loss: 2.347979105993311

Epoch: 6| Step: 10
Training loss: 0.9102012393948845
Validation loss: 2.348849532224204

Epoch: 6| Step: 11
Training loss: 1.5544362080743404
Validation loss: 2.324944704050772

Epoch: 6| Step: 12
Training loss: 1.1277834578675379
Validation loss: 2.317261266135463

Epoch: 6| Step: 13
Training loss: 0.724916131002694
Validation loss: 2.362236497261248

Epoch: 442| Step: 0
Training loss: 0.8269998356128239
Validation loss: 2.3775399577267637

Epoch: 6| Step: 1
Training loss: 1.0586245486575714
Validation loss: 2.255205042776804

Epoch: 6| Step: 2
Training loss: 1.6783532809625552
Validation loss: 2.3822432826759665

Epoch: 6| Step: 3
Training loss: 1.19674576741417
Validation loss: 2.343201211100931

Epoch: 6| Step: 4
Training loss: 1.4069309281460094
Validation loss: 2.3192308001778588

Epoch: 6| Step: 5
Training loss: 1.0702209433496563
Validation loss: 2.2964337753673383

Epoch: 6| Step: 6
Training loss: 1.3096273866373
Validation loss: 2.3470225096195687

Epoch: 6| Step: 7
Training loss: 0.8543042831902051
Validation loss: 2.3807026985688866

Epoch: 6| Step: 8
Training loss: 1.3112067708761712
Validation loss: 2.3632902688451223

Epoch: 6| Step: 9
Training loss: 1.0895164846089664
Validation loss: 2.360808343152568

Epoch: 6| Step: 10
Training loss: 1.0653528733015152
Validation loss: 2.3117693861328665

Epoch: 6| Step: 11
Training loss: 1.2339038191026652
Validation loss: 2.4138473498231243

Epoch: 6| Step: 12
Training loss: 1.8564510275137243
Validation loss: 2.4506667725320344

Epoch: 6| Step: 13
Training loss: 1.2190566044058346
Validation loss: 2.337426628210232

Epoch: 443| Step: 0
Training loss: 1.0608000900881285
Validation loss: 2.393660775782082

Epoch: 6| Step: 1
Training loss: 1.2332857371932138
Validation loss: 2.35928505259722

Epoch: 6| Step: 2
Training loss: 1.1423910917131122
Validation loss: 2.2977474638071045

Epoch: 6| Step: 3
Training loss: 0.7593647504829089
Validation loss: 2.3123838588968675

Epoch: 6| Step: 4
Training loss: 1.9121628657370584
Validation loss: 2.3260490928060262

Epoch: 6| Step: 5
Training loss: 0.9909784655131868
Validation loss: 2.3174752579443827

Epoch: 6| Step: 6
Training loss: 1.2920571885369518
Validation loss: 2.3893198172496724

Epoch: 6| Step: 7
Training loss: 1.3866964419007808
Validation loss: 2.3427285684734396

Epoch: 6| Step: 8
Training loss: 1.411441798189537
Validation loss: 2.3399759721201607

Epoch: 6| Step: 9
Training loss: 0.9775477817691495
Validation loss: 2.333146523616672

Epoch: 6| Step: 10
Training loss: 0.9732417293993817
Validation loss: 2.320331200379679

Epoch: 6| Step: 11
Training loss: 1.2189585189458436
Validation loss: 2.263644131628627

Epoch: 6| Step: 12
Training loss: 1.2329917110248032
Validation loss: 2.2792719627617704

Epoch: 6| Step: 13
Training loss: 0.9568304357236191
Validation loss: 2.346753774405473

Epoch: 444| Step: 0
Training loss: 1.0509956453126077
Validation loss: 2.3733101647454693

Epoch: 6| Step: 1
Training loss: 1.1152447434459458
Validation loss: 2.343568321487765

Epoch: 6| Step: 2
Training loss: 1.2982776364404622
Validation loss: 2.3785171609534466

Epoch: 6| Step: 3
Training loss: 1.1135088771539867
Validation loss: 2.3553651722194604

Epoch: 6| Step: 4
Training loss: 1.2229538820356471
Validation loss: 2.3551898224445122

Epoch: 6| Step: 5
Training loss: 0.9462684652726444
Validation loss: 2.3742315811974346

Epoch: 6| Step: 6
Training loss: 0.9620837376625221
Validation loss: 2.4026281178335807

Epoch: 6| Step: 7
Training loss: 0.8296132300517503
Validation loss: 2.409323087424309

Epoch: 6| Step: 8
Training loss: 1.0510671006985703
Validation loss: 2.4102947106052603

Epoch: 6| Step: 9
Training loss: 1.0359984228939587
Validation loss: 2.319582171267963

Epoch: 6| Step: 10
Training loss: 2.099254148729265
Validation loss: 2.3854845573528696

Epoch: 6| Step: 11
Training loss: 1.3199603271302338
Validation loss: 2.393605837564924

Epoch: 6| Step: 12
Training loss: 1.4200985889058986
Validation loss: 2.3302363107584987

Epoch: 6| Step: 13
Training loss: 0.9843536253530987
Validation loss: 2.3234508365037296

Epoch: 445| Step: 0
Training loss: 0.673326631876988
Validation loss: 2.3000813262270303

Epoch: 6| Step: 1
Training loss: 1.245851690524974
Validation loss: 2.339569218673457

Epoch: 6| Step: 2
Training loss: 1.231386308821996
Validation loss: 2.324347300260685

Epoch: 6| Step: 3
Training loss: 0.9565338087592615
Validation loss: 2.3869343176871567

Epoch: 6| Step: 4
Training loss: 1.261129519225073
Validation loss: 2.3052815256633714

Epoch: 6| Step: 5
Training loss: 1.800487237789197
Validation loss: 2.385781885985507

Epoch: 6| Step: 6
Training loss: 1.2008248176687502
Validation loss: 2.402911262966244

Epoch: 6| Step: 7
Training loss: 0.9022844303333877
Validation loss: 2.3308539035398352

Epoch: 6| Step: 8
Training loss: 1.2451645786017869
Validation loss: 2.3620492814178458

Epoch: 6| Step: 9
Training loss: 1.5390259404366498
Validation loss: 2.3239483160409744

Epoch: 6| Step: 10
Training loss: 1.3627355844354208
Validation loss: 2.348843623132255

Epoch: 6| Step: 11
Training loss: 0.923506957151337
Validation loss: 2.319747130579182

Epoch: 6| Step: 12
Training loss: 1.1676557242628272
Validation loss: 2.358838027385441

Epoch: 6| Step: 13
Training loss: 0.9583931088809605
Validation loss: 2.2609639143061826

Epoch: 446| Step: 0
Training loss: 0.9526851452084676
Validation loss: 2.303340874265392

Epoch: 6| Step: 1
Training loss: 1.0083585339279137
Validation loss: 2.335701791480652

Epoch: 6| Step: 2
Training loss: 1.207512127043363
Validation loss: 2.2413073700285873

Epoch: 6| Step: 3
Training loss: 1.2382037983929282
Validation loss: 2.3862017378401714

Epoch: 6| Step: 4
Training loss: 1.2545619688027707
Validation loss: 2.3479636256951015

Epoch: 6| Step: 5
Training loss: 1.1691745415384065
Validation loss: 2.3368482513648177

Epoch: 6| Step: 6
Training loss: 1.0665828572567828
Validation loss: 2.346582061282822

Epoch: 6| Step: 7
Training loss: 0.8913418077048426
Validation loss: 2.3061554241377618

Epoch: 6| Step: 8
Training loss: 2.1744514387422504
Validation loss: 2.283790584032773

Epoch: 6| Step: 9
Training loss: 1.4085861298941575
Validation loss: 2.423727655770682

Epoch: 6| Step: 10
Training loss: 0.9179219335427149
Validation loss: 2.284205140488897

Epoch: 6| Step: 11
Training loss: 0.9293244237933347
Validation loss: 2.3588157202273243

Epoch: 6| Step: 12
Training loss: 1.1666766007318354
Validation loss: 2.336717612580514

Epoch: 6| Step: 13
Training loss: 0.9363124319328221
Validation loss: 2.3664785416157352

Epoch: 447| Step: 0
Training loss: 1.0109871240431696
Validation loss: 2.343097748596665

Epoch: 6| Step: 1
Training loss: 1.9728826713922842
Validation loss: 2.341102100261191

Epoch: 6| Step: 2
Training loss: 1.4384837723374562
Validation loss: 2.2909995930674825

Epoch: 6| Step: 3
Training loss: 1.0299517811904855
Validation loss: 2.305228277895772

Epoch: 6| Step: 4
Training loss: 0.9128943584008322
Validation loss: 2.289662453140211

Epoch: 6| Step: 5
Training loss: 1.2890834459857192
Validation loss: 2.2606180805514997

Epoch: 6| Step: 6
Training loss: 1.1646558542253729
Validation loss: 2.322741906160479

Epoch: 6| Step: 7
Training loss: 1.3598832681991686
Validation loss: 2.3350378511306915

Epoch: 6| Step: 8
Training loss: 1.4412610154008052
Validation loss: 2.369556107973265

Epoch: 6| Step: 9
Training loss: 1.084489474451704
Validation loss: 2.30933857346398

Epoch: 6| Step: 10
Training loss: 1.003703412296659
Validation loss: 2.3192166235846385

Epoch: 6| Step: 11
Training loss: 1.2876070996525149
Validation loss: 2.3056588833190057

Epoch: 6| Step: 12
Training loss: 0.809966060786881
Validation loss: 2.3187006571071755

Epoch: 6| Step: 13
Training loss: 0.7777718750033351
Validation loss: 2.275249462069883

Epoch: 448| Step: 0
Training loss: 1.1243647265216723
Validation loss: 2.285718835027404

Epoch: 6| Step: 1
Training loss: 1.8273853859922347
Validation loss: 2.3807814117251263

Epoch: 6| Step: 2
Training loss: 1.1395625561779172
Validation loss: 2.324589172499699

Epoch: 6| Step: 3
Training loss: 0.930269652108054
Validation loss: 2.440278084065647

Epoch: 6| Step: 4
Training loss: 1.2031457081783703
Validation loss: 2.3518514088107474

Epoch: 6| Step: 5
Training loss: 0.9529610477204421
Validation loss: 2.3263789113107856

Epoch: 6| Step: 6
Training loss: 1.0723408323501455
Validation loss: 2.3201228227536363

Epoch: 6| Step: 7
Training loss: 1.0220926198888662
Validation loss: 2.276835341622319

Epoch: 6| Step: 8
Training loss: 1.0477773848103982
Validation loss: 2.3290996516851004

Epoch: 6| Step: 9
Training loss: 1.305895628612752
Validation loss: 2.3368317406958674

Epoch: 6| Step: 10
Training loss: 1.1431210523967876
Validation loss: 2.2771280527393576

Epoch: 6| Step: 11
Training loss: 1.3082260298411008
Validation loss: 2.3826613339425635

Epoch: 6| Step: 12
Training loss: 1.2192562714556807
Validation loss: 2.2508403730915827

Epoch: 6| Step: 13
Training loss: 1.4319826474763373
Validation loss: 2.328135906974932

Epoch: 449| Step: 0
Training loss: 1.2262013869609216
Validation loss: 2.3084380536307023

Epoch: 6| Step: 1
Training loss: 1.8126874366394332
Validation loss: 2.360312935177255

Epoch: 6| Step: 2
Training loss: 1.124200748938362
Validation loss: 2.2867714364343037

Epoch: 6| Step: 3
Training loss: 1.4363366270708475
Validation loss: 2.314076019354193

Epoch: 6| Step: 4
Training loss: 1.2824954980544405
Validation loss: 2.410689745184156

Epoch: 6| Step: 5
Training loss: 0.8059721756361243
Validation loss: 2.397088641591257

Epoch: 6| Step: 6
Training loss: 1.3039737965051468
Validation loss: 2.415010993314422

Epoch: 6| Step: 7
Training loss: 1.0598657152300326
Validation loss: 2.381956837464607

Epoch: 6| Step: 8
Training loss: 0.8290088543321269
Validation loss: 2.3791231047496963

Epoch: 6| Step: 9
Training loss: 0.9953819574048015
Validation loss: 2.2715264269581583

Epoch: 6| Step: 10
Training loss: 1.5075855776154894
Validation loss: 2.4257445766329515

Epoch: 6| Step: 11
Training loss: 1.0797261497546728
Validation loss: 2.390983773921592

Epoch: 6| Step: 12
Training loss: 0.9814788964442099
Validation loss: 2.349267455266501

Epoch: 6| Step: 13
Training loss: 1.1632859885155757
Validation loss: 2.35770846089592

Epoch: 450| Step: 0
Training loss: 0.8809340756157947
Validation loss: 2.3145690858458057

Epoch: 6| Step: 1
Training loss: 1.1230510678420373
Validation loss: 2.369866752494243

Epoch: 6| Step: 2
Training loss: 1.286868314498721
Validation loss: 2.3634895454615

Epoch: 6| Step: 3
Training loss: 1.3416974559749866
Validation loss: 2.3231337927883313

Epoch: 6| Step: 4
Training loss: 1.242569198984071
Validation loss: 2.3636564879772974

Epoch: 6| Step: 5
Training loss: 0.747743749331587
Validation loss: 2.3588468436813166

Epoch: 6| Step: 6
Training loss: 1.2212954617553342
Validation loss: 2.2903227287585914

Epoch: 6| Step: 7
Training loss: 1.5047454474234996
Validation loss: 2.3083786294462305

Epoch: 6| Step: 8
Training loss: 1.0903365138944463
Validation loss: 2.2961217322983205

Epoch: 6| Step: 9
Training loss: 0.9813756206307874
Validation loss: 2.3470780745477633

Epoch: 6| Step: 10
Training loss: 0.7679607806175466
Validation loss: 2.3192106268319908

Epoch: 6| Step: 11
Training loss: 1.4704481007621153
Validation loss: 2.384620904190899

Epoch: 6| Step: 12
Training loss: 2.004157632449191
Validation loss: 2.3318100822992225

Epoch: 6| Step: 13
Training loss: 1.2059360214109667
Validation loss: 2.3013401802154676

Epoch: 451| Step: 0
Training loss: 1.2041626456082446
Validation loss: 2.425939094716337

Epoch: 6| Step: 1
Training loss: 1.1094651521399246
Validation loss: 2.2777057917788555

Epoch: 6| Step: 2
Training loss: 1.0675517207710834
Validation loss: 2.3233487366427177

Epoch: 6| Step: 3
Training loss: 1.0736639081127406
Validation loss: 2.373196635569237

Epoch: 6| Step: 4
Training loss: 1.1349339056726437
Validation loss: 2.4072626958293957

Epoch: 6| Step: 5
Training loss: 1.148511300343184
Validation loss: 2.3966312863023833

Epoch: 6| Step: 6
Training loss: 1.2417485163207278
Validation loss: 2.3608521328706016

Epoch: 6| Step: 7
Training loss: 0.9894401781369884
Validation loss: 2.32318560941963

Epoch: 6| Step: 8
Training loss: 1.204271241149402
Validation loss: 2.36876430984977

Epoch: 6| Step: 9
Training loss: 0.8715620279020205
Validation loss: 2.3091006349508123

Epoch: 6| Step: 10
Training loss: 1.2089868400684178
Validation loss: 2.3313329749904357

Epoch: 6| Step: 11
Training loss: 1.8082904602570395
Validation loss: 2.390638811046221

Epoch: 6| Step: 12
Training loss: 0.9681483215320634
Validation loss: 2.455899468884206

Epoch: 6| Step: 13
Training loss: 0.9819691337174616
Validation loss: 2.282149219269085

Epoch: 452| Step: 0
Training loss: 0.68115103116473
Validation loss: 2.344463905250527

Epoch: 6| Step: 1
Training loss: 0.7233094021651651
Validation loss: 2.3907277964952263

Epoch: 6| Step: 2
Training loss: 1.3926540530613405
Validation loss: 2.2715622325824363

Epoch: 6| Step: 3
Training loss: 1.0427152061172384
Validation loss: 2.312757062329279

Epoch: 6| Step: 4
Training loss: 0.9831899442762988
Validation loss: 2.3113553862573615

Epoch: 6| Step: 5
Training loss: 1.2196459289237624
Validation loss: 2.2724116284805413

Epoch: 6| Step: 6
Training loss: 0.9328775252229201
Validation loss: 2.3305575060719432

Epoch: 6| Step: 7
Training loss: 1.1096372697312338
Validation loss: 2.2527590212188584

Epoch: 6| Step: 8
Training loss: 1.315122935346874
Validation loss: 2.2943914482151118

Epoch: 6| Step: 9
Training loss: 0.9792844755576892
Validation loss: 2.3706922555943213

Epoch: 6| Step: 10
Training loss: 1.3566412787596502
Validation loss: 2.332360386344548

Epoch: 6| Step: 11
Training loss: 1.1930095952903967
Validation loss: 2.2977380387510333

Epoch: 6| Step: 12
Training loss: 1.9349788136271133
Validation loss: 2.350786799532319

Epoch: 6| Step: 13
Training loss: 1.5804406729753184
Validation loss: 2.3610317582636116

Epoch: 453| Step: 0
Training loss: 1.225824267554629
Validation loss: 2.3452157898597044

Epoch: 6| Step: 1
Training loss: 1.2140183174410497
Validation loss: 2.3442525378210095

Epoch: 6| Step: 2
Training loss: 0.519728859627918
Validation loss: 2.3267233968724055

Epoch: 6| Step: 3
Training loss: 0.7808706888635838
Validation loss: 2.3450704791150834

Epoch: 6| Step: 4
Training loss: 0.7860438705266501
Validation loss: 2.2549604019905827

Epoch: 6| Step: 5
Training loss: 1.3560091200299618
Validation loss: 2.3834974649634746

Epoch: 6| Step: 6
Training loss: 1.9343248006441955
Validation loss: 2.36490086843907

Epoch: 6| Step: 7
Training loss: 1.2160971697833116
Validation loss: 2.321275784214234

Epoch: 6| Step: 8
Training loss: 1.1935868616126328
Validation loss: 2.2961279551529366

Epoch: 6| Step: 9
Training loss: 0.8616659665304718
Validation loss: 2.4378847008454305

Epoch: 6| Step: 10
Training loss: 1.0610266174731198
Validation loss: 2.2558537558833787

Epoch: 6| Step: 11
Training loss: 1.1118370995754872
Validation loss: 2.390313783661853

Epoch: 6| Step: 12
Training loss: 1.3767300905360862
Validation loss: 2.267634507187263

Epoch: 6| Step: 13
Training loss: 1.1751709935374592
Validation loss: 2.3031988264799406

Epoch: 454| Step: 0
Training loss: 1.1152679384862987
Validation loss: 2.403033107718882

Epoch: 6| Step: 1
Training loss: 1.3181325759778506
Validation loss: 2.3320569914551412

Epoch: 6| Step: 2
Training loss: 0.9249280386074221
Validation loss: 2.360095756047059

Epoch: 6| Step: 3
Training loss: 0.9153854707782944
Validation loss: 2.342561138346018

Epoch: 6| Step: 4
Training loss: 0.8406164473768607
Validation loss: 2.3728729620496885

Epoch: 6| Step: 5
Training loss: 1.0705303332446834
Validation loss: 2.3214661700974326

Epoch: 6| Step: 6
Training loss: 1.264425392070658
Validation loss: 2.323060967699613

Epoch: 6| Step: 7
Training loss: 1.8960011865555797
Validation loss: 2.3868731820051576

Epoch: 6| Step: 8
Training loss: 0.9275065895319468
Validation loss: 2.2718869245325997

Epoch: 6| Step: 9
Training loss: 1.4841007983273735
Validation loss: 2.332145530503312

Epoch: 6| Step: 10
Training loss: 1.3877370614651452
Validation loss: 2.4299799311828836

Epoch: 6| Step: 11
Training loss: 1.2370523317349214
Validation loss: 2.298836513478228

Epoch: 6| Step: 12
Training loss: 1.047552885664275
Validation loss: 2.359529421324048

Epoch: 6| Step: 13
Training loss: 0.8319418774096228
Validation loss: 2.300010896071082

Epoch: 455| Step: 0
Training loss: 1.0221938519468539
Validation loss: 2.358127712244728

Epoch: 6| Step: 1
Training loss: 1.3246560963991436
Validation loss: 2.2900045958556734

Epoch: 6| Step: 2
Training loss: 0.9903243887354102
Validation loss: 2.319322543025131

Epoch: 6| Step: 3
Training loss: 0.7701685246677217
Validation loss: 2.373982497052531

Epoch: 6| Step: 4
Training loss: 1.8992813809297804
Validation loss: 2.329919784910941

Epoch: 6| Step: 5
Training loss: 1.2230353209572074
Validation loss: 2.3211244563102382

Epoch: 6| Step: 6
Training loss: 1.2902105594276818
Validation loss: 2.374841483190349

Epoch: 6| Step: 7
Training loss: 1.0144858207031358
Validation loss: 2.233035204145097

Epoch: 6| Step: 8
Training loss: 0.4889545376352252
Validation loss: 2.3769396410461954

Epoch: 6| Step: 9
Training loss: 1.1822284339878628
Validation loss: 2.390868953381058

Epoch: 6| Step: 10
Training loss: 1.4738939179092911
Validation loss: 2.3178886348052057

Epoch: 6| Step: 11
Training loss: 1.25942955561526
Validation loss: 2.332444439904763

Epoch: 6| Step: 12
Training loss: 1.045435812936857
Validation loss: 2.299552754552653

Epoch: 6| Step: 13
Training loss: 1.2917169694437187
Validation loss: 2.3519985906741687

Epoch: 456| Step: 0
Training loss: 1.13935551478663
Validation loss: 2.3698019208464234

Epoch: 6| Step: 1
Training loss: 1.0658519268327877
Validation loss: 2.2912504580778084

Epoch: 6| Step: 2
Training loss: 1.1332673310714052
Validation loss: 2.2628643219143907

Epoch: 6| Step: 3
Training loss: 1.0044169629772077
Validation loss: 2.3422407126697324

Epoch: 6| Step: 4
Training loss: 1.4622706893732924
Validation loss: 2.3980249187194893

Epoch: 6| Step: 5
Training loss: 0.9836276108395279
Validation loss: 2.3507268661888885

Epoch: 6| Step: 6
Training loss: 1.3980379865885548
Validation loss: 2.327445562653993

Epoch: 6| Step: 7
Training loss: 1.8089821318149353
Validation loss: 2.347705404227616

Epoch: 6| Step: 8
Training loss: 1.2259813620689268
Validation loss: 2.3976647701904676

Epoch: 6| Step: 9
Training loss: 0.8177539707415141
Validation loss: 2.327804727294142

Epoch: 6| Step: 10
Training loss: 0.6933828000691921
Validation loss: 2.271619323362204

Epoch: 6| Step: 11
Training loss: 1.2748334757197644
Validation loss: 2.365715630325512

Epoch: 6| Step: 12
Training loss: 1.1024227165417382
Validation loss: 2.3329922608825444

Epoch: 6| Step: 13
Training loss: 1.1749390281928263
Validation loss: 2.322742621366448

Epoch: 457| Step: 0
Training loss: 1.0213300832774723
Validation loss: 2.2721014471899963

Epoch: 6| Step: 1
Training loss: 0.8339747622648398
Validation loss: 2.377783802384738

Epoch: 6| Step: 2
Training loss: 1.631625679574163
Validation loss: 2.272374811855779

Epoch: 6| Step: 3
Training loss: 1.1071714626079943
Validation loss: 2.3028273405873176

Epoch: 6| Step: 4
Training loss: 1.0804774837733937
Validation loss: 2.2775303409192036

Epoch: 6| Step: 5
Training loss: 1.1389571759962518
Validation loss: 2.3988447859956246

Epoch: 6| Step: 6
Training loss: 1.3251333763362318
Validation loss: 2.28798642656676

Epoch: 6| Step: 7
Training loss: 1.1655862551224998
Validation loss: 2.3397493077844103

Epoch: 6| Step: 8
Training loss: 1.830805647126603
Validation loss: 2.350183479077619

Epoch: 6| Step: 9
Training loss: 1.26227781587968
Validation loss: 2.3606229531022005

Epoch: 6| Step: 10
Training loss: 0.990337389040072
Validation loss: 2.4017319086958877

Epoch: 6| Step: 11
Training loss: 1.127806236480122
Validation loss: 2.414848062032069

Epoch: 6| Step: 12
Training loss: 1.1161378851586947
Validation loss: 2.3480830723639174

Epoch: 6| Step: 13
Training loss: 0.9055681952437541
Validation loss: 2.245306634079993

Epoch: 458| Step: 0
Training loss: 1.3344597032450853
Validation loss: 2.4351855765589594

Epoch: 6| Step: 1
Training loss: 1.187186500928458
Validation loss: 2.3762675132152915

Epoch: 6| Step: 2
Training loss: 1.314593054024636
Validation loss: 2.2725074612733387

Epoch: 6| Step: 3
Training loss: 0.9577494203789295
Validation loss: 2.3338436244051652

Epoch: 6| Step: 4
Training loss: 0.9735998762216858
Validation loss: 2.3438247723427805

Epoch: 6| Step: 5
Training loss: 0.9423471710896936
Validation loss: 2.350606119687574

Epoch: 6| Step: 6
Training loss: 1.0996052011847686
Validation loss: 2.314398466030495

Epoch: 6| Step: 7
Training loss: 0.7603776129182755
Validation loss: 2.3520553105732986

Epoch: 6| Step: 8
Training loss: 0.8782902572270408
Validation loss: 2.3542304798537415

Epoch: 6| Step: 9
Training loss: 0.9155812158629261
Validation loss: 2.362628434047509

Epoch: 6| Step: 10
Training loss: 0.9700809380594286
Validation loss: 2.3923524999222194

Epoch: 6| Step: 11
Training loss: 1.2120126196956507
Validation loss: 2.373553658724935

Epoch: 6| Step: 12
Training loss: 1.966232021707941
Validation loss: 2.3214254324935863

Epoch: 6| Step: 13
Training loss: 0.9827918688817743
Validation loss: 2.3708191142746244

Epoch: 459| Step: 0
Training loss: 0.8765886734643472
Validation loss: 2.2819069767481377

Epoch: 6| Step: 1
Training loss: 0.9453094104054302
Validation loss: 2.31845240902126

Epoch: 6| Step: 2
Training loss: 1.1188902782956431
Validation loss: 2.328183507256413

Epoch: 6| Step: 3
Training loss: 1.0685439708732225
Validation loss: 2.321014280491922

Epoch: 6| Step: 4
Training loss: 1.0597397347988207
Validation loss: 2.321114551292775

Epoch: 6| Step: 5
Training loss: 1.3146330439644376
Validation loss: 2.3035366972078153

Epoch: 6| Step: 6
Training loss: 1.2098235882874044
Validation loss: 2.309610617357341

Epoch: 6| Step: 7
Training loss: 0.7740682476817479
Validation loss: 2.376208658959581

Epoch: 6| Step: 8
Training loss: 1.1553851837003248
Validation loss: 2.354969163028325

Epoch: 6| Step: 9
Training loss: 1.9487321815875083
Validation loss: 2.23127890568388

Epoch: 6| Step: 10
Training loss: 0.7677351618667938
Validation loss: 2.362727050019054

Epoch: 6| Step: 11
Training loss: 1.439520949444137
Validation loss: 2.3863867913908985

Epoch: 6| Step: 12
Training loss: 0.906262693645106
Validation loss: 2.386579665749298

Epoch: 6| Step: 13
Training loss: 1.0491649008855486
Validation loss: 2.40643724315764

Epoch: 460| Step: 0
Training loss: 1.540016459587618
Validation loss: 2.3739983936592353

Epoch: 6| Step: 1
Training loss: 0.9655865115300541
Validation loss: 2.363336726091532

Epoch: 6| Step: 2
Training loss: 0.7912657542415501
Validation loss: 2.3539284482045066

Epoch: 6| Step: 3
Training loss: 1.0636205374341323
Validation loss: 2.279777656319888

Epoch: 6| Step: 4
Training loss: 1.307397050396768
Validation loss: 2.4121356084694954

Epoch: 6| Step: 5
Training loss: 1.8364808921993525
Validation loss: 2.4015190292923436

Epoch: 6| Step: 6
Training loss: 1.0209009900671469
Validation loss: 2.2905381331595165

Epoch: 6| Step: 7
Training loss: 0.9457174647495542
Validation loss: 2.3254570775129495

Epoch: 6| Step: 8
Training loss: 1.2147284449965012
Validation loss: 2.354064176526205

Epoch: 6| Step: 9
Training loss: 0.938620088937053
Validation loss: 2.3765821050138523

Epoch: 6| Step: 10
Training loss: 1.0574130409866607
Validation loss: 2.3136055644687024

Epoch: 6| Step: 11
Training loss: 1.1689149220020894
Validation loss: 2.276021569043302

Epoch: 6| Step: 12
Training loss: 0.935517535615676
Validation loss: 2.334835582637066

Epoch: 6| Step: 13
Training loss: 1.2321682773360954
Validation loss: 2.3814671185833434

Epoch: 461| Step: 0
Training loss: 1.2890444205201137
Validation loss: 2.3293586485708766

Epoch: 6| Step: 1
Training loss: 0.8004963437770667
Validation loss: 2.3832095666140156

Epoch: 6| Step: 2
Training loss: 1.0293839072216742
Validation loss: 2.4325759053025378

Epoch: 6| Step: 3
Training loss: 1.300964434214551
Validation loss: 2.302237908667597

Epoch: 6| Step: 4
Training loss: 2.0343304091575307
Validation loss: 2.3583280053102644

Epoch: 6| Step: 5
Training loss: 0.8549299590104971
Validation loss: 2.316633174256054

Epoch: 6| Step: 6
Training loss: 1.546979573115573
Validation loss: 2.3228244238035387

Epoch: 6| Step: 7
Training loss: 0.9718016888115673
Validation loss: 2.30524637166542

Epoch: 6| Step: 8
Training loss: 1.0994673479686732
Validation loss: 2.3145462313013634

Epoch: 6| Step: 9
Training loss: 1.3768662878480347
Validation loss: 2.2775805690424433

Epoch: 6| Step: 10
Training loss: 1.0912970147596015
Validation loss: 2.2944938768492267

Epoch: 6| Step: 11
Training loss: 1.1549766849460035
Validation loss: 2.258588279864232

Epoch: 6| Step: 12
Training loss: 0.7423436853805832
Validation loss: 2.3994988442060503

Epoch: 6| Step: 13
Training loss: 1.0383066855961087
Validation loss: 2.320427138343484

Epoch: 462| Step: 0
Training loss: 0.9554319447924657
Validation loss: 2.2789624126041486

Epoch: 6| Step: 1
Training loss: 1.0439919585323854
Validation loss: 2.372778347251879

Epoch: 6| Step: 2
Training loss: 1.4038622612024103
Validation loss: 2.427046186710463

Epoch: 6| Step: 3
Training loss: 0.9322603032183919
Validation loss: 2.3027768805087407

Epoch: 6| Step: 4
Training loss: 1.4440711386743543
Validation loss: 2.3635350906564843

Epoch: 6| Step: 5
Training loss: 0.9991879742545431
Validation loss: 2.3417580718928064

Epoch: 6| Step: 6
Training loss: 0.9146798486262506
Validation loss: 2.3469036441746622

Epoch: 6| Step: 7
Training loss: 1.1934260023531629
Validation loss: 2.3268186239547752

Epoch: 6| Step: 8
Training loss: 1.232971165724411
Validation loss: 2.37253318313295

Epoch: 6| Step: 9
Training loss: 1.0446864923625792
Validation loss: 2.316745683591841

Epoch: 6| Step: 10
Training loss: 1.0810179665384299
Validation loss: 2.361052223048681

Epoch: 6| Step: 11
Training loss: 0.9336336518383599
Validation loss: 2.3155103289097463

Epoch: 6| Step: 12
Training loss: 0.8107009925016523
Validation loss: 2.331633869261733

Epoch: 6| Step: 13
Training loss: 2.1907185446102426
Validation loss: 2.336035996597724

Epoch: 463| Step: 0
Training loss: 2.0753108883256806
Validation loss: 2.299595509504817

Epoch: 6| Step: 1
Training loss: 1.245886806416404
Validation loss: 2.3191429536471064

Epoch: 6| Step: 2
Training loss: 0.9712440932890825
Validation loss: 2.2726209368165575

Epoch: 6| Step: 3
Training loss: 1.173817360014594
Validation loss: 2.322123575662635

Epoch: 6| Step: 4
Training loss: 1.0545253487728632
Validation loss: 2.343416786707981

Epoch: 6| Step: 5
Training loss: 0.6774053297022957
Validation loss: 2.3409437392356107

Epoch: 6| Step: 6
Training loss: 0.7806946497220176
Validation loss: 2.3505721136103532

Epoch: 6| Step: 7
Training loss: 1.1989148279820585
Validation loss: 2.389699354703406

Epoch: 6| Step: 8
Training loss: 1.266649796766743
Validation loss: 2.336628315293301

Epoch: 6| Step: 9
Training loss: 0.9915939718470241
Validation loss: 2.320352841719832

Epoch: 6| Step: 10
Training loss: 1.1570231971228666
Validation loss: 2.2717352384996428

Epoch: 6| Step: 11
Training loss: 0.8685253236995509
Validation loss: 2.281484574683738

Epoch: 6| Step: 12
Training loss: 1.0072116095450263
Validation loss: 2.2611508194890173

Epoch: 6| Step: 13
Training loss: 1.0239238602561558
Validation loss: 2.318774077963744

Epoch: 464| Step: 0
Training loss: 1.0978190888408825
Validation loss: 2.408890256248299

Epoch: 6| Step: 1
Training loss: 0.9414342978956808
Validation loss: 2.3468238761313254

Epoch: 6| Step: 2
Training loss: 1.3104872938731433
Validation loss: 2.338313477859548

Epoch: 6| Step: 3
Training loss: 1.620234765125818
Validation loss: 2.3485284360111303

Epoch: 6| Step: 4
Training loss: 1.1869900763047823
Validation loss: 2.410497308374557

Epoch: 6| Step: 5
Training loss: 1.2489168242406938
Validation loss: 2.348593686801057

Epoch: 6| Step: 6
Training loss: 1.175406665635499
Validation loss: 2.4065032184372614

Epoch: 6| Step: 7
Training loss: 0.8472925979450311
Validation loss: 2.3943951892008304

Epoch: 6| Step: 8
Training loss: 0.8129408080757449
Validation loss: 2.376025948701742

Epoch: 6| Step: 9
Training loss: 1.8387035554353257
Validation loss: 2.354749322330576

Epoch: 6| Step: 10
Training loss: 0.8875980470790584
Validation loss: 2.369645185697744

Epoch: 6| Step: 11
Training loss: 1.193756586825588
Validation loss: 2.3334198901240706

Epoch: 6| Step: 12
Training loss: 1.1191338610486314
Validation loss: 2.3085697463561177

Epoch: 6| Step: 13
Training loss: 0.6519920177526918
Validation loss: 2.3720331891563977

Epoch: 465| Step: 0
Training loss: 0.8061893484678635
Validation loss: 2.323789687350712

Epoch: 6| Step: 1
Training loss: 0.7312587607095322
Validation loss: 2.34457866717536

Epoch: 6| Step: 2
Training loss: 1.2219638509226576
Validation loss: 2.318319065216874

Epoch: 6| Step: 3
Training loss: 2.021876966897046
Validation loss: 2.311553942261174

Epoch: 6| Step: 4
Training loss: 0.9280637778695261
Validation loss: 2.411262878677189

Epoch: 6| Step: 5
Training loss: 1.0630804608056958
Validation loss: 2.34085728578833

Epoch: 6| Step: 6
Training loss: 1.0779696919350987
Validation loss: 2.3779871213857064

Epoch: 6| Step: 7
Training loss: 1.5213992838148165
Validation loss: 2.281739559565458

Epoch: 6| Step: 8
Training loss: 0.8715235244390511
Validation loss: 2.335168438423896

Epoch: 6| Step: 9
Training loss: 1.28379828877618
Validation loss: 2.27402912551474

Epoch: 6| Step: 10
Training loss: 1.076057940369574
Validation loss: 2.302250056274847

Epoch: 6| Step: 11
Training loss: 1.1765896372306177
Validation loss: 2.3684688054126197

Epoch: 6| Step: 12
Training loss: 1.0749738224302103
Validation loss: 2.4059749649048947

Epoch: 6| Step: 13
Training loss: 1.2176511652666655
Validation loss: 2.392780344396852

Epoch: 466| Step: 0
Training loss: 1.2847469338912882
Validation loss: 2.3403148188917107

Epoch: 6| Step: 1
Training loss: 0.8820551096119318
Validation loss: 2.417089695410131

Epoch: 6| Step: 2
Training loss: 1.2322238575628597
Validation loss: 2.4115933648216137

Epoch: 6| Step: 3
Training loss: 1.0677974136532709
Validation loss: 2.3695838084312255

Epoch: 6| Step: 4
Training loss: 1.29901837554574
Validation loss: 2.3792561302851585

Epoch: 6| Step: 5
Training loss: 1.1204641880575035
Validation loss: 2.3388890393183637

Epoch: 6| Step: 6
Training loss: 1.185247996330378
Validation loss: 2.341401813006373

Epoch: 6| Step: 7
Training loss: 0.8155556221756084
Validation loss: 2.3709272406018473

Epoch: 6| Step: 8
Training loss: 1.6328230131988097
Validation loss: 2.3473796224571664

Epoch: 6| Step: 9
Training loss: 1.7962677302643564
Validation loss: 2.3235901843408797

Epoch: 6| Step: 10
Training loss: 0.9299613164731995
Validation loss: 2.3080561987021455

Epoch: 6| Step: 11
Training loss: 0.8411180277067872
Validation loss: 2.251508629714718

Epoch: 6| Step: 12
Training loss: 1.0996041170743243
Validation loss: 2.2963944602753608

Epoch: 6| Step: 13
Training loss: 0.525502217860673
Validation loss: 2.2946371919432207

Epoch: 467| Step: 0
Training loss: 0.9930111927773111
Validation loss: 2.276539019714978

Epoch: 6| Step: 1
Training loss: 1.7484000248851612
Validation loss: 2.3036045740089794

Epoch: 6| Step: 2
Training loss: 1.1662347993340512
Validation loss: 2.322914301954144

Epoch: 6| Step: 3
Training loss: 1.2099669474036074
Validation loss: 2.220675497070517

Epoch: 6| Step: 4
Training loss: 1.239301195279606
Validation loss: 2.346190213041177

Epoch: 6| Step: 5
Training loss: 1.1717504307978257
Validation loss: 2.2903323236865116

Epoch: 6| Step: 6
Training loss: 0.7568482231865739
Validation loss: 2.3215924312560814

Epoch: 6| Step: 7
Training loss: 1.3338366492314138
Validation loss: 2.308501236514925

Epoch: 6| Step: 8
Training loss: 1.3493118068497685
Validation loss: 2.3055792638998884

Epoch: 6| Step: 9
Training loss: 0.7996896514326987
Validation loss: 2.314491816551604

Epoch: 6| Step: 10
Training loss: 0.9163223761561062
Validation loss: 2.3248879854580076

Epoch: 6| Step: 11
Training loss: 0.9313467269945623
Validation loss: 2.3439225601605784

Epoch: 6| Step: 12
Training loss: 1.3497800594882132
Validation loss: 2.3142388659275652

Epoch: 6| Step: 13
Training loss: 0.8055759451101733
Validation loss: 2.3854445460172946

Epoch: 468| Step: 0
Training loss: 0.9291365457507951
Validation loss: 2.361526441709877

Epoch: 6| Step: 1
Training loss: 0.6372806901122611
Validation loss: 2.3280643582696348

Epoch: 6| Step: 2
Training loss: 1.0505144993154996
Validation loss: 2.3008650165166653

Epoch: 6| Step: 3
Training loss: 1.2179336748339606
Validation loss: 2.324193683370867

Epoch: 6| Step: 4
Training loss: 1.1536346963153998
Validation loss: 2.3768233891939854

Epoch: 6| Step: 5
Training loss: 1.8710892902233516
Validation loss: 2.313103102484042

Epoch: 6| Step: 6
Training loss: 0.8800267854320403
Validation loss: 2.3927569576194596

Epoch: 6| Step: 7
Training loss: 1.2571543043562903
Validation loss: 2.321832579829999

Epoch: 6| Step: 8
Training loss: 1.3030918437298233
Validation loss: 2.228415407935616

Epoch: 6| Step: 9
Training loss: 0.6887555362042751
Validation loss: 2.379090343021406

Epoch: 6| Step: 10
Training loss: 1.1450971955270781
Validation loss: 2.2235638203541903

Epoch: 6| Step: 11
Training loss: 1.0321244664800078
Validation loss: 2.252404650752558

Epoch: 6| Step: 12
Training loss: 1.467403525149554
Validation loss: 2.308311212884663

Epoch: 6| Step: 13
Training loss: 1.115076003713066
Validation loss: 2.321460499409265

Epoch: 469| Step: 0
Training loss: 1.4072596845891647
Validation loss: 2.311329830182865

Epoch: 6| Step: 1
Training loss: 1.143013113312078
Validation loss: 2.331293451184195

Epoch: 6| Step: 2
Training loss: 1.1859857541848189
Validation loss: 2.3676425638983107

Epoch: 6| Step: 3
Training loss: 1.0200409765988496
Validation loss: 2.3848074542451383

Epoch: 6| Step: 4
Training loss: 1.3693631545041565
Validation loss: 2.2916451066271732

Epoch: 6| Step: 5
Training loss: 1.8860480022531183
Validation loss: 2.267066839064932

Epoch: 6| Step: 6
Training loss: 1.0523145188744243
Validation loss: 2.3158470139600884

Epoch: 6| Step: 7
Training loss: 0.8480586841381297
Validation loss: 2.3012421882332244

Epoch: 6| Step: 8
Training loss: 0.9366634451198723
Validation loss: 2.3348332845298545

Epoch: 6| Step: 9
Training loss: 1.3436916693513585
Validation loss: 2.3328627259742105

Epoch: 6| Step: 10
Training loss: 1.174743549281316
Validation loss: 2.3208525743035047

Epoch: 6| Step: 11
Training loss: 0.787872172013318
Validation loss: 2.355731259791765

Epoch: 6| Step: 12
Training loss: 1.1227254656411048
Validation loss: 2.2898453851987464

Epoch: 6| Step: 13
Training loss: 0.8918008905321197
Validation loss: 2.338454564023586

Epoch: 470| Step: 0
Training loss: 1.167658531812564
Validation loss: 2.31539723638722

Epoch: 6| Step: 1
Training loss: 1.0221503513808239
Validation loss: 2.3992753466212386

Epoch: 6| Step: 2
Training loss: 1.213624741271637
Validation loss: 2.3787295995929267

Epoch: 6| Step: 3
Training loss: 1.8687366140645292
Validation loss: 2.2582531763772415

Epoch: 6| Step: 4
Training loss: 0.891206417703464
Validation loss: 2.270581137621784

Epoch: 6| Step: 5
Training loss: 1.109307461684106
Validation loss: 2.4072678853782445

Epoch: 6| Step: 6
Training loss: 1.0618870032733931
Validation loss: 2.2810664005429646

Epoch: 6| Step: 7
Training loss: 1.2671485490374674
Validation loss: 2.3340456592369088

Epoch: 6| Step: 8
Training loss: 1.0639267486152735
Validation loss: 2.322321212101754

Epoch: 6| Step: 9
Training loss: 0.9396490578737592
Validation loss: 2.3406065437518806

Epoch: 6| Step: 10
Training loss: 0.6541500553119709
Validation loss: 2.273624135244394

Epoch: 6| Step: 11
Training loss: 0.49472987809785135
Validation loss: 2.323079208947734

Epoch: 6| Step: 12
Training loss: 1.3402315251479373
Validation loss: 2.235814361874594

Epoch: 6| Step: 13
Training loss: 1.2613351433618663
Validation loss: 2.2611652110406855

Epoch: 471| Step: 0
Training loss: 0.9093272154008873
Validation loss: 2.353095848252531

Epoch: 6| Step: 1
Training loss: 1.230466376408301
Validation loss: 2.3872813370071033

Epoch: 6| Step: 2
Training loss: 0.9268772381931066
Validation loss: 2.380302436135053

Epoch: 6| Step: 3
Training loss: 1.988057002104246
Validation loss: 2.289467596791993

Epoch: 6| Step: 4
Training loss: 1.0880897106953626
Validation loss: 2.3287607896621227

Epoch: 6| Step: 5
Training loss: 0.9697300660222775
Validation loss: 2.3489826149205366

Epoch: 6| Step: 6
Training loss: 1.3564800700162378
Validation loss: 2.302122089499816

Epoch: 6| Step: 7
Training loss: 0.763202415619832
Validation loss: 2.3651148737263297

Epoch: 6| Step: 8
Training loss: 1.2585330581475869
Validation loss: 2.358857964535151

Epoch: 6| Step: 9
Training loss: 0.9446291384523647
Validation loss: 2.32622929515768

Epoch: 6| Step: 10
Training loss: 0.8116244954375381
Validation loss: 2.302596475515737

Epoch: 6| Step: 11
Training loss: 1.0691299030963564
Validation loss: 2.3057661226816637

Epoch: 6| Step: 12
Training loss: 1.3010720967423868
Validation loss: 2.3363234534164623

Epoch: 6| Step: 13
Training loss: 1.467752564383976
Validation loss: 2.3445536689675865

Epoch: 472| Step: 0
Training loss: 0.7490020311223643
Validation loss: 2.309453634432263

Epoch: 6| Step: 1
Training loss: 0.8539111445252637
Validation loss: 2.285525404066803

Epoch: 6| Step: 2
Training loss: 1.8628796798502907
Validation loss: 2.295452908508267

Epoch: 6| Step: 3
Training loss: 0.9578575459726618
Validation loss: 2.3514854416618896

Epoch: 6| Step: 4
Training loss: 1.2924397011420907
Validation loss: 2.3402775659110002

Epoch: 6| Step: 5
Training loss: 1.189864264528656
Validation loss: 2.325638590119442

Epoch: 6| Step: 6
Training loss: 1.0201869916614905
Validation loss: 2.374162440990129

Epoch: 6| Step: 7
Training loss: 1.088437612327112
Validation loss: 2.315906114782643

Epoch: 6| Step: 8
Training loss: 1.3747480768556908
Validation loss: 2.3524613910071785

Epoch: 6| Step: 9
Training loss: 0.9646342432306639
Validation loss: 2.2460768244508236

Epoch: 6| Step: 10
Training loss: 1.2805872808201
Validation loss: 2.296586534853754

Epoch: 6| Step: 11
Training loss: 1.2341136414244642
Validation loss: 2.3107612722661495

Epoch: 6| Step: 12
Training loss: 0.9313756537951595
Validation loss: 2.2938068170164327

Epoch: 6| Step: 13
Training loss: 0.8130644524892675
Validation loss: 2.3466082486321027

Epoch: 473| Step: 0
Training loss: 1.4637938946169877
Validation loss: 2.2877371221040392

Epoch: 6| Step: 1
Training loss: 1.1589979561169748
Validation loss: 2.2470366265844532

Epoch: 6| Step: 2
Training loss: 1.2851915441611848
Validation loss: 2.2951987308605357

Epoch: 6| Step: 3
Training loss: 1.0024616222693639
Validation loss: 2.2463115028380987

Epoch: 6| Step: 4
Training loss: 0.9541874576507877
Validation loss: 2.282002277658461

Epoch: 6| Step: 5
Training loss: 1.0512929471708536
Validation loss: 2.348431124352516

Epoch: 6| Step: 6
Training loss: 0.8106191947570319
Validation loss: 2.29166938766661

Epoch: 6| Step: 7
Training loss: 1.0108907839138475
Validation loss: 2.339473878857669

Epoch: 6| Step: 8
Training loss: 0.8684786558059531
Validation loss: 2.354486725380298

Epoch: 6| Step: 9
Training loss: 1.1868171736464337
Validation loss: 2.426949035514644

Epoch: 6| Step: 10
Training loss: 1.8184851778069808
Validation loss: 2.345790377972763

Epoch: 6| Step: 11
Training loss: 1.0826254084407616
Validation loss: 2.3478220960107308

Epoch: 6| Step: 12
Training loss: 1.128021051579039
Validation loss: 2.3617991805912575

Epoch: 6| Step: 13
Training loss: 1.1172086273543147
Validation loss: 2.4286177654706846

Epoch: 474| Step: 0
Training loss: 1.6861318764340982
Validation loss: 2.2928197903558383

Epoch: 6| Step: 1
Training loss: 1.2496592534071675
Validation loss: 2.286585966232038

Epoch: 6| Step: 2
Training loss: 1.0362483184027746
Validation loss: 2.3632710552139753

Epoch: 6| Step: 3
Training loss: 0.8825259123285822
Validation loss: 2.266270958367379

Epoch: 6| Step: 4
Training loss: 1.0966799049003568
Validation loss: 2.266189849902154

Epoch: 6| Step: 5
Training loss: 0.8149377126821443
Validation loss: 2.2435681796849076

Epoch: 6| Step: 6
Training loss: 1.5181443816165305
Validation loss: 2.3202543058362606

Epoch: 6| Step: 7
Training loss: 0.9735762446737879
Validation loss: 2.292332025929601

Epoch: 6| Step: 8
Training loss: 0.9167778894110782
Validation loss: 2.3703468347684757

Epoch: 6| Step: 9
Training loss: 1.1444927117951844
Validation loss: 2.364807343986062

Epoch: 6| Step: 10
Training loss: 1.3262494925480914
Validation loss: 2.2946065181511566

Epoch: 6| Step: 11
Training loss: 0.8388944006381602
Validation loss: 2.2856369765188065

Epoch: 6| Step: 12
Training loss: 1.0080566701891343
Validation loss: 2.2847614321329215

Epoch: 6| Step: 13
Training loss: 0.9919245814602922
Validation loss: 2.2705961993397223

Epoch: 475| Step: 0
Training loss: 0.6167431934230049
Validation loss: 2.3358683644310663

Epoch: 6| Step: 1
Training loss: 1.088520080255026
Validation loss: 2.3554860268508193

Epoch: 6| Step: 2
Training loss: 1.2832926308175894
Validation loss: 2.2939640216351433

Epoch: 6| Step: 3
Training loss: 1.1109899666759766
Validation loss: 2.374365044361135

Epoch: 6| Step: 4
Training loss: 1.3161379939838238
Validation loss: 2.3031162351457444

Epoch: 6| Step: 5
Training loss: 1.0147918805382088
Validation loss: 2.3389787489992564

Epoch: 6| Step: 6
Training loss: 1.1088400074616365
Validation loss: 2.400410779327729

Epoch: 6| Step: 7
Training loss: 1.15683525326303
Validation loss: 2.3175862612809226

Epoch: 6| Step: 8
Training loss: 1.7865627098917443
Validation loss: 2.412821492842896

Epoch: 6| Step: 9
Training loss: 0.933061008801477
Validation loss: 2.4037939305182046

Epoch: 6| Step: 10
Training loss: 0.82002580264829
Validation loss: 2.3525576562768626

Epoch: 6| Step: 11
Training loss: 0.8326576990826139
Validation loss: 2.3271599979048174

Epoch: 6| Step: 12
Training loss: 1.5098677942366339
Validation loss: 2.241855178953462

Epoch: 6| Step: 13
Training loss: 0.6935453783300546
Validation loss: 2.292819310683623

Epoch: 476| Step: 0
Training loss: 1.0608820095916165
Validation loss: 2.3585368227316383

Epoch: 6| Step: 1
Training loss: 0.9631142192239677
Validation loss: 2.3149654155322716

Epoch: 6| Step: 2
Training loss: 1.1640544097414438
Validation loss: 2.3383735353112427

Epoch: 6| Step: 3
Training loss: 1.9003066919655502
Validation loss: 2.4623413831897625

Epoch: 6| Step: 4
Training loss: 0.6911613116702722
Validation loss: 2.4117776409539595

Epoch: 6| Step: 5
Training loss: 0.8485706512898072
Validation loss: 2.3429675479939953

Epoch: 6| Step: 6
Training loss: 0.9308308855148091
Validation loss: 2.396922960432722

Epoch: 6| Step: 7
Training loss: 0.8954495043892138
Validation loss: 2.2750837801940667

Epoch: 6| Step: 8
Training loss: 1.1119499411155773
Validation loss: 2.2971165585619744

Epoch: 6| Step: 9
Training loss: 1.0748355273910877
Validation loss: 2.304909922756038

Epoch: 6| Step: 10
Training loss: 0.9883596517351255
Validation loss: 2.3576804768393482

Epoch: 6| Step: 11
Training loss: 1.0145991499736526
Validation loss: 2.2587361578785035

Epoch: 6| Step: 12
Training loss: 0.8998938325675068
Validation loss: 2.391368077299672

Epoch: 6| Step: 13
Training loss: 1.0036993741276656
Validation loss: 2.3715191301579837

Epoch: 477| Step: 0
Training loss: 0.9665012716885887
Validation loss: 2.299755599121116

Epoch: 6| Step: 1
Training loss: 0.863683477398853
Validation loss: 2.324952538489154

Epoch: 6| Step: 2
Training loss: 0.9274181911346175
Validation loss: 2.329137545185336

Epoch: 6| Step: 3
Training loss: 1.2771792057926352
Validation loss: 2.3323526273509323

Epoch: 6| Step: 4
Training loss: 1.1176973259992065
Validation loss: 2.302185306528011

Epoch: 6| Step: 5
Training loss: 2.0468910740810884
Validation loss: 2.2928524167758546

Epoch: 6| Step: 6
Training loss: 0.7828048492484164
Validation loss: 2.4298928758975147

Epoch: 6| Step: 7
Training loss: 0.9273225532815184
Validation loss: 2.4141173252467305

Epoch: 6| Step: 8
Training loss: 0.904005296138846
Validation loss: 2.346502968693742

Epoch: 6| Step: 9
Training loss: 0.8585492414994877
Validation loss: 2.3384974480268004

Epoch: 6| Step: 10
Training loss: 0.8944928689910173
Validation loss: 2.3349170130084604

Epoch: 6| Step: 11
Training loss: 1.1418241703139262
Validation loss: 2.361549523331937

Epoch: 6| Step: 12
Training loss: 1.0815462753899792
Validation loss: 2.32953957655003

Epoch: 6| Step: 13
Training loss: 1.6206587242210115
Validation loss: 2.3915103761028265

Epoch: 478| Step: 0
Training loss: 1.523085646467266
Validation loss: 2.3762257364673354

Epoch: 6| Step: 1
Training loss: 0.7703333126452169
Validation loss: 2.2664710044182197

Epoch: 6| Step: 2
Training loss: 0.7671432233724813
Validation loss: 2.2742774318707673

Epoch: 6| Step: 3
Training loss: 1.1197994616333284
Validation loss: 2.314013380874684

Epoch: 6| Step: 4
Training loss: 1.4070935580253279
Validation loss: 2.340101919825888

Epoch: 6| Step: 5
Training loss: 0.7950310034674477
Validation loss: 2.3057663611711106

Epoch: 6| Step: 6
Training loss: 1.732892889526368
Validation loss: 2.378543122538252

Epoch: 6| Step: 7
Training loss: 0.8333967939690958
Validation loss: 2.2971024553045485

Epoch: 6| Step: 8
Training loss: 1.0173658856195607
Validation loss: 2.3607928975692927

Epoch: 6| Step: 9
Training loss: 1.2057522413821014
Validation loss: 2.3123597931533535

Epoch: 6| Step: 10
Training loss: 0.9015075309828153
Validation loss: 2.4122441879580836

Epoch: 6| Step: 11
Training loss: 0.8500102182783883
Validation loss: 2.282042871978336

Epoch: 6| Step: 12
Training loss: 0.7002607285761443
Validation loss: 2.3446689316456926

Epoch: 6| Step: 13
Training loss: 1.0403875635670232
Validation loss: 2.355358628593405

Epoch: 479| Step: 0
Training loss: 0.9501891336896838
Validation loss: 2.382188045634032

Epoch: 6| Step: 1
Training loss: 0.9233584349166173
Validation loss: 2.2675633620562134

Epoch: 6| Step: 2
Training loss: 1.2966923412700198
Validation loss: 2.3822998678920664

Epoch: 6| Step: 3
Training loss: 1.0489876908124682
Validation loss: 2.3147118989314275

Epoch: 6| Step: 4
Training loss: 1.1328536453667255
Validation loss: 2.3837984554423324

Epoch: 6| Step: 5
Training loss: 1.15078070718891
Validation loss: 2.366410166688497

Epoch: 6| Step: 6
Training loss: 1.0253902762276192
Validation loss: 2.320166190332336

Epoch: 6| Step: 7
Training loss: 0.9562123434593367
Validation loss: 2.2795979733555294

Epoch: 6| Step: 8
Training loss: 0.9400757057059267
Validation loss: 2.2727318923843582

Epoch: 6| Step: 9
Training loss: 1.0444546519506648
Validation loss: 2.3203539056896387

Epoch: 6| Step: 10
Training loss: 1.3925465370223098
Validation loss: 2.4124170930832727

Epoch: 6| Step: 11
Training loss: 0.9966811897555061
Validation loss: 2.3717157878145327

Epoch: 6| Step: 12
Training loss: 1.2761499268156817
Validation loss: 2.395901648968361

Epoch: 6| Step: 13
Training loss: 2.18160226595222
Validation loss: 2.33501489061201

Epoch: 480| Step: 0
Training loss: 1.1044745945562269
Validation loss: 2.30911245779596

Epoch: 6| Step: 1
Training loss: 1.0730387917551958
Validation loss: 2.3749291302006115

Epoch: 6| Step: 2
Training loss: 1.0555086683155
Validation loss: 2.3541795283939138

Epoch: 6| Step: 3
Training loss: 2.0229496312492037
Validation loss: 2.3054916589027634

Epoch: 6| Step: 4
Training loss: 0.8364990701094508
Validation loss: 2.4326251040917337

Epoch: 6| Step: 5
Training loss: 0.7365999403101876
Validation loss: 2.3997485680715434

Epoch: 6| Step: 6
Training loss: 1.29542543220356
Validation loss: 2.2676535368412027

Epoch: 6| Step: 7
Training loss: 1.2134780321368657
Validation loss: 2.382730754739159

Epoch: 6| Step: 8
Training loss: 0.944413253948558
Validation loss: 2.3628173904440706

Epoch: 6| Step: 9
Training loss: 0.9892308192886867
Validation loss: 2.3685320489057577

Epoch: 6| Step: 10
Training loss: 0.9064331527318487
Validation loss: 2.3731625540440096

Epoch: 6| Step: 11
Training loss: 0.9457127377991733
Validation loss: 2.3531494171606258

Epoch: 6| Step: 12
Training loss: 0.9881385428787227
Validation loss: 2.3285712115755284

Epoch: 6| Step: 13
Training loss: 1.1768746598983169
Validation loss: 2.3400709617221036

Epoch: 481| Step: 0
Training loss: 0.894373250942266
Validation loss: 2.3481834739216136

Epoch: 6| Step: 1
Training loss: 0.9379187602343609
Validation loss: 2.3213883622982974

Epoch: 6| Step: 2
Training loss: 1.035817233968413
Validation loss: 2.342148141128631

Epoch: 6| Step: 3
Training loss: 0.6772658077745348
Validation loss: 2.27127874257969

Epoch: 6| Step: 4
Training loss: 0.9985416328201484
Validation loss: 2.3093060745014817

Epoch: 6| Step: 5
Training loss: 0.9275110558213346
Validation loss: 2.3458468283279643

Epoch: 6| Step: 6
Training loss: 0.7065586597147614
Validation loss: 2.3931802509884545

Epoch: 6| Step: 7
Training loss: 1.9140382103449243
Validation loss: 2.329379478014966

Epoch: 6| Step: 8
Training loss: 1.1830526695167498
Validation loss: 2.295877766581673

Epoch: 6| Step: 9
Training loss: 1.3918769858337132
Validation loss: 2.3426945104231183

Epoch: 6| Step: 10
Training loss: 0.931885693064691
Validation loss: 2.320436212163999

Epoch: 6| Step: 11
Training loss: 1.18563827338302
Validation loss: 2.345313904446976

Epoch: 6| Step: 12
Training loss: 0.9886948093390329
Validation loss: 2.365262430097358

Epoch: 6| Step: 13
Training loss: 1.3120098561201656
Validation loss: 2.367019555850107

Epoch: 482| Step: 0
Training loss: 1.1741414342262322
Validation loss: 2.391428076444304

Epoch: 6| Step: 1
Training loss: 0.8641300085367638
Validation loss: 2.3599913276379536

Epoch: 6| Step: 2
Training loss: 0.8220005287646707
Validation loss: 2.3537026319251617

Epoch: 6| Step: 3
Training loss: 0.8950201639109705
Validation loss: 2.2863847833444404

Epoch: 6| Step: 4
Training loss: 1.246889249103556
Validation loss: 2.230579655993663

Epoch: 6| Step: 5
Training loss: 1.084477492883744
Validation loss: 2.253864617726624

Epoch: 6| Step: 6
Training loss: 1.7453061915653323
Validation loss: 2.320007406913509

Epoch: 6| Step: 7
Training loss: 1.023437732958585
Validation loss: 2.3723014581430357

Epoch: 6| Step: 8
Training loss: 1.1611455430599424
Validation loss: 2.28300373601851

Epoch: 6| Step: 9
Training loss: 1.0765799909923113
Validation loss: 2.3429297173262222

Epoch: 6| Step: 10
Training loss: 0.5638313696980523
Validation loss: 2.2970565557838043

Epoch: 6| Step: 11
Training loss: 0.9903439493142107
Validation loss: 2.2735138676513604

Epoch: 6| Step: 12
Training loss: 1.0968381609259534
Validation loss: 2.288445861965762

Epoch: 6| Step: 13
Training loss: 1.2992777340196837
Validation loss: 2.263954056178226

Epoch: 483| Step: 0
Training loss: 1.1561413791258042
Validation loss: 2.282981252153689

Epoch: 6| Step: 1
Training loss: 1.1266052661243775
Validation loss: 2.270347108140938

Epoch: 6| Step: 2
Training loss: 0.9739031784569788
Validation loss: 2.362811477766612

Epoch: 6| Step: 3
Training loss: 0.8224353026247591
Validation loss: 2.325007529880002

Epoch: 6| Step: 4
Training loss: 1.1508952719455816
Validation loss: 2.398010645611767

Epoch: 6| Step: 5
Training loss: 0.9384661782094094
Validation loss: 2.2935499732809017

Epoch: 6| Step: 6
Training loss: 0.9668210113286868
Validation loss: 2.23161268854352

Epoch: 6| Step: 7
Training loss: 0.6817571108733628
Validation loss: 2.314855136228476

Epoch: 6| Step: 8
Training loss: 1.8253276321836671
Validation loss: 2.3509755468910414

Epoch: 6| Step: 9
Training loss: 1.0181448560901283
Validation loss: 2.2858528555605915

Epoch: 6| Step: 10
Training loss: 0.9785155945433347
Validation loss: 2.3557426559897343

Epoch: 6| Step: 11
Training loss: 1.0775603875322657
Validation loss: 2.2837330195828884

Epoch: 6| Step: 12
Training loss: 1.6190929152726636
Validation loss: 2.3301419621382347

Epoch: 6| Step: 13
Training loss: 0.8245472908592213
Validation loss: 2.3802636823755

Epoch: 484| Step: 0
Training loss: 1.1378478115839372
Validation loss: 2.3483423319760863

Epoch: 6| Step: 1
Training loss: 0.9483108888483059
Validation loss: 2.3666562792341934

Epoch: 6| Step: 2
Training loss: 1.8263815366776708
Validation loss: 2.4425094334252915

Epoch: 6| Step: 3
Training loss: 0.8144333651773403
Validation loss: 2.203033384851563

Epoch: 6| Step: 4
Training loss: 1.1338883125702024
Validation loss: 2.2947778168974216

Epoch: 6| Step: 5
Training loss: 1.0743054164258137
Validation loss: 2.1800815447948896

Epoch: 6| Step: 6
Training loss: 0.8609493746345331
Validation loss: 2.330204356294285

Epoch: 6| Step: 7
Training loss: 1.1813449458157146
Validation loss: 2.323916615438565

Epoch: 6| Step: 8
Training loss: 0.8928750376951682
Validation loss: 2.340684359456991

Epoch: 6| Step: 9
Training loss: 0.7644464413560739
Validation loss: 2.3067298323078256

Epoch: 6| Step: 10
Training loss: 0.8391306844104225
Validation loss: 2.309970031612783

Epoch: 6| Step: 11
Training loss: 0.9705549775637259
Validation loss: 2.3233849463490768

Epoch: 6| Step: 12
Training loss: 1.3325084379691226
Validation loss: 2.286878624318146

Epoch: 6| Step: 13
Training loss: 0.7063100097277496
Validation loss: 2.310333261218194

Epoch: 485| Step: 0
Training loss: 0.9923993282524182
Validation loss: 2.31237156385765

Epoch: 6| Step: 1
Training loss: 0.9899303563985747
Validation loss: 2.365017801730433

Epoch: 6| Step: 2
Training loss: 0.9373158273990769
Validation loss: 2.3595066415491757

Epoch: 6| Step: 3
Training loss: 1.1018046660757428
Validation loss: 2.3216943499677716

Epoch: 6| Step: 4
Training loss: 1.0509586680784726
Validation loss: 2.3922595294705933

Epoch: 6| Step: 5
Training loss: 0.8814053756961094
Validation loss: 2.3177209140113066

Epoch: 6| Step: 6
Training loss: 0.9304070773372944
Validation loss: 2.377084793913325

Epoch: 6| Step: 7
Training loss: 0.6882673879173589
Validation loss: 2.347344605273746

Epoch: 6| Step: 8
Training loss: 1.1778364501040306
Validation loss: 2.29797914011554

Epoch: 6| Step: 9
Training loss: 1.0280762588403103
Validation loss: 2.2914843049489777

Epoch: 6| Step: 10
Training loss: 1.4121679607811484
Validation loss: 2.313519370405097

Epoch: 6| Step: 11
Training loss: 0.7929507098471319
Validation loss: 2.3633146132634

Epoch: 6| Step: 12
Training loss: 1.9338164230212695
Validation loss: 2.2400970375403895

Epoch: 6| Step: 13
Training loss: 1.0341397458757395
Validation loss: 2.318279732846313

Epoch: 486| Step: 0
Training loss: 0.8750365794573898
Validation loss: 2.351456910930028

Epoch: 6| Step: 1
Training loss: 1.1746932664198426
Validation loss: 2.258964948718586

Epoch: 6| Step: 2
Training loss: 1.11098433340857
Validation loss: 2.282701327042776

Epoch: 6| Step: 3
Training loss: 0.943915982839528
Validation loss: 2.3032015741120864

Epoch: 6| Step: 4
Training loss: 1.0961703088170227
Validation loss: 2.3013034888538577

Epoch: 6| Step: 5
Training loss: 1.0904586315327833
Validation loss: 2.3191344938074328

Epoch: 6| Step: 6
Training loss: 1.0118200774246329
Validation loss: 2.2631844065041355

Epoch: 6| Step: 7
Training loss: 1.0339887260803746
Validation loss: 2.3447501123583216

Epoch: 6| Step: 8
Training loss: 0.8085456870717173
Validation loss: 2.3306626725222923

Epoch: 6| Step: 9
Training loss: 0.6480044791970446
Validation loss: 2.352435596022077

Epoch: 6| Step: 10
Training loss: 1.0001685477312559
Validation loss: 2.326916920976525

Epoch: 6| Step: 11
Training loss: 1.9118455153427363
Validation loss: 2.2855729232168747

Epoch: 6| Step: 12
Training loss: 0.5411408482586003
Validation loss: 2.3570187489202623

Epoch: 6| Step: 13
Training loss: 1.199714483626884
Validation loss: 2.3350246620074766

Epoch: 487| Step: 0
Training loss: 1.2643677860342717
Validation loss: 2.2787523496609605

Epoch: 6| Step: 1
Training loss: 1.0113237117878795
Validation loss: 2.404172457796816

Epoch: 6| Step: 2
Training loss: 0.6278855469942006
Validation loss: 2.375828339466478

Epoch: 6| Step: 3
Training loss: 0.875407737009755
Validation loss: 2.3060419311981604

Epoch: 6| Step: 4
Training loss: 1.2759776144754724
Validation loss: 2.273739243489344

Epoch: 6| Step: 5
Training loss: 0.8351504819008854
Validation loss: 2.3666610367895906

Epoch: 6| Step: 6
Training loss: 1.1206130216589147
Validation loss: 2.339624561761106

Epoch: 6| Step: 7
Training loss: 0.8592699853716642
Validation loss: 2.3191226126163222

Epoch: 6| Step: 8
Training loss: 0.8032400946767723
Validation loss: 2.275099596937612

Epoch: 6| Step: 9
Training loss: 1.0374436926211934
Validation loss: 2.3164521495897246

Epoch: 6| Step: 10
Training loss: 0.8882335210506811
Validation loss: 2.3563667941355804

Epoch: 6| Step: 11
Training loss: 1.847449518941349
Validation loss: 2.3103195793034836

Epoch: 6| Step: 12
Training loss: 1.520811037222409
Validation loss: 2.3631509458680657

Epoch: 6| Step: 13
Training loss: 1.0618821760073223
Validation loss: 2.3189403943012197

Epoch: 488| Step: 0
Training loss: 0.9145445897289416
Validation loss: 2.288445768984678

Epoch: 6| Step: 1
Training loss: 0.7242440590659237
Validation loss: 2.30664433379704

Epoch: 6| Step: 2
Training loss: 0.9912692649479722
Validation loss: 2.294357084944371

Epoch: 6| Step: 3
Training loss: 1.4690201693475244
Validation loss: 2.412814174280984

Epoch: 6| Step: 4
Training loss: 1.0402139579324956
Validation loss: 2.3460492839268663

Epoch: 6| Step: 5
Training loss: 0.953024749486523
Validation loss: 2.327087684392481

Epoch: 6| Step: 6
Training loss: 1.1545414028219507
Validation loss: 2.320582221717465

Epoch: 6| Step: 7
Training loss: 0.9232359070682301
Validation loss: 2.357777916158762

Epoch: 6| Step: 8
Training loss: 0.9156783078660315
Validation loss: 2.339146073325966

Epoch: 6| Step: 9
Training loss: 0.8024289183464902
Validation loss: 2.312478140495148

Epoch: 6| Step: 10
Training loss: 0.9361303496970068
Validation loss: 2.2551399392426927

Epoch: 6| Step: 11
Training loss: 1.6992621054544372
Validation loss: 2.3760333638534092

Epoch: 6| Step: 12
Training loss: 1.1205182342815951
Validation loss: 2.347173391105538

Epoch: 6| Step: 13
Training loss: 1.4897279291286472
Validation loss: 2.3344598817884075

Epoch: 489| Step: 0
Training loss: 1.861428545297414
Validation loss: 2.3234921813016776

Epoch: 6| Step: 1
Training loss: 1.2649838742822825
Validation loss: 2.29102460549641

Epoch: 6| Step: 2
Training loss: 1.1044902447346971
Validation loss: 2.351220768343957

Epoch: 6| Step: 3
Training loss: 0.8605101630803775
Validation loss: 2.2925862474406165

Epoch: 6| Step: 4
Training loss: 1.339921020415014
Validation loss: 2.3337060400684586

Epoch: 6| Step: 5
Training loss: 1.0465197743362435
Validation loss: 2.3107110653256577

Epoch: 6| Step: 6
Training loss: 0.6239414310448034
Validation loss: 2.288861718479314

Epoch: 6| Step: 7
Training loss: 0.904922960701118
Validation loss: 2.3728381249898867

Epoch: 6| Step: 8
Training loss: 0.9453776943960787
Validation loss: 2.337421155276197

Epoch: 6| Step: 9
Training loss: 0.8912730619809388
Validation loss: 2.3356302495328074

Epoch: 6| Step: 10
Training loss: 1.0115038080073062
Validation loss: 2.3861999479550864

Epoch: 6| Step: 11
Training loss: 0.7649615001340374
Validation loss: 2.3242944330233324

Epoch: 6| Step: 12
Training loss: 0.7012591081935529
Validation loss: 2.2812193170187425

Epoch: 6| Step: 13
Training loss: 0.8154488749730756
Validation loss: 2.248346127656615

Epoch: 490| Step: 0
Training loss: 1.245027857549223
Validation loss: 2.328971430882363

Epoch: 6| Step: 1
Training loss: 0.7903651824563451
Validation loss: 2.352052072851926

Epoch: 6| Step: 2
Training loss: 0.8346733088627691
Validation loss: 2.367575036863124

Epoch: 6| Step: 3
Training loss: 0.8480705971301415
Validation loss: 2.361844942093498

Epoch: 6| Step: 4
Training loss: 0.8995490454364169
Validation loss: 2.376017609932786

Epoch: 6| Step: 5
Training loss: 1.0944559271501064
Validation loss: 2.3215238413688404

Epoch: 6| Step: 6
Training loss: 0.8905521162226718
Validation loss: 2.3130940747085296

Epoch: 6| Step: 7
Training loss: 1.8366075956719052
Validation loss: 2.294311698134428

Epoch: 6| Step: 8
Training loss: 1.3661144296127403
Validation loss: 2.326228801435445

Epoch: 6| Step: 9
Training loss: 1.0261935333069019
Validation loss: 2.336999897774269

Epoch: 6| Step: 10
Training loss: 1.0973106193076605
Validation loss: 2.314294297993344

Epoch: 6| Step: 11
Training loss: 1.1233082873403868
Validation loss: 2.3033747946544256

Epoch: 6| Step: 12
Training loss: 1.0752419332571088
Validation loss: 2.384692600243441

Epoch: 6| Step: 13
Training loss: 0.7864824927116038
Validation loss: 2.2707635967214816

Epoch: 491| Step: 0
Training loss: 0.6225626148767196
Validation loss: 2.248858074333287

Epoch: 6| Step: 1
Training loss: 1.384491240914887
Validation loss: 2.2976344197185607

Epoch: 6| Step: 2
Training loss: 1.2351910754511406
Validation loss: 2.337960629528759

Epoch: 6| Step: 3
Training loss: 1.9906092956019312
Validation loss: 2.308961982621316

Epoch: 6| Step: 4
Training loss: 0.8250328129687499
Validation loss: 2.29252758653695

Epoch: 6| Step: 5
Training loss: 0.9774358582489259
Validation loss: 2.3761629108305593

Epoch: 6| Step: 6
Training loss: 1.082096745130415
Validation loss: 2.299276683864779

Epoch: 6| Step: 7
Training loss: 0.9161028139309139
Validation loss: 2.37223699697674

Epoch: 6| Step: 8
Training loss: 0.8835181395326007
Validation loss: 2.4354596829152118

Epoch: 6| Step: 9
Training loss: 0.8854838775855771
Validation loss: 2.356544631620538

Epoch: 6| Step: 10
Training loss: 1.0679627960418627
Validation loss: 2.4108903917249633

Epoch: 6| Step: 11
Training loss: 0.9938257764319681
Validation loss: 2.374014993968458

Epoch: 6| Step: 12
Training loss: 1.334945756760338
Validation loss: 2.271794134990634

Epoch: 6| Step: 13
Training loss: 0.8895208977104088
Validation loss: 2.3335490859466095

Epoch: 492| Step: 0
Training loss: 0.8712050704645615
Validation loss: 2.3227485416740694

Epoch: 6| Step: 1
Training loss: 1.3187932409636847
Validation loss: 2.2959413531802837

Epoch: 6| Step: 2
Training loss: 0.951619444397584
Validation loss: 2.434030622176239

Epoch: 6| Step: 3
Training loss: 0.8242045035193153
Validation loss: 2.390973667233305

Epoch: 6| Step: 4
Training loss: 1.0097794375037528
Validation loss: 2.3393277018582346

Epoch: 6| Step: 5
Training loss: 0.898856223014106
Validation loss: 2.3643782711371557

Epoch: 6| Step: 6
Training loss: 1.377669041433502
Validation loss: 2.2717593308822797

Epoch: 6| Step: 7
Training loss: 0.9959887879364859
Validation loss: 2.3818486360033333

Epoch: 6| Step: 8
Training loss: 1.044200498474797
Validation loss: 2.3249324258173134

Epoch: 6| Step: 9
Training loss: 1.112457345294822
Validation loss: 2.2889361927833707

Epoch: 6| Step: 10
Training loss: 1.7004574524857226
Validation loss: 2.272504114165575

Epoch: 6| Step: 11
Training loss: 0.9697704478126798
Validation loss: 2.300247521298823

Epoch: 6| Step: 12
Training loss: 0.7685427440602324
Validation loss: 2.331594923407267

Epoch: 6| Step: 13
Training loss: 0.6590641174730664
Validation loss: 2.2750847396925957

Epoch: 493| Step: 0
Training loss: 1.313388523710744
Validation loss: 2.335459778125535

Epoch: 6| Step: 1
Training loss: 0.5609807584866097
Validation loss: 2.3319096162420565

Epoch: 6| Step: 2
Training loss: 1.4255951224293952
Validation loss: 2.2987918332155335

Epoch: 6| Step: 3
Training loss: 0.8055400961090401
Validation loss: 2.353151818309077

Epoch: 6| Step: 4
Training loss: 1.779084344726763
Validation loss: 2.3894468752079514

Epoch: 6| Step: 5
Training loss: 1.0376796268172956
Validation loss: 2.356173864502048

Epoch: 6| Step: 6
Training loss: 1.192741771157095
Validation loss: 2.3513297184939743

Epoch: 6| Step: 7
Training loss: 1.082495193999372
Validation loss: 2.219720113909204

Epoch: 6| Step: 8
Training loss: 1.05510127110322
Validation loss: 2.3323260647755926

Epoch: 6| Step: 9
Training loss: 1.0685916627187768
Validation loss: 2.351798494905046

Epoch: 6| Step: 10
Training loss: 0.7660679606252165
Validation loss: 2.345520794421574

Epoch: 6| Step: 11
Training loss: 1.0449568983251414
Validation loss: 2.302187943456294

Epoch: 6| Step: 12
Training loss: 0.6540856319297513
Validation loss: 2.2570391442998416

Epoch: 6| Step: 13
Training loss: 1.055361271150042
Validation loss: 2.2898425392517723

Epoch: 494| Step: 0
Training loss: 1.6845437045000067
Validation loss: 2.312948749328955

Epoch: 6| Step: 1
Training loss: 1.065112268592718
Validation loss: 2.360461691539634

Epoch: 6| Step: 2
Training loss: 1.2225614760841992
Validation loss: 2.319288029623349

Epoch: 6| Step: 3
Training loss: 1.0464868537671277
Validation loss: 2.3113321394582726

Epoch: 6| Step: 4
Training loss: 0.673582214596488
Validation loss: 2.2670092491506457

Epoch: 6| Step: 5
Training loss: 0.8507401931986639
Validation loss: 2.3133390623304644

Epoch: 6| Step: 6
Training loss: 0.9219213571046111
Validation loss: 2.3666096791667273

Epoch: 6| Step: 7
Training loss: 0.670626878264713
Validation loss: 2.234954656679782

Epoch: 6| Step: 8
Training loss: 1.0547583097070423
Validation loss: 2.353862373257843

Epoch: 6| Step: 9
Training loss: 0.9451073668305318
Validation loss: 2.3730354441483037

Epoch: 6| Step: 10
Training loss: 1.0362870859244244
Validation loss: 2.280870205691856

Epoch: 6| Step: 11
Training loss: 0.9232872313019879
Validation loss: 2.343124015096135

Epoch: 6| Step: 12
Training loss: 1.0557847708292933
Validation loss: 2.3004733671671818

Epoch: 6| Step: 13
Training loss: 1.5754576699282394
Validation loss: 2.2789820006773405

Epoch: 495| Step: 0
Training loss: 1.009083264592963
Validation loss: 2.3202112409944244

Epoch: 6| Step: 1
Training loss: 1.1755040244322001
Validation loss: 2.275767329087085

Epoch: 6| Step: 2
Training loss: 1.7433630565251432
Validation loss: 2.3756700853892996

Epoch: 6| Step: 3
Training loss: 1.233367605420504
Validation loss: 2.3426163729960785

Epoch: 6| Step: 4
Training loss: 1.067714015046176
Validation loss: 2.334164634701626

Epoch: 6| Step: 5
Training loss: 1.0522841586067482
Validation loss: 2.3260895477453296

Epoch: 6| Step: 6
Training loss: 0.850857994464458
Validation loss: 2.2765531619636463

Epoch: 6| Step: 7
Training loss: 0.9138380247787986
Validation loss: 2.2773986470949272

Epoch: 6| Step: 8
Training loss: 0.7534902739425542
Validation loss: 2.2639562382601066

Epoch: 6| Step: 9
Training loss: 0.8904024481869104
Validation loss: 2.290037087186161

Epoch: 6| Step: 10
Training loss: 0.9194256199244316
Validation loss: 2.2924307767723984

Epoch: 6| Step: 11
Training loss: 0.9813777767497296
Validation loss: 2.324365289318068

Epoch: 6| Step: 12
Training loss: 0.854213368294389
Validation loss: 2.294154586622815

Epoch: 6| Step: 13
Training loss: 1.4074416303981865
Validation loss: 2.300844244255899

Epoch: 496| Step: 0
Training loss: 0.9018842179322337
Validation loss: 2.3031655296149762

Epoch: 6| Step: 1
Training loss: 1.619231770231278
Validation loss: 2.3179550694013127

Epoch: 6| Step: 2
Training loss: 1.1134269752829413
Validation loss: 2.343706485248628

Epoch: 6| Step: 3
Training loss: 1.1388920199860328
Validation loss: 2.289515133217577

Epoch: 6| Step: 4
Training loss: 1.0975413958100453
Validation loss: 2.240573899991082

Epoch: 6| Step: 5
Training loss: 0.9237807666987257
Validation loss: 2.313261032704632

Epoch: 6| Step: 6
Training loss: 0.9142921354928346
Validation loss: 2.3064578885076883

Epoch: 6| Step: 7
Training loss: 1.1828402900202764
Validation loss: 2.341662113410214

Epoch: 6| Step: 8
Training loss: 0.8468808613817139
Validation loss: 2.3668753351360854

Epoch: 6| Step: 9
Training loss: 1.1124517194579726
Validation loss: 2.3449058357064905

Epoch: 6| Step: 10
Training loss: 1.2682248010370938
Validation loss: 2.2848864094274903

Epoch: 6| Step: 11
Training loss: 1.0003423700756002
Validation loss: 2.375519233209147

Epoch: 6| Step: 12
Training loss: 0.8354722270104886
Validation loss: 2.3257848333030746

Epoch: 6| Step: 13
Training loss: 0.7211504119400025
Validation loss: 2.2796260544966525

Epoch: 497| Step: 0
Training loss: 1.824292526550325
Validation loss: 2.3748017893852915

Epoch: 6| Step: 1
Training loss: 0.9526161962006493
Validation loss: 2.3750061516501306

Epoch: 6| Step: 2
Training loss: 0.7599475319218485
Validation loss: 2.308706925947709

Epoch: 6| Step: 3
Training loss: 1.2734843520456347
Validation loss: 2.3070234398674776

Epoch: 6| Step: 4
Training loss: 0.8961762540795237
Validation loss: 2.3926749435232866

Epoch: 6| Step: 5
Training loss: 0.9696824907965795
Validation loss: 2.3122160481418064

Epoch: 6| Step: 6
Training loss: 1.320155117428583
Validation loss: 2.350174106684162

Epoch: 6| Step: 7
Training loss: 1.0239888227754277
Validation loss: 2.398362110210751

Epoch: 6| Step: 8
Training loss: 1.148750729565809
Validation loss: 2.332366488880962

Epoch: 6| Step: 9
Training loss: 1.3852260668824221
Validation loss: 2.33308227861411

Epoch: 6| Step: 10
Training loss: 0.916062050885329
Validation loss: 2.303447164791648

Epoch: 6| Step: 11
Training loss: 1.121001023767635
Validation loss: 2.28797525088239

Epoch: 6| Step: 12
Training loss: 0.5789663018548417
Validation loss: 2.2942040887321955

Epoch: 6| Step: 13
Training loss: 0.857502231873035
Validation loss: 2.356136542920982

Epoch: 498| Step: 0
Training loss: 0.9747313153691405
Validation loss: 2.307203711491555

Epoch: 6| Step: 1
Training loss: 0.8392045183241044
Validation loss: 2.3291099189946682

Epoch: 6| Step: 2
Training loss: 0.8617195053304784
Validation loss: 2.296429541020152

Epoch: 6| Step: 3
Training loss: 1.0414960657925407
Validation loss: 2.2969266199111593

Epoch: 6| Step: 4
Training loss: 0.9426235069482621
Validation loss: 2.383231478711217

Epoch: 6| Step: 5
Training loss: 0.8311312110176547
Validation loss: 2.3796626264461955

Epoch: 6| Step: 6
Training loss: 0.8803109366904431
Validation loss: 2.3132269020890273

Epoch: 6| Step: 7
Training loss: 0.7028791209627034
Validation loss: 2.336951071261701

Epoch: 6| Step: 8
Training loss: 1.0991131762334223
Validation loss: 2.351991534107708

Epoch: 6| Step: 9
Training loss: 1.1883268990861886
Validation loss: 2.3298798140540113

Epoch: 6| Step: 10
Training loss: 1.9634472717207139
Validation loss: 2.3626279859094663

Epoch: 6| Step: 11
Training loss: 0.9266963250973722
Validation loss: 2.2850842368046123

Epoch: 6| Step: 12
Training loss: 1.1490817176969237
Validation loss: 2.3474372315387253

Epoch: 6| Step: 13
Training loss: 1.3154611789074528
Validation loss: 2.3183393090754527

Epoch: 499| Step: 0
Training loss: 0.9831477795657929
Validation loss: 2.399887526860764

Epoch: 6| Step: 1
Training loss: 0.8662103182028156
Validation loss: 2.2848214649490495

Epoch: 6| Step: 2
Training loss: 1.201186662288298
Validation loss: 2.328762250503473

Epoch: 6| Step: 3
Training loss: 1.1350842027057093
Validation loss: 2.3398708769440786

Epoch: 6| Step: 4
Training loss: 1.170676572267541
Validation loss: 2.2944831596716164

Epoch: 6| Step: 5
Training loss: 1.7490232330271027
Validation loss: 2.331036463021928

Epoch: 6| Step: 6
Training loss: 0.8801679921734054
Validation loss: 2.3287851801983783

Epoch: 6| Step: 7
Training loss: 1.4577031363365116
Validation loss: 2.277908557691859

Epoch: 6| Step: 8
Training loss: 0.7407160980598149
Validation loss: 2.260457764689479

Epoch: 6| Step: 9
Training loss: 0.7762970130922898
Validation loss: 2.381100872825203

Epoch: 6| Step: 10
Training loss: 1.1366760665378102
Validation loss: 2.276792368700035

Epoch: 6| Step: 11
Training loss: 1.067624692044327
Validation loss: 2.3394553714922544

Epoch: 6| Step: 12
Training loss: 0.7404772679550773
Validation loss: 2.3250343822574973

Epoch: 6| Step: 13
Training loss: 0.905655600199962
Validation loss: 2.360104865274439

Epoch: 500| Step: 0
Training loss: 1.053841710924639
Validation loss: 2.350781193029753

Epoch: 6| Step: 1
Training loss: 0.7222797134535572
Validation loss: 2.3012876010019805

Epoch: 6| Step: 2
Training loss: 0.9297321212703029
Validation loss: 2.306752979899062

Epoch: 6| Step: 3
Training loss: 1.1094308758485734
Validation loss: 2.3345761204985545

Epoch: 6| Step: 4
Training loss: 1.1309625186561407
Validation loss: 2.4460773180783333

Epoch: 6| Step: 5
Training loss: 0.7779614471993791
Validation loss: 2.34874596706821

Epoch: 6| Step: 6
Training loss: 1.82553895804368
Validation loss: 2.3345030362909474

Epoch: 6| Step: 7
Training loss: 1.2651379436927204
Validation loss: 2.243479913004097

Epoch: 6| Step: 8
Training loss: 1.2610881162405811
Validation loss: 2.252759834888987

Epoch: 6| Step: 9
Training loss: 0.9369859239646646
Validation loss: 2.370692063107063

Epoch: 6| Step: 10
Training loss: 1.1246503180536849
Validation loss: 2.331256188754991

Epoch: 6| Step: 11
Training loss: 1.0603099017303947
Validation loss: 2.3954634656924383

Epoch: 6| Step: 12
Training loss: 0.9216485796102752
Validation loss: 2.28133047863483

Epoch: 6| Step: 13
Training loss: 0.8967540725900541
Validation loss: 2.3839553007643834

Epoch: 501| Step: 0
Training loss: 1.7251979216766753
Validation loss: 2.336593636198643

Epoch: 6| Step: 1
Training loss: 1.2944359881862049
Validation loss: 2.303347217855195

Epoch: 6| Step: 2
Training loss: 0.741102570061634
Validation loss: 2.3043366473984372

Epoch: 6| Step: 3
Training loss: 1.1940116036456694
Validation loss: 2.2673510083291823

Epoch: 6| Step: 4
Training loss: 1.015685446480965
Validation loss: 2.3548436495970324

Epoch: 6| Step: 5
Training loss: 0.8000173134718435
Validation loss: 2.311438091900956

Epoch: 6| Step: 6
Training loss: 0.965645646056652
Validation loss: 2.341794208230644

Epoch: 6| Step: 7
Training loss: 1.0654883154412331
Validation loss: 2.312014778579496

Epoch: 6| Step: 8
Training loss: 0.7265315715810906
Validation loss: 2.316395872151948

Epoch: 6| Step: 9
Training loss: 0.6958913643750799
Validation loss: 2.3077444196535493

Epoch: 6| Step: 10
Training loss: 1.061171037142404
Validation loss: 2.373697522819431

Epoch: 6| Step: 11
Training loss: 1.0089438542150162
Validation loss: 2.2716923000080684

Epoch: 6| Step: 12
Training loss: 0.8143265440571046
Validation loss: 2.2616354243175554

Epoch: 6| Step: 13
Training loss: 0.7682327313529034
Validation loss: 2.283152753331381

Epoch: 502| Step: 0
Training loss: 0.8932557653502106
Validation loss: 2.3013710867501103

Epoch: 6| Step: 1
Training loss: 0.8706355236811326
Validation loss: 2.276185455214458

Epoch: 6| Step: 2
Training loss: 0.9620620226465137
Validation loss: 2.249882808946723

Epoch: 6| Step: 3
Training loss: 0.7310377546546203
Validation loss: 2.3158333197868313

Epoch: 6| Step: 4
Training loss: 1.1887687631082964
Validation loss: 2.3487037379018427

Epoch: 6| Step: 5
Training loss: 0.9829862577461527
Validation loss: 2.222879140501977

Epoch: 6| Step: 6
Training loss: 0.9731113946903177
Validation loss: 2.3747747926524645

Epoch: 6| Step: 7
Training loss: 1.0637480194037499
Validation loss: 2.310675423660278

Epoch: 6| Step: 8
Training loss: 2.0146795613431427
Validation loss: 2.370011566211423

Epoch: 6| Step: 9
Training loss: 1.0427294967490384
Validation loss: 2.2780272633530325

Epoch: 6| Step: 10
Training loss: 0.8628032275692626
Validation loss: 2.4527520682090214

Epoch: 6| Step: 11
Training loss: 1.3038257791179313
Validation loss: 2.3472246715848963

Epoch: 6| Step: 12
Training loss: 1.0692361584798318
Validation loss: 2.277254438502019

Epoch: 6| Step: 13
Training loss: 0.9393330455657305
Validation loss: 2.3765625749061736

Epoch: 503| Step: 0
Training loss: 0.7560567672018954
Validation loss: 2.275043799226509

Epoch: 6| Step: 1
Training loss: 1.3279799438248951
Validation loss: 2.285323859708772

Epoch: 6| Step: 2
Training loss: 0.7968865188065305
Validation loss: 2.2271284373272455

Epoch: 6| Step: 3
Training loss: 0.8171376871422771
Validation loss: 2.3147752095962386

Epoch: 6| Step: 4
Training loss: 0.9712470696992991
Validation loss: 2.366385500670776

Epoch: 6| Step: 5
Training loss: 1.8933990556207858
Validation loss: 2.314877169308178

Epoch: 6| Step: 6
Training loss: 0.8908339138284855
Validation loss: 2.288876724866271

Epoch: 6| Step: 7
Training loss: 0.8751768887059138
Validation loss: 2.32679829218131

Epoch: 6| Step: 8
Training loss: 0.9775144895957757
Validation loss: 2.3761810200872513

Epoch: 6| Step: 9
Training loss: 1.1338809006564465
Validation loss: 2.334806843507227

Epoch: 6| Step: 10
Training loss: 0.8987885162631711
Validation loss: 2.3393575350209654

Epoch: 6| Step: 11
Training loss: 1.1011775000064186
Validation loss: 2.363004172223718

Epoch: 6| Step: 12
Training loss: 0.9525668276474561
Validation loss: 2.356569128402398

Epoch: 6| Step: 13
Training loss: 0.9742282894496491
Validation loss: 2.3619759043794146

Epoch: 504| Step: 0
Training loss: 1.1911358635933729
Validation loss: 2.2278750250066843

Epoch: 6| Step: 1
Training loss: 1.1265099247318726
Validation loss: 2.3439599263782354

Epoch: 6| Step: 2
Training loss: 0.9470354567438901
Validation loss: 2.363917973576683

Epoch: 6| Step: 3
Training loss: 0.5110272693225896
Validation loss: 2.354597724292804

Epoch: 6| Step: 4
Training loss: 0.572837075571499
Validation loss: 2.3632862058130093

Epoch: 6| Step: 5
Training loss: 0.9621042750940123
Validation loss: 2.266549171639338

Epoch: 6| Step: 6
Training loss: 2.039488532331266
Validation loss: 2.367810598656256

Epoch: 6| Step: 7
Training loss: 0.7193323347098295
Validation loss: 2.3555177352127936

Epoch: 6| Step: 8
Training loss: 0.8348151899589878
Validation loss: 2.245412178084006

Epoch: 6| Step: 9
Training loss: 0.8134529687361041
Validation loss: 2.3517329051681966

Epoch: 6| Step: 10
Training loss: 1.101980900946852
Validation loss: 2.35872734539904

Epoch: 6| Step: 11
Training loss: 0.894452054045342
Validation loss: 2.3506435437994098

Epoch: 6| Step: 12
Training loss: 0.7579288983175039
Validation loss: 2.278895854306467

Epoch: 6| Step: 13
Training loss: 0.510164097817596
Validation loss: 2.322481194498204

Epoch: 505| Step: 0
Training loss: 1.0342025105927077
Validation loss: 2.2802183521529056

Epoch: 6| Step: 1
Training loss: 1.165884039273562
Validation loss: 2.3042676072836934

Epoch: 6| Step: 2
Training loss: 0.5896668579418605
Validation loss: 2.373379489645273

Epoch: 6| Step: 3
Training loss: 1.080002959741846
Validation loss: 2.3757046883008917

Epoch: 6| Step: 4
Training loss: 0.9223491936209108
Validation loss: 2.2940270515281407

Epoch: 6| Step: 5
Training loss: 1.0627883071187276
Validation loss: 2.292606085888039

Epoch: 6| Step: 6
Training loss: 0.8220308743454076
Validation loss: 2.4435221562249656

Epoch: 6| Step: 7
Training loss: 1.021708534984217
Validation loss: 2.2837789455340327

Epoch: 6| Step: 8
Training loss: 1.916655733934265
Validation loss: 2.3043442570821235

Epoch: 6| Step: 9
Training loss: 1.2986447771347098
Validation loss: 2.2744706979066884

Epoch: 6| Step: 10
Training loss: 0.9787266364786387
Validation loss: 2.3529986508536864

Epoch: 6| Step: 11
Training loss: 0.8413829095378282
Validation loss: 2.2965261833336315

Epoch: 6| Step: 12
Training loss: 0.7602100396409404
Validation loss: 2.276116107472269

Epoch: 6| Step: 13
Training loss: 0.6046477627573316
Validation loss: 2.2944875562679448

Epoch: 506| Step: 0
Training loss: 0.6858949131008532
Validation loss: 2.2886424782613695

Epoch: 6| Step: 1
Training loss: 0.8267352841212151
Validation loss: 2.267688078660813

Epoch: 6| Step: 2
Training loss: 1.3151998000419771
Validation loss: 2.273966247485596

Epoch: 6| Step: 3
Training loss: 0.9710546275426983
Validation loss: 2.328918400022579

Epoch: 6| Step: 4
Training loss: 0.8518928447038245
Validation loss: 2.3564142487137296

Epoch: 6| Step: 5
Training loss: 0.8687639084395586
Validation loss: 2.34593911376614

Epoch: 6| Step: 6
Training loss: 1.1708886636893996
Validation loss: 2.2829130580711654

Epoch: 6| Step: 7
Training loss: 1.6780834256781654
Validation loss: 2.3133088143880274

Epoch: 6| Step: 8
Training loss: 1.20136657625523
Validation loss: 2.343942508790013

Epoch: 6| Step: 9
Training loss: 0.934749191528689
Validation loss: 2.277905581474018

Epoch: 6| Step: 10
Training loss: 1.1383909529982599
Validation loss: 2.358528289518579

Epoch: 6| Step: 11
Training loss: 0.7021760258673002
Validation loss: 2.3080343282107334

Epoch: 6| Step: 12
Training loss: 0.7180567175902707
Validation loss: 2.365981168346269

Epoch: 6| Step: 13
Training loss: 0.8870493066860591
Validation loss: 2.2617875451312894

Epoch: 507| Step: 0
Training loss: 0.9854653390124061
Validation loss: 2.2979660395101993

Epoch: 6| Step: 1
Training loss: 0.8754881791275909
Validation loss: 2.2394337261927775

Epoch: 6| Step: 2
Training loss: 0.7819274254168859
Validation loss: 2.279004625237925

Epoch: 6| Step: 3
Training loss: 1.1289325433856794
Validation loss: 2.370562459402329

Epoch: 6| Step: 4
Training loss: 0.8512622408890028
Validation loss: 2.275154338597079

Epoch: 6| Step: 5
Training loss: 1.1127505459635212
Validation loss: 2.3466592448573174

Epoch: 6| Step: 6
Training loss: 0.8787175632963826
Validation loss: 2.2990016371504343

Epoch: 6| Step: 7
Training loss: 0.9408165125248442
Validation loss: 2.2821500775044106

Epoch: 6| Step: 8
Training loss: 0.720773957035953
Validation loss: 2.3594302908667926

Epoch: 6| Step: 9
Training loss: 1.2212842366818537
Validation loss: 2.318942379265905

Epoch: 6| Step: 10
Training loss: 0.7035974822431433
Validation loss: 2.276790490551459

Epoch: 6| Step: 11
Training loss: 1.181293430236409
Validation loss: 2.3224219883431076

Epoch: 6| Step: 12
Training loss: 1.8785820124098531
Validation loss: 2.3312184264664864

Epoch: 6| Step: 13
Training loss: 0.7614333180407663
Validation loss: 2.330130876416888

Epoch: 508| Step: 0
Training loss: 1.7746155309014062
Validation loss: 2.3042570635092585

Epoch: 6| Step: 1
Training loss: 1.3706100784512347
Validation loss: 2.360442876828213

Epoch: 6| Step: 2
Training loss: 0.9991814123936889
Validation loss: 2.333204880780971

Epoch: 6| Step: 3
Training loss: 0.803207146862993
Validation loss: 2.2311471585114764

Epoch: 6| Step: 4
Training loss: 1.0336133867101085
Validation loss: 2.3140344570178693

Epoch: 6| Step: 5
Training loss: 0.7714445852328098
Validation loss: 2.3283912730506358

Epoch: 6| Step: 6
Training loss: 0.9225018842931179
Validation loss: 2.2766314188060752

Epoch: 6| Step: 7
Training loss: 0.7621727006452184
Validation loss: 2.2543113072823395

Epoch: 6| Step: 8
Training loss: 0.8550582667345591
Validation loss: 2.3226929167867114

Epoch: 6| Step: 9
Training loss: 1.097826689930593
Validation loss: 2.290166212257198

Epoch: 6| Step: 10
Training loss: 0.8127908552867175
Validation loss: 2.316232164494886

Epoch: 6| Step: 11
Training loss: 0.9683799036703734
Validation loss: 2.1967544675002237

Epoch: 6| Step: 12
Training loss: 1.0861903932149741
Validation loss: 2.361203984294497

Epoch: 6| Step: 13
Training loss: 1.2248683819810517
Validation loss: 2.3473885090915076

Epoch: 509| Step: 0
Training loss: 0.8951099639341412
Validation loss: 2.2782639545205554

Epoch: 6| Step: 1
Training loss: 0.8925705790461594
Validation loss: 2.350497477380205

Epoch: 6| Step: 2
Training loss: 1.241726627864883
Validation loss: 2.3582961885223006

Epoch: 6| Step: 3
Training loss: 0.6494448088057625
Validation loss: 2.290081759983874

Epoch: 6| Step: 4
Training loss: 0.8051975448563389
Validation loss: 2.322868876050905

Epoch: 6| Step: 5
Training loss: 0.7456842866719161
Validation loss: 2.2807296820334297

Epoch: 6| Step: 6
Training loss: 1.0720485891461424
Validation loss: 2.317267517961228

Epoch: 6| Step: 7
Training loss: 1.1323870155782572
Validation loss: 2.3005082230127116

Epoch: 6| Step: 8
Training loss: 1.3596354706369722
Validation loss: 2.3416297165515

Epoch: 6| Step: 9
Training loss: 0.8844464465285835
Validation loss: 2.372728071763652

Epoch: 6| Step: 10
Training loss: 1.7945356980942506
Validation loss: 2.318034879755178

Epoch: 6| Step: 11
Training loss: 1.0616270855203003
Validation loss: 2.3852314661975402

Epoch: 6| Step: 12
Training loss: 0.6731746434967472
Validation loss: 2.34278483052638

Epoch: 6| Step: 13
Training loss: 1.2610472790887128
Validation loss: 2.301266051632567

Epoch: 510| Step: 0
Training loss: 0.8047756035729281
Validation loss: 2.2767221679027667

Epoch: 6| Step: 1
Training loss: 0.9199676178333336
Validation loss: 2.447484819855217

Epoch: 6| Step: 2
Training loss: 0.7005564079091252
Validation loss: 2.389448193266823

Epoch: 6| Step: 3
Training loss: 0.8641011413984306
Validation loss: 2.3284675069259446

Epoch: 6| Step: 4
Training loss: 1.117353627050949
Validation loss: 2.320807868032941

Epoch: 6| Step: 5
Training loss: 1.0848532553729833
Validation loss: 2.312670370232086

Epoch: 6| Step: 6
Training loss: 1.0533165958338262
Validation loss: 2.342922921768874

Epoch: 6| Step: 7
Training loss: 1.0916784560074133
Validation loss: 2.3429163319031567

Epoch: 6| Step: 8
Training loss: 1.6569024726147021
Validation loss: 2.3706517312748705

Epoch: 6| Step: 9
Training loss: 0.9651805274482791
Validation loss: 2.2602842165576056

Epoch: 6| Step: 10
Training loss: 0.9721009534559782
Validation loss: 2.3496956439001684

Epoch: 6| Step: 11
Training loss: 1.1751312791250603
Validation loss: 2.249507870741591

Epoch: 6| Step: 12
Training loss: 1.227397950042261
Validation loss: 2.2869510820914227

Epoch: 6| Step: 13
Training loss: 0.7589642532359294
Validation loss: 2.264474257300099

Epoch: 511| Step: 0
Training loss: 1.0085864976168621
Validation loss: 2.3348897154189943

Epoch: 6| Step: 1
Training loss: 0.72252179518828
Validation loss: 2.2451562335372057

Epoch: 6| Step: 2
Training loss: 0.8248323443593065
Validation loss: 2.2921581431146723

Epoch: 6| Step: 3
Training loss: 0.7196407603409438
Validation loss: 2.3545655985093448

Epoch: 6| Step: 4
Training loss: 1.817907357091132
Validation loss: 2.2760015356338115

Epoch: 6| Step: 5
Training loss: 1.1534784452477311
Validation loss: 2.3301715278380297

Epoch: 6| Step: 6
Training loss: 0.8934123942159135
Validation loss: 2.340346228913001

Epoch: 6| Step: 7
Training loss: 1.03790413672195
Validation loss: 2.3699136855174356

Epoch: 6| Step: 8
Training loss: 0.9080252524490071
Validation loss: 2.3010113524091986

Epoch: 6| Step: 9
Training loss: 0.8427984028430392
Validation loss: 2.3879625106633293

Epoch: 6| Step: 10
Training loss: 0.9846534940561241
Validation loss: 2.3520908494633406

Epoch: 6| Step: 11
Training loss: 1.0330113483555246
Validation loss: 2.3798977566286292

Epoch: 6| Step: 12
Training loss: 1.1189323084950034
Validation loss: 2.4090950735610197

Epoch: 6| Step: 13
Training loss: 0.9416608347473049
Validation loss: 2.3497607919068444

Epoch: 512| Step: 0
Training loss: 1.0095489682719652
Validation loss: 2.269918945390119

Epoch: 6| Step: 1
Training loss: 1.0486481865622512
Validation loss: 2.2864440570689926

Epoch: 6| Step: 2
Training loss: 0.9723730326047964
Validation loss: 2.305825664225363

Epoch: 6| Step: 3
Training loss: 1.6215571097480843
Validation loss: 2.2609826332993443

Epoch: 6| Step: 4
Training loss: 1.109134540555951
Validation loss: 2.324166123609679

Epoch: 6| Step: 5
Training loss: 0.5810694588458577
Validation loss: 2.3396351570794316

Epoch: 6| Step: 6
Training loss: 0.627021548141226
Validation loss: 2.3678523963888005

Epoch: 6| Step: 7
Training loss: 1.0138658988355083
Validation loss: 2.3196653765572153

Epoch: 6| Step: 8
Training loss: 0.7390184304645275
Validation loss: 2.2502267887301577

Epoch: 6| Step: 9
Training loss: 1.0651920658518
Validation loss: 2.349664653448701

Epoch: 6| Step: 10
Training loss: 1.0447853070436677
Validation loss: 2.3782336350388293

Epoch: 6| Step: 11
Training loss: 0.7727005269909416
Validation loss: 2.416277632059328

Epoch: 6| Step: 12
Training loss: 1.125388396293025
Validation loss: 2.3751702692883674

Epoch: 6| Step: 13
Training loss: 0.94411777631253
Validation loss: 2.30939146780849

Epoch: 513| Step: 0
Training loss: 0.798285787542995
Validation loss: 2.3118058515046553

Epoch: 6| Step: 1
Training loss: 1.214811220377508
Validation loss: 2.289522958442973

Epoch: 6| Step: 2
Training loss: 1.1349242422893626
Validation loss: 2.308340147505999

Epoch: 6| Step: 3
Training loss: 0.9814878539928821
Validation loss: 2.327366553072265

Epoch: 6| Step: 4
Training loss: 1.128205183988961
Validation loss: 2.252213015297426

Epoch: 6| Step: 5
Training loss: 1.257038755139599
Validation loss: 2.321255581150666

Epoch: 6| Step: 6
Training loss: 1.0821437846030972
Validation loss: 2.273915612858538

Epoch: 6| Step: 7
Training loss: 0.8403898371087878
Validation loss: 2.335251899098349

Epoch: 6| Step: 8
Training loss: 0.8542983178508977
Validation loss: 2.2914804468722916

Epoch: 6| Step: 9
Training loss: 0.9852571924271816
Validation loss: 2.415381968109814

Epoch: 6| Step: 10
Training loss: 1.5692773700033136
Validation loss: 2.370832674128871

Epoch: 6| Step: 11
Training loss: 0.8262562088725872
Validation loss: 2.326846550036665

Epoch: 6| Step: 12
Training loss: 0.538475131260212
Validation loss: 2.3470537042613144

Epoch: 6| Step: 13
Training loss: 1.0201511763757505
Validation loss: 2.3980356873707813

Epoch: 514| Step: 0
Training loss: 0.9097398779678909
Validation loss: 2.3701278720287022

Epoch: 6| Step: 1
Training loss: 1.0852709034714854
Validation loss: 2.247774919882064

Epoch: 6| Step: 2
Training loss: 1.6957152279428713
Validation loss: 2.363159727631423

Epoch: 6| Step: 3
Training loss: 0.8998731338305702
Validation loss: 2.1897139337247107

Epoch: 6| Step: 4
Training loss: 0.6986643975220418
Validation loss: 2.3078999662034896

Epoch: 6| Step: 5
Training loss: 0.6679284379183207
Validation loss: 2.333772325384629

Epoch: 6| Step: 6
Training loss: 0.8405965580436167
Validation loss: 2.3897695912428984

Epoch: 6| Step: 7
Training loss: 1.003493881138506
Validation loss: 2.3444469725442865

Epoch: 6| Step: 8
Training loss: 0.7361188839156156
Validation loss: 2.3544254249704752

Epoch: 6| Step: 9
Training loss: 1.1965571885428172
Validation loss: 2.2827620159875304

Epoch: 6| Step: 10
Training loss: 1.0408829538282638
Validation loss: 2.2967373051408306

Epoch: 6| Step: 11
Training loss: 0.9257493798287066
Validation loss: 2.2967555975138136

Epoch: 6| Step: 12
Training loss: 1.0478213004571202
Validation loss: 2.3563836817136767

Epoch: 6| Step: 13
Training loss: 1.241329880724639
Validation loss: 2.276903021345077

Epoch: 515| Step: 0
Training loss: 1.1250660664974612
Validation loss: 2.2812806140184474

Epoch: 6| Step: 1
Training loss: 0.9795422070587596
Validation loss: 2.344413280633095

Epoch: 6| Step: 2
Training loss: 0.6708632547406955
Validation loss: 2.4353110910797025

Epoch: 6| Step: 3
Training loss: 1.0329596479571994
Validation loss: 2.3841246388095847

Epoch: 6| Step: 4
Training loss: 0.8263595403985979
Validation loss: 2.3544513865261156

Epoch: 6| Step: 5
Training loss: 1.0746127429106507
Validation loss: 2.3276448112142036

Epoch: 6| Step: 6
Training loss: 0.7963903860900002
Validation loss: 2.302595864832497

Epoch: 6| Step: 7
Training loss: 1.0658208337090134
Validation loss: 2.389468688800965

Epoch: 6| Step: 8
Training loss: 0.9717914766194978
Validation loss: 2.288057746181506

Epoch: 6| Step: 9
Training loss: 0.8389298900755585
Validation loss: 2.352951406584674

Epoch: 6| Step: 10
Training loss: 1.7277814609874025
Validation loss: 2.273775500212659

Epoch: 6| Step: 11
Training loss: 0.6809231061320083
Validation loss: 2.248960807619698

Epoch: 6| Step: 12
Training loss: 1.1824939011462887
Validation loss: 2.3202166904382264

Epoch: 6| Step: 13
Training loss: 0.4227984000742784
Validation loss: 2.347822342785286

Epoch: 516| Step: 0
Training loss: 0.8025300074400937
Validation loss: 2.3233548385738976

Epoch: 6| Step: 1
Training loss: 1.2366473853895097
Validation loss: 2.270123918381953

Epoch: 6| Step: 2
Training loss: 0.9869521782371602
Validation loss: 2.3040156432680585

Epoch: 6| Step: 3
Training loss: 1.003462340773021
Validation loss: 2.211627618999029

Epoch: 6| Step: 4
Training loss: 1.005752646700425
Validation loss: 2.336443395868934

Epoch: 6| Step: 5
Training loss: 0.959959509412881
Validation loss: 2.2854281227024433

Epoch: 6| Step: 6
Training loss: 1.8833889533863017
Validation loss: 2.3934345420800907

Epoch: 6| Step: 7
Training loss: 0.5439272865582233
Validation loss: 2.334455288126545

Epoch: 6| Step: 8
Training loss: 0.8644574468188325
Validation loss: 2.304922059617738

Epoch: 6| Step: 9
Training loss: 1.1029465009523411
Validation loss: 2.34321583283645

Epoch: 6| Step: 10
Training loss: 0.919658096626349
Validation loss: 2.3054813709210267

Epoch: 6| Step: 11
Training loss: 0.9798729594759663
Validation loss: 2.3725041183221034

Epoch: 6| Step: 12
Training loss: 1.2252987711379808
Validation loss: 2.360725631790676

Epoch: 6| Step: 13
Training loss: 0.9399778046929776
Validation loss: 2.3153314060327537

Epoch: 517| Step: 0
Training loss: 0.9351094921790891
Validation loss: 2.2897177059541316

Epoch: 6| Step: 1
Training loss: 1.043067613123658
Validation loss: 2.298670553201697

Epoch: 6| Step: 2
Training loss: 0.9779796236368948
Validation loss: 2.332455558045285

Epoch: 6| Step: 3
Training loss: 1.074890481559876
Validation loss: 2.3317447021226325

Epoch: 6| Step: 4
Training loss: 0.5811004877071668
Validation loss: 2.29102916594809

Epoch: 6| Step: 5
Training loss: 1.0116516444511738
Validation loss: 2.282423451717685

Epoch: 6| Step: 6
Training loss: 0.6159245086801741
Validation loss: 2.316930397572382

Epoch: 6| Step: 7
Training loss: 0.717108178167345
Validation loss: 2.3243898583293334

Epoch: 6| Step: 8
Training loss: 0.7560515639945933
Validation loss: 2.326970136953067

Epoch: 6| Step: 9
Training loss: 1.2075658311925765
Validation loss: 2.3402535974958156

Epoch: 6| Step: 10
Training loss: 1.724964282453865
Validation loss: 2.267475820279208

Epoch: 6| Step: 11
Training loss: 0.8923146800237474
Validation loss: 2.3472963865774688

Epoch: 6| Step: 12
Training loss: 1.3200599835233975
Validation loss: 2.371742071377091

Epoch: 6| Step: 13
Training loss: 0.7199024829125935
Validation loss: 2.323875472902202

Epoch: 518| Step: 0
Training loss: 0.5548813977973732
Validation loss: 2.255446581838471

Epoch: 6| Step: 1
Training loss: 0.8070403948816903
Validation loss: 2.296445609840703

Epoch: 6| Step: 2
Training loss: 0.8558424738612839
Validation loss: 2.3459842743555783

Epoch: 6| Step: 3
Training loss: 0.9590394107230619
Validation loss: 2.2343439085237344

Epoch: 6| Step: 4
Training loss: 1.194262223920416
Validation loss: 2.371353751716534

Epoch: 6| Step: 5
Training loss: 1.042831583325726
Validation loss: 2.247874372491695

Epoch: 6| Step: 6
Training loss: 0.9363222035271307
Validation loss: 2.260667745468053

Epoch: 6| Step: 7
Training loss: 2.0075871085036336
Validation loss: 2.3635258086289386

Epoch: 6| Step: 8
Training loss: 0.7896597462084236
Validation loss: 2.343354339564388

Epoch: 6| Step: 9
Training loss: 0.7923969781863245
Validation loss: 2.330702254872752

Epoch: 6| Step: 10
Training loss: 0.8820605155745728
Validation loss: 2.3323469743379133

Epoch: 6| Step: 11
Training loss: 0.74202726541792
Validation loss: 2.2858919448512722

Epoch: 6| Step: 12
Training loss: 1.1827118360852682
Validation loss: 2.296911084615269

Epoch: 6| Step: 13
Training loss: 0.9051787523382839
Validation loss: 2.310029690086507

Epoch: 519| Step: 0
Training loss: 1.0087759454692349
Validation loss: 2.3580327150866873

Epoch: 6| Step: 1
Training loss: 0.4920396885613136
Validation loss: 2.320173133202161

Epoch: 6| Step: 2
Training loss: 1.150918991433067
Validation loss: 2.3526062381627595

Epoch: 6| Step: 3
Training loss: 0.9123430953274178
Validation loss: 2.2859707729997747

Epoch: 6| Step: 4
Training loss: 0.9135355286227073
Validation loss: 2.3519621200745537

Epoch: 6| Step: 5
Training loss: 0.8583458026116059
Validation loss: 2.3250751580686986

Epoch: 6| Step: 6
Training loss: 1.734381873314787
Validation loss: 2.281308633992252

Epoch: 6| Step: 7
Training loss: 0.9934600719036765
Validation loss: 2.350056074813513

Epoch: 6| Step: 8
Training loss: 0.5945117982346556
Validation loss: 2.296036402068823

Epoch: 6| Step: 9
Training loss: 1.075713515244311
Validation loss: 2.269730225398194

Epoch: 6| Step: 10
Training loss: 0.7863439809429483
Validation loss: 2.3320685473149205

Epoch: 6| Step: 11
Training loss: 1.200033600654663
Validation loss: 2.3590264087644024

Epoch: 6| Step: 12
Training loss: 1.0304960326775925
Validation loss: 2.2781381840489447

Epoch: 6| Step: 13
Training loss: 1.5915828256677984
Validation loss: 2.2582464061289285

Epoch: 520| Step: 0
Training loss: 1.8945554122170556
Validation loss: 2.3228254987816452

Epoch: 6| Step: 1
Training loss: 0.8475579411327998
Validation loss: 2.2849441002130626

Epoch: 6| Step: 2
Training loss: 1.0005605437887326
Validation loss: 2.3260645464642806

Epoch: 6| Step: 3
Training loss: 1.4992443406553384
Validation loss: 2.3790860057910046

Epoch: 6| Step: 4
Training loss: 0.6348253427438093
Validation loss: 2.277795470497747

Epoch: 6| Step: 5
Training loss: 0.6309596593176531
Validation loss: 2.3872642113315306

Epoch: 6| Step: 6
Training loss: 0.8656660600419454
Validation loss: 2.34271383754926

Epoch: 6| Step: 7
Training loss: 0.9517100728675443
Validation loss: 2.2632826790714202

Epoch: 6| Step: 8
Training loss: 1.1318722736361617
Validation loss: 2.2599831858198316

Epoch: 6| Step: 9
Training loss: 0.8661451174942763
Validation loss: 2.339026471132874

Epoch: 6| Step: 10
Training loss: 0.6272106176657556
Validation loss: 2.271687709201187

Epoch: 6| Step: 11
Training loss: 0.9946557529667186
Validation loss: 2.4057712534137834

Epoch: 6| Step: 12
Training loss: 0.8714642613448181
Validation loss: 2.324283480447304

Epoch: 6| Step: 13
Training loss: 0.8871472705455296
Validation loss: 2.295454475426312

Epoch: 521| Step: 0
Training loss: 0.7624105588642114
Validation loss: 2.292293178426416

Epoch: 6| Step: 1
Training loss: 0.626506586980937
Validation loss: 2.3275811897540906

Epoch: 6| Step: 2
Training loss: 0.6139168331159305
Validation loss: 2.2513899446560584

Epoch: 6| Step: 3
Training loss: 1.6399323954255438
Validation loss: 2.2904327876227617

Epoch: 6| Step: 4
Training loss: 1.154066860047158
Validation loss: 2.2938139195809963

Epoch: 6| Step: 5
Training loss: 0.9776305804632927
Validation loss: 2.2408174892241823

Epoch: 6| Step: 6
Training loss: 0.8110462167296876
Validation loss: 2.2894508250542587

Epoch: 6| Step: 7
Training loss: 0.7511660729877007
Validation loss: 2.320283749481226

Epoch: 6| Step: 8
Training loss: 1.082246834661975
Validation loss: 2.3353795368710037

Epoch: 6| Step: 9
Training loss: 0.8803973963611897
Validation loss: 2.332352608665125

Epoch: 6| Step: 10
Training loss: 1.2399431983181899
Validation loss: 2.3169592931567244

Epoch: 6| Step: 11
Training loss: 0.7220756053859552
Validation loss: 2.277636484698864

Epoch: 6| Step: 12
Training loss: 0.9169693721577634
Validation loss: 2.349145302901732

Epoch: 6| Step: 13
Training loss: 0.8194152284431955
Validation loss: 2.2219652574243782

Epoch: 522| Step: 0
Training loss: 0.6138072582658461
Validation loss: 2.358138705488879

Epoch: 6| Step: 1
Training loss: 0.9467714259339938
Validation loss: 2.31640609948446

Epoch: 6| Step: 2
Training loss: 0.8257203367462232
Validation loss: 2.2801201323720948

Epoch: 6| Step: 3
Training loss: 1.6917102707879108
Validation loss: 2.379003683119868

Epoch: 6| Step: 4
Training loss: 0.7545360642289655
Validation loss: 2.2849394625419177

Epoch: 6| Step: 5
Training loss: 0.9697215837886732
Validation loss: 2.3371144431966067

Epoch: 6| Step: 6
Training loss: 1.0263048147600609
Validation loss: 2.256719844381985

Epoch: 6| Step: 7
Training loss: 1.1871790201155898
Validation loss: 2.3766926862999282

Epoch: 6| Step: 8
Training loss: 0.9889287523713187
Validation loss: 2.343819564279195

Epoch: 6| Step: 9
Training loss: 1.2196045838227025
Validation loss: 2.2302202215898657

Epoch: 6| Step: 10
Training loss: 0.7612205245351519
Validation loss: 2.328198596038583

Epoch: 6| Step: 11
Training loss: 0.9011073373372426
Validation loss: 2.345765946768088

Epoch: 6| Step: 12
Training loss: 0.915198183015707
Validation loss: 2.28395579537538

Epoch: 6| Step: 13
Training loss: 0.743206649542545
Validation loss: 2.2520411108074163

Epoch: 523| Step: 0
Training loss: 0.7378661184446855
Validation loss: 2.3050264632410933

Epoch: 6| Step: 1
Training loss: 1.9383862222140138
Validation loss: 2.2822695513275

Epoch: 6| Step: 2
Training loss: 1.2438654093655837
Validation loss: 2.325689999305449

Epoch: 6| Step: 3
Training loss: 0.7950876049141173
Validation loss: 2.3011071126733356

Epoch: 6| Step: 4
Training loss: 0.6849667955968752
Validation loss: 2.3773818941486686

Epoch: 6| Step: 5
Training loss: 1.0433025040403328
Validation loss: 2.3661438587935812

Epoch: 6| Step: 6
Training loss: 1.0079148114931007
Validation loss: 2.355588287888544

Epoch: 6| Step: 7
Training loss: 0.5879037545090926
Validation loss: 2.3574090405686823

Epoch: 6| Step: 8
Training loss: 1.0254386381988245
Validation loss: 2.4216378160999352

Epoch: 6| Step: 9
Training loss: 0.8650964493534579
Validation loss: 2.2718504289084103

Epoch: 6| Step: 10
Training loss: 0.8714154936526087
Validation loss: 2.348698784610679

Epoch: 6| Step: 11
Training loss: 0.8025669935077029
Validation loss: 2.2705212250929856

Epoch: 6| Step: 12
Training loss: 0.9446312837975999
Validation loss: 2.3473834061339685

Epoch: 6| Step: 13
Training loss: 0.577281800948329
Validation loss: 2.3943564750955284

Epoch: 524| Step: 0
Training loss: 0.8785660148746227
Validation loss: 2.3048721000389167

Epoch: 6| Step: 1
Training loss: 1.0684451778344641
Validation loss: 2.2840039729377657

Epoch: 6| Step: 2
Training loss: 1.1148575181117575
Validation loss: 2.329725989755447

Epoch: 6| Step: 3
Training loss: 0.6595383410150546
Validation loss: 2.334955915255045

Epoch: 6| Step: 4
Training loss: 1.6014661062121525
Validation loss: 2.3411756097472574

Epoch: 6| Step: 5
Training loss: 0.9947903351833094
Validation loss: 2.233705605800958

Epoch: 6| Step: 6
Training loss: 0.9058654232242702
Validation loss: 2.3224829933378515

Epoch: 6| Step: 7
Training loss: 0.6792429862602732
Validation loss: 2.3236162366574082

Epoch: 6| Step: 8
Training loss: 0.49958084836261746
Validation loss: 2.32190523256117

Epoch: 6| Step: 9
Training loss: 0.947606385280034
Validation loss: 2.2164744670454497

Epoch: 6| Step: 10
Training loss: 1.014836225122007
Validation loss: 2.3438281969814567

Epoch: 6| Step: 11
Training loss: 1.0580750493146975
Validation loss: 2.3490032594382333

Epoch: 6| Step: 12
Training loss: 0.9852548935562255
Validation loss: 2.317327066005117

Epoch: 6| Step: 13
Training loss: 0.6086635348816377
Validation loss: 2.28415523200424

Epoch: 525| Step: 0
Training loss: 1.7459537868173671
Validation loss: 2.340047592648111

Epoch: 6| Step: 1
Training loss: 0.9774285405471175
Validation loss: 2.3129215687669586

Epoch: 6| Step: 2
Training loss: 0.639962854350489
Validation loss: 2.334746285289158

Epoch: 6| Step: 3
Training loss: 1.01718770626318
Validation loss: 2.408206352698327

Epoch: 6| Step: 4
Training loss: 0.879971820423461
Validation loss: 2.333160215063003

Epoch: 6| Step: 5
Training loss: 0.8825186856590712
Validation loss: 2.3079229754275414

Epoch: 6| Step: 6
Training loss: 0.8076261914269097
Validation loss: 2.3084301342703792

Epoch: 6| Step: 7
Training loss: 0.7893192138048035
Validation loss: 2.3266344167897937

Epoch: 6| Step: 8
Training loss: 0.9184351608698269
Validation loss: 2.3051585427120207

Epoch: 6| Step: 9
Training loss: 0.9634376813434896
Validation loss: 2.243619705161506

Epoch: 6| Step: 10
Training loss: 1.0220523225413691
Validation loss: 2.3087412843919974

Epoch: 6| Step: 11
Training loss: 0.8320730494355741
Validation loss: 2.3448121101463193

Epoch: 6| Step: 12
Training loss: 1.6566929494792841
Validation loss: 2.2986224360031553

Epoch: 6| Step: 13
Training loss: 0.8890074044102687
Validation loss: 2.284262648148901

Epoch: 526| Step: 0
Training loss: 1.2189009157300497
Validation loss: 2.2929918302312986

Epoch: 6| Step: 1
Training loss: 0.7155734231011688
Validation loss: 2.3128459375671357

Epoch: 6| Step: 2
Training loss: 0.6574833497234543
Validation loss: 2.3796130506952

Epoch: 6| Step: 3
Training loss: 0.9314976548509875
Validation loss: 2.337572883512484

Epoch: 6| Step: 4
Training loss: 0.737784687957645
Validation loss: 2.2950736884716036

Epoch: 6| Step: 5
Training loss: 1.0667487631934331
Validation loss: 2.2635904514242493

Epoch: 6| Step: 6
Training loss: 0.7174636276011084
Validation loss: 2.2910103925619625

Epoch: 6| Step: 7
Training loss: 0.9833585850388259
Validation loss: 2.2463617579574144

Epoch: 6| Step: 8
Training loss: 0.8641738419769815
Validation loss: 2.3620297613901697

Epoch: 6| Step: 9
Training loss: 1.0530502043744374
Validation loss: 2.313283276015303

Epoch: 6| Step: 10
Training loss: 2.053414069834334
Validation loss: 2.316609316437875

Epoch: 6| Step: 11
Training loss: 0.7346004383550094
Validation loss: 2.372662483080268

Epoch: 6| Step: 12
Training loss: 1.1142672271731975
Validation loss: 2.296192656322222

Epoch: 6| Step: 13
Training loss: 0.9132876902566109
Validation loss: 2.2641605304652064

Epoch: 527| Step: 0
Training loss: 1.6496886797736534
Validation loss: 2.313561867252229

Epoch: 6| Step: 1
Training loss: 0.8215732876434696
Validation loss: 2.218765098131023

Epoch: 6| Step: 2
Training loss: 1.1274867653757237
Validation loss: 2.2773424351641847

Epoch: 6| Step: 3
Training loss: 1.035088533309857
Validation loss: 2.305404097281232

Epoch: 6| Step: 4
Training loss: 0.7592668636862145
Validation loss: 2.2677813380413956

Epoch: 6| Step: 5
Training loss: 0.8544777830817153
Validation loss: 2.2924305464012122

Epoch: 6| Step: 6
Training loss: 0.6114114820303767
Validation loss: 2.248317864499509

Epoch: 6| Step: 7
Training loss: 1.131647760844751
Validation loss: 2.28293795359707

Epoch: 6| Step: 8
Training loss: 0.8671094842132738
Validation loss: 2.3372070838564665

Epoch: 6| Step: 9
Training loss: 1.0565764289576414
Validation loss: 2.357454555614015

Epoch: 6| Step: 10
Training loss: 0.8634371379419397
Validation loss: 2.320865275645034

Epoch: 6| Step: 11
Training loss: 0.9259103612562917
Validation loss: 2.3063370841472

Epoch: 6| Step: 12
Training loss: 0.5978363862677112
Validation loss: 2.349940614357966

Epoch: 6| Step: 13
Training loss: 0.9640525631879381
Validation loss: 2.3333598804135653

Epoch: 528| Step: 0
Training loss: 1.156383661328629
Validation loss: 2.2775593300305914

Epoch: 6| Step: 1
Training loss: 0.9480060633050995
Validation loss: 2.3152601658586693

Epoch: 6| Step: 2
Training loss: 0.899963873562009
Validation loss: 2.4097584106070715

Epoch: 6| Step: 3
Training loss: 0.8155584724742525
Validation loss: 2.3211214465943044

Epoch: 6| Step: 4
Training loss: 1.8316413122799415
Validation loss: 2.3191595510045593

Epoch: 6| Step: 5
Training loss: 0.9423520730494991
Validation loss: 2.26626429436759

Epoch: 6| Step: 6
Training loss: 0.8855075714718148
Validation loss: 2.2740548809466428

Epoch: 6| Step: 7
Training loss: 0.7065632572701473
Validation loss: 2.352804970780157

Epoch: 6| Step: 8
Training loss: 0.9608728650693276
Validation loss: 2.310137328027536

Epoch: 6| Step: 9
Training loss: 0.8090492845076996
Validation loss: 2.2007675398612654

Epoch: 6| Step: 10
Training loss: 0.9438104281752919
Validation loss: 2.344635291033914

Epoch: 6| Step: 11
Training loss: 0.7185947416381231
Validation loss: 2.2816462524526013

Epoch: 6| Step: 12
Training loss: 1.10762019458861
Validation loss: 2.301340440886132

Epoch: 6| Step: 13
Training loss: 0.7846659557646667
Validation loss: 2.2509032416730608

Epoch: 529| Step: 0
Training loss: 0.9129314434701721
Validation loss: 2.297512779006591

Epoch: 6| Step: 1
Training loss: 0.6859997071579733
Validation loss: 2.303864401223798

Epoch: 6| Step: 2
Training loss: 0.8978830700022682
Validation loss: 2.3409715411674763

Epoch: 6| Step: 3
Training loss: 0.7876949734998031
Validation loss: 2.3133492256035466

Epoch: 6| Step: 4
Training loss: 1.1412040599254722
Validation loss: 2.2680569844487497

Epoch: 6| Step: 5
Training loss: 0.7526727576937107
Validation loss: 2.3510581836348057

Epoch: 6| Step: 6
Training loss: 0.8592097730457272
Validation loss: 2.2936149086850355

Epoch: 6| Step: 7
Training loss: 0.76405902229875
Validation loss: 2.310381883513085

Epoch: 6| Step: 8
Training loss: 0.9255124438236002
Validation loss: 2.2829237571334158

Epoch: 6| Step: 9
Training loss: 0.8546425648929538
Validation loss: 2.339162758357433

Epoch: 6| Step: 10
Training loss: 1.1766743863872855
Validation loss: 2.339659308243102

Epoch: 6| Step: 11
Training loss: 0.8659742305018199
Validation loss: 2.2675014941238665

Epoch: 6| Step: 12
Training loss: 1.877487503497801
Validation loss: 2.296276510402474

Epoch: 6| Step: 13
Training loss: 0.731536492851334
Validation loss: 2.405561580126398

Epoch: 530| Step: 0
Training loss: 1.1121831464132925
Validation loss: 2.236634579757796

Epoch: 6| Step: 1
Training loss: 0.8209276708298364
Validation loss: 2.271144433192927

Epoch: 6| Step: 2
Training loss: 1.1489598649753427
Validation loss: 2.3254606212535

Epoch: 6| Step: 3
Training loss: 0.6471191240456168
Validation loss: 2.2996647010323232

Epoch: 6| Step: 4
Training loss: 1.7308547577552102
Validation loss: 2.2492933981126844

Epoch: 6| Step: 5
Training loss: 1.1934178614292876
Validation loss: 2.316726085605822

Epoch: 6| Step: 6
Training loss: 0.9285305100637252
Validation loss: 2.4317988763644536

Epoch: 6| Step: 7
Training loss: 0.7949111900267568
Validation loss: 2.258966904105679

Epoch: 6| Step: 8
Training loss: 0.6529594987413356
Validation loss: 2.309538260807698

Epoch: 6| Step: 9
Training loss: 1.0117452610622204
Validation loss: 2.330803718595947

Epoch: 6| Step: 10
Training loss: 0.7694454242074225
Validation loss: 2.342464822600095

Epoch: 6| Step: 11
Training loss: 0.7933875420292589
Validation loss: 2.310965401049929

Epoch: 6| Step: 12
Training loss: 0.7944167498190329
Validation loss: 2.278447765174121

Epoch: 6| Step: 13
Training loss: 0.7210231163668244
Validation loss: 2.2474476450124685

Epoch: 531| Step: 0
Training loss: 0.9118110119734744
Validation loss: 2.265546404274801

Epoch: 6| Step: 1
Training loss: 0.6708204065779405
Validation loss: 2.3100906115886835

Epoch: 6| Step: 2
Training loss: 0.786452215478272
Validation loss: 2.3257841311575844

Epoch: 6| Step: 3
Training loss: 0.8661697188658745
Validation loss: 2.272522623034428

Epoch: 6| Step: 4
Training loss: 0.8794585124732963
Validation loss: 2.304149476870085

Epoch: 6| Step: 5
Training loss: 1.0226667574116128
Validation loss: 2.2531244877098735

Epoch: 6| Step: 6
Training loss: 0.748344740564732
Validation loss: 2.27371410010387

Epoch: 6| Step: 7
Training loss: 1.090830967645336
Validation loss: 2.352800297436747

Epoch: 6| Step: 8
Training loss: 1.3085597247354697
Validation loss: 2.2708084099056554

Epoch: 6| Step: 9
Training loss: 0.9337592836094685
Validation loss: 2.394660025374576

Epoch: 6| Step: 10
Training loss: 1.698478870888159
Validation loss: 2.332049476597792

Epoch: 6| Step: 11
Training loss: 0.8076412838497352
Validation loss: 2.3405566122789727

Epoch: 6| Step: 12
Training loss: 0.5579879783921436
Validation loss: 2.324339977759015

Epoch: 6| Step: 13
Training loss: 0.7017249686000219
Validation loss: 2.30985203523061

Epoch: 532| Step: 0
Training loss: 0.659698824439708
Validation loss: 2.340067840527422

Epoch: 6| Step: 1
Training loss: 0.844369025445748
Validation loss: 2.2388118464399756

Epoch: 6| Step: 2
Training loss: 0.8679816930923469
Validation loss: 2.4065414931884477

Epoch: 6| Step: 3
Training loss: 0.8589344629460112
Validation loss: 2.290458406169985

Epoch: 6| Step: 4
Training loss: 0.8956211563315374
Validation loss: 2.312778216706382

Epoch: 6| Step: 5
Training loss: 0.8861989922096137
Validation loss: 2.339806410083609

Epoch: 6| Step: 6
Training loss: 1.091978873436262
Validation loss: 2.31292190516612

Epoch: 6| Step: 7
Training loss: 0.8246551009474483
Validation loss: 2.257426347002665

Epoch: 6| Step: 8
Training loss: 0.8006550014809652
Validation loss: 2.3051391325900883

Epoch: 6| Step: 9
Training loss: 0.9126126454991433
Validation loss: 2.3019669454680036

Epoch: 6| Step: 10
Training loss: 1.8936585608838623
Validation loss: 2.2985555062142846

Epoch: 6| Step: 11
Training loss: 0.6460655676750546
Validation loss: 2.278082287458864

Epoch: 6| Step: 12
Training loss: 0.8569728222858626
Validation loss: 2.240657957995986

Epoch: 6| Step: 13
Training loss: 1.236613935124363
Validation loss: 2.3768972926075267

Epoch: 533| Step: 0
Training loss: 1.0576657665363869
Validation loss: 2.345584519490022

Epoch: 6| Step: 1
Training loss: 1.0177233806475126
Validation loss: 2.2733479583566187

Epoch: 6| Step: 2
Training loss: 0.9972399530868149
Validation loss: 2.2465503909344156

Epoch: 6| Step: 3
Training loss: 0.7110864671850968
Validation loss: 2.3246859129153017

Epoch: 6| Step: 4
Training loss: 0.8247966457935141
Validation loss: 2.3734706851147935

Epoch: 6| Step: 5
Training loss: 0.8044987058919547
Validation loss: 2.3799843570460215

Epoch: 6| Step: 6
Training loss: 0.7340622093749009
Validation loss: 2.25289664479024

Epoch: 6| Step: 7
Training loss: 0.7400270035688207
Validation loss: 2.348829601258161

Epoch: 6| Step: 8
Training loss: 0.7226731581900773
Validation loss: 2.3744334887501872

Epoch: 6| Step: 9
Training loss: 0.9546720113293875
Validation loss: 2.335991567738494

Epoch: 6| Step: 10
Training loss: 0.5443353812410259
Validation loss: 2.284306074507431

Epoch: 6| Step: 11
Training loss: 1.7946043179840037
Validation loss: 2.3269003806035937

Epoch: 6| Step: 12
Training loss: 0.6911066128014357
Validation loss: 2.339121688898482

Epoch: 6| Step: 13
Training loss: 0.9912397408646022
Validation loss: 2.362963002885214

Epoch: 534| Step: 0
Training loss: 0.7803509689216516
Validation loss: 2.2671182861898864

Epoch: 6| Step: 1
Training loss: 1.123265677988998
Validation loss: 2.321140437008112

Epoch: 6| Step: 2
Training loss: 1.0178032038553717
Validation loss: 2.2368985814962503

Epoch: 6| Step: 3
Training loss: 0.8904938182926821
Validation loss: 2.33102497518179

Epoch: 6| Step: 4
Training loss: 0.6202788375061127
Validation loss: 2.2872796066628855

Epoch: 6| Step: 5
Training loss: 1.0673509821634897
Validation loss: 2.2972532743123892

Epoch: 6| Step: 6
Training loss: 0.7815144663452319
Validation loss: 2.3347330258910834

Epoch: 6| Step: 7
Training loss: 1.0420859955137571
Validation loss: 2.327871054000797

Epoch: 6| Step: 8
Training loss: 1.0736171633138702
Validation loss: 2.3693314018908964

Epoch: 6| Step: 9
Training loss: 0.8640204324535943
Validation loss: 2.337263582474137

Epoch: 6| Step: 10
Training loss: 0.8647051499429679
Validation loss: 2.3222412399534735

Epoch: 6| Step: 11
Training loss: 0.9548915064434068
Validation loss: 2.292833893680417

Epoch: 6| Step: 12
Training loss: 0.8639816963808975
Validation loss: 2.2780503025274763

Epoch: 6| Step: 13
Training loss: 2.1026979236678343
Validation loss: 2.3236778395756548

Epoch: 535| Step: 0
Training loss: 0.7363147683791489
Validation loss: 2.2950158344025673

Epoch: 6| Step: 1
Training loss: 0.7985882760436691
Validation loss: 2.3205190813615095

Epoch: 6| Step: 2
Training loss: 1.809654896751564
Validation loss: 2.306574316882021

Epoch: 6| Step: 3
Training loss: 1.071307089140151
Validation loss: 2.344011338406401

Epoch: 6| Step: 4
Training loss: 0.746816035860033
Validation loss: 2.3378666480135815

Epoch: 6| Step: 5
Training loss: 0.8628988670552997
Validation loss: 2.2949732104241054

Epoch: 6| Step: 6
Training loss: 0.9162413882153991
Validation loss: 2.3207162965807266

Epoch: 6| Step: 7
Training loss: 0.7520120572863487
Validation loss: 2.284760023946516

Epoch: 6| Step: 8
Training loss: 0.9658073833282891
Validation loss: 2.3433745315219388

Epoch: 6| Step: 9
Training loss: 1.1822703803522698
Validation loss: 2.3220989666646528

Epoch: 6| Step: 10
Training loss: 1.024689352831339
Validation loss: 2.3758348984706927

Epoch: 6| Step: 11
Training loss: 1.3347965298302034
Validation loss: 2.3317822349020916

Epoch: 6| Step: 12
Training loss: 0.9183216471773714
Validation loss: 2.4384158622249723

Epoch: 6| Step: 13
Training loss: 0.8622891693619772
Validation loss: 2.3239838264018604

Epoch: 536| Step: 0
Training loss: 1.405924823039929
Validation loss: 2.303107897318653

Epoch: 6| Step: 1
Training loss: 0.53896864474823
Validation loss: 2.3092216044781093

Epoch: 6| Step: 2
Training loss: 1.7556992098156479
Validation loss: 2.351066139324954

Epoch: 6| Step: 3
Training loss: 0.7910481387390921
Validation loss: 2.216863627275997

Epoch: 6| Step: 4
Training loss: 0.9213797645326627
Validation loss: 2.3218904386714936

Epoch: 6| Step: 5
Training loss: 0.9466760432647583
Validation loss: 2.373538642250219

Epoch: 6| Step: 6
Training loss: 1.102798093602771
Validation loss: 2.3887675253636576

Epoch: 6| Step: 7
Training loss: 0.7843433936084947
Validation loss: 2.2491528119299087

Epoch: 6| Step: 8
Training loss: 0.8262036905858673
Validation loss: 2.267306680852066

Epoch: 6| Step: 9
Training loss: 0.7254539975620338
Validation loss: 2.2875533170968163

Epoch: 6| Step: 10
Training loss: 1.2176120042294376
Validation loss: 2.31557938588374

Epoch: 6| Step: 11
Training loss: 0.9877017285932721
Validation loss: 2.336571392066484

Epoch: 6| Step: 12
Training loss: 0.9456451083085662
Validation loss: 2.249043840308985

Epoch: 6| Step: 13
Training loss: 0.8784031084806476
Validation loss: 2.2278145712884503

Epoch: 537| Step: 0
Training loss: 0.7024612684874345
Validation loss: 2.261452307523299

Epoch: 6| Step: 1
Training loss: 1.0509951916120968
Validation loss: 2.3610311920116978

Epoch: 6| Step: 2
Training loss: 0.7908878929711544
Validation loss: 2.3660792014286187

Epoch: 6| Step: 3
Training loss: 1.5731988447435814
Validation loss: 2.2908434059389164

Epoch: 6| Step: 4
Training loss: 1.1593782532844243
Validation loss: 2.2873349803618876

Epoch: 6| Step: 5
Training loss: 1.111351133621248
Validation loss: 2.3653208186204697

Epoch: 6| Step: 6
Training loss: 0.7592128125209986
Validation loss: 2.2436614841150604

Epoch: 6| Step: 7
Training loss: 1.2092595442039782
Validation loss: 2.3497750389739775

Epoch: 6| Step: 8
Training loss: 0.900680925484636
Validation loss: 2.33326474504993

Epoch: 6| Step: 9
Training loss: 0.693697586313442
Validation loss: 2.325639555216478

Epoch: 6| Step: 10
Training loss: 1.0454896899298303
Validation loss: 2.4411999828860167

Epoch: 6| Step: 11
Training loss: 0.6719699393329598
Validation loss: 2.3013615495420927

Epoch: 6| Step: 12
Training loss: 0.9981330789562743
Validation loss: 2.3532040982424256

Epoch: 6| Step: 13
Training loss: 0.7221419695338946
Validation loss: 2.3763419889683406

Epoch: 538| Step: 0
Training loss: 0.8479717739733832
Validation loss: 2.1964976513164105

Epoch: 6| Step: 1
Training loss: 1.9555403766018904
Validation loss: 2.3066176796726743

Epoch: 6| Step: 2
Training loss: 0.7777539421773757
Validation loss: 2.293758856527241

Epoch: 6| Step: 3
Training loss: 0.9270374772521559
Validation loss: 2.3468867716730175

Epoch: 6| Step: 4
Training loss: 0.9613532120811548
Validation loss: 2.306309743408033

Epoch: 6| Step: 5
Training loss: 0.7387029664482642
Validation loss: 2.295465875476754

Epoch: 6| Step: 6
Training loss: 1.3291317882366287
Validation loss: 2.3360709594218956

Epoch: 6| Step: 7
Training loss: 0.9534317523554249
Validation loss: 2.2642074518064805

Epoch: 6| Step: 8
Training loss: 0.9984836108047467
Validation loss: 2.3543737928213724

Epoch: 6| Step: 9
Training loss: 0.7121203716222081
Validation loss: 2.33324839251327

Epoch: 6| Step: 10
Training loss: 0.7301445307771757
Validation loss: 2.3402630140011853

Epoch: 6| Step: 11
Training loss: 0.7418419284406905
Validation loss: 2.3574680618448807

Epoch: 6| Step: 12
Training loss: 0.6548031798064728
Validation loss: 2.3178301762715146

Epoch: 6| Step: 13
Training loss: 0.7135839983409756
Validation loss: 2.2554553641040163

Epoch: 539| Step: 0
Training loss: 0.7838550622539959
Validation loss: 2.273216379734809

Epoch: 6| Step: 1
Training loss: 1.0381035072081475
Validation loss: 2.3210286098514996

Epoch: 6| Step: 2
Training loss: 1.3081627890518488
Validation loss: 2.3142375399284365

Epoch: 6| Step: 3
Training loss: 0.666181258471821
Validation loss: 2.3269405712029423

Epoch: 6| Step: 4
Training loss: 0.730838702351398
Validation loss: 2.2675906391707707

Epoch: 6| Step: 5
Training loss: 0.6690147642294059
Validation loss: 2.296936385920956

Epoch: 6| Step: 6
Training loss: 0.6207469235734604
Validation loss: 2.2631325822243222

Epoch: 6| Step: 7
Training loss: 0.8491872857098384
Validation loss: 2.242374670039943

Epoch: 6| Step: 8
Training loss: 1.850852991326353
Validation loss: 2.3507288962907484

Epoch: 6| Step: 9
Training loss: 1.058399816111969
Validation loss: 2.276604536038084

Epoch: 6| Step: 10
Training loss: 0.6848809249086933
Validation loss: 2.228763484825585

Epoch: 6| Step: 11
Training loss: 0.8155167401839172
Validation loss: 2.313387465751327

Epoch: 6| Step: 12
Training loss: 0.9382920416243928
Validation loss: 2.319544860514539

Epoch: 6| Step: 13
Training loss: 1.0086814623573475
Validation loss: 2.2715901472830655

Epoch: 540| Step: 0
Training loss: 0.9927945420151287
Validation loss: 2.253037941502505

Epoch: 6| Step: 1
Training loss: 0.8439763083545182
Validation loss: 2.3000260373126884

Epoch: 6| Step: 2
Training loss: 1.635464718187661
Validation loss: 2.3348354871113934

Epoch: 6| Step: 3
Training loss: 0.5753427002546905
Validation loss: 2.296332973346079

Epoch: 6| Step: 4
Training loss: 0.7491088181913256
Validation loss: 2.3587649629128533

Epoch: 6| Step: 5
Training loss: 0.8695199203095841
Validation loss: 2.3206666032833474

Epoch: 6| Step: 6
Training loss: 0.9663316011701703
Validation loss: 2.3339980104562725

Epoch: 6| Step: 7
Training loss: 1.1664633857648061
Validation loss: 2.26239334251178

Epoch: 6| Step: 8
Training loss: 0.8696250679835285
Validation loss: 2.318156104659659

Epoch: 6| Step: 9
Training loss: 0.6974755406620201
Validation loss: 2.288384472343284

Epoch: 6| Step: 10
Training loss: 0.8399507676183796
Validation loss: 2.3211906226865304

Epoch: 6| Step: 11
Training loss: 0.6800160545669798
Validation loss: 2.2691120813040686

Epoch: 6| Step: 12
Training loss: 0.8331867486459453
Validation loss: 2.346641120264108

Epoch: 6| Step: 13
Training loss: 1.3562260691557488
Validation loss: 2.3204249905838665

Epoch: 541| Step: 0
Training loss: 0.844568385490801
Validation loss: 2.306717864440843

Epoch: 6| Step: 1
Training loss: 0.6539353012139871
Validation loss: 2.215458835328846

Epoch: 6| Step: 2
Training loss: 0.7836660791030081
Validation loss: 2.3182043311968403

Epoch: 6| Step: 3
Training loss: 0.8887072210304183
Validation loss: 2.3084592284297116

Epoch: 6| Step: 4
Training loss: 0.855592797051616
Validation loss: 2.2949896267935253

Epoch: 6| Step: 5
Training loss: 1.1680105960966254
Validation loss: 2.32064147674348

Epoch: 6| Step: 6
Training loss: 0.6064949936719104
Validation loss: 2.2631466558903863

Epoch: 6| Step: 7
Training loss: 0.931632211835129
Validation loss: 2.3322791920729307

Epoch: 6| Step: 8
Training loss: 0.8050287504570877
Validation loss: 2.259578355633777

Epoch: 6| Step: 9
Training loss: 1.8760307657651274
Validation loss: 2.274109190063766

Epoch: 6| Step: 10
Training loss: 0.8836620935103245
Validation loss: 2.3022164984790536

Epoch: 6| Step: 11
Training loss: 0.5996547023278695
Validation loss: 2.3665521782349304

Epoch: 6| Step: 12
Training loss: 1.0045936101585309
Validation loss: 2.2582858935183854

Epoch: 6| Step: 13
Training loss: 0.5909157920170669
Validation loss: 2.3158996002498373

Epoch: 542| Step: 0
Training loss: 0.6202356180355648
Validation loss: 2.2966047480558753

Epoch: 6| Step: 1
Training loss: 0.7847341665035966
Validation loss: 2.336965999220945

Epoch: 6| Step: 2
Training loss: 1.6742440667243077
Validation loss: 2.3584218475777172

Epoch: 6| Step: 3
Training loss: 1.0276036387057268
Validation loss: 2.3225958008567935

Epoch: 6| Step: 4
Training loss: 0.9890502531188329
Validation loss: 2.276449082597071

Epoch: 6| Step: 5
Training loss: 1.065339277786393
Validation loss: 2.381613335668906

Epoch: 6| Step: 6
Training loss: 0.803842230231952
Validation loss: 2.2591093965400932

Epoch: 6| Step: 7
Training loss: 0.8374585013285427
Validation loss: 2.302821210424756

Epoch: 6| Step: 8
Training loss: 0.816072094443915
Validation loss: 2.3000366091211117

Epoch: 6| Step: 9
Training loss: 0.9551809992704734
Validation loss: 2.3756391418704137

Epoch: 6| Step: 10
Training loss: 1.0269290681838412
Validation loss: 2.3364333034277753

Epoch: 6| Step: 11
Training loss: 0.7457349223915525
Validation loss: 2.32030985660015

Epoch: 6| Step: 12
Training loss: 0.8701134198896054
Validation loss: 2.2743524987153894

Epoch: 6| Step: 13
Training loss: 0.8382756342348702
Validation loss: 2.2467279090572365

Epoch: 543| Step: 0
Training loss: 2.000552816283476
Validation loss: 2.197521591973607

Epoch: 6| Step: 1
Training loss: 0.9106544146372181
Validation loss: 2.2673072914292622

Epoch: 6| Step: 2
Training loss: 0.6096544847489733
Validation loss: 2.3904321710590795

Epoch: 6| Step: 3
Training loss: 0.7994800696021002
Validation loss: 2.23476083769976

Epoch: 6| Step: 4
Training loss: 0.6702690448324705
Validation loss: 2.3943222081253155

Epoch: 6| Step: 5
Training loss: 1.204958225016803
Validation loss: 2.307073049221249

Epoch: 6| Step: 6
Training loss: 1.012187834289439
Validation loss: 2.3170120190624206

Epoch: 6| Step: 7
Training loss: 0.7686083531335005
Validation loss: 2.370250859621991

Epoch: 6| Step: 8
Training loss: 0.6236839744161642
Validation loss: 2.3504464624500208

Epoch: 6| Step: 9
Training loss: 1.119946414397913
Validation loss: 2.326669298868582

Epoch: 6| Step: 10
Training loss: 0.9330419082592455
Validation loss: 2.315658105709306

Epoch: 6| Step: 11
Training loss: 0.7469748841216449
Validation loss: 2.3253532119316933

Epoch: 6| Step: 12
Training loss: 0.8696099203737074
Validation loss: 2.316054843721644

Epoch: 6| Step: 13
Training loss: 0.8608783403899268
Validation loss: 2.287202732453481

Epoch: 544| Step: 0
Training loss: 1.1643811500210806
Validation loss: 2.3434807013570684

Epoch: 6| Step: 1
Training loss: 1.172305371412444
Validation loss: 2.2833533126816836

Epoch: 6| Step: 2
Training loss: 0.4237018344309595
Validation loss: 2.3185940093571733

Epoch: 6| Step: 3
Training loss: 0.6523845911090265
Validation loss: 2.2095450580676967

Epoch: 6| Step: 4
Training loss: 1.1194448007772893
Validation loss: 2.309360675827567

Epoch: 6| Step: 5
Training loss: 0.7712642307297872
Validation loss: 2.342316926204168

Epoch: 6| Step: 6
Training loss: 0.8464840285613403
Validation loss: 2.2958813141050323

Epoch: 6| Step: 7
Training loss: 0.7108843856924413
Validation loss: 2.3440302822738155

Epoch: 6| Step: 8
Training loss: 1.0972037689384844
Validation loss: 2.3437666577256526

Epoch: 6| Step: 9
Training loss: 0.9918749159180114
Validation loss: 2.3117103575426565

Epoch: 6| Step: 10
Training loss: 0.7295156370425765
Validation loss: 2.3181261921791543

Epoch: 6| Step: 11
Training loss: 1.6393095283072685
Validation loss: 2.32616315087366

Epoch: 6| Step: 12
Training loss: 0.7644426207680844
Validation loss: 2.2690984694444905

Epoch: 6| Step: 13
Training loss: 1.0814144428429515
Validation loss: 2.2496716169682087

Epoch: 545| Step: 0
Training loss: 0.7804375811244042
Validation loss: 2.235335207609057

Epoch: 6| Step: 1
Training loss: 0.5233725891859509
Validation loss: 2.289736108987296

Epoch: 6| Step: 2
Training loss: 0.660428324053995
Validation loss: 2.3044610075062475

Epoch: 6| Step: 3
Training loss: 0.925340571726522
Validation loss: 2.2882281604922605

Epoch: 6| Step: 4
Training loss: 1.1255161372976323
Validation loss: 2.3938700997730806

Epoch: 6| Step: 5
Training loss: 1.5884235609164552
Validation loss: 2.325884163259561

Epoch: 6| Step: 6
Training loss: 0.9187403905456817
Validation loss: 2.334762916116678

Epoch: 6| Step: 7
Training loss: 1.0886255928552169
Validation loss: 2.3109705788770207

Epoch: 6| Step: 8
Training loss: 0.6856244252566742
Validation loss: 2.333620762005151

Epoch: 6| Step: 9
Training loss: 0.722186745379527
Validation loss: 2.348591069774586

Epoch: 6| Step: 10
Training loss: 0.7167311802000946
Validation loss: 2.3105029856795922

Epoch: 6| Step: 11
Training loss: 0.7665727160426583
Validation loss: 2.3453871523988465

Epoch: 6| Step: 12
Training loss: 0.8377871149323044
Validation loss: 2.323666568557012

Epoch: 6| Step: 13
Training loss: 0.8717915430084531
Validation loss: 2.3404971448237353

Epoch: 546| Step: 0
Training loss: 0.8064688437297686
Validation loss: 2.3570454519682307

Epoch: 6| Step: 1
Training loss: 1.7143654818936431
Validation loss: 2.3312584277066137

Epoch: 6| Step: 2
Training loss: 0.9153190192670602
Validation loss: 2.350360453436705

Epoch: 6| Step: 3
Training loss: 0.998550079159578
Validation loss: 2.3966872232242906

Epoch: 6| Step: 4
Training loss: 0.6927651881546043
Validation loss: 2.3711841030366996

Epoch: 6| Step: 5
Training loss: 0.8192521644659148
Validation loss: 2.2922649739840084

Epoch: 6| Step: 6
Training loss: 1.2745380911269943
Validation loss: 2.311448680556206

Epoch: 6| Step: 7
Training loss: 0.8044112388669835
Validation loss: 2.271476558170711

Epoch: 6| Step: 8
Training loss: 0.8531888078575178
Validation loss: 2.3191409450874163

Epoch: 6| Step: 9
Training loss: 0.9843570162629022
Validation loss: 2.2937939339922946

Epoch: 6| Step: 10
Training loss: 0.8892216920376673
Validation loss: 2.3180899711078595

Epoch: 6| Step: 11
Training loss: 0.940095138858692
Validation loss: 2.303010236024338

Epoch: 6| Step: 12
Training loss: 0.8326793170524875
Validation loss: 2.3690449824420585

Epoch: 6| Step: 13
Training loss: 0.7916752831508802
Validation loss: 2.3133821863944943

Epoch: 547| Step: 0
Training loss: 0.6169537210141574
Validation loss: 2.2805650272410594

Epoch: 6| Step: 1
Training loss: 0.5918450162839685
Validation loss: 2.343718353385975

Epoch: 6| Step: 2
Training loss: 0.8663476537181631
Validation loss: 2.306469595965438

Epoch: 6| Step: 3
Training loss: 0.7106307908680274
Validation loss: 2.315668063957407

Epoch: 6| Step: 4
Training loss: 0.9927445897742898
Validation loss: 2.3777308909031003

Epoch: 6| Step: 5
Training loss: 1.6071579856766018
Validation loss: 2.309358098154473

Epoch: 6| Step: 6
Training loss: 0.9930673137641517
Validation loss: 2.3208682022955602

Epoch: 6| Step: 7
Training loss: 1.0573659159830113
Validation loss: 2.237412150657709

Epoch: 6| Step: 8
Training loss: 1.0607093981565576
Validation loss: 2.2963171680483665

Epoch: 6| Step: 9
Training loss: 0.8906955691036255
Validation loss: 2.2692636975286087

Epoch: 6| Step: 10
Training loss: 1.2003311812842252
Validation loss: 2.354779379262023

Epoch: 6| Step: 11
Training loss: 0.7301453471170775
Validation loss: 2.310360880018949

Epoch: 6| Step: 12
Training loss: 0.7857391319433582
Validation loss: 2.2962652623047184

Epoch: 6| Step: 13
Training loss: 0.8451291222078955
Validation loss: 2.3337520239832705

Epoch: 548| Step: 0
Training loss: 0.8490706917455688
Validation loss: 2.2714130485393134

Epoch: 6| Step: 1
Training loss: 0.8044479161597988
Validation loss: 2.224973976118563

Epoch: 6| Step: 2
Training loss: 0.8222603333364096
Validation loss: 2.3459920385323345

Epoch: 6| Step: 3
Training loss: 0.8600851072848685
Validation loss: 2.240303500306174

Epoch: 6| Step: 4
Training loss: 0.8874289403594349
Validation loss: 2.3002925101396228

Epoch: 6| Step: 5
Training loss: 1.705848406246937
Validation loss: 2.300157072866354

Epoch: 6| Step: 6
Training loss: 0.8816916853654698
Validation loss: 2.29597719342278

Epoch: 6| Step: 7
Training loss: 1.1140473523922547
Validation loss: 2.2902492230239258

Epoch: 6| Step: 8
Training loss: 0.8032882524506807
Validation loss: 2.328697361623026

Epoch: 6| Step: 9
Training loss: 0.7865376632461099
Validation loss: 2.270924270478391

Epoch: 6| Step: 10
Training loss: 0.714270648627118
Validation loss: 2.2761394779796436

Epoch: 6| Step: 11
Training loss: 0.8097542805666019
Validation loss: 2.2460236637689057

Epoch: 6| Step: 12
Training loss: 0.9767321019716264
Validation loss: 2.3972373076668614

Epoch: 6| Step: 13
Training loss: 1.002794889995031
Validation loss: 2.25741111905369

Epoch: 549| Step: 0
Training loss: 1.611096100718996
Validation loss: 2.315897629281798

Epoch: 6| Step: 1
Training loss: 0.6515887111084606
Validation loss: 2.2679061206566558

Epoch: 6| Step: 2
Training loss: 0.9227101374046023
Validation loss: 2.2866566080789803

Epoch: 6| Step: 3
Training loss: 1.017348953770432
Validation loss: 2.3272305069789243

Epoch: 6| Step: 4
Training loss: 1.0287674586505307
Validation loss: 2.4114124218687483

Epoch: 6| Step: 5
Training loss: 0.626847659358182
Validation loss: 2.315693015297479

Epoch: 6| Step: 6
Training loss: 0.7643603955274934
Validation loss: 2.306475233485844

Epoch: 6| Step: 7
Training loss: 0.9449168236271426
Validation loss: 2.29545275103462

Epoch: 6| Step: 8
Training loss: 1.028672494019694
Validation loss: 2.312520012385083

Epoch: 6| Step: 9
Training loss: 0.9141648716127987
Validation loss: 2.3303449614602094

Epoch: 6| Step: 10
Training loss: 1.0979002549008283
Validation loss: 2.342926352102597

Epoch: 6| Step: 11
Training loss: 0.7939178724813996
Validation loss: 2.35915165021739

Epoch: 6| Step: 12
Training loss: 0.9450265751487769
Validation loss: 2.376697956621299

Epoch: 6| Step: 13
Training loss: 0.6713881613975978
Validation loss: 2.3768561708440106

Epoch: 550| Step: 0
Training loss: 1.0142177515843351
Validation loss: 2.2977019375556527

Epoch: 6| Step: 1
Training loss: 0.8107152557127175
Validation loss: 2.394179639030483

Epoch: 6| Step: 2
Training loss: 1.0282449576942654
Validation loss: 2.3560682209497563

Epoch: 6| Step: 3
Training loss: 1.6803636476359838
Validation loss: 2.350676303927086

Epoch: 6| Step: 4
Training loss: 0.4351096588888916
Validation loss: 2.2973184431660005

Epoch: 6| Step: 5
Training loss: 0.8467951325202342
Validation loss: 2.1972218180930296

Epoch: 6| Step: 6
Training loss: 0.8689826050170772
Validation loss: 2.2147469048791923

Epoch: 6| Step: 7
Training loss: 0.5737432470319014
Validation loss: 2.1690888657889915

Epoch: 6| Step: 8
Training loss: 0.889796691668365
Validation loss: 2.302820181214895

Epoch: 6| Step: 9
Training loss: 0.9752518365310239
Validation loss: 2.2899394931422

Epoch: 6| Step: 10
Training loss: 0.9545331464940007
Validation loss: 2.2750236588881516

Epoch: 6| Step: 11
Training loss: 1.0503959658463198
Validation loss: 2.315821011511486

Epoch: 6| Step: 12
Training loss: 0.5026050297494175
Validation loss: 2.3772011777610866

Epoch: 6| Step: 13
Training loss: 1.140020811409635
Validation loss: 2.3428755246564985

Epoch: 551| Step: 0
Training loss: 1.114357839335617
Validation loss: 2.314972158883986

Epoch: 6| Step: 1
Training loss: 1.036280989051253
Validation loss: 2.2773816232496356

Epoch: 6| Step: 2
Training loss: 1.0690112592141676
Validation loss: 2.270979450315731

Epoch: 6| Step: 3
Training loss: 1.621471094542549
Validation loss: 2.3121579811668207

Epoch: 6| Step: 4
Training loss: 0.5345011690446364
Validation loss: 2.348230194012778

Epoch: 6| Step: 5
Training loss: 0.8286462978423276
Validation loss: 2.2991573392035116

Epoch: 6| Step: 6
Training loss: 0.7345903770670208
Validation loss: 2.3079400583561487

Epoch: 6| Step: 7
Training loss: 0.9511659531927923
Validation loss: 2.3064691991599537

Epoch: 6| Step: 8
Training loss: 0.7233703384367868
Validation loss: 2.266697511999955

Epoch: 6| Step: 9
Training loss: 0.8748266184553904
Validation loss: 2.3378773291551203

Epoch: 6| Step: 10
Training loss: 0.6016964453657032
Validation loss: 2.3029351904832214

Epoch: 6| Step: 11
Training loss: 0.7437901109409871
Validation loss: 2.2473161133542154

Epoch: 6| Step: 12
Training loss: 0.9727596856083337
Validation loss: 2.2734049044940217

Epoch: 6| Step: 13
Training loss: 0.53135189313414
Validation loss: 2.3014048490289114

Epoch: 552| Step: 0
Training loss: 1.0726527781475472
Validation loss: 2.3039508747089346

Epoch: 6| Step: 1
Training loss: 0.7300986918271661
Validation loss: 2.2615610768679337

Epoch: 6| Step: 2
Training loss: 1.0503190169037178
Validation loss: 2.302008842336225

Epoch: 6| Step: 3
Training loss: 0.8348122983102454
Validation loss: 2.2621009120245636

Epoch: 6| Step: 4
Training loss: 1.0357499633243967
Validation loss: 2.2286193109724284

Epoch: 6| Step: 5
Training loss: 0.5706530037867986
Validation loss: 2.3173264652884265

Epoch: 6| Step: 6
Training loss: 1.0142061152396258
Validation loss: 2.309101327736346

Epoch: 6| Step: 7
Training loss: 0.9145430581356865
Validation loss: 2.327079365253072

Epoch: 6| Step: 8
Training loss: 0.7796004619446311
Validation loss: 2.326663703667405

Epoch: 6| Step: 9
Training loss: 0.753826473146112
Validation loss: 2.301565670471857

Epoch: 6| Step: 10
Training loss: 0.7669904949265726
Validation loss: 2.3345228018563557

Epoch: 6| Step: 11
Training loss: 1.8014194904879426
Validation loss: 2.36900924067941

Epoch: 6| Step: 12
Training loss: 0.607840537868542
Validation loss: 2.4021080143536984

Epoch: 6| Step: 13
Training loss: 0.8690920355426943
Validation loss: 2.3269564623807057

Epoch: 553| Step: 0
Training loss: 0.7040157609741289
Validation loss: 2.3933224018772874

Epoch: 6| Step: 1
Training loss: 1.7391247706476523
Validation loss: 2.3073501570241146

Epoch: 6| Step: 2
Training loss: 1.3755031878740538
Validation loss: 2.3694240612646285

Epoch: 6| Step: 3
Training loss: 1.1255291647943257
Validation loss: 2.390951369321795

Epoch: 6| Step: 4
Training loss: 0.7136932453365562
Validation loss: 2.3519135867423695

Epoch: 6| Step: 5
Training loss: 0.9548602333450136
Validation loss: 2.3456184508742965

Epoch: 6| Step: 6
Training loss: 0.6257436619588888
Validation loss: 2.3423490891909364

Epoch: 6| Step: 7
Training loss: 0.8781833303497932
Validation loss: 2.2672728370924062

Epoch: 6| Step: 8
Training loss: 0.7183459431573329
Validation loss: 2.3161512925340864

Epoch: 6| Step: 9
Training loss: 0.5698893296569021
Validation loss: 2.342304805251892

Epoch: 6| Step: 10
Training loss: 0.9075588771542064
Validation loss: 2.365715731106253

Epoch: 6| Step: 11
Training loss: 0.802580138747679
Validation loss: 2.2625743102064373

Epoch: 6| Step: 12
Training loss: 0.8226108868183429
Validation loss: 2.280385290523573

Epoch: 6| Step: 13
Training loss: 1.3099794253706465
Validation loss: 2.2862312222227703

Epoch: 554| Step: 0
Training loss: 0.9296678492929626
Validation loss: 2.331214157427624

Epoch: 6| Step: 1
Training loss: 1.695628264241604
Validation loss: 2.240330632144066

Epoch: 6| Step: 2
Training loss: 0.8868641335034702
Validation loss: 2.3624125925720705

Epoch: 6| Step: 3
Training loss: 1.0009963317407549
Validation loss: 2.296811372278722

Epoch: 6| Step: 4
Training loss: 1.0562149854646163
Validation loss: 2.35593778229695

Epoch: 6| Step: 5
Training loss: 0.6595805891714487
Validation loss: 2.246823776190409

Epoch: 6| Step: 6
Training loss: 0.8336318117299004
Validation loss: 2.3546842426641947

Epoch: 6| Step: 7
Training loss: 0.6678103208885645
Validation loss: 2.344586597834434

Epoch: 6| Step: 8
Training loss: 1.0292852354024933
Validation loss: 2.2749905885909443

Epoch: 6| Step: 9
Training loss: 0.643008543060112
Validation loss: 2.234476587562129

Epoch: 6| Step: 10
Training loss: 0.6342077532761984
Validation loss: 2.2958986295582218

Epoch: 6| Step: 11
Training loss: 0.8588697161788869
Validation loss: 2.2381007950677287

Epoch: 6| Step: 12
Training loss: 0.9091518246225646
Validation loss: 2.342208183439308

Epoch: 6| Step: 13
Training loss: 0.5674305828423715
Validation loss: 2.3714216160062866

Epoch: 555| Step: 0
Training loss: 0.8653154528930139
Validation loss: 2.292620794921985

Epoch: 6| Step: 1
Training loss: 1.6828615937647131
Validation loss: 2.348873125877406

Epoch: 6| Step: 2
Training loss: 0.7848432685718431
Validation loss: 2.309175910878654

Epoch: 6| Step: 3
Training loss: 0.7883133684161254
Validation loss: 2.2804876934223732

Epoch: 6| Step: 4
Training loss: 0.9601880073727285
Validation loss: 2.3256862982832645

Epoch: 6| Step: 5
Training loss: 1.0236398045592743
Validation loss: 2.2982403133162306

Epoch: 6| Step: 6
Training loss: 0.8371064400098565
Validation loss: 2.2794162776507187

Epoch: 6| Step: 7
Training loss: 1.1705021255128407
Validation loss: 2.332661585497973

Epoch: 6| Step: 8
Training loss: 1.0014029436775584
Validation loss: 2.3838873563997938

Epoch: 6| Step: 9
Training loss: 1.1285997654494306
Validation loss: 2.344740723713411

Epoch: 6| Step: 10
Training loss: 0.7350620545900908
Validation loss: 2.3818812408603587

Epoch: 6| Step: 11
Training loss: 0.7001521949846442
Validation loss: 2.270616473789833

Epoch: 6| Step: 12
Training loss: 0.6268446403598648
Validation loss: 2.279584032745449

Epoch: 6| Step: 13
Training loss: 0.872370276385166
Validation loss: 2.3702498158870005

Epoch: 556| Step: 0
Training loss: 0.8167054937500885
Validation loss: 2.351179653274029

Epoch: 6| Step: 1
Training loss: 0.7084731263237594
Validation loss: 2.285218449929208

Epoch: 6| Step: 2
Training loss: 1.668007271743951
Validation loss: 2.2758848397640405

Epoch: 6| Step: 3
Training loss: 0.7640852333852624
Validation loss: 2.3342404499361056

Epoch: 6| Step: 4
Training loss: 0.8455660314644796
Validation loss: 2.3499228096290974

Epoch: 6| Step: 5
Training loss: 1.132795662590387
Validation loss: 2.35823104258554

Epoch: 6| Step: 6
Training loss: 0.846427378300107
Validation loss: 2.2549567400667705

Epoch: 6| Step: 7
Training loss: 0.859661921374046
Validation loss: 2.328955658026341

Epoch: 6| Step: 8
Training loss: 0.9009272037781789
Validation loss: 2.267402395300447

Epoch: 6| Step: 9
Training loss: 0.7271439061624356
Validation loss: 2.2951575722638085

Epoch: 6| Step: 10
Training loss: 0.9014976464916278
Validation loss: 2.2653865248816563

Epoch: 6| Step: 11
Training loss: 0.9932390182852026
Validation loss: 2.2653443558353787

Epoch: 6| Step: 12
Training loss: 0.765257961499717
Validation loss: 2.308758745463457

Epoch: 6| Step: 13
Training loss: 0.9257878492417911
Validation loss: 2.3673217620565197

Epoch: 557| Step: 0
Training loss: 0.8029469303774842
Validation loss: 2.2975975999989173

Epoch: 6| Step: 1
Training loss: 1.0102742609303075
Validation loss: 2.2844949872498654

Epoch: 6| Step: 2
Training loss: 0.6828324356485986
Validation loss: 2.2888453388026835

Epoch: 6| Step: 3
Training loss: 0.5468340177166459
Validation loss: 2.2952667425438134

Epoch: 6| Step: 4
Training loss: 0.6821682699501377
Validation loss: 2.2477247670725813

Epoch: 6| Step: 5
Training loss: 0.7747932265914664
Validation loss: 2.3621985030905157

Epoch: 6| Step: 6
Training loss: 0.9465934964454474
Validation loss: 2.34616289746244

Epoch: 6| Step: 7
Training loss: 1.1275068539159492
Validation loss: 2.3661177124046358

Epoch: 6| Step: 8
Training loss: 0.9752708132316585
Validation loss: 2.216906580600811

Epoch: 6| Step: 9
Training loss: 0.8981169087172256
Validation loss: 2.3073812991540756

Epoch: 6| Step: 10
Training loss: 0.8043207981133016
Validation loss: 2.4002336571420906

Epoch: 6| Step: 11
Training loss: 0.7837849879022274
Validation loss: 2.2443597090232026

Epoch: 6| Step: 12
Training loss: 1.7916847568160552
Validation loss: 2.3422217086315142

Epoch: 6| Step: 13
Training loss: 1.0924257708893814
Validation loss: 2.29031338228409

Epoch: 558| Step: 0
Training loss: 1.6567465559631627
Validation loss: 2.266067039696604

Epoch: 6| Step: 1
Training loss: 0.8152758424646765
Validation loss: 2.2900342062138996

Epoch: 6| Step: 2
Training loss: 0.9524014963193544
Validation loss: 2.330750461594976

Epoch: 6| Step: 3
Training loss: 1.1905410877204525
Validation loss: 2.34845706593494

Epoch: 6| Step: 4
Training loss: 1.0222564755162593
Validation loss: 2.3180368701955696

Epoch: 6| Step: 5
Training loss: 0.8127201955699338
Validation loss: 2.3150452672168056

Epoch: 6| Step: 6
Training loss: 1.146073743857505
Validation loss: 2.2733362382036577

Epoch: 6| Step: 7
Training loss: 0.8797857334720676
Validation loss: 2.344317867163012

Epoch: 6| Step: 8
Training loss: 0.7386889265604862
Validation loss: 2.395803683731926

Epoch: 6| Step: 9
Training loss: 0.7645261625350247
Validation loss: 2.318546524011435

Epoch: 6| Step: 10
Training loss: 0.7223129694323934
Validation loss: 2.303208248111945

Epoch: 6| Step: 11
Training loss: 0.49376444010805
Validation loss: 2.3109513573488756

Epoch: 6| Step: 12
Training loss: 0.8571161581036498
Validation loss: 2.32182519198174

Epoch: 6| Step: 13
Training loss: 0.9322443831119338
Validation loss: 2.1984783174852884

Epoch: 559| Step: 0
Training loss: 0.7177301302969422
Validation loss: 2.31278628467662

Epoch: 6| Step: 1
Training loss: 0.9637075676587943
Validation loss: 2.3989107082605714

Epoch: 6| Step: 2
Training loss: 0.828081381746705
Validation loss: 2.3711763786426596

Epoch: 6| Step: 3
Training loss: 0.8827615908907278
Validation loss: 2.310868842849302

Epoch: 6| Step: 4
Training loss: 0.6673719629081788
Validation loss: 2.3842639619682418

Epoch: 6| Step: 5
Training loss: 0.9187801589686874
Validation loss: 2.2333442151271807

Epoch: 6| Step: 6
Training loss: 0.8421149482687724
Validation loss: 2.3086049791177516

Epoch: 6| Step: 7
Training loss: 1.2246522059395866
Validation loss: 2.2908622702192725

Epoch: 6| Step: 8
Training loss: 0.620133239057757
Validation loss: 2.303066040759047

Epoch: 6| Step: 9
Training loss: 0.7621842355881119
Validation loss: 2.3361164556334235

Epoch: 6| Step: 10
Training loss: 1.6545303342130222
Validation loss: 2.2847645935362926

Epoch: 6| Step: 11
Training loss: 0.7104256013176024
Validation loss: 2.207899854035155

Epoch: 6| Step: 12
Training loss: 0.9969724481959634
Validation loss: 2.22223155735817

Epoch: 6| Step: 13
Training loss: 0.8213029241129202
Validation loss: 2.348213268813492

Epoch: 560| Step: 0
Training loss: 0.6544444359025737
Validation loss: 2.374560934067142

Epoch: 6| Step: 1
Training loss: 0.671725899764115
Validation loss: 2.3586543639070348

Epoch: 6| Step: 2
Training loss: 0.7265062207810874
Validation loss: 2.391368285275293

Epoch: 6| Step: 3
Training loss: 1.1649994631590037
Validation loss: 2.3546885246775826

Epoch: 6| Step: 4
Training loss: 0.8822107880748467
Validation loss: 2.3545566834341924

Epoch: 6| Step: 5
Training loss: 0.7171061417718402
Validation loss: 2.3828394971179203

Epoch: 6| Step: 6
Training loss: 0.8573461685994723
Validation loss: 2.3930424453790495

Epoch: 6| Step: 7
Training loss: 0.6709679091464584
Validation loss: 2.299662380040705

Epoch: 6| Step: 8
Training loss: 1.1345349601009318
Validation loss: 2.2300878692768076

Epoch: 6| Step: 9
Training loss: 0.7915813165800889
Validation loss: 2.319965539765785

Epoch: 6| Step: 10
Training loss: 1.1073046963709507
Validation loss: 2.2808552393562915

Epoch: 6| Step: 11
Training loss: 0.8873293618582169
Validation loss: 2.3467918602254794

Epoch: 6| Step: 12
Training loss: 1.6663664865377168
Validation loss: 2.248313898712404

Epoch: 6| Step: 13
Training loss: 0.5739893292771022
Validation loss: 2.316581258094301

Epoch: 561| Step: 0
Training loss: 0.8370113071489151
Validation loss: 2.3161075990720175

Epoch: 6| Step: 1
Training loss: 0.755026464377407
Validation loss: 2.2237020964872793

Epoch: 6| Step: 2
Training loss: 1.1986607548783954
Validation loss: 2.2731004938866275

Epoch: 6| Step: 3
Training loss: 0.6940788297350987
Validation loss: 2.2415735603976503

Epoch: 6| Step: 4
Training loss: 0.8037449399631627
Validation loss: 2.3645242216820392

Epoch: 6| Step: 5
Training loss: 0.6338355660092858
Validation loss: 2.288738805321071

Epoch: 6| Step: 6
Training loss: 1.6081897852717106
Validation loss: 2.266920222602418

Epoch: 6| Step: 7
Training loss: 0.7370117413945522
Validation loss: 2.2993934334880457

Epoch: 6| Step: 8
Training loss: 1.055449598973011
Validation loss: 2.3094216929610925

Epoch: 6| Step: 9
Training loss: 0.7340628995606044
Validation loss: 2.2964883311011186

Epoch: 6| Step: 10
Training loss: 0.9278186960549868
Validation loss: 2.390560397795946

Epoch: 6| Step: 11
Training loss: 0.836323693453911
Validation loss: 2.3523556030701505

Epoch: 6| Step: 12
Training loss: 0.7947136233615434
Validation loss: 2.223296750612001

Epoch: 6| Step: 13
Training loss: 1.087999759589898
Validation loss: 2.369746143904943

Epoch: 562| Step: 0
Training loss: 0.5621338288248153
Validation loss: 2.327662823247884

Epoch: 6| Step: 1
Training loss: 0.8255583737539032
Validation loss: 2.2713927970007326

Epoch: 6| Step: 2
Training loss: 1.216017864064705
Validation loss: 2.2795674047789793

Epoch: 6| Step: 3
Training loss: 0.9428020592283047
Validation loss: 2.2971784848657393

Epoch: 6| Step: 4
Training loss: 0.6820166132908703
Validation loss: 2.3071410142153623

Epoch: 6| Step: 5
Training loss: 0.842701719908036
Validation loss: 2.3811919771372523

Epoch: 6| Step: 6
Training loss: 0.8002245572951608
Validation loss: 2.2794566559755527

Epoch: 6| Step: 7
Training loss: 0.7057811792967742
Validation loss: 2.277364787269807

Epoch: 6| Step: 8
Training loss: 0.9488686751977886
Validation loss: 2.178604153732694

Epoch: 6| Step: 9
Training loss: 0.9425090171625462
Validation loss: 2.334598668600678

Epoch: 6| Step: 10
Training loss: 1.7343703261303858
Validation loss: 2.378599818412235

Epoch: 6| Step: 11
Training loss: 0.8480711593911158
Validation loss: 2.303283629797896

Epoch: 6| Step: 12
Training loss: 0.6098344977789005
Validation loss: 2.2944712871434803

Epoch: 6| Step: 13
Training loss: 0.856188188535454
Validation loss: 2.3295959860077806

Epoch: 563| Step: 0
Training loss: 0.9233806405417381
Validation loss: 2.337281669004477

Epoch: 6| Step: 1
Training loss: 0.9326548623668889
Validation loss: 2.2880158400706883

Epoch: 6| Step: 2
Training loss: 1.6405740639181914
Validation loss: 2.3492524319649184

Epoch: 6| Step: 3
Training loss: 0.7742478720291156
Validation loss: 2.28147275249861

Epoch: 6| Step: 4
Training loss: 0.9623061876728558
Validation loss: 2.292542730934862

Epoch: 6| Step: 5
Training loss: 0.930101542876961
Validation loss: 2.2030835263768873

Epoch: 6| Step: 6
Training loss: 0.7504172753799853
Validation loss: 2.3221786439818315

Epoch: 6| Step: 7
Training loss: 0.9405981687349909
Validation loss: 2.349893318971692

Epoch: 6| Step: 8
Training loss: 0.6778924191582952
Validation loss: 2.267955033659133

Epoch: 6| Step: 9
Training loss: 1.094158259899638
Validation loss: 2.2816150377156115

Epoch: 6| Step: 10
Training loss: 0.5470642035026443
Validation loss: 2.3187039485854144

Epoch: 6| Step: 11
Training loss: 0.5962426915710516
Validation loss: 2.327187748590742

Epoch: 6| Step: 12
Training loss: 0.7545921091643311
Validation loss: 2.34116430689479

Epoch: 6| Step: 13
Training loss: 1.1483148522313213
Validation loss: 2.2745123119966406

Epoch: 564| Step: 0
Training loss: 0.9093538603013318
Validation loss: 2.2730201941768353

Epoch: 6| Step: 1
Training loss: 0.7668467135758227
Validation loss: 2.306908893346054

Epoch: 6| Step: 2
Training loss: 0.7804478914606666
Validation loss: 2.271266805192128

Epoch: 6| Step: 3
Training loss: 0.7094442594218114
Validation loss: 2.324319091572194

Epoch: 6| Step: 4
Training loss: 1.1692310771116439
Validation loss: 2.2888215094344364

Epoch: 6| Step: 5
Training loss: 0.8728145145074779
Validation loss: 2.3533087700988213

Epoch: 6| Step: 6
Training loss: 0.8277895985967587
Validation loss: 2.23036931322354

Epoch: 6| Step: 7
Training loss: 0.6575386700662726
Validation loss: 2.3299314432463785

Epoch: 6| Step: 8
Training loss: 0.5346883691527605
Validation loss: 2.2800493079659083

Epoch: 6| Step: 9
Training loss: 0.6912099699739581
Validation loss: 2.3110062060064855

Epoch: 6| Step: 10
Training loss: 0.7153716509265882
Validation loss: 2.313539707511579

Epoch: 6| Step: 11
Training loss: 0.5287130873671283
Validation loss: 2.3231932489534093

Epoch: 6| Step: 12
Training loss: 1.7000480645060772
Validation loss: 2.277766472011147

Epoch: 6| Step: 13
Training loss: 0.7043736073802596
Validation loss: 2.2421336376741987

Epoch: 565| Step: 0
Training loss: 0.7919463909939507
Validation loss: 2.3138312477024727

Epoch: 6| Step: 1
Training loss: 0.8282794448496087
Validation loss: 2.3768421864132954

Epoch: 6| Step: 2
Training loss: 0.6203679576460996
Validation loss: 2.357539542446413

Epoch: 6| Step: 3
Training loss: 1.0281783510412907
Validation loss: 2.320405742414855

Epoch: 6| Step: 4
Training loss: 0.7809978078061645
Validation loss: 2.3015610395604726

Epoch: 6| Step: 5
Training loss: 1.7564731496859345
Validation loss: 2.328352446924413

Epoch: 6| Step: 6
Training loss: 0.813428201875072
Validation loss: 2.2659043662817053

Epoch: 6| Step: 7
Training loss: 1.1380123367981712
Validation loss: 2.329655852777244

Epoch: 6| Step: 8
Training loss: 0.9819521074716949
Validation loss: 2.212215731104345

Epoch: 6| Step: 9
Training loss: 0.7357190595596285
Validation loss: 2.312627673539418

Epoch: 6| Step: 10
Training loss: 0.9644483613290175
Validation loss: 2.2269877941696428

Epoch: 6| Step: 11
Training loss: 0.7827579441209604
Validation loss: 2.263930949987545

Epoch: 6| Step: 12
Training loss: 0.6282797826727539
Validation loss: 2.3024032248761404

Epoch: 6| Step: 13
Training loss: 0.9785612175650379
Validation loss: 2.277441178572581

Epoch: 566| Step: 0
Training loss: 0.7704764046692004
Validation loss: 2.326098809982472

Epoch: 6| Step: 1
Training loss: 0.8365273934466058
Validation loss: 2.2428656935121785

Epoch: 6| Step: 2
Training loss: 1.9418161984059468
Validation loss: 2.329216132855975

Epoch: 6| Step: 3
Training loss: 0.900643567615907
Validation loss: 2.257226075763769

Epoch: 6| Step: 4
Training loss: 0.7634247284803511
Validation loss: 2.3003059385256734

Epoch: 6| Step: 5
Training loss: 0.7288386469950511
Validation loss: 2.2320821482757256

Epoch: 6| Step: 6
Training loss: 0.825283357336094
Validation loss: 2.306516288490477

Epoch: 6| Step: 7
Training loss: 0.8674753072340957
Validation loss: 2.2989557800081037

Epoch: 6| Step: 8
Training loss: 0.7668947084563418
Validation loss: 2.26194377441928

Epoch: 6| Step: 9
Training loss: 0.7857123915228367
Validation loss: 2.250092055603568

Epoch: 6| Step: 10
Training loss: 0.6266213843627328
Validation loss: 2.3136499024211337

Epoch: 6| Step: 11
Training loss: 0.8855745436590949
Validation loss: 2.3535892276779955

Epoch: 6| Step: 12
Training loss: 0.8076155269287455
Validation loss: 2.395107453229648

Epoch: 6| Step: 13
Training loss: 0.4002682010222115
Validation loss: 2.2761651701118963

Epoch: 567| Step: 0
Training loss: 0.4330150075408472
Validation loss: 2.356250950665757

Epoch: 6| Step: 1
Training loss: 0.9220029774429505
Validation loss: 2.27604352553416

Epoch: 6| Step: 2
Training loss: 0.7038280363164341
Validation loss: 2.2952849103727497

Epoch: 6| Step: 3
Training loss: 0.7469819459201609
Validation loss: 2.308845166106926

Epoch: 6| Step: 4
Training loss: 0.6823575204027968
Validation loss: 2.2966028325285435

Epoch: 6| Step: 5
Training loss: 1.668491969358182
Validation loss: 2.2182440913961923

Epoch: 6| Step: 6
Training loss: 0.6901052702888925
Validation loss: 2.2794450718265087

Epoch: 6| Step: 7
Training loss: 0.7210848244624045
Validation loss: 2.2958210378454247

Epoch: 6| Step: 8
Training loss: 1.1768887902017604
Validation loss: 2.2719271320067556

Epoch: 6| Step: 9
Training loss: 1.0769642649099673
Validation loss: 2.343223004997132

Epoch: 6| Step: 10
Training loss: 1.1139444617701486
Validation loss: 2.3392117085763493

Epoch: 6| Step: 11
Training loss: 0.8127267227758673
Validation loss: 2.245455034277732

Epoch: 6| Step: 12
Training loss: 0.7644618014865143
Validation loss: 2.307870571736005

Epoch: 6| Step: 13
Training loss: 0.5733893756266039
Validation loss: 2.328952436075204

Epoch: 568| Step: 0
Training loss: 0.7547052922333326
Validation loss: 2.326092932367676

Epoch: 6| Step: 1
Training loss: 0.9287841960521029
Validation loss: 2.3115728105381925

Epoch: 6| Step: 2
Training loss: 0.8247752548194717
Validation loss: 2.350996381093683

Epoch: 6| Step: 3
Training loss: 0.6707203724531421
Validation loss: 2.3003608604662

Epoch: 6| Step: 4
Training loss: 0.7881084377475572
Validation loss: 2.343675236757168

Epoch: 6| Step: 5
Training loss: 1.7507393501303175
Validation loss: 2.3092190940929966

Epoch: 6| Step: 6
Training loss: 0.9992422570870333
Validation loss: 2.3522539970978125

Epoch: 6| Step: 7
Training loss: 0.9251622573201362
Validation loss: 2.3293118504281507

Epoch: 6| Step: 8
Training loss: 1.0012582968607404
Validation loss: 2.227293434049095

Epoch: 6| Step: 9
Training loss: 0.9367305777139466
Validation loss: 2.2996562074401647

Epoch: 6| Step: 10
Training loss: 0.547572100346726
Validation loss: 2.288788628419134

Epoch: 6| Step: 11
Training loss: 0.6804413834859848
Validation loss: 2.2662814198233616

Epoch: 6| Step: 12
Training loss: 1.2260216656492733
Validation loss: 2.328179280001429

Epoch: 6| Step: 13
Training loss: 0.7370930955440556
Validation loss: 2.2570911868602734

Epoch: 569| Step: 0
Training loss: 1.0288838493440253
Validation loss: 2.270923371875837

Epoch: 6| Step: 1
Training loss: 0.6665672188335627
Validation loss: 2.307660297399756

Epoch: 6| Step: 2
Training loss: 1.6741760675683146
Validation loss: 2.311476518938691

Epoch: 6| Step: 3
Training loss: 0.6666304583452106
Validation loss: 2.31523512459231

Epoch: 6| Step: 4
Training loss: 1.032604945763036
Validation loss: 2.245274967799013

Epoch: 6| Step: 5
Training loss: 0.8510338078248432
Validation loss: 2.2491456144933415

Epoch: 6| Step: 6
Training loss: 0.612557342336329
Validation loss: 2.3664551554473414

Epoch: 6| Step: 7
Training loss: 1.0301082532901087
Validation loss: 2.3163841528859597

Epoch: 6| Step: 8
Training loss: 0.7102345774881806
Validation loss: 2.299031001165075

Epoch: 6| Step: 9
Training loss: 0.5059024394789191
Validation loss: 2.3349349941961397

Epoch: 6| Step: 10
Training loss: 0.6946971828113638
Validation loss: 2.3303721962256954

Epoch: 6| Step: 11
Training loss: 1.075625466097831
Validation loss: 2.3321597928438402

Epoch: 6| Step: 12
Training loss: 0.7844837402107773
Validation loss: 2.3132372176848763

Epoch: 6| Step: 13
Training loss: 0.8097834657358978
Validation loss: 2.3066180986811817

Epoch: 570| Step: 0
Training loss: 0.9442885977744521
Validation loss: 2.2658303767078727

Epoch: 6| Step: 1
Training loss: 0.6106471940285578
Validation loss: 2.346894950143417

Epoch: 6| Step: 2
Training loss: 0.6353424268617475
Validation loss: 2.221255285958595

Epoch: 6| Step: 3
Training loss: 0.8158002000210408
Validation loss: 2.2784205314013173

Epoch: 6| Step: 4
Training loss: 0.7649927448103196
Validation loss: 2.237957768014406

Epoch: 6| Step: 5
Training loss: 0.6913928229973283
Validation loss: 2.2474984935374147

Epoch: 6| Step: 6
Training loss: 0.9160813428001833
Validation loss: 2.220152110758924

Epoch: 6| Step: 7
Training loss: 0.9029203612060257
Validation loss: 2.251704583236538

Epoch: 6| Step: 8
Training loss: 1.5685477897749827
Validation loss: 2.2923213243670766

Epoch: 6| Step: 9
Training loss: 1.0150195150895245
Validation loss: 2.356238183841958

Epoch: 6| Step: 10
Training loss: 0.6748891244884475
Validation loss: 2.297075910600905

Epoch: 6| Step: 11
Training loss: 0.7837640366217523
Validation loss: 2.3481572585584423

Epoch: 6| Step: 12
Training loss: 1.061353401385729
Validation loss: 2.2758238998389815

Epoch: 6| Step: 13
Training loss: 0.8469077466425975
Validation loss: 2.2635722545902652

Epoch: 571| Step: 0
Training loss: 0.9427676032948559
Validation loss: 2.359232343449041

Epoch: 6| Step: 1
Training loss: 0.8060794383769636
Validation loss: 2.3576085508749802

Epoch: 6| Step: 2
Training loss: 0.8914929895216288
Validation loss: 2.3571892871251663

Epoch: 6| Step: 3
Training loss: 0.8022939397250889
Validation loss: 2.3269495210209614

Epoch: 6| Step: 4
Training loss: 0.9906126725545948
Validation loss: 2.3383283077681214

Epoch: 6| Step: 5
Training loss: 0.8989527344483275
Validation loss: 2.3213575113385754

Epoch: 6| Step: 6
Training loss: 0.809030166280456
Validation loss: 2.364032591417408

Epoch: 6| Step: 7
Training loss: 0.9299666041869213
Validation loss: 2.35379763393394

Epoch: 6| Step: 8
Training loss: 0.6412012253443193
Validation loss: 2.2537248683879554

Epoch: 6| Step: 9
Training loss: 1.6331325381630946
Validation loss: 2.2700470052823993

Epoch: 6| Step: 10
Training loss: 0.7890833861353379
Validation loss: 2.318772728023637

Epoch: 6| Step: 11
Training loss: 0.9003609675159024
Validation loss: 2.31104093405287

Epoch: 6| Step: 12
Training loss: 0.9707232651645568
Validation loss: 2.3298595513574956

Epoch: 6| Step: 13
Training loss: 0.9299702895453721
Validation loss: 2.2703185689539427

Epoch: 572| Step: 0
Training loss: 1.0066058009633265
Validation loss: 2.3774797908675023

Epoch: 6| Step: 1
Training loss: 0.5101987087930261
Validation loss: 2.296210104520012

Epoch: 6| Step: 2
Training loss: 0.7324405922087553
Validation loss: 2.30543963807292

Epoch: 6| Step: 3
Training loss: 0.6809622988270779
Validation loss: 2.3453530225548485

Epoch: 6| Step: 4
Training loss: 0.9538755744669407
Validation loss: 2.253588038520489

Epoch: 6| Step: 5
Training loss: 0.8161954105577197
Validation loss: 2.2908744613610685

Epoch: 6| Step: 6
Training loss: 0.5193082000796811
Validation loss: 2.3172974376537256

Epoch: 6| Step: 7
Training loss: 0.4928559804541344
Validation loss: 2.2954684022987846

Epoch: 6| Step: 8
Training loss: 0.5188505546363938
Validation loss: 2.355022755728399

Epoch: 6| Step: 9
Training loss: 0.7050323048758681
Validation loss: 2.317162807888625

Epoch: 6| Step: 10
Training loss: 0.8124503707400341
Validation loss: 2.2762654411018928

Epoch: 6| Step: 11
Training loss: 1.7696604565738816
Validation loss: 2.363257483431756

Epoch: 6| Step: 12
Training loss: 0.8619292706726068
Validation loss: 2.251124634189171

Epoch: 6| Step: 13
Training loss: 0.5788763936898546
Validation loss: 2.226735182151914

Epoch: 573| Step: 0
Training loss: 0.7570029585111547
Validation loss: 2.316710238232523

Epoch: 6| Step: 1
Training loss: 0.7778235253625084
Validation loss: 2.2596943387656077

Epoch: 6| Step: 2
Training loss: 1.1148663930859037
Validation loss: 2.3288567089597287

Epoch: 6| Step: 3
Training loss: 1.6259624858624904
Validation loss: 2.349816352634539

Epoch: 6| Step: 4
Training loss: 0.9473554745564725
Validation loss: 2.271411070007054

Epoch: 6| Step: 5
Training loss: 1.0570799078389022
Validation loss: 2.4296020117146084

Epoch: 6| Step: 6
Training loss: 0.7692410459198763
Validation loss: 2.300878735292626

Epoch: 6| Step: 7
Training loss: 0.8725916552564092
Validation loss: 2.2280703039255414

Epoch: 6| Step: 8
Training loss: 0.710653982116669
Validation loss: 2.326826996911634

Epoch: 6| Step: 9
Training loss: 0.7897432619914144
Validation loss: 2.2796105564935383

Epoch: 6| Step: 10
Training loss: 0.5696215428491672
Validation loss: 2.3743189886157756

Epoch: 6| Step: 11
Training loss: 0.7047567929796067
Validation loss: 2.325159922628492

Epoch: 6| Step: 12
Training loss: 0.7487453456727634
Validation loss: 2.3434198257700496

Epoch: 6| Step: 13
Training loss: 0.63397277614586
Validation loss: 2.3399375332338037

Epoch: 574| Step: 0
Training loss: 0.740172491783247
Validation loss: 2.3193572018160755

Epoch: 6| Step: 1
Training loss: 0.7782595047117602
Validation loss: 2.3207972182430914

Epoch: 6| Step: 2
Training loss: 0.8469658778229564
Validation loss: 2.3759567091119167

Epoch: 6| Step: 3
Training loss: 0.6798775286689721
Validation loss: 2.460810427128448

Epoch: 6| Step: 4
Training loss: 0.7462401720738499
Validation loss: 2.2837412044762746

Epoch: 6| Step: 5
Training loss: 0.900892866486516
Validation loss: 2.2705715845568495

Epoch: 6| Step: 6
Training loss: 0.8388682888321314
Validation loss: 2.4206014184238493

Epoch: 6| Step: 7
Training loss: 0.8224585662423517
Validation loss: 2.2623467410632165

Epoch: 6| Step: 8
Training loss: 0.7496466201506561
Validation loss: 2.286231338281372

Epoch: 6| Step: 9
Training loss: 1.1556788915650122
Validation loss: 2.2881578270952128

Epoch: 6| Step: 10
Training loss: 1.5410886488560003
Validation loss: 2.2276266868361922

Epoch: 6| Step: 11
Training loss: 0.5351802514255928
Validation loss: 2.337499116506207

Epoch: 6| Step: 12
Training loss: 1.1428680834501979
Validation loss: 2.28344075321747

Epoch: 6| Step: 13
Training loss: 0.5567861266454922
Validation loss: 2.2473287757165408

Epoch: 575| Step: 0
Training loss: 1.5616335182919459
Validation loss: 2.393287499888389

Epoch: 6| Step: 1
Training loss: 0.8282175912017368
Validation loss: 2.291125567218187

Epoch: 6| Step: 2
Training loss: 1.0253023236719319
Validation loss: 2.2847166446476783

Epoch: 6| Step: 3
Training loss: 0.8437724287089691
Validation loss: 2.3822234029552822

Epoch: 6| Step: 4
Training loss: 0.7040043736018528
Validation loss: 2.236181631241416

Epoch: 6| Step: 5
Training loss: 0.5038049581285248
Validation loss: 2.2280587586719034

Epoch: 6| Step: 6
Training loss: 0.8727929345494418
Validation loss: 2.3076953835199987

Epoch: 6| Step: 7
Training loss: 0.8837618154467018
Validation loss: 2.2717606825217844

Epoch: 6| Step: 8
Training loss: 0.5758758819122881
Validation loss: 2.2618292843280257

Epoch: 6| Step: 9
Training loss: 0.8198530818000256
Validation loss: 2.3177127614566047

Epoch: 6| Step: 10
Training loss: 0.704727804380462
Validation loss: 2.2803104672459162

Epoch: 6| Step: 11
Training loss: 1.071425145007513
Validation loss: 2.2889784326025193

Epoch: 6| Step: 12
Training loss: 0.9892249445524689
Validation loss: 2.286992092443869

Epoch: 6| Step: 13
Training loss: 0.6799020319027281
Validation loss: 2.2998956603128895

Epoch: 576| Step: 0
Training loss: 0.6652085904619592
Validation loss: 2.331231642622242

Epoch: 6| Step: 1
Training loss: 1.163795440556992
Validation loss: 2.322222408680255

Epoch: 6| Step: 2
Training loss: 0.5546585397816535
Validation loss: 2.222327161519332

Epoch: 6| Step: 3
Training loss: 1.6937237867741006
Validation loss: 2.3244698955200116

Epoch: 6| Step: 4
Training loss: 0.6300319288125342
Validation loss: 2.350182027188109

Epoch: 6| Step: 5
Training loss: 0.726003041783836
Validation loss: 2.2996869744062733

Epoch: 6| Step: 6
Training loss: 0.757228823174582
Validation loss: 2.3406988244134124

Epoch: 6| Step: 7
Training loss: 0.49834992407714657
Validation loss: 2.3042309258217615

Epoch: 6| Step: 8
Training loss: 0.9074479111258716
Validation loss: 2.3037305710912883

Epoch: 6| Step: 9
Training loss: 1.0067919509706897
Validation loss: 2.235026909776601

Epoch: 6| Step: 10
Training loss: 0.5336248106733867
Validation loss: 2.3354069571692837

Epoch: 6| Step: 11
Training loss: 0.8392072172762786
Validation loss: 2.2892690412305186

Epoch: 6| Step: 12
Training loss: 0.6285537537460024
Validation loss: 2.318606466000164

Epoch: 6| Step: 13
Training loss: 1.337342755709195
Validation loss: 2.318300258205059

Epoch: 577| Step: 0
Training loss: 0.5951532546388898
Validation loss: 2.3282365097096025

Epoch: 6| Step: 1
Training loss: 0.961144773877447
Validation loss: 2.301810830927496

Epoch: 6| Step: 2
Training loss: 0.9183113919617961
Validation loss: 2.303162017242943

Epoch: 6| Step: 3
Training loss: 0.926990315060603
Validation loss: 2.3471451831422288

Epoch: 6| Step: 4
Training loss: 0.7584068091571728
Validation loss: 2.259313728160835

Epoch: 6| Step: 5
Training loss: 0.9127924319904709
Validation loss: 2.2632918794814842

Epoch: 6| Step: 6
Training loss: 0.8859054600003209
Validation loss: 2.3082990349800707

Epoch: 6| Step: 7
Training loss: 1.0797560144262672
Validation loss: 2.3208756329557465

Epoch: 6| Step: 8
Training loss: 0.9154699200741371
Validation loss: 2.3801902082240547

Epoch: 6| Step: 9
Training loss: 0.6117524937936254
Validation loss: 2.300738978389766

Epoch: 6| Step: 10
Training loss: 1.5562306322478234
Validation loss: 2.312349705910327

Epoch: 6| Step: 11
Training loss: 0.9008368919107007
Validation loss: 2.260431584406857

Epoch: 6| Step: 12
Training loss: 0.8102033139779015
Validation loss: 2.2757385739927245

Epoch: 6| Step: 13
Training loss: 0.6384572359639239
Validation loss: 2.2597213597412864

Epoch: 578| Step: 0
Training loss: 0.725833650304971
Validation loss: 2.348447624428536

Epoch: 6| Step: 1
Training loss: 0.7202734351167193
Validation loss: 2.3519546214019704

Epoch: 6| Step: 2
Training loss: 1.6072153953046544
Validation loss: 2.290114438844858

Epoch: 6| Step: 3
Training loss: 0.9804851029084796
Validation loss: 2.293850231168554

Epoch: 6| Step: 4
Training loss: 0.721449550744478
Validation loss: 2.368764868300607

Epoch: 6| Step: 5
Training loss: 0.8943965427302006
Validation loss: 2.321368633435393

Epoch: 6| Step: 6
Training loss: 0.7851783787280229
Validation loss: 2.259726972076816

Epoch: 6| Step: 7
Training loss: 0.6974070429642952
Validation loss: 2.3668942059444693

Epoch: 6| Step: 8
Training loss: 0.6766562777889935
Validation loss: 2.347756602655579

Epoch: 6| Step: 9
Training loss: 0.5480635669692211
Validation loss: 2.2683296588709023

Epoch: 6| Step: 10
Training loss: 0.5312078964154204
Validation loss: 2.3713419445912223

Epoch: 6| Step: 11
Training loss: 1.1122669618821863
Validation loss: 2.333140702214161

Epoch: 6| Step: 12
Training loss: 1.2608414661845246
Validation loss: 2.2924899355503876

Epoch: 6| Step: 13
Training loss: 0.6211711907242077
Validation loss: 2.25712058840579

Epoch: 579| Step: 0
Training loss: 0.4892206691873651
Validation loss: 2.28793294660179

Epoch: 6| Step: 1
Training loss: 0.6618766938458923
Validation loss: 2.221741543097727

Epoch: 6| Step: 2
Training loss: 0.7136012467804311
Validation loss: 2.2730373330198277

Epoch: 6| Step: 3
Training loss: 1.7766800867519765
Validation loss: 2.3000699145002095

Epoch: 6| Step: 4
Training loss: 0.8635597987892326
Validation loss: 2.318085204553223

Epoch: 6| Step: 5
Training loss: 0.5284326684190619
Validation loss: 2.268303993269641

Epoch: 6| Step: 6
Training loss: 0.9702208950274456
Validation loss: 2.2745461714550808

Epoch: 6| Step: 7
Training loss: 0.5962313951832567
Validation loss: 2.3036149204519982

Epoch: 6| Step: 8
Training loss: 0.4666334368875242
Validation loss: 2.303532009048439

Epoch: 6| Step: 9
Training loss: 0.9208114437303574
Validation loss: 2.2535700146030893

Epoch: 6| Step: 10
Training loss: 0.6751721454030193
Validation loss: 2.295895628088364

Epoch: 6| Step: 11
Training loss: 0.9925977504551008
Validation loss: 2.365783291164775

Epoch: 6| Step: 12
Training loss: 1.1824332613187263
Validation loss: 2.3217779968674175

Epoch: 6| Step: 13
Training loss: 0.5286931046521297
Validation loss: 2.270309635845944

Epoch: 580| Step: 0
Training loss: 0.4938443618854627
Validation loss: 2.3018334287936906

Epoch: 6| Step: 1
Training loss: 0.6520341606815622
Validation loss: 2.34456851025046

Epoch: 6| Step: 2
Training loss: 0.8518471548297252
Validation loss: 2.2883774968839856

Epoch: 6| Step: 3
Training loss: 0.8884568174276766
Validation loss: 2.3049519243450356

Epoch: 6| Step: 4
Training loss: 0.8247926711612478
Validation loss: 2.277442001435092

Epoch: 6| Step: 5
Training loss: 0.6224761070507281
Validation loss: 2.3150922817711983

Epoch: 6| Step: 6
Training loss: 0.6320699408798677
Validation loss: 2.229727983650836

Epoch: 6| Step: 7
Training loss: 0.6564818835435353
Validation loss: 2.2412016248544155

Epoch: 6| Step: 8
Training loss: 1.6191910573653978
Validation loss: 2.377831410391054

Epoch: 6| Step: 9
Training loss: 0.5538530924137763
Validation loss: 2.334875693192312

Epoch: 6| Step: 10
Training loss: 0.9041308256742423
Validation loss: 2.286304099697638

Epoch: 6| Step: 11
Training loss: 1.1132528736446632
Validation loss: 2.287210849728034

Epoch: 6| Step: 12
Training loss: 0.9004086639517044
Validation loss: 2.257350245979526

Epoch: 6| Step: 13
Training loss: 0.3541663277381322
Validation loss: 2.256670866214817

Epoch: 581| Step: 0
Training loss: 0.6376188504001589
Validation loss: 2.311046327053348

Epoch: 6| Step: 1
Training loss: 0.8780169247405886
Validation loss: 2.3298843276103063

Epoch: 6| Step: 2
Training loss: 1.04100949856385
Validation loss: 2.3553859256903196

Epoch: 6| Step: 3
Training loss: 0.7179699687096481
Validation loss: 2.3466041496146928

Epoch: 6| Step: 4
Training loss: 0.6092893344624342
Validation loss: 2.318662490765617

Epoch: 6| Step: 5
Training loss: 0.7577067822522732
Validation loss: 2.3231666202746517

Epoch: 6| Step: 6
Training loss: 1.6344557528850507
Validation loss: 2.2635347845300027

Epoch: 6| Step: 7
Training loss: 0.8351251808717872
Validation loss: 2.274140605900818

Epoch: 6| Step: 8
Training loss: 0.618362925092154
Validation loss: 2.2923024799224496

Epoch: 6| Step: 9
Training loss: 0.5868096028576483
Validation loss: 2.364346839910769

Epoch: 6| Step: 10
Training loss: 0.7978564184034068
Validation loss: 2.2734844435635715

Epoch: 6| Step: 11
Training loss: 0.6053595413654007
Validation loss: 2.1958868304347807

Epoch: 6| Step: 12
Training loss: 0.8389333003928782
Validation loss: 2.282721772779199

Epoch: 6| Step: 13
Training loss: 0.6382040007406973
Validation loss: 2.3367544549524197

Epoch: 582| Step: 0
Training loss: 0.7795406715495051
Validation loss: 2.305278565879998

Epoch: 6| Step: 1
Training loss: 0.8379536496092327
Validation loss: 2.3091251676478017

Epoch: 6| Step: 2
Training loss: 0.9009087451655599
Validation loss: 2.2287245380879463

Epoch: 6| Step: 3
Training loss: 0.710013155479516
Validation loss: 2.285615451202402

Epoch: 6| Step: 4
Training loss: 0.6331861829050223
Validation loss: 2.389987392437335

Epoch: 6| Step: 5
Training loss: 0.7788474716001487
Validation loss: 2.3556998622846983

Epoch: 6| Step: 6
Training loss: 1.0954708730393854
Validation loss: 2.421218273874391

Epoch: 6| Step: 7
Training loss: 1.5903005482664365
Validation loss: 2.3032287909094116

Epoch: 6| Step: 8
Training loss: 0.612234059812833
Validation loss: 2.3196081962089905

Epoch: 6| Step: 9
Training loss: 0.7657360074280819
Validation loss: 2.294988806871491

Epoch: 6| Step: 10
Training loss: 0.6629770720474486
Validation loss: 2.324820598835214

Epoch: 6| Step: 11
Training loss: 0.828017749679057
Validation loss: 2.2995004533212056

Epoch: 6| Step: 12
Training loss: 0.730886166691636
Validation loss: 2.3278366634879886

Epoch: 6| Step: 13
Training loss: 0.9844555292038857
Validation loss: 2.2540680491754346

Epoch: 583| Step: 0
Training loss: 0.808462012427693
Validation loss: 2.3029200814489723

Epoch: 6| Step: 1
Training loss: 1.0230465207676458
Validation loss: 2.296497647979002

Epoch: 6| Step: 2
Training loss: 0.8668485442994756
Validation loss: 2.338938287916551

Epoch: 6| Step: 3
Training loss: 0.9026786215850743
Validation loss: 2.2266799184814303

Epoch: 6| Step: 4
Training loss: 0.4532063838616018
Validation loss: 2.290457504038449

Epoch: 6| Step: 5
Training loss: 0.7018695643580521
Validation loss: 2.2951240604436194

Epoch: 6| Step: 6
Training loss: 0.6578904493091812
Validation loss: 2.304989530260946

Epoch: 6| Step: 7
Training loss: 0.8467454367763302
Validation loss: 2.3130970111915836

Epoch: 6| Step: 8
Training loss: 0.7904995965829938
Validation loss: 2.300206426293674

Epoch: 6| Step: 9
Training loss: 0.84728264376061
Validation loss: 2.317215300150049

Epoch: 6| Step: 10
Training loss: 0.9438850723010069
Validation loss: 2.2726648983734976

Epoch: 6| Step: 11
Training loss: 0.7037596275728049
Validation loss: 2.353700203019535

Epoch: 6| Step: 12
Training loss: 1.6085694898987137
Validation loss: 2.3327442396438123

Epoch: 6| Step: 13
Training loss: 0.7769703183733854
Validation loss: 2.276027436574589

Epoch: 584| Step: 0
Training loss: 0.7797684927481456
Validation loss: 2.2980948021787637

Epoch: 6| Step: 1
Training loss: 0.6853877912736938
Validation loss: 2.348017407773659

Epoch: 6| Step: 2
Training loss: 1.0390014630510238
Validation loss: 2.2924539669805846

Epoch: 6| Step: 3
Training loss: 0.7185541383658756
Validation loss: 2.355220235134057

Epoch: 6| Step: 4
Training loss: 0.7632163950484662
Validation loss: 2.2430695596038497

Epoch: 6| Step: 5
Training loss: 0.5864890999004696
Validation loss: 2.3277938540096215

Epoch: 6| Step: 6
Training loss: 1.0479828964650444
Validation loss: 2.3118141928928644

Epoch: 6| Step: 7
Training loss: 0.8570476575617912
Validation loss: 2.2974180196750424

Epoch: 6| Step: 8
Training loss: 0.7642102697350781
Validation loss: 2.292718568629301

Epoch: 6| Step: 9
Training loss: 0.8884981090308715
Validation loss: 2.346090844042988

Epoch: 6| Step: 10
Training loss: 0.8922348196972726
Validation loss: 2.28100919330503

Epoch: 6| Step: 11
Training loss: 0.8297814411207215
Validation loss: 2.307798178126641

Epoch: 6| Step: 12
Training loss: 1.6395334881674823
Validation loss: 2.3654208906022123

Epoch: 6| Step: 13
Training loss: 0.33310491091576094
Validation loss: 2.385287875198525

Epoch: 585| Step: 0
Training loss: 0.8375265401933597
Validation loss: 2.2828195369802042

Epoch: 6| Step: 1
Training loss: 0.5341139897703248
Validation loss: 2.338459044036832

Epoch: 6| Step: 2
Training loss: 0.7171934937868667
Validation loss: 2.313993897679649

Epoch: 6| Step: 3
Training loss: 0.5127832246521872
Validation loss: 2.2891473516075256

Epoch: 6| Step: 4
Training loss: 0.7266344424490117
Validation loss: 2.2466013282345645

Epoch: 6| Step: 5
Training loss: 1.7336842304013114
Validation loss: 2.1773540108552045

Epoch: 6| Step: 6
Training loss: 0.6141027306343646
Validation loss: 2.3942289436771786

Epoch: 6| Step: 7
Training loss: 0.6272908189612212
Validation loss: 2.285150551471138

Epoch: 6| Step: 8
Training loss: 1.14136972022953
Validation loss: 2.280280644052616

Epoch: 6| Step: 9
Training loss: 0.9341623019531353
Validation loss: 2.3701138630420107

Epoch: 6| Step: 10
Training loss: 0.5755937164785462
Validation loss: 2.349111009394535

Epoch: 6| Step: 11
Training loss: 0.5569031481152639
Validation loss: 2.3121946499634545

Epoch: 6| Step: 12
Training loss: 0.7979076650591496
Validation loss: 2.3427221164899685

Epoch: 6| Step: 13
Training loss: 0.5200841729189385
Validation loss: 2.2624287578375744

Epoch: 586| Step: 0
Training loss: 0.8740062520133077
Validation loss: 2.352227191701468

Epoch: 6| Step: 1
Training loss: 0.9841443654493713
Validation loss: 2.2845110968117552

Epoch: 6| Step: 2
Training loss: 0.7765194533638446
Validation loss: 2.271535931992308

Epoch: 6| Step: 3
Training loss: 0.698338257909571
Validation loss: 2.3217409576977106

Epoch: 6| Step: 4
Training loss: 0.665584077606925
Validation loss: 2.331702945673306

Epoch: 6| Step: 5
Training loss: 1.6390032791188682
Validation loss: 2.2529018533782867

Epoch: 6| Step: 6
Training loss: 0.5245667134177912
Validation loss: 2.224590406409272

Epoch: 6| Step: 7
Training loss: 0.7855311016090667
Validation loss: 2.255120136118649

Epoch: 6| Step: 8
Training loss: 1.0439117968668408
Validation loss: 2.3101968712103473

Epoch: 6| Step: 9
Training loss: 0.7594286409121431
Validation loss: 2.3041856823226134

Epoch: 6| Step: 10
Training loss: 0.6858306036794796
Validation loss: 2.3130006711009656

Epoch: 6| Step: 11
Training loss: 0.6594091397527619
Validation loss: 2.3445544201642248

Epoch: 6| Step: 12
Training loss: 0.6659457486096926
Validation loss: 2.305381353155538

Epoch: 6| Step: 13
Training loss: 0.734104147127922
Validation loss: 2.3113611383039188

Epoch: 587| Step: 0
Training loss: 0.8024331894512262
Validation loss: 2.2665606017046738

Epoch: 6| Step: 1
Training loss: 0.9399605568260149
Validation loss: 2.2869984897885263

Epoch: 6| Step: 2
Training loss: 1.0739664787232721
Validation loss: 2.2225377440347325

Epoch: 6| Step: 3
Training loss: 0.4527592991969777
Validation loss: 2.298874050483914

Epoch: 6| Step: 4
Training loss: 0.6401782455185089
Validation loss: 2.2582321642755994

Epoch: 6| Step: 5
Training loss: 0.6982687351541922
Validation loss: 2.272718082807462

Epoch: 6| Step: 6
Training loss: 0.7934317153413297
Validation loss: 2.32017005706092

Epoch: 6| Step: 7
Training loss: 0.7466556370579022
Validation loss: 2.2842288872651695

Epoch: 6| Step: 8
Training loss: 0.8050701379726856
Validation loss: 2.314569402622339

Epoch: 6| Step: 9
Training loss: 1.022209887211317
Validation loss: 2.2995525717183694

Epoch: 6| Step: 10
Training loss: 0.8293645686490397
Validation loss: 2.24857089188505

Epoch: 6| Step: 11
Training loss: 1.6509360230479149
Validation loss: 2.3299608663787943

Epoch: 6| Step: 12
Training loss: 0.4703874122802623
Validation loss: 2.196705105804207

Epoch: 6| Step: 13
Training loss: 0.8838564009330053
Validation loss: 2.2966451077113383

Epoch: 588| Step: 0
Training loss: 0.5997333709046089
Validation loss: 2.3392498360919256

Epoch: 6| Step: 1
Training loss: 0.6759113781837783
Validation loss: 2.2819934273605065

Epoch: 6| Step: 2
Training loss: 0.885851162533364
Validation loss: 2.205763098523091

Epoch: 6| Step: 3
Training loss: 1.551654329684526
Validation loss: 2.2583507468680555

Epoch: 6| Step: 4
Training loss: 0.8449881264456182
Validation loss: 2.2979303016875763

Epoch: 6| Step: 5
Training loss: 0.8623055169694481
Validation loss: 2.28375276318523

Epoch: 6| Step: 6
Training loss: 0.9697703248874068
Validation loss: 2.295827191724309

Epoch: 6| Step: 7
Training loss: 0.6224308615900378
Validation loss: 2.2981169608078216

Epoch: 6| Step: 8
Training loss: 0.9071107262777176
Validation loss: 2.2898174002730753

Epoch: 6| Step: 9
Training loss: 0.5733846718051631
Validation loss: 2.3151190132877524

Epoch: 6| Step: 10
Training loss: 0.9163247178695969
Validation loss: 2.340316412187623

Epoch: 6| Step: 11
Training loss: 0.8960708628544474
Validation loss: 2.2840456080750586

Epoch: 6| Step: 12
Training loss: 1.0295261077127171
Validation loss: 2.3043729500362184

Epoch: 6| Step: 13
Training loss: 0.5939082888372763
Validation loss: 2.3321620968832693

Epoch: 589| Step: 0
Training loss: 0.5680982376526563
Validation loss: 2.2461263440778034

Epoch: 6| Step: 1
Training loss: 0.9754664259098785
Validation loss: 2.2649823197685257

Epoch: 6| Step: 2
Training loss: 0.6491531651096301
Validation loss: 2.321862317586144

Epoch: 6| Step: 3
Training loss: 0.928664309577616
Validation loss: 2.2725467880101795

Epoch: 6| Step: 4
Training loss: 0.786955371112358
Validation loss: 2.2775975351212288

Epoch: 6| Step: 5
Training loss: 1.014303315756372
Validation loss: 2.2989960404045235

Epoch: 6| Step: 6
Training loss: 0.8665457060349344
Validation loss: 2.3028777077184626

Epoch: 6| Step: 7
Training loss: 0.8047032771369359
Validation loss: 2.2873172649589626

Epoch: 6| Step: 8
Training loss: 0.7394179620458092
Validation loss: 2.263122000863183

Epoch: 6| Step: 9
Training loss: 1.587792049787544
Validation loss: 2.3607730201977466

Epoch: 6| Step: 10
Training loss: 0.9257378547895756
Validation loss: 2.3754102550109333

Epoch: 6| Step: 11
Training loss: 0.731153850265995
Validation loss: 2.3432983422653186

Epoch: 6| Step: 12
Training loss: 0.8905776831120841
Validation loss: 2.293646788339189

Epoch: 6| Step: 13
Training loss: 0.7754802507926987
Validation loss: 2.3330813237381554

Epoch: 590| Step: 0
Training loss: 1.0540187834996841
Validation loss: 2.2703022700422983

Epoch: 6| Step: 1
Training loss: 0.5281968739374828
Validation loss: 2.2710884186540845

Epoch: 6| Step: 2
Training loss: 1.0131877117762698
Validation loss: 2.2081804363824644

Epoch: 6| Step: 3
Training loss: 0.5805155585041541
Validation loss: 2.368008236060499

Epoch: 6| Step: 4
Training loss: 0.7095999239290405
Validation loss: 2.3252213892799443

Epoch: 6| Step: 5
Training loss: 0.8533674238021474
Validation loss: 2.3244552402370076

Epoch: 6| Step: 6
Training loss: 0.7815746395811011
Validation loss: 2.290508144855012

Epoch: 6| Step: 7
Training loss: 1.4998769709678026
Validation loss: 2.2531856524434835

Epoch: 6| Step: 8
Training loss: 0.5189678320774082
Validation loss: 2.26703183318383

Epoch: 6| Step: 9
Training loss: 0.7857152362916819
Validation loss: 2.35926703695212

Epoch: 6| Step: 10
Training loss: 0.8553568797362822
Validation loss: 2.264332641391227

Epoch: 6| Step: 11
Training loss: 0.8128416370183847
Validation loss: 2.2992952732437835

Epoch: 6| Step: 12
Training loss: 0.7737909145353281
Validation loss: 2.3480534909075685

Epoch: 6| Step: 13
Training loss: 0.7327955183001447
Validation loss: 2.1987140280127457

Epoch: 591| Step: 0
Training loss: 0.7298761912089703
Validation loss: 2.223098527198333

Epoch: 6| Step: 1
Training loss: 0.8398771412443585
Validation loss: 2.317070648710191

Epoch: 6| Step: 2
Training loss: 0.870523342980871
Validation loss: 2.296120477341834

Epoch: 6| Step: 3
Training loss: 0.43409864567648865
Validation loss: 2.302704131930742

Epoch: 6| Step: 4
Training loss: 0.7213827097693447
Validation loss: 2.193477880718887

Epoch: 6| Step: 5
Training loss: 0.6412036654814969
Validation loss: 2.2833596292785

Epoch: 6| Step: 6
Training loss: 0.842169269937729
Validation loss: 2.2754033767460475

Epoch: 6| Step: 7
Training loss: 0.49427062424178636
Validation loss: 2.347322828893907

Epoch: 6| Step: 8
Training loss: 1.624107262334188
Validation loss: 2.263743321930921

Epoch: 6| Step: 9
Training loss: 0.8224685672214974
Validation loss: 2.3181434929820948

Epoch: 6| Step: 10
Training loss: 0.9227155958659131
Validation loss: 2.305732302515782

Epoch: 6| Step: 11
Training loss: 0.6990048171806523
Validation loss: 2.299269325004756

Epoch: 6| Step: 12
Training loss: 0.5208017403239517
Validation loss: 2.2298676198833394

Epoch: 6| Step: 13
Training loss: 0.9842614910742659
Validation loss: 2.3143878581938715

Epoch: 592| Step: 0
Training loss: 1.0150855759310728
Validation loss: 2.276604239878817

Epoch: 6| Step: 1
Training loss: 0.7425260875755717
Validation loss: 2.299429581710419

Epoch: 6| Step: 2
Training loss: 0.5644297875460462
Validation loss: 2.289830356050905

Epoch: 6| Step: 3
Training loss: 1.5789886981591048
Validation loss: 2.3044872499361437

Epoch: 6| Step: 4
Training loss: 0.9546740404544415
Validation loss: 2.3284542497580105

Epoch: 6| Step: 5
Training loss: 0.7979556964727585
Validation loss: 2.25113103780209

Epoch: 6| Step: 6
Training loss: 0.7283537738588365
Validation loss: 2.309642041188279

Epoch: 6| Step: 7
Training loss: 0.6661284678335435
Validation loss: 2.2995435498317662

Epoch: 6| Step: 8
Training loss: 0.707322624401722
Validation loss: 2.233815282626119

Epoch: 6| Step: 9
Training loss: 0.8052397749381016
Validation loss: 2.315460530527505

Epoch: 6| Step: 10
Training loss: 0.43484867053412607
Validation loss: 2.3015811698946127

Epoch: 6| Step: 11
Training loss: 0.973932983286128
Validation loss: 2.28829024219107

Epoch: 6| Step: 12
Training loss: 0.8711831769671091
Validation loss: 2.318128045684801

Epoch: 6| Step: 13
Training loss: 0.6135879527207404
Validation loss: 2.310773943094493

Epoch: 593| Step: 0
Training loss: 0.7797165890085384
Validation loss: 2.308835862968433

Epoch: 6| Step: 1
Training loss: 0.4576080627443431
Validation loss: 2.25176607913411

Epoch: 6| Step: 2
Training loss: 0.5288837974662348
Validation loss: 2.311248552644967

Epoch: 6| Step: 3
Training loss: 0.9843722752124677
Validation loss: 2.2417444311092667

Epoch: 6| Step: 4
Training loss: 0.916392559915126
Validation loss: 2.3328077054589023

Epoch: 6| Step: 5
Training loss: 0.7159034503780619
Validation loss: 2.2433560338392673

Epoch: 6| Step: 6
Training loss: 0.6155079551232273
Validation loss: 2.2592048562914395

Epoch: 6| Step: 7
Training loss: 1.665504511327483
Validation loss: 2.331276106111592

Epoch: 6| Step: 8
Training loss: 0.6121390816905475
Validation loss: 2.326611810234915

Epoch: 6| Step: 9
Training loss: 0.7269468623921076
Validation loss: 2.3332659042155175

Epoch: 6| Step: 10
Training loss: 0.8664653623760085
Validation loss: 2.2765431041238826

Epoch: 6| Step: 11
Training loss: 0.9872517708351712
Validation loss: 2.213101989587735

Epoch: 6| Step: 12
Training loss: 0.39887249332717445
Validation loss: 2.318518471420062

Epoch: 6| Step: 13
Training loss: 0.4544659372969388
Validation loss: 2.2297055374481647

Epoch: 594| Step: 0
Training loss: 0.8378680744115407
Validation loss: 2.123067110070514

Epoch: 6| Step: 1
Training loss: 0.7462299082877218
Validation loss: 2.2383290522871495

Epoch: 6| Step: 2
Training loss: 0.7383959645759274
Validation loss: 2.3116769501094154

Epoch: 6| Step: 3
Training loss: 0.6542907259068563
Validation loss: 2.2553136627086916

Epoch: 6| Step: 4
Training loss: 0.6787978960494107
Validation loss: 2.249158141175448

Epoch: 6| Step: 5
Training loss: 0.529375499783655
Validation loss: 2.2832751194906105

Epoch: 6| Step: 6
Training loss: 0.5428151249533846
Validation loss: 2.2768856672710007

Epoch: 6| Step: 7
Training loss: 0.7974030110447056
Validation loss: 2.265849123948715

Epoch: 6| Step: 8
Training loss: 1.5198652591714756
Validation loss: 2.3171469579702553

Epoch: 6| Step: 9
Training loss: 0.8345448310402633
Validation loss: 2.400548594466917

Epoch: 6| Step: 10
Training loss: 0.8937554472643904
Validation loss: 2.3750622735227567

Epoch: 6| Step: 11
Training loss: 0.7149633505571619
Validation loss: 2.305368887326757

Epoch: 6| Step: 12
Training loss: 0.8224296496837247
Validation loss: 2.3372083370439403

Epoch: 6| Step: 13
Training loss: 0.9604323385177779
Validation loss: 2.290722862294959

Epoch: 595| Step: 0
Training loss: 0.7989396667952431
Validation loss: 2.3176273639210323

Epoch: 6| Step: 1
Training loss: 0.9445262823613163
Validation loss: 2.2459950997266427

Epoch: 6| Step: 2
Training loss: 0.4572129499714017
Validation loss: 2.2790180075105804

Epoch: 6| Step: 3
Training loss: 1.1391728184237875
Validation loss: 2.2953110963209844

Epoch: 6| Step: 4
Training loss: 0.6135053771792969
Validation loss: 2.2892219442848623

Epoch: 6| Step: 5
Training loss: 0.6249045060637963
Validation loss: 2.329834527261772

Epoch: 6| Step: 6
Training loss: 1.591865772090266
Validation loss: 2.275460675347064

Epoch: 6| Step: 7
Training loss: 0.821175294088149
Validation loss: 2.4052584165465705

Epoch: 6| Step: 8
Training loss: 0.5067810734507835
Validation loss: 2.292721809911568

Epoch: 6| Step: 9
Training loss: 0.9540856320038081
Validation loss: 2.3185463061865073

Epoch: 6| Step: 10
Training loss: 0.8255197823855733
Validation loss: 2.3283993227047057

Epoch: 6| Step: 11
Training loss: 0.7538306242808176
Validation loss: 2.300577299056315

Epoch: 6| Step: 12
Training loss: 0.7282814283520117
Validation loss: 2.346878320083639

Epoch: 6| Step: 13
Training loss: 0.7919138012346849
Validation loss: 2.254544791951009

Epoch: 596| Step: 0
Training loss: 0.7408547733095185
Validation loss: 2.269253615005976

Epoch: 6| Step: 1
Training loss: 0.7831818917837547
Validation loss: 2.2730894356172544

Epoch: 6| Step: 2
Training loss: 0.8899188672278546
Validation loss: 2.3480508579935897

Epoch: 6| Step: 3
Training loss: 0.5965465390851319
Validation loss: 2.361398291289413

Epoch: 6| Step: 4
Training loss: 1.0109375990524125
Validation loss: 2.3404351170763618

Epoch: 6| Step: 5
Training loss: 0.6808549785636214
Validation loss: 2.2883580040790648

Epoch: 6| Step: 6
Training loss: 0.34936196081092663
Validation loss: 2.3299195648483644

Epoch: 6| Step: 7
Training loss: 0.6429034629853709
Validation loss: 2.2891523934399887

Epoch: 6| Step: 8
Training loss: 1.0337460106584726
Validation loss: 2.3223994638660286

Epoch: 6| Step: 9
Training loss: 1.6153939294022552
Validation loss: 2.2615426709965147

Epoch: 6| Step: 10
Training loss: 0.5885740344393948
Validation loss: 2.285704007552297

Epoch: 6| Step: 11
Training loss: 0.7229030703128103
Validation loss: 2.2049571721239962

Epoch: 6| Step: 12
Training loss: 0.7964574430438937
Validation loss: 2.188856314400478

Epoch: 6| Step: 13
Training loss: 0.6765691100539878
Validation loss: 2.3470250546652247

Epoch: 597| Step: 0
Training loss: 0.7272103405469053
Validation loss: 2.233186154971537

Epoch: 6| Step: 1
Training loss: 0.6556169771952728
Validation loss: 2.332936782437955

Epoch: 6| Step: 2
Training loss: 0.7068141372072075
Validation loss: 2.29329973542425

Epoch: 6| Step: 3
Training loss: 1.0316203637175503
Validation loss: 2.2477793126049175

Epoch: 6| Step: 4
Training loss: 0.7721755782302785
Validation loss: 2.252519335913764

Epoch: 6| Step: 5
Training loss: 0.49929294661634516
Validation loss: 2.266169716851491

Epoch: 6| Step: 6
Training loss: 0.9382870231660443
Validation loss: 2.1540135905119406

Epoch: 6| Step: 7
Training loss: 0.9638595194255519
Validation loss: 2.3244399319408626

Epoch: 6| Step: 8
Training loss: 1.614589280968653
Validation loss: 2.2285686338971273

Epoch: 6| Step: 9
Training loss: 0.9451079344291567
Validation loss: 2.2912944538038458

Epoch: 6| Step: 10
Training loss: 0.8965193465315985
Validation loss: 2.375492580262254

Epoch: 6| Step: 11
Training loss: 0.6557559924184547
Validation loss: 2.2743224457854097

Epoch: 6| Step: 12
Training loss: 0.7885255402932122
Validation loss: 2.3293863400466654

Epoch: 6| Step: 13
Training loss: 0.5246921704046378
Validation loss: 2.223045747090812

Epoch: 598| Step: 0
Training loss: 0.8018184736491537
Validation loss: 2.264306265318727

Epoch: 6| Step: 1
Training loss: 0.5777020324774288
Validation loss: 2.2792824882690668

Epoch: 6| Step: 2
Training loss: 0.9247150961834121
Validation loss: 2.2770336843921313

Epoch: 6| Step: 3
Training loss: 0.8854421424940581
Validation loss: 2.302223704270777

Epoch: 6| Step: 4
Training loss: 1.152182564534728
Validation loss: 2.2190800550872813

Epoch: 6| Step: 5
Training loss: 1.5873323517232523
Validation loss: 2.16114571410057

Epoch: 6| Step: 6
Training loss: 0.6133538950275784
Validation loss: 2.273505637199312

Epoch: 6| Step: 7
Training loss: 0.8391183603684089
Validation loss: 2.31671171220548

Epoch: 6| Step: 8
Training loss: 0.6155228195980412
Validation loss: 2.2767084472759325

Epoch: 6| Step: 9
Training loss: 0.6844563300871179
Validation loss: 2.3228760663374777

Epoch: 6| Step: 10
Training loss: 0.8957843915004928
Validation loss: 2.3300707930020335

Epoch: 6| Step: 11
Training loss: 0.8745641303956753
Validation loss: 2.298561457590566

Epoch: 6| Step: 12
Training loss: 0.6412675937670607
Validation loss: 2.267806565291155

Epoch: 6| Step: 13
Training loss: 0.5921383115122956
Validation loss: 2.2504607393155407

Epoch: 599| Step: 0
Training loss: 0.7675249697695953
Validation loss: 2.311325020294186

Epoch: 6| Step: 1
Training loss: 0.5675848438681754
Validation loss: 2.3356287304225822

Epoch: 6| Step: 2
Training loss: 0.7483156682444982
Validation loss: 2.407192101731434

Epoch: 6| Step: 3
Training loss: 0.8850135708431126
Validation loss: 2.365156934527591

Epoch: 6| Step: 4
Training loss: 0.55986510495578
Validation loss: 2.3407803136659404

Epoch: 6| Step: 5
Training loss: 0.7305232552985444
Validation loss: 2.288697064018294

Epoch: 6| Step: 6
Training loss: 0.7916019480168072
Validation loss: 2.298682429692029

Epoch: 6| Step: 7
Training loss: 0.6017156628906177
Validation loss: 2.3222343885472148

Epoch: 6| Step: 8
Training loss: 0.8790857428479337
Validation loss: 2.3263781101656864

Epoch: 6| Step: 9
Training loss: 0.6265947500096003
Validation loss: 2.2797424880150237

Epoch: 6| Step: 10
Training loss: 1.7080119303614956
Validation loss: 2.2286739243711997

Epoch: 6| Step: 11
Training loss: 0.49321965574650134
Validation loss: 2.3757205975288036

Epoch: 6| Step: 12
Training loss: 0.5911027217610657
Validation loss: 2.209222427309786

Epoch: 6| Step: 13
Training loss: 0.6591147609807416
Validation loss: 2.3209257061703448

Epoch: 600| Step: 0
Training loss: 1.7486368046977772
Validation loss: 2.263996146094486

Epoch: 6| Step: 1
Training loss: 0.7082110935274174
Validation loss: 2.2645295478895457

Epoch: 6| Step: 2
Training loss: 0.652225003884619
Validation loss: 2.3105675622520896

Epoch: 6| Step: 3
Training loss: 0.6848854286554222
Validation loss: 2.301724287624069

Epoch: 6| Step: 4
Training loss: 0.8507409288503993
Validation loss: 2.3292392008900418

Epoch: 6| Step: 5
Training loss: 0.8161869758471655
Validation loss: 2.2883215792923286

Epoch: 6| Step: 6
Training loss: 0.6160260632004927
Validation loss: 2.264254480868815

Epoch: 6| Step: 7
Training loss: 0.8064413494179952
Validation loss: 2.346260392247211

Epoch: 6| Step: 8
Training loss: 0.5883801725381861
Validation loss: 2.333174028393368

Epoch: 6| Step: 9
Training loss: 0.8518662916985211
Validation loss: 2.3277800357350906

Epoch: 6| Step: 10
Training loss: 0.5930944136198739
Validation loss: 2.2431012758768425

Epoch: 6| Step: 11
Training loss: 0.9092844442787416
Validation loss: 2.394368597545172

Epoch: 6| Step: 12
Training loss: 0.8199319592601341
Validation loss: 2.3206299446255905

Epoch: 6| Step: 13
Training loss: 0.8222343094541572
Validation loss: 2.253323705328568

Testing loss: 3.0448089176280475
