Epoch: 1| Step: 0
Training loss: 5.326682090759277
Validation loss: 5.672301559038059

Epoch: 6| Step: 1
Training loss: 4.4778876304626465
Validation loss: 5.666346206459948

Epoch: 6| Step: 2
Training loss: 4.9836835861206055
Validation loss: 5.662610284743771

Epoch: 6| Step: 3
Training loss: 5.457162857055664
Validation loss: 5.6544124593016925

Epoch: 6| Step: 4
Training loss: 4.836279392242432
Validation loss: 5.648852502146075

Epoch: 6| Step: 5
Training loss: 5.040417194366455
Validation loss: 5.64356461391654

Epoch: 6| Step: 6
Training loss: 5.01217794418335
Validation loss: 5.638715349217897

Epoch: 6| Step: 7
Training loss: 6.097140312194824
Validation loss: 5.629624720542662

Epoch: 6| Step: 8
Training loss: 5.249361991882324
Validation loss: 5.624057474956717

Epoch: 6| Step: 9
Training loss: 5.880048751831055
Validation loss: 5.616665245384298

Epoch: 6| Step: 10
Training loss: 5.718748092651367
Validation loss: 5.613074451364497

Epoch: 6| Step: 11
Training loss: 5.478072643280029
Validation loss: 5.6082215052779

Epoch: 6| Step: 12
Training loss: 5.378137588500977
Validation loss: 5.603797610088061

Epoch: 6| Step: 13
Training loss: 8.429102897644043
Validation loss: 5.595143041303081

Epoch: 2| Step: 0
Training loss: 6.8285298347473145
Validation loss: 5.588377809011808

Epoch: 6| Step: 1
Training loss: 6.392333984375
Validation loss: 5.583917607543289

Epoch: 6| Step: 2
Training loss: 4.4568023681640625
Validation loss: 5.575827501153433

Epoch: 6| Step: 3
Training loss: 4.832653522491455
Validation loss: 5.570831647483251

Epoch: 6| Step: 4
Training loss: 5.099635601043701
Validation loss: 5.565027134392851

Epoch: 6| Step: 5
Training loss: 4.756555557250977
Validation loss: 5.558050396621868

Epoch: 6| Step: 6
Training loss: 5.787770748138428
Validation loss: 5.550736396543441

Epoch: 6| Step: 7
Training loss: 5.728940963745117
Validation loss: 5.545413694074077

Epoch: 6| Step: 8
Training loss: 4.711016654968262
Validation loss: 5.537958237432664

Epoch: 6| Step: 9
Training loss: 6.149825096130371
Validation loss: 5.531490725855673

Epoch: 6| Step: 10
Training loss: 4.558313369750977
Validation loss: 5.522068341573079

Epoch: 6| Step: 11
Training loss: 5.4252824783325195
Validation loss: 5.518471256379159

Epoch: 6| Step: 12
Training loss: 5.568367958068848
Validation loss: 5.5112614580380015

Epoch: 6| Step: 13
Training loss: 3.9101667404174805
Validation loss: 5.505295599660566

Epoch: 3| Step: 0
Training loss: 4.541370391845703
Validation loss: 5.497196710237893

Epoch: 6| Step: 1
Training loss: 4.241679668426514
Validation loss: 5.49156048477337

Epoch: 6| Step: 2
Training loss: 6.141546726226807
Validation loss: 5.4845171846369265

Epoch: 6| Step: 3
Training loss: 6.552886009216309
Validation loss: 5.476854498668383

Epoch: 6| Step: 4
Training loss: 5.446417808532715
Validation loss: 5.468635779555126

Epoch: 6| Step: 5
Training loss: 5.626132011413574
Validation loss: 5.463429461243332

Epoch: 6| Step: 6
Training loss: 5.939720153808594
Validation loss: 5.4563447788197506

Epoch: 6| Step: 7
Training loss: 4.382833003997803
Validation loss: 5.448880534018239

Epoch: 6| Step: 8
Training loss: 6.361482620239258
Validation loss: 5.438546144834128

Epoch: 6| Step: 9
Training loss: 5.044592380523682
Validation loss: 5.435712409275834

Epoch: 6| Step: 10
Training loss: 4.875359535217285
Validation loss: 5.42440757443828

Epoch: 6| Step: 11
Training loss: 4.653171539306641
Validation loss: 5.419045817467474

Epoch: 6| Step: 12
Training loss: 3.8473546504974365
Validation loss: 5.4110009080620225

Epoch: 6| Step: 13
Training loss: 6.205695152282715
Validation loss: 5.402728039731262

Epoch: 4| Step: 0
Training loss: 6.175271034240723
Validation loss: 5.394021464932349

Epoch: 6| Step: 1
Training loss: 6.146690368652344
Validation loss: 5.387082751079272

Epoch: 6| Step: 2
Training loss: 5.302783012390137
Validation loss: 5.379222910891297

Epoch: 6| Step: 3
Training loss: 4.988044738769531
Validation loss: 5.373743088014664

Epoch: 6| Step: 4
Training loss: 4.668374061584473
Validation loss: 5.366396442536385

Epoch: 6| Step: 5
Training loss: 5.73760986328125
Validation loss: 5.357492816063665

Epoch: 6| Step: 6
Training loss: 4.240230560302734
Validation loss: 5.3511666585040345

Epoch: 6| Step: 7
Training loss: 5.575335502624512
Validation loss: 5.343889554341634

Epoch: 6| Step: 8
Training loss: 4.196117877960205
Validation loss: 5.335335910961192

Epoch: 6| Step: 9
Training loss: 5.008846282958984
Validation loss: 5.326738977944979

Epoch: 6| Step: 10
Training loss: 5.487669944763184
Validation loss: 5.316369072083504

Epoch: 6| Step: 11
Training loss: 4.774174690246582
Validation loss: 5.312969212890954

Epoch: 6| Step: 12
Training loss: 5.018307209014893
Validation loss: 5.303933974235289

Epoch: 6| Step: 13
Training loss: 4.220526218414307
Validation loss: 5.293592970858338

Epoch: 5| Step: 0
Training loss: 5.159952163696289
Validation loss: 5.286443428326678

Epoch: 6| Step: 1
Training loss: 5.22164249420166
Validation loss: 5.280607746493432

Epoch: 6| Step: 2
Training loss: 4.02287483215332
Validation loss: 5.271505894199494

Epoch: 6| Step: 3
Training loss: 3.9733054637908936
Validation loss: 5.2629775078065935

Epoch: 6| Step: 4
Training loss: 5.409379005432129
Validation loss: 5.255182481581165

Epoch: 6| Step: 5
Training loss: 5.406806945800781
Validation loss: 5.245864652818249

Epoch: 6| Step: 6
Training loss: 4.422611236572266
Validation loss: 5.237716746586625

Epoch: 6| Step: 7
Training loss: 6.301273345947266
Validation loss: 5.232074758057953

Epoch: 6| Step: 8
Training loss: 6.4816741943359375
Validation loss: 5.223352555305727

Epoch: 6| Step: 9
Training loss: 4.855140686035156
Validation loss: 5.21486065464635

Epoch: 6| Step: 10
Training loss: 4.943621635437012
Validation loss: 5.203129440225581

Epoch: 6| Step: 11
Training loss: 4.755827903747559
Validation loss: 5.195501840242776

Epoch: 6| Step: 12
Training loss: 3.9797251224517822
Validation loss: 5.189380927752423

Epoch: 6| Step: 13
Training loss: 5.67422342300415
Validation loss: 5.174370658013128

Epoch: 6| Step: 0
Training loss: 3.7495899200439453
Validation loss: 5.171405248744513

Epoch: 6| Step: 1
Training loss: 5.758378982543945
Validation loss: 5.159941088768743

Epoch: 6| Step: 2
Training loss: 4.713139533996582
Validation loss: 5.151568233325917

Epoch: 6| Step: 3
Training loss: 4.767762184143066
Validation loss: 5.142489007724229

Epoch: 6| Step: 4
Training loss: 4.822039604187012
Validation loss: 5.133306016204178

Epoch: 6| Step: 5
Training loss: 5.166688442230225
Validation loss: 5.12640747972714

Epoch: 6| Step: 6
Training loss: 5.554335594177246
Validation loss: 5.113407437519361

Epoch: 6| Step: 7
Training loss: 5.422297477722168
Validation loss: 5.10362188277706

Epoch: 6| Step: 8
Training loss: 4.12650203704834
Validation loss: 5.094644905418478

Epoch: 6| Step: 9
Training loss: 4.572824478149414
Validation loss: 5.087681437051424

Epoch: 6| Step: 10
Training loss: 4.434775352478027
Validation loss: 5.076331674411732

Epoch: 6| Step: 11
Training loss: 4.846909523010254
Validation loss: 5.064875382249073

Epoch: 6| Step: 12
Training loss: 6.3831658363342285
Validation loss: 5.054718073978219

Epoch: 6| Step: 13
Training loss: 3.7993404865264893
Validation loss: 5.044068644123692

Epoch: 7| Step: 0
Training loss: 4.214913368225098
Validation loss: 5.03495962901782

Epoch: 6| Step: 1
Training loss: 5.643131732940674
Validation loss: 5.02491057303644

Epoch: 6| Step: 2
Training loss: 4.750985145568848
Validation loss: 5.019452766705585

Epoch: 6| Step: 3
Training loss: 5.737215042114258
Validation loss: 5.008580279606645

Epoch: 6| Step: 4
Training loss: 5.726230621337891
Validation loss: 4.996051103838028

Epoch: 6| Step: 5
Training loss: 4.641499996185303
Validation loss: 4.986603080585438

Epoch: 6| Step: 6
Training loss: 6.227111339569092
Validation loss: 4.974047609554824

Epoch: 6| Step: 7
Training loss: 3.8354077339172363
Validation loss: 4.967855481691258

Epoch: 6| Step: 8
Training loss: 3.8141896724700928
Validation loss: 4.958513639306509

Epoch: 6| Step: 9
Training loss: 4.404721260070801
Validation loss: 4.943050056375483

Epoch: 6| Step: 10
Training loss: 5.030543804168701
Validation loss: 4.934020144965059

Epoch: 6| Step: 11
Training loss: 2.9464712142944336
Validation loss: 4.923535388003113

Epoch: 6| Step: 12
Training loss: 4.561474800109863
Validation loss: 4.909780825338056

Epoch: 6| Step: 13
Training loss: 5.393819332122803
Validation loss: 4.899750719788254

Epoch: 8| Step: 0
Training loss: 4.96240758895874
Validation loss: 4.889732114730343

Epoch: 6| Step: 1
Training loss: 4.716236114501953
Validation loss: 4.874643007914226

Epoch: 6| Step: 2
Training loss: 4.288061141967773
Validation loss: 4.868088024918751

Epoch: 6| Step: 3
Training loss: 3.782824754714966
Validation loss: 4.8525950319023545

Epoch: 6| Step: 4
Training loss: 4.265839099884033
Validation loss: 4.842134567999071

Epoch: 6| Step: 5
Training loss: 4.696983814239502
Validation loss: 4.828587952480521

Epoch: 6| Step: 6
Training loss: 4.543244361877441
Validation loss: 4.819368229117445

Epoch: 6| Step: 7
Training loss: 4.407773971557617
Validation loss: 4.808356454295497

Epoch: 6| Step: 8
Training loss: 5.864462375640869
Validation loss: 4.793244341368316

Epoch: 6| Step: 9
Training loss: 4.651051044464111
Validation loss: 4.780274073282878

Epoch: 6| Step: 10
Training loss: 4.779411315917969
Validation loss: 4.76954448351296

Epoch: 6| Step: 11
Training loss: 5.116687297821045
Validation loss: 4.756987853716779

Epoch: 6| Step: 12
Training loss: 4.066950798034668
Validation loss: 4.742042972195533

Epoch: 6| Step: 13
Training loss: 4.054609298706055
Validation loss: 4.729392687479655

Epoch: 9| Step: 0
Training loss: 3.599839925765991
Validation loss: 4.714360621667677

Epoch: 6| Step: 1
Training loss: 3.612579107284546
Validation loss: 4.705478468248921

Epoch: 6| Step: 2
Training loss: 4.977544784545898
Validation loss: 4.689858559639223

Epoch: 6| Step: 3
Training loss: 3.660330295562744
Validation loss: 4.671677866289692

Epoch: 6| Step: 4
Training loss: 6.207669258117676
Validation loss: 4.663260741900372

Epoch: 6| Step: 5
Training loss: 5.174335479736328
Validation loss: 4.65023930867513

Epoch: 6| Step: 6
Training loss: 4.007317066192627
Validation loss: 4.633454748379287

Epoch: 6| Step: 7
Training loss: 5.205164909362793
Validation loss: 4.620361148670155

Epoch: 6| Step: 8
Training loss: 2.3737845420837402
Validation loss: 4.609055831868162

Epoch: 6| Step: 9
Training loss: 3.370924234390259
Validation loss: 4.5912765636239

Epoch: 6| Step: 10
Training loss: 4.926263332366943
Validation loss: 4.579108392038653

Epoch: 6| Step: 11
Training loss: 5.485872745513916
Validation loss: 4.559125005557973

Epoch: 6| Step: 12
Training loss: 3.958588123321533
Validation loss: 4.545277249428533

Epoch: 6| Step: 13
Training loss: 5.70954704284668
Validation loss: 4.528553978089364

Epoch: 10| Step: 0
Training loss: 5.242824554443359
Validation loss: 4.51754226479479

Epoch: 6| Step: 1
Training loss: 4.671143531799316
Validation loss: 4.497213045756022

Epoch: 6| Step: 2
Training loss: 3.028892993927002
Validation loss: 4.4822465886351885

Epoch: 6| Step: 3
Training loss: 4.6536712646484375
Validation loss: 4.4643173269046255

Epoch: 6| Step: 4
Training loss: 3.7809648513793945
Validation loss: 4.454785546948833

Epoch: 6| Step: 5
Training loss: 4.779515743255615
Validation loss: 4.4324334154846845

Epoch: 6| Step: 6
Training loss: 4.0906267166137695
Validation loss: 4.4200290582513295

Epoch: 6| Step: 7
Training loss: 4.071497440338135
Validation loss: 4.4000567569527576

Epoch: 6| Step: 8
Training loss: 4.273280620574951
Validation loss: 4.387342206893429

Epoch: 6| Step: 9
Training loss: 4.304530143737793
Validation loss: 4.365585765530986

Epoch: 6| Step: 10
Training loss: 4.461538314819336
Validation loss: 4.34537241535802

Epoch: 6| Step: 11
Training loss: 3.9708375930786133
Validation loss: 4.332481948278284

Epoch: 6| Step: 12
Training loss: 3.197014808654785
Validation loss: 4.309729119782807

Epoch: 6| Step: 13
Training loss: 4.166819095611572
Validation loss: 4.293592540166712

Epoch: 11| Step: 0
Training loss: 3.5096070766448975
Validation loss: 4.280683271346554

Epoch: 6| Step: 1
Training loss: 3.3296315670013428
Validation loss: 4.259410509499171

Epoch: 6| Step: 2
Training loss: 4.562487602233887
Validation loss: 4.244543808762745

Epoch: 6| Step: 3
Training loss: 4.3330979347229
Validation loss: 4.220510734024868

Epoch: 6| Step: 4
Training loss: 4.348134994506836
Validation loss: 4.205668336601668

Epoch: 6| Step: 5
Training loss: 3.0345520973205566
Validation loss: 4.191354046585739

Epoch: 6| Step: 6
Training loss: 5.832814693450928
Validation loss: 4.177087286467193

Epoch: 6| Step: 7
Training loss: 3.8014817237854004
Validation loss: 4.154569948873212

Epoch: 6| Step: 8
Training loss: 3.3596208095550537
Validation loss: 4.140677810997091

Epoch: 6| Step: 9
Training loss: 4.00423526763916
Validation loss: 4.118260347714988

Epoch: 6| Step: 10
Training loss: 2.7406022548675537
Validation loss: 4.107342984086724

Epoch: 6| Step: 11
Training loss: 3.839906692504883
Validation loss: 4.0788668176179295

Epoch: 6| Step: 12
Training loss: 4.531461715698242
Validation loss: 4.058886240887386

Epoch: 6| Step: 13
Training loss: 4.50620174407959
Validation loss: 4.0430678398378435

Epoch: 12| Step: 0
Training loss: 3.991328716278076
Validation loss: 4.024924355168497

Epoch: 6| Step: 1
Training loss: 3.4412992000579834
Validation loss: 4.008559473099247

Epoch: 6| Step: 2
Training loss: 3.5659608840942383
Validation loss: 3.9892963594005955

Epoch: 6| Step: 3
Training loss: 3.8118252754211426
Validation loss: 3.9728316286558747

Epoch: 6| Step: 4
Training loss: 3.35176944732666
Validation loss: 3.9514301771758706

Epoch: 6| Step: 5
Training loss: 4.647296905517578
Validation loss: 3.9388065338134766

Epoch: 6| Step: 6
Training loss: 2.993649959564209
Validation loss: 3.920372209241313

Epoch: 6| Step: 7
Training loss: 4.011273384094238
Validation loss: 3.8992681452023086

Epoch: 6| Step: 8
Training loss: 3.699946165084839
Validation loss: 3.8794318322212464

Epoch: 6| Step: 9
Training loss: 4.218855857849121
Validation loss: 3.8566891454881236

Epoch: 6| Step: 10
Training loss: 4.049421310424805
Validation loss: 3.83263821242958

Epoch: 6| Step: 11
Training loss: 2.4727590084075928
Validation loss: 3.8215081768651165

Epoch: 6| Step: 12
Training loss: 4.114999294281006
Validation loss: 3.79197601092759

Epoch: 6| Step: 13
Training loss: 4.053348064422607
Validation loss: 3.7719739201248332

Epoch: 13| Step: 0
Training loss: 2.986856460571289
Validation loss: 3.7563541243153233

Epoch: 6| Step: 1
Training loss: 3.684164524078369
Validation loss: 3.731658043399934

Epoch: 6| Step: 2
Training loss: 4.066413879394531
Validation loss: 3.7166773375644477

Epoch: 6| Step: 3
Training loss: 3.9372811317443848
Validation loss: 3.6999386971996677

Epoch: 6| Step: 4
Training loss: 3.645758867263794
Validation loss: 3.6701832484173518

Epoch: 6| Step: 5
Training loss: 4.172421455383301
Validation loss: 3.6554167142478367

Epoch: 6| Step: 6
Training loss: 3.029458999633789
Validation loss: 3.6358767735060824

Epoch: 6| Step: 7
Training loss: 2.199822425842285
Validation loss: 3.603380431411087

Epoch: 6| Step: 8
Training loss: 2.092780590057373
Validation loss: 3.5944788814872823

Epoch: 6| Step: 9
Training loss: 4.133992671966553
Validation loss: 3.5785455114098004

Epoch: 6| Step: 10
Training loss: 3.2237448692321777
Validation loss: 3.5555015046109437

Epoch: 6| Step: 11
Training loss: 4.194622039794922
Validation loss: 3.5247793197631836

Epoch: 6| Step: 12
Training loss: 3.684680461883545
Validation loss: 3.513007776711577

Epoch: 6| Step: 13
Training loss: 4.118571758270264
Validation loss: 3.486911637808687

Epoch: 14| Step: 0
Training loss: 2.9871878623962402
Validation loss: 3.4707261977657193

Epoch: 6| Step: 1
Training loss: 2.2651500701904297
Validation loss: 3.4562185169548116

Epoch: 6| Step: 2
Training loss: 2.744874954223633
Validation loss: 3.440953767427834

Epoch: 6| Step: 3
Training loss: 2.776813268661499
Validation loss: 3.4052181807897424

Epoch: 6| Step: 4
Training loss: 3.7002081871032715
Validation loss: 3.396609144826089

Epoch: 6| Step: 5
Training loss: 3.4387245178222656
Validation loss: 3.385644740955804

Epoch: 6| Step: 6
Training loss: 4.366921424865723
Validation loss: 3.344162961488129

Epoch: 6| Step: 7
Training loss: 3.087261438369751
Validation loss: 3.3361877574715564

Epoch: 6| Step: 8
Training loss: 2.6407556533813477
Validation loss: 3.311677243119927

Epoch: 6| Step: 9
Training loss: 3.757537841796875
Validation loss: 3.278860809982464

Epoch: 6| Step: 10
Training loss: 4.046509742736816
Validation loss: 3.259826280737436

Epoch: 6| Step: 11
Training loss: 2.4631471633911133
Validation loss: 3.238389238234489

Epoch: 6| Step: 12
Training loss: 3.630061149597168
Validation loss: 3.2126007926079536

Epoch: 6| Step: 13
Training loss: 3.551828384399414
Validation loss: 3.188633054815313

Epoch: 15| Step: 0
Training loss: 2.685370922088623
Validation loss: 3.172217228079355

Epoch: 6| Step: 1
Training loss: 3.7999069690704346
Validation loss: 3.143747825776377

Epoch: 6| Step: 2
Training loss: 3.739481210708618
Validation loss: 3.1313972550053752

Epoch: 6| Step: 3
Training loss: 2.9418015480041504
Validation loss: 3.0999821001483547

Epoch: 6| Step: 4
Training loss: 3.932168483734131
Validation loss: 3.084192378546602

Epoch: 6| Step: 5
Training loss: 2.867825984954834
Validation loss: 3.061540049891318

Epoch: 6| Step: 6
Training loss: 2.94338321685791
Validation loss: 3.037675480688772

Epoch: 6| Step: 7
Training loss: 2.3996920585632324
Validation loss: 3.021114223746843

Epoch: 6| Step: 8
Training loss: 3.070270538330078
Validation loss: 3.004425774338425

Epoch: 6| Step: 9
Training loss: 2.367492198944092
Validation loss: 2.9815889430302445

Epoch: 6| Step: 10
Training loss: 2.8436946868896484
Validation loss: 2.9588855645989858

Epoch: 6| Step: 11
Training loss: 2.776660442352295
Validation loss: 2.9426907570131364

Epoch: 6| Step: 12
Training loss: 2.8963520526885986
Validation loss: 2.9220501312645535

Epoch: 6| Step: 13
Training loss: 2.9273693561553955
Validation loss: 2.898668496839462

Epoch: 16| Step: 0
Training loss: 3.500917434692383
Validation loss: 2.8847169696643786

Epoch: 6| Step: 1
Training loss: 3.228400230407715
Validation loss: 2.870531764081729

Epoch: 6| Step: 2
Training loss: 2.5490808486938477
Validation loss: 2.831261065698439

Epoch: 6| Step: 3
Training loss: 2.251582145690918
Validation loss: 2.8256823196206042

Epoch: 6| Step: 4
Training loss: 3.07320499420166
Validation loss: 2.7983273613837456

Epoch: 6| Step: 5
Training loss: 2.2505946159362793
Validation loss: 2.7813994807581746

Epoch: 6| Step: 6
Training loss: 2.5446925163269043
Validation loss: 2.7672628510382866

Epoch: 6| Step: 7
Training loss: 2.8026533126831055
Validation loss: 2.7509546433725665

Epoch: 6| Step: 8
Training loss: 3.2091612815856934
Validation loss: 2.7239537546711583

Epoch: 6| Step: 9
Training loss: 2.3444619178771973
Validation loss: 2.716457830962314

Epoch: 6| Step: 10
Training loss: 3.362008810043335
Validation loss: 2.683925385116249

Epoch: 6| Step: 11
Training loss: 2.9564003944396973
Validation loss: 2.685356770792315

Epoch: 6| Step: 12
Training loss: 2.9932637214660645
Validation loss: 2.658092421870078

Epoch: 6| Step: 13
Training loss: 2.329991340637207
Validation loss: 2.6528563909633185

Epoch: 17| Step: 0
Training loss: 2.9973177909851074
Validation loss: 2.6207793297306186

Epoch: 6| Step: 1
Training loss: 2.578458786010742
Validation loss: 2.602641374834122

Epoch: 6| Step: 2
Training loss: 2.5806632041931152
Validation loss: 2.6134439975984636

Epoch: 6| Step: 3
Training loss: 2.744633913040161
Validation loss: 2.587898879922846

Epoch: 6| Step: 4
Training loss: 2.1712050437927246
Validation loss: 2.57642186585293

Epoch: 6| Step: 5
Training loss: 2.5933947563171387
Validation loss: 2.557567463126234

Epoch: 6| Step: 6
Training loss: 2.5654184818267822
Validation loss: 2.5376076544484785

Epoch: 6| Step: 7
Training loss: 3.3555145263671875
Validation loss: 2.546932772923541

Epoch: 6| Step: 8
Training loss: 2.7409510612487793
Validation loss: 2.5198222642303794

Epoch: 6| Step: 9
Training loss: 2.1782631874084473
Validation loss: 2.4986500022231892

Epoch: 6| Step: 10
Training loss: 2.553260326385498
Validation loss: 2.4993355120382

Epoch: 6| Step: 11
Training loss: 2.6523048877716064
Validation loss: 2.4829468522020566

Epoch: 6| Step: 12
Training loss: 2.929727554321289
Validation loss: 2.470584310511107

Epoch: 6| Step: 13
Training loss: 2.797659158706665
Validation loss: 2.4682626006423787

Epoch: 18| Step: 0
Training loss: 2.703049898147583
Validation loss: 2.4448865305992866

Epoch: 6| Step: 1
Training loss: 3.0964457988739014
Validation loss: 2.444462776184082

Epoch: 6| Step: 2
Training loss: 2.1422431468963623
Validation loss: 2.425123140376101

Epoch: 6| Step: 3
Training loss: 2.174130439758301
Validation loss: 2.4095651385604695

Epoch: 6| Step: 4
Training loss: 1.7842464447021484
Validation loss: 2.4027539658290085

Epoch: 6| Step: 5
Training loss: 2.361612319946289
Validation loss: 2.418272295305806

Epoch: 6| Step: 6
Training loss: 2.5769355297088623
Validation loss: 2.4074603126895044

Epoch: 6| Step: 7
Training loss: 2.5948450565338135
Validation loss: 2.402762064369776

Epoch: 6| Step: 8
Training loss: 3.1015610694885254
Validation loss: 2.3986299371206634

Epoch: 6| Step: 9
Training loss: 2.3988943099975586
Validation loss: 2.4054298913607033

Epoch: 6| Step: 10
Training loss: 3.2095205783843994
Validation loss: 2.387962577163532

Epoch: 6| Step: 11
Training loss: 2.0039007663726807
Validation loss: 2.3917947994765414

Epoch: 6| Step: 12
Training loss: 2.694563388824463
Validation loss: 2.39071741924491

Epoch: 6| Step: 13
Training loss: 3.690730571746826
Validation loss: 2.3894858360290527

Epoch: 19| Step: 0
Training loss: 2.7318661212921143
Validation loss: 2.367848470646848

Epoch: 6| Step: 1
Training loss: 2.414299964904785
Validation loss: 2.366937296364897

Epoch: 6| Step: 2
Training loss: 2.8074889183044434
Validation loss: 2.367404822380312

Epoch: 6| Step: 3
Training loss: 2.956233501434326
Validation loss: 2.3497630139832855

Epoch: 6| Step: 4
Training loss: 2.4752695560455322
Validation loss: 2.3564507730545534

Epoch: 6| Step: 5
Training loss: 2.598222017288208
Validation loss: 2.3442245144997873

Epoch: 6| Step: 6
Training loss: 2.0802359580993652
Validation loss: 2.3240273434628724

Epoch: 6| Step: 7
Training loss: 2.178438901901245
Validation loss: 2.345083157221476

Epoch: 6| Step: 8
Training loss: 2.7341082096099854
Validation loss: 2.3392228516199256

Epoch: 6| Step: 9
Training loss: 2.9896159172058105
Validation loss: 2.315220022714266

Epoch: 6| Step: 10
Training loss: 2.2757315635681152
Validation loss: 2.3252060618451846

Epoch: 6| Step: 11
Training loss: 2.3832318782806396
Validation loss: 2.316078983327394

Epoch: 6| Step: 12
Training loss: 2.520064353942871
Validation loss: 2.318516433879893

Epoch: 6| Step: 13
Training loss: 2.401660442352295
Validation loss: 2.312457674293108

Epoch: 20| Step: 0
Training loss: 2.7164363861083984
Validation loss: 2.3103943537640315

Epoch: 6| Step: 1
Training loss: 2.2677907943725586
Validation loss: 2.3009056122072282

Epoch: 6| Step: 2
Training loss: 1.9927842617034912
Validation loss: 2.306459649916618

Epoch: 6| Step: 3
Training loss: 3.1413328647613525
Validation loss: 2.2957230101349535

Epoch: 6| Step: 4
Training loss: 1.9569239616394043
Validation loss: 2.2839701688417824

Epoch: 6| Step: 5
Training loss: 1.9869234561920166
Validation loss: 2.3004655607285036

Epoch: 6| Step: 6
Training loss: 2.4215588569641113
Validation loss: 2.293387430970387

Epoch: 6| Step: 7
Training loss: 3.1062464714050293
Validation loss: 2.2863031228383384

Epoch: 6| Step: 8
Training loss: 3.075749158859253
Validation loss: 2.3052388596278366

Epoch: 6| Step: 9
Training loss: 2.595712661743164
Validation loss: 2.289128585528302

Epoch: 6| Step: 10
Training loss: 2.4250826835632324
Validation loss: 2.280938629181154

Epoch: 6| Step: 11
Training loss: 2.6929574012756348
Validation loss: 2.2830611044360745

Epoch: 6| Step: 12
Training loss: 2.3883910179138184
Validation loss: 2.2771182188423733

Epoch: 6| Step: 13
Training loss: 2.309595823287964
Validation loss: 2.281806210035919

Epoch: 21| Step: 0
Training loss: 3.203213691711426
Validation loss: 2.2601833035868983

Epoch: 6| Step: 1
Training loss: 2.5143890380859375
Validation loss: 2.261568546295166

Epoch: 6| Step: 2
Training loss: 2.0785083770751953
Validation loss: 2.2629395633615474

Epoch: 6| Step: 3
Training loss: 2.0675487518310547
Validation loss: 2.264248353178783

Epoch: 6| Step: 4
Training loss: 2.5014188289642334
Validation loss: 2.2680083167168403

Epoch: 6| Step: 5
Training loss: 1.6970014572143555
Validation loss: 2.2753153206199728

Epoch: 6| Step: 6
Training loss: 3.473313808441162
Validation loss: 2.2521375276709117

Epoch: 6| Step: 7
Training loss: 2.1969170570373535
Validation loss: 2.232790188122821

Epoch: 6| Step: 8
Training loss: 2.7172560691833496
Validation loss: 2.251569127523771

Epoch: 6| Step: 9
Training loss: 2.860015869140625
Validation loss: 2.240324463895572

Epoch: 6| Step: 10
Training loss: 2.222532272338867
Validation loss: 2.246700379156297

Epoch: 6| Step: 11
Training loss: 2.5944406986236572
Validation loss: 2.2389727933432466

Epoch: 6| Step: 12
Training loss: 2.3017897605895996
Validation loss: 2.251315032282183

Epoch: 6| Step: 13
Training loss: 2.680111885070801
Validation loss: 2.260842196403011

Epoch: 22| Step: 0
Training loss: 2.688387870788574
Validation loss: 2.239078160255186

Epoch: 6| Step: 1
Training loss: 2.931164026260376
Validation loss: 2.2485046937901485

Epoch: 6| Step: 2
Training loss: 1.9609534740447998
Validation loss: 2.266050636127431

Epoch: 6| Step: 3
Training loss: 2.3407492637634277
Validation loss: 2.240392781073047

Epoch: 6| Step: 4
Training loss: 2.0696516036987305
Validation loss: 2.2528922096375497

Epoch: 6| Step: 5
Training loss: 2.388108491897583
Validation loss: 2.2353869176680043

Epoch: 6| Step: 6
Training loss: 2.859421491622925
Validation loss: 2.2432346164539294

Epoch: 6| Step: 7
Training loss: 2.2814829349517822
Validation loss: 2.241315890383977

Epoch: 6| Step: 8
Training loss: 2.3140640258789062
Validation loss: 2.258482604898432

Epoch: 6| Step: 9
Training loss: 2.1390066146850586
Validation loss: 2.2517428833951234

Epoch: 6| Step: 10
Training loss: 2.9866020679473877
Validation loss: 2.2501811417200233

Epoch: 6| Step: 11
Training loss: 2.4781155586242676
Validation loss: 2.26944084705845

Epoch: 6| Step: 12
Training loss: 2.514686107635498
Validation loss: 2.2549107023464736

Epoch: 6| Step: 13
Training loss: 3.6879026889801025
Validation loss: 2.2633654020165883

Epoch: 23| Step: 0
Training loss: 2.541623115539551
Validation loss: 2.2584811948960826

Epoch: 6| Step: 1
Training loss: 2.5608716011047363
Validation loss: 2.2559481436206448

Epoch: 6| Step: 2
Training loss: 2.6451878547668457
Validation loss: 2.2386564362433647

Epoch: 6| Step: 3
Training loss: 2.8411993980407715
Validation loss: 2.2551860219688824

Epoch: 6| Step: 4
Training loss: 2.371896505355835
Validation loss: 2.266505564412763

Epoch: 6| Step: 5
Training loss: 2.8764257431030273
Validation loss: 2.2611879046245287

Epoch: 6| Step: 6
Training loss: 2.1740102767944336
Validation loss: 2.262256585141664

Epoch: 6| Step: 7
Training loss: 2.4245285987854004
Validation loss: 2.25205853421201

Epoch: 6| Step: 8
Training loss: 1.861885905265808
Validation loss: 2.239592577821465

Epoch: 6| Step: 9
Training loss: 2.754134178161621
Validation loss: 2.253968961777226

Epoch: 6| Step: 10
Training loss: 2.706289768218994
Validation loss: 2.2499173456622708

Epoch: 6| Step: 11
Training loss: 2.021965265274048
Validation loss: 2.2610626989795315

Epoch: 6| Step: 12
Training loss: 2.5527663230895996
Validation loss: 2.24585537756643

Epoch: 6| Step: 13
Training loss: 2.2908315658569336
Validation loss: 2.255683414397701

Epoch: 24| Step: 0
Training loss: 3.0311551094055176
Validation loss: 2.239950531272478

Epoch: 6| Step: 1
Training loss: 3.232722759246826
Validation loss: 2.2569715156350085

Epoch: 6| Step: 2
Training loss: 1.8329145908355713
Validation loss: 2.2584012426355833

Epoch: 6| Step: 3
Training loss: 2.2933707237243652
Validation loss: 2.2683481208739744

Epoch: 6| Step: 4
Training loss: 2.5431432723999023
Validation loss: 2.2518220563088693

Epoch: 6| Step: 5
Training loss: 2.9522993564605713
Validation loss: 2.248647330909647

Epoch: 6| Step: 6
Training loss: 1.9150352478027344
Validation loss: 2.2485348242585377

Epoch: 6| Step: 7
Training loss: 1.757519245147705
Validation loss: 2.242048824987104

Epoch: 6| Step: 8
Training loss: 3.325920343399048
Validation loss: 2.250327146181496

Epoch: 6| Step: 9
Training loss: 2.303758144378662
Validation loss: 2.2599395462261733

Epoch: 6| Step: 10
Training loss: 2.877939224243164
Validation loss: 2.2452042000268095

Epoch: 6| Step: 11
Training loss: 1.9702215194702148
Validation loss: 2.24667941370318

Epoch: 6| Step: 12
Training loss: 2.3304829597473145
Validation loss: 2.2543183962504068

Epoch: 6| Step: 13
Training loss: 1.9303728342056274
Validation loss: 2.259805010211083

Epoch: 25| Step: 0
Training loss: 3.003744602203369
Validation loss: 2.2469168709170435

Epoch: 6| Step: 1
Training loss: 2.6779685020446777
Validation loss: 2.2264538324007423

Epoch: 6| Step: 2
Training loss: 2.5059151649475098
Validation loss: 2.2461971852087204

Epoch: 6| Step: 3
Training loss: 2.1773831844329834
Validation loss: 2.247452178309041

Epoch: 6| Step: 4
Training loss: 2.8553688526153564
Validation loss: 2.258754494369671

Epoch: 6| Step: 5
Training loss: 1.5024192333221436
Validation loss: 2.233098114690473

Epoch: 6| Step: 6
Training loss: 2.724940776824951
Validation loss: 2.248401854627876

Epoch: 6| Step: 7
Training loss: 2.121328115463257
Validation loss: 2.239476482073466

Epoch: 6| Step: 8
Training loss: 1.8408949375152588
Validation loss: 2.2467759463094894

Epoch: 6| Step: 9
Training loss: 2.6171679496765137
Validation loss: 2.2446084599341116

Epoch: 6| Step: 10
Training loss: 2.1419990062713623
Validation loss: 2.2472117613720637

Epoch: 6| Step: 11
Training loss: 3.204987049102783
Validation loss: 2.2390673468189854

Epoch: 6| Step: 12
Training loss: 2.5127458572387695
Validation loss: 2.2403027985685613

Epoch: 6| Step: 13
Training loss: 2.3574299812316895
Validation loss: 2.2453270753224692

Epoch: 26| Step: 0
Training loss: 2.8124606609344482
Validation loss: 2.23149456772753

Epoch: 6| Step: 1
Training loss: 2.6053972244262695
Validation loss: 2.236671209335327

Epoch: 6| Step: 2
Training loss: 2.490833282470703
Validation loss: 2.2339654250811507

Epoch: 6| Step: 3
Training loss: 2.563292980194092
Validation loss: 2.253704301772579

Epoch: 6| Step: 4
Training loss: 2.391343355178833
Validation loss: 2.239370607560681

Epoch: 6| Step: 5
Training loss: 2.0699591636657715
Validation loss: 2.2231669707964827

Epoch: 6| Step: 6
Training loss: 2.513967514038086
Validation loss: 2.225599524795368

Epoch: 6| Step: 7
Training loss: 2.2911863327026367
Validation loss: 2.2238416159024803

Epoch: 6| Step: 8
Training loss: 1.1600289344787598
Validation loss: 2.2427783191844983

Epoch: 6| Step: 9
Training loss: 2.5791478157043457
Validation loss: 2.2116697347292336

Epoch: 6| Step: 10
Training loss: 2.561436176300049
Validation loss: 2.2333447548650924

Epoch: 6| Step: 11
Training loss: 3.3807451725006104
Validation loss: 2.238029328725671

Epoch: 6| Step: 12
Training loss: 2.454911470413208
Validation loss: 2.2234360376993814

Epoch: 6| Step: 13
Training loss: 2.646611213684082
Validation loss: 2.24076332071776

Epoch: 27| Step: 0
Training loss: 2.045032262802124
Validation loss: 2.21846285686698

Epoch: 6| Step: 1
Training loss: 2.0803706645965576
Validation loss: 2.2370684069971882

Epoch: 6| Step: 2
Training loss: 2.925816059112549
Validation loss: 2.2166186276302544

Epoch: 6| Step: 3
Training loss: 2.334575653076172
Validation loss: 2.2328442373583393

Epoch: 6| Step: 4
Training loss: 1.9576281309127808
Validation loss: 2.239966182298558

Epoch: 6| Step: 5
Training loss: 2.47336483001709
Validation loss: 2.234301333786339

Epoch: 6| Step: 6
Training loss: 2.7590041160583496
Validation loss: 2.2578764782156995

Epoch: 6| Step: 7
Training loss: 2.3011817932128906
Validation loss: 2.2479415068062405

Epoch: 6| Step: 8
Training loss: 2.490232467651367
Validation loss: 2.238440066255549

Epoch: 6| Step: 9
Training loss: 2.1945624351501465
Validation loss: 2.2415906767691336

Epoch: 6| Step: 10
Training loss: 2.8352928161621094
Validation loss: 2.2484076766557592

Epoch: 6| Step: 11
Training loss: 2.496495246887207
Validation loss: 2.2439284247736775

Epoch: 6| Step: 12
Training loss: 2.6476664543151855
Validation loss: 2.2374757054031535

Epoch: 6| Step: 13
Training loss: 3.139651298522949
Validation loss: 2.238061099924067

Epoch: 28| Step: 0
Training loss: 2.217866897583008
Validation loss: 2.233598095114513

Epoch: 6| Step: 1
Training loss: 2.232069730758667
Validation loss: 2.2499485887506956

Epoch: 6| Step: 2
Training loss: 2.241179943084717
Validation loss: 2.23262047126729

Epoch: 6| Step: 3
Training loss: 2.0845413208007812
Validation loss: 2.222222028240081

Epoch: 6| Step: 4
Training loss: 2.52346134185791
Validation loss: 2.222231220173579

Epoch: 6| Step: 5
Training loss: 2.699978828430176
Validation loss: 2.240709038190944

Epoch: 6| Step: 6
Training loss: 2.3433778285980225
Validation loss: 2.2288488854644117

Epoch: 6| Step: 7
Training loss: 2.7304491996765137
Validation loss: 2.22262825248062

Epoch: 6| Step: 8
Training loss: 2.84991192817688
Validation loss: 2.2190336681181386

Epoch: 6| Step: 9
Training loss: 2.2167844772338867
Validation loss: 2.215078466682024

Epoch: 6| Step: 10
Training loss: 2.648155450820923
Validation loss: 2.215950838981136

Epoch: 6| Step: 11
Training loss: 3.0046751499176025
Validation loss: 2.2106450091126146

Epoch: 6| Step: 12
Training loss: 1.8792990446090698
Validation loss: 2.2176573109883133

Epoch: 6| Step: 13
Training loss: 2.4976110458374023
Validation loss: 2.2146663665771484

Epoch: 29| Step: 0
Training loss: 2.3052978515625
Validation loss: 2.2136538772172827

Epoch: 6| Step: 1
Training loss: 2.2396583557128906
Validation loss: 2.2203215911824215

Epoch: 6| Step: 2
Training loss: 2.933927059173584
Validation loss: 2.21696896706858

Epoch: 6| Step: 3
Training loss: 2.320284366607666
Validation loss: 2.212074875831604

Epoch: 6| Step: 4
Training loss: 2.213099956512451
Validation loss: 2.206618385930215

Epoch: 6| Step: 5
Training loss: 2.7126083374023438
Validation loss: 2.20495932332931

Epoch: 6| Step: 6
Training loss: 2.4608707427978516
Validation loss: 2.195842791629094

Epoch: 6| Step: 7
Training loss: 2.643454074859619
Validation loss: 2.219243288040161

Epoch: 6| Step: 8
Training loss: 2.1455254554748535
Validation loss: 2.230073385341193

Epoch: 6| Step: 9
Training loss: 2.419802188873291
Validation loss: 2.207062436688331

Epoch: 6| Step: 10
Training loss: 2.077310800552368
Validation loss: 2.206661191037906

Epoch: 6| Step: 11
Training loss: 2.9583184719085693
Validation loss: 2.2151273988908335

Epoch: 6| Step: 12
Training loss: 2.460620880126953
Validation loss: 2.2107657924775155

Epoch: 6| Step: 13
Training loss: 2.0124306678771973
Validation loss: 2.2039394763208207

Epoch: 30| Step: 0
Training loss: 2.952317714691162
Validation loss: 2.2271572697547173

Epoch: 6| Step: 1
Training loss: 2.443864345550537
Validation loss: 2.200409309838408

Epoch: 6| Step: 2
Training loss: 2.630624294281006
Validation loss: 2.226439929777576

Epoch: 6| Step: 3
Training loss: 2.6285197734832764
Validation loss: 2.2181660744451706

Epoch: 6| Step: 4
Training loss: 2.5049169063568115
Validation loss: 2.212891387683089

Epoch: 6| Step: 5
Training loss: 2.6601128578186035
Validation loss: 2.2325362261905464

Epoch: 6| Step: 6
Training loss: 1.82950758934021
Validation loss: 2.2149732369248585

Epoch: 6| Step: 7
Training loss: 2.393122911453247
Validation loss: 2.21315675140709

Epoch: 6| Step: 8
Training loss: 2.628176689147949
Validation loss: 2.2218758495905067

Epoch: 6| Step: 9
Training loss: 2.008662462234497
Validation loss: 2.210951151386384

Epoch: 6| Step: 10
Training loss: 2.350081443786621
Validation loss: 2.2257667844013502

Epoch: 6| Step: 11
Training loss: 1.9816651344299316
Validation loss: 2.214727968297979

Epoch: 6| Step: 12
Training loss: 2.190995693206787
Validation loss: 2.21090877697032

Epoch: 6| Step: 13
Training loss: 2.934725284576416
Validation loss: 2.209913728057697

Epoch: 31| Step: 0
Training loss: 1.9179954528808594
Validation loss: 2.1986262747036514

Epoch: 6| Step: 1
Training loss: 2.083052635192871
Validation loss: 2.193033966966855

Epoch: 6| Step: 2
Training loss: 3.3624722957611084
Validation loss: 2.2213637303280573

Epoch: 6| Step: 3
Training loss: 3.032705545425415
Validation loss: 2.1982444409401185

Epoch: 6| Step: 4
Training loss: 1.8004395961761475
Validation loss: 2.203424317862398

Epoch: 6| Step: 5
Training loss: 2.4169583320617676
Validation loss: 2.208888748640655

Epoch: 6| Step: 6
Training loss: 2.2069754600524902
Validation loss: 2.2006051258374284

Epoch: 6| Step: 7
Training loss: 2.814924478530884
Validation loss: 2.2046000803670576

Epoch: 6| Step: 8
Training loss: 2.9736599922180176
Validation loss: 2.1999485620888333

Epoch: 6| Step: 9
Training loss: 2.314418315887451
Validation loss: 2.1924837225226947

Epoch: 6| Step: 10
Training loss: 2.170011520385742
Validation loss: 2.185054020215106

Epoch: 6| Step: 11
Training loss: 1.913995385169983
Validation loss: 2.2173930239933792

Epoch: 6| Step: 12
Training loss: 2.3521218299865723
Validation loss: 2.200647315671367

Epoch: 6| Step: 13
Training loss: 2.4121575355529785
Validation loss: 2.2083740772739535

Epoch: 32| Step: 0
Training loss: 2.4271035194396973
Validation loss: 2.1880042745221044

Epoch: 6| Step: 1
Training loss: 1.9716928005218506
Validation loss: 2.20259367650555

Epoch: 6| Step: 2
Training loss: 2.1944785118103027
Validation loss: 2.201732986716814

Epoch: 6| Step: 3
Training loss: 2.521998405456543
Validation loss: 2.2090402982568227

Epoch: 6| Step: 4
Training loss: 2.204303503036499
Validation loss: 2.2066497033642185

Epoch: 6| Step: 5
Training loss: 2.768465518951416
Validation loss: 2.2159514606639905

Epoch: 6| Step: 6
Training loss: 2.1364328861236572
Validation loss: 2.1975727876027427

Epoch: 6| Step: 7
Training loss: 2.422858715057373
Validation loss: 2.202065098670221

Epoch: 6| Step: 8
Training loss: 2.771531343460083
Validation loss: 2.199571394151257

Epoch: 6| Step: 9
Training loss: 2.172755718231201
Validation loss: 2.2084545576444237

Epoch: 6| Step: 10
Training loss: 2.3743648529052734
Validation loss: 2.1984435409627934

Epoch: 6| Step: 11
Training loss: 2.3032402992248535
Validation loss: 2.20156362236187

Epoch: 6| Step: 12
Training loss: 2.626664400100708
Validation loss: 2.194980841810985

Epoch: 6| Step: 13
Training loss: 2.843184471130371
Validation loss: 2.1973160313021753

Epoch: 33| Step: 0
Training loss: 2.6100897789001465
Validation loss: 2.209948016751197

Epoch: 6| Step: 1
Training loss: 1.733965277671814
Validation loss: 2.1923505260098364

Epoch: 6| Step: 2
Training loss: 2.31318998336792
Validation loss: 2.197326349955733

Epoch: 6| Step: 3
Training loss: 3.076920986175537
Validation loss: 2.208055483397617

Epoch: 6| Step: 4
Training loss: 2.5528745651245117
Validation loss: 2.1937743386914654

Epoch: 6| Step: 5
Training loss: 2.275453567504883
Validation loss: 2.2080941200256348

Epoch: 6| Step: 6
Training loss: 2.3632700443267822
Validation loss: 2.2030094233892297

Epoch: 6| Step: 7
Training loss: 2.232295274734497
Validation loss: 2.198009393548453

Epoch: 6| Step: 8
Training loss: 2.8219385147094727
Validation loss: 2.2168151153031217

Epoch: 6| Step: 9
Training loss: 1.9937266111373901
Validation loss: 2.2035200724037747

Epoch: 6| Step: 10
Training loss: 2.8298511505126953
Validation loss: 2.2158225121036654

Epoch: 6| Step: 11
Training loss: 1.7922073602676392
Validation loss: 2.194476048151652

Epoch: 6| Step: 12
Training loss: 2.8157105445861816
Validation loss: 2.180629790470164

Epoch: 6| Step: 13
Training loss: 1.9633702039718628
Validation loss: 2.1875587765888502

Epoch: 34| Step: 0
Training loss: 1.8742929697036743
Validation loss: 2.2135227623806206

Epoch: 6| Step: 1
Training loss: 2.8012404441833496
Validation loss: 2.1999589717516335

Epoch: 6| Step: 2
Training loss: 2.593083143234253
Validation loss: 2.215847994691582

Epoch: 6| Step: 3
Training loss: 2.5631299018859863
Validation loss: 2.215564799565141

Epoch: 6| Step: 4
Training loss: 2.1093320846557617
Validation loss: 2.219220474202146

Epoch: 6| Step: 5
Training loss: 2.5098514556884766
Validation loss: 2.2110374691665813

Epoch: 6| Step: 6
Training loss: 1.8987603187561035
Validation loss: 2.18934727227816

Epoch: 6| Step: 7
Training loss: 2.336512565612793
Validation loss: 2.2043198462455504

Epoch: 6| Step: 8
Training loss: 2.2522263526916504
Validation loss: 2.210940904514764

Epoch: 6| Step: 9
Training loss: 2.2078335285186768
Validation loss: 2.198879552143876

Epoch: 6| Step: 10
Training loss: 3.035767078399658
Validation loss: 2.1804338129617835

Epoch: 6| Step: 11
Training loss: 2.055655002593994
Validation loss: 2.208854147182998

Epoch: 6| Step: 12
Training loss: 2.4280457496643066
Validation loss: 2.2014887345734464

Epoch: 6| Step: 13
Training loss: 3.312134027481079
Validation loss: 2.2157886835836593

Epoch: 35| Step: 0
Training loss: 2.88676381111145
Validation loss: 2.194751024246216

Epoch: 6| Step: 1
Training loss: 3.1947503089904785
Validation loss: 2.198611231260402

Epoch: 6| Step: 2
Training loss: 2.071594476699829
Validation loss: 2.186621037862634

Epoch: 6| Step: 3
Training loss: 2.470724105834961
Validation loss: 2.184721457060947

Epoch: 6| Step: 4
Training loss: 2.2397756576538086
Validation loss: 2.1958332420677267

Epoch: 6| Step: 5
Training loss: 2.6759402751922607
Validation loss: 2.1858239045707126

Epoch: 6| Step: 6
Training loss: 2.8769869804382324
Validation loss: 2.1976421443364953

Epoch: 6| Step: 7
Training loss: 2.8558852672576904
Validation loss: 2.1850553840719242

Epoch: 6| Step: 8
Training loss: 2.1572964191436768
Validation loss: 2.1897267885105585

Epoch: 6| Step: 9
Training loss: 2.5251500606536865
Validation loss: 2.164170972762569

Epoch: 6| Step: 10
Training loss: 2.440746307373047
Validation loss: 2.1883180192721787

Epoch: 6| Step: 11
Training loss: 1.77286696434021
Validation loss: 2.1749916153569377

Epoch: 6| Step: 12
Training loss: 1.3971765041351318
Validation loss: 2.1718213199287333

Epoch: 6| Step: 13
Training loss: 1.5531030893325806
Validation loss: 2.1786183259820424

Epoch: 36| Step: 0
Training loss: 2.058081865310669
Validation loss: 2.201917048423521

Epoch: 6| Step: 1
Training loss: 2.30007266998291
Validation loss: 2.175322753126903

Epoch: 6| Step: 2
Training loss: 2.1422297954559326
Validation loss: 2.1836960905341694

Epoch: 6| Step: 3
Training loss: 2.9566354751586914
Validation loss: 2.17097593122913

Epoch: 6| Step: 4
Training loss: 2.476630449295044
Validation loss: 2.1757259368896484

Epoch: 6| Step: 5
Training loss: 2.345667600631714
Validation loss: 2.1832741024673625

Epoch: 6| Step: 6
Training loss: 1.8394827842712402
Validation loss: 2.1868989416348037

Epoch: 6| Step: 7
Training loss: 2.305677890777588
Validation loss: 2.1792735412556636

Epoch: 6| Step: 8
Training loss: 2.441359519958496
Validation loss: 2.1844245208207

Epoch: 6| Step: 9
Training loss: 1.9927592277526855
Validation loss: 2.1834482762121383

Epoch: 6| Step: 10
Training loss: 3.231984853744507
Validation loss: 2.1872501116926952

Epoch: 6| Step: 11
Training loss: 1.9452979564666748
Validation loss: 2.19575846323403

Epoch: 6| Step: 12
Training loss: 3.0144174098968506
Validation loss: 2.1899170350002986

Epoch: 6| Step: 13
Training loss: 2.0968923568725586
Validation loss: 2.1834730409806773

Epoch: 37| Step: 0
Training loss: 1.996970534324646
Validation loss: 2.188664372249316

Epoch: 6| Step: 1
Training loss: 2.853968620300293
Validation loss: 2.1862619769188667

Epoch: 6| Step: 2
Training loss: 2.315807342529297
Validation loss: 2.1968979912419475

Epoch: 6| Step: 3
Training loss: 2.487086772918701
Validation loss: 2.1862650020148164

Epoch: 6| Step: 4
Training loss: 2.7499468326568604
Validation loss: 2.181611414878599

Epoch: 6| Step: 5
Training loss: 1.9375767707824707
Validation loss: 2.188007770046111

Epoch: 6| Step: 6
Training loss: 2.775329828262329
Validation loss: 2.1888650924928728

Epoch: 6| Step: 7
Training loss: 2.36895751953125
Validation loss: 2.195643513433395

Epoch: 6| Step: 8
Training loss: 1.7011497020721436
Validation loss: 2.183393314320554

Epoch: 6| Step: 9
Training loss: 2.931490421295166
Validation loss: 2.18851742693173

Epoch: 6| Step: 10
Training loss: 1.9474468231201172
Validation loss: 2.2150723139444985

Epoch: 6| Step: 11
Training loss: 2.4706101417541504
Validation loss: 2.1942822830651396

Epoch: 6| Step: 12
Training loss: 2.336517333984375
Validation loss: 2.1921982560106503

Epoch: 6| Step: 13
Training loss: 2.2636349201202393
Validation loss: 2.20006210829622

Epoch: 38| Step: 0
Training loss: 2.482788562774658
Validation loss: 2.191674852883944

Epoch: 6| Step: 1
Training loss: 1.9936084747314453
Validation loss: 2.2039248251145884

Epoch: 6| Step: 2
Training loss: 2.4999208450317383
Validation loss: 2.192381787043746

Epoch: 6| Step: 3
Training loss: 2.506826400756836
Validation loss: 2.1996812871707383

Epoch: 6| Step: 4
Training loss: 1.6707792282104492
Validation loss: 2.1974319078589

Epoch: 6| Step: 5
Training loss: 2.83524751663208
Validation loss: 2.2040792331900647

Epoch: 6| Step: 6
Training loss: 2.668863296508789
Validation loss: 2.180691126854189

Epoch: 6| Step: 7
Training loss: 2.1450188159942627
Validation loss: 2.1912282743761615

Epoch: 6| Step: 8
Training loss: 1.9440498352050781
Validation loss: 2.2000479467453493

Epoch: 6| Step: 9
Training loss: 2.461228370666504
Validation loss: 2.186457662172215

Epoch: 6| Step: 10
Training loss: 2.0571398735046387
Validation loss: 2.2129853015304892

Epoch: 6| Step: 11
Training loss: 2.706193685531616
Validation loss: 2.171220338472756

Epoch: 6| Step: 12
Training loss: 2.2927842140197754
Validation loss: 2.1718293236147974

Epoch: 6| Step: 13
Training loss: 3.174771308898926
Validation loss: 2.1760160256457586

Epoch: 39| Step: 0
Training loss: 1.6583631038665771
Validation loss: 2.1765762234246857

Epoch: 6| Step: 1
Training loss: 2.8220489025115967
Validation loss: 2.178393607498497

Epoch: 6| Step: 2
Training loss: 1.8805527687072754
Validation loss: 2.177171286716256

Epoch: 6| Step: 3
Training loss: 2.298727035522461
Validation loss: 2.1816100894763903

Epoch: 6| Step: 4
Training loss: 2.5618844032287598
Validation loss: 2.1806841896426294

Epoch: 6| Step: 5
Training loss: 2.8952765464782715
Validation loss: 2.1788425112283356

Epoch: 6| Step: 6
Training loss: 2.427570343017578
Validation loss: 2.186211791089786

Epoch: 6| Step: 7
Training loss: 2.5584020614624023
Validation loss: 2.196719341380622

Epoch: 6| Step: 8
Training loss: 1.5842058658599854
Validation loss: 2.1881334679101103

Epoch: 6| Step: 9
Training loss: 2.272930145263672
Validation loss: 2.178295441853103

Epoch: 6| Step: 10
Training loss: 2.668466567993164
Validation loss: 2.2104902062364804

Epoch: 6| Step: 11
Training loss: 2.484090805053711
Validation loss: 2.1825560985072965

Epoch: 6| Step: 12
Training loss: 2.331056594848633
Validation loss: 2.16572037307165

Epoch: 6| Step: 13
Training loss: 2.683499336242676
Validation loss: 2.175871100476993

Epoch: 40| Step: 0
Training loss: 2.3004403114318848
Validation loss: 2.1607143904573176

Epoch: 6| Step: 1
Training loss: 2.3662490844726562
Validation loss: 2.160383975634011

Epoch: 6| Step: 2
Training loss: 2.492518186569214
Validation loss: 2.1971495920611965

Epoch: 6| Step: 3
Training loss: 2.6705212593078613
Validation loss: 2.188189083530057

Epoch: 6| Step: 4
Training loss: 1.8775871992111206
Validation loss: 2.1847207366779284

Epoch: 6| Step: 5
Training loss: 2.329162836074829
Validation loss: 2.172802330345236

Epoch: 6| Step: 6
Training loss: 2.652723789215088
Validation loss: 2.1655642165932605

Epoch: 6| Step: 7
Training loss: 2.1095216274261475
Validation loss: 2.1698114128522974

Epoch: 6| Step: 8
Training loss: 2.1594390869140625
Validation loss: 2.172330540995444

Epoch: 6| Step: 9
Training loss: 2.141129493713379
Validation loss: 2.1731239057356313

Epoch: 6| Step: 10
Training loss: 1.8215411901474
Validation loss: 2.162255599934568

Epoch: 6| Step: 11
Training loss: 2.1142382621765137
Validation loss: 2.168484687805176

Epoch: 6| Step: 12
Training loss: 3.200145721435547
Validation loss: 2.1649398431983045

Epoch: 6| Step: 13
Training loss: 2.558805465698242
Validation loss: 2.1758113215046544

Epoch: 41| Step: 0
Training loss: 2.802858829498291
Validation loss: 2.17066777008836

Epoch: 6| Step: 1
Training loss: 2.0199427604675293
Validation loss: 2.161270449238439

Epoch: 6| Step: 2
Training loss: 2.4022581577301025
Validation loss: 2.1721605613667476

Epoch: 6| Step: 3
Training loss: 2.1675515174865723
Validation loss: 2.1663900882967058

Epoch: 6| Step: 4
Training loss: 2.2728707790374756
Validation loss: 2.183511908336352

Epoch: 6| Step: 5
Training loss: 2.608745574951172
Validation loss: 2.169140654225503

Epoch: 6| Step: 6
Training loss: 2.6033334732055664
Validation loss: 2.1546942034075336

Epoch: 6| Step: 7
Training loss: 2.3317034244537354
Validation loss: 2.170959649547454

Epoch: 6| Step: 8
Training loss: 2.542189121246338
Validation loss: 2.166405700868176

Epoch: 6| Step: 9
Training loss: 2.7254443168640137
Validation loss: 2.1884850558414253

Epoch: 6| Step: 10
Training loss: 2.2431094646453857
Validation loss: 2.1423569469041723

Epoch: 6| Step: 11
Training loss: 1.8634531497955322
Validation loss: 2.1762124287184847

Epoch: 6| Step: 12
Training loss: 1.7402286529541016
Validation loss: 2.155804709721637

Epoch: 6| Step: 13
Training loss: 2.691330909729004
Validation loss: 2.160646579598868

Epoch: 42| Step: 0
Training loss: 2.867767810821533
Validation loss: 2.1585763782583256

Epoch: 6| Step: 1
Training loss: 1.8350151777267456
Validation loss: 2.1841624398385324

Epoch: 6| Step: 2
Training loss: 2.086249351501465
Validation loss: 2.1883502339804046

Epoch: 6| Step: 3
Training loss: 3.089045286178589
Validation loss: 2.1773321808025403

Epoch: 6| Step: 4
Training loss: 2.564810276031494
Validation loss: 2.1798126941086142

Epoch: 6| Step: 5
Training loss: 1.916205883026123
Validation loss: 2.1675145126158193

Epoch: 6| Step: 6
Training loss: 2.0713915824890137
Validation loss: 2.1738657823172947

Epoch: 6| Step: 7
Training loss: 2.9216318130493164
Validation loss: 2.1681555035293743

Epoch: 6| Step: 8
Training loss: 2.1807138919830322
Validation loss: 2.1699515914404266

Epoch: 6| Step: 9
Training loss: 2.712406635284424
Validation loss: 2.1690479888710925

Epoch: 6| Step: 10
Training loss: 1.9553078413009644
Validation loss: 2.182693532718125

Epoch: 6| Step: 11
Training loss: 2.5532209873199463
Validation loss: 2.1775152683258057

Epoch: 6| Step: 12
Training loss: 2.0658206939697266
Validation loss: 2.1678302070145965

Epoch: 6| Step: 13
Training loss: 1.5772370100021362
Validation loss: 2.153970182582896

Epoch: 43| Step: 0
Training loss: 2.1528239250183105
Validation loss: 2.1671185480651034

Epoch: 6| Step: 1
Training loss: 2.5600826740264893
Validation loss: 2.1750287778915895

Epoch: 6| Step: 2
Training loss: 2.078301191329956
Validation loss: 2.1521600331029584

Epoch: 6| Step: 3
Training loss: 2.033592700958252
Validation loss: 2.1693363869062035

Epoch: 6| Step: 4
Training loss: 2.392080307006836
Validation loss: 2.157160585926425

Epoch: 6| Step: 5
Training loss: 2.227466583251953
Validation loss: 2.160498011496759

Epoch: 6| Step: 6
Training loss: 2.5448338985443115
Validation loss: 2.1634774951524633

Epoch: 6| Step: 7
Training loss: 2.6876626014709473
Validation loss: 2.1556850889677643

Epoch: 6| Step: 8
Training loss: 1.65529203414917
Validation loss: 2.158274301918604

Epoch: 6| Step: 9
Training loss: 2.949479579925537
Validation loss: 2.1435049323625464

Epoch: 6| Step: 10
Training loss: 2.4699511528015137
Validation loss: 2.1752940480427077

Epoch: 6| Step: 11
Training loss: 2.2557458877563477
Validation loss: 2.165368030148168

Epoch: 6| Step: 12
Training loss: 1.8548457622528076
Validation loss: 2.1609220235578475

Epoch: 6| Step: 13
Training loss: 3.454589366912842
Validation loss: 2.154583026004094

Epoch: 44| Step: 0
Training loss: 2.20723032951355
Validation loss: 2.1416896722650014

Epoch: 6| Step: 1
Training loss: 2.5210156440734863
Validation loss: 2.166028602148897

Epoch: 6| Step: 2
Training loss: 2.134932041168213
Validation loss: 2.1691422923918693

Epoch: 6| Step: 3
Training loss: 2.322640895843506
Validation loss: 2.1624345984510196

Epoch: 6| Step: 4
Training loss: 2.360384941101074
Validation loss: 2.159275083131688

Epoch: 6| Step: 5
Training loss: 1.9538302421569824
Validation loss: 2.1536889704324866

Epoch: 6| Step: 6
Training loss: 2.106383800506592
Validation loss: 2.1564303521187074

Epoch: 6| Step: 7
Training loss: 2.2027974128723145
Validation loss: 2.156970666300866

Epoch: 6| Step: 8
Training loss: 2.5144317150115967
Validation loss: 2.172661660819925

Epoch: 6| Step: 9
Training loss: 2.166233777999878
Validation loss: 2.159321729854871

Epoch: 6| Step: 10
Training loss: 2.4740402698516846
Validation loss: 2.1779407634530017

Epoch: 6| Step: 11
Training loss: 1.8325695991516113
Validation loss: 2.1655485040398053

Epoch: 6| Step: 12
Training loss: 2.876798152923584
Validation loss: 2.1667889664250035

Epoch: 6| Step: 13
Training loss: 3.214770793914795
Validation loss: 2.1635138834676435

Epoch: 45| Step: 0
Training loss: 2.1615867614746094
Validation loss: 2.1761430053300757

Epoch: 6| Step: 1
Training loss: 1.8687641620635986
Validation loss: 2.150100872080813

Epoch: 6| Step: 2
Training loss: 2.147552251815796
Validation loss: 2.150853221134473

Epoch: 6| Step: 3
Training loss: 2.3547821044921875
Validation loss: 2.1550501354279055

Epoch: 6| Step: 4
Training loss: 2.7932662963867188
Validation loss: 2.170216929528021

Epoch: 6| Step: 5
Training loss: 2.1897244453430176
Validation loss: 2.149740024279523

Epoch: 6| Step: 6
Training loss: 2.488870620727539
Validation loss: 2.1774672218548354

Epoch: 6| Step: 7
Training loss: 2.4271602630615234
Validation loss: 2.1588662798686693

Epoch: 6| Step: 8
Training loss: 2.8531923294067383
Validation loss: 2.168971125797559

Epoch: 6| Step: 9
Training loss: 2.280040740966797
Validation loss: 2.1868071504818496

Epoch: 6| Step: 10
Training loss: 2.52785587310791
Validation loss: 2.156528017854178

Epoch: 6| Step: 11
Training loss: 2.635601043701172
Validation loss: 2.1732850587496193

Epoch: 6| Step: 12
Training loss: 1.5353059768676758
Validation loss: 2.172969488687413

Epoch: 6| Step: 13
Training loss: 2.5207810401916504
Validation loss: 2.174654737595589

Epoch: 46| Step: 0
Training loss: 2.072282314300537
Validation loss: 2.1588725864246325

Epoch: 6| Step: 1
Training loss: 2.6939802169799805
Validation loss: 2.1491692220011065

Epoch: 6| Step: 2
Training loss: 2.227426528930664
Validation loss: 2.152958413606049

Epoch: 6| Step: 3
Training loss: 2.6541030406951904
Validation loss: 2.165846772091363

Epoch: 6| Step: 4
Training loss: 2.2900824546813965
Validation loss: 2.175225629601427

Epoch: 6| Step: 5
Training loss: 2.158095359802246
Validation loss: 2.155183594713929

Epoch: 6| Step: 6
Training loss: 1.6221219301223755
Validation loss: 2.155789359923332

Epoch: 6| Step: 7
Training loss: 2.1676149368286133
Validation loss: 2.166924568914598

Epoch: 6| Step: 8
Training loss: 2.74362850189209
Validation loss: 2.1375378844558552

Epoch: 6| Step: 9
Training loss: 1.9749367237091064
Validation loss: 2.1747551092537503

Epoch: 6| Step: 10
Training loss: 1.9112869501113892
Validation loss: 2.1497784404344458

Epoch: 6| Step: 11
Training loss: 2.3230347633361816
Validation loss: 2.1560700170455442

Epoch: 6| Step: 12
Training loss: 2.985628604888916
Validation loss: 2.156738514541298

Epoch: 6| Step: 13
Training loss: 2.8565421104431152
Validation loss: 2.161058082375475

Epoch: 47| Step: 0
Training loss: 2.557734727859497
Validation loss: 2.1557841864965295

Epoch: 6| Step: 1
Training loss: 2.5372092723846436
Validation loss: 2.1775269008451894

Epoch: 6| Step: 2
Training loss: 2.0645956993103027
Validation loss: 2.1736520977430445

Epoch: 6| Step: 3
Training loss: 2.1859259605407715
Validation loss: 2.1550520620038434

Epoch: 6| Step: 4
Training loss: 1.363135576248169
Validation loss: 2.1465388959453953

Epoch: 6| Step: 5
Training loss: 2.517117500305176
Validation loss: 2.1370580516835695

Epoch: 6| Step: 6
Training loss: 2.4696333408355713
Validation loss: 2.1662673206739527

Epoch: 6| Step: 7
Training loss: 2.2541606426239014
Validation loss: 2.157846843042681

Epoch: 6| Step: 8
Training loss: 2.540668249130249
Validation loss: 2.1607860224221342

Epoch: 6| Step: 9
Training loss: 2.089047431945801
Validation loss: 2.1538003080634662

Epoch: 6| Step: 10
Training loss: 2.966494083404541
Validation loss: 2.1704924939781107

Epoch: 6| Step: 11
Training loss: 2.4266200065612793
Validation loss: 2.1531213739866852

Epoch: 6| Step: 12
Training loss: 2.522461414337158
Validation loss: 2.17610667597863

Epoch: 6| Step: 13
Training loss: 1.5123143196105957
Validation loss: 2.170868414704518

Epoch: 48| Step: 0
Training loss: 2.2617886066436768
Validation loss: 2.181600178441694

Epoch: 6| Step: 1
Training loss: 2.9952449798583984
Validation loss: 2.1511773960564726

Epoch: 6| Step: 2
Training loss: 1.7715182304382324
Validation loss: 2.1530101606922765

Epoch: 6| Step: 3
Training loss: 2.4266459941864014
Validation loss: 2.1579102162391908

Epoch: 6| Step: 4
Training loss: 1.8152235746383667
Validation loss: 2.1567132293537097

Epoch: 6| Step: 5
Training loss: 1.975837230682373
Validation loss: 2.1628360491926952

Epoch: 6| Step: 6
Training loss: 2.4318394660949707
Validation loss: 2.1718885488407587

Epoch: 6| Step: 7
Training loss: 2.4509756565093994
Validation loss: 2.1548725969047955

Epoch: 6| Step: 8
Training loss: 2.3531494140625
Validation loss: 2.181548915883546

Epoch: 6| Step: 9
Training loss: 2.4839718341827393
Validation loss: 2.1644180795197845

Epoch: 6| Step: 10
Training loss: 2.7365331649780273
Validation loss: 2.165933983300322

Epoch: 6| Step: 11
Training loss: 2.2856905460357666
Validation loss: 2.1532415087505052

Epoch: 6| Step: 12
Training loss: 2.278559684753418
Validation loss: 2.1520892368849887

Epoch: 6| Step: 13
Training loss: 1.8783879280090332
Validation loss: 2.1622565766816497

Epoch: 49| Step: 0
Training loss: 2.097057819366455
Validation loss: 2.154316209977673

Epoch: 6| Step: 1
Training loss: 2.3381216526031494
Validation loss: 2.1685107087576263

Epoch: 6| Step: 2
Training loss: 3.2503418922424316
Validation loss: 2.1752254040010515

Epoch: 6| Step: 3
Training loss: 2.0523738861083984
Validation loss: 2.1628557943528697

Epoch: 6| Step: 4
Training loss: 2.5973105430603027
Validation loss: 2.129618554986933

Epoch: 6| Step: 5
Training loss: 2.557591438293457
Validation loss: 2.1517288172116844

Epoch: 6| Step: 6
Training loss: 1.951572299003601
Validation loss: 2.1537771635158087

Epoch: 6| Step: 7
Training loss: 2.596325397491455
Validation loss: 2.139120424947431

Epoch: 6| Step: 8
Training loss: 2.1277220249176025
Validation loss: 2.1599824095285065

Epoch: 6| Step: 9
Training loss: 2.34979510307312
Validation loss: 2.1425424339950725

Epoch: 6| Step: 10
Training loss: 1.6669567823410034
Validation loss: 2.158841258736067

Epoch: 6| Step: 11
Training loss: 2.3233437538146973
Validation loss: 2.1860125500668763

Epoch: 6| Step: 12
Training loss: 1.9819531440734863
Validation loss: 2.160701515854046

Epoch: 6| Step: 13
Training loss: 2.5082929134368896
Validation loss: 2.1576455075253724

Epoch: 50| Step: 0
Training loss: 2.3249287605285645
Validation loss: 2.1548321734192553

Epoch: 6| Step: 1
Training loss: 2.3323426246643066
Validation loss: 2.1440690076479347

Epoch: 6| Step: 2
Training loss: 1.9370019435882568
Validation loss: 2.152947715533677

Epoch: 6| Step: 3
Training loss: 2.1883063316345215
Validation loss: 2.1669738959240656

Epoch: 6| Step: 4
Training loss: 2.2748146057128906
Validation loss: 2.1624563176144838

Epoch: 6| Step: 5
Training loss: 2.1799569129943848
Validation loss: 2.1624829435861237

Epoch: 6| Step: 6
Training loss: 2.154231548309326
Validation loss: 2.1455269526409846

Epoch: 6| Step: 7
Training loss: 2.250725746154785
Validation loss: 2.162340385939485

Epoch: 6| Step: 8
Training loss: 2.816399335861206
Validation loss: 2.162730638698865

Epoch: 6| Step: 9
Training loss: 2.3987464904785156
Validation loss: 2.141204700675062

Epoch: 6| Step: 10
Training loss: 2.5410475730895996
Validation loss: 2.1495788148654404

Epoch: 6| Step: 11
Training loss: 2.810786724090576
Validation loss: 2.1446898829552437

Epoch: 6| Step: 12
Training loss: 2.1106274127960205
Validation loss: 2.141206558032702

Epoch: 6| Step: 13
Training loss: 1.8994107246398926
Validation loss: 2.161886190855375

Epoch: 51| Step: 0
Training loss: 3.3974497318267822
Validation loss: 2.166779528382004

Epoch: 6| Step: 1
Training loss: 2.3456554412841797
Validation loss: 2.15680673942771

Epoch: 6| Step: 2
Training loss: 1.9267855882644653
Validation loss: 2.1595660819802234

Epoch: 6| Step: 3
Training loss: 1.9480493068695068
Validation loss: 2.1556865989520984

Epoch: 6| Step: 4
Training loss: 2.0198631286621094
Validation loss: 2.157910094466261

Epoch: 6| Step: 5
Training loss: 2.3349647521972656
Validation loss: 2.1677290342187368

Epoch: 6| Step: 6
Training loss: 2.1551685333251953
Validation loss: 2.157677121059869

Epoch: 6| Step: 7
Training loss: 2.187095880508423
Validation loss: 2.16906484224463

Epoch: 6| Step: 8
Training loss: 2.234457492828369
Validation loss: 2.123256083457701

Epoch: 6| Step: 9
Training loss: 2.7278473377227783
Validation loss: 2.1625486855865805

Epoch: 6| Step: 10
Training loss: 2.219158411026001
Validation loss: 2.167196527604134

Epoch: 6| Step: 11
Training loss: 2.017483711242676
Validation loss: 2.155027343380836

Epoch: 6| Step: 12
Training loss: 1.8561841249465942
Validation loss: 2.1509841154980403

Epoch: 6| Step: 13
Training loss: 3.279297113418579
Validation loss: 2.163603218652869

Epoch: 52| Step: 0
Training loss: 2.3391668796539307
Validation loss: 2.1553541485981276

Epoch: 6| Step: 1
Training loss: 2.632443428039551
Validation loss: 2.1449993912891676

Epoch: 6| Step: 2
Training loss: 2.6630921363830566
Validation loss: 2.159506279935119

Epoch: 6| Step: 3
Training loss: 1.8973091840744019
Validation loss: 2.1641642688423075

Epoch: 6| Step: 4
Training loss: 2.0472395420074463
Validation loss: 2.1575309999527468

Epoch: 6| Step: 5
Training loss: 3.3021557331085205
Validation loss: 2.1369705456559376

Epoch: 6| Step: 6
Training loss: 2.5034005641937256
Validation loss: 2.139742825620918

Epoch: 6| Step: 7
Training loss: 2.4347856044769287
Validation loss: 2.149074064787998

Epoch: 6| Step: 8
Training loss: 2.868961811065674
Validation loss: 2.1583121617635093

Epoch: 6| Step: 9
Training loss: 1.8845196962356567
Validation loss: 2.148113199459609

Epoch: 6| Step: 10
Training loss: 1.6647515296936035
Validation loss: 2.1514366442157375

Epoch: 6| Step: 11
Training loss: 2.1807641983032227
Validation loss: 2.1623643713612712

Epoch: 6| Step: 12
Training loss: 2.137707233428955
Validation loss: 2.1716066214346115

Epoch: 6| Step: 13
Training loss: 1.197164535522461
Validation loss: 2.161514857763885

Epoch: 53| Step: 0
Training loss: 1.236467719078064
Validation loss: 2.1617065091286936

Epoch: 6| Step: 1
Training loss: 2.163694381713867
Validation loss: 2.1289033043769097

Epoch: 6| Step: 2
Training loss: 2.3774309158325195
Validation loss: 2.1690756505535496

Epoch: 6| Step: 3
Training loss: 2.4562087059020996
Validation loss: 2.1443528436845347

Epoch: 6| Step: 4
Training loss: 2.5620803833007812
Validation loss: 2.1400435304128997

Epoch: 6| Step: 5
Training loss: 2.087940216064453
Validation loss: 2.1659212778973322

Epoch: 6| Step: 6
Training loss: 2.6439590454101562
Validation loss: 2.1565648509610083

Epoch: 6| Step: 7
Training loss: 1.599221110343933
Validation loss: 2.141734225775606

Epoch: 6| Step: 8
Training loss: 2.7702784538269043
Validation loss: 2.1502728039218533

Epoch: 6| Step: 9
Training loss: 2.187880754470825
Validation loss: 2.151996556148734

Epoch: 6| Step: 10
Training loss: 2.1090903282165527
Validation loss: 2.1468138284580682

Epoch: 6| Step: 11
Training loss: 2.4991097450256348
Validation loss: 2.14994522576691

Epoch: 6| Step: 12
Training loss: 3.090639591217041
Validation loss: 2.1465532010601414

Epoch: 6| Step: 13
Training loss: 2.5031299591064453
Validation loss: 2.14218904126075

Epoch: 54| Step: 0
Training loss: 3.0223774909973145
Validation loss: 2.1533685166348695

Epoch: 6| Step: 1
Training loss: 1.6310032606124878
Validation loss: 2.153979862889936

Epoch: 6| Step: 2
Training loss: 2.3102526664733887
Validation loss: 2.139684005450177

Epoch: 6| Step: 3
Training loss: 2.710843086242676
Validation loss: 2.152739514586746

Epoch: 6| Step: 4
Training loss: 2.605705499649048
Validation loss: 2.1570394116063274

Epoch: 6| Step: 5
Training loss: 2.1940553188323975
Validation loss: 2.1564290203073972

Epoch: 6| Step: 6
Training loss: 1.8014605045318604
Validation loss: 2.1617964518967496

Epoch: 6| Step: 7
Training loss: 1.9589276313781738
Validation loss: 2.146135425054899

Epoch: 6| Step: 8
Training loss: 2.8999762535095215
Validation loss: 2.1783248814203406

Epoch: 6| Step: 9
Training loss: 2.4429497718811035
Validation loss: 2.1650459304932625

Epoch: 6| Step: 10
Training loss: 2.5652194023132324
Validation loss: 2.1450512614301456

Epoch: 6| Step: 11
Training loss: 2.334498405456543
Validation loss: 2.1561876932779946

Epoch: 6| Step: 12
Training loss: 1.6866672039031982
Validation loss: 2.146307191541118

Epoch: 6| Step: 13
Training loss: 1.7647150754928589
Validation loss: 2.148167533259238

Epoch: 55| Step: 0
Training loss: 2.618429183959961
Validation loss: 2.1390997914857763

Epoch: 6| Step: 1
Training loss: 2.180396795272827
Validation loss: 2.150537831808931

Epoch: 6| Step: 2
Training loss: 2.5967135429382324
Validation loss: 2.1450959226136566

Epoch: 6| Step: 3
Training loss: 2.3673698902130127
Validation loss: 2.1351824216945197

Epoch: 6| Step: 4
Training loss: 2.2824301719665527
Validation loss: 2.160185644703527

Epoch: 6| Step: 5
Training loss: 2.057285785675049
Validation loss: 2.145688961910945

Epoch: 6| Step: 6
Training loss: 1.9670238494873047
Validation loss: 2.1462141736861198

Epoch: 6| Step: 7
Training loss: 1.7620670795440674
Validation loss: 2.1365795648226173

Epoch: 6| Step: 8
Training loss: 2.102430820465088
Validation loss: 2.1753553318720993

Epoch: 6| Step: 9
Training loss: 2.096327781677246
Validation loss: 2.152773872498543

Epoch: 6| Step: 10
Training loss: 2.625328302383423
Validation loss: 2.145814126537692

Epoch: 6| Step: 11
Training loss: 2.6238577365875244
Validation loss: 2.1629285427831833

Epoch: 6| Step: 12
Training loss: 2.6227245330810547
Validation loss: 2.155250759534938

Epoch: 6| Step: 13
Training loss: 2.2197885513305664
Validation loss: 2.15087446858806

Epoch: 56| Step: 0
Training loss: 3.027301073074341
Validation loss: 2.1504359655482794

Epoch: 6| Step: 1
Training loss: 2.1978988647460938
Validation loss: 2.1446639440392934

Epoch: 6| Step: 2
Training loss: 2.5211730003356934
Validation loss: 2.158211156886111

Epoch: 6| Step: 3
Training loss: 1.7124848365783691
Validation loss: 2.177287901601484

Epoch: 6| Step: 4
Training loss: 2.3652350902557373
Validation loss: 2.1490413758062545

Epoch: 6| Step: 5
Training loss: 2.4457478523254395
Validation loss: 2.156098700338794

Epoch: 6| Step: 6
Training loss: 1.8452224731445312
Validation loss: 2.14960265415971

Epoch: 6| Step: 7
Training loss: 2.630953311920166
Validation loss: 2.1731084367280364

Epoch: 6| Step: 8
Training loss: 2.09055495262146
Validation loss: 2.1578704746820594

Epoch: 6| Step: 9
Training loss: 2.8483691215515137
Validation loss: 2.178020961823002

Epoch: 6| Step: 10
Training loss: 2.3206024169921875
Validation loss: 2.1710597571506294

Epoch: 6| Step: 11
Training loss: 1.5138919353485107
Validation loss: 2.1525632284020864

Epoch: 6| Step: 12
Training loss: 2.2488503456115723
Validation loss: 2.1599192439868884

Epoch: 6| Step: 13
Training loss: 1.9893114566802979
Validation loss: 2.178068117428851

Epoch: 57| Step: 0
Training loss: 1.9152156114578247
Validation loss: 2.1433623785613687

Epoch: 6| Step: 1
Training loss: 1.9261789321899414
Validation loss: 2.158109385480163

Epoch: 6| Step: 2
Training loss: 2.949258327484131
Validation loss: 2.168227644376857

Epoch: 6| Step: 3
Training loss: 2.0375170707702637
Validation loss: 2.1572059508292907

Epoch: 6| Step: 4
Training loss: 2.316758632659912
Validation loss: 2.1546837950265534

Epoch: 6| Step: 5
Training loss: 2.8712358474731445
Validation loss: 2.171777794438024

Epoch: 6| Step: 6
Training loss: 1.4448559284210205
Validation loss: 2.161171784964941

Epoch: 6| Step: 7
Training loss: 2.483940362930298
Validation loss: 2.136452287755987

Epoch: 6| Step: 8
Training loss: 1.8617841005325317
Validation loss: 2.1345861368281867

Epoch: 6| Step: 9
Training loss: 2.264237880706787
Validation loss: 2.140651974626767

Epoch: 6| Step: 10
Training loss: 2.1960933208465576
Validation loss: 2.155543086349323

Epoch: 6| Step: 11
Training loss: 2.2861578464508057
Validation loss: 2.1571354071299234

Epoch: 6| Step: 12
Training loss: 3.177912473678589
Validation loss: 2.15246852238973

Epoch: 6| Step: 13
Training loss: 2.34755802154541
Validation loss: 2.149408701927431

Epoch: 58| Step: 0
Training loss: 2.0906708240509033
Validation loss: 2.1381972220636185

Epoch: 6| Step: 1
Training loss: 1.7987183332443237
Validation loss: 2.1521780747239307

Epoch: 6| Step: 2
Training loss: 1.8882149457931519
Validation loss: 2.1584803429982995

Epoch: 6| Step: 3
Training loss: 2.3452272415161133
Validation loss: 2.1564489564587994

Epoch: 6| Step: 4
Training loss: 2.520026206970215
Validation loss: 2.146625831562986

Epoch: 6| Step: 5
Training loss: 2.002955436706543
Validation loss: 2.1744738342941448

Epoch: 6| Step: 6
Training loss: 1.5466437339782715
Validation loss: 2.160365266184653

Epoch: 6| Step: 7
Training loss: 2.898318290710449
Validation loss: 2.1692282922806276

Epoch: 6| Step: 8
Training loss: 2.6122665405273438
Validation loss: 2.1409772160232707

Epoch: 6| Step: 9
Training loss: 2.6187584400177
Validation loss: 2.150334540233817

Epoch: 6| Step: 10
Training loss: 1.8288490772247314
Validation loss: 2.1518095231825307

Epoch: 6| Step: 11
Training loss: 2.7983555793762207
Validation loss: 2.1535453129840154

Epoch: 6| Step: 12
Training loss: 2.8613975048065186
Validation loss: 2.1462228503278507

Epoch: 6| Step: 13
Training loss: 2.1982908248901367
Validation loss: 2.1453252735958306

Epoch: 59| Step: 0
Training loss: 2.016627788543701
Validation loss: 2.160685016262916

Epoch: 6| Step: 1
Training loss: 2.1015539169311523
Validation loss: 2.1530288060506186

Epoch: 6| Step: 2
Training loss: 1.9872936010360718
Validation loss: 2.1527320697743404

Epoch: 6| Step: 3
Training loss: 2.634884834289551
Validation loss: 2.1611648195533344

Epoch: 6| Step: 4
Training loss: 3.0627188682556152
Validation loss: 2.1318644118565384

Epoch: 6| Step: 5
Training loss: 2.541147470474243
Validation loss: 2.163961714313876

Epoch: 6| Step: 6
Training loss: 1.7786105871200562
Validation loss: 2.1496458079225276

Epoch: 6| Step: 7
Training loss: 2.290344715118408
Validation loss: 2.1722833623168287

Epoch: 6| Step: 8
Training loss: 2.242310047149658
Validation loss: 2.149473559471869

Epoch: 6| Step: 9
Training loss: 2.595280647277832
Validation loss: 2.1620779191294024

Epoch: 6| Step: 10
Training loss: 2.108072280883789
Validation loss: 2.1546424819577124

Epoch: 6| Step: 11
Training loss: 2.3983442783355713
Validation loss: 2.152987350699722

Epoch: 6| Step: 12
Training loss: 1.8405168056488037
Validation loss: 2.168055962490779

Epoch: 6| Step: 13
Training loss: 2.387303590774536
Validation loss: 2.158163300124548

Epoch: 60| Step: 0
Training loss: 2.2400195598602295
Validation loss: 2.1563820890201035

Epoch: 6| Step: 1
Training loss: 1.8725637197494507
Validation loss: 2.153478117399318

Epoch: 6| Step: 2
Training loss: 1.9333982467651367
Validation loss: 2.1535329331633863

Epoch: 6| Step: 3
Training loss: 2.5021488666534424
Validation loss: 2.138635238011678

Epoch: 6| Step: 4
Training loss: 2.2285642623901367
Validation loss: 2.164498193289644

Epoch: 6| Step: 5
Training loss: 2.9345858097076416
Validation loss: 2.1694672953697944

Epoch: 6| Step: 6
Training loss: 2.2835500240325928
Validation loss: 2.1291484794309063

Epoch: 6| Step: 7
Training loss: 2.840585231781006
Validation loss: 2.1479732195536294

Epoch: 6| Step: 8
Training loss: 2.1981735229492188
Validation loss: 2.1556077823844007

Epoch: 6| Step: 9
Training loss: 2.9695920944213867
Validation loss: 2.1597838017248336

Epoch: 6| Step: 10
Training loss: 2.017435312271118
Validation loss: 2.147274504425705

Epoch: 6| Step: 11
Training loss: 2.0268938541412354
Validation loss: 2.152684473222302

Epoch: 6| Step: 12
Training loss: 1.9447065591812134
Validation loss: 2.1473150202023086

Epoch: 6| Step: 13
Training loss: 1.8100076913833618
Validation loss: 2.169324582622897

Epoch: 61| Step: 0
Training loss: 2.2915573120117188
Validation loss: 2.175614914586467

Epoch: 6| Step: 1
Training loss: 1.939150094985962
Validation loss: 2.1674583240221907

Epoch: 6| Step: 2
Training loss: 1.9255229234695435
Validation loss: 2.1591214749120895

Epoch: 6| Step: 3
Training loss: 2.347179651260376
Validation loss: 2.146249004589614

Epoch: 6| Step: 4
Training loss: 1.9340089559555054
Validation loss: 2.1571042883780693

Epoch: 6| Step: 5
Training loss: 2.7432167530059814
Validation loss: 2.150646407117126

Epoch: 6| Step: 6
Training loss: 2.714613437652588
Validation loss: 2.1608465743321243

Epoch: 6| Step: 7
Training loss: 1.7584259510040283
Validation loss: 2.1707172752708517

Epoch: 6| Step: 8
Training loss: 2.1494719982147217
Validation loss: 2.178131385516095

Epoch: 6| Step: 9
Training loss: 2.293933153152466
Validation loss: 2.165591961594038

Epoch: 6| Step: 10
Training loss: 2.8905062675476074
Validation loss: 2.164045291562234

Epoch: 6| Step: 11
Training loss: 2.112015724182129
Validation loss: 2.1481051855189826

Epoch: 6| Step: 12
Training loss: 2.6719303131103516
Validation loss: 2.1485266993122716

Epoch: 6| Step: 13
Training loss: 1.9867242574691772
Validation loss: 2.1588913240740375

Epoch: 62| Step: 0
Training loss: 1.5966147184371948
Validation loss: 2.1849579785459783

Epoch: 6| Step: 1
Training loss: 2.2648708820343018
Validation loss: 2.183648027399535

Epoch: 6| Step: 2
Training loss: 2.235942840576172
Validation loss: 2.1757407778052875

Epoch: 6| Step: 3
Training loss: 2.4409070014953613
Validation loss: 2.1630162833839335

Epoch: 6| Step: 4
Training loss: 2.869028091430664
Validation loss: 2.1565038055501957

Epoch: 6| Step: 5
Training loss: 2.0516750812530518
Validation loss: 2.15754517175818

Epoch: 6| Step: 6
Training loss: 2.206833839416504
Validation loss: 2.1575402162408315

Epoch: 6| Step: 7
Training loss: 2.598710536956787
Validation loss: 2.161210416465677

Epoch: 6| Step: 8
Training loss: 2.272467613220215
Validation loss: 2.1669480903174287

Epoch: 6| Step: 9
Training loss: 3.0958495140075684
Validation loss: 2.1560801690624607

Epoch: 6| Step: 10
Training loss: 2.9770381450653076
Validation loss: 2.163760414687536

Epoch: 6| Step: 11
Training loss: 1.973497986793518
Validation loss: 2.1623371237067768

Epoch: 6| Step: 12
Training loss: 1.1977708339691162
Validation loss: 2.1567803877656178

Epoch: 6| Step: 13
Training loss: 1.5499262809753418
Validation loss: 2.1621192552710093

Epoch: 63| Step: 0
Training loss: 2.2473864555358887
Validation loss: 2.1482036562376123

Epoch: 6| Step: 1
Training loss: 2.265766143798828
Validation loss: 2.159091564916795

Epoch: 6| Step: 2
Training loss: 2.2954909801483154
Validation loss: 2.1490603954561296

Epoch: 6| Step: 3
Training loss: 2.7098376750946045
Validation loss: 2.1398697309596564

Epoch: 6| Step: 4
Training loss: 1.843209981918335
Validation loss: 2.1531194820198962

Epoch: 6| Step: 5
Training loss: 2.1626131534576416
Validation loss: 2.1455319132856143

Epoch: 6| Step: 6
Training loss: 1.9445574283599854
Validation loss: 2.169120419409967

Epoch: 6| Step: 7
Training loss: 2.433633804321289
Validation loss: 2.1542195145801832

Epoch: 6| Step: 8
Training loss: 3.5125539302825928
Validation loss: 2.1506788115347586

Epoch: 6| Step: 9
Training loss: 2.210019588470459
Validation loss: 2.1539904148347917

Epoch: 6| Step: 10
Training loss: 1.7301265001296997
Validation loss: 2.1501968676044094

Epoch: 6| Step: 11
Training loss: 2.0964438915252686
Validation loss: 2.153534455965924

Epoch: 6| Step: 12
Training loss: 2.2600815296173096
Validation loss: 2.1587323783546366

Epoch: 6| Step: 13
Training loss: 1.6898964643478394
Validation loss: 2.1522201286849154

Epoch: 64| Step: 0
Training loss: 2.6028389930725098
Validation loss: 2.157009942557222

Epoch: 6| Step: 1
Training loss: 1.9827287197113037
Validation loss: 2.1522863629043743

Epoch: 6| Step: 2
Training loss: 1.9063472747802734
Validation loss: 2.1503760686484714

Epoch: 6| Step: 3
Training loss: 2.840916156768799
Validation loss: 2.139897825897381

Epoch: 6| Step: 4
Training loss: 1.9290634393692017
Validation loss: 2.1633678226060766

Epoch: 6| Step: 5
Training loss: 2.254362106323242
Validation loss: 2.144410225652879

Epoch: 6| Step: 6
Training loss: 2.659830093383789
Validation loss: 2.141179712869788

Epoch: 6| Step: 7
Training loss: 2.5508131980895996
Validation loss: 2.1415949534344416

Epoch: 6| Step: 8
Training loss: 2.1065783500671387
Validation loss: 2.1536012900772916

Epoch: 6| Step: 9
Training loss: 1.8509957790374756
Validation loss: 2.161450657793271

Epoch: 6| Step: 10
Training loss: 2.1776790618896484
Validation loss: 2.164903789438227

Epoch: 6| Step: 11
Training loss: 1.942694902420044
Validation loss: 2.1594904699633197

Epoch: 6| Step: 12
Training loss: 2.2358365058898926
Validation loss: 2.1540583513116323

Epoch: 6| Step: 13
Training loss: 2.808840751647949
Validation loss: 2.1593217401094336

Epoch: 65| Step: 0
Training loss: 2.0715651512145996
Validation loss: 2.1608609281560427

Epoch: 6| Step: 1
Training loss: 1.564042091369629
Validation loss: 2.150310008756576

Epoch: 6| Step: 2
Training loss: 2.459280014038086
Validation loss: 2.1395792550938104

Epoch: 6| Step: 3
Training loss: 2.4158291816711426
Validation loss: 2.1406383950223207

Epoch: 6| Step: 4
Training loss: 2.294039726257324
Validation loss: 2.1524340465504634

Epoch: 6| Step: 5
Training loss: 2.1614584922790527
Validation loss: 2.1595035868306316

Epoch: 6| Step: 6
Training loss: 2.611961603164673
Validation loss: 2.145757549552507

Epoch: 6| Step: 7
Training loss: 3.1952786445617676
Validation loss: 2.154275503209842

Epoch: 6| Step: 8
Training loss: 2.186414957046509
Validation loss: 2.14293425057524

Epoch: 6| Step: 9
Training loss: 2.2988076210021973
Validation loss: 2.149926979054687

Epoch: 6| Step: 10
Training loss: 2.0641980171203613
Validation loss: 2.148450912967805

Epoch: 6| Step: 11
Training loss: 1.9678069353103638
Validation loss: 2.1559051518799155

Epoch: 6| Step: 12
Training loss: 2.1868386268615723
Validation loss: 2.159176436803674

Epoch: 6| Step: 13
Training loss: 2.2580442428588867
Validation loss: 2.151764859435379

Epoch: 66| Step: 0
Training loss: 2.3491599559783936
Validation loss: 2.1546813544406684

Epoch: 6| Step: 1
Training loss: 1.9713129997253418
Validation loss: 2.166351615741689

Epoch: 6| Step: 2
Training loss: 2.3882930278778076
Validation loss: 2.1499215018364692

Epoch: 6| Step: 3
Training loss: 1.7407623529434204
Validation loss: 2.14064686529098

Epoch: 6| Step: 4
Training loss: 1.880312442779541
Validation loss: 2.1509763489487352

Epoch: 6| Step: 5
Training loss: 1.8021788597106934
Validation loss: 2.1471838284564275

Epoch: 6| Step: 6
Training loss: 3.081860065460205
Validation loss: 2.162735487825127

Epoch: 6| Step: 7
Training loss: 2.602198600769043
Validation loss: 2.171550222622451

Epoch: 6| Step: 8
Training loss: 1.9714763164520264
Validation loss: 2.1475504175309212

Epoch: 6| Step: 9
Training loss: 2.232962131500244
Validation loss: 2.1521056749487437

Epoch: 6| Step: 10
Training loss: 1.8577569723129272
Validation loss: 2.154631576230449

Epoch: 6| Step: 11
Training loss: 2.174165964126587
Validation loss: 2.1571674411014845

Epoch: 6| Step: 12
Training loss: 2.8346471786499023
Validation loss: 2.1619005587793167

Epoch: 6| Step: 13
Training loss: 2.985218048095703
Validation loss: 2.1576758687214186

Epoch: 67| Step: 0
Training loss: 2.1179006099700928
Validation loss: 2.1490906028337378

Epoch: 6| Step: 1
Training loss: 2.255112886428833
Validation loss: 2.1563880802482687

Epoch: 6| Step: 2
Training loss: 1.8866406679153442
Validation loss: 2.1488055516314764

Epoch: 6| Step: 3
Training loss: 1.913586139678955
Validation loss: 2.171396897685143

Epoch: 6| Step: 4
Training loss: 2.2968368530273438
Validation loss: 2.142970969600062

Epoch: 6| Step: 5
Training loss: 2.3799445629119873
Validation loss: 2.1739763752106698

Epoch: 6| Step: 6
Training loss: 3.342872142791748
Validation loss: 2.163821489580216

Epoch: 6| Step: 7
Training loss: 2.5527472496032715
Validation loss: 2.15818372080403

Epoch: 6| Step: 8
Training loss: 2.2182698249816895
Validation loss: 2.168285313472953

Epoch: 6| Step: 9
Training loss: 2.0109448432922363
Validation loss: 2.147396678565651

Epoch: 6| Step: 10
Training loss: 1.7819161415100098
Validation loss: 2.1707593779410086

Epoch: 6| Step: 11
Training loss: 1.8747968673706055
Validation loss: 2.161654476196535

Epoch: 6| Step: 12
Training loss: 2.5025625228881836
Validation loss: 2.153482339715445

Epoch: 6| Step: 13
Training loss: 2.833242654800415
Validation loss: 2.153244488982744

Epoch: 68| Step: 0
Training loss: 1.6908297538757324
Validation loss: 2.155499175030698

Epoch: 6| Step: 1
Training loss: 2.246469497680664
Validation loss: 2.1501777889908

Epoch: 6| Step: 2
Training loss: 2.2612521648406982
Validation loss: 2.1800971672099125

Epoch: 6| Step: 3
Training loss: 2.125792980194092
Validation loss: 2.1463331740389586

Epoch: 6| Step: 4
Training loss: 2.168072462081909
Validation loss: 2.1486980863796767

Epoch: 6| Step: 5
Training loss: 2.0898168087005615
Validation loss: 2.149291637123272

Epoch: 6| Step: 6
Training loss: 2.1714611053466797
Validation loss: 2.1537698340672318

Epoch: 6| Step: 7
Training loss: 3.0098206996917725
Validation loss: 2.1591182549794516

Epoch: 6| Step: 8
Training loss: 1.8302545547485352
Validation loss: 2.1589777328634776

Epoch: 6| Step: 9
Training loss: 2.6030993461608887
Validation loss: 2.1539824906215874

Epoch: 6| Step: 10
Training loss: 2.6597156524658203
Validation loss: 2.1522506488266813

Epoch: 6| Step: 11
Training loss: 2.089977741241455
Validation loss: 2.154434818093495

Epoch: 6| Step: 12
Training loss: 2.5486247539520264
Validation loss: 2.167046948145795

Epoch: 6| Step: 13
Training loss: 2.0723555088043213
Validation loss: 2.157096794856492

Epoch: 69| Step: 0
Training loss: 2.1247308254241943
Validation loss: 2.156281543034379

Epoch: 6| Step: 1
Training loss: 2.162740707397461
Validation loss: 2.1582015201609623

Epoch: 6| Step: 2
Training loss: 2.474991798400879
Validation loss: 2.153054263002129

Epoch: 6| Step: 3
Training loss: 2.2268877029418945
Validation loss: 2.1707965866211922

Epoch: 6| Step: 4
Training loss: 2.2856321334838867
Validation loss: 2.1596490080638597

Epoch: 6| Step: 5
Training loss: 2.55941104888916
Validation loss: 2.1479894038169616

Epoch: 6| Step: 6
Training loss: 2.4358747005462646
Validation loss: 2.1743055389773462

Epoch: 6| Step: 7
Training loss: 2.4531729221343994
Validation loss: 2.1606400064242783

Epoch: 6| Step: 8
Training loss: 2.1701831817626953
Validation loss: 2.143079685908492

Epoch: 6| Step: 9
Training loss: 2.2176949977874756
Validation loss: 2.1532882003374

Epoch: 6| Step: 10
Training loss: 1.4627392292022705
Validation loss: 2.158140915696339

Epoch: 6| Step: 11
Training loss: 1.8513622283935547
Validation loss: 2.1381427870001843

Epoch: 6| Step: 12
Training loss: 2.721550226211548
Validation loss: 2.1582305559548

Epoch: 6| Step: 13
Training loss: 2.578775644302368
Validation loss: 2.1709555015769055

Epoch: 70| Step: 0
Training loss: 2.537858486175537
Validation loss: 2.1565224791085846

Epoch: 6| Step: 1
Training loss: 2.7889015674591064
Validation loss: 2.142244246698195

Epoch: 6| Step: 2
Training loss: 1.8494048118591309
Validation loss: 2.133685838791632

Epoch: 6| Step: 3
Training loss: 1.6413469314575195
Validation loss: 2.1704673331270934

Epoch: 6| Step: 4
Training loss: 1.993041753768921
Validation loss: 2.164417994919644

Epoch: 6| Step: 5
Training loss: 2.4268240928649902
Validation loss: 2.175922568126391

Epoch: 6| Step: 6
Training loss: 2.5612051486968994
Validation loss: 2.152674654478668

Epoch: 6| Step: 7
Training loss: 3.0014281272888184
Validation loss: 2.155264840331129

Epoch: 6| Step: 8
Training loss: 2.004031181335449
Validation loss: 2.16694692514276

Epoch: 6| Step: 9
Training loss: 2.417696475982666
Validation loss: 2.1514802286701817

Epoch: 6| Step: 10
Training loss: 2.3066370487213135
Validation loss: 2.1505569386225876

Epoch: 6| Step: 11
Training loss: 2.074022054672241
Validation loss: 2.141728870330318

Epoch: 6| Step: 12
Training loss: 1.6237883567810059
Validation loss: 2.159818003254552

Epoch: 6| Step: 13
Training loss: 2.0044898986816406
Validation loss: 2.1604201178396902

Epoch: 71| Step: 0
Training loss: 2.4022483825683594
Validation loss: 2.155196182189449

Epoch: 6| Step: 1
Training loss: 2.289429187774658
Validation loss: 2.153190210301389

Epoch: 6| Step: 2
Training loss: 2.454763889312744
Validation loss: 2.166492723649548

Epoch: 6| Step: 3
Training loss: 2.4518771171569824
Validation loss: 2.1478140354156494

Epoch: 6| Step: 4
Training loss: 2.3764843940734863
Validation loss: 2.145696509268976

Epoch: 6| Step: 5
Training loss: 2.239015817642212
Validation loss: 2.1529879852007796

Epoch: 6| Step: 6
Training loss: 2.0859146118164062
Validation loss: 2.1399420679256482

Epoch: 6| Step: 7
Training loss: 2.1195497512817383
Validation loss: 2.1620503215379614

Epoch: 6| Step: 8
Training loss: 1.8178980350494385
Validation loss: 2.1398712845258814

Epoch: 6| Step: 9
Training loss: 1.9353376626968384
Validation loss: 2.160996413999988

Epoch: 6| Step: 10
Training loss: 2.6536176204681396
Validation loss: 2.1558201492473645

Epoch: 6| Step: 11
Training loss: 2.101088285446167
Validation loss: 2.1382947737170803

Epoch: 6| Step: 12
Training loss: 2.9244892597198486
Validation loss: 2.1637204462482083

Epoch: 6| Step: 13
Training loss: 1.4225695133209229
Validation loss: 2.1521137068348546

Epoch: 72| Step: 0
Training loss: 2.4608654975891113
Validation loss: 2.1411698889988724

Epoch: 6| Step: 1
Training loss: 1.662068247795105
Validation loss: 2.154657090863874

Epoch: 6| Step: 2
Training loss: 2.0598206520080566
Validation loss: 2.144825582863182

Epoch: 6| Step: 3
Training loss: 3.1266329288482666
Validation loss: 2.1460908689806537

Epoch: 6| Step: 4
Training loss: 2.180304765701294
Validation loss: 2.16138401210949

Epoch: 6| Step: 5
Training loss: 1.880765438079834
Validation loss: 2.159207326109691

Epoch: 6| Step: 6
Training loss: 2.8046607971191406
Validation loss: 2.173253540069826

Epoch: 6| Step: 7
Training loss: 1.667322039604187
Validation loss: 2.1685264969384797

Epoch: 6| Step: 8
Training loss: 2.1303982734680176
Validation loss: 2.1587931263831353

Epoch: 6| Step: 9
Training loss: 2.0302464962005615
Validation loss: 2.1404366275315643

Epoch: 6| Step: 10
Training loss: 2.0741283893585205
Validation loss: 2.170139730617564

Epoch: 6| Step: 11
Training loss: 2.353553056716919
Validation loss: 2.1712754695646224

Epoch: 6| Step: 12
Training loss: 2.697849750518799
Validation loss: 2.1577928758436635

Epoch: 6| Step: 13
Training loss: 2.332021474838257
Validation loss: 2.172045066792478

Epoch: 73| Step: 0
Training loss: 2.5677638053894043
Validation loss: 2.150594470321491

Epoch: 6| Step: 1
Training loss: 2.0572781562805176
Validation loss: 2.148270842849567

Epoch: 6| Step: 2
Training loss: 3.1665821075439453
Validation loss: 2.169546809247745

Epoch: 6| Step: 3
Training loss: 1.7795898914337158
Validation loss: 2.1452244302277923

Epoch: 6| Step: 4
Training loss: 1.4952454566955566
Validation loss: 2.1570836549164145

Epoch: 6| Step: 5
Training loss: 2.41225004196167
Validation loss: 2.1619059526792137

Epoch: 6| Step: 6
Training loss: 2.769818067550659
Validation loss: 2.150094328388091

Epoch: 6| Step: 7
Training loss: 1.8017127513885498
Validation loss: 2.1535966780877884

Epoch: 6| Step: 8
Training loss: 1.899945855140686
Validation loss: 2.162178926570441

Epoch: 6| Step: 9
Training loss: 2.3644509315490723
Validation loss: 2.1461796927195724

Epoch: 6| Step: 10
Training loss: 2.1295974254608154
Validation loss: 2.150752616185014

Epoch: 6| Step: 11
Training loss: 2.3329758644104004
Validation loss: 2.1404605334804905

Epoch: 6| Step: 12
Training loss: 2.0963692665100098
Validation loss: 2.1485076283895843

Epoch: 6| Step: 13
Training loss: 2.8456640243530273
Validation loss: 2.1559835531378306

Epoch: 74| Step: 0
Training loss: 2.336226463317871
Validation loss: 2.1579572718630553

Epoch: 6| Step: 1
Training loss: 2.3030693531036377
Validation loss: 2.1553715018815893

Epoch: 6| Step: 2
Training loss: 2.0081167221069336
Validation loss: 2.146897223687941

Epoch: 6| Step: 3
Training loss: 1.867732286453247
Validation loss: 2.1515632162811937

Epoch: 6| Step: 4
Training loss: 2.2478599548339844
Validation loss: 2.1518830637778006

Epoch: 6| Step: 5
Training loss: 2.5381884574890137
Validation loss: 2.139912082302955

Epoch: 6| Step: 6
Training loss: 2.2725183963775635
Validation loss: 2.161775671025758

Epoch: 6| Step: 7
Training loss: 2.4292259216308594
Validation loss: 2.1630358196073964

Epoch: 6| Step: 8
Training loss: 2.210660219192505
Validation loss: 2.1633603393390612

Epoch: 6| Step: 9
Training loss: 2.6948318481445312
Validation loss: 2.137318430408355

Epoch: 6| Step: 10
Training loss: 1.8590073585510254
Validation loss: 2.172358864097185

Epoch: 6| Step: 11
Training loss: 3.087717294692993
Validation loss: 2.1653862948058755

Epoch: 6| Step: 12
Training loss: 1.7819303274154663
Validation loss: 2.1520601959638697

Epoch: 6| Step: 13
Training loss: 1.556093454360962
Validation loss: 2.1591451244969524

Epoch: 75| Step: 0
Training loss: 2.4813876152038574
Validation loss: 2.1552614268436225

Epoch: 6| Step: 1
Training loss: 2.5968048572540283
Validation loss: 2.136415578985727

Epoch: 6| Step: 2
Training loss: 2.260735511779785
Validation loss: 2.1270747928209204

Epoch: 6| Step: 3
Training loss: 2.143413782119751
Validation loss: 2.1661124511431624

Epoch: 6| Step: 4
Training loss: 2.7024154663085938
Validation loss: 2.138214804792917

Epoch: 6| Step: 5
Training loss: 1.7745758295059204
Validation loss: 2.1515312951098204

Epoch: 6| Step: 6
Training loss: 2.1814496517181396
Validation loss: 2.1716605719699653

Epoch: 6| Step: 7
Training loss: 1.3584306240081787
Validation loss: 2.170154571533203

Epoch: 6| Step: 8
Training loss: 2.268629550933838
Validation loss: 2.16042983916498

Epoch: 6| Step: 9
Training loss: 2.433797597885132
Validation loss: 2.1659750476960213

Epoch: 6| Step: 10
Training loss: 2.662475347518921
Validation loss: 2.157348609739734

Epoch: 6| Step: 11
Training loss: 2.5220887660980225
Validation loss: 2.165143710310741

Epoch: 6| Step: 12
Training loss: 1.897460699081421
Validation loss: 2.1444961896506687

Epoch: 6| Step: 13
Training loss: 2.102992296218872
Validation loss: 2.145965399280671

Epoch: 76| Step: 0
Training loss: 2.6879940032958984
Validation loss: 2.1400545925222416

Epoch: 6| Step: 1
Training loss: 1.6394292116165161
Validation loss: 2.1423845252683087

Epoch: 6| Step: 2
Training loss: 2.0572197437286377
Validation loss: 2.1566258168989614

Epoch: 6| Step: 3
Training loss: 2.223996639251709
Validation loss: 2.139736469073962

Epoch: 6| Step: 4
Training loss: 2.5169801712036133
Validation loss: 2.1669638105618056

Epoch: 6| Step: 5
Training loss: 2.432727336883545
Validation loss: 2.1567846985273462

Epoch: 6| Step: 6
Training loss: 2.3035733699798584
Validation loss: 2.1554458961691907

Epoch: 6| Step: 7
Training loss: 2.4089088439941406
Validation loss: 2.1628253331748386

Epoch: 6| Step: 8
Training loss: 2.3451199531555176
Validation loss: 2.1549403564904326

Epoch: 6| Step: 9
Training loss: 1.7624417543411255
Validation loss: 2.148405171209766

Epoch: 6| Step: 10
Training loss: 2.7873058319091797
Validation loss: 2.157866818930513

Epoch: 6| Step: 11
Training loss: 2.342750072479248
Validation loss: 2.1551432404466855

Epoch: 6| Step: 12
Training loss: 2.127566337585449
Validation loss: 2.1564016060162614

Epoch: 6| Step: 13
Training loss: 1.451757788658142
Validation loss: 2.160442543286149

Epoch: 77| Step: 0
Training loss: 1.707845687866211
Validation loss: 2.153244117254852

Epoch: 6| Step: 1
Training loss: 2.6319899559020996
Validation loss: 2.161480595988612

Epoch: 6| Step: 2
Training loss: 1.7750132083892822
Validation loss: 2.178460399309794

Epoch: 6| Step: 3
Training loss: 2.6351828575134277
Validation loss: 2.168645792109992

Epoch: 6| Step: 4
Training loss: 1.8486887216567993
Validation loss: 2.156674310725222

Epoch: 6| Step: 5
Training loss: 2.495932102203369
Validation loss: 2.1639710510930708

Epoch: 6| Step: 6
Training loss: 1.9177789688110352
Validation loss: 2.162801842535696

Epoch: 6| Step: 7
Training loss: 2.7713587284088135
Validation loss: 2.160772103135304

Epoch: 6| Step: 8
Training loss: 2.5652787685394287
Validation loss: 2.1610109293332664

Epoch: 6| Step: 9
Training loss: 2.179215669631958
Validation loss: 2.156361295330909

Epoch: 6| Step: 10
Training loss: 2.1371796131134033
Validation loss: 2.1416608979625087

Epoch: 6| Step: 11
Training loss: 2.061694622039795
Validation loss: 2.1392020153742966

Epoch: 6| Step: 12
Training loss: 2.1955976486206055
Validation loss: 2.155698768554195

Epoch: 6| Step: 13
Training loss: 2.2116384506225586
Validation loss: 2.160040120924673

Epoch: 78| Step: 0
Training loss: 2.222576141357422
Validation loss: 2.1590063712930165

Epoch: 6| Step: 1
Training loss: 2.5539393424987793
Validation loss: 2.1539222143029653

Epoch: 6| Step: 2
Training loss: 3.2285714149475098
Validation loss: 2.1592597012878745

Epoch: 6| Step: 3
Training loss: 2.274517059326172
Validation loss: 2.1502506053575905

Epoch: 6| Step: 4
Training loss: 2.222026824951172
Validation loss: 2.159730648481718

Epoch: 6| Step: 5
Training loss: 2.1432085037231445
Validation loss: 2.1438694897518364

Epoch: 6| Step: 6
Training loss: 1.7222909927368164
Validation loss: 2.159253534450326

Epoch: 6| Step: 7
Training loss: 1.906015157699585
Validation loss: 2.165510659576744

Epoch: 6| Step: 8
Training loss: 2.176379680633545
Validation loss: 2.140844820648111

Epoch: 6| Step: 9
Training loss: 1.663478970527649
Validation loss: 2.176890503975653

Epoch: 6| Step: 10
Training loss: 2.068986177444458
Validation loss: 2.146283221501176

Epoch: 6| Step: 11
Training loss: 2.7186989784240723
Validation loss: 2.1645203585265786

Epoch: 6| Step: 12
Training loss: 1.9902009963989258
Validation loss: 2.132967351585306

Epoch: 6| Step: 13
Training loss: 2.3091557025909424
Validation loss: 2.1500712556223713

Epoch: 79| Step: 0
Training loss: 2.5625362396240234
Validation loss: 2.146576848081363

Epoch: 6| Step: 1
Training loss: 1.9745490550994873
Validation loss: 2.1745478824902604

Epoch: 6| Step: 2
Training loss: 2.2422842979431152
Validation loss: 2.168506412095921

Epoch: 6| Step: 3
Training loss: 2.5670342445373535
Validation loss: 2.136623005713186

Epoch: 6| Step: 4
Training loss: 1.800292730331421
Validation loss: 2.1594231231238252

Epoch: 6| Step: 5
Training loss: 2.3493525981903076
Validation loss: 2.1385723288341234

Epoch: 6| Step: 6
Training loss: 2.039597511291504
Validation loss: 2.1539266391467025

Epoch: 6| Step: 7
Training loss: 1.5410257577896118
Validation loss: 2.13384981565578

Epoch: 6| Step: 8
Training loss: 2.122429370880127
Validation loss: 2.15222252568891

Epoch: 6| Step: 9
Training loss: 2.688366651535034
Validation loss: 2.1545336631036576

Epoch: 6| Step: 10
Training loss: 2.3353443145751953
Validation loss: 2.1647803527052685

Epoch: 6| Step: 11
Training loss: 2.199381113052368
Validation loss: 2.159052559124526

Epoch: 6| Step: 12
Training loss: 2.231586456298828
Validation loss: 2.15962476371437

Epoch: 6| Step: 13
Training loss: 2.5821588039398193
Validation loss: 2.154128546355873

Epoch: 80| Step: 0
Training loss: 1.8828487396240234
Validation loss: 2.1752587056929067

Epoch: 6| Step: 1
Training loss: 1.6693737506866455
Validation loss: 2.1519588501222673

Epoch: 6| Step: 2
Training loss: 2.606100082397461
Validation loss: 2.1419067011084607

Epoch: 6| Step: 3
Training loss: 2.959728240966797
Validation loss: 2.173957049205739

Epoch: 6| Step: 4
Training loss: 1.5180373191833496
Validation loss: 2.1528908462934595

Epoch: 6| Step: 5
Training loss: 1.8495988845825195
Validation loss: 2.172156141650292

Epoch: 6| Step: 6
Training loss: 2.235507011413574
Validation loss: 2.131157926333848

Epoch: 6| Step: 7
Training loss: 2.788625478744507
Validation loss: 2.1569330525654618

Epoch: 6| Step: 8
Training loss: 3.069660186767578
Validation loss: 2.1552253564198813

Epoch: 6| Step: 9
Training loss: 2.1681509017944336
Validation loss: 2.1722630364920503

Epoch: 6| Step: 10
Training loss: 2.223001480102539
Validation loss: 2.1573428261664604

Epoch: 6| Step: 11
Training loss: 1.925596833229065
Validation loss: 2.1347684911502305

Epoch: 6| Step: 12
Training loss: 2.0598959922790527
Validation loss: 2.138314026658253

Epoch: 6| Step: 13
Training loss: 2.188181161880493
Validation loss: 2.149238304425311

Epoch: 81| Step: 0
Training loss: 2.027060031890869
Validation loss: 2.1449657922149985

Epoch: 6| Step: 1
Training loss: 2.352001667022705
Validation loss: 2.1613553852163334

Epoch: 6| Step: 2
Training loss: 2.1737477779388428
Validation loss: 2.138273064808179

Epoch: 6| Step: 3
Training loss: 2.6574015617370605
Validation loss: 2.153513144421321

Epoch: 6| Step: 4
Training loss: 1.831516981124878
Validation loss: 2.154901171243319

Epoch: 6| Step: 5
Training loss: 2.193108081817627
Validation loss: 2.1518980713300806

Epoch: 6| Step: 6
Training loss: 1.8973426818847656
Validation loss: 2.1528811582954983

Epoch: 6| Step: 7
Training loss: 2.1318297386169434
Validation loss: 2.1604234351906726

Epoch: 6| Step: 8
Training loss: 2.948280096054077
Validation loss: 2.1380846128668836

Epoch: 6| Step: 9
Training loss: 3.0040230751037598
Validation loss: 2.146870202915643

Epoch: 6| Step: 10
Training loss: 2.3332762718200684
Validation loss: 2.170233234282463

Epoch: 6| Step: 11
Training loss: 1.1083335876464844
Validation loss: 2.147643102112637

Epoch: 6| Step: 12
Training loss: 2.1214964389801025
Validation loss: 2.144238328420988

Epoch: 6| Step: 13
Training loss: 2.3338193893432617
Validation loss: 2.148741122215025

Epoch: 82| Step: 0
Training loss: 2.4364006519317627
Validation loss: 2.1649312716658398

Epoch: 6| Step: 1
Training loss: 2.144195318222046
Validation loss: 2.1756314564776678

Epoch: 6| Step: 2
Training loss: 2.4175539016723633
Validation loss: 2.1495192602116573

Epoch: 6| Step: 3
Training loss: 2.0037455558776855
Validation loss: 2.151350179026204

Epoch: 6| Step: 4
Training loss: 2.4191079139709473
Validation loss: 2.152214414329939

Epoch: 6| Step: 5
Training loss: 1.9771538972854614
Validation loss: 2.1527424602098364

Epoch: 6| Step: 6
Training loss: 1.8964309692382812
Validation loss: 2.1682503351601223

Epoch: 6| Step: 7
Training loss: 1.6318466663360596
Validation loss: 2.147007885799613

Epoch: 6| Step: 8
Training loss: 1.967315912246704
Validation loss: 2.1621970720188592

Epoch: 6| Step: 9
Training loss: 2.290132522583008
Validation loss: 2.1481930337926394

Epoch: 6| Step: 10
Training loss: 2.8880484104156494
Validation loss: 2.1505759992907123

Epoch: 6| Step: 11
Training loss: 2.745840311050415
Validation loss: 2.15315511790655

Epoch: 6| Step: 12
Training loss: 2.2854459285736084
Validation loss: 2.1568032285218597

Epoch: 6| Step: 13
Training loss: 1.9123352766036987
Validation loss: 2.1613736588467836

Epoch: 83| Step: 0
Training loss: 2.043086528778076
Validation loss: 2.1745515202963226

Epoch: 6| Step: 1
Training loss: 2.688312530517578
Validation loss: 2.145517119797327

Epoch: 6| Step: 2
Training loss: 2.6199264526367188
Validation loss: 2.151012364254203

Epoch: 6| Step: 3
Training loss: 1.4778153896331787
Validation loss: 2.141249023458009

Epoch: 6| Step: 4
Training loss: 2.844423770904541
Validation loss: 2.159673313940725

Epoch: 6| Step: 5
Training loss: 1.7284852266311646
Validation loss: 2.1515677539251183

Epoch: 6| Step: 6
Training loss: 2.559068202972412
Validation loss: 2.142681606354252

Epoch: 6| Step: 7
Training loss: 3.2092409133911133
Validation loss: 2.1442344983418784

Epoch: 6| Step: 8
Training loss: 2.198087215423584
Validation loss: 2.1356240882668445

Epoch: 6| Step: 9
Training loss: 2.1504948139190674
Validation loss: 2.14080302176937

Epoch: 6| Step: 10
Training loss: 1.77034592628479
Validation loss: 2.1378609006122877

Epoch: 6| Step: 11
Training loss: 1.8384151458740234
Validation loss: 2.1681018183308263

Epoch: 6| Step: 12
Training loss: 2.103895664215088
Validation loss: 2.14166441271382

Epoch: 6| Step: 13
Training loss: 1.859851360321045
Validation loss: 2.132892329205749

Epoch: 84| Step: 0
Training loss: 1.9044835567474365
Validation loss: 2.1603131678796585

Epoch: 6| Step: 1
Training loss: 1.9805383682250977
Validation loss: 2.145891494648431

Epoch: 6| Step: 2
Training loss: 2.7934577465057373
Validation loss: 2.1366716738670104

Epoch: 6| Step: 3
Training loss: 2.115293025970459
Validation loss: 2.1636560681045696

Epoch: 6| Step: 4
Training loss: 2.1802895069122314
Validation loss: 2.1389110242166827

Epoch: 6| Step: 5
Training loss: 2.197334051132202
Validation loss: 2.147554959020307

Epoch: 6| Step: 6
Training loss: 1.8634538650512695
Validation loss: 2.1401816375793947

Epoch: 6| Step: 7
Training loss: 1.9659525156021118
Validation loss: 2.163529670366677

Epoch: 6| Step: 8
Training loss: 2.0818073749542236
Validation loss: 2.155717087048356

Epoch: 6| Step: 9
Training loss: 2.093717098236084
Validation loss: 2.1500051021575928

Epoch: 6| Step: 10
Training loss: 2.5407800674438477
Validation loss: 2.1363187964244554

Epoch: 6| Step: 11
Training loss: 2.5362377166748047
Validation loss: 2.1462656515900806

Epoch: 6| Step: 12
Training loss: 2.984269142150879
Validation loss: 2.145681383789227

Epoch: 6| Step: 13
Training loss: 1.7124781608581543
Validation loss: 2.167632051693496

Epoch: 85| Step: 0
Training loss: 2.0065488815307617
Validation loss: 2.142045364584974

Epoch: 6| Step: 1
Training loss: 1.9646726846694946
Validation loss: 2.1355362553750314

Epoch: 6| Step: 2
Training loss: 2.07269287109375
Validation loss: 2.1609025360435568

Epoch: 6| Step: 3
Training loss: 2.2250914573669434
Validation loss: 2.144742922116351

Epoch: 6| Step: 4
Training loss: 2.1508986949920654
Validation loss: 2.143798996043462

Epoch: 6| Step: 5
Training loss: 2.818512201309204
Validation loss: 2.1473635704286638

Epoch: 6| Step: 6
Training loss: 2.608257532119751
Validation loss: 2.1377846297397407

Epoch: 6| Step: 7
Training loss: 2.830885648727417
Validation loss: 2.1287879046573432

Epoch: 6| Step: 8
Training loss: 1.7924058437347412
Validation loss: 2.1345517737891084

Epoch: 6| Step: 9
Training loss: 1.9552137851715088
Validation loss: 2.1419609285170034

Epoch: 6| Step: 10
Training loss: 2.4460411071777344
Validation loss: 2.1372551174574

Epoch: 6| Step: 11
Training loss: 2.454434394836426
Validation loss: 2.1368165618629864

Epoch: 6| Step: 12
Training loss: 1.6107978820800781
Validation loss: 2.137888980168168

Epoch: 6| Step: 13
Training loss: 2.0168631076812744
Validation loss: 2.160185206320978

Epoch: 86| Step: 0
Training loss: 2.028209924697876
Validation loss: 2.1471450328826904

Epoch: 6| Step: 1
Training loss: 2.618664026260376
Validation loss: 2.127661730653496

Epoch: 6| Step: 2
Training loss: 2.4328737258911133
Validation loss: 2.1604068663812455

Epoch: 6| Step: 3
Training loss: 2.500657081604004
Validation loss: 2.149757377562984

Epoch: 6| Step: 4
Training loss: 2.203101634979248
Validation loss: 2.1412639387192263

Epoch: 6| Step: 5
Training loss: 1.7529346942901611
Validation loss: 2.163147182874782

Epoch: 6| Step: 6
Training loss: 2.5101513862609863
Validation loss: 2.150997543847689

Epoch: 6| Step: 7
Training loss: 2.3140363693237305
Validation loss: 2.1414910029339533

Epoch: 6| Step: 8
Training loss: 1.5266692638397217
Validation loss: 2.1384538117275445

Epoch: 6| Step: 9
Training loss: 2.5038440227508545
Validation loss: 2.155640629030043

Epoch: 6| Step: 10
Training loss: 1.1962741613388062
Validation loss: 2.137178651748165

Epoch: 6| Step: 11
Training loss: 2.8245930671691895
Validation loss: 2.1591185626163276

Epoch: 6| Step: 12
Training loss: 2.0773732662200928
Validation loss: 2.1443364786845382

Epoch: 6| Step: 13
Training loss: 2.5007100105285645
Validation loss: 2.1433089189631964

Epoch: 87| Step: 0
Training loss: 3.0091333389282227
Validation loss: 2.1520815151993946

Epoch: 6| Step: 1
Training loss: 1.770403504371643
Validation loss: 2.151381934842756

Epoch: 6| Step: 2
Training loss: 2.1497604846954346
Validation loss: 2.1398478272140666

Epoch: 6| Step: 3
Training loss: 2.5350513458251953
Validation loss: 2.1637218101050264

Epoch: 6| Step: 4
Training loss: 2.963627815246582
Validation loss: 2.1480741577763713

Epoch: 6| Step: 5
Training loss: 2.2626094818115234
Validation loss: 2.143605301457067

Epoch: 6| Step: 6
Training loss: 1.4415318965911865
Validation loss: 2.1325247723569154

Epoch: 6| Step: 7
Training loss: 2.398346424102783
Validation loss: 2.1346014802173903

Epoch: 6| Step: 8
Training loss: 2.383269786834717
Validation loss: 2.15182541519083

Epoch: 6| Step: 9
Training loss: 2.3613815307617188
Validation loss: 2.1673554553780505

Epoch: 6| Step: 10
Training loss: 2.2753889560699463
Validation loss: 2.134813968853284

Epoch: 6| Step: 11
Training loss: 1.3339951038360596
Validation loss: 2.1359953393218336

Epoch: 6| Step: 12
Training loss: 2.335888624191284
Validation loss: 2.1574825163810485

Epoch: 6| Step: 13
Training loss: 0.9490746259689331
Validation loss: 2.1287696592269407

Epoch: 88| Step: 0
Training loss: 2.511610507965088
Validation loss: 2.1415384072129444

Epoch: 6| Step: 1
Training loss: 1.4662431478500366
Validation loss: 2.165686868852185

Epoch: 6| Step: 2
Training loss: 1.63563871383667
Validation loss: 2.148280151428715

Epoch: 6| Step: 3
Training loss: 2.2782552242279053
Validation loss: 2.1394911555833716

Epoch: 6| Step: 4
Training loss: 2.266575574874878
Validation loss: 2.14481920067982

Epoch: 6| Step: 5
Training loss: 2.6819000244140625
Validation loss: 2.1424301824262066

Epoch: 6| Step: 6
Training loss: 1.6348812580108643
Validation loss: 2.135626567307339

Epoch: 6| Step: 7
Training loss: 2.146047592163086
Validation loss: 2.1523208515618437

Epoch: 6| Step: 8
Training loss: 2.2948756217956543
Validation loss: 2.157860177819447

Epoch: 6| Step: 9
Training loss: 2.086001396179199
Validation loss: 2.144039220707391

Epoch: 6| Step: 10
Training loss: 2.868185043334961
Validation loss: 2.130103034357871

Epoch: 6| Step: 11
Training loss: 2.447033643722534
Validation loss: 2.1399200616344327

Epoch: 6| Step: 12
Training loss: 2.465768814086914
Validation loss: 2.154854554002003

Epoch: 6| Step: 13
Training loss: 2.111678123474121
Validation loss: 2.15821171832341

Epoch: 89| Step: 0
Training loss: 2.779919147491455
Validation loss: 2.150255823648104

Epoch: 6| Step: 1
Training loss: 2.6798906326293945
Validation loss: 2.1212274002772507

Epoch: 6| Step: 2
Training loss: 2.055039167404175
Validation loss: 2.142101937724698

Epoch: 6| Step: 3
Training loss: 1.5830051898956299
Validation loss: 2.1537823894972443

Epoch: 6| Step: 4
Training loss: 1.7732757329940796
Validation loss: 2.144159336243906

Epoch: 6| Step: 5
Training loss: 2.190077304840088
Validation loss: 2.135990601713939

Epoch: 6| Step: 6
Training loss: 2.077338933944702
Validation loss: 2.131784586496251

Epoch: 6| Step: 7
Training loss: 1.8226467370986938
Validation loss: 2.133692873421536

Epoch: 6| Step: 8
Training loss: 2.8106842041015625
Validation loss: 2.149444064786357

Epoch: 6| Step: 9
Training loss: 2.4390811920166016
Validation loss: 2.1321226678868777

Epoch: 6| Step: 10
Training loss: 2.161566972732544
Validation loss: 2.139774736537728

Epoch: 6| Step: 11
Training loss: 2.261018753051758
Validation loss: 2.129349681638902

Epoch: 6| Step: 12
Training loss: 1.8532741069793701
Validation loss: 2.1431465815472346

Epoch: 6| Step: 13
Training loss: 2.5708096027374268
Validation loss: 2.1289535517333658

Epoch: 90| Step: 0
Training loss: 2.3064489364624023
Validation loss: 2.150379334726641

Epoch: 6| Step: 1
Training loss: 1.6427702903747559
Validation loss: 2.1508608838563323

Epoch: 6| Step: 2
Training loss: 2.0637922286987305
Validation loss: 2.127217564531552

Epoch: 6| Step: 3
Training loss: 2.3059000968933105
Validation loss: 2.1550372082700013

Epoch: 6| Step: 4
Training loss: 2.3718299865722656
Validation loss: 2.1669522934062506

Epoch: 6| Step: 5
Training loss: 2.748288631439209
Validation loss: 2.1340675507822344

Epoch: 6| Step: 6
Training loss: 1.9023544788360596
Validation loss: 2.1535398037202897

Epoch: 6| Step: 7
Training loss: 2.157552719116211
Validation loss: 2.1447502490012877

Epoch: 6| Step: 8
Training loss: 2.1753220558166504
Validation loss: 2.138208285454781

Epoch: 6| Step: 9
Training loss: 2.331143379211426
Validation loss: 2.133566494910948

Epoch: 6| Step: 10
Training loss: 1.7709637880325317
Validation loss: 2.1285470070377475

Epoch: 6| Step: 11
Training loss: 2.7851123809814453
Validation loss: 2.1399529928802163

Epoch: 6| Step: 12
Training loss: 2.387326955795288
Validation loss: 2.159149677522721

Epoch: 6| Step: 13
Training loss: 1.8658404350280762
Validation loss: 2.147001411325188

Epoch: 91| Step: 0
Training loss: 1.9346790313720703
Validation loss: 2.148742501453687

Epoch: 6| Step: 1
Training loss: 2.227285861968994
Validation loss: 2.140581043817664

Epoch: 6| Step: 2
Training loss: 2.410245895385742
Validation loss: 2.137114304368214

Epoch: 6| Step: 3
Training loss: 2.3750076293945312
Validation loss: 2.150143623352051

Epoch: 6| Step: 4
Training loss: 2.301237106323242
Validation loss: 2.150671528231713

Epoch: 6| Step: 5
Training loss: 2.821263074874878
Validation loss: 2.1320611405116257

Epoch: 6| Step: 6
Training loss: 2.2572693824768066
Validation loss: 2.139821913934523

Epoch: 6| Step: 7
Training loss: 2.7129974365234375
Validation loss: 2.1343751466402443

Epoch: 6| Step: 8
Training loss: 1.6336233615875244
Validation loss: 2.139714535846505

Epoch: 6| Step: 9
Training loss: 1.1757746934890747
Validation loss: 2.1272093916452057

Epoch: 6| Step: 10
Training loss: 1.917889952659607
Validation loss: 2.1438004534731627

Epoch: 6| Step: 11
Training loss: 2.2418861389160156
Validation loss: 2.1512086391448975

Epoch: 6| Step: 12
Training loss: 2.6978042125701904
Validation loss: 2.135194747678695

Epoch: 6| Step: 13
Training loss: 1.9091486930847168
Validation loss: 2.1359856718329975

Epoch: 92| Step: 0
Training loss: 2.4034152030944824
Validation loss: 2.1606150647645355

Epoch: 6| Step: 1
Training loss: 1.7894275188446045
Validation loss: 2.1492997959095943

Epoch: 6| Step: 2
Training loss: 2.2818403244018555
Validation loss: 2.131498739283572

Epoch: 6| Step: 3
Training loss: 1.9713194370269775
Validation loss: 2.1279111216145177

Epoch: 6| Step: 4
Training loss: 2.192667007446289
Validation loss: 2.152826173331148

Epoch: 6| Step: 5
Training loss: 1.759727954864502
Validation loss: 2.140442602096065

Epoch: 6| Step: 6
Training loss: 3.262526273727417
Validation loss: 2.1441302427681546

Epoch: 6| Step: 7
Training loss: 1.8195418119430542
Validation loss: 2.1284688480438723

Epoch: 6| Step: 8
Training loss: 2.36401104927063
Validation loss: 2.1590262664261686

Epoch: 6| Step: 9
Training loss: 2.8077077865600586
Validation loss: 2.1722846954099593

Epoch: 6| Step: 10
Training loss: 1.8780951499938965
Validation loss: 2.1286263863245645

Epoch: 6| Step: 11
Training loss: 2.1065831184387207
Validation loss: 2.1388365863471903

Epoch: 6| Step: 12
Training loss: 1.949017882347107
Validation loss: 2.130073585817891

Epoch: 6| Step: 13
Training loss: 2.184218168258667
Validation loss: 2.1603491319123136

Epoch: 93| Step: 0
Training loss: 2.4963808059692383
Validation loss: 2.1459386297451553

Epoch: 6| Step: 1
Training loss: 1.8310097455978394
Validation loss: 2.1338621442035963

Epoch: 6| Step: 2
Training loss: 2.2565674781799316
Validation loss: 2.151311779534945

Epoch: 6| Step: 3
Training loss: 2.7690353393554688
Validation loss: 2.146370780083441

Epoch: 6| Step: 4
Training loss: 2.105121612548828
Validation loss: 2.1291081687455535

Epoch: 6| Step: 5
Training loss: 1.7774913311004639
Validation loss: 2.1348452080962477

Epoch: 6| Step: 6
Training loss: 2.5391762256622314
Validation loss: 2.1397533083474762

Epoch: 6| Step: 7
Training loss: 2.0917205810546875
Validation loss: 2.1484409173329673

Epoch: 6| Step: 8
Training loss: 1.843881368637085
Validation loss: 2.1541676944301975

Epoch: 6| Step: 9
Training loss: 2.2085165977478027
Validation loss: 2.1349675527182956

Epoch: 6| Step: 10
Training loss: 2.017007827758789
Validation loss: 2.1520916210707797

Epoch: 6| Step: 11
Training loss: 2.4114623069763184
Validation loss: 2.141343824325069

Epoch: 6| Step: 12
Training loss: 2.3758835792541504
Validation loss: 2.143834138429293

Epoch: 6| Step: 13
Training loss: 1.8172907829284668
Validation loss: 2.139638413665115

Epoch: 94| Step: 0
Training loss: 2.6848132610321045
Validation loss: 2.141373042137392

Epoch: 6| Step: 1
Training loss: 1.6774570941925049
Validation loss: 2.137943834386846

Epoch: 6| Step: 2
Training loss: 2.138843536376953
Validation loss: 2.13007850544427

Epoch: 6| Step: 3
Training loss: 1.5943737030029297
Validation loss: 2.153129255899819

Epoch: 6| Step: 4
Training loss: 2.09598708152771
Validation loss: 2.141707956150014

Epoch: 6| Step: 5
Training loss: 2.626591205596924
Validation loss: 2.133881680427059

Epoch: 6| Step: 6
Training loss: 2.146253824234009
Validation loss: 2.1307440932079027

Epoch: 6| Step: 7
Training loss: 2.431534767150879
Validation loss: 2.1351349584517942

Epoch: 6| Step: 8
Training loss: 1.749600887298584
Validation loss: 2.149253394014092

Epoch: 6| Step: 9
Training loss: 2.115347146987915
Validation loss: 2.1345049347928775

Epoch: 6| Step: 10
Training loss: 2.814940929412842
Validation loss: 2.150143269569643

Epoch: 6| Step: 11
Training loss: 2.2882039546966553
Validation loss: 2.1472358511340235

Epoch: 6| Step: 12
Training loss: 1.9977853298187256
Validation loss: 2.1461116959971767

Epoch: 6| Step: 13
Training loss: 2.3977694511413574
Validation loss: 2.1519180138905845

Epoch: 95| Step: 0
Training loss: 2.1009719371795654
Validation loss: 2.1089434264808573

Epoch: 6| Step: 1
Training loss: 2.052264451980591
Validation loss: 2.149994796322238

Epoch: 6| Step: 2
Training loss: 1.7449567317962646
Validation loss: 2.1445929260664087

Epoch: 6| Step: 3
Training loss: 2.223738431930542
Validation loss: 2.155335733967443

Epoch: 6| Step: 4
Training loss: 2.09973406791687
Validation loss: 2.1286476606963785

Epoch: 6| Step: 5
Training loss: 2.4076740741729736
Validation loss: 2.1404072802553893

Epoch: 6| Step: 6
Training loss: 1.739396572113037
Validation loss: 2.157030361954884

Epoch: 6| Step: 7
Training loss: 1.6744273900985718
Validation loss: 2.1365987588000555

Epoch: 6| Step: 8
Training loss: 2.245811700820923
Validation loss: 2.118619595804522

Epoch: 6| Step: 9
Training loss: 2.7778279781341553
Validation loss: 2.158497425817674

Epoch: 6| Step: 10
Training loss: 2.991367816925049
Validation loss: 2.1552333216513357

Epoch: 6| Step: 11
Training loss: 2.139375686645508
Validation loss: 2.1244669422026603

Epoch: 6| Step: 12
Training loss: 1.9326709508895874
Validation loss: 2.1472253825074885

Epoch: 6| Step: 13
Training loss: 2.7887120246887207
Validation loss: 2.135906296391641

Epoch: 96| Step: 0
Training loss: 2.2301714420318604
Validation loss: 2.1148358493722896

Epoch: 6| Step: 1
Training loss: 1.6291120052337646
Validation loss: 2.1345499113041866

Epoch: 6| Step: 2
Training loss: 2.119490146636963
Validation loss: 2.1316640889772804

Epoch: 6| Step: 3
Training loss: 2.0217161178588867
Validation loss: 2.1505469147877028

Epoch: 6| Step: 4
Training loss: 1.6577470302581787
Validation loss: 2.134638141560298

Epoch: 6| Step: 5
Training loss: 2.0420243740081787
Validation loss: 2.1287967761357627

Epoch: 6| Step: 6
Training loss: 3.0878190994262695
Validation loss: 2.165875583566645

Epoch: 6| Step: 7
Training loss: 2.5296082496643066
Validation loss: 2.133866048628284

Epoch: 6| Step: 8
Training loss: 2.0562057495117188
Validation loss: 2.158706949603173

Epoch: 6| Step: 9
Training loss: 2.3093090057373047
Validation loss: 2.1513075418369745

Epoch: 6| Step: 10
Training loss: 2.33683443069458
Validation loss: 2.1406777340878724

Epoch: 6| Step: 11
Training loss: 1.7558715343475342
Validation loss: 2.141331236849549

Epoch: 6| Step: 12
Training loss: 2.3861806392669678
Validation loss: 2.1439482191557526

Epoch: 6| Step: 13
Training loss: 2.8319714069366455
Validation loss: 2.1665320293877715

Epoch: 97| Step: 0
Training loss: 2.6686453819274902
Validation loss: 2.144072389089933

Epoch: 6| Step: 1
Training loss: 2.142603874206543
Validation loss: 2.1427248895809217

Epoch: 6| Step: 2
Training loss: 1.874161958694458
Validation loss: 2.1506560540968374

Epoch: 6| Step: 3
Training loss: 2.709808349609375
Validation loss: 2.122481028238932

Epoch: 6| Step: 4
Training loss: 2.6860294342041016
Validation loss: 2.135549150487428

Epoch: 6| Step: 5
Training loss: 2.1399612426757812
Validation loss: 2.12174093210569

Epoch: 6| Step: 6
Training loss: 1.949049711227417
Validation loss: 2.1489317058235087

Epoch: 6| Step: 7
Training loss: 2.542053699493408
Validation loss: 2.124615489795644

Epoch: 6| Step: 8
Training loss: 2.2125213146209717
Validation loss: 2.1291290995895222

Epoch: 6| Step: 9
Training loss: 2.1650960445404053
Validation loss: 2.135982151954405

Epoch: 6| Step: 10
Training loss: 2.2618682384490967
Validation loss: 2.1289643344058784

Epoch: 6| Step: 11
Training loss: 1.701570987701416
Validation loss: 2.1279229246160036

Epoch: 6| Step: 12
Training loss: 1.3087413311004639
Validation loss: 2.120319169054749

Epoch: 6| Step: 13
Training loss: 2.3760101795196533
Validation loss: 2.1486277836625294

Epoch: 98| Step: 0
Training loss: 2.829904556274414
Validation loss: 2.1336856606186076

Epoch: 6| Step: 1
Training loss: 1.8262863159179688
Validation loss: 2.1396109468193463

Epoch: 6| Step: 2
Training loss: 1.7112950086593628
Validation loss: 2.1134554532266434

Epoch: 6| Step: 3
Training loss: 2.31817889213562
Validation loss: 2.1229278528562157

Epoch: 6| Step: 4
Training loss: 2.435182571411133
Validation loss: 2.1348068637232624

Epoch: 6| Step: 5
Training loss: 2.0479607582092285
Validation loss: 2.1629748062420915

Epoch: 6| Step: 6
Training loss: 2.459284543991089
Validation loss: 2.120535744133816

Epoch: 6| Step: 7
Training loss: 2.032796859741211
Validation loss: 2.14289540244687

Epoch: 6| Step: 8
Training loss: 2.8599295616149902
Validation loss: 2.1269927178659747

Epoch: 6| Step: 9
Training loss: 2.2144782543182373
Validation loss: 2.1318173754599785

Epoch: 6| Step: 10
Training loss: 1.983008623123169
Validation loss: 2.1276262729398665

Epoch: 6| Step: 11
Training loss: 2.151585817337036
Validation loss: 2.143756353726951

Epoch: 6| Step: 12
Training loss: 2.2599778175354004
Validation loss: 2.1182569201274584

Epoch: 6| Step: 13
Training loss: 1.2085477113723755
Validation loss: 2.1362403951665407

Epoch: 99| Step: 0
Training loss: 2.1787779331207275
Validation loss: 2.1123424294174358

Epoch: 6| Step: 1
Training loss: 1.4374032020568848
Validation loss: 2.1310457542378414

Epoch: 6| Step: 2
Training loss: 1.6735835075378418
Validation loss: 2.1289393158369165

Epoch: 6| Step: 3
Training loss: 1.2720506191253662
Validation loss: 2.139869205413326

Epoch: 6| Step: 4
Training loss: 1.91315495967865
Validation loss: 2.128130933289887

Epoch: 6| Step: 5
Training loss: 2.813908576965332
Validation loss: 2.1399688156702186

Epoch: 6| Step: 6
Training loss: 2.4151761531829834
Validation loss: 2.1277972882793796

Epoch: 6| Step: 7
Training loss: 2.672189474105835
Validation loss: 2.140897153526224

Epoch: 6| Step: 8
Training loss: 2.7930593490600586
Validation loss: 2.162461655114287

Epoch: 6| Step: 9
Training loss: 2.3604159355163574
Validation loss: 2.140932971431363

Epoch: 6| Step: 10
Training loss: 2.7872190475463867
Validation loss: 2.1270082407100226

Epoch: 6| Step: 11
Training loss: 1.9658164978027344
Validation loss: 2.131857395172119

Epoch: 6| Step: 12
Training loss: 1.6015316247940063
Validation loss: 2.131212983080136

Epoch: 6| Step: 13
Training loss: 2.942155361175537
Validation loss: 2.144347284429817

Epoch: 100| Step: 0
Training loss: 2.5169968605041504
Validation loss: 2.1347661120917207

Epoch: 6| Step: 1
Training loss: 1.9467906951904297
Validation loss: 2.1259768829550794

Epoch: 6| Step: 2
Training loss: 2.406449317932129
Validation loss: 2.1444159669260823

Epoch: 6| Step: 3
Training loss: 2.147185802459717
Validation loss: 2.125564936668642

Epoch: 6| Step: 4
Training loss: 2.078174591064453
Validation loss: 2.116358126363447

Epoch: 6| Step: 5
Training loss: 1.7771294116973877
Validation loss: 2.1226148707892305

Epoch: 6| Step: 6
Training loss: 2.70919132232666
Validation loss: 2.110312807944513

Epoch: 6| Step: 7
Training loss: 2.2833166122436523
Validation loss: 2.1159630180687032

Epoch: 6| Step: 8
Training loss: 2.4595112800598145
Validation loss: 2.128758770163341

Epoch: 6| Step: 9
Training loss: 1.6234383583068848
Validation loss: 2.1215504548882924

Epoch: 6| Step: 10
Training loss: 2.238469123840332
Validation loss: 2.1443841457366943

Epoch: 6| Step: 11
Training loss: 2.488173007965088
Validation loss: 2.127728282764394

Epoch: 6| Step: 12
Training loss: 1.5956004858016968
Validation loss: 2.1395871946888585

Epoch: 6| Step: 13
Training loss: 2.4529645442962646
Validation loss: 2.1323491296460553

Epoch: 101| Step: 0
Training loss: 1.9492398500442505
Validation loss: 2.126371000402717

Epoch: 6| Step: 1
Training loss: 1.4733057022094727
Validation loss: 2.1132475227437992

Epoch: 6| Step: 2
Training loss: 1.8224265575408936
Validation loss: 2.126998580912108

Epoch: 6| Step: 3
Training loss: 2.6014022827148438
Validation loss: 2.1479991661605013

Epoch: 6| Step: 4
Training loss: 2.525155782699585
Validation loss: 2.1143985217617405

Epoch: 6| Step: 5
Training loss: 2.197693347930908
Validation loss: 2.117240446870045

Epoch: 6| Step: 6
Training loss: 2.9381332397460938
Validation loss: 2.1234588264137186

Epoch: 6| Step: 7
Training loss: 2.011085271835327
Validation loss: 2.1323962647427797

Epoch: 6| Step: 8
Training loss: 2.4469213485717773
Validation loss: 2.1219450991640807

Epoch: 6| Step: 9
Training loss: 2.572451114654541
Validation loss: 2.151368136047035

Epoch: 6| Step: 10
Training loss: 2.170088768005371
Validation loss: 2.1444544202537945

Epoch: 6| Step: 11
Training loss: 2.2115187644958496
Validation loss: 2.136885763496481

Epoch: 6| Step: 12
Training loss: 1.9555177688598633
Validation loss: 2.1560984747384184

Epoch: 6| Step: 13
Training loss: 1.7781211137771606
Validation loss: 2.144743691208542

Epoch: 102| Step: 0
Training loss: 2.335263252258301
Validation loss: 2.1410151066318637

Epoch: 6| Step: 1
Training loss: 1.8424705266952515
Validation loss: 2.145852176092004

Epoch: 6| Step: 2
Training loss: 2.8245763778686523
Validation loss: 2.126125608721087

Epoch: 6| Step: 3
Training loss: 1.8833374977111816
Validation loss: 2.1330918804291756

Epoch: 6| Step: 4
Training loss: 1.8015916347503662
Validation loss: 2.1259389590191584

Epoch: 6| Step: 5
Training loss: 2.380235195159912
Validation loss: 2.1149819140793173

Epoch: 6| Step: 6
Training loss: 1.6024127006530762
Validation loss: 2.120922153995883

Epoch: 6| Step: 7
Training loss: 2.9580626487731934
Validation loss: 2.1148333216226227

Epoch: 6| Step: 8
Training loss: 2.0946671962738037
Validation loss: 2.134938527179021

Epoch: 6| Step: 9
Training loss: 2.232050895690918
Validation loss: 2.1361969965760426

Epoch: 6| Step: 10
Training loss: 1.9502288103103638
Validation loss: 2.1127465348089896

Epoch: 6| Step: 11
Training loss: 2.0088977813720703
Validation loss: 2.1374015064649683

Epoch: 6| Step: 12
Training loss: 2.3240575790405273
Validation loss: 2.102948425918497

Epoch: 6| Step: 13
Training loss: 2.2597110271453857
Validation loss: 2.123854030844986

Epoch: 103| Step: 0
Training loss: 2.0674540996551514
Validation loss: 2.1353903880683323

Epoch: 6| Step: 1
Training loss: 2.2312560081481934
Validation loss: 2.1439738299257014

Epoch: 6| Step: 2
Training loss: 1.9927780628204346
Validation loss: 2.1316813679151636

Epoch: 6| Step: 3
Training loss: 2.6860008239746094
Validation loss: 2.1158555566623645

Epoch: 6| Step: 4
Training loss: 2.5440385341644287
Validation loss: 2.1188354953642814

Epoch: 6| Step: 5
Training loss: 2.277554750442505
Validation loss: 2.1320168177286782

Epoch: 6| Step: 6
Training loss: 1.5830637216567993
Validation loss: 2.1418936188502977

Epoch: 6| Step: 7
Training loss: 2.0397000312805176
Validation loss: 2.128750624195222

Epoch: 6| Step: 8
Training loss: 2.3289990425109863
Validation loss: 2.1265091280783377

Epoch: 6| Step: 9
Training loss: 1.6656599044799805
Validation loss: 2.111948378624455

Epoch: 6| Step: 10
Training loss: 1.9244370460510254
Validation loss: 2.1294612243611324

Epoch: 6| Step: 11
Training loss: 3.4658312797546387
Validation loss: 2.1313628996572187

Epoch: 6| Step: 12
Training loss: 1.8983370065689087
Validation loss: 2.102636629535306

Epoch: 6| Step: 13
Training loss: 1.4793508052825928
Validation loss: 2.1257902473531742

Epoch: 104| Step: 0
Training loss: 1.9894691705703735
Validation loss: 2.1086580266234694

Epoch: 6| Step: 1
Training loss: 2.6346797943115234
Validation loss: 2.130291815726988

Epoch: 6| Step: 2
Training loss: 1.6079699993133545
Validation loss: 2.1117527356711765

Epoch: 6| Step: 3
Training loss: 2.307408332824707
Validation loss: 2.101041514386413

Epoch: 6| Step: 4
Training loss: 1.8421989679336548
Validation loss: 2.1141688080244165

Epoch: 6| Step: 5
Training loss: 2.1494908332824707
Validation loss: 2.1281499785761677

Epoch: 6| Step: 6
Training loss: 2.915881633758545
Validation loss: 2.1340859167037474

Epoch: 6| Step: 7
Training loss: 2.0476062297821045
Validation loss: 2.1365848484859673

Epoch: 6| Step: 8
Training loss: 1.8754444122314453
Validation loss: 2.082242335042646

Epoch: 6| Step: 9
Training loss: 1.6922268867492676
Validation loss: 2.1196375534098637

Epoch: 6| Step: 10
Training loss: 2.456022262573242
Validation loss: 2.105164466365691

Epoch: 6| Step: 11
Training loss: 2.3525893688201904
Validation loss: 2.1245386318493913

Epoch: 6| Step: 12
Training loss: 2.173320770263672
Validation loss: 2.126072681078347

Epoch: 6| Step: 13
Training loss: 2.5064573287963867
Validation loss: 2.129202676075761

Epoch: 105| Step: 0
Training loss: 2.1516616344451904
Validation loss: 2.135384996732076

Epoch: 6| Step: 1
Training loss: 2.4369826316833496
Validation loss: 2.1241886577298565

Epoch: 6| Step: 2
Training loss: 2.2131853103637695
Validation loss: 2.1225152836051038

Epoch: 6| Step: 3
Training loss: 2.403696060180664
Validation loss: 2.1251534133829098

Epoch: 6| Step: 4
Training loss: 2.0791373252868652
Validation loss: 2.10930194393281

Epoch: 6| Step: 5
Training loss: 1.9985902309417725
Validation loss: 2.125119573326521

Epoch: 6| Step: 6
Training loss: 2.7788331508636475
Validation loss: 2.1369183576235207

Epoch: 6| Step: 7
Training loss: 2.227428436279297
Validation loss: 2.1012067640981367

Epoch: 6| Step: 8
Training loss: 1.8254507780075073
Validation loss: 2.0931678728390763

Epoch: 6| Step: 9
Training loss: 2.0448384284973145
Validation loss: 2.128038598645118

Epoch: 6| Step: 10
Training loss: 2.219237804412842
Validation loss: 2.111129096759263

Epoch: 6| Step: 11
Training loss: 2.158970832824707
Validation loss: 2.124727101736171

Epoch: 6| Step: 12
Training loss: 2.0594677925109863
Validation loss: 2.1187767495391188

Epoch: 6| Step: 13
Training loss: 1.7327218055725098
Validation loss: 2.1056458975679133

Epoch: 106| Step: 0
Training loss: 2.3884294033050537
Validation loss: 2.111010492488902

Epoch: 6| Step: 1
Training loss: 2.5479564666748047
Validation loss: 2.126187070723503

Epoch: 6| Step: 2
Training loss: 2.3306126594543457
Validation loss: 2.1170635889935236

Epoch: 6| Step: 3
Training loss: 2.061746835708618
Validation loss: 2.108337358761859

Epoch: 6| Step: 4
Training loss: 2.136355400085449
Validation loss: 2.1151006555044525

Epoch: 6| Step: 5
Training loss: 1.6836256980895996
Validation loss: 2.124780406234085

Epoch: 6| Step: 6
Training loss: 1.9860700368881226
Validation loss: 2.1262734525947162

Epoch: 6| Step: 7
Training loss: 1.9595797061920166
Validation loss: 2.1236205998287407

Epoch: 6| Step: 8
Training loss: 2.6229681968688965
Validation loss: 2.108916554399716

Epoch: 6| Step: 9
Training loss: 2.178518295288086
Validation loss: 2.0999159236108103

Epoch: 6| Step: 10
Training loss: 1.874621868133545
Validation loss: 2.1142612516239123

Epoch: 6| Step: 11
Training loss: 2.110619068145752
Validation loss: 2.111050141754971

Epoch: 6| Step: 12
Training loss: 2.3203353881835938
Validation loss: 2.111800693696545

Epoch: 6| Step: 13
Training loss: 2.57174015045166
Validation loss: 2.1099624685061875

Epoch: 107| Step: 0
Training loss: 2.039863109588623
Validation loss: 2.1226235243581955

Epoch: 6| Step: 1
Training loss: 2.033806800842285
Validation loss: 2.124158574688819

Epoch: 6| Step: 2
Training loss: 2.1915946006774902
Validation loss: 2.12803566327659

Epoch: 6| Step: 3
Training loss: 2.2396059036254883
Validation loss: 2.121274732774304

Epoch: 6| Step: 4
Training loss: 2.621279239654541
Validation loss: 2.1378026931516585

Epoch: 6| Step: 5
Training loss: 2.5909883975982666
Validation loss: 2.099767129908326

Epoch: 6| Step: 6
Training loss: 2.1113100051879883
Validation loss: 2.1249074461639568

Epoch: 6| Step: 7
Training loss: 2.1745071411132812
Validation loss: 2.1462262984245055

Epoch: 6| Step: 8
Training loss: 1.5130678415298462
Validation loss: 2.1227317343476

Epoch: 6| Step: 9
Training loss: 2.6326849460601807
Validation loss: 2.125556089544809

Epoch: 6| Step: 10
Training loss: 1.8420754671096802
Validation loss: 2.1387084466154858

Epoch: 6| Step: 11
Training loss: 2.103111505508423
Validation loss: 2.118603026995095

Epoch: 6| Step: 12
Training loss: 2.073728322982788
Validation loss: 2.127364981559015

Epoch: 6| Step: 13
Training loss: 2.3025684356689453
Validation loss: 2.12141207597589

Epoch: 108| Step: 0
Training loss: 2.000845432281494
Validation loss: 2.1106346743081206

Epoch: 6| Step: 1
Training loss: 2.5149664878845215
Validation loss: 2.14052931211328

Epoch: 6| Step: 2
Training loss: 2.0012874603271484
Validation loss: 2.156245267519387

Epoch: 6| Step: 3
Training loss: 1.7335079908370972
Validation loss: 2.1447111022087837

Epoch: 6| Step: 4
Training loss: 2.719863176345825
Validation loss: 2.1136872050582722

Epoch: 6| Step: 5
Training loss: 1.1567726135253906
Validation loss: 2.1257413971808647

Epoch: 6| Step: 6
Training loss: 2.014282703399658
Validation loss: 2.1086246531496764

Epoch: 6| Step: 7
Training loss: 3.2312283515930176
Validation loss: 2.0934049775523524

Epoch: 6| Step: 8
Training loss: 2.455975294113159
Validation loss: 2.1116899136574037

Epoch: 6| Step: 9
Training loss: 2.3852133750915527
Validation loss: 2.0997271845417638

Epoch: 6| Step: 10
Training loss: 2.4470274448394775
Validation loss: 2.144901603780767

Epoch: 6| Step: 11
Training loss: 1.813870906829834
Validation loss: 2.1119193338578746

Epoch: 6| Step: 12
Training loss: 1.7424306869506836
Validation loss: 2.1286110724172285

Epoch: 6| Step: 13
Training loss: 2.4149796962738037
Validation loss: 2.11103493039326

Epoch: 109| Step: 0
Training loss: 1.8120408058166504
Validation loss: 2.1069142818450928

Epoch: 6| Step: 1
Training loss: 2.5963327884674072
Validation loss: 2.114766502893099

Epoch: 6| Step: 2
Training loss: 1.996010184288025
Validation loss: 2.1068751030070807

Epoch: 6| Step: 3
Training loss: 2.8178231716156006
Validation loss: 2.1043786541108163

Epoch: 6| Step: 4
Training loss: 2.938906669616699
Validation loss: 2.1355897072822816

Epoch: 6| Step: 5
Training loss: 2.4454221725463867
Validation loss: 2.1345129269425587

Epoch: 6| Step: 6
Training loss: 2.129020929336548
Validation loss: 2.1135960612245785

Epoch: 6| Step: 7
Training loss: 1.8069442510604858
Validation loss: 2.1324493321039344

Epoch: 6| Step: 8
Training loss: 2.1280899047851562
Validation loss: 2.116612316459738

Epoch: 6| Step: 9
Training loss: 1.7968590259552002
Validation loss: 2.1102819135112147

Epoch: 6| Step: 10
Training loss: 2.094521999359131
Validation loss: 2.1003552995702273

Epoch: 6| Step: 11
Training loss: 1.835023283958435
Validation loss: 2.1137955880934194

Epoch: 6| Step: 12
Training loss: 1.9650648832321167
Validation loss: 2.1138539006633144

Epoch: 6| Step: 13
Training loss: 1.708561897277832
Validation loss: 2.105919861024426

Epoch: 110| Step: 0
Training loss: 1.5562317371368408
Validation loss: 2.1280431093708163

Epoch: 6| Step: 1
Training loss: 2.481290817260742
Validation loss: 2.118338023462603

Epoch: 6| Step: 2
Training loss: 2.893770933151245
Validation loss: 2.1129841086685017

Epoch: 6| Step: 3
Training loss: 2.4198338985443115
Validation loss: 2.132970166462724

Epoch: 6| Step: 4
Training loss: 2.2712039947509766
Validation loss: 2.1276967525482178

Epoch: 6| Step: 5
Training loss: 2.316619396209717
Validation loss: 2.104566228005194

Epoch: 6| Step: 6
Training loss: 1.6484112739562988
Validation loss: 2.117141683896383

Epoch: 6| Step: 7
Training loss: 1.6598467826843262
Validation loss: 2.1160747056366294

Epoch: 6| Step: 8
Training loss: 1.6090643405914307
Validation loss: 2.10815687846112

Epoch: 6| Step: 9
Training loss: 2.3893582820892334
Validation loss: 2.1111506813315937

Epoch: 6| Step: 10
Training loss: 2.372220754623413
Validation loss: 2.1207135979847243

Epoch: 6| Step: 11
Training loss: 2.136979579925537
Validation loss: 2.1070624961647937

Epoch: 6| Step: 12
Training loss: 2.258561611175537
Validation loss: 2.1240775277537685

Epoch: 6| Step: 13
Training loss: 2.1824264526367188
Validation loss: 2.1099685686890797

Epoch: 111| Step: 0
Training loss: 2.2867119312286377
Validation loss: 2.1119548120806293

Epoch: 6| Step: 1
Training loss: 2.4344892501831055
Validation loss: 2.1078277634036158

Epoch: 6| Step: 2
Training loss: 2.5068490505218506
Validation loss: 2.1117982300378944

Epoch: 6| Step: 3
Training loss: 1.9282481670379639
Validation loss: 2.1167838996456516

Epoch: 6| Step: 4
Training loss: 2.505270481109619
Validation loss: 2.0874654375096804

Epoch: 6| Step: 5
Training loss: 2.08312726020813
Validation loss: 2.127144553328073

Epoch: 6| Step: 6
Training loss: 2.307575225830078
Validation loss: 2.09443603023406

Epoch: 6| Step: 7
Training loss: 2.0740795135498047
Validation loss: 2.1090365173996135

Epoch: 6| Step: 8
Training loss: 2.0809080600738525
Validation loss: 2.1186571582671134

Epoch: 6| Step: 9
Training loss: 1.8236712217330933
Validation loss: 2.1084311636545325

Epoch: 6| Step: 10
Training loss: 1.6596781015396118
Validation loss: 2.0980863058438866

Epoch: 6| Step: 11
Training loss: 1.6147475242614746
Validation loss: 2.1100379497774187

Epoch: 6| Step: 12
Training loss: 1.9616069793701172
Validation loss: 2.1183664619281726

Epoch: 6| Step: 13
Training loss: 3.7555017471313477
Validation loss: 2.1095535370611374

Epoch: 112| Step: 0
Training loss: 1.9535021781921387
Validation loss: 2.1283894456842893

Epoch: 6| Step: 1
Training loss: 2.1267242431640625
Validation loss: 2.104925271003477

Epoch: 6| Step: 2
Training loss: 2.8203935623168945
Validation loss: 2.109688589649816

Epoch: 6| Step: 3
Training loss: 1.8326210975646973
Validation loss: 2.1140090829582623

Epoch: 6| Step: 4
Training loss: 2.3567631244659424
Validation loss: 2.1231030751300115

Epoch: 6| Step: 5
Training loss: 1.7423901557922363
Validation loss: 2.101884704764171

Epoch: 6| Step: 6
Training loss: 2.0718889236450195
Validation loss: 2.1244464228230138

Epoch: 6| Step: 7
Training loss: 1.5595159530639648
Validation loss: 2.121825356637278

Epoch: 6| Step: 8
Training loss: 2.34441876411438
Validation loss: 2.088448457820441

Epoch: 6| Step: 9
Training loss: 1.8001790046691895
Validation loss: 2.0993977195473126

Epoch: 6| Step: 10
Training loss: 2.6988072395324707
Validation loss: 2.117954807896768

Epoch: 6| Step: 11
Training loss: 2.1519882678985596
Validation loss: 2.1094489687232563

Epoch: 6| Step: 12
Training loss: 2.6485800743103027
Validation loss: 2.1158411913020636

Epoch: 6| Step: 13
Training loss: 2.5465028285980225
Validation loss: 2.112025119925058

Epoch: 113| Step: 0
Training loss: 1.4307103157043457
Validation loss: 2.11114094590628

Epoch: 6| Step: 1
Training loss: 1.72078275680542
Validation loss: 2.1037188755568637

Epoch: 6| Step: 2
Training loss: 2.535905361175537
Validation loss: 2.1108754937366774

Epoch: 6| Step: 3
Training loss: 2.09478497505188
Validation loss: 2.12215414098514

Epoch: 6| Step: 4
Training loss: 2.4104559421539307
Validation loss: 2.107263575318039

Epoch: 6| Step: 5
Training loss: 2.0803956985473633
Validation loss: 2.1104640563329062

Epoch: 6| Step: 6
Training loss: 2.032022476196289
Validation loss: 2.124349783825618

Epoch: 6| Step: 7
Training loss: 1.7745661735534668
Validation loss: 2.0801541882176555

Epoch: 6| Step: 8
Training loss: 2.038766384124756
Validation loss: 2.112726519184728

Epoch: 6| Step: 9
Training loss: 2.295741558074951
Validation loss: 2.1300593294123167

Epoch: 6| Step: 10
Training loss: 2.657550811767578
Validation loss: 2.1226482878449144

Epoch: 6| Step: 11
Training loss: 1.9385035037994385
Validation loss: 2.117437470343805

Epoch: 6| Step: 12
Training loss: 3.1122472286224365
Validation loss: 2.109315144118442

Epoch: 6| Step: 13
Training loss: 1.5756465196609497
Validation loss: 2.1224848583180416

Epoch: 114| Step: 0
Training loss: 1.7169907093048096
Validation loss: 2.0993457853153186

Epoch: 6| Step: 1
Training loss: 2.2933993339538574
Validation loss: 2.1115674229078394

Epoch: 6| Step: 2
Training loss: 2.5996978282928467
Validation loss: 2.1053066317753126

Epoch: 6| Step: 3
Training loss: 2.7140259742736816
Validation loss: 2.1123419397620746

Epoch: 6| Step: 4
Training loss: 1.39301598072052
Validation loss: 2.1059193354780956

Epoch: 6| Step: 5
Training loss: 1.8234636783599854
Validation loss: 2.0935978556192048

Epoch: 6| Step: 6
Training loss: 2.098099708557129
Validation loss: 2.0960420562374975

Epoch: 6| Step: 7
Training loss: 1.547579050064087
Validation loss: 2.094061005500055

Epoch: 6| Step: 8
Training loss: 2.245966911315918
Validation loss: 2.120130440240265

Epoch: 6| Step: 9
Training loss: 1.8262919187545776
Validation loss: 2.0882184736190306

Epoch: 6| Step: 10
Training loss: 3.1019339561462402
Validation loss: 2.1136308229097756

Epoch: 6| Step: 11
Training loss: 2.535825490951538
Validation loss: 2.1223202110618673

Epoch: 6| Step: 12
Training loss: 2.0967252254486084
Validation loss: 2.1053281022656347

Epoch: 6| Step: 13
Training loss: 2.033381462097168
Validation loss: 2.0964783135280816

Epoch: 115| Step: 0
Training loss: 2.149747133255005
Validation loss: 2.1054174515508834

Epoch: 6| Step: 1
Training loss: 1.7394461631774902
Validation loss: 2.099705575614847

Epoch: 6| Step: 2
Training loss: 1.9929111003875732
Validation loss: 2.0788382061066164

Epoch: 6| Step: 3
Training loss: 2.146545886993408
Validation loss: 2.1240664938444733

Epoch: 6| Step: 4
Training loss: 2.157595634460449
Validation loss: 2.1166675372790267

Epoch: 6| Step: 5
Training loss: 2.3114771842956543
Validation loss: 2.1073207957770235

Epoch: 6| Step: 6
Training loss: 3.603726387023926
Validation loss: 2.1178551540579846

Epoch: 6| Step: 7
Training loss: 1.9768152236938477
Validation loss: 2.1055389732442875

Epoch: 6| Step: 8
Training loss: 1.7609660625457764
Validation loss: 2.115469987674426

Epoch: 6| Step: 9
Training loss: 2.2117342948913574
Validation loss: 2.0939595250673193

Epoch: 6| Step: 10
Training loss: 2.318657398223877
Validation loss: 2.11167242962827

Epoch: 6| Step: 11
Training loss: 2.3936781883239746
Validation loss: 2.099544726392274

Epoch: 6| Step: 12
Training loss: 1.8173763751983643
Validation loss: 2.1101369011786675

Epoch: 6| Step: 13
Training loss: 1.1722440719604492
Validation loss: 2.110024485536801

Epoch: 116| Step: 0
Training loss: 1.7325387001037598
Validation loss: 2.1240246013928483

Epoch: 6| Step: 1
Training loss: 1.6227138042449951
Validation loss: 2.102022191529633

Epoch: 6| Step: 2
Training loss: 1.9837019443511963
Validation loss: 2.107850190131895

Epoch: 6| Step: 3
Training loss: 2.6323130130767822
Validation loss: 2.1200803223476616

Epoch: 6| Step: 4
Training loss: 2.5542471408843994
Validation loss: 2.1285795319464897

Epoch: 6| Step: 5
Training loss: 1.3371052742004395
Validation loss: 2.109286364688668

Epoch: 6| Step: 6
Training loss: 2.069143295288086
Validation loss: 2.1108852048074045

Epoch: 6| Step: 7
Training loss: 2.9805643558502197
Validation loss: 2.129782058859384

Epoch: 6| Step: 8
Training loss: 1.8068523406982422
Validation loss: 2.113704995442462

Epoch: 6| Step: 9
Training loss: 2.7204389572143555
Validation loss: 2.120905086558352

Epoch: 6| Step: 10
Training loss: 2.2064599990844727
Validation loss: 2.105291074322116

Epoch: 6| Step: 11
Training loss: 1.7909080982208252
Validation loss: 2.1136033176093973

Epoch: 6| Step: 12
Training loss: 2.423506259918213
Validation loss: 2.105168678427255

Epoch: 6| Step: 13
Training loss: 2.3178892135620117
Validation loss: 2.1172666088227303

Epoch: 117| Step: 0
Training loss: 2.291074752807617
Validation loss: 2.111040366593228

Epoch: 6| Step: 1
Training loss: 2.228233814239502
Validation loss: 2.1191952920729116

Epoch: 6| Step: 2
Training loss: 2.1085832118988037
Validation loss: 2.122972996004166

Epoch: 6| Step: 3
Training loss: 2.3491194248199463
Validation loss: 2.093883865623064

Epoch: 6| Step: 4
Training loss: 2.0767531394958496
Validation loss: 2.123877961148498

Epoch: 6| Step: 5
Training loss: 2.2476577758789062
Validation loss: 2.121676383479949

Epoch: 6| Step: 6
Training loss: 2.648996114730835
Validation loss: 2.087952249793596

Epoch: 6| Step: 7
Training loss: 2.3468589782714844
Validation loss: 2.0986500273468676

Epoch: 6| Step: 8
Training loss: 2.477240562438965
Validation loss: 2.107304774304872

Epoch: 6| Step: 9
Training loss: 2.5504817962646484
Validation loss: 2.1177730842303206

Epoch: 6| Step: 10
Training loss: 1.3988065719604492
Validation loss: 2.1249744789574736

Epoch: 6| Step: 11
Training loss: 1.8446824550628662
Validation loss: 2.0866465876179356

Epoch: 6| Step: 12
Training loss: 1.3037678003311157
Validation loss: 2.1200707086952786

Epoch: 6| Step: 13
Training loss: 2.182720184326172
Validation loss: 2.106887863528344

Epoch: 118| Step: 0
Training loss: 1.9370191097259521
Validation loss: 2.1104327632534887

Epoch: 6| Step: 1
Training loss: 2.0603647232055664
Validation loss: 2.096868990569986

Epoch: 6| Step: 2
Training loss: 2.4062845706939697
Validation loss: 2.1008620185236775

Epoch: 6| Step: 3
Training loss: 1.576372742652893
Validation loss: 2.1046478979049192

Epoch: 6| Step: 4
Training loss: 2.3582687377929688
Validation loss: 2.101459505737469

Epoch: 6| Step: 5
Training loss: 2.7243924140930176
Validation loss: 2.084069505814583

Epoch: 6| Step: 6
Training loss: 2.087245464324951
Validation loss: 2.122982489165439

Epoch: 6| Step: 7
Training loss: 2.003513813018799
Validation loss: 2.099616645484842

Epoch: 6| Step: 8
Training loss: 1.9977903366088867
Validation loss: 2.117403875115097

Epoch: 6| Step: 9
Training loss: 2.041076421737671
Validation loss: 2.1001755473434285

Epoch: 6| Step: 10
Training loss: 2.6412880420684814
Validation loss: 2.0933374551034745

Epoch: 6| Step: 11
Training loss: 1.2706561088562012
Validation loss: 2.0941518980969667

Epoch: 6| Step: 12
Training loss: 2.281571865081787
Validation loss: 2.120740318811068

Epoch: 6| Step: 13
Training loss: 3.0334997177124023
Validation loss: 2.10945100040846

Epoch: 119| Step: 0
Training loss: 2.069765329360962
Validation loss: 2.102297950816411

Epoch: 6| Step: 1
Training loss: 2.030532121658325
Validation loss: 2.107931726722307

Epoch: 6| Step: 2
Training loss: 2.5407283306121826
Validation loss: 2.1055879426258866

Epoch: 6| Step: 3
Training loss: 1.5643656253814697
Validation loss: 2.1090802095269643

Epoch: 6| Step: 4
Training loss: 2.519883394241333
Validation loss: 2.0937747186230076

Epoch: 6| Step: 5
Training loss: 2.586397171020508
Validation loss: 2.113159312996813

Epoch: 6| Step: 6
Training loss: 2.1074271202087402
Validation loss: 2.0975193772264706

Epoch: 6| Step: 7
Training loss: 1.769798994064331
Validation loss: 2.0893824074857976

Epoch: 6| Step: 8
Training loss: 2.287855863571167
Validation loss: 2.0971619198399205

Epoch: 6| Step: 9
Training loss: 2.376774787902832
Validation loss: 2.115779206316958

Epoch: 6| Step: 10
Training loss: 1.9086267948150635
Validation loss: 2.128399195209626

Epoch: 6| Step: 11
Training loss: 2.2085444927215576
Validation loss: 2.1084302727894118

Epoch: 6| Step: 12
Training loss: 1.9727106094360352
Validation loss: 2.125384966532389

Epoch: 6| Step: 13
Training loss: 1.653971791267395
Validation loss: 2.0995171813554663

Epoch: 120| Step: 0
Training loss: 2.619523048400879
Validation loss: 2.095953877254199

Epoch: 6| Step: 1
Training loss: 2.8723931312561035
Validation loss: 2.1043164576253583

Epoch: 6| Step: 2
Training loss: 1.6612188816070557
Validation loss: 2.1047282129205684

Epoch: 6| Step: 3
Training loss: 2.4834628105163574
Validation loss: 2.1007843940488753

Epoch: 6| Step: 4
Training loss: 1.775597333908081
Validation loss: 2.09830480493525

Epoch: 6| Step: 5
Training loss: 2.433223247528076
Validation loss: 2.1012966530297392

Epoch: 6| Step: 6
Training loss: 1.3367869853973389
Validation loss: 2.0968231078117125

Epoch: 6| Step: 7
Training loss: 2.0657148361206055
Validation loss: 2.103756199600876

Epoch: 6| Step: 8
Training loss: 2.410618782043457
Validation loss: 2.111141368906985

Epoch: 6| Step: 9
Training loss: 1.8761694431304932
Validation loss: 2.087273443898847

Epoch: 6| Step: 10
Training loss: 1.979801058769226
Validation loss: 2.1032125898586806

Epoch: 6| Step: 11
Training loss: 2.033785581588745
Validation loss: 2.0875451949334916

Epoch: 6| Step: 12
Training loss: 2.3446273803710938
Validation loss: 2.1256432405082126

Epoch: 6| Step: 13
Training loss: 2.0737626552581787
Validation loss: 2.0937954315575222

Epoch: 121| Step: 0
Training loss: 2.2419748306274414
Validation loss: 2.098534640445504

Epoch: 6| Step: 1
Training loss: 1.7985286712646484
Validation loss: 2.0978971142922678

Epoch: 6| Step: 2
Training loss: 3.587482452392578
Validation loss: 2.1091296954821517

Epoch: 6| Step: 3
Training loss: 2.164989948272705
Validation loss: 2.0976513701100505

Epoch: 6| Step: 4
Training loss: 2.39074444770813
Validation loss: 2.0951008963328537

Epoch: 6| Step: 5
Training loss: 2.3079981803894043
Validation loss: 2.1120079717328473

Epoch: 6| Step: 6
Training loss: 1.8491015434265137
Validation loss: 2.11417204846618

Epoch: 6| Step: 7
Training loss: 2.3873391151428223
Validation loss: 2.0972595163570937

Epoch: 6| Step: 8
Training loss: 1.8685246706008911
Validation loss: 2.1164927610787014

Epoch: 6| Step: 9
Training loss: 1.5445451736450195
Validation loss: 2.092784382963693

Epoch: 6| Step: 10
Training loss: 2.0100221633911133
Validation loss: 2.1019395243737007

Epoch: 6| Step: 11
Training loss: 1.9165679216384888
Validation loss: 2.1011263811460106

Epoch: 6| Step: 12
Training loss: 1.6995450258255005
Validation loss: 2.0952614622731365

Epoch: 6| Step: 13
Training loss: 2.0883467197418213
Validation loss: 2.095562160656016

Epoch: 122| Step: 0
Training loss: 1.8511019945144653
Validation loss: 2.096070078111464

Epoch: 6| Step: 1
Training loss: 1.876499891281128
Validation loss: 2.0990999898602887

Epoch: 6| Step: 2
Training loss: 1.9643977880477905
Validation loss: 2.103706454717985

Epoch: 6| Step: 3
Training loss: 2.292637348175049
Validation loss: 2.0885085508387577

Epoch: 6| Step: 4
Training loss: 2.673983573913574
Validation loss: 2.1212925244403142

Epoch: 6| Step: 5
Training loss: 2.2447550296783447
Validation loss: 2.1001485957894275

Epoch: 6| Step: 6
Training loss: 1.4848310947418213
Validation loss: 2.0970191955566406

Epoch: 6| Step: 7
Training loss: 2.050031900405884
Validation loss: 2.1040368797958537

Epoch: 6| Step: 8
Training loss: 2.3884832859039307
Validation loss: 2.0954583819194506

Epoch: 6| Step: 9
Training loss: 2.3327841758728027
Validation loss: 2.0910581388781146

Epoch: 6| Step: 10
Training loss: 2.0860280990600586
Validation loss: 2.10228362647436

Epoch: 6| Step: 11
Training loss: 1.4935917854309082
Validation loss: 2.0914832622774187

Epoch: 6| Step: 12
Training loss: 2.5681958198547363
Validation loss: 2.117900533060874

Epoch: 6| Step: 13
Training loss: 2.736497163772583
Validation loss: 2.1266053594568723

Epoch: 123| Step: 0
Training loss: 2.290447235107422
Validation loss: 2.084144451284921

Epoch: 6| Step: 1
Training loss: 1.8968757390975952
Validation loss: 2.1121832568158387

Epoch: 6| Step: 2
Training loss: 1.986985206604004
Validation loss: 2.1068110260912167

Epoch: 6| Step: 3
Training loss: 2.458669424057007
Validation loss: 2.086568045359786

Epoch: 6| Step: 4
Training loss: 1.5865123271942139
Validation loss: 2.0922254823869273

Epoch: 6| Step: 5
Training loss: 2.3064730167388916
Validation loss: 2.0855412060214626

Epoch: 6| Step: 6
Training loss: 2.2890477180480957
Validation loss: 2.1252010663350425

Epoch: 6| Step: 7
Training loss: 2.2706708908081055
Validation loss: 2.119823478883313

Epoch: 6| Step: 8
Training loss: 2.1948187351226807
Validation loss: 2.1173686058290544

Epoch: 6| Step: 9
Training loss: 1.6402969360351562
Validation loss: 2.1074379797904723

Epoch: 6| Step: 10
Training loss: 2.1957969665527344
Validation loss: 2.0802866515292915

Epoch: 6| Step: 11
Training loss: 2.2074387073516846
Validation loss: 2.0905735825979583

Epoch: 6| Step: 12
Training loss: 2.4394145011901855
Validation loss: 2.1144391080384612

Epoch: 6| Step: 13
Training loss: 1.9763518571853638
Validation loss: 2.0944815963827152

Epoch: 124| Step: 0
Training loss: 2.1440372467041016
Validation loss: 2.0837937965187976

Epoch: 6| Step: 1
Training loss: 1.9241842031478882
Validation loss: 2.0947606076476393

Epoch: 6| Step: 2
Training loss: 2.4390556812286377
Validation loss: 2.098507978582895

Epoch: 6| Step: 3
Training loss: 1.943679690361023
Validation loss: 2.0941259630264772

Epoch: 6| Step: 4
Training loss: 2.173337459564209
Validation loss: 2.084741852616751

Epoch: 6| Step: 5
Training loss: 2.4599969387054443
Validation loss: 2.107107423966931

Epoch: 6| Step: 6
Training loss: 2.783482074737549
Validation loss: 2.1090082455706853

Epoch: 6| Step: 7
Training loss: 1.7100696563720703
Validation loss: 2.1117125198405278

Epoch: 6| Step: 8
Training loss: 1.752325177192688
Validation loss: 2.10617660450679

Epoch: 6| Step: 9
Training loss: 1.7495896816253662
Validation loss: 2.1098742408137166

Epoch: 6| Step: 10
Training loss: 2.0873537063598633
Validation loss: 2.093526706900648

Epoch: 6| Step: 11
Training loss: 1.8270543813705444
Validation loss: 2.0745887397437968

Epoch: 6| Step: 12
Training loss: 2.827214241027832
Validation loss: 2.098085705951978

Epoch: 6| Step: 13
Training loss: 1.7441946268081665
Validation loss: 2.102252615395413

Epoch: 125| Step: 0
Training loss: 2.8762640953063965
Validation loss: 2.0875639633465837

Epoch: 6| Step: 1
Training loss: 2.41810941696167
Validation loss: 2.0975501896232687

Epoch: 6| Step: 2
Training loss: 1.4182283878326416
Validation loss: 2.083433505027525

Epoch: 6| Step: 3
Training loss: 1.95442795753479
Validation loss: 2.0875808269746843

Epoch: 6| Step: 4
Training loss: 1.8293898105621338
Validation loss: 2.107089827137609

Epoch: 6| Step: 5
Training loss: 2.336562156677246
Validation loss: 2.088012379984702

Epoch: 6| Step: 6
Training loss: 2.2806079387664795
Validation loss: 2.1019634264771656

Epoch: 6| Step: 7
Training loss: 1.8771854639053345
Validation loss: 2.086315519066267

Epoch: 6| Step: 8
Training loss: 2.876122236251831
Validation loss: 2.076885491289118

Epoch: 6| Step: 9
Training loss: 1.3526521921157837
Validation loss: 2.0946499788632957

Epoch: 6| Step: 10
Training loss: 2.999476194381714
Validation loss: 2.1106710305777927

Epoch: 6| Step: 11
Training loss: 1.2993513345718384
Validation loss: 2.09846560160319

Epoch: 6| Step: 12
Training loss: 2.2862181663513184
Validation loss: 2.1183237888479747

Epoch: 6| Step: 13
Training loss: 1.8292677402496338
Validation loss: 2.080788499565535

Epoch: 126| Step: 0
Training loss: 2.0762388706207275
Validation loss: 2.09857613296919

Epoch: 6| Step: 1
Training loss: 2.026498794555664
Validation loss: 2.092787875924059

Epoch: 6| Step: 2
Training loss: 2.29158616065979
Validation loss: 2.1120073051862818

Epoch: 6| Step: 3
Training loss: 2.5112099647521973
Validation loss: 2.0823282580221854

Epoch: 6| Step: 4
Training loss: 2.4390058517456055
Validation loss: 2.092331253072267

Epoch: 6| Step: 5
Training loss: 1.9313430786132812
Validation loss: 2.1163923740386963

Epoch: 6| Step: 6
Training loss: 2.592010021209717
Validation loss: 2.090233979686614

Epoch: 6| Step: 7
Training loss: 2.4589858055114746
Validation loss: 2.105516775961845

Epoch: 6| Step: 8
Training loss: 2.129211902618408
Validation loss: 2.0849350370386595

Epoch: 6| Step: 9
Training loss: 1.653961181640625
Validation loss: 2.0902122938504784

Epoch: 6| Step: 10
Training loss: 1.3999454975128174
Validation loss: 2.0945485458579114

Epoch: 6| Step: 11
Training loss: 2.2278833389282227
Validation loss: 2.107854699575773

Epoch: 6| Step: 12
Training loss: 2.0796258449554443
Validation loss: 2.103014169200774

Epoch: 6| Step: 13
Training loss: 1.8113198280334473
Validation loss: 2.1111951515238774

Epoch: 127| Step: 0
Training loss: 2.5703835487365723
Validation loss: 2.1179827541433354

Epoch: 6| Step: 1
Training loss: 2.6354360580444336
Validation loss: 2.0926442248846895

Epoch: 6| Step: 2
Training loss: 1.870203971862793
Validation loss: 2.08163385493781

Epoch: 6| Step: 3
Training loss: 2.178832769393921
Validation loss: 2.096959029474566

Epoch: 6| Step: 4
Training loss: 2.0382936000823975
Validation loss: 2.087938424079649

Epoch: 6| Step: 5
Training loss: 2.081075668334961
Validation loss: 2.1066351834163872

Epoch: 6| Step: 6
Training loss: 2.2947781085968018
Validation loss: 2.092952653925906

Epoch: 6| Step: 7
Training loss: 2.275364398956299
Validation loss: 2.1061837263004755

Epoch: 6| Step: 8
Training loss: 1.783548355102539
Validation loss: 2.1081882651134203

Epoch: 6| Step: 9
Training loss: 2.174527645111084
Validation loss: 2.1132409316237255

Epoch: 6| Step: 10
Training loss: 1.8495277166366577
Validation loss: 2.10638468111715

Epoch: 6| Step: 11
Training loss: 2.2189605236053467
Validation loss: 2.0993846488255326

Epoch: 6| Step: 12
Training loss: 1.7644495964050293
Validation loss: 2.101005995145408

Epoch: 6| Step: 13
Training loss: 1.994089961051941
Validation loss: 2.0978643689104306

Epoch: 128| Step: 0
Training loss: 2.633208751678467
Validation loss: 2.1080876037638676

Epoch: 6| Step: 1
Training loss: 1.7053916454315186
Validation loss: 2.1133768866139073

Epoch: 6| Step: 2
Training loss: 2.3724169731140137
Validation loss: 2.108498170811643

Epoch: 6| Step: 3
Training loss: 2.6843831539154053
Validation loss: 2.0906020287544496

Epoch: 6| Step: 4
Training loss: 1.8563306331634521
Validation loss: 2.1000205880852154

Epoch: 6| Step: 5
Training loss: 2.4009318351745605
Validation loss: 2.08547197106064

Epoch: 6| Step: 6
Training loss: 1.8086930513381958
Validation loss: 2.1061504015358548

Epoch: 6| Step: 7
Training loss: 2.934342622756958
Validation loss: 2.08793633214889

Epoch: 6| Step: 8
Training loss: 2.222426176071167
Validation loss: 2.0946587029323784

Epoch: 6| Step: 9
Training loss: 1.360659122467041
Validation loss: 2.1059839815221806

Epoch: 6| Step: 10
Training loss: 1.8148152828216553
Validation loss: 2.0941903770610852

Epoch: 6| Step: 11
Training loss: 2.3410449028015137
Validation loss: 2.0934383920443955

Epoch: 6| Step: 12
Training loss: 1.910243272781372
Validation loss: 2.0916404313938592

Epoch: 6| Step: 13
Training loss: 1.511445164680481
Validation loss: 2.1042694148196968

Epoch: 129| Step: 0
Training loss: 2.7190170288085938
Validation loss: 2.0737451635381228

Epoch: 6| Step: 1
Training loss: 2.5385231971740723
Validation loss: 2.1108267281645086

Epoch: 6| Step: 2
Training loss: 1.9574224948883057
Validation loss: 2.0733420823210027

Epoch: 6| Step: 3
Training loss: 2.17189884185791
Validation loss: 2.126891977043562

Epoch: 6| Step: 4
Training loss: 2.0289509296417236
Validation loss: 2.1009094433117936

Epoch: 6| Step: 5
Training loss: 1.811529517173767
Validation loss: 2.0945915124749623

Epoch: 6| Step: 6
Training loss: 2.157017230987549
Validation loss: 2.09297316176917

Epoch: 6| Step: 7
Training loss: 1.6055792570114136
Validation loss: 2.118049954855314

Epoch: 6| Step: 8
Training loss: 2.0440125465393066
Validation loss: 2.083009623712109

Epoch: 6| Step: 9
Training loss: 2.166682720184326
Validation loss: 2.092419385910034

Epoch: 6| Step: 10
Training loss: 1.7167510986328125
Validation loss: 2.086410671152094

Epoch: 6| Step: 11
Training loss: 1.845283031463623
Validation loss: 2.0861608520630868

Epoch: 6| Step: 12
Training loss: 2.898402214050293
Validation loss: 2.08652671306364

Epoch: 6| Step: 13
Training loss: 2.0087761878967285
Validation loss: 2.0617343148877545

Epoch: 130| Step: 0
Training loss: 1.8950921297073364
Validation loss: 2.0987906661084903

Epoch: 6| Step: 1
Training loss: 2.9450650215148926
Validation loss: 2.0761555471727924

Epoch: 6| Step: 2
Training loss: 2.526416778564453
Validation loss: 2.082683760632751

Epoch: 6| Step: 3
Training loss: 2.6344826221466064
Validation loss: 2.097799103747132

Epoch: 6| Step: 4
Training loss: 2.687592029571533
Validation loss: 2.0883091918883787

Epoch: 6| Step: 5
Training loss: 1.3557978868484497
Validation loss: 2.1062636349790838

Epoch: 6| Step: 6
Training loss: 1.6976044178009033
Validation loss: 2.096584232904578

Epoch: 6| Step: 7
Training loss: 1.9931279420852661
Validation loss: 2.09582870493653

Epoch: 6| Step: 8
Training loss: 1.5233317613601685
Validation loss: 2.078677454302388

Epoch: 6| Step: 9
Training loss: 2.187749147415161
Validation loss: 2.096046337517359

Epoch: 6| Step: 10
Training loss: 2.593228340148926
Validation loss: 2.1126243196507937

Epoch: 6| Step: 11
Training loss: 1.8114583492279053
Validation loss: 2.10610015930668

Epoch: 6| Step: 12
Training loss: 1.453404426574707
Validation loss: 2.078521631097281

Epoch: 6| Step: 13
Training loss: 2.4890599250793457
Validation loss: 2.074551092681064

Epoch: 131| Step: 0
Training loss: 3.073718547821045
Validation loss: 2.0918312431663595

Epoch: 6| Step: 1
Training loss: 2.540417194366455
Validation loss: 2.094123558331561

Epoch: 6| Step: 2
Training loss: 2.376450538635254
Validation loss: 2.0903099916314565

Epoch: 6| Step: 3
Training loss: 1.96238374710083
Validation loss: 2.09568259280215

Epoch: 6| Step: 4
Training loss: 1.7249243259429932
Validation loss: 2.081280569876394

Epoch: 6| Step: 5
Training loss: 1.951846718788147
Validation loss: 2.063965937142731

Epoch: 6| Step: 6
Training loss: 1.7727060317993164
Validation loss: 2.105603625697474

Epoch: 6| Step: 7
Training loss: 1.4675570726394653
Validation loss: 2.0857667333336285

Epoch: 6| Step: 8
Training loss: 2.234252452850342
Validation loss: 2.0995049566350956

Epoch: 6| Step: 9
Training loss: 1.5677011013031006
Validation loss: 2.085571389044485

Epoch: 6| Step: 10
Training loss: 2.334502696990967
Validation loss: 2.099025798100297

Epoch: 6| Step: 11
Training loss: 1.7639254331588745
Validation loss: 2.1074344112027075

Epoch: 6| Step: 12
Training loss: 2.702887535095215
Validation loss: 2.100022792816162

Epoch: 6| Step: 13
Training loss: 2.421442985534668
Validation loss: 2.111545208961733

Epoch: 132| Step: 0
Training loss: 1.907179594039917
Validation loss: 2.0977274781914166

Epoch: 6| Step: 1
Training loss: 2.221104383468628
Validation loss: 2.091790203125246

Epoch: 6| Step: 2
Training loss: 2.443202257156372
Validation loss: 2.0934700030152515

Epoch: 6| Step: 3
Training loss: 2.1449027061462402
Validation loss: 2.068075112117234

Epoch: 6| Step: 4
Training loss: 2.1707863807678223
Validation loss: 2.0954235112795265

Epoch: 6| Step: 5
Training loss: 2.491269111633301
Validation loss: 2.0867562652916036

Epoch: 6| Step: 6
Training loss: 2.0893073081970215
Validation loss: 2.086291987408874

Epoch: 6| Step: 7
Training loss: 2.495802879333496
Validation loss: 2.078405208485101

Epoch: 6| Step: 8
Training loss: 2.647360324859619
Validation loss: 2.096379251890285

Epoch: 6| Step: 9
Training loss: 1.682834267616272
Validation loss: 2.0928480343152116

Epoch: 6| Step: 10
Training loss: 2.2773497104644775
Validation loss: 2.069930852100413

Epoch: 6| Step: 11
Training loss: 1.678234577178955
Validation loss: 2.0851121640974477

Epoch: 6| Step: 12
Training loss: 1.7199586629867554
Validation loss: 2.079466255762244

Epoch: 6| Step: 13
Training loss: 1.164135217666626
Validation loss: 2.089794515281595

Epoch: 133| Step: 0
Training loss: 2.9686882495880127
Validation loss: 2.1063470481544413

Epoch: 6| Step: 1
Training loss: 2.3783648014068604
Validation loss: 2.0737885121376283

Epoch: 6| Step: 2
Training loss: 2.64056134223938
Validation loss: 2.087857210507957

Epoch: 6| Step: 3
Training loss: 2.221047878265381
Validation loss: 2.086880144252572

Epoch: 6| Step: 4
Training loss: 2.1163177490234375
Validation loss: 2.0653219082022227

Epoch: 6| Step: 5
Training loss: 1.5816220045089722
Validation loss: 2.077152000960483

Epoch: 6| Step: 6
Training loss: 1.6172360181808472
Validation loss: 2.10103553213099

Epoch: 6| Step: 7
Training loss: 1.632306456565857
Validation loss: 2.076036448119789

Epoch: 6| Step: 8
Training loss: 1.9855706691741943
Validation loss: 2.0733310996845202

Epoch: 6| Step: 9
Training loss: 2.4419589042663574
Validation loss: 2.0917298845065537

Epoch: 6| Step: 10
Training loss: 1.7124574184417725
Validation loss: 2.0862809816996255

Epoch: 6| Step: 11
Training loss: 2.7470006942749023
Validation loss: 2.1002636314720236

Epoch: 6| Step: 12
Training loss: 1.6514739990234375
Validation loss: 2.099465563733091

Epoch: 6| Step: 13
Training loss: 1.9864287376403809
Validation loss: 2.0893330727854083

Epoch: 134| Step: 0
Training loss: 2.029621124267578
Validation loss: 2.0761213328248713

Epoch: 6| Step: 1
Training loss: 1.7541725635528564
Validation loss: 2.066323939190116

Epoch: 6| Step: 2
Training loss: 1.8068606853485107
Validation loss: 2.0841392317125873

Epoch: 6| Step: 3
Training loss: 2.5902814865112305
Validation loss: 2.093853099371797

Epoch: 6| Step: 4
Training loss: 1.8878370523452759
Validation loss: 2.1035984229016047

Epoch: 6| Step: 5
Training loss: 1.9480479955673218
Validation loss: 2.092942235290363

Epoch: 6| Step: 6
Training loss: 1.707773208618164
Validation loss: 2.0910169411731023

Epoch: 6| Step: 7
Training loss: 2.048266887664795
Validation loss: 2.092329896906371

Epoch: 6| Step: 8
Training loss: 2.3150105476379395
Validation loss: 2.0934071643378145

Epoch: 6| Step: 9
Training loss: 3.3791325092315674
Validation loss: 2.0849842691934235

Epoch: 6| Step: 10
Training loss: 2.434516429901123
Validation loss: 2.0605702707844396

Epoch: 6| Step: 11
Training loss: 1.772831916809082
Validation loss: 2.0688566879559587

Epoch: 6| Step: 12
Training loss: 1.7286114692687988
Validation loss: 2.0838741512708765

Epoch: 6| Step: 13
Training loss: 1.885079264640808
Validation loss: 2.0920803777633177

Epoch: 135| Step: 0
Training loss: 2.610555648803711
Validation loss: 2.0757713394780315

Epoch: 6| Step: 1
Training loss: 2.194993019104004
Validation loss: 2.083199583074098

Epoch: 6| Step: 2
Training loss: 1.9907951354980469
Validation loss: 2.086107396310376

Epoch: 6| Step: 3
Training loss: 2.1226820945739746
Validation loss: 2.080061794609152

Epoch: 6| Step: 4
Training loss: 1.9927666187286377
Validation loss: 2.0840243267756637

Epoch: 6| Step: 5
Training loss: 1.9911081790924072
Validation loss: 2.0878645066292054

Epoch: 6| Step: 6
Training loss: 2.068448066711426
Validation loss: 2.0934071874105804

Epoch: 6| Step: 7
Training loss: 2.451432943344116
Validation loss: 2.101995604012602

Epoch: 6| Step: 8
Training loss: 2.50691556930542
Validation loss: 2.087189289831346

Epoch: 6| Step: 9
Training loss: 2.2798805236816406
Validation loss: 2.0942326745679303

Epoch: 6| Step: 10
Training loss: 2.1843104362487793
Validation loss: 2.0942983832410587

Epoch: 6| Step: 11
Training loss: 2.419142723083496
Validation loss: 2.085122090513988

Epoch: 6| Step: 12
Training loss: 1.315051555633545
Validation loss: 2.100527071183728

Epoch: 6| Step: 13
Training loss: 1.1157912015914917
Validation loss: 2.089436379812097

Epoch: 136| Step: 0
Training loss: 2.173098087310791
Validation loss: 2.070199720321163

Epoch: 6| Step: 1
Training loss: 1.804178237915039
Validation loss: 2.0823885445953696

Epoch: 6| Step: 2
Training loss: 2.0344254970550537
Validation loss: 2.095568419784628

Epoch: 6| Step: 3
Training loss: 2.4408793449401855
Validation loss: 2.0762186563143166

Epoch: 6| Step: 4
Training loss: 2.645022392272949
Validation loss: 2.10007030476806

Epoch: 6| Step: 5
Training loss: 1.9154795408248901
Validation loss: 2.0908899050886913

Epoch: 6| Step: 6
Training loss: 2.3125154972076416
Validation loss: 2.0608821658677954

Epoch: 6| Step: 7
Training loss: 1.2924386262893677
Validation loss: 2.070849831386279

Epoch: 6| Step: 8
Training loss: 2.6204347610473633
Validation loss: 2.086311512095954

Epoch: 6| Step: 9
Training loss: 1.351303219795227
Validation loss: 2.065714746393183

Epoch: 6| Step: 10
Training loss: 1.7275876998901367
Validation loss: 2.0975487283481065

Epoch: 6| Step: 11
Training loss: 2.4894845485687256
Validation loss: 2.073298450439207

Epoch: 6| Step: 12
Training loss: 2.2759668827056885
Validation loss: 2.0737466107132616

Epoch: 6| Step: 13
Training loss: 2.514955759048462
Validation loss: 2.0778996277880926

Epoch: 137| Step: 0
Training loss: 1.8397603034973145
Validation loss: 2.0907002828454457

Epoch: 6| Step: 1
Training loss: 2.449204444885254
Validation loss: 2.044037416417112

Epoch: 6| Step: 2
Training loss: 1.2610774040222168
Validation loss: 2.0590358805912796

Epoch: 6| Step: 3
Training loss: 1.7743656635284424
Validation loss: 2.0787161678396244

Epoch: 6| Step: 4
Training loss: 1.5873193740844727
Validation loss: 2.0747189342334704

Epoch: 6| Step: 5
Training loss: 1.6189806461334229
Validation loss: 2.0885935675713325

Epoch: 6| Step: 6
Training loss: 2.201266288757324
Validation loss: 2.0719823657825427

Epoch: 6| Step: 7
Training loss: 2.7489523887634277
Validation loss: 2.0863126811160835

Epoch: 6| Step: 8
Training loss: 3.4732227325439453
Validation loss: 2.085894528255668

Epoch: 6| Step: 9
Training loss: 2.369760513305664
Validation loss: 2.0699465133810557

Epoch: 6| Step: 10
Training loss: 2.431837558746338
Validation loss: 2.0913400701297227

Epoch: 6| Step: 11
Training loss: 1.7426279783248901
Validation loss: 2.0791526648306076

Epoch: 6| Step: 12
Training loss: 1.2865707874298096
Validation loss: 2.0707386386009956

Epoch: 6| Step: 13
Training loss: 3.0281126499176025
Validation loss: 2.082657378206971

Epoch: 138| Step: 0
Training loss: 1.829270839691162
Validation loss: 2.078752120335897

Epoch: 6| Step: 1
Training loss: 1.826300859451294
Validation loss: 2.083458262105142

Epoch: 6| Step: 2
Training loss: 2.135638475418091
Validation loss: 2.099742724049476

Epoch: 6| Step: 3
Training loss: 2.2604219913482666
Validation loss: 2.0733770913975214

Epoch: 6| Step: 4
Training loss: 1.3433760404586792
Validation loss: 2.1092530655604538

Epoch: 6| Step: 5
Training loss: 2.660677671432495
Validation loss: 2.094868894546263

Epoch: 6| Step: 6
Training loss: 1.9491714239120483
Validation loss: 2.0677064208574194

Epoch: 6| Step: 7
Training loss: 2.6987392902374268
Validation loss: 2.070658859386239

Epoch: 6| Step: 8
Training loss: 1.9088385105133057
Validation loss: 2.0896792104167323

Epoch: 6| Step: 9
Training loss: 1.8120107650756836
Validation loss: 2.0804661858466362

Epoch: 6| Step: 10
Training loss: 2.0447235107421875
Validation loss: 2.0641419118450535

Epoch: 6| Step: 11
Training loss: 2.7131292819976807
Validation loss: 2.080180419388638

Epoch: 6| Step: 12
Training loss: 2.015416145324707
Validation loss: 2.0988127569998465

Epoch: 6| Step: 13
Training loss: 2.4580535888671875
Validation loss: 2.0826180493959816

Epoch: 139| Step: 0
Training loss: 1.6743810176849365
Validation loss: 2.079218133803337

Epoch: 6| Step: 1
Training loss: 1.850433111190796
Validation loss: 2.0778869095669

Epoch: 6| Step: 2
Training loss: 2.4975411891937256
Validation loss: 2.0894925850693897

Epoch: 6| Step: 3
Training loss: 1.8133232593536377
Validation loss: 2.0643959122319377

Epoch: 6| Step: 4
Training loss: 2.9757676124572754
Validation loss: 2.0649758218437113

Epoch: 6| Step: 5
Training loss: 1.9268605709075928
Validation loss: 2.0992092522241736

Epoch: 6| Step: 6
Training loss: 1.9472535848617554
Validation loss: 2.090037417668168

Epoch: 6| Step: 7
Training loss: 2.2670936584472656
Validation loss: 2.110663164046503

Epoch: 6| Step: 8
Training loss: 1.9720243215560913
Validation loss: 2.0975676698069416

Epoch: 6| Step: 9
Training loss: 1.797118902206421
Validation loss: 2.0691195739212858

Epoch: 6| Step: 10
Training loss: 2.0498368740081787
Validation loss: 2.0760056857139833

Epoch: 6| Step: 11
Training loss: 2.4952735900878906
Validation loss: 2.097837440429195

Epoch: 6| Step: 12
Training loss: 1.646826982498169
Validation loss: 2.0776198423036965

Epoch: 6| Step: 13
Training loss: 2.2114624977111816
Validation loss: 2.060261890452395

Epoch: 140| Step: 0
Training loss: 2.5349349975585938
Validation loss: 2.086718010646041

Epoch: 6| Step: 1
Training loss: 1.3748435974121094
Validation loss: 2.0657808703760945

Epoch: 6| Step: 2
Training loss: 1.9487931728363037
Validation loss: 2.0850778343856975

Epoch: 6| Step: 3
Training loss: 2.492474317550659
Validation loss: 2.063288446395628

Epoch: 6| Step: 4
Training loss: 2.6553213596343994
Validation loss: 2.077350498527609

Epoch: 6| Step: 5
Training loss: 1.6565998792648315
Validation loss: 2.0731276722364527

Epoch: 6| Step: 6
Training loss: 1.86024808883667
Validation loss: 2.0607398633033998

Epoch: 6| Step: 7
Training loss: 1.8682204484939575
Validation loss: 2.084901004709223

Epoch: 6| Step: 8
Training loss: 2.034963607788086
Validation loss: 2.0721613514807915

Epoch: 6| Step: 9
Training loss: 2.1089608669281006
Validation loss: 2.060394674219111

Epoch: 6| Step: 10
Training loss: 2.1989827156066895
Validation loss: 2.070531515664952

Epoch: 6| Step: 11
Training loss: 2.593662738800049
Validation loss: 2.0739010392978625

Epoch: 6| Step: 12
Training loss: 2.005985736846924
Validation loss: 2.0696873023945797

Epoch: 6| Step: 13
Training loss: 1.716847538948059
Validation loss: 2.0730459510639148

Epoch: 141| Step: 0
Training loss: 1.8696556091308594
Validation loss: 2.0847243544875935

Epoch: 6| Step: 1
Training loss: 1.9355862140655518
Validation loss: 2.083256180568408

Epoch: 6| Step: 2
Training loss: 2.2126619815826416
Validation loss: 2.0866599646947717

Epoch: 6| Step: 3
Training loss: 1.7644553184509277
Validation loss: 2.053038530452277

Epoch: 6| Step: 4
Training loss: 1.595078706741333
Validation loss: 2.0485770240906747

Epoch: 6| Step: 5
Training loss: 2.6340250968933105
Validation loss: 2.080419853169431

Epoch: 6| Step: 6
Training loss: 1.8326411247253418
Validation loss: 2.0660682878186627

Epoch: 6| Step: 7
Training loss: 2.6075074672698975
Validation loss: 2.06925674792259

Epoch: 6| Step: 8
Training loss: 2.415337085723877
Validation loss: 2.0723194691442672

Epoch: 6| Step: 9
Training loss: 1.8801597356796265
Validation loss: 2.092242051196355

Epoch: 6| Step: 10
Training loss: 2.1877541542053223
Validation loss: 2.05494192595123

Epoch: 6| Step: 11
Training loss: 2.117107391357422
Validation loss: 2.0685287573004283

Epoch: 6| Step: 12
Training loss: 2.10800838470459
Validation loss: 2.0616379578908286

Epoch: 6| Step: 13
Training loss: 2.2364962100982666
Validation loss: 2.0760213252036803

Epoch: 142| Step: 0
Training loss: 1.827162265777588
Validation loss: 2.0785898944383026

Epoch: 6| Step: 1
Training loss: 2.252972364425659
Validation loss: 2.0716294665490427

Epoch: 6| Step: 2
Training loss: 1.7240320444107056
Validation loss: 2.070981784533429

Epoch: 6| Step: 3
Training loss: 1.939073920249939
Validation loss: 2.0538228481046614

Epoch: 6| Step: 4
Training loss: 1.5969655513763428
Validation loss: 2.077029581992857

Epoch: 6| Step: 5
Training loss: 2.6530299186706543
Validation loss: 2.086288362421015

Epoch: 6| Step: 6
Training loss: 3.1263389587402344
Validation loss: 2.0693053122489684

Epoch: 6| Step: 7
Training loss: 1.8221526145935059
Validation loss: 2.0703202063037502

Epoch: 6| Step: 8
Training loss: 1.6288095712661743
Validation loss: 2.070193242001277

Epoch: 6| Step: 9
Training loss: 2.523172616958618
Validation loss: 2.103421932907515

Epoch: 6| Step: 10
Training loss: 2.3637959957122803
Validation loss: 2.0913275877634683

Epoch: 6| Step: 11
Training loss: 1.9754184484481812
Validation loss: 2.068238651880654

Epoch: 6| Step: 12
Training loss: 1.6271612644195557
Validation loss: 2.089038905277047

Epoch: 6| Step: 13
Training loss: 2.220379590988159
Validation loss: 2.0935075308686946

Epoch: 143| Step: 0
Training loss: 2.5910749435424805
Validation loss: 2.0641943511142524

Epoch: 6| Step: 1
Training loss: 1.9063262939453125
Validation loss: 2.079351528998344

Epoch: 6| Step: 2
Training loss: 2.1835837364196777
Validation loss: 2.0751796025101856

Epoch: 6| Step: 3
Training loss: 1.8759889602661133
Validation loss: 2.0676328930803525

Epoch: 6| Step: 4
Training loss: 1.9821205139160156
Validation loss: 2.081614266159714

Epoch: 6| Step: 5
Training loss: 1.6941312551498413
Validation loss: 2.0689479279261764

Epoch: 6| Step: 6
Training loss: 1.9812742471694946
Validation loss: 2.0671821589111

Epoch: 6| Step: 7
Training loss: 1.7043708562850952
Validation loss: 2.0655741166043025

Epoch: 6| Step: 8
Training loss: 1.9073282480239868
Validation loss: 2.0726698944645543

Epoch: 6| Step: 9
Training loss: 1.960890769958496
Validation loss: 2.0671888807768464

Epoch: 6| Step: 10
Training loss: 2.6332597732543945
Validation loss: 2.0787838146250737

Epoch: 6| Step: 11
Training loss: 2.715843677520752
Validation loss: 2.075762374426729

Epoch: 6| Step: 12
Training loss: 2.342520236968994
Validation loss: 2.0524863966049685

Epoch: 6| Step: 13
Training loss: 1.8865841627120972
Validation loss: 2.066138461071958

Epoch: 144| Step: 0
Training loss: 1.7770296335220337
Validation loss: 2.068428078005391

Epoch: 6| Step: 1
Training loss: 1.9010112285614014
Validation loss: 2.075086861528376

Epoch: 6| Step: 2
Training loss: 1.950420618057251
Validation loss: 2.0539554754892984

Epoch: 6| Step: 3
Training loss: 2.852029800415039
Validation loss: 2.0836692779294905

Epoch: 6| Step: 4
Training loss: 2.281125068664551
Validation loss: 2.0682759336245957

Epoch: 6| Step: 5
Training loss: 1.7683247327804565
Validation loss: 2.0792202975160334

Epoch: 6| Step: 6
Training loss: 2.551844835281372
Validation loss: 2.0966162694397794

Epoch: 6| Step: 7
Training loss: 1.837048888206482
Validation loss: 2.082490180128364

Epoch: 6| Step: 8
Training loss: 2.5471577644348145
Validation loss: 2.0424338617632465

Epoch: 6| Step: 9
Training loss: 2.2435317039489746
Validation loss: 2.0694942115455546

Epoch: 6| Step: 10
Training loss: 2.007704257965088
Validation loss: 2.073249283657279

Epoch: 6| Step: 11
Training loss: 1.8649061918258667
Validation loss: 2.06491986525956

Epoch: 6| Step: 12
Training loss: 1.9494560956954956
Validation loss: 2.0642528482662734

Epoch: 6| Step: 13
Training loss: 1.5574240684509277
Validation loss: 2.0746618265746744

Epoch: 145| Step: 0
Training loss: 2.7004024982452393
Validation loss: 2.0682277551261325

Epoch: 6| Step: 1
Training loss: 2.294172763824463
Validation loss: 2.074186986492526

Epoch: 6| Step: 2
Training loss: 2.3924126625061035
Validation loss: 2.070352792739868

Epoch: 6| Step: 3
Training loss: 1.4791359901428223
Validation loss: 2.0410891245770197

Epoch: 6| Step: 4
Training loss: 1.616416573524475
Validation loss: 2.080118122921195

Epoch: 6| Step: 5
Training loss: 2.1119167804718018
Validation loss: 2.0517732686893915

Epoch: 6| Step: 6
Training loss: 1.7929456233978271
Validation loss: 2.0762119395758516

Epoch: 6| Step: 7
Training loss: 1.791536569595337
Validation loss: 2.0588349655110347

Epoch: 6| Step: 8
Training loss: 1.6907904148101807
Validation loss: 2.0745974766310824

Epoch: 6| Step: 9
Training loss: 1.8719199895858765
Validation loss: 2.0749961496681295

Epoch: 6| Step: 10
Training loss: 2.185119390487671
Validation loss: 2.069447330249253

Epoch: 6| Step: 11
Training loss: 2.630507469177246
Validation loss: 2.070001768809493

Epoch: 6| Step: 12
Training loss: 2.089224338531494
Validation loss: 2.0849416358496553

Epoch: 6| Step: 13
Training loss: 2.641192674636841
Validation loss: 2.076659623012748

Epoch: 146| Step: 0
Training loss: 1.87987220287323
Validation loss: 2.036702033012144

Epoch: 6| Step: 1
Training loss: 1.498582124710083
Validation loss: 2.061273664556524

Epoch: 6| Step: 2
Training loss: 2.1876401901245117
Validation loss: 2.0612069252998597

Epoch: 6| Step: 3
Training loss: 2.043379306793213
Validation loss: 2.0805654269392773

Epoch: 6| Step: 4
Training loss: 2.400599956512451
Validation loss: 2.0452024526493524

Epoch: 6| Step: 5
Training loss: 2.5166499614715576
Validation loss: 2.0790530802101217

Epoch: 6| Step: 6
Training loss: 2.6814217567443848
Validation loss: 2.0644856922088133

Epoch: 6| Step: 7
Training loss: 1.4229648113250732
Validation loss: 2.0691576465483634

Epoch: 6| Step: 8
Training loss: 2.4222326278686523
Validation loss: 2.0667590659151793

Epoch: 6| Step: 9
Training loss: 2.5960090160369873
Validation loss: 2.092186930359051

Epoch: 6| Step: 10
Training loss: 1.2160701751708984
Validation loss: 2.051633074719419

Epoch: 6| Step: 11
Training loss: 2.632812976837158
Validation loss: 2.054352360387002

Epoch: 6| Step: 12
Training loss: 1.533031702041626
Validation loss: 2.044850730126904

Epoch: 6| Step: 13
Training loss: 2.033475637435913
Validation loss: 2.038753306993874

Epoch: 147| Step: 0
Training loss: 1.691109299659729
Validation loss: 2.07671453363152

Epoch: 6| Step: 1
Training loss: 2.3524885177612305
Validation loss: 2.0702916627289145

Epoch: 6| Step: 2
Training loss: 2.7295351028442383
Validation loss: 2.084383269791962

Epoch: 6| Step: 3
Training loss: 2.665855884552002
Validation loss: 2.0593047013846775

Epoch: 6| Step: 4
Training loss: 2.2068848609924316
Validation loss: 2.0598889730309926

Epoch: 6| Step: 5
Training loss: 1.6698806285858154
Validation loss: 2.0691304091484315

Epoch: 6| Step: 6
Training loss: 2.5536489486694336
Validation loss: 2.086212920886214

Epoch: 6| Step: 7
Training loss: 1.7759629487991333
Validation loss: 2.073976109104772

Epoch: 6| Step: 8
Training loss: 1.6032718420028687
Validation loss: 2.074975934079898

Epoch: 6| Step: 9
Training loss: 2.3133931159973145
Validation loss: 2.075491871885074

Epoch: 6| Step: 10
Training loss: 2.075835704803467
Validation loss: 2.0713058594734437

Epoch: 6| Step: 11
Training loss: 2.201198101043701
Validation loss: 2.091644243527484

Epoch: 6| Step: 12
Training loss: 1.899314522743225
Validation loss: 2.0935726242680706

Epoch: 6| Step: 13
Training loss: 1.2107212543487549
Validation loss: 2.0638882908769833

Epoch: 148| Step: 0
Training loss: 1.7334775924682617
Validation loss: 2.056410451089182

Epoch: 6| Step: 1
Training loss: 2.6007261276245117
Validation loss: 2.0523083363809893

Epoch: 6| Step: 2
Training loss: 2.9271063804626465
Validation loss: 2.077754694928405

Epoch: 6| Step: 3
Training loss: 1.7102131843566895
Validation loss: 2.0746768264360327

Epoch: 6| Step: 4
Training loss: 2.3960461616516113
Validation loss: 2.0441107314120055

Epoch: 6| Step: 5
Training loss: 1.2156264781951904
Validation loss: 2.0680367215987174

Epoch: 6| Step: 6
Training loss: 1.8659956455230713
Validation loss: 2.065272195364839

Epoch: 6| Step: 7
Training loss: 1.6718580722808838
Validation loss: 2.039158544232768

Epoch: 6| Step: 8
Training loss: 2.3587265014648438
Validation loss: 2.0756191412607827

Epoch: 6| Step: 9
Training loss: 2.9784605503082275
Validation loss: 2.063703433159859

Epoch: 6| Step: 10
Training loss: 1.7328407764434814
Validation loss: 2.0588911502592024

Epoch: 6| Step: 11
Training loss: 1.951334834098816
Validation loss: 2.0569639205932617

Epoch: 6| Step: 12
Training loss: 2.0696897506713867
Validation loss: 2.077375893951744

Epoch: 6| Step: 13
Training loss: 1.82352614402771
Validation loss: 2.0493083295001777

Epoch: 149| Step: 0
Training loss: 2.5694563388824463
Validation loss: 2.048559432388634

Epoch: 6| Step: 1
Training loss: 1.59092378616333
Validation loss: 2.0876093782404417

Epoch: 6| Step: 2
Training loss: 2.045825958251953
Validation loss: 2.063709725615799

Epoch: 6| Step: 3
Training loss: 2.643251895904541
Validation loss: 2.0315821286170714

Epoch: 6| Step: 4
Training loss: 2.1426429748535156
Validation loss: 2.0535443521315053

Epoch: 6| Step: 5
Training loss: 1.2047741413116455
Validation loss: 2.081008508641233

Epoch: 6| Step: 6
Training loss: 2.282701015472412
Validation loss: 2.0758962195406676

Epoch: 6| Step: 7
Training loss: 2.136852502822876
Validation loss: 2.0808593150108092

Epoch: 6| Step: 8
Training loss: 2.1533212661743164
Validation loss: 2.067246434509113

Epoch: 6| Step: 9
Training loss: 3.1185388565063477
Validation loss: 2.049916293031426

Epoch: 6| Step: 10
Training loss: 1.8793888092041016
Validation loss: 2.081101256032144

Epoch: 6| Step: 11
Training loss: 2.310029983520508
Validation loss: 2.0737463889583463

Epoch: 6| Step: 12
Training loss: 1.45133376121521
Validation loss: 2.092108416300948

Epoch: 6| Step: 13
Training loss: 1.3650705814361572
Validation loss: 2.0627909975667156

Epoch: 150| Step: 0
Training loss: 1.8275083303451538
Validation loss: 2.0789469249786867

Epoch: 6| Step: 1
Training loss: 1.8390130996704102
Validation loss: 2.046433589791739

Epoch: 6| Step: 2
Training loss: 2.0024917125701904
Validation loss: 2.074408467097949

Epoch: 6| Step: 3
Training loss: 2.278392791748047
Validation loss: 2.0778273664494997

Epoch: 6| Step: 4
Training loss: 1.3742012977600098
Validation loss: 2.0501418946891703

Epoch: 6| Step: 5
Training loss: 2.532580852508545
Validation loss: 2.053655473134851

Epoch: 6| Step: 6
Training loss: 2.065138101577759
Validation loss: 2.066369107974473

Epoch: 6| Step: 7
Training loss: 2.674354076385498
Validation loss: 2.0755002754990772

Epoch: 6| Step: 8
Training loss: 1.852128267288208
Validation loss: 2.064716080824534

Epoch: 6| Step: 9
Training loss: 2.2986788749694824
Validation loss: 2.0680718498845256

Epoch: 6| Step: 10
Training loss: 1.9273736476898193
Validation loss: 2.0766166845957437

Epoch: 6| Step: 11
Training loss: 2.237658977508545
Validation loss: 2.0467239836210847

Epoch: 6| Step: 12
Training loss: 2.1299538612365723
Validation loss: 2.0341521616904967

Epoch: 6| Step: 13
Training loss: 1.7937278747558594
Validation loss: 2.071992140944286

Epoch: 151| Step: 0
Training loss: 2.1496284008026123
Validation loss: 2.027540112054476

Epoch: 6| Step: 1
Training loss: 1.508101224899292
Validation loss: 2.072462801010378

Epoch: 6| Step: 2
Training loss: 2.3636770248413086
Validation loss: 2.050320222813596

Epoch: 6| Step: 3
Training loss: 1.5659608840942383
Validation loss: 2.072042654919368

Epoch: 6| Step: 4
Training loss: 1.447089433670044
Validation loss: 2.0562355684977707

Epoch: 6| Step: 5
Training loss: 2.619596004486084
Validation loss: 2.054623588438957

Epoch: 6| Step: 6
Training loss: 1.9675593376159668
Validation loss: 2.047539372597971

Epoch: 6| Step: 7
Training loss: 2.5680389404296875
Validation loss: 2.04747760680414

Epoch: 6| Step: 8
Training loss: 2.1197900772094727
Validation loss: 2.057386423951836

Epoch: 6| Step: 9
Training loss: 2.573425054550171
Validation loss: 2.0565821816844325

Epoch: 6| Step: 10
Training loss: 2.0700814723968506
Validation loss: 2.066949511087069

Epoch: 6| Step: 11
Training loss: 2.5388996601104736
Validation loss: 2.0459864844558058

Epoch: 6| Step: 12
Training loss: 2.0571436882019043
Validation loss: 2.048120370475195

Epoch: 6| Step: 13
Training loss: 1.2118394374847412
Validation loss: 2.086451845784341

Epoch: 152| Step: 0
Training loss: 1.7766751050949097
Validation loss: 2.053552512199648

Epoch: 6| Step: 1
Training loss: 1.8110582828521729
Validation loss: 2.0538604618400655

Epoch: 6| Step: 2
Training loss: 2.408271551132202
Validation loss: 2.033365221433742

Epoch: 6| Step: 3
Training loss: 1.7150909900665283
Validation loss: 2.0748438194233882

Epoch: 6| Step: 4
Training loss: 2.0884857177734375
Validation loss: 2.0470098269883024

Epoch: 6| Step: 5
Training loss: 2.551241397857666
Validation loss: 2.041585091621645

Epoch: 6| Step: 6
Training loss: 2.8801655769348145
Validation loss: 2.0611100581384476

Epoch: 6| Step: 7
Training loss: 2.0538687705993652
Validation loss: 2.054424765289471

Epoch: 6| Step: 8
Training loss: 2.393558979034424
Validation loss: 2.0426380711217083

Epoch: 6| Step: 9
Training loss: 1.3427612781524658
Validation loss: 2.0748217695502826

Epoch: 6| Step: 10
Training loss: 1.5284976959228516
Validation loss: 2.040742580608655

Epoch: 6| Step: 11
Training loss: 2.3519699573516846
Validation loss: 2.0516392774479364

Epoch: 6| Step: 12
Training loss: 2.0748450756073
Validation loss: 2.0546849645594114

Epoch: 6| Step: 13
Training loss: 1.4954400062561035
Validation loss: 2.0526807590197493

Epoch: 153| Step: 0
Training loss: 2.054548501968384
Validation loss: 2.0702510059520765

Epoch: 6| Step: 1
Training loss: 2.5193166732788086
Validation loss: 2.043739377811391

Epoch: 6| Step: 2
Training loss: 2.344052791595459
Validation loss: 2.0474048109464746

Epoch: 6| Step: 3
Training loss: 1.7911959886550903
Validation loss: 2.07449205588269

Epoch: 6| Step: 4
Training loss: 2.467291831970215
Validation loss: 2.0412530834956835

Epoch: 6| Step: 5
Training loss: 2.423475742340088
Validation loss: 2.0592662852297545

Epoch: 6| Step: 6
Training loss: 2.2150323390960693
Validation loss: 2.0630899501103226

Epoch: 6| Step: 7
Training loss: 1.5881965160369873
Validation loss: 2.045414896421535

Epoch: 6| Step: 8
Training loss: 1.7110763788223267
Validation loss: 2.075606071820823

Epoch: 6| Step: 9
Training loss: 2.487917184829712
Validation loss: 2.026484679150325

Epoch: 6| Step: 10
Training loss: 1.579587697982788
Validation loss: 2.0675892701712986

Epoch: 6| Step: 11
Training loss: 2.0498428344726562
Validation loss: 2.0322407394327144

Epoch: 6| Step: 12
Training loss: 1.8102283477783203
Validation loss: 2.056587314092985

Epoch: 6| Step: 13
Training loss: 1.6188077926635742
Validation loss: 2.0532742213177424

Epoch: 154| Step: 0
Training loss: 1.754695177078247
Validation loss: 2.028570903244839

Epoch: 6| Step: 1
Training loss: 2.207166910171509
Validation loss: 2.0406674556834723

Epoch: 6| Step: 2
Training loss: 1.6748313903808594
Validation loss: 2.0625252518602597

Epoch: 6| Step: 3
Training loss: 1.78346848487854
Validation loss: 2.0626766092033795

Epoch: 6| Step: 4
Training loss: 2.2944858074188232
Validation loss: 2.057208231700364

Epoch: 6| Step: 5
Training loss: 2.6326351165771484
Validation loss: 2.037712194586313

Epoch: 6| Step: 6
Training loss: 2.474198818206787
Validation loss: 2.0365311330364597

Epoch: 6| Step: 7
Training loss: 1.5788414478302002
Validation loss: 2.059299034457053

Epoch: 6| Step: 8
Training loss: 1.8163938522338867
Validation loss: 2.0419619903769544

Epoch: 6| Step: 9
Training loss: 1.5552852153778076
Validation loss: 2.0676523421400335

Epoch: 6| Step: 10
Training loss: 2.320988416671753
Validation loss: 2.06183889860748

Epoch: 6| Step: 11
Training loss: 1.3522367477416992
Validation loss: 2.043756764422181

Epoch: 6| Step: 12
Training loss: 3.109166383743286
Validation loss: 2.0472989518155336

Epoch: 6| Step: 13
Training loss: 2.6462888717651367
Validation loss: 2.0601370155170398

Epoch: 155| Step: 0
Training loss: 2.152263641357422
Validation loss: 2.037959203925184

Epoch: 6| Step: 1
Training loss: 1.9002180099487305
Validation loss: 2.0483511570961244

Epoch: 6| Step: 2
Training loss: 1.8879568576812744
Validation loss: 2.0750221078113844

Epoch: 6| Step: 3
Training loss: 2.090409517288208
Validation loss: 2.028487226014496

Epoch: 6| Step: 4
Training loss: 2.0869505405426025
Validation loss: 2.046412229537964

Epoch: 6| Step: 5
Training loss: 2.429806709289551
Validation loss: 2.0654477932119883

Epoch: 6| Step: 6
Training loss: 1.8670542240142822
Validation loss: 2.0554354831736577

Epoch: 6| Step: 7
Training loss: 1.922830581665039
Validation loss: 2.0587464955545243

Epoch: 6| Step: 8
Training loss: 1.9216694831848145
Validation loss: 2.0698356577145156

Epoch: 6| Step: 9
Training loss: 2.4692347049713135
Validation loss: 2.0471098551186184

Epoch: 6| Step: 10
Training loss: 1.6652902364730835
Validation loss: 2.026371225234001

Epoch: 6| Step: 11
Training loss: 2.5375804901123047
Validation loss: 2.04615282499662

Epoch: 6| Step: 12
Training loss: 1.8701361417770386
Validation loss: 2.036084614774232

Epoch: 6| Step: 13
Training loss: 1.7530163526535034
Validation loss: 2.0490086975918023

Epoch: 156| Step: 0
Training loss: 2.1038870811462402
Validation loss: 2.0725041589429303

Epoch: 6| Step: 1
Training loss: 2.858729839324951
Validation loss: 2.0453718349497807

Epoch: 6| Step: 2
Training loss: 2.5129058361053467
Validation loss: 2.059459311987764

Epoch: 6| Step: 3
Training loss: 1.5685231685638428
Validation loss: 2.0284512555727394

Epoch: 6| Step: 4
Training loss: 1.8852379322052002
Validation loss: 2.0322264432907104

Epoch: 6| Step: 5
Training loss: 1.6505553722381592
Validation loss: 2.063031937486382

Epoch: 6| Step: 6
Training loss: 2.24017333984375
Validation loss: 2.0663844359818326

Epoch: 6| Step: 7
Training loss: 1.8821581602096558
Validation loss: 2.0404278334750923

Epoch: 6| Step: 8
Training loss: 2.3541083335876465
Validation loss: 2.0428398552761284

Epoch: 6| Step: 9
Training loss: 2.076449394226074
Validation loss: 2.0357021285641577

Epoch: 6| Step: 10
Training loss: 1.8368010520935059
Validation loss: 2.042605733358732

Epoch: 6| Step: 11
Training loss: 1.183286190032959
Validation loss: 2.0519558665572957

Epoch: 6| Step: 12
Training loss: 2.429281234741211
Validation loss: 2.0650249732437955

Epoch: 6| Step: 13
Training loss: 2.3992340564727783
Validation loss: 2.070045114845358

Epoch: 157| Step: 0
Training loss: 1.4666705131530762
Validation loss: 2.061670708399947

Epoch: 6| Step: 1
Training loss: 1.7496875524520874
Validation loss: 2.0398179228587816

Epoch: 6| Step: 2
Training loss: 1.9079725742340088
Validation loss: 2.0640064080556235

Epoch: 6| Step: 3
Training loss: 2.2089197635650635
Validation loss: 2.0492590319725776

Epoch: 6| Step: 4
Training loss: 2.0916996002197266
Validation loss: 2.0500819772802372

Epoch: 6| Step: 5
Training loss: 2.5635406970977783
Validation loss: 2.036693937035017

Epoch: 6| Step: 6
Training loss: 2.353630304336548
Validation loss: 2.0574320798279135

Epoch: 6| Step: 7
Training loss: 1.693496823310852
Validation loss: 2.0398663320849018

Epoch: 6| Step: 8
Training loss: 2.417649030685425
Validation loss: 2.0539358226201867

Epoch: 6| Step: 9
Training loss: 2.131155490875244
Validation loss: 2.039627908378519

Epoch: 6| Step: 10
Training loss: 1.9225972890853882
Validation loss: 2.0383810381735525

Epoch: 6| Step: 11
Training loss: 2.1656274795532227
Validation loss: 2.055768817983648

Epoch: 6| Step: 12
Training loss: 2.0316078662872314
Validation loss: 2.0507246832693777

Epoch: 6| Step: 13
Training loss: 1.811378002166748
Validation loss: 2.05248688626033

Epoch: 158| Step: 0
Training loss: 1.9270683526992798
Validation loss: 2.036766202219071

Epoch: 6| Step: 1
Training loss: 2.4369945526123047
Validation loss: 2.0537495049097205

Epoch: 6| Step: 2
Training loss: 2.8064022064208984
Validation loss: 2.067364643978816

Epoch: 6| Step: 3
Training loss: 2.0677342414855957
Validation loss: 2.044252690448556

Epoch: 6| Step: 4
Training loss: 2.209113359451294
Validation loss: 2.05219090882168

Epoch: 6| Step: 5
Training loss: 1.9847612380981445
Validation loss: 2.071997270789198

Epoch: 6| Step: 6
Training loss: 1.9023574590682983
Validation loss: 2.048121993259717

Epoch: 6| Step: 7
Training loss: 2.4856934547424316
Validation loss: 2.067576403258949

Epoch: 6| Step: 8
Training loss: 1.9713321924209595
Validation loss: 2.043733596801758

Epoch: 6| Step: 9
Training loss: 2.005542278289795
Validation loss: 2.0548141182109876

Epoch: 6| Step: 10
Training loss: 1.5457494258880615
Validation loss: 2.0482651969437957

Epoch: 6| Step: 11
Training loss: 1.7874854803085327
Validation loss: 2.056271860676427

Epoch: 6| Step: 12
Training loss: 2.1264543533325195
Validation loss: 2.040682772154449

Epoch: 6| Step: 13
Training loss: 1.5242094993591309
Validation loss: 2.056327368623467

Epoch: 159| Step: 0
Training loss: 1.766619324684143
Validation loss: 2.070762062585482

Epoch: 6| Step: 1
Training loss: 1.9604192972183228
Validation loss: 2.056866584285613

Epoch: 6| Step: 2
Training loss: 2.4609756469726562
Validation loss: 2.054913108066846

Epoch: 6| Step: 3
Training loss: 1.9236071109771729
Validation loss: 2.030928604064449

Epoch: 6| Step: 4
Training loss: 2.224701404571533
Validation loss: 2.038939655468028

Epoch: 6| Step: 5
Training loss: 2.108659267425537
Validation loss: 2.0345929361158803

Epoch: 6| Step: 6
Training loss: 2.042992353439331
Validation loss: 2.029893680285382

Epoch: 6| Step: 7
Training loss: 1.478273868560791
Validation loss: 2.0592216407099078

Epoch: 6| Step: 8
Training loss: 2.566985607147217
Validation loss: 2.034800139806604

Epoch: 6| Step: 9
Training loss: 1.7858786582946777
Validation loss: 2.0260771846258514

Epoch: 6| Step: 10
Training loss: 2.0595057010650635
Validation loss: 2.0459946765694568

Epoch: 6| Step: 11
Training loss: 2.4402670860290527
Validation loss: 2.0288374270162275

Epoch: 6| Step: 12
Training loss: 1.866202473640442
Validation loss: 2.0137344252678657

Epoch: 6| Step: 13
Training loss: 2.058034896850586
Validation loss: 2.059326021902023

Epoch: 160| Step: 0
Training loss: 1.897759199142456
Validation loss: 2.049123059036911

Epoch: 6| Step: 1
Training loss: 1.815436601638794
Validation loss: 2.04600199191801

Epoch: 6| Step: 2
Training loss: 2.1796584129333496
Validation loss: 2.0547059300125285

Epoch: 6| Step: 3
Training loss: 2.65407657623291
Validation loss: 2.05961896270834

Epoch: 6| Step: 4
Training loss: 1.8768330812454224
Validation loss: 2.0521656005613265

Epoch: 6| Step: 5
Training loss: 1.627789855003357
Validation loss: 2.0212738334491687

Epoch: 6| Step: 6
Training loss: 1.4868940114974976
Validation loss: 2.0393796454193773

Epoch: 6| Step: 7
Training loss: 2.036919593811035
Validation loss: 2.0627365496850785

Epoch: 6| Step: 8
Training loss: 2.6088109016418457
Validation loss: 2.0148812237606255

Epoch: 6| Step: 9
Training loss: 1.5825119018554688
Validation loss: 2.0517354293536116

Epoch: 6| Step: 10
Training loss: 1.6168301105499268
Validation loss: 2.040502732799899

Epoch: 6| Step: 11
Training loss: 2.536830186843872
Validation loss: 2.041440458707912

Epoch: 6| Step: 12
Training loss: 2.145057201385498
Validation loss: 2.033030802203763

Epoch: 6| Step: 13
Training loss: 2.784478187561035
Validation loss: 2.0461563769207207

Epoch: 161| Step: 0
Training loss: 2.2421464920043945
Validation loss: 2.0489012041399555

Epoch: 6| Step: 1
Training loss: 2.647923231124878
Validation loss: 2.047271451642436

Epoch: 6| Step: 2
Training loss: 2.3423728942871094
Validation loss: 2.033914848040509

Epoch: 6| Step: 3
Training loss: 1.5376464128494263
Validation loss: 2.03664408704286

Epoch: 6| Step: 4
Training loss: 2.496962308883667
Validation loss: 2.043978475755261

Epoch: 6| Step: 5
Training loss: 2.228111743927002
Validation loss: 2.0586754173360844

Epoch: 6| Step: 6
Training loss: 1.989552617073059
Validation loss: 2.0403382983258975

Epoch: 6| Step: 7
Training loss: 1.5436646938323975
Validation loss: 2.0549065425831783

Epoch: 6| Step: 8
Training loss: 2.291060209274292
Validation loss: 2.063606987717331

Epoch: 6| Step: 9
Training loss: 1.5461530685424805
Validation loss: 2.0487421340839838

Epoch: 6| Step: 10
Training loss: 1.68733549118042
Validation loss: 2.0226747066743913

Epoch: 6| Step: 11
Training loss: 2.2506680488586426
Validation loss: 2.045980718828017

Epoch: 6| Step: 12
Training loss: 1.9094760417938232
Validation loss: 2.0420128453162407

Epoch: 6| Step: 13
Training loss: 1.487241268157959
Validation loss: 2.0645156829587874

Epoch: 162| Step: 0
Training loss: 1.90578031539917
Validation loss: 2.065759402449413

Epoch: 6| Step: 1
Training loss: 2.7241010665893555
Validation loss: 2.0235602983864407

Epoch: 6| Step: 2
Training loss: 1.2942471504211426
Validation loss: 2.02707411396888

Epoch: 6| Step: 3
Training loss: 2.352936267852783
Validation loss: 2.05534920512989

Epoch: 6| Step: 4
Training loss: 2.291745662689209
Validation loss: 2.0415058494896017

Epoch: 6| Step: 5
Training loss: 2.0072999000549316
Validation loss: 2.0424092328676613

Epoch: 6| Step: 6
Training loss: 2.2797179222106934
Validation loss: 2.0457311548212522

Epoch: 6| Step: 7
Training loss: 1.2943825721740723
Validation loss: 2.0473492248083955

Epoch: 6| Step: 8
Training loss: 1.8224679231643677
Validation loss: 2.0231864119088776

Epoch: 6| Step: 9
Training loss: 2.3650963306427
Validation loss: 2.0276201732697023

Epoch: 6| Step: 10
Training loss: 1.640024185180664
Validation loss: 2.0260710908520605

Epoch: 6| Step: 11
Training loss: 1.8711475133895874
Validation loss: 2.0797801351034515

Epoch: 6| Step: 12
Training loss: 2.228853225708008
Validation loss: 2.0436382626974456

Epoch: 6| Step: 13
Training loss: 3.013836145401001
Validation loss: 2.0353632908995434

Epoch: 163| Step: 0
Training loss: 2.013315439224243
Validation loss: 2.0268523052174556

Epoch: 6| Step: 1
Training loss: 2.198636531829834
Validation loss: 2.069496359876407

Epoch: 6| Step: 2
Training loss: 2.291355609893799
Validation loss: 2.0383346619144564

Epoch: 6| Step: 3
Training loss: 2.4824090003967285
Validation loss: 2.0566589870760517

Epoch: 6| Step: 4
Training loss: 2.230167865753174
Validation loss: 2.028141511383877

Epoch: 6| Step: 5
Training loss: 2.1071977615356445
Validation loss: 2.0362728077878236

Epoch: 6| Step: 6
Training loss: 2.07669734954834
Validation loss: 2.037183270659498

Epoch: 6| Step: 7
Training loss: 2.1065893173217773
Validation loss: 2.030760484357034

Epoch: 6| Step: 8
Training loss: 1.611142873764038
Validation loss: 2.034798747749739

Epoch: 6| Step: 9
Training loss: 1.561018943786621
Validation loss: 2.020510155667541

Epoch: 6| Step: 10
Training loss: 1.5037332773208618
Validation loss: 2.0218062387999667

Epoch: 6| Step: 11
Training loss: 1.7748160362243652
Validation loss: 2.004078167741017

Epoch: 6| Step: 12
Training loss: 2.7554426193237305
Validation loss: 2.0268356312987623

Epoch: 6| Step: 13
Training loss: 1.4481449127197266
Validation loss: 2.0662827978851976

Epoch: 164| Step: 0
Training loss: 1.6956589221954346
Validation loss: 2.013442526581467

Epoch: 6| Step: 1
Training loss: 2.2612662315368652
Validation loss: 2.050870580057944

Epoch: 6| Step: 2
Training loss: 2.1020171642303467
Validation loss: 2.0356288289511077

Epoch: 6| Step: 3
Training loss: 2.0527796745300293
Validation loss: 2.004368266751689

Epoch: 6| Step: 4
Training loss: 2.041163921356201
Validation loss: 2.0320256487015755

Epoch: 6| Step: 5
Training loss: 2.447953939437866
Validation loss: 2.0282979088444866

Epoch: 6| Step: 6
Training loss: 2.330375909805298
Validation loss: 2.0174247885263092

Epoch: 6| Step: 7
Training loss: 1.5437434911727905
Validation loss: 2.028012296204926

Epoch: 6| Step: 8
Training loss: 2.4259276390075684
Validation loss: 2.0703568766194005

Epoch: 6| Step: 9
Training loss: 1.8408554792404175
Validation loss: 2.0231718273573023

Epoch: 6| Step: 10
Training loss: 2.2115321159362793
Validation loss: 2.0296986077421453

Epoch: 6| Step: 11
Training loss: 1.8845566511154175
Validation loss: 2.0623986105765066

Epoch: 6| Step: 12
Training loss: 2.0516209602355957
Validation loss: 2.038577369464341

Epoch: 6| Step: 13
Training loss: 0.797344446182251
Validation loss: 2.043094914446595

Epoch: 165| Step: 0
Training loss: 1.7748512029647827
Validation loss: 2.033206142405028

Epoch: 6| Step: 1
Training loss: 2.2377734184265137
Validation loss: 2.0192824807218326

Epoch: 6| Step: 2
Training loss: 1.3425204753875732
Validation loss: 2.029122183399816

Epoch: 6| Step: 3
Training loss: 2.4232497215270996
Validation loss: 2.0428200216703516

Epoch: 6| Step: 4
Training loss: 2.675715923309326
Validation loss: 2.0472051007773286

Epoch: 6| Step: 5
Training loss: 2.3042986392974854
Validation loss: 2.034590244293213

Epoch: 6| Step: 6
Training loss: 1.9437525272369385
Validation loss: 2.026366014634409

Epoch: 6| Step: 7
Training loss: 1.9279232025146484
Validation loss: 2.04195059755797

Epoch: 6| Step: 8
Training loss: 1.1670620441436768
Validation loss: 2.0629381723301385

Epoch: 6| Step: 9
Training loss: 2.23262882232666
Validation loss: 2.0458650306988786

Epoch: 6| Step: 10
Training loss: 1.9479514360427856
Validation loss: 2.0462938201042915

Epoch: 6| Step: 11
Training loss: 1.8908697366714478
Validation loss: 2.065808367985551

Epoch: 6| Step: 12
Training loss: 2.283445358276367
Validation loss: 2.0136429238063034

Epoch: 6| Step: 13
Training loss: 2.0914306640625
Validation loss: 2.0441768976949874

Epoch: 166| Step: 0
Training loss: 2.1912550926208496
Validation loss: 2.0085131840039323

Epoch: 6| Step: 1
Training loss: 1.8433899879455566
Validation loss: 2.0299304428920952

Epoch: 6| Step: 2
Training loss: 1.7121593952178955
Validation loss: 1.9822420715003886

Epoch: 6| Step: 3
Training loss: 1.7992491722106934
Validation loss: 2.0219726703500234

Epoch: 6| Step: 4
Training loss: 2.1933345794677734
Validation loss: 2.0093911899033414

Epoch: 6| Step: 5
Training loss: 2.0338730812072754
Validation loss: 2.0330528379768453

Epoch: 6| Step: 6
Training loss: 1.8273131847381592
Validation loss: 2.0236509923012025

Epoch: 6| Step: 7
Training loss: 1.4321224689483643
Validation loss: 2.0477777847679715

Epoch: 6| Step: 8
Training loss: 1.5475146770477295
Validation loss: 2.0679600264436457

Epoch: 6| Step: 9
Training loss: 1.7863678932189941
Validation loss: 2.061614473660787

Epoch: 6| Step: 10
Training loss: 2.4051313400268555
Validation loss: 2.0362113342490247

Epoch: 6| Step: 11
Training loss: 2.718653678894043
Validation loss: 2.0305198879652124

Epoch: 6| Step: 12
Training loss: 2.881666660308838
Validation loss: 2.0394692062049784

Epoch: 6| Step: 13
Training loss: 2.147312641143799
Validation loss: 2.039323568344116

Epoch: 167| Step: 0
Training loss: 2.006598472595215
Validation loss: 2.0101015260142665

Epoch: 6| Step: 1
Training loss: 1.8500316143035889
Validation loss: 2.0089013358598113

Epoch: 6| Step: 2
Training loss: 2.0698208808898926
Validation loss: 2.0424931844075522

Epoch: 6| Step: 3
Training loss: 2.617215633392334
Validation loss: 2.0212405907210482

Epoch: 6| Step: 4
Training loss: 1.8952889442443848
Validation loss: 2.0051138516395324

Epoch: 6| Step: 5
Training loss: 1.8444130420684814
Validation loss: 2.01390088758161

Epoch: 6| Step: 6
Training loss: 1.3967294692993164
Validation loss: 2.0228803542352494

Epoch: 6| Step: 7
Training loss: 1.9978255033493042
Validation loss: 2.029239818614016

Epoch: 6| Step: 8
Training loss: 1.565735101699829
Validation loss: 2.057957912004122

Epoch: 6| Step: 9
Training loss: 2.2308237552642822
Validation loss: 2.011105929651568

Epoch: 6| Step: 10
Training loss: 2.5473995208740234
Validation loss: 2.0642525290930145

Epoch: 6| Step: 11
Training loss: 2.3945631980895996
Validation loss: 2.0569761183954056

Epoch: 6| Step: 12
Training loss: 1.726023554801941
Validation loss: 2.036957526719698

Epoch: 6| Step: 13
Training loss: 2.102898597717285
Validation loss: 2.0437780669940415

Epoch: 168| Step: 0
Training loss: 2.42124080657959
Validation loss: 2.0465474038995723

Epoch: 6| Step: 1
Training loss: 2.2467269897460938
Validation loss: 2.036118099766393

Epoch: 6| Step: 2
Training loss: 1.5728108882904053
Validation loss: 2.0168647189294138

Epoch: 6| Step: 3
Training loss: 1.6110740900039673
Validation loss: 2.0581045676303167

Epoch: 6| Step: 4
Training loss: 2.1046431064605713
Validation loss: 2.0300910242142214

Epoch: 6| Step: 5
Training loss: 2.358055830001831
Validation loss: 2.0201249635347756

Epoch: 6| Step: 6
Training loss: 1.8135626316070557
Validation loss: 2.0627130000822005

Epoch: 6| Step: 7
Training loss: 2.134845733642578
Validation loss: 2.0026370299759733

Epoch: 6| Step: 8
Training loss: 1.7971032857894897
Validation loss: 2.0362536791832215

Epoch: 6| Step: 9
Training loss: 1.8962681293487549
Validation loss: 2.0201033161532496

Epoch: 6| Step: 10
Training loss: 2.4082345962524414
Validation loss: 2.023207110743369

Epoch: 6| Step: 11
Training loss: 2.0083861351013184
Validation loss: 2.0526794310539

Epoch: 6| Step: 12
Training loss: 1.7895249128341675
Validation loss: 2.054575325340353

Epoch: 6| Step: 13
Training loss: 1.8516976833343506
Validation loss: 2.035066702032602

Epoch: 169| Step: 0
Training loss: 2.41614031791687
Validation loss: 2.0220427410576933

Epoch: 6| Step: 1
Training loss: 2.2486300468444824
Validation loss: 2.0386834964957288

Epoch: 6| Step: 2
Training loss: 1.7682994604110718
Validation loss: 2.0218142053132415

Epoch: 6| Step: 3
Training loss: 1.5924471616744995
Validation loss: 2.0073410593053347

Epoch: 6| Step: 4
Training loss: 1.7161710262298584
Validation loss: 2.000399153719666

Epoch: 6| Step: 5
Training loss: 1.0009660720825195
Validation loss: 2.0382376358073246

Epoch: 6| Step: 6
Training loss: 2.2144722938537598
Validation loss: 2.004160811824183

Epoch: 6| Step: 7
Training loss: 1.365161418914795
Validation loss: 2.0173817244909142

Epoch: 6| Step: 8
Training loss: 2.2643513679504395
Validation loss: 2.0283566367241646

Epoch: 6| Step: 9
Training loss: 2.5031630992889404
Validation loss: 2.000364334352555

Epoch: 6| Step: 10
Training loss: 1.6047250032424927
Validation loss: 2.017861250908144

Epoch: 6| Step: 11
Training loss: 2.520939350128174
Validation loss: 2.0269191111287763

Epoch: 6| Step: 12
Training loss: 2.553560256958008
Validation loss: 2.0374633958262782

Epoch: 6| Step: 13
Training loss: 2.4470396041870117
Validation loss: 2.0030862080153597

Epoch: 170| Step: 0
Training loss: 2.109217643737793
Validation loss: 2.0411484395304034

Epoch: 6| Step: 1
Training loss: 2.432760715484619
Validation loss: 2.0312434550254577

Epoch: 6| Step: 2
Training loss: 1.4597046375274658
Validation loss: 2.035047777237431

Epoch: 6| Step: 3
Training loss: 2.092060089111328
Validation loss: 2.0205013751983643

Epoch: 6| Step: 4
Training loss: 1.5495543479919434
Validation loss: 2.0069886715181413

Epoch: 6| Step: 5
Training loss: 1.7636730670928955
Validation loss: 1.9897506416484874

Epoch: 6| Step: 6
Training loss: 1.7912055253982544
Validation loss: 2.0009599475450415

Epoch: 6| Step: 7
Training loss: 2.2863264083862305
Validation loss: 2.0068346723433463

Epoch: 6| Step: 8
Training loss: 2.2806379795074463
Validation loss: 2.016262141607141

Epoch: 6| Step: 9
Training loss: 2.30789852142334
Validation loss: 2.049585315489

Epoch: 6| Step: 10
Training loss: 1.2786630392074585
Validation loss: 2.012358465502339

Epoch: 6| Step: 11
Training loss: 2.2616679668426514
Validation loss: 2.0029022334724345

Epoch: 6| Step: 12
Training loss: 2.2899253368377686
Validation loss: 2.0316641176900556

Epoch: 6| Step: 13
Training loss: 2.2242493629455566
Validation loss: 1.9689553988877164

Epoch: 171| Step: 0
Training loss: 1.8385200500488281
Validation loss: 1.9964618016314764

Epoch: 6| Step: 1
Training loss: 1.7209649085998535
Validation loss: 2.0240440061015468

Epoch: 6| Step: 2
Training loss: 2.191756248474121
Validation loss: 2.0385673097384873

Epoch: 6| Step: 3
Training loss: 1.480363130569458
Validation loss: 2.0389762770745063

Epoch: 6| Step: 4
Training loss: 1.7729657888412476
Validation loss: 2.0171010032776864

Epoch: 6| Step: 5
Training loss: 2.109238624572754
Validation loss: 2.0397672089197303

Epoch: 6| Step: 6
Training loss: 1.912826657295227
Validation loss: 2.009641755011774

Epoch: 6| Step: 7
Training loss: 1.9535346031188965
Validation loss: 2.0311592278941983

Epoch: 6| Step: 8
Training loss: 2.3988192081451416
Validation loss: 2.0099731183821157

Epoch: 6| Step: 9
Training loss: 1.9617750644683838
Validation loss: 2.028978478523993

Epoch: 6| Step: 10
Training loss: 1.6102988719940186
Validation loss: 2.0107733767519713

Epoch: 6| Step: 11
Training loss: 2.11447811126709
Validation loss: 2.051655823184598

Epoch: 6| Step: 12
Training loss: 2.4546687602996826
Validation loss: 2.069312144351262

Epoch: 6| Step: 13
Training loss: 2.713378429412842
Validation loss: 2.0259619041155745

Epoch: 172| Step: 0
Training loss: 2.6133360862731934
Validation loss: 2.0270978609720864

Epoch: 6| Step: 1
Training loss: 2.0032758712768555
Validation loss: 2.0487019092805925

Epoch: 6| Step: 2
Training loss: 1.7445101737976074
Validation loss: 2.0196322728228826

Epoch: 6| Step: 3
Training loss: 1.8725073337554932
Validation loss: 2.0166187453013595

Epoch: 6| Step: 4
Training loss: 1.7352516651153564
Validation loss: 2.0131634948074177

Epoch: 6| Step: 5
Training loss: 2.170469284057617
Validation loss: 2.01416435292972

Epoch: 6| Step: 6
Training loss: 2.5647759437561035
Validation loss: 1.9920411315015567

Epoch: 6| Step: 7
Training loss: 2.0459299087524414
Validation loss: 2.0052199607254355

Epoch: 6| Step: 8
Training loss: 2.0546092987060547
Validation loss: 2.031706892034059

Epoch: 6| Step: 9
Training loss: 1.790590763092041
Validation loss: 2.0041454427985737

Epoch: 6| Step: 10
Training loss: 2.304457664489746
Validation loss: 2.0278003664426905

Epoch: 6| Step: 11
Training loss: 2.218571186065674
Validation loss: 2.057679982595546

Epoch: 6| Step: 12
Training loss: 1.424910545349121
Validation loss: 1.9994197122512325

Epoch: 6| Step: 13
Training loss: 1.3562650680541992
Validation loss: 2.030515120875451

Epoch: 173| Step: 0
Training loss: 1.5844557285308838
Validation loss: 1.9878706342430525

Epoch: 6| Step: 1
Training loss: 1.7071285247802734
Validation loss: 2.024166432760095

Epoch: 6| Step: 2
Training loss: 1.6472121477127075
Validation loss: 2.0236169676626883

Epoch: 6| Step: 3
Training loss: 2.1314778327941895
Validation loss: 2.02605833930354

Epoch: 6| Step: 4
Training loss: 2.2914905548095703
Validation loss: 2.0311755698214293

Epoch: 6| Step: 5
Training loss: 1.6111013889312744
Validation loss: 2.0358040935249737

Epoch: 6| Step: 6
Training loss: 2.525174140930176
Validation loss: 2.0312279680723786

Epoch: 6| Step: 7
Training loss: 1.852402925491333
Validation loss: 2.029643504850326

Epoch: 6| Step: 8
Training loss: 2.1481924057006836
Validation loss: 2.0439829134172007

Epoch: 6| Step: 9
Training loss: 1.6402089595794678
Validation loss: 1.9884721425271803

Epoch: 6| Step: 10
Training loss: 2.516092300415039
Validation loss: 2.002480600469856

Epoch: 6| Step: 11
Training loss: 1.6749718189239502
Validation loss: 1.9977948409254833

Epoch: 6| Step: 12
Training loss: 2.838522434234619
Validation loss: 2.0278664840165006

Epoch: 6| Step: 13
Training loss: 1.5982826948165894
Validation loss: 2.031204717133635

Epoch: 174| Step: 0
Training loss: 2.093397378921509
Validation loss: 2.0183594239655362

Epoch: 6| Step: 1
Training loss: 1.2479053735733032
Validation loss: 1.9862092964110836

Epoch: 6| Step: 2
Training loss: 1.7907166481018066
Validation loss: 1.9996291847639187

Epoch: 6| Step: 3
Training loss: 2.6486780643463135
Validation loss: 2.001241494250554

Epoch: 6| Step: 4
Training loss: 2.700380802154541
Validation loss: 1.9901698186833372

Epoch: 6| Step: 5
Training loss: 2.8233602046966553
Validation loss: 2.0125179265135076

Epoch: 6| Step: 6
Training loss: 2.081541061401367
Validation loss: 2.0192610589406823

Epoch: 6| Step: 7
Training loss: 1.6759084463119507
Validation loss: 2.0275352360099874

Epoch: 6| Step: 8
Training loss: 2.793295383453369
Validation loss: 2.006630861631004

Epoch: 6| Step: 9
Training loss: 1.5662469863891602
Validation loss: 2.0243745721796507

Epoch: 6| Step: 10
Training loss: 1.5335867404937744
Validation loss: 2.0042734799846524

Epoch: 6| Step: 11
Training loss: 1.483985424041748
Validation loss: 2.0071049736392115

Epoch: 6| Step: 12
Training loss: 2.033289909362793
Validation loss: 2.0372318144767516

Epoch: 6| Step: 13
Training loss: 1.1904093027114868
Validation loss: 2.015648723930441

Epoch: 175| Step: 0
Training loss: 2.0314717292785645
Validation loss: 2.0301509211140294

Epoch: 6| Step: 1
Training loss: 1.8113902807235718
Validation loss: 2.002529457051267

Epoch: 6| Step: 2
Training loss: 2.438199281692505
Validation loss: 2.013149533220517

Epoch: 6| Step: 3
Training loss: 1.7922263145446777
Validation loss: 2.027901895584599

Epoch: 6| Step: 4
Training loss: 1.7304589748382568
Validation loss: 2.0493420682927614

Epoch: 6| Step: 5
Training loss: 2.435582399368286
Validation loss: 2.0568947484416347

Epoch: 6| Step: 6
Training loss: 1.935737133026123
Validation loss: 2.049982581087338

Epoch: 6| Step: 7
Training loss: 2.4104926586151123
Validation loss: 2.016452662406429

Epoch: 6| Step: 8
Training loss: 1.140028715133667
Validation loss: 2.051928222820323

Epoch: 6| Step: 9
Training loss: 2.277437448501587
Validation loss: 2.0287461127004316

Epoch: 6| Step: 10
Training loss: 1.832005500793457
Validation loss: 2.0530118711533083

Epoch: 6| Step: 11
Training loss: 2.3323330879211426
Validation loss: 2.0703844408835135

Epoch: 6| Step: 12
Training loss: 2.1234984397888184
Validation loss: 2.0414322422396753

Epoch: 6| Step: 13
Training loss: 1.3512077331542969
Validation loss: 2.0246066867664294

Epoch: 176| Step: 0
Training loss: 1.9111542701721191
Validation loss: 2.043104182007492

Epoch: 6| Step: 1
Training loss: 1.7915470600128174
Validation loss: 2.0596720762150262

Epoch: 6| Step: 2
Training loss: 2.248232364654541
Validation loss: 2.0433937554718344

Epoch: 6| Step: 3
Training loss: 1.585541844367981
Validation loss: 2.0416705916004796

Epoch: 6| Step: 4
Training loss: 1.612595796585083
Validation loss: 2.0353073304699314

Epoch: 6| Step: 5
Training loss: 2.195582628250122
Validation loss: 2.0100659580640894

Epoch: 6| Step: 6
Training loss: 1.9616289138793945
Validation loss: 2.023887775277579

Epoch: 6| Step: 7
Training loss: 2.799875020980835
Validation loss: 1.978799012399489

Epoch: 6| Step: 8
Training loss: 1.4630820751190186
Validation loss: 2.0136936967090895

Epoch: 6| Step: 9
Training loss: 2.0546770095825195
Validation loss: 1.9897780213304745

Epoch: 6| Step: 10
Training loss: 2.2491822242736816
Validation loss: 2.0106331981638426

Epoch: 6| Step: 11
Training loss: 1.4617507457733154
Validation loss: 2.019173126066885

Epoch: 6| Step: 12
Training loss: 2.236320972442627
Validation loss: 2.0075834887002104

Epoch: 6| Step: 13
Training loss: 2.2752230167388916
Validation loss: 2.0290000733508857

Epoch: 177| Step: 0
Training loss: 1.6989099979400635
Validation loss: 2.0014841761640323

Epoch: 6| Step: 1
Training loss: 2.0703179836273193
Validation loss: 2.0555950749304985

Epoch: 6| Step: 2
Training loss: 2.0132927894592285
Validation loss: 2.0039745633320143

Epoch: 6| Step: 3
Training loss: 1.8909465074539185
Validation loss: 2.025121819588446

Epoch: 6| Step: 4
Training loss: 2.648886203765869
Validation loss: 2.0565906096530218

Epoch: 6| Step: 5
Training loss: 1.5325431823730469
Validation loss: 2.0019303547438754

Epoch: 6| Step: 6
Training loss: 1.6973917484283447
Validation loss: 2.0102700905133317

Epoch: 6| Step: 7
Training loss: 2.2498884201049805
Validation loss: 2.0483835871501634

Epoch: 6| Step: 8
Training loss: 1.600780725479126
Validation loss: 1.9958916940996725

Epoch: 6| Step: 9
Training loss: 2.3848304748535156
Validation loss: 1.9924638155967958

Epoch: 6| Step: 10
Training loss: 2.2038931846618652
Validation loss: 2.02626706195134

Epoch: 6| Step: 11
Training loss: 1.8204375505447388
Validation loss: 1.9823529066578034

Epoch: 6| Step: 12
Training loss: 1.3947633504867554
Validation loss: 1.9887094292589413

Epoch: 6| Step: 13
Training loss: 2.9222652912139893
Validation loss: 1.996670348669893

Epoch: 178| Step: 0
Training loss: 1.9961128234863281
Validation loss: 2.009090610729751

Epoch: 6| Step: 1
Training loss: 1.8167681694030762
Validation loss: 2.012995037981259

Epoch: 6| Step: 2
Training loss: 1.779351830482483
Validation loss: 2.008594851340017

Epoch: 6| Step: 3
Training loss: 2.4787397384643555
Validation loss: 2.001154763724214

Epoch: 6| Step: 4
Training loss: 1.5682458877563477
Validation loss: 2.013817915352442

Epoch: 6| Step: 5
Training loss: 2.987983465194702
Validation loss: 2.05040273486927

Epoch: 6| Step: 6
Training loss: 1.745391845703125
Validation loss: 1.9991149774161718

Epoch: 6| Step: 7
Training loss: 1.3429933786392212
Validation loss: 2.0211628637006207

Epoch: 6| Step: 8
Training loss: 2.6182384490966797
Validation loss: 2.037440989607124

Epoch: 6| Step: 9
Training loss: 1.6534852981567383
Validation loss: 2.035525006632651

Epoch: 6| Step: 10
Training loss: 1.794189214706421
Validation loss: 1.9925712436758063

Epoch: 6| Step: 11
Training loss: 1.5399260520935059
Validation loss: 2.039760048671435

Epoch: 6| Step: 12
Training loss: 2.072114944458008
Validation loss: 2.0246867505452966

Epoch: 6| Step: 13
Training loss: 1.9709802865982056
Validation loss: 2.01421643200741

Epoch: 179| Step: 0
Training loss: 1.3783185482025146
Validation loss: 2.0213560532498103

Epoch: 6| Step: 1
Training loss: 2.632910966873169
Validation loss: 2.0255558618935208

Epoch: 6| Step: 2
Training loss: 1.8873276710510254
Validation loss: 2.0361467356322915

Epoch: 6| Step: 3
Training loss: 1.957311987876892
Validation loss: 2.0157789389292398

Epoch: 6| Step: 4
Training loss: 1.6523187160491943
Validation loss: 2.023114488970849

Epoch: 6| Step: 5
Training loss: 1.8340469598770142
Validation loss: 2.029805311592676

Epoch: 6| Step: 6
Training loss: 1.8518534898757935
Validation loss: 1.9901279877590876

Epoch: 6| Step: 7
Training loss: 2.3369874954223633
Validation loss: 2.052961908360963

Epoch: 6| Step: 8
Training loss: 2.3010611534118652
Validation loss: 2.0181941216991794

Epoch: 6| Step: 9
Training loss: 1.6975573301315308
Validation loss: 2.041049531711045

Epoch: 6| Step: 10
Training loss: 2.2067039012908936
Validation loss: 2.0188441097095446

Epoch: 6| Step: 11
Training loss: 2.0915110111236572
Validation loss: 2.0008298658555552

Epoch: 6| Step: 12
Training loss: 2.091212749481201
Validation loss: 1.9837969298003821

Epoch: 6| Step: 13
Training loss: 1.3042912483215332
Validation loss: 2.035925849791496

Epoch: 180| Step: 0
Training loss: 1.9417972564697266
Validation loss: 2.005573462414485

Epoch: 6| Step: 1
Training loss: 1.5413819551467896
Validation loss: 2.015412417791223

Epoch: 6| Step: 2
Training loss: 2.4126524925231934
Validation loss: 2.0385356590312016

Epoch: 6| Step: 3
Training loss: 2.266862154006958
Validation loss: 2.026797415107809

Epoch: 6| Step: 4
Training loss: 2.251263380050659
Validation loss: 2.0220465711368028

Epoch: 6| Step: 5
Training loss: 2.8298087120056152
Validation loss: 2.0250221734405844

Epoch: 6| Step: 6
Training loss: 2.2240476608276367
Validation loss: 2.0007336947225753

Epoch: 6| Step: 7
Training loss: 1.8697237968444824
Validation loss: 2.0357393615989277

Epoch: 6| Step: 8
Training loss: 1.667477011680603
Validation loss: 2.0053002283137333

Epoch: 6| Step: 9
Training loss: 2.024559497833252
Validation loss: 1.9880337907421974

Epoch: 6| Step: 10
Training loss: 1.3491547107696533
Validation loss: 1.9818276743735037

Epoch: 6| Step: 11
Training loss: 1.187164068222046
Validation loss: 2.013049602508545

Epoch: 6| Step: 12
Training loss: 2.0856709480285645
Validation loss: 1.9540527815459876

Epoch: 6| Step: 13
Training loss: 1.7468713521957397
Validation loss: 1.988548965864284

Epoch: 181| Step: 0
Training loss: 1.6195762157440186
Validation loss: 1.9770277443752493

Epoch: 6| Step: 1
Training loss: 1.4801164865493774
Validation loss: 2.0156881142688055

Epoch: 6| Step: 2
Training loss: 1.7286864519119263
Validation loss: 2.0127180712197417

Epoch: 6| Step: 3
Training loss: 1.3422868251800537
Validation loss: 1.991883547075333

Epoch: 6| Step: 4
Training loss: 2.355034828186035
Validation loss: 2.004556971211587

Epoch: 6| Step: 5
Training loss: 1.6843702793121338
Validation loss: 2.000160204466953

Epoch: 6| Step: 6
Training loss: 1.6326730251312256
Validation loss: 2.010814215547295

Epoch: 6| Step: 7
Training loss: 1.684208631515503
Validation loss: 2.005479816467531

Epoch: 6| Step: 8
Training loss: 2.7755863666534424
Validation loss: 1.992181647208429

Epoch: 6| Step: 9
Training loss: 2.1706159114837646
Validation loss: 2.019875608464723

Epoch: 6| Step: 10
Training loss: 1.474250316619873
Validation loss: 2.0260405258465837

Epoch: 6| Step: 11
Training loss: 2.5009703636169434
Validation loss: 2.014482763505751

Epoch: 6| Step: 12
Training loss: 2.4270811080932617
Validation loss: 1.9972250615396807

Epoch: 6| Step: 13
Training loss: 2.6418230533599854
Validation loss: 1.9972966101861769

Epoch: 182| Step: 0
Training loss: 2.029437780380249
Validation loss: 2.0424837066281225

Epoch: 6| Step: 1
Training loss: 1.7906478643417358
Validation loss: 2.0063373042691137

Epoch: 6| Step: 2
Training loss: 1.7779220342636108
Validation loss: 1.9875111041530487

Epoch: 6| Step: 3
Training loss: 2.0276622772216797
Validation loss: 1.9962931461231683

Epoch: 6| Step: 4
Training loss: 1.7550321817398071
Validation loss: 2.0212308283775084

Epoch: 6| Step: 5
Training loss: 1.2157522439956665
Validation loss: 1.9626994414996075

Epoch: 6| Step: 6
Training loss: 2.132826805114746
Validation loss: 2.0032577783830705

Epoch: 6| Step: 7
Training loss: 1.46010160446167
Validation loss: 1.9782402861502864

Epoch: 6| Step: 8
Training loss: 2.17989182472229
Validation loss: 2.009264415310275

Epoch: 6| Step: 9
Training loss: 2.365648031234741
Validation loss: 1.9956087732827792

Epoch: 6| Step: 10
Training loss: 2.011305332183838
Validation loss: 1.9931361970081125

Epoch: 6| Step: 11
Training loss: 2.617623805999756
Validation loss: 1.9994184176127117

Epoch: 6| Step: 12
Training loss: 2.2279579639434814
Validation loss: 1.9797624977686072

Epoch: 6| Step: 13
Training loss: 1.9139344692230225
Validation loss: 1.9647903083473124

Epoch: 183| Step: 0
Training loss: 1.9116159677505493
Validation loss: 2.02547941412977

Epoch: 6| Step: 1
Training loss: 2.158806800842285
Validation loss: 1.9907789537983556

Epoch: 6| Step: 2
Training loss: 2.2142934799194336
Validation loss: 1.974565891809361

Epoch: 6| Step: 3
Training loss: 2.182194232940674
Validation loss: 2.0045434428799536

Epoch: 6| Step: 4
Training loss: 1.4394477605819702
Validation loss: 1.9597918679637294

Epoch: 6| Step: 5
Training loss: 2.1542396545410156
Validation loss: 2.0081328576610935

Epoch: 6| Step: 6
Training loss: 1.7015087604522705
Validation loss: 2.011273535349036

Epoch: 6| Step: 7
Training loss: 1.9070124626159668
Validation loss: 1.9977458087346887

Epoch: 6| Step: 8
Training loss: 1.9114458560943604
Validation loss: 1.9958923170643468

Epoch: 6| Step: 9
Training loss: 1.7540431022644043
Validation loss: 2.0370482706254527

Epoch: 6| Step: 10
Training loss: 2.0639700889587402
Validation loss: 1.9854479476969729

Epoch: 6| Step: 11
Training loss: 1.9251940250396729
Validation loss: 1.9972575197937668

Epoch: 6| Step: 12
Training loss: 2.059135675430298
Validation loss: 1.971593831175117

Epoch: 6| Step: 13
Training loss: 2.2318239212036133
Validation loss: 2.0247923225484867

Epoch: 184| Step: 0
Training loss: 1.627929449081421
Validation loss: 2.0013944205417427

Epoch: 6| Step: 1
Training loss: 2.330986976623535
Validation loss: 1.9695020362895022

Epoch: 6| Step: 2
Training loss: 2.26190447807312
Validation loss: 1.9864782030864427

Epoch: 6| Step: 3
Training loss: 2.064387083053589
Validation loss: 2.0078613463268487

Epoch: 6| Step: 4
Training loss: 2.302013397216797
Validation loss: 1.9983782024793728

Epoch: 6| Step: 5
Training loss: 1.8614847660064697
Validation loss: 2.014867749265445

Epoch: 6| Step: 6
Training loss: 1.568375825881958
Validation loss: 1.983629326666555

Epoch: 6| Step: 7
Training loss: 1.6717454195022583
Validation loss: 2.008758447503531

Epoch: 6| Step: 8
Training loss: 1.8212742805480957
Validation loss: 2.0086265558837564

Epoch: 6| Step: 9
Training loss: 1.788325309753418
Validation loss: 1.9952317207090315

Epoch: 6| Step: 10
Training loss: 1.6045374870300293
Validation loss: 1.9874708485859696

Epoch: 6| Step: 11
Training loss: 2.1977057456970215
Validation loss: 1.9747857380938787

Epoch: 6| Step: 12
Training loss: 1.9739580154418945
Validation loss: 2.009102003548735

Epoch: 6| Step: 13
Training loss: 2.186319589614868
Validation loss: 1.9767604771480765

Epoch: 185| Step: 0
Training loss: 2.118854522705078
Validation loss: 1.974062140269946

Epoch: 6| Step: 1
Training loss: 2.8427062034606934
Validation loss: 2.0199141399834746

Epoch: 6| Step: 2
Training loss: 1.590611219406128
Validation loss: 1.9904077001797256

Epoch: 6| Step: 3
Training loss: 1.9650113582611084
Validation loss: 2.011743544250406

Epoch: 6| Step: 4
Training loss: 1.6462055444717407
Validation loss: 1.9918330074638448

Epoch: 6| Step: 5
Training loss: 2.0540311336517334
Validation loss: 2.0304163284199213

Epoch: 6| Step: 6
Training loss: 1.784139633178711
Validation loss: 2.0018718063190417

Epoch: 6| Step: 7
Training loss: 1.00323486328125
Validation loss: 1.989462394868174

Epoch: 6| Step: 8
Training loss: 2.7273173332214355
Validation loss: 1.9804885361784248

Epoch: 6| Step: 9
Training loss: 1.6345304250717163
Validation loss: 1.988557033641364

Epoch: 6| Step: 10
Training loss: 2.212495803833008
Validation loss: 1.9964499140298495

Epoch: 6| Step: 11
Training loss: 1.7392284870147705
Validation loss: 1.9882390909297492

Epoch: 6| Step: 12
Training loss: 2.077810049057007
Validation loss: 2.0219792217336674

Epoch: 6| Step: 13
Training loss: 1.9896024465560913
Validation loss: 1.9907349335250033

Epoch: 186| Step: 0
Training loss: 1.8929860591888428
Validation loss: 1.9901699930109003

Epoch: 6| Step: 1
Training loss: 2.0777297019958496
Validation loss: 2.0102592770771315

Epoch: 6| Step: 2
Training loss: 2.502995252609253
Validation loss: 2.0161677906590123

Epoch: 6| Step: 3
Training loss: 1.224745750427246
Validation loss: 2.0133034054951002

Epoch: 6| Step: 4
Training loss: 1.5265483856201172
Validation loss: 2.000670685563036

Epoch: 6| Step: 5
Training loss: 2.11468505859375
Validation loss: 1.9972909753040602

Epoch: 6| Step: 6
Training loss: 2.054354190826416
Validation loss: 1.9964699104268064

Epoch: 6| Step: 7
Training loss: 2.0386576652526855
Validation loss: 1.9561759015565277

Epoch: 6| Step: 8
Training loss: 2.1667706966400146
Validation loss: 2.0264152275618685

Epoch: 6| Step: 9
Training loss: 2.3011324405670166
Validation loss: 1.9791877436381515

Epoch: 6| Step: 10
Training loss: 1.7931835651397705
Validation loss: 1.9949758129735147

Epoch: 6| Step: 11
Training loss: 1.997801661491394
Validation loss: 1.9887071232641897

Epoch: 6| Step: 12
Training loss: 1.5738778114318848
Validation loss: 1.9704220487225441

Epoch: 6| Step: 13
Training loss: 1.5479456186294556
Validation loss: 1.9723403146190028

Epoch: 187| Step: 0
Training loss: 2.135946750640869
Validation loss: 1.9661099987645303

Epoch: 6| Step: 1
Training loss: 2.1398091316223145
Validation loss: 1.964108923430084

Epoch: 6| Step: 2
Training loss: 1.9513130187988281
Validation loss: 1.99490535900157

Epoch: 6| Step: 3
Training loss: 1.6150596141815186
Validation loss: 2.001057299234534

Epoch: 6| Step: 4
Training loss: 1.173270583152771
Validation loss: 1.9872543440070203

Epoch: 6| Step: 5
Training loss: 2.0993399620056152
Validation loss: 1.9691949736687444

Epoch: 6| Step: 6
Training loss: 2.1735877990722656
Validation loss: 1.9806071109669183

Epoch: 6| Step: 7
Training loss: 1.3175299167633057
Validation loss: 1.965776192244663

Epoch: 6| Step: 8
Training loss: 3.4583683013916016
Validation loss: 1.968492514343672

Epoch: 6| Step: 9
Training loss: 1.4856014251708984
Validation loss: 1.9950232146888651

Epoch: 6| Step: 10
Training loss: 1.974417805671692
Validation loss: 2.031475051756828

Epoch: 6| Step: 11
Training loss: 1.764379858970642
Validation loss: 1.9838594954500917

Epoch: 6| Step: 12
Training loss: 1.9774943590164185
Validation loss: 2.000897599804786

Epoch: 6| Step: 13
Training loss: 2.36714243888855
Validation loss: 2.0092908631088915

Epoch: 188| Step: 0
Training loss: 1.9872586727142334
Validation loss: 1.9613129015891784

Epoch: 6| Step: 1
Training loss: 1.3647063970565796
Validation loss: 1.9719661820319392

Epoch: 6| Step: 2
Training loss: 2.197624444961548
Validation loss: 2.0236164728800454

Epoch: 6| Step: 3
Training loss: 1.2928359508514404
Validation loss: 1.9575759454440045

Epoch: 6| Step: 4
Training loss: 1.365574598312378
Validation loss: 1.9701299974995274

Epoch: 6| Step: 5
Training loss: 3.008770227432251
Validation loss: 1.9965373957028953

Epoch: 6| Step: 6
Training loss: 2.4749181270599365
Validation loss: 2.0064945297856487

Epoch: 6| Step: 7
Training loss: 2.0338852405548096
Validation loss: 1.999855363240806

Epoch: 6| Step: 8
Training loss: 2.6193432807922363
Validation loss: 1.987523901847101

Epoch: 6| Step: 9
Training loss: 1.792881727218628
Validation loss: 1.963318629931378

Epoch: 6| Step: 10
Training loss: 1.4840104579925537
Validation loss: 1.9821171452922206

Epoch: 6| Step: 11
Training loss: 2.19766902923584
Validation loss: 1.9759082435279764

Epoch: 6| Step: 12
Training loss: 1.259913444519043
Validation loss: 1.999605340342368

Epoch: 6| Step: 13
Training loss: 2.095871925354004
Validation loss: 1.9885749880985548

Epoch: 189| Step: 0
Training loss: 1.6876249313354492
Validation loss: 1.9779746788804249

Epoch: 6| Step: 1
Training loss: 1.6372654438018799
Validation loss: 2.0094767488459104

Epoch: 6| Step: 2
Training loss: 2.0395450592041016
Validation loss: 1.9900420429886028

Epoch: 6| Step: 3
Training loss: 2.169233798980713
Validation loss: 2.025771088497613

Epoch: 6| Step: 4
Training loss: 1.3179290294647217
Validation loss: 1.9820385568885392

Epoch: 6| Step: 5
Training loss: 1.9723122119903564
Validation loss: 1.9872623002657326

Epoch: 6| Step: 6
Training loss: 2.1439013481140137
Validation loss: 1.9969528426406205

Epoch: 6| Step: 7
Training loss: 1.9345908164978027
Validation loss: 2.0136564905925463

Epoch: 6| Step: 8
Training loss: 1.3257118463516235
Validation loss: 2.007156722007259

Epoch: 6| Step: 9
Training loss: 1.9379196166992188
Validation loss: 2.0047607767966484

Epoch: 6| Step: 10
Training loss: 1.878854513168335
Validation loss: 1.9746303327621952

Epoch: 6| Step: 11
Training loss: 2.8767447471618652
Validation loss: 1.9531830895331599

Epoch: 6| Step: 12
Training loss: 1.743708848953247
Validation loss: 1.9856528261656403

Epoch: 6| Step: 13
Training loss: 1.7511411905288696
Validation loss: 1.9694497431478193

Epoch: 190| Step: 0
Training loss: 2.8636844158172607
Validation loss: 1.9787549382896834

Epoch: 6| Step: 1
Training loss: 1.9868390560150146
Validation loss: 1.9929155431767946

Epoch: 6| Step: 2
Training loss: 1.912332534790039
Validation loss: 1.9793619417375135

Epoch: 6| Step: 3
Training loss: 2.7051520347595215
Validation loss: 2.0061013954941944

Epoch: 6| Step: 4
Training loss: 1.7896816730499268
Validation loss: 1.977888140627133

Epoch: 6| Step: 5
Training loss: 2.0868277549743652
Validation loss: 2.0047227233968754

Epoch: 6| Step: 6
Training loss: 1.5425994396209717
Validation loss: 1.9865835789711244

Epoch: 6| Step: 7
Training loss: 1.7277677059173584
Validation loss: 1.9870561194676224

Epoch: 6| Step: 8
Training loss: 1.4653602838516235
Validation loss: 1.9841378401684504

Epoch: 6| Step: 9
Training loss: 1.7632471323013306
Validation loss: 1.9871040210928967

Epoch: 6| Step: 10
Training loss: 1.7494395971298218
Validation loss: 1.9932456965087562

Epoch: 6| Step: 11
Training loss: 1.8045529127120972
Validation loss: 2.002347056583692

Epoch: 6| Step: 12
Training loss: 1.7649575471878052
Validation loss: 1.9527023633321126

Epoch: 6| Step: 13
Training loss: 1.1904950141906738
Validation loss: 2.0042629421398206

Epoch: 191| Step: 0
Training loss: 2.3413782119750977
Validation loss: 2.0028442003393687

Epoch: 6| Step: 1
Training loss: 1.8093359470367432
Validation loss: 2.013599926425565

Epoch: 6| Step: 2
Training loss: 1.5618681907653809
Validation loss: 1.9568988097611295

Epoch: 6| Step: 3
Training loss: 1.7415823936462402
Validation loss: 1.9592334314059185

Epoch: 6| Step: 4
Training loss: 2.8031482696533203
Validation loss: 1.973521117241152

Epoch: 6| Step: 5
Training loss: 1.1951813697814941
Validation loss: 2.0073955469234015

Epoch: 6| Step: 6
Training loss: 2.2558369636535645
Validation loss: 1.9830117789647912

Epoch: 6| Step: 7
Training loss: 1.5904619693756104
Validation loss: 1.958893883612848

Epoch: 6| Step: 8
Training loss: 1.6612046957015991
Validation loss: 1.9961884303759503

Epoch: 6| Step: 9
Training loss: 2.2115237712860107
Validation loss: 1.9730999521029893

Epoch: 6| Step: 10
Training loss: 2.1776933670043945
Validation loss: 1.9715634930518366

Epoch: 6| Step: 11
Training loss: 1.7396552562713623
Validation loss: 1.9860999648289015

Epoch: 6| Step: 12
Training loss: 2.1294631958007812
Validation loss: 1.9798957583724812

Epoch: 6| Step: 13
Training loss: 1.4614429473876953
Validation loss: 1.9953642096570743

Epoch: 192| Step: 0
Training loss: 1.5256941318511963
Validation loss: 1.9585379964561873

Epoch: 6| Step: 1
Training loss: 2.149784564971924
Validation loss: 1.9741738662924817

Epoch: 6| Step: 2
Training loss: 1.4561175107955933
Validation loss: 2.0005479064039005

Epoch: 6| Step: 3
Training loss: 1.9289071559906006
Validation loss: 2.0196238217815274

Epoch: 6| Step: 4
Training loss: 2.1075479984283447
Validation loss: 1.9799251992215392

Epoch: 6| Step: 5
Training loss: 2.425344944000244
Validation loss: 1.9581066203373734

Epoch: 6| Step: 6
Training loss: 1.6086249351501465
Validation loss: 2.0147018355707966

Epoch: 6| Step: 7
Training loss: 1.6532647609710693
Validation loss: 1.9955100885001562

Epoch: 6| Step: 8
Training loss: 2.0672447681427
Validation loss: 1.989116563591906

Epoch: 6| Step: 9
Training loss: 1.888692855834961
Validation loss: 2.0008751525673816

Epoch: 6| Step: 10
Training loss: 2.224168062210083
Validation loss: 2.0101228106406426

Epoch: 6| Step: 11
Training loss: 2.2828376293182373
Validation loss: 2.0285950194122973

Epoch: 6| Step: 12
Training loss: 1.3740761280059814
Validation loss: 1.97293379229884

Epoch: 6| Step: 13
Training loss: 2.3883230686187744
Validation loss: 1.9553174793079335

Epoch: 193| Step: 0
Training loss: 2.1806936264038086
Validation loss: 1.9976797539700744

Epoch: 6| Step: 1
Training loss: 1.5847930908203125
Validation loss: 1.9702859668321506

Epoch: 6| Step: 2
Training loss: 1.4603008031845093
Validation loss: 1.9748756603528095

Epoch: 6| Step: 3
Training loss: 2.324112892150879
Validation loss: 2.0118870094258297

Epoch: 6| Step: 4
Training loss: 2.427236318588257
Validation loss: 2.0108612583529566

Epoch: 6| Step: 5
Training loss: 2.2286782264709473
Validation loss: 1.9699740089395994

Epoch: 6| Step: 6
Training loss: 1.585863471031189
Validation loss: 1.964478967010334

Epoch: 6| Step: 7
Training loss: 1.974035382270813
Validation loss: 1.9695177424338557

Epoch: 6| Step: 8
Training loss: 1.9980661869049072
Validation loss: 1.959041291667569

Epoch: 6| Step: 9
Training loss: 1.452282190322876
Validation loss: 1.9726935509712464

Epoch: 6| Step: 10
Training loss: 1.9320104122161865
Validation loss: 1.9720275581523936

Epoch: 6| Step: 11
Training loss: 2.2035183906555176
Validation loss: 1.967841955923265

Epoch: 6| Step: 12
Training loss: 1.7116754055023193
Validation loss: 1.9842868889531782

Epoch: 6| Step: 13
Training loss: 1.714475393295288
Validation loss: 1.9809553315562587

Epoch: 194| Step: 0
Training loss: 2.345188617706299
Validation loss: 1.9657588722885295

Epoch: 6| Step: 1
Training loss: 1.8147449493408203
Validation loss: 1.9816226805410078

Epoch: 6| Step: 2
Training loss: 1.667016625404358
Validation loss: 1.983963397241408

Epoch: 6| Step: 3
Training loss: 1.9124929904937744
Validation loss: 1.9845971881702382

Epoch: 6| Step: 4
Training loss: 1.481137752532959
Validation loss: 1.9748392540921447

Epoch: 6| Step: 5
Training loss: 2.0886878967285156
Validation loss: 1.9896830743358982

Epoch: 6| Step: 6
Training loss: 2.4449567794799805
Validation loss: 1.9936841892939743

Epoch: 6| Step: 7
Training loss: 1.6261979341506958
Validation loss: 1.9946828760126585

Epoch: 6| Step: 8
Training loss: 2.0896520614624023
Validation loss: 1.971750259399414

Epoch: 6| Step: 9
Training loss: 2.021573305130005
Validation loss: 1.9307461502731487

Epoch: 6| Step: 10
Training loss: 1.2786576747894287
Validation loss: 1.970619793861143

Epoch: 6| Step: 11
Training loss: 2.347353458404541
Validation loss: 1.9689115247418802

Epoch: 6| Step: 12
Training loss: 1.6444408893585205
Validation loss: 1.9548751846436532

Epoch: 6| Step: 13
Training loss: 1.9929313659667969
Validation loss: 1.9680608446880052

Epoch: 195| Step: 0
Training loss: 1.8127398490905762
Validation loss: 1.9457067622933337

Epoch: 6| Step: 1
Training loss: 2.1781580448150635
Validation loss: 1.9878261807144328

Epoch: 6| Step: 2
Training loss: 1.6291877031326294
Validation loss: 2.023565633322603

Epoch: 6| Step: 3
Training loss: 1.80274498462677
Validation loss: 1.9721144040425618

Epoch: 6| Step: 4
Training loss: 1.8495335578918457
Validation loss: 2.003979736758817

Epoch: 6| Step: 5
Training loss: 2.227407455444336
Validation loss: 1.9543217407759799

Epoch: 6| Step: 6
Training loss: 1.9901095628738403
Validation loss: 1.9871429269031813

Epoch: 6| Step: 7
Training loss: 1.4871232509613037
Validation loss: 2.017392102108207

Epoch: 6| Step: 8
Training loss: 2.151729106903076
Validation loss: 1.971746870266494

Epoch: 6| Step: 9
Training loss: 1.9810800552368164
Validation loss: 1.9489275101692445

Epoch: 6| Step: 10
Training loss: 1.9205306768417358
Validation loss: 1.9444804063407324

Epoch: 6| Step: 11
Training loss: 1.902890920639038
Validation loss: 1.9651140935959355

Epoch: 6| Step: 12
Training loss: 1.754896640777588
Validation loss: 1.9663712760453582

Epoch: 6| Step: 13
Training loss: 2.6369009017944336
Validation loss: 1.9203920646380352

Epoch: 196| Step: 0
Training loss: 1.9491426944732666
Validation loss: 1.943442210074394

Epoch: 6| Step: 1
Training loss: 1.8769848346710205
Validation loss: 1.9319028264732772

Epoch: 6| Step: 2
Training loss: 1.7250969409942627
Validation loss: 1.9716513067163446

Epoch: 6| Step: 3
Training loss: 2.152385950088501
Validation loss: 1.9653946391997799

Epoch: 6| Step: 4
Training loss: 1.8998854160308838
Validation loss: 2.0129994910250426

Epoch: 6| Step: 5
Training loss: 1.828691840171814
Validation loss: 1.990935392277215

Epoch: 6| Step: 6
Training loss: 1.9794423580169678
Validation loss: 1.9748708240447506

Epoch: 6| Step: 7
Training loss: 0.9994397163391113
Validation loss: 1.972038794589299

Epoch: 6| Step: 8
Training loss: 1.8531122207641602
Validation loss: 1.988363237791164

Epoch: 6| Step: 9
Training loss: 2.313673734664917
Validation loss: 1.9869325417344288

Epoch: 6| Step: 10
Training loss: 1.804464340209961
Validation loss: 1.9980718448597898

Epoch: 6| Step: 11
Training loss: 1.9577279090881348
Validation loss: 1.9733753691437423

Epoch: 6| Step: 12
Training loss: 2.180353879928589
Validation loss: 1.9835557835076445

Epoch: 6| Step: 13
Training loss: 2.324004650115967
Validation loss: 1.9616061923324422

Epoch: 197| Step: 0
Training loss: 2.0502917766571045
Validation loss: 2.0146223806565806

Epoch: 6| Step: 1
Training loss: 2.4923813343048096
Validation loss: 1.9541038813129548

Epoch: 6| Step: 2
Training loss: 1.9654102325439453
Validation loss: 2.0024824501365743

Epoch: 6| Step: 3
Training loss: 1.8578431606292725
Validation loss: 1.9647964815939627

Epoch: 6| Step: 4
Training loss: 1.6559215784072876
Validation loss: 1.9501748687477523

Epoch: 6| Step: 5
Training loss: 1.3780276775360107
Validation loss: 1.9859828141427809

Epoch: 6| Step: 6
Training loss: 1.9259425401687622
Validation loss: 1.9401501686342302

Epoch: 6| Step: 7
Training loss: 2.4096157550811768
Validation loss: 1.9825693766276042

Epoch: 6| Step: 8
Training loss: 1.4061601161956787
Validation loss: 1.9537698197108444

Epoch: 6| Step: 9
Training loss: 1.7822774648666382
Validation loss: 1.9805012492723362

Epoch: 6| Step: 10
Training loss: 1.8695138692855835
Validation loss: 1.9370841441615936

Epoch: 6| Step: 11
Training loss: 1.8629999160766602
Validation loss: 1.9034529629574026

Epoch: 6| Step: 12
Training loss: 2.2925219535827637
Validation loss: 1.9491582403900802

Epoch: 6| Step: 13
Training loss: 1.8707281351089478
Validation loss: 1.97195997289432

Epoch: 198| Step: 0
Training loss: 1.698889136314392
Validation loss: 1.9541436984974851

Epoch: 6| Step: 1
Training loss: 1.8365274667739868
Validation loss: 2.0134842216327624

Epoch: 6| Step: 2
Training loss: 2.2177934646606445
Validation loss: 1.9659680653643865

Epoch: 6| Step: 3
Training loss: 1.9594584703445435
Validation loss: 1.964979387098743

Epoch: 6| Step: 4
Training loss: 1.5170042514801025
Validation loss: 1.9344519902301092

Epoch: 6| Step: 5
Training loss: 2.3744144439697266
Validation loss: 1.9712058472376999

Epoch: 6| Step: 6
Training loss: 1.241565465927124
Validation loss: 1.965989988337281

Epoch: 6| Step: 7
Training loss: 1.6963732242584229
Validation loss: 1.9414245313213718

Epoch: 6| Step: 8
Training loss: 1.6856396198272705
Validation loss: 1.9612815867188156

Epoch: 6| Step: 9
Training loss: 1.702799916267395
Validation loss: 1.9942082205126364

Epoch: 6| Step: 10
Training loss: 2.988452672958374
Validation loss: 2.004113849773202

Epoch: 6| Step: 11
Training loss: 2.06801176071167
Validation loss: 1.942067374465286

Epoch: 6| Step: 12
Training loss: 1.2942817211151123
Validation loss: 1.9612780130037697

Epoch: 6| Step: 13
Training loss: 2.0103793144226074
Validation loss: 1.9361744619184924

Epoch: 199| Step: 0
Training loss: 1.9026296138763428
Validation loss: 2.007478444806991

Epoch: 6| Step: 1
Training loss: 1.5630574226379395
Validation loss: 1.9652210179195608

Epoch: 6| Step: 2
Training loss: 2.316683292388916
Validation loss: 1.9644167141247821

Epoch: 6| Step: 3
Training loss: 1.4521315097808838
Validation loss: 1.9845328741176154

Epoch: 6| Step: 4
Training loss: 2.2709145545959473
Validation loss: 2.0110800535448137

Epoch: 6| Step: 5
Training loss: 2.13002610206604
Validation loss: 2.0164595060451056

Epoch: 6| Step: 6
Training loss: 2.176210403442383
Validation loss: 1.948317366261636

Epoch: 6| Step: 7
Training loss: 2.078777313232422
Validation loss: 2.0109813546621673

Epoch: 6| Step: 8
Training loss: 1.5253818035125732
Validation loss: 1.9787356468939012

Epoch: 6| Step: 9
Training loss: 1.790602445602417
Validation loss: 1.9548937838564637

Epoch: 6| Step: 10
Training loss: 2.0976033210754395
Validation loss: 2.0027471614140335

Epoch: 6| Step: 11
Training loss: 1.8553011417388916
Validation loss: 1.9873982565377348

Epoch: 6| Step: 12
Training loss: 1.3700833320617676
Validation loss: 2.0037015561134583

Epoch: 6| Step: 13
Training loss: 1.2308001518249512
Validation loss: 1.9457581786699192

Epoch: 200| Step: 0
Training loss: 1.836348533630371
Validation loss: 2.006195113223086

Epoch: 6| Step: 1
Training loss: 2.2991302013397217
Validation loss: 1.9576281809037732

Epoch: 6| Step: 2
Training loss: 1.9643034934997559
Validation loss: 2.027156981088782

Epoch: 6| Step: 3
Training loss: 1.9765647649765015
Validation loss: 1.963957933969395

Epoch: 6| Step: 4
Training loss: 2.236175537109375
Validation loss: 1.9893325374972435

Epoch: 6| Step: 5
Training loss: 1.2116458415985107
Validation loss: 1.982778133884553

Epoch: 6| Step: 6
Training loss: 1.9450440406799316
Validation loss: 1.9638046308230328

Epoch: 6| Step: 7
Training loss: 2.278092622756958
Validation loss: 1.9752629854345833

Epoch: 6| Step: 8
Training loss: 1.8171955347061157
Validation loss: 2.016948189786685

Epoch: 6| Step: 9
Training loss: 1.4710094928741455
Validation loss: 1.9187285746297529

Epoch: 6| Step: 10
Training loss: 1.6339836120605469
Validation loss: 1.941476083570911

Epoch: 6| Step: 11
Training loss: 1.4462875127792358
Validation loss: 1.9644373334864134

Epoch: 6| Step: 12
Training loss: 2.11405611038208
Validation loss: 1.9571149515849289

Epoch: 6| Step: 13
Training loss: 2.3488032817840576
Validation loss: 1.9773921146187732

Epoch: 201| Step: 0
Training loss: 1.9611157178878784
Validation loss: 1.9816566795431159

Epoch: 6| Step: 1
Training loss: 1.7558993101119995
Validation loss: 1.9357807277351298

Epoch: 6| Step: 2
Training loss: 1.6563489437103271
Validation loss: 1.9382516491797663

Epoch: 6| Step: 3
Training loss: 1.4208331108093262
Validation loss: 1.9632127797731789

Epoch: 6| Step: 4
Training loss: 2.42932391166687
Validation loss: 1.958678812109014

Epoch: 6| Step: 5
Training loss: 1.5046972036361694
Validation loss: 1.9465101854775542

Epoch: 6| Step: 6
Training loss: 1.8568017482757568
Validation loss: 1.94541887826817

Epoch: 6| Step: 7
Training loss: 2.443854808807373
Validation loss: 1.9824536692711614

Epoch: 6| Step: 8
Training loss: 1.5707026720046997
Validation loss: 1.965299980614775

Epoch: 6| Step: 9
Training loss: 2.0204148292541504
Validation loss: 1.9785092440984582

Epoch: 6| Step: 10
Training loss: 2.7936630249023438
Validation loss: 1.9537647783115346

Epoch: 6| Step: 11
Training loss: 1.613796591758728
Validation loss: 1.9165068018820979

Epoch: 6| Step: 12
Training loss: 1.3474316596984863
Validation loss: 1.9436374979634439

Epoch: 6| Step: 13
Training loss: 1.9811795949935913
Validation loss: 1.994319397916076

Epoch: 202| Step: 0
Training loss: 2.1740071773529053
Validation loss: 1.938642773576962

Epoch: 6| Step: 1
Training loss: 1.857884407043457
Validation loss: 1.9766981229987195

Epoch: 6| Step: 2
Training loss: 1.337265968322754
Validation loss: 1.8988594265394314

Epoch: 6| Step: 3
Training loss: 1.7942265272140503
Validation loss: 1.9461554404227965

Epoch: 6| Step: 4
Training loss: 1.7352879047393799
Validation loss: 2.0041413768645255

Epoch: 6| Step: 5
Training loss: 1.2363228797912598
Validation loss: 1.979856042451756

Epoch: 6| Step: 6
Training loss: 1.3111416101455688
Validation loss: 1.9557152845526253

Epoch: 6| Step: 7
Training loss: 2.884624481201172
Validation loss: 1.970630758552141

Epoch: 6| Step: 8
Training loss: 2.643096446990967
Validation loss: 1.8971270566345544

Epoch: 6| Step: 9
Training loss: 2.388115644454956
Validation loss: 1.9904601804671749

Epoch: 6| Step: 10
Training loss: 1.5958857536315918
Validation loss: 1.94558959878901

Epoch: 6| Step: 11
Training loss: 2.0586535930633545
Validation loss: 1.9485998627960042

Epoch: 6| Step: 12
Training loss: 1.2339235544204712
Validation loss: 1.9518427951361543

Epoch: 6| Step: 13
Training loss: 1.6251112222671509
Validation loss: 1.9675410870582826

Epoch: 203| Step: 0
Training loss: 1.7743644714355469
Validation loss: 1.9761040326087707

Epoch: 6| Step: 1
Training loss: 1.5659217834472656
Validation loss: 1.977291327650829

Epoch: 6| Step: 2
Training loss: 2.7704596519470215
Validation loss: 1.979615355050692

Epoch: 6| Step: 3
Training loss: 1.9383294582366943
Validation loss: 1.9738415761660504

Epoch: 6| Step: 4
Training loss: 2.1901674270629883
Validation loss: 1.949850131106633

Epoch: 6| Step: 5
Training loss: 2.067326307296753
Validation loss: 1.9761305957712152

Epoch: 6| Step: 6
Training loss: 1.3895902633666992
Validation loss: 1.9910778614782518

Epoch: 6| Step: 7
Training loss: 0.9490530490875244
Validation loss: 1.9758212489466513

Epoch: 6| Step: 8
Training loss: 1.4360744953155518
Validation loss: 1.961230431833575

Epoch: 6| Step: 9
Training loss: 2.0585031509399414
Validation loss: 1.960692423646168

Epoch: 6| Step: 10
Training loss: 2.21927809715271
Validation loss: 1.9296066876380675

Epoch: 6| Step: 11
Training loss: 2.282015800476074
Validation loss: 1.9286274666427283

Epoch: 6| Step: 12
Training loss: 1.8200808763504028
Validation loss: 1.9309729555601716

Epoch: 6| Step: 13
Training loss: 1.078635573387146
Validation loss: 1.9465104456870788

Epoch: 204| Step: 0
Training loss: 2.169562339782715
Validation loss: 1.9878883438725625

Epoch: 6| Step: 1
Training loss: 1.4656801223754883
Validation loss: 1.9129323190258396

Epoch: 6| Step: 2
Training loss: 1.971808671951294
Validation loss: 1.9367597833756478

Epoch: 6| Step: 3
Training loss: 1.835029125213623
Validation loss: 1.9395250569107712

Epoch: 6| Step: 4
Training loss: 1.795972228050232
Validation loss: 1.949456734042014

Epoch: 6| Step: 5
Training loss: 1.9622763395309448
Validation loss: 1.953297822706161

Epoch: 6| Step: 6
Training loss: 2.0493221282958984
Validation loss: 1.9372640604613929

Epoch: 6| Step: 7
Training loss: 1.2748079299926758
Validation loss: 1.9362318990051106

Epoch: 6| Step: 8
Training loss: 1.9481979608535767
Validation loss: 1.9827001979274135

Epoch: 6| Step: 9
Training loss: 2.278177499771118
Validation loss: 1.9037490993417718

Epoch: 6| Step: 10
Training loss: 1.50310218334198
Validation loss: 1.9588422057449177

Epoch: 6| Step: 11
Training loss: 1.988722801208496
Validation loss: 1.9514837034286991

Epoch: 6| Step: 12
Training loss: 2.0986099243164062
Validation loss: 1.9628568413437053

Epoch: 6| Step: 13
Training loss: 1.7575563192367554
Validation loss: 2.0176442566738335

Epoch: 205| Step: 0
Training loss: 1.8436778783798218
Validation loss: 1.9392722909168532

Epoch: 6| Step: 1
Training loss: 1.9866135120391846
Validation loss: 1.9693564958469842

Epoch: 6| Step: 2
Training loss: 1.5603947639465332
Validation loss: 1.9844077312818138

Epoch: 6| Step: 3
Training loss: 2.0275216102600098
Validation loss: 2.012322279714769

Epoch: 6| Step: 4
Training loss: 2.406236171722412
Validation loss: 1.9768297262089227

Epoch: 6| Step: 5
Training loss: 1.81312894821167
Validation loss: 1.9833016613478303

Epoch: 6| Step: 6
Training loss: 2.3099989891052246
Validation loss: 1.952895466999341

Epoch: 6| Step: 7
Training loss: 2.129509449005127
Validation loss: 2.004117199169692

Epoch: 6| Step: 8
Training loss: 1.625259280204773
Validation loss: 1.9458216518484137

Epoch: 6| Step: 9
Training loss: 1.20561945438385
Validation loss: 1.9639305888965566

Epoch: 6| Step: 10
Training loss: 2.327162265777588
Validation loss: 1.96195149806238

Epoch: 6| Step: 11
Training loss: 1.7423083782196045
Validation loss: 1.9527170670929777

Epoch: 6| Step: 12
Training loss: 1.7025692462921143
Validation loss: 1.9763015444560716

Epoch: 6| Step: 13
Training loss: 0.8161495923995972
Validation loss: 1.9548084364142468

Epoch: 206| Step: 0
Training loss: 2.55523943901062
Validation loss: 1.937062322452504

Epoch: 6| Step: 1
Training loss: 2.5133261680603027
Validation loss: 1.9746028223345358

Epoch: 6| Step: 2
Training loss: 1.667001485824585
Validation loss: 1.9392711923968406

Epoch: 6| Step: 3
Training loss: 1.736048936843872
Validation loss: 1.9586475408205422

Epoch: 6| Step: 4
Training loss: 1.7717398405075073
Validation loss: 1.916215447969334

Epoch: 6| Step: 5
Training loss: 1.7785921096801758
Validation loss: 1.9649305369264336

Epoch: 6| Step: 6
Training loss: 1.205902338027954
Validation loss: 1.9109214480205248

Epoch: 6| Step: 7
Training loss: 1.6790876388549805
Validation loss: 1.942176757320281

Epoch: 6| Step: 8
Training loss: 1.178765892982483
Validation loss: 1.9802419600948211

Epoch: 6| Step: 9
Training loss: 1.97336745262146
Validation loss: 1.9279225205862394

Epoch: 6| Step: 10
Training loss: 2.415130376815796
Validation loss: 1.9400033335531912

Epoch: 6| Step: 11
Training loss: 1.8101567029953003
Validation loss: 1.9278735717137654

Epoch: 6| Step: 12
Training loss: 1.9719818830490112
Validation loss: 1.9070124421068417

Epoch: 6| Step: 13
Training loss: 1.847424030303955
Validation loss: 1.940191053575085

Epoch: 207| Step: 0
Training loss: 1.8554069995880127
Validation loss: 1.9072418764073362

Epoch: 6| Step: 1
Training loss: 2.1197495460510254
Validation loss: 1.9511885361004901

Epoch: 6| Step: 2
Training loss: 1.2576862573623657
Validation loss: 1.9567539179196922

Epoch: 6| Step: 3
Training loss: 1.6409753561019897
Validation loss: 1.9558414733538063

Epoch: 6| Step: 4
Training loss: 1.087312936782837
Validation loss: 1.9546922676024898

Epoch: 6| Step: 5
Training loss: 1.542105793952942
Validation loss: 1.9322817658865323

Epoch: 6| Step: 6
Training loss: 2.329653739929199
Validation loss: 1.9600964553894535

Epoch: 6| Step: 7
Training loss: 1.5673631429672241
Validation loss: 2.002156014083534

Epoch: 6| Step: 8
Training loss: 1.9214301109313965
Validation loss: 1.9357473042703444

Epoch: 6| Step: 9
Training loss: 1.9220404624938965
Validation loss: 1.9838081534190843

Epoch: 6| Step: 10
Training loss: 2.0530567169189453
Validation loss: 1.9354057465830157

Epoch: 6| Step: 11
Training loss: 2.569255828857422
Validation loss: 1.9637709279214182

Epoch: 6| Step: 12
Training loss: 2.0318377017974854
Validation loss: 1.914154791062878

Epoch: 6| Step: 13
Training loss: 1.8592292070388794
Validation loss: 1.9758357950436172

Epoch: 208| Step: 0
Training loss: 1.2939683198928833
Validation loss: 1.9262687711305515

Epoch: 6| Step: 1
Training loss: 1.4864176511764526
Validation loss: 1.9052970537575342

Epoch: 6| Step: 2
Training loss: 1.9284155368804932
Validation loss: 1.9594220884384648

Epoch: 6| Step: 3
Training loss: 1.2006940841674805
Validation loss: 1.928502252024989

Epoch: 6| Step: 4
Training loss: 2.0409374237060547
Validation loss: 1.973451501579695

Epoch: 6| Step: 5
Training loss: 1.5785791873931885
Validation loss: 1.9635098621409426

Epoch: 6| Step: 6
Training loss: 2.437875509262085
Validation loss: 1.9665540725954118

Epoch: 6| Step: 7
Training loss: 1.8931776285171509
Validation loss: 1.9248584585805093

Epoch: 6| Step: 8
Training loss: 2.2930569648742676
Validation loss: 1.9202700122710197

Epoch: 6| Step: 9
Training loss: 2.198793411254883
Validation loss: 1.9819759681660643

Epoch: 6| Step: 10
Training loss: 1.6523497104644775
Validation loss: 1.9502261300240793

Epoch: 6| Step: 11
Training loss: 1.7401714324951172
Validation loss: 1.9520933756264307

Epoch: 6| Step: 12
Training loss: 2.480769634246826
Validation loss: 1.9871907631556194

Epoch: 6| Step: 13
Training loss: 1.2461693286895752
Validation loss: 1.9558258466823126

Epoch: 209| Step: 0
Training loss: 2.479126453399658
Validation loss: 1.9325941942071403

Epoch: 6| Step: 1
Training loss: 1.5042004585266113
Validation loss: 1.9530134611232306

Epoch: 6| Step: 2
Training loss: 1.3778393268585205
Validation loss: 1.8955716779155116

Epoch: 6| Step: 3
Training loss: 1.7686402797698975
Validation loss: 1.894299227704284

Epoch: 6| Step: 4
Training loss: 1.9733963012695312
Validation loss: 1.9093329598826747

Epoch: 6| Step: 5
Training loss: 1.9464468955993652
Validation loss: 1.9375295869765743

Epoch: 6| Step: 6
Training loss: 2.2849597930908203
Validation loss: 1.950096832808628

Epoch: 6| Step: 7
Training loss: 1.0383492708206177
Validation loss: 1.967576648599358

Epoch: 6| Step: 8
Training loss: 2.4247193336486816
Validation loss: 1.9373028701351536

Epoch: 6| Step: 9
Training loss: 1.2070112228393555
Validation loss: 1.9431111120408582

Epoch: 6| Step: 10
Training loss: 1.8860876560211182
Validation loss: 1.957848543761879

Epoch: 6| Step: 11
Training loss: 1.8876852989196777
Validation loss: 1.92595414961538

Epoch: 6| Step: 12
Training loss: 1.804495096206665
Validation loss: 1.9124100951738254

Epoch: 6| Step: 13
Training loss: 1.9603385925292969
Validation loss: 1.9378847845139042

Epoch: 210| Step: 0
Training loss: 1.9493227005004883
Validation loss: 1.9099113120827624

Epoch: 6| Step: 1
Training loss: 1.8612573146820068
Validation loss: 1.9567895166335567

Epoch: 6| Step: 2
Training loss: 2.250941276550293
Validation loss: 1.9460664564563381

Epoch: 6| Step: 3
Training loss: 1.7501918077468872
Validation loss: 1.9715961076880013

Epoch: 6| Step: 4
Training loss: 1.8282485008239746
Validation loss: 1.935377843918339

Epoch: 6| Step: 5
Training loss: 3.0136709213256836
Validation loss: 1.957515106406263

Epoch: 6| Step: 6
Training loss: 1.7556016445159912
Validation loss: 1.943548237123797

Epoch: 6| Step: 7
Training loss: 1.5112383365631104
Validation loss: 1.96970449596323

Epoch: 6| Step: 8
Training loss: 1.4768134355545044
Validation loss: 1.9128158759045344

Epoch: 6| Step: 9
Training loss: 2.1884219646453857
Validation loss: 1.9581360778500956

Epoch: 6| Step: 10
Training loss: 1.3454828262329102
Validation loss: 1.9748473821147796

Epoch: 6| Step: 11
Training loss: 1.6712284088134766
Validation loss: 1.9625208454747354

Epoch: 6| Step: 12
Training loss: 1.0354406833648682
Validation loss: 1.8966085962069932

Epoch: 6| Step: 13
Training loss: 1.832977533340454
Validation loss: 1.9701453921615437

Epoch: 211| Step: 0
Training loss: 2.20582914352417
Validation loss: 1.9200281686680292

Epoch: 6| Step: 1
Training loss: 1.7564685344696045
Validation loss: 1.9601706894495154

Epoch: 6| Step: 2
Training loss: 1.8420138359069824
Validation loss: 1.9610837633891771

Epoch: 6| Step: 3
Training loss: 1.4054921865463257
Validation loss: 1.988985025754539

Epoch: 6| Step: 4
Training loss: 2.331418514251709
Validation loss: 1.959457161605999

Epoch: 6| Step: 5
Training loss: 1.2204680442810059
Validation loss: 1.9172605032561927

Epoch: 6| Step: 6
Training loss: 1.8072664737701416
Validation loss: 1.9316121608980241

Epoch: 6| Step: 7
Training loss: 1.5382990837097168
Validation loss: 1.938551410551994

Epoch: 6| Step: 8
Training loss: 2.198709011077881
Validation loss: 1.981385096426933

Epoch: 6| Step: 9
Training loss: 2.067012310028076
Validation loss: 2.0012546470088344

Epoch: 6| Step: 10
Training loss: 2.2264862060546875
Validation loss: 1.9917854519300564

Epoch: 6| Step: 11
Training loss: 1.9233534336090088
Validation loss: 1.922142849173597

Epoch: 6| Step: 12
Training loss: 0.66191166639328
Validation loss: 1.948848565419515

Epoch: 6| Step: 13
Training loss: 2.728123903274536
Validation loss: 1.9528995662607171

Epoch: 212| Step: 0
Training loss: 2.516500473022461
Validation loss: 1.972886787947788

Epoch: 6| Step: 1
Training loss: 1.6029293537139893
Validation loss: 1.9661670730959984

Epoch: 6| Step: 2
Training loss: 1.4415538311004639
Validation loss: 1.9330256626170168

Epoch: 6| Step: 3
Training loss: 1.7279586791992188
Validation loss: 1.8833053855485813

Epoch: 6| Step: 4
Training loss: 2.0465803146362305
Validation loss: 1.9366493776280393

Epoch: 6| Step: 5
Training loss: 1.5709933042526245
Validation loss: 1.9542974797628259

Epoch: 6| Step: 6
Training loss: 1.4820468425750732
Validation loss: 1.9064317672483382

Epoch: 6| Step: 7
Training loss: 1.7721588611602783
Validation loss: 1.9502947202292822

Epoch: 6| Step: 8
Training loss: 2.084649085998535
Validation loss: 1.955568672508322

Epoch: 6| Step: 9
Training loss: 1.4440083503723145
Validation loss: 1.9641867388961136

Epoch: 6| Step: 10
Training loss: 2.234722137451172
Validation loss: 1.9082329683406378

Epoch: 6| Step: 11
Training loss: 2.14554500579834
Validation loss: 1.9455314823376235

Epoch: 6| Step: 12
Training loss: 1.9951176643371582
Validation loss: 1.9606799720436014

Epoch: 6| Step: 13
Training loss: 1.8134710788726807
Validation loss: 1.9498699736851517

Epoch: 213| Step: 0
Training loss: 1.3696640729904175
Validation loss: 1.9260427810812508

Epoch: 6| Step: 1
Training loss: 1.5600895881652832
Validation loss: 1.9551052201178767

Epoch: 6| Step: 2
Training loss: 1.6246439218521118
Validation loss: 1.892238825880071

Epoch: 6| Step: 3
Training loss: 1.3642854690551758
Validation loss: 1.9490921638345207

Epoch: 6| Step: 4
Training loss: 1.8505537509918213
Validation loss: 1.9285235443422872

Epoch: 6| Step: 5
Training loss: 2.443193197250366
Validation loss: 1.8643724867092666

Epoch: 6| Step: 6
Training loss: 1.915592074394226
Validation loss: 1.9359315185136692

Epoch: 6| Step: 7
Training loss: 2.608250617980957
Validation loss: 1.896380991064092

Epoch: 6| Step: 8
Training loss: 1.5401115417480469
Validation loss: 1.8643384825798772

Epoch: 6| Step: 9
Training loss: 2.8261847496032715
Validation loss: 1.9151151667359054

Epoch: 6| Step: 10
Training loss: 1.1657896041870117
Validation loss: 1.9197371967377201

Epoch: 6| Step: 11
Training loss: 1.4987506866455078
Validation loss: 1.9410660600149503

Epoch: 6| Step: 12
Training loss: 2.2360310554504395
Validation loss: 1.9790085464395502

Epoch: 6| Step: 13
Training loss: 1.7057929039001465
Validation loss: 1.9151030432793401

Epoch: 214| Step: 0
Training loss: 1.8856775760650635
Validation loss: 1.9358361331365441

Epoch: 6| Step: 1
Training loss: 1.5114680528640747
Validation loss: 1.9858765384202361

Epoch: 6| Step: 2
Training loss: 1.6142686605453491
Validation loss: 1.9158703563033894

Epoch: 6| Step: 3
Training loss: 1.8425744771957397
Validation loss: 2.0000347809125016

Epoch: 6| Step: 4
Training loss: 1.754314661026001
Validation loss: 1.9553449461537022

Epoch: 6| Step: 5
Training loss: 2.375258445739746
Validation loss: 1.8834476509401876

Epoch: 6| Step: 6
Training loss: 1.4441609382629395
Validation loss: 1.931793620509486

Epoch: 6| Step: 7
Training loss: 2.2157864570617676
Validation loss: 1.9634640178372782

Epoch: 6| Step: 8
Training loss: 1.7316532135009766
Validation loss: 1.980180940320415

Epoch: 6| Step: 9
Training loss: 2.5423054695129395
Validation loss: 1.917826412826456

Epoch: 6| Step: 10
Training loss: 1.6306205987930298
Validation loss: 1.9659626125007548

Epoch: 6| Step: 11
Training loss: 1.7590970993041992
Validation loss: 1.9669463314035887

Epoch: 6| Step: 12
Training loss: 1.6459112167358398
Validation loss: 1.9831659563126103

Epoch: 6| Step: 13
Training loss: 1.46329927444458
Validation loss: 1.9794833416579871

Epoch: 215| Step: 0
Training loss: 2.420414447784424
Validation loss: 1.9956502273518553

Epoch: 6| Step: 1
Training loss: 1.893363118171692
Validation loss: 1.952320332168251

Epoch: 6| Step: 2
Training loss: 1.520043134689331
Validation loss: 1.9671841141998128

Epoch: 6| Step: 3
Training loss: 1.6735002994537354
Validation loss: 1.9552457063428816

Epoch: 6| Step: 4
Training loss: 1.2283906936645508
Validation loss: 1.9366283083474765

Epoch: 6| Step: 5
Training loss: 2.495192289352417
Validation loss: 1.941475873352379

Epoch: 6| Step: 6
Training loss: 2.5203046798706055
Validation loss: 1.9139407411698373

Epoch: 6| Step: 7
Training loss: 2.32706880569458
Validation loss: 1.9220882615735453

Epoch: 6| Step: 8
Training loss: 1.423478126525879
Validation loss: 1.889638577738116

Epoch: 6| Step: 9
Training loss: 1.3213951587677002
Validation loss: 1.9466062502194477

Epoch: 6| Step: 10
Training loss: 1.9400279521942139
Validation loss: 1.9333645195089362

Epoch: 6| Step: 11
Training loss: 1.3658554553985596
Validation loss: 1.926949022918619

Epoch: 6| Step: 12
Training loss: 1.9308686256408691
Validation loss: 1.9225285258344424

Epoch: 6| Step: 13
Training loss: 1.782967448234558
Validation loss: 1.9354222846287552

Epoch: 216| Step: 0
Training loss: 1.569772481918335
Validation loss: 1.9433091212344427

Epoch: 6| Step: 1
Training loss: 2.0912935733795166
Validation loss: 1.8659444855105491

Epoch: 6| Step: 2
Training loss: 1.6549010276794434
Validation loss: 1.8974848126852384

Epoch: 6| Step: 3
Training loss: 2.309645175933838
Validation loss: 1.9216621780908236

Epoch: 6| Step: 4
Training loss: 1.7855513095855713
Validation loss: 1.933312709613513

Epoch: 6| Step: 5
Training loss: 1.9717940092086792
Validation loss: 1.9123479832885086

Epoch: 6| Step: 6
Training loss: 1.3971549272537231
Validation loss: 1.8739662337046799

Epoch: 6| Step: 7
Training loss: 2.137125253677368
Validation loss: 1.9242682585152246

Epoch: 6| Step: 8
Training loss: 1.4914672374725342
Validation loss: 1.919427312830443

Epoch: 6| Step: 9
Training loss: 2.114741802215576
Validation loss: 1.9108696855524534

Epoch: 6| Step: 10
Training loss: 2.5350828170776367
Validation loss: 1.9374947765822053

Epoch: 6| Step: 11
Training loss: 1.1968083381652832
Validation loss: 1.9405718490641604

Epoch: 6| Step: 12
Training loss: 2.148829936981201
Validation loss: 1.9913943993147982

Epoch: 6| Step: 13
Training loss: 1.4257878065109253
Validation loss: 1.9754806667245843

Epoch: 217| Step: 0
Training loss: 1.5022218227386475
Validation loss: 1.9472857931608796

Epoch: 6| Step: 1
Training loss: 1.9330650568008423
Validation loss: 1.94055784902265

Epoch: 6| Step: 2
Training loss: 1.3027777671813965
Validation loss: 1.9669294203481367

Epoch: 6| Step: 3
Training loss: 1.5785844326019287
Validation loss: 1.9681890677380305

Epoch: 6| Step: 4
Training loss: 2.6902191638946533
Validation loss: 1.9823115461616105

Epoch: 6| Step: 5
Training loss: 2.385023355484009
Validation loss: 1.9873696411809614

Epoch: 6| Step: 6
Training loss: 1.942333698272705
Validation loss: 1.9345330525470037

Epoch: 6| Step: 7
Training loss: 2.01096248626709
Validation loss: 1.9743289383508826

Epoch: 6| Step: 8
Training loss: 1.9491846561431885
Validation loss: 1.955260899759108

Epoch: 6| Step: 9
Training loss: 2.2474780082702637
Validation loss: 1.9187539392902004

Epoch: 6| Step: 10
Training loss: 1.5361430644989014
Validation loss: 1.9714632265029415

Epoch: 6| Step: 11
Training loss: 1.603585958480835
Validation loss: 1.9316321393494964

Epoch: 6| Step: 12
Training loss: 1.1951677799224854
Validation loss: 1.9398281753704112

Epoch: 6| Step: 13
Training loss: 1.6635091304779053
Validation loss: 1.9658031386713828

Epoch: 218| Step: 0
Training loss: 2.1252169609069824
Validation loss: 1.9198569418281637

Epoch: 6| Step: 1
Training loss: 2.2350540161132812
Validation loss: 1.9336090664709769

Epoch: 6| Step: 2
Training loss: 1.8313883543014526
Validation loss: 1.926629485622529

Epoch: 6| Step: 3
Training loss: 2.28857421875
Validation loss: 1.8981282236755534

Epoch: 6| Step: 4
Training loss: 1.5662295818328857
Validation loss: 1.9404674114719513

Epoch: 6| Step: 5
Training loss: 1.7773808240890503
Validation loss: 1.947156798455023

Epoch: 6| Step: 6
Training loss: 1.2881755828857422
Validation loss: 1.9086833769275295

Epoch: 6| Step: 7
Training loss: 1.6603355407714844
Validation loss: 1.92572904914938

Epoch: 6| Step: 8
Training loss: 1.2937679290771484
Validation loss: 1.9371375768415389

Epoch: 6| Step: 9
Training loss: 2.8490476608276367
Validation loss: 1.8984459779595817

Epoch: 6| Step: 10
Training loss: 1.759473204612732
Validation loss: 1.9581461414214103

Epoch: 6| Step: 11
Training loss: 1.5424284934997559
Validation loss: 1.948958376402496

Epoch: 6| Step: 12
Training loss: 2.0482373237609863
Validation loss: 1.9398605644062001

Epoch: 6| Step: 13
Training loss: 1.3278636932373047
Validation loss: 1.9273112794404388

Epoch: 219| Step: 0
Training loss: 1.1780468225479126
Validation loss: 1.9389931207062097

Epoch: 6| Step: 1
Training loss: 2.742612361907959
Validation loss: 1.8886767625808716

Epoch: 6| Step: 2
Training loss: 1.5622411966323853
Validation loss: 1.9176157136117258

Epoch: 6| Step: 3
Training loss: 1.1006360054016113
Validation loss: 1.9587047356431202

Epoch: 6| Step: 4
Training loss: 3.0682015419006348
Validation loss: 1.9267157636662966

Epoch: 6| Step: 5
Training loss: 1.3307576179504395
Validation loss: 1.936689660113345

Epoch: 6| Step: 6
Training loss: 1.1267246007919312
Validation loss: 1.9265428512327132

Epoch: 6| Step: 7
Training loss: 1.9957424402236938
Validation loss: 1.9602734722116941

Epoch: 6| Step: 8
Training loss: 1.9415161609649658
Validation loss: 1.972932388705592

Epoch: 6| Step: 9
Training loss: 2.492788314819336
Validation loss: 1.9844119215524325

Epoch: 6| Step: 10
Training loss: 2.004181146621704
Validation loss: 1.9795706425943682

Epoch: 6| Step: 11
Training loss: 1.417784571647644
Validation loss: 1.9305657699543943

Epoch: 6| Step: 12
Training loss: 1.4079921245574951
Validation loss: 1.9872786960294169

Epoch: 6| Step: 13
Training loss: 1.7343096733093262
Validation loss: 1.9633446201201408

Epoch: 220| Step: 0
Training loss: 1.451478123664856
Validation loss: 1.9466803278974307

Epoch: 6| Step: 1
Training loss: 1.893021821975708
Validation loss: 1.9743854320177467

Epoch: 6| Step: 2
Training loss: 1.1076748371124268
Validation loss: 1.9321805841179305

Epoch: 6| Step: 3
Training loss: 2.2504611015319824
Validation loss: 1.971136232858063

Epoch: 6| Step: 4
Training loss: 2.394866943359375
Validation loss: 1.9883386358138053

Epoch: 6| Step: 5
Training loss: 1.3764560222625732
Validation loss: 1.937987865940217

Epoch: 6| Step: 6
Training loss: 1.751976490020752
Validation loss: 1.961782791281259

Epoch: 6| Step: 7
Training loss: 2.2675256729125977
Validation loss: 1.9515472586436937

Epoch: 6| Step: 8
Training loss: 1.5835480690002441
Validation loss: 1.915070128697221

Epoch: 6| Step: 9
Training loss: 1.7963091135025024
Validation loss: 1.9086278741077711

Epoch: 6| Step: 10
Training loss: 1.8733587265014648
Validation loss: 1.928609985177235

Epoch: 6| Step: 11
Training loss: 1.9373530149459839
Validation loss: 1.9252253450373167

Epoch: 6| Step: 12
Training loss: 1.7071603536605835
Validation loss: 1.9321358575615832

Epoch: 6| Step: 13
Training loss: 1.4185113906860352
Validation loss: 1.9255744103462464

Epoch: 221| Step: 0
Training loss: 1.3144522905349731
Validation loss: 1.9158701050666072

Epoch: 6| Step: 1
Training loss: 2.7209115028381348
Validation loss: 1.87481189158655

Epoch: 6| Step: 2
Training loss: 2.2535672187805176
Validation loss: 1.9611772093721616

Epoch: 6| Step: 3
Training loss: 1.6764075756072998
Validation loss: 1.9018301668987478

Epoch: 6| Step: 4
Training loss: 1.9029130935668945
Validation loss: 1.9249915384477185

Epoch: 6| Step: 5
Training loss: 1.9804108142852783
Validation loss: 1.9632946073368032

Epoch: 6| Step: 6
Training loss: 1.3515307903289795
Validation loss: 1.9466505409568868

Epoch: 6| Step: 7
Training loss: 1.5835392475128174
Validation loss: 1.919465882803804

Epoch: 6| Step: 8
Training loss: 2.0762367248535156
Validation loss: 1.9350063236810828

Epoch: 6| Step: 9
Training loss: 2.173251152038574
Validation loss: 1.913568494140461

Epoch: 6| Step: 10
Training loss: 2.204404830932617
Validation loss: 1.9235283982369207

Epoch: 6| Step: 11
Training loss: 1.1933058500289917
Validation loss: 1.95613952349591

Epoch: 6| Step: 12
Training loss: 1.0661317110061646
Validation loss: 1.9135282231915383

Epoch: 6| Step: 13
Training loss: 2.4823145866394043
Validation loss: 1.9299238945848198

Epoch: 222| Step: 0
Training loss: 1.5850672721862793
Validation loss: 1.9184201814795052

Epoch: 6| Step: 1
Training loss: 1.4352203607559204
Validation loss: 1.9408278695998653

Epoch: 6| Step: 2
Training loss: 2.237626314163208
Validation loss: 1.908937192732288

Epoch: 6| Step: 3
Training loss: 1.9337882995605469
Validation loss: 1.909463083872231

Epoch: 6| Step: 4
Training loss: 2.181431531906128
Validation loss: 1.9480549571334675

Epoch: 6| Step: 5
Training loss: 2.0864992141723633
Validation loss: 1.9260949191226755

Epoch: 6| Step: 6
Training loss: 1.4058822393417358
Validation loss: 1.9386774365619948

Epoch: 6| Step: 7
Training loss: 1.5926122665405273
Validation loss: 1.9109155452379616

Epoch: 6| Step: 8
Training loss: 1.7286802530288696
Validation loss: 1.9003480288290209

Epoch: 6| Step: 9
Training loss: 1.0388357639312744
Validation loss: 1.9344233953824608

Epoch: 6| Step: 10
Training loss: 2.3263258934020996
Validation loss: 1.9438609794903827

Epoch: 6| Step: 11
Training loss: 2.1599349975585938
Validation loss: 1.9215483037374352

Epoch: 6| Step: 12
Training loss: 1.3453208208084106
Validation loss: 1.9228663482973654

Epoch: 6| Step: 13
Training loss: 2.060642719268799
Validation loss: 1.925849732532296

Epoch: 223| Step: 0
Training loss: 1.8399020433425903
Validation loss: 1.8774270908806914

Epoch: 6| Step: 1
Training loss: 2.017087936401367
Validation loss: 1.9301058323152605

Epoch: 6| Step: 2
Training loss: 2.3045005798339844
Validation loss: 1.924242901545699

Epoch: 6| Step: 3
Training loss: 0.9192149639129639
Validation loss: 1.9735733309099752

Epoch: 6| Step: 4
Training loss: 1.8238188028335571
Validation loss: 1.9018577221901185

Epoch: 6| Step: 5
Training loss: 1.8059757947921753
Validation loss: 1.953414624737155

Epoch: 6| Step: 6
Training loss: 1.77303147315979
Validation loss: 1.891233185286163

Epoch: 6| Step: 7
Training loss: 2.3021092414855957
Validation loss: 1.9216373402585265

Epoch: 6| Step: 8
Training loss: 1.5999343395233154
Validation loss: 1.9342710279649304

Epoch: 6| Step: 9
Training loss: 1.5954208374023438
Validation loss: 1.9371307883211362

Epoch: 6| Step: 10
Training loss: 2.602074146270752
Validation loss: 1.9047622578118437

Epoch: 6| Step: 11
Training loss: 1.4370014667510986
Validation loss: 1.9452664518869052

Epoch: 6| Step: 12
Training loss: 1.635945200920105
Validation loss: 1.941977858543396

Epoch: 6| Step: 13
Training loss: 1.0151653289794922
Validation loss: 1.9839090531872166

Epoch: 224| Step: 0
Training loss: 1.415611982345581
Validation loss: 1.8777160708622267

Epoch: 6| Step: 1
Training loss: 2.2422337532043457
Validation loss: 1.8937982641240603

Epoch: 6| Step: 2
Training loss: 1.4312493801116943
Validation loss: 1.8722154312236334

Epoch: 6| Step: 3
Training loss: 1.6574945449829102
Validation loss: 1.8830385797767228

Epoch: 6| Step: 4
Training loss: 1.7925775051116943
Validation loss: 1.9013794340113157

Epoch: 6| Step: 5
Training loss: 1.5749882459640503
Validation loss: 1.9115141783991167

Epoch: 6| Step: 6
Training loss: 1.9335423707962036
Validation loss: 1.9109727080150316

Epoch: 6| Step: 7
Training loss: 1.8382207155227661
Validation loss: 1.8963361017165645

Epoch: 6| Step: 8
Training loss: 2.1871886253356934
Validation loss: 1.8737918817868797

Epoch: 6| Step: 9
Training loss: 1.784346103668213
Validation loss: 1.900012928952453

Epoch: 6| Step: 10
Training loss: 1.8434529304504395
Validation loss: 1.8932768016733148

Epoch: 6| Step: 11
Training loss: 1.5617356300354004
Validation loss: 1.9356116223078903

Epoch: 6| Step: 12
Training loss: 1.4660630226135254
Validation loss: 1.9072316923449117

Epoch: 6| Step: 13
Training loss: 2.7556440830230713
Validation loss: 1.9295226989253875

Epoch: 225| Step: 0
Training loss: 1.4407238960266113
Validation loss: 1.9417127793835056

Epoch: 6| Step: 1
Training loss: 1.2175180912017822
Validation loss: 1.9441626943567747

Epoch: 6| Step: 2
Training loss: 1.9556204080581665
Validation loss: 1.9292940567898493

Epoch: 6| Step: 3
Training loss: 0.9559901356697083
Validation loss: 1.9138583701143983

Epoch: 6| Step: 4
Training loss: 1.7481606006622314
Validation loss: 1.9126007979915989

Epoch: 6| Step: 5
Training loss: 1.6994588375091553
Validation loss: 1.9256206404778264

Epoch: 6| Step: 6
Training loss: 1.901864767074585
Validation loss: 1.9031303364743468

Epoch: 6| Step: 7
Training loss: 1.6156929731369019
Validation loss: 1.9490537784432853

Epoch: 6| Step: 8
Training loss: 2.247966766357422
Validation loss: 1.9395919435767717

Epoch: 6| Step: 9
Training loss: 2.1398887634277344
Validation loss: 1.9344661030718076

Epoch: 6| Step: 10
Training loss: 1.7246533632278442
Validation loss: 1.9014626190226565

Epoch: 6| Step: 11
Training loss: 2.3238368034362793
Validation loss: 1.9139315287272136

Epoch: 6| Step: 12
Training loss: 1.5352232456207275
Validation loss: 1.9302693374695317

Epoch: 6| Step: 13
Training loss: 2.594421863555908
Validation loss: 1.927473460474322

Epoch: 226| Step: 0
Training loss: 1.0317708253860474
Validation loss: 1.8739364813732844

Epoch: 6| Step: 1
Training loss: 1.943472981452942
Validation loss: 1.9218115511760916

Epoch: 6| Step: 2
Training loss: 1.888288974761963
Validation loss: 1.9662198840930898

Epoch: 6| Step: 3
Training loss: 1.6499733924865723
Validation loss: 1.950150848716818

Epoch: 6| Step: 4
Training loss: 2.2875118255615234
Validation loss: 1.947235325331329

Epoch: 6| Step: 5
Training loss: 1.6791056394577026
Validation loss: 1.8675686659351471

Epoch: 6| Step: 6
Training loss: 1.9985377788543701
Validation loss: 1.935618660783255

Epoch: 6| Step: 7
Training loss: 1.0507323741912842
Validation loss: 1.90723592107014

Epoch: 6| Step: 8
Training loss: 1.9909334182739258
Validation loss: 1.9315624647243048

Epoch: 6| Step: 9
Training loss: 2.007740020751953
Validation loss: 1.9214050180168563

Epoch: 6| Step: 10
Training loss: 1.5577380657196045
Validation loss: 1.9355044839202717

Epoch: 6| Step: 11
Training loss: 1.7166574001312256
Validation loss: 1.9717845314292497

Epoch: 6| Step: 12
Training loss: 2.1116690635681152
Validation loss: 1.9412048939735658

Epoch: 6| Step: 13
Training loss: 1.5433210134506226
Validation loss: 1.8845371046373922

Epoch: 227| Step: 0
Training loss: 1.1942232847213745
Validation loss: 1.9363480101349533

Epoch: 6| Step: 1
Training loss: 1.2327271699905396
Validation loss: 1.938766884547408

Epoch: 6| Step: 2
Training loss: 2.243321180343628
Validation loss: 1.918595943399655

Epoch: 6| Step: 3
Training loss: 2.2166342735290527
Validation loss: 1.885558650057803

Epoch: 6| Step: 4
Training loss: 1.4291017055511475
Validation loss: 1.8772248760346444

Epoch: 6| Step: 5
Training loss: 1.6965354681015015
Validation loss: 1.93038002521761

Epoch: 6| Step: 6
Training loss: 1.8823713064193726
Validation loss: 1.9007586920133202

Epoch: 6| Step: 7
Training loss: 1.6289031505584717
Validation loss: 1.9467107993300243

Epoch: 6| Step: 8
Training loss: 2.0793795585632324
Validation loss: 1.941119129939746

Epoch: 6| Step: 9
Training loss: 2.3228840827941895
Validation loss: 1.903043431620444

Epoch: 6| Step: 10
Training loss: 1.5007139444351196
Validation loss: 1.9347779879006006

Epoch: 6| Step: 11
Training loss: 1.7184959650039673
Validation loss: 1.9558836785695886

Epoch: 6| Step: 12
Training loss: 1.8796055316925049
Validation loss: 1.9067349562080957

Epoch: 6| Step: 13
Training loss: 1.4300577640533447
Validation loss: 1.9652178954052668

Epoch: 228| Step: 0
Training loss: 1.7353978157043457
Validation loss: 1.9409187045148624

Epoch: 6| Step: 1
Training loss: 1.8037056922912598
Validation loss: 1.955613797710788

Epoch: 6| Step: 2
Training loss: 1.590388298034668
Validation loss: 1.8863563178687968

Epoch: 6| Step: 3
Training loss: 0.8909306526184082
Validation loss: 1.953945170166672

Epoch: 6| Step: 4
Training loss: 1.5554627180099487
Validation loss: 1.9233983639747865

Epoch: 6| Step: 5
Training loss: 1.9619277715682983
Validation loss: 1.949310048933952

Epoch: 6| Step: 6
Training loss: 1.8029531240463257
Validation loss: 1.9302403196211784

Epoch: 6| Step: 7
Training loss: 1.4759610891342163
Validation loss: 2.0269834379996023

Epoch: 6| Step: 8
Training loss: 1.8531746864318848
Validation loss: 1.9455195447450042

Epoch: 6| Step: 9
Training loss: 2.6873111724853516
Validation loss: 1.9722178892422748

Epoch: 6| Step: 10
Training loss: 2.0745959281921387
Validation loss: 1.9131053340050481

Epoch: 6| Step: 11
Training loss: 1.9504296779632568
Validation loss: 1.8824991628687868

Epoch: 6| Step: 12
Training loss: 1.4088773727416992
Validation loss: 1.9552440361310077

Epoch: 6| Step: 13
Training loss: 2.2409005165100098
Validation loss: 1.9185810473657423

Epoch: 229| Step: 0
Training loss: 1.4997612237930298
Validation loss: 1.954069883592667

Epoch: 6| Step: 1
Training loss: 2.5620055198669434
Validation loss: 1.9792900546904533

Epoch: 6| Step: 2
Training loss: 1.1533302068710327
Validation loss: 1.934125110667239

Epoch: 6| Step: 3
Training loss: 1.457269310951233
Validation loss: 1.9410774246338875

Epoch: 6| Step: 4
Training loss: 2.541350841522217
Validation loss: 1.9256160746338546

Epoch: 6| Step: 5
Training loss: 1.0076266527175903
Validation loss: 1.9190433127905733

Epoch: 6| Step: 6
Training loss: 1.5193705558776855
Validation loss: 1.9120721253015662

Epoch: 6| Step: 7
Training loss: 1.4239060878753662
Validation loss: 1.9398576059649069

Epoch: 6| Step: 8
Training loss: 2.6098456382751465
Validation loss: 1.8937385569336593

Epoch: 6| Step: 9
Training loss: 1.2845371961593628
Validation loss: 1.906822435317501

Epoch: 6| Step: 10
Training loss: 1.695724606513977
Validation loss: 1.9087532976622223

Epoch: 6| Step: 11
Training loss: 2.0136826038360596
Validation loss: 1.9257385628197783

Epoch: 6| Step: 12
Training loss: 1.6673059463500977
Validation loss: 1.9034869517049482

Epoch: 6| Step: 13
Training loss: 1.7753742933273315
Validation loss: 1.9105003879916282

Epoch: 230| Step: 0
Training loss: 2.410003185272217
Validation loss: 1.929949814273465

Epoch: 6| Step: 1
Training loss: 1.6970982551574707
Validation loss: 1.9251595376640238

Epoch: 6| Step: 2
Training loss: 1.6901289224624634
Validation loss: 1.927579520851053

Epoch: 6| Step: 3
Training loss: 1.1828140020370483
Validation loss: 1.8963109600928523

Epoch: 6| Step: 4
Training loss: 1.5867350101470947
Validation loss: 1.9914408845286216

Epoch: 6| Step: 5
Training loss: 1.6031746864318848
Validation loss: 1.924587813756799

Epoch: 6| Step: 6
Training loss: 1.6857028007507324
Validation loss: 1.9743254928178684

Epoch: 6| Step: 7
Training loss: 1.889391303062439
Validation loss: 1.8882901360911708

Epoch: 6| Step: 8
Training loss: 1.9539873600006104
Validation loss: 1.9935857865118212

Epoch: 6| Step: 9
Training loss: 2.293323040008545
Validation loss: 1.9029025082947106

Epoch: 6| Step: 10
Training loss: 1.667676329612732
Validation loss: 1.9194050104387346

Epoch: 6| Step: 11
Training loss: 1.882948398590088
Validation loss: 1.9348859146077146

Epoch: 6| Step: 12
Training loss: 1.728378176689148
Validation loss: 1.9495958064192085

Epoch: 6| Step: 13
Training loss: 1.4166810512542725
Validation loss: 1.9082403952075588

Epoch: 231| Step: 0
Training loss: 2.0205349922180176
Validation loss: 1.9044000961447274

Epoch: 6| Step: 1
Training loss: 1.4378633499145508
Validation loss: 1.914233934494757

Epoch: 6| Step: 2
Training loss: 1.4265456199645996
Validation loss: 1.9331345519711893

Epoch: 6| Step: 3
Training loss: 2.2920784950256348
Validation loss: 1.92579972615806

Epoch: 6| Step: 4
Training loss: 2.0517873764038086
Validation loss: 1.8861156894314675

Epoch: 6| Step: 5
Training loss: 2.7329745292663574
Validation loss: 1.8591727902812343

Epoch: 6| Step: 6
Training loss: 0.9953395128250122
Validation loss: 1.8689719579553092

Epoch: 6| Step: 7
Training loss: 1.4423705339431763
Validation loss: 1.9147224528815157

Epoch: 6| Step: 8
Training loss: 1.4135897159576416
Validation loss: 1.8796473100621214

Epoch: 6| Step: 9
Training loss: 1.6099268198013306
Validation loss: 1.9009916038923367

Epoch: 6| Step: 10
Training loss: 2.0968475341796875
Validation loss: 1.895192305246989

Epoch: 6| Step: 11
Training loss: 1.5729732513427734
Validation loss: 1.8705018617773568

Epoch: 6| Step: 12
Training loss: 1.3662846088409424
Validation loss: 1.9076069503702142

Epoch: 6| Step: 13
Training loss: 1.8632270097732544
Validation loss: 1.8604635833412089

Epoch: 232| Step: 0
Training loss: 1.6122639179229736
Validation loss: 1.8943917392402567

Epoch: 6| Step: 1
Training loss: 2.3313746452331543
Validation loss: 1.9322060103057532

Epoch: 6| Step: 2
Training loss: 1.6738667488098145
Validation loss: 1.9284184158489268

Epoch: 6| Step: 3
Training loss: 2.1055972576141357
Validation loss: 1.9336517562148392

Epoch: 6| Step: 4
Training loss: 1.6196470260620117
Validation loss: 1.9386169218247937

Epoch: 6| Step: 5
Training loss: 2.586003541946411
Validation loss: 1.8726627544690204

Epoch: 6| Step: 6
Training loss: 1.437917947769165
Validation loss: 1.8684304580893567

Epoch: 6| Step: 7
Training loss: 1.8884779214859009
Validation loss: 1.8463548626950992

Epoch: 6| Step: 8
Training loss: 1.7185728549957275
Validation loss: 1.9235990047454834

Epoch: 6| Step: 9
Training loss: 1.2480037212371826
Validation loss: 1.9074788016657676

Epoch: 6| Step: 10
Training loss: 1.4201081991195679
Validation loss: 1.9109371195557296

Epoch: 6| Step: 11
Training loss: 1.6328551769256592
Validation loss: 1.9121476399001254

Epoch: 6| Step: 12
Training loss: 1.411911964416504
Validation loss: 1.940208363276656

Epoch: 6| Step: 13
Training loss: 1.3824045658111572
Validation loss: 1.9294660963037962

Epoch: 233| Step: 0
Training loss: 1.2678215503692627
Validation loss: 1.840692222759288

Epoch: 6| Step: 1
Training loss: 1.869138240814209
Validation loss: 1.905847890402681

Epoch: 6| Step: 2
Training loss: 1.519704818725586
Validation loss: 1.9375174699291107

Epoch: 6| Step: 3
Training loss: 2.0759987831115723
Validation loss: 1.8603601724870744

Epoch: 6| Step: 4
Training loss: 2.0611839294433594
Validation loss: 1.8888586310930149

Epoch: 6| Step: 5
Training loss: 1.5403051376342773
Validation loss: 1.9019430914232809

Epoch: 6| Step: 6
Training loss: 1.6578118801116943
Validation loss: 1.9189519741201913

Epoch: 6| Step: 7
Training loss: 2.2857186794281006
Validation loss: 1.8651006119225615

Epoch: 6| Step: 8
Training loss: 1.2482802867889404
Validation loss: 1.912181838866203

Epoch: 6| Step: 9
Training loss: 1.7217131853103638
Validation loss: 1.895340258075345

Epoch: 6| Step: 10
Training loss: 2.3880743980407715
Validation loss: 1.9150199479954217

Epoch: 6| Step: 11
Training loss: 1.2517836093902588
Validation loss: 1.8841385790096816

Epoch: 6| Step: 12
Training loss: 2.1189992427825928
Validation loss: 1.912171051066409

Epoch: 6| Step: 13
Training loss: 1.6912351846694946
Validation loss: 1.9338648601244854

Epoch: 234| Step: 0
Training loss: 1.9450278282165527
Validation loss: 1.9173174468419885

Epoch: 6| Step: 1
Training loss: 1.6626203060150146
Validation loss: 1.9237863222757976

Epoch: 6| Step: 2
Training loss: 1.846726655960083
Validation loss: 1.9301198951659664

Epoch: 6| Step: 3
Training loss: 0.8573343753814697
Validation loss: 1.9376005331675212

Epoch: 6| Step: 4
Training loss: 1.4998769760131836
Validation loss: 1.9382912446093816

Epoch: 6| Step: 5
Training loss: 2.2465999126434326
Validation loss: 1.9266232944303943

Epoch: 6| Step: 6
Training loss: 1.6474807262420654
Validation loss: 1.9301103520137008

Epoch: 6| Step: 7
Training loss: 1.7772866487503052
Validation loss: 1.8999860132894208

Epoch: 6| Step: 8
Training loss: 2.0183708667755127
Validation loss: 1.9570705890655518

Epoch: 6| Step: 9
Training loss: 1.5310696363449097
Validation loss: 1.9096284335659397

Epoch: 6| Step: 10
Training loss: 1.7189807891845703
Validation loss: 1.9248964325074227

Epoch: 6| Step: 11
Training loss: 1.477782130241394
Validation loss: 1.9070485650852163

Epoch: 6| Step: 12
Training loss: 1.988905906677246
Validation loss: 1.8644037913250666

Epoch: 6| Step: 13
Training loss: 2.5573952198028564
Validation loss: 1.9013159172509306

Epoch: 235| Step: 0
Training loss: 1.735219955444336
Validation loss: 1.9051438006021644

Epoch: 6| Step: 1
Training loss: 2.3359439373016357
Validation loss: 1.9260936924206313

Epoch: 6| Step: 2
Training loss: 1.615208387374878
Validation loss: 1.8587476040727349

Epoch: 6| Step: 3
Training loss: 0.8087112903594971
Validation loss: 1.9177507239003335

Epoch: 6| Step: 4
Training loss: 1.3387967348098755
Validation loss: 1.9062545812258156

Epoch: 6| Step: 5
Training loss: 1.3395955562591553
Validation loss: 1.9483351989458966

Epoch: 6| Step: 6
Training loss: 1.439643144607544
Validation loss: 1.8816508041915072

Epoch: 6| Step: 7
Training loss: 2.4545788764953613
Validation loss: 1.90003453916119

Epoch: 6| Step: 8
Training loss: 2.625195026397705
Validation loss: 1.9158511956532795

Epoch: 6| Step: 9
Training loss: 2.3009305000305176
Validation loss: 1.9122548692969865

Epoch: 6| Step: 10
Training loss: 2.030872344970703
Validation loss: 1.8515035554926882

Epoch: 6| Step: 11
Training loss: 1.6421329975128174
Validation loss: 1.9828567581792031

Epoch: 6| Step: 12
Training loss: 1.3979543447494507
Validation loss: 1.880301812643646

Epoch: 6| Step: 13
Training loss: 2.0770180225372314
Validation loss: 1.8993864187630274

Epoch: 236| Step: 0
Training loss: 2.663731575012207
Validation loss: 1.8929340429203485

Epoch: 6| Step: 1
Training loss: 1.4023346900939941
Validation loss: 1.8930756225380847

Epoch: 6| Step: 2
Training loss: 1.8439370393753052
Validation loss: 1.917789161846202

Epoch: 6| Step: 3
Training loss: 1.214690923690796
Validation loss: 1.8886737362031014

Epoch: 6| Step: 4
Training loss: 1.5706331729888916
Validation loss: 1.8863303930528703

Epoch: 6| Step: 5
Training loss: 1.6329357624053955
Validation loss: 1.892500167251915

Epoch: 6| Step: 6
Training loss: 1.105975866317749
Validation loss: 1.9319167137145996

Epoch: 6| Step: 7
Training loss: 1.5852519273757935
Validation loss: 1.9328949220718876

Epoch: 6| Step: 8
Training loss: 1.5708935260772705
Validation loss: 1.9374271759422876

Epoch: 6| Step: 9
Training loss: 2.3023297786712646
Validation loss: 1.91200763692138

Epoch: 6| Step: 10
Training loss: 2.1759214401245117
Validation loss: 1.9455872710033129

Epoch: 6| Step: 11
Training loss: 1.6416568756103516
Validation loss: 1.9065409424484416

Epoch: 6| Step: 12
Training loss: 2.063411235809326
Validation loss: 1.8737033323575092

Epoch: 6| Step: 13
Training loss: 1.780182123184204
Validation loss: 1.901402558049848

Epoch: 237| Step: 0
Training loss: 2.3156700134277344
Validation loss: 1.8643965362220682

Epoch: 6| Step: 1
Training loss: 1.6643637418746948
Validation loss: 1.9108875131094327

Epoch: 6| Step: 2
Training loss: 1.8298959732055664
Validation loss: 1.9686654972773727

Epoch: 6| Step: 3
Training loss: 1.4653899669647217
Validation loss: 1.9432289446553876

Epoch: 6| Step: 4
Training loss: 2.1952688694000244
Validation loss: 1.9405220823903238

Epoch: 6| Step: 5
Training loss: 1.7931067943572998
Validation loss: 1.8972605146387571

Epoch: 6| Step: 6
Training loss: 1.3070735931396484
Validation loss: 1.9072816782100226

Epoch: 6| Step: 7
Training loss: 1.803724765777588
Validation loss: 1.9080881905812088

Epoch: 6| Step: 8
Training loss: 1.4939802885055542
Validation loss: 1.9068362789769326

Epoch: 6| Step: 9
Training loss: 1.5535228252410889
Validation loss: 1.8704814654524609

Epoch: 6| Step: 10
Training loss: 1.7739449739456177
Validation loss: 1.9198589671042658

Epoch: 6| Step: 11
Training loss: 1.5443532466888428
Validation loss: 1.8932209758348362

Epoch: 6| Step: 12
Training loss: 1.9233636856079102
Validation loss: 1.8926213710538802

Epoch: 6| Step: 13
Training loss: 1.764512538909912
Validation loss: 1.9011565344308012

Epoch: 238| Step: 0
Training loss: 1.3944917917251587
Validation loss: 1.8638295165954097

Epoch: 6| Step: 1
Training loss: 1.4203143119812012
Validation loss: 1.9163054189374369

Epoch: 6| Step: 2
Training loss: 2.275758981704712
Validation loss: 1.924140376429404

Epoch: 6| Step: 3
Training loss: 1.415959358215332
Validation loss: 1.8955635639929003

Epoch: 6| Step: 4
Training loss: 1.7831788063049316
Validation loss: 1.8513507714835546

Epoch: 6| Step: 5
Training loss: 2.305457830429077
Validation loss: 1.9013857623582244

Epoch: 6| Step: 6
Training loss: 1.2327814102172852
Validation loss: 1.8800079232902938

Epoch: 6| Step: 7
Training loss: 1.2865653038024902
Validation loss: 1.9289640380490212

Epoch: 6| Step: 8
Training loss: 1.3056831359863281
Validation loss: 1.8883432803615448

Epoch: 6| Step: 9
Training loss: 2.074155807495117
Validation loss: 1.9015507621149863

Epoch: 6| Step: 10
Training loss: 1.9053221940994263
Validation loss: 1.9158225341509747

Epoch: 6| Step: 11
Training loss: 1.909189224243164
Validation loss: 1.9394730137240501

Epoch: 6| Step: 12
Training loss: 1.7014284133911133
Validation loss: 1.8725641671047415

Epoch: 6| Step: 13
Training loss: 2.623697280883789
Validation loss: 1.8933472146270096

Epoch: 239| Step: 0
Training loss: 1.590412974357605
Validation loss: 1.907853062434863

Epoch: 6| Step: 1
Training loss: 1.6943182945251465
Validation loss: 1.9126868863259592

Epoch: 6| Step: 2
Training loss: 1.6187418699264526
Validation loss: 1.9188820931219286

Epoch: 6| Step: 3
Training loss: 1.5651849508285522
Validation loss: 1.9554323932175994

Epoch: 6| Step: 4
Training loss: 1.877514123916626
Validation loss: 1.9736900688499532

Epoch: 6| Step: 5
Training loss: 2.090052604675293
Validation loss: 2.0070715360744025

Epoch: 6| Step: 6
Training loss: 1.7089459896087646
Validation loss: 1.9670832592953917

Epoch: 6| Step: 7
Training loss: 1.5438791513442993
Validation loss: 1.9181591579991002

Epoch: 6| Step: 8
Training loss: 1.922805905342102
Validation loss: 1.9662560891079646

Epoch: 6| Step: 9
Training loss: 2.152366876602173
Validation loss: 1.939145238168778

Epoch: 6| Step: 10
Training loss: 2.147434949874878
Validation loss: 2.0383601111750447

Epoch: 6| Step: 11
Training loss: 1.6937892436981201
Validation loss: 1.929679924441922

Epoch: 6| Step: 12
Training loss: 1.2145745754241943
Validation loss: 1.963597160513683

Epoch: 6| Step: 13
Training loss: 2.0887696743011475
Validation loss: 1.917657979073063

Epoch: 240| Step: 0
Training loss: 0.9948179721832275
Validation loss: 1.9176042772108508

Epoch: 6| Step: 1
Training loss: 1.5024760961532593
Validation loss: 1.8976625678359822

Epoch: 6| Step: 2
Training loss: 2.039241313934326
Validation loss: 1.9074578541581348

Epoch: 6| Step: 3
Training loss: 2.003268003463745
Validation loss: 1.8829712457554315

Epoch: 6| Step: 4
Training loss: 2.6504032611846924
Validation loss: 1.8813930775529595

Epoch: 6| Step: 5
Training loss: 2.1421713829040527
Validation loss: 1.8842322826385498

Epoch: 6| Step: 6
Training loss: 2.307267665863037
Validation loss: 1.9233464605064803

Epoch: 6| Step: 7
Training loss: 1.6751545667648315
Validation loss: 1.9248602697926183

Epoch: 6| Step: 8
Training loss: 0.8757997155189514
Validation loss: 1.857890998163531

Epoch: 6| Step: 9
Training loss: 1.6472183465957642
Validation loss: 1.9128293247633084

Epoch: 6| Step: 10
Training loss: 1.3214995861053467
Validation loss: 1.9245757364457654

Epoch: 6| Step: 11
Training loss: 1.4365754127502441
Validation loss: 1.9227722947315504

Epoch: 6| Step: 12
Training loss: 2.041584014892578
Validation loss: 1.8939117526495328

Epoch: 6| Step: 13
Training loss: 1.6990501880645752
Validation loss: 1.9130688405806018

Epoch: 241| Step: 0
Training loss: 2.5641753673553467
Validation loss: 1.9293377809627081

Epoch: 6| Step: 1
Training loss: 2.300562620162964
Validation loss: 1.8107268758999404

Epoch: 6| Step: 2
Training loss: 1.847499132156372
Validation loss: 1.9256200841678086

Epoch: 6| Step: 3
Training loss: 1.435585379600525
Validation loss: 1.895475435000594

Epoch: 6| Step: 4
Training loss: 2.0202066898345947
Validation loss: 1.8557153491563694

Epoch: 6| Step: 5
Training loss: 2.240224838256836
Validation loss: 1.8872686938572956

Epoch: 6| Step: 6
Training loss: 1.9920156002044678
Validation loss: 1.9030109925936627

Epoch: 6| Step: 7
Training loss: 2.0830397605895996
Validation loss: 1.8858791500009515

Epoch: 6| Step: 8
Training loss: 0.9651584625244141
Validation loss: 1.9257825420748802

Epoch: 6| Step: 9
Training loss: 1.6396465301513672
Validation loss: 1.8721767753683112

Epoch: 6| Step: 10
Training loss: 1.3962335586547852
Validation loss: 1.9040922003407632

Epoch: 6| Step: 11
Training loss: 0.9706807136535645
Validation loss: 1.9162195395397883

Epoch: 6| Step: 12
Training loss: 1.7226394414901733
Validation loss: 1.8975732147052724

Epoch: 6| Step: 13
Training loss: 0.6973727345466614
Validation loss: 1.9077481864601054

Epoch: 242| Step: 0
Training loss: 1.7018272876739502
Validation loss: 1.9714953207200574

Epoch: 6| Step: 1
Training loss: 1.2573020458221436
Validation loss: 1.9285073472607521

Epoch: 6| Step: 2
Training loss: 1.8436200618743896
Validation loss: 1.908432775928128

Epoch: 6| Step: 3
Training loss: 1.6668524742126465
Validation loss: 1.876414559220755

Epoch: 6| Step: 4
Training loss: 1.4903366565704346
Validation loss: 1.8233696299214517

Epoch: 6| Step: 5
Training loss: 2.200637102127075
Validation loss: 1.8958310183658396

Epoch: 6| Step: 6
Training loss: 2.2992677688598633
Validation loss: 1.9043681224187214

Epoch: 6| Step: 7
Training loss: 1.3789668083190918
Validation loss: 1.8928887690267255

Epoch: 6| Step: 8
Training loss: 1.1796889305114746
Validation loss: 1.9010373251412505

Epoch: 6| Step: 9
Training loss: 2.18609619140625
Validation loss: 1.9068392079363587

Epoch: 6| Step: 10
Training loss: 1.4934887886047363
Validation loss: 1.9192783563367781

Epoch: 6| Step: 11
Training loss: 1.5226281881332397
Validation loss: 1.8934653036056026

Epoch: 6| Step: 12
Training loss: 1.8804688453674316
Validation loss: 1.8880694438052434

Epoch: 6| Step: 13
Training loss: 2.1671254634857178
Validation loss: 1.8775578314258206

Epoch: 243| Step: 0
Training loss: 1.3468222618103027
Validation loss: 1.9191686632812663

Epoch: 6| Step: 1
Training loss: 2.011805295944214
Validation loss: 1.8614423582630772

Epoch: 6| Step: 2
Training loss: 1.7727056741714478
Validation loss: 1.9455168965042278

Epoch: 6| Step: 3
Training loss: 1.6851714849472046
Validation loss: 1.962548291811379

Epoch: 6| Step: 4
Training loss: 1.7769252061843872
Validation loss: 1.926685102524296

Epoch: 6| Step: 5
Training loss: 1.5765459537506104
Validation loss: 1.9307699049672773

Epoch: 6| Step: 6
Training loss: 1.8481972217559814
Validation loss: 1.9230732828058221

Epoch: 6| Step: 7
Training loss: 2.029607057571411
Validation loss: 1.9554880985649683

Epoch: 6| Step: 8
Training loss: 1.8235679864883423
Validation loss: 1.911075266458655

Epoch: 6| Step: 9
Training loss: 2.173319101333618
Validation loss: 1.923347439817203

Epoch: 6| Step: 10
Training loss: 1.8010202646255493
Validation loss: 1.8717739120606454

Epoch: 6| Step: 11
Training loss: 2.2057180404663086
Validation loss: 1.9240114304327196

Epoch: 6| Step: 12
Training loss: 1.314788579940796
Validation loss: 1.8973035479104647

Epoch: 6| Step: 13
Training loss: 0.599418580532074
Validation loss: 1.9221578464713147

Epoch: 244| Step: 0
Training loss: 2.2286994457244873
Validation loss: 1.9101562128272107

Epoch: 6| Step: 1
Training loss: 1.3794536590576172
Validation loss: 1.8631732771473546

Epoch: 6| Step: 2
Training loss: 1.5888996124267578
Validation loss: 1.9091220260948263

Epoch: 6| Step: 3
Training loss: 1.677767276763916
Validation loss: 1.873208535614834

Epoch: 6| Step: 4
Training loss: 1.974884271621704
Validation loss: 1.8849162478600778

Epoch: 6| Step: 5
Training loss: 1.5627650022506714
Validation loss: 1.9015194921083347

Epoch: 6| Step: 6
Training loss: 1.642290711402893
Validation loss: 1.8857227602312643

Epoch: 6| Step: 7
Training loss: 2.099114179611206
Validation loss: 1.9039428862192298

Epoch: 6| Step: 8
Training loss: 2.228084087371826
Validation loss: 1.791292828257366

Epoch: 6| Step: 9
Training loss: 0.9991952180862427
Validation loss: 1.9080536814146145

Epoch: 6| Step: 10
Training loss: 2.204308032989502
Validation loss: 1.8423682797339656

Epoch: 6| Step: 11
Training loss: 2.1952672004699707
Validation loss: 1.918474587061072

Epoch: 6| Step: 12
Training loss: 1.211911678314209
Validation loss: 1.8651033550180414

Epoch: 6| Step: 13
Training loss: 1.4352688789367676
Validation loss: 1.8641704256816576

Epoch: 245| Step: 0
Training loss: 2.2253623008728027
Validation loss: 1.8708100344545098

Epoch: 6| Step: 1
Training loss: 0.9762884974479675
Validation loss: 1.8519940607009395

Epoch: 6| Step: 2
Training loss: 1.4607858657836914
Validation loss: 1.8575673667333459

Epoch: 6| Step: 3
Training loss: 1.9142611026763916
Validation loss: 1.8770337079160957

Epoch: 6| Step: 4
Training loss: 1.505739688873291
Validation loss: 1.8954509919689548

Epoch: 6| Step: 5
Training loss: 1.995383858680725
Validation loss: 1.9175192745782996

Epoch: 6| Step: 6
Training loss: 1.627555251121521
Validation loss: 1.9187944935214134

Epoch: 6| Step: 7
Training loss: 2.0369863510131836
Validation loss: 1.9121686207350863

Epoch: 6| Step: 8
Training loss: 1.3643457889556885
Validation loss: 1.8703635302923058

Epoch: 6| Step: 9
Training loss: 1.500410795211792
Validation loss: 1.93915940612875

Epoch: 6| Step: 10
Training loss: 1.6365808248519897
Validation loss: 1.8363874548224992

Epoch: 6| Step: 11
Training loss: 1.6916463375091553
Validation loss: 1.86295489598346

Epoch: 6| Step: 12
Training loss: 1.9262573719024658
Validation loss: 1.902821228068362

Epoch: 6| Step: 13
Training loss: 2.1619834899902344
Validation loss: 1.9013800044213571

Epoch: 246| Step: 0
Training loss: 1.985616683959961
Validation loss: 1.9146278583875267

Epoch: 6| Step: 1
Training loss: 1.0098254680633545
Validation loss: 1.922066653928449

Epoch: 6| Step: 2
Training loss: 1.229758858680725
Validation loss: 1.8680130871393348

Epoch: 6| Step: 3
Training loss: 1.462270975112915
Validation loss: 1.8597186316726029

Epoch: 6| Step: 4
Training loss: 1.7203752994537354
Validation loss: 1.9226536853339082

Epoch: 6| Step: 5
Training loss: 2.0385568141937256
Validation loss: 1.937113118428056

Epoch: 6| Step: 6
Training loss: 2.087111234664917
Validation loss: 1.9046620348448395

Epoch: 6| Step: 7
Training loss: 1.9279019832611084
Validation loss: 1.8706119573244484

Epoch: 6| Step: 8
Training loss: 2.4280893802642822
Validation loss: 1.8965772326274584

Epoch: 6| Step: 9
Training loss: 1.4393157958984375
Validation loss: 1.9318577063980924

Epoch: 6| Step: 10
Training loss: 1.4211238622665405
Validation loss: 1.8797025501087148

Epoch: 6| Step: 11
Training loss: 2.2599852085113525
Validation loss: 1.9464926642756308

Epoch: 6| Step: 12
Training loss: 1.602026104927063
Validation loss: 1.8805893364773

Epoch: 6| Step: 13
Training loss: 0.7002323269844055
Validation loss: 1.8774831282195223

Epoch: 247| Step: 0
Training loss: 1.725903868675232
Validation loss: 1.9374916117678407

Epoch: 6| Step: 1
Training loss: 1.6279326677322388
Validation loss: 1.915112458249574

Epoch: 6| Step: 2
Training loss: 1.8609423637390137
Validation loss: 1.8767377253501647

Epoch: 6| Step: 3
Training loss: 2.1019887924194336
Validation loss: 1.8477899887228524

Epoch: 6| Step: 4
Training loss: 1.9196271896362305
Validation loss: 1.870174942478057

Epoch: 6| Step: 5
Training loss: 1.53840970993042
Validation loss: 1.9311606871184481

Epoch: 6| Step: 6
Training loss: 1.7325620651245117
Validation loss: 1.8784961110802108

Epoch: 6| Step: 7
Training loss: 1.3965909481048584
Validation loss: 1.8681469040532266

Epoch: 6| Step: 8
Training loss: 1.1257539987564087
Validation loss: 1.8685510094447801

Epoch: 6| Step: 9
Training loss: 1.815206527709961
Validation loss: 1.8763275889940159

Epoch: 6| Step: 10
Training loss: 1.3541836738586426
Validation loss: 1.8991413142091484

Epoch: 6| Step: 11
Training loss: 2.0255274772644043
Validation loss: 1.895266379079511

Epoch: 6| Step: 12
Training loss: 1.9617007970809937
Validation loss: 1.8984102587546072

Epoch: 6| Step: 13
Training loss: 1.2984733581542969
Validation loss: 1.9090874746281614

Epoch: 248| Step: 0
Training loss: 1.6288113594055176
Validation loss: 1.8985837198072864

Epoch: 6| Step: 1
Training loss: 1.5777337551116943
Validation loss: 1.847853027364259

Epoch: 6| Step: 2
Training loss: 1.6194840669631958
Validation loss: 1.8892315613326205

Epoch: 6| Step: 3
Training loss: 1.774848222732544
Validation loss: 1.8443149046231342

Epoch: 6| Step: 4
Training loss: 1.4795637130737305
Validation loss: 1.9294342135870328

Epoch: 6| Step: 5
Training loss: 1.3842008113861084
Validation loss: 1.8925813263462437

Epoch: 6| Step: 6
Training loss: 2.3912010192871094
Validation loss: 1.8660688451541367

Epoch: 6| Step: 7
Training loss: 1.5569394826889038
Validation loss: 1.8727872807492492

Epoch: 6| Step: 8
Training loss: 1.6351022720336914
Validation loss: 1.9011555384564143

Epoch: 6| Step: 9
Training loss: 0.9798315167427063
Validation loss: 1.9053759856890606

Epoch: 6| Step: 10
Training loss: 2.1258668899536133
Validation loss: 1.9114229345834384

Epoch: 6| Step: 11
Training loss: 2.600980758666992
Validation loss: 1.873325106918171

Epoch: 6| Step: 12
Training loss: 1.3010104894638062
Validation loss: 1.9048317632367533

Epoch: 6| Step: 13
Training loss: 2.093449592590332
Validation loss: 1.9230493063567786

Epoch: 249| Step: 0
Training loss: 1.9419875144958496
Validation loss: 1.8934432562961374

Epoch: 6| Step: 1
Training loss: 1.941490650177002
Validation loss: 1.840025495457393

Epoch: 6| Step: 2
Training loss: 1.3231477737426758
Validation loss: 1.8450617046766384

Epoch: 6| Step: 3
Training loss: 1.122957706451416
Validation loss: 1.875068852978368

Epoch: 6| Step: 4
Training loss: 2.220309257507324
Validation loss: 1.8347702103276406

Epoch: 6| Step: 5
Training loss: 1.6820168495178223
Validation loss: 1.8745747484186643

Epoch: 6| Step: 6
Training loss: 1.6807520389556885
Validation loss: 1.837379313284351

Epoch: 6| Step: 7
Training loss: 1.9460729360580444
Validation loss: 1.8611230798946914

Epoch: 6| Step: 8
Training loss: 1.5399491786956787
Validation loss: 1.859240283248245

Epoch: 6| Step: 9
Training loss: 1.5831208229064941
Validation loss: 1.838911691019612

Epoch: 6| Step: 10
Training loss: 1.8862676620483398
Validation loss: 1.8819410826570244

Epoch: 6| Step: 11
Training loss: 1.9362190961837769
Validation loss: 1.8893969546082199

Epoch: 6| Step: 12
Training loss: 2.0430941581726074
Validation loss: 1.8743745883305867

Epoch: 6| Step: 13
Training loss: 1.766701340675354
Validation loss: 1.8375128648614372

Epoch: 250| Step: 0
Training loss: 1.754695177078247
Validation loss: 1.8670382691967873

Epoch: 6| Step: 1
Training loss: 1.931400179862976
Validation loss: 1.896959279173164

Epoch: 6| Step: 2
Training loss: 1.8526694774627686
Validation loss: 1.859349859658108

Epoch: 6| Step: 3
Training loss: 1.7957683801651
Validation loss: 1.9395790997371878

Epoch: 6| Step: 4
Training loss: 1.7713698148727417
Validation loss: 1.9492007481154574

Epoch: 6| Step: 5
Training loss: 1.5491714477539062
Validation loss: 1.8721676693167737

Epoch: 6| Step: 6
Training loss: 1.836135983467102
Validation loss: 1.968217933049766

Epoch: 6| Step: 7
Training loss: 1.7228672504425049
Validation loss: 1.9421042844813357

Epoch: 6| Step: 8
Training loss: 1.5443909168243408
Validation loss: 1.8857085461257606

Epoch: 6| Step: 9
Training loss: 1.3227107524871826
Validation loss: 1.880150039990743

Epoch: 6| Step: 10
Training loss: 1.9359610080718994
Validation loss: 1.918060992353706

Epoch: 6| Step: 11
Training loss: 2.365952730178833
Validation loss: 1.9132047327615882

Epoch: 6| Step: 12
Training loss: 0.8508778214454651
Validation loss: 1.9542209486807547

Epoch: 6| Step: 13
Training loss: 1.9103559255599976
Validation loss: 1.8793910023986653

Epoch: 251| Step: 0
Training loss: 1.860903024673462
Validation loss: 1.9032720981105682

Epoch: 6| Step: 1
Training loss: 1.3189141750335693
Validation loss: 1.9130024345972205

Epoch: 6| Step: 2
Training loss: 1.1781805753707886
Validation loss: 1.9241792053304694

Epoch: 6| Step: 3
Training loss: 1.9426525831222534
Validation loss: 1.9124554869949177

Epoch: 6| Step: 4
Training loss: 1.4788745641708374
Validation loss: 1.864552249190628

Epoch: 6| Step: 5
Training loss: 1.7323769330978394
Validation loss: 1.9014622524220457

Epoch: 6| Step: 6
Training loss: 2.271365165710449
Validation loss: 1.8663279548768075

Epoch: 6| Step: 7
Training loss: 1.4659290313720703
Validation loss: 1.8670095077124975

Epoch: 6| Step: 8
Training loss: 1.7974380254745483
Validation loss: 1.8746783156548776

Epoch: 6| Step: 9
Training loss: 2.1041617393493652
Validation loss: 1.8748769785768242

Epoch: 6| Step: 10
Training loss: 1.704817771911621
Validation loss: 1.8430774186247139

Epoch: 6| Step: 11
Training loss: 1.4258239269256592
Validation loss: 1.8587938688134635

Epoch: 6| Step: 12
Training loss: 1.5826164484024048
Validation loss: 1.8361926719706545

Epoch: 6| Step: 13
Training loss: 1.9561574459075928
Validation loss: 1.854642222004552

Epoch: 252| Step: 0
Training loss: 2.2627859115600586
Validation loss: 1.8514193206705072

Epoch: 6| Step: 1
Training loss: 1.5701305866241455
Validation loss: 1.8519865453884166

Epoch: 6| Step: 2
Training loss: 1.5881600379943848
Validation loss: 1.826808678206577

Epoch: 6| Step: 3
Training loss: 1.7189300060272217
Validation loss: 1.853186304851245

Epoch: 6| Step: 4
Training loss: 1.526790738105774
Validation loss: 1.8784667471403718

Epoch: 6| Step: 5
Training loss: 1.172743558883667
Validation loss: 1.8625200589497883

Epoch: 6| Step: 6
Training loss: 1.6693682670593262
Validation loss: 1.9100324184663835

Epoch: 6| Step: 7
Training loss: 1.7215380668640137
Validation loss: 1.92293430015605

Epoch: 6| Step: 8
Training loss: 1.628835916519165
Validation loss: 1.874391294294788

Epoch: 6| Step: 9
Training loss: 1.3706361055374146
Validation loss: 1.9198382182787823

Epoch: 6| Step: 10
Training loss: 1.2501955032348633
Validation loss: 1.872249690435266

Epoch: 6| Step: 11
Training loss: 2.3927369117736816
Validation loss: 1.9304680337188065

Epoch: 6| Step: 12
Training loss: 1.7380836009979248
Validation loss: 1.93013043813808

Epoch: 6| Step: 13
Training loss: 1.6364825963974
Validation loss: 1.874468913642309

Epoch: 253| Step: 0
Training loss: 1.9536021947860718
Validation loss: 1.8685307387382752

Epoch: 6| Step: 1
Training loss: 1.822428822517395
Validation loss: 1.9109634814723846

Epoch: 6| Step: 2
Training loss: 1.7502925395965576
Validation loss: 1.8250961854893675

Epoch: 6| Step: 3
Training loss: 0.6979823112487793
Validation loss: 1.8700988920786048

Epoch: 6| Step: 4
Training loss: 1.490190863609314
Validation loss: 1.8832001416913924

Epoch: 6| Step: 5
Training loss: 2.1709539890289307
Validation loss: 1.866311138676059

Epoch: 6| Step: 6
Training loss: 1.6643633842468262
Validation loss: 1.856630168935304

Epoch: 6| Step: 7
Training loss: 1.8675537109375
Validation loss: 1.8656905966420327

Epoch: 6| Step: 8
Training loss: 1.9416120052337646
Validation loss: 1.9005424514893563

Epoch: 6| Step: 9
Training loss: 1.580955147743225
Validation loss: 1.8800898367358791

Epoch: 6| Step: 10
Training loss: 1.7241514921188354
Validation loss: 1.8480979524632937

Epoch: 6| Step: 11
Training loss: 1.1433435678482056
Validation loss: 1.8996593477905437

Epoch: 6| Step: 12
Training loss: 2.1158969402313232
Validation loss: 1.849263111750285

Epoch: 6| Step: 13
Training loss: 1.9518170356750488
Validation loss: 1.8730020497434883

Epoch: 254| Step: 0
Training loss: 1.8464500904083252
Validation loss: 1.9172944689309726

Epoch: 6| Step: 1
Training loss: 1.704948902130127
Validation loss: 1.8637912568225656

Epoch: 6| Step: 2
Training loss: 1.7347567081451416
Validation loss: 1.888529646781183

Epoch: 6| Step: 3
Training loss: 1.1303222179412842
Validation loss: 1.9009968234646706

Epoch: 6| Step: 4
Training loss: 1.901451826095581
Validation loss: 1.8848201997818486

Epoch: 6| Step: 5
Training loss: 2.5786993503570557
Validation loss: 1.8849741066655805

Epoch: 6| Step: 6
Training loss: 1.162191390991211
Validation loss: 1.866043229256907

Epoch: 6| Step: 7
Training loss: 1.3958407640457153
Validation loss: 1.8666312322821668

Epoch: 6| Step: 8
Training loss: 2.250727415084839
Validation loss: 1.8742930568674558

Epoch: 6| Step: 9
Training loss: 1.5961859226226807
Validation loss: 1.914937339803224

Epoch: 6| Step: 10
Training loss: 1.1133620738983154
Validation loss: 1.8887499840028825

Epoch: 6| Step: 11
Training loss: 1.3308048248291016
Validation loss: 1.8688766597419657

Epoch: 6| Step: 12
Training loss: 2.0724329948425293
Validation loss: 1.8796638942533923

Epoch: 6| Step: 13
Training loss: 1.6718134880065918
Validation loss: 1.857296161754157

Epoch: 255| Step: 0
Training loss: 2.238919734954834
Validation loss: 1.8694703348221318

Epoch: 6| Step: 1
Training loss: 2.154883861541748
Validation loss: 1.944607848762184

Epoch: 6| Step: 2
Training loss: 1.4425420761108398
Validation loss: 1.8671479725068616

Epoch: 6| Step: 3
Training loss: 1.620638132095337
Validation loss: 1.9020485454990017

Epoch: 6| Step: 4
Training loss: 1.8832694292068481
Validation loss: 1.8465498109017648

Epoch: 6| Step: 5
Training loss: 1.0690587759017944
Validation loss: 1.8573018248363207

Epoch: 6| Step: 6
Training loss: 1.121315836906433
Validation loss: 1.8755604913157802

Epoch: 6| Step: 7
Training loss: 1.79015052318573
Validation loss: 1.8592058817545574

Epoch: 6| Step: 8
Training loss: 1.786132574081421
Validation loss: 1.8538767881290887

Epoch: 6| Step: 9
Training loss: 1.266765832901001
Validation loss: 1.868013943395307

Epoch: 6| Step: 10
Training loss: 1.3909330368041992
Validation loss: 1.7944849883356402

Epoch: 6| Step: 11
Training loss: 1.6899189949035645
Validation loss: 1.853396624647161

Epoch: 6| Step: 12
Training loss: 2.0236403942108154
Validation loss: 1.9050552281000281

Epoch: 6| Step: 13
Training loss: 1.9819378852844238
Validation loss: 1.8988209578298754

Epoch: 256| Step: 0
Training loss: 1.628204345703125
Validation loss: 1.9096601393914991

Epoch: 6| Step: 1
Training loss: 2.511500835418701
Validation loss: 1.8860776924317884

Epoch: 6| Step: 2
Training loss: 1.9068081378936768
Validation loss: 1.871830391627486

Epoch: 6| Step: 3
Training loss: 2.100691556930542
Validation loss: 1.9086077572197042

Epoch: 6| Step: 4
Training loss: 1.0279583930969238
Validation loss: 1.8618421862202306

Epoch: 6| Step: 5
Training loss: 1.8696532249450684
Validation loss: 1.8870427467489754

Epoch: 6| Step: 6
Training loss: 1.4918434619903564
Validation loss: 1.9344126857737058

Epoch: 6| Step: 7
Training loss: 1.7922999858856201
Validation loss: 1.9115982094118673

Epoch: 6| Step: 8
Training loss: 1.028509259223938
Validation loss: 1.9052494956601052

Epoch: 6| Step: 9
Training loss: 1.5318678617477417
Validation loss: 1.846202145340622

Epoch: 6| Step: 10
Training loss: 1.7846136093139648
Validation loss: 1.8522173717457762

Epoch: 6| Step: 11
Training loss: 1.279375433921814
Validation loss: 1.8702586581630092

Epoch: 6| Step: 12
Training loss: 1.5834085941314697
Validation loss: 1.9309480856823664

Epoch: 6| Step: 13
Training loss: 1.6905772686004639
Validation loss: 1.8627633356278943

Epoch: 257| Step: 0
Training loss: 1.367161512374878
Validation loss: 1.8732192465054092

Epoch: 6| Step: 1
Training loss: 1.6533490419387817
Validation loss: 1.8919145138032976

Epoch: 6| Step: 2
Training loss: 1.8283780813217163
Validation loss: 1.8944327369812997

Epoch: 6| Step: 3
Training loss: 1.8047764301300049
Validation loss: 1.884149835955712

Epoch: 6| Step: 4
Training loss: 1.6819531917572021
Validation loss: 1.8548088509549376

Epoch: 6| Step: 5
Training loss: 1.3044872283935547
Validation loss: 1.909921997336931

Epoch: 6| Step: 6
Training loss: 1.2919249534606934
Validation loss: 1.9016564687093098

Epoch: 6| Step: 7
Training loss: 2.188109874725342
Validation loss: 1.878372193664633

Epoch: 6| Step: 8
Training loss: 2.2130556106567383
Validation loss: 1.8709426156936153

Epoch: 6| Step: 9
Training loss: 1.3265509605407715
Validation loss: 1.8519447029277842

Epoch: 6| Step: 10
Training loss: 2.010863780975342
Validation loss: 1.8855124109534807

Epoch: 6| Step: 11
Training loss: 1.5346400737762451
Validation loss: 1.8663224033130112

Epoch: 6| Step: 12
Training loss: 1.7626228332519531
Validation loss: 1.8111603862495833

Epoch: 6| Step: 13
Training loss: 1.984925389289856
Validation loss: 1.8586934689552552

Epoch: 258| Step: 0
Training loss: 1.554518461227417
Validation loss: 1.8629746206345097

Epoch: 6| Step: 1
Training loss: 1.1451935768127441
Validation loss: 1.872753853439003

Epoch: 6| Step: 2
Training loss: 1.9544477462768555
Validation loss: 1.828943032090382

Epoch: 6| Step: 3
Training loss: 1.5413349866867065
Validation loss: 1.8533582392559256

Epoch: 6| Step: 4
Training loss: 1.7357451915740967
Validation loss: 1.8463338472509896

Epoch: 6| Step: 5
Training loss: 1.848712682723999
Validation loss: 1.8382264183413597

Epoch: 6| Step: 6
Training loss: 0.9589185118675232
Validation loss: 1.8789006125542425

Epoch: 6| Step: 7
Training loss: 1.500361680984497
Validation loss: 1.8435743175527102

Epoch: 6| Step: 8
Training loss: 1.6478959321975708
Validation loss: 1.86935987523807

Epoch: 6| Step: 9
Training loss: 2.406808376312256
Validation loss: 1.8720918906632291

Epoch: 6| Step: 10
Training loss: 2.1340737342834473
Validation loss: 1.914753242205548

Epoch: 6| Step: 11
Training loss: 1.0170601606369019
Validation loss: 1.8723689112611996

Epoch: 6| Step: 12
Training loss: 2.1236865520477295
Validation loss: 1.8691959419558126

Epoch: 6| Step: 13
Training loss: 2.654944896697998
Validation loss: 1.8802570296872048

Epoch: 259| Step: 0
Training loss: 2.0014424324035645
Validation loss: 1.8993126410309986

Epoch: 6| Step: 1
Training loss: 1.6061656475067139
Validation loss: 1.8983692405044392

Epoch: 6| Step: 2
Training loss: 1.3404433727264404
Validation loss: 1.8808898733508201

Epoch: 6| Step: 3
Training loss: 1.5285344123840332
Validation loss: 1.8683998828293176

Epoch: 6| Step: 4
Training loss: 1.5065293312072754
Validation loss: 1.8320008964948757

Epoch: 6| Step: 5
Training loss: 1.3005558252334595
Validation loss: 1.8555214584514659

Epoch: 6| Step: 6
Training loss: 1.3586751222610474
Validation loss: 1.8451888817612843

Epoch: 6| Step: 7
Training loss: 2.423285722732544
Validation loss: 1.8730230677512385

Epoch: 6| Step: 8
Training loss: 2.076723337173462
Validation loss: 1.8457814711396412

Epoch: 6| Step: 9
Training loss: 1.2422282695770264
Validation loss: 1.9093240909678961

Epoch: 6| Step: 10
Training loss: 2.0122787952423096
Validation loss: 1.853027582168579

Epoch: 6| Step: 11
Training loss: 1.5498242378234863
Validation loss: 1.8748564797063028

Epoch: 6| Step: 12
Training loss: 1.9978774785995483
Validation loss: 1.877605527959844

Epoch: 6| Step: 13
Training loss: 1.236430048942566
Validation loss: 1.88133063239436

Epoch: 260| Step: 0
Training loss: 1.694512128829956
Validation loss: 1.8850669783930625

Epoch: 6| Step: 1
Training loss: 1.9798035621643066
Validation loss: 1.9222678702364686

Epoch: 6| Step: 2
Training loss: 1.8674910068511963
Validation loss: 1.8631129457104592

Epoch: 6| Step: 3
Training loss: 2.285088062286377
Validation loss: 1.9016441683615408

Epoch: 6| Step: 4
Training loss: 1.7176342010498047
Validation loss: 1.8724827971509708

Epoch: 6| Step: 5
Training loss: 1.264626145362854
Validation loss: 1.8740593976871942

Epoch: 6| Step: 6
Training loss: 1.6230108737945557
Validation loss: 1.8642678106984785

Epoch: 6| Step: 7
Training loss: 1.521501064300537
Validation loss: 1.8521628623367639

Epoch: 6| Step: 8
Training loss: 1.9962306022644043
Validation loss: 1.8570384133246638

Epoch: 6| Step: 9
Training loss: 1.1791517734527588
Validation loss: 1.9131804204756213

Epoch: 6| Step: 10
Training loss: 1.5006492137908936
Validation loss: 1.8532683695516279

Epoch: 6| Step: 11
Training loss: 1.6461992263793945
Validation loss: 1.8716026941935222

Epoch: 6| Step: 12
Training loss: 1.9037036895751953
Validation loss: 1.8727876729862665

Epoch: 6| Step: 13
Training loss: 1.093072772026062
Validation loss: 1.8578236000512236

Epoch: 261| Step: 0
Training loss: 1.493608832359314
Validation loss: 1.868396774415047

Epoch: 6| Step: 1
Training loss: 1.4614453315734863
Validation loss: 1.8712460161537252

Epoch: 6| Step: 2
Training loss: 1.022110939025879
Validation loss: 1.8313920446621474

Epoch: 6| Step: 3
Training loss: 1.8054358959197998
Validation loss: 1.8478746760276057

Epoch: 6| Step: 4
Training loss: 1.5307039022445679
Validation loss: 1.864184300104777

Epoch: 6| Step: 5
Training loss: 1.803345799446106
Validation loss: 1.8933559374142719

Epoch: 6| Step: 6
Training loss: 1.599267601966858
Validation loss: 1.9047859958423081

Epoch: 6| Step: 7
Training loss: 1.8480186462402344
Validation loss: 1.8384382288943055

Epoch: 6| Step: 8
Training loss: 2.1803102493286133
Validation loss: 1.8682814503228793

Epoch: 6| Step: 9
Training loss: 1.550373911857605
Validation loss: 1.8729378972002255

Epoch: 6| Step: 10
Training loss: 1.8769550323486328
Validation loss: 1.8960098887002597

Epoch: 6| Step: 11
Training loss: 2.1062755584716797
Validation loss: 1.880058087328429

Epoch: 6| Step: 12
Training loss: 1.5509798526763916
Validation loss: 1.850230905317491

Epoch: 6| Step: 13
Training loss: 1.1960620880126953
Validation loss: 1.8360851580096829

Epoch: 262| Step: 0
Training loss: 1.6206810474395752
Validation loss: 1.8532049579005088

Epoch: 6| Step: 1
Training loss: 1.536949634552002
Validation loss: 1.7860599102512482

Epoch: 6| Step: 2
Training loss: 1.2529973983764648
Validation loss: 1.895978493075217

Epoch: 6| Step: 3
Training loss: 1.1970546245574951
Validation loss: 1.8442031593732937

Epoch: 6| Step: 4
Training loss: 2.2869861125946045
Validation loss: 1.8973109004318074

Epoch: 6| Step: 5
Training loss: 1.2371976375579834
Validation loss: 1.874693150161415

Epoch: 6| Step: 6
Training loss: 1.5078651905059814
Validation loss: 1.9195200884214012

Epoch: 6| Step: 7
Training loss: 2.3297338485717773
Validation loss: 1.8930917273285568

Epoch: 6| Step: 8
Training loss: 1.4984009265899658
Validation loss: 1.9428603405593543

Epoch: 6| Step: 9
Training loss: 1.375960111618042
Validation loss: 1.9043702079403786

Epoch: 6| Step: 10
Training loss: 1.7553507089614868
Validation loss: 1.8954886159589213

Epoch: 6| Step: 11
Training loss: 1.5641744136810303
Validation loss: 1.8591891091356996

Epoch: 6| Step: 12
Training loss: 1.9112918376922607
Validation loss: 1.8951291256053473

Epoch: 6| Step: 13
Training loss: 2.405575752258301
Validation loss: 1.8795040371597453

Epoch: 263| Step: 0
Training loss: 2.4169998168945312
Validation loss: 1.8149200190779984

Epoch: 6| Step: 1
Training loss: 1.2172907590866089
Validation loss: 1.8378191071171914

Epoch: 6| Step: 2
Training loss: 1.8145346641540527
Validation loss: 1.870864470799764

Epoch: 6| Step: 3
Training loss: 1.779733657836914
Validation loss: 1.804001949166739

Epoch: 6| Step: 4
Training loss: 2.0352959632873535
Validation loss: 1.8584610287861159

Epoch: 6| Step: 5
Training loss: 1.1963131427764893
Validation loss: 1.8815553995870775

Epoch: 6| Step: 6
Training loss: 1.7612634897232056
Validation loss: 1.8784348605781473

Epoch: 6| Step: 7
Training loss: 1.7935431003570557
Validation loss: 1.8875645617003083

Epoch: 6| Step: 8
Training loss: 1.4382927417755127
Validation loss: 1.9358146985371907

Epoch: 6| Step: 9
Training loss: 1.3892321586608887
Validation loss: 1.8913621312828475

Epoch: 6| Step: 10
Training loss: 1.3153791427612305
Validation loss: 1.8307598995906051

Epoch: 6| Step: 11
Training loss: 2.0198211669921875
Validation loss: 1.8891192597727622

Epoch: 6| Step: 12
Training loss: 1.184862732887268
Validation loss: 1.8878079524604223

Epoch: 6| Step: 13
Training loss: 1.3027175664901733
Validation loss: 1.8696079202877578

Epoch: 264| Step: 0
Training loss: 1.1177570819854736
Validation loss: 1.8486574055046163

Epoch: 6| Step: 1
Training loss: 1.3585726022720337
Validation loss: 1.8618122255930336

Epoch: 6| Step: 2
Training loss: 1.52190363407135
Validation loss: 1.8487371398556618

Epoch: 6| Step: 3
Training loss: 1.2937607765197754
Validation loss: 1.8633783222526632

Epoch: 6| Step: 4
Training loss: 1.439582347869873
Validation loss: 1.8860077268333846

Epoch: 6| Step: 5
Training loss: 1.7855000495910645
Validation loss: 1.8772098787369267

Epoch: 6| Step: 6
Training loss: 2.2043113708496094
Validation loss: 1.8759574300499373

Epoch: 6| Step: 7
Training loss: 3.431148052215576
Validation loss: 1.8639543812762025

Epoch: 6| Step: 8
Training loss: 1.222150444984436
Validation loss: 1.811402343934582

Epoch: 6| Step: 9
Training loss: 1.897494912147522
Validation loss: 1.845969715426045

Epoch: 6| Step: 10
Training loss: 1.2471199035644531
Validation loss: 1.8319403971395185

Epoch: 6| Step: 11
Training loss: 1.7206311225891113
Validation loss: 1.8614786260871476

Epoch: 6| Step: 12
Training loss: 1.7456074953079224
Validation loss: 1.8152550548635504

Epoch: 6| Step: 13
Training loss: 1.5588289499282837
Validation loss: 1.8815982123856902

Epoch: 265| Step: 0
Training loss: 1.4861472845077515
Validation loss: 1.8359996375217233

Epoch: 6| Step: 1
Training loss: 1.6369013786315918
Validation loss: 1.895812475553123

Epoch: 6| Step: 2
Training loss: 2.1987767219543457
Validation loss: 1.86352288979356

Epoch: 6| Step: 3
Training loss: 2.347555637359619
Validation loss: 1.9229981360896942

Epoch: 6| Step: 4
Training loss: 1.564450979232788
Validation loss: 1.902738392993968

Epoch: 6| Step: 5
Training loss: 1.6289758682250977
Validation loss: 1.944223000157264

Epoch: 6| Step: 6
Training loss: 1.381934404373169
Validation loss: 1.9250364431770899

Epoch: 6| Step: 7
Training loss: 2.031571626663208
Validation loss: 2.0114570599730297

Epoch: 6| Step: 8
Training loss: 1.3932336568832397
Validation loss: 1.9503978144737981

Epoch: 6| Step: 9
Training loss: 1.4776661396026611
Validation loss: 1.95194274122997

Epoch: 6| Step: 10
Training loss: 1.2375837564468384
Validation loss: 1.935095937021317

Epoch: 6| Step: 11
Training loss: 1.7183356285095215
Validation loss: 1.8767793088830926

Epoch: 6| Step: 12
Training loss: 1.9687883853912354
Validation loss: 1.9472206843796598

Epoch: 6| Step: 13
Training loss: 1.5137419700622559
Validation loss: 1.909560171506738

Epoch: 266| Step: 0
Training loss: 1.6162161827087402
Validation loss: 1.8732604313922185

Epoch: 6| Step: 1
Training loss: 2.545989513397217
Validation loss: 1.8985070310613161

Epoch: 6| Step: 2
Training loss: 1.5893583297729492
Validation loss: 1.844094132864347

Epoch: 6| Step: 3
Training loss: 0.9740060567855835
Validation loss: 1.857779860496521

Epoch: 6| Step: 4
Training loss: 0.5896406173706055
Validation loss: 1.8582096022944297

Epoch: 6| Step: 5
Training loss: 2.3201448917388916
Validation loss: 1.8547304291878977

Epoch: 6| Step: 6
Training loss: 1.6463086605072021
Validation loss: 1.837239824315553

Epoch: 6| Step: 7
Training loss: 1.414177417755127
Validation loss: 1.9060797255526307

Epoch: 6| Step: 8
Training loss: 1.779672384262085
Validation loss: 1.8428231721283288

Epoch: 6| Step: 9
Training loss: 2.0268893241882324
Validation loss: 1.8644816157638386

Epoch: 6| Step: 10
Training loss: 1.834869384765625
Validation loss: 1.8293492935037101

Epoch: 6| Step: 11
Training loss: 1.8047680854797363
Validation loss: 1.8269613404427805

Epoch: 6| Step: 12
Training loss: 1.5927982330322266
Validation loss: 1.8501009172008884

Epoch: 6| Step: 13
Training loss: 2.1215202808380127
Validation loss: 1.8596121931588778

Epoch: 267| Step: 0
Training loss: 1.4485714435577393
Validation loss: 1.8844369175613567

Epoch: 6| Step: 1
Training loss: 1.247905969619751
Validation loss: 1.8832542011814732

Epoch: 6| Step: 2
Training loss: 1.6640288829803467
Validation loss: 1.8801826610360095

Epoch: 6| Step: 3
Training loss: 1.8802945613861084
Validation loss: 1.931612322407384

Epoch: 6| Step: 4
Training loss: 1.6681528091430664
Validation loss: 1.868706759586129

Epoch: 6| Step: 5
Training loss: 1.663062334060669
Validation loss: 1.8679603607423845

Epoch: 6| Step: 6
Training loss: 1.4286677837371826
Validation loss: 1.8966846440428047

Epoch: 6| Step: 7
Training loss: 1.3966540098190308
Validation loss: 1.8372777738878805

Epoch: 6| Step: 8
Training loss: 2.2409095764160156
Validation loss: 1.8993188732413835

Epoch: 6| Step: 9
Training loss: 1.7826192378997803
Validation loss: 1.8395260072523547

Epoch: 6| Step: 10
Training loss: 1.941002368927002
Validation loss: 1.8413930503270959

Epoch: 6| Step: 11
Training loss: 1.2711689472198486
Validation loss: 1.8568874354003577

Epoch: 6| Step: 12
Training loss: 1.2517478466033936
Validation loss: 1.8891044368026078

Epoch: 6| Step: 13
Training loss: 1.531381607055664
Validation loss: 1.8959054382898475

Epoch: 268| Step: 0
Training loss: 1.400915265083313
Validation loss: 1.9025698554131292

Epoch: 6| Step: 1
Training loss: 1.6881539821624756
Validation loss: 1.889574981504871

Epoch: 6| Step: 2
Training loss: 1.776664137840271
Validation loss: 1.9360642074256815

Epoch: 6| Step: 3
Training loss: 1.2225521802902222
Validation loss: 1.87356533030028

Epoch: 6| Step: 4
Training loss: 1.7035338878631592
Validation loss: 1.8503589501944921

Epoch: 6| Step: 5
Training loss: 1.6157097816467285
Validation loss: 1.900639118686799

Epoch: 6| Step: 6
Training loss: 1.96110200881958
Validation loss: 1.8364087202215706

Epoch: 6| Step: 7
Training loss: 1.4158101081848145
Validation loss: 1.869179298800807

Epoch: 6| Step: 8
Training loss: 1.37722647190094
Validation loss: 1.885275221640064

Epoch: 6| Step: 9
Training loss: 1.8106544017791748
Validation loss: 1.8767332838427635

Epoch: 6| Step: 10
Training loss: 2.0973048210144043
Validation loss: 1.8921412088537728

Epoch: 6| Step: 11
Training loss: 1.4501473903656006
Validation loss: 1.8811822309288928

Epoch: 6| Step: 12
Training loss: 1.3679739236831665
Validation loss: 1.8515924471680836

Epoch: 6| Step: 13
Training loss: 3.22184157371521
Validation loss: 1.8624138473182597

Epoch: 269| Step: 0
Training loss: 1.4590197801589966
Validation loss: 1.8964134954637097

Epoch: 6| Step: 1
Training loss: 1.8369863033294678
Validation loss: 1.8528701720699188

Epoch: 6| Step: 2
Training loss: 1.4193329811096191
Validation loss: 1.8228363388328142

Epoch: 6| Step: 3
Training loss: 0.8766233921051025
Validation loss: 1.8182806391869821

Epoch: 6| Step: 4
Training loss: 1.9515857696533203
Validation loss: 1.8255843013845465

Epoch: 6| Step: 5
Training loss: 1.75727117061615
Validation loss: 1.7904179096221924

Epoch: 6| Step: 6
Training loss: 1.4945940971374512
Validation loss: 1.8917161213454379

Epoch: 6| Step: 7
Training loss: 2.2051217555999756
Validation loss: 1.895266309861214

Epoch: 6| Step: 8
Training loss: 1.6765234470367432
Validation loss: 1.8851356493529452

Epoch: 6| Step: 9
Training loss: 1.8924949169158936
Validation loss: 1.8322483801072644

Epoch: 6| Step: 10
Training loss: 1.5614562034606934
Validation loss: 1.8750547952549432

Epoch: 6| Step: 11
Training loss: 1.4851350784301758
Validation loss: 1.8750907631330593

Epoch: 6| Step: 12
Training loss: 2.2009310722351074
Validation loss: 1.890512079320928

Epoch: 6| Step: 13
Training loss: 1.1270700693130493
Validation loss: 1.9159647021242368

Epoch: 270| Step: 0
Training loss: 1.6661330461502075
Validation loss: 1.8517826116213234

Epoch: 6| Step: 1
Training loss: 2.0738086700439453
Validation loss: 1.9222685021738852

Epoch: 6| Step: 2
Training loss: 1.62822687625885
Validation loss: 1.9418205035630094

Epoch: 6| Step: 3
Training loss: 1.009247064590454
Validation loss: 1.9298383112876647

Epoch: 6| Step: 4
Training loss: 1.4265632629394531
Validation loss: 1.9608421992230158

Epoch: 6| Step: 5
Training loss: 1.2450495958328247
Validation loss: 1.9158206498751076

Epoch: 6| Step: 6
Training loss: 2.414543628692627
Validation loss: 1.8978321936822706

Epoch: 6| Step: 7
Training loss: 1.7361866235733032
Validation loss: 1.9590548725538357

Epoch: 6| Step: 8
Training loss: 1.6084293127059937
Validation loss: 1.855738643677004

Epoch: 6| Step: 9
Training loss: 1.4977538585662842
Validation loss: 1.8918869482573641

Epoch: 6| Step: 10
Training loss: 1.2704377174377441
Validation loss: 1.8286158397633543

Epoch: 6| Step: 11
Training loss: 1.4052480459213257
Validation loss: 1.8404138639409056

Epoch: 6| Step: 12
Training loss: 1.8598158359527588
Validation loss: 1.821660631446428

Epoch: 6| Step: 13
Training loss: 2.049553871154785
Validation loss: 1.8549697245320966

Epoch: 271| Step: 0
Training loss: 2.038053512573242
Validation loss: 1.8724965587739022

Epoch: 6| Step: 1
Training loss: 1.786592721939087
Validation loss: 1.8548982989403509

Epoch: 6| Step: 2
Training loss: 1.5893446207046509
Validation loss: 1.847432469808927

Epoch: 6| Step: 3
Training loss: 0.9763951897621155
Validation loss: 1.871581349321591

Epoch: 6| Step: 4
Training loss: 1.5439445972442627
Validation loss: 1.8512728983356106

Epoch: 6| Step: 5
Training loss: 1.8909838199615479
Validation loss: 1.870654470177107

Epoch: 6| Step: 6
Training loss: 1.1805198192596436
Validation loss: 1.830779178168184

Epoch: 6| Step: 7
Training loss: 1.4058895111083984
Validation loss: 1.8634286772820257

Epoch: 6| Step: 8
Training loss: 2.068416118621826
Validation loss: 1.8645426534837293

Epoch: 6| Step: 9
Training loss: 1.4620981216430664
Validation loss: 1.862089696750846

Epoch: 6| Step: 10
Training loss: 2.049651861190796
Validation loss: 1.8347660623570925

Epoch: 6| Step: 11
Training loss: 1.8500034809112549
Validation loss: 1.855520764986674

Epoch: 6| Step: 12
Training loss: 1.591844081878662
Validation loss: 1.9067011174335275

Epoch: 6| Step: 13
Training loss: 1.9926308393478394
Validation loss: 1.877125846442356

Epoch: 272| Step: 0
Training loss: 1.3014086484909058
Validation loss: 1.8696710371202039

Epoch: 6| Step: 1
Training loss: 2.015387773513794
Validation loss: 1.8505383012115315

Epoch: 6| Step: 2
Training loss: 2.168511390686035
Validation loss: 1.8352351368114512

Epoch: 6| Step: 3
Training loss: 1.8223384618759155
Validation loss: 1.899745165660817

Epoch: 6| Step: 4
Training loss: 1.6412227153778076
Validation loss: 1.834100592520929

Epoch: 6| Step: 5
Training loss: 1.7689205408096313
Validation loss: 1.825123010143157

Epoch: 6| Step: 6
Training loss: 1.348145604133606
Validation loss: 1.8581992785135906

Epoch: 6| Step: 7
Training loss: 1.6039263010025024
Validation loss: 1.8792351766299176

Epoch: 6| Step: 8
Training loss: 1.3828623294830322
Validation loss: 1.8544937269662016

Epoch: 6| Step: 9
Training loss: 1.8516321182250977
Validation loss: 1.8454163433403097

Epoch: 6| Step: 10
Training loss: 1.900646686553955
Validation loss: 1.8350487998736802

Epoch: 6| Step: 11
Training loss: 1.2950948476791382
Validation loss: 1.8033784576641616

Epoch: 6| Step: 12
Training loss: 1.262145757675171
Validation loss: 1.8538881514662056

Epoch: 6| Step: 13
Training loss: 1.6000585556030273
Validation loss: 1.8756464258317025

Epoch: 273| Step: 0
Training loss: 1.053025484085083
Validation loss: 1.914004833467545

Epoch: 6| Step: 1
Training loss: 1.1063525676727295
Validation loss: 1.876301674432652

Epoch: 6| Step: 2
Training loss: 1.636086106300354
Validation loss: 1.7914570967356365

Epoch: 6| Step: 3
Training loss: 2.098836898803711
Validation loss: 1.8466862299109017

Epoch: 6| Step: 4
Training loss: 1.902180552482605
Validation loss: 1.840381391586796

Epoch: 6| Step: 5
Training loss: 1.7988760471343994
Validation loss: 1.841221168477048

Epoch: 6| Step: 6
Training loss: 1.4293720722198486
Validation loss: 1.8480290546212146

Epoch: 6| Step: 7
Training loss: 1.9193865060806274
Validation loss: 1.8895478658778693

Epoch: 6| Step: 8
Training loss: 1.6538892984390259
Validation loss: 1.8421321222859044

Epoch: 6| Step: 9
Training loss: 1.5543150901794434
Validation loss: 1.8621261478752218

Epoch: 6| Step: 10
Training loss: 1.2583403587341309
Validation loss: 1.8831339356719807

Epoch: 6| Step: 11
Training loss: 1.6868982315063477
Validation loss: 1.894376644524195

Epoch: 6| Step: 12
Training loss: 1.6985265016555786
Validation loss: 1.8919762155061126

Epoch: 6| Step: 13
Training loss: 2.215630531311035
Validation loss: 1.8951726536596976

Epoch: 274| Step: 0
Training loss: 1.7125298976898193
Validation loss: 1.8334841587210213

Epoch: 6| Step: 1
Training loss: 1.523155927658081
Validation loss: 1.9123102362437914

Epoch: 6| Step: 2
Training loss: 1.4488028287887573
Validation loss: 1.8205046564020135

Epoch: 6| Step: 3
Training loss: 1.1017982959747314
Validation loss: 1.8227796580201836

Epoch: 6| Step: 4
Training loss: 1.7097253799438477
Validation loss: 1.890706621190553

Epoch: 6| Step: 5
Training loss: 1.8441989421844482
Validation loss: 1.8510109019535843

Epoch: 6| Step: 6
Training loss: 1.7335906028747559
Validation loss: 1.8514730904691963

Epoch: 6| Step: 7
Training loss: 2.0777816772460938
Validation loss: 1.8445623715718586

Epoch: 6| Step: 8
Training loss: 1.2712976932525635
Validation loss: 1.8932140258050734

Epoch: 6| Step: 9
Training loss: 1.6448218822479248
Validation loss: 1.8771798046686317

Epoch: 6| Step: 10
Training loss: 1.4619944095611572
Validation loss: 1.796911963852503

Epoch: 6| Step: 11
Training loss: 1.540222406387329
Validation loss: 1.855115670029835

Epoch: 6| Step: 12
Training loss: 1.84991455078125
Validation loss: 1.8214983388941774

Epoch: 6| Step: 13
Training loss: 1.8312926292419434
Validation loss: 1.8691324892864432

Epoch: 275| Step: 0
Training loss: 1.5116071701049805
Validation loss: 1.8498311850332445

Epoch: 6| Step: 1
Training loss: 1.4200234413146973
Validation loss: 1.8731794998209963

Epoch: 6| Step: 2
Training loss: 1.3630696535110474
Validation loss: 1.8664178476538709

Epoch: 6| Step: 3
Training loss: 1.107544183731079
Validation loss: 1.8469073669884795

Epoch: 6| Step: 4
Training loss: 1.9653149843215942
Validation loss: 1.877029534309141

Epoch: 6| Step: 5
Training loss: 2.23078989982605
Validation loss: 1.9149699006029355

Epoch: 6| Step: 6
Training loss: 2.1974830627441406
Validation loss: 1.8399231177504345

Epoch: 6| Step: 7
Training loss: 1.0996692180633545
Validation loss: 1.9096897340589953

Epoch: 6| Step: 8
Training loss: 1.8738189935684204
Validation loss: 1.921358241829821

Epoch: 6| Step: 9
Training loss: 1.2478257417678833
Validation loss: 1.931627187677609

Epoch: 6| Step: 10
Training loss: 1.9534180164337158
Validation loss: 1.955739067446801

Epoch: 6| Step: 11
Training loss: 1.7506778240203857
Validation loss: 1.8723999620765768

Epoch: 6| Step: 12
Training loss: 1.381945252418518
Validation loss: 1.8422511136660011

Epoch: 6| Step: 13
Training loss: 2.362255573272705
Validation loss: 1.9082083778996621

Epoch: 276| Step: 0
Training loss: 1.2257592678070068
Validation loss: 1.9851170098909767

Epoch: 6| Step: 1
Training loss: 2.296147346496582
Validation loss: 1.8593011107496036

Epoch: 6| Step: 2
Training loss: 1.6329782009124756
Validation loss: 1.8723348417589742

Epoch: 6| Step: 3
Training loss: 1.3182570934295654
Validation loss: 1.862516914644549

Epoch: 6| Step: 4
Training loss: 1.7956390380859375
Validation loss: 1.862395924906577

Epoch: 6| Step: 5
Training loss: 1.1387794017791748
Validation loss: 1.8183341795398342

Epoch: 6| Step: 6
Training loss: 1.5715798139572144
Validation loss: 1.926959591527139

Epoch: 6| Step: 7
Training loss: 1.5277049541473389
Validation loss: 1.8045428414498605

Epoch: 6| Step: 8
Training loss: 1.8699777126312256
Validation loss: 1.8421786997907905

Epoch: 6| Step: 9
Training loss: 1.1602206230163574
Validation loss: 1.865072537493962

Epoch: 6| Step: 10
Training loss: 2.0581789016723633
Validation loss: 1.8357929645046112

Epoch: 6| Step: 11
Training loss: 1.4812325239181519
Validation loss: 1.8767789384370208

Epoch: 6| Step: 12
Training loss: 1.7242660522460938
Validation loss: 1.8896347399680846

Epoch: 6| Step: 13
Training loss: 2.2723629474639893
Validation loss: 1.8520909137623285

Epoch: 277| Step: 0
Training loss: 1.2665822505950928
Validation loss: 1.8810339820000432

Epoch: 6| Step: 1
Training loss: 2.293426036834717
Validation loss: 1.85729129340059

Epoch: 6| Step: 2
Training loss: 1.7439764738082886
Validation loss: 1.8573199164482854

Epoch: 6| Step: 3
Training loss: 1.36991548538208
Validation loss: 1.8334015595015658

Epoch: 6| Step: 4
Training loss: 1.5870201587677002
Validation loss: 1.8381237458157282

Epoch: 6| Step: 5
Training loss: 1.449998140335083
Validation loss: 1.8945912879000428

Epoch: 6| Step: 6
Training loss: 1.7448389530181885
Validation loss: 1.8464775367449688

Epoch: 6| Step: 7
Training loss: 1.737504243850708
Validation loss: 1.8450862092356528

Epoch: 6| Step: 8
Training loss: 1.921807050704956
Validation loss: 1.8546730523468347

Epoch: 6| Step: 9
Training loss: 1.9359092712402344
Validation loss: 1.9232164249625257

Epoch: 6| Step: 10
Training loss: 1.4364752769470215
Validation loss: 1.870957040017651

Epoch: 6| Step: 11
Training loss: 1.4032655954360962
Validation loss: 1.8606996702891525

Epoch: 6| Step: 12
Training loss: 1.3503575325012207
Validation loss: 1.8573741041203982

Epoch: 6| Step: 13
Training loss: 1.079842448234558
Validation loss: 1.9004555799627816

Epoch: 278| Step: 0
Training loss: 2.0675129890441895
Validation loss: 1.8499338767861808

Epoch: 6| Step: 1
Training loss: 1.9776818752288818
Validation loss: 1.8398366115426505

Epoch: 6| Step: 2
Training loss: 0.9359862804412842
Validation loss: 1.8735659212194464

Epoch: 6| Step: 3
Training loss: 1.7824348211288452
Validation loss: 1.8742530499735186

Epoch: 6| Step: 4
Training loss: 1.444997787475586
Validation loss: 1.9445800614613358

Epoch: 6| Step: 5
Training loss: 1.3529726266860962
Validation loss: 1.8838207311527704

Epoch: 6| Step: 6
Training loss: 1.3739104270935059
Validation loss: 1.8681265359283776

Epoch: 6| Step: 7
Training loss: 1.4984782934188843
Validation loss: 1.8860797318079139

Epoch: 6| Step: 8
Training loss: 1.4501523971557617
Validation loss: 1.8622704436702113

Epoch: 6| Step: 9
Training loss: 1.3403446674346924
Validation loss: 1.9328388142329391

Epoch: 6| Step: 10
Training loss: 2.049158811569214
Validation loss: 1.9314447346554007

Epoch: 6| Step: 11
Training loss: 2.1097335815429688
Validation loss: 1.8714435074919014

Epoch: 6| Step: 12
Training loss: 1.6094945669174194
Validation loss: 1.8891389549419444

Epoch: 6| Step: 13
Training loss: 1.381015419960022
Validation loss: 1.8242909780112646

Epoch: 279| Step: 0
Training loss: 2.066681385040283
Validation loss: 1.897349416568715

Epoch: 6| Step: 1
Training loss: 1.3796849250793457
Validation loss: 1.8828206036680488

Epoch: 6| Step: 2
Training loss: 1.7023500204086304
Validation loss: 1.8573834191086471

Epoch: 6| Step: 3
Training loss: 1.7747856378555298
Validation loss: 1.854624145774431

Epoch: 6| Step: 4
Training loss: 2.4694128036499023
Validation loss: 1.9045076524057696

Epoch: 6| Step: 5
Training loss: 1.130654215812683
Validation loss: 1.8870007107334752

Epoch: 6| Step: 6
Training loss: 1.75986647605896
Validation loss: 1.832457216837073

Epoch: 6| Step: 7
Training loss: 1.7057864665985107
Validation loss: 1.853832278200375

Epoch: 6| Step: 8
Training loss: 0.8691806793212891
Validation loss: 1.849012428714383

Epoch: 6| Step: 9
Training loss: 1.8957459926605225
Validation loss: 1.8595778788289716

Epoch: 6| Step: 10
Training loss: 1.362837791442871
Validation loss: 1.83554063048414

Epoch: 6| Step: 11
Training loss: 1.4766896963119507
Validation loss: 1.8544456958770752

Epoch: 6| Step: 12
Training loss: 1.3638544082641602
Validation loss: 1.8440085854581607

Epoch: 6| Step: 13
Training loss: 1.452232837677002
Validation loss: 1.8534271691435127

Epoch: 280| Step: 0
Training loss: 1.3353114128112793
Validation loss: 1.8203628806657688

Epoch: 6| Step: 1
Training loss: 2.114267349243164
Validation loss: 1.8660205128372356

Epoch: 6| Step: 2
Training loss: 1.9509106874465942
Validation loss: 1.9079478107472903

Epoch: 6| Step: 3
Training loss: 1.5740041732788086
Validation loss: 1.8815512528983496

Epoch: 6| Step: 4
Training loss: 1.0505365133285522
Validation loss: 1.893711874561925

Epoch: 6| Step: 5
Training loss: 1.435023546218872
Validation loss: 1.8965839006567513

Epoch: 6| Step: 6
Training loss: 1.9260891675949097
Validation loss: 1.8967096703026884

Epoch: 6| Step: 7
Training loss: 1.1147130727767944
Validation loss: 1.9124744912629486

Epoch: 6| Step: 8
Training loss: 1.9315687417984009
Validation loss: 1.885436814318421

Epoch: 6| Step: 9
Training loss: 1.8087862730026245
Validation loss: 1.9052297543453913

Epoch: 6| Step: 10
Training loss: 1.611786127090454
Validation loss: 1.8986189480750792

Epoch: 6| Step: 11
Training loss: 1.523597002029419
Validation loss: 1.8799893932957803

Epoch: 6| Step: 12
Training loss: 1.5604815483093262
Validation loss: 1.8523891010592062

Epoch: 6| Step: 13
Training loss: 1.8325386047363281
Validation loss: 1.848511529225175

Epoch: 281| Step: 0
Training loss: 0.9591565132141113
Validation loss: 1.7832819569495417

Epoch: 6| Step: 1
Training loss: 1.0862665176391602
Validation loss: 1.898044284953866

Epoch: 6| Step: 2
Training loss: 1.7500110864639282
Validation loss: 1.847914526539464

Epoch: 6| Step: 3
Training loss: 1.3844518661499023
Validation loss: 1.8661375814868557

Epoch: 6| Step: 4
Training loss: 1.726738452911377
Validation loss: 1.8335535039183914

Epoch: 6| Step: 5
Training loss: 1.7368645668029785
Validation loss: 1.9091143870866427

Epoch: 6| Step: 6
Training loss: 1.2158206701278687
Validation loss: 1.8923705547086653

Epoch: 6| Step: 7
Training loss: 1.6670582294464111
Validation loss: 1.8854369322458904

Epoch: 6| Step: 8
Training loss: 1.370713472366333
Validation loss: 1.8115338304991364

Epoch: 6| Step: 9
Training loss: 1.7716612815856934
Validation loss: 1.8837466419384044

Epoch: 6| Step: 10
Training loss: 1.5061659812927246
Validation loss: 1.9161420381197365

Epoch: 6| Step: 11
Training loss: 1.4289166927337646
Validation loss: 1.9002612483116887

Epoch: 6| Step: 12
Training loss: 1.5458731651306152
Validation loss: 1.9358457531980289

Epoch: 6| Step: 13
Training loss: 3.8058972358703613
Validation loss: 1.8841626503134286

Epoch: 282| Step: 0
Training loss: 2.0162551403045654
Validation loss: 1.8611950207782049

Epoch: 6| Step: 1
Training loss: 0.9537205696105957
Validation loss: 1.833369029465542

Epoch: 6| Step: 2
Training loss: 1.5637108087539673
Validation loss: 1.8787746660171016

Epoch: 6| Step: 3
Training loss: 1.1742222309112549
Validation loss: 1.8961492687143304

Epoch: 6| Step: 4
Training loss: 1.4365010261535645
Validation loss: 1.8731130502557243

Epoch: 6| Step: 5
Training loss: 1.5578221082687378
Validation loss: 1.9112292925516765

Epoch: 6| Step: 6
Training loss: 2.23478364944458
Validation loss: 1.9040375986406881

Epoch: 6| Step: 7
Training loss: 1.381455421447754
Validation loss: 1.8585637974482712

Epoch: 6| Step: 8
Training loss: 1.5098707675933838
Validation loss: 1.8848414536445373

Epoch: 6| Step: 9
Training loss: 1.9177768230438232
Validation loss: 1.8587504368956371

Epoch: 6| Step: 10
Training loss: 1.3806171417236328
Validation loss: 1.885789873779461

Epoch: 6| Step: 11
Training loss: 1.6090325117111206
Validation loss: 1.9039896880426714

Epoch: 6| Step: 12
Training loss: 1.332897663116455
Validation loss: 1.851203400601623

Epoch: 6| Step: 13
Training loss: 2.0833520889282227
Validation loss: 1.8942308759176603

Epoch: 283| Step: 0
Training loss: 1.7277365922927856
Validation loss: 1.846899591466432

Epoch: 6| Step: 1
Training loss: 0.5769283175468445
Validation loss: 1.8414699287824734

Epoch: 6| Step: 2
Training loss: 1.303213357925415
Validation loss: 1.8293266514296174

Epoch: 6| Step: 3
Training loss: 1.5680335760116577
Validation loss: 1.8893384061833864

Epoch: 6| Step: 4
Training loss: 1.025325059890747
Validation loss: 1.823820888355214

Epoch: 6| Step: 5
Training loss: 1.7911131381988525
Validation loss: 1.8813688896035636

Epoch: 6| Step: 6
Training loss: 1.6603691577911377
Validation loss: 1.8947353016945623

Epoch: 6| Step: 7
Training loss: 2.560760021209717
Validation loss: 1.8544104022364463

Epoch: 6| Step: 8
Training loss: 1.294054388999939
Validation loss: 1.8242155300673617

Epoch: 6| Step: 9
Training loss: 2.0922634601593018
Validation loss: 1.8623037376711447

Epoch: 6| Step: 10
Training loss: 2.5868444442749023
Validation loss: 1.8675367780911025

Epoch: 6| Step: 11
Training loss: 1.6809697151184082
Validation loss: 1.9032684808136315

Epoch: 6| Step: 12
Training loss: 1.4235894680023193
Validation loss: 1.8223079199432044

Epoch: 6| Step: 13
Training loss: 0.7313400506973267
Validation loss: 1.8389973589169082

Epoch: 284| Step: 0
Training loss: 1.5929248332977295
Validation loss: 1.843131426841982

Epoch: 6| Step: 1
Training loss: 2.1925110816955566
Validation loss: 1.8637567976469636

Epoch: 6| Step: 2
Training loss: 0.944208025932312
Validation loss: 1.8116645812988281

Epoch: 6| Step: 3
Training loss: 1.8290914297103882
Validation loss: 1.8244564289687781

Epoch: 6| Step: 4
Training loss: 1.9170520305633545
Validation loss: 1.829218667040589

Epoch: 6| Step: 5
Training loss: 1.4771933555603027
Validation loss: 1.8927336674864574

Epoch: 6| Step: 6
Training loss: 1.5096802711486816
Validation loss: 1.8542697275838544

Epoch: 6| Step: 7
Training loss: 1.9397761821746826
Validation loss: 1.8306237049000238

Epoch: 6| Step: 8
Training loss: 1.849780797958374
Validation loss: 1.8779833457803214

Epoch: 6| Step: 9
Training loss: 1.5456674098968506
Validation loss: 1.8451609624329435

Epoch: 6| Step: 10
Training loss: 1.5484209060668945
Validation loss: 1.80849245543121

Epoch: 6| Step: 11
Training loss: 1.5562009811401367
Validation loss: 1.8486233501024143

Epoch: 6| Step: 12
Training loss: 1.3930010795593262
Validation loss: 1.8427172399336291

Epoch: 6| Step: 13
Training loss: 0.7784289121627808
Validation loss: 1.9040857950846355

Epoch: 285| Step: 0
Training loss: 1.6141318082809448
Validation loss: 1.8505198699171825

Epoch: 6| Step: 1
Training loss: 1.5281422138214111
Validation loss: 1.8739251090634255

Epoch: 6| Step: 2
Training loss: 1.0253323316574097
Validation loss: 1.8137757060348347

Epoch: 6| Step: 3
Training loss: 2.1112351417541504
Validation loss: 1.855385946971114

Epoch: 6| Step: 4
Training loss: 1.8643431663513184
Validation loss: 1.8421986526058567

Epoch: 6| Step: 5
Training loss: 1.3969534635543823
Validation loss: 1.887305982651249

Epoch: 6| Step: 6
Training loss: 1.4265797138214111
Validation loss: 1.7892590466366018

Epoch: 6| Step: 7
Training loss: 1.4529542922973633
Validation loss: 1.843835106459997

Epoch: 6| Step: 8
Training loss: 2.0582618713378906
Validation loss: 1.8418358705377067

Epoch: 6| Step: 9
Training loss: 1.5091058015823364
Validation loss: 1.860806405544281

Epoch: 6| Step: 10
Training loss: 2.0274789333343506
Validation loss: 1.8571270999088083

Epoch: 6| Step: 11
Training loss: 1.6187613010406494
Validation loss: 1.8109099300958778

Epoch: 6| Step: 12
Training loss: 1.4670381546020508
Validation loss: 1.8033113761614727

Epoch: 6| Step: 13
Training loss: 1.374643325805664
Validation loss: 1.880204980091382

Epoch: 286| Step: 0
Training loss: 1.472325086593628
Validation loss: 1.8626545975285191

Epoch: 6| Step: 1
Training loss: 1.4181632995605469
Validation loss: 1.9282230125960482

Epoch: 6| Step: 2
Training loss: 1.84540593624115
Validation loss: 1.8431961382589033

Epoch: 6| Step: 3
Training loss: 1.4926848411560059
Validation loss: 1.8901425253960393

Epoch: 6| Step: 4
Training loss: 1.3893804550170898
Validation loss: 1.887252922981016

Epoch: 6| Step: 5
Training loss: 1.6954643726348877
Validation loss: 1.9367177870965773

Epoch: 6| Step: 6
Training loss: 1.3763294219970703
Validation loss: 1.9068160441613966

Epoch: 6| Step: 7
Training loss: 2.230726480484009
Validation loss: 1.9351927567553777

Epoch: 6| Step: 8
Training loss: 1.750054955482483
Validation loss: 1.9158453249162244

Epoch: 6| Step: 9
Training loss: 1.105517864227295
Validation loss: 1.90958954698296

Epoch: 6| Step: 10
Training loss: 2.199690818786621
Validation loss: 1.9423486263521257

Epoch: 6| Step: 11
Training loss: 0.9970068335533142
Validation loss: 1.8847782445210282

Epoch: 6| Step: 12
Training loss: 2.0486528873443604
Validation loss: 1.8891427042663738

Epoch: 6| Step: 13
Training loss: 1.1206419467926025
Validation loss: 1.838408685499622

Epoch: 287| Step: 0
Training loss: 2.0107474327087402
Validation loss: 1.8819198557125625

Epoch: 6| Step: 1
Training loss: 1.5862725973129272
Validation loss: 1.8014201656464608

Epoch: 6| Step: 2
Training loss: 2.0076756477355957
Validation loss: 1.8627084121909192

Epoch: 6| Step: 3
Training loss: 1.9827159643173218
Validation loss: 1.8331147265690628

Epoch: 6| Step: 4
Training loss: 1.9507511854171753
Validation loss: 1.8719080878842262

Epoch: 6| Step: 5
Training loss: 1.5141273736953735
Validation loss: 1.8391684332201559

Epoch: 6| Step: 6
Training loss: 0.9497874975204468
Validation loss: 1.8577550457369896

Epoch: 6| Step: 7
Training loss: 1.1345964670181274
Validation loss: 1.813038569624706

Epoch: 6| Step: 8
Training loss: 1.4606398344039917
Validation loss: 1.9002998900669876

Epoch: 6| Step: 9
Training loss: 1.728026270866394
Validation loss: 1.8184156046118787

Epoch: 6| Step: 10
Training loss: 1.231245756149292
Validation loss: 1.8600948369631203

Epoch: 6| Step: 11
Training loss: 1.6090922355651855
Validation loss: 1.8254409233729045

Epoch: 6| Step: 12
Training loss: 1.5371953248977661
Validation loss: 1.8242106271046463

Epoch: 6| Step: 13
Training loss: 1.4374585151672363
Validation loss: 1.8605593801826559

Epoch: 288| Step: 0
Training loss: 1.68113112449646
Validation loss: 1.8762395279381865

Epoch: 6| Step: 1
Training loss: 1.8872425556182861
Validation loss: 1.88116366376159

Epoch: 6| Step: 2
Training loss: 1.076200246810913
Validation loss: 1.8367418755767166

Epoch: 6| Step: 3
Training loss: 1.6117554903030396
Validation loss: 1.8737358431662283

Epoch: 6| Step: 4
Training loss: 1.7709662914276123
Validation loss: 1.910759413114158

Epoch: 6| Step: 5
Training loss: 1.256016731262207
Validation loss: 1.833681635959174

Epoch: 6| Step: 6
Training loss: 1.2597784996032715
Validation loss: 1.8423794213161673

Epoch: 6| Step: 7
Training loss: 2.3518929481506348
Validation loss: 1.877862249651263

Epoch: 6| Step: 8
Training loss: 2.056735038757324
Validation loss: 1.8651550815951439

Epoch: 6| Step: 9
Training loss: 1.6889487504959106
Validation loss: 1.8201486372178601

Epoch: 6| Step: 10
Training loss: 1.0029757022857666
Validation loss: 1.9042583447630688

Epoch: 6| Step: 11
Training loss: 1.7419521808624268
Validation loss: 1.8164978975890784

Epoch: 6| Step: 12
Training loss: 1.7485737800598145
Validation loss: 1.9032984664363246

Epoch: 6| Step: 13
Training loss: 0.7351568937301636
Validation loss: 1.8449613125093522

Epoch: 289| Step: 0
Training loss: 1.2445636987686157
Validation loss: 1.8125503396475187

Epoch: 6| Step: 1
Training loss: 1.7590103149414062
Validation loss: 1.8050087972353863

Epoch: 6| Step: 2
Training loss: 1.4534416198730469
Validation loss: 1.87319153611378

Epoch: 6| Step: 3
Training loss: 1.7252333164215088
Validation loss: 1.8831831614176433

Epoch: 6| Step: 4
Training loss: 1.2898855209350586
Validation loss: 1.8524950255629837

Epoch: 6| Step: 5
Training loss: 1.5418726205825806
Validation loss: 1.8740886013994935

Epoch: 6| Step: 6
Training loss: 1.2339063882827759
Validation loss: 1.876000863249584

Epoch: 6| Step: 7
Training loss: 1.3856170177459717
Validation loss: 1.8911681559778029

Epoch: 6| Step: 8
Training loss: 1.6244111061096191
Validation loss: 1.8659653561089629

Epoch: 6| Step: 9
Training loss: 1.6219744682312012
Validation loss: 1.860079478192073

Epoch: 6| Step: 10
Training loss: 1.6320420503616333
Validation loss: 1.861702311423517

Epoch: 6| Step: 11
Training loss: 2.3852481842041016
Validation loss: 1.8124969928495345

Epoch: 6| Step: 12
Training loss: 1.8824893236160278
Validation loss: 1.8339558121978596

Epoch: 6| Step: 13
Training loss: 0.9537889957427979
Validation loss: 1.8647431442814488

Epoch: 290| Step: 0
Training loss: 2.1006288528442383
Validation loss: 1.8539865350210538

Epoch: 6| Step: 1
Training loss: 1.3713233470916748
Validation loss: 1.8631122214819795

Epoch: 6| Step: 2
Training loss: 1.5951623916625977
Validation loss: 1.8359991094117523

Epoch: 6| Step: 3
Training loss: 1.234611988067627
Validation loss: 1.8416489811353787

Epoch: 6| Step: 4
Training loss: 1.9992177486419678
Validation loss: 1.8780959767680014

Epoch: 6| Step: 5
Training loss: 1.5819416046142578
Validation loss: 1.839360240967043

Epoch: 6| Step: 6
Training loss: 1.429087519645691
Validation loss: 1.8262118742030153

Epoch: 6| Step: 7
Training loss: 1.3889602422714233
Validation loss: 1.8287040238739343

Epoch: 6| Step: 8
Training loss: 2.4697437286376953
Validation loss: 1.8102838813617665

Epoch: 6| Step: 9
Training loss: 1.6613075733184814
Validation loss: 1.7890380159501107

Epoch: 6| Step: 10
Training loss: 1.167568325996399
Validation loss: 1.8779787581454042

Epoch: 6| Step: 11
Training loss: 1.068311095237732
Validation loss: 1.905702152559834

Epoch: 6| Step: 12
Training loss: 1.747140884399414
Validation loss: 1.817669201922673

Epoch: 6| Step: 13
Training loss: 0.8960064649581909
Validation loss: 1.856987174480192

Epoch: 291| Step: 0
Training loss: 1.6289398670196533
Validation loss: 1.8434501181366623

Epoch: 6| Step: 1
Training loss: 1.9335525035858154
Validation loss: 1.8951719396857805

Epoch: 6| Step: 2
Training loss: 1.0449819564819336
Validation loss: 1.8146878045092347

Epoch: 6| Step: 3
Training loss: 1.7055171728134155
Validation loss: 1.8410706750808223

Epoch: 6| Step: 4
Training loss: 1.0733329057693481
Validation loss: 1.8603558732617287

Epoch: 6| Step: 5
Training loss: 1.3852832317352295
Validation loss: 1.8231425605794436

Epoch: 6| Step: 6
Training loss: 2.144629955291748
Validation loss: 1.8273286922003633

Epoch: 6| Step: 7
Training loss: 1.3078551292419434
Validation loss: 1.833897957237818

Epoch: 6| Step: 8
Training loss: 1.223214030265808
Validation loss: 1.8681561177776707

Epoch: 6| Step: 9
Training loss: 2.5672526359558105
Validation loss: 1.8433496131691882

Epoch: 6| Step: 10
Training loss: 1.2286503314971924
Validation loss: 1.8470807908683695

Epoch: 6| Step: 11
Training loss: 1.3946597576141357
Validation loss: 1.8508381023201892

Epoch: 6| Step: 12
Training loss: 1.8469161987304688
Validation loss: 1.8258888439465595

Epoch: 6| Step: 13
Training loss: 1.8360053300857544
Validation loss: 1.8808097582991405

Epoch: 292| Step: 0
Training loss: 1.7264213562011719
Validation loss: 1.8669626071888914

Epoch: 6| Step: 1
Training loss: 1.7488653659820557
Validation loss: 1.8838483300260318

Epoch: 6| Step: 2
Training loss: 1.7434792518615723
Validation loss: 1.8729313983712146

Epoch: 6| Step: 3
Training loss: 1.789271354675293
Validation loss: 1.9242012487944735

Epoch: 6| Step: 4
Training loss: 1.2231378555297852
Validation loss: 1.8538743629250476

Epoch: 6| Step: 5
Training loss: 1.6870408058166504
Validation loss: 1.8743273647882606

Epoch: 6| Step: 6
Training loss: 1.4350957870483398
Validation loss: 1.896540634093746

Epoch: 6| Step: 7
Training loss: 1.1901339292526245
Validation loss: 1.9025437549878192

Epoch: 6| Step: 8
Training loss: 1.472651481628418
Validation loss: 1.8370623652653029

Epoch: 6| Step: 9
Training loss: 1.322326421737671
Validation loss: 1.8412848916105045

Epoch: 6| Step: 10
Training loss: 1.6403543949127197
Validation loss: 1.8622806777236283

Epoch: 6| Step: 11
Training loss: 1.6902191638946533
Validation loss: 1.8410399037022744

Epoch: 6| Step: 12
Training loss: 1.535675287246704
Validation loss: 1.9032836562843733

Epoch: 6| Step: 13
Training loss: 1.9121812582015991
Validation loss: 1.8932880099101732

Epoch: 293| Step: 0
Training loss: 1.8635690212249756
Validation loss: 1.886939138494512

Epoch: 6| Step: 1
Training loss: 1.7570059299468994
Validation loss: 1.837439360157136

Epoch: 6| Step: 2
Training loss: 1.2745569944381714
Validation loss: 1.8131456849395589

Epoch: 6| Step: 3
Training loss: 1.613913655281067
Validation loss: 1.8757854623179282

Epoch: 6| Step: 4
Training loss: 2.1028761863708496
Validation loss: 1.8168304145977061

Epoch: 6| Step: 5
Training loss: 1.6628354787826538
Validation loss: 1.8008970252929195

Epoch: 6| Step: 6
Training loss: 1.6386706829071045
Validation loss: 1.8173013682006507

Epoch: 6| Step: 7
Training loss: 1.678039789199829
Validation loss: 1.7907686669339415

Epoch: 6| Step: 8
Training loss: 1.0755454301834106
Validation loss: 1.8301715363738358

Epoch: 6| Step: 9
Training loss: 1.894628643989563
Validation loss: 1.777085336305762

Epoch: 6| Step: 10
Training loss: 2.119253158569336
Validation loss: 1.8461946338735602

Epoch: 6| Step: 11
Training loss: 0.9845684766769409
Validation loss: 1.8168774779124925

Epoch: 6| Step: 12
Training loss: 0.8558021187782288
Validation loss: 1.827525511864693

Epoch: 6| Step: 13
Training loss: 1.2821322679519653
Validation loss: 1.8251173175791258

Epoch: 294| Step: 0
Training loss: 1.7053539752960205
Validation loss: 1.7792087460076937

Epoch: 6| Step: 1
Training loss: 2.3218002319335938
Validation loss: 1.8951844887066913

Epoch: 6| Step: 2
Training loss: 1.9018698930740356
Validation loss: 1.8789805981420702

Epoch: 6| Step: 3
Training loss: 1.4803180694580078
Validation loss: 1.8459988460745862

Epoch: 6| Step: 4
Training loss: 1.4348793029785156
Validation loss: 1.9141946800293461

Epoch: 6| Step: 5
Training loss: 1.0467462539672852
Validation loss: 1.9348440195924492

Epoch: 6| Step: 6
Training loss: 1.7559549808502197
Validation loss: 1.8505450820410123

Epoch: 6| Step: 7
Training loss: 1.691843032836914
Validation loss: 1.8619107636072303

Epoch: 6| Step: 8
Training loss: 1.573667049407959
Validation loss: 1.872762890272243

Epoch: 6| Step: 9
Training loss: 1.2616835832595825
Validation loss: 1.8484981547119796

Epoch: 6| Step: 10
Training loss: 1.6331970691680908
Validation loss: 1.8485309641848329

Epoch: 6| Step: 11
Training loss: 1.5435049533843994
Validation loss: 1.8272105032397854

Epoch: 6| Step: 12
Training loss: 1.3677564859390259
Validation loss: 1.8451585154379568

Epoch: 6| Step: 13
Training loss: 1.6483807563781738
Validation loss: 1.8832764100002986

Epoch: 295| Step: 0
Training loss: 1.7450042963027954
Validation loss: 1.8575938132501417

Epoch: 6| Step: 1
Training loss: 1.3629834651947021
Validation loss: 1.7892417676987187

Epoch: 6| Step: 2
Training loss: 1.13800048828125
Validation loss: 1.8467378077968475

Epoch: 6| Step: 3
Training loss: 1.6697721481323242
Validation loss: 1.8388062471984534

Epoch: 6| Step: 4
Training loss: 1.7428228855133057
Validation loss: 1.8569896862071047

Epoch: 6| Step: 5
Training loss: 0.9940307140350342
Validation loss: 1.8120761097118419

Epoch: 6| Step: 6
Training loss: 2.1456685066223145
Validation loss: 1.8508715334758963

Epoch: 6| Step: 7
Training loss: 1.1941109895706177
Validation loss: 1.858936030377624

Epoch: 6| Step: 8
Training loss: 1.423050045967102
Validation loss: 1.8551612233602872

Epoch: 6| Step: 9
Training loss: 2.310781478881836
Validation loss: 1.8730199734369914

Epoch: 6| Step: 10
Training loss: 0.991560161113739
Validation loss: 1.8587098531825568

Epoch: 6| Step: 11
Training loss: 1.8218560218811035
Validation loss: 1.8384081881533387

Epoch: 6| Step: 12
Training loss: 1.843076467514038
Validation loss: 1.8541301386330717

Epoch: 6| Step: 13
Training loss: 1.734323501586914
Validation loss: 1.8748836965971096

Epoch: 296| Step: 0
Training loss: 2.2456889152526855
Validation loss: 1.8283518873235232

Epoch: 6| Step: 1
Training loss: 1.2109118700027466
Validation loss: 1.8770689836112402

Epoch: 6| Step: 2
Training loss: 1.3468046188354492
Validation loss: 1.8750785038035402

Epoch: 6| Step: 3
Training loss: 1.3173985481262207
Validation loss: 1.8843703513504357

Epoch: 6| Step: 4
Training loss: 1.3061836957931519
Validation loss: 1.9291749436368224

Epoch: 6| Step: 5
Training loss: 1.7354309558868408
Validation loss: 1.9118688657719602

Epoch: 6| Step: 6
Training loss: 1.9242584705352783
Validation loss: 1.9464738856079757

Epoch: 6| Step: 7
Training loss: 1.228179931640625
Validation loss: 1.910046463371605

Epoch: 6| Step: 8
Training loss: 2.0751967430114746
Validation loss: 1.928568652881089

Epoch: 6| Step: 9
Training loss: 1.24260675907135
Validation loss: 1.888379345658005

Epoch: 6| Step: 10
Training loss: 1.191853404045105
Validation loss: 1.9400022568241242

Epoch: 6| Step: 11
Training loss: 1.5169646739959717
Validation loss: 1.8918528941369825

Epoch: 6| Step: 12
Training loss: 1.692458987236023
Validation loss: 1.8765561734476397

Epoch: 6| Step: 13
Training loss: 1.3496854305267334
Validation loss: 1.896587452580852

Epoch: 297| Step: 0
Training loss: 1.7669777870178223
Validation loss: 1.8886888129736787

Epoch: 6| Step: 1
Training loss: 1.6913774013519287
Validation loss: 1.8691573668551702

Epoch: 6| Step: 2
Training loss: 2.0294179916381836
Validation loss: 1.8133239617911718

Epoch: 6| Step: 3
Training loss: 1.8513413667678833
Validation loss: 1.8026712697039369

Epoch: 6| Step: 4
Training loss: 2.048597812652588
Validation loss: 1.871797316817827

Epoch: 6| Step: 5
Training loss: 1.491138219833374
Validation loss: 1.8009357426756172

Epoch: 6| Step: 6
Training loss: 1.0779938697814941
Validation loss: 1.819693608950543

Epoch: 6| Step: 7
Training loss: 1.279881238937378
Validation loss: 1.8615625019996398

Epoch: 6| Step: 8
Training loss: 1.5651518106460571
Validation loss: 1.8461385209073302

Epoch: 6| Step: 9
Training loss: 1.512190818786621
Validation loss: 1.8332090531626055

Epoch: 6| Step: 10
Training loss: 1.1971079111099243
Validation loss: 1.8132169810674523

Epoch: 6| Step: 11
Training loss: 1.9392449855804443
Validation loss: 1.8206472217395742

Epoch: 6| Step: 12
Training loss: 1.2602124214172363
Validation loss: 1.8387822592130272

Epoch: 6| Step: 13
Training loss: 1.1443102359771729
Validation loss: 1.7916192546967538

Epoch: 298| Step: 0
Training loss: 1.3538546562194824
Validation loss: 1.8062341187589912

Epoch: 6| Step: 1
Training loss: 1.7632312774658203
Validation loss: 1.8497334193157893

Epoch: 6| Step: 2
Training loss: 2.1506571769714355
Validation loss: 1.8326084600981845

Epoch: 6| Step: 3
Training loss: 1.3872723579406738
Validation loss: 1.8298467974508963

Epoch: 6| Step: 4
Training loss: 2.017164707183838
Validation loss: 1.8517219763930126

Epoch: 6| Step: 5
Training loss: 1.646453619003296
Validation loss: 1.848913856731948

Epoch: 6| Step: 6
Training loss: 1.7861393690109253
Validation loss: 1.8484887781963553

Epoch: 6| Step: 7
Training loss: 0.9946017265319824
Validation loss: 1.8586314544882825

Epoch: 6| Step: 8
Training loss: 1.9252641201019287
Validation loss: 1.8534719713272587

Epoch: 6| Step: 9
Training loss: 1.5465341806411743
Validation loss: 1.8689639209419169

Epoch: 6| Step: 10
Training loss: 1.3012925386428833
Validation loss: 1.879711378005243

Epoch: 6| Step: 11
Training loss: 1.3969135284423828
Validation loss: 1.8472319623475433

Epoch: 6| Step: 12
Training loss: 1.1638816595077515
Validation loss: 1.8853435977812736

Epoch: 6| Step: 13
Training loss: 2.054821014404297
Validation loss: 1.85329189608174

Epoch: 299| Step: 0
Training loss: 1.5793869495391846
Validation loss: 1.8096468897276028

Epoch: 6| Step: 1
Training loss: 1.5228575468063354
Validation loss: 1.817693369362944

Epoch: 6| Step: 2
Training loss: 1.3762584924697876
Validation loss: 1.810725035205964

Epoch: 6| Step: 3
Training loss: 1.4627548456192017
Validation loss: 1.86003432543047

Epoch: 6| Step: 4
Training loss: 1.8230750560760498
Validation loss: 1.8365825863294705

Epoch: 6| Step: 5
Training loss: 1.3115748167037964
Validation loss: 1.9128986635515768

Epoch: 6| Step: 6
Training loss: 2.6179938316345215
Validation loss: 1.844179960989183

Epoch: 6| Step: 7
Training loss: 2.0351293087005615
Validation loss: 1.815508286158244

Epoch: 6| Step: 8
Training loss: 1.1125080585479736
Validation loss: 1.8410651863262217

Epoch: 6| Step: 9
Training loss: 0.9561808109283447
Validation loss: 1.799155581382013

Epoch: 6| Step: 10
Training loss: 1.5685203075408936
Validation loss: 1.8014417425278695

Epoch: 6| Step: 11
Training loss: 1.0596094131469727
Validation loss: 1.8665603412094938

Epoch: 6| Step: 12
Training loss: 1.7773146629333496
Validation loss: 1.820469512734362

Epoch: 6| Step: 13
Training loss: 2.0066404342651367
Validation loss: 1.8095216546007382

Epoch: 300| Step: 0
Training loss: 1.6040699481964111
Validation loss: 1.858817567107498

Epoch: 6| Step: 1
Training loss: 1.501950740814209
Validation loss: 1.838600048454859

Epoch: 6| Step: 2
Training loss: 1.4836061000823975
Validation loss: 1.8736534657016877

Epoch: 6| Step: 3
Training loss: 1.681328296661377
Validation loss: 1.9499925541621383

Epoch: 6| Step: 4
Training loss: 1.4599370956420898
Validation loss: 1.855468419290358

Epoch: 6| Step: 5
Training loss: 1.5324488878250122
Validation loss: 1.8952872855688936

Epoch: 6| Step: 6
Training loss: 2.3537449836730957
Validation loss: 1.8511873599021667

Epoch: 6| Step: 7
Training loss: 1.5147430896759033
Validation loss: 1.8898840271016604

Epoch: 6| Step: 8
Training loss: 1.3274614810943604
Validation loss: 1.8702281662212905

Epoch: 6| Step: 9
Training loss: 1.4823293685913086
Validation loss: 1.8526456035593504

Epoch: 6| Step: 10
Training loss: 1.4246032238006592
Validation loss: 1.8536597964584187

Epoch: 6| Step: 11
Training loss: 1.8294333219528198
Validation loss: 1.892345783531025

Epoch: 6| Step: 12
Training loss: 1.0701484680175781
Validation loss: 1.8050189710432483

Epoch: 6| Step: 13
Training loss: 2.456299304962158
Validation loss: 1.8704133418298536

Epoch: 301| Step: 0
Training loss: 1.6447192430496216
Validation loss: 1.8140040379698559

Epoch: 6| Step: 1
Training loss: 0.9202596545219421
Validation loss: 1.8361029830030215

Epoch: 6| Step: 2
Training loss: 1.1934239864349365
Validation loss: 1.8060102808860041

Epoch: 6| Step: 3
Training loss: 2.002549648284912
Validation loss: 1.8418233497168428

Epoch: 6| Step: 4
Training loss: 1.6593132019042969
Validation loss: 1.8750231817204466

Epoch: 6| Step: 5
Training loss: 1.72788667678833
Validation loss: 1.815009396563294

Epoch: 6| Step: 6
Training loss: 1.982219934463501
Validation loss: 1.8488249996657014

Epoch: 6| Step: 7
Training loss: 1.32767653465271
Validation loss: 1.8316316091886131

Epoch: 6| Step: 8
Training loss: 1.5542374849319458
Validation loss: 1.7753006027590843

Epoch: 6| Step: 9
Training loss: 0.9535836577415466
Validation loss: 1.7906759887613275

Epoch: 6| Step: 10
Training loss: 2.312675714492798
Validation loss: 1.8882604722053773

Epoch: 6| Step: 11
Training loss: 1.4193480014801025
Validation loss: 1.7868788761477317

Epoch: 6| Step: 12
Training loss: 2.036466360092163
Validation loss: 1.7907265258091751

Epoch: 6| Step: 13
Training loss: 0.5973912477493286
Validation loss: 1.8330146189658874

Epoch: 302| Step: 0
Training loss: 1.2509307861328125
Validation loss: 1.843626860649355

Epoch: 6| Step: 1
Training loss: 1.9645850658416748
Validation loss: 1.8786912810417913

Epoch: 6| Step: 2
Training loss: 1.3038158416748047
Validation loss: 1.8130519178605848

Epoch: 6| Step: 3
Training loss: 2.091017007827759
Validation loss: 1.8245518438277706

Epoch: 6| Step: 4
Training loss: 1.5001996755599976
Validation loss: 1.8074395733494912

Epoch: 6| Step: 5
Training loss: 1.159713864326477
Validation loss: 1.8914724152575257

Epoch: 6| Step: 6
Training loss: 1.6440176963806152
Validation loss: 1.828360697274567

Epoch: 6| Step: 7
Training loss: 1.7774608135223389
Validation loss: 1.8236753684218212

Epoch: 6| Step: 8
Training loss: 1.9468275308609009
Validation loss: 1.8628849239759548

Epoch: 6| Step: 9
Training loss: 1.0654504299163818
Validation loss: 1.8439363920560448

Epoch: 6| Step: 10
Training loss: 0.9727561473846436
Validation loss: 1.8225028732771515

Epoch: 6| Step: 11
Training loss: 1.2614459991455078
Validation loss: 1.8374102154085714

Epoch: 6| Step: 12
Training loss: 1.9669437408447266
Validation loss: 1.9188508666971678

Epoch: 6| Step: 13
Training loss: 1.8263530731201172
Validation loss: 1.8221662967435774

Epoch: 303| Step: 0
Training loss: 1.7334129810333252
Validation loss: 1.860558840536302

Epoch: 6| Step: 1
Training loss: 1.9493627548217773
Validation loss: 1.8345903888825448

Epoch: 6| Step: 2
Training loss: 1.6398601531982422
Validation loss: 1.8116463858594176

Epoch: 6| Step: 3
Training loss: 1.4039990901947021
Validation loss: 1.8277794699515066

Epoch: 6| Step: 4
Training loss: 2.0082757472991943
Validation loss: 1.850690778865609

Epoch: 6| Step: 5
Training loss: 1.1323693990707397
Validation loss: 1.844274405510195

Epoch: 6| Step: 6
Training loss: 1.7546428442001343
Validation loss: 1.8140111328453146

Epoch: 6| Step: 7
Training loss: 1.4794225692749023
Validation loss: 1.848841569756949

Epoch: 6| Step: 8
Training loss: 1.411442518234253
Validation loss: 1.8263375041305379

Epoch: 6| Step: 9
Training loss: 1.19114089012146
Validation loss: 1.8627078558809014

Epoch: 6| Step: 10
Training loss: 1.7289245128631592
Validation loss: 1.7911936608693932

Epoch: 6| Step: 11
Training loss: 1.463985562324524
Validation loss: 1.8418831979074786

Epoch: 6| Step: 12
Training loss: 0.8620944619178772
Validation loss: 1.8305142643631145

Epoch: 6| Step: 13
Training loss: 2.675144672393799
Validation loss: 1.8095431404729043

Epoch: 304| Step: 0
Training loss: 1.528674840927124
Validation loss: 1.8680730737665647

Epoch: 6| Step: 1
Training loss: 0.9586673974990845
Validation loss: 1.7950219723486132

Epoch: 6| Step: 2
Training loss: 1.4458048343658447
Validation loss: 1.8325671303656794

Epoch: 6| Step: 3
Training loss: 1.8134379386901855
Validation loss: 1.8848241247156614

Epoch: 6| Step: 4
Training loss: 1.4084031581878662
Validation loss: 1.8701274676989483

Epoch: 6| Step: 5
Training loss: 2.708733081817627
Validation loss: 1.916332285891297

Epoch: 6| Step: 6
Training loss: 2.49906325340271
Validation loss: 1.893383155586899

Epoch: 6| Step: 7
Training loss: 1.3988479375839233
Validation loss: 1.8754345422149987

Epoch: 6| Step: 8
Training loss: 1.402531385421753
Validation loss: 1.8511626271791355

Epoch: 6| Step: 9
Training loss: 1.2564845085144043
Validation loss: 1.8975349933870378

Epoch: 6| Step: 10
Training loss: 0.8687755465507507
Validation loss: 1.7947729684973275

Epoch: 6| Step: 11
Training loss: 1.3889909982681274
Validation loss: 1.8316008801101356

Epoch: 6| Step: 12
Training loss: 1.8594199419021606
Validation loss: 1.825611073483703

Epoch: 6| Step: 13
Training loss: 1.4359416961669922
Validation loss: 1.8588260335306968

Epoch: 305| Step: 0
Training loss: 1.4991581439971924
Validation loss: 1.854679822921753

Epoch: 6| Step: 1
Training loss: 1.6017491817474365
Validation loss: 1.8835496364101287

Epoch: 6| Step: 2
Training loss: 1.5738956928253174
Validation loss: 1.826042700839299

Epoch: 6| Step: 3
Training loss: 1.2334916591644287
Validation loss: 1.8569579739724436

Epoch: 6| Step: 4
Training loss: 1.6949726343154907
Validation loss: 1.879107754717591

Epoch: 6| Step: 5
Training loss: 2.5409343242645264
Validation loss: 1.811687877101283

Epoch: 6| Step: 6
Training loss: 1.4950380325317383
Validation loss: 1.8294594095599266

Epoch: 6| Step: 7
Training loss: 1.469487190246582
Validation loss: 1.8691989965336298

Epoch: 6| Step: 8
Training loss: 1.5689504146575928
Validation loss: 1.8405644637282177

Epoch: 6| Step: 9
Training loss: 1.9619319438934326
Validation loss: 1.8848051089112476

Epoch: 6| Step: 10
Training loss: 0.9831405282020569
Validation loss: 1.8501062111188007

Epoch: 6| Step: 11
Training loss: 1.2188669443130493
Validation loss: 1.8307930731004285

Epoch: 6| Step: 12
Training loss: 1.4446192979812622
Validation loss: 1.9525301264178367

Epoch: 6| Step: 13
Training loss: 0.6178605556488037
Validation loss: 1.8342855386836554

Epoch: 306| Step: 0
Training loss: 1.1795532703399658
Validation loss: 1.8617185751597087

Epoch: 6| Step: 1
Training loss: 1.0449135303497314
Validation loss: 1.885193520976651

Epoch: 6| Step: 2
Training loss: 1.5951584577560425
Validation loss: 1.9050052447985577

Epoch: 6| Step: 3
Training loss: 1.237735390663147
Validation loss: 1.8317749410547235

Epoch: 6| Step: 4
Training loss: 1.8095744848251343
Validation loss: 1.8746198582392868

Epoch: 6| Step: 5
Training loss: 1.850459098815918
Validation loss: 1.8715974810302898

Epoch: 6| Step: 6
Training loss: 1.147812843322754
Validation loss: 1.8785960866558937

Epoch: 6| Step: 7
Training loss: 1.7151234149932861
Validation loss: 1.8630643506203928

Epoch: 6| Step: 8
Training loss: 2.067664861679077
Validation loss: 1.8953149818604993

Epoch: 6| Step: 9
Training loss: 1.950740933418274
Validation loss: 1.924226450663741

Epoch: 6| Step: 10
Training loss: 1.2389302253723145
Validation loss: 1.8205695203555528

Epoch: 6| Step: 11
Training loss: 1.9632019996643066
Validation loss: 1.8483646595349876

Epoch: 6| Step: 12
Training loss: 1.4341967105865479
Validation loss: 1.8520371144817722

Epoch: 6| Step: 13
Training loss: 1.4214099645614624
Validation loss: 1.831728340477072

Epoch: 307| Step: 0
Training loss: 1.4792671203613281
Validation loss: 1.771676081483082

Epoch: 6| Step: 1
Training loss: 1.2363953590393066
Validation loss: 1.8705369695540397

Epoch: 6| Step: 2
Training loss: 1.8852221965789795
Validation loss: 1.8748704310386413

Epoch: 6| Step: 3
Training loss: 1.1251425743103027
Validation loss: 1.781116295886296

Epoch: 6| Step: 4
Training loss: 1.308147668838501
Validation loss: 1.796073003481793

Epoch: 6| Step: 5
Training loss: 1.5759460926055908
Validation loss: 1.8470298949108328

Epoch: 6| Step: 6
Training loss: 1.131512999534607
Validation loss: 1.8398995194383847

Epoch: 6| Step: 7
Training loss: 1.8839917182922363
Validation loss: 1.8640229548177412

Epoch: 6| Step: 8
Training loss: 2.174790382385254
Validation loss: 1.8164261810241207

Epoch: 6| Step: 9
Training loss: 1.9216727018356323
Validation loss: 1.810873648812694

Epoch: 6| Step: 10
Training loss: 1.1867642402648926
Validation loss: 1.8655817982971028

Epoch: 6| Step: 11
Training loss: 1.3457179069519043
Validation loss: 1.788178889982162

Epoch: 6| Step: 12
Training loss: 2.293689250946045
Validation loss: 1.7978712281873148

Epoch: 6| Step: 13
Training loss: 0.9678513407707214
Validation loss: 1.7969950155545307

Epoch: 308| Step: 0
Training loss: 1.4318931102752686
Validation loss: 1.8190826805689002

Epoch: 6| Step: 1
Training loss: 2.0950145721435547
Validation loss: 1.8116297286043885

Epoch: 6| Step: 2
Training loss: 2.133798599243164
Validation loss: 1.8214246124349616

Epoch: 6| Step: 3
Training loss: 0.9079077243804932
Validation loss: 1.831202458309871

Epoch: 6| Step: 4
Training loss: 1.5445524454116821
Validation loss: 1.7767975894353722

Epoch: 6| Step: 5
Training loss: 1.309554100036621
Validation loss: 1.801615882945317

Epoch: 6| Step: 6
Training loss: 2.0194807052612305
Validation loss: 1.7978487860771917

Epoch: 6| Step: 7
Training loss: 1.2739520072937012
Validation loss: 1.798635640451985

Epoch: 6| Step: 8
Training loss: 1.366162896156311
Validation loss: 1.8337230554191015

Epoch: 6| Step: 9
Training loss: 1.2772016525268555
Validation loss: 1.843026158630207

Epoch: 6| Step: 10
Training loss: 1.4329650402069092
Validation loss: 1.8005324191944574

Epoch: 6| Step: 11
Training loss: 1.722571849822998
Validation loss: 1.8445250065095964

Epoch: 6| Step: 12
Training loss: 1.5179224014282227
Validation loss: 1.8911283170023272

Epoch: 6| Step: 13
Training loss: 1.5722260475158691
Validation loss: 1.8394204839583366

Epoch: 309| Step: 0
Training loss: 1.5528544187545776
Validation loss: 1.849565117589889

Epoch: 6| Step: 1
Training loss: 0.9881638288497925
Validation loss: 1.7754249380480858

Epoch: 6| Step: 2
Training loss: 1.287320852279663
Validation loss: 1.845089461213799

Epoch: 6| Step: 3
Training loss: 1.8652762174606323
Validation loss: 1.817671016980243

Epoch: 6| Step: 4
Training loss: 2.2249019145965576
Validation loss: 1.8023103821662165

Epoch: 6| Step: 5
Training loss: 1.2440191507339478
Validation loss: 1.8228685484137586

Epoch: 6| Step: 6
Training loss: 1.548140048980713
Validation loss: 1.8712769195597658

Epoch: 6| Step: 7
Training loss: 1.025087833404541
Validation loss: 1.838966364501625

Epoch: 6| Step: 8
Training loss: 1.121760606765747
Validation loss: 1.7836254950492614

Epoch: 6| Step: 9
Training loss: 1.6304959058761597
Validation loss: 1.8731933127167404

Epoch: 6| Step: 10
Training loss: 1.5652556419372559
Validation loss: 1.8875263378184328

Epoch: 6| Step: 11
Training loss: 1.240951418876648
Validation loss: 1.8095296762322868

Epoch: 6| Step: 12
Training loss: 2.2164502143859863
Validation loss: 1.9168539316423479

Epoch: 6| Step: 13
Training loss: 1.7163389921188354
Validation loss: 1.8660142101267332

Epoch: 310| Step: 0
Training loss: 1.8388087749481201
Validation loss: 1.8030433167693436

Epoch: 6| Step: 1
Training loss: 1.2869629859924316
Validation loss: 1.8044155464377454

Epoch: 6| Step: 2
Training loss: 0.9919024705886841
Validation loss: 1.8262218634287517

Epoch: 6| Step: 3
Training loss: 1.588416337966919
Validation loss: 1.8219050143354683

Epoch: 6| Step: 4
Training loss: 1.8301143646240234
Validation loss: 1.8236791703008837

Epoch: 6| Step: 5
Training loss: 1.8688355684280396
Validation loss: 1.8174788580145886

Epoch: 6| Step: 6
Training loss: 1.3424878120422363
Validation loss: 1.7744135677173574

Epoch: 6| Step: 7
Training loss: 1.9573695659637451
Validation loss: 1.8478132960616902

Epoch: 6| Step: 8
Training loss: 1.5595811605453491
Validation loss: 1.8346511804929344

Epoch: 6| Step: 9
Training loss: 1.6559979915618896
Validation loss: 1.877550619904713

Epoch: 6| Step: 10
Training loss: 1.217393398284912
Validation loss: 1.88448711492682

Epoch: 6| Step: 11
Training loss: 1.363952398300171
Validation loss: 1.8094097875779676

Epoch: 6| Step: 12
Training loss: 1.7042797803878784
Validation loss: 1.8330480052578835

Epoch: 6| Step: 13
Training loss: 1.339616298675537
Validation loss: 1.8608198499166837

Epoch: 311| Step: 0
Training loss: 0.6049718260765076
Validation loss: 1.8906942541881273

Epoch: 6| Step: 1
Training loss: 1.0830714702606201
Validation loss: 1.7891351881847586

Epoch: 6| Step: 2
Training loss: 2.053744316101074
Validation loss: 1.859297619071058

Epoch: 6| Step: 3
Training loss: 2.400550603866577
Validation loss: 1.8917548900009484

Epoch: 6| Step: 4
Training loss: 1.5944058895111084
Validation loss: 1.9149300077910065

Epoch: 6| Step: 5
Training loss: 1.3621007204055786
Validation loss: 1.8641030032147643

Epoch: 6| Step: 6
Training loss: 1.2390470504760742
Validation loss: 1.8489326251450406

Epoch: 6| Step: 7
Training loss: 2.093491315841675
Validation loss: 1.8244712660389562

Epoch: 6| Step: 8
Training loss: 1.7546076774597168
Validation loss: 1.8925677525099887

Epoch: 6| Step: 9
Training loss: 1.3190293312072754
Validation loss: 1.9175133397502284

Epoch: 6| Step: 10
Training loss: 1.0936999320983887
Validation loss: 1.8461806838230421

Epoch: 6| Step: 11
Training loss: 1.5623191595077515
Validation loss: 1.88637041020137

Epoch: 6| Step: 12
Training loss: 1.5291321277618408
Validation loss: 1.9045629052705662

Epoch: 6| Step: 13
Training loss: 1.9585909843444824
Validation loss: 1.859018789824619

Epoch: 312| Step: 0
Training loss: 1.5223991870880127
Validation loss: 1.862123079197381

Epoch: 6| Step: 1
Training loss: 1.6721775531768799
Validation loss: 1.859503105122556

Epoch: 6| Step: 2
Training loss: 1.855610966682434
Validation loss: 1.8741967434524207

Epoch: 6| Step: 3
Training loss: 1.9587669372558594
Validation loss: 1.7805222106236283

Epoch: 6| Step: 4
Training loss: 1.5992484092712402
Validation loss: 1.8329148375859825

Epoch: 6| Step: 5
Training loss: 1.2468457221984863
Validation loss: 1.8253934870484054

Epoch: 6| Step: 6
Training loss: 1.5795865058898926
Validation loss: 1.812394013968847

Epoch: 6| Step: 7
Training loss: 1.3387761116027832
Validation loss: 1.7989768494841873

Epoch: 6| Step: 8
Training loss: 1.004650354385376
Validation loss: 1.8129095415915213

Epoch: 6| Step: 9
Training loss: 1.4159594774246216
Validation loss: 1.7923798279095722

Epoch: 6| Step: 10
Training loss: 1.3315749168395996
Validation loss: 1.8596655425205026

Epoch: 6| Step: 11
Training loss: 1.408921241760254
Validation loss: 1.8063284479161745

Epoch: 6| Step: 12
Training loss: 2.112175464630127
Validation loss: 1.8540983738437775

Epoch: 6| Step: 13
Training loss: 1.1599884033203125
Validation loss: 1.780208441518968

Epoch: 313| Step: 0
Training loss: 1.863800048828125
Validation loss: 1.8120523844995806

Epoch: 6| Step: 1
Training loss: 1.8153283596038818
Validation loss: 1.823287493439131

Epoch: 6| Step: 2
Training loss: 1.4627996683120728
Validation loss: 1.8215925590966338

Epoch: 6| Step: 3
Training loss: 1.5327231884002686
Validation loss: 1.820266991533259

Epoch: 6| Step: 4
Training loss: 1.3590131998062134
Validation loss: 1.8357401573529808

Epoch: 6| Step: 5
Training loss: 1.2579238414764404
Validation loss: 1.7917860848929292

Epoch: 6| Step: 6
Training loss: 1.5288074016571045
Validation loss: 1.8323750431819628

Epoch: 6| Step: 7
Training loss: 1.7568453550338745
Validation loss: 1.807177847431552

Epoch: 6| Step: 8
Training loss: 1.533085823059082
Validation loss: 1.8472971941835137

Epoch: 6| Step: 9
Training loss: 1.751483678817749
Validation loss: 1.84108825396466

Epoch: 6| Step: 10
Training loss: 1.001969814300537
Validation loss: 1.83787549695661

Epoch: 6| Step: 11
Training loss: 1.8668620586395264
Validation loss: 1.8327206296305503

Epoch: 6| Step: 12
Training loss: 1.4393620491027832
Validation loss: 1.858676956545922

Epoch: 6| Step: 13
Training loss: 1.3568960428237915
Validation loss: 1.8244331985391595

Epoch: 314| Step: 0
Training loss: 1.4106816053390503
Validation loss: 1.822951138660472

Epoch: 6| Step: 1
Training loss: 1.6027441024780273
Validation loss: 1.8167749476689163

Epoch: 6| Step: 2
Training loss: 1.776108741760254
Validation loss: 1.8310101788531068

Epoch: 6| Step: 3
Training loss: 1.6556437015533447
Validation loss: 1.8646646391960882

Epoch: 6| Step: 4
Training loss: 1.458111047744751
Validation loss: 1.8514084982615646

Epoch: 6| Step: 5
Training loss: 1.7816262245178223
Validation loss: 1.8670752394583918

Epoch: 6| Step: 6
Training loss: 0.7168248295783997
Validation loss: 1.8101090808068552

Epoch: 6| Step: 7
Training loss: 1.4326813220977783
Validation loss: 1.870951505117519

Epoch: 6| Step: 8
Training loss: 1.9936739206314087
Validation loss: 1.8326195978349256

Epoch: 6| Step: 9
Training loss: 1.216438889503479
Validation loss: 1.7894148877871934

Epoch: 6| Step: 10
Training loss: 1.3924421072006226
Validation loss: 1.7526121203617384

Epoch: 6| Step: 11
Training loss: 1.4855701923370361
Validation loss: 1.8626495484382875

Epoch: 6| Step: 12
Training loss: 0.9345871806144714
Validation loss: 1.8008844749901884

Epoch: 6| Step: 13
Training loss: 2.189272403717041
Validation loss: 1.8279266639422345

Epoch: 315| Step: 0
Training loss: 1.6853848695755005
Validation loss: 1.7291674255042948

Epoch: 6| Step: 1
Training loss: 1.159867286682129
Validation loss: 1.823419217140444

Epoch: 6| Step: 2
Training loss: 1.6766924858093262
Validation loss: 1.8223965655090988

Epoch: 6| Step: 3
Training loss: 1.97916841506958
Validation loss: 1.7865527111996886

Epoch: 6| Step: 4
Training loss: 1.5960912704467773
Validation loss: 1.8126054092120099

Epoch: 6| Step: 5
Training loss: 1.4133074283599854
Validation loss: 1.7686242480431833

Epoch: 6| Step: 6
Training loss: 1.712166666984558
Validation loss: 1.854770755255094

Epoch: 6| Step: 7
Training loss: 2.050905227661133
Validation loss: 1.796796332123459

Epoch: 6| Step: 8
Training loss: 1.0246198177337646
Validation loss: 1.868321516180551

Epoch: 6| Step: 9
Training loss: 0.9377705454826355
Validation loss: 1.7946392361835768

Epoch: 6| Step: 10
Training loss: 1.6166590452194214
Validation loss: 1.8554069508788407

Epoch: 6| Step: 11
Training loss: 1.7979968786239624
Validation loss: 1.7679845902227587

Epoch: 6| Step: 12
Training loss: 1.199528694152832
Validation loss: 1.8695501025005052

Epoch: 6| Step: 13
Training loss: 1.2273533344268799
Validation loss: 1.8287085717724216

Epoch: 316| Step: 0
Training loss: 1.9125906229019165
Validation loss: 1.7781495125063005

Epoch: 6| Step: 1
Training loss: 1.453481674194336
Validation loss: 1.8210855055880804

Epoch: 6| Step: 2
Training loss: 1.471548080444336
Validation loss: 1.8210781133303078

Epoch: 6| Step: 3
Training loss: 1.9162479639053345
Validation loss: 1.7479433577547792

Epoch: 6| Step: 4
Training loss: 1.785888433456421
Validation loss: 1.7755050838634532

Epoch: 6| Step: 5
Training loss: 1.7283716201782227
Validation loss: 1.8383206270074333

Epoch: 6| Step: 6
Training loss: 1.6365547180175781
Validation loss: 1.8793042282904349

Epoch: 6| Step: 7
Training loss: 1.318068504333496
Validation loss: 1.8316695767064248

Epoch: 6| Step: 8
Training loss: 1.0948090553283691
Validation loss: 1.860733655191237

Epoch: 6| Step: 9
Training loss: 1.4628820419311523
Validation loss: 1.8330513892635223

Epoch: 6| Step: 10
Training loss: 2.047734498977661
Validation loss: 1.8773278420971287

Epoch: 6| Step: 11
Training loss: 0.8767895698547363
Validation loss: 1.8183499920752741

Epoch: 6| Step: 12
Training loss: 1.4337633848190308
Validation loss: 1.824916188434888

Epoch: 6| Step: 13
Training loss: 0.9228945970535278
Validation loss: 1.8495313634154618

Epoch: 317| Step: 0
Training loss: 1.1333709955215454
Validation loss: 1.8576854787847048

Epoch: 6| Step: 1
Training loss: 1.0587491989135742
Validation loss: 1.7772533521857312

Epoch: 6| Step: 2
Training loss: 1.1413078308105469
Validation loss: 1.7801366352265882

Epoch: 6| Step: 3
Training loss: 2.141317367553711
Validation loss: 1.845470807885611

Epoch: 6| Step: 4
Training loss: 1.8174643516540527
Validation loss: 1.839084848280876

Epoch: 6| Step: 5
Training loss: 1.294439673423767
Validation loss: 1.8464111615252752

Epoch: 6| Step: 6
Training loss: 1.241065502166748
Validation loss: 1.8031059131827405

Epoch: 6| Step: 7
Training loss: 2.5721259117126465
Validation loss: 1.8249295808935677

Epoch: 6| Step: 8
Training loss: 1.885851502418518
Validation loss: 1.8924332152130783

Epoch: 6| Step: 9
Training loss: 1.1093019247055054
Validation loss: 1.856684825753653

Epoch: 6| Step: 10
Training loss: 1.7332017421722412
Validation loss: 1.8260815989586614

Epoch: 6| Step: 11
Training loss: 1.3225756883621216
Validation loss: 1.8604364971960745

Epoch: 6| Step: 12
Training loss: 1.7248618602752686
Validation loss: 1.8069872599776073

Epoch: 6| Step: 13
Training loss: 1.3622463941574097
Validation loss: 1.848178635361374

Epoch: 318| Step: 0
Training loss: 1.9696757793426514
Validation loss: 1.8215224050706433

Epoch: 6| Step: 1
Training loss: 1.6798101663589478
Validation loss: 1.8060119946797688

Epoch: 6| Step: 2
Training loss: 1.4837754964828491
Validation loss: 1.8031109327911048

Epoch: 6| Step: 3
Training loss: 1.4086406230926514
Validation loss: 1.8550009958205684

Epoch: 6| Step: 4
Training loss: 1.7559915781021118
Validation loss: 1.78250717091304

Epoch: 6| Step: 5
Training loss: 1.179522156715393
Validation loss: 1.8264606473266438

Epoch: 6| Step: 6
Training loss: 1.2096771001815796
Validation loss: 1.8490057760669338

Epoch: 6| Step: 7
Training loss: 1.7664203643798828
Validation loss: 1.7840052971275904

Epoch: 6| Step: 8
Training loss: 1.440566062927246
Validation loss: 1.8056199473719443

Epoch: 6| Step: 9
Training loss: 1.3028371334075928
Validation loss: 1.821536385884849

Epoch: 6| Step: 10
Training loss: 1.5129835605621338
Validation loss: 1.8567405746829124

Epoch: 6| Step: 11
Training loss: 1.5041749477386475
Validation loss: 1.8091666519000966

Epoch: 6| Step: 12
Training loss: 1.769336462020874
Validation loss: 1.8181626412176317

Epoch: 6| Step: 13
Training loss: 1.333372950553894
Validation loss: 1.8433143451649656

Epoch: 319| Step: 0
Training loss: 1.7756779193878174
Validation loss: 1.8446682166027766

Epoch: 6| Step: 1
Training loss: 1.0158251523971558
Validation loss: 1.86641953837487

Epoch: 6| Step: 2
Training loss: 1.7212152481079102
Validation loss: 1.8871873399262786

Epoch: 6| Step: 3
Training loss: 2.006565570831299
Validation loss: 1.903812120037694

Epoch: 6| Step: 4
Training loss: 1.295975923538208
Validation loss: 1.8445296210627402

Epoch: 6| Step: 5
Training loss: 1.5015833377838135
Validation loss: 1.7829195825002526

Epoch: 6| Step: 6
Training loss: 1.8534266948699951
Validation loss: 1.837534628888612

Epoch: 6| Step: 7
Training loss: 2.068206310272217
Validation loss: 1.8220139318896877

Epoch: 6| Step: 8
Training loss: 1.002622127532959
Validation loss: 1.88122526291878

Epoch: 6| Step: 9
Training loss: 1.5066097974777222
Validation loss: 1.815709920339687

Epoch: 6| Step: 10
Training loss: 1.0109190940856934
Validation loss: 1.8666046306651125

Epoch: 6| Step: 11
Training loss: 1.1847660541534424
Validation loss: 1.9011317068530666

Epoch: 6| Step: 12
Training loss: 1.3546292781829834
Validation loss: 1.8726827483023367

Epoch: 6| Step: 13
Training loss: 1.490769386291504
Validation loss: 1.909190986746101

Epoch: 320| Step: 0
Training loss: 1.9149913787841797
Validation loss: 1.8598029664767686

Epoch: 6| Step: 1
Training loss: 1.2572925090789795
Validation loss: 1.9174236969281269

Epoch: 6| Step: 2
Training loss: 1.3027387857437134
Validation loss: 1.8164024891391877

Epoch: 6| Step: 3
Training loss: 1.9710488319396973
Validation loss: 1.8568104031265422

Epoch: 6| Step: 4
Training loss: 1.0558607578277588
Validation loss: 1.8192694212800713

Epoch: 6| Step: 5
Training loss: 2.034372091293335
Validation loss: 1.7967469692230225

Epoch: 6| Step: 6
Training loss: 1.0970454216003418
Validation loss: 1.8173718003816501

Epoch: 6| Step: 7
Training loss: 2.174412250518799
Validation loss: 1.7930186487013293

Epoch: 6| Step: 8
Training loss: 1.2022844552993774
Validation loss: 1.835459009293587

Epoch: 6| Step: 9
Training loss: 1.4137099981307983
Validation loss: 1.8486589641981228

Epoch: 6| Step: 10
Training loss: 1.396566390991211
Validation loss: 1.7631144972257717

Epoch: 6| Step: 11
Training loss: 0.8616854548454285
Validation loss: 1.8007432465912194

Epoch: 6| Step: 12
Training loss: 1.6529148817062378
Validation loss: 1.7902220936231716

Epoch: 6| Step: 13
Training loss: 1.5424129962921143
Validation loss: 1.8413912788514168

Epoch: 321| Step: 0
Training loss: 1.911569595336914
Validation loss: 1.816215589482297

Epoch: 6| Step: 1
Training loss: 1.6444182395935059
Validation loss: 1.8326594957741358

Epoch: 6| Step: 2
Training loss: 2.3842811584472656
Validation loss: 1.832267185693146

Epoch: 6| Step: 3
Training loss: 1.1297366619110107
Validation loss: 1.8151546550053421

Epoch: 6| Step: 4
Training loss: 1.161228060722351
Validation loss: 1.7910098209176013

Epoch: 6| Step: 5
Training loss: 1.576763391494751
Validation loss: 1.8156902572160125

Epoch: 6| Step: 6
Training loss: 1.4467365741729736
Validation loss: 1.8696388506120252

Epoch: 6| Step: 7
Training loss: 1.8718771934509277
Validation loss: 1.7894581992139098

Epoch: 6| Step: 8
Training loss: 1.2631360292434692
Validation loss: 1.8243066341646257

Epoch: 6| Step: 9
Training loss: 1.2714096307754517
Validation loss: 1.7969530218391008

Epoch: 6| Step: 10
Training loss: 1.1967103481292725
Validation loss: 1.8634998195914811

Epoch: 6| Step: 11
Training loss: 1.5564393997192383
Validation loss: 1.7742825823445474

Epoch: 6| Step: 12
Training loss: 1.019408941268921
Validation loss: 1.798404452621296

Epoch: 6| Step: 13
Training loss: 1.601362705230713
Validation loss: 1.8450302603424236

Epoch: 322| Step: 0
Training loss: 1.6278362274169922
Validation loss: 1.8182129360014392

Epoch: 6| Step: 1
Training loss: 1.012821912765503
Validation loss: 1.8170935594907371

Epoch: 6| Step: 2
Training loss: 1.419409155845642
Validation loss: 1.7897696533510763

Epoch: 6| Step: 3
Training loss: 1.395663857460022
Validation loss: 1.7961102621529692

Epoch: 6| Step: 4
Training loss: 1.7801556587219238
Validation loss: 1.8126855845092444

Epoch: 6| Step: 5
Training loss: 1.726715087890625
Validation loss: 1.823575823537765

Epoch: 6| Step: 6
Training loss: 1.6698482036590576
Validation loss: 1.7820810643575524

Epoch: 6| Step: 7
Training loss: 1.659753680229187
Validation loss: 1.8545547364860453

Epoch: 6| Step: 8
Training loss: 1.6709904670715332
Validation loss: 1.8330975322313205

Epoch: 6| Step: 9
Training loss: 1.2717535495758057
Validation loss: 1.808440472490044

Epoch: 6| Step: 10
Training loss: 1.342545509338379
Validation loss: 1.85518132486651

Epoch: 6| Step: 11
Training loss: 1.197786808013916
Validation loss: 1.8430901624823128

Epoch: 6| Step: 12
Training loss: 1.5300719738006592
Validation loss: 1.8132316361191452

Epoch: 6| Step: 13
Training loss: 1.9440577030181885
Validation loss: 1.8478130884067987

Epoch: 323| Step: 0
Training loss: 1.1626091003417969
Validation loss: 1.8742905432178127

Epoch: 6| Step: 1
Training loss: 1.53974449634552
Validation loss: 1.8728266915967386

Epoch: 6| Step: 2
Training loss: 1.2946313619613647
Validation loss: 1.7973762019988029

Epoch: 6| Step: 3
Training loss: 1.373167872428894
Validation loss: 1.8332203549723471

Epoch: 6| Step: 4
Training loss: 1.5146690607070923
Validation loss: 1.8370377773879676

Epoch: 6| Step: 5
Training loss: 0.9688548445701599
Validation loss: 1.7909534169781594

Epoch: 6| Step: 6
Training loss: 2.062244415283203
Validation loss: 1.7536864934429046

Epoch: 6| Step: 7
Training loss: 0.8041507005691528
Validation loss: 1.7763091800033406

Epoch: 6| Step: 8
Training loss: 1.6001720428466797
Validation loss: 1.8562180560122254

Epoch: 6| Step: 9
Training loss: 2.318953514099121
Validation loss: 1.817776080100767

Epoch: 6| Step: 10
Training loss: 2.380781888961792
Validation loss: 1.8121355067017257

Epoch: 6| Step: 11
Training loss: 1.133348822593689
Validation loss: 1.830548087755839

Epoch: 6| Step: 12
Training loss: 1.1198616027832031
Validation loss: 1.8118887870542464

Epoch: 6| Step: 13
Training loss: 1.6410229206085205
Validation loss: 1.8130767242882841

Epoch: 324| Step: 0
Training loss: 1.575394630432129
Validation loss: 1.7674158132204445

Epoch: 6| Step: 1
Training loss: 2.1330697536468506
Validation loss: 1.864405624328121

Epoch: 6| Step: 2
Training loss: 1.197213053703308
Validation loss: 1.8185321464333484

Epoch: 6| Step: 3
Training loss: 1.822672963142395
Validation loss: 1.7904494475292903

Epoch: 6| Step: 4
Training loss: 1.1521859169006348
Validation loss: 1.8063008157155847

Epoch: 6| Step: 5
Training loss: 2.5528955459594727
Validation loss: 1.8007564262677265

Epoch: 6| Step: 6
Training loss: 1.377360463142395
Validation loss: 1.868659761644179

Epoch: 6| Step: 7
Training loss: 1.391578197479248
Validation loss: 1.821148480138471

Epoch: 6| Step: 8
Training loss: 1.2940679788589478
Validation loss: 1.8380270093999884

Epoch: 6| Step: 9
Training loss: 1.4300110340118408
Validation loss: 1.810341533794198

Epoch: 6| Step: 10
Training loss: 0.8927958011627197
Validation loss: 1.8754549616126603

Epoch: 6| Step: 11
Training loss: 1.135927438735962
Validation loss: 1.8153491263748498

Epoch: 6| Step: 12
Training loss: 1.3250064849853516
Validation loss: 1.8431334469908027

Epoch: 6| Step: 13
Training loss: 1.2504678964614868
Validation loss: 1.8007518834965204

Epoch: 325| Step: 0
Training loss: 1.4316813945770264
Validation loss: 1.8399635399541547

Epoch: 6| Step: 1
Training loss: 1.2158458232879639
Validation loss: 1.840466050691502

Epoch: 6| Step: 2
Training loss: 1.5112273693084717
Validation loss: 1.867774982606211

Epoch: 6| Step: 3
Training loss: 1.4960157871246338
Validation loss: 1.8252160485072801

Epoch: 6| Step: 4
Training loss: 1.6819236278533936
Validation loss: 1.814627512808769

Epoch: 6| Step: 5
Training loss: 1.82626473903656
Validation loss: 1.8065429144008185

Epoch: 6| Step: 6
Training loss: 1.7440905570983887
Validation loss: 1.7819475249577594

Epoch: 6| Step: 7
Training loss: 1.280283808708191
Validation loss: 1.8461359572666947

Epoch: 6| Step: 8
Training loss: 1.336104393005371
Validation loss: 1.8188919277601345

Epoch: 6| Step: 9
Training loss: 2.0226142406463623
Validation loss: 1.8458317236233783

Epoch: 6| Step: 10
Training loss: 1.3512113094329834
Validation loss: 1.8083311742351902

Epoch: 6| Step: 11
Training loss: 0.9703760743141174
Validation loss: 1.8296938634687854

Epoch: 6| Step: 12
Training loss: 1.4996851682662964
Validation loss: 1.826593259329437

Epoch: 6| Step: 13
Training loss: 1.209596037864685
Validation loss: 1.8195673381128619

Epoch: 326| Step: 0
Training loss: 1.1291744709014893
Validation loss: 1.7674391859321184

Epoch: 6| Step: 1
Training loss: 1.5116225481033325
Validation loss: 1.8646693550130373

Epoch: 6| Step: 2
Training loss: 1.7932610511779785
Validation loss: 1.8425847868765555

Epoch: 6| Step: 3
Training loss: 1.6751306056976318
Validation loss: 1.8492093214424707

Epoch: 6| Step: 4
Training loss: 1.4706621170043945
Validation loss: 1.8490181981876332

Epoch: 6| Step: 5
Training loss: 1.2435717582702637
Validation loss: 1.8103838300192228

Epoch: 6| Step: 6
Training loss: 2.27860689163208
Validation loss: 1.8471253379698722

Epoch: 6| Step: 7
Training loss: 1.5513544082641602
Validation loss: 1.8160198221924484

Epoch: 6| Step: 8
Training loss: 1.099156379699707
Validation loss: 1.8337268265344764

Epoch: 6| Step: 9
Training loss: 1.496543288230896
Validation loss: 1.8110279344743299

Epoch: 6| Step: 10
Training loss: 1.291580080986023
Validation loss: 1.8502492263752928

Epoch: 6| Step: 11
Training loss: 1.8207225799560547
Validation loss: 1.8521743718013968

Epoch: 6| Step: 12
Training loss: 0.9253637790679932
Validation loss: 1.7746404999045915

Epoch: 6| Step: 13
Training loss: 1.7269320487976074
Validation loss: 1.8021656415795768

Epoch: 327| Step: 0
Training loss: 1.3169941902160645
Validation loss: 1.7972947609040044

Epoch: 6| Step: 1
Training loss: 1.371819019317627
Validation loss: 1.8323058338575466

Epoch: 6| Step: 2
Training loss: 1.220107078552246
Validation loss: 1.8006790338024017

Epoch: 6| Step: 3
Training loss: 1.3183969259262085
Validation loss: 1.8049698260522657

Epoch: 6| Step: 4
Training loss: 0.7776302099227905
Validation loss: 1.8084344556254726

Epoch: 6| Step: 5
Training loss: 1.8822312355041504
Validation loss: 1.8049052633265013

Epoch: 6| Step: 6
Training loss: 1.6428313255310059
Validation loss: 1.7877494186483405

Epoch: 6| Step: 7
Training loss: 1.535083532333374
Validation loss: 1.8267768070261965

Epoch: 6| Step: 8
Training loss: 1.8851615190505981
Validation loss: 1.8278732338259298

Epoch: 6| Step: 9
Training loss: 1.2859002351760864
Validation loss: 1.8726652873459684

Epoch: 6| Step: 10
Training loss: 1.3402833938598633
Validation loss: 1.8060340637801795

Epoch: 6| Step: 11
Training loss: 1.7508963346481323
Validation loss: 1.8256454647228282

Epoch: 6| Step: 12
Training loss: 1.4404009580612183
Validation loss: 1.8801402404744139

Epoch: 6| Step: 13
Training loss: 1.7038065195083618
Validation loss: 1.7617571674367434

Epoch: 328| Step: 0
Training loss: 1.6763546466827393
Validation loss: 1.783437869882071

Epoch: 6| Step: 1
Training loss: 1.4924116134643555
Validation loss: 1.8245129995448615

Epoch: 6| Step: 2
Training loss: 2.426846981048584
Validation loss: 1.7573348860586844

Epoch: 6| Step: 3
Training loss: 1.5934741497039795
Validation loss: 1.808399595240111

Epoch: 6| Step: 4
Training loss: 1.6862170696258545
Validation loss: 1.8295424074255011

Epoch: 6| Step: 5
Training loss: 1.4366352558135986
Validation loss: 1.7948883028440579

Epoch: 6| Step: 6
Training loss: 1.5208767652511597
Validation loss: 1.8017710588311637

Epoch: 6| Step: 7
Training loss: 0.9181740283966064
Validation loss: 1.8451824149777811

Epoch: 6| Step: 8
Training loss: 1.7811402082443237
Validation loss: 1.77811255890836

Epoch: 6| Step: 9
Training loss: 1.4451745748519897
Validation loss: 1.7993110905411422

Epoch: 6| Step: 10
Training loss: 1.6687768697738647
Validation loss: 1.8173651720887871

Epoch: 6| Step: 11
Training loss: 0.9308273792266846
Validation loss: 1.8314124538052468

Epoch: 6| Step: 12
Training loss: 1.1335166692733765
Validation loss: 1.8235530507179998

Epoch: 6| Step: 13
Training loss: 1.272188425064087
Validation loss: 1.7970188048578077

Epoch: 329| Step: 0
Training loss: 0.8041021823883057
Validation loss: 1.8511900171156852

Epoch: 6| Step: 1
Training loss: 1.6666182279586792
Validation loss: 1.8902138586967223

Epoch: 6| Step: 2
Training loss: 0.9007939100265503
Validation loss: 1.8403670069991902

Epoch: 6| Step: 3
Training loss: 1.8329399824142456
Validation loss: 1.8098368439623105

Epoch: 6| Step: 4
Training loss: 1.820204496383667
Validation loss: 1.8222563984573528

Epoch: 6| Step: 5
Training loss: 2.4940600395202637
Validation loss: 1.8043976932443597

Epoch: 6| Step: 6
Training loss: 1.4887845516204834
Validation loss: 1.8333369634484733

Epoch: 6| Step: 7
Training loss: 1.071157693862915
Validation loss: 1.771417724188938

Epoch: 6| Step: 8
Training loss: 1.662832498550415
Validation loss: 1.8091656187529206

Epoch: 6| Step: 9
Training loss: 0.953342854976654
Validation loss: 1.7932273034126527

Epoch: 6| Step: 10
Training loss: 1.568150520324707
Validation loss: 1.8038370429828603

Epoch: 6| Step: 11
Training loss: 1.458006739616394
Validation loss: 1.8064706517804054

Epoch: 6| Step: 12
Training loss: 1.299609661102295
Validation loss: 1.782370203284807

Epoch: 6| Step: 13
Training loss: 0.9542391300201416
Validation loss: 1.8281590874477098

Epoch: 330| Step: 0
Training loss: 1.0661529302597046
Validation loss: 1.7961710793997652

Epoch: 6| Step: 1
Training loss: 1.5868781805038452
Validation loss: 1.853432329752112

Epoch: 6| Step: 2
Training loss: 2.2916817665100098
Validation loss: 1.8459962567975443

Epoch: 6| Step: 3
Training loss: 1.1426515579223633
Validation loss: 1.849048169710303

Epoch: 6| Step: 4
Training loss: 1.8645216226577759
Validation loss: 1.7925068665576238

Epoch: 6| Step: 5
Training loss: 1.4850685596466064
Validation loss: 1.7706508623656405

Epoch: 6| Step: 6
Training loss: 1.590059757232666
Validation loss: 1.7793946291810723

Epoch: 6| Step: 7
Training loss: 1.5714997053146362
Validation loss: 1.7689572265071254

Epoch: 6| Step: 8
Training loss: 1.2191370725631714
Validation loss: 1.7757382277519471

Epoch: 6| Step: 9
Training loss: 1.3229501247406006
Validation loss: 1.8191300745933288

Epoch: 6| Step: 10
Training loss: 1.123594045639038
Validation loss: 1.817294527125615

Epoch: 6| Step: 11
Training loss: 1.2037227153778076
Validation loss: 1.8058489253444057

Epoch: 6| Step: 12
Training loss: 1.2908626794815063
Validation loss: 1.8021512454555881

Epoch: 6| Step: 13
Training loss: 2.366856575012207
Validation loss: 1.7814891158893544

Epoch: 331| Step: 0
Training loss: 1.2242615222930908
Validation loss: 1.817704906386714

Epoch: 6| Step: 1
Training loss: 1.4785542488098145
Validation loss: 1.7676024795860372

Epoch: 6| Step: 2
Training loss: 1.4784601926803589
Validation loss: 1.8075113399054414

Epoch: 6| Step: 3
Training loss: 1.1597232818603516
Validation loss: 1.8093078469717374

Epoch: 6| Step: 4
Training loss: 1.4918006658554077
Validation loss: 1.7622976713283087

Epoch: 6| Step: 5
Training loss: 0.8265928030014038
Validation loss: 1.8391794902022167

Epoch: 6| Step: 6
Training loss: 2.0273942947387695
Validation loss: 1.846051396862153

Epoch: 6| Step: 7
Training loss: 1.5952190160751343
Validation loss: 1.854281146039245

Epoch: 6| Step: 8
Training loss: 1.5892091989517212
Validation loss: 1.7974002950934953

Epoch: 6| Step: 9
Training loss: 1.74040949344635
Validation loss: 1.8520865235277402

Epoch: 6| Step: 10
Training loss: 1.327845573425293
Validation loss: 1.76776808820745

Epoch: 6| Step: 11
Training loss: 1.732759952545166
Validation loss: 1.8316866197893698

Epoch: 6| Step: 12
Training loss: 1.3037054538726807
Validation loss: 1.787829319636027

Epoch: 6| Step: 13
Training loss: 1.2793083190917969
Validation loss: 1.815563126276898

Epoch: 332| Step: 0
Training loss: 0.854313850402832
Validation loss: 1.7736390303539973

Epoch: 6| Step: 1
Training loss: 1.281089186668396
Validation loss: 1.8196229050236363

Epoch: 6| Step: 2
Training loss: 1.4217863082885742
Validation loss: 1.886862813785512

Epoch: 6| Step: 3
Training loss: 1.3770242929458618
Validation loss: 1.8044910430908203

Epoch: 6| Step: 4
Training loss: 1.9390078783035278
Validation loss: 1.849277219464702

Epoch: 6| Step: 5
Training loss: 1.8880993127822876
Validation loss: 1.8591096978033743

Epoch: 6| Step: 6
Training loss: 1.45009446144104
Validation loss: 1.8293999420699252

Epoch: 6| Step: 7
Training loss: 2.0608386993408203
Validation loss: 1.7845275658433155

Epoch: 6| Step: 8
Training loss: 1.301641821861267
Validation loss: 1.730719235635573

Epoch: 6| Step: 9
Training loss: 1.4766851663589478
Validation loss: 1.7927214714788622

Epoch: 6| Step: 10
Training loss: 1.4815435409545898
Validation loss: 1.840162387458227

Epoch: 6| Step: 11
Training loss: 1.0631667375564575
Validation loss: 1.8591384733876875

Epoch: 6| Step: 12
Training loss: 0.6740947365760803
Validation loss: 1.8681916203550113

Epoch: 6| Step: 13
Training loss: 1.2133949995040894
Validation loss: 1.7601426301463958

Epoch: 333| Step: 0
Training loss: 1.6524574756622314
Validation loss: 1.7745187333835069

Epoch: 6| Step: 1
Training loss: 1.192736029624939
Validation loss: 1.7605866206589567

Epoch: 6| Step: 2
Training loss: 1.728344440460205
Validation loss: 1.8130291918272614

Epoch: 6| Step: 3
Training loss: 2.0301079750061035
Validation loss: 1.8270974300240959

Epoch: 6| Step: 4
Training loss: 1.6820955276489258
Validation loss: 1.830226493138139

Epoch: 6| Step: 5
Training loss: 1.7425098419189453
Validation loss: 1.8050104315562914

Epoch: 6| Step: 6
Training loss: 1.4195274114608765
Validation loss: 1.8015677108559558

Epoch: 6| Step: 7
Training loss: 1.4308075904846191
Validation loss: 1.8462151365895425

Epoch: 6| Step: 8
Training loss: 0.7550263404846191
Validation loss: 1.8144970863096175

Epoch: 6| Step: 9
Training loss: 1.1586735248565674
Validation loss: 1.7666665174627816

Epoch: 6| Step: 10
Training loss: 1.4652247428894043
Validation loss: 1.831766607940838

Epoch: 6| Step: 11
Training loss: 1.6625723838806152
Validation loss: 1.8927008375044791

Epoch: 6| Step: 12
Training loss: 1.1423254013061523
Validation loss: 1.7793865896040393

Epoch: 6| Step: 13
Training loss: 1.2140341997146606
Validation loss: 1.765839547239324

Epoch: 334| Step: 0
Training loss: 1.5038411617279053
Validation loss: 1.8386877300918743

Epoch: 6| Step: 1
Training loss: 1.2773230075836182
Validation loss: 1.8446057163259035

Epoch: 6| Step: 2
Training loss: 1.439550518989563
Validation loss: 1.8813898871021886

Epoch: 6| Step: 3
Training loss: 0.9466120004653931
Validation loss: 1.8650138211506668

Epoch: 6| Step: 4
Training loss: 2.010659694671631
Validation loss: 1.8606453928896176

Epoch: 6| Step: 5
Training loss: 1.4339925050735474
Validation loss: 1.8373536550870506

Epoch: 6| Step: 6
Training loss: 1.140275478363037
Validation loss: 1.860258638217885

Epoch: 6| Step: 7
Training loss: 1.3423839807510376
Validation loss: 1.7718986413812126

Epoch: 6| Step: 8
Training loss: 1.746199369430542
Validation loss: 1.8182290728374193

Epoch: 6| Step: 9
Training loss: 1.2398359775543213
Validation loss: 1.7934948859676239

Epoch: 6| Step: 10
Training loss: 1.2913825511932373
Validation loss: 1.84149089167195

Epoch: 6| Step: 11
Training loss: 1.5510075092315674
Validation loss: 1.78832080030954

Epoch: 6| Step: 12
Training loss: 1.357804298400879
Validation loss: 1.7760849601478987

Epoch: 6| Step: 13
Training loss: 2.2650094032287598
Validation loss: 1.7509848661320184

Epoch: 335| Step: 0
Training loss: 1.3050594329833984
Validation loss: 1.7867147896879463

Epoch: 6| Step: 1
Training loss: 1.3322720527648926
Validation loss: 1.7829548851136239

Epoch: 6| Step: 2
Training loss: 1.1540297269821167
Validation loss: 1.7882855720417474

Epoch: 6| Step: 3
Training loss: 1.0622014999389648
Validation loss: 1.7478024626290927

Epoch: 6| Step: 4
Training loss: 1.8334689140319824
Validation loss: 1.7799915677757674

Epoch: 6| Step: 5
Training loss: 1.7232506275177002
Validation loss: 1.8216605173644198

Epoch: 6| Step: 6
Training loss: 1.5124928951263428
Validation loss: 1.817398250743907

Epoch: 6| Step: 7
Training loss: 1.7505453824996948
Validation loss: 1.7405286809449554

Epoch: 6| Step: 8
Training loss: 1.3739699125289917
Validation loss: 1.8073147343051048

Epoch: 6| Step: 9
Training loss: 1.4225656986236572
Validation loss: 1.8382593662508073

Epoch: 6| Step: 10
Training loss: 1.125047206878662
Validation loss: 1.7662230101964806

Epoch: 6| Step: 11
Training loss: 1.6356091499328613
Validation loss: 1.8017262515201364

Epoch: 6| Step: 12
Training loss: 1.7610000371932983
Validation loss: 1.8282754241779287

Epoch: 6| Step: 13
Training loss: 0.8253244161605835
Validation loss: 1.7953338648683281

Epoch: 336| Step: 0
Training loss: 1.3095052242279053
Validation loss: 1.820525562891396

Epoch: 6| Step: 1
Training loss: 0.8863691091537476
Validation loss: 1.8218831234080817

Epoch: 6| Step: 2
Training loss: 1.6717692613601685
Validation loss: 1.8366740442091418

Epoch: 6| Step: 3
Training loss: 1.2734315395355225
Validation loss: 1.806465519371853

Epoch: 6| Step: 4
Training loss: 0.9330275654792786
Validation loss: 1.7941085241174186

Epoch: 6| Step: 5
Training loss: 1.1195662021636963
Validation loss: 1.7843835956306868

Epoch: 6| Step: 6
Training loss: 1.6508679389953613
Validation loss: 1.7653988586959017

Epoch: 6| Step: 7
Training loss: 1.5625073909759521
Validation loss: 1.8260071533982472

Epoch: 6| Step: 8
Training loss: 1.187849998474121
Validation loss: 1.819712185090588

Epoch: 6| Step: 9
Training loss: 1.5570799112319946
Validation loss: 1.7774975543381066

Epoch: 6| Step: 10
Training loss: 1.370572805404663
Validation loss: 1.8176547288894653

Epoch: 6| Step: 11
Training loss: 2.1014068126678467
Validation loss: 1.7467912922623337

Epoch: 6| Step: 12
Training loss: 1.7557469606399536
Validation loss: 1.758385250645299

Epoch: 6| Step: 13
Training loss: 2.0071170330047607
Validation loss: 1.844409240189419

Epoch: 337| Step: 0
Training loss: 1.1801097393035889
Validation loss: 1.8319639441787556

Epoch: 6| Step: 1
Training loss: 1.3955134153366089
Validation loss: 1.7552703067820559

Epoch: 6| Step: 2
Training loss: 1.0896422863006592
Validation loss: 1.8188354430660125

Epoch: 6| Step: 3
Training loss: 1.608285903930664
Validation loss: 1.754712563689037

Epoch: 6| Step: 4
Training loss: 1.472787857055664
Validation loss: 1.8204696691164406

Epoch: 6| Step: 5
Training loss: 1.6215453147888184
Validation loss: 1.7417560854265768

Epoch: 6| Step: 6
Training loss: 1.0634522438049316
Validation loss: 1.7774824673129666

Epoch: 6| Step: 7
Training loss: 1.9203616380691528
Validation loss: 1.7424154589253087

Epoch: 6| Step: 8
Training loss: 1.300155758857727
Validation loss: 1.7730185293382215

Epoch: 6| Step: 9
Training loss: 1.2360754013061523
Validation loss: 1.814468442752797

Epoch: 6| Step: 10
Training loss: 1.5139981508255005
Validation loss: 1.8867186320725309

Epoch: 6| Step: 11
Training loss: 1.9758107662200928
Validation loss: 1.7508531719125726

Epoch: 6| Step: 12
Training loss: 1.3562140464782715
Validation loss: 1.8186674643588323

Epoch: 6| Step: 13
Training loss: 1.3697550296783447
Validation loss: 1.7854278267070811

Epoch: 338| Step: 0
Training loss: 1.253550410270691
Validation loss: 1.8472131477889193

Epoch: 6| Step: 1
Training loss: 1.1618715524673462
Validation loss: 1.8088218601801063

Epoch: 6| Step: 2
Training loss: 1.3841160535812378
Validation loss: 1.8036463722105949

Epoch: 6| Step: 3
Training loss: 1.3590683937072754
Validation loss: 1.858053958544167

Epoch: 6| Step: 4
Training loss: 1.7856099605560303
Validation loss: 1.7990616700982536

Epoch: 6| Step: 5
Training loss: 1.602344274520874
Validation loss: 1.8093560100883566

Epoch: 6| Step: 6
Training loss: 1.59903085231781
Validation loss: 1.793471013346026

Epoch: 6| Step: 7
Training loss: 1.8204514980316162
Validation loss: 1.826294969486934

Epoch: 6| Step: 8
Training loss: 1.761859655380249
Validation loss: 1.7478885445543515

Epoch: 6| Step: 9
Training loss: 1.3599724769592285
Validation loss: 1.780973643384954

Epoch: 6| Step: 10
Training loss: 1.3199419975280762
Validation loss: 1.7874818040478615

Epoch: 6| Step: 11
Training loss: 1.3415971994400024
Validation loss: 1.8254440625508626

Epoch: 6| Step: 12
Training loss: 1.221285343170166
Validation loss: 1.741432746251424

Epoch: 6| Step: 13
Training loss: 1.5347825288772583
Validation loss: 1.8088231202094787

Epoch: 339| Step: 0
Training loss: 1.2167885303497314
Validation loss: 1.79727550091282

Epoch: 6| Step: 1
Training loss: 1.99762761592865
Validation loss: 1.7538681248182892

Epoch: 6| Step: 2
Training loss: 1.434798240661621
Validation loss: 1.8362918784541469

Epoch: 6| Step: 3
Training loss: 1.779858946800232
Validation loss: 1.808218740647839

Epoch: 6| Step: 4
Training loss: 1.6897592544555664
Validation loss: 1.7874738490709694

Epoch: 6| Step: 5
Training loss: 1.6769261360168457
Validation loss: 1.8249998438742854

Epoch: 6| Step: 6
Training loss: 0.9705742597579956
Validation loss: 1.7920119454783778

Epoch: 6| Step: 7
Training loss: 1.229438066482544
Validation loss: 1.7967429571254279

Epoch: 6| Step: 8
Training loss: 1.0559823513031006
Validation loss: 1.770810991205195

Epoch: 6| Step: 9
Training loss: 1.5379326343536377
Validation loss: 1.7927685219754455

Epoch: 6| Step: 10
Training loss: 1.1619757413864136
Validation loss: 1.8044881000313708

Epoch: 6| Step: 11
Training loss: 1.774503231048584
Validation loss: 1.7456652592587214

Epoch: 6| Step: 12
Training loss: 1.3175400495529175
Validation loss: 1.8429195521980204

Epoch: 6| Step: 13
Training loss: 1.556365966796875
Validation loss: 1.8023660567498976

Epoch: 340| Step: 0
Training loss: 1.5074591636657715
Validation loss: 1.7861454012573406

Epoch: 6| Step: 1
Training loss: 1.4227529764175415
Validation loss: 1.8121843446967423

Epoch: 6| Step: 2
Training loss: 2.013509750366211
Validation loss: 1.8504201263509772

Epoch: 6| Step: 3
Training loss: 1.7982205152511597
Validation loss: 1.7887490257140128

Epoch: 6| Step: 4
Training loss: 1.2734003067016602
Validation loss: 1.823431214978618

Epoch: 6| Step: 5
Training loss: 1.5917799472808838
Validation loss: 1.7440419773901663

Epoch: 6| Step: 6
Training loss: 1.1794495582580566
Validation loss: 1.9047465119310605

Epoch: 6| Step: 7
Training loss: 1.2549152374267578
Validation loss: 1.7801515145968365

Epoch: 6| Step: 8
Training loss: 1.5549097061157227
Validation loss: 1.7973451922016759

Epoch: 6| Step: 9
Training loss: 1.9957561492919922
Validation loss: 1.8039948466003581

Epoch: 6| Step: 10
Training loss: 0.9579216241836548
Validation loss: 1.7977061246031074

Epoch: 6| Step: 11
Training loss: 1.1679704189300537
Validation loss: 1.830392563214866

Epoch: 6| Step: 12
Training loss: 1.676795482635498
Validation loss: 1.813705458435961

Epoch: 6| Step: 13
Training loss: 0.9438027143478394
Validation loss: 1.8274760323186074

Epoch: 341| Step: 0
Training loss: 1.2529363632202148
Validation loss: 1.798655903467568

Epoch: 6| Step: 1
Training loss: 0.9546201229095459
Validation loss: 1.7861610599743423

Epoch: 6| Step: 2
Training loss: 2.224349021911621
Validation loss: 1.7673010954292871

Epoch: 6| Step: 3
Training loss: 1.9202344417572021
Validation loss: 1.767749277494287

Epoch: 6| Step: 4
Training loss: 1.3119245767593384
Validation loss: 1.8267633543219617

Epoch: 6| Step: 5
Training loss: 1.9282933473587036
Validation loss: 1.7714581848472677

Epoch: 6| Step: 6
Training loss: 0.8380637168884277
Validation loss: 1.8015905272576116

Epoch: 6| Step: 7
Training loss: 1.4837372303009033
Validation loss: 1.7350149744300432

Epoch: 6| Step: 8
Training loss: 1.6777663230895996
Validation loss: 1.842372081613028

Epoch: 6| Step: 9
Training loss: 1.0656242370605469
Validation loss: 1.837746036949978

Epoch: 6| Step: 10
Training loss: 1.3920564651489258
Validation loss: 1.8084485530853271

Epoch: 6| Step: 11
Training loss: 0.9779701828956604
Validation loss: 1.7630936330364597

Epoch: 6| Step: 12
Training loss: 1.62564218044281
Validation loss: 1.8531403515928535

Epoch: 6| Step: 13
Training loss: 1.3360323905944824
Validation loss: 1.817691800414875

Epoch: 342| Step: 0
Training loss: 1.188849687576294
Validation loss: 1.8560172934685983

Epoch: 6| Step: 1
Training loss: 2.2042880058288574
Validation loss: 1.798160937524611

Epoch: 6| Step: 2
Training loss: 1.4217946529388428
Validation loss: 1.766587249694332

Epoch: 6| Step: 3
Training loss: 1.2435308694839478
Validation loss: 1.8198641512983589

Epoch: 6| Step: 4
Training loss: 2.0720138549804688
Validation loss: 1.7996143999920096

Epoch: 6| Step: 5
Training loss: 1.6004769802093506
Validation loss: 1.826489185133288

Epoch: 6| Step: 6
Training loss: 1.3416616916656494
Validation loss: 1.8355282634817145

Epoch: 6| Step: 7
Training loss: 1.3220713138580322
Validation loss: 1.787233934607557

Epoch: 6| Step: 8
Training loss: 1.3063924312591553
Validation loss: 1.8337414546679425

Epoch: 6| Step: 9
Training loss: 0.60994952917099
Validation loss: 1.8366090956554617

Epoch: 6| Step: 10
Training loss: 1.5297282934188843
Validation loss: 1.7810054017651467

Epoch: 6| Step: 11
Training loss: 1.3232312202453613
Validation loss: 1.8015264221417007

Epoch: 6| Step: 12
Training loss: 1.4623959064483643
Validation loss: 1.8474806739437966

Epoch: 6| Step: 13
Training loss: 1.0747066736221313
Validation loss: 1.866960479367164

Epoch: 343| Step: 0
Training loss: 0.9641284942626953
Validation loss: 1.8580887497112315

Epoch: 6| Step: 1
Training loss: 1.800257682800293
Validation loss: 1.821470159356312

Epoch: 6| Step: 2
Training loss: 1.45914888381958
Validation loss: 1.8335075609145626

Epoch: 6| Step: 3
Training loss: 1.3678911924362183
Validation loss: 1.835549957008772

Epoch: 6| Step: 4
Training loss: 1.3649648427963257
Validation loss: 1.8771189143580775

Epoch: 6| Step: 5
Training loss: 1.6611909866333008
Validation loss: 1.8580521819412068

Epoch: 6| Step: 6
Training loss: 1.9908149242401123
Validation loss: 1.772258968763454

Epoch: 6| Step: 7
Training loss: 1.5708825588226318
Validation loss: 1.8264033871312295

Epoch: 6| Step: 8
Training loss: 1.3139121532440186
Validation loss: 1.768515020288447

Epoch: 6| Step: 9
Training loss: 1.3668100833892822
Validation loss: 1.821417623950589

Epoch: 6| Step: 10
Training loss: 1.650493860244751
Validation loss: 1.807167519805252

Epoch: 6| Step: 11
Training loss: 1.6235612630844116
Validation loss: 1.7926696346652122

Epoch: 6| Step: 12
Training loss: 1.1752630472183228
Validation loss: 1.816877313839492

Epoch: 6| Step: 13
Training loss: 1.0050855875015259
Validation loss: 1.8166183707534627

Epoch: 344| Step: 0
Training loss: 1.3168573379516602
Validation loss: 1.7700151628063572

Epoch: 6| Step: 1
Training loss: 0.42063474655151367
Validation loss: 1.8051592303860573

Epoch: 6| Step: 2
Training loss: 1.2514925003051758
Validation loss: 1.7578438430704095

Epoch: 6| Step: 3
Training loss: 1.9684748649597168
Validation loss: 1.7960635282660042

Epoch: 6| Step: 4
Training loss: 1.5995967388153076
Validation loss: 1.7451013544554352

Epoch: 6| Step: 5
Training loss: 1.3342359066009521
Validation loss: 1.8103101984147103

Epoch: 6| Step: 6
Training loss: 1.4471760988235474
Validation loss: 1.7930001776705506

Epoch: 6| Step: 7
Training loss: 1.3126282691955566
Validation loss: 1.8408799222720567

Epoch: 6| Step: 8
Training loss: 1.2747386693954468
Validation loss: 1.7853020070701517

Epoch: 6| Step: 9
Training loss: 1.2456876039505005
Validation loss: 1.8145101660041398

Epoch: 6| Step: 10
Training loss: 1.597468614578247
Validation loss: 1.8044622046973116

Epoch: 6| Step: 11
Training loss: 1.2477301359176636
Validation loss: 1.790840756508612

Epoch: 6| Step: 12
Training loss: 1.7290639877319336
Validation loss: 1.8005851455914077

Epoch: 6| Step: 13
Training loss: 2.367750883102417
Validation loss: 1.8350961477525773

Epoch: 345| Step: 0
Training loss: 1.0769624710083008
Validation loss: 1.8011446140145744

Epoch: 6| Step: 1
Training loss: 2.326165199279785
Validation loss: 1.7958017920935025

Epoch: 6| Step: 2
Training loss: 1.065430760383606
Validation loss: 1.8826078112407396

Epoch: 6| Step: 3
Training loss: 1.0924062728881836
Validation loss: 1.840741656159842

Epoch: 6| Step: 4
Training loss: 1.9068340063095093
Validation loss: 1.7823711620864047

Epoch: 6| Step: 5
Training loss: 1.3600835800170898
Validation loss: 1.8011057992135324

Epoch: 6| Step: 6
Training loss: 1.740547776222229
Validation loss: 1.8362940870305544

Epoch: 6| Step: 7
Training loss: 1.6364116668701172
Validation loss: 1.8051661650339763

Epoch: 6| Step: 8
Training loss: 1.5071662664413452
Validation loss: 1.8527695389204129

Epoch: 6| Step: 9
Training loss: 1.637878179550171
Validation loss: 1.7829285616515784

Epoch: 6| Step: 10
Training loss: 1.044459342956543
Validation loss: 1.8255729893202424

Epoch: 6| Step: 11
Training loss: 0.9882588386535645
Validation loss: 1.7834179170670048

Epoch: 6| Step: 12
Training loss: 1.021185278892517
Validation loss: 1.8487487441749983

Epoch: 6| Step: 13
Training loss: 1.51521635055542
Validation loss: 1.7844436463489328

Epoch: 346| Step: 0
Training loss: 0.9508216977119446
Validation loss: 1.8011898430444861

Epoch: 6| Step: 1
Training loss: 1.4440425634384155
Validation loss: 1.8492663368102042

Epoch: 6| Step: 2
Training loss: 2.0448434352874756
Validation loss: 1.9084194142331359

Epoch: 6| Step: 3
Training loss: 1.3686058521270752
Validation loss: 1.8030390226712791

Epoch: 6| Step: 4
Training loss: 0.8277047872543335
Validation loss: 1.858115832010905

Epoch: 6| Step: 5
Training loss: 1.7553930282592773
Validation loss: 1.8410711878089494

Epoch: 6| Step: 6
Training loss: 1.5839903354644775
Validation loss: 1.811561147371928

Epoch: 6| Step: 7
Training loss: 1.4941915273666382
Validation loss: 1.7688917293343493

Epoch: 6| Step: 8
Training loss: 1.1314939260482788
Validation loss: 1.8152247769858247

Epoch: 6| Step: 9
Training loss: 1.1514081954956055
Validation loss: 1.7989070223223778

Epoch: 6| Step: 10
Training loss: 1.5218276977539062
Validation loss: 1.818269274568045

Epoch: 6| Step: 11
Training loss: 1.450545072555542
Validation loss: 1.81745683762335

Epoch: 6| Step: 12
Training loss: 2.205381155014038
Validation loss: 1.792350172996521

Epoch: 6| Step: 13
Training loss: 0.8895454406738281
Validation loss: 1.811745500051847

Epoch: 347| Step: 0
Training loss: 1.7219923734664917
Validation loss: 1.8022964821066907

Epoch: 6| Step: 1
Training loss: 1.163190245628357
Validation loss: 1.7767948463398924

Epoch: 6| Step: 2
Training loss: 1.3762261867523193
Validation loss: 1.7787830445074266

Epoch: 6| Step: 3
Training loss: 1.1962188482284546
Validation loss: 1.7951246974288777

Epoch: 6| Step: 4
Training loss: 1.7006311416625977
Validation loss: 1.8548670058609338

Epoch: 6| Step: 5
Training loss: 1.1540967226028442
Validation loss: 1.7626145450017785

Epoch: 6| Step: 6
Training loss: 1.388221263885498
Validation loss: 1.7699834967172274

Epoch: 6| Step: 7
Training loss: 1.409162163734436
Validation loss: 1.812571269209667

Epoch: 6| Step: 8
Training loss: 1.3683935403823853
Validation loss: 1.8165260296995922

Epoch: 6| Step: 9
Training loss: 1.2622580528259277
Validation loss: 1.829308638008692

Epoch: 6| Step: 10
Training loss: 1.2850700616836548
Validation loss: 1.8277374377814672

Epoch: 6| Step: 11
Training loss: 1.7925810813903809
Validation loss: 1.796484144785071

Epoch: 6| Step: 12
Training loss: 1.7748959064483643
Validation loss: 1.8511506331864225

Epoch: 6| Step: 13
Training loss: 0.8009968400001526
Validation loss: 1.8293388633317844

Epoch: 348| Step: 0
Training loss: 0.8463117480278015
Validation loss: 1.800748308499654

Epoch: 6| Step: 1
Training loss: 1.5909903049468994
Validation loss: 1.821849666615968

Epoch: 6| Step: 2
Training loss: 1.4999120235443115
Validation loss: 1.851281822368663

Epoch: 6| Step: 3
Training loss: 1.7189521789550781
Validation loss: 1.8219297201402727

Epoch: 6| Step: 4
Training loss: 1.4841179847717285
Validation loss: 1.7975742560560986

Epoch: 6| Step: 5
Training loss: 1.1056182384490967
Validation loss: 1.9099254800427345

Epoch: 6| Step: 6
Training loss: 0.7674671411514282
Validation loss: 1.8529792293425529

Epoch: 6| Step: 7
Training loss: 1.1213213205337524
Validation loss: 1.7972562184897802

Epoch: 6| Step: 8
Training loss: 1.4734351634979248
Validation loss: 1.8079424468419885

Epoch: 6| Step: 9
Training loss: 1.3382606506347656
Validation loss: 1.7990554609606344

Epoch: 6| Step: 10
Training loss: 2.058253765106201
Validation loss: 1.7701540121468164

Epoch: 6| Step: 11
Training loss: 1.5109248161315918
Validation loss: 1.7400385961737683

Epoch: 6| Step: 12
Training loss: 1.6374120712280273
Validation loss: 1.8033712217884679

Epoch: 6| Step: 13
Training loss: 1.4473223686218262
Validation loss: 1.8153691701991583

Epoch: 349| Step: 0
Training loss: 1.6363856792449951
Validation loss: 1.801636262606549

Epoch: 6| Step: 1
Training loss: 1.0608779191970825
Validation loss: 1.828705072402954

Epoch: 6| Step: 2
Training loss: 1.0616538524627686
Validation loss: 1.764926238726544

Epoch: 6| Step: 3
Training loss: 1.8030033111572266
Validation loss: 1.8299080351347565

Epoch: 6| Step: 4
Training loss: 1.289071798324585
Validation loss: 1.8526611776762112

Epoch: 6| Step: 5
Training loss: 1.1411831378936768
Validation loss: 1.8361375511333506

Epoch: 6| Step: 6
Training loss: 1.173729419708252
Validation loss: 1.8150081916521954

Epoch: 6| Step: 7
Training loss: 1.070333480834961
Validation loss: 1.7806435451712659

Epoch: 6| Step: 8
Training loss: 1.7055999040603638
Validation loss: 1.8419723049286874

Epoch: 6| Step: 9
Training loss: 1.504021406173706
Validation loss: 1.8128481603437854

Epoch: 6| Step: 10
Training loss: 1.080918550491333
Validation loss: 1.7791665805283414

Epoch: 6| Step: 11
Training loss: 1.8606576919555664
Validation loss: 1.7701855385175316

Epoch: 6| Step: 12
Training loss: 1.2686452865600586
Validation loss: 1.7891322976799422

Epoch: 6| Step: 13
Training loss: 1.400442123413086
Validation loss: 1.7972201198659918

Epoch: 350| Step: 0
Training loss: 1.2094618082046509
Validation loss: 1.7992213054369854

Epoch: 6| Step: 1
Training loss: 1.6612071990966797
Validation loss: 1.7565421647922967

Epoch: 6| Step: 2
Training loss: 1.364732027053833
Validation loss: 1.8691984632963776

Epoch: 6| Step: 3
Training loss: 1.2265335321426392
Validation loss: 1.8333520799554803

Epoch: 6| Step: 4
Training loss: 1.8608438968658447
Validation loss: 1.820421564963556

Epoch: 6| Step: 5
Training loss: 1.4672574996948242
Validation loss: 1.7654138111299085

Epoch: 6| Step: 6
Training loss: 1.5781548023223877
Validation loss: 1.7799653724957538

Epoch: 6| Step: 7
Training loss: 1.5787684917449951
Validation loss: 1.8512707948684692

Epoch: 6| Step: 8
Training loss: 1.1321979761123657
Validation loss: 1.7937024178043488

Epoch: 6| Step: 9
Training loss: 1.0720126628875732
Validation loss: 1.788376259547408

Epoch: 6| Step: 10
Training loss: 1.2677123546600342
Validation loss: 1.8008946731526365

Epoch: 6| Step: 11
Training loss: 1.9083919525146484
Validation loss: 1.8095601758649271

Epoch: 6| Step: 12
Training loss: 1.205367088317871
Validation loss: 1.768528840875113

Epoch: 6| Step: 13
Training loss: 0.8036147952079773
Validation loss: 1.818536340549428

Epoch: 351| Step: 0
Training loss: 1.8275378942489624
Validation loss: 1.8572336678863854

Epoch: 6| Step: 1
Training loss: 1.282966136932373
Validation loss: 1.8106651690698439

Epoch: 6| Step: 2
Training loss: 1.2839553356170654
Validation loss: 1.7982183758930494

Epoch: 6| Step: 3
Training loss: 0.9330075979232788
Validation loss: 1.8167093223141086

Epoch: 6| Step: 4
Training loss: 1.71408212184906
Validation loss: 1.7676343123118083

Epoch: 6| Step: 5
Training loss: 1.0536288022994995
Validation loss: 1.8001159288549935

Epoch: 6| Step: 6
Training loss: 1.1708987951278687
Validation loss: 1.8222479128068494

Epoch: 6| Step: 7
Training loss: 1.5510289669036865
Validation loss: 1.8096606372505106

Epoch: 6| Step: 8
Training loss: 1.1581099033355713
Validation loss: 1.7862755637015066

Epoch: 6| Step: 9
Training loss: 0.8398401141166687
Validation loss: 1.7779878672733103

Epoch: 6| Step: 10
Training loss: 1.8543319702148438
Validation loss: 1.8223543128659647

Epoch: 6| Step: 11
Training loss: 1.5743672847747803
Validation loss: 1.8197654831794001

Epoch: 6| Step: 12
Training loss: 1.0782890319824219
Validation loss: 1.7933128136460499

Epoch: 6| Step: 13
Training loss: 1.7601300477981567
Validation loss: 1.8329349192239905

Epoch: 352| Step: 0
Training loss: 1.6032283306121826
Validation loss: 1.735045588144692

Epoch: 6| Step: 1
Training loss: 1.5827593803405762
Validation loss: 1.7859740052171933

Epoch: 6| Step: 2
Training loss: 1.3181242942810059
Validation loss: 1.7495603881856447

Epoch: 6| Step: 3
Training loss: 0.8014936447143555
Validation loss: 1.7468419459558302

Epoch: 6| Step: 4
Training loss: 1.5845942497253418
Validation loss: 1.7916539574182162

Epoch: 6| Step: 5
Training loss: 1.2698653936386108
Validation loss: 1.779413495012509

Epoch: 6| Step: 6
Training loss: 1.531366229057312
Validation loss: 1.8724600627858152

Epoch: 6| Step: 7
Training loss: 1.370305061340332
Validation loss: 1.8546477210137151

Epoch: 6| Step: 8
Training loss: 1.3754242658615112
Validation loss: 1.7943374495352469

Epoch: 6| Step: 9
Training loss: 2.220979690551758
Validation loss: 1.8204514390678816

Epoch: 6| Step: 10
Training loss: 0.9013282060623169
Validation loss: 1.7967135098672682

Epoch: 6| Step: 11
Training loss: 1.2053658962249756
Validation loss: 1.8428603615812076

Epoch: 6| Step: 12
Training loss: 1.3357993364334106
Validation loss: 1.80981917278741

Epoch: 6| Step: 13
Training loss: 1.1864454746246338
Validation loss: 1.8822853026851531

Epoch: 353| Step: 0
Training loss: 1.2700077295303345
Validation loss: 1.7683740790172289

Epoch: 6| Step: 1
Training loss: 1.7303251028060913
Validation loss: 1.793672739818532

Epoch: 6| Step: 2
Training loss: 0.8914370536804199
Validation loss: 1.7404184995159027

Epoch: 6| Step: 3
Training loss: 1.3561904430389404
Validation loss: 1.8600388060333908

Epoch: 6| Step: 4
Training loss: 1.236984372138977
Validation loss: 1.8168545871652582

Epoch: 6| Step: 5
Training loss: 1.5352977514266968
Validation loss: 1.7966727184992966

Epoch: 6| Step: 6
Training loss: 1.9545626640319824
Validation loss: 1.7912039641411073

Epoch: 6| Step: 7
Training loss: 1.4704009294509888
Validation loss: 1.805052166344017

Epoch: 6| Step: 8
Training loss: 1.4671598672866821
Validation loss: 1.7762586891010244

Epoch: 6| Step: 9
Training loss: 1.2518428564071655
Validation loss: 1.7987379489406463

Epoch: 6| Step: 10
Training loss: 0.9001470804214478
Validation loss: 1.8343671021922943

Epoch: 6| Step: 11
Training loss: 1.3208214044570923
Validation loss: 1.8392754972621959

Epoch: 6| Step: 12
Training loss: 1.4010279178619385
Validation loss: 1.8199435331488167

Epoch: 6| Step: 13
Training loss: 1.1623467206954956
Validation loss: 1.816557333033572

Epoch: 354| Step: 0
Training loss: 1.5022799968719482
Validation loss: 1.8127700949227938

Epoch: 6| Step: 1
Training loss: 1.1727817058563232
Validation loss: 1.8116184806311002

Epoch: 6| Step: 2
Training loss: 1.034586787223816
Validation loss: 1.7871389542856524

Epoch: 6| Step: 3
Training loss: 1.6767909526824951
Validation loss: 1.8352015454282042

Epoch: 6| Step: 4
Training loss: 1.9266036748886108
Validation loss: 1.8584267016380065

Epoch: 6| Step: 5
Training loss: 1.8113662004470825
Validation loss: 1.805918264132674

Epoch: 6| Step: 6
Training loss: 1.7131527662277222
Validation loss: 1.8293069972786853

Epoch: 6| Step: 7
Training loss: 1.1696877479553223
Validation loss: 1.8090412757729972

Epoch: 6| Step: 8
Training loss: 0.9416375756263733
Validation loss: 1.7660620263827744

Epoch: 6| Step: 9
Training loss: 1.3017582893371582
Validation loss: 1.8101023743229527

Epoch: 6| Step: 10
Training loss: 1.842883586883545
Validation loss: 1.807232879823254

Epoch: 6| Step: 11
Training loss: 1.4104266166687012
Validation loss: 1.7767488277086647

Epoch: 6| Step: 12
Training loss: 0.8618474006652832
Validation loss: 1.804830878011642

Epoch: 6| Step: 13
Training loss: 0.7805973291397095
Validation loss: 1.7423769056156118

Epoch: 355| Step: 0
Training loss: 1.0840330123901367
Validation loss: 1.831752775817789

Epoch: 6| Step: 1
Training loss: 1.6760287284851074
Validation loss: 1.841333164963671

Epoch: 6| Step: 2
Training loss: 1.3409485816955566
Validation loss: 1.847408740751205

Epoch: 6| Step: 3
Training loss: 1.0976150035858154
Validation loss: 1.8415958496832079

Epoch: 6| Step: 4
Training loss: 1.553874135017395
Validation loss: 1.8685911573389524

Epoch: 6| Step: 5
Training loss: 1.3493688106536865
Validation loss: 1.8036644381861533

Epoch: 6| Step: 6
Training loss: 1.4812791347503662
Validation loss: 1.8603076460540935

Epoch: 6| Step: 7
Training loss: 1.589168906211853
Validation loss: 1.8382988719530002

Epoch: 6| Step: 8
Training loss: 0.6775481700897217
Validation loss: 1.7677007336770334

Epoch: 6| Step: 9
Training loss: 1.2678903341293335
Validation loss: 1.762656086234636

Epoch: 6| Step: 10
Training loss: 1.2533769607543945
Validation loss: 1.774122025377007

Epoch: 6| Step: 11
Training loss: 1.8817801475524902
Validation loss: 1.8219184542215

Epoch: 6| Step: 12
Training loss: 1.5277049541473389
Validation loss: 1.8590507866233907

Epoch: 6| Step: 13
Training loss: 1.1828124523162842
Validation loss: 1.7986554304758708

Epoch: 356| Step: 0
Training loss: 0.6605445146560669
Validation loss: 1.7697280248006184

Epoch: 6| Step: 1
Training loss: 1.5396976470947266
Validation loss: 1.9013437840246386

Epoch: 6| Step: 2
Training loss: 1.3453795909881592
Validation loss: 1.7998644446813932

Epoch: 6| Step: 3
Training loss: 1.7811059951782227
Validation loss: 1.7696478930852746

Epoch: 6| Step: 4
Training loss: 1.3532969951629639
Validation loss: 1.8084009924242574

Epoch: 6| Step: 5
Training loss: 1.415632963180542
Validation loss: 1.7932614126513082

Epoch: 6| Step: 6
Training loss: 2.0400807857513428
Validation loss: 1.7865920502652404

Epoch: 6| Step: 7
Training loss: 1.1465272903442383
Validation loss: 1.757899562517802

Epoch: 6| Step: 8
Training loss: 1.9080727100372314
Validation loss: 1.7507997161598616

Epoch: 6| Step: 9
Training loss: 1.0248241424560547
Validation loss: 1.7715436937988445

Epoch: 6| Step: 10
Training loss: 1.156419038772583
Validation loss: 1.7846371499441003

Epoch: 6| Step: 11
Training loss: 1.2958067655563354
Validation loss: 1.7690230338804183

Epoch: 6| Step: 12
Training loss: 1.4755407571792603
Validation loss: 1.8298902280869023

Epoch: 6| Step: 13
Training loss: 1.552609920501709
Validation loss: 1.781924375923731

Epoch: 357| Step: 0
Training loss: 1.4682271480560303
Validation loss: 1.7850087881088257

Epoch: 6| Step: 1
Training loss: 0.7251769304275513
Validation loss: 1.8256753670272006

Epoch: 6| Step: 2
Training loss: 1.8050483465194702
Validation loss: 1.7845266365235852

Epoch: 6| Step: 3
Training loss: 1.2090415954589844
Validation loss: 1.7526672104353547

Epoch: 6| Step: 4
Training loss: 1.2100694179534912
Validation loss: 1.7278366242685625

Epoch: 6| Step: 5
Training loss: 1.281819224357605
Validation loss: 1.737835899476082

Epoch: 6| Step: 6
Training loss: 1.635467290878296
Validation loss: 1.7815203756414435

Epoch: 6| Step: 7
Training loss: 1.6984436511993408
Validation loss: 1.7913360544430312

Epoch: 6| Step: 8
Training loss: 1.931661605834961
Validation loss: 1.833360206696295

Epoch: 6| Step: 9
Training loss: 1.3160042762756348
Validation loss: 1.7639985904898694

Epoch: 6| Step: 10
Training loss: 1.5273475646972656
Validation loss: 1.8116577671420189

Epoch: 6| Step: 11
Training loss: 1.4418220520019531
Validation loss: 1.8558228887537473

Epoch: 6| Step: 12
Training loss: 1.0025336742401123
Validation loss: 1.725135878850055

Epoch: 6| Step: 13
Training loss: 0.9284076690673828
Validation loss: 1.8725669717275968

Epoch: 358| Step: 0
Training loss: 1.085436224937439
Validation loss: 1.8210710171730287

Epoch: 6| Step: 1
Training loss: 1.7004550695419312
Validation loss: 1.7512601549907396

Epoch: 6| Step: 2
Training loss: 0.938646674156189
Validation loss: 1.7877905189350087

Epoch: 6| Step: 3
Training loss: 1.2892189025878906
Validation loss: 1.8735440700284895

Epoch: 6| Step: 4
Training loss: 1.253415822982788
Validation loss: 1.782298090637371

Epoch: 6| Step: 5
Training loss: 0.7532782554626465
Validation loss: 1.8638028226872927

Epoch: 6| Step: 6
Training loss: 1.176528811454773
Validation loss: 1.809477981700692

Epoch: 6| Step: 7
Training loss: 2.1058473587036133
Validation loss: 1.78854799783358

Epoch: 6| Step: 8
Training loss: 0.7454201579093933
Validation loss: 1.8171573185151624

Epoch: 6| Step: 9
Training loss: 1.106806755065918
Validation loss: 1.7379658452926143

Epoch: 6| Step: 10
Training loss: 1.5927183628082275
Validation loss: 1.7991713836628904

Epoch: 6| Step: 11
Training loss: 1.7287659645080566
Validation loss: 1.7888009625096475

Epoch: 6| Step: 12
Training loss: 1.9502570629119873
Validation loss: 1.8316090927329114

Epoch: 6| Step: 13
Training loss: 2.0932774543762207
Validation loss: 1.8240315811608427

Epoch: 359| Step: 0
Training loss: 1.4237735271453857
Validation loss: 1.7900369026327645

Epoch: 6| Step: 1
Training loss: 1.4415693283081055
Validation loss: 1.761913122028433

Epoch: 6| Step: 2
Training loss: 1.4257012605667114
Validation loss: 1.7983245811154764

Epoch: 6| Step: 3
Training loss: 1.0772674083709717
Validation loss: 1.811213767656716

Epoch: 6| Step: 4
Training loss: 1.7518984079360962
Validation loss: 1.835056492077407

Epoch: 6| Step: 5
Training loss: 1.5190091133117676
Validation loss: 1.812300144985158

Epoch: 6| Step: 6
Training loss: 1.6969172954559326
Validation loss: 1.8061682927993037

Epoch: 6| Step: 7
Training loss: 1.4947668313980103
Validation loss: 1.7068616728628836

Epoch: 6| Step: 8
Training loss: 1.61470365524292
Validation loss: 1.7715652604256906

Epoch: 6| Step: 9
Training loss: 1.4371278285980225
Validation loss: 1.841820437421081

Epoch: 6| Step: 10
Training loss: 0.9877405762672424
Validation loss: 1.7858187229402605

Epoch: 6| Step: 11
Training loss: 0.9633349180221558
Validation loss: 1.8103733011471328

Epoch: 6| Step: 12
Training loss: 1.4753367900848389
Validation loss: 1.7559243581628288

Epoch: 6| Step: 13
Training loss: 1.5882233381271362
Validation loss: 1.8157327713504914

Epoch: 360| Step: 0
Training loss: 1.4575896263122559
Validation loss: 1.8021042257226922

Epoch: 6| Step: 1
Training loss: 1.427173376083374
Validation loss: 1.792810587472813

Epoch: 6| Step: 2
Training loss: 1.8133131265640259
Validation loss: 1.7863711746790076

Epoch: 6| Step: 3
Training loss: 0.8298295140266418
Validation loss: 1.8213367449339999

Epoch: 6| Step: 4
Training loss: 1.056795358657837
Validation loss: 1.832441960611651

Epoch: 6| Step: 5
Training loss: 1.0510320663452148
Validation loss: 1.8222657954821022

Epoch: 6| Step: 6
Training loss: 1.8139926195144653
Validation loss: 1.816360568487516

Epoch: 6| Step: 7
Training loss: 1.6501065492630005
Validation loss: 1.8242554126247283

Epoch: 6| Step: 8
Training loss: 1.6444337368011475
Validation loss: 1.823652103383054

Epoch: 6| Step: 9
Training loss: 0.9995811581611633
Validation loss: 1.8299110448488625

Epoch: 6| Step: 10
Training loss: 0.9605616331100464
Validation loss: 1.7645569180929532

Epoch: 6| Step: 11
Training loss: 1.7431498765945435
Validation loss: 1.7656635020368843

Epoch: 6| Step: 12
Training loss: 1.6352052688598633
Validation loss: 1.7537683210065287

Epoch: 6| Step: 13
Training loss: 1.767375111579895
Validation loss: 1.7927690129126272

Epoch: 361| Step: 0
Training loss: 1.467355489730835
Validation loss: 1.7553948510077693

Epoch: 6| Step: 1
Training loss: 0.9966152310371399
Validation loss: 1.7632175427611156

Epoch: 6| Step: 2
Training loss: 1.483154058456421
Validation loss: 1.773880773975003

Epoch: 6| Step: 3
Training loss: 1.340559720993042
Validation loss: 1.7540715471390755

Epoch: 6| Step: 4
Training loss: 0.8748801946640015
Validation loss: 1.7949929032274472

Epoch: 6| Step: 5
Training loss: 1.2705750465393066
Validation loss: 1.833786702925159

Epoch: 6| Step: 6
Training loss: 1.2700657844543457
Validation loss: 1.7235809167226155

Epoch: 6| Step: 7
Training loss: 1.6786818504333496
Validation loss: 1.8700179874256093

Epoch: 6| Step: 8
Training loss: 1.7744014263153076
Validation loss: 1.7650615169155983

Epoch: 6| Step: 9
Training loss: 1.4563887119293213
Validation loss: 1.789273977279663

Epoch: 6| Step: 10
Training loss: 1.8290759325027466
Validation loss: 1.8011632247637677

Epoch: 6| Step: 11
Training loss: 1.195313572883606
Validation loss: 1.7259740752558554

Epoch: 6| Step: 12
Training loss: 1.1923580169677734
Validation loss: 1.838005704264487

Epoch: 6| Step: 13
Training loss: 1.1353319883346558
Validation loss: 1.7436929056721349

Epoch: 362| Step: 0
Training loss: 0.7051594257354736
Validation loss: 1.7498589754104614

Epoch: 6| Step: 1
Training loss: 0.9323081970214844
Validation loss: 1.8350254130619827

Epoch: 6| Step: 2
Training loss: 1.3428971767425537
Validation loss: 1.7768304476173975

Epoch: 6| Step: 3
Training loss: 1.027918815612793
Validation loss: 1.7908913653383973

Epoch: 6| Step: 4
Training loss: 1.3180114030838013
Validation loss: 1.8105726395883868

Epoch: 6| Step: 5
Training loss: 1.7609281539916992
Validation loss: 1.8354712814413092

Epoch: 6| Step: 6
Training loss: 1.4660893678665161
Validation loss: 1.790178668114447

Epoch: 6| Step: 7
Training loss: 1.0107240676879883
Validation loss: 1.8283291234765002

Epoch: 6| Step: 8
Training loss: 1.2550441026687622
Validation loss: 1.7636326230982298

Epoch: 6| Step: 9
Training loss: 1.5790706872940063
Validation loss: 1.821708615108203

Epoch: 6| Step: 10
Training loss: 2.379852771759033
Validation loss: 1.7703006293184014

Epoch: 6| Step: 11
Training loss: 1.6906962394714355
Validation loss: 1.8288994501995783

Epoch: 6| Step: 12
Training loss: 1.254235863685608
Validation loss: 1.7610157164194251

Epoch: 6| Step: 13
Training loss: 1.1816437244415283
Validation loss: 1.8027886780359412

Epoch: 363| Step: 0
Training loss: 1.7857606410980225
Validation loss: 1.7944250491357618

Epoch: 6| Step: 1
Training loss: 1.3597140312194824
Validation loss: 1.8036595621416647

Epoch: 6| Step: 2
Training loss: 1.676031231880188
Validation loss: 1.8299844854621476

Epoch: 6| Step: 3
Training loss: 1.197064757347107
Validation loss: 1.7897332765722787

Epoch: 6| Step: 4
Training loss: 1.5036118030548096
Validation loss: 1.7696184881271855

Epoch: 6| Step: 5
Training loss: 1.2986698150634766
Validation loss: 1.7952835739299815

Epoch: 6| Step: 6
Training loss: 1.1320135593414307
Validation loss: 1.7598235991693312

Epoch: 6| Step: 7
Training loss: 1.7909934520721436
Validation loss: 1.7554944728010444

Epoch: 6| Step: 8
Training loss: 1.2588677406311035
Validation loss: 1.7862234705237932

Epoch: 6| Step: 9
Training loss: 1.643074870109558
Validation loss: 1.7453079787633752

Epoch: 6| Step: 10
Training loss: 1.1772810220718384
Validation loss: 1.7765563816152594

Epoch: 6| Step: 11
Training loss: 0.8655361533164978
Validation loss: 1.7468643470477032

Epoch: 6| Step: 12
Training loss: 0.8593583106994629
Validation loss: 1.7889390683943225

Epoch: 6| Step: 13
Training loss: 1.2569724321365356
Validation loss: 1.795522395000663

Epoch: 364| Step: 0
Training loss: 1.75413179397583
Validation loss: 1.7715854388411327

Epoch: 6| Step: 1
Training loss: 1.0736539363861084
Validation loss: 1.7825365527983634

Epoch: 6| Step: 2
Training loss: 1.3656704425811768
Validation loss: 1.832400760342998

Epoch: 6| Step: 3
Training loss: 1.0579402446746826
Validation loss: 1.7458871949103572

Epoch: 6| Step: 4
Training loss: 1.7047200202941895
Validation loss: 1.8060376080133582

Epoch: 6| Step: 5
Training loss: 1.8736443519592285
Validation loss: 1.7367181137043943

Epoch: 6| Step: 6
Training loss: 1.3445574045181274
Validation loss: 1.7659677882348337

Epoch: 6| Step: 7
Training loss: 1.4530665874481201
Validation loss: 1.8217725510238318

Epoch: 6| Step: 8
Training loss: 1.5178618431091309
Validation loss: 1.8599548519298594

Epoch: 6| Step: 9
Training loss: 1.6234135627746582
Validation loss: 1.8463931711771155

Epoch: 6| Step: 10
Training loss: 1.681373119354248
Validation loss: 1.8653100049623879

Epoch: 6| Step: 11
Training loss: 0.8606202006340027
Validation loss: 1.8493434767569266

Epoch: 6| Step: 12
Training loss: 0.717781662940979
Validation loss: 1.8193006771866993

Epoch: 6| Step: 13
Training loss: 1.1079504489898682
Validation loss: 1.814217266216073

Epoch: 365| Step: 0
Training loss: 1.5358794927597046
Validation loss: 1.789046952801366

Epoch: 6| Step: 1
Training loss: 1.4713553190231323
Validation loss: 1.8453215668278355

Epoch: 6| Step: 2
Training loss: 1.934463381767273
Validation loss: 1.8077667041491436

Epoch: 6| Step: 3
Training loss: 1.4330663681030273
Validation loss: 1.7871798007718978

Epoch: 6| Step: 4
Training loss: 1.726290225982666
Validation loss: 1.8112124909636795

Epoch: 6| Step: 5
Training loss: 1.0355157852172852
Validation loss: 1.7959051106565742

Epoch: 6| Step: 6
Training loss: 1.0133190155029297
Validation loss: 1.7099695731234807

Epoch: 6| Step: 7
Training loss: 2.046046495437622
Validation loss: 1.839151923374463

Epoch: 6| Step: 8
Training loss: 1.136407732963562
Validation loss: 1.7948901576380576

Epoch: 6| Step: 9
Training loss: 1.065158724784851
Validation loss: 1.7638359121097031

Epoch: 6| Step: 10
Training loss: 1.063108205795288
Validation loss: 1.7939087588299987

Epoch: 6| Step: 11
Training loss: 0.9479168057441711
Validation loss: 1.8289594598995742

Epoch: 6| Step: 12
Training loss: 0.8769782781600952
Validation loss: 1.7628329774384857

Epoch: 6| Step: 13
Training loss: 1.531512975692749
Validation loss: 1.837532962522199

Epoch: 366| Step: 0
Training loss: 1.4048881530761719
Validation loss: 1.7200035049069313

Epoch: 6| Step: 1
Training loss: 1.3404314517974854
Validation loss: 1.822276488427193

Epoch: 6| Step: 2
Training loss: 0.9523918628692627
Validation loss: 1.7795398645503546

Epoch: 6| Step: 3
Training loss: 1.137350082397461
Validation loss: 1.7436921250435613

Epoch: 6| Step: 4
Training loss: 1.2906615734100342
Validation loss: 1.7990857760111492

Epoch: 6| Step: 5
Training loss: 1.1969321966171265
Validation loss: 1.7527832805469472

Epoch: 6| Step: 6
Training loss: 1.7543312311172485
Validation loss: 1.6758252382278442

Epoch: 6| Step: 7
Training loss: 1.6698272228240967
Validation loss: 1.7827192327027679

Epoch: 6| Step: 8
Training loss: 1.4284642934799194
Validation loss: 1.8159816072833153

Epoch: 6| Step: 9
Training loss: 1.7403826713562012
Validation loss: 1.7793154485764042

Epoch: 6| Step: 10
Training loss: 1.1382360458374023
Validation loss: 1.7449785599144556

Epoch: 6| Step: 11
Training loss: 1.106631875038147
Validation loss: 1.777661859348256

Epoch: 6| Step: 12
Training loss: 1.3519461154937744
Validation loss: 1.7949989470102454

Epoch: 6| Step: 13
Training loss: 1.5844945907592773
Validation loss: 1.7579966283613635

Epoch: 367| Step: 0
Training loss: 1.9254202842712402
Validation loss: 1.7789761468928347

Epoch: 6| Step: 1
Training loss: 1.658944845199585
Validation loss: 1.7721332093720794

Epoch: 6| Step: 2
Training loss: 1.3323554992675781
Validation loss: 1.7673334178104196

Epoch: 6| Step: 3
Training loss: 1.0656837224960327
Validation loss: 1.8479823476524764

Epoch: 6| Step: 4
Training loss: 1.2527562379837036
Validation loss: 1.8569265052836428

Epoch: 6| Step: 5
Training loss: 1.0227043628692627
Validation loss: 1.8075227352880663

Epoch: 6| Step: 6
Training loss: 1.067118525505066
Validation loss: 1.8696700962640906

Epoch: 6| Step: 7
Training loss: 1.06325364112854
Validation loss: 1.8382444932896604

Epoch: 6| Step: 8
Training loss: 1.2348092794418335
Validation loss: 1.763297495021615

Epoch: 6| Step: 9
Training loss: 1.490075707435608
Validation loss: 1.7481285384906236

Epoch: 6| Step: 10
Training loss: 1.459877371788025
Validation loss: 1.8082816857163624

Epoch: 6| Step: 11
Training loss: 1.4259575605392456
Validation loss: 1.7731456782228203

Epoch: 6| Step: 12
Training loss: 1.5155870914459229
Validation loss: 1.804487156611617

Epoch: 6| Step: 13
Training loss: 0.8660728931427002
Validation loss: 1.7772282810621365

Epoch: 368| Step: 0
Training loss: 0.8849810361862183
Validation loss: 1.7665496615953342

Epoch: 6| Step: 1
Training loss: 1.1413286924362183
Validation loss: 1.7833895068014822

Epoch: 6| Step: 2
Training loss: 1.698434591293335
Validation loss: 1.7251647633890952

Epoch: 6| Step: 3
Training loss: 1.2061632871627808
Validation loss: 1.8467259150679394

Epoch: 6| Step: 4
Training loss: 1.1924114227294922
Validation loss: 1.7288666373939925

Epoch: 6| Step: 5
Training loss: 1.5130808353424072
Validation loss: 1.7705556628524617

Epoch: 6| Step: 6
Training loss: 0.9781209230422974
Validation loss: 1.8613172269636584

Epoch: 6| Step: 7
Training loss: 0.9798946976661682
Validation loss: 1.857659221977316

Epoch: 6| Step: 8
Training loss: 1.2864710092544556
Validation loss: 1.8015528968585435

Epoch: 6| Step: 9
Training loss: 2.0479397773742676
Validation loss: 1.7760312223947177

Epoch: 6| Step: 10
Training loss: 1.6553754806518555
Validation loss: 1.8275483013481222

Epoch: 6| Step: 11
Training loss: 1.8493173122406006
Validation loss: 1.7722741275705316

Epoch: 6| Step: 12
Training loss: 0.9911710619926453
Validation loss: 1.8388470872755973

Epoch: 6| Step: 13
Training loss: 1.267021656036377
Validation loss: 1.7767441836736535

Epoch: 369| Step: 0
Training loss: 1.224381446838379
Validation loss: 1.7776625028220556

Epoch: 6| Step: 1
Training loss: 1.5790066719055176
Validation loss: 1.8377352735047698

Epoch: 6| Step: 2
Training loss: 1.2870157957077026
Validation loss: 1.7586498093861405

Epoch: 6| Step: 3
Training loss: 1.6182615756988525
Validation loss: 1.8186585287893973

Epoch: 6| Step: 4
Training loss: 0.9622960090637207
Validation loss: 1.70381195827197

Epoch: 6| Step: 5
Training loss: 1.3839236497879028
Validation loss: 1.7136900963321808

Epoch: 6| Step: 6
Training loss: 1.0112264156341553
Validation loss: 1.8372791300537765

Epoch: 6| Step: 7
Training loss: 0.8623545169830322
Validation loss: 1.7778791009738881

Epoch: 6| Step: 8
Training loss: 1.767962098121643
Validation loss: 1.8294616565909436

Epoch: 6| Step: 9
Training loss: 2.008612632751465
Validation loss: 1.7555195875065301

Epoch: 6| Step: 10
Training loss: 0.741323709487915
Validation loss: 1.6982020537058513

Epoch: 6| Step: 11
Training loss: 1.6562352180480957
Validation loss: 1.7770614470205

Epoch: 6| Step: 12
Training loss: 1.3063008785247803
Validation loss: 1.7999233353522517

Epoch: 6| Step: 13
Training loss: 1.70138418674469
Validation loss: 1.764586761433591

Epoch: 370| Step: 0
Training loss: 0.9416525959968567
Validation loss: 1.7999718150784891

Epoch: 6| Step: 1
Training loss: 1.4832301139831543
Validation loss: 1.7968379271927701

Epoch: 6| Step: 2
Training loss: 1.436102032661438
Validation loss: 1.8214012345960062

Epoch: 6| Step: 3
Training loss: 1.2175661325454712
Validation loss: 1.8014772502324914

Epoch: 6| Step: 4
Training loss: 1.9557850360870361
Validation loss: 1.793439092174653

Epoch: 6| Step: 5
Training loss: 1.561518907546997
Validation loss: 1.8345324454769012

Epoch: 6| Step: 6
Training loss: 1.099876046180725
Validation loss: 1.843668778737386

Epoch: 6| Step: 7
Training loss: 1.7336549758911133
Validation loss: 1.8552293200646677

Epoch: 6| Step: 8
Training loss: 1.5001238584518433
Validation loss: 1.8697707255681355

Epoch: 6| Step: 9
Training loss: 1.4647624492645264
Validation loss: 1.8289824724197388

Epoch: 6| Step: 10
Training loss: 0.9514687657356262
Validation loss: 1.8611992648852769

Epoch: 6| Step: 11
Training loss: 1.3558359146118164
Validation loss: 1.8150766382935226

Epoch: 6| Step: 12
Training loss: 1.125698447227478
Validation loss: 1.7950731906839597

Epoch: 6| Step: 13
Training loss: 1.6720038652420044
Validation loss: 1.7954495106973956

Epoch: 371| Step: 0
Training loss: 1.0680773258209229
Validation loss: 1.767250536590494

Epoch: 6| Step: 1
Training loss: 0.7457592487335205
Validation loss: 1.8382421129493303

Epoch: 6| Step: 2
Training loss: 1.5842746496200562
Validation loss: 1.8188492175071471

Epoch: 6| Step: 3
Training loss: 1.1428427696228027
Validation loss: 1.7646406888961792

Epoch: 6| Step: 4
Training loss: 1.2575600147247314
Validation loss: 1.7955700710255613

Epoch: 6| Step: 5
Training loss: 2.000493049621582
Validation loss: 1.7951693804033342

Epoch: 6| Step: 6
Training loss: 1.5918669700622559
Validation loss: 1.7752957702964864

Epoch: 6| Step: 7
Training loss: 0.9397255182266235
Validation loss: 1.7713477630769052

Epoch: 6| Step: 8
Training loss: 1.4607508182525635
Validation loss: 1.7877138404436008

Epoch: 6| Step: 9
Training loss: 1.8014564514160156
Validation loss: 1.8431594551250499

Epoch: 6| Step: 10
Training loss: 1.0886530876159668
Validation loss: 1.8179198477857856

Epoch: 6| Step: 11
Training loss: 1.3490948677062988
Validation loss: 1.8000505637097102

Epoch: 6| Step: 12
Training loss: 1.3363301753997803
Validation loss: 1.7415280124192596

Epoch: 6| Step: 13
Training loss: 1.1847583055496216
Validation loss: 1.754646808870377

Epoch: 372| Step: 0
Training loss: 1.2228193283081055
Validation loss: 1.867635678219539

Epoch: 6| Step: 1
Training loss: 1.4364359378814697
Validation loss: 1.7975410735735329

Epoch: 6| Step: 2
Training loss: 1.4103000164031982
Validation loss: 1.810287743486384

Epoch: 6| Step: 3
Training loss: 1.1451060771942139
Validation loss: 1.791895592084495

Epoch: 6| Step: 4
Training loss: 1.6576454639434814
Validation loss: 1.8276216778703915

Epoch: 6| Step: 5
Training loss: 0.808976948261261
Validation loss: 1.8366366919650827

Epoch: 6| Step: 6
Training loss: 1.491792917251587
Validation loss: 1.7746379234457528

Epoch: 6| Step: 7
Training loss: 0.9815428256988525
Validation loss: 1.7160093630513837

Epoch: 6| Step: 8
Training loss: 1.6013315916061401
Validation loss: 1.809338019740197

Epoch: 6| Step: 9
Training loss: 1.0527348518371582
Validation loss: 1.7696167666424987

Epoch: 6| Step: 10
Training loss: 1.6970345973968506
Validation loss: 1.8006504351092922

Epoch: 6| Step: 11
Training loss: 1.7447577714920044
Validation loss: 1.7423913055850613

Epoch: 6| Step: 12
Training loss: 0.8898915648460388
Validation loss: 1.6988063884037796

Epoch: 6| Step: 13
Training loss: 0.7501596808433533
Validation loss: 1.8230650694139543

Epoch: 373| Step: 0
Training loss: 1.182142734527588
Validation loss: 1.7571811445297734

Epoch: 6| Step: 1
Training loss: 1.6730773448944092
Validation loss: 1.764642862863438

Epoch: 6| Step: 2
Training loss: 1.3458755016326904
Validation loss: 1.7839713801619828

Epoch: 6| Step: 3
Training loss: 1.1396751403808594
Validation loss: 1.8186883695663945

Epoch: 6| Step: 4
Training loss: 1.3446049690246582
Validation loss: 1.721373104280041

Epoch: 6| Step: 5
Training loss: 1.3717658519744873
Validation loss: 1.78115112550797

Epoch: 6| Step: 6
Training loss: 0.9997304081916809
Validation loss: 1.8100138633481917

Epoch: 6| Step: 7
Training loss: 1.498009204864502
Validation loss: 1.7168503974073677

Epoch: 6| Step: 8
Training loss: 1.0613062381744385
Validation loss: 1.7723256106017737

Epoch: 6| Step: 9
Training loss: 2.1309714317321777
Validation loss: 1.7914794529637983

Epoch: 6| Step: 10
Training loss: 0.805477499961853
Validation loss: 1.828457518290448

Epoch: 6| Step: 11
Training loss: 1.2066848278045654
Validation loss: 1.8124660445797829

Epoch: 6| Step: 12
Training loss: 1.529173493385315
Validation loss: 1.788411017387144

Epoch: 6| Step: 13
Training loss: 1.0941702127456665
Validation loss: 1.7935126148244387

Epoch: 374| Step: 0
Training loss: 1.2945234775543213
Validation loss: 1.7676324177813787

Epoch: 6| Step: 1
Training loss: 1.2932660579681396
Validation loss: 1.7557767309168333

Epoch: 6| Step: 2
Training loss: 1.5311393737792969
Validation loss: 1.712129125031092

Epoch: 6| Step: 3
Training loss: 1.2266112565994263
Validation loss: 1.7583732822889924

Epoch: 6| Step: 4
Training loss: 1.18528151512146
Validation loss: 1.7668830771600046

Epoch: 6| Step: 5
Training loss: 0.9511864185333252
Validation loss: 1.726975514042762

Epoch: 6| Step: 6
Training loss: 1.7875258922576904
Validation loss: 1.792145767519551

Epoch: 6| Step: 7
Training loss: 1.141938328742981
Validation loss: 1.7630480322786557

Epoch: 6| Step: 8
Training loss: 1.7082337141036987
Validation loss: 1.7353088240469656

Epoch: 6| Step: 9
Training loss: 1.4082036018371582
Validation loss: 1.8475651946119083

Epoch: 6| Step: 10
Training loss: 1.2456140518188477
Validation loss: 1.8039190923013995

Epoch: 6| Step: 11
Training loss: 1.3616080284118652
Validation loss: 1.8035959684720604

Epoch: 6| Step: 12
Training loss: 1.4851638078689575
Validation loss: 1.8827955107535086

Epoch: 6| Step: 13
Training loss: 0.6409144401550293
Validation loss: 1.785862535558721

Epoch: 375| Step: 0
Training loss: 1.1182410717010498
Validation loss: 1.7577105927210983

Epoch: 6| Step: 1
Training loss: 1.676565170288086
Validation loss: 1.81480158528974

Epoch: 6| Step: 2
Training loss: 1.388278603553772
Validation loss: 1.8285953178200671

Epoch: 6| Step: 3
Training loss: 1.0669467449188232
Validation loss: 1.8060467140648955

Epoch: 6| Step: 4
Training loss: 1.965057373046875
Validation loss: 1.808349140869674

Epoch: 6| Step: 5
Training loss: 1.2537425756454468
Validation loss: 1.8384298470712477

Epoch: 6| Step: 6
Training loss: 1.6361974477767944
Validation loss: 1.7727434712071573

Epoch: 6| Step: 7
Training loss: 1.1417725086212158
Validation loss: 1.7297069821306454

Epoch: 6| Step: 8
Training loss: 1.3184452056884766
Validation loss: 1.729508489690801

Epoch: 6| Step: 9
Training loss: 1.1843990087509155
Validation loss: 1.7840348674405007

Epoch: 6| Step: 10
Training loss: 1.4938921928405762
Validation loss: 1.7812781782560452

Epoch: 6| Step: 11
Training loss: 0.9993051290512085
Validation loss: 1.8027240127645514

Epoch: 6| Step: 12
Training loss: 1.1847878694534302
Validation loss: 1.8014001269494333

Epoch: 6| Step: 13
Training loss: 1.9604352712631226
Validation loss: 1.785104948987243

Epoch: 376| Step: 0
Training loss: 1.0355690717697144
Validation loss: 1.772773572193679

Epoch: 6| Step: 1
Training loss: 1.0577518939971924
Validation loss: 1.7570094908437421

Epoch: 6| Step: 2
Training loss: 1.3528528213500977
Validation loss: 1.7916944526856946

Epoch: 6| Step: 3
Training loss: 1.2383064031600952
Validation loss: 1.7909065113272717

Epoch: 6| Step: 4
Training loss: 1.5475925207138062
Validation loss: 1.7777608453586538

Epoch: 6| Step: 5
Training loss: 0.8782320022583008
Validation loss: 1.8138225052946357

Epoch: 6| Step: 6
Training loss: 1.0333651304244995
Validation loss: 1.8196858308648551

Epoch: 6| Step: 7
Training loss: 1.2805453538894653
Validation loss: 1.7824635287766815

Epoch: 6| Step: 8
Training loss: 1.5150580406188965
Validation loss: 1.7203084627787273

Epoch: 6| Step: 9
Training loss: 1.6004793643951416
Validation loss: 1.8404680426402757

Epoch: 6| Step: 10
Training loss: 1.5642569065093994
Validation loss: 1.8260173118242653

Epoch: 6| Step: 11
Training loss: 1.6220507621765137
Validation loss: 1.814881851596217

Epoch: 6| Step: 12
Training loss: 1.3071421384811401
Validation loss: 1.835603065388177

Epoch: 6| Step: 13
Training loss: 0.8810674548149109
Validation loss: 1.8112936814626057

Epoch: 377| Step: 0
Training loss: 1.3941925764083862
Validation loss: 1.7742865431693293

Epoch: 6| Step: 1
Training loss: 1.40447998046875
Validation loss: 1.7817236915711434

Epoch: 6| Step: 2
Training loss: 1.326594352722168
Validation loss: 1.7940053452727616

Epoch: 6| Step: 3
Training loss: 0.8989545106887817
Validation loss: 1.7726923675947293

Epoch: 6| Step: 4
Training loss: 1.4690890312194824
Validation loss: 1.7936148246129353

Epoch: 6| Step: 5
Training loss: 1.2765979766845703
Validation loss: 1.755339935261716

Epoch: 6| Step: 6
Training loss: 1.5041590929031372
Validation loss: 1.7741831284697338

Epoch: 6| Step: 7
Training loss: 0.8273807764053345
Validation loss: 1.7946381415090253

Epoch: 6| Step: 8
Training loss: 1.5060880184173584
Validation loss: 1.7346018693780387

Epoch: 6| Step: 9
Training loss: 1.9828435182571411
Validation loss: 1.832814884442155

Epoch: 6| Step: 10
Training loss: 1.2123485803604126
Validation loss: 1.7914507517250635

Epoch: 6| Step: 11
Training loss: 0.6673495173454285
Validation loss: 1.7935751676559448

Epoch: 6| Step: 12
Training loss: 1.1948256492614746
Validation loss: 1.8348246184728478

Epoch: 6| Step: 13
Training loss: 2.1280505657196045
Validation loss: 1.7723948019807056

Epoch: 378| Step: 0
Training loss: 1.3912129402160645
Validation loss: 1.7700882906554847

Epoch: 6| Step: 1
Training loss: 1.549088954925537
Validation loss: 1.7802210559127152

Epoch: 6| Step: 2
Training loss: 1.1381924152374268
Validation loss: 1.861235841628044

Epoch: 6| Step: 3
Training loss: 0.7595685124397278
Validation loss: 1.8102076463801886

Epoch: 6| Step: 4
Training loss: 1.0836100578308105
Validation loss: 1.7671865852930213

Epoch: 6| Step: 5
Training loss: 1.146114468574524
Validation loss: 1.8773799942385765

Epoch: 6| Step: 6
Training loss: 1.4532679319381714
Validation loss: 1.7454179166465678

Epoch: 6| Step: 7
Training loss: 1.4219249486923218
Validation loss: 1.7757262555501794

Epoch: 6| Step: 8
Training loss: 1.1479129791259766
Validation loss: 1.8211629595807803

Epoch: 6| Step: 9
Training loss: 0.848538339138031
Validation loss: 1.812296255942314

Epoch: 6| Step: 10
Training loss: 1.8632670640945435
Validation loss: 1.7892460617967831

Epoch: 6| Step: 11
Training loss: 1.2419586181640625
Validation loss: 1.7642994978094613

Epoch: 6| Step: 12
Training loss: 1.344231128692627
Validation loss: 1.7542685090854604

Epoch: 6| Step: 13
Training loss: 1.990785002708435
Validation loss: 1.7313942704149472

Epoch: 379| Step: 0
Training loss: 1.5406379699707031
Validation loss: 1.8115682550655898

Epoch: 6| Step: 1
Training loss: 1.1224122047424316
Validation loss: 1.7370294088958411

Epoch: 6| Step: 2
Training loss: 0.9021520614624023
Validation loss: 1.7838157069298528

Epoch: 6| Step: 3
Training loss: 1.172057032585144
Validation loss: 1.803159757327008

Epoch: 6| Step: 4
Training loss: 1.2872674465179443
Validation loss: 1.78907149581499

Epoch: 6| Step: 5
Training loss: 1.4772664308547974
Validation loss: 1.7532060415514055

Epoch: 6| Step: 6
Training loss: 1.0136882066726685
Validation loss: 1.770372889375174

Epoch: 6| Step: 7
Training loss: 1.6424555778503418
Validation loss: 1.7773415324508504

Epoch: 6| Step: 8
Training loss: 1.310020089149475
Validation loss: 1.807355344936412

Epoch: 6| Step: 9
Training loss: 0.8356080651283264
Validation loss: 1.7988111267807663

Epoch: 6| Step: 10
Training loss: 1.5402448177337646
Validation loss: 1.7139332884101457

Epoch: 6| Step: 11
Training loss: 1.7655268907546997
Validation loss: 1.7884320136039489

Epoch: 6| Step: 12
Training loss: 1.2889974117279053
Validation loss: 1.733121680957015

Epoch: 6| Step: 13
Training loss: 2.2932844161987305
Validation loss: 1.7708805081664876

Epoch: 380| Step: 0
Training loss: 1.8718979358673096
Validation loss: 1.7951416507844002

Epoch: 6| Step: 1
Training loss: 1.4341528415679932
Validation loss: 1.7568026742627543

Epoch: 6| Step: 2
Training loss: 1.1600537300109863
Validation loss: 1.7406738188958937

Epoch: 6| Step: 3
Training loss: 0.9254448413848877
Validation loss: 1.7819414395158009

Epoch: 6| Step: 4
Training loss: 1.1343762874603271
Validation loss: 1.7726818156498734

Epoch: 6| Step: 5
Training loss: 1.0199579000473022
Validation loss: 1.7622845993247083

Epoch: 6| Step: 6
Training loss: 0.8152810335159302
Validation loss: 1.7295578102911673

Epoch: 6| Step: 7
Training loss: 1.8260595798492432
Validation loss: 1.7131390956140333

Epoch: 6| Step: 8
Training loss: 1.4290311336517334
Validation loss: 1.773481128036335

Epoch: 6| Step: 9
Training loss: 1.0898946523666382
Validation loss: 1.7134054655669837

Epoch: 6| Step: 10
Training loss: 1.836693286895752
Validation loss: 1.7459744202193392

Epoch: 6| Step: 11
Training loss: 0.9942449331283569
Validation loss: 1.7947497175585838

Epoch: 6| Step: 12
Training loss: 1.7340030670166016
Validation loss: 1.8040782072210824

Epoch: 6| Step: 13
Training loss: 0.9693461656570435
Validation loss: 1.7507905639627928

Epoch: 381| Step: 0
Training loss: 1.4960646629333496
Validation loss: 1.7918208555508686

Epoch: 6| Step: 1
Training loss: 1.190449833869934
Validation loss: 1.7311455267731861

Epoch: 6| Step: 2
Training loss: 1.1930134296417236
Validation loss: 1.7819389899571736

Epoch: 6| Step: 3
Training loss: 0.6790156364440918
Validation loss: 1.777275719950276

Epoch: 6| Step: 4
Training loss: 1.3504217863082886
Validation loss: 1.7409803303339149

Epoch: 6| Step: 5
Training loss: 1.7089390754699707
Validation loss: 1.764871822890415

Epoch: 6| Step: 6
Training loss: 1.543095350265503
Validation loss: 1.77639482098241

Epoch: 6| Step: 7
Training loss: 1.5361464023590088
Validation loss: 1.7820223095596477

Epoch: 6| Step: 8
Training loss: 1.6306791305541992
Validation loss: 1.7918268096062444

Epoch: 6| Step: 9
Training loss: 1.8900620937347412
Validation loss: 1.785939396068614

Epoch: 6| Step: 10
Training loss: 0.9958963394165039
Validation loss: 1.8018312044041132

Epoch: 6| Step: 11
Training loss: 0.8173238039016724
Validation loss: 1.727421691340785

Epoch: 6| Step: 12
Training loss: 1.4138227701187134
Validation loss: 1.7914774879332511

Epoch: 6| Step: 13
Training loss: 1.3672451972961426
Validation loss: 1.7260613608103927

Epoch: 382| Step: 0
Training loss: 1.5419816970825195
Validation loss: 1.8225909766330515

Epoch: 6| Step: 1
Training loss: 1.6551179885864258
Validation loss: 1.8062410790433165

Epoch: 6| Step: 2
Training loss: 1.3873050212860107
Validation loss: 1.7430818619266633

Epoch: 6| Step: 3
Training loss: 1.0449365377426147
Validation loss: 1.823190176358787

Epoch: 6| Step: 4
Training loss: 1.4570033550262451
Validation loss: 1.7855151853253763

Epoch: 6| Step: 5
Training loss: 0.9104621410369873
Validation loss: 1.7720814443403674

Epoch: 6| Step: 6
Training loss: 0.6693841218948364
Validation loss: 1.8033972427409182

Epoch: 6| Step: 7
Training loss: 1.343518853187561
Validation loss: 1.8354383860864947

Epoch: 6| Step: 8
Training loss: 1.460708737373352
Validation loss: 1.8742107729757986

Epoch: 6| Step: 9
Training loss: 1.582895278930664
Validation loss: 1.82308788453379

Epoch: 6| Step: 10
Training loss: 1.2907843589782715
Validation loss: 1.8181165033771145

Epoch: 6| Step: 11
Training loss: 1.3593887090682983
Validation loss: 1.8434738292489001

Epoch: 6| Step: 12
Training loss: 0.8185096383094788
Validation loss: 1.7359326411319036

Epoch: 6| Step: 13
Training loss: 2.0452663898468018
Validation loss: 1.7675825754801433

Epoch: 383| Step: 0
Training loss: 1.2477682828903198
Validation loss: 1.8664372403134581

Epoch: 6| Step: 1
Training loss: 1.136048436164856
Validation loss: 1.8075556639702088

Epoch: 6| Step: 2
Training loss: 2.048003911972046
Validation loss: 1.7568234871792536

Epoch: 6| Step: 3
Training loss: 1.3627512454986572
Validation loss: 1.7608887585260535

Epoch: 6| Step: 4
Training loss: 1.126637578010559
Validation loss: 1.741112127098986

Epoch: 6| Step: 5
Training loss: 1.2382868528366089
Validation loss: 1.8267282901271698

Epoch: 6| Step: 6
Training loss: 1.4648044109344482
Validation loss: 1.796987828388009

Epoch: 6| Step: 7
Training loss: 1.2820082902908325
Validation loss: 1.748351235543528

Epoch: 6| Step: 8
Training loss: 1.2609279155731201
Validation loss: 1.7706642714879846

Epoch: 6| Step: 9
Training loss: 0.7224146127700806
Validation loss: 1.7676208608893937

Epoch: 6| Step: 10
Training loss: 1.4154633283615112
Validation loss: 1.7831593892907585

Epoch: 6| Step: 11
Training loss: 1.487532138824463
Validation loss: 1.780002563230453

Epoch: 6| Step: 12
Training loss: 1.1779725551605225
Validation loss: 1.7889159366648684

Epoch: 6| Step: 13
Training loss: 1.2796217203140259
Validation loss: 1.7810755487411254

Epoch: 384| Step: 0
Training loss: 1.1243131160736084
Validation loss: 1.7683113326308548

Epoch: 6| Step: 1
Training loss: 1.6586931943893433
Validation loss: 1.7705525288017847

Epoch: 6| Step: 2
Training loss: 1.2080864906311035
Validation loss: 1.7831194093150478

Epoch: 6| Step: 3
Training loss: 1.240046739578247
Validation loss: 1.7370393224941787

Epoch: 6| Step: 4
Training loss: 0.9003194570541382
Validation loss: 1.746723085321406

Epoch: 6| Step: 5
Training loss: 1.0652027130126953
Validation loss: 1.7649109478919738

Epoch: 6| Step: 6
Training loss: 1.4149115085601807
Validation loss: 1.7733254740315099

Epoch: 6| Step: 7
Training loss: 1.5655208826065063
Validation loss: 1.769918099526436

Epoch: 6| Step: 8
Training loss: 1.4845707416534424
Validation loss: 1.7745821822074153

Epoch: 6| Step: 9
Training loss: 1.3866206407546997
Validation loss: 1.769101119810535

Epoch: 6| Step: 10
Training loss: 1.3538398742675781
Validation loss: 1.819612802997712

Epoch: 6| Step: 11
Training loss: 0.7819257974624634
Validation loss: 1.8093816567492742

Epoch: 6| Step: 12
Training loss: 1.3867558240890503
Validation loss: 1.7324547101092596

Epoch: 6| Step: 13
Training loss: 1.7161868810653687
Validation loss: 1.8639819468221357

Epoch: 385| Step: 0
Training loss: 0.9901094436645508
Validation loss: 1.8129992831137873

Epoch: 6| Step: 1
Training loss: 1.175637125968933
Validation loss: 1.7790298064549763

Epoch: 6| Step: 2
Training loss: 1.7817906141281128
Validation loss: 1.729444037201584

Epoch: 6| Step: 3
Training loss: 1.3792654275894165
Validation loss: 1.7606451037109538

Epoch: 6| Step: 4
Training loss: 1.2334253787994385
Validation loss: 1.7208465389026109

Epoch: 6| Step: 5
Training loss: 1.96181058883667
Validation loss: 1.7664431154087026

Epoch: 6| Step: 6
Training loss: 1.356878399848938
Validation loss: 1.7971463972522366

Epoch: 6| Step: 7
Training loss: 1.3158910274505615
Validation loss: 1.783208643236468

Epoch: 6| Step: 8
Training loss: 0.9942567348480225
Validation loss: 1.7563493738892257

Epoch: 6| Step: 9
Training loss: 1.0307810306549072
Validation loss: 1.787854709932881

Epoch: 6| Step: 10
Training loss: 0.81125408411026
Validation loss: 1.7843728193672754

Epoch: 6| Step: 11
Training loss: 1.3849557638168335
Validation loss: 1.7352216903881361

Epoch: 6| Step: 12
Training loss: 1.8151569366455078
Validation loss: 1.7999648381304998

Epoch: 6| Step: 13
Training loss: 1.010090708732605
Validation loss: 1.7809808869515695

Epoch: 386| Step: 0
Training loss: 0.5558556914329529
Validation loss: 1.8111953171350623

Epoch: 6| Step: 1
Training loss: 1.4455724954605103
Validation loss: 1.7819332820112987

Epoch: 6| Step: 2
Training loss: 1.5885734558105469
Validation loss: 1.8145526788567985

Epoch: 6| Step: 3
Training loss: 1.2012107372283936
Validation loss: 1.7994846118393766

Epoch: 6| Step: 4
Training loss: 0.9537217617034912
Validation loss: 1.797069461114945

Epoch: 6| Step: 5
Training loss: 2.0241236686706543
Validation loss: 1.8363000872314617

Epoch: 6| Step: 6
Training loss: 1.1848430633544922
Validation loss: 1.7660256431948753

Epoch: 6| Step: 7
Training loss: 1.4053983688354492
Validation loss: 1.8010708439734675

Epoch: 6| Step: 8
Training loss: 0.890365719795227
Validation loss: 1.7868143794357136

Epoch: 6| Step: 9
Training loss: 0.8681085109710693
Validation loss: 1.8161872484350716

Epoch: 6| Step: 10
Training loss: 1.0814582109451294
Validation loss: 1.7371896069536927

Epoch: 6| Step: 11
Training loss: 1.6677950620651245
Validation loss: 1.7912826563722344

Epoch: 6| Step: 12
Training loss: 1.3104493618011475
Validation loss: 1.7818080686753797

Epoch: 6| Step: 13
Training loss: 1.4912950992584229
Validation loss: 1.79209307957721

Epoch: 387| Step: 0
Training loss: 1.026822566986084
Validation loss: 1.8245019976810744

Epoch: 6| Step: 1
Training loss: 1.4909205436706543
Validation loss: 1.712599733824371

Epoch: 6| Step: 2
Training loss: 1.0797340869903564
Validation loss: 1.812035790053747

Epoch: 6| Step: 3
Training loss: 2.001512289047241
Validation loss: 1.7646029200605167

Epoch: 6| Step: 4
Training loss: 1.2306514978408813
Validation loss: 1.7928903641239289

Epoch: 6| Step: 5
Training loss: 1.152987003326416
Validation loss: 1.7794304368316487

Epoch: 6| Step: 6
Training loss: 1.7723495960235596
Validation loss: 1.7606784502665203

Epoch: 6| Step: 7
Training loss: 0.9276324510574341
Validation loss: 1.8098939900757165

Epoch: 6| Step: 8
Training loss: 1.4311108589172363
Validation loss: 1.7505399334815241

Epoch: 6| Step: 9
Training loss: 0.9924554824829102
Validation loss: 1.7746756551086262

Epoch: 6| Step: 10
Training loss: 1.401994228363037
Validation loss: 1.7936446948718

Epoch: 6| Step: 11
Training loss: 1.608202576637268
Validation loss: 1.8449595743610012

Epoch: 6| Step: 12
Training loss: 0.6993741393089294
Validation loss: 1.6957557791022844

Epoch: 6| Step: 13
Training loss: 0.7516878843307495
Validation loss: 1.7584888140360515

Epoch: 388| Step: 0
Training loss: 1.2667490243911743
Validation loss: 1.8175936834786528

Epoch: 6| Step: 1
Training loss: 1.3853650093078613
Validation loss: 1.8123522214992072

Epoch: 6| Step: 2
Training loss: 1.3585401773452759
Validation loss: 1.8063733911001554

Epoch: 6| Step: 3
Training loss: 1.0622329711914062
Validation loss: 1.8270226550358597

Epoch: 6| Step: 4
Training loss: 1.2493165731430054
Validation loss: 1.8658539813051942

Epoch: 6| Step: 5
Training loss: 1.3522546291351318
Validation loss: 1.8961435915321432

Epoch: 6| Step: 6
Training loss: 1.0682547092437744
Validation loss: 1.8181236969527377

Epoch: 6| Step: 7
Training loss: 1.5880866050720215
Validation loss: 1.8714568512414091

Epoch: 6| Step: 8
Training loss: 1.0837281942367554
Validation loss: 1.781120333620297

Epoch: 6| Step: 9
Training loss: 1.37430739402771
Validation loss: 1.8149740798498994

Epoch: 6| Step: 10
Training loss: 1.2764058113098145
Validation loss: 1.7656177961698143

Epoch: 6| Step: 11
Training loss: 1.5795338153839111
Validation loss: 1.7748738770843835

Epoch: 6| Step: 12
Training loss: 1.482495903968811
Validation loss: 1.7679679291222685

Epoch: 6| Step: 13
Training loss: 1.5460611581802368
Validation loss: 1.8418208424763014

Epoch: 389| Step: 0
Training loss: 1.2964141368865967
Validation loss: 1.773068638258083

Epoch: 6| Step: 1
Training loss: 1.813974142074585
Validation loss: 1.7854476487764748

Epoch: 6| Step: 2
Training loss: 1.0634294748306274
Validation loss: 1.7803015196195213

Epoch: 6| Step: 3
Training loss: 0.893943727016449
Validation loss: 1.7736290090827531

Epoch: 6| Step: 4
Training loss: 1.1367425918579102
Validation loss: 1.793862920935436

Epoch: 6| Step: 5
Training loss: 1.383206844329834
Validation loss: 1.7906229713911652

Epoch: 6| Step: 6
Training loss: 0.9054468274116516
Validation loss: 1.835233703736336

Epoch: 6| Step: 7
Training loss: 1.4060635566711426
Validation loss: 1.7617910818387104

Epoch: 6| Step: 8
Training loss: 1.6269807815551758
Validation loss: 1.738884736132878

Epoch: 6| Step: 9
Training loss: 1.1647309064865112
Validation loss: 1.7834049514544907

Epoch: 6| Step: 10
Training loss: 1.3833791017532349
Validation loss: 1.7668283575324601

Epoch: 6| Step: 11
Training loss: 1.2806280851364136
Validation loss: 1.7524788213032547

Epoch: 6| Step: 12
Training loss: 1.120039939880371
Validation loss: 1.7836465886844102

Epoch: 6| Step: 13
Training loss: 1.8856934309005737
Validation loss: 1.7774411221986175

Epoch: 390| Step: 0
Training loss: 1.818076729774475
Validation loss: 1.8174303603428665

Epoch: 6| Step: 1
Training loss: 0.9922205805778503
Validation loss: 1.794849758507103

Epoch: 6| Step: 2
Training loss: 1.6911637783050537
Validation loss: 1.8483728760032243

Epoch: 6| Step: 3
Training loss: 1.494896411895752
Validation loss: 1.8487615303326679

Epoch: 6| Step: 4
Training loss: 1.2584822177886963
Validation loss: 1.7972497491426365

Epoch: 6| Step: 5
Training loss: 0.6028417348861694
Validation loss: 1.8541647849544403

Epoch: 6| Step: 6
Training loss: 0.5683904886245728
Validation loss: 1.766281767558026

Epoch: 6| Step: 7
Training loss: 1.586776614189148
Validation loss: 1.7561480133764205

Epoch: 6| Step: 8
Training loss: 0.978623628616333
Validation loss: 1.750918726767263

Epoch: 6| Step: 9
Training loss: 1.6063511371612549
Validation loss: 1.7574486578664472

Epoch: 6| Step: 10
Training loss: 1.275928020477295
Validation loss: 1.7666871073425456

Epoch: 6| Step: 11
Training loss: 1.0533150434494019
Validation loss: 1.8084921029306227

Epoch: 6| Step: 12
Training loss: 1.4554975032806396
Validation loss: 1.7223885507993801

Epoch: 6| Step: 13
Training loss: 1.2073127031326294
Validation loss: 1.78096374388664

Epoch: 391| Step: 0
Training loss: 1.2148585319519043
Validation loss: 1.7134083086444485

Epoch: 6| Step: 1
Training loss: 1.4281034469604492
Validation loss: 1.8521074876990369

Epoch: 6| Step: 2
Training loss: 0.9359539747238159
Validation loss: 1.770581208249574

Epoch: 6| Step: 3
Training loss: 1.1747914552688599
Validation loss: 1.7590639014397897

Epoch: 6| Step: 4
Training loss: 1.6098029613494873
Validation loss: 1.7866827134163148

Epoch: 6| Step: 5
Training loss: 1.2314786911010742
Validation loss: 1.7924240789105814

Epoch: 6| Step: 6
Training loss: 1.159285306930542
Validation loss: 1.7463693247046521

Epoch: 6| Step: 7
Training loss: 1.2791838645935059
Validation loss: 1.8306448331443212

Epoch: 6| Step: 8
Training loss: 1.2967801094055176
Validation loss: 1.839430320647455

Epoch: 6| Step: 9
Training loss: 1.448525071144104
Validation loss: 1.86453204770242

Epoch: 6| Step: 10
Training loss: 1.49456787109375
Validation loss: 1.8237705525531565

Epoch: 6| Step: 11
Training loss: 1.341701626777649
Validation loss: 1.8707332457265546

Epoch: 6| Step: 12
Training loss: 0.973455548286438
Validation loss: 1.8259437648198937

Epoch: 6| Step: 13
Training loss: 0.4406472444534302
Validation loss: 1.852585982250911

Epoch: 392| Step: 0
Training loss: 0.9837650060653687
Validation loss: 1.8199511522887855

Epoch: 6| Step: 1
Training loss: 1.3338643312454224
Validation loss: 1.7849686581601378

Epoch: 6| Step: 2
Training loss: 1.718543291091919
Validation loss: 1.737680491580758

Epoch: 6| Step: 3
Training loss: 1.048408031463623
Validation loss: 1.7666807354137462

Epoch: 6| Step: 4
Training loss: 1.3704578876495361
Validation loss: 1.7910403102956793

Epoch: 6| Step: 5
Training loss: 1.2533873319625854
Validation loss: 1.7553493271591842

Epoch: 6| Step: 6
Training loss: 1.4805703163146973
Validation loss: 1.8115274572885165

Epoch: 6| Step: 7
Training loss: 1.0351216793060303
Validation loss: 1.7503377596537273

Epoch: 6| Step: 8
Training loss: 0.759540319442749
Validation loss: 1.7418351596401584

Epoch: 6| Step: 9
Training loss: 1.5525978803634644
Validation loss: 1.690865465389785

Epoch: 6| Step: 10
Training loss: 1.7043704986572266
Validation loss: 1.7909896450657998

Epoch: 6| Step: 11
Training loss: 0.8912283778190613
Validation loss: 1.759581724802653

Epoch: 6| Step: 12
Training loss: 1.6640000343322754
Validation loss: 1.7695830804045483

Epoch: 6| Step: 13
Training loss: 1.2303842306137085
Validation loss: 1.8381746943278978

Epoch: 393| Step: 0
Training loss: 1.634406566619873
Validation loss: 1.7227767385462278

Epoch: 6| Step: 1
Training loss: 1.7466453313827515
Validation loss: 1.7211562472005044

Epoch: 6| Step: 2
Training loss: 1.26413094997406
Validation loss: 1.7965106964111328

Epoch: 6| Step: 3
Training loss: 0.9291918277740479
Validation loss: 1.7202698415325535

Epoch: 6| Step: 4
Training loss: 1.3073678016662598
Validation loss: 1.7464518662421935

Epoch: 6| Step: 5
Training loss: 0.9738802909851074
Validation loss: 1.8111835115699357

Epoch: 6| Step: 6
Training loss: 1.2277183532714844
Validation loss: 1.7766070340269355

Epoch: 6| Step: 7
Training loss: 1.339745283126831
Validation loss: 1.7681590228952386

Epoch: 6| Step: 8
Training loss: 1.387528896331787
Validation loss: 1.741902889743928

Epoch: 6| Step: 9
Training loss: 1.3657903671264648
Validation loss: 1.7940974261171074

Epoch: 6| Step: 10
Training loss: 1.4568994045257568
Validation loss: 1.8386346537579772

Epoch: 6| Step: 11
Training loss: 1.067091464996338
Validation loss: 1.7974163742475613

Epoch: 6| Step: 12
Training loss: 1.3034815788269043
Validation loss: 1.8498042527065481

Epoch: 6| Step: 13
Training loss: 0.8637076616287231
Validation loss: 1.818569826823409

Epoch: 394| Step: 0
Training loss: 1.2948098182678223
Validation loss: 1.8095226210932578

Epoch: 6| Step: 1
Training loss: 1.5124590396881104
Validation loss: 1.8403588020673363

Epoch: 6| Step: 2
Training loss: 1.826900839805603
Validation loss: 1.8418722665438088

Epoch: 6| Step: 3
Training loss: 1.1092498302459717
Validation loss: 1.7701557861861361

Epoch: 6| Step: 4
Training loss: 1.2959864139556885
Validation loss: 1.72832158688576

Epoch: 6| Step: 5
Training loss: 1.0162301063537598
Validation loss: 1.8686670308472009

Epoch: 6| Step: 6
Training loss: 0.4687472879886627
Validation loss: 1.803686518822947

Epoch: 6| Step: 7
Training loss: 1.4643850326538086
Validation loss: 1.8443365007318475

Epoch: 6| Step: 8
Training loss: 1.37222158908844
Validation loss: 1.7863749086215932

Epoch: 6| Step: 9
Training loss: 1.4886329174041748
Validation loss: 1.7804308963078324

Epoch: 6| Step: 10
Training loss: 1.5242350101470947
Validation loss: 1.7836828385629961

Epoch: 6| Step: 11
Training loss: 0.974671483039856
Validation loss: 1.793948870833202

Epoch: 6| Step: 12
Training loss: 1.4828801155090332
Validation loss: 1.7815352332207464

Epoch: 6| Step: 13
Training loss: 1.3005518913269043
Validation loss: 1.8250415376437608

Epoch: 395| Step: 0
Training loss: 1.3115825653076172
Validation loss: 1.8061989917550036

Epoch: 6| Step: 1
Training loss: 1.460691213607788
Validation loss: 1.756558750265388

Epoch: 6| Step: 2
Training loss: 1.5737873315811157
Validation loss: 1.737022453738797

Epoch: 6| Step: 3
Training loss: 0.9621016979217529
Validation loss: 1.8087660471598308

Epoch: 6| Step: 4
Training loss: 1.5839314460754395
Validation loss: 1.8204020671947028

Epoch: 6| Step: 5
Training loss: 1.0666911602020264
Validation loss: 1.764454432072178

Epoch: 6| Step: 6
Training loss: 1.712632656097412
Validation loss: 1.7827743561037126

Epoch: 6| Step: 7
Training loss: 0.9482940435409546
Validation loss: 1.8290178891151183

Epoch: 6| Step: 8
Training loss: 1.3078147172927856
Validation loss: 1.7838989714140534

Epoch: 6| Step: 9
Training loss: 1.2406151294708252
Validation loss: 1.879346457860803

Epoch: 6| Step: 10
Training loss: 1.803968071937561
Validation loss: 1.7515340889653852

Epoch: 6| Step: 11
Training loss: 1.4521045684814453
Validation loss: 1.79856841282178

Epoch: 6| Step: 12
Training loss: 0.7206571102142334
Validation loss: 1.7809738792398924

Epoch: 6| Step: 13
Training loss: 1.1632533073425293
Validation loss: 1.8515656007233487

Epoch: 396| Step: 0
Training loss: 1.1667001247406006
Validation loss: 1.7944653059846611

Epoch: 6| Step: 1
Training loss: 0.8545562028884888
Validation loss: 1.8241764268567484

Epoch: 6| Step: 2
Training loss: 1.0544861555099487
Validation loss: 1.7616593760828818

Epoch: 6| Step: 3
Training loss: 1.5015709400177002
Validation loss: 1.8407447286831435

Epoch: 6| Step: 4
Training loss: 1.5253170728683472
Validation loss: 1.828860818698842

Epoch: 6| Step: 5
Training loss: 1.0462706089019775
Validation loss: 1.7812244507574266

Epoch: 6| Step: 6
Training loss: 1.263098120689392
Validation loss: 1.8019734069865236

Epoch: 6| Step: 7
Training loss: 1.872971534729004
Validation loss: 1.7813813455643193

Epoch: 6| Step: 8
Training loss: 1.312440037727356
Validation loss: 1.7675522860660349

Epoch: 6| Step: 9
Training loss: 1.0734169483184814
Validation loss: 1.7635029080093547

Epoch: 6| Step: 10
Training loss: 1.156674861907959
Validation loss: 1.8911544353731218

Epoch: 6| Step: 11
Training loss: 0.8967607021331787
Validation loss: 1.7709667278874306

Epoch: 6| Step: 12
Training loss: 1.6296706199645996
Validation loss: 1.7990439643142044

Epoch: 6| Step: 13
Training loss: 1.840553879737854
Validation loss: 1.8048214515050252

Epoch: 397| Step: 0
Training loss: 1.06719172000885
Validation loss: 1.772183834865529

Epoch: 6| Step: 1
Training loss: 1.2993860244750977
Validation loss: 1.7721214345706406

Epoch: 6| Step: 2
Training loss: 0.9482822418212891
Validation loss: 1.7728607180298015

Epoch: 6| Step: 3
Training loss: 1.3292537927627563
Validation loss: 1.7846178341937322

Epoch: 6| Step: 4
Training loss: 1.3069244623184204
Validation loss: 1.7591965249789658

Epoch: 6| Step: 5
Training loss: 1.4245548248291016
Validation loss: 1.758956427215248

Epoch: 6| Step: 6
Training loss: 1.3067461252212524
Validation loss: 1.7756283872870988

Epoch: 6| Step: 7
Training loss: 1.809570550918579
Validation loss: 1.7931900024414062

Epoch: 6| Step: 8
Training loss: 1.2965853214263916
Validation loss: 1.7634516082784182

Epoch: 6| Step: 9
Training loss: 0.7254458665847778
Validation loss: 1.7693866273408294

Epoch: 6| Step: 10
Training loss: 1.281418800354004
Validation loss: 1.8265472278800061

Epoch: 6| Step: 11
Training loss: 0.7970863580703735
Validation loss: 1.815784174908874

Epoch: 6| Step: 12
Training loss: 1.6460587978363037
Validation loss: 1.798435995655675

Epoch: 6| Step: 13
Training loss: 1.4723113775253296
Validation loss: 1.862022542184399

Epoch: 398| Step: 0
Training loss: 0.9452553391456604
Validation loss: 1.7982288111922562

Epoch: 6| Step: 1
Training loss: 1.2040424346923828
Validation loss: 1.7922702784179358

Epoch: 6| Step: 2
Training loss: 0.9174522161483765
Validation loss: 1.7630328709079373

Epoch: 6| Step: 3
Training loss: 1.3756067752838135
Validation loss: 1.758163776448978

Epoch: 6| Step: 4
Training loss: 1.206711769104004
Validation loss: 1.763859245084947

Epoch: 6| Step: 5
Training loss: 1.0806069374084473
Validation loss: 1.6929762850525558

Epoch: 6| Step: 6
Training loss: 1.4476993083953857
Validation loss: 1.7864910876879128

Epoch: 6| Step: 7
Training loss: 1.4377479553222656
Validation loss: 1.8277805543714953

Epoch: 6| Step: 8
Training loss: 1.9537876844406128
Validation loss: 1.8099850877638786

Epoch: 6| Step: 9
Training loss: 0.8919768929481506
Validation loss: 1.7668326349668606

Epoch: 6| Step: 10
Training loss: 1.104569911956787
Validation loss: 1.711907943089803

Epoch: 6| Step: 11
Training loss: 1.2894086837768555
Validation loss: 1.7779569190035585

Epoch: 6| Step: 12
Training loss: 1.4409542083740234
Validation loss: 1.830992773015012

Epoch: 6| Step: 13
Training loss: 1.4361059665679932
Validation loss: 1.8185256809316657

Epoch: 399| Step: 0
Training loss: 0.7929551005363464
Validation loss: 1.784543873161398

Epoch: 6| Step: 1
Training loss: 1.0565099716186523
Validation loss: 1.7146639336821854

Epoch: 6| Step: 2
Training loss: 1.3120031356811523
Validation loss: 1.7530694405237834

Epoch: 6| Step: 3
Training loss: 1.0644073486328125
Validation loss: 1.8013082473508772

Epoch: 6| Step: 4
Training loss: 1.7650892734527588
Validation loss: 1.7674976228385844

Epoch: 6| Step: 5
Training loss: 1.6097266674041748
Validation loss: 1.8158031932769283

Epoch: 6| Step: 6
Training loss: 1.3170329332351685
Validation loss: 1.7400104115086217

Epoch: 6| Step: 7
Training loss: 1.3338655233383179
Validation loss: 1.7457173665364583

Epoch: 6| Step: 8
Training loss: 0.8121203184127808
Validation loss: 1.7664206899622434

Epoch: 6| Step: 9
Training loss: 1.1823235750198364
Validation loss: 1.7632658635416338

Epoch: 6| Step: 10
Training loss: 1.5829358100891113
Validation loss: 1.7753664165414789

Epoch: 6| Step: 11
Training loss: 1.4805124998092651
Validation loss: 1.7963145471388293

Epoch: 6| Step: 12
Training loss: 0.9174105525016785
Validation loss: 1.7839184371373986

Epoch: 6| Step: 13
Training loss: 1.8507351875305176
Validation loss: 1.7441707182955999

Epoch: 400| Step: 0
Training loss: 1.7107197046279907
Validation loss: 1.7508988149704472

Epoch: 6| Step: 1
Training loss: 1.265978217124939
Validation loss: 1.8347535902454006

Epoch: 6| Step: 2
Training loss: 1.2712538242340088
Validation loss: 1.8425496111633957

Epoch: 6| Step: 3
Training loss: 1.5244035720825195
Validation loss: 1.8363945471343173

Epoch: 6| Step: 4
Training loss: 0.6464730501174927
Validation loss: 1.8292176954207882

Epoch: 6| Step: 5
Training loss: 1.250896692276001
Validation loss: 1.7988113357174782

Epoch: 6| Step: 6
Training loss: 1.5092544555664062
Validation loss: 1.7968864748554845

Epoch: 6| Step: 7
Training loss: 1.300689697265625
Validation loss: 1.8009701659602504

Epoch: 6| Step: 8
Training loss: 0.8103683590888977
Validation loss: 1.7782807978250648

Epoch: 6| Step: 9
Training loss: 0.9441789388656616
Validation loss: 1.7471394743970645

Epoch: 6| Step: 10
Training loss: 1.1205484867095947
Validation loss: 1.7400524334240985

Epoch: 6| Step: 11
Training loss: 1.0306792259216309
Validation loss: 1.8407576302046418

Epoch: 6| Step: 12
Training loss: 1.6748288869857788
Validation loss: 1.803682291379539

Epoch: 6| Step: 13
Training loss: 1.7152228355407715
Validation loss: 1.8236273898873279

Epoch: 401| Step: 0
Training loss: 1.0861103534698486
Validation loss: 1.7961978899535311

Epoch: 6| Step: 1
Training loss: 1.0840656757354736
Validation loss: 1.7626120608340028

Epoch: 6| Step: 2
Training loss: 1.2311781644821167
Validation loss: 1.7766537025410643

Epoch: 6| Step: 3
Training loss: 0.9327167272567749
Validation loss: 1.7956659152943601

Epoch: 6| Step: 4
Training loss: 1.4383642673492432
Validation loss: 1.8130511545365857

Epoch: 6| Step: 5
Training loss: 1.0943013429641724
Validation loss: 1.746183273612812

Epoch: 6| Step: 6
Training loss: 1.2585430145263672
Validation loss: 1.7484308429943618

Epoch: 6| Step: 7
Training loss: 2.012059450149536
Validation loss: 1.7654165657617713

Epoch: 6| Step: 8
Training loss: 0.985901951789856
Validation loss: 1.7909327604437386

Epoch: 6| Step: 9
Training loss: 1.2327406406402588
Validation loss: 1.8092830898941203

Epoch: 6| Step: 10
Training loss: 1.5032275915145874
Validation loss: 1.814461019731337

Epoch: 6| Step: 11
Training loss: 1.593624472618103
Validation loss: 1.7961641088608773

Epoch: 6| Step: 12
Training loss: 0.9480923414230347
Validation loss: 1.7688685540230042

Epoch: 6| Step: 13
Training loss: 1.730468511581421
Validation loss: 1.7756376971480667

Epoch: 402| Step: 0
Training loss: 1.6405913829803467
Validation loss: 1.8673910992119902

Epoch: 6| Step: 1
Training loss: 1.6837437152862549
Validation loss: 1.7411496023977957

Epoch: 6| Step: 2
Training loss: 0.9984295964241028
Validation loss: 1.8362724293944657

Epoch: 6| Step: 3
Training loss: 1.1755315065383911
Validation loss: 1.752748365043312

Epoch: 6| Step: 4
Training loss: 1.4238307476043701
Validation loss: 1.8192522448878135

Epoch: 6| Step: 5
Training loss: 0.7753906846046448
Validation loss: 1.77605809832132

Epoch: 6| Step: 6
Training loss: 0.9005081057548523
Validation loss: 1.7958154473253476

Epoch: 6| Step: 7
Training loss: 0.8557115793228149
Validation loss: 1.7448233660831247

Epoch: 6| Step: 8
Training loss: 1.6627686023712158
Validation loss: 1.7105835701829644

Epoch: 6| Step: 9
Training loss: 1.7151421308517456
Validation loss: 1.7719783013866794

Epoch: 6| Step: 10
Training loss: 0.9759608507156372
Validation loss: 1.7449471873621787

Epoch: 6| Step: 11
Training loss: 1.2413243055343628
Validation loss: 1.7830325300975511

Epoch: 6| Step: 12
Training loss: 1.362247347831726
Validation loss: 1.80601179727944

Epoch: 6| Step: 13
Training loss: 0.4506905972957611
Validation loss: 1.7513150707367928

Epoch: 403| Step: 0
Training loss: 1.7376141548156738
Validation loss: 1.7610124503412554

Epoch: 6| Step: 1
Training loss: 0.9790752530097961
Validation loss: 1.8247693328447239

Epoch: 6| Step: 2
Training loss: 1.3929129838943481
Validation loss: 1.798227821626971

Epoch: 6| Step: 3
Training loss: 1.0392956733703613
Validation loss: 1.8314489382569508

Epoch: 6| Step: 4
Training loss: 1.5196865797042847
Validation loss: 1.722398604116132

Epoch: 6| Step: 5
Training loss: 0.8828365802764893
Validation loss: 1.7396926879882812

Epoch: 6| Step: 6
Training loss: 1.440912127494812
Validation loss: 1.760889535309166

Epoch: 6| Step: 7
Training loss: 1.403381109237671
Validation loss: 1.744586783070718

Epoch: 6| Step: 8
Training loss: 1.4952067136764526
Validation loss: 1.765288406802762

Epoch: 6| Step: 9
Training loss: 0.6891142129898071
Validation loss: 1.7972996491257862

Epoch: 6| Step: 10
Training loss: 1.352324366569519
Validation loss: 1.8176633824584305

Epoch: 6| Step: 11
Training loss: 1.638622522354126
Validation loss: 1.808492140103412

Epoch: 6| Step: 12
Training loss: 0.7975847125053406
Validation loss: 1.8120110919398646

Epoch: 6| Step: 13
Training loss: 1.3157316446304321
Validation loss: 1.9097956098536009

Epoch: 404| Step: 0
Training loss: 1.2177947759628296
Validation loss: 1.7959120978591263

Epoch: 6| Step: 1
Training loss: 1.2900665998458862
Validation loss: 1.8798065352183517

Epoch: 6| Step: 2
Training loss: 0.990100085735321
Validation loss: 1.8284953947990172

Epoch: 6| Step: 3
Training loss: 1.2236087322235107
Validation loss: 1.8522729540383944

Epoch: 6| Step: 4
Training loss: 1.0454471111297607
Validation loss: 1.8043039780791088

Epoch: 6| Step: 5
Training loss: 1.0658372640609741
Validation loss: 1.754756276325513

Epoch: 6| Step: 6
Training loss: 2.14422345161438
Validation loss: 1.7692308759176603

Epoch: 6| Step: 7
Training loss: 1.380921483039856
Validation loss: 1.8624119168968611

Epoch: 6| Step: 8
Training loss: 1.070169448852539
Validation loss: 1.7800639201236028

Epoch: 6| Step: 9
Training loss: 1.484338402748108
Validation loss: 1.7676525667149534

Epoch: 6| Step: 10
Training loss: 1.7823419570922852
Validation loss: 1.7430048091437227

Epoch: 6| Step: 11
Training loss: 1.1966383457183838
Validation loss: 1.7960157048317693

Epoch: 6| Step: 12
Training loss: 0.7672121524810791
Validation loss: 1.7945645688682474

Epoch: 6| Step: 13
Training loss: 0.6238769292831421
Validation loss: 1.7913955949967908

Epoch: 405| Step: 0
Training loss: 0.9537109136581421
Validation loss: 1.79352738523996

Epoch: 6| Step: 1
Training loss: 1.7234787940979004
Validation loss: 1.7461303857065016

Epoch: 6| Step: 2
Training loss: 1.0358846187591553
Validation loss: 1.8212637747487714

Epoch: 6| Step: 3
Training loss: 0.8550840020179749
Validation loss: 1.7409383866094774

Epoch: 6| Step: 4
Training loss: 1.1127978563308716
Validation loss: 1.8417720833132345

Epoch: 6| Step: 5
Training loss: 1.0976735353469849
Validation loss: 1.7923887339971398

Epoch: 6| Step: 6
Training loss: 1.3277137279510498
Validation loss: 1.766202618998866

Epoch: 6| Step: 7
Training loss: 1.2396798133850098
Validation loss: 1.808552436931159

Epoch: 6| Step: 8
Training loss: 1.666933298110962
Validation loss: 1.7976026906762073

Epoch: 6| Step: 9
Training loss: 1.460455060005188
Validation loss: 1.745703274203885

Epoch: 6| Step: 10
Training loss: 0.9456515908241272
Validation loss: 1.773085960777857

Epoch: 6| Step: 11
Training loss: 1.3537821769714355
Validation loss: 1.8177292334136141

Epoch: 6| Step: 12
Training loss: 1.5418906211853027
Validation loss: 1.7672002700067335

Epoch: 6| Step: 13
Training loss: 1.425599217414856
Validation loss: 1.7897879628724949

Epoch: 406| Step: 0
Training loss: 1.0813754796981812
Validation loss: 1.7587876191703222

Epoch: 6| Step: 1
Training loss: 1.261114478111267
Validation loss: 1.7595516250979515

Epoch: 6| Step: 2
Training loss: 1.575371265411377
Validation loss: 1.8258885619460896

Epoch: 6| Step: 3
Training loss: 1.04918372631073
Validation loss: 1.8028197160331152

Epoch: 6| Step: 4
Training loss: 1.4592880010604858
Validation loss: 1.7984815143769788

Epoch: 6| Step: 5
Training loss: 1.4028462171554565
Validation loss: 1.7526231542710335

Epoch: 6| Step: 6
Training loss: 0.8550087809562683
Validation loss: 1.7240482017558107

Epoch: 6| Step: 7
Training loss: 1.3159189224243164
Validation loss: 1.7694672128205657

Epoch: 6| Step: 8
Training loss: 1.4815706014633179
Validation loss: 1.791382089737923

Epoch: 6| Step: 9
Training loss: 0.9565515518188477
Validation loss: 1.7432152942944599

Epoch: 6| Step: 10
Training loss: 1.1013998985290527
Validation loss: 1.7459892457531345

Epoch: 6| Step: 11
Training loss: 1.668047547340393
Validation loss: 1.7552914516900175

Epoch: 6| Step: 12
Training loss: 0.9889997839927673
Validation loss: 1.789422788927632

Epoch: 6| Step: 13
Training loss: 1.5817724466323853
Validation loss: 1.7295373229570286

Epoch: 407| Step: 0
Training loss: 1.008765697479248
Validation loss: 1.8069713795056908

Epoch: 6| Step: 1
Training loss: 1.3903762102127075
Validation loss: 1.7513955921255133

Epoch: 6| Step: 2
Training loss: 1.015472412109375
Validation loss: 1.7821523912491337

Epoch: 6| Step: 3
Training loss: 1.0960896015167236
Validation loss: 1.802113047210119

Epoch: 6| Step: 4
Training loss: 0.9520728588104248
Validation loss: 1.7592041723189815

Epoch: 6| Step: 5
Training loss: 1.7363415956497192
Validation loss: 1.7952779646842711

Epoch: 6| Step: 6
Training loss: 1.3574700355529785
Validation loss: 1.8085978338795323

Epoch: 6| Step: 7
Training loss: 1.0698580741882324
Validation loss: 1.832001955278458

Epoch: 6| Step: 8
Training loss: 1.0771305561065674
Validation loss: 1.8280737015508837

Epoch: 6| Step: 9
Training loss: 1.0762338638305664
Validation loss: 1.839330268162553

Epoch: 6| Step: 10
Training loss: 1.3108257055282593
Validation loss: 1.8057926495869954

Epoch: 6| Step: 11
Training loss: 1.3897230625152588
Validation loss: 1.8095743117793914

Epoch: 6| Step: 12
Training loss: 1.4731576442718506
Validation loss: 1.7956814086565407

Epoch: 6| Step: 13
Training loss: 1.260899305343628
Validation loss: 1.8431254779138873

Epoch: 408| Step: 0
Training loss: 0.8436551690101624
Validation loss: 1.7943397927027878

Epoch: 6| Step: 1
Training loss: 1.3952945470809937
Validation loss: 1.7628502166399391

Epoch: 6| Step: 2
Training loss: 1.582134485244751
Validation loss: 1.810699466736086

Epoch: 6| Step: 3
Training loss: 1.2092736959457397
Validation loss: 1.7974014256590156

Epoch: 6| Step: 4
Training loss: 1.1065646409988403
Validation loss: 1.7722245570152038

Epoch: 6| Step: 5
Training loss: 0.936200737953186
Validation loss: 1.7362284288611463

Epoch: 6| Step: 6
Training loss: 1.4562668800354004
Validation loss: 1.8129597197296798

Epoch: 6| Step: 7
Training loss: 1.0554008483886719
Validation loss: 1.7843766007372128

Epoch: 6| Step: 8
Training loss: 1.407808542251587
Validation loss: 1.7738373253935127

Epoch: 6| Step: 9
Training loss: 1.1938737630844116
Validation loss: 1.7476378999730593

Epoch: 6| Step: 10
Training loss: 1.3076705932617188
Validation loss: 1.825319017133405

Epoch: 6| Step: 11
Training loss: 0.8429400324821472
Validation loss: 1.765492654615833

Epoch: 6| Step: 12
Training loss: 1.4637187719345093
Validation loss: 1.761407849609211

Epoch: 6| Step: 13
Training loss: 1.7681492567062378
Validation loss: 1.7868333029490646

Epoch: 409| Step: 0
Training loss: 1.1516696214675903
Validation loss: 1.7831631834788988

Epoch: 6| Step: 1
Training loss: 0.8479769229888916
Validation loss: 1.7878985789514357

Epoch: 6| Step: 2
Training loss: 1.0212091207504272
Validation loss: 1.750143233165946

Epoch: 6| Step: 3
Training loss: 1.063943862915039
Validation loss: 1.8031634028239916

Epoch: 6| Step: 4
Training loss: 1.2387688159942627
Validation loss: 1.7204229434331257

Epoch: 6| Step: 5
Training loss: 1.3755630254745483
Validation loss: 1.697138290251455

Epoch: 6| Step: 6
Training loss: 1.4568202495574951
Validation loss: 1.75416959229336

Epoch: 6| Step: 7
Training loss: 1.60933256149292
Validation loss: 1.7460306267584524

Epoch: 6| Step: 8
Training loss: 0.9906171560287476
Validation loss: 1.786565403784475

Epoch: 6| Step: 9
Training loss: 1.0313626527786255
Validation loss: 1.835612650840513

Epoch: 6| Step: 10
Training loss: 1.0003280639648438
Validation loss: 1.782031270765489

Epoch: 6| Step: 11
Training loss: 1.5834777355194092
Validation loss: 1.7769669127720658

Epoch: 6| Step: 12
Training loss: 1.232002854347229
Validation loss: 1.7371745635104436

Epoch: 6| Step: 13
Training loss: 1.9623091220855713
Validation loss: 1.746584742299972

Epoch: 410| Step: 0
Training loss: 1.0134531259536743
Validation loss: 1.7391935804838776

Epoch: 6| Step: 1
Training loss: 1.9159431457519531
Validation loss: 1.7681908069118377

Epoch: 6| Step: 2
Training loss: 1.034909963607788
Validation loss: 1.8276326861432803

Epoch: 6| Step: 3
Training loss: 1.4658160209655762
Validation loss: 1.7472029270664338

Epoch: 6| Step: 4
Training loss: 1.0020819902420044
Validation loss: 1.817319832822328

Epoch: 6| Step: 5
Training loss: 0.5342305898666382
Validation loss: 1.7824652951250795

Epoch: 6| Step: 6
Training loss: 1.29584538936615
Validation loss: 1.852378688832765

Epoch: 6| Step: 7
Training loss: 1.3634774684906006
Validation loss: 1.8219869726447648

Epoch: 6| Step: 8
Training loss: 1.5809135437011719
Validation loss: 1.7346299002247472

Epoch: 6| Step: 9
Training loss: 1.3040286302566528
Validation loss: 1.7781143803750314

Epoch: 6| Step: 10
Training loss: 1.6133878231048584
Validation loss: 1.7940116249104983

Epoch: 6| Step: 11
Training loss: 1.28220534324646
Validation loss: 1.8076592696610319

Epoch: 6| Step: 12
Training loss: 1.3119266033172607
Validation loss: 1.8180174827575684

Epoch: 6| Step: 13
Training loss: 0.45254409313201904
Validation loss: 1.726589511799556

Epoch: 411| Step: 0
Training loss: 0.857379138469696
Validation loss: 1.7555986283927836

Epoch: 6| Step: 1
Training loss: 1.2924659252166748
Validation loss: 1.7846229178931123

Epoch: 6| Step: 2
Training loss: 1.217822790145874
Validation loss: 1.7900546558441655

Epoch: 6| Step: 3
Training loss: 1.2086710929870605
Validation loss: 1.7404013782419183

Epoch: 6| Step: 4
Training loss: 1.130772352218628
Validation loss: 1.7779468990141345

Epoch: 6| Step: 5
Training loss: 1.3691757917404175
Validation loss: 1.6985418437629618

Epoch: 6| Step: 6
Training loss: 0.6576216816902161
Validation loss: 1.7943276871917069

Epoch: 6| Step: 7
Training loss: 1.9797546863555908
Validation loss: 1.725165924718303

Epoch: 6| Step: 8
Training loss: 0.7928648591041565
Validation loss: 1.7840095309800998

Epoch: 6| Step: 9
Training loss: 1.1192439794540405
Validation loss: 1.7914538409120293

Epoch: 6| Step: 10
Training loss: 1.7321977615356445
Validation loss: 1.808287343671245

Epoch: 6| Step: 11
Training loss: 1.4687557220458984
Validation loss: 1.7953101819561375

Epoch: 6| Step: 12
Training loss: 1.0048185586929321
Validation loss: 1.7367024114055019

Epoch: 6| Step: 13
Training loss: 1.2750129699707031
Validation loss: 1.7626474724021008

Epoch: 412| Step: 0
Training loss: 0.7695993185043335
Validation loss: 1.8156489569653746

Epoch: 6| Step: 1
Training loss: 1.2404475212097168
Validation loss: 1.7692947285149687

Epoch: 6| Step: 2
Training loss: 1.4895670413970947
Validation loss: 1.7587973033228228

Epoch: 6| Step: 3
Training loss: 1.254366397857666
Validation loss: 1.7499413041658298

Epoch: 6| Step: 4
Training loss: 0.8729693293571472
Validation loss: 1.79933790750401

Epoch: 6| Step: 5
Training loss: 1.4594417810440063
Validation loss: 1.8453421849076466

Epoch: 6| Step: 6
Training loss: 1.0454801321029663
Validation loss: 1.8002309337739022

Epoch: 6| Step: 7
Training loss: 1.4922927618026733
Validation loss: 1.7715595486343547

Epoch: 6| Step: 8
Training loss: 1.4248170852661133
Validation loss: 1.7359333012693672

Epoch: 6| Step: 9
Training loss: 1.244994878768921
Validation loss: 1.755218154640608

Epoch: 6| Step: 10
Training loss: 1.1190167665481567
Validation loss: 1.785584178022159

Epoch: 6| Step: 11
Training loss: 1.1039886474609375
Validation loss: 1.7566740807666574

Epoch: 6| Step: 12
Training loss: 1.3086950778961182
Validation loss: 1.8210891523668844

Epoch: 6| Step: 13
Training loss: 1.4665660858154297
Validation loss: 1.818717937315664

Epoch: 413| Step: 0
Training loss: 1.211857795715332
Validation loss: 1.7733507707554808

Epoch: 6| Step: 1
Training loss: 1.2320036888122559
Validation loss: 1.7855236889213644

Epoch: 6| Step: 2
Training loss: 1.4538817405700684
Validation loss: 1.6836743066387792

Epoch: 6| Step: 3
Training loss: 1.8055024147033691
Validation loss: 1.811011875829389

Epoch: 6| Step: 4
Training loss: 0.9805530905723572
Validation loss: 1.7486946172611688

Epoch: 6| Step: 5
Training loss: 1.9586483240127563
Validation loss: 1.8026092385733

Epoch: 6| Step: 6
Training loss: 0.6662418842315674
Validation loss: 1.737341833370988

Epoch: 6| Step: 7
Training loss: 1.365476369857788
Validation loss: 1.760893129533337

Epoch: 6| Step: 8
Training loss: 1.2974191904067993
Validation loss: 1.7981406642544655

Epoch: 6| Step: 9
Training loss: 1.0025148391723633
Validation loss: 1.7660882229446082

Epoch: 6| Step: 10
Training loss: 1.0975124835968018
Validation loss: 1.7684007870253695

Epoch: 6| Step: 11
Training loss: 1.0080167055130005
Validation loss: 1.8193675869254655

Epoch: 6| Step: 12
Training loss: 1.015556812286377
Validation loss: 1.7966544282051824

Epoch: 6| Step: 13
Training loss: 1.4621989727020264
Validation loss: 1.7460711361259542

Epoch: 414| Step: 0
Training loss: 1.458924412727356
Validation loss: 1.7805295221267208

Epoch: 6| Step: 1
Training loss: 1.2591192722320557
Validation loss: 1.7272151375329623

Epoch: 6| Step: 2
Training loss: 1.3939385414123535
Validation loss: 1.7660918017869354

Epoch: 6| Step: 3
Training loss: 0.8934605121612549
Validation loss: 1.7515685532682685

Epoch: 6| Step: 4
Training loss: 1.5453381538391113
Validation loss: 1.7925800072249545

Epoch: 6| Step: 5
Training loss: 0.8724524974822998
Validation loss: 1.8120633940542898

Epoch: 6| Step: 6
Training loss: 1.1161983013153076
Validation loss: 1.800728440284729

Epoch: 6| Step: 7
Training loss: 0.9776588678359985
Validation loss: 1.748539520848182

Epoch: 6| Step: 8
Training loss: 1.3771215677261353
Validation loss: 1.7401662039500412

Epoch: 6| Step: 9
Training loss: 0.7674530744552612
Validation loss: 1.8017276064042123

Epoch: 6| Step: 10
Training loss: 1.0974255800247192
Validation loss: 1.7862899072708622

Epoch: 6| Step: 11
Training loss: 1.4384183883666992
Validation loss: 1.8088990334541566

Epoch: 6| Step: 12
Training loss: 1.1930489540100098
Validation loss: 1.7839915970320344

Epoch: 6| Step: 13
Training loss: 1.632214069366455
Validation loss: 1.7981525774924987

Epoch: 415| Step: 0
Training loss: 1.908953309059143
Validation loss: 1.758258549115991

Epoch: 6| Step: 1
Training loss: 0.9093908071517944
Validation loss: 1.782264458235874

Epoch: 6| Step: 2
Training loss: 0.7850481271743774
Validation loss: 1.802305652249244

Epoch: 6| Step: 3
Training loss: 0.9876788854598999
Validation loss: 1.7800184719024166

Epoch: 6| Step: 4
Training loss: 1.216416835784912
Validation loss: 1.814737271237117

Epoch: 6| Step: 5
Training loss: 1.1284011602401733
Validation loss: 1.7246252157354867

Epoch: 6| Step: 6
Training loss: 1.216071367263794
Validation loss: 1.7341264704222321

Epoch: 6| Step: 7
Training loss: 0.8859735131263733
Validation loss: 1.7797684425948768

Epoch: 6| Step: 8
Training loss: 1.1157115697860718
Validation loss: 1.7835656314767816

Epoch: 6| Step: 9
Training loss: 1.371250867843628
Validation loss: 1.770503359456216

Epoch: 6| Step: 10
Training loss: 0.6053017377853394
Validation loss: 1.7621437823900612

Epoch: 6| Step: 11
Training loss: 1.4427120685577393
Validation loss: 1.7736437423254854

Epoch: 6| Step: 12
Training loss: 1.7004612684249878
Validation loss: 1.807094447074398

Epoch: 6| Step: 13
Training loss: 1.945648193359375
Validation loss: 1.8314330757305186

Epoch: 416| Step: 0
Training loss: 1.1365655660629272
Validation loss: 1.7170456019780969

Epoch: 6| Step: 1
Training loss: 1.3984568119049072
Validation loss: 1.7378674309740785

Epoch: 6| Step: 2
Training loss: 1.6110950708389282
Validation loss: 1.7963938610528105

Epoch: 6| Step: 3
Training loss: 1.2020021677017212
Validation loss: 1.7808134171270555

Epoch: 6| Step: 4
Training loss: 1.0011630058288574
Validation loss: 1.7799693845933484

Epoch: 6| Step: 5
Training loss: 0.7614043951034546
Validation loss: 1.770364680597859

Epoch: 6| Step: 6
Training loss: 1.3019661903381348
Validation loss: 1.787423877305882

Epoch: 6| Step: 7
Training loss: 1.241268515586853
Validation loss: 1.8171861517813899

Epoch: 6| Step: 8
Training loss: 1.3179492950439453
Validation loss: 1.8042709263422156

Epoch: 6| Step: 9
Training loss: 1.0487697124481201
Validation loss: 1.848779172025701

Epoch: 6| Step: 10
Training loss: 1.5875623226165771
Validation loss: 1.8448035499101043

Epoch: 6| Step: 11
Training loss: 0.8090635538101196
Validation loss: 1.7476498939657723

Epoch: 6| Step: 12
Training loss: 1.4821555614471436
Validation loss: 1.7768144479361914

Epoch: 6| Step: 13
Training loss: 1.513964295387268
Validation loss: 1.7746152916262228

Epoch: 417| Step: 0
Training loss: 0.8387467265129089
Validation loss: 1.779343569150535

Epoch: 6| Step: 1
Training loss: 0.9953901767730713
Validation loss: 1.7989305924343806

Epoch: 6| Step: 2
Training loss: 1.765685796737671
Validation loss: 1.7992368128991896

Epoch: 6| Step: 3
Training loss: 0.8888534307479858
Validation loss: 1.7481720626995128

Epoch: 6| Step: 4
Training loss: 1.272060751914978
Validation loss: 1.7982326412713656

Epoch: 6| Step: 5
Training loss: 0.8595617413520813
Validation loss: 1.7224456424354224

Epoch: 6| Step: 6
Training loss: 1.2634613513946533
Validation loss: 1.8161259876784457

Epoch: 6| Step: 7
Training loss: 1.1583075523376465
Validation loss: 1.7477010065509426

Epoch: 6| Step: 8
Training loss: 1.2518737316131592
Validation loss: 1.7099194988127677

Epoch: 6| Step: 9
Training loss: 1.6972826719284058
Validation loss: 1.72901996169039

Epoch: 6| Step: 10
Training loss: 1.637533187866211
Validation loss: 1.7888993678554412

Epoch: 6| Step: 11
Training loss: 1.055112600326538
Validation loss: 1.7837281842385568

Epoch: 6| Step: 12
Training loss: 1.2535582780838013
Validation loss: 1.7541237672170003

Epoch: 6| Step: 13
Training loss: 0.7826530933380127
Validation loss: 1.803043011696108

Epoch: 418| Step: 0
Training loss: 1.1505013704299927
Validation loss: 1.7505121285556464

Epoch: 6| Step: 1
Training loss: 1.2096431255340576
Validation loss: 1.8357666371971049

Epoch: 6| Step: 2
Training loss: 1.3755595684051514
Validation loss: 1.7974553902943928

Epoch: 6| Step: 3
Training loss: 1.8196287155151367
Validation loss: 1.777986998840045

Epoch: 6| Step: 4
Training loss: 1.3028864860534668
Validation loss: 1.8044714555945447

Epoch: 6| Step: 5
Training loss: 1.2942246198654175
Validation loss: 1.8123738368352253

Epoch: 6| Step: 6
Training loss: 1.0737255811691284
Validation loss: 1.802625169036209

Epoch: 6| Step: 7
Training loss: 1.148869276046753
Validation loss: 1.8356708839375486

Epoch: 6| Step: 8
Training loss: 0.6555342078208923
Validation loss: 1.755902837681514

Epoch: 6| Step: 9
Training loss: 1.2633652687072754
Validation loss: 1.7443222166389547

Epoch: 6| Step: 10
Training loss: 1.2722647190093994
Validation loss: 1.819870469390705

Epoch: 6| Step: 11
Training loss: 1.2435953617095947
Validation loss: 1.7797366265327699

Epoch: 6| Step: 12
Training loss: 0.9955826997756958
Validation loss: 1.7331584410000873

Epoch: 6| Step: 13
Training loss: 1.179218053817749
Validation loss: 1.7266035592684181

Epoch: 419| Step: 0
Training loss: 0.976832389831543
Validation loss: 1.759487166199633

Epoch: 6| Step: 1
Training loss: 1.1736679077148438
Validation loss: 1.7188969248084611

Epoch: 6| Step: 2
Training loss: 1.3267407417297363
Validation loss: 1.8248583911567606

Epoch: 6| Step: 3
Training loss: 1.1725685596466064
Validation loss: 1.784255657144772

Epoch: 6| Step: 4
Training loss: 1.1852259635925293
Validation loss: 1.7605491658692718

Epoch: 6| Step: 5
Training loss: 1.7121453285217285
Validation loss: 1.7534344503956456

Epoch: 6| Step: 6
Training loss: 0.8875942230224609
Validation loss: 1.7449728801686277

Epoch: 6| Step: 7
Training loss: 1.2723551988601685
Validation loss: 1.8123906350904895

Epoch: 6| Step: 8
Training loss: 1.9689769744873047
Validation loss: 1.803801603214715

Epoch: 6| Step: 9
Training loss: 0.8672669529914856
Validation loss: 1.747331807049372

Epoch: 6| Step: 10
Training loss: 0.9073697328567505
Validation loss: 1.7291372501721947

Epoch: 6| Step: 11
Training loss: 1.0236091613769531
Validation loss: 1.8125982579364572

Epoch: 6| Step: 12
Training loss: 1.2157078981399536
Validation loss: 1.723776917303762

Epoch: 6| Step: 13
Training loss: 0.8758506774902344
Validation loss: 1.787196102962699

Epoch: 420| Step: 0
Training loss: 1.9594395160675049
Validation loss: 1.7702309931478193

Epoch: 6| Step: 1
Training loss: 1.7951606512069702
Validation loss: 1.7107087348097114

Epoch: 6| Step: 2
Training loss: 1.3044946193695068
Validation loss: 1.7267449017493957

Epoch: 6| Step: 3
Training loss: 1.0880166292190552
Validation loss: 1.79527953363234

Epoch: 6| Step: 4
Training loss: 1.2508121728897095
Validation loss: 1.7409831400840514

Epoch: 6| Step: 5
Training loss: 1.019690990447998
Validation loss: 1.7891938212097331

Epoch: 6| Step: 6
Training loss: 1.0990896224975586
Validation loss: 1.7654918086144231

Epoch: 6| Step: 7
Training loss: 0.7596868872642517
Validation loss: 1.7749267073087795

Epoch: 6| Step: 8
Training loss: 0.9931214451789856
Validation loss: 1.7474104665940808

Epoch: 6| Step: 9
Training loss: 1.0348000526428223
Validation loss: 1.7982296559118456

Epoch: 6| Step: 10
Training loss: 1.3219709396362305
Validation loss: 1.8010674086950158

Epoch: 6| Step: 11
Training loss: 1.2635022401809692
Validation loss: 1.827298689914006

Epoch: 6| Step: 12
Training loss: 1.1564691066741943
Validation loss: 1.7763942031450168

Epoch: 6| Step: 13
Training loss: 0.9180852174758911
Validation loss: 1.7898013950676046

Epoch: 421| Step: 0
Training loss: 1.1672418117523193
Validation loss: 1.78870681793459

Epoch: 6| Step: 1
Training loss: 1.6202293634414673
Validation loss: 1.731804451634807

Epoch: 6| Step: 2
Training loss: 1.3514755964279175
Validation loss: 1.8528395622007308

Epoch: 6| Step: 3
Training loss: 0.7875798940658569
Validation loss: 1.7798752912911036

Epoch: 6| Step: 4
Training loss: 1.134342908859253
Validation loss: 1.7268334614333285

Epoch: 6| Step: 5
Training loss: 1.4218201637268066
Validation loss: 1.8156308743261522

Epoch: 6| Step: 6
Training loss: 0.696354329586029
Validation loss: 1.7556250595277356

Epoch: 6| Step: 7
Training loss: 0.8920021057128906
Validation loss: 1.811983528957572

Epoch: 6| Step: 8
Training loss: 1.0147900581359863
Validation loss: 1.811815897623698

Epoch: 6| Step: 9
Training loss: 1.2757022380828857
Validation loss: 1.7977101700280302

Epoch: 6| Step: 10
Training loss: 1.4970920085906982
Validation loss: 1.78839966558641

Epoch: 6| Step: 11
Training loss: 1.0092320442199707
Validation loss: 1.7298700450569071

Epoch: 6| Step: 12
Training loss: 0.9631283283233643
Validation loss: 1.754062544914984

Epoch: 6| Step: 13
Training loss: 1.0085468292236328
Validation loss: 1.7426071654083908

Epoch: 422| Step: 0
Training loss: 1.2517402172088623
Validation loss: 1.7700571642127088

Epoch: 6| Step: 1
Training loss: 1.3482662439346313
Validation loss: 1.7692130970698532

Epoch: 6| Step: 2
Training loss: 1.0249511003494263
Validation loss: 1.7493108523789274

Epoch: 6| Step: 3
Training loss: 1.0270791053771973
Validation loss: 1.715566074976357

Epoch: 6| Step: 4
Training loss: 0.8686385154724121
Validation loss: 1.8014347143070673

Epoch: 6| Step: 5
Training loss: 1.1789188385009766
Validation loss: 1.7939998911273094

Epoch: 6| Step: 6
Training loss: 1.746603012084961
Validation loss: 1.775619754227259

Epoch: 6| Step: 7
Training loss: 1.3612308502197266
Validation loss: 1.7183802063747118

Epoch: 6| Step: 8
Training loss: 0.9443628787994385
Validation loss: 1.7675987341070687

Epoch: 6| Step: 9
Training loss: 1.57359778881073
Validation loss: 1.7477049020028883

Epoch: 6| Step: 10
Training loss: 0.9122319221496582
Validation loss: 1.7603815550445228

Epoch: 6| Step: 11
Training loss: 1.039560079574585
Validation loss: 1.7655070174124934

Epoch: 6| Step: 12
Training loss: 0.9918186068534851
Validation loss: 1.7453806579753917

Epoch: 6| Step: 13
Training loss: 1.6244280338287354
Validation loss: 1.7542094979234921

Epoch: 423| Step: 0
Training loss: 1.1692217588424683
Validation loss: 1.735811424511735

Epoch: 6| Step: 1
Training loss: 1.8746082782745361
Validation loss: 1.775830332950879

Epoch: 6| Step: 2
Training loss: 1.7559196949005127
Validation loss: 1.8282303092300252

Epoch: 6| Step: 3
Training loss: 1.272498607635498
Validation loss: 1.770952013231093

Epoch: 6| Step: 4
Training loss: 1.1683675050735474
Validation loss: 1.8137851607414983

Epoch: 6| Step: 5
Training loss: 1.2051141262054443
Validation loss: 1.7828973416359193

Epoch: 6| Step: 6
Training loss: 0.39458948373794556
Validation loss: 1.8120194570992583

Epoch: 6| Step: 7
Training loss: 0.9700314402580261
Validation loss: 1.7860903316928494

Epoch: 6| Step: 8
Training loss: 1.1718581914901733
Validation loss: 1.7662665741417998

Epoch: 6| Step: 9
Training loss: 0.43903613090515137
Validation loss: 1.7982227135730047

Epoch: 6| Step: 10
Training loss: 1.1145915985107422
Validation loss: 1.7565450565789336

Epoch: 6| Step: 11
Training loss: 1.2604401111602783
Validation loss: 1.8229202954999861

Epoch: 6| Step: 12
Training loss: 1.1110268831253052
Validation loss: 1.8223950016883113

Epoch: 6| Step: 13
Training loss: 1.8690727949142456
Validation loss: 1.7729785596170733

Epoch: 424| Step: 0
Training loss: 1.1917850971221924
Validation loss: 1.8219250043233235

Epoch: 6| Step: 1
Training loss: 1.3338483572006226
Validation loss: 1.737802860557392

Epoch: 6| Step: 2
Training loss: 1.0105923414230347
Validation loss: 1.767853621513613

Epoch: 6| Step: 3
Training loss: 1.8796076774597168
Validation loss: 1.6878784125851047

Epoch: 6| Step: 4
Training loss: 1.1237200498580933
Validation loss: 1.7390330658164075

Epoch: 6| Step: 5
Training loss: 1.3031301498413086
Validation loss: 1.7576779332212222

Epoch: 6| Step: 6
Training loss: 0.9284661412239075
Validation loss: 1.732536042890241

Epoch: 6| Step: 7
Training loss: 1.1885986328125
Validation loss: 1.7550334379237185

Epoch: 6| Step: 8
Training loss: 0.8304688334465027
Validation loss: 1.788521933299239

Epoch: 6| Step: 9
Training loss: 0.49335476756095886
Validation loss: 1.7465347910440097

Epoch: 6| Step: 10
Training loss: 1.6533806324005127
Validation loss: 1.7472507825461767

Epoch: 6| Step: 11
Training loss: 1.5417536497116089
Validation loss: 1.6946976902664348

Epoch: 6| Step: 12
Training loss: 0.8359829783439636
Validation loss: 1.7356414141193512

Epoch: 6| Step: 13
Training loss: 1.320035457611084
Validation loss: 1.7878802284117667

Epoch: 425| Step: 0
Training loss: 1.2948120832443237
Validation loss: 1.791691344271424

Epoch: 6| Step: 1
Training loss: 1.031073808670044
Validation loss: 1.7597637766151017

Epoch: 6| Step: 2
Training loss: 1.4316654205322266
Validation loss: 1.7871197295445267

Epoch: 6| Step: 3
Training loss: 1.5911425352096558
Validation loss: 1.8374427672355407

Epoch: 6| Step: 4
Training loss: 1.1247408390045166
Validation loss: 1.8117122919328752

Epoch: 6| Step: 5
Training loss: 0.7786253690719604
Validation loss: 1.8179576653306202

Epoch: 6| Step: 6
Training loss: 0.8146083354949951
Validation loss: 1.8059567200240267

Epoch: 6| Step: 7
Training loss: 1.2106226682662964
Validation loss: 1.8083873897470453

Epoch: 6| Step: 8
Training loss: 1.4173011779785156
Validation loss: 1.8258624140934279

Epoch: 6| Step: 9
Training loss: 1.4843406677246094
Validation loss: 1.6661408280813566

Epoch: 6| Step: 10
Training loss: 1.158917784690857
Validation loss: 1.7665036314277238

Epoch: 6| Step: 11
Training loss: 1.0910000801086426
Validation loss: 1.8171564199591195

Epoch: 6| Step: 12
Training loss: 1.551612377166748
Validation loss: 1.8268432514641875

Epoch: 6| Step: 13
Training loss: 0.7249740958213806
Validation loss: 1.7759287331693916

Epoch: 426| Step: 0
Training loss: 0.8936604261398315
Validation loss: 1.802372524815221

Epoch: 6| Step: 1
Training loss: 1.3751593828201294
Validation loss: 1.8137302552500079

Epoch: 6| Step: 2
Training loss: 1.3271902799606323
Validation loss: 1.7052532652372956

Epoch: 6| Step: 3
Training loss: 1.0982110500335693
Validation loss: 1.7838487548212851

Epoch: 6| Step: 4
Training loss: 1.2278574705123901
Validation loss: 1.7691293147302443

Epoch: 6| Step: 5
Training loss: 0.6570675373077393
Validation loss: 1.7506668465111845

Epoch: 6| Step: 6
Training loss: 1.3588882684707642
Validation loss: 1.7210980833217662

Epoch: 6| Step: 7
Training loss: 1.4625277519226074
Validation loss: 1.7273714145024617

Epoch: 6| Step: 8
Training loss: 0.9752267003059387
Validation loss: 1.7899823086236113

Epoch: 6| Step: 9
Training loss: 0.9735729694366455
Validation loss: 1.7360566085384739

Epoch: 6| Step: 10
Training loss: 1.4912549257278442
Validation loss: 1.7331104099109609

Epoch: 6| Step: 11
Training loss: 1.3860089778900146
Validation loss: 1.779326278676269

Epoch: 6| Step: 12
Training loss: 1.4503029584884644
Validation loss: 1.7649633384520007

Epoch: 6| Step: 13
Training loss: 0.7688816785812378
Validation loss: 1.7454980586164741

Epoch: 427| Step: 0
Training loss: 1.805033802986145
Validation loss: 1.7248674259390882

Epoch: 6| Step: 1
Training loss: 0.7721152305603027
Validation loss: 1.7995638962714904

Epoch: 6| Step: 2
Training loss: 1.4131757020950317
Validation loss: 1.7757630860933693

Epoch: 6| Step: 3
Training loss: 1.0608209371566772
Validation loss: 1.7263051335529616

Epoch: 6| Step: 4
Training loss: 1.0566719770431519
Validation loss: 1.7885721627102102

Epoch: 6| Step: 5
Training loss: 0.5959305763244629
Validation loss: 1.805400466406217

Epoch: 6| Step: 6
Training loss: 1.5308994054794312
Validation loss: 1.8141933333489202

Epoch: 6| Step: 7
Training loss: 1.2126922607421875
Validation loss: 1.8648578056725122

Epoch: 6| Step: 8
Training loss: 1.1974613666534424
Validation loss: 1.7872771293886247

Epoch: 6| Step: 9
Training loss: 1.321845531463623
Validation loss: 1.769397181849326

Epoch: 6| Step: 10
Training loss: 1.275336503982544
Validation loss: 1.8029472353637859

Epoch: 6| Step: 11
Training loss: 1.1133508682250977
Validation loss: 1.7764502930384811

Epoch: 6| Step: 12
Training loss: 1.2289485931396484
Validation loss: 1.7872574175557783

Epoch: 6| Step: 13
Training loss: 0.7971059679985046
Validation loss: 1.8084501386970602

Epoch: 428| Step: 0
Training loss: 1.7248868942260742
Validation loss: 1.683034030340051

Epoch: 6| Step: 1
Training loss: 0.9819821715354919
Validation loss: 1.7932896357710644

Epoch: 6| Step: 2
Training loss: 1.0410206317901611
Validation loss: 1.7603404829579015

Epoch: 6| Step: 3
Training loss: 1.27569580078125
Validation loss: 1.7170172519581293

Epoch: 6| Step: 4
Training loss: 1.3468737602233887
Validation loss: 1.8371974857904578

Epoch: 6| Step: 5
Training loss: 0.8049466609954834
Validation loss: 1.7299888416003155

Epoch: 6| Step: 6
Training loss: 1.2605262994766235
Validation loss: 1.8372771163140573

Epoch: 6| Step: 7
Training loss: 1.5191819667816162
Validation loss: 1.752810029573338

Epoch: 6| Step: 8
Training loss: 1.1598408222198486
Validation loss: 1.757539128744474

Epoch: 6| Step: 9
Training loss: 0.9536440372467041
Validation loss: 1.747055563875424

Epoch: 6| Step: 10
Training loss: 0.8728345036506653
Validation loss: 1.7446481720093758

Epoch: 6| Step: 11
Training loss: 1.4152458906173706
Validation loss: 1.7330139542138705

Epoch: 6| Step: 12
Training loss: 0.93932044506073
Validation loss: 1.7175092056233396

Epoch: 6| Step: 13
Training loss: 1.2947989702224731
Validation loss: 1.7752103767087382

Epoch: 429| Step: 0
Training loss: 1.3853861093521118
Validation loss: 1.7867348911941692

Epoch: 6| Step: 1
Training loss: 0.9032815098762512
Validation loss: 1.7276141399978309

Epoch: 6| Step: 2
Training loss: 1.6749132871627808
Validation loss: 1.728371895769591

Epoch: 6| Step: 3
Training loss: 1.203627586364746
Validation loss: 1.7642037586499286

Epoch: 6| Step: 4
Training loss: 1.5073943138122559
Validation loss: 1.7377728774983396

Epoch: 6| Step: 5
Training loss: 1.060103416442871
Validation loss: 1.6567096466659217

Epoch: 6| Step: 6
Training loss: 1.0955610275268555
Validation loss: 1.7429442456973496

Epoch: 6| Step: 7
Training loss: 0.8663960099220276
Validation loss: 1.791158381328788

Epoch: 6| Step: 8
Training loss: 1.3251516819000244
Validation loss: 1.7986289890863563

Epoch: 6| Step: 9
Training loss: 0.9808534383773804
Validation loss: 1.7647797202551236

Epoch: 6| Step: 10
Training loss: 0.9508808851242065
Validation loss: 1.7935044586017568

Epoch: 6| Step: 11
Training loss: 1.252150535583496
Validation loss: 1.746250424333798

Epoch: 6| Step: 12
Training loss: 1.0991768836975098
Validation loss: 1.7946394246111634

Epoch: 6| Step: 13
Training loss: 1.2395693063735962
Validation loss: 1.783678400901056

Epoch: 430| Step: 0
Training loss: 1.4071741104125977
Validation loss: 1.7742458325560375

Epoch: 6| Step: 1
Training loss: 1.2194076776504517
Validation loss: 1.7332359642110846

Epoch: 6| Step: 2
Training loss: 0.7892869114875793
Validation loss: 1.746521565221971

Epoch: 6| Step: 3
Training loss: 1.907702922821045
Validation loss: 1.7719387956844863

Epoch: 6| Step: 4
Training loss: 1.3707176446914673
Validation loss: 1.747984141431829

Epoch: 6| Step: 5
Training loss: 1.2280818223953247
Validation loss: 1.7824582322951286

Epoch: 6| Step: 6
Training loss: 1.6568657159805298
Validation loss: 1.7718159665343582

Epoch: 6| Step: 7
Training loss: 0.7778047323226929
Validation loss: 1.7406370485982587

Epoch: 6| Step: 8
Training loss: 1.0144238471984863
Validation loss: 1.7582932364556096

Epoch: 6| Step: 9
Training loss: 0.9945305585861206
Validation loss: 1.7419230912321357

Epoch: 6| Step: 10
Training loss: 0.7553327083587646
Validation loss: 1.7929753757292224

Epoch: 6| Step: 11
Training loss: 0.9509480595588684
Validation loss: 1.743320377924109

Epoch: 6| Step: 12
Training loss: 1.5139254331588745
Validation loss: 1.811634002193328

Epoch: 6| Step: 13
Training loss: 1.0602238178253174
Validation loss: 1.775862306676885

Epoch: 431| Step: 0
Training loss: 0.719732403755188
Validation loss: 1.7691461578492196

Epoch: 6| Step: 1
Training loss: 1.2885103225708008
Validation loss: 1.7253429915315361

Epoch: 6| Step: 2
Training loss: 2.0633010864257812
Validation loss: 1.675400004591993

Epoch: 6| Step: 3
Training loss: 1.306868553161621
Validation loss: 1.7633534631421488

Epoch: 6| Step: 4
Training loss: 1.0834276676177979
Validation loss: 1.8322059544183875

Epoch: 6| Step: 5
Training loss: 1.0353567600250244
Validation loss: 1.7620973099944413

Epoch: 6| Step: 6
Training loss: 1.0568268299102783
Validation loss: 1.7382632558063795

Epoch: 6| Step: 7
Training loss: 1.2941625118255615
Validation loss: 1.725770955444664

Epoch: 6| Step: 8
Training loss: 0.8394932746887207
Validation loss: 1.7974629953343382

Epoch: 6| Step: 9
Training loss: 1.2520487308502197
Validation loss: 1.8150009506492204

Epoch: 6| Step: 10
Training loss: 1.068148136138916
Validation loss: 1.7527158926892024

Epoch: 6| Step: 11
Training loss: 1.2290287017822266
Validation loss: 1.7533440384813535

Epoch: 6| Step: 12
Training loss: 1.0933853387832642
Validation loss: 1.7621684766584826

Epoch: 6| Step: 13
Training loss: 1.4945999383926392
Validation loss: 1.751089749797698

Epoch: 432| Step: 0
Training loss: 1.0979928970336914
Validation loss: 1.769085221393134

Epoch: 6| Step: 1
Training loss: 1.3209307193756104
Validation loss: 1.7767678870949695

Epoch: 6| Step: 2
Training loss: 1.4114631414413452
Validation loss: 1.775000851641419

Epoch: 6| Step: 3
Training loss: 1.0575124025344849
Validation loss: 1.7805681254274102

Epoch: 6| Step: 4
Training loss: 1.1793004274368286
Validation loss: 1.7378179770643993

Epoch: 6| Step: 5
Training loss: 0.8474006652832031
Validation loss: 1.8254360883466658

Epoch: 6| Step: 6
Training loss: 1.197479248046875
Validation loss: 1.7835525351185952

Epoch: 6| Step: 7
Training loss: 0.7467231154441833
Validation loss: 1.749902166346068

Epoch: 6| Step: 8
Training loss: 1.081898808479309
Validation loss: 1.7410391684501403

Epoch: 6| Step: 9
Training loss: 1.4719970226287842
Validation loss: 1.7104885603791924

Epoch: 6| Step: 10
Training loss: 1.2156505584716797
Validation loss: 1.7725479243904032

Epoch: 6| Step: 11
Training loss: 1.4186598062515259
Validation loss: 1.7894144147954962

Epoch: 6| Step: 12
Training loss: 1.0062587261199951
Validation loss: 1.779644545688424

Epoch: 6| Step: 13
Training loss: 0.8143090009689331
Validation loss: 1.7622830342221003

Epoch: 433| Step: 0
Training loss: 0.7543817758560181
Validation loss: 1.7620565096537273

Epoch: 6| Step: 1
Training loss: 1.0679209232330322
Validation loss: 1.8230971508128668

Epoch: 6| Step: 2
Training loss: 1.4835262298583984
Validation loss: 1.6895541798683904

Epoch: 6| Step: 3
Training loss: 0.9284090399742126
Validation loss: 1.7538115798786122

Epoch: 6| Step: 4
Training loss: 1.804276704788208
Validation loss: 1.8311572561981857

Epoch: 6| Step: 5
Training loss: 1.2768676280975342
Validation loss: 1.7749678575864403

Epoch: 6| Step: 6
Training loss: 1.1637790203094482
Validation loss: 1.763684053574839

Epoch: 6| Step: 7
Training loss: 1.0362920761108398
Validation loss: 1.780922915345879

Epoch: 6| Step: 8
Training loss: 1.0906530618667603
Validation loss: 1.7971789144700574

Epoch: 6| Step: 9
Training loss: 0.8967317342758179
Validation loss: 1.7144125712815153

Epoch: 6| Step: 10
Training loss: 1.125809669494629
Validation loss: 1.7312767108281453

Epoch: 6| Step: 11
Training loss: 0.9739751815795898
Validation loss: 1.7699193364830428

Epoch: 6| Step: 12
Training loss: 1.446526288986206
Validation loss: 1.774400572622976

Epoch: 6| Step: 13
Training loss: 1.0867276191711426
Validation loss: 1.7840178525576027

Epoch: 434| Step: 0
Training loss: 1.131026029586792
Validation loss: 1.7669537605777863

Epoch: 6| Step: 1
Training loss: 1.4501423835754395
Validation loss: 1.777650233237974

Epoch: 6| Step: 2
Training loss: 0.8310774564743042
Validation loss: 1.6476918715302662

Epoch: 6| Step: 3
Training loss: 1.2756669521331787
Validation loss: 1.7161812923287834

Epoch: 6| Step: 4
Training loss: 1.5018761157989502
Validation loss: 1.7671175913144184

Epoch: 6| Step: 5
Training loss: 0.6253851056098938
Validation loss: 1.794517501708

Epoch: 6| Step: 6
Training loss: 1.2529804706573486
Validation loss: 1.7487263038594236

Epoch: 6| Step: 7
Training loss: 1.6477842330932617
Validation loss: 1.7325509055968253

Epoch: 6| Step: 8
Training loss: 1.173642873764038
Validation loss: 1.7360278291086997

Epoch: 6| Step: 9
Training loss: 1.2870216369628906
Validation loss: 1.7419432645202966

Epoch: 6| Step: 10
Training loss: 0.9801522493362427
Validation loss: 1.7631250017432756

Epoch: 6| Step: 11
Training loss: 0.5558207631111145
Validation loss: 1.8199479938835226

Epoch: 6| Step: 12
Training loss: 1.0373129844665527
Validation loss: 1.750716709321545

Epoch: 6| Step: 13
Training loss: 1.2507833242416382
Validation loss: 1.7300637627160678

Epoch: 435| Step: 0
Training loss: 1.7160612344741821
Validation loss: 1.78158091345141

Epoch: 6| Step: 1
Training loss: 1.0113086700439453
Validation loss: 1.805778536745297

Epoch: 6| Step: 2
Training loss: 1.3823974132537842
Validation loss: 1.7451518953487437

Epoch: 6| Step: 3
Training loss: 1.1894068717956543
Validation loss: 1.7719395750312394

Epoch: 6| Step: 4
Training loss: 0.8081649541854858
Validation loss: 1.7875601681329871

Epoch: 6| Step: 5
Training loss: 0.7647360563278198
Validation loss: 1.7959923641656035

Epoch: 6| Step: 6
Training loss: 1.1871477365493774
Validation loss: 1.7599419675847536

Epoch: 6| Step: 7
Training loss: 0.9795087575912476
Validation loss: 1.8429627162154003

Epoch: 6| Step: 8
Training loss: 1.1046429872512817
Validation loss: 1.756936437340193

Epoch: 6| Step: 9
Training loss: 1.3634147644042969
Validation loss: 1.760647217432658

Epoch: 6| Step: 10
Training loss: 1.5819125175476074
Validation loss: 1.8060201368024271

Epoch: 6| Step: 11
Training loss: 0.8767908215522766
Validation loss: 1.795854542845039

Epoch: 6| Step: 12
Training loss: 1.0090456008911133
Validation loss: 1.766479217877952

Epoch: 6| Step: 13
Training loss: 1.0475746393203735
Validation loss: 1.8272736149449502

Epoch: 436| Step: 0
Training loss: 1.213218092918396
Validation loss: 1.735314594802036

Epoch: 6| Step: 1
Training loss: 1.6868271827697754
Validation loss: 1.769175135961143

Epoch: 6| Step: 2
Training loss: 1.5263392925262451
Validation loss: 1.8048540276865805

Epoch: 6| Step: 3
Training loss: 0.9319352507591248
Validation loss: 1.7396208791322605

Epoch: 6| Step: 4
Training loss: 0.7953460216522217
Validation loss: 1.7778553988343926

Epoch: 6| Step: 5
Training loss: 1.1811895370483398
Validation loss: 1.8274601941467614

Epoch: 6| Step: 6
Training loss: 1.4479763507843018
Validation loss: 1.7830143590127268

Epoch: 6| Step: 7
Training loss: 0.7356908321380615
Validation loss: 1.763760797439083

Epoch: 6| Step: 8
Training loss: 1.2105042934417725
Validation loss: 1.799880104680215

Epoch: 6| Step: 9
Training loss: 0.8018629550933838
Validation loss: 1.757075696863154

Epoch: 6| Step: 10
Training loss: 1.2517485618591309
Validation loss: 1.7802308528654036

Epoch: 6| Step: 11
Training loss: 0.779793381690979
Validation loss: 1.746659880043358

Epoch: 6| Step: 12
Training loss: 1.5078223943710327
Validation loss: 1.685306574708672

Epoch: 6| Step: 13
Training loss: 1.0498089790344238
Validation loss: 1.772136798468969

Epoch: 437| Step: 0
Training loss: 1.325484275817871
Validation loss: 1.7359473679655342

Epoch: 6| Step: 1
Training loss: 1.1786296367645264
Validation loss: 1.7654810387601134

Epoch: 6| Step: 2
Training loss: 1.1036012172698975
Validation loss: 1.7562274727770077

Epoch: 6| Step: 3
Training loss: 1.086181640625
Validation loss: 1.8467509195368776

Epoch: 6| Step: 4
Training loss: 0.9462361931800842
Validation loss: 1.8052518701040616

Epoch: 6| Step: 5
Training loss: 1.178404688835144
Validation loss: 1.8064923388983614

Epoch: 6| Step: 6
Training loss: 0.8469148874282837
Validation loss: 1.8245390743337653

Epoch: 6| Step: 7
Training loss: 1.003442645072937
Validation loss: 1.7809064285729521

Epoch: 6| Step: 8
Training loss: 1.8259155750274658
Validation loss: 1.8005403011075911

Epoch: 6| Step: 9
Training loss: 1.3883931636810303
Validation loss: 1.7867294460214593

Epoch: 6| Step: 10
Training loss: 1.0488414764404297
Validation loss: 1.7830696644321564

Epoch: 6| Step: 11
Training loss: 0.7030234336853027
Validation loss: 1.7560831257092056

Epoch: 6| Step: 12
Training loss: 1.1032053232192993
Validation loss: 1.80595830563576

Epoch: 6| Step: 13
Training loss: 0.9863409399986267
Validation loss: 1.7948774048077163

Epoch: 438| Step: 0
Training loss: 2.142049789428711
Validation loss: 1.7140304837175595

Epoch: 6| Step: 1
Training loss: 0.8522388935089111
Validation loss: 1.7735369102929228

Epoch: 6| Step: 2
Training loss: 1.01980459690094
Validation loss: 1.7179503876675841

Epoch: 6| Step: 3
Training loss: 0.953540027141571
Validation loss: 1.7938138502900318

Epoch: 6| Step: 4
Training loss: 1.013534426689148
Validation loss: 1.749610670151249

Epoch: 6| Step: 5
Training loss: 1.4556126594543457
Validation loss: 1.780645893466088

Epoch: 6| Step: 6
Training loss: 1.1538991928100586
Validation loss: 1.767511357543289

Epoch: 6| Step: 7
Training loss: 1.4302879571914673
Validation loss: 1.7956990375313708

Epoch: 6| Step: 8
Training loss: 0.6889123320579529
Validation loss: 1.7874352316702566

Epoch: 6| Step: 9
Training loss: 1.1029921770095825
Validation loss: 1.7779352203492196

Epoch: 6| Step: 10
Training loss: 0.6426646709442139
Validation loss: 1.73763015449688

Epoch: 6| Step: 11
Training loss: 1.0196499824523926
Validation loss: 1.7285053537737938

Epoch: 6| Step: 12
Training loss: 1.4269181489944458
Validation loss: 1.8160461533454157

Epoch: 6| Step: 13
Training loss: 1.09588623046875
Validation loss: 1.8192678395137991

Epoch: 439| Step: 0
Training loss: 0.953214704990387
Validation loss: 1.784587724234468

Epoch: 6| Step: 1
Training loss: 1.4786875247955322
Validation loss: 1.7570051159909976

Epoch: 6| Step: 2
Training loss: 0.5927230715751648
Validation loss: 1.7997138474577217

Epoch: 6| Step: 3
Training loss: 1.7633657455444336
Validation loss: 1.7814586559931438

Epoch: 6| Step: 4
Training loss: 0.803123950958252
Validation loss: 1.780918002128601

Epoch: 6| Step: 5
Training loss: 0.8819290399551392
Validation loss: 1.7949661388192126

Epoch: 6| Step: 6
Training loss: 1.3484468460083008
Validation loss: 1.808281410124994

Epoch: 6| Step: 7
Training loss: 0.7854628562927246
Validation loss: 1.7921788615565146

Epoch: 6| Step: 8
Training loss: 1.1235082149505615
Validation loss: 1.7723249466188493

Epoch: 6| Step: 9
Training loss: 0.9074972867965698
Validation loss: 1.7986060880845594

Epoch: 6| Step: 10
Training loss: 1.0779496431350708
Validation loss: 1.7620245167004165

Epoch: 6| Step: 11
Training loss: 1.2927439212799072
Validation loss: 1.7269017055470457

Epoch: 6| Step: 12
Training loss: 1.5518221855163574
Validation loss: 1.7292218490313458

Epoch: 6| Step: 13
Training loss: 2.070357084274292
Validation loss: 1.7722698296270063

Epoch: 440| Step: 0
Training loss: 1.7378664016723633
Validation loss: 1.7067648813288698

Epoch: 6| Step: 1
Training loss: 1.1287699937820435
Validation loss: 1.7294844478689215

Epoch: 6| Step: 2
Training loss: 1.0206074714660645
Validation loss: 1.76969245044134

Epoch: 6| Step: 3
Training loss: 1.2694991827011108
Validation loss: 1.8244793081796298

Epoch: 6| Step: 4
Training loss: 0.8095185160636902
Validation loss: 1.792375046719787

Epoch: 6| Step: 5
Training loss: 0.6576893925666809
Validation loss: 1.7165178342532086

Epoch: 6| Step: 6
Training loss: 1.0913450717926025
Validation loss: 1.7654971999506797

Epoch: 6| Step: 7
Training loss: 1.314624547958374
Validation loss: 1.7779334245189544

Epoch: 6| Step: 8
Training loss: 0.9163450598716736
Validation loss: 1.8300472280030609

Epoch: 6| Step: 9
Training loss: 0.9871230125427246
Validation loss: 1.7718859423873246

Epoch: 6| Step: 10
Training loss: 1.1330598592758179
Validation loss: 1.763097232387912

Epoch: 6| Step: 11
Training loss: 1.1526784896850586
Validation loss: 1.8082930516171198

Epoch: 6| Step: 12
Training loss: 1.3888239860534668
Validation loss: 1.7835542553214616

Epoch: 6| Step: 13
Training loss: 1.4902948141098022
Validation loss: 1.8022591298626316

Epoch: 441| Step: 0
Training loss: 0.8691584467887878
Validation loss: 1.6907280465608001

Epoch: 6| Step: 1
Training loss: 0.9799131155014038
Validation loss: 1.7512511566121092

Epoch: 6| Step: 2
Training loss: 2.1611711978912354
Validation loss: 1.6969751337523102

Epoch: 6| Step: 3
Training loss: 0.8214743733406067
Validation loss: 1.7331561811508671

Epoch: 6| Step: 4
Training loss: 1.1414133310317993
Validation loss: 1.7307936209504322

Epoch: 6| Step: 5
Training loss: 1.2544212341308594
Validation loss: 1.7561923752548874

Epoch: 6| Step: 6
Training loss: 1.6050196886062622
Validation loss: 1.7417650748324651

Epoch: 6| Step: 7
Training loss: 1.131908655166626
Validation loss: 1.7762128127518522

Epoch: 6| Step: 8
Training loss: 0.9145614504814148
Validation loss: 1.7281954019300398

Epoch: 6| Step: 9
Training loss: 0.9644709825515747
Validation loss: 1.7502746120575936

Epoch: 6| Step: 10
Training loss: 1.107550024986267
Validation loss: 1.7542851817223333

Epoch: 6| Step: 11
Training loss: 0.903119683265686
Validation loss: 1.7460266402972642

Epoch: 6| Step: 12
Training loss: 1.021053671836853
Validation loss: 1.7453306400647728

Epoch: 6| Step: 13
Training loss: 1.4095025062561035
Validation loss: 1.7404090742911063

Epoch: 442| Step: 0
Training loss: 1.3967368602752686
Validation loss: 1.754890771322353

Epoch: 6| Step: 1
Training loss: 0.6482641696929932
Validation loss: 1.7746948157587359

Epoch: 6| Step: 2
Training loss: 1.1809141635894775
Validation loss: 1.8311807429918678

Epoch: 6| Step: 3
Training loss: 0.8198037147521973
Validation loss: 1.7883445011672152

Epoch: 6| Step: 4
Training loss: 1.1302368640899658
Validation loss: 1.7950696355553084

Epoch: 6| Step: 5
Training loss: 0.9336845874786377
Validation loss: 1.7919076873410134

Epoch: 6| Step: 6
Training loss: 1.0149682760238647
Validation loss: 1.7789506758413007

Epoch: 6| Step: 7
Training loss: 1.6388071775436401
Validation loss: 1.8024004787527106

Epoch: 6| Step: 8
Training loss: 1.2115404605865479
Validation loss: 1.7088847955067952

Epoch: 6| Step: 9
Training loss: 1.1940507888793945
Validation loss: 1.8488962945117746

Epoch: 6| Step: 10
Training loss: 0.8705538511276245
Validation loss: 1.7844440360223093

Epoch: 6| Step: 11
Training loss: 1.1967788934707642
Validation loss: 1.8055007932006673

Epoch: 6| Step: 12
Training loss: 0.8080487251281738
Validation loss: 1.8272331632593626

Epoch: 6| Step: 13
Training loss: 1.624056100845337
Validation loss: 1.788969902582066

Epoch: 443| Step: 0
Training loss: 1.2663021087646484
Validation loss: 1.7489041589921521

Epoch: 6| Step: 1
Training loss: 1.183781385421753
Validation loss: 1.7865726947784424

Epoch: 6| Step: 2
Training loss: 0.7143004536628723
Validation loss: 1.7374892478348107

Epoch: 6| Step: 3
Training loss: 0.6792123317718506
Validation loss: 1.7654629330481253

Epoch: 6| Step: 4
Training loss: 1.513716220855713
Validation loss: 1.7574689593366397

Epoch: 6| Step: 5
Training loss: 0.8533957004547119
Validation loss: 1.8087388853872977

Epoch: 6| Step: 6
Training loss: 1.163968801498413
Validation loss: 1.7467893438954507

Epoch: 6| Step: 7
Training loss: 1.342327356338501
Validation loss: 1.7707262590367308

Epoch: 6| Step: 8
Training loss: 0.7274848818778992
Validation loss: 1.674102142292966

Epoch: 6| Step: 9
Training loss: 1.2290353775024414
Validation loss: 1.6813975944313952

Epoch: 6| Step: 10
Training loss: 1.5802695751190186
Validation loss: 1.7482563564854283

Epoch: 6| Step: 11
Training loss: 0.8773095011711121
Validation loss: 1.7486672619337678

Epoch: 6| Step: 12
Training loss: 1.189863681793213
Validation loss: 1.7236948333760744

Epoch: 6| Step: 13
Training loss: 1.507336139678955
Validation loss: 1.7690994995896534

Epoch: 444| Step: 0
Training loss: 1.7515296936035156
Validation loss: 1.7708243746911325

Epoch: 6| Step: 1
Training loss: 0.9491815567016602
Validation loss: 1.7265000343322754

Epoch: 6| Step: 2
Training loss: 1.3230342864990234
Validation loss: 1.740746090489049

Epoch: 6| Step: 3
Training loss: 1.2392139434814453
Validation loss: 1.737926306263093

Epoch: 6| Step: 4
Training loss: 0.7826437950134277
Validation loss: 1.7558745491889216

Epoch: 6| Step: 5
Training loss: 1.1407389640808105
Validation loss: 1.7386226782234766

Epoch: 6| Step: 6
Training loss: 0.8880278468132019
Validation loss: 1.827758683953234

Epoch: 6| Step: 7
Training loss: 1.6985023021697998
Validation loss: 1.7914644274660336

Epoch: 6| Step: 8
Training loss: 0.9662570357322693
Validation loss: 1.80933928233321

Epoch: 6| Step: 9
Training loss: 1.2043267488479614
Validation loss: 1.8469589218016593

Epoch: 6| Step: 10
Training loss: 1.232088327407837
Validation loss: 1.8202592198566725

Epoch: 6| Step: 11
Training loss: 0.8678194284439087
Validation loss: 1.7731691739892448

Epoch: 6| Step: 12
Training loss: 1.4192168712615967
Validation loss: 1.7683447932684293

Epoch: 6| Step: 13
Training loss: 0.5018892884254456
Validation loss: 1.7856077148068337

Epoch: 445| Step: 0
Training loss: 1.168999433517456
Validation loss: 1.7821947079832836

Epoch: 6| Step: 1
Training loss: 0.7578185796737671
Validation loss: 1.7509111332637008

Epoch: 6| Step: 2
Training loss: 0.7650814056396484
Validation loss: 1.709186210427233

Epoch: 6| Step: 3
Training loss: 1.5254719257354736
Validation loss: 1.7960701437406643

Epoch: 6| Step: 4
Training loss: 0.7681483030319214
Validation loss: 1.8015745262945853

Epoch: 6| Step: 5
Training loss: 1.4027341604232788
Validation loss: 1.7837904281513666

Epoch: 6| Step: 6
Training loss: 1.1061193943023682
Validation loss: 1.7538474964839157

Epoch: 6| Step: 7
Training loss: 0.9763944149017334
Validation loss: 1.694735700084317

Epoch: 6| Step: 8
Training loss: 1.1722602844238281
Validation loss: 1.7507347329970329

Epoch: 6| Step: 9
Training loss: 1.493730068206787
Validation loss: 1.79176753182565

Epoch: 6| Step: 10
Training loss: 0.8173137307167053
Validation loss: 1.7458789617784563

Epoch: 6| Step: 11
Training loss: 0.7096174955368042
Validation loss: 1.7425985003030429

Epoch: 6| Step: 12
Training loss: 1.8241311311721802
Validation loss: 1.7153995037078857

Epoch: 6| Step: 13
Training loss: 1.3987513780593872
Validation loss: 1.8195176419391428

Epoch: 446| Step: 0
Training loss: 1.214735507965088
Validation loss: 1.8503239770089426

Epoch: 6| Step: 1
Training loss: 1.28352952003479
Validation loss: 1.820681369432839

Epoch: 6| Step: 2
Training loss: 0.9389065504074097
Validation loss: 1.8369401936889977

Epoch: 6| Step: 3
Training loss: 1.3145992755889893
Validation loss: 1.7312604099191644

Epoch: 6| Step: 4
Training loss: 0.8169424533843994
Validation loss: 1.7511171756252166

Epoch: 6| Step: 5
Training loss: 0.9073165059089661
Validation loss: 1.742794277847454

Epoch: 6| Step: 6
Training loss: 1.3656787872314453
Validation loss: 1.7845104240602063

Epoch: 6| Step: 7
Training loss: 1.740095853805542
Validation loss: 1.7980110171020671

Epoch: 6| Step: 8
Training loss: 1.1808825731277466
Validation loss: 1.7902371806483115

Epoch: 6| Step: 9
Training loss: 0.7842545509338379
Validation loss: 1.7526528117477254

Epoch: 6| Step: 10
Training loss: 0.8332650661468506
Validation loss: 1.741162088609511

Epoch: 6| Step: 11
Training loss: 1.1086206436157227
Validation loss: 1.731057983572765

Epoch: 6| Step: 12
Training loss: 1.0201997756958008
Validation loss: 1.7652753476173646

Epoch: 6| Step: 13
Training loss: 1.1580443382263184
Validation loss: 1.7644367294926797

Epoch: 447| Step: 0
Training loss: 1.1564993858337402
Validation loss: 1.7358082545700895

Epoch: 6| Step: 1
Training loss: 0.8154615163803101
Validation loss: 1.782287492546984

Epoch: 6| Step: 2
Training loss: 1.4341204166412354
Validation loss: 1.7262209410308509

Epoch: 6| Step: 3
Training loss: 1.4324665069580078
Validation loss: 1.755636720247166

Epoch: 6| Step: 4
Training loss: 0.9095830321311951
Validation loss: 1.7390415181395829

Epoch: 6| Step: 5
Training loss: 1.1926618814468384
Validation loss: 1.6891203580364105

Epoch: 6| Step: 6
Training loss: 0.8829158544540405
Validation loss: 1.7804241744420861

Epoch: 6| Step: 7
Training loss: 0.9677451252937317
Validation loss: 1.765336098209504

Epoch: 6| Step: 8
Training loss: 1.108407974243164
Validation loss: 1.764903531279615

Epoch: 6| Step: 9
Training loss: 1.1223409175872803
Validation loss: 1.7754916760229296

Epoch: 6| Step: 10
Training loss: 1.2734304666519165
Validation loss: 1.6749001344045003

Epoch: 6| Step: 11
Training loss: 1.0010011196136475
Validation loss: 1.7849789845046176

Epoch: 6| Step: 12
Training loss: 1.1960266828536987
Validation loss: 1.7881233269168484

Epoch: 6| Step: 13
Training loss: 1.4194895029067993
Validation loss: 1.7688535080161145

Epoch: 448| Step: 0
Training loss: 1.029067873954773
Validation loss: 1.81155554838078

Epoch: 6| Step: 1
Training loss: 1.2770947217941284
Validation loss: 1.749739464893136

Epoch: 6| Step: 2
Training loss: 1.4582746028900146
Validation loss: 1.8199861357288976

Epoch: 6| Step: 3
Training loss: 1.6192245483398438
Validation loss: 1.7757202784220378

Epoch: 6| Step: 4
Training loss: 1.0385236740112305
Validation loss: 1.7265262475577734

Epoch: 6| Step: 5
Training loss: 0.9829652309417725
Validation loss: 1.7698062927492204

Epoch: 6| Step: 6
Training loss: 1.3576585054397583
Validation loss: 1.785997006200975

Epoch: 6| Step: 7
Training loss: 0.8271242380142212
Validation loss: 1.7320247568109983

Epoch: 6| Step: 8
Training loss: 1.0270336866378784
Validation loss: 1.7990753419937626

Epoch: 6| Step: 9
Training loss: 0.9210912585258484
Validation loss: 1.7674992661322317

Epoch: 6| Step: 10
Training loss: 0.6890890598297119
Validation loss: 1.7784851199837142

Epoch: 6| Step: 11
Training loss: 1.4446628093719482
Validation loss: 1.7865881996770059

Epoch: 6| Step: 12
Training loss: 1.0757182836532593
Validation loss: 1.7795557078494821

Epoch: 6| Step: 13
Training loss: 1.0634909868240356
Validation loss: 1.7254930965362056

Epoch: 449| Step: 0
Training loss: 0.8200784921646118
Validation loss: 1.750531760595178

Epoch: 6| Step: 1
Training loss: 1.3102531433105469
Validation loss: 1.7248024479035409

Epoch: 6| Step: 2
Training loss: 1.2551603317260742
Validation loss: 1.7412762385542675

Epoch: 6| Step: 3
Training loss: 1.0025907754898071
Validation loss: 1.7709995162102483

Epoch: 6| Step: 4
Training loss: 0.9903327226638794
Validation loss: 1.7067528796452347

Epoch: 6| Step: 5
Training loss: 1.184563159942627
Validation loss: 1.7307958372177616

Epoch: 6| Step: 6
Training loss: 1.1519114971160889
Validation loss: 1.7070277826760405

Epoch: 6| Step: 7
Training loss: 1.383670449256897
Validation loss: 1.7612410796585904

Epoch: 6| Step: 8
Training loss: 1.4083154201507568
Validation loss: 1.7250265652133572

Epoch: 6| Step: 9
Training loss: 0.8004082441329956
Validation loss: 1.7950201496001212

Epoch: 6| Step: 10
Training loss: 0.8422760963439941
Validation loss: 1.7912189793843094

Epoch: 6| Step: 11
Training loss: 1.1712230443954468
Validation loss: 1.6717628843040877

Epoch: 6| Step: 12
Training loss: 1.0208473205566406
Validation loss: 1.7499042249494983

Epoch: 6| Step: 13
Training loss: 1.0971386432647705
Validation loss: 1.6945738356600526

Epoch: 450| Step: 0
Training loss: 0.6176179647445679
Validation loss: 1.8025952282772268

Epoch: 6| Step: 1
Training loss: 1.6979777812957764
Validation loss: 1.836743922643764

Epoch: 6| Step: 2
Training loss: 1.3102740049362183
Validation loss: 1.7078619028932305

Epoch: 6| Step: 3
Training loss: 0.8411657810211182
Validation loss: 1.6876240520067112

Epoch: 6| Step: 4
Training loss: 2.0819661617279053
Validation loss: 1.7201296264125454

Epoch: 6| Step: 5
Training loss: 1.628847360610962
Validation loss: 1.72503710562183

Epoch: 6| Step: 6
Training loss: 1.292616367340088
Validation loss: 1.7917171370598577

Epoch: 6| Step: 7
Training loss: 1.04032301902771
Validation loss: 1.7839866838147562

Epoch: 6| Step: 8
Training loss: 0.8020975589752197
Validation loss: 1.7731700956180532

Epoch: 6| Step: 9
Training loss: 0.9136849641799927
Validation loss: 1.7537408080152286

Epoch: 6| Step: 10
Training loss: 1.004547119140625
Validation loss: 1.781863615077029

Epoch: 6| Step: 11
Training loss: 1.0471200942993164
Validation loss: 1.8240347395661056

Epoch: 6| Step: 12
Training loss: 0.8708627223968506
Validation loss: 1.6784733354404409

Epoch: 6| Step: 13
Training loss: 0.34898287057876587
Validation loss: 1.758769586522092

Epoch: 451| Step: 0
Training loss: 0.872306764125824
Validation loss: 1.7080336475885043

Epoch: 6| Step: 1
Training loss: 0.9489396810531616
Validation loss: 1.7759535774107902

Epoch: 6| Step: 2
Training loss: 1.0059369802474976
Validation loss: 1.7439022038572578

Epoch: 6| Step: 3
Training loss: 0.8251380920410156
Validation loss: 1.730924730659813

Epoch: 6| Step: 4
Training loss: 1.204016923904419
Validation loss: 1.7395295532800819

Epoch: 6| Step: 5
Training loss: 1.1700408458709717
Validation loss: 1.734739714412279

Epoch: 6| Step: 6
Training loss: 1.2257497310638428
Validation loss: 1.7295517408719627

Epoch: 6| Step: 7
Training loss: 1.0206694602966309
Validation loss: 1.7204155409207909

Epoch: 6| Step: 8
Training loss: 1.484933614730835
Validation loss: 1.7421247164408367

Epoch: 6| Step: 9
Training loss: 1.080082654953003
Validation loss: 1.7601354865617649

Epoch: 6| Step: 10
Training loss: 0.8955355286598206
Validation loss: 1.7431304352257841

Epoch: 6| Step: 11
Training loss: 1.1830804347991943
Validation loss: 1.7621329189628683

Epoch: 6| Step: 12
Training loss: 1.1844767332077026
Validation loss: 1.7350373498855098

Epoch: 6| Step: 13
Training loss: 1.0464764833450317
Validation loss: 1.699790439298076

Epoch: 452| Step: 0
Training loss: 1.3805835247039795
Validation loss: 1.7409786434583767

Epoch: 6| Step: 1
Training loss: 1.2341804504394531
Validation loss: 1.7355215703287432

Epoch: 6| Step: 2
Training loss: 1.0878299474716187
Validation loss: 1.789658461847613

Epoch: 6| Step: 3
Training loss: 1.0479650497436523
Validation loss: 1.780011958973382

Epoch: 6| Step: 4
Training loss: 1.0133678913116455
Validation loss: 1.7736932936535086

Epoch: 6| Step: 5
Training loss: 1.0696676969528198
Validation loss: 1.8063078900819183

Epoch: 6| Step: 6
Training loss: 0.7509756088256836
Validation loss: 1.7717636246835031

Epoch: 6| Step: 7
Training loss: 1.1829861402511597
Validation loss: 1.721953498419895

Epoch: 6| Step: 8
Training loss: 1.4319475889205933
Validation loss: 1.7190993550003215

Epoch: 6| Step: 9
Training loss: 1.1253879070281982
Validation loss: 1.7154308237055296

Epoch: 6| Step: 10
Training loss: 1.3719511032104492
Validation loss: 1.656160682760259

Epoch: 6| Step: 11
Training loss: 1.119086742401123
Validation loss: 1.7476121200028287

Epoch: 6| Step: 12
Training loss: 0.8465412855148315
Validation loss: 1.79053863915064

Epoch: 6| Step: 13
Training loss: 1.041734218597412
Validation loss: 1.7476665127661921

Epoch: 453| Step: 0
Training loss: 1.0787699222564697
Validation loss: 1.8062886166316208

Epoch: 6| Step: 1
Training loss: 1.177894115447998
Validation loss: 1.7783894051787674

Epoch: 6| Step: 2
Training loss: 1.706769585609436
Validation loss: 1.7314692812581216

Epoch: 6| Step: 3
Training loss: 0.9873700141906738
Validation loss: 1.7726144752194803

Epoch: 6| Step: 4
Training loss: 1.2456350326538086
Validation loss: 1.723011753892386

Epoch: 6| Step: 5
Training loss: 0.8950774669647217
Validation loss: 1.745018523226502

Epoch: 6| Step: 6
Training loss: 0.7369582653045654
Validation loss: 1.7992784246321647

Epoch: 6| Step: 7
Training loss: 0.5358253717422485
Validation loss: 1.7693419635936778

Epoch: 6| Step: 8
Training loss: 1.4758362770080566
Validation loss: 1.8694057861963909

Epoch: 6| Step: 9
Training loss: 0.7643451690673828
Validation loss: 1.804762771052699

Epoch: 6| Step: 10
Training loss: 1.5751492977142334
Validation loss: 1.7400134442954935

Epoch: 6| Step: 11
Training loss: 0.7561225891113281
Validation loss: 1.7527239886663293

Epoch: 6| Step: 12
Training loss: 1.6006379127502441
Validation loss: 1.7291318165358676

Epoch: 6| Step: 13
Training loss: 1.269128441810608
Validation loss: 1.7453604821235902

Epoch: 454| Step: 0
Training loss: 0.9762169718742371
Validation loss: 1.7275590204423474

Epoch: 6| Step: 1
Training loss: 1.3954840898513794
Validation loss: 1.731144053961641

Epoch: 6| Step: 2
Training loss: 1.036527395248413
Validation loss: 1.748518745104472

Epoch: 6| Step: 3
Training loss: 0.6229364275932312
Validation loss: 1.7986052651559152

Epoch: 6| Step: 4
Training loss: 1.4139682054519653
Validation loss: 1.7317760388056438

Epoch: 6| Step: 5
Training loss: 1.4029297828674316
Validation loss: 1.801455327259597

Epoch: 6| Step: 6
Training loss: 0.5558620095252991
Validation loss: 1.7220910005672003

Epoch: 6| Step: 7
Training loss: 0.8419268131256104
Validation loss: 1.7675487277328328

Epoch: 6| Step: 8
Training loss: 1.1911516189575195
Validation loss: 1.7640655002286356

Epoch: 6| Step: 9
Training loss: 0.8728557825088501
Validation loss: 1.8302882743138138

Epoch: 6| Step: 10
Training loss: 1.449528455734253
Validation loss: 1.731569766998291

Epoch: 6| Step: 11
Training loss: 1.3677005767822266
Validation loss: 1.7817403693352976

Epoch: 6| Step: 12
Training loss: 1.438443660736084
Validation loss: 1.7758781128032233

Epoch: 6| Step: 13
Training loss: 1.0009902715682983
Validation loss: 1.7732189573267454

Epoch: 455| Step: 0
Training loss: 0.9178943634033203
Validation loss: 1.7573776142571562

Epoch: 6| Step: 1
Training loss: 1.1130832433700562
Validation loss: 1.7527681114853069

Epoch: 6| Step: 2
Training loss: 0.9243105053901672
Validation loss: 1.6650778888374247

Epoch: 6| Step: 3
Training loss: 0.9537241458892822
Validation loss: 1.7854898104103663

Epoch: 6| Step: 4
Training loss: 1.5803476572036743
Validation loss: 1.7321227686379546

Epoch: 6| Step: 5
Training loss: 0.8677873611450195
Validation loss: 1.7167641962728193

Epoch: 6| Step: 6
Training loss: 1.1064956188201904
Validation loss: 1.7253746127569547

Epoch: 6| Step: 7
Training loss: 1.3313987255096436
Validation loss: 1.7229242940102854

Epoch: 6| Step: 8
Training loss: 1.0852136611938477
Validation loss: 1.7670098863622195

Epoch: 6| Step: 9
Training loss: 0.7967116236686707
Validation loss: 1.719735473714849

Epoch: 6| Step: 10
Training loss: 1.394295334815979
Validation loss: 1.725379701583616

Epoch: 6| Step: 11
Training loss: 1.0274443626403809
Validation loss: 1.716907629402735

Epoch: 6| Step: 12
Training loss: 0.8567965030670166
Validation loss: 1.7992233012312202

Epoch: 6| Step: 13
Training loss: 1.6266248226165771
Validation loss: 1.7496378857602355

Epoch: 456| Step: 0
Training loss: 1.0240764617919922
Validation loss: 1.7710295672057776

Epoch: 6| Step: 1
Training loss: 1.3870997428894043
Validation loss: 1.823525103189612

Epoch: 6| Step: 2
Training loss: 1.7628480195999146
Validation loss: 1.7141911522034676

Epoch: 6| Step: 3
Training loss: 1.3879112005233765
Validation loss: 1.8212476174036663

Epoch: 6| Step: 4
Training loss: 1.125131368637085
Validation loss: 1.7990146439562562

Epoch: 6| Step: 5
Training loss: 1.3592772483825684
Validation loss: 1.7529907034289451

Epoch: 6| Step: 6
Training loss: 0.840440034866333
Validation loss: 1.7469198729402275

Epoch: 6| Step: 7
Training loss: 0.5962793827056885
Validation loss: 1.7600369530339395

Epoch: 6| Step: 8
Training loss: 1.497182846069336
Validation loss: 1.722410435317665

Epoch: 6| Step: 9
Training loss: 0.7731184959411621
Validation loss: 1.7314832825814523

Epoch: 6| Step: 10
Training loss: 0.9020562171936035
Validation loss: 1.7925508394036243

Epoch: 6| Step: 11
Training loss: 0.7320898771286011
Validation loss: 1.730638962919994

Epoch: 6| Step: 12
Training loss: 0.9356849193572998
Validation loss: 1.7540257233445362

Epoch: 6| Step: 13
Training loss: 1.230278491973877
Validation loss: 1.7094275207929714

Epoch: 457| Step: 0
Training loss: 1.8860678672790527
Validation loss: 1.7710837843597576

Epoch: 6| Step: 1
Training loss: 1.0743266344070435
Validation loss: 1.734675997047014

Epoch: 6| Step: 2
Training loss: 0.9758472442626953
Validation loss: 1.723994662684779

Epoch: 6| Step: 3
Training loss: 0.9452151656150818
Validation loss: 1.7636020363018077

Epoch: 6| Step: 4
Training loss: 1.1839736700057983
Validation loss: 1.7428193041073379

Epoch: 6| Step: 5
Training loss: 1.5315032005310059
Validation loss: 1.6905615355378838

Epoch: 6| Step: 6
Training loss: 0.7522962093353271
Validation loss: 1.7286227646694388

Epoch: 6| Step: 7
Training loss: 0.8880090713500977
Validation loss: 1.7289550612049718

Epoch: 6| Step: 8
Training loss: 1.1337308883666992
Validation loss: 1.733002366558198

Epoch: 6| Step: 9
Training loss: 1.411698818206787
Validation loss: 1.7016148477472284

Epoch: 6| Step: 10
Training loss: 0.8085919618606567
Validation loss: 1.761248080961166

Epoch: 6| Step: 11
Training loss: 1.0493519306182861
Validation loss: 1.710924111386781

Epoch: 6| Step: 12
Training loss: 0.46617087721824646
Validation loss: 1.789319743392288

Epoch: 6| Step: 13
Training loss: 1.1144628524780273
Validation loss: 1.7953008861951931

Epoch: 458| Step: 0
Training loss: 0.443372905254364
Validation loss: 1.7803064187367756

Epoch: 6| Step: 1
Training loss: 0.9604608416557312
Validation loss: 1.7545695663780294

Epoch: 6| Step: 2
Training loss: 1.0961295366287231
Validation loss: 1.7729744808648222

Epoch: 6| Step: 3
Training loss: 1.5995805263519287
Validation loss: 1.749535608035262

Epoch: 6| Step: 4
Training loss: 0.748058557510376
Validation loss: 1.7596692218575427

Epoch: 6| Step: 5
Training loss: 1.242122769355774
Validation loss: 1.7045429547627766

Epoch: 6| Step: 6
Training loss: 1.7199015617370605
Validation loss: 1.7918799243947512

Epoch: 6| Step: 7
Training loss: 0.9887535572052002
Validation loss: 1.7862826803679108

Epoch: 6| Step: 8
Training loss: 0.5161867737770081
Validation loss: 1.7573873125096804

Epoch: 6| Step: 9
Training loss: 1.267521619796753
Validation loss: 1.7437241564514816

Epoch: 6| Step: 10
Training loss: 1.322199821472168
Validation loss: 1.8076182065471527

Epoch: 6| Step: 11
Training loss: 1.0543839931488037
Validation loss: 1.7562059753684587

Epoch: 6| Step: 12
Training loss: 1.036304235458374
Validation loss: 1.7646166945016513

Epoch: 6| Step: 13
Training loss: 1.0950889587402344
Validation loss: 1.6648947051776353

Epoch: 459| Step: 0
Training loss: 1.0589176416397095
Validation loss: 1.7315559412843438

Epoch: 6| Step: 1
Training loss: 1.1605050563812256
Validation loss: 1.7191832584719504

Epoch: 6| Step: 2
Training loss: 0.7964495420455933
Validation loss: 1.6984228511010446

Epoch: 6| Step: 3
Training loss: 1.1318700313568115
Validation loss: 1.7238418030482467

Epoch: 6| Step: 4
Training loss: 1.0477197170257568
Validation loss: 1.7471778174882293

Epoch: 6| Step: 5
Training loss: 0.9148249626159668
Validation loss: 1.77521611157284

Epoch: 6| Step: 6
Training loss: 1.0947239398956299
Validation loss: 1.73715381468496

Epoch: 6| Step: 7
Training loss: 1.0777260065078735
Validation loss: 1.7678841493463004

Epoch: 6| Step: 8
Training loss: 1.3059405088424683
Validation loss: 1.7285910447438557

Epoch: 6| Step: 9
Training loss: 1.0836645364761353
Validation loss: 1.7823382885225358

Epoch: 6| Step: 10
Training loss: 1.1837588548660278
Validation loss: 1.7023316685871412

Epoch: 6| Step: 11
Training loss: 0.7360588312149048
Validation loss: 1.7187051260343162

Epoch: 6| Step: 12
Training loss: 1.0049163103103638
Validation loss: 1.8231414236048216

Epoch: 6| Step: 13
Training loss: 1.4935535192489624
Validation loss: 1.785565448063676

Epoch: 460| Step: 0
Training loss: 1.048432469367981
Validation loss: 1.7609477299515919

Epoch: 6| Step: 1
Training loss: 1.1781576871871948
Validation loss: 1.7879403150209816

Epoch: 6| Step: 2
Training loss: 0.6149274110794067
Validation loss: 1.7913981926056646

Epoch: 6| Step: 3
Training loss: 1.0725523233413696
Validation loss: 1.7591867946809339

Epoch: 6| Step: 4
Training loss: 0.6718019247055054
Validation loss: 1.7506881183193577

Epoch: 6| Step: 5
Training loss: 0.9632790088653564
Validation loss: 1.8183354267510035

Epoch: 6| Step: 6
Training loss: 1.4846152067184448
Validation loss: 1.7867172123283468

Epoch: 6| Step: 7
Training loss: 1.3240689039230347
Validation loss: 1.7518889173384635

Epoch: 6| Step: 8
Training loss: 1.3048193454742432
Validation loss: 1.6872258160703926

Epoch: 6| Step: 9
Training loss: 1.1139616966247559
Validation loss: 1.718187165516679

Epoch: 6| Step: 10
Training loss: 0.9077203273773193
Validation loss: 1.7675461948558848

Epoch: 6| Step: 11
Training loss: 1.206445574760437
Validation loss: 1.7588967700158396

Epoch: 6| Step: 12
Training loss: 1.0636801719665527
Validation loss: 1.768387471475909

Epoch: 6| Step: 13
Training loss: 0.908263087272644
Validation loss: 1.7341261217671056

Epoch: 461| Step: 0
Training loss: 1.0351651906967163
Validation loss: 1.7439856580508653

Epoch: 6| Step: 1
Training loss: 0.8425658941268921
Validation loss: 1.7266308505048034

Epoch: 6| Step: 2
Training loss: 0.9816218614578247
Validation loss: 1.7999665506424443

Epoch: 6| Step: 3
Training loss: 1.1790621280670166
Validation loss: 1.739959382241772

Epoch: 6| Step: 4
Training loss: 1.4251184463500977
Validation loss: 1.732260993731919

Epoch: 6| Step: 5
Training loss: 1.524895191192627
Validation loss: 1.7779485922987743

Epoch: 6| Step: 6
Training loss: 0.611286997795105
Validation loss: 1.7230842395495343

Epoch: 6| Step: 7
Training loss: 0.9344402551651001
Validation loss: 1.7854009648805023

Epoch: 6| Step: 8
Training loss: 0.92198646068573
Validation loss: 1.7180610651611

Epoch: 6| Step: 9
Training loss: 0.7274051904678345
Validation loss: 1.712663367230405

Epoch: 6| Step: 10
Training loss: 0.8642916083335876
Validation loss: 1.7282395657672678

Epoch: 6| Step: 11
Training loss: 1.3888473510742188
Validation loss: 1.7155745144813292

Epoch: 6| Step: 12
Training loss: 1.7889937162399292
Validation loss: 1.689199725786845

Epoch: 6| Step: 13
Training loss: 0.8644108772277832
Validation loss: 1.7920534303111415

Epoch: 462| Step: 0
Training loss: 0.9779764413833618
Validation loss: 1.7708224711879608

Epoch: 6| Step: 1
Training loss: 0.865418553352356
Validation loss: 1.7649955666193398

Epoch: 6| Step: 2
Training loss: 1.3507550954818726
Validation loss: 1.743811659915473

Epoch: 6| Step: 3
Training loss: 1.006087303161621
Validation loss: 1.7275718540273688

Epoch: 6| Step: 4
Training loss: 1.1218397617340088
Validation loss: 1.725819489007355

Epoch: 6| Step: 5
Training loss: 0.8302063345909119
Validation loss: 1.6918775291853054

Epoch: 6| Step: 6
Training loss: 1.3749980926513672
Validation loss: 1.7317579882119292

Epoch: 6| Step: 7
Training loss: 1.2193331718444824
Validation loss: 1.7417766676154187

Epoch: 6| Step: 8
Training loss: 1.506087064743042
Validation loss: 1.7828099932721866

Epoch: 6| Step: 9
Training loss: 0.9137957096099854
Validation loss: 1.7037733998349918

Epoch: 6| Step: 10
Training loss: 0.7272815108299255
Validation loss: 1.7703704064892185

Epoch: 6| Step: 11
Training loss: 0.745002031326294
Validation loss: 1.7606850106229064

Epoch: 6| Step: 12
Training loss: 1.469464659690857
Validation loss: 1.7597495381550123

Epoch: 6| Step: 13
Training loss: 0.8068904280662537
Validation loss: 1.7162808910492928

Epoch: 463| Step: 0
Training loss: 1.6086573600769043
Validation loss: 1.7048745770608225

Epoch: 6| Step: 1
Training loss: 1.0451481342315674
Validation loss: 1.7880305141531012

Epoch: 6| Step: 2
Training loss: 0.9537233114242554
Validation loss: 1.666067450277267

Epoch: 6| Step: 3
Training loss: 1.0636968612670898
Validation loss: 1.763375364324098

Epoch: 6| Step: 4
Training loss: 1.2142603397369385
Validation loss: 1.6972466271410707

Epoch: 6| Step: 5
Training loss: 1.4428248405456543
Validation loss: 1.7094543262194561

Epoch: 6| Step: 6
Training loss: 0.9379395246505737
Validation loss: 1.7013333587236301

Epoch: 6| Step: 7
Training loss: 1.244086742401123
Validation loss: 1.7164388459215882

Epoch: 6| Step: 8
Training loss: 1.0181087255477905
Validation loss: 1.744304455736632

Epoch: 6| Step: 9
Training loss: 0.691071629524231
Validation loss: 1.7303985306011733

Epoch: 6| Step: 10
Training loss: 0.9234858751296997
Validation loss: 1.689035689958962

Epoch: 6| Step: 11
Training loss: 0.8070734739303589
Validation loss: 1.738403222894156

Epoch: 6| Step: 12
Training loss: 0.7685340642929077
Validation loss: 1.690780089106611

Epoch: 6| Step: 13
Training loss: 1.2800133228302002
Validation loss: 1.702721062526908

Epoch: 464| Step: 0
Training loss: 1.0432932376861572
Validation loss: 1.725108451740716

Epoch: 6| Step: 1
Training loss: 1.2852486371994019
Validation loss: 1.7189506753798454

Epoch: 6| Step: 2
Training loss: 0.8889398574829102
Validation loss: 1.8073075266294583

Epoch: 6| Step: 3
Training loss: 1.2784934043884277
Validation loss: 1.7441123864984

Epoch: 6| Step: 4
Training loss: 1.252760410308838
Validation loss: 1.7893250219283565

Epoch: 6| Step: 5
Training loss: 1.0304237604141235
Validation loss: 1.8202935290592972

Epoch: 6| Step: 6
Training loss: 1.5463321208953857
Validation loss: 1.811115905802737

Epoch: 6| Step: 7
Training loss: 0.9015095233917236
Validation loss: 1.8370830358997468

Epoch: 6| Step: 8
Training loss: 0.7468463778495789
Validation loss: 1.8393409226530342

Epoch: 6| Step: 9
Training loss: 1.2801032066345215
Validation loss: 1.8131950773218626

Epoch: 6| Step: 10
Training loss: 1.1492708921432495
Validation loss: 1.7942985847432127

Epoch: 6| Step: 11
Training loss: 0.7288624048233032
Validation loss: 1.8636983953496462

Epoch: 6| Step: 12
Training loss: 1.1201226711273193
Validation loss: 1.6919266357216785

Epoch: 6| Step: 13
Training loss: 0.9597552418708801
Validation loss: 1.7728259358354794

Epoch: 465| Step: 0
Training loss: 1.0816850662231445
Validation loss: 1.693327292319267

Epoch: 6| Step: 1
Training loss: 0.8028842806816101
Validation loss: 1.8102607765505392

Epoch: 6| Step: 2
Training loss: 1.3793894052505493
Validation loss: 1.7702979874867264

Epoch: 6| Step: 3
Training loss: 1.9289008378982544
Validation loss: 1.7631442393026044

Epoch: 6| Step: 4
Training loss: 0.9440553784370422
Validation loss: 1.7373476553988714

Epoch: 6| Step: 5
Training loss: 0.8529515266418457
Validation loss: 1.763655065208353

Epoch: 6| Step: 6
Training loss: 0.8382929563522339
Validation loss: 1.7063993587288806

Epoch: 6| Step: 7
Training loss: 1.2287702560424805
Validation loss: 1.6922937157333537

Epoch: 6| Step: 8
Training loss: 0.8828331232070923
Validation loss: 1.7898998670680548

Epoch: 6| Step: 9
Training loss: 1.1690653562545776
Validation loss: 1.7293402418013541

Epoch: 6| Step: 10
Training loss: 0.8582831025123596
Validation loss: 1.680473098190882

Epoch: 6| Step: 11
Training loss: 1.219461441040039
Validation loss: 1.7292986646775277

Epoch: 6| Step: 12
Training loss: 0.8373217582702637
Validation loss: 1.6540125095716087

Epoch: 6| Step: 13
Training loss: 0.5828464031219482
Validation loss: 1.7037721474965413

Epoch: 466| Step: 0
Training loss: 0.9739901423454285
Validation loss: 1.666532128087936

Epoch: 6| Step: 1
Training loss: 1.600317120552063
Validation loss: 1.6776872232396116

Epoch: 6| Step: 2
Training loss: 0.6392748355865479
Validation loss: 1.7286589120023994

Epoch: 6| Step: 3
Training loss: 1.0707430839538574
Validation loss: 1.7515770850643035

Epoch: 6| Step: 4
Training loss: 0.5799267292022705
Validation loss: 1.6919363044923352

Epoch: 6| Step: 5
Training loss: 0.7444618940353394
Validation loss: 1.8142913720941032

Epoch: 6| Step: 6
Training loss: 1.3653255701065063
Validation loss: 1.8163869457860147

Epoch: 6| Step: 7
Training loss: 0.7966190576553345
Validation loss: 1.735010277840399

Epoch: 6| Step: 8
Training loss: 1.424424648284912
Validation loss: 1.8147456184510262

Epoch: 6| Step: 9
Training loss: 0.9632465839385986
Validation loss: 1.7662086563725625

Epoch: 6| Step: 10
Training loss: 0.9884418249130249
Validation loss: 1.875422962250248

Epoch: 6| Step: 11
Training loss: 1.6715211868286133
Validation loss: 1.7676877796009023

Epoch: 6| Step: 12
Training loss: 1.1379752159118652
Validation loss: 1.7869428626952633

Epoch: 6| Step: 13
Training loss: 0.7521744966506958
Validation loss: 1.7975682738006755

Epoch: 467| Step: 0
Training loss: 1.1516072750091553
Validation loss: 1.802040530789283

Epoch: 6| Step: 1
Training loss: 0.9583455920219421
Validation loss: 1.7480943126063193

Epoch: 6| Step: 2
Training loss: 0.8131599426269531
Validation loss: 1.746773523028179

Epoch: 6| Step: 3
Training loss: 1.2930572032928467
Validation loss: 1.751290403386598

Epoch: 6| Step: 4
Training loss: 1.0371196269989014
Validation loss: 1.700531449369205

Epoch: 6| Step: 5
Training loss: 1.2030272483825684
Validation loss: 1.7416194356897825

Epoch: 6| Step: 6
Training loss: 0.910119891166687
Validation loss: 1.743214912312005

Epoch: 6| Step: 7
Training loss: 0.780036449432373
Validation loss: 1.7468305839005338

Epoch: 6| Step: 8
Training loss: 1.0813896656036377
Validation loss: 1.7256012924255864

Epoch: 6| Step: 9
Training loss: 0.8184108138084412
Validation loss: 1.754850406800547

Epoch: 6| Step: 10
Training loss: 0.9734423756599426
Validation loss: 1.6464607010605514

Epoch: 6| Step: 11
Training loss: 1.154862403869629
Validation loss: 1.7360085723220662

Epoch: 6| Step: 12
Training loss: 1.1770583391189575
Validation loss: 1.7743446775662002

Epoch: 6| Step: 13
Training loss: 0.8881848454475403
Validation loss: 1.7278952624208184

Epoch: 468| Step: 0
Training loss: 1.1252105236053467
Validation loss: 1.786360845770887

Epoch: 6| Step: 1
Training loss: 0.875173032283783
Validation loss: 1.747770518384954

Epoch: 6| Step: 2
Training loss: 0.7680867910385132
Validation loss: 1.771247310023154

Epoch: 6| Step: 3
Training loss: 1.0802286863327026
Validation loss: 1.6903280083851149

Epoch: 6| Step: 4
Training loss: 1.4710649251937866
Validation loss: 1.7221811586810696

Epoch: 6| Step: 5
Training loss: 1.1923415660858154
Validation loss: 1.7181198109862625

Epoch: 6| Step: 6
Training loss: 1.3350226879119873
Validation loss: 1.7254656232813352

Epoch: 6| Step: 7
Training loss: 1.0971226692199707
Validation loss: 1.6545038607812697

Epoch: 6| Step: 8
Training loss: 0.9649183750152588
Validation loss: 1.7714468317647134

Epoch: 6| Step: 9
Training loss: 1.0469257831573486
Validation loss: 1.803812519196541

Epoch: 6| Step: 10
Training loss: 0.9335780739784241
Validation loss: 1.7451325462710472

Epoch: 6| Step: 11
Training loss: 1.294550895690918
Validation loss: 1.7644263134207776

Epoch: 6| Step: 12
Training loss: 0.8362279534339905
Validation loss: 1.712597280420283

Epoch: 6| Step: 13
Training loss: 0.7204773426055908
Validation loss: 1.7119513339893793

Epoch: 469| Step: 0
Training loss: 1.174804925918579
Validation loss: 1.7341595157500236

Epoch: 6| Step: 1
Training loss: 1.0838907957077026
Validation loss: 1.6704669293536936

Epoch: 6| Step: 2
Training loss: 1.194706678390503
Validation loss: 1.745781986944137

Epoch: 6| Step: 3
Training loss: 1.1021757125854492
Validation loss: 1.833165749426811

Epoch: 6| Step: 4
Training loss: 1.7085747718811035
Validation loss: 1.7801017697139452

Epoch: 6| Step: 5
Training loss: 1.116213321685791
Validation loss: 1.738137270814629

Epoch: 6| Step: 6
Training loss: 0.72931969165802
Validation loss: 1.7396557728449504

Epoch: 6| Step: 7
Training loss: 1.1316759586334229
Validation loss: 1.7087018643656084

Epoch: 6| Step: 8
Training loss: 1.2352137565612793
Validation loss: 1.7773222936097013

Epoch: 6| Step: 9
Training loss: 0.7350253462791443
Validation loss: 1.7778617066721762

Epoch: 6| Step: 10
Training loss: 0.9231414794921875
Validation loss: 1.743074369686906

Epoch: 6| Step: 11
Training loss: 0.8936053514480591
Validation loss: 1.7356590570942048

Epoch: 6| Step: 12
Training loss: 1.012756586074829
Validation loss: 1.7914484329121088

Epoch: 6| Step: 13
Training loss: 0.5910139083862305
Validation loss: 1.6914133846118886

Epoch: 470| Step: 0
Training loss: 0.6612902879714966
Validation loss: 1.7014275135532502

Epoch: 6| Step: 1
Training loss: 1.3557854890823364
Validation loss: 1.6708458700487692

Epoch: 6| Step: 2
Training loss: 0.9854295253753662
Validation loss: 1.7445273104534353

Epoch: 6| Step: 3
Training loss: 1.0948643684387207
Validation loss: 1.7222118851959065

Epoch: 6| Step: 4
Training loss: 1.3999744653701782
Validation loss: 1.638136266380228

Epoch: 6| Step: 5
Training loss: 0.8177300691604614
Validation loss: 1.6165352636767971

Epoch: 6| Step: 6
Training loss: 0.9253886342048645
Validation loss: 1.7505222007792482

Epoch: 6| Step: 7
Training loss: 1.3665673732757568
Validation loss: 1.689909500460471

Epoch: 6| Step: 8
Training loss: 0.8041810393333435
Validation loss: 1.7291508349039222

Epoch: 6| Step: 9
Training loss: 1.4238128662109375
Validation loss: 1.8211885216415569

Epoch: 6| Step: 10
Training loss: 1.198535680770874
Validation loss: 1.7523076700907882

Epoch: 6| Step: 11
Training loss: 0.6636655330657959
Validation loss: 1.7512272006721907

Epoch: 6| Step: 12
Training loss: 1.263533592224121
Validation loss: 1.778240894758573

Epoch: 6| Step: 13
Training loss: 0.6310518980026245
Validation loss: 1.7994743072858421

Epoch: 471| Step: 0
Training loss: 1.2515615224838257
Validation loss: 1.7593554527528825

Epoch: 6| Step: 1
Training loss: 1.3425617218017578
Validation loss: 1.8067577321042296

Epoch: 6| Step: 2
Training loss: 1.1914067268371582
Validation loss: 1.817619800567627

Epoch: 6| Step: 3
Training loss: 0.9061986804008484
Validation loss: 1.7332868909323087

Epoch: 6| Step: 4
Training loss: 0.895652174949646
Validation loss: 1.7587254021757392

Epoch: 6| Step: 5
Training loss: 0.9854964017868042
Validation loss: 1.7116932330592987

Epoch: 6| Step: 6
Training loss: 0.7551063299179077
Validation loss: 1.7251179936111614

Epoch: 6| Step: 7
Training loss: 0.9179567098617554
Validation loss: 1.6800977645381805

Epoch: 6| Step: 8
Training loss: 1.171409249305725
Validation loss: 1.7779072651299097

Epoch: 6| Step: 9
Training loss: 0.6031907796859741
Validation loss: 1.7741284754968458

Epoch: 6| Step: 10
Training loss: 1.4299633502960205
Validation loss: 1.6740591526031494

Epoch: 6| Step: 11
Training loss: 0.9547910690307617
Validation loss: 1.7015209005724998

Epoch: 6| Step: 12
Training loss: 1.5945073366165161
Validation loss: 1.7203673688314294

Epoch: 6| Step: 13
Training loss: 0.8853335976600647
Validation loss: 1.6522803280943184

Epoch: 472| Step: 0
Training loss: 1.170527696609497
Validation loss: 1.7171854460111229

Epoch: 6| Step: 1
Training loss: 0.8564504384994507
Validation loss: 1.709817627424835

Epoch: 6| Step: 2
Training loss: 1.894769549369812
Validation loss: 1.6472483802867193

Epoch: 6| Step: 3
Training loss: 0.9707949161529541
Validation loss: 1.7729398947890087

Epoch: 6| Step: 4
Training loss: 0.9537732601165771
Validation loss: 1.7406113788645754

Epoch: 6| Step: 5
Training loss: 0.8478775024414062
Validation loss: 1.7733272762708767

Epoch: 6| Step: 6
Training loss: 0.5787222385406494
Validation loss: 1.7220452177909114

Epoch: 6| Step: 7
Training loss: 1.9140199422836304
Validation loss: 1.7241222345700828

Epoch: 6| Step: 8
Training loss: 1.147883415222168
Validation loss: 1.6954183706673243

Epoch: 6| Step: 9
Training loss: 0.7799533009529114
Validation loss: 1.7404573258533274

Epoch: 6| Step: 10
Training loss: 0.9135656356811523
Validation loss: 1.7386057453770791

Epoch: 6| Step: 11
Training loss: 1.003950834274292
Validation loss: 1.7065965719120477

Epoch: 6| Step: 12
Training loss: 0.9242692589759827
Validation loss: 1.7264769102937432

Epoch: 6| Step: 13
Training loss: 0.8047214150428772
Validation loss: 1.7888440162904802

Epoch: 473| Step: 0
Training loss: 1.0905330181121826
Validation loss: 1.6893100200160858

Epoch: 6| Step: 1
Training loss: 0.8726086020469666
Validation loss: 1.7517566539907967

Epoch: 6| Step: 2
Training loss: 0.9916737079620361
Validation loss: 1.7821059329535371

Epoch: 6| Step: 3
Training loss: 0.977333664894104
Validation loss: 1.763171524129888

Epoch: 6| Step: 4
Training loss: 1.3917326927185059
Validation loss: 1.8094121640728367

Epoch: 6| Step: 5
Training loss: 1.139369010925293
Validation loss: 1.792184660511632

Epoch: 6| Step: 6
Training loss: 0.8145480155944824
Validation loss: 1.7863498823617094

Epoch: 6| Step: 7
Training loss: 1.6949901580810547
Validation loss: 1.7644483735484462

Epoch: 6| Step: 8
Training loss: 0.6961939334869385
Validation loss: 1.872398841765619

Epoch: 6| Step: 9
Training loss: 1.139804720878601
Validation loss: 1.821413900262566

Epoch: 6| Step: 10
Training loss: 1.5675711631774902
Validation loss: 1.769116565745364

Epoch: 6| Step: 11
Training loss: 0.9624825716018677
Validation loss: 1.6813848377555929

Epoch: 6| Step: 12
Training loss: 0.8515147566795349
Validation loss: 1.78843601288334

Epoch: 6| Step: 13
Training loss: 1.0699386596679688
Validation loss: 1.7237482096559258

Epoch: 474| Step: 0
Training loss: 0.808020830154419
Validation loss: 1.7068788543824227

Epoch: 6| Step: 1
Training loss: 0.7899466753005981
Validation loss: 1.7447390325607792

Epoch: 6| Step: 2
Training loss: 0.8267989158630371
Validation loss: 1.6857504716483496

Epoch: 6| Step: 3
Training loss: 0.7484030723571777
Validation loss: 1.788050756659559

Epoch: 6| Step: 4
Training loss: 0.9949474334716797
Validation loss: 1.7408585522764473

Epoch: 6| Step: 5
Training loss: 1.2981975078582764
Validation loss: 1.768339221195508

Epoch: 6| Step: 6
Training loss: 1.3081512451171875
Validation loss: 1.7462266581032866

Epoch: 6| Step: 7
Training loss: 1.155564546585083
Validation loss: 1.6840141114368234

Epoch: 6| Step: 8
Training loss: 1.5362013578414917
Validation loss: 1.7264628525703185

Epoch: 6| Step: 9
Training loss: 1.2091559171676636
Validation loss: 1.756859270475244

Epoch: 6| Step: 10
Training loss: 0.6552137136459351
Validation loss: 1.7917124686702606

Epoch: 6| Step: 11
Training loss: 0.8589325547218323
Validation loss: 1.7821707840888732

Epoch: 6| Step: 12
Training loss: 0.6124452352523804
Validation loss: 1.7519595084651824

Epoch: 6| Step: 13
Training loss: 1.2840867042541504
Validation loss: 1.7557793407030002

Epoch: 475| Step: 0
Training loss: 1.1073744297027588
Validation loss: 1.6956769022890317

Epoch: 6| Step: 1
Training loss: 1.2333487272262573
Validation loss: 1.6788407564163208

Epoch: 6| Step: 2
Training loss: 0.9769947528839111
Validation loss: 1.7446760567285682

Epoch: 6| Step: 3
Training loss: 0.9353356957435608
Validation loss: 1.7465653393858223

Epoch: 6| Step: 4
Training loss: 1.4221491813659668
Validation loss: 1.7524328988085511

Epoch: 6| Step: 5
Training loss: 0.6482113003730774
Validation loss: 1.704719316574835

Epoch: 6| Step: 6
Training loss: 0.9522097706794739
Validation loss: 1.6910051453498103

Epoch: 6| Step: 7
Training loss: 1.181767225265503
Validation loss: 1.7750289465791436

Epoch: 6| Step: 8
Training loss: 0.8419675230979919
Validation loss: 1.7491825011468702

Epoch: 6| Step: 9
Training loss: 0.8169034719467163
Validation loss: 1.763579014808901

Epoch: 6| Step: 10
Training loss: 0.7140081524848938
Validation loss: 1.75082181602396

Epoch: 6| Step: 11
Training loss: 1.5000360012054443
Validation loss: 1.728396237537425

Epoch: 6| Step: 12
Training loss: 1.1567836999893188
Validation loss: 1.789720066132084

Epoch: 6| Step: 13
Training loss: 1.1374306678771973
Validation loss: 1.727192977423309

Epoch: 476| Step: 0
Training loss: 1.100110650062561
Validation loss: 1.775706744963123

Epoch: 6| Step: 1
Training loss: 1.010526180267334
Validation loss: 1.7301124821427047

Epoch: 6| Step: 2
Training loss: 1.226759433746338
Validation loss: 1.6843465015452395

Epoch: 6| Step: 3
Training loss: 1.4320255517959595
Validation loss: 1.7541698807029313

Epoch: 6| Step: 4
Training loss: 0.7020155787467957
Validation loss: 1.727476066158664

Epoch: 6| Step: 5
Training loss: 1.050488829612732
Validation loss: 1.7106092065893195

Epoch: 6| Step: 6
Training loss: 0.632540225982666
Validation loss: 1.8051958699380197

Epoch: 6| Step: 7
Training loss: 1.4192529916763306
Validation loss: 1.777090343095923

Epoch: 6| Step: 8
Training loss: 1.0640387535095215
Validation loss: 1.797133356012324

Epoch: 6| Step: 9
Training loss: 0.9981130361557007
Validation loss: 1.7427142204776886

Epoch: 6| Step: 10
Training loss: 0.7729024291038513
Validation loss: 1.7793492271054177

Epoch: 6| Step: 11
Training loss: 0.7245970964431763
Validation loss: 1.758463091747735

Epoch: 6| Step: 12
Training loss: 1.1171865463256836
Validation loss: 1.7495873794760755

Epoch: 6| Step: 13
Training loss: 1.2957898378372192
Validation loss: 1.7398542076028802

Epoch: 477| Step: 0
Training loss: 0.7694864869117737
Validation loss: 1.7112877881655129

Epoch: 6| Step: 1
Training loss: 0.7593989968299866
Validation loss: 1.741732443532636

Epoch: 6| Step: 2
Training loss: 1.2696950435638428
Validation loss: 1.7395717302958171

Epoch: 6| Step: 3
Training loss: 1.0484662055969238
Validation loss: 1.7025647727392053

Epoch: 6| Step: 4
Training loss: 1.2241061925888062
Validation loss: 1.6852254290734567

Epoch: 6| Step: 5
Training loss: 1.115639567375183
Validation loss: 1.7051935862469416

Epoch: 6| Step: 6
Training loss: 1.0914186239242554
Validation loss: 1.7362500826517742

Epoch: 6| Step: 7
Training loss: 1.018189787864685
Validation loss: 1.7686340270503875

Epoch: 6| Step: 8
Training loss: 1.0582668781280518
Validation loss: 1.7748107781974218

Epoch: 6| Step: 9
Training loss: 1.6394412517547607
Validation loss: 1.7235676511641471

Epoch: 6| Step: 10
Training loss: 0.6124177575111389
Validation loss: 1.7849036647427468

Epoch: 6| Step: 11
Training loss: 1.063328504562378
Validation loss: 1.7705448301889564

Epoch: 6| Step: 12
Training loss: 0.5612439513206482
Validation loss: 1.7473397280580254

Epoch: 6| Step: 13
Training loss: 1.7939224243164062
Validation loss: 1.7085630842434463

Epoch: 478| Step: 0
Training loss: 0.9209192991256714
Validation loss: 1.7287724864098333

Epoch: 6| Step: 1
Training loss: 0.9529749155044556
Validation loss: 1.7760232879269509

Epoch: 6| Step: 2
Training loss: 1.0352087020874023
Validation loss: 1.70883301765688

Epoch: 6| Step: 3
Training loss: 1.5046783685684204
Validation loss: 1.7129765492613598

Epoch: 6| Step: 4
Training loss: 0.5769510269165039
Validation loss: 1.7590057157701062

Epoch: 6| Step: 5
Training loss: 1.5010485649108887
Validation loss: 1.697994000168257

Epoch: 6| Step: 6
Training loss: 0.7790474891662598
Validation loss: 1.7340931584758144

Epoch: 6| Step: 7
Training loss: 1.523167610168457
Validation loss: 1.7363765842171126

Epoch: 6| Step: 8
Training loss: 0.9775338172912598
Validation loss: 1.7171443341880717

Epoch: 6| Step: 9
Training loss: 1.256301999092102
Validation loss: 1.6811081876036942

Epoch: 6| Step: 10
Training loss: 0.5802407264709473
Validation loss: 1.762703598186534

Epoch: 6| Step: 11
Training loss: 1.07907235622406
Validation loss: 1.7861172742741083

Epoch: 6| Step: 12
Training loss: 0.9160175323486328
Validation loss: 1.7857618408818399

Epoch: 6| Step: 13
Training loss: 1.080819010734558
Validation loss: 1.6896622155302314

Epoch: 479| Step: 0
Training loss: 0.7354322075843811
Validation loss: 1.7105756921152915

Epoch: 6| Step: 1
Training loss: 1.411721110343933
Validation loss: 1.7270302182884627

Epoch: 6| Step: 2
Training loss: 1.0176944732666016
Validation loss: 1.7620076787087224

Epoch: 6| Step: 3
Training loss: 0.8957952260971069
Validation loss: 1.8047339390682917

Epoch: 6| Step: 4
Training loss: 0.87440425157547
Validation loss: 1.833377629198054

Epoch: 6| Step: 5
Training loss: 1.1605831384658813
Validation loss: 1.7239936833740563

Epoch: 6| Step: 6
Training loss: 1.7530381679534912
Validation loss: 1.7915763867798673

Epoch: 6| Step: 7
Training loss: 1.2594555616378784
Validation loss: 1.7304354662536292

Epoch: 6| Step: 8
Training loss: 0.8523982763290405
Validation loss: 1.8232278657215897

Epoch: 6| Step: 9
Training loss: 0.6229289174079895
Validation loss: 1.7557341808913856

Epoch: 6| Step: 10
Training loss: 1.4122562408447266
Validation loss: 1.772534312740449

Epoch: 6| Step: 11
Training loss: 1.0620263814926147
Validation loss: 1.7627900018486926

Epoch: 6| Step: 12
Training loss: 0.9207706451416016
Validation loss: 1.781306210384574

Epoch: 6| Step: 13
Training loss: 0.9800711870193481
Validation loss: 1.7322969782736994

Epoch: 480| Step: 0
Training loss: 1.0631129741668701
Validation loss: 1.6804771295157812

Epoch: 6| Step: 1
Training loss: 0.7678505182266235
Validation loss: 1.7539004869358514

Epoch: 6| Step: 2
Training loss: 0.8639732003211975
Validation loss: 1.7727205214961883

Epoch: 6| Step: 3
Training loss: 1.3617029190063477
Validation loss: 1.7601866619561308

Epoch: 6| Step: 4
Training loss: 0.977754533290863
Validation loss: 1.7678493274155485

Epoch: 6| Step: 5
Training loss: 0.7197134494781494
Validation loss: 1.7416470576358098

Epoch: 6| Step: 6
Training loss: 1.368747591972351
Validation loss: 1.7013362812739548

Epoch: 6| Step: 7
Training loss: 0.6467539072036743
Validation loss: 1.7288567378956785

Epoch: 6| Step: 8
Training loss: 1.3267768621444702
Validation loss: 1.730215919915066

Epoch: 6| Step: 9
Training loss: 1.089467167854309
Validation loss: 1.6884733682037683

Epoch: 6| Step: 10
Training loss: 0.8797321319580078
Validation loss: 1.7382910072162587

Epoch: 6| Step: 11
Training loss: 1.2410887479782104
Validation loss: 1.7218638197068246

Epoch: 6| Step: 12
Training loss: 0.8476049900054932
Validation loss: 1.684150267672795

Epoch: 6| Step: 13
Training loss: 1.4330670833587646
Validation loss: 1.7654610064721876

Epoch: 481| Step: 0
Training loss: 1.3105336427688599
Validation loss: 1.7374845102269163

Epoch: 6| Step: 1
Training loss: 1.6446080207824707
Validation loss: 1.780537671940301

Epoch: 6| Step: 2
Training loss: 1.306904673576355
Validation loss: 1.7577131602071947

Epoch: 6| Step: 3
Training loss: 0.9339218139648438
Validation loss: 1.728246336342186

Epoch: 6| Step: 4
Training loss: 0.9986384510993958
Validation loss: 1.7109556864666682

Epoch: 6| Step: 5
Training loss: 0.6759424805641174
Validation loss: 1.741082340158442

Epoch: 6| Step: 6
Training loss: 0.7578152418136597
Validation loss: 1.7066552421098113

Epoch: 6| Step: 7
Training loss: 1.34690260887146
Validation loss: 1.7288503980123868

Epoch: 6| Step: 8
Training loss: 0.5194410085678101
Validation loss: 1.6884554457920853

Epoch: 6| Step: 9
Training loss: 0.8842623233795166
Validation loss: 1.7196333895447433

Epoch: 6| Step: 10
Training loss: 1.217689037322998
Validation loss: 1.6929593432334162

Epoch: 6| Step: 11
Training loss: 0.9644874334335327
Validation loss: 1.6710923076957784

Epoch: 6| Step: 12
Training loss: 0.8190841674804688
Validation loss: 1.7988050112160303

Epoch: 6| Step: 13
Training loss: 0.9528303146362305
Validation loss: 1.7860583784759685

Epoch: 482| Step: 0
Training loss: 0.7626694440841675
Validation loss: 1.7269551677088584

Epoch: 6| Step: 1
Training loss: 1.3568960428237915
Validation loss: 1.7150675699275026

Epoch: 6| Step: 2
Training loss: 1.0368058681488037
Validation loss: 1.7845199056850967

Epoch: 6| Step: 3
Training loss: 1.210904836654663
Validation loss: 1.680318106887161

Epoch: 6| Step: 4
Training loss: 0.9358545541763306
Validation loss: 1.7465469734643095

Epoch: 6| Step: 5
Training loss: 1.7864642143249512
Validation loss: 1.6887412378864903

Epoch: 6| Step: 6
Training loss: 1.1895496845245361
Validation loss: 1.7353053823594125

Epoch: 6| Step: 7
Training loss: 0.4792535603046417
Validation loss: 1.8027899380653136

Epoch: 6| Step: 8
Training loss: 1.0747506618499756
Validation loss: 1.703949607828612

Epoch: 6| Step: 9
Training loss: 0.9793967008590698
Validation loss: 1.725019480592461

Epoch: 6| Step: 10
Training loss: 0.7686054706573486
Validation loss: 1.6778940359751384

Epoch: 6| Step: 11
Training loss: 0.9759260416030884
Validation loss: 1.7030303990969093

Epoch: 6| Step: 12
Training loss: 0.8359869718551636
Validation loss: 1.7499495936978249

Epoch: 6| Step: 13
Training loss: 0.8894869685173035
Validation loss: 1.706377319110337

Epoch: 483| Step: 0
Training loss: 1.66438627243042
Validation loss: 1.7040585881920272

Epoch: 6| Step: 1
Training loss: 0.7619604468345642
Validation loss: 1.7078391480189499

Epoch: 6| Step: 2
Training loss: 0.9792463183403015
Validation loss: 1.6585890644340104

Epoch: 6| Step: 3
Training loss: 0.733213484287262
Validation loss: 1.726815467239708

Epoch: 6| Step: 4
Training loss: 1.0400729179382324
Validation loss: 1.7583300426442137

Epoch: 6| Step: 5
Training loss: 1.2804265022277832
Validation loss: 1.727316782038699

Epoch: 6| Step: 6
Training loss: 1.207458257675171
Validation loss: 1.7497095395159978

Epoch: 6| Step: 7
Training loss: 1.3599518537521362
Validation loss: 1.7463164111619354

Epoch: 6| Step: 8
Training loss: 0.6949576735496521
Validation loss: 1.7678962574210217

Epoch: 6| Step: 9
Training loss: 1.005645990371704
Validation loss: 1.7669365623945832

Epoch: 6| Step: 10
Training loss: 0.5741458535194397
Validation loss: 1.7261595008193806

Epoch: 6| Step: 11
Training loss: 1.1913244724273682
Validation loss: 1.6320518319324782

Epoch: 6| Step: 12
Training loss: 0.8853684663772583
Validation loss: 1.6877496742433118

Epoch: 6| Step: 13
Training loss: 0.8010227680206299
Validation loss: 1.7406706835633965

Epoch: 484| Step: 0
Training loss: 0.8221444487571716
Validation loss: 1.7731134532600321

Epoch: 6| Step: 1
Training loss: 0.7606117725372314
Validation loss: 1.7073776106680594

Epoch: 6| Step: 2
Training loss: 1.2417118549346924
Validation loss: 1.7387350810471403

Epoch: 6| Step: 3
Training loss: 0.5579574108123779
Validation loss: 1.7619159029376121

Epoch: 6| Step: 4
Training loss: 0.8590934872627258
Validation loss: 1.8186938711391982

Epoch: 6| Step: 5
Training loss: 0.934768557548523
Validation loss: 1.7114120144997873

Epoch: 6| Step: 6
Training loss: 1.3913863897323608
Validation loss: 1.7408480285316386

Epoch: 6| Step: 7
Training loss: 0.9153263568878174
Validation loss: 1.7233316295890397

Epoch: 6| Step: 8
Training loss: 0.9145815372467041
Validation loss: 1.757226263323138

Epoch: 6| Step: 9
Training loss: 0.9296953678131104
Validation loss: 1.737434926853385

Epoch: 6| Step: 10
Training loss: 1.39187490940094
Validation loss: 1.7584790542561521

Epoch: 6| Step: 11
Training loss: 0.9817824363708496
Validation loss: 1.8107583445887412

Epoch: 6| Step: 12
Training loss: 0.936249852180481
Validation loss: 1.7920889713430916

Epoch: 6| Step: 13
Training loss: 1.7897682189941406
Validation loss: 1.7167391956493419

Epoch: 485| Step: 0
Training loss: 1.131264328956604
Validation loss: 1.6955183244520617

Epoch: 6| Step: 1
Training loss: 0.9463843107223511
Validation loss: 1.7364989698574107

Epoch: 6| Step: 2
Training loss: 1.303681492805481
Validation loss: 1.7571954547718007

Epoch: 6| Step: 3
Training loss: 1.0959633588790894
Validation loss: 1.7739838041285032

Epoch: 6| Step: 4
Training loss: 0.5455242991447449
Validation loss: 1.6637692297658613

Epoch: 6| Step: 5
Training loss: 1.0350210666656494
Validation loss: 1.742924492846253

Epoch: 6| Step: 6
Training loss: 1.0650811195373535
Validation loss: 1.7679985236096125

Epoch: 6| Step: 7
Training loss: 0.7539651393890381
Validation loss: 1.7022435947131085

Epoch: 6| Step: 8
Training loss: 0.8389543294906616
Validation loss: 1.6956597746059459

Epoch: 6| Step: 9
Training loss: 1.2237547636032104
Validation loss: 1.7286813989762337

Epoch: 6| Step: 10
Training loss: 0.7918123006820679
Validation loss: 1.7474073030615365

Epoch: 6| Step: 11
Training loss: 1.1528074741363525
Validation loss: 1.8104930103466075

Epoch: 6| Step: 12
Training loss: 1.1899806261062622
Validation loss: 1.7269589952243272

Epoch: 6| Step: 13
Training loss: 0.9720650911331177
Validation loss: 1.798436044364847

Epoch: 486| Step: 0
Training loss: 1.0581743717193604
Validation loss: 1.8079629111033615

Epoch: 6| Step: 1
Training loss: 0.5929077863693237
Validation loss: 1.785287994210438

Epoch: 6| Step: 2
Training loss: 0.9989101886749268
Validation loss: 1.7773910837788736

Epoch: 6| Step: 3
Training loss: 1.680896282196045
Validation loss: 1.759188409774534

Epoch: 6| Step: 4
Training loss: 0.5032011270523071
Validation loss: 1.7781240837548369

Epoch: 6| Step: 5
Training loss: 0.5611439943313599
Validation loss: 1.7096624451298867

Epoch: 6| Step: 6
Training loss: 1.510239601135254
Validation loss: 1.7742311569952196

Epoch: 6| Step: 7
Training loss: 0.982338011264801
Validation loss: 1.713461656724253

Epoch: 6| Step: 8
Training loss: 0.869001030921936
Validation loss: 1.80241483770391

Epoch: 6| Step: 9
Training loss: 1.2344658374786377
Validation loss: 1.7259967737300421

Epoch: 6| Step: 10
Training loss: 0.7059987783432007
Validation loss: 1.7030857878346597

Epoch: 6| Step: 11
Training loss: 0.9725021123886108
Validation loss: 1.7192941763067757

Epoch: 6| Step: 12
Training loss: 1.1099021434783936
Validation loss: 1.7251743872960408

Epoch: 6| Step: 13
Training loss: 1.655549168586731
Validation loss: 1.7535783372899538

Epoch: 487| Step: 0
Training loss: 1.0933802127838135
Validation loss: 1.692571299050444

Epoch: 6| Step: 1
Training loss: 1.2490556240081787
Validation loss: 1.7250939979348132

Epoch: 6| Step: 2
Training loss: 0.6898622512817383
Validation loss: 1.6830727233681628

Epoch: 6| Step: 3
Training loss: 0.9751423001289368
Validation loss: 1.7243391839406823

Epoch: 6| Step: 4
Training loss: 0.7950947284698486
Validation loss: 1.7383857516832248

Epoch: 6| Step: 5
Training loss: 1.0255887508392334
Validation loss: 1.7214408997566468

Epoch: 6| Step: 6
Training loss: 0.665880560874939
Validation loss: 1.7120661389443181

Epoch: 6| Step: 7
Training loss: 1.0097956657409668
Validation loss: 1.7768159848387524

Epoch: 6| Step: 8
Training loss: 0.9721835851669312
Validation loss: 1.7113796613549674

Epoch: 6| Step: 9
Training loss: 1.1387158632278442
Validation loss: 1.6922188548631565

Epoch: 6| Step: 10
Training loss: 1.6694391965866089
Validation loss: 1.702399633264029

Epoch: 6| Step: 11
Training loss: 0.6311993598937988
Validation loss: 1.7587220527792489

Epoch: 6| Step: 12
Training loss: 1.4982397556304932
Validation loss: 1.7393913615134455

Epoch: 6| Step: 13
Training loss: 0.8446066975593567
Validation loss: 1.7349684058978994

Epoch: 488| Step: 0
Training loss: 1.0127700567245483
Validation loss: 1.7449488716740762

Epoch: 6| Step: 1
Training loss: 0.5228619575500488
Validation loss: 1.7467247363059752

Epoch: 6| Step: 2
Training loss: 1.542931079864502
Validation loss: 1.7784970139944425

Epoch: 6| Step: 3
Training loss: 1.3815135955810547
Validation loss: 1.7793995193255845

Epoch: 6| Step: 4
Training loss: 0.8478590846061707
Validation loss: 1.676558756059216

Epoch: 6| Step: 5
Training loss: 0.9793526530265808
Validation loss: 1.7665305855453655

Epoch: 6| Step: 6
Training loss: 1.0408992767333984
Validation loss: 1.744881388961628

Epoch: 6| Step: 7
Training loss: 1.0479146242141724
Validation loss: 1.6978729655665736

Epoch: 6| Step: 8
Training loss: 0.5128095149993896
Validation loss: 1.7027642457715926

Epoch: 6| Step: 9
Training loss: 1.5743404626846313
Validation loss: 1.7531350838240756

Epoch: 6| Step: 10
Training loss: 1.0864577293395996
Validation loss: 1.6487579755885626

Epoch: 6| Step: 11
Training loss: 0.8775942325592041
Validation loss: 1.7518690337416947

Epoch: 6| Step: 12
Training loss: 0.8590904474258423
Validation loss: 1.732761675311673

Epoch: 6| Step: 13
Training loss: 0.7634925246238708
Validation loss: 1.7581249526751939

Epoch: 489| Step: 0
Training loss: 0.6635994911193848
Validation loss: 1.7202455484738914

Epoch: 6| Step: 1
Training loss: 1.0690028667449951
Validation loss: 1.659124433353383

Epoch: 6| Step: 2
Training loss: 0.8416460156440735
Validation loss: 1.7067741937534784

Epoch: 6| Step: 3
Training loss: 0.5175240635871887
Validation loss: 1.7243303855260212

Epoch: 6| Step: 4
Training loss: 0.6679960489273071
Validation loss: 1.7167301934252504

Epoch: 6| Step: 5
Training loss: 1.153221607208252
Validation loss: 1.7607344068506712

Epoch: 6| Step: 6
Training loss: 0.907928466796875
Validation loss: 1.7566311513223956

Epoch: 6| Step: 7
Training loss: 0.8592357635498047
Validation loss: 1.808519760767619

Epoch: 6| Step: 8
Training loss: 1.0798530578613281
Validation loss: 1.7944634524724816

Epoch: 6| Step: 9
Training loss: 1.576216697692871
Validation loss: 1.665628602427821

Epoch: 6| Step: 10
Training loss: 0.8812938928604126
Validation loss: 1.716013644331245

Epoch: 6| Step: 11
Training loss: 1.2398738861083984
Validation loss: 1.7124894460042317

Epoch: 6| Step: 12
Training loss: 0.7271484732627869
Validation loss: 1.7395993099417737

Epoch: 6| Step: 13
Training loss: 2.2584757804870605
Validation loss: 1.7658524538881035

Epoch: 490| Step: 0
Training loss: 0.6526122093200684
Validation loss: 1.7071503426439019

Epoch: 6| Step: 1
Training loss: 1.2309976816177368
Validation loss: 1.6790731965854604

Epoch: 6| Step: 2
Training loss: 0.8071316480636597
Validation loss: 1.679370476353553

Epoch: 6| Step: 3
Training loss: 0.47209465503692627
Validation loss: 1.7071378705322102

Epoch: 6| Step: 4
Training loss: 0.7358540296554565
Validation loss: 1.6992769959152385

Epoch: 6| Step: 5
Training loss: 1.113520860671997
Validation loss: 1.6777702082869828

Epoch: 6| Step: 6
Training loss: 1.2059986591339111
Validation loss: 1.6653349066293368

Epoch: 6| Step: 7
Training loss: 1.33330237865448
Validation loss: 1.6911608570365495

Epoch: 6| Step: 8
Training loss: 0.9906646013259888
Validation loss: 1.750649577827864

Epoch: 6| Step: 9
Training loss: 1.7541441917419434
Validation loss: 1.7122557470875401

Epoch: 6| Step: 10
Training loss: 1.421922206878662
Validation loss: 1.7038861423410394

Epoch: 6| Step: 11
Training loss: 1.0325336456298828
Validation loss: 1.7925758643816876

Epoch: 6| Step: 12
Training loss: 1.022800326347351
Validation loss: 1.7645874010619296

Epoch: 6| Step: 13
Training loss: 0.8852528929710388
Validation loss: 1.6934208011114469

Epoch: 491| Step: 0
Training loss: 1.6526947021484375
Validation loss: 1.716492417038128

Epoch: 6| Step: 1
Training loss: 0.944304883480072
Validation loss: 1.7662228858599098

Epoch: 6| Step: 2
Training loss: 0.8874433040618896
Validation loss: 1.724255823319958

Epoch: 6| Step: 3
Training loss: 0.7900811433792114
Validation loss: 1.7346207954550301

Epoch: 6| Step: 4
Training loss: 0.9296003580093384
Validation loss: 1.8140019665482223

Epoch: 6| Step: 5
Training loss: 1.1700425148010254
Validation loss: 1.8210911263701737

Epoch: 6| Step: 6
Training loss: 1.2664024829864502
Validation loss: 1.871488143039006

Epoch: 6| Step: 7
Training loss: 0.846424400806427
Validation loss: 1.7693421276666785

Epoch: 6| Step: 8
Training loss: 1.3167985677719116
Validation loss: 1.694551944732666

Epoch: 6| Step: 9
Training loss: 0.7385400533676147
Validation loss: 1.652409392018472

Epoch: 6| Step: 10
Training loss: 0.7974539995193481
Validation loss: 1.7150196324112594

Epoch: 6| Step: 11
Training loss: 0.6467273831367493
Validation loss: 1.670008550408066

Epoch: 6| Step: 12
Training loss: 0.7941660284996033
Validation loss: 1.6628620445087392

Epoch: 6| Step: 13
Training loss: 0.5497522950172424
Validation loss: 1.6738646761063607

Epoch: 492| Step: 0
Training loss: 0.7183337211608887
Validation loss: 1.7062518340285107

Epoch: 6| Step: 1
Training loss: 0.8344205617904663
Validation loss: 1.7098074292623868

Epoch: 6| Step: 2
Training loss: 0.7789225578308105
Validation loss: 1.7790219886328584

Epoch: 6| Step: 3
Training loss: 0.8370964527130127
Validation loss: 1.6946216757579515

Epoch: 6| Step: 4
Training loss: 0.931019127368927
Validation loss: 1.7091726705592165

Epoch: 6| Step: 5
Training loss: 1.5473980903625488
Validation loss: 1.7091935014212003

Epoch: 6| Step: 6
Training loss: 1.6405333280563354
Validation loss: 1.7093117557546145

Epoch: 6| Step: 7
Training loss: 1.0135087966918945
Validation loss: 1.7359437711777226

Epoch: 6| Step: 8
Training loss: 0.7446248531341553
Validation loss: 1.6876226202134164

Epoch: 6| Step: 9
Training loss: 0.5997923612594604
Validation loss: 1.7361472075985325

Epoch: 6| Step: 10
Training loss: 0.7872276306152344
Validation loss: 1.7663955611567344

Epoch: 6| Step: 11
Training loss: 1.2062242031097412
Validation loss: 1.755813383286999

Epoch: 6| Step: 12
Training loss: 1.0762989521026611
Validation loss: 1.6616019343817106

Epoch: 6| Step: 13
Training loss: 1.0663355588912964
Validation loss: 1.7240886918960079

Epoch: 493| Step: 0
Training loss: 0.545148491859436
Validation loss: 1.7372194272215649

Epoch: 6| Step: 1
Training loss: 0.8596965670585632
Validation loss: 1.8017113695862472

Epoch: 6| Step: 2
Training loss: 0.9111918210983276
Validation loss: 1.7598141841990973

Epoch: 6| Step: 3
Training loss: 0.6666451692581177
Validation loss: 1.7647195990367601

Epoch: 6| Step: 4
Training loss: 1.41615629196167
Validation loss: 1.774260756789997

Epoch: 6| Step: 5
Training loss: 0.605488121509552
Validation loss: 1.7250137905920706

Epoch: 6| Step: 6
Training loss: 1.0346473455429077
Validation loss: 1.7828019639497161

Epoch: 6| Step: 7
Training loss: 1.520424246788025
Validation loss: 1.7342360173502276

Epoch: 6| Step: 8
Training loss: 1.3167884349822998
Validation loss: 1.6950538645508468

Epoch: 6| Step: 9
Training loss: 0.5818541049957275
Validation loss: 1.7022182967073174

Epoch: 6| Step: 10
Training loss: 0.9969927668571472
Validation loss: 1.657460948472382

Epoch: 6| Step: 11
Training loss: 1.1234188079833984
Validation loss: 1.7584344263999694

Epoch: 6| Step: 12
Training loss: 0.6895366907119751
Validation loss: 1.596822327183139

Epoch: 6| Step: 13
Training loss: 1.1076802015304565
Validation loss: 1.7373276961747037

Epoch: 494| Step: 0
Training loss: 0.87293541431427
Validation loss: 1.7016253099646619

Epoch: 6| Step: 1
Training loss: 0.9035142064094543
Validation loss: 1.6865777674541678

Epoch: 6| Step: 2
Training loss: 0.8120335340499878
Validation loss: 1.6539744048990228

Epoch: 6| Step: 3
Training loss: 0.6050571203231812
Validation loss: 1.7845838069915771

Epoch: 6| Step: 4
Training loss: 0.8608953356742859
Validation loss: 1.7537734175241122

Epoch: 6| Step: 5
Training loss: 0.9967381358146667
Validation loss: 1.6310701626603321

Epoch: 6| Step: 6
Training loss: 0.8613366484642029
Validation loss: 1.6772614820029146

Epoch: 6| Step: 7
Training loss: 1.2202922105789185
Validation loss: 1.683217196054356

Epoch: 6| Step: 8
Training loss: 0.7977734804153442
Validation loss: 1.6733464912701679

Epoch: 6| Step: 9
Training loss: 1.2142329216003418
Validation loss: 1.7356950262541413

Epoch: 6| Step: 10
Training loss: 0.8101933002471924
Validation loss: 1.7457840955385597

Epoch: 6| Step: 11
Training loss: 1.0318387746810913
Validation loss: 1.7386902570724487

Epoch: 6| Step: 12
Training loss: 1.4783815145492554
Validation loss: 1.6880217649603402

Epoch: 6| Step: 13
Training loss: 1.0477932691574097
Validation loss: 1.663277611937574

Epoch: 495| Step: 0
Training loss: 1.2309056520462036
Validation loss: 1.7101001585683515

Epoch: 6| Step: 1
Training loss: 0.7518911957740784
Validation loss: 1.7327250075596634

Epoch: 6| Step: 2
Training loss: 0.8819330334663391
Validation loss: 1.7015597897191201

Epoch: 6| Step: 3
Training loss: 1.0634957551956177
Validation loss: 1.688290988245318

Epoch: 6| Step: 4
Training loss: 0.9260268211364746
Validation loss: 1.7120057023981565

Epoch: 6| Step: 5
Training loss: 1.583125352859497
Validation loss: 1.7569966777678458

Epoch: 6| Step: 6
Training loss: 0.978355884552002
Validation loss: 1.7777115119400846

Epoch: 6| Step: 7
Training loss: 1.0949063301086426
Validation loss: 1.7332396481626777

Epoch: 6| Step: 8
Training loss: 0.9126327037811279
Validation loss: 1.723369611206875

Epoch: 6| Step: 9
Training loss: 0.7973172664642334
Validation loss: 1.7246887581322783

Epoch: 6| Step: 10
Training loss: 1.1428254842758179
Validation loss: 1.698823328941099

Epoch: 6| Step: 11
Training loss: 0.6238040328025818
Validation loss: 1.7244182607179046

Epoch: 6| Step: 12
Training loss: 1.3391237258911133
Validation loss: 1.6841050681247507

Epoch: 6| Step: 13
Training loss: 0.800612211227417
Validation loss: 1.7116303354181268

Epoch: 496| Step: 0
Training loss: 0.9104799032211304
Validation loss: 1.684089490162429

Epoch: 6| Step: 1
Training loss: 0.9935305118560791
Validation loss: 1.7162614817260413

Epoch: 6| Step: 2
Training loss: 0.40437018871307373
Validation loss: 1.7066776508926063

Epoch: 6| Step: 3
Training loss: 0.8654726147651672
Validation loss: 1.7071549020787722

Epoch: 6| Step: 4
Training loss: 0.6054137945175171
Validation loss: 1.677429405591821

Epoch: 6| Step: 5
Training loss: 1.0365848541259766
Validation loss: 1.7345390858188752

Epoch: 6| Step: 6
Training loss: 1.2574520111083984
Validation loss: 1.6997757650190783

Epoch: 6| Step: 7
Training loss: 0.9644542932510376
Validation loss: 1.7913488265006774

Epoch: 6| Step: 8
Training loss: 0.8626030087471008
Validation loss: 1.681144211240994

Epoch: 6| Step: 9
Training loss: 0.8039501309394836
Validation loss: 1.7255370540003623

Epoch: 6| Step: 10
Training loss: 1.2052797079086304
Validation loss: 1.7705097211304532

Epoch: 6| Step: 11
Training loss: 0.8526870608329773
Validation loss: 1.714320319955067

Epoch: 6| Step: 12
Training loss: 1.6914644241333008
Validation loss: 1.7712927197897306

Epoch: 6| Step: 13
Training loss: 0.9652178287506104
Validation loss: 1.7383229706877021

Epoch: 497| Step: 0
Training loss: 0.7464319467544556
Validation loss: 1.7334636693359704

Epoch: 6| Step: 1
Training loss: 1.08833909034729
Validation loss: 1.799341385082532

Epoch: 6| Step: 2
Training loss: 0.8716462254524231
Validation loss: 1.7216758279390232

Epoch: 6| Step: 3
Training loss: 0.6871072053909302
Validation loss: 1.766013080073941

Epoch: 6| Step: 4
Training loss: 0.8697942495346069
Validation loss: 1.7433291891569733

Epoch: 6| Step: 5
Training loss: 1.0337834358215332
Validation loss: 1.6789921304231048

Epoch: 6| Step: 6
Training loss: 1.1941267251968384
Validation loss: 1.7243701578468404

Epoch: 6| Step: 7
Training loss: 0.5502519607543945
Validation loss: 1.6562380124163885

Epoch: 6| Step: 8
Training loss: 1.3915126323699951
Validation loss: 1.720329749968744

Epoch: 6| Step: 9
Training loss: 0.9890769720077515
Validation loss: 1.7398309451277538

Epoch: 6| Step: 10
Training loss: 0.8212598562240601
Validation loss: 1.693955582957114

Epoch: 6| Step: 11
Training loss: 1.1021714210510254
Validation loss: 1.7360394372734973

Epoch: 6| Step: 12
Training loss: 0.8743352293968201
Validation loss: 1.7709689089047012

Epoch: 6| Step: 13
Training loss: 1.5293399095535278
Validation loss: 1.7370726523860809

Epoch: 498| Step: 0
Training loss: 0.7989448308944702
Validation loss: 1.6243959831935104

Epoch: 6| Step: 1
Training loss: 0.9936820268630981
Validation loss: 1.785449763779999

Epoch: 6| Step: 2
Training loss: 0.9621998071670532
Validation loss: 1.713182557013727

Epoch: 6| Step: 3
Training loss: 0.5363603830337524
Validation loss: 1.7015761547191168

Epoch: 6| Step: 4
Training loss: 0.7290927171707153
Validation loss: 1.6629076926938948

Epoch: 6| Step: 5
Training loss: 0.667412281036377
Validation loss: 1.6848421276256602

Epoch: 6| Step: 6
Training loss: 0.7562690377235413
Validation loss: 1.7976732561665196

Epoch: 6| Step: 7
Training loss: 1.2447444200515747
Validation loss: 1.7218636569156442

Epoch: 6| Step: 8
Training loss: 1.2936667203903198
Validation loss: 1.710159460703532

Epoch: 6| Step: 9
Training loss: 1.3319470882415771
Validation loss: 1.7626012755978493

Epoch: 6| Step: 10
Training loss: 1.1992498636245728
Validation loss: 1.7557701269785564

Epoch: 6| Step: 11
Training loss: 1.0178604125976562
Validation loss: 1.7081047693888347

Epoch: 6| Step: 12
Training loss: 0.8989170789718628
Validation loss: 1.7302920228691512

Epoch: 6| Step: 13
Training loss: 1.8235501050949097
Validation loss: 1.7425757941379343

Epoch: 499| Step: 0
Training loss: 1.3689229488372803
Validation loss: 1.7108152989418275

Epoch: 6| Step: 1
Training loss: 1.0893563032150269
Validation loss: 1.738650562942669

Epoch: 6| Step: 2
Training loss: 1.0026171207427979
Validation loss: 1.720494920207608

Epoch: 6| Step: 3
Training loss: 0.5455201864242554
Validation loss: 1.7538893248445244

Epoch: 6| Step: 4
Training loss: 0.9283281564712524
Validation loss: 1.6687065837203816

Epoch: 6| Step: 5
Training loss: 1.398410439491272
Validation loss: 1.7034004106316516

Epoch: 6| Step: 6
Training loss: 0.6383995413780212
Validation loss: 1.7332642539854972

Epoch: 6| Step: 7
Training loss: 0.908087968826294
Validation loss: 1.715329667573334

Epoch: 6| Step: 8
Training loss: 1.6311123371124268
Validation loss: 1.7131565898977301

Epoch: 6| Step: 9
Training loss: 0.6760408878326416
Validation loss: 1.7061720400728204

Epoch: 6| Step: 10
Training loss: 0.8702511191368103
Validation loss: 1.6896045246431906

Epoch: 6| Step: 11
Training loss: 0.6836897134780884
Validation loss: 1.6978576696047218

Epoch: 6| Step: 12
Training loss: 0.8673545718193054
Validation loss: 1.6926745471133982

Epoch: 6| Step: 13
Training loss: 1.2651773691177368
Validation loss: 1.6769216829730618

Epoch: 500| Step: 0
Training loss: 0.7314810752868652
Validation loss: 1.743913572321656

Epoch: 6| Step: 1
Training loss: 0.7688019275665283
Validation loss: 1.756557337699398

Epoch: 6| Step: 2
Training loss: 0.43729010224342346
Validation loss: 1.6833553006572108

Epoch: 6| Step: 3
Training loss: 0.9061908721923828
Validation loss: 1.70932226668122

Epoch: 6| Step: 4
Training loss: 1.0789282321929932
Validation loss: 1.647506042193341

Epoch: 6| Step: 5
Training loss: 0.7080249786376953
Validation loss: 1.6937852931279007

Epoch: 6| Step: 6
Training loss: 1.0373973846435547
Validation loss: 1.7241640462670276

Epoch: 6| Step: 7
Training loss: 1.0356483459472656
Validation loss: 1.7438718811158211

Epoch: 6| Step: 8
Training loss: 1.114990234375
Validation loss: 1.7301232930152648

Epoch: 6| Step: 9
Training loss: 1.3638650178909302
Validation loss: 1.719912867392263

Epoch: 6| Step: 10
Training loss: 0.8748747110366821
Validation loss: 1.6917805402509627

Epoch: 6| Step: 11
Training loss: 1.5149378776550293
Validation loss: 1.7374220894229027

Epoch: 6| Step: 12
Training loss: 0.7054094076156616
Validation loss: 1.7701046569373018

Epoch: 6| Step: 13
Training loss: 0.7180012464523315
Validation loss: 1.6885742730991815

Epoch: 501| Step: 0
Training loss: 0.5614371299743652
Validation loss: 1.6810144807702752

Epoch: 6| Step: 1
Training loss: 0.8559147715568542
Validation loss: 1.7161507042505408

Epoch: 6| Step: 2
Training loss: 0.7236040830612183
Validation loss: 1.71492039772772

Epoch: 6| Step: 3
Training loss: 1.003448486328125
Validation loss: 1.7238736383376583

Epoch: 6| Step: 4
Training loss: 1.023435354232788
Validation loss: 1.7241886649080502

Epoch: 6| Step: 5
Training loss: 1.2238374948501587
Validation loss: 1.6955302120536886

Epoch: 6| Step: 6
Training loss: 0.6194674968719482
Validation loss: 1.7725301570789789

Epoch: 6| Step: 7
Training loss: 1.3908512592315674
Validation loss: 1.7248730877394318

Epoch: 6| Step: 8
Training loss: 0.7469353675842285
Validation loss: 1.7346428517372376

Epoch: 6| Step: 9
Training loss: 1.2342257499694824
Validation loss: 1.7305164516613047

Epoch: 6| Step: 10
Training loss: 1.5254682302474976
Validation loss: 1.7269838253657024

Epoch: 6| Step: 11
Training loss: 0.9175858497619629
Validation loss: 1.725442127514911

Epoch: 6| Step: 12
Training loss: 0.77043616771698
Validation loss: 1.7463745058223765

Epoch: 6| Step: 13
Training loss: 0.914137601852417
Validation loss: 1.7147376024594871

Epoch: 502| Step: 0
Training loss: 0.9675776958465576
Validation loss: 1.7042750837982341

Epoch: 6| Step: 1
Training loss: 1.158553957939148
Validation loss: 1.7366965150320401

Epoch: 6| Step: 2
Training loss: 0.7822901606559753
Validation loss: 1.6958159067297494

Epoch: 6| Step: 3
Training loss: 1.5112160444259644
Validation loss: 1.782496529240762

Epoch: 6| Step: 4
Training loss: 0.6322695016860962
Validation loss: 1.680320357763639

Epoch: 6| Step: 5
Training loss: 0.7658663392066956
Validation loss: 1.6370847097007177

Epoch: 6| Step: 6
Training loss: 1.2638521194458008
Validation loss: 1.7009740106521114

Epoch: 6| Step: 7
Training loss: 0.7613701820373535
Validation loss: 1.7405055107608918

Epoch: 6| Step: 8
Training loss: 0.6945313215255737
Validation loss: 1.6992568623635076

Epoch: 6| Step: 9
Training loss: 0.648966908454895
Validation loss: 1.7442207746608283

Epoch: 6| Step: 10
Training loss: 1.1421709060668945
Validation loss: 1.6456869879076559

Epoch: 6| Step: 11
Training loss: 1.3716132640838623
Validation loss: 1.6719016310989216

Epoch: 6| Step: 12
Training loss: 1.0566109418869019
Validation loss: 1.7861637235969625

Epoch: 6| Step: 13
Training loss: 0.9637647271156311
Validation loss: 1.7018396649309384

Epoch: 503| Step: 0
Training loss: 0.7586775422096252
Validation loss: 1.7120465552935036

Epoch: 6| Step: 1
Training loss: 0.8459588885307312
Validation loss: 1.7976223281634751

Epoch: 6| Step: 2
Training loss: 0.8172929286956787
Validation loss: 1.7536651524164344

Epoch: 6| Step: 3
Training loss: 0.8673093318939209
Validation loss: 1.7631782062592045

Epoch: 6| Step: 4
Training loss: 0.47461557388305664
Validation loss: 1.6830984315564554

Epoch: 6| Step: 5
Training loss: 0.7120971083641052
Validation loss: 1.7568381371036652

Epoch: 6| Step: 6
Training loss: 1.0679714679718018
Validation loss: 1.736822061641242

Epoch: 6| Step: 7
Training loss: 1.0403170585632324
Validation loss: 1.715859737447513

Epoch: 6| Step: 8
Training loss: 1.249183177947998
Validation loss: 1.753187135983539

Epoch: 6| Step: 9
Training loss: 1.199160099029541
Validation loss: 1.7397253256972118

Epoch: 6| Step: 10
Training loss: 0.8372081518173218
Validation loss: 1.724193839616673

Epoch: 6| Step: 11
Training loss: 0.858292281627655
Validation loss: 1.7434817462839105

Epoch: 6| Step: 12
Training loss: 1.2119007110595703
Validation loss: 1.7256722834802443

Epoch: 6| Step: 13
Training loss: 2.3973896503448486
Validation loss: 1.6489257556135937

Epoch: 504| Step: 0
Training loss: 0.79366135597229
Validation loss: 1.6915270423376432

Epoch: 6| Step: 1
Training loss: 1.0021964311599731
Validation loss: 1.7206994795030164

Epoch: 6| Step: 2
Training loss: 0.7766402363777161
Validation loss: 1.6802729791210544

Epoch: 6| Step: 3
Training loss: 0.835354208946228
Validation loss: 1.6921479849405185

Epoch: 6| Step: 4
Training loss: 1.818009376525879
Validation loss: 1.6894023110789638

Epoch: 6| Step: 5
Training loss: 1.267318606376648
Validation loss: 1.7310494530585505

Epoch: 6| Step: 6
Training loss: 0.8899729251861572
Validation loss: 1.6854341991486088

Epoch: 6| Step: 7
Training loss: 1.0906622409820557
Validation loss: 1.7216491481309295

Epoch: 6| Step: 8
Training loss: 1.221299409866333
Validation loss: 1.6845741092517812

Epoch: 6| Step: 9
Training loss: 0.8649181127548218
Validation loss: 1.6608977381901076

Epoch: 6| Step: 10
Training loss: 0.8338505029678345
Validation loss: 1.6931468889277468

Epoch: 6| Step: 11
Training loss: 0.7034325003623962
Validation loss: 1.6974510210816578

Epoch: 6| Step: 12
Training loss: 0.9989043474197388
Validation loss: 1.7152506100234164

Epoch: 6| Step: 13
Training loss: 0.6256246566772461
Validation loss: 1.7089784517083118

Epoch: 505| Step: 0
Training loss: 1.2506968975067139
Validation loss: 1.6587796211242676

Epoch: 6| Step: 1
Training loss: 0.9182292222976685
Validation loss: 1.6708708796449887

Epoch: 6| Step: 2
Training loss: 0.8954250812530518
Validation loss: 1.7573121363116848

Epoch: 6| Step: 3
Training loss: 0.7501083612442017
Validation loss: 1.7174153738124396

Epoch: 6| Step: 4
Training loss: 0.7306208610534668
Validation loss: 1.7504791751984627

Epoch: 6| Step: 5
Training loss: 1.2327113151550293
Validation loss: 1.7348211119251866

Epoch: 6| Step: 6
Training loss: 0.844855546951294
Validation loss: 1.7627310932323497

Epoch: 6| Step: 7
Training loss: 1.1789727210998535
Validation loss: 1.7222762287303965

Epoch: 6| Step: 8
Training loss: 1.2316670417785645
Validation loss: 1.7998260862083846

Epoch: 6| Step: 9
Training loss: 0.6269163489341736
Validation loss: 1.6863641469709334

Epoch: 6| Step: 10
Training loss: 1.5220487117767334
Validation loss: 1.6753013608276204

Epoch: 6| Step: 11
Training loss: 0.478203147649765
Validation loss: 1.7487332897801553

Epoch: 6| Step: 12
Training loss: 0.8116703033447266
Validation loss: 1.6997504003586308

Epoch: 6| Step: 13
Training loss: 1.286895513534546
Validation loss: 1.7546023040689447

Epoch: 506| Step: 0
Training loss: 0.553011417388916
Validation loss: 1.756309954068994

Epoch: 6| Step: 1
Training loss: 1.0600067377090454
Validation loss: 1.7083379196864303

Epoch: 6| Step: 2
Training loss: 1.1109776496887207
Validation loss: 1.7063283766469648

Epoch: 6| Step: 3
Training loss: 0.7808773517608643
Validation loss: 1.7093381715077225

Epoch: 6| Step: 4
Training loss: 0.9643704891204834
Validation loss: 1.7140131496614026

Epoch: 6| Step: 5
Training loss: 0.9827861785888672
Validation loss: 1.7012426827543525

Epoch: 6| Step: 6
Training loss: 0.8707894086837769
Validation loss: 1.7779595351988269

Epoch: 6| Step: 7
Training loss: 1.059451699256897
Validation loss: 1.7120014736729283

Epoch: 6| Step: 8
Training loss: 0.9569424390792847
Validation loss: 1.7508007044433265

Epoch: 6| Step: 9
Training loss: 0.6416511535644531
Validation loss: 1.7046524004269672

Epoch: 6| Step: 10
Training loss: 1.3210854530334473
Validation loss: 1.7668154726746261

Epoch: 6| Step: 11
Training loss: 0.9250290989875793
Validation loss: 1.7455355569880495

Epoch: 6| Step: 12
Training loss: 0.8994797468185425
Validation loss: 1.7354318582883446

Epoch: 6| Step: 13
Training loss: 1.448891043663025
Validation loss: 1.7081306826683782

Epoch: 507| Step: 0
Training loss: 1.2813787460327148
Validation loss: 1.764142600438928

Epoch: 6| Step: 1
Training loss: 0.7793656587600708
Validation loss: 1.673987921848092

Epoch: 6| Step: 2
Training loss: 0.8721715211868286
Validation loss: 1.7284878697446597

Epoch: 6| Step: 3
Training loss: 0.7291218042373657
Validation loss: 1.7308529141128703

Epoch: 6| Step: 4
Training loss: 1.065169334411621
Validation loss: 1.7414564522363807

Epoch: 6| Step: 5
Training loss: 1.4064781665802002
Validation loss: 1.7775739982563963

Epoch: 6| Step: 6
Training loss: 1.2165753841400146
Validation loss: 1.742752170050016

Epoch: 6| Step: 7
Training loss: 0.6009072065353394
Validation loss: 1.6662433480703702

Epoch: 6| Step: 8
Training loss: 1.0563738346099854
Validation loss: 1.7314968647495392

Epoch: 6| Step: 9
Training loss: 0.5749374628067017
Validation loss: 1.7178147915870912

Epoch: 6| Step: 10
Training loss: 1.4693894386291504
Validation loss: 1.6901885053162933

Epoch: 6| Step: 11
Training loss: 0.7908096313476562
Validation loss: 1.6835608674633888

Epoch: 6| Step: 12
Training loss: 0.7025052309036255
Validation loss: 1.7273105754647204

Epoch: 6| Step: 13
Training loss: 0.9260168075561523
Validation loss: 1.7121751000804286

Epoch: 508| Step: 0
Training loss: 0.6634392738342285
Validation loss: 1.7191072625498618

Epoch: 6| Step: 1
Training loss: 0.8514776229858398
Validation loss: 1.6417253517335462

Epoch: 6| Step: 2
Training loss: 0.8168135285377502
Validation loss: 1.7096905298130487

Epoch: 6| Step: 3
Training loss: 1.2599658966064453
Validation loss: 1.7418449642837688

Epoch: 6| Step: 4
Training loss: 0.7312303781509399
Validation loss: 1.740627295227461

Epoch: 6| Step: 5
Training loss: 0.4900321364402771
Validation loss: 1.7302529504222255

Epoch: 6| Step: 6
Training loss: 0.8827465176582336
Validation loss: 1.7555341169398317

Epoch: 6| Step: 7
Training loss: 1.3640072345733643
Validation loss: 1.8086119749212777

Epoch: 6| Step: 8
Training loss: 1.1042125225067139
Validation loss: 1.7181023756663005

Epoch: 6| Step: 9
Training loss: 1.0272139310836792
Validation loss: 1.750831679631305

Epoch: 6| Step: 10
Training loss: 0.7823760509490967
Validation loss: 1.7513933258671914

Epoch: 6| Step: 11
Training loss: 1.0875835418701172
Validation loss: 1.7732206826568933

Epoch: 6| Step: 12
Training loss: 1.6130517721176147
Validation loss: 1.7824638094953311

Epoch: 6| Step: 13
Training loss: 0.9501171112060547
Validation loss: 1.7432276894969325

Epoch: 509| Step: 0
Training loss: 1.2879366874694824
Validation loss: 1.6929640757140292

Epoch: 6| Step: 1
Training loss: 0.7996796369552612
Validation loss: 1.7253583656844271

Epoch: 6| Step: 2
Training loss: 0.8122192621231079
Validation loss: 1.7062453992905156

Epoch: 6| Step: 3
Training loss: 0.8586186170578003
Validation loss: 1.715066522680303

Epoch: 6| Step: 4
Training loss: 0.7547444701194763
Validation loss: 1.7199937989634853

Epoch: 6| Step: 5
Training loss: 1.1052178144454956
Validation loss: 1.7079658969756095

Epoch: 6| Step: 6
Training loss: 1.134817123413086
Validation loss: 1.6242948841023188

Epoch: 6| Step: 7
Training loss: 1.4200084209442139
Validation loss: 1.7401800642731369

Epoch: 6| Step: 8
Training loss: 0.8648112416267395
Validation loss: 1.7080324375501243

Epoch: 6| Step: 9
Training loss: 0.8477304577827454
Validation loss: 1.7454687818404166

Epoch: 6| Step: 10
Training loss: 0.9805347919464111
Validation loss: 1.752467166992926

Epoch: 6| Step: 11
Training loss: 0.9940613508224487
Validation loss: 1.7409036544061476

Epoch: 6| Step: 12
Training loss: 0.9071505069732666
Validation loss: 1.7491603000189668

Epoch: 6| Step: 13
Training loss: 1.1104861497879028
Validation loss: 1.723925370042042

Epoch: 510| Step: 0
Training loss: 0.8415963649749756
Validation loss: 1.7640770891661286

Epoch: 6| Step: 1
Training loss: 1.0905213356018066
Validation loss: 1.7841220273766467

Epoch: 6| Step: 2
Training loss: 1.5887622833251953
Validation loss: 1.7827959496487853

Epoch: 6| Step: 3
Training loss: 0.9520111083984375
Validation loss: 1.7608733151548652

Epoch: 6| Step: 4
Training loss: 0.9363833665847778
Validation loss: 1.7625686532707625

Epoch: 6| Step: 5
Training loss: 0.9539608955383301
Validation loss: 1.712410931946129

Epoch: 6| Step: 6
Training loss: 0.7255204319953918
Validation loss: 1.7590367101853894

Epoch: 6| Step: 7
Training loss: 0.813474178314209
Validation loss: 1.728774700113522

Epoch: 6| Step: 8
Training loss: 0.8499372005462646
Validation loss: 1.708466314500378

Epoch: 6| Step: 9
Training loss: 0.8195110559463501
Validation loss: 1.6987653163171583

Epoch: 6| Step: 10
Training loss: 1.0305801630020142
Validation loss: 1.7826878729686941

Epoch: 6| Step: 11
Training loss: 0.9454025626182556
Validation loss: 1.7465354614360358

Epoch: 6| Step: 12
Training loss: 1.1977765560150146
Validation loss: 1.7104095489748063

Epoch: 6| Step: 13
Training loss: 1.4402610063552856
Validation loss: 1.6854307689974386

Epoch: 511| Step: 0
Training loss: 1.1163837909698486
Validation loss: 1.7117373622873777

Epoch: 6| Step: 1
Training loss: 0.9369238615036011
Validation loss: 1.6683032922847296

Epoch: 6| Step: 2
Training loss: 0.8931244611740112
Validation loss: 1.759861239822962

Epoch: 6| Step: 3
Training loss: 0.709148645401001
Validation loss: 1.7627402338930356

Epoch: 6| Step: 4
Training loss: 0.8087673187255859
Validation loss: 1.693274433894824

Epoch: 6| Step: 5
Training loss: 0.841617226600647
Validation loss: 1.7333548812456028

Epoch: 6| Step: 6
Training loss: 0.9053443670272827
Validation loss: 1.665680157241001

Epoch: 6| Step: 7
Training loss: 1.086707592010498
Validation loss: 1.6734140534554758

Epoch: 6| Step: 8
Training loss: 0.7620115280151367
Validation loss: 1.671315162412582

Epoch: 6| Step: 9
Training loss: 1.1931233406066895
Validation loss: 1.7338334309157504

Epoch: 6| Step: 10
Training loss: 0.9931022524833679
Validation loss: 1.67059205168037

Epoch: 6| Step: 11
Training loss: 1.329967737197876
Validation loss: 1.6496016569035028

Epoch: 6| Step: 12
Training loss: 0.723210871219635
Validation loss: 1.7431279933580788

Epoch: 6| Step: 13
Training loss: 1.1108677387237549
Validation loss: 1.7080183670084963

Epoch: 512| Step: 0
Training loss: 0.8892794847488403
Validation loss: 1.7622755509550854

Epoch: 6| Step: 1
Training loss: 0.7015185952186584
Validation loss: 1.743003878542172

Epoch: 6| Step: 2
Training loss: 0.7252110242843628
Validation loss: 1.7056166984701668

Epoch: 6| Step: 3
Training loss: 1.1778141260147095
Validation loss: 1.7228730391430598

Epoch: 6| Step: 4
Training loss: 0.858475923538208
Validation loss: 1.727603498325553

Epoch: 6| Step: 5
Training loss: 0.9237819314002991
Validation loss: 1.7912991559633644

Epoch: 6| Step: 6
Training loss: 0.7617530822753906
Validation loss: 1.712084489483987

Epoch: 6| Step: 7
Training loss: 1.044655680656433
Validation loss: 1.7221436218548847

Epoch: 6| Step: 8
Training loss: 0.7225394248962402
Validation loss: 1.7122217006580804

Epoch: 6| Step: 9
Training loss: 1.0052927732467651
Validation loss: 1.7357855958323325

Epoch: 6| Step: 10
Training loss: 1.4770872592926025
Validation loss: 1.6990435764353762

Epoch: 6| Step: 11
Training loss: 1.1814274787902832
Validation loss: 1.6513142021753455

Epoch: 6| Step: 12
Training loss: 0.5603759288787842
Validation loss: 1.742628162907016

Epoch: 6| Step: 13
Training loss: 0.8838005065917969
Validation loss: 1.7283290278527044

Epoch: 513| Step: 0
Training loss: 0.9147509336471558
Validation loss: 1.6971702357774139

Epoch: 6| Step: 1
Training loss: 1.0475302934646606
Validation loss: 1.6856396236727316

Epoch: 6| Step: 2
Training loss: 0.8260899186134338
Validation loss: 1.7619802592903056

Epoch: 6| Step: 3
Training loss: 0.7290328145027161
Validation loss: 1.6724661806578278

Epoch: 6| Step: 4
Training loss: 0.6985377669334412
Validation loss: 1.7191714343204294

Epoch: 6| Step: 5
Training loss: 0.9292575120925903
Validation loss: 1.6901093811117194

Epoch: 6| Step: 6
Training loss: 1.284522533416748
Validation loss: 1.7003522355069396

Epoch: 6| Step: 7
Training loss: 0.843155026435852
Validation loss: 1.731968802790488

Epoch: 6| Step: 8
Training loss: 1.7572062015533447
Validation loss: 1.7122212007481565

Epoch: 6| Step: 9
Training loss: 0.9346755146980286
Validation loss: 1.7051588566072526

Epoch: 6| Step: 10
Training loss: 0.9844292998313904
Validation loss: 1.6602059410464378

Epoch: 6| Step: 11
Training loss: 0.6899447441101074
Validation loss: 1.799663387319093

Epoch: 6| Step: 12
Training loss: 0.9430394768714905
Validation loss: 1.7065523350110618

Epoch: 6| Step: 13
Training loss: 0.6792640686035156
Validation loss: 1.7196847161939066

Epoch: 514| Step: 0
Training loss: 0.6551822423934937
Validation loss: 1.6945425041260258

Epoch: 6| Step: 1
Training loss: 0.9174103140830994
Validation loss: 1.8107102519722396

Epoch: 6| Step: 2
Training loss: 0.9681341052055359
Validation loss: 1.827940006409922

Epoch: 6| Step: 3
Training loss: 0.8007501363754272
Validation loss: 1.829532866836876

Epoch: 6| Step: 4
Training loss: 1.40631103515625
Validation loss: 1.802676300848684

Epoch: 6| Step: 5
Training loss: 0.7539277076721191
Validation loss: 1.7925817646006101

Epoch: 6| Step: 6
Training loss: 0.7233954668045044
Validation loss: 1.7586062198044152

Epoch: 6| Step: 7
Training loss: 1.9771320819854736
Validation loss: 1.79598053040043

Epoch: 6| Step: 8
Training loss: 0.865048348903656
Validation loss: 1.687647097854204

Epoch: 6| Step: 9
Training loss: 1.5135178565979004
Validation loss: 1.7260694067965272

Epoch: 6| Step: 10
Training loss: 0.7080134749412537
Validation loss: 1.7248210958255235

Epoch: 6| Step: 11
Training loss: 0.4985415041446686
Validation loss: 1.6539117277309459

Epoch: 6| Step: 12
Training loss: 0.8575690984725952
Validation loss: 1.7349134299062914

Epoch: 6| Step: 13
Training loss: 1.0110880136489868
Validation loss: 1.7045852907242314

Epoch: 515| Step: 0
Training loss: 0.6264733076095581
Validation loss: 1.7100536669454267

Epoch: 6| Step: 1
Training loss: 0.6884257793426514
Validation loss: 1.6691832978238341

Epoch: 6| Step: 2
Training loss: 0.9272935390472412
Validation loss: 1.6986919269766858

Epoch: 6| Step: 3
Training loss: 0.8549699783325195
Validation loss: 1.7066535962525236

Epoch: 6| Step: 4
Training loss: 0.7973254323005676
Validation loss: 1.6931211461303055

Epoch: 6| Step: 5
Training loss: 1.2816812992095947
Validation loss: 1.6673949790257279

Epoch: 6| Step: 6
Training loss: 1.352006435394287
Validation loss: 1.7025890337523593

Epoch: 6| Step: 7
Training loss: 0.9227728843688965
Validation loss: 1.7438386729968491

Epoch: 6| Step: 8
Training loss: 0.8428948521614075
Validation loss: 1.6445802450180054

Epoch: 6| Step: 9
Training loss: 0.8941227793693542
Validation loss: 1.653213885522658

Epoch: 6| Step: 10
Training loss: 0.6955469846725464
Validation loss: 1.6998180676532049

Epoch: 6| Step: 11
Training loss: 0.5530630350112915
Validation loss: 1.6732525774227676

Epoch: 6| Step: 12
Training loss: 1.486079454421997
Validation loss: 1.6741714092992968

Epoch: 6| Step: 13
Training loss: 1.4736056327819824
Validation loss: 1.7139859276433145

Epoch: 516| Step: 0
Training loss: 1.1694492101669312
Validation loss: 1.7702038621389737

Epoch: 6| Step: 1
Training loss: 1.0874292850494385
Validation loss: 1.700504033796249

Epoch: 6| Step: 2
Training loss: 0.7999234199523926
Validation loss: 1.7772254661847187

Epoch: 6| Step: 3
Training loss: 0.9116829633712769
Validation loss: 1.743947567478303

Epoch: 6| Step: 4
Training loss: 1.6615744829177856
Validation loss: 1.7597948863942137

Epoch: 6| Step: 5
Training loss: 0.6681641340255737
Validation loss: 1.753243633495864

Epoch: 6| Step: 6
Training loss: 0.7673389911651611
Validation loss: 1.75144935295146

Epoch: 6| Step: 7
Training loss: 1.2415093183517456
Validation loss: 1.6698163709332865

Epoch: 6| Step: 8
Training loss: 0.636961817741394
Validation loss: 1.7031467563362532

Epoch: 6| Step: 9
Training loss: 1.0275084972381592
Validation loss: 1.6896502830648934

Epoch: 6| Step: 10
Training loss: 0.6959471106529236
Validation loss: 1.7053565286820935

Epoch: 6| Step: 11
Training loss: 0.6810413599014282
Validation loss: 1.6762794012664466

Epoch: 6| Step: 12
Training loss: 0.5615162253379822
Validation loss: 1.663768752928703

Epoch: 6| Step: 13
Training loss: 1.40255606174469
Validation loss: 1.7433623216485465

Epoch: 517| Step: 0
Training loss: 0.9765615463256836
Validation loss: 1.711617672315208

Epoch: 6| Step: 1
Training loss: 0.8418095111846924
Validation loss: 1.6998082707005162

Epoch: 6| Step: 2
Training loss: 1.4489811658859253
Validation loss: 1.7235152131767684

Epoch: 6| Step: 3
Training loss: 0.9921980500221252
Validation loss: 1.7332761108234365

Epoch: 6| Step: 4
Training loss: 0.9048581719398499
Validation loss: 1.6609094694096556

Epoch: 6| Step: 5
Training loss: 0.8395469188690186
Validation loss: 1.7317128694185646

Epoch: 6| Step: 6
Training loss: 0.4265058636665344
Validation loss: 1.7689423061186267

Epoch: 6| Step: 7
Training loss: 1.0207237005233765
Validation loss: 1.6744655460439704

Epoch: 6| Step: 8
Training loss: 0.931692361831665
Validation loss: 1.6643850880284463

Epoch: 6| Step: 9
Training loss: 1.262657880783081
Validation loss: 1.6856579678032988

Epoch: 6| Step: 10
Training loss: 1.4082012176513672
Validation loss: 1.644362675246372

Epoch: 6| Step: 11
Training loss: 0.8282300233840942
Validation loss: 1.6681083133143764

Epoch: 6| Step: 12
Training loss: 0.7502171993255615
Validation loss: 1.8387063985229821

Epoch: 6| Step: 13
Training loss: 1.1267136335372925
Validation loss: 1.6827243066603137

Epoch: 518| Step: 0
Training loss: 0.980623722076416
Validation loss: 1.7640123533946213

Epoch: 6| Step: 1
Training loss: 0.748367190361023
Validation loss: 1.736933905591247

Epoch: 6| Step: 2
Training loss: 0.7646995782852173
Validation loss: 1.6838403581291117

Epoch: 6| Step: 3
Training loss: 0.8579280376434326
Validation loss: 1.7372465056757773

Epoch: 6| Step: 4
Training loss: 0.6820419430732727
Validation loss: 1.7124343610578967

Epoch: 6| Step: 5
Training loss: 0.7409564256668091
Validation loss: 1.7452144545893515

Epoch: 6| Step: 6
Training loss: 0.7876672148704529
Validation loss: 1.7335107723871868

Epoch: 6| Step: 7
Training loss: 0.8791475892066956
Validation loss: 1.7066488650537306

Epoch: 6| Step: 8
Training loss: 1.1925110816955566
Validation loss: 1.7219475956373318

Epoch: 6| Step: 9
Training loss: 1.1444768905639648
Validation loss: 1.7378335306721349

Epoch: 6| Step: 10
Training loss: 1.4826308488845825
Validation loss: 1.7021018913997117

Epoch: 6| Step: 11
Training loss: 0.6777262687683105
Validation loss: 1.7750096962016115

Epoch: 6| Step: 12
Training loss: 1.5241488218307495
Validation loss: 1.7173185938148088

Epoch: 6| Step: 13
Training loss: 0.5675929188728333
Validation loss: 1.7459801884107693

Epoch: 519| Step: 0
Training loss: 0.9364246129989624
Validation loss: 1.6753610846816853

Epoch: 6| Step: 1
Training loss: 0.7832040786743164
Validation loss: 1.6957008229788912

Epoch: 6| Step: 2
Training loss: 1.1024448871612549
Validation loss: 1.6485454664435437

Epoch: 6| Step: 3
Training loss: 0.6515257358551025
Validation loss: 1.7380300567996116

Epoch: 6| Step: 4
Training loss: 1.0608069896697998
Validation loss: 1.7063957593774284

Epoch: 6| Step: 5
Training loss: 0.8161352276802063
Validation loss: 1.6885248678986744

Epoch: 6| Step: 6
Training loss: 1.0964683294296265
Validation loss: 1.725752334440908

Epoch: 6| Step: 7
Training loss: 0.902605414390564
Validation loss: 1.6727279796395251

Epoch: 6| Step: 8
Training loss: 0.7039963006973267
Validation loss: 1.6977632763565227

Epoch: 6| Step: 9
Training loss: 1.229520559310913
Validation loss: 1.7218738371326077

Epoch: 6| Step: 10
Training loss: 1.1342748403549194
Validation loss: 1.6613133312553487

Epoch: 6| Step: 11
Training loss: 1.2500088214874268
Validation loss: 1.6892535583947295

Epoch: 6| Step: 12
Training loss: 0.7881221175193787
Validation loss: 1.7249591991465578

Epoch: 6| Step: 13
Training loss: 0.9943422675132751
Validation loss: 1.7047061074164607

Epoch: 520| Step: 0
Training loss: 0.6657537817955017
Validation loss: 1.6833783170228362

Epoch: 6| Step: 1
Training loss: 0.7396601438522339
Validation loss: 1.6777676574645504

Epoch: 6| Step: 2
Training loss: 0.6883325576782227
Validation loss: 1.676043927028615

Epoch: 6| Step: 3
Training loss: 1.1341302394866943
Validation loss: 1.663975102927095

Epoch: 6| Step: 4
Training loss: 0.6307170987129211
Validation loss: 1.6984995513833978

Epoch: 6| Step: 5
Training loss: 1.1711369752883911
Validation loss: 1.6633953355973767

Epoch: 6| Step: 6
Training loss: 1.4522193670272827
Validation loss: 1.750602529894921

Epoch: 6| Step: 7
Training loss: 0.7192721366882324
Validation loss: 1.6745942856675835

Epoch: 6| Step: 8
Training loss: 0.9888791441917419
Validation loss: 1.6703725425145959

Epoch: 6| Step: 9
Training loss: 0.657805860042572
Validation loss: 1.6259021336032498

Epoch: 6| Step: 10
Training loss: 0.9578391313552856
Validation loss: 1.677286199985012

Epoch: 6| Step: 11
Training loss: 0.682042121887207
Validation loss: 1.7058376855747674

Epoch: 6| Step: 12
Training loss: 1.3466839790344238
Validation loss: 1.7235215312691146

Epoch: 6| Step: 13
Training loss: 0.8448716998100281
Validation loss: 1.7172143946411789

Epoch: 521| Step: 0
Training loss: 0.7043105363845825
Validation loss: 1.7054143374966038

Epoch: 6| Step: 1
Training loss: 1.248396873474121
Validation loss: 1.6948695298164123

Epoch: 6| Step: 2
Training loss: 0.9826140403747559
Validation loss: 1.6758242678898636

Epoch: 6| Step: 3
Training loss: 0.8943976163864136
Validation loss: 1.719481437436996

Epoch: 6| Step: 4
Training loss: 1.3117114305496216
Validation loss: 1.6472665968761648

Epoch: 6| Step: 5
Training loss: 0.857707142829895
Validation loss: 1.7377005597596527

Epoch: 6| Step: 6
Training loss: 1.2957606315612793
Validation loss: 1.7455035255801292

Epoch: 6| Step: 7
Training loss: 0.9240489602088928
Validation loss: 1.6296489713012532

Epoch: 6| Step: 8
Training loss: 0.4796846807003021
Validation loss: 1.7197900433694162

Epoch: 6| Step: 9
Training loss: 0.6579782962799072
Validation loss: 1.69924093702788

Epoch: 6| Step: 10
Training loss: 0.731859564781189
Validation loss: 1.7972058596149567

Epoch: 6| Step: 11
Training loss: 0.6091690063476562
Validation loss: 1.762078821018178

Epoch: 6| Step: 12
Training loss: 1.4022330045700073
Validation loss: 1.6963061683921403

Epoch: 6| Step: 13
Training loss: 0.813863217830658
Validation loss: 1.7066578557414394

Epoch: 522| Step: 0
Training loss: 1.172635555267334
Validation loss: 1.6721543688927927

Epoch: 6| Step: 1
Training loss: 0.8732789754867554
Validation loss: 1.6591922531845749

Epoch: 6| Step: 2
Training loss: 0.842595100402832
Validation loss: 1.624189567822282

Epoch: 6| Step: 3
Training loss: 1.1595146656036377
Validation loss: 1.6706668407686296

Epoch: 6| Step: 4
Training loss: 0.8953009247779846
Validation loss: 1.694281324263542

Epoch: 6| Step: 5
Training loss: 0.9985350370407104
Validation loss: 1.6811883090644755

Epoch: 6| Step: 6
Training loss: 1.0711696147918701
Validation loss: 1.6359151954291968

Epoch: 6| Step: 7
Training loss: 1.0718088150024414
Validation loss: 1.6901259627393497

Epoch: 6| Step: 8
Training loss: 0.8361347913742065
Validation loss: 1.6833263340816702

Epoch: 6| Step: 9
Training loss: 0.7652971148490906
Validation loss: 1.6715852778445008

Epoch: 6| Step: 10
Training loss: 0.6215780973434448
Validation loss: 1.7650840564440655

Epoch: 6| Step: 11
Training loss: 1.178128957748413
Validation loss: 1.6771484600600375

Epoch: 6| Step: 12
Training loss: 0.9688133001327515
Validation loss: 1.7547189484360397

Epoch: 6| Step: 13
Training loss: 0.7895007729530334
Validation loss: 1.697849812046174

Epoch: 523| Step: 0
Training loss: 0.856833815574646
Validation loss: 1.7288061354749946

Epoch: 6| Step: 1
Training loss: 1.0503530502319336
Validation loss: 1.7132292703915668

Epoch: 6| Step: 2
Training loss: 0.9605362415313721
Validation loss: 1.6755460692990212

Epoch: 6| Step: 3
Training loss: 1.1009435653686523
Validation loss: 1.7149608981224798

Epoch: 6| Step: 4
Training loss: 0.8225468397140503
Validation loss: 1.6990865289524038

Epoch: 6| Step: 5
Training loss: 0.8435376882553101
Validation loss: 1.629228017663443

Epoch: 6| Step: 6
Training loss: 1.2639163732528687
Validation loss: 1.6895872239143617

Epoch: 6| Step: 7
Training loss: 1.2361520528793335
Validation loss: 1.6807975948497813

Epoch: 6| Step: 8
Training loss: 0.5189928412437439
Validation loss: 1.687129407800654

Epoch: 6| Step: 9
Training loss: 0.5139833092689514
Validation loss: 1.6861240145980672

Epoch: 6| Step: 10
Training loss: 1.0463886260986328
Validation loss: 1.665637429042529

Epoch: 6| Step: 11
Training loss: 1.1501667499542236
Validation loss: 1.7181096974239554

Epoch: 6| Step: 12
Training loss: 0.49453556537628174
Validation loss: 1.7381744589856876

Epoch: 6| Step: 13
Training loss: 0.7615094780921936
Validation loss: 1.676229202619163

Epoch: 524| Step: 0
Training loss: 0.9502943158149719
Validation loss: 1.6821364715535154

Epoch: 6| Step: 1
Training loss: 1.2159230709075928
Validation loss: 1.7450023171722249

Epoch: 6| Step: 2
Training loss: 0.6727256178855896
Validation loss: 1.6672438524102653

Epoch: 6| Step: 3
Training loss: 1.0184834003448486
Validation loss: 1.6576516487265145

Epoch: 6| Step: 4
Training loss: 0.9824569225311279
Validation loss: 1.657960263631677

Epoch: 6| Step: 5
Training loss: 0.9320603609085083
Validation loss: 1.686861721418237

Epoch: 6| Step: 6
Training loss: 0.7433857917785645
Validation loss: 1.7197690932981429

Epoch: 6| Step: 7
Training loss: 1.0076467990875244
Validation loss: 1.6892926000779676

Epoch: 6| Step: 8
Training loss: 0.6309664845466614
Validation loss: 1.7174274485598329

Epoch: 6| Step: 9
Training loss: 0.5412954688072205
Validation loss: 1.712802472934928

Epoch: 6| Step: 10
Training loss: 1.0777838230133057
Validation loss: 1.6691402991612752

Epoch: 6| Step: 11
Training loss: 1.0903626680374146
Validation loss: 1.6943338853056713

Epoch: 6| Step: 12
Training loss: 0.9896392226219177
Validation loss: 1.6869438937915269

Epoch: 6| Step: 13
Training loss: 1.0646699666976929
Validation loss: 1.7070364593177714

Epoch: 525| Step: 0
Training loss: 0.5180493593215942
Validation loss: 1.6545748390177244

Epoch: 6| Step: 1
Training loss: 1.0356289148330688
Validation loss: 1.6700183306970904

Epoch: 6| Step: 2
Training loss: 1.006632924079895
Validation loss: 1.6405906574700468

Epoch: 6| Step: 3
Training loss: 0.7524222135543823
Validation loss: 1.6986116875884354

Epoch: 6| Step: 4
Training loss: 1.0619726181030273
Validation loss: 1.6793651824356408

Epoch: 6| Step: 5
Training loss: 0.7374349236488342
Validation loss: 1.6419001715157622

Epoch: 6| Step: 6
Training loss: 0.8831536769866943
Validation loss: 1.6761158973939958

Epoch: 6| Step: 7
Training loss: 0.8666892051696777
Validation loss: 1.6412002219948718

Epoch: 6| Step: 8
Training loss: 1.203531265258789
Validation loss: 1.6902071801565026

Epoch: 6| Step: 9
Training loss: 0.9447988867759705
Validation loss: 1.6611881320194533

Epoch: 6| Step: 10
Training loss: 1.3491601943969727
Validation loss: 1.6756968600775606

Epoch: 6| Step: 11
Training loss: 0.5584267377853394
Validation loss: 1.7627165932809152

Epoch: 6| Step: 12
Training loss: 0.8298574686050415
Validation loss: 1.7069603461091236

Epoch: 6| Step: 13
Training loss: 0.3202638328075409
Validation loss: 1.7578778292543145

Epoch: 526| Step: 0
Training loss: 1.2331489324569702
Validation loss: 1.6740640581295054

Epoch: 6| Step: 1
Training loss: 0.7988916039466858
Validation loss: 1.698586117836737

Epoch: 6| Step: 2
Training loss: 0.8877286911010742
Validation loss: 1.6963346183940928

Epoch: 6| Step: 3
Training loss: 0.9281805157661438
Validation loss: 1.6691189978712349

Epoch: 6| Step: 4
Training loss: 1.0727384090423584
Validation loss: 1.7337734519794423

Epoch: 6| Step: 5
Training loss: 1.4007798433303833
Validation loss: 1.7906416077767648

Epoch: 6| Step: 6
Training loss: 0.8280971050262451
Validation loss: 1.5888426419227355

Epoch: 6| Step: 7
Training loss: 0.5963045358657837
Validation loss: 1.7059174596622426

Epoch: 6| Step: 8
Training loss: 0.880237340927124
Validation loss: 1.6988989435216433

Epoch: 6| Step: 9
Training loss: 0.865989625453949
Validation loss: 1.6968757875504032

Epoch: 6| Step: 10
Training loss: 0.7266490459442139
Validation loss: 1.7309808756715508

Epoch: 6| Step: 11
Training loss: 1.140708088874817
Validation loss: 1.7313838389612013

Epoch: 6| Step: 12
Training loss: 0.92891526222229
Validation loss: 1.6668229359452442

Epoch: 6| Step: 13
Training loss: 0.9257782697677612
Validation loss: 1.6880045283225276

Epoch: 527| Step: 0
Training loss: 0.6255748271942139
Validation loss: 1.632698953792613

Epoch: 6| Step: 1
Training loss: 1.2621254920959473
Validation loss: 1.682272175306915

Epoch: 6| Step: 2
Training loss: 0.8076559901237488
Validation loss: 1.6868915878316408

Epoch: 6| Step: 3
Training loss: 0.5479102730751038
Validation loss: 1.7099694257141442

Epoch: 6| Step: 4
Training loss: 0.5104149580001831
Validation loss: 1.6598378445512505

Epoch: 6| Step: 5
Training loss: 1.1356197595596313
Validation loss: 1.6667308653554609

Epoch: 6| Step: 6
Training loss: 0.6164365410804749
Validation loss: 1.7196706776977868

Epoch: 6| Step: 7
Training loss: 1.6062461137771606
Validation loss: 1.7324913727339877

Epoch: 6| Step: 8
Training loss: 1.272675633430481
Validation loss: 1.7362636238016107

Epoch: 6| Step: 9
Training loss: 0.7224357724189758
Validation loss: 1.7463341848824614

Epoch: 6| Step: 10
Training loss: 0.799210250377655
Validation loss: 1.675581879513238

Epoch: 6| Step: 11
Training loss: 0.9369341135025024
Validation loss: 1.731412245381263

Epoch: 6| Step: 12
Training loss: 1.1737525463104248
Validation loss: 1.6892239573181316

Epoch: 6| Step: 13
Training loss: 0.5202531814575195
Validation loss: 1.7068374592770812

Epoch: 528| Step: 0
Training loss: 1.0955106019973755
Validation loss: 1.609853124105802

Epoch: 6| Step: 1
Training loss: 1.4306025505065918
Validation loss: 1.724845297874943

Epoch: 6| Step: 2
Training loss: 0.7917027473449707
Validation loss: 1.6422015082451604

Epoch: 6| Step: 3
Training loss: 0.9046364426612854
Validation loss: 1.6070389401528142

Epoch: 6| Step: 4
Training loss: 0.5854811668395996
Validation loss: 1.673501378746443

Epoch: 6| Step: 5
Training loss: 0.9060769081115723
Validation loss: 1.7204661061686854

Epoch: 6| Step: 6
Training loss: 1.0203959941864014
Validation loss: 1.6933528018254105

Epoch: 6| Step: 7
Training loss: 1.339065670967102
Validation loss: 1.6709689517174997

Epoch: 6| Step: 8
Training loss: 0.842353880405426
Validation loss: 1.641635497411092

Epoch: 6| Step: 9
Training loss: 0.9162064790725708
Validation loss: 1.648905683589238

Epoch: 6| Step: 10
Training loss: 0.6895201206207275
Validation loss: 1.71487029393514

Epoch: 6| Step: 11
Training loss: 0.8214066028594971
Validation loss: 1.699873028262969

Epoch: 6| Step: 12
Training loss: 0.7706797122955322
Validation loss: 1.6776661962591193

Epoch: 6| Step: 13
Training loss: 1.3573213815689087
Validation loss: 1.6584876070740402

Epoch: 529| Step: 0
Training loss: 0.39560502767562866
Validation loss: 1.669752796490987

Epoch: 6| Step: 1
Training loss: 0.9459793567657471
Validation loss: 1.652286273176952

Epoch: 6| Step: 2
Training loss: 0.9436571002006531
Validation loss: 1.6843227801784393

Epoch: 6| Step: 3
Training loss: 0.9511229991912842
Validation loss: 1.6858418641551849

Epoch: 6| Step: 4
Training loss: 1.1759756803512573
Validation loss: 1.6456936444005659

Epoch: 6| Step: 5
Training loss: 1.010981798171997
Validation loss: 1.7186927231409217

Epoch: 6| Step: 6
Training loss: 0.9067474603652954
Validation loss: 1.706717662913825

Epoch: 6| Step: 7
Training loss: 0.9884387850761414
Validation loss: 1.7008992677093835

Epoch: 6| Step: 8
Training loss: 1.0946372747421265
Validation loss: 1.7126877948802004

Epoch: 6| Step: 9
Training loss: 0.7816677093505859
Validation loss: 1.7461339683942898

Epoch: 6| Step: 10
Training loss: 0.8280742168426514
Validation loss: 1.6257207932010773

Epoch: 6| Step: 11
Training loss: 0.8015439510345459
Validation loss: 1.7560679502384637

Epoch: 6| Step: 12
Training loss: 1.372915267944336
Validation loss: 1.6891175316226097

Epoch: 6| Step: 13
Training loss: 0.44478777050971985
Validation loss: 1.6585010443964312

Epoch: 530| Step: 0
Training loss: 1.095149278640747
Validation loss: 1.720067428004357

Epoch: 6| Step: 1
Training loss: 0.7915537357330322
Validation loss: 1.670473103882164

Epoch: 6| Step: 2
Training loss: 1.3727271556854248
Validation loss: 1.7552669176491358

Epoch: 6| Step: 3
Training loss: 0.9091833829879761
Validation loss: 1.7436802938420286

Epoch: 6| Step: 4
Training loss: 0.6894465684890747
Validation loss: 1.7695822356849589

Epoch: 6| Step: 5
Training loss: 1.385572075843811
Validation loss: 1.6447921074846739

Epoch: 6| Step: 6
Training loss: 0.8611761331558228
Validation loss: 1.7039460443681287

Epoch: 6| Step: 7
Training loss: 1.2421334981918335
Validation loss: 1.6865359519117622

Epoch: 6| Step: 8
Training loss: 0.7093854546546936
Validation loss: 1.6696610348199004

Epoch: 6| Step: 9
Training loss: 0.9114445447921753
Validation loss: 1.6807664453342397

Epoch: 6| Step: 10
Training loss: 0.713605523109436
Validation loss: 1.640957579817823

Epoch: 6| Step: 11
Training loss: 0.5584202408790588
Validation loss: 1.7421221348547167

Epoch: 6| Step: 12
Training loss: 0.7878835201263428
Validation loss: 1.6603819170305807

Epoch: 6| Step: 13
Training loss: 0.7899501323699951
Validation loss: 1.7227746363609069

Epoch: 531| Step: 0
Training loss: 0.744295060634613
Validation loss: 1.6719466537557623

Epoch: 6| Step: 1
Training loss: 1.1111940145492554
Validation loss: 1.7215493263736847

Epoch: 6| Step: 2
Training loss: 0.5289681553840637
Validation loss: 1.717681234882724

Epoch: 6| Step: 3
Training loss: 0.6046684980392456
Validation loss: 1.7086878822695823

Epoch: 6| Step: 4
Training loss: 0.4789312481880188
Validation loss: 1.7335196720656527

Epoch: 6| Step: 5
Training loss: 0.7336770296096802
Validation loss: 1.665329904966457

Epoch: 6| Step: 6
Training loss: 1.074632167816162
Validation loss: 1.675521319912326

Epoch: 6| Step: 7
Training loss: 0.8636499047279358
Validation loss: 1.7036950139589206

Epoch: 6| Step: 8
Training loss: 1.6006137132644653
Validation loss: 1.6699295338763986

Epoch: 6| Step: 9
Training loss: 1.2433412075042725
Validation loss: 1.687170846487886

Epoch: 6| Step: 10
Training loss: 0.8182308077812195
Validation loss: 1.7384747228314799

Epoch: 6| Step: 11
Training loss: 0.56854248046875
Validation loss: 1.6479292877258793

Epoch: 6| Step: 12
Training loss: 0.7617753744125366
Validation loss: 1.6607335408528645

Epoch: 6| Step: 13
Training loss: 0.999230146408081
Validation loss: 1.6691333388769498

Epoch: 532| Step: 0
Training loss: 0.44361618161201477
Validation loss: 1.6332155119988225

Epoch: 6| Step: 1
Training loss: 1.170365571975708
Validation loss: 1.6231043672048917

Epoch: 6| Step: 2
Training loss: 0.8509858250617981
Validation loss: 1.6765430345330188

Epoch: 6| Step: 3
Training loss: 0.6434333324432373
Validation loss: 1.7277179764163109

Epoch: 6| Step: 4
Training loss: 1.125989556312561
Validation loss: 1.6675953659960019

Epoch: 6| Step: 5
Training loss: 0.7384887337684631
Validation loss: 1.7004319275579145

Epoch: 6| Step: 6
Training loss: 1.3205071687698364
Validation loss: 1.6269824094669794

Epoch: 6| Step: 7
Training loss: 0.6591416001319885
Validation loss: 1.71008446011492

Epoch: 6| Step: 8
Training loss: 1.1225810050964355
Validation loss: 1.6162834513571955

Epoch: 6| Step: 9
Training loss: 1.0910357236862183
Validation loss: 1.639964254953528

Epoch: 6| Step: 10
Training loss: 0.8466842174530029
Validation loss: 1.7098416128466207

Epoch: 6| Step: 11
Training loss: 1.0690215826034546
Validation loss: 1.7039064899567635

Epoch: 6| Step: 12
Training loss: 0.7644086480140686
Validation loss: 1.6778576630418018

Epoch: 6| Step: 13
Training loss: 0.4662061333656311
Validation loss: 1.6295513030021422

Epoch: 533| Step: 0
Training loss: 1.5632669925689697
Validation loss: 1.7076847732708018

Epoch: 6| Step: 1
Training loss: 0.9271028637886047
Validation loss: 1.6046248020664338

Epoch: 6| Step: 2
Training loss: 0.9005300998687744
Validation loss: 1.6601303418477376

Epoch: 6| Step: 3
Training loss: 1.2609246969223022
Validation loss: 1.669869448549004

Epoch: 6| Step: 4
Training loss: 0.747989296913147
Validation loss: 1.7237954665255804

Epoch: 6| Step: 5
Training loss: 1.1147429943084717
Validation loss: 1.664501533713392

Epoch: 6| Step: 6
Training loss: 1.0773581266403198
Validation loss: 1.680284523194836

Epoch: 6| Step: 7
Training loss: 0.8021466732025146
Validation loss: 1.684103141548813

Epoch: 6| Step: 8
Training loss: 0.6079225540161133
Validation loss: 1.676155754314956

Epoch: 6| Step: 9
Training loss: 0.5903003811836243
Validation loss: 1.6600913450282107

Epoch: 6| Step: 10
Training loss: 0.598293662071228
Validation loss: 1.7051329933187014

Epoch: 6| Step: 11
Training loss: 0.720081627368927
Validation loss: 1.68151766766784

Epoch: 6| Step: 12
Training loss: 0.8269387483596802
Validation loss: 1.6727129964418308

Epoch: 6| Step: 13
Training loss: 1.1168386936187744
Validation loss: 1.6313579569580734

Epoch: 534| Step: 0
Training loss: 0.8751661777496338
Validation loss: 1.7578232429360832

Epoch: 6| Step: 1
Training loss: 0.7143964767456055
Validation loss: 1.7531565312416322

Epoch: 6| Step: 2
Training loss: 0.6901403665542603
Validation loss: 1.7133813775995725

Epoch: 6| Step: 3
Training loss: 0.7894368171691895
Validation loss: 1.651337928669427

Epoch: 6| Step: 4
Training loss: 0.6835386753082275
Validation loss: 1.70664749094235

Epoch: 6| Step: 5
Training loss: 0.9546265602111816
Validation loss: 1.625057037158679

Epoch: 6| Step: 6
Training loss: 0.992621898651123
Validation loss: 1.6617451585749143

Epoch: 6| Step: 7
Training loss: 0.7455514073371887
Validation loss: 1.756066196708269

Epoch: 6| Step: 8
Training loss: 1.1768251657485962
Validation loss: 1.706433790986256

Epoch: 6| Step: 9
Training loss: 1.0185256004333496
Validation loss: 1.6245516269437728

Epoch: 6| Step: 10
Training loss: 1.3044493198394775
Validation loss: 1.5943892143105949

Epoch: 6| Step: 11
Training loss: 0.7155215740203857
Validation loss: 1.6294157735763057

Epoch: 6| Step: 12
Training loss: 1.0869871377944946
Validation loss: 1.7456430645399197

Epoch: 6| Step: 13
Training loss: 1.5001511573791504
Validation loss: 1.6951580380880704

Epoch: 535| Step: 0
Training loss: 0.8353678584098816
Validation loss: 1.6667644798114736

Epoch: 6| Step: 1
Training loss: 1.0038394927978516
Validation loss: 1.647663054927703

Epoch: 6| Step: 2
Training loss: 0.914193868637085
Validation loss: 1.6943310960646598

Epoch: 6| Step: 3
Training loss: 0.6391898393630981
Validation loss: 1.6944818342885664

Epoch: 6| Step: 4
Training loss: 0.8454645276069641
Validation loss: 1.6973347548515565

Epoch: 6| Step: 5
Training loss: 0.8431615829467773
Validation loss: 1.7144776569899691

Epoch: 6| Step: 6
Training loss: 0.9505894184112549
Validation loss: 1.717438805487848

Epoch: 6| Step: 7
Training loss: 1.3441189527511597
Validation loss: 1.6916892797716203

Epoch: 6| Step: 8
Training loss: 0.7024632692337036
Validation loss: 1.8008941937518377

Epoch: 6| Step: 9
Training loss: 0.7191095948219299
Validation loss: 1.630852327551893

Epoch: 6| Step: 10
Training loss: 0.8188122510910034
Validation loss: 1.7200372321631319

Epoch: 6| Step: 11
Training loss: 1.0252234935760498
Validation loss: 1.7399447489810247

Epoch: 6| Step: 12
Training loss: 1.3319604396820068
Validation loss: 1.676569636150073

Epoch: 6| Step: 13
Training loss: 1.188151478767395
Validation loss: 1.7014116805086854

Epoch: 536| Step: 0
Training loss: 1.0011181831359863
Validation loss: 1.6194517125365555

Epoch: 6| Step: 1
Training loss: 0.7253627181053162
Validation loss: 1.779754279762186

Epoch: 6| Step: 2
Training loss: 0.9171863794326782
Validation loss: 1.671147572096958

Epoch: 6| Step: 3
Training loss: 0.9304022789001465
Validation loss: 1.627860289747997

Epoch: 6| Step: 4
Training loss: 1.4348037242889404
Validation loss: 1.6668663486357658

Epoch: 6| Step: 5
Training loss: 0.9329901933670044
Validation loss: 1.6620185541850265

Epoch: 6| Step: 6
Training loss: 1.209995150566101
Validation loss: 1.7181695674055366

Epoch: 6| Step: 7
Training loss: 0.695556104183197
Validation loss: 1.6725380048956922

Epoch: 6| Step: 8
Training loss: 0.4717724323272705
Validation loss: 1.6989042502577587

Epoch: 6| Step: 9
Training loss: 0.7074061036109924
Validation loss: 1.6586190962022351

Epoch: 6| Step: 10
Training loss: 1.2847068309783936
Validation loss: 1.6389404150747484

Epoch: 6| Step: 11
Training loss: 0.5890561938285828
Validation loss: 1.6070007867710565

Epoch: 6| Step: 12
Training loss: 1.2780393362045288
Validation loss: 1.6699784750579505

Epoch: 6| Step: 13
Training loss: 1.004873275756836
Validation loss: 1.6854096420349614

Epoch: 537| Step: 0
Training loss: 0.6752643585205078
Validation loss: 1.6789764306878532

Epoch: 6| Step: 1
Training loss: 0.71577388048172
Validation loss: 1.694447103367057

Epoch: 6| Step: 2
Training loss: 1.1647660732269287
Validation loss: 1.7320690308847735

Epoch: 6| Step: 3
Training loss: 1.2804903984069824
Validation loss: 1.7117598966885639

Epoch: 6| Step: 4
Training loss: 0.78645920753479
Validation loss: 1.7084094016782698

Epoch: 6| Step: 5
Training loss: 0.6871100068092346
Validation loss: 1.702302130319739

Epoch: 6| Step: 6
Training loss: 1.1149916648864746
Validation loss: 1.7275530510051276

Epoch: 6| Step: 7
Training loss: 1.0316894054412842
Validation loss: 1.6849345673796952

Epoch: 6| Step: 8
Training loss: 1.4098643064498901
Validation loss: 1.7387107085156184

Epoch: 6| Step: 9
Training loss: 1.1188061237335205
Validation loss: 1.728186918843177

Epoch: 6| Step: 10
Training loss: 0.5394949913024902
Validation loss: 1.7069562032658567

Epoch: 6| Step: 11
Training loss: 0.7694885730743408
Validation loss: 1.7314632413207844

Epoch: 6| Step: 12
Training loss: 0.7135428190231323
Validation loss: 1.6831220349957865

Epoch: 6| Step: 13
Training loss: 0.6675514578819275
Validation loss: 1.7171625296274822

Epoch: 538| Step: 0
Training loss: 1.1703300476074219
Validation loss: 1.6709600392208304

Epoch: 6| Step: 1
Training loss: 0.8531613349914551
Validation loss: 1.667342552574732

Epoch: 6| Step: 2
Training loss: 0.7436847686767578
Validation loss: 1.653165933906391

Epoch: 6| Step: 3
Training loss: 0.3042925000190735
Validation loss: 1.6962286695357291

Epoch: 6| Step: 4
Training loss: 0.976683497428894
Validation loss: 1.7136320324354275

Epoch: 6| Step: 5
Training loss: 0.7990951538085938
Validation loss: 1.7081584212600545

Epoch: 6| Step: 6
Training loss: 1.1535112857818604
Validation loss: 1.6397224754415534

Epoch: 6| Step: 7
Training loss: 1.2725565433502197
Validation loss: 1.660886965772157

Epoch: 6| Step: 8
Training loss: 0.6697890162467957
Validation loss: 1.746780542917149

Epoch: 6| Step: 9
Training loss: 0.5476328134536743
Validation loss: 1.6552943516803045

Epoch: 6| Step: 10
Training loss: 1.1032540798187256
Validation loss: 1.6357868615017142

Epoch: 6| Step: 11
Training loss: 1.1674855947494507
Validation loss: 1.667372457442745

Epoch: 6| Step: 12
Training loss: 1.0295233726501465
Validation loss: 1.6986533826397312

Epoch: 6| Step: 13
Training loss: 0.5316963195800781
Validation loss: 1.736446572888282

Epoch: 539| Step: 0
Training loss: 0.6226871013641357
Validation loss: 1.6799382009813864

Epoch: 6| Step: 1
Training loss: 1.2301784753799438
Validation loss: 1.67252480471006

Epoch: 6| Step: 2
Training loss: 0.7698838114738464
Validation loss: 1.6615812522108837

Epoch: 6| Step: 3
Training loss: 0.43728476762771606
Validation loss: 1.6320573117143364

Epoch: 6| Step: 4
Training loss: 0.5729387402534485
Validation loss: 1.7201985928320116

Epoch: 6| Step: 5
Training loss: 0.6391726732254028
Validation loss: 1.6836761941191971

Epoch: 6| Step: 6
Training loss: 0.8789511322975159
Validation loss: 1.6569514018233105

Epoch: 6| Step: 7
Training loss: 0.6577812433242798
Validation loss: 1.6310386452623593

Epoch: 6| Step: 8
Training loss: 0.9906361103057861
Validation loss: 1.7329873500331756

Epoch: 6| Step: 9
Training loss: 1.2704856395721436
Validation loss: 1.591984324557807

Epoch: 6| Step: 10
Training loss: 1.4241869449615479
Validation loss: 1.6745833376402497

Epoch: 6| Step: 11
Training loss: 0.8965752124786377
Validation loss: 1.7038038866494292

Epoch: 6| Step: 12
Training loss: 0.6925212740898132
Validation loss: 1.68334565624114

Epoch: 6| Step: 13
Training loss: 0.42323240637779236
Validation loss: 1.6702696559249715

Epoch: 540| Step: 0
Training loss: 1.0627270936965942
Validation loss: 1.6793051906811294

Epoch: 6| Step: 1
Training loss: 0.9127865433692932
Validation loss: 1.7384292092374576

Epoch: 6| Step: 2
Training loss: 0.6079109907150269
Validation loss: 1.6451181442506853

Epoch: 6| Step: 3
Training loss: 0.8044092059135437
Validation loss: 1.681495649840242

Epoch: 6| Step: 4
Training loss: 0.8372013568878174
Validation loss: 1.6141867881180139

Epoch: 6| Step: 5
Training loss: 0.647822916507721
Validation loss: 1.7248214060260403

Epoch: 6| Step: 6
Training loss: 0.7259587645530701
Validation loss: 1.6998874602779266

Epoch: 6| Step: 7
Training loss: 0.7256172895431519
Validation loss: 1.654093006605743

Epoch: 6| Step: 8
Training loss: 0.8342592716217041
Validation loss: 1.6727060733302948

Epoch: 6| Step: 9
Training loss: 0.9944349527359009
Validation loss: 1.707248938980923

Epoch: 6| Step: 10
Training loss: 0.5176663994789124
Validation loss: 1.6733359444525935

Epoch: 6| Step: 11
Training loss: 1.4470521211624146
Validation loss: 1.7607402455422185

Epoch: 6| Step: 12
Training loss: 0.6821404695510864
Validation loss: 1.6728883968886508

Epoch: 6| Step: 13
Training loss: 1.3543400764465332
Validation loss: 1.7122737848630516

Epoch: 541| Step: 0
Training loss: 0.4543894827365875
Validation loss: 1.668087658061776

Epoch: 6| Step: 1
Training loss: 1.3189470767974854
Validation loss: 1.7040790985989314

Epoch: 6| Step: 2
Training loss: 0.43287229537963867
Validation loss: 1.7108979712250412

Epoch: 6| Step: 3
Training loss: 0.904779851436615
Validation loss: 1.7033667711801426

Epoch: 6| Step: 4
Training loss: 1.1934884786605835
Validation loss: 1.6892974043405184

Epoch: 6| Step: 5
Training loss: 1.0941221714019775
Validation loss: 1.6754519477967293

Epoch: 6| Step: 6
Training loss: 1.0441250801086426
Validation loss: 1.6854217462642218

Epoch: 6| Step: 7
Training loss: 0.7656170129776001
Validation loss: 1.6191450831710652

Epoch: 6| Step: 8
Training loss: 0.6887083649635315
Validation loss: 1.7393975001509472

Epoch: 6| Step: 9
Training loss: 1.0257067680358887
Validation loss: 1.6725716911336428

Epoch: 6| Step: 10
Training loss: 1.0381686687469482
Validation loss: 1.7163366156239663

Epoch: 6| Step: 11
Training loss: 1.0839104652404785
Validation loss: 1.700797204048403

Epoch: 6| Step: 12
Training loss: 0.5898630619049072
Validation loss: 1.6519758137323524

Epoch: 6| Step: 13
Training loss: 0.47830718755722046
Validation loss: 1.7042656508825158

Epoch: 542| Step: 0
Training loss: 0.7222094535827637
Validation loss: 1.6740741101644372

Epoch: 6| Step: 1
Training loss: 1.5553758144378662
Validation loss: 1.6490392582390898

Epoch: 6| Step: 2
Training loss: 0.761778712272644
Validation loss: 1.696279869284681

Epoch: 6| Step: 3
Training loss: 1.1211163997650146
Validation loss: 1.6008573296249553

Epoch: 6| Step: 4
Training loss: 1.0041532516479492
Validation loss: 1.7379966410257484

Epoch: 6| Step: 5
Training loss: 1.083949089050293
Validation loss: 1.6152192136292816

Epoch: 6| Step: 6
Training loss: 0.5718963146209717
Validation loss: 1.6776571209712694

Epoch: 6| Step: 7
Training loss: 0.4541054964065552
Validation loss: 1.6580701374238538

Epoch: 6| Step: 8
Training loss: 1.1862213611602783
Validation loss: 1.6387134123873968

Epoch: 6| Step: 9
Training loss: 0.6059330701828003
Validation loss: 1.655862009653481

Epoch: 6| Step: 10
Training loss: 0.9520673751831055
Validation loss: 1.59298534547129

Epoch: 6| Step: 11
Training loss: 0.794284999370575
Validation loss: 1.6501594192238265

Epoch: 6| Step: 12
Training loss: 0.9805213212966919
Validation loss: 1.6399960928065802

Epoch: 6| Step: 13
Training loss: 0.7070589065551758
Validation loss: 1.6784088976921574

Epoch: 543| Step: 0
Training loss: 0.831648588180542
Validation loss: 1.7578854791579708

Epoch: 6| Step: 1
Training loss: 0.733681321144104
Validation loss: 1.6320874011644753

Epoch: 6| Step: 2
Training loss: 0.7017041444778442
Validation loss: 1.683585011830894

Epoch: 6| Step: 3
Training loss: 1.4218013286590576
Validation loss: 1.7642326713890157

Epoch: 6| Step: 4
Training loss: 1.090389370918274
Validation loss: 1.690685833654096

Epoch: 6| Step: 5
Training loss: 0.6935131549835205
Validation loss: 1.6887546905907251

Epoch: 6| Step: 6
Training loss: 1.0031542778015137
Validation loss: 1.6324284653509817

Epoch: 6| Step: 7
Training loss: 0.6813250780105591
Validation loss: 1.6522535329223962

Epoch: 6| Step: 8
Training loss: 1.0919703245162964
Validation loss: 1.621105194732707

Epoch: 6| Step: 9
Training loss: 0.8598824739456177
Validation loss: 1.641271811659618

Epoch: 6| Step: 10
Training loss: 0.9010955095291138
Validation loss: 1.5955721755181589

Epoch: 6| Step: 11
Training loss: 0.6742573976516724
Validation loss: 1.6306071050705448

Epoch: 6| Step: 12
Training loss: 0.624168336391449
Validation loss: 1.6362238455844182

Epoch: 6| Step: 13
Training loss: 1.7273154258728027
Validation loss: 1.7031503121058147

Epoch: 544| Step: 0
Training loss: 0.8448035717010498
Validation loss: 1.6254111400214575

Epoch: 6| Step: 1
Training loss: 0.50310879945755
Validation loss: 1.6737210724943428

Epoch: 6| Step: 2
Training loss: 1.309576392173767
Validation loss: 1.6499340239391531

Epoch: 6| Step: 3
Training loss: 1.0203285217285156
Validation loss: 1.6848263766175957

Epoch: 6| Step: 4
Training loss: 1.0856072902679443
Validation loss: 1.7069323152624152

Epoch: 6| Step: 5
Training loss: 0.9261925220489502
Validation loss: 1.7182126692546311

Epoch: 6| Step: 6
Training loss: 0.9843735694885254
Validation loss: 1.757519893748786

Epoch: 6| Step: 7
Training loss: 1.225038766860962
Validation loss: 1.6707661100613174

Epoch: 6| Step: 8
Training loss: 0.8823437690734863
Validation loss: 1.6306044222206197

Epoch: 6| Step: 9
Training loss: 0.924551248550415
Validation loss: 1.640303215672893

Epoch: 6| Step: 10
Training loss: 1.2847094535827637
Validation loss: 1.6326237352945472

Epoch: 6| Step: 11
Training loss: 0.45491284132003784
Validation loss: 1.6582220292860461

Epoch: 6| Step: 12
Training loss: 0.6555509567260742
Validation loss: 1.6899996085833477

Epoch: 6| Step: 13
Training loss: 0.540966272354126
Validation loss: 1.7077719588433542

Epoch: 545| Step: 0
Training loss: 0.2965826094150543
Validation loss: 1.6748013201580252

Epoch: 6| Step: 1
Training loss: 0.66685950756073
Validation loss: 1.6324335964777137

Epoch: 6| Step: 2
Training loss: 0.6055877208709717
Validation loss: 1.683485887383902

Epoch: 6| Step: 3
Training loss: 0.5745487213134766
Validation loss: 1.6039775968879781

Epoch: 6| Step: 4
Training loss: 1.3015364408493042
Validation loss: 1.6522784233093262

Epoch: 6| Step: 5
Training loss: 1.5331568717956543
Validation loss: 1.703299355763261

Epoch: 6| Step: 6
Training loss: 1.2315456867218018
Validation loss: 1.7066686384139522

Epoch: 6| Step: 7
Training loss: 1.102980375289917
Validation loss: 1.664049784342448

Epoch: 6| Step: 8
Training loss: 0.7214115858078003
Validation loss: 1.6887260290884203

Epoch: 6| Step: 9
Training loss: 0.921165943145752
Validation loss: 1.680920515009152

Epoch: 6| Step: 10
Training loss: 0.4438929855823517
Validation loss: 1.5811349698292312

Epoch: 6| Step: 11
Training loss: 0.8062894940376282
Validation loss: 1.6749842115627822

Epoch: 6| Step: 12
Training loss: 1.0960843563079834
Validation loss: 1.6547010150007022

Epoch: 6| Step: 13
Training loss: 0.5946348905563354
Validation loss: 1.6506924706120645

Epoch: 546| Step: 0
Training loss: 0.9337759613990784
Validation loss: 1.6514503930204658

Epoch: 6| Step: 1
Training loss: 1.1373231410980225
Validation loss: 1.7008649123612272

Epoch: 6| Step: 2
Training loss: 0.7875423431396484
Validation loss: 1.6856971453594904

Epoch: 6| Step: 3
Training loss: 1.0699083805084229
Validation loss: 1.736580188556384

Epoch: 6| Step: 4
Training loss: 0.7931197881698608
Validation loss: 1.6601315723952426

Epoch: 6| Step: 5
Training loss: 1.1537812948226929
Validation loss: 1.6237186296011812

Epoch: 6| Step: 6
Training loss: 0.8300329446792603
Validation loss: 1.6042389023688532

Epoch: 6| Step: 7
Training loss: 1.2464032173156738
Validation loss: 1.6541299871219102

Epoch: 6| Step: 8
Training loss: 0.7497861981391907
Validation loss: 1.654290065329562

Epoch: 6| Step: 9
Training loss: 1.3733806610107422
Validation loss: 1.6858071934792302

Epoch: 6| Step: 10
Training loss: 0.6877338886260986
Validation loss: 1.6473519597002255

Epoch: 6| Step: 11
Training loss: 0.712762713432312
Validation loss: 1.6833625378147248

Epoch: 6| Step: 12
Training loss: 0.6514744758605957
Validation loss: 1.6909889982592674

Epoch: 6| Step: 13
Training loss: 0.7233936786651611
Validation loss: 1.6797319458376976

Epoch: 547| Step: 0
Training loss: 0.5473273992538452
Validation loss: 1.7222796819543327

Epoch: 6| Step: 1
Training loss: 0.4014874994754791
Validation loss: 1.6961186983252083

Epoch: 6| Step: 2
Training loss: 0.6461788415908813
Validation loss: 1.7009686141885736

Epoch: 6| Step: 3
Training loss: 0.7837232351303101
Validation loss: 1.6764281129324308

Epoch: 6| Step: 4
Training loss: 1.2140529155731201
Validation loss: 1.6380651958527104

Epoch: 6| Step: 5
Training loss: 0.9161753058433533
Validation loss: 1.7090590666699153

Epoch: 6| Step: 6
Training loss: 1.3692107200622559
Validation loss: 1.6584835219126877

Epoch: 6| Step: 7
Training loss: 1.0653741359710693
Validation loss: 1.6465277928178028

Epoch: 6| Step: 8
Training loss: 1.0752155780792236
Validation loss: 1.6034514006747995

Epoch: 6| Step: 9
Training loss: 1.1053926944732666
Validation loss: 1.7114690631948493

Epoch: 6| Step: 10
Training loss: 0.9042370915412903
Validation loss: 1.6649982326774186

Epoch: 6| Step: 11
Training loss: 0.8409538269042969
Validation loss: 1.6368604321633615

Epoch: 6| Step: 12
Training loss: 0.9263410568237305
Validation loss: 1.6811071390746741

Epoch: 6| Step: 13
Training loss: 0.6259569525718689
Validation loss: 1.6965725203996063

Epoch: 548| Step: 0
Training loss: 0.8372613191604614
Validation loss: 1.6947768247255715

Epoch: 6| Step: 1
Training loss: 0.7803728580474854
Validation loss: 1.7188809674273255

Epoch: 6| Step: 2
Training loss: 0.8002934455871582
Validation loss: 1.692671133625892

Epoch: 6| Step: 3
Training loss: 0.9889770150184631
Validation loss: 1.6206191855092202

Epoch: 6| Step: 4
Training loss: 0.9122151732444763
Validation loss: 1.755133346844745

Epoch: 6| Step: 5
Training loss: 1.2108880281448364
Validation loss: 1.7154166326727918

Epoch: 6| Step: 6
Training loss: 0.6413975358009338
Validation loss: 1.713440651534706

Epoch: 6| Step: 7
Training loss: 0.7727770805358887
Validation loss: 1.6537785491635721

Epoch: 6| Step: 8
Training loss: 0.7487092614173889
Validation loss: 1.738036951711101

Epoch: 6| Step: 9
Training loss: 1.0861635208129883
Validation loss: 1.7098245133635819

Epoch: 6| Step: 10
Training loss: 0.6256092190742493
Validation loss: 1.7343988700579571

Epoch: 6| Step: 11
Training loss: 0.6797404885292053
Validation loss: 1.7086729977720527

Epoch: 6| Step: 12
Training loss: 1.2140111923217773
Validation loss: 1.7663316867684806

Epoch: 6| Step: 13
Training loss: 0.4453030228614807
Validation loss: 1.6977483136679536

Epoch: 549| Step: 0
Training loss: 0.7690057158470154
Validation loss: 1.7115827170751428

Epoch: 6| Step: 1
Training loss: 0.9117721319198608
Validation loss: 1.701015551884969

Epoch: 6| Step: 2
Training loss: 0.7051737308502197
Validation loss: 1.712290144735767

Epoch: 6| Step: 3
Training loss: 0.5255759954452515
Validation loss: 1.6668197390853718

Epoch: 6| Step: 4
Training loss: 0.5650165677070618
Validation loss: 1.700263064394715

Epoch: 6| Step: 5
Training loss: 0.8849260210990906
Validation loss: 1.6767337963145266

Epoch: 6| Step: 6
Training loss: 0.7891541123390198
Validation loss: 1.7143954692348358

Epoch: 6| Step: 7
Training loss: 1.4024384021759033
Validation loss: 1.6294920841852825

Epoch: 6| Step: 8
Training loss: 0.5058246850967407
Validation loss: 1.7037578667363813

Epoch: 6| Step: 9
Training loss: 0.611993670463562
Validation loss: 1.6789998418541365

Epoch: 6| Step: 10
Training loss: 1.372317910194397
Validation loss: 1.701139368036742

Epoch: 6| Step: 11
Training loss: 1.4280872344970703
Validation loss: 1.6115950051174368

Epoch: 6| Step: 12
Training loss: 0.6337236166000366
Validation loss: 1.569294680831253

Epoch: 6| Step: 13
Training loss: 0.8853564858436584
Validation loss: 1.690530196312935

Epoch: 550| Step: 0
Training loss: 0.5760440230369568
Validation loss: 1.6972482973529446

Epoch: 6| Step: 1
Training loss: 1.051241397857666
Validation loss: 1.7428043593642533

Epoch: 6| Step: 2
Training loss: 1.1610419750213623
Validation loss: 1.7310750792103429

Epoch: 6| Step: 3
Training loss: 0.8483805060386658
Validation loss: 1.6794177229686449

Epoch: 6| Step: 4
Training loss: 1.3489406108856201
Validation loss: 1.7555612325668335

Epoch: 6| Step: 5
Training loss: 1.1042845249176025
Validation loss: 1.6327993869781494

Epoch: 6| Step: 6
Training loss: 0.5565072298049927
Validation loss: 1.7393773383991693

Epoch: 6| Step: 7
Training loss: 0.5629830956459045
Validation loss: 1.7465460864446496

Epoch: 6| Step: 8
Training loss: 0.8555260896682739
Validation loss: 1.672193789994845

Epoch: 6| Step: 9
Training loss: 1.2866156101226807
Validation loss: 1.660679696708597

Epoch: 6| Step: 10
Training loss: 0.5571921467781067
Validation loss: 1.7018318829997894

Epoch: 6| Step: 11
Training loss: 0.8880250453948975
Validation loss: 1.7072143375232656

Epoch: 6| Step: 12
Training loss: 0.6661651134490967
Validation loss: 1.621869948602492

Epoch: 6| Step: 13
Training loss: 0.5928593873977661
Validation loss: 1.6484929310378207

Testing loss: 2.5063001023398503
