Epoch: 1| Step: 0
Training loss: 4.4911290787753675
Validation loss: 4.832924806828489

Epoch: 5| Step: 1
Training loss: 5.382937226421441
Validation loss: 4.826566634829061

Epoch: 5| Step: 2
Training loss: 4.791175662329124
Validation loss: 4.820829749478499

Epoch: 5| Step: 3
Training loss: 4.663906689058868
Validation loss: 4.814277417648035

Epoch: 5| Step: 4
Training loss: 5.218189689115546
Validation loss: 4.806338865212118

Epoch: 5| Step: 5
Training loss: 4.728320389143758
Validation loss: 4.803306264601578

Epoch: 5| Step: 6
Training loss: 4.420852165409764
Validation loss: 4.7970287750886795

Epoch: 5| Step: 7
Training loss: 4.815072895262785
Validation loss: 4.789830546298729

Epoch: 5| Step: 8
Training loss: 4.338425700762335
Validation loss: 4.782461906210934

Epoch: 5| Step: 9
Training loss: 5.174290211233177
Validation loss: 4.778098961661883

Epoch: 5| Step: 10
Training loss: 5.732890339674091
Validation loss: 4.768467794346053

Epoch: 2| Step: 0
Training loss: 4.767359683647908
Validation loss: 4.767404376793779

Epoch: 5| Step: 1
Training loss: 5.445507773971298
Validation loss: 4.756134260419101

Epoch: 5| Step: 2
Training loss: 4.073723650481604
Validation loss: 4.750932104410712

Epoch: 5| Step: 3
Training loss: 4.759582891701595
Validation loss: 4.743021875388798

Epoch: 5| Step: 4
Training loss: 5.292510718765901
Validation loss: 4.738216966492691

Epoch: 5| Step: 5
Training loss: 4.293824378733969
Validation loss: 4.729964059998726

Epoch: 5| Step: 6
Training loss: 4.757652142207331
Validation loss: 4.722071218197535

Epoch: 5| Step: 7
Training loss: 5.039135552401673
Validation loss: 4.720018250770942

Epoch: 5| Step: 8
Training loss: 5.049239888915018
Validation loss: 4.712776759001865

Epoch: 5| Step: 9
Training loss: 5.026054969993998
Validation loss: 4.7081905557145065

Epoch: 5| Step: 10
Training loss: 4.3214988252408
Validation loss: 4.699765346711324

Epoch: 3| Step: 0
Training loss: 5.5201445911654385
Validation loss: 4.693403153814905

Epoch: 5| Step: 1
Training loss: 4.927500002167662
Validation loss: 4.687152010124966

Epoch: 5| Step: 2
Training loss: 4.705670957164822
Validation loss: 4.681145102420936

Epoch: 5| Step: 3
Training loss: 4.652441938182483
Validation loss: 4.67451732065895

Epoch: 5| Step: 4
Training loss: 4.088548456984143
Validation loss: 4.664509012229938

Epoch: 5| Step: 5
Training loss: 4.790509999307672
Validation loss: 4.661617148159581

Epoch: 5| Step: 6
Training loss: 5.018122446389973
Validation loss: 4.654956715927797

Epoch: 5| Step: 7
Training loss: 4.741003451143532
Validation loss: 4.6460859746051675

Epoch: 5| Step: 8
Training loss: 3.9297473212783336
Validation loss: 4.641869189365294

Epoch: 5| Step: 9
Training loss: 4.903886942744173
Validation loss: 4.631872722915035

Epoch: 5| Step: 10
Training loss: 4.88671757906161
Validation loss: 4.6275181919849935

Epoch: 4| Step: 0
Training loss: 4.650936910112381
Validation loss: 4.6194445617258895

Epoch: 5| Step: 1
Training loss: 4.1390368600859775
Validation loss: 4.611372664801916

Epoch: 5| Step: 2
Training loss: 4.771863512426313
Validation loss: 4.606669749158049

Epoch: 5| Step: 3
Training loss: 5.216291933748143
Validation loss: 4.596245466321186

Epoch: 5| Step: 4
Training loss: 5.489251123711679
Validation loss: 4.590787176405212

Epoch: 5| Step: 5
Training loss: 3.9781734298790696
Validation loss: 4.584162482534209

Epoch: 5| Step: 6
Training loss: 4.076904114124064
Validation loss: 4.57270917950352

Epoch: 5| Step: 7
Training loss: 5.534069657262687
Validation loss: 4.568191554208389

Epoch: 5| Step: 8
Training loss: 4.6111872844200406
Validation loss: 4.557522029088044

Epoch: 5| Step: 9
Training loss: 4.627785745842587
Validation loss: 4.55137037167684

Epoch: 5| Step: 10
Training loss: 3.965763319893362
Validation loss: 4.539786891423188

Epoch: 5| Step: 0
Training loss: 4.2003595834026894
Validation loss: 4.535785762751003

Epoch: 5| Step: 1
Training loss: 4.5623296418457375
Validation loss: 4.52955347988519

Epoch: 5| Step: 2
Training loss: 4.700471554090137
Validation loss: 4.517631974104673

Epoch: 5| Step: 3
Training loss: 3.7049149319951074
Validation loss: 4.5126661679849205

Epoch: 5| Step: 4
Training loss: 4.537414566791064
Validation loss: 4.504464670355462

Epoch: 5| Step: 5
Training loss: 4.42852520369212
Validation loss: 4.495560248171638

Epoch: 5| Step: 6
Training loss: 4.8231902844759995
Validation loss: 4.486657396071782

Epoch: 5| Step: 7
Training loss: 5.071810602424467
Validation loss: 4.476402364177873

Epoch: 5| Step: 8
Training loss: 3.9833414569809142
Validation loss: 4.469578760286851

Epoch: 5| Step: 9
Training loss: 5.792224921164018
Validation loss: 4.464790437870809

Epoch: 5| Step: 10
Training loss: 4.357501321202579
Validation loss: 4.4539483515834055

Epoch: 6| Step: 0
Training loss: 3.5367700423491626
Validation loss: 4.4416934922750055

Epoch: 5| Step: 1
Training loss: 4.103367580846254
Validation loss: 4.433803506370355

Epoch: 5| Step: 2
Training loss: 5.342033244313406
Validation loss: 4.424142605472772

Epoch: 5| Step: 3
Training loss: 4.729643115719747
Validation loss: 4.414324550198879

Epoch: 5| Step: 4
Training loss: 4.575737965584076
Validation loss: 4.40416727943349

Epoch: 5| Step: 5
Training loss: 3.5387969264749586
Validation loss: 4.3973164756818575

Epoch: 5| Step: 6
Training loss: 5.060912271821286
Validation loss: 4.387707038974866

Epoch: 5| Step: 7
Training loss: 4.20589358674671
Validation loss: 4.375759931859021

Epoch: 5| Step: 8
Training loss: 4.378311429897701
Validation loss: 4.3670572728187445

Epoch: 5| Step: 9
Training loss: 5.063753702788081
Validation loss: 4.357517248392804

Epoch: 5| Step: 10
Training loss: 4.617876495229741
Validation loss: 4.346065600161

Epoch: 7| Step: 0
Training loss: 4.680945531419399
Validation loss: 4.3388562649438605

Epoch: 5| Step: 1
Training loss: 5.02296153612426
Validation loss: 4.325873102785876

Epoch: 5| Step: 2
Training loss: 4.376331017884797
Validation loss: 4.3131588929921945

Epoch: 5| Step: 3
Training loss: 3.95522496833883
Validation loss: 4.305623830376792

Epoch: 5| Step: 4
Training loss: 4.032904943199602
Validation loss: 4.297322336368238

Epoch: 5| Step: 5
Training loss: 4.116259012360123
Validation loss: 4.283204120959659

Epoch: 5| Step: 6
Training loss: 4.60170798727456
Validation loss: 4.27573489670678

Epoch: 5| Step: 7
Training loss: 4.075581777033687
Validation loss: 4.263730114128934

Epoch: 5| Step: 8
Training loss: 4.841037310580413
Validation loss: 4.252478671174063

Epoch: 5| Step: 9
Training loss: 4.606897548257569
Validation loss: 4.2432634068781185

Epoch: 5| Step: 10
Training loss: 3.8727487977439545
Validation loss: 4.233447867883632

Epoch: 8| Step: 0
Training loss: 4.535065406066894
Validation loss: 4.222559829222284

Epoch: 5| Step: 1
Training loss: 3.5788509515346933
Validation loss: 4.211431867069878

Epoch: 5| Step: 2
Training loss: 4.975815266274153
Validation loss: 4.201288330281308

Epoch: 5| Step: 3
Training loss: 3.813691500224778
Validation loss: 4.191080378872389

Epoch: 5| Step: 4
Training loss: 4.554267039447902
Validation loss: 4.181296065166408

Epoch: 5| Step: 5
Training loss: 3.584706878596428
Validation loss: 4.168679731000358

Epoch: 5| Step: 6
Training loss: 2.9923691657074922
Validation loss: 4.155766479582456

Epoch: 5| Step: 7
Training loss: 4.958647239856937
Validation loss: 4.143159873861828

Epoch: 5| Step: 8
Training loss: 3.379072628445282
Validation loss: 4.132103537133644

Epoch: 5| Step: 9
Training loss: 4.644284433491334
Validation loss: 4.121412923233984

Epoch: 5| Step: 10
Training loss: 5.601667544179384
Validation loss: 4.110434138765869

Epoch: 9| Step: 0
Training loss: 4.097278733950333
Validation loss: 4.102654899449466

Epoch: 5| Step: 1
Training loss: 3.3626412060666397
Validation loss: 4.089940923940147

Epoch: 5| Step: 2
Training loss: 4.375927200158155
Validation loss: 4.077263904272906

Epoch: 5| Step: 3
Training loss: 4.0218173125901195
Validation loss: 4.0661597705238

Epoch: 5| Step: 4
Training loss: 4.367683614486058
Validation loss: 4.057292210908779

Epoch: 5| Step: 5
Training loss: 4.023412848832249
Validation loss: 4.039104375528737

Epoch: 5| Step: 6
Training loss: 4.846875763431295
Validation loss: 4.0313414677523625

Epoch: 5| Step: 7
Training loss: 4.110885284567787
Validation loss: 4.019203320228263

Epoch: 5| Step: 8
Training loss: 4.669087985263904
Validation loss: 4.004848358061861

Epoch: 5| Step: 9
Training loss: 3.618519218609902
Validation loss: 3.991572030464501

Epoch: 5| Step: 10
Training loss: 4.161042397552387
Validation loss: 3.981564430372664

Epoch: 10| Step: 0
Training loss: 4.070184335869089
Validation loss: 3.9712787711257116

Epoch: 5| Step: 1
Training loss: 3.7346454346868256
Validation loss: 3.9555608490301704

Epoch: 5| Step: 2
Training loss: 3.8970920480884734
Validation loss: 3.9410484772183736

Epoch: 5| Step: 3
Training loss: 4.618566833085216
Validation loss: 3.9269691233726878

Epoch: 5| Step: 4
Training loss: 4.579760783249176
Validation loss: 3.916724934839425

Epoch: 5| Step: 5
Training loss: 4.295905430383318
Validation loss: 3.9002258261693643

Epoch: 5| Step: 6
Training loss: 4.301978059947713
Validation loss: 3.8881359319716524

Epoch: 5| Step: 7
Training loss: 3.3637670859445494
Validation loss: 3.8807620153208453

Epoch: 5| Step: 8
Training loss: 3.8774455567306365
Validation loss: 3.8634615940366577

Epoch: 5| Step: 9
Training loss: 3.6695263432743435
Validation loss: 3.8493744719017475

Epoch: 5| Step: 10
Training loss: 3.8298334785695025
Validation loss: 3.8342262719874367

Epoch: 11| Step: 0
Training loss: 3.5806537338171953
Validation loss: 3.8200086703527165

Epoch: 5| Step: 1
Training loss: 3.3830123736600366
Validation loss: 3.806301749080868

Epoch: 5| Step: 2
Training loss: 4.879613600582654
Validation loss: 3.7908510743831116

Epoch: 5| Step: 3
Training loss: 2.6120829892783264
Validation loss: 3.783512353630202

Epoch: 5| Step: 4
Training loss: 4.504912344262892
Validation loss: 3.765492226519259

Epoch: 5| Step: 5
Training loss: 4.547634415278389
Validation loss: 3.7494751559536934

Epoch: 5| Step: 6
Training loss: 3.2553120263432476
Validation loss: 3.7431014181935773

Epoch: 5| Step: 7
Training loss: 3.5889833101961757
Validation loss: 3.72662898440097

Epoch: 5| Step: 8
Training loss: 3.9804850419808884
Validation loss: 3.7176810500216986

Epoch: 5| Step: 9
Training loss: 3.4575508028988473
Validation loss: 3.7009201772464824

Epoch: 5| Step: 10
Training loss: 4.618227149369531
Validation loss: 3.685643736444668

Epoch: 12| Step: 0
Training loss: 3.123875072184189
Validation loss: 3.6682134849350345

Epoch: 5| Step: 1
Training loss: 3.099544454758855
Validation loss: 3.651174301713827

Epoch: 5| Step: 2
Training loss: 3.363531335976477
Validation loss: 3.641291296522164

Epoch: 5| Step: 3
Training loss: 4.082992980681922
Validation loss: 3.6263650099969227

Epoch: 5| Step: 4
Training loss: 3.2642915914660886
Validation loss: 3.608476135952871

Epoch: 5| Step: 5
Training loss: 4.269814247182697
Validation loss: 3.599187166816671

Epoch: 5| Step: 6
Training loss: 4.252097565874611
Validation loss: 3.5824638799036337

Epoch: 5| Step: 7
Training loss: 2.974781855431141
Validation loss: 3.5740797181111783

Epoch: 5| Step: 8
Training loss: 3.99652198741739
Validation loss: 3.551324771242187

Epoch: 5| Step: 9
Training loss: 4.206643599393042
Validation loss: 3.5379698296959727

Epoch: 5| Step: 10
Training loss: 4.236340731597195
Validation loss: 3.521687315169196

Epoch: 13| Step: 0
Training loss: 4.063923043656307
Validation loss: 3.503125886784452

Epoch: 5| Step: 1
Training loss: 3.0290295835292707
Validation loss: 3.4871759526480712

Epoch: 5| Step: 2
Training loss: 3.561852379543154
Validation loss: 3.470080409420841

Epoch: 5| Step: 3
Training loss: 3.7297807468476836
Validation loss: 3.462543993674439

Epoch: 5| Step: 4
Training loss: 3.6706090165070684
Validation loss: 3.440241027903173

Epoch: 5| Step: 5
Training loss: 3.914366567530435
Validation loss: 3.4198434938712943

Epoch: 5| Step: 6
Training loss: 3.126037120381479
Validation loss: 3.4077592546529747

Epoch: 5| Step: 7
Training loss: 4.035406764065407
Validation loss: 3.3912532748471307

Epoch: 5| Step: 8
Training loss: 3.0312902703510596
Validation loss: 3.3730718117238134

Epoch: 5| Step: 9
Training loss: 3.6434228976014578
Validation loss: 3.3582099223980277

Epoch: 5| Step: 10
Training loss: 3.6256634335321243
Validation loss: 3.3391491527295587

Epoch: 14| Step: 0
Training loss: 4.395303317595056
Validation loss: 3.321818501483389

Epoch: 5| Step: 1
Training loss: 4.008433511371729
Validation loss: 3.3081978714360796

Epoch: 5| Step: 2
Training loss: 3.467831051733798
Validation loss: 3.290183349291944

Epoch: 5| Step: 3
Training loss: 3.0986880571915028
Validation loss: 3.2698675161026793

Epoch: 5| Step: 4
Training loss: 3.860630464406382
Validation loss: 3.259220456747646

Epoch: 5| Step: 5
Training loss: 3.052055610470074
Validation loss: 3.2387338943882997

Epoch: 5| Step: 6
Training loss: 2.721028129844405
Validation loss: 3.2226877423161895

Epoch: 5| Step: 7
Training loss: 3.575398301564672
Validation loss: 3.211897134950629

Epoch: 5| Step: 8
Training loss: 2.894452175033246
Validation loss: 3.2004875764043668

Epoch: 5| Step: 9
Training loss: 3.6784041124617066
Validation loss: 3.17306400411848

Epoch: 5| Step: 10
Training loss: 2.6098424070288933
Validation loss: 3.1587303566206346

Epoch: 15| Step: 0
Training loss: 3.1599652170126005
Validation loss: 3.1476472610835056

Epoch: 5| Step: 1
Training loss: 4.066086110641937
Validation loss: 3.1311243207031976

Epoch: 5| Step: 2
Training loss: 3.356035710887032
Validation loss: 3.1110692855213053

Epoch: 5| Step: 3
Training loss: 3.339918990152128
Validation loss: 3.0945545458427888

Epoch: 5| Step: 4
Training loss: 3.679638386457334
Validation loss: 3.083431444101003

Epoch: 5| Step: 5
Training loss: 2.9321701720269595
Validation loss: 3.066336357031317

Epoch: 5| Step: 6
Training loss: 3.292391218446364
Validation loss: 3.0521268846047054

Epoch: 5| Step: 7
Training loss: 2.8817455932975324
Validation loss: 3.029819383932179

Epoch: 5| Step: 8
Training loss: 2.9123811754864994
Validation loss: 3.017733323660364

Epoch: 5| Step: 9
Training loss: 3.395203061892165
Validation loss: 3.0058559464160424

Epoch: 5| Step: 10
Training loss: 3.081380758548088
Validation loss: 2.992738624859388

Epoch: 16| Step: 0
Training loss: 3.1625547984807403
Validation loss: 2.978819598780288

Epoch: 5| Step: 1
Training loss: 3.168057554531363
Validation loss: 2.9596743411962136

Epoch: 5| Step: 2
Training loss: 3.9892605616958092
Validation loss: 2.944434304341477

Epoch: 5| Step: 3
Training loss: 2.5785824456562625
Validation loss: 2.9349233322470534

Epoch: 5| Step: 4
Training loss: 3.221613674869316
Validation loss: 2.9177217154503823

Epoch: 5| Step: 5
Training loss: 2.8061999649990716
Validation loss: 2.9117975443343007

Epoch: 5| Step: 6
Training loss: 3.017877399702279
Validation loss: 2.897537376924844

Epoch: 5| Step: 7
Training loss: 3.1425253209904938
Validation loss: 2.8838744089783686

Epoch: 5| Step: 8
Training loss: 3.2224221624261937
Validation loss: 2.869256537497147

Epoch: 5| Step: 9
Training loss: 2.875916708046513
Validation loss: 2.8652983768476044

Epoch: 5| Step: 10
Training loss: 3.4864037599026
Validation loss: 2.850524637953744

Epoch: 17| Step: 0
Training loss: 3.465099991846009
Validation loss: 2.836193652940832

Epoch: 5| Step: 1
Training loss: 3.6809006167350895
Validation loss: 2.828288087486265

Epoch: 5| Step: 2
Training loss: 2.421747708820934
Validation loss: 2.8057842429136097

Epoch: 5| Step: 3
Training loss: 3.1181348541831975
Validation loss: 2.794076844910584

Epoch: 5| Step: 4
Training loss: 3.1830763694812907
Validation loss: 2.7978368065428874

Epoch: 5| Step: 5
Training loss: 3.2109793778633144
Validation loss: 2.77370685873708

Epoch: 5| Step: 6
Training loss: 2.1598792010543026
Validation loss: 2.7500852355351553

Epoch: 5| Step: 7
Training loss: 2.996988374317775
Validation loss: 2.761643209478888

Epoch: 5| Step: 8
Training loss: 3.1660213482173747
Validation loss: 2.7475918791112153

Epoch: 5| Step: 9
Training loss: 3.141393463101152
Validation loss: 2.7370898891930424

Epoch: 5| Step: 10
Training loss: 2.829496946611929
Validation loss: 2.7238659821970845

Epoch: 18| Step: 0
Training loss: 3.125564829325947
Validation loss: 2.7228831895179946

Epoch: 5| Step: 1
Training loss: 2.610308086291518
Validation loss: 2.714161961138597

Epoch: 5| Step: 2
Training loss: 3.4704753262151518
Validation loss: 2.7037788950262014

Epoch: 5| Step: 3
Training loss: 1.9843580590673886
Validation loss: 2.6893947911133473

Epoch: 5| Step: 4
Training loss: 3.009747563926179
Validation loss: 2.684190477581671

Epoch: 5| Step: 5
Training loss: 2.625735225347905
Validation loss: 2.6928171984876075

Epoch: 5| Step: 6
Training loss: 3.0770080398786783
Validation loss: 2.67805304875333

Epoch: 5| Step: 7
Training loss: 2.8744801590361315
Validation loss: 2.6603648048698747

Epoch: 5| Step: 8
Training loss: 3.230565283000715
Validation loss: 2.664470723728003

Epoch: 5| Step: 9
Training loss: 2.9784126839280836
Validation loss: 2.6537152786166303

Epoch: 5| Step: 10
Training loss: 3.578608317820016
Validation loss: 2.653472305084597

Epoch: 19| Step: 0
Training loss: 2.925646790291085
Validation loss: 2.6432755942303134

Epoch: 5| Step: 1
Training loss: 3.077854512524683
Validation loss: 2.633012667294029

Epoch: 5| Step: 2
Training loss: 2.9888899438786054
Validation loss: 2.6372329197220346

Epoch: 5| Step: 3
Training loss: 3.099863043190077
Validation loss: 2.6189603885836834

Epoch: 5| Step: 4
Training loss: 2.958085833301694
Validation loss: 2.6263302890958755

Epoch: 5| Step: 5
Training loss: 3.211543042334721
Validation loss: 2.608295005205624

Epoch: 5| Step: 6
Training loss: 2.881342319159711
Validation loss: 2.6105242600400587

Epoch: 5| Step: 7
Training loss: 2.3247526180778912
Validation loss: 2.60329332798066

Epoch: 5| Step: 8
Training loss: 3.0516579671166624
Validation loss: 2.598030410159305

Epoch: 5| Step: 9
Training loss: 2.9018728456934917
Validation loss: 2.596241909014512

Epoch: 5| Step: 10
Training loss: 2.8180005855681527
Validation loss: 2.593350837001647

Epoch: 20| Step: 0
Training loss: 2.8906965917021314
Validation loss: 2.593538013962327

Epoch: 5| Step: 1
Training loss: 3.0353757172603992
Validation loss: 2.586268615788883

Epoch: 5| Step: 2
Training loss: 3.121150430443949
Validation loss: 2.593971364567348

Epoch: 5| Step: 3
Training loss: 2.4396752652623386
Validation loss: 2.5876290241871818

Epoch: 5| Step: 4
Training loss: 2.408232726621343
Validation loss: 2.5810460551226506

Epoch: 5| Step: 5
Training loss: 3.4913995523787573
Validation loss: 2.573844694143384

Epoch: 5| Step: 6
Training loss: 3.0956375066980915
Validation loss: 2.585351357872935

Epoch: 5| Step: 7
Training loss: 2.9895642287721635
Validation loss: 2.5837298878485377

Epoch: 5| Step: 8
Training loss: 2.3480825433860284
Validation loss: 2.5805166179806363

Epoch: 5| Step: 9
Training loss: 3.235687137130172
Validation loss: 2.577907084941022

Epoch: 5| Step: 10
Training loss: 2.627406425080157
Validation loss: 2.562251559423732

Epoch: 21| Step: 0
Training loss: 3.289664097946679
Validation loss: 2.564165574006369

Epoch: 5| Step: 1
Training loss: 3.3634842690612747
Validation loss: 2.5633319491659736

Epoch: 5| Step: 2
Training loss: 2.6467491327149046
Validation loss: 2.5741020568443815

Epoch: 5| Step: 3
Training loss: 2.3006748246090947
Validation loss: 2.567395383119696

Epoch: 5| Step: 4
Training loss: 2.238511424853677
Validation loss: 2.5563984292449358

Epoch: 5| Step: 5
Training loss: 2.4988653469131092
Validation loss: 2.5533762151751653

Epoch: 5| Step: 6
Training loss: 3.4000902388322207
Validation loss: 2.5698114949087367

Epoch: 5| Step: 7
Training loss: 3.2923144576293195
Validation loss: 2.565440852683996

Epoch: 5| Step: 8
Training loss: 3.03417402990702
Validation loss: 2.553975193919517

Epoch: 5| Step: 9
Training loss: 2.8079593881131846
Validation loss: 2.558699696381085

Epoch: 5| Step: 10
Training loss: 2.6954932995293492
Validation loss: 2.545461586966575

Epoch: 22| Step: 0
Training loss: 2.9180873862052645
Validation loss: 2.5533476446238974

Epoch: 5| Step: 1
Training loss: 2.8717649752157604
Validation loss: 2.5537871887082977

Epoch: 5| Step: 2
Training loss: 2.5799500450206874
Validation loss: 2.554021060937101

Epoch: 5| Step: 3
Training loss: 3.1671669882668616
Validation loss: 2.5494616743131213

Epoch: 5| Step: 4
Training loss: 3.370696962770688
Validation loss: 2.55110570395036

Epoch: 5| Step: 5
Training loss: 2.709513089401973
Validation loss: 2.544975800174633

Epoch: 5| Step: 6
Training loss: 2.482029797604922
Validation loss: 2.5435517950764286

Epoch: 5| Step: 7
Training loss: 2.93105469400738
Validation loss: 2.547701580395774

Epoch: 5| Step: 8
Training loss: 3.498309953552991
Validation loss: 2.542229721330141

Epoch: 5| Step: 9
Training loss: 2.371391466231272
Validation loss: 2.5460940477982685

Epoch: 5| Step: 10
Training loss: 2.648763450887244
Validation loss: 2.5478250742259037

Epoch: 23| Step: 0
Training loss: 2.613781617391611
Validation loss: 2.543413177110216

Epoch: 5| Step: 1
Training loss: 2.7740036077716583
Validation loss: 2.5450657086857302

Epoch: 5| Step: 2
Training loss: 3.0424619357910303
Validation loss: 2.539623114425311

Epoch: 5| Step: 3
Training loss: 2.6593332684085684
Validation loss: 2.5352564331688705

Epoch: 5| Step: 4
Training loss: 3.422492124048259
Validation loss: 2.5436843594311807

Epoch: 5| Step: 5
Training loss: 2.6998939387364875
Validation loss: 2.541340371430509

Epoch: 5| Step: 6
Training loss: 2.8840537771642185
Validation loss: 2.541570311289515

Epoch: 5| Step: 7
Training loss: 3.23691890023133
Validation loss: 2.533837750207621

Epoch: 5| Step: 8
Training loss: 2.45512192231096
Validation loss: 2.5350376050004115

Epoch: 5| Step: 9
Training loss: 2.7008658433664428
Validation loss: 2.531129795442524

Epoch: 5| Step: 10
Training loss: 3.1935908149120826
Validation loss: 2.53729532870119

Epoch: 24| Step: 0
Training loss: 3.281437605081419
Validation loss: 2.5296281292397143

Epoch: 5| Step: 1
Training loss: 2.784947626932959
Validation loss: 2.545642117773272

Epoch: 5| Step: 2
Training loss: 2.9875212856156916
Validation loss: 2.54690774292228

Epoch: 5| Step: 3
Training loss: 3.14418094176459
Validation loss: 2.5405295854598453

Epoch: 5| Step: 4
Training loss: 2.472539672996127
Validation loss: 2.542175891188507

Epoch: 5| Step: 5
Training loss: 3.143606564110629
Validation loss: 2.5426885533252324

Epoch: 5| Step: 6
Training loss: 2.924276904853534
Validation loss: 2.5359665147339445

Epoch: 5| Step: 7
Training loss: 2.7813498661242364
Validation loss: 2.5272344400221955

Epoch: 5| Step: 8
Training loss: 2.095311507780223
Validation loss: 2.540843952180322

Epoch: 5| Step: 9
Training loss: 2.946649465496323
Validation loss: 2.5448316848784565

Epoch: 5| Step: 10
Training loss: 2.961045879705546
Validation loss: 2.5376742426156684

Epoch: 25| Step: 0
Training loss: 3.0280036453164656
Validation loss: 2.5347209909252264

Epoch: 5| Step: 1
Training loss: 2.633876506300068
Validation loss: 2.542371242373887

Epoch: 5| Step: 2
Training loss: 3.094582339748437
Validation loss: 2.5333657111925323

Epoch: 5| Step: 3
Training loss: 3.0374327852324052
Validation loss: 2.5431336765783787

Epoch: 5| Step: 4
Training loss: 2.412563710532667
Validation loss: 2.5359213548418436

Epoch: 5| Step: 5
Training loss: 3.0977329085919645
Validation loss: 2.5354090786902246

Epoch: 5| Step: 6
Training loss: 2.3477766923269536
Validation loss: 2.5375701724055153

Epoch: 5| Step: 7
Training loss: 3.2017643713617776
Validation loss: 2.539476200852866

Epoch: 5| Step: 8
Training loss: 3.322925930349099
Validation loss: 2.548282704584753

Epoch: 5| Step: 9
Training loss: 2.493005217808765
Validation loss: 2.5363660606379614

Epoch: 5| Step: 10
Training loss: 2.838375168329833
Validation loss: 2.544216133796166

Epoch: 26| Step: 0
Training loss: 2.753425285598875
Validation loss: 2.527451028135304

Epoch: 5| Step: 1
Training loss: 3.016624166565117
Validation loss: 2.5401859445281505

Epoch: 5| Step: 2
Training loss: 3.249016392857557
Validation loss: 2.546590349647574

Epoch: 5| Step: 3
Training loss: 2.1953725569034375
Validation loss: 2.533024261151404

Epoch: 5| Step: 4
Training loss: 2.602153080987141
Validation loss: 2.5421427767151443

Epoch: 5| Step: 5
Training loss: 3.024992786745661
Validation loss: 2.5404614906856207

Epoch: 5| Step: 6
Training loss: 3.1570149618331365
Validation loss: 2.5334468895709827

Epoch: 5| Step: 7
Training loss: 2.887366360300714
Validation loss: 2.53379597320034

Epoch: 5| Step: 8
Training loss: 3.0311290284233503
Validation loss: 2.539648410285307

Epoch: 5| Step: 9
Training loss: 2.619160833430149
Validation loss: 2.5379887862430217

Epoch: 5| Step: 10
Training loss: 2.92682493614636
Validation loss: 2.5356210603295923

Epoch: 27| Step: 0
Training loss: 2.32103196623294
Validation loss: 2.528947890077037

Epoch: 5| Step: 1
Training loss: 2.944860448979687
Validation loss: 2.5376654879269473

Epoch: 5| Step: 2
Training loss: 2.6908907237410213
Validation loss: 2.537472759936943

Epoch: 5| Step: 3
Training loss: 2.9514623735043473
Validation loss: 2.532135622536376

Epoch: 5| Step: 4
Training loss: 3.236726652297332
Validation loss: 2.5335318659879102

Epoch: 5| Step: 5
Training loss: 2.9808744501895696
Validation loss: 2.5317125605484483

Epoch: 5| Step: 6
Training loss: 2.6193831158719116
Validation loss: 2.533488580251597

Epoch: 5| Step: 7
Training loss: 2.668127901348682
Validation loss: 2.542126693798575

Epoch: 5| Step: 8
Training loss: 3.2061052553695584
Validation loss: 2.532280342945118

Epoch: 5| Step: 9
Training loss: 2.8198275585072214
Validation loss: 2.528881945831228

Epoch: 5| Step: 10
Training loss: 3.0741497259861568
Validation loss: 2.5289241730135923

Epoch: 28| Step: 0
Training loss: 3.237411179668136
Validation loss: 2.5328288641691845

Epoch: 5| Step: 1
Training loss: 2.6355156760533878
Validation loss: 2.5436505459925454

Epoch: 5| Step: 2
Training loss: 3.0075913385107462
Validation loss: 2.5374095822845724

Epoch: 5| Step: 3
Training loss: 2.4254115709090613
Validation loss: 2.536195892572101

Epoch: 5| Step: 4
Training loss: 2.7676895969854045
Validation loss: 2.534337008581594

Epoch: 5| Step: 5
Training loss: 2.2640808104728327
Validation loss: 2.534623510424249

Epoch: 5| Step: 6
Training loss: 3.1446753048330995
Validation loss: 2.53706375244366

Epoch: 5| Step: 7
Training loss: 2.6205269986766893
Validation loss: 2.5393893219754324

Epoch: 5| Step: 8
Training loss: 3.21118356174924
Validation loss: 2.5369846855495943

Epoch: 5| Step: 9
Training loss: 3.5111019623981936
Validation loss: 2.526154022373679

Epoch: 5| Step: 10
Training loss: 2.4038489115772568
Validation loss: 2.5292903972122622

Epoch: 29| Step: 0
Training loss: 2.7123522845712533
Validation loss: 2.5461885528872106

Epoch: 5| Step: 1
Training loss: 2.2131673937757883
Validation loss: 2.5433466100229962

Epoch: 5| Step: 2
Training loss: 2.6946311199983883
Validation loss: 2.539023877426731

Epoch: 5| Step: 3
Training loss: 3.2433153511743327
Validation loss: 2.536529800436785

Epoch: 5| Step: 4
Training loss: 3.4226648821239727
Validation loss: 2.536823500530008

Epoch: 5| Step: 5
Training loss: 3.017854331007975
Validation loss: 2.5317208578714823

Epoch: 5| Step: 6
Training loss: 2.783975187596651
Validation loss: 2.525081415893399

Epoch: 5| Step: 7
Training loss: 2.5077251288384583
Validation loss: 2.53781717131586

Epoch: 5| Step: 8
Training loss: 2.701454484323506
Validation loss: 2.521799418182176

Epoch: 5| Step: 9
Training loss: 2.7697263145890516
Validation loss: 2.533673012806214

Epoch: 5| Step: 10
Training loss: 3.1695314967282533
Validation loss: 2.5390382322251277

Epoch: 30| Step: 0
Training loss: 3.19936377041771
Validation loss: 2.530818575816385

Epoch: 5| Step: 1
Training loss: 2.4941080280943013
Validation loss: 2.5302895025450938

Epoch: 5| Step: 2
Training loss: 2.863818608714701
Validation loss: 2.536792731483687

Epoch: 5| Step: 3
Training loss: 2.4344025518501136
Validation loss: 2.5328158451638787

Epoch: 5| Step: 4
Training loss: 2.2177206526151774
Validation loss: 2.523473425127864

Epoch: 5| Step: 5
Training loss: 3.55114677067012
Validation loss: 2.527219119408775

Epoch: 5| Step: 6
Training loss: 3.0111276563570697
Validation loss: 2.538681640331543

Epoch: 5| Step: 7
Training loss: 2.3577010930400646
Validation loss: 2.5281021809323536

Epoch: 5| Step: 8
Training loss: 3.411225211450763
Validation loss: 2.5343301339925675

Epoch: 5| Step: 9
Training loss: 2.7252155463687493
Validation loss: 2.5225002791419824

Epoch: 5| Step: 10
Training loss: 2.879971725007178
Validation loss: 2.5297031955657334

Epoch: 31| Step: 0
Training loss: 3.1916599429651527
Validation loss: 2.5418810193394923

Epoch: 5| Step: 1
Training loss: 2.964967265213743
Validation loss: 2.5369205155262358

Epoch: 5| Step: 2
Training loss: 2.370600490388053
Validation loss: 2.517088824237406

Epoch: 5| Step: 3
Training loss: 3.4317922195012898
Validation loss: 2.5283538331079445

Epoch: 5| Step: 4
Training loss: 2.391280439694573
Validation loss: 2.532712373448996

Epoch: 5| Step: 5
Training loss: 2.6100600936519385
Validation loss: 2.531445028695847

Epoch: 5| Step: 6
Training loss: 2.8878888351412177
Validation loss: 2.544814812030006

Epoch: 5| Step: 7
Training loss: 2.543696379975121
Validation loss: 2.5297434567262855

Epoch: 5| Step: 8
Training loss: 3.0460797176737415
Validation loss: 2.5221247553719826

Epoch: 5| Step: 9
Training loss: 3.3010323152482886
Validation loss: 2.528034149950569

Epoch: 5| Step: 10
Training loss: 2.350512602882055
Validation loss: 2.520063028499568

Epoch: 32| Step: 0
Training loss: 2.678284925851424
Validation loss: 2.5321962711399246

Epoch: 5| Step: 1
Training loss: 3.1277369911180046
Validation loss: 2.5377311534174396

Epoch: 5| Step: 2
Training loss: 2.604405771086985
Validation loss: 2.5359418726074083

Epoch: 5| Step: 3
Training loss: 3.2868240241656563
Validation loss: 2.5260195799761536

Epoch: 5| Step: 4
Training loss: 2.8351245902536175
Validation loss: 2.525651573115275

Epoch: 5| Step: 5
Training loss: 2.427048504187938
Validation loss: 2.5225925908643645

Epoch: 5| Step: 6
Training loss: 3.619058936443177
Validation loss: 2.52250111962968

Epoch: 5| Step: 7
Training loss: 2.734651039359112
Validation loss: 2.525968368950263

Epoch: 5| Step: 8
Training loss: 3.256970925800725
Validation loss: 2.530240898784155

Epoch: 5| Step: 9
Training loss: 1.9197976895874505
Validation loss: 2.529521001711855

Epoch: 5| Step: 10
Training loss: 2.3994273774177772
Validation loss: 2.5267536147438965

Epoch: 33| Step: 0
Training loss: 2.7549017655708807
Validation loss: 2.53002099742426

Epoch: 5| Step: 1
Training loss: 2.9019227986914866
Validation loss: 2.5310619309194933

Epoch: 5| Step: 2
Training loss: 2.476548444545584
Validation loss: 2.5258838607232557

Epoch: 5| Step: 3
Training loss: 2.6979884036234156
Validation loss: 2.534627769629453

Epoch: 5| Step: 4
Training loss: 2.9464869902132764
Validation loss: 2.5265271157506346

Epoch: 5| Step: 5
Training loss: 2.7970118142875116
Validation loss: 2.5205620830179116

Epoch: 5| Step: 6
Training loss: 3.1782830813242136
Validation loss: 2.530492649290274

Epoch: 5| Step: 7
Training loss: 2.7302114995835938
Validation loss: 2.520003348341952

Epoch: 5| Step: 8
Training loss: 2.9533324799489784
Validation loss: 2.5311729675668335

Epoch: 5| Step: 9
Training loss: 3.1281412739668615
Validation loss: 2.5234894603176246

Epoch: 5| Step: 10
Training loss: 2.609862687456083
Validation loss: 2.5300224697317084

Epoch: 34| Step: 0
Training loss: 2.811576182913104
Validation loss: 2.5184299853696226

Epoch: 5| Step: 1
Training loss: 2.669552691705392
Validation loss: 2.5308239435331585

Epoch: 5| Step: 2
Training loss: 3.022964322226948
Validation loss: 2.5212797723693767

Epoch: 5| Step: 3
Training loss: 2.6152203355088988
Validation loss: 2.517237411550797

Epoch: 5| Step: 4
Training loss: 2.7396180376724213
Validation loss: 2.5205691400929062

Epoch: 5| Step: 5
Training loss: 2.7658299946647493
Validation loss: 2.530038605273503

Epoch: 5| Step: 6
Training loss: 2.7968200166721418
Validation loss: 2.533232091751876

Epoch: 5| Step: 7
Training loss: 3.212820869778485
Validation loss: 2.519367334468441

Epoch: 5| Step: 8
Training loss: 2.8254596100017895
Validation loss: 2.5170753133649275

Epoch: 5| Step: 9
Training loss: 2.9032347429472956
Validation loss: 2.512545274516264

Epoch: 5| Step: 10
Training loss: 2.756183521394607
Validation loss: 2.5207466497715325

Epoch: 35| Step: 0
Training loss: 2.830089919208516
Validation loss: 2.529244459277987

Epoch: 5| Step: 1
Training loss: 2.76089348663498
Validation loss: 2.5310917912096875

Epoch: 5| Step: 2
Training loss: 2.7143521748917547
Validation loss: 2.5333300892734103

Epoch: 5| Step: 3
Training loss: 2.991952752449173
Validation loss: 2.5146120906392935

Epoch: 5| Step: 4
Training loss: 2.21563437477356
Validation loss: 2.5243162164790562

Epoch: 5| Step: 5
Training loss: 3.112896482653856
Validation loss: 2.517407501626822

Epoch: 5| Step: 6
Training loss: 3.1169525287380058
Validation loss: 2.5211000615809653

Epoch: 5| Step: 7
Training loss: 2.412574877589922
Validation loss: 2.5231935649941017

Epoch: 5| Step: 8
Training loss: 3.1590476148494093
Validation loss: 2.523301342150317

Epoch: 5| Step: 9
Training loss: 2.7986206914855023
Validation loss: 2.5256475200521447

Epoch: 5| Step: 10
Training loss: 2.9229313373990524
Validation loss: 2.512086431351345

Epoch: 36| Step: 0
Training loss: 2.977901768198548
Validation loss: 2.5160400928652358

Epoch: 5| Step: 1
Training loss: 2.718819979063021
Validation loss: 2.5250351567005285

Epoch: 5| Step: 2
Training loss: 2.4308532665727025
Validation loss: 2.529751689570046

Epoch: 5| Step: 3
Training loss: 3.4516381562395684
Validation loss: 2.5392688146782674

Epoch: 5| Step: 4
Training loss: 2.4565315648183668
Validation loss: 2.5224229053076996

Epoch: 5| Step: 5
Training loss: 3.2255365620274827
Validation loss: 2.52051187077661

Epoch: 5| Step: 6
Training loss: 2.7946098148093608
Validation loss: 2.5161656347982797

Epoch: 5| Step: 7
Training loss: 2.4737199420847293
Validation loss: 2.52470429596825

Epoch: 5| Step: 8
Training loss: 3.026897175983527
Validation loss: 2.5219202799194176

Epoch: 5| Step: 9
Training loss: 1.9385764915403407
Validation loss: 2.533301017384565

Epoch: 5| Step: 10
Training loss: 3.392252729114686
Validation loss: 2.5301092289764093

Epoch: 37| Step: 0
Training loss: 2.4542263012966172
Validation loss: 2.526562566725049

Epoch: 5| Step: 1
Training loss: 3.243517646479276
Validation loss: 2.528552425913361

Epoch: 5| Step: 2
Training loss: 2.8206725168145694
Validation loss: 2.526806727406867

Epoch: 5| Step: 3
Training loss: 3.12735354488458
Validation loss: 2.52660989682587

Epoch: 5| Step: 4
Training loss: 2.643316578789905
Validation loss: 2.524641437509101

Epoch: 5| Step: 5
Training loss: 2.935093157457961
Validation loss: 2.5148609865869465

Epoch: 5| Step: 6
Training loss: 2.4609651109872197
Validation loss: 2.537970199193178

Epoch: 5| Step: 7
Training loss: 3.048432406954517
Validation loss: 2.5303044236141186

Epoch: 5| Step: 8
Training loss: 2.5774026494553453
Validation loss: 2.518200186491107

Epoch: 5| Step: 9
Training loss: 2.7137814426225915
Validation loss: 2.5185416522194477

Epoch: 5| Step: 10
Training loss: 3.022666655458715
Validation loss: 2.509193301718826

Epoch: 38| Step: 0
Training loss: 3.293322488738621
Validation loss: 2.5270324861254614

Epoch: 5| Step: 1
Training loss: 2.971050134339176
Validation loss: 2.526005886997098

Epoch: 5| Step: 2
Training loss: 2.890999434680547
Validation loss: 2.5129252781214255

Epoch: 5| Step: 3
Training loss: 2.8699606807022384
Validation loss: 2.5226156997712925

Epoch: 5| Step: 4
Training loss: 2.8327755285460574
Validation loss: 2.5100044671514756

Epoch: 5| Step: 5
Training loss: 2.423840715619998
Validation loss: 2.5178506226508226

Epoch: 5| Step: 6
Training loss: 2.7810933786933445
Validation loss: 2.519456165006054

Epoch: 5| Step: 7
Training loss: 2.7524345198906004
Validation loss: 2.5152172363738603

Epoch: 5| Step: 8
Training loss: 2.8955573812683757
Validation loss: 2.5106368303845663

Epoch: 5| Step: 9
Training loss: 2.4376377164621386
Validation loss: 2.5142179628149184

Epoch: 5| Step: 10
Training loss: 2.8349417627667077
Validation loss: 2.511925158112137

Epoch: 39| Step: 0
Training loss: 3.4353939193672662
Validation loss: 2.513346699270325

Epoch: 5| Step: 1
Training loss: 2.794380823383991
Validation loss: 2.514558968143601

Epoch: 5| Step: 2
Training loss: 2.414399552503106
Validation loss: 2.527394175444465

Epoch: 5| Step: 3
Training loss: 2.5611677660942718
Validation loss: 2.5108267377245475

Epoch: 5| Step: 4
Training loss: 3.0611368376321395
Validation loss: 2.5175456054957825

Epoch: 5| Step: 5
Training loss: 2.30461436010136
Validation loss: 2.5183492391110374

Epoch: 5| Step: 6
Training loss: 2.3331819439777117
Validation loss: 2.5119942581124066

Epoch: 5| Step: 7
Training loss: 2.650802951300057
Validation loss: 2.5188668066419657

Epoch: 5| Step: 8
Training loss: 3.1156555847687
Validation loss: 2.513043895940568

Epoch: 5| Step: 9
Training loss: 3.411284060309917
Validation loss: 2.5060978048231437

Epoch: 5| Step: 10
Training loss: 2.4985413110480916
Validation loss: 2.511464910882699

Epoch: 40| Step: 0
Training loss: 2.8860443938099762
Validation loss: 2.50824571752939

Epoch: 5| Step: 1
Training loss: 3.2142245877221125
Validation loss: 2.508693333498027

Epoch: 5| Step: 2
Training loss: 2.693896289225339
Validation loss: 2.5191569180043323

Epoch: 5| Step: 3
Training loss: 2.834580782619504
Validation loss: 2.5084598980766266

Epoch: 5| Step: 4
Training loss: 2.5785846647217983
Validation loss: 2.512678300374236

Epoch: 5| Step: 5
Training loss: 2.5595853092666823
Validation loss: 2.509844335904484

Epoch: 5| Step: 6
Training loss: 2.629721074561459
Validation loss: 2.5074100390591685

Epoch: 5| Step: 7
Training loss: 2.7238546221642497
Validation loss: 2.5169330524259443

Epoch: 5| Step: 8
Training loss: 2.8465091608443833
Validation loss: 2.509480560509429

Epoch: 5| Step: 9
Training loss: 3.0032704329034132
Validation loss: 2.5172141432773967

Epoch: 5| Step: 10
Training loss: 3.0392463844191835
Validation loss: 2.5252808467368153

Epoch: 41| Step: 0
Training loss: 2.778361159629432
Validation loss: 2.5133678021840047

Epoch: 5| Step: 1
Training loss: 2.8111429119279863
Validation loss: 2.5090294929682457

Epoch: 5| Step: 2
Training loss: 2.353221624855176
Validation loss: 2.5208947479230175

Epoch: 5| Step: 3
Training loss: 2.849419779022986
Validation loss: 2.527134827491919

Epoch: 5| Step: 4
Training loss: 3.071091725327652
Validation loss: 2.5167224528108534

Epoch: 5| Step: 5
Training loss: 2.9978012928732842
Validation loss: 2.5299286051247845

Epoch: 5| Step: 6
Training loss: 2.720196481648558
Validation loss: 2.519315896636555

Epoch: 5| Step: 7
Training loss: 2.4465929280463485
Validation loss: 2.5166301305224423

Epoch: 5| Step: 8
Training loss: 2.951417298024398
Validation loss: 2.511028013328488

Epoch: 5| Step: 9
Training loss: 2.6034473086849905
Validation loss: 2.5150515372054745

Epoch: 5| Step: 10
Training loss: 3.3529136797325685
Validation loss: 2.523490731221933

Epoch: 42| Step: 0
Training loss: 2.844228515608235
Validation loss: 2.4973109241976137

Epoch: 5| Step: 1
Training loss: 2.400852838622594
Validation loss: 2.5035782949715335

Epoch: 5| Step: 2
Training loss: 2.4818072214624514
Validation loss: 2.517858738599556

Epoch: 5| Step: 3
Training loss: 3.4154551304128957
Validation loss: 2.517878990175387

Epoch: 5| Step: 4
Training loss: 2.271986770504058
Validation loss: 2.505299409930788

Epoch: 5| Step: 5
Training loss: 3.098160191609849
Validation loss: 2.5030884052673263

Epoch: 5| Step: 6
Training loss: 2.6989493339110764
Validation loss: 2.514532749036879

Epoch: 5| Step: 7
Training loss: 3.0479010003800444
Validation loss: 2.5167297147032808

Epoch: 5| Step: 8
Training loss: 2.15573611562868
Validation loss: 2.5037178328417067

Epoch: 5| Step: 9
Training loss: 2.5685999768481764
Validation loss: 2.515452938606917

Epoch: 5| Step: 10
Training loss: 3.6900899810984984
Validation loss: 2.5096177726126334

Epoch: 43| Step: 0
Training loss: 2.7192490218380763
Validation loss: 2.5194348485268807

Epoch: 5| Step: 1
Training loss: 2.9161523274638204
Validation loss: 2.5000470157017034

Epoch: 5| Step: 2
Training loss: 2.7552403891032093
Validation loss: 2.509227452801836

Epoch: 5| Step: 3
Training loss: 3.2203257138917247
Validation loss: 2.515340595477867

Epoch: 5| Step: 4
Training loss: 2.79713958682152
Validation loss: 2.5101599269483184

Epoch: 5| Step: 5
Training loss: 2.603751696266944
Validation loss: 2.5117464896664923

Epoch: 5| Step: 6
Training loss: 2.3319482325309244
Validation loss: 2.5064512099054843

Epoch: 5| Step: 7
Training loss: 2.8729550925919973
Validation loss: 2.5072765138555573

Epoch: 5| Step: 8
Training loss: 3.1149222573365276
Validation loss: 2.5085871913226834

Epoch: 5| Step: 9
Training loss: 2.7640392692801603
Validation loss: 2.5138555188856353

Epoch: 5| Step: 10
Training loss: 2.695532482955585
Validation loss: 2.512975411395397

Epoch: 44| Step: 0
Training loss: 3.1076353180839345
Validation loss: 2.5004840207950254

Epoch: 5| Step: 1
Training loss: 3.2438751608161436
Validation loss: 2.5188882012074876

Epoch: 5| Step: 2
Training loss: 2.6967811895257072
Validation loss: 2.5104794251665683

Epoch: 5| Step: 3
Training loss: 3.157330016622004
Validation loss: 2.518875309123187

Epoch: 5| Step: 4
Training loss: 2.2851747169726573
Validation loss: 2.514624192045007

Epoch: 5| Step: 5
Training loss: 2.7775818713299736
Validation loss: 2.5050998415499057

Epoch: 5| Step: 6
Training loss: 2.5917278818176714
Validation loss: 2.508851772473605

Epoch: 5| Step: 7
Training loss: 2.9608104346395776
Validation loss: 2.5059113028633204

Epoch: 5| Step: 8
Training loss: 2.9601118803789075
Validation loss: 2.5074452736484325

Epoch: 5| Step: 9
Training loss: 2.5238494064456414
Validation loss: 2.5044871571751526

Epoch: 5| Step: 10
Training loss: 2.1698501259163523
Validation loss: 2.5086364353510526

Epoch: 45| Step: 0
Training loss: 2.079585888427355
Validation loss: 2.505754615716065

Epoch: 5| Step: 1
Training loss: 2.613930477586673
Validation loss: 2.5053140935463865

Epoch: 5| Step: 2
Training loss: 2.436148537822302
Validation loss: 2.5090098479103533

Epoch: 5| Step: 3
Training loss: 3.2211499202104332
Validation loss: 2.504948327239744

Epoch: 5| Step: 4
Training loss: 2.6975534162632906
Validation loss: 2.5179303300920455

Epoch: 5| Step: 5
Training loss: 3.0015766451262547
Validation loss: 2.5101344564762997

Epoch: 5| Step: 6
Training loss: 2.4511380257871975
Validation loss: 2.50470726909114

Epoch: 5| Step: 7
Training loss: 2.4104596260834303
Validation loss: 2.507869216481539

Epoch: 5| Step: 8
Training loss: 2.8174451797960516
Validation loss: 2.5111261535443483

Epoch: 5| Step: 9
Training loss: 3.090742248224283
Validation loss: 2.494956079179844

Epoch: 5| Step: 10
Training loss: 3.812490619585348
Validation loss: 2.502844186273838

Epoch: 46| Step: 0
Training loss: 2.875313119837451
Validation loss: 2.4899430229872563

Epoch: 5| Step: 1
Training loss: 2.6401415500840066
Validation loss: 2.496870306111403

Epoch: 5| Step: 2
Training loss: 2.8907973779366904
Validation loss: 2.5061816872547134

Epoch: 5| Step: 3
Training loss: 3.0441075986374924
Validation loss: 2.496797460811853

Epoch: 5| Step: 4
Training loss: 2.5071258080119767
Validation loss: 2.511534816155644

Epoch: 5| Step: 5
Training loss: 3.1016581253953595
Validation loss: 2.506022340867555

Epoch: 5| Step: 6
Training loss: 2.6836387041927074
Validation loss: 2.5077509550022326

Epoch: 5| Step: 7
Training loss: 2.3127862907731727
Validation loss: 2.520444867691432

Epoch: 5| Step: 8
Training loss: 2.997557122304269
Validation loss: 2.5057948191795734

Epoch: 5| Step: 9
Training loss: 2.9217359540361314
Validation loss: 2.5057457730365105

Epoch: 5| Step: 10
Training loss: 2.6690091831396607
Validation loss: 2.5050021591080607

Epoch: 47| Step: 0
Training loss: 3.401484524381155
Validation loss: 2.500296218304569

Epoch: 5| Step: 1
Training loss: 3.2198203075808984
Validation loss: 2.508544422518174

Epoch: 5| Step: 2
Training loss: 2.784564068986521
Validation loss: 2.509759539097287

Epoch: 5| Step: 3
Training loss: 2.145937821396692
Validation loss: 2.5036091302105214

Epoch: 5| Step: 4
Training loss: 3.5520962503297184
Validation loss: 2.4969461719230646

Epoch: 5| Step: 5
Training loss: 2.343823647931418
Validation loss: 2.508497953411094

Epoch: 5| Step: 6
Training loss: 3.0544302361296145
Validation loss: 2.506022936760284

Epoch: 5| Step: 7
Training loss: 2.0470414421608742
Validation loss: 2.5187105946496713

Epoch: 5| Step: 8
Training loss: 2.78743963817707
Validation loss: 2.507737442890386

Epoch: 5| Step: 9
Training loss: 2.4609334309862194
Validation loss: 2.4962962982462016

Epoch: 5| Step: 10
Training loss: 2.452465284531521
Validation loss: 2.509683998312392

Epoch: 48| Step: 0
Training loss: 3.268622523898309
Validation loss: 2.5118533679068134

Epoch: 5| Step: 1
Training loss: 2.4511366640274765
Validation loss: 2.5044044581427003

Epoch: 5| Step: 2
Training loss: 3.041744353116612
Validation loss: 2.49589326682371

Epoch: 5| Step: 3
Training loss: 2.8331315211808636
Validation loss: 2.502857972167693

Epoch: 5| Step: 4
Training loss: 2.940745245231398
Validation loss: 2.496682373495383

Epoch: 5| Step: 5
Training loss: 2.0786842224761415
Validation loss: 2.5108179057608893

Epoch: 5| Step: 6
Training loss: 2.9462045790837346
Validation loss: 2.5151343647106454

Epoch: 5| Step: 7
Training loss: 2.363795100063762
Validation loss: 2.5049983776106024

Epoch: 5| Step: 8
Training loss: 2.9200017299385697
Validation loss: 2.504663096258693

Epoch: 5| Step: 9
Training loss: 2.8152872473614927
Validation loss: 2.5002232093020234

Epoch: 5| Step: 10
Training loss: 2.913025699699853
Validation loss: 2.511359890842856

Epoch: 49| Step: 0
Training loss: 2.7797695034168686
Validation loss: 2.5009769397205215

Epoch: 5| Step: 1
Training loss: 2.0161513003688496
Validation loss: 2.4921373939678406

Epoch: 5| Step: 2
Training loss: 2.5718028840606917
Validation loss: 2.5120183386183568

Epoch: 5| Step: 3
Training loss: 2.6385767289181543
Validation loss: 2.5034903106173276

Epoch: 5| Step: 4
Training loss: 3.2519985802941784
Validation loss: 2.4893522642325037

Epoch: 5| Step: 5
Training loss: 3.040847215050161
Validation loss: 2.5065777056381915

Epoch: 5| Step: 6
Training loss: 2.7695377064617532
Validation loss: 2.5017088638381035

Epoch: 5| Step: 7
Training loss: 3.1982848279600233
Validation loss: 2.4949730426044616

Epoch: 5| Step: 8
Training loss: 2.7231017614340085
Validation loss: 2.5000461830467455

Epoch: 5| Step: 9
Training loss: 2.5748043060013086
Validation loss: 2.496234358912102

Epoch: 5| Step: 10
Training loss: 2.9588556142054876
Validation loss: 2.5020924620051006

Epoch: 50| Step: 0
Training loss: 3.430694362768269
Validation loss: 2.492932094001983

Epoch: 5| Step: 1
Training loss: 2.4689155233399864
Validation loss: 2.4923031507803275

Epoch: 5| Step: 2
Training loss: 3.0167893449767638
Validation loss: 2.492690403984299

Epoch: 5| Step: 3
Training loss: 2.1975774518317475
Validation loss: 2.5024861064433135

Epoch: 5| Step: 4
Training loss: 2.448822427470093
Validation loss: 2.500161434416797

Epoch: 5| Step: 5
Training loss: 2.573015640970334
Validation loss: 2.5009044098286153

Epoch: 5| Step: 6
Training loss: 2.415016158782416
Validation loss: 2.4964821121624774

Epoch: 5| Step: 7
Training loss: 2.8646123896194458
Validation loss: 2.5048809999564408

Epoch: 5| Step: 8
Training loss: 2.5971610378826253
Validation loss: 2.5068336948057954

Epoch: 5| Step: 9
Training loss: 2.567163178693801
Validation loss: 2.5009854866202366

Epoch: 5| Step: 10
Training loss: 3.8260787788970916
Validation loss: 2.5040572724669827

Epoch: 51| Step: 0
Training loss: 3.3701427970538846
Validation loss: 2.490324496931263

Epoch: 5| Step: 1
Training loss: 3.451566732947127
Validation loss: 2.5092975905128596

Epoch: 5| Step: 2
Training loss: 2.7343698556034197
Validation loss: 2.4900624092334027

Epoch: 5| Step: 3
Training loss: 2.8299168763910214
Validation loss: 2.5033671642954975

Epoch: 5| Step: 4
Training loss: 2.5668493437059547
Validation loss: 2.501440235305048

Epoch: 5| Step: 5
Training loss: 2.2811660751164005
Validation loss: 2.500233069189593

Epoch: 5| Step: 6
Training loss: 2.9400656027189283
Validation loss: 2.5009942364503743

Epoch: 5| Step: 7
Training loss: 2.804800557272595
Validation loss: 2.499230597653036

Epoch: 5| Step: 8
Training loss: 2.540171032050856
Validation loss: 2.4973754365295044

Epoch: 5| Step: 9
Training loss: 2.2140277523310408
Validation loss: 2.490500204884315

Epoch: 5| Step: 10
Training loss: 2.526318679774455
Validation loss: 2.4998858025833224

Epoch: 52| Step: 0
Training loss: 3.3529005958573666
Validation loss: 2.4950186189708123

Epoch: 5| Step: 1
Training loss: 3.3099636228008817
Validation loss: 2.4993536677667945

Epoch: 5| Step: 2
Training loss: 2.607758895295662
Validation loss: 2.4920340144967468

Epoch: 5| Step: 3
Training loss: 2.5050452821030924
Validation loss: 2.5029892698081917

Epoch: 5| Step: 4
Training loss: 2.328282702948384
Validation loss: 2.5073769275820377

Epoch: 5| Step: 5
Training loss: 2.4533428897187797
Validation loss: 2.4894074868617

Epoch: 5| Step: 6
Training loss: 2.986616481234483
Validation loss: 2.493366754660031

Epoch: 5| Step: 7
Training loss: 2.7041608997473525
Validation loss: 2.5020669104327347

Epoch: 5| Step: 8
Training loss: 2.7884732005839243
Validation loss: 2.494068454448576

Epoch: 5| Step: 9
Training loss: 3.0134867464808637
Validation loss: 2.5016500554865453

Epoch: 5| Step: 10
Training loss: 2.188285795491028
Validation loss: 2.501200050564976

Epoch: 53| Step: 0
Training loss: 2.9319433047133128
Validation loss: 2.500017258369188

Epoch: 5| Step: 1
Training loss: 2.8482601744614797
Validation loss: 2.502625319530956

Epoch: 5| Step: 2
Training loss: 2.1480456185567
Validation loss: 2.5073742395877563

Epoch: 5| Step: 3
Training loss: 3.009406601214044
Validation loss: 2.5144125762472065

Epoch: 5| Step: 4
Training loss: 3.035001812200618
Validation loss: 2.5043450855765297

Epoch: 5| Step: 5
Training loss: 2.477660696782622
Validation loss: 2.490618630830309

Epoch: 5| Step: 6
Training loss: 2.564536611181508
Validation loss: 2.5005895001639638

Epoch: 5| Step: 7
Training loss: 2.5144963546244075
Validation loss: 2.492229937454625

Epoch: 5| Step: 8
Training loss: 2.8692822197446817
Validation loss: 2.503995527669451

Epoch: 5| Step: 9
Training loss: 2.639127227549547
Validation loss: 2.502869267960521

Epoch: 5| Step: 10
Training loss: 3.3348762914770265
Validation loss: 2.506554653425664

Epoch: 54| Step: 0
Training loss: 3.0065823504121036
Validation loss: 2.4937073318548935

Epoch: 5| Step: 1
Training loss: 2.277965637410044
Validation loss: 2.4931537026791384

Epoch: 5| Step: 2
Training loss: 2.8055494253849083
Validation loss: 2.5033878116500183

Epoch: 5| Step: 3
Training loss: 3.153486949762402
Validation loss: 2.5013641819298718

Epoch: 5| Step: 4
Training loss: 2.424836741192187
Validation loss: 2.5050460363420988

Epoch: 5| Step: 5
Training loss: 2.8649075041481216
Validation loss: 2.5100308305884473

Epoch: 5| Step: 6
Training loss: 2.695460130269652
Validation loss: 2.4937864550272053

Epoch: 5| Step: 7
Training loss: 2.5550707608332477
Validation loss: 2.494031467426491

Epoch: 5| Step: 8
Training loss: 3.2658584730292484
Validation loss: 2.4853452868448556

Epoch: 5| Step: 9
Training loss: 2.280627649148378
Validation loss: 2.5105202442917895

Epoch: 5| Step: 10
Training loss: 3.035031192122777
Validation loss: 2.5045216738817366

Epoch: 55| Step: 0
Training loss: 2.8650348284403577
Validation loss: 2.5091568400767432

Epoch: 5| Step: 1
Training loss: 3.196102874675697
Validation loss: 2.5091644548995227

Epoch: 5| Step: 2
Training loss: 3.1169509989191497
Validation loss: 2.4912523223999656

Epoch: 5| Step: 3
Training loss: 3.066172674722645
Validation loss: 2.4925585067596168

Epoch: 5| Step: 4
Training loss: 2.6738637917635777
Validation loss: 2.5003097506361773

Epoch: 5| Step: 5
Training loss: 2.690266626751009
Validation loss: 2.4904984709137072

Epoch: 5| Step: 6
Training loss: 2.6341331180832452
Validation loss: 2.496587879725217

Epoch: 5| Step: 7
Training loss: 2.762476103666353
Validation loss: 2.4961583050867087

Epoch: 5| Step: 8
Training loss: 2.2876647222859816
Validation loss: 2.47640522611801

Epoch: 5| Step: 9
Training loss: 2.3462724463273696
Validation loss: 2.500159583587088

Epoch: 5| Step: 10
Training loss: 2.7073258408936947
Validation loss: 2.4993126262636918

Epoch: 56| Step: 0
Training loss: 3.281540485421214
Validation loss: 2.4851183355505437

Epoch: 5| Step: 1
Training loss: 2.341997737717289
Validation loss: 2.496506331511298

Epoch: 5| Step: 2
Training loss: 3.1493024750095953
Validation loss: 2.492576309823812

Epoch: 5| Step: 3
Training loss: 2.5433848050943193
Validation loss: 2.485664398885185

Epoch: 5| Step: 4
Training loss: 3.0782802174737176
Validation loss: 2.4959505129850412

Epoch: 5| Step: 5
Training loss: 2.583457102938264
Validation loss: 2.4870584846470902

Epoch: 5| Step: 6
Training loss: 2.317926792321748
Validation loss: 2.496285028680952

Epoch: 5| Step: 7
Training loss: 2.5160076726969303
Validation loss: 2.49773446047089

Epoch: 5| Step: 8
Training loss: 2.6085623200868904
Validation loss: 2.4992690771398487

Epoch: 5| Step: 9
Training loss: 2.996035181142008
Validation loss: 2.491204122962037

Epoch: 5| Step: 10
Training loss: 2.8975799196690226
Validation loss: 2.4987054395605965

Epoch: 57| Step: 0
Training loss: 3.081958223548661
Validation loss: 2.4842037127175365

Epoch: 5| Step: 1
Training loss: 3.0138188621093267
Validation loss: 2.4935133930822606

Epoch: 5| Step: 2
Training loss: 2.473874146216982
Validation loss: 2.501516515930937

Epoch: 5| Step: 3
Training loss: 2.678663052399651
Validation loss: 2.4948470888145846

Epoch: 5| Step: 4
Training loss: 2.180522362307246
Validation loss: 2.4831682595755398

Epoch: 5| Step: 5
Training loss: 3.2763872717342686
Validation loss: 2.4991281111893815

Epoch: 5| Step: 6
Training loss: 2.4625912876926463
Validation loss: 2.4841703388791454

Epoch: 5| Step: 7
Training loss: 2.6319819648727703
Validation loss: 2.504888329952304

Epoch: 5| Step: 8
Training loss: 2.3691755451040954
Validation loss: 2.500135983081046

Epoch: 5| Step: 9
Training loss: 2.7707701845549906
Validation loss: 2.493207888950265

Epoch: 5| Step: 10
Training loss: 3.3282967823092897
Validation loss: 2.4984036188905905

Epoch: 58| Step: 0
Training loss: 3.2868871313387316
Validation loss: 2.490259983124906

Epoch: 5| Step: 1
Training loss: 2.7010203199699148
Validation loss: 2.4865628035323524

Epoch: 5| Step: 2
Training loss: 2.067863426509546
Validation loss: 2.489881148519932

Epoch: 5| Step: 3
Training loss: 2.949943322105985
Validation loss: 2.501368512115931

Epoch: 5| Step: 4
Training loss: 3.1900892026381604
Validation loss: 2.485369908694856

Epoch: 5| Step: 5
Training loss: 2.6663813637064733
Validation loss: 2.487766434059446

Epoch: 5| Step: 6
Training loss: 2.2693061126028224
Validation loss: 2.496829251510649

Epoch: 5| Step: 7
Training loss: 2.3308802948158847
Validation loss: 2.4974362384208924

Epoch: 5| Step: 8
Training loss: 2.554422253945623
Validation loss: 2.4881971288400018

Epoch: 5| Step: 9
Training loss: 3.0701312528504388
Validation loss: 2.4827503452303863

Epoch: 5| Step: 10
Training loss: 3.00334521388316
Validation loss: 2.4871946454849763

Epoch: 59| Step: 0
Training loss: 3.2142822961940456
Validation loss: 2.5060880938343475

Epoch: 5| Step: 1
Training loss: 2.659463083532027
Validation loss: 2.492968525573217

Epoch: 5| Step: 2
Training loss: 2.901710492511035
Validation loss: 2.5010358674276407

Epoch: 5| Step: 3
Training loss: 2.9154173945757282
Validation loss: 2.494374860394469

Epoch: 5| Step: 4
Training loss: 3.0709221698086817
Validation loss: 2.5083135115194892

Epoch: 5| Step: 5
Training loss: 2.1410353886736617
Validation loss: 2.492844073778752

Epoch: 5| Step: 6
Training loss: 2.5473656679024903
Validation loss: 2.503327446179598

Epoch: 5| Step: 7
Training loss: 2.648882353114628
Validation loss: 2.48779037964772

Epoch: 5| Step: 8
Training loss: 2.3391969324900685
Validation loss: 2.4958653088472174

Epoch: 5| Step: 9
Training loss: 2.8082764171715184
Validation loss: 2.48733528850463

Epoch: 5| Step: 10
Training loss: 2.986234874279857
Validation loss: 2.505267753320222

Epoch: 60| Step: 0
Training loss: 2.7936824713616715
Validation loss: 2.5098479967216933

Epoch: 5| Step: 1
Training loss: 3.17269480967626
Validation loss: 2.4980227506362764

Epoch: 5| Step: 2
Training loss: 2.188348986861913
Validation loss: 2.4835174611899284

Epoch: 5| Step: 3
Training loss: 2.172596324545522
Validation loss: 2.499128795920141

Epoch: 5| Step: 4
Training loss: 2.551123883776234
Validation loss: 2.4971440368477347

Epoch: 5| Step: 5
Training loss: 2.8495051238748053
Validation loss: 2.5037114946851413

Epoch: 5| Step: 6
Training loss: 3.2136857275098003
Validation loss: 2.497342007228154

Epoch: 5| Step: 7
Training loss: 2.903104987758157
Validation loss: 2.4939691989268797

Epoch: 5| Step: 8
Training loss: 2.407900454767003
Validation loss: 2.5009676403980388

Epoch: 5| Step: 9
Training loss: 2.7415995171236225
Validation loss: 2.482529544829449

Epoch: 5| Step: 10
Training loss: 3.100537954845261
Validation loss: 2.4944506099152823

Epoch: 61| Step: 0
Training loss: 3.0405741954922685
Validation loss: 2.4863806592536095

Epoch: 5| Step: 1
Training loss: 2.8102484273547255
Validation loss: 2.480950618929141

Epoch: 5| Step: 2
Training loss: 2.6346496149288665
Validation loss: 2.483200130811758

Epoch: 5| Step: 3
Training loss: 2.9569502986979215
Validation loss: 2.4830489682598365

Epoch: 5| Step: 4
Training loss: 2.7369036508311915
Validation loss: 2.480021487500853

Epoch: 5| Step: 5
Training loss: 2.280735323603554
Validation loss: 2.479268047575852

Epoch: 5| Step: 6
Training loss: 2.911419935888813
Validation loss: 2.4931693035761016

Epoch: 5| Step: 7
Training loss: 3.0378032517250695
Validation loss: 2.488613684510156

Epoch: 5| Step: 8
Training loss: 2.5847672410429245
Validation loss: 2.481474632385085

Epoch: 5| Step: 9
Training loss: 2.8204143643145567
Validation loss: 2.4977292813198386

Epoch: 5| Step: 10
Training loss: 2.143970298013344
Validation loss: 2.484756118539021

Epoch: 62| Step: 0
Training loss: 2.2162750839991237
Validation loss: 2.4881341064247575

Epoch: 5| Step: 1
Training loss: 3.195316081523054
Validation loss: 2.4848902730303344

Epoch: 5| Step: 2
Training loss: 2.597468456851474
Validation loss: 2.4939577857277437

Epoch: 5| Step: 3
Training loss: 2.590524713395039
Validation loss: 2.4814227892620866

Epoch: 5| Step: 4
Training loss: 3.2137870674265745
Validation loss: 2.4912485334092187

Epoch: 5| Step: 5
Training loss: 2.968735544269904
Validation loss: 2.4901898805784084

Epoch: 5| Step: 6
Training loss: 2.008332300251844
Validation loss: 2.4995606210644183

Epoch: 5| Step: 7
Training loss: 2.2273451115695373
Validation loss: 2.4911996917529313

Epoch: 5| Step: 8
Training loss: 2.801898983323675
Validation loss: 2.477269230823642

Epoch: 5| Step: 9
Training loss: 2.4918972312714387
Validation loss: 2.4920476225556816

Epoch: 5| Step: 10
Training loss: 3.6319466163980487
Validation loss: 2.4947190764952984

Epoch: 63| Step: 0
Training loss: 2.385074130011865
Validation loss: 2.4874031473887164

Epoch: 5| Step: 1
Training loss: 2.7673546506348146
Validation loss: 2.4868692837775046

Epoch: 5| Step: 2
Training loss: 2.9086795619014554
Validation loss: 2.4799179968208747

Epoch: 5| Step: 3
Training loss: 2.4018300073138406
Validation loss: 2.487371784528846

Epoch: 5| Step: 4
Training loss: 2.861825861945328
Validation loss: 2.490280355165323

Epoch: 5| Step: 5
Training loss: 2.4524838526949555
Validation loss: 2.491202482612906

Epoch: 5| Step: 6
Training loss: 2.8329218023288876
Validation loss: 2.484337169018393

Epoch: 5| Step: 7
Training loss: 2.6179564300128835
Validation loss: 2.4916867935410925

Epoch: 5| Step: 8
Training loss: 2.627562951986192
Validation loss: 2.483650432585334

Epoch: 5| Step: 9
Training loss: 2.8248837269848623
Validation loss: 2.4936572985119576

Epoch: 5| Step: 10
Training loss: 3.49284189395323
Validation loss: 2.4902238866596016

Epoch: 64| Step: 0
Training loss: 2.551351252803001
Validation loss: 2.4814221301229225

Epoch: 5| Step: 1
Training loss: 2.6486724479235177
Validation loss: 2.4886342132166357

Epoch: 5| Step: 2
Training loss: 2.980517385743413
Validation loss: 2.4807600841656527

Epoch: 5| Step: 3
Training loss: 2.5173532934542466
Validation loss: 2.4922417700258426

Epoch: 5| Step: 4
Training loss: 2.4648441369106275
Validation loss: 2.507536723613377

Epoch: 5| Step: 5
Training loss: 2.788786460402161
Validation loss: 2.487508841334132

Epoch: 5| Step: 6
Training loss: 2.653589150095101
Validation loss: 2.4864647640243387

Epoch: 5| Step: 7
Training loss: 3.0952822811340397
Validation loss: 2.4865839574540387

Epoch: 5| Step: 8
Training loss: 2.503362206734025
Validation loss: 2.4865370150521064

Epoch: 5| Step: 9
Training loss: 3.356266304416941
Validation loss: 2.4904389135145184

Epoch: 5| Step: 10
Training loss: 2.412829729386024
Validation loss: 2.482658698884516

Epoch: 65| Step: 0
Training loss: 2.6059174615958947
Validation loss: 2.4738218318843574

Epoch: 5| Step: 1
Training loss: 2.7705282937315743
Validation loss: 2.479101143627139

Epoch: 5| Step: 2
Training loss: 2.6022272034070846
Validation loss: 2.4900386934650593

Epoch: 5| Step: 3
Training loss: 2.4017265705559314
Validation loss: 2.475996158762206

Epoch: 5| Step: 4
Training loss: 3.0523246348602417
Validation loss: 2.4907319716935015

Epoch: 5| Step: 5
Training loss: 2.9682332442421235
Validation loss: 2.486666084163734

Epoch: 5| Step: 6
Training loss: 2.486093946098112
Validation loss: 2.491994095174853

Epoch: 5| Step: 7
Training loss: 2.4818958892750107
Validation loss: 2.4901286505483036

Epoch: 5| Step: 8
Training loss: 2.9803034785333047
Validation loss: 2.4767950338359968

Epoch: 5| Step: 9
Training loss: 2.52164842232985
Validation loss: 2.4917324999787342

Epoch: 5| Step: 10
Training loss: 3.199681957652503
Validation loss: 2.4822817008057814

Epoch: 66| Step: 0
Training loss: 2.5933137090115355
Validation loss: 2.48892318767997

Epoch: 5| Step: 1
Training loss: 2.7750964723605924
Validation loss: 2.4878444385136347

Epoch: 5| Step: 2
Training loss: 2.3418759801133127
Validation loss: 2.4834127927814973

Epoch: 5| Step: 3
Training loss: 2.4741924509735185
Validation loss: 2.5026172986186017

Epoch: 5| Step: 4
Training loss: 3.2140056124758662
Validation loss: 2.483543657796127

Epoch: 5| Step: 5
Training loss: 3.1112594644809466
Validation loss: 2.47128075527019

Epoch: 5| Step: 6
Training loss: 2.045377576709232
Validation loss: 2.4826187289776898

Epoch: 5| Step: 7
Training loss: 3.197975895402541
Validation loss: 2.4982775178945764

Epoch: 5| Step: 8
Training loss: 2.3563896643734905
Validation loss: 2.4813221739813907

Epoch: 5| Step: 9
Training loss: 3.151937125261474
Validation loss: 2.490820838480443

Epoch: 5| Step: 10
Training loss: 2.3664748123024597
Validation loss: 2.485032492817827

Epoch: 67| Step: 0
Training loss: 2.6889668387244052
Validation loss: 2.4965527362979207

Epoch: 5| Step: 1
Training loss: 2.901193136556163
Validation loss: 2.480431143666406

Epoch: 5| Step: 2
Training loss: 3.043137512620048
Validation loss: 2.4917540575616095

Epoch: 5| Step: 3
Training loss: 2.1816054352438363
Validation loss: 2.491004034590746

Epoch: 5| Step: 4
Training loss: 2.9468659773978723
Validation loss: 2.4846356993516534

Epoch: 5| Step: 5
Training loss: 2.9725349792527016
Validation loss: 2.483348415312715

Epoch: 5| Step: 6
Training loss: 2.396759738662398
Validation loss: 2.4903171724520763

Epoch: 5| Step: 7
Training loss: 3.1681605044655905
Validation loss: 2.483694697343324

Epoch: 5| Step: 8
Training loss: 2.4371686856976407
Validation loss: 2.4997493802858126

Epoch: 5| Step: 9
Training loss: 2.6744662206844705
Validation loss: 2.4979165532523995

Epoch: 5| Step: 10
Training loss: 2.49248672650169
Validation loss: 2.4707928906262793

Epoch: 68| Step: 0
Training loss: 3.278904685219352
Validation loss: 2.488391386136175

Epoch: 5| Step: 1
Training loss: 2.7350712353009037
Validation loss: 2.5000426657942945

Epoch: 5| Step: 2
Training loss: 2.5865425254914207
Validation loss: 2.482081431806126

Epoch: 5| Step: 3
Training loss: 2.7194764493107333
Validation loss: 2.4773817554107085

Epoch: 5| Step: 4
Training loss: 2.521121258226514
Validation loss: 2.485188921573262

Epoch: 5| Step: 5
Training loss: 2.6568317449472545
Validation loss: 2.4797574186769795

Epoch: 5| Step: 6
Training loss: 2.5643948318119953
Validation loss: 2.4867251030551727

Epoch: 5| Step: 7
Training loss: 3.051624215825772
Validation loss: 2.4949289173207605

Epoch: 5| Step: 8
Training loss: 2.930856049505394
Validation loss: 2.4822154282428843

Epoch: 5| Step: 9
Training loss: 2.5553081353518716
Validation loss: 2.483246332073194

Epoch: 5| Step: 10
Training loss: 2.310311802879836
Validation loss: 2.4838632572644634

Epoch: 69| Step: 0
Training loss: 2.596544897075122
Validation loss: 2.483114564532171

Epoch: 5| Step: 1
Training loss: 3.1906375776411005
Validation loss: 2.4817345032075493

Epoch: 5| Step: 2
Training loss: 3.1321678354497973
Validation loss: 2.4809381755384035

Epoch: 5| Step: 3
Training loss: 2.4308162900553665
Validation loss: 2.4780196053116232

Epoch: 5| Step: 4
Training loss: 2.911960037669873
Validation loss: 2.4780303785975444

Epoch: 5| Step: 5
Training loss: 2.3418361733696984
Validation loss: 2.4886707643612564

Epoch: 5| Step: 6
Training loss: 2.716282393380405
Validation loss: 2.485519061141859

Epoch: 5| Step: 7
Training loss: 2.7294495608254663
Validation loss: 2.492520843184038

Epoch: 5| Step: 8
Training loss: 2.5319212977033216
Validation loss: 2.4892305184301518

Epoch: 5| Step: 9
Training loss: 2.5063691070488887
Validation loss: 2.487249407876714

Epoch: 5| Step: 10
Training loss: 2.7937905123032656
Validation loss: 2.490517627902201

Epoch: 70| Step: 0
Training loss: 1.9758324763911446
Validation loss: 2.49309200866881

Epoch: 5| Step: 1
Training loss: 2.542424719492136
Validation loss: 2.4857106358206518

Epoch: 5| Step: 2
Training loss: 2.5569802358114866
Validation loss: 2.4919553320618895

Epoch: 5| Step: 3
Training loss: 2.8315675132175784
Validation loss: 2.4911552253783427

Epoch: 5| Step: 4
Training loss: 3.267086450372341
Validation loss: 2.4768405120473824

Epoch: 5| Step: 5
Training loss: 2.308487168383614
Validation loss: 2.4871328510736332

Epoch: 5| Step: 6
Training loss: 2.576277747303268
Validation loss: 2.4813626229789825

Epoch: 5| Step: 7
Training loss: 2.7419999539398257
Validation loss: 2.476166629048196

Epoch: 5| Step: 8
Training loss: 2.8292861156688285
Validation loss: 2.4859704330178047

Epoch: 5| Step: 9
Training loss: 2.9783100595046976
Validation loss: 2.4777524866065095

Epoch: 5| Step: 10
Training loss: 3.1684777618778783
Validation loss: 2.4881275544417982

Epoch: 71| Step: 0
Training loss: 2.5417314323136564
Validation loss: 2.473991956671229

Epoch: 5| Step: 1
Training loss: 2.774656387912544
Validation loss: 2.4885410023803947

Epoch: 5| Step: 2
Training loss: 3.1512329716054013
Validation loss: 2.484403749757372

Epoch: 5| Step: 3
Training loss: 2.6011071708801805
Validation loss: 2.477016227422639

Epoch: 5| Step: 4
Training loss: 2.6398547251061992
Validation loss: 2.4802304766534493

Epoch: 5| Step: 5
Training loss: 3.1650512657412846
Validation loss: 2.496417973139434

Epoch: 5| Step: 6
Training loss: 2.0815417660864752
Validation loss: 2.4720276414226023

Epoch: 5| Step: 7
Training loss: 3.019983492168252
Validation loss: 2.4852618162361666

Epoch: 5| Step: 8
Training loss: 2.3968237999492015
Validation loss: 2.4805668880009932

Epoch: 5| Step: 9
Training loss: 2.3382212214693854
Validation loss: 2.481989821185425

Epoch: 5| Step: 10
Training loss: 2.9969408014132166
Validation loss: 2.4839115527049156

Epoch: 72| Step: 0
Training loss: 2.605366260165617
Validation loss: 2.476003926303287

Epoch: 5| Step: 1
Training loss: 2.497733232912476
Validation loss: 2.468307310045031

Epoch: 5| Step: 2
Training loss: 2.8907111077757603
Validation loss: 2.4857889595218565

Epoch: 5| Step: 3
Training loss: 2.54127964345865
Validation loss: 2.4762918599958543

Epoch: 5| Step: 4
Training loss: 3.0979188516724983
Validation loss: 2.4819369564211273

Epoch: 5| Step: 5
Training loss: 2.7481364091224676
Validation loss: 2.4752884005785254

Epoch: 5| Step: 6
Training loss: 2.6084965123655413
Validation loss: 2.49286081298798

Epoch: 5| Step: 7
Training loss: 3.015108528777632
Validation loss: 2.4877166357309894

Epoch: 5| Step: 8
Training loss: 2.779748146806482
Validation loss: 2.5046384808536533

Epoch: 5| Step: 9
Training loss: 2.584193537659629
Validation loss: 2.4820638411188023

Epoch: 5| Step: 10
Training loss: 2.368114428442492
Validation loss: 2.4924854943016514

Epoch: 73| Step: 0
Training loss: 2.6878091501251236
Validation loss: 2.469044040766919

Epoch: 5| Step: 1
Training loss: 3.3664989077125633
Validation loss: 2.466357684578887

Epoch: 5| Step: 2
Training loss: 2.656685109124333
Validation loss: 2.490633029929689

Epoch: 5| Step: 3
Training loss: 2.906176002134644
Validation loss: 2.4899136957419215

Epoch: 5| Step: 4
Training loss: 2.9110410842853063
Validation loss: 2.4857375910693404

Epoch: 5| Step: 5
Training loss: 2.679257817198503
Validation loss: 2.490986229037428

Epoch: 5| Step: 6
Training loss: 2.3806186269533116
Validation loss: 2.490824731045158

Epoch: 5| Step: 7
Training loss: 2.4783777750216847
Validation loss: 2.4836528118206553

Epoch: 5| Step: 8
Training loss: 2.2905608081019793
Validation loss: 2.4786461269615847

Epoch: 5| Step: 9
Training loss: 2.3145767372053383
Validation loss: 2.4797169305723386

Epoch: 5| Step: 10
Training loss: 3.0234065879798955
Validation loss: 2.482580736988338

Epoch: 74| Step: 0
Training loss: 2.795909608424898
Validation loss: 2.4741308105310065

Epoch: 5| Step: 1
Training loss: 2.996915184921047
Validation loss: 2.4745545659819763

Epoch: 5| Step: 2
Training loss: 2.6406160614042964
Validation loss: 2.486437741907772

Epoch: 5| Step: 3
Training loss: 2.6706709798027983
Validation loss: 2.475565665113651

Epoch: 5| Step: 4
Training loss: 2.9274374497635014
Validation loss: 2.4764833223835114

Epoch: 5| Step: 5
Training loss: 2.6669874495048997
Validation loss: 2.4807068872995113

Epoch: 5| Step: 6
Training loss: 2.378698280401655
Validation loss: 2.473960933629965

Epoch: 5| Step: 7
Training loss: 2.8161256097446397
Validation loss: 2.4811938022531206

Epoch: 5| Step: 8
Training loss: 2.600283379883947
Validation loss: 2.4858615622666824

Epoch: 5| Step: 9
Training loss: 2.750765433857808
Validation loss: 2.478888992376651

Epoch: 5| Step: 10
Training loss: 2.5306283634886055
Validation loss: 2.470839067608882

Epoch: 75| Step: 0
Training loss: 2.6925790388005306
Validation loss: 2.4845553881036646

Epoch: 5| Step: 1
Training loss: 2.629179488290354
Validation loss: 2.4836665535373723

Epoch: 5| Step: 2
Training loss: 2.3505032710653304
Validation loss: 2.4960988462716633

Epoch: 5| Step: 3
Training loss: 2.5812417351172448
Validation loss: 2.4833121357957535

Epoch: 5| Step: 4
Training loss: 2.8851862699515425
Validation loss: 2.4847831450148714

Epoch: 5| Step: 5
Training loss: 2.6565259902288694
Validation loss: 2.47973946827057

Epoch: 5| Step: 6
Training loss: 2.5773079242049124
Validation loss: 2.478476071325551

Epoch: 5| Step: 7
Training loss: 3.1432556977162367
Validation loss: 2.4753394369671944

Epoch: 5| Step: 8
Training loss: 2.707774667095863
Validation loss: 2.4852371159491913

Epoch: 5| Step: 9
Training loss: 2.6913764852309137
Validation loss: 2.4956281089878916

Epoch: 5| Step: 10
Training loss: 2.9186053417879716
Validation loss: 2.469492069056622

Epoch: 76| Step: 0
Training loss: 2.784649603560889
Validation loss: 2.485690727568805

Epoch: 5| Step: 1
Training loss: 2.5906542032066033
Validation loss: 2.48621987622246

Epoch: 5| Step: 2
Training loss: 2.96425923452188
Validation loss: 2.47724942652206

Epoch: 5| Step: 3
Training loss: 2.343301246915378
Validation loss: 2.4885318378984493

Epoch: 5| Step: 4
Training loss: 2.51428281625977
Validation loss: 2.469078214527662

Epoch: 5| Step: 5
Training loss: 2.8037572821676897
Validation loss: 2.481609832038596

Epoch: 5| Step: 6
Training loss: 2.6370109791764
Validation loss: 2.4833635461602803

Epoch: 5| Step: 7
Training loss: 2.49169237725337
Validation loss: 2.4848928233708736

Epoch: 5| Step: 8
Training loss: 2.9976888337202436
Validation loss: 2.4760737440350926

Epoch: 5| Step: 9
Training loss: 2.3533064246688
Validation loss: 2.4753139510105684

Epoch: 5| Step: 10
Training loss: 3.1862931304203426
Validation loss: 2.4758295628506217

Epoch: 77| Step: 0
Training loss: 2.817784494627011
Validation loss: 2.4735738610744344

Epoch: 5| Step: 1
Training loss: 1.8147087450920465
Validation loss: 2.479081356545184

Epoch: 5| Step: 2
Training loss: 2.297395400695368
Validation loss: 2.4778067386053713

Epoch: 5| Step: 3
Training loss: 2.8019913063867445
Validation loss: 2.4635798985010586

Epoch: 5| Step: 4
Training loss: 3.068262245588313
Validation loss: 2.469804123630438

Epoch: 5| Step: 5
Training loss: 2.748978164869218
Validation loss: 2.489906394765012

Epoch: 5| Step: 6
Training loss: 2.3903411497258618
Validation loss: 2.4714346126490248

Epoch: 5| Step: 7
Training loss: 2.7457992374076508
Validation loss: 2.4773354333941757

Epoch: 5| Step: 8
Training loss: 2.5909480391621487
Validation loss: 2.4860355056880206

Epoch: 5| Step: 9
Training loss: 3.2733053758855544
Validation loss: 2.4737663970912713

Epoch: 5| Step: 10
Training loss: 2.8811625899752773
Validation loss: 2.480652668240152

Epoch: 78| Step: 0
Training loss: 3.0349106854992485
Validation loss: 2.486312934861244

Epoch: 5| Step: 1
Training loss: 3.1109262555320076
Validation loss: 2.4715339526698146

Epoch: 5| Step: 2
Training loss: 2.2434391157009217
Validation loss: 2.4773916244557146

Epoch: 5| Step: 3
Training loss: 3.0921586693127594
Validation loss: 2.4725487464109173

Epoch: 5| Step: 4
Training loss: 3.1839927376515744
Validation loss: 2.485243343394865

Epoch: 5| Step: 5
Training loss: 2.87902997396752
Validation loss: 2.4725054236916955

Epoch: 5| Step: 6
Training loss: 2.1955548895879056
Validation loss: 2.4710872288184285

Epoch: 5| Step: 7
Training loss: 2.489576353012791
Validation loss: 2.4756329125459553

Epoch: 5| Step: 8
Training loss: 2.42488432932792
Validation loss: 2.4792100977193496

Epoch: 5| Step: 9
Training loss: 2.3458126909647556
Validation loss: 2.4787099413591025

Epoch: 5| Step: 10
Training loss: 2.545102678787017
Validation loss: 2.4750646640537615

Epoch: 79| Step: 0
Training loss: 2.7295367351574917
Validation loss: 2.4796162807082722

Epoch: 5| Step: 1
Training loss: 2.6627206415440554
Validation loss: 2.475922010754543

Epoch: 5| Step: 2
Training loss: 2.5578523682858547
Validation loss: 2.4760971690623768

Epoch: 5| Step: 3
Training loss: 2.371501252854668
Validation loss: 2.4686504399494686

Epoch: 5| Step: 4
Training loss: 2.4237461860079805
Validation loss: 2.4843351062067014

Epoch: 5| Step: 5
Training loss: 2.557056879788678
Validation loss: 2.464515927505936

Epoch: 5| Step: 6
Training loss: 2.852769235781624
Validation loss: 2.475137267538011

Epoch: 5| Step: 7
Training loss: 2.715600129289072
Validation loss: 2.470584034962845

Epoch: 5| Step: 8
Training loss: 2.965930925353334
Validation loss: 2.455559383693677

Epoch: 5| Step: 9
Training loss: 2.9307841372019388
Validation loss: 2.4696686648775166

Epoch: 5| Step: 10
Training loss: 2.841708613857046
Validation loss: 2.47615408707265

Epoch: 80| Step: 0
Training loss: 2.794708776980586
Validation loss: 2.484878170225691

Epoch: 5| Step: 1
Training loss: 1.8465220415838344
Validation loss: 2.4819980858995736

Epoch: 5| Step: 2
Training loss: 2.7960467257599713
Validation loss: 2.474656358223924

Epoch: 5| Step: 3
Training loss: 2.967864054946759
Validation loss: 2.4843520317375454

Epoch: 5| Step: 4
Training loss: 2.2815844147009443
Validation loss: 2.46671641842002

Epoch: 5| Step: 5
Training loss: 2.820288322535305
Validation loss: 2.4610756601725883

Epoch: 5| Step: 6
Training loss: 3.364093110990185
Validation loss: 2.472531911161553

Epoch: 5| Step: 7
Training loss: 2.223748500195191
Validation loss: 2.4760508364736453

Epoch: 5| Step: 8
Training loss: 2.8085688774270268
Validation loss: 2.4584525041041485

Epoch: 5| Step: 9
Training loss: 2.9240641017728826
Validation loss: 2.480694950620271

Epoch: 5| Step: 10
Training loss: 2.456104485858222
Validation loss: 2.486810594586166

Epoch: 81| Step: 0
Training loss: 2.399130258322571
Validation loss: 2.4703487724654956

Epoch: 5| Step: 1
Training loss: 2.3200268296630635
Validation loss: 2.4799278909204405

Epoch: 5| Step: 2
Training loss: 2.19246002265212
Validation loss: 2.4818690296841424

Epoch: 5| Step: 3
Training loss: 2.4309261390704
Validation loss: 2.4853008348654386

Epoch: 5| Step: 4
Training loss: 2.950924977263154
Validation loss: 2.4697624208513607

Epoch: 5| Step: 5
Training loss: 2.643643251252441
Validation loss: 2.4799841297169807

Epoch: 5| Step: 6
Training loss: 3.4450208752446745
Validation loss: 2.4769762916992075

Epoch: 5| Step: 7
Training loss: 2.8917972971261343
Validation loss: 2.485830299588148

Epoch: 5| Step: 8
Training loss: 2.8402955589162744
Validation loss: 2.474237046574206

Epoch: 5| Step: 9
Training loss: 2.476231501749452
Validation loss: 2.4731496784398095

Epoch: 5| Step: 10
Training loss: 2.8123179058890515
Validation loss: 2.4866360527810283

Epoch: 82| Step: 0
Training loss: 2.6972493606949897
Validation loss: 2.4847847658718596

Epoch: 5| Step: 1
Training loss: 2.5941542344898805
Validation loss: 2.4741017383058836

Epoch: 5| Step: 2
Training loss: 2.885400948785785
Validation loss: 2.4703419989663224

Epoch: 5| Step: 3
Training loss: 2.540769877414483
Validation loss: 2.4848896055257237

Epoch: 5| Step: 4
Training loss: 2.4391647913692847
Validation loss: 2.4796508804967967

Epoch: 5| Step: 5
Training loss: 3.0894597679391853
Validation loss: 2.475782963275671

Epoch: 5| Step: 6
Training loss: 2.5726192987211194
Validation loss: 2.4734197988748607

Epoch: 5| Step: 7
Training loss: 2.3344463577496684
Validation loss: 2.467718683388343

Epoch: 5| Step: 8
Training loss: 2.759219407806759
Validation loss: 2.4736697210712193

Epoch: 5| Step: 9
Training loss: 3.241487064305752
Validation loss: 2.480846288641423

Epoch: 5| Step: 10
Training loss: 2.3017235269044414
Validation loss: 2.4745081806811435

Epoch: 83| Step: 0
Training loss: 2.4362157715320345
Validation loss: 2.46345068390614

Epoch: 5| Step: 1
Training loss: 2.711077507866957
Validation loss: 2.478837057945226

Epoch: 5| Step: 2
Training loss: 2.105601686941358
Validation loss: 2.486884616900765

Epoch: 5| Step: 3
Training loss: 2.458945009675473
Validation loss: 2.465101117437568

Epoch: 5| Step: 4
Training loss: 3.169057562534288
Validation loss: 2.4709845249105467

Epoch: 5| Step: 5
Training loss: 3.0906037024216424
Validation loss: 2.479059050711155

Epoch: 5| Step: 6
Training loss: 2.505406636870881
Validation loss: 2.4746533933096764

Epoch: 5| Step: 7
Training loss: 3.0770830433784475
Validation loss: 2.4703462237141944

Epoch: 5| Step: 8
Training loss: 2.934587048881143
Validation loss: 2.472048610684

Epoch: 5| Step: 9
Training loss: 2.04843685752457
Validation loss: 2.469193675832021

Epoch: 5| Step: 10
Training loss: 2.7049263481224566
Validation loss: 2.477162818485872

Epoch: 84| Step: 0
Training loss: 2.5268822179290695
Validation loss: 2.479062765261747

Epoch: 5| Step: 1
Training loss: 2.1980871944956397
Validation loss: 2.4742249911280627

Epoch: 5| Step: 2
Training loss: 2.7733058844485656
Validation loss: 2.4790335823118155

Epoch: 5| Step: 3
Training loss: 3.430538271827419
Validation loss: 2.476263554407022

Epoch: 5| Step: 4
Training loss: 2.6601536508511074
Validation loss: 2.4820758512616092

Epoch: 5| Step: 5
Training loss: 2.5117592815730005
Validation loss: 2.472048855428038

Epoch: 5| Step: 6
Training loss: 1.917446772447112
Validation loss: 2.471635148442229

Epoch: 5| Step: 7
Training loss: 2.8097808408968215
Validation loss: 2.4530094062800036

Epoch: 5| Step: 8
Training loss: 2.6335417419567166
Validation loss: 2.4784159028115287

Epoch: 5| Step: 9
Training loss: 3.1779334926764142
Validation loss: 2.4646307048725267

Epoch: 5| Step: 10
Training loss: 2.521904447211083
Validation loss: 2.4605598364359733

Epoch: 85| Step: 0
Training loss: 2.253282378013714
Validation loss: 2.4740619969737234

Epoch: 5| Step: 1
Training loss: 2.6914688789599466
Validation loss: 2.469163503060871

Epoch: 5| Step: 2
Training loss: 2.791464319060192
Validation loss: 2.4742774948349076

Epoch: 5| Step: 3
Training loss: 2.414033068628743
Validation loss: 2.475268877675037

Epoch: 5| Step: 4
Training loss: 3.0913245972403045
Validation loss: 2.4702634106969477

Epoch: 5| Step: 5
Training loss: 2.5750413428385728
Validation loss: 2.4727325694650006

Epoch: 5| Step: 6
Training loss: 3.0741075352639666
Validation loss: 2.46315917587169

Epoch: 5| Step: 7
Training loss: 2.4128662898630684
Validation loss: 2.4848023383286404

Epoch: 5| Step: 8
Training loss: 2.649975085591212
Validation loss: 2.4683503190469476

Epoch: 5| Step: 9
Training loss: 2.9173344710462303
Validation loss: 2.482649130618078

Epoch: 5| Step: 10
Training loss: 2.5903372316011652
Validation loss: 2.475191033097508

Epoch: 86| Step: 0
Training loss: 3.127256570516227
Validation loss: 2.4723849013950714

Epoch: 5| Step: 1
Training loss: 2.865710800700153
Validation loss: 2.4714999212607913

Epoch: 5| Step: 2
Training loss: 2.415730810377176
Validation loss: 2.469656387824489

Epoch: 5| Step: 3
Training loss: 2.600862059364791
Validation loss: 2.4774915762013343

Epoch: 5| Step: 4
Training loss: 2.057118417390332
Validation loss: 2.4681319531023362

Epoch: 5| Step: 5
Training loss: 2.5819327238967245
Validation loss: 2.473254678566395

Epoch: 5| Step: 6
Training loss: 2.760373231558088
Validation loss: 2.487519399866481

Epoch: 5| Step: 7
Training loss: 2.7153345336792776
Validation loss: 2.463078645221691

Epoch: 5| Step: 8
Training loss: 2.7912179007352265
Validation loss: 2.477746619021536

Epoch: 5| Step: 9
Training loss: 2.6840107467481698
Validation loss: 2.476816465772273

Epoch: 5| Step: 10
Training loss: 2.741314697476261
Validation loss: 2.472827812048689

Epoch: 87| Step: 0
Training loss: 3.142841373131562
Validation loss: 2.4845700823618424

Epoch: 5| Step: 1
Training loss: 3.179699946948534
Validation loss: 2.469228102408701

Epoch: 5| Step: 2
Training loss: 2.8426107283391184
Validation loss: 2.482759739117534

Epoch: 5| Step: 3
Training loss: 2.4185827705079377
Validation loss: 2.4671224034535597

Epoch: 5| Step: 4
Training loss: 3.0032105750237643
Validation loss: 2.4750571960158

Epoch: 5| Step: 5
Training loss: 2.3007807318746765
Validation loss: 2.454661899298243

Epoch: 5| Step: 6
Training loss: 2.344912024761191
Validation loss: 2.4742025959216174

Epoch: 5| Step: 7
Training loss: 2.990821626232324
Validation loss: 2.4734602252603235

Epoch: 5| Step: 8
Training loss: 2.3672962730269123
Validation loss: 2.466998528713934

Epoch: 5| Step: 9
Training loss: 1.8924088062804745
Validation loss: 2.4753429302875984

Epoch: 5| Step: 10
Training loss: 2.6912699140280574
Validation loss: 2.4717171967278095

Epoch: 88| Step: 0
Training loss: 2.768735698723294
Validation loss: 2.473254793622926

Epoch: 5| Step: 1
Training loss: 2.884038070226386
Validation loss: 2.461976559657418

Epoch: 5| Step: 2
Training loss: 2.2313139962387165
Validation loss: 2.460277476546683

Epoch: 5| Step: 3
Training loss: 3.3677098694379053
Validation loss: 2.4712763651025482

Epoch: 5| Step: 4
Training loss: 2.3365717508444894
Validation loss: 2.4686990039231884

Epoch: 5| Step: 5
Training loss: 2.591191144128537
Validation loss: 2.472018276754344

Epoch: 5| Step: 6
Training loss: 2.5878909013855984
Validation loss: 2.472648285318666

Epoch: 5| Step: 7
Training loss: 2.7975106822228364
Validation loss: 2.4793361422515985

Epoch: 5| Step: 8
Training loss: 2.9908061611428907
Validation loss: 2.474646077353034

Epoch: 5| Step: 9
Training loss: 1.9642610387366926
Validation loss: 2.4666198111437656

Epoch: 5| Step: 10
Training loss: 2.4726912509556245
Validation loss: 2.4600661556103334

Epoch: 89| Step: 0
Training loss: 2.850948905248804
Validation loss: 2.478151978420098

Epoch: 5| Step: 1
Training loss: 2.7197334001821587
Validation loss: 2.472176359629285

Epoch: 5| Step: 2
Training loss: 2.8711834329105343
Validation loss: 2.469716521653109

Epoch: 5| Step: 3
Training loss: 2.450817407761444
Validation loss: 2.474018490399408

Epoch: 5| Step: 4
Training loss: 2.2708550431733228
Validation loss: 2.475415546323161

Epoch: 5| Step: 5
Training loss: 2.9045487213224934
Validation loss: 2.4674269938503817

Epoch: 5| Step: 6
Training loss: 2.714939296879801
Validation loss: 2.474088772420596

Epoch: 5| Step: 7
Training loss: 2.5337846098889902
Validation loss: 2.454553613866334

Epoch: 5| Step: 8
Training loss: 2.4322274721701906
Validation loss: 2.4762046159170734

Epoch: 5| Step: 9
Training loss: 2.395268735840413
Validation loss: 2.479497069749367

Epoch: 5| Step: 10
Training loss: 3.2581542496765032
Validation loss: 2.467318703414365

Epoch: 90| Step: 0
Training loss: 3.111706037253563
Validation loss: 2.463394518275023

Epoch: 5| Step: 1
Training loss: 2.583674797953173
Validation loss: 2.4760904930816

Epoch: 5| Step: 2
Training loss: 2.972925883231861
Validation loss: 2.461440494332749

Epoch: 5| Step: 3
Training loss: 2.2960738257458417
Validation loss: 2.4871827909639532

Epoch: 5| Step: 4
Training loss: 2.2960154683259946
Validation loss: 2.474740909618797

Epoch: 5| Step: 5
Training loss: 2.7265497333041906
Validation loss: 2.4683994456065186

Epoch: 5| Step: 6
Training loss: 2.3277512832849467
Validation loss: 2.474612557522077

Epoch: 5| Step: 7
Training loss: 2.6357087185838175
Validation loss: 2.470534387342318

Epoch: 5| Step: 8
Training loss: 3.0240261874906764
Validation loss: 2.46249642478842

Epoch: 5| Step: 9
Training loss: 2.3746415921871695
Validation loss: 2.461269055136216

Epoch: 5| Step: 10
Training loss: 2.941209439485557
Validation loss: 2.4702064233756347

Epoch: 91| Step: 0
Training loss: 2.749872117970516
Validation loss: 2.4639702338546376

Epoch: 5| Step: 1
Training loss: 2.3799838927869947
Validation loss: 2.4642201916431086

Epoch: 5| Step: 2
Training loss: 2.739498809168084
Validation loss: 2.47023198174627

Epoch: 5| Step: 3
Training loss: 2.2225393254477233
Validation loss: 2.4735761297783796

Epoch: 5| Step: 4
Training loss: 2.2875807200713782
Validation loss: 2.4656639660523876

Epoch: 5| Step: 5
Training loss: 2.982046926895441
Validation loss: 2.458170177481475

Epoch: 5| Step: 6
Training loss: 2.83558471839415
Validation loss: 2.471301856390096

Epoch: 5| Step: 7
Training loss: 2.6453025966398074
Validation loss: 2.4750538483387645

Epoch: 5| Step: 8
Training loss: 2.796512601592469
Validation loss: 2.465698501695592

Epoch: 5| Step: 9
Training loss: 2.831287786303192
Validation loss: 2.472509246071136

Epoch: 5| Step: 10
Training loss: 2.819818511560783
Validation loss: 2.4691514560681056

Epoch: 92| Step: 0
Training loss: 2.9506208510027294
Validation loss: 2.4539419266180524

Epoch: 5| Step: 1
Training loss: 1.7656303338164387
Validation loss: 2.4588587661557897

Epoch: 5| Step: 2
Training loss: 2.7226614165291276
Validation loss: 2.4822625236330187

Epoch: 5| Step: 3
Training loss: 2.4645247215165664
Validation loss: 2.474908388848953

Epoch: 5| Step: 4
Training loss: 2.6007714887569335
Validation loss: 2.4550935637378686

Epoch: 5| Step: 5
Training loss: 2.162105625773059
Validation loss: 2.4675122864705075

Epoch: 5| Step: 6
Training loss: 2.7458978748599074
Validation loss: 2.4784990795596293

Epoch: 5| Step: 7
Training loss: 2.4466805333291126
Validation loss: 2.484791836861

Epoch: 5| Step: 8
Training loss: 2.598527392256407
Validation loss: 2.460896479324484

Epoch: 5| Step: 9
Training loss: 3.5475443069884816
Validation loss: 2.467189585399169

Epoch: 5| Step: 10
Training loss: 2.936846234232877
Validation loss: 2.4654180093324825

Epoch: 93| Step: 0
Training loss: 2.801754238462778
Validation loss: 2.478711168513119

Epoch: 5| Step: 1
Training loss: 3.0470551266367307
Validation loss: 2.4763651718405617

Epoch: 5| Step: 2
Training loss: 1.9516328528667772
Validation loss: 2.465721405622096

Epoch: 5| Step: 3
Training loss: 2.722377155289265
Validation loss: 2.4675404711512297

Epoch: 5| Step: 4
Training loss: 3.0113293981159748
Validation loss: 2.4561998262979374

Epoch: 5| Step: 5
Training loss: 2.6337384596374016
Validation loss: 2.4680434857147273

Epoch: 5| Step: 6
Training loss: 1.8962238733934724
Validation loss: 2.4761544949932768

Epoch: 5| Step: 7
Training loss: 2.8957306182721196
Validation loss: 2.455722418959504

Epoch: 5| Step: 8
Training loss: 3.2040726911225903
Validation loss: 2.4647099902121727

Epoch: 5| Step: 9
Training loss: 2.046672082991169
Validation loss: 2.4660075583648875

Epoch: 5| Step: 10
Training loss: 2.7061772396182375
Validation loss: 2.4670134574419036

Epoch: 94| Step: 0
Training loss: 2.0211039751912656
Validation loss: 2.469072780066423

Epoch: 5| Step: 1
Training loss: 2.416734913706392
Validation loss: 2.457090858119735

Epoch: 5| Step: 2
Training loss: 3.0246196476179197
Validation loss: 2.462273270908029

Epoch: 5| Step: 3
Training loss: 3.094152867452267
Validation loss: 2.4744832041784037

Epoch: 5| Step: 4
Training loss: 2.733969260494324
Validation loss: 2.4562690265077984

Epoch: 5| Step: 5
Training loss: 2.34482976836457
Validation loss: 2.4727546358560435

Epoch: 5| Step: 6
Training loss: 2.954639510678337
Validation loss: 2.4644930373417724

Epoch: 5| Step: 7
Training loss: 2.461779544216441
Validation loss: 2.469030677641871

Epoch: 5| Step: 8
Training loss: 2.9012260081668693
Validation loss: 2.463856296618392

Epoch: 5| Step: 9
Training loss: 2.606387867014016
Validation loss: 2.4646551347586176

Epoch: 5| Step: 10
Training loss: 2.5668098678109086
Validation loss: 2.4784050417265817

Epoch: 95| Step: 0
Training loss: 2.671507782268095
Validation loss: 2.462815006093165

Epoch: 5| Step: 1
Training loss: 2.3480735065255343
Validation loss: 2.461283293671433

Epoch: 5| Step: 2
Training loss: 2.4661034026854627
Validation loss: 2.4673906589407775

Epoch: 5| Step: 3
Training loss: 2.9147644015809635
Validation loss: 2.4608235963243366

Epoch: 5| Step: 4
Training loss: 2.84871064852308
Validation loss: 2.4768625656465444

Epoch: 5| Step: 5
Training loss: 2.438861857732474
Validation loss: 2.4503943662277354

Epoch: 5| Step: 6
Training loss: 2.9100095980771057
Validation loss: 2.4619006617149637

Epoch: 5| Step: 7
Training loss: 3.0762151224638523
Validation loss: 2.4676293991474703

Epoch: 5| Step: 8
Training loss: 2.3255659542569154
Validation loss: 2.4578970669223885

Epoch: 5| Step: 9
Training loss: 2.552549628392701
Validation loss: 2.4592211301951004

Epoch: 5| Step: 10
Training loss: 2.5189185528643745
Validation loss: 2.453832505114283

Epoch: 96| Step: 0
Training loss: 2.479709106428099
Validation loss: 2.4728622673401257

Epoch: 5| Step: 1
Training loss: 2.6757353618613124
Validation loss: 2.464272630745499

Epoch: 5| Step: 2
Training loss: 2.2050187649436594
Validation loss: 2.4700627832569473

Epoch: 5| Step: 3
Training loss: 3.142275703819752
Validation loss: 2.463157144241484

Epoch: 5| Step: 4
Training loss: 2.697482001639663
Validation loss: 2.4607041885924614

Epoch: 5| Step: 5
Training loss: 2.183595715352984
Validation loss: 2.4519685488695577

Epoch: 5| Step: 6
Training loss: 2.8408829205781463
Validation loss: 2.4830579124164402

Epoch: 5| Step: 7
Training loss: 2.3550401490630115
Validation loss: 2.4623984406119184

Epoch: 5| Step: 8
Training loss: 2.7432420229944006
Validation loss: 2.4779632510606406

Epoch: 5| Step: 9
Training loss: 2.910645964720856
Validation loss: 2.47013810867406

Epoch: 5| Step: 10
Training loss: 2.7789024990036095
Validation loss: 2.473788832517878

Epoch: 97| Step: 0
Training loss: 2.4620696839140206
Validation loss: 2.46071501737158

Epoch: 5| Step: 1
Training loss: 2.669369152708444
Validation loss: 2.4526307874205595

Epoch: 5| Step: 2
Training loss: 2.7871424800668363
Validation loss: 2.4727771001604926

Epoch: 5| Step: 3
Training loss: 2.6533016222427843
Validation loss: 2.4681833233928496

Epoch: 5| Step: 4
Training loss: 2.2051819201656335
Validation loss: 2.4745780209300783

Epoch: 5| Step: 5
Training loss: 2.873594023199599
Validation loss: 2.4840908144684946

Epoch: 5| Step: 6
Training loss: 2.4323016758017815
Validation loss: 2.4860515286771276

Epoch: 5| Step: 7
Training loss: 2.6526509754528207
Validation loss: 2.4782862571400397

Epoch: 5| Step: 8
Training loss: 2.6108231780285607
Validation loss: 2.4660326259086767

Epoch: 5| Step: 9
Training loss: 3.1018547477729737
Validation loss: 2.4660725527724883

Epoch: 5| Step: 10
Training loss: 2.560621829357982
Validation loss: 2.4686980059646912

Epoch: 98| Step: 0
Training loss: 2.992714937501324
Validation loss: 2.451527694358555

Epoch: 5| Step: 1
Training loss: 2.804601811452168
Validation loss: 2.4608122627566886

Epoch: 5| Step: 2
Training loss: 2.5932236102835655
Validation loss: 2.4630295353557807

Epoch: 5| Step: 3
Training loss: 2.7558512427347233
Validation loss: 2.4556855141609866

Epoch: 5| Step: 4
Training loss: 2.3646135594344853
Validation loss: 2.475613404786011

Epoch: 5| Step: 5
Training loss: 2.9536038772400506
Validation loss: 2.459819903887396

Epoch: 5| Step: 6
Training loss: 2.250602747397465
Validation loss: 2.4551880631964087

Epoch: 5| Step: 7
Training loss: 2.789580395910432
Validation loss: 2.4674078066826124

Epoch: 5| Step: 8
Training loss: 2.2670212225271893
Validation loss: 2.4633171622530785

Epoch: 5| Step: 9
Training loss: 3.2146578951726115
Validation loss: 2.463039241769486

Epoch: 5| Step: 10
Training loss: 1.6592949282190543
Validation loss: 2.459022486556047

Epoch: 99| Step: 0
Training loss: 2.624306269211504
Validation loss: 2.4704402206695764

Epoch: 5| Step: 1
Training loss: 3.0783778052911854
Validation loss: 2.456468242944373

Epoch: 5| Step: 2
Training loss: 2.3656893480788574
Validation loss: 2.457500586466603

Epoch: 5| Step: 3
Training loss: 1.7980991340184935
Validation loss: 2.4690497421372646

Epoch: 5| Step: 4
Training loss: 2.9537754856193454
Validation loss: 2.471781078515657

Epoch: 5| Step: 5
Training loss: 2.592016353096415
Validation loss: 2.4745565374908103

Epoch: 5| Step: 6
Training loss: 2.661534427119887
Validation loss: 2.455203585820432

Epoch: 5| Step: 7
Training loss: 2.4382381788640166
Validation loss: 2.462689513513901

Epoch: 5| Step: 8
Training loss: 3.1288113049830826
Validation loss: 2.4842375917693698

Epoch: 5| Step: 9
Training loss: 2.732874344070901
Validation loss: 2.4703989312729906

Epoch: 5| Step: 10
Training loss: 2.5887408317429355
Validation loss: 2.462478311077869

Epoch: 100| Step: 0
Training loss: 2.827075911202711
Validation loss: 2.457507539319741

Epoch: 5| Step: 1
Training loss: 2.649887543217489
Validation loss: 2.4658144009264547

Epoch: 5| Step: 2
Training loss: 2.5834339388874374
Validation loss: 2.4821272025394414

Epoch: 5| Step: 3
Training loss: 2.559239802440178
Validation loss: 2.456830646003726

Epoch: 5| Step: 4
Training loss: 2.7493283578671646
Validation loss: 2.4656507062581148

Epoch: 5| Step: 5
Training loss: 2.482031718762251
Validation loss: 2.4669180776715223

Epoch: 5| Step: 6
Training loss: 1.8480782218537086
Validation loss: 2.4657852628790264

Epoch: 5| Step: 7
Training loss: 2.807098457515002
Validation loss: 2.459693501818479

Epoch: 5| Step: 8
Training loss: 2.8700085308200705
Validation loss: 2.4503590216736497

Epoch: 5| Step: 9
Training loss: 2.9430432874507777
Validation loss: 2.4624695326629404

Epoch: 5| Step: 10
Training loss: 2.6577219755352823
Validation loss: 2.4706552261144683

Epoch: 101| Step: 0
Training loss: 2.5067767800163425
Validation loss: 2.4695622987490036

Epoch: 5| Step: 1
Training loss: 2.389080970148875
Validation loss: 2.458071547874371

Epoch: 5| Step: 2
Training loss: 2.1732145062045825
Validation loss: 2.455345146662356

Epoch: 5| Step: 3
Training loss: 2.70349330267298
Validation loss: 2.4525593113949116

Epoch: 5| Step: 4
Training loss: 2.7491897776606384
Validation loss: 2.444318916325416

Epoch: 5| Step: 5
Training loss: 2.917138161469317
Validation loss: 2.458783060785983

Epoch: 5| Step: 6
Training loss: 2.595506647738235
Validation loss: 2.4704112835039638

Epoch: 5| Step: 7
Training loss: 2.6317080210101427
Validation loss: 2.445096641694248

Epoch: 5| Step: 8
Training loss: 2.760744951028861
Validation loss: 2.459663736771658

Epoch: 5| Step: 9
Training loss: 2.779488166236287
Validation loss: 2.442944970412268

Epoch: 5| Step: 10
Training loss: 2.740263783085693
Validation loss: 2.473313397126875

Epoch: 102| Step: 0
Training loss: 2.115583537158898
Validation loss: 2.462971135775781

Epoch: 5| Step: 1
Training loss: 2.885726324512238
Validation loss: 2.4570696193063033

Epoch: 5| Step: 2
Training loss: 2.8634604362843947
Validation loss: 2.454766318986346

Epoch: 5| Step: 3
Training loss: 3.7437036425438115
Validation loss: 2.4685689668439794

Epoch: 5| Step: 4
Training loss: 2.6666219727426523
Validation loss: 2.4660668653104247

Epoch: 5| Step: 5
Training loss: 2.1936642578410104
Validation loss: 2.464974951864444

Epoch: 5| Step: 6
Training loss: 2.232943202812123
Validation loss: 2.466478806971703

Epoch: 5| Step: 7
Training loss: 2.5788452991770177
Validation loss: 2.4577237011700293

Epoch: 5| Step: 8
Training loss: 2.0038978026213887
Validation loss: 2.4679925550233945

Epoch: 5| Step: 9
Training loss: 2.5471324205486567
Validation loss: 2.4771190670194514

Epoch: 5| Step: 10
Training loss: 2.8019222132840222
Validation loss: 2.446917581120277

Epoch: 103| Step: 0
Training loss: 2.2802237723780356
Validation loss: 2.4765458090096044

Epoch: 5| Step: 1
Training loss: 2.72970207922306
Validation loss: 2.46293831474351

Epoch: 5| Step: 2
Training loss: 2.886607744821062
Validation loss: 2.4666316293768387

Epoch: 5| Step: 3
Training loss: 2.51262832237993
Validation loss: 2.461587738008251

Epoch: 5| Step: 4
Training loss: 2.511788422135846
Validation loss: 2.4643134277326957

Epoch: 5| Step: 5
Training loss: 2.6827907554709483
Validation loss: 2.460765013645669

Epoch: 5| Step: 6
Training loss: 2.7295579605503275
Validation loss: 2.461604935546768

Epoch: 5| Step: 7
Training loss: 2.7108856987744923
Validation loss: 2.456172109554187

Epoch: 5| Step: 8
Training loss: 2.581112881544585
Validation loss: 2.4646370233911785

Epoch: 5| Step: 9
Training loss: 3.0280269516384153
Validation loss: 2.4560650138350035

Epoch: 5| Step: 10
Training loss: 2.2624366161256506
Validation loss: 2.472093902437147

Epoch: 104| Step: 0
Training loss: 2.577192843142443
Validation loss: 2.451536791163198

Epoch: 5| Step: 1
Training loss: 2.5942644275544584
Validation loss: 2.463613106414724

Epoch: 5| Step: 2
Training loss: 3.293400818703475
Validation loss: 2.4622129032356304

Epoch: 5| Step: 3
Training loss: 1.991164240118813
Validation loss: 2.4674808526081935

Epoch: 5| Step: 4
Training loss: 2.5383196404284596
Validation loss: 2.4543745083842627

Epoch: 5| Step: 5
Training loss: 3.0320600233553248
Validation loss: 2.4542084968540165

Epoch: 5| Step: 6
Training loss: 2.5600196184956316
Validation loss: 2.4590750677737487

Epoch: 5| Step: 7
Training loss: 2.1231921864800607
Validation loss: 2.4542120719592675

Epoch: 5| Step: 8
Training loss: 2.6713650757811123
Validation loss: 2.449386407504041

Epoch: 5| Step: 9
Training loss: 2.743365260371419
Validation loss: 2.466920722454087

Epoch: 5| Step: 10
Training loss: 2.503726756406507
Validation loss: 2.4691785827438673

Epoch: 105| Step: 0
Training loss: 2.509143606802306
Validation loss: 2.4568007022710927

Epoch: 5| Step: 1
Training loss: 2.686307154456146
Validation loss: 2.4581551157856554

Epoch: 5| Step: 2
Training loss: 2.5146284321109573
Validation loss: 2.4603077812184635

Epoch: 5| Step: 3
Training loss: 2.411985423497933
Validation loss: 2.460213690989966

Epoch: 5| Step: 4
Training loss: 1.9531837149377669
Validation loss: 2.4495969627086924

Epoch: 5| Step: 5
Training loss: 2.7534122105061485
Validation loss: 2.4551762389549596

Epoch: 5| Step: 6
Training loss: 2.9170838920448516
Validation loss: 2.4639580085234294

Epoch: 5| Step: 7
Training loss: 2.842625657712041
Validation loss: 2.4560206133135187

Epoch: 5| Step: 8
Training loss: 2.8010718542032564
Validation loss: 2.4507511667038

Epoch: 5| Step: 9
Training loss: 2.897731643646262
Validation loss: 2.463175414281998

Epoch: 5| Step: 10
Training loss: 2.479836979707104
Validation loss: 2.4458177328900588

Epoch: 106| Step: 0
Training loss: 2.9573958259093347
Validation loss: 2.463041336467978

Epoch: 5| Step: 1
Training loss: 2.60978503631832
Validation loss: 2.464644669146348

Epoch: 5| Step: 2
Training loss: 2.801627612487558
Validation loss: 2.463841837798351

Epoch: 5| Step: 3
Training loss: 2.2137201813165577
Validation loss: 2.461370075085629

Epoch: 5| Step: 4
Training loss: 2.712137270111882
Validation loss: 2.445429618059665

Epoch: 5| Step: 5
Training loss: 3.2399678548937225
Validation loss: 2.460006375726814

Epoch: 5| Step: 6
Training loss: 2.190476164067507
Validation loss: 2.4629782990546927

Epoch: 5| Step: 7
Training loss: 1.7872413794954873
Validation loss: 2.453134219422242

Epoch: 5| Step: 8
Training loss: 2.9083160931824055
Validation loss: 2.4620073619731224

Epoch: 5| Step: 9
Training loss: 2.236677783800099
Validation loss: 2.4633973801826876

Epoch: 5| Step: 10
Training loss: 2.9052168127359974
Validation loss: 2.45833834893904

Epoch: 107| Step: 0
Training loss: 2.6517304510584783
Validation loss: 2.4487837185132384

Epoch: 5| Step: 1
Training loss: 2.9585318342065667
Validation loss: 2.4556564365348152

Epoch: 5| Step: 2
Training loss: 3.0641148260726783
Validation loss: 2.456077814964714

Epoch: 5| Step: 3
Training loss: 3.242071898823892
Validation loss: 2.4569578871448154

Epoch: 5| Step: 4
Training loss: 2.7298528279469125
Validation loss: 2.4558807522175288

Epoch: 5| Step: 5
Training loss: 2.6898287065557858
Validation loss: 2.4522698100958245

Epoch: 5| Step: 6
Training loss: 2.172936818025461
Validation loss: 2.455981214054647

Epoch: 5| Step: 7
Training loss: 2.8825498218316707
Validation loss: 2.4673811145873774

Epoch: 5| Step: 8
Training loss: 1.9212165262735006
Validation loss: 2.461554507457721

Epoch: 5| Step: 9
Training loss: 1.8383299477835104
Validation loss: 2.4674281783027

Epoch: 5| Step: 10
Training loss: 2.273720635155823
Validation loss: 2.4735532809637406

Epoch: 108| Step: 0
Training loss: 2.058601509673172
Validation loss: 2.4643031817352408

Epoch: 5| Step: 1
Training loss: 2.7824109686825595
Validation loss: 2.456142397859539

Epoch: 5| Step: 2
Training loss: 2.521439650158875
Validation loss: 2.4528302183501296

Epoch: 5| Step: 3
Training loss: 3.2987184116691233
Validation loss: 2.435235586388703

Epoch: 5| Step: 4
Training loss: 2.474264239756378
Validation loss: 2.454098361735961

Epoch: 5| Step: 5
Training loss: 2.1313110208585364
Validation loss: 2.4698743065640114

Epoch: 5| Step: 6
Training loss: 3.2402105347789334
Validation loss: 2.4562218721322844

Epoch: 5| Step: 7
Training loss: 2.1861633576749084
Validation loss: 2.459519418402191

Epoch: 5| Step: 8
Training loss: 2.3431377374115105
Validation loss: 2.4621131683919257

Epoch: 5| Step: 9
Training loss: 2.9886772741055334
Validation loss: 2.463692136785028

Epoch: 5| Step: 10
Training loss: 2.4745444369809286
Validation loss: 2.4623856124766137

Epoch: 109| Step: 0
Training loss: 2.5283968822897562
Validation loss: 2.452319488778061

Epoch: 5| Step: 1
Training loss: 2.637077250657219
Validation loss: 2.4609377333482567

Epoch: 5| Step: 2
Training loss: 2.840998397810584
Validation loss: 2.454907172994222

Epoch: 5| Step: 3
Training loss: 3.0672418124131378
Validation loss: 2.4576451610793795

Epoch: 5| Step: 4
Training loss: 1.9939515325879142
Validation loss: 2.4480918540571466

Epoch: 5| Step: 5
Training loss: 2.8135943508947268
Validation loss: 2.4571803698340213

Epoch: 5| Step: 6
Training loss: 2.5191850764487027
Validation loss: 2.4344302384349077

Epoch: 5| Step: 7
Training loss: 2.717205441960243
Validation loss: 2.458399297442071

Epoch: 5| Step: 8
Training loss: 2.5642005116143762
Validation loss: 2.461514919218121

Epoch: 5| Step: 9
Training loss: 2.54508028979206
Validation loss: 2.4396023924466217

Epoch: 5| Step: 10
Training loss: 2.381770271875674
Validation loss: 2.4679834336952227

Epoch: 110| Step: 0
Training loss: 2.1909537162610477
Validation loss: 2.458322872962061

Epoch: 5| Step: 1
Training loss: 2.7307308655148512
Validation loss: 2.4398545051795173

Epoch: 5| Step: 2
Training loss: 2.205343874113146
Validation loss: 2.4665289951078315

Epoch: 5| Step: 3
Training loss: 2.710568801476742
Validation loss: 2.4716667172067925

Epoch: 5| Step: 4
Training loss: 2.4122021861888863
Validation loss: 2.456620442597045

Epoch: 5| Step: 5
Training loss: 3.2803764997113363
Validation loss: 2.4622712906053117

Epoch: 5| Step: 6
Training loss: 2.544938363338759
Validation loss: 2.4674598746589407

Epoch: 5| Step: 7
Training loss: 2.7099948090507087
Validation loss: 2.459751932315669

Epoch: 5| Step: 8
Training loss: 2.681713172725876
Validation loss: 2.46543383980812

Epoch: 5| Step: 9
Training loss: 2.3373948466266596
Validation loss: 2.4525103801348194

Epoch: 5| Step: 10
Training loss: 2.896506764073955
Validation loss: 2.459287343260758

Epoch: 111| Step: 0
Training loss: 2.387280586905623
Validation loss: 2.4617055261909155

Epoch: 5| Step: 1
Training loss: 2.7040614451983074
Validation loss: 2.459454437401867

Epoch: 5| Step: 2
Training loss: 2.801365662365373
Validation loss: 2.4552085946806566

Epoch: 5| Step: 3
Training loss: 2.654526364452607
Validation loss: 2.4636829412633

Epoch: 5| Step: 4
Training loss: 2.5332681593124096
Validation loss: 2.470783901033118

Epoch: 5| Step: 5
Training loss: 2.4290480186141643
Validation loss: 2.4609589679469837

Epoch: 5| Step: 6
Training loss: 2.3760865386333694
Validation loss: 2.4580541869018

Epoch: 5| Step: 7
Training loss: 3.2038379899115665
Validation loss: 2.45667349055625

Epoch: 5| Step: 8
Training loss: 2.1996937538618435
Validation loss: 2.436616884324021

Epoch: 5| Step: 9
Training loss: 2.94351359914467
Validation loss: 2.449940834812698

Epoch: 5| Step: 10
Training loss: 2.2744398496418126
Validation loss: 2.4543684898588083

Epoch: 112| Step: 0
Training loss: 2.3276617626189693
Validation loss: 2.448513987774444

Epoch: 5| Step: 1
Training loss: 2.308764146432047
Validation loss: 2.442551203718006

Epoch: 5| Step: 2
Training loss: 2.4111794845371493
Validation loss: 2.46231490062552

Epoch: 5| Step: 3
Training loss: 2.524286841722956
Validation loss: 2.455680283909316

Epoch: 5| Step: 4
Training loss: 2.213248080063283
Validation loss: 2.4657381334949937

Epoch: 5| Step: 5
Training loss: 2.7909210594819784
Validation loss: 2.444257579751006

Epoch: 5| Step: 6
Training loss: 2.8119160363805844
Validation loss: 2.4699970220001735

Epoch: 5| Step: 7
Training loss: 2.53278775070684
Validation loss: 2.454914948782305

Epoch: 5| Step: 8
Training loss: 2.982515404814133
Validation loss: 2.441835419897831

Epoch: 5| Step: 9
Training loss: 2.6735192309248497
Validation loss: 2.457925686235545

Epoch: 5| Step: 10
Training loss: 3.072423932070471
Validation loss: 2.4562100205117217

Epoch: 113| Step: 0
Training loss: 2.8040099109142553
Validation loss: 2.4528314182125204

Epoch: 5| Step: 1
Training loss: 2.7043336139824414
Validation loss: 2.4537427855984197

Epoch: 5| Step: 2
Training loss: 2.080327752406837
Validation loss: 2.455775765044632

Epoch: 5| Step: 3
Training loss: 2.294326510206647
Validation loss: 2.46910574278694

Epoch: 5| Step: 4
Training loss: 2.34654923170471
Validation loss: 2.4519877773910985

Epoch: 5| Step: 5
Training loss: 2.2838010763669403
Validation loss: 2.4445815099986534

Epoch: 5| Step: 6
Training loss: 2.507922208769007
Validation loss: 2.455433934788389

Epoch: 5| Step: 7
Training loss: 3.118820795085134
Validation loss: 2.453772046797104

Epoch: 5| Step: 8
Training loss: 2.98788054528508
Validation loss: 2.4578570979956047

Epoch: 5| Step: 9
Training loss: 2.995288805402744
Validation loss: 2.459082817872435

Epoch: 5| Step: 10
Training loss: 2.320625052931107
Validation loss: 2.46976287550015

Epoch: 114| Step: 0
Training loss: 2.2621169719723278
Validation loss: 2.4510836949616914

Epoch: 5| Step: 1
Training loss: 2.918408300750204
Validation loss: 2.4392779355100624

Epoch: 5| Step: 2
Training loss: 2.4384943572263214
Validation loss: 2.467738347054605

Epoch: 5| Step: 3
Training loss: 2.7586086950164677
Validation loss: 2.4562739476110473

Epoch: 5| Step: 4
Training loss: 2.738848879068184
Validation loss: 2.4520530409489183

Epoch: 5| Step: 5
Training loss: 2.7059736291315137
Validation loss: 2.4498652284883646

Epoch: 5| Step: 6
Training loss: 2.8569028412958835
Validation loss: 2.432634344298276

Epoch: 5| Step: 7
Training loss: 2.345268368035763
Validation loss: 2.4565193196867354

Epoch: 5| Step: 8
Training loss: 2.2255130904872646
Validation loss: 2.4429162291169844

Epoch: 5| Step: 9
Training loss: 2.600467944216992
Validation loss: 2.458697620707275

Epoch: 5| Step: 10
Training loss: 2.5588515756010177
Validation loss: 2.4575819023223646

Epoch: 115| Step: 0
Training loss: 2.3761945029515017
Validation loss: 2.452979357374838

Epoch: 5| Step: 1
Training loss: 2.3248706576558407
Validation loss: 2.446695582885727

Epoch: 5| Step: 2
Training loss: 2.165738885260275
Validation loss: 2.461135446374801

Epoch: 5| Step: 3
Training loss: 2.8532430634821635
Validation loss: 2.4587963920232228

Epoch: 5| Step: 4
Training loss: 2.4548754430122
Validation loss: 2.4684391430907486

Epoch: 5| Step: 5
Training loss: 2.655867425631735
Validation loss: 2.459070658942921

Epoch: 5| Step: 6
Training loss: 3.2158022224665803
Validation loss: 2.459604942502007

Epoch: 5| Step: 7
Training loss: 2.6499678879717568
Validation loss: 2.4584044270136354

Epoch: 5| Step: 8
Training loss: 2.7216029489989007
Validation loss: 2.452768222919352

Epoch: 5| Step: 9
Training loss: 1.9979052302325249
Validation loss: 2.4773082459832803

Epoch: 5| Step: 10
Training loss: 2.9954303270545757
Validation loss: 2.446077727870533

Epoch: 116| Step: 0
Training loss: 2.047925140994581
Validation loss: 2.460413475257182

Epoch: 5| Step: 1
Training loss: 2.1946743618021802
Validation loss: 2.4678789842417848

Epoch: 5| Step: 2
Training loss: 2.6455635974588594
Validation loss: 2.466955870253974

Epoch: 5| Step: 3
Training loss: 2.961229616918656
Validation loss: 2.459069897900148

Epoch: 5| Step: 4
Training loss: 3.1033075837877764
Validation loss: 2.434188694992335

Epoch: 5| Step: 5
Training loss: 2.2746503288752633
Validation loss: 2.463576861981728

Epoch: 5| Step: 6
Training loss: 2.333948826219865
Validation loss: 2.4598081394307183

Epoch: 5| Step: 7
Training loss: 2.644430724900005
Validation loss: 2.4493143814963583

Epoch: 5| Step: 8
Training loss: 2.268322095635256
Validation loss: 2.4565528161106442

Epoch: 5| Step: 9
Training loss: 3.2811761756948172
Validation loss: 2.455886194992977

Epoch: 5| Step: 10
Training loss: 2.427446122676529
Validation loss: 2.4423807320980755

Epoch: 117| Step: 0
Training loss: 3.2301655526738355
Validation loss: 2.449710165019416

Epoch: 5| Step: 1
Training loss: 2.7921341082437228
Validation loss: 2.4579169551848077

Epoch: 5| Step: 2
Training loss: 2.4149753856786695
Validation loss: 2.464383353005141

Epoch: 5| Step: 3
Training loss: 1.896403097813427
Validation loss: 2.4499939143909097

Epoch: 5| Step: 4
Training loss: 2.7944712618819123
Validation loss: 2.4610175517380615

Epoch: 5| Step: 5
Training loss: 2.182022976475487
Validation loss: 2.456835711024727

Epoch: 5| Step: 6
Training loss: 2.831331069156157
Validation loss: 2.44691922810739

Epoch: 5| Step: 7
Training loss: 2.5307400036600933
Validation loss: 2.438477216426425

Epoch: 5| Step: 8
Training loss: 2.4434590002983305
Validation loss: 2.446017975041158

Epoch: 5| Step: 9
Training loss: 2.219885522107437
Validation loss: 2.4630967857419637

Epoch: 5| Step: 10
Training loss: 2.9048803239815704
Validation loss: 2.4360626616885086

Epoch: 118| Step: 0
Training loss: 2.5375716777130157
Validation loss: 2.449347737813419

Epoch: 5| Step: 1
Training loss: 2.471269697883607
Validation loss: 2.4512379844152536

Epoch: 5| Step: 2
Training loss: 2.169481783925579
Validation loss: 2.4612282076859104

Epoch: 5| Step: 3
Training loss: 2.631511332747526
Validation loss: 2.4505208608822535

Epoch: 5| Step: 4
Training loss: 2.4221792706736234
Validation loss: 2.4371014046419552

Epoch: 5| Step: 5
Training loss: 2.918853176343625
Validation loss: 2.4557682383487625

Epoch: 5| Step: 6
Training loss: 2.0743993188456025
Validation loss: 2.4406412055268096

Epoch: 5| Step: 7
Training loss: 2.458455896285702
Validation loss: 2.432366757187755

Epoch: 5| Step: 8
Training loss: 2.638867306760461
Validation loss: 2.4551622563296136

Epoch: 5| Step: 9
Training loss: 2.69574678764587
Validation loss: 2.439537530362956

Epoch: 5| Step: 10
Training loss: 3.3342732693741945
Validation loss: 2.4632693289358483

Epoch: 119| Step: 0
Training loss: 2.728565431330045
Validation loss: 2.46431640820827

Epoch: 5| Step: 1
Training loss: 2.8959155356909076
Validation loss: 2.4536542340516214

Epoch: 5| Step: 2
Training loss: 2.9105144101120213
Validation loss: 2.452951688897012

Epoch: 5| Step: 3
Training loss: 2.1582013574653396
Validation loss: 2.437920630052463

Epoch: 5| Step: 4
Training loss: 2.1599699357377675
Validation loss: 2.443367587292362

Epoch: 5| Step: 5
Training loss: 2.7460351452061342
Validation loss: 2.452480422983972

Epoch: 5| Step: 6
Training loss: 1.8841028500929544
Validation loss: 2.470610371818922

Epoch: 5| Step: 7
Training loss: 3.211718239270362
Validation loss: 2.463208028163517

Epoch: 5| Step: 8
Training loss: 2.725122459529772
Validation loss: 2.4612253703378357

Epoch: 5| Step: 9
Training loss: 2.2415918496089233
Validation loss: 2.464547142252877

Epoch: 5| Step: 10
Training loss: 2.523332434200125
Validation loss: 2.4367141219270856

Epoch: 120| Step: 0
Training loss: 2.139030698173421
Validation loss: 2.448797247611853

Epoch: 5| Step: 1
Training loss: 2.108589760888571
Validation loss: 2.4640959598030565

Epoch: 5| Step: 2
Training loss: 2.613270758135936
Validation loss: 2.4363101245811443

Epoch: 5| Step: 3
Training loss: 2.352579194863167
Validation loss: 2.460061242093012

Epoch: 5| Step: 4
Training loss: 2.9884459207079677
Validation loss: 2.437111171718351

Epoch: 5| Step: 5
Training loss: 2.8781311565254626
Validation loss: 2.453992584791167

Epoch: 5| Step: 6
Training loss: 2.726127786603706
Validation loss: 2.4473003720888857

Epoch: 5| Step: 7
Training loss: 2.9803484371194964
Validation loss: 2.450704089222874

Epoch: 5| Step: 8
Training loss: 2.3370132265838865
Validation loss: 2.4627335918532056

Epoch: 5| Step: 9
Training loss: 2.7780771051833226
Validation loss: 2.462365481284444

Epoch: 5| Step: 10
Training loss: 2.308492229056132
Validation loss: 2.4737421592646966

Epoch: 121| Step: 0
Training loss: 3.038021272113955
Validation loss: 2.4622427072257547

Epoch: 5| Step: 1
Training loss: 2.7757436700924143
Validation loss: 2.4522343650303733

Epoch: 5| Step: 2
Training loss: 2.5255675405089373
Validation loss: 2.4525787662925116

Epoch: 5| Step: 3
Training loss: 2.772910398442277
Validation loss: 2.4425693413559264

Epoch: 5| Step: 4
Training loss: 2.2171762822346595
Validation loss: 2.4536624317391955

Epoch: 5| Step: 5
Training loss: 2.74557511924972
Validation loss: 2.440975145699493

Epoch: 5| Step: 6
Training loss: 2.2667351469279247
Validation loss: 2.4523940608413968

Epoch: 5| Step: 7
Training loss: 1.8769247983765855
Validation loss: 2.4560011898553755

Epoch: 5| Step: 8
Training loss: 2.4625103480707384
Validation loss: 2.4494531742395873

Epoch: 5| Step: 9
Training loss: 2.8256940141099767
Validation loss: 2.4570294350232746

Epoch: 5| Step: 10
Training loss: 2.678984969777217
Validation loss: 2.457720060242344

Epoch: 122| Step: 0
Training loss: 3.1652025217644733
Validation loss: 2.452758211944859

Epoch: 5| Step: 1
Training loss: 2.3102428658702094
Validation loss: 2.445786439478541

Epoch: 5| Step: 2
Training loss: 2.1905398364525235
Validation loss: 2.459800986721944

Epoch: 5| Step: 3
Training loss: 2.8137928004761172
Validation loss: 2.448081031226095

Epoch: 5| Step: 4
Training loss: 2.0484876031516794
Validation loss: 2.452814793586044

Epoch: 5| Step: 5
Training loss: 2.756272099205225
Validation loss: 2.459695579042176

Epoch: 5| Step: 6
Training loss: 3.0776597654147593
Validation loss: 2.437982897888306

Epoch: 5| Step: 7
Training loss: 2.5224158518945514
Validation loss: 2.4706672190814496

Epoch: 5| Step: 8
Training loss: 2.983388368180634
Validation loss: 2.454413543835299

Epoch: 5| Step: 9
Training loss: 2.2683031761337906
Validation loss: 2.4408921396698315

Epoch: 5| Step: 10
Training loss: 1.7287909164606674
Validation loss: 2.4502340357763406

Epoch: 123| Step: 0
Training loss: 2.956971262395166
Validation loss: 2.455335870807001

Epoch: 5| Step: 1
Training loss: 2.5224263435853733
Validation loss: 2.4538500996799546

Epoch: 5| Step: 2
Training loss: 2.658506893204266
Validation loss: 2.4498304309221575

Epoch: 5| Step: 3
Training loss: 2.499144026130204
Validation loss: 2.45825990852618

Epoch: 5| Step: 4
Training loss: 2.79873867916869
Validation loss: 2.4377989920850287

Epoch: 5| Step: 5
Training loss: 2.2411315770943947
Validation loss: 2.4389968579761994

Epoch: 5| Step: 6
Training loss: 2.445828221936926
Validation loss: 2.4478382207117395

Epoch: 5| Step: 7
Training loss: 2.2898569648749203
Validation loss: 2.4415780580508146

Epoch: 5| Step: 8
Training loss: 2.843226457967107
Validation loss: 2.4467823242822044

Epoch: 5| Step: 9
Training loss: 2.3016483246857162
Validation loss: 2.4472399818138815

Epoch: 5| Step: 10
Training loss: 2.7951120968963497
Validation loss: 2.4544421578095035

Epoch: 124| Step: 0
Training loss: 1.939609794012805
Validation loss: 2.4468082499181656

Epoch: 5| Step: 1
Training loss: 2.9274744245420243
Validation loss: 2.441716977664052

Epoch: 5| Step: 2
Training loss: 2.8527299555264105
Validation loss: 2.453131686226928

Epoch: 5| Step: 3
Training loss: 2.1515523629098636
Validation loss: 2.4575974014812796

Epoch: 5| Step: 4
Training loss: 1.9342706285461135
Validation loss: 2.4432893380391016

Epoch: 5| Step: 5
Training loss: 2.619792313825301
Validation loss: 2.444472202261196

Epoch: 5| Step: 6
Training loss: 3.277172497900233
Validation loss: 2.4503705123975936

Epoch: 5| Step: 7
Training loss: 2.6813982515764287
Validation loss: 2.451322916865947

Epoch: 5| Step: 8
Training loss: 2.793474058310391
Validation loss: 2.461782263250328

Epoch: 5| Step: 9
Training loss: 2.5940776755851
Validation loss: 2.4461888261871123

Epoch: 5| Step: 10
Training loss: 2.2441702658984077
Validation loss: 2.450688713842212

Epoch: 125| Step: 0
Training loss: 2.606356856902224
Validation loss: 2.4318154127362206

Epoch: 5| Step: 1
Training loss: 3.007673463456557
Validation loss: 2.446039702844677

Epoch: 5| Step: 2
Training loss: 2.3710119996911536
Validation loss: 2.4378216964768824

Epoch: 5| Step: 3
Training loss: 2.8652686576638535
Validation loss: 2.4535449459996337

Epoch: 5| Step: 4
Training loss: 2.295860222060725
Validation loss: 2.455272485205554

Epoch: 5| Step: 5
Training loss: 2.489248809259415
Validation loss: 2.4588783192614736

Epoch: 5| Step: 6
Training loss: 2.6277834349399543
Validation loss: 2.435788231135038

Epoch: 5| Step: 7
Training loss: 2.3374020887461997
Validation loss: 2.444462380696131

Epoch: 5| Step: 8
Training loss: 2.118225293749597
Validation loss: 2.42335677266572

Epoch: 5| Step: 9
Training loss: 2.7159128403084556
Validation loss: 2.458597260481936

Epoch: 5| Step: 10
Training loss: 2.7037074172731366
Validation loss: 2.44206712167983

Epoch: 126| Step: 0
Training loss: 2.987647693766022
Validation loss: 2.4233898092324364

Epoch: 5| Step: 1
Training loss: 2.8039967315861567
Validation loss: 2.4479370458448866

Epoch: 5| Step: 2
Training loss: 2.8705851616930347
Validation loss: 2.45144169081542

Epoch: 5| Step: 3
Training loss: 2.5859121453923652
Validation loss: 2.4480538749772447

Epoch: 5| Step: 4
Training loss: 2.258568449086497
Validation loss: 2.457387786846372

Epoch: 5| Step: 5
Training loss: 2.416179037773924
Validation loss: 2.456842731498044

Epoch: 5| Step: 6
Training loss: 2.5151419797830097
Validation loss: 2.4581699970587154

Epoch: 5| Step: 7
Training loss: 3.1838642403303714
Validation loss: 2.449703857185924

Epoch: 5| Step: 8
Training loss: 1.9335750078005807
Validation loss: 2.452062900067864

Epoch: 5| Step: 9
Training loss: 1.8176296913018748
Validation loss: 2.445608944644827

Epoch: 5| Step: 10
Training loss: 2.422833554478875
Validation loss: 2.442311210806434

Epoch: 127| Step: 0
Training loss: 2.4593625796633343
Validation loss: 2.442725050180902

Epoch: 5| Step: 1
Training loss: 2.618619339262108
Validation loss: 2.4478385464245167

Epoch: 5| Step: 2
Training loss: 2.3729179692676463
Validation loss: 2.438091507106282

Epoch: 5| Step: 3
Training loss: 3.0397286359235607
Validation loss: 2.46345006939009

Epoch: 5| Step: 4
Training loss: 2.002163313089493
Validation loss: 2.4505543838527943

Epoch: 5| Step: 5
Training loss: 2.851075849419918
Validation loss: 2.4363925775149013

Epoch: 5| Step: 6
Training loss: 2.3659400800661414
Validation loss: 2.433692168634655

Epoch: 5| Step: 7
Training loss: 2.217205745952606
Validation loss: 2.4515386421010374

Epoch: 5| Step: 8
Training loss: 2.8296755760442966
Validation loss: 2.4440337759349586

Epoch: 5| Step: 9
Training loss: 3.126006612779258
Validation loss: 2.4472347513209725

Epoch: 5| Step: 10
Training loss: 1.942069786475757
Validation loss: 2.449940573733588

Epoch: 128| Step: 0
Training loss: 3.2061735207283357
Validation loss: 2.461531335112512

Epoch: 5| Step: 1
Training loss: 2.5886019438103136
Validation loss: 2.4663529727748474

Epoch: 5| Step: 2
Training loss: 2.405910418440146
Validation loss: 2.4461457146949197

Epoch: 5| Step: 3
Training loss: 2.6595871550480594
Validation loss: 2.444515059061171

Epoch: 5| Step: 4
Training loss: 2.944111303360854
Validation loss: 2.435443088129186

Epoch: 5| Step: 5
Training loss: 1.9433477813528233
Validation loss: 2.461624525159943

Epoch: 5| Step: 6
Training loss: 2.4656695691856116
Validation loss: 2.457657487702399

Epoch: 5| Step: 7
Training loss: 2.3558478864776458
Validation loss: 2.4518968161933987

Epoch: 5| Step: 8
Training loss: 2.384205395427212
Validation loss: 2.4617629789765165

Epoch: 5| Step: 9
Training loss: 2.6039055248297256
Validation loss: 2.449102413460936

Epoch: 5| Step: 10
Training loss: 2.573046033646866
Validation loss: 2.4542052392992333

Epoch: 129| Step: 0
Training loss: 2.553823342411453
Validation loss: 2.4465916517755506

Epoch: 5| Step: 1
Training loss: 2.7942838973669932
Validation loss: 2.4448195708297806

Epoch: 5| Step: 2
Training loss: 2.5010108811341203
Validation loss: 2.4423142034369154

Epoch: 5| Step: 3
Training loss: 1.9875301598713704
Validation loss: 2.4266355051115354

Epoch: 5| Step: 4
Training loss: 2.8828306947046083
Validation loss: 2.4583225913948925

Epoch: 5| Step: 5
Training loss: 2.126729710022166
Validation loss: 2.438712715258369

Epoch: 5| Step: 6
Training loss: 2.5941804275940146
Validation loss: 2.4426548785344666

Epoch: 5| Step: 7
Training loss: 2.9977266917279732
Validation loss: 2.44128270436731

Epoch: 5| Step: 8
Training loss: 2.1443123349601056
Validation loss: 2.4292380287127795

Epoch: 5| Step: 9
Training loss: 2.8093021438537766
Validation loss: 2.4444897561784984

Epoch: 5| Step: 10
Training loss: 2.520466381088675
Validation loss: 2.46084892607073

Epoch: 130| Step: 0
Training loss: 2.5112234905812776
Validation loss: 2.4403770312510398

Epoch: 5| Step: 1
Training loss: 2.460369904472394
Validation loss: 2.43595190032582

Epoch: 5| Step: 2
Training loss: 2.9779630955240566
Validation loss: 2.4483034357674884

Epoch: 5| Step: 3
Training loss: 2.4745724742278816
Validation loss: 2.4490604968707097

Epoch: 5| Step: 4
Training loss: 2.573540976041569
Validation loss: 2.442899553805631

Epoch: 5| Step: 5
Training loss: 2.542594917348575
Validation loss: 2.4547591829173085

Epoch: 5| Step: 6
Training loss: 2.3567921224795247
Validation loss: 2.452635184831919

Epoch: 5| Step: 7
Training loss: 2.9011167086216054
Validation loss: 2.4522563639260277

Epoch: 5| Step: 8
Training loss: 2.6518535357633124
Validation loss: 2.4483690865292385

Epoch: 5| Step: 9
Training loss: 2.2740211393100127
Validation loss: 2.443306917242688

Epoch: 5| Step: 10
Training loss: 2.2518861070835983
Validation loss: 2.4597762293093446

Epoch: 131| Step: 0
Training loss: 2.039184566658794
Validation loss: 2.446054084530037

Epoch: 5| Step: 1
Training loss: 2.582651222579986
Validation loss: 2.432798492277295

Epoch: 5| Step: 2
Training loss: 2.4447528820323177
Validation loss: 2.449222847373039

Epoch: 5| Step: 3
Training loss: 1.9202629089159955
Validation loss: 2.439122605726738

Epoch: 5| Step: 4
Training loss: 2.832019632249877
Validation loss: 2.442297644728759

Epoch: 5| Step: 5
Training loss: 2.0678742644050367
Validation loss: 2.449212397461994

Epoch: 5| Step: 6
Training loss: 2.665352070152728
Validation loss: 2.450287503443546

Epoch: 5| Step: 7
Training loss: 2.331058164992693
Validation loss: 2.4386390672855964

Epoch: 5| Step: 8
Training loss: 3.4320562086059665
Validation loss: 2.472377161886695

Epoch: 5| Step: 9
Training loss: 3.0255162389694865
Validation loss: 2.4414387346629165

Epoch: 5| Step: 10
Training loss: 2.4588193466887476
Validation loss: 2.4480472178175123

Epoch: 132| Step: 0
Training loss: 3.0060819329055732
Validation loss: 2.43151733808083

Epoch: 5| Step: 1
Training loss: 2.26512887718585
Validation loss: 2.421401699471865

Epoch: 5| Step: 2
Training loss: 2.3033792176854178
Validation loss: 2.4429499582329717

Epoch: 5| Step: 3
Training loss: 2.1838103649266203
Validation loss: 2.4468395889346106

Epoch: 5| Step: 4
Training loss: 2.808477449728291
Validation loss: 2.4458689408563905

Epoch: 5| Step: 5
Training loss: 2.0617052338718334
Validation loss: 2.443616169458084

Epoch: 5| Step: 6
Training loss: 2.6532209291403017
Validation loss: 2.453830374868835

Epoch: 5| Step: 7
Training loss: 2.805171829101328
Validation loss: 2.4365950219918306

Epoch: 5| Step: 8
Training loss: 2.7026192076132114
Validation loss: 2.444089549445894

Epoch: 5| Step: 9
Training loss: 2.631164397163336
Validation loss: 2.463060495200294

Epoch: 5| Step: 10
Training loss: 2.5976709351088667
Validation loss: 2.450407502474693

Epoch: 133| Step: 0
Training loss: 2.6118588075959717
Validation loss: 2.453540224218116

Epoch: 5| Step: 1
Training loss: 2.07248076132023
Validation loss: 2.432278904072535

Epoch: 5| Step: 2
Training loss: 2.8643432146639833
Validation loss: 2.428851187300113

Epoch: 5| Step: 3
Training loss: 2.4209940631010554
Validation loss: 2.4437302300046597

Epoch: 5| Step: 4
Training loss: 2.8700103584129204
Validation loss: 2.4398572517993813

Epoch: 5| Step: 5
Training loss: 2.295766965411049
Validation loss: 2.444643168778811

Epoch: 5| Step: 6
Training loss: 2.5496915443707198
Validation loss: 2.440308339532095

Epoch: 5| Step: 7
Training loss: 3.2546350732207854
Validation loss: 2.4456628352364773

Epoch: 5| Step: 8
Training loss: 2.53245986469847
Validation loss: 2.4427629567875626

Epoch: 5| Step: 9
Training loss: 2.0258338906671702
Validation loss: 2.4645120058705436

Epoch: 5| Step: 10
Training loss: 2.215616296662318
Validation loss: 2.4447156952408373

Epoch: 134| Step: 0
Training loss: 2.270288757914183
Validation loss: 2.4544088007456906

Epoch: 5| Step: 1
Training loss: 2.248956756332101
Validation loss: 2.4481932779429036

Epoch: 5| Step: 2
Training loss: 2.6331404756190397
Validation loss: 2.4343718235951837

Epoch: 5| Step: 3
Training loss: 2.1982467427623837
Validation loss: 2.4586920256673697

Epoch: 5| Step: 4
Training loss: 2.413922944710893
Validation loss: 2.438326381864401

Epoch: 5| Step: 5
Training loss: 2.522921199358757
Validation loss: 2.4465070056627156

Epoch: 5| Step: 6
Training loss: 2.655974788994231
Validation loss: 2.4378866904416165

Epoch: 5| Step: 7
Training loss: 2.904779041442232
Validation loss: 2.451191586690263

Epoch: 5| Step: 8
Training loss: 2.336832850918594
Validation loss: 2.438008633183584

Epoch: 5| Step: 9
Training loss: 2.9413261655972054
Validation loss: 2.4258783676471753

Epoch: 5| Step: 10
Training loss: 2.78625158570879
Validation loss: 2.446431444115869

Epoch: 135| Step: 0
Training loss: 2.619678462005063
Validation loss: 2.4351636576873203

Epoch: 5| Step: 1
Training loss: 2.3929391269425735
Validation loss: 2.4438666858903155

Epoch: 5| Step: 2
Training loss: 2.7539563762891492
Validation loss: 2.450099499841528

Epoch: 5| Step: 3
Training loss: 2.4617006117801115
Validation loss: 2.447318932300398

Epoch: 5| Step: 4
Training loss: 2.832246759041585
Validation loss: 2.437282069760333

Epoch: 5| Step: 5
Training loss: 2.336248370762436
Validation loss: 2.4588038062284543

Epoch: 5| Step: 6
Training loss: 2.513669978024731
Validation loss: 2.45785633449099

Epoch: 5| Step: 7
Training loss: 2.653333521400458
Validation loss: 2.4592229831677574

Epoch: 5| Step: 8
Training loss: 2.872994926185257
Validation loss: 2.4435191545822983

Epoch: 5| Step: 9
Training loss: 2.1160294296943896
Validation loss: 2.4364962239831245

Epoch: 5| Step: 10
Training loss: 2.2202445356045986
Validation loss: 2.4440866523427034

Epoch: 136| Step: 0
Training loss: 2.592500776476546
Validation loss: 2.4460921512545517

Epoch: 5| Step: 1
Training loss: 2.4597159123951573
Validation loss: 2.451845872140816

Epoch: 5| Step: 2
Training loss: 2.7265198275224494
Validation loss: 2.4367298753339486

Epoch: 5| Step: 3
Training loss: 2.4033312248964975
Validation loss: 2.447516755632205

Epoch: 5| Step: 4
Training loss: 2.315338557721384
Validation loss: 2.450721435314865

Epoch: 5| Step: 5
Training loss: 2.5309992536515815
Validation loss: 2.458668627189307

Epoch: 5| Step: 6
Training loss: 2.3094588206440245
Validation loss: 2.4309398477019055

Epoch: 5| Step: 7
Training loss: 2.5166799098628485
Validation loss: 2.455722476376512

Epoch: 5| Step: 8
Training loss: 2.5836523740915545
Validation loss: 2.457034019154203

Epoch: 5| Step: 9
Training loss: 2.3641650352252777
Validation loss: 2.4476635989092665

Epoch: 5| Step: 10
Training loss: 3.1813495612912344
Validation loss: 2.430809219725994

Epoch: 137| Step: 0
Training loss: 3.1102655563560306
Validation loss: 2.431138729112888

Epoch: 5| Step: 1
Training loss: 2.512824353589926
Validation loss: 2.431426953820404

Epoch: 5| Step: 2
Training loss: 2.250394680587009
Validation loss: 2.449611151875155

Epoch: 5| Step: 3
Training loss: 2.2572279440689185
Validation loss: 2.438659799071102

Epoch: 5| Step: 4
Training loss: 2.559113567633269
Validation loss: 2.451452037104789

Epoch: 5| Step: 5
Training loss: 2.4084314143746304
Validation loss: 2.441887561762814

Epoch: 5| Step: 6
Training loss: 2.436042251928306
Validation loss: 2.434571410795073

Epoch: 5| Step: 7
Training loss: 2.7311350782994914
Validation loss: 2.44048251698998

Epoch: 5| Step: 8
Training loss: 2.71553314018502
Validation loss: 2.434393048763522

Epoch: 5| Step: 9
Training loss: 2.450924414799556
Validation loss: 2.4423334292420953

Epoch: 5| Step: 10
Training loss: 2.4828912874928317
Validation loss: 2.4431269410957346

Epoch: 138| Step: 0
Training loss: 2.371481447401833
Validation loss: 2.4454904513999467

Epoch: 5| Step: 1
Training loss: 3.413913889428612
Validation loss: 2.4413835479665265

Epoch: 5| Step: 2
Training loss: 2.513524096338353
Validation loss: 2.4548868619472883

Epoch: 5| Step: 3
Training loss: 2.0086327447003036
Validation loss: 2.4572742131462295

Epoch: 5| Step: 4
Training loss: 2.0533952601907832
Validation loss: 2.452071874654504

Epoch: 5| Step: 5
Training loss: 2.9792465163691726
Validation loss: 2.4482844688846077

Epoch: 5| Step: 6
Training loss: 2.7919392428960466
Validation loss: 2.437974612777321

Epoch: 5| Step: 7
Training loss: 2.7462421230642486
Validation loss: 2.447760344789446

Epoch: 5| Step: 8
Training loss: 2.6603350474225382
Validation loss: 2.438408308227812

Epoch: 5| Step: 9
Training loss: 1.8042964098695005
Validation loss: 2.45646116556649

Epoch: 5| Step: 10
Training loss: 1.9906996612680379
Validation loss: 2.4500154007977404

Epoch: 139| Step: 0
Training loss: 2.3360274179560965
Validation loss: 2.4321572611668536

Epoch: 5| Step: 1
Training loss: 2.383853972417418
Validation loss: 2.458109582848205

Epoch: 5| Step: 2
Training loss: 2.2310106250573196
Validation loss: 2.4465996038329165

Epoch: 5| Step: 3
Training loss: 2.8030607558493386
Validation loss: 2.4387180843943272

Epoch: 5| Step: 4
Training loss: 2.4098434368895885
Validation loss: 2.454592770755754

Epoch: 5| Step: 5
Training loss: 2.5970699709932
Validation loss: 2.4384474993934893

Epoch: 5| Step: 6
Training loss: 2.4135259630803416
Validation loss: 2.4426619513098236

Epoch: 5| Step: 7
Training loss: 2.1436751416540605
Validation loss: 2.4449637859366997

Epoch: 5| Step: 8
Training loss: 2.7323399409456655
Validation loss: 2.441441120382695

Epoch: 5| Step: 9
Training loss: 2.8324913756061645
Validation loss: 2.4143527441504746

Epoch: 5| Step: 10
Training loss: 2.9103641717354862
Validation loss: 2.4155202748366706

Epoch: 140| Step: 0
Training loss: 2.5438278786174773
Validation loss: 2.461265118432299

Epoch: 5| Step: 1
Training loss: 1.4275880835192114
Validation loss: 2.4293159485921705

Epoch: 5| Step: 2
Training loss: 2.340826525498899
Validation loss: 2.4463941225069172

Epoch: 5| Step: 3
Training loss: 2.5259711711262343
Validation loss: 2.437391307101765

Epoch: 5| Step: 4
Training loss: 3.0320247957730517
Validation loss: 2.4387517301849195

Epoch: 5| Step: 5
Training loss: 3.0555287639329594
Validation loss: 2.4466893070967046

Epoch: 5| Step: 6
Training loss: 2.5489915349616985
Validation loss: 2.4485722264659726

Epoch: 5| Step: 7
Training loss: 2.9952451854578284
Validation loss: 2.442709650814685

Epoch: 5| Step: 8
Training loss: 2.6239463871503093
Validation loss: 2.434249013065163

Epoch: 5| Step: 9
Training loss: 2.512370403230739
Validation loss: 2.4542367658968534

Epoch: 5| Step: 10
Training loss: 1.6183547815197377
Validation loss: 2.4459307768070264

Epoch: 141| Step: 0
Training loss: 2.5926877339884418
Validation loss: 2.448208293068824

Epoch: 5| Step: 1
Training loss: 2.5420649690646777
Validation loss: 2.4402139703582386

Epoch: 5| Step: 2
Training loss: 2.744088755487319
Validation loss: 2.448869746310319

Epoch: 5| Step: 3
Training loss: 2.7046620844325076
Validation loss: 2.424341875797629

Epoch: 5| Step: 4
Training loss: 2.4950816411362293
Validation loss: 2.4439986519835752

Epoch: 5| Step: 5
Training loss: 1.852813812939968
Validation loss: 2.4450755230718597

Epoch: 5| Step: 6
Training loss: 2.5672208517999584
Validation loss: 2.4530976550441816

Epoch: 5| Step: 7
Training loss: 2.651708153144981
Validation loss: 2.434721771453528

Epoch: 5| Step: 8
Training loss: 2.341928002740377
Validation loss: 2.442749333397788

Epoch: 5| Step: 9
Training loss: 2.5341177813368305
Validation loss: 2.4320708846542485

Epoch: 5| Step: 10
Training loss: 2.7824465288780798
Validation loss: 2.4365943023275296

Epoch: 142| Step: 0
Training loss: 3.1270623077831075
Validation loss: 2.44343616887595

Epoch: 5| Step: 1
Training loss: 2.514842699565591
Validation loss: 2.441350316479567

Epoch: 5| Step: 2
Training loss: 2.723647168526167
Validation loss: 2.4408720559729273

Epoch: 5| Step: 3
Training loss: 2.289811880722231
Validation loss: 2.4357391720176755

Epoch: 5| Step: 4
Training loss: 2.2481756231458707
Validation loss: 2.4387696006924364

Epoch: 5| Step: 5
Training loss: 2.2151630043690447
Validation loss: 2.457282685660041

Epoch: 5| Step: 6
Training loss: 2.6370353000087867
Validation loss: 2.442985692265167

Epoch: 5| Step: 7
Training loss: 2.519955337673592
Validation loss: 2.457198171001009

Epoch: 5| Step: 8
Training loss: 2.519102358723358
Validation loss: 2.4392503123567675

Epoch: 5| Step: 9
Training loss: 2.762277937719592
Validation loss: 2.449583453725348

Epoch: 5| Step: 10
Training loss: 2.268964529272156
Validation loss: 2.4270817355575347

Epoch: 143| Step: 0
Training loss: 3.0941143399338014
Validation loss: 2.449990278195013

Epoch: 5| Step: 1
Training loss: 2.4989910950977166
Validation loss: 2.444958279002054

Epoch: 5| Step: 2
Training loss: 2.171756219703267
Validation loss: 2.4446329567425638

Epoch: 5| Step: 3
Training loss: 3.0455028084977007
Validation loss: 2.445880964170051

Epoch: 5| Step: 4
Training loss: 1.780728447835784
Validation loss: 2.4469296024243956

Epoch: 5| Step: 5
Training loss: 2.2733519233249297
Validation loss: 2.427018024006528

Epoch: 5| Step: 6
Training loss: 2.8248193294850164
Validation loss: 2.4245811625904525

Epoch: 5| Step: 7
Training loss: 2.3368063239111603
Validation loss: 2.4292473625350617

Epoch: 5| Step: 8
Training loss: 2.390177167446938
Validation loss: 2.434683618559141

Epoch: 5| Step: 9
Training loss: 2.7601508150497986
Validation loss: 2.4411502721988345

Epoch: 5| Step: 10
Training loss: 2.2732950801744614
Validation loss: 2.43901914759692

Epoch: 144| Step: 0
Training loss: 2.4273326783899214
Validation loss: 2.4426426115919484

Epoch: 5| Step: 1
Training loss: 2.708454325002997
Validation loss: 2.445201093467331

Epoch: 5| Step: 2
Training loss: 2.7107137538249555
Validation loss: 2.4337735620986143

Epoch: 5| Step: 3
Training loss: 2.0653600802765486
Validation loss: 2.4376364155205383

Epoch: 5| Step: 4
Training loss: 2.4537431460501993
Validation loss: 2.4196630564601627

Epoch: 5| Step: 5
Training loss: 2.712633289630884
Validation loss: 2.441828873870749

Epoch: 5| Step: 6
Training loss: 3.0654292208405987
Validation loss: 2.433044857327888

Epoch: 5| Step: 7
Training loss: 2.411834379883654
Validation loss: 2.4334409229206857

Epoch: 5| Step: 8
Training loss: 1.8874058706294337
Validation loss: 2.4373575909928498

Epoch: 5| Step: 9
Training loss: 2.2515064071032103
Validation loss: 2.440582881572102

Epoch: 5| Step: 10
Training loss: 2.8066549811795762
Validation loss: 2.4346244000479484

Epoch: 145| Step: 0
Training loss: 2.3498293550908915
Validation loss: 2.4357686800185

Epoch: 5| Step: 1
Training loss: 2.976442990444502
Validation loss: 2.4362972522056503

Epoch: 5| Step: 2
Training loss: 2.786006674600398
Validation loss: 2.433874643621316

Epoch: 5| Step: 3
Training loss: 2.7195820905299675
Validation loss: 2.4401513029661386

Epoch: 5| Step: 4
Training loss: 2.561989337931714
Validation loss: 2.4443755443883664

Epoch: 5| Step: 5
Training loss: 2.1442077059128835
Validation loss: 2.4404004365030665

Epoch: 5| Step: 6
Training loss: 2.0029987265648987
Validation loss: 2.4415515959759264

Epoch: 5| Step: 7
Training loss: 2.5784188767757983
Validation loss: 2.4555553986854908

Epoch: 5| Step: 8
Training loss: 2.206495912155213
Validation loss: 2.4337299304673583

Epoch: 5| Step: 9
Training loss: 2.760781394806932
Validation loss: 2.432995023744523

Epoch: 5| Step: 10
Training loss: 2.4851336010761584
Validation loss: 2.436958152320739

Epoch: 146| Step: 0
Training loss: 2.892322103953005
Validation loss: 2.4381831715486726

Epoch: 5| Step: 1
Training loss: 2.9052731092436788
Validation loss: 2.446812294225551

Epoch: 5| Step: 2
Training loss: 2.530763650017954
Validation loss: 2.4412889105706594

Epoch: 5| Step: 3
Training loss: 2.7528186571370865
Validation loss: 2.4346046984831546

Epoch: 5| Step: 4
Training loss: 2.1087642209263766
Validation loss: 2.4485417011631787

Epoch: 5| Step: 5
Training loss: 2.1599817464198496
Validation loss: 2.444494403677081

Epoch: 5| Step: 6
Training loss: 3.0229390839986183
Validation loss: 2.442612628796679

Epoch: 5| Step: 7
Training loss: 2.1693062720241376
Validation loss: 2.445259943655507

Epoch: 5| Step: 8
Training loss: 2.1755568219082586
Validation loss: 2.422801730352121

Epoch: 5| Step: 9
Training loss: 2.727642118840538
Validation loss: 2.4479588016469793

Epoch: 5| Step: 10
Training loss: 1.8305332590898962
Validation loss: 2.4457133147900008

Epoch: 147| Step: 0
Training loss: 2.737048950660727
Validation loss: 2.4295858834034756

Epoch: 5| Step: 1
Training loss: 2.507557888712957
Validation loss: 2.448304665073181

Epoch: 5| Step: 2
Training loss: 1.9788473440530157
Validation loss: 2.4466083763189777

Epoch: 5| Step: 3
Training loss: 2.2456691174695016
Validation loss: 2.429757864668192

Epoch: 5| Step: 4
Training loss: 2.7739491165433936
Validation loss: 2.4326041027253384

Epoch: 5| Step: 5
Training loss: 2.8222627527558912
Validation loss: 2.429430273730649

Epoch: 5| Step: 6
Training loss: 2.1463130920770137
Validation loss: 2.433558021327512

Epoch: 5| Step: 7
Training loss: 2.5235719438292965
Validation loss: 2.437424519466387

Epoch: 5| Step: 8
Training loss: 2.4178459863511983
Validation loss: 2.4481747133647973

Epoch: 5| Step: 9
Training loss: 2.8906480942911914
Validation loss: 2.4406837672161585

Epoch: 5| Step: 10
Training loss: 2.459274456678531
Validation loss: 2.441996016215203

Epoch: 148| Step: 0
Training loss: 1.9896392681254675
Validation loss: 2.4349154813029794

Epoch: 5| Step: 1
Training loss: 2.8839469683000063
Validation loss: 2.4412740755131863

Epoch: 5| Step: 2
Training loss: 2.822807582047291
Validation loss: 2.4423386628839725

Epoch: 5| Step: 3
Training loss: 2.515528422332133
Validation loss: 2.449401084054462

Epoch: 5| Step: 4
Training loss: 2.412500363680955
Validation loss: 2.451227384647225

Epoch: 5| Step: 5
Training loss: 2.4623594989487194
Validation loss: 2.4271823204994574

Epoch: 5| Step: 6
Training loss: 2.2454085656668408
Validation loss: 2.4540245957126707

Epoch: 5| Step: 7
Training loss: 2.5186572074362474
Validation loss: 2.419789280254419

Epoch: 5| Step: 8
Training loss: 2.1411000859235645
Validation loss: 2.422909814923326

Epoch: 5| Step: 9
Training loss: 2.668654436102324
Validation loss: 2.4419789661329596

Epoch: 5| Step: 10
Training loss: 2.918584429274024
Validation loss: 2.4281986410963943

Epoch: 149| Step: 0
Training loss: 2.926550077869225
Validation loss: 2.429220861119111

Epoch: 5| Step: 1
Training loss: 2.107414295087446
Validation loss: 2.4265240757218343

Epoch: 5| Step: 2
Training loss: 2.6817965646234017
Validation loss: 2.4344113735540986

Epoch: 5| Step: 3
Training loss: 2.935547199871073
Validation loss: 2.443466905894838

Epoch: 5| Step: 4
Training loss: 2.2452369714402893
Validation loss: 2.438287957858598

Epoch: 5| Step: 5
Training loss: 2.454585909911434
Validation loss: 2.431479820235187

Epoch: 5| Step: 6
Training loss: 2.019197595065297
Validation loss: 2.4312107405147474

Epoch: 5| Step: 7
Training loss: 2.4324656607388784
Validation loss: 2.4257512622372266

Epoch: 5| Step: 8
Training loss: 2.368349602106723
Validation loss: 2.4278645274679103

Epoch: 5| Step: 9
Training loss: 3.0553648995151876
Validation loss: 2.436821017632618

Epoch: 5| Step: 10
Training loss: 2.1967311632975233
Validation loss: 2.438171203854995

Epoch: 150| Step: 0
Training loss: 2.334807361767763
Validation loss: 2.421116029157949

Epoch: 5| Step: 1
Training loss: 2.2987333292768906
Validation loss: 2.4379221085573812

Epoch: 5| Step: 2
Training loss: 2.7035403070424118
Validation loss: 2.451718558092197

Epoch: 5| Step: 3
Training loss: 2.18195315507067
Validation loss: 2.434948804295718

Epoch: 5| Step: 4
Training loss: 2.512893425803371
Validation loss: 2.429191817084113

Epoch: 5| Step: 5
Training loss: 2.0881835046934167
Validation loss: 2.4503618668961655

Epoch: 5| Step: 6
Training loss: 2.567807260790918
Validation loss: 2.433425470069588

Epoch: 5| Step: 7
Training loss: 3.18218805838502
Validation loss: 2.425127577525951

Epoch: 5| Step: 8
Training loss: 2.2857317859967448
Validation loss: 2.44083579629974

Epoch: 5| Step: 9
Training loss: 2.97189004374807
Validation loss: 2.429458297672073

Epoch: 5| Step: 10
Training loss: 2.3475411842316674
Validation loss: 2.459260575537712

Epoch: 151| Step: 0
Training loss: 2.3464529092202104
Validation loss: 2.454439499580655

Epoch: 5| Step: 1
Training loss: 2.6317987952504347
Validation loss: 2.431555455256465

Epoch: 5| Step: 2
Training loss: 2.5347068635193635
Validation loss: 2.438108064939279

Epoch: 5| Step: 3
Training loss: 2.5371624689221766
Validation loss: 2.4227660933097335

Epoch: 5| Step: 4
Training loss: 2.8718171123195377
Validation loss: 2.4307331174653752

Epoch: 5| Step: 5
Training loss: 2.5323749444329713
Validation loss: 2.4389273978978596

Epoch: 5| Step: 6
Training loss: 2.8797894265759183
Validation loss: 2.433377966792435

Epoch: 5| Step: 7
Training loss: 2.129268622399017
Validation loss: 2.429803377090796

Epoch: 5| Step: 8
Training loss: 2.28665451100328
Validation loss: 2.446179985123311

Epoch: 5| Step: 9
Training loss: 2.2345093373282596
Validation loss: 2.4263841436213363

Epoch: 5| Step: 10
Training loss: 2.478788801188685
Validation loss: 2.4251610339525564

Epoch: 152| Step: 0
Training loss: 2.831422179925509
Validation loss: 2.435495158430593

Epoch: 5| Step: 1
Training loss: 2.5441232805731233
Validation loss: 2.4466120007757874

Epoch: 5| Step: 2
Training loss: 2.707775899790514
Validation loss: 2.4359312896764065

Epoch: 5| Step: 3
Training loss: 2.4991909625365007
Validation loss: 2.4366516643767273

Epoch: 5| Step: 4
Training loss: 2.534136127545904
Validation loss: 2.4257163554860237

Epoch: 5| Step: 5
Training loss: 1.9536508081288577
Validation loss: 2.4374515464474626

Epoch: 5| Step: 6
Training loss: 3.1641646757229265
Validation loss: 2.436739400343415

Epoch: 5| Step: 7
Training loss: 2.0858060531061646
Validation loss: 2.4358449901600103

Epoch: 5| Step: 8
Training loss: 2.4413666012405493
Validation loss: 2.443940957293507

Epoch: 5| Step: 9
Training loss: 2.1491238694097867
Validation loss: 2.4488042639113616

Epoch: 5| Step: 10
Training loss: 2.396787591606178
Validation loss: 2.4224923841121644

Epoch: 153| Step: 0
Training loss: 2.308691548762606
Validation loss: 2.440649114998575

Epoch: 5| Step: 1
Training loss: 2.690531772677587
Validation loss: 2.431199989634351

Epoch: 5| Step: 2
Training loss: 2.3241508409853333
Validation loss: 2.4375527930715015

Epoch: 5| Step: 3
Training loss: 2.7199498302376846
Validation loss: 2.447424579731892

Epoch: 5| Step: 4
Training loss: 2.5398436298446603
Validation loss: 2.420795649241781

Epoch: 5| Step: 5
Training loss: 2.3851153143110366
Validation loss: 2.4055126558966395

Epoch: 5| Step: 6
Training loss: 2.2991163256246216
Validation loss: 2.441490302232569

Epoch: 5| Step: 7
Training loss: 2.4584002297130394
Validation loss: 2.408415098520033

Epoch: 5| Step: 8
Training loss: 2.584798417928974
Validation loss: 2.4226821200206694

Epoch: 5| Step: 9
Training loss: 2.630712922798254
Validation loss: 2.4072319033531313

Epoch: 5| Step: 10
Training loss: 2.4532146073030106
Validation loss: 2.428783458398845

Epoch: 154| Step: 0
Training loss: 2.166083098341825
Validation loss: 2.438117511486453

Epoch: 5| Step: 1
Training loss: 2.4337590193618084
Validation loss: 2.4417382250773634

Epoch: 5| Step: 2
Training loss: 2.3888408510666537
Validation loss: 2.4523964589016582

Epoch: 5| Step: 3
Training loss: 2.4094943678759
Validation loss: 2.433949218349482

Epoch: 5| Step: 4
Training loss: 2.6465559045338063
Validation loss: 2.4406090442791943

Epoch: 5| Step: 5
Training loss: 2.573808976063234
Validation loss: 2.435842624218429

Epoch: 5| Step: 6
Training loss: 2.8607236256182476
Validation loss: 2.432534488559575

Epoch: 5| Step: 7
Training loss: 2.559294114098119
Validation loss: 2.4300232514062743

Epoch: 5| Step: 8
Training loss: 2.6369771647095672
Validation loss: 2.444637860895301

Epoch: 5| Step: 9
Training loss: 2.076722209406035
Validation loss: 2.4371453177830267

Epoch: 5| Step: 10
Training loss: 2.664222779584431
Validation loss: 2.437296833398659

Epoch: 155| Step: 0
Training loss: 2.3393612270168904
Validation loss: 2.444380512509315

Epoch: 5| Step: 1
Training loss: 2.449140872964436
Validation loss: 2.4361012255025605

Epoch: 5| Step: 2
Training loss: 2.155923348715039
Validation loss: 2.427497710798682

Epoch: 5| Step: 3
Training loss: 3.0995307628756015
Validation loss: 2.426041014643715

Epoch: 5| Step: 4
Training loss: 2.466086000537763
Validation loss: 2.423981495747318

Epoch: 5| Step: 5
Training loss: 2.3529333636911494
Validation loss: 2.4175520020618246

Epoch: 5| Step: 6
Training loss: 2.0032177312992463
Validation loss: 2.430809333627644

Epoch: 5| Step: 7
Training loss: 2.391162188643054
Validation loss: 2.42217541067657

Epoch: 5| Step: 8
Training loss: 2.464871123777029
Validation loss: 2.441891830490775

Epoch: 5| Step: 9
Training loss: 2.932215055523032
Validation loss: 2.440420394870774

Epoch: 5| Step: 10
Training loss: 2.5276373054495753
Validation loss: 2.434671828463097

Epoch: 156| Step: 0
Training loss: 2.4333486173315237
Validation loss: 2.437691371021901

Epoch: 5| Step: 1
Training loss: 2.502832810472756
Validation loss: 2.4435069654201484

Epoch: 5| Step: 2
Training loss: 2.6552842123494145
Validation loss: 2.4539349187399315

Epoch: 5| Step: 3
Training loss: 2.6049612028487426
Validation loss: 2.431459797969031

Epoch: 5| Step: 4
Training loss: 2.7642614591681327
Validation loss: 2.4404127220695315

Epoch: 5| Step: 5
Training loss: 2.6956261493796276
Validation loss: 2.436423977902326

Epoch: 5| Step: 6
Training loss: 2.0717945480261686
Validation loss: 2.442158433775345

Epoch: 5| Step: 7
Training loss: 2.787230245085151
Validation loss: 2.4441110536691273

Epoch: 5| Step: 8
Training loss: 2.4956377117273654
Validation loss: 2.4400928359725604

Epoch: 5| Step: 9
Training loss: 2.2922832237595965
Validation loss: 2.4499091734048677

Epoch: 5| Step: 10
Training loss: 1.8509577797804864
Validation loss: 2.437319376279467

Epoch: 157| Step: 0
Training loss: 2.7098765647056995
Validation loss: 2.4240446726492912

Epoch: 5| Step: 1
Training loss: 2.799784335277659
Validation loss: 2.4313415504201834

Epoch: 5| Step: 2
Training loss: 2.4724223190462955
Validation loss: 2.438250804421813

Epoch: 5| Step: 3
Training loss: 2.001741485573784
Validation loss: 2.4349302445505296

Epoch: 5| Step: 4
Training loss: 2.488495869865156
Validation loss: 2.4350566865939087

Epoch: 5| Step: 5
Training loss: 2.7843918788068653
Validation loss: 2.452582127922624

Epoch: 5| Step: 6
Training loss: 2.1279919822226323
Validation loss: 2.42889685603469

Epoch: 5| Step: 7
Training loss: 2.7119799981293937
Validation loss: 2.432179152321582

Epoch: 5| Step: 8
Training loss: 2.019299846208206
Validation loss: 2.4280684811980255

Epoch: 5| Step: 9
Training loss: 2.5982734119127993
Validation loss: 2.427344418585504

Epoch: 5| Step: 10
Training loss: 2.6040055085225005
Validation loss: 2.4269741631818698

Epoch: 158| Step: 0
Training loss: 2.294548049673029
Validation loss: 2.441167565407408

Epoch: 5| Step: 1
Training loss: 1.5008660041829873
Validation loss: 2.4215315232190995

Epoch: 5| Step: 2
Training loss: 2.4300707548538973
Validation loss: 2.4271256990065506

Epoch: 5| Step: 3
Training loss: 2.4319715159843724
Validation loss: 2.43040106528991

Epoch: 5| Step: 4
Training loss: 2.7610275072539547
Validation loss: 2.431559536530676

Epoch: 5| Step: 5
Training loss: 2.2945157345074145
Validation loss: 2.421256100016413

Epoch: 5| Step: 6
Training loss: 2.6234724959219853
Validation loss: 2.428441204716968

Epoch: 5| Step: 7
Training loss: 2.6605894657456677
Validation loss: 2.427925301474041

Epoch: 5| Step: 8
Training loss: 2.6390104154299587
Validation loss: 2.452051988645069

Epoch: 5| Step: 9
Training loss: 2.2308556643672084
Validation loss: 2.4357377490232963

Epoch: 5| Step: 10
Training loss: 3.178770490753578
Validation loss: 2.4270507804683543

Epoch: 159| Step: 0
Training loss: 2.8296666448404926
Validation loss: 2.427498655993362

Epoch: 5| Step: 1
Training loss: 2.329548650092325
Validation loss: 2.4547505168421626

Epoch: 5| Step: 2
Training loss: 2.4274147909749266
Validation loss: 2.414128339632707

Epoch: 5| Step: 3
Training loss: 2.6565389139465387
Validation loss: 2.4260809381690476

Epoch: 5| Step: 4
Training loss: 2.667223534455158
Validation loss: 2.4250990468602853

Epoch: 5| Step: 5
Training loss: 2.7943599197298172
Validation loss: 2.437817906467118

Epoch: 5| Step: 6
Training loss: 2.245099771572294
Validation loss: 2.4316040937731516

Epoch: 5| Step: 7
Training loss: 2.444543589642823
Validation loss: 2.4427471504579215

Epoch: 5| Step: 8
Training loss: 1.9951204140254748
Validation loss: 2.442501286471373

Epoch: 5| Step: 9
Training loss: 2.3585079191397207
Validation loss: 2.4216401451049783

Epoch: 5| Step: 10
Training loss: 2.3785878236124582
Validation loss: 2.4277818862745613

Epoch: 160| Step: 0
Training loss: 2.2609948562907745
Validation loss: 2.4240679891804997

Epoch: 5| Step: 1
Training loss: 2.582760429434378
Validation loss: 2.4154641388325433

Epoch: 5| Step: 2
Training loss: 1.98903930842326
Validation loss: 2.4218322104419583

Epoch: 5| Step: 3
Training loss: 2.934517827889643
Validation loss: 2.426270146730045

Epoch: 5| Step: 4
Training loss: 2.871801504496017
Validation loss: 2.448463302107684

Epoch: 5| Step: 5
Training loss: 2.7437657870661813
Validation loss: 2.424520178269633

Epoch: 5| Step: 6
Training loss: 2.3658046397204386
Validation loss: 2.4571017403842337

Epoch: 5| Step: 7
Training loss: 2.1849852139389494
Validation loss: 2.4218842875725652

Epoch: 5| Step: 8
Training loss: 2.1542003675686283
Validation loss: 2.418612116306267

Epoch: 5| Step: 9
Training loss: 2.6487131341058188
Validation loss: 2.4365631292961574

Epoch: 5| Step: 10
Training loss: 2.263288358467166
Validation loss: 2.422971052841925

Epoch: 161| Step: 0
Training loss: 2.9378489834877954
Validation loss: 2.428082956658094

Epoch: 5| Step: 1
Training loss: 2.6556144402792965
Validation loss: 2.4312590474492537

Epoch: 5| Step: 2
Training loss: 2.3749055341705976
Validation loss: 2.4275539518817966

Epoch: 5| Step: 3
Training loss: 2.975275677642526
Validation loss: 2.4285999770195756

Epoch: 5| Step: 4
Training loss: 2.269540494548728
Validation loss: 2.4461863214318824

Epoch: 5| Step: 5
Training loss: 2.240358251124982
Validation loss: 2.441562412575318

Epoch: 5| Step: 6
Training loss: 2.5792133230530214
Validation loss: 2.4470064351202883

Epoch: 5| Step: 7
Training loss: 2.2325789695861227
Validation loss: 2.443686908333091

Epoch: 5| Step: 8
Training loss: 2.011117671314216
Validation loss: 2.441222037111057

Epoch: 5| Step: 9
Training loss: 2.0506387134245774
Validation loss: 2.4451972645704125

Epoch: 5| Step: 10
Training loss: 2.8669897525791828
Validation loss: 2.4387173206794786

Epoch: 162| Step: 0
Training loss: 2.2475607683667245
Validation loss: 2.435513286512087

Epoch: 5| Step: 1
Training loss: 2.311796545309889
Validation loss: 2.4395580748156496

Epoch: 5| Step: 2
Training loss: 1.6282317963058026
Validation loss: 2.4239322954992613

Epoch: 5| Step: 3
Training loss: 2.854963892025268
Validation loss: 2.4378632705201477

Epoch: 5| Step: 4
Training loss: 2.8554996431404254
Validation loss: 2.4348903755748457

Epoch: 5| Step: 5
Training loss: 2.574926808622564
Validation loss: 2.4210359959961125

Epoch: 5| Step: 6
Training loss: 2.3850306458173733
Validation loss: 2.4222885503851104

Epoch: 5| Step: 7
Training loss: 1.9283800522143446
Validation loss: 2.4332439918091526

Epoch: 5| Step: 8
Training loss: 2.616658900385061
Validation loss: 2.437357050361702

Epoch: 5| Step: 9
Training loss: 2.8320204741174297
Validation loss: 2.417323400550616

Epoch: 5| Step: 10
Training loss: 2.619667631718075
Validation loss: 2.415671595263977

Epoch: 163| Step: 0
Training loss: 2.6792494524262604
Validation loss: 2.4245973273648023

Epoch: 5| Step: 1
Training loss: 2.124100999841023
Validation loss: 2.4184219858246623

Epoch: 5| Step: 2
Training loss: 2.7488682758997913
Validation loss: 2.4356569464179265

Epoch: 5| Step: 3
Training loss: 2.306359773830083
Validation loss: 2.43150522898107

Epoch: 5| Step: 4
Training loss: 2.8519221666905357
Validation loss: 2.4339031514689298

Epoch: 5| Step: 5
Training loss: 2.371191484677447
Validation loss: 2.413278086623732

Epoch: 5| Step: 6
Training loss: 2.1639414178460066
Validation loss: 2.437403794528543

Epoch: 5| Step: 7
Training loss: 1.9913669467069015
Validation loss: 2.435861950568074

Epoch: 5| Step: 8
Training loss: 2.6855004434906586
Validation loss: 2.418229123809088

Epoch: 5| Step: 9
Training loss: 2.4386482468596453
Validation loss: 2.4302196259601465

Epoch: 5| Step: 10
Training loss: 2.5897512289928675
Validation loss: 2.4221711315445966

Epoch: 164| Step: 0
Training loss: 2.586259804546196
Validation loss: 2.4064135091709296

Epoch: 5| Step: 1
Training loss: 2.744316470122131
Validation loss: 2.4242255123996754

Epoch: 5| Step: 2
Training loss: 2.338674109658403
Validation loss: 2.4184498479358694

Epoch: 5| Step: 3
Training loss: 2.503140765460749
Validation loss: 2.4363974682660157

Epoch: 5| Step: 4
Training loss: 2.2039340001590078
Validation loss: 2.4411753251002772

Epoch: 5| Step: 5
Training loss: 2.9645109731207637
Validation loss: 2.435531379722847

Epoch: 5| Step: 6
Training loss: 2.367098262099417
Validation loss: 2.429089718017854

Epoch: 5| Step: 7
Training loss: 2.137131115944523
Validation loss: 2.417051121007848

Epoch: 5| Step: 8
Training loss: 2.8237312708719466
Validation loss: 2.43716500301753

Epoch: 5| Step: 9
Training loss: 2.1644620560959376
Validation loss: 2.42429786609526

Epoch: 5| Step: 10
Training loss: 2.0704987064330815
Validation loss: 2.4231665410250014

Epoch: 165| Step: 0
Training loss: 2.896643070290186
Validation loss: 2.439153020831742

Epoch: 5| Step: 1
Training loss: 2.336864274830066
Validation loss: 2.4148848711529807

Epoch: 5| Step: 2
Training loss: 2.2329115977095992
Validation loss: 2.425568146536494

Epoch: 5| Step: 3
Training loss: 2.5436802585048546
Validation loss: 2.417192018695607

Epoch: 5| Step: 4
Training loss: 2.437810926902644
Validation loss: 2.4382159914537387

Epoch: 5| Step: 5
Training loss: 2.522130101949475
Validation loss: 2.437500077829499

Epoch: 5| Step: 6
Training loss: 2.443217004276651
Validation loss: 2.4281477382998045

Epoch: 5| Step: 7
Training loss: 2.4781820014083897
Validation loss: 2.4149847050936195

Epoch: 5| Step: 8
Training loss: 1.9822913817503887
Validation loss: 2.44206262965409

Epoch: 5| Step: 9
Training loss: 2.6312557338190015
Validation loss: 2.41292677121456

Epoch: 5| Step: 10
Training loss: 2.5375003645572494
Validation loss: 2.4298868505414313

Epoch: 166| Step: 0
Training loss: 2.3447254439879153
Validation loss: 2.4158930082914334

Epoch: 5| Step: 1
Training loss: 2.4938540252940022
Validation loss: 2.4329719028785193

Epoch: 5| Step: 2
Training loss: 2.097537813448238
Validation loss: 2.4431870500410175

Epoch: 5| Step: 3
Training loss: 2.14629631850085
Validation loss: 2.42452328551275

Epoch: 5| Step: 4
Training loss: 2.6101533562633614
Validation loss: 2.4152617042752005

Epoch: 5| Step: 5
Training loss: 2.9564930918712995
Validation loss: 2.4161780637473553

Epoch: 5| Step: 6
Training loss: 2.704066647255628
Validation loss: 2.414613386846592

Epoch: 5| Step: 7
Training loss: 2.5726798150599017
Validation loss: 2.420234901272447

Epoch: 5| Step: 8
Training loss: 2.1062889978437775
Validation loss: 2.439292572512058

Epoch: 5| Step: 9
Training loss: 2.246820852929737
Validation loss: 2.4215675489645507

Epoch: 5| Step: 10
Training loss: 2.639172758483441
Validation loss: 2.4186009850736463

Epoch: 167| Step: 0
Training loss: 2.6753135996449675
Validation loss: 2.4005491946488338

Epoch: 5| Step: 1
Training loss: 2.444350763413887
Validation loss: 2.426398973569055

Epoch: 5| Step: 2
Training loss: 2.722750647070092
Validation loss: 2.435348202518428

Epoch: 5| Step: 3
Training loss: 2.3590660650843107
Validation loss: 2.4229190942969043

Epoch: 5| Step: 4
Training loss: 2.6613295512137487
Validation loss: 2.4384006611617575

Epoch: 5| Step: 5
Training loss: 2.3454410809996737
Validation loss: 2.4122819539607723

Epoch: 5| Step: 6
Training loss: 3.0112934529679594
Validation loss: 2.4145448338701327

Epoch: 5| Step: 7
Training loss: 2.030156354661221
Validation loss: 2.434813095265483

Epoch: 5| Step: 8
Training loss: 2.3327983061147224
Validation loss: 2.4511532142725345

Epoch: 5| Step: 9
Training loss: 2.058690917528611
Validation loss: 2.4394168557958764

Epoch: 5| Step: 10
Training loss: 2.1683121692739795
Validation loss: 2.415887610182147

Epoch: 168| Step: 0
Training loss: 2.231334938975724
Validation loss: 2.435585140680898

Epoch: 5| Step: 1
Training loss: 2.3889003341854056
Validation loss: 2.420666963707757

Epoch: 5| Step: 2
Training loss: 2.333371695702679
Validation loss: 2.4439098701041733

Epoch: 5| Step: 3
Training loss: 2.3363668500111046
Validation loss: 2.4255031374548555

Epoch: 5| Step: 4
Training loss: 2.5347123190862004
Validation loss: 2.40550058747567

Epoch: 5| Step: 5
Training loss: 2.6587347638366627
Validation loss: 2.43288395781101

Epoch: 5| Step: 6
Training loss: 2.106261378407519
Validation loss: 2.416805574337974

Epoch: 5| Step: 7
Training loss: 3.0871347929525847
Validation loss: 2.4102008965889405

Epoch: 5| Step: 8
Training loss: 2.337929275180464
Validation loss: 2.4369033933158186

Epoch: 5| Step: 9
Training loss: 2.7756361292388516
Validation loss: 2.4319131612066265

Epoch: 5| Step: 10
Training loss: 1.9655179939193577
Validation loss: 2.4147310956887114

Epoch: 169| Step: 0
Training loss: 2.02968384446541
Validation loss: 2.426750672771992

Epoch: 5| Step: 1
Training loss: 2.256193326201306
Validation loss: 2.4219363688759388

Epoch: 5| Step: 2
Training loss: 2.40949189413385
Validation loss: 2.4264529833541504

Epoch: 5| Step: 3
Training loss: 2.481695109303226
Validation loss: 2.4048217382876413

Epoch: 5| Step: 4
Training loss: 2.3332314014876845
Validation loss: 2.421405193319249

Epoch: 5| Step: 5
Training loss: 2.636086259498556
Validation loss: 2.4219511921859382

Epoch: 5| Step: 6
Training loss: 2.5347797602099034
Validation loss: 2.4384417748332314

Epoch: 5| Step: 7
Training loss: 2.7612824911517406
Validation loss: 2.416207792601425

Epoch: 5| Step: 8
Training loss: 2.5769849626356276
Validation loss: 2.4282003620152204

Epoch: 5| Step: 9
Training loss: 2.2815591263024424
Validation loss: 2.430058908618225

Epoch: 5| Step: 10
Training loss: 2.5967930786578814
Validation loss: 2.430020170845051

Epoch: 170| Step: 0
Training loss: 2.6090499766875435
Validation loss: 2.421815202592056

Epoch: 5| Step: 1
Training loss: 2.5578857374105266
Validation loss: 2.4285938777301364

Epoch: 5| Step: 2
Training loss: 2.337327932460716
Validation loss: 2.4131667097312794

Epoch: 5| Step: 3
Training loss: 2.1408488581198317
Validation loss: 2.4276549291043774

Epoch: 5| Step: 4
Training loss: 2.458619300459814
Validation loss: 2.413282858499138

Epoch: 5| Step: 5
Training loss: 2.4243162587330014
Validation loss: 2.435863320867063

Epoch: 5| Step: 6
Training loss: 2.555997460162553
Validation loss: 2.4181116075078384

Epoch: 5| Step: 7
Training loss: 2.3728722527701125
Validation loss: 2.425923716136273

Epoch: 5| Step: 8
Training loss: 2.742656787156612
Validation loss: 2.418992379598218

Epoch: 5| Step: 9
Training loss: 2.2195403075041784
Validation loss: 2.4326296588603395

Epoch: 5| Step: 10
Training loss: 2.4506515376184734
Validation loss: 2.432924162086393

Epoch: 171| Step: 0
Training loss: 2.094618318335256
Validation loss: 2.418607826100076

Epoch: 5| Step: 1
Training loss: 2.8273282272279565
Validation loss: 2.4359161736159285

Epoch: 5| Step: 2
Training loss: 2.3055424543057015
Validation loss: 2.4384449661852403

Epoch: 5| Step: 3
Training loss: 2.5827858149816754
Validation loss: 2.4297444553490104

Epoch: 5| Step: 4
Training loss: 2.8883681276239406
Validation loss: 2.413452122246898

Epoch: 5| Step: 5
Training loss: 2.21959423068478
Validation loss: 2.437156072416259

Epoch: 5| Step: 6
Training loss: 2.5896572316296114
Validation loss: 2.4034567384280283

Epoch: 5| Step: 7
Training loss: 2.6818194124839088
Validation loss: 2.4402691961113088

Epoch: 5| Step: 8
Training loss: 2.3717113614333227
Validation loss: 2.436347816374279

Epoch: 5| Step: 9
Training loss: 1.825231430324992
Validation loss: 2.4169475836277514

Epoch: 5| Step: 10
Training loss: 2.254652934295205
Validation loss: 2.4226687673037612

Epoch: 172| Step: 0
Training loss: 2.190147106159459
Validation loss: 2.422175711263345

Epoch: 5| Step: 1
Training loss: 2.933466312977703
Validation loss: 2.4214619824547166

Epoch: 5| Step: 2
Training loss: 2.3182957165662588
Validation loss: 2.439332658551255

Epoch: 5| Step: 3
Training loss: 2.337538562803355
Validation loss: 2.42506778632025

Epoch: 5| Step: 4
Training loss: 2.3259652379883233
Validation loss: 2.428709746832432

Epoch: 5| Step: 5
Training loss: 3.1098341099692632
Validation loss: 2.432204780907272

Epoch: 5| Step: 6
Training loss: 2.428893913367774
Validation loss: 2.4433605616763785

Epoch: 5| Step: 7
Training loss: 2.2800590855488263
Validation loss: 2.430280629053051

Epoch: 5| Step: 8
Training loss: 2.3440443744169692
Validation loss: 2.4100975914599583

Epoch: 5| Step: 9
Training loss: 2.2423829315826116
Validation loss: 2.4361871539451276

Epoch: 5| Step: 10
Training loss: 1.99464032136039
Validation loss: 2.446075597159958

Epoch: 173| Step: 0
Training loss: 2.313087697999995
Validation loss: 2.419599484376411

Epoch: 5| Step: 1
Training loss: 1.8157853572763882
Validation loss: 2.4255757458065133

Epoch: 5| Step: 2
Training loss: 2.8721805513738063
Validation loss: 2.4092730430291014

Epoch: 5| Step: 3
Training loss: 2.5482019817296986
Validation loss: 2.415693816754876

Epoch: 5| Step: 4
Training loss: 2.08153409193143
Validation loss: 2.4167179055204566

Epoch: 5| Step: 5
Training loss: 2.2311281742635667
Validation loss: 2.422049389030975

Epoch: 5| Step: 6
Training loss: 2.7817521231361995
Validation loss: 2.408350076165519

Epoch: 5| Step: 7
Training loss: 2.694689515582117
Validation loss: 2.4242193513436

Epoch: 5| Step: 8
Training loss: 2.6644954385544812
Validation loss: 2.4100543236757366

Epoch: 5| Step: 9
Training loss: 2.305571822858461
Validation loss: 2.429793209248933

Epoch: 5| Step: 10
Training loss: 2.3460548766044043
Validation loss: 2.432039671563189

Epoch: 174| Step: 0
Training loss: 3.0283242489796245
Validation loss: 2.408908508450546

Epoch: 5| Step: 1
Training loss: 2.342653246806221
Validation loss: 2.4276487751676874

Epoch: 5| Step: 2
Training loss: 2.834000864118984
Validation loss: 2.428872266502179

Epoch: 5| Step: 3
Training loss: 1.6568857088609894
Validation loss: 2.4236710022268886

Epoch: 5| Step: 4
Training loss: 2.4691624357264725
Validation loss: 2.4314376783923164

Epoch: 5| Step: 5
Training loss: 2.604018326667014
Validation loss: 2.4339444638192544

Epoch: 5| Step: 6
Training loss: 2.3083764504859694
Validation loss: 2.410514125944862

Epoch: 5| Step: 7
Training loss: 1.94445242501695
Validation loss: 2.4023852785184157

Epoch: 5| Step: 8
Training loss: 2.362138153299556
Validation loss: 2.412868797332621

Epoch: 5| Step: 9
Training loss: 2.63891419738769
Validation loss: 2.4136779098624226

Epoch: 5| Step: 10
Training loss: 2.3998075169623996
Validation loss: 2.418238149751015

Epoch: 175| Step: 0
Training loss: 2.4752131977156044
Validation loss: 2.4229170458544367

Epoch: 5| Step: 1
Training loss: 1.7354172332994773
Validation loss: 2.4333175280933257

Epoch: 5| Step: 2
Training loss: 2.131172639667739
Validation loss: 2.4113632261709075

Epoch: 5| Step: 3
Training loss: 2.5583139980053535
Validation loss: 2.4286589687507205

Epoch: 5| Step: 4
Training loss: 2.933850882851345
Validation loss: 2.4106904834820817

Epoch: 5| Step: 5
Training loss: 1.9648015224401185
Validation loss: 2.405183095064186

Epoch: 5| Step: 6
Training loss: 2.981568779686373
Validation loss: 2.3931407984235347

Epoch: 5| Step: 7
Training loss: 2.4255887997960004
Validation loss: 2.445715628205957

Epoch: 5| Step: 8
Training loss: 2.1392348850470113
Validation loss: 2.435977999110257

Epoch: 5| Step: 9
Training loss: 2.7226452163625963
Validation loss: 2.411260854354639

Epoch: 5| Step: 10
Training loss: 2.3233178195772917
Validation loss: 2.4144233189446886

Epoch: 176| Step: 0
Training loss: 2.450993869594843
Validation loss: 2.430836000704665

Epoch: 5| Step: 1
Training loss: 3.1163371750029976
Validation loss: 2.4508003029384464

Epoch: 5| Step: 2
Training loss: 2.1064528958993654
Validation loss: 2.411565034413495

Epoch: 5| Step: 3
Training loss: 2.441861188081569
Validation loss: 2.4209615127200115

Epoch: 5| Step: 4
Training loss: 2.37674859576727
Validation loss: 2.4217469154067546

Epoch: 5| Step: 5
Training loss: 2.8014850663197803
Validation loss: 2.4298154767355182

Epoch: 5| Step: 6
Training loss: 2.0107751503642235
Validation loss: 2.421711552900401

Epoch: 5| Step: 7
Training loss: 2.0956460139731012
Validation loss: 2.4135627562503603

Epoch: 5| Step: 8
Training loss: 2.6377139325633974
Validation loss: 2.409614640810784

Epoch: 5| Step: 9
Training loss: 2.505923691813926
Validation loss: 2.40621657255745

Epoch: 5| Step: 10
Training loss: 1.8866565765182932
Validation loss: 2.428538692081725

Epoch: 177| Step: 0
Training loss: 2.244313896535068
Validation loss: 2.423070521880046

Epoch: 5| Step: 1
Training loss: 2.1804845302971616
Validation loss: 2.413546126686469

Epoch: 5| Step: 2
Training loss: 2.6899994161669016
Validation loss: 2.416894173936912

Epoch: 5| Step: 3
Training loss: 2.3176020451437602
Validation loss: 2.4359486620322075

Epoch: 5| Step: 4
Training loss: 2.9207539575287615
Validation loss: 2.4314592655157847

Epoch: 5| Step: 5
Training loss: 2.7259053747332302
Validation loss: 2.4322290015671877

Epoch: 5| Step: 6
Training loss: 2.0082851699604456
Validation loss: 2.408760844215815

Epoch: 5| Step: 7
Training loss: 2.4362842755869374
Validation loss: 2.41961176324989

Epoch: 5| Step: 8
Training loss: 2.066283483770495
Validation loss: 2.423094265696306

Epoch: 5| Step: 9
Training loss: 2.7215640533158996
Validation loss: 2.425312815192649

Epoch: 5| Step: 10
Training loss: 2.067596727205012
Validation loss: 2.4377786368237992

Epoch: 178| Step: 0
Training loss: 2.713365418512343
Validation loss: 2.4131181351673883

Epoch: 5| Step: 1
Training loss: 2.12623055675123
Validation loss: 2.4157201184836707

Epoch: 5| Step: 2
Training loss: 2.1913788329668598
Validation loss: 2.4417396813221255

Epoch: 5| Step: 3
Training loss: 2.977481569990617
Validation loss: 2.4347015210321783

Epoch: 5| Step: 4
Training loss: 2.8042127797235437
Validation loss: 2.4152278612798215

Epoch: 5| Step: 5
Training loss: 2.0139819405057606
Validation loss: 2.4256572509723213

Epoch: 5| Step: 6
Training loss: 2.396712487392449
Validation loss: 2.4129025565439797

Epoch: 5| Step: 7
Training loss: 2.2404212507877723
Validation loss: 2.408044796402263

Epoch: 5| Step: 8
Training loss: 2.313102231350405
Validation loss: 2.427368085743116

Epoch: 5| Step: 9
Training loss: 2.326646373663926
Validation loss: 2.3922075736633484

Epoch: 5| Step: 10
Training loss: 2.1890873190802282
Validation loss: 2.3980207910622098

Epoch: 179| Step: 0
Training loss: 2.8072346886188306
Validation loss: 2.440895052117754

Epoch: 5| Step: 1
Training loss: 2.335670583523616
Validation loss: 2.408794069258309

Epoch: 5| Step: 2
Training loss: 2.10428508261674
Validation loss: 2.423557611831227

Epoch: 5| Step: 3
Training loss: 2.3732006886558232
Validation loss: 2.4303762684066457

Epoch: 5| Step: 4
Training loss: 2.553638021037158
Validation loss: 2.42246341708982

Epoch: 5| Step: 5
Training loss: 1.6205057203691524
Validation loss: 2.421472184220965

Epoch: 5| Step: 6
Training loss: 2.7304257019753475
Validation loss: 2.4163942280713284

Epoch: 5| Step: 7
Training loss: 2.625029790800076
Validation loss: 2.401956236477409

Epoch: 5| Step: 8
Training loss: 2.5680697317667986
Validation loss: 2.415946427381596

Epoch: 5| Step: 9
Training loss: 2.2489319491609314
Validation loss: 2.4216414546400116

Epoch: 5| Step: 10
Training loss: 2.29849455948676
Validation loss: 2.4027337905575497

Epoch: 180| Step: 0
Training loss: 2.9862556323975964
Validation loss: 2.4291091566683756

Epoch: 5| Step: 1
Training loss: 2.4572389936333576
Validation loss: 2.40137642734767

Epoch: 5| Step: 2
Training loss: 2.1134065883507427
Validation loss: 2.4195737959112096

Epoch: 5| Step: 3
Training loss: 2.4252132911872852
Validation loss: 2.4185184333252097

Epoch: 5| Step: 4
Training loss: 2.3384956972720023
Validation loss: 2.41856441800708

Epoch: 5| Step: 5
Training loss: 2.485614107725331
Validation loss: 2.425292425958003

Epoch: 5| Step: 6
Training loss: 2.196736481424944
Validation loss: 2.431877771008818

Epoch: 5| Step: 7
Training loss: 2.915446998257042
Validation loss: 2.4246245158323267

Epoch: 5| Step: 8
Training loss: 1.9533611917733298
Validation loss: 2.415188484393918

Epoch: 5| Step: 9
Training loss: 2.247814494566587
Validation loss: 2.424942354253535

Epoch: 5| Step: 10
Training loss: 2.1792101046704633
Validation loss: 2.420092155331077

Epoch: 181| Step: 0
Training loss: 2.21816310373675
Validation loss: 2.425255479877176

Epoch: 5| Step: 1
Training loss: 2.3900569664777938
Validation loss: 2.423332652693772

Epoch: 5| Step: 2
Training loss: 2.0668403731941614
Validation loss: 2.414668408739254

Epoch: 5| Step: 3
Training loss: 2.442699559784989
Validation loss: 2.4059602083224045

Epoch: 5| Step: 4
Training loss: 2.529622437722515
Validation loss: 2.429210577917767

Epoch: 5| Step: 5
Training loss: 2.0344847525013305
Validation loss: 2.389241279699917

Epoch: 5| Step: 6
Training loss: 2.1543103768417553
Validation loss: 2.40010685939185

Epoch: 5| Step: 7
Training loss: 2.547425099508082
Validation loss: 2.4034847153571737

Epoch: 5| Step: 8
Training loss: 2.4403038526731833
Validation loss: 2.412113591207448

Epoch: 5| Step: 9
Training loss: 3.102804170832278
Validation loss: 2.4144623260668077

Epoch: 5| Step: 10
Training loss: 2.404307485474912
Validation loss: 2.435856965072851

Epoch: 182| Step: 0
Training loss: 1.8470701937470222
Validation loss: 2.4083877153541047

Epoch: 5| Step: 1
Training loss: 1.9547153559345771
Validation loss: 2.4365986266229824

Epoch: 5| Step: 2
Training loss: 2.978636171997076
Validation loss: 2.430547416915589

Epoch: 5| Step: 3
Training loss: 2.4997232283928743
Validation loss: 2.4237268005987676

Epoch: 5| Step: 4
Training loss: 2.505242668017028
Validation loss: 2.398433788847563

Epoch: 5| Step: 5
Training loss: 2.7208557743317368
Validation loss: 2.4040918493800656

Epoch: 5| Step: 6
Training loss: 2.0762253877305175
Validation loss: 2.4183022108139207

Epoch: 5| Step: 7
Training loss: 2.215774152332933
Validation loss: 2.3976103642501205

Epoch: 5| Step: 8
Training loss: 1.6545029548994454
Validation loss: 2.4279023704363505

Epoch: 5| Step: 9
Training loss: 3.0335739508411805
Validation loss: 2.4112535076655632

Epoch: 5| Step: 10
Training loss: 2.4599092787784995
Validation loss: 2.403490987162096

Epoch: 183| Step: 0
Training loss: 2.2070436730499368
Validation loss: 2.4218070876450457

Epoch: 5| Step: 1
Training loss: 2.555638967295351
Validation loss: 2.4123554012765207

Epoch: 5| Step: 2
Training loss: 2.638491880657751
Validation loss: 2.4292623079735365

Epoch: 5| Step: 3
Training loss: 1.8268835302852613
Validation loss: 2.442950727445736

Epoch: 5| Step: 4
Training loss: 2.3726269762571475
Validation loss: 2.428443727774938

Epoch: 5| Step: 5
Training loss: 2.403521291055608
Validation loss: 2.4128921814857085

Epoch: 5| Step: 6
Training loss: 2.717056185251283
Validation loss: 2.411340809550522

Epoch: 5| Step: 7
Training loss: 1.9007618179927261
Validation loss: 2.429471146135398

Epoch: 5| Step: 8
Training loss: 2.896452601972985
Validation loss: 2.431793801364618

Epoch: 5| Step: 9
Training loss: 2.451194538148467
Validation loss: 2.436737655470937

Epoch: 5| Step: 10
Training loss: 1.998054034536293
Validation loss: 2.421326527594945

Epoch: 184| Step: 0
Training loss: 2.0869460507316786
Validation loss: 2.4130303005075118

Epoch: 5| Step: 1
Training loss: 2.273830314337655
Validation loss: 2.42658976846255

Epoch: 5| Step: 2
Training loss: 2.7976530047890282
Validation loss: 2.437269134147918

Epoch: 5| Step: 3
Training loss: 2.6449107766922118
Validation loss: 2.419414918693625

Epoch: 5| Step: 4
Training loss: 2.32964188488233
Validation loss: 2.4182751033912075

Epoch: 5| Step: 5
Training loss: 2.6468960487582676
Validation loss: 2.4077461555027067

Epoch: 5| Step: 6
Training loss: 2.154778240857502
Validation loss: 2.427015306164723

Epoch: 5| Step: 7
Training loss: 1.787741627401111
Validation loss: 2.441924905005629

Epoch: 5| Step: 8
Training loss: 2.3904427851628163
Validation loss: 2.4128273727515555

Epoch: 5| Step: 9
Training loss: 2.845978586744977
Validation loss: 2.4405555893691098

Epoch: 5| Step: 10
Training loss: 2.0858954378952057
Validation loss: 2.4154369210189457

Epoch: 185| Step: 0
Training loss: 1.938394647592294
Validation loss: 2.4257935282305807

Epoch: 5| Step: 1
Training loss: 2.768139918776563
Validation loss: 2.428467718863811

Epoch: 5| Step: 2
Training loss: 2.3356293439939555
Validation loss: 2.42819444965096

Epoch: 5| Step: 3
Training loss: 2.2373465671890544
Validation loss: 2.410066487366987

Epoch: 5| Step: 4
Training loss: 1.827069882814955
Validation loss: 2.4239352891391213

Epoch: 5| Step: 5
Training loss: 2.6724800183340522
Validation loss: 2.4310364239222086

Epoch: 5| Step: 6
Training loss: 2.756543264552208
Validation loss: 2.446948696626469

Epoch: 5| Step: 7
Training loss: 1.7158014147721414
Validation loss: 2.4213633822226592

Epoch: 5| Step: 8
Training loss: 2.121715700352561
Validation loss: 2.409199379903996

Epoch: 5| Step: 9
Training loss: 2.892139759628015
Validation loss: 2.4246720817004683

Epoch: 5| Step: 10
Training loss: 2.8589987585459333
Validation loss: 2.426439506113508

Epoch: 186| Step: 0
Training loss: 2.146808908658479
Validation loss: 2.4152793930062684

Epoch: 5| Step: 1
Training loss: 2.7623455194286026
Validation loss: 2.4050224879774054

Epoch: 5| Step: 2
Training loss: 2.4040169200396986
Validation loss: 2.4253534330096

Epoch: 5| Step: 3
Training loss: 2.161756147220395
Validation loss: 2.3870489150814547

Epoch: 5| Step: 4
Training loss: 2.2572921628530462
Validation loss: 2.415924747805256

Epoch: 5| Step: 5
Training loss: 2.1319277538705173
Validation loss: 2.4322539966896097

Epoch: 5| Step: 6
Training loss: 2.2498924441591477
Validation loss: 2.4163989083878015

Epoch: 5| Step: 7
Training loss: 2.2224569382159287
Validation loss: 2.4096548971332834

Epoch: 5| Step: 8
Training loss: 2.8831383332333482
Validation loss: 2.4229543354891825

Epoch: 5| Step: 9
Training loss: 2.6432237646990417
Validation loss: 2.431717261829702

Epoch: 5| Step: 10
Training loss: 2.2164646252598024
Validation loss: 2.4125695676919903

Epoch: 187| Step: 0
Training loss: 2.338402713535756
Validation loss: 2.4075575430802987

Epoch: 5| Step: 1
Training loss: 2.5387424678117894
Validation loss: 2.3974140529310017

Epoch: 5| Step: 2
Training loss: 2.345151965132108
Validation loss: 2.391632361664635

Epoch: 5| Step: 3
Training loss: 2.0669579157132323
Validation loss: 2.3952490423584654

Epoch: 5| Step: 4
Training loss: 2.1578280437995208
Validation loss: 2.3868191337121853

Epoch: 5| Step: 5
Training loss: 2.0561159919273817
Validation loss: 2.4159508862586168

Epoch: 5| Step: 6
Training loss: 2.4476645373640324
Validation loss: 2.4140911695954492

Epoch: 5| Step: 7
Training loss: 2.712414605690668
Validation loss: 2.3954354218364564

Epoch: 5| Step: 8
Training loss: 2.1734514621310836
Validation loss: 2.409088753028594

Epoch: 5| Step: 9
Training loss: 2.4615011871477606
Validation loss: 2.4237918081409746

Epoch: 5| Step: 10
Training loss: 2.8583594014246008
Validation loss: 2.412786346967907

Epoch: 188| Step: 0
Training loss: 2.788851604448857
Validation loss: 2.422619618174346

Epoch: 5| Step: 1
Training loss: 1.8711958759764735
Validation loss: 2.403161166153772

Epoch: 5| Step: 2
Training loss: 1.8804939525073912
Validation loss: 2.409046090730252

Epoch: 5| Step: 3
Training loss: 2.29885726819489
Validation loss: 2.43715757347485

Epoch: 5| Step: 4
Training loss: 2.231597988656849
Validation loss: 2.40897659287757

Epoch: 5| Step: 5
Training loss: 2.2189921931937007
Validation loss: 2.414805879425097

Epoch: 5| Step: 6
Training loss: 2.603769368700792
Validation loss: 2.4131530260240184

Epoch: 5| Step: 7
Training loss: 2.791616429878027
Validation loss: 2.4219631701670754

Epoch: 5| Step: 8
Training loss: 2.445769733423043
Validation loss: 2.4222918069405406

Epoch: 5| Step: 9
Training loss: 2.3814411156723048
Validation loss: 2.443748524643383

Epoch: 5| Step: 10
Training loss: 2.484079403356047
Validation loss: 2.407230310683213

Epoch: 189| Step: 0
Training loss: 2.143319654505118
Validation loss: 2.409943602010167

Epoch: 5| Step: 1
Training loss: 2.46548767867807
Validation loss: 2.4044704742281415

Epoch: 5| Step: 2
Training loss: 2.407671025778144
Validation loss: 2.4004034047708687

Epoch: 5| Step: 3
Training loss: 2.3113324078753417
Validation loss: 2.4086810668016416

Epoch: 5| Step: 4
Training loss: 2.6131296156610047
Validation loss: 2.4292655615121768

Epoch: 5| Step: 5
Training loss: 2.490731223412658
Validation loss: 2.4046508920817975

Epoch: 5| Step: 6
Training loss: 1.9967709939583038
Validation loss: 2.391468927273256

Epoch: 5| Step: 7
Training loss: 2.690936087635765
Validation loss: 2.432715075526896

Epoch: 5| Step: 8
Training loss: 2.317839155184026
Validation loss: 2.3995918397281324

Epoch: 5| Step: 9
Training loss: 1.8929124975721847
Validation loss: 2.436253695236018

Epoch: 5| Step: 10
Training loss: 2.6805359856698794
Validation loss: 2.43491912842937

Epoch: 190| Step: 0
Training loss: 2.2579808155930876
Validation loss: 2.4054071969092004

Epoch: 5| Step: 1
Training loss: 1.9923231490084818
Validation loss: 2.4364128622830012

Epoch: 5| Step: 2
Training loss: 2.325905990458909
Validation loss: 2.387235236739015

Epoch: 5| Step: 3
Training loss: 2.4182264840804524
Validation loss: 2.3833239053129107

Epoch: 5| Step: 4
Training loss: 3.047505944287681
Validation loss: 2.3828879691575025

Epoch: 5| Step: 5
Training loss: 2.2883927859561526
Validation loss: 2.4414018197624454

Epoch: 5| Step: 6
Training loss: 2.456727219831276
Validation loss: 2.410541669474668

Epoch: 5| Step: 7
Training loss: 2.4439655530846394
Validation loss: 2.403361966013744

Epoch: 5| Step: 8
Training loss: 1.7486064675838164
Validation loss: 2.402331520527651

Epoch: 5| Step: 9
Training loss: 2.348755234920074
Validation loss: 2.3926317410450015

Epoch: 5| Step: 10
Training loss: 2.443056180760044
Validation loss: 2.4105894988690966

Epoch: 191| Step: 0
Training loss: 2.463399182662463
Validation loss: 2.4339796717695577

Epoch: 5| Step: 1
Training loss: 2.226788318626829
Validation loss: 2.420004317431394

Epoch: 5| Step: 2
Training loss: 2.2901107939525285
Validation loss: 2.397579138790759

Epoch: 5| Step: 3
Training loss: 2.4675361449774185
Validation loss: 2.420087076968224

Epoch: 5| Step: 4
Training loss: 3.004909313185466
Validation loss: 2.4164267970084525

Epoch: 5| Step: 5
Training loss: 2.557162517904338
Validation loss: 2.3981212158775342

Epoch: 5| Step: 6
Training loss: 2.1159329797338433
Validation loss: 2.4176778255018325

Epoch: 5| Step: 7
Training loss: 2.0540020745851018
Validation loss: 2.407736124499778

Epoch: 5| Step: 8
Training loss: 2.2469240992331816
Validation loss: 2.406219648434272

Epoch: 5| Step: 9
Training loss: 2.2061062385037546
Validation loss: 2.416169066184885

Epoch: 5| Step: 10
Training loss: 2.133085911032468
Validation loss: 2.42085338881657

Epoch: 192| Step: 0
Training loss: 2.1908941911631787
Validation loss: 2.4095903189123637

Epoch: 5| Step: 1
Training loss: 2.161351457887337
Validation loss: 2.4019134208094455

Epoch: 5| Step: 2
Training loss: 2.755614531391805
Validation loss: 2.4251425504676645

Epoch: 5| Step: 3
Training loss: 2.5150099292657715
Validation loss: 2.4247243156396796

Epoch: 5| Step: 4
Training loss: 2.102042784991324
Validation loss: 2.3882362800922206

Epoch: 5| Step: 5
Training loss: 2.2290607557954414
Validation loss: 2.421690414015634

Epoch: 5| Step: 6
Training loss: 2.4738165135474772
Validation loss: 2.3899931496575078

Epoch: 5| Step: 7
Training loss: 2.0653315671876693
Validation loss: 2.404853908017638

Epoch: 5| Step: 8
Training loss: 2.494470489364095
Validation loss: 2.415432409717242

Epoch: 5| Step: 9
Training loss: 2.2199495323561966
Validation loss: 2.3920757886910002

Epoch: 5| Step: 10
Training loss: 2.7845957487648554
Validation loss: 2.4015426808818288

Epoch: 193| Step: 0
Training loss: 2.149014260295773
Validation loss: 2.397547518361814

Epoch: 5| Step: 1
Training loss: 2.1656054563314795
Validation loss: 2.4060046695915585

Epoch: 5| Step: 2
Training loss: 2.937332473198339
Validation loss: 2.40443360909751

Epoch: 5| Step: 3
Training loss: 2.0753428256394426
Validation loss: 2.413266068190916

Epoch: 5| Step: 4
Training loss: 2.8318140407004835
Validation loss: 2.4002953918838403

Epoch: 5| Step: 5
Training loss: 2.232396029692364
Validation loss: 2.3958618051799783

Epoch: 5| Step: 6
Training loss: 2.115316429906602
Validation loss: 2.40875317007901

Epoch: 5| Step: 7
Training loss: 2.327218922689384
Validation loss: 2.423442214676989

Epoch: 5| Step: 8
Training loss: 2.1752422767837882
Validation loss: 2.3675974888807803

Epoch: 5| Step: 9
Training loss: 2.9231181228684036
Validation loss: 2.4211315505147724

Epoch: 5| Step: 10
Training loss: 1.3388766699524024
Validation loss: 2.390045304844043

Epoch: 194| Step: 0
Training loss: 2.6007978902314806
Validation loss: 2.395830815881492

Epoch: 5| Step: 1
Training loss: 2.3106662593642353
Validation loss: 2.404295349160595

Epoch: 5| Step: 2
Training loss: 2.4252963602723168
Validation loss: 2.432145231145851

Epoch: 5| Step: 3
Training loss: 2.1080419778860633
Validation loss: 2.408323332019978

Epoch: 5| Step: 4
Training loss: 2.884310697456654
Validation loss: 2.3967470571226945

Epoch: 5| Step: 5
Training loss: 2.443389721627844
Validation loss: 2.403219990799986

Epoch: 5| Step: 6
Training loss: 2.2052059221021767
Validation loss: 2.387668969411063

Epoch: 5| Step: 7
Training loss: 1.352296001752762
Validation loss: 2.402600688985205

Epoch: 5| Step: 8
Training loss: 2.829614910709179
Validation loss: 2.4187783642822493

Epoch: 5| Step: 9
Training loss: 2.2744538961732927
Validation loss: 2.414818771877047

Epoch: 5| Step: 10
Training loss: 1.8789627161879672
Validation loss: 2.4057682536884863

Epoch: 195| Step: 0
Training loss: 1.41149779354927
Validation loss: 2.3963419281232596

Epoch: 5| Step: 1
Training loss: 2.2976353223795103
Validation loss: 2.385876300480123

Epoch: 5| Step: 2
Training loss: 2.8601069946549242
Validation loss: 2.4110114743728115

Epoch: 5| Step: 3
Training loss: 2.427269618753554
Validation loss: 2.403938692020294

Epoch: 5| Step: 4
Training loss: 2.2291379790079318
Validation loss: 2.403511423212908

Epoch: 5| Step: 5
Training loss: 1.8441542489377405
Validation loss: 2.3896675484750496

Epoch: 5| Step: 6
Training loss: 2.5555920414001667
Validation loss: 2.4055084995239464

Epoch: 5| Step: 7
Training loss: 2.6129452157188258
Validation loss: 2.4114857851061138

Epoch: 5| Step: 8
Training loss: 2.5188386660131354
Validation loss: 2.399445490587636

Epoch: 5| Step: 9
Training loss: 1.8134820842504789
Validation loss: 2.405660664975621

Epoch: 5| Step: 10
Training loss: 2.650596166524502
Validation loss: 2.412950829461931

Epoch: 196| Step: 0
Training loss: 2.379504299313035
Validation loss: 2.402816292460023

Epoch: 5| Step: 1
Training loss: 2.0683070420226697
Validation loss: 2.388747351144252

Epoch: 5| Step: 2
Training loss: 2.463717389173982
Validation loss: 2.414299121493934

Epoch: 5| Step: 3
Training loss: 2.1464111759939857
Validation loss: 2.4033819652893293

Epoch: 5| Step: 4
Training loss: 2.6555065236515163
Validation loss: 2.4041974641659265

Epoch: 5| Step: 5
Training loss: 1.978959029164406
Validation loss: 2.40284853171595

Epoch: 5| Step: 6
Training loss: 2.3200383393638484
Validation loss: 2.392588278485423

Epoch: 5| Step: 7
Training loss: 1.793914877727339
Validation loss: 2.3978667295382263

Epoch: 5| Step: 8
Training loss: 3.045283601329179
Validation loss: 2.381099901675954

Epoch: 5| Step: 9
Training loss: 2.1093861897489665
Validation loss: 2.403820400311484

Epoch: 5| Step: 10
Training loss: 2.4665599718302027
Validation loss: 2.4186157885471276

Epoch: 197| Step: 0
Training loss: 2.6691350440245145
Validation loss: 2.4099650050921717

Epoch: 5| Step: 1
Training loss: 2.411708239355437
Validation loss: 2.4226212901457838

Epoch: 5| Step: 2
Training loss: 2.336949362131536
Validation loss: 2.414862157062691

Epoch: 5| Step: 3
Training loss: 2.903990164327648
Validation loss: 2.4094631889645703

Epoch: 5| Step: 4
Training loss: 2.0241798011392387
Validation loss: 2.400890916216789

Epoch: 5| Step: 5
Training loss: 2.0512676134579526
Validation loss: 2.4084707005574577

Epoch: 5| Step: 6
Training loss: 1.9211743325873962
Validation loss: 2.3865686337898135

Epoch: 5| Step: 7
Training loss: 2.320366958338723
Validation loss: 2.3927724722239634

Epoch: 5| Step: 8
Training loss: 2.562874371233325
Validation loss: 2.4000671169251833

Epoch: 5| Step: 9
Training loss: 2.046688042175965
Validation loss: 2.4351582291291085

Epoch: 5| Step: 10
Training loss: 2.274400539857557
Validation loss: 2.398943255411771

Epoch: 198| Step: 0
Training loss: 2.6719292529214145
Validation loss: 2.4107797233458124

Epoch: 5| Step: 1
Training loss: 2.180573204870806
Validation loss: 2.411710450389919

Epoch: 5| Step: 2
Training loss: 2.3329131792626874
Validation loss: 2.4097690555461777

Epoch: 5| Step: 3
Training loss: 2.341456600916842
Validation loss: 2.374381791781568

Epoch: 5| Step: 4
Training loss: 1.8966328398778132
Validation loss: 2.4300749451729673

Epoch: 5| Step: 5
Training loss: 2.130145630850241
Validation loss: 2.392288009201635

Epoch: 5| Step: 6
Training loss: 2.5025215783651307
Validation loss: 2.38944054669131

Epoch: 5| Step: 7
Training loss: 2.520712500164167
Validation loss: 2.393862252602281

Epoch: 5| Step: 8
Training loss: 2.6772875479105296
Validation loss: 2.402928973799011

Epoch: 5| Step: 9
Training loss: 2.131619074123411
Validation loss: 2.396935641041768

Epoch: 5| Step: 10
Training loss: 2.079077824877701
Validation loss: 2.4223187408250664

Epoch: 199| Step: 0
Training loss: 2.359992748507981
Validation loss: 2.3982195370184196

Epoch: 5| Step: 1
Training loss: 2.1423811565541966
Validation loss: 2.396800172388106

Epoch: 5| Step: 2
Training loss: 2.011387236603153
Validation loss: 2.3995193788949067

Epoch: 5| Step: 3
Training loss: 2.719498892933809
Validation loss: 2.398032112436213

Epoch: 5| Step: 4
Training loss: 2.3207759715398866
Validation loss: 2.420928081914422

Epoch: 5| Step: 5
Training loss: 2.3310263559691684
Validation loss: 2.3957513441169764

Epoch: 5| Step: 6
Training loss: 2.290039270722272
Validation loss: 2.4114708793925237

Epoch: 5| Step: 7
Training loss: 2.2959338485213134
Validation loss: 2.4121878359570346

Epoch: 5| Step: 8
Training loss: 1.9342032656753578
Validation loss: 2.383589453187208

Epoch: 5| Step: 9
Training loss: 2.2355351137301467
Validation loss: 2.3862490205097693

Epoch: 5| Step: 10
Training loss: 2.748846939410664
Validation loss: 2.412873968449101

Epoch: 200| Step: 0
Training loss: 2.006481872659222
Validation loss: 2.4026534080938973

Epoch: 5| Step: 1
Training loss: 2.8241490187946683
Validation loss: 2.4003362391904615

Epoch: 5| Step: 2
Training loss: 1.609683849735672
Validation loss: 2.4014198258653754

Epoch: 5| Step: 3
Training loss: 2.4604668061145833
Validation loss: 2.4139692049085038

Epoch: 5| Step: 4
Training loss: 2.2318416719236955
Validation loss: 2.3925646948170627

Epoch: 5| Step: 5
Training loss: 2.334498443812156
Validation loss: 2.3877651677894387

Epoch: 5| Step: 6
Training loss: 2.7153374312260863
Validation loss: 2.387750250353363

Epoch: 5| Step: 7
Training loss: 2.6389788852091236
Validation loss: 2.4182057880840357

Epoch: 5| Step: 8
Training loss: 2.4915692271016554
Validation loss: 2.385682026014374

Epoch: 5| Step: 9
Training loss: 2.013889482286154
Validation loss: 2.3934703507513824

Epoch: 5| Step: 10
Training loss: 1.5819578554059264
Validation loss: 2.3837670092659824

Epoch: 201| Step: 0
Training loss: 2.318747458238057
Validation loss: 2.383638828466654

Epoch: 5| Step: 1
Training loss: 2.141868174630815
Validation loss: 2.403109357498038

Epoch: 5| Step: 2
Training loss: 2.3315958865886115
Validation loss: 2.4005026352511245

Epoch: 5| Step: 3
Training loss: 1.6880917394667012
Validation loss: 2.4010365120640214

Epoch: 5| Step: 4
Training loss: 2.6171038713900945
Validation loss: 2.3767565814169065

Epoch: 5| Step: 5
Training loss: 2.2622801194383846
Validation loss: 2.3947307737274013

Epoch: 5| Step: 6
Training loss: 2.5436165214591107
Validation loss: 2.378016574122351

Epoch: 5| Step: 7
Training loss: 2.9149135952374636
Validation loss: 2.3889624052603127

Epoch: 5| Step: 8
Training loss: 2.5631975294565588
Validation loss: 2.412601948642935

Epoch: 5| Step: 9
Training loss: 1.7182300127838108
Validation loss: 2.4064600745877134

Epoch: 5| Step: 10
Training loss: 2.074892211320538
Validation loss: 2.3913699619440743

Epoch: 202| Step: 0
Training loss: 2.494646061502106
Validation loss: 2.3962846613543944

Epoch: 5| Step: 1
Training loss: 2.1882054962370896
Validation loss: 2.378052641369153

Epoch: 5| Step: 2
Training loss: 2.3164953822570133
Validation loss: 2.3843358305716778

Epoch: 5| Step: 3
Training loss: 2.5667999290781367
Validation loss: 2.3978628197123246

Epoch: 5| Step: 4
Training loss: 2.0705361299473815
Validation loss: 2.4172437768719828

Epoch: 5| Step: 5
Training loss: 2.729551409520765
Validation loss: 2.403728805555291

Epoch: 5| Step: 6
Training loss: 2.3857003144670115
Validation loss: 2.3913548032718257

Epoch: 5| Step: 7
Training loss: 2.4765002125509485
Validation loss: 2.398803856115926

Epoch: 5| Step: 8
Training loss: 2.2658347197183866
Validation loss: 2.3879700202611427

Epoch: 5| Step: 9
Training loss: 1.995792074978258
Validation loss: 2.3949290284115787

Epoch: 5| Step: 10
Training loss: 1.6825977751618884
Validation loss: 2.412001930963556

Epoch: 203| Step: 0
Training loss: 2.0478448099107793
Validation loss: 2.3918527121820206

Epoch: 5| Step: 1
Training loss: 1.9427099014834976
Validation loss: 2.3864001811428674

Epoch: 5| Step: 2
Training loss: 2.8874353905257255
Validation loss: 2.412413766875402

Epoch: 5| Step: 3
Training loss: 2.57956604420393
Validation loss: 2.394946328886794

Epoch: 5| Step: 4
Training loss: 2.832116277010241
Validation loss: 2.3869446713202436

Epoch: 5| Step: 5
Training loss: 1.6629108150834515
Validation loss: 2.406427042105024

Epoch: 5| Step: 6
Training loss: 2.0733674164737588
Validation loss: 2.3926072470437307

Epoch: 5| Step: 7
Training loss: 2.225411100663328
Validation loss: 2.394464221627734

Epoch: 5| Step: 8
Training loss: 2.455925770100682
Validation loss: 2.4021884865705156

Epoch: 5| Step: 9
Training loss: 2.082515123548237
Validation loss: 2.4231964200660094

Epoch: 5| Step: 10
Training loss: 2.3017265307987844
Validation loss: 2.3890592994905386

Epoch: 204| Step: 0
Training loss: 1.8657889135995755
Validation loss: 2.4088857486498134

Epoch: 5| Step: 1
Training loss: 2.391233778089426
Validation loss: 2.392948315233847

Epoch: 5| Step: 2
Training loss: 1.91036892508532
Validation loss: 2.3912711972869225

Epoch: 5| Step: 3
Training loss: 2.4480883166145833
Validation loss: 2.370258143040725

Epoch: 5| Step: 4
Training loss: 2.610374487688098
Validation loss: 2.3785939681391564

Epoch: 5| Step: 5
Training loss: 1.9512756747719961
Validation loss: 2.3962375563811746

Epoch: 5| Step: 6
Training loss: 2.0788936484154545
Validation loss: 2.391651953618041

Epoch: 5| Step: 7
Training loss: 2.4119841384808995
Validation loss: 2.3969925596361357

Epoch: 5| Step: 8
Training loss: 2.1504418473548594
Validation loss: 2.3938587978042243

Epoch: 5| Step: 9
Training loss: 2.845202064780059
Validation loss: 2.390950244020162

Epoch: 5| Step: 10
Training loss: 2.279382019283197
Validation loss: 2.4134487390427846

Epoch: 205| Step: 0
Training loss: 2.0511075586752243
Validation loss: 2.4048996145825883

Epoch: 5| Step: 1
Training loss: 2.1869333895781233
Validation loss: 2.39602692309251

Epoch: 5| Step: 2
Training loss: 2.1688114212529017
Validation loss: 2.392618974408523

Epoch: 5| Step: 3
Training loss: 2.1820318269165457
Validation loss: 2.408645889248855

Epoch: 5| Step: 4
Training loss: 2.376593005343851
Validation loss: 2.3924689337345963

Epoch: 5| Step: 5
Training loss: 2.1585513011004447
Validation loss: 2.3891163091573397

Epoch: 5| Step: 6
Training loss: 2.3757493694039242
Validation loss: 2.40935373081022

Epoch: 5| Step: 7
Training loss: 2.2815458550059593
Validation loss: 2.4036819749839906

Epoch: 5| Step: 8
Training loss: 2.077215468917243
Validation loss: 2.400832349509049

Epoch: 5| Step: 9
Training loss: 2.2073110217448533
Validation loss: 2.393481690436081

Epoch: 5| Step: 10
Training loss: 3.0496947714242713
Validation loss: 2.3667879728951227

Epoch: 206| Step: 0
Training loss: 2.1630820797440204
Validation loss: 2.3918851603046676

Epoch: 5| Step: 1
Training loss: 2.2065638764672495
Validation loss: 2.4016991415519087

Epoch: 5| Step: 2
Training loss: 2.248277216560467
Validation loss: 2.3868236265950076

Epoch: 5| Step: 3
Training loss: 2.3241049858909375
Validation loss: 2.387394451438376

Epoch: 5| Step: 4
Training loss: 1.992428753774445
Validation loss: 2.3843872654896843

Epoch: 5| Step: 5
Training loss: 2.012523186591549
Validation loss: 2.3590947129823423

Epoch: 5| Step: 6
Training loss: 2.4242866568070203
Validation loss: 2.3947447591423106

Epoch: 5| Step: 7
Training loss: 2.2495746210443817
Validation loss: 2.3947491268914054

Epoch: 5| Step: 8
Training loss: 2.5322566915147426
Validation loss: 2.393737461191441

Epoch: 5| Step: 9
Training loss: 1.753685816312898
Validation loss: 2.3786963954172142

Epoch: 5| Step: 10
Training loss: 3.1025888584884873
Validation loss: 2.3862543390195783

Epoch: 207| Step: 0
Training loss: 2.1028699246900686
Validation loss: 2.383563255630472

Epoch: 5| Step: 1
Training loss: 2.386161377001972
Validation loss: 2.400358535898015

Epoch: 5| Step: 2
Training loss: 2.1449143253458236
Validation loss: 2.4059690948880843

Epoch: 5| Step: 3
Training loss: 2.295415193819589
Validation loss: 2.3986669892036345

Epoch: 5| Step: 4
Training loss: 2.054802256813466
Validation loss: 2.3967276597778246

Epoch: 5| Step: 5
Training loss: 1.8533145646761828
Validation loss: 2.4057416865087533

Epoch: 5| Step: 6
Training loss: 2.3887648981529055
Validation loss: 2.398998347640246

Epoch: 5| Step: 7
Training loss: 2.448030076883088
Validation loss: 2.3873348609985934

Epoch: 5| Step: 8
Training loss: 2.5892297353471756
Validation loss: 2.3915683708845052

Epoch: 5| Step: 9
Training loss: 2.4365513251472675
Validation loss: 2.373203191584568

Epoch: 5| Step: 10
Training loss: 2.361340039193992
Validation loss: 2.3611197797393757

Epoch: 208| Step: 0
Training loss: 1.9622286007545764
Validation loss: 2.414227432864778

Epoch: 5| Step: 1
Training loss: 2.5354137319288195
Validation loss: 2.38636540243837

Epoch: 5| Step: 2
Training loss: 2.39790701202738
Validation loss: 2.3868083004916185

Epoch: 5| Step: 3
Training loss: 1.8314930464862247
Validation loss: 2.3873029169552833

Epoch: 5| Step: 4
Training loss: 2.3284148989430284
Validation loss: 2.361701074598617

Epoch: 5| Step: 5
Training loss: 2.4723755494860673
Validation loss: 2.3874809721377623

Epoch: 5| Step: 6
Training loss: 2.558884745349843
Validation loss: 2.388713765702912

Epoch: 5| Step: 7
Training loss: 2.052291691718487
Validation loss: 2.3647507451116656

Epoch: 5| Step: 8
Training loss: 2.4593859428734275
Validation loss: 2.4062406563440932

Epoch: 5| Step: 9
Training loss: 1.8888831193062923
Validation loss: 2.3853699809928424

Epoch: 5| Step: 10
Training loss: 2.629045275884877
Validation loss: 2.38721717643695

Epoch: 209| Step: 0
Training loss: 2.5678583272851268
Validation loss: 2.397646793260529

Epoch: 5| Step: 1
Training loss: 1.8992735979954876
Validation loss: 2.3709291095968195

Epoch: 5| Step: 2
Training loss: 2.133261832390067
Validation loss: 2.3816121376017376

Epoch: 5| Step: 3
Training loss: 2.3556992147631646
Validation loss: 2.390994684722355

Epoch: 5| Step: 4
Training loss: 2.0184218054275087
Validation loss: 2.4069300312430215

Epoch: 5| Step: 5
Training loss: 2.472682283815852
Validation loss: 2.4102676575132453

Epoch: 5| Step: 6
Training loss: 2.3375263233028605
Validation loss: 2.377487735242423

Epoch: 5| Step: 7
Training loss: 2.392079228916666
Validation loss: 2.3924541195645914

Epoch: 5| Step: 8
Training loss: 2.4089366232016256
Validation loss: 2.407630377447722

Epoch: 5| Step: 9
Training loss: 2.2031729402128386
Validation loss: 2.3703678858986406

Epoch: 5| Step: 10
Training loss: 1.963146652301448
Validation loss: 2.406514691658496

Epoch: 210| Step: 0
Training loss: 2.7081740308029913
Validation loss: 2.3858143059969668

Epoch: 5| Step: 1
Training loss: 2.0603534047205954
Validation loss: 2.394302697447164

Epoch: 5| Step: 2
Training loss: 1.985499086167013
Validation loss: 2.392710998743102

Epoch: 5| Step: 3
Training loss: 1.9102068623271444
Validation loss: 2.397305188868497

Epoch: 5| Step: 4
Training loss: 2.4889441165681423
Validation loss: 2.39307226988579

Epoch: 5| Step: 5
Training loss: 2.5563894779421523
Validation loss: 2.4008121026163125

Epoch: 5| Step: 6
Training loss: 1.996275294459542
Validation loss: 2.4026916897560247

Epoch: 5| Step: 7
Training loss: 2.897852753830971
Validation loss: 2.411017525634161

Epoch: 5| Step: 8
Training loss: 2.1039091147747855
Validation loss: 2.404663396009548

Epoch: 5| Step: 9
Training loss: 1.9578759355916047
Validation loss: 2.395808498437541

Epoch: 5| Step: 10
Training loss: 1.8671203984289857
Validation loss: 2.3910871521887125

Epoch: 211| Step: 0
Training loss: 2.4026888963826116
Validation loss: 2.411028481876829

Epoch: 5| Step: 1
Training loss: 1.8592059274948296
Validation loss: 2.419834535207102

Epoch: 5| Step: 2
Training loss: 1.8708648860227532
Validation loss: 2.3863493960498627

Epoch: 5| Step: 3
Training loss: 2.23619123148153
Validation loss: 2.421544865797384

Epoch: 5| Step: 4
Training loss: 2.1754108435550368
Validation loss: 2.3788528321884526

Epoch: 5| Step: 5
Training loss: 2.385386793013392
Validation loss: 2.405258436797688

Epoch: 5| Step: 6
Training loss: 2.295803105408587
Validation loss: 2.3654262971270072

Epoch: 5| Step: 7
Training loss: 2.3639899586239994
Validation loss: 2.3988693792823823

Epoch: 5| Step: 8
Training loss: 2.5946524095832944
Validation loss: 2.370558583488614

Epoch: 5| Step: 9
Training loss: 2.6739781005350647
Validation loss: 2.3708932026855956

Epoch: 5| Step: 10
Training loss: 1.9895889388666192
Validation loss: 2.394383324921955

Epoch: 212| Step: 0
Training loss: 1.9923467834224589
Validation loss: 2.3586637058640267

Epoch: 5| Step: 1
Training loss: 2.270104130780657
Validation loss: 2.389230292220045

Epoch: 5| Step: 2
Training loss: 2.564730998874567
Validation loss: 2.3847395183029896

Epoch: 5| Step: 3
Training loss: 2.563742173739521
Validation loss: 2.383312223642001

Epoch: 5| Step: 4
Training loss: 2.674921897389718
Validation loss: 2.3608699919968257

Epoch: 5| Step: 5
Training loss: 2.6501653655656567
Validation loss: 2.3834314127208396

Epoch: 5| Step: 6
Training loss: 2.2379988513837907
Validation loss: 2.3396687961711837

Epoch: 5| Step: 7
Training loss: 2.081674283972986
Validation loss: 2.394318846072698

Epoch: 5| Step: 8
Training loss: 1.8308199068230284
Validation loss: 2.394454482946976

Epoch: 5| Step: 9
Training loss: 1.5708967801476243
Validation loss: 2.3871641491830107

Epoch: 5| Step: 10
Training loss: 2.2953096622166447
Validation loss: 2.398156018654958

Epoch: 213| Step: 0
Training loss: 2.306199227784725
Validation loss: 2.386261269555629

Epoch: 5| Step: 1
Training loss: 2.1252685825929714
Validation loss: 2.3866003749735007

Epoch: 5| Step: 2
Training loss: 2.1356431670360942
Validation loss: 2.390714020277714

Epoch: 5| Step: 3
Training loss: 2.2606174245068824
Validation loss: 2.388939236511573

Epoch: 5| Step: 4
Training loss: 2.547332348159537
Validation loss: 2.4039489169624777

Epoch: 5| Step: 5
Training loss: 1.7034887222933384
Validation loss: 2.3713018178718595

Epoch: 5| Step: 6
Training loss: 1.6249817333661951
Validation loss: 2.3936165227426223

Epoch: 5| Step: 7
Training loss: 2.3037829676901507
Validation loss: 2.3864706050168962

Epoch: 5| Step: 8
Training loss: 1.9920919358015143
Validation loss: 2.381222171850695

Epoch: 5| Step: 9
Training loss: 2.2712287791829593
Validation loss: 2.3881300533554772

Epoch: 5| Step: 10
Training loss: 3.203945445611868
Validation loss: 2.3891258490870104

Epoch: 214| Step: 0
Training loss: 2.2305480622255036
Validation loss: 2.3988712708577116

Epoch: 5| Step: 1
Training loss: 2.651241832038927
Validation loss: 2.4177084488842686

Epoch: 5| Step: 2
Training loss: 2.094348081884203
Validation loss: 2.400968992616545

Epoch: 5| Step: 3
Training loss: 1.952124743868844
Validation loss: 2.368056817898885

Epoch: 5| Step: 4
Training loss: 2.7580287081335677
Validation loss: 2.3679259818939675

Epoch: 5| Step: 5
Training loss: 1.8320848664529006
Validation loss: 2.360246114628997

Epoch: 5| Step: 6
Training loss: 2.049545409809536
Validation loss: 2.3685655698322283

Epoch: 5| Step: 7
Training loss: 1.8283176809641821
Validation loss: 2.3894673991850395

Epoch: 5| Step: 8
Training loss: 2.174042971294251
Validation loss: 2.3699934855331306

Epoch: 5| Step: 9
Training loss: 2.231537410913963
Validation loss: 2.3905899696215163

Epoch: 5| Step: 10
Training loss: 2.6702511855709323
Validation loss: 2.3976521490375506

Epoch: 215| Step: 0
Training loss: 2.0310009143400927
Validation loss: 2.3695189501081853

Epoch: 5| Step: 1
Training loss: 2.111822220458037
Validation loss: 2.4015290542384986

Epoch: 5| Step: 2
Training loss: 2.473477147471988
Validation loss: 2.3938229665637185

Epoch: 5| Step: 3
Training loss: 1.6415823913217267
Validation loss: 2.376263599137506

Epoch: 5| Step: 4
Training loss: 1.6841718561821433
Validation loss: 2.3836081706986265

Epoch: 5| Step: 5
Training loss: 2.8394037926482167
Validation loss: 2.354940411600404

Epoch: 5| Step: 6
Training loss: 2.4805316106085056
Validation loss: 2.3788407255075366

Epoch: 5| Step: 7
Training loss: 2.653510083041559
Validation loss: 2.363949862730736

Epoch: 5| Step: 8
Training loss: 1.9019629001268301
Validation loss: 2.3816925305548833

Epoch: 5| Step: 9
Training loss: 2.0525771061751694
Validation loss: 2.3817766234635656

Epoch: 5| Step: 10
Training loss: 2.4636010666205888
Validation loss: 2.377195305443025

Epoch: 216| Step: 0
Training loss: 2.7426623506575423
Validation loss: 2.379520864039389

Epoch: 5| Step: 1
Training loss: 2.2815336286251324
Validation loss: 2.393830448138481

Epoch: 5| Step: 2
Training loss: 2.4568407624701707
Validation loss: 2.3823572351608213

Epoch: 5| Step: 3
Training loss: 1.7450309779087259
Validation loss: 2.3688722891738907

Epoch: 5| Step: 4
Training loss: 2.092524041478678
Validation loss: 2.3762659629046574

Epoch: 5| Step: 5
Training loss: 1.8242350869601038
Validation loss: 2.3727134779292522

Epoch: 5| Step: 6
Training loss: 2.4280707079538453
Validation loss: 2.396105683314716

Epoch: 5| Step: 7
Training loss: 2.2513064724004415
Validation loss: 2.354956710397002

Epoch: 5| Step: 8
Training loss: 2.526669348897324
Validation loss: 2.384955433648651

Epoch: 5| Step: 9
Training loss: 2.324520521047512
Validation loss: 2.3557681067916367

Epoch: 5| Step: 10
Training loss: 2.0076012407477255
Validation loss: 2.413654766992624

Epoch: 217| Step: 0
Training loss: 2.875909246877734
Validation loss: 2.365231193797154

Epoch: 5| Step: 1
Training loss: 2.007295772097602
Validation loss: 2.3866522745355145

Epoch: 5| Step: 2
Training loss: 2.0779317895086415
Validation loss: 2.3979760705778066

Epoch: 5| Step: 3
Training loss: 2.0615259818346447
Validation loss: 2.3879903105502804

Epoch: 5| Step: 4
Training loss: 2.0999403581778346
Validation loss: 2.377760196947345

Epoch: 5| Step: 5
Training loss: 1.809867591546087
Validation loss: 2.3644515671164514

Epoch: 5| Step: 6
Training loss: 2.019480957349479
Validation loss: 2.3876768095570076

Epoch: 5| Step: 7
Training loss: 2.065774110614814
Validation loss: 2.385775900737511

Epoch: 5| Step: 8
Training loss: 2.2390926681157954
Validation loss: 2.385926236592931

Epoch: 5| Step: 9
Training loss: 2.290408419040845
Validation loss: 2.3945191219500264

Epoch: 5| Step: 10
Training loss: 2.8718430144777565
Validation loss: 2.40642731376434

Epoch: 218| Step: 0
Training loss: 2.1617611102333405
Validation loss: 2.3857946166762596

Epoch: 5| Step: 1
Training loss: 2.20860042996066
Validation loss: 2.3896791347108675

Epoch: 5| Step: 2
Training loss: 3.1605150469406844
Validation loss: 2.3671249759896313

Epoch: 5| Step: 3
Training loss: 2.5452178993700003
Validation loss: 2.388604101559234

Epoch: 5| Step: 4
Training loss: 1.580524923671732
Validation loss: 2.372174386402265

Epoch: 5| Step: 5
Training loss: 2.133008563633006
Validation loss: 2.373670254319579

Epoch: 5| Step: 6
Training loss: 1.8016626679231706
Validation loss: 2.343780380653721

Epoch: 5| Step: 7
Training loss: 2.355360038108538
Validation loss: 2.367435814982271

Epoch: 5| Step: 8
Training loss: 1.5658385658413587
Validation loss: 2.3648762276019726

Epoch: 5| Step: 9
Training loss: 2.2567162409774206
Validation loss: 2.3964607997199727

Epoch: 5| Step: 10
Training loss: 2.420680188200697
Validation loss: 2.3645137866805643

Epoch: 219| Step: 0
Training loss: 2.6344111538506967
Validation loss: 2.363864424207017

Epoch: 5| Step: 1
Training loss: 2.156423368256814
Validation loss: 2.376146579474877

Epoch: 5| Step: 2
Training loss: 2.9336794092749483
Validation loss: 2.3805531226711154

Epoch: 5| Step: 3
Training loss: 2.3668368743976727
Validation loss: 2.376760311855374

Epoch: 5| Step: 4
Training loss: 2.1130756835237388
Validation loss: 2.402744849657871

Epoch: 5| Step: 5
Training loss: 2.280170446516496
Validation loss: 2.390275301615243

Epoch: 5| Step: 6
Training loss: 1.5196671216768383
Validation loss: 2.3815722264429087

Epoch: 5| Step: 7
Training loss: 1.5702109232830512
Validation loss: 2.384568264829369

Epoch: 5| Step: 8
Training loss: 1.8897606000707692
Validation loss: 2.3985299969091236

Epoch: 5| Step: 9
Training loss: 2.284530162629691
Validation loss: 2.3720317765794894

Epoch: 5| Step: 10
Training loss: 2.1012447074356007
Validation loss: 2.3991606611074734

Epoch: 220| Step: 0
Training loss: 2.0647979419489597
Validation loss: 2.376902836430367

Epoch: 5| Step: 1
Training loss: 2.6270123896951025
Validation loss: 2.3760179066482348

Epoch: 5| Step: 2
Training loss: 2.9157824311270115
Validation loss: 2.398780643486901

Epoch: 5| Step: 3
Training loss: 2.0334678865949636
Validation loss: 2.380200713440685

Epoch: 5| Step: 4
Training loss: 2.403597670403563
Validation loss: 2.4009004352540324

Epoch: 5| Step: 5
Training loss: 2.65821299106132
Validation loss: 2.371723317507766

Epoch: 5| Step: 6
Training loss: 2.0545074035852777
Validation loss: 2.372233769779345

Epoch: 5| Step: 7
Training loss: 1.9709494278998807
Validation loss: 2.3985425445030906

Epoch: 5| Step: 8
Training loss: 1.5123724891571761
Validation loss: 2.371063970698525

Epoch: 5| Step: 9
Training loss: 1.7929776592490387
Validation loss: 2.381744410049832

Epoch: 5| Step: 10
Training loss: 1.7508021287468947
Validation loss: 2.392094998161898

Epoch: 221| Step: 0
Training loss: 2.084721814632129
Validation loss: 2.3795077819553203

Epoch: 5| Step: 1
Training loss: 1.3101823871259661
Validation loss: 2.396893254431566

Epoch: 5| Step: 2
Training loss: 2.6220855882934915
Validation loss: 2.409701844616122

Epoch: 5| Step: 3
Training loss: 1.950999453757174
Validation loss: 2.4135537372541687

Epoch: 5| Step: 4
Training loss: 2.0770096618177836
Validation loss: 2.3911479925058865

Epoch: 5| Step: 5
Training loss: 1.890890686030616
Validation loss: 2.37010880793159

Epoch: 5| Step: 6
Training loss: 2.3099422227974347
Validation loss: 2.343780356589993

Epoch: 5| Step: 7
Training loss: 2.283402459520611
Validation loss: 2.3519549625732896

Epoch: 5| Step: 8
Training loss: 2.703707505455228
Validation loss: 2.382234495930908

Epoch: 5| Step: 9
Training loss: 2.115594468678272
Validation loss: 2.383786577138904

Epoch: 5| Step: 10
Training loss: 2.600658729442671
Validation loss: 2.3734737807457256

Epoch: 222| Step: 0
Training loss: 2.0523898546074064
Validation loss: 2.3912774689628695

Epoch: 5| Step: 1
Training loss: 2.0838521184309737
Validation loss: 2.369989440483051

Epoch: 5| Step: 2
Training loss: 2.2501438942567296
Validation loss: 2.3786655796435756

Epoch: 5| Step: 3
Training loss: 2.7319806760492726
Validation loss: 2.386187404755129

Epoch: 5| Step: 4
Training loss: 1.9580044639349483
Validation loss: 2.38738678754665

Epoch: 5| Step: 5
Training loss: 2.722498447218103
Validation loss: 2.361717113709113

Epoch: 5| Step: 6
Training loss: 1.9915245598675257
Validation loss: 2.3585624988155893

Epoch: 5| Step: 7
Training loss: 1.906396703859554
Validation loss: 2.368525552480175

Epoch: 5| Step: 8
Training loss: 1.410326199844329
Validation loss: 2.369775825095053

Epoch: 5| Step: 9
Training loss: 2.1710249520321483
Validation loss: 2.367825100364096

Epoch: 5| Step: 10
Training loss: 2.5185028106328424
Validation loss: 2.3854967888305367

Epoch: 223| Step: 0
Training loss: 1.664850182881093
Validation loss: 2.4257678768246476

Epoch: 5| Step: 1
Training loss: 2.2461725105076966
Validation loss: 2.378372694814942

Epoch: 5| Step: 2
Training loss: 2.0347645798210143
Validation loss: 2.408611368959705

Epoch: 5| Step: 3
Training loss: 2.564026168761114
Validation loss: 2.3515878270659463

Epoch: 5| Step: 4
Training loss: 2.2291088869206312
Validation loss: 2.365539284544142

Epoch: 5| Step: 5
Training loss: 2.2904980425240264
Validation loss: 2.3712427890135226

Epoch: 5| Step: 6
Training loss: 2.3056203215156836
Validation loss: 2.3897048119693993

Epoch: 5| Step: 7
Training loss: 1.9795359685240737
Validation loss: 2.385145098212068

Epoch: 5| Step: 8
Training loss: 2.3324164451033766
Validation loss: 2.37678559854046

Epoch: 5| Step: 9
Training loss: 2.215648040866896
Validation loss: 2.37199071313069

Epoch: 5| Step: 10
Training loss: 2.0009157945110116
Validation loss: 2.382532530901907

Epoch: 224| Step: 0
Training loss: 2.300837932205808
Validation loss: 2.3692746562708393

Epoch: 5| Step: 1
Training loss: 2.1940053937875246
Validation loss: 2.384824981868544

Epoch: 5| Step: 2
Training loss: 2.1473547964333086
Validation loss: 2.3915640600355106

Epoch: 5| Step: 3
Training loss: 2.082922195556449
Validation loss: 2.382775724232452

Epoch: 5| Step: 4
Training loss: 2.6035018886195207
Validation loss: 2.391367502686521

Epoch: 5| Step: 5
Training loss: 2.722088485036339
Validation loss: 2.393114385655691

Epoch: 5| Step: 6
Training loss: 1.5530349920276756
Validation loss: 2.386427867095845

Epoch: 5| Step: 7
Training loss: 2.303658569309931
Validation loss: 2.357237618849091

Epoch: 5| Step: 8
Training loss: 1.696209648175232
Validation loss: 2.3962920774722174

Epoch: 5| Step: 9
Training loss: 1.7524609292282893
Validation loss: 2.3707219060151403

Epoch: 5| Step: 10
Training loss: 2.181481392290773
Validation loss: 2.3774310063780524

Epoch: 225| Step: 0
Training loss: 2.298236676849219
Validation loss: 2.398879388584392

Epoch: 5| Step: 1
Training loss: 2.2691685818502876
Validation loss: 2.4025013168075424

Epoch: 5| Step: 2
Training loss: 1.9679124655252338
Validation loss: 2.373479536707511

Epoch: 5| Step: 3
Training loss: 2.271668050331297
Validation loss: 2.416192983923915

Epoch: 5| Step: 4
Training loss: 1.8339519396301445
Validation loss: 2.3688041218697022

Epoch: 5| Step: 5
Training loss: 2.457403837012562
Validation loss: 2.38806126830787

Epoch: 5| Step: 6
Training loss: 1.8959840847345344
Validation loss: 2.395499270254414

Epoch: 5| Step: 7
Training loss: 2.18630011211563
Validation loss: 2.403852000081894

Epoch: 5| Step: 8
Training loss: 1.7711345491223898
Validation loss: 2.4063148814737696

Epoch: 5| Step: 9
Training loss: 2.540037654537528
Validation loss: 2.365099468732782

Epoch: 5| Step: 10
Training loss: 2.2568942515994923
Validation loss: 2.3825069937021053

Epoch: 226| Step: 0
Training loss: 1.8788984461124643
Validation loss: 2.372650020123238

Epoch: 5| Step: 1
Training loss: 2.4184102531975413
Validation loss: 2.410575496903747

Epoch: 5| Step: 2
Training loss: 2.374208117527453
Validation loss: 2.3900756185913603

Epoch: 5| Step: 3
Training loss: 1.8291496600473451
Validation loss: 2.3729458605982194

Epoch: 5| Step: 4
Training loss: 2.2796654619768826
Validation loss: 2.3669422604325714

Epoch: 5| Step: 5
Training loss: 2.480055695031417
Validation loss: 2.374301544316818

Epoch: 5| Step: 6
Training loss: 1.97967922868333
Validation loss: 2.3702921316717074

Epoch: 5| Step: 7
Training loss: 2.0795810732418074
Validation loss: 2.3778246687576696

Epoch: 5| Step: 8
Training loss: 1.7508786584191287
Validation loss: 2.367939534497336

Epoch: 5| Step: 9
Training loss: 1.9718674092819244
Validation loss: 2.3784431623609725

Epoch: 5| Step: 10
Training loss: 2.4120484873388093
Validation loss: 2.3505764707346413

Epoch: 227| Step: 0
Training loss: 1.977362127983571
Validation loss: 2.3730427741167164

Epoch: 5| Step: 1
Training loss: 2.3463053696469856
Validation loss: 2.378383156859573

Epoch: 5| Step: 2
Training loss: 2.221139722328872
Validation loss: 2.351302559114095

Epoch: 5| Step: 3
Training loss: 2.1710871083808994
Validation loss: 2.362468856265079

Epoch: 5| Step: 4
Training loss: 1.904010708165711
Validation loss: 2.381844635304002

Epoch: 5| Step: 5
Training loss: 2.0460302342318575
Validation loss: 2.3496369101888246

Epoch: 5| Step: 6
Training loss: 2.0940728009893794
Validation loss: 2.3776555933818524

Epoch: 5| Step: 7
Training loss: 3.0135437103134453
Validation loss: 2.3414408858882103

Epoch: 5| Step: 8
Training loss: 1.8609870526100658
Validation loss: 2.398328347818951

Epoch: 5| Step: 9
Training loss: 1.8557801959009173
Validation loss: 2.363846091535777

Epoch: 5| Step: 10
Training loss: 2.123920054057264
Validation loss: 2.3737310690814706

Epoch: 228| Step: 0
Training loss: 1.7225396426086328
Validation loss: 2.3470941161017

Epoch: 5| Step: 1
Training loss: 2.084602871953923
Validation loss: 2.386496103025932

Epoch: 5| Step: 2
Training loss: 1.8235787488137165
Validation loss: 2.3653253924410427

Epoch: 5| Step: 3
Training loss: 2.39763247620153
Validation loss: 2.356416560588088

Epoch: 5| Step: 4
Training loss: 2.188548681389232
Validation loss: 2.3868092220583987

Epoch: 5| Step: 5
Training loss: 2.212617700754281
Validation loss: 2.3805481818045036

Epoch: 5| Step: 6
Training loss: 2.683068991804481
Validation loss: 2.3724757922693547

Epoch: 5| Step: 7
Training loss: 1.9598493862671709
Validation loss: 2.3790030419412123

Epoch: 5| Step: 8
Training loss: 2.0751440710585407
Validation loss: 2.3959935745075582

Epoch: 5| Step: 9
Training loss: 2.0912647585624526
Validation loss: 2.380803235798592

Epoch: 5| Step: 10
Training loss: 2.1929101798210286
Validation loss: 2.3891494404114013

Epoch: 229| Step: 0
Training loss: 1.7592821547299262
Validation loss: 2.3706128781467117

Epoch: 5| Step: 1
Training loss: 2.1091283583380602
Validation loss: 2.372209885410259

Epoch: 5| Step: 2
Training loss: 2.3590408998107644
Validation loss: 2.3796255752213065

Epoch: 5| Step: 3
Training loss: 2.3019205326379804
Validation loss: 2.3673085167187566

Epoch: 5| Step: 4
Training loss: 2.1036816658078066
Validation loss: 2.409158558901701

Epoch: 5| Step: 5
Training loss: 1.9214845586390057
Validation loss: 2.3720567937648687

Epoch: 5| Step: 6
Training loss: 2.438807992406972
Validation loss: 2.3853251404772062

Epoch: 5| Step: 7
Training loss: 2.1282608593834302
Validation loss: 2.3867420799388377

Epoch: 5| Step: 8
Training loss: 2.302768024331382
Validation loss: 2.3630161316698177

Epoch: 5| Step: 9
Training loss: 1.9823693179224655
Validation loss: 2.386145986479398

Epoch: 5| Step: 10
Training loss: 2.211624092817242
Validation loss: 2.3879136467063593

Epoch: 230| Step: 0
Training loss: 3.038927874488431
Validation loss: 2.373887427007666

Epoch: 5| Step: 1
Training loss: 1.860464466103174
Validation loss: 2.3458195759613134

Epoch: 5| Step: 2
Training loss: 1.9973387297649507
Validation loss: 2.355892480612746

Epoch: 5| Step: 3
Training loss: 2.2158768009065066
Validation loss: 2.3466985104144498

Epoch: 5| Step: 4
Training loss: 1.5898930872354629
Validation loss: 2.364740900323956

Epoch: 5| Step: 5
Training loss: 1.9597472571884098
Validation loss: 2.3636436548611073

Epoch: 5| Step: 6
Training loss: 1.8766486231522013
Validation loss: 2.3918182871515605

Epoch: 5| Step: 7
Training loss: 2.1909521927869355
Validation loss: 2.3838901804075237

Epoch: 5| Step: 8
Training loss: 2.507890266329781
Validation loss: 2.3586564121845415

Epoch: 5| Step: 9
Training loss: 1.8055585600347057
Validation loss: 2.3720388762019726

Epoch: 5| Step: 10
Training loss: 2.092612569645462
Validation loss: 2.37234095415206

Epoch: 231| Step: 0
Training loss: 2.1242479227636597
Validation loss: 2.380095379676052

Epoch: 5| Step: 1
Training loss: 2.5557763815115906
Validation loss: 2.3761167723305356

Epoch: 5| Step: 2
Training loss: 2.3580337653165193
Validation loss: 2.3803976603020187

Epoch: 5| Step: 3
Training loss: 1.8535584584503457
Validation loss: 2.350316916002449

Epoch: 5| Step: 4
Training loss: 2.296297169358191
Validation loss: 2.4062378969222395

Epoch: 5| Step: 5
Training loss: 1.9349545401031067
Validation loss: 2.361194537299684

Epoch: 5| Step: 6
Training loss: 1.6830981735545048
Validation loss: 2.3831359848122524

Epoch: 5| Step: 7
Training loss: 1.7383381009181262
Validation loss: 2.3809898653170753

Epoch: 5| Step: 8
Training loss: 2.3296960228009973
Validation loss: 2.3618404027796553

Epoch: 5| Step: 9
Training loss: 2.194028865989443
Validation loss: 2.3675523897243838

Epoch: 5| Step: 10
Training loss: 2.207366323776212
Validation loss: 2.381696609009985

Epoch: 232| Step: 0
Training loss: 2.358719387290429
Validation loss: 2.35521323937944

Epoch: 5| Step: 1
Training loss: 1.9939671963142767
Validation loss: 2.373638327268904

Epoch: 5| Step: 2
Training loss: 2.330829662237821
Validation loss: 2.369341784837586

Epoch: 5| Step: 3
Training loss: 2.5992679042083946
Validation loss: 2.4000127430119496

Epoch: 5| Step: 4
Training loss: 1.7929162244229573
Validation loss: 2.3495932284155066

Epoch: 5| Step: 5
Training loss: 1.607606749720284
Validation loss: 2.36081109051961

Epoch: 5| Step: 6
Training loss: 1.8262387186964402
Validation loss: 2.3548640141143875

Epoch: 5| Step: 7
Training loss: 2.4280503820002868
Validation loss: 2.3933926617018106

Epoch: 5| Step: 8
Training loss: 2.3565331326880474
Validation loss: 2.354593371343411

Epoch: 5| Step: 9
Training loss: 1.8489028564153762
Validation loss: 2.348910531215018

Epoch: 5| Step: 10
Training loss: 1.8487618427013368
Validation loss: 2.391932950655239

Epoch: 233| Step: 0
Training loss: 1.419412009774192
Validation loss: 2.3856451800357545

Epoch: 5| Step: 1
Training loss: 2.163515648450477
Validation loss: 2.3212111703488523

Epoch: 5| Step: 2
Training loss: 2.8088305801899924
Validation loss: 2.3522701995284576

Epoch: 5| Step: 3
Training loss: 2.1672378545190427
Validation loss: 2.374892722979294

Epoch: 5| Step: 4
Training loss: 1.9521156449495285
Validation loss: 2.363651015039208

Epoch: 5| Step: 5
Training loss: 2.359028872938641
Validation loss: 2.33797281631557

Epoch: 5| Step: 6
Training loss: 2.2796118092930024
Validation loss: 2.3693575809819487

Epoch: 5| Step: 7
Training loss: 2.2152661117623884
Validation loss: 2.370087519779008

Epoch: 5| Step: 8
Training loss: 1.5821567815262005
Validation loss: 2.3690719303043006

Epoch: 5| Step: 9
Training loss: 2.0593461863885505
Validation loss: 2.383012550922473

Epoch: 5| Step: 10
Training loss: 2.078450801234972
Validation loss: 2.3571997779341465

Epoch: 234| Step: 0
Training loss: 1.7654193994775393
Validation loss: 2.3818114734778013

Epoch: 5| Step: 1
Training loss: 2.096343640287204
Validation loss: 2.3791196991285197

Epoch: 5| Step: 2
Training loss: 3.1085447803675423
Validation loss: 2.3751383267821353

Epoch: 5| Step: 3
Training loss: 2.057426570541502
Validation loss: 2.3811189552934753

Epoch: 5| Step: 4
Training loss: 2.0135606944103928
Validation loss: 2.3897151460896304

Epoch: 5| Step: 5
Training loss: 2.205558677188555
Validation loss: 2.38741194396163

Epoch: 5| Step: 6
Training loss: 1.7860797521719949
Validation loss: 2.3493485349134677

Epoch: 5| Step: 7
Training loss: 1.9941746991839704
Validation loss: 2.390240001193053

Epoch: 5| Step: 8
Training loss: 1.8862821022370886
Validation loss: 2.33981135590372

Epoch: 5| Step: 9
Training loss: 2.210202152103201
Validation loss: 2.327623504210373

Epoch: 5| Step: 10
Training loss: 1.9123853536911888
Validation loss: 2.3990579940626056

Epoch: 235| Step: 0
Training loss: 1.9971786506945033
Validation loss: 2.4016888317775513

Epoch: 5| Step: 1
Training loss: 2.3114287498429595
Validation loss: 2.3526475745699917

Epoch: 5| Step: 2
Training loss: 2.037018200597788
Validation loss: 2.394723081393226

Epoch: 5| Step: 3
Training loss: 2.767545475090799
Validation loss: 2.389317905237138

Epoch: 5| Step: 4
Training loss: 1.986177721959137
Validation loss: 2.378006676447998

Epoch: 5| Step: 5
Training loss: 1.6010810686705406
Validation loss: 2.3697674280924095

Epoch: 5| Step: 6
Training loss: 2.0978305964411774
Validation loss: 2.3666937111443547

Epoch: 5| Step: 7
Training loss: 1.8640815727492404
Validation loss: 2.3757956671873273

Epoch: 5| Step: 8
Training loss: 2.631224744951914
Validation loss: 2.3559890439362543

Epoch: 5| Step: 9
Training loss: 1.8540532223861401
Validation loss: 2.35819249358915

Epoch: 5| Step: 10
Training loss: 1.7257213355906547
Validation loss: 2.3571600429057744

Epoch: 236| Step: 0
Training loss: 1.749090844095597
Validation loss: 2.3917598241301277

Epoch: 5| Step: 1
Training loss: 1.6851328035084372
Validation loss: 2.3605756740859767

Epoch: 5| Step: 2
Training loss: 2.2128534541160447
Validation loss: 2.3922592422710975

Epoch: 5| Step: 3
Training loss: 2.232663866545747
Validation loss: 2.346520233987866

Epoch: 5| Step: 4
Training loss: 2.377910236380919
Validation loss: 2.360312791806192

Epoch: 5| Step: 5
Training loss: 2.073710061321619
Validation loss: 2.350240919077563

Epoch: 5| Step: 6
Training loss: 1.9121890494684313
Validation loss: 2.383240288672895

Epoch: 5| Step: 7
Training loss: 1.855670540528011
Validation loss: 2.3698866806987176

Epoch: 5| Step: 8
Training loss: 2.3114884715946964
Validation loss: 2.324138390894382

Epoch: 5| Step: 9
Training loss: 2.493410964138079
Validation loss: 2.373435039703017

Epoch: 5| Step: 10
Training loss: 1.9816987019936705
Validation loss: 2.3621926718878807

Epoch: 237| Step: 0
Training loss: 1.8335416054188354
Validation loss: 2.379073582410772

Epoch: 5| Step: 1
Training loss: 1.9405252771969834
Validation loss: 2.3641096425504156

Epoch: 5| Step: 2
Training loss: 2.3110264387677595
Validation loss: 2.3678313670146016

Epoch: 5| Step: 3
Training loss: 2.35458382705452
Validation loss: 2.3832576145669346

Epoch: 5| Step: 4
Training loss: 2.311853885600623
Validation loss: 2.3445889629216965

Epoch: 5| Step: 5
Training loss: 2.530781832126928
Validation loss: 2.3828490842326944

Epoch: 5| Step: 6
Training loss: 1.6796882806820497
Validation loss: 2.3615950389087517

Epoch: 5| Step: 7
Training loss: 2.0976377234182446
Validation loss: 2.353119107353292

Epoch: 5| Step: 8
Training loss: 2.017519275143048
Validation loss: 2.3742815181986088

Epoch: 5| Step: 9
Training loss: 2.1042804372516164
Validation loss: 2.3450786289374017

Epoch: 5| Step: 10
Training loss: 1.6597242084883221
Validation loss: 2.4152930758116278

Epoch: 238| Step: 0
Training loss: 2.545142210339063
Validation loss: 2.396653806810582

Epoch: 5| Step: 1
Training loss: 1.9969596403090357
Validation loss: 2.3462656358671024

Epoch: 5| Step: 2
Training loss: 2.1034070396909823
Validation loss: 2.3678164203544774

Epoch: 5| Step: 3
Training loss: 1.8054812448647788
Validation loss: 2.3608982650960515

Epoch: 5| Step: 4
Training loss: 2.754785189137886
Validation loss: 2.365753378914605

Epoch: 5| Step: 5
Training loss: 1.7084984660779472
Validation loss: 2.3541715946594226

Epoch: 5| Step: 6
Training loss: 2.054390657398336
Validation loss: 2.3990634588922637

Epoch: 5| Step: 7
Training loss: 1.834551283832001
Validation loss: 2.4052988209181363

Epoch: 5| Step: 8
Training loss: 2.405755128381094
Validation loss: 2.393360171890676

Epoch: 5| Step: 9
Training loss: 1.6426064288119553
Validation loss: 2.375538865783394

Epoch: 5| Step: 10
Training loss: 1.7019716609832372
Validation loss: 2.3527455742809193

Epoch: 239| Step: 0
Training loss: 2.043952544555409
Validation loss: 2.3848362175395073

Epoch: 5| Step: 1
Training loss: 1.7416073641499126
Validation loss: 2.375512109454065

Epoch: 5| Step: 2
Training loss: 2.4049467049956905
Validation loss: 2.376416862076883

Epoch: 5| Step: 3
Training loss: 1.66705125504058
Validation loss: 2.3705491072638436

Epoch: 5| Step: 4
Training loss: 1.6821586705911675
Validation loss: 2.3960755287760778

Epoch: 5| Step: 5
Training loss: 2.1111467620560966
Validation loss: 2.3754358436821743

Epoch: 5| Step: 6
Training loss: 2.146181121591849
Validation loss: 2.345054016496931

Epoch: 5| Step: 7
Training loss: 2.4955217305977806
Validation loss: 2.38087532085024

Epoch: 5| Step: 8
Training loss: 2.190531564589158
Validation loss: 2.3168549608611637

Epoch: 5| Step: 9
Training loss: 1.7308013802990347
Validation loss: 2.3546672103426523

Epoch: 5| Step: 10
Training loss: 2.509898426386775
Validation loss: 2.3596091640148127

Epoch: 240| Step: 0
Training loss: 1.5756164858027006
Validation loss: 2.373945288061268

Epoch: 5| Step: 1
Training loss: 2.3817254260186767
Validation loss: 2.343687253269337

Epoch: 5| Step: 2
Training loss: 2.443797169105744
Validation loss: 2.3897564531590922

Epoch: 5| Step: 3
Training loss: 1.8012776052780552
Validation loss: 2.349010230032411

Epoch: 5| Step: 4
Training loss: 1.5575091955363531
Validation loss: 2.3816961418555453

Epoch: 5| Step: 5
Training loss: 1.300536490659171
Validation loss: 2.3652471658851892

Epoch: 5| Step: 6
Training loss: 2.220982784755858
Validation loss: 2.3468451508240697

Epoch: 5| Step: 7
Training loss: 2.337362001802871
Validation loss: 2.377857959497078

Epoch: 5| Step: 8
Training loss: 2.150744943419723
Validation loss: 2.3801948940292346

Epoch: 5| Step: 9
Training loss: 2.422801474284504
Validation loss: 2.39201335898869

Epoch: 5| Step: 10
Training loss: 2.4592074655862537
Validation loss: 2.3192489726197416

Epoch: 241| Step: 0
Training loss: 2.1566555360549096
Validation loss: 2.347074655197149

Epoch: 5| Step: 1
Training loss: 2.187960984839355
Validation loss: 2.384171366969557

Epoch: 5| Step: 2
Training loss: 2.0909264727763346
Validation loss: 2.3974485120289883

Epoch: 5| Step: 3
Training loss: 1.8755678588542495
Validation loss: 2.3744206177883385

Epoch: 5| Step: 4
Training loss: 1.8366988531062878
Validation loss: 2.33337056076073

Epoch: 5| Step: 5
Training loss: 2.1387848009926747
Validation loss: 2.3325453316124247

Epoch: 5| Step: 6
Training loss: 2.0020648311060407
Validation loss: 2.3916728193676935

Epoch: 5| Step: 7
Training loss: 2.13529918316463
Validation loss: 2.3522644445259338

Epoch: 5| Step: 8
Training loss: 2.214716724339116
Validation loss: 2.389970872632631

Epoch: 5| Step: 9
Training loss: 2.12637609916355
Validation loss: 2.3576483419556054

Epoch: 5| Step: 10
Training loss: 1.8372403980003693
Validation loss: 2.378375031694347

Epoch: 242| Step: 0
Training loss: 1.928082806637173
Validation loss: 2.381409878432083

Epoch: 5| Step: 1
Training loss: 1.9952488733003335
Validation loss: 2.3619719568502444

Epoch: 5| Step: 2
Training loss: 1.7856923973921848
Validation loss: 2.3742794871799364

Epoch: 5| Step: 3
Training loss: 1.9748726960692762
Validation loss: 2.3533487689618164

Epoch: 5| Step: 4
Training loss: 1.801718776042231
Validation loss: 2.3430656095633995

Epoch: 5| Step: 5
Training loss: 2.8266030953414294
Validation loss: 2.348141554529219

Epoch: 5| Step: 6
Training loss: 1.2399169034956163
Validation loss: 2.3856978117544387

Epoch: 5| Step: 7
Training loss: 2.0637547693133915
Validation loss: 2.4055959193175664

Epoch: 5| Step: 8
Training loss: 2.404419438006253
Validation loss: 2.368495878893496

Epoch: 5| Step: 9
Training loss: 2.057301993686172
Validation loss: 2.325086713345527

Epoch: 5| Step: 10
Training loss: 2.1358597334550957
Validation loss: 2.3509011524725496

Epoch: 243| Step: 0
Training loss: 2.133469923931622
Validation loss: 2.345409118359096

Epoch: 5| Step: 1
Training loss: 2.1423813791276314
Validation loss: 2.3616941154095366

Epoch: 5| Step: 2
Training loss: 1.7170855005045877
Validation loss: 2.3623711199205677

Epoch: 5| Step: 3
Training loss: 1.6237079912702643
Validation loss: 2.33489672265787

Epoch: 5| Step: 4
Training loss: 2.0710907247169414
Validation loss: 2.3602840750584275

Epoch: 5| Step: 5
Training loss: 2.9540755745241185
Validation loss: 2.3727988636063135

Epoch: 5| Step: 6
Training loss: 2.0876343643894835
Validation loss: 2.3294169564579197

Epoch: 5| Step: 7
Training loss: 1.5223940674959378
Validation loss: 2.375239746048131

Epoch: 5| Step: 8
Training loss: 2.020402790362044
Validation loss: 2.363195826356884

Epoch: 5| Step: 9
Training loss: 1.7211564297199735
Validation loss: 2.361446202495753

Epoch: 5| Step: 10
Training loss: 2.311687429821203
Validation loss: 2.368922801788381

Epoch: 244| Step: 0
Training loss: 2.1592176719578364
Validation loss: 2.354321685864834

Epoch: 5| Step: 1
Training loss: 2.2776148848968756
Validation loss: 2.376541024181874

Epoch: 5| Step: 2
Training loss: 1.7618927795660586
Validation loss: 2.3990885997266913

Epoch: 5| Step: 3
Training loss: 2.2564784137784577
Validation loss: 2.3522711101046903

Epoch: 5| Step: 4
Training loss: 2.157241040686759
Validation loss: 2.371377049035322

Epoch: 5| Step: 5
Training loss: 1.9195434569924357
Validation loss: 2.3576645328680965

Epoch: 5| Step: 6
Training loss: 2.0130538510028373
Validation loss: 2.38046299331923

Epoch: 5| Step: 7
Training loss: 2.421009819789228
Validation loss: 2.400993238483934

Epoch: 5| Step: 8
Training loss: 2.1566853843871163
Validation loss: 2.396397141668129

Epoch: 5| Step: 9
Training loss: 2.0001697468248243
Validation loss: 2.3497822151164813

Epoch: 5| Step: 10
Training loss: 1.4407100495163292
Validation loss: 2.380710395823

Epoch: 245| Step: 0
Training loss: 1.8729350481273461
Validation loss: 2.401444424273511

Epoch: 5| Step: 1
Training loss: 1.9360497492159672
Validation loss: 2.3082930265237667

Epoch: 5| Step: 2
Training loss: 2.3845912610293896
Validation loss: 2.3636749414250504

Epoch: 5| Step: 3
Training loss: 2.24276864100223
Validation loss: 2.3643149962303402

Epoch: 5| Step: 4
Training loss: 2.4507786895184065
Validation loss: 2.371866417129091

Epoch: 5| Step: 5
Training loss: 1.581363565339831
Validation loss: 2.3228978782087846

Epoch: 5| Step: 6
Training loss: 1.7051067896090695
Validation loss: 2.326976034799402

Epoch: 5| Step: 7
Training loss: 2.2745708773494893
Validation loss: 2.391412474324429

Epoch: 5| Step: 8
Training loss: 2.0399816787121403
Validation loss: 2.371197027785315

Epoch: 5| Step: 9
Training loss: 1.6838360322242627
Validation loss: 2.357369528742691

Epoch: 5| Step: 10
Training loss: 2.132625473821078
Validation loss: 2.3552835247066173

Epoch: 246| Step: 0
Training loss: 2.175440653744401
Validation loss: 2.347797816980236

Epoch: 5| Step: 1
Training loss: 2.2385309156677713
Validation loss: 2.3648226115791844

Epoch: 5| Step: 2
Training loss: 1.5472434789877978
Validation loss: 2.3622888290010726

Epoch: 5| Step: 3
Training loss: 1.8321724452936228
Validation loss: 2.356941779234798

Epoch: 5| Step: 4
Training loss: 2.228726697148458
Validation loss: 2.3805438483071244

Epoch: 5| Step: 5
Training loss: 2.1207868659644156
Validation loss: 2.338747556794774

Epoch: 5| Step: 6
Training loss: 1.73153756848479
Validation loss: 2.327282551849756

Epoch: 5| Step: 7
Training loss: 1.471495233935701
Validation loss: 2.40658926200223

Epoch: 5| Step: 8
Training loss: 2.3068657360650526
Validation loss: 2.379679971116551

Epoch: 5| Step: 9
Training loss: 1.5888967481980465
Validation loss: 2.365899509023583

Epoch: 5| Step: 10
Training loss: 3.0468712439880696
Validation loss: 2.390376993476157

Epoch: 247| Step: 0
Training loss: 1.9326896017809676
Validation loss: 2.362800627783252

Epoch: 5| Step: 1
Training loss: 2.079144450077269
Validation loss: 2.3510975758141957

Epoch: 5| Step: 2
Training loss: 1.540063058379559
Validation loss: 2.3577609659883296

Epoch: 5| Step: 3
Training loss: 1.895761432611723
Validation loss: 2.3482979711008647

Epoch: 5| Step: 4
Training loss: 1.4388622794929105
Validation loss: 2.345849523821941

Epoch: 5| Step: 5
Training loss: 2.427573507906919
Validation loss: 2.346252265104915

Epoch: 5| Step: 6
Training loss: 2.1648104370153174
Validation loss: 2.3591074556538163

Epoch: 5| Step: 7
Training loss: 2.1971907539327304
Validation loss: 2.3372157190449183

Epoch: 5| Step: 8
Training loss: 1.6572808710302511
Validation loss: 2.3546357572741927

Epoch: 5| Step: 9
Training loss: 2.4001658422073415
Validation loss: 2.361675408755803

Epoch: 5| Step: 10
Training loss: 2.248591512000745
Validation loss: 2.377428028045621

Epoch: 248| Step: 0
Training loss: 2.3635663325598975
Validation loss: 2.343078170251197

Epoch: 5| Step: 1
Training loss: 1.8861328226124832
Validation loss: 2.366100590112141

Epoch: 5| Step: 2
Training loss: 2.2650462496585013
Validation loss: 2.3644843468152015

Epoch: 5| Step: 3
Training loss: 1.8971080127867168
Validation loss: 2.3518839084904237

Epoch: 5| Step: 4
Training loss: 2.2730254229136264
Validation loss: 2.3572183254309698

Epoch: 5| Step: 5
Training loss: 2.380854067589193
Validation loss: 2.396138128141991

Epoch: 5| Step: 6
Training loss: 1.9865534081700302
Validation loss: 2.3573151987646455

Epoch: 5| Step: 7
Training loss: 1.3679342791681963
Validation loss: 2.3331116147622644

Epoch: 5| Step: 8
Training loss: 1.7208287932526163
Validation loss: 2.354975336521896

Epoch: 5| Step: 9
Training loss: 1.8915766062983326
Validation loss: 2.36140309960695

Epoch: 5| Step: 10
Training loss: 1.7637504822036225
Validation loss: 2.3256291017226296

Epoch: 249| Step: 0
Training loss: 1.7346017362834203
Validation loss: 2.358675335706426

Epoch: 5| Step: 1
Training loss: 2.731927092052697
Validation loss: 2.353519686381943

Epoch: 5| Step: 2
Training loss: 2.2490191971030367
Validation loss: 2.3611217732181733

Epoch: 5| Step: 3
Training loss: 1.4875359058053625
Validation loss: 2.3613002945809147

Epoch: 5| Step: 4
Training loss: 1.8658060366207103
Validation loss: 2.350638973584349

Epoch: 5| Step: 5
Training loss: 1.9424047838045315
Validation loss: 2.3386117288080372

Epoch: 5| Step: 6
Training loss: 1.782155258633558
Validation loss: 2.36704846922864

Epoch: 5| Step: 7
Training loss: 2.0555608365560976
Validation loss: 2.38912699456276

Epoch: 5| Step: 8
Training loss: 2.45200200709001
Validation loss: 2.363760850989413

Epoch: 5| Step: 9
Training loss: 1.775266334539123
Validation loss: 2.4048667776013812

Epoch: 5| Step: 10
Training loss: 1.5477252511553738
Validation loss: 2.3574483266273627

Epoch: 250| Step: 0
Training loss: 1.6906747271263405
Validation loss: 2.3541619539191005

Epoch: 5| Step: 1
Training loss: 2.386190152983938
Validation loss: 2.3611217927620745

Epoch: 5| Step: 2
Training loss: 2.530572306017729
Validation loss: 2.315580352405476

Epoch: 5| Step: 3
Training loss: 2.398068576732567
Validation loss: 2.3777606007236964

Epoch: 5| Step: 4
Training loss: 1.7148552896376397
Validation loss: 2.363387076614366

Epoch: 5| Step: 5
Training loss: 1.621622095988608
Validation loss: 2.358334548850163

Epoch: 5| Step: 6
Training loss: 2.349324527004478
Validation loss: 2.3576746844808945

Epoch: 5| Step: 7
Training loss: 1.6673219664098629
Validation loss: 2.376402780127407

Epoch: 5| Step: 8
Training loss: 1.8351390644566354
Validation loss: 2.355885107077547

Epoch: 5| Step: 9
Training loss: 1.6459648787968308
Validation loss: 2.3522504375941784

Epoch: 5| Step: 10
Training loss: 1.7965570583184787
Validation loss: 2.314648467470908

Epoch: 251| Step: 0
Training loss: 1.8618689088699365
Validation loss: 2.358622665104936

Epoch: 5| Step: 1
Training loss: 2.038780923745682
Validation loss: 2.3771773473455093

Epoch: 5| Step: 2
Training loss: 2.588895552230504
Validation loss: 2.372318563237065

Epoch: 5| Step: 3
Training loss: 2.3031571819484538
Validation loss: 2.347826873168416

Epoch: 5| Step: 4
Training loss: 1.4633320650400794
Validation loss: 2.34172176530839

Epoch: 5| Step: 5
Training loss: 2.215187651562396
Validation loss: 2.3629387405544913

Epoch: 5| Step: 6
Training loss: 2.165496130958118
Validation loss: 2.3548383189329

Epoch: 5| Step: 7
Training loss: 1.6892163766786599
Validation loss: 2.3758648915082388

Epoch: 5| Step: 8
Training loss: 1.8636231178777218
Validation loss: 2.3723601148584765

Epoch: 5| Step: 9
Training loss: 1.4918393033395136
Validation loss: 2.331873503727633

Epoch: 5| Step: 10
Training loss: 2.2560186420712047
Validation loss: 2.357332540384141

Epoch: 252| Step: 0
Training loss: 1.8985374644141684
Validation loss: 2.354944087875025

Epoch: 5| Step: 1
Training loss: 1.637788409394554
Validation loss: 2.345581960312225

Epoch: 5| Step: 2
Training loss: 2.085858861462445
Validation loss: 2.3743299932722395

Epoch: 5| Step: 3
Training loss: 1.7061235821181644
Validation loss: 2.318868130701187

Epoch: 5| Step: 4
Training loss: 1.5816860999845315
Validation loss: 2.333902650661123

Epoch: 5| Step: 5
Training loss: 1.7874184596530402
Validation loss: 2.3270134054273823

Epoch: 5| Step: 6
Training loss: 2.0144478369364736
Validation loss: 2.352354130724907

Epoch: 5| Step: 7
Training loss: 2.3059515121536727
Validation loss: 2.345086561185285

Epoch: 5| Step: 8
Training loss: 2.3553304805628565
Validation loss: 2.379135983136724

Epoch: 5| Step: 9
Training loss: 2.0174582963719714
Validation loss: 2.360862665498431

Epoch: 5| Step: 10
Training loss: 2.3519264522523233
Validation loss: 2.4001744543611334

Epoch: 253| Step: 0
Training loss: 1.527148534294464
Validation loss: 2.36455074835544

Epoch: 5| Step: 1
Training loss: 1.7030932922211475
Validation loss: 2.3412531108921053

Epoch: 5| Step: 2
Training loss: 2.0870100257241564
Validation loss: 2.3579307024899436

Epoch: 5| Step: 3
Training loss: 1.8530939906904695
Validation loss: 2.346019728732234

Epoch: 5| Step: 4
Training loss: 2.1597976248915223
Validation loss: 2.348650541322413

Epoch: 5| Step: 5
Training loss: 2.3811279345687604
Validation loss: 2.358665111230271

Epoch: 5| Step: 6
Training loss: 1.9140638701764867
Validation loss: 2.330866699688984

Epoch: 5| Step: 7
Training loss: 2.2299621327354053
Validation loss: 2.376002591766831

Epoch: 5| Step: 8
Training loss: 1.4584204057403203
Validation loss: 2.380579805650483

Epoch: 5| Step: 9
Training loss: 2.1289775871433774
Validation loss: 2.373006708509188

Epoch: 5| Step: 10
Training loss: 2.396814151076087
Validation loss: 2.354428952331134

Epoch: 254| Step: 0
Training loss: 1.6604654181330227
Validation loss: 2.3212101879484326

Epoch: 5| Step: 1
Training loss: 2.18618495105006
Validation loss: 2.3824241640472685

Epoch: 5| Step: 2
Training loss: 1.5260760028955862
Validation loss: 2.3675830626582464

Epoch: 5| Step: 3
Training loss: 2.0891612997494593
Validation loss: 2.3307197285086

Epoch: 5| Step: 4
Training loss: 1.7070156768856644
Validation loss: 2.385120340303243

Epoch: 5| Step: 5
Training loss: 2.761463461033797
Validation loss: 2.3563633727604527

Epoch: 5| Step: 6
Training loss: 1.792862035031448
Validation loss: 2.3503678126722907

Epoch: 5| Step: 7
Training loss: 1.8021227293908453
Validation loss: 2.3550597008988197

Epoch: 5| Step: 8
Training loss: 1.4384673636894012
Validation loss: 2.317685628468456

Epoch: 5| Step: 9
Training loss: 2.1692293368458118
Validation loss: 2.361983833607309

Epoch: 5| Step: 10
Training loss: 2.3977342997476345
Validation loss: 2.340557132552296

Epoch: 255| Step: 0
Training loss: 1.6744828607292026
Validation loss: 2.3195946292356093

Epoch: 5| Step: 1
Training loss: 1.7473660810944147
Validation loss: 2.3638930443199655

Epoch: 5| Step: 2
Training loss: 2.06796177256538
Validation loss: 2.369785700892733

Epoch: 5| Step: 3
Training loss: 1.9511775569432097
Validation loss: 2.3495464181323498

Epoch: 5| Step: 4
Training loss: 1.611646881941998
Validation loss: 2.3878188392964956

Epoch: 5| Step: 5
Training loss: 2.2002529605741104
Validation loss: 2.3458702904419027

Epoch: 5| Step: 6
Training loss: 2.5364966001241567
Validation loss: 2.383949754791671

Epoch: 5| Step: 7
Training loss: 2.129919080674702
Validation loss: 2.33480730137724

Epoch: 5| Step: 8
Training loss: 1.5749760550237948
Validation loss: 2.364112193057978

Epoch: 5| Step: 9
Training loss: 1.6190135431977897
Validation loss: 2.34547884711489

Epoch: 5| Step: 10
Training loss: 2.3302851134946043
Validation loss: 2.3914532911158606

Epoch: 256| Step: 0
Training loss: 2.2462117835834143
Validation loss: 2.339283454970776

Epoch: 5| Step: 1
Training loss: 2.81702262916454
Validation loss: 2.346489983859006

Epoch: 5| Step: 2
Training loss: 1.4515031356909058
Validation loss: 2.3510150320519974

Epoch: 5| Step: 3
Training loss: 1.9286171110484975
Validation loss: 2.329022747789101

Epoch: 5| Step: 4
Training loss: 1.9425687628987778
Validation loss: 2.351901056346016

Epoch: 5| Step: 5
Training loss: 1.8388981748169122
Validation loss: 2.316401865124156

Epoch: 5| Step: 6
Training loss: 1.5915708416492296
Validation loss: 2.3224921412237696

Epoch: 5| Step: 7
Training loss: 2.1337635868044424
Validation loss: 2.39704382992063

Epoch: 5| Step: 8
Training loss: 1.7330876977196106
Validation loss: 2.3296925278691756

Epoch: 5| Step: 9
Training loss: 1.7576753690000058
Validation loss: 2.3764780723053427

Epoch: 5| Step: 10
Training loss: 1.9131865073345369
Validation loss: 2.3676615747660987

Epoch: 257| Step: 0
Training loss: 1.6856929145571296
Validation loss: 2.4067377491860658

Epoch: 5| Step: 1
Training loss: 1.6470859283933776
Validation loss: 2.347653386774242

Epoch: 5| Step: 2
Training loss: 1.7402375945843884
Validation loss: 2.3465057218846384

Epoch: 5| Step: 3
Training loss: 2.3607991953745975
Validation loss: 2.3577831830930576

Epoch: 5| Step: 4
Training loss: 1.802583467029788
Validation loss: 2.33923424925727

Epoch: 5| Step: 5
Training loss: 1.4942103550415937
Validation loss: 2.3402843225935595

Epoch: 5| Step: 6
Training loss: 2.5837614463548917
Validation loss: 2.3609362117822754

Epoch: 5| Step: 7
Training loss: 2.017963560941717
Validation loss: 2.35311280097736

Epoch: 5| Step: 8
Training loss: 2.3594417941510173
Validation loss: 2.342581552730624

Epoch: 5| Step: 9
Training loss: 1.9068651301235757
Validation loss: 2.34906986722021

Epoch: 5| Step: 10
Training loss: 1.6427009890369382
Validation loss: 2.385824191697176

Epoch: 258| Step: 0
Training loss: 1.5783934412101208
Validation loss: 2.363487268978667

Epoch: 5| Step: 1
Training loss: 2.2570481640058846
Validation loss: 2.3683761790248776

Epoch: 5| Step: 2
Training loss: 2.1066018419110475
Validation loss: 2.341044944697206

Epoch: 5| Step: 3
Training loss: 1.6241543843780473
Validation loss: 2.3845934456031026

Epoch: 5| Step: 4
Training loss: 1.9115630354170388
Validation loss: 2.3732601738187546

Epoch: 5| Step: 5
Training loss: 2.496024499448947
Validation loss: 2.3853000281520282

Epoch: 5| Step: 6
Training loss: 2.042838389685011
Validation loss: 2.366031838574987

Epoch: 5| Step: 7
Training loss: 1.7466884342807665
Validation loss: 2.3279207366708263

Epoch: 5| Step: 8
Training loss: 1.7038336163361087
Validation loss: 2.4003775130082614

Epoch: 5| Step: 9
Training loss: 1.9865207634970574
Validation loss: 2.3395045933752927

Epoch: 5| Step: 10
Training loss: 2.1714629736125515
Validation loss: 2.3826456953973083

Epoch: 259| Step: 0
Training loss: 1.6032466314325913
Validation loss: 2.3978080419213756

Epoch: 5| Step: 1
Training loss: 1.9030451490064824
Validation loss: 2.381378672001668

Epoch: 5| Step: 2
Training loss: 2.3493395465713824
Validation loss: 2.3647655756361905

Epoch: 5| Step: 3
Training loss: 2.027833265767593
Validation loss: 2.364394052734109

Epoch: 5| Step: 4
Training loss: 2.062273764484579
Validation loss: 2.3760439181988913

Epoch: 5| Step: 5
Training loss: 2.396327777648986
Validation loss: 2.375673988574602

Epoch: 5| Step: 6
Training loss: 1.7577867294117884
Validation loss: 2.3418940348533477

Epoch: 5| Step: 7
Training loss: 1.643034047322517
Validation loss: 2.353508838767516

Epoch: 5| Step: 8
Training loss: 1.8342194005424137
Validation loss: 2.377721177488622

Epoch: 5| Step: 9
Training loss: 1.9893902456914028
Validation loss: 2.3437518201157808

Epoch: 5| Step: 10
Training loss: 1.813445732417493
Validation loss: 2.3412363876504974

Epoch: 260| Step: 0
Training loss: 1.4928381335233942
Validation loss: 2.3770385034430723

Epoch: 5| Step: 1
Training loss: 1.6690763061615232
Validation loss: 2.344075306838931

Epoch: 5| Step: 2
Training loss: 1.5740180633070713
Validation loss: 2.3480850572582175

Epoch: 5| Step: 3
Training loss: 2.0152883322424993
Validation loss: 2.3349463052441655

Epoch: 5| Step: 4
Training loss: 1.8187308582465298
Validation loss: 2.361812805257023

Epoch: 5| Step: 5
Training loss: 2.36989164595646
Validation loss: 2.352985075931905

Epoch: 5| Step: 6
Training loss: 1.8488532094666221
Validation loss: 2.3414558344927543

Epoch: 5| Step: 7
Training loss: 2.366642149498259
Validation loss: 2.348771455482934

Epoch: 5| Step: 8
Training loss: 2.0877880788515926
Validation loss: 2.412310620274637

Epoch: 5| Step: 9
Training loss: 1.963784389182597
Validation loss: 2.3658553744115176

Epoch: 5| Step: 10
Training loss: 1.9154363567321375
Validation loss: 2.330937254739117

Epoch: 261| Step: 0
Training loss: 1.924735940434212
Validation loss: 2.364148632917405

Epoch: 5| Step: 1
Training loss: 1.827260065466198
Validation loss: 2.369149576091823

Epoch: 5| Step: 2
Training loss: 1.6873394218620337
Validation loss: 2.3518196499275335

Epoch: 5| Step: 3
Training loss: 1.721549095701285
Validation loss: 2.32947046129957

Epoch: 5| Step: 4
Training loss: 2.375881433052445
Validation loss: 2.34328575540679

Epoch: 5| Step: 5
Training loss: 1.748162667472504
Validation loss: 2.3566089179961547

Epoch: 5| Step: 6
Training loss: 1.8676337183784646
Validation loss: 2.305772506852202

Epoch: 5| Step: 7
Training loss: 1.8692962358487748
Validation loss: 2.4098241210249736

Epoch: 5| Step: 8
Training loss: 1.7964482339672965
Validation loss: 2.3414377336726657

Epoch: 5| Step: 9
Training loss: 2.35668043662243
Validation loss: 2.36898392888502

Epoch: 5| Step: 10
Training loss: 1.7833865552904733
Validation loss: 2.3345745512870533

Epoch: 262| Step: 0
Training loss: 1.7307488277243435
Validation loss: 2.3514092213868762

Epoch: 5| Step: 1
Training loss: 2.348461857083748
Validation loss: 2.3555533372282076

Epoch: 5| Step: 2
Training loss: 1.807160833571989
Validation loss: 2.373752590236933

Epoch: 5| Step: 3
Training loss: 1.5408233019741409
Validation loss: 2.3430022328639906

Epoch: 5| Step: 4
Training loss: 2.0885274859650154
Validation loss: 2.3567873275978255

Epoch: 5| Step: 5
Training loss: 1.5246407476545316
Validation loss: 2.376984577195168

Epoch: 5| Step: 6
Training loss: 1.722450988027946
Validation loss: 2.381368238188783

Epoch: 5| Step: 7
Training loss: 1.9603259588235948
Validation loss: 2.3689041922594036

Epoch: 5| Step: 8
Training loss: 2.6993742040980537
Validation loss: 2.3794272693964547

Epoch: 5| Step: 9
Training loss: 1.7835570002014316
Validation loss: 2.3812761760023675

Epoch: 5| Step: 10
Training loss: 1.9343851955065017
Validation loss: 2.3269306215341095

Epoch: 263| Step: 0
Training loss: 2.222774884589313
Validation loss: 2.3972958638188855

Epoch: 5| Step: 1
Training loss: 1.782419456599006
Validation loss: 2.3647363611485894

Epoch: 5| Step: 2
Training loss: 1.5635663018095585
Validation loss: 2.314923851722052

Epoch: 5| Step: 3
Training loss: 1.369636217393588
Validation loss: 2.354150270199301

Epoch: 5| Step: 4
Training loss: 2.139093449816613
Validation loss: 2.328862357235167

Epoch: 5| Step: 5
Training loss: 2.1497414810538893
Validation loss: 2.31645214018269

Epoch: 5| Step: 6
Training loss: 2.04239449535544
Validation loss: 2.3607833930041724

Epoch: 5| Step: 7
Training loss: 1.820424743597172
Validation loss: 2.361386950612797

Epoch: 5| Step: 8
Training loss: 1.9299495997790663
Validation loss: 2.356058655432775

Epoch: 5| Step: 9
Training loss: 2.030083424023775
Validation loss: 2.29008136705557

Epoch: 5| Step: 10
Training loss: 2.3177033727928538
Validation loss: 2.3578412591251303

Epoch: 264| Step: 0
Training loss: 1.7374050718213925
Validation loss: 2.353145393815193

Epoch: 5| Step: 1
Training loss: 1.5724559218592378
Validation loss: 2.339303468914246

Epoch: 5| Step: 2
Training loss: 2.1792303446795427
Validation loss: 2.3598732718589415

Epoch: 5| Step: 3
Training loss: 2.3048136013899474
Validation loss: 2.330688627633744

Epoch: 5| Step: 4
Training loss: 1.972872943118416
Validation loss: 2.3927351477542977

Epoch: 5| Step: 5
Training loss: 2.343834430445399
Validation loss: 2.3371612836436895

Epoch: 5| Step: 6
Training loss: 1.5985777792432507
Validation loss: 2.350340116434193

Epoch: 5| Step: 7
Training loss: 1.4842926002519994
Validation loss: 2.332750652736217

Epoch: 5| Step: 8
Training loss: 1.8660781948882141
Validation loss: 2.3682701916050526

Epoch: 5| Step: 9
Training loss: 1.7283859635337326
Validation loss: 2.4021594017082766

Epoch: 5| Step: 10
Training loss: 2.214254633953461
Validation loss: 2.3891280499022263

Epoch: 265| Step: 0
Training loss: 1.5187662351392006
Validation loss: 2.3745861988292782

Epoch: 5| Step: 1
Training loss: 1.3627839151353018
Validation loss: 2.3465608757025143

Epoch: 5| Step: 2
Training loss: 1.9522535287222111
Validation loss: 2.3845006381598726

Epoch: 5| Step: 3
Training loss: 2.3460714414731902
Validation loss: 2.3616590162949893

Epoch: 5| Step: 4
Training loss: 2.235347082851016
Validation loss: 2.3875515144579085

Epoch: 5| Step: 5
Training loss: 1.53649052300651
Validation loss: 2.341477156317275

Epoch: 5| Step: 6
Training loss: 2.475540094496643
Validation loss: 2.301401512758341

Epoch: 5| Step: 7
Training loss: 1.655396799537521
Validation loss: 2.367768613145248

Epoch: 5| Step: 8
Training loss: 1.8525484574501494
Validation loss: 2.3782957381962047

Epoch: 5| Step: 9
Training loss: 1.581272122073823
Validation loss: 2.3246932712706703

Epoch: 5| Step: 10
Training loss: 2.3704229722654664
Validation loss: 2.3802102562537635

Epoch: 266| Step: 0
Training loss: 2.1467604871746717
Validation loss: 2.3571016110225855

Epoch: 5| Step: 1
Training loss: 1.7320509452199027
Validation loss: 2.3265995319842614

Epoch: 5| Step: 2
Training loss: 1.8395651831186914
Validation loss: 2.296553106956221

Epoch: 5| Step: 3
Training loss: 1.9553343217268244
Validation loss: 2.344365500843377

Epoch: 5| Step: 4
Training loss: 1.8184308325866043
Validation loss: 2.357945517199097

Epoch: 5| Step: 5
Training loss: 1.6197551302044795
Validation loss: 2.339786807484632

Epoch: 5| Step: 6
Training loss: 2.132181374648553
Validation loss: 2.3847136951283194

Epoch: 5| Step: 7
Training loss: 1.9310410420477857
Validation loss: 2.355745654120892

Epoch: 5| Step: 8
Training loss: 1.8566503356384298
Validation loss: 2.3486960296244703

Epoch: 5| Step: 9
Training loss: 2.3275053492565534
Validation loss: 2.367375128180454

Epoch: 5| Step: 10
Training loss: 1.7923023589493448
Validation loss: 2.3436487664130246

Epoch: 267| Step: 0
Training loss: 1.3518199344730226
Validation loss: 2.3415893505430447

Epoch: 5| Step: 1
Training loss: 1.8288370685618627
Validation loss: 2.3579790385869557

Epoch: 5| Step: 2
Training loss: 1.94419228038874
Validation loss: 2.3003137164553165

Epoch: 5| Step: 3
Training loss: 1.7301944144935215
Validation loss: 2.3377704080751203

Epoch: 5| Step: 4
Training loss: 1.9558867193390108
Validation loss: 2.342047665831384

Epoch: 5| Step: 5
Training loss: 1.6834695509130297
Validation loss: 2.3850549360109503

Epoch: 5| Step: 6
Training loss: 2.09299022496944
Validation loss: 2.3615006122149604

Epoch: 5| Step: 7
Training loss: 2.159844981388231
Validation loss: 2.3848802674809626

Epoch: 5| Step: 8
Training loss: 1.792336944761369
Validation loss: 2.3571022374940127

Epoch: 5| Step: 9
Training loss: 2.2899869022244688
Validation loss: 2.349148050813212

Epoch: 5| Step: 10
Training loss: 1.843325937933455
Validation loss: 2.3023500029599884

Epoch: 268| Step: 0
Training loss: 2.027454527546078
Validation loss: 2.3345693890239994

Epoch: 5| Step: 1
Training loss: 2.1708753741605524
Validation loss: 2.3450821698104654

Epoch: 5| Step: 2
Training loss: 1.6338522488995542
Validation loss: 2.3207645693347754

Epoch: 5| Step: 3
Training loss: 2.054742152426373
Validation loss: 2.3424893506154385

Epoch: 5| Step: 4
Training loss: 1.7905468509257465
Validation loss: 2.3762750640874892

Epoch: 5| Step: 5
Training loss: 2.2297501082742706
Validation loss: 2.3341885118787227

Epoch: 5| Step: 6
Training loss: 1.7848175194906788
Validation loss: 2.36409757477356

Epoch: 5| Step: 7
Training loss: 1.529271618864725
Validation loss: 2.395913683884586

Epoch: 5| Step: 8
Training loss: 1.737980437235593
Validation loss: 2.3618320519173044

Epoch: 5| Step: 9
Training loss: 1.6895955813991321
Validation loss: 2.33086849659409

Epoch: 5| Step: 10
Training loss: 1.9985183353494422
Validation loss: 2.3813751883275835

Epoch: 269| Step: 0
Training loss: 1.6804652343032218
Validation loss: 2.3820363201247665

Epoch: 5| Step: 1
Training loss: 2.0336110404851646
Validation loss: 2.3394151027551944

Epoch: 5| Step: 2
Training loss: 1.6476507976327817
Validation loss: 2.3759865107114213

Epoch: 5| Step: 3
Training loss: 2.0433268771087723
Validation loss: 2.4185065930449787

Epoch: 5| Step: 4
Training loss: 1.5040323576134966
Validation loss: 2.350181762117275

Epoch: 5| Step: 5
Training loss: 1.6628099482444507
Validation loss: 2.3269808084813453

Epoch: 5| Step: 6
Training loss: 1.8723133548261301
Validation loss: 2.3585320955278104

Epoch: 5| Step: 7
Training loss: 2.3107078412337336
Validation loss: 2.319563668211071

Epoch: 5| Step: 8
Training loss: 2.517664396644167
Validation loss: 2.441831483884613

Epoch: 5| Step: 9
Training loss: 1.6329820170770173
Validation loss: 2.330175963815845

Epoch: 5| Step: 10
Training loss: 2.0340750196232493
Validation loss: 2.4088874046118947

Epoch: 270| Step: 0
Training loss: 1.941801157647158
Validation loss: 2.3264312011351516

Epoch: 5| Step: 1
Training loss: 1.563866132514553
Validation loss: 2.3537618648599086

Epoch: 5| Step: 2
Training loss: 1.7204998472169888
Validation loss: 2.338930136154001

Epoch: 5| Step: 3
Training loss: 1.2911494614197647
Validation loss: 2.2917227256235115

Epoch: 5| Step: 4
Training loss: 1.9237175769316812
Validation loss: 2.3498774869005383

Epoch: 5| Step: 5
Training loss: 2.667454146301231
Validation loss: 2.3579055435822927

Epoch: 5| Step: 6
Training loss: 1.9554575914833447
Validation loss: 2.3348945936979852

Epoch: 5| Step: 7
Training loss: 2.049996478380109
Validation loss: 2.3623249073929506

Epoch: 5| Step: 8
Training loss: 2.062843640916911
Validation loss: 2.353850579138396

Epoch: 5| Step: 9
Training loss: 1.4618284395329013
Validation loss: 2.374602803261301

Epoch: 5| Step: 10
Training loss: 1.9681026060369424
Validation loss: 2.371422740845257

Epoch: 271| Step: 0
Training loss: 1.6777651409840983
Validation loss: 2.3551109479057066

Epoch: 5| Step: 1
Training loss: 2.0565866026707136
Validation loss: 2.3735751134442094

Epoch: 5| Step: 2
Training loss: 1.842571851967539
Validation loss: 2.343589759735976

Epoch: 5| Step: 3
Training loss: 1.5570898616341895
Validation loss: 2.3504501970164973

Epoch: 5| Step: 4
Training loss: 1.8563015965955514
Validation loss: 2.3014443280490866

Epoch: 5| Step: 5
Training loss: 1.6985714435840933
Validation loss: 2.3143762672227686

Epoch: 5| Step: 6
Training loss: 1.6719594203277353
Validation loss: 2.335293090404349

Epoch: 5| Step: 7
Training loss: 1.7947233503302344
Validation loss: 2.3413809153273615

Epoch: 5| Step: 8
Training loss: 1.7663459993637667
Validation loss: 2.323469225300723

Epoch: 5| Step: 9
Training loss: 2.1633497916811772
Validation loss: 2.318808894206488

Epoch: 5| Step: 10
Training loss: 2.4467940549749865
Validation loss: 2.307879008437472

Epoch: 272| Step: 0
Training loss: 2.1989050958267575
Validation loss: 2.3556878803868213

Epoch: 5| Step: 1
Training loss: 1.8020839654410545
Validation loss: 2.3421552541686133

Epoch: 5| Step: 2
Training loss: 1.6919267307316552
Validation loss: 2.303109125648724

Epoch: 5| Step: 3
Training loss: 1.996404933375181
Validation loss: 2.317940445923984

Epoch: 5| Step: 4
Training loss: 1.5536315245507084
Validation loss: 2.338523768389771

Epoch: 5| Step: 5
Training loss: 1.745027152344815
Validation loss: 2.3714512183903156

Epoch: 5| Step: 6
Training loss: 1.947551006192755
Validation loss: 2.327665845431882

Epoch: 5| Step: 7
Training loss: 1.6310070222274262
Validation loss: 2.346931995952524

Epoch: 5| Step: 8
Training loss: 1.8719369027882937
Validation loss: 2.3774474475254546

Epoch: 5| Step: 9
Training loss: 2.26850634230664
Validation loss: 2.3243626400493214

Epoch: 5| Step: 10
Training loss: 1.8610979960661136
Validation loss: 2.381910745541059

Epoch: 273| Step: 0
Training loss: 1.7167084793751586
Validation loss: 2.377620091578316

Epoch: 5| Step: 1
Training loss: 1.9141371109102956
Validation loss: 2.3863223167066487

Epoch: 5| Step: 2
Training loss: 1.4496924764815424
Validation loss: 2.3574050788672882

Epoch: 5| Step: 3
Training loss: 2.188121380425701
Validation loss: 2.3692077854980886

Epoch: 5| Step: 4
Training loss: 2.026171630247479
Validation loss: 2.3915698405268846

Epoch: 5| Step: 5
Training loss: 2.5378121921561196
Validation loss: 2.355554392372661

Epoch: 5| Step: 6
Training loss: 1.4053215352642316
Validation loss: 2.312681817886564

Epoch: 5| Step: 7
Training loss: 1.7307562664557168
Validation loss: 2.326838980891286

Epoch: 5| Step: 8
Training loss: 1.6038992605228932
Validation loss: 2.3875867757096394

Epoch: 5| Step: 9
Training loss: 2.109086871778576
Validation loss: 2.360850007770553

Epoch: 5| Step: 10
Training loss: 1.5972449185882718
Validation loss: 2.3551080033937883

Epoch: 274| Step: 0
Training loss: 1.708333441881626
Validation loss: 2.3611340022400014

Epoch: 5| Step: 1
Training loss: 1.6353749150415609
Validation loss: 2.4018459900549316

Epoch: 5| Step: 2
Training loss: 1.8009847993479289
Validation loss: 2.378950313834434

Epoch: 5| Step: 3
Training loss: 1.76171875
Validation loss: 2.3019874581372117

Epoch: 5| Step: 4
Training loss: 1.7679091675714917
Validation loss: 2.393625161138137

Epoch: 5| Step: 5
Training loss: 1.876469481336157
Validation loss: 2.401637548571998

Epoch: 5| Step: 6
Training loss: 1.607581240794693
Validation loss: 2.3383130097124534

Epoch: 5| Step: 7
Training loss: 1.1799151977681512
Validation loss: 2.3234926242993454

Epoch: 5| Step: 8
Training loss: 2.7808297514861438
Validation loss: 2.396970363438179

Epoch: 5| Step: 9
Training loss: 1.9106361706787436
Validation loss: 2.3803271666102983

Epoch: 5| Step: 10
Training loss: 2.125928788005356
Validation loss: 2.361176755001881

Epoch: 275| Step: 0
Training loss: 1.7175821671688847
Validation loss: 2.383653212368276

Epoch: 5| Step: 1
Training loss: 1.7599199335352826
Validation loss: 2.3181032775955193

Epoch: 5| Step: 2
Training loss: 1.360284040956518
Validation loss: 2.3723503178576557

Epoch: 5| Step: 3
Training loss: 1.7498330990357913
Validation loss: 2.348792511158536

Epoch: 5| Step: 4
Training loss: 1.955522942030249
Validation loss: 2.394449889821922

Epoch: 5| Step: 5
Training loss: 2.5199577029780844
Validation loss: 2.380877901851949

Epoch: 5| Step: 6
Training loss: 2.126507392746672
Validation loss: 2.3592587649980574

Epoch: 5| Step: 7
Training loss: 1.633376247789422
Validation loss: 2.370726166630863

Epoch: 5| Step: 8
Training loss: 2.0224703683085288
Validation loss: 2.3594681286049908

Epoch: 5| Step: 9
Training loss: 1.927134504583926
Validation loss: 2.3242258577969728

Epoch: 5| Step: 10
Training loss: 1.4257428725838874
Validation loss: 2.3785012747424354

Epoch: 276| Step: 0
Training loss: 2.2268355352741405
Validation loss: 2.362323224759792

Epoch: 5| Step: 1
Training loss: 1.9872722951137718
Validation loss: 2.359843524238669

Epoch: 5| Step: 2
Training loss: 1.5339323411416546
Validation loss: 2.3529846875155176

Epoch: 5| Step: 3
Training loss: 1.689095625786337
Validation loss: 2.355088205945799

Epoch: 5| Step: 4
Training loss: 1.6366526879427772
Validation loss: 2.349169213334348

Epoch: 5| Step: 5
Training loss: 1.9407071057824699
Validation loss: 2.328223843625928

Epoch: 5| Step: 6
Training loss: 1.6017368128748575
Validation loss: 2.3910946423236545

Epoch: 5| Step: 7
Training loss: 1.643423327921467
Validation loss: 2.3512501611221235

Epoch: 5| Step: 8
Training loss: 1.99166121169531
Validation loss: 2.3793974737205126

Epoch: 5| Step: 9
Training loss: 1.9704193425081373
Validation loss: 2.339745654750078

Epoch: 5| Step: 10
Training loss: 1.6873064989834659
Validation loss: 2.3631513906524173

Epoch: 277| Step: 0
Training loss: 2.000924969404104
Validation loss: 2.390055841291366

Epoch: 5| Step: 1
Training loss: 1.8285014751158208
Validation loss: 2.3602784161702184

Epoch: 5| Step: 2
Training loss: 2.230079737208484
Validation loss: 2.3585178562500126

Epoch: 5| Step: 3
Training loss: 1.5562458758318691
Validation loss: 2.385909641122915

Epoch: 5| Step: 4
Training loss: 1.6370658415438155
Validation loss: 2.3515997644443356

Epoch: 5| Step: 5
Training loss: 2.0598360833441536
Validation loss: 2.38774973284743

Epoch: 5| Step: 6
Training loss: 2.1302024884753887
Validation loss: 2.30674513477209

Epoch: 5| Step: 7
Training loss: 1.8044368024811952
Validation loss: 2.3375116116894095

Epoch: 5| Step: 8
Training loss: 1.6174686205973035
Validation loss: 2.3712366227350445

Epoch: 5| Step: 9
Training loss: 1.5092698402181237
Validation loss: 2.3051697963485007

Epoch: 5| Step: 10
Training loss: 1.8508605270185714
Validation loss: 2.366586603566412

Epoch: 278| Step: 0
Training loss: 1.672537841596861
Validation loss: 2.334654468822632

Epoch: 5| Step: 1
Training loss: 1.974213119879221
Validation loss: 2.344086023669183

Epoch: 5| Step: 2
Training loss: 1.5390992910567283
Validation loss: 2.3501804989398045

Epoch: 5| Step: 3
Training loss: 2.300030571278281
Validation loss: 2.4338054155079476

Epoch: 5| Step: 4
Training loss: 1.899758213118329
Validation loss: 2.410019410828369

Epoch: 5| Step: 5
Training loss: 1.9456634817658844
Validation loss: 2.3354496888432834

Epoch: 5| Step: 6
Training loss: 1.4180281025048158
Validation loss: 2.3416998435834753

Epoch: 5| Step: 7
Training loss: 1.5547429367226404
Validation loss: 2.404655627238452

Epoch: 5| Step: 8
Training loss: 1.9284629488514353
Validation loss: 2.3764527470183747

Epoch: 5| Step: 9
Training loss: 1.9872483004131913
Validation loss: 2.333166612727869

Epoch: 5| Step: 10
Training loss: 1.6170441937184266
Validation loss: 2.379605481865502

Epoch: 279| Step: 0
Training loss: 1.9149582615778353
Validation loss: 2.382352827475189

Epoch: 5| Step: 1
Training loss: 1.5523775662413946
Validation loss: 2.3059998371782457

Epoch: 5| Step: 2
Training loss: 1.5191627977537832
Validation loss: 2.4013101580102982

Epoch: 5| Step: 3
Training loss: 1.5672843925972888
Validation loss: 2.3893358643607847

Epoch: 5| Step: 4
Training loss: 1.5141561410328495
Validation loss: 2.332182181832867

Epoch: 5| Step: 5
Training loss: 2.187095931744774
Validation loss: 2.3646198123707234

Epoch: 5| Step: 6
Training loss: 1.6805852575628593
Validation loss: 2.3451707740726553

Epoch: 5| Step: 7
Training loss: 1.983588295531314
Validation loss: 2.3034257113075958

Epoch: 5| Step: 8
Training loss: 2.172969514881366
Validation loss: 2.408375887007483

Epoch: 5| Step: 9
Training loss: 1.5574210973258813
Validation loss: 2.3572888141583084

Epoch: 5| Step: 10
Training loss: 2.1076968829412137
Validation loss: 2.3890972774713393

Epoch: 280| Step: 0
Training loss: 1.83575256714868
Validation loss: 2.3500677788882287

Epoch: 5| Step: 1
Training loss: 2.039566620812476
Validation loss: 2.3879666868400102

Epoch: 5| Step: 2
Training loss: 2.23943529452963
Validation loss: 2.3539112383367033

Epoch: 5| Step: 3
Training loss: 1.84180477136596
Validation loss: 2.323288053002859

Epoch: 5| Step: 4
Training loss: 1.4541427985621733
Validation loss: 2.358879896346349

Epoch: 5| Step: 5
Training loss: 1.8097000857827734
Validation loss: 2.3422793000986553

Epoch: 5| Step: 6
Training loss: 1.3498512857259684
Validation loss: 2.3477291169374706

Epoch: 5| Step: 7
Training loss: 1.278363581916663
Validation loss: 2.358727735586958

Epoch: 5| Step: 8
Training loss: 1.480696044222232
Validation loss: 2.332289594875883

Epoch: 5| Step: 9
Training loss: 2.4233285787221797
Validation loss: 2.3309848550053127

Epoch: 5| Step: 10
Training loss: 1.9624053203316254
Validation loss: 2.3688438239150167

Epoch: 281| Step: 0
Training loss: 2.1948572956176946
Validation loss: 2.340497903894378

Epoch: 5| Step: 1
Training loss: 1.6320999269840608
Validation loss: 2.345482666648337

Epoch: 5| Step: 2
Training loss: 1.7255721898548646
Validation loss: 2.35751770038463

Epoch: 5| Step: 3
Training loss: 2.3406870855391304
Validation loss: 2.366673328179992

Epoch: 5| Step: 4
Training loss: 1.6594462233953424
Validation loss: 2.313716035462429

Epoch: 5| Step: 5
Training loss: 1.595171201241466
Validation loss: 2.3685180624105704

Epoch: 5| Step: 6
Training loss: 1.9471253676489142
Validation loss: 2.320916109587469

Epoch: 5| Step: 7
Training loss: 1.8578415004561775
Validation loss: 2.3547471307550434

Epoch: 5| Step: 8
Training loss: 1.5277495564638173
Validation loss: 2.4025457716611784

Epoch: 5| Step: 9
Training loss: 1.811126912359465
Validation loss: 2.3260630260664836

Epoch: 5| Step: 10
Training loss: 1.795234196401971
Validation loss: 2.3737886747514776

Epoch: 282| Step: 0
Training loss: 1.6861337146294861
Validation loss: 2.3447036181350502

Epoch: 5| Step: 1
Training loss: 1.6409221561711955
Validation loss: 2.3199887343120067

Epoch: 5| Step: 2
Training loss: 1.2500257489413398
Validation loss: 2.340256847706174

Epoch: 5| Step: 3
Training loss: 1.5877700515896038
Validation loss: 2.3646136656830414

Epoch: 5| Step: 4
Training loss: 2.0545491799330753
Validation loss: 2.3573575662063986

Epoch: 5| Step: 5
Training loss: 2.16984298384098
Validation loss: 2.3602070456723157

Epoch: 5| Step: 6
Training loss: 1.4957016712499465
Validation loss: 2.307179299480403

Epoch: 5| Step: 7
Training loss: 2.076482941514952
Validation loss: 2.376583302380601

Epoch: 5| Step: 8
Training loss: 1.7900814170009662
Validation loss: 2.35786734371464

Epoch: 5| Step: 9
Training loss: 1.713335699285118
Validation loss: 2.3693411583563693

Epoch: 5| Step: 10
Training loss: 2.120497477480686
Validation loss: 2.352555307101256

Epoch: 283| Step: 0
Training loss: 1.554501623035662
Validation loss: 2.354604591222872

Epoch: 5| Step: 1
Training loss: 1.6649280857902757
Validation loss: 2.388801385859317

Epoch: 5| Step: 2
Training loss: 1.7685492950980741
Validation loss: 2.401892991975497

Epoch: 5| Step: 3
Training loss: 1.9820587577309359
Validation loss: 2.387097988977819

Epoch: 5| Step: 4
Training loss: 1.5952421944395427
Validation loss: 2.352070324146777

Epoch: 5| Step: 5
Training loss: 1.8800619461121146
Validation loss: 2.3144781869113182

Epoch: 5| Step: 6
Training loss: 1.9644298686351749
Validation loss: 2.3880629032840757

Epoch: 5| Step: 7
Training loss: 1.7975359820503587
Validation loss: 2.3380644070758883

Epoch: 5| Step: 8
Training loss: 2.4458907056206645
Validation loss: 2.3422985512997534

Epoch: 5| Step: 9
Training loss: 1.6699968287729088
Validation loss: 2.354097153137093

Epoch: 5| Step: 10
Training loss: 2.012046179929695
Validation loss: 2.3066842154918215

Epoch: 284| Step: 0
Training loss: 1.8848918022653047
Validation loss: 2.409951414369882

Epoch: 5| Step: 1
Training loss: 1.6164063856992301
Validation loss: 2.3588752926391634

Epoch: 5| Step: 2
Training loss: 1.9905903715897504
Validation loss: 2.317528469899639

Epoch: 5| Step: 3
Training loss: 1.6770595130255492
Validation loss: 2.340008221513588

Epoch: 5| Step: 4
Training loss: 1.8193863243869712
Validation loss: 2.3690771472408305

Epoch: 5| Step: 5
Training loss: 1.5732863625422429
Validation loss: 2.4146967791781813

Epoch: 5| Step: 6
Training loss: 1.5907185465166922
Validation loss: 2.3972238875451732

Epoch: 5| Step: 7
Training loss: 2.261158717365322
Validation loss: 2.3898847531592016

Epoch: 5| Step: 8
Training loss: 2.001314446521331
Validation loss: 2.4072981044537856

Epoch: 5| Step: 9
Training loss: 1.778488092609447
Validation loss: 2.369896380790591

Epoch: 5| Step: 10
Training loss: 2.0862962507146126
Validation loss: 2.3583777078213326

Epoch: 285| Step: 0
Training loss: 1.6005223315706036
Validation loss: 2.3862840243697323

Epoch: 5| Step: 1
Training loss: 1.8169383592452983
Validation loss: 2.2734591473841816

Epoch: 5| Step: 2
Training loss: 1.2041267089198018
Validation loss: 2.3665960961993036

Epoch: 5| Step: 3
Training loss: 1.9518449174295474
Validation loss: 2.3189554724727146

Epoch: 5| Step: 4
Training loss: 1.3933133489066905
Validation loss: 2.3745759996774822

Epoch: 5| Step: 5
Training loss: 1.685056259166921
Validation loss: 2.3456662127926724

Epoch: 5| Step: 6
Training loss: 1.6107478536129425
Validation loss: 2.3232647038067187

Epoch: 5| Step: 7
Training loss: 1.7839417447684263
Validation loss: 2.3545816516567712

Epoch: 5| Step: 8
Training loss: 1.5688414254466994
Validation loss: 2.352904781329105

Epoch: 5| Step: 9
Training loss: 1.9489721474768757
Validation loss: 2.3753200006709703

Epoch: 5| Step: 10
Training loss: 2.8464756573537944
Validation loss: 2.3046121575589424

Epoch: 286| Step: 0
Training loss: 1.8443336856032067
Validation loss: 2.355770223417115

Epoch: 5| Step: 1
Training loss: 1.7665449463400513
Validation loss: 2.3706184874928713

Epoch: 5| Step: 2
Training loss: 1.67100331051474
Validation loss: 2.319043420070583

Epoch: 5| Step: 3
Training loss: 1.4645277165596462
Validation loss: 2.3916655915166323

Epoch: 5| Step: 4
Training loss: 1.7362817816026068
Validation loss: 2.380180398753736

Epoch: 5| Step: 5
Training loss: 2.2898260411983693
Validation loss: 2.3765153621900437

Epoch: 5| Step: 6
Training loss: 2.1302137926648856
Validation loss: 2.3663632010131113

Epoch: 5| Step: 7
Training loss: 1.8284548600434944
Validation loss: 2.3046123322050596

Epoch: 5| Step: 8
Training loss: 1.2637321540334652
Validation loss: 2.314871536191168

Epoch: 5| Step: 9
Training loss: 2.059185022786648
Validation loss: 2.3634260767323814

Epoch: 5| Step: 10
Training loss: 1.6562597886282084
Validation loss: 2.3366307937624207

Epoch: 287| Step: 0
Training loss: 2.225341783482755
Validation loss: 2.349793888916072

Epoch: 5| Step: 1
Training loss: 1.7231200409140914
Validation loss: 2.3400243465914135

Epoch: 5| Step: 2
Training loss: 1.8191461059671228
Validation loss: 2.3103141054052623

Epoch: 5| Step: 3
Training loss: 1.6529035769688654
Validation loss: 2.4079355282262127

Epoch: 5| Step: 4
Training loss: 1.3771987587728456
Validation loss: 2.3812177125400185

Epoch: 5| Step: 5
Training loss: 1.6688517393037345
Validation loss: 2.3459834110605864

Epoch: 5| Step: 6
Training loss: 1.419825827434134
Validation loss: 2.365674018349297

Epoch: 5| Step: 7
Training loss: 2.019242345336597
Validation loss: 2.3774515548291744

Epoch: 5| Step: 8
Training loss: 1.877897122438492
Validation loss: 2.3827361634102067

Epoch: 5| Step: 9
Training loss: 2.2669130018491845
Validation loss: 2.2964321276233552

Epoch: 5| Step: 10
Training loss: 1.5301047733061652
Validation loss: 2.3751799801827587

Epoch: 288| Step: 0
Training loss: 1.3787421109898101
Validation loss: 2.35549751946718

Epoch: 5| Step: 1
Training loss: 1.801283892405986
Validation loss: 2.3314847981496345

Epoch: 5| Step: 2
Training loss: 1.4410650578305855
Validation loss: 2.360167818568294

Epoch: 5| Step: 3
Training loss: 1.747778026855369
Validation loss: 2.3266544954663435

Epoch: 5| Step: 4
Training loss: 1.445705216124619
Validation loss: 2.3374383505556846

Epoch: 5| Step: 5
Training loss: 2.217689690631745
Validation loss: 2.3499281830811367

Epoch: 5| Step: 6
Training loss: 2.247913983060303
Validation loss: 2.3334197341140084

Epoch: 5| Step: 7
Training loss: 1.5500821091838304
Validation loss: 2.336248820668607

Epoch: 5| Step: 8
Training loss: 1.6092842594972463
Validation loss: 2.3264321565367014

Epoch: 5| Step: 9
Training loss: 1.91087343446976
Validation loss: 2.3159524543341132

Epoch: 5| Step: 10
Training loss: 1.8699450062503862
Validation loss: 2.3647971872175817

Epoch: 289| Step: 0
Training loss: 1.3914091920901877
Validation loss: 2.393625560631714

Epoch: 5| Step: 1
Training loss: 1.5864458443877916
Validation loss: 2.3193976894722157

Epoch: 5| Step: 2
Training loss: 1.7258833157779776
Validation loss: 2.352866401119833

Epoch: 5| Step: 3
Training loss: 1.762816634718535
Validation loss: 2.315710566762349

Epoch: 5| Step: 4
Training loss: 1.7433429530056423
Validation loss: 2.3838984534619407

Epoch: 5| Step: 5
Training loss: 1.657649115044492
Validation loss: 2.311356148243526

Epoch: 5| Step: 6
Training loss: 1.6263051293871178
Validation loss: 2.3676852722230164

Epoch: 5| Step: 7
Training loss: 1.88600944628327
Validation loss: 2.3332100493593035

Epoch: 5| Step: 8
Training loss: 2.308161299683726
Validation loss: 2.321425809073154

Epoch: 5| Step: 9
Training loss: 2.050280468060695
Validation loss: 2.2920629675135773

Epoch: 5| Step: 10
Training loss: 1.6049478618674016
Validation loss: 2.349066126093895

Epoch: 290| Step: 0
Training loss: 1.6464260901003007
Validation loss: 2.384504138770293

Epoch: 5| Step: 1
Training loss: 1.7496883932344038
Validation loss: 2.343031945931562

Epoch: 5| Step: 2
Training loss: 1.4091576080813146
Validation loss: 2.3525157377284547

Epoch: 5| Step: 3
Training loss: 1.8315501933716816
Validation loss: 2.3703357407779375

Epoch: 5| Step: 4
Training loss: 2.3173673800450114
Validation loss: 2.306546370429063

Epoch: 5| Step: 5
Training loss: 2.140665318464395
Validation loss: 2.357398211394939

Epoch: 5| Step: 6
Training loss: 1.575713401774917
Validation loss: 2.3799458006177265

Epoch: 5| Step: 7
Training loss: 1.7963951465256571
Validation loss: 2.332742597216746

Epoch: 5| Step: 8
Training loss: 1.8143301307210293
Validation loss: 2.3436789066374755

Epoch: 5| Step: 9
Training loss: 1.2347324674620141
Validation loss: 2.3175796087747496

Epoch: 5| Step: 10
Training loss: 1.8855806634158299
Validation loss: 2.2591813769846025

Epoch: 291| Step: 0
Training loss: 1.9295057450540367
Validation loss: 2.360127591481196

Epoch: 5| Step: 1
Training loss: 1.5598870363661417
Validation loss: 2.369398241043391

Epoch: 5| Step: 2
Training loss: 1.4186419105526902
Validation loss: 2.367458150829261

Epoch: 5| Step: 3
Training loss: 1.9744649621091481
Validation loss: 2.307158615182325

Epoch: 5| Step: 4
Training loss: 1.9353102338233417
Validation loss: 2.3070175569923435

Epoch: 5| Step: 5
Training loss: 1.2283885993239667
Validation loss: 2.286926631569908

Epoch: 5| Step: 6
Training loss: 1.558283801320075
Validation loss: 2.333888723560697

Epoch: 5| Step: 7
Training loss: 1.708642474170054
Validation loss: 2.327818277804716

Epoch: 5| Step: 8
Training loss: 1.6722896453907303
Validation loss: 2.3391628126077024

Epoch: 5| Step: 9
Training loss: 2.436421962910727
Validation loss: 2.379853865456994

Epoch: 5| Step: 10
Training loss: 1.6127261483754551
Validation loss: 2.3339562509333454

Epoch: 292| Step: 0
Training loss: 2.112745855346991
Validation loss: 2.3877229179415336

Epoch: 5| Step: 1
Training loss: 1.5385336959863123
Validation loss: 2.330736791740663

Epoch: 5| Step: 2
Training loss: 1.8655697506083138
Validation loss: 2.3883815970644795

Epoch: 5| Step: 3
Training loss: 1.4820750035497026
Validation loss: 2.331409878004527

Epoch: 5| Step: 4
Training loss: 2.217091222370376
Validation loss: 2.3284275507751917

Epoch: 5| Step: 5
Training loss: 1.7305611958147324
Validation loss: 2.3714734326379774

Epoch: 5| Step: 6
Training loss: 1.5046452279654445
Validation loss: 2.3195052938929006

Epoch: 5| Step: 7
Training loss: 1.7390436793540212
Validation loss: 2.382393117249354

Epoch: 5| Step: 8
Training loss: 1.8980680506518715
Validation loss: 2.3446763590410997

Epoch: 5| Step: 9
Training loss: 2.0545161070611213
Validation loss: 2.298866703717139

Epoch: 5| Step: 10
Training loss: 1.335418645031079
Validation loss: 2.406681271981028

Epoch: 293| Step: 0
Training loss: 1.9766522413545466
Validation loss: 2.403355595736448

Epoch: 5| Step: 1
Training loss: 1.6094901775144521
Validation loss: 2.316813667471882

Epoch: 5| Step: 2
Training loss: 1.4436951531895568
Validation loss: 2.337898479656171

Epoch: 5| Step: 3
Training loss: 1.5991767792069722
Validation loss: 2.389024416239044

Epoch: 5| Step: 4
Training loss: 1.539445858376579
Validation loss: 2.2974285836777137

Epoch: 5| Step: 5
Training loss: 1.4510715701528758
Validation loss: 2.3749541783945407

Epoch: 5| Step: 6
Training loss: 1.5150238890070629
Validation loss: 2.319030753522657

Epoch: 5| Step: 7
Training loss: 1.6709816943706335
Validation loss: 2.3715112387572614

Epoch: 5| Step: 8
Training loss: 1.4500636185468732
Validation loss: 2.3285615683339085

Epoch: 5| Step: 9
Training loss: 1.8134258141963653
Validation loss: 2.401089224943736

Epoch: 5| Step: 10
Training loss: 2.8508303185649306
Validation loss: 2.373350316378998

Epoch: 294| Step: 0
Training loss: 2.533782257492018
Validation loss: 2.3155169126278907

Epoch: 5| Step: 1
Training loss: 1.789083422409388
Validation loss: 2.34802701150864

Epoch: 5| Step: 2
Training loss: 1.930289850162314
Validation loss: 2.3804154524833603

Epoch: 5| Step: 3
Training loss: 1.5485795772898132
Validation loss: 2.365109029119144

Epoch: 5| Step: 4
Training loss: 1.59200737620327
Validation loss: 2.405279699844526

Epoch: 5| Step: 5
Training loss: 1.68069356906841
Validation loss: 2.3007323172839005

Epoch: 5| Step: 6
Training loss: 1.7650380467104525
Validation loss: 2.406540529109812

Epoch: 5| Step: 7
Training loss: 1.4125024609839683
Validation loss: 2.3226334340167725

Epoch: 5| Step: 8
Training loss: 1.5972401419846023
Validation loss: 2.347491012572288

Epoch: 5| Step: 9
Training loss: 1.5256136488189422
Validation loss: 2.298261366785465

Epoch: 5| Step: 10
Training loss: 1.5209259457890982
Validation loss: 2.373681142100612

Epoch: 295| Step: 0
Training loss: 1.5412802426727097
Validation loss: 2.2741234291529153

Epoch: 5| Step: 1
Training loss: 1.4737955639293439
Validation loss: 2.3773055875322915

Epoch: 5| Step: 2
Training loss: 1.8496662844127416
Validation loss: 2.352540689471559

Epoch: 5| Step: 3
Training loss: 1.8504721734903393
Validation loss: 2.321709352283197

Epoch: 5| Step: 4
Training loss: 1.45137016410045
Validation loss: 2.305836160802154

Epoch: 5| Step: 5
Training loss: 1.8575884145690842
Validation loss: 2.349892256375989

Epoch: 5| Step: 6
Training loss: 1.106071281005506
Validation loss: 2.3773080419256623

Epoch: 5| Step: 7
Training loss: 2.38008366654097
Validation loss: 2.3311849469627814

Epoch: 5| Step: 8
Training loss: 1.6338141622399531
Validation loss: 2.359673444038196

Epoch: 5| Step: 9
Training loss: 1.8942644383641825
Validation loss: 2.3270116603543713

Epoch: 5| Step: 10
Training loss: 1.8771151374496329
Validation loss: 2.4187112733318834

Epoch: 296| Step: 0
Training loss: 1.590349871330701
Validation loss: 2.362837510471005

Epoch: 5| Step: 1
Training loss: 1.7586002873384363
Validation loss: 2.2994065192714883

Epoch: 5| Step: 2
Training loss: 1.5884150053296822
Validation loss: 2.3686190280718264

Epoch: 5| Step: 3
Training loss: 1.2106497638081897
Validation loss: 2.4036495495928136

Epoch: 5| Step: 4
Training loss: 1.9544256533508018
Validation loss: 2.36306850852459

Epoch: 5| Step: 5
Training loss: 1.6967209972658635
Validation loss: 2.36235462702237

Epoch: 5| Step: 6
Training loss: 1.8276496986623305
Validation loss: 2.3526389736844435

Epoch: 5| Step: 7
Training loss: 1.7914282470097904
Validation loss: 2.3856716808712912

Epoch: 5| Step: 8
Training loss: 1.9735116444822367
Validation loss: 2.3944578876353853

Epoch: 5| Step: 9
Training loss: 2.1647539376909077
Validation loss: 2.3367545624676853

Epoch: 5| Step: 10
Training loss: 1.6354138400626408
Validation loss: 2.3311168658701398

Epoch: 297| Step: 0
Training loss: 1.8827543764125565
Validation loss: 2.4050495971381363

Epoch: 5| Step: 1
Training loss: 1.6375674867191186
Validation loss: 2.3503267328562427

Epoch: 5| Step: 2
Training loss: 1.5472089618880915
Validation loss: 2.328960435356003

Epoch: 5| Step: 3
Training loss: 1.7146305307943044
Validation loss: 2.3693055893160513

Epoch: 5| Step: 4
Training loss: 1.4171746502580782
Validation loss: 2.362655376970451

Epoch: 5| Step: 5
Training loss: 2.104163166710489
Validation loss: 2.417398831592453

Epoch: 5| Step: 6
Training loss: 1.437541961057494
Validation loss: 2.3451494087617824

Epoch: 5| Step: 7
Training loss: 1.9968497380672054
Validation loss: 2.37787947456734

Epoch: 5| Step: 8
Training loss: 1.8603878308062443
Validation loss: 2.3852894884307614

Epoch: 5| Step: 9
Training loss: 1.7087063110838685
Validation loss: 2.3180823855352077

Epoch: 5| Step: 10
Training loss: 1.5174622558977673
Validation loss: 2.333264631880178

Epoch: 298| Step: 0
Training loss: 2.041439497888992
Validation loss: 2.3407230730305693

Epoch: 5| Step: 1
Training loss: 1.296459728994001
Validation loss: 2.3339044927360906

Epoch: 5| Step: 2
Training loss: 1.9572817095844501
Validation loss: 2.363757090816657

Epoch: 5| Step: 3
Training loss: 2.051351762161727
Validation loss: 2.3598635370857264

Epoch: 5| Step: 4
Training loss: 1.5390002242912937
Validation loss: 2.3698655517339797

Epoch: 5| Step: 5
Training loss: 1.6554907732043675
Validation loss: 2.3991048523820435

Epoch: 5| Step: 6
Training loss: 1.8016753056354649
Validation loss: 2.3247556451479148

Epoch: 5| Step: 7
Training loss: 1.537831777735907
Validation loss: 2.3639397532485167

Epoch: 5| Step: 8
Training loss: 1.8006092576911452
Validation loss: 2.348533289780892

Epoch: 5| Step: 9
Training loss: 1.7471843275008296
Validation loss: 2.389506710163737

Epoch: 5| Step: 10
Training loss: 1.5308814091713745
Validation loss: 2.3318870349922336

Epoch: 299| Step: 0
Training loss: 1.5258689062172317
Validation loss: 2.3897706725811103

Epoch: 5| Step: 1
Training loss: 1.847230890519814
Validation loss: 2.351353506407687

Epoch: 5| Step: 2
Training loss: 1.4355050217113134
Validation loss: 2.338842611633109

Epoch: 5| Step: 3
Training loss: 1.4388701501916525
Validation loss: 2.312532222382517

Epoch: 5| Step: 4
Training loss: 1.5877148670555472
Validation loss: 2.360610690481699

Epoch: 5| Step: 5
Training loss: 1.9097249610958302
Validation loss: 2.2960163113291676

Epoch: 5| Step: 6
Training loss: 1.6850495383793922
Validation loss: 2.324432782887912

Epoch: 5| Step: 7
Training loss: 1.9441260584277293
Validation loss: 2.429336692929957

Epoch: 5| Step: 8
Training loss: 1.7719504553927508
Validation loss: 2.3179669200793316

Epoch: 5| Step: 9
Training loss: 2.090060270982713
Validation loss: 2.3500304301518686

Epoch: 5| Step: 10
Training loss: 1.40391843150463
Validation loss: 2.294888132406258

Epoch: 300| Step: 0
Training loss: 1.6407876796903396
Validation loss: 2.377729372274982

Epoch: 5| Step: 1
Training loss: 1.3119439354931748
Validation loss: 2.390258669843323

Epoch: 5| Step: 2
Training loss: 1.1703470059491359
Validation loss: 2.3619409993965896

Epoch: 5| Step: 3
Training loss: 1.7092158046424681
Validation loss: 2.3649927572395155

Epoch: 5| Step: 4
Training loss: 1.6688773831671988
Validation loss: 2.357543245659518

Epoch: 5| Step: 5
Training loss: 1.5757306508312632
Validation loss: 2.326729082279418

Epoch: 5| Step: 6
Training loss: 2.5085223848021987
Validation loss: 2.3179809815518637

Epoch: 5| Step: 7
Training loss: 1.7373830467766187
Validation loss: 2.386277250214264

Epoch: 5| Step: 8
Training loss: 2.197272894953251
Validation loss: 2.3227890209868205

Epoch: 5| Step: 9
Training loss: 1.5169065897025218
Validation loss: 2.327458717622717

Epoch: 5| Step: 10
Training loss: 1.695112436329433
Validation loss: 2.321232170646016

Epoch: 301| Step: 0
Training loss: 1.8690661312872265
Validation loss: 2.305513670270245

Epoch: 5| Step: 1
Training loss: 1.7891047443583064
Validation loss: 2.3800694517186205

Epoch: 5| Step: 2
Training loss: 2.239644273032341
Validation loss: 2.384898629803527

Epoch: 5| Step: 3
Training loss: 1.8887400412659878
Validation loss: 2.360488777303461

Epoch: 5| Step: 4
Training loss: 1.441887586494874
Validation loss: 2.372559649976038

Epoch: 5| Step: 5
Training loss: 1.327106848507899
Validation loss: 2.3474527524394646

Epoch: 5| Step: 6
Training loss: 2.1535031057264096
Validation loss: 2.4169656620204623

Epoch: 5| Step: 7
Training loss: 1.354919498205946
Validation loss: 2.3182664721581534

Epoch: 5| Step: 8
Training loss: 1.9323634693826535
Validation loss: 2.353936923489949

Epoch: 5| Step: 9
Training loss: 1.362095139223694
Validation loss: 2.3611425363507124

Epoch: 5| Step: 10
Training loss: 1.5721819932386618
Validation loss: 2.3434365941453272

Epoch: 302| Step: 0
Training loss: 1.4557141443704664
Validation loss: 2.3565302661053162

Epoch: 5| Step: 1
Training loss: 1.709022321007298
Validation loss: 2.3704735042885323

Epoch: 5| Step: 2
Training loss: 1.8164344703368949
Validation loss: 2.3626456590856617

Epoch: 5| Step: 3
Training loss: 1.6018204644096092
Validation loss: 2.354453731223881

Epoch: 5| Step: 4
Training loss: 1.7609884774276794
Validation loss: 2.3648502834678387

Epoch: 5| Step: 5
Training loss: 2.158631488526765
Validation loss: 2.3223619748363893

Epoch: 5| Step: 6
Training loss: 1.5242940988691822
Validation loss: 2.4018999488988566

Epoch: 5| Step: 7
Training loss: 1.7283764454471466
Validation loss: 2.325430256474923

Epoch: 5| Step: 8
Training loss: 1.4074094443046226
Validation loss: 2.306019591358018

Epoch: 5| Step: 9
Training loss: 1.774402305551481
Validation loss: 2.3953844510414166

Epoch: 5| Step: 10
Training loss: 1.7897848478405018
Validation loss: 2.334519602962654

Epoch: 303| Step: 0
Training loss: 1.6920113483300896
Validation loss: 2.2816211630557466

Epoch: 5| Step: 1
Training loss: 1.975866021645178
Validation loss: 2.3677989833673427

Epoch: 5| Step: 2
Training loss: 1.740033927016709
Validation loss: 2.340712336969883

Epoch: 5| Step: 3
Training loss: 1.7747907139070727
Validation loss: 2.3727131289381105

Epoch: 5| Step: 4
Training loss: 1.1494657104607977
Validation loss: 2.354978018845923

Epoch: 5| Step: 5
Training loss: 1.7516538434537736
Validation loss: 2.323104431062521

Epoch: 5| Step: 6
Training loss: 2.344602099336138
Validation loss: 2.3704242343895094

Epoch: 5| Step: 7
Training loss: 1.4489837209130645
Validation loss: 2.349219592506796

Epoch: 5| Step: 8
Training loss: 1.4088359368555687
Validation loss: 2.2910473841654113

Epoch: 5| Step: 9
Training loss: 1.9395990384043431
Validation loss: 2.3663358523296334

Epoch: 5| Step: 10
Training loss: 1.3714776439061538
Validation loss: 2.3281163173287065

Epoch: 304| Step: 0
Training loss: 1.183534475925928
Validation loss: 2.3458182973206236

Epoch: 5| Step: 1
Training loss: 1.7138638488215343
Validation loss: 2.3490530888551064

Epoch: 5| Step: 2
Training loss: 1.7349396207565548
Validation loss: 2.3601062991109862

Epoch: 5| Step: 3
Training loss: 1.7438881275885187
Validation loss: 2.3588854922946614

Epoch: 5| Step: 4
Training loss: 1.7113129364990578
Validation loss: 2.37541715027301

Epoch: 5| Step: 5
Training loss: 1.3038981899700333
Validation loss: 2.345143723738374

Epoch: 5| Step: 6
Training loss: 1.7498783341757576
Validation loss: 2.364367145346171

Epoch: 5| Step: 7
Training loss: 2.0711983566890604
Validation loss: 2.3445535913329856

Epoch: 5| Step: 8
Training loss: 1.5125725279513813
Validation loss: 2.3815696182059667

Epoch: 5| Step: 9
Training loss: 2.159156498985049
Validation loss: 2.3736107697131583

Epoch: 5| Step: 10
Training loss: 1.5783973685422947
Validation loss: 2.3727371902984835

Epoch: 305| Step: 0
Training loss: 1.7093896701329687
Validation loss: 2.3373640928690733

Epoch: 5| Step: 1
Training loss: 1.75110904428572
Validation loss: 2.3686533051208563

Epoch: 5| Step: 2
Training loss: 1.2678055522484797
Validation loss: 2.3386902696952028

Epoch: 5| Step: 3
Training loss: 1.3003382114471123
Validation loss: 2.375819239000228

Epoch: 5| Step: 4
Training loss: 2.068625169197457
Validation loss: 2.3712255237177193

Epoch: 5| Step: 5
Training loss: 1.9342620619434383
Validation loss: 2.3305306155796295

Epoch: 5| Step: 6
Training loss: 1.5116600794089625
Validation loss: 2.3298925976727256

Epoch: 5| Step: 7
Training loss: 2.1901869484175442
Validation loss: 2.343888055160447

Epoch: 5| Step: 8
Training loss: 1.6476214228386405
Validation loss: 2.3008257676720816

Epoch: 5| Step: 9
Training loss: 1.6856525339403263
Validation loss: 2.333221168795986

Epoch: 5| Step: 10
Training loss: 1.3700022034035666
Validation loss: 2.289906510628508

Epoch: 306| Step: 0
Training loss: 1.8758204254673376
Validation loss: 2.3732580079787526

Epoch: 5| Step: 1
Training loss: 1.289232508690317
Validation loss: 2.3722518863360085

Epoch: 5| Step: 2
Training loss: 1.2527651719678277
Validation loss: 2.3774665735469767

Epoch: 5| Step: 3
Training loss: 1.4111919456684592
Validation loss: 2.3801170118522945

Epoch: 5| Step: 4
Training loss: 1.4853599091645828
Validation loss: 2.345219038658695

Epoch: 5| Step: 5
Training loss: 1.8553979478678941
Validation loss: 2.349286759418702

Epoch: 5| Step: 6
Training loss: 1.5408639966197866
Validation loss: 2.364046772536636

Epoch: 5| Step: 7
Training loss: 1.799852508224239
Validation loss: 2.257000513971083

Epoch: 5| Step: 8
Training loss: 1.504009768403573
Validation loss: 2.343475949252131

Epoch: 5| Step: 9
Training loss: 2.3114660890118754
Validation loss: 2.3699311437244894

Epoch: 5| Step: 10
Training loss: 2.0109661583388547
Validation loss: 2.3946923669428104

Epoch: 307| Step: 0
Training loss: 1.6689524552765524
Validation loss: 2.313362974930492

Epoch: 5| Step: 1
Training loss: 1.7512769808382374
Validation loss: 2.3223017412021854

Epoch: 5| Step: 2
Training loss: 1.723122185561933
Validation loss: 2.362560238504006

Epoch: 5| Step: 3
Training loss: 1.6918628948385979
Validation loss: 2.3236690134106484

Epoch: 5| Step: 4
Training loss: 1.6537690925216872
Validation loss: 2.3630204512026913

Epoch: 5| Step: 5
Training loss: 1.8985178738130173
Validation loss: 2.3106508830139556

Epoch: 5| Step: 6
Training loss: 2.1291179026813114
Validation loss: 2.3040538942342086

Epoch: 5| Step: 7
Training loss: 1.5919529376142416
Validation loss: 2.3678283863517007

Epoch: 5| Step: 8
Training loss: 1.2666531378040276
Validation loss: 2.359279044137611

Epoch: 5| Step: 9
Training loss: 1.7416437095820456
Validation loss: 2.327348838361382

Epoch: 5| Step: 10
Training loss: 1.6067897438985015
Validation loss: 2.3134902889076323

Epoch: 308| Step: 0
Training loss: 1.4272926993759103
Validation loss: 2.3218655736667806

Epoch: 5| Step: 1
Training loss: 1.6416548630085137
Validation loss: 2.340624243555437

Epoch: 5| Step: 2
Training loss: 1.6933162204123013
Validation loss: 2.4227947085873205

Epoch: 5| Step: 3
Training loss: 1.7517504792831373
Validation loss: 2.358898790362117

Epoch: 5| Step: 4
Training loss: 0.9965687535479405
Validation loss: 2.36927419207732

Epoch: 5| Step: 5
Training loss: 2.071314846167904
Validation loss: 2.3482701576546714

Epoch: 5| Step: 6
Training loss: 1.7168631166561383
Validation loss: 2.3436371883464977

Epoch: 5| Step: 7
Training loss: 1.2550227818188069
Validation loss: 2.3180985282100655

Epoch: 5| Step: 8
Training loss: 1.5376287452944266
Validation loss: 2.327206828854303

Epoch: 5| Step: 9
Training loss: 1.7004364911866252
Validation loss: 2.314778478968478

Epoch: 5| Step: 10
Training loss: 2.270701226641001
Validation loss: 2.318506113267096

Epoch: 309| Step: 0
Training loss: 1.836053982549848
Validation loss: 2.321859041074485

Epoch: 5| Step: 1
Training loss: 1.5912598248078809
Validation loss: 2.335311967771979

Epoch: 5| Step: 2
Training loss: 1.4174979613220517
Validation loss: 2.3718667781342053

Epoch: 5| Step: 3
Training loss: 1.4746470465490216
Validation loss: 2.3341100886037944

Epoch: 5| Step: 4
Training loss: 1.9908302021707232
Validation loss: 2.3677947169430826

Epoch: 5| Step: 5
Training loss: 1.745909064508399
Validation loss: 2.3713501008816116

Epoch: 5| Step: 6
Training loss: 1.4012279268511854
Validation loss: 2.389736383837662

Epoch: 5| Step: 7
Training loss: 1.0898312803806123
Validation loss: 2.3536200411922437

Epoch: 5| Step: 8
Training loss: 1.7988523135800747
Validation loss: 2.3591773695965625

Epoch: 5| Step: 9
Training loss: 1.6899791449890873
Validation loss: 2.375184909550104

Epoch: 5| Step: 10
Training loss: 2.5777312931806002
Validation loss: 2.401980965473317

Epoch: 310| Step: 0
Training loss: 1.7877254904057924
Validation loss: 2.3389103100084716

Epoch: 5| Step: 1
Training loss: 2.6340985425736307
Validation loss: 2.3570465396180436

Epoch: 5| Step: 2
Training loss: 1.3967348954432275
Validation loss: 2.330142935822038

Epoch: 5| Step: 3
Training loss: 1.262515640161912
Validation loss: 2.337133710066685

Epoch: 5| Step: 4
Training loss: 1.247155577180091
Validation loss: 2.412417834837629

Epoch: 5| Step: 5
Training loss: 1.7133811326663364
Validation loss: 2.3408332663595397

Epoch: 5| Step: 6
Training loss: 1.5562682430316437
Validation loss: 2.311770285492536

Epoch: 5| Step: 7
Training loss: 1.6712044770596706
Validation loss: 2.3207389522794135

Epoch: 5| Step: 8
Training loss: 1.5095916687309452
Validation loss: 2.294947541179972

Epoch: 5| Step: 9
Training loss: 1.7520947861571174
Validation loss: 2.312318964963989

Epoch: 5| Step: 10
Training loss: 1.401232988797055
Validation loss: 2.300878102844382

Epoch: 311| Step: 0
Training loss: 1.4452168201015694
Validation loss: 2.355621141406455

Epoch: 5| Step: 1
Training loss: 1.3742145115373319
Validation loss: 2.319203752378866

Epoch: 5| Step: 2
Training loss: 1.7909720944904217
Validation loss: 2.344451099936876

Epoch: 5| Step: 3
Training loss: 1.8913236856067717
Validation loss: 2.316235770495535

Epoch: 5| Step: 4
Training loss: 1.334610262998167
Validation loss: 2.354426590050827

Epoch: 5| Step: 5
Training loss: 2.2453435822673553
Validation loss: 2.315628746618332

Epoch: 5| Step: 6
Training loss: 1.3360635798338791
Validation loss: 2.309539253168065

Epoch: 5| Step: 7
Training loss: 1.1028293872728256
Validation loss: 2.4103992593801986

Epoch: 5| Step: 8
Training loss: 2.368815954090361
Validation loss: 2.353362531332993

Epoch: 5| Step: 9
Training loss: 1.884575552571836
Validation loss: 2.372107662218832

Epoch: 5| Step: 10
Training loss: 1.2976202145050855
Validation loss: 2.345849727636786

Epoch: 312| Step: 0
Training loss: 1.653759072899529
Validation loss: 2.3563958504647555

Epoch: 5| Step: 1
Training loss: 1.4750905445562594
Validation loss: 2.3177815636715424

Epoch: 5| Step: 2
Training loss: 1.717411491079104
Validation loss: 2.3384455540896423

Epoch: 5| Step: 3
Training loss: 1.899688559655962
Validation loss: 2.353561325354592

Epoch: 5| Step: 4
Training loss: 1.3374400473019168
Validation loss: 2.329465908422918

Epoch: 5| Step: 5
Training loss: 1.7634507692288364
Validation loss: 2.3191129024499157

Epoch: 5| Step: 6
Training loss: 1.1614407707676981
Validation loss: 2.3314198882788433

Epoch: 5| Step: 7
Training loss: 1.1846389939287767
Validation loss: 2.324784962861505

Epoch: 5| Step: 8
Training loss: 1.6493060820283105
Validation loss: 2.33186984770015

Epoch: 5| Step: 9
Training loss: 1.7348706336258852
Validation loss: 2.299638235792037

Epoch: 5| Step: 10
Training loss: 2.450068033013378
Validation loss: 2.318664254837401

Epoch: 313| Step: 0
Training loss: 1.7728594539509146
Validation loss: 2.350909894936578

Epoch: 5| Step: 1
Training loss: 1.5121140074209347
Validation loss: 2.3320391474769915

Epoch: 5| Step: 2
Training loss: 1.4093924273916894
Validation loss: 2.378234467762753

Epoch: 5| Step: 3
Training loss: 1.386442387940819
Validation loss: 2.3045527793367633

Epoch: 5| Step: 4
Training loss: 1.279213379908876
Validation loss: 2.2723022807732507

Epoch: 5| Step: 5
Training loss: 1.8052233936571618
Validation loss: 2.314599179976711

Epoch: 5| Step: 6
Training loss: 1.31729774963979
Validation loss: 2.348055791907104

Epoch: 5| Step: 7
Training loss: 1.8427393454757457
Validation loss: 2.27544038828986

Epoch: 5| Step: 8
Training loss: 1.5847953103444297
Validation loss: 2.3491072475985577

Epoch: 5| Step: 9
Training loss: 2.431295666106414
Validation loss: 2.388268116652798

Epoch: 5| Step: 10
Training loss: 1.5740584298937585
Validation loss: 2.3675204960352683

Epoch: 314| Step: 0
Training loss: 1.665870007214149
Validation loss: 2.326848463803584

Epoch: 5| Step: 1
Training loss: 1.6307582801048393
Validation loss: 2.3376366102953137

Epoch: 5| Step: 2
Training loss: 1.7434735533642367
Validation loss: 2.341038324905652

Epoch: 5| Step: 3
Training loss: 1.8400778327941338
Validation loss: 2.371505547743827

Epoch: 5| Step: 4
Training loss: 1.9031374800950929
Validation loss: 2.3361015455652736

Epoch: 5| Step: 5
Training loss: 1.1306024500009364
Validation loss: 2.39302548198937

Epoch: 5| Step: 6
Training loss: 1.575363311038942
Validation loss: 2.3544488723738075

Epoch: 5| Step: 7
Training loss: 1.3902961256349549
Validation loss: 2.3572583737794015

Epoch: 5| Step: 8
Training loss: 1.4847866089985708
Validation loss: 2.302566442734899

Epoch: 5| Step: 9
Training loss: 2.2392663302552784
Validation loss: 2.332172809097764

Epoch: 5| Step: 10
Training loss: 1.7458005654743043
Validation loss: 2.3440572798365737

Epoch: 315| Step: 0
Training loss: 1.928942888050213
Validation loss: 2.3616045950275963

Epoch: 5| Step: 1
Training loss: 2.0280694563067834
Validation loss: 2.34289851756234

Epoch: 5| Step: 2
Training loss: 1.2676511958005157
Validation loss: 2.3121783679452927

Epoch: 5| Step: 3
Training loss: 1.4253602124746523
Validation loss: 2.3001146682967515

Epoch: 5| Step: 4
Training loss: 1.5509066206751705
Validation loss: 2.338932824548091

Epoch: 5| Step: 5
Training loss: 1.7780053552690662
Validation loss: 2.385350679748671

Epoch: 5| Step: 6
Training loss: 2.1841471453622336
Validation loss: 2.351427562710801

Epoch: 5| Step: 7
Training loss: 1.3592531873122933
Validation loss: 2.3534750815995977

Epoch: 5| Step: 8
Training loss: 1.1729046684902709
Validation loss: 2.329732295614095

Epoch: 5| Step: 9
Training loss: 1.5901590920275128
Validation loss: 2.3468496705312654

Epoch: 5| Step: 10
Training loss: 1.4709722872936668
Validation loss: 2.3513394460767363

Epoch: 316| Step: 0
Training loss: 1.3884088237582073
Validation loss: 2.3791145451606694

Epoch: 5| Step: 1
Training loss: 1.3582344970941798
Validation loss: 2.372603866255661

Epoch: 5| Step: 2
Training loss: 0.9920376041152981
Validation loss: 2.352025600320535

Epoch: 5| Step: 3
Training loss: 1.8249004650407397
Validation loss: 2.371421670059109

Epoch: 5| Step: 4
Training loss: 1.3443241666993173
Validation loss: 2.3535606892265606

Epoch: 5| Step: 5
Training loss: 1.7452714250968304
Validation loss: 2.307000888394249

Epoch: 5| Step: 6
Training loss: 1.6314202172344856
Validation loss: 2.368353262437994

Epoch: 5| Step: 7
Training loss: 2.2885685410540035
Validation loss: 2.3488304165745304

Epoch: 5| Step: 8
Training loss: 1.800394608370512
Validation loss: 2.3627080873355064

Epoch: 5| Step: 9
Training loss: 1.746057838565623
Validation loss: 2.317893479185596

Epoch: 5| Step: 10
Training loss: 1.5540971258046667
Validation loss: 2.3554076694282955

Epoch: 317| Step: 0
Training loss: 1.5051110928110525
Validation loss: 2.3865162554557644

Epoch: 5| Step: 1
Training loss: 1.3785940362557525
Validation loss: 2.367920537229026

Epoch: 5| Step: 2
Training loss: 2.249844651687328
Validation loss: 2.3524026642313296

Epoch: 5| Step: 3
Training loss: 1.7341241053659566
Validation loss: 2.3407082347466996

Epoch: 5| Step: 4
Training loss: 1.4378225545152312
Validation loss: 2.309215434115914

Epoch: 5| Step: 5
Training loss: 1.6783552697322424
Validation loss: 2.3969082058778204

Epoch: 5| Step: 6
Training loss: 1.574605359484228
Validation loss: 2.3496645988953704

Epoch: 5| Step: 7
Training loss: 1.4892574923155393
Validation loss: 2.3389050049590665

Epoch: 5| Step: 8
Training loss: 1.3671031816912207
Validation loss: 2.3542071277373116

Epoch: 5| Step: 9
Training loss: 1.7383023721504627
Validation loss: 2.391968809136056

Epoch: 5| Step: 10
Training loss: 1.7692327858202104
Validation loss: 2.3805437594617302

Epoch: 318| Step: 0
Training loss: 1.3214978647290578
Validation loss: 2.361848127857329

Epoch: 5| Step: 1
Training loss: 1.4075300536665238
Validation loss: 2.3429652638810805

Epoch: 5| Step: 2
Training loss: 1.5289466817477453
Validation loss: 2.3297316375739765

Epoch: 5| Step: 3
Training loss: 1.5789118400976856
Validation loss: 2.3489920078929987

Epoch: 5| Step: 4
Training loss: 1.5109695036693085
Validation loss: 2.380264964053474

Epoch: 5| Step: 5
Training loss: 1.6668877057684384
Validation loss: 2.4008982193363684

Epoch: 5| Step: 6
Training loss: 2.3601174102284563
Validation loss: 2.3325939684405004

Epoch: 5| Step: 7
Training loss: 1.6067671154933394
Validation loss: 2.3456484406484215

Epoch: 5| Step: 8
Training loss: 1.8180478133323392
Validation loss: 2.3395301704180347

Epoch: 5| Step: 9
Training loss: 1.3751592543883089
Validation loss: 2.3438003589319885

Epoch: 5| Step: 10
Training loss: 1.679404088440271
Validation loss: 2.3773158639396503

Epoch: 319| Step: 0
Training loss: 1.4988864102934967
Validation loss: 2.408642968672526

Epoch: 5| Step: 1
Training loss: 1.3760442669728632
Validation loss: 2.3844241513346445

Epoch: 5| Step: 2
Training loss: 2.490899593288335
Validation loss: 2.3699141192968627

Epoch: 5| Step: 3
Training loss: 1.398122997188711
Validation loss: 2.3166910222755477

Epoch: 5| Step: 4
Training loss: 1.3122217700877439
Validation loss: 2.3088519087353427

Epoch: 5| Step: 5
Training loss: 1.0949975664294649
Validation loss: 2.367660847142358

Epoch: 5| Step: 6
Training loss: 1.8287976323545454
Validation loss: 2.3387505947991905

Epoch: 5| Step: 7
Training loss: 1.7235229111341885
Validation loss: 2.3310520062418134

Epoch: 5| Step: 8
Training loss: 1.5958651550280922
Validation loss: 2.3524091746677427

Epoch: 5| Step: 9
Training loss: 1.5010847302131392
Validation loss: 2.3596757929175753

Epoch: 5| Step: 10
Training loss: 1.8616102871373312
Validation loss: 2.3017113486734173

Epoch: 320| Step: 0
Training loss: 1.729995421695715
Validation loss: 2.380348592588198

Epoch: 5| Step: 1
Training loss: 2.1888711174481763
Validation loss: 2.368022366306008

Epoch: 5| Step: 2
Training loss: 1.5853842536062486
Validation loss: 2.39390353416183

Epoch: 5| Step: 3
Training loss: 1.5436724253325826
Validation loss: 2.3724825847609865

Epoch: 5| Step: 4
Training loss: 1.428362372973757
Validation loss: 2.3777369352166895

Epoch: 5| Step: 5
Training loss: 1.556119479792019
Validation loss: 2.3570568080951873

Epoch: 5| Step: 6
Training loss: 1.6547177982888432
Validation loss: 2.368967825075493

Epoch: 5| Step: 7
Training loss: 1.716940325926964
Validation loss: 2.405500596001598

Epoch: 5| Step: 8
Training loss: 1.3946784874045577
Validation loss: 2.3271403554275896

Epoch: 5| Step: 9
Training loss: 1.309094233671215
Validation loss: 2.351586238681441

Epoch: 5| Step: 10
Training loss: 1.5100687174287173
Validation loss: 2.3403523013151313

Epoch: 321| Step: 0
Training loss: 1.371538747537044
Validation loss: 2.3685105506695767

Epoch: 5| Step: 1
Training loss: 1.4665213375626729
Validation loss: 2.386404857440179

Epoch: 5| Step: 2
Training loss: 1.5426390476710798
Validation loss: 2.364319918973878

Epoch: 5| Step: 3
Training loss: 1.4866776926261855
Validation loss: 2.359589404332501

Epoch: 5| Step: 4
Training loss: 2.0116483509375067
Validation loss: 2.3179181223255285

Epoch: 5| Step: 5
Training loss: 1.3786891517803925
Validation loss: 2.3544784224767716

Epoch: 5| Step: 6
Training loss: 2.204399876314927
Validation loss: 2.327419002454108

Epoch: 5| Step: 7
Training loss: 1.326742147945374
Validation loss: 2.3993719985417843

Epoch: 5| Step: 8
Training loss: 1.2301167302450149
Validation loss: 2.3416459831883607

Epoch: 5| Step: 9
Training loss: 1.7690427665910387
Validation loss: 2.2929006092187816

Epoch: 5| Step: 10
Training loss: 1.4634066029556996
Validation loss: 2.3342540745612332

Epoch: 322| Step: 0
Training loss: 1.7099085810133166
Validation loss: 2.3582485503184247

Epoch: 5| Step: 1
Training loss: 1.3845093224935885
Validation loss: 2.344717052943534

Epoch: 5| Step: 2
Training loss: 1.3150663263397513
Validation loss: 2.357568387228977

Epoch: 5| Step: 3
Training loss: 1.5960615262192417
Validation loss: 2.3561591752047897

Epoch: 5| Step: 4
Training loss: 1.5894835717863327
Validation loss: 2.371198898189376

Epoch: 5| Step: 5
Training loss: 1.5117296321979927
Validation loss: 2.303742562823279

Epoch: 5| Step: 6
Training loss: 1.2289342121646196
Validation loss: 2.3913147947432263

Epoch: 5| Step: 7
Training loss: 1.7397474641711554
Validation loss: 2.312989763690823

Epoch: 5| Step: 8
Training loss: 2.3949061935625693
Validation loss: 2.3474326556273493

Epoch: 5| Step: 9
Training loss: 1.6265612951268726
Validation loss: 2.369857345440792

Epoch: 5| Step: 10
Training loss: 1.533353100870394
Validation loss: 2.3282731653176487

Epoch: 323| Step: 0
Training loss: 1.4120190012439502
Validation loss: 2.4141967483362348

Epoch: 5| Step: 1
Training loss: 1.0435418543882398
Validation loss: 2.329354385203359

Epoch: 5| Step: 2
Training loss: 2.3404307958407204
Validation loss: 2.329829759426928

Epoch: 5| Step: 3
Training loss: 1.3653530347608416
Validation loss: 2.381443956575469

Epoch: 5| Step: 4
Training loss: 1.5391508745100348
Validation loss: 2.2714409803099778

Epoch: 5| Step: 5
Training loss: 1.6260878516249953
Validation loss: 2.302633019908794

Epoch: 5| Step: 6
Training loss: 1.6583177866119125
Validation loss: 2.353805957209831

Epoch: 5| Step: 7
Training loss: 1.8121413171958083
Validation loss: 2.3400151235885613

Epoch: 5| Step: 8
Training loss: 1.397946617878191
Validation loss: 2.3727460284207282

Epoch: 5| Step: 9
Training loss: 1.8282233969788442
Validation loss: 2.338430217882055

Epoch: 5| Step: 10
Training loss: 1.6483666282713716
Validation loss: 2.309580330297004

Epoch: 324| Step: 0
Training loss: 1.4415661896253826
Validation loss: 2.362353794669475

Epoch: 5| Step: 1
Training loss: 1.8605773628551288
Validation loss: 2.3394551238351196

Epoch: 5| Step: 2
Training loss: 1.525452596697491
Validation loss: 2.3607239583341904

Epoch: 5| Step: 3
Training loss: 1.6821394655646444
Validation loss: 2.3251246501946072

Epoch: 5| Step: 4
Training loss: 2.185810199381952
Validation loss: 2.3005574023106132

Epoch: 5| Step: 5
Training loss: 1.6384720254185676
Validation loss: 2.3362529587039864

Epoch: 5| Step: 6
Training loss: 1.6204281095279092
Validation loss: 2.325174864545357

Epoch: 5| Step: 7
Training loss: 1.369577378988403
Validation loss: 2.270704015289902

Epoch: 5| Step: 8
Training loss: 1.2724134856457094
Validation loss: 2.3858187191075455

Epoch: 5| Step: 9
Training loss: 1.6009578400778663
Validation loss: 2.3381521413657635

Epoch: 5| Step: 10
Training loss: 1.428030335609001
Validation loss: 2.384587463285137

Epoch: 325| Step: 0
Training loss: 1.7937399674510515
Validation loss: 2.3468952254166684

Epoch: 5| Step: 1
Training loss: 1.403140126170164
Validation loss: 2.3659523069379995

Epoch: 5| Step: 2
Training loss: 2.5143207462458803
Validation loss: 2.3496830023896798

Epoch: 5| Step: 3
Training loss: 1.512643930191735
Validation loss: 2.3299134179420427

Epoch: 5| Step: 4
Training loss: 1.1529910580965748
Validation loss: 2.3750326136026683

Epoch: 5| Step: 5
Training loss: 1.5183603830925472
Validation loss: 2.282300265962803

Epoch: 5| Step: 6
Training loss: 1.3981800375121092
Validation loss: 2.3361960735176583

Epoch: 5| Step: 7
Training loss: 1.3749882090669876
Validation loss: 2.400430928146281

Epoch: 5| Step: 8
Training loss: 1.5360733670653783
Validation loss: 2.3249431911906635

Epoch: 5| Step: 9
Training loss: 1.4213522484602052
Validation loss: 2.373196282328154

Epoch: 5| Step: 10
Training loss: 2.002707198873606
Validation loss: 2.3168509613500885

Epoch: 326| Step: 0
Training loss: 1.3979916847592935
Validation loss: 2.3789550586575587

Epoch: 5| Step: 1
Training loss: 1.8800208578575968
Validation loss: 2.2736415796106395

Epoch: 5| Step: 2
Training loss: 1.6984970489422415
Validation loss: 2.339217695152511

Epoch: 5| Step: 3
Training loss: 1.6645267179343826
Validation loss: 2.38629245510729

Epoch: 5| Step: 4
Training loss: 1.4411717666077524
Validation loss: 2.317410211215453

Epoch: 5| Step: 5
Training loss: 1.4605157416780734
Validation loss: 2.3828156319094496

Epoch: 5| Step: 6
Training loss: 1.2709133664970997
Validation loss: 2.3507180810569257

Epoch: 5| Step: 7
Training loss: 2.113957266997295
Validation loss: 2.3353967570623033

Epoch: 5| Step: 8
Training loss: 1.3460887251288023
Validation loss: 2.424411008268528

Epoch: 5| Step: 9
Training loss: 1.4768319666174927
Validation loss: 2.4023447893955647

Epoch: 5| Step: 10
Training loss: 1.453457619940553
Validation loss: 2.3591514383149685

Epoch: 327| Step: 0
Training loss: 1.370953240218365
Validation loss: 2.365182284026125

Epoch: 5| Step: 1
Training loss: 1.456239868914682
Validation loss: 2.3019583712762457

Epoch: 5| Step: 2
Training loss: 1.4993702838246319
Validation loss: 2.3931956626897035

Epoch: 5| Step: 3
Training loss: 2.4744584926500877
Validation loss: 2.3084384051204028

Epoch: 5| Step: 4
Training loss: 1.5167362818967645
Validation loss: 2.348827170587734

Epoch: 5| Step: 5
Training loss: 1.2452858245940959
Validation loss: 2.347259211634578

Epoch: 5| Step: 6
Training loss: 1.4734912397307398
Validation loss: 2.320100142253979

Epoch: 5| Step: 7
Training loss: 1.4168002776175281
Validation loss: 2.3541093663777857

Epoch: 5| Step: 8
Training loss: 1.5493371038199508
Validation loss: 2.3241517123899285

Epoch: 5| Step: 9
Training loss: 1.472971186872081
Validation loss: 2.353877343176597

Epoch: 5| Step: 10
Training loss: 1.5513967066269696
Validation loss: 2.36125089081634

Epoch: 328| Step: 0
Training loss: 1.2527891512850495
Validation loss: 2.3571125274808975

Epoch: 5| Step: 1
Training loss: 1.3906245285204828
Validation loss: 2.295572822112967

Epoch: 5| Step: 2
Training loss: 1.446317416163665
Validation loss: 2.3554174656091673

Epoch: 5| Step: 3
Training loss: 2.063646402514097
Validation loss: 2.3289767772718073

Epoch: 5| Step: 4
Training loss: 1.5609410710718739
Validation loss: 2.3555044180574947

Epoch: 5| Step: 5
Training loss: 2.1690862301560396
Validation loss: 2.3345856213982894

Epoch: 5| Step: 6
Training loss: 1.5233896883773432
Validation loss: 2.3620719118579654

Epoch: 5| Step: 7
Training loss: 1.4403555330488624
Validation loss: 2.3347668679247073

Epoch: 5| Step: 8
Training loss: 1.429668989218025
Validation loss: 2.301176799067511

Epoch: 5| Step: 9
Training loss: 1.4875208396413508
Validation loss: 2.334358028420402

Epoch: 5| Step: 10
Training loss: 1.6759574459609639
Validation loss: 2.3430850424944802

Epoch: 329| Step: 0
Training loss: 1.611188884845643
Validation loss: 2.3688832525768055

Epoch: 5| Step: 1
Training loss: 1.4213679321263628
Validation loss: 2.302025780668079

Epoch: 5| Step: 2
Training loss: 1.8460952584433639
Validation loss: 2.3055577413001114

Epoch: 5| Step: 3
Training loss: 1.1273018282618739
Validation loss: 2.332543567597501

Epoch: 5| Step: 4
Training loss: 1.7389143915848722
Validation loss: 2.2636814492551465

Epoch: 5| Step: 5
Training loss: 2.0284693538766363
Validation loss: 2.352438968348305

Epoch: 5| Step: 6
Training loss: 1.2586210033608263
Validation loss: 2.291824403258327

Epoch: 5| Step: 7
Training loss: 1.470379919275929
Validation loss: 2.400580340360179

Epoch: 5| Step: 8
Training loss: 1.547169358731347
Validation loss: 2.3483207275103055

Epoch: 5| Step: 9
Training loss: 1.5164205292034827
Validation loss: 2.322746990961097

Epoch: 5| Step: 10
Training loss: 1.6265080863359953
Validation loss: 2.3768563434175523

Epoch: 330| Step: 0
Training loss: 1.3292878389681955
Validation loss: 2.308432865125648

Epoch: 5| Step: 1
Training loss: 1.621801456261368
Validation loss: 2.330996845103947

Epoch: 5| Step: 2
Training loss: 1.4145752203834636
Validation loss: 2.3004470173776395

Epoch: 5| Step: 3
Training loss: 2.276412537923687
Validation loss: 2.303325471829761

Epoch: 5| Step: 4
Training loss: 1.667436858873363
Validation loss: 2.357994001940547

Epoch: 5| Step: 5
Training loss: 1.5046960911649128
Validation loss: 2.3426670484819474

Epoch: 5| Step: 6
Training loss: 1.7491892571495145
Validation loss: 2.3379540624099056

Epoch: 5| Step: 7
Training loss: 1.6949812745716932
Validation loss: 2.3653573688357774

Epoch: 5| Step: 8
Training loss: 1.4022897694008656
Validation loss: 2.347546706739869

Epoch: 5| Step: 9
Training loss: 1.3385925679108677
Validation loss: 2.349294146024918

Epoch: 5| Step: 10
Training loss: 1.5472677483624742
Validation loss: 2.2997601612097562

Epoch: 331| Step: 0
Training loss: 1.3225243905455777
Validation loss: 2.3290301700443266

Epoch: 5| Step: 1
Training loss: 1.4771264023772148
Validation loss: 2.380289714304562

Epoch: 5| Step: 2
Training loss: 1.3769058111191872
Validation loss: 2.355468977471015

Epoch: 5| Step: 3
Training loss: 1.2476950374873
Validation loss: 2.3630789450262677

Epoch: 5| Step: 4
Training loss: 1.557919463959181
Validation loss: 2.2823865876708

Epoch: 5| Step: 5
Training loss: 1.5451695452255172
Validation loss: 2.409670659346228

Epoch: 5| Step: 6
Training loss: 1.6893963225413062
Validation loss: 2.3813250308222385

Epoch: 5| Step: 7
Training loss: 1.872752686628605
Validation loss: 2.3206244431256517

Epoch: 5| Step: 8
Training loss: 1.889430149294358
Validation loss: 2.3473992140720057

Epoch: 5| Step: 9
Training loss: 1.5075829682047746
Validation loss: 2.3696899485988387

Epoch: 5| Step: 10
Training loss: 1.697901563830773
Validation loss: 2.356385974034844

Epoch: 332| Step: 0
Training loss: 2.397103898757922
Validation loss: 2.3481115720315833

Epoch: 5| Step: 1
Training loss: 1.3587365240500897
Validation loss: 2.275550145122223

Epoch: 5| Step: 2
Training loss: 1.2887358280442363
Validation loss: 2.310762865415008

Epoch: 5| Step: 3
Training loss: 1.2295007197877097
Validation loss: 2.307173516451571

Epoch: 5| Step: 4
Training loss: 1.6270390701948592
Validation loss: 2.3183487017986666

Epoch: 5| Step: 5
Training loss: 1.7104768873324154
Validation loss: 2.322595675025583

Epoch: 5| Step: 6
Training loss: 1.5373831169546253
Validation loss: 2.3531992524726535

Epoch: 5| Step: 7
Training loss: 1.4202810722541828
Validation loss: 2.365588055803599

Epoch: 5| Step: 8
Training loss: 1.5091194457753938
Validation loss: 2.319349025721772

Epoch: 5| Step: 9
Training loss: 1.055235430767141
Validation loss: 2.300945984537707

Epoch: 5| Step: 10
Training loss: 1.6806147655148482
Validation loss: 2.345905997888634

Epoch: 333| Step: 0
Training loss: 1.7546212622894917
Validation loss: 2.3859452978708995

Epoch: 5| Step: 1
Training loss: 1.519617544043097
Validation loss: 2.324073118654152

Epoch: 5| Step: 2
Training loss: 1.3544698767003764
Validation loss: 2.331205826071151

Epoch: 5| Step: 3
Training loss: 1.6170513445900998
Validation loss: 2.3139619676409513

Epoch: 5| Step: 4
Training loss: 1.9655246047928014
Validation loss: 2.417451652706573

Epoch: 5| Step: 5
Training loss: 1.1452464190020948
Validation loss: 2.3778558043136986

Epoch: 5| Step: 6
Training loss: 1.1633400435286048
Validation loss: 2.389060396173291

Epoch: 5| Step: 7
Training loss: 1.452938765210165
Validation loss: 2.3450353870012814

Epoch: 5| Step: 8
Training loss: 1.701748142676855
Validation loss: 2.411528445703881

Epoch: 5| Step: 9
Training loss: 1.4060247028861326
Validation loss: 2.3206206627701422

Epoch: 5| Step: 10
Training loss: 1.968808127862118
Validation loss: 2.414199464680319

Epoch: 334| Step: 0
Training loss: 1.2547065343873791
Validation loss: 2.3004338124197528

Epoch: 5| Step: 1
Training loss: 1.1932639725380754
Validation loss: 2.397316090147709

Epoch: 5| Step: 2
Training loss: 1.3256564367614356
Validation loss: 2.422865537961139

Epoch: 5| Step: 3
Training loss: 1.5815988208675669
Validation loss: 2.303629357206874

Epoch: 5| Step: 4
Training loss: 2.4947438298512354
Validation loss: 2.3089996531297188

Epoch: 5| Step: 5
Training loss: 0.9453208229392129
Validation loss: 2.338216518977747

Epoch: 5| Step: 6
Training loss: 1.6037822692193533
Validation loss: 2.346977513193567

Epoch: 5| Step: 7
Training loss: 1.7953893739661018
Validation loss: 2.3467948960092824

Epoch: 5| Step: 8
Training loss: 1.4664894726671596
Validation loss: 2.3167200464425863

Epoch: 5| Step: 9
Training loss: 1.5328472915107352
Validation loss: 2.3439790719043785

Epoch: 5| Step: 10
Training loss: 1.581816482094596
Validation loss: 2.34257826306536

Epoch: 335| Step: 0
Training loss: 1.4776954139536598
Validation loss: 2.4058472416551226

Epoch: 5| Step: 1
Training loss: 2.0386004746625046
Validation loss: 2.369617544378768

Epoch: 5| Step: 2
Training loss: 1.7313726746651832
Validation loss: 2.3345832681392786

Epoch: 5| Step: 3
Training loss: 0.9867115144320857
Validation loss: 2.3918879341410655

Epoch: 5| Step: 4
Training loss: 1.7825754822188427
Validation loss: 2.2903687341246433

Epoch: 5| Step: 5
Training loss: 1.9409609615914476
Validation loss: 2.3299808014098935

Epoch: 5| Step: 6
Training loss: 1.4534099668602796
Validation loss: 2.342287133470767

Epoch: 5| Step: 7
Training loss: 1.6725030592817716
Validation loss: 2.3135854290578783

Epoch: 5| Step: 8
Training loss: 1.4374601939121763
Validation loss: 2.3845071609454878

Epoch: 5| Step: 9
Training loss: 1.5244431526492483
Validation loss: 2.336559729008355

Epoch: 5| Step: 10
Training loss: 1.1734404725139977
Validation loss: 2.402316615640658

Epoch: 336| Step: 0
Training loss: 1.2327932532757735
Validation loss: 2.328502988003194

Epoch: 5| Step: 1
Training loss: 1.51006769116993
Validation loss: 2.2690904235181457

Epoch: 5| Step: 2
Training loss: 1.4765968924256028
Validation loss: 2.307304636915727

Epoch: 5| Step: 3
Training loss: 1.763493289122482
Validation loss: 2.26711280353522

Epoch: 5| Step: 4
Training loss: 1.5568574876386105
Validation loss: 2.329569027741884

Epoch: 5| Step: 5
Training loss: 1.511461102907924
Validation loss: 2.3763237649645172

Epoch: 5| Step: 6
Training loss: 1.8867934312907866
Validation loss: 2.366780791447779

Epoch: 5| Step: 7
Training loss: 1.351911113960322
Validation loss: 2.3438478182817386

Epoch: 5| Step: 8
Training loss: 2.182584416700291
Validation loss: 2.3576692085306634

Epoch: 5| Step: 9
Training loss: 1.4489927706909964
Validation loss: 2.309599023778522

Epoch: 5| Step: 10
Training loss: 1.4566994460554674
Validation loss: 2.360719859935425

Epoch: 337| Step: 0
Training loss: 1.32038915287498
Validation loss: 2.364777508286755

Epoch: 5| Step: 1
Training loss: 1.5215578661346856
Validation loss: 2.3742951781307333

Epoch: 5| Step: 2
Training loss: 1.4516723919714325
Validation loss: 2.427540459104187

Epoch: 5| Step: 3
Training loss: 2.122160978526492
Validation loss: 2.2611195020857666

Epoch: 5| Step: 4
Training loss: 1.5099034807797325
Validation loss: 2.361428800978365

Epoch: 5| Step: 5
Training loss: 1.2730091989518968
Validation loss: 2.361496516249685

Epoch: 5| Step: 6
Training loss: 1.5924672218913838
Validation loss: 2.3936812459566563

Epoch: 5| Step: 7
Training loss: 1.999694681704645
Validation loss: 2.332717935944637

Epoch: 5| Step: 8
Training loss: 1.6953786670060422
Validation loss: 2.3620194201058027

Epoch: 5| Step: 9
Training loss: 1.4303419772630517
Validation loss: 2.3430942835018342

Epoch: 5| Step: 10
Training loss: 1.440684067845378
Validation loss: 2.316320064972008

Epoch: 338| Step: 0
Training loss: 1.1213365883282906
Validation loss: 2.414424198116971

Epoch: 5| Step: 1
Training loss: 1.6689723120347513
Validation loss: 2.2770389545767618

Epoch: 5| Step: 2
Training loss: 1.3970253916776407
Validation loss: 2.2849780277981835

Epoch: 5| Step: 3
Training loss: 1.3630508184384138
Validation loss: 2.3219384848279208

Epoch: 5| Step: 4
Training loss: 2.038831675827104
Validation loss: 2.3206575182119176

Epoch: 5| Step: 5
Training loss: 1.2330246311335615
Validation loss: 2.413998392800841

Epoch: 5| Step: 6
Training loss: 1.1131415028449145
Validation loss: 2.354996764547874

Epoch: 5| Step: 7
Training loss: 1.3789360756390605
Validation loss: 2.357713399608133

Epoch: 5| Step: 8
Training loss: 1.3563220501584543
Validation loss: 2.3302156319960194

Epoch: 5| Step: 9
Training loss: 2.1361410137520287
Validation loss: 2.3576509244625323

Epoch: 5| Step: 10
Training loss: 1.8712111657240469
Validation loss: 2.3956871904810906

Epoch: 339| Step: 0
Training loss: 1.3909395269389009
Validation loss: 2.3358901916228385

Epoch: 5| Step: 1
Training loss: 2.152198301963679
Validation loss: 2.3310170957147864

Epoch: 5| Step: 2
Training loss: 1.373832206730857
Validation loss: 2.2804270288277215

Epoch: 5| Step: 3
Training loss: 1.6740674055923783
Validation loss: 2.3706868010617006

Epoch: 5| Step: 4
Training loss: 1.2354659076588987
Validation loss: 2.299878242305214

Epoch: 5| Step: 5
Training loss: 2.1244153733217432
Validation loss: 2.327541533399253

Epoch: 5| Step: 6
Training loss: 1.2334897693879314
Validation loss: 2.3672013579008007

Epoch: 5| Step: 7
Training loss: 1.1877514924216845
Validation loss: 2.3273747285388033

Epoch: 5| Step: 8
Training loss: 1.2794964117854772
Validation loss: 2.3767161146550038

Epoch: 5| Step: 9
Training loss: 1.3974651173996275
Validation loss: 2.3247333825823553

Epoch: 5| Step: 10
Training loss: 1.110878905563211
Validation loss: 2.374820877341071

Epoch: 340| Step: 0
Training loss: 1.3472674707415009
Validation loss: 2.3096243869979696

Epoch: 5| Step: 1
Training loss: 1.3765251630900381
Validation loss: 2.349587374112387

Epoch: 5| Step: 2
Training loss: 1.9596654405965839
Validation loss: 2.3166116591826973

Epoch: 5| Step: 3
Training loss: 1.4488014792642778
Validation loss: 2.3209574404441864

Epoch: 5| Step: 4
Training loss: 1.2929498492470026
Validation loss: 2.2818509921585965

Epoch: 5| Step: 5
Training loss: 1.2108174910606162
Validation loss: 2.3075338805166052

Epoch: 5| Step: 6
Training loss: 1.7104110256137668
Validation loss: 2.3471446998269627

Epoch: 5| Step: 7
Training loss: 2.2868256038596955
Validation loss: 2.3620279900902674

Epoch: 5| Step: 8
Training loss: 1.528030592297587
Validation loss: 2.3689816379324378

Epoch: 5| Step: 9
Training loss: 1.423763906864774
Validation loss: 2.2909708926403525

Epoch: 5| Step: 10
Training loss: 1.4686996775995278
Validation loss: 2.2814072843961495

Epoch: 341| Step: 0
Training loss: 1.5208981992222428
Validation loss: 2.3410356277048177

Epoch: 5| Step: 1
Training loss: 1.2240092922992405
Validation loss: 2.3583202844642335

Epoch: 5| Step: 2
Training loss: 1.6807846389598748
Validation loss: 2.30796485442582

Epoch: 5| Step: 3
Training loss: 1.4580799245918594
Validation loss: 2.3792486233537873

Epoch: 5| Step: 4
Training loss: 1.9344913749630726
Validation loss: 2.3059234736586887

Epoch: 5| Step: 5
Training loss: 1.7086695441034394
Validation loss: 2.3308488562223713

Epoch: 5| Step: 6
Training loss: 1.322285549177114
Validation loss: 2.2937274478540117

Epoch: 5| Step: 7
Training loss: 1.4033694540722723
Validation loss: 2.35982511904842

Epoch: 5| Step: 8
Training loss: 1.8161029521436922
Validation loss: 2.2647891937514966

Epoch: 5| Step: 9
Training loss: 1.6592643226739914
Validation loss: 2.3127087180442123

Epoch: 5| Step: 10
Training loss: 1.5221444144090437
Validation loss: 2.311989756495654

Epoch: 342| Step: 0
Training loss: 1.9240054595853944
Validation loss: 2.303824679360476

Epoch: 5| Step: 1
Training loss: 1.6702850482279916
Validation loss: 2.353123428167055

Epoch: 5| Step: 2
Training loss: 1.6190269439509826
Validation loss: 2.296503875396612

Epoch: 5| Step: 3
Training loss: 1.7040782675476207
Validation loss: 2.3598365557693755

Epoch: 5| Step: 4
Training loss: 1.5650277862275892
Validation loss: 2.318570031291988

Epoch: 5| Step: 5
Training loss: 1.2390049886164325
Validation loss: 2.3130995093327527

Epoch: 5| Step: 6
Training loss: 1.4587286095574985
Validation loss: 2.377965320519712

Epoch: 5| Step: 7
Training loss: 1.3542293191745807
Validation loss: 2.327970647337248

Epoch: 5| Step: 8
Training loss: 1.67173738002335
Validation loss: 2.3145141100616526

Epoch: 5| Step: 9
Training loss: 1.1611943593569216
Validation loss: 2.390662603520214

Epoch: 5| Step: 10
Training loss: 1.6893870787306935
Validation loss: 2.360462007044671

Epoch: 343| Step: 0
Training loss: 1.3207714479471466
Validation loss: 2.2735479911778573

Epoch: 5| Step: 1
Training loss: 1.3524978135632455
Validation loss: 2.3040648478409396

Epoch: 5| Step: 2
Training loss: 1.3719143924836017
Validation loss: 2.337370826714715

Epoch: 5| Step: 3
Training loss: 1.9182698621393992
Validation loss: 2.337544448927411

Epoch: 5| Step: 4
Training loss: 1.3486519935785233
Validation loss: 2.3393242585763043

Epoch: 5| Step: 5
Training loss: 1.4281619745388823
Validation loss: 2.3258524785708596

Epoch: 5| Step: 6
Training loss: 1.7063415670452717
Validation loss: 2.3447119255846105

Epoch: 5| Step: 7
Training loss: 1.2191351746520118
Validation loss: 2.335216294413137

Epoch: 5| Step: 8
Training loss: 1.4760306879073644
Validation loss: 2.3097758789820495

Epoch: 5| Step: 9
Training loss: 1.6892084021635523
Validation loss: 2.328760095019079

Epoch: 5| Step: 10
Training loss: 1.8507981151039448
Validation loss: 2.3658116247448415

Epoch: 344| Step: 0
Training loss: 2.0059903556158316
Validation loss: 2.324887447343147

Epoch: 5| Step: 1
Training loss: 1.4970396552583012
Validation loss: 2.2772355808278983

Epoch: 5| Step: 2
Training loss: 1.446458351999325
Validation loss: 2.2275465777644423

Epoch: 5| Step: 3
Training loss: 1.5267997221594927
Validation loss: 2.381262921079789

Epoch: 5| Step: 4
Training loss: 1.2471261844650414
Validation loss: 2.3115317311084356

Epoch: 5| Step: 5
Training loss: 1.9143578126380527
Validation loss: 2.260974635027813

Epoch: 5| Step: 6
Training loss: 1.5576626475047146
Validation loss: 2.3484037753439977

Epoch: 5| Step: 7
Training loss: 1.6553443735952593
Validation loss: 2.3718110421850045

Epoch: 5| Step: 8
Training loss: 1.4189833696989038
Validation loss: 2.3139730338830136

Epoch: 5| Step: 9
Training loss: 1.2321787744029815
Validation loss: 2.331597115853722

Epoch: 5| Step: 10
Training loss: 1.439552666005779
Validation loss: 2.3666467467629073

Epoch: 345| Step: 0
Training loss: 1.3628411662081255
Validation loss: 2.313078790971674

Epoch: 5| Step: 1
Training loss: 1.2012942368125503
Validation loss: 2.2620286232818745

Epoch: 5| Step: 2
Training loss: 1.8084364095512862
Validation loss: 2.349445166421275

Epoch: 5| Step: 3
Training loss: 1.5881362481077343
Validation loss: 2.3847334240116753

Epoch: 5| Step: 4
Training loss: 1.2328720117088163
Validation loss: 2.309335709910236

Epoch: 5| Step: 5
Training loss: 1.6702932558298202
Validation loss: 2.3340294977968967

Epoch: 5| Step: 6
Training loss: 1.2299424271949368
Validation loss: 2.302220205494797

Epoch: 5| Step: 7
Training loss: 1.4383190972665014
Validation loss: 2.3727210865716684

Epoch: 5| Step: 8
Training loss: 1.3499189317168796
Validation loss: 2.312574709101476

Epoch: 5| Step: 9
Training loss: 1.2871916170140065
Validation loss: 2.285619361240552

Epoch: 5| Step: 10
Training loss: 2.2922329867581688
Validation loss: 2.3498196038008694

Epoch: 346| Step: 0
Training loss: 1.1943172225671128
Validation loss: 2.276721815457663

Epoch: 5| Step: 1
Training loss: 1.45649230643852
Validation loss: 2.4139662419205132

Epoch: 5| Step: 2
Training loss: 1.7929499340524477
Validation loss: 2.3071026033055735

Epoch: 5| Step: 3
Training loss: 1.273415547749222
Validation loss: 2.336227339198242

Epoch: 5| Step: 4
Training loss: 1.753780233023342
Validation loss: 2.315944904931448

Epoch: 5| Step: 5
Training loss: 1.4088089019592704
Validation loss: 2.3299883812541564

Epoch: 5| Step: 6
Training loss: 1.082979523518892
Validation loss: 2.392993551238393

Epoch: 5| Step: 7
Training loss: 1.4616470653708697
Validation loss: 2.328874484854154

Epoch: 5| Step: 8
Training loss: 1.3458115488342288
Validation loss: 2.3001249278980427

Epoch: 5| Step: 9
Training loss: 1.3645545238142425
Validation loss: 2.2785458683054607

Epoch: 5| Step: 10
Training loss: 2.0643708962455425
Validation loss: 2.309720998888146

Epoch: 347| Step: 0
Training loss: 1.4104545890559546
Validation loss: 2.368276306611399

Epoch: 5| Step: 1
Training loss: 1.7132550572847132
Validation loss: 2.236551653763047

Epoch: 5| Step: 2
Training loss: 1.301027337701149
Validation loss: 2.3504438065850293

Epoch: 5| Step: 3
Training loss: 1.3590606676809907
Validation loss: 2.437451773629969

Epoch: 5| Step: 4
Training loss: 1.1915903918435642
Validation loss: 2.3165188063241464

Epoch: 5| Step: 5
Training loss: 1.444357396624731
Validation loss: 2.3284878065084125

Epoch: 5| Step: 6
Training loss: 1.6601330564786103
Validation loss: 2.2562777675255874

Epoch: 5| Step: 7
Training loss: 1.2108067103480693
Validation loss: 2.324655207176062

Epoch: 5| Step: 8
Training loss: 1.6925679153497177
Validation loss: 2.3647312891220533

Epoch: 5| Step: 9
Training loss: 1.300840542561709
Validation loss: 2.3093483702434043

Epoch: 5| Step: 10
Training loss: 2.1698573778457537
Validation loss: 2.411405804949526

Epoch: 348| Step: 0
Training loss: 1.5036260963186685
Validation loss: 2.3093796563826245

Epoch: 5| Step: 1
Training loss: 1.1392966596211727
Validation loss: 2.349083673758203

Epoch: 5| Step: 2
Training loss: 1.44900889560978
Validation loss: 2.3507727892488703

Epoch: 5| Step: 3
Training loss: 2.2416011030212126
Validation loss: 2.337729086603018

Epoch: 5| Step: 4
Training loss: 1.3837877702942538
Validation loss: 2.3023376921963745

Epoch: 5| Step: 5
Training loss: 1.366950227039198
Validation loss: 2.3216546642822213

Epoch: 5| Step: 6
Training loss: 1.3277271347993238
Validation loss: 2.2873189831550684

Epoch: 5| Step: 7
Training loss: 1.3917520649152717
Validation loss: 2.356650409376402

Epoch: 5| Step: 8
Training loss: 1.1192649253001732
Validation loss: 2.375303927945822

Epoch: 5| Step: 9
Training loss: 1.345590307104759
Validation loss: 2.3128330691489363

Epoch: 5| Step: 10
Training loss: 2.017939222284453
Validation loss: 2.335966996188373

Epoch: 349| Step: 0
Training loss: 1.1709199192345017
Validation loss: 2.3680720986432258

Epoch: 5| Step: 1
Training loss: 1.5732251384812943
Validation loss: 2.33228923104237

Epoch: 5| Step: 2
Training loss: 1.4668552270246578
Validation loss: 2.351891456984993

Epoch: 5| Step: 3
Training loss: 1.7040415406245448
Validation loss: 2.295152127547833

Epoch: 5| Step: 4
Training loss: 1.2013417689810162
Validation loss: 2.370435909816178

Epoch: 5| Step: 5
Training loss: 1.7952668664775018
Validation loss: 2.2303993497764965

Epoch: 5| Step: 6
Training loss: 1.3246357579080146
Validation loss: 2.2715806351400576

Epoch: 5| Step: 7
Training loss: 1.8807314693578039
Validation loss: 2.315592752190355

Epoch: 5| Step: 8
Training loss: 1.5208732739085484
Validation loss: 2.3194324068258108

Epoch: 5| Step: 9
Training loss: 1.3095000359825428
Validation loss: 2.3108711126475994

Epoch: 5| Step: 10
Training loss: 1.074054330900734
Validation loss: 2.300366496797809

Epoch: 350| Step: 0
Training loss: 1.9049997450860923
Validation loss: 2.3285482505981654

Epoch: 5| Step: 1
Training loss: 1.484210035292689
Validation loss: 2.272655315150316

Epoch: 5| Step: 2
Training loss: 1.1417575073763822
Validation loss: 2.325296444870718

Epoch: 5| Step: 3
Training loss: 1.5103269177661678
Validation loss: 2.3356911920394556

Epoch: 5| Step: 4
Training loss: 1.588680357168237
Validation loss: 2.303192377851779

Epoch: 5| Step: 5
Training loss: 1.6086225509844267
Validation loss: 2.3631106871133154

Epoch: 5| Step: 6
Training loss: 1.3185153445065934
Validation loss: 2.325278381431362

Epoch: 5| Step: 7
Training loss: 1.7371195479537547
Validation loss: 2.388700229007381

Epoch: 5| Step: 8
Training loss: 0.9799310189901456
Validation loss: 2.295234101297692

Epoch: 5| Step: 9
Training loss: 1.4517271640374858
Validation loss: 2.2851019633488217

Epoch: 5| Step: 10
Training loss: 1.716890820741753
Validation loss: 2.3208983500606735

Epoch: 351| Step: 0
Training loss: 1.5785731821722389
Validation loss: 2.295137671538057

Epoch: 5| Step: 1
Training loss: 1.0498984219599632
Validation loss: 2.30803675185793

Epoch: 5| Step: 2
Training loss: 1.0348592080078138
Validation loss: 2.3595064122943854

Epoch: 5| Step: 3
Training loss: 1.5445940559672928
Validation loss: 2.310757397004626

Epoch: 5| Step: 4
Training loss: 1.9429136138811316
Validation loss: 2.436530629081913

Epoch: 5| Step: 5
Training loss: 1.3981747087314123
Validation loss: 2.309520361617137

Epoch: 5| Step: 6
Training loss: 1.8278817561114151
Validation loss: 2.3564270880192777

Epoch: 5| Step: 7
Training loss: 1.228025499346279
Validation loss: 2.3414972812524626

Epoch: 5| Step: 8
Training loss: 1.780680247420824
Validation loss: 2.3331843964409265

Epoch: 5| Step: 9
Training loss: 1.670724205328269
Validation loss: 2.356462634955042

Epoch: 5| Step: 10
Training loss: 1.1720817383557445
Validation loss: 2.2950194509791277

Epoch: 352| Step: 0
Training loss: 1.5705607203829823
Validation loss: 2.3240183528005827

Epoch: 5| Step: 1
Training loss: 1.0428870236955223
Validation loss: 2.3688271217563477

Epoch: 5| Step: 2
Training loss: 1.1125112983044174
Validation loss: 2.3349657662231174

Epoch: 5| Step: 3
Training loss: 1.497561300229866
Validation loss: 2.3414260992342686

Epoch: 5| Step: 4
Training loss: 1.5018045379200275
Validation loss: 2.3448185148327623

Epoch: 5| Step: 5
Training loss: 2.0111139962519307
Validation loss: 2.403210229995923

Epoch: 5| Step: 6
Training loss: 1.2743700041773571
Validation loss: 2.3154633649165706

Epoch: 5| Step: 7
Training loss: 1.8029889457054864
Validation loss: 2.3216260822180166

Epoch: 5| Step: 8
Training loss: 1.338812918088333
Validation loss: 2.351585297860188

Epoch: 5| Step: 9
Training loss: 1.7616526386180054
Validation loss: 2.3170067889026886

Epoch: 5| Step: 10
Training loss: 1.2397998919839408
Validation loss: 2.2869639201500065

Epoch: 353| Step: 0
Training loss: 1.5555872781485918
Validation loss: 2.347227261191536

Epoch: 5| Step: 1
Training loss: 1.4178886285850094
Validation loss: 2.231426338256406

Epoch: 5| Step: 2
Training loss: 1.2430451029806313
Validation loss: 2.3129252879978015

Epoch: 5| Step: 3
Training loss: 1.1137280019520714
Validation loss: 2.3424666341383005

Epoch: 5| Step: 4
Training loss: 1.0070462529830881
Validation loss: 2.3006508024166656

Epoch: 5| Step: 5
Training loss: 1.51075149858758
Validation loss: 2.3202759252434477

Epoch: 5| Step: 6
Training loss: 1.8641904136340022
Validation loss: 2.3305774755996573

Epoch: 5| Step: 7
Training loss: 2.2154559545768273
Validation loss: 2.3227926041159073

Epoch: 5| Step: 8
Training loss: 1.259016609785276
Validation loss: 2.3964004323385453

Epoch: 5| Step: 9
Training loss: 1.5407582347277815
Validation loss: 2.3108712757268632

Epoch: 5| Step: 10
Training loss: 0.8681425042581344
Validation loss: 2.293180816705537

Epoch: 354| Step: 0
Training loss: 0.9667204855593018
Validation loss: 2.3247552525663786

Epoch: 5| Step: 1
Training loss: 1.3734557843862771
Validation loss: 2.3800331069713145

Epoch: 5| Step: 2
Training loss: 1.6332855269513742
Validation loss: 2.3919808461556955

Epoch: 5| Step: 3
Training loss: 1.96381122010473
Validation loss: 2.333399664760778

Epoch: 5| Step: 4
Training loss: 1.436198931152133
Validation loss: 2.308899747243426

Epoch: 5| Step: 5
Training loss: 1.709712874862746
Validation loss: 2.313713699757829

Epoch: 5| Step: 6
Training loss: 1.6717078579930125
Validation loss: 2.3494163315702616

Epoch: 5| Step: 7
Training loss: 0.8971220586674566
Validation loss: 2.291556519763347

Epoch: 5| Step: 8
Training loss: 1.5414789274534242
Validation loss: 2.303760460166866

Epoch: 5| Step: 9
Training loss: 1.423404667263143
Validation loss: 2.3189998833587744

Epoch: 5| Step: 10
Training loss: 1.2914947220993156
Validation loss: 2.2950231528641862

Epoch: 355| Step: 0
Training loss: 1.637113391577295
Validation loss: 2.398226085560306

Epoch: 5| Step: 1
Training loss: 1.144513074711036
Validation loss: 2.343918204339063

Epoch: 5| Step: 2
Training loss: 1.5621155838152587
Validation loss: 2.3064623178528647

Epoch: 5| Step: 3
Training loss: 2.296178803064363
Validation loss: 2.3335219019915985

Epoch: 5| Step: 4
Training loss: 1.187646455266427
Validation loss: 2.285903136328338

Epoch: 5| Step: 5
Training loss: 1.2711984339245272
Validation loss: 2.318309024914008

Epoch: 5| Step: 6
Training loss: 1.4347453052838108
Validation loss: 2.2647254331952476

Epoch: 5| Step: 7
Training loss: 1.2616813347054947
Validation loss: 2.387503458695005

Epoch: 5| Step: 8
Training loss: 1.5913993104943507
Validation loss: 2.27362199288523

Epoch: 5| Step: 9
Training loss: 1.8343999389824772
Validation loss: 2.277657644202046

Epoch: 5| Step: 10
Training loss: 0.9254612429956967
Validation loss: 2.3617822316014085

Epoch: 356| Step: 0
Training loss: 1.4028210690976584
Validation loss: 2.3722742087175934

Epoch: 5| Step: 1
Training loss: 1.4023735872032557
Validation loss: 2.2851159454625316

Epoch: 5| Step: 2
Training loss: 1.2705240915649767
Validation loss: 2.3203739840232007

Epoch: 5| Step: 3
Training loss: 1.9765189546756536
Validation loss: 2.3265621965806287

Epoch: 5| Step: 4
Training loss: 1.2297785685261398
Validation loss: 2.3033533293662796

Epoch: 5| Step: 5
Training loss: 1.2041827914644414
Validation loss: 2.271755690676958

Epoch: 5| Step: 6
Training loss: 1.5530544886711135
Validation loss: 2.3115846944903184

Epoch: 5| Step: 7
Training loss: 1.3685485168988636
Validation loss: 2.2996356015140895

Epoch: 5| Step: 8
Training loss: 1.5845385615627106
Validation loss: 2.365528305101221

Epoch: 5| Step: 9
Training loss: 1.129824835527036
Validation loss: 2.320371746722306

Epoch: 5| Step: 10
Training loss: 1.8361048845322463
Validation loss: 2.3026283794537825

Epoch: 357| Step: 0
Training loss: 1.5257733557243456
Validation loss: 2.3074342150343194

Epoch: 5| Step: 1
Training loss: 2.1322653491308263
Validation loss: 2.4221446797155837

Epoch: 5| Step: 2
Training loss: 1.5240172236813443
Validation loss: 2.2789943206150762

Epoch: 5| Step: 3
Training loss: 1.4745426794467944
Validation loss: 2.338199124391045

Epoch: 5| Step: 4
Training loss: 1.639022335000389
Validation loss: 2.3343175630245927

Epoch: 5| Step: 5
Training loss: 1.1736946220456097
Validation loss: 2.303551147251372

Epoch: 5| Step: 6
Training loss: 1.2622976953052223
Validation loss: 2.2801045469358154

Epoch: 5| Step: 7
Training loss: 1.4665024788305883
Validation loss: 2.319474428386831

Epoch: 5| Step: 8
Training loss: 1.41937077254989
Validation loss: 2.395912116326128

Epoch: 5| Step: 9
Training loss: 0.9947526468077347
Validation loss: 2.300794190838512

Epoch: 5| Step: 10
Training loss: 1.3966821490471335
Validation loss: 2.288960248318168

Epoch: 358| Step: 0
Training loss: 1.0563711221082326
Validation loss: 2.2941975181622114

Epoch: 5| Step: 1
Training loss: 1.6124929206160457
Validation loss: 2.4137591253576858

Epoch: 5| Step: 2
Training loss: 1.3882504023450546
Validation loss: 2.3166084499426147

Epoch: 5| Step: 3
Training loss: 1.14105143479438
Validation loss: 2.390921849144688

Epoch: 5| Step: 4
Training loss: 1.5872477113193841
Validation loss: 2.324338253840897

Epoch: 5| Step: 5
Training loss: 2.204696527647789
Validation loss: 2.297492792397461

Epoch: 5| Step: 6
Training loss: 1.7270510573490732
Validation loss: 2.3367713106526766

Epoch: 5| Step: 7
Training loss: 1.0696583997605706
Validation loss: 2.361492691677762

Epoch: 5| Step: 8
Training loss: 1.4332732380237918
Validation loss: 2.2935382317307718

Epoch: 5| Step: 9
Training loss: 1.5247946147505378
Validation loss: 2.275287211310632

Epoch: 5| Step: 10
Training loss: 1.3723641620530822
Validation loss: 2.3357503230700596

Epoch: 359| Step: 0
Training loss: 1.6498365928190466
Validation loss: 2.296770150494874

Epoch: 5| Step: 1
Training loss: 0.949168859355918
Validation loss: 2.3528937374812324

Epoch: 5| Step: 2
Training loss: 1.332720267893538
Validation loss: 2.300501077596269

Epoch: 5| Step: 3
Training loss: 2.04944641268068
Validation loss: 2.3739003429775813

Epoch: 5| Step: 4
Training loss: 1.659322515832245
Validation loss: 2.312706731609018

Epoch: 5| Step: 5
Training loss: 1.637375074091152
Validation loss: 2.322517457467676

Epoch: 5| Step: 6
Training loss: 1.3758543134846088
Validation loss: 2.3323766505798877

Epoch: 5| Step: 7
Training loss: 1.144825035120305
Validation loss: 2.310506009227367

Epoch: 5| Step: 8
Training loss: 0.8801744255140972
Validation loss: 2.349423006866205

Epoch: 5| Step: 9
Training loss: 1.6799717152575968
Validation loss: 2.354061199123125

Epoch: 5| Step: 10
Training loss: 1.266449600786183
Validation loss: 2.333885931320293

Epoch: 360| Step: 0
Training loss: 1.4953214479694887
Validation loss: 2.345615266566099

Epoch: 5| Step: 1
Training loss: 1.272818526102248
Validation loss: 2.335049265157151

Epoch: 5| Step: 2
Training loss: 1.2538239163852158
Validation loss: 2.3084182585106388

Epoch: 5| Step: 3
Training loss: 1.729559528196505
Validation loss: 2.3114955974644102

Epoch: 5| Step: 4
Training loss: 1.52101294445421
Validation loss: 2.343037015147215

Epoch: 5| Step: 5
Training loss: 1.0963419583593061
Validation loss: 2.3175363802934643

Epoch: 5| Step: 6
Training loss: 1.6882826791428038
Validation loss: 2.3656387051926195

Epoch: 5| Step: 7
Training loss: 1.134176288361183
Validation loss: 2.297957422499741

Epoch: 5| Step: 8
Training loss: 1.0662308433394956
Validation loss: 2.3106729162414856

Epoch: 5| Step: 9
Training loss: 1.67668792454545
Validation loss: 2.3245628553751487

Epoch: 5| Step: 10
Training loss: 1.9698948029445553
Validation loss: 2.272890650525299

Epoch: 361| Step: 0
Training loss: 1.57424843431225
Validation loss: 2.341022050761182

Epoch: 5| Step: 1
Training loss: 1.4538303427172214
Validation loss: 2.325988798144679

Epoch: 5| Step: 2
Training loss: 1.2138529475167865
Validation loss: 2.3186348641538914

Epoch: 5| Step: 3
Training loss: 1.5921181945391776
Validation loss: 2.364794809818467

Epoch: 5| Step: 4
Training loss: 1.3336400136314381
Validation loss: 2.3453821593115105

Epoch: 5| Step: 5
Training loss: 1.5313458315386743
Validation loss: 2.327807688721792

Epoch: 5| Step: 6
Training loss: 1.683539369771409
Validation loss: 2.2803175432688336

Epoch: 5| Step: 7
Training loss: 1.2882962810687422
Validation loss: 2.3923651833249076

Epoch: 5| Step: 8
Training loss: 1.1055596519811788
Validation loss: 2.355909538897638

Epoch: 5| Step: 9
Training loss: 1.9515998684044333
Validation loss: 2.3387266945918186

Epoch: 5| Step: 10
Training loss: 1.1260092764450296
Validation loss: 2.382965325064718

Epoch: 362| Step: 0
Training loss: 1.247439862179714
Validation loss: 2.3386933751894157

Epoch: 5| Step: 1
Training loss: 1.5596967346125918
Validation loss: 2.357974089558899

Epoch: 5| Step: 2
Training loss: 1.2426479613781847
Validation loss: 2.3426904330100036

Epoch: 5| Step: 3
Training loss: 0.9824671649542113
Validation loss: 2.307860039978886

Epoch: 5| Step: 4
Training loss: 1.6647341809853802
Validation loss: 2.318276727178073

Epoch: 5| Step: 5
Training loss: 1.226047383405548
Validation loss: 2.326349286390405

Epoch: 5| Step: 6
Training loss: 1.3237731543975308
Validation loss: 2.3227281629604115

Epoch: 5| Step: 7
Training loss: 2.2406587606145107
Validation loss: 2.382635373115754

Epoch: 5| Step: 8
Training loss: 1.465539385607013
Validation loss: 2.3334448955457163

Epoch: 5| Step: 9
Training loss: 1.2209477293993445
Validation loss: 2.330417130445227

Epoch: 5| Step: 10
Training loss: 1.4502285218209334
Validation loss: 2.306679877151721

Epoch: 363| Step: 0
Training loss: 1.4619500226507873
Validation loss: 2.322611470652415

Epoch: 5| Step: 1
Training loss: 1.7705545392948028
Validation loss: 2.3081389581424467

Epoch: 5| Step: 2
Training loss: 1.1715613390453057
Validation loss: 2.3405711645540257

Epoch: 5| Step: 3
Training loss: 1.207148870274198
Validation loss: 2.305785070563571

Epoch: 5| Step: 4
Training loss: 1.2693722669383256
Validation loss: 2.338306271453725

Epoch: 5| Step: 5
Training loss: 1.5806614349618668
Validation loss: 2.3488675333615268

Epoch: 5| Step: 6
Training loss: 1.3264146450575585
Validation loss: 2.349058414640283

Epoch: 5| Step: 7
Training loss: 1.2053849928529798
Validation loss: 2.2503553415266344

Epoch: 5| Step: 8
Training loss: 2.217223918634514
Validation loss: 2.333367378965062

Epoch: 5| Step: 9
Training loss: 1.2170739509005828
Validation loss: 2.2695381523514357

Epoch: 5| Step: 10
Training loss: 1.2470197913825556
Validation loss: 2.2918539677331924

Epoch: 364| Step: 0
Training loss: 1.2765792285285353
Validation loss: 2.333444853796993

Epoch: 5| Step: 1
Training loss: 1.1607581224652355
Validation loss: 2.322012718571653

Epoch: 5| Step: 2
Training loss: 2.1462988734248873
Validation loss: 2.336517629053457

Epoch: 5| Step: 3
Training loss: 1.2940180459363475
Validation loss: 2.3872261671392607

Epoch: 5| Step: 4
Training loss: 1.6011557457942807
Validation loss: 2.3370304873918153

Epoch: 5| Step: 5
Training loss: 1.3946294669818038
Validation loss: 2.3305674309068047

Epoch: 5| Step: 6
Training loss: 1.5731301910108626
Validation loss: 2.306731650515735

Epoch: 5| Step: 7
Training loss: 1.0321703185436713
Validation loss: 2.362100279103096

Epoch: 5| Step: 8
Training loss: 1.3212393492645622
Validation loss: 2.31778077061551

Epoch: 5| Step: 9
Training loss: 1.6157709819429444
Validation loss: 2.279188733846016

Epoch: 5| Step: 10
Training loss: 0.9836915686387673
Validation loss: 2.3645675479401227

Epoch: 365| Step: 0
Training loss: 1.541702330236931
Validation loss: 2.2444739211905858

Epoch: 5| Step: 1
Training loss: 1.4047893567862773
Validation loss: 2.3001213735448833

Epoch: 5| Step: 2
Training loss: 1.9387455904902493
Validation loss: 2.351538485259047

Epoch: 5| Step: 3
Training loss: 1.3699763600196297
Validation loss: 2.3532194525558343

Epoch: 5| Step: 4
Training loss: 1.608712587788525
Validation loss: 2.333708139353873

Epoch: 5| Step: 5
Training loss: 1.3374625976181411
Validation loss: 2.281003171969003

Epoch: 5| Step: 6
Training loss: 1.1387121281780046
Validation loss: 2.3240954807538357

Epoch: 5| Step: 7
Training loss: 1.2975165836839997
Validation loss: 2.295333043366739

Epoch: 5| Step: 8
Training loss: 1.2447292785758555
Validation loss: 2.399422518154469

Epoch: 5| Step: 9
Training loss: 1.8171577457737433
Validation loss: 2.3098510768557383

Epoch: 5| Step: 10
Training loss: 1.1155975872700323
Validation loss: 2.2744319809763756

Epoch: 366| Step: 0
Training loss: 1.3988948905157237
Validation loss: 2.281281388297634

Epoch: 5| Step: 1
Training loss: 1.1805452171820447
Validation loss: 2.397500283687163

Epoch: 5| Step: 2
Training loss: 1.3856852804036022
Validation loss: 2.373308323010223

Epoch: 5| Step: 3
Training loss: 1.5534678520164282
Validation loss: 2.3577729373510534

Epoch: 5| Step: 4
Training loss: 1.3171070621858678
Validation loss: 2.3800067340083073

Epoch: 5| Step: 5
Training loss: 1.4813765910333774
Validation loss: 2.307361542188478

Epoch: 5| Step: 6
Training loss: 1.9607498869491597
Validation loss: 2.321981501626191

Epoch: 5| Step: 7
Training loss: 1.280780101299527
Validation loss: 2.4082534503075483

Epoch: 5| Step: 8
Training loss: 1.1870077016206193
Validation loss: 2.299572908598793

Epoch: 5| Step: 9
Training loss: 1.0615592606579012
Validation loss: 2.3434083510474393

Epoch: 5| Step: 10
Training loss: 2.285478931043641
Validation loss: 2.370266400943862

Epoch: 367| Step: 0
Training loss: 1.2034587149581424
Validation loss: 2.378449402113264

Epoch: 5| Step: 1
Training loss: 1.1375814094336234
Validation loss: 2.2932069615609354

Epoch: 5| Step: 2
Training loss: 1.5116377619062131
Validation loss: 2.312549620464324

Epoch: 5| Step: 3
Training loss: 1.277506640019489
Validation loss: 2.3251168075154665

Epoch: 5| Step: 4
Training loss: 1.20377431415154
Validation loss: 2.346899873378786

Epoch: 5| Step: 5
Training loss: 1.907800450392403
Validation loss: 2.328391047338419

Epoch: 5| Step: 6
Training loss: 1.6206238582679149
Validation loss: 2.3451442025467606

Epoch: 5| Step: 7
Training loss: 1.1303559073628893
Validation loss: 2.3549860870273966

Epoch: 5| Step: 8
Training loss: 1.1784326814337
Validation loss: 2.294183997032119

Epoch: 5| Step: 9
Training loss: 2.1100745277440502
Validation loss: 2.3280595669880517

Epoch: 5| Step: 10
Training loss: 1.2804051847198585
Validation loss: 2.313801928031816

Epoch: 368| Step: 0
Training loss: 1.116946481168793
Validation loss: 2.3874642242584265

Epoch: 5| Step: 1
Training loss: 1.169528697692084
Validation loss: 2.3157955478915424

Epoch: 5| Step: 2
Training loss: 1.5582200752076554
Validation loss: 2.350523150756985

Epoch: 5| Step: 3
Training loss: 1.3568473203727132
Validation loss: 2.417228081541086

Epoch: 5| Step: 4
Training loss: 1.4170633583414523
Validation loss: 2.294615459455851

Epoch: 5| Step: 5
Training loss: 1.4610722933513338
Validation loss: 2.283964826641139

Epoch: 5| Step: 6
Training loss: 1.1051404485728398
Validation loss: 2.3343809547660808

Epoch: 5| Step: 7
Training loss: 2.1207003008995287
Validation loss: 2.4042475422342604

Epoch: 5| Step: 8
Training loss: 1.5338034845429733
Validation loss: 2.3295147592133754

Epoch: 5| Step: 9
Training loss: 1.3234430252194056
Validation loss: 2.3658845490752083

Epoch: 5| Step: 10
Training loss: 1.3915006902174174
Validation loss: 2.364595935118109

Epoch: 369| Step: 0
Training loss: 1.376030362487303
Validation loss: 2.3281015429485383

Epoch: 5| Step: 1
Training loss: 1.6898631044955756
Validation loss: 2.314932994733505

Epoch: 5| Step: 2
Training loss: 1.3616433346514722
Validation loss: 2.2575379556820545

Epoch: 5| Step: 3
Training loss: 1.9955612636940947
Validation loss: 2.288846503943223

Epoch: 5| Step: 4
Training loss: 1.3276954404998154
Validation loss: 2.360819564986581

Epoch: 5| Step: 5
Training loss: 1.3112633192260497
Validation loss: 2.3457980225761315

Epoch: 5| Step: 6
Training loss: 1.3416878601832871
Validation loss: 2.2391182609518783

Epoch: 5| Step: 7
Training loss: 1.2725667023929177
Validation loss: 2.3285561747509385

Epoch: 5| Step: 8
Training loss: 1.1066873795704295
Validation loss: 2.2914883683128475

Epoch: 5| Step: 9
Training loss: 0.8608000297665148
Validation loss: 2.2969499265643565

Epoch: 5| Step: 10
Training loss: 1.2950579771665505
Validation loss: 2.335745919630264

Epoch: 370| Step: 0
Training loss: 0.9014985721341978
Validation loss: 2.357453496426454

Epoch: 5| Step: 1
Training loss: 2.0875319198634963
Validation loss: 2.3100526181696

Epoch: 5| Step: 2
Training loss: 1.1455870045689378
Validation loss: 2.3368173077524217

Epoch: 5| Step: 3
Training loss: 1.531285032533328
Validation loss: 2.3406225436791233

Epoch: 5| Step: 4
Training loss: 1.688205571488622
Validation loss: 2.3568743692808503

Epoch: 5| Step: 5
Training loss: 1.3501139469095145
Validation loss: 2.320004574760931

Epoch: 5| Step: 6
Training loss: 1.434918864412089
Validation loss: 2.307721674153552

Epoch: 5| Step: 7
Training loss: 1.2281016515012033
Validation loss: 2.324903383429656

Epoch: 5| Step: 8
Training loss: 1.9926731490043261
Validation loss: 2.3262682030056356

Epoch: 5| Step: 9
Training loss: 1.0705618463474487
Validation loss: 2.336490984905108

Epoch: 5| Step: 10
Training loss: 0.9657393094645481
Validation loss: 2.3588100692282503

Epoch: 371| Step: 0
Training loss: 1.7122021882551068
Validation loss: 2.295181970844217

Epoch: 5| Step: 1
Training loss: 1.0693625808253293
Validation loss: 2.396803554491488

Epoch: 5| Step: 2
Training loss: 1.5875806142208275
Validation loss: 2.360103612839227

Epoch: 5| Step: 3
Training loss: 1.086200984028915
Validation loss: 2.3153609504800245

Epoch: 5| Step: 4
Training loss: 1.1501579632284462
Validation loss: 2.3373092057372946

Epoch: 5| Step: 5
Training loss: 1.305039638121922
Validation loss: 2.3259147519226624

Epoch: 5| Step: 6
Training loss: 1.5191396488138498
Validation loss: 2.408038092246058

Epoch: 5| Step: 7
Training loss: 1.5591545147866566
Validation loss: 2.326969204219701

Epoch: 5| Step: 8
Training loss: 1.7945111191799152
Validation loss: 2.379007533421002

Epoch: 5| Step: 9
Training loss: 1.3731050872400674
Validation loss: 2.295461260180273

Epoch: 5| Step: 10
Training loss: 1.3473375026412497
Validation loss: 2.344929118099799

Epoch: 372| Step: 0
Training loss: 1.3849080473882605
Validation loss: 2.3336142392497

Epoch: 5| Step: 1
Training loss: 1.1877199270479601
Validation loss: 2.306328807984652

Epoch: 5| Step: 2
Training loss: 1.2421263673722422
Validation loss: 2.2960723865352306

Epoch: 5| Step: 3
Training loss: 1.386587647164229
Validation loss: 2.2717364987454833

Epoch: 5| Step: 4
Training loss: 1.613618385981643
Validation loss: 2.3993209051569773

Epoch: 5| Step: 5
Training loss: 1.551982270434466
Validation loss: 2.2886072960759747

Epoch: 5| Step: 6
Training loss: 1.1537892731071218
Validation loss: 2.329094544430208

Epoch: 5| Step: 7
Training loss: 2.2543358880889253
Validation loss: 2.3756636586625626

Epoch: 5| Step: 8
Training loss: 1.061759690820972
Validation loss: 2.37289963847862

Epoch: 5| Step: 9
Training loss: 1.4237727820337869
Validation loss: 2.330141530856691

Epoch: 5| Step: 10
Training loss: 1.2494274258551166
Validation loss: 2.278089805911958

Epoch: 373| Step: 0
Training loss: 1.203467778508711
Validation loss: 2.3408940964098286

Epoch: 5| Step: 1
Training loss: 1.2274684597399528
Validation loss: 2.324787373456727

Epoch: 5| Step: 2
Training loss: 1.5268589821223968
Validation loss: 2.3542617363390885

Epoch: 5| Step: 3
Training loss: 1.3810430725584626
Validation loss: 2.3346175268760763

Epoch: 5| Step: 4
Training loss: 1.17577952641459
Validation loss: 2.3159326907871027

Epoch: 5| Step: 5
Training loss: 1.4293846268156634
Validation loss: 2.328814759820829

Epoch: 5| Step: 6
Training loss: 1.3580451686971085
Validation loss: 2.4014779885988498

Epoch: 5| Step: 7
Training loss: 2.211748601185816
Validation loss: 2.3351801863770554

Epoch: 5| Step: 8
Training loss: 1.0788702116961533
Validation loss: 2.346921133728345

Epoch: 5| Step: 9
Training loss: 1.4566422421279406
Validation loss: 2.3106058795022264

Epoch: 5| Step: 10
Training loss: 1.3764325828601256
Validation loss: 2.3190191393274073

Epoch: 374| Step: 0
Training loss: 1.2396856580970106
Validation loss: 2.330146307955456

Epoch: 5| Step: 1
Training loss: 1.3544295227032725
Validation loss: 2.253296914251714

Epoch: 5| Step: 2
Training loss: 1.1734367136946278
Validation loss: 2.30269450394152

Epoch: 5| Step: 3
Training loss: 1.1998443959598664
Validation loss: 2.408429797483483

Epoch: 5| Step: 4
Training loss: 1.6081638408289078
Validation loss: 2.3814517031058706

Epoch: 5| Step: 5
Training loss: 1.078713076988418
Validation loss: 2.333377545094639

Epoch: 5| Step: 6
Training loss: 1.4131764539135336
Validation loss: 2.269670715107769

Epoch: 5| Step: 7
Training loss: 1.5422732560297634
Validation loss: 2.3025016072450146

Epoch: 5| Step: 8
Training loss: 2.0562983823145355
Validation loss: 2.325901493431106

Epoch: 5| Step: 9
Training loss: 1.0083811139117291
Validation loss: 2.360696488392707

Epoch: 5| Step: 10
Training loss: 1.309666344907091
Validation loss: 2.317285796516983

Epoch: 375| Step: 0
Training loss: 1.690045379729143
Validation loss: 2.3244841365770226

Epoch: 5| Step: 1
Training loss: 1.3194204172099444
Validation loss: 2.3938244733757466

Epoch: 5| Step: 2
Training loss: 1.1419646352279333
Validation loss: 2.3908966529941247

Epoch: 5| Step: 3
Training loss: 1.2997064589163028
Validation loss: 2.3042942485399367

Epoch: 5| Step: 4
Training loss: 1.234435937077503
Validation loss: 2.369119106315686

Epoch: 5| Step: 5
Training loss: 1.0250849386238354
Validation loss: 2.2895498490884245

Epoch: 5| Step: 6
Training loss: 2.024256713464079
Validation loss: 2.3322576182550407

Epoch: 5| Step: 7
Training loss: 1.4780116160740266
Validation loss: 2.3678495995385433

Epoch: 5| Step: 8
Training loss: 1.371498635005237
Validation loss: 2.375570420878282

Epoch: 5| Step: 9
Training loss: 1.23712031579728
Validation loss: 2.305265204270708

Epoch: 5| Step: 10
Training loss: 1.2092409616558035
Validation loss: 2.2884447394709766

Epoch: 376| Step: 0
Training loss: 1.1682025586092868
Validation loss: 2.3107108367769635

Epoch: 5| Step: 1
Training loss: 1.1289586249744925
Validation loss: 2.2965807245930976

Epoch: 5| Step: 2
Training loss: 1.5060798295635556
Validation loss: 2.354414575540344

Epoch: 5| Step: 3
Training loss: 1.194614181483938
Validation loss: 2.3066255535744666

Epoch: 5| Step: 4
Training loss: 1.398445427728271
Validation loss: 2.3054665849248037

Epoch: 5| Step: 5
Training loss: 1.33507309102769
Validation loss: 2.3343833516082944

Epoch: 5| Step: 6
Training loss: 1.789252924883825
Validation loss: 2.292363937963075

Epoch: 5| Step: 7
Training loss: 1.3516960739546073
Validation loss: 2.27483310142479

Epoch: 5| Step: 8
Training loss: 1.1756602380268735
Validation loss: 2.2982279113783983

Epoch: 5| Step: 9
Training loss: 1.8736575725171618
Validation loss: 2.344826874901164

Epoch: 5| Step: 10
Training loss: 1.1610137134041105
Validation loss: 2.298794899210556

Epoch: 377| Step: 0
Training loss: 1.0215494926513737
Validation loss: 2.31300915697728

Epoch: 5| Step: 1
Training loss: 1.6205841366477916
Validation loss: 2.282836836399582

Epoch: 5| Step: 2
Training loss: 2.316573292979703
Validation loss: 2.3702834585332395

Epoch: 5| Step: 3
Training loss: 1.532105965667179
Validation loss: 2.3033350137055897

Epoch: 5| Step: 4
Training loss: 1.1894435036556683
Validation loss: 2.305406483661114

Epoch: 5| Step: 5
Training loss: 1.0919582404651187
Validation loss: 2.3132299863550476

Epoch: 5| Step: 6
Training loss: 1.2487084391935859
Validation loss: 2.263443870280344

Epoch: 5| Step: 7
Training loss: 1.009684280867361
Validation loss: 2.2881476880580114

Epoch: 5| Step: 8
Training loss: 1.0896914796179482
Validation loss: 2.323310161694594

Epoch: 5| Step: 9
Training loss: 1.1388765285307092
Validation loss: 2.3357972589199947

Epoch: 5| Step: 10
Training loss: 1.5175629643256154
Validation loss: 2.301407384368521

Epoch: 378| Step: 0
Training loss: 1.248383907843623
Validation loss: 2.300569395539034

Epoch: 5| Step: 1
Training loss: 1.1205673311014377
Validation loss: 2.3170063939017806

Epoch: 5| Step: 2
Training loss: 1.4771008998470136
Validation loss: 2.3916720636761464

Epoch: 5| Step: 3
Training loss: 1.5185793368678702
Validation loss: 2.3385720386109163

Epoch: 5| Step: 4
Training loss: 1.0768765947769587
Validation loss: 2.339668547440912

Epoch: 5| Step: 5
Training loss: 1.4621942184173233
Validation loss: 2.2453816984172534

Epoch: 5| Step: 6
Training loss: 1.3210837013588859
Validation loss: 2.354753790394793

Epoch: 5| Step: 7
Training loss: 2.45751094532389
Validation loss: 2.3862455820849884

Epoch: 5| Step: 8
Training loss: 1.1286613964397894
Validation loss: 2.392822120318022

Epoch: 5| Step: 9
Training loss: 1.0584812456432755
Validation loss: 2.3895356641868366

Epoch: 5| Step: 10
Training loss: 0.972747246955264
Validation loss: 2.368725238527443

Epoch: 379| Step: 0
Training loss: 1.1896243418468961
Validation loss: 2.378378033093517

Epoch: 5| Step: 1
Training loss: 1.0915124621691203
Validation loss: 2.351750134247117

Epoch: 5| Step: 2
Training loss: 1.6250659489087242
Validation loss: 2.3197065517682707

Epoch: 5| Step: 3
Training loss: 1.2195221826679354
Validation loss: 2.3131279451709954

Epoch: 5| Step: 4
Training loss: 1.984568188492245
Validation loss: 2.374007263127145

Epoch: 5| Step: 5
Training loss: 1.1119572847999173
Validation loss: 2.243779633079243

Epoch: 5| Step: 6
Training loss: 0.9275683445183117
Validation loss: 2.3957661502044822

Epoch: 5| Step: 7
Training loss: 1.775698325641468
Validation loss: 2.26466302643651

Epoch: 5| Step: 8
Training loss: 0.9739291582820694
Validation loss: 2.34487814273914

Epoch: 5| Step: 9
Training loss: 1.414185155111891
Validation loss: 2.339094507234046

Epoch: 5| Step: 10
Training loss: 1.3632361287079895
Validation loss: 2.3142023624560712

Epoch: 380| Step: 0
Training loss: 1.9730126993666772
Validation loss: 2.338896617695251

Epoch: 5| Step: 1
Training loss: 1.5098313172965558
Validation loss: 2.3116546089985293

Epoch: 5| Step: 2
Training loss: 1.1928852844018798
Validation loss: 2.3438957787027386

Epoch: 5| Step: 3
Training loss: 1.0385805891134847
Validation loss: 2.3219394332453187

Epoch: 5| Step: 4
Training loss: 1.556217533370394
Validation loss: 2.313341820636776

Epoch: 5| Step: 5
Training loss: 1.7163876337596704
Validation loss: 2.3642832280234525

Epoch: 5| Step: 6
Training loss: 1.0676820829312452
Validation loss: 2.307731132309571

Epoch: 5| Step: 7
Training loss: 1.1509445747864433
Validation loss: 2.3092352568176944

Epoch: 5| Step: 8
Training loss: 1.390264657299838
Validation loss: 2.2737014775685314

Epoch: 5| Step: 9
Training loss: 0.9901798692257646
Validation loss: 2.3779413255366855

Epoch: 5| Step: 10
Training loss: 1.710198299331899
Validation loss: 2.285286142762719

Epoch: 381| Step: 0
Training loss: 1.3876452292653394
Validation loss: 2.3211739133915694

Epoch: 5| Step: 1
Training loss: 1.1159570493670912
Validation loss: 2.2874988441367985

Epoch: 5| Step: 2
Training loss: 1.2071924688329305
Validation loss: 2.3125066870737103

Epoch: 5| Step: 3
Training loss: 2.190285244659337
Validation loss: 2.2919963886597836

Epoch: 5| Step: 4
Training loss: 1.113086081011325
Validation loss: 2.3190619477294625

Epoch: 5| Step: 5
Training loss: 1.0694805169455397
Validation loss: 2.339545839108765

Epoch: 5| Step: 6
Training loss: 1.3232700246437714
Validation loss: 2.355461209704358

Epoch: 5| Step: 7
Training loss: 1.118991755358857
Validation loss: 2.3033345128499154

Epoch: 5| Step: 8
Training loss: 1.48391234566243
Validation loss: 2.354648395602877

Epoch: 5| Step: 9
Training loss: 1.2991016988963249
Validation loss: 2.338130937240429

Epoch: 5| Step: 10
Training loss: 1.2770143136586698
Validation loss: 2.376852547875333

Epoch: 382| Step: 0
Training loss: 1.4601686463868184
Validation loss: 2.249388694895984

Epoch: 5| Step: 1
Training loss: 1.252077283966295
Validation loss: 2.3831737387715886

Epoch: 5| Step: 2
Training loss: 1.2512381143986744
Validation loss: 2.306820672045276

Epoch: 5| Step: 3
Training loss: 1.692050027238478
Validation loss: 2.2680250265557875

Epoch: 5| Step: 4
Training loss: 1.2114438382716872
Validation loss: 2.341298330114428

Epoch: 5| Step: 5
Training loss: 1.1914777390341083
Validation loss: 2.3229750748169593

Epoch: 5| Step: 6
Training loss: 1.2420202178599493
Validation loss: 2.279159931370052

Epoch: 5| Step: 7
Training loss: 1.0729033583522447
Validation loss: 2.3612556299485465

Epoch: 5| Step: 8
Training loss: 1.5955879982327426
Validation loss: 2.3501558286640742

Epoch: 5| Step: 9
Training loss: 1.0067203725505414
Validation loss: 2.370973267080368

Epoch: 5| Step: 10
Training loss: 2.1871352845374363
Validation loss: 2.360478917184127

Epoch: 383| Step: 0
Training loss: 1.345949811983182
Validation loss: 2.300546108838968

Epoch: 5| Step: 1
Training loss: 1.4493635984353135
Validation loss: 2.332390342698462

Epoch: 5| Step: 2
Training loss: 1.3520887816583378
Validation loss: 2.2933480777621833

Epoch: 5| Step: 3
Training loss: 1.5518615188658338
Validation loss: 2.2955731158250368

Epoch: 5| Step: 4
Training loss: 1.2457630830859001
Validation loss: 2.353624353461769

Epoch: 5| Step: 5
Training loss: 1.2419318169938007
Validation loss: 2.297359306948637

Epoch: 5| Step: 6
Training loss: 0.9560031273004624
Validation loss: 2.210632829651779

Epoch: 5| Step: 7
Training loss: 1.071337522316533
Validation loss: 2.348323378134591

Epoch: 5| Step: 8
Training loss: 1.792594455055242
Validation loss: 2.287017265841316

Epoch: 5| Step: 9
Training loss: 1.2223297268134898
Validation loss: 2.231935241442899

Epoch: 5| Step: 10
Training loss: 1.3090629533560654
Validation loss: 2.3320464293140377

Epoch: 384| Step: 0
Training loss: 1.210337730280661
Validation loss: 2.311715668996437

Epoch: 5| Step: 1
Training loss: 1.5325061550296812
Validation loss: 2.3563832465314283

Epoch: 5| Step: 2
Training loss: 1.9403409740824227
Validation loss: 2.3043070739709854

Epoch: 5| Step: 3
Training loss: 1.1461584612488085
Validation loss: 2.3540547444400928

Epoch: 5| Step: 4
Training loss: 1.7497237532427063
Validation loss: 2.264415995753887

Epoch: 5| Step: 5
Training loss: 1.6235532923094178
Validation loss: 2.3098614546970424

Epoch: 5| Step: 6
Training loss: 1.3154335390075622
Validation loss: 2.3123678808764603

Epoch: 5| Step: 7
Training loss: 0.830949178199722
Validation loss: 2.266478551774275

Epoch: 5| Step: 8
Training loss: 1.020915177366583
Validation loss: 2.294876231252584

Epoch: 5| Step: 9
Training loss: 1.2852101416144055
Validation loss: 2.371905035718042

Epoch: 5| Step: 10
Training loss: 1.4283748082683017
Validation loss: 2.2963648967627917

Epoch: 385| Step: 0
Training loss: 1.358327659446864
Validation loss: 2.327379499750716

Epoch: 5| Step: 1
Training loss: 1.0834741439762086
Validation loss: 2.351284524283905

Epoch: 5| Step: 2
Training loss: 0.9990601891761476
Validation loss: 2.296866455910502

Epoch: 5| Step: 3
Training loss: 1.208928120772597
Validation loss: 2.3477930370335875

Epoch: 5| Step: 4
Training loss: 1.4500124010016162
Validation loss: 2.351778070050077

Epoch: 5| Step: 5
Training loss: 0.8490397330423394
Validation loss: 2.299863413040551

Epoch: 5| Step: 6
Training loss: 1.3710368000603599
Validation loss: 2.3867355138515784

Epoch: 5| Step: 7
Training loss: 1.8565082408949178
Validation loss: 2.3723152040412634

Epoch: 5| Step: 8
Training loss: 1.5311685657256224
Validation loss: 2.2210444571912995

Epoch: 5| Step: 9
Training loss: 1.4811168047417227
Validation loss: 2.2801159433415537

Epoch: 5| Step: 10
Training loss: 1.0801096906412508
Validation loss: 2.3626221465436363

Epoch: 386| Step: 0
Training loss: 1.056879210551135
Validation loss: 2.367916759843269

Epoch: 5| Step: 1
Training loss: 0.967463808540991
Validation loss: 2.3431809055060433

Epoch: 5| Step: 2
Training loss: 1.1585903710427274
Validation loss: 2.309678763802787

Epoch: 5| Step: 3
Training loss: 1.327125936490063
Validation loss: 2.26998156961405

Epoch: 5| Step: 4
Training loss: 1.4863067906135579
Validation loss: 2.339514649007498

Epoch: 5| Step: 5
Training loss: 1.0840545356658065
Validation loss: 2.3651116999503325

Epoch: 5| Step: 6
Training loss: 1.2866565793552847
Validation loss: 2.377286748145551

Epoch: 5| Step: 7
Training loss: 1.6386559432190737
Validation loss: 2.267672809961685

Epoch: 5| Step: 8
Training loss: 1.146980866995143
Validation loss: 2.352697519671222

Epoch: 5| Step: 9
Training loss: 1.3911935308466146
Validation loss: 2.3113384805259014

Epoch: 5| Step: 10
Training loss: 2.198712088999212
Validation loss: 2.323865104140033

Epoch: 387| Step: 0
Training loss: 1.8234509438980957
Validation loss: 2.3819973276628774

Epoch: 5| Step: 1
Training loss: 1.1143837271716093
Validation loss: 2.339586994262259

Epoch: 5| Step: 2
Training loss: 1.1322941087253677
Validation loss: 2.327689301367205

Epoch: 5| Step: 3
Training loss: 1.286112699011053
Validation loss: 2.404816686309967

Epoch: 5| Step: 4
Training loss: 1.99647563110658
Validation loss: 2.3600219576258925

Epoch: 5| Step: 5
Training loss: 1.5141296088401195
Validation loss: 2.3781336138816154

Epoch: 5| Step: 6
Training loss: 1.034613931495054
Validation loss: 2.4060412815677408

Epoch: 5| Step: 7
Training loss: 0.9832691459935218
Validation loss: 2.2776767763927914

Epoch: 5| Step: 8
Training loss: 1.31530919758642
Validation loss: 2.3811909823394934

Epoch: 5| Step: 9
Training loss: 1.2861192336122347
Validation loss: 2.3946714611289583

Epoch: 5| Step: 10
Training loss: 1.6069823321146874
Validation loss: 2.319747801397833

Epoch: 388| Step: 0
Training loss: 1.2705977904281487
Validation loss: 2.340123158128898

Epoch: 5| Step: 1
Training loss: 1.2524132322001647
Validation loss: 2.26970204780281

Epoch: 5| Step: 2
Training loss: 1.8858456062235571
Validation loss: 2.322050464961494

Epoch: 5| Step: 3
Training loss: 1.2358260981030067
Validation loss: 2.3293066379806926

Epoch: 5| Step: 4
Training loss: 1.3889021756278392
Validation loss: 2.3062827908454437

Epoch: 5| Step: 5
Training loss: 1.4648548990461134
Validation loss: 2.3039147790651704

Epoch: 5| Step: 6
Training loss: 1.2007756766076383
Validation loss: 2.321121544893345

Epoch: 5| Step: 7
Training loss: 1.0416655667617076
Validation loss: 2.3504386475450727

Epoch: 5| Step: 8
Training loss: 1.4716142362685214
Validation loss: 2.3077914851855628

Epoch: 5| Step: 9
Training loss: 0.964787068420229
Validation loss: 2.32689516881382

Epoch: 5| Step: 10
Training loss: 1.6230788244965721
Validation loss: 2.2665204189253227

Epoch: 389| Step: 0
Training loss: 1.198044092892158
Validation loss: 2.325322168271531

Epoch: 5| Step: 1
Training loss: 1.3958662038700003
Validation loss: 2.3195706200682906

Epoch: 5| Step: 2
Training loss: 0.8345598651813255
Validation loss: 2.3118487979105007

Epoch: 5| Step: 3
Training loss: 1.564670047651251
Validation loss: 2.307571650439785

Epoch: 5| Step: 4
Training loss: 1.122767246097744
Validation loss: 2.35220108570919

Epoch: 5| Step: 5
Training loss: 1.0123281521426462
Validation loss: 2.419883295952255

Epoch: 5| Step: 6
Training loss: 1.5764366409679935
Validation loss: 2.3692366050848803

Epoch: 5| Step: 7
Training loss: 1.1338621341049822
Validation loss: 2.3332505185802526

Epoch: 5| Step: 8
Training loss: 1.1380551796392329
Validation loss: 2.3188610949264743

Epoch: 5| Step: 9
Training loss: 1.4033874623074973
Validation loss: 2.383643172470019

Epoch: 5| Step: 10
Training loss: 2.0469024889315897
Validation loss: 2.3643544760197006

Epoch: 390| Step: 0
Training loss: 1.3708024979034588
Validation loss: 2.3281715544226063

Epoch: 5| Step: 1
Training loss: 1.0855263130516526
Validation loss: 2.322847601942972

Epoch: 5| Step: 2
Training loss: 1.0068280638748572
Validation loss: 2.3000281191315683

Epoch: 5| Step: 3
Training loss: 1.2241851704659492
Validation loss: 2.2841007055025564

Epoch: 5| Step: 4
Training loss: 1.2876938461001433
Validation loss: 2.2909679608079205

Epoch: 5| Step: 5
Training loss: 1.2934668005246397
Validation loss: 2.35552744332367

Epoch: 5| Step: 6
Training loss: 1.222266723203181
Validation loss: 2.364427238741401

Epoch: 5| Step: 7
Training loss: 1.5429760123939056
Validation loss: 2.334476222544333

Epoch: 5| Step: 8
Training loss: 1.8893592948399647
Validation loss: 2.3013054661941763

Epoch: 5| Step: 9
Training loss: 1.3883010648173097
Validation loss: 2.364983303699077

Epoch: 5| Step: 10
Training loss: 1.113948260812837
Validation loss: 2.3701577490813923

Epoch: 391| Step: 0
Training loss: 1.2546584110522163
Validation loss: 2.3169509857822903

Epoch: 5| Step: 1
Training loss: 1.291344581973177
Validation loss: 2.3214668779661998

Epoch: 5| Step: 2
Training loss: 1.0609134160090565
Validation loss: 2.337415726200716

Epoch: 5| Step: 3
Training loss: 1.5165485046105673
Validation loss: 2.265063455628103

Epoch: 5| Step: 4
Training loss: 1.407425198642386
Validation loss: 2.322577322360195

Epoch: 5| Step: 5
Training loss: 1.319373434509476
Validation loss: 2.361372584157643

Epoch: 5| Step: 6
Training loss: 1.0055661857481002
Validation loss: 2.304991545034949

Epoch: 5| Step: 7
Training loss: 1.2032136760581205
Validation loss: 2.3164249204915115

Epoch: 5| Step: 8
Training loss: 1.8144902450328737
Validation loss: 2.3031524317960197

Epoch: 5| Step: 9
Training loss: 1.269571344769501
Validation loss: 2.309605838020511

Epoch: 5| Step: 10
Training loss: 1.3081961412035519
Validation loss: 2.3516253647383425

Epoch: 392| Step: 0
Training loss: 1.1415768662286758
Validation loss: 2.3571784036500016

Epoch: 5| Step: 1
Training loss: 1.1067922911714323
Validation loss: 2.3709199603198527

Epoch: 5| Step: 2
Training loss: 1.2042339713130874
Validation loss: 2.309759206981396

Epoch: 5| Step: 3
Training loss: 1.1669077056567576
Validation loss: 2.298832643624545

Epoch: 5| Step: 4
Training loss: 1.2214385480003231
Validation loss: 2.320912811305232

Epoch: 5| Step: 5
Training loss: 1.2578145376627274
Validation loss: 2.4057600979333205

Epoch: 5| Step: 6
Training loss: 1.9919886471106947
Validation loss: 2.3201901502445845

Epoch: 5| Step: 7
Training loss: 1.6332753816690966
Validation loss: 2.322302787720272

Epoch: 5| Step: 8
Training loss: 1.3002451115395117
Validation loss: 2.2584676228192437

Epoch: 5| Step: 9
Training loss: 1.2258054498699156
Validation loss: 2.3428455338560816

Epoch: 5| Step: 10
Training loss: 1.1400609646775288
Validation loss: 2.30373530335935

Epoch: 393| Step: 0
Training loss: 0.9884715745125829
Validation loss: 2.3816512978319384

Epoch: 5| Step: 1
Training loss: 1.2126094965307916
Validation loss: 2.331650460717219

Epoch: 5| Step: 2
Training loss: 1.181927001551475
Validation loss: 2.3568541135040957

Epoch: 5| Step: 3
Training loss: 1.0281581189233175
Validation loss: 2.3287237355056636

Epoch: 5| Step: 4
Training loss: 1.1882490506095151
Validation loss: 2.2905881885275248

Epoch: 5| Step: 5
Training loss: 1.0968873395524588
Validation loss: 2.3335174789660544

Epoch: 5| Step: 6
Training loss: 1.9324898082666737
Validation loss: 2.3110655559726236

Epoch: 5| Step: 7
Training loss: 1.419572663949624
Validation loss: 2.2796052214044495

Epoch: 5| Step: 8
Training loss: 1.243598568386114
Validation loss: 2.2904782462583126

Epoch: 5| Step: 9
Training loss: 1.4355556773220781
Validation loss: 2.318819536544539

Epoch: 5| Step: 10
Training loss: 1.0822425388106307
Validation loss: 2.331900117082281

Epoch: 394| Step: 0
Training loss: 2.145198086037423
Validation loss: 2.269414301625831

Epoch: 5| Step: 1
Training loss: 1.3219180756172046
Validation loss: 2.351492174316832

Epoch: 5| Step: 2
Training loss: 1.3440440543708831
Validation loss: 2.339515734397351

Epoch: 5| Step: 3
Training loss: 1.0256525776820804
Validation loss: 2.275288334662915

Epoch: 5| Step: 4
Training loss: 0.9919688667249466
Validation loss: 2.2901935895645433

Epoch: 5| Step: 5
Training loss: 1.2260693087037038
Validation loss: 2.384139393981093

Epoch: 5| Step: 6
Training loss: 1.4803428898358064
Validation loss: 2.289312118140545

Epoch: 5| Step: 7
Training loss: 1.2046141882927115
Validation loss: 2.295529935280375

Epoch: 5| Step: 8
Training loss: 1.2660666272166314
Validation loss: 2.3432726411520646

Epoch: 5| Step: 9
Training loss: 1.1858883009444416
Validation loss: 2.2943376560715056

Epoch: 5| Step: 10
Training loss: 1.1187414818977557
Validation loss: 2.348145849565443

Epoch: 395| Step: 0
Training loss: 1.3606746205090101
Validation loss: 2.293778818671521

Epoch: 5| Step: 1
Training loss: 1.2539770754007
Validation loss: 2.314512541647637

Epoch: 5| Step: 2
Training loss: 1.2015301922049864
Validation loss: 2.350915682152896

Epoch: 5| Step: 3
Training loss: 0.8708298629861947
Validation loss: 2.3560956548133216

Epoch: 5| Step: 4
Training loss: 1.3651350473663448
Validation loss: 2.3763010987153192

Epoch: 5| Step: 5
Training loss: 1.2264409096095066
Validation loss: 2.3763465580281027

Epoch: 5| Step: 6
Training loss: 2.0419042669603558
Validation loss: 2.363224560877976

Epoch: 5| Step: 7
Training loss: 1.020717588337539
Validation loss: 2.318286125684015

Epoch: 5| Step: 8
Training loss: 1.2312546899386705
Validation loss: 2.3020950756591105

Epoch: 5| Step: 9
Training loss: 1.395110493526023
Validation loss: 2.333745183576291

Epoch: 5| Step: 10
Training loss: 1.5229953221971255
Validation loss: 2.3163776009614843

Epoch: 396| Step: 0
Training loss: 1.519385558844486
Validation loss: 2.3599483459152877

Epoch: 5| Step: 1
Training loss: 1.1214524070889775
Validation loss: 2.3999626652401234

Epoch: 5| Step: 2
Training loss: 1.485312075720208
Validation loss: 2.3084440322799744

Epoch: 5| Step: 3
Training loss: 1.377280251894178
Validation loss: 2.2918356105099336

Epoch: 5| Step: 4
Training loss: 1.0751497984910063
Validation loss: 2.324140518676678

Epoch: 5| Step: 5
Training loss: 0.8386102889199691
Validation loss: 2.2749922338346624

Epoch: 5| Step: 6
Training loss: 1.296275034545938
Validation loss: 2.3458694762823935

Epoch: 5| Step: 7
Training loss: 1.9070352906680872
Validation loss: 2.3636356704627928

Epoch: 5| Step: 8
Training loss: 1.0570878582532903
Validation loss: 2.2523973481815145

Epoch: 5| Step: 9
Training loss: 1.3658551072453997
Validation loss: 2.348234592055464

Epoch: 5| Step: 10
Training loss: 1.3166791140696297
Validation loss: 2.321380947083842

Epoch: 397| Step: 0
Training loss: 1.1868877338290797
Validation loss: 2.2429000215730253

Epoch: 5| Step: 1
Training loss: 1.2993329666039968
Validation loss: 2.302160499432782

Epoch: 5| Step: 2
Training loss: 1.3938047937134224
Validation loss: 2.317311031351886

Epoch: 5| Step: 3
Training loss: 1.1447806233135767
Validation loss: 2.263924147742789

Epoch: 5| Step: 4
Training loss: 1.136549632283061
Validation loss: 2.316236141831379

Epoch: 5| Step: 5
Training loss: 1.2414080015425812
Validation loss: 2.3360622382441085

Epoch: 5| Step: 6
Training loss: 2.244153055101835
Validation loss: 2.313344812769274

Epoch: 5| Step: 7
Training loss: 0.9873643926873393
Validation loss: 2.3454214303997114

Epoch: 5| Step: 8
Training loss: 1.1226967970840027
Validation loss: 2.375021478353981

Epoch: 5| Step: 9
Training loss: 1.3112725467398059
Validation loss: 2.290938083319169

Epoch: 5| Step: 10
Training loss: 1.1567089098014938
Validation loss: 2.3375359120137476

Epoch: 398| Step: 0
Training loss: 1.2716487186476875
Validation loss: 2.270565503927098

Epoch: 5| Step: 1
Training loss: 0.9824260612990143
Validation loss: 2.2626911124538855

Epoch: 5| Step: 2
Training loss: 1.338753125697315
Validation loss: 2.325537720113558

Epoch: 5| Step: 3
Training loss: 1.2111454938874568
Validation loss: 2.2993854606784776

Epoch: 5| Step: 4
Training loss: 2.2772216764157145
Validation loss: 2.336826729328221

Epoch: 5| Step: 5
Training loss: 1.3355229052311435
Validation loss: 2.2863866065187555

Epoch: 5| Step: 6
Training loss: 1.557781418898737
Validation loss: 2.3425491680403314

Epoch: 5| Step: 7
Training loss: 1.0466895437372694
Validation loss: 2.3505826710340028

Epoch: 5| Step: 8
Training loss: 0.8209907997117658
Validation loss: 2.3876942151902565

Epoch: 5| Step: 9
Training loss: 1.193023334645883
Validation loss: 2.352900687833133

Epoch: 5| Step: 10
Training loss: 1.320996981730684
Validation loss: 2.2695167719940983

Epoch: 399| Step: 0
Training loss: 1.2187290189844429
Validation loss: 2.282476398657026

Epoch: 5| Step: 1
Training loss: 1.6498873151967954
Validation loss: 2.289065611225161

Epoch: 5| Step: 2
Training loss: 1.0132294793826395
Validation loss: 2.282479494711217

Epoch: 5| Step: 3
Training loss: 0.9017094946812467
Validation loss: 2.3081874794965214

Epoch: 5| Step: 4
Training loss: 0.829130210426461
Validation loss: 2.2777747095772507

Epoch: 5| Step: 5
Training loss: 1.987386505917097
Validation loss: 2.4044797394673862

Epoch: 5| Step: 6
Training loss: 1.388086080061354
Validation loss: 2.3072445879758403

Epoch: 5| Step: 7
Training loss: 1.3313746917784421
Validation loss: 2.3270792055129657

Epoch: 5| Step: 8
Training loss: 1.4882958278793095
Validation loss: 2.284609148856527

Epoch: 5| Step: 9
Training loss: 1.3158463552377027
Validation loss: 2.208480057705274

Epoch: 5| Step: 10
Training loss: 1.2399681466379766
Validation loss: 2.287227736525872

Epoch: 400| Step: 0
Training loss: 1.5177975057859154
Validation loss: 2.283933076746308

Epoch: 5| Step: 1
Training loss: 2.1574964376090864
Validation loss: 2.2479931747337436

Epoch: 5| Step: 2
Training loss: 0.9949235812031405
Validation loss: 2.268004277364734

Epoch: 5| Step: 3
Training loss: 1.3063137403934628
Validation loss: 2.285119616272076

Epoch: 5| Step: 4
Training loss: 1.3727872122752536
Validation loss: 2.3276892534577316

Epoch: 5| Step: 5
Training loss: 1.3326917783706702
Validation loss: 2.335804667880082

Epoch: 5| Step: 6
Training loss: 1.2298073580541768
Validation loss: 2.277592536934079

Epoch: 5| Step: 7
Training loss: 1.14583099827384
Validation loss: 2.35329101100666

Epoch: 5| Step: 8
Training loss: 0.904536139388847
Validation loss: 2.2658901637927427

Epoch: 5| Step: 9
Training loss: 1.1460194985560048
Validation loss: 2.33411018635583

Epoch: 5| Step: 10
Training loss: 1.1877871216449183
Validation loss: 2.337576848665794

Epoch: 401| Step: 0
Training loss: 1.671046684640293
Validation loss: 2.351376343363441

Epoch: 5| Step: 1
Training loss: 1.2674530861052018
Validation loss: 2.326281518916975

Epoch: 5| Step: 2
Training loss: 1.1161318506506317
Validation loss: 2.2876209699765417

Epoch: 5| Step: 3
Training loss: 1.1073782237766328
Validation loss: 2.297879682752804

Epoch: 5| Step: 4
Training loss: 1.0266244204816921
Validation loss: 2.3371152274982707

Epoch: 5| Step: 5
Training loss: 0.932928414866418
Validation loss: 2.2823027236774056

Epoch: 5| Step: 6
Training loss: 1.5256263853548941
Validation loss: 2.3364635608703073

Epoch: 5| Step: 7
Training loss: 1.135933096561004
Validation loss: 2.302047744993354

Epoch: 5| Step: 8
Training loss: 0.8990352798069806
Validation loss: 2.275359709774939

Epoch: 5| Step: 9
Training loss: 2.016981038372764
Validation loss: 2.2578393623941806

Epoch: 5| Step: 10
Training loss: 1.1218632838240443
Validation loss: 2.3147937636654468

Epoch: 402| Step: 0
Training loss: 1.8451373812589116
Validation loss: 2.2926871923887275

Epoch: 5| Step: 1
Training loss: 1.1425479200234299
Validation loss: 2.223855955572418

Epoch: 5| Step: 2
Training loss: 1.5646427720619327
Validation loss: 2.3143827350892803

Epoch: 5| Step: 3
Training loss: 1.1984346790106446
Validation loss: 2.273746731203459

Epoch: 5| Step: 4
Training loss: 1.1780436601562674
Validation loss: 2.349468984327283

Epoch: 5| Step: 5
Training loss: 1.2162020532109865
Validation loss: 2.283929913630722

Epoch: 5| Step: 6
Training loss: 0.9441151878708682
Validation loss: 2.300865983648413

Epoch: 5| Step: 7
Training loss: 1.0084705422316262
Validation loss: 2.2416057897553188

Epoch: 5| Step: 8
Training loss: 1.2723565223462212
Validation loss: 2.307253860307966

Epoch: 5| Step: 9
Training loss: 0.995904582891751
Validation loss: 2.3578126935822126

Epoch: 5| Step: 10
Training loss: 1.5492178389353726
Validation loss: 2.3086448213902453

Epoch: 403| Step: 0
Training loss: 1.2206597160250496
Validation loss: 2.352542837333829

Epoch: 5| Step: 1
Training loss: 1.194887272613421
Validation loss: 2.347644189920974

Epoch: 5| Step: 2
Training loss: 0.9837992664782664
Validation loss: 2.224285841578938

Epoch: 5| Step: 3
Training loss: 2.1508919307388004
Validation loss: 2.252116458942856

Epoch: 5| Step: 4
Training loss: 1.3429828050553654
Validation loss: 2.302092654108605

Epoch: 5| Step: 5
Training loss: 1.2637150328163207
Validation loss: 2.2688625525973722

Epoch: 5| Step: 6
Training loss: 1.0869744927537808
Validation loss: 2.285661905747121

Epoch: 5| Step: 7
Training loss: 1.22245060467928
Validation loss: 2.258612714239427

Epoch: 5| Step: 8
Training loss: 1.2614103241449133
Validation loss: 2.2745847585180377

Epoch: 5| Step: 9
Training loss: 1.1478957890286852
Validation loss: 2.301415809117121

Epoch: 5| Step: 10
Training loss: 1.0512777523954264
Validation loss: 2.3188023668226863

Epoch: 404| Step: 0
Training loss: 1.3864211501884998
Validation loss: 2.312767577606084

Epoch: 5| Step: 1
Training loss: 1.1024436402566444
Validation loss: 2.342272509768588

Epoch: 5| Step: 2
Training loss: 1.1183694842351666
Validation loss: 2.3399628929997753

Epoch: 5| Step: 3
Training loss: 1.1863483064233042
Validation loss: 2.413183514010162

Epoch: 5| Step: 4
Training loss: 1.274179441405867
Validation loss: 2.3720675587198543

Epoch: 5| Step: 5
Training loss: 1.0624118656180925
Validation loss: 2.3060714301280147

Epoch: 5| Step: 6
Training loss: 0.9799406293479284
Validation loss: 2.333995009103011

Epoch: 5| Step: 7
Training loss: 1.3531631957691412
Validation loss: 2.346934359768583

Epoch: 5| Step: 8
Training loss: 1.357915335778732
Validation loss: 2.3325982569350687

Epoch: 5| Step: 9
Training loss: 0.9644556230131842
Validation loss: 2.3622089097925234

Epoch: 5| Step: 10
Training loss: 2.157861190566976
Validation loss: 2.376287052221066

Epoch: 405| Step: 0
Training loss: 1.3144928924757264
Validation loss: 2.301013419688466

Epoch: 5| Step: 1
Training loss: 1.1039489975391914
Validation loss: 2.386407458243885

Epoch: 5| Step: 2
Training loss: 1.142005398659046
Validation loss: 2.242517616873242

Epoch: 5| Step: 3
Training loss: 1.3465778403604602
Validation loss: 2.3123829254074546

Epoch: 5| Step: 4
Training loss: 0.95009625850688
Validation loss: 2.302657465644675

Epoch: 5| Step: 5
Training loss: 1.0608509393586003
Validation loss: 2.288557285317508

Epoch: 5| Step: 6
Training loss: 1.31826343328561
Validation loss: 2.2426011018927965

Epoch: 5| Step: 7
Training loss: 1.0823153456789132
Validation loss: 2.2854301698646435

Epoch: 5| Step: 8
Training loss: 1.2133573411218699
Validation loss: 2.3229073016110666

Epoch: 5| Step: 9
Training loss: 1.5216734233732654
Validation loss: 2.3198084129855787

Epoch: 5| Step: 10
Training loss: 1.971708103861288
Validation loss: 2.299055479625611

Epoch: 406| Step: 0
Training loss: 1.9074403142028045
Validation loss: 2.3000651613156573

Epoch: 5| Step: 1
Training loss: 1.5970920601850271
Validation loss: 2.2530239184783327

Epoch: 5| Step: 2
Training loss: 1.5512182739357907
Validation loss: 2.2901896179331045

Epoch: 5| Step: 3
Training loss: 0.8697876311492196
Validation loss: 2.346964189087536

Epoch: 5| Step: 4
Training loss: 1.118423738269711
Validation loss: 2.3523694916760096

Epoch: 5| Step: 5
Training loss: 0.9646935905953814
Validation loss: 2.253264826091015

Epoch: 5| Step: 6
Training loss: 1.287023422775003
Validation loss: 2.286502593745896

Epoch: 5| Step: 7
Training loss: 1.197681597437072
Validation loss: 2.2921833145800505

Epoch: 5| Step: 8
Training loss: 1.0201778772871681
Validation loss: 2.2740390304439764

Epoch: 5| Step: 9
Training loss: 1.1117396338639853
Validation loss: 2.307847941340023

Epoch: 5| Step: 10
Training loss: 1.2401072519587888
Validation loss: 2.3008659011971044

Epoch: 407| Step: 0
Training loss: 1.825433951218178
Validation loss: 2.4057547511486628

Epoch: 5| Step: 1
Training loss: 1.1919747418985425
Validation loss: 2.3179831028205578

Epoch: 5| Step: 2
Training loss: 1.0702824275114922
Validation loss: 2.2168554235686986

Epoch: 5| Step: 3
Training loss: 1.1191508507386234
Validation loss: 2.262769994294986

Epoch: 5| Step: 4
Training loss: 0.8771285325558599
Validation loss: 2.2626098920900017

Epoch: 5| Step: 5
Training loss: 1.4969679068958437
Validation loss: 2.3037768211528515

Epoch: 5| Step: 6
Training loss: 0.9191348521922312
Validation loss: 2.313223613622999

Epoch: 5| Step: 7
Training loss: 1.0146776916574975
Validation loss: 2.3471154451420237

Epoch: 5| Step: 8
Training loss: 1.280149685183901
Validation loss: 2.2378565406752213

Epoch: 5| Step: 9
Training loss: 1.7294176754444042
Validation loss: 2.335737351996544

Epoch: 5| Step: 10
Training loss: 1.3796833215393178
Validation loss: 2.334368128735619

Epoch: 408| Step: 0
Training loss: 1.1810599926109766
Validation loss: 2.2989582779038678

Epoch: 5| Step: 1
Training loss: 1.9065996693575544
Validation loss: 2.348823980806494

Epoch: 5| Step: 2
Training loss: 1.0032339256780283
Validation loss: 2.3220543832023233

Epoch: 5| Step: 3
Training loss: 1.0326976441017481
Validation loss: 2.379625147521489

Epoch: 5| Step: 4
Training loss: 1.2389162282725918
Validation loss: 2.3300529118082083

Epoch: 5| Step: 5
Training loss: 1.1954788890045198
Validation loss: 2.37609373295462

Epoch: 5| Step: 6
Training loss: 1.1383778108943483
Validation loss: 2.268566473038557

Epoch: 5| Step: 7
Training loss: 1.1743866516802093
Validation loss: 2.2461598370617386

Epoch: 5| Step: 8
Training loss: 1.5820589039587283
Validation loss: 2.32820331766324

Epoch: 5| Step: 9
Training loss: 1.3262169090119253
Validation loss: 2.3338927559365974

Epoch: 5| Step: 10
Training loss: 1.5102693770930031
Validation loss: 2.3099041331555585

Epoch: 409| Step: 0
Training loss: 1.9665839980687225
Validation loss: 2.292480824922927

Epoch: 5| Step: 1
Training loss: 1.1430347540904138
Validation loss: 2.231771282858849

Epoch: 5| Step: 2
Training loss: 1.1531982357267023
Validation loss: 2.3188075802181873

Epoch: 5| Step: 3
Training loss: 1.4410050823749443
Validation loss: 2.3394949404098693

Epoch: 5| Step: 4
Training loss: 1.1160853891861926
Validation loss: 2.264879886476002

Epoch: 5| Step: 5
Training loss: 0.9513722860708335
Validation loss: 2.3028878687349157

Epoch: 5| Step: 6
Training loss: 1.3752446823891065
Validation loss: 2.3093970604531595

Epoch: 5| Step: 7
Training loss: 1.4641044683965219
Validation loss: 2.3158007210076748

Epoch: 5| Step: 8
Training loss: 1.2877011595676726
Validation loss: 2.3552417670590393

Epoch: 5| Step: 9
Training loss: 0.857462123890709
Validation loss: 2.280127298089714

Epoch: 5| Step: 10
Training loss: 0.9555643478316805
Validation loss: 2.3359496380780786

Epoch: 410| Step: 0
Training loss: 1.1785411696657468
Validation loss: 2.3056146507713735

Epoch: 5| Step: 1
Training loss: 1.136604277100202
Validation loss: 2.2730928134421116

Epoch: 5| Step: 2
Training loss: 2.0041833280741854
Validation loss: 2.253758992941525

Epoch: 5| Step: 3
Training loss: 1.3548186224427654
Validation loss: 2.2600020218340204

Epoch: 5| Step: 4
Training loss: 1.087170950118609
Validation loss: 2.2946863786439984

Epoch: 5| Step: 5
Training loss: 1.2810960072342692
Validation loss: 2.365531697506346

Epoch: 5| Step: 6
Training loss: 1.4763737310614513
Validation loss: 2.293394747915972

Epoch: 5| Step: 7
Training loss: 0.7716773455754927
Validation loss: 2.287676825128393

Epoch: 5| Step: 8
Training loss: 0.9759351622705864
Validation loss: 2.285496228841532

Epoch: 5| Step: 9
Training loss: 1.2248501335646327
Validation loss: 2.298501886251326

Epoch: 5| Step: 10
Training loss: 0.9786807166530196
Validation loss: 2.297834213789134

Epoch: 411| Step: 0
Training loss: 1.1938921898646868
Validation loss: 2.272463563794627

Epoch: 5| Step: 1
Training loss: 0.8651196681468631
Validation loss: 2.3609776694631757

Epoch: 5| Step: 2
Training loss: 1.1411141169899592
Validation loss: 2.283076251079756

Epoch: 5| Step: 3
Training loss: 0.8028011619090941
Validation loss: 2.3320101919460337

Epoch: 5| Step: 4
Training loss: 1.5150090175146267
Validation loss: 2.3038652519261675

Epoch: 5| Step: 5
Training loss: 1.5838516875923656
Validation loss: 2.347363577939727

Epoch: 5| Step: 6
Training loss: 1.9665560532298578
Validation loss: 2.2803098522807015

Epoch: 5| Step: 7
Training loss: 1.1585722619685848
Validation loss: 2.3436264235209694

Epoch: 5| Step: 8
Training loss: 0.982012532616489
Validation loss: 2.3956297849957284

Epoch: 5| Step: 9
Training loss: 1.1204975416947192
Validation loss: 2.286856035618693

Epoch: 5| Step: 10
Training loss: 1.2387420085876324
Validation loss: 2.3639851403857026

Epoch: 412| Step: 0
Training loss: 1.2717285859284992
Validation loss: 2.310049641193932

Epoch: 5| Step: 1
Training loss: 1.04098619487451
Validation loss: 2.2369546018048165

Epoch: 5| Step: 2
Training loss: 1.9742963865447933
Validation loss: 2.358359473814915

Epoch: 5| Step: 3
Training loss: 1.0029197031209443
Validation loss: 2.3368327543775083

Epoch: 5| Step: 4
Training loss: 0.8922647806826112
Validation loss: 2.3516456513807333

Epoch: 5| Step: 5
Training loss: 1.4448099448274723
Validation loss: 2.2449388585440233

Epoch: 5| Step: 6
Training loss: 1.3830443365723109
Validation loss: 2.329553302951488

Epoch: 5| Step: 7
Training loss: 1.2551569895182382
Validation loss: 2.385097757650356

Epoch: 5| Step: 8
Training loss: 1.086837450533773
Validation loss: 2.282731567833948

Epoch: 5| Step: 9
Training loss: 1.1642332015870414
Validation loss: 2.297831790537551

Epoch: 5| Step: 10
Training loss: 1.0989530783191646
Validation loss: 2.351773079085473

Epoch: 413| Step: 0
Training loss: 1.0059156679863694
Validation loss: 2.3411802515442397

Epoch: 5| Step: 1
Training loss: 1.1682378146423629
Validation loss: 2.338673915632049

Epoch: 5| Step: 2
Training loss: 1.8104385623405295
Validation loss: 2.312509061689729

Epoch: 5| Step: 3
Training loss: 1.502800393693358
Validation loss: 2.249293094368283

Epoch: 5| Step: 4
Training loss: 1.056710062900807
Validation loss: 2.324501002397517

Epoch: 5| Step: 5
Training loss: 1.3366375254707088
Validation loss: 2.2532140638913525

Epoch: 5| Step: 6
Training loss: 1.1001748076169822
Validation loss: 2.319083426252325

Epoch: 5| Step: 7
Training loss: 1.331590238263006
Validation loss: 2.2360211168940807

Epoch: 5| Step: 8
Training loss: 1.0491907498052624
Validation loss: 2.3420943107455505

Epoch: 5| Step: 9
Training loss: 1.2694355620489202
Validation loss: 2.2962537143864417

Epoch: 5| Step: 10
Training loss: 1.0015895845794875
Validation loss: 2.292251299418501

Epoch: 414| Step: 0
Training loss: 1.1152891022036129
Validation loss: 2.3088956590047798

Epoch: 5| Step: 1
Training loss: 1.1917987114546138
Validation loss: 2.2802928422996036

Epoch: 5| Step: 2
Training loss: 0.9799516993900833
Validation loss: 2.3522762994561086

Epoch: 5| Step: 3
Training loss: 1.0969095643077862
Validation loss: 2.3798825625865776

Epoch: 5| Step: 4
Training loss: 1.1121520087508463
Validation loss: 2.2209967596050726

Epoch: 5| Step: 5
Training loss: 1.9598634977880878
Validation loss: 2.3345472864806376

Epoch: 5| Step: 6
Training loss: 0.9674103919136898
Validation loss: 2.3527353262145954

Epoch: 5| Step: 7
Training loss: 1.206406663198688
Validation loss: 2.2599163062083654

Epoch: 5| Step: 8
Training loss: 1.317041577710403
Validation loss: 2.362371894209281

Epoch: 5| Step: 9
Training loss: 1.2646841154625852
Validation loss: 2.3023925389476254

Epoch: 5| Step: 10
Training loss: 1.6114997541171179
Validation loss: 2.21931360929759

Epoch: 415| Step: 0
Training loss: 1.199906142855852
Validation loss: 2.303388836691164

Epoch: 5| Step: 1
Training loss: 1.133272748384311
Validation loss: 2.2756378190248387

Epoch: 5| Step: 2
Training loss: 0.8905573367466376
Validation loss: 2.3048839612581973

Epoch: 5| Step: 3
Training loss: 1.9144825999838362
Validation loss: 2.2750397493121084

Epoch: 5| Step: 4
Training loss: 1.1427818703556252
Validation loss: 2.3098807052721972

Epoch: 5| Step: 5
Training loss: 1.4030677392910966
Validation loss: 2.2713423383608005

Epoch: 5| Step: 6
Training loss: 1.3445329381299325
Validation loss: 2.3744602151265806

Epoch: 5| Step: 7
Training loss: 1.1411267052490517
Validation loss: 2.162082582468878

Epoch: 5| Step: 8
Training loss: 1.3468152946815986
Validation loss: 2.357389896452316

Epoch: 5| Step: 9
Training loss: 1.0169313685497434
Validation loss: 2.318270779968725

Epoch: 5| Step: 10
Training loss: 1.3648455807040885
Validation loss: 2.3297680523323736

Epoch: 416| Step: 0
Training loss: 0.956612787429692
Validation loss: 2.28349837780108

Epoch: 5| Step: 1
Training loss: 0.8757547461304596
Validation loss: 2.2979043508650028

Epoch: 5| Step: 2
Training loss: 1.0633450681662704
Validation loss: 2.253844952403356

Epoch: 5| Step: 3
Training loss: 1.103122337273256
Validation loss: 2.2742133077523645

Epoch: 5| Step: 4
Training loss: 1.4622422374272115
Validation loss: 2.3242990059567212

Epoch: 5| Step: 5
Training loss: 1.9508870234781008
Validation loss: 2.31422995723712

Epoch: 5| Step: 6
Training loss: 1.006863583500627
Validation loss: 2.267976280661288

Epoch: 5| Step: 7
Training loss: 1.2504568218904943
Validation loss: 2.31985880318826

Epoch: 5| Step: 8
Training loss: 1.3384861866577011
Validation loss: 2.27622554677642

Epoch: 5| Step: 9
Training loss: 0.9041311882605753
Validation loss: 2.2807790062391846

Epoch: 5| Step: 10
Training loss: 1.604634163182748
Validation loss: 2.2709117938694154

Epoch: 417| Step: 0
Training loss: 1.0687032142794284
Validation loss: 2.263323564965792

Epoch: 5| Step: 1
Training loss: 1.3110873021956153
Validation loss: 2.220720520999038

Epoch: 5| Step: 2
Training loss: 1.3952545085616097
Validation loss: 2.36514384615875

Epoch: 5| Step: 3
Training loss: 0.9328632769031431
Validation loss: 2.2979479319253255

Epoch: 5| Step: 4
Training loss: 1.2944001172261368
Validation loss: 2.328354764640899

Epoch: 5| Step: 5
Training loss: 0.9422331854275658
Validation loss: 2.292209223922875

Epoch: 5| Step: 6
Training loss: 0.9993377519242228
Validation loss: 2.2857501367228186

Epoch: 5| Step: 7
Training loss: 1.8579251703565483
Validation loss: 2.2474262541249392

Epoch: 5| Step: 8
Training loss: 1.3439058612653945
Validation loss: 2.257629727769438

Epoch: 5| Step: 9
Training loss: 1.0237093848251868
Validation loss: 2.3334586561039123

Epoch: 5| Step: 10
Training loss: 1.4215424536538763
Validation loss: 2.3150115449590456

Epoch: 418| Step: 0
Training loss: 1.1525850722220492
Validation loss: 2.3061222583390806

Epoch: 5| Step: 1
Training loss: 1.051580869335691
Validation loss: 2.356596590430285

Epoch: 5| Step: 2
Training loss: 1.1178947290937968
Validation loss: 2.3301499699878017

Epoch: 5| Step: 3
Training loss: 0.980796728712417
Validation loss: 2.309421456236723

Epoch: 5| Step: 4
Training loss: 1.3899823965014533
Validation loss: 2.3276869477443203

Epoch: 5| Step: 5
Training loss: 1.4375267026328487
Validation loss: 2.3482238712320016

Epoch: 5| Step: 6
Training loss: 1.0458936504179663
Validation loss: 2.318736542481155

Epoch: 5| Step: 7
Training loss: 1.2423888229275104
Validation loss: 2.259692838378671

Epoch: 5| Step: 8
Training loss: 1.3161076509859535
Validation loss: 2.401157891957248

Epoch: 5| Step: 9
Training loss: 1.3383743191417423
Validation loss: 2.3074052646084877

Epoch: 5| Step: 10
Training loss: 2.0780666027612
Validation loss: 2.303833534814257

Epoch: 419| Step: 0
Training loss: 1.2153612610737694
Validation loss: 2.2949868821759747

Epoch: 5| Step: 1
Training loss: 0.8593456956895548
Validation loss: 2.286045456431055

Epoch: 5| Step: 2
Training loss: 1.9201694146554864
Validation loss: 2.27638607827027

Epoch: 5| Step: 3
Training loss: 0.9264944363533542
Validation loss: 2.344328097894931

Epoch: 5| Step: 4
Training loss: 1.074391964905518
Validation loss: 2.2172591755482234

Epoch: 5| Step: 5
Training loss: 1.6675234340868377
Validation loss: 2.3681544224304263

Epoch: 5| Step: 6
Training loss: 1.2021929115231127
Validation loss: 2.332060324543861

Epoch: 5| Step: 7
Training loss: 0.8317037304918296
Validation loss: 2.2890627911875594

Epoch: 5| Step: 8
Training loss: 1.318154507013285
Validation loss: 2.30457223666899

Epoch: 5| Step: 9
Training loss: 1.0358111918735824
Validation loss: 2.3487717938421806

Epoch: 5| Step: 10
Training loss: 0.8701480470401878
Validation loss: 2.328982551017388

Epoch: 420| Step: 0
Training loss: 1.1187041331857193
Validation loss: 2.273546711357527

Epoch: 5| Step: 1
Training loss: 1.2360591746550411
Validation loss: 2.294927835799282

Epoch: 5| Step: 2
Training loss: 1.382094245195176
Validation loss: 2.289004055667094

Epoch: 5| Step: 3
Training loss: 1.0189332340892685
Validation loss: 2.313032026432119

Epoch: 5| Step: 4
Training loss: 0.757639049068084
Validation loss: 2.29447721168348

Epoch: 5| Step: 5
Training loss: 1.0458314733501375
Validation loss: 2.2839673830238874

Epoch: 5| Step: 6
Training loss: 1.1535305312886133
Validation loss: 2.353953779219456

Epoch: 5| Step: 7
Training loss: 1.9939401135342767
Validation loss: 2.3037452769789

Epoch: 5| Step: 8
Training loss: 1.25820926071419
Validation loss: 2.2682416595385826

Epoch: 5| Step: 9
Training loss: 1.3023919566293904
Validation loss: 2.3664757537041

Epoch: 5| Step: 10
Training loss: 0.8699149465092298
Validation loss: 2.2406250194965405

Epoch: 421| Step: 0
Training loss: 1.1858484930882065
Validation loss: 2.3080707892814236

Epoch: 5| Step: 1
Training loss: 1.551165324197048
Validation loss: 2.309708806772779

Epoch: 5| Step: 2
Training loss: 1.3759101109807812
Validation loss: 2.251031916989009

Epoch: 5| Step: 3
Training loss: 1.8894015680755023
Validation loss: 2.2334751600748186

Epoch: 5| Step: 4
Training loss: 0.9290102246792518
Validation loss: 2.3010912827912877

Epoch: 5| Step: 5
Training loss: 0.8161311804148428
Validation loss: 2.3366288638701365

Epoch: 5| Step: 6
Training loss: 0.9885957843101797
Validation loss: 2.3229810739913157

Epoch: 5| Step: 7
Training loss: 1.0330643154998176
Validation loss: 2.2694772086238886

Epoch: 5| Step: 8
Training loss: 1.2815201637327878
Validation loss: 2.339274145209495

Epoch: 5| Step: 9
Training loss: 1.169818446916327
Validation loss: 2.277095115455583

Epoch: 5| Step: 10
Training loss: 1.010702852967258
Validation loss: 2.267826188677882

Epoch: 422| Step: 0
Training loss: 1.3671392813762637
Validation loss: 2.2636850755475044

Epoch: 5| Step: 1
Training loss: 0.9495087168927692
Validation loss: 2.285103190699788

Epoch: 5| Step: 2
Training loss: 1.3322062894752018
Validation loss: 2.3051867484318493

Epoch: 5| Step: 3
Training loss: 1.0727830760464334
Validation loss: 2.299203126540038

Epoch: 5| Step: 4
Training loss: 1.1413702424497194
Validation loss: 2.283725478173241

Epoch: 5| Step: 5
Training loss: 1.4316150616162875
Validation loss: 2.330281626047146

Epoch: 5| Step: 6
Training loss: 1.1012203686264208
Validation loss: 2.308287736625908

Epoch: 5| Step: 7
Training loss: 1.7402381425981592
Validation loss: 2.2641168889689545

Epoch: 5| Step: 8
Training loss: 1.294123384710332
Validation loss: 2.2842514205766387

Epoch: 5| Step: 9
Training loss: 1.0264637009733435
Validation loss: 2.3567686788091

Epoch: 5| Step: 10
Training loss: 1.1061488239983013
Validation loss: 2.286764030605636

Epoch: 423| Step: 0
Training loss: 1.0537003595282592
Validation loss: 2.308602226256616

Epoch: 5| Step: 1
Training loss: 1.9067891093377405
Validation loss: 2.2983437840083596

Epoch: 5| Step: 2
Training loss: 1.3579212175924884
Validation loss: 2.23433025236992

Epoch: 5| Step: 3
Training loss: 1.0992787272256843
Validation loss: 2.3971808921733406

Epoch: 5| Step: 4
Training loss: 1.1814837391009188
Validation loss: 2.2861595832257517

Epoch: 5| Step: 5
Training loss: 1.3211568807161946
Validation loss: 2.327587738778391

Epoch: 5| Step: 6
Training loss: 0.9750589621884194
Validation loss: 2.2292964762568612

Epoch: 5| Step: 7
Training loss: 0.9355401853190822
Validation loss: 2.250929246908386

Epoch: 5| Step: 8
Training loss: 1.2114753759119663
Validation loss: 2.3122753886743372

Epoch: 5| Step: 9
Training loss: 1.3086217165563343
Validation loss: 2.233124810966588

Epoch: 5| Step: 10
Training loss: 0.871721358075696
Validation loss: 2.2934502299477026

Epoch: 424| Step: 0
Training loss: 1.0356022287926057
Validation loss: 2.3411952620386907

Epoch: 5| Step: 1
Training loss: 1.1434717058651944
Validation loss: 2.262605640331642

Epoch: 5| Step: 2
Training loss: 1.1051155307840013
Validation loss: 2.279793418570414

Epoch: 5| Step: 3
Training loss: 1.2773453832026782
Validation loss: 2.3270188246198855

Epoch: 5| Step: 4
Training loss: 1.1312431250937613
Validation loss: 2.320042659906911

Epoch: 5| Step: 5
Training loss: 1.0311745124700507
Validation loss: 2.343477206744925

Epoch: 5| Step: 6
Training loss: 1.7360111801209355
Validation loss: 2.377039792791791

Epoch: 5| Step: 7
Training loss: 1.2851994284011468
Validation loss: 2.319172351156581

Epoch: 5| Step: 8
Training loss: 1.3181756237685691
Validation loss: 2.266746037144373

Epoch: 5| Step: 9
Training loss: 1.0799477689969996
Validation loss: 2.2967439756007724

Epoch: 5| Step: 10
Training loss: 1.1504381361057223
Validation loss: 2.2748603908230782

Epoch: 425| Step: 0
Training loss: 0.8522308946226537
Validation loss: 2.300766047151666

Epoch: 5| Step: 1
Training loss: 1.211884257697816
Validation loss: 2.3453976959979963

Epoch: 5| Step: 2
Training loss: 1.0917725261777866
Validation loss: 2.282369333699512

Epoch: 5| Step: 3
Training loss: 1.1269973931303567
Validation loss: 2.343846731616665

Epoch: 5| Step: 4
Training loss: 1.3034141402711015
Validation loss: 2.3404479230031123

Epoch: 5| Step: 5
Training loss: 1.1263946789144414
Validation loss: 2.296045375209532

Epoch: 5| Step: 6
Training loss: 1.6193109843749691
Validation loss: 2.2451751516946445

Epoch: 5| Step: 7
Training loss: 1.409133201884542
Validation loss: 2.2599509492706242

Epoch: 5| Step: 8
Training loss: 1.9144016510356539
Validation loss: 2.300552641775573

Epoch: 5| Step: 9
Training loss: 1.1783128522867239
Validation loss: 2.2452887263699908

Epoch: 5| Step: 10
Training loss: 1.1174504430821288
Validation loss: 2.3367010620407487

Epoch: 426| Step: 0
Training loss: 1.2060733191406248
Validation loss: 2.2999273116252112

Epoch: 5| Step: 1
Training loss: 1.5947796356657644
Validation loss: 2.2791408521234096

Epoch: 5| Step: 2
Training loss: 1.162345849348209
Validation loss: 2.3054526205946275

Epoch: 5| Step: 3
Training loss: 0.8075018250294189
Validation loss: 2.324082730881117

Epoch: 5| Step: 4
Training loss: 1.2085252423094577
Validation loss: 2.2548599760376034

Epoch: 5| Step: 5
Training loss: 1.045418309443189
Validation loss: 2.365304191299172

Epoch: 5| Step: 6
Training loss: 1.8071555563675967
Validation loss: 2.3166542498041194

Epoch: 5| Step: 7
Training loss: 1.1353729251286977
Validation loss: 2.325401152504039

Epoch: 5| Step: 8
Training loss: 0.9946364569623188
Validation loss: 2.319504698161352

Epoch: 5| Step: 9
Training loss: 0.8781486127943544
Validation loss: 2.3195231591367342

Epoch: 5| Step: 10
Training loss: 1.2280573391900815
Validation loss: 2.2812687784147747

Epoch: 427| Step: 0
Training loss: 1.0556759758629062
Validation loss: 2.2609753312209873

Epoch: 5| Step: 1
Training loss: 1.0030935835152315
Validation loss: 2.2481437589457594

Epoch: 5| Step: 2
Training loss: 0.8162071678876033
Validation loss: 2.247484362947285

Epoch: 5| Step: 3
Training loss: 1.54625635588318
Validation loss: 2.243299130584925

Epoch: 5| Step: 4
Training loss: 1.882403697353352
Validation loss: 2.3086970231766113

Epoch: 5| Step: 5
Training loss: 1.0316164926048492
Validation loss: 2.298796238578199

Epoch: 5| Step: 6
Training loss: 1.1110644304218293
Validation loss: 2.340946889378522

Epoch: 5| Step: 7
Training loss: 1.5034414390523463
Validation loss: 2.2660667840189004

Epoch: 5| Step: 8
Training loss: 0.9774581769010835
Validation loss: 2.2841461650145325

Epoch: 5| Step: 9
Training loss: 1.2460498861885685
Validation loss: 2.2764083091297547

Epoch: 5| Step: 10
Training loss: 1.0546979550443893
Validation loss: 2.2320298665948366

Epoch: 428| Step: 0
Training loss: 2.011462860128668
Validation loss: 2.321444593248292

Epoch: 5| Step: 1
Training loss: 1.3066622927569798
Validation loss: 2.2830899884593823

Epoch: 5| Step: 2
Training loss: 1.2474481283652785
Validation loss: 2.2521858843190605

Epoch: 5| Step: 3
Training loss: 1.1465250817111934
Validation loss: 2.2830998007425887

Epoch: 5| Step: 4
Training loss: 1.0479156104828888
Validation loss: 2.3244795833083796

Epoch: 5| Step: 5
Training loss: 1.2151063101769073
Validation loss: 2.316210076788291

Epoch: 5| Step: 6
Training loss: 0.7605601571622449
Validation loss: 2.3325081727133186

Epoch: 5| Step: 7
Training loss: 1.1932133212203693
Validation loss: 2.251923936039021

Epoch: 5| Step: 8
Training loss: 1.491270492553601
Validation loss: 2.3070178914743122

Epoch: 5| Step: 9
Training loss: 1.0953393015935928
Validation loss: 2.301760976176118

Epoch: 5| Step: 10
Training loss: 1.0043392212529818
Validation loss: 2.3626065017681417

Epoch: 429| Step: 0
Training loss: 0.9704101243104993
Validation loss: 2.2980162939765254

Epoch: 5| Step: 1
Training loss: 1.1777409542273216
Validation loss: 2.3724013091508476

Epoch: 5| Step: 2
Training loss: 0.7940910177503211
Validation loss: 2.3277275724612263

Epoch: 5| Step: 3
Training loss: 1.130561960802567
Validation loss: 2.358697542024723

Epoch: 5| Step: 4
Training loss: 1.1986880541598834
Validation loss: 2.2546743646388787

Epoch: 5| Step: 5
Training loss: 1.3528179005219647
Validation loss: 2.3478594370190278

Epoch: 5| Step: 6
Training loss: 1.407424351639465
Validation loss: 2.269913622533765

Epoch: 5| Step: 7
Training loss: 1.7934561006838043
Validation loss: 2.25037657982885

Epoch: 5| Step: 8
Training loss: 1.2396398846631898
Validation loss: 2.339536670652704

Epoch: 5| Step: 9
Training loss: 0.9927494530235595
Validation loss: 2.265759968087875

Epoch: 5| Step: 10
Training loss: 1.0578891901026646
Validation loss: 2.254158539776623

Epoch: 430| Step: 0
Training loss: 0.6809414663632591
Validation loss: 2.327774522499294

Epoch: 5| Step: 1
Training loss: 1.1125365326272927
Validation loss: 2.3119106988582705

Epoch: 5| Step: 2
Training loss: 0.9412504201738653
Validation loss: 2.317896934395012

Epoch: 5| Step: 3
Training loss: 1.3007606298513439
Validation loss: 2.277362700212019

Epoch: 5| Step: 4
Training loss: 0.948768728822747
Validation loss: 2.347274147759141

Epoch: 5| Step: 5
Training loss: 1.4013517478597417
Validation loss: 2.229736438357334

Epoch: 5| Step: 6
Training loss: 1.1422013142346579
Validation loss: 2.2831806116592355

Epoch: 5| Step: 7
Training loss: 1.216911298291768
Validation loss: 2.3167870407129114

Epoch: 5| Step: 8
Training loss: 1.0980064403643837
Validation loss: 2.2928853300794727

Epoch: 5| Step: 9
Training loss: 1.7818780427637149
Validation loss: 2.316401702434256

Epoch: 5| Step: 10
Training loss: 1.4123794065326203
Validation loss: 2.3318696338682643

Epoch: 431| Step: 0
Training loss: 1.0417440131399671
Validation loss: 2.3115910520552254

Epoch: 5| Step: 1
Training loss: 1.3225946059398064
Validation loss: 2.246388497080081

Epoch: 5| Step: 2
Training loss: 1.1394587786367176
Validation loss: 2.2868658143669407

Epoch: 5| Step: 3
Training loss: 1.280926035420023
Validation loss: 2.2897655002953354

Epoch: 5| Step: 4
Training loss: 1.0104562548455738
Validation loss: 2.265865873517472

Epoch: 5| Step: 5
Training loss: 0.8826454477160698
Validation loss: 2.2971945841590498

Epoch: 5| Step: 6
Training loss: 1.0436473453316721
Validation loss: 2.354417068496423

Epoch: 5| Step: 7
Training loss: 1.977936158047701
Validation loss: 2.319718538273406

Epoch: 5| Step: 8
Training loss: 1.0239622212384993
Validation loss: 2.2681449728615886

Epoch: 5| Step: 9
Training loss: 1.1904063046469164
Validation loss: 2.335346267413538

Epoch: 5| Step: 10
Training loss: 1.0942427478922112
Validation loss: 2.2473558409915957

Epoch: 432| Step: 0
Training loss: 1.317388241857789
Validation loss: 2.2802216755698006

Epoch: 5| Step: 1
Training loss: 0.8075636415824087
Validation loss: 2.223397691313659

Epoch: 5| Step: 2
Training loss: 0.9168074059094893
Validation loss: 2.274947679989238

Epoch: 5| Step: 3
Training loss: 1.2086421254099033
Validation loss: 2.3498906477535506

Epoch: 5| Step: 4
Training loss: 2.043099685470111
Validation loss: 2.268345480892965

Epoch: 5| Step: 5
Training loss: 1.084233215912816
Validation loss: 2.2589953370358598

Epoch: 5| Step: 6
Training loss: 0.8203758578582979
Validation loss: 2.2483436932557668

Epoch: 5| Step: 7
Training loss: 1.2186293419997232
Validation loss: 2.3471970911685647

Epoch: 5| Step: 8
Training loss: 1.1957493401425292
Validation loss: 2.3752382976020163

Epoch: 5| Step: 9
Training loss: 0.9799478370544147
Validation loss: 2.270249336729856

Epoch: 5| Step: 10
Training loss: 0.629097429680595
Validation loss: 2.2690547274611164

Epoch: 433| Step: 0
Training loss: 1.411681473139038
Validation loss: 2.3050089516524945

Epoch: 5| Step: 1
Training loss: 1.3269925843515291
Validation loss: 2.229004124199316

Epoch: 5| Step: 2
Training loss: 1.1510154180281218
Validation loss: 2.30768946569771

Epoch: 5| Step: 3
Training loss: 0.91451268643756
Validation loss: 2.275610779191173

Epoch: 5| Step: 4
Training loss: 1.8609887180919062
Validation loss: 2.2663029387326423

Epoch: 5| Step: 5
Training loss: 1.1194656725549064
Validation loss: 2.35428006741833

Epoch: 5| Step: 6
Training loss: 1.0818147959229978
Validation loss: 2.3013983168405274

Epoch: 5| Step: 7
Training loss: 1.0170809360357649
Validation loss: 2.288681521027127

Epoch: 5| Step: 8
Training loss: 0.8537166542031128
Validation loss: 2.2823784689640174

Epoch: 5| Step: 9
Training loss: 1.1182193925652772
Validation loss: 2.367416229455239

Epoch: 5| Step: 10
Training loss: 0.8385999473710957
Validation loss: 2.301819788797201

Epoch: 434| Step: 0
Training loss: 1.0263148039454002
Validation loss: 2.3405595663346

Epoch: 5| Step: 1
Training loss: 0.9996772185569337
Validation loss: 2.250664716210343

Epoch: 5| Step: 2
Training loss: 1.2864635740268644
Validation loss: 2.336089968776997

Epoch: 5| Step: 3
Training loss: 0.9090335126119081
Validation loss: 2.27521040514907

Epoch: 5| Step: 4
Training loss: 1.363057596393311
Validation loss: 2.348717877318532

Epoch: 5| Step: 5
Training loss: 0.9368865549241476
Validation loss: 2.3049971044229176

Epoch: 5| Step: 6
Training loss: 1.8189628083305056
Validation loss: 2.3156763720594773

Epoch: 5| Step: 7
Training loss: 1.1491081718806908
Validation loss: 2.3214879938352335

Epoch: 5| Step: 8
Training loss: 1.2501490504092445
Validation loss: 2.326090224449768

Epoch: 5| Step: 9
Training loss: 1.059764594623474
Validation loss: 2.2739303244152236

Epoch: 5| Step: 10
Training loss: 1.203990228831921
Validation loss: 2.3000634309066017

Epoch: 435| Step: 0
Training loss: 1.1555296226081682
Validation loss: 2.351723472452917

Epoch: 5| Step: 1
Training loss: 0.9344214756356902
Validation loss: 2.2845245551187086

Epoch: 5| Step: 2
Training loss: 1.4309693306995899
Validation loss: 2.2406671643507186

Epoch: 5| Step: 3
Training loss: 0.7448219124225757
Validation loss: 2.22184284925907

Epoch: 5| Step: 4
Training loss: 1.3033571141765348
Validation loss: 2.247722012644629

Epoch: 5| Step: 5
Training loss: 1.882225863290443
Validation loss: 2.3253292550559426

Epoch: 5| Step: 6
Training loss: 1.1569441696254184
Validation loss: 2.2474958871186494

Epoch: 5| Step: 7
Training loss: 1.0980166457882596
Validation loss: 2.299103803525406

Epoch: 5| Step: 8
Training loss: 0.9074062337853359
Validation loss: 2.308078539933787

Epoch: 5| Step: 9
Training loss: 0.888690587779459
Validation loss: 2.364829056385123

Epoch: 5| Step: 10
Training loss: 1.1504060650292907
Validation loss: 2.3388713724196237

Epoch: 436| Step: 0
Training loss: 1.0945029800325676
Validation loss: 2.2885575003957936

Epoch: 5| Step: 1
Training loss: 1.3418493357790677
Validation loss: 2.3270458851396065

Epoch: 5| Step: 2
Training loss: 1.0271188468029218
Validation loss: 2.276916863525387

Epoch: 5| Step: 3
Training loss: 1.0396670540306134
Validation loss: 2.3066669265439406

Epoch: 5| Step: 4
Training loss: 1.23772420297151
Validation loss: 2.2494015906265914

Epoch: 5| Step: 5
Training loss: 1.2286744613945266
Validation loss: 2.238458360512884

Epoch: 5| Step: 6
Training loss: 1.3217604332734523
Validation loss: 2.3262071232892283

Epoch: 5| Step: 7
Training loss: 1.1869239915938106
Validation loss: 2.328303954921789

Epoch: 5| Step: 8
Training loss: 0.7354781205289692
Validation loss: 2.2793262398007417

Epoch: 5| Step: 9
Training loss: 1.0342385884947045
Validation loss: 2.310231134256181

Epoch: 5| Step: 10
Training loss: 2.086011678112547
Validation loss: 2.300350806977155

Epoch: 437| Step: 0
Training loss: 1.2178088246506147
Validation loss: 2.2923730457000775

Epoch: 5| Step: 1
Training loss: 0.6785228441169507
Validation loss: 2.345462609246379

Epoch: 5| Step: 2
Training loss: 1.409829564175902
Validation loss: 2.3252553080059006

Epoch: 5| Step: 3
Training loss: 1.020555646587523
Validation loss: 2.3266210759023043

Epoch: 5| Step: 4
Training loss: 0.8078519948014987
Validation loss: 2.3269892508124905

Epoch: 5| Step: 5
Training loss: 1.3319471226412132
Validation loss: 2.3357756130538165

Epoch: 5| Step: 6
Training loss: 1.0765212473280736
Validation loss: 2.3130871981477616

Epoch: 5| Step: 7
Training loss: 1.7555707412108548
Validation loss: 2.3675626613628995

Epoch: 5| Step: 8
Training loss: 1.2222809139281774
Validation loss: 2.318006053430171

Epoch: 5| Step: 9
Training loss: 1.1844928712996667
Validation loss: 2.299513221874757

Epoch: 5| Step: 10
Training loss: 1.1893178176965475
Validation loss: 2.2512416071488595

Epoch: 438| Step: 0
Training loss: 1.2551484891731564
Validation loss: 2.3276307310242825

Epoch: 5| Step: 1
Training loss: 1.7608742730502118
Validation loss: 2.292979456926218

Epoch: 5| Step: 2
Training loss: 0.8307995342877791
Validation loss: 2.3536114106386865

Epoch: 5| Step: 3
Training loss: 1.1551642088149578
Validation loss: 2.338604833553399

Epoch: 5| Step: 4
Training loss: 1.1147648078326775
Validation loss: 2.2978402752539333

Epoch: 5| Step: 5
Training loss: 1.1645874785393295
Validation loss: 2.319675568476378

Epoch: 5| Step: 6
Training loss: 0.8788314109304715
Validation loss: 2.348824329527015

Epoch: 5| Step: 7
Training loss: 1.3594551062822962
Validation loss: 2.2840966402200484

Epoch: 5| Step: 8
Training loss: 1.028252203588631
Validation loss: 2.2933613858393604

Epoch: 5| Step: 9
Training loss: 1.0653487331218674
Validation loss: 2.244604142618594

Epoch: 5| Step: 10
Training loss: 1.3204598429249348
Validation loss: 2.2868397850694175

Epoch: 439| Step: 0
Training loss: 1.4812191795007743
Validation loss: 2.3213574953251914

Epoch: 5| Step: 1
Training loss: 1.0009427395200245
Validation loss: 2.27939333944748

Epoch: 5| Step: 2
Training loss: 0.8814312755194801
Validation loss: 2.2836621127344947

Epoch: 5| Step: 3
Training loss: 1.3446057278510124
Validation loss: 2.307612669273698

Epoch: 5| Step: 4
Training loss: 2.0432000403103268
Validation loss: 2.3237222821168677

Epoch: 5| Step: 5
Training loss: 0.9043128916432224
Validation loss: 2.400111841173169

Epoch: 5| Step: 6
Training loss: 1.0716042068121205
Validation loss: 2.233203717763501

Epoch: 5| Step: 7
Training loss: 1.1461323030172355
Validation loss: 2.258182003038262

Epoch: 5| Step: 8
Training loss: 1.216099669446854
Validation loss: 2.274597050427196

Epoch: 5| Step: 9
Training loss: 1.1088165166915527
Validation loss: 2.281057560100481

Epoch: 5| Step: 10
Training loss: 0.9189444368623784
Validation loss: 2.2525391095495295

Epoch: 440| Step: 0
Training loss: 1.0796147985865265
Validation loss: 2.304796921301779

Epoch: 5| Step: 1
Training loss: 0.8267073102414425
Validation loss: 2.306707384657139

Epoch: 5| Step: 2
Training loss: 1.1111461309371373
Validation loss: 2.2516479370770544

Epoch: 5| Step: 3
Training loss: 1.3160714196243775
Validation loss: 2.3170800720235913

Epoch: 5| Step: 4
Training loss: 1.8474679734031234
Validation loss: 2.388127838738616

Epoch: 5| Step: 5
Training loss: 1.0668112855466643
Validation loss: 2.280624207730955

Epoch: 5| Step: 6
Training loss: 1.272172826440119
Validation loss: 2.303622575921874

Epoch: 5| Step: 7
Training loss: 1.2762923273433522
Validation loss: 2.276277128153016

Epoch: 5| Step: 8
Training loss: 0.7816865845550816
Validation loss: 2.231583042830349

Epoch: 5| Step: 9
Training loss: 0.9941789361133204
Validation loss: 2.241224366423797

Epoch: 5| Step: 10
Training loss: 0.8609725321930709
Validation loss: 2.2282549698009184

Epoch: 441| Step: 0
Training loss: 1.1681323495044824
Validation loss: 2.29470814690826

Epoch: 5| Step: 1
Training loss: 1.3175601599492333
Validation loss: 2.3515033948204587

Epoch: 5| Step: 2
Training loss: 1.703589979620845
Validation loss: 2.3094191034227403

Epoch: 5| Step: 3
Training loss: 1.5138381965074994
Validation loss: 2.234821161732958

Epoch: 5| Step: 4
Training loss: 1.0455456734509074
Validation loss: 2.291903743245701

Epoch: 5| Step: 5
Training loss: 0.8256249026255872
Validation loss: 2.2223508583116303

Epoch: 5| Step: 6
Training loss: 1.0883114341608378
Validation loss: 2.2989383872184757

Epoch: 5| Step: 7
Training loss: 0.8017549131389796
Validation loss: 2.2888172912463904

Epoch: 5| Step: 8
Training loss: 0.925817818865044
Validation loss: 2.2910755375779193

Epoch: 5| Step: 9
Training loss: 1.2910701953706427
Validation loss: 2.17329695123094

Epoch: 5| Step: 10
Training loss: 1.1192489491709774
Validation loss: 2.2455717671393063

Epoch: 442| Step: 0
Training loss: 1.1948620813978144
Validation loss: 2.307599246745449

Epoch: 5| Step: 1
Training loss: 0.7261966071141774
Validation loss: 2.3168694816452446

Epoch: 5| Step: 2
Training loss: 0.7262310379494322
Validation loss: 2.2747888501558475

Epoch: 5| Step: 3
Training loss: 1.5494826714825995
Validation loss: 2.312489979330633

Epoch: 5| Step: 4
Training loss: 0.921890323317597
Validation loss: 2.2863743471572135

Epoch: 5| Step: 5
Training loss: 1.7549460542435638
Validation loss: 2.318948383898107

Epoch: 5| Step: 6
Training loss: 1.2270592819386954
Validation loss: 2.303006383341652

Epoch: 5| Step: 7
Training loss: 0.9759377884658256
Validation loss: 2.3113863335632447

Epoch: 5| Step: 8
Training loss: 1.207910310207212
Validation loss: 2.247120028137081

Epoch: 5| Step: 9
Training loss: 0.8805756714692916
Validation loss: 2.3375821331502147

Epoch: 5| Step: 10
Training loss: 1.1814158832796526
Validation loss: 2.219773118032503

Epoch: 443| Step: 0
Training loss: 1.069678682764007
Validation loss: 2.2561947238107076

Epoch: 5| Step: 1
Training loss: 1.3177649846420019
Validation loss: 2.2279328546834414

Epoch: 5| Step: 2
Training loss: 1.8587388946057788
Validation loss: 2.2794832093222483

Epoch: 5| Step: 3
Training loss: 1.6148447953042244
Validation loss: 2.3129710227979854

Epoch: 5| Step: 4
Training loss: 1.2409896833465894
Validation loss: 2.2630199217745224

Epoch: 5| Step: 5
Training loss: 0.807273376421722
Validation loss: 2.389232902555838

Epoch: 5| Step: 6
Training loss: 1.016968645263269
Validation loss: 2.322589768677513

Epoch: 5| Step: 7
Training loss: 0.7226732406680837
Validation loss: 2.3168411525877217

Epoch: 5| Step: 8
Training loss: 0.9664953204642108
Validation loss: 2.2993084259260907

Epoch: 5| Step: 9
Training loss: 1.0504200821644083
Validation loss: 2.2080521287460284

Epoch: 5| Step: 10
Training loss: 1.0689381037921557
Validation loss: 2.300453091738683

Epoch: 444| Step: 0
Training loss: 1.2423819623637489
Validation loss: 2.2999479993726255

Epoch: 5| Step: 1
Training loss: 0.8203866834248843
Validation loss: 2.3423565326981146

Epoch: 5| Step: 2
Training loss: 1.0075025451476556
Validation loss: 2.357061594815194

Epoch: 5| Step: 3
Training loss: 1.81731708618891
Validation loss: 2.2569493314586535

Epoch: 5| Step: 4
Training loss: 1.0763514761763597
Validation loss: 2.2901454403450487

Epoch: 5| Step: 5
Training loss: 1.1052077022242683
Validation loss: 2.2710337573456996

Epoch: 5| Step: 6
Training loss: 1.3083230720814152
Validation loss: 2.316045385243568

Epoch: 5| Step: 7
Training loss: 1.176755077311396
Validation loss: 2.3352509769457708

Epoch: 5| Step: 8
Training loss: 1.1411381442520303
Validation loss: 2.3014726725787367

Epoch: 5| Step: 9
Training loss: 0.9641680185203559
Validation loss: 2.3083657972064593

Epoch: 5| Step: 10
Training loss: 1.0648835318194811
Validation loss: 2.2870682171066044

Epoch: 445| Step: 0
Training loss: 1.065958061635041
Validation loss: 2.304287358512675

Epoch: 5| Step: 1
Training loss: 1.4866448965887809
Validation loss: 2.309772693541521

Epoch: 5| Step: 2
Training loss: 1.8416291015844461
Validation loss: 2.279712586545053

Epoch: 5| Step: 3
Training loss: 1.0323978162914593
Validation loss: 2.28531942865613

Epoch: 5| Step: 4
Training loss: 1.0979364112270549
Validation loss: 2.3861500820333883

Epoch: 5| Step: 5
Training loss: 1.2552765581048566
Validation loss: 2.366189621321432

Epoch: 5| Step: 6
Training loss: 1.1426490174821904
Validation loss: 2.371020686383224

Epoch: 5| Step: 7
Training loss: 1.0038564944275745
Validation loss: 2.344829704952223

Epoch: 5| Step: 8
Training loss: 1.1137354944656699
Validation loss: 2.2939296597845455

Epoch: 5| Step: 9
Training loss: 0.8165301726256508
Validation loss: 2.3546533548871675

Epoch: 5| Step: 10
Training loss: 1.4602707754158368
Validation loss: 2.2942000134166003

Epoch: 446| Step: 0
Training loss: 0.9223603732707931
Validation loss: 2.3079259534801815

Epoch: 5| Step: 1
Training loss: 0.7571319591825258
Validation loss: 2.209466368020926

Epoch: 5| Step: 2
Training loss: 1.8759397059269889
Validation loss: 2.330567061304402

Epoch: 5| Step: 3
Training loss: 1.0750685780851654
Validation loss: 2.3350090771612617

Epoch: 5| Step: 4
Training loss: 1.3303476920299644
Validation loss: 2.26794884936675

Epoch: 5| Step: 5
Training loss: 1.103684404007317
Validation loss: 2.267918720057879

Epoch: 5| Step: 6
Training loss: 1.3069142965924336
Validation loss: 2.317589756770361

Epoch: 5| Step: 7
Training loss: 1.0401037061776544
Validation loss: 2.29842371764816

Epoch: 5| Step: 8
Training loss: 1.1128154650260078
Validation loss: 2.2989162292584373

Epoch: 5| Step: 9
Training loss: 0.8375554336877153
Validation loss: 2.2416307946542573

Epoch: 5| Step: 10
Training loss: 1.0925963175585003
Validation loss: 2.2613475892514288

Epoch: 447| Step: 0
Training loss: 1.108668465008618
Validation loss: 2.334419599908912

Epoch: 5| Step: 1
Training loss: 1.370809802787756
Validation loss: 2.2226934507184963

Epoch: 5| Step: 2
Training loss: 1.8244391559377562
Validation loss: 2.311912025083078

Epoch: 5| Step: 3
Training loss: 1.1050372140754252
Validation loss: 2.3191283133405687

Epoch: 5| Step: 4
Training loss: 1.2255585564826093
Validation loss: 2.327382533868499

Epoch: 5| Step: 5
Training loss: 0.9547934078528348
Validation loss: 2.2399168181667837

Epoch: 5| Step: 6
Training loss: 0.9440515162849604
Validation loss: 2.2350205970936976

Epoch: 5| Step: 7
Training loss: 0.9849081260899789
Validation loss: 2.2764801299897277

Epoch: 5| Step: 8
Training loss: 0.8954808221741113
Validation loss: 2.3289146936733616

Epoch: 5| Step: 9
Training loss: 1.044054587687312
Validation loss: 2.3028887737895887

Epoch: 5| Step: 10
Training loss: 1.2593785837278657
Validation loss: 2.2526286606408603

Epoch: 448| Step: 0
Training loss: 1.1925746004294309
Validation loss: 2.2915542224433207

Epoch: 5| Step: 1
Training loss: 1.0228593081198696
Validation loss: 2.313733897762954

Epoch: 5| Step: 2
Training loss: 1.186260982418373
Validation loss: 2.262146924699907

Epoch: 5| Step: 3
Training loss: 1.159806735118631
Validation loss: 2.302750341933452

Epoch: 5| Step: 4
Training loss: 0.7649985494786891
Validation loss: 2.2622460775248947

Epoch: 5| Step: 5
Training loss: 0.8623906715872302
Validation loss: 2.315482304303833

Epoch: 5| Step: 6
Training loss: 1.2579485896632818
Validation loss: 2.294963757777061

Epoch: 5| Step: 7
Training loss: 1.1311893805179385
Validation loss: 2.257990081033807

Epoch: 5| Step: 8
Training loss: 0.9505112251249008
Validation loss: 2.3017555671282177

Epoch: 5| Step: 9
Training loss: 0.9054425029225395
Validation loss: 2.3197538487031752

Epoch: 5| Step: 10
Training loss: 1.9318273008610716
Validation loss: 2.2988321608855955

Epoch: 449| Step: 0
Training loss: 1.20490979668238
Validation loss: 2.2749565317787503

Epoch: 5| Step: 1
Training loss: 1.1646062106010635
Validation loss: 2.270399900287433

Epoch: 5| Step: 2
Training loss: 0.6408123579755273
Validation loss: 2.3435624701836866

Epoch: 5| Step: 3
Training loss: 1.3998119057593907
Validation loss: 2.2641292603536627

Epoch: 5| Step: 4
Training loss: 1.0365554278468563
Validation loss: 2.2451736547361594

Epoch: 5| Step: 5
Training loss: 0.9753049459167911
Validation loss: 2.2934751849107817

Epoch: 5| Step: 6
Training loss: 0.9527061667808013
Validation loss: 2.254598647727851

Epoch: 5| Step: 7
Training loss: 1.7955083542674315
Validation loss: 2.2615472376208836

Epoch: 5| Step: 8
Training loss: 1.3866807099618534
Validation loss: 2.298322002911795

Epoch: 5| Step: 9
Training loss: 0.8644830614949045
Validation loss: 2.2801704347111387

Epoch: 5| Step: 10
Training loss: 1.1419586850023333
Validation loss: 2.291587372542543

Epoch: 450| Step: 0
Training loss: 0.7047974088432839
Validation loss: 2.225729272356491

Epoch: 5| Step: 1
Training loss: 1.123460882418405
Validation loss: 2.327462486320854

Epoch: 5| Step: 2
Training loss: 1.0759976171516779
Validation loss: 2.28560858113925

Epoch: 5| Step: 3
Training loss: 1.5828420562846544
Validation loss: 2.2975271110002278

Epoch: 5| Step: 4
Training loss: 1.8543458773412527
Validation loss: 2.3631131161101733

Epoch: 5| Step: 5
Training loss: 1.052171489434016
Validation loss: 2.259167655360911

Epoch: 5| Step: 6
Training loss: 0.912718314353031
Validation loss: 2.293982909425709

Epoch: 5| Step: 7
Training loss: 1.1092182102355204
Validation loss: 2.3196657909985228

Epoch: 5| Step: 8
Training loss: 0.9101931846884864
Validation loss: 2.307818029109088

Epoch: 5| Step: 9
Training loss: 1.0841256814218019
Validation loss: 2.2828706487522767

Epoch: 5| Step: 10
Training loss: 0.7855427108798446
Validation loss: 2.3511599982981997

Epoch: 451| Step: 0
Training loss: 0.8168484161184137
Validation loss: 2.2916972862129663

Epoch: 5| Step: 1
Training loss: 1.0849625856127785
Validation loss: 2.3234893969794097

Epoch: 5| Step: 2
Training loss: 0.9323283602066254
Validation loss: 2.286721413552927

Epoch: 5| Step: 3
Training loss: 0.834535367605925
Validation loss: 2.2451759338579107

Epoch: 5| Step: 4
Training loss: 1.3438077515013058
Validation loss: 2.2999340026503416

Epoch: 5| Step: 5
Training loss: 0.8634696513211952
Validation loss: 2.4239849953948003

Epoch: 5| Step: 6
Training loss: 1.1766753488351818
Validation loss: 2.2709972265624883

Epoch: 5| Step: 7
Training loss: 1.3750361957987778
Validation loss: 2.3202821932538695

Epoch: 5| Step: 8
Training loss: 1.818711260091334
Validation loss: 2.3376451117475843

Epoch: 5| Step: 9
Training loss: 1.1245676905441686
Validation loss: 2.3077104651775637

Epoch: 5| Step: 10
Training loss: 1.2394857715499423
Validation loss: 2.321548004260396

Epoch: 452| Step: 0
Training loss: 0.8545398633463176
Validation loss: 2.284716472969045

Epoch: 5| Step: 1
Training loss: 0.6351117642860481
Validation loss: 2.273097215321196

Epoch: 5| Step: 2
Training loss: 1.1720131856189628
Validation loss: 2.3249759324833033

Epoch: 5| Step: 3
Training loss: 1.2875416424877826
Validation loss: 2.3814369140575087

Epoch: 5| Step: 4
Training loss: 0.9055690509054481
Validation loss: 2.200004188355554

Epoch: 5| Step: 5
Training loss: 1.0134585823174103
Validation loss: 2.248114534209135

Epoch: 5| Step: 6
Training loss: 0.8852804340947374
Validation loss: 2.3404791231218676

Epoch: 5| Step: 7
Training loss: 1.0711218565210163
Validation loss: 2.355213988264699

Epoch: 5| Step: 8
Training loss: 1.0514961845267052
Validation loss: 2.2787871591833224

Epoch: 5| Step: 9
Training loss: 1.7327017746162496
Validation loss: 2.3432289342803525

Epoch: 5| Step: 10
Training loss: 1.1532165842464153
Validation loss: 2.3248522942789496

Epoch: 453| Step: 0
Training loss: 1.104981493643885
Validation loss: 2.2833464694949543

Epoch: 5| Step: 1
Training loss: 0.8892171339772095
Validation loss: 2.2684906971384153

Epoch: 5| Step: 2
Training loss: 1.0759957891225846
Validation loss: 2.2960665822309902

Epoch: 5| Step: 3
Training loss: 0.9474290529829918
Validation loss: 2.3142012302986537

Epoch: 5| Step: 4
Training loss: 0.9074915241339555
Validation loss: 2.313577971105001

Epoch: 5| Step: 5
Training loss: 1.0577054396394332
Validation loss: 2.2649668211701397

Epoch: 5| Step: 6
Training loss: 0.7112405571201778
Validation loss: 2.2720924189789873

Epoch: 5| Step: 7
Training loss: 1.2239693120369344
Validation loss: 2.212857395406264

Epoch: 5| Step: 8
Training loss: 1.2864864619136152
Validation loss: 2.3171359339927005

Epoch: 5| Step: 9
Training loss: 1.9098199029466847
Validation loss: 2.254536936857411

Epoch: 5| Step: 10
Training loss: 1.2299982533791398
Validation loss: 2.30743435280268

Epoch: 454| Step: 0
Training loss: 1.1321576560601705
Validation loss: 2.2595060497242585

Epoch: 5| Step: 1
Training loss: 1.2759300131184566
Validation loss: 2.3318334767582507

Epoch: 5| Step: 2
Training loss: 0.9665243978603131
Validation loss: 2.32568091566923

Epoch: 5| Step: 3
Training loss: 1.037691114816732
Validation loss: 2.290005700793498

Epoch: 5| Step: 4
Training loss: 1.8923963335435916
Validation loss: 2.2495018784796437

Epoch: 5| Step: 5
Training loss: 0.8582280915439516
Validation loss: 2.326594076554785

Epoch: 5| Step: 6
Training loss: 1.3537526108988684
Validation loss: 2.3415954279326163

Epoch: 5| Step: 7
Training loss: 0.8147193967415658
Validation loss: 2.2552754847981933

Epoch: 5| Step: 8
Training loss: 1.1131370584904638
Validation loss: 2.252506196832042

Epoch: 5| Step: 9
Training loss: 1.0144440460680146
Validation loss: 2.2946701868998183

Epoch: 5| Step: 10
Training loss: 0.8173940423082376
Validation loss: 2.320678795826354

Epoch: 455| Step: 0
Training loss: 1.0750628120346952
Validation loss: 2.2817948359822804

Epoch: 5| Step: 1
Training loss: 0.8805379682951292
Validation loss: 2.229166562395972

Epoch: 5| Step: 2
Training loss: 0.7357568118123236
Validation loss: 2.3508270648642218

Epoch: 5| Step: 3
Training loss: 1.7147553927309938
Validation loss: 2.2936132276195202

Epoch: 5| Step: 4
Training loss: 0.9169055381843126
Validation loss: 2.302592155081425

Epoch: 5| Step: 5
Training loss: 1.1699556017871782
Validation loss: 2.289966292134323

Epoch: 5| Step: 6
Training loss: 1.1877937957326727
Validation loss: 2.216092231231136

Epoch: 5| Step: 7
Training loss: 0.8415116891349428
Validation loss: 2.2668692912041655

Epoch: 5| Step: 8
Training loss: 1.2016801952565221
Validation loss: 2.288441829047801

Epoch: 5| Step: 9
Training loss: 0.9818042004056168
Validation loss: 2.2813446114081772

Epoch: 5| Step: 10
Training loss: 1.4192888824528458
Validation loss: 2.21311363950994

Epoch: 456| Step: 0
Training loss: 1.798974643170217
Validation loss: 2.2730732253715584

Epoch: 5| Step: 1
Training loss: 1.2343966325240516
Validation loss: 2.3316438230496925

Epoch: 5| Step: 2
Training loss: 1.0524526017269547
Validation loss: 2.247347880918825

Epoch: 5| Step: 3
Training loss: 0.8284959502089521
Validation loss: 2.313966950420057

Epoch: 5| Step: 4
Training loss: 1.1516693210617222
Validation loss: 2.284124031913313

Epoch: 5| Step: 5
Training loss: 1.049720313651546
Validation loss: 2.2432133401451915

Epoch: 5| Step: 6
Training loss: 0.9013930427587482
Validation loss: 2.180392675776448

Epoch: 5| Step: 7
Training loss: 0.9467614159269744
Validation loss: 2.265347120806251

Epoch: 5| Step: 8
Training loss: 1.1084552767123699
Validation loss: 2.3889863872004344

Epoch: 5| Step: 9
Training loss: 1.0822115861468826
Validation loss: 2.2600106440366163

Epoch: 5| Step: 10
Training loss: 0.6476610199645644
Validation loss: 2.202695012304669

Epoch: 457| Step: 0
Training loss: 0.9130735019102211
Validation loss: 2.353958610367072

Epoch: 5| Step: 1
Training loss: 1.008597194154563
Validation loss: 2.3347349842525347

Epoch: 5| Step: 2
Training loss: 1.6289775293063766
Validation loss: 2.2998215342171275

Epoch: 5| Step: 3
Training loss: 1.1419760658374933
Validation loss: 2.314911043028755

Epoch: 5| Step: 4
Training loss: 0.6430819776730915
Validation loss: 2.264240641666767

Epoch: 5| Step: 5
Training loss: 1.2391063456336142
Validation loss: 2.3235381290332375

Epoch: 5| Step: 6
Training loss: 1.0280243682310946
Validation loss: 2.278353242761125

Epoch: 5| Step: 7
Training loss: 0.8669929629857565
Validation loss: 2.3213449860775732

Epoch: 5| Step: 8
Training loss: 0.9873023632108985
Validation loss: 2.273095182991712

Epoch: 5| Step: 9
Training loss: 1.2491219297562386
Validation loss: 2.2849059758870895

Epoch: 5| Step: 10
Training loss: 1.2055123658117577
Validation loss: 2.295198352211735

Epoch: 458| Step: 0
Training loss: 1.0862341276705827
Validation loss: 2.3123864343057283

Epoch: 5| Step: 1
Training loss: 0.8550981737960713
Validation loss: 2.3819096837749725

Epoch: 5| Step: 2
Training loss: 0.9799027956224604
Validation loss: 2.328139380018112

Epoch: 5| Step: 3
Training loss: 1.1665756439850088
Validation loss: 2.3249705184529903

Epoch: 5| Step: 4
Training loss: 1.0158144847465798
Validation loss: 2.2933572564870954

Epoch: 5| Step: 5
Training loss: 0.8897572690554805
Validation loss: 2.2783595614055545

Epoch: 5| Step: 6
Training loss: 0.8572406273098918
Validation loss: 2.2792467544353436

Epoch: 5| Step: 7
Training loss: 1.2141440974127522
Validation loss: 2.285114247486746

Epoch: 5| Step: 8
Training loss: 1.0006403065165388
Validation loss: 2.266014077593939

Epoch: 5| Step: 9
Training loss: 1.1437167240993007
Validation loss: 2.251307074790978

Epoch: 5| Step: 10
Training loss: 1.8852838149782114
Validation loss: 2.2758301950913857

Epoch: 459| Step: 0
Training loss: 0.9918569479767666
Validation loss: 2.2071127529923578

Epoch: 5| Step: 1
Training loss: 1.0018035598575876
Validation loss: 2.2724033754215927

Epoch: 5| Step: 2
Training loss: 1.2689499213645956
Validation loss: 2.329464204806162

Epoch: 5| Step: 3
Training loss: 0.8450731569708207
Validation loss: 2.357988988798221

Epoch: 5| Step: 4
Training loss: 0.7726302895654188
Validation loss: 2.3246636254203232

Epoch: 5| Step: 5
Training loss: 1.7872493167971406
Validation loss: 2.2569897789158113

Epoch: 5| Step: 6
Training loss: 0.9992045576744496
Validation loss: 2.2479416331774393

Epoch: 5| Step: 7
Training loss: 0.9487779009590208
Validation loss: 2.2780710541842555

Epoch: 5| Step: 8
Training loss: 1.043008753548717
Validation loss: 2.2593861031988847

Epoch: 5| Step: 9
Training loss: 1.009853100999722
Validation loss: 2.2529662324553708

Epoch: 5| Step: 10
Training loss: 1.334239125536783
Validation loss: 2.302303081182923

Epoch: 460| Step: 0
Training loss: 1.801410821516285
Validation loss: 2.2428649139723147

Epoch: 5| Step: 1
Training loss: 0.9671712439531338
Validation loss: 2.3470849465481542

Epoch: 5| Step: 2
Training loss: 1.3422149939602064
Validation loss: 2.2939557561522848

Epoch: 5| Step: 3
Training loss: 0.6499456997345073
Validation loss: 2.182453781999444

Epoch: 5| Step: 4
Training loss: 1.1733996328042189
Validation loss: 2.251648932179967

Epoch: 5| Step: 5
Training loss: 0.7679552311837641
Validation loss: 2.2985079448400363

Epoch: 5| Step: 6
Training loss: 0.8749748975695248
Validation loss: 2.326692867321342

Epoch: 5| Step: 7
Training loss: 0.8543137020621988
Validation loss: 2.2953472624831903

Epoch: 5| Step: 8
Training loss: 1.2004718011978421
Validation loss: 2.272000058849968

Epoch: 5| Step: 9
Training loss: 1.100290795382744
Validation loss: 2.3189494827833625

Epoch: 5| Step: 10
Training loss: 1.2402304341411308
Validation loss: 2.316967442277053

Epoch: 461| Step: 0
Training loss: 0.9654225455083035
Validation loss: 2.369102387701806

Epoch: 5| Step: 1
Training loss: 0.7902366287418044
Validation loss: 2.2784561645512587

Epoch: 5| Step: 2
Training loss: 1.4327788570535247
Validation loss: 2.2479149741138924

Epoch: 5| Step: 3
Training loss: 0.7910126109124674
Validation loss: 2.2553885332323502

Epoch: 5| Step: 4
Training loss: 0.6255081256991215
Validation loss: 2.2740178699634535

Epoch: 5| Step: 5
Training loss: 0.9057966611142402
Validation loss: 2.269293335067487

Epoch: 5| Step: 6
Training loss: 1.3983473935214166
Validation loss: 2.258016605535471

Epoch: 5| Step: 7
Training loss: 0.9733175457910759
Validation loss: 2.337797879286153

Epoch: 5| Step: 8
Training loss: 1.7456544327704504
Validation loss: 2.3112618918651386

Epoch: 5| Step: 9
Training loss: 0.7918993499191512
Validation loss: 2.3048722621522977

Epoch: 5| Step: 10
Training loss: 0.838290565915351
Validation loss: 2.300939525696117

Epoch: 462| Step: 0
Training loss: 0.947000210732796
Validation loss: 2.2092319416276065

Epoch: 5| Step: 1
Training loss: 1.011639860752261
Validation loss: 2.2939660539156788

Epoch: 5| Step: 2
Training loss: 1.0513807664023027
Validation loss: 2.3176595625816296

Epoch: 5| Step: 3
Training loss: 1.0905593109023017
Validation loss: 2.2726301163428047

Epoch: 5| Step: 4
Training loss: 0.8794796916727116
Validation loss: 2.2293724786947067

Epoch: 5| Step: 5
Training loss: 1.2842063291853845
Validation loss: 2.266203064063782

Epoch: 5| Step: 6
Training loss: 1.0819518683334854
Validation loss: 2.2495408096629284

Epoch: 5| Step: 7
Training loss: 1.0404464568513774
Validation loss: 2.3017314000062874

Epoch: 5| Step: 8
Training loss: 1.7651072730514223
Validation loss: 2.2600420074323093

Epoch: 5| Step: 9
Training loss: 0.8472134888482007
Validation loss: 2.311688275981208

Epoch: 5| Step: 10
Training loss: 0.6846697594952891
Validation loss: 2.3298706741307504

Epoch: 463| Step: 0
Training loss: 1.8691239789741732
Validation loss: 2.2605701332247685

Epoch: 5| Step: 1
Training loss: 0.8702844187180122
Validation loss: 2.264327467305549

Epoch: 5| Step: 2
Training loss: 1.015534851768392
Validation loss: 2.2699443753250272

Epoch: 5| Step: 3
Training loss: 1.0750251656181549
Validation loss: 2.179456918779935

Epoch: 5| Step: 4
Training loss: 1.2161960251094412
Validation loss: 2.3207159684917986

Epoch: 5| Step: 5
Training loss: 0.9280929033271768
Validation loss: 2.2632741707118558

Epoch: 5| Step: 6
Training loss: 0.7270868521735472
Validation loss: 2.2431395507026406

Epoch: 5| Step: 7
Training loss: 0.8864917212420822
Validation loss: 2.3175389488702973

Epoch: 5| Step: 8
Training loss: 1.197675376585084
Validation loss: 2.35318834509645

Epoch: 5| Step: 9
Training loss: 1.1828678536407335
Validation loss: 2.3242250349525633

Epoch: 5| Step: 10
Training loss: 0.957245565279125
Validation loss: 2.265201477250216

Epoch: 464| Step: 0
Training loss: 1.2668056867671194
Validation loss: 2.29159998717491

Epoch: 5| Step: 1
Training loss: 0.9011064112927848
Validation loss: 2.267950875004131

Epoch: 5| Step: 2
Training loss: 0.8864831149219295
Validation loss: 2.2954845716602796

Epoch: 5| Step: 3
Training loss: 0.9611722767911299
Validation loss: 2.2576071598310294

Epoch: 5| Step: 4
Training loss: 1.0140176819006428
Validation loss: 2.355982446547792

Epoch: 5| Step: 5
Training loss: 1.248498300687942
Validation loss: 2.322553602867891

Epoch: 5| Step: 6
Training loss: 1.2487719225176324
Validation loss: 2.2163019512957622

Epoch: 5| Step: 7
Training loss: 0.6540449881726811
Validation loss: 2.292705226909749

Epoch: 5| Step: 8
Training loss: 1.1299836188791597
Validation loss: 2.3199600681838333

Epoch: 5| Step: 9
Training loss: 1.6457375929143276
Validation loss: 2.2814779714149003

Epoch: 5| Step: 10
Training loss: 0.9617049401389518
Validation loss: 2.3282493348336546

Epoch: 465| Step: 0
Training loss: 0.885451230141196
Validation loss: 2.273333663663743

Epoch: 5| Step: 1
Training loss: 1.1733099226801624
Validation loss: 2.3158738131470264

Epoch: 5| Step: 2
Training loss: 0.9763090491417332
Validation loss: 2.298555064544816

Epoch: 5| Step: 3
Training loss: 0.9288276414519419
Validation loss: 2.266884473711781

Epoch: 5| Step: 4
Training loss: 1.2192918111090192
Validation loss: 2.350049476041619

Epoch: 5| Step: 5
Training loss: 1.042414257082049
Validation loss: 2.318633380346809

Epoch: 5| Step: 6
Training loss: 0.9950107446406689
Validation loss: 2.32080894946826

Epoch: 5| Step: 7
Training loss: 1.7033666736726527
Validation loss: 2.3422571044899727

Epoch: 5| Step: 8
Training loss: 0.9712387541386212
Validation loss: 2.3089016447966006

Epoch: 5| Step: 9
Training loss: 1.219741515777285
Validation loss: 2.3490738091473258

Epoch: 5| Step: 10
Training loss: 1.1519440555829927
Validation loss: 2.302953750330862

Epoch: 466| Step: 0
Training loss: 1.0068843619007877
Validation loss: 2.2839279885954937

Epoch: 5| Step: 1
Training loss: 1.0136549402487145
Validation loss: 2.25697108700795

Epoch: 5| Step: 2
Training loss: 1.0538970245568355
Validation loss: 2.2460275982161124

Epoch: 5| Step: 3
Training loss: 1.1176518362270915
Validation loss: 2.2532118998507014

Epoch: 5| Step: 4
Training loss: 2.056306846319859
Validation loss: 2.3013661769560234

Epoch: 5| Step: 5
Training loss: 0.8277167987622621
Validation loss: 2.2883079545427796

Epoch: 5| Step: 6
Training loss: 1.410770652258843
Validation loss: 2.273526481079854

Epoch: 5| Step: 7
Training loss: 0.7000244868627733
Validation loss: 2.2307009922929235

Epoch: 5| Step: 8
Training loss: 0.7978089039860096
Validation loss: 2.4033890139036247

Epoch: 5| Step: 9
Training loss: 0.727415056349292
Validation loss: 2.3280004927922184

Epoch: 5| Step: 10
Training loss: 0.8151000675833661
Validation loss: 2.2658440630745167

Epoch: 467| Step: 0
Training loss: 0.8613041465691351
Validation loss: 2.2346208217586727

Epoch: 5| Step: 1
Training loss: 0.929946574809526
Validation loss: 2.2360204570723137

Epoch: 5| Step: 2
Training loss: 1.1680912221532547
Validation loss: 2.3148820847771416

Epoch: 5| Step: 3
Training loss: 1.053899173698677
Validation loss: 2.284080164640185

Epoch: 5| Step: 4
Training loss: 0.7862174989566109
Validation loss: 2.275862030429203

Epoch: 5| Step: 5
Training loss: 1.755637624823541
Validation loss: 2.270579621282876

Epoch: 5| Step: 6
Training loss: 0.9233550136536428
Validation loss: 2.3231437697536217

Epoch: 5| Step: 7
Training loss: 0.965927750616321
Validation loss: 2.340813103954964

Epoch: 5| Step: 8
Training loss: 0.7849938143954184
Validation loss: 2.2100268847270015

Epoch: 5| Step: 9
Training loss: 1.1109274089800247
Validation loss: 2.27150623398942

Epoch: 5| Step: 10
Training loss: 0.8856134121284127
Validation loss: 2.301028305604142

Epoch: 468| Step: 0
Training loss: 0.8665829174829319
Validation loss: 2.3395132118650857

Epoch: 5| Step: 1
Training loss: 0.9410487719026832
Validation loss: 2.3002630028554374

Epoch: 5| Step: 2
Training loss: 1.216718594649175
Validation loss: 2.2916334957134743

Epoch: 5| Step: 3
Training loss: 1.0391502630126515
Validation loss: 2.3071077714672428

Epoch: 5| Step: 4
Training loss: 0.9595305835427742
Validation loss: 2.2747664299131367

Epoch: 5| Step: 5
Training loss: 1.1018919756399055
Validation loss: 2.3014771095689475

Epoch: 5| Step: 6
Training loss: 0.7662898699545244
Validation loss: 2.2775320721267875

Epoch: 5| Step: 7
Training loss: 1.7088885994367902
Validation loss: 2.2746520634018337

Epoch: 5| Step: 8
Training loss: 0.9395052128109704
Validation loss: 2.3025198972463436

Epoch: 5| Step: 9
Training loss: 0.8997614186678733
Validation loss: 2.319316171834991

Epoch: 5| Step: 10
Training loss: 0.9469639248527549
Validation loss: 2.3064165401323464

Epoch: 469| Step: 0
Training loss: 1.166907756735899
Validation loss: 2.3304877593334252

Epoch: 5| Step: 1
Training loss: 0.9081645342103543
Validation loss: 2.244194009635474

Epoch: 5| Step: 2
Training loss: 1.1110237120322026
Validation loss: 2.327881609757198

Epoch: 5| Step: 3
Training loss: 0.8609876933065653
Validation loss: 2.204921599614994

Epoch: 5| Step: 4
Training loss: 1.839411917707105
Validation loss: 2.3010962608532033

Epoch: 5| Step: 5
Training loss: 1.1336873852516123
Validation loss: 2.2550133815523226

Epoch: 5| Step: 6
Training loss: 1.0491896136023926
Validation loss: 2.3400085852424914

Epoch: 5| Step: 7
Training loss: 0.9651589129847972
Validation loss: 2.274700195704801

Epoch: 5| Step: 8
Training loss: 0.7400917580137251
Validation loss: 2.275283871672286

Epoch: 5| Step: 9
Training loss: 0.9390677060000407
Validation loss: 2.3071219696845215

Epoch: 5| Step: 10
Training loss: 0.9401443698278895
Validation loss: 2.3456890439150007

Epoch: 470| Step: 0
Training loss: 1.0288840810694553
Validation loss: 2.385706710395501

Epoch: 5| Step: 1
Training loss: 0.7015085926032666
Validation loss: 2.3558189237779215

Epoch: 5| Step: 2
Training loss: 1.0667365264864177
Validation loss: 2.2268331412520035

Epoch: 5| Step: 3
Training loss: 1.2711949641674734
Validation loss: 2.284205618041879

Epoch: 5| Step: 4
Training loss: 1.6326717334282914
Validation loss: 2.286302734510301

Epoch: 5| Step: 5
Training loss: 0.9314111390967024
Validation loss: 2.2827506619913187

Epoch: 5| Step: 6
Training loss: 0.795660851712893
Validation loss: 2.326308688297218

Epoch: 5| Step: 7
Training loss: 1.1632512997575521
Validation loss: 2.31299828258094

Epoch: 5| Step: 8
Training loss: 1.2661149760160273
Validation loss: 2.3312178562720263

Epoch: 5| Step: 9
Training loss: 0.9191806990369996
Validation loss: 2.2839474218358227

Epoch: 5| Step: 10
Training loss: 0.7777154695061005
Validation loss: 2.2675872565414856

Epoch: 471| Step: 0
Training loss: 0.7654404709765251
Validation loss: 2.2748357928798786

Epoch: 5| Step: 1
Training loss: 1.2001824995184143
Validation loss: 2.2979011556615636

Epoch: 5| Step: 2
Training loss: 0.9489516208102804
Validation loss: 2.304762508505854

Epoch: 5| Step: 3
Training loss: 1.088198387129657
Validation loss: 2.270681349233064

Epoch: 5| Step: 4
Training loss: 1.772414529996806
Validation loss: 2.287325564237706

Epoch: 5| Step: 5
Training loss: 0.9058787802344556
Validation loss: 2.2742009855873286

Epoch: 5| Step: 6
Training loss: 1.0935562507139938
Validation loss: 2.28564920001765

Epoch: 5| Step: 7
Training loss: 0.9182503450965804
Validation loss: 2.3030398567163046

Epoch: 5| Step: 8
Training loss: 1.032544623881555
Validation loss: 2.306742385248263

Epoch: 5| Step: 9
Training loss: 1.0560720892055036
Validation loss: 2.2430816156234474

Epoch: 5| Step: 10
Training loss: 0.9931272726831185
Validation loss: 2.2721974611765576

Epoch: 472| Step: 0
Training loss: 0.8383055684312103
Validation loss: 2.2868619770848393

Epoch: 5| Step: 1
Training loss: 0.8947987052513342
Validation loss: 2.3573444921723077

Epoch: 5| Step: 2
Training loss: 1.102253582116906
Validation loss: 2.2360295082507013

Epoch: 5| Step: 3
Training loss: 0.6452746410209701
Validation loss: 2.2460503121804134

Epoch: 5| Step: 4
Training loss: 0.9714154521573158
Validation loss: 2.355505307248781

Epoch: 5| Step: 5
Training loss: 1.0546731453377887
Validation loss: 2.2528244467559877

Epoch: 5| Step: 6
Training loss: 0.8033457189280501
Validation loss: 2.2736465357436697

Epoch: 5| Step: 7
Training loss: 1.7058013046579898
Validation loss: 2.350367556893702

Epoch: 5| Step: 8
Training loss: 0.827583207732691
Validation loss: 2.335488245775314

Epoch: 5| Step: 9
Training loss: 1.068095898262479
Validation loss: 2.2438862960094124

Epoch: 5| Step: 10
Training loss: 0.956969216340928
Validation loss: 2.200395738386068

Epoch: 473| Step: 0
Training loss: 1.2508672090213242
Validation loss: 2.3205502423042677

Epoch: 5| Step: 1
Training loss: 0.8235266432745664
Validation loss: 2.281361554551249

Epoch: 5| Step: 2
Training loss: 0.772649652744127
Validation loss: 2.2886031122185946

Epoch: 5| Step: 3
Training loss: 0.9782322151484025
Validation loss: 2.3331577829019077

Epoch: 5| Step: 4
Training loss: 1.0338100100423233
Validation loss: 2.2871195774875916

Epoch: 5| Step: 5
Training loss: 1.699356950423422
Validation loss: 2.2790520958699325

Epoch: 5| Step: 6
Training loss: 0.7356223206969597
Validation loss: 2.311706533221839

Epoch: 5| Step: 7
Training loss: 1.06633347483049
Validation loss: 2.289844792946501

Epoch: 5| Step: 8
Training loss: 0.860254080853903
Validation loss: 2.252514491494484

Epoch: 5| Step: 9
Training loss: 1.0628098428766448
Validation loss: 2.3305227767922863

Epoch: 5| Step: 10
Training loss: 1.1712451004854072
Validation loss: 2.361065442678917

Epoch: 474| Step: 0
Training loss: 0.9913915610521604
Validation loss: 2.3404984110366764

Epoch: 5| Step: 1
Training loss: 0.7782342688505096
Validation loss: 2.2437888443351417

Epoch: 5| Step: 2
Training loss: 1.011869205790489
Validation loss: 2.293211138136732

Epoch: 5| Step: 3
Training loss: 1.032700299099705
Validation loss: 2.2785667510248446

Epoch: 5| Step: 4
Training loss: 1.655472987026897
Validation loss: 2.302929902749963

Epoch: 5| Step: 5
Training loss: 1.1337917436277245
Validation loss: 2.2156105320927577

Epoch: 5| Step: 6
Training loss: 1.0778446662330234
Validation loss: 2.2478155233006443

Epoch: 5| Step: 7
Training loss: 0.5816534211318428
Validation loss: 2.277720165958069

Epoch: 5| Step: 8
Training loss: 1.2179200696729078
Validation loss: 2.285764837722298

Epoch: 5| Step: 9
Training loss: 0.972487193663154
Validation loss: 2.2639163886066207

Epoch: 5| Step: 10
Training loss: 0.9117128543614107
Validation loss: 2.3095443736963803

Epoch: 475| Step: 0
Training loss: 0.8243609482013714
Validation loss: 2.1953937525845078

Epoch: 5| Step: 1
Training loss: 1.0448549623545234
Validation loss: 2.329282318941599

Epoch: 5| Step: 2
Training loss: 1.0058157013235534
Validation loss: 2.265596293266476

Epoch: 5| Step: 3
Training loss: 0.8645292556273627
Validation loss: 2.225782094218489

Epoch: 5| Step: 4
Training loss: 1.7710669718679621
Validation loss: 2.3477359449916384

Epoch: 5| Step: 5
Training loss: 1.0705431947113853
Validation loss: 2.2852300754875126

Epoch: 5| Step: 6
Training loss: 1.100866923304644
Validation loss: 2.2575738559823932

Epoch: 5| Step: 7
Training loss: 0.996255719349142
Validation loss: 2.3070552681398366

Epoch: 5| Step: 8
Training loss: 1.043642662148354
Validation loss: 2.2786055765888173

Epoch: 5| Step: 9
Training loss: 0.7780193670799286
Validation loss: 2.2232472852046663

Epoch: 5| Step: 10
Training loss: 1.0325457784004022
Validation loss: 2.23013165996644

Epoch: 476| Step: 0
Training loss: 1.247444114732886
Validation loss: 2.2352274708387583

Epoch: 5| Step: 1
Training loss: 1.0278326111563092
Validation loss: 2.2152973708919763

Epoch: 5| Step: 2
Training loss: 0.9548052376477622
Validation loss: 2.2767789344988834

Epoch: 5| Step: 3
Training loss: 0.8258029122881213
Validation loss: 2.305633895664236

Epoch: 5| Step: 4
Training loss: 1.8335546085452978
Validation loss: 2.2598065756616608

Epoch: 5| Step: 5
Training loss: 0.8919240946847263
Validation loss: 2.3162767078385555

Epoch: 5| Step: 6
Training loss: 0.8842844886427942
Validation loss: 2.3315747712752866

Epoch: 5| Step: 7
Training loss: 0.9125004977394732
Validation loss: 2.303899395488297

Epoch: 5| Step: 8
Training loss: 1.1671966245976326
Validation loss: 2.220097838539457

Epoch: 5| Step: 9
Training loss: 0.8066639007830951
Validation loss: 2.2362076127848605

Epoch: 5| Step: 10
Training loss: 1.1160114206803025
Validation loss: 2.236714830399746

Epoch: 477| Step: 0
Training loss: 0.9705140756768464
Validation loss: 2.2549323342897702

Epoch: 5| Step: 1
Training loss: 1.2261438809517213
Validation loss: 2.2427928430841173

Epoch: 5| Step: 2
Training loss: 1.0801656456473439
Validation loss: 2.355199330534066

Epoch: 5| Step: 3
Training loss: 1.6984317754878877
Validation loss: 2.2565165065786426

Epoch: 5| Step: 4
Training loss: 1.1402934389410868
Validation loss: 2.322840520831247

Epoch: 5| Step: 5
Training loss: 0.8029063984864797
Validation loss: 2.2674776315226266

Epoch: 5| Step: 6
Training loss: 0.8788015006480994
Validation loss: 2.253335442536885

Epoch: 5| Step: 7
Training loss: 1.1064854990840267
Validation loss: 2.3414836626431086

Epoch: 5| Step: 8
Training loss: 0.9506313973837935
Validation loss: 2.2788266953562184

Epoch: 5| Step: 9
Training loss: 0.8544328243888617
Validation loss: 2.226650743043781

Epoch: 5| Step: 10
Training loss: 1.05783498675338
Validation loss: 2.2719967418836786

Epoch: 478| Step: 0
Training loss: 1.1192069308626003
Validation loss: 2.299609552879986

Epoch: 5| Step: 1
Training loss: 0.9956764094890593
Validation loss: 2.2359325872522526

Epoch: 5| Step: 2
Training loss: 0.6460800058731931
Validation loss: 2.1951197869263246

Epoch: 5| Step: 3
Training loss: 1.7061260276163615
Validation loss: 2.2859841234639138

Epoch: 5| Step: 4
Training loss: 0.8413459295754605
Validation loss: 2.347318535082143

Epoch: 5| Step: 5
Training loss: 0.933601219753884
Validation loss: 2.2737060282289203

Epoch: 5| Step: 6
Training loss: 0.9732035127595973
Validation loss: 2.3355629478311117

Epoch: 5| Step: 7
Training loss: 0.8596770016005975
Validation loss: 2.300771700875832

Epoch: 5| Step: 8
Training loss: 0.9540443988960904
Validation loss: 2.30060371672097

Epoch: 5| Step: 9
Training loss: 1.0527592870139133
Validation loss: 2.2697256633780842

Epoch: 5| Step: 10
Training loss: 1.164693111143114
Validation loss: 2.2940180706323723

Epoch: 479| Step: 0
Training loss: 0.9692764390021148
Validation loss: 2.298361375938612

Epoch: 5| Step: 1
Training loss: 0.9194538845552122
Validation loss: 2.3295990188894624

Epoch: 5| Step: 2
Training loss: 0.7342622954547365
Validation loss: 2.2980168779870507

Epoch: 5| Step: 3
Training loss: 0.920395876826816
Validation loss: 2.2844943582614974

Epoch: 5| Step: 4
Training loss: 0.9368291361896354
Validation loss: 2.2985155749361246

Epoch: 5| Step: 5
Training loss: 0.7784209718791062
Validation loss: 2.278224525048377

Epoch: 5| Step: 6
Training loss: 0.9931807164959227
Validation loss: 2.2013399387349035

Epoch: 5| Step: 7
Training loss: 0.8522677519681957
Validation loss: 2.306110069986922

Epoch: 5| Step: 8
Training loss: 1.7362284336714338
Validation loss: 2.322915183479376

Epoch: 5| Step: 9
Training loss: 1.3842713155732942
Validation loss: 2.2380415588685554

Epoch: 5| Step: 10
Training loss: 1.0457362913928967
Validation loss: 2.298910187915471

Epoch: 480| Step: 0
Training loss: 0.9385526151932312
Validation loss: 2.332922246826702

Epoch: 5| Step: 1
Training loss: 0.7965562594361235
Validation loss: 2.3592191624463883

Epoch: 5| Step: 2
Training loss: 1.087265903664463
Validation loss: 2.3018231545325962

Epoch: 5| Step: 3
Training loss: 1.1136757670280664
Validation loss: 2.2643989252512604

Epoch: 5| Step: 4
Training loss: 1.0266047383390613
Validation loss: 2.359188387289443

Epoch: 5| Step: 5
Training loss: 0.9421276952890473
Validation loss: 2.3881032427200233

Epoch: 5| Step: 6
Training loss: 1.7447407577451328
Validation loss: 2.2915445397762646

Epoch: 5| Step: 7
Training loss: 1.1900501976324913
Validation loss: 2.286792633608496

Epoch: 5| Step: 8
Training loss: 0.8882576113116282
Validation loss: 2.297644269749891

Epoch: 5| Step: 9
Training loss: 1.0387703621127518
Validation loss: 2.3365014786772376

Epoch: 5| Step: 10
Training loss: 0.7480163567993467
Validation loss: 2.3247212476960963

Epoch: 481| Step: 0
Training loss: 1.6259030253875775
Validation loss: 2.2830361085769617

Epoch: 5| Step: 1
Training loss: 0.9257621924132868
Validation loss: 2.21282055994068

Epoch: 5| Step: 2
Training loss: 1.1549130520151045
Validation loss: 2.2790744610167972

Epoch: 5| Step: 3
Training loss: 1.1386527162906344
Validation loss: 2.242038569364082

Epoch: 5| Step: 4
Training loss: 1.0379702915431148
Validation loss: 2.2402442296576295

Epoch: 5| Step: 5
Training loss: 0.8960529693928951
Validation loss: 2.297735251113842

Epoch: 5| Step: 6
Training loss: 0.9152761374114611
Validation loss: 2.316298528175001

Epoch: 5| Step: 7
Training loss: 0.9415662320908483
Validation loss: 2.3074564706286065

Epoch: 5| Step: 8
Training loss: 1.061440556720177
Validation loss: 2.239561650790552

Epoch: 5| Step: 9
Training loss: 0.7855320121463086
Validation loss: 2.2998571345261367

Epoch: 5| Step: 10
Training loss: 0.9180937012387695
Validation loss: 2.2371548840500326

Epoch: 482| Step: 0
Training loss: 1.1081560449613745
Validation loss: 2.2520855147860304

Epoch: 5| Step: 1
Training loss: 1.0802658497363358
Validation loss: 2.3415111537915037

Epoch: 5| Step: 2
Training loss: 0.9707162038739438
Validation loss: 2.298537548824448

Epoch: 5| Step: 3
Training loss: 0.9251229565323
Validation loss: 2.2505786714478733

Epoch: 5| Step: 4
Training loss: 0.9905271078653101
Validation loss: 2.2670894146087748

Epoch: 5| Step: 5
Training loss: 1.7451223790668442
Validation loss: 2.299203950534259

Epoch: 5| Step: 6
Training loss: 1.0330332163836933
Validation loss: 2.3017511844145844

Epoch: 5| Step: 7
Training loss: 1.0051215271042364
Validation loss: 2.2823449169337895

Epoch: 5| Step: 8
Training loss: 0.6890925255978612
Validation loss: 2.2997683183243103

Epoch: 5| Step: 9
Training loss: 0.9932260859654536
Validation loss: 2.249348101639413

Epoch: 5| Step: 10
Training loss: 1.001871800979771
Validation loss: 2.2881137870242263

Epoch: 483| Step: 0
Training loss: 0.7181832110497913
Validation loss: 2.3119781712434304

Epoch: 5| Step: 1
Training loss: 0.8346345676332501
Validation loss: 2.2078311331335363

Epoch: 5| Step: 2
Training loss: 0.9923523292897424
Validation loss: 2.257217202145007

Epoch: 5| Step: 3
Training loss: 0.9160708022427523
Validation loss: 2.2416277319579696

Epoch: 5| Step: 4
Training loss: 1.0689890120202965
Validation loss: 2.3174898268339224

Epoch: 5| Step: 5
Training loss: 0.6406120903761299
Validation loss: 2.2933785168708

Epoch: 5| Step: 6
Training loss: 0.880898553015068
Validation loss: 2.2942050542021177

Epoch: 5| Step: 7
Training loss: 1.07890927081614
Validation loss: 2.29612968964435

Epoch: 5| Step: 8
Training loss: 1.0266952498490591
Validation loss: 2.242417515118778

Epoch: 5| Step: 9
Training loss: 1.7365452702511714
Validation loss: 2.269310264820314

Epoch: 5| Step: 10
Training loss: 1.0995928422623429
Validation loss: 2.323746458555278

Epoch: 484| Step: 0
Training loss: 0.8952677331088004
Validation loss: 2.3412099614550157

Epoch: 5| Step: 1
Training loss: 0.9086794680754618
Validation loss: 2.2959346223252544

Epoch: 5| Step: 2
Training loss: 0.876989589009533
Validation loss: 2.2353680634951636

Epoch: 5| Step: 3
Training loss: 0.8714814285645718
Validation loss: 2.297777391102357

Epoch: 5| Step: 4
Training loss: 0.8558014174963794
Validation loss: 2.2783552495838486

Epoch: 5| Step: 5
Training loss: 1.3843899797098433
Validation loss: 2.2368509973417643

Epoch: 5| Step: 6
Training loss: 0.6808670157322814
Validation loss: 2.2820871701904095

Epoch: 5| Step: 7
Training loss: 1.136446051643411
Validation loss: 2.279925317021481

Epoch: 5| Step: 8
Training loss: 1.8241098114094447
Validation loss: 2.3012580975649537

Epoch: 5| Step: 9
Training loss: 0.9718220822073297
Validation loss: 2.327938966819406

Epoch: 5| Step: 10
Training loss: 1.0322405941387538
Validation loss: 2.2353758701161937

Epoch: 485| Step: 0
Training loss: 0.9949811818150055
Validation loss: 2.1882933014655293

Epoch: 5| Step: 1
Training loss: 1.109772624363322
Validation loss: 2.237103930485681

Epoch: 5| Step: 2
Training loss: 0.7248271604573198
Validation loss: 2.3235814604511447

Epoch: 5| Step: 3
Training loss: 0.9681455202926247
Validation loss: 2.2238771483770856

Epoch: 5| Step: 4
Training loss: 1.154993663456697
Validation loss: 2.2953634662043734

Epoch: 5| Step: 5
Training loss: 0.6531802770047176
Validation loss: 2.291026982795934

Epoch: 5| Step: 6
Training loss: 1.025642000902458
Validation loss: 2.2488477267618463

Epoch: 5| Step: 7
Training loss: 0.8993340041391611
Validation loss: 2.259311630669081

Epoch: 5| Step: 8
Training loss: 0.7275475008686393
Validation loss: 2.269773623429088

Epoch: 5| Step: 9
Training loss: 1.098102628146727
Validation loss: 2.2471939076240446

Epoch: 5| Step: 10
Training loss: 1.9967103964910495
Validation loss: 2.282508823621359

Epoch: 486| Step: 0
Training loss: 0.9818004667766282
Validation loss: 2.231233001558751

Epoch: 5| Step: 1
Training loss: 0.5544066725653437
Validation loss: 2.2969530622632965

Epoch: 5| Step: 2
Training loss: 1.109874290616453
Validation loss: 2.299093944136253

Epoch: 5| Step: 3
Training loss: 0.6739431752932875
Validation loss: 2.274664014580795

Epoch: 5| Step: 4
Training loss: 0.9023008790504108
Validation loss: 2.2536133643607905

Epoch: 5| Step: 5
Training loss: 0.7781840244565177
Validation loss: 2.263743867785491

Epoch: 5| Step: 6
Training loss: 1.719403090807382
Validation loss: 2.308604286183269

Epoch: 5| Step: 7
Training loss: 0.99377788528569
Validation loss: 2.230064686941045

Epoch: 5| Step: 8
Training loss: 0.7815580523645386
Validation loss: 2.2961789571387734

Epoch: 5| Step: 9
Training loss: 1.2181446821913637
Validation loss: 2.3066374974691826

Epoch: 5| Step: 10
Training loss: 1.2100209859336495
Validation loss: 2.3461042485068075

Epoch: 487| Step: 0
Training loss: 1.0737217533717174
Validation loss: 2.331946562608983

Epoch: 5| Step: 1
Training loss: 0.8416667935084886
Validation loss: 2.2566467124324068

Epoch: 5| Step: 2
Training loss: 0.82864823995385
Validation loss: 2.353937662979483

Epoch: 5| Step: 3
Training loss: 0.6157595860102539
Validation loss: 2.315771073681496

Epoch: 5| Step: 4
Training loss: 1.0526373257605635
Validation loss: 2.2539639062779977

Epoch: 5| Step: 5
Training loss: 0.7722479023730489
Validation loss: 2.3180835069496113

Epoch: 5| Step: 6
Training loss: 1.7855222898537833
Validation loss: 2.243101943901842

Epoch: 5| Step: 7
Training loss: 1.054013354696399
Validation loss: 2.280871709569644

Epoch: 5| Step: 8
Training loss: 1.0805566427873134
Validation loss: 2.327153929085016

Epoch: 5| Step: 9
Training loss: 0.9240750069621656
Validation loss: 2.3124380128329953

Epoch: 5| Step: 10
Training loss: 0.8599563712874527
Validation loss: 2.2373436464416203

Epoch: 488| Step: 0
Training loss: 0.9078889036609523
Validation loss: 2.3178899399132478

Epoch: 5| Step: 1
Training loss: 1.3090359524247608
Validation loss: 2.2580977362358694

Epoch: 5| Step: 2
Training loss: 1.5621928866881696
Validation loss: 2.2750955603627623

Epoch: 5| Step: 3
Training loss: 0.8302518415996339
Validation loss: 2.273829378550076

Epoch: 5| Step: 4
Training loss: 1.104473892991309
Validation loss: 2.244542734326833

Epoch: 5| Step: 5
Training loss: 0.9595194953182306
Validation loss: 2.310133298575627

Epoch: 5| Step: 6
Training loss: 0.8559383340241685
Validation loss: 2.311312795600671

Epoch: 5| Step: 7
Training loss: 1.2175039132307952
Validation loss: 2.2671095994243076

Epoch: 5| Step: 8
Training loss: 0.8238976381872943
Validation loss: 2.297406536692989

Epoch: 5| Step: 9
Training loss: 0.8097434968772617
Validation loss: 2.2998563547964306

Epoch: 5| Step: 10
Training loss: 0.9070360129376722
Validation loss: 2.2861795828491713

Epoch: 489| Step: 0
Training loss: 1.0437255285443783
Validation loss: 2.312511794379748

Epoch: 5| Step: 1
Training loss: 0.8441668999292843
Validation loss: 2.2695567808578505

Epoch: 5| Step: 2
Training loss: 0.7039597324795087
Validation loss: 2.2877898401733203

Epoch: 5| Step: 3
Training loss: 0.9704313454200965
Validation loss: 2.261676118955356

Epoch: 5| Step: 4
Training loss: 0.9711598601667099
Validation loss: 2.3305690567166772

Epoch: 5| Step: 5
Training loss: 0.9575391706118727
Validation loss: 2.2740424939460704

Epoch: 5| Step: 6
Training loss: 0.9237143061327177
Validation loss: 2.297785457074072

Epoch: 5| Step: 7
Training loss: 1.922928870077318
Validation loss: 2.293646445759888

Epoch: 5| Step: 8
Training loss: 1.0079296546678493
Validation loss: 2.2024826920629756

Epoch: 5| Step: 9
Training loss: 0.6994551786360412
Validation loss: 2.272009288698914

Epoch: 5| Step: 10
Training loss: 1.0975428621094852
Validation loss: 2.3038600497844657

Epoch: 490| Step: 0
Training loss: 1.0508822708068932
Validation loss: 2.28415693967179

Epoch: 5| Step: 1
Training loss: 0.6832487707228198
Validation loss: 2.362984374751146

Epoch: 5| Step: 2
Training loss: 0.9963824283934081
Validation loss: 2.276316681455105

Epoch: 5| Step: 3
Training loss: 0.9310273525161709
Validation loss: 2.286242355972341

Epoch: 5| Step: 4
Training loss: 0.8474119687004709
Validation loss: 2.2521061639073534

Epoch: 5| Step: 5
Training loss: 0.8554977342407258
Validation loss: 2.3106266915995626

Epoch: 5| Step: 6
Training loss: 0.9086438822015603
Validation loss: 2.223875215164535

Epoch: 5| Step: 7
Training loss: 1.7871303202751412
Validation loss: 2.1754109354751288

Epoch: 5| Step: 8
Training loss: 0.8691998750871761
Validation loss: 2.2613217786508297

Epoch: 5| Step: 9
Training loss: 0.9535883418277831
Validation loss: 2.3410597293782964

Epoch: 5| Step: 10
Training loss: 0.8450588741333325
Validation loss: 2.2278827638134153

Epoch: 491| Step: 0
Training loss: 0.8386304741187661
Validation loss: 2.2624209629780676

Epoch: 5| Step: 1
Training loss: 0.9077171748368905
Validation loss: 2.2840116705679185

Epoch: 5| Step: 2
Training loss: 1.8172137690684784
Validation loss: 2.338718970969479

Epoch: 5| Step: 3
Training loss: 0.7748475755495935
Validation loss: 2.2673812887759035

Epoch: 5| Step: 4
Training loss: 0.8967702239504883
Validation loss: 2.2983952649685055

Epoch: 5| Step: 5
Training loss: 1.0898272331927745
Validation loss: 2.257361452899249

Epoch: 5| Step: 6
Training loss: 0.793513557181256
Validation loss: 2.2949614230945916

Epoch: 5| Step: 7
Training loss: 0.7254918731875762
Validation loss: 2.2442735141985097

Epoch: 5| Step: 8
Training loss: 1.0642351679808997
Validation loss: 2.304648172200458

Epoch: 5| Step: 9
Training loss: 0.797501897122031
Validation loss: 2.3244843191046214

Epoch: 5| Step: 10
Training loss: 0.8083266033469239
Validation loss: 2.250734235629302

Epoch: 492| Step: 0
Training loss: 0.846410477550048
Validation loss: 2.2714691510060345

Epoch: 5| Step: 1
Training loss: 0.75169705080705
Validation loss: 2.2738971181467753

Epoch: 5| Step: 2
Training loss: 1.2038040226651268
Validation loss: 2.214703285167525

Epoch: 5| Step: 3
Training loss: 0.9990108485468119
Validation loss: 2.2314689228030096

Epoch: 5| Step: 4
Training loss: 1.7511910744881798
Validation loss: 2.3024704135892358

Epoch: 5| Step: 5
Training loss: 0.9208966899381947
Validation loss: 2.282660301933974

Epoch: 5| Step: 6
Training loss: 0.9722170470115129
Validation loss: 2.285662483941375

Epoch: 5| Step: 7
Training loss: 1.0209349108132748
Validation loss: 2.2809876456713956

Epoch: 5| Step: 8
Training loss: 0.7934919238121203
Validation loss: 2.3377807546411415

Epoch: 5| Step: 9
Training loss: 0.8112386302415757
Validation loss: 2.2760745373474047

Epoch: 5| Step: 10
Training loss: 0.8662764772824701
Validation loss: 2.2621161514682693

Epoch: 493| Step: 0
Training loss: 0.79152382431996
Validation loss: 2.2148307919568557

Epoch: 5| Step: 1
Training loss: 1.1835880594148216
Validation loss: 2.324305184807082

Epoch: 5| Step: 2
Training loss: 0.7795596337058904
Validation loss: 2.247409753829166

Epoch: 5| Step: 3
Training loss: 1.0006118928907437
Validation loss: 2.2899749134661906

Epoch: 5| Step: 4
Training loss: 0.8386665788260305
Validation loss: 2.344407243353623

Epoch: 5| Step: 5
Training loss: 1.1692801675515976
Validation loss: 2.3100433515225665

Epoch: 5| Step: 6
Training loss: 1.0649115179136281
Validation loss: 2.2568487600064144

Epoch: 5| Step: 7
Training loss: 1.7756851002432357
Validation loss: 2.229175719031085

Epoch: 5| Step: 8
Training loss: 0.8086815385570005
Validation loss: 2.209914798791548

Epoch: 5| Step: 9
Training loss: 0.8673597972267068
Validation loss: 2.253543357278964

Epoch: 5| Step: 10
Training loss: 0.9232612467477699
Validation loss: 2.2745531718614407

Epoch: 494| Step: 0
Training loss: 1.0433374674677574
Validation loss: 2.1751527166164073

Epoch: 5| Step: 1
Training loss: 1.7832755902410349
Validation loss: 2.298154118576053

Epoch: 5| Step: 2
Training loss: 0.9472728296379529
Validation loss: 2.2230902559739856

Epoch: 5| Step: 3
Training loss: 0.8508787297222716
Validation loss: 2.2533594236142553

Epoch: 5| Step: 4
Training loss: 1.1226617036499842
Validation loss: 2.310712050525596

Epoch: 5| Step: 5
Training loss: 0.7961667223009273
Validation loss: 2.3597645814509427

Epoch: 5| Step: 6
Training loss: 0.719170571718484
Validation loss: 2.264446717352969

Epoch: 5| Step: 7
Training loss: 0.7108238045462596
Validation loss: 2.288129707808407

Epoch: 5| Step: 8
Training loss: 0.7763504506352387
Validation loss: 2.2654711825638545

Epoch: 5| Step: 9
Training loss: 1.0275930820079278
Validation loss: 2.2876983500995443

Epoch: 5| Step: 10
Training loss: 0.9452994164436305
Validation loss: 2.267319933732377

Epoch: 495| Step: 0
Training loss: 0.8219629668527718
Validation loss: 2.274528848991613

Epoch: 5| Step: 1
Training loss: 0.7800047295989405
Validation loss: 2.287167924352395

Epoch: 5| Step: 2
Training loss: 0.7863472403236719
Validation loss: 2.2430623917931745

Epoch: 5| Step: 3
Training loss: 0.8684703170873687
Validation loss: 2.2252583974829827

Epoch: 5| Step: 4
Training loss: 0.8265122237896794
Validation loss: 2.2996750718898853

Epoch: 5| Step: 5
Training loss: 0.7925890309357595
Validation loss: 2.227223629855235

Epoch: 5| Step: 6
Training loss: 1.3410845202408712
Validation loss: 2.312010451350693

Epoch: 5| Step: 7
Training loss: 1.7489237882085285
Validation loss: 2.321241487606754

Epoch: 5| Step: 8
Training loss: 0.7795562312561405
Validation loss: 2.2494829140848025

Epoch: 5| Step: 9
Training loss: 1.102885162389708
Validation loss: 2.2568034924166174

Epoch: 5| Step: 10
Training loss: 1.005683365023716
Validation loss: 2.2665772968145284

Epoch: 496| Step: 0
Training loss: 1.8337608908113374
Validation loss: 2.377147334739372

Epoch: 5| Step: 1
Training loss: 1.208212857433825
Validation loss: 2.323081398947293

Epoch: 5| Step: 2
Training loss: 0.9264322559234262
Validation loss: 2.2405987882580525

Epoch: 5| Step: 3
Training loss: 0.6247225383952616
Validation loss: 2.138608572751605

Epoch: 5| Step: 4
Training loss: 0.8572179599624958
Validation loss: 2.3752320440175185

Epoch: 5| Step: 5
Training loss: 0.876956013630143
Validation loss: 2.2991575098038424

Epoch: 5| Step: 6
Training loss: 1.049296411294489
Validation loss: 2.2142794562410555

Epoch: 5| Step: 7
Training loss: 0.7823383760962913
Validation loss: 2.2628658230307774

Epoch: 5| Step: 8
Training loss: 0.7455232046495666
Validation loss: 2.3285518375260956

Epoch: 5| Step: 9
Training loss: 0.6252381109612006
Validation loss: 2.3133484393394927

Epoch: 5| Step: 10
Training loss: 0.4359005744909731
Validation loss: 2.2704129183148507

Epoch: 497| Step: 0
Training loss: 0.7894695478464819
Validation loss: 2.2640979762226254

Epoch: 5| Step: 1
Training loss: 1.1243634012248513
Validation loss: 2.295372973049028

Epoch: 5| Step: 2
Training loss: 0.8820865988787313
Validation loss: 2.31246042314723

Epoch: 5| Step: 3
Training loss: 1.0114139407021816
Validation loss: 2.257798692845754

Epoch: 5| Step: 4
Training loss: 1.1595899953227014
Validation loss: 2.2530247331906614

Epoch: 5| Step: 5
Training loss: 0.8673301098382714
Validation loss: 2.3254785807527663

Epoch: 5| Step: 6
Training loss: 0.7452166129755977
Validation loss: 2.3104051870317215

Epoch: 5| Step: 7
Training loss: 0.6915403117582057
Validation loss: 2.2992436033739847

Epoch: 5| Step: 8
Training loss: 1.6566378301314921
Validation loss: 2.2840655156521295

Epoch: 5| Step: 9
Training loss: 0.9923941930108188
Validation loss: 2.2972975618372806

Epoch: 5| Step: 10
Training loss: 0.9433397879452715
Validation loss: 2.3151599997217858

Epoch: 498| Step: 0
Training loss: 0.8798424037244926
Validation loss: 2.256361811434191

Epoch: 5| Step: 1
Training loss: 0.8515287270104525
Validation loss: 2.250771967196331

Epoch: 5| Step: 2
Training loss: 0.7512164582240117
Validation loss: 2.2028210198314877

Epoch: 5| Step: 3
Training loss: 1.0705248211402234
Validation loss: 2.26491661666402

Epoch: 5| Step: 4
Training loss: 1.1942872281563603
Validation loss: 2.2641846403242445

Epoch: 5| Step: 5
Training loss: 0.7710711567669436
Validation loss: 2.3295477003708758

Epoch: 5| Step: 6
Training loss: 0.8607890546316437
Validation loss: 2.216031162233546

Epoch: 5| Step: 7
Training loss: 0.7455252433739873
Validation loss: 2.2643984282370857

Epoch: 5| Step: 8
Training loss: 1.8042105833116366
Validation loss: 2.231305129869338

Epoch: 5| Step: 9
Training loss: 0.943237296788554
Validation loss: 2.2235964299331816

Epoch: 5| Step: 10
Training loss: 0.8320860508884095
Validation loss: 2.2620824187475095

Epoch: 499| Step: 0
Training loss: 0.8230638412660476
Validation loss: 2.270612502915798

Epoch: 5| Step: 1
Training loss: 0.6289420265778619
Validation loss: 2.296560192655124

Epoch: 5| Step: 2
Training loss: 0.9058670681868973
Validation loss: 2.241040933407727

Epoch: 5| Step: 3
Training loss: 1.2157883973126655
Validation loss: 2.3371264649216723

Epoch: 5| Step: 4
Training loss: 0.8900717639921808
Validation loss: 2.272973224106955

Epoch: 5| Step: 5
Training loss: 0.47675010240470694
Validation loss: 2.276247609138872

Epoch: 5| Step: 6
Training loss: 0.9189867259634934
Validation loss: 2.312386281311223

Epoch: 5| Step: 7
Training loss: 0.9575902746387905
Validation loss: 2.171043110081446

Epoch: 5| Step: 8
Training loss: 0.9579056151588986
Validation loss: 2.3264307757774727

Epoch: 5| Step: 9
Training loss: 1.8635255025720932
Validation loss: 2.2231938346219757

Epoch: 5| Step: 10
Training loss: 0.7769356811467778
Validation loss: 2.33412906999526

Epoch: 500| Step: 0
Training loss: 0.9077552265215335
Validation loss: 2.220340651376928

Epoch: 5| Step: 1
Training loss: 0.8054639163089611
Validation loss: 2.31418111585674

Epoch: 5| Step: 2
Training loss: 1.0575365932256682
Validation loss: 2.3065552865669274

Epoch: 5| Step: 3
Training loss: 0.8442497892461395
Validation loss: 2.255096933729691

Epoch: 5| Step: 4
Training loss: 0.8373994254458988
Validation loss: 2.255963088912792

Epoch: 5| Step: 5
Training loss: 1.5552546554517828
Validation loss: 2.2278671011956037

Epoch: 5| Step: 6
Training loss: 0.8639883537280205
Validation loss: 2.240445147537317

Epoch: 5| Step: 7
Training loss: 1.0091714494330937
Validation loss: 2.2888744091759423

Epoch: 5| Step: 8
Training loss: 1.1380505707068584
Validation loss: 2.2703647493209584

Epoch: 5| Step: 9
Training loss: 0.909237311777356
Validation loss: 2.271275029083663

Epoch: 5| Step: 10
Training loss: 0.8973230498840824
Validation loss: 2.2809806835573383

Epoch: 501| Step: 0
Training loss: 0.8768501136277234
Validation loss: 2.341571701280759

Epoch: 5| Step: 1
Training loss: 0.7770675091670611
Validation loss: 2.3109262017214025

Epoch: 5| Step: 2
Training loss: 0.8454736129460152
Validation loss: 2.2014223802726107

Epoch: 5| Step: 3
Training loss: 0.9021094211979087
Validation loss: 2.2830835874616104

Epoch: 5| Step: 4
Training loss: 1.0668237448807072
Validation loss: 2.277914088359741

Epoch: 5| Step: 5
Training loss: 0.7545432132507996
Validation loss: 2.1741851844198354

Epoch: 5| Step: 6
Training loss: 1.0573035115798397
Validation loss: 2.3037577081936518

Epoch: 5| Step: 7
Training loss: 0.7749566850555654
Validation loss: 2.3021406692657522

Epoch: 5| Step: 8
Training loss: 1.695613078529978
Validation loss: 2.314381450157485

Epoch: 5| Step: 9
Training loss: 1.0186009748553442
Validation loss: 2.32548543665664

Epoch: 5| Step: 10
Training loss: 0.985236230155318
Validation loss: 2.272804913392556

Epoch: 502| Step: 0
Training loss: 1.1522569526699313
Validation loss: 2.2567485555405358

Epoch: 5| Step: 1
Training loss: 0.780384881722808
Validation loss: 2.2647494345967263

Epoch: 5| Step: 2
Training loss: 0.657862974391461
Validation loss: 2.278943029099003

Epoch: 5| Step: 3
Training loss: 0.6451180763250055
Validation loss: 2.204602261370223

Epoch: 5| Step: 4
Training loss: 1.0159737208376998
Validation loss: 2.252287534166482

Epoch: 5| Step: 5
Training loss: 0.9614169157674349
Validation loss: 2.316144799721162

Epoch: 5| Step: 6
Training loss: 1.7971802825331757
Validation loss: 2.362008502447577

Epoch: 5| Step: 7
Training loss: 0.8958124040036558
Validation loss: 2.2800861479616645

Epoch: 5| Step: 8
Training loss: 0.8839550557923509
Validation loss: 2.2639228885269347

Epoch: 5| Step: 9
Training loss: 0.8697161194358333
Validation loss: 2.2438804932431817

Epoch: 5| Step: 10
Training loss: 1.1529071529718766
Validation loss: 2.2569862384150063

Epoch: 503| Step: 0
Training loss: 0.9009891928385586
Validation loss: 2.287702930069097

Epoch: 5| Step: 1
Training loss: 1.0640414220483985
Validation loss: 2.294393320894665

Epoch: 5| Step: 2
Training loss: 0.9123012169437306
Validation loss: 2.2717024724266435

Epoch: 5| Step: 3
Training loss: 0.9775574460430335
Validation loss: 2.286370767503188

Epoch: 5| Step: 4
Training loss: 0.8032973790993491
Validation loss: 2.2654300378090553

Epoch: 5| Step: 5
Training loss: 1.6297599330177495
Validation loss: 2.302795348673992

Epoch: 5| Step: 6
Training loss: 0.972592761560607
Validation loss: 2.2592160903232354

Epoch: 5| Step: 7
Training loss: 0.7551007073543703
Validation loss: 2.2783556895430657

Epoch: 5| Step: 8
Training loss: 0.7771384193252128
Validation loss: 2.295754208405468

Epoch: 5| Step: 9
Training loss: 0.7825981714743494
Validation loss: 2.265120714732154

Epoch: 5| Step: 10
Training loss: 0.7823748311123206
Validation loss: 2.2971993382612412

Epoch: 504| Step: 0
Training loss: 1.010640634051332
Validation loss: 2.2243117727665838

Epoch: 5| Step: 1
Training loss: 0.8847470986824507
Validation loss: 2.270268020378788

Epoch: 5| Step: 2
Training loss: 0.8691243030858575
Validation loss: 2.2866573530701255

Epoch: 5| Step: 3
Training loss: 1.1365304902430358
Validation loss: 2.3508908952754752

Epoch: 5| Step: 4
Training loss: 0.8564396404570052
Validation loss: 2.295319719915492

Epoch: 5| Step: 5
Training loss: 0.5902423901016872
Validation loss: 2.2018795532394835

Epoch: 5| Step: 6
Training loss: 0.9497059643109367
Validation loss: 2.26068406904854

Epoch: 5| Step: 7
Training loss: 0.8990509924021215
Validation loss: 2.2505942452084984

Epoch: 5| Step: 8
Training loss: 0.8694885928923167
Validation loss: 2.1930157152211005

Epoch: 5| Step: 9
Training loss: 1.7965966714000305
Validation loss: 2.326446659417923

Epoch: 5| Step: 10
Training loss: 0.8101976492594128
Validation loss: 2.2301610174732693

Epoch: 505| Step: 0
Training loss: 0.8396699592510127
Validation loss: 2.3323991127785804

Epoch: 5| Step: 1
Training loss: 0.9475644928112553
Validation loss: 2.2478816601040754

Epoch: 5| Step: 2
Training loss: 0.7091529162456359
Validation loss: 2.3082668390229846

Epoch: 5| Step: 3
Training loss: 0.9277438193392639
Validation loss: 2.3032339666503576

Epoch: 5| Step: 4
Training loss: 0.6981198076893493
Validation loss: 2.296382855513112

Epoch: 5| Step: 5
Training loss: 0.8535233067356692
Validation loss: 2.2911933473522335

Epoch: 5| Step: 6
Training loss: 1.172392107995632
Validation loss: 2.2974548110285826

Epoch: 5| Step: 7
Training loss: 0.8721479186996507
Validation loss: 2.2748413983538427

Epoch: 5| Step: 8
Training loss: 1.726668272619102
Validation loss: 2.156165478158327

Epoch: 5| Step: 9
Training loss: 0.6881355036073351
Validation loss: 2.310495614863795

Epoch: 5| Step: 10
Training loss: 0.9691260746113834
Validation loss: 2.2519013018112597

Epoch: 506| Step: 0
Training loss: 0.8804835767606116
Validation loss: 2.23437118157054

Epoch: 5| Step: 1
Training loss: 0.8950747042651594
Validation loss: 2.2507582290450014

Epoch: 5| Step: 2
Training loss: 1.039722089865683
Validation loss: 2.34283637886017

Epoch: 5| Step: 3
Training loss: 0.9669001976828078
Validation loss: 2.23030627905488

Epoch: 5| Step: 4
Training loss: 1.301629096590829
Validation loss: 2.2799333708131924

Epoch: 5| Step: 5
Training loss: 0.48524777935764013
Validation loss: 2.2549228172498483

Epoch: 5| Step: 6
Training loss: 0.91805257211631
Validation loss: 2.2649321008914547

Epoch: 5| Step: 7
Training loss: 1.0191912906403362
Validation loss: 2.2673580284063988

Epoch: 5| Step: 8
Training loss: 1.647813579487352
Validation loss: 2.3063986189382204

Epoch: 5| Step: 9
Training loss: 0.6743111026674127
Validation loss: 2.2486534698300735

Epoch: 5| Step: 10
Training loss: 0.7657407167141612
Validation loss: 2.2537049038143215

Epoch: 507| Step: 0
Training loss: 0.9399931182507967
Validation loss: 2.2989656489108135

Epoch: 5| Step: 1
Training loss: 0.696573164709776
Validation loss: 2.2618610095693867

Epoch: 5| Step: 2
Training loss: 0.9490118232890951
Validation loss: 2.2564966996298046

Epoch: 5| Step: 3
Training loss: 0.9942350211603835
Validation loss: 2.315108123609443

Epoch: 5| Step: 4
Training loss: 0.6478927346212112
Validation loss: 2.28352222791535

Epoch: 5| Step: 5
Training loss: 0.8504974284147198
Validation loss: 2.238707662313424

Epoch: 5| Step: 6
Training loss: 1.0153123227556942
Validation loss: 2.3158899507374087

Epoch: 5| Step: 7
Training loss: 0.8398367238305294
Validation loss: 2.24630009698921

Epoch: 5| Step: 8
Training loss: 0.9805971950578807
Validation loss: 2.256876268853264

Epoch: 5| Step: 9
Training loss: 1.681661395255914
Validation loss: 2.2597069096432527

Epoch: 5| Step: 10
Training loss: 0.8271227475695289
Validation loss: 2.3530021817151057

Epoch: 508| Step: 0
Training loss: 0.7314858113423182
Validation loss: 2.283439426174451

Epoch: 5| Step: 1
Training loss: 1.7957915647152896
Validation loss: 2.288832264322682

Epoch: 5| Step: 2
Training loss: 1.029685133611481
Validation loss: 2.2227896382120944

Epoch: 5| Step: 3
Training loss: 0.7799444734543002
Validation loss: 2.277808770398172

Epoch: 5| Step: 4
Training loss: 0.6815573086687363
Validation loss: 2.2240342713232097

Epoch: 5| Step: 5
Training loss: 0.906305344305746
Validation loss: 2.2426264203465487

Epoch: 5| Step: 6
Training loss: 0.8022032231156037
Validation loss: 2.2320486605526324

Epoch: 5| Step: 7
Training loss: 0.8068812937236197
Validation loss: 2.260011983702295

Epoch: 5| Step: 8
Training loss: 1.0944271171530002
Validation loss: 2.1498840032690496

Epoch: 5| Step: 9
Training loss: 0.9571513820687436
Validation loss: 2.316778239197714

Epoch: 5| Step: 10
Training loss: 1.2266609978458471
Validation loss: 2.2402140098290033

Epoch: 509| Step: 0
Training loss: 0.7034516741266407
Validation loss: 2.202437743734254

Epoch: 5| Step: 1
Training loss: 0.905723418790988
Validation loss: 2.2502913109847844

Epoch: 5| Step: 2
Training loss: 0.8475992913160831
Validation loss: 2.182149895157381

Epoch: 5| Step: 3
Training loss: 0.6449193075257182
Validation loss: 2.2139339875804427

Epoch: 5| Step: 4
Training loss: 0.8876000280828071
Validation loss: 2.2540071722564505

Epoch: 5| Step: 5
Training loss: 0.9256597833582406
Validation loss: 2.275982402877447

Epoch: 5| Step: 6
Training loss: 0.9037827086696247
Validation loss: 2.2861670510058025

Epoch: 5| Step: 7
Training loss: 0.8491177594479712
Validation loss: 2.3190251929548045

Epoch: 5| Step: 8
Training loss: 0.8887972229806899
Validation loss: 2.224046844921272

Epoch: 5| Step: 9
Training loss: 1.133048039645967
Validation loss: 2.237675167607356

Epoch: 5| Step: 10
Training loss: 1.8104918964355283
Validation loss: 2.2070803958503955

Epoch: 510| Step: 0
Training loss: 1.0696297019970165
Validation loss: 2.2663091637146606

Epoch: 5| Step: 1
Training loss: 0.8788588447502059
Validation loss: 2.2389931517606216

Epoch: 5| Step: 2
Training loss: 0.6825909916513292
Validation loss: 2.3024319431328677

Epoch: 5| Step: 3
Training loss: 0.9873528020739317
Validation loss: 2.3434189385568724

Epoch: 5| Step: 4
Training loss: 0.9675122013357669
Validation loss: 2.188533747892699

Epoch: 5| Step: 5
Training loss: 1.8680753631991276
Validation loss: 2.3133364680345436

Epoch: 5| Step: 6
Training loss: 1.1352088049676852
Validation loss: 2.253427663363687

Epoch: 5| Step: 7
Training loss: 0.7649487213949904
Validation loss: 2.177557532735527

Epoch: 5| Step: 8
Training loss: 0.8040169820344281
Validation loss: 2.244500305024827

Epoch: 5| Step: 9
Training loss: 0.8063303279042725
Validation loss: 2.250349098614722

Epoch: 5| Step: 10
Training loss: 0.6489596275533034
Validation loss: 2.1752354977302226

Epoch: 511| Step: 0
Training loss: 0.7128531250170171
Validation loss: 2.225340351520097

Epoch: 5| Step: 1
Training loss: 0.7428477512672467
Validation loss: 2.2337434063747263

Epoch: 5| Step: 2
Training loss: 0.8452386439524404
Validation loss: 2.1939757587223143

Epoch: 5| Step: 3
Training loss: 0.8533671444164906
Validation loss: 2.259250230089559

Epoch: 5| Step: 4
Training loss: 0.9169897824906894
Validation loss: 2.268058539774885

Epoch: 5| Step: 5
Training loss: 0.8818063995044322
Validation loss: 2.296839924942759

Epoch: 5| Step: 6
Training loss: 0.6792028606654471
Validation loss: 2.2492793283782375

Epoch: 5| Step: 7
Training loss: 0.7054552248041623
Validation loss: 2.2453346046005183

Epoch: 5| Step: 8
Training loss: 1.689845609553668
Validation loss: 2.1921073086552703

Epoch: 5| Step: 9
Training loss: 1.1547279134035104
Validation loss: 2.1820483434142486

Epoch: 5| Step: 10
Training loss: 0.7875693896164616
Validation loss: 2.2586965248507913

Epoch: 512| Step: 0
Training loss: 1.0524844862095846
Validation loss: 2.2270957010419723

Epoch: 5| Step: 1
Training loss: 1.034115307526762
Validation loss: 2.2855005114873106

Epoch: 5| Step: 2
Training loss: 0.8962960637597004
Validation loss: 2.318212169614645

Epoch: 5| Step: 3
Training loss: 0.9306819950069294
Validation loss: 2.2251977761887445

Epoch: 5| Step: 4
Training loss: 0.6485471058327523
Validation loss: 2.290402529307706

Epoch: 5| Step: 5
Training loss: 0.712413304057009
Validation loss: 2.233872602474091

Epoch: 5| Step: 6
Training loss: 0.8914585562896866
Validation loss: 2.287621252382329

Epoch: 5| Step: 7
Training loss: 0.8125320208181884
Validation loss: 2.2531417687899324

Epoch: 5| Step: 8
Training loss: 0.8443690607411234
Validation loss: 2.2665791687222305

Epoch: 5| Step: 9
Training loss: 1.712475995083488
Validation loss: 2.2822646883379205

Epoch: 5| Step: 10
Training loss: 0.8839964902471543
Validation loss: 2.243694895063284

Epoch: 513| Step: 0
Training loss: 1.0675275447963513
Validation loss: 2.2588692246062143

Epoch: 5| Step: 1
Training loss: 0.7743385153019704
Validation loss: 2.2534582776594134

Epoch: 5| Step: 2
Training loss: 1.0100597786917176
Validation loss: 2.2572314523897283

Epoch: 5| Step: 3
Training loss: 0.7344984397222412
Validation loss: 2.301047974340176

Epoch: 5| Step: 4
Training loss: 1.5094884541522648
Validation loss: 2.2419392226518435

Epoch: 5| Step: 5
Training loss: 0.8477587308330022
Validation loss: 2.240323828045534

Epoch: 5| Step: 6
Training loss: 0.874936442110425
Validation loss: 2.2609017285826445

Epoch: 5| Step: 7
Training loss: 0.803181915641371
Validation loss: 2.258123457669672

Epoch: 5| Step: 8
Training loss: 0.8711991524327922
Validation loss: 2.2026264665459485

Epoch: 5| Step: 9
Training loss: 0.9501626302150157
Validation loss: 2.218429637047635

Epoch: 5| Step: 10
Training loss: 0.8074273805472107
Validation loss: 2.2245953306525306

Epoch: 514| Step: 0
Training loss: 0.6524669051272846
Validation loss: 2.3603668013501764

Epoch: 5| Step: 1
Training loss: 0.847700900119215
Validation loss: 2.229253147561122

Epoch: 5| Step: 2
Training loss: 0.9029227376773961
Validation loss: 2.2414309826931778

Epoch: 5| Step: 3
Training loss: 0.8438122691029913
Validation loss: 2.2188319610381133

Epoch: 5| Step: 4
Training loss: 0.6304534220102606
Validation loss: 2.1430647554260083

Epoch: 5| Step: 5
Training loss: 1.001398598624914
Validation loss: 2.271523056961435

Epoch: 5| Step: 6
Training loss: 0.9861870088755553
Validation loss: 2.2553291588729176

Epoch: 5| Step: 7
Training loss: 1.8836536348902766
Validation loss: 2.203770051079411

Epoch: 5| Step: 8
Training loss: 0.6535911055877761
Validation loss: 2.273498423830278

Epoch: 5| Step: 9
Training loss: 0.8615540707645943
Validation loss: 2.2657197255667048

Epoch: 5| Step: 10
Training loss: 0.6362237234629003
Validation loss: 2.183887320262389

Epoch: 515| Step: 0
Training loss: 0.764143854034375
Validation loss: 2.282444888639717

Epoch: 5| Step: 1
Training loss: 0.9285532981024796
Validation loss: 2.2780401483263235

Epoch: 5| Step: 2
Training loss: 0.9734746714639012
Validation loss: 2.2618931265238817

Epoch: 5| Step: 3
Training loss: 1.0398357640396114
Validation loss: 2.3002312923563037

Epoch: 5| Step: 4
Training loss: 1.0550570370410843
Validation loss: 2.2114942368514434

Epoch: 5| Step: 5
Training loss: 0.5813526319319369
Validation loss: 2.2583476801699844

Epoch: 5| Step: 6
Training loss: 0.7317997031891776
Validation loss: 2.2345016263475297

Epoch: 5| Step: 7
Training loss: 1.4964681211747415
Validation loss: 2.2326450249470082

Epoch: 5| Step: 8
Training loss: 0.8960418938928663
Validation loss: 2.269561412686315

Epoch: 5| Step: 9
Training loss: 0.9951419246994343
Validation loss: 2.2555376428314178

Epoch: 5| Step: 10
Training loss: 0.9147693476730289
Validation loss: 2.292095608061862

Epoch: 516| Step: 0
Training loss: 0.9482726103030329
Validation loss: 2.221544514352412

Epoch: 5| Step: 1
Training loss: 0.8553314098738909
Validation loss: 2.2994796007261153

Epoch: 5| Step: 2
Training loss: 1.0135492092582445
Validation loss: 2.2512374207511763

Epoch: 5| Step: 3
Training loss: 0.7809848335395579
Validation loss: 2.2804033222796853

Epoch: 5| Step: 4
Training loss: 0.7823010050846525
Validation loss: 2.2740969530110813

Epoch: 5| Step: 5
Training loss: 1.0701348373091042
Validation loss: 2.233223297375809

Epoch: 5| Step: 6
Training loss: 0.8750994148998726
Validation loss: 2.272407517467022

Epoch: 5| Step: 7
Training loss: 0.5885274739087334
Validation loss: 2.270566775830667

Epoch: 5| Step: 8
Training loss: 0.7509428693854827
Validation loss: 2.274912961879025

Epoch: 5| Step: 9
Training loss: 0.7513715203965715
Validation loss: 2.2876206102453103

Epoch: 5| Step: 10
Training loss: 1.8586001665053502
Validation loss: 2.2452125182411273

Epoch: 517| Step: 0
Training loss: 0.8326261301117452
Validation loss: 2.246121354042698

Epoch: 5| Step: 1
Training loss: 1.5748778825677947
Validation loss: 2.310528069356008

Epoch: 5| Step: 2
Training loss: 0.6649788984736793
Validation loss: 2.2437057611411366

Epoch: 5| Step: 3
Training loss: 0.7772336335518861
Validation loss: 2.3124833930920583

Epoch: 5| Step: 4
Training loss: 0.7502551042306229
Validation loss: 2.271386098366473

Epoch: 5| Step: 5
Training loss: 0.9665765684715312
Validation loss: 2.2213007667067615

Epoch: 5| Step: 6
Training loss: 0.9677459066191586
Validation loss: 2.2508321189577165

Epoch: 5| Step: 7
Training loss: 0.9436146961255479
Validation loss: 2.2967574989612376

Epoch: 5| Step: 8
Training loss: 0.9026294272546261
Validation loss: 2.190183703755206

Epoch: 5| Step: 9
Training loss: 0.8084721496847919
Validation loss: 2.261155864790729

Epoch: 5| Step: 10
Training loss: 0.9808696519927811
Validation loss: 2.3279781973859204

Epoch: 518| Step: 0
Training loss: 0.8321240154006677
Validation loss: 2.2928727624903975

Epoch: 5| Step: 1
Training loss: 0.7939333756453901
Validation loss: 2.2897537701283235

Epoch: 5| Step: 2
Training loss: 0.9294962325612299
Validation loss: 2.295223409915361

Epoch: 5| Step: 3
Training loss: 0.9073778566283188
Validation loss: 2.212778337714273

Epoch: 5| Step: 4
Training loss: 0.8676559626302135
Validation loss: 2.2551207909204787

Epoch: 5| Step: 5
Training loss: 1.6721522021217288
Validation loss: 2.306646696665524

Epoch: 5| Step: 6
Training loss: 0.8149859471660011
Validation loss: 2.3203360081720605

Epoch: 5| Step: 7
Training loss: 0.8667870017714686
Validation loss: 2.2283515908271374

Epoch: 5| Step: 8
Training loss: 0.7863440567426535
Validation loss: 2.281189323648876

Epoch: 5| Step: 9
Training loss: 0.6647006839077793
Validation loss: 2.2810040840212027

Epoch: 5| Step: 10
Training loss: 0.89608150563609
Validation loss: 2.1898151504668313

Epoch: 519| Step: 0
Training loss: 0.6561124294135688
Validation loss: 2.2980744009020175

Epoch: 5| Step: 1
Training loss: 1.0642926296364235
Validation loss: 2.244795126853187

Epoch: 5| Step: 2
Training loss: 0.9171265979933338
Validation loss: 2.22641047109998

Epoch: 5| Step: 3
Training loss: 0.8587759183945332
Validation loss: 2.252933180893821

Epoch: 5| Step: 4
Training loss: 1.491059760903817
Validation loss: 2.184949699654133

Epoch: 5| Step: 5
Training loss: 1.2123508695935898
Validation loss: 2.2632243336120523

Epoch: 5| Step: 6
Training loss: 0.7713300719652435
Validation loss: 2.2703502800178237

Epoch: 5| Step: 7
Training loss: 0.70059260930675
Validation loss: 2.220860576395205

Epoch: 5| Step: 8
Training loss: 0.5889570126576612
Validation loss: 2.254586432131969

Epoch: 5| Step: 9
Training loss: 1.0054760841511179
Validation loss: 2.2338317479162124

Epoch: 5| Step: 10
Training loss: 0.7630317912871803
Validation loss: 2.270407874388547

Epoch: 520| Step: 0
Training loss: 0.9114824382682608
Validation loss: 2.3469838606321365

Epoch: 5| Step: 1
Training loss: 1.0061770039494404
Validation loss: 2.28320537289725

Epoch: 5| Step: 2
Training loss: 1.576236161028306
Validation loss: 2.1510568876611136

Epoch: 5| Step: 3
Training loss: 1.178845439780947
Validation loss: 2.2648497576559725

Epoch: 5| Step: 4
Training loss: 0.7783779759507135
Validation loss: 2.2728911727525682

Epoch: 5| Step: 5
Training loss: 0.9948630415524495
Validation loss: 2.2582103947646694

Epoch: 5| Step: 6
Training loss: 0.7522643398947816
Validation loss: 2.2513003357511745

Epoch: 5| Step: 7
Training loss: 0.8491460128558497
Validation loss: 2.182727292608629

Epoch: 5| Step: 8
Training loss: 0.693985540768444
Validation loss: 2.231944186860709

Epoch: 5| Step: 9
Training loss: 0.7012430649004768
Validation loss: 2.229040176978325

Epoch: 5| Step: 10
Training loss: 0.883684116265585
Validation loss: 2.220889430230396

Epoch: 521| Step: 0
Training loss: 0.472227453766934
Validation loss: 2.3342858505835853

Epoch: 5| Step: 1
Training loss: 1.5489287951008208
Validation loss: 2.2345524241375387

Epoch: 5| Step: 2
Training loss: 0.8128712979484212
Validation loss: 2.2252356299848866

Epoch: 5| Step: 3
Training loss: 0.9084641932504789
Validation loss: 2.226936366513172

Epoch: 5| Step: 4
Training loss: 0.7027594357782926
Validation loss: 2.2119442731675822

Epoch: 5| Step: 5
Training loss: 0.9909726913588858
Validation loss: 2.241769674041592

Epoch: 5| Step: 6
Training loss: 0.7049970712330362
Validation loss: 2.240802450440614

Epoch: 5| Step: 7
Training loss: 0.6680526903738263
Validation loss: 2.244415901763495

Epoch: 5| Step: 8
Training loss: 0.812436101308159
Validation loss: 2.2377280844019527

Epoch: 5| Step: 9
Training loss: 0.992691452720769
Validation loss: 2.2862136291844077

Epoch: 5| Step: 10
Training loss: 1.0432149189385413
Validation loss: 2.2679265559322546

Epoch: 522| Step: 0
Training loss: 0.706118632226595
Validation loss: 2.2654626150922836

Epoch: 5| Step: 1
Training loss: 0.7048829249643271
Validation loss: 2.235134612629237

Epoch: 5| Step: 2
Training loss: 0.8445768896257636
Validation loss: 2.2797853024362627

Epoch: 5| Step: 3
Training loss: 1.60990652547507
Validation loss: 2.2354394792419288

Epoch: 5| Step: 4
Training loss: 0.7581651398048056
Validation loss: 2.3145900110025277

Epoch: 5| Step: 5
Training loss: 0.839745236318829
Validation loss: 2.228309863644142

Epoch: 5| Step: 6
Training loss: 0.997949942642578
Validation loss: 2.220286238280944

Epoch: 5| Step: 7
Training loss: 0.8113709454538713
Validation loss: 2.258650146776394

Epoch: 5| Step: 8
Training loss: 0.7861648458268757
Validation loss: 2.2227185847553246

Epoch: 5| Step: 9
Training loss: 0.8416784782965742
Validation loss: 2.203828060482417

Epoch: 5| Step: 10
Training loss: 1.0575665772675467
Validation loss: 2.2421348931197187

Epoch: 523| Step: 0
Training loss: 0.7413655598511675
Validation loss: 2.2512376997496997

Epoch: 5| Step: 1
Training loss: 1.095700568265873
Validation loss: 2.2214755277461222

Epoch: 5| Step: 2
Training loss: 0.7817088496274924
Validation loss: 2.2103738774056936

Epoch: 5| Step: 3
Training loss: 0.5625686073848986
Validation loss: 2.331490078299178

Epoch: 5| Step: 4
Training loss: 1.719483860442613
Validation loss: 2.1702583217338285

Epoch: 5| Step: 5
Training loss: 0.6278573049352577
Validation loss: 2.2348684128539387

Epoch: 5| Step: 6
Training loss: 0.7006112410243301
Validation loss: 2.279870590964172

Epoch: 5| Step: 7
Training loss: 1.1340949330195091
Validation loss: 2.2942293573151975

Epoch: 5| Step: 8
Training loss: 0.922897192417313
Validation loss: 2.28971803932446

Epoch: 5| Step: 9
Training loss: 0.9086395855639668
Validation loss: 2.2678837081089855

Epoch: 5| Step: 10
Training loss: 0.4447460587441078
Validation loss: 2.240534004044101

Epoch: 524| Step: 0
Training loss: 0.726926896792053
Validation loss: 2.2468249365937663

Epoch: 5| Step: 1
Training loss: 1.7200774875086464
Validation loss: 2.271286830981936

Epoch: 5| Step: 2
Training loss: 0.707222338402835
Validation loss: 2.198685513964321

Epoch: 5| Step: 3
Training loss: 1.0491977942355926
Validation loss: 2.2657807282140805

Epoch: 5| Step: 4
Training loss: 0.7812327192302667
Validation loss: 2.2711204547867605

Epoch: 5| Step: 5
Training loss: 0.8903549186373165
Validation loss: 2.2389042352463098

Epoch: 5| Step: 6
Training loss: 0.635992794772786
Validation loss: 2.284444817449006

Epoch: 5| Step: 7
Training loss: 0.902343155501529
Validation loss: 2.2734212358532413

Epoch: 5| Step: 8
Training loss: 0.7958703158974552
Validation loss: 2.2252830509452255

Epoch: 5| Step: 9
Training loss: 0.6448614950583094
Validation loss: 2.2373180000758226

Epoch: 5| Step: 10
Training loss: 0.8332917242788491
Validation loss: 2.20763792890077

Epoch: 525| Step: 0
Training loss: 0.7855131941621476
Validation loss: 2.2678975103849996

Epoch: 5| Step: 1
Training loss: 0.5397974615498826
Validation loss: 2.2328575035879363

Epoch: 5| Step: 2
Training loss: 0.8513107627658806
Validation loss: 2.2680007907947584

Epoch: 5| Step: 3
Training loss: 0.8644635144284663
Validation loss: 2.293273951309442

Epoch: 5| Step: 4
Training loss: 1.0905425316528516
Validation loss: 2.22690777032869

Epoch: 5| Step: 5
Training loss: 0.7253141035187963
Validation loss: 2.221536779142523

Epoch: 5| Step: 6
Training loss: 0.8011429504797656
Validation loss: 2.253641426875011

Epoch: 5| Step: 7
Training loss: 0.7354602910648024
Validation loss: 2.280633355044118

Epoch: 5| Step: 8
Training loss: 0.8136687309361889
Validation loss: 2.19644285764323

Epoch: 5| Step: 9
Training loss: 1.734307915017341
Validation loss: 2.2567866812679287

Epoch: 5| Step: 10
Training loss: 1.1443433379497008
Validation loss: 2.240356829904658

Epoch: 526| Step: 0
Training loss: 0.8612507203629226
Validation loss: 2.206939125588543

Epoch: 5| Step: 1
Training loss: 0.70491702281352
Validation loss: 2.2887906020102275

Epoch: 5| Step: 2
Training loss: 0.6350852279087558
Validation loss: 2.2689019312121532

Epoch: 5| Step: 3
Training loss: 1.7245776474865036
Validation loss: 2.300741649846595

Epoch: 5| Step: 4
Training loss: 1.3498734962390713
Validation loss: 2.2464308750274116

Epoch: 5| Step: 5
Training loss: 0.9889359247050082
Validation loss: 2.2531128080004414

Epoch: 5| Step: 6
Training loss: 0.9594720971491691
Validation loss: 2.2786328717169275

Epoch: 5| Step: 7
Training loss: 0.7714314116635085
Validation loss: 2.2358901364500836

Epoch: 5| Step: 8
Training loss: 0.933659571158883
Validation loss: 2.2389794466760495

Epoch: 5| Step: 9
Training loss: 0.8223812357255448
Validation loss: 2.2036120195635287

Epoch: 5| Step: 10
Training loss: 0.6921176160405064
Validation loss: 2.216970138569313

Epoch: 527| Step: 0
Training loss: 0.9780870058523172
Validation loss: 2.2170800373734894

Epoch: 5| Step: 1
Training loss: 0.6264137015276553
Validation loss: 2.2593912046356284

Epoch: 5| Step: 2
Training loss: 0.6650098886686799
Validation loss: 2.2017091070256685

Epoch: 5| Step: 3
Training loss: 0.6643026927310567
Validation loss: 2.3043355782581165

Epoch: 5| Step: 4
Training loss: 0.9594388921878036
Validation loss: 2.2459756200399683

Epoch: 5| Step: 5
Training loss: 0.6100454066136527
Validation loss: 2.224537726811283

Epoch: 5| Step: 6
Training loss: 0.7793148488049038
Validation loss: 2.2082043720589395

Epoch: 5| Step: 7
Training loss: 1.5210405321808849
Validation loss: 2.214003856452931

Epoch: 5| Step: 8
Training loss: 0.9237861543117881
Validation loss: 2.2963233619048866

Epoch: 5| Step: 9
Training loss: 1.0107189525937477
Validation loss: 2.3172988277271105

Epoch: 5| Step: 10
Training loss: 0.8906481890420197
Validation loss: 2.2572523749977575

Epoch: 528| Step: 0
Training loss: 0.8727823151020541
Validation loss: 2.201022198064999

Epoch: 5| Step: 1
Training loss: 0.8002438858928411
Validation loss: 2.284101894108085

Epoch: 5| Step: 2
Training loss: 0.7770673174055621
Validation loss: 2.2800349046193866

Epoch: 5| Step: 3
Training loss: 1.5935311260648626
Validation loss: 2.214357413167966

Epoch: 5| Step: 4
Training loss: 0.5949024510359244
Validation loss: 2.311429541751038

Epoch: 5| Step: 5
Training loss: 0.9724890630347305
Validation loss: 2.255707591998121

Epoch: 5| Step: 6
Training loss: 0.93906532579146
Validation loss: 2.2380554947826328

Epoch: 5| Step: 7
Training loss: 0.6798245741205154
Validation loss: 2.2853366323101616

Epoch: 5| Step: 8
Training loss: 0.7986201456268416
Validation loss: 2.2476051955596485

Epoch: 5| Step: 9
Training loss: 1.031693738778355
Validation loss: 2.28924518715627

Epoch: 5| Step: 10
Training loss: 0.958982945458615
Validation loss: 2.22947427120253

Epoch: 529| Step: 0
Training loss: 0.8821917013729749
Validation loss: 2.2528621660745403

Epoch: 5| Step: 1
Training loss: 0.6497889763068149
Validation loss: 2.210955411133396

Epoch: 5| Step: 2
Training loss: 1.0101993300832015
Validation loss: 2.265700356910217

Epoch: 5| Step: 3
Training loss: 1.627106768072594
Validation loss: 2.2737644136564783

Epoch: 5| Step: 4
Training loss: 0.7839479020724256
Validation loss: 2.3433488126461812

Epoch: 5| Step: 5
Training loss: 0.8824643148928608
Validation loss: 2.180497092247998

Epoch: 5| Step: 6
Training loss: 0.6386764946166786
Validation loss: 2.2842303238370474

Epoch: 5| Step: 7
Training loss: 1.120713598149886
Validation loss: 2.222804691027658

Epoch: 5| Step: 8
Training loss: 0.7128420460492364
Validation loss: 2.259045860950057

Epoch: 5| Step: 9
Training loss: 0.7258181296711415
Validation loss: 2.2405622807188244

Epoch: 5| Step: 10
Training loss: 0.8401894855789369
Validation loss: 2.222105282822351

Epoch: 530| Step: 0
Training loss: 1.0331833374205421
Validation loss: 2.189052383125316

Epoch: 5| Step: 1
Training loss: 0.7259830091763387
Validation loss: 2.1922416779895073

Epoch: 5| Step: 2
Training loss: 1.6435282133330875
Validation loss: 2.234065147306314

Epoch: 5| Step: 3
Training loss: 0.801084023898929
Validation loss: 2.2542291748534216

Epoch: 5| Step: 4
Training loss: 0.9965461152560883
Validation loss: 2.1680759346157807

Epoch: 5| Step: 5
Training loss: 0.761889668386825
Validation loss: 2.2941900267955155

Epoch: 5| Step: 6
Training loss: 0.8193603075515701
Validation loss: 2.2299684419187313

Epoch: 5| Step: 7
Training loss: 0.7952173232290877
Validation loss: 2.2850542038509576

Epoch: 5| Step: 8
Training loss: 0.7995026964997415
Validation loss: 2.2094252449169707

Epoch: 5| Step: 9
Training loss: 0.8618600807254135
Validation loss: 2.2452683539497227

Epoch: 5| Step: 10
Training loss: 0.8634560869710456
Validation loss: 2.1787950153847304

Epoch: 531| Step: 0
Training loss: 0.9139793879878898
Validation loss: 2.251801545475346

Epoch: 5| Step: 1
Training loss: 0.9938963644336393
Validation loss: 2.2714574595324013

Epoch: 5| Step: 2
Training loss: 0.8289689855537479
Validation loss: 2.255971823712441

Epoch: 5| Step: 3
Training loss: 0.6575436783558719
Validation loss: 2.259247153123281

Epoch: 5| Step: 4
Training loss: 0.7533818135514364
Validation loss: 2.2654534636706023

Epoch: 5| Step: 5
Training loss: 1.0085295854010488
Validation loss: 2.298908733195628

Epoch: 5| Step: 6
Training loss: 1.0335126964710133
Validation loss: 2.2876842963603514

Epoch: 5| Step: 7
Training loss: 0.9350520918099662
Validation loss: 2.292540884839746

Epoch: 5| Step: 8
Training loss: 1.6308574745030093
Validation loss: 2.2993782114295054

Epoch: 5| Step: 9
Training loss: 0.8551123586522416
Validation loss: 2.2827722918107893

Epoch: 5| Step: 10
Training loss: 0.6447222571126671
Validation loss: 2.2082699900887923

Epoch: 532| Step: 0
Training loss: 1.6649750549005717
Validation loss: 2.20151821968698

Epoch: 5| Step: 1
Training loss: 0.6319922558952854
Validation loss: 2.2652401606836405

Epoch: 5| Step: 2
Training loss: 0.7121309596236355
Validation loss: 2.2955791218377426

Epoch: 5| Step: 3
Training loss: 0.9129224661488065
Validation loss: 2.241016296003276

Epoch: 5| Step: 4
Training loss: 0.856832001579015
Validation loss: 2.2413594107121084

Epoch: 5| Step: 5
Training loss: 1.0696893256147064
Validation loss: 2.227958499769598

Epoch: 5| Step: 6
Training loss: 1.0872463873309588
Validation loss: 2.2337437047736017

Epoch: 5| Step: 7
Training loss: 0.6455091744782223
Validation loss: 2.226707208835521

Epoch: 5| Step: 8
Training loss: 0.5259298514197016
Validation loss: 2.2815194425253793

Epoch: 5| Step: 9
Training loss: 0.6667599364442479
Validation loss: 2.230516024361296

Epoch: 5| Step: 10
Training loss: 0.7287293394245165
Validation loss: 2.2111776022914778

Epoch: 533| Step: 0
Training loss: 0.8427288092226703
Validation loss: 2.204741138939404

Epoch: 5| Step: 1
Training loss: 0.5771674913078643
Validation loss: 2.228912325972064

Epoch: 5| Step: 2
Training loss: 0.7396589070423542
Validation loss: 2.2554003511969545

Epoch: 5| Step: 3
Training loss: 1.0441422736101018
Validation loss: 2.215004010824759

Epoch: 5| Step: 4
Training loss: 1.8101739098054181
Validation loss: 2.189267534616822

Epoch: 5| Step: 5
Training loss: 0.8120179213368977
Validation loss: 2.2445360629246913

Epoch: 5| Step: 6
Training loss: 0.7324027504013562
Validation loss: 2.2502906547776464

Epoch: 5| Step: 7
Training loss: 0.6267163551530183
Validation loss: 2.2169821879254874

Epoch: 5| Step: 8
Training loss: 0.6965689718460081
Validation loss: 2.2622366014523734

Epoch: 5| Step: 9
Training loss: 0.9863195135666001
Validation loss: 2.1663023423074392

Epoch: 5| Step: 10
Training loss: 0.8174380120856872
Validation loss: 2.2302589278303424

Epoch: 534| Step: 0
Training loss: 0.716180562419931
Validation loss: 2.247733689571092

Epoch: 5| Step: 1
Training loss: 1.711835930146199
Validation loss: 2.2471231791794737

Epoch: 5| Step: 2
Training loss: 0.6049352941511271
Validation loss: 2.3096231499231146

Epoch: 5| Step: 3
Training loss: 0.7411905519599719
Validation loss: 2.2082253615656975

Epoch: 5| Step: 4
Training loss: 0.9099731916104826
Validation loss: 2.289341730736388

Epoch: 5| Step: 5
Training loss: 0.7457770828971434
Validation loss: 2.1946138126910633

Epoch: 5| Step: 6
Training loss: 0.925303661918753
Validation loss: 2.3000944409770154

Epoch: 5| Step: 7
Training loss: 0.7673776379316382
Validation loss: 2.298453294275316

Epoch: 5| Step: 8
Training loss: 0.6513635272104803
Validation loss: 2.2488841362770198

Epoch: 5| Step: 9
Training loss: 0.7368160826705717
Validation loss: 2.266581461382911

Epoch: 5| Step: 10
Training loss: 0.8113633054067676
Validation loss: 2.1906728279980756

Epoch: 535| Step: 0
Training loss: 1.5752746221509668
Validation loss: 2.2370644768881567

Epoch: 5| Step: 1
Training loss: 0.6402288235324185
Validation loss: 2.2142339233190786

Epoch: 5| Step: 2
Training loss: 0.9692788987573197
Validation loss: 2.220976828652322

Epoch: 5| Step: 3
Training loss: 0.9318978776176706
Validation loss: 2.238447194096308

Epoch: 5| Step: 4
Training loss: 0.9301312453454137
Validation loss: 2.2366349809293378

Epoch: 5| Step: 5
Training loss: 0.9197808742790062
Validation loss: 2.2176921864259227

Epoch: 5| Step: 6
Training loss: 0.6802733954430434
Validation loss: 2.2723226782059487

Epoch: 5| Step: 7
Training loss: 0.8323722462961591
Validation loss: 2.1931695844400947

Epoch: 5| Step: 8
Training loss: 0.6088949904992721
Validation loss: 2.208452918223392

Epoch: 5| Step: 9
Training loss: 0.746170758971557
Validation loss: 2.2877254487730543

Epoch: 5| Step: 10
Training loss: 0.9643557468848492
Validation loss: 2.2289815890473337

Epoch: 536| Step: 0
Training loss: 0.8207479865020121
Validation loss: 2.2776722263496385

Epoch: 5| Step: 1
Training loss: 0.8389961401131085
Validation loss: 2.2550237519901635

Epoch: 5| Step: 2
Training loss: 0.8032849505075291
Validation loss: 2.1812012082339676

Epoch: 5| Step: 3
Training loss: 1.6596956219884733
Validation loss: 2.1935179207683904

Epoch: 5| Step: 4
Training loss: 0.7772976272164979
Validation loss: 2.2461736564101282

Epoch: 5| Step: 5
Training loss: 0.8535707224645163
Validation loss: 2.3046726021233876

Epoch: 5| Step: 6
Training loss: 1.108240595262423
Validation loss: 2.1265163997972003

Epoch: 5| Step: 7
Training loss: 0.8946042759834709
Validation loss: 2.1724298364118435

Epoch: 5| Step: 8
Training loss: 0.7495541837013514
Validation loss: 2.2155356352941475

Epoch: 5| Step: 9
Training loss: 0.7534657510771572
Validation loss: 2.2497186980557604

Epoch: 5| Step: 10
Training loss: 0.7619462676039408
Validation loss: 2.2412339627932583

Epoch: 537| Step: 0
Training loss: 0.9836922351595461
Validation loss: 2.17217809840741

Epoch: 5| Step: 1
Training loss: 1.5464068388284944
Validation loss: 2.314641967673464

Epoch: 5| Step: 2
Training loss: 0.8515281670324977
Validation loss: 2.286841425151477

Epoch: 5| Step: 3
Training loss: 0.9018641596913907
Validation loss: 2.2650977022151695

Epoch: 5| Step: 4
Training loss: 0.9381862036393841
Validation loss: 2.276229860942985

Epoch: 5| Step: 5
Training loss: 0.6729279628392099
Validation loss: 2.3032372345960703

Epoch: 5| Step: 6
Training loss: 0.8989214713155438
Validation loss: 2.2598288692225297

Epoch: 5| Step: 7
Training loss: 0.6813967905347977
Validation loss: 2.339280627525123

Epoch: 5| Step: 8
Training loss: 0.7379219755315267
Validation loss: 2.235992946172188

Epoch: 5| Step: 9
Training loss: 0.9496927529955758
Validation loss: 2.2385218522713624

Epoch: 5| Step: 10
Training loss: 0.6359128473925593
Validation loss: 2.3290550850051344

Epoch: 538| Step: 0
Training loss: 0.746506262378014
Validation loss: 2.165040394621382

Epoch: 5| Step: 1
Training loss: 0.732507075122606
Validation loss: 2.250297010637

Epoch: 5| Step: 2
Training loss: 0.9234863035986323
Validation loss: 2.223609406069847

Epoch: 5| Step: 3
Training loss: 0.5198657744282266
Validation loss: 2.166736682899597

Epoch: 5| Step: 4
Training loss: 0.755205053563505
Validation loss: 2.1958922387511177

Epoch: 5| Step: 5
Training loss: 1.0847182530357518
Validation loss: 2.2508991853395046

Epoch: 5| Step: 6
Training loss: 0.6913474537478163
Validation loss: 2.1443139393926267

Epoch: 5| Step: 7
Training loss: 0.9681659599194798
Validation loss: 2.2317737640542727

Epoch: 5| Step: 8
Training loss: 0.9015498776932361
Validation loss: 2.1877695720303163

Epoch: 5| Step: 9
Training loss: 1.5846804442913434
Validation loss: 2.1880742557172126

Epoch: 5| Step: 10
Training loss: 0.6297756606640307
Validation loss: 2.1932645162546085

Epoch: 539| Step: 0
Training loss: 0.6780084940594883
Validation loss: 2.2080380255272485

Epoch: 5| Step: 1
Training loss: 0.9237770243861293
Validation loss: 2.2117250550770713

Epoch: 5| Step: 2
Training loss: 0.6496302653501725
Validation loss: 2.180405230026141

Epoch: 5| Step: 3
Training loss: 1.6016410250137831
Validation loss: 2.202972183390868

Epoch: 5| Step: 4
Training loss: 0.9249659622218936
Validation loss: 2.178947242756508

Epoch: 5| Step: 5
Training loss: 0.6277201348845572
Validation loss: 2.230830369761718

Epoch: 5| Step: 6
Training loss: 0.8378964581764466
Validation loss: 2.1723623914423644

Epoch: 5| Step: 7
Training loss: 0.587762001135745
Validation loss: 2.2946588348471004

Epoch: 5| Step: 8
Training loss: 0.855037493413489
Validation loss: 2.202494055947489

Epoch: 5| Step: 9
Training loss: 0.6309906908488161
Validation loss: 2.270166629063775

Epoch: 5| Step: 10
Training loss: 1.1137875660427456
Validation loss: 2.2637856807603276

Epoch: 540| Step: 0
Training loss: 0.8871835507113173
Validation loss: 2.256286730055583

Epoch: 5| Step: 1
Training loss: 0.5934206651546572
Validation loss: 2.251771479043571

Epoch: 5| Step: 2
Training loss: 0.8409804702264718
Validation loss: 2.1855266571246115

Epoch: 5| Step: 3
Training loss: 0.8104898823383694
Validation loss: 2.2524296575539395

Epoch: 5| Step: 4
Training loss: 0.7657138227982941
Validation loss: 2.231277849218856

Epoch: 5| Step: 5
Training loss: 1.6397467306005329
Validation loss: 2.2051902655358324

Epoch: 5| Step: 6
Training loss: 0.9833290052857492
Validation loss: 2.3078292053481393

Epoch: 5| Step: 7
Training loss: 0.66506565841844
Validation loss: 2.2558044299053277

Epoch: 5| Step: 8
Training loss: 0.8403591969524989
Validation loss: 2.186184866618901

Epoch: 5| Step: 9
Training loss: 1.118046250446106
Validation loss: 2.2372689635595333

Epoch: 5| Step: 10
Training loss: 0.7014122553564256
Validation loss: 2.2689285380279407

Epoch: 541| Step: 0
Training loss: 0.8679703624033952
Validation loss: 2.2378711352994083

Epoch: 5| Step: 1
Training loss: 0.5521464371754616
Validation loss: 2.2228070455618223

Epoch: 5| Step: 2
Training loss: 0.8491473114370931
Validation loss: 2.245785310387691

Epoch: 5| Step: 3
Training loss: 0.8507288080311775
Validation loss: 2.266738939113294

Epoch: 5| Step: 4
Training loss: 1.7394279897926772
Validation loss: 2.259303253164337

Epoch: 5| Step: 5
Training loss: 0.9694496212638593
Validation loss: 2.222920244793004

Epoch: 5| Step: 6
Training loss: 0.7535232203423616
Validation loss: 2.189628049981748

Epoch: 5| Step: 7
Training loss: 0.4796452171254234
Validation loss: 2.231744001014284

Epoch: 5| Step: 8
Training loss: 0.7239992189640237
Validation loss: 2.21145293757398

Epoch: 5| Step: 9
Training loss: 0.7954632464465572
Validation loss: 2.3018325155278947

Epoch: 5| Step: 10
Training loss: 0.7384711127394123
Validation loss: 2.242760642930033

Epoch: 542| Step: 0
Training loss: 1.0337382266793744
Validation loss: 2.228626653496627

Epoch: 5| Step: 1
Training loss: 0.8567263621622241
Validation loss: 2.2542174428672017

Epoch: 5| Step: 2
Training loss: 1.6131474991374437
Validation loss: 2.2182142092299326

Epoch: 5| Step: 3
Training loss: 0.7219397214469454
Validation loss: 2.2203992508247854

Epoch: 5| Step: 4
Training loss: 0.7875614051493371
Validation loss: 2.1593961787999807

Epoch: 5| Step: 5
Training loss: 0.5509530198653279
Validation loss: 2.3266185129446035

Epoch: 5| Step: 6
Training loss: 0.6840940552008065
Validation loss: 2.25328058721643

Epoch: 5| Step: 7
Training loss: 0.804419389521017
Validation loss: 2.2354870900013433

Epoch: 5| Step: 8
Training loss: 0.7145909346981595
Validation loss: 2.2333360762625967

Epoch: 5| Step: 9
Training loss: 0.9439340108885148
Validation loss: 2.1953720921399156

Epoch: 5| Step: 10
Training loss: 0.861447211443239
Validation loss: 2.2679557802719783

Epoch: 543| Step: 0
Training loss: 0.7206939448570562
Validation loss: 2.2070315794527526

Epoch: 5| Step: 1
Training loss: 0.8325223950647225
Validation loss: 2.231886537792179

Epoch: 5| Step: 2
Training loss: 0.8100953096665314
Validation loss: 2.1488076901817696

Epoch: 5| Step: 3
Training loss: 0.5830511080258401
Validation loss: 2.2411714452454876

Epoch: 5| Step: 4
Training loss: 0.8176627460253038
Validation loss: 2.1454206580195856

Epoch: 5| Step: 5
Training loss: 1.7119754795475377
Validation loss: 2.234708703006253

Epoch: 5| Step: 6
Training loss: 0.4860501241649857
Validation loss: 2.2049324873093927

Epoch: 5| Step: 7
Training loss: 0.7164706285476765
Validation loss: 2.2405702751965135

Epoch: 5| Step: 8
Training loss: 0.5587976790360164
Validation loss: 2.2274180862709945

Epoch: 5| Step: 9
Training loss: 1.2645072710937595
Validation loss: 2.201783451856454

Epoch: 5| Step: 10
Training loss: 0.7998552504359353
Validation loss: 2.228747545720536

Epoch: 544| Step: 0
Training loss: 0.5771789542713366
Validation loss: 2.2405624088686844

Epoch: 5| Step: 1
Training loss: 0.9151731411177992
Validation loss: 2.1592273531859734

Epoch: 5| Step: 2
Training loss: 0.6354225163633478
Validation loss: 2.2293228255340276

Epoch: 5| Step: 3
Training loss: 0.9381258147335899
Validation loss: 2.2256698272577267

Epoch: 5| Step: 4
Training loss: 0.691913267970874
Validation loss: 2.2419113315533403

Epoch: 5| Step: 5
Training loss: 0.8584055894851018
Validation loss: 2.300658142371913

Epoch: 5| Step: 6
Training loss: 0.597879953841212
Validation loss: 2.2475018813069596

Epoch: 5| Step: 7
Training loss: 0.7034406165550061
Validation loss: 2.2153509917442507

Epoch: 5| Step: 8
Training loss: 1.683427346628946
Validation loss: 2.2882830238922884

Epoch: 5| Step: 9
Training loss: 0.6060261283535743
Validation loss: 2.23698616812243

Epoch: 5| Step: 10
Training loss: 0.8306707443373981
Validation loss: 2.24412044607214

Epoch: 545| Step: 0
Training loss: 1.6884147848959101
Validation loss: 2.221824568971746

Epoch: 5| Step: 1
Training loss: 0.8445754781570077
Validation loss: 2.2495526888332917

Epoch: 5| Step: 2
Training loss: 0.7523381820266687
Validation loss: 2.2342782304023565

Epoch: 5| Step: 3
Training loss: 0.7564462359851467
Validation loss: 2.2517293985714653

Epoch: 5| Step: 4
Training loss: 0.8397782411088103
Validation loss: 2.182402081087052

Epoch: 5| Step: 5
Training loss: 0.703819398253212
Validation loss: 2.2904826583769036

Epoch: 5| Step: 6
Training loss: 0.7829790056295783
Validation loss: 2.2643066247912285

Epoch: 5| Step: 7
Training loss: 0.6704327384329433
Validation loss: 2.207351199941821

Epoch: 5| Step: 8
Training loss: 0.6949238494621991
Validation loss: 2.3037074365314383

Epoch: 5| Step: 9
Training loss: 0.5730869011399261
Validation loss: 2.2460772193703438

Epoch: 5| Step: 10
Training loss: 0.7775918382577384
Validation loss: 2.2958027829718395

Epoch: 546| Step: 0
Training loss: 0.7502622145993476
Validation loss: 2.1592980554676076

Epoch: 5| Step: 1
Training loss: 0.7766564939785008
Validation loss: 2.275073615569707

Epoch: 5| Step: 2
Training loss: 1.6352177476686858
Validation loss: 2.2210481242406237

Epoch: 5| Step: 3
Training loss: 0.9699417597698474
Validation loss: 2.256719077579793

Epoch: 5| Step: 4
Training loss: 0.6906957693650008
Validation loss: 2.2377402259083032

Epoch: 5| Step: 5
Training loss: 0.6989404561409138
Validation loss: 2.155157290609649

Epoch: 5| Step: 6
Training loss: 0.9104462845012482
Validation loss: 2.2297580184953403

Epoch: 5| Step: 7
Training loss: 0.7409931008510677
Validation loss: 2.2742198971692735

Epoch: 5| Step: 8
Training loss: 0.7748428831501393
Validation loss: 2.2036612306174144

Epoch: 5| Step: 9
Training loss: 0.7585018994151042
Validation loss: 2.1851061953003783

Epoch: 5| Step: 10
Training loss: 0.7738509566180197
Validation loss: 2.2667351740715347

Epoch: 547| Step: 0
Training loss: 0.8855219086575924
Validation loss: 2.216634642932306

Epoch: 5| Step: 1
Training loss: 0.7685002813022275
Validation loss: 2.2040130296350333

Epoch: 5| Step: 2
Training loss: 0.8683765267253967
Validation loss: 2.268050595845034

Epoch: 5| Step: 3
Training loss: 0.9529749642773244
Validation loss: 2.246418778210098

Epoch: 5| Step: 4
Training loss: 1.0155527529328858
Validation loss: 2.215530231537071

Epoch: 5| Step: 5
Training loss: 0.7145968985497994
Validation loss: 2.3227919159657167

Epoch: 5| Step: 6
Training loss: 1.6441399115454172
Validation loss: 2.251358481226304

Epoch: 5| Step: 7
Training loss: 0.725963550745565
Validation loss: 2.15214027914182

Epoch: 5| Step: 8
Training loss: 0.4831876198725662
Validation loss: 2.2643007781195856

Epoch: 5| Step: 9
Training loss: 0.9034241982598735
Validation loss: 2.226301762948582

Epoch: 5| Step: 10
Training loss: 0.7747015978479458
Validation loss: 2.192206382417251

Epoch: 548| Step: 0
Training loss: 0.8758593494666054
Validation loss: 2.2275686308335807

Epoch: 5| Step: 1
Training loss: 0.8900482920606976
Validation loss: 2.2106340786335856

Epoch: 5| Step: 2
Training loss: 0.5828145024569477
Validation loss: 2.246075962133537

Epoch: 5| Step: 3
Training loss: 0.7985686088161761
Validation loss: 2.227766896097014

Epoch: 5| Step: 4
Training loss: 1.5904026408181247
Validation loss: 2.2012765321605077

Epoch: 5| Step: 5
Training loss: 0.6644915821354562
Validation loss: 2.151319332168774

Epoch: 5| Step: 6
Training loss: 0.7459345942401903
Validation loss: 2.311307818745986

Epoch: 5| Step: 7
Training loss: 0.7715095226197078
Validation loss: 2.2585393569716707

Epoch: 5| Step: 8
Training loss: 0.8982850650342057
Validation loss: 2.3297715466007087

Epoch: 5| Step: 9
Training loss: 0.8458697571138883
Validation loss: 2.2282354483531415

Epoch: 5| Step: 10
Training loss: 0.7779796050862617
Validation loss: 2.2934114147994284

Epoch: 549| Step: 0
Training loss: 1.7167343110889335
Validation loss: 2.2673349232674025

Epoch: 5| Step: 1
Training loss: 0.8171906421958366
Validation loss: 2.218498592411549

Epoch: 5| Step: 2
Training loss: 0.7236592523478201
Validation loss: 2.2205390043752886

Epoch: 5| Step: 3
Training loss: 0.6555271254542167
Validation loss: 2.2603981690613733

Epoch: 5| Step: 4
Training loss: 1.221730914974376
Validation loss: 2.30537736654412

Epoch: 5| Step: 5
Training loss: 0.9467968596895885
Validation loss: 2.2648026792634663

Epoch: 5| Step: 6
Training loss: 0.9833645554343428
Validation loss: 2.213252690156112

Epoch: 5| Step: 7
Training loss: 0.8420132670886353
Validation loss: 2.150095360356504

Epoch: 5| Step: 8
Training loss: 0.8154351696812346
Validation loss: 2.22527716568245

Epoch: 5| Step: 9
Training loss: 0.541531561239055
Validation loss: 2.295288396265203

Epoch: 5| Step: 10
Training loss: 0.7970128033733193
Validation loss: 2.283218687320201

Epoch: 550| Step: 0
Training loss: 0.7468056602691576
Validation loss: 2.230361177583669

Epoch: 5| Step: 1
Training loss: 0.5882327076209929
Validation loss: 2.261404061029086

Epoch: 5| Step: 2
Training loss: 0.7970919968100493
Validation loss: 2.227075835031097

Epoch: 5| Step: 3
Training loss: 1.473197453060015
Validation loss: 2.246663275336041

Epoch: 5| Step: 4
Training loss: 0.948047244681344
Validation loss: 2.215626511322408

Epoch: 5| Step: 5
Training loss: 0.8066670780601188
Validation loss: 2.225190922361282

Epoch: 5| Step: 6
Training loss: 0.8959472642944609
Validation loss: 2.181926116255764

Epoch: 5| Step: 7
Training loss: 0.8898474327326017
Validation loss: 2.2486076912370274

Epoch: 5| Step: 8
Training loss: 0.6973740095427926
Validation loss: 2.2533508976955465

Epoch: 5| Step: 9
Training loss: 0.8945017647360659
Validation loss: 2.1788819303040623

Epoch: 5| Step: 10
Training loss: 0.8194387960149487
Validation loss: 2.1794157117135504

Testing loss: 3.1441939926678795
